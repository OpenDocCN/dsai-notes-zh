<!--yml

分类: 未分类

日期: 2024-09-03 17:29:45

-->

# 超越链式思维：针对大型语言模型的链式思维范式调查

> 来源：[`arxiv.org/html/2404.15676`](https://arxiv.org/html/2404.15676)

1.  [1 介绍](https://arxiv.org/html/2404.15676v1#S1 "在 超越链式思维：针对大型语言模型的链式思维范式调查")

    1.  [动机](https://arxiv.org/html/2404.15676v1#S1.SS0.SSS0.Px1 "在 1 介绍 ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

    1.  [区分焦点](https://arxiv.org/html/2404.15676v1#S1.SS0.SSS0.Px2 "在 1 介绍 ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

    1.  [调查概述](https://arxiv.org/html/2404.15676v1#S1.SS0.SSS0.Px3 "在 1 介绍 ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

1.  [2 什么是链式思维？](https://arxiv.org/html/2404.15676v1#S2 "在 超越链式思维：针对大型语言模型的链式思维范式调查")

    1.  [链式思维](https://arxiv.org/html/2404.15676v1#S2.SS0.SSS0.Px1 "在 2 什么是链式思维？ ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

    1.  [链式思维的变体](https://arxiv.org/html/2404.15676v1#S2.SS0.SSS0.Px2 "在 2 什么是链式思维？ ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

1.  [3 链式思维节点](https://arxiv.org/html/2404.15676v1#S3 "在 超越链式思维：针对大型语言模型的链式思维范式调查")

    1.  [3.1 链式中介](https://arxiv.org/html/2404.15676v1#S3.SS1 "在 3 链式思维节点 ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

        1.  [问题分解](https://arxiv.org/html/2404.15676v1#S3.SS1.SSS0.Px1 "在 3.1 链式中介 ‣ 3 链式思维节点 ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

        1.  [知识组合](https://arxiv.org/html/2404.15676v1#S3.SS1.SSS0.Px2 "在 3.1 链式中介 ‣ 3 链式思维节点 ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

    1.  [3.2 链式增强](https://arxiv.org/html/2404.15676v1#S3.SS2 "在 3 链式思维节点 ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

        1.  [指令](https://arxiv.org/html/2404.15676v1#S3.SS2.SSS0.Px1 "在 3.2 链式增强 ‣ 3 链式思维节点 ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

        1.  [历史](https://arxiv.org/html/2404.15676v1#S3.SS2.SSS0.Px2 "在 3.2 链式增强 ‣ 3 链式思维节点 ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

        1.  [检索](https://arxiv.org/html/2404.15676v1#S3.SS2.SSS0.Px3 "在 3.2 链式增强 ‣ 3 链式思维节点 ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

        1.  [其他](https://arxiv.org/html/2404.15676v1#S3.SS2.SSS0.Px4 "在 3.2 链式增强 ‣ 3 链式思维节点 ‣ 超越链式思维：针对大型语言模型的链式思维范式调查")

    1.  [3.3 反馈链](https://arxiv.org/html/2404.15676v1#S3.SS3 "在 3 Chain-of-X 节点 ‣ 超越链式思维：大语言模型链式范式的调查")

        1.  [外部反馈](https://arxiv.org/html/2404.15676v1#S3.SS3.SSS0.Px1 "在 3.3 反馈链 ‣ 3 Chain-of-X 节点 ‣ 超越链式思维：大语言模型链式范式的调查")

        1.  [自我优化](https://arxiv.org/html/2404.15676v1#S3.SS3.SSS0.Px2 "在 3.3 反馈链 ‣ 3 Chain-of-X 节点 ‣ 超越链式思维：大语言模型链式范式的调查")

    1.  [3.4 模型链](https://arxiv.org/html/2404.15676v1#S3.SS4 "在 3 Chain-of-X 节点 ‣ 超越链式思维：大语言模型链式范式的调查")

1.  [4 Chain-of-X 任务](https://arxiv.org/html/2404.15676v1#S4 "在超越链式思维：大语言模型链式范式的调查")

    1.  [4.1 多模态交互](https://arxiv.org/html/2404.15676v1#S4.SS1 "在 4 Chain-of-X 任务 ‣ 超越链式思维：大语言模型链式范式的调查")

        1.  [文本-图像](https://arxiv.org/html/2404.15676v1#S4.SS1.SSS0.Px1 "在 4.1 多模态交互 ‣ 4 Chain-of-X 任务 ‣ 超越链式思维：大语言模型链式范式的调查")

        1.  [文本-表格](https://arxiv.org/html/2404.15676v1#S4.SS1.SSS0.Px2 "在 4.1 多模态交互 ‣ 4 Chain-of-X 任务 ‣ 超越链式思维：大语言模型链式范式的调查")

        1.  [文本-代码](https://arxiv.org/html/2404.15676v1#S4.SS1.SSS0.Px3 "在 4.1 多模态交互 ‣ 4 Chain-of-X 任务 ‣ 超越链式思维：大语言模型链式范式的调查")

        1.  [文本-语音](https://arxiv.org/html/2404.15676v1#S4.SS1.SSS0.Px4 "在 4.1 多模态交互 ‣ 4 Chain-of-X 任务 ‣ 超越链式思维：大语言模型链式范式的调查")

    1.  [4.2 事实性与安全性](https://arxiv.org/html/2404.15676v1#S4.SS2 "在 4 Chain-of-X 任务 ‣ 超越链式思维：大语言模型链式范式的调查")

        1.  [幻觉减少](https://arxiv.org/html/2404.15676v1#S4.SS2.SSS0.Px1 "在 4.2 事实性与安全性 ‣ 4 Chain-of-X 任务 ‣ 超越链式思维：大语言模型链式范式的调查")

        1.  [对齐](https://arxiv.org/html/2404.15676v1#S4.SS2.SSS0.Px2 "在 4.2 事实性与安全性 ‣ 4 Chain-of-X 任务 ‣ 超越链式思维：大语言模型链式范式的调查")

    1.  [4.3 多步骤推理](https://arxiv.org/html/2404.15676v1#S4.SS3 "在 4 Chain-of-X 任务 ‣ 超越链式思维：大语言模型链式范式的调查")

    1.  [4.4 指令遵循](https://arxiv.org/html/2404.15676v1#S4.SS4 "在 4 Chain-of-X 任务 ‣ 超越链式思维：大语言模型链式范式的调查")

    1.  [4.5 作为代理的大语言模型](https://arxiv.org/html/2404.15676v1#S4.SS5 "在 4 Chain-of-X 任务 ‣ 超越链式思维：大语言模型链式范式的调查")

    1.  [4.6 评估工具](https://arxiv.org/html/2404.15676v1#S4.SS6 "在 4 Chain-of-X 任务 ‣ 超越链式思维：大语言模型链式范式的调查")

1.  [5 个未来方向](https://arxiv.org/html/2404.15676v1#S5 "在超越认知链：LLM 的链式 X 范式综述")

    1.  [因果中介分析](https://arxiv.org/html/2404.15676v1#S5.SS0.SSS0.Px1 "在 5 个未来方向 ‣ 超越认知链：LLM 的链式 X 范式综述")

    1.  [降低推理成本](https://arxiv.org/html/2404.15676v1#S5.SS0.SSS0.Px2 "在 5 个未来方向 ‣ 超越认知链：LLM 的链式 X 范式综述")

    1.  [知识蒸馏](https://arxiv.org/html/2404.15676v1#S5.SS0.SSS0.Px3 "在 5 个未来方向 ‣ 超越认知链：LLM 的链式 X 范式综述")

    1.  [端到端微调](https://arxiv.org/html/2404.15676v1#S5.SS0.SSS0.Px4 "在 5 个未来方向 ‣ 超越认知链：LLM 的链式 X 范式综述")

1.  [6 结论](https://arxiv.org/html/2404.15676v1#S6 "在超越认知链：LLM 的链式 X 范式综述")

1.  [节点和任务的分类法](https://arxiv.org/html/2404.15676v1#A1 "在超越认知链：LLM 的链式 X 范式综述")

# 超越思维链：LLM 的链式 X 范式综述

Yu Xia^(1,2)  Rui Wang³  Xu Liu¹  Mingyan Li¹  Tong Yu⁴

Xiang Chen⁴  Julian McAuley²  Shuai Li¹

¹上海交通大学  ²加州大学圣地亚哥分校  ³杜克大学  ⁴Adobe 研究

{yux078, jmcauley}@ucsd.edu   {tyu, xiangche}@adobe.com

rui.wang16@duke.edu  {liu_skywalker, QYLJM1217, shuaili8}@sjtu.edu.cn   通讯作者。

###### 摘要

思维链（CoT）是一种被广泛采用的提示方法，引起了大语言模型（LLM）令人印象深刻的推理能力。受 CoT 的连续思维结构启发，已经开发了一些链式 X（CoX）方法，以应对涉及 LLM 的各种领域和任务的各种挑战。在本文中，我们提供了 LLM 不同上下文中的 CoX 方法的全面调查。具体来说，我们通过节点（即 CoX 中的 X）和应用任务的分类法对它们进行分类。我们还讨论了现有 CoX 方法的发现和意义，以及潜在的未来方向。我们的调查旨在成为寻求将 CoT 的理念应用于更广泛场景的研究人员的详尽和及时的资源。

超越认知链：LLM 的链式 X 范式综述

Yu Xia^(1,2)  Rui Wang³  Xu Liu¹  Mingyan Li¹  Tong Yu⁴ Xiang Chen⁴  Julian McAuley²  Shuai Li¹^†^†感谢：  通讯作者。 ¹上海交通大学  ²加州大学圣地亚哥分校  ³杜克大学  ⁴Adobe 研究 {yux078, jmcauley}@ucsd.edu   {tyu, xiangche}@adobe.com rui.wang16@duke.edu  {liu_skywalker, QYLJM1217, shuaili8}@sjtu.edu.cn

## 1 引言

大型语言模型 (LLMs) 在使用 Chain-of-Thought (CoT) 方法时表现出了强大的推理能力 Wei et al. ([2022](https://arxiv.org/html/2404.15676v1#bib.bib59)); Yao et al. ([2024](https://arxiv.org/html/2404.15676v1#bib.bib70)); Besta et al. ([2024a](https://arxiv.org/html/2404.15676v1#bib.bib6))。CoT 的本质是将复杂问题分解为一系列中间子任务 Chu et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib10)); Zhou et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib85))。通过逐步处理这些子任务，LLMs 能够专注于重要的细节和假设，从而显著提高其在各种推理任务中的表现 Huang 和 Chang ([2023](https://arxiv.org/html/2404.15676v1#bib.bib24)); Chu et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib10))。此外，CoT 的中间步骤提供了更透明的推理过程，便于对 LLMs 进行解释和评估 Yu et al. ([2023b](https://arxiv.org/html/2404.15676v1#bib.bib72))。

随着 CoT 的成功，许多 Chain-of-X (CoX) 方法相继被开发出来 Yu et al. ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib71))。超越推理思维，近期的 CoX 方法构建了包含各种组件的链，例如 Chain-of-Feedback Lei et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib33)); Dhuliawala et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib11))，Chain-of-Instructions Zhang et al. ([2023d](https://arxiv.org/html/2404.15676v1#bib.bib83)); Hayati et al. ([2024](https://arxiv.org/html/2404.15676v1#bib.bib18))，Chain-of-Histories Luo et al. ([2024](https://arxiv.org/html/2404.15676v1#bib.bib41)); Xia et al. ([2024d](https://arxiv.org/html/2404.15676v1#bib.bib65))，等等。这些方法已被应用于解决涉及 LLMs 的多种任务挑战，超越了推理，包括多模态交互 Xi et al. ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib60)); Zhang et al. ([2024a](https://arxiv.org/html/2404.15676v1#bib.bib78))，幻觉减少 Lei et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib33)); Dhuliawala et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib11))，与基于 LLM 的代理进行规划 Zhan 和 Zhang ([2023](https://arxiv.org/html/2404.15676v1#bib.bib76)); Zhang et al. ([2024c](https://arxiv.org/html/2404.15676v1#bib.bib80))，等等。

#### 动机

尽管这些 CoX 方法越来越普遍，但它们尚未被系统地审查或分类，导致我们对它们的潜力和细微差别了解不足。为此，本调查旨在提供一个结构化的概述，捕捉 CoX 方法的本质和多样性，以便进一步探索和创新。

#### 区分重点

虽然几项调查已经探讨了 CoT Chu 等（[2023](https://arxiv.org/html/2404.15676v1#bib.bib10)）；Yu 等（[2023b](https://arxiv.org/html/2404.15676v1#bib.bib72)）；Besta 等（[2024b](https://arxiv.org/html/2404.15676v1#bib.bib7)），但它们主要关注不同结构的推理思维，例如图中的 Chain-of-Thought [1](https://arxiv.org/html/2404.15676v1#S1.F1 "Figure 1 ‣ Overview of the Survey ‣ 1 Introduction ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")(a)。相比之下，本文关注于 Chain-of-X 的多面组件设计，超越了推理思维，如图 [1](https://arxiv.org/html/2404.15676v1#S1.F1 "Figure 1 ‣ Overview of the Survey ‣ 1 Introduction ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs") 所示，提供了 CoT 概念在更广泛领域的见解。我们通过 CoX 中 X 的分类以及这些方法应用的任务进行全面回顾。

#### 调查概述

我们首先提供 Chain-of-Thought 的背景信息，并将 Chain-of-X 定义为其推广（§[2](https://arxiv.org/html/2404.15676v1#S2 "2 What is Chain-of-X? ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）。接下来，我们根据用于构建链的组件类型对 CoX 方法进行分类（§[3](https://arxiv.org/html/2404.15676v1#S3 "3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）。此外，根据这些 CoX 方法的应用领域，我们按任务对它们进行分类（§[4](https://arxiv.org/html/2404.15676v1#S4 "4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）。然后，我们讨论现有 CoX 方法的见解，并探索潜在的未来方向（§[5](https://arxiv.org/html/2404.15676v1#S5 "5 Future Directions ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）。调查的详细结构见图 [2](https://arxiv.org/html/2404.15676v1#S2.F2 "Figure 2 ‣ Chain-of-X ‣ 2 What is Chain-of-X? ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")。

图 1：四种节点类型的链式 X 范式插图：（a）中间节点，例如，思维（§[3.1](https://arxiv.org/html/2404.15676v1#S3.SS1 "3.1 Chain-of-Intermediates ‣ 3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")），（b）增强（§[3.2](https://arxiv.org/html/2404.15676v1#S3.SS2 "3.2 Chain-of-Augmentation ‣ 3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")），（c）反馈（§[3.3](https://arxiv.org/html/2404.15676v1#S3.SS3 "3.3 Chain-of-Feedback ‣ 3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")），（d）模型（§[3.4](https://arxiv.org/html/2404.15676v1#S3.SS4 "3.4 Chain-of-Models ‣ 3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）。

## 2 什么是链式 X？

在本节中，我们介绍了一些关于链式思维提示（Chain-of-Thought prompting）的背景信息，并定义了一个链式 X 的广义概念。

#### 链式思维

链式思维提示（CoT prompting）是一种显著增强大型语言模型（LLMs）推理能力的方法。由 Wei 等人（[2022](https://arxiv.org/html/2404.15676v1#bib.bib59)）首次提出，链式思维提示涉及使用结构化格式的<input, thoughts, output>来提示 LLMs，其中“thoughts”包括连贯的、逐步的自然语言推理过程，最终得出答案。链式思维在需要复杂推理的任务中效果最为显著。传统的少样本学习方法在这种情况下往往效果不佳，因为它们倾向于提供直接答案，而没有必要的中间步骤。Rae 等人（[2021](https://arxiv.org/html/2404.15676v1#bib.bib49)）指出了这一局限性，指出随着模型规模的增加，这些方法的不足之处。相比之下，链式思维提示通过融入中间推理步骤而表现优异。这些步骤引导模型通过逻辑推理过程，提高其处理复杂问题的能力，如涉及算术、常识和符号推理的问题 Wang 等人（[2023d](https://arxiv.org/html/2404.15676v1#bib.bib56)）；Lyu 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib42)）。链式思维的本质在于通过将复杂问题分解为可管理的中间步骤来应对这些问题 Zhou 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib85)）。Kojima 等人（[2022](https://arxiv.org/html/2404.15676v1#bib.bib27)）也通过提示“让我们一步一步来思考”展示了零样本链式思维的强大表现。明确的推理步骤还为模型的思维过程提供了透明的路径，允许进一步的评估和修正 Yu 等人（[2023b](https://arxiv.org/html/2404.15676v1#bib.bib72)）。

#### 链式 X

受到 CoT 序列分解特性的启发，最近开发了大量的 CoX 方法（Yu et al. ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib71)））。在这里，我们将 CoX 定义为 CoT 方法在超越 LLM 推理的多样化任务中的一种推广。我们将 CoX 中的 X 称为链结构中的“节点”。除了 CoT 提示中的思考，CoX 中的 X 可以采取多种形式，针对特定任务进行定制，包括中间体（§[3.1](https://arxiv.org/html/2404.15676v1#S3.SS1 "3.1 Chain-of-Intermediates ‣ 3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）、增强（§[3.2](https://arxiv.org/html/2404.15676v1#S3.SS2 "3.2 Chain-of-Augmentation ‣ 3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）、反馈（§[3.3](https://arxiv.org/html/2404.15676v1#S3.SS3 "3.3 Chain-of-Feedback ‣ 3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")），甚至模型（§[3.4](https://arxiv.org/html/2404.15676v1#S3.SS4 "3.4 Chain-of-Models ‣ 3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")），如图 [1](https://arxiv.org/html/2404.15676v1#S1.F1 "Figure 1 ‣ Overview of the Survey ‣ 1 Introduction ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs") 所示。我们在图 [2](https://arxiv.org/html/2404.15676v1#S2.F2 "Figure 2 ‣ Chain-of-X ‣ 2 What is Chain-of-X? ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs") 中总结了现有 CoX 方法中节点的类型。CoX 的理念是构建一系列与问题相关的组件，这些组件要么通过组合性方式对解决方案做出贡献，要么通过迭代方式改进复杂任务的输出。同样，我们将 CoX 的结构化格式定义为 <input, X[1], $\dots$, X[n], output>，其中 $n$ 是链的长度。注意，这种格式超出了 CoT 等提示策略的范围，并且可以适应多种算法框架或结构，涉及各种涉及 LLM 的任务。例如，Chain-of-Verification（Dhuliawala et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib11)））是一个幻觉减少框架，它利用 LLM 生成初步回应，编排一系列验证问题，并根据这些问题修正其之前的回应。除了幻觉减少，CoX 方法已被应用于各种任务，如图 [2](https://arxiv.org/html/2404.15676v1#S2.F2 "Figure 2 ‣ Chain-of-X ‣ 2 What is Chain-of-X? ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs") 所示，包括多模态互动（§[4.1](https://arxiv.org/html/2404.15676v1#S4.SS1 "4.1 Multi-Modal Interaction ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）、事实性与安全性（§[4.2](https://arxiv.org/html/2404.15676v1#S4.SS2 "4.2 Factuality & Safety ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）、多步骤推理（§[4.3](https://arxiv.org/html/2404.15676v1#S4.SS3 "4.3 Multi-Step Reasoning ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）、指令跟随（§[4.4](https://arxiv.org/html/2404.15676v1#S4.SS4 "4.4 Instruction Following ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）、LLM 作为代理（§[4.5](https://arxiv.org/html/2404.15676v1#S4.SS5 "4.5 LLMs as Agents ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）和评估工具（§[4.6](https://arxiv.org/html/2404.15676v1#S4.SS6 "4.6 Evaluation Tools ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")）。

{森林}

对于 tree= font=, draw=myblue, semithick, rounded corners, minimum height = 1.5ex, minimum width = 2em, anchor = west, grow = east, forked edge, s sep = 0.8mm, l sep = 3.5mm, fork sep = 2mm, [链式任务调查，rotate=90, anchor=center [任务分类 (§[4](https://arxiv.org/html/2404.15676v1#S4 "4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")), fit=band, text width=1cm [评估工具

(§[4.6](https://arxiv.org/html/2404.15676v1#S4.SS6 "4.6 Evaluation Tools ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")), text width=2.1cm, l sep = 2mm [例如，CoUtterances Bhardwaj 和 Poria ([2023](https://arxiv.org/html/2404.15676v1#bib.bib8)), CoImages Meng 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib44)), CoFeedback Ahn 和 Shin ([2024](https://arxiv.org/html/2404.15676v1#bib.bib3)), text width=10.9cm, fill=lightblue] ] [LLMs 作为代理

(§[4.5](https://arxiv.org/html/2404.15676v1#S4.SS5 "4.5 LLMs as Agents ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，文本宽度=2.1cm，左边距=2mm [例如，CoAction^a Zhan 和 Zhang（[2023](https://arxiv.org/html/2404.15676v1#bib.bib76)），CoSummarization Ma 等（[2023](https://arxiv.org/html/2404.15676v1#bib.bib43)），Co3DThought Yamada 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib69)），CoActionThought Zhang 等（[2024c](https://arxiv.org/html/2404.15676v1#bib.bib80)），CoAbstraction Gao 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib14)），CoContacts Xiao 等（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib66)），文本宽度=10.9cm，填充=lightblue] ] [指令跟随 (§[4.4](https://arxiv.org/html/2404.15676v1#S4.SS4 "4.4 Instruction Following ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，文本宽度=2.1cm，左边距=2mm [例如，CoTask Li 等（[2024b](https://arxiv.org/html/2404.15676v1#bib.bib37)），CoInstructions Hayati 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib18)），CoModality Zhang 等（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib77)），文本宽度=10.9cm，填充=lightblue] ] [多步骤推理 (§[4.3](https://arxiv.org/html/2404.15676v1#S4.SS3 "4.3 Multi-Step Reasoning ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，文本宽度=2.1cm，左边距=2mm [例如，CoT Wei 等（[2022](https://arxiv.org/html/2404.15676v1#bib.bib59)），CoKnowledge^b Wang 等（[2023c](https://arxiv.org/html/2404.15676v1#bib.bib55)），CoMemory Hu 等（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib20)），CoReference Kuppa 等（[2023](https://arxiv.org/html/2404.15676v1#bib.bib28)），CoQuery Xu 等（[2023](https://arxiv.org/html/2404.15676v1#bib.bib68)），CoLogic Servantez 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib50)），CoFeedback Ahn 和 Shin（[2024](https://arxiv.org/html/2404.15676v1#bib.bib3)），文本宽度=10.9cm，填充=lightblue] ] [事实性与安全 (§[4.2](https://arxiv.org/html/2404.15676v1#S4.SS2 "4.2 Factuality & Safety ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，文本宽度=2.1cm [对齐，文本宽度=1.3cm，左边距=2mm [例如，CoUtterances Bhardwaj 和 Poria（[2023](https://arxiv.org/html/2404.15676v1#bib.bib8)），CoHindsight Liu 等（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib38)），文本宽度=9.0cm，填充=lightblue] ] [幻觉减少，文本宽度=1.3cm，左边距=2mm [例如，CoNLI Lei 等（[2023](https://arxiv.org/html/2404.15676v1#bib.bib33)），CoVerification Dhuliawala 等（[2023](https://arxiv.org/html/2404.15676v1#bib.bib11)），CoKnowledge^a Li 等（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib36)），CoNote Yu 等（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib71)），CoQuestion Huang 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib25)），CoAction^b Pan 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib46)），文本宽度=9.0cm，填充=lightblue] ] ] [多模态交互 (§[4.1](https://arxiv.org/html/2404.15676v1#S4.SS1 "4.1 Multi-Modal Interaction ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，文本宽度=2.1cm [文本-语音，文本宽度=1.3cm，左边距=2mm [例如，CoInformation Zhang 等（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib78)），CoModality Zhang 等（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib77)），文本宽度=9.0cm，填充=lightblue] ] [文本-代码，文本宽度=1.3cm，左边距=2mm [例如，CoRepair Wang 等（[2023b](https://arxiv.org/html/2404.15676v1#bib.bib54)），CoCode Li 等（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib34)），CoSimulation La Malfa 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib29)），文本宽度=9.0cm，填充=lightblue] ] [文本-表格，文本宽度=1.3cm，左边距=2mm [例如，CoCommand Zha 等（[2023](https://arxiv.org/html/2404.15676v1#bib.bib75)），CoTable Wang 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib58)），文本宽度=9.0cm，填充=lightblue] ] [文本-图像，文本宽度=1.3cm，左边距=2mm [例如，CoLook Xi 等（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib60)），CoSpot Liu 等（[2024b](https://arxiv.org/html/2404.15676v1#bib.bib39)），CoReasoning Uehara 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib52)），文本宽度=9.0cm，填充=lightblue] ] ] ] [节点分类 (§[3](https://arxiv.org/html/2404.15676v1#S3 "3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，适合带状，文本宽度=1cm [Chain-of-Models

（§[3.4](https://arxiv.org/html/2404.15676v1#S3.SS4 "3.4 模型链 ‣ 3 增补链节点 ‣ 超越思维链：LLM 的增补链范式综述")），文本宽度=2.1cm，左边距=2mm [例如，CoExperts Xiao 等（[2024b](https://arxiv.org/html/2404.15676v1#bib.bib67)），CoDiscussion Tao 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib51)），CoLoRA Xia 等（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib62)），文本宽度=10.9cm，填充色=浅蓝色] ] [反馈链 (§[3.3](https://arxiv.org/html/2404.15676v1#S3.SS3 "3.3 反馈链 ‣ 3 增补链节点 ‣ 超越思维链：LLM 的增补链范式综述"))，文本宽度=2.1cm [自我完善，文本宽度=1.3cm，左边距=2mm [例如，CoVerification Dhuliawala 等（[2023](https://arxiv.org/html/2404.15676v1#bib.bib11)），CoSelfRevisions Le 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib30)），文本宽度=9.0cm，填充色=浅蓝色] ] [外部

反馈，文本宽度=1.3cm，左边距=2mm [例如，CoRepair Wang 等（[2023b](https://arxiv.org/html/2404.15676v1#bib.bib54)），CoHindsight Liu 等（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib38)），文本宽度=9.0cm，填充色=浅蓝色] ] ] [增补链 (§[3.2](https://arxiv.org/html/2404.15676v1#S3.SS2 "3.2 增补链 ‣ 3 增补链节点 ‣ 超越思维链：LLM 的增补链范式综述"))，文本宽度=2.1cm [其他，文本宽度=1.3cm，左边距=2mm [例如，CoReference Kuppa 等（[2023](https://arxiv.org/html/2404.15676v1#bib.bib28)），CoDictionary Lu 等（[2023](https://arxiv.org/html/2404.15676v1#bib.bib40)），CoMemory Hu 等（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib20)），文本宽度=9.0cm，填充色=浅蓝色] ] [检索，文本宽度=1.3cm，左边距=2mm [例如，CoQuery Xu 等（[2023](https://arxiv.org/html/2404.15676v1#bib.bib68)），CoKnowledge^a Li 等（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib36)），CoQuestion Huang 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib25)），文本宽度=9.0cm，填充色=浅蓝色] ] [历史，文本宽度=1.3cm，左边距=2mm [例如，CoOpinion Do 等（[2023](https://arxiv.org/html/2404.15676v1#bib.bib12)），CoHistory^a Luo 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib41)），CoHistory^b Xia 等（[2024d](https://arxiv.org/html/2404.15676v1#bib.bib65)），文本宽度=9.0cm，填充色=浅蓝色] ] [指令，文本宽度=1.3cm，左边距=2mm [例如，CoInstructEditing Zhang 等（[2023d](https://arxiv.org/html/2404.15676v1#bib.bib83)），CoInstructions Hayati 等（[2024](https://arxiv.org/html/2404.15676v1#bib.bib18)），文本宽度=9.0cm，填充色=浅蓝色] ] ] [中介链 (§[3.1](https://arxiv.org/html/2404.15676v1#S3.SS1 "3.1 中介链 ‣ 3 增补链节点 ‣ 超越思维链：LLM 的增补链范式综述"))，文本宽度=2.1cm [知识

组成，文本宽度=1.3cm，l sep = 2mm [例如，CoSymbol Hu 等人 ([2023b](https://arxiv.org/html/2404.15676v1#bib.bib22))，CoKnowledge^b Wang 等人 ([2023c](https://arxiv.org/html/2404.15676v1#bib.bib55))，CoManipulation Qi 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib47))，CoSimulation La Malfa 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib29))，CoSpot Liu 等人 ([2024b](https://arxiv.org/html/2404.15676v1#bib.bib39))，文本宽度=9.0cm，填充=浅蓝色] ] [问题

分解，文本宽度=1.3cm，l sep = 2mm [例如，CoT Wei 等人 ([2022](https://arxiv.org/html/2404.15676v1#bib.bib59))，CoCode Li 等人 ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib34))，CoTable Wang 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib58))，CoLogic Servantez 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib50))，CoEvent Bao 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib5))，CoInteraction Han 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib17))，文本宽度=9.0cm，填充=浅蓝色] ] ] ] ]

图 2: 基于节点和任务的 Chain-of-X 调查（由于空间限制，仅列出了代表性方法，更完整的版本可以在附录 [A](https://arxiv.org/html/2404.15676v1#A1 "附录 A 节点和任务的分类 ‣ 超越链式思维：链式思维（CoX）范式的调查") 中找到）。

## 3 Chain-of-X 节点

在本节中，我们通过节点的分类调查现有的 CoX 方法，如图 [2](https://arxiv.org/html/2404.15676v1#S2.F2 "图 2 ‣ Chain-of-X ‣ 2 什么是 Chain-of-X? ‣ 超越链式思维：链式思维（CoX）范式的调查") 所示，基于节点的不同性质对其进行分类。

### 3.1 中间链

基于利用明确中间步骤的概念，链式思维（CoT）的自然演变是用其他类型的中间组件来替代推理思维，即中间链（Chain-of-Intermediates）。根据主要关注点，我们将其进一步划分为以下子类型。

#### 问题分解

在问题分解中，中间步骤由从原始复杂问题中派生出的可管理的子任务组成。这种方法的经典例子是**Wei et al.** 提出的 Chain-of-Thought 方法（[2022](https://arxiv.org/html/2404.15676v1#bib.bib59)）。进一步扩展，**Li et al.**（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib34)）提出了 Chain-of-Code 方法，它将任务划分为编程子任务，通过模拟代码输出增强推理过程。类似地，**Wang et al.**（[2024](https://arxiv.org/html/2404.15676v1#bib.bib58)）开发了 Chain-of-Table 框架。该框架通过一系列战略操作将复杂的表格重构为特定问题的格式，使数据更加易于访问并适应查询。此外，**Servantez et al.**（[2024](https://arxiv.org/html/2404.15676v1#bib.bib50)）提出的 Chain-of-Logic 方法，将逻辑分解应用于基于规则的推理任务，将其转化为一系列逻辑表达式。方法论上的分解有助于更清晰的推理路径。这些分解方法也在 Chain-of-Event 中得到了体现，**Han et al.**（[2024](https://arxiv.org/html/2404.15676v1#bib.bib17)）将多文档总结简化为离散且可管理的事件提取任务，从而显著提高质量并减少潜在错误。

#### 知识构成

在知识构成中，中间步骤的主要目标不是简化，而是积累相关的信息和证据。这种方法旨在通过丰富的理解和细节来增强解决方案。例如，**Hu et al.**（[2023b](https://arxiv.org/html/2404.15676v1#bib.bib22)）提出了 Chain-of-Symbol 方法，该方法在空间规划任务中精确收集空间关系，从而提高模型的准确性和有效性。同样，**La Malfa et al.**（[2024](https://arxiv.org/html/2404.15676v1#bib.bib29)）采用 Chain-of-Simulation 提示，以确保代码执行中的每一步都由程序跟踪信息指导，从而避免记忆陷阱。**Wang et al.**（[2023c](https://arxiv.org/html/2404.15676v1#bib.bib55)）采用类似的方法，通过 Chain-of-Knowledge 在每一步提取关键证据，以支持更有根据和可靠的问答环节。这种技术在促进对查询材料的深刻理解方面尤其有效。在视觉任务中，像 Chain-of-Spot（**Liu et al.**（[2024b](https://arxiv.org/html/2404.15676v1#bib.bib39)））和 Chain-of-Reasoning（**Uehara et al.**（[2024](https://arxiv.org/html/2404.15676v1#bib.bib52)））的方法帮助视觉语言模型专注于特定的图像细节，这对于需要详细视觉证据的任务至关重要。通过这些富有证据的方法，LLMs 实现了对复杂场景的全面而细致的理解，从而产生更高质量的输出。

### 3.2 Chain-of-Augmentation

CoX 方法的一个流行变体是 Chain-of-Augmentation，其中链条被额外知识增强。根据增强数据的类型，我们将其分类如下。

#### 指令

指令作为一种重要的补充，引导 LLMs 通过复杂的推理或任务执行过程，其中确定下一步可能并非易事 Zha 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib75)）。例如，Chain-of-InstructEditing 框架 Zhang 等人（[2023d](https://arxiv.org/html/2404.15676v1#bib.bib83)）利用这一概念，通过生成顺序指令来指导图像编辑任务，展示了如何通过关注相关区域来细化输出。此外，Zha 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib75)）引入了 Chain-of-Command 来处理用户指令中的模糊性，特别是表格操作中的模糊性。通过从用户指令中推断，它使得 LLMs 能够使用一系列精确的预定义命令来进行更准确的表格执行。在电子商务领域，Li 等人（[2024b](https://arxiv.org/html/2404.15676v1#bib.bib37)）使用类似的结构化方法，即 Chain-of-Task，将客户交互分解为可管理的基本任务，从而显著简化复杂操作。类似地，Hayati 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib18)）提出的 Chain-of-Instructions 框架通过使用前一步骤的输出作为下一步骤的指令，迭代解决分解的子任务。结果表明，逐步引导可以显著改善复杂问题解决任务的过程和结果。

#### 历史

利用历史数据进行有根据的预测建模是 Chain-of-Augmentation 的另一个方面，从过去的互动或事件中提取上下文洞察。这种方法的例子是 Do 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib12)）的 Chain-of-Opinion，它通过分析历史用户意见来预测未来的反应，为用户情感提供宝贵的前瞻性。在用户界面探索中，Zhan 和 Zhang（[2023](https://arxiv.org/html/2404.15676v1#bib.bib76)）应用了 Chain-of-Action^a 框架，利用过去的行为来指导未来的互动，从而通过学习行为优化用户体验。Ma 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib43)）在类似 StarCraft II 的游戏环境中采取了类似的方法，其中 Chain-of-Summarization 根据对过去游戏观察的综合提供战略建议。分类结构的发展也从历史数据中获益，正如 Zeng 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib74)）的 Chain-of-Layer 所示，它基于以前识别的类别来增强分类任务。时序知识图谱也得到了前瞻性的处理，例如 Luo 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib41)）和 Xia 等人（[2024d](https://arxiv.org/html/2404.15676v1#bib.bib65)）的 Chain-of-History，其中历史图谱结构用于预测未来的联系和互动。

#### 检索

Chain-of-Retrievals 方法旨在将生成过程与一系列明确的检索序列交替进行，从而提高生成内容的质量（Zhao 等人，[2023](https://arxiv.org/html/2404.15676v1#bib.bib84)）。例如，Xu 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib68)）提出了 Chain-of-Query 框架，通过系统地安排问答对来提升 LLMs 的搜索能力，每对问答都旨在增强信息检索。类似地，Huang 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib25)）提出的 Chain-of-Question 专注于改进查询机制，其中从原始问题分解出的每个子问题有助于从外部知识库中检索更准确的知识。进一步完善这一概念，Li 等人（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib36)）构建了 Chain-of-Knowledge，该方法动态地从知识库中提取相关信息，以纠正和调整 CoT 框架中的不一致推理。这些方法展示了战略性检索集成如何提高 LLMs 的问题解决准确性，从而提升输出的保真度。

#### 其他

除了常规的增强类型外，各种特定领域的增强方法也被应用于 LLM 的 CoX 方法。在情感智能领域，Lee 等人（[2023b](https://arxiv.org/html/2404.15676v1#bib.bib32)）引入了同理心链，将心理治疗的见解融入，以培养 LLM 的同理回应。与此同时，Kuppa 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib28)）提出了参考链方法，整合法律框架，以细致拆解和解决复杂的法律问题，展示了 CoX 在专业领域中的多功能性。类似地，Gao 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib14)）开发了抽象链框架，利用特定领域工具填补 LLM 推理链中故意留出的抽象占位符。语言工具的增强在字典链 Lu 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib40)）中也有体现，该方法通过针对每句话量身定制的多语种字典增强了机器翻译。这些多样化的增强方法不仅扩展了 LLM 的操作范围，还突显了量身定制的领域特定增强的潜力。

### 3.3 反馈链

反馈链代表了 CoX 的另一种变体。与通常在生成前进行的增强不同，反馈在生成过程中贯穿于整个过程，以增强和优化回应。根据反馈来源，我们将其分类为外部和自我精炼反馈。

#### 外部反馈

外部来源的反馈提供了有价值的外部视角，可以指导 LLM 的精炼过程。例如，Yamada 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib69)）引入了 3D 思想链，利用外部批评帮助迭代地完善 LLM 对 3D 空间的理解。类似地，Wang 等人（[2023b](https://arxiv.org/html/2404.15676v1#bib.bib54)）在其修复链中采用了教师-学生框架，其中编译器的反馈首先由教师 LLM 解释，然后用于指导学生 LLM 进行代码生成。这种方法不仅纠正了错误，还促进了学生模型的学习过程，使其随着时间的推移逐渐提高。此外，Liu 等人（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib38)）开发了后见链，将直接的人类偏好转化为更符合 LLM 处理信息方式的自然语言反馈。这些反馈使模型输出的精炼更加精准，确保响应既准确又符合上下文。

#### 自我精炼

外部反馈的潜在成本和不可用性引发了对 LLM 自我完善能力的日益关注。李等人 ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib31)) 进行了强调。Lei 等人 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib33)) 提出的自然语言推理链（Chain-of-NLI）指导 LLM 通过一系列基于初始响应的自然语言推理任务来评估和完善其输出。呼应这种方法，Dhuliawala 等人 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib11)) 引入了验证链（Chain-of-Verification），使 LLM 能够通过一系列自生成的验证问题进行自我评估，从而得到逐渐完善的答案。这两种方法都能自动识别并纠正无根据的输出，提高响应的可靠性。Adams 等人 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib1)) 进一步发展了这一概念，引入了密度链（Chain-of-Density），使 LLM 能够将自我检测到的缺失信息迭代地融入先前的输出中。结合自我修订链（Chain-of-SelfRevisions）（Le 等人，[2024](https://arxiv.org/html/2404.15676v1#bib.bib30)）和反馈链（Chain-of-Feedback）（Ahn 和 Shin，[2024](https://arxiv.org/html/2404.15676v1#bib.bib3)），这些框架展示了 LLM 如何利用自身的输出进行持续自我提升。

### 3.4 模型链

之前的 CoX 方法大多是为单一 LLM 设计的。认识到不同的 LLM 可能具有不同的专长，Xiao 等人 ([2024b](https://arxiv.org/html/2404.15676v1#bib.bib67)); Xia 等人 ([2024b](https://arxiv.org/html/2404.15676v1#bib.bib63))，另一系列工作提议构建模型链以利用每个模型的不同优势。**专家链** Xiao 等人 ([2024b](https://arxiv.org/html/2404.15676v1#bib.bib67)) 就是这一协作策略的典型例子。它涉及一个专家 LLM 联盟，这些 LLM 按顺序工作，每个 LLM 提供其专业知识以在前任所发展的推理基础上进行构建。这种方法在解决操作研究中的复杂问题时特别有效，因为这些问题的复杂性往往超出了单一 LLM 的处理能力。同样，Qiu 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib48)) 部署了一系列专门的 LoRA（低秩自适应 Hu 等人 ([2022](https://arxiv.org/html/2404.15676v1#bib.bib21))) 网络，每个网络针对广泛问题的不同领域进行微调。这种量身定制的方法确保了特定任务受益于最相关和有效的专长，从而提高了整体效率和结果准确性。同时，Tao 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib51)) 开发了 **讨论链**，其中多个 LLM 参与结构化对话，批评和改进彼此的贡献，然后在最终回应中达成共识。这一过程确保了合成输出不仅全面，而且从多个角度经过了严格的评估。

## 4 Chain-of-X 任务

正如前一节所述，CoX 的节点可以有多种形式，使其应用超越 LLM 推理。本节调查了按任务分类的现有 CoX 方法，如图 [2](https://arxiv.org/html/2404.15676v1#S2.F2 "图 2 ‣ Chain-of-X ‣ 2 什么是 Chain-of-X？ ‣ 超越 Chain-of-Thought：针对 LLM 的 Chain-of-X 范式的调查") 所示。

### 4.1 多模态互动

尽管 CoT 最初是为文本生成提出的，但已经开发了各种 CoX 方法来解决多模态中的挑战。

#### 文本-图像

在视觉语言模型领域，文本数据和视觉数据之间的协同作用至关重要 Zhang 等人 ([2024b](https://arxiv.org/html/2404.15676v1#bib.bib79))。CoX 方法在增强这种交互方面发挥了重要作用。例如，Chain-of-InstructEditing Zhang 等人 ([2023d](https://arxiv.org/html/2404.15676v1#bib.bib83)) 利用基于文本的指令来指导图像编辑的细微任务，特别是面部操作。该方法确保图像修改严格遵循文本描述，从而提高了编辑的准确性和相关性。同样，Chain-of-Look Xi 等人 ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib60)) 通过构建视觉语义推理链来引入一种结构化的视觉实体识别方法，该方法镜像了 CoT 的逻辑进程。该方法通过描述性的文本提示促进了对视觉元素的更深入理解和识别。此外，Chain-of-QA Kim 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib26)) 将这种方法扩展到 LLM 和视觉问答模型之间的动态对话中，通过文本和视觉分析的结合解决复杂问题。另外，Chain-of-Reasoning Uehara 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib52)) 和 Chain-of-Manipulation Qi 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib47)) 重点关注在图像中识别和解释关键细节的过程。这些方法系统地引导模型关注图像的特定区域，从而提高了模型的视觉推理能力，实现更精确的响应。

#### Text-Table

复杂表格数据处理的挑战也通过 CoX 方法进行了研究。例如，Chain-of-Command Zha 等人 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib75)) 向 LLM 提供了一系列预定义的命令，引导它们准确地操作表格。这种结构化的指导有助于防止因任务要求的模糊或不正确解释而导致的错误。相关地，Chain-of-Table Wang 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib58)) 利用表格数据作为推理链的一部分。在这里，表格不仅是数据源，还在推理过程中作为不断发展的实体，根据 LLM 的查询和任务动态更新和完善自己。这种迭代过程使模型能够更自然、更有效地处理表格，从而对所包含的信息有更细致的理解和操作。

#### Text-Code

代码生成是另一个受益于 CoX 方法引入的任务 Zan 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib73)）。例如，Chain-of-Code Li 等人（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib34)）通过将问题分解为一系列程序并模拟代码执行来解决任务，从而有效地应对整体任务。基于这一思路，Chain-of-Simulation La Malfa 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib29)）采取了逐行执行代码的细化方法。相比之下，Chain-of-Repair Wang 等人（[2023b](https://arxiv.org/html/2404.15676v1#bib.bib54)）从传统的调试过程中汲取灵感，利用编译器的反馈不仅识别而且解释错误，从而帮助 LLM 在生成修复时实现更深层次的学习。同时，Chain-of-SelfRevisions Le 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib30)）探索了一种创意重用策略，将之前任务中的代码片段回收到新项目中，提高了效率并促进了模块化的代码生成方法。这些方法共同突显了 CoX 技术在优化代码生成任务中的多功能性，彰显了其适应和回应编程复杂性的能力。

#### 文本-语音

同样，语音生成领域也见证了 CoX 方法的创新应用。例如，Chain-of-Information Zhang 等人（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib78)）通过系统地分离和重新组合语义与感知组件来提升语音合成，这使得语音输出更加细腻和准确。另一种方法是 Chain-of-Modality Zhang 等人（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib77)），它将文本和语音指令结合起来以引导语音生成过程。这种方法不仅提高了语音生成的质量，还赋予 LLMs 处理对话细微差别的能力，有效地弥合了文本与语音数据之间的差距。

### 4.2 事实性与安全性

确保 LLM 输出的事实一致性和安全性至关重要 Wang 等人（[2023e](https://arxiv.org/html/2404.15676v1#bib.bib57)）；Zhang 等人（[2023c](https://arxiv.org/html/2404.15676v1#bib.bib82)）；Dong 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib13)）。为了使 LLM 生成更具事实性和安全性的输出，近期的研究探索了 CoX 方法在幻觉减少和对齐中的应用。

#### 幻觉减少

大型语言模型（LLMs）表现出产生幻觉的倾向 Akhtar et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib4)); Agrawal et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib2)); Xia et al. ([2024c](https://arxiv.org/html/2404.15676v1#bib.bib64))。研究探讨了使用 CoX 方法来减少幻觉。例如，Chain-of-NLI Lei et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib33)) 利用从初始模型输出中得出的自然语言推理问题序列来指导系统性的修订，从而提高后续响应的事实准确性。类似地，Chain-of-Verification Dhuliawala et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib11)) 促使 LLM 生成并回答其自己的验证问题，使其能够批判性地评估和修正其响应。此外，认识到检索增强方法在用准确的信息支撑响应方面的有效性 Gao et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib15))，一些 CoX 方法，例如 Chain-of-Note Yu et al. ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib71))、Chain-of-Knowledge^a Li et al. ([2024a](https://arxiv.org/html/2404.15676v1#bib.bib36))、Chain-of-Action^b Pan et al. ([2024](https://arxiv.org/html/2404.15676v1#bib.bib46))，已被实施以在每一步检索并整合领域特定知识，从而有效减少错误或误导性信息的发生。

#### 对齐

将 LLM 与人类偏好对齐是 CoX 方法显示出有希望的结果的另一个关键领域 Wang et al. ([2023e](https://arxiv.org/html/2404.15676v1#bib.bib57))。为了增强 LLM 对人类偏好的理解，Chain-of-Hindsight Liu et al. ([2024a](https://arxiv.org/html/2404.15676v1#bib.bib38)) 将其转化为自然语言反馈序列以进行微调。利用 LLM 的语言理解能力，Chain-of-Hindsight 实现了比以前的 RLHF 方法 Ouyang et al. ([2022](https://arxiv.org/html/2404.15676v1#bib.bib45)) 更优的对齐性能。同时，Chain-of-Utterance prompting Bhardwaj and Poria ([2023](https://arxiv.org/html/2404.15676v1#bib.bib8)) 已被提出用于 LLM 的红队测试，建立了一个有害 LLM 和一个有益但不安全的 LLM 之间的越狱对话。通过 Chain-of-Utterances 收集的有害问题被用于创建 HarmfulQA 数据集，作为进一步安全对齐工作的基础 Bhardwaj and Poria ([2023](https://arxiv.org/html/2404.15676v1#bib.bib8))。通过整合这些方法，CoX 框架不仅提升了 LLM 的即时效用，也为开发有效且符合伦理的 AI 系统作出了贡献。

### 4.3 多步骤推理

推理一直是一个广泛研究的主题，特别是那些要求对上下文和逻辑有强大理解的多步骤推理任务 Wei 等 ([2022](https://arxiv.org/html/2404.15676v1#bib.bib59))。CoX 方法的顺序特性使它们非常适合这项任务。例如，Chain-of-Knowledge^b Wang 等 ([2023c](https://arxiv.org/html/2404.15676v1#bib.bib55)) 在每一步都引出明确的知识证据，从而提高了 LLMs 在各种推理任务中的表现。同时，Chain-of-Feedback Ahn 和 Shin ([2024](https://arxiv.org/html/2404.15676v1#bib.bib3)) 通过将初始的错误推理步骤分解为更小的、独立的任务来修正错误，从而实现更扎实的推理。其他专业的推理任务包括基于规则的推理 Servantez 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib50))，数据库推理 Hu 等 ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib20))，法律推理 Kuppa 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib28))，用户行为推理 Do 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib12))；Han 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib17))，结构和图形推理 Zeng 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib74))；Luo 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib41))；Xia 等 ([2024d](https://arxiv.org/html/2404.15676v1#bib.bib65))，以及文本摘要推理 Adams 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib1))；Bao 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib5)) 和机器翻译 Lu 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib40))。通过这些多样的应用，CoX 方法展示了其将复杂任务分解为可管理步骤的能力，从而提升了 LLMs 有效处理和分析信息的能力。

### 4.4 指令跟随

指令跟随，作为大型语言模型（LLMs）的一项重要能力，使得人类能够为各种任务提供明确的指导（Zhang et al. ([2023b](https://arxiv.org/html/2404.15676v1#bib.bib81))）。CoX 方法的演变也带来了增强这一特性的多种方法。例如，任务链（Chain-of-Task）（Li et al. ([2024b](https://arxiv.org/html/2404.15676v1#bib.bib37))）提供了一种结构化的方法，其中每条指令由中间的原子任务组成，专门策划以微调电子商务 LLM 的回应，以更好地满足客户需求。延伸这一概念，指令链（Chain-of-Instructions）（Hayati et al. ([2024](https://arxiv.org/html/2404.15676v1#bib.bib18))）引入了一种组合方法，其中每个输出直接作为下一个的输入，形成一个连续的任务特定调整循环，逐步优化 LLM 的任务处理。对于语音生成应用，模态链（Chain-of-Modality）（Zhang et al. ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib77))）构建了一个由文本和语音指令串联组成的微调序列。此外，LoRA 指令链（Chain-of-LoRA）（Qiu et al. ([2024](https://arxiv.org/html/2404.15676v1#bib.bib48))）使用 LoRA 网络来专门处理指令，通过针对每个 LoRA 调整指令微调过程，从而在各种任务中优化性能。这些进展强调了 CoX 方法如何提升 LLM 的指令跟随能力，使其能够更清晰地理解和执行任务。

### 4.5 LLMs 作为代理

凭借强大的规划能力，LLMs 已被用于广泛的任务中，Xi 等人 ([2023b](https://arxiv.org/html/2404.15676v1#bib.bib61))。CoX 方法已被探索以进一步提升基于 LLM 的代理的规划能力。在这方面，Chain-of-Action^a Zhan 和 Zhang ([2023](https://arxiv.org/html/2404.15676v1#bib.bib76)) 和 Chain-of-ActionThought Zhang 等人 ([2024c](https://arxiv.org/html/2404.15676v1#bib.bib80)) 利用一系列计划好的行动来指导代理的决策，确保每一步都受到前一步的影响。而在像 StarCraft II 这样的游戏中，Chain-of-Summarization Ma 等人 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib43)) 使用 LLMs 总结过去的观察结果，以建议未来的策略。Chain-of-3DThought Yamada 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib69)) 进一步利用 LLM 代理通过在 3D 模拟环境中的试错来合成图像中的对象。LLMs 还在与人类场景互动任务中作为规划者发挥作用，如 Chain-of-Contacts Xiao 等人 ([2024a](https://arxiv.org/html/2404.15676v1#bib.bib66))，以及在工具使用任务中，如 Chain-of-Abstraction Gao 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib14))。CoX 方法也被应用于多代理设置中，如 Chain-of-Experts Xiao 等人 ([2024b](https://arxiv.org/html/2404.15676v1#bib.bib67)) 和 Chain-of-Discussion Tao 等人 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib51))。这些方法突显了 CoX 方法在提升 LLMs 作为自主和协作代理的多维能力中的整合作用。

### 4.6 评估工具

随着 LLM 的复杂度不断提高，评估 LLM 变得越来越具有挑战性，Chang 等人 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib9)) 认为 CoX 方法在评估过程中具有重要价值。Bhardwaj 和 Poria ([2023](https://arxiv.org/html/2404.15676v1#bib.bib8)) 提出的链式对话提示就是 CoX 方法如何照亮特定关注领域的一个典型例子，比如在 LLM 与潜在有害模型互动的场景中安全问题。该方法揭示了可能导致 LLM 越狱的脆弱对话，为 LLM 安全性提供了重要见解。此外，Ahn 和 Shin ([2024](https://arxiv.org/html/2404.15676v1#bib.bib3)) 的反馈链方法展示了提示对 LLM 性能的影响。通过反复提供像“再试一次”这样的无信息提示，研究人员观察到响应质量逐渐下降。在视觉推理方面，Meng 等人 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib44)) 提出的图像链基准涉及一系列图像，旨在逐步评估 LLM 的推理能力。它为衡量模型在解释视觉数据方面的能力提供了强有力的工具。这些 CoX 方法强调了对 LLM 进行更细致评估的重要性。

## 5 未来方向

尽管 LLM 在逐步解决各种任务中展示了显著能力，但仍有若干挑战待解决。

#### 对中间结果的因果分析

现有工作通常侧重于提高任务特定的生成结果。然而，理解和解释 LLM 推理的潜在机制在实际场景中也至关重要。例如，Wang 等人 ([2023d](https://arxiv.org/html/2404.15676v1#bib.bib56)) 显示 LLM 在生成最终结果时可能会跳过理性步骤。Wang 等人 ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib53)) 观察到，即使有无效的推理链，CoT 仍能带来性能提升。这些观察表明，对中间步骤如何真正影响最终结果进行因果分析具有重要价值。

#### 减少推理成本

通向生成最终节点的链条通常需要多个连续推理步骤，这在 LLM 中尤其计算密集且耗时。如果未来研究能够在保持生成质量的同时减少 CoX 链的长度，那将非常有趣。例如，值得研究 CoX 的中间节点是否可以在单个推理步骤中并行或联合执行。

#### 知识蒸馏

CoX 的中间节点揭示了细粒度的任务说明，这有益于使用教师 LLM 进行知识蒸馏时较小学生模型的训练。Li et al.（[2023b](https://arxiv.org/html/2404.15676v1#bib.bib35)）和 Hsieh et al.（[2023](https://arxiv.org/html/2404.15676v1#bib.bib19)）已经表明，当使用 LLM 为知识蒸馏生成 CoT 的理由时，学生模型可以有效地学习。尽管如此，在启发学生学习方面，仍然存在一个开放问题，即更广泛的 CoX 方法的中间节点是否同样具有信息量。

#### 端对端微调

CoX 的一个缺点是它不遵循端到端的范式；也就是说，当不强制进行自我校正 Le et al.（[2024](https://arxiv.org/html/2404.15676v1#bib.bib30)）；Dhuliawala et al.（[2023](https://arxiv.org/html/2404.15676v1#bib.bib11)）时，生成错误可能会在链条上累积。未来的研究可以探索使用 CoX 提示和惩罚最终输出的错误来微调 LLMs。通过端到端地减少生成错误，我们期望这将改进 CoX 中的中间和最终节点的质量。

## 6 结论

该调查探索了 Chain-of-X 方法，建立在 Chain-of-Thought 概念的基础上。通过基于节点和任务对它们进行分类，我们提供了一个全面的概览，强调了 CoX 在增强 LLM 能力方面的潜力，并为未来的研究开辟了新的途径。通过这项调查，我们旨在激发更深入理解和更创造性地运用 CoX 范式来增强 LLMs 的进一步探索。

## 参考资料

+   Adams et al. (2023) Griffin Adams, Alex Fabbri, Faisal Ladhak, Eric Lehman 和 Noémie Elhadad. 2023. [从稀疏到密集：用密度提示的 GPT-4 摘要](https://doi.org/10.18653/v1/2023.newsum-1.7). 在 *Proceedings of the 4th New Frontiers in Summarization Workshop*, 页码 68–74, 新加坡。Association for Computational Linguistics.

+   Agrawal et al. (2023) Garima Agrawal, Tharindu Kumarage, Zeyad Alghami 和 Huan Liu. 2023. [知识图能减少 LLMs 的幻觉吗？：一项调查](https://arxiv.org/abs/2311.07914). *arXiv preprint arXiv:2311.07914*。

+   Ahn and Shin (2024) Jinwoo Ahn 和 Kyuseung Shin. 2024. [递归反馈链防止冗余提示导致绩效下降](https://arxiv.org/abs/2402.02648v2). *arXiv preprint arXiv:2402.02648v2*.

+   Akhtar et al. (2023) Mubashara Akhtar, Michael Schlichtkrull, Zhijiang Guo, Oana Cocarascu, Elena Simperl 和 Andreas Vlachos. 2023. [多模态自动事实检查：一项调查](https://doi.org/10.18653/v1/2023.findings-emnlp.361). 在 *Findings of the Association for Computational Linguistics: EMNLP 2023*, 页码 5430–5448, 新加坡。Association for Computational Linguistics.

+   Bao 等人 (2024) Songlin Bao, Tiantian Li, 和 Bin Cao. 2024. [链式事件提示用于多文档摘要的大型语言模型](https://www.emerald.com/insight/content/doi/10.1108/IJWIS-12-2023-0249/full/html)。*国际网络信息系统期刊*。

+   Besta 等人 (2024a) Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk 等人. 2024a. [思维图：利用大型语言模型解决复杂问题](https://ojs.aaai.org/index.php/AAAI/article/view/29720)。发表于 *AAAI 人工智能会议论文集*，第 38 卷，第 17682–17690 页。

+   Besta 等人 (2024b) Maciej Besta, Florim Memedi, Zhenyu Zhang, Robert Gerstenberger, Nils Blach, Piotr Nyczyk, Marcin Copik, Grzegorz Kwaśniewski, Jürgen Müller, Lukas Gianinazzi 等人. 2024b. [推理的拓扑：揭示思维链、树和图的奥秘](https://arxiv.org/abs/2401.14295)。*arXiv 预印本 arXiv:2401.14295*。

+   Bhardwaj 和 Poria (2023) Rishabh Bhardwaj 和 Soujanya Poria. 2023. [使用话语链进行安全对齐的大型语言模型红队测试](https://arxiv.org/abs/2308.09662)。*arXiv 预印本 arXiv:2308.09662*。

+   Chang 等人 (2023) Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang 等人. 2023. [大型语言模型评估综述](https://dl.acm.org/doi/10.1145/3641289)。*ACM 智能系统与技术学报*。

+   Chu 等人 (2023) Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Tao He, Haotian Wang, Weihua Peng, Ming Liu, Bing Qin, 和 Ting Liu. 2023. [链式思维推理综述：进展、前沿和未来](https://arxiv.org/abs/2309.15402)。*arXiv 预印本 arXiv:2309.15402*。

+   Dhuliawala 等人 (2023) Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, 和 Jason Weston. 2023. [链式验证减少大型语言模型中的幻觉](https://arxiv.org/abs/2309.11495)。*arXiv 预印本 arXiv:2309.11495*。

+   Do 等人 (2023) Xuan Long Do, Kenji Kawaguchi, Min Yen Kan, 和 Nancy F Chen. 2023. [Choire：利用意见链推理表征和预测人类意见](https://arxiv.org/abs/2311.08385)。*arXiv 预印本 arXiv:2311.08385*。

+   Dong 等人 (2024) Zhichen Dong, Zhanhui Zhou, Chao Yang, Jing Shao, 和 Yu Qiao. 2024. [LLM 对话安全的攻击、防御与评估：综述](https://arxiv.org/abs/2402.09283)。*arXiv 预印本 arXiv:2402.09283*。

+   Gao 等人 (2024) Silin Gao, Jane Dwivedi-Yu, Ping Yu, Xiaoqing Ellen Tan, Ramakanth Pasunuru, Olga Golovneva, Koustuv Sinha, Asli Celikyilmaz, Antoine Bosselut, 和 Tianlu Wang. 2024. [链式抽象推理的高效工具使用](https://arxiv.org/abs/2401.17464)。*arXiv 预印本 arXiv:2401.17464*。

+   Gao 等 (2023) Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, 和 Haofen Wang. 2023. [Retrieval-augmented generation for large language models: A survey](https://arxiv.org/abs/2312.10997)。*arXiv 预印本 arXiv:2312.10997*。

+   Gong 和 Mao (2023) Peiyuan Gong 和 Jiaxin Mao. 2023. [Coascore: Chain-of-aspects prompting for nlg evaluation](https://arxiv.org/abs/2312.10355)。*arXiv 预印本 arXiv:2312.10355*。

+   Han 等 (2024) Guangzeng Han, Weisi Liu, Xiaolei Huang, 和 Brian Borsari. 2024. [Chain-of-interaction: Enhancing large language models for psychiatric behavior understanding by dyadic contexts](https://arxiv.org/abs/2403.13786)。*arXiv 预印本 arXiv:2403.13786*。

+   Hayati 等 (2024) Shirley Anugrah Hayati, Taehee Jung, Tristan Bodding-Long, Sudipta Kar, Abhinav Sethy, Joo-Kyung Kim, 和 Dongyeop Kang. 2024. [Chain-of-instructions: Compositional instruction tuning on large language models](https://arxiv.org/abs/2402.11532)。*arXiv 预印本 arXiv:2402.11532*。

+   Hsieh 等 (2023) Cheng-Yu Hsieh, Chun-Liang Li, Chih-kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alex Ratner, Ranjay Krishna, Chen-Yu Lee, 和 Tomas Pfister. 2023. [Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes](https://doi.org/10.18653/v1/2023.findings-acl.507)。见于 *计算语言学协会年会：ACL 2023 发现*，页码 8003–8017，加拿大多伦多。计算语言学协会。

+   Hu 等 (2023a) Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, 和 Hang Zhao. 2023a. [Chatdb: Augmenting llms with databases as their symbolic memory](https://arxiv.org/abs/2306.03901)。*arXiv 预印本 arXiv:2306.03901*。

+   Hu 等 (2022) Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, 和 Weizhu Chen. 2022. [LoRA: Low-rank adaptation of large language models](https://openreview.net/forum?id=nZeVKeeFYf9)。见于 *国际学习表示会议*。

+   Hu 等 (2023b) Hanxu Hu, Hongyuan Lu, Huajian Zhang, Wai Lam, 和 Yue Zhang. 2023b. [Chain-of-symbol prompting elicits planning in large language models](https://arxiv.org/abs/2305.10276)。*arXiv 预印本 arXiv:2305.10276*。

+   Huang 等 (2023) Fan Huang, Haewoon Kwak, 和 Jisun An. 2023. [Chain of explanation: New prompting method to generate quality natural language explanation for implicit hate speech](https://dl.acm.org/doi/10.1145/3543873.3587320)。见于 *ACM Web Conference 2023 附录会议录*，页码 90–93。

+   Huang 和 Chang (2023) Jie Huang 和 Kevin Chen-Chuan Chang. 2023. [Towards reasoning in large language models: A survey](https://doi.org/10.18653/v1/2023.findings-acl.67)。见于 *计算语言学协会年会：ACL 2023 发现*，页码 1049–1065，加拿大多伦多。计算语言学协会。

+   Huang et al. (2024) Qiang Huang, Feng Huang, DeHao Tao, YueTong Zhao, BingKun Wang, 和 YongFeng Huang. 2024. [Coq: 一个由大语言模型赋能的多跳问答的实证框架](https://ieeexplore.ieee.org/abstract/document/10447488)。在 *ICASSP 2024-2024 IEEE 国际声学、语音和信号处理会议 (ICASSP)*，第 11566–11570 页。IEEE。

+   Kim et al. (2024) Taehee Kim, Yeongjae Cho, Heejun Shin, Yohan Jo, 和 Dongmyung Shin. 2024. [将合成问题到人类编写问题的视觉问答进行泛化，通过大语言模型的问答链](https://arxiv.org/abs/2401.06400)。*arXiv 预印本 arXiv:2401.06400*。

+   Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, 和 Yusuke Iwasawa. 2022. [大型语言模型是零样本推理器](https://proceedings.neurips.cc/paper_files/paper/2022/hash/8bb0d291acd4acf06ef112099c16f326-Abstract-Conference.html)。*神经信息处理系统进展*，35:22199–22213。

+   Kuppa et al. (2023) Aditya Kuppa, Nikon Rasumov-Rahe, 和 Marc Voses. 2023. [参考提示链帮助大语言模型像律师一样思考](https://genlaw.org/CameraReady/37.pdf)。在 *生成性人工智能与法律研讨会*。

+   La Malfa et al. (2024) Emanuele La Malfa, Christoph Weinhuber, Orazio Torre, Fangru Lin, Anthony Cohn, Nigel Shadbolt, 和 Michael Wooldridge. 2024. [大语言模型的代码模拟挑战](https://arxiv.org/abs/2401.09074)。*arXiv 预印本 arXiv:2401.09074*。

+   Le et al. (2024) Hung Le, Hailin Chen, Amrita Saha, Akash Gokul, Doyen Sahoo, 和 Shafiq Joty. 2024. [Codechain: 通过具有代表性的子模块的自我修订链实现模块化代码生成](https://openreview.net/forum?id=vYhglxSj8j)。在 *第十二届国际学习表征会议*。

+   Lee et al. (2023a) Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu, Thomas Mesnard, Colton Bishop, Victor Carbune, 和 Abhinav Rastogi. 2023a. [Rlaif: 利用人工智能反馈扩展从人类反馈中获得的强化学习](https://arxiv.org/abs/2309.00267)。*arXiv 预印本 arXiv:2309.00267*。

+   Lee et al. (2023b) Yoon Kyung Lee, Inju Lee, Minjung Shin, Seoyeon Bae, 和 Sowon Hahn. 2023b. [同理心链：基于心理治疗模型增强大语言模型的同理回应](https://arxiv.org/abs/2311.04915)。*arXiv 预印本 arXiv:2311.04915*。

+   Lei et al. (2023) Deren Lei, Yaxi Li, Mingyu Wang, Vincent Yun, Emily Ching, Eslam Kamal, 等. 2023. [自然语言推理链用于减少大语言模型的无依据幻觉](https://arxiv.org/abs/2310.03951)。*arXiv 预印本 arXiv:2310.03951*。

+   Li et al. (2023a) Chengshu Li, Jacky Liang, Andy Zeng, Xinyun Chen, Karol Hausman, Dorsa Sadigh, Sergey Levine, Li Fei-Fei, Fei Xia, 和 Brian Ichter. 2023a. [代码链：与语言模型增强的代码模拟器进行推理](https://arxiv.org/abs/2312.04474)。*arXiv 预印本 arXiv:2312.04474*。

+   Li 等（2023b）刘年·哈罗德·李、杰克·赫塞尔、杨杰·于、向仁、凯伟·张和叶真·崔。2023b. [符号化链式思考蒸馏：小模型也能“逐步思考”](https://doi.org/10.18653/v1/2023.acl-long.150)。在 *第 61 届计算语言学协会年会论文集（第 1 卷：长篇论文）*，页码 2665–2679，加拿大多伦多。计算语言学协会。

+   Li 等（2024a）兴轩·李、若辰·赵、叶肯·贾、博生·丁、沙菲克·乔蒂、苏佳娜·波里亚和李栋·宾。2024a. [Chain-of-knowledge: 通过在异构来源上动态适应知识来基础大型语言模型](https://openreview.net/forum?id=cPgh4gWZlz)。在 *第十二届学习表示国际会议*。

+   Li 等（2024b）杨宁·李、石荣·马、肖彬·王、沈煌、程悦·姜、海涛·郑、彭俊·谢、费煌和永江。2024b. [Ecomgpt: 使用任务链对电商的大型语言模型进行指令微调](https://ojs.aaai.org/index.php/AAAI/article/view/29820)。在 *AAAI 人工智能会议论文集*，第 38 卷，页码 18582–18590。

+   Liu 等（2024a）浩·刘、卡梅洛·斯费拉扎和皮特·阿贝尔。2024a. [后见之明链将语言模型与反馈对齐](https://openreview.net/forum?id=6xfe4IVcOu)。在 *第十二届学习表示国际会议*。

+   Liu 等（2024b）祖彦·刘、宇豪·董、永铭·饶、杰·周和吉文·陆。2024b. [链式定位：互动推理改善大型视觉语言模型](https://arxiv.org/abs/2403.12966)。*arXiv 预印本 arXiv:2403.12966*。

+   Lu 等（2023）洪源·陆、浩阳·黄、东东·张、浩然·杨、伟·林和富如·魏。2023. [字典链提示引发大型语言模型中的翻译](https://arxiv.org/abs/2305.06575)。*arXiv 预印本 arXiv:2305.06575*。

+   Luo 等（2024）瑞麟·罗、天乐·顾、浩灵·李、俊哲·李、紫诚·林、佳怡·李和玉久·杨。2024. [历史链：通过大型语言模型进行时间知识图谱的学习和预测](https://arxiv.org/abs/2401.06072)。*arXiv 预印本 arXiv:2401.06072*。

+   Lyu 等（2023）青·吕、什瑞亚·哈瓦尔达尔、亚当·斯坦、李·张、德里普·拉奥、埃里克·黄、玛丽安娜·阿皮迪安基和克里斯·卡利森-伯奇。2023. [忠实的链式思考推理](https://aclanthology.org/2023.ijcnlp-main.20)。在 *第 13 届国际联合自然语言处理大会暨计算语言学协会亚太分会第三届会议（第 1 卷：长篇论文）*，页码 305–329，努沙杜瓦，巴厘岛。计算语言学协会。

+   Ma 等（2023）韦宇·马、启瑞·米、薛颜、余俏·吴、润基·林、海峰·张和俊·王。2023. [大型语言模型玩星际争霸 II：基准测试和总结链方法](https://arxiv.org/abs/2312.11865)。*arXiv 预印本 arXiv:2312.11865*。

+   Meng 等（2023）孟凡旭，杨浩通，王宜丁，和张木寒。2023 年。[图像链：直观推理](https://arxiv.org/abs/2311.09241)。*arXiv 预印本 arXiv:2311.09241*。

+   Ouyang 等（2022）龙·欧阳，杰弗里·吴，徐江，迪奥戈·阿尔梅达，卡罗尔·温赖特，帕梅拉·米什金，崇张，桑迪尼·阿加瓦尔，卡塔里娜·斯拉马，亚历克斯·雷等。2022 年。[训练语言模型以遵循带有人类反馈的指令](https://proceedings.neurips.cc/paper_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html)。*神经信息处理系统进展*，35:27730–27744。

+   Pan 等（2024）潘振宇，罗浩铮，李曼玲，和刘汉。2024 年。[行动链：通过大型语言模型进行忠实且多模态的问题回答](https://arxiv.org/abs/2403.17359)。*arXiv 预印本 arXiv:2403.17359*。

+   Qi 等（2024）季齐，明丁，魏汉·王，余诗·白，青松·吕，文义·洪，彬·徐，雷·侯，娟子·李，俞孝·董等。2024 年。[Cogcom：通过操作链深入细节训练大型视觉-语言模型](https://arxiv.org/abs/2402.04236)。*arXiv 预印本 arXiv:2402.04236*。

+   Qiu 等（2024）邱喜和，郝特琪，石少杰，谭小宇，和熊宇杰。2024 年。[链下调整：在多样指令集上提升低秩适配的指令微调性能](https://ieeexplore.ieee.org/abstract/document/10472574)。*IEEE 信号处理信函*。

+   Rae 等（2021）杰克·W·雷，塞巴斯蒂安·博尔戈德，特雷弗·蔡，凯蒂·米尔利肯，乔丹·霍夫曼，弗朗西斯·宋，约翰·阿斯拉尼德斯，莎拉·亨德森，罗曼·林，苏珊娜·杨等。2021 年。[扩展语言模型：方法、分析与训练“戈弗”所得的见解](https://arxiv.org/abs/2112.11446)。*arXiv 预印本 arXiv:2112.11446*。

+   Servantez 等（2024）塞尔吉奥·塞万特斯，乔·巴罗，克里斯蒂安·汉蒙德，和拉吉夫·贾因。2024 年。[逻辑链：基于规则的大型语言模型推理](https://arxiv.org/abs/2402.10400)。*arXiv 预印本 arXiv:2402.10400*。

+   Tao 等（2024）陶明旭，赵东岩，和冯艳松。2024 年。[讨论链：一种用于复杂证据基础问题回答的多模型框架](https://arxiv.org/abs/2402.16313)。*arXiv 预印本 arXiv:2402.16313*。

+   Uehara 等（2024）上原浩平，纳巴伦·戈斯瓦米，韩勤·王，敏明·巴巴，小田岛·田中，桥本智宏，凯·王，磯·礼，高木尚也，梅上·亮等。2024 年。[通过明确的推理链和视觉问题生成推动大型多模态模型的发展](https://arxiv.org/abs/2401.10005)。*arXiv 预印本 arXiv:2401.10005*。

+   Wang 等人（2023a）Boshi Wang, Sewon Min, Xiang Deng, Jiaming Shen, You Wu, Luke Zettlemoyer, 和 Huan Sun。2023a 年。 [理解链式思维提示：对重要因素的实证研究](https://doi.org/10.18653/v1/2023.acl-long.153)。在*第 61 届计算语言学协会年会（第 1 卷：长篇论文）*，第 2717–2739 页，加拿大多伦多。计算语言学协会。

+   Wang 等人（2023b）Hanbin Wang, Zhenghao Liu, Shuo Wang, Ganqu Cui, Ning Ding, Zhiyuan Liu, 和 Ge Yu。2023b 年。 [Intervenor：通过互动修复链提示大型语言模型的编码能力](https://arxiv.org/abs/2311.09868)。*arXiv 预印本 arXiv:2311.09868*。

+   Wang 等人（2023c）Jianing Wang, Qiushi Sun, Nuo Chen, Xiang Li, 和 Ming Gao。2023c 年。 [通过知识链提示提升语言模型推理](https://arxiv.org/abs/2306.06427)。*arXiv 预印本 arXiv:2306.06427*。

+   Wang 等人（2023d）Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, 和 Denny Zhou。2023d 年。 [自洽性提升语言模型中的链式思维推理](https://openreview.net/forum?id=1PL1NIMMrw)。在*第十一届国际学习表征会议*。

+   Wang 等人（2023e）Yufei Wang, Wanjun Zhong, Liangyou Li, Fei Mi, Xingshan Zeng, Wenyong Huang, Lifeng Shang, Xin Jiang, 和 Qun Liu。2023e 年。 [将大型语言模型与人类对齐：一项调查](https://arxiv.org/abs/2307.12966)。*arXiv 预印本 arXiv:2307.12966*。

+   Wang 等人（2024）Zilong Wang, Hao Zhang, Chun-Liang Li, Julian Martin Eisenschlos, Vincent Perot, Zifeng Wang, Lesly Miculicich, Yasuhisa Fujii, Jingbo Shang, Chen-Yu Lee, 和 Tomas Pfister。2024 年。 [链式表格：在推理链中演变表格以实现表格理解](https://openreview.net/forum?id=4L0xnS4GQM)。在*第十二届国际学习表征会议*。

+   Wei 等人（2022）Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, 和 Denny Zhou。2022 年。 [链式思维提示在大型语言模型中引发推理](https://openreview.net/forum?id=_VjQlMeSB_J)。在*神经信息处理系统进展*。

+   Xi 等人（2023a）Nan Xi, Jingjing Meng, 和 Junsong Yuan。2023a 年。 [链式查看提示用于内窥镜视频中的动词中心手术三元组识别](https://dl.acm.org/doi/abs/10.1145/3581783.3611898)。在*第 31 届 ACM 国际多媒体会议论文集*，第 5007–5016 页。

+   Xi 等人（2023b）Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou，等。2023b 年。 [大型语言模型代理的崛起与潜力：一项调查](https://arxiv.org/abs/2309.07864)。*arXiv 预印本 arXiv:2309.07864*。

+   Xia 等（2024a）Wenhan Xia, Chengwei Qin 和 Elad Hazan. 2024a. [Lora 链：通过残差学习高效微调语言模型](https://arxiv.org/abs/2401.04151)。*arXiv 预印本 arXiv:2401.04151*。

+   Xia 等（2024b）Yu Xia, Fang Kong, Tong Yu, Liya Guo, Ryan A Rossi, Sungchul Kim 和 Shuai Li. 2024b. [哪个 llm 进行游戏？具有时间递增带子的收敛感知在线模型选择](https://arxiv.org/abs/2403.07213)。*arXiv 预印本 arXiv:2403.07213*。

+   Xia 等（2024c）Yu Xia, Xu Liu, Tong Yu, Sungchul Kim, Ryan A Rossi, Anup Rao, Tung Mai 和 Shuai Li. 2024c. [幻觉多样性感知主动学习用于文本摘要](https://arxiv.org/abs/2404.01588)。*arXiv 预印本 arXiv:2404.01588*。

+   Xia 等（2024d）Yuwei Xia, Ding Wang, Qiang Liu, Liang Wang, Shu Wu 和 Xiaoyu Zhang. 2024d. [通过历史链推理提升大型知识图谱的预测能力](https://arxiv.org/abs/2402.14382)。*arXiv 预印本 arXiv:2402.14382*。

+   Xiao 等（2024a）Zeqi Xiao, Tai Wang, Jingbo Wang, Jinkun Cao, Wenwei Zhang, Bo Dai, Dahua Lin 和 Jiangmiao Pang. 2024a. [通过提示的联系链实现统一的人类-场景交互](https://openreview.net/forum?id=1vCnDyQkjg)。在*第十二届国际学习表征会议*。

+   Xiao 等（2024b）Ziyang Xiao, Dongxiang Zhang, Yangjun Wu, Lilin Xu, Yuan Jessica Wang, Xiongwei Han, Xiaojin Fu, Tao Zhong, Jia Zeng, Mingli Song 和 Gang Chen. 2024b. [专家链：当 LLMs 遇到复杂运筹学问题](https://openreview.net/forum?id=HobyL1B9CZ)。在*第十二届国际学习表征会议*。

+   Xu 等（2023）Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng 和 Tat-seng Chua. 2023. [链中搜索：朝着准确、可靠和可追溯的内容生成迈进，以应对复杂的知识密集型任务](https://arxiv.org/abs/2304.14732)。*arXiv 预印本 arXiv:2304.14732*。

+   Yamada 等（2024）Yutaro Yamada, Khyathi Chandu, Yuchen Lin, Jack Hessel, Ilker Yildirim 和 Yejin Choi. 2024. [L3go：具有链式 3d 思维的语言代理，用于生成非常规对象](https://arxiv.org/abs/2402.09052)。*arXiv 预印本 arXiv:2402.09052*。

+   Yao 等（2024）Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao 和 Karthik Narasimhan. 2024. [思维树：利用大型语言模型进行深思熟虑的问题解决](https://proceedings.neurips.cc/paper_files/paper/2023/hash/271db9922b8d1f4dd7aaef84ed5ac703-Abstract-Conference.html)。*神经信息处理系统进展*, 36。

+   Yu 等（2023a）Wenhao Yu, Hongming Zhang, Xiaoman Pan, Kaixin Ma, Hongwei Wang 和 Dong Yu. 2023a. [笔记链：增强检索增强型语言模型的鲁棒性](https://arxiv.org/abs/2311.09210)。*arXiv 预印本 arXiv:2311.09210*。

+   Yu et al. (2023b) Zihan Yu, Liang He, Zhen Wu, Xinyu Dai, 和 Jiajun Chen. 2023b. [朝着更好的思维链提示策略迈进：综述](https://arxiv.org/abs/2310.04959). *arXiv 预印本 arXiv:2310.04959*。

+   Zan et al. (2023) Daoguang Zan, Bei Chen, Fengji Zhang, Dianjie Lu, Bingchao Wu, Bei Guan, Wang Yongji, 和 Jian-Guang Lou. 2023. [大型语言模型遇见 NL2Code：综述](https://doi.org/10.18653/v1/2023.acl-long.411). 见 *第 61 届计算语言学协会年会论文集（第 1 卷：长篇论文）*，第 7443–7464 页，多伦多，加拿大。计算语言学协会。

+   Zeng et al. (2024) Qingkai Zeng, Yuyang Bai, Zhaoxuan Tan, Shangbin Feng, Zhenwen Liang, Zhihan Zhang, 和 Meng Jiang. 2024. [Chain-of-layer：通过有限示例迭代提示大型语言模型进行分类](https://arxiv.org/abs/2402.07386). *arXiv 预印本 arXiv:2402.07386*。

+   Zha et al. (2023) Liangyu Zha, Junlin Zhou, Liyao Li, Rui Wang, Qingyi Huang, Saisai Yang, Jing Yuan, Changbao Su, Xiang Li, Aofeng Su, 等人. 2023. [Tablegpt：将表格、自然语言和命令统一为一个 gpt](https://arxiv.org/abs/2307.08674). *arXiv 预印本 arXiv:2307.08674*。

+   Zhan and Zhang (2023) Zhuosheng Zhan 和 Aston Zhang. 2023. [你只看屏幕：多模态行动链代理](https://arxiv.org/abs/2309.11436). *arXiv 预印本 arXiv:2309.11436*。

+   Zhang et al. (2023a) Dong Zhang, Shimin Li, Xin Zhang, Jun Zhan, Pengyu Wang, Yaqian Zhou, 和 Xipeng Qiu. 2023a. [SpeechGPT：赋能大型语言模型内在的跨模态对话能力](https://doi.org/10.18653/v1/2023.findings-emnlp.1055). 见 *计算语言学协会发现：EMNLP 2023*，第 15757–15773 页，新加坡。计算语言学协会。

+   Zhang et al. (2024a) Dong Zhang, Xin Zhang, Jun Zhan, Shimin Li, Yaqian Zhou, 和 Xipeng Qiu. 2024a. [Speechgpt-gen：扩展信息链生成](https://arxiv.org/abs/2401.13527). *arXiv 预印本 arXiv:2401.13527*。

+   Zhang et al. (2024b) Jingyi Zhang, Jiaxing Huang, Sheng Jin, 和 Shijian Lu. 2024b. [视觉语言模型在视觉任务中的应用：综述](https://ieeexplore.ieee.org/abstract/document/10445007). *IEEE 模式分析与机器智能汇刊*。

+   Zhang et al. (2024c) Jiwen Zhang, Jihao Wu, Yihua Teng, Minghui Liao, Nuo Xu, Xiao Xiao, Zhongyu Wei, 和 Duyu Tang. 2024c. [Android 在动物园：GUI 代理的行动思维链](https://arxiv.org/abs/2403.02713). *arXiv 预印本 arXiv:2403.02713*。

+   Zhang et al. (2023b) Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, 等人. 2023b. [大型语言模型的指令调优：综述](https://arxiv.org/abs/2308.10792). *arXiv 预印本 arXiv:2308.10792*。

+   Zhang 等（2023c）Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen 等. 2023c. [AI 海洋中的海妖之歌：大型语言模型中幻觉的综述](https://arxiv.org/abs/2309.01219)。*arXiv 预印本 arXiv:2309.01219*。

+   Zhang 等（2023d）Zhenduo Zhang, Bowen Zhang, 和 Guang Liu. 2023d. [Coie：用于多属性面部操控的链式指令编辑](https://arxiv.org/abs/2312.07879)。*arXiv 预印本 arXiv:2312.07879*。

+   Zhao 等（2023）Ruochen Zhao, Hailin Chen, Weishi Wang, Fangkai Jiao, Xuan Long Do, Chengwei Qin, Bosheng Ding, Xiaobao Guo, Minzhi Li, Xingxuan Li, 和 Shafiq Joty. 2023. [检索多模态信息以增强生成：综述](https://doi.org/10.18653/v1/2023.findings-emnlp.314)。在*计算语言学协会年会论文集：EMNLP 2023*，第 4736–4756 页，新加坡。计算语言学协会。

+   Zhou 等（2023）Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le, 和 Ed H. Chi. 2023. [从少到多的提示促进大型语言模型中的复杂推理](https://openreview.net/forum?id=WZH7099tgfM)。在*第十一届国际学习表征会议*上。

+   Zhou 等（2024）Enshen Zhou, Yiran Qin, Zhenfei Yin, Yuzhou Huang, Ruimao Zhang, Lu Sheng, Yu Qiao, 和 Jing Shao. 2024. [Minedreamer：通过链式想象学习跟随指令以控制模拟世界](https://arxiv.org/abs/2403.12037)。*arXiv 预印本 arXiv:2403.12037*。

## 附录 A 节点和任务的分类

我们在图 [3](https://arxiv.org/html/2404.15676v1#A1.F3 "图 3 ‣ 附录 A 节点和任务的分类 ‣ 超越链式思维：大型语言模型的链式 X 范式综述") 中展示了图 [2](https://arxiv.org/html/2404.15676v1#S2.F2 "图 2 ‣ 链式 X ‣ 2 什么是链式 X？ ‣ 超越链式思维：大型语言模型的链式 X 范式综述") 的完整版本，按节点和任务分类的 Chain-of-X 分类法。

{forest}

for tree= font=, draw=myblue, semithick, rounded corners, minimum height = 1.5ex, minimum width = 2em, anchor = west, grow = east, forked edge, s sep = 0.8mm, l sep = 3.5mm, fork sep = 2mm, [Chain-of-X 综述，rotate=90, anchor=center [任务分类 (§[4](https://arxiv.org/html/2404.15676v1#S4 "4 链式 X 任务 ‣ 超越链式思维：大型语言模型的链式 X 范式综述"))，fit=band, text width=1cm [评估工具

(§[4.6](https://arxiv.org/html/2404.15676v1#S4.SS6 "4.6 评估工具 ‣ 4 Chain-of-X 任务 ‣ 超越思维链：LLMs 的 Chain-of-X 范式调查")), 文本宽度=2.1cm，l sep = 2mm [CoUtterances Bhardwaj 和 Poria ([2023](https://arxiv.org/html/2404.15676v1#bib.bib8))，CoImages Meng 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib44))，CoExplanation Huang 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib23))，CoAspects Gong 和 Mao ([2023](https://arxiv.org/html/2404.15676v1#bib.bib16))，CoFeedback Ahn 和 Shin ([2024](https://arxiv.org/html/2404.15676v1#bib.bib3))，文本宽度=10.9cm，填充=lightblue] ] [LLMs 作为代理

(§[4.5](https://arxiv.org/html/2404.15676v1#S4.SS5 "4.5 LLMs as Agents ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，文本宽度=2.1cm，左侧间距=2mm [CoAction^a Zhan 和 Zhang ([2023](https://arxiv.org/html/2404.15676v1#bib.bib76))，CoSymbol Hu 等 ([2023b](https://arxiv.org/html/2404.15676v1#bib.bib22))，CoSummarization Ma 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib43))，Co3DThought Yamada 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib69))，CoActionThought Zhang 等 ([2024c](https://arxiv.org/html/2404.15676v1#bib.bib80))，CoExperts Xiao 等 ([2024b](https://arxiv.org/html/2404.15676v1#bib.bib67))，CoDiscussion Tao 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib51))，CoAbstraction Gao 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib14))，CoContacts Xiao 等 ([2024a](https://arxiv.org/html/2404.15676v1#bib.bib66))，文本宽度=10.9cm，填充=浅蓝色] ] [Instruction Following (§[4.4](https://arxiv.org/html/2404.15676v1#S4.SS4 "4.4 Instruction Following ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，文本宽度=2.1cm，左侧间距=2mm [CoTask Li 等 ([2024b](https://arxiv.org/html/2404.15676v1#bib.bib37))，CoImagination Zhou 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib86))，CoInstructions Hayati 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib18))，CoModality Zhang 等 ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib77))，CoLoRA^b Qiu 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib48))，文本宽度=10.9cm，填充=浅蓝色] ] [Multi-Step Reasoning (§[4.3](https://arxiv.org/html/2404.15676v1#S4.SS3 "4.3 Multi-Step Reasoning ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，文本宽度=2.1cm，左侧间距=2mm [CoT Wei 等 ([2022](https://arxiv.org/html/2404.15676v1#bib.bib59))，CoDensity Adams 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib1))，CoKnowledge^b Wang 等 ([2023c](https://arxiv.org/html/2404.15676v1#bib.bib55))，CoMemory Hu 等 ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib20))，CoOpinion Do 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib12))，CoReference Kuppa 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib28))，CoQuery Xu 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib68))，CoInteraction Han 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib17))，CoLogic Servantez 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib50))，CoFeedback Ahn 和 Shin ([2024](https://arxiv.org/html/2404.15676v1#bib.bib3))，CoLayer Zeng 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib74))，CoEvent Bao 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib5))，文本宽度=10.9cm，填充=浅蓝色] ] [Factuality & Safety (§[4.2](https://arxiv.org/html/2404.15676v1#S4.SS2 "4.2 Factuality & Safety ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，文本宽度=2.1cm [Alignment，文本宽度=1.3cm，左侧间距=2mm [CoUtterances Bhardwaj 和 Poria ([2023](https://arxiv.org/html/2404.15676v1#bib.bib8))，CoHindsight Liu 等 ([2024a](https://arxiv.org/html/2404.15676v1#bib.bib38))，文本宽度=9.0cm，填充=浅蓝色] ] [Hallucination Reduction，文本宽度=1.3cm，左侧间距=2mm [CoNLI Lei 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib33))，CoVerification Dhuliawala 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib11))，CoKnowledge^a Li 等 ([2024a](https://arxiv.org/html/2404.15676v1#bib.bib36))，CoNote Yu 等 ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib71))，CoQuestion Huang 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib25))，CoAction^b Pan 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib46))，文本宽度=9.0cm，填充=浅蓝色] ] ] [Multi-Modal Interaction (§[4.1](https://arxiv.org/html/2404.15676v1#S4.SS1 "4.1 Multi-Modal Interaction ‣ 4 Chain-of-X Tasks ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，文本宽度=2.1cm [Text-Speech，文本宽度=1.3cm，左侧间距=2mm [CoInformation Zhang 等 ([2024a](https://arxiv.org/html/2404.15676v1#bib.bib78))，CoModality Zhang 等 ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib77))，文本宽度=9.0cm，填充=浅蓝色] ] [Text-Code，文本宽度=1.3cm，左侧间距=2mm [CoRepair Wang 等 ([2023b](https://arxiv.org/html/2404.15676v1#bib.bib54))，CoCode Li 等 ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib34))，CoSimulation La Malfa 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib29))，CoSelfRevisions Le 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib30))，文本宽度=9.0cm，填充=浅蓝色] ] [Text-Table，文本宽度=1.3cm，左侧间距=2mm [CoCommand Zha 等 ([2023](https://arxiv.org/html/2404.15676v1#bib.bib75))，CoTable Wang 等 ([2024](https://arxiv.org/html/2404.15676v1#bib.bib58))，文本宽度=9.0cm，填充=浅蓝色] ] [Text-Image，文本宽度=1.3cm，左侧间距=2mm [CoInstructEditing Zhang 等 ([2023d](https://arxiv.org/html/2404.15676v1#bib.bib83))，CoLook Xi 等 ([2023a](https://arxiv.org/html/2404.15676v1#bib.bib60))，CoQA Kim 等 ([2024](https://arxiv.org/html/2404.15676v1#bib

(§[3.4](https://arxiv.org/html/2404.15676v1#S3.SS4 "3.4 Chain-of-Models ‣ 3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，文本宽度=2.1cm，左右间距=2mm [CoExperts Xiao et al. ([2024b](https://arxiv.org/html/2404.15676v1#bib.bib67))，CoDiscussion Tao et al. ([2024](https://arxiv.org/html/2404.15676v1#bib.bib51))，CoLoRA^a Xia et al. ([2024a](https://arxiv.org/html/2404.15676v1#bib.bib62))，CoLoRA^b Qiu et al. ([2024](https://arxiv.org/html/2404.15676v1#bib.bib48))，文本宽度=10.9cm，填充=浅蓝色] ] [Chain-of-Feedback (§[3.3](https://arxiv.org/html/2404.15676v1#S3.SS3 "3.3 Chain-of-Feedback ‣ 3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs"))，文本宽度=2.1cm [Self-Refine，文本宽度=1.3cm，左右间距=2mm [CoNLI Lei et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib33))，CoVerification Dhuliawala et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib11))，CoDensity Adams et al. ([2023](https://arxiv.org/html/2404.15676v1#bib.bib1))，CoSelfRevisions Le et al. ([2024](https://arxiv.org/html/2404.15676v1#bib.bib30))，CoFeedback Ahn and Shin ([2024](https://arxiv.org/html/2404.15676v1#bib.bib3))，文本宽度=9.0cm，填充=浅蓝色] ] [External

反馈，文本宽度=1.3cm，左边距=2mm [Co3DThought Yamada 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib69)），CoRepair Wang 等人（[2023b](https://arxiv.org/html/2404.15676v1#bib.bib54)），CoHindsight Liu 等人（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib38)），文本宽度=9.0cm，填充=浅蓝色] ] ] [链式增强 (§[3.2](https://arxiv.org/html/2404.15676v1#S3.SS2 "3.2 Chain-of-Augmentation ‣ 3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")），文本宽度=2.1cm [其他，文本宽度=1.3cm，左边距=2mm [CoEmpathy Lee 等人（[2023b](https://arxiv.org/html/2404.15676v1#bib.bib32)），CoReference Kuppa 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib28)），CoDictionary Lu 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib40)），CoMemory Hu 等人（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib20)），CoAbstraction Gao 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib14)），文本宽度=9.0cm，填充=浅蓝色] ] [检索，文本宽度=1.3cm，左边距=2mm [CoQuery Xu 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib68)），CoNote Yu 等人（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib71)），CoKnowledge^a Li 等人（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib36)），CoQuestion Huang 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib25)），CoAction^b Pan 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib46)），文本宽度=9.0cm，填充=浅蓝色] ] [历史，文本宽度=1.3cm，左边距=2mm [CoOpinion Do 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib12)），CoAction^a Zhan 和 Zhang（[2023](https://arxiv.org/html/2404.15676v1#bib.bib76)），CoSummarization Ma 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib43)），CoLayer Zeng 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib74)），CoHistory^a Luo 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib41)），CoHistory^b Xia 等人（[2024d](https://arxiv.org/html/2404.15676v1#bib.bib65)），文本宽度=9.0cm，填充=浅蓝色] ] [指令，文本宽度=1.3cm，左边距=2mm [CoInstructEditing Zhang 等人（[2023d](https://arxiv.org/html/2404.15676v1#bib.bib83)），CoCommand Zha 等人（[2023](https://arxiv.org/html/2404.15676v1#bib.bib75)），CoModality Zhang 等人（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib77)），CoTask Li 等人（[2024b](https://arxiv.org/html/2404.15676v1#bib.bib37)），CoInstructions Hayati 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib18)），文本宽度=9.0cm，填充=浅蓝色] ] ] [链式中介 (§[3.1](https://arxiv.org/html/2404.15676v1#S3.SS1 "3.1 Chain-of-Intermediates ‣ 3 Chain-of-X Nodes ‣ Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs")），文本宽度=2.1cm [知识

组合，文本宽度=1.3cm，l sep = 2mm [CoSymbol Hu 等人（[2023b](https://arxiv.org/html/2404.15676v1#bib.bib22)），CoKnowledge^b Wang 等人（[2023c](https://arxiv.org/html/2404.15676v1#bib.bib55)），CoManipulation Qi 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib47)），CoSimulation La Malfa 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib29)），CoSpot Liu 等人（[2024b](https://arxiv.org/html/2404.15676v1#bib.bib39)），CoReasoning Uehara 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib52)），文本宽度=9.0cm，填充=浅蓝色] ] [问题

分解，文本宽度=1.3cm，l sep = 2mm [CoT Wei 等人（[2022](https://arxiv.org/html/2404.15676v1#bib.bib59)），CoCode Li 等人（[2023a](https://arxiv.org/html/2404.15676v1#bib.bib34)），CoTable Wang 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib58)），CoLogic Servantez 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib50)），CoEvent Bao 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib5)），CoInteraction Han 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib17)），CoAction^b Pan 等人（[2024](https://arxiv.org/html/2404.15676v1#bib.bib46)），CoInformation Zhang 等人（[2024a](https://arxiv.org/html/2404.15676v1#bib.bib78)），文本宽度=9.0cm，填充=浅蓝色] ] ] ] ]

图 3：按节点和任务的分类对 Chain-of-X 的调查。

生成于 2024 年 4 月 30 日 星期二 20:07:51，由 LaTeXML![吉祥物 Sammy](http://dlmf.nist.gov/LaTeXML/)
