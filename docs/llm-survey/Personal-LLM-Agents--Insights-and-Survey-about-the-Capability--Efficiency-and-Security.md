<!--yml

类别：未分类

日期：2024-09-03 17:31:11

-->

# 个人 LLM 代理：关于能力、效率和安全性的洞察与调查

> 来源：[`arxiv.org/html/2401.05459`](https://arxiv.org/html/2401.05459)

1.  [1 介绍](https://arxiv.org/html/2401.05459v2#S1 "在个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

1.  [2 智能个人助手的简要历史](https://arxiv.org/html/2401.05459v2#S2 "在个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [2.1 智能个人助手历史时间线视图](https://arxiv.org/html/2401.05459v2#S2.SS1 "在 2 智能个人助手的简要历史 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [2.2 智能个人助手的技术视图](https://arxiv.org/html/2401.05459v2#S2.SS2 "在 2 智能个人助手的简要历史 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [2.2.1 基于模板的编程](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS1 "在 2.2 智能个人助手的技术视图 ‣ 2 智能个人助手的简要历史 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [2.2.2 监督学习方法](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS2 "在 2.2 智能个人助手的技术视图 ‣ 2 智能个人助手的简要历史 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [2.2.3 强化学习方法](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS3 "在 2.2 智能个人助手的技术视图 ‣ 2 智能个人助手的简要历史 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [2.2.4 基础模型的早期应用](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS4 "在 2.2 智能个人助手的技术视图 ‣ 2 智能个人助手的简要历史 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

1.  [3 个人 LLM 代理：定义与洞察](https://arxiv.org/html/2401.05459v2#S3 "在个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [3.1 关键组件](https://arxiv.org/html/2401.05459v2#S3.SS1 "在 3 个人 LLM 代理：定义与洞察 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [3.2 个人 LLM 代理的智能水平](https://arxiv.org/html/2401.05459v2#S3.SS2 "在 3 个人 LLM 代理：定义与洞察 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [3.3 对常见问题的看法](https://arxiv.org/html/2401.05459v2#S3.SS3 "在 3 个人 LLM 代理：定义与见解 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

1.  [4 个基本能力](https://arxiv.org/html/2401.05459v2#S4 "在 个人 LLM 代理：关于能力、效率和安全的见解和调查")

    1.  [4.1 任务执行](https://arxiv.org/html/2401.05459v2#S4.SS1 "在 4 个基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

        1.  [4.1.1 任务自动化方法](https://arxiv.org/html/2401.05459v2#S4.SS1.SSS1 "在 4.1 任务执行 ‣ 4 个基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

        1.  [4.1.2 自主代理框架](https://arxiv.org/html/2401.05459v2#S4.SS1.SSS2 "在 4.1 任务执行 ‣ 4 个基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

        1.  [4.1.3 评估](https://arxiv.org/html/2401.05459v2#S4.SS1.SSS3 "在 4.1 任务执行 ‣ 4 个基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

    1.  [4.2 情境感知](https://arxiv.org/html/2401.05459v2#S4.SS2 "在 4 个基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

        1.  [4.2.1 感知源](https://arxiv.org/html/2401.05459v2#S4.SS2.SSS1 "在 4.2 情境感知 ‣ 4 个基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

        1.  [4.2.2 感知目标](https://arxiv.org/html/2401.05459v2#S4.SS2.SSS2 "在 4.2 情境感知 ‣ 4 个基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

    1.  [4.3 记忆](https://arxiv.org/html/2401.05459v2#S4.SS3 "在 4 个基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

        1.  [4.3.1 获得记忆](https://arxiv.org/html/2401.05459v2#S4.SS3.SSS1 "在 4.3 记忆 ‣ 4 个基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

        1.  [4.3.2 管理和利用记忆](https://arxiv.org/html/2401.05459v2#S4.SS3.SSS2 "在 4.3 记忆 ‣ 4 个基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

1.  [5 效率](https://arxiv.org/html/2401.05459v2#S5 "在 个人 LLM 代理：关于能力、效率和安全的见解和调查")

    1.  [5.1 高效推理](https://arxiv.org/html/2401.05459v2#S5.SS1 "在 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

        1.  [5.1.1 模型压缩](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS1 "在 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")

        1.  [5.1.2 推理加速](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS2 "在 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [5.1.3 内存减少](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS3 "在 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [5.1.4 能源优化](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS4 "在 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

    1.  [5.2 高效定制](https://arxiv.org/html/2401.05459v2#S5.SS2 "在 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [5.2.1 上下文加载效率](https://arxiv.org/html/2401.05459v2#S5.SS2.SSS1 "在 5.2 高效定制 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [5.2.2 微调效率](https://arxiv.org/html/2401.05459v2#S5.SS2.SSS2 "在 5.2 高效定制 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

    1.  [5.3 高效内存操作](https://arxiv.org/html/2401.05459v2#S5.SS3 "在 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [5.3.1 搜索效率](https://arxiv.org/html/2401.05459v2#S5.SS3.SSS1 "在 5.3 高效内存操作 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [5.3.2 工作流优化](https://arxiv.org/html/2401.05459v2#S5.SS3.SSS2 "在 5.3 高效内存操作 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

1.  [6 安全与隐私](https://arxiv.org/html/2401.05459v2#S6 "在 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

    1.  [6.1 保密性](https://arxiv.org/html/2401.05459v2#S6.SS1 "在 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [6.1.1 本地处理](https://arxiv.org/html/2401.05459v2#S6.SS1.SSS1 "在 6.1 保密性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [6.1.2 安全远程处理](https://arxiv.org/html/2401.05459v2#S6.SS1.SSS2 "在 6.1 保密性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [6.1.3 数据遮蔽](https://arxiv.org/html/2401.05459v2#S6.SS1.SSS3 "在 6.1 保密性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [6.1.4 信息流控制](https://arxiv.org/html/2401.05459v2#S6.SS1.SSS4 "在 6.1 保密性 ‣ 6 安全性和隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

    1.  [6.2 完整性](https://arxiv.org/html/2401.05459v2#S6.SS2 "在 6 安全性和隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [6.2.1 对抗性攻击](https://arxiv.org/html/2401.05459v2#S6.SS2.SSS1 "在 6.2 完整性 ‣ 6 安全性和隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [6.2.2 后门攻击](https://arxiv.org/html/2401.05459v2#S6.SS2.SSS2 "在 6.2 完整性 ‣ 6 安全性和隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [6.2.3 提示注入攻击](https://arxiv.org/html/2401.05459v2#S6.SS2.SSS3 "在 6.2 完整性 ‣ 6 安全性和隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

    1.  [6.3 可靠性](https://arxiv.org/html/2401.05459v2#S6.SS3 "在 6 安全性和隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [6.3.1 问题](https://arxiv.org/html/2401.05459v2#S6.SS3.SSS1 "在 6.3 可靠性 ‣ 6 安全性和隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [6.3.2 改进](https://arxiv.org/html/2401.05459v2#S6.SS3.SSS2 "在 6.3 可靠性 ‣ 6 安全性和隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [6.3.3 检查](https://arxiv.org/html/2401.05459v2#S6.SS3.SSS3 "在 6.3 可靠性 ‣ 6 安全性和隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

1.  [7 结论与展望](https://arxiv.org/html/2401.05459v2#S7 "在 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

# 个人 LLM 代理：

关于能力、效率和安全性的见解与调查

元春·李¹^†、浩·温¹^‡、伟君·王¹^‡、向宇·李¹^‡、逸真·袁¹^‡、国宏·刘¹^‡，

佳诚·刘¹、文兴·徐¹、翔·王¹、怡·孙¹、瑞·孔¹、怡乐·王¹、汉飞·耿¹，

剑·栾²、雪峰·金³、自龙·叶⁴、关婧·熊⁵、范·张⁶、向·李⁷，

孟伟·徐⁸、志军·李⁹、鹏·李¹、杨·刘¹、亚钦·张¹、云欣·刘¹

¹ 人工智能产业研究院 (AIR)，清华大学

² 小米 AI 实验室   ³ 华为技术有限公司   ⁴ 深圳嘿拓科技有限公司

⁵ vivo AI Lab   ⁶ 维奥米科技有限公司   ⁷ 理想汽车股份有限公司

⁸ 北京邮电大学   ⁹ 苏州大学

^† 项目负责人     ^‡ 章节负责人

联系方式：liyuanchun@air.tsinghua.edu.cn

网站：[`github.com/MobileLLM/Personal_LLM_Agents_Survey`](https://github.com/MobileLLM/Personal_LLM_Agents_Survey)

###### 摘要

自个人计算设备出现以来，智能个人助理（IPAs）一直是研究人员和工程师关注的关键技术之一，旨在帮助用户高效获取信息和执行任务，并为用户提供更智能、便捷、丰富的交互体验。随着智能手机和物联网的发展，计算和感知设备已变得无处不在，大大扩展了 IPAs 的功能边界。然而，由于缺乏用户意图理解、任务规划、工具使用和个人数据管理等能力，现有的 IPAs 仍然在实用性和可扩展性上有限。

最近，以大型语言模型（LLMs）为代表的基础模型的出现，为 IPAs 的发展带来了新的机遇。凭借强大的语义理解和推理能力，LLM 可以使智能代理自主解决复杂问题。本文重点讨论*个人 LLM 代理*，即基于 LLM 的代理，深入整合个人数据和个人设备，用于个人助手。我们设想个人 LLM 代理将在即将到来的时代成为终端用户的主要软件范式。为实现这一愿景，我们首先讨论关于个人 LLM 代理的几个重要问题，包括其架构、能力、效率和安全性。我们从总结个人 LLM 代理架构中的关键组件和设计选择开始，随后对领域专家收集的意见进行深入分析。接下来，我们讨论实现智能、高效、安全的个人 LLM 代理的几个关键挑战，并对应对这些挑战的代表性解决方案进行全面调查。

*关键词* 智能个人助理  $\cdot$ 大语言模型  $\cdot$ LLM 代理  $\cdot$ 移动设备  $\cdot$ 智能水平  $\cdot$ 任务自动化  $\cdot$ 感知  $\cdot$ 记忆  $\cdot$ 效率  $\cdot$ 安全与隐私

###### 内容

1.  [1 引言](https://arxiv.org/html/2401.05459v2#S1 "在 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

1.  [2 智能个人助理的简要历史](https://arxiv.org/html/2401.05459v2#S2 "在 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [2.1 智能个人助理历史时间线视图](https://arxiv.org/html/2401.05459v2#S2.SS1 "在 2 智能个人助理的简要历史 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [2.2 智能个人助理历史技术视图](https://arxiv.org/html/2401.05459v2#S2.SS2 "在 2 智能个人助理的简要历史 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [2.2.1 基于模板的编程](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS1 "在 2.2 智能个人助理的技术视角 ‣ 2 智能个人助理的简史 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [2.2.2 监督学习方法](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS2 "在 2.2 智能个人助理的技术视角 ‣ 2 智能个人助理的简史 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [2.2.3 强化学习方法](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS3 "在 2.2 智能个人助理的技术视角 ‣ 2 智能个人助理的简史 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [2.2.4 基础模型的早期应用](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS4 "在 2.2 智能个人助理的技术视角 ‣ 2 智能个人助理的简史 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

1.  [3 个人 LLM 代理：定义与见解](https://arxiv.org/html/2401.05459v2#S3 "在个人 LLM 代理：关于能力、效率和安全性的见解与调查")

    1.  [3.1 关键组件](https://arxiv.org/html/2401.05459v2#S3.SS1 "在 3 个人 LLM 代理：定义与见解 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

    1.  [3.2 个人 LLM 代理的智能水平](https://arxiv.org/html/2401.05459v2#S3.SS2 "在 3 个人 LLM 代理：定义与见解 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

    1.  [3.3 对常见问题的看法](https://arxiv.org/html/2401.05459v2#S3.SS3 "在 3 个人 LLM 代理：定义与见解 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

1.  [4 基本能力](https://arxiv.org/html/2401.05459v2#S4 "在个人 LLM 代理：关于能力、效率和安全性的见解与调查")

    1.  [4.1 任务执行](https://arxiv.org/html/2401.05459v2#S4.SS1 "在 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [4.1.1 任务自动化方法](https://arxiv.org/html/2401.05459v2#S4.SS1.SSS1 "在 4.1 任务执行 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [4.1.2 自主代理框架](https://arxiv.org/html/2401.05459v2#S4.SS1.SSS2 "在 4.1 任务执行 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")

        1.  [4.1.3 评估](https://arxiv.org/html/2401.05459v2#S4.SS1.SSS3 "在 4.1 任务执行 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [4.2 上下文感知](https://arxiv.org/html/2401.05459v2#S4.SS2 "在 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [4.2.1 感知来源](https://arxiv.org/html/2401.05459v2#S4.SS2.SSS1 "在 4.2 上下文感知 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [4.2.2 感知目标](https://arxiv.org/html/2401.05459v2#S4.SS2.SSS2 "在 4.2 上下文感知 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [4.3 记忆](https://arxiv.org/html/2401.05459v2#S4.SS3 "在 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [4.3.1 获取记忆](https://arxiv.org/html/2401.05459v2#S4.SS3.SSS1 "在 4.3 记忆 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [4.3.2 内存管理与利用](https://arxiv.org/html/2401.05459v2#S4.SS3.SSS2 "在 4.3 记忆 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

1.  [5 效率](https://arxiv.org/html/2401.05459v2#S5 "在个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [5.1 高效推理](https://arxiv.org/html/2401.05459v2#S5.SS1 "在 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.1.1 模型压缩](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS1 "在 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.1.2 推理加速](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS2 "在 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.1.3 内存减少](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS3 "在 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.1.4 能源优化](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS4 "在 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [5.2 高效定制](https://arxiv.org/html/2401.05459v2#S5.SS2 "在 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.2.1 上下文加载效率](https://arxiv.org/html/2401.05459v2#S5.SS2.SSS1 "在 5.2 高效定制 ‣ 5 效率 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

        1.  [5.2.2 微调效率](https://arxiv.org/html/2401.05459v2#S5.SS2.SSS2 "在 5.2 高效定制 ‣ 5 效率 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

    1.  [5.3 高效内存操作](https://arxiv.org/html/2401.05459v2#S5.SS3 "在 5 效率 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

        1.  [5.3.1 搜索效率](https://arxiv.org/html/2401.05459v2#S5.SS3.SSS1 "在 5.3 高效内存操作 ‣ 5 效率 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

        1.  [5.3.2 工作流优化](https://arxiv.org/html/2401.05459v2#S5.SS3.SSS2 "在 5.3 高效内存操作 ‣ 5 效率 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

1.  [6 安全与隐私](https://arxiv.org/html/2401.05459v2#S6 "在 个人 LLM 代理：能力、效率和安全性的见解与调查")

    1.  [6.1 保密性](https://arxiv.org/html/2401.05459v2#S6.SS1 "在 6 安全与隐私 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

        1.  [6.1.1 本地处理](https://arxiv.org/html/2401.05459v2#S6.SS1.SSS1 "在 6.1 保密性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

        1.  [6.1.2 安全远程处理](https://arxiv.org/html/2401.05459v2#S6.SS1.SSS2 "在 6.1 保密性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

        1.  [6.1.3 数据屏蔽](https://arxiv.org/html/2401.05459v2#S6.SS1.SSS3 "在 6.1 保密性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

        1.  [6.1.4 信息流控制](https://arxiv.org/html/2401.05459v2#S6.SS1.SSS4 "在 6.1 保密性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

    1.  [6.2 完整性](https://arxiv.org/html/2401.05459v2#S6.SS2 "在 6 安全与隐私 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

        1.  [6.2.1 对抗攻击](https://arxiv.org/html/2401.05459v2#S6.SS2.SSS1 "在 6.2 完整性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

        1.  [6.2.2 后门攻击](https://arxiv.org/html/2401.05459v2#S6.SS2.SSS2 "在 6.2 完整性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：能力、效率和安全性的见解与调查")

        1.  [6.2.3 提示注入攻击](https://arxiv.org/html/2401.05459v2#S6.SS2.SSS3 "在 6.2 完整性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全的见解与调查")

    1.  [6.3 可靠性](https://arxiv.org/html/2401.05459v2#S6.SS3 "在 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全的见解与调查")

        1.  [6.3.1 问题](https://arxiv.org/html/2401.05459v2#S6.SS3.SSS1 "在 6.3 可靠性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全的见解与调查")

        1.  [6.3.2 改进](https://arxiv.org/html/2401.05459v2#S6.SS3.SSS2 "在 6.3 可靠性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全的见解与调查")

        1.  [6.3.3 检查](https://arxiv.org/html/2401.05459v2#S6.SS3.SSS3 "在 6.3 可靠性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全的见解与调查")

1.  [7 结论与展望](https://arxiv.org/html/2401.05459v2#S7 "在 个人 LLM 代理：关于能力、效率和安全的见解与调查")

## 1 引言

科幻作品描绘了许多引人注目的智能个人助理（IPA）角色，这些软件代理能够增强个人能力、完成复杂任务，甚至满足情感需求。这些智能代理代表了大多数人对人工智能（AI）的幻想。随着个人设备（如智能手机、智能家居设备、电动汽车等）的广泛采用和机器学习技术的进步，这一幻想正逐渐成为现实。如今，许多移动设备嵌入了 IPA 软件，如 Siri [[1](https://arxiv.org/html/2401.05459v2#bib.bib1)]、Google Assistant [[2](https://arxiv.org/html/2401.05459v2#bib.bib2)]、Alexa [[3](https://arxiv.org/html/2401.05459v2#bib.bib3)] 等。这些智能代理与用户深度交织，能够访问用户数据和传感器，控制各种个人设备，并访问与私人账户相关的个性化服务。

然而，今天的智能个人助理仍然受到灵活性和可扩展性限制的困扰。它们的智能水平远远不足，特别是在理解用户意图、推理和任务执行方面尤为明显。目前大多数智能个人助理的功能限于特定领域（例如，内置应用中的简单功能）。一旦用户请求超出这些范围的任务，代理就无法准确理解和执行操作。要改变这种情况，需要显著扩展代理的能力，以支持更广泛和更灵活的任务范围。然而，目前的 IPA 产品很难支持大规模的任务。今天的大多数 IPA 需要遵循特定的预定义规则来完成任务，例如开发者定义的或用户演示的步骤。因此，开发者或用户必须明确指定他们希望支持哪些功能，并定义任务执行的触发条件和步骤。这种方法本质上限制了支持更多任务的可扩展性，因为支持更多任务需要大量的时间和劳动力成本。一些方法已经尝试通过监督学习或强化学习[[4](https://arxiv.org/html/2401.05459v2#bib.bib4), [5](https://arxiv.org/html/2401.05459v2#bib.bib5), [6](https://arxiv.org/html/2401.05459v2#bib.bib6)] 自动学习以支持任务。然而，这些方法也依赖于大量的手动演示和/或奖励函数的定义。

近年来，大型语言模型（LLMs）[[7](https://arxiv.org/html/2401.05459v2#bib.bib7)] 的出现为智能个人助理（IPAs）的发展带来了全新的机遇，展示了应对智能个人助理可扩展性问题的潜力。与传统方法相比，大型语言模型如 ChatGPT、Claude 等展现了独特的能力，如指令跟随、常识推理和零样本泛化。这些能力是通过在大规模语料库（超过 1.4 万亿字）上进行无监督学习，并随后通过人类反馈进行微调实现的。借助这些能力，研究人员成功地采用了大型语言模型来赋能自主代理（即 LLM 代理），旨在通过自动制定计划并使用搜索引擎、代码解释器和第三方 API 等工具来解决复杂问题。

作为一种独特的智能代理，IPAs 也有可能通过 LLM 实现显著增强的可扩展性、能力和实用性。我们称这种 LLM 驱动的智能个人助手为个人 LLM 代理。与普通 LLM 代理相比，个人 LLM 代理更深入地与个人数据和移动设备互动，更明确地设计为帮助人们而非替代人类。具体来说，帮助用户的主要方式是减少他们日常生活中的重复、乏味和低价值的劳动，让用户专注于更有趣和有价值的事情，从而提高他们工作和生活的效率和质量。个人 LLM 代理可以建立在现有的软件堆栈（如移动应用程序、网站等）之上，同时带来令人耳目一新的用户体验，并具有无处不在的智能自动化能力。因此，我们期望个人 LLM 代理在 AI 时代成为个人计算设备的主要软件范式，如图 [1](https://arxiv.org/html/2401.05459v2#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security") 所示。

![参考说明](img/4262fe0a3f74c57e3c9f55b88604e6b5.png)

图 1：我们设想个人 LLM 代理将在即将到来的时代成为个人用户主导的软件范式。

尽管个人 LLM 代理的前景令人期待，但相关研究仍处于起步阶段，面临诸多复杂性和挑战。本文迈出了讨论路线图、设计选择、主要挑战和实施个人 LLM 代理的可能解决方案的第一步。具体而言，我们主要关注与个人 LLM 代理中的“*个人*”部分相关的方面，包括用户个人数据的分析和利用、个人资源的使用、个人设备上的部署以及提供个性化服务。将 LLM 的通用语言能力直接整合到 IPA 中不在本文讨论范围之内。

我们首先进行了对个人 LLM 代理领域专家的调查。我们邀请了来自领先公司的 25 位首席架构师、管理董事和/或高级工程师/研究员，他们在个人设备上的 IPA 和/或 LLM 方面有工作经验。我们询问了专家们关于将 LLM 集成到他们面向消费者的产品中的机会和挑战的意见。基于我们对专家见解的理解和分析，我们总结了个人 LLM 代理的一个简单而通用的架构，其中智能管理和利用个人数据（用户上下文、环境状态、活动历史、个性等）和个人资源（移动应用、传感器、智能家居设备等）发挥了至关重要的作用。管理和利用这些个人对象的能力使个人 LLM 代理的智能水平有所不同。受到自主驾驶 L1-L5 智能水平的启发，我们还给出了个人 LLM 代理的五个智能级别的分类法。

我们的研究还突出了实现此类个人 LLM 代理的几个主要技术挑战，这些挑战可以分为三个方面，包括基础能力、效率以及安全性与隐私。我们进一步深入探讨了这些方面，详细解释了挑战并全面调查了可能的解决方案。具体来说，对于每一个技术方面，我们简要解释了其与个人 LLM 代理的相关性和重要性，然后将其分解为几个主要的研究问题。例如，个人 LLM 代理的基础能力包括任务执行、上下文感知和记忆。代理的效率主要由 LLM 推理效率、定制效率和记忆检索效率决定。个人 LLM 代理的安全性和隐私问题可以归类为数据保密性、决策可靠性和系统完整性。对于每个研究问题，我们总结了涉及该问题的主要技术，并简要介绍了相关的工作。由于个人 LLM 代理技术的范围广泛，我们只包括了最相关或最新的工作，而不是尝试覆盖所有相关的方法。

本文的主要内容和贡献可以总结如下：

1.  1.

    我们总结了现有智能个人助理在工业界和学术界的现状，同时分析了它们的主要局限性和在 LLM 时代的未来趋势。

1.  2.

    我们从 LLM 和个人代理领域的高级专家那里收集了见解，提出了一个通用系统架构和个人 LLM 代理的智能级别定义。

1.  3.

    我们回顾了个人 LLM 代理的三个重要技术方面的文献，包括基础能力、效率以及安全性与隐私。

## 2 智能个人助理的简要历史

图 2：智能个人助理（IPAs）历史上的主要里程碑。我们用不同的颜色标记不同的发展阶段，并用**粗体**文本突出一些重要或开创性的事件。

### 2.1 智能个人助理历史的时间线视图

智能个人助理（IPA）有着悠久的发展历史。我们在图[2](https://arxiv.org/html/2401.05459v2#S2.F2 "Figure 2 ‣ 2 A Brief History of Intelligent Personal Assistants ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")中描绘了 IPA 历史的大致时间线。发展进程可以分为四个阶段，每个阶段在图中用不同的颜色标记。

第一阶段从 1950 年代持续到 1980 年代末，主要涉及语音识别技术的发展。语音识别的早期阶段从基本的数字和单词开始。贝尔实验室开发了“奥黛丽”（Audrey），能够以约 90%的准确率识别 0-9 的数字。1962 年，IBM 的高级系统开发部实验室推出了“鞋盒”[[8](https://arxiv.org/html/2401.05459v2#bib.bib8)]系统，能够识别最多 16 个单词。从 1971 年到 1976 年，由美国国防部资助的语音理解研究（SUR）项目显著推进了语音识别技术。哈比（Harpy）系统[[9](https://arxiv.org/html/2401.05459v2#bib.bib9)]尤其具有代表性，因为它能够理解由 1011 个单词组成的句子，相当于一个三岁儿童的语言能力。1986 年，IBM 开发了 Tangora 语音识别输入系统[[10](https://arxiv.org/html/2401.05459v2#bib.bib10)]，能够识别 20,000 个单词，并提供预测和纠错功能。Tangora 系统利用了隐马尔可夫模型[[11](https://arxiv.org/html/2401.05459v2#bib.bib11)]，需要对每个说话者进行单独的语音训练，每个单词之间需要暂停。

第二阶段涵盖了 1990 年代到 2000 年代末的时期，因为语音识别开始被集成到某些高级功能的软件中。1990 年，"Dragon Dictate"软件 [[12](https://arxiv.org/html/2401.05459v2#bib.bib12)] 发布，它是第一个面向消费者的语音识别产品。它最初设计用于在 Microsoft Windows 上运行，支持离散语音识别。1993 年，苹果公司推出了"Speakable items" [[13](https://arxiv.org/html/2401.05459v2#bib.bib13)]，使用户能够通过自然语言控制计算机。1996 年，IBM 为放射科医生推出了"MedSpeak" [[14](https://arxiv.org/html/2401.05459v2#bib.bib14)]，这也是第一个支持连续语音识别的商业产品。微软于 2002 年将语音识别集成到 Office 应用程序中 [[15](https://arxiv.org/html/2401.05459v2#bib.bib15)]，谷歌则在 2008 年将语音搜索添加到 iPhone 上的 Google Mobile App 中 [[16](https://arxiv.org/html/2401.05459v2#bib.bib16)]。

第三阶段从 2010 年代初期开始。在这一时期，始终在线的虚拟助手服务开始出现在智能手机和个人计算机等移动设备上。Siri [[1](https://arxiv.org/html/2401.05459v2#bib.bib1)] 被广泛认为是现代智能手机上安装的第一个智能个人助理，于 2011 年集成到苹果公司的 iPhone 4S 中。自发布以来，Siri 一直是苹果设备（包括 iPhone、iPad、Apple Watch、HomePod 和 Mac）的关键内置软件，并不断进行更新和迭代以融入新功能。与 Siri 类似，许多其他虚拟智能助手在此期间也开始出现。2014 年，微软发布了 Cortana [[17](https://arxiv.org/html/2401.05459v2#bib.bib17)]，并逐步将其集成到台式计算机和其他平台中。亚马逊在同年发布了 Alexa [[3](https://arxiv.org/html/2401.05459v2#bib.bib3)]，能够完成语音互动、播放音乐、设置闹钟等任务。除了语音搜索，谷歌助理 [[2](https://arxiv.org/html/2401.05459v2#bib.bib2)] 于 2016 年推出，支持用户通过语音和键盘输入进行互动。

第四阶段最近开始，当 LLM（大型语言模型）开始吸引全球关注时，基于 LLM 的许多智能聊天机器人（例如，ChatGPT [[18](https://arxiv.org/html/2401.05459v2#bib.bib18)]）以及一些安装在个人设备上的 LLM 驱动 IPA（智能个人助理）软件（例如，Copilot [[19](https://arxiv.org/html/2401.05459v2#bib.bib19)]）相继出现。此阶段的详细内容将在第[2.2.4](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS4 "2.2.4 Foundation Models 的早期采用 ‣ 2.2 智能个人助理历史的技术视角 ‣ 2 智能个人助理简史 ‣ 个人 LLM 代理：关于能力、效率和安全的见解和调查")节中讨论。

### 2.2 智能个人助理历史的技术视角

由于有许多方面可以反映个人助理的智能性，我们选择智能个人助理最重要的能力之一，即任务自动化能力（遵循指令和完成任务），作为主要关注点。在以下子章节中，我们将介绍四种主要的技术，以实现 IPA 的智能任务自动化。请注意，这些类型的解决方案正在并行发展，它们之间没有严格的时间顺序。

#### 2.2.1 基于模板的编程

大多数商业 IPA 产品通过基于模板的方法支持任务自动化。在这些方法中，可以自动化的功能被预定义为模板，每个模板通常包含任务描述、相关操作、匹配的示例查询、需要完成的支持参数等。给定用户命令后，代理首先将命令映射到最相关的模板，然后按照预定义的步骤完成任务。工作流程如图[3](https://arxiv.org/html/2401.05459v2#S2.F3 "Figure 3 ‣ 2.2.1 Template-based Programming ‣ 2.2 Technical View of the Intelligent Personal Assistants History ‣ 2 A Brief History of Intelligent Personal Assistants ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")所示。

当使用这种方法来自动化任务时，应用开发者需要参考某些 API 的文档（例如，Google Assistant API [[2](https://arxiv.org/html/2401.05459v2#bib.bib2)]、SiriKit [[20](https://arxiv.org/html/2401.05459v2#bib.bib20)]等）来为他们希望自动化的每个功能创建模板。此外，还提出了一些方法，使最终用户能够创建自己的任务模板，例如 iPhone 设备上的“Shortcuts” [[21](https://arxiv.org/html/2401.05459v2#bib.bib21)]功能，实现了重复操作序列的自动化。类似的功能也在许多 Android 系统的产品和学术研究中实现，例如 Tasker [[22](https://arxiv.org/html/2401.05459v2#bib.bib22)]、Anywhere [[23](https://arxiv.org/html/2401.05459v2#bib.bib23)]、Epidosite [[24](https://arxiv.org/html/2401.05459v2#bib.bib24)]以及微软的 uLink [[25](https://arxiv.org/html/2401.05459v2#bib.bib25)]系统等。

这种基于模板的任务自动化方法的优势在于其可靠性和准确性，因为模板中的步骤是确定性和精心编程的。然而，由于支持新任务的机制相对复杂，其可扩展性相当有限。因此，大多数应用程序，包括大型公司的流行应用程序，不能支持任何自动化任务或仅支持一些基本任务，导致用户体验非常不灵活。终端用户在几次失败尝试后可能会轻易放弃使用 IPA 的想法[[26](https://arxiv.org/html/2401.05459v2#bib.bib26), [27](https://arxiv.org/html/2401.05459v2#bib.bib27), [28](https://arxiv.org/html/2401.05459v2#bib.bib28), [29](https://arxiv.org/html/2401.05459v2#bib.bib29)]。这一限制对基于模板的智能个人助理的进一步发展构成了重大障碍。

图 3：基于模板的任务自动化工作流程。

#### 2.2.2 监督学习方法

为了应对基于模板的 IPA 方法的局限性，研究人员正在积极探讨自动化方法，以增强 UI 理解和自动化。监督学习通过训练模型来预测后续动作和状态，提供了一种直接的任务自动化方法，这些模型基于任务输入和当前状态。主要的研究问题包括如何学习软件 GUI 的表示和如何训练交互模型。

从人类交互痕迹中学习交互模型的想法在 Humanoid [[30](https://arxiv.org/html/2401.05459v2#bib.bib30)] 中提出，该模型旨在根据 GUI 布局信息生成类似人类的测试输入。Seq2act [[4](https://arxiv.org/html/2401.05459v2#bib.bib4)] 首先关注于移动 UI 任务自动化领域，其中自然语言指令需要映射到可以直接执行的动作序列。该框架将问题分解为动作短语提取部分和基础部分，两者均使用 Transformer [[31](https://arxiv.org/html/2401.05459v2#bib.bib31)] 网络。受到 NLP 中预训练成功的启发，ActionBert [[32](https://arxiv.org/html/2401.05459v2#bib.bib32)] 使用自监督预训练来增强模型对 UIs 的理解。具体而言，为了捕捉 UI 切换动作的语义信息，该模型被设计为输入一对 UI，并输出这两个 UI 及其单独组件的嵌入。Fu 等人 [[33](https://arxiv.org/html/2401.05459v2#bib.bib33)] 将 NLP 中的单词/句子的概念扩展到像素词/屏幕句子。通过用视觉原子组件（像素词）进行预训练，PW2SS 框架（句子 Transformer）能够完成各种下游 GUI 理解任务。为了更好地兼容移动设备上的受限资源，提出了 Versatile UI Transformer (VUT) [[34](https://arxiv.org/html/2401.05459v2#bib.bib34)]，旨在通过单一的小模型学习不同的 UI 基础任务。它处理图像、结构和基于文本的数据类型，使用 3 个任务头同时支持执行 5 项不同任务，包括 UI 对象检测、自然语言命令基础、控件标注、屏幕总结和 UI 可点击性预测。基于不同模态组件之间自对齐的特征，UIBert [[35](https://arxiv.org/html/2401.05459v2#bib.bib35)] 提出了一个设计良好的联合图像-文本模型来利用这种对应关系，从未标注数据中学习上下文 UI 嵌入。为了解决缺乏 UI 元数据的问题，例如 DOM 树和视图层级，SpotLight [[36](https://arxiv.org/html/2401.05459v2#bib.bib36)] 引入了一种仅基于视觉的移动 UI 理解方法，通过截图和感兴趣区域（“焦点”）作为输入。它由一个视觉编码器和一个语言解码器组成，可以根据提供的截图和提示完成任务。此外，Lexi [[37](https://arxiv.org/html/2401.05459v2#bib.bib37)] 提出了利用基于文本的说明手册和用户指南来策划多模态数据集。通过将文本和视觉特征融合作为 co-attention transformer 层的输入，模型经过预训练，以形成文本指令和 UI 截图之间的联系。UINav [[38](https://arxiv.org/html/2401.05459v2#bib.bib38)] 使用裁判模型来评估代理的性能，并立即向用户反馈。此外，它还采用了示范增强来增加数据多样性。

与基于模板的方法相比，监督学习方法在经过充分训练后有可能对未见过的任务进行泛化。然而，训练模型通常需要大量高质量的人类标注数据。鉴于现实世界任务和应用的多样性，获取涵盖各种使用场景的训练数据是具有挑战性的。

#### 2.2.3 强化学习方法

与需要大量训练样本的监督学习基础的任务自动化方法不同，基于强化学习（RL）的方法允许代理通过持续与目标界面互动来获得任务自动化的能力。在互动过程中，代理会获得指示任务完成进展的奖励反馈，并通过最大化奖励收益逐渐学会如何自动化任务。

要训练基于 RL 的任务自动化代理，需要一个指示任务完成进展的奖励函数。World of Bits (WoB) [[39](https://arxiv.org/html/2401.05459v2#bib.bib39)] 被提出作为一个通用平台，让代理在 Web 上使用键盘和鼠标完成任务。该平台提供了一个名为“MiniWoB”的基准，其中包含了一组自创建的玩具网站上的任务，并附有预定义的奖励。Glider [[5](https://arxiv.org/html/2401.05459v2#bib.bib5)] 根据任务描述与 UI 动作序列之间的语义相似性、以及动作序列的局部性和方向性来定义现实世界网站的奖励函数。

基于强化学习（RL）的任务自动化面临的另一个挑战是巨大的动作空间和稀疏的奖励。典型的 GUI 任务通常涉及$5$-$10$步，每步包含$10$-$100$个候选动作，导致搜索空间大小为$10^{5}$-$100^{10}$。只有采取正确的动作序列才能完成任务。为了应对这一挑战，提出了许多框架。刘等人 [[6](https://arxiv.org/html/2401.05459v2#bib.bib6)] 引入了使用高级“工作流”来约束每个时间步骤的允许动作的方法。工作流可以剪枝不良探索方向，加快智能体发现奖励的能力。Gur 等人 [[40](https://arxiv.org/html/2401.05459v2#bib.bib40)] 将复杂的指令分解为多个较小的指令，并为智能体安排课程，以逐渐管理越来越多的子指令。此外，还提出了一种元学习框架来生成指令跟随任务。Jia 等人 [[41](https://arxiv.org/html/2401.05459v2#bib.bib41)] 将智能体在网页上的动作框架分为三个不同的类别，即 DOM 选择、token 选择和模式选择。此外，还设计了一个因子化的 Q 值函数，假设 DOM 选择和 token 选择是独立的。Glider [[5](https://arxiv.org/html/2401.05459v2#bib.bib5)] 通过分层策略实现了减少动作空间的目标，该策略包含一个主策略来处理总体导航和子策略来处理特定的小部件。Humphreys 等人 [[42](https://arxiv.org/html/2401.05459v2#bib.bib42)] 提出了一个框架，直接使用鼠标和键盘来完成任务，而不是依赖于专门的动作空间，这简化了由实际人机交互所告知的行为先验的使用。

类似于监督学习方法，基于强化学习的方法也面临较差的泛化能力。为了实现灵活而稳健的任务自动化，RL 智能体需要在大量任务上进行训练，每个任务都需要一个精心设计的奖励函数。为大量多样化的任务定义奖励函数可能是困难的。

#### 2.2.4 基础模型的早期应用

近年来，以大型语言模型（LLMs）为代表的预训练大规模基础模型得到了迅速发展，为个人助理带来了新的机会。

语言模型的缩放法则[[43](https://arxiv.org/html/2401.05459v2#bib.bib43)]揭示了增加模型参数对于提高模型性能的重要性，紧随其后的是一系列具有数十亿参数的模型。大语言模型（LLMs）通常在无监督的情况下用大规模开放域文本数据进行训练，然后进行指令微调[[44](https://arxiv.org/html/2401.05459v2#bib.bib44)]和基于人类反馈的强化学习（RLHF）[[45](https://arxiv.org/html/2401.05459v2#bib.bib45), [44](https://arxiv.org/html/2401.05459v2#bib.bib44)]以提高性能和对齐度。由 OpenAI 于 2022 年底推出的 ChatGPT[[18](https://arxiv.org/html/2401.05459v2#bib.bib18)]是 LLM 的一个里程碑，展示了惊人的问答能力。通过将简单的任务描述作为输入提示给 LLM，任务和 LLM 的响应可以轻松定制。此外，这些模型还展示了在各种语言理解和推理任务中的强大泛化能力。ChatGPT 本身可以被视为一个智能个人助手，通过返回文本响应来协助用户获取信息。

受到 LLM 能力的启发，研究人员尝试让 LLM 自主使用工具[[46](https://arxiv.org/html/2401.05459v2#bib.bib46)]来完成复杂任务。例如，控制浏览器[[47](https://arxiv.org/html/2401.05459v2#bib.bib47), [48](https://arxiv.org/html/2401.05459v2#bib.bib48)]进行信息检索和总结，调用机器人编程接口进行机器人行为控制[[49](https://arxiv.org/html/2401.05459v2#bib.bib49), [50](https://arxiv.org/html/2401.05459v2#bib.bib50), [51](https://arxiv.org/html/2401.05459v2#bib.bib51)]，以及调用代码解释器进行复杂数据处理[[52](https://arxiv.org/html/2401.05459v2#bib.bib52), [53](https://arxiv.org/html/2401.05459v2#bib.bib53), [54](https://arxiv.org/html/2401.05459v2#bib.bib54), [55](https://arxiv.org/html/2401.05459v2#bib.bib55)]等。将这些能力整合到智能个人助手中是一个自然的想法，可以实现更智能的方式来操控个人数据、个人设备和个性化服务。

已经有一些商业产品尝试将 LLM 与 IPA 集成。例如，微软的 Copilot 系统[[19](https://arxiv.org/html/2401.05459v2#bib.bib19)]集成了 GPT-4 的能力[[56](https://arxiv.org/html/2401.05459v2#bib.bib56)]，帮助 Windows 用户自动草拟文档、创建演示文稿、总结电子邮件，从而提高用户的工作效率。新必应[[57](https://arxiv.org/html/2401.05459v2#bib.bib57)]也提升了上网体验，提供了一个强大高效的搜索引擎，更好地理解用户的需求。类似地，谷歌将 LLMs（Bard [[58](https://arxiv.org/html/2401.05459v2#bib.bib58)], Gemini [[59](https://arxiv.org/html/2401.05459v2#bib.bib59)]）集成到搜索引擎中，以实现更便捷的网页搜索体验。包括华为、小米、OPPO、Vivo 在内的智能手机公司也将大模型（如 PanGu [[60](https://arxiv.org/html/2401.05459v2#bib.bib60)], MiLM [[61](https://arxiv.org/html/2401.05459v2#bib.bib61)]等）集成到他们的本地 IPA 产品中。值得注意的是，其中一些采用了基于本地部署的轻量级 LLM 的解决方案。到目前为止，这些商业产品大多只是将 LLM 的聊天界面简单地集成到个人助理中。有关更深层次功能集成的研究将在第[4.1](https://arxiv.org/html/2401.05459v2#S4.SS1 "4.1 任务执行 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全的见解与调查")节中讨论。

尽管展示了巨大的潜力，但这一研究方向目前仍处于早期探索阶段。距离真正理解和帮助用户的智能代理的最终目标还有相当大的距离。而且，许多与效率、安全和隐私相关的问题尚未得到充分解决。本文的后续部分将系统地总结和讨论这一方向的关键问题。

## 3 个人 LLM 代理：定义与见解

目睹了基于 LLM 的智能个人助理的巨大潜力以及学术界和工业界的广泛兴趣，我们迈出了系统性讨论与这一方向相关的机会、挑战和技术的第一步。

我们将个人 LLM 代理定义为一种特殊类型的基于 LLM 的代理，它与个人数据、个人设备和个人服务紧密集成。个人 LLM 代理的主要目的是协助最终用户，帮助他们减少重复和繁琐的工作，更多地关注有趣和重要的事务。根据这一定义，通用的自动化方法（如提示、规划、自我反思等）与普通的 LLM 基于的代理类似。我们关注的是与“个人”部分相关的方面，例如个人数据管理、智能手机应用的使用、部署到资源受限的个人设备等。

我们设想个人 LLM 代理将成为 LLM 时代个人设备的主要软件范式。然而，个人 LLM 代理的软件堆栈和生态系统仍处于非常早期的阶段。与系统设计和实施相关的许多重要问题尚不明确。

因此，我们尝试根据从领域专家那里收集到的见解来解答一些问题。具体来说，我们邀请了 25 位专家，他们是 8 家领先公司的首席架构师、总经理或高级工程师/研究员，这些公司正在开发与 IPA 相关的产品，包括智能手机个人助手、智能家居解决方案和智能驾驶舱系统。我们与他们随意讨论了个人 LLM 代理的话题，并向他们提出了一些常见问题，从应用场景到部署挑战。根据我们的讨论和收集到的答案，我们将见解总结为三个子章节，包括个人 LLM 代理的关键组件、智能水平的分类法以及对常见问题的专家意见。

### 3.1 关键组件

根据我们对个人 LLM 代理所需特性的讨论，我们首先总结了支持这些特性的主要组件，如图 [4](https://arxiv.org/html/2401.05459v2#S3.F4 "Figure 4 ‣ 3.1 Key Components ‣ 3 Personal LLM Agents: Definition & Insights ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security") 所示。

![参见说明文字](img/f5d26367fddeeeae61a6a1e5a3cbd320.png)

图 4：个人 LLM 代理的主要组件。

毫无疑问，个人 LLM 代理的核心是一个基础模型（大语言模型或其他变体，我们为了简便称之为 LLM），它连接了所有其他组件。首先，LLM 是支持不同技能的基础，以服务用户，包括直接执行用户请求任务的响应性技能（如回答问题、检查天气、安排事件等）和在没有明确用户命令的情况下提供服务的主动技能（如生活记录、管理用户注意力、活动推荐等）。

其次，为了支持这些技能，LLM 管理各种本地资源，包括移动应用、传感器和物联网设备。例如，代理可以通过与智能手机天气应用交互来完成天气检查。同时，许多人提到了个人 LLM 代理提供个性化和上下文感知服务的重要性。因此，LLM 应保持有关用户的信息，包括当前用户上下文（状态、活动、位置等）和历史用户记忆（个人资料、日志、个性等）。为了操作这些资源、上下文和记忆，也希望使用像向量数据库这样的专用管理系统与 LLM 结合。

这些关键组件的组合类似于操作系统[[62](https://arxiv.org/html/2401.05459v2#bib.bib62)]，其中：

1.  1.

    基础模型就像传统操作系统中的内核。它用于系统化管理和调度各种资源，从而促进代理的功能。

1.  2.

    本地资源层类似于传统操作系统中的驱动程序。在传统操作系统中，每个驱动程序管理一组特定的硬件。而在个人 LLM 代理中，每个本地资源组件管理一种工具，并为 LLM 提供 API。

1.  3.

    用户上下文和用户记忆对应于系统操作过程中维护的程序上下文和系统日志。这些组件为代理支持个性化服务奠定了基础。

1.  4.

    顶层的技能类似于传统操作系统中的软件应用。类似于应用程序的安装和卸载，代理的技能也应允许灵活启用或禁用。

### 3.2 个人 LLM 代理的智能等级

个人 LLM 代理所需的功能要求不同种类的能力。受到自动驾驶六个等级的启发，我们将个人 LLM 代理的智能等级分为五个等级，分别为 L1 到 L5，如图[5](https://arxiv.org/html/2401.05459v2#S3.F5 "Figure 5 ‣ 3.2 Intelligence Levels of Personal LLM Agents ‣ 3 Personal LLM Agents: Definition & Insights ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")所示。每个等级的关键特征和代表性使用案例列在表[1](https://arxiv.org/html/2401.05459v2#S3.T1 "Table 1 ‣ 3.2 Intelligence Levels of Personal LLM Agents ‣ 3 Personal LLM Agents: Definition & Insights ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")中。

图 5：不同智能等级下个人 LLM 代理的职责。

表 1：个人 LLM 代理的不同智能等级。

| 等级 | 关键特征 | 代表性使用案例 |
| --- | --- | --- |

| L1 - 简单步骤跟随 | 代理根据用户或开发者预定义的*确切步骤*完成任务。 | - 用户：“打开 Messenger”; 机器人打开名为 Messenger 的应用程序。 - 用户：“打开我的邮箱中第一封未读的邮件并阅读其内容”; 机器人逐步按照命令执行。

- 用户：“给爱丽丝打电话”; 机器人匹配开发者定义的模板，在通讯录中找到爱丽丝的电话号码，并拨打该号码。

| L2 - 确定性任务自动化 | 基于用户对确定性任务的描述，代理根据预定义的行动空间*自动完成*必要的步骤。 | - 用户：“查看今天北京的天气”; 机器人自动调用天气 API，参数为“北京”，并解析响应中的信息。 - 用户：“给爱丽丝视频通话”; 机器人自动打开通讯录，找到爱丽丝的联系方式，并点击“视频通话”。

- 用户：“告诉机器人吸尘器今晚清理房间”; 机器人打开吸尘器应用，点击“定时”，并设置时间为今晚。

| L3 - 战略任务自动化 | 基于用户指定的任务，代理*自主规划*使用各种资源和工具的执行步骤，并根据中间反馈*迭代*计划直至完成。 | - 用户：“告诉爱丽丝我的明天日程安排”; 机器人从用户的日历和聊天记录中收集明天的日程安排信息，然后总结并通过 Messenger 发送给爱丽丝。 - 用户：“找出最近适合旅行的城市”; 机器人列出几个适合旅行的城市，检查每个城市的天气，总结信息，并返回推荐。

- 用户：“记录今晚的睡眠质量”; 机器人在睡眠时间内每隔 10 分钟检查用户是否在使用手机，移动或打呼噜（基于智能手机传感器和麦克风），总结信息并生成报告。

| L4 - 内存和环境感知 | 机器人感知用户环境，了解用户记忆，并在适当的时候主动提供*个性化*服务。 | - 机器人根据用户最近的收入和支出，考虑用户的个性和风险偏好，自动推荐适合的金融产品。 - 机器人根据对话和行为估计用户最近的焦虑水平，推荐电影/音乐来帮助放松，并根据情况通知用户的朋友或医生。

- 当用户在浴室摔倒时，代理检测事件，并根据用户的年龄和身体状况决定是否询问用户，通知用户的家人，或者根据情况求助。

| L5 - 自主化头像 | 代理*完全代表*用户完成复杂事务，可以代表用户与其他用户或代理互动，确保*安全*和*可靠*。 | - 代理自动读取用户的电子邮件和消息，回复问题无需用户干预，并将其总结为摘要。 - 代理代表用户参加工作讨论会议，根据用户的工作日志表达意见，听取建议，并撰写会议纪要。

- 代理记录用户的日常饮食和活动，私下研究或咨询专家任何异常情况，并提出健康改善建议。

在每个级别中，用户和代理负责不同的职责。在第 1 级（简单步骤跟随）中，代理仅负责步骤执行，其他职责由用户承担。例如，当用户发出命令时，代理按照开发者定义的明确步骤或用户给出的步骤完成任务。L1 代理没有感知或规划能力。大多数基于模板的 IPA 产品属于这一类别。

随着智能水平的提高，代理逐渐承担更多的职责。在第 2 级，支持的任务仍然是确定性的（即，涉及完成的固定动作序列），但执行每个任务的详细步骤不再明确给出。代理必须根据用户的任务描述自动完成必要的步骤。例如，对于用户查询“今天北京的天气如何”，代理使用“北京”作为参数调用天气 API，并从响应中获取天气信息。与第 2 级的确定性任务不同，第 3 级的代理可以完成更复杂的任务，这些任务需要战略规划和自我反思。例如，命令“告诉爱丽丝我的明天安排”需要代理确定如何收集安排信息（例如，使用用户的日历和聊天记录）以及如何将信息告知爱丽丝（例如，汇总日历事件并通过消息应用发送）。在这些任务中，代理根据中间反馈自主迭代地生成和执行计划，直到完成任务。

L1-L3 级的代理被动地受用户命令驱动，而第 4 级的代理可以理解用户的历史数据，感知当前情况，并在适当的时候主动提供个性化服务。

具有 5 级超智能的代理扮演着完全代表用户完成复杂事务的自主化化身，因此用户只需专注于创造力和情感。代理不仅感知当前状态，还预测用户的未来活动并采取行动以促进这些活动。除了直接服务用户外，自主化化身还可以与其他代理协作，以减轻用户的沟通负担。此外，5 级代理应能够通过自我进化不断提升自身能力。

### 3.3 对常见问题的意见

接下来，我们报告了专家对若干常见问题的意见汇总结果。这些问题包括个人 LLM 代理的设计选择和潜在挑战，如表[2](https://arxiv.org/html/2401.05459v2#S3.T2 "Table 2 ‣ 3.3 Opinions on Common Problems ‣ 3 Personal LLM Agents: Definition & Insights ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")所总结的。

我们分析了问题的回答，并总结出以下主要结论。

表 2：我们询问领域专家的常见问题。在问题 1 至 6 中，我们提供了几个常见选项供专家选择/优先排序，同时专家也可以给出自由回答。在问题 7 和 8 中，专家被要求用文本回答。

| ID | 问题 |
| --- | --- |
| 1 | 如果将 LLM 应用于个人智能代理，你认为应该在本地部署还是远程部署？ |
| 2 | 你认为针对不同用户或组织量身定制的模型应如何实施？ |
| 3 | 对于在个人设备上部署的 LLM，你认为需要支持哪些模态？ |
| 4 | 你认为 LLM 对个人 LLM 代理最重要的能力是什么？ |
| 5 | 考虑到你所在的行业，你认为哪些交互方式对个人 LLM 代理最具前景？ |
| 6 | 在未来个人 LLM 代理的发展中，哪个方面最为关键？ |
| 7 | 你希望未来的个人 LLM 代理可以为你或你的客户提供哪些功能？ |
| 8 | 在将 LLM 与个人设备集成时，你认为会面临哪些挑战？哪些最紧迫的技术问题需要解决？ |

意见 1（LLM 的部署位置）：*更倾向于边缘云（本地-远程）协作部署 LLM，而现有的仅云端（远程）解决方案（例如，ChatGPT）并不是一个广泛接受的解决方案。* 如图 [7](https://arxiv.org/html/2401.05459v2#S3.F7 "图 7 ‣ 3.3 对常见问题的意见 ‣ 3 个人 LLM 代理：定义与见解 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查") 所示，88% 的参与者更倾向于边缘云协作架构，58.33% 的人支持本地部署，81.82% 的人对现有的仅云端解决方案不满意。他们主要关注的问题包括 1) 远程 LLM 服务的高延迟，2) 传输个人数据到云端的隐私问题，以及 3) 基于云的 LLM 服务的高昂成本。

图 6：个人 LLM 代理中不同 LLM 部署策略的投票分布。

图 7：个人 LLM 代理中不同模型定制方法的投票分布。

意见 2（如何定制代理）：*结合微调和上下文学习是实现定制的最可接受方式。* 在个人 LLM 代理中，为不同用户和场景定制代理被认为是必要的。图 [7](https://arxiv.org/html/2401.05459v2#S3.F7 "图 7 ‣ 3.3 对常见问题的意见 ‣ 3 个人 LLM 代理：定义与见解 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查") 显示，66.67% 的参与者支持结合微调和上下文学习的优势来实现个性化（L4 智能）。43.75% 的人认为 L4 不能通过上下文学习实现；一个可能的原因是我们的参与者来自行业，因此他们更关注 LLM 在特定垂直领域的应用，而上下文学习在这些领域尚未得到太多关注。

在问题 3-5 中，我们要求参与者对选项进行排名，以下表格（表 [3](https://arxiv.org/html/2401.05459v2#S3.T3 "Table 3 ‣ 3.3 Opinions on Common Problems ‣ 3 Personal LLM Agents: Definition & Insights ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")-[5](https://arxiv.org/html/2401.05459v2#S3.T5 "Table 5 ‣ 3.3 Opinions on Common Problems ‣ 3 Personal LLM Agents: Definition & Insights ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")）总结了他们的排名。第一名到第四名表示这些选项在参与者投票中的排名；例如，表 [3](https://arxiv.org/html/2401.05459v2#S3.T3 "Table 3 ‣ 3.3 Opinions on Common Problems ‣ 3 Personal LLM Agents: Definition & Insights ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security") 中的 72%意味着 72%的参与者将文本排为首选模式。每个表格中的“分数”是根据 Borda Count 计算的[[63](https://arxiv.org/html/2401.05459v2#bib.bib63)]，其中每个候选人获得的分数等于他们在每张选票中超越的候选人数的平均值，最低排名的获得 $2$ 分，最高的获得 $n+1$ 分，其中 n 是候选人的总数。例如，表 [3](https://arxiv.org/html/2401.05459v2#S3.T3 "Table 3 ‣ 3.3 Opinions on Common Problems ‣ 3 Personal LLM Agents: Definition & Insights ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security") 中的 $4.56$ 等于 $5\times 72\%+4\times 20\%+3\times 0+2\times 8\%$。

意见 3（使用什么模式）：*多模态 LLM，特别是文本和视觉模式，是个人 LLM 代理的理想选择。* 在我们的统计结果中，文本是最受欢迎的模式，就像最流行的 LLM（例如 GPT 系列和 LLaMA 系列）一样。第二受欢迎的图像选项以及 20%的参与者特别提到的视频模式显示了视觉模式在个人 LLM 代理未来中的潜力。

表 3: 个人 LLM 代理中首选的模式。

| 选项 | 分数 | 第一名 | 第二名 | 第三名 | 第四名 |
| --- | --- | --- | --- | --- | --- |
| 文本 | 4.56 | 72% | 20% | 0% | 8% |
| 图像 | 3.64 | 4% | 64% | 24% | 4% |
| 语音 | 3.18 | 16% | 4% | 60% | 20% |
| 传感器 | 2.18 | 9.52% | 14.29% | 9.52% | 66.67% |

意见 4（LLM 的哪个能力对 IPA 产品最为关键）：*语言理解被认为是 LLM 最重要的能力，而处理长上下文的能力则被认为是最不重要的。* 相反，在学术界，处理长上下文的能力被视为非常重要，并且得到了广泛的研究。这种不同的观点源于我们参与者所设想的特定垂直领域 LLM 和学术研究人员的通用 LLM。在垂直领域 LLM 中，用户的查询和任务并不十分多样化，因此长上下文的能力并不是那么关键。

表 4：IPA 产品对 LLM 能力的重要性排名。

| 选项 | 分数 | 第一名 | 第二名 | 第三名 | 第四名 |
| --- | --- | --- | --- | --- | --- |
| 语言理解 | 4.52 | 83.33% | 8.33% | 4.17% | 4.17% |
| 上下文学习 | 3.16 | 4.55% | 50% | 45.45% | 0% |
| 常识推理 | 3 | 8.33% | 33.33% | 29.17% | 20.83% |
| 长上下文 | 1.8 | 5.56% | 11.11% | 16.67% | 61.11% |

意见 5（如何与代理互动）：*基于语音的互动是最受欢迎的方式。* 不出所料，就像现有的虚拟助手 Siri 一样，模仿人类的交流方式——语音互动是最常见和高效的选择。基于文本的聊天机器人和 GUI 排在第二和第三位，因为大多数参与的专家专注于移动设备，例如智能手机。虚拟现实仅获得 $1.52$ 的分数，在所有问题中最低；这可能源于 VR 设备的高价格和当前 VR 技术的用户体验不佳。

表 5：个人 LLM 代理的首选互动方式。

| 选项 | 分数 | 第一名 | 第二名 | 第三名 | 第四名 |
| --- | --- | --- | --- | --- | --- |
| 语音互动 | 4.04 | 60.87% | 17.39% | 21.74% | 0% |
| 文本聊天框 | 3.32 | 22.73% | 45.45% | 18.18% | 13.64% |
| GUI | 3.24 | 23.81% | 38.1% | 38.1% | 0% |
| 虚拟现实 | 1.52 | 0% | 6.25% | 25% | 68.75% |

意见 6（需要发展哪些代理能力）：在未来个人 LLM 代理的发展中，“更智能和自主的决策能力”被认为是我们参与者认为最关键的特性；几乎一半的参与者（47.83%）将其排名第一。选项“持续改善用户体验和互动方式”和“安全处理个人数据”也获得了很多关注，分别为 36.36% 和 33.33%，并列第二。尽管“与 IoT 设备集成”排名最后，但 47.63% 的参与者仍然认为它作为个人 LLM 代理的基础设施是重要的。

意见 7（理想 IPA 所需的特性）：根据参与者的反馈，我们总结出理想代理的以下六个关键特性：

+   •

    *高效的数据管理和搜索：* 代理充当外部大脑，通过高效的数据存储来记住用户的数据。它为用户提供快速检索和精确搜索的能力。

+   •

    *工作和生活辅助：* 代理在用户请求技术细节时，作为工作中的副驾驶。它还可以执行重复和繁重的任务，为用户提供文档和内容生成服务。

+   •

    *个性化服务和推荐：* 根据用户习惯，代理可以发现用户的潜在需求，并主动提供服务。它可以作为个人和家庭健康管理者、医疗服务提供者、购物比较助手、旅行助手等。

+   •

    *自主任务规划与完成：* 代理能够理解用户的意图，分解用户提出的任务，并逐步自动执行这些任务（进一步在自主链式思维功能中），并帮助用户完成需要手动操作的步骤，提供明确的指示。

+   •

    *情感支持与社交互动：* 代理可以通过聊天理解并帮助用户调整情绪。它还可以理解用户与不同人的关系，帮助用户以其声音撰写回应草稿。

+   •

    *数字代表及其他：* 代理可以代表用户参加会议、驾驶汽车、上班和执行任何授权任务。它可以真正理解用户，并与他人进行交流和社交，就像用户自己在场一样。

意见 8（最紧迫的技术挑战）：根据参与者的反馈，最紧迫的挑战和技术问题被分类如下：

+   •

    *智能。* 1) 多模态支持：大型语言模型（LLMs）需要理解和处理不同的数据类型（例如，文本、图像和视频），因此它应具备先进的数据对齐和解释能力。2) 上下文理解和上下文感知行动：在各种应用场景中，大型语言模型必须准确理解用户需求，并生成相应的控制指令。这需要大型语言模型的上下文理解能力以及将上下文转化为有效行动的能力。3) 增强轻量级大型语言模型的领域特定能力：在资源有限的个人设备上，大型语言模型可能由于其规模和复杂性限制而在复杂任务或深层次上下文理解方面表现不佳。因此，如何提升轻量级模型的能力并处理特定领域的复杂任务是广泛关注的问题。

+   •

    *性能.* 1) 有效的 LLM 压缩或紧凑型架构：在资源有限的移动设备上运行 LLM 需要在性能和任务完成质量之间找到平衡。高效的模型压缩技术需要考虑 LLM 的特性，以保持任务完成的高质量。 2) 实用的本地-远程协作架构：LLM 的本地-远程协作架构被认为有前景，期望继承本地模型的快速/低成本响应能力以及云模型的高质量生成能力。然而，如何实现准确且高效的协作被广泛认为是一个重要挑战。

+   •

    *安全与隐私.* 1) 数据安全和隐私保护：在使用个人数据训练和执行 LLM 时，确保个人数据的安全和用户隐私的保护至关重要。这提出了开发新数据匿名化技术和隐私保护协议的紧迫需求。 2) 推理准确性和无害性：确保模型输出对用户准确且无害，特别是在用于决策或在敏感场景中使用时。

+   •

    *个性化与存储.* 个性化需要高效的数据存储解决方案，以管理和利用与用户相关的数据，包括他们的偏好、历史行为和互动。

+   •

    *传统操作系统支持.* 对于基于移动的 LLM 代理，关键需求是 LLM 友好的接口和对传统操作系统如 Android 的支持。这可能涉及操作系统级别的更新以及应用程序编程接口（API）的开发，以便更好地集成和利用 LLM 的功能。

在领域专家宝贵意见的启发下，以下部分将更详细地讨论所需的能力和潜在挑战。

## 4 种基本能力

我们首先讨论支持多种功能的个人 LLM 代理所需的能力。除了普通 LLM 代理的一般能力外，我们重点关注个人助手的三项基本能力，包括任务执行、情境感知和记忆。任务执行（§[4.1](https://arxiv.org/html/2401.05459v2#S4.SS1 "4.1 Task Execution ‣ 4 Fundamental Capabilities ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")）是将用户的命令或主动感知的任务转化为个人资源上的操作。情境感知（§[4.2](https://arxiv.org/html/2401.05459v2#S4.SS2 "4.2 Context Sensing ‣ 4 Fundamental Capabilities ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")）的目的是感知用户及环境的当前状态，为任务执行提供全面的信息。记忆（§[4.3](https://arxiv.org/html/2401.05459v2#S4.SS3 "4.3 Memorizing ‣ 4 Fundamental Capabilities ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")）是记录用户数据，使代理能够回忆过去的事件、总结知识并自我进化。虽然情境感知和记忆与从用户查询信息相关，但任务执行指的是为用户提供服务的能力。图[8](https://arxiv.org/html/2401.05459v2#S4.F8 "Figure 8 ‣ 4 Fundamental Capabilities ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")展示了这些基本能力之间的关系。接下来的部分将详细讨论这些能力。

![参考说明](img/355137182e1f229836d28c8252cfeb7a.png)

图 8：个人 LLM 代理的基本能力。

### 4.1 任务执行

任务执行是个人 LLM 代理的一项基本能力，使其能够响应用户请求并执行指定任务。在我们的场景中，代理被设计用于与各种个人设备如智能手机、计算机和物联网设备互动和控制，以自动执行用户的命令。

任务执行的一个基本要求是代理能够准确解释用户传达的任务。通常，任务可能来源于用户的口头或书面指令，智能代理从中辨别用户的意图。随着语音识别技术的成熟，将语音信息转换为文本已变得非常方便[[64](https://arxiv.org/html/2401.05459v2#bib.bib64), [65](https://arxiv.org/html/2401.05459v2#bib.bib65)]。

个人 LLM 代理应该在将用户的命令转换为文本后，自动制定计划并采取行动。虽然计划制定对传统的 DNN 来说是一个挑战，但基于 LLM 的代理在这方面表现出更高的熟练度。LLM 代理的计划和推理能力已在以前的调查中讨论过[[66](https://arxiv.org/html/2401.05459v2#bib.bib66)、[67](https://arxiv.org/html/2401.05459v2#bib.bib67)、[68](https://arxiv.org/html/2401.05459v2#bib.bib68)]。我们的论文主要关注个人数据的处理和与个人设备的互动。一个重要的考虑因素是，个人 LLM 代理可能需要与缺乏全面 API 支持的应用程序或系统进行交互。因此，我们还探讨了用户界面（UI）作为个人代理的重要工具，在 API 限制存在的情况下，实现有效互动。

#### 4.1.1 任务自动化方法

根据交互模式的类型，任务执行的方法可以分为基于代码的方法和基于 UI 的方法。在基于代码的场景中，代理主要通过自动生成代码来调用 API 完成任务。在基于 UI 的场景中，代理通过自动模拟与 UI 界面的人工交互来与个人设备进行互动。

基于代码的任务自动化通常涉及生成适当的代码以与 API、数据库和 DNN 模型进行交互。传统的基于代码的个人助手通常依赖于基于插槽填充的任务导向对话（TOD）框架。在 LLM 时代，越来越多的研究人员尝试直接使用 LLM 生成调用 API 的代码，以完成更复杂的任务。

+   •

    插槽填充方法常用于任务导向对话系统（TOD）或聊天机器人，这些对话式人工智能旨在通过对话帮助用户完成特定任务 [[69](https://arxiv.org/html/2401.05459v2#bib.bib69), [70](https://arxiv.org/html/2401.05459v2#bib.bib70)]。在任务导向对话系统中，“插槽”是完成任务所需的预定义信息类别。例如，在旅行预订应用中，插槽可能包括目的地、旅行日期、乘客人数等。在对话过程中，系统会提示用户提供这些信息，并调用相应的 API 来完成任务。对于移动设备，许多方法专注于通过允许用户展示所需任务来促进任务自动化，这些任务可以通过对话界面执行 [[71](https://arxiv.org/html/2401.05459v2#bib.bib71), [72](https://arxiv.org/html/2401.05459v2#bib.bib72), [24](https://arxiv.org/html/2401.05459v2#bib.bib24), [25](https://arxiv.org/html/2401.05459v2#bib.bib25)]。这些方法通常假设用户的任务可以定义为插槽-值对的集合。这个假设使得对话的管理更为精确，通过可控单元进行控制，并且执行任务就是不断提示用户填写尚未识别的插槽值。然而，这些方法未考虑到插槽有多个值或插槽之间的关系的复杂情况 [[73](https://arxiv.org/html/2401.05459v2#bib.bib73)]。此外，它们严重依赖于明确定义的 API，并且缺乏对未知领域的适应性。最近的研究论文利用大语言模型（LLMs）的理解和推理能力来完成更复杂和多轮的 TOD 任务 [[74](https://arxiv.org/html/2401.05459v2#bib.bib74), [75](https://arxiv.org/html/2401.05459v2#bib.bib75), [76](https://arxiv.org/html/2401.05459v2#bib.bib76), [77](https://arxiv.org/html/2401.05459v2#bib.bib77)]，并提高了插槽填充方法的效率。

+   •

    程序合成方法是利用 LLMs 的代码生成能力与 API 进行交互。一种方法是对 LLMs 进行微调，以使用特定的 API。WebGPT [[47](https://arxiv.org/html/2401.05459v2#bib.bib47)] 微调了一个 GPT-3 [[78](https://arxiv.org/html/2401.05459v2#bib.bib78)]，通过调用 Microsoft Bing Web Search API [[79](https://arxiv.org/html/2401.05459v2#bib.bib79)] 来回答长形式问题。一些最近的工作[[46](https://arxiv.org/html/2401.05459v2#bib.bib46), [80](https://arxiv.org/html/2401.05459v2#bib.bib80), [81](https://arxiv.org/html/2401.05459v2#bib.bib81), [82](https://arxiv.org/html/2401.05459v2#bib.bib82)] 微调 LLMs 以检索和调用 API，从而提高它们在数学推理和程序合成等各种任务中的表现。Octopus V2 [[83](https://arxiv.org/html/2401.05459v2#bib.bib83)] 引入了一个 2B 参数的设备内 LLM 来调用 Android API 进行任务自动化。另一种方法是利用 LLMs 的链式推理[[84](https://arxiv.org/html/2401.05459v2#bib.bib84), [85](https://arxiv.org/html/2401.05459v2#bib.bib85), [68](https://arxiv.org/html/2401.05459v2#bib.bib68)] 和上下文学习能力[[78](https://arxiv.org/html/2401.05459v2#bib.bib78)]。它们在上下文中展示工具（例如 API、其他 DNN 等）的描述和演示，并询问 LLMs 如何使用这些工具来完成任务[[86](https://arxiv.org/html/2401.05459v2#bib.bib86), [87](https://arxiv.org/html/2401.05459v2#bib.bib87), [88](https://arxiv.org/html/2401.05459v2#bib.bib88), [52](https://arxiv.org/html/2401.05459v2#bib.bib52), [89](https://arxiv.org/html/2401.05459v2#bib.bib89)]。然而，微调 LLMs 可能成本高昂且受限于预定义的工具集，而上下文学习在 API 数量增加时可能会失败。因此，ToolkenGPT [[90](https://arxiv.org/html/2401.05459v2#bib.bib90)] 的作者尝试通过将每个工具（API）表示为一个标记来解决这个问题。

基于代码的方法可以完成从网页搜索到图像生成的数千项任务。然而，由于安全问题或商业利益，并非所有所需的 API 都对实际应用中的代理开发者开放。此外，有些任务对于人类用户而言容易执行，但调用系统 API 却很困难[[73](https://arxiv.org/html/2401.05459v2#bib.bib73)]。仅依靠公开可用的 API 可能无法完全满足移动任务自动化的高度多样化需求。

基于 UI 的任务自动化。自主 UI 代理试图将用户的任务转换为智能手机或其他个人设备上的 UI 操作，通过直接的 UI 交互来自动化这些任务。与基于代码的任务执行相比，自主 UI 代理不依赖于公开的 API，从而可能允许更灵活的自动化能力。然而，通过 UI 操作执行用户任务对于传统的 DNN 模型并不容易，因为任务和 UI 元素之间存在隐式关系。最近，研究人员利用 LLM 的理解和推理能力来提升自主 UI 代理的性能。

UI 代理的输入是用自然语言描述的任务和当前 UI 的表示，输出是需要在 UI 上执行的 UI 操作。根据它们如何表示 UI，我们可以将自主 UI 代理分为基于文本的 GUI 表示和多模态 GUI 表示。

+   •

    基于文本的 GUI 表示是将 UI 转换为纯文本。Seq2act [[4](https://arxiv.org/html/2401.05459v2#bib.bib4)] 训练了一个基于变换器的模型 [[31](https://arxiv.org/html/2401.05459v2#bib.bib31)]，将用户的指令转换为描述为 <操作，对象，参数> 元组的 UI 操作。研究人员还研究了使用移动 UI 的提示来完成 UI 指令映射任务 [[91](https://arxiv.org/html/2401.05459v2#bib.bib91)]。作者将移动 UI 转换为 HTML 代码，这对 LLM 来说很容易理解，因为它们训练数据的重要部分来自 Github。DroidBot-GPT [[92](https://arxiv.org/html/2401.05459v2#bib.bib92)] 是一个基于 LLM 的系统，用于按序列完成用户的任务。Mind2Web [[93](https://arxiv.org/html/2401.05459v2#bib.bib93)] 使用较小的 LM 过滤网页的原始 HTML，并利用 LLM 选择目标元素和操作。AutoDroid [[94](https://arxiv.org/html/2401.05459v2#bib.bib94)] 使用应用分析工具获取应用领域特定知识，并利用这些知识增强 LLM 以实现任务自动化。在 AXNav [[95](https://arxiv.org/html/2401.05459v2#bib.bib95)] 中，作者构建了一个使用 LLM 和基于像素的 UI 理解来执行手动可访问性测试的系统。MemoDroid [[96](https://arxiv.org/html/2401.05459v2#bib.bib96)] 介绍了一个基于 LLM 的移动任务自动化工具，可以将任务分解为更小的子任务，并通过回忆以前的操作来完成这些子任务。

+   •

    多模态表示是将 UI 的图像（和文本）描述作为个人 LLM 代理的输入。早期的研究工作集中于训练多模态变换器，将用户命令与 UI 元素进行对接[[97](https://arxiv.org/html/2401.05459v2#bib.bib97), [98](https://arxiv.org/html/2401.05459v2#bib.bib98), [38](https://arxiv.org/html/2401.05459v2#bib.bib38)]。在 LLM 时代，一些方法尝试将视觉编码器与 LLM 结合，以处理 GUI 图像[[99](https://arxiv.org/html/2401.05459v2#bib.bib99), [100](https://arxiv.org/html/2401.05459v2#bib.bib100), [101](https://arxiv.org/html/2401.05459v2#bib.bib101)]。随着大型多模态模型（LMM）的出现，越来越多的项目开始使用视觉语言代理进行 UI 动作对接和导航[[102](https://arxiv.org/html/2401.05459v2#bib.bib102), [103](https://arxiv.org/html/2401.05459v2#bib.bib103)]。一种趋势是利用强大的 LMM 如 GPT-4V 来理解 GUI 并选择 UI 元素[[104](https://arxiv.org/html/2401.05459v2#bib.bib104), [105](https://arxiv.org/html/2401.05459v2#bib.bib105), [106](https://arxiv.org/html/2401.05459v2#bib.bib106), [107](https://arxiv.org/html/2401.05459v2#bib.bib107)]。另一种研究方向是通过在大规模数据集上进行微调，定制开源 LMM 以适应 GUI 相关任务[[108](https://arxiv.org/html/2401.05459v2#bib.bib108), [109](https://arxiv.org/html/2401.05459v2#bib.bib109), [110](https://arxiv.org/html/2401.05459v2#bib.bib110)]。

尽管基于 UI 的任务自动化相较于基于 API 的自动化具有实现更灵活个人代理框架的潜力，但其研究仍处于早期阶段。完成更复杂的用户命令仍然具有挑战性。此外，隐私和安全问题尚未得到完全解决[[94](https://arxiv.org/html/2401.05459v2#bib.bib94), [99](https://arxiv.org/html/2401.05459v2#bib.bib99)]。关于 UI 表示的问题仍然存在争议。虽然多模态表示可以处理通过可访问性服务无法解析的元素，但它受到屏幕录制的高需求和当前视觉语言模型有限推理能力的困扰[[111](https://arxiv.org/html/2401.05459v2#bib.bib111)]。

#### 4.1.2 自主代理框架

一个由 LLM 驱动的自主代理由一个 LLM 大脑组成，用于制定计划和自我反思，一个用于存储过去信息和知识的内存，以及一个与工具（如 API、UI、编程语言）交互的工具使用模块 [[112](https://arxiv.org/html/2401.05459v2#bib.bib112), [67](https://arxiv.org/html/2401.05459v2#bib.bib67)]。有许多流行的项目提供了框架，供用户创建 LLM 驱动的代理 [[113](https://arxiv.org/html/2401.05459v2#bib.bib113), [114](https://arxiv.org/html/2401.05459v2#bib.bib114), [115](https://arxiv.org/html/2401.05459v2#bib.bib115), [116](https://arxiv.org/html/2401.05459v2#bib.bib116), [117](https://arxiv.org/html/2401.05459v2#bib.bib117), [118](https://arxiv.org/html/2401.05459v2#bib.bib118), [119](https://arxiv.org/html/2401.05459v2#bib.bib119), [120](https://arxiv.org/html/2401.05459v2#bib.bib120), [121](https://arxiv.org/html/2401.05459v2#bib.bib121)]。它们试图通过与其他外部工具互动和检索长期/短期记忆来增强 LLM 的能力。Auto-GPT [[113](https://arxiv.org/html/2401.05459v2#bib.bib113)] 是其中一个最著名的框架，它通过生成 GPT 提示和使用外部工具来执行用户命令。LangChain [[114](https://arxiv.org/html/2401.05459v2#bib.bib114)] 是另一个流行的框架，它帮助开发者创建更复杂和上下文感知的应用程序。由于理解和生成自然语言的能力，LLM 驱动的代理也可以轻松地互相互动，促进多个代理之间的合作与竞争 [[122](https://arxiv.org/html/2401.05459v2#bib.bib122), [123](https://arxiv.org/html/2401.05459v2#bib.bib123), [118](https://arxiv.org/html/2401.05459v2#bib.bib118), [124](https://arxiv.org/html/2401.05459v2#bib.bib124)]。这些自主代理框架在工程方面做出了重大贡献，为 LLM 驱动的应用程序提供了更友好的框架。

对于移动设备，AutoDroid [[94](https://arxiv.org/html/2401.05459v2#bib.bib94)] 提供了一个有效的框架，用于开发移动代理。开发者可以通过使用测试输入生成器探索应用程序或通过手动演示，轻松创建移动任务的自动化工具。然后，AutoDroid 会自动分析这些记录，并利用它们来改进语言学习模型（LLMs），以实现更高效的任务自动化。黄等人 [[125](https://arxiv.org/html/2401.05459v2#bib.bib125)] 开发了一种新方法，可以有效地从用户与智能手机的交互痕迹中提取宏（如“登录”或“拨打联系人”）等基本活动单位。这些宏可以帮助代理自动完成任务。

#### 4.1.3 评估

评估任务执行性能是一个具有挑战性的问题。对于基于 API 的任务执行，之前的调查提供了关于如何评估它们的全面总结 [[66](https://arxiv.org/html/2401.05459v2#bib.bib66)， [68](https://arxiv.org/html/2401.05459v2#bib.bib68)]。我们的论文主要集中在基于 UI 的任务自动化评估上。

指标：基于 UI 的任务执行指标包括完成率 [[4](https://arxiv.org/html/2401.05459v2#bib.bib4)， [97](https://arxiv.org/html/2401.05459v2#bib.bib97)， [94](https://arxiv.org/html/2401.05459v2#bib.bib94)] 和手动设计的奖励 [[126](https://arxiv.org/html/2401.05459v2#bib.bib126)， [127](https://arxiv.org/html/2401.05459v2#bib.bib127)]。完成率是指模型预测的所有操作与真实情况完全一致的概率。然而，由于完成任务的方法可能不同，且真实情况通常仅代表这些方法之一，因此这种方法评估的准确性并不完全正确 [[94](https://arxiv.org/html/2401.05459v2#bib.bib94)]。基于关键步骤手动设计奖励可能更精确 [[127](https://arxiv.org/html/2401.05459v2#bib.bib127)]，但由于复杂的标注过程，它们的扩展性较差。

表 6：UI 任务自动化基准测试。结构化 UI 形式分别为安卓的视图层级（VH）和网页的文档对象模型（DOM）。对于 Windows，元数据源自操作系统中的文本元数据。

| 基准测试 | 名称 | 平台 | 人工注释 | UI 格式 | 高级任务 | 探索记忆 |
| --- | --- | --- | --- | --- | --- | --- |
| 数据集 | PhraseNode [[128](https://arxiv.org/html/2401.05459v2#bib.bib128)] | 网页 | 51,663 | 文档对象模型（DOM），屏幕 | ✗ | ✗ |
| UIBert [[35](https://arxiv.org/html/2401.05459v2#bib.bib35)] | 网页 | 16,660 | 文档对象模型（DOM），屏幕 | ✗ | ✗ |
| RicoSCA [[4](https://arxiv.org/html/2401.05459v2#bib.bib4)] | 安卓 | 不适用 | 视图层级（VH），屏幕 | ✗ | ✗ |
| PixelHelp [[4](https://arxiv.org/html/2401.05459v2#bib.bib4)] | 安卓 | 187 | 视图层级（VH），屏幕 | ✓ | ✗ |
| MoTiF [[129](https://arxiv.org/html/2401.05459v2#bib.bib129)] | 安卓 | 6,100 | 视图层级（VH），屏幕 | ✓ | ✗ |
| META-GUI [[97](https://arxiv.org/html/2401.05459v2#bib.bib97)] | 安卓 | 4,684 | 视图层级（VH），屏幕 | ✓ | ✗ |
| UGIF [[130](https://arxiv.org/html/2401.05459v2#bib.bib130)] | 安卓 | 523 | 视图层级（VH），屏幕 | ✓ | ✗ |
| Mind2Web [[93](https://arxiv.org/html/2401.05459v2#bib.bib93)] | 网页 | 2,350 | 文档对象模型（DOM），屏幕 | ✓ | ✗ |
| AITW [[131](https://arxiv.org/html/2401.05459v2#bib.bib131)] | 安卓+网页 | 715,142 | 屏幕 | ✓ | ✗ |
| DroidTask [[94](https://arxiv.org/html/2401.05459v2#bib.bib94)] | 安卓 | 158 | 视图层级（VH），屏幕 | ✓ | ✓ |
|  | OmniACT [[132](https://arxiv.org/html/2401.05459v2#bib.bib132)] | 桌面+网页 | 9,802 | 视图层级（VH），屏幕 | ✓ | ✗ |
|  | AutoWebBench [[133](https://arxiv.org/html/2401.05459v2#bib.bib133)] | 网页 | 10,000 | 文档对象模型（DOM），屏幕 | ✓ | ✗ |
|  | VisualWebBench [[134](https://arxiv.org/html/2401.05459v2#bib.bib134)] | Web | 1,500 | DOM, Screen | ✓ | ✗ |
|  | ScreenAgent [[135](https://arxiv.org/html/2401.05459v2#bib.bib135)] | Desktop | 273 | Screen | ✓ | ✗ |
| 平台 | MninWoB++ [[39](https://arxiv.org/html/2401.05459v2#bib.bib39), [6](https://arxiv.org/html/2401.05459v2#bib.bib6)] | Web | 17,971 | DOM, Screen | ✗ | ✓ |
| WebShop [[136](https://arxiv.org/html/2401.05459v2#bib.bib136)] | Web | 12,087 | DOM, Screen | ✓ | ✓ |
| WebArena [[137](https://arxiv.org/html/2401.05459v2#bib.bib137)] | Web | 812 | DOM, Screen | ✓ | ✓ |
| AndroidEnv [[126](https://arxiv.org/html/2401.05459v2#bib.bib126)] | Android | N/A | Screen | ✓ | ✓ |
| MobileEnv [[127](https://arxiv.org/html/2401.05459v2#bib.bib127)] | Android | N/A | VH, Screen | ✓ | ✓ |
| AssistGUI [[107](https://arxiv.org/html/2401.05459v2#bib.bib107)] | Windows | 100 | Metadata, Screen | ✓ | ✓ |
|  | OSWorld [[103](https://arxiv.org/html/2401.05459v2#bib.bib103)] | Desktop | 369 | VH, Screen | ✓ | ✓ |
|  | AgentStudio [[138](https://arxiv.org/html/2401.05459v2#bib.bib138)] | Desktop+Web | 227 | DOM, Screen | ✓ | ✓ |

基准测试：表格[6](https://arxiv.org/html/2401.05459v2#S4.T6 "Table 6 ‣ 4.1.3 Evaluation ‣ 4.1 Task Execution ‣ 4 Fundamental Capabilities ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security") 列出了基于 UI 的任务自动化的基准测试。一组基准测试是静态数据集，这些数据集通常包括一组人工标注的任务、结构化的 UI 数据（及截图）和完成任务的操作。其中一些任务是合成生成的 [[4](https://arxiv.org/html/2401.05459v2#bib.bib4), [126](https://arxiv.org/html/2401.05459v2#bib.bib126), [127](https://arxiv.org/html/2401.05459v2#bib.bib127)]。早期的研究主要集中在具有明确指令的低级任务上 [[128](https://arxiv.org/html/2401.05459v2#bib.bib128), [35](https://arxiv.org/html/2401.05459v2#bib.bib35)]，例如，点击“设置”按钮，然后点击“字体大小”。后来的研究引入了可以通过多个步骤完成的高级任务 [[4](https://arxiv.org/html/2401.05459v2#bib.bib4), [129](https://arxiv.org/html/2401.05459v2#bib.bib129), [97](https://arxiv.org/html/2401.05459v2#bib.bib97), [130](https://arxiv.org/html/2401.05459v2#bib.bib130), [93](https://arxiv.org/html/2401.05459v2#bib.bib93), [131](https://arxiv.org/html/2401.05459v2#bib.bib131), [132](https://arxiv.org/html/2401.05459v2#bib.bib132), [133](https://arxiv.org/html/2401.05459v2#bib.bib133), [134](https://arxiv.org/html/2401.05459v2#bib.bib134), [135](https://arxiv.org/html/2401.05459v2#bib.bib135)]，例如，删除我日历中的所有事件。另一组基准测试是使代理能够进行交互的平台。MiniWoB++ [[39](https://arxiv.org/html/2401.05459v2#bib.bib39), [6](https://arxiv.org/html/2401.05459v2#bib.bib6)]、WebShop [[136](https://arxiv.org/html/2401.05459v2#bib.bib136)] 和 WebArena [[137](https://arxiv.org/html/2401.05459v2#bib.bib137)] 提供了网络环境，代理可以通过点击、输入、关闭页面等方式在网络上进行导航和操作。AgentStudio [[138](https://arxiv.org/html/2401.05459v2#bib.bib138)] 提供了一个全面的平台，支持与多种现实世界计算机的交互。AndroidEnv [[126](https://arxiv.org/html/2401.05459v2#bib.bib126)] 和 MobileEnv [[127](https://arxiv.org/html/2401.05459v2#bib.bib127)] 提供了一个动态环境，代理可以与任何基于 Android 的应用程序及核心操作系统进行交互。这个框架允许在多样的 Android 平台上进行广泛的交互和任务解决。

<svg class="ltx_picture" height="189.78" id="S4.SS1.SSS3.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,189.78) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="175.94" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">备注。现有的方法已展示了 LLM 代理在任务推理和规划方面的显著能力。然而，实现实用的个人 LLM 代理仍面临几个重要问题。1. 如何准确高效地评估代理在现实世界场景中的表现。由于通常有多种方法可以完成相同的任务，因此使用静态数据集来测量任务执行的准确性是不准确的。同时，在模拟环境中动态测试任务可能效率低下且难以重现。2. 如何稳健地判断任务是否已完成。LLM 在任务执行过程中常常会出现幻觉，这使得确定当前任务是否已完成变得困难。3. 关于 UI 代理，如何最好地表示软件 UI？基于视觉的表示（例如截图）是一般可用的，而基于文本的表示通常更加轻量级，更易于 LLM 代理操作。</foreignobject></g></g></svg>

### 4.2 上下文感知

上下文感知指的是代理感知用户或环境状态的过程，以便提供更定制化的服务。在这项工作中，我们采用了广义的上下文感知定义，将通用的信息收集过程视为一种感知方式。基于硬件的感知符合传统的感知概念，主要涉及通过各种传感器、可穿戴设备、边缘设备和其他数据源进行数据采集。另一方面，基于软件的感知强调多样的数据采集方式。例如，分析用户的打字习惯和常用短语构成了一种基于软件的感知。

在个人 LLM 代理中，上下文感知能力有多种用途。1\. 启用感知任务：一些任务本质上要求代理进行感知。例如，当用户要求代理在睡眠期间检测打鼾时，代理必须具备主动获取、处理和分析音频数据的能力。2\. 补充上下文信息：感知的信息可以促进模糊或复杂任务的执行。例如，当用户想听音乐时，了解用户当前的活动有助于推荐合适的音乐。3\. 触发上下文感知服务：感知能力也是提供主动服务的基础。例如，代理可能会在检测到危险驾驶行为时提醒用户保持专注。4\. 增强代理记忆：通过感知获得的一些信息可以成为代理记忆的一部分，供代理进一步定制和自我进化使用。

我们从两个角度介绍上下文感知技术，包括感知源和感知目标。

#### 4.2.1 感知源

硬件传感器。现代个人设备配备了各种内置硬件传感器，包括加速度计、陀螺仪、磁场传感器、光传感器、温度计[[139](https://arxiv.org/html/2401.05459v2#bib.bib139)]、麦克风[[140](https://arxiv.org/html/2401.05459v2#bib.bib140)]、GPS 模块、摄像头[[141](https://arxiv.org/html/2401.05459v2#bib.bib141)]等。其他一些模块，如蓝牙和 Wi-Fi[[142](https://arxiv.org/html/2401.05459v2#bib.bib142)]，也可以用于感知目的。随着可穿戴设备和物联网设备如智能手表、蓝牙耳机[[143](https://arxiv.org/html/2401.05459v2#bib.bib143)]和智能家居设备[[144](https://arxiv.org/html/2401.05459v2#bib.bib144)]的普及，感知范围和感知方式大大扩展。

最近，关于 LLMs 与原始传感器数据深度融合的研究迅速增加。例如，一些研究直接将原始 IMU 数据嵌入 LLM 的提示中，实现了人体活动识别（HAR）[[145](https://arxiv.org/html/2401.05459v2#bib.bib145)]或轨迹预测[[146](https://arxiv.org/html/2401.05459v2#bib.bib146)]。张等[[147](https://arxiv.org/html/2401.05459v2#bib.bib147)]为 LLM 提供了 3D 场景的鸟瞰图，并允许其迭代选择视角以理解 3D 点云场景。此外，郑等[[148](https://arxiv.org/html/2401.05459v2#bib.bib148)]使用可训练的双通道音频前端和微调的 LLM，使 LLM 能够理解空间声音。类似的前端和微调方法在各种领域，如 LiDAR[[149](https://arxiv.org/html/2401.05459v2#bib.bib149)]和自动驾驶[[150](https://arxiv.org/html/2401.05459v2#bib.bib150), [151](https://arxiv.org/html/2401.05459v2#bib.bib151)]中也很常见。

软件传感器。与从真实传感器设备获取数据的硬件感知不同，软件感知侧重于从现有数据中获取信息，如应用使用[[152](https://arxiv.org/html/2401.05459v2#bib.bib152)]、通话记录[[153](https://arxiv.org/html/2401.05459v2#bib.bib153)]、打字习惯[[154](https://arxiv.org/html/2401.05459v2#bib.bib154)]、视频游戏[[155](https://arxiv.org/html/2401.05459v2#bib.bib155)]等。软件感知的范围极其广泛。例如，在自然语言处理或音频领域，存在大量基于文本或语音的感知研究。此外，像电子商务或短视频平台这样的推荐系统，过程通常涉及首先感知某些用户信息，然后推荐特定的产品或内容。这些传感器让代理更好地理解用户，从而提供更智能和个性化的服务。

多传感器组合。多传感器协作感知作为一种有效的方法，突显了增强感知能力的优势。以前的努力展示了基于触摸屏和惯性传感器对用户情感、压力水平和情绪状态的评估[[156](https://arxiv.org/html/2401.05459v2#bib.bib156)]，通过屏幕捕捉和传感器数据识别花费的时间[[157](https://arxiv.org/html/2401.05459v2#bib.bib157)]，通过耳机麦克风检测呼吸[[158](https://arxiv.org/html/2401.05459v2#bib.bib158)]，以及通过传感器和音频进行细致的运动检测[[159](https://arxiv.org/html/2401.05459v2#bib.bib159)]。

多传感器协作的重要性延伸至智能可穿戴设备和智能家居的普及。例如，利用从个人设备[[160](https://arxiv.org/html/2401.05459v2#bib.bib160)]（智能手表、笔记本电脑和智能手机）收集的数据自动识别用户何时工作或休息，或者通过耳机和智能手机麦克风的组合进行动作检测[[143](https://arxiv.org/html/2401.05459v2#bib.bib143)]。此外，还涉及家用电器融合的技术，例如基于现有有线设备的用户动作感知[[161](https://arxiv.org/html/2401.05459v2#bib.bib161)]、智能家居环境中的运动识别[[144](https://arxiv.org/html/2401.05459v2#bib.bib144)]、基于 Wi-Fi 的运动检测[[162](https://arxiv.org/html/2401.05459v2#bib.bib162)]、多人检测[[142](https://arxiv.org/html/2401.05459v2#bib.bib142)]和睡眠监测[[163](https://arxiv.org/html/2401.05459v2#bib.bib163)]。

有三种不同的方法可以使大型语言模型（LLM）理解和利用传感器数据。

+   •

    选项 1：将传感器数据作为提示。这种方法直接将传感器数据作为文本提示输入 LLM。此方法可以应用于各种传感源，如 IMU[[146](https://arxiv.org/html/2401.05459v2#bib.bib146)]和蓝牙[[164](https://arxiv.org/html/2401.05459v2#bib.bib164)]。原始传感器数据与提示之间的映射可以通过规则创建，例如将物体表面的触觉感受映射为“软”或“硬”[[165](https://arxiv.org/html/2401.05459v2#bib.bib165)]。这种方法简单而有效，许多现有研究已证明了这一点。然而，它也有重要的限制，例如处理大量原始数据的显著计算成本和 LLM 在纯文本中理解复杂传感器数据的能力有限。

+   •

    选项 2：传感器数据编码 + 微调。这种方法通过数据编码器使 LLM 理解传感器数据。编码器利用学习到的神经网络从原始传感器数据生成令牌嵌入，并将这些嵌入通常通过微调集成到 LLM 中。这种方法在处理复杂传感器数据（如 LiDAR[[149](https://arxiv.org/html/2401.05459v2#bib.bib149)]和双通道音频[[148](https://arxiv.org/html/2401.05459v2#bib.bib148)]）时产生了显著的结果。此方法使 LLM 能够高效地理解传感器模态，广泛用于构建像自动驾驶[[151](https://arxiv.org/html/2401.05459v2#bib.bib151), [150](https://arxiv.org/html/2401.05459v2#bib.bib150)]这样的复杂端到端系统。其缺点在于训练难度较高。

+   •

    选项 3：将传感器数据重定向到特定领域模型。这种方法不会直接用 LLM 处理传感器数据，而是利用 LLM 调用其他专门的小模型来处理原始传感器数据。例如，Darvish 等人[[166](https://arxiv.org/html/2401.05459v2#bib.bib166)]利用物体检测或姿态估计等技术来帮助化学实验机器人改善感知和理解，额外的信息被添加到原始数据流中，并转化为 LLM 能够理解的形式。

多传感器和多设备场景需要在数据源选择、数据融合和数据分析方法上进行复杂的考虑。现有的方法包括用于生成多传感器策略的人类行为理解的 LLM 驱动策略[[167](https://arxiv.org/html/2401.05459v2#bib.bib167)]、与情感无关的多传感器数据多任务学习框架[[168](https://arxiv.org/html/2401.05459v2#bib.bib168)]、传感数据的跨模态融合[[169](https://arxiv.org/html/2401.05459v2#bib.bib169)]、专注于多传感器融合的可穿戴设备运动识别[[170](https://arxiv.org/html/2401.05459v2#bib.bib170)]，以及在数据缺失条件下传感数据中的预测焦虑[[171](https://arxiv.org/html/2401.05459v2#bib.bib171)]。此外，还有研究分析了数据特征在跌倒检测中的重要性[[172](https://arxiv.org/html/2401.05459v2#bib.bib172)]。

随着传感技术的发展，多传感器和多设备协同感知已成为感知复杂场景的常用方法。有效整合多样的数据源以最大化准确性，并确定从大量数据源中消除不太重要数据的方法以节省资源是重要的研究领域。

#### 4.2.2 感知目标

情境感知的目标可以分为环境感知和用户感知。环境感知包括位置、场合、宗教和文化背景、国家和社会背景等因素。与此同时，用户感知涵盖了用户活动、状态、个人信息、个性特征、情感、目标、身体状况及其他相关方面。

环境感知。我们进一步将环境感知分为两个维度：场景感知和场合感知。场景感知主要涉及更具可触摸性的环境因素，如位置和场所。场合感知则深入到更深层次的环境信息，包括宗教和文化背景、国家差异以及社会关系。

+   •

    场景感知通常很容易察觉，但具有重要意义，这会导致行为和重点的变化。例如，在图书馆检测到用户时，代理应将电话调整为静音模式，而在酒吧则可能需要增加音量并激活振动。类似地，对于重点，当用户在会议室时，代理应更多地关注与会议内容记录和工作组织相关的任务，而在健身房时，重点应转向健身计划和心率分析。之前的场景感知工作采用了各种技术[[173](https://arxiv.org/html/2401.05459v2#bib.bib173)]，如基于位置的方法[[174](https://arxiv.org/html/2401.05459v2#bib.bib174)]，音频或视频分析[[175](https://arxiv.org/html/2401.05459v2#bib.bib175), [176](https://arxiv.org/html/2401.05459v2#bib.bib176)]，以及通过分析智能手机麦克风的气流来评估通风的传感器能力[[140](https://arxiv.org/html/2401.05459v2#bib.bib140)]，或通过分析将智能手机相机放置在表面附近拍摄的宏观照片来实现场景识别[[141](https://arxiv.org/html/2401.05459v2#bib.bib141)]。张等[[147](https://arxiv.org/html/2401.05459v2#bib.bib147)]让 LLM 通过 LLM 引导的多视角选择来理解 3D 场景。

+   •

    场合感知在感知中更为难以捉摸，其影响相对隐秘。早期研究已经发现不同国家[[177](https://arxiv.org/html/2401.05459v2#bib.bib177)]和地区[[178](https://arxiv.org/html/2401.05459v2#bib.bib178)]在行为和情感识别任务上存在差异。当前用户和设置所暗示的国家、民族、宗教和文化背景是至关重要的。感知当前环境中的他人和物体同样重要。例如，之前的工作基于传感器数据检测社交场景，分析了社交焦虑个体在不同社交环境中的行为[[179](https://arxiv.org/html/2401.05459v2#bib.bib179)]。其他研究深入分析了使用多种传感器的饮酒相关社交场景，甚至预测了饮酒群体的规模和性别组成[[180](https://arxiv.org/html/2401.05459v2#bib.bib180)]。此外，研究还探索了传感器数据、饮食习惯和社交环境之间的关系，揭示了暴饮暴食与社交环境之间的强关联，使其具有可预测性[[181](https://arxiv.org/html/2401.05459v2#bib.bib181)]。梁等[[182](https://arxiv.org/html/2401.05459v2#bib.bib182)]通过分析公共事件使用 LLM 预测行人流量。

环境感知是个人智能体至关重要的上下文信息。不同的环境导致不同的行为和关注点，超越了单纯的位置，还包括社交场合、文化背景以及更深层次的概念元素，涵盖了环境中的个体及其关系、互动，并预测对环境和用户的影响。这些考虑直接影响个人智能体所表现出的智能水平。

用户感知。用户意识是个人 LLM 智能体的主要特征之一。对用户的更深入理解可以更好地体现个人 LLM 智能体的价值和意义。我们将用户感知分为两个时间维度，包括短期和长期。短期感知表现出更高的时间变异性和随机性。另一方面，长期感知需要长期维护和修正，使其相对更加稳定和可靠。

+   •

    短期用户感知包括多个方面，如用户的日常活动 [[183](https://arxiv.org/html/2401.05459v2#bib.bib183)]，或如刷牙效果这样的专业活动 [[184](https://arxiv.org/html/2401.05459v2#bib.bib184)]，Ji 等 [[145](https://arxiv.org/html/2401.05459v2#bib.bib145)] 发现，即使直接将 IMU 数据输入 LLM 也能执行人类活动识别（HAR）任务。用户状态如工作或休息 [[160](https://arxiv.org/html/2401.05459v2#bib.bib160), [157](https://arxiv.org/html/2401.05459v2#bib.bib157)]，用户健康状况 [[185](https://arxiv.org/html/2401.05459v2#bib.bib185), [139](https://arxiv.org/html/2401.05459v2#bib.bib139), [186](https://arxiv.org/html/2401.05459v2#bib.bib186)]，以及用户情绪 [[187](https://arxiv.org/html/2401.05459v2#bib.bib187), [156](https://arxiv.org/html/2401.05459v2#bib.bib156)] 和压力水平 [[188](https://arxiv.org/html/2401.05459v2#bib.bib188)]。最近，许多研究尝试探索 LLMs 在健康监测领域的应用 [[189](https://arxiv.org/html/2401.05459v2#bib.bib189), [190](https://arxiv.org/html/2401.05459v2#bib.bib190), [191](https://arxiv.org/html/2401.05459v2#bib.bib191)]。短期感知通常涉及快速变化的浅层状态信息。有效捕捉这些信息可以显著增强个人 LLM 智能体的上下文感知能力。

+   •

    长期用户感知主要集中在对用户档案和个性的分析。已经提出了多种方法来理解用户的工作、学习和日常生活。例如，一项研究利用新智能手机的传感器数据来检测新生的长期心理状态[[192](https://arxiv.org/html/2401.05459v2#bib.bib192)]。另一项研究展示了基于感知数据预测学习表现和社交活动的能力[[193](https://arxiv.org/html/2401.05459v2#bib.bib193)]。Gao 等人[[194](https://arxiv.org/html/2401.05459v2#bib.bib194)]深入探讨了基于身体活动强度预测个性的技术。还有研究检查了传感器数据与用户职业发展的关系[[195](https://arxiv.org/html/2401.05459v2#bib.bib195)]，以及预测用户生活满意度的研究[[196](https://arxiv.org/html/2401.05459v2#bib.bib196)]。此外，用户的特定状态也成为研究重点，包括对心理疾病的感知研究[[197](https://arxiv.org/html/2401.05459v2#bib.bib197), [198](https://arxiv.org/html/2401.05459v2#bib.bib198)]，如预测和分析精神分裂症[[199](https://arxiv.org/html/2401.05459v2#bib.bib199)]、抑郁症[[190](https://arxiv.org/html/2401.05459v2#bib.bib190)]，以及检测吸烟等习惯[[200](https://arxiv.org/html/2401.05459v2#bib.bib200)]。Lifelo 等人[[191](https://arxiv.org/html/2401.05459v2#bib.bib191)]利用 LLM 进行了一种极为罕见的非洲语言的心理障碍分析。此外，Ouyang 和 Srivastava[[201](https://arxiv.org/html/2401.05459v2#bib.bib201)]尝试从简单数据中提取更高层次的感知信息。长期感知涉及深层次和抽象的信息，包含用户行为背后的深刻逻辑。这些信息通常更加微妙，使得感知和维护具有挑战性。然而，它们构成了先进个人代理的重要方面。

在用户感知方面，也有一些基于 LLM 的举措，例如将 LLM 用于推荐任务[[202](https://arxiv.org/html/2401.05459v2#bib.bib202), [203](https://arxiv.org/html/2401.05459v2#bib.bib203)]，使用 LLM 进行情感分析[[204](https://arxiv.org/html/2401.05459v2#bib.bib204)]，以及开发具备查询和感知能力的个人医生[[205](https://arxiv.org/html/2401.05459v2#bib.bib205)]。

<svg class="ltx_picture" height="127.15" id="S4.SS2.SSS2.p8.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,127.15) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="113.31" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">备注。现有的方法通常局限于特定的传感器、单个应用程序或特定领域。在个人语言模型代理中，一个可能的机会是将所有与环境和用户相关的感知结果统一来自不同的来源。然而，实现这一目标涉及几个重要的研究挑战。1. 感知信息的统一格式或本体是什么？代理应能够将各种感知数据转换为这种格式，并方便地用于各种下游任务。2. 鉴于感知范围广泛，代理如何决定何时以及感知什么，以提供上下文感知的服务且最小化开销？</foreignobject></g></g></svg>

### 4.3 记忆

记忆指的是在个人语言模型代理中记录、管理和利用历史数据的能力。这种能力使得代理能够跟踪用户，学习过去的经验，提取有用的知识，并将这些获得的知识应用于进一步提升服务质量。相关工作主要针对两个问题，即如何获取记忆以及如何利用记忆。

#### 4.3.1 获取记忆

代理的记忆可以有多种格式。例如，基本的用户档案（如出生日期、地址、个性、偏好）通常以键值对的形式存储，方便通过键进行检索。历史记录通常表示为按时间戳索引的序列，记录用户服务访问、活动、系统事件等信息。用户的文档、照片、视频等则作为文件存储，这些文件通常由其他应用程序生成。获取记忆主要有两种方式：直接记录原始数据或间接从原始数据中推断知识。

记录。获取记忆的最直接方式是通过记录，例如记录用户输入、系统事件和感知到的环境。记录的数据通常相对简单。*生活记录* 是一个常被讨论的话题，专注于跟踪和记录通过用户活动和行为生成的用户数据，有助于全面了解个人的生活方式和偏好 [[206](https://arxiv.org/html/2401.05459v2#bib.bib206), [207](https://arxiv.org/html/2401.05459v2#bib.bib207)]。在特定时刻使用摄像头记录的数据可以提供对日常活动的更深刻概述 [[208](https://arxiv.org/html/2401.05459v2#bib.bib208)]。此外，长时间记录的数据可以提供行为模式的宝贵见解，这将支持智能代理的个性化 [[209](https://arxiv.org/html/2401.05459v2#bib.bib209)]。

推断。个人 LLM 代理获取记忆的另一种方式是从原始数据中提取知识。随着机器学习和数据分析的进步，推断用户行为、模式和互动以获得其心理、偏好及其他高层次信息变得可能。例如，用户个性可以从文本中提取 [[210](https://arxiv.org/html/2401.05459v2#bib.bib210), [211](https://arxiv.org/html/2401.05459v2#bib.bib211)]，情感可以从图像和文本数据中读取 [[212](https://arxiv.org/html/2401.05459v2#bib.bib212), [213](https://arxiv.org/html/2401.05459v2#bib.bib213)]，偏好可以从历史互动信息中建模 [[214](https://arxiv.org/html/2401.05459v2#bib.bib214)]，知识图谱可以从智能手机推送通知中提取 [[215](https://arxiv.org/html/2401.05459v2#bib.bib215)]。这些提取的高层次信息也将作为代理的记忆存储并在服务中利用。

#### 4.3.2 管理和利用记忆

在获得记忆之后，下一个问题是如何管理和利用这些记忆以在个人 LLM 代理中提供更好的服务。根据利用记忆的目的，我们将相关技术分为以下三部分，包括原始数据管理、记忆增强的 LLM 推理和代理自我进化。

原始数据管理和处理。个人 LLM 代理的基本能力之一是访问和处理原始内存数据（例如，选择、过滤、转换为其他格式等），以便促进其他高级功能。这一工作主要集中在实现更自然和人类可理解的数据访问、操作和修改上。由于 LLM 的输入输出和推理过程基于自然语言，这些接口更容易与大型模型的其他能力集成。在这一研究领域，许多努力探讨了如何使用机器学习模型或基于模板的方法将用户数据请求映射到数据库 SQL 语句 [[216](https://arxiv.org/html/2401.05459v2#bib.bib216), [217](https://arxiv.org/html/2401.05459v2#bib.bib217)]。还有一些框架级的工作研究如何统一和简化数据接口。例如，PrivacyStreams [[218](https://arxiv.org/html/2401.05459v2#bib.bib218)] 将所有个人数据访问和处理接口统一为基于流的框架，这更有利于大型语言模型理解和管理。

记忆增强的 LLM 推理。为了使个人 LLM 代理能够基于与用户相关的记忆提供定制化服务，通常希望在 LLM 推理过程中利用记忆数据。最近的 LLM 代理研究探讨了利用记忆来增强决策和推理 [[85](https://arxiv.org/html/2401.05459v2#bib.bib85), [219](https://arxiv.org/html/2401.05459v2#bib.bib219), [220](https://arxiv.org/html/2401.05459v2#bib.bib220), [221](https://arxiv.org/html/2401.05459v2#bib.bib221), [222](https://arxiv.org/html/2401.05459v2#bib.bib222)]，这为个人 LLM 代理通过记忆向用户提供个性化服务的解决方案提供了灵感。技术可以根据记忆的类型有所不同。

+   •

    短期记忆以符号变量的形式保存和保留相关信息，确保在当前决策周期内的可访问性和适用性。这包括感知输入、主动知识（通过推理生成或从记忆数据中检索到的）以及从前一个决策周期转移过来的其他核心信息（例如，代理的主动目标）。CoT [[84](https://arxiv.org/html/2401.05459v2#bib.bib84)]、Scratchpads [[223](https://arxiv.org/html/2401.05459v2#bib.bib223)] 鼓励 LLM 生成中间推理，利用 LLM 自身的上下文作为工作记忆的一种形式。CoALA [[224](https://arxiv.org/html/2401.05459v2#bib.bib224)] 提议工作记忆应在长期记忆（LLM）调用期间作为一个持久的数据结构。每次调用从工作记忆的子集（例如，提示模板和相关变量）生成输入，输出随后被解析成其他变量（例如，动作名称和参数），这些变量被存储回工作记忆中并用于执行相应的动作。此外，短期记忆能够与长期记忆和其他数据接口进行交互，作为连接语言代理不同组件的中心枢纽 [[225](https://arxiv.org/html/2401.05459v2#bib.bib225), [226](https://arxiv.org/html/2401.05459v2#bib.bib226)]。

+   •

    长期记忆存储早期决策周期的经验。这可以包括历史事件流 [[219](https://arxiv.org/html/2401.05459v2#bib.bib219)]、前几期的游戏轨迹 [[227](https://arxiv.org/html/2401.05459v2#bib.bib227), [228](https://arxiv.org/html/2401.05459v2#bib.bib228)]、用户与代理之间的交互信息或代理经验的其他表现形式。在决策周期的规划阶段，这些经历可以被检索到工作记忆中以支持推理。代理还可以将从工作记忆中获得的新经验写入到情节记忆中，作为一种学习方式。其次，长期记忆存储代理关于世界和自身的知识。传统方法利用检索来进行推理或决策，初始化来自外部数据库的记忆以支持知识（例如，NLP 中的检索增强方法 [[229](https://arxiv.org/html/2401.05459v2#bib.bib229), [230](https://arxiv.org/html/2401.05459v2#bib.bib230)]、RL 中的“阅读以学习”方法 [[231](https://arxiv.org/html/2401.05459v2#bib.bib231), [232](https://arxiv.org/html/2401.05459v2#bib.bib232)]）。代理还可以将从 LLM 推理和用户那里获得的新知识写入长期记忆，作为一种学习方式，从经验中逐步建立世界知识。

代理自我进化。为了更好地适应用户，个人 LLM 代理可能也需要基于记忆数据动态更新自己。我们将此称为“自我进化”。智能代理的基础功能主要依赖于 LLM。因此，智能代理自我进化的关键在于如何利用 LLM 发现和探索新技能，以及 LLM 自身的持续更新。

+   •

    学习技能。目前，许多努力正在进行中，以使基于 LLM 的代理能够进行持续的技能学习和获取[[233](https://arxiv.org/html/2401.05459v2#bib.bib233), [234](https://arxiv.org/html/2401.05459v2#bib.bib234)]。这些方法受到程序的通用性和可解释性的启发[[235](https://arxiv.org/html/2401.05459v2#bib.bib235)]，将技能视为可执行代码，并通过策略性使用提示来优化技能获取，利用 LLM 的上下文学习能力。它们还管理技能库，将新技能集成作为 API，使智能代理能够不断学习和重用这些技能于后续任务。以往的工作已证明，现代 LLM 能够捕捉关于有意义技能链的相关信息[[51](https://arxiv.org/html/2401.05459v2#bib.bib51), [49](https://arxiv.org/html/2401.05459v2#bib.bib49)]。因此，智能代理有能力通过战略性地链接基础技能集内的技能来获得新技能[[236](https://arxiv.org/html/2401.05459v2#bib.bib236)]。在这种技能链的过程中，智能代理有目的地选择后续有意义的技能，利用 LLM 中嵌入的先验知识和执行反馈，使语言模型调整其选择。这种有针对性的方法使代理能够高效地掌握复杂技能。

+   •

    微调 LLM。为了实现智能体的自我进化，还需要对 LLM 进行持续的微调。原因有以下几点：1\. 当前的 LLM 并未专门针对智能体特定的使用场景进行设计，例如生成行动或自我评估，其中有限的学习支持由少量提示提供。2\. 由于移动设备上的性能限制，智能体的 LLM 组件的能力受到限制。这种限制使得模型很难通过先验知识和上下文学习能力来获得新技能。3\. 在智能体的操作阶段，最新语料[[237](https://arxiv.org/html/2401.05459v2#bib.bib237)]、新知识[[238](https://arxiv.org/html/2401.05459v2#bib.bib238)]和工具[[239](https://arxiv.org/html/2401.05459v2#bib.bib239)]等材料的不断出现可能频繁地改变任务模式。这就需要 LLM 的持续适应。在这种情况下，微调模型变得必要，以提升其处理新任务和生成适当行动的能力。研究表明，对于特定的推理[[240](https://arxiv.org/html/2401.05459v2#bib.bib240), [241](https://arxiv.org/html/2401.05459v2#bib.bib241)]和行动[[225](https://arxiv.org/html/2401.05459v2#bib.bib225)]需求，微调后的较小 LLM 可能优于提示的大型 LLM，同时具有更低的推理时间和费用。参数高效微调（PEFT）[[242](https://arxiv.org/html/2401.05459v2#bib.bib242)]提供了一种高效微调 LLM 的有希望的方法。它只需微调少量外部参数[[243](https://arxiv.org/html/2401.05459v2#bib.bib243)]，使其适用于边缘设备，并能有效缓解灾难性遗忘问题[[244](https://arxiv.org/html/2401.05459v2#bib.bib244)]。也有一些初步尝试进行 LLM 智能体微调的研究[[245](https://arxiv.org/html/2401.05459v2#bib.bib245)]，涵盖多个任务和提示方法的轨迹，为未来开发更具能力和实用性的个人 LLM 智能体提供了启示。

<svg class="ltx_picture" height="145.29" id="S4.SS3.SSS2.p7.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,145.29) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="131.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">备注。生成和利用有关用户的记忆的能力是个人 LLM 代理个性化的基础。我们突出以下三个围绕个人 LLM 代理记忆机制的开放问题。1. 代理的记忆可能会很庞大、多样且动态。代理如何组织和检索记忆是最有效和高效的方式？2. 人类有遗忘的能力。由于记忆中不适当的数据可能会对代理的服务质量和效率产生负面影响，代理如何确定要记住哪些信息？3. 代理如何利用记忆自我演变？具体而言，使用什么数据，何时演变，以及如何（微调还是其他）？个性化模型如何接受基础模型的更新？</foreignobject></g></g></svg>

## 5 效率

图 9：个人 LLM 代理的低级过程与高级能力之间的映射关系。

由于许多个人设备的硬件资源和电力供应有限，因此在部署阶段提高个人 LLM 代理的效率非常重要。我们在第 [4](https://arxiv.org/html/2401.05459v2#S4 "4 Fundamental Capabilities ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security") 节中讨论了个人 LLM 代理的基本能力，包括任务执行、情境感知和记忆。这些能力如图 [9](https://arxiv.org/html/2401.05459v2#S5.F9 "Figure 9 ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security") 所示，依托于更基础的过程，主要包括 LLM 代理的推理、自定义和记忆检索。每个过程都需要仔细优化效率，如下所述。

LLM 的推理是代理各种能力的基础。例如，代理可以先借助 LLM 将复杂任务分解为几个步骤，然后通过 LLM 推理或调用个人工具（例如安排会议）来解决每个步骤。情境感知或生成记忆也可能依赖于 LLM 的推理能力。虽然使用工具或传感器的成本通常因多样性而难以估算，但 LLM 推理是一种常见的程序，需要大量的计算和内存资源。因此，LLM 推理成为个人 LLM 代理的性能瓶颈，需要仔细优化其效率。

定制是个人 LLM 代理的另一个重要过程，以适应不同用户的需求。当代理被安装到不同用户或用于不同场景时，需要进行定制。个人 LLM 代理的自我演进也是一种定制过程。为了提供定制服务，代理可以通过不同的上下文标记喂入 LLM 或用特定领域的数据调整 LLM。由于定制需求频繁，这些过程可能对系统的计算和存储资源施加相当大的压力。

内存操作是另一个成本高昂的过程。为了提供更好的服务，代理可能需要访问更长的上下文或外部记忆，如环境感知、用户档案、互动历史、数据文件等。因此，这引发了两个考虑因素。第一个涉及到需要 LLM 处理更长的输入。第二个问题则集中在从外部记忆库中管理和获取信息。

{森林}

forked edges, for tree= grow=east, reversed=true, anchor=base west, parent anchor=east, child anchor=west, base=center, font=, rectangle, draw=hidden-draw, rounded corners, align=left, text centered, minimum width=4em, edge+=darkgray, line width=1pt, s sep=3pt, inner xsep=2pt, inner ysep=3pt, line width=0.8pt, ver/.style=rotate=90, child anchor=north, parent anchor=south, anchor=center, , where level=1text width=10em,font=,, where level=2text width=15em,font=,, where level=3text width=15em,font=,, [效率, ver [高效

推理 (§[5.1](https://arxiv.org/html/2401.05459v2#S5.SS1 "5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查"))，填充=蓝色!10 [模型压缩 (§[5.1.1](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS1 "5.1.1 模型压缩 ‣ 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查"))，填充=蓝色!10 [量化，填充=蓝色!10 [仅权重量化: GPTQ [[246](https://arxiv.org/html/2401.05459v2#bib.bib246)]，AWQ [[247](https://arxiv.org/html/2401.05459v2#bib.bib247)]，LLM-QAT [[248](https://arxiv.org/html/2401.05459v2#bib.bib248)] 等，叶子，文本宽度=29em ] [共同量化: ZeroQuant [[249](https://arxiv.org/html/2401.05459v2#bib.bib249)]，SmoothQuant [[250](https://arxiv.org/html/2401.05459v2#bib.bib250)] 等，叶子，文本宽度=23em ] ] [修剪，填充=蓝色!10 [LLM-Pruner [[251](https://arxiv.org/html/2401.05459v2#bib.bib251)]，SparseGPT [[252](https://arxiv.org/html/2401.05459v2#bib.bib252)]，Wanda [[253](https://arxiv.org/html/2401.05459v2#bib.bib253)] 等，叶子，文本宽度=24em ] ] [知识蒸馏，填充=蓝色!10 [白盒: BabyLlama [[254](https://arxiv.org/html/2401.05459v2#bib.bib254)]，MiniLLM [[255](https://arxiv.org/html/2401.05459v2#bib.bib255)] 等，叶子，文本宽度=22em ] [黑盒: Hsieh 等 [[256](https://arxiv.org/html/2401.05459v2#bib.bib256)]，SCoTD [[257](https://arxiv.org/html/2401.05459v2#bib.bib257)] 等，叶子，文本宽度=21em ] ] [低秩分解，填充=蓝色!10 [ZeroQuant-V2 [[258](https://arxiv.org/html/2401.05459v2#bib.bib258)]，LoSparse [[259](https://arxiv.org/html/2401.05459v2#bib.bib259)] 等，叶子，文本宽度=18em ] ] ] [推理加速 (§[5.1.2](https://arxiv.org/html/2401.05459v2#S5

Anagnostidis 等人 [[263](https://arxiv.org/html/2401.05459v2#bib.bib263)]、Zhang 等人 [[264](https://arxiv.org/html/2401.05459v2#bib.bib264)]、Ge 等人 [[265](https://arxiv.org/html/2401.05459v2#bib.bib265)] 等，叶子，文本宽度=27em ] ] [内核优化，填充=蓝色!10 [ FlashAttention [[266](https://arxiv.org/html/2401.05459v2#bib.bib266)]、[267](https://arxiv.org/html/2401.05459v2#bib.bib267)]、FlashDecoding++ [[268](https://arxiv.org/html/2401.05459v2#bib.bib268)] 等，叶子，文本宽度=24em ] ] [推测解码，填充=蓝色!10 [ Chen 等人 [[269](https://arxiv.org/html/2401.05459v2#bib.bib269)]、Leviathan 等人 [[270](https://arxiv.org/html/2401.05459v2#bib.bib270)] 等，叶子，文本宽度=20em ] ] ] [内存减少 (§[5.1.3](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS3 "5.1.3 Memory Reduction ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security"))，填充=蓝色!10 [KV 量化，填充=蓝色!10 [ ZeroQuant [[249](https://arxiv.org/html/2401.05459v2#bib.bib249)]、SmoothQuant [[250](https://arxiv.org/html/2401.05459v2#bib.bib250)] 等，叶子，文本宽度=18em ] ] [KV 剪枝，填充=蓝色!10 [ Anagnostidis 等人 [[263](https://arxiv.org/html/2401.05459v2#bib.bib263)]、Zhang 等人 [[264](https://arxiv.org/html/2401.05459v2#bib.bib264)] 等，叶子，文本宽度=22em ] ] [卸载，填充=蓝色!10 [ FlexGen [[271](https://arxiv.org/html/2401.05459v2#bib.bib271)]、PowerInfer [[272](https://arxiv.org/html/2401.05459v2#bib.bib272)]、Alizadeh 等人 [[273](https://arxiv.org/html/2401.05459v2#bib.bib273)] 等，叶子，文本宽度=25em ] ] ] [能源优化 (§[5.1.4](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS4 "5.1.4 Energy Optimization ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security"))，填充=蓝色!10 [软件方法，填充=蓝色!10 [ 同上，叶子，文本宽度=6em ] ] [硬件方法，填充=蓝色!10 [ NPU [[274](https://arxiv.org/html/2401.05459v2#bib.bib274)]、TPU [[275](https://arxiv.org/html/2401.05459v2#bib.bib275)]、FPGA [[276](https://arxiv.org/html/2401.05459v2#bib.bib276)] 等，叶子，文本宽度=18em ] ] ] ] [高效

自定义（§[5.2](https://arxiv.org/html/2401.05459v2#S5.SS2 "5.2 高效自定义 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解和调查")），填充=蓝色！10 [微调效率（§[5.2.2](https://arxiv.org/html/2401.05459v2#S5.SS2.SSS2 "5.2.2 微调效率 ‣ 5.2 高效自定义 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解和调查")），填充=蓝色！10 [参数高效的微调，填充=蓝色！10 [Houlsby 等 [[277](https://arxiv.org/html/2401.05459v2#bib.bib277)]，LLM-Adapters [[278](https://arxiv.org/html/2401.05459v2#bib.bib278)]，LoRA [[279](https://arxiv.org/html/2401.05459v2#bib.bib279)]，等，叶子，文本宽度=26em]] [高效优化器设计，填充=蓝色！10 [LOMO [[280](https://arxiv.org/html/2401.05459v2#bib.bib280)]，Sophia [[281](https://arxiv.org/html/2401.05459v2#bib.bib281)]，等，叶子，文本宽度=14em]] [训练数据策划，填充=蓝色！10 [phi-1 [[282](https://arxiv.org/html/2401.05459v2#bib.bib282)]，phi-1.5 [[283](https://arxiv.org/html/2401.05459v2#bib.bib283)]，phi-2 [[284](https://arxiv.org/html/2401.05459v2#bib.bib284)]，等，叶子，文本宽度=18em]]]] [上下文加载效率（§[5.2.1](https://arxiv.org/html/2401.05459v2#S5.SS2.SSS1 "5.2.1 上下文加载效率 ‣ 5.2 高效自定义 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解和调查")），填充=蓝色！10 [加载加速，填充=蓝色！10 [CacheGen [[285](https://arxiv.org/html/2401.05459v2#bib.bib285)]，等，叶子，文本宽度=10em]]]] [高效内存

操作（§[5.3](https://arxiv.org/html/2401.05459v2#S5.SS3 "5.3 高效内存操作 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解和调查")），填充=蓝色！10 [搜索效率（§[5.3.1](https://arxiv.org/html/2401.05459v2#S5.SS3.SSS1 "5.3.1 搜索效率 ‣ 5.3 高效内存操作 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解和调查")），填充=蓝色！10 [索引，填充=蓝色！10 [典型：随机化划分 [[286](https://arxiv.org/html/2401.05459v2#bib.bib286)， [287](https://arxiv.org/html/2401.05459v2#bib.bib287)]，学习的

分区 [[288](https://arxiv.org/html/2401.05459v2#bib.bib288)], 可导航分区 [[289](https://arxiv.org/html/2401.05459v2#bib.bib289)], 等等，叶子节点，文本宽度=23em ] [ 硬件感知：DiskANN [[290](https://arxiv.org/html/2401.05459v2#bib.bib290)], CXL-ANNS [[291](https://arxiv.org/html/2401.05459v2#bib.bib291)], FANNS [[292](https://arxiv.org/html/2401.05459v2#bib.bib292)], 等等，叶子节点，文本宽度=31em ] ] [搜索，填充=blue!10 [ 搜索计划 [[293](https://arxiv.org/html/2401.05459v2#bib.bib293), [294](https://arxiv.org/html/2401.05459v2#bib.bib294), [295](https://arxiv.org/html/2401.05459v2#bib.bib295), [296](https://arxiv.org/html/2401.05459v2#bib.bib296)], 元数据过滤 [[295](https://arxiv.org/html/2401.05459v2#bib.bib295), [297](https://arxiv.org/html/2401.05459v2#bib.bib297)], 等等，叶子节点，文本宽度=29em ] [ 执行：GPU [[298](https://arxiv.org/html/2401.05459v2#bib.bib298), [296](https://arxiv.org/html/2401.05459v2#bib.bib296)], SIMD [[298](https://arxiv.org/html/2401.05459v2#bib.bib298), [296](https://arxiv.org/html/2401.05459v2#bib.bib296), [299](https://arxiv.org/html/2401.05459v2#bib.bib299)],

OPENMP [[298](https://arxiv.org/html/2401.05459v2#bib.bib298), [296](https://arxiv.org/html/2401.05459v2#bib.bib296)], 分布式 [[300](https://arxiv.org/html/2401.05459v2#bib.bib300), [293](https://arxiv.org/html/2401.05459v2#bib.bib293)], 等等，叶子节点，文本宽度=22em ] ] ] [工作流程效率 (§[5.3.2](https://arxiv.org/html/2401.05459v2#S5.SS3.SSS2 "5.3.2 工作流程优化 ‣ 5.3 高效内存操作 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解和调查")), 填充=blue!10 [流水线，填充=blue!10 [ RaLMSpec [[301](https://arxiv.org/html/2401.05459v2#bib.bib301)], PipeRAG [[302](https://arxiv.org/html/2401.05459v2#bib.bib302)], 等等，叶子节点，文本宽度=16em ] ] [缓存，填充=blue!10 [ RAGCache [[303](https://arxiv.org/html/2401.05459v2#bib.bib303)], GRITLM [[304](https://arxiv.org/html/2401.05459v2#bib.bib304)], 等等，叶子节点，文本宽度=16em ] ] ] ] ]

图 10：提高 LLM 代理效率的技术概述。叶子节点是我们引用的代表性工作的一部分。

我们将在接下来的子节中深入探讨每个组件的效率，如图[10](https://arxiv.org/html/2401.05459v2#S5.F10 "图 10 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解和调查")所示。

### 5.1 高效推理

由于个人 LLM 代理的运行时成本主要由 LLM 推理主导，因此提高推理效率对于提升代理的整体效率至关重要。虽然代理的整体推理成本可能会受到代理设计的显著影响，包括代理如何向 LLM 发送请求、使用什么提示等，但我们将仅关注模型和系统级的方法。原因是代理的设计可能根据实际应用而有所不同，并不会直接影响 LLM 推理本身的效率。

已提出许多模型和系统级的方法来提高大语言模型（LLM）推理的效率。虽然其中一些方法是针对整体性能和效率的（例如，模型压缩），但也有针对特定方面效率的技术，如模型大小、推理延迟、内存消耗、能耗等。我们将在本小节的后续部分分别讨论这些方面。

#### 5.1.1 模型压缩

模型压缩技术直接减少模型的大小和计算量，是提高 LLM 推理效率的通用优化方法，包括计算、内存、能量等。模型压缩技术进一步被分类为各种方法，包括量化、剪枝（稀疏性）、蒸馏和低秩分解。

量化是 LLM 最重要的压缩方法之一。它通过使用更少的位数来表示模型参数，从而减少模型大小，同时通过对量化内核的系统级支持减少计算量。量化方法可以进一步分为训练后量化（PTQ）和量化感知训练（QAT），取决于量化后是否需要额外的训练。与 QAT（例如，LLM-QAT [[248](https://arxiv.org/html/2401.05459v2#bib.bib248)]）需要相当多的额外训练工作不同，PTQ 在不同硬件约束下的设备端部署中更为可用和灵活。

最近的工作揭示了 LLM 量化的难点主要在于激活，其中异常值难以量化 [[305](https://arxiv.org/html/2401.05459v2#bib.bib305), [306](https://arxiv.org/html/2401.05459v2#bib.bib306)]。现有工作提出了各种方法来应对这一挑战。一种典型的工作线采用了仅权重量化（WOQ）范式，该范式仅对权重进行整数量化（例如，INT4 和 INT8），同时保留激活为浮点格式（例如，FP16 和 FP32）。WOQ 在压缩比和模型困惑度之间实现了权衡。WOQ 的一种直接方式是在当前移动部署框架中实现的分组均匀量化（例如，llama.cpp [[307](https://arxiv.org/html/2401.05459v2#bib.bib307)]和 MLC-LLM [[308](https://arxiv.org/html/2401.05459v2#bib.bib308)]）。最近的工作还提出了不同的量化算法以增强模型能力，如 GPTQ [[246](https://arxiv.org/html/2401.05459v2#bib.bib246)]和 AWQ [[247](https://arxiv.org/html/2401.05459v2#bib.bib247)]。

尽管有 WOQ 技术，另一种工作线量化了权重和激活。例如，ZeroQuant [[249](https://arxiv.org/html/2401.05459v2#bib.bib249)]对权重和激活进行 INT8 量化，使用分组量化对模型权重进行量化，对激活进行逐个标记量化。然而，由于异常值，激活（包括键值对（KV））通常比模型权重更难以量化。已经有大量工作来解决这一挑战。SmoothQuant [[250](https://arxiv.org/html/2401.05459v2#bib.bib250)]通过额外的缩放操作将激活的量化难度迁移到权重上，这些操作“平滑”激活中的异常值，从而在 W8A8 量化中实现了微不足道的精度下降。后续工作进一步尝试通过各种技术（包括通道重新排序（RPTQ [[309](https://arxiv.org/html/2401.05459v2#bib.bib309)]）、通道级移位和缩放（Outlier Suppression+ [[310](https://arxiv.org/html/2401.05459v2#bib.bib310)]）以及自适应通道重新组装（QLLM [[311](https://arxiv.org/html/2401.05459v2#bib.bib311)]））将可用的量化位宽降低到 4 位。值得注意的是，RPTQ 通过开发一个新的量化方案来解决 KV 存储问题，该方案在量化激活时专注于 KV 缓存，这是长上下文推理中主要的内存消耗者。

尽管像 INT4 和 INT8 这样的整数量化方法仍然是当前部署实践中的主流解决方案，但低位浮点量化（如 FP4 和 FP8）已经成为一种新趋势。原因之一是浮点量化能够实现与整数量化相当甚至更高的精度 [[312](https://arxiv.org/html/2401.05459v2#bib.bib312), [313](https://arxiv.org/html/2401.05459v2#bib.bib313), [314](https://arxiv.org/html/2401.05459v2#bib.bib314)]。此外，浮点量化在具有专用计算支持的云 GPU（如 NVIDIA H100）和移动 GPU [[315](https://arxiv.org/html/2401.05459v2#bib.bib315)] 上也可能实现更高的计算性能。

剪枝通过去除网络中不重要的连接来减少模型大小和计算量。剪枝分为结构化剪枝和非结构化剪枝。结构化剪枝通常在规则模式下移除权重，如矩阵中的矩形块或整个通道，而非结构化剪枝则没有这种限制。因此，结构化剪枝（例如，LLM-Pruner [[251](https://arxiv.org/html/2401.05459v2#bib.bib251)]）更适合硬件，但更难维持模型精度。虽然传统剪枝方法需要昂贵的保留过程以保持模型能力，但近期的工作如 SparseGPT [[252](https://arxiv.org/html/2401.05459v2#bib.bib252)] 和 Wanda [[253](https://arxiv.org/html/2401.05459v2#bib.bib253)] 已探索在一次操作中执行非结构化或半结构化剪枝。

知识蒸馏（KD）涉及使用表现良好的教师模型（通常具有大量参数和高精度）来指导轻量级学生模型的训练（通常具有较少的参数和较低的精度）。通过蒸馏，学生模型在相对较小的训练数据集上与教师模型很好地对齐，并有机会在下游任务中表现得更好 [[256](https://arxiv.org/html/2401.05459v2#bib.bib256)]。根据教师模型的参数是否在训练过程中需要，蒸馏方法可以进一步分为白盒（例如，BabyLlama [[254](https://arxiv.org/html/2401.05459v2#bib.bib254)] 和 MiniLLM [[255](https://arxiv.org/html/2401.05459v2#bib.bib255)]）和黑盒（例如，Distilling Step-by-Step [[256](https://arxiv.org/html/2401.05459v2#bib.bib256)] 和 SCoTD [[257](https://arxiv.org/html/2401.05459v2#bib.bib257)]）。由于学生模型通常是轻量级量化或剪枝模型，KD 也被采用于 QAT 和剪枝技术以提升训练性能。例如，LLM-QAT [[248](https://arxiv.org/html/2401.05459v2#bib.bib248)] 提出了一个无数据的蒸馏方法，以保留量化模型中的原始输出分布。

低秩分解是指通过两个低秩矩阵的乘积来近似原始权重矩阵，从而减少模型的参数大小和计算负担。具体而言，形状为$m\times n$的权重矩阵$W$被分解为$U^{m\times r}$和$V^{n\times r}$的乘积，使得$W\approx UV^{T}$且$r\ll m,n$。低秩分解可以与量化（例如，ZeroQuant-V2 [[258](https://arxiv.org/html/2401.05459v2#bib.bib258)])和剪枝（例如，LoSparse [[259](https://arxiv.org/html/2401.05459v2#bib.bib259)])方法结合使用，以提高压缩比。此外，低秩适配器有效地减少了 LLM 的定制开销，详细内容见[5.2 节](https://arxiv.org/html/2401.05459v2#S5.SS2 "5.2 Efficient Customization ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")。

#### 5.1.2 推理加速

除了在第[5.1.3 节](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS3 "5.1.3 Memory Reduction ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")讨论的使模型更加紧凑之外，还有各种其他技术可以加速 LLM 推理过程。

区别 LLM 与传统非 Transformer 模型的一个主要特征是注意力机制[[31](https://arxiv.org/html/2401.05459v2#bib.bib31)]。由于注意力的计算成本随着上下文长度的增加接近平方增长，因此提升长上下文推理的计算效率尤为重要。现有的研究已探索了减少上下文长度和优化注意力内核的方法，以更好地支持长上下文推理。我们将单独深入探讨这些技术。

KV 缓存是一种在移动（例如，llama.cpp [[307](https://arxiv.org/html/2401.05459v2#bib.bib307)]和 mlc-llm [[308](https://arxiv.org/html/2401.05459v2#bib.bib308)])和云 LLM 服务框架（例如，DeepSpeed [[316](https://arxiv.org/html/2401.05459v2#bib.bib316)]和 vLLM [[317](https://arxiv.org/html/2401.05459v2#bib.bib317)]）中广泛采用的技术，以避免 LLM 推理中的冗余计算。具体来说，KV 缓存涉及存储（即“缓存”）和逐步更新键值对（KV 对），这些是注意力计算中的中间结果，在每个标记的生成中进行。因此，可以避免 KV 计算中的重复部分，从而减少计算成本。然而，在长上下文推理中，尽管跳过了 KV 计算，但注意力的计算成本仍然是系统瓶颈，这使得在这种情况下压缩上下文长度变得至关重要。

上下文压缩方法通过减少上下文的长度，特别是 KV 缓存，来提高推理效率。权重和激活的共同量化，包括 KV 缓存，是压缩 KV 缓存的直观方法，已在第[5.1.1](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS1 "5.1.1 Model Compression ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")节讨论。除了量化，上下文修剪会移除上下文中不重要的标记以降低计算成本。这种方法的有效性基于这样一个观察：标记对最终输出的影响不同，删除不重要的标记不会显著降低模型的能力 [[263](https://arxiv.org/html/2401.05459v2#bib.bib263), [318](https://arxiv.org/html/2401.05459v2#bib.bib318), [264](https://arxiv.org/html/2401.05459v2#bib.bib264), [265](https://arxiv.org/html/2401.05459v2#bib.bib265)]。一种典型的工作是基于标记的重要性在预填充阶段压缩上下文 [[260](https://arxiv.org/html/2401.05459v2#bib.bib260), [261](https://arxiv.org/html/2401.05459v2#bib.bib261), [262](https://arxiv.org/html/2401.05459v2#bib.bib262)]。然而，这些方法是一次性的，在标记生成过程中上下文长度持续增长时无法修剪 KV 缓存。为了解决这个问题，Dynamic Context Pruning [[263](https://arxiv.org/html/2401.05459v2#bib.bib263)] 使用一种可学习机制来持续确定和删除无信息标记。虽然可学习机制引入了微调开销，但张等人 [[264](https://arxiv.org/html/2401.05459v2#bib.bib264)] 提出了一个可以在不进行微调的情况下应用的标记驱逐策略。

受相同观察的启发，即标记的重要性不均等，其他研究也探讨了减少不重要标记的计算，而不是直接删除它们。COLT5 [[319](https://arxiv.org/html/2401.05459v2#bib.bib319)] 采用了一种条件计算机制，在 FFN 和注意力机制中都将更多资源分配给重要标记。SkipDecode [[320](https://arxiv.org/html/2401.05459v2#bib.bib320)] 设计了一种标记级别的早期退出方法，该方法与批处理推理和 KV 缓存无缝配合，当标记不重要时跳过计算图中的某些操作。

内核优化是加速 LLM 推理的另一种方法。对小批量或单批量推理的优化在包括本地部署的个人 LLM 代理在内的边缘场景中尤为重要。现有研究表明，当序列长度较长时，注意力计算成为瓶颈，因为注意力的复杂度与序列长度的平方成正比，而 FFN 的复杂度则是线性的。因此，已提出了包括 FlashAttention [[266](https://arxiv.org/html/2401.05459v2#bib.bib266)、[267](https://arxiv.org/html/2401.05459v2#bib.bib267)] 和 FlashDecoding++ [[268](https://arxiv.org/html/2401.05459v2#bib.bib268)] 在内的高效注意力内核，以提高长文本推理的速度。一些研究还从算法角度减少了注意力的计算复杂度。例如，Linformer [[321](https://arxiv.org/html/2401.05459v2#bib.bib321)] 在预填充阶段实现了自注意力的线性复杂度。此外，减少反量化开销也带来了显著的性能提升，正如 LUT-GEMM [[322](https://arxiv.org/html/2401.05459v2#bib.bib322)] 所示。

推测解码 [[270](https://arxiv.org/html/2401.05459v2#bib.bib270)、[269](https://arxiv.org/html/2401.05459v2#bib.bib269)] 是一种有效的处理小批量推理以提高延迟的方法。在边缘的 LLM 推理的批量大小小于云端，通常为 1（即单查询），这使得推理工作负载极度依赖内存。推测解码通过通过轻量级的“草稿模型” “猜测”若干个后续标记，然后使用大型的“预言模型”批量验证草稿标记，从而缓解了这一挑战。Miao 等人 [[323](https://arxiv.org/html/2401.05459v2#bib.bib323)] 和 Spector 与 Re [[324](https://arxiv.org/html/2401.05459v2#bib.bib324)] 进一步通过基于树的验证而非顺序验证来增强推测解码，以重用这些序列间共享的中间结果。虽然这些方法确保了生成结果的零偏差，但 BiLD [[325](https://arxiv.org/html/2401.05459v2#bib.bib325)] 提出了仅在草稿模型无法生成高质量内容时偶尔回退或回滚到预言模型。

#### 5.1.3 内存减少

LLM 推理不仅计算密集，而且内存消耗也很大，这给个人 LLM 代理的部署带来了挑战。因此，有必要对 LLM 推理的内存效率进行优化。KV 缓存和模型权重是这种内存开销的两个主要原因。在短上下文场景中，KV 存储所需的内存远少于模型权重，第[5.1.1](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS1 "5.1.1 Model Compression ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")节中的模型压缩技术在减少存储权重的内存需求方面非常有效。然而，在长上下文场景中，KV 缓存的大小随着上下文长度线性增长，将主导总内存消耗。

解决此问题的有效方法是使用第[5.1.1](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS1 "5.1.1 Model Compression ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")节和第[5.1.2](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS2 "5.1.2 Inference Acceleration ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")节中提到的量化和剪枝技术来压缩 KV 缓存。虽然量化方法具有通用性，可以减少 KV 缓存的内存占用，但并非所有基于剪枝的方法都能直接提高内存效率。只有那些在上下文中连续移除输入令牌时修剪相应行/列的剪枝方法才能防止 KV 缓存大小超过内存限制。例如，Anagnostidis 等人[[263](https://arxiv.org/html/2401.05459v2#bib.bib263)]和 Zhang 等人[[264](https://arxiv.org/html/2401.05459v2#bib.bib264)]建议在生成过程中识别并驱逐无信息的令牌。然而，只有在预填充阶段修剪上下文的一次性方法在生成场景中的效果较差。

尽管基于压缩的方法已被证明能够有效减少 LLM 推理的内存需求，但在某些情况下，压缩造成的准确性下降不可忽视。为了解决这个问题，FlexGen [[271](https://arxiv.org/html/2401.05459v2#bib.bib271)] 设计了一种卸载策略，以充分利用 GPU、CPU 和磁盘，并配合一种锯齿形调度方案，以支持在受限的 GPU 内存下进行高吞吐量推理。这种方法与基于压缩的方法是正交的，因此可以共同使用，以进一步减少 GPU 内存占用。另一条工作线，包括 PowerInfer [[272](https://arxiv.org/html/2401.05459v2#bib.bib272)] 和 Alizadeh 等人 [[273](https://arxiv.org/html/2401.05459v2#bib.bib273)]，通过预测上下文稀疏性来减少低批量推理中的交换开销，这一灵感来源于 [[326](https://arxiv.org/html/2401.05459v2#bib.bib326)]。

#### 5.1.4 能源优化

能源消耗是影响大规模语言模型（LLM）代理实际部署的关键因素，因为 LLM 的计算和内存访问成本高昂。一个高能耗的代理不仅会增加运行时成本和碳足迹，还会由于温度升高和电池寿命缩短而影响用户体验质量（QoE）。因此，优化 LLM 推理的能源效率非常重要。

由于计算和内存访问（主要是权重加载）是能源消耗大的两个主要原因，因此已经有大量的工作从软件和硬件两个角度对这两个方面进行优化。我们在前面几节中介绍了各种类型的软件优化。例如，模型压缩方法通过减少模型大小和计算量来节省能源；KV 缓存通过避免冗余计算来节省能源；高效的注意力核也通过内存重用和局部性优化来提高能源效率。

除了软件优化，利用能源高效的硬件也为提高代理系统的效率提供了新的机会。尽管 CPU 和 GPU 仍然是边缘设备上运行 LLM 推理的主流选择，但它们设计用于支持通用任务，并没有专门针对基于变换器的模型，特别是生成型 LLM 进行优化。研究人员已经探索利用更适合 LLM 推理工作负载的高效处理器，包括 NPUs [[274](https://arxiv.org/html/2401.05459v2#bib.bib274)] 和 TPUs [[275](https://arxiv.org/html/2401.05459v2#bib.bib275)]。然而，有限的操作符和模型支持在实际部署中仍然存在挑战。此外，现有工作还设计了基于 FPGA 的解决方案，以提高 LLM 推理的内存带宽和能源效率比（EER） [[276](https://arxiv.org/html/2401.05459v2#bib.bib276), [327](https://arxiv.org/html/2401.05459v2#bib.bib327)]。

然而，由于硬件部署的复杂性以及能源测量和分析的波动性，对大型语言模型（LLM）推理的能效研究仍然远远不够。已有一些研究关注这一主题，例如评估 LLMs 在 GPU 上的推理能耗 [[328](https://arxiv.org/html/2401.05459v2#bib.bib328), [329](https://arxiv.org/html/2401.05459v2#bib.bib329)]、边缘设备 [[330](https://arxiv.org/html/2401.05459v2#bib.bib330)] 以及数据中心中 LLMs 的碳足迹 [[331](https://arxiv.org/html/2401.05459v2#bib.bib331)]。其他工作倾向于提出 LLM 推理的快速能量预测方法，例如 IrEne [[332](https://arxiv.org/html/2401.05459v2#bib.bib332)]，它对基于 Transformer 的 NLP 模型进行了层级能量分析，并提供了一个可解释且可扩展的能量预测系统。然而，这些预测模型仅适用于 GPU 主机后端，并且缺乏对其他硬件平台如移动电话的泛化能力，而个人 LLM 代理更可能部署在这些平台上。

<svg class="ltx_picture" height="127.15" id="S5.SS1.SSS4.p5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,127.15) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="113.31" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">备注：如何提高 LLM 推理的效率最近已经得到了广泛研究。尽管取得了显著进展，但在个人 LLM 代理的普及和经济部署方面仍然存在很大差距。尚未解决的问题有：1. 是否可以在不降低准确性的情况下进一步压缩或设计高度紧凑的模型，超越语言模型的扩展定律？2. 如果扩展定律不可打破，如何通过动态推理（例如，大模型和小模型的动态协作）在效率和质量之间实现最佳权衡？3. 硬件和操作系统将如何演变以适应 LLMs 和个人 LLM 代理的高效部署？</foreignobject></g></g></svg>

### 5.2 高效定制

个人 LLM 代理可能需要为不同的用户、任务和场景提供服务，这要求对每种情况进行高效的定制。主要有两种方式可以定制 LLMs 的行为；一种是通过不同的上下文提示进行上下文学习，另一种是通过领域特定的数据对 LLM 进行调优。因此，定制的效率主要由上下文加载效率和 LLM 微调效率决定。

#### 5.2.1 上下文加载效率

在个人 LLM 代理的多任务服务过程中，频繁加载上下文是不可避免的，每个任务或场景可能需要新的上下文来进行 LLM 推断。然而，个人设备固有的严格资源限制使得个人 LLM 代理在处理繁琐的上下文信息时面临重大挑战。有多种方法可以使上下文加载过程更高效。一种直接的方法是修剪一些冗余的标记或缩短上下文长度，这些内容已在第[5.1](https://arxiv.org/html/2401.05459v2#S5.SS1 "5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")节中讨论。

提升上下文加载的另一种方法是减少上下文数据传输过程中的带宽消耗。在某些情况下，修剪或丢弃一些标记不可避免地会影响 LLM 的性能，而加载 KV 缓存需要高带宽成本。CacheGen [[285](https://arxiv.org/html/2401.05459v2#bib.bib285)] 解决了上下文加载带来的挑战，它利用了标记和层之间 KV 特征的不同特性，引入了一种新颖的 KV 编码器设计。该编码器将 KV 缓存有效地压缩成紧凑的比特流，从而有效降低带宽需求，同时减少处理延迟。此外，由于不同的输入提示可能有重叠的文本段，Gim 等人[[333](https://arxiv.org/html/2401.05459v2#bib.bib333)] 提出了 Prompt Cache，以在提示之间重用注意力状态。通过预计算并存储频繁出现的文本的注意力状态，该框架可以在这些文本段在新提示中出现时高效地重用，从而加快推断过程。

#### 5.2.2 微调效率

将基础大型语言模型（LLM）进行微调，以更好地支持领域特定任务是可取的，但由于 LLM 参数众多，这对计算资源和内存占用提出了重大挑战。为解决这些问题，已经有各种努力，主要可分为参数高效微调技术、高效优化器设计和训练数据整理，以下各节将详细阐述这些内容。

参数高效微调（PEFT）。在大型语言模型（LLMs）中，庞大的参数量使得完全参数微调成本高昂。为减少 LLMs 的训练开销，出现了许多关于参数高效微调的努力。PEFT 的基本概念是冻结大部分参数，仅专注于训练有限的参数集或引入参数显著较少的适配器。一种常见做法是将一些适配器，即小型神经网络模块，引入现有网络结构中，包括调整隐藏状态[[277](https://arxiv.org/html/2401.05459v2#bib.bib277), [278](https://arxiv.org/html/2401.05459v2#bib.bib278), [334](https://arxiv.org/html/2401.05459v2#bib.bib334)]，添加完整层[[277](https://arxiv.org/html/2401.05459v2#bib.bib277)]，以及将一些前缀向量添加到变换器架构中[[335](https://arxiv.org/html/2401.05459v2#bib.bib335), [336](https://arxiv.org/html/2401.05459v2#bib.bib336), [337](https://arxiv.org/html/2401.05459v2#bib.bib337)]。Liu 等人[[338](https://arxiv.org/html/2401.05459v2#bib.bib338)]也在输入层引入了可训练的向量，其性能高度依赖于底层模型的能力。这些工作中的一些未能避免额外的适配器计算并引入了推理延迟。LoRA[[279](https://arxiv.org/html/2401.05459v2#bib.bib279)]冻结了所有模型权重，并通过附加的秩分解矩阵增强了每个变换器层，大大减少了微调过程中的内存和存储使用，而没有额外的推理延迟。LoRA 的另一个优点是用户可以通过简单地添加或减去适配器矩阵，轻松地在不同的下游任务之间切换。$\mathtt{(IA)^{3}}$[[339](https://arxiv.org/html/2401.05459v2#bib.bib339)]探讨了模型激活与学习向量逐元素相乘的情况。它引入了学习向量，这些向量重新调整了注意力机制中的键和值以及位置前馈网络中的内部激活。通过仅训练这些向量，$\mathtt{(IA)^{3}}$能够以更少的计算保持性能。

**高效优化器设计**。高效优化器设计是另一组训练/微调策略，旨在加速训练或减少训练期间的内存开销。Sophia [[281](https://arxiv.org/html/2401.05459v2#bib.bib281)]，一种轻量级的二阶优化器，通过提供比常用方法如 Adam 及其变体更高效的优化过程，解决了 LLM 预训练所需的高成本和时间。另一方面，庞大的参数数量特别是在较大的批量大小中需要存储更多的激活和优化器状态，这对内存提出了巨大的需求。LOMO [[280](https://arxiv.org/html/2401.05459v2#bib.bib280)] 对所提出的优化器与其他方法的内存配置、吞吐量和下游性能进行了详细分析，展示了在保持训练效率的同时显著减少内存使用。Zhao 等人 [[340](https://arxiv.org/html/2401.05459v2#bib.bib340)] 提出了 HiZOO，旨在利用对角 Hessian 来增强零阶优化器以微调 LLM。它通过每步多进行一次前向传播来避免昂贵的内存成本。

**训练数据整理**。上述方法主要关注于 LLM 的训练过程，而也有一些研究旨在从不同的角度提高 LLM 的训练性能，即训练数据的数量和质量。phi-1 [[282](https://arxiv.org/html/2401.05459v2#bib.bib282)] 研究表明，使用少量高质量数据训练 LLM 可以显著降低训练成本，并实现与大规模数据集和模型相媲美的能力。这挑战了深度学习中传统的规模定律，即强调更大的数据集和模型。此外，phi-1.5 [[283](https://arxiv.org/html/2401.05459v2#bib.bib283)] 和 phi-2 [[284](https://arxiv.org/html/2401.05459v2#bib.bib284)] 将焦点扩展到许多其他任务，如常识推理和语言理解，分别实现了与 5 倍和 25 倍更大模型相当的性能。同样，TinyGSM [[341](https://arxiv.org/html/2401.05459v2#bib.bib341)] 引入了一个在年级学校数学上样本量较少（12.3M）的合成数据集，这在使用该数据集调整小型语言模型时取得了显著的准确性。

值得注意的是，这些方法通常假设 LLM 可以完全适配设备内存，但对于在个人设备上部署的个人 LLM 代理来说，这并不是一个实际的假设，这些设备通常具有有限的计算能力和内存容量。在这些设备上微调 LLM 通常需要利用分层存储，如 CPU 内存甚至磁盘存储。因此，在个人设备上微调 LLM 时，重要的是仔细考虑当前系统的资源限制。

<svg class="ltx_picture" height="141.06" id="S5.SS2.SSS2.p6.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,141.06) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="127.22" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">备注：尽管高效的模型微调和上下文学习技术已经得到广泛研究，但在不同情况下定制个人 LLM 代理的理想机制尚不明确。在这里，我们重点关注两个在个人 LLM 代理系统中可能特别重要的开放问题。1. 类似于操作系统管理应用程序的 RAM，代理系统应如何高效地管理不同（可能并行）的代理、任务和用户的上下文？2. 类似于可以高效安装、卸载和在设备之间移动的移动应用程序，如何使定制（微调）的代理能够高效地回滚到以前的版本或转移到其他基础模型？</foreignobject></g></g></svg>

### 5.3 高效内存操作

个人 LLM 代理需要频繁检索外部内存以便做出更为明智的决策，这可能依赖于被称为检索增强生成（RAG）的机制。考虑到外部内存数据的多样形式，如用户资料、互动历史和本地原始文件（图片、视频等），常见做法是使用嵌入模型 [[342](https://arxiv.org/html/2401.05459v2#bib.bib342), [343](https://arxiv.org/html/2401.05459v2#bib.bib343)] 以统一且高维的向量格式表示内存数据。向量之间的距离表示对应数据的语义相似度。对于每个给定的查询，个人 LLM 代理需要在外部内存存储中找到最相关的内容。然后，通过提示拼接或中间层交叉注意力 [[301](https://arxiv.org/html/2401.05459v2#bib.bib301)] 将检索到的知识注入到个人 LLM 代理中，这两种方式都会使 LLM 推理的上下文变得更加复杂。这导致 LLM 在长上下文中进行更高效的计算，并在推理过程中尽量减少内存占用，这与第[5.1](https://arxiv.org/html/2401.05459v2#S5.SS1 "5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的见解与调查")节讨论的提升 LLM 推理效率类似。

因此，在这一小节中，我们主要关注高效的外部内存检索，这可以从两个方面来考虑：高效搜索和高效工作流。高效搜索关注于向量索引和在像向量库（如 Faiss [[344](https://arxiv.org/html/2401.05459v2#bib.bib344), [345](https://arxiv.org/html/2401.05459v2#bib.bib345), [346](https://arxiv.org/html/2401.05459v2#bib.bib346)] 和 SCaNN [[229](https://arxiv.org/html/2401.05459v2#bib.bib229)]）这样的结构内快速搜索，向量数据库 [[347](https://arxiv.org/html/2401.05459v2#bib.bib347), [348](https://arxiv.org/html/2401.05459v2#bib.bib348), [349](https://arxiv.org/html/2401.05459v2#bib.bib349)]，或一些定制的内存结构 [[350](https://arxiv.org/html/2401.05459v2#bib.bib350), [351](https://arxiv.org/html/2401.05459v2#bib.bib351)]，这些结构用于存储外部内存。而高效工作流则旨在进一步优化检索增强型 LLM 推理的端到端效率。

#### 5.3.1 搜索效率

在比较查询向量 $q$ 与外部内存中的向量之间的相似性时，暴力搜索方法会导致 $O(DN)$ 的计算复杂度。然而，这种方法在向量维度 ($D$) 和数据集大小 ($N$) 较大的情况下变得不切实际。为了减轻搜索开销，通常使用索引来加快查询搜索，通过减少所需的比较次数来实现。

典型的索引算法。这是通过分区方案 [[348](https://arxiv.org/html/2401.05459v2#bib.bib348)] 来实现的，该方案将数据集 $S$ 划分为较小的子集，从而促进选择性比较和更快的搜索查询处理。这些分区然后被组织成数据结构，如表格、树和图，以实现高效遍历。常用的分区方法包括随机化（如 RPTree [[287](https://arxiv.org/html/2401.05459v2#bib.bib287), [352](https://arxiv.org/html/2401.05459v2#bib.bib352)] 和 E2LSH [[286](https://arxiv.org/html/2401.05459v2#bib.bib286)]），学习型分区（如 SPANN [[288](https://arxiv.org/html/2401.05459v2#bib.bib288)]），以及可导航分区（如 NSW [[353](https://arxiv.org/html/2401.05459v2#bib.bib353)] 和 HNSW [[289](https://arxiv.org/html/2401.05459v2#bib.bib289)]）。这些分区方法可以与不同的数据结构结合使用。例如，Vamana [[354](https://arxiv.org/html/2401.05459v2#bib.bib354)] 是一种单调搜索网络，提供图索引，并使用随机初始化。

硬件感知索引优化。由于提高索引的可扩展性和效率已成为关键问题，研究工作也集中在硬件感知的方法上，以扩展外部存储容量，同时保持低延迟和高吞吐量。这是通过利用基于磁盘的索引或硬件与算法的共同设计来实现的[[355](https://arxiv.org/html/2401.05459v2#bib.bib355)]。例如，DiskANN [[290](https://arxiv.org/html/2401.05459v2#bib.bib290)] 通过采用混合 DRAM-SSD 方法来解决成本效益问题。它在 SSD 上采用 Vamana 图索引，并在 DRAM 中使用压缩点表示。这种配置使得在处理十亿点数据库时，能够在不到 10 毫秒的延迟内提供准确的查询响应。DiskANN++ [[356](https://arxiv.org/html/2401.05459v2#bib.bib356)] 通过引入动态条目顶点选择和优化 SSD 布局进一步提高了效率。这一改进使每秒查询次数（QPS）增加了 1.5 倍到 2.2 倍，同时保持了在实际数据集上的准确性。此外，CXL-ANNS [[291](https://arxiv.org/html/2401.05459v2#bib.bib291)] 引入了一种协作的软件-硬件方法，用于可扩展的近似最近邻搜索（ANNS）。通过利用计算扩展链接（CXL），CXL-ANNS 将 DRAM 从主机中解耦，并将重要数据集整合到其内存池中。FANNS [[292](https://arxiv.org/html/2401.05459v2#bib.bib292)] 是一个基于 FPGA 的向量搜索框架，具有基于用户定义的召回需求和硬件限制的自动硬件和算法共同设计。它支持通过硬件 TCP/IP 堆栈进行扩展，并与 FPGA 和 CPU 基线相比表现出显著的加速效果。

在搜索效率分析和优化方面，一些方面与搜索机制设计相关，如相似性测量、搜索范围以及查询类型、选择和优化。另一方面，一些方面则关注搜索过程的高效执行。

搜索机制设计。可以采用多种相似度标准来评估向量相似性，包括汉明距离、余弦距离和聚合得分[[296](https://arxiv.org/html/2401.05459v2#bib.bib296)]。然而，评分机制的选择缺乏严格的原则，通常依赖于经验规则[[348](https://arxiv.org/html/2401.05459v2#bib.bib348)]。在搜索类型方面，可以利用近似和精确的 $k(\geq 1)$ 最近邻 [[355](https://arxiv.org/html/2401.05459v2#bib.bib355)] 搜索以及距离范围搜索来检索相应的向量。为了优化搜索延迟，通常采用基于规则的 [[293](https://arxiv.org/html/2401.05459v2#bib.bib293), [294](https://arxiv.org/html/2401.05459v2#bib.bib294)] 或基于估算成本的方法 [[295](https://arxiv.org/html/2401.05459v2#bib.bib295), [296](https://arxiv.org/html/2401.05459v2#bib.bib296)] 来确定最佳的搜索方案。这些规则和成本模型通常在离线配置，以避免不必要或耗时的搜索操作。为了进一步优化搜索过程，结合向量搜索和元数据过滤的混合操作正变得越来越受欢迎。这涉及诸如预过滤 [[295](https://arxiv.org/html/2401.05459v2#bib.bib295), [296](https://arxiv.org/html/2401.05459v2#bib.bib296), [354](https://arxiv.org/html/2401.05459v2#bib.bib354)]、后过滤和单阶段过滤 [[297](https://arxiv.org/html/2401.05459v2#bib.bib297)] 的技术，以缩小向量搜索的范围。

搜索过程执行。可以采取多种硬件加速方法来提高搜索执行的效率。例如，为了实现并行查询处理，Faiss [[298](https://arxiv.org/html/2401.05459v2#bib.bib298)] 使用 OpenMP 多线程，而 Milvus [[296](https://arxiv.org/html/2401.05459v2#bib.bib296)] 进一步减少 CPU 缓存未命中，并使用新颖的细粒度机制来最佳利用多核并行性。此外，Faiss 和 Quicker ADC [[299](https://arxiv.org/html/2401.05459v2#bib.bib299)] 还支持 SIMD shuffle 指令，以在单个 SIMD 处理器中并行化这些表查找。GPU 也用于快速查询处理 [[357](https://arxiv.org/html/2401.05459v2#bib.bib357), [358](https://arxiv.org/html/2401.05459v2#bib.bib358), [359](https://arxiv.org/html/2401.05459v2#bib.bib359)]，例如向量数据库如 Faiss 和 Milvus。许多向量数据库管理系统还支持分布式集群，以扩展到更大的数据集或更重的工作负载，如 Vald [[300](https://arxiv.org/html/2401.05459v2#bib.bib300)]、Qdrant [[293](https://arxiv.org/html/2401.05459v2#bib.bib293)] 等。

#### 5.3.2 工作流优化

无论是一体化还是迭代的 RAG 系统，传统工作流都是顺序的，在进行检索/生成时推理/检索阶段处于闲置状态。这个特点忽略了执行并行性和请求的检索局部性潜力的优化机会。近期的研究正致力于管道和缓存技术，以进一步提高 RAG 系统的效率。

管道化。RaLMSpec [[301](https://arxiv.org/html/2401.05459v2#bib.bib301)] 是首个通过启用本地缓存以进行推测性检索来利用管道优势的工作。为了保持正确性，使用批处理验证步骤来保证准确性。此外，还采用了缓存预取、最佳推测步长调度器和异步验证，以进一步提升推测性能。PipeRAG [[302](https://arxiv.org/html/2401.05459v2#bib.bib302)] 也使用了管道，并通过两种不同的解决方案来提高其性能：灵活的检索间隔和一个性能模型，该模型会动态调整向量搜索空间，以应对管道中 LLM 推理的下一个 token 的延迟预期。PipeRAG 采用算法系统协同设计，以避免在优化搜索质量的同时增加端到端生成延迟。

缓存。选择缓存方法的原因源于不同请求期间检索文档的时间和空间局部性，RaLMSpec [[301](https://arxiv.org/html/2401.05459v2#bib.bib301)] 已经利用了这一点。RAGCache [[303](https://arxiv.org/html/2401.05459v2#bib.bib303)] 进一步利用知识树在 GPU 和主机内存层次结构中组织检索文档的中间状态。它还提出了一个前缀感知的贪婪双尺寸频率（PGDSF）替换策略和一个缓存感知的请求调度方法，以最小化缓存未命中率。另一项工作，GRITLM [[304](https://arxiv.org/html/2401.05459v2#bib.bib304)]，通过指令区分生成任务和嵌入任务来训练语言模型。由于 RAG 中的常见场景是使用嵌入模型为生成模型提供相关背景以回答用户查询，GRITLM 使嵌入和生成模型等效，从而允许我们进行查询缓存或查询-文档缓存，并节省计算开销。

<svg class="ltx_picture" height="127.15" id="S5.SS3.SSS2.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,127.15) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="113.31" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">备注。使用外部向量存储管理内存数据并不是 LLM 代理的新要求。尽管许多基本技术挑战已得到充分解决，但我们指出了两个需要特别关注的问题。1. 个人 LLM 代理可能会频繁更新内存。因此，外部内存需要支持快速更新、维护和重新索引。2. 个人 LLM 代理的内存可能存储在存储空间有限的个人设备上，而个人代理的内存会随着时间的推移而积累。因此，有必要有效地压缩内存，以避免空间和计算成本的快速增长。</foreignobject></g></g></svg>

## 6 安全性与隐私

![参见说明](img/2ce047a7c07bf4daf5cd91ad3567c6d9.png)

图 11：解决个人 LLM 代理的安全性和隐私问题的技术总结。

敏感个人数据和安全关键个人工具的广泛集成使个人 LLM 代理与普通 LLM 代理有所区别。因此，在个人 LLM 代理中，确保用户数据隐私和服务安全成为一个关键问题。在个人 LLM 代理的背景下，我们关注三个安全原则，包括保密性、完整性和可靠性，如图 [11](https://arxiv.org/html/2401.05459v2#S6.F11 "Figure 11 ‣ 6 Security and Privacy ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security") 所示。保密性代表了用户数据隐私的保护，确保在用户与代理互动过程中不会发生不必要和未经授权的敏感信息泄露。完整性代表了代理决策的弹性，确保代理所执行的行为与预期行为一致，并未被恶意方故意修改或影响。可靠性则侧重于使代理的行为更加可靠和真实。与完整性不同，完整性中的错误答案是由于有意的外部干预，而可靠性则解决了代理内部的错误。

### 6.1 保密性

在本小节中，我们讨论了保护个人 LLM 代理中用户隐私的可能方法。如前所述，确保用户隐私对于拥有大量用户敏感数据的个人代理至关重要。与传统的基于 LLM 的聊天机器人不同，个人 LLM 代理有可能在用户未察觉的情况下自发地发起查询，这些查询可能包含关于用户的敏感信息。同时，代理也可能将用户信息暴露给其他代理或服务。因此，保护用户隐私变得尤为关键。提高保密性的各种方法包括本地数据处理、同态加密、数据遮蔽、权限访问控制等。

#### 6.1.1 本地处理

保护用户隐私的一个简单有效的方法是将计算过程在用户的个人设备上进行。虽然大型语言模型（LLM）服务提供商目前正致力于提升安全性和建立用户信任，但必须承认，将私人数据传输到云端本质上会引入额外的潜在风险。因此，与将数据传输到云端相比，所有数据本地处理被认为是一种更安全的与 LLM 互动的方法。然而，由于个人设备上的资源限制，本地部署 LLM 在高效处理用户请求时面临挑战。这可能导致推理速度缓慢，甚至由于可用内存的限制而无法进行推理。由于个人 LLM 代理中的数据主要由 LLM 处理，实现本地计算的关键是将 LLM 运行在用户自己的设备上。当前有多种现有的轻量级模型 [[360](https://arxiv.org/html/2401.05459v2#bib.bib360), [283](https://arxiv.org/html/2401.05459v2#bib.bib283)] 和部署框架 [[361](https://arxiv.org/html/2401.05459v2#bib.bib361), [308](https://arxiv.org/html/2401.05459v2#bib.bib308), [362](https://arxiv.org/html/2401.05459v2#bib.bib362)] 可用于在边缘设备上部署模型。此外，还提出了各种模型压缩技术 [[363](https://arxiv.org/html/2401.05459v2#bib.bib363), [250](https://arxiv.org/html/2401.05459v2#bib.bib250), [246](https://arxiv.org/html/2401.05459v2#bib.bib246)]，以减少模型大小，从而进一步实现本地部署，如[5.1.3](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS3 "5.1.3 Memory Reduction ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")节所述。

尽管研究人员做出了各种努力，使用本地部署的模型不可避免地面临模型准确性有限的挑战[[43](https://arxiv.org/html/2401.05459v2#bib.bib43)]。大多数领域专家也建议采用云边协作部署的方法，以实现更好的性能权衡。同时，与其他软件应用程序一样，许多个人 LLM 代理也需要与云进行通信，以提供在线服务。通常很难甚至不可能将私密数据完全保留在本地设备上。

#### 6.1.2 安全远程处理

为了在保护隐私的同时调用基于云的模型推理服务，理想的解决方案是同态加密（HE）[[364](https://arxiv.org/html/2401.05459v2#bib.bib364), [365](https://arxiv.org/html/2401.05459v2#bib.bib365)]。在这种方法中，客户端使用加密对用户的明文请求进行编码，服务器对生成的密文进行模型推理。随后，客户端收到加密格式的推理结果，并在解密后获得明文结果。有几项研究[[366](https://arxiv.org/html/2401.05459v2#bib.bib366)]展示了将 HE 应用于深度神经网络的可行性，展示了将 HE 集成到模型中的潜力。

在个人 LLM 代理中使用 HE 时，会出现两个挑战。第一个挑战涉及到 LLM 中的所有操作并非都能使用 HE 执行。HE 最多支持无限次加法（相当于布尔电路中的 XOR）和乘法（相当于布尔电路中的 AND）。然而，LLM 中的某些操作，如 max、min 和 softmax，不能使用 HE 准确执行。第二个挑战是由于 LLM 的计算复杂性大，HE 的推理速度较慢。

针对这两个问题，有几个解决方案。The-x[[367](https://arxiv.org/html/2401.05459v2#bib.bib367)]提出了一种工作流，用于用可以使用 HE 计算的层替代原始的非线性层。在 HE 无法执行某些操作（如 Max 操作）的情况下，密文将被发送回本地设备。本地设备将执行操作，然后将重新加密的文本发送回云端。Cheetah[[368](https://arxiv.org/html/2401.05459v2#bib.bib368)]涵盖了一系列针对服务器端系统进行 HE 推理的算法和硬件优化。Cheetah 的主要目标是提高 HE 的计算效率，从而加快 HE 操作的速度。

然而，尽管在加速基于同态加密（HE）的深度神经网络（DNN）推理方面做出了大量努力，当前同态加密的状态仍远未满足代理的延迟需求[[369](https://arxiv.org/html/2401.05459v2#bib.bib369)]。

除了同态加密（HE），**多方通信（MPC）**[[370](https://arxiv.org/html/2401.05459v2#bib.bib370)]是传统应用密码学的重要组成部分，涉及多方通信过程，其中多个参与者需要在不可信环境中进行通信。在 LLM 中应用 MPC 的挑战在于计算成本高，以及从 MPC 的数学理论到 LLM 实际实现的显著过渡。**Crypten**[[371](https://arxiv.org/html/2401.05459v2#bib.bib371)]是一个包括常见 MPC 方法的框架，支持标准 PyTorch 张量操作，并且启用 GPU 计算。

另一种实现机密远程数据处理的方法是使用**可信执行环境（TEE）**[[372](https://arxiv.org/html/2401.05459v2#bib.bib372)]进行模型推理。然而，TEE 可能会受到各种攻击[[373](https://arxiv.org/html/2401.05459v2#bib.bib373)]，并且可能导致性能受限。

#### 6.1.3 数据掩码

另一种方法是在将信息发送到云端之前使用数据掩码进行预处理。基本思路是将原始输入转换为不涉及隐私的形式，同时保留对推理结果具有重要影响的信息。

数据掩码的一种直接方法是通过隐藏或替换敏感内容（如账户号码、地址和个人姓名）来转换明文输入。这些信息通常被称为**个人身份信息（PII）**。然而，由于其模糊的边界和多样的形式，准确界定 PII 可能具有挑战性，使得从原始内容中一致地识别和删除 PII 变得困难。**国家标准与技术研究院（NIST）**提供了一份指南[[374](https://arxiv.org/html/2401.05459v2#bib.bib374)]，该指南提供了保护 PII 机密性的建议，有助于更安全地管理 PII。**EmojiCrypt**[[375](https://arxiv.org/html/2401.05459v2#bib.bib375)]建议使用表情符号替代用户敏感信息，然后使用修改后的句子进行生成。

另一方面，研究人员提出了基于嵌入的数据匿名化方法，其中客户端将原始用户请求编码成隐藏向量，并将这些向量发送给云端模型进行后续推理。挑战在于如何确保隐私得到保护，如何确保推理准确度不会下降，以及如何确保推理速度不会过多降低。已有几种解决方案。Coavoux 等人[[376](https://arxiv.org/html/2401.05459v2#bib.bib376)]提出了一种度量指标来评估神经表示中的隐私泄漏程度，并通过改变训练目标来实现隐私与准确性之间的权衡。Zhou 等人[[377](https://arxiv.org/html/2401.05459v2#bib.bib377)]通过将动态融合添加到中间表示中来保护用户隐私。TextObfuscator[[378](https://arxiv.org/html/2401.05459v2#bib.bib378)]通过文本模糊技术保护用户隐私。在编码过程中，可以通过引入额外约束来最小化编码向量中隐私敏感信息的包含，从而采用“对抗表示学习”[[379](https://arxiv.org/html/2401.05459v2#bib.bib379)]。尽管这种方法在推理性能方面优于同态加密，但通常未能严格保护数据隐私，因为编码向量本身仍有泄露敏感信息的风险。此外，这些方法需要对隐私特征进行明确的定义，以便编码器在对抗表示学习过程中学习如何去除隐私信息。

#### 6.1.4 信息流控制

上述技术主要涉及模型输入数据的隐私，而模型输出中也可能存在隐私泄露的风险。这是因为模型的输出不仅可能直接返回给用户，还可能发送到其他第三方应用程序、模型、用户或智能代理。例如，当智能代理帮助用户进行餐馆预订时，它可能会将用户的基本资料和日程信息输入到餐馆预订软件中。同样，当企业旨在向用户推荐产品时，可能会依赖于从某些个人代理的输出中检索到的用户偏好信息。这种从 LLMs 的输出中获取隐私信息的方法类似于传统操作系统中的个人数据访问接口，其中确保隐私数据访问的控制和透明度至关重要，需通过权限管理系统来实现[[380](https://arxiv.org/html/2401.05459v2#bib.bib380)]。透明度要求告知用户有关隐私数据访问的信息，包括访问实体（谁）、内容（什么）、时间（何时）、意图（为何）、访问方式（如何）等。Evertz 等人[[381](https://arxiv.org/html/2401.05459v2#bib.bib381)]提出了一种评估 LLM 集成系统中隐私泄漏的方法。

也可以直接要求 LLMs 保留私人信息。然而，由于 LLMs 的工作是基于统计而非明确规则，其安全性无法严格证明。因此，我们在处理数据机密性时，不应将 LLMs 视为可信计算基准（TCB）的一部分。因此，我们可能需要基于规则的权限控制来限制 LLMs 的操作和访问。权限机制允许用户配置不同实体是否被允许访问不同类型的信息。在个人 LLM 代理中，设计权限机制的挑战之一在于界定隐私数据的类型，因为第三方应用程序获取的内容是由模型生成的。在传统系统中，研究人员提出了大量细化隐私内容划分和权限控制的方法，以及基于信息流传播的隐私数据可追溯性技术[[382](https://arxiv.org/html/2401.05459v2#bib.bib382)]。然而，为 LLM 代理生成的输出建立隐私数据可追溯性仍然是一个未解的问题。

<svg class="ltx_picture" height="157.66" id="S6.SS1.SSS4.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,157.66) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="143.83" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">备注。确保用户数据的机密性对于个人 LLM 代理建立用户信任至关重要。然而，现有的隐私保护技术仍不足以支持更高智能水平的代理。存在以下开放问题：1. 现有方法面临平衡效率和效果的共同挑战。例如，我们如何使强大且高效的本地 LLM 成为可能，如何将同态加密（HE）或可信执行环境（TEE）扩展到大型模型，以及如何实现数据屏蔽/混淆技术以实现严格的机密性？2. 作为一种新的软件范式，个人 LLM 代理的系统隐私保护机制仍不明确。我们是否仍需要符号规则或权限进行访问控制？它们如何与 LLM 的不可解释性无缝集成？</foreignobject></g></g></svg>

### 6.2 完整性

完整性指的是个人 LLM 代理能够确保在面对各种攻击类型时仍能正确输出预期内容的能力。由于个人 LLM 代理需要与各种数据、应用程序和其他代理进行交互，因此可能存在敌对第三方试图通过非常规手段窃取用户数据和资产或破坏系统正常功能的风险。因此，系统必须能够抵御各种类型的攻击。传统的攻击方法，如模型参数修改、盗窃和本地数据篡改，可以通过加密、权限、硬件隔离等措施进行防御。然而，除了防御传统攻击方法外，还应关注 LLM 代理可能遇到的新型攻击：对抗攻击、后门攻击和提示注入攻击。

#### 6.2.1 对抗攻击

恶意攻击主要通过对模型输入的专门定制或对模型的恶意篡改来实现其目标。一类重要的攻击称为“对抗性攻击”，通过定制或篡改模型的输入数据来导致模型推理错误，这最初在图像分类模型中被发现[[383](https://arxiv.org/html/2401.05459v2#bib.bib383)]。这种攻击类型通过在图像中添加不可察觉的噪声来引发严重的分类错误。随后，研究人员将这种攻击方法扩展到文本数据、图形数据及其他领域[[384](https://arxiv.org/html/2401.05459v2#bib.bib384)]。这种攻击在大型语言模型中也存在[[385](https://arxiv.org/html/2401.05459v2#bib.bib385)]，这些模型可能还接受来自第三方的图像[[386](https://arxiv.org/html/2401.05459v2#bib.bib386)]、文本[[387](https://arxiv.org/html/2401.05459v2#bib.bib387)]以及其他数据模态[[388](https://arxiv.org/html/2401.05459v2#bib.bib388)]。例如，在帮助用户自动化任务时，攻击者可能误导代理删除日历事件并泄露私人对话数据[[389](https://arxiv.org/html/2401.05459v2#bib.bib389)]，因为大型语言模型通常需要输入应用程序的内部信息内容以生成下一步的互动决策。在这种情况下，如果第三方应用程序向大型语言模型输入恶意定制的内容，可能会导致智能代理进行不安全的互动。传统的防御方法通常包括对抗性防御、异常输入检测、输入预处理、输出安全验证等[[384](https://arxiv.org/html/2401.05459v2#bib.bib384)]。尽管这些方法在理论上适用于大型语言模型和大型语言模型代理，但由于参数的大规模以及自回归生成的特点，一些计算开销大的方法（如形式化输出安全验证和基于中间层激活检测异常数据）可能难以实现。此外，某些防御方法在大型语言模型的背景下可能需要调整。例如，训练大型语言模型可能会产生巨大的成本，使得通过对抗性训练提升安全性不切实际。因此，探索通过参数高效微调实现对抗性防御的良好效果是值得研究的。Zhu 等人[[390](https://arxiv.org/html/2401.05459v2#bib.bib390)]显示当前的解决方案可能过于乐观：防御这些攻击是可能的：对抗性攻击生成无限但不可读的废话提示，可以通过基于困惑度的过滤器检测；手动越狱攻击制作可读的提示，但由于需要人类创造力而数量有限，因此容易被阻止。然后，他们介绍了 AutoDAN，这是一种解释性、基于梯度的对抗攻击，结合了两种攻击类型的优点。在越狱和可读性的双重目标指导下，AutoDAN 从左到右逐个优化和生成标记，产生可读的提示，绕过困惑度过滤器，同时保持高攻击成功率，为红队测试大型语言模型和通过可解释性理解越狱机制提供了一种新方法。

#### 6.2.2 后门攻击

另一种常见的攻击形式是后门攻击。传统的模型后门攻击通常通过数据中毒实现[[391](https://arxiv.org/html/2401.05459v2#bib.bib391)]，即将恶意修改的样本插入到模型的训练数据中，从而使模型学习到故意隐藏的决策逻辑，例如“当看到一个苹果的图案时，模型输出一个错误的分类”。对于大型语言模型（LLMs），由于训练数据量巨大且统一管理严格，数据中毒可能更具挑战性，但另一种类型的后门攻击方法[[392](https://arxiv.org/html/2401.05459v2#bib.bib392)]仍然有效，即通过在测试时修改模型输入来植入不安全的逻辑。Kandpal 等人[[393](https://arxiv.org/html/2401.05459v2#bib.bib393)] 在语言模型被提示执行特定目标任务时引发了有针对性的错误分类。ProAttack [[394](https://arxiv.org/html/2401.05459v2#bib.bib394)] 直接利用提示作为触发器将后门注入到 LLMs 中，这是首次尝试基于提示探索干净标签的文本后门攻击。PoisonPrompt [[395](https://arxiv.org/html/2401.05459v2#bib.bib395)] 是一种基于双层优化的提示后门攻击，针对软提示和硬提示的 LLMs。由于 LLMs 在某些场景中通常使用多个固定提示，这种通过修改提示实现的攻击，本质上是对模型参数进行微调，从而改变其决策逻辑。Han 等人[[396](https://arxiv.org/html/2401.05459v2#bib.bib396)] 从中毒的预训练编码器中提取良性知识，并将其转移到新的编码器上，从而得到一个干净的预训练编码器，这可能会损害 LLMs 的性能。Sun 等人[[397](https://arxiv.org/html/2401.05459v2#bib.bib397)] 提出，测试给定目标生成源的反向概率能够有效防御不同类型的攻击。确实，当攻击者模拟正常行为时，这种防御方法可能会失效。因此，尚未有针对代理系统的强健后门防御解决方案[[398](https://arxiv.org/html/2401.05459v2#bib.bib398)]。这突显了需要开发有效防御措施以应对模仿合法行为的复杂攻击。

#### 6.2.3 提示注入攻击

在 LLM 时代，出现了一种新的且特别重要的安全风险，即提示注入攻击 [[399](https://arxiv.org/html/2401.05459v2#bib.bib399), [400](https://arxiv.org/html/2401.05459v2#bib.bib400), [401](https://arxiv.org/html/2401.05459v2#bib.bib401), [402](https://arxiv.org/html/2401.05459v2#bib.bib402)]。这种攻击形式中，模型本身通过对齐和提示来实现某些安全保障。然而，第三方模型用户可以通过使用提示中的微妙或特殊措辞来绕过这些预设的安全保障。例如，智能个人助理可能被预设为不执行某些敏感操作，例如修改用户账户密码 [[403](https://arxiv.org/html/2401.05459v2#bib.bib403)]，但通过提示注入（例如，要求 LLM“忽略先前设定的限制”或“假设在授权的安全模式下操作”），它可能诱使模型违反规定，执行这些敏感操作。

对于这种基于提示的攻击方法，目前没有完美的防御机制。SmoothLLM [[404](https://arxiv.org/html/2401.05459v2#bib.bib404)] 是首个通用的提示注入防御方法，它随机扰动给定输入提示的多个副本，然后汇总相应的预测以检测对抗性输入。然而，它的防御效果高度依赖于模型的鲁棒性，因为某些模型的攻击成功率仅减少了约 1%。缓解这一问题的一个重要方法是确保 LLM 提示的透明性和安全性。例如，个人 LLM 代理可以严格控制提示的模板和规范，要求所有请求都必须符合预设的模板和规范。此外，对第三方应用程序的输入内容进行后处理（如总结、翻译、重新表述等）或提示封装（例如在前后添加明确文本以指示其来源于第三方）可以帮助模型清晰地区分系统的固有提示。

<svg class="ltx_picture" height="148.06" id="S6.SS2.SSS3.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,148.06) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="134.22" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">备注。确保决策过程的完整性对于个人 LLM 代理至关重要。完整性面临的威胁非常多样且不断演变，而防御技术的发展则滞后。在这里，我们强调了两个适用于所有类型攻击的重要开放问题。1. 代理如何知道其输入或决策过程是否被第三方篡改？这需要代理具备对正常输入和行为的感知，并能够识别异常。2. 由于直接避免攻击可能具有挑战性，因此考虑用户验证机制会更为实际，即在代理不确定时要求用户进行验证。如何设计一个安全且用户友好的验证机制是一个挑战。</foreignobject></g></g></svg>

### 6.3 可靠性

在个人 LLM 代理中，LLM 确定了许多关键操作，包括一些敏感操作，如修改和删除用户信息、购买服务和发送消息。因此，确保代理决策过程的可靠性至关重要。我们从三个方面讨论 LLM 的可靠性，包括问题（即，LLM 可靠性问题的表现在哪里？）、改进（即，我们如何使 LLM 的响应更可靠？）和检查（即，我们如何处理 LLM 可能不可靠的输出？）。

#### 6.3.1 问题

**幻觉**。LLM 可能会产生不正确的答案，这可能会导致严重的后果。与直接通过文本与用户互动的 LLM 基于的聊天机器人相比，个人 LLM 代理通过避免频繁的结果验证来减少用户干扰，从而加剧了产生错误答案的严重性。研究人员发现了 LLM 生成文本的情况，这些文本虽然连贯流畅，但最终是错误的。这种现象在自然语言处理任务中被称为幻觉，对个人代理也是一种挑战。**Ji** 等人 [[405](https://arxiv.org/html/2401.05459v2#bib.bib405)] 深入探讨了自然语言处理任务中幻觉的各种表现形式。**Rawte** 等人 [[406](https://arxiv.org/html/2401.05459v2#bib.bib406)] 进一步讨论了多模态基础模型中的幻觉，为感兴趣的读者提供了宝贵的参考。

未识别操作。与聚焦于 LLM 生成的“错误答案”的幻觉问题不同，LLM 模型的响应中有许多情况是“甚至不对”。例如，考虑一个场景，其中 LLM 被指示使用格式“CALL XXXXXX”来发起电话呼叫。作为回应，LLM 可能生成“我将打电话给 XXXX”的回复，这准确传达了预期的含义，但偏离了指定的格式，使其不可执行。正如我们所知，LLM 的本质是语言建模，而语言模型的输出通常以语言形式呈现。与直接与人类互动的其他 LLM 相比，个人 LLM 代理需要执行动作。因此，它们对输出的格式和可执行性有显著更高的要求[[407](https://arxiv.org/html/2401.05459v2#bib.bib407)]。

顺序可靠性。LLM 最初是在顺序数据（即语料库）和训练目标（即从左到右的语言建模任务）上进行预训练的。然而，现实世界中的问题可能无法完全顺序地解决。实现顺序可靠性面临几个挑战，包括上下文保持、一致性维护等。为了更好地与用户和个人 LLM 代理保持连贯且有意义的对话，我们需要激发 LLM 从全局视角进行思考的能力，而不仅仅依赖于之前生成的标记或上下文。在提高 LLM 的思维和推理能力方面，Yao 等人[[85](https://arxiv.org/html/2401.05459v2#bib.bib85)]提出了“思维树”来生成并在多个不同的推理路径上得出结论，Zhang 等人[[408](https://arxiv.org/html/2401.05459v2#bib.bib408)]提出了“累积推理”以累积和迭代的方式解决复杂任务。还可以设计解决任务的总体计划[[89](https://arxiv.org/html/2401.05459v2#bib.bib89)]或从先前的工作中获取洞见[[409](https://arxiv.org/html/2401.05459v2#bib.bib409), [410](https://arxiv.org/html/2401.05459v2#bib.bib410)]。

#### 6.3.2 改进

改进方法旨在提高 LLM 输出的质量，从而增强基于 LLM 的代理的可靠性。

对齐。随着大语言模型（LLMs）规模和复杂性的增长，人们对它们生成偏见、 harmful 或不当内容的潜在能力表示担忧。对齐方法旨在减轻这些风险，确保 LLM 的行为与伦理和社会规范保持一致。一个常见的对齐方法是使用预训练和微调[[411](https://arxiv.org/html/2401.05459v2#bib.bib411), [412](https://arxiv.org/html/2401.05459v2#bib.bib412), [413](https://arxiv.org/html/2401.05459v2#bib.bib413)]。LLM 在大量文本数据上进行预训练，以学习语言模式和表示。在微调阶段，模型在更具体且精心策划的数据集上进一步训练，包括人工生成的示例和演示。这个过程通过将人类的价值观和意图融入训练中，帮助将模型对齐到期望的行为上。另一个对齐方法是奖励建模，它涉及定义和优化反映期望结果或行为的奖励函数。通过对特定操作提供明确的奖励或惩罚，可以训练 LLM 生成符合这些预定义目标的输出。可以采用强化学习技术（例如，RLHF [[44](https://arxiv.org/html/2401.05459v2#bib.bib44)], RLAIF [[414](https://arxiv.org/html/2401.05459v2#bib.bib414)], C-RLFT [[415](https://arxiv.org/html/2401.05459v2#bib.bib415)]）来基于这些奖励信号优化模型行为。监督和干预是关键的对齐方法。人工审查员或监督员在审查和过滤 LLM 输出的潜在偏见、有害内容或不当行为方面发挥着重要作用。他们的反馈和干预用于迭代地改进模型的性能，并使其与期望的标准对齐。

自我反思。研究表明，语言模型能够提供正确答案的概率[[416](https://arxiv.org/html/2401.05459v2#bib.bib416)]。受到大语言模型（LLMs）自主运行的启发，研究人员建议利用模型的自我反思来减轻错误内容生成的问题。黄等人[[241](https://arxiv.org/html/2401.05459v2#bib.bib241)]和马达安等人[[417](https://arxiv.org/html/2401.05459v2#bib.bib417)]表明，LLMs 能够通过未标注数据进行自我改进，辛恩等人[[418](https://arxiv.org/html/2401.05459v2#bib.bib418)]提出了 Reflexion 方法，让 LLMs 通过语言反馈进行更新。陈等人[[419](https://arxiv.org/html/2401.05459v2#bib.bib419)]提出了 Self-Debug，通过迭代改进多个代码生成任务上的响应。SelfCheckGPT [[420](https://arxiv.org/html/2401.05459v2#bib.bib420)]允许大型模型对相同输入问题提供多次答案，并检查这些响应之间的一致性。如果答案之间存在矛盾，则模型生成不可靠内容的概率更高。杜等人[[421](https://arxiv.org/html/2401.05459v2#bib.bib421)]尝试通过让多个大型模型代理进行相互讨论和验证来提高模型输出的可靠性。组合模型的方式多种多样，类似于人类世界中的多样化协作方法。然而，就像更多的员工需要增加开支一样，拥有更多模型也意味着更大的计算能力需求。上述工作展示了 LLMs 从单纯的文本生成器演变为智能体的趋势，从原始的基于理解的推理过渡到带有迭代更新的反思性推理。

检索增强。大规模语言模型（LLMs）在各种任务中表现强劲，但模型中存储的参数化知识仍可能不完整且难以高效更新。相对而言，检索增强的方法[[229](https://arxiv.org/html/2401.05459v2#bib.bib229)、[230](https://arxiv.org/html/2401.05459v2#bib.bib230)、[422](https://arxiv.org/html/2401.05459v2#bib.bib422)] 提供了一种半参数化的方法，以提供补充的非参数信息，使 LLMs 在生成内容时可以利用检索到的现实世界知识，例如维基百科、文档或知识图谱[[423](https://arxiv.org/html/2401.05459v2#bib.bib423)]。这种方法的优势在于无需修改模型，便于实时信息更新，并且允许生成结果追溯到原始数据，从而增强生成信息的可解释性。检索增强已被证明对传统预训练模型如 BERT 有效[[424](https://arxiv.org/html/2401.05459v2#bib.bib424)]。然而，对于已经具备强大推理能力的 LLMs 来说，增强上下文也可能因为无关或噪声信息而产生负面影响[[425](https://arxiv.org/html/2401.05459v2#bib.bib425)]。为解决这些问题，Guo 等人[[222](https://arxiv.org/html/2401.05459v2#bib.bib222)] 提出了针对非知识密集型任务的提示引导检索方法，增强检索段落与更一般查询的相关性。Yu 等人[[426](https://arxiv.org/html/2401.05459v2#bib.bib426)] 提出了链式笔记方法以提高处理噪声和无关文档时的鲁棒性。Asai 等人[[427](https://arxiv.org/html/2401.05459v2#bib.bib427)] 提出了自我检索增强生成（Self-RAG）以通过自我反思增强事实准确性。Wang 等人[[428](https://arxiv.org/html/2401.05459v2#bib.bib428)] 提出了自我知识引导检索方法（SKR），以平衡外部知识与内部知识。Wang 等人[[429](https://arxiv.org/html/2401.05459v2#bib.bib429)] 提出了 FLICO，通过预先筛选上下文来改善检索片段的细粒度相关性。CRITIC[[430](https://arxiv.org/html/2401.05459v2#bib.bib430)]框架利用 LLMs 通过与外部工具（如计算器、Python 解释器和维基百科）互动，验证并迭代自我纠正其输出。Zhang 等人[[431](https://arxiv.org/html/2401.05459v2#bib.bib431)] 提出了 RAFT，一种检索增强微调方法，用于提高领域特定问题的回答能力。然而，这些方法仍依赖于高性能文本检索器，并且对用户请求的帮助有限，尤其是那些在外部知识库中难以找到匹配内容的请求。

#### 6.3.3 检查

另一方面，基于检查的方法不会干扰 LLM 生成过程。相反，它侧重于如何基于已经生成的结果来增强或理解代理的可靠性。

验证。由于在实际使用这些系统时，LLM 生成不可靠内容的问题无法完全避免，因此仍然需要建立基于规则的安全验证机制。关于前述的未识别操作，“受限生成”指的是生成格式化和受限输出的过程，这可以用来解决这个问题。Kumar 等人[[432](https://arxiv.org/html/2401.05459v2#bib.bib432)]使用 Langevin Dynamics 模拟来进行非自回归文本生成作为解决方案。另一方面，Miao 等人[[433](https://arxiv.org/html/2401.05459v2#bib.bib433)]介绍了一种方法，该方法在每次迭代时建议一个候选修改，并验证修改后的句子是否满足给定的约束，从而生成受限句子。Li 等人[[434](https://arxiv.org/html/2401.05459v2#bib.bib434)]和 Weng 等人[[435](https://arxiv.org/html/2401.05459v2#bib.bib435)]提出了自我验证以帮助大语言模型的推理过程。Responsible Task Automation [[99](https://arxiv.org/html/2401.05459v2#bib.bib99)]是一个可以预测命令可行性、确认执行者的完整性并增强大语言模型安全性的系统。然而，仍需进一步研究以提高识别敏感操作的准确性和召回率，并减轻用户的决策负担。

解释。虽然前面提到过智能个人助手应尽量减少对用户的打扰，但融入用户意见或人工协助在做出重要决策时可能很有价值。如果智能个人助手犯了错误，可解释的逻辑在后续调试过程中也能提供帮助。有几项调查[[436](https://arxiv.org/html/2401.05459v2#bib.bib436), [437](https://arxiv.org/html/2401.05459v2#bib.bib437), [438](https://arxiv.org/html/2401.05459v2#bib.bib438)]讨论了可解释语言模型。传统上，基于理由的方法[[439](https://arxiv.org/html/2401.05459v2#bib.bib439), [440](https://arxiv.org/html/2401.05459v2#bib.bib440)]可以通过明确训练在人工标注的数据上来解释模型输出。至于大型语言模型（LLMs），链式推理[[84](https://arxiv.org/html/2401.05459v2#bib.bib84)]方法也可以帮助模型生成文本解释。为了使推理过程更具鲁棒性和可靠性，近期研究通过多数投票[[441](https://arxiv.org/html/2401.05459v2#bib.bib441)]和迭代引导[[442](https://arxiv.org/html/2401.05459v2#bib.bib442)]机制进一步增强链式推理。显然，研究人员对可解释性给予了极大的重视，因为它不仅有助于可靠性，而且代表了一个有趣的研究方向。

中间特征分析。除了最后一层表示外，一些研究还涉及分析模型推理过程中的中间状态，以判断生成虚假信息的情况。Halawi 等人[[443](https://arxiv.org/html/2401.05459v2#bib.bib443)]发现模型在某些层的行为可能会显著偏离，强调了分析模型中间计算的重要性。Li 等人[[444](https://arxiv.org/html/2401.05459v2#bib.bib444)]发现中间层的模型激活可以揭示一些“真实性”的方向，表明 LLMs 可能已经捕捉到知识，尽管未生成，他们进一步提出在推理过程中改变模型激活并改进 LLMs 的响应。van der Poel 等人[[445](https://arxiv.org/html/2401.05459v2#bib.bib445)]提出了一种利用互信息并通过评估下一个标记的置信度来缓解幻觉的方法，其基本原因是 LLMs 在生成幻觉内容时的神经激活模式与正常输出有所不同。这些研究突显了仅依赖最终层表示进行语言建模的不足，揭示了利用模型不同层级的层次信息的潜在好处。

<svg class="ltx_picture" height="193.2" id="S6.SS3.SSS3.p5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,193.2) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="179.36" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">备注：LLM 生成的可靠性受到相当多的关注，特别是在幻觉问题上。然而，避免不可靠行为仍然困难重重，甚至可以说是不可能的。开放性问题包括：1. 我们如何评估 LLM 和 LLM 代理的可靠性？现有方法依赖于如 GPT-4 等黑箱 LLM 或成本高昂的人类注释。需要权威的基准和方法来评估和提高可靠性。2. 类似于保密问题，在个人 LLM 代理的决策过程中引入严格的符号规则将是提高可靠性的实际解决方案。然而，在保留 LLM 代理强大能力的同时遵守这些规则是具有挑战性的。3. DNN 的缺乏透明性和可解释性一直是一个长期存在的问题，对于个人 LLM 代理的所有安全和隐私方面尤为关键。如何解释和说明 LLM 的内部机制是一个值得持续研究的方向。</foreignobject></g></g></svg>

## 7 结论与展望

大型语言模型的出现为智能个人助手的发展带来了新的机遇，具有彻底改变人机交互方式的潜力。在本文中，我们重点关注个人 LLM 代理，基于领域专家的反馈和广泛的文献综述，系统地讨论了几个关键的机遇和挑战。

当前，个人 LLM 代理的研究仍处于早期阶段。任务执行能力仍然相对不足，支持的功能范围也相当狭窄，仍有很大的改进空间。此外，确保这些个人代理的效率、可靠性和可用性需要解决众多关键性能和安全问题。在 LLM 需要大规模参数以实现更好服务质量的需求与个人代理在资源、隐私和安全方面的约束之间存在固有的紧张关系。

展望未来，除了应对各个具体方向的挑战外，还需要共同努力建立完整的软件/硬件栈和个人 LLM 代理的生态系统。研究人员和工程师还需要仔细考虑这些技术的责任，以确保个人 LLM 代理的良性和辅助性质。

## 致谢

本工作得到中国国家自然科学基金（NSFC，资助号 62272261）及与亚信科技（中国）有限公司和小米有限公司的合作研究项目的支持。我们衷心感谢包括 Xiaobo Peng（Autohome）、Ligeng Chen（Honor Device）、Miao Wei、Pengpeng He（华为）、Hansheng Hong、Wenjun Chen、Zhiyao Yang（Oppo）、Xuesheng Qi（vivo）、Liang Tao、Lishun Sun、Shuang Dong（小米）及其他匿名专家在内的许多领域专家提供的宝贵反馈。在共同作者中，Jiacheng Liu、Wenxing Xu 和 Rui Kong 在撰写本文时是清华大学人工智能产业研究院（AIR）的实习生。

## 参考文献

+   苹果 [2023a] 苹果。Siri。 [`www.apple.com/siri/`](https://www.apple.com/siri/)，2023a 年。[在线；访问日期：2023 年 12 月 26 日]。

+   谷歌 [2023a] 谷歌。适用于安卓的 Google 助手。 [`developer.android.com/guide/app-actions/overview`](https://developer.android.com/guide/app-actions/overview)，2023a 年。[在线；访问日期：2023 年 12 月 24 日]。

+   亚马逊 [2023] 亚马逊。Alexa。 [`www.alexa.com`](https://www.alexa.com)，2023 年。[在线；访问日期：2023 年 12 月 26 日]。

+   Li et al. [2020] Yang Li, Jiacong He, Xin Zhou, Yuan Zhang, 和 Jason Baldridge。将自然语言指令映射到移动 UI 操作序列，2020 年。

+   Li 和 Riva [2021] Yuanchun Li 和 Oriana Riva。Glider：一种从网站提取 UI 脚本的强化学习方法。在*第 44 届国际 ACM SIGIR 信息检索研究与发展会议论文集*，SIGIR ’21，第 1420–1430 页，纽约，NY，美国，2021 年。计算机协会。ISBN 9781450380379。doi: 10.1145/3404835.3462905。

+   Liu et al. [2018] Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tianlin Shi, 和 Percy Liang。使用工作流引导探索的 Web 界面上的强化学习。*ArXiv*，abs/1802.08802，2018 年。

+   Zhao et al. [2023a] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, 和 Ji-Rong Wen。关于大型语言模型的调查，2023a。

+   IBM [2023] IBM。Ibm shoebox。 [`www.ibm.com/ibm/history/exhibits/specialprod1/specialprod1_7.html`](https://www.ibm.com/ibm/history/exhibits/specialprod1/specialprod1_7.html)，2023 年。[在线；访问日期：2023 年 12 月 26 日]。

+   Lowerre 和 Reddy [1976] Bruce Lowerre 和 R Reddy。Harpy 语音识别系统：大词汇量下的性能。*美国声学学会杂志*，60(S1)：S10–S11，1976 年。

+   Cerf-Danon et al. [1991] Helene Cerf-Danon, Steven DeGennaro, Marco Ferretti, Jorge Gonzalez, 和 Eric Keppel。1\. 0 TANGORA - 一个支持五种语言的大词汇量语音识别系统。在*第 2 届欧洲语音通信与技术会议（Eurospeech 1991）*，第 183–192 页，1991 年。doi: 10.21437/Eurospeech.1991-44。

+   Rabiner 和 Juang [1986] L. Rabiner 和 B. Juang. 《隐马尔可夫模型简介》。 *IEEE ASSP 杂志*，3(1):4–16，1986 年。doi: 10.1109/MASSP.1986.1165342。

+   Bamberg 等 [1990] Paul G. Bamberg, Yen Lu Chow, Larry Gillick, Robert Roth, 和 Dean G. Sturtevant. 《Dragon 连续语音识别系统：实时实现》。见 *Human Language Technology - The Baltic Perspective*，1990 年。

+   Wikipedia [2023a] Wikipedia. 《可读项》。 [`en.wikipedia.org/wiki/Speakable_items`](https://en.wikipedia.org/wiki/Speakable_items)，2023a。 [在线；访问日期：2023 年 1 月 5 日]。

+   Lai 和 Vergo [1997] Jennifer Lai 和 John Vergo. 《Medspeak：使用连续语音识别进行报告创建》。见 *ACM SIGCHI 人机交互系统会议论文集*，CHI ’97，第 431–438 页，美国纽约，1997 年。计算机协会。ISBN 0897918029。doi: 10.1145/258549.258829。

+   Microsoft [2002] Microsoft. 《语音记录 - Jim Allchin，WinHEC 2002》。 [`news.microsoft.com/speeches/speech-transcript-jim-allchin-winhec-2002/`](https://news.microsoft.com/speeches/speech-transcript-jim-allchin-winhec-2002/)，2002 年。 [在线；访问日期：2023 年 1 月 5 日]。

+   Markoff [2008] John Markoff. 《Google 正在接受问题（通过 iPhone 语音）》。 [`www.nytimes.com/2008/11/14/technology/internet/14voice.html`](https://www.nytimes.com/2008/11/14/technology/internet/14voice.html)，2008 年。 [在线；访问日期：2024 年 1 月 5 日]。

+   Microsoft [2023a] Microsoft. 《Cortana》。 [`www.microsoft.com/en-us/cortana`](https://www.microsoft.com/en-us/cortana)，2023a。 [在线；访问日期：2023 年 12 月 26 日]。

+   OpenAI [2022] OpenAI. 《介绍 ChatGPT》。 [`openai.com/blog/chatgpt`](https://openai.com/blog/chatgpt)，2022 年。 [在线；访问日期：2023 年 11 月 28 日]。

+   Microsoft [2023b] Microsoft. 《宣布 Microsoft Copilot，你的日常 AI 伴侣》。 [`blogs.microsoft.com/blog/2023/09/21/announcing-microsoft-copilot-your-everyday-ai-companion/`](https://blogs.microsoft.com/blog/2023/09/21/announcing-microsoft-copilot-your-everyday-ai-companion/)，2023b。 [在线；访问日期：2023 年 12 月 4 日]。

+   Apple [2023b] Apple. 《SiriKit：通过语音、智能建议和个性化工作流赋能用户与设备交互》。 [`developer.apple.com/documentation/sirikit/`](https://developer.apple.com/documentation/sirikit/)，2023b。 [在线；访问日期：2023 年 12 月 24 日]。

+   Apple [2023c] Apple. 《快捷方式用户指南》。 [`support.apple.com/en-hk/guide/shortcuts/welcome/ios`](https://support.apple.com/en-hk/guide/shortcuts/welcome/ios)，2023c。 [在线；访问日期：2023 年 12 月 24 日]。

+   Joaoapps [2023] Joaoapps. 《Tasker：Android 的全面自动化》。 [`tasker.joaoapps.com`](https://tasker.joaoapps.com)，2023。 [在线；访问日期：2023 年 12 月 24 日]。

+   Absinthe [2023] Absinthe. Anywhere shortcuts. [`play.google.com/store/apps/details?id=com.absinthe.anywhere_&hl=en_US&pli=1`](https://play.google.com/store/apps/details?id=com.absinthe.anywhere_&hl=en_US&pli=1)，2023 年。[在线; 访问日期：2023 年 12 月 24 日]

+   Li 等人 [2017a] Toby Jia-Jun Li, Yuanchun Li, Fanglin Chen, 和 Brad A Myers. 通过演示使用移动应用程序编程物联网设备。在 *终端用户开发：第 6 届国际研讨会，IS-EUD 2017，荷兰埃因霍温，2017 年 6 月 13-15 日，论文集 6*，第 3–17 页。Springer，2017a。

+   Azim 等人 [2016] Tanzirul Azim, Oriana Riva, 和 Suman Nath. Ulink：启用用户定义的深度链接到应用内容。在 *第 14 届年度国际移动系统、应用程序和服务会议论文集*，MobiSys ’16，第 305–318 页，纽约，美国，2016 年。计算机协会。ISBN 9781450342698。doi: 10.1145/2906388.2906416。

+   Cowan 等人 [2017] Benjamin R. Cowan, Nadia Pantidi, David Coyle, Kellie Morrissey, Peter Clarke, Sara Al-Shehri, David Earley, 和 Natasha Bandeira. “我能帮你什么？”：不频繁用户对智能个人助理的体验。在 *第 19 届国际移动设备与服务人机交互会议论文集*，MobileHCI ’17，纽约，美国，2017 年。计算机协会。ISBN 9781450350754。doi: 10.1145/3098279.3098539。

+   Baughan 等人 [2023] Amanda Baughan, Xuezhi Wang, Ariel Liu, Allison Mercurio, Jilin Chen, 和 Xiao Ma. 了解语音助手故障后用户信任的混合方法。 在 *2023 年 CHI 人机交互系统会议论文集*，CHI ’23，纽约，美国，2023 年。计算机协会。ISBN 9781450394215。doi: 10.1145/3544548.3581152。

+   Luger 和 Sellen [2016] Ewa Luger 和 Abigail Sellen. “就像有一个非常糟糕的助理”：用户期望与对话代理体验之间的差距。在 *2016 年 CHI 人机交互系统会议论文集*，CHI ’16，第 5286–5297 页，纽约，美国，2016 年。计算机协会。ISBN 9781450333627。doi: 10.1145/2858036.2858288。

+   Hoy [2018] Matthew B. Hoy. Alexa、Siri、Cortana 等：语音助手简介。*医学参考服务季刊*，37(1)：81–88，2018 年。doi: 10.1080/02763869.2018.1404391。PMID: 29327988。

+   Li 等人 [2019] Yuanchun Li, Ziyue Yang, Yao Guo, 和 Xiangqun Chen. Humanoid：一种基于深度学习的自动化黑箱安卓应用测试方法。在 *2019 年第 34 届 IEEE/ACM 国际自动化软件工程会议（ASE）*，第 1070–1073 页。IEEE，2019 年。

+   Vaswani 等[2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, 和 Illia Polosukhin. 注意力即是你所需要的。在*第 31 届国际神经信息处理系统会议论文集*中，NIPS’17，第 6000–6010 页，Red Hook, NY, USA, 2017。Curran Associates Inc. ISBN 9781510860964。

+   He 等[2020] Zecheng He, Srinivas Sunkara, Xiaoxue Zang, Ying Xu, Lijuan Liu, Nevan Wichers, Gabriel Schubiner, Ruby B. Lee, 和 Jindong Chen. Actionbert: 利用用户行为进行用户界面的语义理解。在*AAAI 人工智能会议*中，2020。

+   Fu 等[2021] Jingwen Fu, Xiaoyi Zhang, Yuwang Wang, Wenjun Zeng, Sam Yang, 和 Grayson Hilliard. 理解移动 GUI: 从像素词到屏幕句子。*ArXiv*，abs/2105.11941，2021。网址 [`api.semanticscholar.org/CorpusID:235187035`](https://api.semanticscholar.org/CorpusID:235187035)。

+   Li 等[2021] Yang Li, Gang Li, Xin Zhou, Mostafa Dehghani, 和 Alexey A. Gritsenko. Vut: 多模态多任务用户界面建模的多功能 UI 变换器。*ArXiv*，abs/2112.05692，2021。

+   Bai 等[2021] Chongyang Bai, Xiaoxue Zang, Ying Xu, Srinivas Sunkara, Abhinav Rastogi, Jindong Chen, 和 Blaise Agüera y Arcas. Uibert: 学习用于 UI 理解的通用多模态表示。在*第 30 届国际人工智能联合会议论文集，IJCAI-21*中，第 1705–1712 页。国际人工智能联合会议组织，2021 年 8 月。doi: 10.24963/ijcai.2021/235。主要轨道。

+   Li 和 Li[2022] Gang Li 和 Yang Li. Spotlight: 使用视觉-语言模型的移动 UI 理解。*ArXiv*，abs/2209.14927，2022。

+   Banerjee 等[2023] Pratyay Banerjee, Shweti Mahajan, Kushal Arora, Chitta Baral, 和 Oriana Riva. Lexi: UI 语言的自监督学习。*ArXiv*，abs/2301.10165，2023。

+   Li 等[2023a] Wei Li, Fu-Lin Hsu, Will Bishop, Folawiyo Campbell-Ajala, Oriana Riva, 和 Max Lin. Uinav: 一个 UI 自动化代理的创建者。*arXiv 预印本 arXiv:2312.10170*，2023a。

+   Shi 等[2017] Tianlin Tim Shi, Andrej Karpathy, Linxi Jim Fan, Jonathan Hernandez, 和 Percy Liang. Bits 的世界: 一个开放领域的网页代理平台。在*第 34 届国际机器学习会议 - 第 70 卷*中，ICML’17，第 3135–3144 页。JMLR.org，2017。

+   Gur 等[2018] Izzeddin Gur, Ulrich Rückert, Aleksandra Faust, 和 Dilek Z. Hakkani-Tür. 学习导航网页。*ArXiv*，abs/1812.09195，2018。

+   Jia 等[2019] Sheng Jia, Jamie Ryan Kiros, 和 Jimmy Ba. Dom-q-net: 结构化语言上的有监督强化学习。*ArXiv*，abs/1902.07257，2019。

+   Humphreys 等人 [2022] Peter C Humphreys, David Raposo, Tobias Pohlen, Gregory Thornton, Rachita Chhaparia, Alistair Muldal, Josh Abramson, Petko Georgiev, Adam Santoro, 和 Timothy Lillicrap. 一种基于数据驱动的计算机控制学习方法. 见于 *国际机器学习会议*，第 9466–9482 页。PMLR，2022。

+   Kaplan 等人 [2020] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, 和 Dario Amodei. 神经语言模型的规模定律, 2020。

+   Ouyang 等人 [2022] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, 和 Ryan Lowe. 训练语言模型以跟随指令与人类反馈, 2022。

+   Christiano 等人 [2023] Paul Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, 和 Dario Amodei. 基于人类偏好的深度强化学习, 2023。

+   Schick 等人 [2023] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, 和 Thomas Scialom. Toolformer: 语言模型可以自学使用工具, 2023。

+   Nakano 等人 [2022] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, 和 John Schulman. Webgpt: 浏览器辅助的问题回答与人类反馈, 2022。

+   Furuta 等人 [2023] Hiroki Furuta, Ofir Nachum, Kuang-Huei Lee, Yutaka Matsuo, Shixiang Shane Gu, 和 Izzeddin Gur. 基于指令微调的基础模型进行多模态网页导航. *ArXiv*，abs/2305.11854，2023。

+   Singh 等人 [2023] Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, 和 Animesh Garg. Progprompt: 使用大语言模型生成情境化的机器人任务计划. 见于 *2023 IEEE 国际机器人与自动化大会 (ICRA)*，第 11523–11530 页。IEEE，2023。

+   Zhen 等人 [2023] Yue Zhen, Sheng Bi, Lu Xing-tong, Pan Wei-qin, Shi Hai-peng, Chen Zi-rui, 和 Fang Yi-shu. 基于大语言模型和有向图结构表示知识的机器人任务规划, 2023。

+   Huang 等人 [2022a] Wenlong Huang, Pieter Abbeel, Deepak Pathak, 和 Igor Mordatch. 语言模型作为零-shot 规划器: 提取具身体代理的可操作知识, 2022a。

+   Shen 等人 [2023] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, 和 Yueting Zhuang. Hugginggpt: 使用 ChatGPT 及其在 Hugging Face 中的朋友解决 AI 任务, 2023。

+   Wang et al. [2023a] Ke Wang, Houxing Ren, Aojun Zhou, Zimu Lu, Sichun Luo, Weikang Shi, Renrui Zhang, Linqi Song, Mingjie Zhan, 和 Hongsheng Li. MathCoder：LLMs 中无缝代码集成以增强数学推理。*ArXiv*，abs/2310.03731，2023a。

+   Rozière et al. [2023] Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, I. Evtimov, Joanna Bitton, Manish P Bhatt, Cristian Cantón Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre D’efossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, 和 Gabriel Synnaeve. Code Llama：用于代码的开源基础模型。*ArXiv*，abs/2308.12950，2023 年。

+   Zhou et al. [2023a] Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, 和 Hongsheng Li. 使用 GPT-4 代码解释器和基于代码的自我验证解决具有挑战性的数学文字问题，2023a。

+   OpenAI [2023] OpenAI. GPT-4 技术报告，2023 年。

+   Microsoft [2023c] Microsoft. 通过全新的 AI 驱动的 Microsoft Bing 和 Edge 重新定义搜索，成为您的网页副驾驶。 [`blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/`](https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/), 2023c. [在线；访问日期：2023 年 12 月 8 日]。

+   Google [2023b] Google. Bard：Google 的对话 AI 工具。 [`bard.google.com`](https://bard.google.com), 2023b. [在线；访问日期：2023 年 12 月 26 日]。

+   Google [2023c] Google. 介绍 gemini：我们最大、最强大的 AI 模型。 [`blog.google/technology/ai/google-gemini-ai/`](https://blog.google/technology/ai/google-gemini-ai/), 2023c. [在线；访问日期：2023 年 12 月 26 日]。

+   Huawei [2023] Huawei. 通过 AI 重新塑造行业：Huawei Cloud 推出 Pangu 模型 3.0 和 Ascend AI 云服务。 [`www.huaweicloud.com/intl/en-us/news/20230707180809498.html`](https://www.huaweicloud.com/intl/en-us/news/20230707180809498.html), 2023. [在线；访问日期：2023 年 11 月 28 日]。

+   XiaoMi [2023] XiaoMi. MiLM-6B。 [`github.com/XiaoMi/MiLM-6B`](https://github.com/XiaoMi/MiLM-6B), 2023. [在线；访问日期：2023 年 12 月 24 日]。

+   Bokhari [1995] Sayed Naem Bokhari. Linux 操作系统。*Computer*，28(8):74–79，1995 年。

+   Wikipedia [2023b] Wikipedia. Borda 计数。 [`en.wikipedia.org/wiki/Borda_count`](https://en.wikipedia.org/wiki/Borda_count), 2023b. [在线；访问日期：2023 年 12 月 13 日]。

+   Li [2022] Jinyu Li. 端到端自动语音识别的近期进展，2022 年。

+   Prabhavalkar et al. [2023] Rohit Prabhavalkar, Takaaki Hori, Tara N. Sainath, Ralf Schlüter, 和 Shinji Watanabe. 端到端语音识别：综述，2023 年。

+   Wang et al. [2023b] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Ji-Rong Wen. 关于基于大型语言模型的自主代理的综述，2023b。

+   Xi et al. [2023] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, and Tao Gui. 基于大型语言模型的代理的兴起与潜力：一项综述，2023。

+   Zhang et al. [2023a] Zhuosheng Zhang, Yao Yao, Aston Zhang, Xiangru Tang, Xinbei Ma, Zhiwei He, Yiming Wang, Mark Gerstein, Rui Wang, Gongshen Liu, and Hai Zhao. 激发语言智能：从链式思维推理到语言代理的指南，2023a。

+   Young et al. [2013] Steve Young, Milica Gašić, Blaise Thomson, and Jason D. Williams. 基于 Pomdp 的统计语音对话系统：回顾。*IEEE 会议录*，101(5)：1160–1179，2013。doi: 10.1109/JPROC.2012.2225812。

+   Rastogi et al. [2018] Abhinav Rastogi, Raghav Gupta, and Dilek Hakkani-Tur. 联合语言理解与对话状态跟踪的多任务学习。在*第 19 届年度 SIGdial 对话与对话会议论文集*中，第 376–384 页，澳大利亚墨尔本，2018 年 7 月。计算语言学协会。doi: 10.18653/v1/W18-5045。

+   Li and Riva [2018] Toby Jia-Jun Li and Oriana Riva. Kite: 从移动应用构建对话机器人。在*第 16 届年度国际移动系统、应用和服务会议论文集*中，MobiSys ’18，第 96–109 页，美国纽约，2018。计算机协会。ISBN 9781450357203。doi: 10.1145/3210240.3210339。

+   Li et al. [2017b] Toby Jia-Jun Li, Amos Azaria, and Brad A. Myers. Sugilite: 通过示范创建多模态智能手机自动化。在*2017 年 CHI 计算机系统人因会议论文集*中，CHI ’17，第 6038–6049 页，美国纽约，2017b。计算机协会。ISBN 9781450346559。doi: 10.1145/3025453.3025483。

+   Lee et al. [2023a] Sang-Woo Lee, Sungdong Kim, Donghyeon Ko, Donghoon Ham, Youngki Hong, Shin Ah Oh, Hyunhoon Jung, Wangkyo Jung, Kyunghyun Cho, Donghyun Kwak, Hyungsuk Noh, and Woomyoung Park. 目前任务导向对话模型能否在实际场景中实现自动化？2023a。

+   Chung et al. [2023] Willy Chung, Samuel Cahyawijaya, Bryan Wilie, Holy Lovenia, and Pascale Fung. Instructtods: 用于端到端任务导向对话系统的大型语言模型，2023。

+   Hu et al. [2023a] Zhiyuan Hu, Yue Feng, Yang Deng, Zekun Li, See-Kiong Ng, Anh Tuan Luu, and Bryan Hooi. 通过前瞻性动机目标增强大型语言模型引发的任务导向对话系统，2023a。

+   Hudeček 和 Dušek [2023] Vojtěch Hudeček 和 Ondřej Dušek. 大型语言模型是否足以应对任务导向的对话？，2023。

+   Hu 等 [2023b] Zhiyuan Hu, Yue Feng, Anh Tuan Luu, Bryan Hooi, 和 Aldo Lipani. 解锁用户反馈的潜力：利用大型语言模型作为用户模拟器来增强对话系统。见 *第 32 届 ACM 国际信息与知识管理会议论文集*，CIKM ’23，第 3953–3957 页，美国纽约，2023b。计算机协会。ISBN 9798400701245。doi: 10.1145/3583780.3615220。

+   Brown 等 [2020] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, 和 Dario Amodei. 语言模型是少量示例学习者，2020。

+   Microsoft [2023d] Microsoft. Bing 网络搜索 API。 [`www.microsoft.com/en-us/bing/apis/bing-web-search-api`](https://www.microsoft.com/en-us/bing/apis/bing-web-search-api)，2023d。

+   Patil 等 [2023] Shishir G. Patil, Tianjun Zhang, Xin Wang, 和 Joseph E. Gonzalez. Gorilla：与海量 API 连接的大型语言模型。*arXiv 预印本 arXiv:2305.15334*，2023。

+   Yang 等 [2023a] Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu Li, 和 Ying Shan. Gpt4tools：通过自我指导教大型语言模型使用工具，2023a。

+   Qin 等 [2023a] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, 和 Maosong Sun. Toolllm：帮助大型语言模型掌握 16000+ 实际应用程序接口，2023a。

+   Chen 和 Li [2024] Wei Chen 和 Zhiyuan Li. Octopus v2：用于超级代理的设备内语言模型。*arXiv 预印本 arXiv:2404.01744*，2024。

+   Wei 等 [2022a] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le, 和 Denny Zhou. 思维链提示引发大型语言模型的推理。见 *神经信息处理系统进展*，第 35 卷，第 24824–24837 页。Curran Associates, Inc.，2022a。

+   Yao 等 [2023a] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, 和 Karthik Narasimhan. 思维树：使用大型语言模型进行深思熟虑的问题解决。*arXiv 预印本 arXiv:2305.10601*，2023a。

+   Karpas 等人 [2022] Ehud Karpas、Omri Abend、Yonatan Belinkov、Barak Lenz、Opher Lieber、Nir Ratner、Yoav Shoham、Hofit Bata、Yoav Levine、Kevin Leyton-Brown、Dor Muhlgay、Noam Rozen、Erez Schwartz、Gal Shachaf、Shai Shalev-Shwartz、Amnon Shashua 和 Moshe Tenenholtz。MRKL 系统：一个模块化的神经符号架构，结合了大型语言模型、外部知识源和离散推理，2022。

+   Li 等人 [2023b] Guohao Li、Hasan Abed Al Kader Hammoud、Hani Itani、Dmitrii Khizbullin 和 Bernard Ghanem。Camel：用于“大规模语言模型社会”中的“心智”探索的交流代理，2023b。

+   Kim 等人 [2023a] Geunwoo Kim、Pierre Baldi 和 Stephen Marcus McAleer。语言模型可以解决计算机任务。发表于 *第三十七届神经信息处理系统会议*，2023a。

+   Lu 等人 [2023] Pan Lu、Baolin Peng、Hao Cheng、Michel Galley、Kai-Wei Chang、Ying Nian Wu、Song-Chun Zhu 和 Jianfeng Gao。Chameleon：使用大型语言模型进行即插即用的组合推理。发表于 *第 37 届神经信息处理系统会议（NeurIPS）*，2023。

+   Hao 等人 [2023] Shibo Hao、Tianyang Liu、Zhen Wang 和 Zhiting Hu。ToolkenGPT：通过工具嵌入增强冻结的语言模型。发表于 *第三十七届神经信息处理系统会议*，2023。

+   Wang 等人 [2023c] Bryan Wang、Gang Li 和 Yang Li。利用大型语言模型实现移动用户界面的对话交互。发表于 *2023 CHI 人机交互系统会议论文集*，CHI ’23，纽约，NY，美国，2023c。计算机协会。ISBN 9781450394215。doi: 10.1145/3544548.3580895。

+   Wen 等人 [2023a] Hao Wen、Hongming Wang、Jiaxuan Liu 和 Yuanchun Li。Droidbot-gpt：用于 Android 的 GPT 驱动 UI 自动化。*arXiv 预印本 arXiv:2304.07061*，2023a。

+   Deng 等人 [2023] Xiang Deng、Yu Gu、Boyuan Zheng、Shijie Chen、Samuel Stevens、Boshi Wang、Huan Sun 和 Yu Su。Mind2web：面向 Web 的通用代理，2023。

+   Wen 等人 [2023b] Hao Wen、Yuanchun Li、Guohong Liu、Shanhui Zhao、Tao Yu、Toby Jia-Jun Li、Shiqi Jiang、Yunhao Liu、Yaqin Zhang 和 Yunxin Liu。赋能大型语言模型使用智能手机进行智能任务自动化。*arXiv 预印本 arXiv:2308.15272*，2023b。

+   Taeb 等人 [2023] Maryam Taeb、Amanda Swearngin、Eldon Schoop、Ruijia Cheng、Yue Jiang 和 Jeffrey Nichols。Axnav：从自然语言重放无障碍测试，2023。

+   Lee 等人 [2023b] Sunjae Lee、Junyoung Choi、Jungjae Lee、Hojun Choi、Steven Y. Ko、Sangeun Oh 和 Insik Shin。探索、选择、推导和回忆：通过类人记忆增强大型语言模型以进行移动任务自动化。*arXiv 预印本 arXiv:2312.03003*，2023b。

+   Sun 等人 [2022] Liangtai Sun、Xingyu Chen、Lu Chen、Tianle Dai、Zichen Zhu 和 Kai Yu。Meta-gui：面向移动 GUI 的多模态对话代理。*arXiv 预印本 arXiv:2205.11029*，2022。

+   He et al. [2021] Zecheng He、Srinivas Sunkara、Xiaoxue Zang、Ying Xu、Lijuan Liu、Nevan Wichers、Gabriel Schubiner、Ruby Lee 和 Jindong Chen。Actionbert：利用用户操作来实现对用户界面的语义理解。*Proceedings of the AAAI Conference on Artificial Intelligence*，35(7)：5931–5938，2021 年 5 月。doi: 10.1609/aaai.v35i7.16741。网址 [`ojs.aaai.org/index.php/AAAI/article/view/16741`](https://ojs.aaai.org/index.php/AAAI/article/view/16741)。

+   Zhang et al. [2023b] Zhizheng Zhang、Xiaoyi Zhang、Wenxuan Xie 和 Yan Lu。负责任的任务自动化：赋能大型语言模型作为负责任的任务自动化者，2023b。

+   Zhang et al. [2023c] Zhizheng Zhang、Wenxuan Xie、Xiaoyi Zhang 和 Yan Lu。增强的用户界面指令基础：朝着通用的用户界面任务自动化 API 迈进。*ArXiv*，abs/2310.04716，2023c。

+   Zhan and Zhang [2023] Zhuosheng Zhan 和 Aston Zhang。你只看屏幕：多模态行动链代理。*arXiv preprint arXiv:2309.11436*，2023。

+   Shaw et al. [2023] Peter Shaw、Mandar Joshi、James Cohan、Jonathan Berant、Panupong Pasupat、Hexiang Hu、Urvashi Khandelwal、Kenton Lee 和 Kristina Toutanova。从像素到用户界面操作：通过图形用户界面学习跟随指令。在*第三十七届神经信息处理系统会议*，2023。网址 [`openreview.net/forum?id=3PjCt4kmRx`](https://openreview.net/forum?id=3PjCt4kmRx)。

+   Xie et al. [2024] Tianbao Xie、Danyang Zhang、Jixuan Chen、Xiaochuan Li、Siheng Zhao、Ruisheng Cao、Toh Jing Hua、Zhoujun Cheng、Dongchan Shin、Fangyu Lei 等。OSWorld：在真实计算机环境中对开放任务的多模态代理进行基准测试。*arXiv preprint arXiv:2404.07972*，2024。

+   Yan et al. [2023] An Yan、Zhengyuan Yang、Wanrong Zhu、Kevin Lin、Linjie Li、Jianfeng Wang、Jianwei Yang、Yiwu Zhong、Julian McAuley、Jianfeng Gao 等。GPT-4V 在奇幻世界中：用于零样本智能手机 GUI 导航的大型多模态模型。*arXiv preprint arXiv:2311.07562*，2023。

+   Zhang et al. [2023d] Chi Zhang、Zhao Yang、Jiaxuan Liu、Yucheng Han、Xin Chen、Zebiao Huang、Bin Fu 和 Gang Yu。Appagent：作为智能手机用户的多模态代理，2023d。

+   Zheng et al. [2024a] Boyuan Zheng、Boyu Gou、Jihyung Kil、Huan Sun 和 Yu Su。GPT-4V（ision）是一个通用的网络代理，前提是要进行基础化。*arXiv preprint arXiv:2401.01614*，2024a。

+   Gao et al. [2023a] Difei Gao、Lei Ji、Zechen Bai、Mingyu Ouyang、Peiran Li、Dongxing Mao、Qinchen Wu、Weichen Zhang、Peiyi Wang、Xiangwu Guo、Hengxu Wang、Luowei Zhou 和 Mike Zheng Shou。Assistgui：面向任务的桌面图形用户界面自动化，2023a。

+   Hong et al. [2023a] Wenyi Hong、Weihan Wang、Qingsong Lv、Jiazheng Xu、Wenmeng Yu、Junhui Ji、Yan Wang、Zihan Wang、Yuxuan Zhang、Juanzi Li、Bin Xu、Yuxiao Dong、Ming Ding 和 Jie Tang。Cogagent：用于 GUI 代理的视觉语言模型，2023a。

+   Cheng 等人[2024] 成侃之，孙秋实，储幽岡，许方智，李燕涛，张建兵和吴志勇。seeclick:利用 gui 的基础性视觉 gui 代理。*arXiv 预印本 arXiv:2401.10935*，2024 年。

+   You 等人[2024] 尹恳，张浩天，艾尔顿·施乌普，弗洛里斯·维尔斯，阿曼达·斯韦尔金，杰弗里·尼古拉斯，杨音飞和甘喆。ferret-ui:基于多模式 llms 的地面移动 ui 理解。*arXiv 预印本 arXiv:2404.05719*，2024 年。

+   Cheng 等人[2023]成思捷，郭志成，吴靖雯，方克臣，李鹏，刘华平和刘扬。视觉语言模型是否可以从第一人称角度思考？，2023 年。

+   Weng [2023] Lilian Weng。Llm 支持的自主代理。[`lilianweng.github.io/posts/2023-06-23-agent/`](https://lilianweng.github.io/posts/2023-06-23-agent/)，2023 年。

+   aut [2023] Autogpt。[`github.com/Significant-Gravitas/AutoGPT`](https://github.com/Significant-Gravitas/AutoGPT)，2023 年。

+   lan [2023] Langchain。[`github.com/langchain-ai/langchain`](https://github.com/langchain-ai/langchain)，2023 年。

+   bab [2023] Babyagi。[`github.com/yoheinakajima/babyagi`](https://github.com/yoheinakajima/babyagi)，2023 年。

+   Osika [2023] 安东·奥西卡。GPT 工程师。[`github.com/AntonOsika/gpt-engineer`](https://github.com/AntonOsika/gpt-engineer)，2023 年。

+   Chen 等人[2023a]陈光耀，董思炜，舒瑜，张各，Sesay Jaward，卡尔森·博尔杰，傅杰和史业民。autoagents:自动生成代理的框架。*arXiv 预印本*，2023 年。

+   Xie 等人[2023]谢天宝，周凡，程洲军，史鹏，翁洛轩，刘一涛，Toh Jing Hua，赵钧宁，刘倩，刘彻，刘泽驹，徐伊恒，苏宏晋，辛东蝉，熊才明和于涛。openagents:一种野外语言代理的开放平台，2023 年。

+   KillianLucas [2023] 基利安·卢卡斯。开放解释器。[`github.com/KillianLucas/open-interpreter`](https://github.com/KillianLucas/open-interpreter)，2023 年。

+   Liu [2022] 刘嘉瑞。LlamaIndex, 2022 年 11 月。URL [`github.com/jerryjliu/llama_index`](https://github.com/jerryjliu/llama_index)。

+   Taranjeet Singh [2023] 德什拉吉亚德·塔兰吉特辛格。Embedchain:llms 的数据平台-加载、索引、检索和同步任何非结构化数据。[`github.com/embedchain/embedchain`](https://github.com/embedchain/embedchain)，2023 年。

+   Zhou 等人[2023b]周旺春树，姜玉琛·姜玉琛，李龙，吴嘉龙，王天南，邱士，张津，陈静，吴瑞璞，王帅，朱世定，陈继玉，张文涛，张柠，陈华俊，崔鹏和梅林·萨昌。代理：用于自主语言代理的开源框架，2023 年 b。

+   Hong 等人[2023b]洪思锐，诸葛明晨，陈杰强，郑夏武，程育恒，张策瑶，王津麟，王子立，叶守胜尧·叶炜正，蓝与洲，周立阳·周立阳，冉晨宇，肖凌峰，吴成琳和尤尔根·施密德胡贝尔。metagpt:多人合作框架的元编程，2023 年 b。

+   Wu et al. [2023a] 吴庆云、加根·班萨尔、张杰宇、吴怡然、张少坤、朱尔康、李贝宾、姜丽、小云张、王驰。Autogen: 通过多代理对话框架实现下一代大型语言模型应用。*arXiv 预印本 arXiv:2308.08155*，2023a 年。

+   Huang et al. [2023] 黄福瑞、李刚、李涛、李杨。大规模互动踪迹中的自动宏挖掘，2023 年。

+   Toyama et al. [2021] 托亚马·丹尼尔、菲利普·哈梅尔、安妮塔·格尔吉、乔治·科曼尼奇、阿梅利亚·格莱斯、扎法拉利·艾哈迈德、泰勒·杰克逊、希布尔·穆拉德、德伊娜·普雷库普。Androidenv: 一个用于 Android 的强化学习平台。*arXiv 预印本 arXiv:2105.13231*，2021 年。

+   Zhang et al. [2023e] 张丹阳、陈璐、赵紫涵、曹瑞生、余凯。Mobile-Env: 一个用于互动代理的评估平台和基准。*CoRR*，abs/2305.08144，2023e 年。

+   Pasupat et al. [2018] 帕努蓬·帕苏帕特、姜天顺、埃文·刘、凯尔文·古、帕西·梁。将自然语言命令映射到网页元素。在*2018 年自然语言处理实证方法会议论文集*，第 4970-4976 页，比利时布鲁塞尔，2018 年 10-11 月。计算语言学协会。doi: 10.18653/v1/D18-1540。

+   Burns et al. [2022] 安德里亚·伯恩斯、德尼兹·阿尔桑、桑杰纳·阿格拉瓦尔、兰吉塔·库马尔、凯特·塞恩科、布赖恩·A·普拉默。一个用于交互式视觉语言导航的数据集，具有未知命令可行性。在*欧洲计算机视觉会议 (ECCV)*，2022 年。

+   Venkatesh et al. [2023] 萨加尔·古比·维克特斯、帕尔塔·塔卢克达尔、斯里尼·纳拉延。Ugif: UI 基础指令跟随，2023 年。

+   Rawles et al. [2023] 克里斯托弗·劳尔斯、爱丽丝·李、丹尼尔·罗德里格斯、奥里安娜·里瓦、蒂莫西·利利克拉普。野外中的 Android: 一个大规模的 Android 设备控制数据集，2023 年。

+   Kapoor et al. [2024] 拉赫伽夫·卡普尔、亚什·帕拉格·布塔拉、梅丽莎·鲁萨克、京·余·科赫、基兰·坎布尔、瓦西姆·阿尔希克、鲁斯兰·萨拉胡丁诺夫。Omniact: 一个数据集和基准，用于支持多模态通用自主代理在桌面和网页上的应用。*arXiv 预印本 arXiv:2402.17553*，2024 年。

+   Lai et al. [2024] 莱汉宇、刘晓、杨兆龙、姚顺天、陈宇轩、沈鹏博、余浩、张汉晨、张晓寒、董玉晓等。Autowebglm: 引导和强化基于大型语言模型的网页导航代理。*arXiv 预印本 arXiv:2404.03648*，2024 年。

+   Liu et al. [2024a] 刘俊鹏、宋逸凡、林玉晨、林伟、格雷厄姆·纽比格、李元智、岳翔。Visualwebbench: 多模态大型语言模型在网页理解和基础定位中的进展如何？*arXiv 预印本 arXiv:2404.05955*，2024a 年。

+   Niu et al. [2024] 任良牛、李金东、王世奇、傅雅丽、胡希宇、冷雪苑、孔赫、常一、王琦。Screenagent: 一种基于视觉语言模型的计算机控制代理。*arXiv 预印本 arXiv:2402.07945*，2024 年。

+   Yao 等人 [2022a] Shunyu Yao, Howard Chen, John Yang 和 Karthik Narasimhan. Webshop: 朝着可扩展的现实世界网络互动与基础语言代理的方向发展。发表于 *神经信息处理系统进展*，第 35 卷，第 20744–20757 页。Curran Associates, Inc., 2022a。

+   Zhou 等人 [2023c] Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon 等人. Webarena: 一个用于构建自主代理的真实网络环境。*arXiv 预印本 arXiv:2307.13854*，2023c。

+   Zheng 等人 [2024b] Longtao Zheng, Zhiyuan Huang, Zhenghai Xue, Xinrun Wang, Bo An 和 Shuicheng Yan. Agentstudio: 一个用于构建通用虚拟代理的工具包。*arXiv 预印本 arXiv:2403.17918*，2024b。

+   Breda 等人 [2023] Joseph Breda, Mastafa Springston, Alex Mariakakis 和 Shwetak Patel. Feverphone: 使用普通智能手机进行发烧监测的核心体温传感技术。*ACM 交互、移动、可穿戴和无处不在技术会议录*，7(1):1–23，2023。

+   Chhaglani 等人 [2022] Bhawana Chhaglani, Camellia Zakaria, Adam Lechowicz, Jeremy Gummeson 和 Prashant Shenoy. Flowsense: 使用音频传感监测建筑通风系统中的气流。*ACM 交互、移动、可穿戴和无处不在技术会议录*，6(1):1–26，2022。

+   Hu 等人 [2023c] Yongquan Hu, Hui-Shyong Yeo, Mingyue Yuan, Haoran Fan, Don Samitha Elvitigala, Wen Hu 和 Aaron Quigley. Microcam: 利用智能手机显微镜相机进行上下文感知的接触面传感。*ACM 交互、移动、可穿戴和无处不在技术会议录*，7(3):1–28，2023c。

+   Hu 等人 [2023d] Jingzhi Hu, Tianyue Zheng, Zhe Chen, Hongbo Wang 和 Jun Luo. Muse-fi: 利用近场 Wi-Fi 信道变化进行无接触多人感知。发表于 *第 29 届年度国际移动计算与网络会议*，第 1–15 页，2023d。

+   Gong 等人 [2021] Jian Gong, Xinyu Zhang, Yuanjun Huang, Ju Ren 和 Yaoxue Zhang. 通过深度传感器融合在智能耳机和智能手机之间实现鲁棒的惯性运动跟踪。*ACM 交互、移动、可穿戴和无处不在技术会议录*，5(2):1–26，2021。

+   Arrotta 等人 [2022] Luca Arrotta, Gabriele Civitarese 和 Claudio Bettini. Dexar: 在智能家居环境中基于传感器的深度可解释活动识别。*ACM 交互、移动、可穿戴和无处不在技术会议录*，6(1):1–30，2022。

+   Ji 等人 [2024] Sijie Ji, Xinzhe Zheng 和 Chenshu Wu. Hargpt: 大型语言模型是否能进行零样本人类活动识别？*arXiv 预印本 arXiv:2403.02727*，2024。

+   Yang 等人 [2024] Huanqi Yang, Sijie Ji, Rucheng Wu 和 Weitao Xu. 你被跟踪了吗？发现利用大型语言模型进行零样本轨迹追踪的力量！*arXiv 预印本 arXiv:2403.06201*，2024。

+   Zhang et al. [2024a] Sha Zhang, Di Huang, Jiajun Deng, Shixiang Tang, Wanli Ouyang, Tong He, 和 Yanyong Zhang. Agent3d-zero: 一个用于零样本 3d 理解的代理。*arXiv 预印本 arXiv:2403.11835*，2024 年。

+   Zheng et al. [2024c] Zhisheng Zheng, Puyuan Peng, Ziyang Ma, Xie Chen, Eunsol Choi, 和 David Harwath. Bat: 学习通过大语言模型推理空间声音。*arXiv 预印本 arXiv:2402.01591*，2024 年。

+   Yang et al. [2023b] Senqiao Yang, Jiaming Liu, Ray Zhang, Mingjie Pan, Zoey Guo, Xiaoqi Li, Zehui Chen, Peng Gao, Yandong Guo, 和 Shanghang Zhang. Lidar-llm: 探索大语言模型在 3d lidar 理解中的潜力。*arXiv 预印本 arXiv:2312.14074*，2023 年。

+   Shao et al. [2023] Hao Shao, Yuxuan Hu, Letian Wang, Steven L Waslander, Yu Liu, 和 Hongsheng Li. Lmdrive: 使用大语言模型的闭环端到端驾驶。*arXiv 预印本 arXiv:2312.07488*，2023 年。

+   Duan et al. [2024] Yiqun Duan, Qiang Zhang, 和 Renjing Xu. 提示多模态令牌以增强端到端自动驾驶模仿学习与 llms。*arXiv 预印本 arXiv:2404.04869*，2024 年。

+   Wen et al. [2023c] Haoyang Wen, Zhenxin Xiao, Eduard Hovy, 和 Alexander G Hauptmann. 朝着开放域 Twitter 用户档案推断迈进。见于 *计算语言学协会会议论文集：ACL 2023*，第 3172–3188 页，2023 年。

+   Bianchi et al. [2016] Filippo Maria Bianchi, Antonello Rizzi, Alireza Sadeghian, 和 Corrado Moiso. 通过对通话记录进行数据挖掘来识别用户习惯。*人工智能工程应用*，54:49–61，2016 年。

+   Shin et al. [2023] Jaemin Shin, Hyungjun Yoon, Seungjoo Lee, Sungjoon Park, Yunxin Liu, Jinho D Choi, 和 Sung-Ju Lee. Fedtherapist: 利用用户生成的语言表达通过联邦学习进行心理健康监测。*arXiv 预印本 arXiv:2310.16538*，2023 年。

+   Hu et al. [2024] Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Tekin, Gaowen Liu, Ramana Kompella, 和 Ling Liu. 关于基于大语言模型的游戏代理的调查。*arXiv 预印本 arXiv:2404.02039*，2024 年。

+   Wampfler et al. [2022] Rafael Wampfler, Severin Klingler, Barbara Solenthaler, Victor R Schinazi, Markus Gross, 和 Christian Holz. 从智能手机触摸和传感器数据中预测情感状态。见于 *2022 年 CHI 人机交互系统会议论文集*，第 1–14 页，2022 年。

+   Chen et al. [2023b] Yu-Chun Chen, Yu-Jen Lee, Kuei-Chun Kao, Jie Tsai, En-Chi Liang, Wei-Chen Chiu, Faye Shih, 和 Yung-Ju Chang. 你在浪费时间吗？通过融合智能手机传感器数据和截图预测智能手机用户的时间消磨时刻。见于 *2023 年 CHI 人机交互系统会议论文集*，第 1–19 页，2023 年。

+   Ahmed 等 [2023] Tousif Ahmed、Md Mahbubur Rahman、Ebrahim Nemati、Mohsin Yusuf Ahmed、Jilong Kuang 和 Alex Jun Gao。使用耳机的运动和声学传感器进行静止位置的远程呼吸频率跟踪。在*2023 年 CHI 计算系统人因会议录*，第 1–22 页，2023 年。

+   Mollyn 等 [2022] Vimal Mollyn、Karan Ahuja、Dhruv Verma、Chris Harrison 和 Mayank Goel。Samosa：利用运动和下采样音频进行活动感知。*ACM 互动、移动、可穿戴和普及技术会议录*，6(3):1–19，2022 年。

+   Di Lascio 等 [2020] Elena Di Lascio、Shkurta Gashi、Juan Sebastian Hidalgo、Beatrice Nale、Maike E Debus 和 Silvia Santini。多传感器方法自动识别学术界知识工作者的休息和工作活动。*ACM 互动、移动、可穿戴和普及技术会议录*，4(3):1–20，2020 年。

+   Cui 等 [2023] Minhao Cui、Binbin Xie、Qing Wang 和 Jie Xiong。Dancingant：利用电力线的普遍辐射进行身体赋能的无线感应。在*第 29 届年度国际移动计算与网络会议录*，第 1–15 页，2023 年。

+   He 等 [2023] Yinghui He、Jianwei Liu、Mo Li、Guanding Yu、Jinsong Han 和 Kui Ren。Sencom：集成感应与通信的实用 wifi。在*第 29 届年度国际移动计算与网络会议录*，第 1–16 页，2023 年。

+   Zakaria 等 [2023] Camellia Zakaria、Gizem Yilmaz、Priyanka Mary Mammen、Michael Chee、Prashant Shenoy 和 Rajesh Balan。Sleepmore：通过多设备 wifi 感应推断大规模的睡眠时间。*ACM 互动、移动、可穿戴和普及技术会议录*，6(4):1–32，2023 年。

+   Wang 等 [2024] Qijun Wang、Shichen Zhang、Kunzhe Song 和 Huacheng Zeng。Chattracer：大型语言模型驱动的实时蓝牙设备跟踪系统。*arXiv 预印本 arXiv:2403.19833*，2024 年。

+   Zhao 等 [2023b] Xufeng Zhao、Mengdi Li、Cornelius Weber、Muhammad Burhan Hafez 和 Stefan Wermter。与环境聊天：使用大型语言模型的互动多模态感知。在*2023 年 IEEE/RSJ 国际智能机器人与系统会议（IROS）*，第 3590–3596 页。IEEE，2023b 年。

+   Darvish 等 [2024] Kourosh Darvish、Marta Skreta、Yuchi Zhao、Naruki Yoshikawa、Sagnik Som、Miroslav Bogdanovic、Yang Cao、Han Hao、Haoping Xu、Alán Aspuru-Guzik 等。Organa：一种用于自动化化学实验和表征的机器人助手。*arXiv 预印本 arXiv:2401.06949*，2024 年。

+   Gao 等 [2023b] Nan Gao、Zhuolei Yu、Chun Yu、Yuntao Wang、Flora D Salim 和 Yuanchun Shi。用于理解人类行为的自动化移动感应策略生成。*arXiv 预印本 arXiv:2311.05457*，2023b 年。

+   Samyoun 等 [2022] 西拉特·萨缪恩、Md·莫菲朱尔·伊斯兰、塔里克·伊克巴尔和约翰·斯坦科维奇。M3sense：使用多模态可穿戴传感器进行情感无关的多任务表示学习。*ACM 互动、移动、可穿戴和无处不在技术会议录*，6(2):1–32，2022 年。

+   Deldari 等 [2022] 肖赫雷·德尔达里、郝雪、阿基布·萨伊德、丹尼尔·V·史密斯和弗洛拉·D·萨利姆。Cocoa：用于传感器数据的跨模态对比学习。*ACM 互动、移动、可穿戴和无处不在技术会议录*，6(3):1–28，2022 年。

+   Abedin 等 [2021] 阿利雷扎·阿贝丁、玛赫莎·艾赫桑普尔、秦峰·施、哈米德·雷扎托菲吉和达米斯·C·拉纳辛赫。关注与区分：超越最先进的可穿戴传感器人体活动识别技术。*ACM 互动、移动、可穿戴和无处不在技术会议录*，5(1):1–22，2021 年。

+   Rashid 等 [2020] 哈伦·拉希德、桑贾娜·门杜、凯瑟琳·E·丹尼尔、米兰达·L·贝尔泽、贝瑟妮·A·蒂奇曼、梅赫迪·布赫赫巴和劳拉·E·巴恩斯。通过稀疏收集的移动传感器数据预测主观社会焦虑测量。*ACM 互动、移动、可穿戴和无处不在技术会议录*，4(3):1–24，2020 年。

+   Kim 等 [2022] 郑均·金、达-宋·吴、康博克·李和尚·吉·洪。基于手腕可穿戴传感器对重要特征的解释进行跌倒检测。见于*第 28 届国际移动计算与网络年会会议录*，页码 823–825，2022 年。

+   Xu 等 [2023] 俞韬·徐、李英·韩、莫·李和马尼·斯里瓦斯塔瓦。渗透 AI：让 LLMs 理解物理世界。*arXiv 预印本 arXiv:2310.09605*，2023 年。

+   Liu 等 [2013] 凯凯·刘、欣欣·刘和晓林·李。Guoguo：通过智能手机实现精细化室内定位。见于*第 11 届国际移动系统、应用与服务年会论文集*，页码 235–248，2013 年。

+   Chu 等 [2009] 塞琳娜·楚、施里坎特·纳拉扬和 C-C·杰伊·郭。具有时间-频率音频特征的环境声音识别。*IEEE 音频、语音和语言处理汇刊*，17(6):1142–1158，2009 年。

+   Chandrakala 和 Jayalakshmi [2019] S·钱德拉卡拉和 SL·贾雅拉克什米。用于自主监控的环境音频场景和声音事件识别：综述与比较研究。*ACM 计算调查（CSUR）*，52(3):1–34，2019 年。

+   Assi 等 [2023] 卡里姆·阿西、拉克马尔·梅加哈波拉、威廉·德罗兹、彼得·昆、阿玛利亚·德·戈岑、米里亚姆·比多利亚、萨莉·斯塔雷斯、乔治·加斯凯尔、阿尔坦格雷尔·查格纳、阿玛尔萨娜·甘博尔等。复杂的日常活动、国家级多样性和智能手机传感：丹麦、意大利、蒙古、巴拉圭和英国的研究。见于*2023 年 CHI 计算机系统人因会议录*，页码 1–23，2023 年。

+   Meegahapola 等人 [2023] Lakmal Meegahapola, William Droz, Peter Kun, Amalia De Götzen, Chaitanya Nutakki, Shyam Diwakar, Salvador Ruiz Correa, Donglei Song, Hao Xu, Miriam Bidoglia 等人. 移动感知基础的情绪推断模型的泛化与个性化：对八个国家大学生的分析。*ACM 互动、移动、可穿戴和无处不在技术会议论文集*，6(4):1–32, 2023。

+   Wang 等人 [2023d] Zhiyuan Wang, Maria A Larrazabal, Mark Rucker, Emma R Toner, Katharine E Daniel, Shashwat Kumar, Mehdi Boukhechba, Bethany A Teachman 和 Laura E Barnes. 从移动感知指标中检测社交情境，在与社交焦虑个体的虚拟互动中。*ACM 互动、移动、可穿戴和无处不在技术会议论文集*，7(3):1–26, 2023d。

+   Meegahapola 等人 [2021a] Lakmal Meegahapola, Florian Labhart, Thanh-Trung Phan 和 Daniel Gatica-Perez. 使用智能手机感知检查年轻成人的饮酒社交背景。*ACM 互动、移动、可穿戴和无处不在技术会议论文集*，5(3):1–26, 2021a。

+   Meegahapola 等人 [2021b] Lakmal Meegahapola, Salvador Ruiz-Correa, Viridiana del Carmen Robledo-Valero, Emilio Ernesto Hernandez-Huerfano, Leonardo Alvarez-Rivera, Ronald Chenu-Abente 和 Daniel Gatica-Perez. 再来一口？通过智能手机感知和自我报告推断大学生的食物消费水平。*ACM 互动、移动、可穿戴和无处不在技术会议论文集*，5(1):1–28, 2021b。

+   Liang 等人 [2023] Yuebing Liang, Yichao Liu, Xiaohan Wang 和 Zhan Zhao. 探索大型语言模型在公共事件下的人类移动预测。*arXiv 预印本 arXiv:2311.17351*，2023。

+   Su 等人 [2014] Xing Su, Hanghang Tong 和 Ping Ji. 使用智能手机传感器进行活动识别。*清华科技*，19(3):235–249, 2014。

+   Akther 等人 [2021] Sayma Akther, Nazir Saleheen, Mithun Saha, Vivek Shetty 和 Santosh Kumar. mteeth: 使用腕戴惯性传感器识别刷牙表面。*ACM 互动、移动、可穿戴和无处不在技术会议论文集*，5(2):1–25, 2021。

+   Cao 等人 [2022] Yetong Cao, Fan Li, Huijie Chen, Xiaochen Liu, Li Zhang 和 Yu Wang. 默默守护你的心脏：使用腕戴运动传感器进行连续心电图波形监测。*ACM 互动、移动、可穿戴和无处不在技术会议论文集*，6(3):1–29, 2022。

+   Lin 等人 [2020] Zongyu Lin, Shiqing Lyu, Hancheng Cao, Fengli Xu, Yuqiong Wei, Hanan Samet 和 Yong Li. Healthwalks: 通过移动数据感知精细化的个体健康状况。*ACM 互动、移动、可穿戴和无处不在技术会议论文集*，4(4):1–26, 2020。

+   Zhang et al. [2018] Xiao Zhang, Wenzhong Li, Xu Chen, 和 Sanglu Lu. Moodexplorer：通过智能手机传感器进行复合情感检测。*ACM 互动、移动、可穿戴及普适技术论文集*，1(4):1–30，2018 年。

+   Adler et al. [2021] Daniel A Adler, Vincent W-S Tseng, Gengmo Qi, Joseph Scarpa, Srijan Sen, 和 Tanzeem Choudhury. 识别压力韧性的移动感知指标。*ACM 互动、移动、可穿戴及普适技术论文集*，5(2):1–32，2021 年。

+   Kim et al. [2024] Yubin Kim, Xuhai Xu, Daniel McDuff, Cynthia Breazeal, 和 Hae Won Park. Health-llm：通过可穿戴传感器数据的健康预测的大语言模型。*arXiv 预印本 arXiv:2401.06866*，2024 年。

+   Lan et al. [2024] Xiaochong Lan, Yiming Cheng, Li Sheng, Chen Gao, 和 Yong Li. 利用大语言模型在社交媒体上检测抑郁。*arXiv 预印本 arXiv:2403.10750*，2024 年。

+   Lifelo et al. [2024] Zita Lifelo, Huansheng Ning, 和 Sahraoui Dhelim. 通过元训练和大语言模型的上下文学习调整心理健康预测任务。*arXiv 预印本 arXiv:2404.09045*，2024 年。

+   Wang et al. [2022a] Weichen Wang, Subigya Nepal, Jeremy F Huckins, Lessley Hernandez, Vlado Vojdanovski, Dante Mack, Jane Plomp, Arvind Pillai, Mikio Obuchi, Alex Dasilva 等. 第一代镜头：使用移动传感技术评估第一代大学生在大学首年的心理健康。*ACM 互动、移动、可穿戴及普适技术论文集*，6(2):1–32，2022a 年。

+   Wang et al. [2015] Rui Wang, Gabriella Harari, Peilin Hao, Xia Zhou, 和 Andrew T Campbell. Smartgpa：智能手机如何评估和预测大学生的学术表现。在*2015 ACM 国际联合会议论文集*，第 295–306 页，2015 年。

+   Gao et al. [2019] Nan Gao, Wei Shao, 和 Flora D Salim. 从身体活动强度预测个性特征。*Computer*，52(7):47–56，2019 年。

+   Nepal et al. [2020] Subigya Nepal, Shayan Mirjafari, Gonzalo J Martinez, Pino Audia, Aaron Striegel, 和 Andrew T Campbell. 使用移动传感检测信息工作者的职位晋升。*ACM 互动、移动、可穿戴及普适技术论文集*，4(3):1–28，2020 年。

+   Yürüten et al. [2014] Onur Yürüten, Jiyong Zhang, 和 Pearl HZ Pu. 基于移动传感器数据的日常活动对生活满意度的预测因素。在*SIGCHI 计算机系统人因会议论文集*，第 497–500 页，2014 年。

+   Wang et al. [2020a] Weichen Wang, Shayan Mirjafari, Gabriella Harari, Dror Ben-Zeev, Rachel Brian, Tanzeem Choudhury, Marta Hauser, John Kane, Kizito Masaba, Subigya Nepal 等. 社会感知：使用手机传感技术评估精神分裂症患者的社会功能。在*2020 CHI 计算机系统人因会议论文集*，第 1–15 页，2020a 年。

+   Guo et al. [2024] 郭志君、艾尔维娜·赖、约翰·希尔格·泰格森、约瑟夫·法林顿、托马斯·基恩和李克之。大语言模型在心理健康中的应用：系统评审。*arXiv 预印本 arXiv:2403.15401*，2024。

+   Wang et al. [2017a] 王锐、王伟辰、Min SH Aung、Dror Ben-Zeev、Rachel Brian、Andrew T Campbell、Tanzeem Choudhury、Marta Hauser、John Kane、Emily A Scherer 等。使用移动传感预测精神分裂症的症状轨迹。*Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies*，1(3):1–24，2017a。

+   Chatterjee et al. [2020] Soujanya Chatterjee、Alexander Moreno、Steven Lloyd Lizotte、Sayma Akther、Emre Ertin、Christopher P Fagundes、Cho Lam、James M Rehg、Neng Wan、David W Wetter 等。Smokingopp：使用移动传感器检测“吸烟机会”上下文。*Proceedings of the ACM on interactive, mobile, wearable and ubiquitous technologies*，4(1):1–26，2020。

+   Ouyang and Srivastava [2024] 欧小敏和曼尼·斯里瓦斯塔瓦。Llmsense：利用 LLMs 对时空传感器轨迹进行高级推理。*arXiv 预印本 arXiv:2403.19857*，2024。

+   Chen [2023] 郑晨。Palr：推荐系统中的个性化感知 LLMs。*arXiv 预印本 arXiv:2305.07622*，2023。

+   Zhang et al. [2023f] 温轩张、刘洪智、杜英鹏、朱晨、宋杨、朱恒舒和吴中海。弥合领域特定模型与通用 LLM 之间的信息差距以实现个性化推荐。*arXiv 预印本 arXiv:2311.03778*，2023f。

+   Sun et al. [2023a] 孙晓飞、李小雅、张圣宇、王舒赫、吴飞、李佳伟、张天伟和王国银。通过 LLM 谈判进行情感分析。*arXiv 预印本 arXiv:2311.01876*，2023a。

+   Abbasian et al. [2023] 马赫亚尔·阿巴西安、伊曼·阿齐米、阿米尔·M·拉赫马尼和拉梅什·贾因。对话式健康代理：个性化 LLM 驱动的代理框架。*arXiv 预印本 arXiv:2310.02374*，2023。

+   Gurrin et al. [2014] 卡瑟尔·古林、艾伦·F·斯密顿、艾登·R·多赫提 等。生活日志：个人大数据。*Foundations and Trends® in information retrieval*，8(1):1–125，2014。

+   Dodge and Kitchin [2007] 马丁·道奇和罗布·基钦。“即将到来的世界概述”：普及计算与遗忘的伦理。*Environment and planning B: planning and design*，34(3):431–445，2007。

+   Beddiar et al. [2020] 贾米拉·罗梅莎·贝迪亚尔、布拉希姆·尼尼、穆罕默德·萨博克鲁和阿卜德努尔·哈迪德。基于视觉的人类活动识别：综述。*Multimedia Tools and Applications*，79(41-42):30509–30555，2020。

+   Stachl et al. [2020] 克莱门斯·斯塔赫尔、奎·奥、拉莫娜·舒德尔、塞缪尔·D·戈斯林、加布里埃拉·M·哈拉里、丹尼尔·布施克、莎拉·泰雷斯·沃尔克尔、托比亚斯·舒维尔克、米歇尔·奥尔德梅耶、特蕾莎·乌尔曼 等。从手机收集的行为模式预测个性。*Proceedings of the National Academy of Sciences*，117(30):17680–17687，2020。

+   Majumder 等 [2017] Navonil Majumder, Soujanya Poria, Alexander Gelbukh, 和 Erik Cambria. 基于深度学习的文档建模用于从文本中检测个性。*IEEE Intelligent Systems*, 32(2):74–79, 2017。

+   Štajner 和 Yenikent [2020] Sanja Štajner 和 Seren Yenikent. 自动化个性检测的调查。在 *第 28 届国际计算语言学会议论文集*，页码 6284–6295, 2020。

+   Jaiswal 等 [2020] Akriti Jaiswal, A Krishnama Raju, 和 Suman Deb. 使用深度学习进行面部情感检测。在 *2020 新兴技术国际会议 (INCET)*，页码 1–5。IEEE, 2020。

+   Zad 等 [2021] Samira Zad, Maryam Heidari, H James Jr, 和 Ozlem Uzuner. 文本数据的情感检测：跨学科调查。在 *2021 IEEE 世界人工智能物联网大会 (AIIoT)*, 页码 0255–0261。IEEE, 2021。

+   Tang 等 [2019] Xiaoli Tang, Tengyun Wang, Haizhi Yang, 和 Hengjie Song. Akupm：基于注意力增强的知识感知用户偏好模型用于推荐。在 *第 25 届 ACM SIGKDD 国际知识发现与数据挖掘大会论文集*，页码 1891–1899, 2019。

+   Li 等 [2018] Yuanchun Li, Ziyue Yang, Yao Guo, Xiangqun Chen, Yuvraj Agarwal, 和 Jason I Hong. 从智能手机推送通知中自动提取个人知识。在 *2018 IEEE 大数据国际会议 (Big Data)*，页码 733–742。IEEE, 2018。

+   Singh 和 Solanki [2016] Garima Singh 和 Arun Solanki. 一种将自然语言转换为关系数据库中 SQL 查询的算法。*Selforganizology*, 3(3):100–116, 2016。

+   Lin 等 [2019] Kevin Lin, Ben Bogin, Mark Neumann, Jonathan Berant, 和 Matt Gardner. 基于语法的神经文本到 SQL 生成。*arXiv 预印本 arXiv:1905.13326*, 2019。

+   Li 等 [2017c] Yuanchun Li, Fanglin Chen, Toby Jia-Jun Li, Yao Guo, Gang Huang, Matthew Fredrikson, Yuvraj Agarwal, 和 Jason I Hong. Privacystreams：实现移动应用中的个人数据处理透明度。*Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies*, 1(3):76, 2017c。

+   Park 等 [2023] Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, 和 Michael S Bernstein. 生成代理：人类行为的互动模拟。 在 *第 36 届 ACM 用户界面软件与技术年度研讨会论文集*，页码 1–22, 2023。

+   Li 和 Qiu [2023] Xiaonan Li 和 Xipeng Qiu. MOT：Memory-of-Thought 使 ChatGPT 自我改进。在 *2023 年自然语言处理实证方法会议论文集*，页码 6354–6374, 2023。

+   Wang 等 [2023e] Weizhi Wang, Li Dong, Hao Cheng, Xiaodong Liu, Xifeng Yan, Jianfeng Gao, 和 Furu Wei. 通过长期记忆增强语言模型。*arXiv 预印本 arXiv:2306.07174*, 2023e。

+   Guo et al. [2023] Zhicheng Guo, Sijie Cheng, Yile Wang, Peng Li, 和 Yang Liu. 通过提示引导的检索增强用于非知识密集型任务。*arXiv 预印本 arXiv:2305.17653*，2023 年。

+   Nye et al. [2021] Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, 等等。展示你的工作：用于中间计算的语言模型的草稿板。*arXiv 预印本 arXiv:2112.00114*，2021 年。

+   Sumers et al. [2023] Theodore Sumers, Shunyu Yao, Karthik Narasimhan, 和 Thomas L Griffiths. 语言代理的认知架构。*arXiv 预印本 arXiv:2309.02427*，2023 年。

+   Yao et al. [2022b] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, 和 Yuan Cao. React：在语言模型中协同推理和行动。*arXiv 预印本 arXiv:2210.03629*，2022 年。

+   Peng et al. [2023] Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, 等等。检查你的事实并重试：通过外部知识和自动反馈改进大型语言模型。*arXiv 预印本 arXiv:2302.12813*，2023 年。

+   Tuyls et al. [2022] Jens Tuyls, Shunyu Yao, Sham Kakade, 和 Karthik Narasimhan. 用于战略探索的多阶段情节控制在文本游戏中。*arXiv 预印本 arXiv:2201.01251*，2022 年。

+   Yao et al. [2020] Shunyu Yao, Rohan Rao, Matthew Hausknecht, 和 Karthik Narasimhan. 保持冷静并探索：用于文本游戏中的动作生成的语言模型。*arXiv 预印本 arXiv:2010.02903*，2020 年。

+   Borgeaud et al. [2022] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, 等等。通过从万亿个标记中检索来改进语言模型。在 *国际机器学习会议*，页码 2206–2240。PMLR，2022 年。

+   Lewis et al. [2020] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, 等等。用于知识密集型 NLP 任务的检索增强生成。*神经信息处理系统进展*，33:9459–9474，2020 年。

+   Zhao et al. [2022] Wenjia Joyce Zhao, Russell Richie, 和 Sudeep Bhatia. 记忆中的决策过程和内容。*心理学评论*，129(1):73，2022 年。

+   Hanjie et al. [2021] Austin W Hanjie, Victor Y Zhong, 和 Karthik Narasimhan. 语言与实体和动态的基础以用于强化学习中的泛化。在 *国际机器学习会议*，页码 4051–4062。PMLR，2021 年。

+   Parakh et al. [2023] Meenal Parakh, Alisha Fong, Anthony Simeonov, Abhishek Gupta, Tao Chen, 和 Pulkit Agrawal. 通过基础模型实现人类辅助的持续机器人学习。*arXiv 预印本 arXiv:2309.14321*，2023 年。

+   Wang 等 [2023f] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan 和 Anima Anandkumar。Voyager：一种开放式的具身代理，使用大型语言模型。 *arXiv 预印本 arXiv:2305.16291*，2023f。

+   Ellis 等 [2023] Kevin Ellis, Lionel Wong, Maxwell Nye, Mathias Sable-Meyer, Luc Cary, Lore Anaya Pozo, Luke Hewitt, Armando Solar-Lezama 和 Joshua B Tenenbaum。Dreamcoder：通过觉醒–睡眠贝叶斯程序学习生成可推广的、可解释的知识。 *皇家学会哲学学报 A*，381(2251):20220050，2023。

+   Zhang 等 [2023g] Jesse Zhang, Jiahui Zhang, Karl Pertsch, Ziyi Liu, Xiang Ren, Minsuk Chang, Shao-Hua Sun 和 Joseph J Lim。利用大型语言模型指导来提升你的技能：学习解决新任务。 *arXiv 预印本 arXiv:2310.10021*，2023g。

+   Jin 等 [2021] Xisen Jin, Dejiao Zhang, Henghui Zhu, Wei Xiao, Shang-Wen Li, Xiaokai Wei, Andrew Arnold 和 Xiang Ren。终身预训练：持续适应语言模型以应对新兴语料。 *arXiv 预印本 arXiv:2110.08534*，2021。

+   Monaikul 等 [2021] Natawut Monaikul, Giuseppe Castellucci, Simone Filice 和 Oleg Rokhlenko。命名实体识别的持续学习。在 *AAAI 人工智能会议论文集*，第 35 卷，第 13570–13577 页，2021。

+   Qin 等 [2023b] Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han 等。工具学习与基础模型。 *arXiv 预印本 arXiv:2304.08354*，2023b。

+   Zelikman 等 [2022] Eric Zelikman, Yuhuai Wu, Jesse Mu 和 Noah Goodman。Star：通过推理进行推理的引导。 *神经信息处理系统进展*，35:15476–15488，2022。

+   Huang 等 [2022b] Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu 和 Jiawei Han。大型语言模型可以自我改进。 *arXiv 预印本 arXiv:2210.11610*，2022b。

+   Houlsby 等 [2019a] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan 和 Sylvain Gelly。用于自然语言处理的参数高效迁移学习。在 *国际机器学习会议*，第 2790–2799 页。PMLR，2019a。

+   Mangrulkar 等 [2022] Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul 和 Benjamin Bossan。Peft：最先进的参数高效微调方法。 [`github.com/huggingface/peft`](https://github.com/huggingface/peft)，2022。

+   Wang 等 [2022b] Yaqing Wang, Subhabrata Mukherjee, Xiaodong Liu, Jing Gao, Ahmed Hassan Awadallah 和 Jianfeng Gao。Adamix：用于大规模语言模型参数高效调整的适配器混合。 *arXiv 预印本 arXiv:2205.12410*，1(2):4，2022b。

+   Chen 等 [2023c] Baian Chen, Chang Shu, Ehsan Shareghi, Nigel Collier, Karthik Narasimhan 和 Shunyu Yao。Fireact：面向语言代理的微调。 *arXiv 预印本 arXiv:2310.05915*，2023c。

+   Frantar et al. [2022] Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. Gptq：生成预训练变换器的准确后训练量化。*arXiv 预印本 arXiv:2210.17323*，2022。

+   Lin et al. [2023] Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Xingyu Dang, and Song Han. Awq：针对 llm 压缩和加速的激活感知权重量化。*arXiv 预印本 arXiv:2306.00978*，2023。

+   Liu et al. [2023a] Zechun Liu, Barlas Oguz, Changsheng Zhao, Ernie Chang, Pierre Stock, Yashar Mehdad, Yangyang Shi, Raghuraman Krishnamoorthi, and Vikas Chandra. Llm-qat：大型语言模型的数据无关量化感知训练。*arXiv 预印本 arXiv:2305.17888*，2023a。

+   Yao et al. [2022c] Zhewei Yao, Reza Yazdani Aminabadi, Minjia Zhang, Xiaoxia Wu, Conglong Li, and Yuxiong He. Zeroquant：高效且经济的大规模变换器后训练量化。*神经信息处理系统进展*，35:27168–27183，2022c。

+   Xiao et al. [2023] Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, and Song Han. Smoothquant：大型语言模型的准确高效的后训练量化。载于*国际机器学习大会*，第 38087–38099 页。PMLR，2023。

+   Ma et al. [2023] Xinyin Ma, Gongfan Fang, and Xinchao Wang. Llm-pruner：关于大语言模型的结构剪枝。*arXiv 预印本 arXiv:2305.11627*，2023。

+   Frantar and Alistarh [2023] Elias Frantar and Dan Alistarh. Sparsegpt：大型语言模型可以在一次剪枝中准确修剪。载于*国际机器学习大会*，第 10323–10337 页。PMLR，2023。

+   Sun et al. [2023b] Mingjie Sun, Zhuang Liu, Anna Bair, and J Zico Kolter. 一种简单有效的大型语言模型剪枝方法。*arXiv 预印本 arXiv:2306.11695*，2023b。

+   Timiryasov and Tastet [2023] Inar Timiryasov and Jean-Loup Tastet. Baby llama：从一个教师集群中进行知识蒸馏，该集群在一个小数据集上训练而没有性能惩罚。*arXiv 预印本 arXiv:2308.02019*，2023。

+   Gu et al. [2023] Yuxian Gu, Li Dong, Furu Wei, and Minlie Huang. 大型语言模型的知识蒸馏。*arXiv 预印本 arXiv:2306.08543*，2023。

+   Hsieh et al. [2023] Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister. 逐步蒸馏！用更少的训练数据和更小的模型超越更大的语言模型。*arXiv 预印本 arXiv:2305.02301*，2023。

+   Li et al. [2023c] Liunian Harold Li, Jack Hessel, Youngjae Yu, Xiang Ren, Kai-Wei Chang, and Yejin Choi. 符号链式思维蒸馏：小模型也能"逐步思考"。*arXiv 预印本 arXiv:2306.14050*，2023c。

+   Yao et al. [2023b] Zhewei Yao, Xiaoxia Wu, Cheng Li, Stephen Youn, and Yuxiong He. Zeroquant-v2：从综合研究到低秩补偿，探索后训练量化。2023b。

+   李等人 [2023d] 易晓·李、亿凡·余、庆如·张、陈·梁、鹏程·何、伟柱·陈和拓·赵。Losparse：基于低秩和稀疏近似的大型语言模型的结构化压缩。*arXiv 预印本 arXiv:2306.11222*，2023d。

+   李等人 [2023e] 于城·李、博·董、程华·林和弗兰克·盖林。压缩上下文以提高大型语言模型的推理效率，2023e。

+   江等人 [2023a] 惠强·江、乾辉·吴、林振耀、愈青·杨和丽丽·邱。Llmlingua：压缩提示以加速大型语言模型的推理。发表于*2023 年自然语言处理经验方法会议（EMNLP 2023）论文集*，2023 年 12 月。

+   谢瓦利耶等人 [2023] 亚历克西斯·谢瓦利耶、亚历山大·韦蒂希、阿尼鲁德·阿吉斯和丹琪·陈。调整语言模型以压缩上下文。*ArXiv*，abs/2305.14788，2023。

+   阿纳戈斯蒂迪斯等人 [2023] 索提里斯·阿纳戈斯蒂迪斯、达里奥·帕夫洛、卢卡·比吉奥、洛伦佐·诺奇、奥雷利安·卢奇和托马斯·霍夫曼。用于高效且可解释的自回归变换器的动态上下文剪枝。*arXiv 预印本 arXiv:2305.15805*，2023。

+   张等人 [2023h] 震宇·张、英·盛、天翼·周、天龙·陈、连敏·郑、瑞斯·蔡、赵·宋、远东·田、克里斯托弗·瑞、克拉克·巴雷特等。H2o：用于高效生成推理的大型语言模型的重型击球手预言机。*arXiv 预印本 arXiv:2306.14048*，2023h。

+   葛等人 [2024] 苏宇·葛、余南·张、李源·刘、敏佳·张、贾伟·韩和剑峰·高。模型告诉你要丢弃什么：用于大型语言模型的自适应 KV 缓存压缩。*arXiv 预印本 arXiv:2306.14048*，2024。

+   道等人 [2022] 特里·道、丹·傅、斯特凡诺·厄尔蒙、阿特里·鲁德拉和克里斯托弗·瑞。Flashattention：具有 IO 觉知的快速且内存高效的精确注意力。*神经信息处理系统进展*，35:16344–16359，2022。

+   道 [2023] 特里·道。Flashattention-2：通过更好的并行性和工作分配实现更快的注意力。*arXiv 预印本 arXiv:2307.08691*，2023。

+   洪等人 [2023c] 柯·洪、郭浩·戴、贾明·徐、丘丽·毛、修红·李、俊·刘、康迪·陈、汉宇·董和余·王。Flashdecoding++：在 GPU 上更快的大型语言模型推理。*arXiv 预印本 arXiv:2311.01282*，2023c。

+   陈等人 [2023d] 查理·陈、塞巴斯蒂安·博尔戈、杰弗里·欧文、让-巴蒂斯特·莱斯皮厄、劳伦特·西弗和约翰·詹珀。通过投机采样加速大型语言模型解码。*arXiv 预印本 arXiv:2302.01318*，2023d。

+   利维坦等人 [2023] 亚尼夫·利维坦、马坦·卡尔曼和约西·马蒂亚斯。通过投机解码实现变换器的快速推理。发表于*国际机器学习会议*，第 19274–19286 页。PMLR，2023。

+   盛等人 [2023] 英·盛、连敏·郑、宾航·袁、卓汉·李、马克斯·里亚宾、丹尼尔·Y·傅、志强·谢、贝迪·陈、克拉克·巴雷特、约瑟夫·E·冈萨雷斯、珀西·梁、克里斯托弗·瑞、伊昂·斯托伊卡和策·张。Flexgen：利用单个 GPU 进行高通量生成推理的大型语言模型，2023。

+   Song 等人[2023] Yixin Song, Zeyu Mi, Haotong Xie 和 Haibo Chen。Powerinfer：一种使用消费级 GPU 的快速大型语言模型服务。*arXiv 预印本 arXiv:2312.12456*，2023 年。

+   Alizadeh 等人[2023] Keivan Alizadeh, Iman Mirzadeh, Dmitry Belenko, Karen Khatamifard, Minsik Cho, Carlo C Del Mundo, Mohammad Rastegari 和 Mehrdad Farajtabar。Llm in a flash：有限内存下的高效大型语言模型推理。*arXiv 预印本 arXiv:2312.11514*，2023 年。

+   Qualcomm [2023] Qualcomm。Snapdragon 8 Gen 3 移动平台。[`www.qualcomm.com/products/mobile/snapdragon/smartphones/snapdragon-8-series-mobile-platforms/snapdragon-8-gen-3-mobile-platform`](https://www.qualcomm.com/products/mobile/snapdragon/smartphones/snapdragon-8-series-mobile-platforms/snapdragon-8-gen-3-mobile-platform)，2023 年。

+   Reidy 等人[2023] Brendan C Reidy, Mohammadreza Mohammadi, Mohammed E Elbtity 和 Ramtin Zand。高效部署变换器模型于边缘 TPU 加速器：一个实际系统评估。在*变换器模型的架构与系统支持（ASSYST@ ISCA 2023）*中，2023 年。

+   Hong 等人[2022] Seongmin Hong, Seungjae Moon, Junsoo Kim, Sungjae Lee, Minsub Kim, Dongsoo Lee 和 Joo-Young Kim。Dfx：一种低延迟多 FPGA 设备，用于加速基于变换器的文本生成。在*2022 年 55 届 IEEE/ACM 国际微架构研讨会（MICRO）*中，第 616-630 页。IEEE，2022 年。

+   Houlsby 等人[2019b] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan 和 Sylvain Gelly。用于 NLP 的参数高效迁移学习。*CoRR*，abs/1902.00751，2019b。

+   Hu 等人[2023e] Zhiqiang Hu, Lei Wang, Yihuai Lan, Wanyu Xu, Ee-Peng Lim, Lidong Bing, Xing Xu, Soujanya Poria 和 Roy Ka-Wei Lee。Llm-adapters：一种用于参数高效微调大型语言模型的适配器家族，2023e。

+   Hu 等人[2022] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang 和 Weizhu Chen。Lora：大型语言模型的低秩适配。在*国际学习表示会议*中，2022 年。网址[`openreview.net/forum?id=nZeVKeeFYf9`](https://openreview.net/forum?id=nZeVKeeFYf9)。

+   Lv 等人[2023] Kai Lv, Yuqing Yang, Tengxiao Liu, Qinghui Gao, Qipeng Guo 和 Xipeng Qiu。资源有限的大型语言模型的全参数微调，2023 年。

+   Liu 等人[2023b] Hong Liu, Zhiyuan Li, David Hall, Percy Liang 和 Tengyu Ma。Sophia：一种用于语言模型预训练的可扩展随机二阶优化器，2023b。

+   Gunasekar 等人[2023] Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, Sébastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee 和 Yuanzhi Li。教科书就是你所需要的，2023 年。

+   Li et al. [2023f] 李元之、塞巴斯蒂安·布贝克、罗嫩·艾尔丹、艾莉·德尔·乔诺、苏里亚·古纳塞卡尔和李银达。教科书就是你所需 ii: phi-1.5 技术报告，2023f。

+   Javaheripi and Bubeck [2023] 莫詹·贾瓦赫里皮和塞巴斯蒂安·布贝克。Phi-2: 小型语言模型的惊人力量。 [`www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/`](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/)，2023。

+   Liu et al. [2023c] 刘宇汉、李汉晨、杜昆泰、姚佳怡、程义华、黄雨扬、陆珊、迈克尔·梅尔、亨利·霍夫曼、阿里·霍尔茨曼、加内什·阿南丹纳拉亚南、江俊辰。Cachegen: 快速上下文加载用于语言模型应用，2023c。

+   Datar et al. [2004] 马尤尔·达塔尔、尼科尔·伊莫尔里卡、皮奥特·印迪克和瓦哈布·S·米罗克尼。基于 p-稳定分布的局部敏感哈希方案。载于*第二十届计算几何年会论文集*，SCG ’04，第 253–262 页，美国纽约，2004 年。计算机协会。ISBN 1581138857。doi: 10.1145/997817.997857。

+   Dasgupta and Freund [2008] 桑乔伊·达斯古普塔和尤阿夫·弗雷恩德。随机投影树和低维流形。载于*第四十届 ACM 理论计算大会论文集*，STOC ’08，第 537–546 页，美国纽约，2008 年。计算机协会。ISBN 9781605580470。doi: 10.1145/1374376.1374452。

+   Chen et al. [2021] 陈琪、赵炳、王海东、李名钦、刘传杰、李增忠、杨茂和王景东。SPANN: 高效的大规模近似最近邻搜索。载于*神经信息处理系统进展*，2021。

+   Malkov and Yashunin [2020] 尤·A·马尔科夫和 D·A·雅舒宁。使用分层可导航小世界图的高效且稳健的近似最近邻搜索。*IEEE 计算机学会模式分析与机器智能汇刊*，42(4):824–836，2020 年 4 月。ISSN 0162-8828。doi: 10.1109/TPAMI.2018.2889473。

+   Jayaram Subramanya et al. [2019] 苏哈斯·贾亚拉姆·苏布拉曼亚、弗努·德夫里特、哈沙·瓦尔丹·辛哈德里、拉维香卡·克里希纳瓦米和罗汉·卡德科迪。Diskann: 单节点上的快速准确十亿点最近邻搜索。载于*神经信息处理系统进展*，第 32 卷，2019 年。

+   Jang et al. [2023] 张俊赫、崔汉镇、裴韩妍、李胜俊、权美荣和郑明洙。Cxl-anns: 软件-硬件协作内存去离散化和计算用于大规模近似最近邻搜索。载于*USENIX 年度技术会议*，2023。

+   Jiang et al. [2023b] 江文奇、李时刚、朱宇、约翰内斯·德·芬·里希特、何振浩、施润彬、塞德里克·伦格利、张帅、西奥多罗斯·雷卡津纳斯、托尔斯滕·霍夫勒和古斯塔沃·阿隆索。协同设计硬件和算法以进行向量搜索。*国际高性能计算、网络、存储和分析会议论文集*，2023b。

+   team [2021] Qdrant 团队。Qdrant。 [`github.com/qdrant/qdrant`](https://github.com/qdrant/qdrant)，2021。

+   team [2016] Vespa.ai 团队。Vespa。 [`github.com/vespa-engine/vespa`](https://github.com/vespa-engine/vespa)，2016。

+   Wei et al. [2020] Chuangxian Wei, Bin Wu, Sheng Wang, Renjie Lou, Chaoqun Zhan, Feifei Li, and Yuanzhe Cai. Analyticdb-v: 一个用于结构化和非结构化数据查询融合的混合分析引擎。*Proc. VLDB Endow.*，13(12):3152–3165，2020 年 8 月。ISSN 2150-8097。doi: 10.14778/3415478.3415541。

+   Wang et al. [2021] Jianguo Wang, Xiaomeng Yi, Rentong Guo, Hai Jin, Peng Xu, Shengjun Li, Xiangyu Wang, Xiangzhou Guo, Chengming Li, Xiaohai Xu, Kun Yu, Yuxing Yuan, Yinghao Zou, Jiquan Long, Yudong Cai, Zhenxiang Li, Zhifeng Zhang, Yihua Mo, Jun Gu, Ruiyi Jiang, Yi Wei, and Charles Xie. Milvus: 一个专门构建的向量数据管理系统。 在*2021 年国际数据管理大会论文集*中，SIGMOD ’21，第 2614–2627 页，纽约，NY，USA，2021 年。计算机协会。ISBN 9781450383431。doi: 10.1145/3448016.3457550。

+   Wu et al. [2022a] Wei Wu, Junlin He, Yu Qiao, Guoheng Fu, Li Liu, and Jin Yu. Hqann: 高效且稳健的结构化和非结构化约束的混合查询相似性搜索。在*第 31 届 ACM 国际信息与知识管理会议论文集*中，CIKM ’22，第 4580–4584 页，纽约，NY，USA，2022a。计算机协会。ISBN 9781450392365。doi: 10.1145/3511808.3557610。

+   Johnson et al. [2019] Jeff Johnson, Matthijs Douze, and Hervé Jégou. 十亿规模的相似性搜索与 GPU。*IEEE Transactions on Big Data*，7(3):535–547，2019。

+   Andre et al. [2021] Fabien Andre, Anne-Marie Kermarrec, and Nicolas Le Scouarnec. 更快的 adc: 通过 simd 发掘产品量化的潜力。*IEEE Transactions on Pattern Analysis and Machine Intelligence*，43(5):1666–1677，2021 年 5 月。ISSN 1939-3539。doi: 10.1109/tpami.2019.2952606。

+   team [2019] Vald 团队。Vald。 [`github.com/vdaas/vald`](https://github.com/vdaas/vald)，2019。

+   Zhang et al. [2024b] Zhihao Zhang, Alan Zhu, Lijie Yang, Yihua Xu, Lanting Li, Phitchaya Mangpo Phothilimthana, and Zhihao Jia. 通过推测加速检索增强语言模型服务。*ArXiv*，abs/2401.14021，2024b。URL [`api.semanticscholar.org/CorpusID:267212215`](https://api.semanticscholar.org/CorpusID:267212215)。

+   Jiang et al. [2024] Wenqi Jiang, Shuai Zhang, Boran Han, Jie Wang, Bernie Wang, and Tim Kraska. Piperag: 通过算法-系统共同设计实现快速检索增强生成，2024。

+   Jin et al. [2024] Chao Jin, Zili Zhang, Xuanlin Jiang, Fangyue Liu, Xin Liu, Xuanzhe Liu, and Xin Jin. Ragcache: 高效的检索增强生成知识缓存，2024。

+   Muennighoff et al. [2024] Niklas Muennighoff, Hongjin Su, Liang Wang, Nan Yang, Furu Wei, Tao Yu, Amanpreet Singh, and Douwe Kiela. 生成式表征指令调优，2024。

+   Bondarenko 等人 [2021] Yelysei Bondarenko, Markus Nagel 和 Tijmen Blankevoort。理解和克服高效变换器量化的挑战。*arXiv 预印本 arXiv:2109.12948*，2021。

+   Wei 等人 [2022b] Xiuying Wei, Yunchen Zhang, Xiangguo Zhang, Ruihao Gong, Shanghang Zhang, Qi Zhang, Fengwei Yu 和 Xianglong Liu。异常值抑制：推动低比特变换器语言模型的极限。*神经信息处理系统进展*，35:17402-17414，2022b。

+   llama.cpp 开发者 [2023] llama.cpp 开发者。ggerganov/llama.cpp: Facebook 的 llama 模型在 C/C++ 中的移植。 [`github.com/ggerganov/llama.cpp`](https://github.com/ggerganov/llama.cpp)，2023。

+   团队 [2023] MLC 团队。MLC-LLM，2023。网址 [`github.com/mlc-ai/mlc-llm`](https://github.com/mlc-ai/mlc-llm)。

+   Yuan 等人 [2023a] Zhihang Yuan, Lin Niu, Jiawei Liu, Wenyu Liu, Xinggang Wang, Yuzhang Shang, Guangyu Sun, Qiang Wu, Jiaxiang Wu 和 Bingzhe Wu。RPTQ：基于重排序的大型语言模型后训练量化。*arXiv 预印本 arXiv:2304.01089*，2023a。

+   Wei 等人 [2023a] Xiuying Wei, Yunchen Zhang, Yuhang Li, Xiangguo Zhang, Ruihao Gong, Jinyang Guo 和 Xianglong Liu。异常值抑制+：通过等效和最佳的偏移与缩放实现大型语言模型的精确量化。*arXiv 预印本 arXiv:2304.09145*，2023a。

+   Liu 等人 [2023d] Jing Liu, Ruihao Gong, Xiuying Wei, Zhiwei Dong, Jianfei Cai 和 Bohan Zhuang。QLLM：大型语言模型的准确而高效的低比特宽度量化。*arXiv 预印本 arXiv:2310.08041*，2023d。

+   Zhang 等人 [2023i] Yijia Zhang, Lingran Zhao, Shijie Cao, Wenqiang Wang, Ting Cao, Fan Yang, Mao Yang, Shanghang Zhang 和 Ningyi Xu。整数还是浮点？大型语言模型低比特量化的新展望。*arXiv 预印本 arXiv:2305.12356*，2023i。

+   Wu 等人 [2023b] Xiaoxia Wu, Zhewei Yao 和 Yuxiong He。Zeroquant-fp：LLMs 后训练 W4A8 量化在浮点格式下的飞跃。*arXiv 预印本 arXiv:2307.09782*，2023b。

+   Liu 等人 [2023e] Shih-yang Liu, Zechun Liu, Xijie Huang, Pingcheng Dong 和 Kwang-Ting Cheng。LLM-FP4：4 比特浮点量化变换器。*arXiv 预印本 arXiv:2310.16836*，2023e。

+   Li 等人 [2024] Luchang Li, Sheng Qian, Jie Lu, Lunxi Yuan, Rui Wang 和 Qin Xie。Transformer-lite：在手机 GPU 上高效部署大型语言模型。*arXiv 预印本 arXiv:2403.20041*，2024。

+   Aminabadi 等人 [2022] Reza Yazdani Aminabadi, Samyam Rajbhandari, Ammar Ahmad Awan, Cheng Li, Du Li, Elton Zheng, Olatunji Ruwase, Shaden Smith, Minjia Zhang, Jeff Rasley 等人。Deepspeed-inference：在前所未有的规模下实现高效的变换器模型推理。在 *SC22: 国际高性能计算、网络、存储和分析会议* 上，第 1-15 页。IEEE，2022。

+   Kwon 等 [2023] 禹硕·权、卓涵·李、思源·庄、颖盛·盛、联民·郑、科迪·郝·余、约瑟夫·冈萨雷斯、浩·张和艾昂·斯托伊卡。基于分页注意的高效内存管理用于大语言模型服务。在*第 29 届操作系统原理研讨会*，页码 611–626，2023。

+   Liu 等 [2023f] 子昌·刘、阿迪亚·德赛、方硕·廖、伟涛·王、维克多·谢、赵卓·徐、阿纳斯塔西奥斯·基里迪斯和安舒马利·施里瓦斯塔瓦。Scissorhands: 利用重要性假设的持久性进行 LLM KV 缓存压缩。在*arXiv 预印本 arXiv:2305.17118*，2023f。

+   Ainslie 等 [2023] 乔舒亚·安斯利、陶磊、米歇尔·德·容、圣地亚哥·翁坦、悉达多·布拉马、尤里·泽姆利扬斯基、戴维·C·乌斯、曼迪·郭、詹姆斯·李-索普、易·泰、云轩·宋和苏密特·K·桑海。Colt5: 基于条件计算的更快长距离变换器。在*自然语言处理实证方法会议*，2023。

+   Del Corro 等 [2023] 卢西亚诺·德尔·科罗、艾莉·德尔·乔诺、萨哈杰·阿格瓦尔、宾·余、艾哈迈德·阿瓦达拉和苏巴布拉塔·穆克吉。Skipdecode: 自回归跳过解码，结合批处理和缓存以提高 LLM 推理效率。*arXiv 预印本 arXiv:2307.02628*，2023。

+   Wang 等 [2020b] 思农·王、贝琳达·Z·李、马迪安·哈布萨、汉·方和浩·马。Linformer: 具有线性复杂性的自注意。*ArXiv*，abs/2006.04768，2020b。

+   Park 等 [2022] 俊豪·朴、倍成·朴、敏洙·金、成宰·李、郑熙·金、范硕·权、世钟·权、炳旭·金、永周·李和东洙·李。Lut-gemm: 基于 LUT 的量化矩阵乘法以提高大规模生成语言模型的推理效率。*arXiv 预印本 arXiv:2206.09557*，2022。

+   Miao 等 [2023] 旭鹏·苗、加布里埃尔·奥利亚罗、志豪·张、鑫浩·程、泽宇·王、瑞莹·余·黄、卓明·陈、戴亚恩·阿尔费恩、瑞娜·阿比扬卡和志豪·贾。Specinfer: 通过推测推理和令牌树验证加速生成 LLM 服务。*arXiv 预印本 arXiv:2305.09781*，2023。

+   Spector 和 Re [2023] 本杰明·斯佩克特和克里斯·瑞。通过阶段性推测解码加速 LLM 推理。*arXiv 预印本 arXiv:2308.04623*，2023。

+   Kim 等 [2023b] 世勋·金、卡尔提克·曼加拉姆、素红·穆恩、吉特恩德拉·马利克、迈克尔·W·马赫尼、阿米尔·戈拉米和库尔特·凯策。使用大小解码器的推测解码。在*第 37 届神经信息处理系统会议*，2023b。

+   Liu 等 [2023g] 子昌·刘、觉王、Tri Dao、天意·周、滨航·袁、赵松、安舒马利·施里瓦斯塔瓦、策·张、远东·田、克里斯托弗·瑞等。Deja vu: 上下文稀疏性以提高 LLM 推理时的效率。在*国际机器学习大会*，页码 22137–22176。PMLR，2023g。

+   Ye 等 [2023] 文华·叶、徐舟、乔伊·周、岑晨和肯利·李。基于高效重配置脉冲阵列的 FPGA 上的注意机制加速。*ACM 嵌入式计算系统期刊*，22(6):1–22，2023。

+   Samsi et al. [2023] Siddharth Samsi, Dan Zhao, Joseph McDonald, Baolin Li, Adam Michaleas, Michael Jones, William Bergeron, Jeremy Kepner, Devesh Tiwari, 和 Vijay Gadepally. 从词汇到瓦特：大语言模型推理的能源成本基准测试。*2023 IEEE 高性能极限计算会议 (HPEC)*, 页码 1–9, 2023。网址 [`api.semanticscholar.org/CorpusID:263620702`](https://api.semanticscholar.org/CorpusID:263620702)。

+   Stojkovic et al. [2024] Jovan Stojkovic, Esha Choukse, Chaojie Zhang, Íñigo Goiri, 和 Josep Torrellas. 迈向更环保的语言模型：将能源效率置于语言模型推理的前沿。*ArXiv*, abs/2403.20306, 2024。网址 [`api.semanticscholar.org/CorpusID:268793445`](https://api.semanticscholar.org/CorpusID:268793445)。

+   Laskaridis et al. [2024] Stefanos Laskaridis, Kleomenis Katevas, Lorenzo Minto, 和 Hamed Haddadi. 熔点：移动语言变换器评估, 2024。

+   Faiz et al. [2023] Ahmad Faiz, Sotaro Kaneda, Ruhan Wang, Rita Osi, Parteek Sharma, Fan Chen, 和 Lei Jiang. Llmcarbon：大语言模型的端到端碳足迹建模。*ArXiv*, abs/2309.14393, 2023。网址 [`api.semanticscholar.org/CorpusID:262825233`](https://api.semanticscholar.org/CorpusID:262825233)。

+   Cao et al. [2021] Qingqing Cao, Yash Kumar Lal, H. Trivedi, Aruna Balasubramanian, 和 Niranjan Balasubramanian. Irene：变换器的可解释能源预测。*ArXiv*, abs/2106.01199, 2021。网址 [`api.semanticscholar.org/CorpusID:235294249`](https://api.semanticscholar.org/CorpusID:235294249)。

+   Gim et al. [2023] In Gim, Guojun Chen, Seung seob Lee, Nikhil Sarda, Anurag Khandelwal, 和 Lin Zhong. 提示缓存：低延迟推理的模块化注意力重用。*ArXiv*, abs/2311.04934, 2023。网址 [`api.semanticscholar.org/CorpusID:265067391`](https://api.semanticscholar.org/CorpusID:265067391)。

+   He et al. [2022] Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, 和 Graham Neubig. 迈向参数高效迁移学习的统一视角, 2022。

+   Li and Liang [2021] Xiang Lisa Li 和 Percy Liang. 前缀调优：优化生成的连续提示, 2021。

+   Liu et al. [2022a] Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Lam Tam, Zhengxiao Du, Zhilin Yang, 和 Jie Tang. P-tuning v2：提示调优可以在各个规模和任务上与微调相媲美, 2022a。

+   Zhang et al. [2023j] Renrui Zhang, Jiaming Han, Chris Liu, Peng Gao, Aojun Zhou, Xiangfei Hu, Shilin Yan, Pan Lu, Hongsheng Li, 和 Yu Qiao. Llama-adapter：使用零初始化注意力的高效语言模型微调, 2023j。

+   Liu et al. [2023h] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, 和 Jie Tang. GPT 也能理解, 2023h。

+   Liu 等 [2022b] Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal 和 Colin Raffel. 少量样本参数高效微调优于上下文学习，且成本更低. *ArXiv*, abs/2205.05638, 2022b. URL [`api.semanticscholar.org/CorpusID:248693283`](https://api.semanticscholar.org/CorpusID:248693283).

+   Zhao 等 [2024] Yanjun Zhao, Sizhe Dang, Haishan Ye, Guang Dai, Yi Qian 和 Ivor Wai-Hung Tsang. 针对 llm 的二阶微调: 一个 Hessian 影响的零阶优化器. *ArXiv*, abs/2402.15173, 2024. URL [`api.semanticscholar.org/CorpusID:267897669`](https://api.semanticscholar.org/CorpusID:267897669).

+   Liu 等 [2023i] Bingbin Liu, Sébastien Bubeck, Ronen Eldan, Janardhan Kulkarni, Yuanzhi Li, Anh Nguyen, Rachel Ward 和 Yi Zhang. Tinygsm: 在小型语言模型上实现 >80% 的 gsm8k. *ArXiv*, abs/2312.09241, 2023i. URL [`api.semanticscholar.org/CorpusID:266210221`](https://api.semanticscholar.org/CorpusID:266210221).

+   Mikolov 等 [2013] Tomas Mikolov, Kai Chen, Greg Corrado 和 Jeffrey Dean. 向量空间中词表示的高效估计, 2013.

+   Le 和 Mikolov [2014] Quoc Le 和 Tomas Mikolov. 句子和文档的分布式表示. 在 *第 31 届国际机器学习大会论文集* 中，*机器学习研究论文集* 第 32 卷，页码 1188–1196，北京，中国，2014 年 6 月 22–24 日\. PMLR.

+   Liu 等 [2023j] Jiongnan Liu, Jiajie Jin, Zihan Wang, Jiehan Cheng, Zhicheng Dou 和 Ji-Rong Wen. Reta-llm: 一个检索增强大型语言模型工具包, 2023j.

+   Melz [2023] Eric Melz. 通过 arm-rag 增强 llm 智能: 辅助推理记忆用于检索增强生成, 2023.

+   Zhong 等 [2022] Zexuan Zhong, Tao Lei 和 Danqi Chen. 使用记忆增强训练语言模型. *ArXiv*, abs/2205.12674, 2022. URL [`api.semanticscholar.org/CorpusID:249062699`](https://api.semanticscholar.org/CorpusID:249062699).

+   Han 等 [2023] Yikun Han, Chunjiang Liu 和 Pengfei Wang. 向量数据库的全面综述: 存储与检索技术、挑战. *arXiv 预印本 arXiv:2310.11703*, 2023.

+   Pan 等 [2023] James Jie Pan, Jianguo Wang 和 Guoliang Li. 向量数据库管理系统综述, 2023.

+   Taipalus [2023] Toni Taipalus. 向量数据库管理系统: 基本概念、应用案例和当前挑战. *ArXiv*, abs/2309.11322, 2023.

+   Wu 等 [2022b] Yuhuai Wu, Markus N. Rabe, DeLesley S. Hutchins 和 Christian Szegedy. 记忆变换器. *ArXiv*, abs/2203.08913, 2022b.

+   Modarressi 等 [2023] Ali Modarressi, Ayyoob Imani, Mohsen Fayyaz 和 Hinrich Schütze. Ret-llm: 面向大型语言模型的通用读写记忆. *arXiv 预印本 arXiv:2305.14322*, 2023.

+   Dasgupta 和 Sinha [2013] Sanjoy Dasgupta 和 Kaushik Sinha. 用于精确最近邻搜索的随机分区树, 2013.

+   Malkov 等人 [2014] Yury Malkov, Alexander Ponomarenko, Andrey Logvinov 和 Vladimir Krylov。基于可导航小世界图的近似最近邻算法。*Inf. Syst.*，45:61–68，2014 年。

+   Gollapudi 等人 [2023] Siddharth Gollapudi, Neel Karia, Varun Sivashankar, Ravishankar Krishnaswamy, Nikit Begwani, Swapnil Raz, Yiyong Lin, Yin Zhang, Neelam Mahapatro, Premkumar Srinivasan, Amit Singh 和 Harsha Vardhan Simhadri。Filtered-diskann: 具有过滤器的近似最近邻搜索图算法。见于 *ACM Web Conference 2023 论文集*，WWW ’23，页面 3406–3416，美国纽约，2023 年。计算机协会。ISBN 9781450394161。doi: 10.1145/3543507.3583552。

+   Tian 等人 [2023] Yao Tian, Ziyang Yue, Ruiyuan Zhang, Xi Zhao, Bolong Zheng 和 Xiaofang Zhou。高维向量数据库中的近似最近邻搜索：当前研究与未来方向，2023 年。

+   Ni 等人 [2023] Jiongkang Ni, Xiaoliang Xu, Yuxiang Wang, Can Li, Jiajie Yao, Shihai Xiao 和 Xuecang Zhang。Diskann++: 基于查询敏感性入口顶点的高效页面式搜索。*ArXiv*，abs/2310.00402，2023 年。

+   Zhao 等人 [2020] Weijie Zhao, Shulong Tan 和 Ping Li。Song: 基于 GPU 的近似最近邻搜索。*2020 IEEE 第 36 届数据工程国际会议 (ICDE)*，页面 1033–1044，2020 年。

+   Groh 等人 [2019] Fabian Groh, Lukas Ruppert, Patrick Wieschollek 和 Hendrik P. A. Lensch。GGNN: 基于图的 GPU 最近邻搜索。*IEEE Transactions on Big Data*，9:267–279，2019 年。

+   Ootomo 等人 [2023] Hiroyuki Ootomo, Akira Naruse, Corey J. Nolet, Ray Wang, Tamas B. Fehér 和 Y. Wang。Cagra: 高度并行的图构建和 GPU 的近似最近邻搜索。*ArXiv*，abs/2308.15136，2023 年。

+   Touvron 等人 [2023] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave 和 Guillaume Lample。Llama: 开放且高效的基础语言模型，2023 年。

+   Team [2023] BlueLM Team。Bluelm: 一个开放的多语言 7b 语言模型。 [`github.com/vivo-ai-lab/BlueLM`](https://github.com/vivo-ai-lab/BlueLM)，2023 年。

+   Liu 等人 [2024b] Zhiwei Liu, Weiran Yao, Jianguo Zhang, Liangwei Yang, Zuxin Liu, Juntao Tan, Prafulla K Choubey, Tian Lan, Jason Wu, Huan Wang 等人。Agentlite: 用于构建和提升任务导向的 LLM 代理系统的轻量级库。*arXiv 预印本 arXiv:2402.15538*，2024 年。

+   Dettmers 等人 [2023] Tim Dettmers, Ruslan Svirschevski, Vage Egiazarian, Denis Kuznedelev, Elias Frantar, Saleh Ashkboos, Alexander Borzunov, Torsten Hoefler 和 Dan Alistarh。Spqr: 一种稀疏量化表示用于近乎无损的 LLM 权重压缩。*arXiv 预印本 arXiv:2306.03078*，2023 年。

+   Rivest 等人 [1978] Ronald L Rivest, Len Adleman, Michael L Dertouzos 等. 关于数据银行和隐私同态映射。*安全计算基础*, 4(11):169–180, 1978。

+   Gentry [2009] Craig Gentry. 使用理想格的完全同态加密。发表于 *第四十一届年度 ACM 理论计算研讨会会议录*, 页码 169–178, 2009。

+   Gilad-Bachrach 等人 [2016] Ran Gilad-Bachrach, Nathan Dowlin, Kim Laine, Kristin Lauter, Michael Naehrig 和 John Wernsing. Cryptonets: 将神经网络应用于加密数据，实现高吞吐量和高精度。发表于 *国际机器学习会议*, 页码 201–210\. PMLR, 2016。

+   Chen 等人 [2022] Tianyu Chen, Hangbo Bao, Shaohan Huang, Li Dong, Binxing Jiao, Daxin Jiang, Haoyi Zhou, Jianxin Li 和 Furu Wei. The-x: 使用同态加密进行隐私保护的变换器推断。*arXiv 预印本 arXiv:2206.00216*, 2022。

+   Reagen 等人 [2021] Brandon Reagen, Woo-Seok Choi, Yeongil Ko, Vincent T Lee, Hsien-Hsin S Lee, Gu-Yeon Wei 和 David Brooks. Cheetah: 优化和加速同态加密以实现私密推断。发表于 *2021 IEEE 国际高性能计算架构研讨会 (HPCA)*, 页码 26–39\. IEEE, 2021。

+   Acar 等人 [2018] Abbas Acar, Hidayet Aksu, A Selcuk Uluagac 和 Mauro Conti. 关于同态加密方案的调查：理论与实现。*ACM 计算调查 (Csur)*, 51(4):1–35, 2018。

+   Goldwasser [1997] Shafi Goldwasser. 多方计算：过去与现在。发表于 *第十六届年度 ACM 分布式计算原则研讨会会议录*, 页码 1–6, 1997。

+   Knott 等人 [2021] Brian Knott, Shobha Venkataraman, Awni Hannun, Shubho Sengupta, Mark Ibrahim 和 Laurens van der Maaten. Crypten: 安全多方计算与机器学习的结合。*神经信息处理系统进展*, 34:4961–4973, 2021。

+   Tramer 和 Boneh [2018] Florian Tramer 和 Dan Boneh. Slalom: 在受信硬件中快速、可验证和私密地执行神经网络。*arXiv 预印本 arXiv:1806.03287*, 2018。

+   Fei 等人 [2021] Shufan Fei, Zheng Yan, Wenxiu Ding 和 Haomeng Xie. SGX 的安全漏洞及其对策：一项调查。*ACM 计算调查 (CSUR)*, 54(6):1–36, 2021。

+   McCallister [2010] Erika McCallister. *保护个人可识别信息的指南*, 第 800 卷。Diane Publishing, 2010。

+   Lin 等人 [2024] Guo Lin, Wenyue Hua 和 Yongfeng Zhang. Promptcrypt: 用于大语言模型安全通信的即时加密。*arXiv 预印本 arXiv:2402.05868*, 2024。

+   Coavoux 等人 [2018] Maximin Coavoux, Shashi Narayan 和 Shay B Cohen. 隐私保护的文本神经表示。*arXiv 预印本 arXiv:1808.09408*, 2018。

+   Zhou et al. [2022] Xin Zhou, Jinzhu Lu, Tao Gui, Ruotian Ma, Zichu Fei, Yuran Wang, Yong Ding, Yibo Cheung, Qi Zhang, 和 Xuan-Jing Huang。Textfusion: 通过令牌融合进行隐私保护的预训练模型推断。见于 *2022 年自然语言处理经验方法会议论文集*，第 8360–8371 页，2022 年。

+   Zhou et al. [2023d] Xin Zhou, Yi Lu, Ruotian Ma, Tao Gui, Yuran Wang, Yong Ding, Yibo Zhang, Qi Zhang, 和 Xuan-Jing Huang。Textobfuscator: 通过混淆词表示使预训练语言模型成为隐私保护者。见于 *计算语言学协会 2023 年会议成果*，第 5459–5473 页，2023 年。

+   Liu et al. [2020] Xiaodong Liu, Hao Cheng, Pengcheng He, Weizhu Chen, Yu Wang, Hoifung Poon, 和 Jianfeng Gao。大型神经语言模型的对抗训练。*arXiv 预印本 arXiv:2004.08994*，2020 年。

+   Roesner et al. [2012] Franziska Roesner, Tadayoshi Kohno, Alexander Moshchuk, Bryan Parno, Helen J Wang, 和 Crispin Cowan。用户驱动的访问控制：重新思考现代操作系统中的权限授予。在 *2012 年 IEEE 安全与隐私研讨会*，第 224–238 页。IEEE，2012 年。

+   Evertz et al. [2024] Jonathan Evertz, Merlin Chlosta, Lea Schönherr, 和 Thorsten Eisenhofer。机器中的耳语：LLM 集成系统中的保密性。*arXiv 预印本 arXiv:2402.06922*，2024 年。

+   Enck et al. [2014] William Enck, Peter Gilbert, Seungyeop Han, Vasant Tendulkar, Byung-Gon Chun, Landon P Cox, Jaeyeon Jung, Patrick McDaniel, 和 Anmol N Sheth。Taintdroid: 一种用于智能手机实时隐私监控的信息流跟踪系统。*ACM 计算机系统学报（TOCS）*，32(2):1–29，2014 年。

+   Szegedy et al. [2014] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, 和 Rob Fergus。神经网络的有趣特性，2014 年。

+   Xu et al. [2020] Han Xu, Yao Ma, Hao-Chen Liu, Debayan Deb, Hui Liu, Ji-Liang Tang, 和 Anil K. Jain。图像、图形和文本中的对抗攻击与防御：综述。*自动化与计算国际期刊*，17(2):151–178，2020 年。doi: 10.1007/s11633-019-1211-x。

+   Kumar et al. [2023] Aounon Kumar, Chirag Agarwal, Suraj Srinivas, Aaron Jiaxun Li, Soheil Feizi, 和 Himabindu Lakkaraju。证明 LLM 对抗性提示的安全性，2023 年。

+   Zhao et al. [2023c] Yunqing Zhao, Tianyu Pang, Chao Du, Xiao Yang, Chongxuan Li, Ngai-Man Cheung, 和 Min Lin。评估大型视觉语言模型的对抗鲁棒性。*arXiv 预印本 arXiv:2305.16934*，2023c。

+   Wei et al. [2023b] Alexander Wei, Nika Haghtalab, 和 Jacob Steinhardt。Jailbroken: LLM 安全训练如何失败？*arXiv 预印本 arXiv:2307.02483*，2023b。

+   Schlarmann and Hein [2023] Christian Schlarmann 和 Matthias Hein。多模态基础模型的对抗鲁棒性。见于 *IEEE/CVF 国际计算机视觉会议论文集*，第 3677–3685 页，2023 年。

+   Fu 等人[2023] Xiaohan Fu, Zihan Wang, Shuheng Li, Rajesh K. Gupta, Niloofar Mireshghallah, Taylor Berg-Kirkpatrick 和 Earlence Fernandes。误用大语言模型中的视觉对抗样本，2023 年。

+   Zhu 等人[2023a] Sicheng Zhu, Ruiyi Zhang, Bang An, Gang Wu, Joe Barrow, Zichao Wang, Furong Huang, Ani Nenkova 和 Tong Sun。Autodan：基于梯度的可解释对抗攻击大语言模型，2023a 年。

+   Gu 等人[2019] Tianyu Gu, Kang Liu, Brendan Dolan-Gavitt 和 Siddharth Garg。Badnets：评估深度神经网络的后门攻击。*IEEE Access*，7:47230–47244，2019 年。doi: 10.1109/ACCESS.2019.2909068。

+   Yuan 等人[2023b] Yizhen Yuan, Rui Kong, Shenghao Xie, Yuanchun Li 和 Yunxin Liu。Patchbackdoor：无模型修改的深度神经网络后门攻击。在*第 31 届 ACM 国际多媒体会议论文集*，第 9134–9142 页，2023b 年。

+   Kandpal 等人[2023] Nikhil Kandpal, Matthew Jagielski, Florian Tramèr 和 Nicholas Carlini。面向语言模型的上下文学习的后门攻击。*arXiv 预印本 arXiv:2307.14692*，2023 年。

+   Zhao 等人[2023d] Shuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao 和 Jie Fu。提示作为后门攻击触发器：检查语言模型的脆弱性，2023d 年。

+   Yao 等人[2023c] Hongwei Yao, Jian Lou 和 Zhan Qin。Poisonprompt：针对基于提示的大语言模型的后门攻击，2023c 年。

+   Han 等人[2024] Tingxu Han, Shenghan Huang, Ziqi Ding, Weisong Sun, Yebo Feng, Chunrong Fang, Jun Li, Hanwei Qian, Cong Wu, Quanjun Zhang, Yang Liu 和 Zhenyu Chen。蒸馏在缓解预训练编码器中的后门攻击中的有效性，2024 年。

+   Sun 等人[2023c] Xiaofei Sun, Xiaoya Li, Yuxian Meng, Xiang Ao, Lingjuan Lyu, Jiwei Li 和 Tianwei Zhang。防御自然语言生成中的后门攻击。在*AAAI 人工智能会议论文集*，第 37 卷，第 5257–5265 页，2023c 年。

+   Abdelnabi 等人[2023] Sahar Abdelnabi, Kai Greshake, Shailesh Mishra, Christoph Endres, Thorsten Holz 和 Mario Fritz。不是你所注册的：通过间接提示注入攻击现实世界的 LLM 集成应用。在*第 16 届 ACM 人工智能与安全研讨会论文集*，AISec ’23，第 79–90 页，美国纽约，2023 年。计算机协会。ISBN 9798400702600。doi: 10.1145/3605764.3623985。

+   Perez 和 Ribeiro[2022] Fábio Perez 和 Ian Ribeiro。忽略前提示：语言模型攻击技术，2022 年。

+   Liu 等人[2023k] Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang, Yepang Liu, Haoyu Wang, Yan Zheng 和 Yang Liu。针对 LLM 集成应用的提示注入攻击，2023k 年。

+   Shayegani 等人[2023] Erfan Shayegani, Yue Dong 和 Nael Abu-Ghazaleh。Jailbreak in pieces：对多模态语言模型的组合对抗攻击，2023 年。

+   Chao et al. [2023] 帕特里克·曹、亚历山大·罗贝、埃德加·多布里班、哈梅德·哈萨尼、乔治·J·帕帕斯和埃里克·黄。在二十个查询中破解黑箱大型语言模型，2023。

+   Carlini et al. [2021] 尼古拉斯·卡尔尼、弗洛里安·特拉梅尔、埃里克·沃勒斯、马修·贾吉尔斯基、阿里尔·赫伯特-沃斯、凯瑟琳·李、亚当·罗伯茨、汤姆·布朗、道恩·宋、乌尔法尔·厄尔林森、阿琳娜·奥普雷亚和科林·拉费尔。从大型语言模型中提取训练数据。在*第 30 届 USENIX 安全研讨会（USENIX Security 21）*，第 2633–2650 页。USENIX 协会，2021 年 8 月。ISBN 978-1-939133-24-3。

+   Robey et al. [2023] 亚历山大·罗贝、埃里克·黄、哈梅德·哈萨尼和乔治·J·帕帕斯。Smoothllm：防御大型语言模型的破解攻击，2023。

+   Ji et al. [2023] 纪子伟、李娜妍、丽塔·弗里斯克、田征宇、段苏、阎旭、石井悦子、叶金邦、安德烈亚·马多托和帕斯卡尔·冯。自然语言生成中的幻觉调查。*ACM Computing Surveys*，55(12):1–38，2023。

+   Rawte et al. [2023] 维普拉·劳特、阿米特·谢特和阿米塔瓦·达斯。大型基础模型中的幻觉调查。*arXiv 预印本 arXiv:2309.05922*，2023。

+   Nair et al. [2023] 瓦伦·奈尔、艾略特·舒马赫、杰弗里·佐和阿尼莎·卡南。Dera：通过对话启用的解析代理增强大型语言模型的完成。*arXiv 预印本 arXiv:2303.17071*，2023。

+   Zhang et al. [2023k] 张一凡、杨静琴、袁杨和姚基智。与大型语言模型的累积推理。*arXiv 预印本 arXiv:2308.04371*，2023k。

+   An et al. [2023] 安盛南、马泽雄、林泽奇、郑南宁、楼建广和陈伟柱。从错误中学习使大型语言模型成为更好的推理者。*arXiv 预印本 arXiv:2310.20689*，2023。

+   Zhu et al. [2023b] 赵成朱、袁雪、辛云陈、丹尼·周、简堂、戴尔·舒尔曼和汉军·戴。大型语言模型能够学习规则。*arXiv 预印本 arXiv:2310.07064*，2023b。

+   Gururangan et al. [2020] 苏钦·古鲁拉根、安娜·马拉索维奇、斯瓦巴·斯瓦扬迪普塔、凯尔·洛、伊兹·贝尔塔吉、道格·道尼和诺亚·A·史密斯。不要停止预训练：将语言模型适应于领域和任务。在*第 58 届计算语言学协会年会论文集*，2020。

+   Liu et al. [2023l] 刘鹏飞、袁伟哲、傅锦兰、姜正宝、林浩昭和格雷厄姆·纽比格。预训练、提示和预测：自然语言处理中的提示方法系统调查。*ACM Computing Surveys*，55(9):1–35，2023l。

+   Wei et al. [2021] 杰森·魏、马滕·博斯马、文森特·赵、凯尔文·古、亚当斯·魏·余、布莱恩·莱斯特、南杜、安德鲁·M·戴和阮国伟。微调的语言模型是零样本学习者。在*国际学习表示大会*，2021。

+   Lee et al. [2023c] 哈里森·李、萨姆拉特·帕塔尔、哈桑·曼苏尔、凯莉·陆、托马斯·梅斯纳德、科尔顿·比肖普、维克多·卡布内和阿比纳夫·拉斯托吉。Rlaif：通过人工智能反馈扩展人类反馈的强化学习。*arXiv 预印本 arXiv:2309.00267*，2023c。

+   Wang 等人 [2023g] 汪冠、程思杰、詹鲜元、李显刚、宋森 和 刘洋。Openchat：通过混合质量数据推进开源语言模型。*arXiv 预印本 arXiv:2309.11235*，2023g。

+   Kadavath 等人 [2022] 苏拉夫·卡达瓦斯、汤姆·科纳利、阿曼达·阿斯克尔、汤姆·赫尼根、道恩·德雷恩、伊桑·佩雷斯、尼古拉斯·谢弗、扎克·哈特菲尔德-多兹、诺娃·达斯萨尔马、伊莱·特兰-约翰逊 等人。语言模型（大多）知道它们知道什么。*arXiv 预印本 arXiv:2207.05221*，2022。

+   Madaan 等人 [2023] 阿曼·马达安、尼凯特·坦顿、普拉卡什·古普塔、斯凯勒·霍利南、刘玉高、莎拉·维格雷夫、乌里·阿隆、诺哈·德齐里、施瑞迈·普拉布莫耶、杨一鸣 等人。Self-refine：带有自我反馈的迭代精炼。*arXiv 预印本 arXiv:2303.17651*，2023。

+   Shinn 等人 [2023] 诺亚·辛、费德里科·卡萨诺、爱德华·伯曼、阿什温·戈皮纳斯、卡尔蒂克·纳拉辛汉 和 申宇·姚。Reflexion：具有语言强化学习的语言代理，2023。

+   Chen 等人 [2023e] 陈欣云、林麦克斯维尔、纳塔纳厄尔·施尔和周登尼。教大型语言模型自我调试。*arXiv 预印本 arXiv:2304.05128*，2023e。

+   Manakul 等人 [2023] 波萨维·马纳库尔、艾迪安·刘西 和 马克·JF·盖尔斯。Selfcheckgpt：零资源黑箱幻觉检测用于生成大型语言模型。*arXiv 预印本 arXiv:2303.08896*，2023。

+   Du 等人 [2023] 余伦·杜、双李、安东尼奥·托拉尔巴、乔舒亚·B·特嫩鲍姆 和 伊戈尔·莫达奇。通过多智能体辩论提升语言模型的事实性和推理能力。*arXiv 预印本 arXiv:2305.14325*，2023。

+   Guu 等人 [2020] 凯尔文·谷、肯顿·李、佐拉·通、帕努蓬·帕苏帕特 和 明伟·张。检索增强语言模型的预训练。在*国际机器学习会议*，第 3929–3938 页。PMLR，2020。

+   Wang 等人 [2017b] 王全、毛振东、王斌 和 郭丽。知识图谱嵌入：方法与应用的综述。*IEEE 知识与数据工程汇刊*，29(12):2724–2743，2017b。

+   Kenton 和 Toutanova [2019] 雅各布·德夫林、明伟·张、肯顿 和 李·克里斯蒂娜·图塔诺瓦。Bert：深度双向变换器的预训练用于语言理解。在*NAACL-HLT 会议录*，第 1 卷，第 2 页，2019。

+   Shi 等人 [2023] 弗雷达·石、陈欣云、卡尼什卡·米斯拉、内森·斯凯尔斯、大卫·多汉、埃德·H·池、纳塔纳厄尔·施尔 和 周登尼。大型语言模型容易被无关的上下文分散注意力。在*国际机器学习会议*，第 31210–31227 页。PMLR，2023。

+   Yu 等人 [2023] 于文浩、张宏明、潘晓曼、马凯欣、王洪伟 和 董宇。Chain-of-note：增强检索增强语言模型的鲁棒性。*arXiv 预印本 arXiv:2311.09210*，2023。

+   Asai 等人 [2023] 浅井晓、吴泽秋、王一中、阿维鲁普·西尔 和 汉娜赫·哈吉什尔齐。Self-rag：通过自我反思学习检索、生成和批判。*arXiv 预印本 arXiv:2310.11511*，2023。

+   Wang 等 [2023h] Yile Wang, Peng Li, Maosong Sun 和 Yang Liu。自我知识引导的大型语言模型检索增强。*arXiv 预印本 arXiv:2310.05002*，2023h 年。

+   Wang 等 [2023i] Zhiruo Wang, Jun Araki, Zhengbao Jiang, Md Rizwan Parvez 和 Graham Neubig。学习过滤上下文以进行检索增强生成。*arXiv 预印本 arXiv:2311.08377*，2023i 年。

+   Gou 等 [2023] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan 和 Weizhu Chen。Critic：大型语言模型可以通过工具交互批评自我纠正。*arXiv 预印本 arXiv:2305.11738*，2023 年。

+   Zhang 等 [2024c] Tianjun Zhang, Shishir G Patil, Naman Jain, Sheng Shen, Matei Zaharia, Ion Stoica 和 Joseph E Gonzalez。RAFT：将语言模型适应于特定领域的 RAG。*arXiv 预印本 arXiv:2403.10131*，2024c 年。

+   Kumar 等 [2022] Sachin Kumar, Biswajit Paria 和 Yulia Tsvetkov。基于梯度的语言模型约束采样。在 *2022 年自然语言处理实证方法会议论文集* 中，第 2251–2277 页，2022 年。

+   Miao 等 [2019] Ning Miao, Hao Zhou, Lili Mou, Rui Yan 和 Lei Li。CGMH：通过 Metropolis-Hastings 采样约束句子生成。在 *AAAI 人工智能会议论文集* 中，第 33 卷，第 6834–6842 页，2019 年。

+   Li 等 [2023g] Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou 和 Weizhu Chen。通过步进感知验证器提升语言模型的推理能力。在 *计算语言学协会第 61 届年会论文集（第 1 卷：长篇论文）* 中，2023g 年。

+   Weng 等 [2023] Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Shengping Liu, Bin Sun, Kang Liu 和 Jun Zhao。大型语言模型在自我验证方面的推理能力更强。在 *计算语言学协会发现：EMNLP 2023* 中，2023 年。

+   Danilevsky 等 [2020] Marina Danilevsky, Kun Qian, Ranit Aharonov, Yannis Katsis, Ban Kawas 和 Prithviraj Sen。可解释 AI 在自然语言处理中的现状调查。*arXiv 预印本 arXiv:2010.00711*，2020 年。

+   Zhao 等 [2023e] Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin 和 Mengnan Du。大型语言模型的可解释性：一项调查。*arXiv 预印本 arXiv:2309.01029*，2023e 年。

+   Wiegreffe 和 Marasović [2021] Sarah Wiegreffe 和 Ana Marasović。教我如何解释：对可解释自然语言处理数据集的综述。*arXiv 预印本 arXiv:2102.12060*，2021 年。

+   Carton 等 [2022] Samuel Carton, Surya Kanoria 和 Chenhao Tan。学习什么以及如何学习：朝着从理由中有效学习迈进。在 *计算语言学协会发现：ACL 2022* 中，2022 年。

+   Gurrapu 等 [2023] Sai Gurrapu, Ajay Kulkarni, Lifu Huang, Ismini Lourentzou 和 Feras A Batarseh。可解释 NLP 的合理化：一项调查。*前沿人工智能*，6，2023 年。

+   Wang 等人 [2022c] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, 和 Denny Zhou。自一致性提升语言模型的思维链推理。*arXiv 预印本 arXiv:2203.11171*，2022c。

+   Sun 等人 [2023d] Jiashuo Sun, Yi Luo, Yeyun Gong, Chen Lin, Yelong Shen, Jian Guo, 和 Nan Duan。通过迭代引导增强大型语言模型的思维链提示。*arXiv 预印本 arXiv:2304.11657*，2023d。

+   Halawi 等人 [2023] Danny Halawi, Jean-Stanislas Denain, 和 Jacob Steinhardt。过度思考真相：理解语言模型如何处理虚假演示。*arXiv 预印本 arXiv:2307.09476*，2023。

+   Li 等人 [2023h] Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister, 和 Martin Wattenberg。推理时间干预：从语言模型中引出真实的回答。*arXiv 预印本 arXiv:2306.03341*，2023h。

+   van der Poel 等人 [2022] Liam van der Poel, Ryan Cotterell, 和 Clara Meister。互信息缓解抽象总结中的幻觉。*arXiv 预印本 arXiv:2210.13210*，2022。

生成于 2024 年 5 月 14 日 星期二 19:14:45，由 LaTeXML![吉祥物 Sammy](http://dlmf.nist.gov/LaTeXML/)
