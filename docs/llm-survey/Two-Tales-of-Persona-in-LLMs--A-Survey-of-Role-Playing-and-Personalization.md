<!--yml

类别: 未分类

日期: 2024-09-03 17:28:57

-->

# 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》

> 来源：[`arxiv.org/html/2406.01171`](https://arxiv.org/html/2406.01171)

1.  [1 引言](https://arxiv.org/html/2406.01171v2#S1 "在《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

1.  [2 LLM 角色扮演](https://arxiv.org/html/2406.01171v2#S2 "在《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

    1.  [2.1 环境](https://arxiv.org/html/2406.01171v2#S2.SS1 "在 2 LLM 角色扮演 ‣ 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

        1.  [2.1.1 软件开发](https://arxiv.org/html/2406.01171v2#S2.SS1.SSS1 "在 2.1 环境 ‣ 2 LLM 角色扮演 ‣ 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

        1.  [2.1.2 游戏](https://arxiv.org/html/2406.01171v2#S2.SS1.SSS2 "在 2.1 环境 ‣ 2 LLM 角色扮演 ‣ 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

        1.  [2.1.3 医疗应用](https://arxiv.org/html/2406.01171v2#S2.SS1.SSS3 "在 2.1 环境 ‣ 2 LLM 角色扮演 ‣ 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

        1.  [2.1.4 LLM-作为评估者](https://arxiv.org/html/2406.01171v2#S2.SS1.SSS4 "在 2.1 环境 ‣ 2 LLM 角色扮演 ‣ 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

    1.  [2.2 角色扮演模式](https://arxiv.org/html/2406.01171v2#S2.SS2 "在 2 LLM 角色扮演 ‣ 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

        1.  [单智能体](https://arxiv.org/html/2406.01171v2#S2.SS2.SSS0.Px1 "在 2.2 角色扮演模式 ‣ 2 LLM 角色扮演 ‣ 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

        1.  [多智能体](https://arxiv.org/html/2406.01171v2#S2.SS2.SSS0.Px2 "在 2.2 角色扮演模式 ‣ 2 LLM 角色扮演 ‣ 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

    1.  [2.3 角色扮演中的新兴行为](https://arxiv.org/html/2406.01171v2#S2.SS3 "在 2 LLM 角色扮演 ‣ 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

        1.  [自愿行为](https://arxiv.org/html/2406.01171v2#S2.SS3.SSS0.Px1 "在 2.3 角色扮演中的新兴行为 ‣ 2 LLM 角色扮演 ‣ 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

        1.  [顺应行为](https://arxiv.org/html/2406.01171v2#S2.SS3.SSS0.Px2 "在 2.3 角色扮演中的新兴行为 ‣ 2 LLM 角色扮演 ‣ 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

        1.  [破坏性行为](https://arxiv.org/html/2406.01171v2#S2.SS3.SSS0.Px3 "在 2.3 角色扮演中的新兴行为 ‣ 2 LLM 角色扮演 ‣ 《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

1.  [3 LLM 个性化](https://arxiv.org/html/2406.01171v2#S3 "在《LLMs 中的角色扮演和个性化的两个故事：角色扮演和个性化的调查》中")

    1.  [3.1 个性化推荐](https://arxiv.org/html/2406.01171v2#S3.SS1 "在 3 LLM 个性化 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

    1.  [3.2 个性化搜索](https://arxiv.org/html/2406.01171v2#S3.SS2 "在 3 LLM 个性化 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

    1.  [3.3 个性化教育](https://arxiv.org/html/2406.01171v2#S3.SS3 "在 3 LLM 个性化 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

    1.  [3.4 个性化医疗](https://arxiv.org/html/2406.01171v2#S3.SS4 "在 3 LLM 个性化 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

    1.  [3.5 个性化对话生成](https://arxiv.org/html/2406.01171v2#S3.SS5 "在 3 LLM 个性化 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

        1.  [ToD 建模](https://arxiv.org/html/2406.01171v2#S3.SS5.SSS0.Px1 "在 3.5 个性化对话生成 ‣ 3 LLM 个性化 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

        1.  [用户个性建模](https://arxiv.org/html/2406.01171v2#S3.SS5.SSS0.Px2 "在 3.5 个性化对话生成 ‣ 3 LLM 个性化 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

1.  [4 LLM 个性评估](https://arxiv.org/html/2406.01171v2#S4 "在 LLM 中的角色扮演与个性化的两个故事：个性化调查")

1.  [5 限制与未来方向](https://arxiv.org/html/2406.01171v2#S5 "在 LLM 中的角色扮演与个性化的两个故事：个性化调查")

    1.  [5.1 朝向通用框架](https://arxiv.org/html/2406.01171v2#S5.SS1 "在 5 限制与未来方向 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

    1.  [5.2 长上下文个性](https://arxiv.org/html/2406.01171v2#S5.SS2 "在 5 限制与未来方向 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

    1.  [5.3 数据集和基准的缺乏](https://arxiv.org/html/2406.01171v2#S5.SS3 "在 5 限制与未来方向 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

    1.  [5.4 偏见](https://arxiv.org/html/2406.01171v2#S5.SS4 "在 5 限制与未来方向 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

    1.  [5.5 安全性与隐私](https://arxiv.org/html/2406.01171v2#S5.SS5 "在 5 限制与未来方向 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

    1.  [5.6 更广泛的影响](https://arxiv.org/html/2406.01171v2#S5.SS6 "在 5 限制与未来方向 ‣ LLM 中的角色扮演与个性化的两个故事：个性化调查")

1.  [6 结论](https://arxiv.org/html/2406.01171v2#S6 "在 LLM 中的角色扮演与个性化的两个故事：个性化调查")

1.  [一个网页](https://arxiv.org/html/2406.01171v2#A1 "在 LLMs 中的两个角色故事：角色扮演和个性化的调查")

    1.  [HTML 理解](https://arxiv.org/html/2406.01171v2#A1.SS0.SSS0.Px1 "在附录 A 网页 ‣ LLMs 中的角色扮演和个性化：一个调查")

    1.  [视觉基础](https://arxiv.org/html/2406.01171v2#A1.SS0.SSS0.Px2 "在附录 A 网页 ‣ LLMs 中的角色扮演和个性化：一个调查")。

# LLMs 中的两个角色故事：

角色扮演和个性化调查

Yu-Min Tseng^*^α^β Yu-Chao Huang^*^α Teng-Yun Hsiao^*^α Wei-Lin Chen^*^γ

Chao-Wei Huang^α Yu Meng^γ Yun-Nung Chen^α

^α国立台湾大学 ^β中央研究院 ^γ弗吉尼亚大学

ymtseng@nlg.csie.ntu.edu.tw

yumeng5@virginia.edu, y.v.chen@ieee.org

\faGithub [`github.com/MiuLab/PersonaLLM-Survey`](https://github.com/MiuLab/PersonaLLM-Survey)

###### 摘要

人物概念最初应用于对话文献，现已重新成为定制大型语言模型（LLMs）以适应特定上下文（例如个性化搜索、LLM 作为裁判）的有前途框架。然而，利用人物概念的研究尚显零散，缺乏系统的分类。为填补这一空白，我们提供了一个全面的调查，以对当前领域的状态进行分类。我们识别了两条研究线索，即（1）LLM 角色扮演，其中将人物分配给 LLMs，以及（2）LLM 个性化，其中 LLMs 关注用户人物。此外，我们介绍了现有的 LLM 个性评估方法。据我们所知，这是首次从统一人物视角对 LLMs 中的角色扮演和个性化进行的调查。我们不断维护文献集，以促进未来的研究。^*^*脚注：贡献相等。

LLMs 中的两个角色故事：

角色扮演和个性化调查

Yu-Min Tseng^*^α^β Yu-Chao Huang^*^α Teng-Yun Hsiao^*^α Wei-Lin Chen^*^γ Chao-Wei Huang^α Yu Meng^γ Yun-Nung Chen^α ^α国立台湾大学 ^β中央研究院 ^γ弗吉尼亚大学 ymtseng@nlg.csie.ntu.edu.tw yumeng5@virginia.edu, y.v.chen@ieee.org \faGithub [`github.com/MiuLab/PersonaLLM-Survey`](https://github.com/MiuLab/PersonaLLM-Survey)

![参考图注](img/5ef62bde5736f5f34fe024e9df6e0e39.png)

图 1：在角色扮演中，LLMs 根据分配的角色（即角色）在定义的环境中行动。例如，给定带有描述的角色名称，LLMs 在社交模拟游戏中进行角色扮演。对于个性化，LLMs 考虑用户角色以生成针对相同问题的量身定制的回应。虚线矩形为提示，实线矩形为 LLMs 的回应。

## 1 引言

大型语言模型（LLMs）的显著能力，以 ChatGPT OpenAI ([2022](https://arxiv.org/html/2406.01171v2#bib.bib90)) 为例，显著推动了自然语言处理（NLP； Wei 等，[2023](https://arxiv.org/html/2406.01171v2#bib.bib129)； Madaan 等，[2024](https://arxiv.org/html/2406.01171v2#bib.bib86)； Shinn 等，[2024](https://arxiv.org/html/2406.01171v2#bib.bib105)）领域的发展。最近，除了将 LLMs 作为 NLP 任务解决者或通用聊天机器人外，如何将 LLMs 适应特定上下文的问题引起了极大的关注。为此，利用角色模型作为适应 LLMs 的理想视角重新受到关注（Chen 等，[2023a](https://arxiv.org/html/2406.01171v2#bib.bib17)，[2024](https://arxiv.org/html/2406.01171v2#bib.bib16)）。通过引入角色模型，LLMs 可以生成更符合上下文的响应，从而最大化其在特定应用中的实用性和效果。然而，关于 LLM 时代角色模型的文献日益增多，但相对较为零散，缺乏统一的概述。

{forest}

对于树形图= 分叉边，绘制=edgeColor，粗体，字体=，填充=tnodeColor，矩形，圆角=4pt，文本=textColor，模糊阴影=阴影比例=0.95，阴影 x 偏移=.5ex，阴影 y 偏移=-.5ex，阴影透明度=0.25，边=，绘制=edgeColor，线宽=2pt，增长=0，子节点锚点=west，父节点锚点=east，锚点=west，居中对齐，l sep+=0.3cm，s sep+=0.1cm，根节点/.style= 填充=Gray!15，字体=，圆角=6pt，文本宽度=4cm，/tikz/居中对齐，内边距=6pt，tnode2_1/.style=填充=Gray!15，字体=，文本宽度=12cm，/tikz/居中对齐，内边距=6pt，tnode2_2/.style=填充=Gray!15，字体=，文本宽度=11cm，/tikz/居中对齐，内边距=6pt，tnode2_3/.style=填充=Gray!15，字体=，文本宽度=12cm，/tikz/居中对齐，内边距=6pt，tnode3_1/.style=填充=Gray!15，字体=，文本宽度=12cm，/tikz/居中对齐，内边距=6pt，tnode3_2/.style=填充=Gray!15，字体=，文本宽度=11cm，/tikz/居中对齐，内边距=6pt，tnode3_3/.style=填充=Gray!15，字体=，文本宽度=12cm，/tikz/居中对齐，内边距=6pt，[分类学，根节点 [LLM 个性评估 [第四部分](https://arxiv.org/html/2406.01171v2#S4 "4 LLM Personality Evaluation ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode2_1 [BigFive; MBTI; 等，tnode2_2] ] [LLM 个性化 [第三部分](https://arxiv.org/html/2406.01171v2#S3 "3 LLM Personalization ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode2_1 [对话 [第 3.5 节](https://arxiv.org/html/2406.01171v2#S3.SS5 "3.5 Personalized Dialogue Generation ‣ 3 LLM Personalization ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode2_2 [用户个性建模，tnode2_3] [任务导向建模，tnode2_3] ] [医疗 [第 3.4 节](https://arxiv.org/html/2406.01171v2#S3.SS4 "3.4 Personalized Healthcare ‣ 3 LLM Personalization ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode2_2] [教育 [第 3.3 节](https://arxiv.org/html/2406.01171v2#S3.SS3 "3.3 Personalized Education ‣ 3 LLM Personalization ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode2_2] [搜索 [第 3.2 节](https://arxiv.org/html/2406.01171v2#S3.SS2 "3.2 Personalized Search ‣ 3 LLM Personalization ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode2_2] [推荐 [第 3.1 节](https://arxiv.org/html/2406.01171v2#S3.SS1 "3.1 Personalized Recommendation ‣ 3 LLM Personalization ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode2_2] ] [LLM 角色扮演 [第二部分](https://arxiv.org/html/2406.01171v2#S2 "2 LLM Role-Playing ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode3_1 [新兴行为 [第 2.3 节](https://arxiv.org/html/2406.01171v2#S2.SS3 "2.3 Emergent Behaviors in Role-Playing ‣ 2 LLM Role-Playing ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode3_2 [破坏性行为，tnode3_3] [顺从行为，tnode3_3] [自愿行为，tnode3_3] ] [角色扮演模式 [第 2.2 节](https://arxiv.org/html/2406.01171v2#S2.SS2 "2.2 Role-Playing Schema ‣ 2 LLM Role-Playing ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode3_2 [多智能体，tnode3_3] [单智能体，tnode3_3] ] [环境 [第 2.1 节](https://arxiv.org/html/2406.01171v2#S2.SS1 "2.1 Environments ‣ 2 LLM Role-Playing ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode3_2 [LLM 作为评估者 [第 2.1.4 节](https://arxiv.org/html/2406.01171v2#S2.SS1.SSS4 "2.1.4 LLM-as-Evaluator ‣ 2.1 Environments ‣ 2 LLM Role-Playing ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode3_3] [医疗应用 [第 2.1.3 节](https://arxiv.org/html/2406.01171v2#S2.SS1.SSS3 "2.1.3 Medical Application ‣ 2.1 Environments ‣ 2 LLM Role-Playing ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode3_3] [游戏 [第 2.1.2 节](https://arxiv.org/html/2406.01171v2#S2.SS1.SSS2 "2.1.2 Game ‣ 2.1 Environments ‣ 2 LLM Role-Playing ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode3_3] [软件开发 [第 2.1.1 节](https://arxiv.org/html/2406.01171v2#S2.SS1.SSS1 "2.1.1 Software Development ‣ 2.1 Environments ‣ 2 LLM Role-Playing ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，tnode3_3] ] ] ]

图 2：LLM 角色扮演和 LLM 个性化的分类系统。

在本文中，我们旨在通过提供全面的调查和现有研究的系统分类来弥合差距。具体而言，我们将当前的研究分为两个主要方向，即 LLM 角色扮演和 LLM 个性化，如[图 1](https://arxiv.org/html/2406.01171v2#S0.F1 "在 LLMs 中的角色扮演与个性化的两个故事：角色扮演和个性化的调查")所示。主要区别在于，在角色扮演中，角色属于 LLM，而在个性化中，角色属于用户。定义详见下文。

+   •

    LLM 角色扮演：LLM 被任务赋予角色（即角色）并根据环境反馈进行行动，适应环境。

+   •

    LLM 个性化：LLM 被任务赋予照顾用户角色（例如，背景信息或历史行为）以满足个性化需求，适应不同的用户。

据我们所知，我们提供了第一个关于 LLM 角色扮演和 LLM 个性化的统一视角的调查。为了促进未来的努力，我们积极维护一个供研究社区使用的论文集合。我们期望这项工作既能作为对新人的有价值的介绍，也能作为当前研究人员的全面资源。

我们的分类系统在[图 2](https://arxiv.org/html/2406.01171v2#S1.F2 "在引言 ‣ LLMs 中的角色扮演与个性化的两个故事：角色扮演和个性化的调查")中进行了说明。我们首先介绍 LLM 角色扮演[第二部分](https://arxiv.org/html/2406.01171v2#S2 "2 LLM 角色扮演 ‣ LLMs 中的角色扮演与个性化的两个故事：角色扮演和个性化的调查")，随后介绍 LLM 个性化[第三部分](https://arxiv.org/html/2406.01171v2#S3 "3 LLM 个性化 ‣ LLMs 中的角色扮演与个性化的两个故事：角色扮演和个性化的调查")。接下来，我们提供了评估方法的概述[第四部分](https://arxiv.org/html/2406.01171v2#S4 "4 LLM 个性评估 ‣ LLMs 中的角色扮演与个性化的两个故事：角色扮演和个性化的调查")，评估 LLM 的个性（例如，个性特征或心理行为）是否在适应后（即，对角色扮演 LLM 根据分配的角色行为和个性化 LLM 适应用户角色）准确地符合预期角色。最后，我们强调了当前的挑战和未来方向[第五部分](https://arxiv.org/html/2406.01171v2#S5 "5 限制与未来方向 ‣ LLMs 中的角色扮演与个性化的两个故事：角色扮演和个性化的调查")。附录中提供了基准和数据集的全面列表。

## 2 LLM 角色扮演

![参见说明](img/a4b9b632e5e703f5e894dcd86077b86d.png)

图 3：五种 LLM 角色扮演环境的示例：软件开发 [第 2.1.1 节](https://arxiv.org/html/2406.01171v2#S2.SS1.SSS1 "2.1.1 软件开发 ‣ 2.1 环境 ‣ 2 LLM 角色扮演 ‣ LLM 中的角色的两个故事：角色扮演与个性化的调查")，游戏 [第 2.1.2 节](https://arxiv.org/html/2406.01171v2#S2.SS1.SSS2 "2.1.2 游戏 ‣ 2.1 环境 ‣ 2 LLM 角色扮演 ‣ LLM 中的角色的两个故事：角色扮演与个性化的调查")，医疗应用 [第 2.1.3 节](https://arxiv.org/html/2406.01171v2#S2.SS1.SSS3 "2.1.3 医疗应用 ‣ 2.1 环境 ‣ 2 LLM 角色扮演 ‣ LLM 中的角色的两个故事：角色扮演与个性化的调查")，以及 LLM 作为评估者 [第 2.1.4 节](https://arxiv.org/html/2406.01171v2#S2.SS1.SSS4 "2.1.4 LLM 作为评估者 ‣ 2.1 环境 ‣ 2 LLM 角色扮演 ‣ LLM 中的角色的两个故事：角色扮演与个性化的调查")。对于每种环境，我们提供了一个带有任务描述（红色边框）和相关角色（即角色；蓝色边框）的简单场景。虚线矩形表示一个 LLM 角色扮演提示模板。除了上述环境之外，过去的研究还提出了一些适用于不同环境的一般框架 [第 5.1 节](https://arxiv.org/html/2406.01171v2#S5.SS1 "5.1 朝着一般框架的方向 ‣ 5 局限性和未来方向 ‣ LLM 中的角色的两个故事：角色扮演与个性化的调查")。

基于 LLM 的语言代理最近展示了令人印象深刻的能力，如计划、反思和工具使用 (Yao et al. ([2022b](https://arxiv.org/html/2406.01171v2#bib.bib141)); Shinn et al. ([2024](https://arxiv.org/html/2406.01171v2#bib.bib105)); Yao et al. ([2024](https://arxiv.org/html/2406.01171v2#bib.bib140)))。LLM 角色扮演的主要方法是通过将角色与语言代理结合，具体而言，是通过将角色直接包含在语言代理的提示中。这种无需训练的范式由于其简单性和有效性而特别受到青睐。

角色扮演的语言代理通过引发 LLM 中的相应参数化知识，生成与指定角色（即角色）一致的响应，使其能够适应各种互动环境。LLM 角色扮演还扩展到多代理设置，其中多个语言代理被赋予不同的角色，相互合作和沟通以解决复杂任务 (Guo et al., [2024](https://arxiv.org/html/2406.01171v2#bib.bib41))。例如，在角色扮演 LLM 的早期研究之一中，Park et al. ([2023](https://arxiv.org/html/2406.01171v2#bib.bib93)) 提出了生成代理，这些代理通过根据提示中指定的名字、年龄和性格特征模拟人类行为，参与社交模拟环境。

接下来，我们介绍 LLMS 适应的不同环境和相关角色 [第 2.1 节](https://arxiv.org/html/2406.01171v2#S2.SS1 "2.1 Environments ‣ 2 LLM Role-Playing ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，LLMs 在环境中的互动 [第 2.2 节](https://arxiv.org/html/2406.01171v2#S2.SS2 "2.2 Role-Playing Schema ‣ 2 LLM Role-Playing ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")，以及由这些互动引发的突现行为 [第 2.3 节](https://arxiv.org/html/2406.01171v2#S2.SS3 "2.3 Emergent Behaviors in Role-Playing ‣ 2 LLM Role-Playing ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")。[图 3](https://arxiv.org/html/2406.01171v2#S2.F3 "In 2 LLM Role-Playing ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization") 提供了一个说明性的概述。

### 2.1 环境

#### 2.1.1 软件开发

对于软件开发，目标通常涉及设计程序或编码项目。例如，“创建一个贪吃蛇游戏。” 或 “创建一个 Python 程序来开发一个互动天气仪表板。” (Hong et al., [2023a](https://arxiv.org/html/2406.01171v2#bib.bib50))。由于这些任务的复杂性，通常过于复杂以至于第一次尝试无法正确完成，现有研究利用如瀑布模型 Petersen et al. ([2009](https://arxiv.org/html/2406.01171v2#bib.bib95)); Bassil ([2012](https://arxiv.org/html/2406.01171v2#bib.bib10)) 或标准操作程序 (SOPs) Belbin and Brown ([2022](https://arxiv.org/html/2406.01171v2#bib.bib11)); DeMarco and Lister ([2013](https://arxiv.org/html/2406.01171v2#bib.bib27)) 等方法，将任务分解为可管理的子任务。

类似于现实世界的设置，LLMs 角色扮演以在协作的多代理软件开发环境中运作 Qian et al. ([2023](https://arxiv.org/html/2406.01171v2#bib.bib96)); Hong et al. ([2023a](https://arxiv.org/html/2406.01171v2#bib.bib50)); Dong et al. ([2023](https://arxiv.org/html/2406.01171v2#bib.bib32))。不同的角色包括首席技术官 (CTO)、首席产品官 (CPO)、首席执行官 (CEO)、产品经理、工程师、审阅者和测试人员。通过分配特定角色，LLMs 能够以逐步和准确的方式执行任务。

最近的工作 Dong 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib32)) 提出了首个自我协作框架之一，涵盖了多个 LLM 代理之间的劳动分工和协作，每个代理作为专门的“专家”来解决复杂的代码生成任务。遵循瀑布模型，ChatDev (Qian 等人，[2023](https://arxiv.org/html/2406.01171v2#bib.bib96)) 将开发过程分为四个阶段：设计、编码、测试和文档编制，并提出了 Chat Chain 来将每个阶段分解为一系列原子子任务。与上述工作不同，MetaGPT (Hong 等人，[2023a](https://arxiv.org/html/2406.01171v2#bib.bib50)) 要求 LLM 代理生成结构化输出而非自由文本，展示了目标代码生成成功率的显著提高。

#### 2.1.2 游戏

LLM 已经成为各种游戏环境中代理的有效支柱，包括 Minecraft (Wang 等人，[2023a](https://arxiv.org/html/2406.01171v2#bib.bib120))、社交模拟 (Park 等人，[2023](https://arxiv.org/html/2406.01171v2#bib.bib93); Wang 等人，[2023d](https://arxiv.org/html/2406.01171v2#bib.bib128)) 和讨价还价游戏 (Fu 等人，[2023](https://arxiv.org/html/2406.01171v2#bib.bib37))。在这些环境中，LLM 被要求扮演通用助手 (Wang 等人，[2023a](https://arxiv.org/html/2406.01171v2#bib.bib120))，或与环境相关的角色，如买家和卖家 (Fu 等人，[2023](https://arxiv.org/html/2406.01171v2#bib.bib37))。游戏环境通常包含广泛的信息，包括设置、可用工具和周边情况，这对 LLM 记忆和响应提出了挑战。因此，基于检索的记忆流方法是语言代理在游戏环境中角色扮演有效性的关键组成部分 (Park 等人，[2023](https://arxiv.org/html/2406.01171v2#bib.bib93); Wang 等人，[2023a](https://arxiv.org/html/2406.01171v2#bib.bib120))。

#### 2.1.3 医疗应用

在医学领域环境中，Wu 等人 ([2023a](https://arxiv.org/html/2406.01171v2#bib.bib131)) 提出了 DR-CoT 提示，这是首个利用 LLM 角色扮演进行诊断推理的方法。通过模仿医生的潜在思维过程，DR-CoT 相较于标准提示表现出显著改进。然后，Kwon 等人 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib68)) 通过知识蒸馏将这种成功扩展到基于图像的诊断，解决了在现实临床环境中的应用问题。另一个工作，MedAgent (Tang 等人，[2023a](https://arxiv.org/html/2406.01171v2#bib.bib116))，引入了一个多代理协作框架，通过五个过程：专家收集、分析提议、报告总结、协作咨询和决策，来模拟实际的医疗场景。

这些研究为 LLM 分配了医学相关的角色，从一般的角色如医生和病人到具体的如神经学和精神病学专家。研究表明，LLM 本身具有医学知识（Liévin 等，[2024](https://arxiv.org/html/2406.01171v2#bib.bib77)），通过 LLM 角色扮演成功地提升了表现。

#### 2.1.4 LLM 作为评估者

采用强大的 LLM 作为评估者的概念已经成为评估 LM 对齐的实际框架。研究表明，LLM 能够评估模型回应中的类人价值观，LLM 作出的判断可能比传统指标与人类真实情况的相关性更高（Chiang 和 Lee，[2023](https://arxiv.org/html/2406.01171v2#bib.bib23); Wang 等，[2023b](https://arxiv.org/html/2406.01171v2#bib.bib126); Lin 和 Chen，[2023](https://arxiv.org/html/2406.01171v2#bib.bib78)）。

为了更接近人类评估，LLM 作为评估者环境中的角色涵盖了广泛的范围，代表了社会中各种人类视角，如普通公众、批评者和新闻作者。在 LLM 作为法官的环境中（Zheng 等，[2023](https://arxiv.org/html/2406.01171v2#bib.bib150)），LLM 扮演公正的法官，并考虑有用性、相关性、准确性、深度和创造性等因素。Wu 等（[2023b](https://arxiv.org/html/2406.01171v2#bib.bib133)）提出了 DRPE，通过根据任务设置将 LLM 静态地分配客观角色和动态地分配主观角色来评估摘要的质量。另一个工作，ChatEval（Chan 等，[2023](https://arxiv.org/html/2406.01171v2#bib.bib13)），进一步在角色中添加讨论回合，以改善评估过程，模拟现实中的法官小组。

### 2.2 角色扮演方案

我们将 LLM 角色扮演环境中的方案分为两类：单代理和多代理。

##### 单代理

我们定义单代理方案为：一个代理能够独立实现其目标而不依赖于其他人，尽管多个代理可能在同一环境中共存。

单代理方案在游戏环境中最为常见，在这种环境下，LLM 更关注环境信息和反馈，而非协作。例如，Voyager（Wang 等，[2023a](https://arxiv.org/html/2406.01171v2#bib.bib120)）代理扮演一般助手角色，任务是持续探索定义的环境，获取多样的技能，并在 Minecraft 中做出新的发现。尽管 Minecraft 中存在多个 Voyager 代理，但每个代理都能独立探索游戏世界。

##### 多代理

我们定义多代理方案为：其他代理的支持（例如，协作和沟通）对一个代理实现其目标是必要的。

软件开发和医疗应用是多智能体模型的主要应用环境。与现实世界类似，环境中的交互至关重要。代表性的工作如 AgentVerse (Chen et al., [2023c](https://arxiv.org/html/2406.01171v2#bib.bib19)) 和 ChatDev (Qian et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib96)) 都提出了多智能体框架，通过信息交换和合作高效地完成任务。此外，我们在多智能体模型中识别出两种合作范式 (Xi et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib134); Guo et al., [2024](https://arxiv.org/html/2406.01171v2#bib.bib41))：合作型和对抗型。合作型范式促进智能体之间的信息共享，例如，一些工作使用消息池来存储每个智能体的当前状态和正在进行的任务 (Hong et al., [2023a](https://arxiv.org/html/2406.01171v2#bib.bib50); Tang et al., [2023a](https://arxiv.org/html/2406.01171v2#bib.bib116); Chen et al., [2023c](https://arxiv.org/html/2406.01171v2#bib.bib19))。对于对抗型范式，包括辩论、竞争和批评，通过采纳对立的观点来增强决策过程并寻求更多优势 (Chan et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib13); Fu et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib37))。

![参考标题](img/9df2a699c179d7d103da938773675ba1.png)

图 4：五种个性化 LLM 的示意图：推荐 [第 3.1 节](https://arxiv.org/html/2406.01171v2#S3.SS1 "3.1 个性化推荐 ‣ 3 LLM 个性化 ‣ LLMs 中的角色扮演与个性化：一个综述")、搜索 [第 3.2 节](https://arxiv.org/html/2406.01171v2#S3.SS2 "3.2 个性化搜索 ‣ 3 LLM 个性化 ‣ LLMs 中的角色扮演与个性化：一个综述")、教育 [第 3.3 节](https://arxiv.org/html/2406.01171v2#S3.SS3 "3.3 个性化教育 ‣ 3 LLM 个性化 ‣ LLMs 中的角色扮演与个性化：一个综述")、医疗 [第 3.4 节](https://arxiv.org/html/2406.01171v2#S3.SS4 "3.4 个性化医疗 ‣ 3 LLM 个性化 ‣ LLMs 中的角色扮演与个性化：一个综述") 和对话 [第 3.5 节](https://arxiv.org/html/2406.01171v2#S3.SS5 "3.5 个性化对话生成 ‣ 3 LLM 个性化 ‣ LLMs 中的角色扮演与个性化：一个综述")。左侧，虚线矩形表示提示，实线矩形表示 LLM 的响应。右侧，我们描绘了 LLM 和用户之间的多轮交互。

### 2.3 角色扮演中的 emergent 行为

在多智能体模式下，不同的行为反映了人类社会中的现象（例如，遵从和达成共识），这些现象通过 LLMs 的协作而显现。我们介绍了 Chen et al. ([2023c](https://arxiv.org/html/2406.01171v2#bib.bib19))提出的三种协作行为。

##### 自愿行为

自愿行为通常发生在合作协作模式中，在这种模式下，代理主动协助其同伴或询问是否有任何可以帮助的事项，以实现团队目标。此外，他们可能会向其他人贡献资源，如未分配的时间和拥有的材料。通过自愿行为，LLMs 提升了团队效率，并在特定环境中展示了凝聚力和承诺 (Chen et al., [2023c](https://arxiv.org/html/2406.01171v2#bib.bib19); Hong et al., [2023a](https://arxiv.org/html/2406.01171v2#bib.bib50))。

##### 遵从行为

遵从行为发生在代理偏离团队目标的情况下。在收到他人的批评和建议后，偏离的代理会改进和调整其行为或决策，以更好地与团队合作。通过遵从行为，LLMs 与共同目标对齐，追求更高的准确性和完整性 (Tang et al., [2023a](https://arxiv.org/html/2406.01171v2#bib.bib116); Fu et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib37))。

##### 破坏性行为

有时，LLMs 会采取各种行动，导致不希望的和有害的结果。例如，它可能表现出一种试图控制世界的坏心态 (Li et al., [2024a](https://arxiv.org/html/2406.01171v2#bib.bib69))。此外，LLMs 可能在赋予角色时展示毒性或暴露根深蒂固的刻板偏见 (Deshpande et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib30); Gupta et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib42))。这种破坏性行为引发了关于角色扮演的安全性和偏见问题。

## 3 LLM 个性化

对齐 LLMs 与用户意图的主要方法通常利用人类反馈的强化学习（RLHF），这一过程将集体意识和偏见注入模型中。为了增强个人体验和偏好，个性化 LLMs 考虑用户角色（例如，个人信息、历史行为）并满足定制需求 Chen et al. ([2023e](https://arxiv.org/html/2406.01171v2#bib.bib21)); Deshpande et al. ([2024](https://arxiv.org/html/2406.01171v2#bib.bib29))。接下来，我们介绍各种个性化任务及实现个性化的相关方法。 [图 4](https://arxiv.org/html/2406.01171v2#S2.F4 "在多智能体 ‣ 2.2 角色扮演模式 ‣ 2 LLM 角色扮演 ‣ LLM 中的角色扮演与个性化：一个角色扮演和个性化的调查") 展示了个性化任务的示意概述。

### 3.1 个性化推荐

推荐系统旨在向用户推荐与其偏好匹配的项目（例如书籍或电影）。我们在[表 2](https://arxiv.org/html/2406.01171v2#A1.T2 "In Visual Grounding. ‣ Appendix A Web ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")中比较了现有研究，并在[表 3](https://arxiv.org/html/2406.01171v2#A1.T3 "In Visual Grounding. ‣ Appendix A Web ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")中汇编了相关数据集。

现有研究探索了各种用于推荐系统的 LLMs 提示方法。Li 等人（[2023a](https://arxiv.org/html/2406.01171v2#bib.bib71)）开发了一种高效整合用户个人信息的方法。Li 等人（[2023b](https://arxiv.org/html/2406.01171v2#bib.bib72)）通过 LLMs 提示调优将方面提取与基于方面的推荐相结合。Chen 等人（[2022](https://arxiv.org/html/2406.01171v2#bib.bib15)）生成个性化闲聊以增强推荐。Yang 等人（[2023b](https://arxiv.org/html/2406.01171v2#bib.bib138)）专注于框架设计，提出了一种新颖的 LLM 微调推荐系统。Chu 等人（[2023](https://arxiv.org/html/2406.01171v2#bib.bib24)）融合不同的推荐系统，以有效整合 LLMs 的常识和推理能力。Hu 等人（[2024](https://arxiv.org/html/2406.01171v2#bib.bib53)）提出了一种序列推荐框架，以保留细粒度的项目文本信息。

很多研究集中在零样本设置上，利用 LLMs 强大的开箱即用能力。Wang 和 Lim（[2023](https://arxiv.org/html/2406.01171v2#bib.bib122)）采用三步提示流程以实现更好的零样本下一个项目推荐。Hou 等人（[2024](https://arxiv.org/html/2406.01171v2#bib.bib52)）提出了一种通过上下文学习的零样本序列推荐系统。Zhang 等人（[2023](https://arxiv.org/html/2406.01171v2#bib.bib144)）通过允许用户自由互动和通过自然语言指令获得更精确的推荐，从而提升了用户友好性。为了提高泛化能力，Wang 等人（[2024d](https://arxiv.org/html/2406.01171v2#bib.bib125)）强调当前推荐系统主要关注特定任务，缺乏对新任务的泛化能力。他们提出了一种用于一般推荐目的的 LLM 驱动代理。尽管基于 LLM 的个性化搜索系统提供了更便捷和简单的信息搜索解决方案，但确保合成结果的问责性和可信度仍需进一步发展 Li 等人（[2024b](https://arxiv.org/html/2406.01171v2#bib.bib75)）。

### 3.2 个性化搜索

与传统搜索系统相比，后者提供难以组织的相关结果列表且仅限于简单查询，个性化搜索系统能够理解复杂查询和过去的互动，以推断用户偏好，综合来自多个来源的信息，并以连贯的自然语言形式呈现。

Spatharioti et al. ([2023](https://arxiv.org/html/2406.01171v2#bib.bib110)) 证明了基于 LLM 的搜索系统在某些情况下提高了用户的表现。Ziems et al. ([2023](https://arxiv.org/html/2406.01171v2#bib.bib156)) 建议 LLMs 可以作为内置搜索引擎进行少量示例演示。具体来说，LLMs 可以生成正确的网页 URL 以对应文档。在 Zhou et al. ([2021](https://arxiv.org/html/2406.01171v2#bib.bib154)) 的基础上，Zhou et al. ([2024](https://arxiv.org/html/2406.01171v2#bib.bib155)) 提出了一个将认知记忆机制与 LLMs 结合以实现个性化搜索的策略，使 LLMs 能够高效地检索记忆。一些研究还利用搜索引擎结果来增强 LLM 个性化 (Baek et al., [2024](https://arxiv.org/html/2406.01171v2#bib.bib9)); Salemi and Zamani ([2024](https://arxiv.org/html/2406.01171v2#bib.bib101))。实证研究表明，Sharma et al. ([2024](https://arxiv.org/html/2406.01171v2#bib.bib103)) 进行了实验，调查 LLM 驱动的搜索系统如何导致观点极化。

### 3.3 个性化教育

大型语言模型（LLMs）的能力可以以多种方式促进个性化教育。例如，LLMs 可以提供详细的、逐步的解释，以苏格拉底式教学风格进行讲解 (Hao et al., [2024](https://arxiv.org/html/2406.01171v2#bib.bib46))，回答有关技术和复杂主题的问题 (Arefeen et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib7))，以及自动总结讲座以增强学习体验 (Gonzalez et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib40))。

个性化 LLMs 有潜力创建一个更加包容和公平的教育生态系统，从而避免个人支付不成比例的费用。近期的研究展示了将 LLMs 融入教育环境的各种机会和愿景。这些应用范围从个性化学习和教学辅助到作业评估和反馈 (Kasneci et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib64)); Wang et al. ([2024b](https://arxiv.org/html/2406.01171v2#bib.bib123)); Jeon and Lee ([2023](https://arxiv.org/html/2406.01171v2#bib.bib59)); Huber et al. ([2024](https://arxiv.org/html/2406.01171v2#bib.bib56))。

例如，EduChat Dan 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib26)) 在教育语料库上预训练模型，以建立基础知识库，随后在个性化任务如作文评估、苏格拉底式教学或情感支持上对模型进行微调。HumSum Shehata 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib104)) 总结了来自不同场景的个性化讲座稿，考虑了长度、深度、语调和复杂性等因素。随后通过提示调整来修改摘要，以适应用户提供的个性化选项。Park 等人 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib94)) 将学生的情感状态、认知状态和学习风格纳入提示中，以创建一个基于对话的个性化辅导系统。

### 3.4 个性化医疗

LLMs 在一系列通用生物医学任务中展示了专家级的能力，并有潜力融入人们的日常生活中，Cohan 等人 ([2020](https://arxiv.org/html/2406.01171v2#bib.bib25))；Milne-Ives 等人 ([2020](https://arxiv.org/html/2406.01171v2#bib.bib87))；Singhal 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib106))；Saab 等人 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib100))；Abbasian 等人 ([2024b](https://arxiv.org/html/2406.01171v2#bib.bib2))。

为了实现个性化医疗助理，Abbasian 等人 ([2024a](https://arxiv.org/html/2406.01171v2#bib.bib1)) 提出了 openCHA，一个集成外部数据和个性化健康数据的 LLM 代理框架，以解决个性化医疗问题。继 openCHA 之后，Abbasian 等人 ([2024c](https://arxiv.org/html/2406.01171v2#bib.bib3)) 注入领域特定知识，以有效利用健康数据、知识库和分析工具来应对与糖尿病相关的问题。MaLP Zhang 等人 ([2024a](https://arxiv.org/html/2406.01171v2#bib.bib145)) 将参数高效微调（PEFT）与记忆检索模块结合，以生成个性化的医疗回应。其他框架如 HealthLLM Jin 等人 ([2024b](https://arxiv.org/html/2406.01171v2#bib.bib63)) 结合 LlamaIndex Liu ([2022](https://arxiv.org/html/2406.01171v2#bib.bib79)) 来进行诊断预测，并能够根据用户提供的症状描述生成个性化医疗建议。此外，LLMs 在心理治疗方面也显示出巨大潜力，Stade 等人 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib111))；Chen 等人 ([2023b](https://arxiv.org/html/2406.01171v2#bib.bib18))；Xu 等人 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib136))。

### 3.5 个性化对话生成

根据目标，对话生成任务可以分为：（1）任务导向对话建模（ToD 建模）和（2）用户个性建模。接下来我们讨论 ToD 建模和用户个性。我们还在[表 4](https://arxiv.org/html/2406.01171v2#A1.T4 "在视觉定位中。 ‣ 附录 A 网页 ‣ LLM 中的个性化角色扮演两则：角色扮演和个性化的调查")中整理了各种对话生成数据集。

##### ToD 建模

ToD 建模引导用户通过多个交互步骤完成特定任务，例如酒店预订或餐厅预约。参见[表 5](https://arxiv.org/html/2406.01171v2#A1.T5 "在视觉定位中。 ‣ 附录 A 网页 ‣ LLM 中的个性化角色扮演两则：角色扮演和个性化的调查")中的示例。

Hudeček 和 Dusek ([2023](https://arxiv.org/html/2406.01171v2#bib.bib57)) 利用指令调整的 LLMs，并采用上下文学习进行检索和状态跟踪。关注事实准确性，RefGPT Yang 等人 ([2023a](https://arxiv.org/html/2406.01171v2#bib.bib137)) 通过用可靠来源扩展对话历史生成真实的响应，并使用提示来根据预定义的对话设置引导 LLM。Li 等人 ([2024c](https://arxiv.org/html/2406.01171v2#bib.bib76))；Hu 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib54)) 探索了提示扩展；另一方面，DSP Li 等人 ([2024c](https://arxiv.org/html/2406.01171v2#bib.bib76)) 训练了一个小型策略模型来生成提示并引导 LLMs 完成任务。许多研究使用 LLMs 生成多轮对话作为训练数据集（Yang 等人，[2023a](https://arxiv.org/html/2406.01171v2#bib.bib137)；Huryn 等人，[2022](https://arxiv.org/html/2406.01171v2#bib.bib58)；Xu 等人，[2023](https://arxiv.org/html/2406.01171v2#bib.bib135)）。此外，个性化对话已被应用于视频游戏中的程序化内容生成，用于定制对话生成（Ashby 等人，[2023](https://arxiv.org/html/2406.01171v2#bib.bib8)）。

##### 用户个性建模

用户个性建模基于对话历史检测用户个性，并生成量身定制的响应以适应每个用户。参见[附录 A](https://arxiv.org/html/2406.01171v2#A1.SS0.SSS0.Px2 "视觉定位。 ‣ 附录 A 网页 ‣ LLM 中的个性化角色扮演两则：角色扮演和个性化的调查")中的示例。

CoBert Zhong 等人（[2020](https://arxiv.org/html/2406.01171v2#bib.bib151)）提出了基于 persona 的同理心对话，使用 BERT 和双跳协同注意机制，Lu 等人（[2017](https://arxiv.org/html/2406.01171v2#bib.bib84)）用于优化嵌入和在给定上下文和 persona 信息的情况下识别最相关的回应。Song 等人（[2020](https://arxiv.org/html/2406.01171v2#bib.bib107)）将自然语言推理（NLI）作为一个 RL 任务，并以回应 persona 作为奖励来生成一致的对话。Liu 等人（[2020](https://arxiv.org/html/2406.01171v2#bib.bib82)）提出了 $\mathcal{P}^{2}$，一种互相 persona 感知模型，并在训练过程中采用监督训练和自我对战微调。Tang 等人（[2023b](https://arxiv.org/html/2406.01171v2#bib.bib117)）结合了稀疏 persona 描述、密集 persona 描述和对话历史来生成个性化回应。

## 4 LLM 个性评估

在前面的部分，我们总结了 LLM 角色扮演和 LLM 个性化的当前进展。同样重要的是评估 LLM 的个性是否在适应后准确反映了预期的 persona（即对于基于指定 persona 行动的角色扮演 LLM 和针对个性化 persona 定制的个性化 LLM）。

一些研究利用人类个性评估进行评估，包括 BigFive Jiang 等人（[2023](https://arxiv.org/html/2406.01171v2#bib.bib61)）；Sorokovikova 等人（[2024](https://arxiv.org/html/2406.01171v2#bib.bib109)）和 MBTI Pan 和 Zeng（[2023](https://arxiv.org/html/2406.01171v2#bib.bib91)）；Song 等人（[2024](https://arxiv.org/html/2406.01171v2#bib.bib108)）。例如，Sorokovikova 等人（[2024](https://arxiv.org/html/2406.01171v2#bib.bib109)）；Jiang 等人（[2024](https://arxiv.org/html/2406.01171v2#bib.bib60)）基于 BigFive Personality Inventory（BFI）测试和故事写作测试对 LLM 个性进行了定量评估。在 BFI 评估中，LLM 通常能够准确反映其预期的 persona。此外，他们的 personas 通常会影响他们的语言风格和个性一致性 Frisch 和 Giulianelli（[2024](https://arxiv.org/html/2406.01171v2#bib.bib36)）；Jiang 等人（[2023](https://arxiv.org/html/2406.01171v2#bib.bib61)）。尽管大多数工作仅关注语义准确性或个性一致性，Harrison 等人（[2019](https://arxiv.org/html/2406.01171v2#bib.bib48)）进一步探讨了同时控制这两个方面的方法。

Jiang 等人 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib60)) 引入了机器个性清单（MPI）来评估 LLMs 的个性特征。他们使用 BigFive 个性因素来评估每个个性特征，包括一系列描述和一组选项，并统计地测量每个特征。通过与人类评估比较，他们发现内部一致性与模型能力相关。另一方面，Pan 和 Zeng ([2023](https://arxiv.org/html/2406.01171v2#bib.bib91)) 使用 MBTI 测试评估 LLMs，判断 LLMs 是否具有人类类似的个性，并得出不同 LLMs 具有不同 MBTI 类型的结论，这通常归因于其训练语料库。此外，他们发现仅仅修改提示不太可能改变 LLMs 的 MBTI 类型。

王等人 ([2024c](https://arxiv.org/html/2406.01171v2#bib.bib124)) 的另一项工作评估了角色扮演 LLMs 的个性忠诚度，采用了个性测试访谈，并要求 LLM 根据访谈评分每个个性维度。他们的结果表明，LLMs 展示的个性与分配的角色形象相符。然而，上述人类心理测量测试是否可以直接应用于 LLMs 仍然是一个未解之谜（Dorner 等，[2023](https://arxiv.org/html/2406.01171v2#bib.bib33)）。

## 5 限制与未来方向

### 5.1 迈向通用框架

尽管各种角色扮演框架有效，但它们大多依赖于任务，并严重依赖人工制定的角色。这两者都需要对任务的先验知识和深入理解（Chen 等，[2023c](https://arxiv.org/html/2406.01171v2#bib.bib19)）。因此，增强框架的通用性和采用自动化提示工程是有前途的方向（Li 等，[2024a](https://arxiv.org/html/2406.01171v2#bib.bib69)；Wang 等，[2023c](https://arxiv.org/html/2406.01171v2#bib.bib127)）。

为此，Li 等人 ([2024a](https://arxiv.org/html/2406.01171v2#bib.bib69)) 提出了一个新颖的任务无关框架，允许代理自主协作，但仅限于两个角色，并且仍然需要人工分配的角色。随后，Wang 等人 ([2023c](https://arxiv.org/html/2406.01171v2#bib.bib127)) 引入了 LLMs 根据给定问题自动识别角色的方法。Chen 等人 ([2023c](https://arxiv.org/html/2406.01171v2#bib.bib19)) 的另一项工作也使 LLMs 能够动态调整角色。然而，它们需要对预期任务的先验知识和预定义配置（例如，代理数量）。

### 5.2 长上下文角色

Richardson 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib99)) 指出，将用户历史数据纳入个性化 LLMs 的提示中可能会导致输入超出上下文长度以及增加推理成本。利用基于检索的方法可能会有潜在的信息丢失问题。一些研究提出了总结用户档案、设计专注于用户画像的长期记忆机制、预存用户信息或有效表示以增强检索的方式 (Richardson 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib99)); Zhong 等人 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib152)); Zhang 等人 ([2024b](https://arxiv.org/html/2406.01171v2#bib.bib146)); Sun 等人 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib113)))。然而，由于无关或嘈杂的提示，检索增强可能表现不佳 (Tan 等人 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib115)))。如何更好地存储、编码和整合长期上下文的角色在 LLMs 中需要进一步研究。

### 5.3 数据集和基准缺乏

对于 LLM 角色扮演，几个任务缺乏适合特定格式的数据集 (Ahn 等人 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib5))) 和环境信息（例如，游戏环境需要有关配置和工具的信息）。对于个性化对话生成，用户角色建模缺乏矛盾的角色数据集和多模态角色数据集，这些数据集可以更准确地代表真实的人类行为 (Kim 等人，[2024b](https://arxiv.org/html/2406.01171v2#bib.bib66); Ahn 等人，[2023](https://arxiv.org/html/2406.01171v2#bib.bib6))。此外，由于隐私问题，LLM 个性化面临高质量个人数据的稀缺，阻碍了对不同个性化方法的全面评估。此外，现有的 LLM 角色扮演和个性化基准相对有限，缺乏跨多个维度的全面评估 (Chang 等人，[2023](https://arxiv.org/html/2406.01171v2#bib.bib14))。因此，扩大专门环境和隐私保护下的个人信息的数据集和基准是未来的重要方向。

### 5.4 偏见

虽然大量研究集中在提高最终任务的性能上，但探讨角色扮演和个性化在 LLM 中引发的偏见的工作较少。在这方面，Gupta 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib42)) 作为首批研究之一，突出了 LLM 在分配社会人口统计画像时存在的深层次刻板偏见。对于个性化的 LLM 推荐系统，由于项目的受欢迎程度或项目在提示中的位置，可以观察到偏见 (Hou 等人，[2024](https://arxiv.org/html/2406.01171v2#bib.bib52))。从实证角度来看，Dorner 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib33)) 也揭示了 LLM 中存在的同意偏见——对真实和虚假的内容都有同意的倾向，不管实际事实如何。总之，在 LLM 角色扮演和个性化的背景下，存在广阔的研究和缓解各种偏见的空间。

### 5.5 安全性和隐私

过去的研究已经显示了 LLM 角色扮演和个性化中的安全问题。Jin 等人 ([2024a](https://arxiv.org/html/2406.01171v2#bib.bib62)) 和 Shah 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib102)) 成功地操控 LLM 进行协作式越狱。Deshpande 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib30)) 也显示，将角色分配给 LLM 有助于越狱。Chen 等人 ([2023c](https://arxiv.org/html/2406.01171v2#bib.bib19)) 和 Li 等人 ([2024a](https://arxiv.org/html/2406.01171v2#bib.bib69)) 也展示了 LLM 角色扮演中的负面行为。此外，Deshpande 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib30)) 发现，当分配角色时，LLM 在一系列话题中始终表现出毒性。这些研究揭示了不安全的问题，表明了防止潜在漏洞的紧迫性和更多的努力。

由于大语言模型（LLM）个性化高度依赖于用户画像，包括个人信息和历史行为，因此确保隐私尤为重要。最近，Wang 等人 ([2024a](https://arxiv.org/html/2406.01171v2#bib.bib121)) 发现使用会员推断攻击可以泄露个人信息，提出了将个人数据编码到模型中的担忧。尽管现有研究提供了解决个人信息泄露的方法 (Lukas 等人，[2023](https://arxiv.org/html/2406.01171v2#bib.bib85); Gambarelli 等人，[2023](https://arxiv.org/html/2406.01171v2#bib.bib38); Huang 等人，[2022](https://arxiv.org/html/2406.01171v2#bib.bib55); Chen 等人，[2023d](https://arxiv.org/html/2406.01171v2#bib.bib20))，但这些风险仍需研究界付出更多努力和关注。

### 5.6 更广泛的影响

随着大规模语言模型（LLM）个性化在教育领域的不断进步，个人可以轻松获取个性化的教育内容、讲座材料，并获得负担得起的辅导，这对资源有限的少数群体尤其有利。然而，可能会出现极化趋势的担忧，其中特权群体享有私人导师，而代表性不足的个体只能获得 LLM 驱动的支持 Li et al. ([2023c](https://arxiv.org/html/2406.01171v2#bib.bib73))。此外，个性化 LLM 在医疗保健领域可能会被广泛整合到临床场景、心理健康评估或处方治疗中，关键问题如这些个性化系统的法律责任需要仔细考虑 Swift and Allen ([2010](https://arxiv.org/html/2406.01171v2#bib.bib114))。

如[第四部分](https://arxiv.org/html/2406.01171v2#S4 "4 LLM Personality Evaluation ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization")所讨论，虽然已有 LLM 个性评估的方法被提出，但仍缺乏统一的理解来量化 LLM 中的个性 Fang et al. ([2023](https://arxiv.org/html/2406.01171v2#bib.bib35))。Song et al. ([2024](https://arxiv.org/html/2406.01171v2#bib.bib108)); Jiang et al. ([2024](https://arxiv.org/html/2406.01171v2#bib.bib60)) 也表明 LLM 有时表现出不一致的个性。持续探索新的测量方法对于可靠评估 LLM 的个性和心理特征至关重要，因为未来它们可能会在社会中扮演更高级的角色和能力。

## 6 结论

利用个性角色，LLM 可以生成量身定制的回应，并有效适应各种场景。在这篇调查论文中，我们总结了角色扮演和个性化两条研究路线，探讨了 LLM 时代的个性角色研究。我们还介绍了各种 LLM 个性评估方法。最后，我们强调了当前面临的挑战和有前景的未来方向。我们希望我们的广泛调查和资源能作为入门指南，帮助初学者入门，并为未来的努力提供实用的路线图。

## 致谢

我们感谢来自国立台湾大学的许育青和傅佳颖对我们的帮助和讨论。这项工作得到了台湾国家科学技术委员会（NSTC）的财政支持，资助编号为 112-2223-E-002-012-MY5 和 111-2222-E-002-013-MY3，同时也得到了教育部高等教育萌芽计划下的特色领域研究中心项目的支持（113L900901/113L900902/113L900903）。

## 参考文献

+   Abbasian et al. (2024a) Mahyar Abbasian, Iman Azimi, Amir M. Rahmani, and Ramesh Jain. 2024a. [对话健康代理：一个个性化 LLM 驱动的代理框架](http://arxiv.org/abs/2310.02374)。

+   Abbasian 等人（2024b）Mahyar Abbasian、Elahe Khatibi、Iman Azimi、David Oniani、Zahra Shakeri Hossein Abad、Alexander Thieme、Ram Sriram、Zhongqi Yang、Yanshan Wang、Bryant Lin、Olivier Gevaert、Li-Jia Li、Ramesh Jain 和 Amir M. Rahmani。2024b。[用于评估生成式 AI 驱动的医疗对话有效性的基础指标](http://arxiv.org/abs/2309.12444)。

+   Abbasian 等人（2024c）Mahyar Abbasian、Zhongqi Yang、Elahe Khatibi、Pengfei Zhang、Nitish Nagesh、Iman Azimi、Ramesh Jain 和 Amir M. Rahmani。2024c。[知识注入的 LLM 驱动对话健康代理：糖尿病患者的案例研究](http://arxiv.org/abs/2402.10153)。

+   Achiam 等人（2023）Josh Achiam、Steven Adler、Sandhini Agarwal、Lama Ahmad、Ilge Akkaya、Florencia Leoni Aleman、Diogo Almeida、Janko Altenschmidt、Sam Altman、Shyamal Anadkat 等人。2023。Gpt-4 技术报告。*arXiv 预印本 arXiv:2303.08774*。

+   Ahn 等人（2024）Jaewoo Ahn、Taehyun Lee、Junyoung Lim、Jin-Hwa Kim、Sangdoo Yun、Hwaran Lee 和 Gunhee Kim。2024。Timechara: 评估角色扮演大型语言模型的时间点角色幻觉。*arXiv 预印本 arXiv:2405.18027*。

+   Ahn 等人（2023）Jaewoo Ahn、Yeda Song、Sangdoo Yun 和 Gunhee Kim。2023。Mpchat: 朝着多模态个性化对话迈进。*arXiv 预印本 arXiv:2305.17388*。

+   Arefeen 等人（2023）Md Adnan Arefeen、Biplob Debnath 和 Srimat Chakradhar。2023。[Leancontext: 使用 LLMs 的成本效益领域特定问答](http://arxiv.org/abs/2309.00841)。

+   Ashby 等人（2023）Trevor Ashby、Braden K Webb、Gregory Knapp、Jackson Searle 和 Nancy Fulda。2023。角色扮演游戏中的个性化任务和对话生成：基于知识图谱和语言模型的方法。在 *2023 年人机交互会议论文集* 中，第 1–20 页。

+   Baek 等人（2024）Jinheon Baek、Nirupama Chandrasekaran、Silviu Cucerzan、Allen Herring 和 Sujay Kumar Jauhar。2024。[知识增强的大型语言模型用于个性化上下文查询建议](http://arxiv.org/abs/2311.06318)。

+   Bassil（2012）Youssef Bassil。2012。瀑布式软件开发生命周期的仿真模型。*arXiv 预印本 arXiv:1205.6904*。

+   Belbin 和 Brown（2022）R Meredith Belbin 和 Victoria Brown。2022。*工作中的团队角色*。Routledge。

+   Budzianowski 等人（2018）Paweł Budzianowski、Tsung-Hsien Wen、Bo-Hsiang Tseng、Iñigo Casanueva、Stefan Ultes、Osman Ramadan 和 Milica Gašić。2018。[MultiWOZ - 一个大型多领域的任务导向对话建模数据集](https://doi.org/10.18653/v1/D18-1547)。在 *2018 年自然语言处理实证方法会议论文集* 中，第 5016–5026 页，比利时布鲁塞尔。计算语言学协会。

+   Chan 等人（2023） Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, 和 Zhiyuan Liu。2023 年。Chateval：通过多智能体辩论实现更好的基于 LLM 的评估器。*arXiv 预印本 arXiv:2308.07201*。

+   Chang 等人（2023） Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, 和 Xing Xie。2023 年。[关于大型语言模型评估的调查](http://arxiv.org/abs/2307.03109)。

+   陈等人（2022） Changyu Chen, Xiting Wang, Xiaoyuan Yi, Fangzhao Wu, Xing Xie, 和 Rui Yan。2022 年。基于外部聊天语料库的个性化闲聊生成推荐。在*第 28 届 ACM SIGKDD 知识发现与数据挖掘大会论文集*中，页码 2721–2731。

+   陈等人（2024） Jiangjie Chen, Xintao Wang, Rui Xu, Siyu Yuan, Yikai Zhang, Wei Shi, Jian Xie, Shuang Li, Ruihan Yang, Tinghui Zhu 等。2024 年。从角色到个性化：关于角色扮演语言智能体的调查。*arXiv 预印本 arXiv:2404.18231*。

+   陈等人（2023a） Jin Chen, Zheng Liu, Xu Huang, Chenwang Wu, Qi Liu, Gangwei Jiang, Yuanhao Pu, Yuxuan Lei, Xiaolong Chen, Xingmei Wang, Defu Lian, 和 Enhong Chen。2023a。[当大型语言模型遇上个性化：挑战与机遇的视角](http://arxiv.org/abs/2307.16376)。

+   陈等人（2023b） Siyuan Chen, Mengyue Wu, Kenny Q Zhu, Kunyao Lan, Zhiling Zhang, 和 Lyuchun Cui。2023b。利用大型语言模型的聊天机器人进行精神科医生和患者模拟：应用与评估。*arXiv 预印本 arXiv:2305.13614*。

+   陈等人（2023c） Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie 等。2023c。Agentverse：促进多智能体协作并探索智能体中的新兴行为。*arXiv 预印本 arXiv:2308.10848*。

+   陈等人（2023d） Yang Chen, Ethan Mendes, Sauvik Das, Wei Xu, 和 Alan Ritter。2023d。[语言模型能否被指示保护个人信息？](http://arxiv.org/abs/2310.02224)

+   陈等人（2023e） Zheng Chen, Ziyan Jiang, Fan Yang, Zhankui He, Yupeng Hou, Eunah Cho, Julian McAuley, Aram Galstyan, Xiaohua Hu, 和 Jie Yang。2023e。个性化生成 AI@CIKM 2023 的首次研讨会：个性化与大型语言模型的结合。在*第 32 届 ACM 国际信息与知识管理会议论文集*中，页码 5267–5270。

+   程等人（2024） Kanzhi Cheng, Qiushi Sun, Yougang Chu, Fangzhi Xu, Yantao Li, Jianbing Zhang, 和 Zhiyong Wu。2024 年。Seeclick：利用 GUI 基础进行高级视觉 GUI 智能体。*arXiv 预印本 arXiv:2401.10935*。

+   Chiang 和 Lee（2023） Cheng-Han Chiang 和 Hung-yi Lee。2023 年。大型语言模型能否成为对人类评估的替代？*arXiv 预印本 arXiv:2305.01937*。

+   Chu 等人（2023）Zhixuan Chu、Hongyan Hao、Xin Ouyang、Simeng Wang、Yan Wang、Yue Shen、Jinjie Gu、Qing Cui、Longfei Li、Siqiao Xue、James Y Zhang 和 Sheng Li。2023。[利用大型语言模型进行预训练推荐系统](http://arxiv.org/abs/2308.10837)。

+   Cohan 等人（2020）Arman Cohan、Sergey Feldman、Iz Beltagy、Doug Downey 和 Daniel Weld。2020。[SPECTER: 使用引用信息的转换器进行文档级表示学习](https://doi.org/10.18653/v1/2020.acl-main.207)。在 *第 58 届计算语言学协会年会论文集*，第 2270–2282 页，在线。计算语言学协会。

+   Dan 等人（2023）Yuhao Dan、Zhikai Lei、Yiyang Gu、Yong Li、Jianghao Yin、Jiaju Lin、Linhao Ye、Zhiyan Tie、Yougen Zhou、Yilei Wang 等人。2023。Educhat: 一种基于大型语言模型的智能教育聊天系统。*arXiv 预印本 arXiv:2308.02773*。

+   DeMarco 和 Lister（2013）Tom DeMarco 和 Tim Lister。2013。*Peopleware: productive projects and teams*。Addison-Wesley。

+   Deng 等人（2024）Xiang Deng、Yu Gu、Boyuan Zheng、Shijie Chen、Sam Stevens、Boshi Wang、Huan Sun 和 Yu Su。2024。Mind2web: 面向网络的通用代理。*神经信息处理系统进展*，36。

+   Deshpande 等人（2024）Ameet Deshpande、EunJeong Hwang、Vishvak Murahari、Joon Sung Park、Diyi Yang、Ashish Sabharwal、Karthik Narasimhan 和 Ashwin Kalyan，编辑。2024。[*第 1 届生成 AI 系统个性化研讨会论文集（PERSONALIZE 2024）*](https://aclanthology.org/2024.personalize-1.0)。计算语言学协会，马耳他圣朱利安斯。

+   Deshpande 等人（2023）Ameet Deshpande、Vishvak Murahari、Tanmay Rajpurohit、Ashwin Kalyan 和 Karthik Narasimhan。2023。[ChatGPT 中的毒性: 分析角色分配语言模型](http://arxiv.org/abs/2304.05335)。

+   Dinan 等人（2019）Emily Dinan、Varvara Logacheva、Valentin Malykh、Alexander Miller、Kurt Shuster、Jack Urbanek、Douwe Kiela、Arthur Szlam、Iulian Serban、Ryan Lowe、Shrimai Prabhumoye、Alan W Black、Alexander Rudnicky、Jason Williams、Joelle Pineau、Mikhail Burtsev 和 Jason Weston。2019。[第二届对话智能挑战赛（convai2）](http://arxiv.org/abs/1902.00098)。

+   Dong 等人（2023）Yihong Dong、Xue Jiang、Zhi Jin 和 Ge Li。2023。Self-collaboration code generation via chatgpt。*arXiv 预印本 arXiv:2304.07590*。

+   Dorner 等人（2023）Florian E Dorner、Tom Sühr、Samira Samadi 和 Augustin Kelava。2023。个性测试能否推广到大型语言模型？*arXiv 预印本 arXiv:2311.05297*。

+   Eric 等人 (2020) Mihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi, Sanchit Agarwal, Shuyang Gao, Adarsh Kumar, Anuj Goyal, Peter Ku, 和 Dilek Hakkani-Tur. 2020. [MultiWOZ 2.1：一个综合的多领域对话数据集，包含状态修正和状态跟踪基准](https://aclanthology.org/2020.lrec-1.53)。在 *第十二届语言资源与评估会议论文集*，页 422–428，法国马赛。欧洲语言资源协会。

+   Fang 等人 (2023) Qixiang Fang, Anastasia Giachanou, Ayoub Bagheri, Laura Boeschoten, Erik-Jan van Kesteren, Mahdi Shafiee Kamalabad, 和 Daniel Oberski. 2023. [基于文本的个性计算：挑战与未来方向](https://doi.org/10.18653/v1/2023.findings-acl.691)。在 *计算语言学协会年会论文集：ACL 2023*，页 10861–10879，加拿大多伦多。计算语言学协会。

+   Frisch 和 Giulianelli (2024) Ivar Frisch 和 Mario Giulianelli. 2024. [互动中的 LLM 代理：测量大语言模型群体中的个性一致性和语言对齐](https://aclanthology.org/2024.personalize-1.9)。在 *第 1 届生成 AI 系统个性化研讨会 (PERSONALIZE 2024)*，页 102–111，马耳他圣朱利安斯。计算语言学协会。

+   Fu 等人 (2023) Yao Fu, Hao Peng, Tushar Khot, 和 Mirella Lapata. 2023. 改进语言模型谈判的自我博弈和从 AI 反馈中学习。*arXiv 预印本 arXiv:2305.10142*。

+   Gambarelli 等人 (2023) Gaia Gambarelli, Aldo Gangemi, 和 Rocco Tripodi. 2023. [你的模型敏感吗？spedac：自动分类敏感个人数据的新资源](https://doi.org/10.1109/access.2023.3240089)。*IEEE Access*，11:10864–10880。

+   Geng 等人 (2022) Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, 和 Yongfeng Zhang. 2022. 作为语言处理的推荐（RLP）：统一的预训练、个性化提示与预测范式（P5）。在 *第 16 届 ACM 推荐系统会议论文集*，页 299–315。

+   Gonzalez 等人 (2023) Hannah Gonzalez, Jiening Li, Helen Jin, Jiaxuan Ren, Hongyu Zhang, Ayotomiwa Akinyele, Adrian Wang, Eleni Miltsakaki, Ryan Baker, 和 Chris Callison-Burch. 2023. [自动生成的讲座总结可能增强学生的学习体验](https://doi.org/10.18653/v1/2023.bea-1.31)。在 *第 18 届创新使用 NLP 构建教育应用研讨会 (BEA 2023)*，页 382–393，加拿大多伦多。计算语言学协会。

+   Guo 等人 (2024) Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V Chawla, Olaf Wiest, 和 Xiangliang Zhang. 2024. 基于大语言模型的多代理：进展与挑战综述。*arXiv 预印本 arXiv:2402.01680*。

+   Gupta et al. (2023) Shashank Gupta, Vaishnavi Shrivastava, Ameet Deshpande, Ashwin Kalyan, Peter Clark, Ashish Sabharwal, 和 Tushar Khot. 2023. Bias runs deep: Persona 分配的 llms 中的隐式推理偏差。*arXiv 预印本 arXiv:2311.04892*。

+   Gur et al. (2023) Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari, Yutaka Matsuo, Douglas Eck, 和 Aleksandra Faust. 2023. 一个具备规划、长上下文理解和程序合成的真实世界 Web 代理。*arXiv 预印本 arXiv:2307.12856*。

+   Gur et al. (2022) Izzeddin Gur, Ofir Nachum, Yingjie Miao, Mustafa Safdari, Austin Huang, Aakanksha Chowdhery, Sharan Narang, Noah Fiedel, 和 Aleksandra Faust. 2022. 使用大型语言模型理解 HTML。*arXiv 预印本 arXiv:2210.03945*。

+   Han et al. (2024) Ji-Eun Han, Jun-Seok Koh, Hyeon-Tae Seo, Du-Seong Chang, 和 Kyung-Ah Sohn. 2024. [Psydial: 基于个性的合成对话生成，使用大型语言模型](http://arxiv.org/abs/2404.00930)。

+   Hao et al. (2024) Shibo Hao, Yi Gu, Haotian Luo, Tianyang Liu, Xiyan Shao, Xinyuan Wang, Shuhua Xie, Haodi Ma, Adithya Samavedhi, Qiyue Gao, Zhen Wang, 和 Zhiting Hu. 2024. [Llm reasoners: 新的评估、库和大型语言模型逐步推理的分析](http://arxiv.org/abs/2404.05221)。

+   Harper and Konstan (2015) F Maxwell Harper 和 Joseph A Konstan. 2015. Movielens 数据集：历史与背景。*ACM 交互式智能系统（TIIS）*，5(4):1–19。

+   Harrison et al. (2019) Vrindavan Harrison, Lena Reed, Shereen Oraby, 和 Marilyn Walker. 2019. [最大化 NLG 中的风格控制和语义准确性：个性变化和话语对比](https://doi.org/10.18653/v1/W19-8101)。在 *第 1 届神经 NLG 话语结构研讨会论文集*，第 1–12 页，东京，日本。计算语言学协会。

+   He et al. (2022) Wanwei He, Yinpei Dai, Yinhe Zheng, Yuchuan Wu, Zheng Cao, Dermot Liu, Peng Jiang, Min Yang, Fei Huang, Luo Si, Jian Sun, 和 Yongbin Li. 2022. [Galaxy: 一个用于任务导向对话的生成预训练模型，结合半监督学习和显式策略注入](http://arxiv.org/abs/2111.14592)。

+   Hong et al. (2023a) Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, 等. 2023a. Metagpt: 面向多代理协作框架的元编程。*arXiv 预印本 arXiv:2308.00352*。

+   Hong et al. (2023b) Wenyi Hong, Weihan Wang, Qingsong Lv, Jiazheng Xu, Wenmeng Yu, Junhui Ji, Yan Wang, Zihan Wang, Yuxiao Dong, Ming Ding, 等. 2023b. Cogagent: 一个用于 GUI 代理的视觉语言模型。*arXiv 预印本 arXiv:2312.08914*。

+   Hou et al. (2024) Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley, 和 Wayne Xin Zhao. 2024. [大型语言模型是推荐系统的零样本排序器](http://arxiv.org/abs/2305.08845)。

+   Hu 等（2024）俊·胡、文文·夏、晓璐·张、池林·傅、伟昌·吴、兆鑫·黄、昂·李、左力·唐和俊·周。2024 年。《通过基于大语言模型的语义嵌入学习增强序列推荐》。在 *2024 年 ACM 网络会议附录论文集*，页 103–111。

+   Hu 等（2023）志远·胡、悦·冯、杨·邓、泽坤·李、施琼·吴、安·阮·吕和布赖恩·霍伊。2023 年。[通过前瞻性目标增强大语言模型引导的任务导向对话系统](http://arxiv.org/abs/2309.08949)。

+   Huang 等（2022）杰·黄、汉银·邵和凯文·陈传·张。2022 年。[大型预训练语言模型是否泄露你的个人信息？](https://doi.org/10.18653/v1/2022.findings-emnlp.148) 在 *计算语言学协会发现：EMNLP 2022*，页 2038–2047，阿布扎比，阿拉伯联合酋长国。计算语言学协会。

+   Huber 等（2024）斯特凡·E·胡贝尔、克里斯蒂安·基利、史蒂夫·内贝尔、理查德·M·瑞安、迈克尔·赛勒和曼努埃尔·尼瑙斯。2024 年。《通过有趣和基于游戏的学习发挥大语言模型在教育中的潜力》。*教育心理学评论*，36(1):1–20。

+   Hudeček 和 Dusek（2023）沃伊捷赫·胡德切克和翁德雷·杜塞克。2023 年。[任务导向对话是否只需大语言模型？](https://doi.org/10.18653/v1/2023.sigdial-1.21) 在 *第 24 届年度特别兴趣小组讨论会论文集*，页 216–228，布拉格，捷克。计算语言学协会。

+   Huryn 等（2022）丹尼尔·胡林、威廉·M·赫特塞尔和晋浩·崔。2022 年。[自动生成大规模多轮对话](https://aclanthology.org/2022.coling-1.297)。在 *第 29 届国际计算语言学大会论文集*，页 3360–3373，庆州，韩国。国际计算语言学委员会。

+   Jeon 和 Lee（2023）宰浩·全和成容·李。2023 年。《教育中的大语言模型：专注于人类教师与 ChatGPT 之间的互补关系》。*教育与信息技术*，28(12):15873–15892。

+   Jiang 等（2024）广元·姜、曼杰·徐、宋春·朱、文娟·韩、池·张和毅欣·朱。2024 年。《评估和引导预训练语言模型中的个性》。*神经信息处理系统进展*，36。

+   Jiang 等（2023）杭·姜、夏杰·张、旭波·曹和贾德·卡巴拉。2023 年。《Personallm：探究大语言模型表达大五人格特质的能力》。*arXiv 预印本 arXiv:2305.02547*。

+   Jin 等（2024a）海博·金、若曦·陈、安迪·周、金银·陈、杨·张和浩瀚·王。2024a 年。《Guard：角色扮演生成自然语言破解以测试大语言模型的指导方针遵守情况》。*arXiv 预印本 arXiv:2402.03299*。

+   Jin 等 (2024b) Mingyu Jin, Qinkai Yu, Dong Shu, Chong Zhang, Lizhou Fan, Wenyue Hua, Suiyuan Zhu, Yanda Meng, Zhenting Wang, Mengnan Du, 和 Yongfeng Zhang. 2024b. [Health-llm：个性化检索增强的疾病预测系统](http://arxiv.org/abs/2402.00746)。

+   Kasneci 等 (2023) Enkelejda Kasneci, Kathrin Seßler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnemann, Eyke Hüllermeier 等. 2023. Chatgpt 的积极意义？关于大型语言模型在教育中机遇与挑战。*学习与个体差异*，103:102274。

+   Kim 等 (2024a) Geunwoo Kim, Pierre Baldi, 和 Stephen McAleer. 2024a. 语言模型可以解决计算机任务。*神经信息处理系统进展*，36。

+   Kim 等 (2024b) Hana Kim, Kai Tzu-iunn Ong, Seoyeon Kim, Dongha Lee, 和 Jinyoung Yeo. 2024b. 通过上下文感知角色细化的常识增强记忆构建与管理。*arXiv 预印本 arXiv:2401.14215*。

+   Koh 等 (2024) Jing Yu Koh, Robert Lo, Lawrence Jang, Vikram Duvvur, Ming Chong Lim, Po-Yu Huang, Graham Neubig, Shuyan Zhou, Ruslan Salakhutdinov, 和 Daniel Fried. 2024. Visualwebarena：评估多模态代理在现实视觉网络任务中的表现。*arXiv 预印本 arXiv:2401.13649*。

+   Kwon 等 (2024) Taeyoon Kwon, Kai Tzu-iunn Ong, Dongjin Kang, Seungjun Moon, Jeong Ryong Lee, Dosik Hwang, Beomseok Sohn, Yongsik Sim, Dongha Lee, 和 Jinyoung Yeo. 2024. 大型语言模型是临床推理者：具有提示生成理由的推理感知诊断框架。收录于 *AAAI 人工智能会议论文集*，第 38 卷，第 18417–18425 页。

+   Li 等 (2024a) Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, 和 Bernard Ghanem. 2024a. Camel：用于大型语言模型社会“心智”探索的交流代理。*神经信息处理系统进展*，36。

+   Li 等 (2021) Lei Li, Yongfeng Zhang, 和 Li Chen. 2021. 个性化变换器用于可解释推荐。*arXiv 预印本 arXiv:2105.11601*。

+   Li 等 (2023a) Lei Li, Yongfeng Zhang, 和 Li Chen. 2023a. 个性化提示学习用于可解释推荐。*ACM 信息系统学报*，41(4):1–26。

+   Li 等 (2023b) Pan Li, Yuyan Wang, Ed H. Chi, 和 Minmin Chen. 2023b. [个性化方面提取的提示调整大型语言模型用于推荐](http://arxiv.org/abs/2306.01475)。

+   Li 等 (2023c) Qingyao Li, Lingyue Fu, Weiming Zhang, Xianyu Chen, Jingwei Yu, Wei Xia, Weinan Zhang, Ruiming Tang, 和 Yong Yu. 2023c. 大型语言模型在教育中的适应：基础能力、潜力与挑战。*arXiv 预印本 arXiv:2401.08664*。

+   Li et al. (2017) Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. 2017. [DailyDialog: 手动标注的多轮对话数据集](https://aclanthology.org/I17-1099)。在 *第八届国际自然语言处理联合会议（第一卷：长篇论文）* 中，页面 986–995，台北，台湾。亚洲自然语言处理联合会。

+   Li et al. (2024b) Yongqi Li, Xinyu Lin, Wenjie Wang, Fuli Feng, Liang Pang, Wenjie Li, Liqiang Nie, Xiangnan He, and Tat-Seng Chua. 2024b. [大型语言模型时代的生成搜索和推荐调查](http://arxiv.org/abs/2404.16924)。

+   Li et al. (2024c) Zekun Li, Baolin Peng, Pengcheng He, Michel Galley, Jianfeng Gao, and Xifeng Yan. 2024c. 通过方向性刺激引导大型语言模型。*神经信息处理系统进展*, 36。

+   Liévin et al. (2024) Valentin Liévin, Christoffer Egeberg Hother, Andreas Geert Motzfeldt, and Ole Winther. 2024. 大型语言模型能否推理医学问题？*Patterns*, 5(3)。

+   Lin and Chen (2023) Yen-Ting Lin and Yun-Nung Chen. 2023. [LLM-eval: 面向开放域对话的大型语言模型的统一多维自动评估](https://doi.org/10.18653/v1/2023.nlp4convai-1.5)。在 *第 5 届对话人工智能 NLP 研讨会（NLP4ConvAI 2023）* 中，页面 47–58，多伦多，加拿大。计算语言学协会。

+   Liu (2022) Jerry Liu. 2022. [LlamaIndex](https://doi.org/10.5281/zenodo.1234)。

+   Liu et al. (2023) Junling Liu, Chao Liu, Peilin Zhou, Renjie Lv, Kang Zhou, and Yan Zhang. 2023. [ChatGPT 是否是一个好的推荐系统？初步研究](http://arxiv.org/abs/2304.10149)。

+   Liu et al. (2024) Junpeng Liu, Yifan Song, Bill Yuchen Lin, Wai Lam, Graham Neubig, Yuanzhi Li, and Xiang Yue. 2024. Visualwebbench: 多模态 LLMs 在网页理解和定位上进展如何？*arXiv 预印本 arXiv:2404.05955*。

+   Liu et al. (2020) Qian Liu, Yihong Chen, Bei Chen, Jian-Guang Lou, Zixuan Chen, Bin Zhou, and Dongmei Zhang. 2020. [你让我印象深刻：通过互相的人物感知生成对话](https://doi.org/10.18653/v1/2020.acl-main.131)。在 *第 58 届计算语言学协会年会* 中，页面 1417–1427，在线。计算语言学协会。

+   Lotfi et al. (2024) Ehsan Lotfi, Maxime De Bruyn, Jeska Buhmann, and Walter Daelemans. 2024. [Personalitychat: 基于事实和特征的个性化对话建模对话蒸馏](http://arxiv.org/abs/2401.07363)。

+   Lu et al. (2017) Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. 2017. [层次化问题-图像共注意力用于视觉问答](http://arxiv.org/abs/1606.00061)。

+   Lukas 等人 (2023) Nils Lukas、Ahmed Salem、Robert Sim、Shruti Tople、Lukas Wutschitz 和 Santiago Zanella-Béguelin。2023. [分析语言模型中个人身份信息的泄露](http://arxiv.org/abs/2302.00539)。

+   Madaan 等人 (2024) Aman Madaan、Niket Tandon、Prakhar Gupta、Skyler Hallinan、Luyu Gao、Sarah Wiegreffe、Uri Alon、Nouha Dziri、Shrimai Prabhumoye、Yiming Yang 等。2024. 自我精炼：自我反馈的迭代精炼。 *神经信息处理系统进展*，第 36 卷。

+   Milne-Ives 等人 (2020) Madison Milne-Ives、Caroline de Cock、Ernest Lim、Melissa Harper Shehadeh、Nick de Pennington、Guy Mole、Eduardo Normando 和 Edward Meinert。2020. 人工智能对话代理在医疗保健中的有效性：系统评估。 *医学互联网研究杂志*，22(10)：e20346。

+   Mosig 等人 (2020) Johannes E. M. Mosig、Shikib Mehri 和 Thomas Kober。2020. [Star：用于迁移学习的基于模式的对话数据集](http://arxiv.org/abs/2010.11853)。

+   Ni 等人 (2019) Jianmo Ni、Jiacheng Li 和 Julian McAuley。2019. 使用远程标记评论和细粒度方面来证明推荐。 在 *2019 年自然语言处理实证方法会议和第 9 届国际联合自然语言处理会议 (EMNLP-IJCNLP) 论文集*，第 188–197 页。

+   OpenAI (2022) OpenAI。2022. 介绍 ChatGPT。 [`openai.com/index/chatgpt/`](https://openai.com/index/chatgpt/)。

+   Pan 和 Zeng (2023) 潘柯宇和曾雅文。2023. [大型语言模型是否具备个性？将 MBTI 测试作为大型语言模型的惊人评估](http://arxiv.org/abs/2307.16180)。

+   PapersWithCode (2020) PapersWithCode。2020. 百度 Personachat 数据集。 [`paperswithcode.com/dataset/baidu-personachat`](https://paperswithcode.com/dataset/baidu-personachat)。

+   Park 等人 (2023) Joon Sung Park、Joseph O’Brien、Carrie Jun Cai、Meredith Ringel Morris、Percy Liang 和 Michael S Bernstein。2023. 生成代理：人类行为的互动模拟。 在 *第 36 届年度 ACM 用户界面软件与技术研讨会论文集*，第 1–22 页。

+   Park 等人 (2024) Minju Park、Sojung Kim、Seunghyun Lee、Soonwoo Kwon 和 Kyuseok Kim。2024. 通过具有学生建模的基于对话的辅导系统赋能个性化学习。 *arXiv 预印本 arXiv:2403.14071*。

+   Petersen 等人 (2009) Kai Petersen、Claes Wohlin 和 Dejan Baca. 2009. 大规模开发中的瀑布模型。在 *以产品为中心的软件过程改进：第十届国际会议，PROFES 2009，芬兰欧卢，2009 年 6 月 15-17 日. 论文集 10*，第 386–400 页。Springer。

+   Qian 等人 (2023) 陈倩、辛聪、程阳、魏泽辰、余生苏、巨元徐、志远刘和毛松孙。2023. 用于软件开发的交流代理。*arXiv 预印本 arXiv:2307.07924*。

+   Ramadan 等（2018）**Osman Ramadan**、**Paweł Budzianowski**和**Milica Gašić**。2018 年。[大规模多领域信念跟踪与知识共享](https://doi.org/10.18653/v1/P18-2069)。载于*第 56 届计算语言学协会年会论文集（第 2 卷：短论文）*，第 432–437 页，澳大利亚墨尔本。计算语言学协会。

+   Rastogi 等（2020）**Abhinav Rastogi**、**Xiaoxue Zang**、**Srinivas Sunkara**、**Raghav Gupta**和**Pranav Khaitan**。2020 年。迈向可扩展的多领域对话代理：方案引导的对话数据集。载于*AAAI 人工智能会议论文集*，第 34 卷，第 8689–8696 页。

+   Richardson 等（2023）**Chris Richardson**、**Yao Zhang**、**Kellen Gillespie**、**Sudipta Kar**、**Arshdeep Singh**、**Zeynab Raeesy**、**Omar Zia Khan**和**Abhinav Sethy**。2023 年。[通过大型语言模型集成总结和检索以增强个性化](http://arxiv.org/abs/2310.20081)。

+   Saab 等（2024）**Khaled Saab**、**Tao Tu**、**Wei-Hung Weng**、**Ryutaro Tanno**、**David Stutz**、**Ellery Wulczyn**、**Fan Zhang**、**Tim Strother**、**Chunjong Park**、**Elahe Vedadi**等。2024 年。双子模型在医学中的能力。*arXiv 预印本 arXiv:2404.18416*。

+   Salemi 和 Zamani（2024）**Alireza Salemi**和**Hamed Zamani**。2024 年。迈向机器搜索引擎：统一排名多种检索增强型大型语言模型。*arXiv 预印本 arXiv:2405.00175*。

+   Shah 等（2023）**Rusheb Shah**、**Quentin Feuillade-Montixi**、**Soroush Pour**、**Arush Tagade**、**Stephen Casper**和**Javier Rando**。2023 年。[通过人格调节的可扩展和可转移的黑箱破解语言模型](http://arxiv.org/abs/2311.03348)。

+   Sharma 等（2024）**Nikhil Sharma**、**Q Vera Liao**和**Ziang Xiao**。2024 年。生成回音室？LLM 驱动的搜索系统对多样信息获取的影响。*arXiv 预印本 arXiv:2402.05880*。

+   Shehata 等（2023）**Shady Shehata**、**David Santandreu Calonge**、**Philip Purnell**和**Mark Thompson**。2023 年。[通过知识追踪增强基于视频的学习：使用 ORBITS 个性化学生学习体验](https://doi.org/10.18653/v1/2023.bea-1.8)。载于*第 18 届自然语言处理在教育应用中的创新使用研讨会（BEA 2023）*，第 100–107 页，加拿大多伦多。计算语言学协会。

+   Shinn 等（2024）**Noah Shinn**、**Federico Cassano**、**Ashwin Gopinath**、**Karthik Narasimhan**和**Shunyu Yao**。2024 年。Reflexion：具有语言强化学习的语言代理。*神经信息处理系统进展*，第 36 卷。

+   Singhal 等（2023）**Karan Singhal**、**Shekoofeh Azizi**、**Tao Tu**、**S Sara Mahdavi**、**Jason Wei**、**Hyung Won Chung**、**Nathan Scales**、**Ajay Tanwani**、**Heather Cole-Lewis**、**Stephen Pfohl**等。2023 年。大型语言模型编码临床知识。*自然*，620(7972)：172–180。

+   Song 等人（2020）Haoyu Song, Wei-Nan Zhang, Jingwen Hu, 和 Ting Liu. 2020. [通过利用自然语言推理生成一致的人格对话](https://doi.org/10.1609/aaai.v34i05.6417)。*AAAI 人工智能会议录*, 34(05):8878–8885。

+   Song 等人（2024）Xiaoyang Song, Yuta Adachi, Jessie Feng, Mouwei Lin, Linhao Yu, Frank Li, Akshat Gupta, Gopala Anumanchipalli, 和 Simerjot Kaur. 2024. [通过外部评估识别大型语言模型中的多重人格](http://arxiv.org/abs/2402.14805)。

+   Sorokovikova 等人（2024）Aleksandra Sorokovikova, Sharwin Rezagholi, Natalia Fedorova, 和 Ivan Yamshchikov. 2024. [大型语言模型模拟 Big5 人格特质：进一步证据](https://aclanthology.org/2024.personalize-1.7)。在*第 1 届生成 AI 系统个性化研讨会（PERSONALIZE 2024）*的*会议录*中，页码 83–87，St. Julians, Malta。计算语言学协会。

+   Spatharioti 等人（2023）Sofia Eleni Spatharioti, David M. Rothschild, Daniel G. Goldstein, 和 Jake M. Hofman. 2023. [传统与基于 LLM 的搜索在消费者选择中的比较：一项随机实验](http://arxiv.org/abs/2307.03744)。

+   Stade 等人（2024）Elizabeth C Stade, Shannon Wiltsey Stirman, Lyle H Ungar, Cody L Boland, H Andrew Schwartz, David B Yaden, João Sedoc, Robert J DeRubeis, Robb Willer, 和 Johannes C Eichstaedt. 2024. 大型语言模型可能改变行为健康护理的未来：负责任的发展和评估提案。*npj Mental Health Research*, 3(1):12。

+   Sugiyama 等人（2021）Hiroaki Sugiyama, Masahiro Mizukami, Tsunehiro Arimoto, Hiromi Narimatsu, Yuya Chiba, Hideharu Nakajima, 和 Toyomi Meguro. 2021. [基于变压器的日语闲聊系统训练策略的实证分析](http://arxiv.org/abs/2109.05217)。

+   Sun 等人（2024）Chenkai Sun, Ke Yang, Revanth Gangi Reddy, Yi R. Fung, Hou Pong Chan, ChengXiang Zhai, 和 Heng Ji. 2024. [Persona-db: 利用协作数据优化的高效大型语言模型个性化](http://arxiv.org/abs/2402.11060)。

+   Swift 和 Allen（2010）M Swift 和 J Allen. 2010. 朝向个人健康管理助手。*生物医学信息学期刊*, 43(5):S13–S16。

+   Tan 等人（2024）Zhaoxuan Tan, Qingkai Zeng, Yijun Tian, Zheyuan Liu, Bing Yin, 和 Meng Jiang. 2024. [通过个性化参数高效微调民主化大型语言模型](http://arxiv.org/abs/2402.04401)。

+   Tang 等人（2023a）Xiangru Tang, Anni Zou, Zhuosheng Zhang, Yilun Zhao, Xingyao Zhang, Arman Cohan, 和 Mark Gerstein. 2023a. Medagents: 大型语言模型作为零-shot 医学推理的协作者。*arXiv 预印本 arXiv:2311.10537*。

+   Tang 等（2023b）益宏 Tang, 博 Wang, 苗 Fang, 东明 Zhao, 昆 Huang, 瑞芳 He, 和 月贤 Hou。2023b。 [通过对比潜在变量增强个性化对话生成：结合稀疏和密集角色](https://doi.org/10.18653/v1/2023.acl-long.299)。在*第 61 届计算语言学协会年会论文集（第 1 卷：长篇论文）*，第 5456–5468 页，多伦多，加拿大。计算语言学协会。

+   Team 等（2023）双子座团队, 罗汉 Anil, 塞巴斯蒂安 Borgeaud, 永辉 Wu, 让-巴普蒂斯特 Alayrac, 佳慧 Yu, 拉杜 Soricut, 约翰 Schalkwyk, 安德鲁 M Dai, 安雅 Hauth, 等。2023。双子座：一系列高能力的多模态模型。*arXiv 预印本 arXiv:2312.11805*。

+   Tu 等（2023）全 Tu, 川齐 Chen, 晋鹏 Li, 雁然 Li, 朔 Shang, 东燕 Zhao, 然 Wang, 和 瑞 Yan。2023。Characterchat：朝着具有人际支持的对话 AI 学习。*arXiv 预印本 arXiv:2308.10278*。

+   Wang 等（2023a）冠志 Wang, 玉琪 Xie, 云凡 Jiang, 阿杰 Mandlekar, 朝伟 Xiao, 雨珂 Zhu, 林曦 Fan, 和 安尼玛 Anandkumar。2023a。Voyager：一个基于大型语言模型的开放式具身代理。*arXiv 预印本 arXiv:2305.16291*。

+   Wang 等（2024a）Jeffrey G. Wang, Jason Wang, Marvin Li, 和 Seth Neel。2024a。 [潘多拉的白盒：开放大型语言模型中的训练数据泄漏增加](https://api.semanticscholar.org/CorpusID:268033676)。*ArXiv*, abs/2402.17012。

+   Wang 和 Lim（2023）雷 Wang 和 Ee-Peng Lim。2023。 [使用大型预训练语言模型的零-shot 下一项推荐](http://arxiv.org/abs/2304.03153)。

+   Wang 等（2024b）申 Wang, 天龙 Xu, 行 Li, 超力 Zhang, 乔琳 Liang, 纪亮 Tang, 菲利普 S Yu, 和 青松 Wen。2024b。教育中的大型语言模型：一项调查与展望。*arXiv 预印本 arXiv:2403.18105*。

+   Wang 等（2024c）新涛 Wang, 云泽 Xiao, 仁 Tse Huang, 思宇 Yuan, 瑞 Xu, 昊然 Guo, 全 Tu, 雅颖 Fei, 赟 Leng, 伟 Wang, 江杰 Chen, 晟 Li, 和 杨华 Xiao。2024c。 [Incharacter：通过心理访谈评估角色扮演代理的个性忠实度](http://arxiv.org/abs/2310.17976)。

+   Wang 等（2024d）燕城 Wang, 子言 Jiang, 郑 Chen, 凡 Yang, 应雪 Zhou, Eunah Cho, 兴 Fan, 晓江 Huang, 艳斌 Lu, 和 盈臻 Yang。2024d。 [Recmind：大型语言模型驱动的推荐代理](http://arxiv.org/abs/2308.14296)。

+   Wang 等（2023b）余飞 Wang, 万俊 Zhong, 梁游 Li, 菲 Mi, 兴山 Zeng, 文勇 Huang, 励锋 Shang, 辛 Jiang, 和 群 Liu。2023b。将大型语言模型与人类对齐：一项调查。*arXiv 预印本 arXiv:2307.12966*。

+   Wang 等（2023c）镇海龙 Wang, 少光 Mao, 文山 Wu, 淘 Ge, 福如 Wei, 和 恒 Ji。2023c。释放大型语言模型中的认知协同：通过多角色自我协作的任务解决代理。*arXiv 预印本 arXiv:2307.05300*, 1(2):3。

+   Wang et al. (2023d) Zhilin Wang, Yu Ying Chiu, 和 Yu Cheung Chiu. 2023d. 人形代理：模拟类人生成代理的平台。*arXiv 预印本 arXiv:2310.05418*。

+   Wei et al. (2023) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, 和 Denny Zhou. 2023. [链式思维提示引发大型语言模型中的推理](http://arxiv.org/abs/2201.11903)。

+   Wei et al. (2018) Wei Wei, Quoc Le, Andrew Dai, 和 Jia Li. 2018. [AirDialogue: 一个目标导向对话研究环境](https://doi.org/10.18653/v1/D18-1419)。在*2018 年自然语言处理领域经验方法会议论文集*中，第 3844–3854 页，比利时布鲁塞尔。计算语言学协会。

+   Wu et al. (2023a) Cheng-Kuang Wu, Wei-Lin Chen, 和 Hsin-Hsi Chen. 2023a. 大型语言模型进行诊断推理。*arXiv 预印本 arXiv:2307.08922*。

+   Wu et al. (2020) Fangzhao Wu, Ying Qiao, Jiun-Hung Chen, Chuhan Wu, Tao Qi, Jianxun Lian, Danyang Liu, Xing Xie, Jianfeng Gao, Winnie Wu, 和 Ming Zhou. 2020. [MIND: 一个大规模新闻推荐数据集](https://doi.org/10.18653/v1/2020.acl-main.331)。在*计算语言学协会第 58 届年会论文集*中，第 3597–3606 页，在线。计算语言学协会。

+   Wu et al. (2023b) Ning Wu, Ming Gong, Linjun Shou, Shining Liang, 和 Daxin Jiang. 2023b. 大型语言模型是多样化的角色扮演者，用于摘要评价。在*CCF 国际自然语言处理与中文计算会议*中，第 695–707 页。施普林格。

+   Xi et al. (2023) Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou，等。2023. 大型语言模型基础代理的兴起与潜力：一项调查。*arXiv 预印本 arXiv:2309.07864*。

+   Xu et al. (2023) Canwen Xu, Daya Guo, Nan Duan, 和 Julian McAuley. 2023. [Baize: 一个开源聊天模型，通过自聊数据的参数高效调优](https://doi.org/10.18653/v1/2023.emnlp-main.385)。在*2023 年自然语言处理领域经验方法会议论文集*中，第 6268–6278 页，新加坡。计算语言学协会。

+   Xu et al. (2024) Xuhai Xu, Bingsheng Yao, Yuanzhe Dong, Saadia Gabriel, Hong Yu, James Hendler, Marzyeh Ghassemi, Anind K Dey, 和 Dakuo Wang. 2024. Mental-llm: 利用大型语言模型通过在线文本数据进行心理健康预测。*ACM 互动、移动、可穿戴和无处不在技术会议论文集*，8(1):1–32。

+   Yang et al. (2023a) Dongjie Yang, Ruifeng Yuan, Yuantao Fan, Yifei Yang, Zili Wang, Shusen Wang, 和 Hai Zhao. 2023a. [RefGPT: GPT 的对话生成，由 GPT 生成，为 GPT 服务](https://doi.org/10.18653/v1/2023.findings-emnlp.165)。在*计算语言学协会：EMNLP 2023 发现*中，第 2511–2535 页，新加坡。计算语言学协会。

+   Yang et al. (2023b) Fan Yang, Zheng Chen, Ziyan Jiang, Eunah Cho, Xiaojiang Huang, 和 Yanbin Lu. 2023b. [Palr: 关注个性化的 LLMs 推荐](http://arxiv.org/abs/2305.07622)。

+   Yao et al. (2022a) Shunyu Yao, Howard Chen, John Yang, 和 Karthik Narasimhan. 2022a. Webshop: 向可扩展的现实世界网页交互迈进，利用有基础的语言代理。*神经信息处理系统进展*，35:20744–20757。

+   Yao et al. (2024) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, 和 Karthik Narasimhan. 2024. 思维树：利用大型语言模型进行深思熟虑的问题解决. *神经信息处理系统进展*，36。

+   Yao et al. (2022b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan, 和 Yuan Cao. 2022b. React: 在语言模型中协同推理和行动. 见 *第十一届国际学习表征会议*。

+   Yelp (2013) Yelp. 2013. Yelp 数据集. [`www.yelp.com/dataset`](https://www.yelp.com/dataset)。

+   Zang et al. (2020) Xiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara, Raghav Gupta, Jianguo Zhang, 和 Jindong Chen. 2020. [MultiWOZ 2.2 : 一个包含附加注释修正和状态跟踪基准的对话数据集](https://doi.org/10.18653/v1/2020.nlp4convai-1.13). 见 *第二届对话 AI 自然语言处理研讨会论文集*，第 109–117 页，在线。计算语言学协会。

+   Zhang et al. (2023) Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, 和 Ji-Rong Wen. 2023. [推荐作为指令跟随：一种由大型语言模型增强的推荐方法](http://arxiv.org/abs/2305.07001)。

+   Zhang et al. (2024a) Kai Zhang, Yangyang Kang, Fubang Zhao, 和 Xiaozhong Liu. 2024a. [基于 LLM 的医学助手个性化，协调短期和长期记忆](http://arxiv.org/abs/2309.11696)。

+   Zhang et al. (2024b) Kai Zhang, Lizhi Qing, Yangyang Kang, 和 Xiaozhong Liu. 2024b. [基于参数化记忆注入的个性化 LLM 响应生成](http://arxiv.org/abs/2404.03565)。

+   Zhang et al. (2018a) Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, 和 Jason Weston. 2018a. [个性化对话代理：我有一只狗，你也有宠物吗？](http://arxiv.org/abs/1801.07243)

+   Zhang et al. (2018b) Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, 和 Jason Weston. 2018b. [个性化对话代理：我有一只狗，你也有宠物吗？](https://doi.org/10.18653/v1/P18-1205) 见 *第 56 届计算语言学协会年会论文集（第 1 卷：长篇论文）*，第 2204–2213 页，澳大利亚墨尔本。计算语言学协会。

+   Zheng et al. (2024) Boyuan Zheng, Boyu Gou, Jihyung Kil, Huan Sun, 和 Yu Su. 2024. Gpt-4v (vision) 是一个通用的网页代理，如果是有基础的话。*arXiv 预印本 arXiv:2401.01614*。

+   Zheng 等（2023）Lianmin Zheng、Wei-Lin Chiang、Ying Sheng、Siyuan Zhuang、Zhanghao Wu、Yonghao Zhuang、Zi Lin、Zhuohan Li、Dacheng Li、Eric. P Xing、Hao Zhang、Joseph E. Gonzalez 和 Ion Stoica。2023。[使用 mt-bench 和聊天机器人竞技场判断 llm-as-a-judge](http://arxiv.org/abs/2306.05685)。

+   Zhong 等（2020）Peixiang Zhong、Chen Zhang、Hao Wang、Yong Liu 和 Chunyan Miao。2020。[面向角色的情感对话模型](https://doi.org/10.18653/v1/2020.emnlp-main.531)。在*2020 年自然语言处理实证方法会议（EMNLP）论文集*，页码 6556–6566，在线。计算语言学协会。

+   Zhong 等（2024）Wanjun Zhong、Lianghong Guo、Qiqi Gao、He Ye 和 Yanlin Wang。2024。[Memorybank：通过长期记忆增强大型语言模型](https://doi.org/10.1609/aaai.v38i17.29946)。*人工智能领域会议论文集*，38(17):19724–19731。

+   Zhou 等（2023）Shuyan Zhou、Frank F Xu、Hao Zhu、Xuhui Zhou、Robert Lo、Abishek Sridhar、Xianyi Cheng、Yonatan Bisk、Daniel Fried、Uri Alon 等。2023。Webarena：用于构建自主代理的真实网络环境。*arXiv 预印本 arXiv:2307.13854*。

+   Zhou 等（2021）Yujia Zhou、Zhicheng Dou、Bingzheng Wei 和 Ruobing Xievand Ji-Rong Wen。2021。[通过整合搜索行为和朋友网络的基于组的个性化搜索](http://arxiv.org/abs/2111.12618)。

+   Zhou 等（2024）Yujia Zhou、Qiannan Zhu、Jiajie Jin 和 Zhicheng Dou。2024。认知个性化搜索将大型语言模型与高效记忆机制集成。*arXiv 预印本 arXiv:2402.10548*。

+   Ziems 等（2023）Noah Ziems、Wenhao Yu、Zhihan Zhang 和 Meng Jiang。2023。[大型语言模型是内置的自回归搜索引擎](http://arxiv.org/abs/2305.09612)。

## 附录 A Web

先前的研究还调查了将基于 LLM 的语言代理调整到解决网页环境中的任务。然而，它们通常通过任务无关的指令来实现，而不是特定的角色扮演。这里我们提供了在网页环境中利用 LLM 的相关研究。

在这个环境中，LLMs 自主进行网页导航，执行如点击项目、捕获内容和从网络外部知识中搜索等操作，而不分配特定角色。当然，网页任务涉及两个关键组件：HTML 理解和视觉定位，这些与网页代理的效果高度相关（Zheng 等，[2024](https://arxiv.org/html/2406.01171v2#bib.bib149)；Koh 等，[2024](https://arxiv.org/html/2406.01171v2#bib.bib67)）。同时，编纂的一系列工作在[表 1](https://arxiv.org/html/2406.01171v2#A1.T1 "在视觉定位中。‣ 附录 A Web ‣ 大型语言模型中的角色扮演和个性化的两种故事：角色扮演和个性化的调查")中提出了几个基准，以评估网页代理在不同方面的表现。

##### HTML 理解。

Kim et al. ([2024a](https://arxiv.org/html/2406.01171v2#bib.bib65)) 展示了 HTML 理解的能力是 LLMs 的固有特性，这得益于递归批评与改进（RCI）提示方法。然而，由于 HTML 的特殊格式和长上下文元素难以处理和准确响应，大多数研究通过微调方法来提升这一能力（Gur et al., [2022](https://arxiv.org/html/2406.01171v2#bib.bib44), [2023](https://arxiv.org/html/2406.01171v2#bib.bib43); Deng et al., [2024](https://arxiv.org/html/2406.01171v2#bib.bib28)）。

##### 视觉定位。

另一条研究方向集中在 HTML 理解的视觉定位方面，它直接操作渲染的网页而非 HTML 源代码。一些文献提出了网页代理框架，如 CogAgent (Hong et al., [2023b](https://arxiv.org/html/2406.01171v2#bib.bib51)) 和 SeeClick (Cheng et al., [2024](https://arxiv.org/html/2406.01171v2#bib.bib22))，利用大规模多模态模型（LMMs） (Achiam et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib4); Team et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib118))。通过网页截图的额外信息，LMMs 通常优于基于文本的 LLMs Zheng et al. ([2024](https://arxiv.org/html/2406.01171v2#bib.bib149))。

| 基准 | #实例 | #领域 | 现实 | 动态 | 视觉 | 评估 |
| --- | --- | --- | --- | --- | --- | --- |
| 环境 | 互动 | 需求 |
| WebShop (Yao et al., [2022a](https://arxiv.org/html/2406.01171v2#bib.bib139)) | 12,087 | 1 | ✗ | ✓ | ✗ | 端到端 |
| Mind2Web (Deng et al., [2024](https://arxiv.org/html/2406.01171v2#bib.bib28)) | 2,350 | 5 | ✓ | ✗ | ✗ | 端到端 |
| WebArena (Zhou et al., [2023](https://arxiv.org/html/2406.01171v2#bib.bib153)) | 812 | 4 | ✓ | ✓ | ✗ | 端到端 |
| VisualWebArena (Koh et al., [2024](https://arxiv.org/html/2406.01171v2#bib.bib67)) | 910 | 3 | ✓ | ✓ | ✓ | 端到端 |
| VisualWebBench (Liu et al., [2024](https://arxiv.org/html/2406.01171v2#bib.bib81)) | 1,500 | 12 | ✓ | ✗ | ✓ | 细粒度 |

表 1：最近在网页环境中基准的比较。现实环境指基准的环境是否基于实际网页或现实的网页导航模拟。动态交互指基准是否支持动态交互而不是保持静态状态。视觉需求指基准是否涉及视觉基础任务。评估指的是评估类型。端到端基准包括简单指令的任务，需要逐步解决以得到最终答案。细粒度基准包含对网页环境中必需技能如光学字符识别（OCR）和语义理解的详细评估。

| 论文 | 场景 | 数据集 | 方法 | 任务 |
| --- | --- | --- | --- | --- |
| Li 等人 ([2023b](https://arxiv.org/html/2406.01171v2#bib.bib72)) | 酒店、电影与电视、餐馆 | TripAdvisor、亚马逊、Yelp | 嵌入、提示、微调 | 方面提取、评分预测 |
| P5 Geng 等人 ([2022](https://arxiv.org/html/2406.01171v2#bib.bib39)) | 体育、美容、玩具、Yelp | 亚马逊 Ni 等人 ([2019](https://arxiv.org/html/2406.01171v2#bib.bib89))、Yelp | 预训练、提示 | 评分预测、序列推荐、解释生成、评论生成和直接推荐 |
| PETER Li 等人 ([2021](https://arxiv.org/html/2406.01171v2#bib.bib70)) | 酒店、电影与电视、餐馆 | TripAdvisor、亚马逊、Yelp | Transformer | 评分预测和解释生成 |
| PEPLER Li 等人 ([2023a](https://arxiv.org/html/2406.01171v2#bib.bib71)) | 酒店、电影、电视和餐馆 | TripAdvisor5（酒店）、亚马逊（电影与电视）和 Yelp7（餐馆） | 提示、微调 | 解释生成 |
| PALR Yang 等人 ([2023b](https://arxiv.org/html/2406.01171v2#bib.bib138)) | 电影、美容 | MovieLens-1M Harper 和 Konstan ([2015](https://arxiv.org/html/2406.01171v2#bib.bib47))、亚马逊美容 Ni 等人 ([2019](https://arxiv.org/html/2406.01171v2#bib.bib89)) | 微调、用户画像生成、检索 | 用户画像生成和直接推荐 |
| Chu 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib24)) | 体育、户外、美容、玩具和游戏 | 亚马逊 | 微调 | 评分预测、序列推荐、直接推荐、解释生成和评论总结 |
| Liu 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib80)) | 美容 | 亚马逊 | 提示 | 评分预测、序列推荐、直接推荐、解释生成和评论总结 |
| Zhang 等人 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib144)) | 视频游戏 | 亚马逊 | 指令调优 | 序列推荐和直接推荐 |
| Hou 等人 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib52)) | 电影 | 亚马逊 Ni 等人 ([2019](https://arxiv.org/html/2406.01171v2#bib.bib89))、MovieLens-1M Harper 和 Konstan ([2015](https://arxiv.org/html/2406.01171v2#bib.bib47)) | 提示 | 序列推荐 |
| Wang 和 Lim ([2023](https://arxiv.org/html/2406.01171v2#bib.bib122)) | 电影 | MovieLens-1M Harper 和 Konstan ([2015](https://arxiv.org/html/2406.01171v2#bib.bib47)) | 提示 | 序列推荐和直接推荐 |
| Chen 等人 ([2022](https://arxiv.org/html/2406.01171v2#bib.bib15)) | 新闻 | MIND Wu 等人 ([2020](https://arxiv.org/html/2406.01171v2#bib.bib132))、Reddit | 带有弱标签的微调 | 直接推荐 |

表 2: 推荐系统领域现有研究概述。根据 Liu 等 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib80)) 的分类，我们将推荐系统分为五种类型：评分预测、序列推荐、解释生成、评论生成和直接推荐。

| 数据集 | 场景 | 任务 | #实例 | #用户 | #项目 |
| --- | --- | --- | --- | --- | --- |
| 亚马逊评论 Ni 等 ([2019](https://arxiv.org/html/2406.01171v2#bib.bib89)) | 产品 | 评分, 评论 | 233.1M | 43.53M | 15.17M |
| MovieLens Harper 和 Konstan ([2015](https://arxiv.org/html/2406.01171v2#bib.bib47)) | 电影 | 评分 | 100,000 | 1,000 | 1,700 |
| Yelp Yelp ([2013](https://arxiv.org/html/2406.01171v2#bib.bib142)) | 商业 | 评分 & 评论 | 6,990,280 | 1,987,897 | 150,346 |
| TripAdvisor Li 等 ([2023a](https://arxiv.org/html/2406.01171v2#bib.bib71)) | 酒店, 餐馆 | 评分 & 评论 | 320,023 | 9,765 | 6,280 |
| MIND Wu 等 ([2020](https://arxiv.org/html/2406.01171v2#bib.bib132)) | 新闻 | 序列推荐 | 15M | 1M | 160k |

表 3: 个性化 LLMs 中用于推荐和搜索任务的常用数据集列表。第五列中的实例包括评论和评分。

| 类别 | 数据集 | #对话 | #发言 | #领域 |
| --- | --- | --- | --- | --- |
| ToD | MultiWOZ 1.0 Budzianowski 等 ([2018](https://arxiv.org/html/2406.01171v2#bib.bib12)) | 10,438 | 75,894 | 7 |
|  | MultiWOZ 2.0 Ramadan 等 ([2018](https://arxiv.org/html/2406.01171v2#bib.bib97)) | 8,438 | 63,841 | 7 |
|  | MultiWOZ 2.1 Eric 等 ([2020](https://arxiv.org/html/2406.01171v2#bib.bib34)) | 7,032 | 57,022 | 7 |
|  | MultiWOZ 2.2 Zang 等 ([2020](https://arxiv.org/html/2406.01171v2#bib.bib143)) | 10,438 | 71,572 | 7 |
|  | SGD Rastogi 等 ([2020](https://arxiv.org/html/2406.01171v2#bib.bib98)) | 22,825 | 463,284 | 20 |
|  | STAR Mosig 等 ([2020](https://arxiv.org/html/2406.01171v2#bib.bib88)) | 6,652 | 127,833 | 13 |
|  | AirDialogue Wei 等 ([2018](https://arxiv.org/html/2406.01171v2#bib.bib130)) | 4,000 | 52,000 | 1 |
|  | UniDA He 等 ([2022](https://arxiv.org/html/2406.01171v2#bib.bib49)) | 70,726 | 975,780 | 13 |
| 用户画像 | PersonaChat 张等 ([2018a](https://arxiv.org/html/2406.01171v2#bib.bib147)) | 11,907 | 164,356 | 1 |
|  | ConvAI2 Dinan 等 ([2019](https://arxiv.org/html/2406.01171v2#bib.bib31)) | 13,500 | 182,150 | 1 |
|  | Baidu PersonaChat PapersWithCode ([2020](https://arxiv.org/html/2406.01171v2#bib.bib92)) | 20,000 | 280,000 | 1 |
|  | JPersonaChat Sugiyama 等 ([2021](https://arxiv.org/html/2406.01171v2#bib.bib112)) | 10,000 | 140,000 | 1 |
|  | JEmpatheticDialogues Sugiyama 等 ([2021](https://arxiv.org/html/2406.01171v2#bib.bib112)) | 25,000 | 350,000 | 1 |
|  | DailyDialog Li 等 ([2017](https://arxiv.org/html/2406.01171v2#bib.bib74)) | 13,118 | 102,979 | 10 |

表 4: 常用于 ToD 建模和用户画像建模的数据集列表。其中，不同版本的 MultiWOZ Budzianowski 等 ([2018](https://arxiv.org/html/2406.01171v2#bib.bib12)); Ramadan 等 ([2018](https://arxiv.org/html/2406.01171v2#bib.bib97)); Eric 等 ([2020](https://arxiv.org/html/2406.01171v2#bib.bib34)); Zang 等 ([2020](https://arxiv.org/html/2406.01171v2#bib.bib143)) 和 PersonaChat Zhang 等 ([2018a](https://arxiv.org/html/2406.01171v2#bib.bib147)) 是最常用的。更新版的 MultiWOZ 在多个方面有所改进：数据质量、对话复杂性、模式和本体更新，以及数据集规模。PersonaChat 包含各种个人资料，涵盖背景、偏好和个性特征。这些资料使得建模连贯且具有上下文的多轮对话场景成为可能。在用户画像建模的应用中，Tu 等 ([2023](https://arxiv.org/html/2406.01171v2#bib.bib119)) 将个人与符合个人画像的虚拟支持者匹配，并介绍了 MBTI-S2Conv 数据集，其中包含具有不同个人资料的角色之间的对话。Lotfi 等 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib83)) 和 Han 等 ([2024](https://arxiv.org/html/2406.01171v2#bib.bib45)) 均提出了与大五人格相关的合成数据集。 |

| 领域 | 对话、槽位和状态 |
| --- | --- |
| 餐馆 | [用户:] 我需要一个位于市中心且价格贵的就餐地点。 |
|  | 槽位: 餐馆区域: 市中心, 餐馆价格范围: 贵 |
|  | 状态: active_intent: find_restaurant |
|  | [系统:] 我有几个选择；你更喜欢非洲、亚洲还是英国食物？ |
|  | 状态: active_intent: find_restaurant, 请求的槽位: restaurant-food |
|  | [用户:] 任何食物都可以，只要价格有点贵。可以告诉我你推荐的酒店的电话吗？ |
|  | 槽位: 餐馆区域: 市中心, 餐馆价格范围: 贵, 餐馆食物类型 |
|  | 状态: active_intent: find_restaurant, 请求的槽位: restaurant-phone |
|  | [系统:] 市中心有一家非洲餐厅叫 Bedouin。你觉得怎么样？ |
|  | 槽位: 餐馆名称: Bedouin |
|  | [用户:] 听起来不错，可以告诉我那个电话吗？另外，你能推荐一家贵的酒店吗？ |
|  | 槽位: 餐馆区域: 市中心, 餐馆名称: Bedouin, 餐馆价格范围: 贵, 餐馆电话 |
|  | 状态: active_intent: find_restaurant, 请求的槽位: restaurant-phone |
| 酒店 | [系统:] Bedouin 的电话是 01223367660。就酒店而言，我推荐位于市中心的 University Arms Hotel。 |
|  | 槽位: 酒店名称: University Arms Hotel |
|  | 状态: active_intent: find_hotel |
|  | [用户:] 是的。你能为我预定吗？ |
|  | 状态: active_intent: find_hotel, 请求的槽位: hotel-booking |
|  | [系统:] 当然，你希望什么时候预定？ |
|  | [用户:] 我想为 2 个人预订 2 晚，从星期六开始。 |
|  | 插槽：酒店-预订日期：星期六，酒店-预订人数：2，酒店-住宿天数：2 |
|  | 状态：active_intent: book_hotel，插槽值：酒店-预订日期：星期六，酒店-预订人数：2，酒店-住宿天数：2 |
|  | [系统:] 你的预订已成功。你的参考编号是 FRGZWQL2。还有什么我可以帮忙的吗？ |
|  | 插槽：酒店-预订日期：星期六，酒店-预订人数：2，酒店-住宿天数：2，参考编号：FRGZWQL2 |
|  | [用户:] 这就是我需要知道的全部。谢谢，再见。 |
|  | [系统:] 非常感谢你使用剑桥市信息中心。祝你有美好的一天！ |

表格 5：MultiWOZ 数据集中 ToD 建模的一个示例 Zang et al. ([2020](https://arxiv.org/html/2406.01171v2#bib.bib143))。

| 角色 | 聊天 |
| --- | --- |
| 我飞飞机。我喜欢组装电脑。我最喜欢的乐队是 Tool。我在军队中。我中途退学了。 | [人物 1:] 你好，你今晚怎么样？ |
|  | [人物 2:] 嗨。我还好。累，但还好。你怎么样？ |
|  | [人物 1:] 我还不错，应该去睡觉了，我有学校，但睡不着。 |
|  | [人物 2:] 我没有完成学业，而是参军了。 |
|  | [人物 1:] 哇，我才 14 岁，所以现在还做不到，但我希望能做到。 |
|  | [人物 2:] 很好。好好待在学校，努力工作。 |
|  | [人物 1:] 我试过，我喜欢视频游戏和赛车。 |
|  | [人物 2:] 我也喜欢视频游戏，《辐射》是我最喜欢的。 |
|  | [人物 1:] 我是《使命召唤》的粉丝，迫不及待想要玩新的版本。 |
|  | [人物 2:] 我的小弟弟也是一名《使命召唤》的玩家，他还挺不错的。 |
|  | [人物 1:] 我有三个最好的朋友，但还有很多其他的朋友也玩这个游戏。 |
|  | [人物 2:] 我有一个最好的朋友，她也是像我一样的飞行员。 |
|  | [人物 1:] 你飞的是什么类型的飞机？ |
|  | [人物 2:] 一架轰炸机，真棒。你想上课吗？ |
|  | [人物 1:] 我有点怕高，所以不确定飞行是否适合我。 |
|  | [人物 2:] 你至少应该尝试坐飞机，这真的很刺激。 |

表格 6：Persona-Chat 数据集中用户角色建模的一个示例 [第 3.5 节](https://arxiv.org/html/2406.01171v2#S3.SS5 "3.5 Personalized Dialogue Generation ‣ 3 LLM Personalization ‣ Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization") Zhang et al. ([2018b](https://arxiv.org/html/2406.01171v2#bib.bib148))。

由 LaTeXML![吉祥物 Sammy](http://dlmf.nist.gov/LaTeXML/) 于 2024 年 6 月 26 日（周三）生成 09:38:22。
