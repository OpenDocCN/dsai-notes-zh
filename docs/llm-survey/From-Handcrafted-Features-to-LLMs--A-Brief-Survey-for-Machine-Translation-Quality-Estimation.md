<!--yml

category: 未分类

date: 2024-09-03 17:29:54

-->

# From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation

> 来源：[`arxiv.org/html/2403.14118`](https://arxiv.org/html/2403.14118)

1.  [I 引言](https://arxiv.org/html/2403.14118v1#S1 "I Introduction ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

    1.  [I-A 大纲](https://arxiv.org/html/2403.14118v1#S1.SS1 "I-A Outline ‣ I Introduction ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

    1.  [I-B 贡献](https://arxiv.org/html/2403.14118v1#S1.SS2 "I-B Contribution ‣ I Introduction ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

1.  [II 数据、注释方法和质量估计共享任务](https://arxiv.org/html/2403.14118v1#S2 "II DATA, ANNOTATIONS METHODS, AND SHARED TASKS FOR QUALITY ESTIMATION ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

    1.  [II-A 数据集](https://arxiv.org/html/2403.14118v1#S2.SS1 "II-A Datasets ‣ II DATA, ANNOTATIONS METHODS, AND SHARED TASKS FOR QUALITY ESTIMATION ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

    1.  [II-B 注释方法](https://arxiv.org/html/2403.14118v1#S2.SS2 "II-B Annotation Methods ‣ II DATA, ANNOTATIONS METHODS, AND SHARED TASKS FOR QUALITY ESTIMATION ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

        1.  [II-B1 人类翻译错误率 (HTER)](https://arxiv.org/html/2403.14118v1#S2.SS2.SSS1 "II-B1 Human Translation Error Rate (HTER) ‣ II-B Annotation Methods ‣ II DATA, ANNOTATIONS METHODS, AND SHARED TASKS FOR QUALITY ESTIMATION ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

        1.  [II-B2 直接评估 (DA)](https://arxiv.org/html/2403.14118v1#S2.SS2.SSS2 "II-B2 Direct Assessment (DA) ‣ II-B Annotation Methods ‣ II DATA, ANNOTATIONS METHODS, AND SHARED TASKS FOR QUALITY ESTIMATION ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

        1.  [II-B3 多维度质量指标 (MQM)](https://arxiv.org/html/2403.14118v1#S2.SS2.SSS3 "II-B3 Multi-dimensional Quality Metrics (MQM) ‣ II-B Annotation Methods ‣ II DATA, ANNOTATIONS METHODS, AND SHARED TASKS FOR QUALITY ESTIMATION ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

        1.  [II-B4 难度讨论](https://arxiv.org/html/2403.14118v1#S2.SS2.SSS4 "II-B4 Discussion of Difficulty ‣ II-B Annotation Methods ‣ II DATA, ANNOTATIONS METHODS, AND SHARED TASKS FOR QUALITY ESTIMATION ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

    1.  [II-C 共享任务](https://arxiv.org/html/2403.14118v1#S2.SS3 "II-C 共享任务 ‣ II 质量估计的数据、注释方法和共享任务 ‣ 从手工特征到大语言模型：机器翻译质量估计的简要调查")

        1.  [II-C1 单词级质量估计共享任务](https://arxiv.org/html/2403.14118v1#S2.SS3.SSS1 "II-C1 单词级质量估计共享任务 ‣ II-C 共享任务 ‣ II 质量估计的数据、注释方法和共享任务 ‣ 从手工特征到大语言模型：机器翻译质量估计的简要调查")

        1.  [II-C2 句子级质量估计共享任务](https://arxiv.org/html/2403.14118v1#S2.SS3.SSS2 "II-C2 句子级质量估计共享任务 ‣ II-C 共享任务 ‣ II 质量估计的数据、注释方法和共享任务 ‣ 从手工特征到大语言模型：机器翻译质量估计的简要调查")

        1.  [II-C3 文档级质量估计共享任务](https://arxiv.org/html/2403.14118v1#S2.SS3.SSS3 "II-C3 文档级质量估计共享任务 ‣ II-C 共享任务 ‣ II 质量估计的数据、注释方法和共享任务 ‣ 从手工特征到大语言模型：机器翻译质量估计的简要调查")

        1.  [II-C4 可解释的质量估计共享任务](https://arxiv.org/html/2403.14118v1#S2.SS3.SSS4 "II-C4 可解释的质量估计共享任务 ‣ II-C 共享任务 ‣ II 质量估计的数据、注释方法和共享任务 ‣ 从手工特征到大语言模型：机器翻译质量估计的简要调查")

1.  [III 质量估计的方法](https://arxiv.org/html/2403.14118v1#S3 "III 质量估计的方法 ‣ 从手工特征到大语言模型：机器翻译质量估计的简要调查")

    1.  [III-A 基于手工特征的质量估计](https://arxiv.org/html/2403.14118v1#S3.SS1 "III-A 基于手工特征的质量估计 ‣ III 质量估计的方法 ‣ 从手工特征到大语言模型：机器翻译质量估计的简要调查")

    1.  [III-B 基于深度学习的质量估计](https://arxiv.org/html/2403.14118v1#S3.SS2 "III-B 基于深度学习的质量估计 ‣ III 质量估计的方法 ‣ 从手工特征到大语言模型：机器翻译质量估计的简要调查")

        1.  [III-B1 经典深度学习方法](https://arxiv.org/html/2403.14118v1#S3.SS2.SSS1 "III-B1 经典深度学习方法 ‣ III-B 基于深度学习的质量估计 ‣ III 质量估计的方法 ‣ 从手工特征到大语言模型：机器翻译质量估计的简要调查")

        1.  [III-B2 融合预训练语言模型的方法](https://arxiv.org/html/2403.14118v1#S3.SS2.SSS2 "III-B2 融合预训练语言模型的方法 ‣ III-B 基于深度学习的质量估计 ‣ III 质量估计的方法 ‣ 从手工特征到大语言模型：机器翻译质量估计的简要调查")

    1.  [III-C 基于大语言模型的质量评估](https://arxiv.org/html/2403.14118v1#S3.SS3 "III-C Quality Estimation Based on Large Language Models ‣ III Methods of Quality Estimation ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

        1.  [III-C1 基于 LLMs 生成内容的直接预测](https://arxiv.org/html/2403.14118v1#S3.SS3.SSS1 "III-C1 Direct prediction based on content generated by LLMs ‣ III-C Quality Estimation Based on Large Language Models ‣ III Methods of Quality Estimation ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

        1.  [III-C2 基于 LLMs 的生成概率](https://arxiv.org/html/2403.14118v1#S3.SS3.SSS2 "III-C2 Based on the generative probabilities of LLMs ‣ III-C Quality Estimation Based on Large Language Models ‣ III Methods of Quality Estimation ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

        1.  [III-C3 利用 LLMs 生成伪数据](https://arxiv.org/html/2403.14118v1#S3.SS3.SSS3 "III-C3 Leveraging LLMs to generate pseudo data ‣ III-C Quality Estimation Based on Large Language Models ‣ III Methods of Quality Estimation ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

        1.  [III-C4 LLMs 作为 QE 模型的基础](https://arxiv.org/html/2403.14118v1#S3.SS3.SSS4 "III-C4 LLMs as the foundation for QE models ‣ III-C Quality Estimation Based on Large Language Models ‣ III Methods of Quality Estimation ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

        1.  [III-C5 基于检索的方法](https://arxiv.org/html/2403.14118v1#S3.SS3.SSS5 "III-C5 Retrieval-based methods ‣ III-C Quality Estimation Based on Large Language Models ‣ III Methods of Quality Estimation ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

1.  [IV 发现](https://arxiv.org/html/2403.14118v1#S4 "IV Finding ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

1.  [V 结论](https://arxiv.org/html/2403.14118v1#S5 "V Conclusion ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")

许可：arXiv.org 永久性非独占许可 arXiv:2403.14118v1 [cs.CL] 2024 年 3 月 21 日

# 从手工特征到 LLMs：机器翻译质量评估简要调查

匿名作者

###### 摘要

机器翻译质量估计（MTQE）是指在实时估计机器翻译文本质量的任务，无需参考翻译，这对于 MT 的发展至关重要。经过二十年的演变，QE 已经取得了丰富的成果。本文提供了对 QE 数据集、注释方法、共享任务、方法论、挑战以及未来研究方向的全面概述。它从 QE 的背景和重要性介绍开始，接着解释了单词级 QE、句子级 QE、文档级 QE 和可解释 QE 的概念和评估指标。本文将 QE 历史上开发的方法分为基于手工特征、深度学习和大语言模型（LLMs）的方法，其中深度学习方法又分为经典深度学习和包含预训练语言模型（LMs）的方法。此外，文章详细说明了每种方法的优缺点，并对不同方法进行了简单的比较。最后，论文讨论了 QE 研究中的当前挑战，并展望了未来的研究方向。

###### 索引词：

机器翻译，质量估计，大语言模型

## I 引言

作为 NLP 中的一个关键子领域，MT 随着深度学习技术的出现经历了突破性的进展。然而，MT 的质量仍然固有地不确定。传统的评估指标，如 BLEU [papineni2002bleu]、METEOR [banerjee2005meteor]、TER [snover2006study] 和 CHRF 依赖参考翻译来评估翻译质量。相比之下，QE 技术能够在无需参考的情况下自动评估翻译质量，为评估 MT 系统的性能提供了一种有价值的替代方案。

在实际应用场景中，MT 系统的使用往往在没有参考翻译的情况下进行。在这种情况下，QE 的重要性尤其突出。在没有参考的情况下，QE 为用户、开发者和翻译服务提供商提供了一个重要的独立评估翻译质量的手段。对于用户来说，这使他们能够更准确地确定翻译质量的水平；对于开发者，QE 作为衡量 MT 系统性能的有效手段；对于翻译服务提供商，QE 提供了一种在交付前筛选低质量翻译的方法。这些应用展示了 QE 在各个层面和领域中的广泛适用性和关键作用。

在机器翻译（MT）质量评估（QE）的初期阶段，该领域并没有统一和明确的定义，研究主要集中在统计机器翻译系统上。2009 年，Specia 等研究人员 [specia2009estimating] 引入了一个创新的 QE 框架，该框架包括对翻译进行手动评分注释、特征工程的实施以及使用机器学习算法训练能够预测翻译质量的模型。自 2012 年机器翻译研讨会（WMT）将 QE 确立为独立任务以来，研究已经发展为三种主要方法：第一种是基于手工特征的 QE；第二种利用深度学习进行 QE，其中进一步包括经典的深度学习方法和那些结合了预训练语言模型的深度学习方法；第三种是基于大型语言模型（LLMs）的新兴方法。这些方法的发展显著推动了 QE 的进展，并逐渐提高了 QE 模型评估的准确性。

毋庸置疑，基于 LLMs 的方法已成为 QE 领域的研究焦点。研究人员正在寻求利用 LLMs 的广泛知识库和学习能力，在 QE 研究中取得新突破。目前，基于 LLMs 的 QE 研究主要包括以下方向：首先，使用 LLMs 直接预测翻译质量分数 [kocmi2023large]、错误等级 [lu2023error] 或流畅度 [yang2023knowledge]；其次，利用 LLMs 的生成概率，这涉及使用各种提示和示例获取源文本翻译句子的多个生成概率，从而计算均值和方差，以获得对翻译质量更准确的测量 [huang2023towards]；第三，基于 LLMs 内的知识生成伪数据，然后转移到 QE 模型中 [xu2023instructscore, HUANG2024102022]；第四，使用 LLMs 作为预训练基础模型来增强 QE 系统 [xu2023instructscore, gladkoff2023predicting]；第五，采用基于检索的方法将翻译知识注入 LLMs [huang2023towards, HUANG2024102022]。尽管基于 LLMs 的 QE 方法的性能尚未超越包含预训练语言模型的 QE 方法，但预计随着持续的研究，基于 LLMs 的方法有可能达到最先进（SOTA）的性能水平。

确实，尽管 QE 取得了显著进展，但仍然存在若干亟待解决的挑战，包括数据稀缺、解释性不足、词级和文档级 QE 方法的稀有、预训练语言模型和 LLMs 对计算资源的高需求，以及缺乏标准化评估基准。为了提高 QE 的准确性、解释性和可持续性，这些挑战必须逐一解决。

在本文中，我们的目标是为从事质量估计（QE）研究的实践者和有意进入这一领域的学者提供清晰而简洁的概述。与共享任务概述不同，我们的工作不仅综合了过去四年 WMT QE 共享任务的内容，还扩展了内容的范围。具体而言，本文回顾了 QE 领域的数据集、注释方法、共享任务以及所有开创性的经典方法，特别强调了目前备受推崇的基于大语言模型（LLMs）的 QE 方法。此外，我们探讨了 LLMs 对 QE 的具体影响，这是其他调查综述尚未涉及的主题。最终，我们深入讨论了 QE 面临的当前挑战以及该领域未来的研究方向。

### I-A 大纲

在第[II](https://arxiv.org/html/2403.14118v1#S2 "II DATA, ANNOTATIONS METHODS, AND SHARED TASKS FOR QUALITY ESTIMATION ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")节中，我们讨论了 QE 中常用的数据集，并根据应用场景将注释方法分类为人工翻译错误率（HTER）、直接评估（DA）和多维度质量指标（MQM）。我们还将 QE 共享任务分为词级、句级、文档级和可解释的 QE。然而，QE 任务仍在不断发展，需要更合理的目标和数据注释原则。

在第[III](https://arxiv.org/html/2403.14118v1#S3 "III Methods of Quality Estimation ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")节中，我们回顾了 QE 领域的不同方法，并将其分类为特征工程和基于机器学习（ML）的方法、基于深度学习的方法以及基于 LLMs 的方法。在基于深度学习的方法中，我们进一步将其分为经典深度学习方法和那些结合预训练语言模型的方法。我们还在图[1](https://arxiv.org/html/2403.14118v1#S1.F1 "Figure 1 ‣ I-A Outline ‣ I Introduction ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")的每个框中列出了显著的方法。在第[IV](https://arxiv.org/html/2403.14118v1#S4 "IV Finding ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")节中，我们列出了当前 QE 领域存在的五个主要挑战。最后，在第[V](https://arxiv.org/html/2403.14118v1#S5 "V Conclusion ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation")节中，我们给出了我们的结论。

![参考图注](img/5ef62bde5736f5f34fe024e9df6e0e39.png)

图 1：本文提到的所有方法。

### I-B 贡献

我们的贡献可以总结如下：

+   •

    我们为从事质量估计（QE）的实践者和有意进入这一研究领域的学者提供了清晰简洁的概述，涵盖了 QE 的研究发展，这是自然语言处理（NLP）中的一个重要且创新的领域。这包括数据集、注释方法、共享任务以及 QE 领域中的几乎所有关键方法，特别强调了基于 LLMs 的当前流行的 QE 方法，这是其他综述尚未涵盖的话题。

+   •

    我们将 QE 领域发展过程中出现的方法分为三大类：使用手工特征的方法、基于深度学习的方法和利用 LLMs 的方法。我们对 QE 领域几乎所有具有代表性的方法进行了深入探讨，特别强调阐明它们之间的内在联系。我们的目标是提供对当前 QE 方法状态的全面和专业的理解。

+   •

    与共享任务的概述相比，我们综合了过去四年 WMT 的 QE 共享任务，并增加了额外的内容。此外，我们深入讨论了 QE 面临的五个挑战，以及未来的研究方向。

## II 数据、注释方法和质量估计的共享任务

本节提供了 QE 的综合概述，涵盖了数据集、注释方法和共享任务。它回顾了 QE 研究中使用的数据集，探讨了注释方法，并介绍了词级、句子级、文档级和可解释 QE 的共享任务。这些方面为研究人员提供了宝贵的资源和评估方法。

### II-A 数据集

MLQE-PE 数据集[fomicheva2020mlqepe]是 QE 和自动后编辑（APE）研究中的一个重要里程碑，提供了多语言环境中的注释。该数据集使用维基百科和 Reddit 文章中的句子构建。为 11 对不同语言对（LPs）生成了平行语料库，包括 7 对传统资源语言对（英语-德语（En-De）、英语-中文（En-Zh）、俄语-英语（Ru-En）、罗马尼亚语-英语（Ro-En）、爱沙尼亚语-英语（Et-En）、尼泊尔语-英语（Ne-En）和僧伽罗语-英语（Si-En）），每对有 10K 句子，分为训练集、开发集和两个测试集（test20 和 test21）。此外，该数据集还包括 4 对零样本语言对（普什图语-英语（Ps-En）、高棉语-英语（Km-En）、英语-日语（En-Ja）和英语-捷克语（En-Cs）），每对有 2K 句子，也均分为两个测试集。

WMT2023 QE 数据集由 WMT2023 的组织者提供，包括 DA 和后编辑（PE）数据，以及基于 MQM 的数据。值得注意的是，WMT2023 QE 数据集中英语-印地语（En-Hi）、英语-古吉拉特语（En-Gu）、英语-泰米尔语（En-Ta）、英语-泰卢固语（En-Te）、英语-波斯语（En-Fa）和希伯来语-英语（He-En）语言对的数据在 2023 年新发布。

DA & PE 数据包括了来自 MLQE-PE 数据集的所有 LP，并新增了如英语-约鲁巴语（En-Yo）、英语-马拉地语（En-Mr）、英语-印地语（En-Hi）、英语-泰米尔语（En-Ta）、英语-泰卢固语（En-Te）、英语-古吉拉特语（En-Gu）和英语-波斯语（En-Fa）等新的 LP。在这个数据集中，有 14 个 LP 提供了 PE 信息，17 个 LP 提供了 DA 注释。训练集包括了 MLQE-PE 数据集中的所有 LP，每个 LP 大约有 10,000 个样本；对于 En-Hi、En-Gu、En-Ta 和 En-Te，各有约 7,000 个样本；而 En-Mr 则有约 27,000 个样本。测试集包括了如 En-Mr、En-Hi、En-Gu、En-Ta、En-Te 和 En-Fa 等 LP，每个 LP 有超过 1,000 个样本。

MQM 数据部分涵盖了四个 LP：英德（En-De）、英俄（En-Ru）、中英（Zh-En）和希英（He-En）。训练集包括英德、英俄和中英 LP，样本数量分别为 30,425、17,144 和 36,851。测试集包括英德、中英和希英对，每对都有超过 1,000 个样本。

这些数据集为 QE 领域的研究提供了极为重要的资源。它们为研究人员提供了丰富的文本和详细的注释，推动了 QE 研究的进展。具体相关信息可以在表格 [I](https://arxiv.org/html/2403.14118v1#S2.T1 "TABLE I ‣ II-A Datasets ‣ II DATA, ANNOTATIONS METHODS, AND SHARED TASKS FOR QUALITY ESTIMATION ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation") 中找到。需要注意的是，为了展示的简洁，WMT2023 QE 数据集省略了所有来自 MLQE-PE 数据集的 LP。

表 I：质量评估的数据集。

| 数据集 | LPs | 句子数 | 词元数 | 注释 | 数据来源 | 发布日期 |
| --- | --- | --- | --- | --- | --- | --- |
| 训练集 | 开发集 | 测试集 | 训练集 | 开发集 | 测试集 | DA | PE | MQM |
| MLQE-PE | 英德 | 7,000 | 1,000 | 1,000/1,000 | 114,980 | 16,519 | 16,371/16,545 | ✓ | ✓ |  | 维基百科 | 2021/22 |
| 英中 | 7,000 | 1,000 | 1,000/1,000 | 115,585 | 16,307 | 16,765/16,637 | ✓ | ✓ |  | 维基百科 | 2021/22 |
| 俄英 | 7,000 | 1,000 | 1,000/1,000 | 82,229 | 11,992 | 11,760/11,650 | ✓ | ✓ |  | Reddit | 2021/22 |
| 罗英 | 7,000 | 1,000 | 1,000/1,000 | 120,198 | 17,268 | 17,001/17,359 | ✓ | ✓ |  | 维基百科 | 2021/22 |
| 爱沙英 | 7,000 | 1,000 | 1,000/1,000 | 98,080 | 14,423 | 14,358/14,044 | ✓ | ✓ |  | 维基百科 | 2021/22 |
| 荷英 | 7,000 | 1,000 | 1,000/1,000 | 104,934 | 15,144 | 14,770/15,017 | ✓ | ✓ |  | 维基百科 | 2021/22 |
| 英中 | 7,000 | 1,000 | 1,000/1,000 | 109,515 | 15,708 | 15,821/15,709 | ✓ | ✓ |  | 维基百科 | 2021/22 |
| 普英 | - | 1,000 | 1,000 | - | 27,045 | 27,414 | ✓ | ✓ |  | 维基百科 | 2021/22 |
| 高棉英 | - | 1,000 | 1,000 | - | 21,981 | 22,048 | ✓ | ✓ |  | 维基百科 | 2021/22 |
| 英日 | - | 1,000 | 1,000 | - | 20,626 | 20,646 | ✓ | ✓ |  | 维基百科 | 2021/22 |
| 英捷 | - | 1,000 | 1,000 | - | 20,394 | 20,244 | ✓ | ✓ |  | 维基百科 | 2021/22 |
| WMT2023 QE | 英-马 | 27,000 | 1,000 | 1,086 | 717,581 | 26,253 | 27,951 | ✓ | ✓ |  | 多领域/多语料库 | 2023 | 英-印 | 7,000 | 1,000 | 1,074 | 181,336 | 25,943 | 28,032 | ✓ | 多领域/多语料库 | 2023 |
| 英-古 | 7,000 | 1,000 | 1,075 | 153,685 | 21,238 | 23,084 | ✓ |  |  | 多领域/多语料库 | 2023 |
| 英-塔 | 7,000 | 1,000 | 1,067 | 150,670 | 21,655 | 20,342 | ✓ |  |  | 多领域/多语料库 | 2023 |
| 英-泰 | 7,000 | 1,028 | 1,000 | 147,492 | 20,686 | 22,640 | ✓ |  |  | 多领域/多语料库 | 2023 |
| 英-法 | - | - | 1,000 | - | - | 26,807 |  | ✓ |  | 新闻（多领域） | 2023 |
| 英-德 | 30,425 | - | 1,897 | 877,066 | - | 37,996 |  |  | ✓ | 多领域 | 2021/23 |
| 英-俄 | 17,144 | - | - | 395,045 | - | - |  |  | ✓ | 多领域 | 2021/22 |
| 中-英 | 36,851 | - | 1,675 | 1,654,454 | - | 39,770 |  |  | ✓ | 多领域 | 2021/23 |
| 他-英 | - | - | 1,182 | - | - | 35,592 |  |  | ✓ | 多领域 | 2023 |
|  |  |  |  |  |  |  |  |  |  |  |  |  |

### II-B 标注方法

本节讨论了 QE 中的标注方法，这些方法通过提供标记数据来服务于 QE 系统。将介绍三种主要方法：HTER、DA 和 MQM，每种方法都有其独特的优点和局限性，适用于不同的应用场景。最后，本节将讨论与这三种标注方法相关的难度级别。

#### II-B1 人类翻译错误率（HTER）

HTER 是一种用于根据后期编辑所需的工作量来标注翻译句子的常见方法。它建立在词级质量评估的基础上，并从其结果中计算得出。参考翻译的目标是在保持原意和语法正确性的同时进行尽可能少的修改。HTER 通过计算在后期编辑过程中所做的编辑（插入、删除和替换）的比例与后期编辑中的单词数量之比来为翻译句子打分，公式见于 ([1](https://arxiv.org/html/2403.14118v1#S2.E1 "1 ‣ II-B1 Human Translation Error Rate (HTER) ‣ II-B Annotation Methods ‣ II DATA, ANNOTATIONS METHODS, AND SHARED TASKS FOR QUALITY ESTIMATION ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation"))。在以往的研究中，HTER 被分析作为人类评估的替代品，一些研究 [Snover2005ASO] 推荐将其用作评估的黄金标准。然而，学术界对 HTER 作为替代品的适用性存在不同意见 [Graham2016IsAT]。

|  | $HTER=\frac{\#\text{ of edits}}{\#\text{ of words in the post-edition}}.$ |  | (1) |
| --- | --- | --- | --- |

#### II-B2 直接评估（DA）

DA 是一种广泛使用的人工评估方法，它提供主观质量评估，考虑了翻译输出的整体效果，并作为 HTER 的替代方法。在 DA 评估过程中，注释员直接在 0 到 100 的范围内对翻译质量进行评分。当将多个 DA 评分作为 QE 任务的目标时，这些评分通常会先进行归一化，然后使用归一化的平均值来表示机器翻译输出的质量评分。由于注释员个人偏好的影响，DA 评分容易出现不一致性。然而，已有解决方案提出以提高注释员之间的一致性 [graham-etal-2013-continuous, guzman-etal-2019-flores]。因此，DA 已确立为一种可靠的人工评估方法 [shapira2019crowdsourcing]，并在 QE 任务中广泛应用。一些人主张使用 DA 进行人工评估，而另一些人 [fomicheva2020mlqepe] 则认为 DA 和 HTER 提供了对机器翻译质量的不同视角。这两种观点都被认为是有效的。

#### II-B3 多维度质量指标 (MQM)

MQM [lommel2014multidimensional] 是一种创新且更为客观的注释方法，它结合了多个评估指标。它将机器翻译错误分为 7 个维度：术语、准确性、语言规范、风格、地域规范、受众适宜性和设计及标记。每个维度进一步细分为不同的错误类型，从而提供了更为精细的机器翻译质量评估。每个维度对应四个严重程度等级：无错误、轻微错误、重大错误和严重错误，并为每个等级设定了不同的扣分标准。注释员可以根据具体需求调整参数，并将 MQM 融入到特定场景中。根据机器翻译引发的错误类型进行扣分，最终的机器翻译评分是通过从满分中减去扣分来计算的。与 HTER 和 DA 相比，MQM 提供了更全面和客观的机器翻译质量评估。它提供了灵活性和个性化的评估，但需要具备领域知识的注释员和细致的参数设置。公式见于 ([2](https://arxiv.org/html/2403.14118v1#S2.E2 "2 ‣ II-B3 Multi-dimensional Quality Metrics (MQM) ‣ II-B Annotation Methods ‣ II DATA, ANNOTATIONS METHODS, AND SHARED TASKS FOR QUALITY ESTIMATION ‣ From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation"))，其中 $n_{\text{minor}}$、$n_{\text{major}}$、$n_{\text{critical}}$ 和 $n$ 分别对应轻微错误、重大错误、严重错误的计数和总词数。

|  | $MQM=1\textendash\frac{n_{\text{minor}}\textendash 5n_{\text{major}}\textendash 1% 0n_{\text{critical}}}{n}.$ |  | (2) |
| --- | --- | --- | --- |

#### II-B4 讨论难度

HTER 对注释员的语言技能和编辑专业知识要求很高，需要对源语言和目标语言的语言特征有深刻理解。其结果可能受到注释员编辑风格的影响，导致不同注释员之间存在不一致。DA 需要注释员直接打分，他们需要接受培训以确保评分标准的一致应用。MQM 对注释员的专业知识要求很高，注释员必须对错误类型有透彻了解并进行精确标注。总体而言，没有一种范式能完美解决 MTQE 中的固有权衡。持续的研究致力于标准化最佳实践，旨在结合这些指标的各自优势。

### II-C 共享任务

QE 共享任务旨在通过提供标准化的数据集和评估指标来推动 QE 领域的最新技术。这些任务涵盖不同级别的 QE，具有多样的目标。流行的 QE 共享任务可以分为单词级、句子级、文档级和可解释的 QE，每种任务都有其独特的目标、评估指标和理由。

#### II-C1 单词级质量评估共享任务

单词级质量评估（QE）的目标是将单词作为基本评估单位，自动识别每个单词在翻译句子中的位置是否正确，并检测任何翻译错误和遗漏现象，参考源句。此任务的输入包括源文本和机器翻译文本，而输出是一系列标记标签序列（包括源标签、MT 标签和空隙标签）。每个标签对应翻译句子中的每个单词或空隙，指示该位置是否存在错误。

在总结过去四年 WMT 的单词级质量评估共享任务后，我们将其分类为三种类型：分类、回归和细粒度错误跨度检测。分类任务涉及对源语言和目标语言的分类，进一步区分为单词分类和空隙分类；正确的翻译标记为 OK，而有错误的翻译标记为 BAD。回归任务使用半监督或无监督模型根据句子级别分数对单词进行评分，设置阈值，将高于阈值的单词标记为 OK，低于阈值的单词标记为 BAD。细粒度错误跨度检测是 WMT2023 QE 中引入的一项新任务¹¹1https://wmt-qe-task.github.io/subtasks/task2/，该任务将翻译单词分类为无错误、轻微错误和重大错误，并通过后处理链接同一类别内单词的索引来预测错误跨度。

单词级 QE 的主要评估指标是 Matthews 相关系数 (MCC) [lin2004automatic]，辅以 F1-score 作为次要指标。MCC 特别适用于二分类模型和分布不均的数据集。它用于测量错误翻译的单词与人工注释之间的相关性。

#### II-C2 句子级 QE 共享任务

句子级 QE 旨在预测每个 LP 的质量分数，表明翻译质量，类似于 ML 中的回归任务。它采用 HTER、DA 和 MQM [freitag2021experts] 等注释方法来评估翻译质量。WMT2021²²2https://www.statmt.org/wmt21/quality-estimation-task.html、WMT2022 和 WMT2023³³3https://wmt-qe-task.github.io/subtasks/task1/ 的句子级 QE 任务采用了 HTER、DA 和 MQM 注释。

句子级 QE 的主要评估指标是斯皮尔曼等级相关系数 (Spearman’s $\rho$) [lin2004automatic, specia2009estimating]，而皮尔逊相关系数和肯德尔相关系数则作为辅助评估指标。斯皮尔曼 $\rho$ 不依赖于翻译质量分数的正态性和方差齐性假设，对异常值的影响较小。因此，它更好地反映了 MT 模型预测的翻译质量与人工注释之间的相关性。

#### II-C3 文档级 QE 共享任务

相比于更精细的单词级和句子级 QE，文档级 QE 复杂得多，需要大量的数据资源。文档级 QE 的核心目标是对翻译文档进行 QE，其中“文档”通常指包含至少 3 个句子的文本，而不仅仅是单个文档。传统的 MT 任务通常将单个句子视为输入和翻译的基本单元，忽视了文档内句子之间的相互依赖。这种方法可能导致整个文档缺乏语义连贯性。自 2016 年发展以来，文档级 QE 任务主要集中在两种预测目标上。一种类型涉及使用两步 PE 方法计算质量分数，另一种类型涉及预测 MQM 分数以及单词级和句子级错误类型。

预测两个步骤的 PE 分数和 MQM 分数使用皮尔逊相关系数作为主要评估指标，同时采用平均绝对误差 (MAE) 和均方根误差 (RMSE) 作为辅助指标。另一方面，预测单词级错误类型使用 F1-score 作为评估指标。

#### II-C4 可解释的 QE 共享任务

在 QE 中，可解释性对于增强用户信任和促进错误分析非常重要。与专注于总体质量评分的句子级 QE 不同，可解释的 QE 主要关注翻译中的错误。本文将可解释的 QE 分为两种情况。第一种情况旨在预测句子级的二元评分，以指示翻译是否包含关键错误。这些错误主要由翻译错误、幻觉和从源句中删除的内容引起，可能在健康、安全、法律、声誉和宗教等领域导致误信息。根据这些评分，用户可以判断翻译中是否发生了关键错误。第二种情况提供句子级质量评分，以指示句子中是否存在翻译错误，但不识别具体哪些单词被翻译错误。这些评分帮助用户理解为什么一个句子可能被认为质量低下。

在可解释的 QE 中，Top K 召回率是主要的评估指标，它衡量模型在 MT 模型做出的前 K 个预测中检测和排名翻译错误单词的能力。曲线下面积 (AUC) 和平均精度作为辅助评估指标使用。

总结来说，QE 共享任务具有不同的目标，重点在于定义各个方面的质量指标。每个任务都配备了独特的评估指标来衡量模型性能。词级 QE 类似于分类任务，其中单词被标记为 OK 或 BAD。句子级 QE 类似于回归任务，旨在预测翻译句子的质量评分。文档级 QE 更为复杂，负责对整个翻译文档或包含多个句子的文本块进行评分。另一方面，可解释的 QE 主要关注翻译中的错误，而不是翻译的质量评分。它不仅识别出具体类型的错误，还根据句子给出的分数指出翻译错误存在的单词，但并不具体说明哪个单词是错误的。

## III 质量估计方法

本节回顾了在 QE 发展过程中出现的三种主要方法类别中的相关研究工作。它讨论了各类别中相应方法的优点和局限性，并对不同方法进行了简要比较。

### III-A 基于手工特征的质量估计

在 2009 年之前，QE 研究主要集中在使用手工特征 [blatz2004confidence, ueffing2005word, ueffing2007word] 为统计机器翻译（SMT）输出预测质量标签。随后，QE 研究的重点转向预测人工标注的质量评分。例如，QuEst [specia-etal-2013-quest] 框架利用特征提取模块从源文本和翻译文本中提取质量标签。这些特征随后被应用于 ML 算法来构建 QE 系统。de Souza 等 [de2014fbk] 使用监督树基集成学习方法在各种特征下预测 PE 工作量和时间，并使用 BLSTM-RNNs 预测词级标签。

QuEst++ [specia2015multi] 是 QuEst 的改进和扩展版本，新增了用于词级和文档级 QE 的特征提取模块。它将三个不同层次的预测整合到一个单一的工作流程中，促进了词级、句子级和文档级 QE 之间的交互。此外，QuEst++ 还融合了用于词级 QE 的序列标注学习算法。这个工具可以方便地扩展新特性，以满足不同文本层次的需求，具有很高的灵活性。

### III-B 深度学习基础的质量估计

自 2010 年代以来，深度学习技术已广泛应用于自然语言处理领域，并且从 2015 年左右开始，它们逐渐被集成到 QE 方法中。这些方法可以分为基于经典深度学习技术的和融入预训练语言模型的。

#### III-B1 经典深度学习方法

随着 QE 的进步，词嵌入的出现 [turian2010word, mikolov2013linguistic, mikolov2013efficient, pennington2014glove] 和神经机器翻译（NMT） [bahdanau2014neural, sutskever2014sequence] 技术使一些研究人员开始将神经网络应用于 QE 任务。从最初使用神经网络进行特征提取到完全基于神经网络的 QE 系统的出现，QE 系统的性能得到了极大的提升。

除了利用 QuEst 的手工特征外，SHAH 等人 [shah2015shef, shah2015investigating] 还使用了从 Word2Vec [mikolov2013linguistic, mikolov2013efficient] 嵌入中提取的额外词级别 QE 特征以及源语言和目标语言词之间的嵌入空间相似度。他们将从训练的连续空间模型生成的语言模型概率与这些手工特征结合用于句子级别的 QE。此外，Scarton 等人提出了词嵌入特征 [scarton2016word]、话语特征和从伪参考翻译中提取的特征 [scarton2015searching] 用于文档级别的 QE。受他们工作的启发，Chen 等人 [chen2017improving] 提出了使用句子嵌入特征和交叉熵特征来增强 QE 与人工评估的相关性，并研究了影响 QE 系统性能的几个因素。

随后，一些研究人员探索了仅使用神经网络进行特征提取和质量估计（QE）。QUETCH [kreutzer-etal-2015-quality] 是这种方法的早期示例，采用了预训练的词表示和深度神经网络（DNN）架构。QUETCH 包括一个输入层、查找表、多层感知器（MLP）和一个输出层。它通过固定大小的词窗口将双语上下文表示输入到 MLP，最终通过输出层完成词级别的 QE 任务。然而，其效果并未达到 QUETCH+ 的水平，后者集成了额外的基线特征。在 QUETCH 的基础上，Martins 等人 [martins-etal-2016-unbabels] 引入了一个 200 单元的双向门控循环单元（BiGRU）网络和堆叠的前馈神经网络，随后加入了源语言和目标语言的词性标记，以实现当时的最佳性能。类似于 QUETCH，Patel 等人 [patel2016translation] 从 DNN 转向 RNN，利用 LSTM 和 GRU 提取双语序列的表示，并引入了子标签来解决标签不平衡的问题。

虽然 QUETCH [kreutzer-etal-2015-quality] 方法完全依赖神经网络进行特征提取，但它需要双语对齐信息，这通常通过统计方法获得，容易出现显著的错误。随着深度学习技术的发展，QE 研究的趋势逐渐转向完全基于神经网络的方法。

在 2016 年，Kim 等人[kim-lee-2016-recurrent, kim2016recurrent]首次尝试使用 NMT 模型进行 QE，提出了首个纯神经网络方法用于句子级、词汇级和短语级 QE，无需手动提取特征。2017 年，Kim 等人[kim2017predictor]进行了更深入的研究，并将其命名为预测-估计器（PredEst）模型，这是一种解决昂贵 QE 标注和有限标注 QE 数据问题的方法。它由两个组件组成：预测器和估计器。预测器是一个使用平行语料库训练的神经词预测模型。它掩盖目标词，将源语言和损坏的目标语言输入到双向 RNN（Bi-RNN）中，并预测被掩盖词的概率分布。另一方面，估计器是一个在 QE 数据上训练的神经 QE 模型，提取 QE 特征向量（QEFVs），并在前馈网络上进行训练。QEFVs 通过 FNN、RNN 或 Bi-RNN 处理以获得隐藏表示，这些表示随后用于预测句子、短语或词汇级任务的质量标签。后来，为了有效训练模型，Kim 等人[kim-etal-2017-predictor]引入了堆叠传播和多级任务算法，以改进原始方法。在 2018 年，Ive 等人[ive2018deepquest]提出了 deepQuest 框架，用于句子级和文档级 QE，标志着首个纯神经网络文档级 QE 方法，首次尝试实验 SMT 和 NMT 的输出。经过测试，该框架证明了其速度更快、成本效益更高，并大大提高了文档级 QE 框架的性能。

Martins 等人[martins2017pushing, martins2017unbabel]在 WMT17 词汇级 QE 任务中引入了一个 STACKEDQE 系统，该系统将线性和神经系统堆叠在一起，然后将 APE 与词汇级 QE 结合创建了 APEQE 系统。最终，他们将这两个系统合并形成了针对词汇级 QE 的 FULLSTACKEDQE 系统，并将 FULLSTACKEDQE 扩展到句子级 QE。这些系统都取得了令人称赞的结果。在 Martins 等人[martins2017pushing, martins2017unbabel]的方法基础上，Hokamp 等人[hokamp2017ensembling]将被证明对词汇级 QE 有效的特征纳入了 NMT 系统的输入中，从而提出了 APE-QE 模型。这一统一的 APE 与词汇级 QE 模型在 APE 和 QE 任务中均取得了当时的最佳表现。

随着 Transformer [DBLP:journals/corr/VaswaniSPUJGKP17] 模型在 MT 领域取得显著成功，Fan、Wang 等人 [DBLP:journals/corr/abs-1807-09433, wang2018alibaba] 基于双向 Transformer 和包含词预测模块及 QE 模块的 PredEst 架构开发了一种双语专家模型。词预测模块利用从大规模平行语料库预训练中获得的先验知识和源语言与翻译之间的联合潜在表示来进行标记预测，提取出一组特征。随后，他们引入了测量双语专家获得的先验知识与 QE 数据集中目标之间差异的错配特征来训练 QE 模块，该模块使用双向 LSTM 模型，当时取得了 SOTA 性能。Wang 等人 [wang-etal-2020-hw-tscs] 采用了预训练的 Transformer 作为预测器，并集成了瓶颈适配器层（BAL）以实现高效的迁移学习，使用特定的分类器和回归器作为估计器。他们还使用统一模型进行了词级和句子级任务的联合训练，并提出了伪 PE 辅助 QE 方法。这展示了使用预训练 NMT 模型进行 QE 任务迁移学习的有效性。

然而，Cui 等人 [cui2021directqe] 认为 PredEst 框架中数据质量与训练目标之间的差距阻碍了其从平行语料库中获益。因此，他们提出了一个名为 DirectQE 的框架，该框架包括一个用于生成伪 QE 数据的生成器和一个用这些伪数据预训练的检测器。该框架允许使用大规模平行语料库进行预训练，并在真实 QE 数据上进行微调，从而解决了 PredEst 框架中固有的问题。

#### III-B2 引入预训练语言模型的方法

随着预训练语言模型如 ELMo [peters2018deep]、BERT [devlin2018bert]、XLM [lample2019cross] 和 XLM-R [conneau2019unsupervised, DBLP:journals/corr/abs-1911-02116] 的出现和发展，一些研究开始将预训练语言模型整合到 QE 模型中。这种整合使得从源文本和翻译文本中更好地提取质量向量，从而提升了 QE 系统的性能。

Kepler 等人 [kepler2019unbabel] 将 OpenKiwi [kepler2019openkiwi] 扩展为基于 Transformer 的 PredEst 模型，用预训练的 LMs BERT 和 XLM 替换了预测器，并提出了一种使用 POWELL 技术将词级别和句子级别预测结果结合的集成方法。此外，他们建议了一种简单的技术，将词标签转换为文档级预测。Wu 等人 [wu2020tencent] 在他们提交给 WMT20 的文献中，通过将基于 XLM 和 Transformer 的 PredEst 模型集成扩展了 OpenKiwi。前者预测器生成掩蔽和非掩蔽表示，而后者仅生成非掩蔽表示。估计器使用 LSTM 或 Transformer 进行训练，采用 top-K 和多头注意力策略来增强句子特征表示。Ranasinghe 等人 [DBLP:journals/corr/abs-2011-01536] 提出了 TransQuest，这是一种 PredEst 模型，旨在减少句子级 QE 对大规模平行语料库的依赖。TransQuest 不使用平行数据来预训练预测器，而是直接采用 SOTA 跨语言嵌入模型如 XLM-R [conneau2019unsupervised, DBLP:journals/corr/abs-1911-02116] 来编码源语言和目标语言句子。它由两个神经网络组成：MonoTransQuest (MTransQuest) 和 SiameseTransQuest (STransQuest)。MTransQuest 使用单个 XLM-R 模型来编码连接的源语言和目标语言句子，而 STransQuest 采用 Siamese 架构，使用分别针对源语言和翻译的 XLM-R 模型。这两个模型使用均方误差损失作为目标函数，并在特定的池化策略下表现出了改进的结果。Zerva 等人 [zerva2021unbabel] 使用了结合了适配器的预训练多语言编码器，在 OpenKiwi [kepler2019openkiwi] PredEst 上训练了多语言模型，并发现适配器调整可以抵抗过拟合。此外，他们还展示了整合不确定性信息和使用领域外数据进行预训练可以提升 QE 系统性能。

Zhou 等人 [zhou2019source] 主要研究了预训练翻译模型在 QE 中的应用，并比较了双语专家、ELMo 和 BERT 在 QE 任务中的有效性。Yankovskaya 等人 [yankovskaya2019quality] 对比了两种方法：一种仅使用 BERT 和 LASER [artetxe2019massively] 嵌入作为特征，另一种额外融入了 MT 系统的对数概率特征。他们的研究展示了 MT 系统对数概率的重要性。

2020 年，Rei 等人 [rei2020comet] 推出了 COMET，一个用于训练多语言和可适应 MT 评估模型的神经框架，通常用于基于参考的评估，以生成对人类判断的预测估计，如 HTER、DA 和 MQM。COMET 框架支持两种不同的架构：估计模型和翻译排序模型，二者都由跨语言编码器和池化层组成，其根本区别在于训练目标。估计模型是最常用的，它被训练以直接回归到质量分数，而翻译排序模型则训练以最小化“更好”假设与其对应的参考翻译和源语言之间的距离。

2022 年，Rei 等人 [rei2022cometkiwi] 通过将 COMET 与 OpenKiwi 的 PredEst 架构连接起来，并配备了词级序列标注器和解释提取器，从而结合了 COMET 和 OpenKiwi [kepler2019openkiwi] 的优势，形成了用于质量评估（QE）的 COMETKIWI。COMETKIWI 在带有 UniTE 模型 [wan2022unite] 提出的学习目标的指标数据上对模型进行了预训练，该学习目标将参考翻译纳入训练，作为数据增强的一种形式。此外，COMETKIWI 提出了使用注意力和梯度信息的可解释性方法，并通过 Head Mix 模块进一步优化了注意力头对预测的影响。COMETKIWI 还展示了少量样本学习的有效性，在仅有 500 个样本的情况下显著提高了模型性能。

### III-C 基于大型语言模型的质量评估

随着 LLM 的发展，越来越多的研究人员将注意力转向利用 LLM 进行质量评估。当前的方法大致可以分为五种类型，这些方法对质量评估的发展做出了重要贡献。

#### III-C1 基于 LLM 生成内容的直接预测

Kocmi 和 Federmann [kocmi2023large] 提出了 GEMBA，这是一种基于 GPT [brown2020language] 的翻译质量评估度量，通过单步提示并可应用于参考翻译场景以及 QE。他们评估了 9 种不同的 GPT 模型，并得出只有 GPT-3.5 及更大的模型能够执行 QE。GEMBA 关注零-shot 提示，作者使用了 4 种不同的提示模板来执行基于参考和非基于参考的翻译模式的质量评估。GEMBA 直接基于 LLMs 生成的内容预测分数，独立评估每个段落，然后平均所有段落的分数以获得最终的系统级分数，达到了系统级的 SOTA 性能，但在段落级分析上有所欠缺。为了提高 LLMs 在质量评估中的表现，陆等人 [lu2023error] 介绍了错误分析提示（EAPrompt），这是一种将 Chain-of-Thought（CoT）[wei2022chain] 与 EA [lu2022toward] 相结合的新提示方法。通过 ChatGPT，这种方法预测错误的程度和数量，并根据这些错误的严重性提供评分，生成类似 MQM 的评估。它在 CPT-3.5-turbo 上取得了比 GEMBA 更好的结果。杨等人 [yang2023knowledge] 介绍了知识提示估计器（KPE），这是一种 CoT 方法，结合了三种单步提示技术，利用 LLMs 预测流畅度、词级相似度 [zhang2023implicit] 和句子级相似度 [yang2023teachersim]，在段落级 QE 上表现更好。此外，KPE 在可解释性 [tao2022crossqe] 方面也展示了其优势。

#### III-C2 基于 LLMs 的生成概率

黄等人 [huang2023towards] 利用各种提示和示例在 GPT-3.5 界面中获取了某个源句子及其对应翻译句子的多个生成概率。然后，他们通过计算这些概率的均值和方差来评估翻译句子的质量，从而计算出更准确的不确定性测量。

#### III-C3 利用 LLMs 生成伪数据

许等人 [xu2023instructscore] 介绍了 INSTRUCTSCORE，这是一种无需人工注释评分的可解释文本生成度量方法，通过构建类似 MQM 的数据，利用 GPT-4 [openai2023gpt4] 提供的知识来训练 LLaMA 模型 [touvron2023llama]。此外，黄等人 [HUANG2024102022] 还利用 LLMs 破坏参考句子，随后从破坏后的句子中生成流畅的句子并输出，以获取有噪声的负面视角。由于这种方法不需要数据注释，因此具有较强的泛化能力。

#### III-C4 作为 QE 模型基础的 LLMs

Gladkoff 等人 [gladkoff2023predicting] 使用 OpenAI API 接口微调 LLMs，以评估翻译是否需要编辑。同样，Xu 等人 [xu2023instructscore] 如上所述，也利用 GPT-4 [openai2023gpt4] 生成的伪数据来训练 LLaMA 模型 [touvron2023llama]。

#### III-C5 基于检索的方法

这是一种辅助增强策略。黄等人 [huang2023towards, HUANG2024102022] 如前所述，使用 BM25 [robertson2009probabilistic] 检索类似的平行语料作为示例，以增强 LLMs 的翻译知识。

## IV 发现

根据我们对这些方法的观察，我们已经确定了当前 QE 面临的挑战和发展的以下发现：

+   •

    数据稀缺：手动标注的数据稀缺，特别是对于资源匮乏的语言。获取足够的标注数据涉及重大成本，这在很大程度上阻碍了 QE 研究的进展。

+   •

    解释性不足：早期的 QE 方法缺乏解释性，使得很难识别特定类型的错误及其位置。相比之下，LLMs 拥有强大的知识基础和学习能力。未来的研究应更多地关注利用 LLMs 来提升 QE 的解释性。

+   •

    单词级和文档级的 QE 方法较少。目前的 QE 方法主要集中在句子级，针对单词级和文档级 QE 的工作有限，特别是单词级方法数量较少且性能欠佳。然而，单词级 QE 能提取更细粒度的信息，未来研究应更多关注单词级 QE。

+   •

    预训练的 LMs 和 LLMs 需要大量的硬件资源。由于硬件资源不足，许多研究团队无法独立预训练 LMs，不得不依赖开源预训练 LMs，这阻碍了 QE 的发展。

+   •

    缺乏标准化评估指标：由于 QE 任务的主观性和对翻译质量的不同偏好，缺乏统一的评估指标使得比较和整合模型性能变得困难。

## V 结论

在过去的 20 年里，质量评估（QE）取得了显著进展。作为一种能够实时评估翻译文本质量的应用，无需参考翻译，QE 具有很强的实用性，并在推动机器翻译（MT）发展的过程中发挥了重要作用。本文对 QE 进行了全面的介绍和分析，提供了数据集、标注方法、共享任务和方法论的广泛概述。具体而言，本文介绍了词级、句级、文档级和可解释 QE 共享任务的具体概念和细节。它将 QE 演变过程中开发的方法分类为基于手工特征的方法、基于深度学习的方法以及利用大语言模型（LLMs）的方法，并进一步将基于深度学习的方法细分为经典深度学习方法和那些结合了预训练模型的方法。本文详细说明了每种方法的优缺点，并提供了不同方法的简单比较。最后，本文讨论了 QE 领域的当前挑战，并提出了未来的研究方向。

生成于 2024 年 3 月 21 日 04:01:42，由 [LATExml![[LOGO]](img/70e087b9e50c3aa663763c3075b0d6c5.png)](http://dlmf.nist.gov/LaTeXML/)
