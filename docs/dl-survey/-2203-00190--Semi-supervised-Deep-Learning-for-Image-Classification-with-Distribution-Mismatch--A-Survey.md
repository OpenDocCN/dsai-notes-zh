<!--yml

category: 未分类

日期：2024-09-06 19:47:45

-->

# [2203.00190] 半监督深度学习在图像分类中的分布不匹配：综述

> 来源：[`ar5iv.labs.arxiv.org/html/2203.00190`](https://ar5iv.labs.arxiv.org/html/2203.00190)

# 半监督深度学习在图像分类中的分布不匹配：综述

Saul Calderon-Ramirez, Shengxiang Yang 和 David Elizondo 手稿收到日期：2022 年 2 月 7 日。S. Calderon-Ramirez, S. Yang 和 D. Elizondo 现为英国莱斯特德蒙福特大学人工智能研究所（IAI）成员（电子邮件：sacalderon@itcr.ac.cr, syang@dmu.ac.uk, elizondo@dmu.ac.uk）。

###### Abstract

深度学习方法已被应用于多个不同领域，在图像识别应用中取得了显著成功，如材料质量控制、医学成像、自动驾驶等。深度学习模型依赖大量标注观察数据来训练一个潜在模型。这些模型由数百万个参数组成，需要更多的训练观察数据。收集标注数据通常成本较高，使得深度学习模型的使用并不理想，因为模型可能会对数据过拟合。在半监督设置中，未标注的数据用于提高模型在小规模标注数据集上的准确性和泛化能力。然而，在许多情况下，可能会有不同的未标注数据源。这增加了标注数据集与未标注数据集之间存在显著分布不匹配的风险。这种现象可能会对典型的半监督深度学习框架造成显著性能损失，因为这些框架通常假设标注和未标注数据集来自类似的分布。因此，本文研究了用于图像识别的半监督深度学习的最新方法。重点介绍了旨在处理标注和未标注数据集之间分布不匹配的半监督深度学习模型。我们讨论了开放挑战，旨在鼓励社区应对这些挑战，并克服传统深度学习流程在实际使用中的高数据需求。

影响声明：本文深入综述了最新的半监督深度学习方法，重点关注处理分布不匹配设置的方法。在实际使用场景中，可能会发生标注数据集与未标注数据集之间的分布不匹配。最近的研究发现，最新的半监督深度学习（SSDL）方法存在显著的性能下降。因此，最新的方法旨在提高半监督深度学习框架对这种现象的鲁棒性。在这项工作中，我们是首个系统化和研究在分布不匹配场景下的鲁棒 SSDL 方法的研究者。我们认为这项工作可以为该领域的文献增添价值，因为它识别了相关的主要趋势。我们还认为，我们的工作鼓励社区关注这一新兴主题，这是一项重要的挑战，需要解决，以缩小深度学习方法在实验室与实际应用之间的差距。

###### 关键词：

深度学习、图像分类、半监督学习、分布不匹配

## I 引言

基于深度学习的方法在从医学到生物多样性保护等广泛领域继续提供更准确的结果[10, 33, 14, 69, 97, 7, 62, 17, 12]。大多数深度学习架构依赖于使用广泛标注的数据集来训练具有数百万个参数的模型[35, 16, 13]。当使用小型或不具代表性的数据集训练深度学习解决方案时，过拟合是一个常见问题。这种现象通常会导致在实际使用中表现不佳。尽管存在这种风险，通过严格的程序和标准获取足够大且具代表性的样本仍然是一个悬而未决的挑战，如[5]所述。此外，如何确定数据集是否足够大和/或具代表性仍然是文献中的一个开放问题，如[58]所讨论。

标签的生成往往成本高昂，尤其是在由高度训练的医学专业人员，如放射科医生、病理学家或心理学家，开发的领域中[17, 30, 10, 42]。例如，组织病理学图像的标注是训练深度学习模型以用于临床程序所必需的[17]。因此，对于处理稀缺标注数据以喂养深度学习架构的兴趣日益增加，这一趋势受到基于深度学习模型成功的刺激[63]。

处理有限标注观测数据和减少模型过拟合的最流行和简单的方法之一是数据增强。数据增强通过对真实数据样本进行简单的变换，如图像旋转、翻转和添加人工噪声[35]，向训练数据集中添加人工观测数据。关于深度学习架构的数据增强的简单程序描述可以参见[96]。更复杂的数据增强技术利用生成对抗网络。生成模型近似数据分布，可以对其进行采样以创建新观测数据，如[78, 102, 32] 中不同应用所示。数据增强在流行的深度学习框架中实现，如 *Pytorch* 和 *TensorFlow* [64]。

迁移学习也是处理标签不足的常见方法。它首先使用外部或源标签数据集训练模型 $f$，理想情况下该数据集来自类似的领域。其次，用目标数据集对参数进行微调[88]。类似于数据增强，*TensorFlow* 和 *Pytorch* 包含了在通用数据集如 ImageNet [27] 上训练的广泛使用的深度学习模型的权重，使其应用非常广泛。其实现效果更佳时，源数据集和目标数据集越相似。有关深度迁移学习的详细回顾可以参见[84]。

另一种处理小规模标注数据集的替代方法是半监督深度学习（SSDL），它使模型能够利用未标注或甚至是噪声标注的数据[94, 47]。以训练基于面部的表情识别模型为例。网络上可以获取到人脸的未标注视频和图像，并可以通过网络爬虫获取。利用这些未标注的信息可能会提高深度学习模型的准确性和泛化能力。

文献中关于半监督学习的最早工作之一是[76]；其中提出了使用未标记数据的不同方法。近年来，随着深度学习架构的不断发展和使用，半监督学习方法正吸引越来越多的关注。许多 SSDL 框架足够通用，可以在不同应用领域中使用流行的深度学习架构[63]。因此，我们认为有必要回顾和研究近期基于深度学习的半监督技术之间的关系，以发现缺失的环节并推动该领域的研究。文献中已经有一些最近的半监督学习综述。这些综述在 I-A 部分中详细介绍。此外，我们认为讨论在实际环境中实施 SSDL 的开放挑战也很重要，以缩小实验室与应用之间的差距。一个剩余的挑战是标记数据和未标记数据之间的频繁分布不匹配，这可能会阻碍 SSDL 框架的性能。

### I-A 之前的工作

在[101]中，开发了一项关于机器学习的半监督方法的广泛综述。作者定义了以下半监督方法：自我训练、共同训练和基于图的方法。然而，在调查时，深度学习概念并不流行，因为自编码器和生成对抗网络的使用较少，主要由于其高计算成本和随之而来的不实用性。

随后，在[66]中开发了一项半监督学习方法的综述。在这项工作中，作者列出了自我训练、共同训练、传导支持向量机、多视角学习和生成判别方法。然而，到那时深度学习架构尚不流行。因此，相关工作回顾了基于更传统机器学习方法的半监督架构。

在[67]中开发了一项关于图像分析和自然语言处理的半监督学习简要调查。该研究定义了以下半监督学习方法：生成模型、自我训练、共同训练、多视角学习和基于图的方法。然而，该综述并未关注深度半监督学习方法。

关于医学影像的半监督学习的最新调查可以在[21]中找到，其中列出了不同的机器学习方法。作者区分了自我训练、基于图的方法、共同训练和流形正则化方法。由于其实现的简单性，作者发现基于迁移学习的医学影像解决方案比半监督学习更多。

在[63]中，作者实验了一些最近的 SSDL 架构，并进行了简要的综述。作者认为，半监督技术的典型测试不足以衡量其在实际应用中的性能。例如，常见的半监督学习基准不包括来自未标记数据集中定义之外类别的观察。这被称为干扰类别或集体异常值[79]。作者还强调了半监督学习管道与其他类型学习（即迁移学习）的互动测试缺乏。

最近，在[92]中，作者对不同的半监督学习框架进行了广泛的回顾，主要针对深度学习架构。开发了一个围绕大多数 SSDL（低密度/聚类和流形假设）的关键假设的详细概念框架。提出的半监督方法的分类包括两个主要类别：归纳和推断方法。归纳方法建立一个可以用于输入空间中新点的数学模型或函数，而推断方法则不建立。根据作者的说法，文献中可以找到显著更多的半监督归纳方法。这些方法可以进一步分为：无监督预处理、包装型和内在半监督方法[92]。作者提到[63]中提出的半监督学习的分布不匹配挑战。然而，他们的综述中没有关注这一主题的技术。

在[74]中，开发了一个关于图像分类的半监督、自监督和无监督学习方法的综述。作者关注于这些方法中使用的共同概念（大多数基于深度学习架构）。例如，预任务或代理任务学习、数据增强、对比优化等概念被描述为这三种学习方法中的共同理念。文中包含了一组有用的表格，描述了不同的半监督学习方法及其共同概念。在回顾了最近半监督方法的结果后，作者总结道，其中少数方法包含了更接近实际世界的基准（高分辨率图像，每个类别具有相似特征）。此外，实际世界设置，如类别不平衡和标签噪声，通常被忽略。

我们认为，关于 SSDL 的详细调查仍然缺失，因为 SSDL 论文中包含的常见简短评论通常关注于其最相关的工作。我们发现的最新半监督学习调查已经过时，并且没有关注基于深度学习的方法。我们认为，近期的 SSDL 方法为半监督学习框架提供了新的视角。然而，更重要的是，为了缩小实验室到应用的差距，有必要充分研究当前在解决这些挑战方面的最新进展。在 SSDL 的背景下，我们认为，提高 SSDL 方法对标记数据集和未标记数据集之间分布不匹配的鲁棒性是关键。因此，本综述集中讨论了标记数据集和未标记数据集之间的分布不匹配问题。

在节 I-B 中，对半监督学习的主要思想进行了回顾。基于前两节的概念，在节 II 中，我们回顾了 SSDL 的主要方法。随后，我们讨论了文献中已开发的不同方法，这些方法在面对$S^{(u)}$和$S^{(l)}$之间的分布不匹配时的表现。最后，我们在节 IV 中讨论了 SSDL 在分布不匹配条件下的待解决挑战。

### I-B 半监督学习

在本节中，我们描述了分析 SSDL 的关键术语。我们的术语基于在[4]中开发的半监督学习分析框架。该框架扩展了在[90]中提出的学习框架，作为一个机器学习理论框架。

如果模型 $f_{\textbf{w}}$ 是半监督的，则它是使用一组标记观察 $S^{(l)}$ 和一组未标记观察 $S^{(u)}=\left\{\mathbf{x}_{n_{1}},\mathbf{x}_{n_{2}},\ldots,\mathbf{x}_{n_{u}}\right\},$ 以及总观察数 $n=n_{l}+n_{u}$ 进行训练的。通常，未标记观察 $n_{u}$ 的数量远高于标记观察的数量。这使得 $n_{u}\gg n_{l}$，因为在不同领域中获取标签的成本很高。如果模型 $f_{\textbf{w}}$ 对应于深度神经网络（DNN），我们称之为半监督深度学习（SSDL）。深度模型 $f_{\textbf{w}}$ 通常被称为骨干模型。在半监督学习中，从未标记数据集 $S^{(u)}$ 中提取附加信息。因此，训练深度模型可以扩展到 $f_{\mathbf{w}}=T\left(S^{(l)},S^{(u)},f_{\mathbf{w}}\right)$。估计的假设应该比仅使用标记数据 $S^{(l)}$ 更准确地对测试数据 $\mathbf{x}\in S^{(t)}$ 进行分类。

图 1：半监督设置，圆圈代表未标记的观察 $S^{(u)}$，填充形状对应于 $K=2$ 类的标记观察 $S^{(l)}$，黄色圆圈对应于未标记的观察或干扰类的成员。

图 1 描绘了一个在 $d=2$ 维度中观察的半监督设置。标签也可以对应于数组 $\mathbf{y}_{i}\in\mathbb{R}^{k}$，如果使用 $1-K$ 编码（独热向量）来对 $K$ 类的观察进行分类，或 $y_{i}\in\mathbb{R}$ 用于回归。更具体地说，标记和未标记数据集的观察都属于观察空间 $\mathbf{x}_{i}\in\mathcal{X}$，标签位于标签空间 $\mathcal{Y}$ 中。例如，对于具有 $d$ 像素的手写数字的二值图像，其观察空间 $\mathcal{X}\in\{0,1\}^{d}$，其标签集为 $\mathcal{Y}=\left\{0,1,\ldots,9\right\}$。

概念类 $\mathcal{C}_{k}$ 对应于特定类别 $k$ 中数组 $\mathbf{x}_{i}\in\mathbb{R}^{d}$ 中所有有效值的组合。例如，对于数字 $1$，属于类别 $k$ 的所有可能观察的子集属于概念 $\mathcal{C}_{k}$。概念类模型表示所有可能的数字 $1$ 的图像。在这种情况下 $\mathbf{x}_{i}\in\mathcal{C}_{k=1}$。概念类 $\mathcal{C}=\left\{\mathcal{C}_{1},\ldots,\mathcal{C}_{k}\right\}$ 包含了给定问题领域中所有现有类别的所有可能观察。

从数据分布的角度来看，通常情况下概念类别的总体密度函数 $p_{\mathbf{x}\sim\mathcal{C}}\left(\mathbf{x}\right)=p\left(\mathbf{x}|y=1,\ldots,K\right)$ 以及每个概念的密度函数 $p_{\mathbf{x}\sim\mathcal{C}_{k}}\left(\mathbf{x}\right)=p\left(\mathbf{x}|y=k\right)$ 都是未知的。大多数半监督方法假设 $S^{(u)}$ 和有标签数据 $S^{(l)}$ 都采样自概念类别密度，使得 $p_{\mathbf{x}\sim S^{(l)}}\left(\mathbf{x}\right)$ 和 $p_{\mathbf{x}\sim S^{(u)}}\left(\mathbf{x}\right)$ 非常相似 [92]。标记的数据集 $S^{(l)}$ 和未标记的数据集 $S^{(u)}$ 被认为是独立同分布采样的，如果密度函数 $p_{\mathbf{x}\sim S^{(u)}}$ 和 $p_{\mathbf{x}\sim S^{(l)}}$ 是相同且统计独立的。

然而，现实世界的设置可能面临不同的违反独立同分布（IID）假设。例如，未标记的数据很可能包含不属于 $K$ 个类别之一的观测。从理论上讲，这可能导致从 $p_{\mathbf{x}\sim\mathcal{C}}\left(\mathbf{x}\right)$ 不同的采样密度函数。这些观测属于干扰类别数据集 $\mathbf{x}\in\mathcal{D}$，并且是从干扰类别的理论分布 $p_{\mathbf{x}\sim\mathcal{D}}\left(\mathbf{x}\right)$ 中抽取的。图 1 展示了从干扰分布 $p_{\mathbf{x}\sim\mathcal{D}}\left(\mathbf{x}\right)$ 抽取的干扰观测。

如果从与概念类别不同的分布中抽取的未标记观测 ${S^{(u)}}_{D}$ 被称为干扰类别，则干扰类别通常在语义上与概念类别有所不同。

在现实世界的情况下，可能会面临多种导致 $S^{(u)}$ 和 $S^{(l)}$ 违反独立同分布（IID）假设的原因。以下列出了这些原因，并且可以在不同程度上找到 [45]：

+   •

    先验概率偏移：数据集 $S^{(l)}$ 的标签分布可能与 $S^{(u)}$ 不同。一个特殊的例子是标记数据集 $S^{(l)}$ 的标签不平衡和一个平衡的未标记数据集。

+   •

    协变量偏移：数据集 $S^{(l)}$ 和数据集 $S^{(u)}$ 之间的特征分布可能存在差异，尽管两者都具有相同的类别，在采样时可能导致分布不匹配。例如，在医学成像应用中，这可能与 $S^{(l)}$ 和 $S^{(u)}$ 之间抽样特征分布的差异有关。这可能是由于患者样本的差异引起的。

+   •

    概念漂移：这与 $S^{(l)}$ 中标签的变化相关，相对于具有相同特征的 $S^{(u)}$ 数据。例如，在医学影像领域，不同的从业者可能将相同的 x 光图像分类为不同的类别。这与噪声标签的问题密切相关 [31]。

+   •

    未见类别：数据集 $S^{(u)}$ 包含了在数据集 $S^{(l)}$ 中未见或未表示的类别的观察值。未标记数据集中采样了一个或多个干扰类。因此，存在标签数量的不匹配，以及先验概率偏移和特征分布不匹配。

图 1 说明了一个分布不匹配的设置。圆圈对应于未标记的数据，方块和菱形对应于标记的数据集。这两个类别的标记和未标记数据明显不平衡，并且样本具有不同的特征值。在这种情况下，所有的蓝色未标记观察值都来自概念类别。然而，黄色未标记观察值可以被认为具有不同的特征值分布。许多 SSDL 方法利用了簇状数据/低密度分离假设以及流形假设 [70]。

## II 半监督深度学习

在这一部分，我们研究了最近的半监督深度学习架构。它们被分为不同的类别。这样的分类旨在简化分析。然而，每个类别并不是彼此排斥的，因为有几个方法混合了两个或更多类别的概念。这为理解当前 SSDL 方法处理 $S^{(u)}$ 和 $S^{(l)}$ 之间的分布不匹配提供了背景。

### II-A 半监督深度学习的预训练

利用未标记数据集 $S^{(u)}$ 信息的一种基本方法是，首先对分类器 $f_{\textbf{w}}$ 进行无监督预训练。在本文中，我们称之为预训练的半监督深度学习（PT-SSDL）。实施 PT-SSDL 的一种直接方法是，预训练模型的编码部分 $h_{\textbf{w}_{\textrm{FE}}}^{\left(\textrm{FE}\right)}\left(\textbf{x}_{i}\right)$，以优化 *代理* 或 *预设 [89]* 任务 $\delta$。代理任务不需要具体标签，允许使用未标记数据。在训练过程中最小化代理损失，从而实现未标记数据的使用。

|  | $\mathcal{\>L}_{u}^{\left(p\right)}\left(S^{(u)},\textbf{w}_{\textrm{FE}}\right)=\>\sum_{\textbf{x}_{i}\in S^{(u)}}\delta\left(r_{i},f_{\textrm{proxy}}\left(f_{\textbf{w}_{\textrm{FE}}}\left(\Psi^{\eta}\left(\textbf{x}_{i}\right)\right)\right)\right),$ |  | (1) |
| --- | --- | --- | --- |

其中函数 $\delta$ 比较代理标签 $r_{i}$ 与代理模型 $f_{\textrm{proxy}}$ 的输出。代理任务也可以使用标记数据进行优化。优化代理任务的过程也称为自监督 [44]。这可以在预训练步骤或训练过程中完成，如在具有无监督正则化的模型中所见。对于这种*代理*或*辅助*损失，一种简单的方法是最小化无监督重建误差。这类似于一致性函数 $\delta$ 的使用，其中代理任务对应于重建输入，使得 $\delta\left(\textbf{x}_{i},h_{\textbf{w}_{\textrm{DE}}}^{\textrm{(DE)}}\left(h_{\textbf{w}_{\textrm{FE}}}^{\left(\textrm{FE}\right)}\left(\textbf{x}_{i}\right)\right)\right)$。使用基于自动编码器的重建意味着通常需要添加一个解码器路径 $h_{\textbf{w}_{\textrm{DE}}}^{\textrm{(DE)}}$，在评估时将其丢弃。预训练可以针对整个模型进行，或者逐层进行，如 [6] 中最初探讨的那样。此外，预训练可以很容易地与其他半监督技术结合，如 [50] 中所见。

在 [28] 中，一个卷积神经网络（CNN）通过来自未标记数据的图像补丁进行预训练，代理任务是预测新第二个补丁的位置。该方法在物体检测基准中进行了测试。在 [18] 中，提出了一种无监督预训练方法。它实现了代理任务优化，随后进行聚类步骤，均使用未标记数据。代理任务包括未标记数据的随机旋转以及其旋转的预测。所提方法在使用 PASCAL Visual Object Classes 2007 数据集的其他无监督预训练方法中进行了测试。

代理或辅助任务在 SSDL 中以不同方式实现，因为它并不限于预训练方法。这可以在基于一致性的正则化技术中看到，后者将在本工作中进一步讨论。例如，在 [98] 中，添加了一组广泛的代理任务作为无监督正则化项，并与一些流行的正则化 SSDL 方法进行了比较。作者使用了 ImageNet Large Scale Visual Recognition Challenge（ILSVRC）进行执行基准测试。所提方法显示出略微的准确性提升，但与其他两种基于无监督正则化的方法相比，统计学上并不显著。

### II-B 伪标签半监督深度学习

在伪标签半监督深度学习（PLT-SSDL），也称为自训练、自教学或引导训练中，伪标签被估计用于未标记数据，并用于模型微调。基于伪标签的训练的直接方法可以在 [4] 中找到，其中涉及两个模型的共同训练。

在协同训练中，使用两个或更多不同的输入维度或视图来训练两个或更多不同的模型。这些视图可以仅仅是拆分原始输入数组$\textbf{x}_{i}$的结果。例如，在两个视图$v_{1}$和$v_{2}$的协同训练[4]中，使用了两个标记数据集$S^{\left(l,v_{1}\right)}$和$S^{\left(l,v_{2}\right)}$。在初始迭代$i=1$中，使用标记数据集训练两个模型，得到两个视图模型$\widetilde{\textbf{w}}_{i}^{\left(v_{1}\right)}=T\left(f_{\textbf{w}},S^{\left(l,v_{1}\right)}\right)$和$\widetilde{\textbf{w}}_{i}^{\left(v_{1}\right)}=T\left(f_{\textbf{w}},S^{\left(l,v_{2}\right)}\right)$。这可以视为预训练步骤。得到的模型可以被称为模型集成$\textbf{f}_{\widetilde{\textbf{w}}_{1}}=\left[f_{\widetilde{\textbf{w}}_{1}^{\left(v_{2}\right)}},f_{\widetilde{\textbf{w}}_{2}^{\left(v_{2}\right)}}\right]$。

作为第二步，使用不一致概率$\mathbf{Pr}_{\textbf{x}_{i}\sim S^{(u)}}\left[f_{\widetilde{\textbf{w}}_{1}^{\left(v_{2}\right)}}\left(\textbf{x}_{j}\right)\neq f_{\widetilde{\textbf{w}}_{2}^{\left(v_{2}\right)}}\left(\textbf{x}_{j}\right)\right]$，其中$\textbf{x}_{j}\in S^{(u)}$，来估计新的标签或伪标签$\widehat{y}_{j}^{(i,k)}=f_{\widetilde{\textbf{w}}_{i}^{\left(v_{k}\right)}}\left(\textbf{x}_{j}\right)$。每个观察值$\textbf{x}_{j}$的最终伪标签可以是应用视图汇总操作$\mu$（如平均或取最大 logits）的结果，使得$\widehat{y}_{j}^{(i)}=\mu\left(\textbf{f}_{\textbf{w}_{i}}\left(\textbf{x}_{j}\right)\right)$。

迭代$i$的伪标签集合可以表示为$\widehat{S}_{i}=\mu\left(\textbf{f}_{\textbf{w}_{i}}\left(S^{(u)}\right)\right)$。在协同训练[4]中，两个模型的同意观察被挑选出来，函数为$\widetilde{S}_{i}=\varphi\left(\widehat{S}_{i}\right)$，作为高置信度观察。具有高置信度的伪标签数据被包含在标记数据集$S_{i+1}^{\left(r\right)}=S^{(l)}\bigcup\widetilde{S}_{i}$中作为伪标签观察。之后，模型会在$i=2,..,\vartheta$迭代中重新训练，重复伪标记过程，筛选出最有信心的伪标签并重新训练模型。一般来说，我们将伪标记指代为估计硬标签$\widehat{y}_{j}^{(i)}$的思想。

在[29]中提出了 Tri-net 半监督深度模型（Tri-Net）。这里训练了一个由深度卷积神经网络（DCNN）组成的集成$\textbf{f}_{\textbf{w}}$，使用$k=1,2,3$不同的顶级模型，以及$k=1,2,3$不同的标记数据集$S_{i}^{(l,k)}$。输出的后验概率是三个模型投票的结果。这导致了对整个评估数据集的伪标记$\widetilde{S}_{i}$，其中$i=1$表示第一次迭代。伪标签过滤操作$\varphi$包括至少两个模型一致的观测结果，并将其包含到标记数据集中。该过程重复进行固定次数的迭代。Tri-Net 还可以与任何正则化的 SSDL 方法结合。这种组合在[82]中进行了测试，并在本文档中称为具有 Pi-Model 正则化的 Tri-net 半监督深度模型（TriNet+Pi）。在[82]中，发现了类似的基于集成的伪标签方法。在该工作中，实现了一个乳腺 X 光图像分类器，使用一个投票的分类器集成来处理未标记的观测结果。具有最高置信度的观测结果被迭代地添加到数据集中。

另一种近期的深度自训练方法可以在[23]中找到，称为半监督学习模型的速度监督（SaaSM）。在第一步中，通过测量训练周期中的学习速度来估计伪标签，利用随机梯度下降方法优化估计标签作为概率密度函数$\widetilde{S}_{1}=f_{\textbf{w}_{1}}\left(S^{(u)}\right)$。估计标签用于优化无监督正则化损失。SaaSM 使用加拿大高级研究院的 10 类数据集（CIFAR-10）和街景房屋号码数据集（SVHN）进行了测试。根据报告的结果，其准确率略高于其他一致性正则化方法，如均值教师。没有进行统计显著性分析。

### II-C 正则化半监督学习

在正则化半监督深度学习（R-SSDL）中，或如[101]所定义的共同正则化学习中，深度学习模型$f_{\textbf{w}}$的损失函数包括一个使用未标记数据$S^{(u)}$的正则化项：

|  | $\overset{\underset{\textbf{w}}{\textrm{argmin}}\mathcal{L}\left(S,f_{\textbf{w}}\right)=}{\underset{\textbf{w}}{\textrm{argmin}}\sum_{\left(\textbf{x}_{i},y_{i}\right)\in S^{(l)}}\mathcal{L}_{l}\left(f_{\textbf{w}}\left(\textbf{x}_{i}\right),y_{i}\right)+\gamma\sum_{\textbf{x}_{j}\in S^{(u)}}\mathcal{L}_{u}\left(f_{\textbf{w}},\textbf{x}_{i}\right)}.$ |  | (2) |
| --- | --- | --- | --- |

无监督损失 $\mathcal{L}_{u}$ 使用未标记的观测 $\textbf{x}_{j}$ 对模型 $f_{\textbf{w}}$ 进行正则化。无监督正则化系数 $\gamma$ 控制模型训练过程中的无监督正则化影响。我们将其视为 SSDL 的一个子类别，因为有许多方法受到了这一思想的启发。文献中可以找到不同的实现无监督损失函数 $\mathcal{L}_{u}$ 的方法。章节 II-C1、II-C2 和 II-C3 汇总了实现该方法的最常见的方法。

#### II-C1 基于一致性的正则化

一致性正则化的半监督深度学习 (RC-SSDL) 损失函数测量了模型在对 $S^{(u)}$ 中未标记观测进行分类时的*鲁棒性*，其中对未标记数据应用了不同的变换。这些变换通常会扰动未标记数据而不改变其语义和类别标签（标签保持变换）。例如，在 [4] 中，一致性假设 $\chi^{\textrm{(CL)}}$ 是通过使用欧几里得距离在 [4] 中对两个视图进行强制的：$\delta\left(\textbf{x}_{j},f_{\textbf{w}}\right)=\left\|f_{\textbf{w}^{\prime}}\left(\Psi^{\eta^{\prime}}\left(\textbf{x}_{j}\right)\right)-f_{\textbf{w}}\left(\Psi^{\eta}\left(\textbf{x}_{j}\right)\right)\right\|.$

其中 $\delta\left(\textbf{x}_{i},f_{\textbf{w}}\right)$ 是一致性函数。一致性也可以在 $\textbf{x}_{j}\in S^{(l)}$ 的标记观测上进行测量。一些 SSDL 技术基于一致性正则化。因此，我们将这一类别称为基于一致性的正则化半监督深度学习 (CR-SSDL)。

一致性正则化项的简单解释是通过使用 $S^{(u)}$ 中的数据来提高模型对噪声的鲁棒性。对于损坏观察的一致模型输出意味着模型更鲁棒，具有更好的泛化能力。一致性可以在两个深度学习模型 $f_{\textbf{w}^{\prime}}$ 和 $f_{\textbf{w}}$ 之间测量，这两个模型分别接受两个不同视图或相同观察的随机修改 $\Psi^{\eta^{\prime}}\left(\textbf{x}_{j}\right)$ 和 $\Psi^{\eta}\left(\textbf{x}_{j}\right)$。因此，一些作者将基于一致性的 SSDL 方法称为自集成学习模型[55]。通过评估模型的两个或更多变体的一致性，来测量整体模型的鲁棒性。

一致性正则化方法基于一致性假设 $\chi^{(\textrm{CL})}$。因此，这些方法可以与其他以前的 SSDL 方法相关联，这些方法也利用了这一假设。例如，如前所述，一致性假设也在 PT-SSDL 中作为代理任务实现，在该任务中，模型被预训练以最小化代理函数。一致性函数可以被认为是前述自训练置信度函数 $\varphi$ 的特定情况，使用两个或更多观察视图，如在[4]中所述。然而，在这种情况下，观察 $\textbf{x}_{j}$ 的不同损坏视图高度相关，尽管存在于[4]中开发的原始共同训练方法中。尽管如此，最近的正则化 SSDL 模型[3, 86, 49]简化了这一假设。它们将观察 $\textbf{x}_{j}$ 的视图视为其与随机噪声 $\eta$ 的损坏，形成一个损坏视图 $\Psi^{\eta}\left(\textbf{x}_{j}\right)$。当测量不同信号源之间的一致性时，[4]中对共同训练视图之间独立性假设的拟合更好，如[56]中所见。在这项工作中，使用了不同的数据源进行半监督的人体活动识别。

在[3]中提出了 Pi 模型（Pi-M）。评估了将随机噪声注入其权重（通常称为丢弃）的深度模型的一致性。权重 $\textbf{w}^{\prime}$ 是父模型权重 w 的损坏版本，形成了作者所称的伪集成。Pi-M 模型在[86]中使用 CIFAR-10 和 SVHN 数据集进行了测试。交叉的 Pi-M 结果与本文讨论的其他方法的结果可以在表 I 中找到。

可以对未标记和标记的数据集进行一致性评估，如[72] 中提出的，在互斥-变换模型（METM）中。在这种方法中，提出了变换监督（TS）的无监督损失项：$\mathcal{L}_{u}^{\left(\textrm{TS}\right)}\left(f_{\textbf{w}},\textbf{x}_{i}\right)=\sum_{j}^{M}\sum_{k}^{M}\left\|f_{\textbf{w}}\left(\Psi_{j}\left(\textbf{x}_{i}\right)\right)-f_{\textbf{w}}\left(\Psi_{k}\left(\textbf{x}_{i}\right)\right)\right\|^{2},$ 其中 $M$ 次随机变换 $\Psi$ 作用于观测值 $\textbf{x}_{i}$。这可以用于无监督预训练。这种损失项可以视为一致性测量。此外，使用了基于互斥性（ME）的损失函数。它鼓励模型的预测不重叠。ME 损失项表示为 $\mathcal{L}_{u}^{\left(\textrm{ME}\right)}=\left\|-\prod_{k}^{K}f\left(\textbf{x}_{i}\right)\prod_{k}^{K}\left(1-f_{\textbf{w}}\left(\textbf{x}_{i}\right)\right)\right\|^{2}$。最终的无监督损失实现为 $\mathcal{L}_{u}=\lambda_{1}\mathcal{L}_{u}^{\left(\textrm{ME}\right)}+\lambda_{2}\mathcal{L}_{u}^{\left(\textrm{TS}\right)}$，其中 $\lambda_{1}$ 和 $\lambda_{2}$ 为每个无监督损失项的权重系数。METM 在 SVHN 和 CIFAR-10 数据集上进行了测试。表 I 中显示了与本文所评审的其他方法相当的结果。

后来，[49] 的作者提出了时间集合模型（TEM），该模型计算经过训练的模型与不同模型在每个训练周期 $\tau$ 的移动加权平均预测的一致性。

|  | $f_{\textbf{w}^{\prime}_{\tau}}\left(\Psi^{\eta}\left(\textbf{x}_{i}\right)\right)=(1-\rho)f_{\textbf{w}_{\tau}}\left(\Psi^{\eta}\left(\textbf{x}_{i}\right)\right)+\rho f_{\textbf{w}_{\tau-1}}\left(\Psi^{\eta}\left(\textbf{x}_{i}\right)\right),$ |  | (3) |
| --- | --- | --- | --- |

其中 $\rho$ 是衰减参数，$\tau$ 是当前的训练周期。时间集成评估了时间平均模型的输出与嘈杂观测值 $\Psi^{\eta}\left(\textbf{x}_{i}\right)$ 的一致性。这强制模型的时间一致性。表格 I 显示了 TEM 方法在 CIFAR-10 数据集上的结果。基于这种方法，作者在 [85] 中开发了一种基于 Kullback-Leibler 交叉熵来测量模型一致性的 SSDL 方法。对输入观测值 $\textbf{x}_{j}$ 应用不同的转换 $\Psi^{\eta}$。这些转换包括图像翻转、随机对比度调整、旋转和裁剪。该方法在实际场景中使用超声胎儿图像进行解剖分类进行了评估。

[86] 的作者提出了时间集成思想的扩展，即流行的均值教师模型（MTM）。作者没有对过去周期中计算的模型进行平均预测，而是实现了指数加权平均：$\textbf{w}^{\prime}_{\tau}=\rho\textbf{w}^{\prime}_{\tau-1}+\left(1-\rho\right)\textbf{w}^{\prime}_{\tau}$，其中 $\tau$ 是训练周期，$\rho$ 是指数加权系数。具有参数 $\textbf{w}^{\prime}$ 的这种指数平均模型被作者称为教师模型。为了比较目的，MTM 在 CIFAR-10 数据集上的结果如表格 I 所示。

最近，作者在 [59] 中提出了虚拟对抗训练模型（VATM）。他们实现了一个生成对抗网络，将对抗扰动 $\eta$ 注入到标记和未标记的观测数据中。将人工生成的观测数据与原始未标记数据进行比较。这会产生对抗噪声，促使模型在一致性方面变得更加具有挑战性。此外，作者还添加了条件熵项，以使模型在最小化时更具信心。我们将这种变体称为具有熵最小化的虚拟对抗训练（VATM+EM）。VATM 和 VATM+EM 都在 CIFAR-10 数据集上进行了测试，因此我们在表格 I 中包含了与其他方法的可比结果。

另一种一致性函数 $\mathcal{L}_{u}$ 的变体是在[19]中开发的，作者将其称为记忆丧失函数。我们称之为基于记忆的模型（MeM）。这种记忆丧失基于一个记忆模块，由一个嵌入 $m_{i}=\left(\check{\textbf{x}}_{i},\hat{\textbf{y}}_{i}\right)$ 组成。它由深度学习模型 $f_{\textbf{w}}$ 提取的特征 $\check{\textbf{x}}_{i}=h_{{}_{\textbf{w}^{\left(\textrm{FE}\right)}}}^{\left(\textrm{FE}\right)}\left(\textbf{x}_{i}\right)$ 和对应的概率密度函数 $\hat{\textbf{y}}_{i}=f_{\textbf{w}}\left(\textbf{x}_{i}\right)$（其中 $\hat{\textbf{y}}$ 为 logits 输出）组成，用于给定的观测 $\textbf{x}_{i}$。记忆模块每个类别存储一个嵌入 $k$，即 $m_{k}=\left(\check{\textbf{$\textbf{x}$}}_{k},\hat{\textbf{$\textbf{y}$}}_{k}\right)$，对应于类别 $k$ 中所有观测的平均嵌入。以前的方法如时间集成 [49] 需要为每个观测存储过去模型的输出。在[19] 的记忆丧失方法中，通过仅存储每个类别的一个平均嵌入来避免这一点。在第二步中，记忆丧失的计算如下：$\mathcal{L}_{m}=H\left(\textbf{p}_{i}\right)+\max\left(\textbf{p}_{i}\right)\delta_{\textrm{KL}}\left(\textbf{p}_{i},\hat{\textbf{y}}_{i}\right),$ 其中 $\textbf{p}_{i}$ 是关键地址概率，计算为与 $\textbf{x}_{i}$ 最接近的嵌入，而 $\hat{\textbf{y}}_{i}$ 是模型对该观测的输出。因子 $\max\left(\textbf{p}_{i}\right)$ 是概率分布 $\textbf{p}_{i}$ 的最高值，$H\left(\textbf{p}_{i}\right)$ 是关键地址输出分布 $\textbf{p}_{i}$ 的熵。因子 $\delta_{\textrm{KL}}\left(\textbf{p}_{i},\hat{\textbf{y}}_{i}\right)$ 是观测 $\textbf{x}_{i}$ 的输出与从记忆映射中恢复的关键地址之间的 Kullback-Leibler 距离。MeM 方法与其余审查方法的可比结果显示在表 I 中，用于 CIFAR-10 数据集。

最近，[77]中提出了一种 SSDL 方法。这被称为传导模型（TransM）。作者实施了一种传导学习方法。这意味着未知标签 $\widetilde{y}$ 也被视为变量，从而与模型参数 w 一起进行优化。因此，损失函数实现了一个交叉熵监督损失：$\mathcal{L}_{l}\left(f_{\textbf{w}},\textbf{x}_{i},y_{i}\right)=r_{i}H_{\textrm{CE}}\left(f_{\textbf{w}}\left(\textbf{x}_{i}\right),y_{i}\right),$ 其中 $r_{i}$ 是集合 $R=\left\{r_{i}\right\}_{i=1}^{n_{l}+n_{u}}$ 的一个元素，表示对观察 $\textbf{x}_{i}$ 的标签估计置信度水平。这样的置信度系数使模型对标记和未标记数据集中都能更好地抵御异常值。置信度系数是使用来自标记数据的 k 最近邻方法计算的，利用了观察密度假设 $\chi^{(\textrm{CL})}$。这意味着如果观察位于特征空间内的标记数据的高密度区域，则标签估计具有高置信度。由于 DCNN 是模型使用的，因此特征空间在训练过程中进行学习，必须在每个训练步骤 $\tau$ 重新计算 $R$。对于未标记正则化项：$\mathcal{L}_{u}\left(f_{\textbf{w}},\textbf{x}_{j}\right)=\lambda_{\textrm{RF}}\mathcal{L}_{\textrm{RF}}\left(f_{\textbf{w}},\textbf{x}_{j}\right)+\lambda_{\textrm{MMF}}\sum_{\textbf{x}_{i}}\mathcal{L}_{\textrm{MMF}}\left(f_{\textbf{w}},\textbf{x}_{j},\textbf{x}_{i}\right),$ 它由一个鲁棒特征度量 $\mathcal{L}_{\textrm{RF}}$ 和一个最小-最大分离项 $\mathcal{L}_{\textrm{MMF}}$ 组成，其中 $\lambda_{\textrm{RF}}$ 和 $\lambda_{\textrm{MMF}}$ 权衡它们对无监督信号的贡献。第一个项度量特征一致性，使用模型的学习特征提取器的输出 $\check{\textbf{x}}_{i}=h_{\textbf{w}_{\textrm{FE}}}^{\left(\textrm{FE}\right)}\left(\textbf{x}_{i}\right)$。学习特征的一致性通过欧氏距离 $\mathcal{L}_{\textrm{RF}}\left(\textbf{w},\textbf{x}_{j}\right)=\left\|h_{\textbf{w}_{\textrm{FE}}}^{\left(\textrm{FE}\right)}\left(\Psi^{\eta}\left(\textbf{x}_{j}\right)\right)-h_{\textbf{w}_{\textrm{FE}}}^{\left(\textrm{FE}\right)}\left(\Psi^{\eta^{\prime}}\left(\textbf{x}_{j}\right)\right)\right\|^{2}$ 来衡量。至于第二项，被称为最小-最大分离函数，它旨在通过最小边际 $\rho$ 最大化不同类别观察之间的距离，并最小化同一类别观察之间的距离。其实现如下：

|  | $\mathcal{L}_{\textrm{MMF}}\left(f_{\textbf{w}},\textbf{x}_{i},\textbf{x}_{j}\right)=r_{i}r_{j}\left\&#124;f_{\textbf{w}}\left(\textbf{x}_{i}\right)-f_{\textbf{w}}\left(\textbf{x}_{j}\right)\right\&#124;^{2}\delta\left(\widetilde{y}_{i,}\widetilde{y}_{j}\right)$ |  | (4) |
| --- | --- | --- | --- |
|  | $-\textrm{min}\left(\left\&#124;f_{\textbf{w}}\left(\textbf{x}_{i}\right)-f_{\textbf{w}}\left(\textbf{x}_{j}\right)\right\&#124;^{2}-\rho,0\right)\left(1-\delta\left(\widetilde{y}_{i,}\widetilde{y}_{j}\right)\right).$ |  |

当$\delta\left(\widetilde{y}_{i,}\widetilde{y}_{j}\right)=1$时，$\widetilde{y}_{i}=\widetilde{y}_{j}$，否则为零。$\mathcal{L}_{\textrm{MMF}}$中的第一个项最小化类内距离，第二个项最大化类间观察距离。我们通过实现置信系数$r_{i}$来突显该方法的理论异常值鲁棒性。该系数能够对不确定的估计给予较低的相关性。然而，尚未完全证明，因为在[77]中进行的实验未测试模型对无标签单个和集体异常值的鲁棒性。该方法还与其他一致性正则化方法结合并进行测试，如 MTM。在本文中，这被称为均值教师的转导模型（TransM+MTM）。与其他评审方法的可比结果见表 I。

一种替代一致性函数的方法在[89]中实施，模型名称为作者命名的自监督网络模型（SESEMI）。一致性函数由作者定义的自监督分支提供输入。该分支旨在学习简单的图像变换或预训练任务，如图像旋转。作者声称他们的模型比 MTM 更容易校准，只需使用一个无监督信号权重$\lambda=1$。SESEMI 与其他评审方法的交集结果详见表 I。

在[9]中，作者提出了一种名为 MixMatch 的新型 SSDL 方法。该方法实现了一种一致性损失，首先计算每个无标签观测的软伪标签。这些软伪标签是对输入$\textbf{x}_{j}$的若干次变换模型响应的平均值得到的 $\widehat{\textbf{y}}{}_{j}=\frac{1}{\mathcal{T}}\sum_{\eta=1}^{\mathcal{T}}f_{\textbf{w}}\left(\Psi^{\eta}\left(\textbf{x}_{j}\right)\right)$。在这个方程中，$\mathcal{T}$是指输入图像的变换次数（即图像旋转、裁剪等）。特定的图像变换在$\Psi^{\eta}$中表示。作者在[9]中建议使用$\mathcal{T}=2$。随后，获得的软伪标签被锐化，以减少其熵和伪标签的低置信度。为此，在输出$\widehat{\textbf{y}}{}_{j}$的 softmax 中使用参数$\rho$：$s\left(\widehat{\textbf{y}},\rho\right)_{i}=\frac{\widehat{y}_{i}^{1/\rho}}{\sum_{j}\widehat{y}_{j}^{1/\rho}}$。数据集$\widetilde{S}_{u}=\left(X_{u},\widetilde{Y}\right)$包含锐化的软伪标签，其中$\widetilde{Y}=\left\{\widetilde{\textbf{y}}_{1},\widetilde{\textbf{y}}_{2},\ldots,\widetilde{\textbf{y}}_{n_{u}}\right\}$。MixMatch 的作者发现数据增强对提高性能非常重要。考虑到这一点，作者实施了 MixUp 方法来增强标记和未标记的数据集[99]。表示如下：$\left(S^{\prime}_{l},\widetilde{S}^{\prime}_{u}\right)=\Psi_{\textrm{MixUp}}\left(S_{l},\widetilde{S}_{u},\alpha\right)$。MixUp 通过标记数据和未标记数据的不同组合之间的线性插值生成新的观测。新观测的标签也是线性插值的，同时使用标签和伪标签（用于未标记数据）。

在数学上，MixUp 采用两个伪标记或标记的数据对$\left(\textbf{x}_{a},y_{a}\right)$和$\left(\textbf{x}_{b},y_{b}\right)$，并生成增强数据集$\left(S^{\prime}_{l},\widetilde{S}^{\prime}_{u}\right)$。这些增强数据集由 MixMatch 使用，通过最小化以下损失函数来训练具有参数 w 的神经网络：

|  | $\mathcal{L}\left(S,\textbf{w}\right)=\sum_{\left(\textbf{x}_{i},\textbf{y}_{i}\right)\in S^{\prime}_{l}}\mathcal{L}_{l}\left(\textbf{w},\textbf{x}_{i},\textbf{y}_{i}\right)+$ |  |
| --- | --- | --- |
|  | $\gamma r(t)\sum_{\left(\textbf{x}_{j},\widetilde{\textbf{y}}_{j}\right)\in\widetilde{S}^{\prime}_{u}}\mathcal{L}_{u}\left(\textbf{w},\textbf{x}_{j},\widetilde{\textbf{y}}_{j}\right)$ |  | (5) |

标记损失项 $\mathcal{L}_{l}$ 可以通过交叉熵函数来实现，如[9]中推荐的那样；$\mathcal{L}_{l}\left(\textbf{w},\textbf{x}_{i},\textbf{y}_{i}\right)=H_{\textrm{CE}}\left(\textbf{y}_{i},f_{\textbf{w}}\left(\textbf{x}_{i}\right)\right)$。关于未标记损失项，作者在[9]中测试了欧几里得距离，$\mathcal{L}_{u}\left(\textbf{w},\textbf{x}_{j},\widetilde{\textbf{y}}_{j}\right)=\left\|\widetilde{\textbf{y}}_{j}-f_{\textbf{w}}\left(\textbf{x}_{j}\right)\right\|$。在 MixMatch 损失函数中，系数 $r(t)$ 被实现为一个递增函数，该函数随着 $t$ 的增加而增强未标记损失项的权重。参数 $\gamma$ 控制未标记损失项的整体影响。在表 I 中，[9] 中得到的结果展示了 CIFAR-10 数据集的表现。

在[8]中，开发了一种 MixMatch 算法的扩展，称为 ReMixMatch。提出了两个主要修改：分布对齐程序和数据增强的更广泛使用。分布对齐包括利用每个类别的运行平均预测（在一组先前模型的训练周期中）和带标签数据集的边际标签分布对每个预测进行标准化。这样，软伪标签估计考虑了标签分布和先前的标签预测，强制软伪标签在两种分布下保持一致。原始 MixMatch 算法中实现的简单数据增强步骤（使用翻转和裁剪）扩展为两种方法。作者称之为锚点增强（anchor augmentation）和 CT 增强（CTAugment）。作者在 MixMatch 中实施更强的数据增强变换（即伽玛和亮度修改等）时，收集到的实证证据表明性能下降。这是因为每种强变换的模型输出变化较大，使伪标签的意义降低。为了解决这个问题，作者提出了一种增强锚点方法。该方法使用在使用弱变换时估计的相同伪标签，用于$\mathcal{T}^{\prime}$强变换。这些强变换通过修改自动增强算法来计算。自动增强最初使用强化学习来寻找针对特定目标问题的最佳增强策略（使用的变换集合）[24]。为了简化在小型标注数据集上的实现，[8]中的作者提出了一种修改，称为 CTAugment。它估计生成正确分类图像的可能性，以生成不容易导致错误预测的图像。在 ReMixMatch 执行的基准测试中报告的性能显示，与原始 MixMatch 算法相比，准确率提高了 1% 到 6%。未报告统计显著性测试。与本文中其他方法在 CIFAR-10 数据集上的结果对比见表 I。

最近，提出了一种被称为 FixMatch 的 SSDL 方法，参考了[80]。作者认为，与其他技术相比，这种简化的 SSDL 方法具有一定优势。FixMatch 基于伪标签和一致性正则化的 SSDL。损失函数使用交叉熵标签损失项，并对标记数据进行弱增强。对于未标记数据的损失项，也使用交叉熵，但对于强未标记观测值使用其相应的伪标签。软伪标签是通过弱变换计算的，取模型输出的最大 logit。因此，没有进行模型输出的锐化，这与 MixMatch 不同。强增强使用了随机增强（RA）[25]和 CT 增强（CTA）[8]进行测试。为了对 FixMatch 进行基准测试，作者使用了 CIFAR-10（40, 250, 4000 标签）、加拿大高级研究院数据集（CIFAR-100）（400, 2500 和 10000 标签）、SVHN（40, 250, 1000 标签）和自学学习 10 类（STL-10）（1000 标签）数据集。所有方法均使用了 Wide-ResNet CNN 骨干网的变体。每个测试配置的平均准确度与 ReMixMatch 的结果相似，没有进行统计显著性检验。FixMatch 所产生的可比结果如表 I 所示。

#### II-C2 基于对抗增强的正则化

深度生成网络在学习数据分布方面的最新进展推动了其在 SSDL 架构中的使用[36]。正则化技术通常采用基本的数据增强管道，以评估一致性项$\mathcal{L}_{u}$。然而，生成对抗网络可以用来学习标记和未标记数据的分布，并生成全新的观测数据。这些被分类为基于生成对抗网络的一致性正则化半监督深度学习（GaNC-SSDL）。学习数据分布$\mathbf{Pr}_{\textbf{x}\sim\mathcal{C}}\left(\textbf{x}\right)$的良好近似允许人工生成新观测数据。这些观测数据可以添加到未标记数据集$S^{(u)}$中，或者对抗训练可能会导致模型参数的优化。

在[81]中，通过实现一个判别函数$f_{\textbf{w}_{d}}^{\left(d\right)}$，将生成网络架构扩展到 SSDL 中，该函数不仅能够估计观察$\textbf{x}_{i}$是否属于要区分的类别之一，还能估计其属于哪个具体类别。作者将模型命名为分类生成对抗网络（CAT-GAN），因为判别器能够执行普通的$1-K$分类。因此，$f_{\textbf{w}_{d}}^{\left(d\right)}$能够估计未标记观察$\textbf{x}_{i}\in S^{(u)}$的密度函数，$\hat{\textbf{y}}_{i}=f_{\textbf{w}_{d}}^{\left(d\right)}\left(\textbf{x}_{i}\right)$。判别器模型实现了一个半监督损失函数：

|  | $\mathcal{L}^{\left(d\right)}\left(f_{\textbf{w}_{d}}^{\left(d\right)},\textbf{x}_{i}\right)=\mathcal{L}_{l}^{\left(d\right)}\left(f_{\textbf{w}_{d}}^{\left(d\right)},\textbf{x}_{i},\textbf{y}_{i}\right)+\mathcal{L}_{u}^{\left(d\right)}\left(f_{\textbf{w}_{d}}^{\left(d\right)},\textbf{x}_{i}\right)$ |  | (6) |
| --- | --- | --- | --- |

使用$\mathcal{L}_{l}^{\left(d\right)}\left(\textbf{w}_{d},\textbf{x}_{i}\right)=H_{\textrm{CE}}\left(\textbf{y}_{i},f_{\textbf{w}_{d}}^{\left(d\right)}\left(\textbf{x}_{i}\right)\right),$ 其中$H_{\textrm{CE}}$是交叉熵。无监督判别器项$\mathcal{L}_{u}^{\left(d\right)}$旨在最大化未标记观察的确定性，并最小化人工观察的确定性。作者还加入了一个项以鼓励对$K$个类别的不平衡修正。[81]中提出的方法在 CIFAR-10 和修改版国家标准与技术研究所数据集（MNIST）上进行了测试。它仅与 Pi-M 进行比较，结果略有改善，但没有对结果进行统计显著性分析。然而，CAT-GAN 为后续利用生成深度模型进行 SSDL 的工作奠定了基础。

在[73]中，实现了对训练 $f_{\textbf{w}_{d}}^{\left(d\right)}$ 和 $f_{\textbf{w}_{g}}^{\left(g\right)}$ 模型的突破性改进，旨在克服使用随机梯度下降算法训练互补损失函数的困难。这个问题被称为纳什均衡困境。作者通过对生成器 $f_{\textbf{w}_{g}}^{\left(g\right)}$ 使用特征匹配损失函数取得了这样的改进，该函数旨在使生成的观测值与训练数据 $S$ 中真实样本的统计矩匹配。特征匹配生成对抗网络（FM-GAN）的增强训练能力在半监督学习设置中进行了测试。半监督损失函数实现了一个无监督项 $\mathcal{L}_{u}^{\left(d\right)}\left(f_{\textbf{w}_{d}}^{\left(d\right)},\textbf{x}_{i}\right)$，旨在最大化鉴别器在区分未标记的真实观测值 $\textbf{x}_{i}\in S^{(u)}$ 和人工生成的观测值时的成功率。鉴别器模型 $f_{\textbf{w}_{d}}^{\left(d\right)}\left(\textbf{x}_{i}\right)$ 输出观测值 $\textbf{x}_{i}$ 属于真实类别之一的概率。在这项工作中，作者还展示了如何在获得良好的半监督学习准确性（即良好的鉴别器）的情况下，通常会导致生成性能较差。作者建议，一个差的生成器更好地描述了分布外（OOD）数据，从而提高了整体模型的鲁棒性。与其他回顾的 SSDL 方法的交叉结果见表 I。

在[26]中，作者进一步探讨了生成器与半监督判别性能之间的逆关系，使用了**不良生成对抗网络**（Bad-GAN）。实验展示了一个*不良*生成器 $f_{\textbf{w}_{g}}^{\left(g\right)}$ 如何从概念类分布 $\mathbf{Pr}_{\textbf{x}\sim\mathcal{C}}$ 中产生观察数据，从而提升了半监督学习中判别器 $f_{\textbf{w}_{d}}^{\left(d\right)}$ 的性能。更具体地说，生成器损失 $\mathcal{L}^{\left(g\right)}$ 被鼓励最大化与采样数据分布的 Kullback-Leibler 距离。这强制了判别器 $f_{\textbf{w}_{d}}^{\left(d\right)}$ 为干扰观察建立的边界。在[52]中，对比了[22]中提出的三重生成网络和[26]中的不良生成器。没有得出结论性的结果，导致作者建议结合这些方法以提高准确性。为与相关工作进行比较，CIFAR-10 的结果描述在表格 I 中。

后来，在[68]中，作者提出了一种用于联合生成对抗网络（Co-GAN）的共同训练对抗正则化方法，利用了两个不同模型 $f_{\textbf{w}_{d_{1}}}^{\left(d_{1}\right)}$ 和 $f_{\textbf{w}_{d_{2}}}^{\left(d_{2}\right)}$ 的一致性假设。每个模型都使用来自相同观察 $\textbf{x}_{i}=\left\langle\textbf{x}_{i}^{\left(v_{1}\right)},\textbf{x}_{i}^{\left(v_{2}\right)}\right\rangle$ 的不同视图进行训练。最小化了一个通用损失函数 $\mathcal{L}\left(S\right)=\mathcal{L}_{l}\left(S_{l}\right)+\mathcal{L}_{u}\left(S^{(u)}\right)$，其中无监督损失函数定义为

|  | $\mathcal{L}_{u}\left(f_{\textbf{w}},S^{(u)}\right)=\lambda_{\textrm{cot}}\mathcal{L}_{\textrm{cot}}\left(f_{\textbf{w}},S^{(u)}\right)+\lambda_{\textrm{dif}}\mathcal{L}_{\textrm{dif}}\left(f_{\textbf{w}},\textbf{z}\right).$ |  | (7) |
| --- | --- | --- | --- |

术语 $\mathcal{L}_{\textrm{cot}}$ 通过 Jensen-Shannon 散度测量两个模型在使用相同观测的两个视图时的期望一致性。在 $\mathcal{L}_{\textrm{dif}}\left(\textbf{z}\right)$ 中，每个模型人工生成观测以欺骗另一个模型。这刺激了模型之间的视图差异，以避免它们互相崩溃。系数 $\lambda_{\textrm{cot}}$ 和 $\lambda_{\textrm{dif}}$ 权衡了每个术语的贡献。因此，对于每个视图，训练一个生成器，而模型 $f_{\textbf{w}_{d_{1}}}^{\left(d_{1}\right)}$ 和 $f_{\textbf{w}_{d_{2}}}^{\left(d_{2}\right)}$ 扮演侦探角色。根据 [68]，所提出的方法优于 MTM、TEM 和 Bad-GAN。实验使用了两个以上的观测视图，推广了模型到多视图布局 $\textbf{x}_{i}=\left\langle\textbf{x}_{i}^{\left(v_{1}\right)},\textbf{x}_{i}^{\left(v_{2}\right)}\right\rangle$。表现最佳的模型实现了 8 个视图，文档中称为 8 视图联合生成对抗网络（Co-8-GAN）。我们包括了 [68] 中使用 SVHN 和 CIFAR-10 数据集的基准结果。作者没有报告提供结果的统计显著性分析。

三重生成对抗网络（Triple-GAN）[22] 通过训练三种不同的模型，解决了生成模型与半监督分类性能之间的逆向关系，具体如下。首先，一个分类器 $f_{\textbf{w}_{c}}^{\left(c\right)}\left(\textbf{x}_{i}\right)$ 学习数据分布 $\mathbf{Pr}_{\textbf{x}\sim\mathcal{C}}$ 并输出人工生成观测值的伪标签。其次，一个条件生成器 $f_{\textbf{w}_{g}}^{\left(g\right)}$ 能够为每个类别生成观测值。第三，一个鉴别器 $f_{\textbf{w}_{d}}^{\left(d\right)}\left(\textbf{x}_{i}\right)$，它会拒绝标签类别之外的观测值。该架构使用伪标签，因为鉴别器使用分类器的伪标签 $\hat{\textbf{y}}_{i}=f_{\textbf{w}_{c}}^{\left(c\right)}\left(\textbf{x}_{i}\right)$。尽管如此，分类器损失 $\mathcal{L}^{\left(c\right)}$ 中实现了一个一致性正则化。使用 CIFAR-10 和其他审阅工作的设置测试的结果见表 I。

#### II-C3 基于图的正则化

基于图的正则化半监督深度学习（GR-SSDL）基于以前的图正则化技术 [34]。GR-SSDL 的核心思想是将数据集 $S$（包括标记和未标记）中的观察值的相互距离保留在新的特征空间中。通过映射函数 $\check{\textbf{x}}_{i}=h_{\textbf{w}_{\textrm{FE}}}^{\left(\textrm{FE}\right)}\left(\textbf{x}_{i}\right)$ 构建了一个嵌入，将输入维度 $d$ 减少到 $\check{d}$。在原始输入空间 $\textbf{x}_{i}\in\mathbb{R}^{d}$ 中的观察值的相互距离，以矩阵 $W\in\mathbb{R}^{n\times n}$ 表示，$W_{i,j}=\delta\left(\textbf{x}_{i},\textbf{x}_{j}\right)$，旨在新的特征空间 $\check{\textbf{x}}_{i}\in\mathbb{R}^{\check{d}}$ 中保留。[48] 开发的多维尺度算法是保留观察值嵌入的相互距离的首批方法之一。

最近，在 [55] 中，在平滑邻域教师图模型（SNTGM）中实施了基于图的正则化。该模型旨在平滑分类器在簇中观察的一致性，而不仅仅是先前一致性基于正则化技术人工创建的观察。所提出的方法同时实现了带有权重 $\lambda_{1}$ 的一致性基正则化 $\mathcal{L}_{c}$ 和带有系数 $\lambda_{2}$ 的引导嵌入 $\mathcal{L}_{e}$：

|  | $\mathcal{L}_{u}\left(f_{\textbf{w}},\textbf{x}_{i},\textbf{x}_{j},W_{i,j}\right)=\lambda_{1}\mathcal{L}_{c}\left(f_{\textbf{w}},\textbf{x}_{i}\right)+\lambda_{2}\mathcal{L}_{e}\left(f_{\textbf{w}},\textbf{x}_{i},\textbf{x}_{j},W\right)$ |  | (8) |
| --- | --- | --- | --- |

其中 $\textbf{x}_{i},\textbf{x}_{j}\in S^{(u)}$。$\mathcal{L}_{c}$ 通过使用基于一致性的正则化技术的先前方法来测量预测的一致性。术语 $\mathcal{L}_{e}$ 实现了观察嵌入，具有 $\gamma$ 边界限制的距离。为了构建邻域矩阵 $W$，[55] 的作者使用了标签信息，而不是计算观察之间的距离。关于 $S^{(u)}$ 中的未标记观察，作者估计教师的输出为 $\hat{y}_{i}=f_{\textbf{w}^{\prime}}\left(\Psi^{\eta}\left(\textbf{x}_{i}\right)\right)$。因此，邻域矩阵如下所示：

|  | $W_{i,j}=\begin{cases}1&amp;\textrm{如果 }\hat{y}_{i}=\hat{y}_{j}\\ 0&amp;\textrm{如果 }\hat{y}_{i}\neq\hat{y}_{j}\end{cases}.$ |  | (9) |
| --- | --- | --- | --- |

损失项 $\mathcal{L}_{e}$ 鼓励相同类别观察的表示相似，并且不同类别的表示有更高的差异。该算法与 Pi-M 和 VATM 一致性函数结合并测试，分别称为带有 Pi-Model 正则化的平滑邻居教师图模型 (SNTGM+Pi-M) 和带有虚拟对抗训练的平滑邻居教师图模型 (SNTGM+VATM)。

| Model | Category | $n_{l}=2000$ | $n_{l}=4000$ | $n_{l}=5000$ |
| --- | --- | --- | --- | --- |
| Supervised only | Supervised | 33.94$\pm$0.73[86] | 20.02$\pm$0.6[86] | 18.02$\pm$0.6[86] |
| Pi-M |  | 18.02$\pm$0.6[86] | 13.2$\pm$0.27[49] | 6.06$\pm$0.11[49] |
| TEM |  | - | 12.16$\pm$0.24[49] | 5.6$\pm$0.1 [49] |
| VATM+EM |  | - | 13.15$\pm$0.21[59] | - |
| VATM |  | - | 14.87$\pm$0.13[59] | - |
| MTM |  | 15.73$\pm$0.31[86] | 12.31$\pm$0.28[86] | 5.94$\pm$0.15[68, 86] |
| SESEMI |  | 14.22$\pm$0.27[89] | 11.65$\pm$0.13[89] | - |
| METM |  | - | 11.29$\pm$0.24[72] | - |
| TransM | RC-SSDL | 14.65$\pm$0.33[77] | 10.9$\pm$0.23[77] | 5.2$\pm$0.14[77] |
| TransM+MTM |  | 13.54$\pm$0.32[77] | 9.3$\pm$0.55[77] | 5.19$\pm$0.14[77] |
| MeM |  | - | 11.91$\pm$0.22[19] | - |
| MixMatch |  | - | 6.42$\pm$0.10[9] | - |
| ReMixMatch |  | - | 4.72$\pm$0.13[8] | - |
| FixMatch(RA) |  | - | 4.31$\pm$0.15 | - |
| FixMatch(CTA) |  | - | 4.26$\pm$0.05 | - |
| SNTGM+VATM | GR-SSDL | - | 12.49$\pm$0.36[55] | - |
| SNTGM+Pi-M |  | - | 13.62$\pm$0.17[55] | - |
| FM-GAN |  | - | 18.63$\pm$2.32[23] | - |
| CAT-GAN |  | - | 19.58$\pm$0.58[81] | - |
| Co-8-GAN | GaNC-SSDL | - | 8.35$\pm$0.06[68] | - |
| Bad-GAN |  | - | 14.41$\pm$0.3[26] | - |
| Triple-GAN |  | - | 16.99$\pm$0.36[22] | - |
| Tri-Net |  | - | 8.45$\pm$0.22[29] | - |
| SaaSM | PLT-SSDL | - | 10.94$\pm$0.07[23] | - |
| TriNet+Pi |  | - | 8.3$\pm$0.15[29] | - |

表 I: 使用 CIFAR-10 数据集的最先进方法的 SSDL 错误率（越低越好）。文献中使用的标签数量 $n_{l}=2000$、$n_{l}=4000$ 和 $n_{l}=5000$ 是最常见的。

## III 处理 SSDL 中的分布不匹配

在 [63] 和 [15] 中，对分布不匹配设置进行了广泛评估。作者一致认为，这对 SSDL 方法的性能具有决定性影响，因此提高其对这种现象的鲁棒性具有重要意义。旨在处理 $S^{(u)}$ 和 $S^{(l)}$ 之间分布不匹配的 SSDL 方法通常使用来自 OOD 检测技术的理念和概念。大多数对分布不匹配鲁棒的 SSDL 方法计算一个称为 $\mathcal{H}\left(\textbf{x}_{j}^{u}\right)$ 的函数，用于评估未标记观察 $\textbf{x}_{j}^{u}$ 是否 OOD。该评分可以用于完全丢弃 $\textbf{x}_{j}^{u}$（在本文中称为硬阈值处理），或对其进行加权（软阈值处理）。阈值处理未标记数据集可以作为数据预处理步骤，或在训练过程中在线进行。

因此，我们首先在 Section III-A 中回顾现代基于深度学习的 OOD 检测方法。随后，我们在 Section III-B 中介绍对分布不匹配鲁棒的最先进 SSDL 方法。

### III-A OOD 数据检测

OOD 数据检测是机器学习应用中面临的经典挑战。它涉及到检测远离训练数据集分布的数据观察 [38]。个体和集体异常值检测是 OOD 检测的特定问题 [79]。文献中已经解决了其他特定的 OOD 检测设置，例如新颖数据和异常检测 [65] 和不频繁事件检测 [37, 1]。在模式识别社区中已经开发了与 OOD 检测相关的成熟和已知概念。其中一些包括核表示 [87]、密度估计 [57]、鲁棒矩估计 [71] 和原型 [57]。

在图像分析任务中，深度学习领域的最新发展引发了对开发深度学习架构 OOD 检测方法的兴趣。根据我们的文献调查，我们发现深度学习架构的 OOD 检测方法可以分为以下几类：基于 DNN 输出和基于 DNN 特征空间。接下来的小节中，我们将描述每个类别中最受欢迎的方法。

#### III-A1 基于 DNN 输出

在[39]中，作者提出了一种简单的方法，称为**神经网络的分布外检测器（ODIN）**，用于根据其 OOD 概率对输入观测进行评分。作者提出的方法实现了一个基于 DNN 模型输出的置信度分数，该分数通过 softmax 层进行变换。所有单位的最大 softmax 值与模型的置信度相关联。作者认为，这种分数能够区分分布内数据和 OOD 数据。

最近，在[53]中，作者认为使用 DNN 模型的 softmax 输出估计 OOD 概率在未校准模型中常常会导致误导。因此，[53]中的作者提出了一种 DNN 校准方法。该方法实现了一个温度系数，旨在提高模型在 OOD 和分布内（IOD）数据之间的输出区分能力。在[53]中，作者对 ODIN 进行了测试，结果显著优于[39]中提出的基于 softmax 的 OOD 分数。

使用 DNN 输出进行 OOD 检测的另一种方法是被称为**蒙特卡罗丢弃（Monte Carlo Dropout，MCD）**的流行方法[54, 46]。这种方法利用$N$次模型前向传递（输入评估）的分布，通过对相同的输入观测进行轻微变换（噪声、翻转等）或通过丢弃参数向模型注入噪声。输出分布用于计算分布矩（通常是方差）或其他标量分布描述符，如熵。这个思路已经在 OOD 检测中得到了应用，因为 OOD 观测可能会获得更高的熵或方差值[43, 75]。

#### III-A2 基于 DNN 特征空间的

最近，作为 OOD 检测的另一种方法，不同的方法使用特征或潜在空间进行 OOD 检测。在[51]中，作者提出了在特征空间中使用马氏距离来衡量训练数据集和输入观测之间的距离。因此，从训练数据（分布内数据）中计算协方差矩阵和均值观测。通过使用马氏距离，作者提出的方法假设训练数据服从高斯分布。此外，所提出的方法与之前讨论过的 ODIN 校准方法混合进行测试。作者报告称，他们的方法在性能上优于[39]中提出的基于 softmax 的分数和 ODIN[53, 39]。然而，结果没有进行统计显著性分析。

在[91]中，作者提出了另一种基于特征空间的方法，称为确定性不确定性量化（DUQ）。该方法在不确定性估计和 OOD 检测方面都进行了测试。它的核心在于为训练数据集中的每个类别计算一个质心。然后，对于每个新的观察数据，不论是用于不确定性估计还是 OOD 检测，该方法计算到每个质心的距离。最短的距离被用作不确定性或 OOD 得分。DUQ 在 OOD 检测方面的表现与一种变体的 MCD 方法进行了比较，后者使用了一个网络集成进行 OOD 检测。作者声称 DUQ 在 OOD 检测方面表现更好，但未进行结果的统计分析。基准测试使用 CIFAR-10 作为 IOD 数据集，SVHN 作为 OOD 数据集。因此，像往常一样，OOD 检测基准测试中对 IID 假设违反的未见类别设置进行了测试。

### III-B 适应分布不匹配的半监督深度学习方法

文献中通常研究的 IID 假设违反的两个主要原因是：第一个是$S^{(u)}$和$S^{(l)}$之间的先验概率偏移（标签分布不同）。本节描述了应对这一挑战的新方法。另一个 IID 假设违反的原因是未见类别设置，这一方面的研究较为广泛。当前最先进的方法也在本节中讨论。

#### III-B1 未见类别作为分布不匹配的原因

大多数旨在处理分布不匹配的 SSDL 方法都是使用标签数据集（通常是较少的类别）与未标签数据集进行测试的。例如，在这种设置中，对于$S^{(l)}$使用 SVHN，而对于$S^{(u)}$，则从 CIFAR-10 数据集中抽取一定比例的样本，其余则来自 SVHN 数据集。在这个背景下，CIFAR-10 数据集通常被称为 OOD 数据污染源。文献中可以找到针对分布不匹配的 SSDL 在不同程度数据污染下的基准测试。在这一部分，我们描述了文献中针对分布不匹配和未见类别的 SSDL 的最新方法。

在[61]中，提出了一种处理分布不匹配的 SSDL 方法。作者将这种方法称为 RealMix。它被提出作为 MixMatch SSDL 方法的扩展。因此，它使用基于一致性的正则化方法，并结合了 MixMatch 中实现的 MixUp 数据增强方法。为了提高对分布不匹配的鲁棒性，RealMix 使用模型输出的 softmax 作为置信度值，以对每个未标记的观察进行评分。在训练过程中，损失函数中使用这样的置信度分数来掩蔽未标记的观察。每次训练周期中，置信度分数最低的$\phi$百分比未标记观察会被丢弃。为了测试他们的方法，作者在 CIFAR-10 的基础上部署了一个基准测试，并为$S^{(l)}$和$S^{(u)}$设置了不重叠的类别。报告的结果显示，与其他未针对分布不匹配鲁棒性设计的 SSDL 方法相比，所提出的方法略有准确度提升。使用了固定数量的标记观察和 CNN 骨干网络。结果未进行统计显著性测试。RealMix 可以归类为基于 DNN 输出的 OOD 评分方法。阈值设置在训练过程中进行，多次使用二进制或硬阈值（保留或丢弃）。由于 OOD 污染源导致了严重的分布不匹配，测试可以认为是有限的。

最近，名为不确定性感知自蒸馏（UASD）的方法被提出用于 SSDL 分布不匹配的鲁棒性[20]。UASD 使用一种无监督正则化的损失函数。对于每个未标记的观察，伪标签被估计为来自模型集成的平均标签。这个集成由在之前训练周期中产生的过去模型组成。与 RealMix 类似，UASD 使用 DNN 模型的输出对每个未标记的观察进行评分。然而，为了提高这种置信度评分的鲁棒性，UASD 使用来自过去模型的预测集成，以估计模型对每个未标记观察的预测置信度。集成预测的最大 logits 被用作置信度评分。因此，我们可以将 UASD 方法归类为基于 DNN 输出的方法。与 RealMix 类似，估计的分数用于对未标记观察进行硬阈值处理。与 RealMix 相似，UASD 方法的作者使用 CIFAR-10 数据集评估了他们的方法。$S^{(l)}$包括 6 类动物，而$S^{(u)}$从 CIFAR-10 中采样其他 4 类，具有不同程度的类别分布不匹配。仅进行过五次实验以近似误差率分布，且未对结果进行统计分析。未测试不同数量的标记观察或不同的 DNN 骨干。UASD 与未针对分布不匹配鲁棒性设计的 SSDL 方法进行了比较。从报告的结果来看，UASD 在面对严重分布不匹配设置时，相对于以前的 SSDL 方法，准确率提高了最多 6 个百分点。

在[20]中，介绍了一种应对分布不匹配的 SSDL 方法。作者将他们提出的方法称为深度安全半监督学习（D3SL）。该方法通过未标记观测的预测与其噪声修改之间的均方损失来实现无监督正则化。为每个未标记观测实现了观测级别的权重，类似于 RealMix 和 UASD。然而，整个未标记数据集的权重是通过误差梯度优化方法计算的。模型的参数和观测级别的权重在两个嵌套的优化步骤中估计。因此，我们可以将该方法归类为对未标记观测进行梯度优化评分的方法。权重是连续的或非二进制的，因此我们可以称此方法为软阈值方法。根据作者的说法，这会将训练时间增加最多$3\times$。测试基准使用了 CIFAR-10 和 MNIST 数据集。在这两者中，6 个类别用于采样$S^{(l)}$，其余用于$S^{(u)}$。仅使用了固定标签数量的 Wide ResNet-28-10 CNN 骨干网。测试了不同程度的 OOD 污染。提出的 D3SL 方法与通用 SSDL 方法进行了比较，因此忽略了先前的 SSDL 对分布不匹配的鲁棒方法。从报告的结果来看，在最严重的 OOD 数据污染设置下，提出的方法平均准确率提高了约 2%，但没有报告统计显著性。仅进行了五次实验来报告这样的平均错误率。

与 D3SL 类似的梯度优化方法可以在[95]中找到。作者将所提方法称为多任务课程框架（MTCF）。与之前的方法类似，MTCF 为未标记的观察定义了一个 OOD 分数，作为对 MixMatch 算法[9]的扩展。这些分数与 DNN 参数交替优化，类似于 D3SL。然而，这个优化问题可能比 D3SL 更简单，因为 OOD 分数并不是直接以梯度下降的方式优化的。相反，DNN 输出被用作 OOD 分数。包含 OOD 分数的损失函数在 DNN 参数的优化中引入了一个新条件。作者在[95]中将其称为课程多任务学习框架。所提方法在作者定义的开放集半监督学习设置（Open-Set-SSLS）中进行了测试，其中使用了不同的 OOD 数据污染源。关于具体的基准设置，作者仅测试了一个宽度 ResNet DNN 骨干，以将基线 MixMatch 方法与其提出的方法进行比较。没有与其他 SSDL 方法进行比较。作者使用了两个 IOD 数据集：CIFAR-10 和 SVHN。使用了四个不同的 OOD 数据集：均匀分布、Gaussian 噪声、Tiny ImageNet (TIN)和大规模场景理解数据集 (LSUN)。报告了使用相同分区的模型训练最后 10 个检查点的平均值（未测试不同的分区）。测试了固定的 OOD 数据污染程度。报告的准确率提升从 1%到 10%不等。使用相同数据分区阻碍了结果的适当统计分析。

在相同的趋势下，[100] 的作者提出了一种基于梯度优化的方法来计算数据在 $S^{(u)}$ 中的观察权重。测试了两种不同的梯度近似方法：隐式微分（IF）和元近似（MetaA）。作者认为，寻找大样本 $S^{(u)}$ 中每个未标记观察的权重是一个难以处理的问题。因此，这两种测试的方法都旨在减少优化这些权重的计算成本。此外，为了进一步减少需要找到的权重数量，该方法在特征空间中进行聚类。这减少了需要找到的权重数量，因为每个聚类分配一个权重。作者报告的另一个有趣发现是 OOD 数据在批量归一化中的影响。即使 OOD 数据远离决策边界，如果进行批量归一化，性能也可能会下降。如果不进行批量归一化，远离决策边界的 OOD 数据可能不会显著损害性能。因此，找到的权重也用于对数据进行加权的小批量归一化。在对所提方法进行基准测试时，作者使用了 CIFAR-10 和 FashionMNIST 数据集，具有不同程度的 OOD 污染。OOD 数据从排除在 IOD 数据集之外的一组类别中抽样。使用了 WRN-28-2（WideResNet）骨干网。未对测试方法中相同数量分区的结果进行统计分析。平均准确率的提升显示出所提方法具有 5%到 20%不等的正向增益。

针对分布不匹配的鲁棒性半监督深度学习（SSDL）方法，[93] 提出了另一种方法，作者称之为增强分布对齐（ADA）。类似于 MixMatch，ADA 使用 MixMup [99] 进行数据增强。该方法包括一个无监督的正则化项，用于衡量 $S^{(u)}$ 和 $S^{(l)}$ 数据集之间的分布差异。这种差异在特征空间中进行衡量。为了减少 $S^{(u)}$ 和 $S^{(l)}$ 的经验分布不匹配，最小化两个数据集的分布距离，以构建一个特征提取器，旨在建立一个特征密度对齐的潜在空间。这是通过对抗损失优化来完成的。我们可以将这种方法归类为基于特征空间的方法。至于报告的基准测试，作者没有测试不同程度的 OOD 数据污染，仅将其方法与通用 SSDL 方法进行比较，而这些方法并未设计用于处理分布不匹配。没有进行统计显著性测试来测量其准确性提升的信心。与其他通用 SSDL 方法相比，该方法的平均错误率似乎从 0.5% 改善到 2%。这些结果并不能确保实际的准确性提升，因为没有进行统计分析。从没有分布对齐的基准模型中报告的准确性提升约为 5%，但也没有进行统计意义分析。[11] 的作者也使用特征空间对未标记的观察进行评分。该方法在使用胸部 X 光图像进行 COVID-19 检测的特定应用设置中进行了测试。

最近，在[40]中，开发了一种针对分布不匹配鲁棒性的 SSDL 方法。该方法包括两个训练步骤。第一个或预热步骤执行自我训练阶段，其中通过 DNN 骨干网络优化一个预任务。这通过预测每个图像的旋转度来实现，该图像来自一个旋转增强的数据集。这包括来自数据样本$S^{(u)}$和$S^{(l)}$的观察结果（以及 OOD 观察结果）。在第二步中，模型使用基于一致性的正则化方法对未标记数据进行训练。这个一致性正则化方法也使用旋转一致性损失。在这一步中，实施了一种被作者称为跨模态机制的 OOD 过滤方法。这包括伪标签的预测，定义为 DNN 输出的 softmax。这个伪标签及其特征嵌入被送入作者所称的匹配头。这个匹配头由一个多层感知器模型组成，该模型被训练来估计伪标签是否准确匹配到其嵌入。匹配头模型使用标记数据进行训练，配有不同的标签和观察组合。作为测试基准，作者使用了 CIFAR-10、Animals-10 和 CIFAR-ID-50 作为 IOD 数据集。对于 OOD 数据源，使用了高斯噪声和均匀噪声图像，以及 TIN 和 LSUN 数据集。所有测试方法的平均准确率对应于训练期间最后 20 个模型副本。因此，没有测试不同的训练分区，阻止了结果的适当统计分析。与其他通用 SSDL 方法（如 FixMatch）相比，平均结果并没有显著提高，准确率提高约 0.5%至 3%。没有提供训练额外匹配头或预热训练的计算成本数据。作者声称他们的方法中，OOD 数据被重新利用。然而，其他方法如 UASD 也防止完全丢弃 OOD 数据，因为每个 epoch 都会计算动态和软观察权重。从我们的角度来看，对其方法新颖性的更合适描述可能是指在预训练阶段完全使用 OOD 数据。

##### 先验概率偏移

有监督方法中的数据不平衡问题在文献中已经得到了广泛探讨。提出了不同的方法，包括数据转换（过采样、数据增强等）到模型架构相关的方法（即，损失函数的修改等）[2, 83, 60]。然而，关于标注数据集和未标注数据集之间的标签不平衡或标签平衡不匹配的问题，在文献中却较为稀少。这种情况可以被解释为在[63]中描述的分布不匹配问题的一个特例。当两个数据集中的观察值的标签或类别分布存在实质性差异时，$S^{(l)}$和$S^{(u)}$之间可能会出现分布不匹配。

在[41]中，对分布不匹配如何影响 SSDL 模型进行了评估。标注数据集和未标注数据集之间的分布不匹配原因是它们之间的标签不平衡差异。当 SSDL 遇到这种数据设置时，测量到 2%到 10%的准确度下降。作者提出了一种简单的方法来恢复这种性能下降。该方法包括在损失项中为每个未标注观察分配特定的权重。选择权重时，使用当前纪元中得分最高的模型输出单元作为标签预测。在这项工作中，均值教师模型作为 SSDL 方法进行了测试[86]。作者通过使用提出的方法获得了 SSDL 模型的优越性能。在[41]中的工作的扩展可以在[16]中找到，其中在这种情况下，最近的 MixMatch SSDL 方法被修改以提高模型在标注数据集中的严重不平衡条件下的鲁棒性。这一方法在使用胸部 X 射线图像进行 COVID-19 检测的特定应用中进行了广泛测试。

## IV 开放挑战

在实际使用情况下，SSDL 面临的最重要挑战之一是标注数据集和未标注数据集之间的分布不匹配。然而，根据我们的前沿综述，仍有大量工作待完成，主要涉及对新方法的标准基准的实施。迄今为止，文献中的基准显示出对未见类别分布不匹配设置的显著偏见。文献中未发现其他分布不匹配原因如协变量转移的测试。现实世界的使用设置可能包括协变量转移和先验概率分布转移，这违背了常用的 IID 假设。因此，我们敦促社区关注不同的分布不匹配原因。

研究和开发应对分布不匹配设置的方法，将重点转向数据导向的方法（即数据转换、过滤和增强），而不是更流行的模型导向方法。最近，著名研究员**安德鲁·吴**引起了对数据导向方法的关注¹¹1[`www.forbes.com/sites/gilpress/2021/06/16/andrew-ng-launches-a-campaign-for-data-centric-ai/?sh=68b63b2174f5`](https://www.forbes.com/sites/gilpress/2021/06/16/andrew-ng-launches-a-campaign-for-data-centric-ai/?sh=68b63b2174f5)。在他看来，社区在研究和开发应对实际应用设置的数据导向方法方面的努力还不够。

我们同意安德鲁·吴的观点，并补充说，除了建立和测试不同分布不匹配设置的标准基准外，还必须强制实验的可重复性。最近的技术进步不仅允许共享代码和使用的数据集，还可以通过虚拟化和容器技术共享测试环境。最后，我们认为深度学习研究社区必须注意不仅仅比较不同最先进方法的平均准确度。必须使用统计分析工具来测试一种方法与另一种方法之间的性能差异是否可重复且具有统计意义。因此，我们建议共享结果的分布，而不仅仅是结果的均值和标准差，以便进行进一步的统计分析。

## 参考文献

+   [1] Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, 和 Dan Mané. 人工智能安全中的具体问题. arXiv 预印本 arXiv:1606.06565, 2016.

+   [2] Shin Ando 和 Chun Yuan Huang. 用于分类不平衡数据的深度过采样框架. 在联合欧洲机器学习与数据库知识发现会议中，页面 770–785. Springer, 2017.

+   [3] Philip Bachman, Ouais Alsharif, 和 Doina Precup. 使用伪集成学习. 在神经信息处理系统进展中，页面 3365–3373, 2014.

+   [4] Maria-Florina Balcan 和 Avrim Blum. 21 增强型 PAC 模型用于半监督学习. 2006.

+   [5] Indranil Balki, Afsaneh Amirabadi, Jacob Levman, Anne L Martel, Ziga Emersic, Blaz Meden, Angel Garcia-Pedrero, Saul C Ramirez, Dehan Kong, Alan R Moody, 等等. 医学影像研究中的样本大小确定方法：系统评审. 加拿大放射学会期刊, 2019.

+   [6] Yoshua Bengio, Pascal Lamblin, Dan Popovici, 和 Hugo Larochelle. 贪婪逐层训练深度网络. 在神经信息处理系统进展中，页面 153–160, 2007.

+   [7] Ariana Bermudez、Saul Calderon-Ramirez、Trevor Thang、Pascal Tyrrell、Armaghan Moemeni、Shengxiang Yang 和 Jordina Torrents-Barrena。利用深度学习评估牙科光刺激磷光板的质量。《电气与电子工程师协会》，2020 年。

+   [8] David Berthelot、Nicholas Carlini、Ekin D Cubuk、Alex Kurakin、Kihyuk Sohn、Han Zhang 和 Colin Raffel。Remixmatch：具有分布对齐和数据增强锚定的半监督学习。arXiv 预印本 arXiv:1911.09785，2019 年。

+   [9] David Berthelot、Nicholas Carlini、Ian Goodfellow、Nicolas Papernot、Avital Oliver 和 Colin A Raffel。Mixmatch：一种整体性的半监督学习方法。发表于《神经信息处理系统进展》，页码 5050–5060，2019 年。

+   [10] S Calderon、F Fallas、M Zumbado、PN Tyrrell、H Stark、Ziga Emersic、Blaz Meden 和 M Solis。评估在基于卷积神经网络的年龄估计中，欺骗性非局部均值滤波器作为预处理阶段的影响。发表于 2018 年第 25 届 IEEE 国际图像处理会议（ICIP），页码 1752–1756。IEEE，2018 年。

+   [11] Saul Calderon-Ramirez、Raghvendra Giri、Shengxiang Yang、Armaghan Moemeni、Mario Umana、David Elizondo、Jordina Torrents-Barrena 和 Miguel A Molina-Cabello。应对稀缺标记数据：利用 Mixmatch 进行半监督深度学习以检测 COVID-19，使用胸部 X 光图像。发表于 2020 年第 25 届国际模式识别会议（ICPR），页码 5294–5301。IEEE，2021 年 1 月。

+   [12] Saul Calderon-Ramirez 和 Erick Mata-Montero。通过条件生成对抗网络对标本样本图像进行衰老逆转的初步研究。发表于《高性能计算：第六届拉丁美洲会议，CARLA 2019》，图尔里亚巴，哥斯达黎加，2019 年 9 月 25–27 日，修订版论文，卷 1087，页 438。Springer Nature，2020 年。

+   [13] Saul Calderon-Ramirez、Diego Murillo-Hernandez、Kevin Rojas-Salazar、Luis-Alexander Calvo-Valverde、Shengxiang Yang、Armaghan Moemeni、David Elizondo、Ezequiel Lopez-Rubio 和 Miguel Molina-Cabello。利用半监督学习改进乳腺 X 光图像分类的不确定性估计。发表于《电气与电子工程师协会》，2021 年。

+   [14] Saul Calderon-Ramirez、Diego Murillo-Hernandez、Kevin Rojas-Salazar、David Elizondo、Shengxiang Yang 和 Miguel Molina-Cabello。在哥斯达黎加一家本地诊所中进行乳腺 X 光图像分类的半监督学习实际案例。arXiv 预印本 arXiv:2107.11696，2021 年。

+   [15] Saul Calderon-Ramirez、Luis Oala、Jordina Torrents-Barrena、Shengxiang Yang、Armaghan Moemeni、Wojciech Samek 和 Miguel A Molina-Cabello。Mixmood：一种系统化的方法来解决半监督学习中的类别分布不匹配问题，使用深度数据集不相似度度量。arXiv 预印本 arXiv:2006.07767，2020 年。

+   [16] Saul Calderon-Ramirez, Shengxiang Yang, Armaghan Moemeni, David Elizondo, Simon Colreavy-Donnelly, Luis Fernando Chavarría-Estrada 和 Miguel A Molina-Cabello. 使用 x 射线胸部图像纠正半监督 COVID-19 检测中的数据不平衡. 应用软计算, 111:107692, 2021.

+   [17] Iván Calvo, Saul Calderon-Ramirez, Jordina Torrents-Barrena, Erick Muñoz 和 Domenec Puig. 评估预处理阶段对乳腺肿瘤多类别分类深度学习架构的影响，使用组织病理图像. 拉丁美洲高性能计算会议论文集，页码 262–275. Springer, 2019.

+   [18] Mathilde Caron, Piotr Bojanowski, Julien Mairal 和 Armand Joulin. 在非精细数据上进行图像特征的无监督预训练. 见于 IEEE/CVF 国际计算机视觉会议论文集，页码 2959–2968, 2019.

+   [19] Yanbei Chen, Xiatian Zhu 和 Shaogang Gong. 具有记忆的半监督深度学习. 见于欧洲计算机视觉会议（ECCV）论文集，页码 268–283, 2018.

+   [20] Yanbei Chen, Xiatian Zhu, Wei Li 和 Shaogang Gong. 类别分布不匹配下的半监督学习. 见于 AAI，页码 3569–3576, 2020.

+   [21] Veronika Cheplygina, Marleen de Bruijne 和 Josien PW Pluim. 不完全监督: 医学图像分析中半监督、多实例和迁移学习的调查. 医学图像分析, 54:280–296, 2019.

+   [22] LI Chongxuan, Taufik Xu, Jun Zhu 和 Bo Zhang. 三重生成对抗网络. 见于神经信息处理系统进展，页码 4088–4098, 2017.

+   [23] Safa Cicek, Alhussein Fawzi 和 Stefano Soatto. Saas: 作为半监督学习监督者的速度. 见于欧洲计算机视觉会议（ECCV）论文集，页码 149–163, 2018.

+   [24] Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan 和 Quoc V Le. Autoaugment: 从数据中学习增强策略. arXiv 预印本 arXiv:1805.09501, 2018.

+   [25] Ekin D Cubuk, Barret Zoph, Jonathon Shlens 和 Quoc V Le. Randaugment: 实用的自动数据增强，减少了搜索空间. 见于 IEEE/CVF 计算机视觉与模式识别会议研讨会论文集，页码 702–703, 2020.

+   [26] Zihang Dai, Zhilin Yang, Fan Yang, William W Cohen 和 Ruslan R Salakhutdinov. 需要一个糟糕的 gan 的良好半监督学习. 见于神经信息处理系统进展，页码 6510–6520, 2017.

+   [27] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li 和 Li Fei-Fei. Imagenet: 大规模层次图像数据库. 见于 2009 IEEE 计算机视觉与模式识别会议，页码 248–255. IEEE, 2009.

+   [28] Carl Doersch, Abhinav Gupta 和 Alexei A Efros. 通过上下文预测进行无监督视觉表示学习. 见于 IEEE 国际计算机视觉会议论文集，页码 1422–1430, 2015.

+   [29] WeiWang Dong-DongChen 和 Zhi-HuaZhou WeiGao. Tri-net 用于半监督深度学习. IJCAI, 2018.

+   [30] Dominic B Dwyer、Peter Falkai 和 Nikolaos Koutsouleris。用于临床心理学和精神病学的机器学习方法。《临床心理学年鉴》，14:91–118，2018 年。

+   [31] Benoît Frénay 和 Michel Verleysen。在标签噪声存在下的分类：综述。《IEEE 神经网络与学习系统汇刊》，25(5):845–869，2013 年。

+   [32] Maayan Frid-Adar、Eyal Klang、Michal Amitai、Jacob Goldberger 和 Hayit Greenspan。使用 GAN 进行合成数据增强以提高肝病变分类。载于 2018 年 IEEE 第 15 届生物医学成像国际研讨会（ISBI 2018），第 289–293 页。IEEE，2018 年。

+   [33] Angel Garcia-Pedrero、Ana I García-Cervigón、José M Olano、Miguel García-Hidalgo、Mario Lillo-Saavedra、Consuelo Gonzalo-Martín、Cristina Caetano 和 Saúl Calderón-Ramírez。用于分割染色横截面图像中木质部导管的卷积神经网络。《神经计算与应用》，第 1–13 页，2019 年。

+   [34] Andrew B Goldberg、Xiaojin Zhu 和 Stephen Wright。图基半监督分类中的差异。载于《人工智能与统计》，第 155–162 页，2007 年。

+   [35] Ian Goodfellow、Yoshua Bengio 和 Aaron Courville。深度学习。MIT 出版社，2016 年。

+   [36] Ian Goodfellow、Jean Pouget-Abadie、Mehdi Mirza、Bing Xu、David Warde-Farley、Sherjil Ozair、Aaron Courville 和 Yoshua Bengio。生成对抗网络。载于《神经信息处理系统进展》，第 2672–2680 页，2014 年。

+   [37] Ryuhei Hamaguchi、Ken Sakurada 和 Ryosuke Nakamura。使用解耦表示学习进行稀有事件检测。载于 IEEE 计算机视觉与模式识别会议论文集，第 9327–9335 页，2019 年。

+   [38] Dan Hendrycks 和 Kevin Gimpel。在神经网络中检测误分类和分布外样本的基线。arXiv 预印本 arXiv:1610.02136，2016 年。

+   [39] Dan Hendrycks 和 Kevin Gimpel。在神经网络中检测误分类和分布外样本的基线。CoRR，abs/1610.02136，2016 年。

+   [40] Junkai Huang、Chaowei Fang、Weikai Chen、Zhenhua Chai、Xiaolin Wei、Pengxu Wei、Liang Lin 和 Guanbin Li。废物变宝物：通过跨模态匹配进行开放集半监督学习的数据收获。arXiv 预印本 arXiv:2108.05617，2021 年。

+   [41] Minsung Hyun、Jisoo Jeong 和 Nojun Kwak。类别不平衡的半监督学习。arXiv 预印本 arXiv:2002.06815，2020 年。

+   [42] Vladimir I Iglovikov、Alexander Rakhlin、Alexandr A Kalinin 和 Alexey A Shvets。使用深度卷积神经网络进行儿科骨龄评估。载于《医学图像分析中的深度学习与临床决策支持的多模态学习》，第 300–308 页。Springer，2018 年。

+   [43] Baihong Jin、Yingshui Tan、Yuxin Chen 和 Alberto Sangiovanni-Vincentelli。通过无监督学习任务增强蒙特卡罗 Dropout 分类模型，以检测和诊断分布外故障。arXiv 预印本 arXiv:1909.04202，2019 年。

+   [44] Longlong Jing 和 Yingli Tian. 基于深度神经网络的自监督视觉特征学习：综述。IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020。

+   [45] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings 等。联邦学习的进展与开放问题。arXiv 预印本 arXiv:1912.04977, 2019。

+   [46] Alex Kendall 和 Yarin Gal. 在计算机视觉的贝叶斯深度学习中我们需要什么不确定性？发表于第 31 届国际神经信息处理系统会议论文集，页面 5580–5590, 2017。

+   [47] Kyeongbo Kong, Junggi Lee, Youngchul Kwak, Minsung Kang, Seong Gyun Kim 和 Woo-Jin Song. 回收：在深度神经网络中处理噪声标签的半监督学习。IEEE Access, 7:66998–67005, 2019。

+   [48] Joseph B Kruskal. 通过优化与非度量假设的拟合优度进行多维尺度分析。Psychometrika, 29(1):1–27, 1964。

+   [49] Samuli Laine 和 Timo Aila. 半监督学习的时间集成。arXiv 预印本 arXiv:1610.02242, 2016。

+   [50] Hye-Woo Lee, Noo-ri Kim 和 Jee-Hyong Lee. 基于无监督学习和 Dropout 的深度神经网络自训练。International Journal of Fuzzy Logic and Intelligent Systems, 17(1):1–9, 2017。

+   [51] Kimin Lee, Kibok Lee, Honglak Lee 和 Jinwoo Shin. 检测分布外样本和对抗攻击的简单统一框架。发表于神经信息处理系统进展，页面 7167–7177, 2018。

+   [52] Wenyuan Li, Zichen Wang, Jiayun Li, Jennifer Polson, William Speier 和 Corey Arnold. 基于生成对抗网络的半监督学习：Good GAN 与 Bad GAN 方法的比较。arXiv 预印本 arXiv:1905.06484, 2019。

+   [53] Shiyu Liang, Yixuan Li 和 Rayadurgam Srikant. 增强神经网络中分布外图像检测的可靠性。发表于第 6 届国际学习表征会议，ICLR 2018, 2018。

+   [54] Antonio Loquercio, Mattia Segu 和 Davide Scaramuzza. 深度学习中的不确定性估计通用框架。IEEE Robotics and Automation Letters, 5(2):3153–3160, 2020。

+   [55] Yucen Luo, Jun Zhu, Mengxi Li, Yong Ren 和 Bo Zhang. 在教师图上的平滑邻居用于半监督学习。发表于 IEEE 计算机视觉与模式识别会议论文集，页面 8896–8905, 2018。

+   [56] Mingqi Lv, Ling Chen, Tieming Chen 和 Gencai Chen. 基于双视图的半监督学习用于加速度计的语义人体活动识别。IEEE Transactions on Mobile Computing, 17(9):1991–2001, 2018。

+   [57] Markos Markou 和 Sameer Singh. 新奇检测：综述—第一部分：统计方法。Signal Processing, 83(12):2481–2497, 2003。

+   [58] Mauro Mendez、Saul Calderon-Ramirez 和 Pascal Tyrrell。使用聚类分析评估数据集异质性对深度卷积网络准确性的影响：初步观察。发表于拉丁美洲高性能计算会议（CARLA）2019 年。

+   [59] Takeru Miyato、Shin-ichi Maeda、Masanori Koyama 和 Shin Ishii。虚拟对抗训练：一种用于监督和半监督学习的正则化方法。IEEE 模式分析与机器智能学报，41(8)：1979–1993，2018 年。

+   [60] Sankha Subhra Mullick、Shounak Datta 和 Swagatam Das。生成对抗性少数类过采样。发表于 IEEE 国际计算机视觉会议论文集，第 1695–1704 页，2019 年。

+   [61] Varun Nair、Javier Fuentes Alonso 和 Tony Beltramelli。RealMix：面向现实的半监督深度学习算法。arXiv 预印本 arXiv:1912.08766，2019 年。

+   [62] Luis Oala、Jana Fehr、Luca Gilli、Pradeep Balachandran、Alixandro Werneck Leite、Saul Calderon-Ramirez、Danny Xie Li、Gabriel Nobis、Erick Alejandro Muñoz Alvarado、Giovanna Jaramillo-Gutierrez 等。Ml4h 审计：从理论到实践。发表于《健康机器学习》，第 280–317 页。PMLR，2020 年。

+   [63] Avital Oliver、Augustus Odena、Colin A Raffel、Ekin Dogus Cubuk 和 Ian Goodfellow。深度半监督学习算法的现实评估。发表于神经信息处理系统进展论文集，第 3235–3246 页，2018 年。

+   [64] Adam Paszke、Sam Gross、Soumith Chintala、Gregory Chanan、Edward Yang、Zachary DeVito、Zeming Lin、Alban Desmaison、Luca Antiga 和 Adam Lerer。PyTorch 中的自动微分。2017 年。

+   [65] Pramuditha Perera 和 Vishal M Patel。用于多类别新颖性检测的深度迁移学习。发表于 IEEE 计算机视觉与模式识别会议论文集，第 11544–11552 页，2019 年。

+   [66] Nitin Namdeo Pise 和 Parag Kulkarni. 半监督学习方法的调查。发表于 2008 年计算智能与安全国际会议，第二卷，第 30–34 页。IEEE，2008 年。

+   [67] V Jothi Prakash 和 Dr LM Nithya。半监督学习技术的调查。arXiv 预印本 arXiv:1402.4645，2014 年。

+   [68] Siyuan Qiao、Wei Shen、Zhishuai Zhang、Bo Wang 和 Alan Yuille。深度协同训练用于半监督图像识别。发表于欧洲计算机视觉会议（ECCV）论文集，第 135–152 页，2018 年。

+   [69] Saúl Calderón Ramírez、Raghvendra Giri、Shengxiang Yang、Armaghan Moemeni、Mario Umaña、David A Elizondo、Jordina Torrents-Barrena 和 Miguel A Molina-Cabello。处理稀缺标记数据：使用 MixMatch 进行半监督深度学习以检测 COVID-19 并利用胸部 X 光图像。发表于 ICPR，第 5294–5301 页，2020 年。

+   [70] Salah Rifai、Yann N Dauphin、Pascal Vincent、Yoshua Bengio 和 Xavier Muller。流形切线分类器。发表于神经信息处理系统进展论文集，第 2294–2302 页，2011 年。

+   [71] Peter J. Rousseeuw. 最小中位数平方回归。美国统计协会期刊，79(388):871–880，1984。

+   [72] Mehdi Sajjadi, Mehran Javanmardi, 和 Tolga Tasdizen. 使用随机变换和扰动的正则化进行深度半监督学习。在神经信息处理系统进展中，页 1163–1171，2016。

+   [73] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, 和 Xi Chen. 改进的生成对抗网络训练技术。在神经信息处理系统进展中，页 2234–2242，2016。

+   [74] Lars Schmarje, Monty Santarossa, Simon-Martin Schröder, 和 Reinhard Koch. 关于图像分类的半监督、自监督和无监督学习的综述。IEEE Access，2021。

+   [75] Andreas Sedlmeier, Thomas Gabor, Thomy Phan, 和 Lenz Belzner. 基于不确定性的深度强化学习中的分布外检测。数字世界，4(1):74–78，2020。

+   [76] Behzad M Shahshahani 和 David A Landgrebe. 无标签样本在减少小样本问题和缓解 Hughes 现象中的作用。IEEE 地球科学与遥感学报，32(5):1087–1095，1994。

+   [77] Weiwei Shi, Yihong Gong, Chris Ding, Zhiheng MaXiaoyu Tao, 和 Nanning Zheng. 使用最小-最大特征的传导性半监督深度学习。在欧洲计算机视觉会议（ECCV）论文集中，页 299–315，2018。

+   [78] Hoo-Chang Shin, Neil A Tenenholtz, Jameson K Rogers, Christopher G Schwarz, Matthew L Senjem, Jeffrey L Gunter, Katherine P Andriole, 和 Mark Michalski. 使用生成对抗网络进行医学图像合成以实现数据增强和匿名化。在医学影像模拟与合成国际研讨会论文集中，页 1–11。Springer，2018。

+   [79] Karanjit Singh 和 Shuchita Upadhyaya. 离群点检测：应用与技术。计算机科学问题国际期刊（IJCSI），9(1):307，2012。

+   [80] Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A Raffel, Ekin Dogus Cubuk, Alexey Kurakin, 和 Chun-Liang Li. Fixmatch: 利用一致性和置信度简化半监督学习。神经信息处理系统进展，33，2020。

+   [81] Jost Tobias Springenberg. 使用分类生成对抗网络的无监督和半监督学习。arXiv 预印本 arXiv:1511.06390，2015。

+   [82] Wenqing Sun, Tzu-Liang Bill Tseng, Jianying Zhang, 和 Wei Qian. 利用无标签数据增强深度卷积神经网络方案用于乳腺癌诊断。计算机化医学影像与图形，57:4–9，2017。

+   [83] Aboozar Taherkhani, Georgina Cosma, 和 TM McGinnity. Adaboost-cnn: 一种自适应提升算法，用于通过迁移学习分类多类别不平衡数据集的卷积神经网络。神经计算，2020。

+   [84] Chuanqi Tan, Fuchun Sun, Tao Kong, Wenchang Zhang, Chao Yang 和 Chunfang Liu。深度迁移学习综述。载于《国际人工神经网络会议》，第 270–279 页。Springer，2018 年。

+   [85] Jeremy Tan, Anselm Au, Qingjie Meng 和 Bernhard Kainz。利用超声波进行胎儿解剖的半监督学习。载于《领域适应与表示迁移以及医学图像学习：标签较少和不完美数据》，第 157–164 页。Springer，2019 年。

+   [86] Antti Tarvainen 和 Harri Valpola。均值教师是更好的榜样：权重平均一致性目标改善半监督深度学习结果。载于《神经信息处理系统进展》，第 1195–1204 页，2017 年。

+   [87] David M. J. Tax 和 Robert P. W. Duin。支持向量数据描述。《机器学习》，54(1):45–66，2004 年。

+   [88] Lisa Torrey 和 Jude Shavlik。迁移学习。载于《机器学习应用与趋势手册：算法、方法与技术》，第 242–264 页。IGI Global，2010 年。

+   [89] Phi Vu Tran。使用自监督网络的半监督学习。arXiv 预印本 arXiv:1906.10343，2019 年。

+   [90] Leslie G Valiant。可学习性的理论。载于《第十六届 ACM 计算理论年会论文集》，第 436–445 页。ACM，1984 年。

+   [91] Joost van Amersfoort, Lewis Smith, Yee Whye Teh 和 Yarin Gal。使用单一深度确定性神经网络进行简单且可扩展的认识不确定性估计。arXiv e-prints，2020 年 6 月。

+   [92] Jesper E Van Engelen 和 Holger H Hoos。半监督学习综述。《机器学习》，109(2):373–440，2020 年。

+   [93] Qin Wang, Wen Li 和 Luc Van Gool。通过增强分布对齐进行半监督学习。载于《IEEE/CVF 国际计算机视觉会议论文集》，第 1466–1475 页，2019 年。

+   [94] Tong Xiao, Tian Xia, Yi Yang, Chang Huang 和 Xiaogang Wang。利用大量噪声标签数据进行图像分类。载于《IEEE 计算机视觉与模式识别会议论文集》，第 2691–2699 页，2015 年。

+   [95] Qing Yu, Daiki Ikami, Go Irie 和 Kiyoharu Aizawa。开放集半监督学习的多任务课程框架。载于《欧洲计算机视觉会议》，第 438–454 页。Springer，2020 年。

+   [96] Xingrui Yu, Xiaomin Wu, Chunbo Luo 和 Peng Ren。遥感场景分类中的深度学习：数据增强增强的卷积神经网络框架。《地理信息科学与遥感》，54(5):741–758，2017 年。

+   [97] Willard Zamora-Cárdenas, Mauro Mendez, Saul Calderon-Ramirez, Martin Vargas, Gerardo Monge, Steve Quiros, David Elizondo, Jordina Torrents-Barrena 和 Miguel A Molina-Cabello。加强完全卷积网络中的形态学信息，以改善荧光显微镜图像中的细胞实例分割。载于《国际人工神经网络工作会议》，第 36–46 页。Springer，2021 年。

+   [98] Xiaohua Zhai, Avital Oliver, Alexander Kolesnikov 和 Lucas Beyer. S4l: 自监督半监督学习。发表于 IEEE 国际计算机视觉会议，页面 1476–1485，2019 年。

+   [99] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin 和 David Lopez-Paz. mixup: 超越经验风险最小化。arXiv 预印本 arXiv:1710.09412，2017 年。

+   [100] Xujiang Zhao, Killamsetty Krishnateja, Rishabh Iyer 和 Feng Chen. 使用分布外数据的鲁棒半监督学习。arXiv 预印本 arXiv:2010.03658，2020 年。

+   [101] Xiaojin Jerry Zhu. 半监督学习文献综述。技术报告，威斯康星大学麦迪逊分校计算机科学系，2005 年。

+   [102] Xinyue Zhu, Yifan Liu, Jiahong Li, Tao Wan 和 Zengchang Qin. 使用生成对抗网络的数据增强情感分类。发表于太平洋-亚洲知识发现与数据挖掘会议，页面 349–360。Springer，2018 年。
