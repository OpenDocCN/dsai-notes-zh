<!--yml

分类：未分类

日期：2024-09-06 19:50:23

-->

# [2110.10436] 关于自动驾驶中车辆轨迹预测的深度学习方法综述

> 来源：[`ar5iv.labs.arxiv.org/html/2110.10436`](https://ar5iv.labs.arxiv.org/html/2110.10436)

# 关于自动驾驶中车辆轨迹预测的深度学习方法综述

刘建邦^(∗1)、毛鑫宇^(∗1)、方宇琦²、朱德龙¹，以及**IEEE 会士**孟庆华^(†3)，$*$等贡献。$\dagger$通讯作者。¹刘建邦、毛鑫宇和朱德龙均在香港中文大学电子工程系工作，香港。({henryliu, maoxinyu, zhudelong}@link.cuhk.edu.hk)²方宇琦在香港中文大学生物医学工程系工作，香港。(fangyuqi@link.cuhk.edu.hk)³孟庆华在中国深圳南方科技大学电子与电气工程系工作，同时从香港中文大学电子工程系休假，并且还在中国深圳香港中文大学深圳研究院工作。(max.meng@ieee.org.)

###### 摘要

随着机器学习的快速发展，自动驾驶已成为一个热点问题，对更智能的感知和规划系统提出了迫切需求。自动驾驶汽车可以通过精确预测周围车辆的未来轨迹来避免交通事故。在这项工作中，我们从表示、建模和学习的角度回顾和分类了现有的基于学习的轨迹预测方法。此外，我们将 Target-driveN 轨迹预测的实现公开于[`github.com/Henry1iu/TNT-Trajectory-Predition`](https://github.com/Henry1iu/TNT-Trajectory-Predition)，展示了其出色的性能，而其原始代码被保留。希望这些成果能为寻求提高轨迹预测性能的研究者提供启示。

## 引言

人们越来越依赖自动系统来摆脱繁琐的任务，其中一个典型实例就是自动驾驶。在自动驾驶场景中，安全是首要关注点。预测参与者的未来轨迹有助于自动系统找到最有前景的局部路径规划解决方案，防止可能的碰撞。

先驱者们利用卡尔曼滤波器[1]、线性轨迹规避模型[2]和社会力模型[3]预测动态物体的运动。与这些基于手工特征的传统建模技术相比，近年来通过优化损失函数自动学习特征的深度学习算法吸引了研究人员的注意。在这项工作中，我们综述了一些最近的车辆轨迹预测方法，并提出了一些创新的想法。我们实现了赵等人提出的在[4]中的方法，因为它的向量化表示是创新且高效的。通过发布这项调查和我们的代码，我们希望在这个快速扩展的研究领域取得新的突破。

主要有以下两个贡献：

1.  1.

    最近针对驾驶场景中的轨迹预测问题的深度学习方法进行了回顾和讨论。

1.  2.

    我们实现了赵等人介绍的预测模型[4]并向研究社区发布了我们的代码。

## II 问题表述

假设一个自动驾驶系统配备了检测和跟踪模块，能够准确观察所有涉及的代理的状态$\displaystyle{\mathbb{S}}$。给定一个场景，预测目标记作$\displaystyle{\bm{a}}_{tar}$，周围代理记作$\displaystyle{\mathbb{A}}_{nbrs}=\{{\bm{a}}_{1},{\bm{a}}_{2},...,{\bm{a}}_{m}\}$。代理$\displaystyle{\bm{a}}_{i}\in{\mathbb{A}}$在帧$t$的状态记作$\displaystyle s^{t}_{i}$，包括位置、速度、航向角、演员类型等特征，$\displaystyle{\bm{s}}_{i}=\{s^{-T_{obs}+1}_{i},s^{-T_{obs}+2}_{i},...,s^{0}_{i}\}$表示在观察期$\displaystyle T_{obs}$内不同时间戳采样的状态序列。预测框架的目标是预测目标代理$\displaystyle{\bm{a}}_{tar}$的未来轨迹$\uptau_{tar}=\{\tau_{i}|i=1,2,...,K\}$，其中$\displaystyle\tau_{i}=\{(x^{1}_{i},y^{1}_{i}),(x^{2}_{i},y^{2}_{i}),...,(x^{T_{pred}}_{i},y^{T_{pred}}_{i})\}$表示预测的目标代理在预测视野$\displaystyle T_{pred}$内的轨迹。此外，预测的轨迹$\displaystyle\tau_{i}\in\uptau_{tar}$需要满足无碰撞约束和目标代理的运动学约束。

## III 方法

本节中，我们回顾了某些代表性方法的数据表示、模型结构、学习技术和目标函数。

表 I: 模态和建模比较：$\displaystyle CSDTS_{multi}$, $\vec{Polyline}$, $\Delta_{dist}$, $\mathcal{G}_{Lane}$, $\uptau_{cond}$, $Anchor_{T}$, $\Delta$, $State\_Map^{F}$, 和 $\mathcal{L}$ 分别表示包含多个坐标系统下的位置的 CSDTS、矢量化的多段线、相对距离、车道连接图、条件未来轨迹、轨迹锚点、偏移量、未来状态图和拉普拉斯分布。S-Pool 表示社交池化[5, 6]，Spatial&Temporal 表示空间和时间学习[7]，SA 和 DPA 表示自注意力和点积注意力。XFMR 是 transformer 的缩写。

|  | 输入模态 | 输出模态 | 建模 |
| --- | --- | --- | --- |
| 模型 | $\displaystyle{\mathbb{S}}$ 表示 | 场景表示 | 额外 | 输出 | $\displaystyle{\mathbb{S}}$ 编码 | 场景编码 | 交互 |
| DESIRE[8] | CSDTS | BEV | - | $\uptau_{tar}$, $\Delta$, Score | GRU, CVAE | ConvNet | S-Pool |
| MTP[9] | BEV | 状态 | $\uptau_{tar}$, $\Pr(\cdot)$ | MobileNetV2[10] | - |
| MultiPath[11] | BEV | - | $\uptau_{tar}$, $\Pr(\cdot)$, $\mu$, $\sigma$ | ResNet[12] | CNN |
| CoverNet[13] | BEV | 状态 | $\uptau_{tar}$, $\Pr(\cdot)$ | ResNet[12] | - |
| VectorNet[14] | $\vec{Polyline}$ | - | $\uptau_{tar}$ | PointNet[15] | SA-GNN |
| TPNet[16] | BEV | - | $P(t)$, $\Delta$, $\Pr(\cdot)$ | ResNet[12] | - |
| SAMMP[17] | CSDTS | - | - | $\uptau_{tar}$ | LSTM | - | SA, RNN |
| Luo[18] | CSDTS | 车道, 点 | - | 车道, $\mu$, $\sigma$ | LSTM | 1D-Conv, MLP | DPA |
| BaiduUS[19] | CSDTS | 车道, 点 | $\Delta_{dist}$ | 车道, $\mu$, $\sigma$ | LSTM | LSTM | ST-G |
| LaneGCN[20] | CSDTS | $\vec{Polyline}$ | $\mathcal{G}_{Lane}$ | $\uptau_{tar}$, Score | 1D-Conv | LaneGCN | SA |
| DATF[21] | CSDTS | BEV | - | $\uptau_{tar}$ | LSTM | ConvNet | SA |
| SMART[22] | BEV | - | $State\_Map^{F}$ | U-Net, CVAE | S-Pool |
| PiP[23] | CSDTS | - | $\uptau_{cond}$ | $\uptau_{tar}$ | LSTM | - | S-Pool |
| TNT[4] | $\vec{Polyline}$ | - | $\uptau_{tar}$, Score | PointNet[15] | SA-GNN |
| WIMP[24] | CSDTS | $\vec{Polyline}$ | - | $\uptau_{tar}$ | RNN | SA | SA |
| HOME[25] | CSDTS | BEV | - | 热图, $\uptau_{tar}$ | 1D-Conv, RNN | CNN | SA |
| TPCN[7] | CSDTS | 点 | 表格 | $\uptau_{tar}$, $\Delta$ | PointNet++, 空间&时间 | - |
| LaPred[26] | CSDTS | 点 | - | $\uptau_{tar}$ | 1D-Conv, LSTM, MLP | SA |
| MMTrans[27] | CSDTS | $\vec{Polyline}$ | - | $\uptau_{tar}$ | XFMR | VectorNet | XFMR |
| ALAN[28] | $\displaystyle CSDTS_{multi}$ | 点, BEV | - | $\uptau_{tar}$ | MLP, LSTM | 1D-Conv | S-Pool |
| LaneRCNN[29] | CSDTS | 点, $\mathcal{G}_{Lane}$ | LaneRoI | $\Pr(\cdot)$, $\Delta$, $\Delta\theta$ | LaneConv, LanePool | LaneRoI |
| PRIME[30] | $\displaystyle CSDTS_{multi}$ | $\mathcal{G}_{Lane}$ | $Anchor_{T}$ | Score | 1D-Conv, RNN | bi-LSTM | SA |
| SceneTrans[31] | CSDTS | $\vec{Polyline}$ | - | $\uptau_{tar}$, $\mathcal{L}$, $\theta$ | XFMR, PointNet[15] | SA |

### III-A 表示方法

主要有两种表示类型，即图像和连续空间样本，用于描述每个车辆轨迹预测案例中的历史观察和未来预测。由于其密集特性，图像通常用于承载代理和道路观察 [8, 9, 11, 13, 16, 21, 22, 25, 28]。一些研究人员 [14, 4, 7, 26] 更喜欢在描述历史轨迹或场景上下文时使用稀疏点或多边形线。

#### III-A1 代理状态表示

由于实际检测和跟踪系统的限制，代理状态只能周期性地记录。用连续空间离散时间样本（CSDTS）表示代理状态是自然的，这些样本是包含代理状态特征的向量（或数组）。在 [8, 14, 17, 18, 19, 21, 23, 4, 24, 25, 7, 26, 27, 28, 29, 30, 31] 中，特征主要包括时间戳、在鸟瞰视图（BEV）坐标系统下的代理位置、到上一个时间戳的位移、代理的速度以及相对航向角。然而，研究人员也探讨了在 [9, 11, 13, 16, 22] 中在光栅化的 BEV 图像上勾画轨迹。近年来，图像表示在描述代理状态时并不广泛采用。

#### III-A2 场景上下文表示

与连续空间样本相比，图像是传达场景上下文的最直接表示方式，并且在许多研究中得到了探讨 [8, 9, 11, 13, 16, 21, 22, 25, 28]。道路的形状和状态在 BEV 图像中尽可能详细地可视化。有时，这种栅格化图像也被称为高分辨率（HD）地图 [14, 4]。高等人 [14] 提出了对场景上下文进行离散化并用向量表示的方案。这个新颖的想法得到了其他研究人员的迅速认可和采纳 [4, 24, 27, 31]，因为它提供了一种统一的表示方式，向量化表示的计算成本也较低。此外，一些研究 [20, 7, 29] 构建了额外的表格或图表来指示向量化场景上下文的时间和空间对应关系，这有助于在其预测模型中进行特征提取和交互建模。

#### III-A3 输出表示

一些方法专注于改善输入数据表示 [14]、建模 [18, 23, 26, 27] 以及目标函数 [28]，仅仅输出由单一模态表示的未来轨迹，表示未来位置集合 $\uptau_{tar}$。为了生成有前景的结果，方法估计额外的模态，如预测轨迹与真实值之间的偏差 [8, 16, 29]、根据预定义评分指标的预测得分 [8, 20, 4, 30]、每个轨迹预测或锚点的概率 $\Pr(\cdot)$ [9, 11, 13, 16, 29]、最终位置的概率热图 [25]，以及目标代理在目的地的航向 $\theta$ 或角度偏差 $\Delta\theta$ [29, 31]。MultiPath [11] 使用高斯混合模型（GMM）建模控制不确定性，并将 GMM 的均值 $\mu$ 和方差 $\sigma$ 作为模型输出。TPNet [16] 和 PRIME [30] 决定以多项式 $P(t)$ 的形式表达轨迹锚点或输出轨迹，而非通常的点集 $\uptau_{tar}$。

### III-B 建模

为了实现更好的预测性能，研究人员提出了具有各种架构的新模型，例如多层感知机（**MLP**）、卷积神经网络（**CNN**）、递归神经网络（**RNN**）、图神经网络（**GNN**）。我们总结了一些常见的设计选择及其在特征编码、交互建模和预测头方面的差异。还回顾了一些采用生成模型的方法。

#### III-B1 特征编码

将轨迹视为序列数据，许多论文[8, 17, 18, 19, 21, 23, 24] 提出了由**RNN** 单元组成的特征编码器，如门控递归单元（**GRU**）[32] 和长短期记忆网络（**LSTM**）。有些将**MLP** 或 1D 卷积与**RNN** 单元结合，以提取轨迹输入[25, 26, 28, 30] 或场景上下文输入[26] 的隐空间特征。**Transformer** 在自然语言处理中的巨大成功引起了部分研究人员的关注，他们将**Transformer** 模块应用于特征提取[24, 27, 31]。为了处理栅格化输入，一些工作[8, 9, 11, 13, 21, 22, 25] 直接借用了对象检测[12, 10] 和图像分割任务[33] 中的卷积特征编码器。**VectorNet**[14] 遵循**PointNet**[15] 的思路，为矢量化输入提取瞬时级特征。**TNT** [4] 直接继承了**VectorNet** 的特征提取骨干网。**Ye** 等人将离散输入视为点云，并在他们的工作中模拟点云编码[7]。**LaneGCN** [20] 和**LaneRCNN**[29] 在编码阶段引入了图卷积模块，并在基于道路连通性或时间序列构建的图中聚合特征。

#### III-B2 交互建模

车辆、行人和道路元素之间的互动非常重要且复杂。为了同时建模代理之间的互动和代理与场景的互动，研究人员通过引入场景上下文特征图[8, 22, 28]来增强[5, 6]提出的社会汇聚机制。受到注意力机制成功的启发，许多研究人员[14, 17, 18, 20, 21, 24, 25, 26, 30]设计了互动建模模块。此外，刘等[27]和 Ngiam 等[31]用多头注意力构建了整个互动模块。图建模和 GNN 层也经常涉及，因为 GNN 的消息传递可以融合不同代理（和道路元素）的特征。我们认为特征融合行为本质上与代理与道路元素之间的互动相同。唯一的例外是 TPCN[7]没有明确考虑互动建模，但仍然实现了良好的性能。

#### III-B3 预测头

一些研究人员通过隐马尔可夫模型表征预测，并使用 RNN 生成轨迹预测[8, 17, 18, 21, 23, 24]。其他研究人员将预测视为回归过程，并在[14, 9, 19, 20, 4, 25, 26, 27, 29, 30, 31]中用 MLP 解码特征。受到计算机视觉领域锚点提议概念[34, 35]的显著影响，许多研究人员在其预测头中添加了分类分支，以预测每个提议轨迹锚点的概率或置信度分数[11, 16, 18, 20, 23, 4, 26, 27, 31, 29]。受到深度学习模型对未见情况预测不确定性的启发，CoverNet[13]和 PRIME[30]进一步部署了基于模型的规划器，以提出满足车辆和场景上下文运动学约束的轨迹锚点。

#### III-B4 生成模型

DESIRE[8]和 SMART[22]将轨迹预测视为条件采样和选择过程。识别模块首先将轨迹观察和预测真实值投影到潜在空间。潜在变量 $z$ 被假设满足由识别模块编码的分布先验。然后，条件解码器从给定的条件输入和潜在变量 $z$ 中恢复未来轨迹。然而，无法获得从生成模型中采样的每个轨迹的可能性。DESIRE 设计了排名和精炼模块来评估从 CVAE 模块生成的轨迹。

### III-C 学习与目标函数

大多数提出的深度学习模型都是以监督的方式进行训练的。交叉熵（CE）损失、平滑-L1（Huber）损失、负对数似然（NLL）损失和均方误差（MSE）损失都是训练过程中常用的目标函数。研究人员使用一些训练技巧并提出新技术或目标函数，以便模型能够收敛到更优的解。

MultiPath[11] 采用无监督学习方法来寻找合适的轨迹锚点，并通过模仿学习对其模型进行训练。VectorNet[14] 设计了一种辅助图补全损失，以鼓励互动模块捕捉更好的见解。TNT[4] 基于其单模态假设通过教师强迫技术[36] 训练轨迹回归器。

将真实轨迹标记为某一特定轨迹，同时预测不同输出的模型会遇到模式崩溃问题[37, 38]，导致无法进行多模态预测。为了解决这个问题，一些研究人员提出了新颖的目标函数或引入了新函数。MTP[9]旨在最小化多轨迹预测损失，可以视为[39]中提出的赢家通吃（WTA）损失的一种变体：

|  | $\mathcal{L}^{MTP}=-\sum_{i=1}^{K}I_{i^{*}}\log{p_{i}}+\alpha\sum_{i=1}^{K}I_{i^{*}}L(\tau_{gt},\tau_{i}),$ |  | (1) |
| --- | --- | --- | --- |

其中 $I_{i^{*}}$ 是一个二进制指示符，如果 $i^{*}$ 模式根据任意轨迹距离函数最接近真实轨迹则为 1，否则为 0，$p_{i}$ 是最佳模式 $i^{*}$ 的概率，$L(\cdot,\cdot)$ 表示任意位移误差函数，$\alpha$ 是一个加权回归损失的系数。一些研究人员也在他们的工作中引入了 WTA 损失[20, 24, 31]。Narayanan 等人[28]提出了一种分治（DAC）初始化技术，以稳定带有 WTA 损失的训练。使用 DAC 训练的模型在他们的工作中超越了其他竞争者。

## IV TNT 方法的实现

TNT[4]作为 VectorNet[14]的扩展，以其良好的模型可解释性和出色的性能引起了我们的兴趣。然而，由于知识产权问题，官方代码已公开。为了促进在车辆轨迹预测中使用向量和图表示的探索，我们根据对 TNT[4]方法的理解实现了我们版本的 TNT[4]，并公开了我们的实现。

我们的代码是用 Pytorch 和 Pytorch Geometric 库实现的。严格按照[14, 4]中的细节，我们实现了 VectorNet 特征提取骨干网和 TNT 预测头。这三个预测头，即目标候选预测头、目标条件轨迹预测头和评分头，都由 2 层 MLP 模型建模。目标候选预测模块由两个 2 层 MLP 组成，一个用于预测目标位置的离散分布，另一个用于预测与每个目标候选者对应的最可能的偏移量。在我们的设计中，目标条件轨迹预测模块由一个 2 层 MLP 实现，但它在每个批次的损失计算中涉及两次。第一次，MLP 根据被视为教师强制训练的实际最终位置预测轨迹。然后，MLP 预测 M 条轨迹，这些轨迹将由评分模块根据 M 选定的目标候选者进行评分。

在实现 TNT[4]的过程中，我们发现对一些设计选择和超参数的描述模糊或缺失。我们提出了适当的解决方案来填补这些空白，并在本节剩余部分简要介绍：

数据归一化：如[14]中提到的，我们将每个数据序列中的坐标集中在目标代理的最后观察位置。此外，我们应用了[17, 29, 31]中描述的航向归一化。轨迹和场景上下文表示被旋转，以确保目标代理在最后观察位置的航向与 x 轴对齐。

目标候选者：根据[4]中的描述，TNT 采用等距离的目标候选者采样方法，并沿候选中心线进行。作者以$1000$个目标候选者作为示例。值得注意的是，目标候选者的数量在序列中可能会有所不同，因为未来目标代理的可能旅行距离和区域可能会有所不同。统一的候选者数量可能无法覆盖足够的区域来预测未来目标。在我们的代码中，我们实现了等距离采样策略，并为每个序列采样不同数量的目标候选者。

非极大值抑制（NMS）：受到物体检测的启发，TNT[4] 根据预测分数和与选定轨迹的距离筛选 M 个多模态预测。这些 M 个轨迹首先按预测分数排序，然后如果它们与选定轨迹的距离超过某个阈值，则被贪婪地选择。然而，决定近似重复轨迹的精确距离阈值在他们的论文中没有给出。在这里，我们实现了一个硬阈值策略。具体而言，只有超过距离阈值的轨迹才会被选择，如果没有更多轨迹的距离足够远，则用全零轨迹填充剩余的槽位。

尽管尚未获得与[4]完全相同的结果，但我们的实现仍然表现出色。迄今为止取得的结果见于第 V 节。

## V 实验

本节组织如下。首先，介绍几个常用的数据集。其次，我们展示实验评估所使用的现有指标。此外，我们列出了常用的预处理技巧和数据增强策略。最后，展示了最近提出方法的详细比较。

表 II：Argoverse 数据集上的轨迹预测性能

验证集 测试集 k=1 k=6 k=1 k=6 模型 minADE^† minFDE^† MR^‡ minADE minFDE MR minADE minFDE MR minADE minFDE MR DAC VectorNet[14] 1.66 3.67 - - - - 1.81 4.01 - - - - - TPNet[16] 1.75 3.88 - - - - 2.23 4.70 - 1.61 3.28 - 0.96 Luo[18] 1.60 3.64 - 1.35 2.68 - 1.91 4.31 0.66 0.99 1.71 0.19 0.98 LaneGCN[20] 1.35 2.97 - 0.71 1.08 - 1.71 3.78 0.59 0.87 1.36 0.16 - SMART[22] - - - 1.44 2.47 - - - - - - - - TNT[4] - - - 0.73 1.29 0.09 - - - 0.94 1.54 0.13 - WIMP[24] 1.45 3.19 - 0.75 1.14 0.12 1.82 4.03 - 0.90 1.42 0.17 - HOME[25] - 3.02 0.51 - 1.28 0.07 1.73 3.73 0.58 0.94 1.45 0.10 - TPCN[7] 1.34 2.95 0.50 0.73 1.15 0.11 1.66 3.69 0.59 0.87 1.38 0.16 - LaPred[26] 1.48 3.29 - 0.71 1.44 - - - - - - - - MMTrans[27] - - - 0.71 1.15 0.11 - - - 0.84 1.34 0.15 - LaneRCNN[29] 1.33 2.85 - 0.77 1.19 0.08 1.69 3.69 0.57 0.90 1.45 0.12 - PRIME[30] - - - - - - 1.91 3.82 0.59 1.22 1.56 0.12 - SceneTrans[31] - - - - - - - - - 0.80 1.23 0.13 - 我们 - - - 1.11 2.12 0.31 - - - - - - - $\star$ minADE/ minFDE: 单位为米 $\ddagger$ MR: 端点误差的阈值为 2 米

### V-A 数据集

Argoverse Argoverse 数据集[40]是最常用于运动预测实验的数据集。它包含了匹兹堡和迈阿密的超过 30 万场景。每个场景包含了不同对象在 10 Hz 下的二维鸟瞰图心点。运动预测的任务是根据前 2 秒的轨迹以及通过 Argoverse API 访问的高清地图特征，预测接下来 3 秒内的单一代理类型对象的轨迹。整个数据集可以分为 208,272 个训练序列，40,127 个验证序列和 79,391 个测试序列。在训练和验证中，提供完整的 5 秒轨迹。而在测试中，只提供前 2 秒的轨迹。

NuScenes NuScenes 是一个公开的大规模自动驾驶数据集[41]。轨迹以 2 Hz 的频率在 x-y 坐标系统中表示。原始驾驶场景在波士顿和新加坡收集，分别适用右侧和左侧交通规则。最多可以利用 2 秒的过去历史来预测每个代理的 6 秒长的未来轨迹。

NGSIM 下一代模拟[42]数据集是通过高架数字视频摄像机从实际高速公路驾驶场景中提取的。每辆车的位置以 10 Hz 的频率记录。由于数据集不是纯粹为了轨迹预测而发布的，因此过去观察和预测的长度可以自定义。

### V-B 指标

一些常用的指标如下。

FDE(K) 最终位移误差（K）指的是预测轨迹终点与真实值终点之间的 L2 距离，在最佳 K 次预测中计算。

ADE(K) 平均位移误差（K）指的是在最佳 K 次预测中，整个预测轨迹与真实值之间的逐点 L2 距离的平均值。

MR 漏检率评估所有提出的解决方案中不可接受输出的比例。当最佳轨迹的终点误差大于 2.0 米时，通常将一个场景定义为漏检。

一些论文提出了与其创新方法相对应的若干特定指标。

DAC 可驱动区域合规性[16, 18, 21]等于在可驱动区域内的未来轨迹数量除以所有可能轨迹的数量。DAC 评估提出解决方案的可行性。

### V-C 预处理和增强

中心化 为了减少预测的复杂性，选择将代表轨迹的坐标系统原点设置为最后观察时间戳的预测代理位置[13, 14, 17, 29, 31]。

**标题归一化** 标题归一化意味着轨迹表示的坐标系统被旋转[13, 17, 29, 31]，以使最后观察时间戳的预测代理的方向与 x 轴对齐。

**场景旋转** 为了对抗过拟合并提高泛化能力，通常对整个场景及其中心化后的轨迹坐标进行随机旋转[8, 25, 29, 31]。

**代理丢弃** 如常见的情况一样，一个场景中可能存在过多的代理，其中一些并不值得关注。在[31]中，非预测代理以 0.1 的概率被人工移除。

### **第 V-D 部分 结果**

本节对上述方法的结果进行了比较。由于 Argoverse 是最常用的数据集，为了公平比较，我们仅比较 Argoverse 中的实验结果。所有数据均来自已发布的论文，并列在表 II 中。

**场景变换器**[31]在按 minADE(K=6)和 minFDE(K=6)排序的结果中排名第一，而在按 MR(K=6)排序时，第一名属于[25]。这两种方法都使用了注意力模块来建模代理与环境之间的交互，这为交互表示提供了有前途的解决方案。通常会观察到其他方法（TNT[4], WIMP[24], HOME[25], TPCN[7], MMTrans[27], 和 laneRCNN[29）在测试集上应用时性能下降。我们在 Argoverse 的验证集上评估了我们的 TNT 实现。与最先进的方法相比，我们在 minADE 上差 0.4 米，在 minFDE 上差 1.04 米，在 MR 上差 0.24。预计通过引入 WTA 损失或车道注意力策略可以改善性能。

## **第 VI 部分 结论**

在这项工作中，我们对现有的车辆轨迹预测方法进行了彻底的回顾。从预测问题的数学公式出发，我们将复杂的预测任务分解为三个组成部分：表示、建模以及学习和目标函数。从 MLP 到 CNN、RNN、GNN 的模块组成了预测网络的组成部分，即特征编码、交互建模和预测头。我们还将我们的 TNT 版本公开，并详细介绍了实现方法。对 Argoverse 数据集结果的公平比较以及指标和预处理技巧的列表在本工作末尾进行了说明。预计在我们工作的帮助下，轨迹预测的准确性或效率将有所提升。

## **致谢**

本工作部分由深圳市机器人感知与智能重点实验室、南方科技大学（中国深圳 518055）、香港研究资助局 CRF 资助 C4063-18G、香港研究资助局 GRF 资助#14200618 支持。

## 参考文献

+   [1] A. Ess, K. Schindler, B. Leibe, 和 L. Van Gool，“动态环境中自主导航的物体检测与跟踪，”*国际机器人研究期刊*，第 29 卷，第 14 期，页 1707–1725，2010。

+   [2] S. Pellegrini, A. Ess, 和 L. Van Gool，“预测行人轨迹，”发表于*视觉人类分析*。 Springer，2011，页 473–491。

+   [3] M. Luber, J. A. Stork, G. D. Tipaldi, 和 K. O. Arras，“基于社会力的人的运动预测进行行人跟踪，”发表于*2010 年 IEEE 国际机器人与自动化会议*。 IEEE，2010，页 464–469。

+   [4] H. Zhao, J. Gao, T. Lan, C. Sun, B. Sapp, B. Varadarajan, Y. Shen, Y. Shen, Y. Chai, C. Schmid *等*，“TNT: 目标驱动的轨迹预测，”*arXiv 预印本 arXiv:2008.08294*，2020。

+   [5] A. Alahi, K. Goel, V. Ramanathan, A. Robicquet, L. Fei-Fei, 和 S. Savarese，“Social lstm: 拥挤空间中的人类轨迹预测，”发表于*IEEE 计算机视觉与模式识别会议论文集*，2016，页 961–971。

+   [6] A. Gupta, J. Johnson, L. Fei-Fei, S. Savarese, 和 A. Alahi，“Social GAN: 使用生成对抗网络生成社会可接受的轨迹，”发表于*IEEE 计算机视觉与模式识别会议论文集*，2018，页 2255–2264。

+   [7] M. Ye, T. Cao, 和 Q. Chen，“tpcn: 用于运动预测的时序点云网络，”发表于*IEEE/CVF 计算机视觉与模式识别会议论文集*，2021，页 11 318–11 327。

+   [8] N. Lee, W. Choi, P. Vernaza, C. B. Choy, P. H. Torr, 和 M. Chandraker，“Desire: 在动态场景中与交互体的远期预测，”发表于*IEEE 计算机视觉与模式识别会议论文集*，2017，页 336–345。

+   [9] H. Cui, V. Radosavljevic, F.-C. Chou, T.-H. Lin, T. Nguyen, T.-K. Huang, J. Schneider, 和 N. Djuric，“利用深度卷积网络进行自主驾驶的多模态轨迹预测，”发表于*2019 年国际机器人与自动化会议（ICRA）*。 IEEE，2019，页 2090–2096。

+   [10] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, 和 L.-C. Chen，“Mobilenetv2: 反向残差和线性瓶颈，”发表于*IEEE 计算机视觉与模式识别会议论文集*，2018，页 4510–4520。

+   [11] Y. Chai, B. Sapp, M. Bansal, 和 D. Anguelov，“Multipath: 多重概率锚点轨迹假设用于行为预测，”*arXiv 预印本 arXiv:1910.05449*，2019。

+   [12] K. He, X. Zhang, S. Ren, 和 J. Sun，“用于图像识别的深度残差学习，”发表于*IEEE 计算机视觉与模式识别会议论文集*，2016，页 770–778。

+   [13] T. Phan-Minh, E. C. Grigore, F. A. Boulton, O. Beijbom, 和 E. M. Wolff, “Covernet: 使用轨迹集进行多模态行为预测，”在*IEEE/CVF 计算机视觉与模式识别会议论文集*中，2020，第 14 074–14 083 页。

+   [14] J. Gao, C. Sun, H. Zhao, Y. Shen, D. Anguelov, C. Li, 和 C. Schmid, “Vectornet: 从矢量化表示编码高清地图和智能体动态，”在*IEEE/CVF 计算机视觉与模式识别会议论文集*中，2020，第 11 525–11 533 页。

+   [15] C. R. Qi, H. Su, K. Mo, 和 L. J. Guibas, “Pointnet: 深度学习点集用于 3D 分类和分割，”在*IEEE 计算机视觉与模式识别会议论文集*中，2017，第 652–660 页。

+   [16] L. Fang, Q. Jiang, J. Shi, 和 B. Zhou, “Tpnet: 用于运动预测的轨迹提议网络，”在*IEEE/CVF 计算机视觉与模式识别会议论文集*中，2020，第 6797–6806 页。

+   [17] J. Mercat, T. Gilles, N. El Zoghby, G. Sandou, D. Beauvois, 和 G. P. Gil, “用于多模态联合车辆运动预测的多头注意力，”在*2020 IEEE 国际机器人与自动化会议（ICRA）*中。 IEEE, 2020，第 9638–9644 页。

+   [18] C. Luo, L. Sun, D. Dabiri, 和 A. Yuille, “具有车道注意力的概率性多模态轨迹预测用于自动驾驶车辆，”在*2020 IEEE/RSJ 国际智能机器人与系统会议（IROS）*中。 IEEE, 2020，第 2370–2376 页。

+   [19] J. Pan, H. Sun, K. Xu, Y. Jiang, X. Xiao, J. Hu, 和 J. Miao, “车道注意力: 通过学习车道上的注意力预测车辆移动轨迹，”在*2020 IEEE/RSJ 国际智能机器人与系统会议（IROS）*中。 IEEE, 2020，第 7949–7956 页。

+   [20] M. Liang, B. Yang, R. Hu, Y. Chen, R. Liao, S. Feng, 和 R. Urtasun, “学习车道图表示进行运动预测，”在*欧洲计算机视觉会议*上。 Springer, 2020, 第 541–556 页。

+   [21] S. H. Park, G. Lee, J. Seo, M. Bhat, M. Kang, J. Francis, A. Jadhav, P. P. Liang, 和 L.-P. Morency, “通过多模态上下文理解实现多样化且可接受的轨迹预测，”在*欧洲计算机视觉会议*上。 Springer, 2020, 第 282–298 页。

+   [22] N. Sriram, B. Liu, F. Pittaluga, 和 M. Chandraker, “Smart: 同时多智能体递归轨迹预测，”在*欧洲计算机视觉会议*上。 Springer, 2020, 第 463–479 页。

+   [23] H. Song, W. Ding, Y. Chen, S. Shen, M. Y. Wang, 和 Q. Chen, “Pip: 基于规划的轨迹预测用于自动驾驶，”在*欧洲计算机视觉会议*上。 Springer, 2020, 第 598–614 页。

+   [24] S. Khandelwal, W. Qi, J. Singh, A. Hartnett, 和 D. Ramanan, “自动驾驶的‘如果-那么’运动预测，”*arXiv 预印本 arXiv:2008.10587*，2020。

+   [25] T. Gilles, S. Sabatini, D. Tsishkou, B. Stanciulescu, 和 F. Moutarde, “Home: 用于未来运动估计的热图输出，”*arXiv 预印本 arXiv:2105.10968*，2021。

+   [26] B. Kim, S. H. Park, S. Lee, E. Khoshimjonov, D. Kum, J. Kim, J. S. Kim, 和 J. W. Choi，“Lapred：面向车道的动态体的多模态未来轨迹预测，”收录于*IEEE/CVF 计算机视觉与模式识别会议论文集*，2021 年，第 14 636–14 645 页。

+   [27] Y. Liu, J. Zhang, L. Fang, Q. Jiang, 和 B. Zhou，“使用堆叠变换器的多模态运动预测，”收录于*IEEE/CVF 计算机视觉与模式识别会议论文集*，2021 年，第 7577–7586 页。

+   [28] S. Narayanan, R. Moslemi, F. Pittaluga, B. Liu, 和 M. Chandraker，“面向车道的多样化轨迹预测的分而治之方法，”收录于*IEEE/CVF 计算机视觉与模式识别会议论文集*，2021 年，第 15 799–15 808 页。

+   [29] W. Zeng, M. Liang, R. Liao, 和 R. Urtasun，“Lanercnn：面向图中心运动预测的分布式表示，”*arXiv 预印本 arXiv:2101.06653*，2021 年。

+   [30] H. Song, D. Luan, W. Ding, M. Y. Wang, 和 Q. Chen，“基于模型的规划学习预测车辆轨迹，”*arXiv 预印本 arXiv:2103.04027*，2021 年。

+   [31] J. Ngiam, B. Caine, V. Vasudevan, Z. Zhang, H.-T. L. Chiang, J. Ling, R. Roelofs, A. Bewley, C. Liu, A. Venugopal *等*，“场景变换器：用于行为预测和规划的统一多任务模型，”*arXiv 预印本 arXiv:2106.08417*，2021 年。

+   [32] K. Cho, B. Van Merriënboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, 和 Y. Bengio，“使用 rnn 编码器-解码器学习短语表示用于统计机器翻译，”*arXiv 预印本 arXiv:1406.1078*，2014 年。

+   [33] O. Ronneberger, P. Fischer, 和 T. Brox，“U-net：用于生物医学图像分割的卷积网络，”收录于*国际医学图像计算与计算机辅助干预会议*。Springer，2015 年，第 234–241 页。

+   [34] D. Erhan, C. Szegedy, A. Toshev, 和 D. Anguelov，“使用深度神经网络的可扩展物体检测，”收录于*IEEE 计算机视觉与模式识别会议论文集*，2014 年，第 2147–2154 页。

+   [35] S. Ren, K. He, R. Girshick, 和 J. Sun，“Faster r-cnn：朝向实时物体检测的区域提议网络，”*神经信息处理系统进展*，第 28 卷，第 91–99 页，2015 年。

+   [36] R. J. Williams 和 D. Zipser，“用于持续运行的全递归神经网络的学习算法，”*神经计算*，第 1 卷，第 2 期，第 270–280 页，1989 年。

+   [37] N. Rhinehart, K. M. Kitani, 和 P. Vernaza，“R2p2：用于多样化、精确生成路径预测的重新参数化推送策略，”收录于*欧洲计算机视觉会议（ECCV）论文集*，2018 年，第 772–788 页。

+   [38] J. Hong, B. Sapp, 和 J. Philbin，“道路规则：通过语义交互的卷积模型预测驾驶行为，”收录于*IEEE/CVF 计算机视觉与模式识别会议论文集*，2019 年，第 8454–8462 页。

+   [39] S. Lee, S. P. S. Prakash, M. Cogswell, V. Ranjan, D. Crandall, 和 D. Batra， “用于训练多样化深度集成的随机多选学习，” 收录于*神经信息处理系统进展*，2016 年，第 2119–2127 页。

+   [40] M.-F. Chang, J. W. Lambert, P. Sangkloy, J. Singh, S. Bak, A. Hartnett, D. Wang, P. Carr, S. Lucey, D. Ramanan, 和 J. Hays， “Argoverse：具有丰富地图的 3D 跟踪与预测，” 收录于*计算机视觉与模式识别会议（CVPR）*，2019 年。

+   [41] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, A. Krishnan, Y. Pan, G. Baldan, 和 O. Beijbom， “nuscenes：用于自动驾驶的多模态数据集，” 收录于*IEEE/CVF 计算机视觉与模式识别会议论文集*，2020 年，第 11 621–11 631 页。

+   [42] J. C. John Halkias， “下一代模拟信息表，” 联邦公路管理局（FHWA），2006 年。
