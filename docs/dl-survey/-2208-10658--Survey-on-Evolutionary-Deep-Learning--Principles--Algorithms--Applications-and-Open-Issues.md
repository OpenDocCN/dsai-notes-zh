<!--yml

分类：未分类

日期：2024-09-06 19:44:42

-->

# [2208.10658] 关于进化深度学习的调查：原理、算法、应用及开放问题

> 来源：[`ar5iv.labs.arxiv.org/html/2208.10658`](https://ar5iv.labs.arxiv.org/html/2208.10658)

\UseRawInputEncoding

# 关于进化深度学习的调查：原理、算法、应用及开放问题

Nan Li Northeastern UniversityNo.195, Chuangxin RoadShenyangLiaoning ProvinceChina 2010500@stu.neu.edu.cn ,  Lianbo Ma Northeastern UniversityNo.195, Chuangxin RoadShenyang CityLiaoning ProvinceChina malb@swc.neu.edu.cn ,  Guo Yu East China University of Science and TechnologyMeilong Road 130ShanghaiChina guoyu@ecust.edu.cn ,  Bing Xue Victoria University of WellingtonWellingtonNew Zealand bing.xue@ecs.vuw.ac.nz ,  Mengjie Zhang Victoria University of WellingtonWellingtonNew Zealand mengjie.zhang@ecs.vuw.ac.nz  and  Yaochu Jin Bielefeld UniversityBielefeldGermany yaochu.jin@uni-bielefeld.de

###### 摘要。

近年来，深度学习（DL）在工业和学术界都取得了快速发展。然而，找到深度学习模型的最佳超参数通常需要高计算成本和人类专业知识。为了缓解上述问题，进化计算（EC）作为一种强大的启发式搜索方法，在深度学习模型的自动设计中表现出了显著的优势，这被称为进化深度学习（EDL）。本文旨在从自动化机器学习（AutoML）的角度分析 EDL。具体而言，我们首先从机器学习和 EC 的角度阐明 EDL，并将 EDL 视为一个优化问题。根据 DL 管道，我们系统地介绍了从特征工程、模型生成到模型部署的 EDL 方法，并提出了一种新的分类方法（即，如何演化/优化），重点讨论了在处理优化问题时 EC 的解表示和搜索范式。最后，提出了关键应用、开放问题以及潜在的未来研究方向。本文回顾了 EDL 的最新进展，并为 EDL 的发展提供了有价值的指导。

深度学习，进化计算，特征工程，模型生成，模型部署。^†^†ccs: 一般和参考 调查与概述^†^†ccs: 计算方法 机器学习算法^†^†ccs: 计算理论 进化算法

## 1\. 引言

深度学习（DL）作为一种前景广阔的技术，已经广泛应用于各种具有挑战性的任务，如图像分析（Krizhevsky et al., 2012）和模式识别（LeCun et al., 2015）。然而，DL 的从业者在手动设计深度模型和通过试错找到合适的配置时面临困难。图中 1 展示了一个例子，其中领域知识在不同阶段被输入到 DL 中，例如特征工程（FE）（Xue et al., 2015）、模型生成（Zhou et al., 2021a）和模型部署（Choudhary et al., 2020; Cheng et al., 2017）。不幸的是，专家知识获取的困难使得 DL 在发展过程中面临巨大挑战。

相比之下，深度神经网络（DNNs）的自动设计在近几十年内趋于流行（He et al., 2021; Zhou et al., 2021a）。主要原因在于自动化机器学习（AutoML）在特征工程（FE）（Xue et al., 2015）、参数优化（PO）（Zhang 和 Gouza, 2018）、超参数优化（HPO）（Stanley 和 Miikkulainen, 2002）、神经架构搜索（NAS）（Yao et al., 2018; He et al., 2021; Zhou et al., 2021a）和模型压缩（MC）（Hu et al., 2021b）中的灵活性和计算效率。因此，AutoML 在没有人工干预的情况下引起了广泛关注，并取得了很大进展。

![参见说明](img/157981cf4645442887259fefbd7ba762.png)

图 1. DL 的概述，由领域知识或进化计算驱动，其中 DL 的生命周期经历了问题、数据收集、特征工程、模型生成和模型部署。

进化计算（EC）由于其灵活性和自动演化机制，已广泛应用于自动深度学习（DL）。在 EC 中，一组个体通过环境选择驱动向最优解或前沿演化（Jin，2006）。目前，许多自动 DL 方法是由 EC 驱动的，称为进化深度学习（EDL）（Telikani 等，2021；Evans 等，2018a；Zhang 和 Cagnoni，2020；Zhang，2018）。例如，已经有许多关于 EC 的研究涉及特征工程（Xue 等，2015）、模型生成（姚等，2018；周等，2021a）和模型部署（Choudhary 等，2020），如图 1 所示。因此，EC 和 DL 的结合已成为学术界和工业界的热门研究主题。此外，在图 2 中，涉及 EC 和 DL 的出版物和引用数量从 Web of Science 起逐年增加，直到大约 2012 年，而在接下来的十年中急剧上升。因此，越来越多的研究人员开始从事 EDL 领域的研究。

![参见图注](img/e00f51b178cb0629a960e5ee4e773716.png)

图 2. 从 Web of Science 到 2022 年 7 月涉及 EC 和 DL 的总出版物和引用数量。

表 1. 现有调查与我们工作的比较，其中 FE、PO、HPO、NAS 和 MC 分别表示特征工程、参数优化、超参数优化、神经架构搜索和模型压缩。 “✓” 和 “-” 分别表示论文中是否包含该内容。

| 调查 | 类型 | FE | PO | HPO | NAS | MC \bigstrut |
| --- | --- | --- | --- | --- | --- | --- |
| (姚等，2018) | AutoML | ✓ | - | ✓ | ✓ | - \bigstrut[t] |
| (He 等，2021) | AutoML | ✓ | - | ✓ | ✓ | - |
| (姚，1993) | NAS | - | ✓ | ✓ | ✓ | - |
| (Ren 等，2021) | NAS | - | - | ✓ | ✓ | - |
| (Jaâfra 等，2019) | NAS | - | - | ✓ | ✓ | - |
| (Santra 等，2021) | NAS | - | - | ✓ | ✓ | - |
| (Telikani 等，2021) | EDL | - | - | - | ✓ | - |
| (刘等，2021b) | EDL | - | ✓ | ✓ | ✓ | - |
| (周等，2021a) | EDL | - | ✓ | ✓ | - |
| (Xue 等，2015) | EDL | ✓ | - | - | - | - |
| (Al-Sahaf 等，2019) | EDL | ✓ | ✓ | - | - | - |
| (Zhang 等，2011) | EDL | - | ✓ | ✓ | ✓ | - |
| (Alexandropoulos 和 Aridas，2019) | EDL | ✓ | - | ✓ | ✓ | - |
| (Mirjalili 等，2019) | EDL | ✓ | ✓ | ✓ | ✓ | - |
| (Darwish 等， 2020) | EDL | - | ✓ | ✓ | ✓ | - |
| (Freitas, 2003) | EDL | - | ✓ | ✓ | ✓ | - |
| 我们的 | EDL | ✓ | ✓ | ✓ | ✓ | ✓\bigstrut[b] |

在表格 1 中，我们列出了关于自动深度学习的近期调查。大量的调查集中在深度学习模型的优化（He 等，2021；Telikani 等，2021；Zhou 等，2021a；Xue 等，2015），或神经架构搜索（Liu 等，2021b；Yao，1993）。许多其他研究关注特定的优化范式，如强化学习（RL）（Jaâfra 等，2019），进化计算（EC）（Sun 等，2020）和梯度（Santra 等，2021）。然而，很少有研究系统地分析了进化深度学习（EDL）并涵盖了特征工程（FE）、超参数优化（HPO）、神经架构搜索（NAS）和模型选择（MC）。为填补这一空白，我们旨在详细综述 EDL。这项工作的主要贡献如下。

+   •

    从深度学习和进化计算的角度回顾现有的 EDL 工作，以促进机器学习和进化计算社区读者的理解，我们还从进化计算的角度将 EDL 形式化为一个优化问题。

+   •

    该调查从一种新的分类法角度描述和讨论了 EDL，重点强调并系统地讨论了解决方案表示和搜索范式。据我们所知，少有调查研究了进化模型部署。

+   •

    基于对 EDL 方法的全面综述，讨论了多个应用、开放问题和 EDL 的趋势，这将指导 EDL 的发展。

本文其余部分的组织结构如下。第二部分介绍了进化深度学习的概述。在第三部分中介绍了 EC 驱动的特征工程。第四部分讨论了 EC 驱动的模型生成。第五部分回顾了 EC 驱动的模型压缩。之后，在第六部分中讨论了相关应用、开放问题和进化深度学习的趋势。最后，在第七部分中对本文进行了总结。

## 2\. 进化深度学习概述

### 2.1\. 深度学习

深度学习可以被描述为三元组$M$ = ($D$, $T$, $P$) (Yao et al., 2018)，其中$D$是用于训练深度模型($M$)的数据集，$T$是目标任务。$P$表示$M$的性能。深度学习的目标是提升其在特定任务$T$上的性能，这通过在数据集$D$上测量$P$来实现。在图 1 中，我们可以看到深度学习的三个基本过程，即特征工程、模型生成和模型部署。

特征工程：它旨在寻找一个高质量的$D$来提升深度模型($M$)在特定任务($T$)上的性能($P$)。在实际应用中，$D$的特征空间可能包含冗余和噪声信息，这会损害模型($M$)的性能($P$)。在前列腺数据集上，(Tran et al., 2018)中选择的特征子集的大小（65）仅占特征总大小（10509）的 1%。

模型生成：旨在优化/生成具有理想性能（$P$）的模型（$M$），以执行特定任务（$T$）在给定的数据集（$D$）上（He 等， 2021）。模型生成可以进一步分为参数优化、模型架构优化和联合优化（Zhou 等， 2021a）。参数优化是为预定义的模型搜索最佳参数（例如权重）。架构优化致力于寻找深度模型（$M$）的最佳网络拓扑（例如层数和操作类型）（Luo 等， 2018）。联合优化通过在数据集（$D$）上自动搜索强大的模型（$M$）来涉及上述两个优化问题（Miikkulainen 等， 2019）。

模型部署：此过程旨在将深度模型（$M$）部署以在有限的计算预算内解决一个部署任务（$T$），并在输入数据（$D$）上达到可接受的性能（$P$）。模型部署的关键问题是当深度模型的参数数量很大时如何减少延迟、存储和能耗，例如 Transformer-XL Large 有 257M 参数（Dowdell 和 Zhang， 2020）。

### 2.2\. 进化计算

EC 是一种基于随机种群的搜索方法，灵感来源于自然选择和遗传学等进化机制，它不需要梯度信息，能够处理没有明确数学公式的黑箱优化问题（Ma 等， 2022; Vargas-Hákim 等， 2022）。由于上述特点，EC 已被广泛应用于深度学习的自动设计。

![参考说明](img/43778ec24fd8eb2d2ec7491b539a713d.png)

图 3. EC 的通用框架。

原则上，我们可以将 EC 方法大致分为两类：进化算法（EA）和群体智能（SI）（Zhou 等， 2021a）。我们的工作没有明确区分 EA 和 SI，因为它们符合一个通用框架，如图 3 所示，该框架由三个主要组件组成。

初始化：

进行以生成一群个体，这些个体根据优化问题的决策空间（或搜索空间和变量空间）进行编码，如特征集、模型参数和拓扑结构。

评估：

旨在计算个体的适应度。实际上，在 EDL 中评估个体是一个计算密集的任务（Miahi 等， 2022）。例如，工作（Real 等， 2017）使用了 3000 个 GPU 天来寻找理想的架构。

更新：

旨在通过各种繁殖运算生成许多后代解决方案。例如，通过粒子群优化（PSO）中的速度和位置公式生成功能解（Tran 等人，2018）。对于遗传算法（GA），使用一些繁殖算子（例如交叉和变异）来生成新的个体（Vafaie 和 De Jong，1998）。

### 2.3\. 进化深度学习

#### 2.3.1\. EDL 的两个视角

与传统的依赖专家或领域知识构建深度模型的 DL 相比，EDL 是通过进化过程自动设计深度模型的。（Sun 等人，2020; Yao，1993; Ren 等人，2021; Zhang，2018）。

从 DL 的角度来看：传统的 DL 需要很多专家知识来发明和分析特定数据集或任务的学习工具。相反，EDL 可以被看作是一个人性化的学习工具，可以在给定的数据集或任务上自动找到合适的深度模型（Yao 等人，2018）。换句话说，EDL 关注的是学习工具的易用性。

从 EC 的角度：模型的配置表示为一个个体，性能作为要优化的目标。 EC 在以进化机制驱动的优化中起着重要作用。也就是说，EDL 可以被看作是一个进化优化过程，以找到具有高性能的深度模型的最优配置。

从上述分析可知，EDL 不仅通过自动构建方法（从 DL 的角度）旨在增加深度模型对学习任务的适应性，而且还试图在设计的目标或约束条件下实现最优模型（从 EC 的角度）。

#### 2.3.2\. EDL 的定义和框架

根据第 2.3.1 小节中的讨论和随后的（Yao 等人，2018）我们可以如下定义 EDL。

| (1) |  | <math   alttext="\begin{array}[]{l}\begin{array}[]{*{20}{c}}{\mathop{{\rm{Max}}}\limits_{config.}}&amp;{{\textrm{Learning tools' performance,}}}\end{array}\\ \begin{array}[]{*{20}{c}}{s.t.}&amp;{\left\{{\begin{array}[]{*{20}{c}}{{\textrm{No assistance from humans}}}\\

\begin{array}[]{l}\begin{array}[]{*{20}{c}}{\mathop{{\rm{Max}}}\limits_{config.}}&{{\textrm{学习工具的性能，}}}\end{array}\\ \begin{array}[]{*{20}{c}}{s.t.}&{\left\{{\begin{array}[]{*{20}{c}}{{\textrm{没有人工帮助}}}\\ {{\textrm{有限的计算预算。}}}\end{array}}\right.}\end{array}\end{array}

其中 $config.$ 表示形成优化问题决策空间的配置。问题是最大化任务 $T$ 在数据集 $D$ 上的目标（即学习工具的性能 $P$），在没有人类帮助和有限计算资源的约束下。因此，EDL 的设计考虑了三个方面。

良好的泛化性能::

EDL 应该在给定的数据集和任务上具有良好的泛化性能。

高搜索效率::

EDL 能够在不同设计目标（例如，高准确率、小模型尺寸）的限制下，在有限的计算预算（例如，硬件、延迟、能耗）内找到最佳或理想的配置。

无需人工干预::

EDL 能够在没有人工干预的情况下自动配置。

按照图 3 中描述的 EC 框架，我们提出了如下的 EDL 通用框架。

步骤 1 初始化::

根据设计的编码方案初始化一个个体群体。

步骤 2 评估::

根据目标（例如，高准确率、小模型尺寸）或约束（例如，能耗）评估每个个体。

步骤 3 更新::

从上一代生成所需数量的新解决方案，通过各种更新操作。

步骤 4 终止条件::

如果未满足预定义的终止条件，则进入步骤 2；否则，进入步骤 5。

步骤 5 输出::

输出性能最佳的解决方案。

#### 2.3.3\. EDL 方法的分类

本节根据“要进化/优化的内容”和“如何进化/优化”提出了一种新的 EDL 方法分类，如图 4 所示。

![参见说明](img/dc42ccf964acca317096d7d4d08a8c05.png)

图 4. EDL 方法的分类。

“要进化/优化的内容”：我们可能关注“EDL 能做什么”或“EDL 可以解决哪些问题”。在特征工程中，有三个关键问题需要解决，包括特征选择、特征构造和特征提取 (Yao et al., 2018)。在模型生成中，参数优化、架构优化和联合优化成为关键问题 (Zhou et al., 2021a)，而模型部署涉及模型剪枝和其他压缩技术的问题。

“如何进化/优化”：这个问题的答案是为 EC 设计适当的解决方案表示和搜索范式，以及 NAS 的加速策略。表示方案用于个体的编码，搜索范式用于实现最佳配置，加速策略用于减少时间或资源消耗。

根据上述分类，我们将在第 3、4 和 5 节中详细介绍特征工程中的 EDL、模型生成和模型部署。

## 3\. 特征工程

特征工程用于通过筛选数据中的无关特征或基于原始特征创建新特征来预处理给定的原始数据（Xue 等，2015）。已经提出了各种基于进化计算（EC）的技术，以减少数据维度，加速学习过程或提高模型性能（Xue 等，2015）。常见的技术可以分为特征选择（Nguyen 等，2014）、特征构造（Bhanu 和 Krawiec，2002）和特征提取（Peng 等，2021）。

### 3.1\. 特征选择

#### 3.1.1\. 问题表述

特征选择旨在自动选择一个具有代表性的特征子集，其中没有无关或冗余的特征。然而，随着特征数量的增加，搜索空间呈指数增长。如果一个数据集有 $n$ 个特征，那么搜索空间中有 $2^{n}$ 个解。此外，特征之间的相互作用可能会严重影响特征选择性能（Xue 等，2015）。接下来，我们将回顾在 EC 中用于特征选择的解决方案表示和搜索范式的现有工作。

#### 3.1.2\. 解决方案表示

通常，有三种不同的解决方案表示类别。

线性编码：这种编码使用向量或字符串来存储特征信息。例如，在（Estévez 和 Caballero，1998）中，使用固定长度的二进制向量来表示特征是否被选择，其中“1”表示对应的特征被选择，“0”则表示相反。在（Hong 和 Cho，2006）中，使用二进制索引来表示对应的特征。

**基于树的编码**：在经典遗传编程（GP）中，所有叶节点/终端节点代表所选特征，而非终端节点则代表函数（例如，算术或逻辑运算符）（Krawiec，2002）。针对高维数据的自动分类，Krawiec 等人（Krawiec，2002）提出了一种基于树的编码方法，用于选择具有高度区分性的特征子集，其中每个特征由兄弟叶节点及其父功能节点组成。在基于树的编码的基础上，Muni 等人（Muni 等，2006）提出了一种用于在线特征选择的多树 GP 方法。

**基于图的编码**：在（O’Boyle 和 Palmer，2008）中，高维数据的特征空间由一个图表示，图中的每个节点代表一个特征。特征子集由图中的访问节点组成，即节点组合的路径或子图。Yu 等人（Yu 等，2009）将特征选择转化为有向图中的最优路径问题，其中节点的值为“1”或“0”以表示特征是否被选择。

#### **3.1.3 搜索范式**

在特征选择中，介绍了以下几种代表性的搜索范式。

**基本进化计算搜索范式**：在特征选择中，已经广泛使用了典型的进化搜索方法，如 GA（Da Silva 和 Neto，2011；Estévez 和 Caballero，1998），GP（Krawiec，2002；Nekrasov 等，2020），PSO（Vieira 等，2013；Nguyen 等，2014），蚁群优化（ACO）（Khushaba 等，2008；Ma 等，2021c），以及人工蜂群（ABC）（Wang 等，2020d）。此外，一些其他研究（Khushaba 等，2008）将 ACO 与 DE 结合使用以寻找最优特征子集，其中 ACO 搜索到的解被输入到 DE 中以进一步探索最优解。在（Da Silva 和 Neto，2011）中，开发了一系列基于不同变种的 GA 的特征选择方法，以提高基于内容的图像检索系统的准确性。

**协同进化搜索范式**：在特征选择的协同进化搜索范式中，至少有两个种群同时进行进化并相互作用，以找到最优的特征子集（Wen 和 Xu，2011；Rashid 等，2020）。例如，（Wen 和 Xu，2011）中开发了一种分而治之的策略来管理两个子种群。一个子种群负责进行分类器设计的进化过程，而另一个子种群则负责搜索最优的特征子集。

多目标搜索范式：这类搜索范式由两个或更多冲突的目标驱动（Xue et al., 2012; Hancer et al., 2015; Cheng et al., 2021），例如分类器准确度的最大化和特征子集大小的最小化。在这两个冲突目标的基础上，Xue et al.（Xue et al., 2012）设计了一个多目标 PSO 算法用于特征选择，并在多目标搜索后获得了一组帕累托非支配的候选解用于特征选择。

#### 3.1.4\. 总结

GA 和 GP 广泛应用于特征选择。GA 早期用于低维（即，$\leq$1000）数据集（Xue et al., 2015; Hosni et al., 2020）。最近，许多基于 GA 的方法被提出用于解决高维特征选择（Cheng et al., 2021）。然而，GP 通常应用于大规模/高维特征选择，因为它在特征表示上具有灵活性（Xue et al., 2015）。特别是，GP 在一些小但高维的数据集上优于 GA，例如，具有 10367 个特征但仅 50 个样本的 Brain Tumor-2（Chen et al., 2022）。此外，PSO 已被证明比 GA 和 GP 具有更快的收敛速度（Zhang et al., 2017）。ACO 的图表示在灵活性上优于 GA 和 GP，但 ACO 的挑战在于如何为大规模场景设计合适的图编码（Telikani et al., 2021; Xue et al., 2015）。

### 3.2\. 特征构建

#### 3.2.1\. 问题表述

特征构建是通过适当的函数操作符（例如，连接和平均）（Xue et al., 2013; Neshatian et al., 2012）从原始特征（Tran et al., 2016）创建新的高级特征，使得高级特征比原始特征更容易区分。特征构建是一个复杂的组合优化问题，其中搜索空间随着原始特征和函数操作符的总数呈指数增长。在以下小节中，我们将描述基于 EC 的特征构建方法，包括解的表示和搜索范式。

#### 3.2.2\. 解的表示

现有的基于 EC 的方法可以分为三类。

线性编码：研究（Xue et al., 2013）使用$n$-bit（$n$是原始特征的总数）二进制向量来表示每个粒子，其中“0”表示相应的特征未被用于构建新的高级特征，而“1”则相反。在此编码的基础上，进行了局部搜索，从预定义的函数集中选择候选操作符以构建新的高级特征。

基于树的编码：基于树的编码对特征构建来说是自然的，其中叶节点表示特征信息，内部节点表示操作符。许多研究（Tran 等，2016；Bhanu 和 Krawiec，2002）已经证明了树编码在特征构建中的有效性。例如，Bhanu 等（Bhanu 和 Krawiec，2002）设计了一种基于 GP 的协同进化特征构建程序，以提高分类器的区分能力。在（Tran 等，2016）中，EC 中的一个个体由多棵树编码表示，具有多个高级特征。

基于图的编码：在这种编码中，节点和边分别表示特征和操作符（例如，“+”，“ -”，“*”，“/”）。Teller 等（Teller 和 Veloso，1996）应用任意有向图表示所有特征和操作符，其中每个可能的高级特征可以表示为这个有向图的一个子图。对于线性 GP，特征和操作形成一个多对多的有向无环图，其中每个特征被加载到预定义的寄存器中，寄存器的值可以在多个操作符中使用（Fogelberg 和 Zhang，2005）。然而，图编码在高维特征集上变得低效，因为图遍历的复杂性加剧了特征构建的难度。

#### 3.2.3 搜索范式

现有研究中的特征构建有四种搜索范式。

基础 EC 搜索范式：现有研究包括但不限于 GA（Vafaie 和 De Jong，1998）和 GP（Tran 等，2016；Neshatian 等，2007；Tariq 等，2018）。例如，工作（Neshatian 等，2007）设计了基于 GP 的特征构建以减少分类器的特征（输入）维度。特别是，GP 也被广泛用于构建新特征，其中每个遵循 GP 树形式的个体通常代表一个构建的高级特征（García 等，2011）。

协同进化搜索范式：它可以被分解为特征构建子问题和分类器设计子问题，每个子问题由 EC 方法的独立子种群解决（Bhanu 和 Krawiec，2002；Roberts 和 Claridge，2005）。例如，研究（Roberts 和 Claridge，2005）将特征构建分解为两个子问题（即特征构建和目标检测），其中特征构建通过进化像素（即特征）种群来解决，而目标检测则通过目标检测算法（ODA）（Roberts 和 Claridge，2005）进行优化。

多特征构建搜索范式：与早期方法（Tran et al., 2016; Vafaie 和 De Jong, 1998; Shafti 和 Pérez, 2008; Tran et al., 2019）仅在单次搜索过程中构建一个高级特征不同，这类范式能够创建多个高级特征。例如，Ahmed et al.（Ahmed et al., 2014）利用 Fisher 准则和$p$-值度量作为类别间的判别信息，基于此通过多个 GP 树构建了多个特征。

多目标进化搜索范式：在这一搜索范式中，特征数量和分类准确率通常作为多目标进化优化的目标函数（Hammami et al., 2018; Castelli et al., 2011）。特别是，Hammami et al.（Hammami et al., 2018）通过优化一个具有三个目标（即特征数量、互信息和分类准确率）的多目标优化问题（MOP）构建了一组高级特征，并使用了帕累托主导关系。

#### 3.2.4\. 总结

基于 GP 的方法在特征构建中很受欢迎，因为它们对特征和操作的表示灵活。此外，进化算法的混合也受到特征构建的广泛关注。然而，在高维或大规模场景下构建特征的效率仍有很大的提升空间，因为这些场景需要大量的计算资源（Tariq et al., 2018; Tran et al., 2019）。值得注意的是，特征构建通常需要比特征选择更多的计算开销，因为特征构建通常在特征选择之后进行，所选特征的质量可能会影响特征构建的性能。

### 3.3\. 特征提取

#### 3.3.1\. 问题定义

特征提取是通过一些变换函数（He et al., 2021）改变原始特征/数据以减少特征维度。传统的提取方法包括主成分分析（PCA）（Abdi 和 Williams, 2010）和线性判别分析（LDA）（Izenman, 2013）。然而，它们在变换后无法保留一些重要的信息（Abdi 和 Williams, 2010），并且调整它们的超参数（例如，保留特征的数量）以找到最佳提取方法非常繁琐。因此，通过基于 EC 的方法自动寻找高质量的映射函数以获得信息丰富的特征集趋向于更受欢迎。

#### 3.3.2\. 解表示

在 EC 驱动的特征提取中，有两种典型的解表示方式。

线性编码：在这种编码中，映射函数（Refahi 等，2020；Albukhanajer 等，2015）或函数参数（Zhao 等，2006）被编码为线性格式。例如，Wissam 等（Albukhanajer 等，2015）为特征提取预定义了三组轨迹函数（即，追踪函数、直径函数和圆形函数），并通过基于进化计算的方法获得了函数之间的最优组合。在 (Zhao 等，2006) 中，映射函数的超参数被编码为一些线性向量，这些向量由通过进化计算获得的若干最优投影基向量构建而成。

基于树的编码：在基于树的编码中，叶子节点代表原始特征或常量，而非叶子节点则是一些用于特征提取的运算符，包括常见的算术运算符、逻辑运算符（例如，“+”、 “/”、 “$\cup$”）或其他变换运算符（如 uLBP 和 SobelY）。在基于进化计算的特征提取中，一个个体代表一个特征提取器或映射函数（Peng 等，2021；Zhang 和 Rockett，2011）。特别是，基于进化计算的框架在 (Zhang 和 Rockett，2011) 中被开发出来，用于通过树形编码来搜索特征和操作序列。

#### 3.3.3\. 搜索范式

本节介绍了一些用于特征提取的常见搜索范式。

基本的进化计算搜索范式：进化计算已经成功应用于各种特征提取任务（Z.-Flores 等，2020；Bi 等，2018）。例如，Zhao 等（Zhao 等，2007）将袋装概念引入了特征提取的进化算法中。工作 (Zhao 等，2009) 开发了一种进化判别特征提取（EDFE）算法，通过将遗传算法与子空间分析结合，减少了搜索空间的复杂性，并提高了分类性能。

共进化搜索范式：在特征提取中，找到最优的提取器是一个优化问题，这可以被分解成一系列子问题（Kotani 和 Kato，2004；Hajati 等，2010）。例如，Hajati 等（Hajati 等，2010）提出了一种用于特征提取的共进化方法。具体来说，一个子群体被进化以优化与分类器相关的子问题（即，分类器构建），另一个子群体利用第一个群体的遗传信息来优化与特征相关的子问题（即，特征提取）。

多目标搜索范式：在多目标特征提取中，模型准确性、计算时间、复杂性和鲁棒性通常作为目标（Zhang and Rockett, 2011; Cano et al., 2017）。Cano et al.（Cano et al., 2017）提出了一种基于帕累托的多目标 GP 算法用于特征提取和数据可视化，其中目标是最小化数据转换的复杂性（即树的大小）并最大化识别性能（即准确性）。

#### 3.3.4\. 总结

在现有研究中，近年来已经开发了许多高效的搜索和平衡策略，这些策略由 EC 方法驱动，以在显著降低计算开销的情况下实现满意的解决方案（Zhang and Rockett, 2011; Cano et al., 2017; Mauceri et al., 2021; Shakya et al., 2021）。然而，现有编码方法和预定义操作集可能限制提取器的性能。因此，开发高效的算法、操作控制策略和高维特征提取的表示是至关重要的。

## 4\. 模型生成

模型生成是指在给定任务上搜索具有理想学习能力的最佳模型（Yao et al., 2018; He et al., 2021）。在这一部分，我们介绍了从解的表示到搜索范式的对应演化参数优化、架构优化和联合优化。对其他模型生成方法（例如，基于强化学习和基于梯度的方法）感兴趣的读者可以参考相关综述（Ren et al., 2021; Jaâfra et al., 2019）。

### 4.1\. 模型参数优化

#### 4.1.1\. 问题定义

模型参数优化的目标是搜索一个预定义架构（$A$）的最佳参数集（即权重 $W^{*}$）。损失函数 $L$（例如，交叉熵损失函数）衡量在给定数据集上优化参数（即 $W$ 在 Eq. 2）的模型性能。一般的模型参数优化可以表示为

| (2) |  | $\displaystyle\begin{matrix}{{W}^{*}}$=$\underset{W}{\arg\min}L\left(W,A\right)\end{matrix}$ |  |
| --- | --- | --- | --- |

其中 $W$ 通常是大规模的（数百万个模型参数）且高度非凸。

#### 4.1.2\. 解的表示

基于演化计算（EC）的模型参数优化有两种典型的表示方案，包括直接编码和间接编码（He et al., 2021）。

直接编码：模型参数通过向量或矩阵直接表示，其中每个元素表示一个特定的参数（Ijjina 和 Chalavadi，2016；Karegowda 和 Manjunath，2011）。例如，使用包含 64 个实数的染色体直接表示网络对应的权重，其中前 63 个实数用于编码大小为 1 $\times$ 21 的三个卷积掩模。最后一个实数是一个生成器的随机种子，用于初始化一个全连接网络（Ijjina 和 Chalavadi，2016）。这种编码方法可能需要巨大的计算开销来表示和优化大规模权重。

间接编码：这种编码方法通过确定性变换仅表示模型参数的一个子集（Li 等，2019；Koutník 等，2010）。在 (Koutník 等，2010) 中，权重信息被编码为频域中的一组傅里叶系数，以通过忽略高频系数来减少表示的维度。虽然这种方法能够加速搜索过程，但由于信息表示不完整，可能会丢失参数信息，从而降低模型性能。

#### 4.1.3\. 搜索范式

基于 EC 的方法可以根据是否结合梯度方法分为两类，即纯 EC 和基于梯度的 EC。

纯 EC 范式仅通过进化搜索优化模型参数，包括基本 EC 搜索范式和共同进化搜索范式。

+   •

    基本 EC 搜索范式：除了 GA（Montana 和 Davis，1989；Karegowda 和 Manjunath，2011），一些启发式算法如 PSO（Al-kazemi 和 Mohan，2002），ABC（Karaboga 等，2007）和 ACO（Socha 和 Blum，2007）也常用于模型参数优化。例如，Karaboga 等（Karaboga 等，2007）采用 ABC 来为目标任务上的前馈神经网络（FNN）找到一组权重。

+   •

    共同进化搜索范式：共同进化搜索是在原始优化问题的子问题上进行的（例如，基于突触和基于神经元的问题（Chandra 和 Zhang，2012；Chandra，2015））。例如，Chandra 等（Chandra 和 Zhang，2012）在初始化阶段将单个隐藏层视为一个子组件，该子组件将在共同进化优化过程中与来自不同子种群的最佳适应个体合并，以构成新的神经网络。

![参见说明](img/6825f4f47b67248cf5a997f1ecfa83e1.png)

(a)

![参见说明](img/38e7f4b1d3767aae05ade0ace0f876a1.png)

(b)

![参见说明](img/2410148fead42dccca01069d6689080e.png)

(c)

图 5. 基于梯度的 EC 的三种混合方式。

基于梯度的 EC 将基础 EC 与基于梯度的方法结合起来，以增强在优化模型参数时的开发能力。根据执行顺序，有三种混合方式。

+   •

    第一个混合方法如图所示 (5(a))，其中 EC 用于识别模型的最佳参数，然后使用基于梯度的方法进一步优化这些参数，以找到最终的最优解 (Zhang 和 Smart, 2004; Chen 等, 2015)。例如，(Zhang 和 Gouza, 2018) 提出的遗传自适应动量估计算法（GADAM）通过将 Adam 和 GA 融入统一学习方案中，其中 Adam 是一个具有一阶梯度的自适应动量估计方法。

+   •

    第二种混合方法如图所示 (5(b))，其中基于梯度的方法用于生成一组参数以初始化用于 EC 的人群 (Wu 等, 2021b)。例如，研究 (Khadka 和 Tumer, 2018) 首先通过基于梯度的方法训练一个 RL 代理，然后将 RL 的参数作为初始种群输入 EC。因此，参数将由 EC 进一步优化。

+   •

    第三种方法在图中展示 (5(c))，它在优化过程中迭代地应用 EC 和基于梯度的方法以找到最优参数。根据这一框架，何时使用该方法以及选择哪种方法在不同的研究中有所不同 (Yang 等, 2021; Cui 等, 2018)。

#### 4.1.4\. 总结

在模型参数优化中，直接编码直观且能够保留比间接编码更多的信息。与容易陷入局部最优的基于梯度的方法相比，EC 在全局搜索中展现出更强的能力。这里介绍了几个场景，其中 EC 应用于模型参数优化。

小规模场景： (Montana 和 Davis, 1989) 显示纯 EC 方法在一些小规模问题的搜索有效性上优于基于梯度的方法，这些问题中的模型参数较少或结构简单（例如，FNN）。

大规模场景：在大规模学习模型中，纯 EC 方法的表现可能不尽如人意，而更好的方法是利用 EC 和基于梯度的方法的混合。这种混合方法可以缓解陷入局部最优解的问题，并提高后续开发的有效性（Yang et al., 2021）。

除了上述场景，当难以获得损失函数的确切梯度信息时，可以使用基于 EC 的方法来训练 DNN（Peng et al., 2018）。例如，在深度强化学习（DRL）中，策略网络的奖励是稀疏或具有误导性的，从而使得梯度信息无法获得。工作（Conti et al., 2018）将新颖性搜索（NS）和质量多样性（QD）引入了策略网络的进化策略（ES）中。

### 4.2\. 模型架构优化

#### 4.2.1\. 问题表述

模型架构优化，也称为 NAS，是指搜索具有良好性能的网络架构，例如在给定任务上的模型准确性。模型架构优化可以表述如下。

| (3) |  | <math alttext="\left\{\begin{matrix}{{A}^{*}}$=$\underset{W,A}{\mathop{\arg\min}}\,L\left(W,A\right)\\ \begin{matrix}s.t.&amp;A\in\mathcal{A}\\

\end{matrix}\\

\end{matrix}\right." display="block"><semantics ><mrow ><mo >{</mo><mtable displaystyle="true" rowspacing="0pt" ><mtr ><mtd ><mrow ><msup ><mi >A</mi><mo >∗</mo></msup><mo lspace="0em" rspace="0em" >​</mo><mtext >=</mtext><mo lspace="0.167em" rspace="0em" >​</mo><munder accentunder="true" ><mrow ><mi >arg</mi><mo lspace="0.167em" >⁡</mo><mi >min</mi></mrow><mrow ><mi >W</mi><mo >,</mo><mi >A</mi></mrow></munder><mo lspace="0.167em" rspace="0em" >​</mo><mi >L</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo >(</mo><mi >W</mi><mo >,</mo><mi >A</mi><mo >)</mo></mrow></mrow></mtd></mtr><mtr ><mtd ><mtable columnspacing="5pt" displaystyle="true" ><mtr ><mtd ><mrow ><mrow ><mi >s</mi><mo lspace="0em" rspace="0.167em" >.</mo><mi >t</mi></mrow><mo lspace="0em" >.</mo></mrow></mtd><mtd ><mrow ><mi >A</mi><mo >∈</mo><mi >𝒜</mi></mrow></mtd></mtr></mtable></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex" >\left\{\begin{matrix}{{A}^{*}}$=$\underset{W,A}{\mathop{\arg\min}}\,L\left(W,A\right)\\ \begin{matrix}s.t.&A\in\mathcal{A}\\ \end{matrix}\\ \end{matrix}\right.</annotation></semantics></math> |  |

其中 $A^{*}$ 表示在参数 $W$ 下，具有最佳性能的搜索空间（$\mathcal{A}$）中的架构，而 $L$ 用于衡量架构在给定任务上的性能。因此，这种优化是一个双层次优化问题（Zhou et al., 2021a; Liu et al., 2021b），其中模型架构优化受限于模型参数优化（Lu et al., 2021）。由于目前的 NAS 工作主要集中在 CNN 上，我们将讨论 CNN 的解决方案表示、搜索范式和加速策略。由于页面限制，这里没有介绍 NAS 的搜索空间设计，但感兴趣的读者可以查阅这些综述（Liu et al., 2021b; Ren et al., 2021），其中包含有关搜索空间设计的详细信息。

#### 4.2.2\. 解决方案表示

根据编码长度的不同，我们可以将编码策略分为固定长度编码和变长编码。

固定长度编码：在进化过程中，每个个体的长度是固定的。例如，设计一个固定长度的向量来表示 CNN 的模型架构（Xie and Yuille, 2017），其中向量中的一个子集表示 CNN 的架构单元（例如卷积层、池化层或全连接层）。这种编码可能容易适应进化计算（EC）的操作（例如交叉和突变）（Xie and Yuille, 2017），但它必须指定一个合适的最大长度，这通常是未知的，需要基于领域专业知识预先定义。

变长编码：与固定长度方法不同，变长编码策略不需要事先了解模型架构的最佳深度，实际上可能是减少搜索空间复杂性的一种方式。这种编码的灵活设计可能将有关架构的更多详细信息编码到解决方案向量中，并且解决方案的最佳长度在搜索过程中自动找到（Liu et al., 2021b）。在（Chen et al., 2020）中，整个变分自编码器（VAE）被分为四个块，包括 h 块、$\mu$块、$\sigma$块和 t 块，而变长染色体则由不同数量和类型的层组成。值得注意的是，变长编码不容易直接应用标准遗传操作（例如交叉）。

由于神经网络架构由基本单元及其之间的连接组成，因此这两者都需要编码，如（Liu et al., 2021b）所建议的。

1) 基本单元的超参数编码。在卷积神经网络（CNN）中，每个单元（例如，层、块或细胞）都有许多需要指定的超参数，如特征图大小、卷积层类型和滤波器大小（Sun et al., 2020）。在（Sun et al., 2019b）中，DenseBlock 只需设置两个超参数（例如，块类型和内部单元的具体参数）即可配置该块，这可以看作是完整 CNN 模型的缩影。与块的参数化相比，细胞的参数化更加灵活，因为它可以通过不同原始层的组合来配置（Sun et al., 2019c）。

2) 单元之间连接的编码。一般来说，根据基本单元的连接模式，有两种类型的模型架构：线性拓扑架构和非线性拓扑架构（Yang et al., 2020）。线性架构的模式由连续的基本单元组成，而非线性模式允许在架构中进行跳跃或循环连接（Liu et al., 2021b）。

+   •

    线性拓扑结构：线性拓扑广泛出现在层次化和模块化的搜索空间构建中。由于线性拓扑的简单性，基本单元可以通过线性拼接方法一个接一个地堆叠起来。通过这种方式，架构的骨架可以有效地建立起来（Sun et al., 2019b; Chen et al., 2020），而不考虑基本单元内部的复杂性。

+   •

    非线性拓扑结构：与线性结构相比，非线性拓扑结构因其在构建高性能架构方面的灵活性而受到更多关注（Wang et al., 2021c, 2020b; Xie and Yuille, 2017），例如由基本单元组成的宏观结构和基本单元内部的微观结构。非线性拓扑结构有两种典型的编码方法。一种是使用邻接矩阵表示非线性架构中的连接，其中矩阵中的“1”表示两个单元之间的连接存在，而“0”表示连接不存在。在（Lorenzo and Nalepa, 2018）中，跳跃连接由一个矩阵表示，其中可以设置约束以保证有效编码，并避免在执行跳跃连接时出现重复边。需要注意的是，邻接矩阵有一个限制，即基本单元的数量需要预先固定（Kitano, 1990）。另一种是利用有序对表示有向无环图，然后编码单元之间的连接。这个有序对可以表示为 $G$ = ($V$, $E$)，其中 $V$ 是顶点的集合，$E$ 是无环图中的有向边，并已在（Irwin-Harris et al., 2019）中应用于连接的编码。

#### 4.2.3 搜索范式

本节介绍了用于 NAS 的常用 EC 基础搜索范式。

基本 EC 搜索范式：许多基本的 EC 算法已广泛应用于现有的 NAS 方法中，如 GA (Kitano, 1990) 和 PSO (Sun et al., 2019d)。EC 的一般框架见图 3。

增量搜索范式：模型架构可以以增量的方式构建，其中模型元素（例如，层和连接）在进化过程中逐步添加到模型中（Liu et al., 2018c; Wang et al., 2020c; Shen et al., 2019）。这种方式允许在不同优化阶段找到架构的一部分，从而减少一次性获取完整模型的计算负担（Liu et al., 2018c）。例如，Wang et al. (Wang et al., 2020c) 使用增量方法堆叠块来构建架构，通过渐进过程提高了最终架构的能力。

协同进化搜索范式：一个架构优化问题被分解为蓝图及其组件的优化（O’Neill et al., 2018; Zhang et al., 2022b）。具体来说，蓝图在指定其组件的拓扑连接模式方面发挥作用，通过协同优化蓝图及其组件来获得最佳架构。例如，O’Neill et al. (O’Neill et al., 2018) 提出了用于 NAS 的协同进化搜索范式，其中候选蓝图和组件从两个种群中采样，然后组合形成新的架构。

多目标搜索范式：该范式旨在基于多个标准搜索一组帕累托最优架构，并根据一些实际考虑因素（如计算环境）寻找最终解决方案（Neshat et al., 2020; Lu et al., 2019）。该范式在实际应用中变得流行，因为需要考虑许多目标，如准确性、推理时间、模型大小和能耗。在 (Neshat et al., 2020) 中，使用了 NSGA-II 和 RL 来探索与模型准确性和模型复杂性（例如，模型参数数量和乘加操作数）相关的模型架构。

#### 4.2.4\. 加速策略

NAS 是一个高计算开销的任务，这主要是由于大的搜索空间和高度耗时的评估 (Yao et al., 2018)。为克服这一挑战，已经开发了各种加速策略 (Sun et al., 2019d; Assunção et al., 2019b) 以加速优化。在这一部分，我们从算法设计到硬件实现的各个方面总结了加速策略，如图 6 所示。

![参考说明](img/f173dbb8c1a13e886eadc7aa6aba2e6a.png)

图 6. 加速策略概览。

从算法设计的角度来看，我们总结了从种群初始化到评估的多种加速策略。

+   •

    初始化：

    +   –

        减少种群：在初始化阶段，加速的最简单方法是设定一个较小的种群。换句话说，较小的种群需要更少的评估，因为候选架构的评估是耗时的 (Yao et al., 2018)。因此，一些研究 (Assunção et al., 2019b, 2018) 使用固定大小的小种群来加速其演化，比如 CARS (大小 = 32) (Yang et al., 2020)。相比之下，其他一些研究在优化过程中使用动态大小的种群。在 (Fan et al., 2020) 中，种群大小动态变化，以在算法效率和种群多样性之间达到平衡。

    +   –

        高效的搜索空间：另一种方法是设计高效的搜索空间以加速搜索过程。例如，基于细胞搜索空间 (Liu et al., 2021b) 构建的架构由许多相似的细胞结构组成，仅需要优化代表性细胞，这有助于显著加快计算速度。

+   •

    评估：

    1.  (1)

        早期停止策略：使用相对较少的训练周期来减少训练成本（即早期停止策略），因为训练时间减少 (Ahmed et al., 2019; Tian et al., 2019; Sun et al., 2019d)。

    1.  (2)

        减少训练集：一些方法旨在减少训练集的大小，以提高训练效率，但会牺牲一些准确性 (Sapra and Pimentel, 2020; Liu et al., 2019a)。此外，低分辨率数据 (例如，ImageNet 32) (Chrabaszcz et al., 2017) 也常用于训练集，以加速搜索最佳架构的过程。

    1.  (3)

        权重继承 ¹¹1In（Rumelhart et al., 1985, 1986; LeCun et al., 1989），Rumelhart/Hinton/LeCun 使用“权重共享”一词来表示不同的网络连接/链接共享相同的权重集，并指出“权重共享”是共享权重 NNs/CNNs 的核心。最近（Lu et al., 2021; Xie et al., 2022a）对这个术语的使用指的是“权重/参数复制”或“权重继承”。

        +   –

            基于超网络的继承：使用一个过度参数化且预训练的超网络来编码所有候选架构（即子网络）。换句话说，子网络从超网络中共享相同结构的权重，并在验证数据集上直接评估以获得其模型准确性（Rapaport et al., 2019; Dahal and Zhan, 2020; Elsken et al., 2019; Sapra and Pimentel, 2020）。

        +   –

            基于父体的继承：从先前训练过的网络（即父网络）继承权重，而不是从超网络，因为后代个体保留了父母架构的一些相同部分（Real et al., 2017; Elsken et al., 2017; Kwasigroch et al., 2019; Zhu et al., 2019)（Real et al., 2017）。因此，后代架构可以继承相同部分的权重，而不需要从头开始训练。

    1.  (4)

        替代模型：由于架构评估是耗时的（Yao et al., 2018; Liu et al., 2021b），在 NAS 中引入了廉价的替代模型作为性能预测器，以减少计算时间（Lu et al., 2021）。

        +   –

            在线性能预测器：它们在线训练，使用来自过去几个训练周期的数据集（Liu et al., 2021b），包括具有不同训练周期的数据对及这些周期对应的性能（Lu et al., 2021）。之后，它们将用于对新架构进行性能预测。为了减少对架构的真实评估，一些性能预测器直接通过训练的排序或分类方法预测候选架构是否能进入下一次迭代，例如分类导向的 NAS（Ma et al., 2021a）。

        +   –

            离线性能预测器：它们本质上是一种回归模型，将架构映射到特定性能。端到端预测器可以以离线方式进行训练，以便在整个搜索过程中预测架构的性能。因此，它们可以显著减少计算负担（Sun et al., 2019a; Liu et al., 2018c; Sun et al., 2021）。

    1.  (5)

        人口记忆：人口记忆用于在优化过程中存储来自不同世代的精英个体（Sun et al., 2020; Fujino et al., 2017）。当生成新的个体时，如果它与记忆中的个体相同，则无需再次评估。换句话说，具有相同架构的个体的表现是相同的，可以通过人口记忆获取，而无需从头开始训练。该机制依赖于相似或相同的个体可能在不同世代中重复出现这一事实。

根据上述介绍，我们可以得出结论，许多方法通过牺牲次优性来提高搜索效率。例如，小规模种群无法很好地覆盖多目标最优前沿。参数共享可能由于个体之间的相似性过多而导致偏倚搜索。高度准确的代理需要大量的训练数据，这通常是时间消耗大的。人口记忆在很大程度上依赖于相似或相同个体的随机出现。

硬件实现：重要的是，强大的硬件平台可以在合理利用计算资源（例如，云计算（Chiba et al., 2019）和志愿计算机（Atre et al., 2021））的情况下显著加快搜索过程。并行计算是将大规模搜索问题分解为小型子问题的有力工具，这些子问题可以由几台便宜的硬件同时优化（Jin et al., 2019, 2018）。例如，Lorenzo et al.（Lorenzo et al., 2017）提出了一种并行 PSO 算法来搜索 CNN 的最优架构。计算设备的安全性也成为一个重要的考虑因素。因此，应用于 NAS 的一个新兴的去中心化隐私保护框架将多个本地客户端联合起来，共同学习一个基于本地模型参数或梯度训练的共享全局模型，而不是原始数据。例如，Zhu et al.（Zhu and Jin, 2022）首次提出了一种实时联邦 NAS，不仅可以优化模型架构，还能减少计算负担。具体来说，去中心化系统能够加速联邦 NAS 的算法效率。此外，对客户端与服务器之间传输的数据（本地模型的参数或梯度）进行数据加密，以确保隐私，即使所有训练都在本地进行。因此，联邦 NAS 高效且安全，可能成为新的热门研究话题。

表 2. 不同的加速策略

| 算法设计 | 初始化 | 减少的种群 | (Assunção et al., 2019b),(Fan et al., 2020),(Liu et al., 2019a),(Yang et al., 2020) \bigstrut |
| --- | --- | --- | --- |
| 评估 | 早停策略 | (Sun et al., 2019d),(Ahmed et al., 2019),(Ortego et al., 2020),(Frachon et al., 2019),(Assunção et al., 2019a),(Assunção et al., 2019b),(Mo et al., 2021) \bigstrut |
| 减少的训练集 | (Sapra and Pimentel, 2020),(Liu et al., 2019a),(Wang et al., 2020c) \bigstrut |
| 权重继承 | 基于超网络的共享 | (Sapra and Pimentel, 2020),(Rapaport et al., 2019),(Dahal and Zhan, 2020),(Elsken et al., 2019) \bigstrut |
| 基于父级的共享 | (Elsken et al., 2017),(Kwasigroch et al., 2019),(Zhu et al., 2019),(Ahmed et al., 2019),(Frachon et al., 2019),(Schorn et al., 2020),(Chen et al., 2019b) \bigstrut |
| 替代模型 | 在线性能预测器 | (Lu et al., 2021),(Liu et al., 2018c), (Ma et al., 2021a), (Lomurno et al., 2021) \bigstrut |
| 离线性能预测器 | (Sun et al., 2019a),(Liu et al., 2021a), (Rawal and Miikkulainen, 2018)\bigstrut |
|  | 人口记忆 | (Sun et al., 2020),(Miahi et al., 2022),(Li et al., 2022),(Chu et al., 2020) \bigstrut |
| 硬件实现 | (Chiba et al., 2019),(Jin et al., 2019),(Jin et al., 2018),(Zhu and Jin, 2022) \bigstrut |

表 2 列出了常见的加速策略以提高算法效率。值得注意的是，可以结合多种策略以提高计算速度。例如，Lu et al. (Lu et al., 2021) 在 NAS 中使用了超网络和学习曲线性能预测器，而 Liu et al. (Liu et al., 2019a) 利用较小的种群规模和数据集来减少评估的时间开销。

#### 4.2.5\. 摘要

大多数 NAS 方法基于整个结构化搜索空间上的基本 EC 搜索范式，如上所述。然而，还有一些其他自动搜索技术，例如基于 RL 的 (Jaâfra et al., 2019)、基于贝叶斯的 (White et al., 2021) 和基于梯度的 (Liu et al., 2018b) 方法，用于架构搜索。

基于 RL 的方法可以被视为一种增量搜索，其中通过使用奖励预测误差来驱动增量架构的生成，从而学习一个策略函数。由于状态空间和动作空间的规模庞大，基于 RL 的方法需要巨大的计算资源。此外，基于 RL 的 NAS 中有大量的超参数（例如，折扣因子）。此外，它们通过先验或专家知识将多目标优化问题转化为单目标问题，因此无法为目标任务找到一个 Pareto 最优集。

基于贝叶斯的方法是用于低维超参数优化问题的常用工具。与基于 EC 的方法相比，在设计合适的距离函数以评估两个子网之间的相似性时，它们的效率更高。然而，当问题的维度增加时，高斯过程的计算成本呈指数增长，其准确性也会下降。

基于梯度的方法将 NAS 问题视为连续可微的问题，而不是离散问题，能够有效地搜索具有适当权重参数的架构。不幸的是，由于梯度方法中需要更新的参数数量庞大，这些方法的 GPU 成本通常非常高 (Liu et al., 2018b)。

相比之下，基于 EC 的方法受益于需要优化的超参数较少且无需设计距离函数。此外，基于 EC 的方法可以应用于具有多个目标和约束的 NAS。尽管基于 EC 的方法有许多加速策略，但它们仍然面临高计算开销的问题。

### 4.3\. 联合优化

#### 4.3.1\. 问题表述

架构或参数的独立优化难以在给定任务上实现**最佳模型**。因此，已经开发了联合优化方法来搜索**架构**($A^{*}$)和**参数**($W^{*}$，相关权重)的最佳配置。优化问题可以在 Eq. 4 中定义。

| (4) |  | $\displaystyle\begin{matrix}\left({{W}^{*}},{{A}^{*}}\right)$=$\underset{W,A}{\arg\min}L\left(W,A\right)\end{matrix}$ |  |
| --- | --- | --- | --- |

其中 $L$ 是损失函数。

接下来，我们将介绍有关解决方案表示和搜索范式的联合优化，然后讨论与其他方法相比，基于 EC 的方法的优缺点。

#### 4.3.2\. 解决方案表示

有三种典型的编码方案用于联合优化。

线性编码：这是一种简单但有效的编码策略，在许多研究中被广泛使用，以构建高性能的架构（Aljarah 等，2018；Maniezzo，1994）。在 (Maniezzo，1994) 中，使用了一个变长的二进制向量来表示神经网络的权重和结构，其中权重利用直接编码。

基于树的编码：在这种编码中，架构的拓扑和权重可以通过一个具有多个节点和边的树结构来表示（Zhang 和 Mühlenbein，1995；Golubski 和 Feuring，1999）。在 (Zhang 等，2020b) 中，开发了反向编码树（RET）机制，以确保深度模型的鲁棒性，其中架构的拓扑信息由节点组合表示，权重信息记录在边缘上。

基于图的编码：在这种编码中，图的节点代表神经元或其他网络单元，边缘用于记录权重信息（Han 和 Cho，2006；Chai 等，2022）。例如，在 (Oong 和 Isa，2011) 中，开发了一个图的发生矩阵来编码神经网络。矩阵的大小设置为 ($N_{i}$ + $N_{h}$ + $N_{o}$) $\times$ ($N_{i}$ + $N_{h}$ + $N_{o}$)，其中 $N_{i}$、$N_{h}$ 和 $N_{o}$ 分别表示输入、隐藏和输出节点的数量。在图的发生矩阵中，实数表示权重和偏置，“0”表示两个节点之间没有连接。

#### 4.3.3\. 搜索范式

有许多有效的搜索范式用于联合优化，其中基于 EC 的搜索范式备受关注。

基本的 EC 搜索范式：一些基本的 EC 搜索方法已经被用于处理联合优化问题（Fahrudin 等，2016；Oong 和 Isa，2011；Stanley 和 Miikkulainen，2002；Barman 和 Kwon，2020；Behjat 和 Chidambaran，2019）。在 (Oong 和 Isa，2011) 中，通过使用线性和图编码的基于 EC 的方法，同时优化了一个架构及其对应的权重。在增强拓扑的神经进化（NEAT）（Stanley 和 Miikkulainen，2002）中，小型网络的架构通过增量机制进行进化，而权重由基于 EC 的方法进行优化。NEAT 能够在所有代中确保最低维度的搜索空间。在 (Barman 和 Kwon，2020；Behjat 和 Chidambaran，2019) 中介绍了一些 NEAT 的代表性研究。

多目标搜索范式：在模型设计上的多目标优化已经在许多研究中得到发展（例如，人工神经网络（Rostami 和 Neri, 2016）和递归神经网络（Smith 和 Jin, 2014））。例如，Smith 等人（Smith 和 Jin, 2014）建立了一个双目标优化（即，最小化训练数据集上的均方误差（MSE）和网络中的连接数）来搜索网络架构的最优权重和连接。个体的染色体由两部分组成，其中 Boolean 类型的部分代表网络的结构，另一个具有实数值的部分代表权重。

#### 4.3.4\. 总结

直接编码在小规模神经网络的联合优化中曾经很流行（Oong 和 Isa, 2011；Yao 和 Liu, 1996）。然而，随着神经网络规模的增加，直接编码高维向量或矩阵的权重已不再现实。因此，近期的研究更多集中在间接编码上。例如，在（Koutník 等, 2014；D’Ambrosio 和 Stanley, 2007）中设计了一个复杂的映射，具有可接受的准确度损失，以构造任意大小的权重向量。

具有搜索最优解能力的基于进化计算的方法已被开发出来，以配置用于特定任务的深度学习模型。然而，它们通常会遇到难以承受的计算成本，这甚至高于模型架构优化的成本。因此，设计高效的基于进化计算的架构和参数搜索方法值得深入研究。

## 5\. 模型部署

大规模深度神经网络在部署到计算和存储资源有限的设备（例如，智能手机）上并不简单（例如，电池容量和内存大小）。为了解决这个问题，已经提出了各种模型压缩方法来减少模型大小和推理时间，如剪枝、模型蒸馏和量化（Choudhary 等, 2020）。然而，这些方法需要大量的专家知识和对神经网络模型的手动压缩付出很多努力。相比之下，基于进化计算的方法是自动化的方法，并且最近被引入以实现自动化模型压缩。我们观察到，它们中的大多数集中在模型剪枝领域。

### 5.1\. 模型剪枝

#### 5.1.1\. 问题描述

深度神经网络通常是一个过度参数化的模型，具有冗余和非信息性的组件（例如，权重、通道和滤波器）。为了解决这个问题，研究人员设计了各种剪枝方法（例如，通道剪枝（He 等, 2017））来获得一个具有高准确度的轻量级深度网络模型。模型剪枝可以被表述为

| (5) |  |  | $\displaystyle Los{{s}_{A_{s}^{*}}}\approx Los{{s}_{A}}$ |  |
| --- | --- | --- | --- | --- |
|  |  | $\displaystyle\begin{matrix}\text{s}\text{.t}\text{.}&amp;{A}_{{s}}^{*}$=$\underset{{C}}{\mathop{\text{pruning}}}\,\left({A,C}\right)\\ \end{matrix}$ |  |

其中 $C$ 表示冗余和无信息的单元，$A$ 和 $A{{}_{s}}^{*}$ 分别表示原始模型和轻量级模型，$Los{{s}_{A_{s}^{*}}}$ 和 $Los{{s}_{A}}$ 分别表示 $A{{}_{s}}^{*}$ 和 $A$ 的损失。

本研究旨在引入基于 EC 的模型剪枝方法，感兴趣于传统剪枝方法如基于权重的剪枝、基于神经元的剪枝、基于滤波器的剪枝、基于层的剪枝和基于通道的剪枝的读者可以参考调查（Choudhary et al., 2020）以获取更多细节。

#### 5.1.2\. 解决方案表示

对于模型剪枝，二进制编码是这些解决方案表示方法中最流行的方式之一，其中每个元素对应于网络组件（例如，通道）。在（Wang et al., 2018）中，网络剪枝任务被表述为一个二进制编程问题，其中一个二进制变量直接与每个卷积滤波器相关联，以确定该滤波器是否有效。尽管二进制表示方式简单明了，但当模型复杂度（即单位数量）增加时，表示的长度也会变得很大，探索的开销也会增加。

为了应对上述问题，一些高效的解决方案表示（即间接编码）已经被开发出来。例如，Liu et al.（Liu and Guo, 2021）使用 $N$ 位来记录压缩层的数量。第一位表示压缩层的数量，后续位记录每层选择的压缩操作符索引。这种方式可以显著提高搜索效率。在（Liu et al., 2019b）中，编码向量用于表示原始网络中每层的通道数量。然后构建一个元网络，根据网络编码向量生成权重。通过以不同的结构编码随机喂入，元网络逐渐学习生成各种剪枝结构的权重。

#### 5.1.3\. 搜索范式

模型剪枝研究中的搜索范式可以分为两大类。

基本的 EC 搜索范式：一些研究介绍了单目标 EC 搜索范式用于模型剪枝（Wu et al., 2021a; Tang et al., 2019）。例如，Wu et al.（Wu et al., 2021a）首先通过差分进化（DE）分析了权重的剪枝敏感性，然后通过根据权重敏感性迭代执行权重剪枝过程来压缩模型。此外，该方法在微调阶段采用了恢复策略，以提高剪枝模型的性能。

多目标搜索范式：最近，这种搜索范式已被采用到模型修剪中，能够为用户提供一组帕累托轻量级模型。例如，周等人（周等，2020）考虑了两个目标（即最小化卷积滤波器和最大化模型性能）用于生物医学图像分割。在模型修剪过程中，使用了一个经典的多目标优化算法（NSGA-II (Deb 等，2002）），找到了一组非支配解的最优集，其中优化基于二进制字符串编码（每个比特代表一个滤波器）。

在表 3 中，我们总结了这两类搜索范式以及它们对应的编码方式。

表 3. 模型修剪的不同搜索范式和解决方案表示

|  | 直接编码 | 间接编码 \bigstrut |
| --- | --- | --- |
| 基本 EC 搜索范式 | (Samala 等，2018),(Junior 和 Yen，2021a),(唐等，2019),(吴等，2021a),(Junior 和 Yen，2021b),(周等，2021b),(Gerum 等，2020),(Zemouri 等，2019),(陈等，2019a),(Poyatos 等，2022),(Fernandes 和 Yen，2021),(李等，2020),(尚等，2022) | (刘等，2019b)  \bigstrut |
| 多目标搜索范式 | (周等，2020),(周等，2021c),(吴等，2019),(洪等，2020),(徐等，2021),(杨等，2019),(张等，2021a) | (王等，2021a),(张等，2021b),(Loni 等，2020)  \bigstrut |

### 5.2\. 其他基于 EC 的模型部署方法

与模型修剪不同，还有一些其他基于 EC 的模型压缩方法用于模型部署。接下来，介绍了一些典型的方法，包括知识蒸馏、低秩因子分解和混合技术的 EC。

#### 5.2.1\. 知识蒸馏

知识蒸馏（KD）（高等，2021）旨在获得一个小型轻量级网络，但具有良好的泛化能力。其基本思想是将从一个大型繁琐网络（或教师网络）学到的知识，转移到一个小而轻的网络（或学生网络）。

然而，当教师网络和学生网络之间的学习能力差距很大时，知识蒸馏可能会受到严重影响。换句话说，如果差距很大，学生网络可能无法从教师网络中学习知识。最近，提出了几种基于 EC 的方法来缓解知识蒸馏中的上述问题。例如，Wu et al.（Wu et al., 2020）提出了一种进化嵌入学习（EEL）范式，通过大量知识蒸馏来学习一个快速准确的学生网络。他们的实验结果表明，EEL 能够缩小教师和学生网络在特定任务上的性能差距。Zhang et al.（Zhang et al., 2022a）开发了一种进化知识蒸馏方法，以提高知识转移的有效性。在此方法中，进化教师在线学习并持续将中间知识传递给学生网络，以缩小两者之间的学习能力差距。

#### 5.2.2\. 低秩分解

深度神经网络（DNNs）通常涉及大量的权重，这可能会影响推理速度，并严重增加 DNN 的存储开销。权重可以视为一个$W$的矩阵，具有$m$ $\times$ $n$维度。低秩方法通常应用于 DNN 完全训练后的权重矩阵（$W$）。例如，奇异值分解（Fortuna 和 Frasca，2021）是一种典型的低秩分解方法，其中$W$被分解如下。

| (6) |  | $\displaystyle\begin{matrix}W$=$USV^{T}\end{matrix}$ |  |
| --- | --- | --- | --- |

其中$U$ $\in$ $R^{m\times m}$，$V^{T}$ $\in$ $R^{n\times n}$是正交矩阵，$S$ $\in$ $R^{m\times n}$是对角矩阵。

值得注意的是，大多数现有的低秩分解方法依赖于领域专业知识和经验来选择超参数（例如，权重矩阵的秩和稀疏性），以获得合适的压缩结果，而不会出现严重的性能下降（Swaminathan et al., 2020；Winata et al., 2019；Hsu et al., 2021）。

相应地，基于 EC 的方法已被引入以解决上述挑战（Wang et al., 2018；Huang et al., 2020）。例如，Huang et al.（Huang et al., 2020）提出了一种多目标进化方法，以自动优化权重矩阵的秩和稀疏性，无需人工干预，其中考虑了两个目标，包括最小化模型分类错误率和最大化模型压缩率。因此，他们生成了一组具有不同压缩率的近似压缩模型，以缓解昂贵的训练过程。

#### 5.2.3\. 联合优化中的 EC

许多压缩技术（例如，量化）可以轻松地应用于其他技术（例如，剪枝和低秩分解）。例如，先剪枝再量化可以获得一个具有更快推理速度的轻量级模型。同样，EC 可以同时优化多个模型压缩方法。接下来，我们将简要回顾这些工作。

Phan 等人（Phan et al., 2020）设计了一种高效的 1-Bit CNNs，将量化与紧凑模型相结合。具体而言，他们首先创建了一些强大的基线二值网络（BNNs），这些网络在每个卷积层有丰富的随机组组合。然后，他们采用进化搜索来寻求一个准确度高于阈值的最佳组卷积组合。最后，获得的二值模型从头开始训练，以实现最终的轻量级网络。与（Phan et al., 2020）不同，Polino 等人（Polino et al., 2018）联合利用权重量化和蒸馏将大型网络（即教师网络）压缩成小型网络（即学生网络），在优化过程中，将延迟和模型误差作为目标。

最近，Zhou 等人（Zhou et al., 2021b）开发了一种基于进化算法的方法，用于在块级别浅化 DNN（ESNB）。在 ESNB 中，从原始模型中提取了先验知识以指导种群初始化。然后，执行了一种进化多目标优化方法，以最小化块的数量和准确度下降（即损失）。之后，采用知识蒸馏来弥补通过将剪枝模型的输出与原始模型的软化和硬化输出匹配所带来的性能退化。

#### 5.2.4\. 摘要

在解决进化模型部署的巨大计算开销方面仍有很大的改进空间。加速策略可能有助于缓解这个问题。此外，由于压缩网络的性能强烈依赖于原始网络的性能，模型部署与模型生成之间存在较高的耦合性。模型的黑箱性质也阻碍了在安全关键任务（例如，医学和金融）中的部署。因此，将模型压缩、NAS 和可解释性作为一个单一优化问题来处理，并在可接受的时间消耗内完成这一任务是充满前景但又具有挑战性的。

## 6\. 应用、开放问题与趋势

### 6.1\. 应用

EDL 算法已广泛应用于各种现实世界的应用中。在实践中，计算机视觉（CV）、自然语言处理（NLP）及其他实际应用（例如，危机预测和疾病预测）取得了显著进展。

#### 6.1.1\. 计算机视觉

计算机视觉（CV）是计算机科学中的一个重要领域，在识别有用信息（例如，对象和分类）方面发挥了重要作用（例如，图像分割（Zhou et al., 2020）和对象检测（Zhang and Rockett, 2005））。早期，手动设计的计算机视觉模型在公共数据集上表现良好，但付出了大量时间和劳力。随着 EDL 的发展，许多新结构由计算机编程开发，并且它们在图像分类等广泛使用的基准数据集上表现优于这些手动设计的模型，如 CIFAR-10、CIFAR-100（Krizhevsky et al., 2009）和 ImageNet（Deng et al., 2009）。例如，最先进的 NAT-M4（Lu et al., 2021）在 ImageNet 上以较小的模型规模实现了 80.5%的 Top-1 准确率。图像到图像处理（Liu et al., 2021b）（例如，超分辨率、图像修补和图像恢复）也受到了研究人员的广泛关注（Rundo et al., 2019; Song et al., 2020; Zhan et al., 2021）。Ho et al.（Ho et al., 2021）在深度图像先验的基础上使用了 NAS 技术来改进图像去噪、修补和超分辨率。除了上述应用，EDL 在 CV 的其他领域也具有巨大潜力，例如对象检测（Demirkir and Sankur, 2006）、视频/图片理解（Maniezzo, 1994）和图像分割（Fan et al., 2020）。

#### 6.1.2\. 自然语言处理

自然语言处理（NLP）由计算机科学和计算语言学推动，旨在理解、分析和提取文本和语音识别的知识（Young et al., 2018）。许多有效的 NLP 模型（例如，GPT-2（Radford et al., 2018）和 BERT（Devlin et al., 2018））利用复杂机制缩短了人类交流与计算机理解之间的鸿沟。最近，提出了受进化计算启发的 NLP 模型，如语言模型（Murray and Chiang, 2015）、实体识别（Sikdar et al., 2012）、文本分类（Tanaka et al., 2016; Andersen et al., 2021; Londt et al., 2021, 2020）和关键词识别（Mazzawi et al., 2019）。Satapathy et al.（Song, 2021）在英语翻译系统中引入了进化多目标（即推理时间和准确性）优化。Sikdar et al.（Sikdar et al., 2012）在命名实体识别（NER）的特征选择中应用了差分进化（DE）。

#### 6.1.3\. 其他应用

除了 CV 和 NLP，EDL 在处理其他实际应用方面也展现了强大的能力，例如医学分析（Liu 等，2018a；Zhu 等，2007）、金融预测（Tang 等，2019）、信号处理（Erguzel 等，2014；Huang 等，2012）和工业预测（Mei 等，2017；Ma 等，2021b）。特别是，Zhu 等（Zhu 等，2007）提出了一种嵌入马尔可夫毯的遗传算法，用于特征选择以改善基因选择。在（Tang 等，2019）中，金融破产分析通过进化修剪神经网络来处理。工作（Erguzel 等，2014）设计了一种基于 ACO 的特征选择方法，用于分类肌电图信号。对于遥感图像，通过多目标神经进化架构搜索（Ma 等，2021b）找到了适合的模型，其中架构复杂性和搜索网络的性能误差是两个相互冲突的目标。

### 6.2\. 未解决的问题

EDL 是机器学习和进化计算领域的一个热门研究话题。关于这一主题，有大量的论文发表在各大顶级会议和期刊上，如 ICCV、CVPR、GECCO、TPAMI、TEVC、TCYB 和 TNNLS（请参见参考文献列表）。然而，仍然存在一些挑战需要解决。

加速策略：许多 EDL 方法由于评估成本高而效率低下。因此，设计了各种加速策略，如代理模型（Sun 等，2019a）、超网络（Guo 等，2020）和早停（Sun 等，2019d）。然而，这些策略在提高准确性的同时，也牺牲了部分模型精度。以基于超网络的继承为例（Xie 等，2022a），由于灾难性遗忘（Zhang 等，2020a）和权重耦合（Hu 等，2021a），我们无法保证每个子网络都能得到可靠的评估。因此，如何平衡效率和准确性需要进一步研究。

效果性：关于 EDL 是否相较于其他搜索范式（如随机搜索和 RL）具有更多优势存在争论。一些研究认为，许多流行的搜索范式（如基于 EC 的方法和基于 RL 的方法）在性能上与随机搜索方法没有太大区别，甚至在某些场景下，一些随机搜索方法的表现优于基于 EC 的方法（Sciuto et al., 2020）。相反，基于 EC 的方法也在许多研究中被证明比随机搜索方法更有效（Real et al., 2019；Guo et al., 2020；Jones et al., 2019）。因此，在一致的搜索空间和超参数配置下，建立一个统一的平台来衡量不同搜索模型的效果是至关重要的（Xie et al., 2022b）。此外，需要详细的实验来证明不同遗传算子（如交叉算子）对 EDL 进化过程的影响。

大规模数据集：在大规模数据集上研究 EDL 存在问题。注意到许多 EDL 的研究是在小型和中型数据集上测试的，如 CIFAR-10 和 CIFAR-100（包括 60000 张 32$\times$32 的图像），尤其是 CIFAR-10 上的准确率达到 98%（Lu et al., 2021）。尽管大规模数据集在基因分析（Yu et al., 2009）和 ImageNet（Deng et al., 2009）等各种领域中随处可见且至关重要，但如一些统计报告所指出，计算成本对许多研究人员来说是难以承受的（He et al., 2021；Liu et al., 2021b）。因此，EDL 方法对不同规模数据集的敏感性是必要的（Zhou et al., 2021a），如何经济高效地在大规模数据集上验证 EDL 方法也值得深入研究。

端到端的 EDL：最初，AutoML 旨在整体上同时优化特征工程、模型生成和模型部署。然而，它们之间有很强的关联，下一阶段的表现严重依赖于前一阶段的结果（Liu 和 Guo, 2021）。因此，大多数研究仅关注 EDL 管道的部分内容（图 1）。例如，TPOT（Olson 和 Moore, 2016）是基于 Pytorch 构建分类任务的，但只支持多层感知机（即，模型生成）。目前有许多部分完成的端到端 EDL，例如 ModelArts（模型生成）、Google 的 Cloud（NAS）和 Feature Labs（特征工程）（Yao 等, 2018），仅举几例。主要原因是优化整个 EDL 管道可能需要巨大的计算成本，不仅在探索大规模搜索空间方面，还在处理 EDL 不同部分之间的高度耦合关系方面。因此，找到完整 EDL 管道的最优解决方案至关重要但具有挑战性。

### 6.3\. 挑战与未来趋势

尽管 EDL 取得了显著进展，但仍有许多有前景的研究方向。

公平比较：不同 EDL 方法的非公平比较常因以下原因出现。首先，统一基准测试是必需的。在特征工程中，由于不同的下游预测模型和特征集，没有统一的基准测试来公平比较不同算法。其次，处理 NAS 和模型压缩的不同方法没有统一标准（例如，cutout（DeVries 和 Taylor, 2017）和 ScheduledDropPath（Zoph 等, 2018）），这可能影响最终架构的性能。第三，公平的 EDL 平台是必需的。有一些公平的基准测试，但仅限于特定任务，例如 BenchENAS（Xie 等, 2022b）、NAS-Bench-101（Ying 等, 2019）、NAS-Bench-201（Dong 和 Yang, 2020）、NAS-Bench-301（Siems 等, 2020）和 HW-NAS-Bench（Li 等, 2021）。

可解释性：EDL 被称为黑箱优化，目前缺乏理论分析来解释其优越性（Wang et al., 2021b）。例如，很难解释为什么基于 EC 的方法倾向于选择有助于分类模型性能的特征。在特征工程中。这导致 EDL 在一些敏感领域，如金融和医疗领域的发展缓慢。为了解决这个问题，Evans et al. (Evans et al., 2018b) 使用可视化来阐明进化卷积滤波器的作用，并间接解释模型的搜索过程。然而，一些研究认为，这些现象的解释通常是事后解释的，缺乏可靠的数学推导（Liu et al., 2021b；Al-Sahaf et al., 2019）。因此，EDL 的可解释性是一个有趣且充满前景的研究方向。

探索更多场景：在基准测试和实际应用中，EDL 的性能仍有很大的提升空间。虽然 EDL 方法在各种图像基准测试（如 CIFAR-10 和 ImageNet）中优于手动设计的模型，但最先进的 EDL 方法（Wang et al., 2020a）在 NLP 领域相比于人类设计的模型（如 GPT-2 (Radford et al., 2018)，Transformer-XL (Dai et al., 2019)）失去了其优势。与基准测试相比，处理实际任务更为困难，因为实际任务不可避免地包含噪声（如错误标记和数据不足或不平衡）或可能具有小规模数据集（导致过拟合）。因此，可以将一些技术，如无监督和自监督学习，纳入 EDL 中，以缓解这些问题。

## 7\. 结论

随着机器学习和进化计算的发展，许多 EDL 方法被提出，用于自动优化深度模型的参数或架构，遵循 EC 优化框架。与手动设计的方法相比，EDL 方法在鲁棒性和搜索能力方面表现出竞争力。因此，EDL 已成为一个热门研究课题。

在这项调查中，我们首先从 DL 和 EC 的角度介绍了 EDL，以便 ML 和 EC 领域的读者能够更好地理解。接着，我们将 EDL 定义为一个复杂的优化问题，并提供了关于 EC 技术在解决 EDL 优化问题中的全面调查，包括特征工程、模型生成到模型部署，从而形成了一个新的分类法（即，在 EDL 中什么、在哪里以及如何进化/优化）。具体而言，我们详细讨论了 EDL 在其管道不同阶段的解决方案表示和搜索范式。然后，讨论了基于 EC 的方法与非 EC 方法的优缺点。随后，总结了各种应用，以展示 EDL 在处理现实世界问题中的潜在能力。

尽管 EDL 方法在 AutoML 中取得了巨大进展，但仍然存在许多待解决的挑战性问题。例如，有效的加速策略对于减少昂贵的优化过程至关重要。另一个问题是处理大规模数据集以及如何在不同的 EDL 方法或非 EC 方法之间进行公平比较。需要更多研究来理论分析或解释 EDL 的搜索能力。此外，还需要大量努力来提高 EDL 在基准（例如，大规模和小规模数据）和现实应用中的表现。最后，端到端的 EDL 开发具有挑战性，但值得付出大量努力。

## 参考文献

+   (1)

+   Abdi 和 Williams（2010）Hervé Abdi 和 Lynne J Williams。2010 年。主成分分析。*Comput. Stat.* 2, 4 (2010), 433–459。

+   Ahmed 等（2019）Amr Ahmed、Saad Mohamed Darwish 和 Mohamed M. El-Sherbiny。2019 年。基于遗传算法的自动 CNN 架构设计新方法。在*Int. Conf. Adv. Intell. Syst. Inform.* 473–482。

+   Ahmed 等（2014）Soha Ahmed、Mengjie Zhang、Lifeng Peng 和 Bing Xue。2014 年。使用遗传编程进行有效生物标志物识别和分类的多特征构造。在*Proc. Genetic Evol. Comput. Conf.* 249–256。

+   Al-kazemi 和 Mohan（2002）Buthainah Al-kazemi 和 Chilukuri Krishna Mohan。2002 年。使用多相粒子群优化训练前馈神经网络。在*Proc. Int. Conf. Neural Inf. Process.*, Vol. 5. 2615–2619。

+   Al-Sahaf 等（2019）Harith Al-Sahaf、Ying Bi、Qi Chen、Andrew Lensen、Yi Mei、Yanan Sun、Binh Tran、Bing Xue 和 Mengjie Zhang。2019 年。关于进化机器学习的调查。*J. R. Soc. N. Z.* 49, 2 (2019), 205–228。

+   Albukhanajer 等（2015）Wissam A. Albukhanajer、Johann A. Briffa 和 Yaochu Jin。2015 年。在噪声存在下的进化多目标图像特征提取。*IEEE Trans. Cybern.* 45, 9 (2015), 1757–1768。

+   Alexandropoulos and Aridas (2019) Stamatios-Aggelos N Alexandropoulos 和 Christos K Aridas. 2019. 机器学习的多目标进化优化算法：最新综述。*Approximation and Optimization* (2019), 35–55.

+   Aljarah et al. (2018) Ibrahim Aljarah, Hossam Faris, 和 Seyed Mohammad Mirjalili. 2018. 使用鲸鱼优化算法优化神经网络中的连接权重。*Soft Comput.* 22, 1 (2018), 1–15.

+   Andersen et al. (2021) Hayden Andersen, Sean Stevenson, Tuan Ha, Xiaoying Gao, 和 Bing Xue. 2021. 利用基于遗传算法的方法进化神经网络进行文本分类。见于 *Proc. IEEE Congr. Evol. Comput.* 1241–1248.

+   Assunção et al. (2019a) Filipe Assunção, Joao Correia, 和 Rúben Conceição. 2019a. 用于伽马射线探测的人工神经网络自动设计。*IEEE Access* 7 (2019), 110531–110540.

+   Assunção et al. (2018) Filipe Assunção, Nuno Lourenço, P. Machado, 和 Bernardete Ribeiro. 2018. 大规模深度神经网络的拓扑进化。见于 *Proc. Eur. Conf. Genetic Program*. 19–34.

+   Assunção et al. (2019b) Filipe Assunção, Nuno Lourenço, Penousal Machado, 和 Bernardete Ribeiro. 2019b. Fast denser: Efficient Deep Neuroevolution. 见于 *Proc. Eur. Conf. Genetic Program*. 197–212.

+   Atre et al. (2021) Medha Atre, Birendra Jha, 和 Ashwini Rao. 2021. 使用志愿计算类似范式的分布式深度学习。见于 *Proc. Int. Parallel and Distrib. Process. Symp.* 933–942.

+   Barman and Kwon (2020) Shohag Barman 和 Yung-Keun Kwon. 2020. 一种神经进化方法来推断时间序列基因表达的布尔网络。*Bioinformatics* 36, 2 (2020), i762–i769.

+   Behjat and Chidambaran (2019) Amir Behjat 和 Sharat Chidambaran. 2019. 自适应基因组进化神经网络拓扑（AGENT）用于自主体的状态到动作映射。见于 *Proc. Int. Conf. Robot. Autom.* 9638–9644.

+   Bhanu and Krawiec (2002) Bir Bhanu 和 Krzysztof Krawiec. 2002. 用于机器学习中表示转化的特征的共进化构造。见于 *Proc. Genetic Evol. Comput. Conf.* 249–254.

+   Bi et al. (2018) Ying Bi, Bing Xue, 和 Mengjie Zhang. 2018. 一种基于遗传编程的自动特征提取方法用于图像分类。见于 *Proc. Int. Conf. Appl. Evol. Comput.* 421–438.

+   Cano et al. (2017) Alberto Cano, Sebastián Ventura, 和 Krzysztof J. Cios. 2017. 多目标遗传编程用于特征提取和数据可视化。*Soft Comput.* 21, 8 (2017), 2069–2089.

+   Castelli et al. (2011) Mauro Castelli, Luca Manzoni, 和 Leonardo Vanneschi. 2011. 多目标遗传编程用于分类问题中的特征构造。见于 *Proc. Int. Conf. Learn. Intell. Optim.* 503–506.

+   Chai et al. (2022) Zheng-Yi Chai, ChuanHua Yang, 和 Ya-Lun Li. 2022. 基于多目标进化算法的联邦学习通信效率优化。*Evol. Intell.* (2022), 1–12.

+   Chandra (2015) Rohitash Chandra. 2015. 合作进化中的竞争与合作：用于时间序列预测的 Elman 递归神经网络。*IEEE Trans. Neural Netw. Learn. Syst.* 26, 12 (2015), 3123–3136。

+   Chandra and Zhang (2012) Rohitash Chandra 和 Mengjie Zhang. 2012. 用于混沌时间序列预测的 Elman 递归神经网络的合作进化。*Neurocomputing* 86 (2012), 116–123。

+   Chen et al. (2022) Ke Chen, Bing Xue, Mengjie Zhang, 和 Fengyu Zhou. 2022. 基于粒子群优化的高维分类特征选择的进化多任务处理。*IEEE Trans. Evol. Comput.* 26, 3 (2022), 446–460。

+   Chen et al. (2015) Qi Chen, Bing Xue, 和 Mengjie Zhang. 2015. 使用梯度下降的 GP 中的泛化和领域适应。发表于 *Proc. IEEE Congr. Evol. Comput.* 1137–1144。

+   Chen et al. (2019a) Shuxin Chen, Lin Lin, Zixun Zhang, 和 Mitsuo Gen. 2019a. 用于深度神经网络剪枝的进化网络架构搜索。发表于 *Proc. Aust. Conf. Artif. Intell.* 189–196。

+   Chen et al. (2020) Xiangru Chen, Yanan Sun, Mengjie Zhang, 和 Dezhong Peng. 2020. 为图像分类进化深度卷积变分自编码器。*IEEE Trans. Evol. Comput.* 25, 5 (2020), 815–829。

+   Chen et al. (2019b) Yukang Chen, Gaofeng Meng, Qian Zhang, Shiming Xiang, 和 Chang Huang. 2019b. RENAS：强化进化神经架构搜索。发表于 *Proc. IEEE Conf. Comput. Vis. Pattern Recognit.* 4787–4796。

+   Cheng et al. (2021) Fan Cheng, Feixiang Chu, Yi Xu, 和 Lei Zhang. 2021. 基于引导矩阵的多目标进化算法用于高维特征选择。*IEEE Trans. Cybern.* 52, 9 (2021), 9695–9708。

+   Cheng et al. (2017) Yu Cheng, Duo Wang, Pan Zhou, 和 Tao Zhang. 2017. 深度神经网络的模型压缩和加速调查。*arXiv preprint arXiv:1710.09282* (2017)。

+   Chiba et al. (2019) Zouhair Chiba, Noreddine Abghour, Khalid Moussaid, Amina El Omri, 和 Mohamed Rida. 2019. 基于深度神经网络的云环境入侵检测系统的智能构建方法，结合了机器学习算法。*Comput. & Sec.* 86 (2019), 291–317。

+   Choudhary et al. (2020) Tejalal Choudhary, Vipul Mishra, Anurag Goswami, 和 Jagannathan Sarangapani. 2020. 关于模型压缩和加速的全面调查。*Artif. Intell. Rev.* 53, 7 (2020), 5113–5155。

+   Chrabaszcz et al. (2017) Patryk Chrabaszcz, Ilya Loshchilov, 和 Frank Hutter. 2017. 作为 Cifar 数据集替代方案的下采样版 imageNet。*arXiv preprint arXiv:1707.08819* (2017)。

+   Chu et al. (2020) Xiangxiang Chu, Bo Zhang, Ruijun Xu, 和 Hailong Ma. 2020. 移动神经架构搜索中的多目标强化进化。发表于 *Proc. Eur. Conf. Comput. Vis.* 99–113。

+   Conti 等（2018）Edoardo Conti、Vashisht Madhavan、Felipe Petroski Such、Joel Lehman、Kenneth O. Stanley 和 Jeff Clune。2018。通过一群寻求新奇的代理改进深度强化学习的进化策略探索。在 *Proc. Adv. Neural Inf. Process. Syst.*，第 31 卷，5032–5043。

+   Cui 等（2018）Xiaodong Cui、Wei Zhang、Zoltán Tüske 和 Michael Picheny。2018。用于优化深度神经网络的进化随机梯度下降。*Proc. Adv. Neural Inf. Process. Syst.* 31（2018），6051–6061。

+   Da Silva 和 Neto（2011）Sérgio Francisco Da Silva 和 João do ES Batista Neto。2011。使用遗传特征选择方法提高医学图像检索的排名质量。*Decis. Support. Syst.* 51, 4（2011），810–820。

+   Dahal 和 Zhan（2020）Binay Dahal 和 Justin Zhijun Zhan。2020。有效的突变和重组以演化卷积网络。在 *Proc. Adv. Neural Inf. Process. Syst.* 1–6。

+   Dai 等（2019）Zihang Dai、Zhilin Yang、Yiming Yang、Jaime G Carbonell、Quoc Le 和 Ruslan Salakhutdinov。2019。Transformer-XL：超越固定长度上下文的注意力语言模型。在 *Proc. Assoc. Comput. Linguist.* 2978–2988。

+   D’Ambrosio 和 Stanley（2007）David B. D’Ambrosio 和 Kenneth O. Stanley。2007。用于利用神经网络传感器和输出几何的新型生成编码。在 *Proc. Genetic Evol. Comput. Conf.* 974–981。

+   Darwish 等（2020）Ashraf Darwish、Aboul Ella Hassanien 和 Swagatam Das。2020。深度学习的群体和进化计算方法调查。*Artif. Intell. Rev.* 53, 3（2020），1767–1812。

+   Deb 等（2002）Kalyanmoy Deb、Samir Agrawal、Amrit Pratap 和 T. Meyarivan。2002。一个快速且精英的多目标遗传算法：NSGA-II。*IEEE Trans. Evol. Comput.* 6, 2（2002），182–197。

+   Demirkir 和 Sankur（2006）Cem Demirkir 和 Bülent Sankur。2006。使用 Haar 特征选择优化进行目标检测。在 *Proc. IEEE Signal Process. Commun. Appl.* 1–4。

+   Deng 等（2009）Jia Deng、Wei Dong、Richard Socher、Li-Jia Li、K. Li 和 Li Fei-Fei。2009。ImageNet：一个大规模层次化图像数据库。*Proc. IEEE Conf. Comput. Vis. Pattern Recognit.*（2009），248–255。

+   Devlin 等（2018）Jacob Devlin、Ming-Wei Chang、Kenton Lee 和 Kristina Toutanova。2018。Bert：用于语言理解的深度双向 Transformer 预训练。*arXiv preprint arXiv:1810.04805*（2018）。

+   DeVries 和 Taylor（2017）Terrance DeVries 和 Graham W Taylor。2017。通过 Cutout 改进卷积神经网络的正则化。*arXiv preprint arXiv:1708.04552*（2017）。

+   Dong 和 Yang（2020）Xuanyi Dong 和 Yi Yang。2020。NAS-Bench-201：扩展可重复神经架构搜索的范围。在 *Proc. Int. Conf. Learn. Represent.* https://arxiv.org/abs/2001.00326。

+   Dowdell 和 Zhang（2020）Thomas Dowdell 和 Hongyu Zhang。2020。使用 Transformer-XL 的源代码语言建模。*arXiv preprint arXiv:2007.15813*（2020）。

+   [Elsken et al. (2017)](https://arxiv.org/abs/1711.04528) Thomas Elsken, Jan-Hendrik Metzen, and Frank Hutter. 2017. 卷积神经网络的简单高效架构搜索。*arXiv 预印本 arXiv:1711.04528* (2017)。

+   [Elsken et al. (2019)](https://arxiv.org/abs/1804.09081) Thomas Elsken, Jan Hendrik Metzen, 和 Frank Hutter. 2019. 通过拉马克进化实现的高效多目标神经架构搜索。在*学习代表国际会议*。https://arxiv.org/abs/1804.09081。

+   [Erguzel et al. (2014)](https://pubmed.ncbi.nlm.nih.gov/25071325/) Turker Tekin Erguzel, Serhat Ozekes, Selahattin Gultekin, 和 Nevzat Tarhan. 2014. 用于 QEEG 数据分类的蚁群优化的特征选择方法。*Psychiatry Investig.* 11, 3 (2014), 243。

+   [Estévez and Caballero (1998)](https://link.springer.com/chapter/10.1007/3-540-49435-4_19) Pablo A Estévez and Rodrigo E Caballero. 1998. 用于神经网络分类器特征选择的分级遗传算法。在*国际人工神经网络会议*。311–316。

+   [Evans et al. (2018a)](https://ieeexplore.ieee.org/document/8477923) Benjamin Evans, Harith Al-Sahaf, Bing Xue, 和 Mengjie Zhang. 2018a. 进化深度学习：一种基于遗传编程的图像分类方法。在*IEEE Evol. Comput. 学会议*。1538–1545。

+   [Evans et al. (2018b)](https://ieeexplore.ieee.org/document/8479282) Benjamin Patrick Evans, Harith Al-Sahaf, Bing Xue, and Mengjie Zhang. 2018b. 进化深度学习：一种基于遗传编程的图像分类方法。在*IEEE Evol. Comput. 学会议*。1–6。

+   [Fahrudin et al. (2016)](https://doi.org/10.1109/IESYSD.2016.7852844) Tresna Maulana Fahrudin, Iwan Syarif, and Ali Ridho Barakbah. 2016. 特征选择的蚁群算法在微阵列数据集上的应用。在*国际电子学研讨会*。351–356。

+   [Fan et al. (2020)](https://arxiv.org/abs/2001.06678) Zhun Fan, Jiahong Wei, Guijie Zhu, Jiajie Mo, and Wenji Li. 2020. 用于视网膜血管分割的进化神经架构搜索。*arXiv 预印本 arXiv:2001.06678* (2020)。

+   [Fernandes and Yen (2021)](https://doi.org/10.1109/TNNLS.2021.3090053) Francisco Erivaldo Fernandes and Gary G. Yen. 2021. 医学影像诊断的深度神经网络的自动搜索和修剪。*IEEE Trans. Neural Netw. Learn. Syst.* 32, 12 (2021), 5664–5674。

+   [Fogelberg and Zhang (2005)](https://doi.org/10.1007/11552569_36) Christopher Fogelberg and Mengjie Zhang. 2005. 多类物体分类的线性遗传编程。在*澳大利亚人工智能联合会议*。369–379。

+   [Fortuna and Frasca (2021)](https://doi.org/10.1080/01430708.2021.1902983) Luigi Fortuna and Mattia Frasca. 2021. 奇异值分解。*Optim. Rob. 控制* (2021), 51–58。

+   [Frachon et al. (2019)](https://arxiv.org/abs/1911.07729) Luc Frachon, Wei Pang, and George M Coghill. 2019. Immunecs: 神经委员会搜索的人工免疫系统。*arXiv 预印本 arXiv:1911.07729* (2019)。

+   [Freitas (2003)](https://doi.org/10.1007/978-3-540-39695-5_31) Alex A Freitas. 2003. 用于数据挖掘和知识发现的进化算法综述。在*Adv. Evol. Comput.* Springer, 819–845。

+   [Fujino et al. (2017)](https://doi.org/10.1109/SCIS-ISIS.2017.108) Saya Fujino, Naoki Mori, and Keinosuke Matsumoto. 2017. 通过进化深度学习实现人类素描的深度卷积网络。在*国际软计算智能系统会议*。1–5。

+   García 等 (2011) David García, Antonio González Muñoz, 和 Raúl Pérez. 2011. 一种用于遗传学习算法的特征构造的两步法。见 *Proc. Int. Conf. Fuzzy Syst.* (2011), 1255–1262。

+   Gerum 等 (2020) Richard C Gerum, André Erpenbeck, Patrick Krauss, 和 Achim Schilling. 2020. 通过进化剪枝实现的稀疏性防止神经网络过拟合。*Neural Netw.* 128 (2020), 305–312。

+   Golubski 和 Feuring (1999) Wolfgang Golubski 和 Thomas Feuring. 1999. 通过遗传编程演化神经网络结构。见 *Proc. Eur. Conf. Genetic Program*. 211–220。

+   Gou 等 (2021) Jianping Gou, Baosheng Yu, Stephen J Maybank, 和 Dacheng Tao. 2021. 知识蒸馏：综述。*Int. J. Comput. Vis.* 129, 6 (2021), 1789–1819。

+   Guo 等 (2020) Zichao Guo, Xiangyu Zhang, Haoyuan Mu, Wen Heng, Zechun Liu, Yichen Wei, 和 Jian Sun. 2020. 单路径一次性神经架构搜索与均匀采样。见 *Proc. Eur. Conf. Comput. Vis.* 544–560。

+   Hajati 等 (2010) Farshid Hajati, Caro Lucas, 和 Yongsheng Gao. 2010. 使用有效的协进化遗传算法进行人脸定位。见 *Proc. Int. Conf. Digit. Image Comput.: Tech. and Appl.* (2010), 522–527。

+   Hammami 等 (2018) Marwa Hammami, Slim Bechikh, 和 Chih-Cheng Hung. 2018. 面向高维数据的多目标混合过滤-包裹进化方法用于特征构造。见 *Proc. IEEE Congr. Evol. Comput.* 1–8。

+   Han 和 Cho (2006) Sang-Jun Han 和 Sung-Bae Cho. 2006. 基于程序行为的异常检测的进化神经网络。*IEEE Trans. Syst. Man Cybern.* 36, 3 (2006), 559–570。

+   Hancer 等 (2015) Emrah Hancer, Bing Xue, Mengjie Zhang, 和 Dervis Karaboga. 2015. 使用模糊互信息的多目标人工蜂群算法进行特征选择。见 *Proc. IEEE Congr. Evol. Comput.* 2420–2427。

+   He 等 (2021) Xin He, Kaiyong Zhao, 和 Xiaowen Chu. 2021. AutoML: 前沿技术调查。*Knowl-Based Syst* 212 (2021), 106622。

+   He 等 (2017) Yihui He, Xiangyu Zhang, 和 Jian Sun. 2017. 加速非常深层神经网络的通道剪枝。见 *Proc. IEEE Int. Conf. Comput. Vis.* 1398–1406。

+   Ho 等 (2021) Kary Ho, Andrew Gilbert, Hailin Jin, 和 John P. Collomosse. 2021. 深度图像先验的神经架构搜索。*Comput. & Graph.* 98 (2021), 188–196。

+   Hong 和 Cho (2006) Jin-Hyuk Hong 和 Sung-Bae Cho. 2006. 使用专化遗传算法进行高效的大规模特征选择。*Pattern Recognit. Lett.* 27, 2 (2006), 143–150。

+   Hong 等 (2020) Wenjing Hong, Peng Yang, Yiwen Wang, 和 Ke Tang. 2020. 面向延迟感知的多目标基于幅度的剪枝用于深度神经网络压缩。见 *Proc. Int. Conf. on Parallel Probl. Solving Nat.* 470–483。

+   Hosni 等人 (2020) Mohamed Hosni、Ginés García-Mateos 和 Juan Carrillo-de Gea。2020 年。肺癌决策支持系统中集成分类方法的映射研究。*医学与生物工程与计算* 58, 10 (2020), 2177–2193。

+   Hsu 等人 (2021) Yen-Chang Hsu、Ting Hua、Sungen Chang、Qian Lou、Yilin Shen 和 Hongxia Jin。2021 年。基于加权低秩分解的语言模型压缩。在 *国际学习表征会议论文集* https://arxiv.org/abs/2207.00112。

+   Hu 等人 (2021b) Bin Hu、Tianming Zhao、Yucheng Xie、Yan Wang 和 Xiaonan Guo。2021b。MIXP：通过神经元绑定进一步压缩 FLOPs 的高效深度神经网络剪枝。在 *国际联合神经网络会议论文集* 1–8。

+   Hu 等人 (2021a) Yiming Hu、Xingang Wang、Lujun Li 和 Qingyi Gu。2021a。通过收缩与扩展超级网络改进单次神经架构搜索。*模式识别* 118 (2021), 108025。

+   Huang 等人 (2012) Hu Huang、Hong-Bo Xie、Jing-Yi Guo 和 Hui-Juan Chen。2012 年。基于蚁群优化的表面肌电信号分类特征选择方法。*计算生物医学* 42, 1 (2012), 30–38。

+   Huang 等人 (2020) Junhao Huang、Weize Sun 和 Lei Huang。2020 年。基于多目标进化算法的深度神经网络压缩学习。*神经计算* 378 (2020), 260–269。

+   Ijjina 和 Chalavadi (2016) Earnest Paul Ijjina 和 Krishna Mohan Chalavadi。2016 年。使用遗传算法和卷积神经网络的人体动作识别。*模式识别* 59 (2016), 199–212。

+   Irwin-Harris 等人 (2019) William Irwin-Harris、Yanan Sun、Bing Xue 和 Mengjie Zhang。2019 年。用于演化卷积神经网络架构设计的图编码。 在 *IEEE 进化计算大会论文集* 546–553。

+   Izenman (2013) Alan Julian Izenman。2013 年。线性判别分析。在 *现代多变量统计技术*。Springer，237–280。

+   Jaâfra 等人 (2019) Yesmina Jaâfra、Jean Luc Laurent、Aline Deruyver 和 Mohamed Saber Naceur。2019 年。神经架构搜索的强化学习：综述。*图像视觉计算* 89 (2019), 57–66。

+   Jin 等人 (2018) Haifeng Jin、Qingquan Song 和 Xia Hu。2018 年。Auto-keras：具有网络形态学的高效神经架构搜索。*arXiv 预印本 arXiv:1806.10282* (2018)。

+   Jin 等人 (2019) Haifeng Jin、Qingquan Song 和 Xia Hu。2019 年。Auto-Keras：高效的神经架构搜索系统。在 *ACM SIGKDD 国际会议论文集* 1946–1956。

+   Jin (2006) Yaochu Jin。2006 年。*多目标机器学习*。Springer Science。

+   Jones 等人 (2019) David T Jones、Anja Schroeder 和 Geoff S. Nitschke。2019 年。演化深度学习用于识别回避区的星系。*arXiv 预印本 arXiv:1903.07461* (2019)。

+   Junior 和 Yen (2021a) Francisco Erivaldo Fernandes Junior 和 Gary G. Yen。2021a。使用进化策略修剪深度卷积神经网络架构。*信息科学* 552 (2021), 29–47。

+   Junior 和 Yen（2021b）Francisco Erivaldo Fernandes Junior 和 Gary G. Yen。2021b 年。通过进化策略对生成对抗神经网络进行剪枝，用于医疗成像诊断。*Inf. Sci.* 558（2021），91–102。

+   Karaboga 等（2007）Dervis Karaboga，Bahriye Akay 和 Celal Öztürk。2007 年。用于训练前馈神经网络的人工蜂群（ABC）优化算法。发表于*Proc. Int. Conf. Modeling Decis. Artif. Intell.* 318–329。

+   Karegowda 和 Manjunath（2011）Asha Gowda Karegowda 和 A. S. Manjunath。2011 年。基于遗传算法优化的神经网络连接权重在 PIMA 印第安人糖尿病医疗诊断中的应用。*Int. J. Soft Comput.* 2, 2（2011），15–23。

+   Khadka 和 Tumer（2018）Shauharda Khadka 和 Kagan Tumer。2018 年。强化学习中的进化引导策略梯度。发表于*Proc. Adv. Neural Inf. Process. Syst.*，第 31 卷。1196–1208。

+   Khushaba 等（2008）Rami N Khushaba，Ahmed Al-Ani，Akram AlSukker 和 Adel Al-Jumaily。2008 年。结合蚁群算法和差分进化特征选择算法。发表于*Proc. Int. Conf. Ant Colony Optim. Swarm Intell.* 1–12。

+   Kitano（1990）Hiroaki Kitano。1990 年。使用图生成系统设计神经网络的遗传算法。*Complex Syst.* 4, 4（1990），225–238。

+   Kotani 和 Kato（2004）Manabu Kotani 和 Daisuke Kato。2004 年。使用共进化遗传编程进行特征提取。发表于*Proc. IEEE Congr. Evol. Comput.* 614–619。

+   Koutník 等（2010）Jan Koutník，Faustino J. Gomez 和 Jürgen Schmidhuber。2010 年。在压缩权重空间中进化神经网络。发表于*Proc. Genetic Evol. Comput. Conf.* 619–626。

+   Koutník 等（2014）Jan Koutník，Jürgen Schmidhuber 和 Faustino J. Gomez。2014 年。为基于视觉的强化学习进化深度无监督卷积网络。发表于*Proc. Genetic Evol. Comput. Conf.* 541–548。

+   Krawiec（2002）Krzysztof Krawiec。2002 年。基于遗传编程的特征构造用于机器学习和知识发现任务。*Genet. Program Evolvable Mach.* 3, 4（2002），329–343。

+   Krizhevsky 等（2009）Alex Krizhevsky，Geoffrey Hinton 等。2009 年。从微小图像中学习多个层次的特征。（2009 年）。

+   Krizhevsky 等（2012）Alex Krizhevsky，Ilya Sutskever 和 Geoffrey E Hinton。2012 年。使用深度卷积神经网络的 ImageNet 分类。发表于*Proc. Adv. Neural Inf. Process. Syst.*，第 25 卷。1097–1105。

+   Kwasigroch 等（2019）Arkadiusz Kwasigroch，Michał Grochowski 和 Mateusz Mikolajczyk。2019 年。使用网络形态学的深度神经网络架构搜索。发表于*Proc. Int. Conf. Methods and Models in Autom. and Robot.* 30–35。

+   LeCun 等（2015）Yann LeCun，Yoshua Bengio 和 Geoffrey Hinton。2015 年。深度学习。*Nature* 521, 7553（2015），436–444。

+   LeCun 等（1989）Yann LeCun，Bernhard Boser，John S Denker，Donnie Henderson，Richard E Howard 和 Wayne Hubbard。1989 年。反向传播应用于手写邮政编码识别。*Neural computation* 1, 4（1989），541–551。

+   Li et al. (2020) Bailin Li, Bowen Wu, Jiang Su, Guangrun Wang, and Liang Lin. 2020. EagleEye：用于高效神经网络剪枝的快速子网络评估。在*Proc. Eur. Conf. Comput. Vis.* 639–654.

+   Li et al. (2021) Chaojian Li, Zhongzhi Yu, Yonggan Fu, Yongan Zhang, Yang Zhao, Haoran You, Qixuan Yu, Yue Wang, Cong Hao, and Yingyan Lin. 2021. HW-NAS-Bench：硬件感知神经架构搜索基准。在*Proc. Int. Conf. Learn. Represent.* https://arxiv.org/abs/2103.10584.

+   Li et al. (2022) Qing Li, Wei Zhang, Lin Zhao, Xia Wu, and Tianming Liu. 2022. 用于优化时空脑网络分解的进化神经架构搜索。*IEEE. Trans. Biomed. Eng.* 69, 2 (2022), 624–634.

+   Li et al. (2019) Youru Li, Zhenfeng Zhu, Deqiang Kong, Hua Han, and Yao Zhao. 2019. EA-LSTM：基于进化注意力的 LSTM 用于时间序列预测。*Knowl.-Based Syst.* 181 (2019), 104785.

+   Liu et al. (2018c) Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan Huang, and Kevin Murphy. 2018c. 渐进神经架构搜索。在*Proc. Eur. Conf. Comput. Vis.* 19–34.

+   Liu et al. (2021a) Chia-Hsiang Liu, Yu-Shin Han, Yuan-Yao Sung, Yi Lee, Hung-Yueh Chiang, and Kai-Chiang Wu. 2021a. FOX-NAS：快速、设备端和可解释的神经架构搜索。在*Proc. IEEE Int. Conf. Comput. Vis.* 789–797.

+   Liu et al. (2018b) Hanxiao Liu, Karen Simonyan, and Yiming Yang. 2018b. DARTS：可微分架构搜索。在*Proc. Int. Conf. Learn. Represent.* https://arxiv.org/abs/1806.09055.

+   Liu et al. (2019a) Peng Liu, Mohammad D. El Basha, Yangjunyi Li, Yao Xiao, Pina C. Sanelli, and Ruogu Fang. 2019a. 使用加速遗传算法的深度进化网络用于医学图像去噪。*Med. Image Anal.* 54 (2019), 306–315.

+   Liu and Guo (2021) Sicong Liu and Bin Guo. 2021. AdaSpring：适应上下文和运行时演化的深度模型压缩用于移动应用。在*Proc. ACM Interact., Mobile, Wearable Ubiquitous Tech.*, Vol. 5. ACM, 1–22.

+   Liu et al. (2018a) Xiao-Ying Liu, Yong Liang, Sai Wang, Zi-Yi Yang, and Han-Shuo Ye. 2018a. 一种混合遗传算法与包装嵌入方法的特征选择。*IEEE Access* 6 (2018), 22863–22874.

+   Liu et al. (2021b) Yuqiao Liu, Yanan Sun, Bing Xue, Mengjie Zhang, Gary G. Yen, and Kay Chen Tan. 2021b. 关于进化神经架构搜索的综述。*IEEE Trans. Neural Netw. Learn. Syst.* (2021). [`doi.org/10.1109/TNNLS.2021.3100554`](https://doi.org/10.1109/TNNLS.2021.3100554)

+   Liu et al. (2019b) Zechun Liu, Haoyuan Mu, Xiangyu Zhang, Zichao Guo, Xin Yang, K. Cheng, and Jian Sun. 2019b. MetaPruning：用于自动神经网络通道剪枝的元学习。在*Proc. IEEE Int. Conf. Comput. Vis.* 3295–3304.

+   Lomurno 等（2021）Eugenio Lomurno, Stefano Samele, Matteo Matteucci 和 Danilo Ardagna。2021 年。Pareto 最优渐进神经架构搜索。发表于 *Proc. Genetic Evol. Comput. Conf.* 1726–1734。

+   Londt 等（2021）Trevor Londt, Xiaoying Gao 和 Peter Andreae。2021 年。使用遗传编程进化字符级 DenseNet 架构。发表于 *Proc. Int. Conf. Appl. Evol. Comput.* 665–680。

+   Londt 等（2020）Trevor Londt, Xiaoying Gao, Bing Xue 和 Peter Andreae。2020 年。针对文本分类的字符级卷积神经网络进化。*arXiv preprint arXiv:2012.02223*（2020）。

+   Loni 等（2020）Mohammad Loni, Sima Sinaei 和 Ali Zoljodi。2020 年。DeepMaker：用于嵌入式系统中深度神经网络的多目标优化框架。*Microprocess. Microsyst.* 73（2020），102989。

+   Lorenzo 和 Nalepa（2018）Pablo Ribalta Lorenzo 和 Jakub Nalepa。2018 年。深度神经网络的记忆进化。发表于 *Proc. Genetic Evol. Comput. Conf.* 505–512。

+   Lorenzo 等（2017）Pablo Ribalta Lorenzo, Jakub Nalepa, Luciano Sánchez Ramos 和 José Ranilla。2017 年。使用并行粒子群优化进行深度神经网络的超参数选择。发表于 *Proc. Genetic Evol. Comput. Conf.* 1864–1871。

+   Lu 等（2021）Zhichao Lu, Gautam Sreekumar, Erik Goodman, Wolfgang Banzhaf, Kalyanmoy Deb 和 Vishnu Naresh Boddeti。2021 年。神经架构迁移。*IEEE IEEE Trans. Pattern Anal. Mach. Intell.* 43, 9（2021），2971–2989。

+   Lu 等（2019）Zhichao Lu, Ian Whalen, Vishnu Naresh Boddeti, Yashesh D. Dhebar 和 Kalyanmoy Deb。2019 年。NSGA-Net：使用多目标遗传算法的神经架构搜索。发表于 *Proc. Genetic Evol. Comput. Conf.* 419–427。

+   Luo 等（2018）Renqian Luo, Fei Tian, Tao Qin, Enhong Chen 和 Tie-Yan Liu。2018 年。神经架构优化。发表于 *Proc. Adv. Neural Inf. Process. Syst.*, Vol. 31\. 7827–7838。

+   Ma 等（2021b）Ailong Ma, Yuting Wan, Yanfei Zhong, Junjue Wang 和 Liang pei Zhang。2021b 年。SceneNet：使用多目标神经进化架构搜索的遥感场景分类深度学习网络。*ISPRS J. Photogramm. Remote Sens.* 172（2021），171–188。

+   Ma 等（2022）Lianbo Ma, Min Huang, Shengxiang Yang, Rui Wang 和 Xingwei Wang。2022 年。一种自适应局部决策变量分析方法用于大规模多目标和多目标优化。*IEEE Trans. Cybern.* 52, 7（2022），6684–6696。

+   Ma 等（2021a）Lianbo Ma, Nan Li, Guo Yu, Xiaoyu Geng, Min Huang 和 Xingwei Wang。2021a 年。如何简化搜索：面向分类的 Pareto 进化用于一阶段神经架构搜索。*arXiv preprint arXiv:2109.07582*（2021）。

+   Ma 等（2021c）Wenping Ma, Xiaobo Zhou, Hao Zhu, Longwei Li 和 Licheng Jiao。2021c 年。一种两阶段混合蚁群优化用于高维特征选择。*Pattern Recognit.* 116（2021），107933。

+   Maniezzo (1994) V. Maniezzo。1994 年。神经网络拓扑和权重分布的遗传进化。*IEEE Trans. Neural. Netw.* 5, 1 (1994), 39–53。

+   Mauceri 等人 (2021) Stefano Mauceri, James Sweeney, Miguel Nicolau 和 James McDermott。2021 年。通过语法进化进行特征提取用于单类时间序列分类。*Genet. Program. Evolvable Mach.* 22, 3 (2021), 267–295。

+   Mazzawi 等人 (2019) Hanna Mazzawi, Xavi Gonzalvo, Aleksandar Kracun 和 Prashant Sridhar。2019 年。通过大规模神经架构搜索改进关键词检测和语言识别。在 *INTERSPEECH*。1278–1282。

+   Mei 等人 (2017) Yi Mei, Su Nguyen, Bing Xue 和 Mengjie Zhang。2017 年。用于进化作业车间调度规则的高效特征选择算法。*IEEE Trans. Emerg. Topics Comput. Intell.* 1, 5 (2017), 339–353。

+   Miahi 等人 (2022) Erfan Miahi, Seyed Abolghasem Mirroshandel 和 Alexis Nasr。2022 年。用于自动评估人类精子图像的遗传神经架构搜索。*Expert Syst. Appl.* 188 (2022), 115937。

+   Miikkulainen 等人 (2019) Risto Miikkulainen, Jason Liang, Elliot Meyerson, Aditya Rawal, Daniel Fink, Olivier Francon, Bala Raju, Hormoz Shahrzad, Arshak Navruzyan, Nigel Duffy 等。2019 年。进化深度神经网络。在 *Artificial Intelligence in the Age Of Neural Networks and Brain Computing*。Elsevier，293–312。

+   Mirjalili 等人 (2019) Seyedali Mirjalili, Hossam Faris 和 Ibrahim Aljarah。2019 年。*进化机器学习技术*。Springer。

+   Mo 等人 (2021) Hyunho Mo, Leonardo Lucio Custode 和 Giovanni Iacca。2021 年。用于剩余有效寿命预测的进化神经架构搜索。*Appl. Soft Comput.* 108 (2021), 107474。

+   Montana 和 Davis (1989) David J Montana 和 Lawrence Davis。1989 年。使用遗传算法训练前馈神经网络。在 *Proc. of the Int. Joint Conf. Artif. Intell.*, 第 4 卷。762–767。

+   Muni 等人 (2006) Durga Prasad Muni, Nikhil R Pal 和 Jyotirmay Das。2006 年。用于特征选择和分类器设计的遗传编程。*IEEE Trans. Syst. Man. Cybern.* 36, 1 (2006), 106–117。

+   Murray 和 Chiang (2015) Kenton Murray 和 David Chiang。2015 年。自动调整神经网络：应用于 N-Gram 语言模型。在 *Proc. Conf. Empir. Methods Nat. Lang. Proc.* 908–916。

+   Nekrasov 等人 (2020) Vladimir Nekrasov, Chunhua Shen 和 Ian Reid。2020 年。基于模板的紧凑语义分割架构自动搜索。在 *Proc. Winter Conf. Appl. Comput. Vis.* 1980–1989。

+   Neshat 等人 (2020) Mehdi Neshat, Meysam Majidi Nezhad, Ehsan Abbasnejad, Lina Bertling Tjernberg, Davide Astiaso Garcia, Bradley Alexander 和 Markus Wagner。2020 年。用于短期风速预测的进化深度学习方法：以 Lillgrund 海上风电场为例。*arXiv 预印本 arXiv:abs/2002.09106* (2020)。

+   Neshatian 等（2012）库罗什·内沙蒂安、张梦洁 和 彼得·安德烈。2012 年。使用遗传编程的多特征构建的过滤方法。*IEEE Trans. Evol. Comput.* 16, 5 (2012), 645–661。

+   Neshatian 等（2007）库罗什·内沙蒂安、张梦洁 和 马克·约翰斯顿。2007 年。使用遗传编程的特征构建与维度约简。见于 *Proc. Aust. Conf. Artif. Intell.* 242–253。

+   阮等（2014）阮怀博、薛冰、刘艾维 和 张梦洁。2014 年。用于特征选择的 PSO 和统计聚类：一种新表示。见于 *Proc. Asia-Pacific Conf. Simulated Evol. Learn.* 569–581。

+   O’Boyle 和 Palmer（2008）诺埃尔·M·奥博伊尔 和 大卫·S·帕尔默。2008 年。使用人工蚁群进行特征选择与参数优化的同时进行：熔点预测案例研究。*Chem. Cent. J.* 2, 1 (2008), 1–15。

+   Olson 和 Moore（2016）兰道尔·S·奥尔森 和 詹森·H·摩尔。2016 年。TPOT：一种基于树的管道优化工具，用于自动化机器学习。见于 *Proc. Int. Conf. Mach. Learn.* 151–160。

+   O’Neill 等（2018）达米安·奥尼尔、薛冰 和 张梦洁。2018 年。新型树状 ANN 和激活函数的共进化：一种观察性研究。见于 *Proc. Aust. Conf. Artif. Intell.* 616–629。

+   Oong 和 Isa（2011）黄达禧 和 马特·伊萨。2011 年。用于模式分类的自适应进化人工神经网络。*IEEE Trans. Neural Netw.* 22, 11 (2011), 1823–1836。

+   Ortego 等（2020）帕特西·奥尔特戈、阿尔贝托·迪耶斯-奥利万、哈维尔·德尔·塞尔 和 费尔南多·维加。2020 年。用于工业过程模式分类的进化 LSTM-FCN 网络。*Swarm Evol. Comput.* 54 (2020), 100650。

+   彭等（2021）彭博、万书婷、毕莹、薛冰和张梦洁。2021 年。使用遗传编程进行旋转机械故障诊断的自动特征提取与构建。*IEEE Trans. Cybern.* 51, 10 (2021), 4909–4923。

+   彭等（2018）彭逸鸣、陈刚、哈曼·辛格 和 张梦洁。2018 年。通过进化特征学习和策略梯度搜索的大规模强化学习的 NEAT。见于 *Proc. Genetic Evol. Comput. Conf.* 490–497。

+   Phan 等（2020）潘海涛、刘泽春、胡淡和 马里奥斯·萨夫维德斯、郑光廷、沈智强。2020 年。通过基于进化的搜索二值化 MobileNet。见于 *Proc. IEEE Conf. Comput. Vis. Pattern Recognit.* 13417–13426。

+   Polino 等（2018）安东尼奥·波利诺、拉兹万·帕斯卡努 和 丹·阿利斯塔赫。2018 年。通过蒸馏和量化进行模型压缩。见于 *Proc. Int. Conf. Learn. Represent.* https://arxiv.org/abs/1802.05668。

+   Poyatos 等（2022）哈维尔·波亚托斯、丹尼尔·莫利纳、阿里茨·马丁内斯 等。2022 年。EvoPruneDeepTL：一种用于迁移学习的进化剪枝模型，基于深度神经网络。*arXiv preprint arXiv:2202.03844* (2022)。

+   Radford 等 (2018) Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, 等. 2018. 通过生成预训练提高语言理解。 (2018), https://www.cs.ubc.ca/amuham01/LING530/papers/radford2018improving.pdf.

+   Rapaport 等 (2019) Elad Rapaport, Oren Shriki, 和 Rami Puzis. 2019. EEGNAS: 用于脑电图数据分析和解码的神经架构搜索。见 *国际人工智能联合会议论文集* 3–20.

+   Rashid 等 (2020) ANM Bazlur Rashid, Mohiuddin Ahmed, Leslie F Sikos, 和 Paul Haskell-Dowland. 2020. 在大数据中使用随机特征分组的特征选择合作共进。*大数据杂志* 7, 1 (2020), 1–42.

+   Rawal 和 Miikkulainen (2018) Aditya Rawal 和 Risto Miikkulainen. 2018. 从节点到网络：进化递归神经网络。*arXiv 预印本 arXiv:1803.04439* (2018).

+   Real 等 (2019) Esteban Real, Alok Aggarwal, Yanping Huang, 和 Quoc V Le. 2019. 用于图像分类器架构搜索的正则化进化。见 *AAAI 人工智能会议论文集* 第 33 卷 4780–4789.

+   Real 等 (2017) Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc V. Le, 和 Alexey Kurakin. 2017. 大规模图像分类器进化。见 *国际机器学习会议论文集* 2902–2911.

+   Refahi 等 (2020) Mohammad Saleh Refahi, A Mir, 和 Jalal A Nasiri. 2020. 基于进化特征的新型融合方法用于蛋白质折叠识别，使用支持向量机。*科学报告* 10, 1 (2020), 1–13.

+   Ren 等 (2021) Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, 和 Zhihui Li. 2021. 神经架构搜索的综合调查：挑战与解决方案。*ACM 计算机调查* 54, 4 (2021), 1–34.

+   Roberts 和 Claridge (2005) Mark E. Roberts 和 Ela Claridge. 2005. 合作共进的特征构建与物体检测的多阶段方法。见 *应用进化计算会议论文集* 396–406.

+   Rostami 和 Neri (2016) Shahin Rostami 和 Ferrante Neri. 2016. 协方差矩阵适应帕累托归档进化策略与超体积排序自适应网格算法。*集成计算机辅助工程* 23, 4 (2016), 313–329.

+   Rumelhart 等 (1985) David E Rumelhart, Geoffrey E Hinton, 和 Ronald J Williams. 1985. *通过误差传播学习内部表示*。技术报告。加州大学圣地亚哥分校认知科学研究所.

+   Rumelhart 等 (1986) David E Rumelhart, Geoffrey E Hinton, 和 Ronald J Williams. 1986. 通过误差反向传播学习表示。*自然* 323, 6088 (1986), 533–536.

+   Rundo 等 (2019) Leonardo Rundo, Andrea Tangherloni, Marco S Nobile, Carmelo Militello, Daniela Besozzi, Giancarlo Mauri, 和 Paolo Cazzaniga. 2019. MedGA: 一种用于医学成像系统中图像增强的新型进化方法。*专家系统应用* 119 (2019), 387–399.

+   Samala et al. (2018) Ravi K. Samala, Heang-Ping Chan, Lubomir M. Hadjiiski, Mark A. Helvie, Caleb D. Richter, 和 Kenny H. Cha. 2018. 用于数字乳腺断层扫描的迁移学习深度卷积神经网络的进化剪枝。*Phys. Med. Biol.* 63, 9 (2018), 095005。

+   Santra et al. (2021) Santanu Santra, Jun-Wei Hsieh, 和 Chi-Fang Lin. 2021. 梯度下降对差分神经架构搜索的影响：一项调查。*IEEE Access* 9 (2021), 89602–89618。

+   Sapra and Pimentel (2020) Dolly Sapra 和 Andy D Pimentel. 2020. 受限进化分段训练设计卷积神经网络。在 *Proc. Int. Conf. Industr., Eng. and Other Appl. of App. Intell. Syst.* 中。709–721。

+   Schorn et al. (2020) Christoph Schorn, Thomas Elsken, Sebastian Vogel, 和 Armin Runge. 2020. 自动设计错误弹性和硬件高效的深度神经网络。*Neural. Comput. Appl.* 32, 24 (2020), 18327–18345。

+   Sciuto et al. (2020) Christian Sciuto, Kaicheng Yu, Martin Jaggi, Claudiu Cristian Musat, 和 Mathieu Salzmann. 2020. 评估神经架构搜索的搜索阶段。在 *Proc. Int. Conf. Learn. Represent.* 中。https://arxiv.org/abs/1902.08142。

+   Shafti and Pérez (2008) Leila Shila Shafti 和 E. Islas Pérez. 2008. 通过遗传算法和非代数特征构造的数据减少：案例研究。在 *Proc. Int. Conf. Hybri. Intell. Syst.* 中。(2008), 573–578。

+   Shakya et al. (2021) Pratistha Shakya, Eamonn Kennedy, Christopher Rose, 和 Jacob K. Rotein. 2021. 低成本机器嗅觉的高维时间序列特征提取。*IEEE Sens. J.* 21, 3 (2021), 2495–2504。

+   Shang et al. (2022) Haopu Shang, Jia-Liang Wu, Wenjing Hong, 和 Chao Qian. 2022. 通过合作共进化进行神经网络剪枝。*arXiv preprint arXiv:2204.05639* (2022)。

+   Shen et al. (2019) Mingzhu Shen, Kai Han, Chunjing Xu, 和 Yunhe Wang. 2019. 寻找准确的二进制神经架构。在 *Proc. IEEE Int. Conf. Comput. Vis.* 中。2041–2044。

+   Siems et al. (2020) Julien Siems, Lucas Zimmer, Arber Zela, Jovita Lukasik, Margret Keuper, 和 Frank Hutter. 2020. NAS-bench-301 和神经架构搜索的替代基准的案例。*arXiv preprint arXiv:2008.09777* (2020)。

+   Sikdar et al. (2012) Utpal Kumar Sikdar, Asif Ekbal, 和 Sriparna Saha. 2012. 基于差分进化的特征选择和分类器集成用于命名实体识别。在 *Proc. COLING* 中。2475–2490。

+   Smith and Jin (2014) Christopher Smith 和 Yaochu Jin. 2014. 用于时间序列预测的进化多目标生成递归神经网络集成。*Neurocomputing* 143 (2014), 302–311。

+   Socha and Blum (2007) Krzysztof Socha 和 Christian Blum. 2007. 一种用于连续优化的蚁群优化算法：应用于前馈神经网络训练。*Neural. Comput. Appl.* 16, 3 (2007), 235–247。

+   Song 等（2020）Dehua Song, Chang Xu, Xu Jia, Yiyi Chen, Chunjing Xu 和 Yunhe Wang. 2020. 高效残差密集块搜索用于图像超分辨率。见 *Proc. AAAI Conf. Artif. Intell.*, 第 34 卷. 12007–12014.

+   Song（2021）Xin Song. 2021. 基于进化多目标优化算法的智能英语翻译系统。*J. Intell. Fuzzy Syst.* 40 (2021), 6327–6337.

+   Stanley 和 Miikkulainen（2002）Kenneth O Stanley 和 Risto Miikkulainen. 2002. 通过扩展拓扑演化神经网络。*Evol. Comput.* 10, 2 (2002), 99–127.

+   Sun 等（2021）Yanan Sun, Xian Sun, Yuhan Fang, Gary G. Yen 和 Yuqiao Liu. 2021. 用于进化神经网络架构搜索算法性能预测器的新训练协议。*IEEE Trans. Evol. Comput.* 25, 3 (2021), 524–536.

+   Sun 等（2019a）Yanan Sun, Handing Wang, Bing Xue, Yaochu Jin, Gary G Yen 和 Mengjie Zhang. 2019a. 使用端到端随机森林性能预测器的代理辅助进化深度学习。*IEEE Trans. Evol. Comput.* 24, 2 (2019), 350–364.

+   Sun 等（2019b）Yanan Sun, Bing Xue, Mengjie Zhang 和 Gary G Yen. 2019b. 基于块的完全自动化 CNN 架构设计。*IEEE Trans. Neural Netw. Learn. Syst.* 31, 4 (2019), 1242–1254.

+   Sun 等（2019c）Yanan Sun, Bing Xue, Mengjie Zhang 和 Gary G Yen. 2019c. 为图像分类演化深度卷积神经网络。*IEEE Trans. Evol. Comput.* 24, 2 (2019), 394–407.

+   Sun 等（2019d）Yanan Sun, Bing Xue, Mengjie Zhang 和 Gary G. Yen. 2019d. 基于粒子群优化的灵活卷积自编码器用于图像分类。*IEEE Trans. Neural Netw. Learn. Syst.* 30, 8 (2019), 2295–2309.

+   Sun 等（2020）Yanan Sun, Bing Xue, Mengjie Zhang, Gary G Yen 和 Jiancheng Lv. 2020. 使用遗传算法自动设计 CNN 架构用于图像分类。*IEEE Trans. Cybern.* 50, 9 (2020), 3840–3854.

+   Swaminathan 等（2020）Sridhar Swaminathan, Deepak Garg, Rajkumar Kannan 和 Frédéric Andrès. 2020. 用于深度神经网络压缩的稀疏低秩分解。*Neurocomputing* 398 (2020), 185–196.

+   Tanaka 等（2016）Tomohiro Tanaka, Takafumi Moriya 和 Takahiro Shinozaki. 2016. 长短期记忆神经网络语言模型的进化优化。*J. Acoust. Soc. Am.* 140, 4 (2016), 3062–3062.

+   Tang 等（2019）Yajiao Tang, Junkai Ji, Yulin Zhu, Shangce Gao, Zheng Tang 和 Yuki Todo. 2019. 面向差分进化的破产预测神经网络模型。在 *Complexity*, 第 2019 卷. 8682124:1–8682124:21.

+   Tariq 等（2018）Hassan Tariq, Elf Eldridge 和 Ian Welch. 2018. 通过随机投影对高维微阵列数据进行特征构建的高效方法。*PLoS ONE* 13, 4 (2018), e0196385.

+   Telikani 等 (2021) Akbar Telikani、Amirhessam Tahmassebi、Wolfgang Banzhaf 和 Amir H Gandomi。2021 年。进化机器学习：综述。*ACM Comput. Surv.* 54, 8 (2021), 1–35。

+   Teller 和 Veloso (1996) Astro Teller 和 Manuela Veloso。1996 年。PADO：一种用于物体识别的新学习架构。*Symbolic visual learn.* (1996), 81–116。

+   Tian 等 (2019) Haiman Tian、ShuChing Chen、MeiLing Shyu 和 Stuart Harvey Rubin。2019 年。具有相似性敏感进化算法的自动神经网络构建。在 *Proc. IEEE Int. Conf. Inf. Reuse Integr. Data Sci.* 283–290。

+   Tran 等 (2018) Binh Tran、Bing Xue 和 Mengjie Zhang。2018 年。在 PSO 中的新表示方法用于基于离散化的特征选择。*IEEE Trans. Cybern.* 48, 6 (2018), 1733–1746。

+   Tran 等 (2019) Binh Tran、Bing Xue 和 Mengjie Zhang。2019 年。用于高维分类的多特征构建的遗传编程。*Pattern Recognit.* 93 (2019), 404–417。

+   Tran 等 (2016) Binh Tran、Mengjie Zhang 和 Bing Xue。2016 年。在高维数据分类中使用 GP 进行多特征构建。在 *IEEE Symposium Series on Computational Intelligence*。1–8。

+   Vafaie 和 De Jong (1998) Haleh Vafaie 和 Kenneth De Jong。1998 年。利用遗传算法进行特征空间转换。*IEEE Intell. Syst. Appli.* 13, 2 (1998), 57–65。

+   Vargas-Hákim 等 (2022) Gustavo A Vargas-Hákim、Efrén Mezura-Montes 和 Héctor-Gabriel Acosta-Mesa。2022 年。关于用于神经进化的卷积神经网络编码的综述。*IEEE Trans. Evol. Comput.* 26, 1 (2022), 12–27。

+   Vieira 等 (2013) Susana M Vieira、Luís F Mendonça、Goncalo J Farinha 和 João MC Sousa。2013 年。使用 SVM 的改进二进制 PSO 特征选择应用于脓毒症患者的死亡预测。*Appl. Soft Comput.* 13, 8 (2013), 3494–3504。

+   Wang 等 (2021b) Bin Wang、Wenbin Pei、Bing Xue 和 Mengjie Zhang。2021b 年。为图像分类中的深度神经网络演化局部可解释模型无关解释。在 *Proc. Genetic Evol. Comput. Conf.* 173–174。

+   Wang 等 (2020b) Bin Wang、Bing Xue 和 Mengjie Zhang。2020b 年。用于图像分类的深度卷积神经网络的粒子群优化：单目标和多目标方法。在 *Deep Neural Evolution*。Springer，155–184。

+   Wang 等 (2020c) Bin Wang、Bing Xue 和 Mengjie Zhang。2020c 年。通过演化和堆叠可迁移块进行图像分类的深度神经网络的粒子群优化。在 *Proc. IEEE Congr. Evol. Comput.* 1–8。

+   Wang 等 (2021c) Bin Wang、Bing Xue 和 Mengjie Zhang。2021c 年。用于图像分类的可变长度可迁移块的代理辅助粒子群优化。*IEEE Trans. Neural Netw. Learn. Syst.* 33, 8 (2021), 3727–3740。

+   Wang et al. (2020a) Hanrui Wang, Zhanghao Wu, Zhijian Liu, Han Cai, Ligeng Zhu, Chuang Gan, 和 Song Han. 2020a. HAT：针对高效自然语言处理的硬件感知变换器。在*Proc. Assoc. Comput. Linguist.* 7675–7688。

+   Wang et al. (2020d) Xiao-han Wang, Yong Zhang, 和 Xiao-yan Sun. 2020d. 基于人工蜂群的多目标特征选择：一种具有可变样本量的加速方法。*Appl. Soft Comput.* 88 (2020), 106041。

+   Wang et al. (2018) Yunhe Wang, Chang Xu, Jiayan Qiu, Chao Xu, 和 Dacheng Tao. 2018. 朝着进化压缩的方向。在*Proc. ACM SIGKDD Int. Conf. Knowl. Discov. & Data Min.* 2476–2485。

+   Wang et al. (2021a) Zhehui Wang, Tao Luo, Miqing Li, Joey Tianyi Zhou, Rick Siow Mong Goh, 和 Liangli Zhen. 2021a. 用于深度神经网络的进化多目标模型压缩。*IEEE Comput. Intell. Mag.* 16, 3 (2021), 10–21。

+   Wen 和 Xu (2011) Yun Wen 和 Hua Xu. 2011. 一种基于协作共进化的匹兹堡学习分类器系统，嵌入了启发式特征选择。在*Proc. IEEE Congr. Evol. Comput.* 2415–2422。

+   White et al. (2021) Colin White, Willie Neiswanger, 和 Yash Savani. 2021. BANANAS：用于神经架构搜索的贝叶斯优化与神经架构。在*Proc. AAAI Conf. Artif. Intell.*, 第 35 卷. 10293–10301。

+   Winata et al. (2019) Genta Indra Winata, Andrea Madotto, Jamin Shin, Elham J Barezi, 和 Pascale Fung. 2019. 低秩矩阵分解在 LSTM 模型压缩中的有效性。*arXiv preprint arXiv:1908.09982* (2019)。

+   Wu et al. (2021b) Min Wu, Wanjuan Su, Luefeng Chen, 和 Zhentao Liu. 2021b. 面向人机交互的面部表情识别的权重自适应卷积神经网络。*IEEE Trans. Syst. Man Cybern.* 51, 3 (2021), 1473–1484。

+   Wu et al. (2021a) Tao Wu, Xiaoyang Li, Deyun Zhou, Na Li, 和 Jiao Shi. 2021a. 基于差分进化的逐层权重剪枝用于压缩深度神经网络。*Sens.* 21, 3 (2021), 880。

+   Wu et al. (2019) Tao Wu, Jiao Shi, Deyun Zhou, Yu Lei, 和 Maoguo Gong. 2019. 用于神经网络剪枝的多目标粒子群优化。在*Proc. IEEE Congr. Evol. Comput.* 570–577。

+   Wu et al. (2020) Xiang Wu, Ran He, Yibo Hu, 和 Zhenan Sun. 2020. 通过大规模知识蒸馏学习进化嵌入。*Int. J. Comput. Vis.* 128, 8 (2020), 1–18。

+   Xie et al. (2022a) Lingxi Xie, Xin Chen, Kaifeng Bi, Longhui Wei, Yuhui Xu, Zhengsu Chen, Lanfei Wang, Anxiang Xiao, Jianlong Chang, Xiaopeng Zhang, 和 Qi Tian. 2022a. 权重共享神经架构搜索：缩小优化差距的战斗。*ACM Comput. Surv.* 54, 9 (2022), 1–37。

+   Xie 和 Yuille (2017) Lingxi Xie 和 Alan Yuille. 2017. 遗传卷积神经网络。在*Proc. IEEE Int. Conf. Comput. Vis.* 1379–1388。

+   Xie et al. (2022b) Xiangning Xie, Yuqiao Liu, Yanan Sun, Gary G. Yen, Bing Xue, 和 Mengjie Zhang. 2022b. BenchENAS：用于进化神经架构搜索的基准平台。*IEEE Trans. Evol. Comput.* (2022). [`doi.org/10.1109/TEVC.2022.3147526`](https://doi.org/10.1109/TEVC.2022.3147526)

+   Xu et al. (2021) Ke Xu, Dezheng Zhang, Jianjing An, Li Liu, Lingzhi Liu, 和 Dong Wang. 2021. GenExp：基于遗传算法的深度神经网络多目标剪枝。*Neurocomputing* 451 (2021), 81–94。

+   Xue et al. (2012) Bing Xue, Mengjie Zhang, 和 Will N Browne. 2012. 用于特征选择的多目标粒子群优化（PSO）。见于 *Proc. Genetic Evol. Comput. Conf.* 81–88。

+   Xue et al. (2015) Bing Xue, Mengjie Zhang, Will N Browne, 和 Xin Yao. 2015. 关于进化计算方法在特征选择中的应用的综述。*IEEE Trans. Evol. Comput.* 20, 4 (2015), 606–626。

+   Xue et al. (2013) Bing Xue, Mengjie Zhang, Yan Dai, 和 Will N Browne. 2013. 用于特征构建和二分类的 PSO。见于 *Proc. Genetic Evol. Comput. Conf.* 137–144。

+   Yang et al. (2019) Chuanguang Yang, Zhulin An, Chao Li, Boyu Diao, 和 Yongjun Xu. 2019. 使用遗传算法的 CNN 多目标剪枝。见于 *Proc. Int. Conf. Artif. Neural Netw.* 299–305。

+   Yang et al. (2021) Shangshang Yang, Ye Tian, Cheng He, Xingyi Zhang, Kay Chen Tan, 和 Yaochu Jin. 2021. 一种梯度引导的进化方法用于训练深度神经网络。*IEEE Trans. Neural Netw. Learn. Syst.* (2021). [`doi.org/10.1109/TNNLS.2021.3061630`](https://doi.org/10.1109/TNNLS.2021.3061630)

+   Yang et al. (2020) Zhaohui Yang, Yunhe Wang, Xinghao Chen, Boxin Shi, 和 Chao Xu. 2020. CARS：用于高效神经架构搜索的连续进化。见于 *Proc. IEEE Conf. Comput. Vis. Pattern Recognit.* 1826–1835。

+   Yao et al. (2018) Quanming Yao, Mengshuo Wang, Yuqiang Chen, Wenyuan Dai, 和 Yu-Feng Li. 2018. 从学习应用中去除人为因素：自动化机器学习的综述。*arXiv preprint arXiv:1810.13306* (2018)。

+   Yao (1993) Xin Yao. 1993. 进化人工神经网络的综述。*Int. J. Intell. Syst.* 8, 4 (1993), 539–567。

+   Yao and Liu (1996) Xin Yao 和 Yong Liu. 1996. 进化人工神经网络的集成结构。见于 *Proc. Genetic Evol. Comput. Conf.* 659–664。

+   Ying et al. (2019) Chris Ying, Aaron Klein, Esteban Real, Eric Christiansen, Kevin P. Murphy, 和 Frank Hutter. 2019. NAS-Bench-101：迈向可重复的神经架构搜索。见于 *Proc. Int. Conf. Learn. Represent.* https://arxiv.org/abs/1902.09635。

+   Young et al. (2018) Tom Young, Devamanyu Hazarika, Soujanya Poria, 和 Erik Cambria. 2018. 基于深度学习的自然语言处理的最新趋势 [综述文章]。*IEEE Comput. Intell. Mag.* 13, 3 (2018), 55–75。

+   Yu 等 (2009) Hualong Yu, Guochang Gu, Haibo Liu, Jing Shen, 和 Jing Zhao. 2009. 一种改进的蚁群优化算法用于肿瘤标志基因选择。*基因组学、蛋白质组学与生物信息学* 7, 4 (2009), 200–208。

+   Z.-Flores 等 (2020) Emigdio Z.-Flores, Leonardo Trujillo, Pierrick Legrand, 和 Frédérique Faïta-Aïnseba. 2020. 使用遗传编程的脑电图特征提取用于心理状态分类。*算法* 13, 9 (2020), 221。

+   Zemouri 等 (2019) Ryad A. Zemouri, N. Omri, Farhat Fnaiech, Noureddine Zerhouni, 和 Nader Fnaiech. 2019. 一种新的生长剪枝深度学习神经网络算法 (GP-DLNN)。*神经计算应用* 32 (2019), 1–17。

+   Zhan 等 (2021) Zheng Zhan, Yifan Gong, Pu Zhao, Geng Yuan, Wei Niu, Yushu Wu, Tianyun Zhang, Malith Jayaweera, David R. Kaeli, Bin Ren, Xue Lin, 和 Yanzhi Wang. 2021. 基于移动设备的实时超分辨率实现，结合神经架构与剪枝搜索。在 *IEEE 国际计算机视觉会议论文集* 4801–4811。

+   Zhang 和 Mühlenbein (1995) Byoung-Tak Zhang 和 Heinz Mühlenbein. 1995. 在遗传编程中平衡准确性和简约性。*进化计算* 3, 1 (1995), 17–38。

+   Zhang 等 (2022b) Di Zhang, Yichen Zhou, Jiaqi Zhao, 和 Yong Zhou. 2022b. 基于共进化的遥感场景分类参数学习。*国际小波多分辨率信息处理杂志* 20, 2 (2022), 2150046。

+   Zhang 等 (2020b) Haoling Zhang, Chao-Han Huck Yang, Hector Zenil, Narsis Aftab Kiani, Yue Shen, 和 Jesper N. Tegner. 2020b. 通过反向编码树进化神经网络。在 *IEEE 进化计算大会论文集* 1–10。

+   Zhang 和 Gouza (2018) Jiawei Zhang 和 Fisher B Gouza. 2018. GADAM：用于深度神经网络优化的遗传进化 ADAM。*arXiv 预印本 arXiv:1805.07500* (2018)。

+   Zhang 等 (2011) Jun Zhang, Zhi-hui Zhan, Ying Lin, Ni Chen, Yue-jiao Gong, Jing-hui Zhong, Henry SH Chung, Yun Li, 和 Yu-hui Shi. 2011. 进化计算与机器学习的交汇：一项调查。*IEEE 计算智能杂志* 6, 4 (2011), 68–75。

+   Zhang 等 (2021a) Kaiyu Zhang, Jinglong Chen, Shuilong He, Enyong Xu, Fudong Li, 和 Zitong Zhou. 2021a. 增强的可微神经架构搜索与剪枝和多目标优化，用于机械设备的时间高效智能故障诊断。*机械系统信号处理* 158 (2021), 107773。

+   Zhang 等 (2022a) Kangkai Zhang, Chunhui Zhang, Shikun Li, Dan Zeng, 和 Shiming Ge. 2022a. 通过进化知识蒸馏进行学生网络学习。*IEEE 电路与系统视频技术汇刊* 32, 4 (2022), 2251–2263。

+   Zhang (2018) Mengjie Zhang. 2018. 图像分析的进化深度学习。 (2018), https://ieeetv.ieee.org/mengjie–zhang–evolutionary–deep–learning–for–image–analysis。

+   Zhang 和 Cagnoni (2020) Mengjie Zhang 和 Stefano Cagnoni. 2020. 图像分析、信号处理和模式识别中的演化计算与演化深度学习。见于 *Proc. Genetic Evol. Comput. Conf.* 1221–1257。

+   Zhang 等 (2020a) Miao Zhang, Huiqi Li, Shirui Pan, Xiaojun Chang, 和 Steven W. Su. 2020a. 通过多样性最大化克服一-shot NAS 中的多模型遗忘。见于 *Proc. IEEE Conf. Comput. Vis. Pattern Recognit.* 7806–7815。

+   Zhang 和 Smart (2004) Mengjie Zhang 和 Will Smart. 2004. 使用梯度下降搜索的遗传编程用于多类别对象分类。见于 *Proc. Eur. Conf. Genetic Program*. 399–408。

+   Zhang 等 (2017) Yong Zhang, Dun-wei Gong, Xiao-yan Sun, 和 Yi-nan Guo. 2017. 一种基于 PSO 的多目标多标签特征选择方法用于分类。*Sci. Rep.* 7, 1 (2017), 1–12。

+   Zhang 和 Rockett (2005) Yang Zhang 和 Peter I. Rockett. 2005. 使用多目标遗传编程演化最优特征提取：边缘检测方法及初步研究。见于 *Proc. Genetic Evol. Comput. Conf.* 795–802。

+   Zhang 和 Rockett (2011) Yang Zhang 和 Peter I. Rockett. 2011. 一种通用优化特征提取方法，使用多目标遗传编程。*Appl. Soft Comput.* 11, 1 (2011), 1087–1097。

+   Zhang 等 (2021b) Yidan Zhang, Youheng Zhen, Zhenan He, 和 Gray G. Yen. 2021b. 演化修剪效率的提高。见于 *Proc. Int. Joint Conf. Neural Netw.* 1–8。

+   Zhao 等 (2006) Qijun Zhao, David Zhang, 和 Hongtao Lu. 2006. 一种直接演化特征提取算法用于分类高维数据。见于 *Proc. AAAI Conf. Artif. Intell.*, Vol. 1. 561–566。

+   Zhao 等 (2009) Qijun Zhao, David Dian Zhang, Lei Zhang, 和 Hongtao Lu. 2009. 演化判别特征提取及其在人脸识别中的应用。*EURASIP J. Adv. Signal. Process.* 2009 (2009), 1–12。

+   Zhao 等 (2007) Tianwen Zhao, Qijun Zhao, Hongtao Lu, 和 David Dian Zhang. 2007. 用于分类的袋装演化特征提取算法。见于 *Proc. Int. Conf. Neural Comput.*, Vol. 3. 540–545。

+   Zhou 等 (2021a) Xun Zhou, A. K. Qin, Maoguo Gong, 和 Kay Chen Tan. 2021a. 关于演化构建深度神经网络的调查。*IEEE Trans. Evol. Comput.* 25, 5 (2021), 894–912。

+   Zhou 等 (2020) Yao Zhou, Gary G. Yen, 和 Zhang Yi. 2020. 用于生物医学图像分割的深度神经网络演化压缩。*IEEE Trans. Neural Netw. Learn. Syst.* 31, 8 (2020), 2916–2929。

+   Zhou 等 (2021b) Yao Zhou, Gary G. Yen, 和 Zhang Yi. 2021b. 在块级别演化浅层深度神经网络。*IEEE Trans. Neural Netw. Learn. Syst.* (2021). [`doi.org/10.1109/TNNLS.2021.3059529`](https://doi.org/10.1109/TNNLS.2021.3059529)

+   Zhou 等 (2021c) Yao Zhou, Gary G. Yen, 和 Zhang Yi. 2021c. 一种膝部引导的演化算法用于压缩深度神经网络。*IEEE Trans. Cybern.* 51, 3 (2021), 1626–1638。

+   Zhu 等人 (2019) Hui Zhu, Zhulin An, Chuanguang Yang, Kaiqiang Xu 和 Yongjun Xu. 2019. EENA: Efficient Evolution of Neural Architecture. 见于 *Proc. IEEE Int. Conf. Comput. Vis.* 1891–1899.

+   Zhu 和 Jin (2022) Hangyu Zhu 和 Yaochu Jin. 2022. Real-Time Federated Evolutionary Neural Architecture Search. *IEEE Trans. Evol. Comput.* 26, 2 (2022), 364–378.

+   Zhu 等人 (2007) Zexuan Zhu, Y. Ong 和 Manoranjan Dash. 2007. Markov Blanket-Embedded Genetic Algorithm for Gene Selection. *Pattern Recognit.* 40, 11 (2007), 3236–3248.

+   Zoph 等人 (2018) Barret Zoph, Vijay Vasudevan, Jonathon Shlens 和 Quoc V Le. 2018. Learning Transferable Architectures for Scalable Image Recognition. 见于 *Proc. IEEE Conf. Comput. Vis. Pattern Recognit.* 8697–8710.
