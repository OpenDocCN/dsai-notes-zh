<!--yml

category: 未分类

date: 2024-09-06 20:01:10

-->

# [2005.10691] 通过基于约束的领域知识改进深度学习模型：简要综述

> 来源：[`ar5iv.labs.arxiv.org/html/2005.10691`](https://ar5iv.labs.arxiv.org/html/2005.10691)

# 通过基于约束的领域知识改进深度学习模型：简要综述

安德烈亚·博尔赫西，费德里科·巴尔多，米凯拉·米兰诺

博洛尼亚大学 DISI

###### 摘要

深度学习（DL）模型在广泛的学习任务中表现出色，因为它们可以从大数据集中学习有用的模式。然而，当需要学习非常困难的函数或没有足够的训练数据时，纯粹的数据驱动模型可能会遇到困难。幸运的是，在许多领域，可以提取并利用先验信息来提升 DL 模型的性能。

本文介绍了首次综述了将领域知识（以约束形式表达）整合到 DL 学习模型中的方法，以提高其性能，特别是针对深度神经网络。我们识别了五种（非相互排斥的）类别，涵盖了注入领域知识的主要方法：1）作用于特征空间，2）对假设空间的修改，3）数据增强，4）正则化方案，5）约束学习。

## 1 引言

近年来，各种深度学习（DL）方法在许多不同的学习任务中已被证明成功。DL 模型的一个关键优势是它们能够自动学习数据集中组成特征的*表示*。深度神经网络（DNNs）是最重要和广泛应用的 DL 模型类别。广义而言，DNNs 是*子符号*的机器学习方法，非常擅长从大型数据集中提取有用信息。DL 技术的一个优点是，它们通常不依赖于对底层数据分布和待学习或近似的函数的严格假设。这使得它们可以在许多不同的领域中取得非常好的结果，而无需对 DNNs 的结构和训练算法进行重大修改。

然而，在某些情况下，纯粹的数据驱动模型并不是理想的选择，例如当数据稀缺且学习任务非常困难时。在这种情况下，通过利用领域知识（例如可以用来改进 DL 模型和/或简化训练过程的特定问题信息，如结构化数据、关于数据生成过程的知识、领域专家经验等），可以显著提高神经网络（以及机器学习模型）的性能。因此，利用领域信息来提高 DL 模型的性能是有意义的，这样它们在处理困难学习任务时就不必从头开始。换句话说，*为何再学习你已经知道的东西？*

一般来说，领域知识在深度学习模型中的集成是一个多方面的话题，已从多个角度进行了广泛的探索，涉及不同类型的领域知识和大量不同的目标深度学习模型。在本文中，我们并不声称提供文献中所有方法论的全面和详尽的概述（有关广泛概述，[32] 提供了很好的分类），而是希望专注于一种特定的技术类别，用于将先验信息注入深度学习模型。具体而言，我们考虑可以用约束形式表示的先验知识，以及要用这些信息改进的目标模型，我们将兴趣限制在深度神经网络（DNNs）上。我们考虑不同性质的约束，从一阶和命题逻辑谓词到线性和非线性方程。在本文的范围内，这些约束可以表示输入特征之间的关系、输入与输出特征之间的关系、输出变量的界限。我们考虑硬约束（设定必须满足的条件）和软约束（设定条件并附加惩罚，如果未满足的情况下）。

论文结构如下。第二部分是调查的核心，介绍了文献中关于将领域知识（以约束形式表达）注入深度神经网络（DNNs）的研究项目，并将相关工作分为五个宏观领域。第三部分强调了调查论文与深度学习领域内其他相关领域之间的类比。第四部分讨论了注入方法的共同趋势，并提供了观察和见解。最后，第五部分总结并结束了本文。

## 2 领域知识注入方法

在这一部分，我们探讨了在深度神经网络（DNNs）中注入先验信息的最新方法。我们假设有一个学习任务，其中学习者试图逼近一个将输入$X$映射到输出$y$的函数$f^{*}$；训练集由例子$(x_{i},y_{i})$组成。我们考虑可以用一组约束或谓词$\pi$表达的领域知识。领域知识可以通过代数方程表示，如线性和非线性方程、等式和不等式约束、逻辑公式。这些谓词可以应用于不同的变量组：1）它们可能只涉及输入特征$X$，例如已知良好数据实例的输入特征共享特定属性，或通过一组精确的关系关联；2）约束可能只涉及输出变量$y$，例如网络的输出必须在特定范围内；3）条件可以涉及输入$x_{i}$和输出$y_{i}$，例如，待逼近的真实函数$f$可能是单调的（$x_{1}\leq x_{2}\rightarrow y_{1}\leq y_{2}$）。作为基于约束的信息的一个特殊情况，我们还包括以图的形式表达的领域知识（例如知识图谱），因为图可以被分解为包含节点和边之间关系的更简单约束的集合。基于这些假设，可以通过多种方式将约束表达的领域知识集成到 DNNs 中。我们将文献中的工作分为五个分支，基于注入机制：1）特征空间，2）假设空间，3）数据增强，4）正则化方案，5）约束学习。每个子部分都专门讨论一个分支。

### 2.1 特征空间

DL 模型的表现高度依赖于可用训练数据的质量，无论是标记的还是未标记的；数据中的特征定义了*特征空间*，其隐含信息由 DNN 提取。特征空间的形状对 DL 模型的表现和训练的难易程度是一个关键问题。例如，*特征工程*是一种常见方法，通过选择有用特征和/或转换原始特征来提高纯数据驱动 ML 模型的准确性，以促进学习者的任务。一般而言，这是一个困难的问题，需要系统专家和 ML 从业者付出大量努力[14]。近年来，几条研究路径探讨了自动探索特征空间以提取最相关特征的可能性，大多数方法属于 AutoML 领域[26]和强化学习[15]。目前大多数特征工程方法旨在为特定学习任务选择最佳特征，通常倾向于通过选择最相关的特征（特征提取或特征压缩）来减少特征空间。此外，这些方法通常是纯数据驱动的，且需要大量数据；尽管它们旨在以高效的方式探索特征空间，但当特征数量很大时，这变成了一个非平凡的问题。

一个相对未被探索的方向是利用领域知识创建新特征，从而*明确*原始数据中隐藏的信息。这是一种特征空间扩展的形式，目的是突出原始特征中嵌入的先验知识，但神经网络不容易提取。在实际应用中，该领域提出的方法在原始输入特征 $X$ 上工作，生成一个扩展的特征集 $X^{\prime}=X\cup\{x_{j}\}$，其中 $\{x_{j}\},j\in 1,..N_{j}$ 是由额外特征组成的集合（$N_{j}$ 是添加的特征数量）。新特征 $x_{j}$ 的计算是原始特征的组合（线性或非线性方程），这取决于领域约束。例如，[1] 使用由知识图谱编码的领域特定信息来丰富特征空间。知识图谱中明确描述的关系表示原始输入特征之间的约束（软约束和硬约束），这些关系可以用来创建附加特征，从而提高监督 DNN 的准确性。类似地，[23] 通过领域基础特征来增加特征空间，提升 DL 模型的性能。他们没有使用知识图谱来获取额外特征，而是使用决策树集群解决一个子集数据的分类任务，这些数据用于 DL 模型的训练。每棵树学习领域特定的信息，并通过其自身的分数参与最终预测；这些分数随后作为附加特征添加到训练集中。另一个通过丰富特征空间来整合领域知识的方法由 [3] 讨论，该方法研究了通过添加领域启发特征来改进 DNN 在预测足球比赛结果中的表现。训练集是由两支不同球队的比赛及其相关结果组成的时间序列；他们的方法包括添加一组新特征，涵盖 i) 比赛中涉及的球队的评级和 ii) 每支球队在最近 $k$ 场比赛中取得的结果。这些新特征被编码为应用于原始输入 $X$ 的一组线性和非线性方程。

### 2.2 假设空间

DNN 可以通过其在所谓的*假设空间*中的位置来特征化，即覆盖其结构和超参数的多维空间。神经网络的架构是决定其在不同学习任务中性能的一个非常重要的因素。假设空间多年来一直在领域知识的隐式指导下进行探索，这一点可以通过卷积网络的引入得到证明，卷积网络的结构基于局部性假设（例如，图像中彼此接近的像素是相关的）。对时间局部性的隐性知识也导致了针对处理时间序列和序列的广泛架构，例如递归神经网络（RNNs）、长短期记忆网络（LSTMs）、时间卷积网络[2]。

最近几年，显著的研究努力集中在探索针对可以用图的形式表达领域知识的情况的深度神经网络（DNN）架构上，特别是利用一种被称为*图神经网络*（GNNs）的深度学习模型[27]；*图卷积网络*（GCNN）[16]也被引入以利用相同类型的图可表达先验信息。由于 GCNN 能够处理数据，其结构可以通过图来描述，这得益于在许多深度学习网络中卷积层在谱域的推广，GNNs 已被广泛应用于多个领域[37]。GCNNs 最常见的应用涉及半监督分类任务，目的是预测图中未标记节点的类别——这是一种图学习的情况。利用可以表达为图的先验信息也被提议用于设计其他类型的神经网络，即那些结构类似于 LSTM 的网络，但节点连接由先验信息决定[20]。类似地，[13]将 RNNs 的时间结构与基于空间的信息结合起来，即领域信息被编码为每个动作的序列，每个动作都有时间和空间位置，然后通过扩展的 RNN 进行表示。如前所述，表示为图的领域知识可以通过一组约束来表达，这些约束通过边缘编码节点之间的关系。目前，该领域绝大多数信息注入方法（以及本节列出的所有方法）都在输入特征$X$上操作，这些特征可以被看作是图结构中的概念和相关连接。

### 2.3 数据增强

除了在特征和假设空间上进行工作，另一个将领域知识注入深度神经网络（DNN）的机制涉及训练数据，主要表现为创建*全新*的整个训练集或根据领域知识定义的标准（例如，遵循输入特征之间某些关系的示例）向现有数据集中添加新示例。我们将这些方法称为*数据增强*。基于先前信息（约束）的数据增强方法近年来开始被探索，特别是为了应对数据集规模有限及相关的泛化性能差的问题[12]。数据增强技术在基于图像的学习任务（例如图像分类）中有着成功的历史[33]。对于图像分类任务，可以通过对原始训练集中的图像应用各种变换来增强训练集，从而为神经网络提供更为多样化的示例。选择最佳的变换方法来增强现有数据通常是由领域专家提供的信息指导的。特别是，基于约束的领域信息可以用来增强现有数据，例如旋转、扭曲、翻转等线性和非线性函数。例如，[4]提出了一种数据增强技术来训练 LSTM 模型以分类化学分子。每个分子可以描述为其组成元素的组合，编码为字符串的串联。单个分子有多种可能的编码字符串；作者建议通过枚举每个数据点/分子的化学允许组合来扩展训练集。枚举通过启发式算法进行，该算法对生成的示例强加了与原始数据点相同的化学性质；这些性质被编码为输入特征（串联字符串）之间的约束集合（表示可接受的化学性质的线性组合）。在这种情况下，约束涉及输入特征$x_{i}$和输出$y_{i}$，因为$X$之间的关系用于生成具有相同输出值（标签）的新数据点。

[24] 提出了一个不同的数据集增强方法：他们考虑了*特征侧信息*，即描述特征属性和/或特征关系的领域知识。特征侧信息以矩阵的形式表示，其中的行代表与每个特征相关的先验信息；引入了相似性函数来计算不同特征之间的成对相似性。通过应用一种保留相关标签并扰动相似特征值的变换，从原始示例中获得一个增强的训练数据点。再次强调，重点在于输入特征 $x_{i}$ 之间的约束。类似地，[31] 设计了一种基于特征之间相似度的增强方法，旨在提高用于情感分析的 CNN 的结果。在这种情况下，原始数据集由标记句子（训练示例）组成；每个句子可以分解为一组情感词，即特征。作者引入了一种情感相似度度量，然后提出了一种基于二次规划的算法，从原始句子中生成相似句子，基于情感相似度分数；增强的相似示例标注为与相应原始训练点相同的标签。

### 2.4 正则化方案

正则化是避免机器学习模型过拟合的广泛使用的方法，但它也可以用来注入领域知识。为此，一些形式的先验知识，即约束，被转换为能够测量与领域知识一致性的正则化项，并指导损失优化过程。更一般地，损失函数可以定义如下：

|  | $\sum_{i=1}^{N}\lambda_{\tau}L(f(x_{i}),y_{i})+\lambda_{\pi}L_{\pi}(f(x_{i}))$ |  |
| --- | --- | --- |

其中 $L$ 代表真实的损失，例如 MSE，而 $L_{\pi}$ 代表在一组约束 $\pi$ 下的正则化项；这些项分别用 $\lambda_{\tau}$ 和 $\lambda_{\pi}$ 加权；这些权重参数的选择并非简单且可能持续影响最终结果（[10] 利用 *拉格朗日对偶性* 解决了这个问题）。在过去几年中，许多作者在这类方法上进行研究，提出了各种解决问题的方法；例如，[25] 开发了一个叫做 *领域自适应神经网络*（DANN）的 DNN，利用约束的数学公式，即逼近和单调性约束，其满足程度用作正则化项。[8] 提出的 *基于语义的正则化*（SBR）方法是一种更通用的方式，它提供了一套规则，将一阶逻辑公式转化为模糊约束，然后作为损失函数中的惩罚因子。这通过引入一个 *t-范数* 函数来实现，该函数可以通过不同的方式定义，以适应正则化中涉及的领域约束的解释，从而提供了一个可调整的工具。[22] 提出了一种高度相关的方法，称为 *LYRICS*，这是一个引入声明性语言以表达领域知识的框架，并在 DNN 上应用 SBR，从而允许对约束和先验信息进行非常灵活的表示。[35] 提出了一个带有语义损失的随机方法，该方法使用一个正则化项，该项由生成满足领域约束的状态的概率给出；在训练过程中，不满足所需约束的状态会受到惩罚，作用于损失函数。[29] 提出了一个受 SBR 启发的技术，用于在 DNN 中注入领域约束，扩展部分变量分配以解决部分拉丁方问题，具体是找到符合领域约束的可行解。

### 2.5 在约束条件下学习

深度学习（DL）模型通常用于特定任务，例如解决优化问题。这些方法通常遵循两个步骤的过程：首先使用观察到的数据训练模型，然后用来近似优化问题的某个方面，例如成本函数。在这些情况下，模型的准确性并不是衡量方法性能的唯一标准，因为任务相关的指标可能更为重要。最近出现了一种新的范式，即*决策聚焦学习*（或*端到端学习*），其中深度神经网络（DNN）被训练以直接产生整体任务的良好结果。在这种情况下，引入了针对特定优化任务的先验信息，以指导 DNN 的训练，用于近似所需的函数。这类方法与正则化方法有一些相似之处，因为损失函数中的惩罚项也可以应用于端到端学习。然而，由于在这种情况下 DNN 被用于更大的优化模型中，影响其行为的机制有所不同。一般来说，决策聚焦学习的 DNN 为目标任务生成代理（中间）解，给定网络的固定参数化，然后通过损失函数进行优化；然而，由于解空间可能不连续，可能会出现可微性问题，这通常通过变换解决。

这种方法的第一个例子可以在[34]中看到，其中它被应用于组合优化，通过引入代理解的连续放松（代理解是离散的），即*凸包*；然后通过将关于决策变量的梯度与模型自身参数的梯度相结合来计算损失。[9]提供了一个略有不同的贡献，它将端到端学习应用于随机优化问题；然而，在这种方法中，重点在于训练过程，其中梯度下降使用两个函数来更新网络参数：一个计算约束违反次数，另一个由经典损失函数表示。如果代理解不满足约束，则使用第一个函数更新参数，否则使用对数似然损失。

[17]提供了一种完全不同的方法来处理先验知识通过一阶逻辑公式表达的问题；在这种情况下，先验信息直接嵌入到 DNN 中，其中节点称为*命名神经元*，被标记以模仿公式中的逻辑元素；这些节点用于构建*约束神经层*，根据层中每个命名神经元的真值来生成输出。

最近，[19]引入了一种类似于端到端学习范式的方法，但更通用，称为*DL2*。DL2 是一个显式嵌入约束到 DNN 中的框架，具体来说，它允许将逻辑公式转换为损失函数，即通过递归定义公式中每个项的相应数学方程；训练则使用投影梯度下降进行。该模型还提供了类似 SQL 的查询语言，允许对特定输入进行网络查询，以便：检查约束是否得到满足，并为观测数据集之外的输入训练模型；基本上，网络可以通过查询来挑战，以帮助提高其准确性超出训练数据——这种方法称为*全球训练*。

## 3 相关领域

另一个利用先验信息来提升性能的领域是*强化学习*。在这个领域，知识领域信息也可以用来改进模型和/或将非常困难的问题转化为更易处理的问题；例如，通过为训练算法创建良好的初始条件，从而减少所需的训练样本数量，并因此为强化学习过程提供*温暖的起点*[28]。先验信息在各种适合强化学习的背景下已成功应用，带来了显著的好处[18]。然而，在这种设置中注入领域知识时必须考虑一个重要的方面：领域知识中的不确定性如果在学习阶段初期做出错误的决策（由系统状态的某些不确定或不完整的信息引起）可能会严重阻碍学习过程[30]。另一个领域是领域知识在深度神经网络（DNN）权重初始化中的好处。例如，[36]描述了一种针对工业过程行为预测的半监督预训练策略；该预训练基于关于化学性质和数据集特征之间关系的领域信息。类似地，[11]利用基于语义的知识来解决标准机器学习技术无法解决的人工任务；关键思想是向学习者提供关于适当中间概念的“提示”。

## 4 观察与备注

在这一部分，我们将讨论之前描述的所有知识注入方法的一些共同特征，并提供一些见解。

#### 特征操作

组成数据的特征通常是第二部分中描述的技术的目标，因为它们提供了一种实用的机制，用于在各种深度学习模型中注入先验信息。当知识能够以输入特征之间关系的形式表达时，这种方法尤其有效，这些关系可以用来增加训练样本的数量（这些关系提供了从原始样本生成新有效样本的指导）或创建新的、更具信息性的特征，这些特征可以突出数据中已经存在但难以提取的隐含信息。值得注意的一点是，作用于特征空间并不一定需要关于标签$y_{i}$的信息，因为领域知识可能仅涉及$x_{i}$特征之间的约束；这表明这种方法特别适合无监督学习任务。这些方法与近年来最主要的深度学习研究方向相对立，即开发完全数据驱动的模型，这些模型在没有任何帮助的情况下提取特征空间中隐藏的所有信息。显然，拥有能够在不考虑领域信息的情况下实现良好性能的强大通用模型是一个非常重要的目标，然而我们认为，存在许多上下文可以从领域衍生的先验信息中受益，这一研究方向值得在未来的工作中进一步探索。

#### 精度与优化

我们认为一个部分尚未探索的领域是深度学习模型（例如分类任务的高准确性和回归任务的低误差）准确性与模型约束满足之间的权衡。例如，我们已经提到在*端到端*学习中，目标是优化神经网络以完成特定任务，因此我们可能不会观察到模型本身准确性的提升（例如均值绝对误差），而是对特定任务的改善。这也适用于正则化方案，其中结果模型的输出与先验知识更一致，但预测准确性并没有提升。这是一个隐含在最小化由多个不指向相同方向的项组成的目标函数的愿望中的方面。一般来说，大多数这些方法选择对神经网络输出施加“软”约束，即约束不会被严格执行（如硬约束），而是优化尝试平衡不同的项。这个问题在 DNN 上只得到部分研究[21, 7]，尽管在优化领域中已知，最小化一个包含多个项的目标函数会导致较差的收敛特性，主要因为优化器可能会专注于目标函数的一个项而忽略其他项；此外，施加多种不同性质的约束意味着这些项可能不具有可比性。最后，这些方法中的一个额外复杂因素是为各种项（模型准确性和基于约束的项）选择适当的权重。

#### 小数据集

对于深度学习方法而言，一个不可忽视的问题是需要大量的数据，最好是带标签的数据。在许多情况下，这种数据并不存在，因此深度模型的训练受到阻碍。注入领域知识可以在训练数据稀缺时提升深度学习模型的性能。为此，最明显的选择是那些扩充现有数据的技术，但正则化方案和特征工程方法也能提供帮助，前者通过“引导”DNN 的训练过程，后者通过简化学习任务和将附加特征添加到原始数据中而带来好处。一般来说，在*主动学习*以及其他无法绕过数据不足的场景中，整合先验信息的技术可以非常有用。如今，大多数主动学习的方法并未借助领域知识，而利用这些知识可能带来很大好处，例如驱动新实例的选择，这一探索目前是由基于信息增益等度量的领域无关策略来指导的。一些近期的研究朝着这个方向做了初步工作。例如，[6] 提出了主动学习和端到端学习的组合，通过将 DNN 嵌入浮点变量精度调优的优化模型中。由于训练集相对较小，DNN 初期预测不准确；作者利用主动学习，通过在新示例上重新训练 DNN 来迭代改进它，这些示例即为优化模型的解，直接依赖于领域知识。

#### 评估指标

在领域信息注入领域，一个尚未完全探索的问题是评估注入机制性能的最佳指标。一般来说，大多数常见的深度学习技术都是基于单一指标来进行测量，如准确率（分类任务）或平均绝对误差或均方误差（回归任务）。然而，当需要评估注入领域知识的好处时，这些指标并不是最公平的。例如，常规化方案和将约束嵌入神经网络的方法的一个共同点是，它们的目标不仅仅是减少预测误差或提高模型的准确性，而是获得输出符合某些期望特性（例如单调性）或输入与输出之间需要保持某些关系的神经网络。在实践中，这意味着没有建立且直接的方法来衡量知识注入方法的改进，因为每个领域的不同作者选择了不同的评估指标。在许多情况下，作者将他们的注入方法与标准深度学习模型进行比较，使用为特定任务精心设计的测试集。例如，强制输出不违反特定约束的模型可以在包含违反约束实例的数据集上进行训练，但仅在没有违反的数据集上进行测试。这在进行公平比较时是可以接受的，但增加了创建人工实验设置的风险。这种缺乏同质性的问题并不简单，它使得不同技术之间的比较变得复杂。制定一套共同的基准和关键性能指标将极大地有利于这一研究领域。

#### 朝着统一框架的方向

总体而言，可以注意到之前讨论的各种方法在相对孤立的情况下运作。这是可以理解的，部分原因在于领域注入技术本质上是领域特定的。这个问题由于可能的注入机制和目标的数量庞大而加剧。这导致了缺乏共同的视角，使得比较不同的注入方法变得更加困难；然而，最近已进行了一些尝试，例如[5]，其中采用了多种知识注入技术来提升处理复杂学习任务的 DNN。我们认为，一个统一的方法论或框架来注入领域衍生的约束将是推进该领域研究进展的重要一步。这样的统一框架需要一个共同的语言来表达领域知识；它应该是一个具有表现力（允许表示多种不同类型的关系和概念）和灵活的语言，能够描述来自非常多样化领域的信息。我们认为基于约束和逻辑谓词的语言可能是非常合适的选择，特别是得益于诸如约束编程和混合整数与线性编程等范式，这些方法已被证明能够处理广泛的领域特定挑战。下一步将是决定最佳的信息注入机制；要得到详细的答案需要进行后续研究，但在这一阶段可以提供一些指导。首先，当可用数据稀少时，应优先考虑数据增强和特征空间操控技术，因为它们通过利用输入集特征$x_{i}$之间的已知关系以及输入特征和输出特征$y_{i}$之间的关系来增加训练集的规模。其次，如果输入数据中的信息隐藏且不易提取，特定的 DNN 架构可以极其有用——例如，作用于假设空间——因为领域专家知识可以直接注入到神经网络结构中，从设计到训练算法。最后，正则化方法和神经网络中的显式约束学习是端到端学习以及在一般情况下，更复杂学习任务中非常有效的策略，其中模型的准确性不是唯一的性能指标。在这种情况下，应谨慎选择优化问题和 DNN 损失函数纯最小化之间的正确权衡。这是一个非平凡的问题，因为它使得正则化和约束学习技术的实际开发变得复杂，加上这些技术非常特定于任务（例如，一种上下文的权重集不适合其他上下文）；实施这些方法的从业者将面临比数据增强方法更为陡峭的挑战，而数据增强方法通常也更具可迁移性。

## 5 结论

将以约束形式表达的领域知识整合到深度神经网络中是一个广泛的研究领域，近年来引起了越来越多的研究兴趣。这个话题从不同角度被各种方法探讨，通常是相对孤立的，这可能阻碍了研究突破。本文提供了一个跨学科的首次尝试，对现有方法进行分类，识别领域知识注入的主要技术类别，并突出与深度学习领域相关的联系。此外，我们识别了一系列已解决的共同趋势和问题以及仍需解决的挑战，希望为未来的研究工作提供有用的见解和指导。

## 致谢

本工作部分得到了欧洲 H2020 FET 项目 OPRECOMP（g.a. 732631）和 ICT 项目 AI4EU（g.a. 825619）的支持。

## 参考文献

+   [1] M. Atzmueller 和 E. Sternberg。使用知识图谱的混合主动特征工程。发表于知识捕捉会议论文集，第 1–4 页, 2017。

+   [2] S. Bai, J. Z. Kolter, 和 V. Koltun。通用卷积和递归网络用于序列建模的实证评估。arXiv 预印本 arXiv:1803.01271, 2018。

+   [3] D. Berrar, P. Lopes, 和 W. Dubitzky。将领域知识融入足球结果预测的机器学习中。机器学习, 108(1):97–126, 2019。

+   [4] E. J. Bjerrum. 将笑脸枚举作为神经网络分子建模的数据增强。arXiv 预印本 arXiv:1703.07076, 2017。

+   [5] A. Borghesi, F. Baldo, M. Lombardi, 和 M. Milano。在神经网络中注入领域知识以进行精度计算。arXiv 预印本 arXiv:2002.10214, 2020。

+   [6] A. Borghesi, G. Tagliavini, 等。结合学习与优化进行精度计算。发表于第 17 届 ACM 国际计算前沿会议论文集, 2020。

+   [7] F. De Tassis, M. Lombardi, 和 M. Milano。教老狗学新把戏：带约束的监督学习。arXiv 预印本 arXiv:2002.10766, 2020。

+   [8] M. Diligenti, M. Gori, 和 C. Sacca。基于语义的正则化用于学习和推断。人工智能, 244:143–165, 2017。

+   [9] P. Donti, B. Amos, 和 J. Z. Kolter。基于任务的端到端模型学习在随机优化中的应用。发表于神经信息处理系统进展, 第 5484–5494 页, 2017。

+   [10] F. Fioretto, T. W. Mak, 等。带约束的深度神经网络的拉格朗日对偶框架。arXiv 预印本 arXiv:2001.09394, 2020。

+   [11] Ç. Gülçehre 和 Y. Bengio。知识很重要：优化中先验信息的重要性。机器学习研究期刊, 17(1):226–257, 2016。

+   [12] A. Hernández-García 和 P. König。数据增强代替显式正则化。arXiv 预印本 arXiv:1806.03852, 2018。

+   [13] A. Jain、A. R. Zamir、S. Savarese 和 A. Saxena. Structural-rnn：在时空图上的深度学习。在 IEEE 计算机视觉与模式识别会议论文集，页面 5308–5317, 2016.

+   [14] S. Khalid、T. Khalil 和 S. Nasreen. 机器学习中特征选择和特征提取技术的综述。在 2014 科学与信息会议，页面 372–378。IEEE, 2014.

+   [15] U. Khurana、H. Samulowitz 和 D. Turaga. 使用强化学习进行预测建模的特征工程。在第三十二届 AAAI 人工智能会议，2018.

+   [16] T. N. Kipf 和 M. Welling. 基于图卷积网络的半监督分类。在第五届国际学习表示会议，ICLR ’17, 2017.

+   [17] T. Li 和 V. Srikumar. 用一阶逻辑增强神经网络。arXiv 预印本 arXiv:1906.06298, 2019.

+   [18] J. Luketina、N. Nardelli 等. 一种由自然语言启发的强化学习综述。arXiv 预印本 arXiv:1906.03926, 2019.

+   [19] D. D.-C. T. G. C. Z. M. V. Marc Fischer、Mislav Balunovic. Dl2：用逻辑训练和查询神经网络。在国际机器学习会议，2019.

+   [20] K. Marino、R. Salakhutdinov 和 A. Gupta. 知识越多：利用知识图谱进行图像分类。arXiv 预印本 arXiv:1612.04844, 2016.

+   [21] P. Márquez-Neila、M. Salzmann 和 P. Fua. 对深度网络施加硬性约束：承诺与局限性。arXiv 预印本 arXiv:1706.02025, 2017.

+   [22] G. Marra、F. Giannini、M. Diligenti 和 M. Gori. Lyrics：一个将逻辑推理和深度学习集成的通用接口层。在 ECML-PKDD 2019，2019.

+   [23] R. Miao、Z. Yang 和 V. Gavrishchaka. 利用领域专家知识、提升和深度学习来识别稀有和复杂状态。在《物理学期刊：会议系列》，卷 1207，页码 012016。IOP Publishing, 2019.

+   [24] A. Mollaysa、A. Kalousis、E. Bruno 和 M. Diephuis. 学习利用特征侧信息进行增强。在亚洲机器学习会议，页面 173–187, 2019.

+   [25] N. Muralidhar、M. Islam 等. 将先验领域知识融入深度神经网络。在 2018 IEEE 国际大数据会议（Big Data）。IEEE, 2018.

+   [26] F. Nargesian、H. Samulowitz、U. Khurana、E. B. Khalil 和 D. S. Turaga. 学习特征工程用于分类。在 IJCAI，页面 2529–2535, 2017.

+   [27] F. Scarselli、M. Gori、A. C. Tsoi、M. Hagenbuchner 和 G. Monfardini. 图神经网络模型。IEEE 神经网络学报，20(1)：61–80, 2008.

+   [28] A. Silva 和 M. Gombolay. Prolonets：神经编码人类专家的领域知识以启动强化学习。arXiv 预印本 arXiv:1902.06007, 2019.

+   [29] M. Silvestri、M. Lombardi 和 M. Milano. 将领域知识注入神经网络：对受限问题的受控实验。arXiv 预印本 arXiv:2002.10742, 2020.

+   [30] K. Terashima 和 J. Murata. 关于利用先验信息加速强化学习的研究。发表于《SICE 年会 2011》，第 537–543 页。IEEE，2011 年。

+   [31] K. Vo, D. Pham, M. Nguyen, T. Mai, 和 T. Quan. 领域知识与深度学习相结合用于情感分析。发表于《人工智能跨学科趋势国际研讨会》，第 162–173 页。Springer，2017 年。

+   [32] L. von Rueden, S. Mayer, 等. 有信息的机器学习 – 整合知识到学习系统的分类与综述。arXiv 预印本 arXiv:1903.12394v2，2020 年。

+   [33] J. Wang 和 L. Perez. 使用深度学习进行图像分类的数据增强效果。《卷积神经网络视觉识别》，第 11 页，2017 年。

+   [34] B. Wilder, B. Dilkina, 和 M. Tambe. 数据决策管道的融合：针对组合优化的决策导向学习。发表于《AAAI 人工智能会议论文集》，第 33 卷，第 1658–1665 页，2019 年。

+   [35] J. Xu, Z. Zhang, 等. 带符号知识的深度学习语义损失函数。发表于第 35 届 ICML 会议论文集，2018 年。

+   [36] X. Yuan, C. Ou, Y. Wang, C. Yang, 和 W. Gui. 一种新型半监督预训练策略用于深度网络及其在工业过程质量变量预测中的应用。《化学工程科学》，第 115509 页，2020 年。

+   [37] S. Zhang, H. Tong, J. Xu, 和 R. Maciejewski. 图卷积网络：全面综述。《计算社会网络》，6(1):11，2019 年。
