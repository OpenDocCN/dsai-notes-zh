<!--yml

分类：未分类

日期：2024-09-06 20:07:56

-->

# [1803.07608] 移动机器人应用的深度学习技术综述

> 来源：[`ar5iv.labs.arxiv.org/html/1803.07608`](https://ar5iv.labs.arxiv.org/html/1803.07608)

# 深度学习技术综述

移动机器人应用

Jahanzaib Shabbir 和 Tarique Anwer

###### 摘要

近年来，深度学习的进展引起了对深度人工神经网络在机器人系统中应用的研究。基于此，以下研究综述将讨论深度学习在与物理机器人系统的比较中的应用、收益和障碍，同时使用现代研究作为例子。研究综述将总结当前的研究，特别关注相较于机器人技术的收益和障碍。接下来将介绍如何将显著的深度学习结构应用于机器人领域，并提供相关例子。下一部分将展示机器人研究人员在深度学习神经网络方面希望使用的实际考虑因素。最后，研究综述将展示缺陷及其解决方案，并讨论未来趋势。此研究旨在展示最近在更广泛机器人领域的进展如何激发进一步在机器人中应用深度学习的研究。

###### 索引词：

深度学习，机器人视觉，导航，自动驾驶，深度强化学习，机器人感知算法，半监督和自监督学习，深度学习架构，多模态，决策制定与控制。

## 1 引言

### 1.1 在机器人系统背景下定义深度学习

深度学习被定义为一个科学领域，它涉及使用复杂函数（例如，非线性动态）训练广泛的人工神经网络，将数据从原始、高维、多模态状态转变为机器人系统能够理解的形式[1]。然而，深度学习存在一些缺陷，这些缺陷影响物理机器人系统，其中训练数据的生成总体上是昂贵的，因此在训练过程中表现不佳在某些应用中构成风险。尽管存在这些困难，机器人研究人员仍在寻找创造性的解决方案，例如，通过数字处理、自动化训练和使用多个深度神经网络来提升性能并缩短训练时间[2]。使用机器学习来控制机器人需要人类愿意放弃一定程度的控制。尽管这在开始时似乎违反直觉，但这样做的收益是让系统开始自主学习[3]。这使得系统具备适应能力，其最终提升方向的潜力源自于人类控制。这使得深度神经网络非常适合与机器人一起使用，因为它们灵活，并且可以在其他机器学习模型无法支持的框架中使用[4]。长期以来，优化神经网络的最著名方法被称为随机梯度下降。然而，改进的技术，例如最近的 RMSProp 和 Adam，已经得到了广泛使用。每种深度学习模型都是通过堆叠多个回归模型层来构建的[5]。在这些模型中，针对多种目标的不同类型的层已经经历了演变。

### 1.2 应用于移动机器人系统的深度学习形式

一种特别值得提及的层是卷积层。与传统的完全连接层不同，卷积层在所有输入空间中应用相同的权重。这大大减少了神经网络中的总体权重数量，这在通常由数十万甚至数百万像素组成的图像处理时尤其重要[6]。值得注意的是，处理这些具有完全连接层的图像将需要超过 100K2 到 1M2 的权重来连接每一层，这使得它完全不切实际。卷积层的灵感来源于视觉皮层中的皮质神经元，这些神经元只对特定环境中的刺激做出反应。由于卷积层可以估计这种行为，因此可以预期卷积层在图像处理任务中表现出色[7]。在使用卷积层的神经网络的开创性研究中，我们在 2012 年左右的 ImageNet 图像识别竞赛的进展上进行了构建。在这一时期获得的经验引起了广泛的关注，卷积层能够实现超人级别的图像识别[8]。目前，卷积神经网络已广为人知，并在许多基于图像的应用中表现出高度的有效性。这些应用包括语义图像分割、使用超分辨率对图像进行缩放、场景识别、图像中的目标定位、人类手势识别和面部识别[9] [10]。图像并不是唯一能够体现卷积神经网络卓越性能的信号形式。它们在任何形式的信号中也表现出有效性，例如语音识别以及语音和音频合成[11]。自然，这些技术也开始在信号处理领域占据主导地位，并在机器人技术中得到广泛应用，例如利用 LIDAR、微多普勒签名以及深度图估计行人检测[12] [13]。最近的项目甚至开始整合来自多种模态的信号，并将其结合以进行统一的识别和感知[14]。最终，深度学习社区的基本理念是复杂系统的每个组件都可以被教会“学习”。因此，深度学习的真正力量并不来自于在机器人系统中应用前面描述的某一种结构，而是将所有这些结构的组件连接起来形成一个完整的系统，从而实现全面学习[15]。这是深度学习开始发挥其影响力的地方，使得系统的每个组件都能够作为一个整体进行学习，并能够适应复杂的方法。例如，神经科学家们甚至开始认识到深度学习社区及人工智能中的许多模式开始镜像人脑中已演化的模式[16]。在学习复杂、高维和新颖动态的过程中，这些复杂动态的导数分析需要人类的专业知识。然而，这一过程通常消耗大量时间，并可能在维度和可处理性之间带来权衡[17]。因此，使这些模型对不可预见的影响具有鲁棒性是具有挑战性的，并且在大多数情况下，完整的状态信息通常是未知的。在这种情况下，需要能够快速、自主适应现代动态的系统来解决问题，例如在具有未知或不确定属性的服务上移动、在新环境中管理互动或适应或降级机器人子系统[18]。因此，我们需要能够实现数百或数千个自由度并表现出高度不确定性的技术，这些不确定性仅在部分信息状态下才能得到解决。另一方面，学习动态环境中的控制策略和动态控制系统的过程能够容纳高度自由度，用于诸如群体机器人、类人手、机器人视觉、自动驾驶和机器人手臂操作等应用[19]。然而，尽管多年来在积极研究中取得了进展，但针对任务的稳健和全面解决方案，例如在变形表面上移动或使用工具和执行器系统在复杂几何体中导航，仍然难以捉摸，尤其是在新颖场景中。这一缺陷包括先进运动中固有的运动学和路径规划任务[20]。另一方面，在高级物体识别方面，深度神经网络已被证明在物体识别和分类方面越来越具有适应性。高级应用的例子包括对变形物体的识别及其状态和姿态的估计、语义任务和路径规范，例如在桌子周围移动[20]。此外，还包括识别物体和表面的属性，例如在某些环境下，如粗糙地形，尖锐物体可能对人类协作者构成危险。面对这些困难，深度学习模型可以用于从样本输入输出对中近似函数。这些可以是最通用的深度学习结构，因为在机器人学中有多个不同的函数，研究人员可以利用样本观察进行近似[21]。这些观察的一些例子包括从动作到阶段变化的映射，将这些状态变化映射到可以引起这些变化的动作，或从力到运动的映射。虽然在某些情况下，这些函数的具体物理方程可能已经定义，但在环境高度复杂的情况下，这些方程生成的精度可能不够理想[22]。然而，在这种情况下，从样本观察中学习函数近似可以获得显著更好的精度。换句话说，近似函数不需要是连续的。然而，函数近似模型在分类任务中也表现出色，例如，确定机器人面前的障碍物类型、为当前环境制定的整体路径规划策略或某些复杂对象的状态[23]。此外，使用整流器的函数近似深度学习架构可以建模自主移动机器人高度耦合的动态，以解决解析导数和具有挑战性的系统识别问题。深度神经网络在检测和感知方面已经超越了其他模型，因为它们能够直接处理高维输入，而无需基于人类设计的特征向量[24]。这降低了对人类的依赖，使得额外的训练时间可以通过降低初始工程努力来部分抵消[25]。从视频或静态图像中提取意义是深度学习取得显著进展的另一个应用领域。这个过程要求使用四个独立因素同时解决对象检测和单个深度神经网络。这些因素包括特征提取、运动处理、分类、关节处理和遮挡处理[26]。统一系统通过仅使用视觉预测动态场景的物理结果，从而限制了通常分开的系统之间的次优交互。这是基于人类的动作，能够从视觉信息预测动态场景的结果，例如，一块石头落下并撞击另一块石头[27]。因此，深度学习已被确定为在机器人传感器应用中管理多模态数据生成的有效工具。这些应用包括集成视觉和触觉传感器数据、结合深度数据和来自 RGB-D 相机的数据。由于大量的元参数，深度神经网络在非专家有效使用上形成了相当的挑战[28]。然而，这些参数也提供了显著的灵活性，这是其成功的一个关键因素。因此，训练深度神经网络需要用户能够至少对许多概念有基本了解。具体而言，应用这些技术将有助于解决高级物体识别挑战，并减少整体变化的程度[29]。

## 2 深度学习用于机器人感知

### 2.1 当前机器人感知趋势

尽管当前趋势更倾向于深度和大型模型，但一个仅有单个隐藏层和基本 S 型激活函数的简化神经网络将会训练更快，并提供一个基准，用于赋予任何更深模型改进的含义。当我们使用更深的模型时，Leaky Rectifiers 能够通过降低梯度消失挑战的影响，从而通常促进更快的训练，并通过使用简化的单调导数来提高准确性 [30]。此外，由于具有额外权重的模型具有增强拟合训练数据的灵活性，正则化是训练最佳模型的关键技术。此外，弹性网络是促进对抗权重饱和和促进权重稀疏性的多种成熟正则化方法的组合 [31]。然而，包括 drop-out 和 drop-connect 在内的新正则化方法已经取得了更好的经验性结果。此外，许多正则化方法也专门用于改善自编码器的鲁棒性。在这种情况下，专用层也可以在深度神经网络中产生显著区别 [32]。在卷积和最大池化层之间交替是一种常见方法。这些池化层可以降低网络中的权重总数，并且使模型能够独立于它们在视觉场景中的放置位置识别对象 [33]。另一方面，批归一化可以通过确保梯度范围对所有神经元的权重产生影响，显著改善收敛评级。此外，残差层可以允许训练更深和因此更灵活的模型 [34]。为了有效利用深度学习模型，至关重要的是训练一个或多个通用图形处理单元，因为其他深度神经网络并行化方法已经尝试过，但尚未提供通用图形处理单元在性能上的收益。长期以来直到近年来，机器人一直被用于工业环境。在工业环境中，机器人系统预先编程了重复的任务，缺乏自主性的能力，因此基于结构化方法操作。这样的环境无法适应移动机器人，因为它消除了自主性的需求。另一方面，移动机器人需要较少结构化的环境，以便能够做出自己的决策，例如导航路径，确定物体是否为障碍物，识别图像和音频以及映射其环境。因此，与工业设置相比，生存和适应现实世界对任何机器人系统来说更为复杂，因为失败风险、系统错误、外部因素、障碍物、数据损坏、人为错误和不可识别的环境更为普遍 [15]。

### 2.2 机器学习在训练机器人系统感知中的应用

深度学习与机器学习之间的区别在于，深度学习强调机器学习资源和方法的子集，并使用它们来解决需要“思考”的任何困难，无论是人类还是人工的。深度学习也被引入为利用多个抽象层次理解数据的手段。在训练过程中，深度神经网络能够学习发现有用模式以数字化表示数据，如声音和图像。这正是为什么我们从深度学习中观察到更多的在图像识别和自然语言处理领域的进展 [36]。正是在这个背景下，深度学习在帮助研究人员开发感知能力突破性方法方面占据了前沿位置 [16]。更简化的说法是，感知指的是机器人能够检测其周围环境的功能。因此，它在很大程度上依赖于多源感官信息。然而，传统的机器人技术通过使用简陋构造的传感器从原始传感器中提取数据，这些老方法受到适应通用设置的约束 [17]。在这些机器人系统面对动态环境的情况下，它们通过结合混合和自主功能以无结构方式操作来处理其周围环境的信息 [18]。因此，随着深度学习的引入，从机器人系统感知环境中处理数据的新方法被称为感知特征。这些方法包括机器人运动、感知、人机交互、操作和抓取、自动化、自我监督、自我训练和学习以及机器人视觉 [19]。深度学习模型利用自动化动作技术只需使用监督学习即可实现他们的目标 [20]。例如，为了完善图像识别应用程序，神经网络将需要用标记数据集进行训练。另一方面，无监督学习是深度学习的操作方式，允许通过解决问题发现新的模式和见解，没有对机器人应该如何感知结果的洞察 [21]。移动机器人能够使用感知技术检测其环境的方法是通过使用明确的决策制定政策 [20]。例如，使用深度学习的移动机器人能够通过使用驱动机器学习算法的运动和跟踪精度传感器来理性导航。然而，在拥挤的房间等困难环境中，准确感知其环境的能力受到限制。因此，基于深度学习的解决方案可以通过使用人工智能、高计算硬件和深度卷积神经网络的处理层来成功解决这一难题，成功解析复杂环境感知困难 [22]。机器人系统环境中存在的各种障碍表明机器人系统需要具备的巨大高维数据处理能力来感知其环境 [23]。通过使用自我监督、半监督和全监督训练以及学习，机器人系统能够利用其机器学习和模式识别能力实时处理原始数据，如图像、对象和语义、音频以及处理自然语言。这一深度学习领域最好使用前馈人工神经网络成功分析视觉图像。它还使用基于低预处理设计的多个多层感知器 [22]。与其他图像分类算法相比，它使用最少的预处理，这意味着网络能够使用自动化过程学习过滤器，而不像传统算法那样需要手动设计。因此，不依赖于过去的知识和人类在特征设计上的努力使其具有重大优势 [24]。因此，总的来说，这使得深度学习能够直接从原始传感器数据中提取多层次属性，无需人类辅助机器人控制 [24]。这使得深度学习编程库，如 Python 的 TensorflowTheano、C++的 Caffe、R 的 darch、CNTK、Javascript 的 Convent.js 以及源自 C++和 Java 的 Deeplearning4j 等在提供机器人系统开发其感知数据分析和环境学习方面极为有用 [25]。机器人系统感知是移动机器人辅助功能中的关键部分，对与机器人环境进行交互至关重要。感知和智能感知是一些关键应用，因为它们决定了机器人系统的性能。这些性能在很大程度上取决于机器人传感器的表现。现代传感器及其功能可以提供令人印象深刻的机器人感知，这是自适应和机器人人工智能的基础 [26]。从感官输入到控制输出的过程利用感觉-运动控制结构在机器人感知中面临巨大困难 [27]。一些重要的移动机器人组件包括由多个关节和连接组成的操作器，一个运动装置，传感器，控制器和一个端效应器 [37]。移动机器人是能够移动的自动化系统。它们还能够在其周围环境中移动，并且不限于单个物理位置。有了这些特征，移动机器人能够使用感觉数据和自主控制命令感知其环境 [28]。

### 2.3 深度学习在机器人感知中的不足之处

然而，这些机器人系统中某些挑战仍未解决，尤其是在感知和智能控制方面。其中一些挑战体现在需要大量数据以逐步训练和教导算法。需要大规模的数据集来确保机器能够产生期望的结果。就像人脑需要丰富的经验来学习和推导信息一样，人工神经网络也需要大量的数据。这意味着，为了实现更强大的抽象，所需的参数更多，因此数据也更多。另一个挑战是神经网络的过拟合倾向，在某些情况下，训练集中的错误与新未训练数据集中的错误之间存在明显的区别。当许多模型使得参数的相对数量无法可靠地执行时，这个问题就会出现。因此，模型仅仅记住训练示例，而无法学会对新情况和新数据集进行泛化。

### 2.4 如何利用移动机器人感知模型实现全面的情境意识

这些能力将在研究调查中通过深度学习感知模型算法进行调查，这些算法能够确定机器人如何应对环境中的动态变化[29]。这些模型的基础围绕着控制理论相关的范式，例如系统稳定性、控制以及观察[30]。该理论指出，机器人系统能够通过利用学习的层次扩展或增强来感知其环境，最大化其传感器能力的范围，同时使用路径规划算法来绕过障碍物或路径[31]。大多数实时地图算法关注于在室内环境中获取紧凑的 3D 映射，利用距离和成像感测能力[32]。开发机器人环境模型的过程是一个重要的问题，特别是在管理其工作空间时，尤其是当它与其他机械设备共享时[33]。移动机器人通过使用控制系统与环境互动，将结构或障碍物定义为几何区域，以便覆盖机器人上所有可能的配置。对象或结构根据平行六面体、球体、平面和圆柱体来定义。通过这样的简化模型，移动机器人系统能够定义许多这种性质的几何区域，以覆盖其周围几乎所有的物体，例如移动物体、固定物体如家具和机械。因此，我们提出基本几何体积作为建模移动机器人环境感知能力的一种手段[34]。这种方法将允许机器人在环境中移动时有一定的确定性，以避免与已定义、声明和激活的禁区碰撞，从而正确工作[35]。

几何感知算法将检查机器人末端执行器是否在受控区域或警告区内。这项检查是通过使用用户已经定义的几何区域来完成的[38]。类似地，在这种情况下，动态物体的位置为感知系统提供了将几何区域与任意移动点连接的可能性[39]。这些点可以从外部传感器如编码器读取。速度控制是通过几何区域块来实现的，这些块能够检测形状类型并选择正确的运动规律，以修改机器人覆盖并避免与用户定义的区域发生碰撞[40]。当机器人末端执行器与球形区域发生碰撞时，速度覆盖会平滑地转变，符合感知法则(1) [3]。

|  | <math   alttext="\begin{split}V=v_{0}.\frac{d-r}{\delta},r\leq d\leq r+\delta,\\ V=v_{0},d>r+\delta,and\\

`V=v_{0}.\frac{d-r}{\delta},r\leq d\leq r+\delta,` 和 `V=v_{0},d>r+\delta,and` 和 `V=0,d<r`

在这种情况下，$v$ 表示为机器人末端执行器的实际速度覆盖值，$v_{0}$ 为旧的覆盖值，$d$ 表示机器人末端执行器与主要球形区域之间的距离，警告区域的厚度表示为 $\delta$，而 $r$ 是球体半径 [41]。当机器人遇到圆柱形区域时，速度覆盖值将受到在 (2) [3] 的感知法则的影响。

|  | <math   alttext="\begin{split}V=v_{0}.\frac{d_{1}-r}{R-r},0\leq z\leq h,\\ V=v_{0}.\frac{d_{2}}{\delta},h\leq z\leq h+\delta,-\delta\leq z<0,p\in cyl,and\\

V=`v_{0}`.\frac{d_{3}}{\delta}, h\leq z\leq h+\delta, -\delta\leq z<0, p\in cyl\end{split}" display="block"><semantics ><mtable displaystyle="true" rowspacing="0pt" ><mtr ><mtd columnalign="right" ><mrow ><mrow ><mrow ><mi >V</mi><mo >=</mo><msub ><mi >v</mi><mn >0</mn></msub></mrow><mo lspace="0em" rspace="0.167em" >.</mo><mrow ><mrow ><mfrac  ><mrow ><msub ><mi  >d</mi><mn >1</mn></msub><mo >−</mo><mi >r</mi></mrow><mrow ><mi  >R</mi><mo >−</mo><mi >r</mi></mrow></mfrac><mo >,</mo><mn  >0</mn></mrow><mo >≤</mo><mi >z</mi><mo >≤</mo><mi >h</mi></mrow></mrow><mo >,</mo></mrow></mtd></mtr><mtr ><mtd columnalign="right" ><mrow ><mrow ><mi  >V</mi><mo >=</mo><msub ><mi >v</mi><mn >0</mn></msub></mrow><mo lspace="0em" rspace="0.167em" >.</mo><mrow ><mrow ><mfrac id="S2.E2.m1.

上述感知法则将 $h$ 表示为圆柱体的高度，机器人的末端执行器位置记作 $p$，圆柱体中心与机器人位置之间的距离记作 $d_{1}$，而 $d_{2}$ 表示圆柱体顶部或底部基座与机器人位置之间的距离 [42]。

此外，机器人位置与圆柱体顶部/底部周长点之间的最小距离记作 $d_{3}$。此外，当机器人末端执行器位于警告区域之外时，机器人的速度超控与过去的速度超控相一致 [43]。

## 3 深度学习在机器人控制和探索中的应用

### 3.1 自主机器人系统如何使用深度学习来控制和探索其环境

实现自主机器人探索的好处为机器人研究人员提供了许多具有重大社区和财务影响的应用[44]。机器人研究依赖于对环境的完美知识和控制[45]。与非结构化环境相关的问题是由于高维状态空间以及将传感器感知映射到特定状态的固有可能性所产生的。需要注意的是，状态空间的高维度是最基本的困难，因为机器人离开高度控制的实验室环境，进入非结构化的周围环境。例如，使用深度学习的自主无人机对地形进行分类，并通过生成控制命令来解决任何探索上的不足，以便对某种折衷进行适应[46]。因此，这种方法的主要假设是移动机器人在非结构化环境中成功，以便它们可以仔细选择任务特定属性，并识别相关的实时结构，以降低其状态空间，而不影响其探索目标的性能[47]。机器人通过探索其周围环境来执行任务。因此，鉴于我们对自主移动探索的关注，我们将主要注意力集中在服务于运动的探索上，即无碰撞运动以进行末端执行器定位[48]。产生这种运动的挑战是运动规划中面临的一个例子。由于维度配置空间的增加，具有许多自由度的机器人系统的运动规划在高度结构化的环境中甚至也具有计算挑战[49]。此外，非结构化环境相较于传统运动规划过程，还会增加运动生成的难度。此外，在非结构化环境中，机器人只能对其环境拥有有限的知识，通过操作分配来使用末端执行器可以将对象从未知状态转变为已知状态[50]。然而，这种能力可能受到受限轨迹的挑战，以至于移动机器人无法轻松到达特定位置[51]。这些问题使得运动生成的挑战变得更加复杂。管理动态环境所需的规划和传感的明确协调增加了状态空间的维度。此外，机器人任务要求以高频反馈的形式施加严格的条件[52]。因此，现有的运动规划者往往对非结构化环境做出高度限制性的假设，因为这些假设在获得操作员与机器人反馈方面非常难以满足[53]。这些假设以及计算难度，都是运动规划基础的结果，其高维配置空间使得解决空间问题变得非常不适合。规划者可以通过仅使用工作空间信息来避免碰撞来解决这一范式。然而，几乎所有现实世界的环境都包含了相当程度的结构[54]。例如，建筑物被划分为走廊、门和房间；户外环境包括路径、街道和交叉路口，而例如桌子、架子和椅子等物体有更有利的接近方向。然而，当机器人探索规划者仅基于配置空间操作时，这些信息却被忽视了[55]。因此，大多数机器人探索规划者的结果是基于假设任何环境在规划过程中是完全定义并保持静态的[56]。

## 4 深度学习在机器人导航和自动驾驶中的应用

使用深度学习来实现自主驾驶任务并不像大多数人认为的那样是一个完全受控和建模的任务。相反，它需要最优的感知能力[57]。机器人感知环境和解读其获取的信息的过程使其能够理解周围环境的状况，制定改变状态的计划，并观察其行为对环境的影响。在非结构化环境中，物体识别已被证明极具挑战性。例如，区分铺砌和非铺砌的道路以及识别物体[58]。深度学习利用机器学习运动捕捉能力以及最优的感知功能。这是机器人若干关键应用的前提，例如灵活制造、行星探索、与人类专家的合作以及老人护理[59]。在环境中驾驶的挑战包括机器人在导航不同障碍物时的移动问题，比如推和拉。即使在结构化环境中，由于相关状态空间的复杂性，自动驾驶仍然困难[60]。这个状态空间包括场景中物体的外观、尺寸、位置以及重量。它还包括其他若干相关属性，这些属性提供了拉、推或抓取的位置以及施加力量的程度的指示[61]。深度学习及其相关的机器学习集体行动提高了机器人决策的性能，通过将选择可能行动和确定其控制器所需参数的能力嵌入这些系统中。

### 4.1 自主机器人系统如何利用深度学习来导航其环境

在非结构化环境中，自主驾驶面临许多在结构化环境中不存在的挑战。在非结构化环境中，驾驶所需的物体属性无法事先定义。有关物体的信息必须通过传感器获得，尽管这些传感器通常是模糊的，因此引入了不确定性，并提供冗余的信息。此外，在非结构化和动态环境中的自主驾驶通常需要及时响应迅速变化的环境[62]。通过利用人类环境中固有的结构，可以简化自主驾驶的问题。现实世界中的大多数物体都是基于执行某些功能的设计，目的是被人类使用[44]。因此，一些现实世界的物体可以共享指向其预期用途的共同属性。通过强调这些与任务相关的物体属性，可以降低自主驾驶的复杂性。例如，视觉数据可以被分析以识别几个点，这些点对应于机器人可以操控的积极位置。此外，由于许多物体的运动特征相似，机器人可以被训练以识别这些物体。因此，需要探索的状态空间显著减少[63]。在这种情况下，研究人员通常会做出假设，以降低在非结构化环境中自主驾驶的复杂性。例如，通常假设环境中物体的完整模型可以事先获得，或者可以通过传感器获得，同时环境在交互过程中保持不变[64]。然而，实际情况是，在现实世界中，无法提供具有完整先验模型的自主驾驶。然而，完美的模型并不是成功自主驾驶的前提条件[65]。机器人移动驾驶可以利用世界上现有的结构，并且在大多数情况下，这些结构容易被感知。因此，通过利用这些结构，可以显著降低在非结构化环境中的自主驾驶复杂性。同样，理解环境中物体的内在自由度也能够降低在非结构化环境中的自主驾驶复杂性[45]。

## 5 半监督和自监督学习在机器人中的应用

基于模仿的学习是一种有前景的方法，用于解决困难的机器人任务，例如自主导航。然而，它需要人工监督来监管训练过程，并在没有反馈的情况下向机器人发送正确的控制指令。正是这种过程形式容易导致失败和高成本[66]。因此，为了减少人工干预并限制模仿学习中自主机器人导航的手动数据标注，可以引入半监督学习和自监督学习技术。然而，需要注意的是，这些技术需要按照多感知设计方法来操作。解决方案应包括基于传感器融合和自动标注机器人可能遇到的状态的次优传感器策略[67]。这也是为了在学习过程中消除人工监督[68] [69]。此外，需要制定记录策略，以缓解从次优传感器策略中学习过多数据的对抗性影响。因此，该解决方案将使机器人具备在大多数任务中达到接近人类表现的能力[70]。在面对意外结果，例如硬件故障或操作员错误的情况下，它也能够超越人类表现。此外，半监督方法可以作为解决拥挤环境（例如房间）中轨迹分类问题的解决方案。这个问题涉及到物体分类、分割和跟踪，而不使用类模型[71]。因此，我们引入半监督学习作为一种能够通过迭代训练分类器并从未标记数据中提取重要训练样本的技术。这是通过利用跟踪数据来实现的。此外，该过程还涉及评估来自拥挤的人工自然环境（例如街道）的数据所呈现的大规模多类难题[72]。因此，当提供手动标记的单个对象类别训练轨迹时，半监督学习的性能相较于自监督学习能够使用数千个训练轨迹[73]。此外，当提供增强的未标记数据时，半监督学习显示出超越自监督学习方法的能力。在这种情况下，半监督学习呈现为加速增量更新助推分类器的最简化算法方法，通过将学习时间因素降低三倍[74]。

## 6 种用于机器人视觉与控制的多模态深度学习方法

在不完美的受控和建模环境中执行任务意味着机器人需要具备最佳的多模态能力。感知环境并解释获得的信息的过程使得机器人能够感知环境状态，制定改变状态的方法，并观察其行动对环境的影响。

### 6.1 自主机器人系统如何使用半监督和自监督学习来学习其环境

机器人的环境可以在多个层次上进行控制。原则上，约束较少的环境更难以感知。在现实世界及其如植被景观和地形这样的非结构化和动态环境中，移动机器人需要能够利用传感器模态在未知环境中导航。更重要的是，即使不考虑不确定性，传感器本身也是模糊的[75]。例如，从某个角度来看，柠檬和足球可能看起来很相似。此外，如果橱柜关闭，杯子可能会变得不可见，而在遥控器和手机都朝下的情况下，很难区分它们。这些因素都增加了感知环境状态的挑战。此外，例如，人脸识别的进展通常在假设图像中个体的位置和方向的基础上进行。对象分割的结果通常基于通过颜色差异区分物体和背景的能力[76]。另外，对象识别通常被简化为对有限集合中的给定对象的相似性进行计算。另一方面，在非结构化环境中，位置和方向是不可控的，因为对颜色和阴影的假设难以证明。此外，机器人可能遇到的范围和可能对象是不可处理的[77]。

### 6.2 自主机器人系统如何使用多模态和深度学习方法来感知其环境

因此，为了应对不结构化环境中的感知，机器人需要能够降低需要分析的状态空间。通过限制不确定性并因此降低状态空间的维度来提供某些感知任务的便利。例如，为了计算环境中物体的距离，机器人需要将深度与视觉信息相关联[78]。这通常通过使用立体视觉系统并解决两个静态 2D 图像之间的对应问题来完成。然而，在解决对应问题时，由于噪声、许多可能的匹配以及相机标定的不确定性，问题变得复杂[79]。另一方面，在一个能够在一张图像中捕获至少三个视角的系统中，这通过将多传感器系统减少为单传感器来降低状态空间。此外，在不结构化环境中，物体识别被证明是非常具有挑战性的[57]。这是由于大量的传感器数据以及同一类别物体之间的变化增加。在这种情况下，物体识别是一个增加维度的挑战。然而，即使面对这些挑战，同一类别的物体确实具有相似的属性。因此，通过应用这一见解，机器人能够将重点放在仅由最相关特征组成的状态空间的最小子集上，以进行分类[58]。

## 7 深度模型在视觉和机器人问题中的应用

之前对机器人领域机器学习应用的概述将突出五个主要领域，这些领域在当前的机器人技术中和长期使用的发展阶段中产生了显著影响。然而，这并不是全面的总结，旨在为读者提供对机器人领域现有机器学习应用形式的预览，并激发对这些领域及其他领域进一步研究的兴趣[80]。大

计算机视觉的跨学科领域关注于如何开发计算机以提高对视频数字图像的感知。计算机视觉任务包括获取、处理、分析数字图像以及从实际世界中提取高维信息，以便生成数字或符号数据，例如决策的格式[85]。涉及自主规划或深思熟虑的机器人系统导航的人工智能领域，需要对这些设置有透彻的理解，因为计算机视觉系统作为视觉传感器可以提供环境信息[57]。因此，人工智能和计算机视觉共享其他领域，例如模式识别和学习方法。因此，在某些情况下，计算机视觉被视为人工智能的一部分。计算机视觉的另一个应用是固态物理，因为许多计算机视觉系统依赖于图像传感器，这些传感器检测电磁辐射，通常以可见光或红外光的形式出现[81] [86]。这些传感器根据量子物理设计操作，光与表面的相互作用过程更好地通过光学行为解释。这些复杂的内部工作机制表明，即使是复杂的图像传感器也需要量子力学来全面理解图像形成过程。此外，计算机视觉的另一个应用是物理中的多重测量挑战，例如流体运动[39]。

## 8 深度学习在移动机器人中的优缺点

### 8.1 深度学习在移动机器人中的好处

深度学习作为更广泛的机器学习技术家族的一部分，其优势在于基于对学习数据的表征，而不是通过监督、无监督和半监督学习的任务特定算法，这允许对信息处理和通信模式的结构化解读，可以视为定义多个刺激与相关神经反应之间关系的尝试[87]。例如，深度神经网络、深度信念网络以及递归神经网络等深度学习架构已经在计算机视觉、自然语言处理、社交网络过滤、语音识别、生物信息学和音频识别等领域得到了应用。在这些领域中，深度学习架构的成果与某些情况下甚至超越了人类专业知识。此外，深度学习算法利用多层非线性处理单元进行特征提取和变换，特定层将前一层的输出作为输入[88]。

深度强化学习提出了一个简化的概念框架，利用异步梯度下降来优化深度神经网络控制器。标准强化学习算法中的异步变体显示，平行的演员学习者对训练具有稳定影响，从而允许成功训练神经网络控制器[19]。在这一前提下，异步变体被提出作为最具吸引力的深度强化学习方法。

### 8.2 移动机器人中深度学习的缺点

深度学习在应用机器人学中的缺点是，使用回放记忆存储代理数据不允许从不同时间阶段随机重批次或采样。因此，这种方法中的记忆聚合降低了非平稳和侵蚀更新，同时限制了技术仅用于脱离策略强化学习算法[23]。

## 9 结论

深度学习有望改变人工智能领域，并代表了朝着开发具有更广泛视觉感知能力的自主系统迈进的一步。目前，深度学习使得处理传统上难以解决的挑战成为可能，例如通过像素直接玩视频游戏。此外，深度学习算法还被应用于机器人技术中，以增强机器人从实际世界中的摄像头输入间接学习控制功能的能力。正是在这种基础上，上述调查展示了强化学习在价值驱动和政策驱动方法主要流派中的主要进展和方法，并涵盖了深度学习中的核心算法，例如深度网络、异步优势演员-评论员以及信任区域策略优化。此外，研究调查还突出了深度神经网络在通过深度学习进行视觉感知方面的收益。人工智能学科的核心目标之一是生产完全自主的智能体，使其能够与环境互动，以学习最佳行为，并通过试错法随着时间的推移展示改进。因此，创建响应性强且具有学习能力的人工智能系统长期以来一直是一个难以攻克的挑战。然而，在深度学习的原则性数学框架中找到希望，该框架利用经验驱动的自主学习来应用功能逼近，从而表示深度神经网络的学习属性，以克服这些挑战。

## 参考文献

+   [1] Y. LeCun, Y. Bengio, 和 G. Hinton, “深度学习，” *自然*，第 521 卷，第 7553 期，第 436 页，2015 年。

+   [2] T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa, D. Silver, 和 D. Wierstra, “使用深度强化学习进行连续控制，” *arXiv 预印本 arXiv:1509.02971*，2015 年。

+   [3] J. S. Esteves, A. Carvalho, 和 C. Couto, “用于移动机器人绝对自我定位的广义几何三角测量算法，” 发表在 *工业电子学，2003 年 ISIE’03 第 2003 年 IEEE 国际研讨会*，第 1 卷。IEEE，2003 年，第 346–351 页。

+   [4] A. Vedaldi 和 K. Lenc, “Matconvnet：用于 Matlab 的卷积神经网络，” 发表在 *第 23 届 ACM 国际多媒体会议论文集*。ACM，2015 年，第 689–692 页。

+   [5] A. Eitel, J. T. Springenberg, L. Spinello, M. Riedmiller, 和 W. Burgard, “多模态深度学习用于鲁棒的 RGB-D 物体识别，” 发表在 *智能机器人与系统（IROS），2015 年 IEEE/RSJ 国际会议上*。IEEE，2015 年，第 681–687 页。

+   [6] Y. Yang 和 Y. Li, “机器人通过观看来自互联网的无约束视频来学习操作计划。” 2015 年。

+   [7] D. C. Cireşan, U. Meier, L. M. Gambardella, 和 J. Schmidhuber， “用于手写数字识别的深度、大规模、简单神经网络，” *神经计算*，第 22 卷，第 12 期，第 3207–3220 页，2010 年。

+   [8] J. Lu, V. Behbood, P. Hao, H. Zuo, S. Xue, 和 G. Zhang， “使用计算智能的迁移学习：综述，” *基于知识的系统*，第 80 卷，第 14–23 页，2015 年。

+   [9] M. Turan, J. Shabbir, H. Araujo, E. Konukoglu, 和 M. Sitti， “基于深度学习的 RGB 相机信息与磁性定位信息融合，用于内窥镜胶囊机器人，” *国际智能机器人与应用杂志*，第 1 卷，第 4 期，第 442–450 页，2017 年。

+   [10] M. I. Jordan 和 T. M. Mitchell， “机器学习：趋势、观点与前景，” *科学*，第 349 卷，第 6245 期，第 255–260 页，2015 年。

+   [11] M. Turan, Y. Almalioglu, H. Araujo, E. Konukoglu, 和 M. Sitti， “深度 Endovo：一种基于递归卷积神经网络（RCNN）的视觉里程计方法，用于内窥镜胶囊机器人，” *神经计算*，第 275 卷，第 1861–1870 页，2018 年。

+   [12] N. Sünderhauf, S. Shirazi, A. Jacobson, F. Dayoub, E. Pepperell, B. Upcroft, 和 M. Milford， “使用卷积网络地标进行地点识别：视角鲁棒、条件鲁棒、无需训练，” *机器人学：科学与系统 XII 会议录*，2015 年。

+   [13] M. Turan, Y. Y. Pilavci, R. Jamiruddin, H. Araujo, E. Konukoglu, 和 M. Sitti， “一种完全密集且全球一致的 3D 地图重建方法，用于胃肠道，以增强内窥镜胶囊机器人治疗的相关性，” *arXiv 预印本 arXiv:1705.06524*，2017 年。

+   [14] M. Turan, Y. Y. Pilavci, I. Ganiyusufoglu, H. Araujo, E. Konukoglu, 和 M. Sitti， “基于稀疏到密集对齐的 3D 地图重建方法，用于内窥镜胶囊机器人，” *机器视觉与应用*，第 29 卷，第 2 期，第 345–359 页，2018 年。

+   [15] B. M. Lake, R. Salakhutdinov, 和 J. B. Tenenbaum， “通过概率程序归纳进行人类水平的概念学习，” *科学*，第 350 卷，第 6266 期，第 1332–1338 页，2015 年。

+   [16] S. Marsland， “机器学习，算法视角，Chapman & Hall/CRC 机器学习与模式识别，” *CRC，佛罗里达州博卡拉顿*，2009 年。

+   [17] I. Lenz, H. Lee, 和 A. Saxena， “用于检测机器人抓取的深度学习，” *国际机器人研究杂志*，第 34 卷，第 4-5 期，第 705–724 页，2015 年。

+   [18] Z. Ghahramani， “概率机器学习与人工智能，” *自然*，第 521 卷，第 7553 期，第 452 页，2015 年。

+   [19] Y. Duan, X. Chen, R. Houthooft, J. Schulman, 和 P. Abbeel， “用于连续控制的深度强化学习基准测试，” 在 *国际机器学习大会* 中，2016 年，第 1329–1338 页。

+   [20] S. Levine, P. Pastor, A. Krizhevsky, 和 D. Quillen， “利用大规模数据收集学习手眼协调以进行机器人抓取，” 在 *国际实验机器人学研讨会* 中。 Springer，2016 年，第 173–184 页。

+   [21] Y. Yang, C. Fermuller, Y. Li 和 Y. Aloimonos，“抓取类型重访：对视觉经典特征的现代视角”，载于 *IEEE 计算机视觉与模式识别会议论文集*，2015 年，第 400–408 页。

+   [22] C. Dong, C. C. Loy, K. He 和 X. Tang，“使用深度卷积网络的图像超分辨率”，*IEEE 模式分析与机器智能学报*，第 38 卷，第 2 期，第 295–307 页，2016 年。

+   [23] A. Gongal, S. Amatya, M. Karkee, Q. Zhang 和 K. Lewis，“用于果实检测和定位的传感器与系统：综述”，*农业中的计算机与电子*，第 116 卷，第 8–19 页，2015 年。

+   [24] A. M. Nguyen, J. Yosinski 和 J. Clune，“创新引擎：通过深度学习实现自动化创造力和改进的随机优化”，载于 *2015 年年度遗传与进化计算会议论文集*。 ACM，2015 年，第 959–966 页。

+   [25] Y. Du, W. Wang 和 L. Wang，“基于骨架的层次递归神经网络用于动作识别”，载于 *IEEE 计算机视觉与模式识别会议论文集*，2015 年，第 1110–1118 页。

+   [26] Y. Tang，“使用线性支持向量机的深度学习”，*arXiv 预印本 arXiv:1306.0239*，2013 年。

+   [27] N. Sünderhauf, S. Shirazi, F. Dayoub, B. Upcroft 和 M. Milford，“关于用于地点识别的卷积网络特征的性能”，载于 *智能机器人与系统（IROS），2015 年 IEEE/RSJ 国际会议*。 IEEE，2015 年，第 4297–4304 页。

+   [28] C. Chen, A. Seff, A. Kornhauser 和 J. Xiao，“Deepdriving：为自动驾驶中的直接感知学习可用性”，载于 *计算机视觉（ICCV），2015 年 IEEE 国际会议*。 IEEE，2015 年，第 2722–2730 页。

+   [29] J. Schmidhuber，“神经网络中的深度学习：概述”，*神经网络*，第 61 卷，第 85–117 页，2015 年。

+   [30] H. Brighton 和 H. Selina，*《人工智能简介：图解指南》*，系列：Introducing… Icon Books Limited，2015 年。[在线]. 可用： https://books.google.com.pk/books?id=4GxGCgAAQBAJ

+   [31] J. Bai, Y. Wu, J. Zhang 和 F. Chen，“基于子集的深度学习用于 RGB-D 对象识别”，*神经计算*，第 165 卷，第 280–292 页，2015 年。

+   [32] V. Veeriah, N. Zhuang 和 G.-J. Qi，“用于动作识别的差分递归神经网络”，载于 *计算机视觉（ICCV），2015 年 IEEE 国际会议*。 IEEE，2015 年，第 4041–4049 页。

+   [33] R. Xu, C. Xiong, W. Chen 和 J. J. Corso，“联合建模深度视频与组成文本以在统一框架中弥合视觉与语言”，2015 年。

+   [34] K. Narasimhan, T. Kulkarni 和 R. Barzilay，“利用深度强化学习进行文本游戏的语言理解”，*arXiv 预印本 arXiv:1506.08941*，2015 年。

+   [35] J. Wu, I. Yildirim, J. J. Lim, B. Freeman 和 J. Tenenbaum，“Galileo：通过将物理引擎与深度学习结合来感知物理对象属性”，载于 *神经信息处理系统进展*，2015 年，第 127–135 页。

+   [36] M. Turan, E. P. Ornek, N. Ibrahimli, C. Giracoglu, Y. Almalioglu, M. F. Yanik 和 M. Sitti，“用于内镜胶囊机器人的无监督里程计和深度学习，” *arXiv 预印本 arXiv:1803.01047*，2018 年。

+   [37] M. Turan, Y. Almalioglu, H. Araujo, T. Cemgil 和 M. Sitti，“内镜传感器融合：基于粒子滤波的多传感器数据融合及切换状态空间模型，用于使用递归神经网络运动学的内镜胶囊机器人，” *arXiv 预印本 arXiv:1709.03401*，2017 年。

+   [38] R. Lun 和 W. Zhao，“微软 Kinect 的应用和人体运动识别综述，” *国际模式识别与人工智能期刊*，第 29 卷，第 05 期，页码 1555008，2015 年。

+   [39] J. Kuen, K. M. Lim 和 C. P. Lee，“通过时间缓慢原则自学深度不变表征用于视觉跟踪，” *模式识别*，第 48 卷，第 10 期，页码 2964–2982，2015 年。

+   [40] Y. Hou, H. Zhang 和 S. Zhou，“基于卷积神经网络的图像表征用于视觉回环检测，”在 *信息与自动化，2015 IEEE 国际会议* 中。IEEE，2015 年，页码 2238–2245。

+   [41] Y. Qian, J. Dong, W. Wang 和 T. Tan，“通过卷积神经网络进行深度学习隐写分析，”在 *2015 媒体水印、安全与取证* 中，第 9409 卷。国际光学与光子学学会，2015 年，页码 94090J。

+   [42] E. Tzeng, J. Hoffman, T. Darrell 和 K. Saenko，“跨领域和任务的深度转移学习，”在 *计算机视觉（ICCV），2015 IEEE 国际会议* 中。IEEE，2015 年，页码 4068–4076。

+   [43] L. Pinto, D. Gandhi, Y. Han, Y.-L. Park 和 A. Gupta，“好奇的机器人：通过物理交互学习视觉表征，”在 *欧洲计算机视觉会议* 中。Springer，2016 年，页码 3–18。

+   [44] B. M. Lake, T. D. Ullman, J. B. Tenenbaum 和 S. J. Gershman，“构建像人类一样学习和思考的机器，” *行为与脑科学*，第 40 卷，2017 年。

+   [45] G. Chen, D. Clarke, M. Giuliani, A. Gaschler 和 A. Knoll，“结合无监督学习和区分以进行 3D 动作识别，” *信号处理*，第 110 卷，页码 67–81，2015 年。

+   [46] J. Wulff 和 M. J. Black，“使用学习基和层进行高效稀疏到密集光流估计，”在 *IEEE 计算机视觉与模式识别会议论文集* 中，2015 年，页码 120–130。

+   [47] J.-R. Ruiz-Sarmiento, C. Galindo 和 J. Gonzalez-Jimenez，“通过语义知识和概率图模型进行移动机器人场景物体识别，” *专家系统与应用*，第 42 卷，第 22 期，页码 8805–8816，2015 年。

+   [48] N. Das, E. Ohn-Bar 和 M. M. Trivedi，“驾驶员手部检测算法性能评估：挑战、数据集和指标，”在 *智能交通系统（ITSC），2015 IEEE 第 18 届国际会议* 中。IEEE，2015 年，页码 2953–2958。

+   [49] R. Salakhutdinov，“学习深度生成模型，” *Annual Review of Statistics and Its Application*，第 2 卷，页码 361–385，2015 年。

+   [50] J. Schmidhuber，“关于学习思考：针对新型强化学习控制器和递归神经世界模型的算法信息理论，” *arXiv preprint arXiv:1511.09249*，2015 年。

+   [51] M. Turan, Y. Almalioglu, H. Araujo, E. Konukoglu 和 M. Sitti，“一种基于非刚性地图融合的内窥镜胶囊机器人直接 SLAM 方法，” *International journal of intelligent robotics and applications*，第 1 卷，第 4 期，页码 399–409，2017 年。

+   [52] T. Chen, Z. Chen, Q. Shi 和 X. Huang，“使用机器学习算法进行道路标线检测与分类，” 载于*Intelligent Vehicles Symposium (IV), 2015 IEEE*。IEEE，2015，页码 617–621。

+   [53] M. Vrigkas, C. Nikou 和 I. A. Kakadiaris，“人类活动识别方法的综述，” *Frontiers in Robotics and AI*，第 2 卷，页码 28，2015 年。

+   [54] O. K. Oyedotun 和 A. Khashman，“基于视觉的静态手势识别中的深度学习，” *Neural Computing and Applications*，第 28 卷，第 12 期，页码 3941–3951，2017 年。

+   [55] R. K. Moore，“从谈话和倾听机器人到智能交互机器。”

+   [56] G. E. Hinton, S. Osindero 和 Y.-W. Teh，“一种快速学习深度信念网络的算法，” *Neural computation*，第 18 卷，第 7 期，页码 1527–1554，2006 年。

+   [57] Y. Zhu, R. Mottaghi, E. Kolve, J. J. Lim, A. Gupta, L. Fei-Fei 和 A. Farhadi，“使用深度强化学习进行室内场景的目标驱动视觉导航，” 载于*Robotics and Automation (ICRA), 2017 IEEE International Conference on*。IEEE，2017，页码 3357–3364。

+   [58] F. Cruz, J. Twiefel, S. Magg, C. Weber, 和 S. Wermter，“在家庭场景中的语音指导交互式强化学习，” 载于*Neural Networks (IJCNN), 2015 International Joint Conference on*。IEEE，2015，页码 1–8。

+   [59] A. Vinciarelli, A. Esposito, E. André, F. Bonin, M. Chetouani, J. F. Cohn, M. Cristani, F. Fuhrmann, E. Gilmartin, Z. Hammal *等*，“在人类-人类和人类-机器交互中的人类行为建模、分析和合成的开放挑战，” *Cognitive Computation*，第 7 卷，第 4 期，页码 397–413，2015 年。

+   [60] J. Doshi, Z. Kira 和 A. Wagner，“从深度学习到情节记忆：创建视觉体验的类别，” 载于*Proceedings of the third annual conference on advances in cognitive systems ACS*，2015 年，页码 15。

+   [61] X. Wang, D. Fouhey 和 A. Gupta，“为表面法线估计设计深度网络，” 载于*Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*，2015 年，页码 539–547。

+   [62] H. Cuayáhuitl, S. Keizer 和 O. Lemon，“通过深度强化学习进行战略对话管理，” *arXiv preprint arXiv:1511.08099*，2015 年。

+   [63] E. Ohn-Bar 和 M. M. Trivedi，“在自动驾驶和高度自动化车辆时代观察人类，” *IEEE Transactions on Intelligent Vehicles*，第 1 卷，第 1 期，页码 90–104，2016 年。

+   [64] J. Wei, H. Liu, G. Yan, 和 F. Sun, “使用多模态深度极端学习机的机器人抓取识别，” *多维系统与信号处理*，第 28 卷，第 3 期，页码 817–833，2017 年。

+   [65] M. Mathieu, C. Couprie, 和 Y. LeCun, “超越均方误差的深度多尺度视频预测，” *arXiv 预印本 arXiv:1511.05440*，2015 年。

+   [66] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, 和 Z. Wojna, “重新思考计算机视觉中的 inception 架构，” 见于 *IEEE 计算机视觉与模式识别会议论文集*，2016 年，页码 2818–2826。

+   [67] M. Turan, Y. Almalioglu, E. Konukoglu, 和 M. Sitti, “一种基于深度学习的 6 自由度定位方法用于内窥镜胶囊机器人，” *arXiv 预印本 arXiv:1705.05435*，2017 年。

+   [68] J. Tang, C. Deng, 和 G.-B. Huang, “多层感知器的极端学习机，” *IEEE 神经网络与学习系统交易*，第 27 卷，第 4 期，页码 809–821，2016 年。

+   [69] M. Turan, Y. Almalioglu, H. Araujo, E. Konukoglu, 和 M. Sitti, “基于非刚性地图融合的 RGB-深度 SLAM 方法用于内窥镜胶囊机器人，” *arXiv 预印本 arXiv:1705.05444*，2017 年。

+   [70] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, 和 A. L. Yuille, “Deeplab: 使用深度卷积网络、空洞卷积和全连接 CRFs 的语义图像分割，” *arXiv 预印本 arXiv:1606.00915*，2016 年。

+   [71] J.-C. Chen, V. M. Patel, 和 R. Chellappa, “使用深度 CNN 特征进行无约束的人脸验证，” 见于 *计算机视觉应用（WACV），2016 IEEE 冬季会议*。IEEE，2016 年，页码 1–9。

+   [72] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, 和 A. Swami, “对抗设置中深度学习的局限性，” 见于 *安全与隐私（EuroS&P），2016 IEEE 欧洲研讨会*。IEEE，2016 年，页码 372–387。

+   [73] S. Levine, C. Finn, T. Darrell, 和 P. Abbeel, “端到端深度视觉运动策略的训练，” *机器学习研究杂志*，第 17 卷，第 1 期，页码 1334–1373，2016 年。

+   [74] G. Huang, Y. Sun, Z. Liu, D. Sedra, 和 K. Q. Weinberger, “具有随机深度的深度网络，” 见于 *欧洲计算机视觉会议*。Springer，2016 年，页码 646–661。

+   [75] S. Niekum, S. Osentoski, G. Konidaris, S. Chitta, B. Marthi, 和 A. G. Barto, “从非结构化演示中学习基于状态的有限表示，” *国际机器人研究杂志*，第 34 卷，第 2 期，页码 131–157，2015 年。

+   [76] C. Devin, A. Gupta, T. Darrell, P. Abbeel, 和 S. Levine, “学习用于多任务和多机器人迁移的模块化神经网络策略，” 见于 *机器人与自动化（ICRA），2017 IEEE 国际会议*。IEEE，2017 年，页码 2169–2176。

+   [77] C. Finn, X. Y. Tan, Y. Duan, T. Darrell, S. Levine, 和 P. Abbeel, “用于视觉运动学习的深度空间自编码器，” 见于 *机器人与自动化（ICRA），2016 IEEE 国际会议*。IEEE，2016 年，页码 512–519。

+   [78] A. A. Rusu, M. Vecerik, T. Rothörl, N. Heess, R. Pascanu, 和 R. Hadsell, “从像素到现实的机器人学习与渐进网络，” *arXiv 预印本 arXiv:1610.04286*，2016 年。

+   [79] S. Mohamed 和 D. J. Rezende, “用于内在动机强化学习的变分信息最大化，” 在 *神经信息处理系统进展*，2015 年，第 2125–2133 页。

+   [80] D. Maturana 和 S. Scherer, “Voxnet：用于实时物体识别的 3D 卷积神经网络，” 在 *智能机器人与系统（IROS），2015 IEEE/RSJ 国际会议*。IEEE, 2015 年，第 922–928 页。

+   [81] Y. Zhang, K. Sohn, R. Villegas, G. Pan, 和 H. Lee, “通过贝叶斯优化和结构化预测改进深度卷积网络的目标检测，” 在 *IEEE 计算机视觉与模式识别会议论文集*，2015 年，第 249–258 页。

+   [82] M. Turan, Y. Almalioglu, E. P. Ornek, H. Araujo, M. F. Yanik, 和 M. Sitti, “基于磁视觉传感器融合的内窥镜胶囊机器人稠密三维重建与定位，” *arXiv 预印本 arXiv:1803.01048*，2018 年。

+   [83] C. Finn 和 S. Levine, “用于规划机器人运动的深度视觉预测，” 在 *机器人与自动化（ICRA），2017 IEEE 国际会议*。IEEE, 2017 年，第 2786–2793 页。

+   [84] V. Campos, A. Salvador, X. Giro-i Nieto, 和 B. Jou, “深入探讨情感：理解用于视觉情感预测的精细调整卷积神经网络，” 在 *第一届国际多媒体情感与情感研讨会论文集*。ACM, 2015 年，第 57–62 页。

+   [85] S. Gu, E. Holly, T. Lillicrap, 和 S. Levine, “用于机器人操作的深度强化学习与异步脱离策略更新，” 在 *机器人与自动化（ICRA），2017 IEEE 国际会议*。IEEE, 2017 年，第 3389–3396 页。

+   [86] M. Turan, Y. Almalioglu, H. Gilbert, A. E. Sari, U. Soylu, 和 M. Sitti, “Endo-vmfusenet：用于非校准、不同步和不对称内窥镜胶囊机器人定位数据的深度视觉-磁传感器融合方法，” *arXiv 预印本 arXiv:1709.06041*，2017 年。

+   [87] J. Sanchez-Riera, K.-L. Hua, Y.-S. Hsiao, T. Lim, S. C. Hidayati, 和 W.-H. Cheng, “基于 RGB-D 的视觉识别数据融合的比较研究，” *模式识别快报*，第 73 卷，第 1–6 页，2016 年。

+   [88] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin *等*，“Tensorflow：异构分布式系统上的大规模机器学习，” *arXiv 预印本 arXiv:1603.04467*，2016 年。
