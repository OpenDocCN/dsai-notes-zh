<!--yml

分类：未分类

日期：2024-09-06 19:46:14

-->

# [2205.15683] 为什么 NLP 模型在基础数学问题上表现不佳？基于深度学习的文字问题求解器综述

> 来源：[`ar5iv.labs.arxiv.org/html/2205.15683`](https://ar5iv.labs.arxiv.org/html/2205.15683)

# 为什么 NLP 模型在基础数学问题上表现不佳？

基于深度学习的文字问题求解器综述

Sowmya S Sundaram L3S 研究中心，德国汉诺威 Sairam Gurajada IBM 研究，USA¹¹1 作者在此处进行的工作 Marco Fisichella L3S 研究中心，德国汉诺威 Deepak P 女王大学，英国贝尔法斯特 Savitha Sam Abraham Örebro 大学，瑞典

###### 摘要

从上世纪最后十年下半期开始，对自动解决数学文字问题（MWP）算法的兴趣逐渐增加。这是一项具有挑战性且独特的任务，需要将表层文本模式识别与数学推理相结合。尽管进行了广泛的研究，我们仍然离建立稳健的基础数学文字问题表示和有效的通用解决方案还有很远的距离。在本文中，我们对各种已开发的解决问题模型进行批判性检查，分析它们的优缺点及未来面临的挑战。在过去两年中，许多深度学习模型在基准数据集上取得了具有竞争力的结果，使得在这一时刻对文献进行批判性和概念性的分析非常有用。我们退一步分析，尽管学术兴趣如此丰富，主要使用的实验和数据集设计仍然是一个障碍。从密切分析文献的角度出发，我们还努力为未来的数学文字问题研究提供一个路线图。

## 介绍

自然语言处理一直是人工智能中最受欢迎且最引人入胜的 AI-完全子领域之一。最早的系统之一可以说是 Bobrow 的博士论文，题为自动解决算术文字问题（1964）。挑战主要有两个方面：（a）分析无约束的自然语言，以及（b）将复杂的文本模式映射到一个小的数学词汇中，以便在其推理框架内使用。

直到 2010 年，已经在各种领域（如代数、百分比、比例等）进行了大量的 MWP 求解器探索。这些求解器在很大程度上依赖于手工制作的规则，以弥合语言和相应数学符号之间的差距。可以推测，虽然这些方法在其特定领域中有效，但未能很好地推广到解决 MWP 的更广泛问题。此外，由于缺乏被广泛接受的数据集，很难衡量所提出系统的相对性能（Mukherjee 和 Garain 2008）。

| 输入 | Kevin 有 3 本书。Kylie 有 7 本书。他们一共有多少本书？ |
| --- | --- |
| 答案 | 10 |

表 1：典型示例

Kushman 等人 (2014) 的开创性工作使用统计方法解决文字问题，为利用传统机器学习方法开发自动 MWP 解算器奠定了基础。该工作还引入了第一个数据集，通常称为 Alg514，包含与问题相关的多个线性方程。机器学习任务是将方程中的系数映射到问题中的数字。该数据集由三元组结构的数据单元组成：自然语言问题、方程集和最终答案。

镜鉴自然语言处理（NLP）的最新趋势，针对数学文字问题（MWP）的深度学习模型迅猛增长。一些早期的模型，如 Wang 等人 (2017) 和 Ling 等人 (2017)，将文本转换为方程的任务建模为序列到序列（seq2seq，简称）问题。在这种背景下，越来越复杂的模型被提出以捕捉超越表面文本的语义。一些模型以图的形式捕捉结构信息（涉及输入文本、领域知识、输出方程结构），并利用图神经网络的进展（Li 等人 (2020)，Zhang 等人 (2020c) 等）。另一些模型则利用了变换器在建模中的优势（Liang 等人 (2021)，Piękos 等人 (2021) 等）。我们将详细探讨这些模型。

由于这是一个从自然语言处理领域诞生之初就一直受到稳定（可以说是缓慢而稳定）关注的问题，对解决该问题技术的综述为研究人员提供了良好的视野。作者收集了过去三年在主要 NLP 领域发表的 30+篇关于文字问题解决的深度学习论文。每篇论文都有其独特的直观基础，但大多数实现了相当的实证表现。方法的丰富使得即便是对于比较一般的文字问题解决设置，也难以明确指出最新技术水平。因此，对采用的技术进行广泛概述为进一步研究提供了良好的基础。同样，理解数据集的来源、设置和相关性也很重要。例如，许多数据集在不同时间点通常被不同名称引用。此外，问题场景的细微方面在系统之间有所不同（例如是否可以解决多个方程，是否仅限于代数或更多领域等）。在本综述中，我们系统分析了模型，列出了基准数据集，并从批判性分析的角度审查了文字问题解决文献。

### 相关综述

有两项开创性的调查涵盖了文字问题求解研究。一项是 Mukherjee 和 Garain（2008），详细概述了这一问题的符号求解器。第二项较新的调查是 Zhang 等人（2020a），涵盖了截至 2020 年提出的模型。在过去两年里，专注于深度学习的各种算法开发出现了急剧上升，以建模这一问题。我们的调查主要基于这些深度学习模型。我们调查与另一相关调查，Faldu 等人（2021）的区别在于：使用批判性的视角分析深度学习模型，使我们能够在分析中识别方法的稳健性缺陷，并追溯到模型设计和数据集选择问题。我们还将包括各种方法在热门数据集上的经验性能值，并讨论未来的方向。

## 符号求解器

我们的讨论从使用基于规则的方法将文本输入转换为一组符号的传统求解器开始。在这一领域的早期求解器，如 STUDENT Bobrow（1964）及其他后续的求解器（Fletcher（1985），Dellarosa（1986）），主要的方法是将自然语言输入映射到一个预定义的基础模式。这需要一种机制来提炼语言、文字问题及相应数学符号的共同预期，以形成定制的规则集来驱动转换。这可以被视为建立一个槽填充机制，将文字问题的主要实体映射到一组方程模板中的槽位。

表示代数 MWP（数学文字问题）的模式的示例见表 2。

| 问题 | 约翰有 5 个苹果。他给了玛丽 2 个，他现在还剩多少个？ |
| --- | --- |
| 模板 | [所有者[1]] 拥有 [X] [对象]。 |
|  | [所有者[1]] [转移] [Y] [对象] 给 [所有者[2]]。 |
|  | [所有者[1]] 拥有 [Z] [对象]。 |
|  | Z = X - Y |
| 槽填充 | [约翰] 拥有 [5] [苹果]。 |
|  | [约翰] [给] [2] [苹果] 给 [玛丽]。 |
|  | [玛丽] 拥有 [Z] [苹果]。 |
|  | Z = 5 - 2 |
| 答案 | Z = 3 |

表 2：符号求解器的工作流程

优势在于这些系统在处理无关信息方面具有鲁棒性，专家编写的规则集使其能够专注于问题的相关部分。为了进一步提高在专注于特定领域的应用中的实际效果，研究致力于为目标领域量身定制这些符号系统 Mukherjee 和 Garain (2008)。如观察所示，规则需要全面，以捕捉语言的各种细微差别。因此，它们在不同语言风格之间的泛化效果不佳。由于每个系统都是为特定领域设计的，因此由于缺乏跨领域数据集，比较性能评估受到了阻碍。

## 统计求解器

与自然语言处理中的许多任务一样，统计机器学习技术在解决词汇问题上自 2014 年起开始主导该领域。这些技术的核心主题是，在基于优化的评分框架中评分多个潜在解决方案（可能是方程或表达树，如我们将很快看到的），然后得出给定文本的正确数学模型。这可以视为将任务视为结构预测挑战 Zhang 等 (2020a)。

|  | $P(y\|x;\theta)=\frac{e^{\theta.\phi(x,y)}}{\sum_{y^{\prime}\in Y}e^{\theta.\phi(x,y^{\prime})}}$ |  | (1) |
| --- | --- | --- | --- |

与优化问题类似，方程 1 涉及学习参数 $\theta$ 的问题，这些参数与特征函数 $\phi$ 相关。考虑标记数据集 $D$，它由 $n$ 对 $(x,y,a)$ 组成，其中 $x$ 是自然语言问题，$y$ 是数学表达式，$a$ 是数值答案。任务是对所有可能的表达式 $Y$ 进行评分，并通过优化设置最大化标记的 $y$ 选择。这是通过修改特征函数 $\phi(x,y)$ 的参数 $\theta$ 完成的。不同的模型提出了不同的 $\phi$ 公式。在实践中，束搜索被用作控制机制。我们根据数学结构 $y$ 的类型，将开发的丰富算法分为两类——方程模板或表达树。方程模板是从训练数据中挖掘的，有点类似于符号系统的槽填充概念。然而，如果推理时的词汇问题来自未见过的方程模板，它们成为泛化的瓶颈。为了解决这个问题，使用具有明确后缀遍历的表达树来建模方程。尽管它们将系统的复杂性限制在单一方程模型中，但它们提供了更广泛的泛化范围。

### 方程模板

方程模板提取出数值系数，并保持变量和运算符结构。这被用作数学建模的流行表示。首先，Kushman 等 (2014) 使用结构预测来对方程模板和输入文本中数字与模板系数的对齐进行评分。使用基于状态的表示，Hosseini 等 (2014) 模型化了简单的基础级别单词问题，重点关注动词分类。Zhou 等 (2015) 通过使用二次规划来提高效率，从而增强了 Kushman 等 (2014) 的工作。Upadhyay 和 Chang (2017) 介绍了一种在此空间中表示推导的复杂方法。

### 表达式树

表达式树仅适用于单方程系统。单个方程被表示为一棵树，树的叶子是数字，内部节点是运算符，如 Koncel-Kedziorski 等 (2015) 所示。

表达式树基于的方法收敛速度更快，这显然是因为模型复杂度降低。一些解算器（如 Roy 和 Roth (2015)) 设有联合优化目标，以识别相关数字并填充表达式树。另一方面，Koncel-Kedziorski 等 (2015)；Mitra 和 Baral (2016) 使用领域知识来限制搜索空间。

## 神经解算器

迄今为止我们看到的解算器的主要挑战之一是将输入文本转换为有意义的特征空间，以便进行后续求解；前几节中看到的论文之间的主要分歧基于技术风格和用于文本到表示转换的方法论。

{森林}

用于树= 绘制，文本宽度=1.4cm，居中对齐，分叉边缘，[自动

单词

问题

解算器 [符号

解算器] [统计

解算器 [表达式

树] [方程

模板] ] [神经

解算器 [Seq2Seq] [基于图的] [变换器] [对比] [知识

蒸馏] ] ] \node[draw, fit=(current bounding box.south east) (current bounding box.north west)] ;

图 1：单词问题解算器类型

分布式表示的出现 Le 和 Mikolov (2014); Peters 等 (2018); Pennington 等 (2014); Devlin 等 (2018)，标志着在解决数学文字问题的研究方向上的重大转变，重点关注学习架构的细节，而不是特征空间建模。甚至出现了针对文字问题的领域特定分布式表示学习者 Sundaram 等 (2020)。例如，Ling 等 (2017) 设计了一种 seq2seq 模型，将学习程序作为中间步骤。这些早期工作使得将文字问题求解任务视为语言翻译任务，即从输入自然语言文本翻译为表示方程或谓词序列的字符序列，成为一种流行做法。然而，这种设计选择有其局限性，有时对可以被纳入这种架构的数学问题有严重的限制 Patel 等 (2021)。表 3 中展示了这些语言结构与数学结构理解挑战的一些例子，特别是对于神经求解器而言。一个重要的例子是，涉及解决多个方程的方程组在这种框架下并不容易处理。一个显著的例外是流行的基准 MathDQN Wang 等 (2018)，该方法采用了深度强化学习。我们在下文的不同子节中考虑了不同类别的深度学习求解器。

| 输入 | Kevin 有 3 本书。Kylie 有 7 本书和 3 支铅笔。他们一共拥有多少本书？ |
| --- | --- |
| 数学结构 | 3 + 7 |
| 语言结构 | (Person1) 有 (X) (object1)。 (Person2) 有 (Y) (object1) 和 (Z) (object2)。 |
| 挑战 | (1) X 和 Y 的顺序在加法中不重要 (2) 多个方程不形成序列 (3) 相似对象需要归为一组 |

表 3: 典型挑战

### Seq2Seq 求解器

广泛使用的 Seq2Seq Sutskever 等 (2014) 架构在自动文字问题求解中非常流行。从早期直接使用 LSTMs Hochreiter 和 Schmidhuber (1997) / GRUs Cho 等 (2014) 的 Seq2Seq 模型 (Huang 等 (2017), Wang 等 (2017)) 到包括领域知识的复杂模型 Ling 等 (2017); Qin 等 (2020); Chiang 和 Chen (2019); Qin 等 (2021))，对这一基本架构的多种形式已被采用。

<svg height="198.51" overflow="visible" version="1.1" width="353.91"><g transform="translate(0,198.51) matrix(1 0 0 -1 0 0) translate(61.76,0) translate(0,178.55)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -45.39 -3.38)" fill="#000000" stroke="#000000"><foreignobject width="90.79" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">输入序列</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 97.84 -3.38)" fill="#000000" stroke="#000000"><foreignobject width="101.93" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">输出序列</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 -44.12 -84.1)" fill="#000000" stroke="#000000"><foreignobject width="88.25" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">数学问题</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 121.23 -82.68)" fill="#000000" stroke="#000000"><foreignobject width="55.16" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">方程</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 -55.89 -162.05)" fill="#000000" stroke="#000000"><foreignobject width="112.16" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">词嵌入</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 107.27 -162.05)" fill="#000000" stroke="#000000"><foreignobject width="180.27" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">字符/词嵌入</foreignobject></g></g></svg>

图 2：通用 Seq2Seq 表达式

初始的一组模型直接使用了 Seq2Seq，使用 LSTM 或 GRUs 的变体或简单启发式方法（例如，黄等人（2016）通过检索来提升结果）。通过引入一些数学方面的内容，取得了显著的改进。这再次证明了这个任务不仅仅是语言翻译的问题。凌等人（2017）将文字问题转换为包含解释或理由的文本。这是通过在大数据集上生成逐步程序的中间步骤完成的。尽管报告的准确率较低，但领域范围从概率到相对速度不等，统一框架通过定性示例展示了有意义的分析。这一点在阿米尼等人（2019）的研究中得到了改进，该研究通过对类别的标签增强了数据集并添加了领域信息。SAU-Solver 秦等人（2020）引入了一种树状表示法，其中的语义元素与文字问题对齐。如表 6 所示，这是一个强有力的竞争者。在江和陈（2019）的研究中，设计了一种将方程构建分解为一组栈操作的新方法——以便可以学习语言与运算符之间更细致的映射。文献中有一个新兴领域致力于使用神经符号推理来弥合感知层面任务（语言理解）和认知层面任务（数学推理）之间的差距。秦等人（2021）的研究就是一个例子。通过这些讨论，显而易见，添加某种形式的领域知识对自动求解器有益。

### 基于图的求解器

随着图模型的出现 Xia 等人 (2019) 和对多模态处理的兴趣增加，图数据结构成为了向求解器添加知识的一种手段。实现这一点的一种方式是简单地将输入问题建模为图 Feng 等人 (2021); Li 等人 (2020); Yu 等人 (2021); Hong 等人 (2021)。这包括领域知识 (a) 与数学推理相关的语言交互，或 (b) 量图表明文本中各种数字如何连接。另一种方式是建模解码器以接受方程的图形输入 Xie 和 Sun (2019); Lin 等人 (2021); Zaporojets 等人 (2021); Cao 等人 (2021); Liu 等人 (2019); Wu 等人 (2021b)。另一种自然的途径是利用图形神经网络用于编码器和解码器 Zhang 等人 (2020c); Wu 等人 (2020, 2021a); Shen 和 Jin (2020)。

<svg height="198.51" overflow="visible" version="1.1" width="258.25"><g transform="translate(0,198.51) matrix(1 0 0 -1 0 0) translate(54.72,0) translate(0,178.55)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -38.31 -3.46)" fill="#000000" stroke="#000000"><foreignobject width="76.62" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">图形输入</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 96.73 -3.38)" fill="#000000" stroke="#000000"><foreignobject width="104.16" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">输出序列</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 -46.51 -82.68)" fill="#000000" stroke="#000000"><foreignobject width="93.02" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">输入序列</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 104.93 -82.75)" fill="#000000" stroke="#000000"><foreignobject width="87.77" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">图形输出</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 -38.31 -162.05)" fill="#000000" stroke="#000000"><foreignobject width="76.62" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">图形输入</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 104.93 -162.05)" fill="#000000" stroke="#000000"><foreignobject width="87.77" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">图形输出</foreignobject></g></g></svg>

图 3：基于图的通用公式

图形能够表示复杂的关系。凭借图神经网络（GNNs） Wu 等人 (2021c) 的成功，它们很容易融入编码器-解码器架构。从直观上讲，当在输入侧使用图形时，我们可以建模任务的语言侧的复杂语义关系。当在解码器侧使用图形时，可以捕捉到数值实体之间的关系或问题的中间表示。类似地，图到图建模使语言和数学的语义匹配成为可能。这并不一定意味着图到图超越了所有其他形式化。每种基于图的论文都有独特的优缺点，因为语言和数学模型都很难 (a) 单独建模和 (b) 建模交互。正如在表 6 中看到的那样，基于图的模型既流行又强大。与序列不同，当输入文本表示为图形时，重点更多地放在相关实体上，而不是文本流。同样，数量图或语义信息图消除了方程中的排序歧义。然而，这种形式化仍未解决多个方程问题。

### Transformer

Transformer Vaswani 等人 (2017) 最近彻底改变了自然语言处理（NLP）领域。词汇问题解决也不例外。通过使用 BERT Devlin 等人 (2018) 嵌入或通过基于 Transformer 的编码器-解码器模型，一些近期的研究利用了 Transformer 模型的概念 Liu 等人 (2019); Kim 等人 (2020)。翻译被多种方式建模，例如从文本到解释 Piękos 等人 (2021); Griffith 和 Kalita (2020)，或者从文本到方程 Shen 等人 (2021); Liang 等人 (2021)。

当从 Word2Vec Mikolov 等人 (2013) 向 BERT 嵌入 Devlin 等人 (2018) 迁移时，预计会有巨大的收益，因为 (a) 更大程度地融入了上下文信息和 (b) 自动捕获了相关信息，因为 BERT 本质上是一个掩蔽语言模型。有趣的是，这些收益并不像在其他语言任务如问答或机器翻译 Devlin 等人 (2018) 中那样大。BERT 是一个大型模型，需要用领域特定的信息进行微调。这些小的收益表明词汇问题数据集的质量较低，这与数据集要么在深度学习标准下相当小，要么具有高词汇重叠的事实相符，实际上暗示了特征词汇问题的集合很小。

### 对比解算器

随着 Siamese 网络的广泛使用（Koch et al. (2015）），构建在数据类间矢量表示对比的表示的想法引起了一些关注。在解决文字问题的背景下，一些定制的基于变换器的编码器-解码器模型（Li et al. (2021b)；Hong et al. (2021)）已经被提出；这些模型旨在有效利用对比学习（Le-Khac et al. (2020））。

这是一个相对较新的范式，仍需要更多研究来确定明确的趋势。解决文字问题的主要障碍之一是两个在语言上高度相似的文字问题可能具有完全不同的数学结构。由于对比学习基于相似输入示例会导致更接近的表示的原则，它使得我们可以利用相似性和差异性来克服这个瓶颈，并有意识地设计语义信息丰富的中间表示，从而使相似性不仅来自语言词汇，还来自数学概念。

### 教师-学生解算器

在大型通用端到端模型的背景下，知识蒸馏的范式在自然语言处理领域变得流行（Li et al. (2021a））。其基本思想是从通用的大型预训练模型中提炼出较小的任务特定模型。由于文字问题数据集的规模相对较小，因此大型通用网络可以针对文字问题解决进行微调，这一点在 Zhang et al. (2020b) 和 Hong et al. (2021) 的研究中得到了有利的证明。

再次强调，这也是一个新兴的范式。与我们之前讨论的基于变换器的模型类似，预训练语言模型单独存在的事实不足以完成这一任务，这增强了这一方向的初步努力。知识蒸馏使得一个模型能够将一个通用模型的学习集中到一个更小、更专注的模型上，尤其是在数据点较少的情况下。因此，通过使用知识蒸馏算法添加语义信息的方法是有前景的，值得关注。

## 领域-细分解算器

一些研究，涵盖了统计解算器和深度模型的家族，关注数学中特定领域的相关特征，例如概率文字问题（Dries et al. (2017)；Suster et al. (2021)；Tsai et al. (2021）），数论文字问题（Shi et al. (2015）），几何文字问题（Seo et al. (2015)；Chen et al. (2021））和年龄文字问题（Sundaram and Abraham (2019））。

## 数据集

用于数学文字问题求解的数据集列在表 4 中，并附有其特点。表的上半部分描述了数据对象相对较少的数据集（具体为$\leq 1k$）。下半部分包含了更新的数据集，这些数据集更大且在深度学习方法中更为流行。

| 数据集 | 类型 | 领域 | 大小 | 来源 |
| --- | --- | --- | --- | --- |
| Alg514 | 多方程 | (+,-,*,/) | 514 | Kushman 等 (2014) |
| (SimulEq-S) |  |  |  |  |
| AddSub | 单方程 | (+,-) | 340 | Hosseini 等 (2014) |
| (AI2) |  |  |  |  |
| SingleOp | 单方程 | (+,-,*,/) | 562 | Roy 等 (2015) |
| (Illinois, IL) |  |  |  |  |
| SingleEq | 单方程 | (+,-,*,/) | 508 | Koncel-Kedziorski 等 (2015) |
| MAWPS | 多方程 | (+,-,*,/) | 3320 | Koncel-Kedziorski 等 (2016) |
| MultiArith | 单方程 | (+,-,*,/) | 600 | Roy 和 Roth (2015) |
| (Common Core, CC) |  |  |  |  |
| AllArith | 单方程 | (+,-,*,/) | 831 | Roy 和 Roth (2017) |
| Perturb | 单方程 | (+,-,*,/) | 661 | Roy 和 Roth (2017) |
| Aggregate | 单方程 | (+,-,*,/) | 1492 | Roy 和 Roth (2017) |
| DRAW-1k | 多方程 | (+,-,*,/) | 1k | Upadhyay 和 Chang (2017) |
| AsDIV-A | 单方程 | (+,-,*,/) | 2373 | Miao 等 (2020) |
| SVAMP | 单方程 | (+,-,*,/) | 1000 | Patel 等 (2021) |
| Dolphin18k | 多方程 | (+,-,*,/) | 18k | Huang 等 (2016) |
| AQuA-RAT | 多项选择 | - | 100k | Ling 等 (2017) |
| Math23k* | 单方程 | (+,-,*,/) | 23k | Huang 等 (2017) |
| MathQA | 单方程 | (+,-,*,/) | 35k | Amini 等 (2019) |
| HMWP* | 多方程 | (+,-,*,/) | 5k | Qin 等 (2020) |
| Ape210k* | 单方程 | (+,-,*,/) | 210k | Liang 等 (2021) |
| GSM8k | 单方程 | (+,-,*,/) | 8.5k | Cobbe 等 (2021) |
| CM17k* | 多方程 | (+,-,*,/) | 17k | Qin 等 (2021) |

表 4：数据集

(*中文数据集)

### 小型数据集

Kushman 等人（2014）在解决文字题问题方面的开创性工作，介绍了一个经典数据集（Alg514），包含 514 个跨各种代数领域（如百分比、混合、速度等）的文字题。这个数据集为每个问题标注了多个方程。AddSub 由 Hosseini 等人（2014）提出，包含简单的加法/减法问题，展示了有限的语言复杂性。SingleOp 由 Roy 等人（2015）和 MultiArith 由 Roy 和 Roth（2015）提出，允许对操作符进行控制（前者是单一操作符，后者是两个操作符）。SingleEq 由 Koncel-Kedziorski 等人（2015）提出，其独特之处在于为小学水平的问题融入了长句结构。AllArith 由 Roy 和 Roth（2017）提出，是 AddSub、SingleEq 和 SingleOp 的并集子集。 "Perturb" 是 AllArith 的轻微扰动的文字题集合，而 Aggregate 是 AllArith 和 Perturb 的并集。MAWPS（数学文字题解决库）由 Koncel-Kedziorski 等人（2016）创建，是一个经过精心策划的数据集（具有故意的模板重叠控制），包括了截至那时所有提出的数据集。MAWPS 的单一方程子集（AsDIV-A）由 Miao 等人（2020）研究，用于解算器的诊断分析。类似地，Patel 等人（2021）提供的批评使用了他们新提出的数据集 SVAMP。在 SVAMP 中，来自流行数据集 AsDIV-A 的细微扰动的文字题。这个特定子集用于展示，尽管在 AsDIV-A 上可以轻松获得高准确值，但 SVAMP 对大多数解算器构成了严峻挑战，因为它捕捉了相似语言形式与不相似方程之间的细微差别。所有上述数据集都包括方程和答案的注释。鉴于这些数据集之间的子集-超集关系，实际使用这些数据集时需要确保谨慎采样，以创建用于训练、测试和交叉验证的子集。

### 大型数据集

Dolphin18k Huang 等人 (2016) 是一个早期的专有数据集，主要使用统计解算器进行评估。AQuA-RAT Ling 等人 (2017) 引入了第一个大型众包数据集，包含具有理由或解释的词题。这使得设置与上述数据集大相径庭，不仅在于规模，还涵盖了多种领域（如物理学、代数、几何、概率等）。另一个不同之处在于注释包括了整个文本解释，而不仅仅是方程式。MathQA Amini 等人 (2019) 对 AQuA-RAT 进行了关键分析，选择了核心子集并用谓词列表进行了注释，以扩大其使用范围。研究人员必须注意，MathQA 是 AQuA-RAT 的一个子集。GSM8k Cobbe 等人 (2021) 是一个最近的单方程数据集，是 AsDIV-A Miao 等人 (2020) 的大规模版本。Math23K 是一个流行的中文单方程数学词题解决数据集。最近的继任者是 Ape210k Liang 等人 (2021)。

## 评估指标

最流行的指标是答案准确度，它评估预测的方程式并检查是否与标记的方程式相同。另一个指标是方程式准确度，它主要进行字符串匹配，并评估生成的方程式与注释标签中的方程式之间的匹配度。

## 深度模型的性能

在这一部分，我们描述了神经解算器的表现，以向读者提供一个高层次的视角，比较各个提出的模型的性能。

我们在表格 6 中列出了深度模型的性能，涉及两个主要数据集——Math23K 和 MAWPS。

这些深度模型中有一些也在其他数据集上报告了分数。为了简洁起见，我们选择了最受欢迎的深度模型数据集。总体来看，模型在答案准确性上通常达到 70-80 个百分点。Shen 等 (2021) 在 Math23k 上超越了所有其他模型，而 RPKHS Yu 等 (2021) 仍是 MAWPS 最佳模型。如前所述，基于图的模型既受欢迎又有效。需要注意的是，正如数据集讨论中所推断的，(a) Math23k 和 MAWPS 都是单方程数据集，并且 (b) 尽管这两个数据集在设计时进行了某些词汇重叠，但它们的语义质量非常相似。Patel 等 (2021) 也对这一方面进行了实验和探索。因此，尽管我们在表中展示了最佳表现的算法，但仍需进一步研究以设计合适的度量标准或数据集，以便可以最终比较这些不同的算法。

| 模型 | 类型 | AQuA-RAT | MathQA | 来源 |
| --- | --- | --- | --- | --- |
| AQuA | Seq2Seq | 36.4 | - | Ling 等 (2017) |
| Seq2Prog | Seq2Seq | 37.9 | 57.2 | Amini 等 (2019) |
| BERT-NPROP | Transformer | 37.0 | - | Piękos 等 (2021) |
| Graph-To-Tree | 基于图的 | - | 69.65 | Li 等 (2020) |

表 5：大型多领域数据集上的表现

除了这些代数数据集，多个领域的数据集 MathQA 和 AQuA 也备受关注。这在表格 5 中有所描述。值得注意的是，将 BERT 模型添加到 AQuA Piękos 等 (2021) 中，表现仍略逊于 Seq2Prog Amini 等 (2019) 模型，后者是 Seq2Seq 范式的衍生模型。

| 模型名称 | 类型 | Math23k | MAWPS | 来源 |
| --- | --- | --- | --- | --- |
| GTS | 基于图的 | 74.3 | - | Xie 和 Sun (2019) |
| SAU-SOLVER | 基于图的 | 74.8 | - | Chiang 和 Chen (2019) |
| Group-att | Transformer | 69.5 | 76.1 | Li 等 (2019) |
| Graph2Tree | 基于图的 | 77.4 | - | Li 等 (2020) |
| KA-S2T | 基于图的 | 76.3 | - | Wu 等 (2020) |
| NS-Solver | Seq2Seq | 75.67 | - | Qin 等 (2020) |
| Graph-To-Tree | 基于图的 | 78.8 | - | Li 等 (2020) |
| TSN-MD | 教师-学生 | 77.4 | 84.4 | Zhang 等 (2020b) |
| Graph-Teacher | 图与教师 | 79.1 | 84.2 | Liang 和 Zhang (2021) |
| NumS2T | 基于图的 | 78.1 | - | Wu 等 (2020) |
| Multi-E/D | 基于图的 | 78.4 | - | Shen 和 Jin (2020) |
| EPT | Transformer | - | 84.5 | Kim 等 (2020) |
| Seq2DAG | 基于图的 | 77.1 | - | Cao et al. (2021) |
| EEH-D2T | 基于图的 | 78.5 | 84.8 | Wu et al. (2021a) |
| 生成与排序 | 基于图的 | 85.4 | 84.0 | Shen et al. (2021) |
| HMS | 基于图的 | 76.1 | 80.3 | Lin et al. (2021) |
| RPKHS | 基于图的 | 83.9 | 89.8 | Yu et al. (2021) |
| CL | 对比学习 | 83.2 | - | Li et al. (2021b) |
| GTS+RODA | 基于图的 | 77.9 | - | Liu et al. (2022) |

表 6：深度模型的回答准确率

## 深度模型分析

在本文的这一部分，我们深入分析了将深度学习技术应用于自动解决文字题的优缺点。首先，理解需要两个层次：（i）描述情况或事件序列的语言结构，以及（ii）支配这些语言描述的数学结构。尽管深度学习模型迅速扩展并展示了捕捉这两个特征的良好结果，但仔细观察仍发现了进一步探索的巨大潜力。主要的操作模式是创建一个深度模型，将输入自然语言转换为基础方程。在某些情况下，输入会转换为一组谓词 Amini et al. (2019) 或解释 Ling et al. (2017)。

### 学到了什么捷径？

*Shortcut Learning* Geirhos et al. (2020) 是最近对深度神经网络进行广泛研究的现象。它描述了深度学习模型如何以浅层的方式学习模式，并因数据集中的可疑泛化而受害（例如，如果图像中只有草，就被分类为羊；由于数据集中的特殊性）。这与我们提供给模型的低级输入（如像素、词嵌入等）有关。在文字问题的背景下，Patel et al. (2021) 揭示了如何通过去除问题并仅传递情境背景，来预测正确的方程。这表明了模型设计以及数据集设计的问题。数据集具有高方程模板重叠和文本重叠。文字问题的解决很困难，因为两个完全相同的文字问题，仅有一个小的词汇变化（例如将“give”改为“take”），就会完全改变方程。因此，高词汇相似性并不意味着在数学领域的对应相似性 Patel et al. (2021); Sundaram et al. (2020)，对文本中关键方面的关注至关重要。

### 是语言还是数学在被学习？

| 问题 | 解决？ |
| --- | --- |
| John 有 5 个苹果。Mary 比 John 多 2 个苹果。Mary 有多少个苹果？ | 是 |
| John 有 5 个苹果。Mary 比 John 多 2 个苹果。谁有的苹果更少？ | 否 |
| 要使两变成五，应添加什么？ | 否 |

表 7：基线 BERT 模型的行为

一个主要的问题是是否已经对语言与数学的映射进行了充分建模，语言建模是否被不利地强调，还是数学方面已被简洁地捕捉。我们观察到在解决文字问题的语言和数学建模方面有改进的机会。除了 SVAMP Patel 等人（2021）进行的扰动实验，揭示了语言结构与数学结构之间的映射未被捕捉之外，我们建议两个额外的实验分析框架，以展示语言和数学建模的不足。第一个框架涉及在文字问题上添加问答任务作为探测测试。例如，基于 MAWPS 训练的基准 BERT 模型可以解决类似“约翰有 5 个苹果。玛丽比约翰多 2 个苹果。玛丽有多少个苹果？”的简单文字问题，但无法回答以下相关问题“约翰有 5 个苹果。玛丽比约翰多 2 个苹果。谁的苹果更少？”当然，一个原因是数据集设计。该问题的主方程是“X = 5-2”。然而，文本版本的“要使其成为 5，应该加到 2 上多少？”无法被基准模型解决。同样，许多解算器错误地输出了“X = 2 - 5”等方程，Patel 等人（2021）表明，基本数学方面的嵌入可能会改进整数减法的数学建模。因此，我们观察到，深度翻译模型既没有充分建模语言，也没有充分建模数学。

### 准确性是否足够？

如上所述，自然的研究方向是检查评估措施，也许还包括深度模型的误差度量，以便在语法和语义之间建立更紧密的联系。模型在预测答案或方程的准确性高，表明文本与数学符号之间存在浅层映射。这类似于著名的 McNamara 谬误²²2 [`en.wikipedia.org/wiki/McNamara_fallacy`](https://en.wikipedia.org/wiki/McNamara_fallacy)，该谬误警告不要过度使用单一指标来评估复杂问题。一个探索方向是数据增强，即用多个等效方程标注单个词汇问题。未来需要衡量生成方程的合理性、模型对简单扰动的鲁棒性（也许可以通过去噪自编码器实现）以及模型识别词汇问题中重要实体的能力（也许使用基于注意力分析的指标）。Kumar et al. (2021) 已经进行了一项努力，生成了对抗样本并利用其评估 SOTA 模型。

### 训练模型是否可访问？

大多数 SOTA 系统都有自己详细记录的代码库。尽管有一个聚合工具包 Lan et al. (2021)（开源 MIT 许可证）可用，但运行保存的模型进行推理模式，以探测数据集的质量，证明是一项艰巨的任务，存在各种缺失的超参数或缺少的保存模型。然而，这有趣地表明，能够接受单个词汇问题作为输入并计算输出的 API，对于应用设计师将非常有用。这在早期的系统中已经实现，例如 Roy and Roth (2018) 和 Wolfram (2015)。

## 基准数据集分析

在论文的这一部分，我们以批判性和建设性的视角探讨了流行数据集的各种维度（表 4）。

### 低资源环境

与通常的文本相关任务相比，可用的数据集规模相当小。它们还存在较大的词汇重叠问题 Amini et al. (2019)。这对算法提出了挑战，因为现在它们必须从一个实际很小的数据集中进行泛化。词汇问题解决领域的冷门性，无法简单地从像维基百科这样的通用来源中提取文本，是这些数据集规模小的主要原因之一。语言精确性是必需的，同时保持数学意义。因此，语言生成也是一个困难的任务。

### 注释成本

目前的数据集几乎没有注释成本，因为它们通常是从作业网站抓取的。也有一些例外，涉及到众包 Ling 等（2017）或除了方程之外的中间表示 Amini 等（2019）。

### 模板重叠

许多研究 Zhang 等（2020a）已经证明，流行数据集中的词题存在较高的词汇和数学重叠。尽管词汇重叠在原则上是可取的，如 Patel 等（2021）所示，但它往往限制了数据集的多样性，从而影响其实用性。因此，许多策略已被采纳以缓解这些问题。早期的尝试包括控制语言学和方程模板重叠（Koncel-Kedziorski 等（2016），Miao 等（2020））。后来的想法围绕着众包的控制设计和质量控制（Amini 等（2019））。

## 前路展望

在本节中，我们描述了解决词题算法的令人兴奋的研究前沿。

### 语义解析

正如 Zhang 等（2020a）正确指出的那样，解决词题的最接近自然语言任务是语义解析，而不是大多数深度学习模型所建模的翻译。将极长的文本片段映射到简短的方程句子的优点是可以在解码器端进行泛化，但同样也有将许多相关语义简化为单一方程模型的危险。例如，方程可能是通过应用一系列步骤推导出来的，而这些步骤在简单的翻译过程中可能会丢失。已经投入了大量的努力来添加这种细微差别。一种方法是智能地建模输入（例如，Liang 等（2021））。在这里，从基于 BERT 的模型中学习到复杂的嵌入，将词题文本作为训练数据。中间表示包括简单的谓词 Roy 和 Roth（2018），而其他则涉及程序化描述（Ling 等（2017），Amini 等（2019））。另一种方法是以图的形式包含语义信息，如（Huang 等（2018），Chiang 和 Chen（2019），Qin 等（2020），Li 等（2020）等）所示。

### 知识数据集设计

由于大多数数据集来源于网站，不可避免地会出现重复。投入精力建模以下内容可能有助于推进文字问题研究：（a）同一问题的不同版本，（b）不同的等效方程类型，（c）语言和数学的语义。Patel 等人（2021）探讨了朝这个方向迈出的第一步，提供了一个用于评估文字问题的挑战数据集，Kumar 等人（2021）则自动生成了对抗性示例。

#### 数据集增强

数据集设计的自然延伸是数据集增强。增强是当我们有小型且专注于单一领域的数据集时的自然选择。然后，领域专家可以自动化语言和数学增强。虽然数据集设计中的模板重叠是一个问题，但在对比设计中可以利用这种重叠，如 Sundaram 等人（2020）；Li 等人（2021b）。刘等人（2022）在此探索了逆操作和构建等效表达树用于增强的原则方法。

#### 少量学习

如果我们有大量未标注的文字问题，或者可以为少量文字问题提供复杂的标注（捕捉语义），那么少量学习是有用的。这样，少量学习可以从少量标注示例中泛化。

### 知识感知模型

我们建议，解答文字问题比语义解析更复杂。从直观的角度来看，我们通过示例和互动学习语言，但我们需要在数学方面进行明确的训练才能解决文字问题 Marshall（1996）。这表明我们需要将数学模型纳入我们的深度学习模型，以建立泛化能力和鲁棒性。如前所述，一种常见的方法是将领域知识作为图表纳入 Chiang 和 Chen（2019）；Wu 等人（2020）；Qin 等人（2020，2021）。

## 结论

在本文中，我们对现有的数学问题求解器进行了调查，重点关注深度学习模型。深度模型主要被建模为编码器-解码器模型，其中输入为文本，解码器输出为方程式。我们列举了这种范式的几种有趣的表现形式 - 即 Seq2Seq 模型，基于图的模型，基于 transformer 的模型，对比模型和师生模型。一般来说，基于图的模型往往能够捕捉到有益于语言和数学方面的复杂结构元素。然后，我们详细探讨了各种正在使用的数据集。随后，我们分析了建模单词问题解决的各种方法，以及流行数据集的特点。我们看到，非常重视数学建模并与语言方面联系在一起，会带来丰厚的回报。我们得出结论，SOTA 模型的脆弱性是由于：（a）建模决策，以及（b）数据集设计。这是一项综合调查，但作者承认可能有一些方法逃脱了他们的注意。我们还警告说，所提供的分析可能是主观和有意见的，并且可能与提出的观点存在合理的分歧。最后，我们提到了几个进一步探索的途径，比如使用语义丰富的模型，知情数据集设计和融入领域知识。

## 参考文献

+   Amini et al. (2019) Amini, A., Gabriel, S., Lin, S., Koncel-Kedziorski, R., Choi, Y., and Hajishirzi, H. (2019). MathQA: Towards interpretable math word problem solving with operation-based formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 2357–2367, Minneapolis, Minnesota. Association for Computational Linguistics.

+   Bobrow (1964) Bobrow, D. G. (1964). A question-answering system for high school algebra word problems. In Proceedings of the October 27-29, 1964, fall joint computer conference, part I, pages 591–614\. ACM.

+   Cao et al. (2021) Cao, Y., Hong, F., Li, H., and Luo, P. (2021). A bottom-up dag structure extraction model for math word problems. Proceedings of the AAAI Conference on Artificial Intelligence, 35(1):39–46.

+   Chen et al. (2021) Chen, J., Tang, J., Qin, J., Liang, X., Liu, L., Xing, E., and Lin, L. (2021). GeoQA: A geometric question answering benchmark towards multimodal numerical reasoning. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 513–523, Online. Association for Computational Linguistics.

+   Chiang and Chen (2019) Chiang, T.-R. 和 Chen, Y.-N. (2019). 语义对齐方程生成用于解决和推理数学文字问题。发表于 2019 年北美计算语言学协会人类语言技术会议：长篇和短篇论文集，第 1 卷，页码 2656–2668，美国明尼苏达州明尼阿波利斯。计算语言学协会。

+   Cho et al. (2014) Cho, K., van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., 和 Bengio, Y. (2014). 使用 RNN 编码器–解码器学习短语表示用于统计机器翻译。发表于 2014 年自然语言处理经验方法会议论文集（EMNLP），页码 1724–1734，卡塔尔多哈。计算语言学协会。

+   Cobbe et al. (2021) Cobbe, K., Kosaraju, V., Bavarian, M., Hilton, J., Nakano, R., Hesse, C., 和 Schulman, J. (2021). 培训验证器以解决数学文字问题。CoRR, abs/2110.14168。

+   Dellarosa (1986) Dellarosa, D. (1986). 儿童算术文字问题解决的计算机模拟。行为研究方法、工具和计算机, 18(2):147–154。

+   Devlin et al. (2018) Devlin, J., Chang, M., Lee, K., 和 Toutanova, K. (2018). BERT: 深度双向变换器的预训练用于语言理解。CoRR, abs/1810.04805。

+   Dries et al. (2017) Dries, A., Kimmig, A., Davis, J., Belle, V., 和 De Raedt, L. (2017). 解决自然语言中的概率问题。第二十六届国际人工智能联合会议论文集，页码 3981–3987。

+   Faldu et al. (2021) Faldu, K., Sheth, A. P., Kikani, P., Gaur, M., 和 Avasthi, A. (2021). 朝向可处理的数学推理：解决数学文字问题的挑战、策略和机遇。CoRR, abs/2111.05364。

+   Feng et al. (2021) Feng, W., Liu, B., Xu, D., Zheng, Q., 和 Xu, Y. (2021). GraphMR: 用于数学推理的图神经网络。发表于 2021 年自然语言处理经验方法会议论文集，页码 3395–3404，在线和多米尼加共和国蓬塔卡纳。计算语言学协会。

+   Fletcher (1985) Fletcher, C. R. (1985). 理解和解决算术文字问题：计算机模拟。行为研究方法、工具和计算机, 17(5):565–571。

+   Geirhos et al. (2020) Geirhos, R., Jacobsen, J.-H., Michaelis, C., Zemel, R., Brendel, W., Bethge, M., 和 Wichmann, F. A. (2020). 深度神经网络中的捷径学习。自然机器智能, 2(11):665–673。

+   Griffith and Kalita (2020) Griffith, K. 和 Kalita, J. (2020). 使用变换器和问题文本预处理解决算术文字问题。发表于第 17 届国际自然语言处理会议（ICON），页码 76–84，印度理工学院帕特纳，印度。印度自然语言处理协会（NLPAI）。

+   Hochreiter 和 Schmidhuber (1997) Hochreiter, S. 和 Schmidhuber, J. (1997). 长短期记忆。神经计算, 9(8):1735–1780。

+   Hong 等 (2021) Hong, Y., Li, Q., Ciao, D., Huang, S., 和 Zhu, S.-C. (2021). 通过修正进行学习：利用弱监督解决数学文字问题。发表于 AAAI 人工智能会议论文集，35(6):4959–4967。

+   Hosseini 等 (2014) Hosseini, M. J., Hajishirzi, H., Etzioni, O., 和 Kushman, N. (2014). 通过动词分类学习解决算术文字问题。发表于 2014 年自然语言处理经验方法会议论文集 (EMNLP)，页码 523–533。

+   Huang 等 (2017) Huang, D., Shi, S., Lin, C.-Y., 和 Yin, J. (2017). 学习细粒度表达以解决数学文字问题。发表于 2017 年自然语言处理经验方法会议论文集，页码 805–814。

+   Huang 等 (2016) Huang, D., Shi, S., Lin, C.-Y., Yin, J., 和 Ma, W.-Y. (2016). 计算机解决数学文字问题的效果如何？大规模数据集构建与评估。发表于第 54 届计算语言学协会年会 (卷 1：长篇论文)，页码 887–896，德国柏林。计算语言学协会。

+   Huang 等 (2018) Huang, D., Yao, J.-G., Lin, C.-Y., Zhou, Q., 和 Yin, J. (2018). 使用中间表示解决数学文字问题。发表于第 56 届计算语言学协会年会 (卷 1：长篇论文)，页码 419–428，澳大利亚墨尔本。计算语言学协会。

+   Kim 等 (2020) Kim, B., Ki, K. S., Lee, D., 和 Gweon, G. (2020). 指向表达：使用表达指针转换模型解决代数文字问题。发表于 2020 年自然语言处理经验方法会议论文集 (EMNLP)，页码 3768–3779，在线。计算语言学协会。

+   Koch 等 (2015) Koch, G., Zemel, R., 和 Salakhutdinov, R. (2015). 用于一次性图像识别的孪生神经网络。发表于 ICML 深度学习研讨会，第 2 卷。

+   Koncel-Kedziorski 等 (2015) Koncel-Kedziorski, R., Hajishirzi, H., Sabharwal, A., Etzioni, O., 和 Ang, S. D. (2015). 将代数文字问题解析为方程。计算语言学协会会刊, 3:585–597。

+   Koncel-Kedziorski 等 (2016) Koncel-Kedziorski, R., Roy, S., Amini, A., Kushman, N., 和 Hajishirzi, H. (2016). Mawps：一个数学文字问题库。发表于 2016 年北美计算语言学协会会议：人类语言技术论文集，页码 1152–1157。

+   Kumar 等 (2021) Kumar, V., Maheshwary, R., 和 Pudi, V. (2021). 用于评估数学文字问题求解器的对抗样本。发表于计算语言学协会：EMNLP 2021 会议论文集，页码 2705–2712，多米尼加共和国蓬塔卡纳。计算语言学协会。

+   Kushman 等（2014）Kushman, N., Artzi, Y., Zettlemoyer, L., 和 Barzilay, R.（2014）。学习自动解决代数文字问题。ACL (1), 页码 271–281。

+   Lan 等（2021）Lan, Y., Wang, L., Zhang, Q., Lan, Y., Dai, B. T., Wang, Y., Zhang, D., 和 Lim, E.-P.（2021）。Mwptoolkit：一种开源框架，用于基于深度学习的数学文字问题求解器。arXiv 预印本 arXiv:2109.00799。

+   Le 和 Mikolov（2014）Le, Q. 和 Mikolov, T.（2014）。句子和文档的分布式表示。在国际机器学习会议上，页码 1188–1196。

+   Le-Khac 等（2020）Le-Khac, P. H., Healy, G., 和 Smeaton, A. F.（2020）。对比表示学习：框架与综述。《IEEE Access》，8:193907–193934。

+   Li 等（2019）Li, J., Wang, L., Zhang, J., Wang, Y., Dai, B. T., 和 Zhang, D.（2019）。使用不同功能的多头注意力建模数学文字问题中的内部关系。在《第 57 届计算语言学协会年会论文集》，页码 6162–6167，意大利佛罗伦萨。计算语言学协会。

+   Li 等（2021a）Li, L., Lin, Y., Ren, S., Li, P., Zhou, J., 和 Sun, X.（2021a）。针对预训练语言模型的动态知识蒸馏。在《2021 年自然语言处理实证方法会议论文集》，页码 379–389，在线及多米尼加共和国蓬塔卡纳。计算语言学协会。

+   Li 等（2020）Li, S., Wu, L., Feng, S., Xu, F., Xu, F., 和 Zhong, S.（2020）。图到树神经网络，用于学习结构化的输入输出翻译及其在语义解析和数学文字问题中的应用。在《计算语言学协会发现：EMNLP 2020》，页码 2841–2852，在线。计算语言学协会。

+   Li 等（2021b）Li, Z., Zhang, W., Yan, C., Zhou, Q., Li, C., Liu, H., 和 Cao, Y.（2021b）。寻找模式，而不仅仅是记忆程序：对比学习用于解决数学文字问题。CoRR, abs/2110.08464。

+   Liang 等（2021）Liang, Z., Zhang, J., Shao, J., 和 Zhang, X.（2021）。MWP-BERT：数学文字问题的强基准。CoRR, abs/2107.13435。

+   Liang 和 Zhang（2021）Liang, Z. 和 Zhang, X.（2021）。在教师监督下解决数学文字问题。在 Zhou, Z.-H.（主编），《第三十届国际联合人工智能会议论文集》，IJCAI-21，页码 3522–3528。国际联合人工智能会议组织。主会议轨道。

+   Lin 等（2021）Lin, X., Huang, Z., Zhao, H., Chen, E., Liu, Q., Wang, H., 和 Wang, S.（2021）。Hms：一种具有依赖关系增强理解的分层求解器，用于数学文字问题。《AAAI 人工智能会议论文集》，35(5)：4232–4240。

+   Ling 等（2017）Ling, W., Yogatama, D., Dyer, C., 和 Blunsom, P.（2017）。通过理由生成进行程序归纳：学习解决和解释代数文字问题。arXiv 预印本 arXiv:1705.04146。

+   Liu et al. (2022) Liu, Q., Guan, W., Li, S., Cheng, F., Kawahara, D., and Kurohashi, S. (2022). Roda：基于反向操作的数据增强用于解决数学题。IEEE/ACM 语音、音频与语言处理交易，30:1–11。

+   Liu et al. (2019) Liu, Q., Guan, W., Li, S., 和 Kawahara, D. (2019). 树结构解码用于解决数学题。在 2019 年自然语言处理实证方法会议和第 9 届国际自然语言处理联合会议（EMNLP-IJCNLP）上，页码 2370–2379，中国香港。计算语言学协会。

+   Marshall (1996) Marshall, S. P. (1996). 问题解决中的图式。剑桥大学出版社。

+   Miao et al. (2020) Miao, S.-y., Liang, C.-C., and Su, K.-Y. (2020). 用于评估和开发英语数学题解答器的多样化语料库。在第 58 届计算语言学协会年会上，页码 975–984，在线。计算语言学协会。

+   Mikolov et al. (2013) Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., 和 Dean, J. (2013). 词语和短语的分布式表示及其组合性。在神经信息处理系统进展中，页码 3111–3119。

+   Mitra and Baral (2016) Mitra, A. 和 Baral, C. (2016). 学习使用公式解决简单算术问题。在第 54 届计算语言学协会年会（第 1 卷：长篇论文）上，页码 2144–2153，德国柏林。计算语言学协会。

+   Mukherjee and Garain (2008) Mukherjee, A. 和 Garain, U. (2008). 自动理解自然语言数学问题的方法综述。人工智能评论，29(2):93–122。

+   Patel et al. (2021) Patel, A., Bhattamishra, S., and Goyal, N. (2021). NLP 模型真的能解决简单的数学题吗？在 2021 年北美计算语言学协会会议：人类语言技术会议上，页码 2080–2094，在线。计算语言学协会。

+   Pennington et al. (2014) Pennington, J., Socher, R., and Manning, C. (2014). Glove：全球词向量表示。第 2014 年自然语言处理实证方法会议（EMNLP）论文集，页码 1532–1543。

+   Peters et al. (2018) Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L. (2018). 深层上下文化词表示。在 NAACL 会议论文集中。

+   Piękos et al. (2021) Piękos, P., Malinowski, M., and Michalewski, H. (2021). 通过预测推理顺序来测量和提高 BERT 的数学能力。在第 59 届计算语言学协会年会和第 11 届国际自然语言处理联合会议（第 2 卷：短篇论文）上，页码 383–394，在线。计算语言学协会。

+   Qin 等（2021）Qin, J., Liang, X., Hong, Y., Tang, J., 和 Lin, L. (2021). 具有辅助任务的神经符号求解器用于数学词问题。在第 59 届计算语言学协会年会和第 11 届国际自然语言处理联合会议（第 1 卷：长篇论文）论文集中，第 5870–5881 页，在线。计算语言学协会。

+   Qin 等（2020）Qin, J., Lin, L., Liang, X., Zhang, R., and Lin, L. (2020). 语义对齐的通用树结构求解器用于数学词问题。在 2020 年自然语言处理实证方法会议论文集中，第 3780–3789 页，在线。计算语言学协会。

+   Roy 和 Roth（2015）Roy, S. 和 Roth, D. (2015). 解决一般算术词问题。在 2015 年自然语言处理实证方法会议论文集中，第 1743–1752 页，葡萄牙里斯本。计算语言学协会。

+   Roy 和 Roth（2017）Roy, S. 和 Roth, D. (2017). 单位依赖图及其在算术词问题解决中的应用。在第 31 届 AAAI 人工智能会议论文集中，AAAI’17，第 3082–3088 页。AAAI 出版社。

+   Roy 和 Roth（2018）Roy, S. 和 Roth, D. (2018). 映射到声明性知识以解决词问题。《计算语言学协会会刊》，6:159–172。

+   Roy 等（2015）Roy, S., Vieira, T., 和 Roth, D. (2015). 处理自然语言中的数量推理。《计算语言学协会会刊》，3:1–13。

+   Seo 等（2015）Seo, M., Hajishirzi, H., Farhadi, A., Etzioni, O., 和 Malcolm, C. (2015). 解决几何问题：结合文本和图示解释。2015 年自然语言处理实证方法会议论文集，第 1466–1476 页。

+   Shen 等（2021）Shen, J., Yin, Y., Li, L., Shang, L., Jiang, X., Zhang, M., 和 Liu, Q. (2021). 生成与排序：一个用于数学词问题的多任务框架。在计算语言学协会：EMNLP 2021 论文集，第 2269–2279 页，多米尼加共和国蓬塔卡纳。计算语言学协会。

+   Shen 和 Jin（2020）Shen, Y. 和 Jin, C. (2020). 使用多编码器和多解码器解决数学词问题。在第 28 届国际计算语言学会议论文集中，第 2924–2934 页，西班牙巴塞罗那（在线）。国际计算语言学委员会。

+   Shi 等（2015）Shi, S., Wang, Y., Lin, C., Liu, X., and Rui, Y. (2015). 通过语义解析和推理自动解决数字词问题。2015 年自然语言处理实证方法会议论文集，EMNLP 2015，葡萄牙里斯本，2015 年 9 月 17-21 日，第 1132–1142 页。

+   Sundaram 和 Abraham（2019）Sundaram, S. S. 和 Abraham, S. S. (2019). 带有模式的年龄词问题的语义表示。《新一代计算》，37(4):429–452。

+   Sundaram 等（2020）Sundaram, S. S., P, D., 和 Abraham, S. S.（2020）。用于算术文字问题的分布式表示。第 34 届 AAAI 人工智能会议。

+   Suster 等（2021）Suster, S., Fivez, P., Totis, P., Kimmig, A., Davis, J., de Raedt, L., 和 Daelemans, W.（2021）。将概率文字问题映射到可执行表示。在 2021 年自然语言处理实证方法会议论文集，第 3627–3640 页，在线和多米尼加共和国蓬塔卡纳。计算语言学协会。

+   Sutskever 等（2014）Sutskever, I., Vinyals, O., 和 Le, Q. V.（2014）。使用神经网络进行序列到序列的学习。在第 27 届国际神经信息处理系统会议论文集 - 第 2 卷，NIPS’14，第 3104–3112 页，剑桥，马萨诸塞州，美国。麻省理工学院出版社。

+   Tsai 等（2021）Tsai, S.-h., Liang, C.-C., Wang, H.-M., 和 Su, K.-Y.（2021）。序列到通用树：知识指导的几何文字问题解决。在第 59 届计算语言学协会年会和第 11 届国际自然语言处理联合会议（第 2 卷：短篇论文）论文集，第 964–972 页，在线。计算语言学协会。

+   Upadhyay 和 Chang（2017）Upadhyay, S. 和 Chang, M.-W.（2017）。注释推导：一种用于代数文字问题的新评价策略和数据集。在第 15 届计算语言学协会欧洲分会会议论文集：第 1 卷，长篇论文，第 494–504 页，西班牙瓦伦西亚。计算语言学协会。

+   Vaswani 等（2017）Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L. u., 和 Polosukhin, I.（2017）。注意力机制就是你所需的一切。在 Guyon, I., Luxburg, U. V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan, S., 和 Garnett, R.（编辑），《神经信息处理系统进展》，第 30 卷。Curran Associates, Inc.

+   Wang 等（2018）Wang, L., Zhang, D., Gao, L., Song, J., Guo, L., 和 Shen, H. T.（2018）。Mathdqn：通过深度强化学习解决算术文字问题。AAAI 人工智能会议论文集，第 32 卷第 1 期。

+   Wang 等（2017）Wang, Y., Liu, X., 和 Shi, S.（2017）。用于数学文字问题的深度神经解算器。在 2017 年自然语言处理实证方法会议论文集，第 845–854 页。

+   Wolfram（2015）Wolfram, S.（2015）。Wolfram|alpha。在 WWW 上。网址 http://www.wolframalpha.com。

+   Wu 等（2020）Wu, Q., Zhang, Q., Fu, J., 和 Huang, X.（2020）。用于数学文字问题解决的知识感知序列到树网络。在 2020 年自然语言处理实证方法会议（EMNLP）论文集，第 7137–7146 页，在线。计算语言学协会。

+   Wu 等（2021a）Wu, Q., Zhang, Q., 和 Wei, Z. (2021a). 一种边增强的层次图到树网络用于数学应用题求解。在计算语言学协会的发现：EMNLP 2021 会议论文集中，第 1473–1482 页，多米尼加共和国蓬塔卡纳。计算语言学协会。

+   Wu 等（2021b）Wu, Q., Zhang, Q., Wei, Z., 和 Huang, X. (2021b). 具有显式数值的数学应用题求解。在第 59 届计算语言学协会年会上及第 11 届国际自然语言处理联合会议（第 1 卷：长篇论文）论文集中，第 5859–5869 页，在线。计算语言学协会。

+   Wu 等（2021c）Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., 和 Yu, P. S. (2021c). 图神经网络的综合调查。IEEE 神经网络与学习系统汇刊，32(1)：4–24。

+   Xia 等（2019）Xia, M., Huang, G., Liu, L., 和 Shi, S. (2019). 基于图的翻译记忆用于神经机器翻译。在 AAAI 人工智能会议论文集中，第 33 卷，第 7297–7304 页。

+   Xie 和 Sun（2019）Xie, Z. 和 Sun, S. (2019). 一种目标驱动的树结构神经模型用于数学应用题。在第二十八届国际人工智能联合会议论文集中，IJCAI-19，第 5299–5305 页。国际人工智能联合会议组织。

+   Yu 等（2021）Yu, W., Wen, Y., Zheng, F., 和 Xiao, N. (2021). 通过预训练知识和层次推理改进数学应用题。在 2021 年自然语言处理经验方法会议论文集中，第 3384–3394 页，在线和多米尼加共和国蓬塔卡纳。计算语言学协会。

+   Zaporojets 等（2021）Zaporojets, K., Bekoulis, G., Deleu, J., Demeester, T., 和 Develder, C. (2021). 通过递归神经网络评分方程来解决算术应用题。专家系统与应用，174：114704。

+   Zhang 等（2020a）Zhang, D., Wang, L., Zhang, L., Dai, B. T., 和 Shen, H. T. (2020a). 语义解析的差距：关于自动数学应用题求解器的调查。IEEE 模式分析与机器智能汇刊，42(9)：2287–2305。

+   Zhang 等（2020b）Zhang, J., Lee, R. K.-W., Lim, E.-P., Qin, W., Wang, L., Shao, J., 和 Sun, Q. (2020b). 带有多个解码器的师生网络用于解决数学应用题。在 Bessiere, C.（编辑），第二十九届国际人工智能联合会议论文集中，IJCAI-20，第 4011–4017 页。国际人工智能联合会议组织。主要分会。

+   Zhang 等（2020c）Zhang, J., Wang, L., Lee, R. K.-W., Bin, Y., Wang, Y., Shao, J., 和 Lim, E.-P.（2020c）。图到树学习用于解决数学文字问题。在《第 58 届计算语言学协会年会论文集》中，页码 3928–3937，在线。计算语言学协会。

+   Zhou 等（2015）Zhou, L., Dai, S., 和 Chen, L.（2015）。利用二次规划解决代数文字问题。在《2015 年自然语言处理经验方法会议论文集》中，页码 817–822，葡萄牙里斯本。计算语言学协会。
