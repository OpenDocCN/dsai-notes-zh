<!--yml

分类：未分类

日期：2024-09-06 19:51:33

-->

# [2109.08853] 关于乳腺癌诊断的深度学习方法的综述

> 来源：[`ar5iv.labs.arxiv.org/html/2109.08853`](https://ar5iv.labs.arxiv.org/html/2109.08853)

# 关于乳腺癌诊断的深度学习方法的综述

Timothy Kwong¹ 和 Samaneh Mazaheri²

¹工程与应用科学学院，

加拿大安大略理工大学，安大略省奥沙瓦

²商业与信息技术学院，

加拿大安大略理工大学，安大略省奥沙瓦

timothy.kwong@ontariotechu.net, Samaneh.Mazaheri@ontariotechu.ca

###### 摘要

深度学习引入了几种基于学习的方法来识别乳腺肿瘤，并在乳腺癌诊断中展现出高度的适用性。它已经作为一种实用的计算机辅助诊断（CAD）系统的组成部分，进一步帮助放射科医师在不同的影像模式下进行诊断。基于医院或公共数据库提供的图像训练的深度学习网络可以进行分类、检测和病变类型的分割。虽然在 2D 图像肿瘤识别方面已经取得了显著进展，但 3D 图像识别仍然是一个前沿领域。不同研究领域之间深度学习网络的互联有助于推动更高效、准确和稳健网络的发现。在这篇综述文章中，将探讨以下主题：（i）深度学习的理论与应用，（ii）从性能指标角度看 2D、2.5D 和 3D 卷积神经网络在乳腺肿瘤识别中的进展，以及（iii）卷积神经网络方法面临的挑战。

###### 关键词：

乳腺 X 线摄影、数字乳腺断层合成、自动乳腺超声、MRI、2D 卷积神经网络、3D 卷积神经网络、分类、检测、分割

## I 引言

在 2020 年，女性乳腺癌的新发病例达到 226 万例，使乳腺癌成为 36 种癌症中新发病例最多的 [1]。此外，由于女性乳腺癌导致的新死亡人数为 68.4 万，排名 35 种其他癌症中第四高 [1]。目前的乳腺癌筛查方法包括乳腺 X 线摄影、数字乳腺层析成像、乳腺超声和磁共振成像 [2]。乳腺 X 线摄影有两种类型，即屏幕胶卷乳腺 X 线摄影和数字乳腺 X 线摄影（DM），这两种类型都是 X 射线成像形式，利用辐射获得乳腺组织的二维图像 [2, 3]。此外，乳腺 X 线摄影有助于早期发现乳腺癌，降低癌症死亡的风险 [2, 4]。图像获取技术的进步带来了数字乳腺层析成像（DBT）。DBT 解决了乳腺 X 线摄影中的问题，并提供了改进的图像获取 [5, 3, 6, 7]。它捕获乳腺的多个二维图像切片，然后将这些图像合成成三维图像 [2, 6, 5]。然而，这些三维图像（体积）是准三维的，因为它们是多张捕获的二维图像的重建 [6, 7]。此外，图像切片是使用一个 X 射线管捕获的，该 X 射线管沿 15^∘到 60^∘的弧线绕胸壁旋转 [5]。自动乳腺超声（ABUS）使用高频率对整个乳腺进行成像。这些二维图像是在横截面上获得的，并合成成三维体积 [8]。磁共振成像（MRI）使用高功率磁铁和计算机生成的无线电波对乳腺进行成像 [2]。计算机辅助诊断（CAD）系统通过提供“第二意见”来帮助放射科医师做出更有信心的诊断决策 [9, 10, 11]。此外，如[12]所述，CAD 系统应改善放射科医师的表现，节省时间，与工作流程无缝集成，并不增加责任。将深度学习算法集成到 CAD 系统中，旨在解决上述目标，并减少不同放射科医师的评估变异性 [13, 14]，降低复查率，提高癌症检测率。深度学习的持续进步带来了在医学图像中分类和定位癌症肿瘤方面优于放射科医师的模型 [15, 16]。随着算法的进步、计算能力的普及和广泛的精心策划的数据集的开源，机器学习技术能够向最先进的技术转变，并在医疗保健领域的任务中提供帮助 [17]。深度学习作为机器学习的一个子领域，将表示以更简单的形式传达，以解决学习不同表示的问题 [18]。此外，深度学习使用多个互联的人工神经元层来学习实际表示的简单表达形式的模式 [19, 18]。2012 年，一个卷积神经网络架构的错误率为 15.3%，比第二名低 10.9% [20]。这一突破导致了对深度学习领域的研究参与增加，以及继续研究和使用 CNN 架构解决图像识别问题 [21]。卷积神经网络（CNN）是专门处理具有已知网格模式的数据的网络，并学习数据中空间特征的层次结构 [18, 22]。因此，考虑到 CNN 可以学习特征，癌症肿瘤的手工特征不再是 CNN 所必需的。深度学习在医疗领域的适用性体现在对医疗图像中癌症肿瘤的分类、定位和分割，这些图像来自 MRI、CT、超声等模态。这篇综述文章将深入探讨深度学习理论、2D、2.5D 和 3D CNN 架构的发展，以及训练网络时遇到的挑战。

## II 深度学习理论

本节提供了深度学习概念的理论概述，包括数据增强、典型 CNN 架构中的构建块、过拟合和迁移学习。

### II-A 数据增强

数据增强是一种旨在增加数据集大小并提高模型性能和鲁棒性的技术[23, 24, 25]。数据增强方法，如平移、旋转、反射、模糊和裁剪，直接应用于原始图像以生成新的增强图像。数据增强的一个实例是对每个列出的方法应用于原始图像，从而生成 5 个新的增强图像，这样可以通过新的未见训练实例来增加数据集的大小。图像的缩放和灰度化是数据预处理过程中使用的其他策略，以减少处理这些图像所需的计算复杂性。

|  | $s(t)=(x\ast w)(t)=\sum_{a=-\infty}^{\infty}x(a)w(t-a)$ |  | (1) |
| --- | --- | --- | --- |

![参见说明](img/cb48fc9253e1673e739bef050bbd012a.png)

图 1：基本的卷积神经网络（CNN）从输入中提取特征并输出特征向量。这个 CNN 包含两个层，卷积层和池化层。在卷积层中，整个输入被一个卷积核进行卷积，而在池化层中，输入被下采样。最终输出是一个包含输入重要特征的扁平列向量。改编自[26]。

### II-B 2D 卷积层

卷积神经网络使用一种叫做卷积的数学运算；卷积是一种线性操作，在这种情况下用于特征提取 [18, 22]。离散卷积表示为公式 (1)，如 [18, 公式 (9.1)] 中所示，其中 s(t) 表示特征图，x(a) 表示输入，w(t-a) 表示卷积核。此外，公式 (1) 说明了输入与卷积核之间的逐元素乘积以生成特征图 [22, 27]。2D 卷积核是一个权重矩阵，用于从输入中提取有意义的特征，以便网络学习和识别不同的输入。通过将卷积核与输入进行卷积，然后在卷积输出上应用激活函数，可以生成特征图 [23]。此外，反向传播用于更新卷积核权重，以最小化损失函数 [22]。步幅，如 [22] 所定义，是“两个连续卷积核位置之间的距离”，决定了卷积核在输入上的步长。填充是一种技术，用于在卷积后保持特征图的平面维度，从而允许更多的卷积层 [22, 27]。零填充通过在输入边界对齐零来保持维度 [28]。参数共享是卷积神经网络中一种通过共享卷积核权重来限制参数数量的机制，这最终减少了模型的复杂性 [22, 23, 28]。此外，参数可以在不同图像中出现的更抽象特征之间共享 [28, 29]。图 1 说明了卷积和池化层对输入进行特征提取以输出特征图。

### II-C 3D 卷积层

在 3D CNN 中，卷积核、步幅和池化操作都是三维的，其中第三维度表示深度维度 [30]。这个额外的维度使得 3D CNN 能够从额外的信息轴中提取特征。在 3D 卷积层中，体素表示空间信息，而不是像素。

![参见说明](img/a6171bd3a26e3a1fd02fd96235bcd3b0.png)

图 2：修正线性单元（ReLU）函数。改编自 [31]。

### II-D 激活层

修正线性单元（ReLU）是一种常用于神经网络的激活函数 [22, 32, 33, 34]。ReLU 函数如下面所示：

|  | <math   alttext="f(x)=max(0,x)=\begin{cases}x,&amp;x\geq 0\\ 0,&amp;x<0\\

\end{cases}" display="block"><semantics ><mrow ><mrow  ><mi >f</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo stretchy="false"  >(</mo><mi >x</mi><mo stretchy="false" >)</mo></mrow></mrow><mo  >=</mo><mrow ><mi  >m</mi><mo lspace="0em" rspace="0em"  >​</mo><mi >a</mi><mo lspace="0em" rspace="0em" >​</mo><mi >x</mi><mo lspace="0em" rspace="0em" >​</mo><mrow  ><mo stretchy="false"  >(</mo><mn >0</mn><mo >,</mo><mi  >x</mi><mo stretchy="false"  >)</mo></mrow></mrow><mo >=</mo><mrow  ><mo >{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"  ><mtr ><mtd columnalign="left"  ><mrow ><mi  >x</mi><mo >,</mo></mrow></mtd><mtd columnalign="left"  ><mrow ><mi >x</mi><mo  >≥</mo><mn >0</mn></mrow></mtd></mtr><mtr ><mtd columnalign="left"  ><mrow ><mn  >0</mn><mo >,</mo></mrow></mtd><mtd columnalign="left"  ><mrow ><mi >x</mi><mo  ><</mo><mn >0</mn></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" ><apply  ><apply ><apply  ><ci >𝑓</ci><ci >𝑥</ci></apply><apply  ><ci >𝑚</ci><ci >𝑎</ci><ci  >𝑥</ci><interval closure="open"  ><cn type="integer" >0</cn><ci  >𝑥</ci></interval></apply></apply><apply ><apply ><csymbol cd="latexml"  >cases</csymbol><ci >𝑥</ci><apply ><ci  >𝑥</ci><cn type="integer"  >0</cn></apply><cn type="integer"  >0</cn><apply ><ci >𝑥</ci><cn type="integer" >0</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" >f(x)=max(0,x)=\begin{cases}x,&x\geq 0\\ 0,&x<0\\ \end{cases}</annotation></semantics></math> |  | (2) |

并且可以在 [34, 等式 (1.14)] 中看到，将小于零的值归零，将大于或等于零的值保持不变。ReLU 函数的图示见图 2。

![参见说明文字](img/6ec99838f30d83388998c7a3e8003524.png)

图 3：全连接神经网络（FCNN）。改编自 [26]。

### II-E 池化层

池化是一种下采样特征图的技术 [22]，引入不变性 [18]，并合并语义上相似的特征 [18]。下采样特征图减少了平面内的维度 [22, 35]，从而在不减少特征图中用于学习的关键特征的情况下减少了数据大小。最大池化是一种池化操作，在方形区域内获取最大值 [18, 22, 35]。此外，通过获取最大值，这也使表示对小的平移或扭曲具有不变性 [18, 22]。

![参考说明](img/a48dd7396b3d2efdfd1b4c03cd52b894.png)

图 4：这个三维图的表面表示目标函数。梯度下降用于在此图上向最深点移动。最深点表示全局最小值，以及使目标函数最小化的参数。来源：改编自 [31]。

### II-F 完全连接层

完全连接（FC）层学习一个非线性函数，以映射特征空间中的所有特征。图 3 展示了完全连接神经网络（FCNN）的基本结构。CNN 可以包含 FC 层，其中从 CNN 中提取的特征输入到 FC 层以进行决策输出 [36]。在训练过程中，目标是最小化 CNN 的预测误差，使用反向传播和梯度下降等技术来改善预测结果。目标函数，也称为损失函数或代价函数，确定预测与真实值之间的差异；它衡量网络在预测中的误差。二元交叉熵是用于二分类的损失函数。反向传播是一种用于确定相对于权重的目标函数梯度的技术 [32]。相对于权重的目标函数反向传播的方程可以使用链式法则计算，公式如下：

|  | $\frac{\partial{L}}{\partial{w}}=\frac{\partial{z}}{\partial{w}}\frac{\partial{a}}{\partial{z}}\frac{\partial{L}}{\partial{w}}$ |  | (3) |
| --- | --- | --- | --- |

梯度下降用于通过对参数（如权重、偏置和核）的迭代更新，在目标函数的梯度负方向上最小化目标函数 [22, 37]。相关方程为：

|  | $w:=w-\alpha\frac{\partial{L}}{\partial{w}}$ |  | (4) |
| --- | --- | --- | --- |

其中，w 代表权重，$\alpha$ 代表学习率，以及目标函数相对于权重的偏导数。图 4 说明了目标函数的三维表面，其中最暗的点代表目标函数的全局最小值。

![参见说明](img/ed0f502fe3fa6ef1f61bd867eb07adfd.png)

图 5：过拟合训练数据的模型在训练和验证损失上出现了偏离。改编自 [31]。

### II-G 过拟合

无法对新数据进行泛化的模型已经过拟合了训练数据，如图 5 所示。过拟合可以通过早停、网络剪枝、增加训练数据和正则化来解决[38, 39]。早停是在训练和验证损失曲线既不出现过拟合也不出现欠拟合的点停止学习[38, 39]。网络剪枝涉及剪除冗余的权重，同时保留重要的权重[40]。需要增加训练数据以调整网络中的参数，使网络能够更好地泛化到新数据。通过收集和/或数据增强可以增加训练数据。正则化旨在去除无用特征并最小化模型学习到的较不重要特征的权重[38]。然而，由于网络所需特征的不确定性，会在目标函数中加入一个惩罚项以最小化特征数量[38]。此外，还有不同类型的正则化方法，如 L1 正则化、L2 正则化（权重衰减）和 Dropout [38]。Dropout 由 Srivastava 等人提出 [41]，是一种减少过拟合的有效策略。

### II-H 迁移学习

迁移学习是一种通过将知识从相似领域转移到一个特定领域来提高学习者专业性的技术[42, 43]。此外，它也可以解决训练数据不足的问题[42, 43, 44]。由于数据收集和整理的困难，适合有效训练学习者的高质量训练数据可能非常昂贵[43]。因此，提出了如同质迁移学习和异质迁移学习等解决方案[42]。

## III 性能指标

混淆矩阵可以用来展示分类器的不同预测结果 [45, 46]。混淆矩阵可以可视化为一个 2x2 的矩阵，其中包含真正例（TP）、真负例（TN）、假正例（FP）和假负例（FN） [46, 47]。真正例是被正确预测为正类的正样本，而假正例是被错误预测为正类的负样本 [45, 46]。真负例是被正确预测为负类的负样本，而假负例是被错误预测为负类的正样本 [45, 46]。

以下公式将用于评估表格 I、II ‣ IV Discussion ‣ A survey on deep learning approaches for breast cancer diagnosis") 和 III 中展示的深度学习模型。准确度是正确分类样本与总样本的比率 [46, 47]。准确度的公式由 [48, equ. (2)] 给出：

|  | $Accuracy=\frac{TP+TN}{TP+TN+FP+FN}$ |  | (5) |
| --- | --- | --- | --- |

敏感度，也称为召回率和真正例率，是检索到的相关（实际真正例）实例的比例 [46]。敏感度的计算公式由 [48, equ. (5)] 给出：

|  | $Sensitivity=\frac{TP}{TP+FN}$ |  | (6) |
| --- | --- | --- | --- |

特异性，也称为真负率，是检索到的相关（实际真负例）实例的比例。特异性的公式由 [48, equ. (6)] 给出：

|  | $Specificity=\frac{\text{TN}}{TN+FP}$ |  | (7) |
| --- | --- | --- | --- |

精确度是检索到的实例中相关（实际真正例）的比例 [46, 47]。精确度的公式由 [48, equ. (4)] 给出：

|  | $Precision=\frac{TP}{TP+FP}$ |  | (8) |
| --- | --- | --- | --- |

F 分数是一个加权比率，用于测量精确度和召回率的平均值 [46]，F 分数的公式由 [47, equ. (4)] 给出：

|  | $F_{1}=2\>\frac{precision\>\cdot\>recall}{precision+recall}$ |  | (9) |
| --- | --- | --- | --- |

Dice 相似系数（DSC）是一个空间重叠指标 [49]，可以用来测量模型的分割性能。DSC 由 [50, equ. (2)] 给出：

|  | $DSC=\frac{2\cdot TP}{2\cdot TP+FP+FN}$ |  | (10) |
| --- | --- | --- | --- |

Matthews 相关系数（MCC）计算实际值与预测值之间的皮尔逊积矩相关系数 [47]。MCC 由 [47, equ. (2)] 给出：

|  | $MCC=\frac{TP\cdot TN-FP\cdot FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$ |  | (11) |
| --- | --- | --- | --- |

表格 I: 乳腺癌诊断的 2D CNN 架构

参考文献 模型 任务 数据集 AUROC (%) MCC (%) Dice (%) DM Dhungel et al. (2017) [51] CNN + RF + 假设-细化 分类 检测 分割 INbreast $0.76\pm 0.23$ (通过 RF，最小用户交互) $0.69\pm 0.10$ (通过 CNN，最小用户交互) — $0.85\pm 0.02$ Al-antari et al. (2018) [52] YOLO + FrCN + CNN 分类 检测 分割 INbreast 0.9478 (通过 CNN) 0.9762 (通过 YOLO) 0.8593 (通过 FrCN) 0.8991 (通过 CNN) 0.9269 (通过 FrCN) Chougrad et al. (2018) [53] Inception v3 分类 检测 DDSM INbreast BCDR 0.99 (通过 MIAS) — — Ribli et al. (2018) [54] Faster-RCNN 分类 检测 DDSM Semmelweis University 0.95 (通过 INbreast) — — Singh et al. (2020) [55] cGAN 分类 分割 DDSM INbreast Hospital Sant Joan de Reus 0.80 — 0.94

## IV 讨论

本节探讨了用于乳腺肿瘤分类、检测和分割的不同深度学习架构，所有这些都展示在表格 I、II ‣ IV Discussion ‣ A survey on deep learning approaches for breast cancer diagnosis") 和 III 中。

### IV-A 数字乳腺断层扫描（DBT）的现状

与数字乳腺摄影相比，DBT 因其更高的图像质量、更丰富的结构细节以及更好的背景信号噪声减少而逐渐受到欢迎 [56]。此外，近期研究 [57, 6, 58, 59, 60] 表明，DBT 在 40 至 79 岁有密集和非密集乳房的女性中的癌症检测率有所提高，但对减少召回率的结果仍存在争议。此外，[6, 58, 59, 60] 还显示，DBT 减少了 40 至 79 岁有密集和非密集乳房女性的召回率，但 [61, 62] 表明 DBT 加 DM 的召回率与 DM 单独使用的召回率相似。DBT 减少了在 2D 图像上出现的重叠乳腺组织，而不是乳腺 X 光检查 [63, 6, 3]。因此，DBT 图像有助于检测可能被其他健康乳腺组织重叠的肿瘤。然而，DBT 的一个缺点是对恶性钙化和微钙化群体的成像敏感性低于 DM [64, 56]。此外，使用像素汇聚的 DBT 系统提高了探测器读数的效率，但反过来降低了三维空间分辨率 [7]。

### IV-B 自动乳腺超声（ABUS）的状态

ABUS 包括一个超声扫描仪和一个传感器 [65, 66]。ABUS 捕捉乳房的不同视角的轴向切片，然后这些轴向切片用于矢状面和冠状面图像的三维重建 [65, 66]。

### IV-C 磁共振成像（MRI）的状态

磁共振成像（MRI）筛查推荐给那些由于遗传或家族史而有乳腺癌高风险的患者 [67, 2]。乳腺线圈与 MRI 一起使用，以获取乳房图像；患者俯卧在乳腺线圈中，然后进入 MRI [68]。乳腺 MRI 有不同类型，如 T1 加权对比增强成像、T2 加权成像、超快速成像和扩散加权成像 [68]。获取的图像的维度取决于 MRI 类型 [69]。在 2D 图像获取中，捕获对象的多个 2D 图像切片，而在 3D 图像获取中，可以捕获真实的 3D 图像 [69, 70]。

表 II：用于乳腺癌诊断的 2.5D CNN 架构

参考文献 模型 任务 数据集 AUROC (%) Dice (%) DM-DBT Yousefi 等人（2018） [71] DCNN MI-RF 基于 CAD 分类 麻省总医院（内部）：87 张 DBT 图像（27 张恶性，60 张良性） 0.87 — Kim 等人（2017） [72] VGG16 + LSTM 分类（内部） 0.919 — Liu 等人（2017） [73] 3D 各向异性混合网络（3D AH-Net） 分割（内部）：2809 个 DBT 卷 — 0.834 Zhang 等人（2020） [74] AlexNet（后融合 + 最大池化） 分类（内部）：3018 个负样本 272 个恶性 415 个良性 0.854 — Liang 等人（2020） [75] CNN 集成 分类 肯塔基大学医学中心（内部）：DBT 和 DM（709 个恶性，415 个良性） 0.97 —

### IV-D 目前使用的 2D CNN 架构

对于 2D 分类，Chougrad 等人 [53] 采用了包括 ResNet50 [76]、VGG16 [77] 和 Inception v3 [78] 在内的最先进架构，这些架构在 ImageNet 上进行了预训练，并重新用于乳腺癌筛查。Chougrad 等人 [53] 使用预训练并微调的 Inception v3 模型在 MIAS 数据库上达到了 0.99 的分类 AUC。研究结论表明，微调策略提高了最先进架构的分类准确率，而 Inception v3 的准确率高于 VGG16 和 ResNet50。

对于 2D 分割，Singh 等人 [55] 在 Isola 等人 [79] 的研究基础上，提出了一种条件生成对抗网络（cGAN）CAD 框架，用于乳腺肿瘤的分类和分割。Singh 等人 [55] 在 cGAN 上达到了 92.11% 的 Dice 系数分数和 84.55% 的 IoU，用于肿瘤感兴趣区域（ROI）的紧密框架。此外，研究测试了 Single Shot Detector (SSD)、You Only Look Once (YOLO) 和 Faster-RCNN，并发现 SSD 在检测小肿瘤区域时表现最佳，总体准确率达到了 97%。该研究的主要贡献包括首次适应 cGAN 用于乳腺肿瘤分割，提出了一种多类别 CNN 用于预测四种乳腺肿瘤形状，并且提出的模型优于最先进的架构。

表 III：乳腺癌诊断的 3D CNN 架构

参考模型 数据集 准确率（%） AUROC（%） AP（%） FNR（%） Dice（%） Fscore（%） DBT Zhang et al. (2018)[80] 3D-T2-Alex 肯塔基大学（内部） — 0.6632 — — — — Fan et al. (2020)[81] 3D Mask-RCNN 复旦大学附属肿瘤中心（内部）：364 DBT 样本（289 例恶性，75 例良性） — 0.934 0.053 — — — Wichakam et al. (2018)[82] 3D ConvNet（内部）：115 DBT 体积（91 例恶性，24 例正常） 0.72 — — — — 0.842 ABUS Lei et al. (2021)[83] Mask scoring RCNN（私人） — — — $0.85\pm 0.104$ — — Zhou et al. (2021)[84] $\mathrm{C_{MS}}\mathrm{VNet_{Iter}}$ 北京大学人民医院（内部）：900 ABUS 体积 — 0.787 — 0.392 $0.778\pm 0.145$ 0.811 MRI Zhou et al. (2019)[85] 3D DenseNet（内部）：720 例恶性，353 例良性 — 0.859 — — $0.501\pm 0.274$ — Hu et al. (2020)[86] VGG19Net（内部）：728 例恶性，199 例良性 — DEC: 0.85 T2w: 0.78 ImageFusion: 0.85 FeatureFusion: 0.87 ClassifierFusion: 0.86 — — — —

### IV-E 2.5D CNN 概述

为了利用 DBT 信息的全部内容，需要利用深度维度和 DBT 体积内的图像集合 [72, 74, 87]。此外，2D CNN 无法保留 DBT 体积中的切片间信息 [88, 89, 44, 73]。而且，相对于 ImageNet [72, 74, 90]，高复杂度、潜在的过拟合以及较小的 DBT 数据集可能使得训练 3D CNN 相当不可行，这使得 [72, 73, 75] 的方法更具优势。在接下来的部分，将讨论利用 DBT 图像内全部信息的 2D 和 3D CNN 方法的替代方案。

### IV-F 当前使用 2.5D CNN 架构的方法

Kim et al. [72] 提出了用于空间特征表示和深度方向长期递归学习的 CNN。VGG16 网络被用作 CNN，而 LSTM 被用于深度方向长期递归学习。该模型达到了 91.9% 的 AUROC。然而，LSTM 网络可能很难 [73] 并且训练成本高 [90]。

因此，刘等人提出了另一种学习 3D DBT 体积的方法。他们提出了 3D 各向异性混合网络（3D AH-Net）。3D AH-Net 实现了 83.4%的全局骰子得分。正如刘等人所提到的，直接用 DBT 或 CT 扫描训练 3D CNN 面临的挑战包括（1）各向异性体素，（2）相比于 2D CNN 所需更多的特征，以及（3）缺乏预训练的 3D CNN 模型和有限的训练数据。各向异性体素数据分布不均，这会阻碍 3D CNN 的训练，例如 CT 和 DBT 体积在切片内的分辨率大于切片之间的分辨率。DBT 图像中的各向异性体素挑战通过各向异性卷积得到处理。3D AH-Net 具有特征编码器和解码器。编码器从 2D 图像切片中提取深层表示。而解码器，作为一个密集连接的各向异性卷积网络，利用 3D 上下文，同时保持切片间的一致性。AH-ResNet，一个将 2D ResNet50 转换为 3D ResNet50 的网络，被用作 3D AH-Net 的骨干网和编码器。一个 2D 多通道全局卷积网络（MC-GCN）用于训练 3D AH-NET 中使用的编码器参数。训练好的 MC-GCN 参数被提取并转移到 AH-ResNet 中。3D AH-Net 的结构顺序为 AH-ResNet、解码器，然后是金字塔体积池化。

梁等人提到的一个关键挑战是**有效利用 DBT 数据**，因为 DBT 数据具有高分辨率且深度各异。用 DBT 数据训练 3D CNN 模型在计算和内存上都非常耗费资源。因此，梁等人提出了一种包含两种 CNN 的网络：CNN 特征提取器和 CNN 分类器。该模型实现了 97%的 AUROC。网络序列从 2D CNN 特征提取器开始，过渡到由三种 CNN 分类器组成的集成体。用于 DM、DBT 和 DM-DBT 特征图分类的分类器，其中 DM-DBT 特征图是 DM 和 DBT 特征图的拼接。

### IV-G 3D CNN 概述

与 2D CNN 相比，2D CNN 无法保留 DBT 体积中的切片之间信息 [88, 89, 44, 73]。3D CNN 能够学习 2D 图像中的空间信息以及多个切片之间的信息。3D 卷积核使这一特性成为可能，但也产生了比 2D 卷积核更多的训练参数。因此，每个卷积核能够提取的特征复杂性增加。当使用各向同性的 3D 卷积核学习各向异性 DBT 体积时，由于每个各向异性体素沿每个平面的分辨率变化，会出现挑战 [73, 88]。此外，DBT 图像的空间分辨率质量可能会影响 2D 和 3D CNN 的训练 [7, 88, 73]。训练 3D CNN 的另一个挑战是缺乏良好策划的公开 DBT 数据集。Buda 等人 [91] 通过策划和发布一个包含 22,032 个重建 DBT 体积的公开数据集来解决了这个问题。

### IV-H 当前使用 3D CNN 架构的方法

Fan 等人 [81] 展示了 3D 深度学习方法相对于 2D 方法的优越性，例如 Yousefi 等人 [71]，在学习对 DBT 图像切片中的肿瘤进行分类、检测和分割方面。Fan 等人 [81] 提出了一个以 ResNet50 为骨干网的 3D-Mask-RCNN。该 3D-Mask-RCNN 在乳腺基质检测中实现了 90% 的灵敏度，在 0.83 FPs/乳腺的条件下，并且在病变分割中达到了 93.4% 的 AP 和 5.3% 的 FNR。研究结论表明，所提出的模型 3D-Mask-RCNN 优于 2D 对应模型 Mask-RCNN 和 Faster-RCNN。

## V 挑战

本节讨论了在乳腺肿瘤诊断中的深度学习所面临的挑战。

### V-A 小数据集

小数据集对深度学习模型的训练构成挑战 [91, 92, 93]，因为需要使模型熟悉所有可能的情况，以最小化分类错误。此外，缺乏标准化数据集使得比较和重现研究变得困难 [94]。深度学习模型的训练数据集应提供正常乳腺 X 光片、各种 BI-RADS 1-6 的乳腺 X 光片、肿块类型、钙化、不对称、结构畸变案例以及一张乳腺 X 光片中的多个案例 [95]。虽然已使用数据增强、批量归一化和迁移学习等技术来应对有限数据集大小的问题，但大型且精心策划的数据集仍然是训练良好模型的高度需求 [21, 96, 97]。Yousefi 等人 [71] 使用数据增强技术将样本数量从 5,040 增加到 40,320 2D 切片。

### V-B 类别不平衡

类别不平衡是深度学习中的另一个挑战，它发生在类别的训练数据比例不同的情况下[98, 48, 99, 100, 46]。类别不平衡可能导致分类器产生偏差，从而使预测偏向于正类或负类，这取决于类别之间的数据大小比例[96]。此外，用于衡量模型性能的指标，如准确率[47]，也容易受到类别不平衡的影响，从而影响模型的表现。然而，有技术可以在数据层面和分类器层面处理类别不平衡。数据层面的技术包括随机欠采样和随机过采样[101, 48, 98]，而分类器层面的技术包括成本敏感学习和阈值调整[48, 98]。

### V-C 计算成本和内存约束

内存约束在处理具有大特征空间的训练数据时是一个问题，例如高分辨率或高维图像[96, 102, 103, 74]。例如，当从头开始训练一个具有大特征空间的 DBT 数据的 3D CNN 时，计算和内存成本会显著增加。

### V-D 图像质量变异性

图像质量依赖于医疗筛查设备的系统设置和制造商规格，而模型的性能则依赖于图像质量[56]。乳腺癌筛查中图像的分辨率、清晰度、对比度、焦点或噪声过高会在训练、预测或病灶定位过程中对模型造成阻碍[17]。

## VI 未来展望

本文讨论的神经网络模型在乳腺肿瘤的分类、检测和分割任务中取得了有希望的结果。然而，应进一步探索不同的架构，以扩展可能的解决方案，解决常见问题，如计算成本和内存使用、3D 数据学习中的冗余以及鲁棒性。此外，需要开发能够更高效、更快速、更自信地评估 DBT、MRI 和 ABUS 图像的架构。此外，最先进的模型需要具备高度的鲁棒性和自信，以显示出所需的完整性，作为放射科医生的“第二意见”。

## VII 结论

深度学习在监督学习领域展示了显著的增长，并继续朝着更好地支持放射科医生在工作流程和决策中的方向发展。本文概述了深度学习理论、不同深度学习架构在乳腺癌筛查中的有效性，以及深度学习面临的挑战。此外，本文还旨在建立对乳腺肿瘤诊断中深度学习当前进展的清晰理解，以便未来方向能够清晰可见。

## 参考文献

+   [1] H. Sung, J. Ferlay, R. L. Siegel, M. Laversanne, I. Soerjomataram, A. Jemal, 和 F. Bray，《2020 年全球癌症统计数据：Globocan 对 185 个国家 36 种癌症发病率和死亡率的估计》，*CA：临床癌症杂志*，第 71 卷，第 3 期，第 212 页，2021 年。

+   [2] A. C. Society，《2019–2020 年乳腺癌事实与数据》，*美国癌症学会*，第 1–44 页，2019 年。

+   [3] C. P. A. Cancer，《加拿大乳腺癌筛查；质量指标的监测与评估——结果报告，2011 年 1 月到 2012 年 12 月》，2017 年。

+   [4] M. Løberg, M. L. Lousdal, M. Bretthauer, 和 M. Kalager，《乳腺 X 光检查的益处与风险》，*乳腺癌研究*，第 17 卷，第 1 期，第 1–12 页，2015 年。

+   [5] A. Chong, S. P. Weinstein, E. S. McDonald, 和 E. F. Conant，《数字乳腺断层合成：概念与临床实践》，*放射学*，第 292 卷，第 1 期，第 1–14 页，2019 年。

+   [6] M. L. Marinovich, K. E. Hunter, P. Macaskill, 和 N. Houssami，《使用断层合成或乳腺 X 光检查进行乳腺癌筛查：癌症检测和回召的荟萃分析》，*国家癌症研究所杂志*，第 110 卷，第 9 期，第 942–949 页，2018 年。

+   [7] D. B. Kopans，《数字乳腺断层合成从概念到临床应用》，*美国放射学杂志*，第 202 卷，第 2 期，第 299–308 页，2014 年。

+   [8] M. L. Giger, M. F. Inciardi, A. Edwards, J. Papaioannou, K. Drukker, Y. Jiang, R. Brem, 和 J. B. Brown，《自动化乳腺超声在密集乳腺女性乳腺癌筛查中的应用：对乳腺 X 光检查阴性和阳性癌症的读者研究》，*美国放射学杂志*，第 206 卷，第 6 期，第 1341–1350 页，2016 年。

+   [9] K. Doi，《医学影像中的计算机辅助诊断：历史回顾、现状与未来潜力》，*计算机医学影像与图形*，第 31 卷，第 4-5 期，第 198–211 页，2007 年。

+   [10] M. L. Giger, N. Karssemeijer, 和 J. A. Schnabel，《用于风险评估、检测、诊断和治疗癌症的乳腺影像分析》，*生物医学工程年度综述*，第 15 卷，第 327–357 页，2013 年。

+   [11] J.-Z. Cheng, Y.-H. Chou, C.-S. Huang, Y.-C. Chang, C.-M. Tiu, K.-W. Chen, 和 C.-M. Chen，《利用基于细胞的轮廓分组进行乳腺病变的计算机辅助超声诊断》，*放射学*，第 255 卷，第 3 期，第 746–754 页，2010 年。

+   [12] B. Van Ginneken, C. M. Schaefer-Prokop, 和 M. Prokop，《计算机辅助诊断：如何从实验室转向临床》，*放射学*，第 261 卷，第 3 期，第 719–732 页，2011 年。

+   [13] K. H. Allison, L. M. Reisch, P. A. Carney, D. L. Weaver, S. J. Schnitt, F. P. O’Malley, B. M. Geller, 和 J. G. Elmore，《理解乳腺病理诊断的变异性：从专家共识评审小组中学到的经验教训》，*组织病理学*，第 65 卷，第 2 期，第 240–251 页，2014 年。

+   [14] L. J. Grimm, A. L. Anderson, J. A. Baker, K. S. Johnson, R. Walsh, S. C. Yoon, 和 S. V. Ghate, “使用第五版 BI-RADS MRI 词汇表的乳腺影像医师之间的观察者变异性，” *美国放射学杂志*，第 204 卷，第 5 期，页码 1120–1124，2015 年。

+   [15] D. Wang, A. Khosla, R. Gargeya, H. Irshad, 和 A. H. Beck, “用于识别转移性乳腺癌的深度学习，” *arXiv 预印本 arXiv:1606.05718*，2016 年。

+   [16] S. M. McKinney, M. Sieniek, V. Godbole, J. Godwin, N. Antropova, H. Ashrafian, T. Back, M. Chesus, G. S. Corrado, A. Darzi *等*，“国际评估乳腺癌筛查的人工智能系统，” *自然*，第 577 卷，第 7788 期，页码 89–94，2020 年。

+   [17] A. Ibrahim, P. Gamble, R. Jaroensri, M. M. Abdelsamea, C. H. Mermel, P.-H. C. Chen, 和 E. A. Rakha, “数字乳腺病理中的人工智能：技术与应用，” *乳腺*，第 49 卷，页码 267–273，2020 年。

+   [18] I. Goodfellow, Y. Bengio, 和 A. Courville, *深度学习*。MIT 出版社，2016 年，[`www.deeplearningbook.org`](http://www.deeplearningbook.org)。

+   [19] S. P. Singh, L. Wang, S. Gupta, H. Goli, P. Padmanabhan, 和 B. Gulyás, “医学影像上的 3D 深度学习：综述，” *传感器*，第 20 卷，第 18 期，页码 5097，2020 年。

+   [20] A. Krizhevsky, I. Sutskever, 和 G. E. Hinton, “使用深度卷积神经网络进行 ImageNet 分类，” *神经信息处理系统进展*，第 25 卷，页码 1097–1105，2012 年。

+   [21] K. Suzuki, “深度学习在医学影像中的概述，” *放射物理与技术*，第 10 卷，第 3 期，页码 257–273，2017 年。

+   [22] R. Yamashita, M. Nishio, R. K. G. Do, 和 K. Togashi, “卷积神经网络：概述及其在放射学中的应用，” *影像学前沿*，第 9 卷，第 4 期，页码 611–629，2018 年。

+   [23] J. Gu, Z. Wang, J. Kuen, L. Ma, A. Shahroudy, B. Shuai, T. Liu, X. Wang, G. Wang, J. Cai *等*，“卷积神经网络的最新进展，” *模式识别*，第 77 卷，页码 354–377，2018 年。

+   [24] F. Amherd 和 E. Rodriguez, “基于热图的物体检测与跟踪，使用全卷积神经网络，” *arXiv 预印本 arXiv:2101.03541*，2021 年。

+   [25] S. Zheng, Y. Song, T. Leung, 和 I. Goodfellow, “通过稳定性训练提高深度神经网络的鲁棒性，” *arXiv 预印本 arXiv:1604.04326*，2016 年。

+   [26] A. LeNail, “NN-SVG：适合出版的神经网络架构示意图，” *开源软件杂志*，第 4 卷，第 33 期，页码 747，2019 年。[在线]. 可用：[`doi.org/10.21105/joss.00747`](https://doi.org/10.21105/joss.00747)

+   [27] A. Zhang, Z. C. Lipton, M. Li, 和 A. J. Smola, “深入探索深度学习，” *arXiv 预印本 arXiv:2106.11342*，2021 年。

+   [28] K. O’Shea 和 R. Nash, “卷积神经网络入门，” *arXiv 预印本 arXiv:1511.08458*，2015 年。

+   [29] J. Wu, “卷积神经网络简介，” *国家新型软件技术重点实验室，南京大学，中国*，第 5 卷，第 23 期，页码 495，2017 年。

+   [30] G. Kang, K. Liu, B. Hou, 和 N. Zhang, “用于肺结节分类的 3d 多视角卷积神经网络，” *PloS one*，第 12 卷，第 11 期，页 e0188290，2017。

+   [31] J. D. Hunter, “Matplotlib：一个 2D 图形环境，” *科学与工程计算*，第 9 卷，第 3 期，页 90–95，2007。

+   [32] Y. LeCun, Y. Bengio, 和 G. Hinton, “深度学习，” *自然*，第 521 卷，第 7553 期，页 436–444，2015。

+   [33] P. Ramachandran, B. Zoph, 和 Q. V. Le, “激活函数的搜索，” *arXiv 预印本 arXiv:1710.05941*，2017。

+   [34] C. Nwankpa, W. Ijomah, A. Gachagan, 和 S. Marshall, “激活函数：深度学习中的实践与研究趋势比较，” *arXiv 预印本 arXiv:1811.03378*，2018。

+   [35] M. Sun, Z. Song, X. Jiang, J. Pan, 和 Y. Pang, “卷积神经网络的学习池化，” *神经计算*，第 224 卷，页 96–104，2017。

+   [36] M. A. Mazurowski, M. Buda, A. Saha, 和 M. R. Bashir, “放射学中的深度学习：概念概述及最新进展调查，” *arXiv 预印本 arXiv:1802.08717*，2018。

+   [37] S. Ruder, “梯度下降优化算法概述，” *arXiv 预印本 arXiv:1609.04747*，2016。

+   [38] X. Ying, “过拟合及其解决方案概述，” 见 *物理学杂志：会议系列*，第 1168 卷，第 2 期。IOP 出版社，2019，页 022022。

+   [39] W. S. Sarle *等*，“停止训练和其他应对过拟合的方法，” *计算科学与统计*，页 352–360，1996。

+   [40] Z. Liu, M. Sun, T. Zhou, G. Huang, 和 T. Darrell, “重新思考网络剪枝的价值，” *arXiv 预印本 arXiv:1810.05270*，2018。

+   [41] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, 和 R. Salakhutdinov, “Dropout：一种防止神经网络过拟合的简单方法，” *机器学习研究杂志*，第 15 卷，第 1 期，页 1929–1958，2014。

+   [42] K. Weiss, T. M. Khoshgoftaar, 和 D. Wang, “迁移学习调查，” *大数据杂志*，第 3 卷，第 1 期，页 1–40，2016。

+   [43] C. Tan, F. Sun, T. Kong, W. Zhang, C. Yang, 和 C. Liu, “深度迁移学习调查，” 见 *国际人工神经网络会议*。Springer，2018，页 270–279。

+   [44] A. Garcia-Garcia, S. Orts-Escolano, S. Oprea, V. Villena-Martinez, P. Martinez-Gonzalez, 和 J. Garcia-Rodriguez, “图像和视频语义分割的深度学习技术调查，” *应用软计算*，第 70 卷，页 41–65，2018。

+   [45] J. Davis 和 M. Goadrich, “精确率-召回率与 ROC 曲线的关系，” 见 *第 23 届国际机器学习会议论文集*，2006，页 233–240。

+   [46] L. A. Jeni, J. F. Cohn, 和 F. De La Torre, “面对不平衡数据–性能指标使用建议，” 见 *2013 人工情感计算与智能互动协会会议*。IEEE，2013，页 245–251。

+   [47] D. Chicco 和 G. Jurman，“马修斯相关系数（MCC）相对于 F1 得分和准确性的优势，在二分类评估中的应用，” *BMC genomics*，第 21 卷，第 1 期，页码 1–13，2020 年。

+   [48] J. M. Johnson 和 T. M. Khoshgoftaar，“关于类不平衡的深度学习调查，” *Journal of Big Data*，第 6 卷，第 1 期，页码 1–54，2019 年。

+   [49] K. H. Zou, S. K. Warfield, A. Bharatha, C. M. Tempany, M. R. Kaus, S. J. Haker, W. M. Wells III, F. A. Jolesz, 和 R. Kikinis，“基于空间重叠指数的图像分割质量的统计验证 1：科学报告，” *Academic radiology*，第 11 卷，第 2 期，页码 178–189，2004 年。

+   [50] M. El Adoui, S. A. Mahmoudi, M. A. Larhmam, 和 M. Benjelloun，“使用不同编码器和解码器 CNN 架构进行 MRI 乳腺肿瘤分割，” *Computers*，第 8 卷，第 3 期，页码 52，2019 年。

+   [51] N. Dhungel, G. Carneiro, 和 A. P. Bradley，“一种用于分析乳腺 X 光片中肿块的深度学习方法，具有最小用户干预，” *Medical image analysis*，第 37 卷，页码 114–128，2017 年。

+   [52] M. A. Al-Antari, M. A. Al-Masni, M.-T. Choi, S.-M. Han, 和 T.-S. Kim，“通过深度学习检测、分割和分类的全功能计算机辅助诊断系统，用于数字 X 光乳腺图像，” *International journal of medical informatics*，第 117 卷，页码 44–54，2018 年。

+   [53] H. Chougrad, H. Zouaki, 和 O. Alheyane，“用于乳腺癌筛查的深度卷积神经网络，” *Computer methods and programs in biomedicine*，第 157 卷，页码 19–30，2018 年。

+   [54] D. Ribli, A. Horváth, Z. Unger, P. Pollner, 和 I. Csabai，“使用深度学习检测和分类乳腺 X 光片中的病变，” *Scientific reports*，第 8 卷，第 1 期，页码 1–7，2018 年。

+   [55] V. K. Singh, H. A. Rashwan, S. Romani, F. Akram, N. Pandey, M. M. K. Sarker, A. Saleh, M. Arenas, M. Arquez, D. Puig *等*，“使用生成对抗网络和卷积神经网络对乳腺 X 光片中的乳腺肿瘤进行分割和形状分类，” *Expert Systems with Applications*，第 139 卷，页码 112855，2020 年。

+   [56] W. T. Tran, A. Sadeghi-Naini, F.-I. Lu, S. Gandhi, N. Meti, M. Brackstone, E. Rakovitch, 和 B. Curpen，“使用人工智能进行乳腺癌筛查和诊断的计算放射学，” *Canadian Association of Radiologists Journal*，第 72 卷，第 1 期，页码 98–108，2021 年。

+   [57] E. F. Conant, W. E. Barlow, S. D. Herschorn, D. L. Weaver, E. F. Beaber, A. N. Tosteson, J. S. Haas, K. P. Lowry, N. K. Stout, A. Trentham-Dietz *等*，“数字乳腺断层扫描与数字乳腺 X 光片在癌症检测和召回率方面的年龄和乳腺密度关联，” *JAMA oncology*，第 5 卷，第 5 期，页码 635–642，2019 年。

+   [58] E. A. Rafferty, M. A. Durand, E. F. Conant, D. S. Copit, S. M. Friedewald, D. M. Plecha, 和 D. P. Miller，“在致密和非致密乳腺中使用断层扫描和数字乳腺 X 光片进行乳腺癌筛查，” *Jama*，第 315 卷，第 16 期，页码 1784–1786，2016 年。

+   [59] K. P. Lowry, R. Y. Coley, D. L. Miglioretti, K. Kerlikowske, L. M. Henderson, T. Onega, B. L. Sprague, J. M. Lee, S. Herschorn, A. N. Tosteson *等*，“按患者年龄、筛查轮次和乳腺密度划分的社区实践中数字乳腺断层扫描与数字化乳腺摄影的筛查性能，” *JAMA 网络开放*，第 3 卷，第 7 期，第 e2 011 792–e2 011 792 页，2020 年。

+   [60] E. F. Conant, E. F. Beaber, B. L. Sprague, S. D. Herschorn, D. L. Weaver, T. Onega, A. N. Tosteson, A. M. McCarthy, S. P. Poplack, J. S. Haas *等*，“结合数字化乳腺摄影的乳腺癌筛查与单独数字化乳腺摄影的比较：PROSPR 联盟中的一项队列研究，” *乳腺癌研究与治疗*，第 156 卷，第 1 期，第 109–116 页，2016 年。

+   [61] X.-A. Phi, A. Tagliafico, N. Houssami, M. J. Greuter, 和 G. H. de Bock，“用于密集乳腺女性的乳腺癌筛查和诊断的数字乳腺断层扫描——系统评价和荟萃分析，” *BMC 癌症*，第 18 卷，第 1 期，第 1–9 页，2018 年。

+   [62] P. Pattacini, A. Nitrosi, P. Giorgi Rossi, V. Iotti, V. Ginocchi, S. Ravaioli, R. Vacondio, L. Braglia, S. Cavuto, C. Campari *等*，“数字化乳腺摄影与数字化乳腺摄影加断层扫描的乳腺癌筛查比较：雷焦艾米利亚断层扫描随机试验，” *放射学*，第 288 卷，第 2 期，第 375–385 页，2018 年。

+   [63] J. A. Baker 和 J. Y. Lo，“乳腺断层扫描：最新进展及文献综述，” *学术放射学*，第 18 卷，第 10 期，第 1298–1310 页，2011 年。

+   [64] J. V. Horvat, D. M. Keating, H. Rodrigues-Duarte, E. A. Morris, 和 V. L. Mango，“数字乳腺断层扫描中的钙化：影像特征和活检技术，” *放射图像学*，第 39 卷，第 2 期，第 307–318 页，2019 年。

+   [65] S. H. Kim, H. H. Kim, 和 W. K. Moon，“针对密集乳腺的自动化乳腺超声筛查，” *韩国放射学杂志*，第 21 卷，第 1 期，第 15–24 页，2020 年。

+   [66] H. J. Shin, H. H. Kim, 和 J. H. Cha，“自动化乳腺超声检查的现状，” *超声医学*，第 34 卷，第 3 期，第 165 页，2015 年。

+   [67] C. D. Lehman, J. M. Lee, W. B. DeMartini, D. S. Hippe, M. H. Rendi, G. Kalish, P. Porter, J. Gralow, 和 S. C. Partridge，“具有乳腺癌个人病史的女性的筛查 MRI，” *国家癌症研究所杂志*，第 108 卷，第 3 期，第 djv349 页，2016 年。

+   [68] R. M. Mann, N. Cho, 和 L. Moy，“乳腺 MRI：最新进展，” *放射学*，第 292 卷，第 3 期，第 520–536 页，2019 年。

+   [69] H. Greenspan, G. Oz, N. Kiryati, 和 S. Peled，“使用超分辨率的 MRI 切片间重建，” *磁共振成像*，第 20 卷，第 5 期，第 437–446 页，2002 年。

+   [70] R. Z. Shilling, T. Q. Robbie, T. Bailloeul, K. Mewes, R. M. Mersereau, 和 M. E. Brummer，“使用 2-D 多切片 MRI 的 3-D 高分辨率和高对比度成像的超分辨率框架，” *IEEE 医学影像学杂志*，第 28 卷，第 5 期，第 633–644 页，2008 年。

+   [71] M. Yousefi, A. Krzyżak, 和 C. Y. Suen, “使用卷积神经网络和多实例学习进行数字乳腺断层合成数据中的肿块检测，” *生物医学计算机*，第 96 卷，第 283–293 页，2018 年。

+   [72] D. H. Kim, S. T. Kim, J. M. Chang, 和 Y. M. Ro, “数字乳腺断层合成中乳腺肿块的深度方向长期递归学习的潜在特征表示，” *医学与生物物理学*，第 62 卷，第 3 期，第 1009 页，2017 年。

+   [73] S. Liu, D. Xu, S. K. Zhou, T. Mertelmeier, J. Wicklein, A. Jerebko, S. Grbic, O. Pauly, W. Cai, 和 D. Comaniciu, “3d 各向异性混合网络：将卷积特征从 2d 图像转移到 3d 各向异性体积，” *arXiv 预印本 arXiv:1711.08580*，2017 年。

+   [74] Y. Zhang, X. Wang, H. Blanton, G. Liang, X. Xing, 和 N. Jacobs, “用于 3d 数字乳腺断层合成分类的 2d 卷积神经网络，” 见于 *2019 IEEE 国际生物信息学与生物医学会议 (BIBM)*。 IEEE，2019 年。

+   [75] G. Liang, X. Wang, Y. Zhang, X. Xing, H. Blanton, T. Salem, 和 N. Jacobs, “联合 2d-3d 乳腺癌分类，” 见于 *2019 IEEE 国际生物信息学与生物医学会议 (BIBM)*。 IEEE，2019 年。

+   [76] K. He, X. Zhang, S. Ren, 和 J. Sun, “用于图像识别的深度残差学习，” *arXiv 预印本 arXiv:1512.03385*，2015 年。

+   [77] K. Simonyan 和 A. Zisserman, “用于大规模图像识别的非常深卷积网络，” 见于 *国际学习表征会议*，2015 年。

+   [78] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, 和 Z. Wojna, “重新思考计算机视觉中的 inception 架构，” 见于 *计算机视觉与模式识别会议 (CVPR)*，2016 年。

+   [79] P. Isola, J.-Y. Zhu, T. Zhou, 和 A. A. Efros, “使用条件对抗网络进行图像到图像的转换，” *CVPR*，2017 年。

+   [80] X. Zhang, Y. Zhang, E. Y. Han, N. Jacobs, Q. Han, X. Wang, 和 J. Liu, “使用深度卷积神经网络对整个乳腺摄影和断层合成图像进行分类，” *IEEE 纳米生物科学学报*，第 17 卷，第 3 期，第 237–242 页，2018 年。

+   [81] M. Fan, H. Zheng, S. Zheng, C. You, Y. Gu, X. Gao, W. Peng, 和 L. Li, “使用 3d-mask 区域卷积神经网络进行数字乳腺断层合成中的肿块检测和分割：比较分析，” *分子生物科学前沿*，第 7 卷，2020 年。

+   [82] I. Wichakam, J. Chayakulkheeree, 和 P. Vateekul, “用于 dbt 乳腺癌诊断的深度多标签 3d convnet 与反转增强，” 见于 *第十届国际数字图像处理会议 (ICDIP 2018)*。 国际光学与光子学学会，2018 年。

+   [83] Y. Lei, X. He, J. Yao, T. Wang, L. Wang, W. Li, W. J. Curran, T. Liu, D. Xu, 和 X. Yang, “使用 mask scoring r-cnn 进行 3d 自动乳腺超声中的乳腺肿瘤分割，” *医学物理学*，第 48 卷，第 1 期，第 204–214 页，2021 年。

+   [84] Y. Zhou, H. Chen, Y. Li, Q. Liu, X. Xu, S. Wang, P.-T. Yap, 和 D. Shen, “用于 3D 自动化乳腺超声图像中肿瘤分割和分类的多任务学习，” *医学图像分析*，第 70 卷，页码 101918，2021。

+   [85] J. Zhou, L.-Y. Luo, Q. Dou, H. Chen, C. Chen, G.-J. Li, Z.-F. Jiang, 和 P.-A. Heng, “用于乳腺癌分类和 MR 图像中病变定位的弱监督 3D 深度学习，” *磁共振成像杂志*，第 50 卷，第 4 期，页码 1144–1151，2019。

+   [86] Q. Hu, H. M. Whitney, 和 M. L. Giger, “一种改进乳腺癌诊断的深度学习方法，使用多参数 MRI，” *科学报告*，第 10 卷，第 1 期，页码 1–11，2020。

+   [87] B. Xiao, H. Sun, Y. Meng, Y. Peng, X. Yang, S. Chen, Z. Yan, 和 J. Zheng, “在数字乳腺断层扫描中使用集成卷积神经网络进行微钙化簇的分类，” *生物医学工程在线*，第 20 卷，第 1 期，页码 1–20，2021。

+   [88] S. Liu, D. Xu, S. K. Zhou, S. Grbic, W. Cai, 和 D. Comaniciu, “用于 3D 医学图像中跨维度可转移特征学习的各向异性混合网络，” 见于 *深度学习和卷积神经网络在医学成像和临床信息学中的应用*。 Springer，2019。

+   [89] D. Tran, H. Wang, L. Torresani, J. Ray, Y. LeCun, 和 M. Paluri, “对时空卷积在动作识别中的应用的更深入探讨，” 见于 *CVPR*，2018。

+   [90] J. Carreira 和 A. Zisserman, “前途如何，动作识别？一个新模型和 Kinetics 数据集，” 见于 *计算机视觉与模式识别 (CVPR)*，2017。

+   [91] M. Buda, A. Saha, R. Walsh, S. Ghate, N. Li, A. Święcicki, J. Y. Lo, 和 M. A. Mazurowski, “在数字乳腺断层扫描中检测肿块和结构扭曲：一个包含 5,060 名患者的公开数据集和一个深度学习模型，” *arXiv 预印本 arXiv:2011.07995*，2020。

+   [92] S. J. S. Gardezi, A. Elazab, B. Lei, 和 T. Wang, “使用乳腺 X 光数据进行乳腺癌检测和诊断：系统综述，” *医学互联网研究杂志*，第 21 卷，第 7 期，页码 e14464，2019。

+   [93] K. Dembrower, P. Lindholm, 和 F. Strand, “一个数百万张乳腺 X 光图像数据集和基于人群筛查的队列，用于训练和评估深度神经网络——筛查年龄女性队列（CSAW），” *数字成像杂志*，页码 1–6，2019。

+   [94] R. S. Lee, F. Gimenez, A. Hoogi, K. K. Miyake, M. Gorovoy, 和 D. L. Rubin, “一个经过策划的乳腺 X 光数据集，用于计算机辅助检测和诊断研究，” *科学数据*，第 4 卷，第 1 期，页码 1–9，2017。

+   [95] I. C. Moreira, I. Amaral, I. Domingues, A. Cardoso, M. J. Cardoso, 和 J. S. Cardoso, “Inbreast：迈向全面数字化乳腺 X 光数据库，” *学术放射学*，第 19 卷，第 2 期，页码 236–248，2012。

+   [96] D. Abdelhafiz, C. Yang, R. Ammar 和 S. Nabavi，“用于乳腺 X 光检查的深度卷积神经网络：进展、挑战与应用，”*BMC 生物信息学*，第 20 卷，第 11 期，第 1–20 页，2019 年。

+   [97] K.-H. Yu, A. L. Beam 和 I. S. Kohane，“医疗保健中的人工智能，”*自然生物医学工程*，第 2 卷，第 10 期，第 719–731 页，2018 年。

+   [98] M. Buda, A. Maki 和 M. A. Mazurowski，“卷积神经网络中的类不平衡问题的系统研究，”*神经网络*，第 106 卷，第 249–259 页，2018 年。

+   [99] W. W. Ng, G. Zeng, J. Zhang, D. S. Yeung 和 W. Pedrycz，“用于不平衡分类问题的双重自编码器特征，”*模式识别*，第 60 卷，第 875–889 页，2016 年。

+   [100] L. Ge, J. Gao, H. Ngo, K. Li 和 A. Zhang，“处理多源迁移学习中的负迁移和不平衡分布，”*统计分析与数据挖掘：ASA 数据科学杂志*，第 7 卷，第 4 期，第 254–271 页，2014 年。

+   [101] S. M. Abd Elrahman 和 A. Abraham，“类不平衡问题的综述，”*网络与创新计算杂志*，第 1 卷，2013 年，第 332–340 页，2013 年。

+   [102] Z. Qiu, T. Yao 和 T. Mei，“使用伪 3D 残差网络学习时空表示，”发表于 *ICCV*，2017 年。

+   [103] D. Tran, L. Bourdev, R. Fergus, L. Torresani 和 M. Paluri，“使用 3D 卷积网络学习时空特征，”发表于 *国际计算机视觉大会（ICCV）*，2015 年。
