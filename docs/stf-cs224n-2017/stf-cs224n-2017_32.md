# CS224n 研究热点 14 自动组合神经网络做问答系统

![hankcs.com 2017-07-13 下午 4.29.41.png](img/4fcf3f47a15c574367b41e27f1dae538.jpg "hankcs.com 2017-07-13 下午 4.29.41.png")

这是自我组装推断的 QA，可接受多种知识，包括图片和结构化知识库。问答具有复合性，很早就有人引入句法分析判断究竟在问什么，甚至脑洞大开想做自然语言编译器。但他们总是脱离不了手写规则的思维，白白糟蹋了性能卓越的句法分析器。而该模型自动组装多个神经网络用于逻辑推断，拿到了显著的好成绩。

## 四个 Jointly 训练的组件

![hankcs.com 2017-07-13 下午 4.34.11.png](img/081d88c67949806516f1e3ed3b3ba134.jpg "hankcs.com 2017-07-13 下午 4.34.11.png")

利用这四个组件可以组装分析问题的逻辑流：

![hankcs.com 2017-07-13 下午 4.36.09.png](img/62c7d94c0b8ad77ac8cc26717e0c1e7e.jpg "hankcs.com 2017-07-13 下午 4.36.09.png")

目标是训练模型自动分析 query，组装逻辑组件。

## 模型：在两个分布上构建

![hankcs.com 2017-07-13 下午 4.40.44.png](img/f2b1293647c74589e6876575800af1b3.jpg "hankcs.com 2017-07-13 下午 4.40.44.png")

一个 Layout Model，选择问题的 layout（应该是逻辑语句的“语法树”）。一个 Execution Model，在 world representation（应该理解为 fact 的表示）上执行 layout。

## Layout Model

这个模型的训练有 3 步，首先将输入句子解析为依存句法树：

![hankcs.com 2017-07-13 下午 4.42.18.png](img/acee74b6cd62c0d02cd4a1629134f8fe.jpg "hankcs.com 2017-07-13 下午 4.42.18.png")

第二步，将句法树的片段分配给合适的逻辑组件：

![hankcs.com 2017-07-13 下午 4.43.57.png](img/f0ecf228b6c50277672e7bb31064848e.jpg "hankcs.com 2017-07-13 下午 4.43.57.png")

最后，将逻辑片段组装为完整的 layout：

![hankcs.com 2017-07-13 下午 4.45.11.png](img/2ec353189332327469995a5385b58d56.jpg "hankcs.com 2017-07-13 下午 4.45.11.png")

这个 layout 的 root 是 and 逻辑，每个句子可能有多个 layout，接下来介绍如何为 layout 打分

### Layout Scoring Model

得到问题的 LSTM 表示，以及特征表示，将两个表示传入多层感知机。每个时刻的梯度是 layout 的 log-probability 乘以该 layout 预测的准确率的梯度。

## Execution Model

在知识库上面执行逻辑查询，输入结构化知识库中某种实体的所有 representation，流入逻辑树输出每个备选答案的分值，取最大的那个。

![hankcs.com 2017-07-13 下午 4.55.03.png](img/43d7e665376186983dfbab38673b6243.jpg "hankcs.com 2017-07-13 下午 4.55.03.png")

### Module: lookup

就是 lookup table，去结构化知识库（数据库）取数据，查出实体的向量表示：

![hankcs.com 2017-07-13 下午 5.50.17.png](img/3d13cf34229289f3e2f50fbd25946aa4.jpg "hankcs.com 2017-07-13 下午 5.50.17.png")

“把全部 attention 放到第![](img/fb36ad595aa9f5e0fc95ee87b664e384.jpg)个元素上”，真是清丽脱俗的说法呢。

### Module: relate

![hankcs.com 2017-07-13 下午 5.57.02.png](img/97ae0f1619ce568c61ea2c273e5a6d4c.jpg "hankcs.com 2017-07-13 下午 5.57.02.png")

将 attention 从输入的一部分导向另一部分，条件中含有当前的 attention![](img/7cb1807f05c90f9cdce1f91ba4cee58d.jpg)。公式没展开讲，详细看论文吧。

### Module: find

![hankcs.com 2017-07-13 下午 6.00.53.png](img/6576b25bf531ed33000dcd1a16b6e6f8.jpg "hankcs.com 2017-07-13 下午 6.00.53.png")

也是把输入的特征拼接起来往多层感知机里面过一下然后 softmax。这里的输入应当是遍历所有单词。

### Module: and

有点像集合运算中的交集，只不过是在多个 attention 上做的乘法：

![hankcs.com 2017-07-13 下午 6.03.13.png](img/c459bf6600ced36884aecefdf25835ef.jpg "hankcs.com 2017-07-13 下午 6.03.13.png")

### 训练 Execution Model

目标函数是给定 world representation 和 layout 下正确答案的最大似然：

![hankcs.com 2017-07-13 下午 6.05.40.png](img/7381c51b4a318a88de93c4673e09b461.jpg "hankcs.com 2017-07-13 下午 6.05.40.png")

## 结果

### VQA

直观效果不错：

![hankcs.com 2017-07-13 下午 6.06.56.png](img/e36c809c05c631c2cf3fc2ee54f0bcf3.jpg "hankcs.com 2017-07-13 下午 6.06.56.png")

也拿到了最高分数：

![hankcs.com 2017-07-13 下午 6.07.42.png](img/e254c20aaec96b5f36bbc81544c1a5ea.jpg "hankcs.com 2017-07-13 下午 6.07.42.png")

### GeoQA

在这个领域知识库上表现也很出色：

![hankcs.com 2017-07-13 下午 6.09.43.png](img/6450b94e4d158c957bc3d0b6093c30c5.jpg "hankcs.com 2017-07-13 下午 6.09.43.png")

虽然在结构化知识库的手写特征利用上没有免俗，但总算自动化了“推断”这个被丑陋规则统治的部分。

![知识共享许可协议](http://www.hankcs.com/license/) [知识共享署名-非商业性使用-相同方式共享](http://www.hankcs.com/license/)：[码农场](http://www.hankcs.com) » [CS224n 研究热点 14 自动组合神经网络做问答系统](http://www.hankcs.com/nlp/cs224n-compose-nn-for-qa.html)