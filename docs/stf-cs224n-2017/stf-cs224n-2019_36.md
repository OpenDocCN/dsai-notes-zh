# CS224n Assignment 3

![hankcs.com 2017-07-02 下午 7.41.06.png](img/0a51b483b695119123d418192bcb12a2.jpg "hankcs.com 2017-07-02 下午 7.41.06.png")![q3-0-dynamics.png](img/87ca46933355d787709c9f9e09e65183.jpg "q3-0-dynamics.png")![q3-clip-gru.png](img/db90383450e7ae9cab381a7471c7b3f9.jpg "q3-clip-gru.png")命名实体识别任务，先实现基于窗口的基线模型，然后进阶到 RNN 和 GRU。中间利用对自动机的模拟和推导展示 RNN 的缺点，演示梯度剪裁的作用。这是 Latex 解答，[代码已提交](https://github.com/hankcs/CS224n)，最后还有一个彩蛋。

## 命名实体识别初步

定位命名实体并将其分类到：

*   人名 PER

*   组织名 ORG

*   地名 LOC

*   其他 MISC

加上非命名实体 O 一共 5 类。连续的标注视为同一个实体。比如样本![](img/fedcfa2869ac5659a86e70574d0c765f.jpg)与标注![](img/71261ea94d104c05ca21ec94692faced.jpg)以及预测结果![](img/2adae091f97b3f2c26a9f7d72575ba8d.jpg)：

![hankcs.com 2017-07-02 上午 11.07.41.png](img/fceca8a9537269b8c5a6d3bcc8604501.jpg "hankcs.com 2017-07-02 上午 11.07.41.png")

系统一共识别出 3 个命名实体，在 token 级别和 entity 级别各有评测方法。

token 级别

*   P 值为预测出的正确非 O 标签比上预测出的全部非 O 标签，于是![](img/ee2dc3ff115f22b0546c3475a6c8bde2.jpg)

*   R 值为预测出的正确非 O 标签比上正确答案的全部非 O 标签，于是![](img/4216b871ad967e59575be28d5827f9b1.jpg)

*   ![](img/cd52d9ccb051cd9662cf686f83c9753f.jpg)值是两者的调和平均：![](img/8c7532b1ef8e10773ce3f96d877beb57.jpg)

entity 级别

*   P 值为完美（不残缺不多余）识别的实体数量比上预测出的所有实体数量，于是![](img/a3e86d2686b4d1b57249c154874bae17.jpg)

*   R 值为完美识别的实体数量比上正确答案中的实体数量，于是![](img/7da685e30f35df6b28d306785f29c18b.jpg)

*   ![](img/cd52d9ccb051cd9662cf686f83c9753f.jpg)值是两者的调和平均：![](img/272eebc890950317e14b59c0ab029996.jpg)

## 1 A window into NER

基线模型使用半径![](img/f16e78fda8eb72a97d51d051c1695a2b.jpg)窗口中的特征![](img/618aeb3170f479187ac5901931de0bc9.jpg)预测![](img/c24f015066624d06719e2c659b7f47fa.jpg) ：

![hankcs.com 2017-07-02 上午 11.20.37.png](img/7c8c0b5af34db25c4db8b33d86fe75c5.jpg "hankcs.com 2017-07-02 上午 11.20.37.png")

模型为一个以 ReLU 为激活函数的隐藏层的神经网络，输出层为 softmax，损失函数为交叉熵：

![](img/7c7bab35705d516a517fcfccc6fda262.jpg)

其中![](img/7b2b6f105d356019243997f835866247.jpg)是词嵌入，![](img/d1d121536c94e65c39571cba3824ee71.jpg) 维度为 ![](img/9b7d9beafd65e2cf6493bdca741827a5.jpg)，![](img/44008eb188a69811703a2f7dbe80b365.jpg) 维度 ![](img/6c8feca3b2da3d6cf371417edff4be4f.jpg), ![](img/21ec2ab32d1af3e766487093bb20cf22.jpg)是词表大小，![](img/683792a4ccec414f11d2a19bc4258015.jpg) 是词嵌入维度，![](img/9b7d9beafd65e2cf6493bdca741827a5.jpg)是隐藏层维度，![](img/6c8feca3b2da3d6cf371417edff4be4f.jpg)是分类数目（此处为 5）。

### a 概念

请列举有歧义的命名实体？

太多了：

方地/nr, 的/ude1, 茶/n, 喝/vg, 个/q, 一罐/mq

![](img/12da8c9f3cbc6ae898b4ab452501b570.jpg)

![baoji.png](img/4e0177024bedea5b3e3672a4f123c26d.jpg "baoji.png")

![一个亿.jpg](img/8990294ed223ac1919223707e0832122.jpg "一个亿.jpg")

通常命名实体中含有低频词，为了泛化必须引入除了字符之外的特征，比如词性。这次作业为了简单，只使用字符特征。

### b 维度和复杂度

如果窗口大小为![](img/f16e78fda8eb72a97d51d051c1695a2b.jpg)，则窗口特征![](img/8fb3823135701384bfec6ef804733888.jpg)的维度是![](img/c7860ffdbca920cc8c21bf315ec2069e.jpg)的行向量。![](img/90490a34512e9bd1843ed4da713d0813.jpg)是![](img/95ae5ac8ec70542df9db302623aacf14.jpg)的矩阵。![](img/921e0f0523608a65f324548e8dc504e4.jpg)是![](img/31888fb148889f4e013fd62594d1e1e9.jpg)的矩阵。

对长![](img/5a047a5ca04e45726dba21b8302977da.jpg)的句子来讲，计算复杂度是![](img/3b4a2f5e5e921c8aa61a57d63fd090ae.jpg)，这是因为从输入到隐藏层是计算瓶颈。

### c 实现基线模型

就贴个最重要的 predict 方法吧：

```py
def add_prediction_op(self):
    """Adds the 1-hidden-layer NN:
        h = Relu(xW + b1)
        h_drop = Dropout(h, dropout_rate)
        pred = h_dropU + b2
    Recall that we are not applying a softmax to pred. The softmax will instead be done in
    the add_loss_op function, which improves efficiency because we can use
    tf.nn.softmax_cross_entropy_with_logits
    When creating a new variable, use the tf.get_variable function
    because it lets us specify an initializer.
    Use tf.contrib.layers.xavier_initializer to initialize matrices.
    This is TensorFlow's implementation of the Xavier initialization
    trick we used in last assignment.
    Note: tf.nn.dropout takes the keep probability (1 - p_drop) as an argument.
        The keep probability should be set to the value of dropout_rate.
    Returns:
        pred: tf.Tensor of shape (batch_size, n_classes)
    """
    x = self.add_embedding()
    dropout_rate = self.dropout_placeholder
    ### YOUR CODE HERE (~10-20 lines)
    b1 = tf.get_variable(name='b1', shape = [self.config.hidden_size,], \
                         initializer=tf.contrib.layers.xavier_initializer(seed=1))
    b2 = tf.get_variable(name='b2', shape = [self.config.n_classes], \
                         initializer=tf.contrib.layers.xavier_initializer(seed=2))
    W = tf.get_variable(name='W', shape = [self.config.n_window_features * self.config.embed_size, self.config.hidden_size], \
                        initializer=tf.contrib.layers.xavier_initializer(seed=3))
    U = tf.get_variable(name='U', shape = [self.config.hidden_size, self.config.n_classes], \
                        initializer=tf.contrib.layers.xavier_initializer(seed=4))
    z1 = tf.matmul(x,W) + b1
    h = tf.nn.relu(z1)
    h_drop = tf.nn.dropout(h, dropout_rate)
    pred = tf.matmul(h_drop,U) + b2
    ### END YOUR CODE
    return pred
```

### d 分析结果

```py
DEBUG:Token-level confusion matrix:
go\gu   PER     ORG     LOC     MISC    O    
PER     2968    26      84      16      55   
ORG     147     1621    131     65      128  
LOC     48      88      1896    26      36   
MISC    37      40      54      1030    107  
O       42      46      18      39      42614
DEBUG:Token-level scores:
label   acc     prec    rec     f1   
PER     0.99    0.92    0.94    0.93 
ORG     0.99    0.89    0.77    0.83 
LOC     0.99    0.87    0.91    0.89 
MISC    0.99    0.88    0.81    0.84 
O       0.99    0.99    1.00    0.99 
micro   0.99    0.98    0.98    0.98 
macro   0.99    0.91    0.89    0.90 
not-O   0.99    0.89    0.87    0.88 
INFO:Entity level P/R/F1: 0.82/0.85/0.84
```

最拖后腿的是机构名识别，经常误识别为人名或非 NER。

由于窗口的限制，模型不擅长做完整连续的识别，如果增大窗口则会有所进步。

窗口=2

```py
DEBUG:Token-level confusion matrix:
go\gu   PER     ORG     LOC     MISC    O    
PER     2995    23      50      10      71   
ORG     148     1679    96      52      117  
LOC     54      65      1910    24      41   
MISC    40      51      48      1029    100  
O       34      42      25      29      42629
DEBUG:Token-level scores:
label   acc     prec    rec     f1   
PER     0.99    0.92    0.95    0.93 
ORG     0.99    0.90    0.80    0.85 
LOC     0.99    0.90    0.91    0.90 
MISC    0.99    0.90    0.81    0.85 
O       0.99    0.99    1.00    0.99 
micro   0.99    0.98    0.98    0.98 
macro   0.99    0.92    0.89    0.91 
not-O   0.99    0.91    0.88    0.90 
INFO:Entity level P/R/F1: 0.85/0.87/0.86
```

![知识共享许可协议](http://www.hankcs.com/license/) [知识共享署名-非商业性使用-相同方式共享](http://www.hankcs.com/license/)：[码农场](http://www.hankcs.com) » [CS224n Assignment 3](http://www.hankcs.com/nlp/ner/cs224n-assignment-3.html)