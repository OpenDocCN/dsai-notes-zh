- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-06 19:48:05'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 19:48:05'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2202.05126] Deep Learning for Computational Cytology: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2202.05126] 深度学习在计算细胞学中的应用：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2202.05126](https://ar5iv.labs.arxiv.org/html/2202.05126)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2202.05126](https://ar5iv.labs.arxiv.org/html/2202.05126)
- en: 'Deep Learning for Computational Cytology: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在计算细胞学中的应用：综述
- en: Hao Jiang Yanning Zhou Yi Lin Ronald CK Chan Jiang Liu Hao Chen Department of
    Computer Science and Engineering, The Hong Kong University of Science and Technology,
    Hong Kong, China Department of Computer Science and Engineering, The Chinese University
    of Hong Kong, Hong Kong, China Department of Anatomical and Cellular Pathology,
    The Chinese University of Hong Kong, Hong Kong, China School of Computer Science
    and Engineering, Southern University of Science and Technology, Shenzhen, China
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 侯江、周燕宁、林逸、陈荣达、刘江、陈浩 计算机科学与工程系，香港科技大学，香港，中国 计算机科学与工程系，香港中文大学，香港，中国 解剖学与细胞病理学系，香港中文大学，香港，中国
    计算机科学与工程学院，南方科技大学，深圳，中国
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Computational cytology is a critical, rapid-developing, yet challenging topic
    in the field of medical image computing which analyzes the digitized cytology
    image by computer-aided technologies for cancer screening. Recently, an increasing
    number of deep learning (DL) algorithms have made significant progress in medical
    image analysis, leading to the boosting publications of cytological studies. To
    investigate the advanced methods and comprehensive applications, we survey more
    than 120 publications of DL-based cytology image analysis in this article. We
    first introduce various deep learning methods, including fully supervised, weakly
    supervised, unsupervised, and transfer learning. Then, we systematically summarize
    the public datasets, evaluation metrics, versatile cytology image analysis applications
    including classification, detection, segmentation, and other related tasks. Finally,
    we discuss current challenges and potential research directions of computational
    cytology.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 计算细胞学是医学影像计算领域中一个至关重要、快速发展的且具有挑战性的话题，它通过计算机辅助技术分析数字化的细胞学图像以进行癌症筛查。近年来，越来越多的深度学习（DL）算法在医学影像分析方面取得了显著进展，导致细胞学研究的出版物大幅增加。为了探讨先进的方法和综合应用，我们在本文中调查了120多篇基于DL的细胞图像分析的出版物。我们首先介绍了各种深度学习方法，包括完全监督、弱监督、无监督和迁移学习。然后，我们系统总结了公共数据集、评价指标、包括分类、检测、分割及其他相关任务在内的多种细胞图像分析应用。最后，我们讨论了计算细胞学的当前挑战和潜在研究方向。
- en: 'keywords:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '关键词:'
- en: '\KWDArtificial Intelligence, Deep Learning, Computational Cytology, Pathology,
    Cancer Screening, Survey^†^†journal: XXX'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '\KWD人工智能、深度学习、计算细胞学、病理学、癌症筛查、调查^†^†期刊: XXX'
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: 'Cytology is a branch of pathology to study the cells under microscopes to analyze
    the cellular morphology, and compositions, usually for cancer screening [[31](#bib.bib31),
    [1](#bib.bib1), [118](#bib.bib118)]. Compared with histopathology, cytology focuses
    on the pathological characteristics of cells instead of tissues, which is a collection
    of thousands of cells in a specific architecture [[112](#bib.bib112), [34](#bib.bib34)].
    Cells being the structural and functional unit of living organisms [[2](#bib.bib2)],
    their morphologies reflect the biological of the organ and even the body [[62](#bib.bib62),
    [147](#bib.bib147), [61](#bib.bib61)]. The clinical cytology testing procedure
    can be divided into collection and preservation, centrifugation, slide making,
    and staining (Fig. [1](#S1.F1 "Fig. 1 ‣ 1 Introduction ‣ Deep Learning for Computational
    Cytology: A Survey")(A)). For cytology screening, cytologists observe cytology
    slides under microscopes and analyze the properties and morphologies of cells
    (Fig. [1](#S1.F1 "Fig. 1 ‣ 1 Introduction ‣ Deep Learning for Computational Cytology:
    A Survey")(B)). These slides can be also scanned into whole slide images (WSI)
    (Fig. [1](#S1.F1 "Fig. 1 ‣ 1 Introduction ‣ Deep Learning for Computational Cytology:
    A Survey")(C)) for further digital analysis and processing. In addition, there
    are three types of cytology specimens, depending on the collection techniques:
    1) Exfoliative cytology, including sputum, urine sediment, pleural eﬀusion, and
    ascites [[100](#bib.bib100)]. 2) Abrasive cytology, including cervical scraping,
    gastrointestinal tract, and endoscopic brushing [[126](#bib.bib126)]. 3) Aspiration
    cytology, also named fine-needle aspiration cell inspection (FNAC) [[78](#bib.bib78)]
    usually from breast, thyroid, and lung [[72](#bib.bib72), [59](#bib.bib59)]. Unlike
    histology, cytology specimens do not require removal of intact sizable tissue,
    allowing much less invasive sampling procedures. Therefore, the sampling is frequently
    painless, low-cost, and equipment-undemanding, making cytology useful for cancer
    screening and early diagnosis [[68](#bib.bib68)].'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 细胞学是病理学的一个分支，通过显微镜研究细胞，以分析细胞的形态和成分，通常用于癌症筛查[[31](#bib.bib31)、[1](#bib.bib1)、[118](#bib.bib118)]。与组织病理学相比，细胞学关注的是细胞的病理特征而不是组织，这是一组在特定结构中排列的成千上万的细胞[[112](#bib.bib112)、[34](#bib.bib34)]。细胞是生物体的结构和功能单位[[2](#bib.bib2)]，它们的形态反映了器官甚至整个身体的生物学特征[[62](#bib.bib62)、[147](#bib.bib147)、[61](#bib.bib61)]。临床细胞学检测过程可以分为取样和保存、离心、制片和染色（图
    [1](#S1.F1 "图 1 ‣ 1 引言 ‣ 计算细胞学中的深度学习：综述")(A)）。在细胞学筛查中，细胞学家在显微镜下观察细胞学切片并分析细胞的特性和形态（图
    [1](#S1.F1 "图 1 ‣ 1 引言 ‣ 计算细胞学中的深度学习：综述")(B)）。这些切片也可以扫描成全切片图像（WSI）（图 [1](#S1.F1
    "图 1 ‣ 1 引言 ‣ 计算细胞学中的深度学习：综述")(C)），以便进一步进行数字分析和处理。此外，根据取样技术，细胞学标本有三种类型：1) 脱落细胞学，包括痰液、尿沉渣、胸腔积液和腹水[[100](#bib.bib100)]。2)
    磨擦细胞学，包括宫颈刮片、胃肠道和内窥镜刷检[[126](#bib.bib126)]。3) 吸引细胞学，也称为细针抽吸细胞检查（FNAC）[[78](#bib.bib78)]，通常取样于乳腺、甲状腺和肺[[72](#bib.bib72)、[59](#bib.bib59)]。与组织学不同，细胞学标本不需要去除完整的大块组织，因此取样过程侵入性较小。由于取样通常无痛、低成本且对设备要求较少，使得细胞学在癌症筛查和早期诊断中具有重要作用[[68](#bib.bib68)]。
- en: '![Refer to caption](img/11ec89ff42db910925f5ba2c906c51c9.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/11ec89ff42db910925f5ba2c906c51c9.png)'
- en: 'Fig. 1: Illustration of clinical cytology screening. (A) The procedure of cytology
    specimen preparation (taking the cervix as an example). (B) Cytology images in
    different categories. (C) WSI for digital analysis and processing.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：临床细胞学筛查示意图。（A）细胞学标本制备的过程（以宫颈为例）。 （B）不同类别的细胞学图像。 （C）用于数字分析和处理的全切片图像（WSI）。
- en: 'Diagnosing cytological specimens is a highly professional task, requiring formal
    training and assessments overseen by international bodies. Currently, there is
    a trend to standardize cytological diagnosis reporting, allowing reports and implied
    risk of cancers to be understood by clinicians without ambiguity [[11](#bib.bib11)].
    It also provides well-defined features to be looked for among the cells being
    examined. Fig. [2](#S1.F2 "Fig. 2 ‣ 1 Introduction ‣ Deep Learning for Computational
    Cytology: A Survey") illustrates typical cytological morphologies of commonly
    encountered specimens. Specifically, cytology screening was ﬁrst applied in cervix
    cancers almost 100 years ago. Present reporting of cervical cytology is guided
    by the Bethesda system [[113](#bib.bib113)]. Pre-cancerous and cancerous cells
    are first categorized into squamous cells and glandular cells, then they can be
    identified and graded by combinations of cytological features including enlarged
    nuclei, multinucleation, perinuclear halo, increased nuclear to cytoplasm ratio,
    wrinkled nuclear membrane, dyskeratosis (abnormal keratin formation), prominent
    nucleoli and tumor diathesis. Following the success of Bethesda system, present
    reporting of breast aspiration cytology is guided by [[42](#bib.bib42)]. Aspiration
    of malignant breast lesions are often hypercellular and the cancer cells possess
    large sometimes irregular nuclei with prominent nucleoli and the lack of myoepithelial
    cells. Different grades of atypia were also established to estimate the risk of
    malignancy [[14](#bib.bib14)]. Similarly, bladder cancer cells from urine often
    show irregular nuclei with very high N/C ratio ($>$0.7), prominent nucleoli and
    clumped/coarse chromatin, as outlined in [[135](#bib.bib135)]. Thyroid cancer
    aspirates show distinctive features including papillary structures, psammoma bodies
    and optically clear nuclei with nuclear grooves and nuclear inclusions [[30](#bib.bib30)].
    Together with examples from lung and oral mucosa illustrated in Fig. [2](#S1.F2
    "Fig. 2 ‣ 1 Introduction ‣ Deep Learning for Computational Cytology: A Survey"),
    cytological morphology from diﬀerent organs provides diagnostic information for
    cancer screening and guide patient management at a minimal cost [[18](#bib.bib18),
    [69](#bib.bib69)].'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断细胞学标本是一项高度专业的工作，需要经过正式培训和由国际机构监督的评估。目前，标准化细胞学诊断报告的趋势越来越明显，使得临床医生可以明确无误地理解报告和癌症风险[[11](#bib.bib11)]。这也提供了在检查细胞时需要寻找的明确特征。图
    [2](#S1.F2 "图 2 ‣ 1 介绍 ‣ 计算细胞学中的深度学习：综述") 展示了常见标本的典型细胞学形态。具体而言，细胞学筛查最早应用于子宫颈癌，至今已有近
    100 年。现在的子宫颈细胞学报告由 Bethesda 系统指导[[113](#bib.bib113)]。癌前及癌细胞首先被分类为鳞状细胞和腺体细胞，然后可以通过细胞学特征的组合来识别和分级，包括细胞核增大、多核现象、核周光晕、核浆比增加、皱纹状核膜、异常角质形成、明显的
    nucleoli 和肿瘤倾向。继 Bethesda 系统成功之后，现今乳腺抽吸细胞学的报告由 [[42](#bib.bib42)] 指导。恶性乳腺病变的抽吸样本通常细胞密度很高，癌细胞具有大且有时不规则的细胞核，伴有明显的
    nucleoli 和缺乏肌上皮细胞。还建立了不同程度的异常来估计恶性风险[[14](#bib.bib14)]。类似地，尿液中的膀胱癌细胞常表现为不规则核，N/C
    比值非常高（$>$0.7），明显的 nucleoli 和凝聚/粗糙的染色质，如 [[135](#bib.bib135)] 所述。甲状腺癌抽吸样本表现出独特特征，包括乳头状结构、钙化体和光学上清晰的细胞核，伴有核沟和核内包涵体[[30](#bib.bib30)]。结合图
    [2](#S1.F2 "图 2 ‣ 1 介绍 ‣ 计算细胞学中的深度学习：综述") 中肺和口腔黏膜的示例，不同器官的细胞学形态提供了癌症筛查的诊断信息，并以最低的成本指导患者管理[[18](#bib.bib18)，[69](#bib.bib69)]。
- en: '![Refer to caption](img/bf78ae09c897e5cee16bb528a70835fb.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/bf78ae09c897e5cee16bb528a70835fb.png)'
- en: 'Fig. 2: Typical cytological morphologies of commonly encountered specimens,
    including (A) Cervix [[195](#bib.bib195)], (B) Breast [[139](#bib.bib139)], (C)
    Urine [[7](#bib.bib7)], (D) Thyroid [[38](#bib.bib38)], (E) Lung [[161](#bib.bib161)],
    (F) Oral [[105](#bib.bib105)]. Single cellular structures are zoomed by red boxes.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：常见标本的典型细胞形态，包括 (A) 子宫颈 [[195](#bib.bib195)]，(B) 乳腺 [[139](#bib.bib139)]，(C)
    尿液 [[7](#bib.bib7)]，(D) 甲状腺 [[38](#bib.bib38)]，(E) 肺 [[161](#bib.bib161)]，(F)
    口腔 [[105](#bib.bib105)]。单细胞结构用红色框标出。
- en: In clinical cytology screening, scrutinizing every cell under the microscope
    (or in gigapixel whole slide images) in search of malignancy can be very time-consuming
    and tedious for cytologists [[106](#bib.bib106), [32](#bib.bib32)]. Considering
    ever increase in caseload, researchers have attempted to develop automatic methods
    for accurate and eﬃcient cancer screening. The ﬁrst successful trial could date
    back to the 1950s when an automatic screening system was developed for cervix
    [[167](#bib.bib167), [166](#bib.bib166)]. Afterwards, a series of cervical screening
    systems were launched with varying market success [[71](#bib.bib71), [175](#bib.bib175),
    [17](#bib.bib17)]. These automated cytology screening systems have been shown
    to improve the eﬃciency without compromising accuracy of cytology screening procedures.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在临床细胞学筛查中，逐一在显微镜下（或在千兆像素全切片图像中）检查每一个细胞以寻找恶性肿瘤，对于细胞学家来说可能非常耗时且繁琐[[106](#bib.bib106),
    [32](#bib.bib32)]。考虑到病例量的不断增加，研究人员尝试开发自动化的方法以实现准确和高效的癌症筛查。第一次成功的尝试可以追溯到1950年代，当时开发了用于宫颈的自动筛查系统[[167](#bib.bib167),
    [166](#bib.bib166)]。此后，推出了一系列宫颈筛查系统，其市场成功各异[[71](#bib.bib71), [175](#bib.bib175),
    [17](#bib.bib17)]。这些自动化细胞学筛查系统已被证明可以提高效率，同时不影响细胞学筛查程序的准确性。
- en: In recent decades, the automation technology and artiﬁcial intelligence (AI)
    have achieved remarkable progress in the ﬁeld of medicine. Machine learning (ML),
    which is a subfield of AI, focuses on learning algorithms to represent the underlying
    patterns of data by imitating human beings. With rapid progress in ML, medical
    image interpretation and computer assisted-diagnosis in pathology (e.g., histopathology,
    cytology [[24](#bib.bib24), [191](#bib.bib191), [199](#bib.bib199)]), and radiology
    (e.g., computed tomography (CT), magnetic resonance imaging (MRI), X-ray, ultrasound
    [[76](#bib.bib76), [63](#bib.bib63), [19](#bib.bib19)]). For cytology, previous
    studies demonstrated the feasibility of various ML approaches in cytology image
    analysis, including support vector machine (SVM), fuzzy c-means (FCM) [[22](#bib.bib22)],
    k-means [[58](#bib.bib58)], and fuzzy clustering [[122](#bib.bib122)]. However,
    there remains challenges in these machine learning algorithms, such as developing
    accurate and efficient cytology image analysis approaches, establishing human-machine
    collaborative cytological screening systems.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近几十年，自动化技术和人工智能（AI）在医学领域取得了显著进展。机器学习（ML），作为AI的一个子领域，专注于通过模仿人类来学习算法，以表示数据的潜在模式。随着机器学习的快速进步，医学图像解读和计算机辅助诊断在病理学（如组织病理学、细胞学[[24](#bib.bib24),
    [191](#bib.bib191), [199](#bib.bib199)]）和放射学（如计算机断层扫描（CT）、磁共振成像（MRI）、X射线、超声波[[76](#bib.bib76),
    [63](#bib.bib63), [19](#bib.bib19)]）中得到了广泛应用。对于细胞学，以前的研究展示了各种机器学习方法在细胞图像分析中的可行性，包括支持向量机（SVM）、模糊C均值（FCM）[[22](#bib.bib22)]、k均值[[58](#bib.bib58)]和模糊聚类[[122](#bib.bib122)]。然而，这些机器学习算法仍然面临挑战，例如开发准确且高效的细胞图像分析方法，建立人机协作的细胞学筛查系统。
- en: Deep learning, as a branch of the ML family, was developed with multilayers
    neural networks for leveraging feature representations of input data. DL aims
    to reduce the heavy reliance on task-related features designed from expert knowledge
    in traditional ML approaches. It can also increase the model’s capability of feature
    representation by end-to-end learning. In computational cytology, DL could provide
    cytologists with feasible solutions for accurate and efficient cytological screening.
    These approaches have been widely investigated in versatile types of cancers,
    such as cervix [[124](#bib.bib124)], breast [[43](#bib.bib43)], bladder [[38](#bib.bib38)],
    and lung [[161](#bib.bib161)]. Among these DL-based methods, supervised learning
    involves mapping input images to predeﬁned labels and it has been the most commonly
    developed DL scheme. Most existing studies on cytological applications focus on
    improving DL models performance by introducing specific constrains or architecture
    designs of DL models, such as introducing morphological constraints [[196](#bib.bib196),
    [21](#bib.bib21), [25](#bib.bib25)].
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习作为机器学习（ML）家族的一个分支，利用多层神经网络来提高输入数据的特征表示。深度学习旨在减少对传统机器学习方法中依赖专家知识设计的任务相关特征的高度依赖。它还可以通过端到端学习提高模型的特征表示能力。在计算细胞学中，深度学习可以为细胞学家提供准确高效的细胞学筛查的可行方案。这些方法在多种癌症类型中得到了广泛研究，例如宫颈
    [[124](#bib.bib124)]、乳腺 [[43](#bib.bib43)]、膀胱 [[38](#bib.bib38)] 和肺 [[161](#bib.bib161)]。在这些基于深度学习的方法中，监督学习涉及将输入图像映射到预定义标签，并且它是最常开发的深度学习方案。现有的大多数细胞学应用研究专注于通过引入特定约束或深度学习模型的架构设计来提高模型性能，例如引入形态学约束
    [[196](#bib.bib196), [21](#bib.bib21), [25](#bib.bib25)]。
- en: 'The advancement of DL has greatly accelerated the development of computational
    cytology. There is a 10-fold increase in DL-based computational research from
    2014 to 2021 with a booming trend in recent two years. The number of related publications
    is illustrated in Fig. [3](#S1.F3 "Fig. 3 ‣ 1 Introduction ‣ Deep Learning for
    Computational Cytology: A Survey"), after searching literature databases (Google
    Scholar, PubMed, and arXiv). These publications focus on developing various DL
    approaches for cytological screening, such as classifying between normal and abnormal
    cells [[189](#bib.bib189)], locating and identifying cells in cytological smears
    [[121](#bib.bib121)], and segmentation of different cellular compartments [[194](#bib.bib194)].'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的进步极大地加速了计算细胞学的发展。从2014年到2021年，基于深度学习的计算研究增加了10倍，并且在最近两年呈现出蓬勃发展的趋势。相关出版物的数量如图
    [3](#S1.F3 "图 3 ‣ 1 介绍 ‣ 深度学习在计算细胞学中的应用：综述") 所示，这些出版物通过搜索文献数据库（Google Scholar、PubMed
    和 arXiv）获得。这些出版物专注于开发各种深度学习方法用于细胞学筛查，例如区分正常和异常细胞 [[189](#bib.bib189)]、定位和识别细胞在细胞学涂片中的位置
    [[121](#bib.bib121)] 和不同细胞 compartment 的分割 [[194](#bib.bib194)]。
- en: '![Refer to caption](img/59852a86492babb146f434da435dfcb4.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/59852a86492babb146f434da435dfcb4.png)'
- en: 'Fig. 3: Number of publications in deep learning-based computational cytology
    of classification, detection, segmentation and other tasks.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：基于深度学习的计算细胞学中分类、检测、分割及其他任务的出版物数量。
- en: There exists several surveys in the field of cytology image analysis [[74](#bib.bib74),
    [109](#bib.bib109), [124](#bib.bib124)]. However, these reviews were far from
    exhaustive in terms of the advanced algorithms, publicly available datasets, and
    promising trends in this field. Besides, most of the DL-based cytology surveys
    focused on the cervix, ignoring the progress in other types of cancer, such as
    lung and bladder [[124](#bib.bib124)]. Afterwards, [[109](#bib.bib109)] focused
    on various cytology applications instead of analyzing them in the DL methodology
    perspective. In this paper, we have surveyed over 120 publications since 2014,
    and systematically reviewed the progress of DL approaches and techniques in computational
    cytology, also covering cytology specimens from various parts of the body.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在细胞学图像分析领域存在几项综述 [[74](#bib.bib74), [109](#bib.bib109), [124](#bib.bib124)]。然而，这些综述在先进算法、公开可用数据集和该领域的有前景趋势方面远未详尽。此外，大多数基于深度学习的细胞学综述专注于宫颈，忽视了其他类型癌症的进展，如肺和膀胱
    [[124](#bib.bib124)]。之后，[[109](#bib.bib109)] 专注于各种细胞学应用，而不是从深度学习方法的角度进行分析。在本文中，我们调查了自2014年以来的120多篇出版物，系统回顾了深度学习方法和技术在计算细胞学中的进展，并涵盖了来自身体各个部位的细胞学标本。
- en: 'There are six sections in this paper. Section [1](#S1 "1 Introduction ‣ Deep
    Learning for Computational Cytology: A Survey") briefly introduces the background
    and objective of this review. Section [2](#S2 "2 Deep learning methodology ‣ Deep
    Learning for Computational Cytology: A Survey") gives an overview of different
    learning approaches in the context of computational cytology. Section [3](#S3
    "3 Datasets and metrics ‣ Deep Learning for Computational Cytology: A Survey")
    summarizes public cytology datasets and common evaluation metrics. Section [4](#S4
    "4 Deep learning in cytology application ‣ Deep Learning for Computational Cytology:
    A Survey") presents the progress and achievements on the DL-based cytology image
    analysis. Section [5](#S5 "5 Challenges and Promises ‣ Deep Learning for Computational
    Cytology: A Survey") discusses existing challenges and potential research directions
    in computational cytology. Section [6](#S6 "6 Conclusion ‣ Deep Learning for Computational
    Cytology: A Survey") concludes this survey paper.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '本文分为六个部分。[第1部分](#S1 "1 Introduction ‣ Deep Learning for Computational Cytology:
    A Survey")简要介绍了本综述的背景和目标。[第2部分](#S2 "2 Deep learning methodology ‣ Deep Learning
    for Computational Cytology: A Survey")概述了计算细胞学中的不同学习方法。[第3部分](#S3 "3 Datasets
    and metrics ‣ Deep Learning for Computational Cytology: A Survey")总结了公共细胞学数据集和常见评估指标。[第4部分](#S4
    "4 Deep learning in cytology application ‣ Deep Learning for Computational Cytology:
    A Survey")展示了基于DL的细胞学图像分析的进展和成就。[第5部分](#S5 "5 Challenges and Promises ‣ Deep Learning
    for Computational Cytology: A Survey")讨论了计算细胞学中的现有挑战和潜在研究方向。[第6部分](#S6 "6 Conclusion
    ‣ Deep Learning for Computational Cytology: A Survey")总结了本综述论文。'
- en: 2 Deep learning methodology
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 深度学习方法论
- en: 'In this section, we present the definition, formulations, and general procedures
    of DL methods, which can be developed for various cytological applications. According
    to the availability of annotations, DL can be categorized as supervised learning
    (section [2.1](#S2.SS1 "2.1 Supervised learning ‣ 2 Deep learning methodology
    ‣ Deep Learning for Computational Cytology: A Survey")), weakly supervised learning
    (section [2.2](#S2.SS2 "2.2 Weakly supervised learning ‣ 2 Deep learning methodology
    ‣ Deep Learning for Computational Cytology: A Survey")), unsupervised learning
    (section [2.3](#S2.SS3 "2.3 Unsupervised learning ‣ 2 Deep learning methodology
    ‣ Deep Learning for Computational Cytology: A Survey")), together with transfer
    learning (section [2.4](#S2.SS4 "2.4 Transfer Learning ‣ 2 Deep learning methodology
    ‣ Deep Learning for Computational Cytology: A Survey")).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '在这一部分，我们展示了DL方法的定义、公式和一般程序，这些方法可以开发用于各种细胞学应用。根据注释的可用性，DL可以分为监督学习（[第2.1节](#S2.SS1
    "2.1 Supervised learning ‣ 2 Deep learning methodology ‣ Deep Learning for Computational
    Cytology: A Survey")）、弱监督学习（[第2.2节](#S2.SS2 "2.2 Weakly supervised learning ‣
    2 Deep learning methodology ‣ Deep Learning for Computational Cytology: A Survey")）、无监督学习（[第2.3节](#S2.SS3
    "2.3 Unsupervised learning ‣ 2 Deep learning methodology ‣ Deep Learning for Computational
    Cytology: A Survey")）以及迁移学习（[第2.4节](#S2.SS4 "2.4 Transfer Learning ‣ 2 Deep learning
    methodology ‣ Deep Learning for Computational Cytology: A Survey")）。'
- en: '![Refer to caption](img/f95d7ec46284f07dd9d087dcfd99bf87.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f95d7ec46284f07dd9d087dcfd99bf87.png)'
- en: 'Fig. 4: Standard workflow of DL-based supervised learning for cytological classification.
    (A) Cell-level: Firstly, ROIs are extracted from WSIs and cut into cell patches,
    then they are input into the DNN for extracting features and predicting category
    of each cell patch. (B) Slide-level: Patches cut from WSIs are input into a DNN
    to obtain multi-level predictions (e.g., instance-level and patch-level), then
    these predictions are used to predict final WSI-level results.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：基于DL的细胞学分类的标准工作流程。（A）细胞级：首先，从WSI中提取ROIs并切割成细胞补丁，然后输入到DNN中以提取特征并预测每个细胞补丁的类别。（B）幻灯片级：从WSI中切割的补丁输入到DNN中以获得多层次的预测（例如，实例级和补丁级），然后这些预测用于预测最终的WSI级结果。
- en: 2.1 Supervised learning
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 监督学习
- en: Supervised learning aims to learn functional mappings between input data and
    corresponding labels. For medical image analysis, the inputs are medical images,
    while labels are varied according to different tasks, e.g., image-level categories
    for classification, object-level localizations (e.g., boxes, points) for detection,
    and pixel-wise masks for segmentation. Formally, the input images $X=\{x_{i}\}_{i=1}^{N}$
    together with corresponding labels $Y=\{y_{i}\}_{i=1}^{N}$ are used to train a
    predictive model by minimizing the objective function. The typical deep models
    in supervised learning include multilayer perceptron (MLP) [[134](#bib.bib134)],
    convolutional neural network (CNN) [[77](#bib.bib77)], recurrent neural network
    (RNN) [[184](#bib.bib184)], and transformer [[160](#bib.bib160)].
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习旨在学习输入数据与相应标签之间的函数映射。对于医学图像分析，输入是医学图像，而标签则根据不同任务而有所不同，例如分类的图像级别类别、检测的对象级别定位（例如，框、点）以及分割的像素级掩码。形式上，输入图像
    $X=\{x_{i}\}_{i=1}^{N}$ 与相应的标签 $Y=\{y_{i}\}_{i=1}^{N}$ 被用来通过最小化目标函数来训练预测模型。监督学习中的典型深度模型包括多层感知机（MLP）
    [[134](#bib.bib134)]、卷积神经网络（CNN） [[77](#bib.bib77)]、递归神经网络（RNN） [[184](#bib.bib184)]
    和 transformer [[160](#bib.bib160)]。
- en: 'CNN is regarded as the most successful DL architecture in image analysis [[90](#bib.bib90)].
    It mainly consists of three types of hidden layers: convolutional layers for feature
    extraction, pooling layers for reducing the feature resolution, and fully connected
    layers for compiling the features extracted by previous layers and outputting
    prediction results. Then, backpropagation algorithm is introduced to update parameters
    of different layers during training [[77](#bib.bib77)]. Due to the strategies
    of local receptive fields, shared weights, and downsampling in pooling layers,
    CNN has achieved great success in many image analysis tasks, such as autonomous
    driving [[136](#bib.bib136)], face recognition [[173](#bib.bib173)], and biomedicine
    [[90](#bib.bib90)].'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 被认为是图像分析中最成功的深度学习架构 [[90](#bib.bib90)]。它主要由三种类型的隐藏层组成：用于特征提取的卷积层、用于减少特征分辨率的池化层和用于汇总前面层提取的特征并输出预测结果的全连接层。然后，反向传播算法被引入以更新训练过程中不同层的参数
    [[77](#bib.bib77)]。由于局部感受野、共享权重和池化层中的下采样策略，CNN 在许多图像分析任务中取得了巨大成功，例如自动驾驶 [[136](#bib.bib136)]、人脸识别
    [[173](#bib.bib173)] 和生物医学 [[90](#bib.bib90)]。
- en: 'Commonly-used CNN architectures in computer vision fields have been employed
    and developed for various cytological applications, e.g., AlexNet [[110](#bib.bib110)],
    VGGNet [[3](#bib.bib3)], ResNet [[108](#bib.bib108)]. Currently, most cytology
    researches focus on developing new algorithms based on these basic architectures
    in various DL tasks: classification, detection, and segmentation [[87](#bib.bib87),
    [153](#bib.bib153), [57](#bib.bib57)].'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉领域，常用的 CNN 架构已被应用并开发用于各种细胞学应用，例如 AlexNet [[110](#bib.bib110)]、VGGNet [[3](#bib.bib3)]
    和 ResNet [[108](#bib.bib108)]。目前，大多数细胞学研究集中在基于这些基本架构开发新算法，用于各种深度学习任务：分类、检测和分割
    [[87](#bib.bib87)、[153](#bib.bib153)、[57](#bib.bib57)]。
- en: 'Classification. This classification model aims at predicting the category of
    the input image. It can be essentially formulated as $\hat{y}=f(x,\theta)$, where
    $x$ and $\hat{y}$ is input image and its predicted category, and $\theta$ represents
    learnable parameters of classification architecture. For training these architectures,
    cross-entropy loss $L_{CE}$ measures the discrepancy between predicted probability
    $\hat{y_{ic}}$ and true label $y_{ic}$ by probability distribution:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 分类。这个分类模型的目标是预测输入图像的类别。它可以基本上表示为 $\hat{y}=f(x,\theta)$，其中 $x$ 和 $\hat{y}$ 分别是输入图像及其预测类别，而
    $\theta$ 代表分类架构的可学习参数。为了训练这些架构，交叉熵损失 $L_{CE}$ 通过概率分布测量预测概率 $\hat{y_{ic}}$ 和真实标签
    $y_{ic}$ 之间的差异。
- en: '|  | $L_{CE}=-\frac{1}{N}\sum_{i=1}^{N}\sum_{c=1}^{M}y_{ic}\log\left(\hat{y}_{ic}\right)$
    |  | (1) |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '|  | $L_{CE}=-\frac{1}{N}\sum_{i=1}^{N}\sum_{c=1}^{M}y_{ic}\log\left(\hat{y}_{ic}\right)$
    |  | (1) |'
- en: where, $N$ is the amount of image samples, and $M$ is the number of categories.
    Then, the prediction loss is used to optimize parameters $\theta$ of network by
    backpropagation [[137](#bib.bib137)].
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$N$ 是图像样本的数量，$M$ 是类别的数量。然后，预测损失用于通过反向传播 [[137](#bib.bib137)] 优化网络的参数 $\theta$。
- en: 'Usually, the label space of the cytology image refers to its benign/malignant
    or sub-category. In the standard cell-level classification workflow, regions of
    interest (ROIs) are extracted from collected slides by cytologists or technicians.
    Then, ROIs are cut into cell patches as input of deep models. After that, a DL-based
    feature extractor is responsible for representing high-level features and outputting
    prediction categories (Fig. [4](#S2.F4 "Fig. 4 ‣ 2 Deep learning methodology ‣
    Deep Learning for Computational Cytology: A Survey")). For slide-level screening,
    existing studies mainly divide this task into two stages: First, the deep neural
    network (e.g., CNN, RNN, and Transformer) is responsible for predicting multi-level
    results, such as detection of malignant or benign cells and the category of patches.
    Then, another network aggregates these results and predicts the final WSI-level
    results [[174](#bib.bib174), [86](#bib.bib86)].'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，细胞学图像的标签空间指其良性/恶性或子类别。在标准的细胞级分类工作流程中，细胞学家或技术人员从采集的切片中提取感兴趣区域（ROIs）。然后，ROIs被切割成细胞补丁作为深度模型的输入。之后，基于DL的特征提取器负责表示高级特征并输出预测类别（图[4](#S2.F4
    "图 4 ‣ 2 深度学习方法 ‣ 深度学习在计算细胞学中的应用：综述")）。对于切片级筛查，现有研究主要将此任务分为两个阶段：首先，深度神经网络（例如CNN、RNN和Transformer）负责预测多级结果，如恶性或良性细胞的检测和补丁的类别。然后，另一个网络汇总这些结果并预测最终的WSI级结果[[174](#bib.bib174),
    [86](#bib.bib86)]。
- en: 'Detection. Unlike classification, the detection task is to locate objects from
    whole images and predict categories of these objects. Thus, it can be regarded
    as the combination of two tasks: regressing the object’s location and classifying
    the types of objects. CNN-based object detection algorithms are mainly divided
    into two categories: two-stage method and one-stage method. In two-stage, the
    workflow includes feature extraction, region proposal, and prediction. The first
    stage is to regress coarse prediction (box location and predicted probability)
    by region proposal. The second stage aims to output fine predictions (box location
    and object category). Typical models for two-stage algorithms include R-CNN [[45](#bib.bib45)],
    Fast R-CNN [[44](#bib.bib44)], Faster R-CNN [[128](#bib.bib128)]. One-stage detection
    methods aim to abandon the strategy of region proposal. Instead, they directly
    predict the category and location of the objects in an end-to-end architecture,
    including SSD [[92](#bib.bib92)], YOLO [[127](#bib.bib127)], FCOS [[165](#bib.bib165)]
    and RetinaNet [[89](#bib.bib89)].'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 检测。与分类不同，检测任务是从整张图像中定位对象，并预测这些对象的类别。因此，它可以看作是两个任务的结合：回归对象的位置和分类对象的类型。基于CNN的目标检测算法主要分为两类：两阶段方法和单阶段方法。在两阶段方法中，工作流程包括特征提取、区域提议和预测。第一阶段通过区域提议回归粗略预测（框位置和预测概率）。第二阶段旨在输出精细预测（框位置和对象类别）。典型的两阶段算法模型包括R-CNN
    [[45](#bib.bib45)]、Fast R-CNN [[44](#bib.bib44)]、Faster R-CNN [[128](#bib.bib128)]。单阶段检测方法旨在摒弃区域提议策略，而是直接在端到端架构中预测对象的类别和位置，包括SSD
    [[92](#bib.bib92)]、YOLO [[127](#bib.bib127)]、FCOS [[165](#bib.bib165)]和RetinaNet
    [[89](#bib.bib89)]。
- en: 'There are two types of loss functions in object detection task, classification
    loss and location loss. For classification loss, by improving $L_{CE}$, focal
    loss $L_{focal}$ is proposed in RetinaNet to balance classification samples [[89](#bib.bib89)]:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在目标检测任务中，有两种类型的损失函数：分类损失和位置损失。对于分类损失，通过改进$L_{CE}$，在RetinaNet中提出了**焦点损失**$L_{focal}$来平衡分类样本[[89](#bib.bib89)]：
- en: '|  | $L_{focal}=\left\{\begin{array}[]{ccc}-\alpha(1-p)^{\gamma}\log(p),&amp;\text{if}&amp;y=1\\
    -(1-\alpha)p^{\gamma}\log(1-p),&amp;\text{if}&amp;y=0\end{array}\right.$ |  |
    (2) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|  | $L_{focal}=\left\{\begin{array}[]{ccc}-\alpha(1-p)^{\gamma}\log(p),&\text{if}&y=1\\
    -(1-\alpha)p^{\gamma}\log(1-p),&\text{if}&y=0\end{array}\right.$ |  | (2) |'
- en: 'where $p$ is the model’s estimated probability with label $y$, and $\gamma$
    and $\alpha$ are tunable parameters. For location loss, mean absolute error loss
    $L_{MAE}$ calculates the average distance between the predicted and the true locations:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$p$是模型对标签$y$的估计概率，$\gamma$和$\alpha$是可调参数。对于位置损失，均方绝对误差损失$L_{MAE}$计算预测位置与真实位置之间的平均距离：
- en: '|  | $L_{MAE}=\frac{\sum_{i=1}^{N}\left&#124;f\left(x_{i}\right)-y_{i}\right&#124;}{N}$
    |  | (3) |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | $L_{MAE}=\frac{\sum_{i=1}^{N}\left|f\left(x_{i}\right)-y_{i}\right|}{N}$
    |  | (3) |'
- en: 'Then, intersection over union (IoU) loss was introduced to calculate the loss
    of predicted boxes instead of coordinates in $L_{MAE}$ [[182](#bib.bib182)]:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，引入了**交并比（IoU）损失**来计算预测框的损失，而不是$L_{MAE}$中的坐标[[182](#bib.bib182)]：
- en: '|  | $L_{IoU}=-\ln\frac{\text{Intersection}\left(box_{gt},box_{p}\right)}{\text{
    Union }\left(box_{gt},box_{p}\right)}$ |  | (4) |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '|  | $L_{IoU}=-\ln\frac{\text{Intersection}\left(box_{gt},box_{p}\right)}{\text{
    Union }\left(box_{gt},box_{p}\right)}$ |  | (4) |'
- en: where $box_{gt}$ and $box_{p}$ represent ground truth box and predicted box,
    respectively. After that, some advanced loss functions are designed recently,
    including GIoU loss for non-intersection area [[129](#bib.bib129)], CIoU loss
    for closing center points [[192](#bib.bib192)], etc.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$box_{gt}$和$box_{p}$分别表示真实框和预测框。之后，最近设计了一些高级损失函数，包括用于非交集区域的GIoU损失[[129](#bib.bib129)]、用于闭合中心点的CIoU损失[[192](#bib.bib192)]等。
- en: In addition, there are still someFor example, fully common issues for both one-stage
    and two-stage algorithms. For example, multiple overlapping predicted boxes in
    the prediction results. These repetitive and redundant proposals can be removed
    by the strategy of non-maximum suppression [[114](#bib.bib114)].
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对于一阶段和两阶段算法，仍然存在一些普遍问题。例如，在预测结果中出现多个重叠的预测框。这些重复和冗余的建议可以通过非极大值抑制策略[[114](#bib.bib114)]来移除。
- en: 'Segmentation. This is a fundamental and essential task in medical image analysis.
    Segmentation is to make the pixel-wise prediction which represents the morphology
    of biomedical structures, such as cell [[194](#bib.bib194)], gland [[26](#bib.bib26)],
    and organ [[124](#bib.bib124)]. According to whether to distinguish each instance
    object, DL-based segmentation models can be divided into two branches: semantic
    segmentation and instance segmentation. Semantic segmentation aims to predict
    the category of each pixel to obtain masks of objects, which can be regarded as
    a pixel-wise classification task. Fully convolutional network (FCN) is one of
    the successful segmentation architectures, which replaced the fully connected
    layers in traditional CNN with convolutional layers for outputting segmentation
    map [[93](#bib.bib93)]. Then, [[41](#bib.bib41)] proposed U-Net for biomedical
    image segmentation by multi-scale feature fusion with a downsampling-upsampling
    architecture. In instance segmentation, models not only segment pixels into categories
    but also assigned them corresponding instance ID. Its popular structures mainly
    follow the detect-then-segment pipeline (Fig. [5](#S2.F5 "Fig. 5 ‣ 2.1 Supervised
    learning ‣ 2 Deep learning methodology ‣ Deep Learning for Computational Cytology:
    A Survey")). For instance, Mask R-CNN was proposed by introducing a mask prediction
    head based on Faster R-CNN [[51](#bib.bib51)].'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 分割。这是医学图像分析中的一项基本而重要的任务。分割是进行逐像素预测，以表示生物医学结构的形态，例如细胞[[194](#bib.bib194)]、腺体[[26](#bib.bib26)]和器官[[124](#bib.bib124)]。根据是否区分每个实例对象，基于深度学习的分割模型可以分为两个分支：语义分割和实例分割。语义分割旨在预测每个像素的类别，以获取对象的掩膜，这可以看作是一个逐像素分类任务。全卷积网络（FCN）是成功的分割架构之一，它将传统CNN中的全连接层替换为卷积层以输出分割图[[93](#bib.bib93)]。随后，[[41](#bib.bib41)]提出了U-Net，通过具有下采样-上采样架构的多尺度特征融合进行生物医学图像分割。在实例分割中，模型不仅将像素分割为类别，还分配了相应的实例ID。其流行的结构主要遵循先检测后分割的流程（图[5](#S2.F5
    "图 5 ‣ 2.1 监督学习 ‣ 2 深度学习方法 ‣ 计算细胞学的深度学习综述")）。例如，Mask R-CNN通过在Faster R-CNN基础上引入掩膜预测头[[51](#bib.bib51)]来提出。
- en: '![Refer to caption](img/af40f26a9365e86ed7235cc49b5ef848.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/af40f26a9365e86ed7235cc49b5ef848.png)'
- en: 'Fig. 5: Instance segmentation in cytology image analysis by Mask R-CNN.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：通过Mask R-CNN在细胞学图像分析中的实例分割。
- en: 'When training mentioned semantic and instance segmentation models, classification
    loss $L_{CE}$ is introduced as the pixel-wise classification supervision for segmentation.
    Another widely-used loss function, dice coefficient loss $L_{dice}$ is designed
    to measure the similarity between predicted masks $Y_{m}$ and ground truth $Y_{gt}$
    by calculating the dice coefficient, and is defined as [[107](#bib.bib107)]:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练提到的语义分割和实例分割模型时，分类损失$L_{CE}$被引入作为分割的逐像素分类监督。另一个广泛使用的损失函数，dice系数损失$L_{dice}$，旨在通过计算dice系数来衡量预测掩膜$Y_{m}$和真实值$Y_{gt}$之间的相似性，定义如下[[107](#bib.bib107)]：
- en: '|  | $L_{dice}=1-\frac{2&#124;Y_{m}\cap Y_{gt}&#124;}{&#124;Y_{m}&#124;+&#124;Y_{gt}&#124;}$
    |  | (5) |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | $L_{dice}=1-\frac{2\|Y_{m}\cap Y_{gt}\|}{\|Y_{m}\|+\|Y_{gt}\|}$ |  | (5)
    |'
- en: 2.2 Weakly supervised learning
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 弱监督学习
- en: Weakly supervised learning is proposed for the scenarios where labels are not
    fully available, including incomplete supervision, inaccurate supervision, and
    inexact supervision [[197](#bib.bib197)].
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 弱监督学习是为标签不完全可用的场景提出的，包括不完全监督、不准确监督和不精确监督[[197](#bib.bib197)]。
- en: '![Refer to caption](img/528b0924789c3074d708c4a1a77a6eab.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/528b0924789c3074d708c4a1a77a6eab.png)'
- en: 'Fig. 6: Overview of multiple instance learning paradigm. Original WSIs are
    extracted to ROIs and cut into patches, then they are formed instance bags with
    bag-level label (positive or negative). For learning algorithms, these bags are
    used to learn a classification function that can predict the labels of bags and
    instances in the testing data.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：多实例学习范式概述。原始WSI被提取为ROI并切割成补丁，然后它们被形成实例包，带有包级标签（正面或负面）。对于学习算法，这些包用于学习一个分类函数，该函数可以预测测试数据中包和实例的标签。
- en: Semi-supervised learning is one successful learning paradigm of incomplete supervision.
    It leverages both labeled and unlabeled data by extracting hidden information
    in unlabeled sets to enhance the feature representation of the labeled set. For
    inaccurate supervision, methods for noisy label problem can identify the potentially
    mislabeled samples and make corrections, thus improving the reliability of supervision.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习是一个成功的、不完全监督学习范式。它通过提取未标记集中的隐含信息来增强标记集的特征表示，从而利用标记和未标记的数据。对于不准确的监督，处理噪声标签问题的方法可以识别潜在的错误标记样本并进行修正，从而提高监督的可靠性。
- en: 'Multi-instance learning (MIL) is an effective inexact supervision method, which
    aims at utilizing coarse-level annotations (e.g., image-level) for learning fine-level
    (e.g., pixel-level, patch-level) tasks [[103](#bib.bib103), [179](#bib.bib179)].
    The standard workflow of MIL is illustrated in Fig. [6](#S2.F6 "Fig. 6 ‣ 2.2 Weakly
    supervised learning ‣ 2 Deep learning methodology ‣ Deep Learning for Computational
    Cytology: A Survey"). Firstly, a series of patches are extracted from whole images
    with patch-level annotations. Then, these patches are cut into instances and formed
    bags. Finally, a multi-instance classifier is established by learning for multi-instance
    bags, which is used for the prediction of unknown bags or instances. Specifically,
    given a training dataset $\{(X_{i},Y_{i})_{i=1}^{N}\}$, where $X_{i}=\left\{x_{i1},x_{i2},\ldots,x_{i,m}\right\}$
    are instance bags, $x_{i,m}$ is the $m\text{-}th$ instance of the $i\text{-}th$
    bag. $Y_{i}\in\{-1,+1\}$ is its corresponding label of the $i\text{-}th$ bag,
    +1 represents positive bag with at least one positive instance in this bag, and
    -1 represents negative bag with no positive instance. Then, bags $X_{i}$ together
    with labels are used to learn a classification function that can predict the labels
    of bags and instances.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 多实例学习（MIL）是一种有效的不精确监督方法，旨在利用粗粒度注释（例如图像级）来学习细粒度（例如像素级、补丁级）任务[[103](#bib.bib103),
    [179](#bib.bib179)]。MIL的标准工作流程如图[6](#S2.F6 "图6 ‣ 2.2 弱监督学习 ‣ 2 深度学习方法 ‣ 计算细胞学的深度学习：综述")所示。首先，从整个图像中提取一系列具有补丁级注释的补丁。然后，这些补丁被切割成实例并形成包。最后，通过学习多实例包建立一个多实例分类器，该分类器用于预测未知的包或实例。具体来说，给定一个训练数据集$\{(X_{i},Y_{i})_{i=1}^{N}\}$，其中$X_{i}=\left\{x_{i1},x_{i2},\ldots,x_{i,m}\right\}$是实例包，$x_{i,m}$是第$i$个包的第$m$个实例。$Y_{i}\in\{-1,+1\}$是第$i$个包的相应标签，+1表示该包中至少有一个正实例的正包，-1表示没有正实例的负包。然后，包$X_{i}$及其标签用于学习一个分类函数，该函数可以预测包和实例的标签。
- en: Weakly supervised learning is particularly appealing in computational cytology
    scenarios (e.g., whole slide thyroid malignancy prediction [[38](#bib.bib38)]),
    where full labels are expensive to obtain [[154](#bib.bib154)]. Because fully
    labeling of all lesions and cells in cytological screening WSIs is hardly possible
    for cytologists. Hence, weakly supervised learning is introduced to effectively
    represent and enhance features in the scenarios of limited annotations.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 弱监督学习在计算细胞学场景中特别吸引人（例如，整个切片的甲状腺恶性预测[[38](#bib.bib38)]），因为获得完整标签的成本很高[[154](#bib.bib154)]。因为对于细胞学家来说，完全标记所有病变和细胞几乎是不可能的。因此，引入了弱监督学习，以有效表示和增强在有限注释场景中的特征。
- en: 2.3 Unsupervised learning
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 无监督学习
- en: 'Unsupervised learning is effective for learning useful and underlying representations
    from unlabeled data, which can be utilized for downstream tasks. For example,
    unsupervised image augmentation can increase the amount and variety of original
    dataset for increasing the performance of classification models. Afterwards, unsupervised
    stain transformation can be adopted to normalize datasets in preprocessing pathology
    images. Auto-encoder (AE) is a typical structure in unsupervised learning, which
    is formulated as: $\mathrm{P}(x_{i})\rightarrow z\rightarrow\mathrm{P}\left(x_{i}^{\prime}\right)$,
    where AE is trained to encode the input image $x_{i}$ to obtain latent representation
    $z$. Then, decoders generate reconstructed image $x_{i}^{\prime}$ with the supervision
    of the raw input $x_{i}$.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习对于从未标记的数据中学习有用的和潜在的表示是有效的，这些表示可以用于下游任务。例如，无监督图像增强可以增加原始数据集的数量和多样性，从而提高分类模型的性能。之后，可以采用无监督染色转换来规范化病理图像的预处理数据集。自编码器（AE）是无监督学习中的典型结构，其公式为：$\mathrm{P}(x_{i})\rightarrow
    z\rightarrow\mathrm{P}\left(x_{i}^{\prime}\right)$，其中AE被训练以编码输入图像$x_{i}$以获得潜在表示$z$。然后，解码器在原始输入$x_{i}$的监督下生成重建图像$x_{i}^{\prime}$。
- en: 'Two typical unsupervised models have gained popularities: variational auto-encoder
    (VAE) [[75](#bib.bib75), [67](#bib.bib67)] and generative adversarial network
    (GAN) [[47](#bib.bib47)]. As shown in Fig. [7](#S2.F7 "Fig. 7 ‣ 2.3 Unsupervised
    learning ‣ 2 Deep learning methodology ‣ Deep Learning for Computational Cytology:
    A Survey")(A), VAE improved AE by constraining latent variables to be normally
    distributed, then sampling a latent vector into a decoder for outputting the image.
    GAN is another promising architecture that can mitigate the difficulty of collecting
    large-scale labeled medical datasets by synthesizing high-quality fake images.
    For its structure, GAN is formed by a generator-discriminator architecture, as
    shown in Fig. [7](#S2.F7 "Fig. 7 ‣ 2.3 Unsupervised learning ‣ 2 Deep learning
    methodology ‣ Deep Learning for Computational Cytology: A Survey")(B). The generator
    aims to generate realistic images, while the discriminator competes with generator
    to differentiate real images and generated images. Therefore, this generator-discriminator
    architecture is optimized via the adversarial training [[47](#bib.bib47)]:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '两种典型的无监督模型已经获得了广泛的关注：变分自编码器（VAE）[[75](#bib.bib75), [67](#bib.bib67)]和生成对抗网络（GAN）[[47](#bib.bib47)]。如图[7](#S2.F7
    "Fig. 7 ‣ 2.3 Unsupervised learning ‣ 2 Deep learning methodology ‣ Deep Learning
    for Computational Cytology: A Survey")(A)所示，VAE通过将潜在变量限制为正态分布来改进AE，然后将潜在向量输入解码器以输出图像。GAN是另一种有前途的架构，它通过合成高质量的虚假图像来缓解收集大规模标记医学数据集的困难。GAN的结构是由生成器-判别器架构组成，如图[7](#S2.F7
    "Fig. 7 ‣ 2.3 Unsupervised learning ‣ 2 Deep learning methodology ‣ Deep Learning
    for Computational Cytology: A Survey")(B)所示。生成器的目标是生成逼真的图像，而判别器则与生成器竞争以区分真实图像和生成图像。因此，该生成器-判别器架构通过对抗训练[[47](#bib.bib47)]进行优化：'
- en: '|  | $\begin{split}\min_{G}\max_{D}V(D,G)=\mathbb{E}_{x\sim p_{\text{data }}(x)}[\log
    D(x)]\\ +\mathbb{E}_{z\sim p_{\text{z }}(z)}[\log(1-D(G(z)))]\end{split}$ |  |
    (6) |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\min_{G}\max_{D}V(D,G)=\mathbb{E}_{x\sim p_{\text{data }}(x)}[\log
    D(x)]\\ +\mathbb{E}_{z\sim p_{\text{z }}(z)}[\log(1-D(G(z)))]\end{split}$ |  |
    (6) |'
- en: 'where $G(\cdot)$ denotes the generator, and $D(\cdot)$ denotes the discriminator.
    $\mathbb{E(\cdot)}$ is the expectation value of distribution, $p_{\text{data }}(x)$
    and $p_{\text{z }}(z)$ are the distribution of the real sample and noise, respectively.
    During training, generator $G(\cdot)$ aims to learn the distribution of real samples
    $p_{\text{data}}$, and discriminator $D(\cdot)$ is responsible for discriminating
    generated and real images, thus forcing the generator to generate realistic images.
    After the emergence of this basic GAN structure and adversarial loss, many advanced
    GAN models are proposed to satisfy higher requirements of generated images (e.g.,
    quality, fidelity, and diversity) [[180](#bib.bib180)]. For example, one promising
    architecture, CycleGAN is designed for style transformation between unpaired images
    ($s$, $t$), which is a symmetrical structure consisting of two generators $\{G_{S\rightarrow
    T},G_{T\rightarrow S}\}$ for mutual generation between two domains ($S$ and $T$),
    and two discriminators $\{D_{S},D_{T}\}$ for discriminating generated images of
    respective domains. In addition, cycle consistency loss $L_{cyc}(G_{S\rightarrow
    T},G_{T\rightarrow S})$ is designed for one-to-one mapping in CycleGAN architecture,
    defined as [[198](#bib.bib198)]:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $G(\cdot)$ 表示生成器，$D(\cdot)$ 表示判别器。$\mathbb{E(\cdot)}$ 是分布的期望值，$p_{\text{data
    }}(x)$ 和 $p_{\text{z }}(z)$ 分别是实际样本和噪声的分布。在训练过程中，生成器 $G(\cdot)$ 旨在学习真实样本 $p_{\text{data}}$
    的分布，而判别器 $D(\cdot)$ 负责区分生成的图像和真实图像，从而迫使生成器生成逼真的图像。在这种基本的 GAN 结构和对抗损失出现之后，许多高级
    GAN 模型被提出，以满足对生成图像（例如质量、保真度和多样性）的更高要求 [[180](#bib.bib180)]。例如，一种有前途的架构 CycleGAN
    被设计用于在未配对图像（$s$, $t$）之间进行风格转换，它是一个对称结构，包括两个生成器 $\{G_{S\rightarrow T},G_{T\rightarrow
    S}\}$ 用于两个领域（$S$ 和 $T$）之间的相互生成，以及两个判别器 $\{D_{S},D_{T}\}$ 用于区分各自领域的生成图像。此外，循环一致性损失
    $L_{cyc}(G_{S\rightarrow T},G_{T\rightarrow S})$ 被设计用于 CycleGAN 架构中的一对一映射，定义为
    [[198](#bib.bib198)]：
- en: '|  | $\begin{split}L_{cyc}(G_{S\rightarrow T},G_{T\rightarrow S})=\mathbb{E}_{s\sim
    p_{\text{data }}(x)}\left[\&#124;G_{T\rightarrow S}(G_{S\rightarrow T}(s))-s\&#124;_{1}\right]\\
    +\mathbb{E}_{t\sim p_{\text{data }}(y)}\left[\&#124;G_{S\rightarrow T}(G_{T\rightarrow
    S}(t))-t\&#124;_{1}\right]\end{split}$ |  | (7) |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}L_{cyc}(G_{S\rightarrow T},G_{T\rightarrow S})=\mathbb{E}_{s\sim
    p_{\text{data }}(x)}\left[\&#124;G_{T\rightarrow S}(G_{S\rightarrow T}(s))-s\&#124;_{1}\right]\\
    +\mathbb{E}_{t\sim p_{\text{data }}(y)}\left[\&#124;G_{S\rightarrow T}(G_{T\rightarrow
    S}(t))-t\&#124;_{1}\right]\end{split}$ |  | (7) |'
- en: where $p_{\text{data}}(s)$ and $p_{\text{data}}(t)$ are the distribution of
    images in domain $S$ and domain $T$.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p_{\text{data}}(s)$ 和 $p_{\text{data}}(t)$ 是域 $S$ 和域 $T$ 中图像的分布。
- en: In cytology, unsupervised learning algorithms have been designed for various
    DL tasks, such as stain conversion by CycleGAN [[164](#bib.bib164)], data augmentation
    for improving the accuracy of classification by cGAN [[35](#bib.bib35)], and generating
    high-resolution images by GAN-based super-resolution model [[99](#bib.bib99)].
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在细胞学中，无监督学习算法已经被设计用于各种深度学习任务，例如通过 CycleGAN 进行染色转换 [[164](#bib.bib164)]、通过 cGAN
    进行数据增强以提高分类准确性 [[35](#bib.bib35)]，以及通过基于 GAN 的超分辨率模型生成高分辨率图像 [[99](#bib.bib99)]。
- en: '![Refer to caption](img/e9b07f2c2f61117b0d4c6f3e1b3a42d4.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e9b07f2c2f61117b0d4c6f3e1b3a42d4.png)'
- en: 'Fig. 7: AE-based unsupervised learning models. (A) Variational auto-encoder
    (VAE) improved AE by constraining the latent representation to be the normal distribution.
    (B) Generative adversarial network (GAN), which consists of a generator and a
    discriminator. The generator is responsible for generating fake images from random
    noise while discriminator forcing the generator generating realistic images by
    discriminating generated fake image and real image.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：基于 AE 的无监督学习模型。（A）变分自编码器（VAE）通过将潜在表示约束为正态分布来改进 AE。（B）生成对抗网络（GAN），包括生成器和判别器。生成器负责从随机噪声中生成假图像，而判别器通过区分生成的假图像和真实图像来迫使生成器生成逼真的图像。
- en: 2.4 Transfer Learning
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 迁移学习
- en: Transfer learning is a subfield of deep learning that focuses on transferring
    knowledge from source to target domain for enhancing target tasks. Two transfer
    learning approaches are commonly used in medical image analysis, including fine-tuning
    and domain adaptation (DA).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是深度学习的一个子领域，专注于将知识从源领域转移到目标领域，以提升目标任务的性能。在医学图像分析中，常用的迁移学习方法包括微调和领域适应（DA）。
- en: Fine-tuning is regarded as a common model initialization trick for training
    DL models. It can reduce the overfitting issue and improve the generalization
    capability of deep models by transferring knowledge from large public datasets
    (e.g., ImageNet [[33](#bib.bib33)]) to domain-specific tasks (e.g., cervical cell
    classification) [[153](#bib.bib153), [181](#bib.bib181)]. Formally, the goal of
    fine-tuning is training a task $\mathcal{T}^{t}$ by a small dataset $T$. Specifically,
    it exploits a large-scale and task-similar $\mathcal{T}^{t}$ dataset $S=\{s_{i}\}_{i=1}^{M}(M>>N)$
    to pre-train a network $f(\sim;\theta)$ first, then a small target dataset $T=\{t_{i}\}_{i=1}^{N}$
    is used to train the several last layers of the pre-trained model for obtaining
    the target model $N_{t}$. Under the premise that different datasets for training
    similar tasks have similar low-level feature representations, fine-tuning is regarded
    as a common and effective training strategy in various DL tasks as well as cytology
    image analysis [[189](#bib.bib189)].
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 微调被认为是训练深度学习模型的常见模型初始化技巧。通过将知识从大型公共数据集（例如，ImageNet [[33](#bib.bib33)]）转移到领域特定任务（例如，宫颈细胞分类）[[153](#bib.bib153),
    [181](#bib.bib181)]，它可以减少过拟合问题并提高深度模型的泛化能力。正式来说，微调的目标是通过一个小数据集 $T$ 来训练一个任务 $\mathcal{T}^{t}$。具体而言，它首先利用一个大规模且任务相似的
    $\mathcal{T}^{t}$ 数据集 $S=\{s_{i}\}_{i=1}^{M}(M>>N)$ 来预训练一个网络 $f(\sim;\theta)$，然后使用一个小的目标数据集
    $T=\{t_{i}\}_{i=1}^{N}$ 来训练预训练模型的几层最后层，以获得目标模型 $N_{t}$。在训练类似任务的不同数据集具有相似的低级特征表示的前提下，微调被认为是一种常见且有效的训练策略，在各种深度学习任务以及细胞学图像分析中
    [[189](#bib.bib189)]。
- en: 'Domain adaptation (DA) is another transfer learning approach that transfers
    knowledge by learning to narrow the distribution gap of datasets in different
    domains. The paradigm of DA can be defined as: giving two different datasets ($T$
    and $S$) with different distributions ($p(S)\neq p(T)$), DA methods can align
    the distributions of these datasets by marginal, conditional or joint distribution
    adaptation. As a result, the knowledge is transferred from source to target domain,
    thus improving the performance of target models [[117](#bib.bib117)]. In medical
    image analysis, data heterogeneity hinders the successful practice of deep models
    in the clinic. This issue can be mitigated by domain adaptation for improving
    the validity and reproducibility of deep models clinically [[48](#bib.bib48)].'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 域自适应（DA）是另一种迁移学习方法，通过学习缩小不同领域的数据集的分布差距来转移知识。DA 的范式可以定义为：给定两个具有不同分布 ($p(S)\neq
    p(T)$) 的不同数据集（$T$ 和 $S$），DA 方法可以通过边际、条件或联合分布自适应来对齐这些数据集的分布。因此，知识从源领域转移到目标领域，从而改善目标模型的性能
    [[117](#bib.bib117)]。在医学图像分析中，数据异质性阻碍了深度模型在临床中的成功应用。通过域自适应可以缓解这个问题，从而提高深度模型在临床中的有效性和可重复性
    [[48](#bib.bib48)]。
- en: 'Table 1: Summary of publicly available and representative private databases
    in computational cytology'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：计算细胞学中公开和代表性私有数据库的总结
- en: '| Reference/Year | Task | Organ | Stain | Size | Description | Link |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 参考/年份 | 任务 | 器官 | 染色 | 尺寸 | 描述 | 链接 |'
- en: '| Herlev 2005 [[60](#bib.bib60)] | Classification | Cervix | Pap | variable
    | 917 cells | [http://mde-lab.aegean.gr/downloads](http://mde-lab.aegean.gr/downloads)
    |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| Herlev 2005 [[60](#bib.bib60)] | 分类 | 宫颈 | 巴氏涂片 | 变化 | 917 个细胞 | [http://mde-lab.aegean.gr/downloads](http://mde-lab.aegean.gr/downloads)
    |'
- en: '| ISBI 2014 [[95](#bib.bib95)] | Segmentation | Cervix | Pap | 512 × 512 |
    16 images (645 cells) | [https://github.com/luzhi/cellsegmentation_TIP2015](https://github.com/luzhi/cellsegmentation_TIP2015)
    |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| ISBI 2014 [[95](#bib.bib95)] | 分割 | 宫颈 | 巴氏涂片 | 512 × 512 | 16 张图像（645 个细胞）
    | [https://github.com/luzhi/cellsegmentation_TIP2015](https://github.com/luzhi/cellsegmentation_TIP2015)
    |'
- en: '| ISBI 2015 [[96](#bib.bib96)] | Segmentation | Cervix | Pap | 512 × 512 |
    945 images synthesized by ISBI 2014 | [http://goo.gl/KcpLrQ](http://goo.gl/KcpLrQ)
    |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| ISBI 2015 [[96](#bib.bib96)] | 分割 | 宫颈 | 巴氏涂片 | 512 × 512 | 945 张由 ISBI 2014
    合成的图像 | [http://goo.gl/KcpLrQ](http://goo.gl/KcpLrQ) |'
- en: '| Sipakmed 2018 [[123](#bib.bib123)] | Classification | Cervix | Pap | 2,048
    × 1,536 | 966 images (4,049 annotated cells) | [https://www.cs.uoi.gr/~marina/sipakmed.html](https://www.cs.uoi.gr/~marina/sipakmed.html)
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| Sipakmed 2018 [[123](#bib.bib123)] | 分类 | 宫颈 | 巴氏涂片 | 2,048 × 1,536 | 966
    张图像（4,049 个标注细胞） | [https://www.cs.uoi.gr/~marina/sipakmed.html](https://www.cs.uoi.gr/~marina/sipakmed.html)
    |'
- en: '| CERVIX93 2018 [[120](#bib.bib120)] | Classification Detection | Cervix |
    Pap | 1,280 × 960 | 93 stacks of images (2,705 nuclei) | [https://github.com/parham-ap/cytology_dataset](https://github.com/parham-ap/cytology_dataset)
    |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| CERVIX93 2018 [[120](#bib.bib120)] | 分类检测 | 宫颈 | 巴氏涂片 | 1,280 × 960 | 93
    叠图像（2,705 个细胞核） | [https://github.com/parham-ap/cytology_dataset](https://github.com/parham-ap/cytology_dataset)
    |'
- en: '| FNAC 2019 [[139](#bib.bib139)] | Classification | Breast | Pap | 2,048 ×
    1,536 | 212 images in two classes: benign (99) and malignant (113) | [https://1drv.ms/u/s!Al-T6d-_ENf6axsEbvhbEc2gUFs](https://1drv.ms/u/s!Al-T6d-_ENf6axsEbvhbEc2gUFs)
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| FNAC 2019 [[139](#bib.bib139)] | 分类 | 乳腺 | Pap | 2,048 × 1,536 | 212 张图像，分为两类：良性（99）和恶性（113）
    | [https://1drv.ms/u/s!Al-T6d-_ENf6axsEbvhbEc2gUFs](https://1drv.ms/u/s!Al-T6d-_ENf6axsEbvhbEc2gUFs)
    |'
- en: '| BHS 2019 [[6](#bib.bib6)] | Segmentation Ranking | Cervix | Pap | 1,392 ×
    1,040 | 194 images in classes of carcinoma, HSIL, LSIL, ASC-US and ASC-H | [https://sites.google.com/view/centercric](https://sites.google.com/view/centercric)
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| BHS 2019 [[6](#bib.bib6)] | 分割 排名 | 子宫颈 | Pap | 1,392 × 1,040 | 194 张图像，类别包括癌症、HSIL、LSIL、ASC-US
    和 ASC-H | [https://sites.google.com/view/centercric](https://sites.google.com/view/centercric)
    |'
- en: '| AgNOR 2020 [[4](#bib.bib4)] | Segmentation | Cervix | AgNOR | 1,600 × 1,200
    | 2,540 images (4,515 nuclei) | [https://arquivos.ufsc.br/d/373be2177a33426a9e6c/](https://arquivos.ufsc.br/d/373be2177a33426a9e6c/)
    |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| AgNOR 2020 [[4](#bib.bib4)] | 分割 | 子宫颈 | AgNOR | 1,600 × 1,200 | 2,540 张图像（4,515
    个细胞核） | [https://arquivos.ufsc.br/d/373be2177a33426a9e6c/](https://arquivos.ufsc.br/d/373be2177a33426a9e6c/)
    |'
- en: '| LBC 2020 [[55](#bib.bib55)] | Classification | Cervix | Pap | 2,048 × 1,536
    | 963 LBC images in classes of NILM, LSIL, HSIL, and SCC | [https://data.mendeley.com/datasets/zddtpgzv63/4](https://data.mendeley.com/datasets/zddtpgzv63/4)
    |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| LBC 2020 [[55](#bib.bib55)] | 分类 | 子宫颈 | Pap | 2,048 × 1,536 | 963 张 LBC
    图像，类别包括 NILM、LSIL、HSIL 和 SCC | [https://data.mendeley.com/datasets/zddtpgzv63/4](https://data.mendeley.com/datasets/zddtpgzv63/4)
    |'
- en: '| Oral 2021 [[105](#bib.bib105)] | Classification Detection Segmentation |
    Oral | Pap | 1,200 × 1,600 | 1,934 images (4,287 annotations) | [https://arquivos.ufsc.br/d/5035aec3c24f421a95d0/](https://arquivos.ufsc.br/d/5035aec3c24f421a95d0/)
    |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| Oral 2021 [[105](#bib.bib105)] | 分类 检测 分割 | 口腔 | Pap | 1,200 × 1,600 | 1,934
    张图像（4,287 个标注） | [https://arquivos.ufsc.br/d/5035aec3c24f421a95d0/](https://arquivos.ufsc.br/d/5035aec3c24f421a95d0/)
    |'
- en: '| Cric 2021 [[130](#bib.bib130)] | Classification | Cervix | Pap | 1,376 ×
    1,020 | 400 images (11,534 cells) | [https://database.cric.com.br](https://database.cric.com.br)
    |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| Cric 2021 [[130](#bib.bib130)] | 分类 | 子宫颈 | Pap | 1,376 × 1,020 | 400 张图像（11,534
    个细胞） | [https://database.cric.com.br](https://database.cric.com.br) |'
- en: '| CDetector 2021 [[83](#bib.bib83)] | Detection | Cervix | Pap | 224 × 224
    | 7,410 images (48,587 object instance bounding boxes) in 11 classes | [https://github.com/kuku-sichuan/ComparisonDetector](https://github.com/kuku-sichuan/ComparisonDetector)
    |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| CDetector 2021 [[83](#bib.bib83)] | 检测 | 子宫颈 | Pap | 224 × 224 | 7,410 张图像（48,587
    个物体实例边界框），共 11 个类别 | [https://github.com/kuku-sichuan/ComparisonDetector](https://github.com/kuku-sichuan/ComparisonDetector)
    |'
- en: '| Ascites 2020 [[155](#bib.bib155)] | Classification Detection | Stomach |
    H&E, Pap | 1,064 × 690 | 487 images for classification in two classes: malignant
    (18,558) and benign (6,089). 176 images for detection (6,573 annotated cell bounding
    boxes) | [https://pan.baidu.com/s/1r0cd0PVm5DiUmaNozMSxgg](https://pan.baidu.com/s/1r0cd0PVm5DiUmaNozMSxgg)
    |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| Ascites 2020 [[155](#bib.bib155)] | 分类 检测 | 胃 | H&E, Pap | 1,064 × 690 |
    487 张图像用于分类，分为恶性（18,558）和良性（6,089）两类。176 张图像用于检测（6,573 个标注细胞边界框） | [https://pan.baidu.com/s/1r0cd0PVm5DiUmaNozMSxgg](https://pan.baidu.com/s/1r0cd0PVm5DiUmaNozMSxgg)
    |'
- en: '| RSDC 2021 [[98](#bib.bib98)] | Super resolution | Cervix | Pap | 128 × 128
    (HR) 64 × 164 (LR) | 5 slides (25000 patches) | [https://www.kaggle.com/birkhoff007/rsdcdata](https://www.kaggle.com/birkhoff007/rsdcdata)
    |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| RSDC 2021 [[98](#bib.bib98)] | 超分辨率 | 子宫颈 | Pap | 128 × 128（高分辨率） 64 × 164（低分辨率）
    | 5 张切片（25,000 个补丁） | [https://www.kaggle.com/birkhoff007/rsdcdata](https://www.kaggle.com/birkhoff007/rsdcdata)
    |'
- en: '| IRNet 2019 [[195](#bib.bib195)] | Segmentation | Cervix | Pap | 1,000 × 1,000
    | 413 images (4,439 cytoplasm and 4,789 nuclei) | Private dataset |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| IRNet 2019 [[195](#bib.bib195)] | 分割 | 子宫颈 | Pap | 1,000 × 1,000 | 413 张图像（4,439
    个细胞质和 4,789 个细胞核） | 私有数据集 |'
- en: '| DCCL 2020 [[186](#bib.bib186)] | Detection | Cervix | Pap | 1,200 × 2,000
    | 1,167 WSIs (14,432 patches, and 27,972 labeled lesion cells) | Private dataset
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| DCCL 2020 [[186](#bib.bib186)] | 检测 | 子宫颈 | Pap | 1,200 × 2,000 | 1,167 张
    WSIs（14,432 个补丁和 27,972 个标注病变细胞） | 私有数据集 |'
- en: '| Dual 2021 [[86](#bib.bib86)] | Risk stratification | Cervix | Pap | Up to
    50,000 × 50,000 | 19,303 WSIs in two classes: abnormal (202,557) and normal (272,933)
    | Private dataset |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| Dual 2021 [[86](#bib.bib86)] | 风险分层 | 子宫颈 | Pap | 最多 50,000 × 50,000 | 19,303
    张 WSIs 分为两类：异常（202,557）和正常（272,933） | 私有数据集 |'
- en: '| Hybrid 2021 [[199](#bib.bib199)] | Classification Detection Segmentation
    | Cervix | Pap | 6000 × 6000 | 24 categories and 2000 images in each category,
    81,727 smears (1.7 million annotated targets) for detection model | Private dataset
    |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| Hybrid 2021 [[199](#bib.bib199)] | 分类 检测 分割 | 子宫颈 | Pap | 6000 × 6000 | 24
    个类别，每个类别 2000 张图像，81,727 个涂片（170 万个标注目标）用于检测模型 | 私有数据集 |'
- en: 3 Datasets and metrics
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 数据集和指标
- en: 'Deep learning relies on large amounts of labeled data, we summarize publicly
    available datasets as well as representative private datasets in cytology. As
    illustrated in Table [1](#S2.T1 "Table 1 ‣ 2.4 Transfer Learning ‣ 2 Deep learning
    methodology ‣ Deep Learning for Computational Cytology: A Survey"), the majority
    of public datasets are from the cervix, with a small number of other cancer types,
    such as breast, oral, and stomach. These publicly available cytology datasets
    can be used to develop deep learning algorithms for various tasks, including classification,
    detection, and segmentation.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '深度学习依赖于大量标记的数据，我们总结了细胞学中公开的可用数据集以及具有代表性的私有数据集。如表 [1](#S2.T1 "Table 1 ‣ 2.4
    Transfer Learning ‣ 2 Deep learning methodology ‣ Deep Learning for Computational
    Cytology: A Survey") 所示，大多数公开数据集来自宫颈，还有少量其他癌症类型，如乳腺、口腔和胃。这些公开的细胞学数据集可以用于开发深度学习算法，涵盖分类、检测和分割等各种任务。'
- en: 'Table 2: Summary of evaluation metrics in computational cytology'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：计算细胞学中评估指标的总结
- en: '| Metric | Definition | Description | Application in cytology |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 指标 | 定义 | 描述 | 细胞学中的应用 |'
- en: '| Classification |  |  |  |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 分类 |  |  |  |'
- en: '| TP/TN/FP/FN | True Positive, True Negative, False Positive, False Negative
    | A test result that correctly indicates the presence of a condition (TP), correctly
    indicates the absence of a condition (TF), wrongly indicates the presence of a
    particular condition (FP), wrongly indicates the absence of a particular condition
    (FN). | Classification of FNAC images; formulate other metrics (e.g., accuracy,
    precision, recall) [[142](#bib.bib142), [82](#bib.bib82)]. |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| TP/TN/FP/FN | 真阳性、真阴性、假阳性、假阴性 | 正确指示条件存在的测试结果（TP）、正确指示条件不存在的测试结果（TN）、错误指示特定条件存在的测试结果（FP）、错误指示特定条件不存在的测试结果（FN）。
    | FNAC图像分类；制定其他指标（例如准确率、精确度、召回率） [[142](#bib.bib142), [82](#bib.bib82)]。 |'
- en: '| Confusion matrix | A Matrix. Row: actual class; Column: predicted class.
    | The number of correct and incorrect predictions are summarized with count values
    and broken down by each class. | Classification of lung cancer sub-type; pap smear
    image; quantitative analysis of abnormalities; WSI-level risk stratification [[161](#bib.bib161),
    [110](#bib.bib110), [65](#bib.bib65), [7](#bib.bib7)]. |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 混淆矩阵 | 一个矩阵。行：实际类别；列：预测类别。 | 正确和错误预测的数量以计数值总结，并按每个类别分类。 | 肺癌亚型分类；宫颈涂片图像；异常的定量分析；WSI级风险分层
    [[161](#bib.bib161), [110](#bib.bib110), [65](#bib.bib65), [7](#bib.bib7)]。 |'
- en: '| Accuracy (Acc) | $\frac{TP+TN}{FP+FN+TP+TN}$ | Proportion of all positive
    and negative classes with correct predictions in all samples. | Cervical squamous
    lesions classification; FNAC image classification [[91](#bib.bib91), [9](#bib.bib9),
    [3](#bib.bib3)]. |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 (Acc) | $\frac{TP+TN}{FP+FN+TP+TN}$ | 所有样本中，所有正负类的正确预测比例。 | 宫颈鳞状病变分类；FNAC图像分类
    [[91](#bib.bib91), [9](#bib.bib9), [3](#bib.bib3)]。 |'
- en: '| Precision (P) | $\frac{TP}{FP+TP}$ | The proportion of positive samples classified
    as positive examples by the classifier. | Cervical cells classification; cervical
    lesions classification; multi-cell classification in liquid-based cytology images
    [[153](#bib.bib153), [91](#bib.bib91), [125](#bib.bib125)]. |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 精确度 (P) | $\frac{TP}{FP+TP}$ | 分类器将正样本分类为正例的比例。 | 宫颈细胞分类；宫颈病变分类；液基细胞学图像中的多细胞分类
    [[153](#bib.bib153), [91](#bib.bib91), [125](#bib.bib125)]。 |'
- en: '| Recall (R) | $\frac{TP}{FN+TP}$ | The proportion of the samples predicted
    to be positive cases in the total positive cases. | Pap smear image classification;
    classification of cervical cells [[110](#bib.bib110), [125](#bib.bib125)]. |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 召回率 (R) | $\frac{TP}{FN+TP}$ | 在所有正例中，被预测为正例的样本比例。 | 宫颈涂片图像分类；宫颈细胞分类 [[110](#bib.bib110),
    [125](#bib.bib125)]。'
- en: '| Specificity (Spec) | $\frac{TN}{FP+TN}$ | The proportion of samples that
    are correctly predicted as negative classes in all negative classes. | Cell classification;
    differential diagnosing of papillary thyroid carcinomas; detection of cervical
    intraepithelial neoplasia or invasive cancer [[189](#bib.bib189), [50](#bib.bib50),
    [10](#bib.bib10)]. |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 特异性 (Spec) | $\frac{TN}{FP+TN}$ | 所有负类样本中，正确预测为负类的样本比例。 | 细胞分类；乳头状甲状腺癌的差异诊断；宫颈上皮内瘤变或侵袭性癌症的检测
    [[189](#bib.bib189), [50](#bib.bib50), [10](#bib.bib10)]。 |'
- en: '| Sensitivity (Sens) | $\frac{TP}{FN+TP}$ | The proportion of the samples predicted
    to be positive cases in the total positive cases. | Distinguish large cell neuroendocrine;
    identify cells; high resolution image classification [[46](#bib.bib46), [79](#bib.bib79)].
    |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 敏感性 (Sens) | $\frac{TP}{FN+TP}$ | 在所有实际为正的样本中，预测为正的样本的比例。 | 区分大细胞神经内分泌；识别细胞；高分辨率图像分类
    [[46](#bib.bib46), [79](#bib.bib79)]。 |'
- en: '| F1-score (F1) | $\frac{2\times Precision\times Recall}{Precision+Recall}$
    =$\frac{2\times TP}{FP+FN+2TP}$ | Harmonic average of precision and recall, and
    it is defined as the final evaluation index in many classification tasks. | Classification
    of cervical cells; multi-cell classification in liquid-based cytology images;
    cell image ranking [[153](#bib.bib153), [6](#bib.bib6), [125](#bib.bib125)]. |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| F1 分数 (F1) | $\frac{2\times Precision\times Recall}{Precision+Recall}$ =$\frac{2\times
    TP}{FP+FN+2TP}$ | 精确率和召回率的调和平均值，在许多分类任务中被定义为最终评估指标。 | 宫颈细胞分类；液基细胞学图像中的多细胞分类；细胞图像排序
    [[153](#bib.bib153), [6](#bib.bib6), [125](#bib.bib125)]。 |'
- en: '| ROC curve | (FP rate, TP rate) | ROC is a graph showing the performance of
    a classification model at all classification thresholds. | Prediction of malignancy;
    cervical cancer screening; smear-level risk stratification [[40](#bib.bib40),
    [158](#bib.bib158), [86](#bib.bib86)]. |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| ROC 曲线 | (FP 率, TP 率) | ROC 是展示分类模型在所有分类阈值下性能的图形。 | 恶性预测；宫颈癌筛查；涂片级风险分层 [[40](#bib.bib40),
    [158](#bib.bib158), [86](#bib.bib86)]。 |'
- en: '| AUC | Area under the ROC curve | The closer the AUC is to 1, the better the
    classifier performance. | Cancer screening (cell-level detection, patch-level
    and case-level classification); quantitative analysis of abnormalities; automating
    the paris system for cytopathology [[169](#bib.bib169), [65](#bib.bib65), [20](#bib.bib20)].
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| AUC | ROC 曲线下面积 | AUC 越接近 1，分类器性能越好。 | 癌症筛查（细胞级检测、补丁级和病例级分类）；异常量化分析；自动化的巴黎系统细胞病理学
    [[169](#bib.bib169), [65](#bib.bib65), [20](#bib.bib20)]。 |'
- en: '| Detection |  |  |  |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 检测 |  |  |  |'
- en: '| IoU | $\frac{P\cap GT}{P\cup GT}$  $=\frac{TP}{FP+FN+TP}$ | $P$ denotes predicted
    bounding box, and GT is ground truth box. The ratio of the intersection and union
    of the predicted bounding box and the ground truth bounding box. | Nuclei/Cell
    detection; automation-assisted cervical cancer reading [[66](#bib.bib66), [177](#bib.bib177),
    [82](#bib.bib82)]. |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| IoU | $\frac{P\cap GT}{P\cup GT}$  $=\frac{TP}{FP+FN+TP}$ | $P$ 表示预测的边界框，GT
    是真实边界框。预测边界框和真实边界框的交集与并集的比率。 | 细胞/核检测；自动化辅助宫颈癌阅读 [[66](#bib.bib66), [177](#bib.bib177),
    [82](#bib.bib82)]。 |'
- en: '| AP | Average precision | The mean value of precision on precision-recall
    curve. | Detection of abnormal cervical cells [[20](#bib.bib20)]. |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| AP | 平均精度 | 精确度-召回曲线上的精度均值。 | 异常宫颈细胞的检测 [[20](#bib.bib20)]。 |'
- en: '| mAP | mean AP | Average of AP in all categories. | Cell/Clumps detection;
    quantification of pulmonary hemosiderophages [[104](#bib.bib104), [21](#bib.bib21),
    [83](#bib.bib83)]. |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| mAP | 平均 AP | 所有类别中的 AP 平均值。 | 细胞/团块检测；肺部含铁血黄素细胞的量化 [[104](#bib.bib104),
    [21](#bib.bib21), [83](#bib.bib83)]。 |'
- en: '| Segmentation |  |  |  |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 分割 |  |  |  |'
- en: '| Pixel Precision (P[p]) | $\frac{TP_{p}}{TP_{p}+FP_{p}}$ | The ${p}$ means
    this is a pixel-level metric. Proportion of correctly segmented pixels to all
    segmented pixels. | Cytological examination (overlapping cell segmentation) [[159](#bib.bib159)].
    |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 像素精确率 (P[p]) | $\frac{TP_{p}}{TP_{p}+FP_{p}}$ | ${p}$ 代表这是一个像素级指标。正确分割的像素在所有分割像素中的比例。
    | 细胞学检查（重叠细胞分割） [[159](#bib.bib159)]。 |'
- en: '| Pixel Recall (R[p]) | $\frac{TP_{p}}{TP_{p}+FN_{p}}$ | Proportion of correctly
    segmented pixels to all pixels in the ground truth. | Cytological examination
    (overlapping cell segmentation) [[159](#bib.bib159)]. |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 像素召回率 (R[p]) | $\frac{TP_{p}}{TP_{p}+FN_{p}}$ | 正确分割的像素在真实标注中的比例。 | 细胞学检查（重叠细胞分割）
    [[159](#bib.bib159)]。 |'
- en: '| Pixel Accuracy (Acc[p]) | $\frac{TP_{p}+TN_{p}}{FP_{p}+FN_{p}+TP_{p}+TN_{p}}$
    | Pixel level accuracy. | Segmentation of cytoplasm and nuclei [[150](#bib.bib150),
    [151](#bib.bib151), [65](#bib.bib65)]. |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 像素准确率 (Acc[p]) | $\frac{TP_{p}+TN_{p}}{FP_{p}+FN_{p}+TP_{p}+TN_{p}}$ | 像素级别的准确率。
    | 细胞质和细胞核的分割 [[150](#bib.bib150), [151](#bib.bib151), [65](#bib.bib65)]。 |'
- en: '| Hausdorff Distance | $\max(\sup\limits_{x\in X}d(x,Y)$, $\sup\limits_{y\in
    Y}d(X,y))$ | X and Y are two sets, $sup$ represents the supremum. It measures
    the similarity between two point sets. | Cell nuclei segmentation [[73](#bib.bib73)].
    |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| Hausdorff 距离 | $\max(\sup\limits_{x\in X}d(x,Y)$, $\sup\limits_{y\in Y}d(X,y))$
    | X 和 Y 是两个集合，$sup$ 表示上确界。它度量两个点集之间的相似性。 | 细胞核分割 [[73](#bib.bib73)]。 |'
- en: '| Dice coefficient (Dice) | $\frac{2\times TP}{FP+FN+2TP}$ | Dice coefficient
    is a statistical tool which measures the similarity between two sets of data.
    It can be used for comparing algorithm output against reference masks. | Semantic
    instance segmentation of touching and overlapping objects; cytoplasm segmentation;
    instance segmentation [[16](#bib.bib16), [172](#bib.bib172), [171](#bib.bib171)].
    |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| Dice系数 (Dice) | $\frac{2\times TP}{FP+FN+2TP}$ | Dice系数是一种统计工具，用于测量两个数据集之间的相似性。它可以用于比较算法输出与参考掩膜。
    | 触摸和重叠对象的语义实例分割；细胞质分割；实例分割 [[16](#bib.bib16), [172](#bib.bib172), [171](#bib.bib171)]。'
- en: '| Zijdenbos similarity index (ZSI) | $2\frac{\left&#124;R_{GT}\cap R_{Seg}\right&#124;}{\left&#124;R_{GT}\right&#124;+\left&#124;R_{Seg}\right&#124;}$
    | $R_{GT}$ and $R_{Seg}$ denote the ground truth and segmented regions, respectively.
    ZSI computes the ratio of aggregated union between cardinality predicted segmentation
    output and manual segmentation output. | Overlapping cell segmentation; cervical
    nuclei segmentation [[159](#bib.bib159), [56](#bib.bib56)]. |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| Zijdenbos相似性指数 (ZSI) | $2\frac{\left|R_{GT}\cap R_{Seg}\right|}{\left|R_{GT}\right|+\left|R_{Seg}\right|}$
    | $R_{GT}$和$R_{Seg}$分别表示地面真值和分割区域。ZSI计算预测分割输出和手动分割输出之间的聚合并集的比率。 | 重叠细胞分割；宫颈核分割
    [[159](#bib.bib159), [56](#bib.bib56)]。'
- en: '| Average Jaccard Index (AJI) | $\frac{\sum_{i=1}^{N}\left&#124;G_{i}\cap P_{M}^{i}\right&#124;}{\sum_{i=1}^{N}\left&#124;G_{i}\cup
    P_{M}^{i}\right&#124;+\sum_{F\in U}\left&#124;P_{F}\right&#124;}$ | $G_{i}$ is
    the $i\text{-}{th}$ object from the ground truth with $N$ objects. $P_{M}^{i}$
    means the $M\text{-}{th}$ connected component in prediction which has the largest
    Jaccard Index with $G_{i}$. AJI measures the ratio of the aggregated intersection
    and aggregated union for all the predictions and ground truths in the image. |
    Cell segmentation [[195](#bib.bib195)]. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 平均Jaccard指数 (AJI) | $\frac{\sum_{i=1}^{N}\left|G_{i}\cap P_{M}^{i}\right|}{\sum_{i=1}^{N}\left|G_{i}\cup
    P_{M}^{i}\right|+\sum_{F\in U}\left|P_{F}\right|}$ | $G_{i}$是来自地面真值的第$i$个对象，共有$N$个对象。$P_{M}^{i}$表示预测中与$G_{i}$具有最大Jaccard指数的第$M$个连通组件。AJI测量图像中所有预测和地面真值的聚合交集与聚合并集的比率。
    | 细胞分割 [[195](#bib.bib195)]。'
- en: Herlev [[60](#bib.bib60)]. This database consists of 917 Papanicolaou (Pap)
    smear cervical images in 7 classes (3 normal cell classes and 4 abnormal cell
    classes), which are collected from the Herlev University Hospital. As the earliest
    established public cytology dataset, Herlev dataset is extensively adopted for
    developing DL-based coarse and fine-grained classification models for cervical
    cancer screening [[189](#bib.bib189), [87](#bib.bib87)].
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Herlev [[60](#bib.bib60)]。该数据库包含917张Papanicolaou（Pap）涂片宫颈图像，分为7类（3类正常细胞和4类异常细胞），这些图像来自Herlev大学医院。作为最早建立的公共细胞学数据集，Herlev数据集被广泛用于开发基于深度学习的宫颈癌筛查粗粒度和细粒度分类模型
    [[189](#bib.bib189), [87](#bib.bib87)]。
- en: ISBI 2014 [[95](#bib.bib95)]. Another widely developed cervical dataset comes
    from the ISBI challenge. Different from Herlev dataset, this dataset focuses on
    the segmentation task with pixel-wise annotations. It consists of 16 non-overlapping
    fields of view images (×40 magnification) with 645 cells obtained from four cervical
    cytology specimens. Each sample in this dataset contains 20 to 60 Pap-stained
    cervical cells with varying degrees of overlapping.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ISBI 2014 [[95](#bib.bib95)]。另一个广泛开发的宫颈数据集来自ISBI挑战。与Herlev数据集不同，这个数据集专注于具有像素级注释的分割任务。它包含16张无重叠视野的图像（×40放大），从四个宫颈细胞学标本中获得，共有645个细胞。该数据集中的每个样本包含20到60个Pap染色的宫颈细胞，具有不同程度的重叠。
- en: ISBI 2015 [[96](#bib.bib96)]. ISBI 2015 extends ISBI 2014 dataset to 945 cervical
    cytology images by synthesizing. ISBI 2015 has a varying number of cells and different
    degrees of cell overlapping (size of 512 × 512 pixels), which contains 45 training
    images (taken from the 4 extended depth field images) and 900 testing images (from
    12 images).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ISBI 2015 [[96](#bib.bib96)]。ISBI 2015通过合成将ISBI 2014数据集扩展到了945张宫颈细胞学图像。ISBI
    2015具有不同数量的细胞和不同程度的细胞重叠（尺寸为512 × 512像素），其中包含45张训练图像（来自4张扩展深度场图像）和900张测试图像（来自12张图像）。
- en: Sipakmed [[123](#bib.bib123)]. This database consists of 4049 images of isolated
    cells that have been manually cropped from 966 cluster cell images of Pap smear
    slides. Sipakmed dataset has 5 types of cervical cells, including superficial-intermediate,
    parabasal, koilocytotic, dyskeratotic, and metaplastic cells.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Sipakmed [[123](#bib.bib123)]。该数据库包含4049张从966张Pap涂片幻灯片中的集群细胞图像中手动裁剪出来的孤立细胞图像。Sipakmed数据集具有5种类型的宫颈细胞，包括表面-中间、基底、空泡、异性角质形成细胞和化生细胞。
- en: 'CERVIX93 [[120](#bib.bib120)]. This is the first dataset established for nuclei
    detection tasks in cytology. It consists of 93 stacks of images at 40$\times$
    magnification. Each stack has 10-20 images acquired at the equally spaced field
    of views from the top to the bottom of the slide. In this dataset, 2705 nuclei
    are annotated by bounding boxes with three different Pap test grades: negative,
    low-grade squamous in the intraepithelial lesion (LSIL) or high-grade squamous
    intraepithelial lesion (HSIL).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: CERVIX93 [[120](#bib.bib120)]。这是第一个为细胞学中的核检测任务建立的数据集。它包含93个以40$\times$放大倍数拍摄的图像堆叠。每个堆叠有10-20张从幻灯片顶部到底部等间隔视野拍摄的图像。在这个数据集中，2705个核被标注为边界框，并具有三种不同的Pap测试等级：阴性、低级鳞状上皮内病变（LSIL）或高级鳞状上皮内病变（HSIL）。
- en: FNAC [[139](#bib.bib139)]. This is the only public breast cytology dataset developed
    for classification model. These breast images are collected from 20 patients,
    comprising of 212 fine-needle aspiration cell inspection images in classes of
    benign (99) and malignant (113).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: FNAC [[139](#bib.bib139)]。这是唯一一个为分类模型开发的公共乳腺细胞学数据集。这些乳腺图像收集自20名患者，包括212张细针穿刺细胞检查图像，分为良性（99）和恶性（113）类别。
- en: 'BHS [[6](#bib.bib6)]. It collects 194 Pap-smear cervical slides from the Brazilian
    Health System (BHS). Among them, 108 images have at least one abnormal cell and
    86 images with normal cells only. In sum, it has 5 types of abnormalities: carcinoma,
    HSIL, LSIL, atypical squamous cells of undetermined significance (ASC-US) and
    atypical squamous cells cannot exclude HSIL (ASC-H).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: BHS [[6](#bib.bib6)]。它收集了194张来自巴西卫生系统（BHS）的Pap涂片宫颈幻灯片。其中，108张图像至少有一个异常细胞，86张图像仅有正常细胞。总的来说，它有5种异常类型：癌症、HSIL、LSIL、未确定意义的典型鳞状细胞（ASC-US）和无法排除HSIL的典型鳞状细胞（ASC-H）。
- en: AgNOR [[4](#bib.bib4)]. The dataset is composed of 2540 images with $1200\times
    1600$ pixels each. Different from other public cervical datasets, it contains
    cells stained with the silver technique, which is known as argyrophilic nucleolar
    organizer regions (AgNOR). For developing segmentation approaches, experts annotate
    objects by the Labelme tool [[138](#bib.bib138)], including nuclei, clusters,
    and satellites.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: AgNOR [[4](#bib.bib4)]。该数据集由2540张$1200\times 1600$像素的图像组成。与其他公共宫颈数据集不同，它包含用银染技术染色的细胞，即银亲核小体组织区域（AgNOR）。为了开发分割方法，专家使用Labelme工具[[138](#bib.bib138)]对对象进行标注，包括细胞核、簇和卫星。
- en: 'LBC [[55](#bib.bib55)]. Recently, liquid-based cytology (LBC) is developed
    for providing more uniform fixation with a cleaner background and well-preserved
    samples than conventional Pap smear tests. This dataset consists of 963 images
    with four classes: NILM, LSIL, HSIL, and squamous cell carcinoma (SCC).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: LBC [[55](#bib.bib55)]。最近，液基细胞学（LBC）被开发出来，以提供比传统Pap涂片测试更均匀的固定、更干净的背景和保存良好的样本。这个数据集包含963张图像，分为四类：NILM、LSIL、HSIL和鳞状细胞癌（SCC）。
- en: Oral [[105](#bib.bib105)]. Totally, 1,934 oral images of $1200\times 1600$ pixels
    are acquired from two Pap-stained slides of cancer diagnosed oral brush samples.
    With different types of annotation (category, box, mask), various DL tasks can
    be conducted by this dataset, including classification, detection, and segmentation.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Oral [[105](#bib.bib105)]。总共获得了1,934张$1200\times 1600$像素的口腔图像，来自于两张癌症诊断的Pap染色刷样品幻灯片。通过不同类型的标注（类别、框、掩模），这个数据集可以进行各种深度学习任务，包括分类、检测和分割。
- en: 'CRIC [[130](#bib.bib130)]. The collection CRIC cervix has 400 images of pap
    smears with 11,534 classified cells. Based on the Bethesda system [[113](#bib.bib113)],
    CRIC dataset covers conventional cytology cervical cells with six types: NILM
    (6,779), ASC-US (606), LSIL (1,360), ASC-H (925), HSIL (1,703), and SCC (161).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: CRIC [[130](#bib.bib130)]。CRIC宫颈数据集中包含400张Pap涂片图像和11,534个已分类细胞。根据Bethesda系统[[113](#bib.bib113)]，CRIC数据集涵盖了六种类型的常规细胞学宫颈细胞：NILM（6,779）、ASC-US（606）、LSIL（1,360）、ASC-H（925）、HSIL（1,703）和SCC（161）。
- en: 'CDetector [[83](#bib.bib83)]. This dataset consists of 7,410 cervical images
    cropped from the WSIs. According to the Bethesda system (TBS), 48,587 object instance
    bounding boxes are annotated by experienced pathologists which belong to 11 categories:
    ASC-US, ASC-H, HSIL, LSIL, SCC, atypical glandular cells (AGC), trichomonas (TRICH),
    candida (CAND), flora, herps, actinomyces (ACTIN). Till now, CDetector is the
    largest public dataset for the object detection task in cytology.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: CDetector [[83](#bib.bib83)]。这个数据集由7,410幅从WSI中裁剪出来的宫颈图像组成。根据Bethesda系统（TBS），48,587个对象实例边界框由经验丰富的病理学家标注，属于11个类别：ASC-US、ASC-H、HSIL、LSIL、SCC、非典型腺细胞（AGC）、滴虫（TRICH）、念珠菌（CAND）、菌群、单纯疱疹、放线菌（ACTIN）。截至目前，CDetector
    是用于细胞学目标检测任务的最大公共数据集。
- en: Ascites [[155](#bib.bib155)]. This dataset is established for screening gastric
    cancer and collected from Peking University. It consists of 176 H&E stained and
    Pap stained images cropped from ascites cytopathology images at 40 × magnification.
    A total of 6573 cells (benign and malignant) are annotated using bounding boxes.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 腹水 [[155](#bib.bib155)]。这个数据集用于胃癌筛查，来自北京大学。它包含了176幅H&E染色和Pap染色的图像，这些图像是在40 ×
    放大倍数下从腹水细胞病理图像中裁剪出来的。总共有6573个细胞（良性和恶性）通过边界框进行了标注。
- en: RSDC [[98](#bib.bib98)]. It is the only public cytology dataset for developing
    the refocusing and super-resolution task. The images in the dataset are collected
    from 5 LBC slides with the resolution 0.243$\mu m/pixel$. Strategies of bicubic
    interpolation and gaussian blur are used to generate 15,000 low-resolution images
    (64 × 64) and corresponding high-resolution images (128 × 128) from original slides.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: RSDC [[98](#bib.bib98)]。这是开发重新聚焦和超分辨率任务的唯一公共细胞学数据集。数据集中的图像来自5张LBC切片，分辨率为0.243$\mu
    m/pixel$。使用了双三次插值和高斯模糊策略，从原始切片生成了15,000张低分辨率图像（64 × 64）和对应的高分辨率图像（128 × 128）。
- en: 'Furthermore, to evaluate the performance of proposed deep learning models,
    we summarize the evaluation metrics in terms of three canonical DL approaches:
    classification, detection, and segmentation along with typical cytological applications
    adopting these metrics, more details are shown in Table [2](#S3.T2 "Table 2 ‣
    3 Datasets and metrics ‣ Deep Learning for Computational Cytology: A Survey").'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，为了评估提出的深度学习模型的性能，我们总结了三种典型深度学习方法的评估指标：分类、检测和分割，以及采用这些指标的典型细胞学应用，更多细节见表 [2](#S3.T2
    "Table 2 ‣ 3 Datasets and metrics ‣ Deep Learning for Computational Cytology:
    A Survey")。'
- en: Among these summarized evaluation metrics, classification metrics evaluate the
    classifier’s capability of predicting the category. Accuracy is the most straightforward
    metric, yet it ignores the imbalance problem between different categories. The
    confusion matrix can represent the prediction result of each category. To measure
    the detection task, $IoU$ is a commonly-used metric, which can measure the overlap
    between the predicted box and the ground truth box. Based on various set thresholds,
    average precision ($AP$) is utilized to evaluate the performance of the detector
    in different overlapping levels, including $AP_{50}$, $AP_{75}$, etc. Segmentation
    models can be evaluated by various metrics. For example, $Pixel\ accuracy$ measures
    the predicted result of each pixel, and $Dice$ calculates the similarity coefficient
    of predicted masks and ground truth.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些总结的评估指标中，分类指标评估分类器预测类别的能力。准确率是最直接的指标，但它忽略了不同类别之间的不平衡问题。混淆矩阵可以表示每个类别的预测结果。为了衡量检测任务，$IoU$
    是一个常用的指标，它可以衡量预测框和真实框之间的重叠程度。根据不同的设置阈值，平均精度（$AP$）被用来评估检测器在不同重叠水平下的性能，包括 $AP_{50}$、$AP_{75}$
    等。分割模型可以通过各种指标进行评估。例如，$Pixel\ accuracy$ 测量每个像素的预测结果，而 $Dice$ 计算预测掩膜和真实情况的相似系数。
- en: 4 Deep learning in cytology application
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 细胞学应用中的深度学习
- en: 'In this section, we survey and summarize literatures on various deep learning
    models applied in computational cytology. Firstly, we introduce preprocessing
    techniques in cytology image analysis, followed by representative clinical tasks:
    classification, detection, segmentation, and others. More details of these surveyed
    literatures are as follows.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们调查和总结了应用于计算细胞学的各种深度学习模型的文献。首先，我们介绍了细胞学图像分析中的预处理技术，然后是代表性的临床任务：分类、检测、分割等。这些调查文献的更多细节如下。
- en: 4.1 Preprocessing
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 预处理
- en: Staining techniques. In cytology, staining techniques are introduced to enhance
    the image features of cells (e.g., texture, structure, and biochemical properties)
    for visually presenting cellular structures.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 染色技术。在细胞学中，引入染色技术是为了增强细胞图像的特征（例如，纹理、结构和生化性质），以便更清晰地展示细胞结构。
- en: 'Fig. [8](#S4.F8 "Fig. 8 ‣ 4.1 Preprocessing ‣ 4 Deep learning in cytology application
    ‣ Deep Learning for Computational Cytology: A Survey") shows various staining
    techniques in cytology. 1) Pap. As the extensive staining protocols, it has four
    steps: fixation, nuclear staining, cytosol staining, and transparency. Cell stained
    by Pap has a clearly-structured nucleus and transparent cytoplasm. According to
    surveyed literatures, Pap is the most common staining method in cytology images,
    especially in cervical cancer. 2) Hematoxylin and Eosin (H&E). Hematoxylin stains
    cell nuclei purplish-blue, and eosin stains the extracellular matrix and cytoplasm
    pink. In the clinic, H&E is mainly used for staining cells and tissues. 3) Giemsa.
    It is particularly effective for staining cytoplasm, so Giemsa is mainly used
    for blood and bone marrow cytological evaluation. Other staining techniques are
    used for some specific situations. For example, [[4](#bib.bib4)] stained cervical
    cells by AgNOR to present cell proliferation, differentiation, and malignant transformation.
    In another work, [[177](#bib.bib177)] stained cervical specimens of LBC by Feulgen.
    [[104](#bib.bib104)] stained pulmonary hemosiderophages cytology by Perlss’ Prussian
    Blue, Turnbull’s Blue.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '图[8](#S4.F8 "Fig. 8 ‣ 4.1 Preprocessing ‣ 4 Deep learning in cytology application
    ‣ Deep Learning for Computational Cytology: A Survey")展示了细胞学中的各种染色技术。1) Pap。作为一种广泛应用的染色方案，它包含四个步骤：固定、核染色、细胞质染色和透明化。Pap染色的细胞具有结构清晰的细胞核和透明的细胞质。根据调查的文献，Pap是细胞学图像中最常用的染色方法，尤其是在宫颈癌的研究中。2)
    苏木精-伊红（H&E）。苏木精将细胞核染成紫蓝色，而伊红则将细胞外基质和细胞质染成粉红色。在临床上，H&E主要用于染色细胞和组织。3) Giemsa。它特别有效于染色细胞质，因此Giemsa主要用于血液和骨髓细胞学评估。其他染色技术用于一些特定的情况。例如，[[4](#bib.bib4)]使用AgNOR染色宫颈细胞以展示细胞增殖、分化和恶性转化。在另一项工作中，[[177](#bib.bib177)]用Feulgen染色了LBC的宫颈标本。[[104](#bib.bib104)]用Perlss’普鲁士蓝和Turnbull’s蓝染色了肺部含铁细胞的细胞学。'
- en: '![Refer to caption](img/9850e9ac50d060503f93bb5fbd95e0a1.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9850e9ac50d060503f93bb5fbd95e0a1.png)'
- en: 'Fig. 8: Staining techniques. (A) Pap [[195](#bib.bib195)]. (B) H&E [[155](#bib.bib155)].
    (C) Giemsa [[9](#bib.bib9)]. (D) Feulgen [[177](#bib.bib177)]. (E) AgNOR [[4](#bib.bib4)].
    (F) Diff-quik [[46](#bib.bib46)].'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：染色技术。（A）Pap [[195](#bib.bib195)]。（B）H&E [[155](#bib.bib155)]。（C）Giemsa [[9](#bib.bib9)]。（D）Feulgen
    [[177](#bib.bib177)]。（E）AgNOR [[4](#bib.bib4)]。（F）Diff-quik [[46](#bib.bib46)]。
- en: Stain Normalization. A significant amount of color variations exist in cytology
    images due to various staining techniques mentioned and other issues (e.g., imaging
    environment). These differences bring challenges for building robust and generated
    DL-based cytology models. Besides, normalization can accelerate the convergence
    when training networks. Therefore, normalization can be a crucial preprocessing
    step, especially when analyzing stained images, like cytology images, and histopathology
    images. Commonly-used methods include whiting for removing redundant information
    from input data, and linear normalization for scaling gray values of input data,
    etc.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 染色归一化。由于上述各种染色技术以及其他问题（例如，成像环境），细胞学图像中存在显著的颜色变化。这些差异给构建稳健的深度学习（DL）细胞学模型带来了挑战。此外，归一化可以加速训练网络的收敛。因此，归一化可以成为一个关键的预处理步骤，特别是在分析染色图像时，如细胞学图像和组织病理图像。常用的方法包括用于去除输入数据中冗余信息的白化和用于缩放输入数据灰度值的线性归一化等。
- en: Data augmentation. When the amount of images is not sufficient to learn a robust
    DL model, especially for medical images. Data augmentation strategies are introduced
    to increase the amount of input images for improving the model’s generalization.
    Conventional augmentation methods include geometric transformation (e.g., flipping,
    rotating, and scaling) and color transformation (e.g., noise, blurring, and contrast).
    Recently, generative adversarial network (GAN) has been adopted to synthesize
    a large-scale dataset based on a limited set. [[183](#bib.bib183)] utilized GAN
    to generate 16,000 images from 961 real images for improving cervical cell classification
    models. In another study, [[35](#bib.bib35)] generated 180 images by conditional
    GAN and learnable class-specific priors for improving classifier performance on
    cytology tasks. To overcome the data limitation issue, [[162](#bib.bib162)] proposed
    a GAN-based augmentation structure, progressive growing of GANs (PGGAN). In this
    study, real lung cytological images together with synthesized images by PGGAN
    are used to train classification CNNs, leading to the performance improvements
    in cytology image classification.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强。当图像数量不足以学习一个稳健的 DL 模型时，尤其是在医学图像中。数据增强策略被引入以增加输入图像的数量，从而提高模型的泛化能力。传统的增强方法包括几何变换（例如，翻转、旋转和缩放）和颜色变换（例如，噪声、模糊和对比度）。近年来，生成对抗网络（GAN）已被采用，以基于有限的图像集合成大规模数据集。[[183](#bib.bib183)]
    利用 GAN 从961张真实图像中生成了16,000张图像，以改善宫颈细胞分类模型。在另一项研究中，[[35](#bib.bib35)] 通过条件 GAN
    生成了180张图像，并学习了特定类别的先验知识，以提高分类器在细胞学任务中的表现。为了克服数据限制问题，[[162](#bib.bib162)] 提出了基于
    GAN 的增强结构——渐进式 GAN（PGGAN）。在这项研究中，真实的肺细胞图像与通过 PGGAN 合成的图像一起用于训练分类 CNN，从而提升了细胞学图像分类的性能。
- en: 4.2 Classification
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 分类
- en: 'In cytology, the DL approaches are feasible and promising for image classification
    with distinguishable characteristics of cytology samples. The clinical cytologists
    can distinguish between benign and malignant cells based on their cytological
    features. For example, the abnormalities are displayed in malignant cells, such
    as larger and irregular nuclei, enlarged nuclear-cytoplasmic ratio, and the altered
    shape of the nucleolus. Within cytology image classification tasks, DL-based models
    aim to extract the underlying patterns of input images for identifying objects
    (e.g., nucleus, cell) or making slide-level predictions (e.g., cytopathology screening).
    Therefore, we further divide the cytological classification task into two categories:
    1) cell-level, 2) slide-level.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在细胞学中，DL 方法在具有可区分细胞学样本特征的图像分类中是可行且有前景的。临床细胞学家可以根据细胞学特征区分良性和恶性细胞。例如，恶性细胞显示出异常，如较大且不规则的细胞核、增大的核质比和改变的核仁形状。在细胞学图像分类任务中，基于
    DL 的模型旨在提取输入图像的潜在模式，以识别对象（例如，细胞核、细胞）或进行幻灯片级预测（例如，细胞病理筛查）。因此，我们进一步将细胞学分类任务分为两类：1）细胞级，2）幻灯片级。
- en: 'Table 3: Overview of deep learning-based classification studies for computational
    cytology'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：基于深度学习的计算细胞学分类研究概述
- en: '| Reference | Application | Staining | Organ | Method | Dataset | Result |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 应用 | 染色 | 器官 | 方法 | 数据集 | 结果 |'
- en: '| Cell-level classification |  |  |  |  |  |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 细胞级分类 |  |  |  |  |  |'
- en: '| [[189](#bib.bib189)] | Cell classification | Pap H&E | Cervix | Data preprocessing
    (patch extraction, data augmentation) + CNN + Transfer learning (fine-tune) |
    Herlev; HEMLBC | Herlev: Sens=0.982, Spec=0.983, Acc=0.983, F1=0.988, AUC=0.998;
          HEMLBC: Sens=0.983, Spec=0.990, Acc=0.986. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| [[189](#bib.bib189)] | 细胞分类 | Pap H&E | 子宫颈 | 数据预处理（补丁提取、数据增强）+ CNN + 迁移学习（微调）
    | Herlev；HEMLBC | Herlev: Sens=0.982, Spec=0.983, Acc=0.983, F1=0.988, AUC=0.998；HEMLBC:
    Sens=0.983, Spec=0.990, Acc=0.986。 |'
- en: '| [[161](#bib.bib161)] | Classification of cancer types (adenocarcinoma, squamous
    cell carcinoma, and small cell carcinoma) | Pap | Lung | Data augmentation + CNN
    | Private dataset: 76 images in classes of adenocarcinoma (40), squamous cell
    carcinoma (20), and small cell carcinoma (16) | Adenocarcinoma: Acc=0.89; Squamous
    cell carcinoma: Acc=0.600; Small cell carcinoma: Acc=0.703; Total: Acc=0.711.
    |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| [[161](#bib.bib161)] | 癌症类型分类（腺癌、鳞状细胞癌和小细胞癌） | Pap | 肺 | 数据增强 + CNN | 私有数据集：腺癌（40张）、鳞状细胞癌（20张）和小细胞癌（16张）共76张图像
    | 腺癌：Acc=0.89；鳞状细胞癌：Acc=0.600；小细胞癌：Acc=0.703；总计：Acc=0.711。 |'
- en: '| [[36](#bib.bib36)] | Cell classification | Pap | Nasal | Three-block CNN
    | Private dataset: 3,423 images (cell) | Sens=0.97, Acc=0.99. |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| [[36](#bib.bib36)] | 细胞分类 | Pap | 鼻部 | 三层卷积神经网络 | 私有数据集：3,423 张图像（细胞） | Sens=0.97,
    Acc=0.99. |'
- en: '| [[144](#bib.bib144)] | Malignancy detection and classification | Pap | Cervix
    | Three-layer CNN | Herlev | 5-class: Acc=0.941; 4-class: Acc=0.962; 3-class:
    Acc=0.948; 2-class: Acc=0.957. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| [[144](#bib.bib144)] | 恶性肿瘤检测和分类 | Pap | 宫颈 | 三层卷积神经网络 | Herlev | 5 类：Acc=0.941;
    4 类：Acc=0.962; 3 类：Acc=0.948; 2 类：Acc=0.957. |'
- en: '| [[163](#bib.bib163)] | Classification of benign and malignant cells | Pap
    | Lung | Data augmentation + VGG-16 + GradCAM | Private dataset: 621 images (patch)
    in classes of benign (306) and malignant (315) | Patch-level: Acc=0.792, AUC=0.872;
    Case-level: Acc=0.870, AUC=0.932. |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| [[163](#bib.bib163)] | 良恶性细胞分类 | Pap | 肺部 | 数据增强 + VGG-16 + GradCAM | 私有数据集：621
    张图像（补丁），良性（306）和恶性（315） | 补丁级别：Acc=0.792, AUC=0.872; 案例级别：Acc=0.870, AUC=0.932.
    |'
- en: '| [[91](#bib.bib91)] | Classification of cervical squamous lesions | Pap |
    Cervix | VGG-16 | Private dataset: 3,290 images in classes of abnormal cells (1,736
    ) and normal cells (1,554) | Acc=0.9807, P=0.9791, Sens=0.9801, F1=0.9809. |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| [[91](#bib.bib91)] | 宫颈鳞状病变分类 | Pap | 宫颈 | VGG-16 | 私有数据集：3,290 张图像，异常细胞（1,736）和正常细胞（1,554）
    | Acc=0.9807, P=0.9791, Sens=0.9801, F1=0.9809. |'
- en: '| [[87](#bib.bib87)] | Fine-grained cell classification | Pap | Cervix | Fine-tune
    + CNN (AlexNet, GoogLeNet, ResNet, and DenseNet) | Herlev | GoogLeNet: Acc=0.945
    (2-class), Acc=0.713 (4-class), Acc=0.645 (7-class). |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| [[87](#bib.bib87)] | 精细化细胞分类 | Pap | 宫颈 | 微调 + CNN（AlexNet, GoogLeNet, ResNet
    和 DenseNet） | Herlev | GoogLeNet: Acc=0.945（2 类），Acc=0.713（4 类），Acc=0.645（7 类）。
    |'
- en: '| [[153](#bib.bib153)] | Multi-cell classification in liquid-based cytology
    images | Pap | Cervix | Fine-tune + CNN (ResNet-50, VGG-19, DenseNet-121, Inception-v3)
    | Herlev; Private dataset: 25 images | ResNet-50: F1=0.8865, AUC=0.95; VGG-19:
    F1=0.8896, AUC=0.95; Densenet-121: F1=0.8546, AUC=0.94; Inception-v3: F1=0.8072,
    AUC=0.88. |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| [[153](#bib.bib153)] | 液基细胞学图像中的多细胞分类 | Pap | 宫颈 | 微调 + CNN（ResNet-50, VGG-19,
    DenseNet-121, Inception-v3） | Herlev; 私有数据集：25 张图像 | ResNet-50: F1=0.8865, AUC=0.95;
    VGG-19: F1=0.8896, AUC=0.95; Densenet-121: F1=0.8546, AUC=0.94; Inception-v3:
    F1=0.8072, AUC=0.88. |'
- en: '| [[57](#bib.bib57)] | Cervical cancer diagnostic prediction | Pap | Cervix
    | CNN (AlexNet, VGG-16, VGG-19, ResNet-50, ResNet-101, and GoogLeNet) | Herlev
    | AlexNet: Acc=0.8;     VGG-16: Acc=0.8337;   VGG-19: Acc=0.8455;   ResNet-50:
    Acc=0.8937; ResNet-101: Acc=0.9450; GoogLeNet: Acc=0.9567. |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| [[57](#bib.bib57)] | 宫颈癌诊断预测 | Pap | 宫颈 | CNN（AlexNet, VGG-16, VGG-19, ResNet-50,
    ResNet-101 和 GoogLeNet） | Herlev | AlexNet: Acc=0.8;     VGG-16: Acc=0.8337;   VGG-19:
    Acc=0.8455;   ResNet-50: Acc=0.8937; ResNet-101: Acc=0.9450; GoogLeNet: Acc=0.9567.
    |'
- en: '| [[110](#bib.bib110)] | Smear classification | Pap | Cervix | 10 popular pre-trained
    CNN | Sipakmed | DenseNet-169: Acc=0.990, P=0.974, R=0.974, F1=0.974. |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| [[110](#bib.bib110)] | 涂片分类 | Pap | 宫颈 | 10 种流行的预训练 CNN | Sipakmed | DenseNet-169:
    Acc=0.990, P=0.974, R=0.974, F1=0.974. |'
- en: '| [[3](#bib.bib3)] | Classification of cervical cancer risk | Pap | Cervix
    | 9 popular CNN | Herlev | Acc=0.756 (7-class), Acc=0.813 (4-class). |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| [[3](#bib.bib3)] | 宫颈癌风险分类 | Pap | 宫颈 | 9 种流行的 CNN | Herlev | Acc=0.756（7
    类），Acc=0.813（4 类）。 |'
- en: '| [[108](#bib.bib108)] | Classification of FANC images | H&E | Breast | CNN
    (AlexNet, GoogLeNet, SqueezeNet, DenseNet, Inception-V3) | Private dataset: 737
    images (ROIs from specimens) in classes of benign (275) and malignant (462) |
    AlexNet: AUC=0.9730; GoogLeNet: AUC=0.9455; SqueezeNe: AUC=0.9152; DenseNet: AUC=0.9244;
    Inception-V3: AUC=0.9730. |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| [[108](#bib.bib108)] | FANC 图像分类 | H&E | 乳腺 | CNN（AlexNet, GoogLeNet, SqueezeNet,
    DenseNet, Inception-V3） | 私有数据集：737 张图像（来自标本的 ROI），良性（275）和恶性（462） | AlexNet:
    AUC=0.9730; GoogLeNet: AUC=0.9455; SqueezeNe: AUC=0.9152; DenseNet: AUC=0.9244;
    Inception-V3: AUC=0.9730. |'
- en: '| [[102](#bib.bib102)] | Classification of cervical cells | Pap | Cervix |
    Fuzzy rank + Pre-trained CNN (Inception-V3, Xception and DenseNet‑169) | Sipakmed
    | Acc=0.9855, Sens=0.9852. |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| [[102](#bib.bib102)] | 宫颈细胞分类 | Pap | 宫颈 | 模糊排名 + 预训练 CNN（Inception-V3, Xception
    和 DenseNet‑169） | Sipakmed | Acc=0.9855, Sens=0.9852. |'
- en: '| [[125](#bib.bib125)] | Classification of cervical cells | Pap | Cervix |
    Hybrid deep feature fusion + CNN (VGG-16, VGG-19, XceptionNet, and ResNet-50)
    | Sipakmed | Acc=0.9985 (2-class), Acc=0.9914 (3-class), Acc=0.9914 (5-class).
    |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| [[125](#bib.bib125)] | 宫颈细胞分类 | Pap | 宫颈 | 混合深度特征融合 + CNN（VGG-16, VGG-19,
    XceptionNet 和 ResNet-50） | Sipakmed | Acc=0.9985（2 类），Acc=0.9914（3 类），Acc=0.9914（5
    类）。 |'
- en: '| [[183](#bib.bib183)] | Classification of cervical cells | Pap | Cervix |
    AlexNet + GAN | Private dataset: 22,124 images (cell) in classes of abnormal (1,202)
    and normal (20,922) | AUC=0.984 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| [[183](#bib.bib183)] | 宫颈细胞分类 | Pap | 宫颈 | AlexNet + GAN | 私有数据集：22,124 张图像（细胞），异常（1,202）和正常（20,922）
    | AUC=0.984 |'
- en: '| [[35](#bib.bib35)] | FNAC cytology image classification | H&E | Breast |
    Conditional GAN (synthesis) + CNN (ResNet-152, DenseNet-161, Inception-V3) | Private
    dataset: 150 images in classes of begin (75) and malignant (75) | 180 generated
    images. ResNet-152: Acc=0.7667; DenseNet-161: Acc=0.8667; Inception-V3: Acc=0.8000.
    |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| [[35](#bib.bib35)] | FNAC 细胞学图像分类 | H&E | 乳腺 | 条件 GAN（合成）+ CNN（ResNet-152，DenseNet-161，Inception-V3）
    | 私有数据集：150 张图像，分为良性（75）和恶性（75） | 生成图像 180 张。ResNet-152：准确率=0.7667；DenseNet-161：准确率=0.8667；Inception-V3：准确率=0.8000。
    |'
- en: '| [[162](#bib.bib162)] | Classification of cytological images | Pap | Lung
    | CNN + PGGAN | Private dataset: 511 images (patch) in classes of benign (244)
    and malignant (267) | Acc=0.853, Sens=0.854, Spec=0.853. |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| [[162](#bib.bib162)] | 细胞学图像分类 | Pap | 肺 | CNN + PGGAN | 私有数据集：511 张图像（补丁），分为良性（244）和恶性（267）
    | 准确率=0.853，灵敏度=0.854，特异性=0.853。 |'
- en: '| [[8](#bib.bib8)] | Classification of FNAC images | Pap | Thyroid | CNN (VGG-19,
    AlexNet) + Transfer learning (Fine-tune) | Private dataset: 9,209 images (cell)
    in 5 classes | VGG-19: Acc=0.9305; AlexNet: Acc=0.9288. |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| [[8](#bib.bib8)] | FNAC 图像分类 | Pap | 甲状腺 | CNN（VGG-19，AlexNet） + 迁移学习（微调）
    | 私有数据集：9,209 张图像（细胞），分为 5 类 | VGG-19：准确率=0.9305；AlexNet：准确率=0.9288。 |'
- en: '| [[169](#bib.bib169)] | Automating the Paris system for cytopathology | Pap
    | Urine | VGG-19 + Morphometric model | Private dataset: 217 WSIs in classes of
    negative (51), atypical (60), suspicious (52), and positive (54) | Acc=0.972,
    Spec=0.976, Sens=0.970. |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| [[169](#bib.bib169)] | 自动化巴黎系统用于细胞病理学 | Pap | 尿液 | VGG-19 + 形态计量模型 | 私有数据集：217
    张 WSI，分为阴性（51），非典型（60），可疑（52）和阳性（54） | 准确率=0.972，特异性=0.976，灵敏度=0.970。 |'
- en: '| continued on the next page |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 续下页 |'
- en: 'Table 4: Overview of deep learning-based classification studies for computational
    cytology (continued)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：基于深度学习的计算细胞学分类研究概述（续）
- en: '| Reference | Application | Staining | Organ | Method | Dataset | Result |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 应用 | 染色 | 器官 | 方法 | 数据集 | 结果 |'
- en: '| [[64](#bib.bib64)] | Cell image recognition | Pap | Urine | EfficientNet
    | Private dataset: 4,637 images (cell) | Acc=0.95, Sens=0.97, Spec=0.95, and AUC=0.99.
    |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| [[64](#bib.bib64)] | 细胞图像识别 | Pap | 尿液 | EfficientNet | 私有数据集：4,637 张图像（细胞）
    | 准确率=0.95，灵敏度=0.97，特异性=0.95，AUC=0.99。 |'
- en: '| [[185](#bib.bib185)] | Classification of cancer cytological specimen | H&E
    | Breast | CNN (AlexNet, GoogLeNet) | 550 images (ROIs) in classes of malignant
    (275) and benign (275) | AlexNet: Acc=0.80; GoogLeNet: Acc=0.83. |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| [[185](#bib.bib185)] | 癌症细胞学标本的分类 | H&E | 乳腺 | CNN（AlexNet，GoogLeNet） | 550
    张图像（ROIs），包括恶性（275）和良性（275） | AlexNet：准确率=0.80；GoogLeNet：准确率=0.83。 |'
- en: '| [[146](#bib.bib146)] | Classification of cervical cells | Pap | Cervix |
    Graph convolutional Network (GCN) | Sipakmed | Acc=98.37 ± 0.57, Sens=99.80 ±
    0.10, Spec=99.60 ± 0.20, F1=99.80 ± 0.10. |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| [[146](#bib.bib146)] | 宫颈细胞分类 | Pap | 子宫颈 | 图卷积网络（GCN） | Sipakmed | 准确率=98.37
    ± 0.57，灵敏度=99.80 ± 0.10，特异性=99.60 ± 0.20，F1=99.80 ± 0.10。 |'
- en: '| [[43](#bib.bib43)] | Classification of FANC cell samples | H&E | Breast |
    GoogLeNet | Private dataset: 37 images in classes of benign (24) and malignant
    (13) | Acc=0.8076. |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| [[43](#bib.bib43)] | FANC 细胞样本分类 | H&E | 乳腺 | GoogLeNet | 私有数据集：37 张图像，分为良性（24）和恶性（13）
    | 准确率=0.8076。'
- en: '| [[139](#bib.bib139)] | Classification of FNAC images | Pap | Breast | CNN
    (VGG-16, VGG-19, ResNet-50, and GoogLeNet-V3) | FANC 2019 | VGG-16: Acc=0.8867;
    VGG-19: Acc=0.882; ResNet-50: Acc=0.9056; GoogLeNet-V3: Acc=0.9625. |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| [[139](#bib.bib139)] | FNAC 图像分类 | Pap | 乳腺 | CNN（VGG-16，VGG-19，ResNet-50
    和 GoogLeNet-V3） | FANC 2019 | VGG-16：准确率=0.8867；VGG-19：准确率=0.882；ResNet-50：准确率=0.9056；GoogLeNet-V3：准确率=0.9625。
    |'
- en: '| [[115](#bib.bib115)] | Diagnose the malignant potential of carcinoma cells
    | Pap | Urine | Visual geometry group CNN | Private dataset: 203 images | AUC=0.9890,
    F1=0.9002. |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| [[115](#bib.bib115)] | 诊断癌细胞的恶性潜力 | Pap | 尿液 | 视觉几何组 CNN | 私有数据集：203 张图像
    | AUC=0.9890，F1=0.9002。 |'
- en: '| [[84](#bib.bib84)] | Cell classification | Pap | Urine | VGG-16 | Private
    dataset: 690 images in classes of urothelial normal cells (274) and abnormal cells
    (416) | Acc=0.899. |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| [[84](#bib.bib84)] | 细胞分类 | Pap | 尿液 | VGG-16 | 私有数据集：690 张图像，分为尿路上皮正常细胞（274）和异常细胞（416）
    | 准确率=0.899。 |'
- en: '| [[50](#bib.bib50)] | Differential diagnosing of papillary thyroid carcinomas
    | H&E | Thyroid | VGG-16 and Inception-v3 | Private dataset: 279 images (thyroid
    nodules) | VGG-16: 0.9766 (image-level), 0.95 (patient-level); Inception-v3: 0.9275
    (image-level), 0.875 (patient-level). |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| [[50](#bib.bib50)] | 乳头状甲状腺癌的鉴别诊断 | H&E | 甲状腺 | VGG-16 和 Inception-v3 | 私有数据集：279
    张图像（甲状腺结节） | VGG-16：0.9766（图像级别），0.95（患者级别）；Inception-v3：0.9275（图像级别），0.875（患者级别）。
    |'
- en: '| [[9](#bib.bib9)] | Classification of FNAC images | Giemsa H&E | Breast |
    CNN (13 layers, convolution and fully-connected layers) | Private dataset: Giemsa
    (1020 images in classes of benign and malignant) and H&E (631 images in classes
    of benign and malignant) | Giemsa: Acc=0.9781, P=0.977, R=0.973, Spec=0.982, F1=0.975;
    H&E: Acc=0.9753, P=0.973, R=0.950, Spec=0.987, F1=0.961. |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| [[9](#bib.bib9)] | FNAC 图像分类 | Giemsa H&E | 乳腺 | CNN（13 层，卷积和全连接层） | 私有数据集：Giemsa（1020
    张良性和恶性分类图像）和 H&E（631 张良性和恶性分类图像） | Giemsa：准确率=0.9781, 精确度=0.977, 召回率=0.973, 特异度=0.982,
    F1=0.975；H&E：准确率=0.9753, 精确度=0.973, 召回率=0.950, 特异度=0.987, F1=0.961. |'
- en: '| [[49](#bib.bib49)] | Differential diagnosing of lymph node | H&E | Cervix
    | Inception-v3 | Private dataset: 742 images in 4 classes | Acc=0.8962. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| [[49](#bib.bib49)] | 淋巴结的鉴别诊断 | H&E | 宫颈 | Inception-v3 | 私有数据集：742 张图像，分为
    4 类 | 准确率=0.8962. |'
- en: '| [[15](#bib.bib15)] | Cervical cancer detection | Pap | Cervix | EfficientNet
    + Grad-CAM | Herlev, Sipakmed | Acc=0.9970, P=0.9970, R=0.9972, F1=0.9963, Kappa=0.9931.
    |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| [[15](#bib.bib15)] | 宫颈癌检测 | Pap | 宫颈 | EfficientNet + Grad-CAM | Herlev,
    Sipakmed | 准确率=0.9970, 精确度=0.9970, 召回率=0.9972, F1=0.9963, Kappa=0.9931. |'
- en: '| [[116](#bib.bib116)] | Cell identification | Giemsa | Skin | ResNet-50 |
    Private dataset: 2,260 images (Tzanck smear) | Acc=0.943, Sens=0.837, Spec=0.973,
    AUC=0.974. |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| [[116](#bib.bib116)] | 细胞识别 | Giemsa | 皮肤 | ResNet-50 | 私有数据集：2,260 张图像（Tzanck
    涂片） | 准确率=0.943, 灵敏度=0.837, 特异度=0.973, AUC=0.974. |'
- en: '| [[10](#bib.bib10)] | Detection of cervical intraepithelial neoplasia or invasive
    cancer | Pap | Cervix | VGG-16 | Private dataset: 188,542 mages | CIN 2: Acc=0.926;
    CIN 3+: Acc=0.961. |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| [[10](#bib.bib10)] | 宫颈上皮内瘤变或侵袭性癌症检测 | Pap | 宫颈 | VGG-16 | 私有数据集：188,542
    张图像 | CIN 2：准确率=0.926；CIN 3+：准确率=0.961.'
- en: '| [[142](#bib.bib142)] | Classification of FNAC images | Giemsa Pap | Thyroid
    | CNN | Private dataset: 370 images in classes of non‑PTCA (184) and PTCA (186)
    | Sens=0.9048, Spec=0.8333, Acc=0.8506. |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| [[142](#bib.bib142)] | FNAC 图像分类 | Giemsa Pap | 甲状腺 | CNN | 私有数据集：370 张图像，分为非
    PTCA（184）和 PTCA（186） | 灵敏度=0.9048, 特异度=0.8333, 准确率=0.8506. |'
- en: '| [[176](#bib.bib176)] | Classification of cancer types | H&E | Cervix | AlexNet
    | Private dataset: 79 specimens in 3 classes | Acc=0.9333. |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| [[176](#bib.bib176)] | 癌症类型分类 | H&E | 宫颈 | AlexNet | 私有数据集：79 个标本，分为 3 类
    | 准确率=0.9333. |'
- en: '| [[80](#bib.bib80)] | Cervical cell classification | Pap | Cervix | ResNet-50
    + Attention mechanism + LSTM | Sipakmed | Sensitivity=0.999, specificity=0.998,
    F1=0.9989. |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| [[80](#bib.bib80)] | 宫颈细胞分类 | Pap | 宫颈 | ResNet-50 + 注意力机制 + LSTM | Sipakmed
    | 灵敏度=0.999, 特异度=0.998, F1=0.9989. |'
- en: '| Slide-level classification |  |  |  |  |  |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 幻灯片级分类 |  |  |  |  |  |'
- en: '| [[40](#bib.bib40)] | Classification (prediction of malignancy) | Pap | Thyroid
    | AlexNet | Private dataset: 908 WSIs | Sens=0.92, Spec=0.905, AUC=0.932. |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| [[40](#bib.bib40)] | 分类（恶性预测） | Pap | 甲状腺 | AlexNet | 私有数据集：908 张 WSIs |
    灵敏度=0.92, 特异度=0.905, AUC=0.932. |'
- en: '| [[39](#bib.bib39)] | Classification (prediction of malignancy) | Pap | Thyroid
    | VGG-11 + Multiple instance learning | Private dataset: 908 WSIs | AUC=0.932,
    AP=0.872. |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| [[39](#bib.bib39)] | 分类（恶性预测） | Pap | 甲状腺 | VGG-11 + 多实例学习 | 私有数据集：908 张
    WSIs | AUC=0.932, AP=0.872. |'
- en: '| [[158](#bib.bib158)] | Cervical cancer screening | Pap | Cervix | Faster
    R-CNN | Private dataset: 408,030 images | Sens=0.994, Spec=0.348, AUC=0.67. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| [[158](#bib.bib158)] | 宫颈癌筛查 | Pap | 宫颈 | Faster R-CNN | 私有数据集：408,030 张图像
    | 灵敏度=0.994, 特异度=0.348, AUC=0.67. |'
- en: '| [[65](#bib.bib65)] | Quantitative analysis of abnormalities | Pap | Cervix
    | U-Net, ResNet-50 | Private dataset: 130 WSIs | Segmentation: Pixel Acc=0.974
    ± 0.001, IoU=0.913 ± 0.007; Classification: Acc=0.945 ± 0.006. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| [[65](#bib.bib65)] | 异常的定量分析 | Pap | 宫颈 | U-Net, ResNet-50 | 私有数据集：130 张
    WSIs | 分割：像素准确率=0.974 ± 0.001, IoU=0.913 ± 0.007；分类：准确率=0.945 ± 0.006. |'
- en: '| [[20](#bib.bib20)] | Cancer screening (cell-level detection, patch-level
    and case-level classification) | Pap | Cervix | Multi-scale region-based CNN +
    Attention mechanism | Private dataset: 7030 images | Cell-level detection: AP=0.7509;
    Patch-level classification: AUC=0.9909; Case-level classification: AUC=0.934,
    Sens=0.913, Spec=0.906 and Acc=0.909. |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| [[20](#bib.bib20)] | 癌症筛查（细胞级检测、补丁级和病例级分类） | Pap | 宫颈 | 多尺度区域基础 CNN + 注意力机制
    | 私有数据集：7030 张图像 | 细胞级检测：AP=0.7509；补丁级分类：AUC=0.9909；病例级分类：AUC=0.934, 灵敏度=0.913,
    特异度=0.906 和 准确率=0.909. |'
- en: '| [[79](#bib.bib79)] | High resolution image classification | Pap | Cervix
    | Mixed supervision learning (image-level + pixel-level) | Private dataset: 862
    images from 2 data centers | Center A: Sens=1, Spec=0.86; Center B: Sens=1, Spec=0.87.
    |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| [[79](#bib.bib79)] | 高分辨率图像分类 | Pap | 宫颈 | 混合监督学习（图像级 + 像素级） | 私有数据集：来自 2
    个数据中心的 862 张图像 | A 中心：灵敏度=1, 特异度=0.86；B 中心：灵敏度=1, 特异度=0.87. |'
- en: '| continued on the next page |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 继续在下一页 |'
- en: 'Table 5: Overview of deep learning-based classification studies for computational
    cytology (continued)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：基于深度学习的计算细胞学分类研究概述（续）
- en: '| Reference | Application | Staining | Organ | Method | Dataset | Result |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 应用 | 染色 | 组织 | 方法 | 数据集 | 结果 |'
- en: '| [[38](#bib.bib38)] | Classification (prediction of malignancy) | Pap | Thyroid
    | MIL+ NoisyAND + Attention mechanism + Maximum likelihood estimation | Private
    dataset: 142 WSIs with 4,494 instances | AUC=0.870 ± 0.017, AP=0.743 ± 0.037.
    |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| [[38](#bib.bib38)] | 分类（恶性预测） | 巴氏染色 | 甲状腺 | MIL+ NoisyAND + 注意力机制 + 最大似然估计
    | 私有数据集：142张WSI，包含4,494个实例 | AUC=0.870 ± 0.017，AP=0.743 ± 0.037。 |'
- en: '| [[46](#bib.bib46)] | Distinguish large cell neuroendocrine | Pap, H&E, Diff-Quik
    | Lung | CNN | Private dataset: 40 images in high-grade neuroendocrine carcinoma
    (17 small cell, 13 large cell, 10 mixed/unclassifiable) | H&E: Acc=0.900; Pap:
    Acc=0.875; Diff-Quik: Acc=0.889. |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| [[46](#bib.bib46)] | 区分大细胞神经内分泌癌 | 巴氏染色，H&E，Diff-Quik | 肺 | CNN | 私有数据集：40张图像，包含高分化神经内分泌癌（17张小细胞，13张大细胞，10张混合/不可分类）
    | H&E：准确率=0.900；巴氏染色：准确率=0.875；Diff-Quik：准确率=0.889。 |'
- en: '| [[199](#bib.bib199)] | Rapid TBS classification of cervical liquid-based
    thin-layer cell smears | Pap | Cervix | Model assembly: Xception (classification),
    YOLOv3 (object detection), and U-Net (segmentation) | Private dataset: 81,727
    images | Speed=180s/slide, Sens=0.9474. |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| [[199](#bib.bib199)] | 快速TBS分类子宫颈液基薄层细胞涂片 | 巴氏染色 | 子宫颈 | 模型组合：Xception（分类）、YOLOv3（物体检测）和U-Net（分割）
    | 私有数据集：81,727张图像 | 速度=180秒/切片，灵敏度=0.9474。 |'
- en: '| [[174](#bib.bib174)] | Cervical lesion detection, WSI-level classification
    of normal and abnormal | Pap | Cervix | YOLOv3 + Transformer | Private dataset:
    2,019 images (slide) from four scanning devices | AUC=0.872. |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| [[174](#bib.bib174)] | 子宫颈病变检测，WSI级正常与异常分类 | 巴氏染色 | 子宫颈 | YOLOv3 + Transformer
    | 私有数据集：来自四台扫描设备的2,019张图像（切片） | AUC=0.872。 |'
- en: '| [[29](#bib.bib29)] | WSI-level cervical cancer screening | Pap | Cervix |
    CNN (ResNet50) + RNN | Private dataset: 3,545 images (slide) with 79,911 annotations
    | Spec=0.935, Sens=0.951, Speed=1.5min/slide. |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| [[29](#bib.bib29)] | WSI级子宫颈癌筛查 | 巴氏染色 | 子宫颈 | CNN（ResNet50）+ RNN | 私有数据集：3,545张图像（切片），拥有79,911个标注
    | 特异性=0.935，灵敏度=0.951，速度=1.5分钟/切片。 |'
- en: '| [[7](#bib.bib7)] | Cell-level classification, WSI-level risk stratification
    | Pap | Urine | RetinaNet + Counting of atypical and malignant cells | Private
    dataset: 398 images (slide) in classes of normal (243), inflammatory (13), CA
    (76), ASM (38) and TCC (28) | Cell-level classification: AUC=0.99; Risk stratification:
    AUC=0.83. |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| [[7](#bib.bib7)] | 细胞级分类，WSI级风险分层 | 巴氏染色 | 尿液 | RetinaNet + 异常和恶性细胞计数 | 私有数据集：398张图像（切片），分类为正常（243）、炎症（13）、CA（76）、ASM（38）和TCC（28）
    | 细胞级分类：AUC=0.99；风险分层：AUC=0.83。 |'
- en: '| [[86](#bib.bib86)] | Smear-level risk stratification | Pap | Cervix | CNN
    with dual-path encode + Synergistic grouping loss | Private dataset: 19,303 WSIs
    (13,486 for training, 2,486 for validation and 3,331 for testing) from 4 centers
    in 6 classes of cells | Sens=0.907, Spec=0.80, AUC=0.925. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| [[86](#bib.bib86)] | 涂片级风险分层 | 巴氏染色 | 子宫颈 | CNN 与双路径编码 + 协同分组损失 | 私有数据集：来自4个中心的19,303张WSI（训练用13,486张，验证用2,486张，测试用3,331张），包含6类细胞
    | 灵敏度=0.907，特异性=0.80，AUC=0.925。 |'
- en: 4.2.1 Cell-level classification
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1 细胞级分类
- en: Cell-level classification could be one of the most successful tasks in DL-based
    cytology image analysis [[60](#bib.bib60)]. Due to the giga-pixel resolution of
    collected cytology WSIs, they are usually cut into cell patches for image analysis
    [[186](#bib.bib186)]. When training a deep network for classifying cells, cell
    patches are cropped from these whole images first. Then, these cell patches are
    fed into DL models to train cell-level classification models after preprocessing.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 细胞级分类可能是基于深度学习的细胞学图像分析中最成功的任务之一 [[60](#bib.bib60)]。由于收集的细胞学WSI的超高像素分辨率，它们通常会被切割成细胞补丁以进行图像分析
    [[186](#bib.bib186)]。在训练用于细胞分类的深度网络时，首先从这些整体图像中裁剪出细胞补丁。然后，这些细胞补丁经过预处理后输入深度学习模型，用于训练细胞级分类模型。
- en: The most straightforward method is to directly feed cell patches into a multi-layer
    CNN for extracting feature maps, then crossing the output layer to get the predicted
    category. A series of CNN-based methods have been proposed. For lung cytology
    classification, [[161](#bib.bib161)] designed a deep convolutional neural network
    consisting of three convolutional layers, three pooling layers, and two fully
    connected layers. Similarly, [[36](#bib.bib36)] constructed a three-block CNN
    model for nasal cell classification. For cervical cytology, [[144](#bib.bib144)]
    designed a CNN architecture consisting of three convolutional layers. Its experimental
    results in different settings (2 class, 3 class, 4 class, and 5 class) showed
    an effective performance of different grades of cancer in cervical images. In
    addition, [[189](#bib.bib189)] proposed a simple ConvNet, which was first pre-trained
    in a natural image dataset, ImageNet. Then, the model was fine-tuned in two cervical
    cytological datasets, Herlev and HEMLBC [[60](#bib.bib60), [188](#bib.bib188)],
    achieving outperforming performance than previous algorithms. However, the performances
    and generalization capabilities of these simply-designed CNN with several layers
    are limited to specific datasets and scenarios.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 最直接的方法是将细胞补丁直接输入到多层 CNN 中以提取特征图，然后通过输出层获取预测类别。已经提出了一系列基于 CNN 的方法。对于肺细胞学分类，[[161](#bib.bib161)]
    设计了一个深度卷积神经网络，包括三层卷积层、三层池化层和两层全连接层。类似地，[[36](#bib.bib36)] 构建了一个三块 CNN 模型用于鼻腔细胞分类。对于宫颈细胞学，[[144](#bib.bib144)]
    设计了一个由三层卷积层组成的 CNN 架构。在不同设置（2 类、3 类、4 类和 5 类）的实验结果显示了宫颈图像中不同等级癌症的有效表现。此外，[[189](#bib.bib189)]
    提出了一个简单的 ConvNet，该模型首先在自然图像数据集 ImageNet 上进行预训练。然后，该模型在两个宫颈细胞学数据集 Herlev 和 HEMLBC
    [[60](#bib.bib60), [188](#bib.bib188)] 上进行了微调，表现优于之前的算法。然而，这些简单设计的几层 CNN 的性能和泛化能力仅限于特定的数据集和场景。
- en: A large amount of advanced deep models are proposed in the computer vision field,
    such as Inception [[157](#bib.bib157)], ResNet [[52](#bib.bib52)] and DenseNet
    [[54](#bib.bib54)]. These networks can be directly adopted for cytology image
    analysis and achieve better performance than simply-designed structures in the
    classification task. For example, [[163](#bib.bib163)] presented a VGG-based model
    for classifying benign and malignant cells from lung cytology images. [[116](#bib.bib116)]
    proposed TzanckNet based on ResNet-50 to identify cells in the cytology of erosive‑vesiculobullous
    diseases. Additionally, some studies compared the performance of advanced CNN
    architectures in cytology image classification tasks [[153](#bib.bib153), [57](#bib.bib57),
    [110](#bib.bib110), [3](#bib.bib3)]. From their experimental results, popular
    architectures (e.g., ResNet, Inception, and DenseNet) achieved promising performance
    in cell classification. To provide the interpretability analysis of this CNN-based
    classification, [[143](#bib.bib143)] designed Grad-CAM to show region of interests
    (ROIs) in network decision-making using the gradient information of the last convolution
    layer of CNN. [[163](#bib.bib163)] utilized Grad-CAM to generate heatmaps for
    observing high activation areas on typical regions lung cytology images. By observing
    the model’s high response regions of urothelial cytology images via Grad-CAM,
    [[115](#bib.bib115)] concluded that the color of tumor nuclei contributes to the
    prediction of the model most.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉领域，提出了大量先进的深度模型，如 Inception [[157](#bib.bib157)]、ResNet [[52](#bib.bib52)]
    和 DenseNet [[54](#bib.bib54)]。这些网络可以直接用于细胞学图像分析，并在分类任务中比简单设计的结构实现更好的性能。例如，[[163](#bib.bib163)]
    提出了一个基于 VGG 的模型用于从肺细胞学图像中分类良性和恶性细胞。[[116](#bib.bib116)] 提出了基于 ResNet-50 的 TzanckNet，用于识别侵蚀性水疱病细胞。此外，一些研究比较了先进的
    CNN 架构在细胞学图像分类任务中的性能 [[153](#bib.bib153), [57](#bib.bib57), [110](#bib.bib110),
    [3](#bib.bib3)]。从他们的实验结果来看，流行的架构（如 ResNet、Inception 和 DenseNet）在细胞分类中表现出色。为了提供基于
    CNN 分类的可解释性分析，[[143](#bib.bib143)] 设计了 Grad-CAM，通过 CNN 最后一层卷积层的梯度信息显示网络决策中的兴趣区域（ROIs）。[[163](#bib.bib163)]
    利用 Grad-CAM 生成热图，以观察典型区域肺细胞学图像上的高激活区域。通过观察 Grad-CAM 的高响应区域 [[115](#bib.bib115)]
    认为，肿瘤核的颜色对模型预测贡献最大。
- en: Apart from binary classification (i.e., benign and malignant), multi-class scenarios
    are more common, yet challenging in cytology image analysis, because benign and
    malignant cells mainly include several sub-categories [[169](#bib.bib169)]. For
    example, Herlev dataset contains 3 types of normal cervical cells and 4 types
    of abnormal cervical cells [[60](#bib.bib60)]. However, the boundaries between
    the image features of two sub-categories are usually ambiguous, which brings challenges
    for CNNs to learn distinguishable features. To solve these issues, [[87](#bib.bib87)]
    proposed a fine-grained classification model for cervical cells. This model introduced
    mask maps as the morphological appearance information for enhancing fine-grained
    distinguishable features of cells.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 除了二分类（即良性和恶性），在细胞学图像分析中，多类别场景更为常见，但也更具挑战性，因为良性和恶性细胞主要包括几个子类别[[169](#bib.bib169)]。例如，Herlev
    数据集包含3种正常宫颈细胞和4种异常宫颈细胞[[60](#bib.bib60)]。然而，两个子类别之间的图像特征边界通常模糊，这给 CNN 学习可区分特征带来了挑战。为解决这些问题，[[87](#bib.bib87)]
    提出了一个用于宫颈细胞的细粒度分类模型。该模型引入了掩码图作为形态学外观信息，以增强细粒度的可区分特征。
- en: In addition, several cytological studies focus on improving the model’s performance
    in limited or imbalanced datasets. GAN-based models can be utilized to augment
    original dataset for improving the performance of the classification task. For
    example, [[183](#bib.bib183)] adopted GAN-based data augmentation to improve cervical
    cell classification models. [[35](#bib.bib35)] synthesized 180 images by conditional
    GAN. Together with the original data, these images are utilized to train three
    common models (ResNet-152, DenseNet-161, and Inception-V3), achieving significant
    improvement in FNAC image classification. For the imbalanced dataset problem,
    the number of positive samples is always far less than the negative ones in cytological
    scenarios [[183](#bib.bib183), [8](#bib.bib8)]. A few studies employed sampling
    techniques to balance different classes [[81](#bib.bib81), [8](#bib.bib8)]. For
    learning-based solutions, [[183](#bib.bib183)] adopted GAN to balance different
    classes by synthesizing images for those classes with far less amount than others.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些细胞学研究专注于改善在有限或不平衡数据集上的模型性能。可以利用基于 GAN 的模型来增强原始数据集，从而提高分类任务的性能。例如，[[183](#bib.bib183)]
    采用基于 GAN 的数据增强来改进宫颈细胞分类模型。[[35](#bib.bib35)] 通过条件 GAN 合成了180张图像。这些图像与原始数据一起用于训练三种常见模型（ResNet-152、DenseNet-161
    和 Inception-V3），在 FNAC 图像分类中取得了显著改进。对于不平衡的数据集问题，细胞学场景中正样本的数量总是远少于负样本[[183](#bib.bib183),
    [8](#bib.bib8)]。一些研究采用了采样技术来平衡不同类别[[81](#bib.bib81), [8](#bib.bib8)]。对于基于学习的解决方案，[[183](#bib.bib183)]
    通过合成图像来平衡类别，其中 GAN 用于合成数量远少于其他类别的图像。
- en: Recently, some other advanced methods have been investigated for cytology classification.
    [[80](#bib.bib80)] introduced an attention mechanism block to guide the network
    to focus on cell areas, thus improving the capability of extracting deep features.
    Then, they added a pyramid pooling layer and a long short-term memory module (LSTM)
    to aggregate image features in different regions. To improve the classification
    performance, [[146](#bib.bib146)] proposed a cervical cell classification method
    based on graph convolutional network (GCN), which can explore the potential relationship
    of cervical cell images.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，已经有一些其他先进的方法被研究用于细胞学分类。[[80](#bib.bib80)] 引入了一个注意机制块，以引导网络专注于细胞区域，从而提高提取深层特征的能力。随后，他们添加了一个金字塔池化层和一个长短期记忆模块（LSTM），以汇聚不同区域的图像特征。为了提高分类性能，[[146](#bib.bib146)]
    提出了基于图卷积网络（GCN）的宫颈细胞分类方法，这可以探索宫颈细胞图像的潜在关系。
- en: In clinic practice, DL-based classification approaches have been widely applied
    for various types of cancers, including cervix [[144](#bib.bib144)], breast [[108](#bib.bib108)],
    lung [[161](#bib.bib161)], thyroid [[8](#bib.bib8)], urine [[169](#bib.bib169)],
    nasal [[36](#bib.bib36)] and skin [[116](#bib.bib116)]. Specifically, [[169](#bib.bib169)]
    proposed a VGG-based model for classifying urine cytopathology images. [[8](#bib.bib8)]
    developed a VGG-based model for thyroid nodule cell classification. For cervical
    cytology, [[10](#bib.bib10)] compared AI-assisted techniques with skilled cytologists
    in detecting cervical intraepithelial neoplasia or invasive cancer. For skin cytology,
    [[116](#bib.bib116)] proposed a ResNet-based model to identify cells in the cytology
    of erosive‑vesiculobullous diseases. These studies demonstrated the substantial
    clinical value of classification-assisted cytology image analysis.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在临床实践中，基于深度学习的分类方法已被广泛应用于多种类型的癌症，包括宫颈 [[144](#bib.bib144)]、乳腺 [[108](#bib.bib108)]、肺
    [[161](#bib.bib161)]、甲状腺 [[8](#bib.bib8)]、尿液 [[169](#bib.bib169)]、鼻 [[36](#bib.bib36)]
    和皮肤 [[116](#bib.bib116)]。具体来说，[[169](#bib.bib169)] 提出了一个基于 VGG 的模型用于分类尿液细胞病理图像。[[8](#bib.bib8)]
    开发了一个基于 VGG 的模型用于甲状腺结节细胞分类。对于宫颈细胞学，[[10](#bib.bib10)] 比较了 AI 辅助技术与熟练细胞学家的宫颈上皮内瘤变或侵袭性癌症的检测效果。对于皮肤细胞学，[[116](#bib.bib116)]
    提出了一个基于 ResNet 的模型来识别腐蚀性泡疹疾病细胞。这些研究展示了分类辅助细胞学图像分析的重大临床价值。
- en: 4.2.2 Slide-level classification
  id: totrans-214
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2 幻灯片级分类
- en: Different from cell-level classification, the goal of the slide-level classification
    model is to predict the category of whole images instead of cell samples.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 与细胞级分类不同，幻灯片级分类模型的目标是预测整个图像的类别，而不是细胞样本。
- en: Giga-pixel WSI classification systems are being investigated for efficient and
    high-accuracy predictions. Some studies built slide-level classification systems
    by multi-stage designs. For example, [[29](#bib.bib29)] designed a robust and
    progressive WSI analysis method for cervical cancer screening. In the first stage,
    the authors developed a progressive lesion cell recognition method combining low-
    and high-resolution WSIs. Then, a RNN-based WSI classification model was built
    for WSI-level predictions in the second stage. In another slide-level study, [[174](#bib.bib174)]
    designed a lightweight model (YOLCO) based on YOLO series [[127](#bib.bib127)]
    to make local predictions (e.g., cell-level, patch-level) in the first stage,
    which can enrich the multi-scale connectivity by additional supervision of spatial
    information. In the second stage, these local predictions were input to a transformer
    architecture for WSI-level results. Its experimental results showed that the framework
    presented a higher AUC score and $2.51\times$ faster than the state-of-the-art
    methods in WSI classification. For accurate and efficient screening of cervical
    cancer, [[199](#bib.bib199)] developed a complete cervical LBC smear TBS diagnostic
    system. This system integrated XGBoost and a logical decision tree with three
    typical DL models, i.e., Xception for classification, YOLOv3 for object detection,
    and U-Net for segmentation. This diagnostic system can reduce cytologists’ workload,
    improve the accuracy of cervical cancer screening.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 正在研究 Giga-pixel WSI 分类系统以实现高效且高准确率的预测。一些研究通过多阶段设计建立了幻灯片级分类系统。例如，[[29](#bib.bib29)]
    设计了一种强大而渐进的 WSI 分析方法用于宫颈癌筛查。在第一阶段，作者开发了一种结合低分辨率和高分辨率 WSI 的渐进性病变细胞识别方法。然后，在第二阶段建立了一个基于
    RNN 的 WSI 分类模型用于 WSI 级别的预测。在另一项幻灯片级研究中，[[174](#bib.bib174)] 设计了一个基于 YOLO 系列 [[127](#bib.bib127)]
    的轻量级模型（YOLCO），在第一阶段进行局部预测（例如，细胞级、补丁级），通过额外的空间信息监督来丰富多尺度连接。在第二阶段，这些局部预测被输入到变换器架构中以获得
    WSI 级别的结果。实验结果表明，该框架在 WSI 分类中比现有最先进方法具有更高的 AUC 分数和 $2.51\times$ 的速度提升。为了准确和高效地筛查宫颈癌，[[199](#bib.bib199)]
    开发了一个完整的宫颈 LBC 涂片 TBS 诊断系统。该系统集成了 XGBoost 和逻辑决策树与三个典型的深度学习模型，即用于分类的 Xception、用于目标检测的
    YOLOv3 和用于分割的 U-Net。该诊断系统可以减少细胞学家的工作负担，提高宫颈癌筛查的准确性。
- en: Weakly supervised learning strategies are introduced to learn information from
    limited annotations in slide-level classification. Weakly supervised learning
    is appealing for this scenario. For example, [[38](#bib.bib38)] presented a MIL
    model for thyroid cancer malignancy prediction from cytopathology images. Then,
    an attention module was integrated into this MIL-based model with maximum likelihood
    estimation (MLE) architecture. The experimental results showed the competitive
    performance in thyroid malignancy prediction. [[79](#bib.bib79)] developed mixed
    supervision learning for WSI classification by effectively utilizing their various
    labels (e.g., sufficient image-level coarse annotations and a few pixel-level
    fine labels).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 弱监督学习策略被引入以从有限的标注中学习滑片级分类的信息。弱监督学习在这种情况下具有吸引力。例如，[[38](#bib.bib38)] 提出了一个MIL模型用于从细胞病理图像中预测甲状腺癌恶性度。随后，一个注意力模块被集成到这个基于MIL的模型中，采用最大似然估计（MLE）架构。实验结果显示了在甲状腺恶性度预测中的竞争性能。[[79](#bib.bib79)]
    通过有效利用其各种标签（例如，足够的图像级粗略标注和少量的像素级精细标签）开发了混合监督学习用于WSI分类。
- en: By introducing advanced strategies or designs, quite a few cytology studies
    investigated to improve classification performance. For example, [[20](#bib.bib20)]
    integrated the attention module into multi-scale region-based CNN (feature pyramid
    network) between upsampling and downsampling pathway. Three experiments in different
    levels consisting of cell-level detection, patch-level, and case-level classification
    demonstrated the effectiveness of the introduced attention mechanism. Other studies
    designed different auxiliary tasks (e.g., detection, segmentation) to assist the
    classification task. [[158](#bib.bib158)] employed an object detection model (Faster
    R-CNN) to assist classification for cancer screening. [[65](#bib.bib65)] introduced
    U-Net for improving the classification of squamous cell abnormalities.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 通过引入先进的策略或设计，许多细胞学研究致力于提高分类性能。例如，[[20](#bib.bib20)] 将注意力模块集成到多尺度区域基础的卷积神经网络（特征金字塔网络）中，介于上采样和下采样路径之间。不同层次的三项实验，包括细胞级检测、补丁级检测和病例级分类，展示了引入的注意力机制的有效性。其他研究设计了不同的辅助任务（例如，检测、分割）来辅助分类任务。[[158](#bib.bib158)]
    使用对象检测模型（Faster R-CNN）来辅助癌症筛查的分类。[[65](#bib.bib65)] 引入了U-Net以改进鳞状细胞异常的分类。
- en: Risk stratification is one important task of slide-level classification, which
    determines the risk level of patients suffering from diseases. [[7](#bib.bib7)]
    designed a DL-based digital cell profile for risk stratification of urine cytology
    images. In this system, RetinaNet was adopted for cell-level classification and
    detection in the first stage. For WSI-level risk stratification, they identified
    low-risk and high-risk cases using the count of atypical cells and the total count
    of atypical and malignant cells. [[86](#bib.bib86)] presented a dual-path network
    for cervix risk stratification, which can be divided into two steps. Firstly,
    an efficient CNN with a dual-path encoder was proposed for lesion retrieval, which
    can ensure the inference efficiency and sensitivity on both tiny and large lesions.
    Then, a smear-level classifier (rule-based risk stratification) was introduced
    to align reasonably with the intricate cytological definition of the classes.
    Extensive experiments on a huge dataset consisting of 19,303 WSIs from multiple
    medical centers validated the robustness of this risk stratification method.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 风险分层是滑片级分类的一个重要任务，它决定了患者患病的风险等级。[[7](#bib.bib7)] 设计了一个基于深度学习的数字细胞档案系统，用于尿液细胞学图像的风险分层。在这个系统中，RetinaNet
    被采用用于细胞级分类和检测。在WSI级别的风险分层中，他们通过异常细胞的计数和异常及恶性细胞的总计数来识别低风险和高风险病例。[[86](#bib.bib86)]
    提出了一个双路径网络用于宫颈风险分层，可以分为两个步骤。首先，提出了一个具有双路径编码器的高效卷积神经网络，用于病变检索，这可以确保对小病变和大病变的推理效率和灵敏度。然后，引入了一个涂片级分类器（基于规则的风险分层）以合理地与复杂的细胞学定义对齐。对来自多个医疗中心的19,303个WSI的大型数据集进行的广泛实验验证了这种风险分层方法的稳健性。
- en: 4.3 Detection
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 检测
- en: 'In cytology image analysis, developing automatic detection methods to find
    tiny objects (e.g., malignant cells and nuclei) in the whole image is crucial
    to reduce experts’ tedious and time-consuming workflow. DL-based object detection
    has achieved significant progress in medical image analysis, which can be divided
    into two categories: 1) One-stage method, which directly regresses the category
    and location of instance objects in a single architecture. 2) Two-stage method,
    which firstly predicts object candidates in the first stage and then classifies
    and localizes them in the second stage.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在细胞学图像分析中，开发自动检测方法以在整个图像中找到微小物体（例如，恶性细胞和细胞核）对于减少专家的繁琐和耗时的工作流程至关重要。基于深度学习的目标检测在医学图像分析中取得了显著进展，可分为两类：1）单阶段方法，直接在单一架构中回归实例对象的类别和位置。2）两阶段方法，首先在第一阶段预测对象候选框，然后在第二阶段对其进行分类和定位。
- en: 'Table 6: Overview of deep learning-based detection studies for computational
    cytology'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：基于深度学习的计算细胞学检测研究概述
- en: '| Reference | Application | Staining | Organ | Method | Dataset | Result |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 应用 | 染色 | 器官 | 方法 | 数据集 | 结果 |'
- en: '| One-stage methods |  |  |  |  |  |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 单阶段方法 |  |  |  |  |  |'
- en: '| [[66](#bib.bib66)] | Nuclei detection | Pap | Pleural effusion | YOLOv3 |
    Private dataset: 200 images with 11,157 nuclei | Precision: 0.941, Recall=0.9898,
    F1=0.9648, Test time=0.060 sec/img. |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| [[66](#bib.bib66)] | 细胞核检测 | Pap | 胸腔积液 | YOLOv3 | 私有数据集：200张图像，含11,157个细胞核
    | 精度：0.941，召回率=0.9898，F1=0.9648，测试时间=0.060秒/图像。 |'
- en: '| [[177](#bib.bib177)] | Automation-assisted cervical cancer reading | Feulgen
    | Cervix | YOLOv3 | Private dataset: 12,909 images with 58,995 ground truth boxes
    in 10 categories | Detection: mAP=0.602; Classification: Sens=0.975, Spec=0.687.
    |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| [[177](#bib.bib177)] | 自动化辅助子宫颈癌读取 | Feulgen | 子宫颈 | YOLOv3 | 私有数据集：12,909张图像，含58,995个真实框，分为10类
    | 检测：mAP=0.602；分类：敏感度=0.975，特异度=0.687。 |'
- en: '| [[111](#bib.bib111)] | Hematological diagnosis | Giemsa | Bone marrow | YOLOv4
    | Private dataset: 75,000 annotated tiles of bone marrow aspirate | Region detection:
    Acc=0.97, AUC=0.99; Cell detection: mAP=0.75, F1-score=0.78. |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| [[111](#bib.bib111)] | 血液学诊断 | Giemsa | 骨髓 | YOLOv4 | 私有数据集：75,000张标注的骨髓抽取图块
    | 区域检测：Acc=0.97，AUC=0.99；细胞检测：mAP=0.75，F1分数=0.78。'
- en: '| [[82](#bib.bib82)] | Cell detection | Pap | Cervix | Global context-aware
    + Soft scale anchor matching | Private dataset: 12,909 cervical images with 58,995
    ground truth boxes corresponding to 10 categories objects | mAP=0.6544. |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| [[82](#bib.bib82)] | 细胞检测 | Pap | 子宫颈 | 全球上下文感知 + 软尺度锚匹配 | 私有数据集：12,909张子宫颈图像，含58,995个真实框，分为10类
    | mAP=0.6544。 |'
- en: '| Two-stage methods |  |  |  |  |  |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 两阶段方法 |  |  |  |  |  |'
- en: '| [[81](#bib.bib81)] | Cell detection and classification | Pap | Cervix | Faster
    R-CNN + Transfer learning | Private dataset: 680 LBC cervical exfoliated cell
    samples | Classification: Acc=0.9161 Detection: mAP=0.6698. |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| [[81](#bib.bib81)] | 细胞检测与分类 | Pap | 子宫颈 | Faster R-CNN + 迁移学习 | 私有数据集：680个LBC子宫颈脱落细胞样本
    | 分类：Acc=0.9161 检测：mAP=0.6698。 |'
- en: '| [[53](#bib.bib53)] | Nuclei detection, Estimate proliferation rate | H&E
    | Kidney | R-CNN | Private dataset: 16,905 segmented cancer cell and 22,948 normal
    cell nuclei | P=0.9901, R=0.9870, F1=0.988. |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| [[53](#bib.bib53)] | 细胞核检测，估计增殖率 | H&E | 肾脏 | R-CNN | 私有数据集：16,905个分割癌细胞和22,948个正常细胞核
    | P=0.9901，R=0.9870，F1=0.988。 |'
- en: '| [[121](#bib.bib121)] | Localization and detection of abnormalities | Pap
    | Cervix | Weakly supervised CNN + Regression constraint | Herlev | Severity classification:
    Acc=0.952; Normal/abnormal classification: Acc=0.952, KAPPA score=0.870; Detection:
    Acc=0.804. |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| [[121](#bib.bib121)] | 异常的定位与检测 | Pap | 子宫颈 | 弱监督CNN + 回归约束 | Herlev | 严重程度分类：Acc=0.952；正常/异常分类：Acc=0.952，KAPPA得分=0.870；检测：Acc=0.804。
    |'
- en: '| [[21](#bib.bib21)] | Cell detection | Pap | Cervix | Faster R-CNN + Deep
    metric learning | Private dataset: 240,860 images | 100% labeled: mAP=0.27; 75%
    labeled: mAP=0.254; 50% labeled: mAP=0.195. |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| [[21](#bib.bib21)] | 细胞检测 | Pap | 子宫颈 | Faster R-CNN + 深度度量学习 | 私有数据集：240,860张图像
    | 100%标注：mAP=0.27；75%标注：mAP=0.254；50%标注：mAP=0.195。 |'
- en: '| [[155](#bib.bib155)] | Ascites cytopathology interpretation | Pap, H&E |
    Stomach | Classification: pre-trained AlexNet, VGG-16, GooleNet, ResNet18, and
    ResNet-50\. Detection: Faster R-CNN | Ascites 2020 | Classification: AUC=88.51
    (ResNet50); Detection: IoU=0.8722, mAP=0.8316. |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| [[155](#bib.bib155)] | 腹水细胞病理解释 | Pap, H&E | 胃 | 分类：预训练的AlexNet, VGG-16,
    GooleNet, ResNet18和ResNet-50。检测：Faster R-CNN | Ascites 2020 | 分类：AUC=88.51（ResNet50）；检测：IoU=0.8722，mAP=0.8316。
    |'
- en: '| [[178](#bib.bib178)] | Cell detection | H&E | Cervix | Fully residual CNN
    + Structured regression | HeLa cervical cancer | Precision=0.98, Recall=0.98,
    F1=0.98. |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| [[178](#bib.bib178)] | 细胞检测 | H&E | 宫颈 | 完全残差CNN + 结构回归 | HeLa宫颈癌 | 精度=0.98,
    召回率=0.98, F1=0.98。 |'
- en: '| [[104](#bib.bib104)] | Quantification of pulmonary hemosiderophages | Prussian
    turnbull | Lung | ResNet-18, FPN | Private dataset: 17 WSIs with 78,047 hemosiderophages
    | Concordance=0.85, mAP=0.66. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| [[104](#bib.bib104)] | 肺部含铁血黄素细胞的量化 | 普鲁士蓝 | 肺部 | ResNet-18, FPN | 私有数据集：17个WSI，共78,047个含铁血黄素细胞
    | 一致性=0.85, mAP=0.66。 |'
- en: '| [[186](#bib.bib186)] | Cervical cytology analysis | Pap | Cervix | Lesion
    cell detection: Faster R-CNN and RetinaNet. Cell type classification: Inception-v3,
    ResNet-101, and DenseNet-121 | Private dataset: 1,167 WSIs with 14,432 image patches,
    and 27,972 labeled lesion cells | Detection: mAP=0.2116 (Faster R-CNN); Classification:
    Acc=0.8884, F1=0.5996 (DenseNet-121). |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| [[186](#bib.bib186)] | 宫颈细胞学分析 | Pap | 宫颈 | 病变细胞检测：Faster R-CNN和RetinaNet。细胞类型分类：Inception-v3,
    ResNet-101和DenseNet-121 | 私有数据集：1,167个WSI，14,432个图像补丁和27,972个标注的病变细胞 | 检测：mAP=0.2116（Faster
    R-CNN）；分类：Acc=0.8884, F1=0.5996（DenseNet-121）。 |'
- en: '| [[83](#bib.bib83)] | Cervical cancer screening (cell/clumps detection) |
    Pap | Cervix | Faster R-CNN + Few-shot learning + Prototype representation | CDetector
    | mAP=0.488. |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| [[83](#bib.bib83)] | 宫颈癌筛查（细胞/团块检测） | Pap | 宫颈 | Faster R-CNN + 少样本学习 + 原型表示
    | CDetector | mAP=0.488。 |'
- en: '| [[12](#bib.bib12)] | Nuclei detection | Pap | Pleural effusion | Detector:
    Faster R-CNN, R-FCN and SSD | Private dataset: 200 images (11,157 nuclei) | Faster
    R-CNN (ResNet-101): F1=0.9812. |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| [[12](#bib.bib12)] | 细胞核检测 | Pap | 胸腔积液 | 检测器：Faster R-CNN, R-FCN和SSD | 私有数据集：200张图像（11,157个细胞核）
    | Faster R-CNN（ResNet-101）：F1=0.9812。 |'
- en: 4.3.1 One-stage methods
  id: totrans-240
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1 一阶段方法
- en: One-stage algorithms detect objects by directly generating the category and
    coordinates of objects with the advantages of high detection efficiency, such
    as SSD [[92](#bib.bib92)], YOLO [[127](#bib.bib127)], and RetinaNet [[89](#bib.bib89)].
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 一阶段算法通过直接生成对象的类别和坐标来检测对象，具有高检测效率的优点，如SSD [[92](#bib.bib92)]、YOLO [[127](#bib.bib127)]
    和 RetinaNet [[89](#bib.bib89)]。
- en: Many works in cytology introduce the YOLO model as their base network due to
    its high efficiency. For the structure of YOLO, it divides the original image
    into an $S\times S$ grid cell. Then, YOLO predicts bounding boxes, confidence
    for each cell. Afterwards, redundant boxes are removed by the confidence threshold
    and non-maximum suppression. [[177](#bib.bib177)] used YOLO as their detector
    for cervical cells. Similarly, [[66](#bib.bib66)] adopted YOLO to detect nuclei
    in pleural effusion cytology. The authors compared the detection efficiency between
    one-stage and two-stage detectors [[128](#bib.bib128)]. Its experimental result
    showed that YOLO achieved a test speed of 0.060 second/image that was much faster
    than 1.627 second/image in Faster R-CNN (two-stage detector). Besides, [[111](#bib.bib111)]
    applied YOLO on selected appropriate ROI tiles to automatically detect and classify
    bone marrow cellular and non-cellular objects. To improve the performance of YOLO
    in cervical cell detection, [[82](#bib.bib82)] proposed a global context-aware
    framework by introducing an image-level classification branch and a weighted loss
    that can filter false positive predictions.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 许多细胞学研究引入了YOLO模型作为基础网络，因为它具有很高的效率。对于YOLO的结构，它将原始图像分成$S\times S$网格单元。然后，YOLO预测每个单元的边界框和置信度。之后，通过置信度阈值和非极大值抑制来去除冗余框。[[177](#bib.bib177)]使用YOLO作为其宫颈细胞的检测器。类似地，[[66](#bib.bib66)]采用YOLO来检测胸腔积液细胞学中的细胞核。作者比较了一阶段和二阶段检测器的检测效率[[128](#bib.bib128)]。实验结果显示，YOLO达到了0.060秒/图像的测试速度，比Faster
    R-CNN（两阶段检测器）的1.627秒/图像快得多。此外，[[111](#bib.bib111)]将YOLO应用于选定的适当ROI图块，以自动检测和分类骨髓细胞和非细胞对象。为了提高YOLO在宫颈细胞检测中的性能，[[82](#bib.bib82)]提出了一种全球上下文感知框架，通过引入图像级分类分支和加权损失来过滤假阳性预测。
- en: To improve the feature extractor for learning multi-scale features, RetinaNet
    was proposed by using feature pyramid network (FPN) as its feature extractor,
    which achieved the state-of-the-art detection performance [[88](#bib.bib88)].
    [[104](#bib.bib104)] employed RetinaNet for generating rich and multi-scale features
    for functional head (e.g., box, regression, and classification). These results
    contributed to the quantification of pulmonary hemosiderophages in this work.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 为了改进特征提取器以学习多尺度特征，提出了RetinaNet，使用特征金字塔网络（FPN）作为其特征提取器，这实现了最先进的检测性能[[88](#bib.bib88)]。[[104](#bib.bib104)]
    采用RetinaNet生成丰富的多尺度特征用于功能性头部（例如，框、回归和分类）。这些结果有助于本工作中肺部含铁血黄素细胞的量化。
- en: 4.3.2 Two-stage methods
  id: totrans-244
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.2 两阶段方法
- en: Two-stage methods use different region proposal strategies to generate bounding
    boxes, such as sliding windows [[44](#bib.bib44)], selective search [[141](#bib.bib141)],
    and region proposal network [[128](#bib.bib128)]. For example, Fast R-CNN designed
    selective search strategy to generate bounding boxes. Then, the ROI pooling layer
    extracts the features of each ROI. Fast R-CNN outputs softmax probabilities and
    per-class bounding-box regression offsets with a multi-task loss [[44](#bib.bib44)].
    To integrate different modules and increase the speed [[128](#bib.bib128)], Faster
    R-CNN improves Fast R-CNN by integrating feature extraction, proposal, bounding
    box regression, and classification. It designs region proposal networks (RPN),
    which uses bounding box regression for accurate region proposal.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 两阶段方法使用不同的区域提议策略来生成边界框，例如滑动窗口[[44](#bib.bib44)]、选择性搜索[[141](#bib.bib141)]和区域提议网络[[128](#bib.bib128)]。例如，Fast
    R-CNN设计了选择性搜索策略来生成边界框。然后，ROI池化层提取每个ROI的特征。Fast R-CNN输出softmax概率和每类边界框回归偏移量，并具有多任务损失[[44](#bib.bib44)]。为了集成不同模块并提高速度[[128](#bib.bib128)]，Faster
    R-CNN通过集成特征提取、提议、边界框回归和分类来改进Fast R-CNN。它设计了区域提议网络（RPN），该网络使用边界框回归进行准确的区域提议。
- en: To detect cell objects in the whole cytology image, some studies employed Faster
    R-CNN as their base architecture. For example, [[81](#bib.bib81)] utilized Faster
    R-CNN to detect cervical exfoliated cells on the LBC dataset. Similarly, Faster
    R-CNN was also used to detect tumor cells for further classification, which formed
    an ascites cytopathology image interpretation system [[155](#bib.bib155)].
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在整个细胞学图像中检测细胞对象，一些研究采用了Faster R-CNN作为其基础架构。例如，[[81](#bib.bib81)] 使用Faster
    R-CNN来检测LBC数据集中的宫颈脱落细胞。类似地，Faster R-CNN也被用于检测肿瘤细胞以进行进一步分类，从而形成了一个腹水细胞病理图像解读系统[[155](#bib.bib155)]。
- en: For different cytological scenarios, researchers improved detection performance
    by modifying architectures or integrating with other strategies [[53](#bib.bib53),
    [104](#bib.bib104)]. For efficient cell and robust detection, [[178](#bib.bib178)]
    presented a structured regression model based on a proposed fully residual CNN.
    This model produced a dense proximity map that exhibited higher responses at locations
    near cell center. Then, training this model only required annotations of the dot
    instead of the traditional box, which can improve efficiency of annotating. Several
    studies paid attention to weakly supervised learning settings in cytological detection.
    For example, [[121](#bib.bib121)] proposed a computer-aided diagnosis tool for
    cervical cancer screening. In this method, the authors designed a weakly supervised
    localization strategy, which performed the Integrated Gradient method [[156](#bib.bib156)]
    to compute attribution maps and morphological operations to obtain the localization
    boxes. In another work, [[21](#bib.bib21)] proposed a semi-supervised deep metric
    learning method to improve intra-class feature compactness for cervical cancer
    cell detection. This model learned an embedding metric space and conducted dual
    alignment of semantic features on both the proposal and prototype levels. From
    their quantitative experiments, detection of cervical cancer cell can be a challenging
    study, especially for some cell classes, like ASC-US.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不同的细胞学场景，研究人员通过修改架构或与其他策略结合来提高检测性能[[53](#bib.bib53), [104](#bib.bib104)]。为了实现高效的细胞和稳健的检测，[[178](#bib.bib178)]
    提出了一个基于建议的全残差 CNN 的结构回归模型。该模型生成了一个密集的邻近图，显示了在靠近细胞中心的位置上有更高的响应。然后，训练该模型只需要点的注释，而不是传统的框，这可以提高注释的效率。一些研究关注了细胞学检测中的弱监督学习设置。例如，[[121](#bib.bib121)]
    提出了一个用于宫颈癌筛查的计算机辅助诊断工具。在这种方法中，作者设计了一种弱监督定位策略，执行集成梯度方法[[156](#bib.bib156)]来计算归因图，并进行形态学操作以获得定位框。在另一项工作中，[[21](#bib.bib21)]
    提出了一个半监督深度度量学习方法，以提高宫颈癌细胞检测的类内特征紧凑性。该模型学习了一个嵌入度量空间，并在提议和原型层面上进行了语义特征的双重对齐。根据他们的定量实验，宫颈癌细胞的检测可能是一个具有挑战性的研究，特别是对于一些细胞类别，如
    ASC-US。
- en: The clinic practice not only requires high detection accuracy but also efficiency
    because faster detection speed is more suitable for large-scale screening scenarios
    [[85](#bib.bib85)]. Detection models usually face trade-offs between the accuracy
    and the speed. For example, two-stage detectors (e.g., Faster R-CNN) can achieve
    higher detection results while one-stage detectors (e.g., YOLO) have advantages
    in faster detection speed. In cytological studies, [[186](#bib.bib186)] compared
    the performance between two-stage (Faster R-CNN) and one-stage (RetinaNet) methods
    for the detection of cervical lesion cells. The results showed that the former
    one achieved better experimental results in average precision. In another work
    [[83](#bib.bib83)], the authors improved Faster R-CNN and compared it with baseline
    and RetinaNet in a limited data scenario. The results in cervical cell/clumps
    detection showed that RetinaNet (one-stage) achieved significantly faster speed
    (FPS). [[12](#bib.bib12)] compared three detectors, i.e., Faster R-CNN (two-stage),
    R-FCN (two-stage), and SSD (one-stage). As a result, R-FCN achieved a higher mAP
    score while SSD spent less time when testing. Their experimental results validated
    the trade-offs of these detection models between speed and accuracy.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 临床实践不仅需要高检测准确率，还需要效率，因为更快的检测速度更适合大规模筛查场景[[85](#bib.bib85)]。检测模型通常面临准确性和速度之间的权衡。例如，两阶段检测器（如
    Faster R-CNN）可以获得更高的检测结果，而单阶段检测器（如 YOLO）在更快的检测速度上具有优势。在细胞学研究中，[[186](#bib.bib186)]
    比较了两阶段（Faster R-CNN）和单阶段（RetinaNet）方法在宫颈病变细胞检测中的性能。结果表明，前者在平均精度上取得了更好的实验结果。在另一项工作中[[83](#bib.bib83)]，作者改进了
    Faster R-CNN，并在有限数据场景下与基线和 RetinaNet 进行了比较。宫颈细胞/团块检测的结果显示，RetinaNet（单阶段）实现了显著更快的速度（FPS）。[[12](#bib.bib12)]
    比较了三种检测器，即 Faster R-CNN（两阶段）、R-FCN（两阶段）和 SSD（单阶段）。结果显示，R-FCN 实现了更高的 mAP 分数，而 SSD
    测试时花费的时间较少。他们的实验结果验证了这些检测模型在速度和准确性之间的权衡。
- en: 4.4 Segmentation
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 分割
- en: The segmentation task aims at morphologically delineating the object contour.
    For segmentation models, they assign each pixel of the image to a specific category,
    so it can be regarded as a pixel-wise classification task. In cytological screening,
    segmentation is an essential step for different applications, including 1) separating
    cells/clump and background from specimens, 2) morphologically distinguishing cell
    types, 3) accurately segmenting cellular structures, such as nuclei and cytoplasm.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 分割任务旨在从形态学上描绘对象轮廓。对于分割模型，它们将图像的每个像素分配到特定类别，因此可以视为像素级分类任务。在细胞学筛查中，分割是不同应用的关键步骤，包括1）从标本中分离细胞/团块和背景，2）形态学区分细胞类型，3）准确分割细胞结构，如核和细胞质。
- en: 'The main challenge of cytology segmentation is accurately segmenting overlapping
    areas between cells [[95](#bib.bib95), [96](#bib.bib96)]. To address this issue,
    there are mainly two solution schemes. One is dividing the cytological segmentation
    task into two stages. The first stage is to utilize a semantic segmentation model
    (e.g., U-Net) for a coarse result, followed by a series of refinement designs
    for overlapping areas, thus obtaining the final accurate segmentation result.
    The other is based on the detect-then-segment paradigm (e.g., Mask R-CNN), which
    detects cytology objects in whole images and output a segmentation map by mask
    prediction head. This type of approach can segment objects from each detected
    instance in an end-to-end architecture without any refinement design. Therefore,
    we divide the solutions of cytology segmentation into two categories: 1) segment-then-refine
    method, 2) detect-then-segment method.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 细胞学分割的主要挑战在于准确分割细胞之间的重叠区域[[95](#bib.bib95), [96](#bib.bib96)]。为了解决这个问题，主要有两种解决方案。一种是将细胞学分割任务分为两个阶段。第一阶段使用语义分割模型（例如，U-Net）进行粗略结果，然后对重叠区域进行一系列精细化设计，从而获得最终的准确分割结果。另一种是基于检测-再分割范式（例如，Mask
    R-CNN），它检测整张图像中的细胞学对象，并通过掩码预测头输出分割图。这种方法可以在端到端的架构中从每个检测实例中分割对象，无需任何精细化设计。因此，我们将细胞学分割的解决方案分为两类：1）分割-再精细化方法，2）检测-再分割方法。
- en: 'Table 7: Overview of deep learning-based segmentation studies for computational
    cytology'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：基于深度学习的计算细胞学分割研究概述
- en: '| Reference | Application | Staining | Organ | Method | Dataset | Result |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 应用 | 染色 | 器官 | 方法 | 数据集 | 结果 |'
- en: '| Segment-then-refine methods |  |  |  |  |  |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| 分割-再精细化方法 |  |  |  |  |  |'
- en: '| [[41](#bib.bib41)] | Cell counting, detection, and morphometry | Fluore-
    scence | Various | U-Net | ISBI cell tracking 2015 | IoU=0.9203 (PhC-U373), IoU=0.7756
    (DIC-HeLa). |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| [[41](#bib.bib41)] | 细胞计数、检测和形态测量 | 荧光 | 各种 | U-Net | ISBI细胞跟踪 2015 | IoU=0.9203（PhC-U373），IoU=0.7756（DIC-HeLa）。
    |'
- en: '| [[105](#bib.bib105)] | Segmentation, detection, and classification of cell
    nuclei | Pap | Oral | Classification: ResNet-34\. Detection: Faster R-CNN. Segmentation:
    U-Net | Oral 2021 | Classification: Acc=0.88, F1=0.86; Detection: IoU=0.5832;
    Segmentation: IoU=0.4607. |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| [[105](#bib.bib105)] | 细胞核的分割、检测和分类 | Pap | 口腔 | 分类：ResNet-34\. 检测：Faster
    R-CNN。分割：U-Net | 口腔 2021 | 分类：Acc=0.88，F1=0.86；检测：IoU=0.5832；分割：IoU=0.4607。'
- en: '| [[151](#bib.bib151)] | Segmentation of cytoplasm and nuclei | H&E | Cervix
    | CNN+ Coarse to fine segmentation | Private dataset: 53 slides with 1400 cells
    | Nuclei region detection: Acc=0.9450, F1=0.9453; Segmentation: F1=0.8951±0.0215.
    |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| [[151](#bib.bib151)] | 细胞质和核的分割 | H&E | 子宫颈 | CNN+ 从粗到精分割 | 私有数据集：53片切片，1400个细胞
    | 核区域检测：Acc=0.9450，F1=0.9453；分割：F1=0.8951±0.0215。 |'
- en: '| [[150](#bib.bib150)] | Segmentation of cytoplasm and Nuclei | H&E | Cervix
    | Multi-scale CNN + Graph partitioning + Touching cell splitting | Private dataset:
    53 images (slide) | Cytoplasm: Dice=0.95; Nuclei: Dice=0.99. |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| [[150](#bib.bib150)] | 细胞质和核的分割 | H&E | 子宫颈 | 多尺度CNN + 图划分 + 相邻细胞分割 | 私有数据集：53张图像（切片）
    | 细胞质：Dice=0.95；核：Dice=0.99。 |'
- en: '| [[149](#bib.bib149)] | Cell segmentation | Pap H&E | Cervix | Multi-scale
    CNN + Dynamic multi-template deformation | ISBI 2015\. Private dataset: 21 images
    (each image has 30$\sim$80 cells) | ISBI 2015: Dice=0.89; Private dataset: Dice=0.84.
    |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| [[149](#bib.bib149)] | 细胞分割 | Pap H&E | 子宫颈 | 多尺度CNN + 动态多模板变形 | ISBI 2015\.
    私有数据集：21张图像（每张图像有30$\sim$80个细胞） | ISBI 2015：Dice=0.89；私有数据集：Dice=0.84。 |'
- en: '| [[6](#bib.bib6)] | Cell image segmentation and ranking | Pap | Cervix | CNN
    | BHS 2019 | Segmentation: P=0.73, R=0.65, F1=0.69, Time=4.75s; Ranking: mAP=0.936.
    |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| [[6](#bib.bib6)] | 细胞图像分割和排名 | Pap | 子宫颈 | CNN | BHS 2019 | 分割：P=0.73，R=0.65，F1=0.69，时间=4.75秒；排名：mAP=0.936。
    |'
- en: '| [[73](#bib.bib73)] | Cell nuclei segmentation | H&E | Breast | CNN + Seeded
    watershed | Public dataset: 80 images | Benign: Hausdorff distance=0.840, Jaccard
    distance=0.776; Malignant: Hausdorff distance=0.781, Jaccard distance=0.732. |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| [[73](#bib.bib73)] | 细胞核分割 | H&E | 乳腺 | CNN + 种子分水岭 | 公共数据集：80张图像 | 良性：Hausdorff距离=0.840,
    Jaccard距离=0.776; 恶性：Hausdorff距离=0.781, Jaccard距离=0.732。 |'
- en: '| [[16](#bib.bib16)] | Semantic instance segmentation of touching and overlapping
    objects | Pap | Cervix | U-Net | OSC-ISBI | Dice=0.895±.0.079. |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| [[16](#bib.bib16)] | 接触和重叠物体的语义实例分割 | Pap | 宫颈 | U-Net | OSC-ISBI | Dice=0.895±.0.079。
    |'
- en: '| [[187](#bib.bib187)] | Cervical cell segmentation | Pap | Cervix | Attention
    mechanism + U-Net + Random walk | ISBI 2014 | Nuclei: $P_{p}$=0.94 ±0.06, $R_{p}$=0.95
    ±0.05, Dice=0.93 ±0.04; Cytoplasm: $TP_{p}$=0.94 ±0.06, $FP_{p}$=0.003 ±0.004,
    Dice=0.93 ±0.07. |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| [[187](#bib.bib187)] | 宫颈细胞分割 | Pap | 宫颈 | 注意机制 + U-Net + 随机游走 | ISBI 2014
    | 细胞核：$P_{p}$=0.94 ±0.06, $R_{p}$=0.95 ±0.05, Dice=0.93 ±0.04; 细胞质：$TP_{p}$=0.94
    ±0.06, $FP_{p}$=0.003 ±0.004, Dice=0.93 ±0.07。 |'
- en: '| [[171](#bib.bib171)] | Instance segmentation | Pap | Cervix | U-Net + Star-convex
    polygons | OSC-ISBI | Dice=0.85 ± 0.07. |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| [[171](#bib.bib171)] | 实例分割 | Pap | 宫颈 | U-Net + 星形凸多边形 | OSC-ISBI | Dice=0.85
    ± 0.07。 |'
- en: '| [[56](#bib.bib56)] | Segmentation and classification of cervical nuclei |
    Pap | Cervix | U-Net | Herlev | Classification: Acc=0.988; Segmentation: ZSI=0.97.
    |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| [[56](#bib.bib56)] | 宫颈细胞核分割和分类 | Pap | 宫颈 | U-Net | Herlev | 分类：Acc=0.988;
    分割：ZSI=0.97。 |'
- en: '| [[159](#bib.bib159)] | Cytological examination (overlapping cell segmentation)
    | Pap | Cervix | CNN+ Shape prior (dynamic shape modeling) | ISBI 2014 | Nuclei:
    $P_{p}$=0.94 ±0.06, $R_{p}$=0.95 ±0.06, ZSI=0.94 ±0.04; Cytoplasm: ZSI=0.90 ±0.08.
    |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| [[159](#bib.bib159)] | 细胞学检查（重叠细胞分割） | Pap | 宫颈 | CNN+ 形状先验（动态形状建模） | ISBI
    2014 | 细胞核：$P_{p}$=0.94 ±0.06, $R_{p}$=0.95 ±0.06, ZSI=0.94 ±0.04; 细胞质：ZSI=0.90
    ±0.08。 |'
- en: '| [[152](#bib.bib152)] | Overlapping cytoplasms segmentation | Pap H&E | Cervix
    | Shape mask generator + Refining shape priors | ISBI 2015\. Private dataset:
    160 clumps with 962 cytoplasms | Pap: Dice=0.854 ± 0.049; H&E: Dice=0.846 ± 0.054.
    |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| [[152](#bib.bib152)] | 重叠细胞质分割 | Pap H&E | 宫颈 | 形状掩模生成器 + 形状先验优化 | ISBI 2015\.
    私有数据集：160团块，962个细胞质 | Pap: Dice=0.854 ± 0.049; H&E: Dice=0.846 ± 0.054。 |'
- en: '| [[172](#bib.bib172)] | Nuclei detection, cytoplasm segmentation | Pap | Cervix
    | CNN + Double-window + Image processing + Deeplab V2 + CRFs + Cell boundary refinement
    | ISBI 2014; ISBI 2015; Private dataset: 580 image (patch) | ISBI 2014: Dice=0.93
    ± 0.04; ISBI 2015: Dice=0.92 ± 0.05; Private: Dice=0.92 ± 0.04. |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| [[172](#bib.bib172)] | 细胞核检测，细胞质分割 | Pap | 宫颈 | CNN + 双窗口 + 图像处理 + Deeplab
    V2 + CRFs + 细胞边界优化 | ISBI 2014; ISBI 2015; 私有数据集：580图像（补丁） | ISBI 2014：Dice=0.93
    ± 0.04; ISBI 2015：Dice=0.92 ± 0.05; 私有数据集：Dice=0.92 ± 0.04。 |'
- en: '| Detect-then-segment methods |  |  |  |  |  |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 检测-然后分割方法 |  |  |  |  |  |'
- en: '| [[148](#bib.bib148)] | Pap smear cancer screening | Pap | Cervix | Mask R-CNN
    + Fine-tuning | Private dataset: 178 images in classes of normal (2,734 ), atypical
    (494), low-grade (148), and high-grade cells (84) | Image-level: mAP=0.578, Acc=0.917,
    Sens=0.917,Spec=0.917; Nucleus: Acc=0.898, Sens=0.725, Spec=0.943. |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| [[148](#bib.bib148)] | 宫颈癌筛查 | Pap | 宫颈 | Mask R-CNN + 微调 | 私有数据集：178张图像，正常（2,734），非典型（494），低级别（148），高级别细胞（84）
    | 图像级别：mAP=0.578, Acc=0.917, Sens=0.917, Spec=0.917; 细胞核：Acc=0.898, Sens=0.725,
    Spec=0.943。 |'
- en: '| [[195](#bib.bib195)] | Cell segmentation | Pap | Cervix | PRN + Cell association
    matrix | Private dataset: 413 images (annotated 4,439 cytoplasm and 4,789 nuclei)
    | Cytoplasm: AJI=0.7185, F1=0.7497; Nuclei: AJI=0.5496, F1=0.7554. |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| [[195](#bib.bib195)] | 细胞分割 | Pap | 宫颈 | PRN + 细胞关联矩阵 | 私有数据集：413张图像（标注4,439个细胞质和4,789个细胞核）
    | 细胞质：AJI=0.7185, F1=0.7497; 细胞核：AJI=0.5496, F1=0.7554。 |'
- en: '| [[194](#bib.bib194)] | Cell instance segmentation | Pap | Cervix | RPN +
    Knowledge distillation | Private dataset: 413 labeled (4,439 cytoplasm and 4,789
    nuclei) and 4,371 unlabeled images | 100% labeled: AJI=0.6643, mAP=40.52; 80%.
    labeled: AJI=0.6692, mAP=0.4013; 40% labeled: AJI=0.6449, mAP=0.3726. |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| [[194](#bib.bib194)] | 细胞实例分割 | Pap | 宫颈 | RPN + 知识蒸馏 | 私有数据集：413张标注（4,439细胞质和4,789细胞核）和4,371张未标注图像
    | 100%标注：AJI=0.6643, mAP=40.52; 80%标注：AJI=0.6692, mAP=0.4013; 40%标注：AJI=0.6449,
    mAP=0.3726。'
- en: 4.4.1 Segment-then-refine method
  id: totrans-273
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.1 分割-然后-优化方法
- en: Cytological structures can be segmented by segmentation models, like U-Net.
    However, overlapping areas belonging to several cells bring defiance of accurately
    segmenting each cell structure. To overcome this issue, different refinement strategies
    are proposed to add after the coarse segmentation model for fine-level segmentation.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 细胞学结构可以通过分割模型进行分割，例如 U-Net。然而，属于多个细胞的重叠区域使得准确分割每个细胞结构变得困难。为了解决这个问题，提出了不同的精细化策略，以便在粗分割模型之后进行细级别的分割。
- en: The segmentation network was originally implemented by establishing a pixel-wise
    classification network through CNN. [[150](#bib.bib150)] designed a multi-scale
    convolutional network for coarse segmentation. [[73](#bib.bib73)] proposed a more
    complex CNN structure consisting of four convolutional layers, two max-pooling
    layers, and one fully connected layer. This architecture was utilized in the first
    stage for nuclei segmentation in cytological images.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 分割网络最初通过建立一个基于 CNN 的像素级分类网络来实现。[[150](#bib.bib150)] 设计了一个用于粗分割的多尺度卷积网络。[[73](#bib.bib73)]
    提出了一个更复杂的 CNN 结构，包括四个卷积层、两个最大池化层和一个全连接层。该架构在细胞图像的第一阶段用于核分割。
- en: Afterwards, U-Net almost replaces the previous pixel-level classification network
    after its occurrence, especially in biomedical image segmentation [[133](#bib.bib133)].
    U-Net is a downsampling-upsampling structure with skip connections for combining
    low-level and high-level features. Recently, U-Net has made great achievements
    in medical image segmentation. For example, [[41](#bib.bib41)] designed U-Net
    for cell counting, detection, and segmentation. This work illustrated its potential
    for cellular structure analysis. In cytology image segmentation, U-Net has been
    introduced as the backbone for segmenting cellular objects in various cytology,
    such as oral [[105](#bib.bib105)], cervix [[6](#bib.bib6)], and breast [[73](#bib.bib73)].
    Several works focus on improving the performance of U-Net to enhance their capacities
    of cell segmentation. For instance, [[16](#bib.bib16)] proposed to mix 2D and
    3D U-Net for semantic instance segmentation of touching objects. [[187](#bib.bib187)]
    introduced attention mechanism to improve U-Net for focusing on ROIs. Besides,
    [[56](#bib.bib56)] improved U-Net by adding residual blocks, densely connected
    blocks, and a fully convolutional layer as a bottleneck between encoder-decoder
    blocks for nuclei segmentation in cervical images.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 此后，U-Net 几乎取代了之前的像素级分类网络，特别是在生物医学图像分割中 [[133](#bib.bib133)]。U-Net 是一个具有跳跃连接的下采样-上采样结构，用于结合低级特征和高级特征。最近，U-Net
    在医学图像分割中取得了巨大成就。例如，[[41](#bib.bib41)] 设计了 U-Net 用于细胞计数、检测和分割。这项工作展示了它在细胞结构分析中的潜力。在细胞学图像分割中，U-Net
    已被引入作为分割各种细胞对象的骨干网，例如口腔 [[105](#bib.bib105)]、宫颈 [[6](#bib.bib6)] 和乳腺 [[73](#bib.bib73)]。一些研究集中于提高
    U-Net 的性能，以增强其细胞分割能力。例如，[[16](#bib.bib16)] 提出了混合 2D 和 3D U-Net 以进行接触对象的语义实例分割。[[187](#bib.bib187)]
    引入了注意力机制以改善 U-Net 对 ROIs 的关注。此外，[[56](#bib.bib56)] 通过添加残差块、密集连接块和一个全卷积层作为编码器-解码器块之间的瓶颈来改进
    U-Net，以实现宫颈图像中的核分割。
- en: 'In segment-then-refine methods, the second stage is to address the issue of
    overlapping and refine segmentation results. Most of them take the shape prior
    of cell into considerations. For instance, [[149](#bib.bib149)] proposed a dynamic
    multi-template deformation model together with high-level morphological constrain
    for further boundary refinement. [[73](#bib.bib73)] designed a series of refinement
    strategies in the second stage: conditional erosion for determining nuclei seeds,
    the seeded watershed for separation overlapping nuclei, and aggregating segmentation
    results for overlapping and non-overlapping nuclei. In addition, [[187](#bib.bib187)]
    proposed a graph-based random walk method for extracting both nucleus and cytoplasm
    of overlapping cervical cells. This method utilized polar coordinate sampling
    for removing fake nuclei. Its experimental results in ISBI 2014 dataset showed
    the performance improvement on extracting an individual cell from heavy overlapping
    cell clumps. [[171](#bib.bib171)] proposed to predict object probability, star
    distance, and overlap probability based on U-Net. Then, non-maximum suppression
    was used to generate overlapping cell segmentation results. These refinement strategies
    can achieve more accurate segmentation results, especially for overlapping regions.
    However, complex clinical data will present more challenges to the reproducibility
    and generalizability.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在分割-再细化方法中，第二阶段是解决重叠问题并细化分割结果。大多数方法考虑了细胞的形状先验。例如，[[149](#bib.bib149)]提出了一个动态多模板变形模型，并结合高级形态学约束进一步细化边界。[[73](#bib.bib73)]在第二阶段设计了一系列细化策略：用于确定细胞核种子的条件腐蚀，种子分水岭用于分离重叠的细胞核，以及聚合分割结果以处理重叠和非重叠的细胞核。此外，[[187](#bib.bib187)]提出了一种基于图的随机游走方法，用于提取重叠的子宫颈细胞的细胞核和细胞质。该方法利用极坐标采样去除虚假细胞核。其在ISBI
    2014数据集中的实验结果显示，提取个别细胞从重叠的细胞团中表现出性能提升。[[171](#bib.bib171)]提出基于U-Net预测物体概率、星距和重叠概率。然后，使用非极大值抑制生成重叠细胞的分割结果。这些细化策略可以实现更准确的分割结果，特别是对于重叠区域。然而，复杂的临床数据将对可重复性和普适性提出更多挑战。
- en: In addition, some other models have been proposed for cytological segmentation.
    [[159](#bib.bib159)] designed a two-stage segmentation model, which consists of
    initial segmentation based on Voronoi diagram, and final segmentation with learning
    shape prior model. In order to segment overlapping cervical cytoplasms, [[152](#bib.bib152)]
    proposed a shape mask generator to refine shape priors. [[172](#bib.bib172)] presented
    an architecture for cell detection and cytoplasm segmentation. In this method,
    conditional random field algorithm (CRFs) and cell boundary refinement were utilized
    to achieve accurate segmentation of overlapping cells in cervical cytology.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还提出了一些其他模型用于细胞学分割。[[159](#bib.bib159)]设计了一个两阶段分割模型，包括基于Voronoi图的初步分割和利用形状先验模型的最终分割。为了分割重叠的子宫颈细胞质，[[152](#bib.bib152)]提出了一种形状掩码生成器来细化形状先验。[[172](#bib.bib172)]提出了一种用于细胞检测和细胞质分割的架构。在该方法中，利用条件随机场算法（CRFs）和细胞边界细化来实现子宫颈细胞重叠的准确分割。
- en: 'Table 8: Overview of deep learning-based studies of other tasks for computational
    cytology'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 表8：基于深度学习的其他计算细胞学任务研究概述
- en: '| Reference | Application | Staining | Organ | Method | Dataset | Result |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 应用 | 染色 | 器官 | 方法 | 数据集 | 结果 |'
- en: '| [[99](#bib.bib99)] | Super resolution | Pap | Cervix | Image registration
    + GAN | Private dataset: 142 WSIs (118 for training and 24 for testing) with 174,500
    patches | PSNR=26.92, SSIM=0.88, MOS=3.80. |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| [[99](#bib.bib99)] | 超分辨率 | Pap | 子宫颈 | 图像配准 + GAN | 私有数据集：142张WSI（118用于训练，24用于测试），共174,500块补丁
    | PSNR=26.92, SSIM=0.88, MOS=3.80。 |'
- en: '| [[98](#bib.bib98)] | Super resolution | Pap | Cervix | Backbone + Self-texture
    + Flexible reconstruction | Public dataset: 5 slides (25,000 patches) | PSNR=35.47,
    SSIM=0.958, MSE=22.07. |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| [[98](#bib.bib98)] | 超分辨率 | Pap | 子宫颈 | 主干网络 + 自我纹理 + 灵活重建 | 公开数据集：5张切片（25,000块补丁）
    | PSNR=35.47, SSIM=0.958, MSE=22.07。 |'
- en: '| [[164](#bib.bib164)] | Mutual stain conversion | Giemsa and Pap | Lung |
    CycleGAN | Private dataset: 191 Giemsa-stained images and 209 Papanicolaou-stained
    images | T test: P-value $<$0.001. |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| [[164](#bib.bib164)] | 互染转换 | Giemsa和Pap | 肺 | CycleGAN | 私有数据集：191张Giemsa染色图像和209张Papanicolaou染色图像
    | T检验：P值 $<$0.001。 |'
- en: 4.4.2 Detect-then-segment method
  id: totrans-284
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.2 检测-再分割方法
- en: 'For the segmentation of instance objects in cytology images, these methods
    follow the detect-then-segment paradigm, which divides this task into two steps:
    detecting all objects in whole images, then segmenting instances from each detected
    object. As one popular architecture of this paradigm, Mask R-CNN improves Faster
    R-CNN by adding full connected layers as the segmentation head. Thus, it can output
    the prediction of classification, detection, and segmentation via a single architecture
    [[51](#bib.bib51), [128](#bib.bib128)].'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 对于细胞学图像中的实例对象分割，这些方法遵循检测-分割范式，将任务分为两个步骤：检测整个图像中的所有对象，然后从每个检测到的对象中分割实例。作为这一范式的一个流行架构，Mask
    R-CNN通过添加全连接层作为分割头来改进Faster R-CNN。因此，它可以通过单一架构输出分类、检测和分割的预测[[51](#bib.bib51),
    [128](#bib.bib128)]。
- en: Instance segmentation is regarded as one of the most challenging tasks in cytology
    image analysis, because it not only predicts the instance morphology but also
    distinguishes different instances (e.g., cytoplasm, nucleus). Building detect-then-segment
    models can solve this problem, since they can predict instance detection and segmentation
    results through a single architecture. A few studies investigated this category
    of cytological segmentation methods. Existing researches almost employ Mask R-CNN
    as their architecture, because there is no need for further design of overlapping
    areas in this category of methods. For example, [[148](#bib.bib148)] adopted Mask
    R-CNN for specifying the bounding box, nucleus mask, and class of each cervical
    cell. In another study [[195](#bib.bib195)], authors utilized the multi-head attention
    mechanism to explore instance-level association by propagating features based
    on attention scores. Consequently, this proposed model improved the instance representation
    and achieved better instance segmentation performance than original Mask R-CNN.
    To further reduce reliance on large amounts of labeled data, [[194](#bib.bib194)]
    proposed a semi-supervised learning approach to leverage both labeled and unlabeled
    data for instance segmentation by knowledge distillation.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 实例分割被认为是细胞图像分析中最具挑战性的任务之一，因为它不仅预测实例的形态，还区分不同的实例（例如，细胞质、细胞核）。构建检测-分割模型可以解决这个问题，因为它们可以通过单一架构预测实例检测和分割结果。一些研究探讨了这种细胞学分割方法的类别。现有研究几乎都采用了Mask
    R-CNN作为其架构，因为这种方法不需要对重叠区域进行进一步设计。例如，[[148](#bib.bib148)] 采用了Mask R-CNN来指定每个宫颈细胞的边界框、细胞核掩膜和类别。在另一项研究[[195](#bib.bib195)]中，作者利用多头注意力机制，通过基于注意力分数的特征传播来探索实例级的关联。因此，这种提出的模型改善了实例表示，并且比原始的Mask
    R-CNN取得了更好的实例分割性能。为了进一步减少对大量标注数据的依赖，[[194](#bib.bib194)] 提出了一种半监督学习方法，通过知识蒸馏利用标注数据和未标注数据进行实例分割。
- en: 4.5 Other tasks
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 其他任务
- en: 'In addition to the typical deep learning tasks, i.e., classification, detection,
    and segmentation, a few other tasks of cytology image analysis have also been
    investigated, such as super-resolution (SR), and stain conversion (Table [8](#S4.T8
    "Table 8 ‣ 4.4.1 Segment-then-refine method ‣ 4.4 Segmentation ‣ 4 Deep learning
    in cytology application ‣ Deep Learning for Computational Cytology: A Survey")).
    In the cytopathology screening, low-resolution and out-of-focus images will harm
    the decision-making process of cytologists, thus high-resolution digital cytopathology
    slides are the prerequisite for the interpretation of lesion cells. To control
    the image quality, super-resolution models are designed to generate high-resolution
    images. [[99](#bib.bib99)] introduced a GAN-based progressive multi-supervised
    super-resolution model (PathSRGAN) to learn the mapping of real low-resolution
    and high-resolution images. After that, they designed a self-texture transfer
    super-resolution and refocusing network (STSRNet) to reconstruct HR multi-focal
    plane (MFP) images from a single 2D low-resolution (LR) wide filed image [[5](#bib.bib5)].
    As mentioned in section [4.1](#S4.SS1 "4.1 Preprocessing ‣ 4 Deep learning in
    cytology application ‣ Deep Learning for Computational Cytology: A Survey"), different
    staining methods are used to observe different cell structures and components.
    DL-based stain conversion can be used for staining normalization and eliminate
    data heterogeneity issues. [[164](#bib.bib164)] proposed a CycleGAN-based style
    transfer model for stain conversion between Giemsa-stained and Pap-stained images.
    This study performed visual evaluations of the authenticity of cell nuclei, cytoplasm,
    and cell layouts of synthetic lung cytology images.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '除了典型的深度学习任务，如分类、检测和分割外，还有一些其他细胞图像分析任务也被研究过，如超分辨率（SR）和染色转换（表 [8](#S4.T8 "Table
    8 ‣ 4.4.1 Segment-then-refine method ‣ 4.4 Segmentation ‣ 4 Deep learning in cytology
    application ‣ Deep Learning for Computational Cytology: A Survey")）。在细胞病理学筛查中，低分辨率和失焦图像会影响细胞学家的决策过程，因此，高分辨率数字细胞病理切片是解释病变细胞的前提。为了控制图像质量，超分辨率模型被设计用来生成高分辨率图像。[[99](#bib.bib99)]
    引入了一种基于GAN的渐进式多重监督超分辨率模型（PathSRGAN），以学习真实低分辨率和高分辨率图像的映射。之后，他们设计了一个自我纹理转移超分辨率和再聚焦网络（STSRNet），从单个2D低分辨率（LR）广角图像重建高分辨率多焦平面（MFP）图像
    [[5](#bib.bib5)]。如[4.1](#S4.SS1 "4.1 Preprocessing ‣ 4 Deep learning in cytology
    application ‣ Deep Learning for Computational Cytology: A Survey")节所述，不同的染色方法用于观察不同的细胞结构和成分。基于DL的染色转换可用于染色规范化，并消除数据异质性问题。[[164](#bib.bib164)]
    提出了一个基于CycleGAN的样式转换模型，用于Giemsa染色图像和Pap染色图像之间的染色转换。本研究对合成肺细胞图像的细胞核、细胞质和细胞布局的真实性进行了视觉评估。'
- en: 5 Challenges and Promises
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 挑战与前景
- en: Despite great advancements and improvements in computational cytology over the
    last few years, there are still quite a few challenges and opening problems that
    are waiting to be resolved. Meanwhile, the development of deep learning technologies
    and pathology is continuously bringing vigor and vitality into this emerging field.
    In this section, we further discuss prospects and potential research directions
    of computational cytology.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在过去几年中计算细胞学取得了显著的进展和改进，但仍然存在许多挑战和待解决的问题。同时，深度学习技术和病理学的发展持续为这一新兴领域注入活力和生机。在本节中，我们将进一步探讨计算细胞学的前景和潜在研究方向。
- en: 5.1 Label-efficient learning with limited annotations
  id: totrans-291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 有限标注下的标签高效学习
- en: 'Data is regarded as the prerequisite of learning-based methods, because it
    is hard to develop effective models without good quality datasets [[41](#bib.bib41),
    [63](#bib.bib63)]. In medical image analysis, large-scale labeling can be a heavy
    burden for cytologists, because they need to first manually delineate ROIs in
    WSIs, then annotate each object (e.g., nucleus, cell, and cluster) in these ROIs
    by the box or mask. Compared with the extensive dataset in histopathology (such
    as TCGA [[168](#bib.bib168)]), public datasets of cytology are more limited not
    only in their numbers, but also in cancer types and annotation types (see in Table
    [1](#S2.T1 "Table 1 ‣ 2.4 Transfer Learning ‣ 2 Deep learning methodology ‣ Deep
    Learning for Computational Cytology: A Survey")). Therefore, how to efficiently
    utilize datasets with limited annotations can be challenging for developing cytological
    analysis models [[38](#bib.bib38), [21](#bib.bib21)].'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '数据被视为基于学习的方法的前提，因为没有高质量的数据集很难开发有效的模型[[41](#bib.bib41), [63](#bib.bib63)]。在医学图像分析中，大规模标注对细胞学家来说可能是沉重的负担，因为他们需要首先手动勾画WSIs中的ROIs，然后使用框或掩码标注这些ROIs中的每个对象（例如细胞核、细胞和簇）。与组织病理学中的广泛数据集（如TCGA
    [[168](#bib.bib168)]）相比，细胞学的公共数据集不仅在数量上有限，而且在癌症类型和标注类型上也较少（见表[1](#S2.T1 "Table
    1 ‣ 2.4 Transfer Learning ‣ 2 Deep learning methodology ‣ Deep Learning for Computational
    Cytology: A Survey")）。因此，如何有效利用有限标注的数据集对于开发细胞学分析模型来说可能是一个挑战[[38](#bib.bib38),
    [21](#bib.bib21)]。'
- en: 'In recent years, the concept of label-efficient learning is proposed to makes
    full use of the limited annotations for leveraging information, including semi-supervised
    learning, multiple instance learning, mixed supervised learning, etc. Specifically,
    semi-supervised learning aims to solve this problem by learning knowledge from
    both labeled data and unlabeled data. Recently, [[194](#bib.bib194)] designed
    a semi-supervised learning method by a mask-guided teacher-student framework for
    overlapping cell instance segmentation. Another learning scheme, MIL utilizes
    image-level annotations for instance-level tasks, which has been investigated
    in the field of medical image analysis, especially for histopathology. Recently,
    [[38](#bib.bib38)] proposed a MIL-based algorithm in thyroid cytology, which can
    simultaneously predict multiple bag and instance-level labels for thyroid malignancy
    prediction from WSIs. However, the potential of MIL in pap smear image and other
    cytology images remains to be explored. As illustrated in Table [1](#S2.T1 "Table
    1 ‣ 2.4 Transfer Learning ‣ 2 Deep learning methodology ‣ Deep Learning for Computational
    Cytology: A Survey"), there are usually different annotation types in different
    datasets, including box, mask, and the image-level label. Recently, mixed supervised
    learning gains popularity in analyzing images with different types of annotations.
    It has been demonstrated as an effective learning scheme in medical domain. For
    example, [[97](#bib.bib97)] present a deep omni-supervised thoracic disease detection
    network from chest X-rays with massive image-level annotations and scarce lesion-level
    annotations. This learning paradigm can substantially reduce the demand for fine
    annotation, thus reducing workload of doctors significantly.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '近年来，提出了标签高效学习的概念，旨在充分利用有限的标注信息，包括半监督学习、多实例学习、混合监督学习等。具体而言，半监督学习通过从标注数据和未标注数据中学习知识来解决这个问题。最近，[[194](#bib.bib194)]
    设计了一种基于掩码引导的教师-学生框架的半监督学习方法，用于重叠细胞实例分割。另一种学习方案，MIL，利用图像级别的标注进行实例级别的任务，这在医学图像分析领域，尤其是组织病理学中已有研究。最近，[[38](#bib.bib38)]
    提出了一个基于MIL的算法，用于甲状腺细胞学，可以同时预测来自WSIs的多个包和实例级别的标签，以预测甲状腺恶性肿瘤。然而，MIL在宫颈涂片图像和其他细胞学图像中的潜力尚待探索。如表[1](#S2.T1
    "Table 1 ‣ 2.4 Transfer Learning ‣ 2 Deep learning methodology ‣ Deep Learning
    for Computational Cytology: A Survey")所示，不同数据集中通常存在不同的标注类型，包括框、掩码和图像级标签。最近，混合监督学习在分析具有不同类型标注的图像时越来越受欢迎。它已被证明在医学领域是一种有效的学习方案。例如，[[97](#bib.bib97)]
    提出了一种基于深度全监督的胸部疾病检测网络，使用大量的图像级标注和稀缺的病变级标注。这种学习范式可以显著减少对精细标注的需求，从而大大减轻医生的工作负担。'
- en: In addition to the effective utilization of annotations, it is also promising
    to build efficient labeling approaches for reducing the burden on annotators.
    For example, introducing human knowledge into the loop of annotation can effectively
    and actively obtain accurate and credible annotations. [[70](#bib.bib70)] proposed
    an annotating method named NuClick with a squiggle as a guiding signal, enabling
    it to segment the glandular boundaries. However, this method still requires human
    full attention to annotate samples, which is a huge cost for society and tedious
    for human experts. For cytology images, they always contain numerous cells, especially
    in giga-pixel WSIs, how to establish an effective labeling process remains largely
    unexplored.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 除了有效利用注释外，建立高效的标注方法以减少标注者的负担也很有前景。例如，将人类知识引入注释环节可以有效地、主动地获得准确可靠的注释。[[70](#bib.bib70)]提出了一种名为NuClick的注释方法，该方法使用波浪线作为指导信号，使其能够分割腺体边界。然而，这种方法仍然需要人工全神贯注地标注样本，这对社会来说成本巨大，对人类专家来说也很繁琐。对于细胞学图像，它们通常包含大量细胞，特别是在吉比像素WSI中，如何建立一个有效的标注过程仍然很大程度上未被探索。
- en: 5.2 Fine-grained classification and morphological feature characterization
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 细粒度分类与形态学特征表征
- en: Although various deep learning applications have been developed in cytology
    image analysis (e.g., classification, detection, and segmentation), some of these
    tasks are worthy of further investigation, such as fine-grained classification
    for cancer diagnosis and instance segmentation in overlapping cell scenarios.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在细胞学图像分析中已经开发了各种深度学习应用（例如分类、检测和分割），但一些任务仍值得进一步研究，例如癌症诊断的细粒度分类和重叠细胞场景中的实例分割。
- en: As a fundamental task, cytological classification aims to distinguish between
    benign and malignant cells. However, there are many types of cells with varying
    degrees of cancerization. For example, the types of cervical cells include squamous
    cells and glandular cells, and they can be further subdivided into subcategories
    [[113](#bib.bib113)]. Besides, each type of cell has large intra-variance and
    small inter-variance. These factors bring significant challenges to deep feature
    extractors for learning distinguishable features. Further fine-grained classification
    of malignant cells can solve these problems and assist cytologists in accurate
    cancer diagnosis. [[186](#bib.bib186)] demonstrated the difficulty of fine-grained
    tasks compared to coarse-grained tasks. In their experiments, the classifier of
    cervical cytology showed significantly worse performance of fine-grained than
    coarse-grained tasks. Some studies introduced additional information and prior
    to learn fine-grained feature representations. For example, [[87](#bib.bib87)]
    built a fine-grained classification model for distinguishing cervical cells. The
    authors introduced cytoplasm and nucleus masks as morphological information to
    extract fine-grained features. Therefore, fine-grained feature extractors for
    learning subtle feature diversity are essential for cytology image analysis.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一项基础任务，细胞学分类旨在区分良性和恶性细胞。然而，有许多细胞类型具有不同程度的癌变。例如，宫颈细胞的类型包括鳞状细胞和腺体细胞，它们可以进一步细分为子类别[[113](#bib.bib113)]。此外，每种细胞类型的内部差异很大，而不同类型细胞之间的差异较小。这些因素给深度特征提取器带来了显著挑战，使得提取可区分的特征变得困难。进一步的恶性细胞细粒度分类可以解决这些问题，并帮助细胞学家进行准确的癌症诊断。[[186](#bib.bib186)]展示了细粒度任务相比于粗粒度任务的难度。在他们的实验中，宫颈细胞学的分类器在细粒度任务上的表现明显低于粗粒度任务。一些研究引入了额外的信息和先验知识以学习细粒度特征表示。例如，[[87](#bib.bib87)]建立了一个用于区分宫颈细胞的细粒度分类模型。作者引入了细胞质和细胞核掩模作为形态学信息来提取细粒度特征。因此，学习细微特征多样性的细粒度特征提取器对于细胞学图像分析至关重要。
- en: 'Another fundamental application, instance-level segmentation of cytoplasm and
    nucleus can be used to calculate the nuclear-cytoplasmic ratio, which is an essential
    indicator for distinguishing malignant cells. However, cell overlapping brings
    challenges for accurately instance segmenting cellular structures [[151](#bib.bib151),
    [150](#bib.bib150)]. A large amount of studies focus on this challenge, and most
    of them divide this task into two stages: semantic segmentation models for coarse
    segmentation, followed by refinement processing technologies for overlapping areas
    [[149](#bib.bib149), [187](#bib.bib187)]. These multiple-stage architectures introduce
    lots of human designs and interventions, leading to increasing training difficulties
    and poor generalizations. Recently, few studies investigate the feasibility of
    building end-to-end models by the detect-then-segment paradigm [[195](#bib.bib195)],
    which detect objects and then segment each detected object in a single learning
    framework. Although cytological segmentation has made some progress, for complex
    morphological feature representation, building end-to-end instance segmentation
    models still remains value to be studied and explored.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个基本应用是细胞质和细胞核的实例级分割，这可以用来计算核-细胞质比，这是区分恶性细胞的一个重要指标。然而，细胞重叠给准确的实例分割细胞结构带来了挑战[[151](#bib.bib151),
    [150](#bib.bib150)]。大量研究集中在这一挑战上，大多数研究将任务分为两个阶段：首先是用于粗分割的语义分割模型，其次是针对重叠区域的细化处理技术[[149](#bib.bib149),
    [187](#bib.bib187)]。这些多阶段架构引入了大量的人工设计和干预，导致训练难度增加和泛化能力差。最近，一些研究探讨了通过检测-再分割范式构建端到端模型的可行性[[195](#bib.bib195)]，该范式在一个学习框架中检测对象并随后对每个检测到的对象进行分割。尽管细胞学分割已有所进展，但在复杂形态特征表示方面，构建端到端实例分割模型仍然具有研究和探索的价值。
- en: 5.3 Effective feature representation learning
  id: totrans-299
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 有效特征表示学习
- en: In deep learning, the performance of downstream tasks will be greatly influenced
    by the feature representation capability of feature extractors. The main goal
    of DL models in cytology is to learn effective features of cytology images for
    cell classification, cellular objects detection and segmentation. Thus, building
    models that effectively represent features is crucial for cytology image analysis.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，下游任务的性能将受到特征提取器特征表示能力的极大影响。细胞学领域DL模型的主要目标是学习细胞学图像的有效特征，以进行细胞分类、细胞对象检测和分割。因此，构建能够有效表示特征的模型对于细胞学图像分析至关重要。
- en: Recently, attention mechanism has made promising achievements in effective representation
    of image features, thus improving performances of down-stream tasks [[170](#bib.bib170)].
    The deep neural networks with attention modules can reduce the dependence on external
    information, and be better at capturing internal correlations of data or features.
    In cytology images, there are too many useless objects, like background, mucus,
    blood, and inflammatory cells [[55](#bib.bib55)]. Attention mechanism-based strategies
    can make deep models focus more on lesion-related regions or object-related (e.g.,
    nuclei, cytoplasm) regions. Besides, the attention mechanism not only improves
    the deep learning model but also provides convenience for model visualization
    and understanding. A few studies have validated the superiority of the attention
    mechanism in cytology image analysis. [[187](#bib.bib187)] utilized the attention
    mechanism to enhance U-Net for segmentation of overlapping cervical cells. Besides,
    [[195](#bib.bib195)] introduced a multi-head attention mechanism module into the
    instance segmentation model for improving instance representation. These studies
    integrated attention modules into the framework and achieved improved performances.
    After that, the popular structure with attention mechanism, transformer has been
    demonstrated its superiority of learning global dependencies in various applications
    [[37](#bib.bib37)]. Transformer-based structures are waiting to be investigated
    in cytology image analysis, such as building dependencies between different cells
    in patch images, or different regions in WSIs.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，注意力机制在有效表示图像特征方面取得了有希望的成就，从而提高了下游任务的表现[[170](#bib.bib170)]。具有注意力模块的深度神经网络可以减少对外部信息的依赖，更好地捕捉数据或特征的内部相关性。在细胞学图像中，存在许多无用的对象，如背景、粘液、血液和炎性细胞[[55](#bib.bib55)]。基于注意力机制的策略可以使深度模型更加关注病变相关区域或对象相关（例如，细胞核、细胞质）区域。此外，注意力机制不仅改善了深度学习模型，还提供了模型可视化和理解的便利。一些研究验证了注意力机制在细胞学图像分析中的优越性。[[187](#bib.bib187)]利用注意力机制增强了U-Net对重叠宫颈细胞的分割。此外，[[195](#bib.bib195)]将多头注意力机制模块引入实例分割模型中以提高实例表示。这些研究将注意力模块集成到框架中，实现了性能的提升。之后，带有注意力机制的流行结构Transformer在各种应用中展示了其学习全局依赖的优越性[[37](#bib.bib37)]。基于Transformer的结构有待在细胞学图像分析中进一步研究，例如在补丁图像中建立不同细胞之间的依赖关系，或在全切片图像中建立不同区域之间的依赖关系。
- en: 5.4 Generalizability and robustness
  id: totrans-302
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 泛化性和鲁棒性
- en: The generalizability of DL-based algorithms in computational cytology determines
    whether the model can be successfully applied to actual clinical scenarios with
    various influences. At present, many DL approaches for medical image analysis
    can obtain acceptable performance in their own datasets, but their clinical performance
    is far from reaching practical standards [[90](#bib.bib90)].
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 基于深度学习的算法在计算细胞学中的泛化性决定了模型是否能够成功应用于具有各种影响的实际临床场景。目前，许多用于医学图像分析的深度学习方法在自身数据集上可以获得可接受的性能，但其临床表现远未达到实际标准[[90](#bib.bib90)]。
- en: Due to various specimen collection methods, staining techniques and imaging
    protocols, the data heterogeneity is the key reason for the poor clinical performance.
    It can lead to the weak robustness and generalization capability of DL models,
    thus performing poorly when applied to unseen data scenarios. Clinically, the
    performance of these DL models could degrade significantly, leading to low clinical
    reproducibility [[73](#bib.bib73)].
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 由于各种样本采集方法、染色技术和成像协议，数据异质性是导致临床表现不佳的主要原因。这可能导致深度学习模型的鲁棒性和泛化能力较弱，因此在应用于未见过的数据场景时表现较差。在临床上，这些深度学习模型的性能可能显著下降，导致临床重复性低[[73](#bib.bib73)]。
- en: Extensive researchers are investigating to mitigate this issue. For image processing
    strategies, normalization methods are utilized to pre-process input data in many
    image analysis tasks. These methods provide limited benefit in DL-based medical
    image analysis, because two datasets can be influenced and normalized against
    each other [[101](#bib.bib101)]. For learning strategy, domain adaptation can
    alleviate this problem by transferring knowledge for decreasing the need for annotations
    of target tasks [[117](#bib.bib117)]. Domain adaptation has been used for other
    medical scenarios with cross-domain data (e.g., CT and MRI [[23](#bib.bib23)]),
    the potential of domain adaptation methods in cytology image analysis remains
    to be explored. For instance, building cross-domain learning framework to analyze
    multi-domain images, such as images from multi-center, differently stained cytology
    images, and even different pathology images (e.g., cytology and histopathology).
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 大量研究人员正在致力于缓解这一问题。对于图像处理策略，归一化方法被用于许多图像分析任务中的数据预处理。这些方法在基于深度学习的医学图像分析中效果有限，因为两个数据集可能会相互影响和归一化[[101](#bib.bib101)]。对于学习策略，领域自适应可以通过转移知识来减轻这个问题，从而减少目标任务的注释需求[[117](#bib.bib117)]。领域自适应已在其他医学场景中用于跨领域数据（例如，CT和MRI[[23](#bib.bib23)]），但其在细胞学图像分析中的潜力仍需探索。例如，建立跨领域学习框架来分析多领域图像，例如来自多中心的图像、不同染色的细胞学图像，甚至不同的病理图像（例如，细胞学和组织病理学）。
- en: Designing new models for robust feature extraction of cytology images is also
    worthy of being explored, especially for feature extractor, which aims to map
    cytology images from multi-center to the same feature space for learning domain-invariant
    representations, thereby addressing the data heterogeneity issue [[79](#bib.bib79)].
    In addition, multimodal data has been demonstrated to compensate for the missing
    information in single modality data [[190](#bib.bib190)]. For medical scenarios,
    [[145](#bib.bib145)] designs a multimodal fusion framework to combine histopathological
    images and genomic sequences for early-stage cancer prognosis. Similarly, multimodality
    or full modality learning is also worth exploring and studying in cytology applications.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 设计用于细胞学图像稳健特征提取的新模型也值得探索，特别是特征提取器，其旨在将多中心的细胞学图像映射到相同的特征空间，以学习领域不变的表示，从而解决数据异质性问题[[79](#bib.bib79)]。此外，多模态数据已被证明可以弥补单一模态数据中的缺失信息[[190](#bib.bib190)]。对于医学场景，[[145](#bib.bib145)]设计了一个多模态融合框架，将组织病理图像和基因组序列结合起来，用于早期癌症预后。同样，多模态或全模态学习在细胞学应用中也值得探索和研究。
- en: 5.5 Transparency and interpretability
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 透明度和可解释性
- en: Unlike other deep learning application scenarios, the medical domain not only
    focuses on the model performance in clinical practice but also its interpretability,
    which is of paramount importance in clinical decision-making. However, the black-box
    nature of DL algorithms lacking clinical interpretability and transparency has
    restricted its clinical adoption [[94](#bib.bib94)]. Therefore, explainable AI
    for medicine is introduced to establish the confidence between AI technologies
    and doctors/patients. There are some explorable issues in computational cytology,
    such as slide-level cytology screening based on rules, and visualization of the
    decision-making process of deep models.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他深度学习应用场景不同，医学领域不仅关注模型在临床实践中的性能，还关注其可解释性，这在临床决策中至关重要。然而，深度学习算法的黑箱特性缺乏临床可解释性和透明度，限制了其临床应用[[94](#bib.bib94)]。因此，引入了解释性人工智能以建立AI技术与医生/患者之间的信任。在计算细胞学中，有一些值得探索的问题，例如基于规则的幻灯片级细胞学筛查，以及深度模型决策过程的可视化。
- en: Visualization is regarded as one of techniques for interpretation. Current techniques
    mainly utilize attention mechanism to generate heatmaps to visualize the deep
    features and models, such as class activation mapping (CAM) [[193](#bib.bib193)].
    In cytology image analysis, a few studies have employed heat maps or feature maps
    for exploring the decision-making basis of deep learning models in the classification
    task. [[115](#bib.bib115)] used Grad-CAM to observe the model’s high response
    regions of urothelial cytology images, which can improve medical decision-making
    from the gradient of the differentiable model. For model-agnostic visualization,
    another technique, local interpretable model-agnostic explanation (LIME) [[131](#bib.bib131)]
    can be effective to provide the interpretability and transparency. LIME presents
    a locally faithful explanation by fitting a set of perturbed samples near the
    target sample using a potentially interpretable model. In addition to these mentioned
    methods, more visualization techniques are under exploration for interpretability.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化被视为一种解释技术。目前的技术主要利用注意机制生成热图以可视化深度特征和模型，例如类激活映射（CAM）[[193](#bib.bib193)]。在细胞学图像分析中，一些研究采用热图或特征图来探索深度学习模型在分类任务中的决策基础。[[115](#bib.bib115)]
    使用Grad-CAM观察模型对尿路上皮细胞学图像的高响应区域，这可以通过可微分模型的梯度改进医学决策。对于模型无关的可视化，另一种技术，即局部可解释模型无关解释（LIME）[[131](#bib.bib131)]，可以有效地提供可解释性和透明性。LIME通过使用可能可解释的模型拟合目标样本附近的一组扰动样本，提供局部可信的解释。除了这些提到的方法之外，更多的可视化技术正在探索中，以提升可解释性。
- en: To increase the credibility of deep models in computational cytology, researchers
    constructed slide-level screening system by assembling multiple tasks rather than
    predicting the final diagnosis results of cytology slides, which can assist pathologists
    to obtain multi-stage analysis results. [[199](#bib.bib199)] integrated DL-based
    classification, detection, and segmentation models to build a cervical LBC smear
    TBS diagnostic system. Another study, [[86](#bib.bib86)] built a dual-path network
    for outputting the detected lesions, followed by a rule-based risk stratification
    system. [[174](#bib.bib174)] divided the cervical WSI analysis into two stages,
    i.e., cervical lesion detection at the patch level in preselected ROIs, and normal/abnormal
    classification at the WSI level. The output of each stage of these multi-stage
    methods can provide intermediate explanations for model prediction and cytology
    screening, thus improving the transparency of the diagnostic process.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增加深度模型在计算细胞学中的可信度，研究人员通过组装多个任务构建了幻灯片级筛选系统，而不是预测细胞学幻灯片的最终诊断结果，这可以帮助病理学家获得多阶段分析结果。[[199](#bib.bib199)]
    整合了基于DL的分类、检测和分割模型，构建了一个宫颈LBC涂片TBS诊断系统。另一项研究[[86](#bib.bib86)] 构建了一个双路径网络用于输出检测到的病变，随后是基于规则的风险分层系统。[[174](#bib.bib174)]
    将宫颈WSI分析分为两个阶段，即在预选ROI中的补丁级别进行宫颈病变检测，以及在WSI级别进行正常/异常分类。这些多阶段方法的每个阶段的输出可以提供模型预测和细胞学筛查的中间解释，从而提高诊断过程的透明度。
- en: 5.6 Digital medicine and human-AI collaboration
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6 数字医学与人类-人工智能合作
- en: Digital medicine integrates medicine and information technology for clinical
    diagnosis and treatment, it aims to transform digital models to clinical scenarios
    [[13](#bib.bib13), [140](#bib.bib140)]. Although a large number of DL models report
    that they can achieve state-of-the-art performance, they are mostly validated
    on domain-specific datasets and cannot achieve the same good performance in clinical
    practice. Unavailability of data is one of the crucial factors leading to this
    problem, because data privacy cannot be overemphasized in medicine domain. Currently,
    privacy-preserving learning approaches are being explored and studied for improving
    the availability of multi-center data [[27](#bib.bib27)], e.g., federated learning
    [[132](#bib.bib132)]. Another crucial issue facing clinical transformation is
    that clinical data is usually more diverse and complex than collected training
    data, caused by variable clinical factors regarding imaging microscopes, staining
    techniques, patch extraction, and selection, etc. To address this issue, designing
    more robust architectures can make the model less dependent on data quality in
    digital medicine. In addition, cytologists analyze specimens of different cancer
    types using different diagnostic criteria [[113](#bib.bib113)], which makes it
    difficult for DL algorithms that focus on domain-specific cytology to adapt to
    different cancer scenarios.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 数字医学将医学和信息技术整合用于临床诊断和治疗，旨在将数字模型转化为临床场景[[13](#bib.bib13), [140](#bib.bib140)]。虽然大量DL模型报告其能实现最先进的性能，但这些模型大多是在特定领域的数据集上验证的，无法在临床实践中取得同样良好的效果。数据不可用性是导致这一问题的关键因素之一，因为数据隐私在医学领域无法过分强调。目前，隐私保护学习方法正在被探索和研究，以提高多中心数据的可用性[[27](#bib.bib27)]，例如，联邦学习[[132](#bib.bib132)]。临床转化面临的另一个关键问题是，临床数据通常比收集的训练数据更为多样和复杂，受到成像显微镜、染色技术、切片提取和选择等变数的影响。为了解决这个问题，设计更为健壮的架构可以使模型在数字医学中对数据质量的依赖性降低。此外，细胞学家使用不同的诊断标准分析不同类型的癌症标本[[113](#bib.bib113)]，这使得专注于领域特定细胞学的DL算法难以适应不同的癌症场景。
- en: In recent years, numerous studies show that the human-machine collaborative
    medical diagnosis system can achieve better diagnosis performance than conventional
    diagnosis systems by the intervention of human experts and assistance of machines
    [[199](#bib.bib199), [119](#bib.bib119)]. The DL algorithm in the intelligent
    medical system provides doctors with multi-level, and high-confidence prediction
    results. Besides, the digital diagnostic system provides doctors with real-time
    diagnostic information through human-computer interaction technology. The mart
    microscope system (ARM), designed by Google Health, has made an early breakthrough
    in this field [[28](#bib.bib28)]. ARM integrates AI algorithms with optical microscope
    to analyze pathological slides and provide pathologists analysis results (e.g.,
    lesion contour, probability heatmap) in the field of view by augmented reality
    technologies. Then, pathologists make the final diagnosis based on these quantitative
    and qualitative results. This computer-assisted diagnostic system has provided
    prospects for the automation of histopathology, cytology, parasitology, etc. However,
    there is still a long way to go in terms of accurate and efficient diagnosis,
    system integration, hardware resources, and AI algorithms.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，许多研究表明，人机协作医学诊断系统通过人类专家的干预和机器的辅助，能够实现比传统诊断系统更好的诊断性能[[199](#bib.bib199),
    [119](#bib.bib119)]。智能医疗系统中的DL算法为医生提供了多层次和高置信度的预测结果。此外，数字诊断系统通过人机交互技术向医生提供实时诊断信息。由Google
    Health设计的智能显微镜系统（ARM）在这一领域取得了早期突破[[28](#bib.bib28)]。ARM将AI算法与光学显微镜结合，通过增强现实技术分析病理切片，并在视野中提供病理学分析结果（例如，病变轮廓、概率热图）。然后，病理学家根据这些定量和定性结果做出最终诊断。该计算机辅助诊断系统为组织病理学、细胞学、寄生虫学等领域的自动化提供了前景。然而，在准确和高效诊断、系统集成、硬件资源和AI算法方面仍有很长的路要走。
- en: 6 Conclusion
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In recent years, the development of deep learning has enabled great success
    in computational cytology, showing signiﬁcant promise for efficient cancer screening.
    In this paper, we have comprehensively reviewed the current progress of deep learning-based
    methods in computational cytology, including supervised learning, weakly supervised
    learning, unsupervised learning, and transfer learning. More specifically, we
    survey image analysis-based approaches and state-of-the-art DL algorithms with
    the applications of classification, detection, and segmentation in cytology. Various
    applications of advanced DL-based works of various cytology were investigated
    in this paper, including the cervix, breast, lung, thyroid, oral, kidney, stomach,
    etc. We also summarize the evaluation metrics and public datasets for developing
    new models. Finally, we outline current challenges and potential directions for
    future research of computational cytology.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度学习的发展在计算细胞学中取得了巨大成功，显示了在癌症筛查中的显著前景。在这篇论文中，我们全面回顾了基于深度学习的方法在计算细胞学中的当前进展，包括监督学习、弱监督学习、无监督学习和迁移学习。更具体地，我们调查了基于图像分析的方法和最先进的深度学习算法在细胞学中的分类、检测和分割应用。本文探讨了先进的深度学习方法在各种细胞学应用中的应用，包括宫颈、乳腺、肺、甲状腺、口腔、肾脏、胃等。我们还总结了开发新模型的评估指标和公共数据集。最后，我们概述了计算细胞学当前面临的挑战和未来研究的潜在方向。
- en: Declaration of Competing Interest
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利益冲突声明
- en: The authors declare that they have no known competing financial interests or
    personal relationships that could have appeared to influence the work reported
    in this paper.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 作者声明他们没有已知的竞争性财务利益或个人关系，这些关系可能影响了本文报告的工作。
- en: CRediT authorship contribution statement
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CRediT 作者贡献声明
- en: 'Hao Jiang: Conceptualization, Methodology, Writing - original draft, Visualization.
    Yanning Zhou: Conceptualization, Formal analysis, Writing - review & editing.
    Yi Lin: Conceptualization, Writing - review & editing, Investigation. Ronald CK
    Chan: Formal analysis, Writing - review & editing. Jiang Liu: Conceptualization,
    Investigation. Hao Chen: Conceptualization, Funding acquisition, Project administration,
    Resources, Supervision, Writing - review & editing.'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 'Hao Jiang: 概念构建、方法学、原创草稿撰写、可视化。Yanning Zhou: 概念构建、形式分析、审稿及编辑。Yi Lin: 概念构建、审稿及编辑、调查。Ronald
    CK Chan: 形式分析、审稿及编辑。Jiang Liu: 概念构建、调查。Hao Chen: 概念构建、资助获取、项目管理、资源、监督、审稿及编辑。'
- en: Acknowledgments
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work was supported by Beijing Institute of Collaborative Innovation Program
    (No. BICI22EG01).
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了北京协同创新计划（No. BICI22EG01）的支持。
- en: References
  id: totrans-322
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Alberts et al. [2015] Alberts, B., Bray, D., Hopkin, K., Johnson, A.D., Lewis,
    J., Raff, M., Roberts, K., Walter, P., 2015. Essential cell biology. Garland Science.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alberts et al. [2015] Alberts, B., Bray, D., Hopkin, K., Johnson, A.D., Lewis,
    J., Raff, M., Roberts, K., Walter, P., 2015. 细胞生物学基础。Garland Science.
- en: Alberts et al. [2003] Alberts, B., Johnson, A., Lewis, J., Raff, M., Roberts,
    K., Walter, P., et al., 2003. Molecular biology of the cell. Scandinavian Journal
    of Rheumatology 32, 125–125.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alberts et al. [2003] Alberts, B., Johnson, A., Lewis, J., Raff, M., Roberts,
    K., Walter, P., et al., 2003. 细胞分子生物学。斯堪的纳维亚风湿病学杂志 32, 125–125.
- en: Albuquerque et al. [2021] Albuquerque, T., Cruz, R., Cardoso, J.S., 2021. Ordinal
    losses for classification of cervical cancer risk. PeerJ Computer Science 7, e457.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Albuquerque et al. [2021] Albuquerque, T., Cruz, R., Cardoso, J.S., 2021. 宫颈癌风险分类的序数损失。PeerJ
    计算机科学 7, e457.
- en: 'Amorim et al. [2020] Amorim, J.G.A., Macarini, L.A.B., Matias, A.V., Cerentini,
    A., Onofre, F.B.D.M., Onofre, A.S.C., Von Wangenheim, A., 2020. A novel approach
    on segmentation of agnor-stained cytology images using deep learning, in: 2020
    IEEE 33rd International Symposium on Computer-Based Medical Systems (CBMS), IEEE.
    pp. 552–557.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amorim et al. [2020] Amorim, J.G.A., Macarini, L.A.B., Matias, A.V., Cerentini,
    A., Onofre, F.B.D.M., Onofre, A.S.C., Von Wangenheim, A., 2020. 基于深度学习的Agnor染色细胞学图像分割的新方法，见：2020
    IEEE 第33届计算机医学系统国际研讨会（CBMS），IEEE。第552–557页。
- en: 'An et al. [2021] An, Y., Shen, H.W., Shan, G., Li, G., Liu, J., 2021. Stsrnet:
    Deep joint space–time super-resolution for vector field visualization. IEEE Computer
    Graphics and Applications 41, 122–132.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: An et al. [2021] An, Y., Shen, H.W., Shan, G., Li, G., Liu, J., 2021. Stsrnet：用于矢量场可视化的深度联合时空超分辨率。IEEE
    计算机图形与应用 41, 122–132.
- en: Araujo et al. [2019] Araujo, F.H., Silva, R.R., Ushizima, D.M., Rezende, M.T.,
    Carneiro, C.M., Bianchi, A.G.C., Medeiros, F.N., 2019. Deep learning for cell
    image segmentation and ranking. Computerized Medical Imaging and Graphics 72,
    13–21.
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Araujo 等人 [2019] Araujo, F.H., Silva, R.R., Ushizima, D.M., Rezende, M.T., Carneiro,
    C.M., Bianchi, A.G.C., Medeiros, F.N., 2019. 用于细胞图像分割和排序的深度学习。Computerized Medical
    Imaging and Graphics 72, 13–21。
- en: Awan et al. [2021] Awan, R., Benes, K., Azam, A., Song, T.H., Shaban, M., Verrill,
    C., Tsang, Y.W., Snead, D., Minhas, F., Rajpoot, N., 2021. Deep learning based
    digital cell profiles for risk stratification of urine cytology images. Cytometry
    Part A .
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Awan 等人 [2021] Awan, R., Benes, K., Azam, A., Song, T.H., Shaban, M., Verrill,
    C., Tsang, Y.W., Snead, D., Minhas, F., Rajpoot, N., 2021. 基于深度学习的数字细胞画像用于尿液细胞学图像的风险分层。Cytometry
    Part A。
- en: 'Bakht et al. [2020] Bakht, A.B., Javed, S., Dina, R., Almarzouqi, H., Khandoker,
    A., Werghi, N., 2020. Thyroid nodule cell classification in cytology images using
    transfer learning approach., in: International Conference on Soft Computing and
    Pattern Recognition, pp. 539–549.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bakht 等人 [2020] Bakht, A.B., Javed, S., Dina, R., Almarzouqi, H., Khandoker,
    A., Werghi, N., 2020. 使用迁移学习方法对细胞学图像中的甲状腺结节细胞进行分类., 见：国际软计算与模式识别会议，页码 539–549。
- en: 'Bal et al. [2021] Bal, A., Das, M., Satapathy, S.M., Jena, M., Das, S.K., 2021.
    Bfcnet: a cnn for diagnosis of ductal carcinoma in breast from cytology images.
    Pattern Analysis and Applications , 1–14.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bal 等人 [2021] Bal, A., Das, M., Satapathy, S.M., Jena, M., Das, S.K., 2021.
    Bfcnet：一种用于从细胞学图像中诊断乳腺导管癌的卷积神经网络。Pattern Analysis and Applications , 1–14。
- en: 'Bao et al. [2020] Bao, H., Bi, H., Zhang, X., Zhao, Y., Dong, Y., Luo, X.,
    Zhou, D., You, Z., Wu, Y., Liu, Z., et al., 2020. Artificial intelligence-assisted
    cytology for detection of cervical intraepithelial neoplasia or invasive cancer:
    A multicenter, clinical-based, observational study. Gynecologic Oncology 159,
    171–178.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bao 等人 [2020] Bao, H., Bi, H., Zhang, X., Zhao, Y., Dong, Y., Luo, X., Zhou,
    D., You, Z., Wu, Y., Liu, Z., 等人，2020. 人工智能辅助的细胞学检测宫颈上皮内瘤变或侵袭性癌症：一项多中心、临床基础的观察性研究。Gynecologic
    Oncology 159, 171–178。
- en: 'Barkan et al. [2016] Barkan, G.A., Wojcik, E.M., Nayar, R., Savic-Prince, S.,
    Quek, M.L., Kurtycz, D.F., Rosenthal, D.L., 2016. The paris system for reporting
    urinary cytology: the quest to develop a standardized terminology. Acta Cytologica
    60, 185–197.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barkan 等人 [2016] Barkan, G.A., Wojcik, E.M., Nayar, R., Savic-Prince, S., Quek,
    M.L., Kurtycz, D.F., Rosenthal, D.L., 2016. 巴黎系统用于尿液细胞学报告：制定标准化术语的探索。Acta Cytologica
    60, 185–197。
- en: Baykal et al. [2020] Baykal, E., Dogan, H., Ercin, M.E., Ersoz, S., Ekinci,
    M., 2020. Modern convolutional object detectors for nuclei detection on pleural
    effusion cytology images. Multimedia Tools and Applications 79, 15417–15436.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baykal 等人 [2020] Baykal, E., Dogan, H., Ercin, M.E., Ersoz, S., Ekinci, M.,
    2020. 用于胸腔积液细胞学图像中核检测的现代卷积目标检测器。Multimedia Tools and Applications 79, 15417–15436。
- en: Beam et al. [2020] Beam, A.L., Manrai, A.K., Ghassemi, M., 2020. Challenges
    to the reproducibility of machine learning models in health care. Jama 323, 305–306.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beam 等人 [2020] Beam, A.L., Manrai, A.K., Ghassemi, M., 2020. 机器学习模型在医疗保健中可重复性面临的挑战。Jama
    323, 305–306。
- en: 'Beca and Schmitt [2019] Beca, F., Schmitt, F.C., 2019. Ancillary tests in breast
    cytology: a practical guide. Acta cytologica 63, 302–313.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beca 和 Schmitt [2019] Beca, F., Schmitt, F.C., 2019. 乳腺细胞学中的辅助检查：实用指南。Acta cytologica
    63, 302–313。
- en: Bhatt et al. [2021] Bhatt, A.R., Ganatra, A., Kotecha, K., 2021. Cervical cancer
    detection in pap smear whole slide images using convnet with transfer learning
    and progressive resizing. PeerJ Computer Science 7, e348.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bhatt 等人 [2021] Bhatt, A.R., Ganatra, A., Kotecha, K., 2021. 使用卷积神经网络和迁移学习及逐步调整图像大小的宫颈癌检测。PeerJ
    Computer Science 7, e348。
- en: 'Böhm et al. [2019] Böhm, A., Tatarchenko, M., Falk, T., 2019. Isoo v2 dl-semantic
    instance segmentation of touching and overlapping objects, in: 2019 IEEE 16th
    International Symposium on Biomedical Imaging (ISBI 2019), IEEE. pp. 343–347.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Böhm 等人 [2019] Böhm, A., Tatarchenko, M., Falk, T., 2019. Isoo v2 dl-语义实例分割触碰和重叠物体，见：2019
    IEEE 第16届生物医学成像国际研讨会（ISBI 2019），IEEE。页码 343–347。
- en: Brown and Garber [1999] Brown, A.D., Garber, A.M., 1999. Cost-effectiveness
    of 3 methods to enhance the sensitivity of papanicolaou testing. Jama 281, 347–353.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 和 Garber [1999] Brown, A.D., Garber, A.M., 1999. 提高巴氏涂片测试敏感性的三种方法的成本效益。Jama
    281, 347–353。
- en: Caddy et al. [2005] Caddy, G., Conron, M., Wright, G., Desmond, P., Hart, D.,
    Chen, R., 2005. The accuracy of eus-fna in assessing mediastinal lymphadenopathy
    and staging patients with nsclc. European Respiratory Journal 25, 410–415.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caddy 等人 [2005] Caddy, G., Conron, M., Wright, G., Desmond, P., Hart, D., Chen,
    R., 2005. EUS-FNA 评估纵隔淋巴结肿大和分期 NSCLC 患者的准确性。European Respiratory Journal 25, 410–415。
- en: 'Çallı et al. [2021] Çallı, E., Sogancioglu, E., van Ginneken, B., van Leeuwen,
    K.G., Murphy, K., 2021. Deep learning for chest x-ray analysis: A survey. Medical
    Image Analysis , 102125.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Çallı 等 [2021] Çallı, E., Sogancioglu, E., van Ginneken, B., van Leeuwen, K.G.,
    Murphy, K., 2021. 胸部 X 光分析中的深度学习：综述。Medical Image Analysis , 102125。
- en: Cao et al. [2021] Cao, L., Yang, J., Rong, Z., Li, L., Xia, B., You, C., Lou,
    G., Jiang, L., Du, C., Meng, H., et al., 2021. A novel attention-guided convolutional
    network for the detection of abnormal cervical cells in cervical cancer screening.
    Medical Image Analysis , 102197.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等 [2021] Cao, L., Yang, J., Rong, Z., Li, L., Xia, B., You, C., Lou, G.,
    Jiang, L., Du, C., Meng, H., 等，2021. 一种新颖的注意力引导卷积网络，用于宫颈癌筛查中的异常宫颈细胞检测。Medical
    Image Analysis , 102197。
- en: Chai et al. [2021] Chai, Z., Luo, L., Lin, H., Chen, H., Heng, P.A., 2021. Deep
    semi-supervised metric learning with dual alignment for cervical cancer cell detection.
    arXiv preprint arXiv:2104.03265 .
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chai 等 [2021] Chai, Z., Luo, L., Lin, H., Chen, H., Heng, P.A., 2021. 具有双重对齐的深度半监督度量学习用于宫颈癌细胞检测。arXiv
    预印本 arXiv:2104.03265。
- en: Chankong et al. [2014] Chankong, T., Theera-Umpon, N., Auephanwiriyakul, S.,
    2014. Automatic cervical cell segmentation and classification in pap smears. Computer
    Methods and Programs in Biomedicine 113, 539–556.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chankong 等 [2014] Chankong, T., Theera-Umpon, N., Auephanwiriyakul, S., 2014.
    在宫颈抹片中自动进行宫颈细胞分割和分类。Computer Methods and Programs in Biomedicine 113, 539–556。
- en: Chen et al. [2020] Chen, C., Dou, Q., Chen, H., Qin, J., Heng, P.A., 2020. Unsupervised
    bidirectional cross-modality adaptation via deeply synergistic image and feature
    alignment for medical image segmentation. IEEE Transactions on Medical Imaging
    39, 2494–2505.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 [2020] Chen, C., Dou, Q., Chen, H., Qin, J., Heng, P.A., 2020. 通过深度协同的图像和特征对齐实现无监督的双向跨模态适应，用于医学图像分割。IEEE
    Transactions on Medical Imaging 39, 2494–2505。
- en: 'Chen et al. [2016a] Chen, H., Dou, Q., Wang, X., Qin, J., Heng, P.A., 2016a.
    Mitosis detection in breast cancer histology images via deep cascaded networks,
    in: Thirtieth AAAI conference on artificial intelligence, pp. 1160–1166.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 [2016a] Chen, H., Dou, Q., Wang, X., Qin, J., Heng, P.A., 2016a. 通过深度级联网络在乳腺癌组织图像中检测有丝分裂，在：第三十届
    AAAI 人工智能会议上，页码 1160–1166。
- en: 'Chen et al. [2017] Chen, H., Qi, X., Yu, L., Dou, Q., Qin, J., Heng, P.A.,
    2017. Dcan: Deep contour-aware networks for object instance segmentation from
    histology images. Medical Image Analysis 36, 135–146.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 [2017] Chen, H., Qi, X., Yu, L., Dou, Q., Qin, J., Heng, P.A., 2017.
    DCAN：用于从组织图像中进行目标实例分割的深度轮廓感知网络。Medical Image Analysis 36, 135–146。
- en: 'Chen et al. [2016b] Chen, H., Qi, X., Yu, L., Heng, P.A., 2016b. Dcan: deep
    contour-aware networks for accurate gland segmentation, in: Proceedings of the
    IEEE conference on Computer Vision and Pattern Recognition, pp. 2487–2496.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 [2016b] Chen, H., Qi, X., Yu, L., Heng, P.A., 2016b. DCAN：用于准确腺体分割的深度轮廓感知网络，在：IEEE
    计算机视觉与模式识别会议论文集，页码 2487–2496。
- en: 'Chen et al. [2021] Chen, M., Zhang, Z., Wang, T., Backes, M., Humbert, M.,
    Zhang, Y., 2021. When machine unlearning jeopardizes privacy, in: Proceedings
    of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pp.
    896–911.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 [2021] Chen, M., Zhang, Z., Wang, T., Backes, M., Humbert, M., Zhang,
    Y., 2021. 当机器遗忘威胁隐私时，在：2021 年 ACM SIGSAC 计算机与通信安全会议论文集，页码 896–911。
- en: Chen et al. [2019] Chen, P.H.C., Gadepalli, K., MacDonald, R., Liu, Y., Kadowaki,
    S., Nagpal, K., Kohlberger, T., Dean, J., Corrado, G.S., Hipp, J.D., et al., 2019.
    An augmented reality microscope with real-time artificial intelligence integration
    for cancer diagnosis. Nature Medicine 25, 1453–1457.
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 [2019] Chen, P.H.C., Gadepalli, K., MacDonald, R., Liu, Y., Kadowaki,
    S., Nagpal, K., Kohlberger, T., Dean, J., Corrado, G.S., Hipp, J.D., 等，2019. 一种具有实时人工智能集成的增强现实显微镜，用于癌症诊断。Nature
    Medicine 25, 1453–1457。
- en: Cheng et al. [2021] Cheng, S., Liu, S., Yu, J., Rao, G., Xiao, Y., Han, W.,
    Zhu, W., Lv, X., Li, N., Cai, J., et al., 2021. Robust whole slide image analysis
    for cervical cancer screening using deep learning. Nature Communications 12, 1–10.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 等 [2021] Cheng, S., Liu, S., Yu, J., Rao, G., Xiao, Y., Han, W., Zhu,
    W., Lv, X., Li, N., Cai, J., 等，2021. 使用深度学习进行宫颈癌筛查的稳健全切片图像分析。Nature Communications
    12, 1–10。
- en: Cibas and Ali [2017] Cibas, E.S., Ali, S.Z., 2017. The 2017 bethesda system
    for reporting thyroid cytopathology. Thyroid 27, 1341–1346.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cibas 和 Ali [2017] Cibas, E.S., Ali, S.Z., 2017. 2017 年 Bethesda 甲状腺细胞病理报告系统。Thyroid
    27, 1341–1346。
- en: 'Davey et al. [2006] Davey, E., Barratt, A., Irwig, L., Chan, S.F., Macaskill,
    P., Mannes, P., Saville, A.M., 2006. Effect of study design and quality on unsatisfactory
    rates, cytology classifications, and accuracy in liquid-based versus conventional
    cervical cytology: a systematic review. The Lancet 367, 122–132.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Davey et al. [2006] Davey, E., Barratt, A., Irwig, L., Chan, S.F., Macaskill,
    P., Mannes, P., Saville, A.M., 2006. 研究设计和质量对液基细胞学与传统细胞学中不满意率、细胞学分类和准确度的影响：一项系统评价。柳叶刀
    367, 122–132。
- en: De Vito et al. [2014] De Vito, C., Angeloni, C., De Feo, E., Marzuillo, C.,
    Lattanzi, A., Ricciardi, W., Villari, P., Boccia, S., 2014. A large cross-sectional
    survey investigating the knowledge of cervical cancer risk aetiology and the predictors
    of the adherence to cervical cancer screening related to mass media campaign.
    BioMed Research International 2014.
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: De Vito et al. [2014] De Vito, C., Angeloni, C., De Feo, E., Marzuillo, C.,
    Lattanzi, A., Ricciardi, W., Villari, P., Boccia, S., 2014. 一项大规模横断面调查，研究了对宫颈癌风险病因的知识以及对宫颈癌筛查的遵循度的预测因素与大众媒体宣传的关系。生物医学研究国际
    2014。
- en: 'Deng et al. [2009] Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei,
    L., 2009. Imagenet: A large-scale hierarchical image database, in: 2009 IEEE conference
    on computer vision and pattern recognition, Ieee. pp. 248–255.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Deng et al. [2009] Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei,
    L., 2009. Imagenet: 一个大规模的层次图像数据库，见：2009 IEEE计算机视觉与模式识别会议，Ieee。第248–255页。'
- en: Dey [2018] Dey, P., 2018. Basic and advanced laboratory techniques in histopathology
    and cytology. Springer.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dey [2018] Dey, P., 2018. 组织病理学和细胞学中的基础和高级实验室技术。Springer。
- en: 'Dey et al. [2019] Dey, S., Das, S., Ghosh, S., Mitra, S., Chakrabarty, S.,
    Das, N., 2019. Syncgan: Using learnable class specific priors to generate synthetic
    data for improving classifier performance on cytological images, in: National
    Conference on Computer Vision, Pattern Recognition, Image Processing, and Graphics,
    Springer. pp. 32–42.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dey et al. [2019] Dey, S., Das, S., Ghosh, S., Mitra, S., Chakrabarty, S.,
    Das, N., 2019. Syncgan: 使用可学习的类别特定先验生成合成数据，以提高分类器在细胞学图像上的性能，见：计算机视觉、模式识别、图像处理与图形学国家会议，Springer。第32–42页。'
- en: Dimauro et al. [2019] Dimauro, G., Ciprandi, G., Deperte, F., Girardi, F., Ladisa,
    E., Latrofa, S., Gelardi, M., 2019. Nasal cytology with deep learning techniques.
    International journal of medical informatics 122, 13–19.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dimauro et al. [2019] Dimauro, G., Ciprandi, G., Deperte, F., Girardi, F., Ladisa,
    E., Latrofa, S., Gelardi, M., 2019. 采用深度学习技术的鼻腔细胞学。国际医学信息学杂志 122, 13–19。
- en: 'Dosovitskiy et al. [2020] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,
    D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly,
    S., et al., 2020. An image is worth 16x16 words: Transformers for image recognition
    at scale. arXiv preprint arXiv:2010.11929 .'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dosovitskiy et al. [2020] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,
    D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly,
    S., 等，2020. 一张图像价值16x16个词：用于大规模图像识别的变换器。arXiv预印本 arXiv:2010.11929。
- en: Dov et al. [2021] Dov, D., Kovalsky, S.Z., Assaad, S., Cohen, J., Range, D.E.,
    Pendse, A.A., Henao, R., Carin, L., 2021. Weakly supervised instance learning
    for thyroid malignancy prediction from whole slide cytopathology images. Medical
    Image Analysis 67, 101814.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dov et al. [2021] Dov, D., Kovalsky, S.Z., Assaad, S., Cohen, J., Range, D.E.,
    Pendse, A.A., Henao, R., Carin, L., 2021. 从全片细胞病理学图像中预测甲状腺恶性度的弱监督实例学习。医学影像分析 67,
    101814。
- en: 'Dov et al. [2019] Dov, D., Kovalsky, S.Z., Cohen, J., Range, D.E., Henao, R.,
    Carin, L., 2019. Thyroid cancer malignancy prediction from whole slide cytopathology
    images, in: Machine Learning for Healthcare Conference, PMLR. pp. 553–570.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dov et al. [2019] Dov, D., Kovalsky, S.Z., Cohen, J., Range, D.E., Henao, R.,
    Carin, L., 2019. 从全片细胞病理学图像中预测甲状腺癌恶性度，见：医疗保健会议，PMLR。第553–570页。
- en: Elliott Range et al. [2020] Elliott Range, D.D., Dov, D., Kovalsky, S.Z., Henao,
    R., Carin, L., Cohen, J., 2020. Application of a machine learning algorithm to
    predict malignancy in thyroid cytopathology. Cancer cytopathology 128, 287–295.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elliott Range et al. [2020] Elliott Range, D.D., Dov, D., Kovalsky, S.Z., Henao,
    R., Carin, L., Cohen, J., 2020. 机器学习算法在预测甲状腺细胞病理学恶性度中的应用。癌症细胞病理学 128, 287–295。
- en: 'Falk et al. [2019] Falk, T., Mai, D., Bensch, R., Çiçek, Ö., Abdulkadir, A.,
    Marrakchi, Y., Böhm, A., Deubner, J., Jäckel, Z., Seiwald, K., et al., 2019. U-net:
    deep learning for cell counting, detection, and morphometry. Nature Methods 16,
    67–70.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Falk et al. [2019] Falk, T., Mai, D., Bensch, R., Çiçek, Ö., Abdulkadir, A.,
    Marrakchi, Y., Böhm, A., Deubner, J., Jäckel, Z., Seiwald, K., 等，2019. U-net:
    用于细胞计数、检测和形态测量的深度学习。自然方法 16, 67–70。'
- en: Field et al. [2019] Field, A.S., Raymond, W.A., Rickard, M., Arnold, L., Brachtel,
    E.F., Chaiwun, B., Chen, L., Di Bonito, L., Kurtycz, D.F., Lee, A.H., et al.,
    2019. The international academy of cytology yokohama system for reporting breast
    fine-needle aspiration biopsy cytopathology. Acta Cytologica 63, 257–273.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Field 等 [2019] Field, A.S., Raymond, W.A., Rickard, M., Arnold, L., Brachtel,
    E.F., Chaiwun, B., Chen, L., Di Bonito, L., Kurtycz, D.F., Lee, A.H., 等, 2019.
    国际细胞学学会横滨系统用于乳腺细针穿刺活检细胞病理报告。Acta Cytologica 63, 257–273。
- en: 'Garud et al. [2017] Garud, H., Karri, S.P.K., Sheet, D., Chatterjee, J., Mahadevappa,
    M., Ray, A.K., Ghosh, A., Maity, A.K., 2017. High-magnification multi-views based
    classification of breast fine needle aspiration cytology cell samples using fusion
    of decisions from deep convolutional networks, in: Proceedings of the IEEE conference
    on computer vision and pattern recognition workshops, pp. 76–81.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Garud 等 [2017] Garud, H., Karri, S.P.K., Sheet, D., Chatterjee, J., Mahadevappa,
    M., Ray, A.K., Ghosh, A., Maity, A.K., 2017. 基于高倍多视图的乳腺细针穿刺细胞学样本分类，使用深度卷积网络决策融合，见：IEEE
    计算机视觉与模式识别会议研讨会论文集，第 76–81 页。
- en: 'Girshick [2015] Girshick, R., 2015. Fast r-cnn, in: Proceedings of the IEEE
    international conference on computer vision, pp. 1440–1448.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Girshick [2015] Girshick, R., 2015. 快速 r-cnn, 见：IEEE 计算机视觉国际会议论文集，第 1440–1448
    页。
- en: 'Girshick et al. [2014] Girshick, R., Donahue, J., Darrell, T., Malik, J., 2014.
    Rich feature hierarchies for accurate object detection and semantic segmentation,
    in: Proceedings of the IEEE conference on computer vision and pattern recognition,
    pp. 580–587.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Girshick 等 [2014] Girshick, R., Donahue, J., Darrell, T., Malik, J., 2014. 用于精确物体检测和语义分割的丰富特征层次，见：IEEE
    计算机视觉与模式识别会议论文集，第 580–587 页。
- en: Gonzalez et al. [2020] Gonzalez, D., Dietz, R.L., Pantanowitz, L., 2020. Feasibility
    of a deep learning algorithm to distinguish large cell neuroendocrine from small
    cell lung carcinoma in cytology specimens. Cytopathology 31, 426–431.
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gonzalez 等 [2020] Gonzalez, D., Dietz, R.L., Pantanowitz, L., 2020. 深度学习算法在细胞学样本中区分大细胞神经内分泌癌与小细胞肺癌的可行性。Cytopathology
    31, 426–431。
- en: Goodfellow et al. [2014] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,
    Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., 2014. Generative adversarial
    nets. Advances in Neural Information Processing Systems 27.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等 [2014] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley,
    D., Ozair, S., Courville, A., Bengio, Y., 2014. 生成对抗网络。Advances in Neural Information
    Processing Systems 27。
- en: 'Guan and Liu [2021] Guan, H., Liu, M., 2021. Domain adaptation for medical
    image analysis: a survey. arXiv preprint arXiv:2102.09508 .'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guan 和 Liu [2021] Guan, H., Liu, M., 2021. 医学图像分析的领域适应：综述。arXiv 预印本 arXiv:2102.09508。
- en: 'Guan et al. [2019a] Guan, Q., Wan, X., Lu, H., Ping, B., Li, D., Wang, L.,
    Zhu, Y., Wang, Y., Xiang, J., 2019a. Deep convolutional neural network inception-v3
    model for differential diagnosing of lymph node in cytological images: a pilot
    study. Annals of Translational Medicine 7.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guan 等 [2019a] Guan, Q., Wan, X., Lu, H., Ping, B., Li, D., Wang, L., Zhu, Y.,
    Wang, Y., Xiang, J., 2019a. 用于细胞学图像中淋巴结鉴别诊断的深度卷积神经网络 inception-v3 模型：初步研究。Annals
    of Translational Medicine 7。
- en: 'Guan et al. [2019b] Guan, Q., Wang, Y., Ping, B., Li, D., Du, J., Qin, Y.,
    Lu, H., Wan, X., Xiang, J., 2019b. Deep convolutional neural network vgg-16 model
    for differential diagnosing of papillary thyroid carcinomas in cytological images:
    a pilot study. Journal of Cancer 10, 4876.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guan 等 [2019b] Guan, Q., Wang, Y., Ping, B., Li, D., Du, J., Qin, Y., Lu, H.,
    Wan, X., Xiang, J., 2019b. 用于细胞学图像中乳头状甲状腺癌鉴别诊断的深度卷积神经网络 vgg-16 模型：初步研究。Journal
    of Cancer 10, 4876。
- en: 'He et al. [2017] He, K., Gkioxari, G., Dollár, P., Girshick, R., 2017. Mask
    r-cnn, in: Proceedings of the IEEE international conference on computer vision,
    pp. 2961–2969.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等 [2017] He, K., Gkioxari, G., Dollár, P., Girshick, R., 2017. Mask r-cnn,
    见：IEEE 计算机视觉国际会议论文集，第 2961–2969 页。
- en: 'He et al. [2016] He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning
    for image recognition, in: Proceedings of the IEEE conference on computer vision
    and pattern recognition, pp. 770–778.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等 [2016] He, K., Zhang, X., Ren, S., Sun, J., 2016. 图像识别的深度残差学习，见：IEEE 计算机视觉与模式识别会议论文集，第
    770–778 页。
- en: Hossain et al. [2019] Hossain, M.S., Jalab, H.A., Zulfiqar, F., Pervin, M.,
    2019. Renal cancer cell nuclei detection from cytological images using convolutional
    neural network for estimating proliferation rate. Journal of Telecommunication,
    Electronic and Computer Engineering (JTEC) 11, 63–71.
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hossain 等 [2019] Hossain, M.S., Jalab, H.A., Zulfiqar, F., Pervin, M., 2019.
    使用卷积神经网络从细胞学图像中检测肾癌细胞核以估算增殖率。Journal of Telecommunication, Electronic and Computer
    Engineering (JTEC) 11, 63–71。
- en: 'Huang et al. [2017] Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q.,
    2017. Densely connected convolutional networks, in: Proceedings of the IEEE conference
    on computer vision and pattern recognition, pp. 4700–4708.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. [2017] Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q.,
    2017. 密集连接的卷积网络，摘自：IEEE计算机视觉和模式识别会议论文集，4700–4708。
- en: Hussain et al. [2020a] Hussain, E., Mahanta, L.B., Borah, H., Das, C.R., 2020a.
    Liquid based-cytology pap smear dataset for automated multi-class diagnosis of
    pre-cancerous and cervical cancer lesions. Data in brief 30, 105589.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hussain et al. [2020a] Hussain, E., Mahanta, L.B., Borah, H., Das, C.R., 2020a.
    基于液基细胞学的宫颈抹片数据集，用于自动多类癌前和宫颈癌病变诊断。数据简报30, 105589.
- en: Hussain et al. [2020b] Hussain, E., Mahanta, L.B., Das, C.R., Choudhury, M.,
    Chowdhury, M., 2020b. A shape context fully convolutional neural network for segmentation
    and classification of cervical nuclei in pap smear images. Artificial Intelligence
    in Medicine 107, 101897.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hussain et al. [2020b] Hussain, E., Mahanta, L.B., Das, C.R., Choudhury, M.,
    Chowdhury, M., 2020b. 用于宫颈涂片图像中细胞核分割和分类的形状上下文全卷积神经网络。医学人工智能107, 101897。
- en: Hussain et al. [2020c] Hussain, E., Mahanta, L.B., Das, C.R., Talukdar, R.K.,
    2020c. A comprehensive study on the multi-class cervical cancer diagnostic prediction
    on pap smear images using a fusion-based decision from ensemble deep convolutional
    neural network. Tissue and Cell 65, 101347.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hussain et al. [2020c] Hussain, E., Mahanta, L.B., Das, C.R., Talukdar, R.K.,
    2020c. 关于宫颈癌多类诊断预测的综合研究，基于涂片图像的集成深度卷积神经网络决策的融合。组织与细胞65, 101347。
- en: Isa [2005] Isa, N.M., 2005. Automated edge detection technique for pap smear
    images using moving k-means clustering and modified seed based region growing
    algorithm. International Journal of The Computer, the Internet and Management
    13, 45–59.
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Isa [2005] Isa, N.M., 2005. 利用移动k均值聚类和修改的种子区域生长算法进行宫颈抹片图像的自动边缘检测技术。国际计算机、互联网和管理期刊13,
    45–59。
- en: Ivanovic [2014] Ivanovic, M., 2014. Overview of cytopathology procedures and
    techniques. Cytopathology in Oncology , 1–12.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ivanovic [2014] Ivanovic, M., 2014. 细胞病理学程序和技术概述。《肿瘤学中的细胞病理学》，1–12。
- en: Jantzen et al. [2005] Jantzen, J., Norup, J., Dounias, G., Bjerregaard, B.,
    2005. Pap-smear benchmark data for pattern classification. Nature inspired Smart
    Information Systems (NiSIS 2005) , 1–9.
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jantzen et al. [2005] Jantzen, J., Norup, J., Dounias, G., Bjerregaard, B.,
    2005. 用于模式分类的宫颈抹片基准数据。自然启发的智能信息系统 (NiSIS 2005), 1–9.
- en: Ji et al. [2020] Ji, A.L., Rubin, A.J., Thrane, K., Jiang, S., Reynolds, D.L.,
    Meyers, R.M., Guo, M.G., George, B.M., Mollbrink, A., Bergenstråhle, J., et al.,
    2020. Multimodal analysis of composition and spatial architecture in human squamous
    cell carcinoma. Cell 182, 497–514.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ji et al. [2020] Ji, A.L., Rubin, A.J., Thrane, K., Jiang, S., Reynolds, D.L.,
    Meyers, R.M., Guo, M.G., George, B.M., Mollbrink, A., Bergenstråhle, J., 等, 2020.
    人类鳞状细胞癌中组成和空间结构的多模态分析。细胞182, 497–514。
- en: 'Johnston [1952] Johnston, D., 1952. Cytoplasmic: nuclear ratios in the cytological
    diagnosis of cancer. Cancer 5, 945–949.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Johnston [1952] Johnston, D., 1952. 细胞质：核比在癌症细胞学诊断中的应用。癌症5, 945–949.
- en: Jónsson et al. [2019] Jónsson, B.A., Bjornsdottir, G., Thorgeirsson, T., Ellingsen,
    L.M., Walters, G.B., Gudbjartsson, D., Stefansson, H., Stefansson, K., Ulfarsson,
    M., 2019. Brain age prediction using deep learning uncovers associated sequence
    variants. Nature Communications 10, 1–10.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jónsson et al. [2019] Jónsson, B.A., Bjornsdottir, G., Thorgeirsson, T., Ellingsen,
    L.M., Walters, G.B., Gudbjartsson, D., Stefansson, H., Stefansson, K., Ulfarsson,
    M., 2019. 利用深度学习进行脑龄预测揭示相关的序列变体。自然通讯10, 1–10.
- en: Kaneko et al. [2021] Kaneko, M., Tsuji, K., Masuda, K., Ueno, K., Henmi, K.,
    Nakagawa, S., Fujita, R., Suzuki, K., Inoue, Y., Teramukai, S., et al., 2021.
    Urine cell image recognition using a deep learning model for an automated slide
    evaluation system. BJU international .
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaneko et al. [2021] Kaneko, M., Tsuji, K., Masuda, K., Ueno, K., Henmi, K.,
    Nakagawa, S., Fujita, R., Suzuki, K., Inoue, Y., Teramukai, S., 等, 2021. 利用深度学习模型的尿液细胞图像识别，用于自动化幻灯片评估系统。BJU国际。
- en: Ke et al. [2021] Ke, J., Shen, Y., Lu, Y., Deng, J., Wright, J.D., Zhang, Y.,
    Huang, Q., Wang, D., Jing, N., Liang, X., et al., 2021. Quantitative analysis
    of abnormalities in gynecologic cytopathology with deep learning. Laboratory Investigation
    101, 513–524.
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ke et al. [2021] Ke, J., Shen, Y., Lu, Y., Deng, J., Wright, J.D., Zhang, Y.,
    Huang, Q., Wang, D., Jing, N., Liang, X., 等, 2021. 利用深度学习进行妇科细胞病理学异常情况的定量分析。实验室调查101,
    513–524。
- en: 'Kilic et al. [2019] Kilic, B., Baykal, E., Ekinci, M., Dogan, H., Ercin, M.E.,
    Ersoz, S., 2019. Automated nuclei detection on pleural effusion cytopathology
    images using yolov3, in: 2019 4th International Conference on Computer Science
    and Engineering (UBMK), IEEE. pp. 1–5.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kilic et al. [2019] Kilic, B., Baykal, E., Ekinci, M., Dogan, H., Ercin, M.E.,
    Ersoz, S., 2019. 使用 yolov3 对胸膜积液细胞病理图像进行自动化核检测，见：2019年第4届国际计算机科学与工程会议（UBMK），IEEE。第1–5页。
- en: Kingma and Welling [2013] Kingma, D.P., Welling, M., 2013. Auto-encoding variational
    bayes. arXiv preprint arXiv:1312.6114 .
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma and Welling [2013] Kingma, D.P., Welling, M., 2013. 自编码变分贝叶斯。arXiv 预印本
    arXiv:1312.6114。
- en: Kitchener et al. [2006] Kitchener, H.C., Castle, P.E., Cox, J.T., 2006. Achievements
    and limitations of cervical cytology screening. Vaccine 24, S63–S70.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kitchener et al. [2006] Kitchener, H.C., Castle, P.E., Cox, J.T., 2006. 宫颈细胞学筛查的成就与局限性。疫苗
    24, S63–S70。
- en: 'Kontzoglou et al. [2005] Kontzoglou, K., Moulakakis, K.G., Konofaos, P., Kyriazi,
    M., Kyroudes, A., Karakitsos, P., 2005. The role of liquid-based cytology in the
    investigation of breast lesions using fine-needle aspiration: a cytohistopathological
    evaluation. Journal of Surgical Oncology 89, 75–78.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kontzoglou et al. [2005] Kontzoglou, K., Moulakakis, K.G., Konofaos, P., Kyriazi,
    M., Kyroudes, A., Karakitsos, P., 2005. 液基细胞学在细针抽吸乳腺病变检查中的作用：细胞组织病理学评估。外科肿瘤学杂志
    89, 75–78。
- en: 'Koohbanani et al. [2020] Koohbanani, N.A., Jahanifar, M., Tajadin, N.Z., Rajpoot,
    N., 2020. Nuclick: a deep learning framework for interactive segmentation of microscopic
    images. Medical Image Analysis 65, 101771.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koohbanani et al. [2020] Koohbanani, N.A., Jahanifar, M., Tajadin, N.Z., Rajpoot,
    N., 2020. Nuclick：一种用于显微图像交互分割的深度学习框架。医学图像分析 65, 101771。
- en: Koss et al. [1994] Koss, L.G., Lin, E., Schreiber, K., Elgert, P., Mango, L.,
    1994. Evaluation of the papnet™ cytologic screening system for quality control
    of cervical smears. American Journal of Clinical Pathology 101, 220–229.
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koss et al. [1994] Koss, L.G., Lin, E., Schreiber, K., Elgert, P., Mango, L.,
    1994. 对 papnet™ 细胞学筛查系统的评估，以进行宫颈涂片的质量控制。美国临床病理学杂志 101, 220–229。
- en: Koss and Melamed [2006] Koss, L.G., Melamed, M.R., 2006. Koss’ diagnostic cytology
    and its histopathologic bases. volume 1. Lippincott Williams & Wilkins.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koss and Melamed [2006] Koss, L.G., Melamed, M.R., 2006. Koss 的诊断细胞学及其组织病理学基础。第1卷。利普曼科。
- en: Kowal et al. [2020] Kowal, M., Żejmo, M., Skobel, M., Korbicz, J., Monczak,
    R., 2020. Cell nuclei segmentation in cytological images using convolutional neural
    network and seeded watershed algorithm. Journal of Digital Imaging 33, 231–242.
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kowal et al. [2020] Kowal, M., Żejmo, M., Skobel, M., Korbicz, J., Monczak,
    R., 2020. 使用卷积神经网络和种子分水岭算法在细胞学图像中进行细胞核分割。数字成像杂志 33, 231–242。
- en: 'Landau and Pantanowitz [2019] Landau, M.S., Pantanowitz, L., 2019. Artificial
    intelligence in cytopathology: a review of the literature and overview of commercial
    landscape. Journal of the American Society of Cytopathology 8, 230–241.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Landau and Pantanowitz [2019] Landau, M.S., Pantanowitz, L., 2019. 细胞病理学中的人工智能：文献综述与商业环境概述。美国细胞病理学会杂志
    8, 230–241。
- en: 'Larsen et al. [2016] Larsen, A.B.L., Sønderby, S.K., Larochelle, H., Winther,
    O., 2016. Autoencoding beyond pixels using a learned similarity metric, in: International
    conference on machine learning, PMLR. pp. 1558–1566.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Larsen et al. [2016] Larsen, A.B.L., Sønderby, S.K., Larochelle, H., Winther,
    O., 2016. 超越像素的自编码：使用学习到的相似性度量，见：国际机器学习会议，PMLR。第1558–1566页。
- en: Lassau et al. [2021] Lassau, N., Ammari, S., Chouzenoux, E., Gortais, H., Herent,
    P., Devilder, M., Soliman, S., Meyrignac, O., Talabard, M.P., Lamarque, J.P.,
    et al., 2021. Integrating deep learning ct-scan model, biological and clinical
    variables to predict severity of covid-19 patients. Nature Communications 12,
    1–11.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lassau et al. [2021] Lassau, N., Ammari, S., Chouzenoux, E., Gortais, H., Herent,
    P., Devilder, M., Soliman, S., Meyrignac, O., Talabard, M.P., Lamarque, J.P.,
    等, 2021. 整合深度学习CT扫描模型、生物学和临床变量以预测COVID-19患者的严重程度。自然通讯 12, 1–11。
- en: LeCun et al. [1998] LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., 1998. Gradient-based
    learning applied to document recognition. Proceedings of the IEEE 86, 2278–2324.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun et al. [1998] LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., 1998. 基于梯度的学习应用于文档识别。IEEE
    会议录 86, 2278–2324。
- en: Lever et al. [1985] Lever, J., Trott, P., Webb, A., 1985. Fine needle aspiration
    cytology. Journal of Clinical Pathology 38, 1–11.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lever et al. [1985] Lever, J., Trott, P., Webb, A., 1985. 细针抽吸细胞学。临床病理学杂志 38,
    1–11。
- en: Li et al. [2021] Li, J., Chen, W., Huang, X., Hu, Z., Duan, Q., Li, H., Metaxas,
    D.N., Zhang, S., 2021. Mixed supervision learning for whole slide image classification.
    arXiv preprint arXiv:2107.00934 .
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2021] Li, J., Chen, W., Huang, X., Hu, Z., Duan, Q., Li, H., Metaxas,
    D.N., Zhang, S., 2021. 全切片图像分类的混合监督学习。arXiv 预印本 arXiv:2107.00934。
- en: Li et al. [2022] Li, J., Dou, Q., Yang, H., Liu, J., Fu, L., Zhang, Y., Zheng,
    L., Zhang, D., 2022. Cervical cell multi-classification algorithm using global
    context information and attention mechanism. Tissue and Cell 74, 101677.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等人 [2022] Li, J., Dou, Q., Yang, H., Liu, J., Fu, L., Zhang, Y., Zheng, L.,
    Zhang, D., 2022. 使用全局上下文信息和注意机制的宫颈细胞多分类算法。《组织与细胞》74, 101677。
- en: 'Li et al. [2019] Li, X., Li, Q., et al., 2019. Detection and classification
    of cervical exfoliated cells based on faster r-cnn, in: 2019 IEEE 11th international
    conference on advanced infocomm technology (ICAIT), IEEE. pp. 52–57.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等人 [2019] Li, X., Li, Q., 等，2019. 基于Faster R-CNN的宫颈脱落细胞检测与分类，见：2019 IEEE第11届国际先进信息通信技术会议（ICAIT），IEEE。第52–57页。
- en: Liang et al. [2021a] Liang, Y., Pan, C., Sun, W., Liu, Q., Du, Y., 2021a. Global
    context-aware cervical cell detection with soft scale anchor matching. Computer
    Methods and Programs in Biomedicine 204, 106061.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang等人 [2021a] Liang, Y., Pan, C., Sun, W., Liu, Q., Du, Y., 2021a. 具有软尺度锚匹配的全局上下文感知宫颈细胞检测。《生物医学计算方法与程序》204,
    106061。
- en: Liang et al. [2021b] Liang, Y., Tang, Z., Yan, M., Chen, J., Liu, Q., Xiang,
    Y., 2021b. Comparison detector for cervical cell/clumps detection in the limited
    data scenario. Neurocomputing 437, 195–205.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang等人 [2021b] Liang, Y., Tang, Z., Yan, M., Chen, J., Liu, Q., Xiang, Y.,
    2021b. 在有限数据场景下进行宫颈细胞/团块检测的比较检测器。《神经计算》437, 195–205。
- en: Lilli et al. [2021] Lilli, L., Giarnieri, E., Scardapane, S., 2021. A calibrated
    multiexit neural network for detecting urothelial cancer cells. Computational
    and Mathematical Methods in Medicine 2021.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lilli等人 [2021] Lilli, L., Giarnieri, E., Scardapane, S., 2021. 一种用于检测尿路上皮癌细胞的校准多出口神经网络。《计算与数学医学方法》2021。
- en: 'Lin et al. [2019a] Lin, H., Chen, H., Graham, S., Dou, Q., Rajpoot, N., Heng,
    P.A., 2019a. Fast scannet: Fast and dense analysis of multi-gigapixel whole-slide
    images for cancer metastasis detection. IEEE Transactions on Medical Imaging 38,
    1948–1958.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin等人 [2019a] Lin, H., Chen, H., Graham, S., Dou, Q., Rajpoot, N., Heng, P.A.,
    2019a. 快速扫描：用于癌症转移检测的快速且密集的多千兆像素全切片图像分析。《IEEE医学影像学交易》38, 1948–1958。
- en: Lin et al. [2021] Lin, H., Chen, H., Wang, X., Wang, Q., Wang, L., Heng, P.A.,
    2021. Dual-path network with synergistic grouping loss and evidence driven risk
    stratification for whole slide cervical image analysis. Medical Image Analysis
    69, 101955.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin等人 [2021] Lin, H., Chen, H., Wang, X., Wang, Q., Wang, L., Heng, P.A., 2021.
    具有协同分组损失和证据驱动风险分层的双路径网络用于全切片宫颈图像分析。《医学图像分析》69, 101955。
- en: Lin et al. [2019b] Lin, H., Hu, Y., Chen, S., Yao, J., Zhang, L., 2019b. Fine-grained
    classification of cervical cells using morphological and appearance based convolutional
    neural networks. IEEE Access 7, 71541–71549.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin等人 [2019b] Lin, H., Hu, Y., Chen, S., Yao, J., Zhang, L., 2019b. 使用基于形态和外观的卷积神经网络对宫颈细胞进行细粒度分类。《IEEE
    Access》7, 71541–71549。
- en: 'Lin et al. [2017a] Lin, T.Y., Dollár, P., Girshick, R., He, K., Hariharan,
    B., Belongie, S., 2017a. Feature pyramid networks for object detection, in: Proceedings
    of the IEEE conference on computer vision and pattern recognition, pp. 2117–2125.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin等人 [2017a] Lin, T.Y., Dollár, P., Girshick, R., He, K., Hariharan, B., Belongie,
    S., 2017a. 用于目标检测的特征金字塔网络，见：IEEE计算机视觉与模式识别会议论文集，第2117–2125页。
- en: 'Lin et al. [2017b] Lin, T.Y., Goyal, P., Girshick, R., He, K., Dollár, P.,
    2017b. Focal loss for dense object detection, in: Proceedings of the IEEE international
    conference on computer vision, pp. 2980–2988.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin等人 [2017b] Lin, T.Y., Goyal, P., Girshick, R., He, K., Dollár, P., 2017b.
    用于密集目标检测的焦点损失，见：IEEE国际计算机视觉会议论文集，第2980–2988页。
- en: Litjens et al. [2017] Litjens, G., Kooi, T., Bejnordi, B.E., Setio, A.A.A.,
    Ciompi, F., Ghafoorian, M., Van Der Laak, J.A., Van Ginneken, B., Sánchez, C.I.,
    2017. A survey on deep learning in medical image analysis. Medical Image Analysis
    42, 60–88.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Litjens等人 [2017] Litjens, G., Kooi, T., Bejnordi, B.E., Setio, A.A.A., Ciompi,
    F., Ghafoorian, M., Van Der Laak, J.A., Van Ginneken, B., Sánchez, C.I., 2017.
    关于医疗图像分析中的深度学习的调查。《医学图像分析》42, 60–88。
- en: Liu et al. [2020] Liu, L., Wang, Y., Ma, Q., Tan, L., Wu, Y., Xiao, J., 2020.
    Artificial classification of cervical squamous lesions in thinprep cytologic tests
    using a deep convolutional neural network. Oncology Letters 20, 1–1.
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等人 [2020] Liu, L., Wang, Y., Ma, Q., Tan, L., Wu, Y., Xiao, J., 2020. 使用深度卷积神经网络对ThinPrep细胞学测试中的宫颈鳞状病变进行人工分类。《肿瘤学快报》20,
    1–1。
- en: 'Liu et al. [2016] Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S.,
    Fu, C.Y., Berg, A.C., 2016. Ssd: Single shot multibox detector, in: European conference
    on computer vision, Springer. pp. 21–37.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu等人 [2016] Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y.,
    Berg, A.C., 2016. Ssd: 单次多框检测器，见：欧洲计算机视觉会议，Springer出版社。第21–37页。'
- en: 'Long et al. [2015] Long, J., Shelhamer, E., Darrell, T., 2015. Fully convolutional
    networks for semantic segmentation, in: Proceedings of the IEEE conference on
    computer vision and pattern recognition, pp. 3431–3440.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Long 等人 [2015] Long, J., Shelhamer, E., Darrell, T., 2015. 用于语义分割的全卷积网络，发表于
    IEEE 计算机视觉与模式识别会议论文集，页 3431–3440。
- en: Lu et al. [2021] Lu, M.Y., Williamson, D.F., Chen, T.Y., Chen, R.J., Barbieri,
    M., Mahmood, F., 2021. Data-efficient and weakly supervised computational pathology
    on whole-slide images. Nature Biomedical Engineering 5, 555–570.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu 等人 [2021] Lu, M.Y., Williamson, D.F., Chen, T.Y., Chen, R.J., Barbieri, M.,
    Mahmood, F., 2021. 数据高效且弱监督的计算病理学在全切片图像上的应用。自然生物医学工程 5, 555–570。
- en: Lu et al. [2015] Lu, Z., Carneiro, G., Bradley, A.P., 2015. An improved joint
    optimization of multiple level set functions for the segmentation of overlapping
    cervical cells. IEEE Transactions on Image Processing 24, 1261–1272.
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu 等人 [2015] Lu, Z., Carneiro, G., Bradley, A.P., 2015. 一种改进的多级集函数联合优化方法用于重叠宫颈细胞的分割。IEEE
    图像处理学报 24, 1261–1272。
- en: Lu et al. [2016] Lu, Z., Carneiro, G., Bradley, A.P., Ushizima, D., Nosrati,
    M.S., Bianchi, A.G., Carneiro, C.M., Hamarneh, G., 2016. Evaluation of three algorithms
    for the segmentation of overlapping cervical cells. IEEE Journal of Biomedical
    and Health Informatics 21, 441–450.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu 等人 [2016] Lu, Z., Carneiro, G., Bradley, A.P., Ushizima, D., Nosrati, M.S.,
    Bianchi, A.G., Carneiro, C.M., Hamarneh, G., 2016. 三种重叠宫颈细胞分割算法的评估。IEEE 生物医学与健康信息学学报
    21, 441–450。
- en: 'Luo et al. [2021] Luo, L., Chen, H., Zhou, Y., Lin, H., Pheng, P.A., 2021.
    Oxnet: Omni-supervised thoracic disease detection from chest x-rays. arXiv preprint
    arXiv:2104.03218 .'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luo 等人 [2021] Luo, L., Chen, H., Zhou, Y., Lin, H., Pheng, P.A., 2021. Oxnet：基于全监督的胸部
    X 射线疾病检测。arXiv 预印本 arXiv:2104.03218。
- en: 'Ma et al. [2021] Ma, J., Liu, S., Cheng, S., Chen, R., Liu, X., Chen, L., Zeng,
    S., 2021. Stsrnet: Self-texture transfer super-resolution and refocusing network.
    IEEE Transactions on Medical Imaging .'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma 等人 [2021] Ma, J., Liu, S., Cheng, S., Chen, R., Liu, X., Chen, L., Zeng,
    S., 2021. Stsrnet：自纹理转移超分辨率和再聚焦网络。IEEE 医学影像学报。
- en: 'Ma et al. [2020] Ma, J., Yu, J., Liu, S., Chen, L., Li, X., Feng, J., Chen,
    Z., Zeng, S., Liu, X., Cheng, S., 2020. Pathsrgan: Multi-supervised super-resolution
    for cytopathological images using generative adversarial network. IEEE Transactions
    on Medical Imaging 39, 2920–2930.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma 等人 [2020] Ma, J., Yu, J., Liu, S., Chen, L., Li, X., Feng, J., Chen, Z.,
    Zeng, S., Liu, X., Cheng, S., 2020. Pathsrgan：基于生成对抗网络的细胞病理图像多重监督超分辨率。IEEE 医学影像学报
    39, 2920–2930。
- en: Maharjan et al. [2017] Maharjan, S., Ranabhat, S., Tiwari, M., Bhandari, A.,
    Osti, B.P., Neopane, P., 2017. Exfoliative cytology analysis from different sites
    of the body. Journal of Chitwan Medical College 7, 33–39.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maharjan 等人 [2017] Maharjan, S., Ranabhat, S., Tiwari, M., Bhandari, A., Osti,
    B.P., Neopane, P., 2017. 来自身体不同部位的脱落细胞学分析。Chitwan 医学院学报 7, 33–39。
- en: Mahmood et al. [2019] Mahmood, F., Borders, D., Chen, R.J., McKay, G.N., Salimian,
    K.J., Baras, A., Durr, N.J., 2019. Deep adversarial training for multi-organ nuclei
    segmentation in histopathology images. IEEE Transactions on Medical Imaging 39,
    3257–3267.
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahmood 等人 [2019] Mahmood, F., Borders, D., Chen, R.J., McKay, G.N., Salimian,
    K.J., Baras, A., Durr, N.J., 2019. 基于深度对抗训练的多脏器核分割在组织病理图像中的应用。IEEE 医学影像学报 39,
    3257–3267。
- en: Manna et al. [2021] Manna, A., Kundu, R., Kaplun, D., Sinitca, A., Sarkar, R.,
    2021. A fuzzy rank-based ensemble of cnn models for classification of cervical
    cytology. Scientific Reports 11, 1–18.
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Manna 等人 [2021] Manna, A., Kundu, R., Kaplun, D., Sinitca, A., Sarkar, R., 2021.
    一种模糊排名基础的 CNN 模型集成用于宫颈细胞学分类。科学报告 11, 1–18。
- en: Maron and Lozano-Pérez [1998] Maron, O., Lozano-Pérez, T., 1998. A framework
    for multiple-instance learning. Advances in Neural Information Processing Systems
    , 570–576.
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maron 和 Lozano-Pérez [1998] Maron, O., Lozano-Pérez, T., 1998. 多实例学习框架。神经信息处理系统进展，570–576。
- en: Marzahl et al. [2020] Marzahl, C., Aubreville, M., Bertram, C.A., Stayt, J.,
    Jasensky, A.K., Bartenschlager, F., Fragoso-Garcia, M., Barton, A.K., Elsemann,
    S., Jabari, S., et al., 2020. Deep learning-based quantification of pulmonary
    hemosiderophages in cytology slides. Scientific Reports 10, 1–10.
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marzahl 等人 [2020] Marzahl, C., Aubreville, M., Bertram, C.A., Stayt, J., Jasensky,
    A.K., Bartenschlager, F., Fragoso-Garcia, M., Barton, A.K., Elsemann, S., Jabari,
    S., 等, 2020. 基于深度学习的肺部含铁细胞在细胞学切片中的定量分析。科学报告 10, 1–10。
- en: Matias et al. [2021] Matias, A.V., Cerentini, A., Macarini, L.A.B., Amorim,
    J.G.A., Daltoé, F.P., von Wangenheim, A., 2021. Segmentation, detection, and classification
    of cell nuclei on oral cytology samples stained with papanicolaou. SN Computer
    Science 2, 1–15.
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matias 等人 [2021] Matias, A.V., Cerentini, A., Macarini, L.A.B., Amorim, J.G.A.,
    Daltoé, F.P., von Wangenheim, A., 2021. 在用巴氏染色的口腔细胞学样本上进行细胞核的分割、检测和分类. SN Computer
    Science 2, 1–15.
- en: Mehrotra et al. [2011] Mehrotra, R., Mishra, S., Singh, M., Singh, M., 2011.
    The efficacy of oral brush biopsy with computer-assisted analysis in identifying
    precancerous and cancerous lesions. Head & Neck Oncology 3, 1–8.
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mehrotra 等人 [2011] Mehrotra, R., Mishra, S., Singh, M., Singh, M., 2011. 口腔刷活检结合计算机辅助分析在识别癌前病变和癌症病变中的有效性.
    Head & Neck Oncology 3, 1–8.
- en: 'Milletari et al. [2016] Milletari, F., Navab, N., Ahmadi, S.A., 2016. V-net:
    Fully convolutional neural networks for volumetric medical image segmentation,
    in: 2016 fourth international conference on 3D vision (3DV), IEEE. pp. 565–571.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Milletari 等人 [2016] Milletari, F., Navab, N., Ahmadi, S.A., 2016. V-net: 完全卷积神经网络用于体积医学图像分割,
    载于: 2016 年第四届国际 3D 视觉会议 (3DV), IEEE. pp. 565–571.'
- en: 'Miselis et al. [2019] Miselis, B., Fevens, T., Krzyżak, A., Kowal, M., Monczak,
    R., 2019. Deep neural networks for breast cancer diagnosis: fine needle biopsy
    scenario, in: Polish Conference on Biocybernetics and Biomedical Engineering,
    Springer. pp. 131–142.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Miselis 等人 [2019] Miselis, B., Fevens, T., Krzyżak, A., Kowal, M., Monczak,
    R., 2019. 深度神经网络在乳腺癌诊断中的应用：细针活检场景, 载于: 波兰生物网络学与生物医学工程会议, Springer. pp. 131–142.'
- en: 'Mitra et al. [2021] Mitra, S., Das, N., Dey, S., Chakraborty, S., Nasipuri,
    M., Naskar, M.K., 2021. Cytology image analysis techniques toward automation:
    Systematically revisited. ACM Computing Surveys (CSUR) 54, 1–41.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mitra 等人 [2021] Mitra, S., Das, N., Dey, S., Chakraborty, S., Nasipuri, M.,
    Naskar, M.K., 2021. 细胞学图像分析技术朝向自动化：系统性回顾. ACM Computing Surveys (CSUR) 54, 1–41.
- en: Mohammed et al. [2021] Mohammed, M.A., Abdurahman, F., Ayalew, Y.A., 2021. Single-cell
    conventional pap smear image classification using pre-trained deep neural network
    architectures. BMC Biomedical Engineering 3, 11–11.
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mohammed 等人 [2021] Mohammed, M.A., Abdurahman, F., Ayalew, Y.A., 2021. 使用预训练深度神经网络架构的单细胞常规巴氏涂片图像分类.
    BMC Biomedical Engineering 3, 11–11.
- en: 'Moosavi Tayebi et al. [2021] Moosavi Tayebi, R., Mu, Y., Dehkharghanian, T.,
    Ross, C., Sur, M., Foley, R., Tizhoosh, H.R., Campbell, C.J., 2021. Histogram
    of cell types: Deep learning for automated bone marrow cytology. arXiv e-prints
    , arXiv–2107.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moosavi Tayebi 等人 [2021] Moosavi Tayebi, R., Mu, Y., Dehkharghanian, T., Ross,
    C., Sur, M., Foley, R., Tizhoosh, H.R., Campbell, C.J., 2021. 细胞类型的直方图：深度学习用于自动化骨髓细胞学.
    arXiv e-prints , arXiv–2107.
- en: 'Morrison and DeNicola [1993] Morrison, W., DeNicola, D., 1993. Advantages and
    disadvantages of cytology and histopathology for the diagnosis of cancer., in:
    Seminars in veterinary medicine and surgery (small animal), pp. 222–227.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Morrison 和 DeNicola [1993] Morrison, W., DeNicola, D., 1993. 细胞学和组织病理学在癌症诊断中的优缺点,
    载于: 小动物兽医学和外科学研讨会, pp. 222–227.'
- en: 'Nayar and Wilbur [2015] Nayar, R., Wilbur, D.C., 2015. The Bethesda system
    for reporting cervical cytology: definitions, criteria, and explanatory notes.
    Springer.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nayar 和 Wilbur [2015] Nayar, R., Wilbur, D.C., 2015. 贝塞斯达系统用于报告宫颈细胞学：定义、标准和解释说明.
    Springer.
- en: 'Neubeck and Van Gool [2006] Neubeck, A., Van Gool, L., 2006. Efficient non-maximum
    suppression, in: 18th International Conference on Pattern Recognition (ICPR’06),
    IEEE. pp. 850–855.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Neubeck 和 Van Gool [2006] Neubeck, A., Van Gool, L., 2006. 高效的非极大值抑制, 载于: 第
    18 届国际模式识别大会 (ICPR’06), IEEE. pp. 850–855.'
- en: Nojima et al. [2021] Nojima, S., Terayama, K., Shimoura, S., Hijiki, S., Nonomura,
    N., Morii, E., Okuno, Y., Fujita, K., 2021. A deep learning system to diagnose
    the malignant potential of urothelial carcinoma cells in cytology specimens. Cancer
    Cytopathology .
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nojima 等人 [2021] Nojima, S., Terayama, K., Shimoura, S., Hijiki, S., Nonomura,
    N., Morii, E., Okuno, Y., Fujita, K., 2021. 一种深度学习系统用于诊断尿路上皮癌细胞在细胞学标本中的恶性潜力. Cancer
    Cytopathology .
- en: 'Noyan et al. [2020] Noyan, M.A., Durdu, M., Eskiocak, A.H., 2020. Tzancknet:
    a convolutional neural network to identify cells in the cytology of erosive-vesiculobullous
    diseases. Scientific Reports 10, 1–7.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Noyan 等人 [2020] Noyan, M.A., Durdu, M., Eskiocak, A.H., 2020. Tzancknet: 一种卷积神经网络用于识别侵蚀性水泡病细胞的细胞学.
    Scientific Reports 10, 1–7.'
- en: 'Oza et al. [2021] Oza, P., Sindagi, V.A., VS, V., Patel, V.M., 2021. Unsupervised
    domain adaption of object detectors: A survey. arXiv preprint arXiv:2105.13502
    .'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oza 等人 [2021] Oza, P., Sindagi, V.A., VS, V., Patel, V.M., 2021. 物体检测器的无监督领域适应：综述.
    arXiv preprint arXiv:2105.13502 .
- en: O’Flynn et al. [2021] O’Flynn, H., Ryan, N.A., Narine, N., Shelton, D., Rana,
    D., Crosbie, E.J., 2021. Diagnostic accuracy of cytology for the detection of
    endometrial cancer in urine and vaginal samples. Nature Communications 12, 1–8.
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: O’Flynn 等人 [2021] O’Flynn, H., Ryan, N.A., Narine, N., Shelton, D., Rana, D.,
    Crosbie, E.J., 2021. 尿液和阴道样本中子宫内膜癌的细胞学诊断准确性。自然通讯 12, 1–8。
- en: Patel et al. [2019] Patel, B.N., Rosenberg, L., Willcox, G., Baltaxe, D., Lyons,
    M., Irvin, J., Rajpurkar, P., Amrhein, T., Gupta, R., Halabi, S., et al., 2019.
    Human–machine partnership with artificial intelligence for chest radiograph diagnosis.
    NPJ Digital Medicine 2, 1–10.
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Patel 等人 [2019] Patel, B.N., Rosenberg, L., Willcox, G., Baltaxe, D., Lyons,
    M., Irvin, J., Rajpurkar, P., Amrhein, T., Gupta, R., Halabi, S., 等人，2019. 人工智能与人类机器合作进行胸部X光诊断。NPJ
    数字医学 2, 1–10。
- en: Phoulady and Mouton [2018] Phoulady, H.A., Mouton, P.R., 2018. A new cervical
    cytology dataset for nucleus detection and image classification (cervix93) and
    methods for cervical nucleus detection. arXiv preprint arXiv:1811.09651 .
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Phoulady 和 Mouton [2018] Phoulady, H.A., Mouton, P.R., 2018. 用于核检测和图像分类的新宫颈细胞学数据集（cervix93）及宫颈核检测方法。arXiv
    预印本 arXiv:1811.09651。
- en: Pirovano et al. [2021] Pirovano, A., Almeida, L.G., Ladjal, S., Bloch, I., Berlemont,
    S., 2021. Computer-aided diagnosis tool for cervical cancer screening with weakly
    supervised localization and detection of abnormalities using adaptable and explainable
    classifier. Medical Image Analysis , 102167.
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pirovano 等人 [2021] Pirovano, A., Almeida, L.G., Ladjal, S., Bloch, I., Berlemont,
    S., 2021. 一种用于宫颈癌筛查的计算机辅助诊断工具，具有弱监督定位和检测异常的自适应与可解释分类器。医学图像分析，102167。
- en: 'Plissiti et al. [2009] Plissiti, M., Tripoliti, E., Charchanti, A., Krikoni,
    O., Fotiadis, D., 2009. Automated detection of cell nuclei in pap stained cervical
    smear images using fuzzy clustering, in: 4th European Conference of the International
    Federation for Medical and Biological Engineering, Springer. pp. 637–641.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Plissiti 等人 [2009] Plissiti, M., Tripoliti, E., Charchanti, A., Krikoni, O.,
    Fotiadis, D., 2009. 使用模糊聚类自动检测宫颈涂片图像中的细胞核，见：第4届国际医学与生物工程联合会欧洲会议，Springer，pp. 637–641。
- en: 'Plissiti et al. [2018] Plissiti, M.E., Dimitrakopoulos, P., Sfikas, G., Nikou,
    C., Krikoni, O., Charchanti, A., 2018. Sipakmed: A new dataset for feature and
    image based classification of normal and pathological cervical cells in pap smear
    images, in: 2018 25th IEEE International Conference on Image Processing (ICIP),
    IEEE. pp. 3144–3148.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Plissiti 等人 [2018] Plissiti, M.E., Dimitrakopoulos, P., Sfikas, G., Nikou, C.,
    Krikoni, O., Charchanti, A., 2018. Sipakmed：一个用于正常和病理性宫颈细胞特征和图像分类的新数据集，见：2018年第25届IEEE国际图像处理会议（ICIP），IEEE，pp.
    3144–3148。
- en: Rahaman et al. [2020] Rahaman, M.M., Li, C., Wu, X., Yao, Y., Hu, Z., Jiang,
    T., Li, X., Qi, S., 2020. A survey for cervical cytopathology image analysis using
    deep learning. IEEE Access 8, 61687–61710.
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rahaman 等人 [2020] Rahaman, M.M., Li, C., Wu, X., Yao, Y., Hu, Z., Jiang, T.,
    Li, X., Qi, S., 2020. 使用深度学习的宫颈细胞病理图像分析综述。IEEE Access 8, 61687–61710。
- en: 'Rahaman et al. [2021] Rahaman, M.M., Li, C., Yao, Y., Kulwa, F., Wu, X., Li,
    X., Wang, Q., 2021. Deepcervix: A deep learning-based framework for the classification
    of cervical cells using hybrid deep feature fusion techniques. arXiv preprint
    arXiv:2102.12191 .'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rahaman 等人 [2021] Rahaman, M.M., Li, C., Yao, Y., Kulwa, F., Wu, X., Li, X.,
    Wang, Q., 2021. Deepcervix：一种基于深度学习的宫颈细胞分类框架，使用混合深度特征融合技术。arXiv 预印本 arXiv:2102.12191。
- en: kour Raina et al. [2021] kour Raina, M., Gupta, N., Kumar, S., Kusum, A., 2021.
    Evaluation of cell block technique versus conventional cytology on bronchoscopy
    guided needle aspiration/brush cytology for diagnosis of lung cancer. International
    Journal of Scientific Research 10.
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kour Raina 等人 [2021] kour Raina, M., Gupta, N., Kumar, S., Kusum, A., 2021.
    细胞块技术与传统细胞学在支气管镜引导下针吸/刷取细胞学肺癌诊断中的评估。国际科学研究期刊 10。
- en: 'Redmon et al. [2016] Redmon, J., Divvala, S., Girshick, R., Farhadi, A., 2016.
    You only look once: Unified, real-time object detection, in: Proceedings of the
    IEEE conference on computer vision and pattern recognition, pp. 779–788.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redmon 等人 [2016] Redmon, J., Divvala, S., Girshick, R., Farhadi, A., 2016. 你只需看一次：统一的实时物体检测，见：IEEE
    计算机视觉与模式识别会议论文集，pp. 779–788。
- en: 'Ren et al. [2015] Ren, S., He, K., Girshick, R., Sun, J., 2015. Faster r-cnn:
    Towards real-time object detection with region proposal networks. Advances in
    Neural Information Processing Systems 28, 91–99.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ren 等人 [2015] Ren, S., He, K., Girshick, R., Sun, J., 2015. Faster r-cnn：基于区域建议网络的实时物体检测。神经信息处理系统进展
    28, 91–99。
- en: 'Rezatofighi et al. [2019] Rezatofighi, H., Tsoi, N., Gwak, J., Sadeghian, A.,
    Reid, I., Savarese, S., 2019. Generalized intersection over union: A metric and
    a loss for bounding box regression, in: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 658–666.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rezatofighi 等人 [2019] Rezatofighi, H., Tsoi, N., Gwak, J., Sadeghian, A., Reid,
    I., Savarese, S., 2019. 广义交并比：用于边界框回归的度量和损失, 在: IEEE/CVF 计算机视觉与模式识别会议论文集, pp.
    658–666.'
- en: Rezende et al. [2021] Rezende, M.T., Silva, R., Bernardo, F.d.O., Tobias, A.H.,
    Oliveira, P.H., Machado, T.M., Costa, C.S., Medeiros, F.N., Ushizima, D.M., Carneiro,
    C.M., et al., 2021. Cric searchable image database as a public platform for conventional
    pap smear cytology data. Scientific Data 8, 1–8.
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rezende 等人 [2021] Rezende, M.T., Silva, R., Bernardo, F.d.O., Tobias, A.H.,
    Oliveira, P.H., Machado, T.M., Costa, C.S., Medeiros, F.N., Ushizima, D.M., Carneiro,
    C.M., 等人, 2021. Cric 可搜索图像数据库作为传统 Pap 涂片细胞学数据的公共平台。Scientific Data 8, 1–8.
- en: 'Ribeiro et al. [2016] Ribeiro, M.T., Singh, S., Guestrin, C., 2016. ” why should
    i trust you?” explaining the predictions of any classifier, in: Proceedings of
    the 22nd ACM SIGKDD international conference on knowledge discovery and data mining,
    pp. 1135–1144.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ribeiro 等人 [2016] Ribeiro, M.T., Singh, S., Guestrin, C., 2016. “我为什么要相信你？”
    解释任何分类器的预测, 在: 第22届 ACM SIGKDD 国际知识发现与数据挖掘会议论文集, pp. 1135–1144.'
- en: Rieke et al. [2020] Rieke, N., Hancox, J., Li, W., Milletari, F., Roth, H.R.,
    Albarqouni, S., Bakas, S., Galtier, M.N., Landman, B.A., Maier-Hein, K., et al.,
    2020. The future of digital health with federated learning. NPJ Digital Medicine
    3, 1–7.
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rieke 等人 [2020] Rieke, N., Hancox, J., Li, W., Milletari, F., Roth, H.R., Albarqouni,
    S., Bakas, S., Galtier, M.N., Landman, B.A., Maier-Hein, K., 等人, 2020. 未来数字健康与联邦学习的前景。NPJ
    Digital Medicine 3, 1–7.
- en: 'Ronneberger et al. [2015] Ronneberger, O., Fischer, P., Brox, T., 2015. U-net:
    Convolutional networks for biomedical image segmentation, in: International Conference
    on Medical image computing and computer-assisted intervention, Springer. pp. 234–241.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ronneberger 等人 [2015] Ronneberger, O., Fischer, P., Brox, T., 2015. U-net:
    用于生物医学图像分割的卷积网络, 在: 国际医学图像计算与计算机辅助干预会议, Springer. pp. 234–241.'
- en: Rosenblatt [1961] Rosenblatt, F., 1961. Principles of neurodynamics. perceptrons
    and the theory of brain mechanisms. Technical Report. Cornell Aeronautical Lab
    Inc Buffalo NY.
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rosenblatt [1961] Rosenblatt, F., 1961. 神经动力学原理。感知机及大脑机制理论。技术报告。康奈尔航空实验室公司布法罗
    NY.
- en: Rosenthal et al. [2016] Rosenthal, D.L., Wojcik, E.M., Kurtycz, D.F., 2016.
    The Paris system for reporting urinary cytology. Springer.
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rosenthal 等人 [2016] Rosenthal, D.L., Wojcik, E.M., Kurtycz, D.F., 2016. 巴黎系统用于尿液细胞学报告。Springer.
- en: Rosenzweig and Bartl [2015] Rosenzweig, J., Bartl, M., 2015. A review and analysis
    of literature on autonomous driving. E-Journal Making-of Innovation , 1–57.
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rosenzweig 和 Bartl [2015] Rosenzweig, J., Bartl, M., 2015. 自动驾驶相关文献的回顾与分析。E-Journal
    Making-of Innovation , 1–57.
- en: Rumelhart et al. [1986] Rumelhart, D.E., Hinton, G.E., Williams, R.J., 1986.
    Learning representations by back-propagating errors. Nature 323, 533–536.
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rumelhart 等人 [1986] Rumelhart, D.E., Hinton, G.E., Williams, R.J., 1986. 通过反向传播错误学习表示。Nature
    323, 533–536.
- en: 'Russell et al. [2008] Russell, B.C., Torralba, A., Murphy, K.P., Freeman, W.T.,
    2008. Labelme: a database and web-based tool for image annotation. International
    Journal of Computer Vision 77, 157–173.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Russell 等人 [2008] Russell, B.C., Torralba, A., Murphy, K.P., Freeman, W.T.,
    2008. Labelme: 一个用于图像注释的数据库和基于网页的工具。国际计算机视觉杂志 77, 157–173.'
- en: Saikia et al. [2019] Saikia, A.R., Bora, K., Mahanta, L.B., Das, A.K., 2019.
    Comparative assessment of cnn architectures for classification of breast fnac
    images. Tissue and Cell 57, 8–14.
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saikia 等人 [2019] Saikia, A.R., Bora, K., Mahanta, L.B., Das, A.K., 2019. CNN
    架构在乳腺 FNAC 图像分类中的比较评估。Tissue and Cell 57, 8–14.
- en: 'Samuel et al. [2020] Samuel, S., Löffler, F., König-Ries, B., 2020. Machine
    learning pipelines: provenance, reproducibility and fair data principles. arXiv
    preprint arXiv:2006.12117 .'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Samuel 等人 [2020] Samuel, S., Löffler, F., König-Ries, B., 2020. 机器学习管道：来源、可重复性和公平数据原则。arXiv
    预印本 arXiv:2006.12117.
- en: 'Van de Sande et al. [2011] Van de Sande, K.E., Uijlings, J.R., Gevers, T.,
    Smeulders, A.W., 2011. Segmentation as selective search for object recognition,
    in: 2011 international conference on computer vision, IEEE. pp. 1879–1886.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Van de Sande 等人 [2011] Van de Sande, K.E., Uijlings, J.R., Gevers, T., Smeulders,
    A.W., 2011. 作为选择性搜索的分割用于物体识别, 在: 2011 国际计算机视觉会议, IEEE. pp. 1879–1886.'
- en: 'Sanyal et al. [2018] Sanyal, P., Mukherjee, T., Barui, S., Das, A., Gangopadhyay,
    P., 2018. Artificial intelligence in cytopathology: a neural network to identify
    papillary carcinoma on thyroid fine-needle aspiration cytology smears. Journal
    of pathology informatics 9.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sanyal 等人 [2018] Sanyal, P., Mukherjee, T., Barui, S., Das, A., Gangopadhyay,
    P., 2018. 细胞病理学中的人工智能：识别甲状腺细针抽吸细胞学涂片中乳头状癌的神经网络。病理信息学杂志 9。
- en: 'Selvaraju et al. [2017] Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R.,
    Parikh, D., Batra, D., 2017. Grad-cam: Visual explanations from deep networks
    via gradient-based localization, in: Proceedings of the IEEE international conference
    on computer vision, pp. 618–626.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Selvaraju 等人 [2017] Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh,
    D., Batra, D., 2017. Grad-cam：通过基于梯度的定位从深度网络中获得视觉解释，发表于：IEEE 国际计算机视觉会议论文集，pp.
    618–626。
- en: 'Shanthi et al. [2019] Shanthi, P., Faruqi, F., Hareesha, K., Kudva, R., 2019.
    Deep convolution neural network for malignancy detection and classification in
    microscopic uterine cervix cell images. Asian Pacific Journal of Cancer Prevention:
    APJCP 20, 3447.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shanthi 等人 [2019] Shanthi, P., Faruqi, F., Hareesha, K., Kudva, R., 2019. 用于显微宫颈细胞图像中的恶性肿瘤检测和分类的深度卷积神经网络。亚太癌症预防杂志：APJCP
    20, 3447。
- en: Shao et al. [2019] Shao, W., Han, Z., Cheng, J., Cheng, L., Wang, T., Sun, L.,
    Lu, Z., Zhang, J., Zhang, D., Huang, K., 2019. Integrative analysis of pathological
    images and multi-dimensional genomic data for early-stage cancer prognosis. IEEE
    Transactions on Medical Imaging 39, 99–110.
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shao 等人 [2019] Shao, W., Han, Z., Cheng, J., Cheng, L., Wang, T., Sun, L., Lu,
    Z., Zhang, J., Zhang, D., Huang, K., 2019. 综合分析病理图像和多维基因组数据以预测早期癌症。IEEE 医学成像交易
    39, 99–110。
- en: Shi et al. [2021] Shi, J., Wang, R., Zheng, Y., Jiang, Z., Zhang, H., Yu, L.,
    2021. Cervical cell classification with graph convolutional network. Computer
    Methods and Programs in Biomedicine 198, 105807.
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等人 [2021] Shi, J., Wang, R., Zheng, Y., Jiang, Z., Zhang, H., Yu, L., 2021.
    使用图卷积网络进行宫颈细胞分类。计算机方法与程序在生物医学 198, 105807。
- en: 'Skaarland [1986] Skaarland, E., 1986. New concept in diagnostic endometrial
    cytology: diagnostic criteria based on composition and architecture of large tissue
    fragments in smears. Journal of Clinical Pathology 39, 36–43.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Skaarland [1986] Skaarland, E., 1986. 诊断性子宫内膜细胞学的新概念：基于涂片中大组织片段的组成和结构的诊断标准。临床病理学杂志
    39, 36–43。
- en: 'Sompawong et al. [2019] Sompawong, N., Mopan, J., Pooprasert, P., Himakhun,
    W., Suwannarurk, K., Ngamvirojcharoen, J., Vachiramon, T., Tantibundhit, C., 2019.
    Automated pap smear cervical cancer screening using deep learning, in: 2019 41st
    Annual International Conference of the IEEE Engineering in Medicine and Biology
    Society (EMBC), IEEE. pp. 7044–7048.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sompawong 等人 [2019] Sompawong, N., Mopan, J., Pooprasert, P., Himakhun, W.,
    Suwannarurk, K., Ngamvirojcharoen, J., Vachiramon, T., Tantibundhit, C., 2019.
    使用深度学习的自动化宫颈癌筛查，发表于：2019年第41届IEEE医学与生物工程年会（EMBC），IEEE。pp. 7044–7048。
- en: Song et al. [2016] Song, Y., Tan, E.L., Jiang, X., Cheng, J.Z., Ni, D., Chen,
    S., Lei, B., Wang, T., 2016. Accurate cervical cell segmentation from overlapping
    clumps in pap smear images. IEEE transactions on medical imaging 36, 288–300.
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song 等人 [2016] Song, Y., Tan, E.L., Jiang, X., Cheng, J.Z., Ni, D., Chen, S.,
    Lei, B., Wang, T., 2016. 从重叠的团块中准确分割宫颈细胞。IEEE 医学成像交易 36, 288–300。
- en: Song et al. [2015] Song, Y., Zhang, L., Chen, S., Ni, D., Lei, B., Wang, T.,
    2015. Accurate segmentation of cervical cytoplasm and nuclei based on multiscale
    convolutional network and graph partitioning. IEEE Transactions on Biomedical
    Engineering 62, 2421–2433.
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song 等人 [2015] Song, Y., Zhang, L., Chen, S., Ni, D., Lei, B., Wang, T., 2015.
    基于多尺度卷积网络和图分割的宫颈细胞质和细胞核的准确分割。IEEE 生物医学工程交易 62, 2421–2433。
- en: 'Song et al. [2014] Song, Y., Zhang, L., Chen, S., Ni, D., Li, B., Zhou, Y.,
    Lei, B., Wang, T., 2014. A deep learning based framework for accurate segmentation
    of cervical cytoplasm and nuclei, in: 2014 36th Annual International Conference
    of the IEEE Engineering in Medicine and Biology Society, IEEE. pp. 2903–2906.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song 等人 [2014] Song, Y., Zhang, L., Chen, S., Ni, D., Li, B., Zhou, Y., Lei,
    B., Wang, T., 2014. 基于深度学习的框架用于准确分割宫颈细胞质和细胞核，发表于：2014年第36届IEEE医学与生物工程年会，IEEE。pp.
    2903–2906。
- en: 'Song et al. [2020] Song, Y., Zhu, L., Lei, B., Sheng, B., Dou, Q., Qin, J.,
    Choi, K.S., 2020. Shape mask generator: Learning to refine shape priors for segmenting
    overlapping cervical cytoplasms, in: International Conference on Medical Image
    Computing and Computer-Assisted Intervention, Springer. pp. 639–649.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song 等人 [2020] Song, Y., Zhu, L., Lei, B., Sheng, B., Dou, Q., Qin, J., Choi,
    K.S., 2020. 形状掩模生成器：学习优化形状先验以分割重叠的宫颈细胞质，见于：国际医学图像计算与计算机辅助干预会议，Springer。第639–649页。
- en: 'Sornapudi et al. [2019] Sornapudi, S., Brown, G.T., Xue, Z., Long, R., Allen,
    L., Antani, S., 2019. Comparing deep learning models for multi-cell classification
    in liquid-based cervical cytology image, in: AMIA Annual Symposium Proceedings,
    American Medical Informatics Association. p. 820.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sornapudi 等人 [2019] Sornapudi, S., Brown, G.T., Xue, Z., Long, R., Allen, L.,
    Antani, S., 2019. 比较用于液基宫颈细胞学图像的多细胞分类深度学习模型，见于：AMIA 年会论文集，美国医学信息学协会。第820页。
- en: 'Srinidhi et al. [2020] Srinidhi, C.L., Ciga, O., Martel, A.L., 2020. Deep neural
    network models for computational histopathology: A survey. Medical Image Analysis
    , 101813.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Srinidhi 等人 [2020] Srinidhi, C.L., Ciga, O., Martel, A.L., 2020. 用于计算机病理学的深度神经网络模型：综述。《医学图像分析》，101813。
- en: Su et al. [2020] Su, F., Sun, Y., Hu, Y., Yuan, P., Wang, X., Wang, Q., Li,
    J., Ji, J.F., 2020. Development and validation of a deep learning system for ascites
    cytopathology interpretation. Gastric Cancer 23, 1041–1050.
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Su 等人 [2020] Su, F., Sun, Y., Hu, Y., Yuan, P., Wang, X., Wang, Q., Li, J.,
    Ji, J.F., 2020. 深度学习系统在腹水细胞病理学解释中的开发与验证。《胃癌》23, 1041–1050。
- en: 'Sundararajan et al. [2017] Sundararajan, M., Taly, A., Yan, Q., 2017. Axiomatic
    attribution for deep networks, in: International Conference on Machine Learning,
    PMLR. pp. 3319–3328.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sundararajan 等人 [2017] Sundararajan, M., Taly, A., Yan, Q., 2017. 深度网络的公理归因，见于：国际机器学习大会，PMLR。第3319–3328页。
- en: 'Szegedy et al. [2015] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.,
    Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A., 2015. Going deeper with
    convolutions, in: Proceedings of the IEEE conference on computer vision and pattern
    recognition, pp. 1–9.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等人 [2015] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov,
    D., Erhan, D., Vanhoucke, V., Rabinovich, A., 2015. 更深入的卷积，见于：IEEE 计算机视觉与模式识别会议论文集，第1–9页。
- en: 'Tan et al. [2021] Tan, X., Li, K., Zhang, J., Wang, W., Wu, B., Wu, J., Li,
    X., Huang, X., 2021. Automatic model for cervical cancer screening based on convolutional
    neural network: a retrospective, multicohort, multicenter study. Cancer Cell International
    21, 1–10.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan 等人 [2021] Tan, X., Li, K., Zhang, J., Wang, W., Wu, B., Wu, J., Li, X.,
    Huang, X., 2021. 基于卷积神经网络的宫颈癌筛查自动模型：一项回顾性、多队列、多中心研究。《癌症细胞国际》21, 1–10。
- en: Tareef et al. [2017] Tareef, A., Song, Y., Huang, H., Wang, Y., Feng, D., Chen,
    M., Cai, W., 2017. Optimizing the cervix cytological examination based on deep
    learning and dynamic shape modeling. Neurocomputing 248, 28–40.
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tareef 等人 [2017] Tareef, A., Song, Y., Huang, H., Wang, Y., Feng, D., Chen,
    M., Cai, W., 2017. 基于深度学习和动态形状建模的宫颈细胞学检查优化。《神经计算》248, 28–40。
- en: 'Tay et al. [2020] Tay, Y., Dehghani, M., Bahri, D., Metzler, D., 2020. Efficient
    transformers: A survey. arXiv preprint arXiv:2009.06732 .'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tay 等人 [2020] Tay, Y., Dehghani, M., Bahri, D., Metzler, D., 2020. 高效的变换器：综述。arXiv
    预印本 arXiv:2009.06732。
- en: Teramoto et al. [2017] Teramoto, A., Tsukamoto, T., Kiriyama, Y., Fujita, H.,
    2017. Automated classification of lung cancer types from cytological images using
    deep convolutional neural networks. BioMed research international 2017.
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Teramoto 等人 [2017] Teramoto, A., Tsukamoto, T., Kiriyama, Y., Fujita, H., 2017.
    使用深度卷积神经网络对肺癌类型进行自动分类的研究。《生物医学研究国际》2017。
- en: 'Teramoto et al. [2020] Teramoto, A., Tsukamoto, T., Yamada, A., Kiriyama, Y.,
    Imaizumi, K., Saito, K., Fujita, H., 2020. Deep learning approach to classification
    of lung cytological images: Two-step training using actual and synthesized images
    by progressive growing of generative adversarial networks. PloS one 15, e0229951.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Teramoto 等人 [2020] Teramoto, A., Tsukamoto, T., Yamada, A., Kiriyama, Y., Imaizumi,
    K., Saito, K., Fujita, H., 2020. 基于深度学习的肺细胞学图像分类方法：通过生成对抗网络逐步训练实际图像和合成图像。《PloS
    一》15, e0229951。
- en: Teramoto et al. [2019] Teramoto, A., Yamada, A., Kiriyama, Y., Tsukamoto, T.,
    Yan, K., Zhang, L., Imaizumi, K., Saito, K., Fujita, H., 2019. Automated classification
    of benign and malignant cells from lung cytological images using deep convolutional
    neural network. Informatics in Medicine Unlocked 16, 100205.
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Teramoto 等人 [2019] Teramoto, A., Yamada, A., Kiriyama, Y., Tsukamoto, T., Yan,
    K., Zhang, L., Imaizumi, K., Saito, K., Fujita, H., 2019. 使用深度卷积神经网络对肺细胞学图像中的良性和恶性细胞进行自动分类。《医学信息学解锁》16,
    100205。
- en: Teramoto et al. [2021] Teramoto, A., Yamada, A., Tsukamoto, T., Kiriyama, Y.,
    Sakurai, E., Shiogama, K., Michiba, A., Imaizumi, K., Saito, K., Fujita, H., 2021.
    Mutual stain conversion between giemsa and papanicolaou in cytological images
    using cycle generative adversarial network. Heliyon 7, e06331.
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Teramoto 等 [2021] Teramoto, A., Yamada, A., Tsukamoto, T., Kiriyama, Y., Sakurai,
    E., Shiogama, K., Michiba, A., Imaizumi, K., Saito, K., Fujita, H., 2021. 使用循环生成对抗网络在细胞学图像中进行
    Giemsa 与 Papanicolaou 之间的相互染色转换。Heliyon 7, e06331。
- en: 'Tian et al. [2019] Tian, Z., Shen, C., Chen, H., He, T., 2019. Fcos: Fully
    convolutional one-stage object detection, in: Proceedings of the IEEE/CVF international
    conference on computer vision, pp. 9627–9636.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tian 等 [2019] Tian, Z., Shen, C., Chen, H., He, T., 2019. FCOS：全卷积单阶段目标检测，见：IEEE/CVF
    国际计算机视觉会议论文集，第 9627–9636 页。
- en: 'Tolles [1955] Tolles, W.E., 1955. Section of biology: The cytoanalyzer—an example
    of physics in medical research. Transactions of the New York Academy of Sciences
    17, 250–256.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tolles [1955] Tolles, W.E., 1955. 生物学部分：细胞分析仪——医学研究中的物理学实例。纽约科学院学报 17, 250–256。
- en: 'Tolles and Bostrom [1956] Tolles, W.E., Bostrom, R., 1956. Automatic screening
    of cytological smears for cancer: the instrumentation. Annals of the New York
    Academy of Sciences 63, 1211–1218.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tolles 和 Bostrom [1956] Tolles, W.E., Bostrom, R., 1956. 癌症细胞学涂片的自动筛查：仪器设备。纽约科学院年鉴
    63, 1211–1218。
- en: 'Tomczak et al. [2015] Tomczak, K., Czerwińska, P., Wiznerowicz, M., 2015. The
    cancer genome atlas (tcga): an immeasurable source of knowledge. Contemporary
    Oncology 19, A68.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tomczak 等 [2015] Tomczak, K., Czerwińska, P., Wiznerowicz, M., 2015. 癌症基因组图谱
    (TCGA)：一个不可估量的知识来源。现代肿瘤学 19, A68。
- en: Vaickus et al. [2019] Vaickus, L.J., Suriawinata, A.A., Wei, J.W., Liu, X.,
    2019. Automating the paris system for urine cytopathology—a hybrid deep-learning
    and morphometric approach. Cancer Cytopathology 127, 98–115.
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaickus 等 [2019] Vaickus, L.J., Suriawinata, A.A., Wei, J.W., Liu, X., 2019.
    自动化尿液细胞病理学的巴黎系统——一种混合深度学习与形态计量的方法。癌症细胞病理学 127, 98–115。
- en: 'Vaswani et al. [2017] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J.,
    Jones, L., Gomez, A.N., Kaiser, Ł., Polosukhin, I., 2017. Attention is all you
    need, in: Advances in neural information processing systems, pp. 5998–6008.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani 等 [2017] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,
    L., Gomez, A.N., Kaiser, Ł., Polosukhin, I., 2017. 注意力机制就是你所需要的，见：神经信息处理系统进展，第
    5998–6008 页。
- en: 'Walter et al. [2021] Walter, F.C., Damrich, S., Hamprecht, F.A., 2021. Multistar:
    Instance segmentation of overlapping objects with star-convex polygons, in: 2021
    IEEE 18th International Symposium on Biomedical Imaging (ISBI), IEEE. pp. 295–298.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Walter 等 [2021] Walter, F.C., Damrich, S., Hamprecht, F.A., 2021. Multistar：使用星形凸多边形对重叠对象进行实例分割，见：2021
    IEEE 第 18 届国际生物医学成像研讨会 (ISBI)，IEEE，第 295–298 页。
- en: Wan et al. [2019] Wan, T., Xu, S., Sang, C., Jin, Y., Qin, Z., 2019. Accurate
    segmentation of overlapping cells in cervical cytology with deep convolutional
    neural networks. Neurocomputing 365, 157–170.
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wan 等 [2019] Wan, T., Xu, S., Sang, C., Jin, Y., Qin, Z., 2019. 使用深度卷积神经网络对宫颈细胞学中重叠细胞进行准确分割。神经计算
    365, 157–170。
- en: 'Wang and Deng [2021] Wang, M., Deng, W., 2021. Deep face recognition: A survey.
    Neurocomputing 429, 215–244.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 和 Deng [2021] Wang, M., Deng, W., 2021. 深度人脸识别：综述。神经计算 429, 215–244。
- en: Wei et al. [2021] Wei, Z., Cheng, S., Liu, X., Zeng, S., 2021. An efficient
    cervical whole slide image analysis framework based on multi-scale semantic and
    spatial deep features. arXiv preprint arXiv:2106.15113 .
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等 [2021] Wei, Z., Cheng, S., Liu, X., Zeng, S., 2021. 基于多尺度语义和空间深度特征的高效宫颈全幅图像分析框架。arXiv
    预印本 arXiv:2106.15113。
- en: 'Wilbur et al. [2009] Wilbur, D.C., Black-Schaffer, W.S., Luff, R.D., Abraham,
    K.P., Kemper, C., Molina, J.T., Tench, W.D., 2009. The becton dickinson focalpoint
    gs imaging system: clinical trials demonstrate significantly improved sensitivity
    for the detection of important cervical lesions. American Journal of Clinical
    Pathology 132, 767–775.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wilbur 等 [2009] Wilbur, D.C., Black-Schaffer, W.S., Luff, R.D., Abraham, K.P.,
    Kemper, C., Molina, J.T., Tench, W.D., 2009. 贝克顿·迪金森 FocalPoint GS 成像系统：临床试验表明其在检测重要宫颈病变方面的敏感性显著提高。美国临床病理学杂志
    132, 767–775。
- en: Wu et al. [2018] Wu, M., Yan, C., Liu, H., Liu, Q., Yin, Y., 2018. Automatic
    classification of cervical cancer from cytological images by using convolutional
    neural network. Bioscience reports 38, BSR20181769.
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等 [2018] Wu, M., Yan, C., Liu, H., Liu, Q., Yin, Y., 2018. 使用卷积神经网络对宫颈癌进行自动分类。生物科学报告
    38, BSR20181769。
- en: Xiang et al. [2020] Xiang, Y., Sun, W., Pan, C., Yan, M., Yin, Z., Liang, Y.,
    2020. A novel automation-assisted cervical cancer reading method based on convolutional
    neural network. Biocybernetics and Biomedical Engineering 40, 611–623.
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiang et al. [2020] Xiang, Y., Sun, W., Pan, C., Yan, M., Yin, Z., Liang, Y.,
    2020. 基于卷积神经网络的新型自动化辅助宫颈癌阅读方法。生物网络与生物医学工程 40, 611–623。
- en: 'Xie et al. [2018] Xie, Y., Xing, F., Shi, X., Kong, X., Su, H., Yang, L., 2018.
    Efficient and robust cell detection: A structured regression approach. Medical
    Image Analysis 44, 245–254.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie et al. [2018] Xie, Y., Xing, F., Shi, X., Kong, X., Su, H., Yang, L., 2018.
    高效且稳健的细胞检测：一种结构化回归方法。医学图像分析 44, 245–254。
- en: 'Xu et al. [2014] Xu, Y., Mo, T., Feng, Q., Zhong, P., Lai, M., Eric, I., Chang,
    C., 2014. Deep learning of feature representation with multiple instance learning
    for medical image analysis, in: 2014 IEEE international conference on acoustics,
    speech and signal processing (ICASSP), IEEE. pp. 1626–1630.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. [2014] Xu, Y., Mo, T., Feng, Q., Zhong, P., Lai, M., Eric, I., Chang,
    C., 2014. 基于多实例学习的医学图像分析特征表示的深度学习，见：2014 IEEE国际声学、语音与信号处理会议（ICASSP），IEEE。pp. 1626–1630。
- en: 'Yi et al. [2019] Yi, X., Walia, E., Babyn, P., 2019. Generative adversarial
    network in medical imaging: A review. Medical Image Analysis 58, 101552.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yi et al. [2019] Yi, X., Walia, E., Babyn, P., 2019. 医学成像中的生成对抗网络：综述。医学图像分析
    58, 101552。
- en: Yosinski et al. [2014] Yosinski, J., Clune, J., Bengio, Y., Lipson, H., 2014.
    How transferable are features in deep neural networks? arXiv preprint arXiv:1411.1792
    .
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yosinski et al. [2014] Yosinski, J., Clune, J., Bengio, Y., Lipson, H., 2014.
    深度神经网络中的特征可迁移性如何？arXiv 预印本 arXiv:1411.1792。
- en: 'Yu et al. [2016] Yu, J., Jiang, Y., Wang, Z., Cao, Z., Huang, T., 2016. Unitbox:
    An advanced object detection network, in: Proceedings of the 24th ACM international
    conference on Multimedia, pp. 516–520.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu et al. [2016] Yu, J., Jiang, Y., Wang, Z., Cao, Z., Huang, T., 2016. Unitbox：一种先进的目标检测网络，见：第24届ACM国际多媒体会议论文集，pp.
    516–520。
- en: 'Yu et al. [2021] Yu, S., Zhang, S., Wang, B., Dun, H., Xu, L., Huang, X., Shi,
    E., Feng, X., 2021. Generative adversarial network based data augmentation to
    improve cervical cell classification model. Mathematical Biosciences and Engineering:
    MBE 18, 1740–1752.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu et al. [2021] Yu, S., Zhang, S., Wang, B., Dun, H., Xu, L., Huang, X., Shi,
    E., Feng, X., 2021. 基于生成对抗网络的数据增强以改善宫颈细胞分类模型。数学生物科学与工程：MBE 18, 1740–1752。
- en: Zaremba et al. [2014] Zaremba, W., Sutskever, I., Vinyals, O., 2014. Recurrent
    neural network regularization. arXiv preprint arXiv:1409.2329 .
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zaremba et al. [2014] Zaremba, W., Sutskever, I., Vinyals, O., 2014. 循环神经网络的正则化。arXiv
    预印本 arXiv:1409.2329。
- en: 'Żejmo et al. [2017] Żejmo, M., Kowal, M., Korbicz, J., Monczak, R., 2017. Classification
    of breast cancer cytological specimen using convolutional neural network, in:
    Journal of Physics: Conference Series, IOP Publishing. p. 012060.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Żejmo et al. [2017] Żejmo, M., Kowal, M., Korbicz, J., Monczak, R., 2017. 使用卷积神经网络对乳腺癌细胞学样本进行分类，见：物理学杂志：会议系列，IOP
    Publishing。p. 012060。
- en: 'Zhang et al. [2019] Zhang, C., Liu, D., Wang, L., Li, Y., Chen, X., Luo, R.,
    Che, S., Liang, H., Li, Y., Liu, S., et al., 2019. Dccl: a benchmark for cervical
    cytology analysis, in: International Workshop on Machine Learning in Medical Imaging,
    Springer. pp. 63–72.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. [2019] Zhang, C., Liu, D., Wang, L., Li, Y., Chen, X., Luo, R.,
    Che, S., Liang, H., Li, Y., Liu, S., 等，2019. Dccl：宫颈细胞学分析基准，见：医学成像中的机器学习国际研讨会，Springer。pp.
    63–72。
- en: Zhang et al. [2020] Zhang, H., Zhu, H., Ling, X., 2020. Polar coordinate sampling-based
    segmentation of overlapping cervical cells using attention u-net and random walk.
    Neurocomputing 383, 212–223.
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. [2020] Zhang, H., Zhu, H., Ling, X., 2020. 基于极坐标采样的重叠宫颈细胞分割方法，结合注意力u-net和随机游走。神经计算
    383, 212–223。
- en: Zhang et al. [2014] Zhang, L., Kong, H., Ting Chin, C., Liu, S., Fan, X., Wang,
    T., Chen, S., 2014. Automation-assisted cervical cancer screening in manual liquid-based
    cytology with hematoxylin and eosin staining. Cytometry Part A 85, 214–230.
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. [2014] Zhang, L., Kong, H., Ting Chin, C., Liu, S., Fan, X., Wang,
    T., Chen, S., 2014. 手动液基细胞学中的自动化辅助宫颈癌筛查，采用苏木精-伊红染色。细胞计数A部分 85, 214–230。
- en: 'Zhang et al. [2017] Zhang, L., Lu, L., Nogues, I., Summers, R.M., Liu, S.,
    Yao, J., 2017. Deeppap: deep convolutional networks for cervical cell classification.
    IEEE journal of biomedical and health informatics 21, 1633–1643.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. [2017] Zhang, L., Lu, L., Nogues, I., Summers, R.M., Liu, S., Yao,
    J., 2017. Deeppap：用于宫颈细胞分类的深度卷积网络。IEEE生物医学与健康信息学杂志 21, 1633–1643。
- en: 'Zhang et al. [2021] Zhang, Y., Sidibé, D., Morel, O., Mériaudeau, F., 2021.
    Deep multimodal fusion for semantic image segmentation: A survey. Image and Vision
    Computing 105, 104042.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. [2021] Zhang, Y., Sidibé, D., Morel, O., Mériaudeau, F., 2021.
    深度多模态融合用于语义图像分割：综述。图像与视觉计算 105, 104042。
- en: 'Zhao et al. [2019] Zhao, Z., Lin, H., Chen, H., Heng, P.A., 2019. Pfa-scannet:
    Pyramidal feature aggregation with synergistic learning for breast cancer metastasis
    analysis, in: International Conference on Medical Image Computing and Computer-Assisted
    Intervention, Springer. pp. 586–594.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '赵等人 [2019] 赵志, 林辉, 陈浩, Heng, P.A., 2019. PFA-ScanNet: 基于金字塔特征聚合的乳腺癌转移分析与协同学习,
    见: 医学图像计算与计算机辅助干预国际会议, Springer. 页586–594。'
- en: 'Zheng et al. [2020] Zheng, Z., Wang, P., Liu, W., Li, J., Ye, R., Ren, D.,
    2020. Distance-iou loss: Faster and better learning for bounding box regression,
    in: Proceedings of the AAAI Conference on Artificial Intelligence, pp. 12993–13000.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '郑等人 [2020] 郑志, 王鹏, 刘伟, 李静, 叶瑞, 任东, 2020. Distance-IoU损失: 更快更好地进行边界框回归学习, 见:
    AAAI人工智能会议论文集, 页12993–13000。'
- en: 'Zhou et al. [2016] Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba,
    A., 2016. Learning deep features for discriminative localization, in: Proceedings
    of the IEEE conference on computer vision and pattern recognition, pp. 2921–2929.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '周等人 [2016] 周博文, Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., 2016. 用于判别性定位的深度特征学习,
    见: IEEE计算机视觉与模式识别会议论文集, 页2921–2929。'
- en: 'Zhou et al. [2020] Zhou, Y., Chen, H., Lin, H., Heng, P.A., 2020. Deep semi-supervised
    knowledge distillation for overlapping cervical cell instance segmentation, in:
    International Conference on Medical Image Computing and Computer-Assisted Intervention,
    Springer. pp. 521–531.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '周等人 [2020] 周毅, 陈浩, 林辉, Heng, P.A., 2020. 用于重叠宫颈细胞实例分割的深度半监督知识蒸馏, 见: 医学图像计算与计算机辅助干预国际会议,
    Springer. 页521–531。'
- en: 'Zhou et al. [2019a] Zhou, Y., Chen, H., Xu, J., Dou, Q., Heng, P.A., 2019a.
    Irnet: Instance relation network for overlapping cervical cell segmentation, in:
    International Conference on Medical Image Computing and Computer-Assisted Intervention,
    Springer. pp. 640–648.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '周等人 [2019a] 周毅, 陈浩, 徐杰, Dou, Q., Heng, P.A., 2019a. IRNet: 用于重叠宫颈细胞分割的实例关系网络,
    见: 医学图像计算与计算机辅助干预国际会议, Springer. 页640–648。'
- en: 'Zhou et al. [2019b] Zhou, Y., Onder, O.F., Dou, Q., Tsougenis, E., Chen, H.,
    Heng, P.A., 2019b. Cia-net: Robust nuclei instance segmentation with contour-aware
    information aggregation, in: International Conference on Information Processing
    in Medical Imaging, Springer. pp. 682–693.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '周等人 [2019b] 周毅, Onder, O.F., Dou, Q., Tsougenis, E., 陈浩, Heng, P.A., 2019b.
    CIA-Net: 通过轮廓感知信息聚合实现鲁棒的细胞实例分割, 见: 医学影像信息处理国际会议, Springer. 页682–693。'
- en: Zhou [2018] Zhou, Z.H., 2018. A brief introduction to weakly supervised learning.
    National Science Review 5, 44–53.
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 周 [2018] 周志华, 2018. 对弱监督学习的简要介绍. 《国家科学评论》5, 44–53。
- en: 'Zhu et al. [2017] Zhu, J.Y., Park, T., Isola, P., Efros, A.A., 2017. Unpaired
    image-to-image translation using cycle-consistent adversarial networks, in: Proceedings
    of the IEEE international conference on computer vision, pp. 2223–2232.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '朱等人 [2017] 朱晋跃, Park, T., Isola, P., Efros, A.A., 2017. 使用循环一致对抗网络的无配对图像到图像转换,
    见: IEEE国际计算机视觉会议论文集, 页2223–2232。'
- en: Zhu et al. [2021] Zhu, X., Li, X., Ong, K., Zhang, W., Li, W., Li, L., Young,
    D., Su, Y., Shang, B., Peng, L., et al., 2021. Hybrid ai-assistive diagnostic
    model permits rapid tbs classification of cervical liquid-based thin-layer cell
    smears. Nature Communications 12, 1–12.
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朱等人 [2021] 朱兴, 李翔, Ong, K., 张伟, 李文, 李龙, Young, D., 苏勇, 尚博, 彭龙, 等, 2021. 混合AI辅助诊断模型允许快速TBS分类宫颈液基薄层细胞涂片.
    《自然通讯》12, 1–12。
