- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-06 20:04:29'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 20:04:29'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1910.02923] A Survey on Active Learning and Human-in-the-Loop Deep Learning
    for Medical Image Analysis1footnote 11footnote 1'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1910.02923] 关于主动学习和人机交互深度学习在医学图像分析中的应用1脚注 11脚注 1'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1910.02923](https://ar5iv.labs.arxiv.org/html/1910.02923)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1910.02923](https://ar5iv.labs.arxiv.org/html/1910.02923)
- en: 'A Survey on Active Learning and Human-in-the-Loop Deep Learning for Medical
    Image Analysis¹¹footnotemark: 1'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '关于主动学习和人机交互深度学习在医学图像分析中的应用¹¹脚注标记: 1'
- en: 'Samuel Budd Emma C Robinson²²footnotemark: 2 Bernhard Kainz³³footnotemark:
    3 Department of Computing, Imperial College London, UK Department of Imaging Sciences,
    King’s College London, UK'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 'Samuel Budd Emma C Robinson²²脚注标记: 2 Bernhard Kainz³³脚注标记: 3 计算系，帝国理工学院，英国
    成像科学系，国王学院，伦敦，英国'
- en: Feature Table
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征表
- en: 'Samuel Budd Emma C Robinson²²footnotemark: 2 Bernhard Kainz³³footnotemark:
    3 Department of Computing, Imperial College London, UK Department of Imaging Sciences,
    King’s College London, UK'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 'Samuel Budd Emma C Robinson²²脚注标记: 2 Bernhard Kainz³³脚注标记: 3 计算系，帝国理工学院，英国
    成像科学系，国王学院，伦敦，英国'
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Fully automatic deep learning has become the state-of-the-art technique for
    many tasks including image acquisition, analysis and interpretation, and for the
    extraction of clinically useful information for computer-aided detection, diagnosis,
    treatment planning, intervention and therapy. However, the unique challenges posed
    by medical image analysis suggest that retaining a human end-user in any deep
    learning enabled system will be beneficial. In this review we investigate the
    role that humans might play in the development and deployment of deep learning
    enabled diagnostic applications and focus on techniques that will retain a significant
    input from a human end user. Human-in-the-Loop computing is an area that we see
    as increasingly important in future research due to the safety-critical nature
    of working in the medical domain. We evaluate four key areas that we consider
    vital for deep learning in the clinical practice: (1) *Active Learning* to choose
    the best data to annotate for optimal model performance; (2) *Interaction with
    model outputs* - using iterative feedback to steer models to optima for a given
    prediction and offering meaningful ways to interpret and respond to predictions;
    (3) *Practical considerations* - developing full scale applications and the key
    considerations that need to be made before deployment; (4) *Future Prospective
    and Unanswered Questions* - knowledge gaps and related research fields that will
    benefit human-in-the-loop computing as they evolve. We offer our opinions on the
    most promising directions of research and how various aspects of each area might
    be unified towards common goals.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 完全自动化的深度学习已成为许多任务的前沿技术，包括图像获取、分析和解释，以及提取临床有用的信息以用于计算机辅助检测、诊断、治疗规划、干预和治疗。然而，医学图像分析所带来的独特挑战表明，在任何深度学习驱动的系统中保留一个人类终端用户将是有益的。在这篇综述中，我们探讨了人类可能在深度学习驱动的诊断应用的开发和部署中发挥的作用，并重点关注能够保留人类终端用户重要输入的技术。我们认为，人机交互计算是未来研究中越来越重要的领域，因为在医学领域工作具有安全关键的性质。我们评估了我们认为对临床实践中的深度学习至关重要的四个关键领域：（1）*主动学习*，选择最佳数据进行标注以获得最佳模型性能；（2）*与模型输出的互动*
    - 使用迭代反馈引导模型达到特定预测的最优，并提供有意义的方式来解释和响应预测；（3）*实际考虑* - 开发全面的应用程序以及在部署前需要考虑的关键因素；（4）*未来展望与未解之谜*
    - 知识空白和相关研究领域，这些领域将在其发展过程中受益于人机交互计算。我们提出了对最有前景的研究方向的意见，并探讨了各个领域的不同方面如何朝着共同目标统一。
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: Medical imaging is a major pillar of clinical decision making and is an integral
    part of many patient journeys. Information extracted from medical images is clinically
    useful in many areas such as computer-aided detection, diagnosis, treatment planning,
    intervention and therapy. While medical imaging remains a vital component of a
    myriad of clinical tasks, an increasing shortage of qualified radiologists to
    interpret complex medical images suggests a clear need for reliable automated
    methods to alleviate the growing burden on health-care practitioners [[67](#bib.bib67)].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 医学影像是临床决策的主要支柱，并且是许多患者就医过程中的一个重要部分。从医学影像中提取的信息在计算机辅助检测、诊断、治疗计划、干预和治疗等多个领域具有临床价值。尽管医学影像仍然是众多临床任务的关键组成部分，但对复杂医学影像进行解读的合格放射科医生日益短缺，这表明迫切需要可靠的自动化方法来减轻医疗从业人员日益增长的负担[[67](#bib.bib67)]。
- en: In parallel, medical imaging sciences are benefiting from the development of
    novel computational techniques for the analysis of structured data like images.
    Development of algorithms for image acquisition, analysis and interpretation are
    driving innovation, particularly in the areas of registration, reconstruction,
    tracking, segmentation and modelling.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，医学影像学正在受益于结构化数据（如影像）分析新计算技术的发展。图像获取、分析和解释算法的发展正在推动创新，特别是在配准、重建、跟踪、分割和建模等领域。
- en: Medical images are inherently difficult to interpret, requiring prior expertise
    to understand. Bio-medical images can be noisy and contain many modality-specific
    artefacts, acquired under a wide variety of acquisition conditions with different
    protocols. Thus, once trained models do not transfer seamlessly from one clinical
    task or site to another because of an often yawning domain gap [[34](#bib.bib34),
    [10](#bib.bib10)]. Supervised learning methods require extensive relabelling to
    regain initial performance in different workflows.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 医学影像本质上难以解读，需要先验的专业知识来理解。生物医学影像可能会有噪声，并且包含许多特定模态的伪影，且在各种采集条件和不同协议下获取。因此，一旦训练好的模型不能从一个临床任务或地点无缝迁移到另一个任务或地点，因为通常存在显著的领域差距[[34](#bib.bib34),
    [10](#bib.bib10)]。监督学习方法需要广泛的重新标注才能在不同工作流程中恢复初始性能。
- en: The experience and prior knowledge required to work with such data means that
    there is often large inter- and intra-observer variability in annotating medical
    data. This not only raises questions about what constitutes a gold-standard ground
    truth annotation, but also results in disagreement of what that ground truth truly
    is. These issues result in a large cost associated with annotating and re-labelling
    of medical image datasets, as we require numerous expert annotators (oracles)
    to perform each annotation and to reach a consensus.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 处理此类数据所需的经验和先验知识意味着在医学数据标注中，观察者之间以及观察者内部通常会存在较大的变异。这不仅引发了关于什么构成金标准真值标注的问题，还导致了对该真值到底是什么的分歧。这些问题导致标注和重新标注医学影像数据集的成本非常高，因为我们需要大量的专家标注员（“神谕者”）来执行每次标注并达成共识。
- en: In recent years, Deep Learning (DL) has emerged as the state-of-the-art technique
    for performing many medical image analysis tasks [[85](#bib.bib85), [88](#bib.bib88),
    [79](#bib.bib79), [51](#bib.bib51), [84](#bib.bib84)]. Developments in the field
    of computer vision have shown great promise in transferring to medical image analysis,
    and several techniques have been shown to perform as accurately as human observers
    [[28](#bib.bib28), [56](#bib.bib56)]. However, uptake of DL methods within the
    clinical practice has been limited thus far, largely due to the unique challenges
    of working with complex medical data, regulatory compliance issues and trust in
    trained models.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度学习（DL）作为一种先进的技术，已在执行许多医学影像分析任务中表现出色[[85](#bib.bib85), [88](#bib.bib88),
    [79](#bib.bib79), [51](#bib.bib51), [84](#bib.bib84)]。计算机视觉领域的进展显示出在医学影像分析中转化的巨大潜力，且几种技术已被证明能达到与人类观察者相同的准确度[[28](#bib.bib28),
    [56](#bib.bib56)]。然而，到目前为止，临床实践中对DL方法的采用仍然有限，这在很大程度上是由于处理复杂医学数据的独特挑战、合规问题和对训练模型的信任。
- en: 'We identify three key challenges when developing DL enabled applications for
    medical image analysis in a clinical setting:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发用于临床设置的深度学习（DL）增强应用时，我们识别出三个关键挑战：
- en: '1.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Lack of Training Data: Supervised DL techniques traditionally rely on a large
    and even distribution of accurately annotated data points, and while more medical
    image datasets are becoming available, the time, cost and effort required to annotate
    such datasets remains significant.'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 缺乏训练数据：监督式深度学习技术传统上依赖于大量且均匀分布的准确注释数据点，虽然医学图像数据集变得越来越多，但标注这些数据集所需的时间、成本和精力仍然是巨大的。
- en: '2.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'The Final Percent: DL techniques have achieved state-of-the-art performance
    for medical image analysis tasks, but in safety-critical domains even the smallest
    of errors can cause catastrophic results downstream. Achieving clinically credible
    output may require interactive interpretation of predictions (from an oracle)
    to be useful in practice, i.e users must have the capability to correct and override
    automated predictions for them to meet any acceptance criteria required.'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最终百分比：深度学习技术在医学图像分析任务中取得了最先进的性能，但在安全关键领域，即使最小的错误也可能导致灾难性的后果。实现临床可信的输出可能需要对预测结果进行交互式解释（来自预言者），才能在实际中有用，即用户必须具备纠正和覆盖自动预测的能力，以满足任何需要的接受标准。
- en: '3.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Transparency and Interpretability: At present, most DL applications are considered
    to be a ’black-box’ where the user has limited meaningful ways of interpreting,
    understanding or correcting how a model has made its prediction. Credence is a
    detrimental feature for medical applications as information from a wide variety
    of sources must be evaluated in order to make clinical decisions. Further indication
    of how a model has reached a predicted conclusion is needed in order to foster
    trust for DL enabled systems and allow users to weigh automated predictions appropriately.'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 透明度和可解释性：目前，大多数深度学习应用被认为是“黑匣子”，用户只能以有限的方式去解释、理解或纠正模型是如何进行预测的。对于医疗应用来说，通过评估来自各种信息源的信息以做出临床决策是一个不利的特征。为了建立对深度学习系统的信任，并让用户适当权衡自动预测，我们需要更多的指示来了解模型是如何得出预测结论的。
- en: There is concerted effort in the medical image analysis research community to
    apply DL methods to various medical image analysis tasks, and these are showing
    great promise. We refer the reader to a number of reviews of DL in medical imaging
    [[30](#bib.bib30), [54](#bib.bib54), [99](#bib.bib99)]. These works primarily
    focus on the development of predictive models for a specific task and demonstrate
    state-of-the-art performance for that task.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 目前医学图像分析研究社区正在积极努力将深度学习方法应用于各种医学图像分析任务，并取得了巨大的成功。我们建议读者参阅多篇关于医学图像中深度学习的评论[[30](#bib.bib30),
    [54](#bib.bib54), [99](#bib.bib99)]。这些工作主要关注于针对特定任务开发预测模型，并展示了该任务的最新性能。
- en: This review aims to give an overview of where humans will remain involved in
    the development, deployment and practical use of DL systems for medical image
    analysis. We focus on medical image segmentation techniques to explore the role
    of human end users in DL enabled systems.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本评价旨在概述人类将在深度学习系统的开发、部署和实际应用中发挥作用的地方。我们重点关注医学图像分割技术，探讨人类最终用户在深度学习系统中的作用。
- en: Automating image interpretation tasks like image segmentation suffers from all
    of the drawbacks incurred by medical image data described above. There are many
    emerging techniques that seek to alleviate the added complexity of working with
    medical image data to perform automated segmentation of images. Segmentation seeks
    to divide an image into semantically meaningful regions (sets of pixels) in order
    to perform a number of downstream tasks, e.g. biometric measurements. Manually
    assigning a label to each pixel of an image is a laborious task and as such automated
    segmentation methods are important in practice. Advances in DL techniques such
    as Active Learning (AL) and Human-in-the-Loop computing applied to segmentation
    problems have shown progress in overcoming the key challenges outlined above and
    these are the studies this review focuses on. We categorise each study based on
    the nature of human interaction proposed and broadly divide them between which
    of the three key challenges they address.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化图像解释任务，如图像分割，遭遇了上述医疗图像数据所带来的所有缺点。许多新兴技术旨在减轻处理医疗图像数据以执行自动分割的额外复杂性。分割旨在将图像划分为语义上有意义的区域（像素集合），以执行许多后续任务，例如生物测量。手动为每个像素分配标签是一项繁重的任务，因此自动分割方法在实践中非常重要。深度学习技术的进展，如应用于分割问题的主动学习（Active
    Learning）和人机交互计算，已显示出克服上述关键挑战的进展，这些研究是本综述关注的重点。我们根据提出的人机交互的性质对每项研究进行分类，并大致将它们分为解决三个关键挑战中的哪一个。
- en: Section [2](#S2 "2 Active Learning ‣ A Survey on Active Learning and Human-in-the-Loop
    Deep Learning for Medical Image Analysis1footnote 11footnote 1") introduces Active
    Learning, a branch of Machine Learning (ML) and Human-in-the-Loop Computing that
    seeks to find the most informative samples from an unlabelled distribution to
    be annotated next. By training on the most informative subset of samples, related
    work can achieve state-of-the-art performance while reducing the costly annotation
    burden associated with annotating medical image data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 第[2](#S2 "2 Active Learning ‣ A Survey on Active Learning and Human-in-the-Loop
    Deep Learning for Medical Image Analysis1footnote 11footnote 1")节介绍了主动学习（Active
    Learning），这是机器学习（ML）和人机交互计算（Human-in-the-Loop Computing）的一个分支，旨在从未标记的分布中找到最有信息量的样本以供下次标注。通过在最有信息量的样本子集上训练，相关工作能够在减少标注医疗图像数据的高成本负担的同时，达到最先进的性能。
- en: 'Section [3](#S3 "3 The Final Percent: Interactive refinement of model outputs
    ‣ A Survey on Active Learning and Human-in-the-Loop Deep Learning for Medical
    Image Analysis1footnote 11footnote 1") evaluates techniques used to refine model
    predictions in response to user feedback, guiding models towards more accurate
    per-image predictions. We evaluate techniques that seek to improve interpretability
    of automated predictions and how models provide feedback on their own outputs
    to guide users towards better decision making.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '第[3](#S3 "3 The Final Percent: Interactive refinement of model outputs ‣ A
    Survey on Active Learning and Human-in-the-Loop Deep Learning for Medical Image
    Analysis1footnote 11footnote 1")节评估了用于根据用户反馈优化模型预测的技术，指导模型朝着更准确的每图像预测方向发展。我们评估了旨在提高自动预测可解释性的技术，以及模型如何对自身输出提供反馈，从而引导用户做出更好的决策。'
- en: Section [4](#S4 "4 Practical Considerations ‣ A Survey on Active Learning and
    Human-in-the-Loop Deep Learning for Medical Image Analysis1footnote 11footnote
    1") evaluates the key practical considerations of developing and deploying Human-in-the-Loop
    DL enabled systems in practice and outlines the work being done in these areas
    that addresses the three key challenges identified above. These areas are human
    focused and assess how human end users might interact with these systems.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 第[4](#S4 "4 Practical Considerations ‣ A Survey on Active Learning and Human-in-the-Loop
    Deep Learning for Medical Image Analysis1footnote 11footnote 1")节评估了在实践中开发和部署人机交互深度学习（Human-in-the-Loop
    DL）系统的关键实际考虑因素，并概述了这些领域的工作，解决了上述三个关键挑战。这些领域以人为中心，评估了人类最终用户如何与这些系统进行交互。
- en: In Section [5](#S5 "5 Future Prospective and Unanswered Questions ‣ A Survey
    on Active Learning and Human-in-the-Loop Deep Learning for Medical Image Analysis1footnote
    11footnote 1") we discuss related areas of ML and DL research that are having
    an impact on AL and Human-in-the-Loop Computing and are beginning to influence
    the three key challenges outlined. We offer our opinions on the future directions
    of Human-in-the-Loop DL research and how many of the techniques evaluated might
    be combined to work towards common goals.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 [5](#S5 "5 未来展望和未解答的问题 ‣ 关于主动学习和人机协作深度学习在医学图像分析中的调查1脚注 11脚注 1") 节中，我们讨论了对主动学习（AL）和人机协作计算产生影响的机器学习（ML）和深度学习（DL）研究的相关领域，并开始影响所概述的三大挑战。我们对人机协作深度学习研究的未来方向提出了我们的观点，以及如何将评估的许多技术结合起来以朝着共同目标努力。
- en: 2 Active Learning
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 主动学习
- en: '![Refer to caption](img/ae50c499c9ed85e58669d98cd781f736.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ae50c499c9ed85e58669d98cd781f736.png)'
- en: 'Fig. 1: Overview of Active Learning frameworks.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：主动学习框架概述。
- en: In this section we assume a scenario in which a large pool of un-annotated data
    $U$ is available to us, and that we have an oracle (or group of oracles) from
    which we can request annotations for every un-annotated data point $x_{U}$ to
    add to an annotated set $L$. We wish to train some model $f(x|L^{*})$ where $L^{*}\subseteq
    L$ and consider methods that rely on annotated data to do so. A brute-force solution
    to this problem would be to ask the oracle(s) to annotate every $x_{U}$ such that
    $L^{*}=L$, but this is rarely a practical or cost-effective solution due to the
    unique challenges associated with annotating biomedical image data. It is theorised
    that there is some $L^{*}$ that achieves equivalent performance to $L$, i.e. $f(x|L^{*})\approx
    f(x|L)$. A model trained on some optimal subset $L^{*}$ of a dataset might achieve
    equivalent performance to a model trained on the entire, annotated dataset. Active
    Learning (AL) is the branch of machine learning that seeks to find this optimal
    subset $L^{*}$ given a current model $f^{\prime}(x|L^{\prime})$, where $L^{\prime}$
    is an intermediate annotated dataset, and an un-annotated dataset $U$. AL methods
    aim to iteratively seek the most informative data-points $x^{*}_{i}$ for training
    a model, under the assumption that both the model and the un-annotated dataset
    will evolve over time, rather than selecting a fixed subset once to be used for
    training. In a wider context and before the advent of DL, [[75](#bib.bib75)] reviewed
    this field as a state-of-the-art ML methodology.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们假设存在一个大规模的未标注数据池 $U$，并且我们有一个神谕（或一组神谕），我们可以请求对每一个未标注的数据点 $x_{U}$ 进行标注，以便将其添加到标注集
    $L$ 中。我们希望训练一个模型 $f(x|L^{*})$，其中 $L^{*}\subseteq L$，并考虑依赖标注数据的方法。解决这个问题的一个粗暴方法是要求神谕对每个
    $x_{U}$ 进行标注，使得 $L^{*}=L$，但由于标注生物医学图像数据的独特挑战，这种方法很少是实际可行或具有成本效益的。理论上存在一个 $L^{*}$
    能达到与 $L$ 相当的性能，即 $f(x|L^{*})\approx f(x|L)$。一个在数据集的某个最优子集 $L^{*}$ 上训练的模型可能会达到与在整个标注数据集上训练的模型相当的性能。主动学习（AL）是机器学习的一个分支，旨在找到给定当前模型
    $f^{\prime}(x|L^{\prime})$（其中 $L^{\prime}$ 是一个中间标注数据集）和一个未标注数据集 $U$ 的最优子集 $L^{*}$。AL
    方法旨在迭代地寻找最有信息的数据点 $x^{*}_{i}$ 来训练模型，假设模型和未标注数据集都会随着时间的推移而演变，而不是一次性选择一个固定的子集进行训练。在更广泛的背景下，在深度学习（DL）出现之前，[[75](#bib.bib75)]
    回顾了这一领域作为最先进的机器学习方法。
- en: A typical AL framework, as outlined in Figure [1](#S2.F1 "Fig. 1 ‣ 2 Active
    Learning ‣ A Survey on Active Learning and Human-in-the-Loop Deep Learning for
    Medical Image Analysis1footnote 11footnote 1"), consists of a method to evaluate
    the informativeness of each un-annotated data point $x_{U}$ given $f^{\prime}(x_{U}|L^{\prime})$,
    tied heavily to the choice of query type, after which all chosen data-points are
    required to be annotated. Once new annotations have been acquired, the AL framework
    must use the new data to improve the model. This is normally done by either retraining
    the entire model using all available annotated data $L^{\prime}$, or by fine-tuning
    the network using the most recently annotated data-points $x^{*}_{i}$. Using this
    approach, state-of-the-art performance can be achieved using fewer annotations
    for several bio-medical image analysis tasks, as shown in the methods discussed
    in this section, thus widening the annotation bottleneck and reducing the costs
    associated with developing DL enabled systems from un-annotated data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的主动学习（AL）框架，如图 [1](#S2.F1 "Fig. 1 ‣ 2 Active Learning ‣ A Survey on Active
    Learning and Human-in-the-Loop Deep Learning for Medical Image Analysis1footnote
    11footnote 1") 所示，包括一种方法来评估每个未标注数据点 $x_{U}$ 的信息量，给定 $f^{\prime}(x_{U}|L^{\prime})$，这与查询类型的选择密切相关，之后所有选择的数据点都需要进行标注。一旦获得了新的标注，AL
    框架必须利用这些新数据来改进模型。通常，这通过使用所有可用的标注数据 $L^{\prime}$ 重新训练整个模型，或者通过使用最新标注的数据点 $x^{*}_{i}$
    来微调网络来完成。采用这种方法，可以在多个生物医学图像分析任务中使用更少的标注实现最先进的性能，如本节讨论的方法所示，从而扩大标注瓶颈，并降低从未标注数据中开发深度学习（DL）系统的成本。
- en: 2.1 Query Types
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 查询类型
- en: In every AL framework the first choice to be made is what type of query we wish
    to make using a model and un-annotated dataset. There are currently three main
    choices available and each lends itself to a particular scenario dependant on
    what type of un-annotated data we have access to, and what question we wish to
    ask the oracle(s).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个 AL 框架中，第一个需要做出的选择是我们希望使用模型和未标注数据集进行何种类型的查询。目前有三种主要选择，每种选择适用于特定的场景，这取决于我们可以访问的未标注数据类型，以及我们希望向oracle提问的问题。
- en: 'Stream-based Selective Sampling assumes a continuous stream of incoming un-annotated
    data-points $x_{U}$ ([[5](#bib.bib5), [17](#bib.bib17)]). The current model and
    an informativeness measure $I(x_{U})$ are used to decide, for each incoming data-point,
    whether or not to ask the oracle(s) for an annotation ([[19](#bib.bib19)]). This
    query type is usually computationally inexpensive but offers limited performance
    benefits due to the isolated nature of each decision: the wider context of the
    underlying distribution is not considered, thus balancing exploration and exploitation
    of the distribution is less well captured than in other query types. Another disadvantage
    of this query type is calibrating the threshold to use for the chosen informativeness
    measure such that we do not request annotations for every incoming data-point,
    and that we do not reject annotations for too many data-points resulting in valuable
    information being lost.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 基于流的选择性采样假设有一个持续的未标注数据点流 $x_{U}$ ([[5](#bib.bib5), [17](#bib.bib17)])。使用当前模型和信息量度量
    $I(x_{U})$ 来决定是否对每个到来的数据点向oracle请求标注 ([[19](#bib.bib19)])。这种查询类型通常计算开销较小，但由于每个决策的孤立性，提供的性能收益有限：没有考虑到潜在分布的更广泛背景，因此分布的探索与利用平衡的效果不如其他查询类型。另一缺点是需要校准所选择的信息量度量的阈值，以确保我们不会对每个到来的数据点请求标注，也不会对过多的数据点拒绝标注，导致有价值的信息丢失。
- en: Membership Query Synthesis assumes that rather than drawing from a real-world
    distribution of data-points, we instead generate a data-point $x^{*}_{G}$ that
    needs to be annotated ([[3](#bib.bib3)]). The generated data-point is what the
    current model ’believes’ will be most informative to itself. This data-point is
    then annotated by the oracle(s) ([[4](#bib.bib4)]), this can be very efficient
    in finite domains. This approach may suffer from the same drawbacks as Stream-based
    methods as a model may have no knowledge of unseen areas of the distribution,
    and thus be unable to request annotations of those areas. Issues can arise where
    queries can request annotations for data-points that make no sense to a human
    oracle ([[45](#bib.bib45)]), and are not representative of the actual distribution
    that is being modelled, stream based and pool based sampling methods were proposed
    to overcome these issues ([[75](#bib.bib75)]). Nevertheless, recent advances of
    Generative Adversarial Networks (GANs) have shown great promise in generating
    data-points that mimic real-world distributions for many different types of data,
    including biomedical images, that may go someway to addressing the key issue with
    using query synthesis for complex distributions, which we discuss in Section [2.2.3](#S2.SS2.SSS3
    "2.2.3 Generative Adversarial Networks for Informativeness ‣ 2.2 Evaluating Informativeness
    ‣ 2 Active Learning ‣ A Survey on Active Learning and Human-in-the-Loop Deep Learning
    for Medical Image Analysis1footnote 11footnote 1"). This query type can be advantageous
    in scenarios where the distribution to generate is fully understood, or domains
    in which annotations are acquired autonomously instead of from humans ([[38](#bib.bib38),
    [37](#bib.bib37)]).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 会员查询合成假设，我们不是从实际的数据分布中提取数据点，而是生成一个需要被注释的数据点 $x^{*}_{G}$（[[3](#bib.bib3)]）。生成的数据点是当前模型认为对其自身最有信息量的数据点。然后，这个数据点由神谕者（[[4](#bib.bib4)]）进行注释，这在有限领域中可能非常高效。这种方法可能会受到与基于流的方法相同的缺点的影响，因为模型可能对数据分布的未见区域一无所知，从而无法请求这些区域的注释。问题可能出现于查询可能请求对对人类神谕者没有意义的数据点的注释（[[45](#bib.bib45)]），而这些数据点并不代表实际建模的数据分布，提出了基于流和基于池的采样方法以克服这些问题（[[75](#bib.bib75)]）。尽管如此，生成对抗网络（GANs）的最新进展在生成模仿实际数据分布的数据点方面显示出了极大的潜力，包括生物医学图像，这可能在一定程度上解决使用查询合成处理复杂分布的关键问题，这将在第[2.2.3](#S2.SS2.SSS3
    "2.2.3 生成对抗网络用于信息量 ‣ 2.2 评估信息量 ‣ 2 主动学习 ‣ 关于主动学习和人机协作深度学习在医学图像分析中的调查1footnote
    11footnote 1")节中讨论。这种查询类型在对分布的生成完全理解的场景中，或者在注释是自主获取而非来自人类的领域中可能具有优势（[[38](#bib.bib38),
    [37](#bib.bib37)]）。
- en: Pool-based Sampling assumes a large un-annotated real-world dataset $U$ to draw
    samples from and seeks to select a batch of N samples ${x^{*}_{0},...,x^{*}_{N}}$
    from the distribution to request labels for ([[47](#bib.bib47)]. Pool-based methods
    usually use the current model to make a prediction on each un-annotated data point
    to obtain a ranked measure of informativeness $I(x_{U}|f^{\prime}(x_{U}|L^{\prime}))$
    for every data-point in the un-annotated set, and select the top N samples using
    this metric to be annotated by the oracle(s). Pool based sampling has been applied
    to several real world tasks, prior to the advent of deep learning ([[47](#bib.bib47),
    [57](#bib.bib57), [76](#bib.bib76), [104](#bib.bib104), [29](#bib.bib29)]. These
    methods can be computationally expensive as every iteration requires a metric
    evaluation for every data-point in the distribution. However, these methods have
    shown to be the most promising when combined with DL methods, which inherently
    rely on a batch-based training scheme. Pool based sampling is used in the majority
    of methods discussed in the rest of this section unless stated otherwise. While
    pool-based methods hold advantages over other methods in terms of finding the
    most informative annotations to acquire, scenarios in which stream based or synthesis
    based queries are advantageous are also common, such as when memory or processing
    power is limited for example in mobile or embedded devices ([[75](#bib.bib75)]).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 基于池的采样假设有一个大型未标注的现实世界数据集 $U$，从中抽取样本，并试图从分布中选择一批 N 个样本 ${x^{*}_{0},...,x^{*}_{N}}$
    请求标签（[[47](#bib.bib47)]）。基于池的方法通常使用当前模型对每个未标注的数据点进行预测，以获得每个数据点在未标注集合中的信息量排名度量
    $I(x_{U}|f^{\prime}(x_{U}|L^{\prime}))$，并使用该度量选择前 N 个样本，由 oracle(s) 进行标注。基于池的采样已被应用于多个现实世界任务，在深度学习出现之前（[[47](#bib.bib47),
    [57](#bib.bib57), [76](#bib.bib76), [104](#bib.bib104), [29](#bib.bib29)]）。这些方法可能计算成本较高，因为每次迭代都需要对分布中的每个数据点进行度量评估。然而，当与深度学习方法结合使用时，这些方法显示出了最有前景的效果，因为深度学习方法本质上依赖于基于批次的训练方案。除非另有说明，基于池的采样在本节其余部分讨论的大多数方法中都被使用。尽管基于池的方法在寻找最具信息量的标注方面相较其他方法具有优势，但在一些情况下，如内存或处理能力有限的移动或嵌入式设备中，流式或合成查询的方法也很常见（[[75](#bib.bib75)]）。
- en: 2.2 Evaluating Informativeness
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 评估信息量
- en: In developing an AL framework, once a query type has been selected, the next
    question to ask is how to measure the informativeness $I(x_{U})$ of each of the
    data-points? Many varying approaches have been taken to quantifying the informativeness
    of a sample given a model and an underlying distribution. Here we sort these metrics
    by the level of human interpretability they offer.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发主动学习框架时，一旦选择了查询类型，下一个问题是如何测量每个数据点的信息量 $I(x_{U})$？对于给定模型和底层分布，已经采取了许多不同的方法来量化样本的信息量。在这里，我们按其提供的人类可解释性水平对这些度量标准进行排序。
- en: Traditionally, AL methods employ hand-designed heuristics to quantify what we
    as humans believe makes something informative. A variety of model specific metrics
    seek to quantify what the effect of using a sample for training would have on
    the model, e.g., the biggest change in model parameters. However, these methods
    are less prevalent than human designed heuristics due to the computational challenge
    of applying these to DL models with a large number of parameters. Finally some
    methods are emerging that are completely agnostic to human interpretability of
    informativeness and instead seek to learn the best selection policy from available
    data and previous iterations, as discussed in detail in Section [2.2.4](#S2.SS2.SSS4
    "2.2.4 Learning Active Learning ‣ 2.2 Evaluating Informativeness ‣ 2 Active Learning
    ‣ A Survey on Active Learning and Human-in-the-Loop Deep Learning for Medical
    Image Analysis1footnote 11footnote 1").
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，主动学习（AL）方法使用手工设计的启发式规则来量化我们作为人类认为使某样东西具有信息量的因素。一些特定于模型的度量方法试图量化使用样本进行训练对模型的影响，例如，模型参数的最大变化。然而，由于将这些方法应用于具有大量参数的深度学习（DL）模型的计算挑战，这些方法的使用不如人工设计的启发式规则普遍。最后，一些方法正在出现，这些方法完全与信息量的人类可解释性无关，而是试图从现有数据和以前的迭代中学习最佳选择策略，详细讨论见第[2.2.4](#S2.SS2.SSS4
    "2.2.4 Learning Active Learning ‣ 2.2 Evaluating Informativeness ‣ 2 Active Learning
    ‣ A Survey on Active Learning and Human-in-the-Loop Deep Learning for Medical
    Image Analysis1footnote 11footnote 1")节。
- en: 2.2.1 Uncertainty
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1 不确定性
- en: The main family of informativeness measures falls into calculating uncertainty.
    It is argued that the more uncertain a prediction is, the more information we
    can gain by including the ground truth for that sample in the training set.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 信息量度量的主要家族涉及计算不确定性。有观点认为，预测的不确定性越大，通过将该样本的真实情况纳入训练集，我们可以获得的信息就越多。
- en: 'There are several ways of calculating uncertainty from different ML/DL models.
    When considering DL for segmentation the most simple measure is the sum of lowest
    class probability for each pixel in a given image segmentation. It is argued that
    more certain predictions will have high pixel-wise class probabilities, so the
    lower the sum of the minimum class probability over each pixel in an image, the
    more certain a prediction is considered to be:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 计算不同机器学习/深度学习模型的不确定性有多种方式。在考虑深度学习进行分割时，最简单的度量方法是对给定图像分割中每个像素的最低类别概率进行求和。有人认为，更确定的预测会具有较高的像素级类别概率，因此图像中每个像素最低类别概率的总和越低，预测越被认为是确定的：
- en: '|  | $x^{*}_{LC}=\operatorname*{argmax}_{x}1-P_{\theta}(\hat{y}&#124;x)$ |  |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|  | $x^{*}_{LC}=\operatorname*{argmax}_{x}1-P_{\theta}(\hat{y}&#124;x)$ |  |'
- en: 'where $\hat{y}=\operatorname*{argmax}_{y}P_{\theta}(y|x)$. This is a fairly
    intuitive way of thinking about uncertainty and offers a means to rank uncertainty
    of samples within a distribution. We refer to the method above as least confident
    sampling where the samples with the highest uncertainty are selected for labelling 
    [[75](#bib.bib75)]. A drawback of least confident sampling is that it only considers
    information about the most probable label, and discards the information about
    the remaining label distribution. Two alternative methods have been proposed that
    alleviate this concern. The first, called margin sampling [[75](#bib.bib75)],
    can be used in a multi-class setting and considers the first and second most probable
    labels under the model and calculates the difference between them:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\hat{y}=\operatorname*{argmax}_{y}P_{\theta}(y|x)$。这是一种相当直观的不确定性思考方式，并提供了一种在分布中对样本不确定性进行排序的方法。我们将上述方法称为最不自信采样，其中选择不确定性最高的样本进行标注
    [[75](#bib.bib75)]。最不自信采样的一个缺点是它仅考虑最可能标签的信息，而忽略了其他标签分布的信息。已有两种替代方法被提出以缓解这一问题。第一种称为边际采样
    [[75](#bib.bib75)]，可用于多类设置，考虑模型下最可能的前两种标签，并计算它们之间的差异：
- en: '|  | $x^{*}_{M}=\operatorname*{argmin}_{x}P_{\theta}(\hat{y}_{1}&#124;x)-P_{\theta}(\hat{y}_{2}&#124;x)$
    |  |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | $x^{*}_{M}=\operatorname*{argmin}_{x}P_{\theta}(\hat{y}_{1}&#124;x)-P_{\theta}(\hat{y}_{2}&#124;x)$
    |  |'
- en: 'where $\hat{y}_{1}$ and $\hat{y}_{2}$ are the first and second most probable
    labels under the current model, respectively. The intuition here is that the larger
    the margin is between the two most probable labels, the more confident the model
    is in assigning that label. The second, more popular approach is to use entropy
    ([[78](#bib.bib78)]) as an uncertainty measure:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\hat{y}_{1}$ 和 $\hat{y}_{2}$ 分别是当前模型下最可能的前两种标签。这里的直觉是，两种最可能标签之间的边际越大，模型对该标签的分配就越自信。第二种，更受欢迎的方法是使用熵
    ([[78](#bib.bib78)]) 作为不确定性度量：
- en: '|  | $x^{*}_{E}=\operatorname*{argmax}_{x}-\sum_{i}P(y_{i}&#124;x)logP(y_{i}&#124;x)$
    |  |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | $x^{*}_{E}=\operatorname*{argmax}_{x}-\sum_{i}P(y_{i}&#124;x)logP(y_{i}&#124;x)$
    |  |'
- en: where $y_{i}$ ranges across all possible annotations. Entropy is used to measure
    the amount of information required to encode a distribution and as such, is often
    thought of as a measure of uncertainty in machine learning. For binary classification,
    all three methods reduce to querying for the data-point with a class posterior
    closest to 0.5\. The ability of entropy to generalise easily to probabilistic
    multi-class annotations, as well as models for more complex structured data-points
    has made it the most popular choice for uncertainty based query strategies [[76](#bib.bib76)].
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $y_{i}$ 涵盖了所有可能的标注。熵用于衡量编码分布所需的信息量，因此在机器学习中，熵常被视为不确定性的度量。对于二分类问题，所有三种方法都归结为查询与0.5最接近的类后验的数据点。熵能够轻松推广到概率多类标注及更复杂结构数据点的模型，使其成为基于不确定性的查询策略中最受欢迎的选择
    [[76](#bib.bib76)]。
- en: Using one of the above measures, un-annotated samples are ranked and the most
    ’uncertain’ cases are chosen for the next round of annotation. There have been
    many recent uses of uncertainty based sampling in AL methods in the DL field and
    these are discussed next.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述一种度量方法，对未标注样本进行排名，并选择最“无确定性”的案例进行下一轮标注。在深度学习领域，最近有许多基于不确定性的采样方法应用于主动学习，这些方法将在接下来的部分中讨论。
- en: '[[94](#bib.bib94)] propose the Cost-Effective Active Learning (CEAL) method
    for deep image classification. The CEAL methods is initialised with a set of unlabelled
    sample $U$, initially labelled samples $L$, a choice of pool size $K$, a high
    confidence sample selection threshold $\omega$, a threshold decay rate $dr$, a
    maximum iteration number $T$ and a fine-tuning interval $t$. After initialisation,
    CNN weights $W$ are initialised with $L$ and the model is used to make predictions
    on each data-point in $U$. CEAL explores using each of the three uncertainty methods
    described above to obtain $K$ uncertain data-points to be manually annotated and
    added to $D_{L}$. So far the CEAL method follows very closely the approach outlined
    in traditional active learning methods as described above, but they introduce
    an additional training step where the most confident samples (whose entropy is
    less than $\omega$) from $U$ are added to $D_{H}$. $D_{L}$ and $D_{H}$ are then
    used to fine-tune $W$ for $t$ iterations. CEAL then updates $\omega$ before the
    pseudo-labels from $D_{H}$ are discarded and each data-point is added back to
    $U$, while $D_{L}$ is added to $L$. This process repeats for $T$ iterations. The
    authors describe this approach of simultaneously learning from manual labels of
    the most uncertain annotations and predicted labels of the least uncertain annotations
    as complementary sampling. The CEAL method showed that state-of-the-art performance
    can be achieved using less than 60% of available data for two non-medical datasets
    (CACD and Caltech-256) for face recognition and object categorisation.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[[94](#bib.bib94)] 提出了用于深度图像分类的成本效益主动学习（CEAL）方法。CEAL方法初始化时需要一组未标记样本 $U$、初始标记样本
    $L$、池大小 $K$、高置信度样本选择阈值 $\omega$、阈值衰减率 $dr$、最大迭代次数 $T$ 和微调间隔 $t$。初始化后，CNN权重 $W$
    使用 $L$ 进行初始化，并且模型用于对 $U$ 中的每个数据点进行预测。CEAL探索使用上述三种不确定性方法中的每一种，以获得 $K$ 个不确定数据点进行手动标注并添加到
    $D_{L}$。到目前为止，CEAL方法非常接近于传统主动学习方法，但他们引入了一个额外的训练步骤，将 $U$ 中最有信心的样本（熵小于 $\omega$）添加到
    $D_{H}$。然后，$D_{L}$ 和 $D_{H}$ 被用来对 $W$ 进行 $t$ 次迭代的微调。CEAL 然后更新 $\omega$，在丢弃 $D_{H}$
    的伪标签之前，每个数据点被重新添加到 $U$ 中，而 $D_{L}$ 则被添加到 $L$。这个过程重复进行 $T$ 次迭代。作者将从最不确定注释的手动标签和最确定注释的预测标签中同时学习的这种方法描述为补充采样。CEAL方法显示，使用不到60%的可用数据可以在两个非医疗数据集（CACD和Caltech-256）上实现最先进的性能，用于面部识别和物体分类。'
- en: '[[96](#bib.bib96)] propose an active learning method that uses uncertainty
    sampling to support quality control of nucleus segmentation in pathology images.
    Their work compares the performance improvements achieved through active learning
    for three different families of algorithms: Support Vector Machines (SVM), Random
    Forest (RF) and Convolutional Neural Networks (CNN). They show that CNNs achieve
    the greatest accuracy, requiring significantly fewer iterations to achieve equivalent
    accuracy to the SVMs and RFs.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[[96](#bib.bib96)] 提出了一个利用不确定性采样来支持病理图像核分割质量控制的主动学习方法。他们的工作比较了通过主动学习在三种不同算法家族（支持向量机（SVM）、随机森林（RF）和卷积神经网络（CNN））中获得的性能提升。他们展示了CNN实现了最高的准确性，所需的迭代次数显著少于SVM和RF。'
- en: Another common method of estimating informativeness is to measure the agreement
    between multiple models performing the same task. It is argued that more disagreement
    found between predictions on the same data point implies a higher level of uncertainty.
    These methods are referred to as Query by consensus and are generally applied
    when Ensembling is used to improve performance - i.e, training multiple models
    to perform the same task under slightly different parameters/settings [[75](#bib.bib75)].
    Ensembling methods have shown to measure informativeness well, but at the cost
    of computational resources - multiple models need to be trained and maintained,
    and each of these needs to be updated in the presence of newly selected training
    samples.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常见的信息量估计方法是测量多个模型在执行相同任务时的协议。有人认为，在相同数据点上预测之间的分歧越大，表示不确定性水平越高。这些方法被称为共识查询，通常在使用集成方法来提高性能时应用——即，训练多个模型在稍微不同的参数/设置下执行相同任务
    [[75](#bib.bib75)]。集成方法已经被证明可以很好地衡量信息量，但代价是计算资源——需要训练和维护多个模型，每个模型都需要在选择新的训练样本时进行更新。
- en: Nevertheless, [[9](#bib.bib9)] demonstrate the power of ensembles for active
    learning and compare to alternatives to ensembling. They specifically compare
    the performance of acquisition functions and uncertainty estimation methods for
    active learning with CNNs for image classification tasks and show that ensemble
    based uncertainties outperform other methods of uncertainty estimation such as
    ’MC Dropout’. They find that the difference in active learning performance can
    be explained by a combination of decreased model capacity and lower diversity
    of MC dropout ensembles. A good performance is demonstrated on a diabetic retinopathy
    diagnosis task.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，[[9](#bib.bib9)] 展示了集成方法在主动学习中的强大力量，并与其他集成方法进行了比较。他们特别比较了获取函数和不确定性估计方法在使用
    CNNs 进行图像分类任务中的表现，并展示了基于集成的不确定性在性能上优于其他不确定性估计方法，如 'MC Dropout'。他们发现，主动学习性能的差异可以通过模型容量降低和
    MC dropout 集成的多样性降低来解释。在糖尿病视网膜病变诊断任务中表现良好。
- en: '[[41](#bib.bib41)] propose an active learning approach that exploits geometric
    smoothness priors in the image space to aid the segmentation process. They use
    traditional uncertainty measures to estimate which pixels should be annotated
    next, and introduce novel criteria for uncertainty in multi-class settings. They
    exploit geometric uncertainty by estimating the entropy of the probability of
    supervoxels belonging to a class given the predictions of its neighbours and combine
    these to encourage selection of uncertain regions in areas of non-smooth transition
    between classes. They demonstrate state-of-the-art performance on mitochondria
    segmentation from EM images and on an MRI tumour segmentation task for both binary
    and multi-class segmentations. They suggest that exploiting geometric properties
    of images is useful to answer the questions of where to annotate next and by reducing
    3D annotations to 2D annotations provide a possible answer to how to annotate
    the data, and that addressing both jointly can bring additional benefits to the
    annotation method, however they acknowledge that it would impossible to design
    bespoke selection strategies this way for every new task at hand.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[[41](#bib.bib41)] 提出了一种主动学习方法，该方法利用图像空间中的几何平滑先验来辅助分割过程。他们使用传统的不确定性测量来估计应优先标注的像素，并在多类设置中引入了新的不确定性标准。他们通过估计超像素属于某个类别的概率熵，结合邻居的预测来利用几何不确定性，并鼓励选择类别之间过渡不平滑区域的不确定区域。他们在从
    EM 图像中分割线粒体和在 MRI 肿瘤分割任务中（无论是二类还是多类分割）展示了最先进的性能。他们建议，利用图像的几何属性有助于回答下一个标注位置的问题，并通过将
    3D 标注简化为 2D 标注，为如何标注数据提供了可能的答案，同时，解决这两者的结合可以给标注方法带来额外的好处，但他们也承认，为每个新任务设计量身定制的选择策略将是不可行的。'
- en: '[[25](#bib.bib25)] introduce the use of Bayesian CNNs for Active Learning with
    ’Bayesian Active Learning by Disagreement’ or BALD, and show that the use of Bayesian
    CNNs outperform deterministic CNNs in the context of Active Learning, and exploit
    this through the use of a new acquisition function that chooses data-points expected
    to maximise the information gained about the model parameters i.e maximise the
    mutual information between predictions and model posterior. This approach uses
    a Bayesian CNN (induced using Dropout during inference [[24](#bib.bib24)]), to
    produce a single prediction using all parameters of the network for each unlabelled
    data-point, and a set of stochastic predictions for each unlabelled data-point,
    generated with dropout enabled. The BALD acquisition function is then calculated
    as the difference between the entropy of the average prediction and average entropy
    of stochastic predictions. Intuitively this function selects data-points for which
    the model is uncertain on average, but there exist model parameters that produce
    disagreeing predicted annotations with high certainty. They demonstrate their
    approach for skin cancer diagnosis from skin lesion images to show significant
    performance improvements over uniform sampling using the BALD method for sample
    selection. While this method has been shown to be particularly effective for AL,
    when querying batches of data-points, it often results in many very similar, redundant
    data-points being acquired when used in a greedy fashion, as such BatchBALD was
    introduced to alleviate this problem [[39](#bib.bib39)]. The BatchBALD approach
    instead no longer calculates the mutual information between a single sample predictions
    and model posterior, but instead calculates the mutual information between a batch
    of samples and the model posterior to jointly score the batch of samples, enabling
    BatchBALD to more accurately evaluate the joint mutual information and select
    batches of samples for annotation that result in less redundant data-points being
    selected together in an acquired batch. This extension is an example of the motivation
    behind Section [2.2.2](#S2.SS2.SSS2 "2.2.2 Representativeness ‣ 2.2 Evaluating
    Informativeness ‣ 2 Active Learning ‣ A Survey on Active Learning and Human-in-the-Loop
    Deep Learning for Medical Image Analysis1footnote 11footnote 1") in which we discuss
    methods that move beyond pure uncertainty based methods and begin to measure diversity
    among selected samples to reduce redundant annotation.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[[25](#bib.bib25)] 介绍了使用贝叶斯卷积神经网络（Bayesian CNNs）进行主动学习的方法，称为“基于不一致性的贝叶斯主动学习”（’Bayesian
    Active Learning by Disagreement’，简称BALD），并展示了在主动学习的背景下，贝叶斯卷积神经网络的表现优于确定性卷积神经网络，并通过使用一种新的获取函数来实现这一点，该函数选择期望最大化模型参数信息的点，即最大化预测与模型后验之间的互信息。这种方法使用一个贝叶斯卷积神经网络（在推理过程中使用Dropout来诱导[[24](#bib.bib24)]），对于每个未标记的数据点，使用网络的所有参数生成单一预测，并为每个未标记的数据点生成一组随机预测，这些预测是在启用Dropout的情况下生成的。然后，BALD获取函数计算为平均预测的熵和随机预测的平均熵之间的差异。从直观上看，这个函数选择那些模型在平均上不确定的数据点，但存在一些模型参数能够以高确定性产生不一致的预测注释。他们展示了这种方法在皮肤病变图像的皮肤癌诊断中的应用，显示出相较于均匀采样，使用BALD方法进行样本选择显著提高了性能。尽管这种方法在主动学习中表现出特别有效，当查询数据点的批次时，它常常会导致许多非常相似的冗余数据点被获取，因此BatchBALD被引入以缓解这个问题[[39](#bib.bib39)]。BatchBALD方法不再计算单个样本预测与模型后验之间的互信息，而是计算一批样本与模型后验之间的互信息，以共同评分样本批次，使得BatchBALD能够更准确地评估联合互信息，并选择导致较少冗余数据点一起被选择的批次。这个扩展是第[2.2.2节](#S2.SS2.SSS2
    "2.2.2 Representativeness ‣ 2.2 Evaluating Informativeness ‣ 2 Active Learning
    ‣ A Survey on Active Learning and Human-in-the-Loop Deep Learning for Medical
    Image Analysis1footnote 11footnote 1")动机的一个例子，其中我们讨论了超越纯不确定性方法并开始测量选定样本之间的多样性以减少冗余标注的方法。'
- en: 2.2.2 Representativeness
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2 代表性
- en: Many AL frameworks extend selection strategies to include some measure of representativeness
    in addition to an uncertainty measure. The intuition behind including a representativeness
    measure is that methods only concerned with uncertainty have the potential to
    focus only on small regions of the distribution, and that training on samples
    from the same area of the distribution will introduce redundancy to the selection
    strategy, or may skew the model towards a particular area of the distribution.
    The addition of a representativeness measure seeks to encourage selection strategies
    to sample from different areas of the distribution, and to increase the diversity
    of samples, thus improving AL performance. A sample with a high representativeness
    covers the information for many images in the same area of the distribution, so
    there is less need to include many samples covered by a representative image.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 许多主动学习（AL）框架扩展了选择策略，除了不确定性度量之外，还包括一些代表性度量。包括代表性度量的直觉在于，单纯关注不确定性的方法可能只关注分布的局部区域，且从分布的相同区域进行训练会导致选择策略的冗余，或者使模型偏向分布的某一特定区域。增加代表性度量旨在鼓励选择策略从分布的不同区域采样，并增加样本的多样性，从而提高主动学习（AL）性能。具有高代表性的样本涵盖了分布中许多图像的信息，因此无需包括许多由代表性图像覆盖的样本。
- en: To this end, [[100](#bib.bib100)] present Suggestive Annotation, a deep active
    learning framework for medical image segmentation, which uses an alternative formulation
    of uncertainty sampling combined with a form of representativeness density weighting.
    Their method consists of training multiple models that each exclude a portion
    of the training data, which are used to calculate an ensemble based uncertainty
    measure. They formulate choosing the most representative example as a generalised
    version of the maximum set-cover problem (NP Hard) and offer a greedy approach
    to selecting the most representative images using feature vectors from their models.
    They demonstrate state-of-the-art performance using 50% of the available data
    on the MICCAI Gland segmentation challenge and a lymph node segmentation task.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，[[100](#bib.bib100)] 提出了建议性注释（Suggestive Annotation），这是一个用于医学图像分割的深度主动学习框架，它使用了不确定性采样的替代公式，并结合了代表性密度加权形式。他们的方法包括训练多个模型，每个模型排除一部分训练数据，用于计算基于集成的不确定性度量。他们将选择最具代表性的示例形式化为最大集合覆盖问题（NP难问题）的广义版本，并提供了一种贪心的方法来使用其模型中的特征向量选择最具代表性的图像。他们在MICCAI腺体分割挑战和淋巴结分割任务中，使用了50%的可用数据，展示了最先进的性能。
- en: '[[80](#bib.bib80)] propose MedAL, an active learning framework for medical
    image segmentation. They propose a sampling method that combines uncertainty,
    and distance between feature descriptors, to extract the most informative samples
    from an unlabelled data-set. Once an initial model has been trained, the MedAL
    method selects data-points to be labelled by first filtering out unlabelled data-points
    with a predictive entropy below a threshold. From this set the CNN being trained
    is used to generate feature descriptors for each data-point by taking the output
    of intermediate layers of the CNN, these feature descriptors are then compared
    amongst each other using a variety of distance functions (e.g ’Euclidian’, ’Russellrao’,
    ’Cosine’) in order to find the feature descriptors which are most distant from
    each other. The data-point with the highest average distance to all other unlabelled
    data-points (above the entropy threshold) is selected for annotation. In this
    way, the MedAL acquisition function finds the set of data-points that are both
    informative to the model, and incur the least redundancy between them by sampling
    from areas of the input distribution most distant from each other. MedAL method
    initialises the model in a novel way by leveraging existing computer vision image
    descriptors to find the images that are most dissimilar to each other and thus
    cover a larger area of the image distribution to use as the initial training set
    after annotation. They show good results on three different medical image analysis
    tasks, achieving the baseline accuracy with less training data than random or
    pure uncertainty based methods.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[[80](#bib.bib80)] 提出了 MedAL，这是一种用于医学图像分割的主动学习框架。他们提出了一种采样方法，该方法结合了不确定性和特征描述符之间的距离，从未标记的数据集中提取最具信息量的样本。在训练了初始模型后，MedAL
    方法通过首先过滤掉预测熵低于阈值的未标记数据点来选择需要标记的数据点。在这个数据集中，通过使用 CNN 的中间层输出生成每个数据点的特征描述符，然后使用各种距离函数（例如
    ’欧几里得’、’拉塞尔-拉奥’、’余弦’）相互比较这些特征描述符，以找到彼此之间距离最远的特征描述符。与所有其他未标记数据点的平均距离最大的（高于熵阈值）的数据点将被选择用于标注。通过这种方式，MedAL
    获取函数找到了对模型最有信息量且彼此之间冗余最少的数据点集合，通过从输入分布中距离最远的区域进行采样。MedAL 方法通过利用现有的计算机视觉图像描述符来初始化模型，以找到彼此最不相似的图像，从而覆盖图像分布的更大区域，作为标注后的初始训练集。他们在三种不同的医学图像分析任务中展示了良好的结果，使用比随机或纯不确定性方法更少的训练数据达到了基准准确率。'
- en: '[[64](#bib.bib64)] propose a Borda-count based combination of an uncertainty
    and a representativeness measure to select the next batch of samples. Uncertainty
    is measured as the voxel-wise variance of N predictions using MC dropout in their
    model. They introduce new representativeness measures such as ’Content Distance’,
    defined as the mean squared error between layer activation responses of a pre-trained
    classification network. They extend this contribution by encoding representativeness
    by maximum entropy to optimise network weights using an novel entropy loss function.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[[64](#bib.bib64)] 提出了基于 Borda 计数的不确定性和代表性度量的组合方法，以选择下一批样本。不确定性通过使用 MC dropout
    的 N 次预测的体素级方差来衡量。他们引入了新的代表性度量，如 ’内容距离’，定义为预训练分类网络层激活响应之间的均方误差。他们通过使用新颖的熵损失函数将代表性编码为最大熵，从而扩展了这一贡献，以优化网络权重。'
- en: '[[81](#bib.bib81)] propose a novel method for ensuring diversity among queried
    samples by calculating the Fisher Information (FI), for the first time in CNNs.
    Here, efficient computation is enabled by the gradient computations of propagation
    to allow FI to be calculated on the large parameter space of CNNs. They demonstrate
    the performance of their approach on two different flavours of task: a) semi-automatic
    segmentation of a particular subject (from a different group/different pathology
    not present in the original training data) where iteratively labelling small numbers
    of voxels queried by AL achieves accurate segmentation for that subject; and b)
    using AL to build a model generalisable to all images in a given data-set. They
    show that in both these scenarios the FI-based AL improves performance after labelling
    a small percentage of voxels, outperformed random sampling and achieved higher
    accuracy than entropy based querying.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[[81](#bib.bib81)] 首次在卷积神经网络（CNNs）中提出了一种确保查询样本多样性的新方法，通过计算费舍尔信息（FI）。在这里，通过传播的梯度计算使得在CNN的大参数空间上计算FI变得高效。他们在两个不同任务的场景下展示了他们方法的性能：a）对某一特定对象（来自不同组/不同病理的对象，原始训练数据中不存在）进行半自动分割，通过AL迭代标记少量体素实现该对象的准确分割；b）使用AL构建一个对给定数据集中的所有图像具有泛化能力的模型。他们展示了在这两种情况下，基于FI的AL在标记少量体素后提高了性能，优于随机采样，并且比基于熵的查询获得了更高的准确性。'
- en: 2.2.3 Generative Adversarial Networks for Informativeness
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.3 生成对抗网络在信息性方面的应用
- en: Generative Adversarial Network (GAN) based methods have been applied to several
    areas of medical imaging such as de-noising, modality transfer, abnormality detection,
    and for image synthesis, directly applicable to AL scenarios. This offers an alternative
    (or addition) to the many data augmentation techniques used to expand limited
    data-sets [[101](#bib.bib101)] and a DL approach to Membership Query Synthesis.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 基于生成对抗网络（GAN）的方法已应用于医学成像的多个领域，如去噪、模态转换、异常检测以及图像合成，直接适用于主动学习场景。这提供了一种替代（或补充）用于扩展有限数据集的许多数据增强技术的方案[[101](#bib.bib101)]，并且是一种用于成员查询合成的深度学习方法。
- en: '[[46](#bib.bib46)] propose a conditional GAN (cGAN) based method for active
    learning where they use the discriminator $D$ output as a measure of uncertainty
    of the proposed segmentations, and use this metric to rank samples from the unlabelled
    data-set. From this ranking the most uncertain samples are presented to an oracle
    for segmentation and the least uncertain images are included in the labelled data-set
    as pseudo ground truth labels. They show their method approaches increasing accuracy
    as the percentage of interactively annotated samples increases - reaching the
    performance of fully supervised benchmark methods using only 80% of the labels.
    This work motivates the use of GAN discriminator scores as a measure of prediction
    uncertainty.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[[46](#bib.bib46)] 提出了一种基于条件生成对抗网络（cGAN）的主动学习方法，其中他们使用判别器$D$的输出作为提出的分割的不确定性度量，并利用这个度量对未标记数据集中的样本进行排名。从这个排名中，最不确定的样本被呈现给oracle进行分割，而最确定的图像则作为伪地面真实标签包含在标记数据集中。他们展示了他们的方法在交互式注释样本的百分比增加时逐渐提高准确性——仅使用80%的标签便达到了完全监督基准方法的性能。这项工作激励了将GAN判别器分数作为预测不确定性度量的使用。'
- en: '[[55](#bib.bib55)] also use a cGAN to generate chest X-Ray images conditioned
    on a real image, and using a Bayesian neural network to assess the informativeness
    of each generated sample, decide whether each generated sample should be used
    as training data. If so, is used to fine-tune the network. They demonstrate that
    the approach can achieve comparable performance to training on the fully annotated
    data, using a dataset where only 33% of the pixels in the training set are annotated,
    offering a huge saving of time, effort and costs for annotators.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[[55](#bib.bib55)] 还使用cGAN生成基于真实图像的胸部X射线图像，并使用贝叶斯神经网络评估每个生成样本的信息性，决定是否将每个生成的样本用作训练数据。如果是，则用来微调网络。他们展示了该方法在仅标记训练集中33%的像素的情况下，能够实现与完全注释数据上的训练相当的性能，为注释员节省了大量的时间、精力和成本。'
- en: '[[105](#bib.bib105)] present an alternative method of data synthesis to GANs
    through the use of learned transformations. From a single manually segmented image,
    they leverage other un-annotated images in a SSL like approach to learn a transformation
    model from the images, and use the model along with the labelled data to synthesise
    additional annotated samples. Transformations consist of spatial deformations
    and intensity changes to enable to synthesis of complex effects such as anatomical
    and image acquisition variations. They train a model in a supervised way for the
    segmentation of MRI brain images and show state-of-the-art improvements over other
    one-shot bio-medical image segmentation methods.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[[105](#bib.bib105)] 提出了通过学习变换的方式来替代GAN的数据合成方法。通过单张手动分割的图像，他们利用其他未标注图像，以类似SSL的方法从这些图像中学习变换模型，并将模型与标注数据结合，合成额外的标注样本。变换包括空间形变和强度变化，以实现复杂效果的合成，如解剖和图像获取的变化。他们以监督方式训练了一个用于MRI脑部图像分割的模型，并展示了相对于其他一次性生物医学图像分割方法的最先进改进。'
- en: The utility of GAN based approaches in AL scenarios goes beyond single-modality
    image synthesis. Many works have demonstrated the capabilities of GANs to perform
    cross-modality image synthesis, which directly addresses not only problems of
    limited training data, but also issues of missing modalities which occur in multi-modal
    analysis scenarios. Methods by which missing modalities can be generated to fill
    missing data-points enabling the full suite of AL methods to be applied to multi-modal
    analysis problems.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 基于GAN的方法在AL场景中的实用性不仅限于单模态图像合成。许多工作已展示了GAN在跨模态图像合成中的能力，这不仅直接解决了有限训练数据的问题，还解决了多模态分析场景中缺失模态的问题。通过生成缺失模态以填补数据点，能够将完整的AL方法应用于多模态分析问题。
- en: '[[93](#bib.bib93)] introduce a GAN based method for super-resolution across
    different microscopy modalities. This work uses GANs to transform diffraction
    limited input images into super-resolved ones, improving the resolution of wide-field
    images acquired using low-numerical-aperture objectives to match the resolution
    acquired using high-numerical-aperture objectives. This work extends this approach
    to demonstrate cross-modality super-resolution to transform confocal microscopy
    images to the resolution acquired with a stimulated emission depletion microscope.
    This approach enables many types of images acquired at lower resolutions to be
    super-resolved to match those of higher resolutions, enable greater performance
    of multi-modal image analysis methods in both AL and beyond.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[[93](#bib.bib93)] 引入了一种基于GAN的超分辨率方法，适用于不同显微镜模式下。这项工作使用GAN将衍射限制的输入图像转换为超分辨率图像，从而提高使用低数值孔径物镜获得的宽场图像的分辨率，使其与使用高数值孔径物镜获得的分辨率相匹配。这项工作进一步扩展了该方法，展示了跨模式超分辨率，将共聚焦显微镜图像转换为刺激发射耗竭显微镜的分辨率。这种方法使得许多低分辨率的图像能够超分辨率到匹配高分辨率图像，提高了多模态图像分析方法在自动化学习（AL）及其他领域的性能。'
- en: '[[95](#bib.bib95)] introduce a GAN based method for the generation of high-quality
    PET images which usually require a full dose radioactive tracer to obtain. This
    work enables a low dose tracer to be used to obtain a low-quality PET images,
    from which a high quality PET image can be generated using a 3D conditional GAN,
    conditioned on the low-dose image. Additional to this, a 3D c-GANs based progressive
    refinement scheme is introduced to further improve the quality of estimated images.
    Through this work the dose of radioactive tracer required to acquire high-quality
    PET images is greatly reduced, reducing the hazards to patients and enabling low-dose
    PET images to be used alongside high-dose images in downstream analysis.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[[95](#bib.bib95)] 引入了一种基于GAN的高质量PET图像生成方法，这通常需要全剂量的放射性示踪剂才能获得。这项工作使得可以使用低剂量示踪剂获取低质量的PET图像，并使用3D条件GAN对低剂量图像进行条件生成高质量PET图像。此外，还引入了一种基于3D
    c-GAN的渐进精细化方案，以进一步提高估计图像的质量。通过这项工作，获取高质量PET图像所需的放射性示踪剂剂量大大减少，从而降低了对患者的风险，并使低剂量PET图像可以与高剂量图像一起用于下游分析。'
- en: '[[102](#bib.bib102)] extend existing GAN based methods for improved cross-modality
    synthesis of MR images acquired under different scanning parameters. Their work
    introduces edge-aware generative adversarial networks (Ea-GANs), which specifically
    integrate edge information reflecting the textural structure of image content
    to depict the boundaries of different objects in images, which goes beyond methods
    which focus only on minimising pixel.voxel-wise intensity differences. Using two
    learning strategies they introduce edge information to a generator-induced Ea-GAN
    (gEa-GAN) and to a discriminator-induced Ea-GAN (dEa-GAN), incorporating edge
    information via the generator and both generator and discriminator respectively,
    so that the edge similarity is also adversarially learned. Their method demonstrates
    state-of-the-art performance for cross-modal MR synthesis as well as excellent
    generality to generic image synthesis tasks on facades, maps and cityscapes.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[[102](#bib.bib102)] 扩展了现有的基于GAN的方法，以改进在不同扫描参数下获得的MR图像的跨模态合成。他们的工作引入了边缘感知生成对抗网络（Ea-GANs），该网络特别整合了反映图像内容纹理结构的边缘信息，以描绘图像中不同对象的边界，这超越了仅关注最小化像素/体素强度差异的方法。他们使用两种学习策略，将边缘信息引入到生成器驱动的Ea-GAN（gEa-GAN）和判别器驱动的Ea-GAN（dEa-GAN）中，分别通过生成器和生成器与判别器同时引入边缘信息，使得边缘相似性也能对抗性地学习。他们的方法展示了在跨模态MR合成中的最先进性能，并在外立面、地图和城市景观等通用图像合成任务中表现出色。'
- en: '[[65](#bib.bib65)] explore the use of GANs to impute missing PET images from
    corresponding MR images for brain disease identification using a GAN based approach,
    to avoid discarding data-missing subjects, thus increasing the number of training
    samples available. A hybrid GAN is used to generate the missing PET images, after
    which a spatially-constrained Fisher representation network is used to extract
    statistical descriptors of neuroimages for disease diagnosis. Results on three
    databases show this method can synthesise reasonable neuroimages and achieve promising
    results in brain disease identification in comparison to other state-of-the-art
    methods.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[[65](#bib.bib65)] 探索了使用GANs从相应的MR图像中补全缺失的PET图像，以用于脑部疾病的识别，采用了一种基于GAN的方法，以避免丢弃数据缺失的受试者，从而增加可用的训练样本数量。使用混合GAN生成缺失的PET图像，然后使用空间约束的Fisher表示网络提取神经影像的统计描述符用于疾病诊断。三个数据库上的结果表明，这种方法可以合成合理的神经影像，并在脑部疾病识别中取得了比其他最先进方法更有希望的结果。'
- en: The above works demonstrate the power of using synthetic data conditioned on
    a very small amount of annotated data to generate new training samples that can
    be used to train a model to a high accuracy, this is of great value to AL methods
    where we usually require a initial training set to train a model on before we
    can employ a data selection policy. These methods also demonstrate the efficient
    use of labelled data and allow us to generate multiple training samples from a
    individually annotated image, this may allow the annotated data obtained in AL/Human-in-the-Loop
    methods to be used more effectively through generating multiple training samples
    for a single requested annotation, further reducing the annotation effort required
    to train state-of-the-art models.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 上述工作展示了使用基于非常少量标注数据的合成数据生成新的训练样本的能力，这对主动学习（AL）方法具有重要价值，因为我们通常需要一个初始训练集来训练模型，然后才能采用数据选择策略。这些方法还展示了对标注数据的高效利用，并允许我们从单个标注图像生成多个训练样本，这可能使得通过生成多个训练样本来更有效地利用AL/人类在环方法中获得的标注数据，从而进一步减少训练最先进模型所需的标注工作量。
- en: 2.2.4 Learning Active Learning
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.4 学习主动学习
- en: The majority of methods discussed so far employ hand designed heuristics of
    informativeness, but some works have emerged that attempt to learn what the most
    informative samples are through experience of previous sample selection outcomes.
    This offers a potential way to select samples more efficiently but at the cost
    of interpretability of the heuristics employed. Many factors influence the performance
    and optimality of using hand-crafted heuristics for data selection. [[40](#bib.bib40)]
    propose ’Learning Active Learning’, where a regression model learns data selection
    strategies based on experience from previous AL outcomes. Arguing there is no
    way to foresee the influence of all factors such as class imbalance, label noise,
    outliers and distribution shape. Instead, their regression model ’adapts’ its
    selection to the problem without explicitly stating specific rules. [[6](#bib.bib6)]
    take this idea a step further and propose a model that leverages labelled instances
    from different but related tasks to learn a selection strategy, while simultaneously
    adapting its representation of the data and its prediction function.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止讨论的大多数方法都使用了手工设计的信息量启发式，但也出现了一些尝试通过以前样本选择结果的经验来学习最有信息量的样本的研究。这提供了一种更有效地选择样本的潜在方式，但代价是启发式方法的可解释性。许多因素影响手工设计的启发式方法在数据选择中的性能和最优性。[[40](#bib.bib40)]
    提出了“学习主动学习”，其中回归模型基于以前的主动学习结果学习数据选择策略。他们认为没有办法预见所有因素的影响，如类别不平衡、标签噪声、异常值和分布形状。相反，他们的回归模型根据问题“适应”其选择，而无需明确指出具体规则。[[6](#bib.bib6)]
    更进一步，提出了一种模型，该模型利用来自不同但相关任务的标记实例来学习选择策略，同时调整数据的表示和预测函数。
- en: Reinforcement learning (RL) is a branch of ML that enables an ’agent’ to learn
    in an interactive environment, by trial and error, using feedback from its own
    actions and experiences, working towards achieving the defined goal of the system.
    Active Learning has recently been suggested as a potential use-case of RL and
    several works have begun to explore this area.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习（RL）是机器学习（ML）的一个分支，它使“智能体”能够在交互环境中通过试错的方式学习，利用自身行动和经验的反馈，致力于实现系统定义的目标。最近有人提出主动学习作为RL的潜在应用案例，并且已有一些研究开始探讨这一领域。
- en: '[[97](#bib.bib97)] propose a one-shot learning method that combines with RL
    to allow the model to decide, during inference, which examples are worth labelling.
    A stream of images is presented and a decision is made either to predict the label,
    or pay to receive the the correct label. Through the choice of RL reward function
    they are able to achieve higher prediction accuracy than a purely supervised task,
    or trade prediction accuracy for fewer label requests.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[[97](#bib.bib97)] 提出了一个一体化学习方法，该方法结合了RL，以便模型在推理过程中决定哪些示例值得标注。呈现一系列图像，然后做出决定：要么预测标签，要么支付以获取正确标签。通过选择RL奖励函数，他们能够实现比纯监督任务更高的预测准确性，或者用较少的标签请求来交换预测准确性。'
- en: '[[22](#bib.bib22)] re-frame the data selection process as a RL problem, and
    explicitly learn a data selection policy. This is agnostic to the data selection
    heuristics common in AL frameworks, providing a more general approach, demonstrating
    improvements in entity recognition, however this is yet to be applied to medical
    image data.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[[22](#bib.bib22)] 将数据选择过程重新构建为RL问题，并明确学习数据选择策略。这不依赖于主动学习框架中常见的数据选择启发式方法，提供了更通用的方法，显示了在实体识别方面的改进，但尚未应用于医学图像数据。'
- en: RL methods offer a different approach to AL and Human-in-the-Loop problems that
    is well aligned with aiding real-time feedback between a DL enabled application
    and its end users, however it requires task specific goals that may not be generalisable
    across different medical image analysis tasks.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: RL 方法提供了一种不同于主动学习和人机交互问题的方法，这与实时反馈有很好的契合，但它需要特定任务的目标，这些目标可能无法在不同的医学图像分析任务中泛化。
- en: 2.3 Fine-tuning vs Retraining
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 微调与再训练
- en: The final step of each AL framework is to use newly acquired annotations to
    improve a model. Two main approaches are used to train a model on new annotations.
    These are retraining the model using all available data including the newly acquired
    annotations or to fine-tune the model using only new annotations or the new annotations
    plus a subset from the existing annotations.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 每个AL框架的最后一步是利用新获得的注释来改进模型。用于在新注释上训练模型的两种主要方法是：使用包括新获得的注释在内的所有可用数据重新训练模型，或仅使用新注释或新注释加上一部分现有注释来微调模型。
- en: '[[86](#bib.bib86)] investigate using transfer learning and fine-tuning in several
    medical image analysis tasks and demonstrate that the use of a pre-trained CNN
    with fine-tuning outperformed a CNN trained from scratch and that these fine-tuned
    CNNs were more robust to the size of the training sets. They also showed that
    neither shallow nor deep tuning was the optimal choice for a particular application
    and present a layer-wise training scheme that could offer a practical way to reach
    optimal performance for the chosen task based on the amount of data available.
    The methods employed in this work perform one-time fine-tuning where a pre-trained
    model is fine-tuned just once with available training samples, however this does
    not accommodate an active selection process or continuous fine-tuning.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[[86](#bib.bib86)] 研究了在多个医学图像分析任务中使用迁移学习和微调的方法，并展示了使用经过微调的预训练CNN优于从头开始训练的CNN，且这些微调的CNN对训练集大小更具鲁棒性。他们还表明，浅层或深层微调都不是特定应用的最佳选择，并提出了一种逐层训练方案，这种方案可以根据可用数据量提供一种实用的方式来达到所选任务的最佳性能。这项工作中的方法执行一次性微调，即只使用可用的训练样本对预训练模型进行一次微调，但这不支持主动选择过程或连续微调。'
- en: '[[109](#bib.bib109)] propose a continuous fine-tuning method that fine-tunes
    a pre-trained CNN with successively larger datasets and demonstrate that this
    approach converges faster than repeatedly fine-tuning the pre-trained CNN. They
    also find that continuously fine-tuning with only newly acquired annotations requires
    careful meta-parameter adjustments making it less practical across many different
    tasks.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[[109](#bib.bib109)] 提出了一个连续微调的方法，该方法使用逐渐增大的数据集来微调预训练CNN，并展示了这种方法比反复微调预训练CNN收敛更快。他们还发现，只有使用新获得的注释进行连续微调需要仔细的元参数调整，使得它在许多不同任务中不够实际。'
- en: An alternative approach to retraining from new data that is inspired by the
    two main approaches described above is to retrain a model using all available
    data, but using the previous parameters as initialisation, however this approach
    has not been applied to AL in any works the authors are aware of.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一种受上述两种主要方法启发的重新训练新数据的替代方法是使用所有可用数据来重新训练模型，但使用之前的参数作为初始化，然而，作者所知的任何工作中尚未应用这种方法于主动学习（AL）。
- en: Retraining is computationally more expensive than fine-tuning but it provides
    a consistent means to evaluate AL framework performance. Fine-tuning is used across
    a number of different ML areas such as one or few shot learning, and transfer
    learning and the best approach to this is still an open question and as such is
    less prevalent in AL frameworks, as fine tuning improves we may see a shift towards
    its use in AL frameworks. It is important to establish baseline fine-tuning and
    retraining schemes to effectively compare the DL/AL methods in which they are
    applied in order to isolate the effects of these schemes from the improvements
    made in other areas.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 重新训练比微调计算开销更大，但它提供了一种一致的方法来评估AL框架的性能。微调在许多不同的机器学习领域中使用，如一次或少次学习和迁移学习，这方面的最佳方法仍然是一个开放问题，因此在AL框架中不太常见。随着微调技术的改进，我们可能会看到其在AL框架中的应用有所增加。为了有效比较所应用的DL/AL方法，建立基准微调和重新训练方案是重要的，以便将这些方案的效果与其他领域的改进分开。
- en: '3 The Final Percent: Interactive refinement of model outputs'
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 最终百分比：模型输出的互动细化
- en: '![Refer to caption](img/c54c2b4a9ee98dff75e79a5d805fe01b.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c54c2b4a9ee98dff75e79a5d805fe01b.png)'
- en: 'Fig. 2: Overview of Refinement frameworks.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：细化框架概述。
- en: 'So far we have considered the role of humans in annotating data to be used
    to train a model, but once a model is trained, we still require a human-in-the-loop
    to interpret model predictions and potentially to refine them to acquire the most
    accurate results for unseen data, as outlined in Figure [2](#S3.F2 "Fig. 2 ‣ 3
    The Final Percent: Interactive refinement of model outputs ‣ A Survey on Active
    Learning and Human-in-the-Loop Deep Learning for Medical Image Analysis1footnote
    11footnote 1"). In Human-in-the-loop scenarios, a model makes predictions on unseen
    input, and subject to acceptance criteria, automated predictions may need manual
    adjustment to meet those acceptance criteria. Communication of information about
    the prediction is important to allow acceptance criteria to be met with confidence,
    and form an understanding of the limitations of automated predictions. This communication
    is two fold i.e. a user must be able to communicate with the model being used
    to guide predictions to more accurate results or to correct erroneous predictions,
    and a model must be able to communicate with the user to provide meaningful interpretation
    of model predictions, enabling users to take the best course of action when interacting
    with model outputs and to mitigate human uncertainty. This creates the feedback
    loop as shown in Figure [2](#S3.F2 "Fig. 2 ‣ 3 The Final Percent: Interactive
    refinement of model outputs ‣ A Survey on Active Learning and Human-in-the-Loop
    Deep Learning for Medical Image Analysis1footnote 11footnote 1").'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '到目前为止，我们已经考虑了人工标注数据以用于训练模型的角色，但一旦模型训练完成，我们仍然需要“人机互动”的方式来解释模型预测，并可能对其进行改进，以获取对未知数据的最准确结果，如图
    [2](#S3.F2 "Fig. 2 ‣ 3 The Final Percent: Interactive refinement of model outputs
    ‣ A Survey on Active Learning and Human-in-the-Loop Deep Learning for Medical
    Image Analysis1footnote 11footnote 1") 所述。在“人机互动”场景中，模型对未知输入进行预测，并且根据接受标准，自动预测可能需要手动调整以满足这些接受标准。关于预测的信息传达非常重要，以使接受标准能够自信地达到，并形成对自动预测局限性的理解。这种沟通是双重的，即用户必须能够与使用的模型沟通，以指导预测结果更准确或纠正错误预测，同时，模型也必须能够与用户沟通，以提供对模型预测的有意义的解释，使用户能够在与模型输出互动时采取最佳行动，并减少人为不确定性。这创建了如图
    [2](#S3.F2 "Fig. 2 ‣ 3 The Final Percent: Interactive refinement of model outputs
    ‣ A Survey on Active Learning and Human-in-the-Loop Deep Learning for Medical
    Image Analysis1footnote 11footnote 1") 所示的反馈循环。'
- en: 3.1 Interactive Refinement
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 互动改进
- en: If we can develop accurate, robust and interpretable models for medical image
    applications we still cannot guarantee automated predictions meet acceptance criteria
    for every unseen data-point presented to a model. The ability to generalise to
    unseen input is a cornerstone of deep learning applications, but in real world
    distributions, generalisation is rarely perfect. As such, methods to rectify these
    discrepancies must be built into applications used for medical image analysis.
    This iterative refinement must save the end user time and mental effort over performing
    manual annotation or purely manual correction. Many interactive image segmentation
    systems have been proposed, and more recently these have built on the advances
    in deep learning to allow users to refine model outputs and feedback the more
    accurate results to the model for improvement.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能为医学图像应用开发准确、稳健且可解释的模型，但仍无法保证自动化预测满足每一个模型呈现的未知数据点的接受标准。对未知输入进行泛化的能力是深度学习应用的基石，但在现实世界的分布中，泛化很少是完美的。因此，必须将纠正这些差异的方法嵌入到用于医学图像分析的应用程序中。这种迭代的改进必须节省最终用户在执行手动标注或纯粹手动修正上的时间和精力。许多互动图像分割系统已被提出，最近这些系统在深度学习的进展基础上，允许用户改进模型输出，并将更准确的结果反馈给模型进行改进。
- en: '[[1](#bib.bib1)] introduced UI-Net, that builds on the popular U-Net architecture
    for medical image segmentation [[73](#bib.bib73)]. The UI-Net is trained with
    an active user model, and allows for users to interact with proposed segmentations
    by providing scribbles over the image to indicate areas that should be included
    or not, the network is trained using simulated user interactions and as such responds
    to iterative user scribbles to refine a segmentation towards a more accurate result.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1](#bib.bib1)] 引入了 UI-Net，它基于流行的 U-Net 架构用于医学图像分割 [[73](#bib.bib73)]。UI-Net
    使用活跃用户模型进行训练，允许用户通过在图像上提供涂鸦来指示应包含或不包含的区域来与建议的分割进行交互，网络使用模拟用户交互进行训练，因此对迭代用户涂鸦做出响应，以将分割结果改进为更准确的结果。'
- en: Conditional Random fields have been used in various tasks to encourage segmentation
    homogeneity. [[106](#bib.bib106)] propose CRF-CNN, a recurrent neural network
    which has the desirable properties of both CNNs and CRFs. [[92](#bib.bib92)] propose
    DeepIGeoS, an interactive geodesic framework for medical image segmentation. This
    framework uses two CNNs, the first performs an initial automatic segmentation,
    and the second takes the initial segmentation as well as user interactions with
    the initial segmentation to provide a refined result. They combine user interactions
    with CNNs through geodesic distance transforms [[18](#bib.bib18)], and these user
    interactions are integrated as hard constraints into a Conditional Random Field,
    inspired by [[106](#bib.bib106)]. They call their two networks P-Net (initial
    segmentation) and R-Net (for refinement). They demonstrate superior results for
    segmentation of the placenta from 2D fetal MRI and brain tumors from 3D FLAIR
    images when compared to fully automatic CNNs. These segmentation results were
    also obtained in roughly a third of the time taken to perform the same segmentation
    with traditional interactive methods such as GeoS or ITK-SNAP.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 条件随机场（Conditional Random Fields）已被应用于各种任务以促进分割的同质性。[[106](#bib.bib106)] 提出了
    CRF-CNN，这是一种递归神经网络，结合了 CNN 和 CRF 的优良特性。[[92](#bib.bib92)] 提出了 DeepIGeoS，这是一个用于医学图像分割的交互式测地框架。该框架使用两个
    CNN，第一个执行初步自动分割，第二个结合初步分割以及用户对初步分割的交互来提供精细化结果。他们通过测地距离变换[[18](#bib.bib18)]将用户交互与
    CNN 结合，这些用户交互被作为硬约束整合到条件随机场中，灵感来源于 [[106](#bib.bib106)]。他们将这两个网络称为 P-Net（初步分割）和
    R-Net（用于精细化）。与完全自动的 CNN 相比，他们在 2D 胎儿 MRI 中的胎盘分割和 3D FLAIR 图像中的脑肿瘤分割上展示了卓越的结果。这些分割结果的获得时间大约是使用传统交互方法如
    GeoS 或 ITK-SNAP 进行相同分割时间的三分之一。
- en: Graph Cuts have also been used in segmentation to incorporate user interaction
    - a user provides seed points to the algorithm (e.g. mark some pixel as foreground,
    and another as background) and from this the segmentation is calculated. [[91](#bib.bib91)]
    propose BIFSeg, an interactive segmentation framework inspired by graph cuts.
    Their work introduces a deep learning framework for interactive segmentation by
    combining CNNs with a bounding box and scribble based segmentation pipeline. The
    user provides a bounding box around the area which they are interested in segmenting,
    this is then fed into their CNN to produce an initial segmentation prediction,
    the user can then provide scribbles to mark areas of the image as mis-classified
    - these user inputs are then weighted heavily in the calculation of the refined
    segmentation using their graph cut based algorithm.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图割（Graph Cuts）也被用于分割中以纳入用户交互——用户向算法提供种子点（例如，标记一些像素为前景，另一些为背景），从中计算分割。[[91](#bib.bib91)]
    提出了 BIFSeg，这是一个受图割启发的交互式分割框架。他们的工作引入了一种通过结合 CNN 和基于边界框与涂鸦的分割管道的深度学习框架来实现交互式分割。用户在他们感兴趣的区域周围提供一个边界框，然后将其输入
    CNN 以生成初步分割预测，用户可以提供涂鸦以标记图像中被误分类的区域——这些用户输入在使用他们的图割算法计算精细化分割时被赋予了很大的权重。
- en: '[[11](#bib.bib11)] propose an alternative to BIFSeg in which two networks are
    trained, one to perform an initial segmentation (they use a CNN but this initial
    segmentation could be performed with any existing algorithm) and a second network
    they call interCNN that takes as input the image, some user scribbles and the
    initial segmentation prediction and outputs a refined segmentation, they show
    that with several iterations over multiple user inputs the quality of the segmentations
    improve over the initial segmentation and achieve state-of-the-art performance
    in comparison to other interactive methods.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[[11](#bib.bib11)] 提出了 BIFSeg 的一种替代方案，其中训练了两个网络，一个用于执行初步分割（他们使用 CNN，但这个初步分割也可以用任何现有算法进行），另一个网络称为
    interCNN，它以图像、一些用户涂鸦和初步分割预测作为输入，并输出精细化分割。他们展示了通过对多个用户输入进行几轮迭代，分割质量在初步分割的基础上得到改进，并在与其他交互式方法的比较中达到了最先进的性能。'
- en: The methods discussed above have so far been concerned with producing segmentations
    for individual images or slices, however many segmentation tasks seek to extract
    the 3D shape/surface of a particular region of interest (ROI). [[43](#bib.bib43)]
    propose a dual method for producing segmentations in 3D based on a Smart-brush
    2D segmentation that the user guides towards a good 2D segmentation, and after
    a few slices are segmented this is transformed to a 3D surface shape using Hermite
    radial basis functions, achieving high accuracy. While this method does not use
    deep learning it is a strong example of the ways in which interactive segmentation
    can be used to generate high quality training data for use in deep learning applications
    - their approach is general and can produce segmentations for a large number of
    tasks. There is potential to incorporate deep learning into their pipeline to
    improve results and accelerate the interactive annotation process.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 上述方法迄今为止主要关注于为单个图像或切片生成分割，但许多分割任务旨在提取特定感兴趣区域（ROI）的三维形状/表面。[[43](#bib.bib43)]
    提出了基于Smart-brush 2D分割的三维分割双重方法，用户引导该方法实现良好的2D分割，在分割几个切片后，使用Hermite径向基函数将其转换为三维表面形状，实现高精度。虽然该方法没有使用深度学习，但它是交互式分割生成高质量训练数据用于深度学习应用的强大示例
    - 他们的方法是通用的，可以为大量任务生成分割。还有潜力将深度学习融入他们的流程中，以改善结果并加速交互注释过程。
- en: '[[32](#bib.bib32)] propose an interactive segmentation scheme that generalises
    to any previously trained segmentation model, which accepts user annotations about
    a target object and the background. User annotations are converted into interaction
    maps by measuring the distance of each pixel to the annotated landmarks, after
    which the forward pass outputs an initial segmentation. The user annotated points
    can be mis-segmented in the initial segmentation so they propose BRS (back-propogating
    refinement scheme) that corrects the mis-labelled pixels. They demonstrate that
    their algorithm outperforms conventional approaches on several datasets and that
    BRS can generalise to medical image segmentation tasks by transforming existing
    CNNs into user-interactive versions.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[[32](#bib.bib32)] 提出了一个交互式分割方案，该方案可以推广到任何之前训练过的分割模型，接受关于目标物体和背景的用户注释。用户注释通过测量每个像素到标注地标的距离转换为交互图，然后前向传播输出初步分割。用户标注的点可能在初步分割中被误分割，因此他们提出了BRS（反向传播修正方案），以纠正错误标记的像素。他们展示了他们的算法在多个数据集上优于传统方法，并且BRS可以通过将现有的CNN转换为用户交互版本来推广到医学图像分割任务。'
- en: '[[50](#bib.bib50)] propose modelling the dynamics of iterative interactive
    refinement as a Markov Decision Process (MDP) and solve this with multi-agent
    RL. Treating each voxel as an agent with a shared voxel-level behaviour strategy
    they make voxel-wise prediction tractable in this way. The multi-agent method
    successfully captures the dependencies among voxels for segmentation tasks, and
    by passing prediction uncertainty of previous segmentations through the state
    space can derive more precise and finer segmentations. Using this method they
    significantly outperform existing state-of-the-art methods with fewer interactions
    and a faster convergence.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[[50](#bib.bib50)] 提出了将迭代交互修正的动态建模为马尔可夫决策过程（MDP），并通过多代理强化学习（RL）来解决这个问题。通过将每个体素视为具有共享体素级行为策略的代理，他们使体素级预测变得可处理。多代理方法成功捕获了体素之间的依赖关系，用于分割任务，并通过将先前分割的预测不确定性传递通过状态空间来得出更精确和细致的分割。使用这种方法，他们在较少的交互和更快的收敛速度下显著超越了现有的最先进方法。'
- en: In this section we focus on applications concerned with iteratively refining
    a segmentation towards a desired quality of output. In the scenarios above this
    is performed on an un-seen image provided by the end user, but there is no reason
    the same approach could not be taken to generate iteratively more accurate annotations
    to be used in training, e.g., using active learning to select which samples to
    annotate next, and iteratively refining the prediction made by the current model
    until a sufficiently accurate annotation is curated. This has the potential to
    accelerate annotation for training without any additional implementation overhead.
    Much work done in AL ignores the role of the oracle and merely assumes we can
    acquire an accurate label when we need it, but in practice this presents a more
    significant challenge. We foresee AL and HITL computing become more tightly coupled
    as AL research improves it’s consideration for the oracle providing the annotations.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们重点关注迭代细化分割以达到期望的输出质量的应用。在上述场景中，这是在用户提供的未见过的图像上进行的，但没有理由认为不能采用相同的方法来生成迭代地更准确的注释以供训练使用，例如，使用主动学习来选择下一步需要注释的样本，并迭代地细化当前模型所做的预测，直到得到足够准确的注释。这有可能加速训练的注释工作，而无需额外的实现开销。许多主动学习（AL）工作忽略了oracle的角色，仅假设我们在需要时可以获得准确的标签，但在实践中这提出了更大的挑战。我们预见到，随着主动学习研究对提供注释的oracle考虑的改进，AL和HITL计算将变得更加紧密地结合在一起。
- en: It is fairly intuitive how a user might refine segmentations of medical images,
    but this is not the case for other medical image analysis tasks. Refinements of
    predictions on clinical tasks involving classification and regression have seen
    less development than those in segmentation and remains an open area of research.
    The following works have taken steps towards addressing interactive refinement
    strategies for classification and regression tasks.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可能会直观地理解如何细化医学图像的分割，但这并不适用于其他医学图像分析任务。在临床任务中的分类和回归预测的细化发展较少，相较于分割领域，仍然是一个开放的研究领域。以下工作在分类和回归任务的交互细化策略方面迈出了步伐。
- en: '[[49](#bib.bib49)] explore the use of CNN methods for automated diagnosis of
    Alzheimer’s disease and identify that many state-of-the-art methods rely on the
    pre-determination of informative locations in structural MRI (sMRI). This stage
    of discriminative localisation is isolated from the latter stages of feature extraction
    and classifier construction. Their work proposes a hierarchical fully convolutional
    CNN (H-FCN) to automatically identify discriminative local patches and regions
    in whole brain sMRI, from which multi-scale feature representations can be jointly
    learned and fused to construct classification models. This work enables interactive
    refinement of patch choice and classifier construction which, if intervened on
    by human end users could guide the network towards more discriminative regions
    of interest and thus more effective classifiers.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[[49](#bib.bib49)] 探索了使用卷积神经网络（CNN）方法进行阿尔茨海默病的自动诊断，并指出许多先进的方法依赖于在结构性MRI（sMRI）中预先确定信息丰富的位置。这个阶段的区分定位与特征提取和分类器构建的后续阶段是隔离的。他们的工作提出了一种层次化全卷积CNN（H-FCN），以自动识别全脑sMRI中的区分性局部补丁和区域，从中可以联合学习和融合多尺度特征表示以构建分类模型。这项工作使得补丁选择和分类器构建的交互细化成为可能，如果由人类终端用户进行干预，可以引导网络关注更具区分性的感兴趣区域，从而构建更有效的分类器。'
- en: Similarly, [[52](#bib.bib52)] introduce a landmark-based deep multi-instance
    learning (LDMIL) framework for brain disease diagnosis. Firstly, by adopting a
    data-driven approach to discover disease related anatomical landmarks in brain
    MR images, along with nearby image patches. Secondly the framework learns an end-to-end
    MR image classifier for capturing local structural information in the selected
    landmark patches, and global structure information derived from all detected landmarks.
    By splitting the steps of landmark detection and classifier construction, a human-in-the-loop
    can be introduced to intervene on selected landmarks and to guide the network
    towards maximally informative image regions. Thus, the resulting classifier can
    be refined via updating which regions of the image are used as input.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，[[52](#bib.bib52)] 引入了一种基于地标的深度多实例学习（LDMIL）框架，用于脑部疾病诊断。首先，通过采用数据驱动的方法发现脑部MR图像中的疾病相关解剖学地标，以及附近的图像块。其次，该框架学习一个端到端的MR图像分类器，以捕捉选定地标块中的局部结构信息，以及从所有检测到的地标中提取的全局结构信息。通过将地标检测和分类器构建的步骤分开，可以引入人机协作以干预选定的地标，并引导网络关注最大信息量的图像区域。因此，结果分类器可以通过更新哪些图像区域作为输入来进行优化。
- en: 3.2 Interactive Interpretation
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 互动解释
- en: 'In the previous section we discussed methods by which the user of a human-in-the-loop
    system might communicate with a predictive model, in this section we consider
    methods by which a model might communicate with the user, thus completing the
    feedback loop in Figure [2](#S3.F2 "Fig. 2 ‣ 3 The Final Percent: Interactive
    refinement of model outputs ‣ A Survey on Active Learning and Human-in-the-Loop
    Deep Learning for Medical Image Analysis1footnote 11footnote 1"). ’Interpretation’
    can mean many different things depending on the context, so here we focus on interpretation
    of model outputs with the goal of appropriately weighting automated predictions
    in downstream analysis (e.g uncertainty of predictions) and to enable users to
    make the most informed corrections or manual adjustments to model predictions
    (e.g ’Attention Gating’[[63](#bib.bib63)]).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了用户如何与预测模型进行沟通的方法，本节我们将考虑模型如何与用户沟通，从而完成图[2](#S3.F2 "图2 ‣ 3 最终百分比：模型输出的互动优化
    ‣ 医学图像分析中的主动学习和人机协作深度学习综述1脚注 11脚注 1")中的反馈回路。‘解释’根据上下文可以有许多不同的含义，因此在这里我们专注于模型输出的解释，目标是适当地权衡下游分析中的自动预测（例如预测的不确定性），并使用户能够对模型预测进行最有信息量的修正或手动调整（例如‘注意力门控’[[63](#bib.bib63)]）。
- en: While DL methods have become a standard state-of-the-art approach for many medical
    image analysis tasks, they largely remain black-box methods where the end user
    has limited meaningful ways of interpreting model predictions. This feature of
    DL methods is a significant hurdle in the deployment of DL enabled applications
    to safety-critical domains such as medical image analysis. We want models to be
    highly accurate and robust, but also explainable and interpretable. This interpretability
    is vital to mitigate human uncertainty and foster trust in using automated predictions
    in downstream tasks with real-world consequences.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度学习（DL）方法已经成为许多医学图像分析任务的标准最先进方法，但它们仍然大多是黑箱方法，最终用户对于模型预测的解释方式有限。这种特性是将深度学习应用于如医学图像分析等安全关键领域的一大障碍。我们希望模型不仅具有高度的准确性和鲁棒性，还要具有可解释性和可理解性。这种可解释性对于减少人类的不确定性并在具有实际后果的下游任务中培养对自动预测的信任至关重要。
- en: Recent EU law⁴⁴4Regulation (EU) 2016/679 on the protection of natural persons
    with regard to the processing of personal data and on the free movement of such
    data, and repealing Directive 95/46/EC (General Data Protection Regulation) [2016]
    OJ L119/1 has led to the ’right for explanation’, whereby any subject has the
    right to have automated decisions that have been made about them explained. This
    even further highlights the need for transparent algorithms which we can reason
    about [[[26](#bib.bib26)], [[20](#bib.bib20)], [[21](#bib.bib21)]].
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的欧盟法律⁴⁴4《2016/679号条例》（欧盟）关于自然人的个人数据处理和这些数据自由流动的保护，以及废除《95/46/EC号指令》（一般数据保护条例）[2016]
    OJ L119/1，进一步突显了‘解释权’的必要性，即任何主体都有权获得关于他们做出的自动决策的解释。这更进一步突显了我们需要可以推理的透明算法的必要性[[[26](#bib.bib26)],
    [[20](#bib.bib20)], [[21](#bib.bib21)]]。
- en: It is important for users to understand how a certain decision has been made
    by the model, as even the most accurate and robust models aren’t infallible, and
    false or uncertain predictions must be identified so that trust in the model can
    be fostered and predictions are appropriately weighted in the clinical decision
    making process. It is vital the end user, regulators and auditors all have the
    ability to contextualise automated decisions produced by DL models. Here we outline
    some different methods for providing interpretable ways of reasoning about DL
    models and their predictions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 用户理解模型做出某一决策的过程至关重要，因为即使是最准确和最强大的模型也不是绝对无误的，必须识别错误或不确定的预测，以便在临床决策过程中建立对模型的信任，并对预测进行适当加权。至关重要的是，最终用户、监管机构和审计员都能将DL模型产生的自动决策进行背景化。在这里，我们概述了一些提供DL模型及其预测的可解释性推理方法。
- en: Typically DL methods can provide statistical metrics on the uncertainty of a
    model output, many of the uncertainty measures discussed in Section [2](#S2 "2
    Active Learning ‣ A Survey on Active Learning and Human-in-the-Loop Deep Learning
    for Medical Image Analysis1footnote 11footnote 1") are also used to aid in intepretability.
    While uncertainty measures are important, these are not sufficient to foster complete
    trust in DL model, the model should provide human-understandable justifications
    for its output that allow insights to be drawn elucidating the inner workings
    of a model. [[13](#bib.bib13)] discuss many of the core concerns surrounding model
    intepretability and highlight various works that have demonstrated sophisticated
    methods of making a DL model interpretable across the DL field. Here we evaluate
    some of the works that have been applied to medical image segmentation and refer
    the reader to [[[83](#bib.bib83)], [[31](#bib.bib31)]] for further reading on
    interpretability in the rest of the medical imaging domain.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，深度学习（DL）方法可以提供关于模型输出不确定性的统计指标，许多在第[2](#S2 "2 Active Learning ‣ A Survey on
    Active Learning and Human-in-the-Loop Deep Learning for Medical Image Analysis1footnote
    11footnote 1")节讨论的不确定性度量也用于辅助解释性。虽然不确定性度量很重要，但这些措施不足以完全建立对DL模型的信任，模型应提供人类可理解的理由来解释其输出，从而揭示模型的内部工作原理。[[13](#bib.bib13)]
    讨论了围绕模型解释性的许多核心问题，并强调了各种展示使DL模型可解释的复杂方法的工作。在这里，我们评估了一些已应用于医学图像分割的工作，并将读者参考[[[83](#bib.bib83)],
    [[31](#bib.bib31)]]以获取有关医学成像领域其他解释性的进一步阅读。
- en: '[[63](#bib.bib63)] and [[74](#bib.bib74)] introduce ’Attention Gating’ to guide
    networks towards giving more ’attention’ to certain image areas, in a visually
    interpretable way - potentially aiding in the subsequent refinement of annotations.
    Attention Gates are introduced into the popular U-Net architecture ([[73](#bib.bib73)]),
    where information extracted from coarse scale layers is used in gating to disambiguate
    irrelevant and noisy responses in skip connections, prior to concatenation, to
    merge only relevant layer activations. This approach eliminates the need for applying
    external object localisation models in image segmentation and regression tasks.
    Coefficients of Attention Gate layers indicate where in an image feature activations
    will be allowed to propagate through to final predictions, providing users with
    a visual representation of the areas of an image that a model has weighted highly
    in making predictions.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[[63](#bib.bib63)] 和 [[74](#bib.bib74)] 介绍了“注意力门控”（’Attention Gating’），以一种可视化的方式指导网络更多关注某些图像区域，从而潜在地有助于后续注释的精细化。注意力门控被引入到流行的U-Net架构中（[[73](#bib.bib73)]），在跳跃连接的级联之前，利用从粗尺度层提取的信息进行门控，以消除不相关和噪声响应，只合并相关层的激活。该方法消除了在图像分割和回归任务中应用外部物体定位模型的需求。注意力门控层的系数表明图像中的特征激活将被允许传播到最终预测中，为用户提供模型在做出预测时高度加权的图像区域的可视化表示。'
- en: In [[12](#bib.bib12)] we propose a visual method for interpreting automated
    head circumference measurements from ultrasound images, using MC Dropout at test-time
    to acquire N head segmentations to calculate an upper and lower bound on the head
    circumference measurement in real-time. These bounds were displayed over the image
    to guide the sonographer towards views in which the model predicts with the most
    confidence. This upper lower bound is presented as a measure of model compliance
    of the unseen image rather than uncertainty. Finally, variance heuristics are
    proposed to quantify the confidence of a prediction in order to either accept
    or reject head circumference measurements, and it is shown these can improve overall
    performance measures once ’rejected’ images are removed.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[12](#bib.bib12)]中，我们提出了一种用于解释超声图像中自动头围测量的视觉方法，利用测试时的MC Dropout获取N个头部分割，以实时计算头围测量的上限和下限。这些界限被显示在图像上，以引导超声技师关注模型最自信的视图。这个上限和下限作为对未见图像的模型合规性的一种度量，而非不确定性。最后，提出了方差启发式方法来量化预测的信心，以决定是否接受或拒绝头围测量，结果表明，一旦“拒绝”的图像被移除，这些方法可以改善总体性能指标。
- en: '[[58](#bib.bib58)] propose the application of RL to ultrasound care, guiding
    a potentially inexperienced user to the correct sonic window and enabling them
    to obtain clinically relevant images of the anatomy of interest. This human-in-the-loop
    application is an example of the novel applications possible when combining DL/RL
    with real-time systems enabling users to respond to model feedback to acquire
    the most accurate information available.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[[58](#bib.bib58)]提出将强化学习应用于超声护理，指导潜在的不熟练用户找到正确的声窗，并使他们能够获得与解剖结构相关的临床图像。这种人机互动的应用是结合深度学习/强化学习与实时系统时可能出现的创新应用的一个例子，使用户能够响应模型反馈，获取最准确的信息。'
- en: '[[90](#bib.bib90)] propose using test-time augmentation to acquire a measure
    of aleatoric (image-based) uncertainty and compare their method with epistemic
    (model) uncertainty measures and show that their method provides a better uncertainty
    estimation than a test-time dropout based model uncertainty alone and reduces
    overconfident incorrect predictions.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[[90](#bib.bib90)]提出使用测试时数据增强来获得一种测量图像基础的不确定性的方法，并将其与模型基础的不确定性测量进行比较，结果表明他们的方法提供了比单纯基于测试时Dropout的模型不确定性更好的不确定性估计，并减少了过度自信的错误预测。'
- en: '[[33](#bib.bib33)] evaluate several different voxel-wise uncertainty estimation
    methods applied to medical image segmentation with respect to their reliability
    and limitations and show that current uncertainty estimation methods perform similarly.
    Their results show that while uncertainty estimates may be well calibrated at
    the dataset level (capturing epistemic uncertainty), they tend to be mis-calibrated
    at a subject-level (aleatoric uncertainty). This compromises the reliability of
    these uncertainty estimates and highlights the need to develop subject-wise uncertainty
    estimates. They show auxiliary networks to be a valid alternative to common uncertainty
    methods as they can be applied to any previously trained segmentation model.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[[33](#bib.bib33)]评估了几种不同的体素级不确定性估计方法在医学图像分割中的可靠性和局限性，结果表明当前的不确定性估计方法表现相似。他们的结果表明，尽管不确定性估计可能在数据集级别上（捕捉到模型不确定性）经过良好校准，但在个体级别上（图像基础不确定性）往往校准不佳。这削弱了这些不确定性估计的可靠性，突出了开发个体级不确定性估计的必要性。他们展示了辅助网络作为常见不确定性方法的有效替代方案，因为它们可以应用于任何之前训练过的分割模型。'
- en: Developing transparent systems will enable faster uptake in clinical practice
    and including humans within the deep learning clinical pipelines will ease the
    period of transition between current best practices and the breadth of possible
    enhancements that deep learning has to offer.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 发展透明的系统将加速临床实践中的应用，并且将人类纳入深度学习临床流程中，将简化从当前最佳实践到深度学习所能提供的广泛改进的过渡期。
- en: We suggest that ongoing work in improving interpretability of DL models will
    also have a positive impact on AL, as the majority of methods to improve intepretability
    are centred on providing uncertainty measures for a models prediction, these same
    uncertainty measures can be used for AL selection strategies in place of existing
    uncertainty measures that are currently employed. As intepretability and uncertainty
    measures improve we expect to see a similar improvement of AL frameworks as they
    incorporate the most promising uncertainty measures.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议，DL模型可解释性的持续改进也将对AL产生积极影响，因为提高可解释性的多数方法集中于为模型预测提供不确定性度量，这些不确定性度量可以用于AL选择策略，替代当前使用的不确定性度量。随着可解释性和不确定性度量的改进，我们预计AL框架也会随着其整合最有前景的不确定性度量而得到类似的改进。
- en: 'The methods discussed in Section [3](#S3 "3 The Final Percent: Interactive
    refinement of model outputs ‣ A Survey on Active Learning and Human-in-the-Loop
    Deep Learning for Medical Image Analysis1footnote 11footnote 1") remain open areas
    of research interest with great implications for the progress of AL development
    and greater uptake of DL and HITL methods in clinical practice. The study of interaction
    between users and models is of growing importance and is having a significant
    impact on the efficacy of Deep Active Learning systems and their deployment to
    real-world applications, especially in clinical scenarios ([[8](#bib.bib8), [2](#bib.bib2)]).
    The wider study of interpretability in ML and the study of Human Computer Interaction
    may seem distinct and diverging, however we expect to see these two research fields
    converge through Active Learning as the feedback loop between human users and
    machine models becomes of increasing importance.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '第[3](#S3 "3 The Final Percent: Interactive refinement of model outputs ‣ A
    Survey on Active Learning and Human-in-the-Loop Deep Learning for Medical Image
    Analysis1footnote 11footnote 1")节中讨论的方法仍然是研究兴趣的开放领域，对AL发展进程及DL和HITL方法在临床实践中的更广泛应用具有重大影响。用户与模型之间互动的研究日益重要，对深度主动学习系统的效能以及其在现实应用，特别是临床场景中的部署产生了显著影响（[[8](#bib.bib8),
    [2](#bib.bib2)]）。虽然机器学习中的可解释性研究和人机交互研究看似不同且有所分歧，但我们预计这两个研究领域将通过主动学习趋于融合，因为人类用户与机器模型之间的反馈循环变得越来越重要。'
- en: 4 Practical Considerations
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实际考虑
- en: '![Refer to caption](img/e2475e5bcf77913fa7e7284617499864.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e2475e5bcf77913fa7e7284617499864.png)'
- en: 'Fig. 3: Overview of practical considerations'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 实际考虑的概述'
- en: We have so far discussed the core body of work behind AL, model interpretation
    and prediction refinement, and while the works discussed above go a long way in
    covering the majority of research being done, there are several practical considerations
    for developing and deploying DL enabled applications that we must consider. In
    this section we outline the main practical research areas that are impacting DL
    enabled application development pipelines and suggest where we might look next.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今讨论了AL的核心工作、模型解释和预测细化，虽然上述讨论的工作在覆盖大部分研究方面做得很好，但在开发和部署DL驱动的应用时，我们必须考虑几个实际因素。在本节中，我们概述了影响DL驱动应用开发流程的主要实际研究领域，并建议了我们可能接下来要关注的方向。
- en: 4.1 Noisy Oracles
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 嘈杂的专家
- en: Gold-standard annotations for medical image data are acquired by aggregating
    annotations from multiple expert oracles, but as previously discussed, this is
    rarely feasible to obtain for large complex datasets due to the expertise required
    to perform such annotations. Here we ask what effect on performance we might incur
    if we acquire labels from oracles without domain expertise, and what techniques
    can we use to mitigate the suspected degradation of annotation quality when using
    non-expert oracles, to avoid any potential loss in accuracy.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 医学图像数据的金标准注释通过汇集来自多个专家的注释获得，但如前所述，由于进行这些注释所需的专业知识，这在处理大型复杂数据集时往往难以实现。在这里，我们探讨了如果从没有领域专长的专家那里获取标签，可能对性能造成的影响，以及我们可以使用哪些技术来缓解使用非专家注释时质量下降的可能性，以避免准确性潜在的损失。
- en: '[[103](#bib.bib103)] propose active learning method that assume data will be
    annotated by a crowd of non-expert or ’weak’ annotators, and offer approaches
    to mitigate the introduction of bad labels into the data set. They simultaneously
    learn about the quality of individual annotators so that the most informative
    examples can be labelled by the strongest annotators.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[[103](#bib.bib103)] 提出了主动学习方法，该方法假设数据将由一群非专家或“弱”标注者进行标注，并提供了缓解数据集中不良标签引入的方法。他们同时了解每个标注者的质量，以便最具信息性的示例可以由最强的标注者进行标注。'
- en: '[[48](#bib.bib48)] propose methods for crowd-sourced learning in two scenarios.
    Firstly, they aim at inferring instances ground truth given the crowd’s annotations
    by modelling the crowd’s expertise and label correlations from two different perspectives:
    firstly they model expertise based on individual labels, based on the idea that
    labeller’s annotations for similar instances should be similar, and secondly through
    modelling the crowd’s expertise to distinguish the relevance between label pairs.
    They extend their approach to the active paradigm and offer criteria for instance,
    label and labeller selected in tandem to minimise annotation cost.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[[48](#bib.bib48)] 提出了两种情况下的众包学习方法。首先，他们旨在通过从两个不同的角度建模人群的专业知识和标签相关性，推断实例的真实情况：首先，他们基于单个标签建模专业知识，基于这样一个理念，即标注者对类似实例的标注应该相似，其次，通过建模人群的专业知识来区分标签对之间的相关性。他们将其方法扩展到主动学习范式，并提供了实例、标签和标注者同时选择的标准，以最小化标注成本。'
- en: '[[15](#bib.bib15)] explore using Amazon’s MTurk to gather annotations of airways
    in CT images. Results showed that the novice oracles were able to interpret the
    images, but that instructions provided were too complex, leading to many unusable
    annotations. Once the bad annotations were removed, the annotations did show medium
    to high correlation with expert annotations, especially if annotations were aggregated.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[[15](#bib.bib15)] 探讨了使用亚马逊的MTurk来收集CT图像中的气道标注。结果显示，尽管新手标注者能够解释图像，但所提供的说明过于复杂，导致许多标注不可用。一旦删除了不良标注，这些标注与专家标注之间的相关性中等至高，尤其是当标注被聚合时。'
- en: '[[72](#bib.bib72)] describe an approach to assess the reliability of annotators
    in a crowd, and a crowd layer used to train deep models from noisy labels from
    multiple annotators, internally capturing the reliability and biases of different
    annotators to achieve state-of-the-art results for several crowd-sourced data-set
    tasks.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[[72](#bib.bib72)] 描述了一种评估人群中标注者可靠性的方法，并使用一个人群层来训练深度模型，以处理来自多个标注者的噪声标签，内部捕捉不同标注者的可靠性和偏见，从而在多个众包数据集任务中实现了最先进的结果。'
- en: We can see that by using a learned model of oracle annotation quality we can
    mitigate the effects of low quality annotations and present the most challenging
    cases to most capable oracles. By providing clear instructions we can lower the
    barriers for non-expert oracles to perform accurate annotation, but this is not
    generalisable and would be required for every new annotation task we wish to perform.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，通过使用学习到的标注质量模型，我们可以减轻低质量标注的影响，并将最具挑战性的案例呈现给最有能力的标注者。通过提供清晰的说明，我们可以降低非专家标注者进行准确标注的障碍，但这不能普遍适用，每个新的标注任务都需要这种说明。
- en: 4.2 Weakly Supervised Learning
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 弱监督学习
- en: Most segmentation tasks require pixel-wise annotations, but these are not the
    only type of annotation we can give an image. Segmentation can be performed with
    ’weak’ annotations, which include image level labels e.g. modality, organs present
    etc. and annotations such as bounding boxes, ellipses or scribbles. It is argued
    that using ’weaker’ annotation formulations can make the task easier for the human
    oracle, leading to more accurate annotations. ’Weak’ annotations have been shown
    to perform well in several segmentation tasks, [[70](#bib.bib70)] demonstrate
    obtaining pixel-wise segmentations given a data-set of images with ’weak’ bounding
    box annotations. They propose DeepCut, an architecture that combines a CNN with
    an iterative dense CRF formulation to achieve good accuracy while greatly reducing
    annotation effort required. In a later study, [[69](#bib.bib69)] examine the impact
    of expertise required for different ’weak’ annotation types on the accuracy of
    liver segmentations. The results showed a decrease in accuracy with less expertise,
    as expected, across all annotation types. Despite this, segmentation accuracy
    was comparable to state-of-the-art performance when using a weakly labelled atlas
    for outlier correction. The robust performance of their approach suggests ’weak’
    annotations from non-expert crowds could be used to obtain accurate segmentations
    on many different tasks, however their use of an atlas makes this approach less
    generalisable than is desired.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数分割任务需要逐像素标注，但这并不是我们可以对图像进行的唯一标注类型。分割可以通过“弱”标注进行，这包括图像级别的标签，如模态、存在的器官等，以及诸如边界框、椭圆或涂鸦等标注。有人认为，使用“较弱”的标注形式可以使任务对人类专家更容易，从而导致更准确的标注。“弱”标注在几个分割任务中表现良好，[[70](#bib.bib70)]展示了在给定具有“弱”边界框标注的数据集的情况下获得逐像素分割。他们提出了DeepCut，这是一种将CNN与迭代密集CRF模型结合的架构，以实现良好的准确性，同时大大减少所需的标注工作。在稍后的研究中，[[69](#bib.bib69)]研究了不同“弱”标注类型对肝脏分割准确性的影响。结果显示，随着专业知识的减少，所有标注类型的准确性都下降，这与预期一致。尽管如此，当使用弱标记的图谱进行异常值修正时，分割准确性与最先进的性能相当。他们的方法的强大性能表明，来自非专家人群的“弱”标注可以用于在许多不同任务中获得准确的分割，但他们使用图谱使得这种方法的通用性不如预期。
- en: In [[71](#bib.bib71)] they examine using super pixels to accelerate the annotation
    process. This approach uses a pre-processing step to acquire a super-pixel segmentation
    of each image, non-experts are then used to perform the annotation by selecting
    which super-pixels are part of the target region. Results showed that the approach
    largely reduces the annotation load on users. Non-expert annotation of 5000 slices
    was completed in under an hour by 12 annotators, compared to an expert taking
    three working days to establish the same with an advanced interface. The non-expert
    interface is web-based demonstrating the potential of distributed annotation collection/crowd-sourcing.
    An encouraging aspect of this paper is that the results showed high performance
    on the segmentation task in question compared with expert annotation performance,
    but may not be suitable for all medical image analysis tasks.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[71](#bib.bib71)]中，他们研究了使用超像素来加速标注过程。这种方法使用预处理步骤获取每张图像的超像素分割，然后利用非专业人员通过选择哪些超像素属于目标区域来进行标注。结果表明，这种方法大大减少了用户的标注负担。12名标注员在不到一小时内完成了5000张切片的非专业标注，而专家使用高级界面则需要三天工作时间才能完成相同的工作。非专业人员界面是基于网络的，展示了分布式标注收集/众包的潜力。这篇论文的一个鼓舞人心的方面是，结果显示在分割任务上的表现与专家标注相比表现良好，但可能并不适用于所有医学图像分析任务。
- en: It has been shown that we can develop high performing models using weakly annotated
    data, and as weak annotations requires less expertise to perform, they can be
    acquired faster and from a non-expert crowd with a smaller loss in accuracy than
    gold-standard annotations. This is very promising for future research as datasets
    of weakly annotated data might be much easier and more cost-effective to curate.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 已经证明，我们可以利用弱标注数据开发高性能模型，且由于弱标注所需的专业知识较少，它们可以更快地从非专业人群中获取，且比黄金标准标注的准确性损失更小。这对未来的研究非常有前景，因为弱标注数据集可能更容易且更具成本效益地进行整理。
- en: 4.3 Multi-task learning
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 多任务学习
- en: Many works aim to train models or acquire training data for several tasks at
    once, it is argued that this can save on cost as complementary information may
    result in higher performance over multiple different tasks [[59](#bib.bib59)].
    [[89](#bib.bib89)] propose a dual network for joint segmentation and detection
    task for lung nodule segmentation and cochlea segmentation from CT images, where
    only a part of the data is densely annotated and the rest is weakly labelled by
    bounding boxes, using this they show that their architecture out-performs several
    baselines. At present this work only handles the case for two different label
    types but they propose extending the framework for a true multi-task scenario.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究旨在同时训练模型或获取多任务的训练数据，有人认为这可以节省成本，因为互补的信息可能会提高在多个不同任务上的性能[[59](#bib.bib59)]。[[89](#bib.bib89)]
    提出了一个双网络模型，用于肺结节分割和耳蜗从CT图像中分割的联合任务，其中只有一部分数据被密集标注，其余部分通过边界框进行弱标注，他们展示了他们的架构在多个基准测试中的表现优于其他模型。目前，这项工作仅处理了两种不同标签类型的情况，但他们提出了将框架扩展到真正的多任务场景的建议。
- en: This is a promising area but, as of yet, it has not been incorporated into an
    active learning setting. As such, it may be elucidating to analyse the differences
    in samples chosen by different AL methods when the model is being training for
    multiple tasks simultaneously. However, [[53](#bib.bib53)] raise concerns over
    the transferability of actively acquired datasets to future models due to the
    inherent coupling between active learning selection strategies and the model being
    trained, and show that training a successor model on the actively acquired dataset
    can often result in worse performance than from random sampling. They suggest
    that, as datasets begin to outlive the models trained on them, there is a concern
    for the efficacy of active learning, since the acquired dataset may be disadvantageous
    for training subsequent models. An exploration of how actively acquired datasets
    perform on multiple models may be required to explain the effects of an actively
    acquired dataset coupled with one model on the performance of related models.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有前景的领域，但迄今为止，它尚未融入主动学习环境中。因此，分析不同主动学习方法在模型同时训练多个任务时选择的样本之间的差异可能是有启发性的。然而，[[53](#bib.bib53)]
    对主动获取数据集在未来模型中的转移性提出了担忧，因为主动学习选择策略与正在训练的模型之间的固有耦合，并且显示了在主动获取的数据集上训练继任模型通常会导致比随机采样更差的性能。他们建议，随着数据集开始超越训练它们的模型，存在对主动学习有效性的担忧，因为获取的数据集可能对训练后续模型不利。可能需要探讨主动获取的数据集在多个模型上的表现，以解释主动获取的数据集与一个模型耦合对相关模型性能的影响。
- en: 4.4 Annotation Interface
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 注释界面
- en: So far the majority of Human-in-the-loop methods assume a significant level
    of interaction from an oracle to annotate data and model predictions, but few
    consider the nature of the interface with which an oracle might interact with
    these images. The nature of medical images require special attention when proposing
    distributed online platforms to perform such annotations. While the majority of
    techniques discussed so far have used pre-existing data labels in place of newly
    acquired labels to demonstrate their performance, it is important to consider
    the effects of accuracy of annotation that the actual interface might incur.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，大多数“人机协作”方法假设来自神谕的显著交互来标注数据和模型预测，但很少考虑神谕与这些图像交互的界面的性质。医学图像的性质要求在提出分布式在线平台进行这种标注时给予特别关注。尽管到目前为止讨论的大多数技术已经使用了预先存在的数据标签来展示其性能，但考虑实际界面可能引发的标注准确性问题是很重要的。
- en: '[[61](#bib.bib61)] propose a framework for the online classification of Whole-slide
    images (WSIs) of tissues. Their interface enables users to rapidly build classifiers
    using an active learning process that minimises labelling efforts and demonstrates
    the effectiveness of their solution for the quantification of glioma brain tumours.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[[61](#bib.bib61)] 提出了一个用于组织切片图像（WSIs）在线分类的框架。他们的界面使用户能够快速构建分类器，使用一个减少标注工作量的主动学习过程，并展示了他们的解决方案在胶质瘤脑肿瘤定量化中的有效性。'
- en: '[[35](#bib.bib35)] propose a novel interface for the segmentation of images
    that tracks the users gaze to initiate seed points for the segmentation of the
    object of interest as the only means of interaction with the image, achieving
    high segmentation performance. [[82](#bib.bib82)] extend this idea and compare
    using eye tracking generated training samples to traditional hand annotated training
    samples for training a DL model. They show that almost equivalent performance
    was achieved using annotation generated through eye tracking, and suggest that
    this approach might be applicable to rapidly generate training data. They acknowledge
    that there is still improvements to be made integrate eye tracking into typical
    clinical radiology work flow in a faster, more natural and less distracting way.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[[35](#bib.bib35)] 提出了一个新颖的图像分割界面，该界面通过跟踪用户的视线来启动种子点，以进行感兴趣对象的分割，这是与图像交互的唯一方式，从而实现了高分割性能。[[82](#bib.bib82)]
    扩展了这一思想，并将使用眼动追踪生成的训练样本与传统手动标注的训练样本进行比较，以训练深度学习模型。他们展示了使用眼动追踪生成的标注获得了几乎等同的性能，并建议这种方法可能适用于快速生成训练数据。他们承认，将眼动追踪更快、更自然、减少干扰地整合到典型的临床放射学工作流程中仍有改进的空间。'
- en: '[[87](#bib.bib87)] evaluate the player motivations behind EyeWire, an online
    game that asks a crowd of players to help segment neurons in a mouse brain. The
    gamification of this task has seen over 500,000 players sign up and the segmentations
    acquired have gone onto be used in several research works [[[36](#bib.bib36)]].
    One of the most exciting things about gamification is that when surveyed, users
    were motivated most by making a scientific contribution rather than any potential
    monetary reward. However this is very specialised towards this particular task
    and would be difficult to apply across other types of medical image analysis tasks.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[[87](#bib.bib87)] 评估了 EyeWire 这款在线游戏背后的玩家动机，该游戏要求大量玩家帮助分割小鼠大脑中的神经元。该任务的游戏化使超过
    500,000 名玩家注册参与，而获得的分割结果已被用于若干研究工作 [[[36](#bib.bib36)]]. 游戏化的一个令人兴奋的方面是，当被调查时，用户最受激励的是进行科学贡献，而不是任何潜在的金钱奖励。然而，这对于特定任务来说非常专业，难以应用于其他类型的医学图像分析任务。'
- en: There are many different approaches to developing annotation interfaces and
    the ones we consider above are just a few that have been applied to medical image
    analysis. As development increases we expect to see more online tools being used
    for medical image analysis and the chosen format of the interface will play a
    large part in the usability and overall success of these applications.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 开发标注界面有许多不同的方法，我们上面提到的只是应用于医学图像分析的一些方法。随着开发的增加，我们预计会看到更多在线工具被用于医学图像分析，而界面的选择格式将在这些应用程序的可用性和整体成功中发挥重要作用。
- en: 4.5 Variable Learning Costs
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 变量学习成本
- en: When acquiring training data from various types of oracle it is worth considering
    the relative cost associated with querying a particular oracle type for that annotation.
    We may wish to acquire more accurate labels from an expert oracle, but this is
    likely more expensive to obtain than from a non-expert oracle. The trade off,
    of course, being accuracy of the obtained label - less expertise of the oracle
    will likely result in a lower quality of annotation. Several methods have been
    proposed to model this and allow developers to trade off between cost and overall
    accuracy of acquired annotations.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在从各种类型的预言机获取训练数据时，值得考虑与查询特定预言机类型相关的相对成本。我们可能希望从专家预言机那里获得更准确的标签，但这可能比从非专家预言机那里获得的成本更高。当然，权衡的是所获得标签的准确性——预言机的专业性较低可能会导致标注质量较差。已经提出了几种方法来建模这一点，并允许开发人员在成本和获得标注的整体准确性之间进行权衡。
- en: '[[42](#bib.bib42)] propose a cost-sensitive active learning approach for intracranial
    haemorrhage detection. Since annotation time may vary significantly across examples,
    they model the annotation time and optimize the return on investment. They show
    their approach selects a diverse and meaningful set of samples to be annotated,
    relative to a uniform cost model, which mostly selects samples with massive bleeds
    which are time consuming to annotate.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[[42](#bib.bib42)] 提出了一个针对颅内出血检测的成本敏感型主动学习方法。由于标注时间在不同示例之间可能显著不同，他们对标注时间进行了建模，并优化了投资回报。他们展示了他们的方法选择了一组多样且有意义的样本进行标注，相较于均匀成本模型，这种模型主要选择了大量出血的样本，这些样本标注起来耗时较长。'
- en: '[[77](#bib.bib77)] propose a budget based cost minimisation framework in a
    mixed-supervision setting (strong and weak annotations) via dense segmentation,
    bounding boxes, and landmarks. Their framework uses an uncertainty and a representativeness
    ranking strategy to select samples to be annotated next. They demonstrate state-of-the-art
    performance at a significantly reduced training budget, highlighting the important
    role of choice of annotation type on the costs of acquiring training data.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[[77](#bib.bib77)] 提出了一个基于预算的成本最小化框架，在混合监督设置（强标注和弱标注）下，通过密集分割、边界框和标志点实现。他们的框架使用不确定性和代表性排名策略来选择下一步需要标注的样本。他们展示了在显著减少训练预算的情况下达到最先进的性能，突显了标注类型对获取训练数据成本的重要影响。'
- en: The above works each show an improved consideration for the economic burden
    that is incurred when curating training data. A valuable research direction would
    be to assess the effects of oracle expertise level, annotation type and image
    annotation cost in a unified framework as these three factors are very much linked
    and may have a profound influence over each other.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 上述工作都更好地考虑了在整理训练数据时产生的经济负担。一个有价值的研究方向是评估在统一框架中，oracle 专家水平、标注类型和图像标注成本的影响，因为这三个因素紧密相关，并且可能相互影响。
- en: 5 Future Prospective and Unanswered Questions
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 未来展望和未解答的问题
- en: 'In Sections [2](#S2 "2 Active Learning ‣ A Survey on Active Learning and Human-in-the-Loop
    Deep Learning for Medical Image Analysis1footnote 11footnote 1") & [3](#S3 "3
    The Final Percent: Interactive refinement of model outputs ‣ A Survey on Active
    Learning and Human-in-the-Loop Deep Learning for Medical Image Analysis1footnote
    11footnote 1") we discuss methods through which a user might gather training data
    to build a model, use their model to predict on new data and receive feedback
    to iteratively refine the model output towards a more accurate result. Each of
    these techniques assume some human end user will be present to interact with the
    system at the point of initial annotation, interpretation and refinement. Each
    of these areas seeks to achieve a shared goal of achieving the highest performing
    model from as little annotated data as possible - with a means to weigh conclusions
    of models predictions appropriately.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '在[2](#S2 "2 Active Learning ‣ A Survey on Active Learning and Human-in-the-Loop
    Deep Learning for Medical Image Analysis1footnote 11footnote 1")和[3](#S3 "3 The
    Final Percent: Interactive refinement of model outputs ‣ A Survey on Active Learning
    and Human-in-the-Loop Deep Learning for Medical Image Analysis1footnote 11footnote
    1")节中，我们讨论了用户如何收集训练数据以构建模型，使用模型对新数据进行预测，并接收反馈以迭代地优化模型输出以获得更准确的结果。每种技术都假设有一些人类最终用户会在初次标注、解释和优化的过程中与系统互动。这些领域都旨在实现一个共同的目标，即从尽可能少的标注数据中获得性能最优的模型，并以适当的方式权衡模型预测的结论。'
- en: AL is not the only area of research that aim to learn from limited data. Semi-supervised
    learning, and Transfer Learning both make significant contributions to extracting
    the most value from limited labelled data.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 主动学习并不是唯一一个旨在从有限数据中学习的研究领域。半监督学习和迁移学习都在从有限标记数据中提取最大价值方面做出了重要贡献。
- en: In the presence of large data-sets, but the absence of labels, unsupervised
    and semi-supervised approaches offer a means by which information can be extracted
    without requiring labels for all the data-points. This could potentially have
    a massive impact on the medical image analysis field where this is often the case.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在大数据集存在但标签缺失的情况下，无监督和半监督方法提供了一种在不要求所有数据点都有标签的情况下提取信息的手段。这可能对医学图像分析领域产生巨大影响，因为在这个领域中这种情况经常发生。
- en: 'In a semi-supervised learning (SSL) scenario we may have some labelled data,
    but this is often very limited. We do however have a large set of un-annotated
    instances (much like in active learning) to draw information from, the goal being
    to improve a model (trained only on the labelled instances) using the un-labelled
    instances. From this we derive two distinct goals: a) predicting labels for future
    data (inductive SSL) and b) predicting labels for the available un-annotated data
    (transductive SSL) ([[14](#bib.bib14), [98](#bib.bib98)]). SSL methods provide
    a powerful way of extracting useful information from un-annotated image data and
    we believe that progress in this area will be beneficial to AL systems that desire
    a more accurate model for initialisation to guide data selection strategies.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在半监督学习（SSL）场景中，我们可能有一些标注数据，但通常非常有限。然而，我们确实有大量未标注的实例（类似于主动学习）可以获取信息，目标是利用未标注的实例来改善一个仅基于标注实例训练的模型。由此，我们得出两个不同的目标：a）为未来数据预测标签（归纳SSL），b）为现有未标注数据预测标签（传导SSL）([[14](#bib.bib14)、[98](#bib.bib98)]）。SSL方法提供了一种从未标注图像数据中提取有用信息的强大方式，我们相信这一领域的进展将对希望获得更准确初始化模型以指导数据选择策略的主动学习系统有益。
- en: Transfer Learning (TL) is a branch of DL that aim to use pre-trained networks
    as a starting point for new applications. Given a pre-trained network trained
    for a particular task, it has been shown that this network can be ’fine-tuned’
    towards a target task from limited training data. We refer the reader to [[60](#bib.bib60),
    [68](#bib.bib68), [14](#bib.bib14)] for a more general overview of transfer learning
    in medical imaging, and focus on the use of TL in AL scenarios in the following.
    [[86](#bib.bib86)] demonstrated the applicability of TL for a variety of medical
    image analysis tasks, and show, despite the large differences between natural
    images and medical images, CNNs pre-trained on natural images and fine-tuned on
    medical images can perform better than medical CNNs trained from scratch. This
    performance boost was greater where fewer target task training examples were available.
    Many of the methods discussed so far start with a network pre-trained on natural
    image data.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习（TL）是深度学习（DL）的一个分支，旨在使用预训练网络作为新应用的起点。对于一个为特定任务训练的预训练网络，已有研究表明，该网络可以通过有限的训练数据“微调”到目标任务。我们建议读者参考[[60](#bib.bib60)、[68](#bib.bib68)、[14](#bib.bib14)]以获得关于医学影像中迁移学习的更一般概述，以下内容则重点讨论迁移学习在主动学习（AL）场景中的应用。[[86](#bib.bib86)]展示了迁移学习在多种医学图像分析任务中的适用性，并表明，尽管自然图像和医学图像之间存在较大差异，但在自然图像上预训练并在医学图像上微调的卷积神经网络（CNN）表现优于从头开始训练的医学CNN。这种性能提升在目标任务训练样本较少的情况下尤为明显。迄今为止讨论的许多方法都以自然图像数据上预训练的网络为起点。
- en: '[[107](#bib.bib107)] propose AFT*, a platform that combines AL and TL to reduce
    annotation efforts, which aims at solving several problems within AL. AFT* starts
    with a completely empty labelled data-set, requiring no seed samples. A pre-trained
    CNN is used to seek ’worthy’ samples for annotation and to gradually enhance the
    CNN via continuous fine-tuning. A number of steps are taken to minimise the risk
    of catastrophic forgetting. Their previous work [[109](#bib.bib109)] applies a
    similar but less featureful approach to several medical image analysis tasks to
    demonstrate equivalent performance can be reached with a heavily reduced training
    data-set. They then use these tasks to evaluate several patterns of prediction
    that the network exhibits and how these relate to the choice of AL selection criteria.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[[107](#bib.bib107)] 提出了 AFT*，一个结合了主动学习和迁移学习的平台，以减少标注工作，旨在解决主动学习中的几个问题。AFT*
    从一个完全空白的标注数据集开始，无需种子样本。使用预训练的CNN来寻找“有价值”的样本进行标注，并通过持续的微调逐步增强CNN。采取了若干步骤以最小化灾难性遗忘的风险。他们的先前工作[[109](#bib.bib109)]应用了类似但功能较少的方法于若干医学图像分析任务，以展示在大幅减少训练数据集的情况下仍能达到相当的性能。然后，他们使用这些任务来评估网络所表现出的几种预测模式以及这些模式与主动学习选择标准之间的关系。'
- en: '[[108](#bib.bib108)] have gone onto to use their AFT framework for annotation
    of CIMT videos, a clinical technique for characterisation of Cardiovascular disease.
    Their extension into the video domain presents its own unique challenges and thus
    they propose a new concept of an Annotation Unit - reducing annotating a CIMT
    video to just 6 user mouse clicks, and by combining this with their AFT framework
    reduce annotation cost by 80% relative to training from scratch and by 50% relative
    to random selection of new samples to be annotated (and used for fine-tuning).'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[[108](#bib.bib108)] 使用他们的AFT框架对CIMT视频进行标注，CIMT是一种用于表征心血管疾病的临床技术。他们将该框架扩展到视频领域，提出了独特的挑战，因此他们提出了一个新的概念：标注单元——将标注CIMT视频减少到仅需6次用户鼠标点击，并通过将其与AFT框架结合，将标注成本降低80%（相对于从头开始训练）以及50%（相对于随机选择新样本进行标注并用于微调）。'
- en: '[[44](#bib.bib44)] use TL for supervised domain adaptation for sub-cortical
    brain structure segmentation with minimal user interaction. They significantly
    reduce the number of training images from different MRI imaging domains by leveraging
    a pre-trained network and improve training speed by reducing the number of trainable
    parameters in the CNN. They show their method achieves similar results to their
    baseline while using a remarkably small amount of images from the target domain
    and show that using even one image from the target domain was enough to outperform
    their baseline.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[[44](#bib.bib44)] 使用迁移学习（TL）进行有监督的领域自适应，以实现对皮层下脑结构的分割，并尽量减少用户交互。他们通过利用预训练网络显著减少了来自不同MRI成像领域的训练图像数量，并通过减少CNN中的可训练参数数量来提高训练速度。他们的研究表明，使用来自目标领域的少量图像即可获得与基准方法相当的结果，并且显示出即使使用一张来自目标领域的图像也足以超越其基准方法。'
- en: The above methods and more discussed in this review demonstrate the applicability
    of TL to reducing the number of annotated sample required to train a model on
    a new task from limited training data. By using pre-trained networks trained on
    annotated natural image data (there is an abundance) we can boost model performance
    and further reduce the annotation effort required to achieve state-of-the-art
    performance.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 上述方法及本综述中讨论的更多方法展示了迁移学习（TL）在减少用于训练新任务的标注样本数量方面的适用性。通过使用在标注自然图像数据（这种数据非常丰富）上训练的预训练网络，我们可以提升模型性能，并进一步减少实现最先进性能所需的标注工作。
- en: A related sub-field of TL worth exploring is domain adaptation (DA). Many DL
    techniques used in medical image analysis suffer from the domain shift problem
    caused by different distributions between source data and target data, often due
    to medical images being acquired on a variety of different scanners, scanning
    parameters and subject cohorts etc. DA has been proposed as a special type of
    transfer learning in which the domain feature space and tasks remain the same
    while marginal distributions of the source and target domains are different. We
    refer the reader to [[27](#bib.bib27), [16](#bib.bib16)] for an overview of DA
    methods used for medical image analysis, and hope to see greater application of
    DA methods in AL scenarios in the future.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习（TL）中的一个相关子领域是领域自适应（DA）。许多用于医学图像分析的深度学习（DL）技术由于源数据和目标数据之间的不同分布而受到领域偏移问题的困扰，这通常是由于医学图像是在各种不同的扫描仪、扫描参数和受试者群体等下获取的。领域自适应被提出为一种特殊类型的迁移学习，其中领域特征空间和任务保持不变，而源领域和目标领域的边际分布不同。我们推荐读者参考
    [[27](#bib.bib27), [16](#bib.bib16)] 以了解用于医学图像分析的领域自适应方法，并希望未来在主动学习场景中能看到更多领域自适应方法的应用。
- en: 'In many of scenarios described in this review, models continuously receive
    new annotations to be used for training, and in theory we could continue to retrain
    or fine-tune a model indefinitely, but is this practical and cost effective? It
    is important to quantify the long term effects of training a model with new data
    to assess how the model changes over time and whether or not performance has improved,
    or worse, declined. Learning from continuous streams of data has proven more difficult
    than anticipated, often resulting in ’catastrophic forgetting’ or ’interference’
    [[66](#bib.bib66)]. We face the stability-plasticity-dilemma. Avoiding catastrophic
    forgetting in neural networks when learning from continuous streams of data can
    be broadly divided among three conceptual strategies: a) Retraining the the whole
    network while regularising (to prevent forgetting of previously learned tasks).
    b) selectively train the network and expand it if needed to represent new tasks,
    and c) retaining previous experience to use memory replay to learn in the absence
    of new input. We refer the reader to [[66](#bib.bib66)] for a more detailed overview
    of these approaches.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在本综述中描述的许多场景中，模型不断接收新的注释用于训练，理论上我们可以无限期地继续重新训练或微调模型，但这是否实际和成本有效？量化使用新数据训练模型的长期效果很重要，以评估模型随时间的变化以及性能是否有所改善，或更糟，是否下降。从连续数据流中学习比预期的更为困难，常常导致‘灾难性遗忘’或‘干扰’[[66](#bib.bib66)]。我们面临稳定性-可塑性困境。在从连续数据流中学习时，避免神经网络的灾难性遗忘可以大致分为三种概念策略：a)
    重新训练整个网络，同时进行正则化（以防止遗忘之前学习的任务）。b) 有选择性地训练网络并根据需要扩展以表示新任务，c) 保留先前经验以利用记忆重放在没有新输入的情况下进行学习。有关这些方法的详细概述，请参阅[[66](#bib.bib66)]。
- en: '[[7](#bib.bib7)] investigate continual learning of two MRI segmentation tasks
    with neural networks for countering catastrophic forgetting of the first task
    when a new one is learned. They investigate elastic weight consolidation, a method
    based on Fisher information to sequentially learn segmentation of normal brain
    structures and then segmentation of white matter lesions and demonstrate this
    method reduces catastrophic forgetting, but acknowledge there is a large room
    for improvement for the challenging setting of continual learning.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[[7](#bib.bib7)] 研究了使用神经网络对两个MRI分割任务进行持续学习，以应对在学习新任务时第一个任务的灾难性遗忘。他们研究了弹性权重巩固，这是一种基于Fisher信息的方法，用于顺序学习正常脑结构的分割，然后是白质病变的分割，并证明这种方法可以减少灾难性遗忘，但承认在持续学习的挑战性设置中仍有很大的改进空间。'
- en: It is important to quantify the performance and robustness of a model at every
    stage of its lifespan. One way to consider stopping could evaluate when the cost
    of continued training outweighs the cost of errors made by the current model.
    An existing measure that attempts to quantify the economical value of medical
    intervention is the Quality-adjusted Life year (QALY), where one QALY equates
    to one year of healthy life [[62](#bib.bib62)]. Could this metric be incorporated
    into models? At present we cannot quantify the cost of errors made by DL medical
    imaging applications but doing so could lead to a deeper understanding of how
    accurate a DL model really ought to be.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型生命周期的每个阶段量化其性能和鲁棒性非常重要。考虑停止的一个方法可能是评估继续训练的成本是否超过当前模型错误的成本。一种试图量化医疗干预经济价值的现有度量是质量调整生命年（QALY），其中一个QALY等于一年的健康生活[[62](#bib.bib62)]。这个指标可以纳入模型中吗？目前我们无法量化深度学习医疗影像应用中出现的错误成本，但这样做可能会深入了解深度学习模型真正应有的准确度。
- en: As models are trained on more of the end user’s own data, will this cause the
    network to perform better on data from that user’s system despite performing worse
    on data the model was initially trained on? Catastrophic forgetting suggests this
    will be the case, but is this a bad thing? It may be beneficial for models to
    gradually bias themselves towards high performance for the end user’s own data,
    even if this results in the model becoming less transferable to other data. [[23](#bib.bib23)]
    explore the role of bias in AL methods. Bias is introduced because the training
    data no longer follows the population distribution in AL. The authors providing
    a general method by which unbiased AL estimators may be constructed using novel
    corrective weights to remove bias. Further to this, an explanation of the empirical
    successes of existing AL methods which ignore this bias is provided. It is shown
    that bias introduced by AL methods can be actively helpful when training overparameterized
    models like neural networks with relatively little data. This further motivates
    future work to better understand when the bias introduced by AL could have a positive
    influence on the performance of AL methods, to the detriment of generalisability
    to other data sources.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型在更多终端用户的数据上进行训练，这是否会导致网络在该用户系统的数据上表现更好，尽管在模型最初训练的数据上表现更差？灾难性遗忘理论表明，这可能是事实，但这真的是一件坏事吗？即使这会导致模型对其他数据的迁移能力下降，模型逐渐偏向于对终端用户自身数据的高性能可能是有益的。[[23](#bib.bib23)]
    探讨了在主动学习（AL）方法中偏差的作用。偏差的引入是因为训练数据不再遵循主动学习中的总体分布。作者提供了一种通用的方法，通过使用新颖的纠正权重来去除偏差，从而构建无偏差的主动学习估计器。进一步解释了现有忽略这种偏差的主动学习方法的实证成功。研究表明，主动学习方法引入的偏差在训练过参数的模型（如神经网络）时，尤其是在相对较少的数据情况下，可以积极地发挥作用。这进一步激励了未来的工作，以更好地理解主动学习中引入的偏差何时可能对主动学习方法的性能产生积极影响，尽管这可能会对其他数据源的泛化能力造成不利影响。
- en: Active learning assumes the presence of a user interface to perform annotations
    but is only concerned with which data to annotate. Refinement assumes we can generate
    an annotation through iterative interaction with the current model prediction.
    Hence, it would be desirable to combine these two in future work. If we can train
    a model with a tiny amount of training data, and then ask annotators to refine
    model predictions towards a more accurate label, we can expedite the annotation
    process by reducing the initial annotation workload and reduce additional interface
    work for use with unseen data. This would be the same interface used to create
    the training annotations. By combining the efforts of active learning and iterative
    refinement into a unified framework we can rapidly produce annotations to train
    our model, as well as acquiring high quality results from our models from the
    beginning. This should also have the added side effect of training the model on
    data from the same distribution that it will be predicting on, reducing domain
    shift effects in unseen distributions.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 主动学习假设存在一个用户界面来执行注释，但只关注哪些数据需要注释。精炼则假设我们可以通过与当前模型预测的迭代交互生成注释。因此，未来的工作中将这两者结合起来是理想的。如果我们可以用极少量的训练数据训练模型，然后要求注释者将模型预测精炼为更准确的标签，我们可以通过减少初始注释工作量和减少对未见数据的额外界面工作的需求来加速注释过程。这将是用于创建训练注释的相同界面。通过将主动学习和迭代精炼的努力结合成一个统一的框架，我们可以快速生成注释来训练我们的模型，同时从一开始就获得高质量的结果。这还应该有一个附加的副作用，即使模型在将来预测时数据来自相同的分布，减少未见分布中的领域转移效应。
- en: By incorporating our end user at each stage of the model life cycle we could
    also use human feedback on model performance to add a more ’human interpretable’
    metric of model confidence as each user could rank the performance of the model
    for each input as it sees it, potentially giving a metric of confidence based
    on human interpretation of the model output. This of course requires experts to
    be using the system.One might argue that the models initial predictions may impart
    some influence over the human user but by crowd-sourcing the initial annotations
    to a less expert multi-label crowd we could reduce this bias.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在模型生命周期的每个阶段纳入我们的终端用户，我们还可以使用人类反馈来添加一个更“人类可解释”的模型置信度度量，因为每个用户可以对每个输入的模型性能进行排序，从而可能基于人类对模型输出的解释提供置信度度量。当然，这需要专家使用系统。有人可能会争辩说，模型的初步预测可能对人类用户产生一定影响，但通过将初步注释众包给不太专业的多标签众包群体，我们可以减少这种偏差。
- en: Developments in uncertainty quantification will benefit both AL selection heuristics
    and interpretation of model outputs, but there is no guarantee that the best performing
    uncertainty metrics for selecting new samples to be annotated will be the same
    metrics that are the most interpretable to a human user.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定性量化的发展将有利于AL选择启发式方法和模型输出的解释，但无法保证用于选择新样本进行标注的最佳不确定性度量将是对人类用户最具解释性的度量。
- en: Figure [4](#Sx2.F4 "Fig. 4 ‣ Supplementary Material ‣ A Survey on Active Learning
    and Human-in-the-Loop Deep Learning for Medical Image Analysis1footnote 11footnote
    1") outlines the core methods being used in human-in-the-loop computing for each
    of the papers discussed in this review. This figure shows that there is significant
    overlap of research goals for many areas of human-in-the-loop computing but there
    are large gaps that need to be filled in order to understand the relationships
    between different methods and how these might affect their performance.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图[4](#Sx2.F4 "Fig. 4 ‣ Supplementary Material ‣ A Survey on Active Learning
    and Human-in-the-Loop Deep Learning for Medical Image Analysis1footnote 11footnote
    1")概述了本综述中讨论的每篇论文中用于人机交互计算的核心方法。该图表明，许多人机交互计算领域的研究目标有显著重叠，但也存在较大的空白，需要填补，以理解不同方法之间的关系以及这些关系如何影响它们的性能。
- en: As the many areas of DL research converge towards shared goals of working with
    limited training data to achieve state-of-the-art results, we expect to see more
    systems emerge that exploit the advances made in the range of sub-fields of ML
    described here. We have already seen the combination of several methods into individual
    frameworks but as of yet no works combine all of the approaches discussed into
    a single framework. As different combinations of approaches begin to appear it
    is important to consider the measure by which we assess their performance, as
    isolating individual developments becomes more difficult. Developing baseline
    human-in-the-loop methods to compare to will be vital to assess the contributions
    of individual works in each area and to better understand the influences of competing
    improvements in these areas.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习研究的许多领域朝着使用有限训练数据实现最先进结果的共同目标汇聚，我们预计会看到更多系统出现，利用在此描述的机器学习子领域中的进展。我们已经看到将几种方法组合成单个框架的情况，但到目前为止，还没有将讨论的所有方法组合成一个单一框架的工作。随着不同组合方法的出现，考虑我们评估其性能的度量变得重要，因为隔离个别发展的难度增加。开发基线人机交互方法进行比较将对评估每个领域的个别工作贡献以及更好地理解这些领域中竞争性改进的影响至关重要。
- en: 6 Conclusions
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this review we have explored the large body of emerging medical image analysis
    work in which a human end user is at the centre. Deep Learning has all the ingredients
    to induce a paradigm shift in our approach to a plethora of clinical tasks. The
    direct involvement of humans is set to play a core role in this shift. The works
    presented in this review each offer their own approaches to including humans in
    the loop and we suggest that there is sufficient overlap in many methods for them
    to be considered under the same title of Human-in-the-Loop computing. We hope
    to see new methodologies emerge that combine the strengths of AL and HITL computing
    into end-to-end systems for the development of deep learning applications that
    can be used in clinical practice. While there are some practical limitations as
    discussed, there are many proposed solutions to such issues and as research in
    these directions continues it is only a matter of time before deep learning applications
    blossom into fully-fledged, accurate and robust systems to be used for daily routine
    tasks. We are in an exciting era for medical image analysis, with endless opportunity
    to innovate and improve the current state-of-the-art and to leverage the powers
    of deep learning to make a real impact in health care across the board. With diligent
    research and development we should see more and more applications boosted by deep
    learning capabilities finding their way onto the market, allowing users to achieve
    better results, faster, and with less expertise than before, freeing up expert
    time to be used on the most challenging cases. The field of Human-in-the-loop
    computing will play a crucial role to achieve this.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇综述中，我们探讨了大量新兴的医学图像分析工作，其中以人为终端用户为中心。深度学习具备所有促进我们在众多临床任务中发生范式转变的要素。人类的直接参与将在这种转变中发挥核心作用。本综述中介绍的工作各自提供了将人类纳入循环的不同方法，我们认为许多方法之间存在足够的重叠，可以归纳为“人机协同计算”（Human-in-the-Loop
    computing）的同一类别。我们希望看到新的方法论出现，将主动学习（AL）和人机协同计算（HITL）的优点结合成端到端的系统，用于开发可以在临床实践中应用的深度学习应用程序。尽管如前所述存在一些实际限制，但对这些问题有许多提出的解决方案，随着这些方向上的研究不断推进，深度学习应用程序发展成成熟、准确和可靠的系统以用于日常例行任务只是时间问题。我们正处于医学图像分析的激动人心的时代，拥有无尽的创新和改善现有尖端技术的机会，并利用深度学习的力量在整个医疗保健领域产生真正的影响。通过勤奋的研究和开发，我们应该会看到越来越多的应用受益于深度学习能力，进入市场，使用户能够获得更好的结果、更快的速度，并且比以前需要更少的专业知识，从而腾出专家时间用于最具挑战性的案例。人机协同计算领域将在实现这一目标中发挥至关重要的作用。
- en: Acknowledgments
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: 'SB is supported by the EPSRC Centre for Doctoral Training in Smart Medical
    Imaging EP/S022104/1\. This work was in part supported by EP/S013687/1, Intel
    and Nvidia. We thank Innovate UK: London Medical Imaging & Artificial Intelligence
    Centre for Value-Based Healthcare [104691] for co-funding this research.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 'SB 得到了 EPSRC 智能医学成像博士生培训中心 EP/S022104/1 的支持。本工作部分得到了 EP/S013687/1、英特尔和英伟达的支持。我们感谢
    Innovate UK: 伦敦医学成像与人工智能中心（104691）对本研究的共同资助。'
- en: References
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Amrehn et al. [2017] Amrehn, M., Gaube, S., Unberath, M., Schebesch, F., Horz,
    T., Strumia, M., Steidl, S., Kowarschik, M., Maier, A., 2017. UI-Net: Interactive
    Artificial Neural Networks for Iterative Image Segmentation Based on a User Model,
    in: Bruckner, S., Hennemuth, A., Kainz, B., Hotz, I., Merhof, D., Rieder, C. (Eds.),
    Eurographics Workshop on Visual Computing for Biology and Medicine, The Eurographics
    Association. doi:[10.2312/vcbm.20171248](http://dx.doi.org/10.2312/vcbm.20171248).'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Amrehn 等人 [2017] Amrehn, M., Gaube, S., Unberath, M., Schebesch, F., Horz,
    T., Strumia, M., Steidl, S., Kowarschik, M., Maier, A., 2017. UI-Net: 基于用户模型的交互式人工神经网络用于迭代图像分割,
    in: Bruckner, S., Hennemuth, A., Kainz, B., Hotz, I., Merhof, D., Rieder, C. (Eds.),
    Eurographics 生物医学视觉计算研讨会，Eurographics 协会。doi:[10.2312/vcbm.20171248](http://dx.doi.org/10.2312/vcbm.20171248)。'
- en: 'Amrehn et al. [2019] Amrehn, M., Steidl, S., Kortekaas, R., Strumia, M., Weingarten,
    M., Kowarschik, M., Maier, A., 2019. A semi-automated usability evaluation framework
    for interactive image segmentation systems. International Journal of Biomedical
    Imaging 2019. URL: [https://pubmed.ncbi.nlm.nih.gov/31582963/](https://pubmed.ncbi.nlm.nih.gov/31582963/),
    doi:[10.1155/2019/1464592](http://dx.doi.org/10.1155/2019/1464592).'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Amrehn 等人 [2019] Amrehn, M., Steidl, S., Kortekaas, R., Strumia, M., Weingarten,
    M., Kowarschik, M., Maier, A., 2019. 用于交互式图像分割系统的半自动化可用性评估框架。国际生物医学成像杂志 2019。网址:
    [https://pubmed.ncbi.nlm.nih.gov/31582963/](https://pubmed.ncbi.nlm.nih.gov/31582963/)，doi:[10.1155/2019/1464592](http://dx.doi.org/10.1155/2019/1464592)。'
- en: 'Angluin [1988] Angluin, D., 1988. Queries and Concept Learning. Machine Learning
    2, 319–342. URL: [https://link.springer.com/article/10.1023/A:1022821128753](https://link.springer.com/article/10.1023/A:1022821128753),
    doi:[10.1023/A:1022821128753](http://dx.doi.org/10.1023/A:1022821128753).'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Angluin [1988] Angluin, D., 1988. 《查询和概念学习》。机器学习 2, 319–342。网址: [https://link.springer.com/article/10.1023/A:1022821128753](https://link.springer.com/article/10.1023/A:1022821128753)，doi:[10.1023/A:1022821128753](http://dx.doi.org/10.1023/A:1022821128753)。'
- en: 'Angluin [2001] Angluin, D., 2001. Queries revisited, in: Lecture Notes in Computer
    Science (including subseries Lecture Notes in Artificial Intelligence and Lecture
    Notes in Bioinformatics), Springer Verlag. pp. 12–31. URL: [https://link.springer.com/chapter/10.1007/3-540-45583-3_3](https://link.springer.com/chapter/10.1007/3-540-45583-3_3),
    doi:[10.1007/3-540-45583-3{\_}3](http://dx.doi.org/10.1007/3-540-45583-3_3).'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Angluin [2001] Angluin, D., 2001. 《查询回顾》，见：Lecture Notes in Computer Science（包括子系列
    Lecture Notes in Artificial Intelligence 和 Lecture Notes in Bioinformatics），Springer
    Verlag，第12–31页。网址: [https://link.springer.com/chapter/10.1007/3-540-45583-3_3](https://link.springer.com/chapter/10.1007/3-540-45583-3_3)，doi:[10.1007/3-540-45583-3{\_}3](http://dx.doi.org/10.1007/3-540-45583-3_3)。'
- en: 'Atlas et al. [1990] Atlas, L.E., Cohn, D.A., Ladner, R.E., 1990. Training connectionist
    networks with queries and selective sampling, in: Touretzky, D.S. (Ed.), Advances
    in Neural Information Processing Systems 2. Morgan-Kaufmann, pp. 566–573. URL:
    [http://papers.nips.cc/paper/261-training-connectionist-networks-with-queries-and-selective-sampling.pdf](http://papers.nips.cc/paper/261-training-connectionist-networks-with-queries-and-selective-sampling.pdf).'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Atlas 等 [1990] Atlas, L.E., Cohn, D.A., Ladner, R.E., 1990. 《通过查询和选择性采样训练联结网络》，见：Touretzky,
    D.S. (编)，《神经信息处理系统进展 2》。Morgan-Kaufmann，第566–573页。网址: [http://papers.nips.cc/paper/261-training-connectionist-networks-with-queries-and-selective-sampling.pdf](http://papers.nips.cc/paper/261-training-connectionist-networks-with-queries-and-selective-sampling.pdf)。'
- en: 'Bachman et al. [2017] Bachman, P., Sordoni, A., Trischler, A., 2017. Learning
    Algorithms for Active Learning. Technical Report. URL: [http://proceedings.mlr.press/v70/bachman17a/bachman17a.pdf](http://proceedings.mlr.press/v70/bachman17a/bachman17a.pdf).'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bachman 等 [2017] Bachman, P., Sordoni, A., Trischler, A., 2017. 《主动学习的学习算法》。技术报告。网址:
    [http://proceedings.mlr.press/v70/bachman17a/bachman17a.pdf](http://proceedings.mlr.press/v70/bachman17a/bachman17a.pdf)。'
- en: 'Baweja et al. [2018] Baweja, C., Glocker, B., Kamnitsas, K., 2018. Towards
    continual learning in medical imaging. Technical Report. URL: [https://www.doc.ic.ac.uk/~bglocker/public/mednips2018/med-nips_2018_paper_82.pdf](https://www.doc.ic.ac.uk/~bglocker/public/mednips2018/med-nips_2018_paper_82.pdf).'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Baweja 等 [2018] Baweja, C., Glocker, B., Kamnitsas, K., 2018. 《面向医学影像的持续学习》。技术报告。网址:
    [https://www.doc.ic.ac.uk/~bglocker/public/mednips2018/med-nips_2018_paper_82.pdf](https://www.doc.ic.ac.uk/~bglocker/public/mednips2018/med-nips_2018_paper_82.pdf)。'
- en: 'Beede et al. [2020] Beede, E., Baylor, E., Hersch, F., Iurchenko, A., Wilcox,
    L., Ruamviboonsuk, P., Vardoulakis, L.M., 2020. A Human-Centered Evaluation of
    a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy,
    in: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems,
    Association for Computing Machinery (ACM), New York, NY, USA. pp. 1–12. URL: [https://dl.acm.org/doi/10.1145/3313831.3376718](https://dl.acm.org/doi/10.1145/3313831.3376718),
    doi:[10.1145/3313831.3376718](http://dx.doi.org/10.1145/3313831.3376718).'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Beede 等 [2020] Beede, E., Baylor, E., Hersch, F., Iurchenko, A., Wilcox, L.,
    Ruamviboonsuk, P., Vardoulakis, L.M., 2020. 《对临床应用的深度学习系统进行以人为本的评估：用于糖尿病视网膜病变检测》，见：2020
    CHI 计算机系统人因会议论文集，计算机协会 (ACM)，纽约，NY，美国，第1–12页。网址: [https://dl.acm.org/doi/10.1145/3313831.3376718](https://dl.acm.org/doi/10.1145/3313831.3376718)，doi:[10.1145/3313831.3376718](http://dx.doi.org/10.1145/3313831.3376718)。'
- en: 'Beluch Bcai et al. [2018] Beluch Bcai, W.H., Nürnberger, A., Bcai, J.M.K.,
    2018. The power of ensembles for active learning in image classification. Technical
    Report. URL: [http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1487.pdf](http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1487.pdf).'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Beluch Bcai 等 [2018] Beluch Bcai, W.H., Nürnberger, A., Bcai, J.M.K., 2018.
    《集成方法在图像分类中的主动学习能力》。技术报告。网址: [http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1487.pdf](http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1487.pdf)。'
- en: Ben-David et al. [2010] Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A.,
    Pereira, F., Vaughan, J.W., 2010. A theory of learning from different domains.
    Machine learning 79, 151–175.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ben-David 等 [2010] Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira,
    F., Vaughan, J.W., 2010. 《来自不同领域的学习理论》。机器学习 79, 151–175。
- en: 'Bredell et al. [2018] Bredell, G., Tanner, C., Konukoglu, E., 2018. Iterative
    interaction training for segmentation editing networks, in: Lecture Notes in Computer
    Science (including subseries Lecture Notes in Artificial Intelligence and Lecture
    Notes in Bioinformatics), Springer Verlag. pp. 363–370. URL: [https://doi.org/10.1007/978-3-030-00919-9_42](https://doi.org/10.1007/978-3-030-00919-9_42),
    doi:[10.1007/978-3-030-00919-9{\_}42](http://dx.doi.org/10.1007/978-3-030-00919-9_42).'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bredell 等人 [2018] Bredell, G., Tanner, C., Konukoglu, E., 2018. 用于分割编辑网络的迭代交互训练，见：Lecture
    Notes in Computer Science（包括子系列 Lecture Notes in Artificial Intelligence 和 Lecture
    Notes in Bioinformatics），Springer Verlag. 第 363–370 页。URL: [https://doi.org/10.1007/978-3-030-00919-9_42](https://doi.org/10.1007/978-3-030-00919-9_42)，doi:[10.1007/978-3-030-00919-9{\_}42](http://dx.doi.org/10.1007/978-3-030-00919-9_42)。'
- en: 'Budd et al. [2019] Budd, S., Sinclair, M., Khanal, B., Matthew, J., Lloyd,
    D., Gomez, A., Toussaint, N., Robinson, E.C., Kainz, B., 2019. Confident head
    circumference measurement from ultrasound with real-time feedback for sonographers,
    in: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial
    Intelligence and Lecture Notes in Bioinformatics), Springer. pp. 683–691. URL:
    [https://link.springer.com/chapter/10.1007/978-3-030-32251-9_75](https://link.springer.com/chapter/10.1007/978-3-030-32251-9_75),
    doi:[10.1007/978-3-030-32251-9{\_}75](http://dx.doi.org/10.1007/978-3-030-32251-9_75).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Budd 等人 [2019] Budd, S., Sinclair, M., Khanal, B., Matthew, J., Lloyd, D.,
    Gomez, A., Toussaint, N., Robinson, E.C., Kainz, B., 2019. 从超声波中获得信心的头围测量，并为超声技师提供实时反馈，见：Lecture
    Notes in Computer Science（包括子系列 Lecture Notes in Artificial Intelligence 和 Lecture
    Notes in Bioinformatics），Springer. 第 683–691 页。URL: [https://link.springer.com/chapter/10.1007/978-3-030-32251-9_75](https://link.springer.com/chapter/10.1007/978-3-030-32251-9_75)，doi:[10.1007/978-3-030-32251-9{\_}75](http://dx.doi.org/10.1007/978-3-030-32251-9_75)。'
- en: 'Chakraborty et al. [2017] Chakraborty, S., Tomsett, R., Raghavendra, R., Harborne,
    D., Alzantot, M., Cerutti, F., Srivastava, M., Preece, A., Julier, S., Rao, R.M.,
    Kelley, T.D., Braines, D., Sensoy, M., Willis, C.J., Gurram, P., 2017. Interpretability
    of deep learning models: A survey of results, in: 2017 IEEE SmartWorld, Ubiquitous
    Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications,
    Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI),
    IEEE. pp. 1–6. URL: [https://ieeexplore.ieee.org/document/8397411/](https://ieeexplore.ieee.org/document/8397411/),
    doi:[10.1109/UIC-ATC.2017.8397411](http://dx.doi.org/10.1109/UIC-ATC.2017.8397411).'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chakraborty 等人 [2017] Chakraborty, S., Tomsett, R., Raghavendra, R., Harborne,
    D., Alzantot, M., Cerutti, F., Srivastava, M., Preece, A., Julier, S., Rao, R.M.,
    Kelley, T.D., Braines, D., Sensoy, M., Willis, C.J., Gurram, P., 2017. 深度学习模型的可解释性：结果综述，见：2017
    IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed,
    Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People
    and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)，IEEE. 第
    1–6 页。URL: [https://ieeexplore.ieee.org/document/8397411/](https://ieeexplore.ieee.org/document/8397411/)，doi:[10.1109/UIC-ATC.2017.8397411](http://dx.doi.org/10.1109/UIC-ATC.2017.8397411)。'
- en: 'Cheplygina et al. [2019] Cheplygina, V., de Bruijne, M., Pluim, J.P., 2019.
    Not-so-supervised: A survey of semi-supervised, multi-instance, and transfer learning
    in medical image analysis. Medical Image Analysis 54, 280–296. doi:[10.1016/j.media.2019.03.009](http://dx.doi.org/10.1016/j.media.2019.03.009).'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheplygina 等人 [2019] Cheplygina, V., de Bruijne, M., Pluim, J.P., 2019. 不那么监督：医学图像分析中的半监督、多实例和迁移学习综述。Medical
    Image Analysis 54, 280–296。doi:[10.1016/j.media.2019.03.009](http://dx.doi.org/10.1016/j.media.2019.03.009)。
- en: 'Cheplygina et al. [2016] Cheplygina, V., Perez-Rovira, A., Kuo, W., Tiddens,
    H.A., de Bruijne, M., 2016. Early experiences with crowdsourcing airway annotations
    in chest CT, in: Lecture Notes in Computer Science (including subseries Lecture
    Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), Springer
    Verlag. pp. 209–218. URL: [https://link.springer.com/chapter/10.1007/978-3-319-46976-8_22](https://link.springer.com/chapter/10.1007/978-3-319-46976-8_22),
    doi:[10.1007/978-3-319-46976-8{\_}22](http://dx.doi.org/10.1007/978-3-319-46976-8_22).'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cheplygina 等人 [2016] Cheplygina, V., Perez-Rovira, A., Kuo, W., Tiddens, H.A.,
    de Bruijne, M., 2016. 在胸部 CT 中早期经验与众包气道注释，见：Lecture Notes in Computer Science（包括子系列
    Lecture Notes in Artificial Intelligence 和 Lecture Notes in Bioinformatics），Springer
    Verlag. 第 209–218 页。URL: [https://link.springer.com/chapter/10.1007/978-3-319-46976-8_22](https://link.springer.com/chapter/10.1007/978-3-319-46976-8_22)，doi:[10.1007/978-3-319-46976-8{\_}22](http://dx.doi.org/10.1007/978-3-319-46976-8_22)。'
- en: 'Choudhary et al. [2020] Choudhary, A., Tong, L., Zhu, Y., Wang, M.D., 2020.
    Advancing Medical Imaging Informatics by Deep Learning-Based Domain Adaptation.
    Yearbook of medical informatics 29, 129–138. URL: [/pmc/articles/PMC7442502//pmc/articles/PMC7442502/?report=abstracthttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC7442502/](/pmc/articles/PMC7442502//pmc/articles/PMC7442502/?report=abstracthttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC7442502/),
    doi:[10.1055/s-0040-1702009](http://dx.doi.org/10.1055/s-0040-1702009).'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Choudhary 等人 [2020] Choudhary, A., Tong, L., Zhu, Y., Wang, M.D., 2020. 通过基于深度学习的领域适应推动医学影像信息学的发展。《医学信息学年鉴》29,
    129–138. URL: [/pmc/articles/PMC7442502//pmc/articles/PMC7442502/?report=abstracthttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC7442502/](/pmc/articles/PMC7442502//pmc/articles/PMC7442502/?report=abstracthttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC7442502/),
    doi:[10.1055/s-0040-1702009](http://dx.doi.org/10.1055/s-0040-1702009).'
- en: 'Cohn et al. [1994] Cohn, D., Atlas, L., Ladner, R., 1994. Improving generalization
    with active learning. Machine Learning 15, 201–221. URL: [https://link.springer.com/article/10.1007/BF00993277](https://link.springer.com/article/10.1007/BF00993277),
    doi:[10.1007/bf00993277](http://dx.doi.org/10.1007/bf00993277).'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cohn 等人 [1994] Cohn, D., Atlas, L., Ladner, R., 1994. 通过主动学习提高泛化能力。《机器学习》15,
    201–221. URL: [https://link.springer.com/article/10.1007/BF00993277](https://link.springer.com/article/10.1007/BF00993277),
    doi:[10.1007/bf00993277](http://dx.doi.org/10.1007/bf00993277).'
- en: 'Criminisi et al. [2008] Criminisi, A., Sharp, T., Blake, A., 2008. GeoS: Geodesic
    Image Segmentation, Springer, Berlin, Heidelberg, pp. 99–112. URL: [http://link.springer.com/10.1007/978-3-540-88682-2_9](http://link.springer.com/10.1007/978-3-540-88682-2_9),
    doi:[10.1007/978-3-540-88682-2{\_}9](http://dx.doi.org/10.1007/978-3-540-88682-2_9).'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Criminisi 等人 [2008] Criminisi, A., Sharp, T., Blake, A., 2008. GeoS: Geodesic
    Image Segmentation, Springer, Berlin, Heidelberg, pp. 99–112. URL: [http://link.springer.com/10.1007/978-3-540-88682-2_9](http://link.springer.com/10.1007/978-3-540-88682-2_9),
    doi:[10.1007/978-3-540-88682-2{\_}9](http://dx.doi.org/10.1007/978-3-540-88682-2_9).'
- en: 'Dagan and Engelson [1995] Dagan, I., Engelson, S.P., 1995. Committee-Based
    Sampling For Training Probabilistic Classifiers, in: Machine Learning Proceedings
    1995. Elsevier, pp. 150–157. doi:[10.1016/b978-1-55860-377-6.50027-x](http://dx.doi.org/10.1016/b978-1-55860-377-6.50027-x).'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dagan 和 Engelson [1995] Dagan, I., Engelson, S.P., 1995. 基于委员会的采样用于训练概率分类器，发表于：1995年机器学习会议论文集。Elsevier,
    pp. 150–157. doi:[10.1016/b978-1-55860-377-6.50027-x](http://dx.doi.org/10.1016/b978-1-55860-377-6.50027-x).
- en: 'Edwards and Veale [2017a] Edwards, L., Veale, M., 2017a. Enslaving the Algorithm:
    From a Right to an Explanationn to a Right to Better Decisionss? SSRN Electronic
    Journal URL: [https://www.ssrn.com/abstract=3052831](https://www.ssrn.com/abstract=3052831),
    doi:[10.2139/ssrn.3052831](http://dx.doi.org/10.2139/ssrn.3052831).'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Edwards 和 Veale [2017a] Edwards, L., Veale, M., 2017a. 奴役算法：从解释权到更好决策的权利？SSRN
    电子期刊 URL: [https://www.ssrn.com/abstract=3052831](https://www.ssrn.com/abstract=3052831),
    doi:[10.2139/ssrn.3052831](http://dx.doi.org/10.2139/ssrn.3052831).'
- en: 'Edwards and Veale [2017b] Edwards, L., Veale, M., 2017b. Slave to the Algorithm?
    Why a Right to Explanationn is Probably Not the Remedy You are Looking for. SSRN
    Electronic Journal URL: [https://www.ssrn.com/abstract=2972855](https://www.ssrn.com/abstract=2972855),
    doi:[10.2139/ssrn.2972855](http://dx.doi.org/10.2139/ssrn.2972855).'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Edwards 和 Veale [2017b] Edwards, L., Veale, M., 2017b. 受算法支配？为什么解释权可能不是你想要的解决办法。SSRN
    电子期刊 URL: [https://www.ssrn.com/abstract=2972855](https://www.ssrn.com/abstract=2972855),
    doi:[10.2139/ssrn.2972855](http://dx.doi.org/10.2139/ssrn.2972855).'
- en: 'Fang et al. [2017] Fang, M., Li, Y., Cohn, T., 2017. Learning how to active
    learn: A deep reinforcement learning approach, in: Proceedings of the 2017 Conference
    on Empirical Methods in Natural Language Processing, Association for Computational
    Linguistics, Copenhagen, Denmark. pp. 595–605. URL: [https://www.aclweb.org/anthology/D17-1063](https://www.aclweb.org/anthology/D17-1063),
    doi:[10.18653/v1/D17-1063](http://dx.doi.org/10.18653/v1/D17-1063).'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fang 等人 [2017] Fang, M., Li, Y., Cohn, T., 2017. 学习如何主动学习：一种深度强化学习方法，发表于：2017年自然语言处理实证方法会议论文集，计算语言学协会，哥本哈根，丹麦。pp.
    595–605. URL: [https://www.aclweb.org/anthology/D17-1063](https://www.aclweb.org/anthology/D17-1063),
    doi:[10.18653/v1/D17-1063](http://dx.doi.org/10.18653/v1/D17-1063).'
- en: 'Farquhar et al. [2021] Farquhar, S., Gal, Y., Rainforth, T., 2021. On statistical
    bias in active learning: How and when to fix it, in: International Conference
    on Learning Representations. URL: [https://openreview.net/forum?id=JiYq3eqTKY](https://openreview.net/forum?id=JiYq3eqTKY).'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Farquhar 等人 [2021] Farquhar, S., Gal, Y., Rainforth, T., 2021. 关于主动学习中的统计偏差：如何以及何时修正，发表于：国际学习表征会议。URL:
    [https://openreview.net/forum?id=JiYq3eqTKY](https://openreview.net/forum?id=JiYq3eqTKY).'
- en: 'Gal and Ghahramani [2016] Gal, Y., Ghahramani, Z., 2016. Dropout as a Bayesian
    approximation: Representing model uncertainty in deep learning, in: Proceedings
    of the 33rd International Conference on Machine Learning (ICML-16).'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gal 和 Ghahramani [2016] Gal, Y., Ghahramani, Z., 2016. 作为贝叶斯近似的 Dropout：在深度学习中表示模型不确定性，载于：第33届国际机器学习会议论文集（ICML-16）。
- en: 'Gal et al. [2017] Gal, Y., Islam, R., Ghahramani, Z., 2017. Deep bayesian active
    learning with image data, in: Proceedings of the 34th International Conference
    on Machine Learning - Volume 70, JMLR.org. p. 1183–1192.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gal 等人 [2017] Gal, Y., Islam, R., Ghahramani, Z., 2017. 使用图像数据的深度贝叶斯主动学习，载于：第34届国际机器学习会议论文集
    - 第70卷，JMLR.org。第1183–1192页。
- en: 'Goodman and Flaxman [2017] Goodman, B., Flaxman, S., 2017. European union regulations
    on algorithmic decision-making and a “right to explanation”. AI Magazine 38, 50–57.
    URL: [https://www.aaai.org/ojs/index.php/aimagazine/article/view/2741](https://www.aaai.org/ojs/index.php/aimagazine/article/view/2741),
    doi:[10.1609/aimag.v38i3.2741](http://dx.doi.org/10.1609/aimag.v38i3.2741).'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodman 和 Flaxman [2017] Goodman, B., Flaxman, S., 2017. 欧盟关于算法决策和“解释权”的法规。人工智能杂志
    38, 50–57。网址：[https://www.aaai.org/ojs/index.php/aimagazine/article/view/2741](https://www.aaai.org/ojs/index.php/aimagazine/article/view/2741)，doi：[10.1609/aimag.v38i3.2741](http://dx.doi.org/10.1609/aimag.v38i3.2741)。
- en: 'Guan and Liu [2021] Guan, H., Liu, M., 2021. Domain Adaptation for Medical
    Image Analysis: A Survey URL: [http://arxiv.org/abs/2102.09508](http://arxiv.org/abs/2102.09508).'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guan 和 Liu [2021] Guan, H., Liu, M., 2021. 医学图像分析的领域适应：综述 网址：[http://arxiv.org/abs/2102.09508](http://arxiv.org/abs/2102.09508)。
- en: 'Haenssle et al. [2018] Haenssle, H.A., Fink, C., Schneiderbauer, R., Toberer,
    F., Buhl, T., Blum, A., Kalloo, A., Hassen, A.B.H., Thomas, L., Enk, A., Uhlmann,
    L., Alt, C., Arenbergerova, M., Bakos, R., Baltzer, A., Bertlich, I., Blum, A.,
    Bokor-Billmann, T., Bowling, J., Braghiroli, N., Braun, R., Buder-Bakhaya, K.,
    Buhl, T., Cabo, H., Cabrijan, L., Cevic, N., Classen, A., Deltgen, D., Fink, C.,
    Georgieva, I., Hakim-Meibodi, L.E., Hanner, S., Hartmann, F., Hartmann, J., Haus,
    G., Hoxha, E., Karls, R., Koga, H., Kreusch, J., Lallas, A., Majenka, P., Marghoob,
    A., Massone, C., Mekokishvili, L., Mestel, D., Meyer, V., Neuberger, A., Nielsen,
    K., Oliviero, M., Pampena, R., Paoli, J., Pawlik, E., Rao, B., Rendon, A., Russo,
    T., Sadek, A., Samhaber, K., Schneiderbauer, R., Schweizer, A., Toberer, F., Trennheuser,
    L., Vlahova, L., Wald, A., Winkler, J., Wölbing, P., Zalaudek, I., 2018. Man against
    machine: diagnostic performance of a deep learning convolutional neural network
    for dermoscopic melanoma recognition in comparison to 58 dermatologists. Annals
    of Oncology 29, 1836–1842. URL: [https://academic.oup.com/annonc/article/29/8/1836/5004443](https://academic.oup.com/annonc/article/29/8/1836/5004443),
    doi:[10.1093/annonc/mdy166](http://dx.doi.org/10.1093/annonc/mdy166).'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haenssle 等人 [2018] Haenssle, H.A., Fink, C., Schneiderbauer, R., Toberer, F.,
    Buhl, T., Blum, A., Kalloo, A., Hassen, A.B.H., Thomas, L., Enk, A., Uhlmann,
    L., Alt, C., Arenbergerova, M., Bakos, R., Baltzer, A., Bertlich, I., Blum, A.,
    Bokor-Billmann, T., Bowling, J., Braghiroli, N., Braun, R., Buder-Bakhaya, K.,
    Buhl, T., Cabo, H., Cabrijan, L., Cevic, N., Classen, A., Deltgen, D., Fink, C.,
    Georgieva, I., Hakim-Meibodi, L.E., Hanner, S., Hartmann, F., Hartmann, J., Haus,
    G., Hoxha, E., Karls, R., Koga, H., Kreusch, J., Lallas, A., Majenka, P., Marghoob,
    A., Massone, C., Mekokishvili, L., Mestel, D., Meyer, V., Neuberger, A., Nielsen,
    K., Oliviero, M., Pampena, R., Paoli, J., Pawlik, E., Rao, B., Rendon, A., Russo,
    T., Sadek, A., Samhaber, K., Schneiderbauer, R., Schweizer, A., Toberer, F., Trennheuser,
    L., Vlahova, L., Wald, A., Winkler, J., Wölbing, P., Zalaudek, I., 2018. 人工智能与机器对抗：深度学习卷积神经网络在皮肤镜黑色素瘤识别中的诊断表现与58位皮肤科医生的比较。肿瘤学年鉴
    29, 1836–1842。网址：[https://academic.oup.com/annonc/article/29/8/1836/5004443](https://academic.oup.com/annonc/article/29/8/1836/5004443)，doi：[10.1093/annonc/mdy166](http://dx.doi.org/10.1093/annonc/mdy166)。
- en: 'Hauptmann et al. [2006] Hauptmann, A., Lin, W.H., Yan, R., Yang, J., Chen,
    M.y., 2006. Extreme video retrieval: Joint maximization of human and computer
    performance, pp. 385–394. doi:[10.1145/1180639.1180721](http://dx.doi.org/10.1145/1180639.1180721).'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hauptmann 等人 [2006] Hauptmann, A., Lin, W.H., Yan, R., Yang, J., Chen, M.y.,
    2006. 极端视频检索：人类和计算机性能的联合最大化，第385–394页。doi：[10.1145/1180639.1180721](http://dx.doi.org/10.1145/1180639.1180721)。
- en: 'Hesamian et al. [2019] Hesamian, M.H., Jia, W., He, X., Kennedy, P., 2019.
    Deep Learning Techniques for Medical Image Segmentation: Achievements and Challenges.
    Journal of Digital Imaging 32, 582–596. URL: [http://link.springer.com/10.1007/s10278-019-00227-x](http://link.springer.com/10.1007/s10278-019-00227-x),
    doi:[10.1007/s10278-019-00227-x](http://dx.doi.org/10.1007/s10278-019-00227-x).'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hesamian 等人 [2019] Hesamian, M.H., Jia, W., He, X., Kennedy, P., 2019. 医学图像分割的深度学习技术：成就与挑战。数字成像杂志
    32, 582–596。网址：[http://link.springer.com/10.1007/s10278-019-00227-x](http://link.springer.com/10.1007/s10278-019-00227-x)，doi：[10.1007/s10278-019-00227-x](http://dx.doi.org/10.1007/s10278-019-00227-x)。
- en: 'Holzinger et al. [2017] Holzinger, A., Malle, B., Kieseberg, P., Roth, P.M.,
    Müller, H., Reihs, R., Zatloukal, K., 2017. Towards the Augmented Pathologist:
    Challenges of Explainable-AI in Digital Pathology URL: [http://arxiv.org/abs/1712.06657](http://arxiv.org/abs/1712.06657).'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Holzinger等人 [2017] Holzinger, A., Malle, B., Kieseberg, P., Roth, P.M., Müller,
    H., Reihs, R., Zatloukal, K., 2017. 朝向增强型病理学家：数字病理学中的可解释AI挑战 URL: [http://arxiv.org/abs/1712.06657](http://arxiv.org/abs/1712.06657).'
- en: 'Jang and Kim [2019] Jang, W.D., Kim, C.S., 2019. Interactive image segmentation
    via backpropagating refinement scheme, in: Proceedings of The IEEE Conference
    on Computer Vision and Pattern Recognition.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jang和Kim [2019] Jang, W.D., Kim, C.S., 2019. 通过反向传播细化方案进行交互式图像分割，见于《IEEE计算机视觉与模式识别会议论文集》。
- en: 'Jungo and Reyes [2019] Jungo, A., Reyes, M., 2019. Assessing Reliability and
    Challenges of Uncertainty Estimations for Medical Image Segmentation. Technical
    Report. URL: [https://github.com/alainjungo/reliability-challenges-uncertainty](https://github.com/alainjungo/reliability-challenges-uncertainty).'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jungo和Reyes [2019] Jungo, A., Reyes, M., 2019. 医学图像分割的不确定性估计的可靠性和挑战评估。技术报告。URL:
    [https://github.com/alainjungo/reliability-challenges-uncertainty](https://github.com/alainjungo/reliability-challenges-uncertainty).'
- en: 'Kamnitsas et al. [2017] Kamnitsas, K., Baumgartner, C., Ledig, C., Newcombe,
    V., Simpson, J., Kane, A., Menon, D., Nori, A., Criminisi, A., Rueckert, D., et al.,
    2017. Unsupervised domain adaptation in brain lesion segmentation with adversarial
    networks, in: International conference on information processing in medical imaging,
    Springer. pp. 597–609.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kamnitsas等人 [2017] Kamnitsas, K., Baumgartner, C., Ledig, C., Newcombe, V.,
    Simpson, J., Kane, A., Menon, D., Nori, A., Criminisi, A., Rueckert, D., 等人, 2017.
    在脑损伤分割中使用对抗网络进行无监督领域适应，见于：医学影像信息处理国际会议，施普林格，第597–609页。
- en: 'Khosravan et al. [2017] Khosravan, N., Celik, H., Turkbey, B., Cheng, R., McCreedy,
    E., McAuliffe, M., Bednarova, S., Jones, E., Chen, X., Choyke, P., Wood, B., Bagci,
    U., 2017. Gaze2Segment: A Pilot Study for Integrating Eye-Tracking Technology
    into Medical Image Segmentation, Springer, Cham, pp. 94–104. URL: [http://link.springer.com/10.1007/978-3-319-61188-4_9](http://link.springer.com/10.1007/978-3-319-61188-4_9),
    doi:[10.1007/978-3-319-61188-4{\_}9](http://dx.doi.org/10.1007/978-3-319-61188-4_9).'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Khosravan等人 [2017] Khosravan, N., Celik, H., Turkbey, B., Cheng, R., McCreedy,
    E., McAuliffe, M., Bednarova, S., Jones, E., Chen, X., Choyke, P., Wood, B., Bagci,
    U., 2017. Gaze2Segment: 一项将眼动追踪技术融入医学图像分割的初步研究，施普林格，Cham，第94–104页。URL: [http://link.springer.com/10.1007/978-3-319-61188-4_9](http://link.springer.com/10.1007/978-3-319-61188-4_9),
    doi:[10.1007/978-3-319-61188-4{\_}9](http://dx.doi.org/10.1007/978-3-319-61188-4_9).'
- en: 'Kim et al. [2014] Kim, J.S., Greene, M.J., Zlateski, A., Lee, K., Richardson,
    M., Turaga, S.C., Purcaro, M., Balkam, M., Robinson, A., Behabadi, B.F., Campos,
    M., Denk, W., Seung, H.S., EyeWirers, t., 2014. Space–time wiring specificity
    supports direction selectivity in the retina. Nature 509, 331–336. URL: [http://www.nature.com/articles/nature13240](http://www.nature.com/articles/nature13240),
    doi:[10.1038/nature13240](http://dx.doi.org/10.1038/nature13240).'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kim等人 [2014] Kim, J.S., Greene, M.J., Zlateski, A., Lee, K., Richardson, M.,
    Turaga, S.C., Purcaro, M., Balkam, M., Robinson, A., Behabadi, B.F., Campos, M.,
    Denk, W., Seung, H.S., EyeWirers, t., 2014. 空间–时间接线特异性支持视网膜中的方向选择性。《自然》509, 331–336.
    URL: [http://www.nature.com/articles/nature13240](http://www.nature.com/articles/nature13240),
    doi:[10.1038/nature13240](http://dx.doi.org/10.1038/nature13240).'
- en: 'King et al. [2009] King, R.D., Rowland, J., Oliver, S.G., Young, M., Aubrey,
    W., Byrne, E., Liakata, M., Markham, M., Pir, P., Soldatova, L.N., Sparkes, A.,
    Whelan, K.E., Clare, A., 2009. The automation of science. Science 324, 85–89.
    URL: [https://pubmed.ncbi.nlm.nih.gov/19342587/](https://pubmed.ncbi.nlm.nih.gov/19342587/),
    doi:[10.1126/science.1165620](http://dx.doi.org/10.1126/science.1165620).'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'King等人 [2009] King, R.D., Rowland, J., Oliver, S.G., Young, M., Aubrey, W.,
    Byrne, E., Liakata, M., Markham, M., Pir, P., Soldatova, L.N., Sparkes, A., Whelan,
    K.E., Clare, A., 2009. 科学的自动化。《科学》324, 85–89. URL: [https://pubmed.ncbi.nlm.nih.gov/19342587/](https://pubmed.ncbi.nlm.nih.gov/19342587/),
    doi:[10.1126/science.1165620](http://dx.doi.org/10.1126/science.1165620).'
- en: 'King et al. [2004] King, R.D., Whelan, K.E., Jones, F.M., Reiser, P.G., Bryant,
    C.H., Muggleton, S.H., Kell, D.B., Oliver, S.G., 2004. Functional genomic hypothesis
    generation and experimentation by a robot scientist. Nature 427, 247–252. URL:
    [https://pubmed.ncbi.nlm.nih.gov/14724639/](https://pubmed.ncbi.nlm.nih.gov/14724639/),
    doi:[10.1038/nature02236](http://dx.doi.org/10.1038/nature02236).'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'King等人 [2004] King, R.D., Whelan, K.E., Jones, F.M., Reiser, P.G., Bryant,
    C.H., Muggleton, S.H., Kell, D.B., Oliver, S.G., 2004. 通过机器人科学家进行功能基因组假设生成和实验。《自然》427,
    247–252. URL: [https://pubmed.ncbi.nlm.nih.gov/14724639/](https://pubmed.ncbi.nlm.nih.gov/14724639/),
    doi:[10.1038/nature02236](http://dx.doi.org/10.1038/nature02236).'
- en: 'Kirsch et al. [2019] Kirsch, A., van Amersfoort, J., Gal, Y., 2019. Batchbald:
    Efficient and diverse batch acquisition for deep bayesian active learning, in:
    Advances in Neural Information Processing Systems 32\. Curran Associates, Inc.,
    pp. 7026–7037. URL: [http://papers.nips.cc/paper/8925-batchbald-efficient-and-diverse-batch-acquisition-for-deep-bayesian-active-learning.pdf](http://papers.nips.cc/paper/8925-batchbald-efficient-and-diverse-batch-acquisition-for-deep-bayesian-active-learning.pdf).'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kirsch 等人 [2019] Kirsch, A., van Amersfoort, J., Gal, Y., 2019. Batchbald:
    高效且多样化的批量获取用于深度贝叶斯主动学习，收录于《神经信息处理系统进展 32》。Curran Associates, Inc., 页码 7026–7037。网址:
    [http://papers.nips.cc/paper/8925-batchbald-efficient-and-diverse-batch-acquisition-for-deep-bayesian-active-learning.pdf](http://papers.nips.cc/paper/8925-batchbald-efficient-and-diverse-batch-acquisition-for-deep-bayesian-active-learning.pdf)。'
- en: 'Konyushkova et al. [2017] Konyushkova, K., Sznitman, R., Fua, P., 2017. Learning
    Active Learning from Data. URL: [https://papers.nips.cc/paper/7010-learning-active-learning-from-data](https://papers.nips.cc/paper/7010-learning-active-learning-from-data).'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Konyushkova 等人 [2017] Konyushkova, K., Sznitman, R., Fua, P., 2017. 从数据中学习主动学习。网址:
    [https://papers.nips.cc/paper/7010-learning-active-learning-from-data](https://papers.nips.cc/paper/7010-learning-active-learning-from-data)。'
- en: 'Konyushkova et al. [2019] Konyushkova, K., Sznitman, R., Fua, P., 2019. Geometry
    in active learning for binary and multi-class image segmentation. Computer Vision
    and Image Understanding 182, 1–16. URL: [https://www.sciencedirect.com/science/article/pii/S107731421930013X](https://www.sciencedirect.com/science/article/pii/S107731421930013X),
    doi:[10.1016/J.CVIU.2019.01.007](http://dx.doi.org/10.1016/J.CVIU.2019.01.007).'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Konyushkova 等人 [2019] Konyushkova, K., Sznitman, R., Fua, P., 2019. 用于二类和多类图像分割的主动学习中的几何学。《计算机视觉与图像理解》182,
    1–16。网址: [https://www.sciencedirect.com/science/article/pii/S107731421930013X](https://www.sciencedirect.com/science/article/pii/S107731421930013X)，doi:[10.1016/J.CVIU.2019.01.007](http://dx.doi.org/10.1016/J.CVIU.2019.01.007)。'
- en: 'Kuo et al. [2018] Kuo, W., Häne, C., Yuh, E., Mukherjee, P., Malik, J., 2018.
    Cost-Sensitive Active Learning for Intracranial Hemorrhage Detection, Springer,
    Cham, pp. 715–723. URL: [http://link.springer.com/10.1007/978-3-030-00931-1_82](http://link.springer.com/10.1007/978-3-030-00931-1_82),
    doi:[10.1007/978-3-030-00931-1{\_}82](http://dx.doi.org/10.1007/978-3-030-00931-1_82).'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kuo 等人 [2018] Kuo, W., Häne, C., Yuh, E., Mukherjee, P., Malik, J., 2018. 用于颅内出血检测的成本敏感主动学习，Springer,
    Cham, 页码 715–723。网址: [http://link.springer.com/10.1007/978-3-030-00931-1_82](http://link.springer.com/10.1007/978-3-030-00931-1_82)，doi:[10.1007/978-3-030-00931-1{\_}82](http://dx.doi.org/10.1007/978-3-030-00931-1_82)。'
- en: 'Kurzendorfer et al. [2017] Kurzendorfer, T., Fischer, P., Mirshahzadeh, N.,
    Pohl, T., Brost, A., Steidl, S., Maier, A., 2017. Rapid Interactive and Intuitive
    Segmentation of 3D Medical Images Using Radial Basis Function Interpolation †.
    Annual Conference on Medical Image Understanding and Analysis , 11–13URL: [www.mdpi.com/journal/jimaging](www.mdpi.com/journal/jimaging),
    doi:[10.3390/jimaging3040056](http://dx.doi.org/10.3390/jimaging3040056).'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kurzendorfer 等人 [2017] Kurzendorfer, T., Fischer, P., Mirshahzadeh, N., Pohl,
    T., Brost, A., Steidl, S., Maier, A., 2017. 使用径向基函数插值进行 3D 医学图像的快速交互式和直观分割†。医学图像理解与分析年会,
    11–13。网址: [www.mdpi.com/journal/jimaging](www.mdpi.com/journal/jimaging)，doi:[10.3390/jimaging3040056](http://dx.doi.org/10.3390/jimaging3040056)。'
- en: 'Kushibar et al. [2019] Kushibar, K., Valverde, S., González-Villà, S., Bernal,
    J., Cabezas, M., Oliver, A., Lladó, X., 2019. Supervised Domain Adaptation for
    Automatic Sub-cortical Brain Structure Segmentation with Minimal User Interaction.
    Scientific Reports 9, 6742. URL: [http://www.nature.com/articles/s41598-019-43299-z](http://www.nature.com/articles/s41598-019-43299-z),
    doi:[10.1038/s41598-019-43299-z](http://dx.doi.org/10.1038/s41598-019-43299-z).'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kushibar 等人 [2019] Kushibar, K., Valverde, S., González-Villà, S., Bernal,
    J., Cabezas, M., Oliver, A., Lladó, X., 2019. 用于自动亚皮层脑结构分割的有监督领域适应，最小用户交互。《科学报告》9,
    6742。网址: [http://www.nature.com/articles/s41598-019-43299-z](http://www.nature.com/articles/s41598-019-43299-z)，doi:[10.1038/s41598-019-43299-z](http://dx.doi.org/10.1038/s41598-019-43299-z)。'
- en: 'Lang and Baum [1992] Lang, K., Baum, E., 1992. Query learning can work poorly
    when a human oracle is used, in: Proceedings of the IEEE International Joint Conference
    on Neural Networks, IEEE. pp. 335––340.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lang 和 Baum [1992] Lang, K., Baum, E., 1992. 当使用人工神谕时查询学习可能效果不佳，收录于《IEEE 国际联合神经网络会议论文集》，IEEE。页码
    335–340。
- en: 'Last et al. [2018] Last, F., Klein, T., Ravanbakhsh, M., Nabi, M., Batmanghelich,
    K., Tresp, V., 2018. Human-Machine Collaboration for Medical Image Segmentation.
    Technical Report. URL: [https://pdfs.semanticscholar.org/4e0c/535386e3a3d307cee45e97b9417eff4da92e.pdf](https://pdfs.semanticscholar.org/4e0c/535386e3a3d307cee45e97b9417eff4da92e.pdf).'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Last et al. [2018] Last, F., Klein, T., Ravanbakhsh, M., Nabi, M., Batmanghelich,
    K., Tresp, V., 2018. 医学图像分割的人机协作。技术报告。网址：[https://pdfs.semanticscholar.org/4e0c/535386e3a3d307cee45e97b9417eff4da92e.pdf](https://pdfs.semanticscholar.org/4e0c/535386e3a3d307cee45e97b9417eff4da92e.pdf)。
- en: 'Lewis and Catlett [1994] Lewis, D.D., Catlett, J., 1994. Heterogeneous uncertainty
    sampling for supervised learning, in: In Proceedings of the Eleventh International
    Conference on Machine Learning, Morgan Kaufmann. pp. 148–156.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis and Catlett [1994] Lewis, D.D., Catlett, J., 1994. 用于监督学习的异质不确定性采样，见：第十一届国际机器学习会议论文集，Morgan
    Kaufmann。第148–156页。
- en: Li et al. [2019] Li, S., Jiang, Y., Chawla, N.V., Zhou, Z., 2019. Multi-label
    learning from crowds. IEEE Transactions on Knowledge and Data Engineering 31,
    1369–1382. doi:[10.1109/TKDE.2018.2857766](http://dx.doi.org/10.1109/TKDE.2018.2857766).
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2019] Li, S., Jiang, Y., Chawla, N.V., Zhou, Z., 2019. 从众包数据中进行多标签学习。IEEE
    知识与数据工程汇刊 31, 1369–1382. doi:[10.1109/TKDE.2018.2857766](http://dx.doi.org/10.1109/TKDE.2018.2857766)。
- en: Lian et al. [2020] Lian, C., Liu, M., Zhang, J., Shen, D., 2020. Hierarchical
    fully convolutional network for joint atrophy localization and Alzheimer’s disease
    diagnosis using structural MRI. IEEE Transactions on Pattern Analysis and Machine
    Intelligence 42, 880–893. doi:[10.1109/TPAMI.2018.2889096](http://dx.doi.org/10.1109/TPAMI.2018.2889096).
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lian et al. [2020] Lian, C., Liu, M., Zhang, J., Shen, D., 2020. 用于联合萎缩定位和阿尔茨海默病诊断的分层全卷积网络，基于结构性MRI。IEEE
    模式分析与机器智能汇刊 42, 880–893. doi:[10.1109/TPAMI.2018.2889096](http://dx.doi.org/10.1109/TPAMI.2018.2889096)。
- en: Liao et al. [2020] Liao, X., Li, W.H., Xu, Q., Wang, X., Jin, B., Zhang, X.,
    Zhang, Y., Wang, Y., 2020. Iteratively-refined interactive 3d medical image segmentation
    with multi-agent reinforcement learning. 2020 IEEE/CVF Conference on Computer
    Vision and Pattern Recognition (CVPR) , 9391–9399.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liao et al. [2020] Liao, X., Li, W.H., Xu, Q., Wang, X., Jin, B., Zhang, X.,
    Zhang, Y., Wang, Y., 2020. 使用多智能体强化学习的迭代精细化互动三维医学图像分割。2020 IEEE/CVF 计算机视觉与模式识别会议
    (CVPR)，9391–9399。
- en: 'Litjens et al. [2017] Litjens, G., Kooi, T., Bejnordi, B.E., Setio, A.A.A.,
    Ciompi, F., Ghafoorian, M., van der Laak, J.A., van Ginneken, B., Sánchez, C.I.,
    2017. A survey on deep learning in medical image analysis. Medical Image Analysis
    42, 60–88. URL: [https://www.sciencedirect.com/science/article/pii/S1361841517301135](https://www.sciencedirect.com/science/article/pii/S1361841517301135),
    doi:[10.1016/J.MEDIA.2017.07.005](http://dx.doi.org/10.1016/J.MEDIA.2017.07.005).'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Litjens et al. [2017] Litjens, G., Kooi, T., Bejnordi, B.E., Setio, A.A.A.,
    Ciompi, F., Ghafoorian, M., van der Laak, J.A., van Ginneken, B., Sánchez, C.I.,
    2017. 医学图像分析中深度学习的调查。医学图像分析 42, 60–88. 网址：[https://www.sciencedirect.com/science/article/pii/S1361841517301135](https://www.sciencedirect.com/science/article/pii/S1361841517301135)，doi:[10.1016/J.MEDIA.2017.07.005](http://dx.doi.org/10.1016/J.MEDIA.2017.07.005)。
- en: Liu et al. [2018] Liu, M., Zhang, J., Adeli, E., Shen, D., 2018. Landmark-based
    deep multi-instance learning for brain disease diagnosis. Medical Image Analysis
    43, 157–168. doi:[10.1016/j.media.2017.10.005](http://dx.doi.org/10.1016/j.media.2017.10.005).
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. [2018] Liu, M., Zhang, J., Adeli, E., Shen, D., 2018. 基于地标的深度多实例学习用于脑疾病诊断。医学图像分析
    43, 157–168. doi:[10.1016/j.media.2017.10.005](http://dx.doi.org/10.1016/j.media.2017.10.005)。
- en: 'Lowell et al. [2019] Lowell, D., Lipton, Z.C., Wallace, B.C., 2019. Practical
    obstacles to deploying active learning, in: Proceedings of the 2019 Conference
    on Empirical Methods in Natural Language Processing and the 9th International
    Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for
    Computational Linguistics, Hong Kong, China. pp. 21–30. URL: [https://www.aclweb.org/anthology/D19-1003](https://www.aclweb.org/anthology/D19-1003),
    doi:[10.18653/v1/D19-1003](http://dx.doi.org/10.18653/v1/D19-1003).'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lowell et al. [2019] Lowell, D., Lipton, Z.C., Wallace, B.C., 2019. 部署主动学习的实际障碍，见：2019年自然语言处理经验方法会议暨第九届国际自然语言处理联合会议
    (EMNLP-IJCNLP) 论文集，计算语言学协会，香港，中国。第21–30页。网址：[https://www.aclweb.org/anthology/D19-1003](https://www.aclweb.org/anthology/D19-1003)，doi:[10.18653/v1/D19-1003](http://dx.doi.org/10.18653/v1/D19-1003)。
- en: 'Lundervold and Lundervold [2019] Lundervold, A.S., Lundervold, A., 2019. An
    overview of deep learning in medical imaging focusing on MRI. Zeitschrift für
    Medizinische Physik 29, 102–127. URL: [https://www.sciencedirect.com/science/article/pii/S0939388918301181](https://www.sciencedirect.com/science/article/pii/S0939388918301181),
    doi:[10.1016/J.ZEMEDI.2018.11.002](http://dx.doi.org/10.1016/J.ZEMEDI.2018.11.002).'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lundervold 和 Lundervold [2019] Lundervold, A.S., Lundervold, A., 2019. 深度学习在医学影像中的概述，重点关注
    MRI。《医学物理学杂志》29, 102–127. URL: [https://www.sciencedirect.com/science/article/pii/S0939388918301181](https://www.sciencedirect.com/science/article/pii/S0939388918301181)，doi:[10.1016/J.ZEMEDI.2018.11.002](http://dx.doi.org/10.1016/J.ZEMEDI.2018.11.002)。'
- en: 'Mahapatra et al. [2018] Mahapatra, D., Bozorgtabar, B., Thiran, J.P., Reyes,
    M., 2018. Efficient Active Learning for Image Classification and Segmentation
    Using a Sample Selection and Conditional Generative Adversarial Network, Springer,
    Cham, pp. 580–588. URL: [http://link.springer.com/10.1007/978-3-030-00934-2_65](http://link.springer.com/10.1007/978-3-030-00934-2_65),
    doi:[10.1007/978-3-030-00934-2{\_}65](http://dx.doi.org/10.1007/978-3-030-00934-2_65).'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mahapatra 等人 [2018] Mahapatra, D., Bozorgtabar, B., Thiran, J.P., Reyes, M.,
    2018. 用于图像分类和分割的高效主动学习，结合样本选择和条件生成对抗网络，Springer, Cham, 页码 580–588. URL: [http://link.springer.com/10.1007/978-3-030-00934-2_65](http://link.springer.com/10.1007/978-3-030-00934-2_65)，doi:[10.1007/978-3-030-00934-2{\_}65](http://dx.doi.org/10.1007/978-3-030-00934-2_65)。'
- en: 'Mar and Soyer [2018] Mar, V.J., Soyer, H.P., 2018. Artificial intelligence
    for melanoma diagnosis: how can we deliver on the promise? Annals of Oncology
    29, 1625–1628. URL: [https://academic.oup.com/annonc/article/29/8/1625/5004449](https://academic.oup.com/annonc/article/29/8/1625/5004449),
    doi:[10.1093/annonc/mdy193](http://dx.doi.org/10.1093/annonc/mdy193).'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mar 和 Soyer [2018] Mar, V.J., Soyer, H.P., 2018. 人工智能在黑色素瘤诊断中的应用：我们如何兑现承诺？《肿瘤学年鉴》29,
    1625–1628. URL: [https://academic.oup.com/annonc/article/29/8/1625/5004449](https://academic.oup.com/annonc/article/29/8/1625/5004449)，doi:[10.1093/annonc/mdy193](http://dx.doi.org/10.1093/annonc/mdy193)。'
- en: 'McCallum and Nigam [1998] McCallum, A., Nigam, K., 1998. Employing em and pool-based
    active learning for text classification, in: Proceedings of the Fifteenth International
    Conference on Machine Learning, Morgan Kaufmann Publishers Inc., San Francisco,
    CA, USA. p. 350–358. doi:[10.5555/645527.757765](http://dx.doi.org/10.5555/645527.757765).'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McCallum 和 Nigam [1998] McCallum, A., Nigam, K., 1998. 采用 EM 和基于池的主动学习进行文本分类，载于：第十五届国际机器学习会议论文集，Morgan
    Kaufmann Publishers Inc., San Francisco, CA, USA. 页码 350–358. doi:[10.5555/645527.757765](http://dx.doi.org/10.5555/645527.757765)。
- en: 'Milletari et al. [2019] Milletari, F., Birodkar, V., Sofka, M., 2019. Straight
    to the Point: Reinforcement learning for user guidance in ultrasound, in: Lecture
    Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence
    and Lecture Notes in Bioinformatics), Springer. pp. 3–10. URL: [https://doi.org/10.1007/978-3-030-32875-7_1](https://doi.org/10.1007/978-3-030-32875-7_1),
    doi:[10.1007/978-3-030-32875-7{\_}1](http://dx.doi.org/10.1007/978-3-030-32875-7_1).'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Milletari 等人 [2019] Milletari, F., Birodkar, V., Sofka, M., 2019. 直击要点：用于超声引导的强化学习，载于：计算机科学讲义（包括人工智能讲义和生物信息学讲义），Springer.
    页码 3–10. URL: [https://doi.org/10.1007/978-3-030-32875-7_1](https://doi.org/10.1007/978-3-030-32875-7_1)，doi:[10.1007/978-3-030-32875-7{\_}1](http://dx.doi.org/10.1007/978-3-030-32875-7_1)。'
- en: 'Moeskops et al. [2016] Moeskops, P., Wolterink, J.M., van der Velden, B.H.M.,
    Gilhuijs, K.G.A., Leiner, T., Viergever, M.A., Išgum, I., 2016. Deep Learning
    for Multi-task Medical Image Segmentation in Multiple Modalities, Springer, Cham,
    pp. 478–486. URL: [http://link.springer.com/10.1007/978-3-319-46723-8_55](http://link.springer.com/10.1007/978-3-319-46723-8_55),
    doi:[10.1007/978-3-319-46723-8{\_}55](http://dx.doi.org/10.1007/978-3-319-46723-8_55).'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Moeskops 等人 [2016] Moeskops, P., Wolterink, J.M., van der Velden, B.H.M., Gilhuijs,
    K.G.A., Leiner, T., Viergever, M.A., Išgum, I., 2016. 多任务医学图像分割的深度学习，Springer,
    Cham, 页码 478–486. URL: [http://link.springer.com/10.1007/978-3-319-46723-8_55](http://link.springer.com/10.1007/978-3-319-46723-8_55)，doi:[10.1007/978-3-319-46723-8{\_}55](http://dx.doi.org/10.1007/978-3-319-46723-8_55)。'
- en: Morid et al. [2021] Morid, M.A., Borjali, A., Del Fiol, G., 2021. A scoping
    review of transfer learning research on medical image analysis using ImageNet.
    doi:[10.1016/j.compbiomed.2020.104115](http://dx.doi.org/10.1016/j.compbiomed.2020.104115).
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Morid 等人 [2021] Morid, M.A., Borjali, A., Del Fiol, G., 2021. 关于使用 ImageNet
    的医学图像分析迁移学习研究的范围评估。doi:[10.1016/j.compbiomed.2020.104115](http://dx.doi.org/10.1016/j.compbiomed.2020.104115)。
- en: 'Nalisnik et al. [2015] Nalisnik, M., Gutman, D.A., Kong, J., Cooper, L.A.,
    2015. An Interactive Learning Framework for Scalable Classification of Pathology
    Images. Proceedings : … IEEE International Conference on Big Data. IEEE International
    Conference on Big Data 2015, 928–935. URL: [http://www.ncbi.nlm.nih.gov/pubmed/27796014http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5082843](http://www.ncbi.nlm.nih.gov/pubmed/27796014http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5082843),
    doi:[10.1109/BigData.2015.7363841](http://dx.doi.org/10.1109/BigData.2015.7363841).'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nalisnik等人[2015] Nalisnik，M.，Gutman，D.A.，Kong，J.，Cooper，L.A.，2015。用于可扩展病理图像分类的交互式学习框架。会议论文：……IEEE国际大数据会议。
    IEEE International Conference on Big Data 2015，928-935。URL:[http://www.ncbi.nlm.nih.gov/pubmed/27796014http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5082843](http://www.ncbi.nlm.nih.gov/pubmed/27796014http://www.pubmedcentral.nih.gov/articlerender.fcgi?artmc=PMC5082843)，doi：[10.1109/BigData.2015.7363841](http://dx.doi.org/10.1109/BigData.2015.7363841)。
- en: 'NICE [2013] NICE, 2013. Judging whether public health interventions offer value
    for money — Guidance and guidelines — NICE URL: [https://www.nice.org.uk/advice/lgb10](https://www.nice.org.uk/advice/lgb10).'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精华[2013] NICE，2013。判断公共卫生干预是否物有所值-指导和准则-NICE。 URL：[https://www.nice.org.uk/advice/lgb10](https://www.nice.org.uk/advice/lgb10)。
- en: 'Oktay et al. [2018] Oktay, O., Schlemper, J., Folgoc, L., Lee, M., Heinrich,
    M., Misawa, K., Mori, K., McDonagh, S., Hammerla, N., Kainz, B., Glocker, B.,
    Rueckert, D., 2018. Attention u-net: Learning where to look for the pancreas URL:
    [https://arxiv.org/pdf/1804.03999.pdf](https://arxiv.org/pdf/1804.03999.pdf).'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oktay等人[2018] Oktay，O.，Schlemper，J.，Folgoc，L.，Lee，M.，Heinrich，M.，Misawa，K.，Mori，K.，McDonagh，S.，Hammerla，N.，Kainz，B.，Glocker，B.，Rueckert，D.，2018.关注u-net：学会在哪里寻找胰腺URL:[https://arxiv.org/pdf/1804.03999.pdf](https://arxiv.org/pdf/1804.03999.pdf)。
- en: 'Ozdemir et al. [2018] Ozdemir, F., Peng, Z., Tanner, C., Fuernstahl, P., Goksel,
    O., 2018. Active Learning for Segmentation by Optimizing Content Information for
    Maximal Entropy, Springer, Cham, pp. 183–191. URL: [http://link.springer.com/10.1007/978-3-030-00889-5_21](http://link.springer.com/10.1007/978-3-030-00889-5_21),
    doi:[10.1007/978-3-030-00889-5{\_}21](http://dx.doi.org/10.1007/978-3-030-00889-5_21).'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ozdemir等人[2018] Ozdemir，F.，Peng，Z.，Tanner，C.，Fuernstahl，P.，Goksel，O.，2018。通过最大熵优化内容信息进行分割的主动学习，Springer，Cham，页码183-191。URL:[http://link.springer.com/10.1007/978-3-030-00889-5_21](http://link.springer.com/10.1007/978-3-030-00889-5_21)，doi:[10.1007/978-3-030-00889-5_21](http://dx.doi.org/10.1007/978-3-030-00889-5_21)。
- en: 'Pan et al. [2020] Pan, Y., Liu, M., Lian, C., Xia, Y., Shen, D., 2020. Spatially-Constrained
    Fisher Representation for Brain Disease Identification with Incomplete Multi-Modal
    Neuroimages. IEEE Transactions on Medical Imaging 39, 2965–2975. URL: [https://pubmed.ncbi.nlm.nih.gov/32217472/](https://pubmed.ncbi.nlm.nih.gov/32217472/),
    doi:[10.1109/TMI.2020.2983085](http://dx.doi.org/10.1109/TMI.2020.2983085).'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan等人[2020] Pan，Y.，Liu，M.，Lian，C.，Xia，Y.，Shen，D.，2020。用于不完整多模态神经影像的空间受限费舍表示的脑疾病识别。IEEE医学成像交易39，2965-2975。URL:[https://pubmed.ncbi.nlm.nih.gov/32217472/](https://pubmed.ncbi.nlm.nih.gov/32217472/)，doi:[10.1109/TMI.2020.2983085](http://dx.doi.org/10.1109/TMI.2020.2983085)。
- en: 'Parisi et al. [2019] Parisi, G.I., Kemker, R., Part, J.L., Kanan, C., Wermter,
    S., 2019. Continual lifelong learning with neural networks: A review. doi:[10.1016/j.neunet.2019.01.012](http://dx.doi.org/10.1016/j.neunet.2019.01.012).'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Parisi等人[2019] Parisi，G.I.，Kemker，R.，Part，J.L.，Kanan，C.，Wermter，S.，2019。用神经网络进行持续终身学习：一项回顾。doi:[10.1016/j.neunet.2019.01.012](http://dx.doi.org/10.1016/j.neunet.2019.01.012)。
- en: 'of Radiologists [2017] of Radiologists, T.R.C., 2017. Clinical radiology UK
    workforce census 2017 report. Technical Report. URL: [https://www.rcr.ac.uk/system/files/publication/field_publication_files/bfcr185_cr_census_2017.pdf](https://www.rcr.ac.uk/system/files/publication/field_publication_files/bfcr185_cr_census_2017.pdf).'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 放射科学家[2017] 放射科学家，T.R.C.，2017。2017年英国临床放射学工作力量普查报告。技术报告。 URL：[https://www.rcr.ac.uk/system/files/publication/field_publication_files/bfcr185_cr_census_2017.pdf](https://www.rcr.ac.uk/system/files/publication/field_publication_files/bfcr185_cr_census_2017.pdf)。
- en: 'Raghu et al. [2019] Raghu, M., Zhang, C., Kleinberg, J., Bengio, S., 2019.
    Transfusion: Understanding transfer learning for medical imaging, in: NeurIPS.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raghu等人[2019] Raghu，M.，Zhang，C.，Kleinberg，J.，Bengio，S.，2019。Transfusion：理解医学图像的迁移学习，在：NeurIPS。
- en: 'Rajchl et al. [2017] Rajchl, M., Koch, L.M., Ledig, C., Passerat-Palmbach,
    J., Misawa, K., Mori, K., Rueckert, D., 2017. Employing Weak Annotations for Medical
    Image Analysis Problems URL: [https://arxiv.org/pdf/1708.06297v1.pdf](https://arxiv.org/pdf/1708.06297v1.pdf).'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajchl等人[2017] Rajchl，M.，Koch，L.M.，Ledig，C.，Passerat-Palmbach，J.，Misawa，K.，Mori，K.，Rueckert，D.，2017。为医学图像分析问题雇佣弱注释URL:[https://arxiv.org/pdf/1708.06297v1.pdf](https://arxiv.org/pdf/1708.06297v1.pdf)。
- en: 'Rajchl et al. [2016a] Rajchl, M., Lee, M.C.H., Oktay, O., Kamnitsas, K., Passerat-Palmbach,
    J., Bai, W., Damodaram, M., Rutherford, M.A., Hajnal, J.V., Kainz, B., Rueckert,
    D., 2016a. Deepcut: Object segmentation from bounding box annotations using convolutional
    neural networks. IEEE Transactions on Medical Imaging 36, 674–683.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rajchl 等人 [2016a] Rajchl, M., Lee, M.C.H., Oktay, O., Kamnitsas, K., Passerat-Palmbach,
    J., Bai, W., Damodaram, M., Rutherford, M.A., Hajnal, J.V., Kainz, B., Rueckert,
    D., 2016a. Deepcut: 使用卷积神经网络从边界框注释中进行物体分割。《IEEE医学成像汇刊》36, 674–683。'
- en: 'Rajchl et al. [2016b] Rajchl, M., Lee, M.C.H., Schrans, F., Davidson, A., Passerat-Palmbach,
    J., Tarroni, G., Alansary, A., Oktay, O., Kainz, B., Rueckert, D., 2016b. Learning
    under Distributed Weak Supervision URL: [https://arxiv.org/pdf/1606.01100v1.pdf](https://arxiv.org/pdf/1606.01100v1.pdf).'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajchl 等人 [2016b] Rajchl, M., Lee, M.C.H., Schrans, F., Davidson, A., Passerat-Palmbach,
    J., Tarroni, G., Alansary, A., Oktay, O., Kainz, B., Rueckert, D., 2016b. 在分布式弱监督下的学习。网址：[https://arxiv.org/pdf/1606.01100v1.pdf](https://arxiv.org/pdf/1606.01100v1.pdf)。
- en: 'Rodrigues and Pereira [2018] Rodrigues, F., Pereira, F.C., 2018. Deep learning
    from crowds, in: The Thirty-Second AAAI Conference on Artificial Intelligence
    (AAAI), 2018, AAAI Press. pp. 1611–1618.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rodrigues 和 Pereira [2018] Rodrigues, F., Pereira, F.C., 2018. 从众人中学习，载于：第32届AAAI人工智能会议（AAAI），2018年，AAAI出版社。第1611–1618页。
- en: 'Ronneberger et al. [2015] Ronneberger, O., Fischer, P., Brox, T., 2015. U-Net:
    Convolutional Networks for Biomedical Image Segmentation, Springer, Cham, pp.
    234–241. URL: [http://link.springer.com/10.1007/978-3-319-24574-4_28](http://link.springer.com/10.1007/978-3-319-24574-4_28),
    doi:[10.1007/978-3-319-24574-4{\_}28](http://dx.doi.org/10.1007/978-3-319-24574-4_28).'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ronneberger 等人 [2015] Ronneberger, O., Fischer, P., Brox, T., 2015. U-Net:
    用于生物医学图像分割的卷积网络，Springer, Cham，第234–241页。网址：[http://link.springer.com/10.1007/978-3-319-24574-4_28](http://link.springer.com/10.1007/978-3-319-24574-4_28)，doi:[10.1007/978-3-319-24574-4{\_}28](http://dx.doi.org/10.1007/978-3-319-24574-4_28)。'
- en: 'Schlemper et al. [2019] Schlemper, J., Oktay, O., Schaap, M., Heinrich, M.,
    Kainz, B., Glocker, B., Rueckert, D., 2019. Attention gated networks: Learning
    to leverage salient regions in medical images. Medical Image Analysis 53, 197–207.
    doi:[10.1016/j.media.2019.01.012](http://dx.doi.org/10.1016/j.media.2019.01.012).'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schlemper 等人 [2019] Schlemper, J., Oktay, O., Schaap, M., Heinrich, M., Kainz,
    B., Glocker, B., Rueckert, D., 2019. 注意力门控网络：学习在医学图像中利用显著区域。《医学图像分析》53, 197–207。doi:[10.1016/j.media.2019.01.012](http://dx.doi.org/10.1016/j.media.2019.01.012)。
- en: Settles [2009] Settles, B., 2009. Active learning literature survey. Technical
    Report. University of Wisconsin-Madison Department of Computer Sciences.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Settles [2009] Settles, B., 2009. 活跃学习文献综述。技术报告。威斯康星大学麦迪逊分校计算机科学系。
- en: 'Settles and Craven [2008] Settles, B., Craven, M., 2008. An analysis of active
    learning strategies for sequence labeling tasks, in: Proceedings of the Conference
    on Empirical Methods in Natural Language Processing, Association for Computational
    Linguistics, USA. p. 1070–1079. doi:[10.5555/1613715.1613855](http://dx.doi.org/10.5555/1613715.1613855).'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Settles 和 Craven [2008] Settles, B., Craven, M., 2008. 活跃学习策略在序列标注任务中的分析，载于：自然语言处理实证方法会议论文集，计算语言学协会，美国。第1070–1079页。doi:[10.5555/1613715.1613855](http://dx.doi.org/10.5555/1613715.1613855)。
- en: 'Shah et al. [2018] Shah, M.P., Bhalgat, Y.S., Awate, S.P., 2018. Annotation-cost
    Minimization for Medical Image Segmentation using Suggestive Mixed Supervision
    Fully Convolutional Networks. Technical Report. URL: [https://www.doc.ic.ac.uk/~bglocker/public/mednips2018/med-nips_2018_paper_30.pdf](https://www.doc.ic.ac.uk/~bglocker/public/mednips2018/med-nips_2018_paper_30.pdf).'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shah 等人 [2018] Shah, M.P., Bhalgat, Y.S., Awate, S.P., 2018. 使用建议混合监督全卷积网络进行医学图像分割的标注成本最小化。技术报告。网址：[https://www.doc.ic.ac.uk/~bglocker/public/mednips2018/med-nips_2018_paper_30.pdf](https://www.doc.ic.ac.uk/~bglocker/public/mednips2018/med-nips_2018_paper_30.pdf)。
- en: '[78] Shannon, C.E., . A Mathematical Theory of Communication. Technical Report.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] 香农, C.E.，《通信的数学理论》。技术报告。'
- en: 'Shen et al. [2017] Shen, D., Wu, G., Suk, H.I., 2017. Deep Learning in Medical
    Image Analysis. Annual review of biomedical engineering 19, 221–248. URL: [http://www.ncbi.nlm.nih.gov/pubmed/28301734http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5479722](http://www.ncbi.nlm.nih.gov/pubmed/28301734http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5479722),
    doi:[10.1146/annurev-bioeng-071516-044442](http://dx.doi.org/10.1146/annurev-bioeng-071516-044442).'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等人 [2017] Shen, D., Wu, G., Suk, H.I., 2017. 医学图像分析中的深度学习。《生物医学工程年鉴》19,
    221–248。网址：[http://www.ncbi.nlm.nih.gov/pubmed/28301734http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5479722](http://www.ncbi.nlm.nih.gov/pubmed/28301734http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5479722)，doi:[10.1146/annurev-bioeng-071516-044442](http://dx.doi.org/10.1146/annurev-bioeng-071516-044442)。
- en: 'Smailagic et al. [2018] Smailagic, A., Noh, H.Y., Costa, P., Walawalkar, D.,
    Khandelwal, K., Mirshekari, M., Fagert, J., Galdran, A., Xu, S., 2018. MedAL:
    Deep Active Learning Sampling Method for Medical Image Analysis. undefined URL:
    [https://www.semanticscholar.org/paper/MedAL%3A-Deep-Active-Learning-Sampling-Method-for-Smailagic-Noh/fa23dc7a8b3927953d83f5ce46e0b622b7cac456](https://www.semanticscholar.org/paper/MedAL%3A-Deep-Active-Learning-Sampling-Method-for-Smailagic-Noh/fa23dc7a8b3927953d83f5ce46e0b622b7cac456).'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Smailagic 等人 [2018] Smailagic, A., Noh, H.Y., Costa, P., Walawalkar, D., Khandelwal,
    K., Mirshekari, M., Fagert, J., Galdran, A., Xu, S., 2018。MedAL：用于医学图像分析的深度主动学习采样方法。未定义网址：[https://www.semanticscholar.org/paper/MedAL%3A-Deep-Active-Learning-Sampling-Method-for-Smailagic-Noh/fa23dc7a8b3927953d83f5ce46e0b622b7cac456](https://www.semanticscholar.org/paper/MedAL%3A-Deep-Active-Learning-Sampling-Method-for-Smailagic-Noh/fa23dc7a8b3927953d83f5ce46e0b622b7cac456)。
- en: 'Sourati et al. [2018] Sourati, J., Gholipour, A., Dy, J.G., Kurugol, S., Warfield,
    S.K., 2018. Active Deep Learning with Fisher Information for Patch-Wise Semantic
    Segmentation, in: Deep learning in medical image analysis and multimodal learning
    for clinical decision support : 4th International Workshop, DLMIA 2018, and 8th
    International Workshop, ML-CDS 2018, held in conjunction with MICCAI 2018, Granada,
    Spain, S…. volume 11045, pp. 83–91. URL: [http://www.ncbi.nlm.nih.gov/pubmed/30450490http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6235453http://link.springer.com/10.1007/978-3-030-00889-5_10](http://www.ncbi.nlm.nih.gov/pubmed/30450490http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6235453http://link.springer.com/10.1007/978-3-030-00889-5_10),
    doi:[10.1007/978-3-030-00889-5{\_}10](http://dx.doi.org/10.1007/978-3-030-00889-5_10).'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sourati 等人 [2018] Sourati, J., Gholipour, A., Dy, J.G., Kurugol, S., Warfield,
    S.K., 2018。基于费舍尔信息的主动深度学习用于补丁级语义分割，见：医学图像分析中的深度学习与临床决策支持的多模态学习：第 4 届国际研讨会 DLMIA
    2018 和第 8 届国际研讨会 ML-CDS 2018，与 MICCAI 2018 一同举办，西班牙格拉纳达，S…。第 11045 卷，第 83–91 页。网址：[http://www.ncbi.nlm.nih.gov/pubmed/30450490http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6235453http://link.springer.com/10.1007/978-3-030-00889-5_10](http://www.ncbi.nlm.nih.gov/pubmed/30450490http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6235453http://link.springer.com/10.1007/978-3-030-00889-5_10)，doi：[10.1007/978-3-030-00889-5{\_}10](http://dx.doi.org/10.1007/978-3-030-00889-5_10)。
- en: 'Stember et al. [2019] Stember, J.N., Celik, H., Krupinski, E., Chang, P.D.,
    Mutasa, S., Wood, B.J., Lignelli, A., Moonis, G., Schwartz, L.H., Jambawalikar,
    S., Bagci, U., 2019. Eye Tracking for Deep Learning Segmentation Using Convolutional
    Neural Networks. Journal of Digital Imaging 32, 597–604. URL: [http://link.springer.com/10.1007/s10278-019-00220-4](http://link.springer.com/10.1007/s10278-019-00220-4),
    doi:[10.1007/s10278-019-00220-4](http://dx.doi.org/10.1007/s10278-019-00220-4).'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stember 等人 [2019] Stember, J.N., Celik, H., Krupinski, E., Chang, P.D., Mutasa,
    S., Wood, B.J., Lignelli, A., Moonis, G., Schwartz, L.H., Jambawalikar, S., Bagci,
    U., 2019。使用卷积神经网络进行深度学习分割的眼动追踪。《数字成像杂志》32, 597–604。网址：[http://link.springer.com/10.1007/s10278-019-00220-4](http://link.springer.com/10.1007/s10278-019-00220-4)，doi：[10.1007/s10278-019-00220-4](http://dx.doi.org/10.1007/s10278-019-00220-4)。
- en: 'Stoyanov et al. [2018] Stoyanov, D., Taylor, Z., Kia, S.M., Oguz, I., Reyes,
    M., Martel, A., Maier-Hein, L., Marquand, A.F., Duchesnay, E., Löfstedt, T., Landman,
    B., Cardoso, M.J., Silva, C.A., Pereira, S., Meier, R. (Eds.), 2018. Understanding
    and Interpreting Machine Learning in Medical Image Computing Applications. volume
    11038 of Lecture Notes in Computer Science. Springer International Publishing,
    Cham. URL: [http://link.springer.com/10.1007/978-3-030-02628-8](http://link.springer.com/10.1007/978-3-030-02628-8),
    doi:[10.1007/978-3-030-02628-8](http://dx.doi.org/10.1007/978-3-030-02628-8).'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stoyanov 等人 [2018] Stoyanov, D., Taylor, Z., Kia, S.M., Oguz, I., Reyes, M.,
    Martel, A., Maier-Hein, L., Marquand, A.F., Duchesnay, E., Löfstedt, T., Landman,
    B., Cardoso, M.J., Silva, C.A., Pereira, S., Meier, R. (编辑)，2018。理解与解释医学图像计算应用中的机器学习。计算机科学讲义系列第
    11038 卷。施普林格国际出版公司，查姆。网址：[http://link.springer.com/10.1007/978-3-030-02628-8](http://link.springer.com/10.1007/978-3-030-02628-8)，doi：[10.1007/978-3-030-02628-8](http://dx.doi.org/10.1007/978-3-030-02628-8)。
- en: 'Suzuki [2017] Suzuki, K., 2017. Overview of deep learning in medical imaging.
    Radiological Physics and Technology 10, 257–273. URL: [http://www.ncbi.nlm.nih.gov/pubmed/28689314http://link.springer.com/10.1007/s12194-017-0406-5](http://www.ncbi.nlm.nih.gov/pubmed/28689314http://link.springer.com/10.1007/s12194-017-0406-5),
    doi:[10.1007/s12194-017-0406-5](http://dx.doi.org/10.1007/s12194-017-0406-5).'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suzuki [2017] Suzuki, K., 2017。医学影像中的深度学习概述。《放射物理与技术》10, 257–273。网址：[http://www.ncbi.nlm.nih.gov/pubmed/28689314http://link.springer.com/10.1007/s12194-017-0406-5](http://www.ncbi.nlm.nih.gov/pubmed/28689314http://link.springer.com/10.1007/s12194-017-0406-5)，doi：[10.1007/s12194-017-0406-5](http://dx.doi.org/10.1007/s12194-017-0406-5)。
- en: 'Tajbakhsh et al. [2020] Tajbakhsh, N., Jeyaseelan, L., Li, Q., Chiang, J.N.,
    Wu, Z., Ding, X., 2020. Embracing imperfect datasets: A review of deep learning
    solutions for medical image segmentation. Medical Image Analysis 63, 101693. doi:[10.1016/j.media.2020.101693](http://dx.doi.org/10.1016/j.media.2020.101693).'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tajbakhsh 等人 [2020] Tajbakhsh, N., Jeyaseelan, L., Li, Q., Chiang, J.N., Wu,
    Z., Ding, X., 2020. 拥抱不完美的数据集：医疗图像分割深度学习解决方案的综述。医学图像分析 63, 101693. doi:[10.1016/j.media.2020.101693](http://dx.doi.org/10.1016/j.media.2020.101693)。
- en: 'Tajbakhsh et al. [2016] Tajbakhsh, N., Shin, J.Y., Gurudu, S.R., Hurst, R.T.,
    Kendall, C.B., Gotway, M.B., Liang, J., 2016. Convolutional Neural Networks for
    Medical Image Analysis: Full Training or Fine Tuning? IEEE Transactions on Medical
    Imaging 35, 1299–1312. URL: [http://ieeexplore.ieee.org/document/7426826/](http://ieeexplore.ieee.org/document/7426826/),
    doi:[10.1109/TMI.2016.2535302](http://dx.doi.org/10.1109/TMI.2016.2535302).'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tajbakhsh 等人 [2016] Tajbakhsh, N., Shin, J.Y., Gurudu, S.R., Hurst, R.T., Kendall,
    C.B., Gotway, M.B., Liang, J., 2016. 用于医学图像分析的卷积神经网络：全面训练还是微调？IEEE 医学成像汇刊 35,
    1299–1312. URL: [http://ieeexplore.ieee.org/document/7426826/](http://ieeexplore.ieee.org/document/7426826/),
    doi:[10.1109/TMI.2016.2535302](http://dx.doi.org/10.1109/TMI.2016.2535302)。'
- en: 'Tinati et al. [2017] Tinati, R., Luczak-Roesch, M., Simperl, E., Hall, W.,
    2017. An investigation of player motivations in Eyewire, a gamified citizen science
    project. Computers in Human Behavior 73, 527–540. URL: [https://ac.els-cdn.com/S0747563216309037/1-s2.0-S0747563216309037-main.pdf?_tid=abaecc23-8276-4fab-ad47-300db95a3b56&acdnat=1523979569_9e91cf49a50416e7c8772bfb73614a6b](https://ac.els-cdn.com/S0747563216309037/1-s2.0-S0747563216309037-main.pdf?_tid=abaecc23-8276-4fab-ad47-300db95a3b56&acdnat=1523979569_9e91cf49a50416e7c8772bfb73614a6b),
    doi:[10.1016/j.chb.2016.12.074](http://dx.doi.org/10.1016/j.chb.2016.12.074).'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tinati 等人 [2017] Tinati, R., Luczak-Roesch, M., Simperl, E., Hall, W., 2017.
    对游戏化公民科学项目 Eyewire 中玩家动机的调查。人类行为中的计算机 73, 527–540. URL: [https://ac.els-cdn.com/S0747563216309037/1-s2.0-S0747563216309037-main.pdf?_tid=abaecc23-8276-4fab-ad47-300db95a3b56&acdnat=1523979569_9e91cf49a50416e7c8772bfb73614a6b](https://ac.els-cdn.com/S0747563216309037/1-s2.0-S0747563216309037-main.pdf?_tid=abaecc23-8276-4fab-ad47-300db95a3b56&acdnat=1523979569_9e91cf49a50416e7c8772bfb73614a6b),
    doi:[10.1016/j.chb.2016.12.074](http://dx.doi.org/10.1016/j.chb.2016.12.074)。'
- en: 'Tizhoosh and Pantanowitz [2018] Tizhoosh, H.R., Pantanowitz, L., 2018. Artificial
    Intelligence and Digital Pathology: Challenges and Opportunities. Journal of pathology
    informatics 9, 38. URL: [http://www.ncbi.nlm.nih.gov/pubmed/30607305](http://www.ncbi.nlm.nih.gov/pubmed/30607305),
    doi:[10.4103/jpi.jpi{\_}53{\_}18](http://dx.doi.org/10.4103/jpi.jpi_53_18).'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tizhoosh 和 Pantanowitz [2018] Tizhoosh, H.R., Pantanowitz, L., 2018. 人工智能与数字病理学：挑战与机遇。病理信息学杂志
    9, 38. URL: [http://www.ncbi.nlm.nih.gov/pubmed/30607305](http://www.ncbi.nlm.nih.gov/pubmed/30607305),
    doi:[10.4103/jpi.jpi{\_}53{\_}18](http://dx.doi.org/10.4103/jpi.jpi_53_18)。'
- en: 'Wang et al. [2019a] Wang, D., Li, M., Ben-Shlomo, N., Corrales, C.E., Cheng,
    Y., Zhang, T., Jayender, J., 2019a. Mixed-Supervised Dual-Network for Medical
    Image Segmentation, in: Lecture Notes in Computer Science (including subseries
    Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),
    Springer. pp. 192–200. URL: [https://doi.org/10.1007/978-3-030-32245-8_22](https://doi.org/10.1007/978-3-030-32245-8_22),
    doi:[10.1007/978-3-030-32245-8{\_}22](http://dx.doi.org/10.1007/978-3-030-32245-8_22).'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等人 [2019a] Wang, D., Li, M., Ben-Shlomo, N., Corrales, C.E., Cheng, Y.,
    Zhang, T., Jayender, J., 2019a. 混合监督双网络用于医学图像分割，在：计算机科学讲义（包括人工智能讲义和生物信息学讲义），Springer.
    pp. 192–200. URL: [https://doi.org/10.1007/978-3-030-32245-8_22](https://doi.org/10.1007/978-3-030-32245-8_22),
    doi:[10.1007/978-3-030-32245-8{\_}22](http://dx.doi.org/10.1007/978-3-030-32245-8_22)。'
- en: Wang et al. [2019b] Wang, G., Li, W., Aertsen, M., Deprest, J., Ourselin, S.,
    Vercauteren, T., 2019b. Aleatoric uncertainty estimation with test-time augmentation
    for medical image segmentation with convolutional neural networks. Neurocomputing
    338, 34–45. doi:[10.1016/J.NEUCOM.2019.01.103](http://dx.doi.org/10.1016/J.NEUCOM.2019.01.103).
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2019b] Wang, G., Li, W., Aertsen, M., Deprest, J., Ourselin, S., Vercauteren,
    T., 2019b. 通过测试时间增强估计医学图像分割中的随机不确定性，使用卷积神经网络。神经计算 338, 34–45. doi:[10.1016/J.NEUCOM.2019.01.103](http://dx.doi.org/10.1016/J.NEUCOM.2019.01.103)。
- en: Wang et al. [2018] Wang, G., Li, W., Zuluaga, M.A., Pratt, R., Patel, P.A.,
    Aertsen, M., Doel, T., David, A.L., Deprest, J., Ourselin, S., Vercauteren, T.,
    2018. Interactive medical image segmentation using deep learning with image-specific
    fine tuning. IEEE Transactions on Medical Imaging 37, 1562–1573.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2018] Wang, G., Li, W., Zuluaga, M.A., Pratt, R., Patel, P.A., Aertsen,
    M., Doel, T., David, A.L., Deprest, J., Ourselin, S., Vercauteren, T., 2018. 使用深度学习与图像特定微调的互动医学图像分割。IEEE
    医学成像汇刊 37, 1562–1573。
- en: 'Wang et al. [2019] Wang, G., Zuluaga, M.A., Li, W., Pratt, R., Patel, P.A.,
    Aertsen, M., Doel, T., David, A.L., Deprest, J., Ourselin, S., Vercauteren, T.,
    2019. Deepigeos: A deep interactive geodesic framework for medical image segmentation.
    IEEE Transactions on Pattern Analysis and Machine Intelligence 41, 1559–1572.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 [2019] Wang, G., Zuluaga, M.A., Li, W., Pratt, R., Patel, P.A., Aertsen,
    M., Doel, T., David, A.L., Deprest, J., Ourselin, S., Vercauteren, T., 2019. Deepigeos：一种用于医学图像分割的深度交互式测地框架。IEEE
    Transactions on Pattern Analysis and Machine Intelligence 41, 1559–1572。
- en: 'Wang et al. [2019] Wang, H., Rivenson, Y., Jin, Y., Wei, Z., Gao, R., Günaydın,
    H., Bentolila, L.A., Kural, C., Ozcan, A., 2019. Deep learning enables cross-modality
    super-resolution in fluorescence microscopy. Nature Methods 16, 103–110. URL:
    [https://www.nature.com/articles/s41592-018-0239-0](https://www.nature.com/articles/s41592-018-0239-0),
    doi:[10.1038/s41592-018-0239-0](http://dx.doi.org/10.1038/s41592-018-0239-0).'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等 [2019] Wang, H., Rivenson, Y., Jin, Y., Wei, Z., Gao, R., Günaydın,
    H., Bentolila, L.A., Kural, C., Ozcan, A., 2019. 深度学习实现荧光显微镜中的跨模态超分辨率。Nature Methods
    16, 103–110。网址: [https://www.nature.com/articles/s41592-018-0239-0](https://www.nature.com/articles/s41592-018-0239-0)，doi:[10.1038/s41592-018-0239-0](http://dx.doi.org/10.1038/s41592-018-0239-0)。'
- en: Wang et al. [2017] Wang, K., Zhang, D., Li, Y., Zhang, R., Lin, L., 2017. Cost-Effective
    Active Learning for Deep Image Classification. IEEE Transactions on Circuits and
    Systems for Video Technology 27, 2591–2600. doi:[10.1109/TCSVT.2016.2589879](http://dx.doi.org/10.1109/TCSVT.2016.2589879).
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 [2017] Wang, K., Zhang, D., Li, Y., Zhang, R., Lin, L., 2017. 成本效益高的主动学习用于深度图像分类。IEEE
    Transactions on Circuits and Systems for Video Technology 27, 2591–2600。doi:[10.1109/TCSVT.2016.2589879](http://dx.doi.org/10.1109/TCSVT.2016.2589879)。
- en: 'Wang et al. [2018] Wang, Y., Yu, B., Wang, L., Zu, C., Lalush, D.S., Lin, W.,
    Wu, X., Zhou, J., Shen, D., Zhou, L., 2018. 3D conditional generative adversarial
    networks for high-quality PET image estimation at low dose. NeuroImage 174, 550–562.
    URL: [https://pubmed.ncbi.nlm.nih.gov/29571715/](https://pubmed.ncbi.nlm.nih.gov/29571715/),
    doi:[10.1016/j.neuroimage.2018.03.045](http://dx.doi.org/10.1016/j.neuroimage.2018.03.045).'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等 [2018] Wang, Y., Yu, B., Wang, L., Zu, C., Lalush, D.S., Lin, W., Wu,
    X., Zhou, J., Shen, D., Zhou, L., 2018. 3D 条件生成对抗网络用于低剂量 PET 图像的高质量估计。NeuroImage
    174, 550–562。网址: [https://pubmed.ncbi.nlm.nih.gov/29571715/](https://pubmed.ncbi.nlm.nih.gov/29571715/)，doi:[10.1016/j.neuroimage.2018.03.045](http://dx.doi.org/10.1016/j.neuroimage.2018.03.045)。'
- en: 'Wen et al. [2018] Wen, S., Kurc, T.M., Hou, L., Saltz, J.H., Gupta, R.R., Batiste,
    R., Zhao, T., Nguyen, V., Samaras, D., Zhu, W., 2018. Comparison of Different
    Classifiers with Active Learning to Support Quality Control in Nucleus Segmentation
    in Pathology Images. AMIA Joint Summits on Translational Science proceedings.
    AMIA Joint Summits on Translational Science 2017, 227–236. URL: [http://www.ncbi.nlm.nih.gov/pubmed/29888078](http://www.ncbi.nlm.nih.gov/pubmed/29888078).'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wen 等 [2018] Wen, S., Kurc, T.M., Hou, L., Saltz, J.H., Gupta, R.R., Batiste,
    R., Zhao, T., Nguyen, V., Samaras, D., Zhu, W., 2018. 比较不同分类器与主动学习在病理图像中支持核分割质量控制的效果。AMIA
    联合翻译科学峰会会议记录。AMIA 联合翻译科学峰会 2017, 227–236。网址: [http://www.ncbi.nlm.nih.gov/pubmed/29888078](http://www.ncbi.nlm.nih.gov/pubmed/29888078)。'
- en: 'Woodward et al. [2017] Woodward, M., Finn, C., Research, B.A., 2017. Active
    One-shot Learning. Technical Report. URL: [https://arxiv.org/pdf/1702.06559.pdf](https://arxiv.org/pdf/1702.06559.pdf).'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Woodward 等 [2017] Woodward, M., Finn, C., Research, B.A., 2017. 主动单次学习。技术报告。网址:
    [https://arxiv.org/pdf/1702.06559.pdf](https://arxiv.org/pdf/1702.06559.pdf)。'
- en: 'Xia et al. [2020] Xia, Y., Liu, F., Yang, D., Cai, J., Yu, L., Zhu, Z., Xu,
    D., Yuille, A., Roth, H., 2020. 3d semi-supervised learning with uncertainty-aware
    multi-view co-training, in: 2020 IEEE Winter Conference on Applications of Computer
    Vision (WACV), pp. 3635–3644.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xia 等 [2020] Xia, Y., Liu, F., Yang, D., Cai, J., Yu, L., Zhu, Z., Xu, D., Yuille,
    A., Roth, H., 2020. 3D 半监督学习与不确定性感知多视图协同训练，见于：2020 IEEE 冬季计算机视觉应用会议 (WACV)，第 3635–3644
    页。
- en: 'Yamashita et al. [2018] Yamashita, R., Nishio, M., Do, R.K.G., Togashi, K.,
    2018. Convolutional neural networks: an overview and application in radiology.
    Insights into Imaging 9, 611–629. URL: [https://insightsimaging.springeropen.com/articles/10.1007/s13244-018-0639-9](https://insightsimaging.springeropen.com/articles/10.1007/s13244-018-0639-9),
    doi:[10.1007/s13244-018-0639-9](http://dx.doi.org/10.1007/s13244-018-0639-9).'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yamashita 等 [2018] Yamashita, R., Nishio, M., Do, R.K.G., Togashi, K., 2018.
    卷积神经网络：概述及其在放射学中的应用。Insights into Imaging 9, 611–629。网址: [https://insightsimaging.springeropen.com/articles/10.1007/s13244-018-0639-9](https://insightsimaging.springeropen.com/articles/10.1007/s13244-018-0639-9)，doi:[10.1007/s13244-018-0639-9](http://dx.doi.org/10.1007/s13244-018-0639-9)。'
- en: 'Yang et al. [2017] Yang, L., Zhang, Y., Chen, J., Zhang, S., Chen, D.Z., 2017.
    Suggestive Annotation: A Deep Active Learning Framework for Biomedical Image Segmentation,
    Springer, Cham, pp. 399–407. URL: [http://link.springer.com/10.1007/978-3-319-66179-7_46](http://link.springer.com/10.1007/978-3-319-66179-7_46),
    doi:[10.1007/978-3-319-66179-7{\_}46](http://dx.doi.org/10.1007/978-3-319-66179-7_46).'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang et al. [2017] Yang, L., Zhang, Y., Chen, J., Zhang, S., Chen, D.Z., 2017.
    Suggestive Annotation：一个深度主动学习框架用于生物医学图像分割，Springer，Cham，第399–407页。URL: [http://link.springer.com/10.1007/978-3-319-66179-7_46](http://link.springer.com/10.1007/978-3-319-66179-7_46),
    doi:[10.1007/978-3-319-66179-7{\_}46](http://dx.doi.org/10.1007/978-3-319-66179-7_46)。'
- en: 'Yi et al. [2019] Yi, X., Walia, E., Babyn, P., 2019. Generative adversarial
    network in medical imaging: A review. Medical Image Analysis 58, 101552. doi:[10.1016/j.media.2019.101552](http://dx.doi.org/10.1016/j.media.2019.101552).'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yi et al. [2019] Yi, X., Walia, E., Babyn, P., 2019. 医学成像中的生成对抗网络：综述。医学图像分析
    58, 101552。doi:[10.1016/j.media.2019.101552](http://dx.doi.org/10.1016/j.media.2019.101552)。
- en: 'Yu et al. [2019] Yu, B., Zhou, L., Wang, L., Shi, Y., Fripp, J., Bourgeat,
    P., 2019. Ea-GANs: Edge-Aware Generative Adversarial Networks for Cross-Modality
    MR Image Synthesis. IEEE Transactions on Medical Imaging 38, 1750–1762. doi:[10.1109/TMI.2019.2895894](http://dx.doi.org/10.1109/TMI.2019.2895894).'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu et al. [2019] Yu, B., Zhou, L., Wang, L., Shi, Y., Fripp, J., Bourgeat, P.,
    2019. Ea-GANs：边缘感知生成对抗网络用于跨模态磁共振图像合成。IEEE医学成像学报 38, 1750–1762。doi:[10.1109/TMI.2019.2895894](http://dx.doi.org/10.1109/TMI.2019.2895894)。
- en: 'Zhang and Chaudhuri [2015] Zhang, C., Chaudhuri, K., 2015. Active learning
    from weak and strong labelers, in: Proceedings of the 28th International Conference
    on Neural Information Processing Systems - Volume 1, MIT Press, Cambridge, MA,
    USA. p. 703–711. doi:[10.5555/2969239.2969318](http://dx.doi.org/10.5555/2969239.2969318).'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang and Chaudhuri [2015] Zhang, C., Chaudhuri, K., 2015. 从弱标注者和强标注者中进行主动学习，发表于：第28届国际神经信息处理系统会议
    - 第1卷，麻省理工学院出版社，剑桥，MA，美国，第703–711页。doi:[10.5555/2969239.2969318](http://dx.doi.org/10.5555/2969239.2969318)。
- en: Zhang and Chen [2002] Zhang, C., Chen, T., 2002. An active learning framework
    for content-based information retrieval. IEEE Trans. Multimedia 4, 260–268.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang and Chen [2002] Zhang, C., Chen, T., 2002. 基于内容的信息检索的主动学习框架。IEEE多媒体学报
    4, 260–268。
- en: 'Zhao et al. [2019] Zhao, A., Balakrishnan, G., Durand, F., Guttag, J.V., Dalca,
    A.V., 2019. Data augmentation using learned transformations for one-shot medical
    image segmentation, in: Proceedings of the IEEE conference on computer vision
    and pattern recognition, pp. 8543–8553.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao et al. [2019] Zhao, A., Balakrishnan, G., Durand, F., Guttag, J.V., Dalca,
    A.V., 2019. 使用学习到的变换进行数据增强，以实现一次性医学图像分割，发表于：IEEE计算机视觉与模式识别会议论文集，第8543–8553页。
- en: Zheng et al. [2015] Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V.,
    Su, Z., Du, D., Huang, C., Torr, P.H.S., 2015. Conditional Random Fields as Recurrent
    Neural Networks. Technical Report.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. [2015] Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V.,
    Su, Z., Du, D., Huang, C., Torr, P.H.S., 2015. 条件随机场作为递归神经网络。技术报告。
- en: 'Zhou et al. [2018a] Zhou, Z., Shin, J., Feng, R., Hurst, R.T., Kendall, C.B.,
    Liang, J., 2018a. Integrating Active Learning and Transfer Learning for Carotid
    Intima-Media Thickness Video Interpretation. Journal of Digital Imaging URL: [http://www.ncbi.nlm.nih.gov/pubmed/30402668http://link.springer.com/10.1007/s10278-018-0143-2](http://www.ncbi.nlm.nih.gov/pubmed/30402668http://link.springer.com/10.1007/s10278-018-0143-2),
    doi:[10.1007/s10278-018-0143-2](http://dx.doi.org/10.1007/s10278-018-0143-2).'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou et al. [2018a] Zhou, Z., Shin, J., Feng, R., Hurst, R.T., Kendall, C.B.,
    Liang, J., 2018a. 将主动学习与迁移学习结合用于颈动脉内膜中层厚度视频解读。数字成像杂志 URL: [http://www.ncbi.nlm.nih.gov/pubmed/30402668http://link.springer.com/10.1007/s10278-018-0143-2](http://www.ncbi.nlm.nih.gov/pubmed/30402668http://link.springer.com/10.1007/s10278-018-0143-2),
    doi:[10.1007/s10278-018-0143-2](http://dx.doi.org/10.1007/s10278-018-0143-2)。'
- en: 'Zhou et al. [2018b] Zhou, Z., Shin, J., Feng, R., Hurst, R.T., Kendall, C.B.,
    Liang, J., 2018b. Integrating Active Learning and Transfer Learning for Carotid
    Intima-Media Thickness Video Interpretation. Journal of Digital Imaging URL: [http://www.ncbi.nlm.nih.gov/pubmed/30402668http://link.springer.com/10.1007/s10278-018-0143-2](http://www.ncbi.nlm.nih.gov/pubmed/30402668http://link.springer.com/10.1007/s10278-018-0143-2),
    doi:[10.1007/s10278-018-0143-2](http://dx.doi.org/10.1007/s10278-018-0143-2).'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou et al. [2018b] Zhou, Z., Shin, J., Feng, R., Hurst, R.T., Kendall, C.B.,
    Liang, J., 2018b. 将主动学习与迁移学习结合用于颈动脉内膜中层厚度视频解读。数字成像杂志 URL: [http://www.ncbi.nlm.nih.gov/pubmed/30402668http://link.springer.com/10.1007/s10278-018-0143-2](http://www.ncbi.nlm.nih.gov/pubmed/30402668http://link.springer.com/10.1007/s10278-018-0143-2),
    doi:[10.1007/s10278-018-0143-2](http://dx.doi.org/10.1007/s10278-018-0143-2)。'
- en: 'Zhou et al. [2017] Zhou, Z., Shin, J., Zhang, L., Gurudu, S., Gotway, M., Liang,
    J., 2017. Fine-tuning Convolutional Neural Networks for Biomedical Image Analysis:
    Actively and Incrementally. Proceedings. IEEE Computer Society Conference on Computer
    Vision and Pattern Recognition 2017, 4761. URL: [http://www.ncbi.nlm.nih.gov/pubmed/30337799http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6191179](http://www.ncbi.nlm.nih.gov/pubmed/30337799http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6191179),
    doi:[10.1109/CVPR.2017.506](http://dx.doi.org/10.1109/CVPR.2017.506).'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou等人[2017] Zhou, Z., Shin, J., Zhang, L., Gurudu, S., Gotway, M., Liang, J.,
    2017. 微调卷积神经网络用于生物医学图像分析：主动和增量式。会议录。IEEE计算机视觉与模式识别会议2017，4761。网址：[http://www.ncbi.nlm.nih.gov/pubmed/30337799http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6191179](http://www.ncbi.nlm.nih.gov/pubmed/30337799http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6191179)，doi：[10.1109/CVPR.2017.506](http://dx.doi.org/10.1109/CVPR.2017.506)。
- en: Supplementary Material
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附加材料
- en: '![Refer to caption](img/076cb9c4d9af80a8af08516ef754ea05.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/076cb9c4d9af80a8af08516ef754ea05.png)'
- en: 'Fig. 4: Table of features demonstrated by work discussed in this review'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：本综述讨论的工作所展示的特征表
