- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:09:03'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:09:03
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1702.05747] A Survey on Deep Learning in Medical Image Analysis'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1702.05747] 关于深度学习在医学影像分析中的调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1702.05747](https://ar5iv.labs.arxiv.org/html/1702.05747)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1702.05747](https://ar5iv.labs.arxiv.org/html/1702.05747)
- en: A Survey on Deep Learning in Medical Image Analysis
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于深度学习在医学影像分析中的调查
- en: Geert Litjens, Thijs Kooi, Babak Ehteshami Bejnordi, Arnaud Arindra Adiyoso
    Setio, Francesco Ciompi,
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Geert Litjens, Thijs Kooi, Babak Ehteshami Bejnordi, Arnaud Arindra Adiyoso
    Setio, Francesco Ciompi,
- en: Mohsen Ghafoorian, Jeroen A.W.M. van der Laak, Bram van Ginneken, Clara I. Sánchez
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Mohsen Ghafoorian, Jeroen A.W.M. van der Laak, Bram van Ginneken, Clara I. Sánchez
- en: Diagnostic Image Analysis Group
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断影像分析组
- en: Radboud University Medical Center
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 拉德布德大学医学中心
- en: Nijmegen, The Netherlands
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尼梅根，荷兰
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Deep learning algorithms, in particular convolutional networks, have rapidly
    become a methodology of choice for analyzing medical images. This paper reviews
    the major deep learning concepts pertinent to medical image analysis and summarizes
    over 300 contributions to the field, most of which appeared in the last year.
    We survey the use of deep learning for image classification, object detection,
    segmentation, registration, and other tasks. Concise overviews are provided of
    studies per application area: neuro, retinal, pulmonary, digital pathology, breast,
    cardiac, abdominal, musculoskeletal. We end with a summary of the current state-of-the-art,
    a critical discussion of open challenges and directions for future research.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习算法，特别是卷积网络，迅速成为分析医学影像的首选方法。本文回顾了与医学影像分析相关的主要深度学习概念，并总结了300多篇相关领域的贡献，大多数出现在过去一年。我们调查了深度学习在图像分类、对象检测、分割、配准和其他任务中的应用。针对每个应用领域提供了简明的概述：神经影像、视网膜影像、肺部影像、数字病理、乳腺影像、心脏影像、腹部影像、肌肉骨骼影像。最后，我们总结了当前的最先进技术，对开放挑战和未来研究方向进行了批判性的讨论。
- en: 'keywords:'
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: deep learning , convolutional neural networks , medical imaging , survey
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习，卷积神经网络，医学影像，调查
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: As soon as it was possible to scan and load medical images into a computer,
    researchers have built systems for automated analysis. Initially, from the 1970s
    to the 1990s, medical image analysis was done with sequential application of low-level
    pixel processing (edge and line detector filters, region growing) and mathematical
    modeling (fitting lines, circles and ellipses) to construct compound rule-based
    systems that solved particular tasks. There is an analogy with expert systems
    with many if-then-else statements that were popular in artificial intelligence
    in the same period. These expert systems have been described as GOFAI (good old-fashioned
    artificial intelligence) (Haugeland, [1985](#bib.bib121)) and were often brittle;
    similar to rule-based image processing systems.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦可以将医学影像扫描并加载到计算机中，研究人员就开始建立自动化分析系统。最初，从1970年代到1990年代，医学影像分析是通过低级像素处理（边缘和线检测滤波器、区域生长）和数学建模（拟合线条、圆和椭圆）的顺序应用来构建复合规则基础系统，从而解决特定任务。这与同一时期人工智能中流行的包含许多
    if-then-else 语句的专家系统相似。这些专家系统被称为 GOFAI（好老式人工智能）（Haugeland, [1985](#bib.bib121)），并且往往很脆弱；类似于基于规则的图像处理系统。
- en: At the end of the 1990s, supervised techniques, where training data is used
    to develop a system, were becoming increasingly popular in medical image analysis.
    Examples include active shape models (for segmentation), atlas methods (where
    the atlases that are fit to new data form the training data), and the concept
    of feature extraction and use of statistical classifiers (for computer-aided detection
    and diagnosis). This pattern recognition or machine learning approach is still
    very popular and forms the basis of many successful commercially available medical
    image analysis systems. Thus, we have seen a shift from systems that are completely
    designed by humans to systems that are trained by computers using example data
    from which feature vectors are extracted. Computer algorithms determine the optimal
    decision boundary in the high-dimensional feature space. A crucial step in the
    design of such systems is the extraction of discriminant features from the images.
    This process is still done by human researchers and, as such, one speaks of systems
    with handcrafted features.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在1990年代末期，监督技术（通过训练数据来开发系统）在医学图像分析中变得越来越流行。例子包括主动形状模型（用于分割）、图谱方法（通过与新数据匹配的图谱形成训练数据），以及特征提取和统计分类器的概念（用于计算机辅助检测和诊断）。这种模式识别或机器学习方法仍然非常受欢迎，并形成了许多成功的商业医学图像分析系统的基础。因此，我们看到系统从完全由人设计转变为通过计算机使用示例数据进行训练的系统，从中提取特征向量。计算机算法确定高维特征空间中的最佳决策边界。设计此类系统的关键步骤是从图像中提取判别特征。这个过程仍然由人类研究人员完成，因此，这些系统被称为具有手工制作特征的系统。
- en: 'A logical next step is to let computers learn the features that optimally represent
    the data for the problem at hand. This concept lies at the basis of many deep
    learning algorithms: models (networks) composed of many layers that transform
    input data (e.g. images) to outputs (e.g. disease present/absent) while learning
    increasingly higher level features. The most successful type of models for image
    analysis to date are convolutional neural networks (CNNs). CNNs contain many layers
    that transform their input with convolution filters of a small extent. Work on
    CNNs has been done since the late seventies (Fukushima, [1980](#bib.bib99)) and
    they were already applied to medical image analysis in 1995 by Lo et al. ([1995](#bib.bib180)).
    They saw their first successful real-world application in LeNet (LeCun et al.,
    [1998](#bib.bib167)) for hand-written digit recognition. Despite these initial
    successes, the use of CNNs did not gather momentum until various new techniques
    were developed for efficiently training deep networks, and advances were made
    in core computing systems. The watershed was the contribution of Krizhevsky et al.
    ([2012](#bib.bib165)) to the ImageNet challenge in December 2012\. The proposed
    CNN, called AlexNet, won that competition by a large margin. In subsequent years,
    further progress has been made using related but deeper architectures (Russakovsky
    et al., [2014](#bib.bib241)). In computer vision, deep convolutional networks
    have now become the technique of choice.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑上的下一步是让计算机学习能够最佳表示问题数据的特征。这个概念是许多深度学习算法的基础：由多个层组成的模型（网络）将输入数据（例如图像）转换为输出（例如疾病有无），同时学习越来越高层次的特征。到目前为止，用于图像分析的最成功的模型类型是卷积神经网络（CNNs）。CNNs包含许多层，这些层通过小范围的卷积滤波器来转换输入。自70年代末期以来，关于CNNs的研究已经展开（Fukushima,
    [1980](#bib.bib99)），并且在1995年，Lo等人（[1995](#bib.bib180)）已经将其应用于医学图像分析。它们在LeNet（LeCun
    et al., [1998](#bib.bib167)）中首次成功应用于手写数字识别。尽管有这些初步成功，直到开发出各种新技术以高效训练深度网络，并在核心计算系统上取得进展，CNNs的使用才开始得到广泛关注。转折点是Krizhevsky等人（[2012](#bib.bib165)）在2012年12月的ImageNet挑战赛中的贡献。提出的CNN称为AlexNet，以大幅领先赢得了那次比赛。随后几年，使用相关但更深层次的架构（Russakovsky
    et al., [2014](#bib.bib241)）取得了进一步的进展。在计算机视觉领域，深度卷积网络现已成为首选技术。
- en: The medical image analysis community has taken notice of these pivotal developments.
    However, the transition from systems that use handcrafted features to systems
    that learn features from the data has been gradual. Before the breakthrough of
    AlexNet, many different techniques to learn features were popular. Bengio et al.
    ([2013](#bib.bib27)) provide a thorough review of these techniques. They include
    principal component analysis, clustering of image patches, dictionary approaches,
    and many more. Bengio et al. ([2013](#bib.bib27)) introduce CNNs that are trained
    end-to-end only at the end of their review in a section entitled Global training
    of deep models. In this survey, we focus particularly on such deep models, and
    do not include the more traditional feature learning approaches that have been
    applied to medical images. For a broader review on the application of deep learning
    in health informatics we refer to Ravi et al. ([2017](#bib.bib227)), where medical
    image analysis is briefly touched upon.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 医学图像分析社区已经注意到这些关键性进展。然而，从使用手工特征的系统到从数据中学习特征的系统的过渡是渐进的。在AlexNet突破之前，许多不同的特征学习技术曾经流行。Bengio等人（[2013](#bib.bib27)）对这些技术进行了全面的回顾。其中包括主成分分析、图像块的聚类、字典方法等。Bengio等人（[2013](#bib.bib27)）在回顾的最后部分的“深度模型的全局训练”一节中介绍了仅在这一部分训练的CNN。在本调查中，我们特别关注这样的深度模型，而不包括那些已应用于医学图像的更传统的特征学习方法。有关深度学习在健康信息学中的应用的更广泛回顾，请参阅Ravi等人（[2017](#bib.bib227)），其中简要涉及了医学图像分析。
- en: Applications of deep learning to medical image analysis first started to appear
    at workshops and conferences, and then in journals. The number of papers grew
    rapidly in 2015 and 2016\. This is illustrated in Figure [1](#S1.F1 "Figure 1
    ‣ 1 Introduction ‣ A Survey on Deep Learning in Medical Image Analysis"). The
    topic is now dominant at major conferences and a first special issue appeared
    of IEEE Transaction on Medical Imaging in May 2016 (Greenspan et al., [2016](#bib.bib114)).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在医学图像分析中的应用最初出现在研讨会和会议上，然后在期刊中出现。2015年和2016年论文数量迅速增长。图[1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ A Survey on Deep Learning in Medical Image Analysis")中对此进行了说明。该主题现在在主要会议中占主导地位，并且2016年5月IEEE医学影像学交易的首个特刊已发布（Greenspan等人，[2016](#bib.bib114)）。
- en: '![Refer to caption](img/c3f4d045c22705070bf888b6dd588681.png)![Refer to caption](img/4c7cb7004f3d79f5f891b696c363f92f.png)![Refer
    to caption](img/e21674891f0353bc17a0d5c73d98a6cc.png)![Refer to caption](img/c90ce4da1f8a139f444b326c3ad47544.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c3f4d045c22705070bf888b6dd588681.png)![参见说明](img/4c7cb7004f3d79f5f891b696c363f92f.png)![参见说明](img/e21674891f0353bc17a0d5c73d98a6cc.png)![参见说明](img/c90ce4da1f8a139f444b326c3ad47544.png)'
- en: 'Figure 1: Breakdown of the papers included in this survey in year of publication,
    task addressed (Section [3](#S3 "3 Deep Learning Uses in Medical Imaging ‣ A Survey
    on Deep Learning in Medical Image Analysis")), imaging modality, and application
    area (Section [4](#S4 "4 Anatomical application areas ‣ A Survey on Deep Learning
    in Medical Image Analysis")). The number of papers for 2017 has been extrapolated
    from the papers published in January.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：本调查中所包含论文的出版年份、所涉及的任务（第[3](#S3 "3 Deep Learning Uses in Medical Imaging ‣
    A Survey on Deep Learning in Medical Image Analysis")节）、成像模式和应用领域（第[4](#S4 "4
    Anatomical application areas ‣ A Survey on Deep Learning in Medical Image Analysis")节）的详细分解。2017年的论文数量是通过对1月份发表的论文进行外推得出的。
- en: One dedicated review on application of deep learning to medical image analysis
    was published by Shen et al. ([2017](#bib.bib253)). Although they cover a substantial
    amount of work, we feel that important areas of the field were not represented.
    To give an example, no work on retinal image analysis was covered. The motivation
    for our review was to offer a comprehensive overview of (almost) all fields in
    medical imaging, both from an application and a methodology-drive perspective.
    This also includes overview tables of all publications which readers can use to
    quickly assess the field. Last, we leveraged our own experience with the application
    of deep learning methods to medical image analysis to provide readers with a dedicated
    discussion section covering the state-of-the-art, open challenges and overview
    of research directions and technologies that will become important in the future.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Shen等人发表了一篇关于深度学习在医学图像分析应用的专门综述 ([2017](#bib.bib253))。虽然他们涵盖了大量的工作，但我们认为该领域的重要领域并未得到体现。举个例子，他们没有涵盖视网膜图像分析的工作。我们撰写这篇综述的动机是提供一个（几乎）所有医学成像领域的全面概述，涵盖应用和方法驱动的视角。这还包括所有出版物的概述表格，读者可以使用这些表格快速评估该领域。最后，我们利用自己在医学图像分析中应用深度学习方法的经验，为读者提供了一个专门讨论当前技术水平、面临的挑战以及未来将变得重要的研究方向和技术的讨论部分。
- en: This survey includes over 300 papers, most of them recent, on a wide variety
    of applications of deep learning in medical image analysis. To identify relevant
    contributions PubMed was queried for papers containing (”convolutional” OR ”deep
    learning”) in title or abstract. ArXiv was searched for papers mentioning one
    of a set of terms related to medical imaging. Additionally, conference proceedings
    for MICCAI (including workshops), SPIE, ISBI and EMBC were searched based on titles
    of papers. We checked references in all selected papers and consulted colleagues.
    We excluded papers that did not report results on medical image data or only used
    standard feed-forward neural networks with handcrafted features. When overlapping
    work had been reported in multiple publications, only the publication(s) deemed
    most important were included. We expect the search terms used to cover most, if
    not all, of the work incorporating deep learning methods. The last update to the
    included papers was on February 1, 2017\. The appendix describes the search process
    in more detail.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查包含了300多篇论文，其中大多数是近期的，涵盖了深度学习在医学图像分析中的广泛应用。为了识别相关贡献，我们查询了PubMed中标题或摘要包含（”卷积”
    OR ”深度学习”）的论文。我们还搜索了ArXiv中提到与医学成像相关的术语的论文。此外，我们根据论文标题搜索了MICCAI（包括研讨会）、SPIE、ISBI和EMBC的会议论文集。我们检查了所有选定论文中的参考文献，并咨询了同事。我们排除了那些未报告医学图像数据结果或仅使用标准前馈神经网络与手工特征的论文。当重复的工作在多篇出版物中报告时，只有被认为最重要的出版物被纳入。我们预计所使用的搜索词覆盖了大多数，如果不是全部的话，涉及深度学习方法的工作。所包含论文的最后更新是在2017年2月1日。附录中详细描述了搜索过程。
- en: 'Summarizing, with this survey we aim to:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们的调查旨在：
- en: '1.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1.'
- en: show that deep learning techniques have permeated the entire field of medical
    image analysis;
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 证明深度学习技术已经渗透到医学图像分析的整个领域；
- en: '2.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2.'
- en: identify the challenges for successful application of deep learning to medical
    imaging tasks;
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确定将深度学习成功应用于医学成像任务的挑战；
- en: '3.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '3.'
- en: highlight specific contributions which solve or circumvent these challenges.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 突出具体贡献，解决或绕过这些挑战。
- en: 'The rest of this survey as structured as followed. In Section [2](#S2 "2 Overview
    of deep learning methods ‣ A Survey on Deep Learning in Medical Image Analysis")
    we introduce the main deep learning techniques that have been used for medical
    image analysis and that are referred to throughout the survey. Section [3](#S3
    "3 Deep Learning Uses in Medical Imaging ‣ A Survey on Deep Learning in Medical
    Image Analysis") describes the contributions of deep learning to canonical tasks
    in medical image analysis: classification, detection, segmentation, registration,
    retrieval, image generation and enhancement. Section [4](#S4 "4 Anatomical application
    areas ‣ A Survey on Deep Learning in Medical Image Analysis") discusses obtained
    results and open challenges in different application areas: neuro, ophthalmic,
    pulmonary, digital pathology and cell imaging, breast, cardiac, abdominal, musculoskeletal,
    and remaining miscellaneous applications. We end with a summary, a critical discussion
    and an outlook for future research.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查的其余部分结构如下。在[2](#S2 "2 Overview of deep learning methods ‣ A Survey on Deep
    Learning in Medical Image Analysis")节中，我们介绍了用于医学图像分析的主要深度学习技术，并在整个调查中提到这些技术。[3](#S3
    "3 Deep Learning Uses in Medical Imaging ‣ A Survey on Deep Learning in Medical
    Image Analysis")节描述了深度学习在医学图像分析中的经典任务的贡献：分类、检测、分割、配准、检索、图像生成和增强。[4](#S4 "4 Anatomical
    application areas ‣ A Survey on Deep Learning in Medical Image Analysis")节讨论了在不同应用领域获得的结果和面临的挑战：神经、眼科、肺部、数字病理学和细胞成像、乳腺、心脏、腹部、肌肉骨骼以及其他杂项应用。我们以总结、批判性讨论和对未来研究的展望结束。
- en: 2 Overview of deep learning methods
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 深度学习方法概述
- en: The goal of this section is to provide a formal introduction and definition
    of the deep learning concepts, techniques and architectures that we found in the
    medical image analysis papers surveyed in this work.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是提供一个正式的介绍和定义我们在医学图像分析论文中发现的深度学习概念、技术和架构。
- en: 2.1 Learning algorithms
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 学习算法
- en: Machine learning methods are generally divided into supervised and unsupervised
    learning algorithms, although there are many nuances. In supervised learning,
    a model is presented with a dataset $\mathcal{D}=\{{\bf x},y\}^{N}_{n=1}$ of input
    features ${\bf x}$ and label $y$ pairs, where $y$ typically represents an instance
    of a fixed set of classes. In the case of regression tasks $y$ can also be a vector
    with continuous values. Supervised training typically amounts to finding model
    parameters $\Theta$ that best predict the data based on a loss function $L(y,\hat{y})$.
    Here $\hat{y}$ denotes the output of the model obtained by feeding a data point
    ${\bf x}$ to the function $f({\bf x};\Theta)$ that represents the model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习方法通常分为监督学习和无监督学习算法，尽管有许多细微差别。在监督学习中，模型会接收到一个数据集 $\mathcal{D}=\{{\bf x},y\}^{N}_{n=1}$，其中包含输入特征
    ${\bf x}$ 和标签 $y$ 对，其中 $y$ 通常表示固定类别集合中的一个实例。在回归任务中，$y$ 也可以是具有连续值的向量。监督训练通常是找到最佳预测数据的模型参数
    $\Theta$，基于损失函数 $L(y,\hat{y})$。这里 $\hat{y}$ 表示通过将数据点 ${\bf x}$ 输入到代表模型的函数 $f({\bf
    x};\Theta)$ 中得到的模型输出。
- en: Unsupervised learning algorithms process data without labels and are trained
    to find patterns, such as latent subspaces. Examples of traditional unsupervised
    learning algorithms are principal component analysis and clustering methods. Unsupervised
    training can be performed under many different loss functions. One example is
    reconstruction loss $L({\bf x},\hat{{\bf x}})$ where the model has to learn to
    reconstruct its input, often through a lower-dimensional or noisy representation.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习算法处理没有标签的数据，并被训练以寻找模式，如潜在的子空间。传统的无监督学习算法的例子包括主成分分析和聚类方法。无监督训练可以在许多不同的损失函数下进行。一个例子是重构损失
    $L({\bf x},\hat{{\bf x}})$，其中模型必须学会重构其输入，通常通过较低维度或噪声表示。
- en: 2.2 Neural Networks
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 神经网络
- en: 'Neural networks are a type of learning algorithm which forms the basis of most
    deep learning methods. A neural network comprises of neurons or units with some
    activation $a$ and parameters $\Theta=\{\mathcal{W},\mathcal{B}\}$, where $\mathcal{W}$
    is a set of weights and $\mathcal{B}$ a set of biases. The activation represents
    a linear combination of the input ${\bf x}$ to the neuron and the parameters,
    followed by an element-wise non-linearity $\sigma(\cdot)$, referred to as a transfer
    function:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络是一种学习算法，构成了大多数深度学习方法的基础。一个神经网络由一些具有激活 $a$ 和参数 $\Theta=\{\mathcal{W},\mathcal{B}\}$
    的神经元或单元组成，其中 $\mathcal{W}$ 是一组权重，$\mathcal{B}$ 是一组偏置。激活表示输入 ${\bf x}$ 到神经元的线性组合和参数，随后是逐元素的非线性函数
    $\sigma(\cdot)$，称为传递函数：
- en: '|  | $a=\sigma({\bf w}^{T}{\bf x}+b).$ |  | (1) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|  | $a=\sigma({\bf w}^{T}{\bf x}+b).$ |  | (1) |'
- en: 'Typical transfer functions for traditional neural networks are the sigmoid
    and hyperbolic tangent function. The multi-layered perceptrons (MLP), the most
    well-known of the traditional neural networks, have several layers of these transformations:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 传统神经网络的典型传递函数是 sigmoid 和双曲正切函数。多层感知机（MLP），作为最著名的传统神经网络，具有多个这些变换层：
- en: '|  | $f({\bf x};\Theta)=\sigma({\bf W}^{T}\sigma({\bf W}^{T}\ldots\sigma({\bf
    W}^{T}{\bf x}+b))+b).$ |  | (2) |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | $f({\bf x};\Theta)=\sigma({\bf W}^{T}\sigma({\bf W}^{T}\ldots\sigma({\bf
    W}^{T}{\bf x}+b))+b).$ |  | (2) |'
- en: Here, ${\bf W}$ is a matrix comprising of columns ${\bf w}_{k}$, associated
    with activation $k$ in the output. Layers in between the input and output are
    often referred to as ’hidden’ layers. When a neural network contains multiple
    hidden layers it is typically considered a ’deep’ neural network, hence the term
    ’deep learning’.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，${\bf W}$ 是一个矩阵，包含列 ${\bf w}_{k}$，与输出中的激活 $k$ 相关联。输入层和输出层之间的层通常被称为“隐藏”层。当神经网络包含多个隐藏层时，通常被认为是“深层”神经网络，因此有了“深度学习”这个术语。
- en: 'At the final layer of the network the activations are mapped to a distribution
    over classes $P(y|{\bf x};\Theta)$ through a softmax function:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络的最终层，激活值通过 softmax 函数被映射到类别分布 $P(y|{\bf x};\Theta)$ 上：
- en: '|  | $P(y&#124;{\bf x};\Theta)=\text{softmax}({\bf x};\Theta)=\frac{e^{{\bf
    w}_{i}^{T}{\bf x}+b_{i}}}{\sum^{K}_{k=1}e^{{\bf w}_{k}^{T}{\bf x}+b_{k}}},$ |  |
    (3) |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '|  | $P(y|{\bf x};\Theta)=\text{softmax}({\bf x};\Theta)=\frac{e^{{\bf w}_{i}^{T}{\bf
    x}+b_{i}}}{\sum^{K}_{k=1}e^{{\bf w}_{k}^{T}{\bf x}+b_{k}}},$ |  | (3) |'
- en: where ${\bf w}_{i}$ indicates the weight vector leading to the output node associated
    with class $i$. A schematic representation of three-layer MLP is shown in Figure
    [2](#S2.F2 "Figure 2 ‣ 2.7 Hardware and Software ‣ 2 Overview of deep learning
    methods ‣ A Survey on Deep Learning in Medical Image Analysis").
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ${\bf w}_{i}$ 表示通向与类别 $i$ 相关联的输出节点的权重向量。三层 MLP 的示意图见图 [2](#S2.F2 "Figure
    2 ‣ 2.7 Hardware and Software ‣ 2 Overview of deep learning methods ‣ A Survey
    on Deep Learning in Medical Image Analysis")。
- en: 'Maximum likelihood with stochastic gradient descent is currently the most popular
    method to fit parameters $\Theta$ to a dataset $\mathcal{D}$. In stochastic gradient
    descent a small subset of the data, a mini-batch, is used for each gradient update
    instead of the full data set. Optimizing maximum likelihood in practice amounts
    to minimizing the negative log-likelihood:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，最大似然估计与随机梯度下降是拟合参数 $\Theta$ 到数据集 $\mathcal{D}$ 的最流行方法。在随机梯度下降中，数据的一个小子集，即小批量，用于每次梯度更新，而不是整个数据集。实际中优化最大似然即是最小化负对数似然：
- en: '|  | $\arg\min_{\Theta}-\sum^{N}_{n=1}\log\big{[}P(y_{n}&#124;{\bf x}_{n};\Theta)\big{]}.$
    |  | (4) |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | $\arg\min_{\Theta}-\sum^{N}_{n=1}\log\big{[}P(y_{n}|{\bf x}_{n};\Theta)\big{]}.$
    |  | (4) |'
- en: This results in the binary cross-entropy loss for two-class problems and the
    categorical cross-entropy for multi-class tasks. A downside of this approach is
    that it typically does not optimize the quantity we are interested in directly,
    such as area under the receiver-operating characteristic (ROC) curve or common
    evaluation measures for segmentation, such as the Dice coefficient.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了二分类问题的二元交叉熵损失和多分类任务的分类交叉熵损失。这种方法的一个缺点是，它通常不会直接优化我们感兴趣的量，例如接收者操作特征（ROC）曲线下的面积或分割的常见评估指标，如
    Dice 系数。
- en: For a long time, deep neural networks (DNN) were considered hard to train efficiently.
    They only gained popularity in 2006 (Bengio et al., [2007](#bib.bib28); Hinton
    and Salakhutdinov, [2006](#bib.bib127); Hinton et al., [2006](#bib.bib126)) when
    it was shown that training DNNs layer-by-layer in an unsupervised manner (pre-training),
    followed by supervised fine-tuning of the stacked network, could result in good
    performance. Two popular architectures trained in such a way are stacked auto-encoders
    (SAEs) and deep belief networks (DBNs). However, these techniques are rather complex
    and require a significant amount of engineering to generate satisfactory results.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 长时间以来，深度神经网络（DNN）被认为很难高效训练。直到2006年（Bengio等，[2007](#bib.bib28); Hinton和Salakhutdinov，[2006](#bib.bib127);
    Hinton等，[2006](#bib.bib126)）才开始流行，当时展示了以无监督的方式（预训练）逐层训练DNN，再通过有监督的方式对堆叠网络进行微调，可以取得良好的性能。以这种方式训练的两个流行架构是堆叠自编码器（SAEs）和深度置信网络（DBNs）。然而，这些技术相当复杂，需要大量的工程工作才能生成令人满意的结果。
- en: Currently, the most popular models are trained end-to-end in a supervised fashion,
    greatly simplifying the training process. The most popular architectures are convolutional
    neural networks (CNNs) and recurrent neural networks (RNNs). CNNs are currently
    most widely used in (medical) image analysis, although RNNs are gaining popularity.
    The following sections will give a brief overview of each of these methods, starting
    with the most popular ones, and discussing their differences and potential challenges
    when applied to medical problems.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，最流行的模型是以有监督的方式进行端到端训练，大大简化了训练过程。最流行的架构是卷积神经网络（CNNs）和递归神经网络（RNNs）。CNNs目前在（医学）图像分析中最为广泛使用，尽管RNNs正在获得越来越多的关注。接下来的部分将简要概述这些方法中的每一种，从最流行的开始，并讨论它们在应用于医学问题时的差异和潜在挑战。
- en: 2.3 Convolutional Neural Networks (CNNs)
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 卷积神经网络（CNNs）
- en: There are two key differences between MLPs and CNNs. First, in CNNs weights
    in the network are shared in such a way that it the network performs convolution
    operations on images. This way, the model does not need to learn separate detectors
    for the same object occurring at different positions in an image, making the network
    equivariant with respect to translations of the input. It also drastically reduces
    the amount of parameters (i.e. the number of weights no longer depends on the
    size of the input image) that need to be learned. An example of a 1D CNN is shown
    in Figure [2](#S2.F2 "Figure 2 ‣ 2.7 Hardware and Software ‣ 2 Overview of deep
    learning methods ‣ A Survey on Deep Learning in Medical Image Analysis").
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: MLPs和CNNs之间有两个关键区别。首先，在CNNs中，网络中的权重是共享的，使得网络对图像执行卷积操作。这样，模型不需要为图像中不同位置出现的相同对象学习单独的检测器，从而使网络在输入的平移方面具有等变性。这也大大减少了需要学习的参数量（即权重的数量不再依赖于输入图像的大小）。图1D
    CNN的示例见图[2](#S2.F2 "Figure 2 ‣ 2.7 Hardware and Software ‣ 2 Overview of deep
    learning methods ‣ A Survey on Deep Learning in Medical Image Analysis")。
- en: 'At each layer, the input image is convolved with a set of $K$ kernels $\mathcal{W}=\{{\bf
    W}_{1},{\bf W}_{2},\ldots,{\bf W}_{K}\}$ and added biases $\mathcal{B}=\{b_{1},\ldots,b_{K}\}$,
    each generating a new feature map ${\bf X}_{k}$. These features are subjected
    to an element-wise non-linear transform $\sigma(\cdot)$ and the same process is
    repeated for every convolutional layer $l$:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一层中，输入图像会与一组$K$个核$\mathcal{W}=\{{\bf W}_{1},{\bf W}_{2},\ldots,{\bf W}_{K}\}$和添加的偏置$\mathcal{B}=\{b_{1},\ldots,b_{K}\}$进行卷积，每个核生成一个新的特征图${\bf
    X}_{k}$。这些特征经过逐元素的非线性变换$\sigma(\cdot)$，然后对每个卷积层$l$重复相同的过程：
- en: '|  | ${\bf X}_{k}^{l}=\sigma\big{(}{\bf W}_{k}^{l-1}\ast{\bf X}^{l-1}+b_{k}^{l-1}\big{)}.$
    |  | (5) |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|  | ${\bf X}_{k}^{l}=\sigma\big{(}{\bf W}_{k}^{l-1}\ast{\bf X}^{l-1}+b_{k}^{l-1}\big{)}.$
    |  | (5) |'
- en: The second key difference between CNNs and MLPs, is the typical incorporation
    of pooling layers in CNNs, where pixel values of neighborhoods are aggregated
    using a permutation invariant function, typically the max or mean operation. This
    induces a certain amount of translation invariance and again reduces the amount
    of parameters in the network. At the end of the convolutional stream of the network,
    fully-connected layers (i.e. regular neural network layers) are usually added,
    where weights are no longer shared. Similar to MLPs, a distribution over classes
    is generated by feeding the activations in the final layer through a softmax function
    and the network is trained using maximum likelihood.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 和 MLP 之间的第二个主要区别是 CNN 中典型地包含池化层，其中邻域的像素值使用置换不变函数（通常是最大值或均值操作）进行聚合。这引入了一定程度的平移不变性，并再次减少了网络中的参数数量。在网络的卷积流的末尾，通常会添加全连接层（即常规神经网络层），在这些层中权重不再共享。类似于
    MLP，通过将最终层的激活输入 softmax 函数生成类别分布，并使用最大似然法进行训练。
- en: 2.4 Deep CNN Architectures
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 深度 CNN 架构
- en: Given the prevalence of CNNs in medical image analysis, we elaborate on the
    most common architectures and architectural differences among the widely used
    models.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于 CNN 在医学图像分析中的广泛应用，我们详细讨论了最常见的架构以及广泛使用模型之间的架构差异。
- en: 2.4.1 General classification architectures
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.1 通用分类架构
- en: LeNet (LeCun et al., [1998](#bib.bib167)) and AlexNet (Krizhevsky et al., [2012](#bib.bib165)),
    introduced over a decade later, were in essence very similar models. Both networks
    were relatively shallow, consisting of two and five convolutional layers, respectively,
    and employed kernels with large receptive fields in layers close to the input
    and smaller kernels closer to the output. AlexNet did incorporate rectified linear
    units instead of the hyperbolic tangent as activation function.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet（LeCun 等，[1998](#bib.bib167)）和 AlexNet（Krizhevsky 等，[2012](#bib.bib165)）在十多年后被引入，本质上是非常相似的模型。这两个网络都相对较浅，分别由两个和五个卷积层组成，并且在接近输入的层中使用了大感受野的卷积核，而在接近输出的层中使用了较小的卷积核。AlexNet
    确实采用了修正线性单元作为激活函数，而不是双曲正切函数。
- en: After 2012 the exploration of novel architectures took off, and in the last
    three years there is a preference for far deeper models. By stacking smaller kernels,
    instead of using a single layer of kernels with a large receptive field, a similar
    function can be represented with less parameters. These deeper architectures generally
    have a lower memory footprint during inference, which enable their deployment
    on mobile computing devices such as smartphones. Simonyan and Zisserman ([2014](#bib.bib264))
    were the first to explore much deeper networks, and employed small, fixed size
    kernels in each layer. A 19-layer model often referred to as VGG19 or OxfordNet
    won the ImageNet challenge of 2014.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 2012 年后，探索新架构的工作开始加速，最近三年中更倾向于更深的模型。通过堆叠较小的卷积核，而不是使用单层大感受野的卷积核，可以用更少的参数表示类似的功能。这些更深的架构在推理过程中通常具有较低的内存占用，从而使其能够在如智能手机等移动计算设备上部署。Simonyan
    和 Zisserman（[2014](#bib.bib264)）首次探索了更深的网络，并在每一层中使用了小的固定大小卷积核。一个常被称为 VGG19 或 OxfordNet
    的 19 层模型赢得了 2014 年的 ImageNet 挑战。
- en: On top of the deeper networks, more complex building blocks have been introduced
    that improve the efficiency of the training procedure and again reduce the amount
    of parameters. Szegedy et al. ([2014](#bib.bib282)) introduced a 22-layer network
    named GoogLeNet, also referred to as Inception, which made use of so-called inception
    blocks (Lin et al., [2013](#bib.bib175)), a module that replaces the mapping defined
    in Eq. ([5](#S2.E5 "In 2.3 Convolutional Neural Networks (CNNs) ‣ 2 Overview of
    deep learning methods ‣ A Survey on Deep Learning in Medical Image Analysis"))
    with a set of convolutions of different sizes. Similar to the stacking of small
    kernels, this allows a similar function to be represented with less parameters.
    The ResNet architecture (He et al., [2015](#bib.bib124)) won the ImageNet challenge
    in 2015 and consisted of so-called ResNet-blocks. Rather than learning a function,
    the residual block only learns the residual and is thereby pre-conditioned towards
    learning mappings in each layer that are close to the identity function. This
    way, even deeper models can be trained effectively.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在更深的网络之上，引入了更复杂的构建模块，这些模块提高了训练过程的效率，并再次减少了参数的数量。Szegedy等人（[2014](#bib.bib282)）引入了一个名为GoogLeNet的22层网络，也称为Inception，该网络利用了所谓的inception块（Lin等，[2013](#bib.bib175)），这是一个用不同大小的卷积替代方程式中定义的映射的模块（见Eq. ([5](#S2.E5
    "In 2.3 Convolutional Neural Networks (CNNs) ‣ 2 Overview of deep learning methods
    ‣ A Survey on Deep Learning in Medical Image Analysis")）。类似于小卷积核的堆叠，这使得用更少的参数表示类似的功能成为可能。ResNet架构（He等，[2015](#bib.bib124)）在2015年赢得了ImageNet挑战赛，包含了所谓的ResNet块。Residual
    block不是学习一个函数，而是学习残差，因此预先条件化为学习每层中接近恒等函数的映射。这样，即使是更深的模型也可以有效地训练。
- en: Since 2014, the performance on the ImageNet benchmark has saturated and it is
    difficult to assess whether the small increases in performance can really be attributed
    to ’better’ and more sophisticated architectures. The advantage of the lower memory
    footprint these models provide is typically not as important for medical applications.
    Consequently, AlexNet or other simple models such as VGG are still popular for
    medical data, though recent landmark studies all use a version of GoogleNet called
    Inception v3 (Gulshan et al., [2016](#bib.bib115); Esteva et al., [2017](#bib.bib89);
    Liu et al., [2017](#bib.bib179)). Whether this is due to a superior architecture
    or simply because the model is a default choice in popular software packages is
    again difficult to assess.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 自2014年以来，ImageNet基准测试的表现已经趋于饱和，很难评估性能的小幅提升是否真的可以归因于“更好”的、更复杂的架构。这些模型提供的较低内存占用的优势通常对医疗应用并不那么重要。因此，尽管近期的重大研究都使用了一个叫做Inception
    v3的GoogleNet版本（Gulshan等，[2016](#bib.bib115)；Esteva等，[2017](#bib.bib89)；Liu等，[2017](#bib.bib179)），但AlexNet或其他简单模型如VGG仍然在医疗数据中很受欢迎。是否由于架构的优越性或仅仅是因为该模型在流行的软件包中是默认选择，这一点仍然难以评估。
- en: 2.4.2 Multi-stream architectures
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.2 多流架构
- en: 'The default CNN architecture can easily accommodate multiple sources of information
    or representations of the input, in the form of channels presented to the input
    layer. This idea can be taken further and channels can be merged at any point
    in the network. Under the intuition that different tasks require different ways
    of fusion, multi-stream architectures are being explored. These models, also referred
    to as dual pathway architectures (Kamnitsas et al., [2017](#bib.bib148)), have
    two main applications at the time of writing: (1) multi-scale image analysis and
    (2) 2.5D classification; both relevant for medical image processing tasks.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的CNN架构可以轻松容纳多种信息源或输入表示，以通道的形式呈现给输入层。这个想法可以进一步延伸，在网络中的任何点合并通道。基于不同任务需要不同融合方式的直觉，多流架构正在被探索。这些模型也被称为双通道架构（Kamnitsas等，[2017](#bib.bib148)），目前有两个主要应用：
    (1) 多尺度图像分析和 (2) 2.5D分类；这两者都与医疗图像处理任务相关。
- en: For the detection of abnormalities, context is often an important cue. The most
    straightforward way to increase context is to feed larger patches to the network,
    but this can significantly increase the amount of parameters and memory requirements
    of a network. Consequently, architectures have been investigated where context
    is added in a down-scaled representation in addition to high resolution local
    information. To the best of our knowledge, the multi-stream multi-scale architecture
    was first explored by Farabet et al. ([2013](#bib.bib90)), who used it for segmentation
    in natural images. Several medical applications have also successfully used this
    concept (Kamnitsas et al., [2017](#bib.bib148); Moeskops et al., [2016a](#bib.bib196);
    Song et al., [2015](#bib.bib269); Yang et al., [2016c](#bib.bib330)).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于异常检测，背景常常是一个重要的线索。增加背景的最直接方法是将更大的补丁输入网络，但这会显著增加网络的参数量和内存需求。因此，已经研究了在高分辨率局部信息的基础上添加缩放背景表示的架构。据我们了解，多流多尺度架构首次由
    Farabet 等人（[2013](#bib.bib90)）探索，他们将其用于自然图像的分割。一些医学应用也成功地使用了这一概念（Kamnitsas 等人，[2017](#bib.bib148)；Moeskops
    等人，[2016a](#bib.bib196)；Song 等人，[2015](#bib.bib269)；Yang 等人，[2016c](#bib.bib330)）。
- en: As so much methodology is still developed on natural images, the challenge of
    applying deep learning techniques to the medical domain often lies in adapting
    existing architectures to, for instance, different input formats such as three-dimensional
    data. In early applications of CNNs to such volumetric data, full 3D convolutions
    and the resulting large amount of parameters were circumvented by dividing the
    Volume of Interest (VOI) into slices which are fed as different streams to a network.
    Prasoon et al. ([2013](#bib.bib219)) were the first to use this approach for knee
    cartilage segmentation. Similarly, the network can be fed with multiple angled
    patches from the 3D-space in a multi-stream fashion, which has been applied by
    various authors in the context of medical imaging (Roth et al., [2016b](#bib.bib236);
    Setio et al., [2016](#bib.bib249)). These approaches are also referred to as 2.5D
    classification.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由于许多方法仍在自然图像上开发，将深度学习技术应用于医学领域的挑战通常在于将现有架构适应于不同的输入格式，例如三维数据。在早期将 CNN 应用于这种体积数据时，通过将兴趣体积（VOI）划分为切片并作为不同的流输入网络，从而规避了全三维卷积和由此产生的大量参数。Prasoon
    等人（[2013](#bib.bib219)）首次使用这种方法进行膝关节软骨分割。同样，网络可以以多流的方式从 3D 空间输入多个角度的补丁，这在医学成像的背景下被多个作者应用（Roth
    等人，[2016b](#bib.bib236)；Setio 等人，[2016](#bib.bib249)）。这些方法也被称为 2.5D 分类。
- en: 2.4.3 Segmentation Architectures
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.3 分割架构
- en: Segmentation is a common task in both natural and medical image analysis and
    to tackle this, CNNs can simply be used to classify each pixel in the image individually,
    by presenting it with patches extracted around the particular pixel. A drawback
    of this naive ’sliding-window’ approach is that input patches from neighboring
    pixels have huge overlap and the same convolutions are computed many times. Fortunately,
    the convolution and dot product are both linear operators and thus inner products
    can be written as convolutions and vice versa. By rewriting the fully connected
    layers as convolutions, the CNN can take input images larger than it was trained
    on and produce a likelihood map, rather than an output for a single pixel. The
    resulting ’fully convolutional network’ (fCNN) can then be applied to an entire
    input image or volume in an efficient fashion.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 分割是自然和医学图像分析中的常见任务，为此，可以简单地使用 CNN 来单独分类图像中的每个像素，通过将其呈现为提取的补丁。这个简单的“滑动窗口”方法的一个缺点是，相邻像素的输入补丁有大量重叠，相同的卷积被计算多次。幸运的是，卷积和点积都是线性运算符，因此内积可以被写作卷积，反之亦然。通过将全连接层重写为卷积，CNN
    可以处理比其训练时更大的输入图像，并生成一个可能性图，而不是单个像素的输出。由此产生的“全卷积网络”（fCNN）可以有效地应用于整个输入图像或体积。
- en: However, because of pooling layers, this may result in output with a far lower
    resolution than the input. ’Shift-and-stitch’ (Long et al., [2015](#bib.bib181))
    is one of several methods proposed to prevent this decrease in resolution. The
    fCNN is applied to shifted versions of the input image. By stitching the result
    together, one obtains a full resolution version of the final output, minus the
    pixels lost due to the ’valid’ convolutions.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于池化层，这可能导致输出的分辨率远低于输入。‘Shift-and-stitch’（Long 等人，[2015](#bib.bib181)）是为防止分辨率下降而提出的几种方法之一。fCNN
    被应用于输入图像的移位版本。通过将结果拼接在一起，可以获得最终输出的全分辨率版本，减去由于‘有效’卷积丢失的像素。
- en: Ronneberger et al. ([2015](#bib.bib232)) took the idea of the fCNN one step
    further and proposed the U-net architecture, comprising a ’regular’ fCNN followed
    by an upsampling part where ’up’-convolutions are used to increase the image size,
    coined contractive and expansive paths. Although this is not the first paper to
    introduce learned upsampling paths in convolutional neural networks (e.g.Long
    et al. ([2015](#bib.bib181))), the authors combined it with so called skip-connections
    to directly connect opposing contracting and expanding convolutional layers. A
    similar approach was used by Çiçek et al. ([2016](#bib.bib65)) for 3D data. Milletari
    et al. ([2016b](#bib.bib194)) proposed an extension to the U-Net layout that incorporates
    ResNet-like residual blocks and a Dice loss layer, rather than the conventional
    cross-entropy, that directly minimizes this commonly used segmentation error measure.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Ronneberger 等人 ([2015](#bib.bib232)) 将 fCNN 的概念进一步发展，提出了 U-net 架构，该架构包括一个“常规”
    fCNN，随后是一个上采样部分，其中使用“上”-卷积来增加图像大小，称为收缩路径和扩张路径。虽然这不是第一个在卷积神经网络中引入学习上采样路径的论文（例如
    Long 等人 ([2015](#bib.bib181)))，但作者将其与所谓的跳跃连接结合在一起，直接连接对立的收缩和扩张卷积层。Çiçek 等人 ([2016](#bib.bib65))
    对 3D 数据使用了类似的方法。Milletari 等人 ([2016b](#bib.bib194)) 提出了 U-Net 布局的扩展，包含了类似 ResNet
    的残差块和一个 Dice 损失层，而不是传统的交叉熵，直接最小化这一常用的分割误差度量。
- en: 2.5 Recurrent Neural Networks (RNNs)
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5 循环神经网络（RNNs）
- en: Traditionally, RNNs were developed for discrete sequence analysis. They can
    be seen as a generalization of MLPs because both the input and output can be of
    varying length, making them suitable for tasks such as machine translation where
    a sentence of the source and target language are the input and output. In a classification
    setting, the model learns a distribution over classes $P(y|{\bf x}_{1},{\bf x}_{2},\ldots,{\bf
    x}_{T};\Theta)$ given a sequence ${\bf x}_{1},{\bf x}_{2},\ldots,{\bf x}_{T}$,
    rather than a single input vector ${\bf x}$.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，RNNs 是为离散序列分析而开发的。它们可以被看作是 MLPs 的一种推广，因为输入和输出都可以具有不同的长度，使其适合于机器翻译等任务，其中源语言和目标语言的句子作为输入和输出。在分类设置中，模型学习给定序列
    ${\bf x}_{1},{\bf x}_{2},\ldots,{\bf x}_{T}$ 的类别分布 $P(y|{\bf x}_{1},{\bf x}_{2},\ldots,{\bf
    x}_{T};\Theta)$，而不是单一的输入向量 ${\bf x}$。
- en: 'The plain RNN maintains a latent or hidden state ${\bf h}$ at time $t$ that
    is the output of a non-linear mapping from its input ${\bf x}_{t}$ and the previous
    state ${\bf h}_{t-1}$:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 普通 RNN 在时间 $t$ 维持一个潜在或隐藏状态 ${\bf h}$，该状态是其输入 ${\bf x}_{t}$ 和前一状态 ${\bf h}_{t-1}$
    的非线性映射的输出：
- en: '|  | ${\bf h}_{t}=\sigma({\bf W}{\bf x}_{t}+{\bf R}{\bf h}_{t-1}+{\bf b}),$
    |  | (6) |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '|  | ${\bf h}_{t}=\sigma({\bf W}{\bf x}_{t}+{\bf R}{\bf h}_{t-1}+{\bf b}),$
    |  | (6) |'
- en: where weight matrices ${\bf W}$ and ${\bf R}$ are shared over time. For classification,
    one or more fully connected layers are typically added followed by a softmax to
    map the sequence to a posterior over the classes.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 其中权重矩阵 ${\bf W}$ 和 ${\bf R}$ 在时间上是共享的。对于分类，通常会添加一个或多个全连接层，然后通过 softmax 将序列映射到类别的后验概率。
- en: '|  | $P(y&#124;{\bf x}_{1},{\bf x}_{2},\ldots,{\bf x}_{T};\Theta)=\text{softmax}({\bf
    h}_{T};{\bf W}_{out},{\bf b}_{out}).$ |  | (7) |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '|  | $P(y&#124;{\bf x}_{1},{\bf x}_{2},\ldots,{\bf x}_{T};\Theta)=\text{softmax}({\bf
    h}_{T};{\bf W}_{out},{\bf b}_{out}).$ |  | (7) |'
- en: Since the gradient needs to be backpropagated from the output through time,
    RNNs are inherently deep (in time) and consequently suffer from the same problems
    with training as regular deep neural networks (Bengio et al., [1994](#bib.bib29)).
    To this end, several specialized memory units have been developed, the earliest
    and most popular being the Long Short Term Memory (LSTM) cell (Hochreiter and
    Schmidhuber, [1997](#bib.bib128)). The Gated Recurrent Unit (Cho et al., [2014](#bib.bib61))
    is a recent simplification of the LSTM and is also commonly used.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 由于梯度需要从输出通过时间进行反向传播，RNNs 天生具有深度（在时间上），因此面临与常规深度神经网络相同的训练问题（Bengio 等，[1994](#bib.bib29)）。为此，开发了几种专门的记忆单元，最早且最受欢迎的是长短期记忆（LSTM）单元（Hochreiter
    和 Schmidhuber，[1997](#bib.bib128)）。门控递归单元（Cho 等，[2014](#bib.bib61)）是对 LSTM 的一种最近简化，并且也被广泛使用。
- en: Although initially proposed for one-dimensional input, RNNs are increasingly
    applied to images. In natural images ’pixelRNNs’ are used as autoregressive models,
    generative models that can eventually produce new images similar to samples in
    the training set. For medical applications, they have been used for segmentation
    problems, with promising results (Stollenga et al., [2015](#bib.bib273)) in the
    MRBrainS challenge.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管最初是为一维输入提出的，但 RNNs 正越来越多地应用于图像。在自然图像中，‘pixelRNNs’ 被用作自回归模型，这些生成模型最终可以生成类似于训练集样本的新图像。对于医学应用，它们已被用于分割问题，并在
    MRBrainS 挑战中取得了有希望的结果（Stollenga 等，[2015](#bib.bib273)）。
- en: 2.6 Unsupervised models
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.6 无监督模型
- en: 2.6.1 Auto-encoders (AEs) and Stacked Auto-encoders (SAEs)
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.6.1 自编码器（AEs）和堆叠自编码器（SAEs）
- en: 'AEs are simple networks that are trained to reconstruct the input ${\bf x}$
    on the output layer ${\bf x}^{\prime}$ through one hidden layer ${\bf h}$. They
    are governed by a weight matrix ${\bf W}_{x,h}$ and bias $b_{x,h}$ from input
    to hidden state and ${\bf W}_{h,x^{\prime}}$ with corresponding bias $b_{h,x^{\prime}}$
    from the hidden layer to the reconstruction. A non-linear function is used to
    compute the hidden activation:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: AEs 是简单的网络，通过一个隐藏层 ${\bf h}$ 被训练以重建输入 ${\bf x}$ 到输出层 ${\bf x}^{\prime}$。它们由从输入到隐藏状态的权重矩阵
    ${\bf W}_{x,h}$ 和偏置 $b_{x,h}$ 以及从隐藏层到重建的权重矩阵 ${\bf W}_{h,x^{\prime}}$ 和相应的偏置 $b_{h,x^{\prime}}$
    控制。使用非线性函数来计算隐藏激活：
- en: '|  | ${\bf h}=\sigma({\bf W}_{x,h}{\bf x}+{\bf b}_{x,h}).$ |  | (8) |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '|  | ${\bf h}=\sigma({\bf W}_{x,h}{\bf x}+{\bf b}_{x,h}).$ |  | (8) |'
- en: Additionally, the dimension of the hidden layer $|{\bf h}|$ is taken to be smaller
    than $|{\bf x}|$. This way, the data is projected onto a lower dimensional subspace
    representing a dominant latent structure in the input. Regularization or sparsity
    constraints can be employed to enhance the discovery process. If the hidden layer
    had the same size as the input and no further non-linearities were added, the
    model would simply learn the identity function.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，隐藏层的维度 $|{\bf h}|$ 被设定为小于 $|{\bf x}|$。这样，数据被投影到表示输入中主要潜在结构的低维子空间。可以使用正则化或稀疏约束来增强发现过程。如果隐藏层的大小与输入相同且没有添加其他非线性函数，模型将只是学习身份函数。
- en: The denoising auto-encoder (Vincent et al., [2010](#bib.bib299)) is another
    solution to prevent the model from learning a trivial solution. Here the model
    is trained to reconstruct the input from a noise corrupted version (typically
    salt-and-pepper-noise). SAEs (or deep AEs) are formed by placing auto-encoder
    layers on top of each other. In medical applications surveyed in this work, auto-encoder
    layer were often trained individually (‘greedily’) after which the full network
    was fine-tuned using supervised training to make a prediction.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 去噪自编码器（Vincent 等，[2010](#bib.bib299)）是防止模型学习到简单解决方案的另一种方法。这里，模型被训练以从噪声污染版本（通常是盐和胡椒噪声）中重建输入。SAEs（或深度
    AEs）通过将自编码器层堆叠在一起形成。在本文调查的医学应用中，自编码器层通常被单独训练（“贪婪地”），然后使用监督训练对整个网络进行微调以进行预测。
- en: 2.6.2 Restricted Boltzmann Machines (RBMs) and Deep Belief Networks (DBNs)
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.6.2 受限玻尔兹曼机（RBMs）和深度置信网络（DBNs）
- en: 'RBMs (Hinton, [2010](#bib.bib125)) are a type of Markov Random Field (MRF),
    constituting an input layer or visible layer ${\bf x}=(x_{1},x_{2},\ldots,x_{N})$
    and a hidden layer ${\bf h}=(h_{1},h_{2},\ldots,h_{M})$ that carries the latent
    feature representation. The connections between the nodes are bi-directional,
    so given an input vector $\bf x$ one can obtain the latent feature representation
    $\bf h$ and also vice versa. As such, the RBM is a generative model, and we can
    sample from it and generate new data points. In analogy to physical systems, an
    energy function is defined for a particular state $({\bf x},{\bf h})$ of input
    and hidden units:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: RBMs（Hinton, [2010](#bib.bib125)）是一种马尔可夫随机场（MRF），由一个输入层或可见层 ${\bf x}=(x_{1},x_{2},\ldots,x_{N})$
    和一个隐藏层 ${\bf h}=(h_{1},h_{2},\ldots,h_{M})$ 组成，该隐藏层携带潜在特征表示。节点之间的连接是双向的，因此给定一个输入向量
    $\bf x$ 可以得到潜在特征表示 $\bf h$，反之亦然。因此，RBM 是一个生成模型，我们可以从中采样并生成新的数据点。类比于物理系统，为输入和隐藏单元的特定状态
    $({\bf x},{\bf h})$ 定义了一个能量函数：
- en: '|  | $E({\bf x},{\bf h})={\bf h}^{T}{\bf W}{\bf x}-{\bf c}^{T}{\bf x}-{\bf
    b}^{T}{\bf h},$ |  | (9) |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '|  | $E({\bf x},{\bf h})={\bf h}^{T}{\bf W}{\bf x}-{\bf c}^{T}{\bf x}-{\bf
    b}^{T}{\bf h},$ |  | (9) |'
- en: 'with ${\bf c}$ and ${\bf b}$ bias terms. The probability of the ‘state’ of
    the system is defined by passing the energy to an exponential and normalizing:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ${\bf c}$ 和 ${\bf b}$ 是偏置项。系统的‘状态’概率通过将能量传递到指数函数并进行归一化来定义：
- en: '|  | $p({\bf x},{\bf h})=\frac{1}{Z}\exp\{-E({\bf x},{\bf h})\}.$ |  | (10)
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '|  | $p({\bf x},{\bf h})=\frac{1}{Z}\exp\{-E({\bf x},{\bf h})\}.$ |  | (10)
    |'
- en: 'Computing the partition function $Z$ is generally intractable. However, conditional
    inference in the form of computing ${\bf h}$ conditioned on ${\bf v}$ or vice
    versa is tractable and results in a simple formula:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 计算分区函数 $Z$ 通常是不可处理的。然而，计算 ${\bf h}$ 在 ${\bf v}$ 条件下或反之的条件推断是可处理的，并且结果是一个简单的公式：
- en: '|  | $P(h_{j}&#124;{\bf x})=\frac{1}{1+\exp\{-b_{j}-{\bf W}_{j}{\bf x}\}}.$
    |  | (11) |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  | $P(h_{j}&#124;{\bf x})=\frac{1}{1+\exp\{-b_{j}-{\bf W}_{j}{\bf x}\}}.$
    |  | (11) |'
- en: Since the network is symmetric, a similar expression holds for $P(x_{i}|{\bf
    h})$.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 由于网络是对称的，对于 $P(x_{i}|{\bf h})$ 也有类似的表达式。
- en: DBNs (Bengio et al., [2007](#bib.bib28); Hinton et al., [2006](#bib.bib126))
    are essentially SAEs where the AE layers are replaced by RBMs. Training of the
    individual layers is, again, done in an unsupervised manner. Final fine-tuning
    is performed by adding a linear classifier to the top layer of the DBN and performing
    a supervised optimization.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: DBNs（Bengio 等, [2007](#bib.bib28); Hinton 等, [2006](#bib.bib126)）本质上是 SAEs，其中
    AE 层被 RBMs 取代。个别层的训练再次以无监督的方式进行。最终的微调是通过在 DBN 的顶层添加线性分类器并进行监督优化来完成的。
- en: 2.6.3 Variational Auto-Encoders and Generative Adverserial Networks
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.6.3 变分自编码器和生成对抗网络
- en: 'Recently, two novel unsupervised architectures were introduced: the variational
    auto-encoder (VAE) (Kingma and Welling, [2013](#bib.bib158)) and the generative
    adversarial network (GAN) (Goodfellow et al., [2014](#bib.bib113)). There are
    no peer-reviewed papers applying these methods to medical images yet, but applications
    in natural images are promising. We will elaborate on their potential in the discussion.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，引入了两种新颖的无监督架构：变分自编码器（VAE）（Kingma 和 Welling, [2013](#bib.bib158)）和生成对抗网络（GAN）（Goodfellow
    等, [2014](#bib.bib113)）。目前还没有同行评审的论文将这些方法应用于医学图像，但在自然图像中的应用前景很有希望。我们将在讨论中详细说明它们的潜力。
- en: 2.7 Hardware and Software
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.7 硬件和软件
- en: One of the main contributors to steep rise of deep learning has been the widespread
    availability of GPU and GPU-computing libraries (CUDA, OpenCL). GPUs are highly
    parallel computing engines, which have an order of magnitude more execution threads
    than central processing units (CPUs). With current hardware, deep learning on
    GPUs is typically 10 to 30 times faster than on CPUs.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习急剧发展的主要原因之一是 GPU 和 GPU 计算库（CUDA, OpenCL）的广泛可用性。GPU 是高度并行的计算引擎，具有比中央处理单元（CPU）多一个数量级的执行线程。使用当前的硬件，GPU
    上的深度学习通常比 CPU 上快 10 到 30 倍。
- en: 'Next to hardware, the other driving force behind the popularity of deep learning
    methods is the wide availability of open source software packages. These libraries
    provide efficient GPU implementations of important operations in neural networks,
    such as convolutions; allowing the user to implement ideas at a high level rather
    than worrying about low-level efficient implementations. At the time of writing,
    the most popular packages were (in alphabetical order):'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 除了硬件之外，深度学习方法流行的另一个推动力是开源软件包的广泛可用性。这些库提供了神经网络中重要操作（如卷积）的高效 GPU 实现；使用户能够在高层次上实现想法，而无需担心低层次的高效实现。在撰写本文时，最受欢迎的软件包（按字母顺序排列）包括：
- en: '1.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1.'
- en: Caffe  (Jia et al., [2014](#bib.bib144)). Provides C++ and Python interfaces,
    developed by graduate students at UC Berkeley.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Caffe (Jia 等人, [2014](#bib.bib144))。提供 C++ 和 Python 接口，由 UC Berkeley 的研究生开发。
- en: '2.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2.'
- en: Tensorflow  (Abadi et al., [2016](#bib.bib1)). Provides C++ and Python and interfaces,
    developed by Google and is used by Google research.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Tensorflow (Abadi 等人, [2016](#bib.bib1))。提供 C++ 和 Python 接口，由 Google 开发并由 Google
    研究所使用。
- en: '3.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '3.'
- en: Theano  (Bastien et al., [2012](#bib.bib22)). Provides a Python interface, developed
    by MILA lab in Montreal.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Theano (Bastien 等人, [2012](#bib.bib22))。提供 Python 接口，由蒙特利尔的 MILA 实验室开发。
- en: '4.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '4.'
- en: Torch  (Collobert et al., [2011](#bib.bib72)). Provides a Lua interface and
    is used by, among others, Facebook AI research.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Torch (Collobert 等人, [2011](#bib.bib72))。提供 Lua 接口，Facebook AI 研究等也在使用。
- en: There are third-party packages written on top of one or more of these frameworks,
    such as Lasagne ([https://github.com/Lasagne/Lasagne](https://github.com/Lasagne/Lasagne))
    or Keras ([https://keras.io/](https://keras.io/)). It goes beyond the scope of
    this paper to discuss all these packages in detail.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些框架之上，还有第三方软件包，例如 Lasagne ([https://github.com/Lasagne/Lasagne](https://github.com/Lasagne/Lasagne))
    或 Keras ([https://keras.io/](https://keras.io/))。详细讨论这些软件包超出了本文的范围。
- en: '![Refer to caption](img/e056345cf64fbc98b103060731beaf76.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e056345cf64fbc98b103060731beaf76.png)'
- en: 'Figure 2: Node graphs of 1D representations of architectures commonly used
    in medical imaging. a) Auto-encoder, b) restricted Boltzmann machine, c) recurrent
    neural network, d) convolutional neural network, e) multi-stream convolutional
    neural network, f) U-net (with a single downsampling stage).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：常用于医学影像的架构的 1D 表示的节点图。a) 自编码器，b) 限制玻尔兹曼机，c) 循环神经网络，d) 卷积神经网络，e) 多流卷积神经网络，f)
    U-net（具有单一下采样阶段）。
- en: .
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: 3 Deep Learning Uses in Medical Imaging
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 医学影像中的 3 种深度学习应用
- en: 3.1 Classification
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 分类
- en: 3.1.1 Image/exam classification
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 图像/检查分类
- en: Image or exam classification was one of the first areas in which deep learning
    made a major contribution to medical image analysis. In exam classification one
    typically has one or multiple images (an exam) as input with a single diagnostic
    variable as output (e.g., disease present or not). In such a setting, every diagnostic
    exam is a sample and dataset sizes are typically small compared to those in computer
    vision (e.g., hundreds/thousands vs. millions of samples). The popularity of transfer
    learning for such applications is therefore not surprising.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图像或检查分类是深度学习对医学图像分析做出重大贡献的第一个领域之一。在检查分类中，通常以一个或多个图像（检查）作为输入，以单一的诊断变量作为输出（例如，疾病是否存在）。在这种情况下，每个诊断检查都是一个样本，并且数据集的规模通常较小，相比于计算机视觉领域（例如，数百/数千个样本对比于数百万个样本）。因此，对于这种应用，迁移学习的流行并不令人惊讶。
- en: 'Transfer learning is essentially the use of pre-trained networks (typically
    on natural images) to try to work around the (perceived) requirement of large
    data sets for deep network training. Two transfer learning strategies were identified:
    (1) using a pre-trained network as a feature extractor and (2) fine-tuning a pre-trained
    network on medical data. The former strategy has the extra benefit of not requiring
    one to train a deep network at all, allowing the extracted features to be easily
    plugged in to existing image analysis pipelines. Both strategies are popular and
    have been widely applied. However, few authors perform a thorough investigation
    in which strategy gives the best result. The two papers that do, Antony et al.
    ([2016](#bib.bib11)) and Kim et al. ([2016a](#bib.bib155)), offer conflicting
    results. In the case of Antony et al. ([2016](#bib.bib11)), fine-tuning clearly
    outperformed feature extraction, achieving 57.6% accuracy in multi-class grade
    assessment of knee osteoarthritis versus 53.4%. Kim et al. ([2016a](#bib.bib155)),
    however, showed that using CNN as a feature extractor outperformed fine-tuning
    in cytopathology image classification accuracy (70.5% versus 69.1%). If any guidance
    can be given to which strategy might be most successful, we would refer the reader
    to two recent papers, published in high-ranking journals, which fine-tuned a pre-trained
    version of Google’s Inception v3 architecture on medical data and achieved (near)
    human expert performance (Esteva et al., [2017](#bib.bib89); Gulshan et al., [2016](#bib.bib115)).
    As far as the authors are aware, such results have not yet been achieved by simply
    using pre-trained networks as feature extractors.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习本质上是利用预训练网络（通常是在自然图像上）来绕过对深度网络训练所需的大数据集的（感知）要求。确定了两种迁移学习策略：（1）使用预训练网络作为特征提取器和（2）在医学数据上微调预训练网络。前者策略的额外好处是完全不需要训练深度网络，使提取的特征能够轻松地插入现有的图像分析管道。两种策略都很受欢迎并且被广泛应用。然而，少数作者对哪种策略效果最佳进行了彻底调查。Antony等（[2016](#bib.bib11)）和Kim等（[2016a](#bib.bib155)）这两篇论文提供了相互矛盾的结果。在Antony等（[2016](#bib.bib11)）的研究中，微调明显优于特征提取，在膝关节骨关节炎的多类分级评估中达到了57.6%的准确率，而特征提取为53.4%。然而，Kim等（[2016a](#bib.bib155)）显示，在细胞病理图像分类准确率上，使用CNN作为特征提取器优于微调（70.5%对69.1%）。如果有任何关于哪种策略可能最成功的指导，我们建议读者参考两篇最近发表在高排名期刊上的论文，它们在医学数据上微调了Google的Inception
    v3架构的预训练版本，并实现了（接近）人类专家的表现（Esteva等，[2017](#bib.bib89)；Gulshan等，[2016](#bib.bib115)）。据作者所知，仅使用预训练网络作为特征提取器尚未达到这样的结果。
- en: With respect to the type of deep networks that are commonly used in exam classification,
    a timeline similar to computer vision is apparent. The medical imaging community
    initially focused on unsupervised pre-training and network architectures like
    SAEs and RBMs. The first papers applying these techniques for exam classification
    appeared in 2013 and focused on neuroimaging. Brosch and Tam ([2013](#bib.bib35)),
    Plis et al. ([2014](#bib.bib217)), Suk and Shen ([2013](#bib.bib276)), and Suk
    et al. ([2014](#bib.bib274)) applied DBNs and SAEs to classify patients as having
    Alzheimer’s disease based on brain Magnetic Resonance Imaging (MRI). Recently,
    a clear shift towards CNNs can be observed. Out of the 47 papers published on
    exam classification in 2015, 2016, and 2017, 36 are using CNNs, 5 are based on
    AEs and 6 on RBMs. The application areas of these methods are very diverse, ranging
    from brain MRI to retinal imaging and digital pathology to lung computed tomography
    (CT).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在考试分类中常用的深度网络类型，类似于计算机视觉的时间线是显而易见的。医学影像界最初集中在无监督预训练和SAE及RBM等网络架构上。2013年首次出现了应用这些技术进行考试分类的论文，重点在于神经影像学。Brosch和Tam（[2013](#bib.bib35)），Plis等（[2014](#bib.bib217)），Suk和Shen（[2013](#bib.bib276)），以及Suk等（[2014](#bib.bib274)）应用DBN和SAE来根据脑部磁共振成像（MRI）对患者进行阿尔茨海默病的分类。最近，可以观察到明显的向CNN的转变。在2015年、2016年和2017年发表的47篇关于考试分类的论文中，36篇使用了CNN，5篇基于AE，6篇基于RBM。这些方法的应用领域非常广泛，从脑部MRI到视网膜成像，再到数字病理学和肺部CT。
- en: In the more recent papers using CNNs authors also often train their own network
    architectures from scratch instead of using pre-trained networks. Menegola et al.
    ([2016](#bib.bib190)) performed some experiments comparing training from scratch
    to fine-tuning of pre-trained networks and showed that fine-tuning worked better
    given a small data set of around a 1000 images of skin lesions. However, these
    experiments are too small scale to be able to draw any general conclusions from.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在更近期使用CNN的论文中，作者们也经常从头开始训练自己的网络架构，而不是使用预训练的网络。Menegola 等人（[2016](#bib.bib190)）进行了比较从头训练与微调预训练网络的实验，并展示了在小数据集（大约1000张皮肤病变图像）上微调效果更好。然而，这些实验规模过小，无法得出任何普遍的结论。
- en: 'Three papers used an architecture leveraging the unique attributes of medical
    data: two use 3D convolutions (Hosseini-Asl et al., [2016](#bib.bib131); Payan
    and Montana, [2015](#bib.bib212)) instead of 2D to classify patients as having
    Alzheimer; Kawahara et al. ([2016b](#bib.bib152)) applied a CNN-like architecture
    to a brain connectivity graph derived from MRI diffusion-tensor imaging (DTI).
    In order to do this, they developed several new layers which formed the basis
    of their network, so-called edge-to-edge, edge-to-node, and node-to-graph layers.
    They used their network to predict brain development and showed that they outperformed
    existing methods in assessing cognitive and motor scores.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 三篇论文使用了利用医学数据独特属性的架构：其中两篇使用了3D卷积（Hosseini-Asl 等，[2016](#bib.bib131); Payan 和
    Montana，[2015](#bib.bib212)），而不是2D卷积来将患者分类为阿尔茨海默病；Kawahara 等人（[2016b](#bib.bib152)）将类似CNN的架构应用于从MRI扩散张量成像（DTI）得到的大脑连接图。为了实现这一点，他们开发了几种新层，这些层构成了他们网络的基础，即所谓的边到边、边到节点和节点到图层。他们使用他们的网络来预测大脑发展，并展示了在评估认知和运动评分方面超过了现有方法。
- en: Summarizing, in exam classification CNNs are the current standard techniques.
    Especially CNNs pre-trained on natural images have shown surprisingly strong results,
    challenging the accuracy of human experts in some tasks. Last, authors have shown
    that CNNs can be adapted to leverage intrinsic structure of medical images.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，在考试分类中，CNN（卷积神经网络）是目前的标准技术。尤其是那些在自然图像上预训练的CNN表现出了令人惊讶的强大效果，在某些任务中甚至挑战了人类专家的准确性。最后，作者们已经展示了CNN可以被调整以利用医学图像的内在结构。
- en: 3.1.2 Object or lesion classification
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 对象或病变分类
- en: Object classification usually focuses on the classification of a small (previously
    identified) part of the medical image into two or more classes (e.g. nodule classification
    in chest CT). For many of these tasks both local information on lesion appearance
    and global contextual information on lesion location are required for accurate
    classification. This combination is typically not possible in generic deep learning
    architectures. Several authors have used multi-stream architectures to resolve
    this in a multi-scale fashion (Section [2.4.2](#S2.SS4.SSS2 "2.4.2 Multi-stream
    architectures ‣ 2.4 Deep CNN Architectures ‣ 2 Overview of deep learning methods
    ‣ A Survey on Deep Learning in Medical Image Analysis")). Shen et al. ([2015b](#bib.bib256))
    used three CNNs, each of which takes a nodule patch at a different scale as input.
    The resulting feature outputs of the three CNNs are then concatenated to form
    the final feature vector. A somewhat similar approach was followed by Kawahara
    and Hamarneh ([2016](#bib.bib153)) who used a multi-stream CNN to classify skin
    lesions, where each stream works on a different resolution of the image. Gao et al.
    ([2015](#bib.bib103)) proposed to use a combination of CNNs and RNNs for grading
    nuclear cataracts in slit-lamp images, where CNN filters were pre-trained. This
    combination allows the processing of all contextual information regardless of
    image size. Incorporating 3D information is also often a necessity for good performance
    in object classification tasks in medical imaging. As images in computer vision
    tend to be 2D natural images, networks developed in those scenarios do not directly
    leverage 3D information. Authors have used different approaches to integrate 3D
    in an effective manner with custom architectures. Setio et al. ([2016](#bib.bib249))
    used a multi-stream CNN to classify points of interest in chest CT as a nodule
    or non-nodule. Up to nine differently oriented patches extracted from the candidate
    were used in separate streams and merged in the fully-connected layers to obtain
    the final classification output. In contrast, Nie et al. ([2016c](#bib.bib206))
    exploited the 3D nature of MRI by training a 3D CNN to assess survival in patients
    suffering from high-grade gliomas.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对象分类通常侧重于将医学图像中一个小的（先前识别出的）部分分类为两类或更多类别（例如，胸部CT中的结节分类）。对于这些任务，准确的分类通常需要病变外观的局部信息和病变位置的全局上下文信息。这种结合在通用的深度学习架构中通常是不可行的。一些作者使用了多流架构来以多尺度的方式解决这个问题（详见[2.4.2节](#S2.SS4.SSS2
    "2.4.2 Multi-stream architectures ‣ 2.4 Deep CNN Architectures ‣ 2 Overview of
    deep learning methods ‣ A Survey on Deep Learning in Medical Image Analysis")）。Shen等人（[2015b](#bib.bib256)）使用了三种CNN，每种CNN以不同尺度的结节补丁作为输入。这三种CNN的特征输出结果随后被连接起来形成最终的特征向量。Kawahara和Hamarneh（[2016](#bib.bib153)）采用了类似的方法，使用多流CNN来分类皮肤病变，其中每个流处理图像的不同分辨率。Gao等人（[2015](#bib.bib103)）建议使用CNN和RNN的组合来对裂隙灯图像中的核性白内障进行分级，其中CNN过滤器是预训练的。这种组合允许处理所有的上下文信息，而不受图像大小的影响。将3D信息纳入也是医学影像对象分类任务中获得良好性能的一个必要条件。由于计算机视觉中的图像往往是2D自然图像，因此在这些场景下开发的网络并未直接利用3D信息。作者们使用了不同的方法来有效地将3D信息整合到定制架构中。Setio等人（[2016](#bib.bib249)）使用了多流CNN来将胸部CT中的兴趣点分类为结节或非结节。从候选区域中提取的最多九个不同方向的补丁被用于不同的流，并在全连接层中合并以获得最终的分类输出。相比之下，Nie等人（[2016c](#bib.bib206)）通过训练3D
    CNN来评估高等级胶质瘤患者的生存期，从而利用MRI的3D特性。
- en: Almost all recent papers prefer the use of end-to-end trained CNNs. In some
    cases other architectures and approaches are used, such as RBMs (van Tulder and
    de Bruijne, [2016](#bib.bib297); Zhang et al., [2016c](#bib.bib341)), SAEs (Cheng
    et al., [2016a](#bib.bib58)) and convolutional sparse auto-encoders (CSAE) (Kallenberg
    et al., [2016](#bib.bib147)). The major difference between CSAE and a classic
    CNN is the usage of unsupervised pre-training with sparse auto-encoders.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有近期的论文都倾向于使用端到端训练的CNN。在某些情况下，也使用了其他架构和方法，如RBMs（van Tulder和de Bruijne，[2016](#bib.bib297)；Zhang等人，[2016c](#bib.bib341)），SAEs（Cheng等人，[2016a](#bib.bib58)）和卷积稀疏自编码器（CSAE）（Kallenberg等人，[2016](#bib.bib147)）。CSAE和经典CNN之间的主要区别在于使用了稀疏自编码器的无监督预训练。
- en: An interesting approach, especially in cases where object annotation to generate
    training data is expensive, is the integration of multiple instance learning (MIL)
    and deep learning. Xu et al. ([2014](#bib.bib323)) investigated the use of a MIL-framework
    with both supervised and unsupervised feature learning approaches as well as handcrafted
    features. The results demonstrated that the performance of the MIL-framework was
    superior to handcrafted features, which in turn closely approaches the performance
    of a fully supervised method. We expect such approaches to be popular in the future
    as well, as obtaining high-quality annotated medical data is challenging.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一种有趣的方法，尤其是在对象注释以生成训练数据昂贵的情况下，是多实例学习（MIL）与深度学习的结合。Xu等人（[2014](#bib.bib323)）研究了使用MIL框架的监督和无监督特征学习方法以及手工特征。结果表明，MIL框架的性能优于手工特征，而手工特征又接近于完全监督方法的性能。我们预计这种方法在未来也会受到欢迎，因为获取高质量的注释医学数据具有挑战性。
- en: Overall, object classification sees less use of pre-trained networks compared
    to exam classifications, mostly due to the need for incorporation of contextual
    or three-dimensional information. Several authors have found innovative solutions
    to add this information to deep networks with good results, and as such we expect
    deep learning to become even more prominent for this task in the near future.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，与考试分类相比，对象分类较少使用预训练网络，这主要是由于需要结合上下文或三维信息。一些作者已经找到创新的方法将这些信息添加到深度网络中，并取得了良好的结果，因此我们预计深度学习在不久的将来会在这一任务中变得更加突出。
- en: 3.2 Detection
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 检测
- en: 3.2.1 Organ, region and landmark localization
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 器官、区域和标志点定位
- en: Anatomical object localization (in space or time), such as organs or landmarks,
    has been an important pre-processing step in segmentation tasks or in the clinical
    workflow for therapy planning and intervention. Localization in medical imaging
    often requires parsing of 3D volumes. To solve 3D data parsing with deep learning
    algorithms, several approaches have been proposed that treat the 3D space as a
    composition of 2D orthogonal planes. Yang et al. ([2015](#bib.bib327)) identified
    landmarks on the distal femur surface by processing three independent sets of
    2D MRI slices (one for each plane) with regular CNNs. The 3D position of the landmark
    was defined as the intersection of the three 2D slices with the highest classification
    output. de Vos et al. ([2016b](#bib.bib78)) went one step further and localized
    regions of interest (ROIs) around anatomical regions (heart, aortic arch, and
    descending aorta) by identifying a rectangular 3D bounding box after 2D parsing
    the 3D CT volume. Pre-trained CNN architectures, as well as RBM, have been used
    for the same purpose (Cai et al., [2016b](#bib.bib41); Chen et al., [2015b](#bib.bib50);
    Kumar et al., [2016](#bib.bib166)), overcoming the lack of data to learn better
    feature representations. All these studies cast the localization task as a classification
    task and as such generic deep learning architectures and learning processes can
    be leveraged.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 解剖对象定位（在空间或时间上），例如器官或标志点，一直是分割任务或临床治疗计划和干预中的重要预处理步骤。在医学成像中，定位通常需要解析3D体积。为了解决使用深度学习算法解析3D数据的问题，提出了几种方法，这些方法将3D空间视为2D正交平面的组合。Yang等人（[2015](#bib.bib327)）通过使用常规CNN处理三个独立的2D
    MRI切片（每个平面一个）来识别远端股骨表面的标志点。标志点的3D位置被定义为三个2D切片中分类输出最高的交点。de Vos等人（[2016b](#bib.bib78)）更进一步，通过在2D解析3D
    CT体积后识别矩形3D边界框，定位了解剖区域（心脏、主动脉弓和降主动脉）周围的感兴趣区域（ROI）。预训练的CNN架构以及RBM已被用于相同的目的（Cai等人，[2016b](#bib.bib41)；Chen等人，[2015b](#bib.bib50)；Kumar等人，[2016](#bib.bib166)），克服了学习更好特征表示的数据不足问题。所有这些研究将定位任务视为分类任务，因此可以利用通用深度学习架构和学习过程。
- en: 'Other authors try to modify the network learning process to directly predict
    locations. For example, Payer et al. ([2016](#bib.bib213)) proposed to directly
    regress landmark locations with CNNs. They used landmark maps, where each landmark
    is represented by a Gaussian, as ground truth input data and the network is directly
    trained to predict this landmark map. Another interesting approach was published
    by Ghesu et al. ([2016a](#bib.bib109)), in which reinforcement learning is applied
    to the identification of landmarks. The authors showed promising results in several
    tasks: 2D cardiac MRI and ultrasound (US) and 3D head/neck CT.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 其他作者尝试修改网络学习过程以直接预测位置。例如，Payer 等人 ([2016](#bib.bib213)) 提出了直接回归地标位置的 CNNs。他们使用地标图，其中每个地标由高斯表示，作为真实数据输入，并直接训练网络以预测该地标图。Ghesu
    等人 ([2016a](#bib.bib109)) 发表了另一种有趣的方法，其中应用了强化学习来识别地标。作者在几个任务中展示了有希望的结果：2D 心脏 MRI
    和超声（US）以及 3D 头/颈 CT。
- en: Due to its increased complexity, only a few methods addressed the direct localization
    of landmarks and regions in the 3D image space. Zheng et al. ([2015](#bib.bib346))
    reduced this complexity by decomposing 3D convolution as three one-dimensional
    convolutions for carotid artery bifurcation detection in CT data. Ghesu et al.
    ([2016b](#bib.bib110)) proposed a sparse adaptive deep neural network powered
    by marginal space learning in order to deal with data complexity in the detection
    of the aortic valve in 3D transesophageal echocardiogram.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其复杂性增加，只有少数方法处理了在 3D 图像空间中直接定位地标和区域的问题。Zheng 等人 ([2015](#bib.bib346)) 通过将
    3D 卷积分解为三种一维卷积来降低这种复杂性，以检测 CT 数据中的颈动脉分叉。Ghesu 等人 ([2016b](#bib.bib110)) 提出了一个稀疏自适应深度神经网络，该网络由边际空间学习驱动，以应对
    3D 经食道超声心动图中数据的复杂性。
- en: CNNs have also been used for the localization of scan planes or key frames in
    temporal data. Baumgartner et al. ([2016](#bib.bib24)) trained CNNs on video frame
    data to detect up to 12 standardized scan planes in mid-pregnancy fetal US. Furthermore,
    they used saliency maps to obtain a rough localization of the object of interest
    in the scan plan (e.g. brain, spine). RNNs, particularly LSTM-RNNs, have also
    been used to exploit the temporal information contained in medical videos, another
    type of high dimensional data. Chen et al. ([2015a](#bib.bib48)), for example,
    employed LSTM models to incorporate temporal information of consecutive sequence
    in US videos for fetal standard plane detection. Kong et al. ([2016](#bib.bib161))
    combined an LSTM-RNN with a CNN to detect the end-diastole and end-systole frames
    in cine-MRI of the heart.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: CNNs 也被用于在时间数据中定位扫描平面或关键帧。Baumgartner 等人 ([2016](#bib.bib24)) 在视频帧数据上训练 CNNs
    以检测中孕期胎儿超声中的多达 12 个标准化扫描平面。此外，他们使用显著性图来获得扫描平面中感兴趣对象的粗略定位（例如，大脑，脊柱）。RNNs，特别是 LSTM-RNNs，也被用于利用医学视频中的时间信息，这是一种高维数据类型。例如，Chen
    等人 ([2015a](#bib.bib48)) 使用 LSTM 模型将超声视频中连续序列的时间信息纳入胎儿标准平面检测中。Kong 等人 ([2016](#bib.bib161))
    将 LSTM-RNN 与 CNN 结合，用于检测心脏的舒张末期和收缩末期帧。
- en: Concluding, localization through 2D image classification with CNNs seems to
    be the most popular strategy overall to identify organs, regions and landmarks,
    with good results. However, several recent papers expand on this concept by modifying
    the learning process such that accurate localization is directly emphasized, with
    promising results. We expect such strategies to be explored further as they show
    that deep learning techniques can be adapted to a wide range of localization tasks
    (e.g. multiple landmarks). RNNs have shown promise in localization in the temporal
    domain, and multi-dimensional RNNs could play a role in spatial localization as
    well.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，通过 CNNs 进行 2D 图像分类的定位似乎是识别器官、区域和地标的最流行策略，并取得了良好的结果。然而，几篇近期的论文通过修改学习过程扩展了这一概念，以便直接强调准确的定位，取得了令人期待的结果。我们预计这些策略将得到进一步探索，因为它们表明深度学习技术可以适应广泛的定位任务（例如多个地标）。RNNs
    在时间域中的定位表现出良好的前景，且多维 RNNs 可能在空间定位中也会发挥作用。
- en: 3.2.2 Object or lesion detection
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 对象或病变检测
- en: The detection of objects of interest or lesions in images is a key part of diagnosis
    and is one of the most labor-intensive for clinicians. Typically, the tasks consist
    of the localization and identification of small lesions in the full image space.
    There has been a long research tradition in computer-aided detection systems that
    are designed to automatically detect lesions, improving the detection accuracy
    or decreasing the reading time of human experts. Interestingly, the first object
    detection system using CNNs was already proposed in 1995, using a CNN with four
    layers to detect nodules in x-ray images (Lo et al., [1995](#bib.bib180)).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像中检测感兴趣的物体或病变是诊断的关键部分，并且是临床医生最为费力的任务之一。通常，这些任务包括在整个图像空间中定位和识别小病变。计算机辅助检测系统在自动检测病变、提高检测准确性或减少人工专家阅读时间方面有着悠久的研究传统。有趣的是，使用卷积神经网络（CNN）的第一个物体检测系统早在1995年就已经提出，使用了一个具有四层的CNN来检测X射线图像中的结节（Lo
    et al., [1995](#bib.bib180)）。
- en: Most of the published deep learning object detection systems still uses CNNs
    to perform pixel (or voxel) classification, after which some form of post processing
    is applied to obtain object candidates. As the classification task performed at
    each pixel is essentially object classification, CNN architecture and methodology
    are very similar to those in section [3.1.2](#S3.SS1.SSS2 "3.1.2 Object or lesion
    classification ‣ 3.1 Classification ‣ 3 Deep Learning Uses in Medical Imaging
    ‣ A Survey on Deep Learning in Medical Image Analysis"). The incorporation of
    contextual or 3D information is also handled using multi-stream CNNs (Section
    [2.4.2](#S2.SS4.SSS2 "2.4.2 Multi-stream architectures ‣ 2.4 Deep CNN Architectures
    ‣ 2 Overview of deep learning methods ‣ A Survey on Deep Learning in Medical Image
    Analysis"), for example by Barbu et al. ([2016](#bib.bib21)) and Roth et al. ([2016b](#bib.bib236)).
    Teramoto et al. ([2016](#bib.bib289)) used a multi-stream CNN to integrate CT
    and Positron Emission Tomography (PET) data. Dou et al. ([2016c](#bib.bib84))
    used a 3D CNN to find micro-bleeds in brain MRI. Last, as the annotation burden
    to generate training data can be similarly significant compared to object classification,
    weakly-supervised deep learning has been explored by Hwang and Kim ([2016](#bib.bib136)),
    who adopted such a strategy for the detection of nodules in chest radiographs
    and lesions in mammography.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数已发表的深度学习物体检测系统仍然使用CNN进行像素（或体素）分类，然后应用某种形式的后处理来获得物体候选区域。由于在每个像素上执行的分类任务本质上是物体分类，CNN架构和方法与[3.1.2](#S3.SS1.SSS2
    "3.1.2 Object or lesion classification ‣ 3.1 Classification ‣ 3 Deep Learning
    Uses in Medical Imaging ‣ A Survey on Deep Learning in Medical Image Analysis")节中的非常相似。上下文或3D信息的整合也使用多流CNN（第[2.4.2](#S2.SS4.SSS2
    "2.4.2 Multi-stream architectures ‣ 2.4 Deep CNN Architectures ‣ 2 Overview of
    deep learning methods ‣ A Survey on Deep Learning in Medical Image Analysis")节），例如Barbu
    et al. ([2016](#bib.bib21))和Roth et al. ([2016b](#bib.bib236))。Teramoto et al.
    ([2016](#bib.bib289))使用多流CNN来整合CT和正电子发射断层扫描（PET）数据。Dou et al. ([2016c](#bib.bib84))使用3D
    CNN来发现脑部MRI中的微出血。最后，由于生成训练数据的标注负担可能与物体分类类似，Hwang和Kim ([2016](#bib.bib136))探索了弱监督深度学习，他们采用了这种策略来检测胸部X光片中的结节和乳腺摄影中的病变。
- en: There are some aspects which are significantly different between object detection
    and object classification. One key point is that because every pixel is classified,
    typically the class balance is skewed severely towards the non-object class in
    a training setting. To add insult to injury, usually the majority of the non-object
    samples are easy to discriminate, preventing the deep learning method to focus
    on the challenging samples. van Grinsven et al. ([2016](#bib.bib296)) proposed
    a selective data sampling in which wrongly classified samples were fed back to
    the network more often to focus on challenging areas in retinal images. Last,
    as classifying each pixel in a sliding window fashion results in orders of magnitude
    of redundant calculation, fCNNs, as used in Wolterink et al. ([2016](#bib.bib310)),
    are important aspect of an object detection pipeline as well.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 物体检测与物体分类之间有一些显著不同的方面。一个关键点是，由于每个像素都被分类，因此在训练设置中，类别平衡通常严重偏向于非物体类别。更糟糕的是，通常大多数非物体样本容易区分，这阻止了深度学习方法专注于具有挑战性的样本。van
    Grinsven et al. ([2016](#bib.bib296))提出了一种选择性数据采样方法，其中错误分类的样本被更频繁地反馈给网络，以专注于视网膜图像中的挑战性区域。最后，由于在滑动窗口方式中对每个像素进行分类会导致数量级的冗余计算，fCNNs，如Wolterink
    et al. ([2016](#bib.bib310))中使用的，是物体检测管道中的一个重要方面。
- en: Challenges in meaningful application of deep learning algorithms in object detection
    are thus mostly similar to those in object classification. Only few papers directly
    address issues specific to object detection like class imbalance/hard-negative
    mining or efficient pixel/voxel-wise processing of images. We expect that more
    emphasis will be given to those areas in the near future, for example in the application
    of multi-stream networks in a fully convolutional fashion.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在目标检测中，深度学习算法的有意义应用面临的挑战通常与目标分类类似。只有少数论文直接解决了特定于目标检测的问题，如类别不平衡/难负样本挖掘或高效的像素/体素级图像处理。我们预计未来会更多关注这些领域，例如在全卷积方式下应用多流网络。
- en: 3.3 Segmentation
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 分割
- en: 3.3.1 Organ and substructure segmentation
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1 器官和子结构分割
- en: The segmentation of organs and other substructures in medical images allows
    quantitative analysis of clinical parameters related to volume and shape, as,
    for example, in cardiac or brain analysis. Furthermore, it is often an important
    first step in computer-aided detection pipelines. The task of segmentation is
    typically defined as identifying the set of voxels which make up either the contour
    or the interior of the object(s) of interest. Segmentation is the most common
    subject of papers applying deep learning to medical imaging (Figure [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ A Survey on Deep Learning in Medical Image Analysis")),
    and as such has also seen the widest variety in methodology, including the development
    of unique CNN-based segmentation architectures and the wider application of RNNs.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 器官和其他子结构在医学图像中的分割允许对与体积和形状相关的临床参数进行定量分析，例如在心脏或大脑分析中。此外，它通常是计算机辅助检测管道中的重要第一步。分割任务通常被定义为识别组成感兴趣对象的轮廓或内部的体素集。分割是将深度学习应用于医学成像的论文中最常见的主题（图[1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ A Survey on Deep Learning in Medical Image Analysis")），因此在方法论上也经历了最广泛的变化，包括独特的基于CNN的分割架构的发展以及RNN的广泛应用。
- en: The most well-known, in medical image analysis, of these novel CNN architectures
    is U-net, published by Ronneberger et al. ([2015](#bib.bib232)) (section [2.4.3](#S2.SS4.SSS3
    "2.4.3 Segmentation Architectures ‣ 2.4 Deep CNN Architectures ‣ 2 Overview of
    deep learning methods ‣ A Survey on Deep Learning in Medical Image Analysis")).
    The two main architectural novelties in U-net are the combination of an equal
    amount of upsampling and downsampling layers. Although learned upsampling layers
    have been proposed before, U-net combines them with so-called skip connections
    between opposing convolution and deconvolution layers. This which concatenate
    features from the contracting and expanding paths. From a training perspective
    this means that entire images/scans can be processed by U-net in one forward pass,
    resulting in a segmentation map directly. This allows U-net to take into account
    the full context of the image, which can be an advantage in contrast to patch-based
    CNNs. Furthermore, in an extended paper by Çiçek et al. ([2016](#bib.bib65)),
    it is shown that a full 3D segmentation can be achieved by feeding U-net with
    a few 2D annotated slices from the same volume. Other authors have also built
    derivatives of the U-net architecture; Milletari et al. ([2016b](#bib.bib194)),
    for example, proposed a 3D-variant of U-net architecture, called V-net, performing
    3D image segmentation using 3D convolutional layers with an objective function
    directly based on the Dice coefficient. Drozdzal et al. ([2016](#bib.bib85)) investigated
    the use of short ResNet-like skip connections in addition to the long skip-connections
    in a regular U-net.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在医学图像分析中，最著名的这些新型CNN架构是U-net，由Ronneberger等人发布（[2015](#bib.bib232)）（第[2.4.3](#S2.SS4.SSS3
    "2.4.3 Segmentation Architectures ‣ 2.4 Deep CNN Architectures ‣ 2 Overview of
    deep learning methods ‣ A Survey on Deep Learning in Medical Image Analysis")节）。U-net的两个主要架构创新是等量的上采样层和下采样层的组合。虽然之前已经提出了学习的上采样层，但U-net将其与所谓的跳跃连接结合在一起，这些跳跃连接在相对的卷积层和反卷积层之间连接特征。这使得从收缩路径和扩展路径中连接特征。从训练的角度来看，这意味着整个图像/扫描可以在一次前向传递中被U-net处理，从而直接生成分割图。这使得U-net能够考虑图像的全部上下文，相较于基于补丁的CNN，这可能是一种优势。此外，在Çiçek等人（[2016](#bib.bib65)）的扩展论文中，显示通过用来自同一体积的少量2D标注切片喂入U-net可以实现完整的3D分割。其他作者也建立了U-net架构的衍生版本；例如，Milletari等人（[2016b](#bib.bib194)）提出了一种U-net架构的3D变体，称为V-net，使用3D卷积层进行3D图像分割，并且其目标函数直接基于Dice系数。Drozdzal等人（[2016](#bib.bib85)）调查了在常规U-net中除了长跳跃连接之外使用短ResNet-like跳跃连接的效果。
- en: RNNs have recently become more popular for segmentation tasks. For example,
    Xie et al. ([2016b](#bib.bib317)) used a spatial clockwork RNN to segment the
    perimysium in H&E-histopathology images. This network takes into account prior
    information from both the row and column predecessors of the current patch. To
    incorporate bidirectional information from both left/top and right/bottom neighbors,
    the RNN is applied four times in different orientations and the end-result is
    concatenated and fed to a fully-connected layer. This produces the final output
    for a single patch. Stollenga et al. ([2015](#bib.bib273)) where the first to
    use a 3D LSTM-RNN with convolutional layers in six directions. Andermatt et al.
    ([2016](#bib.bib9)) used a 3D RNN with gated recurrent units to segment gray and
    white matter in a brain MRI data set. Chen et al. ([2016d](#bib.bib55)) combined
    bi-directional LSTM-RNNs with 2D U-net-like-architectures to segment structures
    in anisotropic 3D electron microscopy images. Last, Poudel et al. ([2016](#bib.bib218))
    combined a 2D U-net architecture with a gated recurrent unit to perform 3D segmentation.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: RNNs最近在分割任务中变得越来越受欢迎。例如，Xie等人（[2016b](#bib.bib317)）使用空间时钟RNN分割H&E组织病理图像中的肌膜。这个网络考虑了当前补丁的行和列前驱的信息。为了结合来自左/上和右/下邻居的双向信息，RNN在不同的方向上应用四次，最终结果被拼接并输入到一个全连接层。这生成了单个补丁的最终输出。Stollenga等人（[2015](#bib.bib273)）是第一个在六个方向上使用带卷积层的3D
    LSTM-RNN的研究者。Andermatt等人（[2016](#bib.bib9)）使用带门控递归单元的3D RNN来分割脑MRI数据集中的灰质和白质。Chen等人（[2016d](#bib.bib55)）将双向LSTM-RNN与2D
    U-net类似架构结合，用于分割各向异性3D电子显微镜图像中的结构。最后，Poudel等人（[2016](#bib.bib218)）将2D U-net架构与门控递归单元结合，执行3D分割。
- en: Although these specific segmentation architectures offered compelling advantages,
    many authors have also obtained excellent segmentation results with patch-trained
    neural networks. One of the earliest papers covering medical image segmentation
    with deep learning algorithms used such a strategy and was published by Ciresan
    et al. ([2012](#bib.bib70)). They applied pixel-wise segmentation of membranes
    in electron microscopy imagery in a sliding window fashion. Most recent papers
    now use fCNNs (subsection [2.4.3](#S2.SS4.SSS3 "2.4.3 Segmentation Architectures
    ‣ 2.4 Deep CNN Architectures ‣ 2 Overview of deep learning methods ‣ A Survey
    on Deep Learning in Medical Image Analysis")) in preference over sliding-window-based
    classification to reduce redundant computation.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些特定的分割架构提供了引人注目的优势，但许多作者也通过补丁训练的神经网络获得了出色的分割结果。最早的一篇涉及深度学习算法的医学图像分割论文使用了这样的策略，由Ciresan等人发布（[2012](#bib.bib70)）。他们在电子显微镜图像中以滑动窗口的方式应用了像素级分割膜的技术。最近的论文现在更倾向于使用fCNNs（子节[2.4.3](#S2.SS4.SSS3
    "2.4.3 Segmentation Architectures ‣ 2.4 Deep CNN Architectures ‣ 2 Overview of
    deep learning methods ‣ A Survey on Deep Learning in Medical Image Analysis")），而不是基于滑动窗口的分类，以减少冗余计算。
- en: 'fCNNs have also been extended to 3D and have been applied to multiple targets
    at once: Korez et al. ([2016](#bib.bib164)), used 3D fCNNs to generate vertebral
    body likelihood maps which drove deformable models for vertebral body segmentation
    in MR images, Zhou et al. ([2016](#bib.bib347)) segmented nineteen targets in
    the human torso, and Moeskops et al. ([2016b](#bib.bib197)) trained a single fCNN
    to segment brain MRI, the pectoral muscle in breast MRI, and the coronary arteries
    in cardiac CT angiography (CTA).'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: fCNNs也被扩展到3D，并应用于多个目标：Korez等人（[2016](#bib.bib164)）使用3D fCNNs生成脊椎体可能性图，这些图驱动了脊椎体在MR图像中的变形模型分割，Zhou等人（[2016](#bib.bib347)）在人体躯干中分割了十九个目标，而Moeskops等人（[2016b](#bib.bib197)）训练了一个单一的fCNN来分割脑MRI、乳腺MRI中的胸肌和心脏CT血管造影（CTA）中的冠状动脉。
- en: One challenge with voxel classification approaches is that they sometimes lead
    to spurious responses. To combat this, groups have tried to combine fCNNs with
    graphical models like MRFs (Shakeri et al., [2016](#bib.bib252); Song et al.,
    [2015](#bib.bib269)) and Conditional Random Fields (CRFs) (Alansary et al., [2016](#bib.bib5);
    Cai et al., [2016a](#bib.bib40); Christ et al., [2016](#bib.bib63); Dou et al.,
    [2016c](#bib.bib84); Fu et al., [2016a](#bib.bib97); Gao et al., [2016c](#bib.bib102))
    to refine the segmentation output. In most of the cases, graphical models are
    applied on top of the likelihood map produced by CNNs or fCNNs and act as label
    regularizers.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 使用体素分类方法的一项挑战是它们有时会导致虚假的响应。为应对这一问题，研究小组尝试将 fCNNs 与图形模型如 MRFs (Shakeri 等人，[2016](#bib.bib252);
    Song 等人，[2015](#bib.bib269)) 和条件随机场 (CRFs) (Alansary 等人，[2016](#bib.bib5); Cai
    等人，[2016a](#bib.bib40); Christ 等人，[2016](#bib.bib63); Dou 等人，[2016c](#bib.bib84);
    Fu 等人，[2016a](#bib.bib97); Gao 等人，[2016c](#bib.bib102)) 结合使用，以细化分割输出。在大多数情况下，图形模型应用于
    CNNs 或 fCNNs 生成的似然图上，作为标签正则化器。
- en: Summarizing, segmentation in medical imaging has seen a huge influx of deep
    learning related methods. Custom architectures have been created to directly target
    the segmentation task. These have obtained promising results, rivaling and often
    improving over results obtained with fCNNs.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，医学成像中的分割方法已经出现了大量与深度学习相关的方法。定制的架构被创建来直接针对分割任务。这些方法取得了有前景的结果，与 fCNNs 得到的结果相媲美，并且通常有所改进。
- en: 3.3.2 Lesion segmentation
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2 病灶分割
- en: Segmentation of lesions combines the challenges of object detection and organ
    and substructure segmentation in the application of deep learning algorithms.
    Global and local context are typically needed to perform accurate segmentation,
    such that multi-stream networks with different scales or non-uniformly sampled
    patches are used as in for example Kamnitsas et al. ([2017](#bib.bib148)) and
    Ghafoorian et al. ([2016b](#bib.bib108)). In lesion segmentation we have also
    seen the application of U-net and similar architectures to leverage both this
    global and local context. The architecture used by Wang et al. ([2015](#bib.bib302)),
    similar to the U-net, consists of the same downsampling and upsampling paths,
    but does not use skip connections. Another U-net-like architecture was used by
    Brosch et al. ([2016](#bib.bib36)) to segment white matter lesions in brain MRI.
    However, they used 3D convolutions and a single skip connection between the first
    convolutional and last deconvolutional layers.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 病灶分割结合了目标检测以及器官和子结构分割中的挑战，应用于深度学习算法。通常需要全球和局部上下文以进行准确的分割，因此使用了多流网络，具有不同的尺度或非均匀采样的补丁，例如
    Kamnitsas 等人 ([2017](#bib.bib148)) 和 Ghafoorian 等人 ([2016b](#bib.bib108))。在病灶分割中，我们还看到了
    U-net 和类似架构的应用，以利用全球和局部上下文。Wang 等人 ([2015](#bib.bib302)) 使用的架构类似于 U-net，包含相同的下采样和上采样路径，但不使用跳跃连接。Brosch
    等人 ([2016](#bib.bib36)) 使用了另一种类似 U-net 的架构来分割脑 MRI 中的白质病灶。然而，他们使用了 3D 卷积和在第一次卷积层和最后一次反卷积层之间的单一跳跃连接。
- en: 'One other challenge that lesion segmentation shares with object detection is
    class imbalance, as most voxels/pixels in an image are from the non-diseased class.
    Some papers combat this by adapting the loss function: Brosch et al. ([2016](#bib.bib36))
    defined it to be a weighted combination of the sensitivity and the specificity,
    with a larger weight for the specificity to make it less sensitive to the data
    imbalance. Others balance the data set by performing data augmentation on positive
    samples (Kamnitsas et al., [2017](#bib.bib148); Litjens et al., [2016](#bib.bib176);
    Pereira et al., [2016](#bib.bib214)).'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 病灶分割与目标检测共享的另一个挑战是类别不平衡，因为图像中的大多数体素/像素来自非病变类别。一些论文通过调整损失函数来应对这一问题：Brosch 等人
    ([2016](#bib.bib36)) 将其定义为灵敏度和特异性的加权组合，特异性的权重较大，以减少对数据不平衡的敏感性。其他研究通过对正样本进行数据增强来平衡数据集（Kamnitsas
    等人，[2017](#bib.bib148); Litjens 等人，[2016](#bib.bib176); Pereira 等人，[2016](#bib.bib214)）。
- en: Thus lesion segmentation sees a mixture of approaches used in object detection
    and organ segmentation. Developments in these two areas will most likely naturally
    propagate to lesion segmentation as the existing challenges are also mostly similar.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，病灶分割结合了目标检测和器官分割中的各种方法。这两个领域的进展很可能会自然地传播到病灶分割，因为现有的挑战大多相似。
- en: 3.4 Registration
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 配准
- en: 'Registration (i.e. spatial alignment) of medical images is a common image analysis
    task in which a coordinate transform is calculated from one medical image to another.
    Often this is performed in an iterative framework where a specific type of (non-)parametric
    transformation is assumed and a pre-determined metric (e.g. L2-norm) is optimized.
    Although segmentation and lesion detection are more popular topics for deep learning,
    researchers have found that deep networks can be beneficial in getting the best
    possible registration performance. Broadly speaking, two strategies are prevalent
    in current literature: (1) using deep-learning networks to estimate a similarity
    measure for two images to drive an iterative optimization strategy, and (2) to
    directly predict transformation parameters using deep regression networks.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 医学图像的配准（即空间对齐）是一个常见的图像分析任务，其中计算从一幅医学图像到另一幅医学图像的坐标变换。这通常在一个迭代框架中进行，其中假设了一种特定类型的（非）参数变换，并优化一个预先确定的度量（例如L2范数）。虽然分割和病灶检测是深度学习中更受欢迎的主题，但研究人员发现深度网络在获得最佳配准性能方面是有益的。广泛来说，目前文献中流行两种策略：（1）使用深度学习网络估计两幅图像的相似性度量来驱动迭代优化策略，以及（2）使用深度回归网络直接预测变换参数。
- en: Wu et al. ([2013](#bib.bib313)), Simonovsky et al. ([2016](#bib.bib263)), and
    Cheng et al. ([2015](#bib.bib60)) used the first strategy to try to optimize registration
    algorithms. Cheng et al. ([2015](#bib.bib60)) used two types of stacked auto-encoders
    to assess the local similarity between CT and MRI images of the head. Both auto-encoders
    take vectorized image patches of CT and MRI and reconstruct them through four
    layers. After the networks are pre-trained using unsupervised patch reconstruction
    they are fine-tuned using two prediction layers stacked on top of the third layer
    of the SAE. These prediction layers determine whether two patches are similar
    (class 1) or dissimilar (class 2). Simonovsky et al. ([2016](#bib.bib263)) used
    a similar strategy, albeit with CNNs, to estimate a similarity cost between two
    patches from differing modalities. However, they also presented a way to use the
    derivative of this metric to directly optimize the transformation parameters,
    which are decoupled from the network itself. Last, Wu et al. ([2013](#bib.bib313))
    combined independent subspace analysis and convolutional layers to extract features
    from input patches in an unsupervised manner. The resultant feature vectors are
    used to drive the HAMMER registration algorithm instead of handcrafted features.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Wu 等人 ([2013](#bib.bib313))，Simonovsky 等人 ([2016](#bib.bib263)) 和 Cheng 等人 ([2015](#bib.bib60))
    采用了第一种策略来尝试优化配准算法。Cheng 等人 ([2015](#bib.bib60)) 使用了两种类型的堆叠自编码器来评估头部CT和MRI图像之间的局部相似性。这些自编码器接受CT和MRI的矢量化图像补丁，并通过四层进行重建。在使用无监督补丁重建进行预训练后，这些网络通过堆叠在第三层自编码器上的两个预测层进行微调。这些预测层确定两个补丁是否相似（类别1）或不相似（类别2）。Simonovsky
    等人 ([2016](#bib.bib263)) 采用了类似的策略，但使用了卷积神经网络（CNN）来估计来自不同模态的两个补丁之间的相似性成本。然而，他们还提出了一种方法，利用该度量的导数直接优化变换参数，这些参数与网络本身解耦。最后，Wu
    等人 ([2013](#bib.bib313)) 结合独立子空间分析和卷积层，以无监督的方式从输入补丁中提取特征。结果特征向量用于驱动HAMMER配准算法，而不是手工制作的特征。
- en: 'Miao et al. ([2016](#bib.bib192)) and Yang et al. ([2016d](#bib.bib331)) used
    deep learning algorithms to directly predict the registration transform parameters
    given input images. Miao et al. ([2016](#bib.bib192)) leveraged CNNs to perform
    3D model to 2D x-ray registration to assess the pose and location of an implanted
    object during surgery. In total the transformation has 6 parameters, two translational,
    1 scaling and 3 angular parameters. They parameterize the feature space in steps
    of 20 degrees for two angular parameters and train a separate CNN to predict the
    update to the transformation parameters given an digitally reconstructed x-ray
    of the 3D model and the actual inter-operative x-ray. The CNNs are trained with
    artificial examples generated by manually adapting the transformation parameters
    for the input training data. They showed that their approach has significantly
    higher registration success rates than using traditional - purely intensity based
    - registration methods. Yang et al. ([2016d](#bib.bib331)) tackled the problem
    of prior/current registration in brain MRI using the OASIS data set. They used
    the large deformation diffeomorphic metric mapping (LDDMM) registration methodology
    as a basis. This method takes as input an initial momentum value for each pixel
    which is then evolved over time to obtain the final transformation. However, the
    calculation of the initial momentum map is often an expensive procure. The authors
    circumvent this by training a U-net like architecture to predict the x- and y-momentum
    map given the input images. They obtain visually similar results but with significantly
    improved execution time: 1500x speed-up for 2D and 66x speed-up for 3D.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Miao 等人 ([2016](#bib.bib192)) 和 Yang 等人 ([2016d](#bib.bib331)) 使用深度学习算法直接预测给定输入图像的配准变换参数。Miao
    等人 ([2016](#bib.bib192)) 利用 CNNs 执行 3D 模型到 2D X 射线图像的配准，以评估手术中植入物的姿态和位置。总的来说，这个变换有
    6 个参数，包括两个平移参数、1 个缩放参数和 3 个角度参数。他们将特征空间的角度参数分为每 20 度一步，并训练一个单独的 CNN 来预测变换参数的更新，给定
    3D 模型的数字重建 X 射线图像和实际的术中 X 射线图像。这些 CNN 是通过手动调整变换参数生成的人工样本进行训练的。他们展示了他们的方法在配准成功率上明显高于使用传统的
    - 纯基于强度的 - 配准方法。Yang 等人 ([2016d](#bib.bib331)) 使用 OASIS 数据集解决了脑 MRI 中的前期/当前配准问题。他们以大变形同胚度量映射（LDDMM）配准方法为基础。该方法以每个像素的初始动量值为输入，随后随着时间的推移演化以获得最终变换。然而，计算初始动量图通常是一个昂贵的过程。作者通过训练类似
    U-net 的架构来预测给定输入图像的 x 和 y 动量图，从而绕过这一问题。他们获得了视觉上类似的结果，但执行时间显著缩短：2D 速度提高了 1500 倍，3D
    速度提高了 66 倍。
- en: In contrast to classification and segmentation, the research community seems
    not have yet settled on the best way to integrate deep learning techniques in
    registration methods. Not many papers have yet appeared on the subject and existing
    ones each have a distinctly different approach. Thus, giving recommendations on
    what method is most promising seems inappropriate. However, we expect to see many
    more contributions of deep learning to medical image registration in the near
    future.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 与分类和分割不同，研究界似乎尚未确定将深度学习技术整合到配准方法中的最佳方式。关于该主题的文献不多，现有文献的处理方法各有不同。因此，给出哪种方法最具前景的建议似乎不太合适。然而，我们预计在不久的将来，深度学习将在医学图像配准领域做出更多贡献。
- en: 3.5 Other tasks in medical imaging
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 医学成像中的其他任务
- en: 3.5.1 Content-based image retrieval
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.5.1 基于内容的图像检索
- en: Content-based image retrieval (CBIR) is a technique for knowledge discovery
    in massive databases and offers the possibility to identify similar case histories,
    understand rare disorders, and, ultimately, improve patient care. The major challenge
    in the development of CBIR methods is extracting effective feature representations
    from the pixel-level information and associating them with meaningful concepts.
    The ability of deep CNN models to learn rich features at multiple levels of abstraction
    has elicited interest from the CBIR community.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 基于内容的图像检索（CBIR）是一种在大规模数据库中发现知识的技术，提供了识别相似病例、理解罕见疾病以及最终改善患者护理的可能性。CBIR 方法开发中的主要挑战是从像素级信息中提取有效的特征表示，并将其与有意义的概念关联起来。深度
    CNN 模型在多个抽象层次上学习丰富特征的能力引起了 CBIR 社区的关注。
- en: All current approaches use (pre-trained) CNNs to extract feature descriptors
    from medical images. Anavi et al. ([2016](#bib.bib8)) and Liu et al. ([2016b](#bib.bib178))
    applied their methods to databases of X-ray images. Both used a five-layer CNN
    and extracted features from the fully-connected layers. Anavi et al. ([2016](#bib.bib8))
    used the last layer and a pre-trained network. Their best results were obtained
    by feeding these features to a one-vs-all support vector machine (SVM) classifier
    to obtain the distance metric. They showed that incorporating gender information
    resulted in better performance than just CNN features. Liu et al. ([2016b](#bib.bib178))
    used the penultimate fully-connected layer and a custom CNN trained to classify
    X-rays in 193 classes to obtain the descriptive feature vector. After descriptor
    binarization and data retrieval using Hamming separation values, the performance
    was inferior to the state of the art, which the authors attributed to small patch
    sizes of 96 pixels. The method proposed by Shah et al. ([2016](#bib.bib251)) combines
    CNN feature descriptors with hashing-forests. 1000 features were extracted for
    overlapping patches in prostate MRI volumes, after which a large feature matrix
    was constructed over all volumes. Hashing forests were then used to compress this
    into descriptors for each volume.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 所有当前的方法都使用（预训练的）CNN 从医学图像中提取特征描述符。Anavi 等人（[2016](#bib.bib8)）和 Liu 等人（[2016b](#bib.bib178)）将他们的方法应用于
    X 射线图像数据库。两者都使用了五层 CNN，并从全连接层中提取特征。Anavi 等人（[2016](#bib.bib8)）使用了最后一层和一个预训练的网络。他们通过将这些特征输入到一对多支持向量机（SVM）分类器中来获得距离度量，从而获得了最佳结果。他们展示了纳入性别信息比仅使用
    CNN 特征能够获得更好的性能。Liu 等人（[2016b](#bib.bib178)）使用了倒数第二个全连接层和一个定制的 CNN，该 CNN 经过训练以在
    193 个类别中对 X 射线进行分类，从而获得描述特征向量。经过描述符二值化和使用 Hamming 分离值的数据检索后，性能不如最先进的技术，作者将其归因于
    96 像素的小补丁尺寸。Shah 等人（[2016](#bib.bib251)）提出的方法结合了 CNN 特征描述符和哈希森林。在前列腺 MRI 体积的重叠补丁中提取了
    1000 个特征，然后在所有体积上构建了一个大型特征矩阵。随后使用哈希森林将其压缩为每个体积的描述符。
- en: Content-based image retrieval as a whole has thus not seen many successful applications
    of deep learning methods yet, but given the results in other areas it seems only
    a matter of time. An interesting avenue of research could be the direct training
    of deep networks for the retrieval task itself.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 基于内容的图像检索整体上尚未见到许多深度学习方法的成功应用，但鉴于其他领域的结果，这似乎只是时间问题。一个有趣的研究方向可能是直接训练深度网络来执行检索任务本身。
- en: '![Refer to caption](img/3f0adeed393358151179fc8b4a3c1e64.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/3f0adeed393358151179fc8b4a3c1e64.png)'
- en: 'Figure 3: Collage of some medical imaging applications in which deep learning
    has achieved state-of-the-art results. From top-left to bottom-right: mammographic
    mass classification (Kooi et al., [2016](#bib.bib162)), segmentation of lesions
    in the brain (top ranking in BRATS, ISLES and MRBrains challenges, image from
    Ghafoorian et al. ([2016b](#bib.bib108)), leak detection in airway tree segmentation
    (Charbonnier et al., [2017](#bib.bib47)), diabetic retinopathy classification
    (Kaggle Diabetic Retinopathy challenge 2015, image from van Grinsven et al. ([2016](#bib.bib296)),
    prostate segmentation (top rank in PROMISE12 challenge), nodule classification
    (top ranking in LUNA16 challenge), breast cancer metastases detection in lymph
    nodes (top ranking and human expert performance in CAMELYON16), human expert performance
    in skin lesion classification (Esteva et al., [2017](#bib.bib89)), and state-of-the-art
    bone suppression in x-rays, image from Yang et al. ([2016c](#bib.bib330)).'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：一些医学影像应用的拼贴图，其中深度学习已实现最先进的结果。从左上角到右下角：乳腺肿块分类（Kooi 等人，[2016](#bib.bib162)），脑部病变分割（在
    BRATS、ISLES 和 MRBrains 挑战中排名靠前，图像来自 Ghafoorian 等人（[2016b](#bib.bib108)）），气道树分割中的泄漏检测（Charbonnier
    等人，[2017](#bib.bib47)），糖尿病视网膜病变分类（Kaggle 糖尿病视网膜病变挑战 2015，图像来自 van Grinsven 等人（[2016](#bib.bib296)）），前列腺分割（PROMISE12
    挑战中的最高排名），结节分类（LUNA16 挑战中的最高排名），淋巴结中乳腺癌转移的检测（CAMELYON16 中的最高排名和人类专家表现），皮肤病变分类中的人类专家表现（Esteva
    等人，[2017](#bib.bib89)），以及 X 射线中的最先进骨骼抑制，图像来自 Yang 等人（[2016c](#bib.bib330)）。
- en: 'Table 1: Overview of papers using deep learning techniques for brain image
    analysis. All works use MRI unless otherwise mentioned.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：使用深度学习技术进行脑部图像分析的论文概述。除非另有说明，否则所有工作均使用 MRI。
- en: '| Reference | Method | Application; remarks |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 方法 | 应用；备注 |'
- en: '| Disorder classification (AD, MCI, Schizophrenia) |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 疾病分类（AD、MCI、精神分裂症） |'
- en: '| Brosch and Tam ([2013](#bib.bib35)) | DBN | AD/HC classification; Deep belief
    networks with convolutional RBMs for manifold learning |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| Brosch 和 Tam ([2013](#bib.bib35)) | DBN | AD/HC 分类；用于流形学习的卷积 RBMs 的深度信念网络
    |'
- en: '| Plis et al. ([2014](#bib.bib217)) | DBN | Deep belief networks evaluated
    on brain network estimation, Schizophrenia and Huntington’s disease classification
    |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| Plis 等人 ([2014](#bib.bib217)) | DBN | 在脑网络估计、精神分裂症和亨廷顿舞蹈症分类上评估的深度信念网络 |'
- en: '| Suk and Shen ([2013](#bib.bib276)) | SAE | AD/MCI classification; Stacked
    auto encoders with supervised fine tuning |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| Suk 和 Shen ([2013](#bib.bib276)) | SAE | AD/MCI 分类；带有监督微调的堆叠自编码器 |'
- en: '| Suk et al. ([2014](#bib.bib274)) | RBM | AD/MCI/HC classification; Deep Boltzmann
    Machines on MRI and PET modalities |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| Suk 等人 ([2014](#bib.bib274)) | RBM | AD/MCI/HC 分类；在 MRI 和 PET 模态上使用深度玻尔兹曼机
    |'
- en: '| Payan and Montana ([2015](#bib.bib212)) | CNN | AD/MCI/HC classification;
    3D CNN pre-trained with sparse auto-encoders |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| Payan 和 Montana ([2015](#bib.bib212)) | CNN | AD/MCI/HC 分类；使用稀疏自编码器进行预训练的
    3D CNN |'
- en: '| Suk et al. ([2015](#bib.bib275)) | SAE | AD/MCI/HC classification; SAE for
    latent feature extraction on a large set of hand-crafted features from MRI and
    PET |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| Suk 等人 ([2015](#bib.bib275)) | SAE | AD/MCI/HC 分类；用于从 MRI 和 PET 的大量手工特征中提取潜在特征的
    SAE |'
- en: '| Hosseini-Asl et al. ([2016](#bib.bib131)) | CNN | AD/MCI/HC classification;
    3D CNN pre-trained with a 3D convolutional auto-encoder on fMRI data |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| Hosseini-Asl 等人 ([2016](#bib.bib131)) | CNN | AD/MCI/HC 分类；使用 3D 卷积自编码器在
    fMRI 数据上进行预训练的 3D CNN |'
- en: '| Kim et al. ([2016b](#bib.bib157)) | ANN | Schizophrenia/NH classification
    on fMRI; Neural network showing advantage of pre-training with SAEs, and L1 sparsification
    |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| Kim 等人 ([2016b](#bib.bib157)) | ANN | 精神分裂症/NH 分类（使用 fMRI）；神经网络展示了与 SAE 进行预训练的优势，并进行了
    L1 稀疏化 |'
- en: '| Ortiz et al. ([2016](#bib.bib209)) | DBN | AD/MCI/HC classification; An ensemble
    of Deep belief networks, with their votes fused using an SVM classifier |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| Ortiz 等人 ([2016](#bib.bib209)) | DBN | AD/MCI/HC 分类；深度信念网络的集成，其投票使用 SVM 分类器融合
    |'
- en: '| Pinaya et al. ([2016](#bib.bib216)) | DBN | Schizophrenia/NH classification;
    DBN pre-training followed by supervised fine-tuning |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| Pinaya 等人 ([2016](#bib.bib216)) | DBN | 精神分裂症/NH 分类；DBN 预训练后进行监督微调 |'
- en: '| Sarraf and Tofighi ([2016](#bib.bib245)) | CNN | AD/HC classification; Adapted
    Lenet-5 architecture on fMRI data |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| Sarraf 和 Tofighi ([2016](#bib.bib245)) | CNN | AD/HC 分类；在 fMRI 数据上调整后的 Lenet-5
    架构 |'
- en: '| Suk et al. ([2016](#bib.bib278)) | SAE | MCI/HC classification of fMRI data;
    Stacked auto-encoders for feature extraction, HMM as a generative model on top
    |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| Suk 等人 ([2016](#bib.bib278)) | SAE | fMRI 数据的 MCI/HC 分类；用于特征提取的堆叠自编码器，顶层为生成模型
    HMM |'
- en: '| Suk and Shen ([2016](#bib.bib277)) | CNN | AD/MCI/HC classification; CNN
    on sparse representations created by regression models |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Suk 和 Shen ([2016](#bib.bib277)) | CNN | AD/MCI/HC 分类；CNN 在回归模型创建的稀疏表示上 |'
- en: '| Shi et al. ([2017](#bib.bib257)) | ANN | AD/MCI/HC classification; Multi-modal
    stacked deep polynomial networks with an SVM classifier on top using MRI and PET
    |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| Shi 等人 ([2017](#bib.bib257)) | ANN | AD/MCI/HC 分类；使用 MRI 和 PET 的多模态堆叠深度多项式网络与
    SVM 分类器 |'
- en: '| Tissue/anatomy/lesion/tumor segmentation |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 组织/解剖/病变/肿瘤分割 |'
- en: '| Guo et al. ([2014](#bib.bib119)) | SAE | Hippocampus segmentation; SAE for
    representation learning used for target/atlas patch similarity measurement |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| Guo 等人 ([2014](#bib.bib119)) | SAE | 海马体分割；用于目标/图谱补丁相似性测量的表示学习 SAE |'
- en: '| de Brebisson and Montana ([2015](#bib.bib76)) | CNN | Anatomical segmentation;
    fusing multi-scale 2D patches with a 3D patch using a CNN |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| de Brebisson 和 Montana ([2015](#bib.bib76)) | CNN | 解剖分割；使用 CNN 融合多尺度 2D
    补丁与 3D 补丁 |'
- en: '| Choi and Jin ([2016](#bib.bib62)) | CNN | Striatum segmentation; Two-stage
    (global/local) approximations with 3D CNNs |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| Choi 和 Jin ([2016](#bib.bib62)) | CNN | 纹状体分割；使用 3D CNN 的两阶段（全局/局部）近似 |'
- en: '| Stollenga et al. ([2015](#bib.bib273)) | RNN | Tissue segmentation; PyraMiD-LSTM,
    best brain segmentation results on MRBrainS13 (and competitive results on EM-ISBI12)
    |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| Stollenga 等人 ([2015](#bib.bib273)) | RNN | 组织分割；PyraMiD-LSTM，在 MRBrainS13
    上取得了最佳的大脑分割结果（在 EM-ISBI12 上也有竞争力的结果） |'
- en: '| Zhang et al. ([2015](#bib.bib343)) | CNN | Tissue segmentation; multi-modal
    2D CNN |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| Zhang 等人 ([2015](#bib.bib343)) | CNN | 组织分割；多模态 2D CNN |'
- en: '| Andermatt et al. ([2016](#bib.bib9)) | RNN | Tissue segmentation; two convolutional
    gated recurrent units in different directions for each dimension |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| Andermatt 等人 ([2016](#bib.bib9)) | RNN | 组织分割；每个维度中具有不同方向的两个卷积门控递归单元 |'
- en: '| Bao and Chung ([2016](#bib.bib18)) | CNN | Anatomical segmentation; Multi-scale
    late fusion CNN with random walker as a novel label consistency method |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| Bao and Chung ([2016](#bib.bib18)) | CNN | 解剖分割；多尺度晚期融合CNN与随机游走作为新颖的标签一致性方法
    |'
- en: '| Birenbaum and Greenspan ([2016](#bib.bib34)) | CNN | Lesion segmentation;
    Multi-view (2.5D) CNN concatenating features from previous time step for a longitudinal
    analysis |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| Birenbaum and Greenspan ([2016](#bib.bib34)) | CNN | 病变分割；多视图（2.5D）CNN串联来自前一步的特征以进行纵向分析
    |'
- en: '| Brosch et al. ([2016](#bib.bib36)) | CNN | Lesion segmentation; Convolutional
    encoder-decoder network with shortcut connections and convolutional RBM pretraining
    |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| Brosch et al. ([2016](#bib.bib36)) | CNN | 病变分割；卷积编码器-解码器网络，具有快捷连接和卷积RBM预训练
    |'
- en: '| Chen et al. ([2016a](#bib.bib49)) | CNN | Tissue segmentation; 3D res-net
    combining features from different layers |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| Chen et al. ([2016a](#bib.bib49)) | CNN | 组织分割；结合来自不同层的特征的3D res-net |'
- en: '| Ghafoorian et al. ([2016b](#bib.bib108)) | CNN | Lesion segmentation; CNN
    trained on non-uniformly sampled patch to integrate a larger context with a foviation
    effect |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| Ghafoorian et al. ([2016b](#bib.bib108)) | CNN | 病变分割；在非均匀采样的贴片上训练的CNN，集成更大上下文与中心化效应
    |'
- en: '| Ghafoorian et al. ([2016a](#bib.bib107)) | CNN | Lesion segmentation; multi-scale
    CNN with late fusion that integrates anatomical location information into network
    |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| Ghafoorian et al. ([2016a](#bib.bib107)) | CNN | 病变分割；多尺度CNN与晚期融合，集成解剖位置信息到网络中
    |'
- en: '| Havaei et al. ([2016b](#bib.bib123)) | CNN | Tumor segmentation; CNN handling
    missing modalities with abstraction layer that transforms feature maps to their
    statistics |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| Havaei et al. ([2016b](#bib.bib123)) | CNN | 肿瘤分割；CNN处理缺失模态，通过抽象层将特征图转换为其统计量
    |'
- en: '| Havaei et al. ([2016a](#bib.bib122)) | CNN | Tumor segmentation; two-path
    way CNN with different receptive fields |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| Havaei et al. ([2016a](#bib.bib122)) | CNN | 肿瘤分割；两路径CNN具有不同的感受野 |'
- en: '| Kamnitsas et al. ([2017](#bib.bib148)) | CNN | Tumor segmentation; 3D multi-scale
    fully convolutional network with CRF for label consistency |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| Kamnitsas et al. ([2017](#bib.bib148)) | CNN | 肿瘤分割；3D多尺度全卷积网络与CRF用于标签一致性
    |'
- en: '| Kleesiek et al. ([2016](#bib.bib160)) | CNN | Brain extraction; 3D fully
    convolutional CNN on multi-modal input |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| Kleesiek et al. ([2016](#bib.bib160)) | CNN | 大脑提取；在多模态输入上的3D全卷积CNN |'
- en: '| Mansoor et al. ([2016](#bib.bib188)) | SAE | Visual pathway segmentation;
    Learning appearance features from SAE for steering the shape model for segmentation
    |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| Mansoor et al. ([2016](#bib.bib188)) | SAE | 视觉通路分割；从SAE学习外观特征以引导形状模型进行分割
    |'
- en: '| Milletari et al. ([2016a](#bib.bib193)) | CNN | Anatomical segmentation on
    MRI and US; Hough-voting to acquire mapping from CNN features to full patch segmentations
    |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| Milletari et al. ([2016a](#bib.bib193)) | CNN | 基于MRI和US的解剖分割；Hough投票用于从CNN特征获取全贴片分割的映射
    |'
- en: '| Moeskops et al. ([2016a](#bib.bib196)) | CNN | Tissue segmentation; CNN trained
    on multiple patch sizes |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| Moeskops et al. ([2016a](#bib.bib196)) | CNN | 组织分割；在多种贴片尺寸上训练的CNN |'
- en: '| Nie et al. ([2016b](#bib.bib205)) | CNN | Infant tissue segmentation; FCN
    with a late fusion method on different modalities |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| Nie et al. ([2016b](#bib.bib205)) | CNN | 婴儿组织分割；FCN与晚期融合方法在不同模态上 |'
- en: '| Pereira et al. ([2016](#bib.bib214)) | CNN | Tumor segmentation; CNN on multiple
    modality input |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| Pereira et al. ([2016](#bib.bib214)) | CNN | 肿瘤分割；多模态输入上的CNN |'
- en: '| Shakeri et al. ([2016](#bib.bib252)) | CNN | Anatomical segmentation; FCN
    followed by Markov random fields |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| Shakeri et al. ([2016](#bib.bib252)) | CNN | 解剖分割；FCN后跟Markov随机场 |'
- en: '| Zhao and Jia ([2016](#bib.bib345)) | CNN | Tumor segmentation; Multi-scale
    CNN with a late fusion architecture |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| Zhao and Jia ([2016](#bib.bib345)) | CNN | 肿瘤分割；多尺度CNN与晚期融合架构 |'
- en: '| Lesion/tumor detection and classification |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| 病变/肿瘤检测和分类 |'
- en: '| Pan et al. ([2015](#bib.bib211)) | CNN | Tumor grading; 2D tumor patch classification
    using a CNN |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| Pan et al. ([2015](#bib.bib211)) | CNN | 肿瘤分级；使用CNN进行2D肿瘤贴片分类 |'
- en: '| Dou et al. ([2015](#bib.bib83)) | ISA | Microbleed detection; 3D stacked
    Independent Subspace Analysis for candidate feature extraction, SVM classification
    |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| Dou et al. ([2015](#bib.bib83)) | ISA | 微出血检测；3D堆叠独立子空间分析用于候选特征提取，SVM分类 |'
- en: '| Dou et al. ([2016c](#bib.bib84)) | CNN | Microbleed detection; 3D FCN for
    candidate segmentation followed by a 3D CNN as false positive reduction |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| Dou et al. ([2016c](#bib.bib84)) | CNN | 微出血检测；3D FCN进行候选分割，随后用3D CNN进行假阳性减少
    |'
- en: '| Ghafoorian et al. ([2017](#bib.bib106)) | CNN | Lacune detection; FCN for
    candidate segmentation then a multi-scale 3D CNN with anatomical features as false
    positive reduction |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| Ghafoorian 等人 ([2017](#bib.bib106)) | CNN | 空洞检测；使用 FCN 进行候选分割，然后用具有解剖特征的多尺度
    3D CNN 进行假阳性减少 |'
- en: '| Survival/disease activity/development prediction |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 生存/疾病活动/发展预测 |'
- en: '| Kawahara et al. ([2016b](#bib.bib152)) | CNN | Neurodevelopment prediction;
    CNN with specially-designed edge-to-edge, edge-to-node and node-to-graph conv.
    layers for brain nets |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| Kawahara 等人 ([2016b](#bib.bib152)) | CNN | 神经发育预测；CNN 具有专门设计的边缘到边缘、边缘到节点和节点到图的卷积层用于大脑网络
    |'
- en: '| Nie et al. ([2016c](#bib.bib206)) | CNN | Survival prediction; features from
    a Multi-modal 3D CNN is fused with hand-crafted features to train an SVM |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| Nie 等人 ([2016c](#bib.bib206)) | CNN | 生存预测；将来自多模态 3D CNN 的特征与手工制作的特征融合以训练
    SVM |'
- en: '| Yoo et al. ([2016](#bib.bib333)) | CNN | Disease activity prediction; Training
    a CNN on the Euclidean distance transform of the lesion masks as the input |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| Yoo 等人 ([2016](#bib.bib333)) | CNN | 疾病活动预测；训练 CNN 以欧几里得距离变换的病灶掩模作为输入 |'
- en: '| van der Burgh et al. ([2017](#bib.bib294)) | CNN | Survival prediction; DBN
    on MRI and fusing it with clinical characteristics and structural connectivity
    data |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| van der Burgh 等人 ([2017](#bib.bib294)) | CNN | 生存预测；在 MRI 上使用 DBN，并将其与临床特征和结构连接数据融合
    |'
- en: '| Image construction/enhancement |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 图像构建/增强 |'
- en: '| Li et al. ([2014](#bib.bib170)) | CNN | Image construction; 3D CNN for constructing
    PET from MR images |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| Li 等人 ([2014](#bib.bib170)) | CNN | 图像构建；用于从 MR 图像构建 PET 的 3D CNN |'
- en: '| Bahrami et al. ([2016](#bib.bib17)) | CNN | Image construction; 3D CNN for
    constructing 7T-like images from 3T MRI |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| Bahrami 等人 ([2016](#bib.bib17)) | CNN | 图像构建；用于从 3T MRI 构建 7T 类图像的 3D CNN
    |'
- en: '| Benou et al. ([2016](#bib.bib30)) | SAE | Denoising DCE-MRI; using an ensemble
    of denoising SAE (pretrained with RBMs) |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| Benou 等人 ([2016](#bib.bib30)) | SAE | 去噪 DCE-MRI；使用一组去噪 SAE（用 RBMs 预训练） |'
- en: '| Golkov et al. ([2016](#bib.bib112)) | CNN | Image construction; Per-pixel
    neural network to predict complex diffusion parameters based on fewer measurements
    |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| Golkov 等人 ([2016](#bib.bib112)) | CNN | 图像构建；每像素神经网络基于更少的测量来预测复杂的扩散参数 |'
- en: '| Hoffmann et al. ([2016](#bib.bib129)) | ANN | Image construction; Deep neural
    nets with SRelu nonlinearity for thermal image construction |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| Hoffmann 等人 ([2016](#bib.bib129)) | ANN | 图像构建；使用 SRelu 非线性的深度神经网络进行热图像构建
    |'
- en: '| Nie et al. ([2016a](#bib.bib204)) | CNN | Image construction; 3D fully convolutional
    network for constructing CT from MR images |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| Nie 等人 ([2016a](#bib.bib204)) | CNN | 图像构建；用于从 MR 图像构建 CT 的 3D 全卷积网络 |'
- en: '| Sevetlidis et al. ([2016](#bib.bib250)) | ANN | Image construction; Encoder-decoder
    network for synthesizing one MR modality from another |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| Sevetlidis 等人 ([2016](#bib.bib250)) | ANN | 图像构建；用于从一种 MR 模态合成另一种 MR 模态的编码-解码网络
    |'
- en: '| Other |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 其他 |'
- en: '| Brosch et al. ([2014](#bib.bib37)) | DBN | Manifold Learning; DBN with conv.
    RBM layers for modeling the variability in brain morphology and lesion distribution
    in MS |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| Brosch 等人 ([2014](#bib.bib37)) | DBN | 流形学习；具有卷积 RBM 层的 DBN 用于建模大脑形态和 MS
    中病变分布的变异性 |'
- en: '| Cheng et al. ([2015](#bib.bib60)) | ANN | Similarity measurement; neural
    network fusing the moving and reference image patches, pretrained with SAE |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| Cheng 等人 ([2015](#bib.bib60)) | ANN | 相似性测量；神经网络融合移动图像和参考图像块，使用 SAE 进行预训练
    |'
- en: '| Huang et al. ([2016](#bib.bib134)) | RBM | fMRI blind source separation;
    RBM for both internal and functional interaction-induced latent sources detection
    |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| Huang 等人 ([2016](#bib.bib134)) | RBM | fMRI 盲源分离；RBM 用于内部和功能相互作用诱导的潜在源检测
    |'
- en: '| Simonovsky et al. ([2016](#bib.bib263)) | CNN | Similarity measurement; 3D
    CNN estimating similarity between reference and moving images stacked in the input
    |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| Simonovsky 等人 ([2016](#bib.bib263)) | CNN | 相似性测量；3D CNN 估计参考图像和移动图像之间的相似性
    |'
- en: '| Wu et al. ([2013](#bib.bib313)) | ISA | Correspondence detection in deformable
    registration; stacked convolutional ISA for unsupervised feature learning |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| Wu 等人 ([2013](#bib.bib313)) | ISA | 变形配准中的对应检测；用于无监督特征学习的堆叠卷积 ISA |'
- en: '| Yang et al. ([2016d](#bib.bib331)) | CNN | Image registration; Conv. encoder-decoder
    net. predicting momentum in x and y directions, given the moving and fixed image
    patches |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| Yang 等人 ([2016d](#bib.bib331)) | CNN | 图像配准；卷积编码-解码网络预测 x 和 y 方向的动量，给定移动和固定图像块
    |'
- en: 3.5.2 Image Generation and Enhancement
  id: totrans-230
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.5.2 图像生成与增强
- en: A variety of image generation and enhancement methods using deep architectures
    have been proposed, ranging from removing obstructing elements in images, normalizing
    images, improving image quality, data completion, and pattern discovery.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 提出了各种使用深度架构的图像生成和增强方法，这些方法包括去除图像中的遮挡元素、图像归一化、提高图像质量、数据补全和模式发现。
- en: In image generation, 2D or 3D CNNs are used to convert one input image into
    another. Typically these architectures lack the pooling layers present in classification
    networks. These systems are then trained with a data set in which both the input
    and the desired output are present, defining the differences between the generated
    and desired output as the loss function. Examples are regular and bone-suppressed
    X-ray in Yang et al. ([2016c](#bib.bib330)), 3T and 7T brain MRI in Bahrami et al.
    ([2016](#bib.bib17)), PET from MRI in Li et al. ([2014](#bib.bib170)), and CT
    from MRI in Nie et al. ([2016a](#bib.bib204)). Li et al. ([2014](#bib.bib170))
    even showed that one can use these generated images in computer-aided diagnosis
    systems for Alzheimer’s disease when the original data is missing or not acquired.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像生成中，2D 或 3D CNN 用于将一个输入图像转换为另一个图像。这些架构通常缺少分类网络中的池化层。这些系统通常使用一个数据集进行训练，其中输入和期望输出都存在，并将生成的输出与期望输出之间的差异定义为损失函数。例如，Yang
    et al. ([2016c](#bib.bib330)) 的常规 X 射线和骨抑制 X 射线，Bahrami et al. ([2016](#bib.bib17))
    的 3T 和 7T 脑 MRI，Li et al. ([2014](#bib.bib170)) 的 MRI 中的 PET，以及 Nie et al. ([2016a](#bib.bib204))
    的 MRI 中的 CT。Li et al. ([2014](#bib.bib170)) 甚至展示了当原始数据丢失或未获取时，可以将这些生成的图像用于计算机辅助诊断系统。
- en: With multi-stream CNNs super-resolution images can be generated from multiple
    low-resolution inputs (section [2.4.2](#S2.SS4.SSS2 "2.4.2 Multi-stream architectures
    ‣ 2.4 Deep CNN Architectures ‣ 2 Overview of deep learning methods ‣ A Survey
    on Deep Learning in Medical Image Analysis")). In Oktay et al. ([2016](#bib.bib208)),
    multi-stream networks reconstructed high-resolution cardiac MRI from one or more
    low-resolution input MRI volumes. Not only can this strategy be used to infer
    missing spatial information, but can also be leveraged in other domains; for example,
    inferring advanced MRI diffusion parameters from limited data (Golkov et al.,
    [2016](#bib.bib112)). Other image enhancement applications like intensity normalization
    and denoising have seen only limited application of deep learning algorithms.
    Janowczyk et al. ([2016a](#bib.bib140)) used SAEs to normalize H&E-stained histopathology
    images whereas Benou et al. ([2016](#bib.bib30)) used CNNs to perform denoising
    in DCE-MRI time-series.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多流 CNN 可以从多个低分辨率输入生成超分辨率图像（章节 [2.4.2](#S2.SS4.SSS2 "2.4.2 多流架构 ‣ 2.4 深度 CNN
    架构 ‣ 2 深度学习方法概述 ‣ 医学图像分析中的深度学习调查")）。在 Oktay et al. ([2016](#bib.bib208)) 的研究中，多流网络从一个或多个低分辨率输入
    MRI 数据重建了高分辨率的心脏 MRI。这种策略不仅可以用来推断缺失的空间信息，还可以在其他领域中发挥作用；例如，从有限的数据中推断高级 MRI 扩散参数（Golkov
    et al., [2016](#bib.bib112)）。其他图像增强应用如强度归一化和去噪则仅限于深度学习算法的有限应用。Janowczyk et al.
    ([2016a](#bib.bib140)) 使用 SAE 来归一化 H&E 染色的组织病理图像，而 Benou et al. ([2016](#bib.bib30))
    使用 CNN 在 DCE-MRI 时间序列中进行去噪。
- en: Image generation has seen impressive results with very creative applications
    of deep networks in significantly differing tasks. One can only expect the number
    of tasks to increase further in the future.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图像生成在任务显著不同的情况下展示了深度网络非常有创意的应用，取得了令人印象深刻的结果。可以预期，未来任务的数量将进一步增加。
- en: 'Table 2: Overview of papers using deep learning techniques for retinal image
    analysis. All works use CNNs.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：使用深度学习技术进行视网膜图像分析的论文概述。所有工作都使用了 CNN。
- en: '| Color fundus images: segmentation of anatomical structures and quality assessment
    |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 彩色眼底图像：解剖结构的分割和质量评估 |'
- en: '| --- |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Fu et al. ([2016b](#bib.bib98)) | Blood vessel segmentation; CNN combined
    with CRF to model long-range pixel interactions |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| Fu et al. ([2016b](#bib.bib98)) | 血管分割；将 CNN 与 CRF 结合以建模长距离像素交互 |'
- en: '| Fu et al. ([2016a](#bib.bib97)) | Blood vessel segmentation; extending the
    approach by Fu et al. ([2016b](#bib.bib98)) by reformulating CRF as RNN |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| Fu et al. ([2016a](#bib.bib97)) | 血管分割；通过将 CRF 重构为 RNN 扩展 Fu et al. ([2016b](#bib.bib98))
    的方法 |'
- en: '| Mahapatra et al. ([2016](#bib.bib185)) | Image quality assessment; classification
    output using CNN-based features combined with the output using saliency maps |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| Mahapatra et al. ([2016](#bib.bib185)) | 图像质量评估；使用基于 CNN 的特征结合显著性图的分类输出 |'
- en: '| Maninis et al. ([2016](#bib.bib187)) | Segmentation of blood vessels and
    optic disk; VGG-19 network extended with specialized layers for each segmentation
    task |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| Maninis 等人 ([2016](#bib.bib187)) | 血管和视盘分割；VGG-19网络扩展了每个分割任务的专用层 |'
- en: '| Wu et al. ([2016](#bib.bib312)) | Blood vessel segmentation; patch-based
    CNN followed by mapping PCA solution of last layer feature maps to full segmentation
    |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| Wu 等人 ([2016](#bib.bib312)) | 血管分割；基于补丁的CNN，接着将最后一层特征图的PCA解决方案映射到完整分割上 |'
- en: '| Zilly et al. ([2017](#bib.bib349)) | Segmentation of the optic disk and the
    optic cup; simple CNN with filters sequentially learned using boosting |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| Zilly 等人 ([2017](#bib.bib349)) | 视盘和视杯的分割；简单CNN，使用提升算法逐步学习滤波器 |'
- en: '| Color fundus images: detection of abnormalities and diseases |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 彩色眼底图像：异常和疾病检测 |'
- en: '| Chen et al. ([2015d](#bib.bib57)) | Glaucoma detection; end-to-end CNN, the
    input is a patch centered at the optic disk |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人 ([2015d](#bib.bib57)) | 青光眼检测；端到端CNN，输入为以视盘为中心的补丁 |'
- en: '| Abràmoff et al. ([2016](#bib.bib2)) | Diabetic retinopathy detection; end-to-end
    CNN, outperforms traditional method, evaluated on a public dataset |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| Abràmoff 等人 ([2016](#bib.bib2)) | 糖尿病视网膜病变检测；端到端CNN，性能优于传统方法，基于公开数据集评估 |'
- en: '| Burlina et al. ([2016](#bib.bib38)) | Age-related macular degeneration detection;
    uses overfeat pretrained network for feature extraction |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| Burlina 等人 ([2016](#bib.bib38)) | 年龄相关性黄斑变性检测；使用overfeat预训练网络进行特征提取 |'
- en: '| van Grinsven et al. ([2016](#bib.bib296)) | Hemorrhage detection; CNN dynamically
    trained using selective data sampling to perform hard negative mining |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| van Grinsven 等人 ([2016](#bib.bib296)) | 出血检测；CNN动态训练，使用选择性数据采样进行困难负样本挖掘 |'
- en: '| Gulshan et al. ([2016](#bib.bib115)) | Diabetic retinopathy detection; Inception
    network, performance comparable to a panel of seven certified ophthalmologists
    |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| Gulshan 等人 ([2016](#bib.bib115)) | 糖尿病视网膜病变检测；Inception网络，性能与七位认证眼科医生的面板相当
    |'
- en: '| Prentasic and Loncaric ([2016](#bib.bib221)) | Hard exudate detection; end-to-end
    CNN combined with the outputs of traditional classifiers for detection of landmarks
    |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| Prentasic 和 Loncaric ([2016](#bib.bib221)) | 硬性渗出物检测；端到端CNN与传统分类器输出结合，用于地标检测
    |'
- en: '| Worrall et al. ([2016](#bib.bib311)) | Retinopathy of prematurity detection;
    fine-tuned ImageNet trained GoogLeNet, feature map visualization to highlight
    disease |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| Worrall 等人 ([2016](#bib.bib311)) | 早产儿视网膜病变检测；微调的ImageNet训练GoogLeNet，特征图可视化以突出疾病
    |'
- en: '| Work in other imaging modalities |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 其他成像模态的工作 |'
- en: '| Gao et al. ([2015](#bib.bib103)) | Cataract classification in slit lamp images;
    CNN followed by a set of recursive neural networks to extract higher order features
    |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| Gao 等人 ([2015](#bib.bib103)) | 裂隙灯图像中的白内障分类；CNN后接一组递归神经网络以提取更高阶特征 |'
- en: '| Schlegl et al. ([2015](#bib.bib247)) | Fluid segmentation in OCT; weakly
    supervised CNN improved with semantic descriptors from clinical reports |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| Schlegl 等人 ([2015](#bib.bib247)) | OCT中的液体分割；使用临床报告中的语义描述符改进的弱监督CNN |'
- en: '| Prentasic et al. ([2016](#bib.bib220)) | Blood vessel segmentation in OCT
    angiography; simple CNN, segmentation of several capillary networks |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| Prentasic 等人 ([2016](#bib.bib220)) | OCT血管造影中的血管分割；简单的CNN，分割多个毛细血管网络 |'
- en: 3.5.3 Combining Image Data With Reports
  id: totrans-256
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.5.3 结合图像数据与报告
- en: 'The combination of text reports and medical image data has led to two avenues
    of research: (1) leveraging reports to improve image classification accuracy (Schlegl
    et al., [2015](#bib.bib247)), and (2) generating text reports from images (Kisilev
    et al., [2016](#bib.bib159); Shin et al., [2015](#bib.bib258), [2016a](#bib.bib260);
    Wang et al., [2016e](#bib.bib309)); the latter inspired by recent caption generation
    papers from natural images (Karpathy and Fei-Fei, [2015](#bib.bib149)). To the
    best of our knowledge, the first step towards leveraging reports was taken by
    Schlegl et al. ([2015](#bib.bib247)), who argued that large amounts of annotated
    data may be difficult to acquire and proposed to add semantic descriptions from
    reports as labels. The system was trained on sets of images along with their textual
    descriptions and was taught to predict semantic class labels during test time.
    They showed that semantic information increases classification accuracy for a
    variety of pathologies in Optical Coherence Tomography (OCT) images.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 文本报告和医学图像数据的结合导致了两个研究方向：（1）利用报告提高图像分类准确性（Schlegl 等人，[2015](#bib.bib247)），以及（2）从图像生成文本报告（Kisilev
    等人，[2016](#bib.bib159)；Shin 等人，[2015](#bib.bib258)，[2016a](#bib.bib260)；Wang 等人，[2016e](#bib.bib309)）；后者受到最近自然图像标注论文的启发（Karpathy
    和 Fei-Fei，[2015](#bib.bib149)）。据我们所知，Schlegl 等人 ([2015](#bib.bib247)) 是第一个迈出利用报告的步骤的人，他们认为大量标注数据可能难以获取，并建议将报告中的语义描述作为标签添加。该系统在图像及其文本描述集上进行了训练，并被教导在测试时预测语义类别标签。他们展示了语义信息如何提高光学相干断层扫描（OCT）图像中各种病理的分类准确性。
- en: 'Shin et al. ([2015](#bib.bib258)) and Wang et al. ([2016e](#bib.bib309)) mined
    semantic interactions between radiology reports and images from a large data set
    extracted from a PACS system. They employed latent Dirichlet allocation (LDA),
    a type of stochastic model that generates a distribution over a vocabulary of
    topics based on words in a document. In a later work, Shin et al. ([2016a](#bib.bib260))
    proposed a system to generate descriptions from chest X-rays. A CNN was employed
    to generate a representation of an image one label at a time, which was then used
    to train an RNN to generate sequence of MeSH keywords. Kisilev et al. ([2016](#bib.bib159))
    used a completely different approach and predicted categorical BI-RADS descriptors
    for breast lesions. In their work they focused on three descriptors used in mammography:
    shape, margin, and density, where each have their own class label. The system
    was fed with the image data and region proposals and predicts the correct label
    for each descriptor (e.g. for shape either oval, round, or irregular).'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: Shin 等人 ([2015](#bib.bib258)) 和 Wang 等人 ([2016e](#bib.bib309)) 从从 PACS 系统中提取的大数据集中挖掘了放射学报告与图像之间的语义交互。他们使用了潜在狄利克雷分配（LDA），这是一种基于文档中的单词生成主题词汇分布的随机模型。在后续工作中，Shin
    等人 ([2016a](#bib.bib260)) 提出了一个从胸部 X 光片生成描述的系统。该系统使用卷积神经网络（CNN）逐个生成图像的表示，然后用这些表示训练递归神经网络（RNN）生成
    MeSH 关键词的序列。Kisilev 等人 ([2016](#bib.bib159)) 采用了完全不同的方法，预测乳腺病变的分类 BI-RADS 描述符。在他们的工作中，他们集中于乳腺摄影中使用的三个描述符：形状、边缘和密度，每个描述符都有其自己的类别标签。系统接收图像数据和区域提议，并预测每个描述符的正确标签（例如，形状可以是椭圆、圆形或不规则）。
- en: Given the wealth of data that is available in PACS systems in terms of images
    and corresponding diagnostic reports, it seems like an ideal avenue for future
    deep learning research. One could expect that advances in captioning natural images
    will in time be applied to these data sets as well.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于 PACS 系统中图像及其对应诊断报告的数据量丰富，这似乎是未来深度学习研究的理想方向。可以预期，自然图像的标注进展最终也会应用于这些数据集。
- en: 4 Anatomical application areas
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 解剖学应用领域
- en: 'This section presents an overview of deep learning contributions to the various
    application areas in medical imaging. We highlight some key contributions and
    discuss performance of systems on large data sets and on public challenge data
    sets. All these challenges are listed on [http:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '本节概述了深度学习在医学影像各个应用领域的贡献。我们突出了一些关键贡献，并讨论了系统在大数据集和公共挑战数据集上的性能。所有这些挑战列在 [http:'
- en: www.grand-challenge.org](http:%5C%5C%0A%5C%5C%0Awww.grand-challenge.org).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.grand-challenge.org](http:%5C%5C%0A%5C%5C%0Awww.grand-challenge.org)。'
- en: 4.1 Brain
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 大脑
- en: DNNs have been extensively used for brain image analysis in several different
    application domains (Table [1](#S3.T1 "Table 1 ‣ 3.5.1 Content-based image retrieval
    ‣ 3.5 Other tasks in medical imaging ‣ 3 Deep Learning Uses in Medical Imaging
    ‣ A Survey on Deep Learning in Medical Image Analysis")). A large number of studies
    address classification of Alzheimer’s disease and segmentation of brain tissue
    and anatomical structures (e.g. the hippocampus). Other important areas are detection
    and segmentation of lesions (e.g. tumors, white matter lesions, lacunes, micro-bleeds).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在几个不同的应用领域中，DNNs广泛用于大脑图像分析（表[1](#S3.T1 "Table 1 ‣ 3.5.1 Content-based image
    retrieval ‣ 3.5 Other tasks in medical imaging ‣ 3 Deep Learning Uses in Medical
    Imaging ‣ A Survey on Deep Learning in Medical Image Analysis")）。大量研究涉及阿尔茨海默病的分类和大脑组织及解剖结构（例如海马区）的分割。其他重要领域包括病变（例如肿瘤、白质病变、小梗死、微出血）的检测和分割。
- en: Apart from the methods that aim for a scan-level classification (e.g. Alzheimer
    diagnosis), most methods learn mappings from local patches to representations
    and subsequently from representations to labels. However, the local patches might
    lack the contextual information required for tasks where anatomical information
    is paramount (e.g. white matter lesion segmentation). To tackle this, Ghafoorian
    et al. ([2016b](#bib.bib108)) used non-uniformly sampled patches by gradually
    lowering sampling rate in patch sides to span a larger context. An alternative
    strategy used by many groups is multi-scale analysis and a fusion of representations
    in a fully-connected layer.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 除了旨在进行扫描级分类（例如阿尔茨海默病诊断）的方法之外，大多数方法都从局部补丁到表示的映射学习，然后从表示到标签的映射。然而，对于需要解剖信息至关重要的任务（例如白质病变分割），局部补丁可能缺乏所需的上下文信息。为了解决这个问题，Ghafoorian
    et al. ([2016b](#bib.bib108))逐渐降低补丁边缘的采样率，以覆盖更大范围的上下文。许多团队采用的另一种替代策略是多尺度分析和在全连接层中融合表示。
- en: Even though brain images are 3D volumes in all surveyed studies, most methods
    work in 2D, analyzing the 3D volumes slice-by-slice. This is often motivated by
    either the reduced computational requirements or the thick slices relative to
    in-plane resolution in some data sets. More recent publications had also employed
    3D networks.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管所有调查研究中的大脑图像都是3D体积，但大多数方法都是在2D平面上一层层地分析3D体积。这往往是由于减少的计算需求或在某些数据集中与平面分辨率相对较厚的切片所致。最近的出版物还采用了3D网络。
- en: DNNs have completely taken over many brain image analysis challenges. In the
    2014 and 2015 brain tumor segmentation challenges (BRATS), the 2015 longitudinal
    multiple sclerosis lesion segmentation challenge, the 2015 ischemic stroke lesion
    segmentation challenge (ISLES), and the 2013 MR brain image segmentation challenge
    (MRBrains), the top ranking teams to date have all used CNNs. Almost all of the
    aforementioned methods are concentrating on brain MR images. We expect that other
    brain imaging modalities such as CT and US can also benefit from deep learning
    based analysis.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: DNNs已经完全接管了许多大脑图像分析挑战。在2014和2015年的脑肿瘤分割挑战（BRATS）、2015年的多发性硬化症病灶分割挑战、2015年的缺血性中风病灶分割挑战（ISLES）和2013年的MR脑图像分割挑战（MRBrains）中，迄今为止排名靠前的团队都使用了CNN。几乎所有上述方法都集中在大脑MR图像上。我们预计其他大脑成像模态，如CT和US，也可以从基于深度学习的分析中受益。
- en: 'Table 3: Overview of papers using deep learning techniques for chest x-ray
    image analysis.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：使用深度学习技术进行胸部X射线图像分析的论文概览。
- en: '| Reference | Application | Remarks |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 参考 | 应用 | 备注 |'
- en: '| --- | --- | --- |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Lo et al. ([1995](#bib.bib180)) | Nodule detection | Classifies candidates
    from small patches with two-layer CNN, each with 12 $5\times 5$ filters |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| Lo et al. ([1995](#bib.bib180)) | 结节检测 | 用两层CNN从小补丁中分类候选补丁，每个补丁有12个$5\times
    5$的滤波器 |'
- en: '| Anavi et al. ([2015](#bib.bib7)) | Image retrieval | Combines classical features
    with those from pre-trained CNN for image retrieval using SVM |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| Anavi et al. ([2015](#bib.bib7)) | 图像检索 | 使用SVM将经典特征和来自预训练CNN的特征结合起来进行图像检索
    |'
- en: '| Bar et al. ([2015](#bib.bib19)) | Pathology detection | Features from a pre-trained
    CNN and low level features are used to detect various diseases |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| Bar et al. ([2015](#bib.bib19)) | 病理学检测 | 使用预训练的CNN和低级特征来检测各种疾病的特征 |'
- en: '| Anavi et al. ([2016](#bib.bib8)) | Image retrieval | Continuation of Anavi
    et al. ([2015](#bib.bib7)), adding age and gender as features |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| Anavi et al. ([2016](#bib.bib8)) | 图像检索 | 在Anavi et al. ([2015](#bib.bib7))的基础上，添加了年龄和性别作为特征
    |'
- en: '| Bar et al. ([2016](#bib.bib20)) | Pathology detection | Continuation of Bar
    et al. ([2015](#bib.bib19)), more experiments and adding feature selection |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| Bar 等人 ([2016](#bib.bib20)) | 病理检测 | Bar 等人 ([2015](#bib.bib19)) 的继续，更多实验并添加特征选择
    |'
- en: '| Cicero et al. ([2016](#bib.bib66)) | Pathology detection | GoogLeNet CNN
    detects five common abnormalities, trained and validated on a large data set |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| Cicero 等人 ([2016](#bib.bib66)) | 病理检测 | GoogLeNet CNN 检测五种常见异常，在大数据集上训练和验证
    |'
- en: '| Hwang et al. ([2016](#bib.bib137)) | Tuberculosis detection | Processes entire
    radiographs with a pre-trained fine-tuned network with 6 convolution layers |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| Hwang 等人 ([2016](#bib.bib137)) | 结核检测 | 使用一个经过微调的预训练网络处理整个放射线图，包含 6 层卷积层
    |'
- en: '| Kim and Hwang ([2016](#bib.bib156)) | Tuberculosis detection | MIL framework
    produces heat map of suspicious regions via deconvolution |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| Kim 和 Hwang ([2016](#bib.bib156)) | 结核检测 | MIL 框架通过反卷积生成可疑区域的热图 |'
- en: '| Shin et al. ([2016a](#bib.bib260)) | Pathology detection | CNN detects 17
    diseases, large data set (7k images), recurrent networks produce short captions
    |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| Shin 等人 ([2016a](#bib.bib260)) | 病理检测 | CNN 检测 17 种疾病，大数据集（7k 图像），递归网络生成简短说明
    |'
- en: '| Rajkomar et al. ([2017](#bib.bib226)) | Frontal/lateral classification |
    Pre-trained CNN performs frontal/lateral classification task |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| Rajkomar 等人 ([2017](#bib.bib226)) | 正面/侧面分类 | 预训练 CNN 执行正面/侧面分类任务 |'
- en: '| Yang et al. ([2016c](#bib.bib330)) | Bone suppression | Cascade of CNNs at
    increasing resolution learns bone images from gradients of radiographs |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| Yang 等人 ([2016c](#bib.bib330)) | 骨骼抑制 | 随着分辨率的增加，CNN 的级联从放射线图的梯度中学习骨骼图像 |'
- en: '| Wang et al. ([2016a](#bib.bib301)) | Nodule classification | Combines classical
    features with CNN features from pre-trained ImageNet CNN |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等人 ([2016a](#bib.bib301)) | 结节分类 | 将经典特征与预训练 ImageNet CNN 的 CNN 特征结合
    |'
- en: 'Table 4: Overview of papers using deep learning techniques for chest CT image
    analysis.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：使用深度学习技术进行胸部 CT 图像分析的论文概述。
- en: '| Reference | Application; remarks |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 应用；备注 |'
- en: '| Segmentation |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 分割 |'
- en: '| Charbonnier et al. ([2017](#bib.bib47)) | Airway segmentation where multi-view
    CNN classifies candidate branches as true airways or leaks |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| Charbonnier 等人 ([2017](#bib.bib47)) | 气道分割，使用多视角 CNN 将候选分支分类为真实气道或泄漏 |'
- en: '| Nodule detection and analysis |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 结节检测和分析 |'
- en: '| Ciompi et al. ([2015](#bib.bib68)) | Used a standard feature extractor and
    a pre-trained CNN to classify detected lesions as benign peri-fissural nodules
    |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| Ciompi 等人 ([2015](#bib.bib68)) | 使用标准特征提取器和预训练 CNN 将检测到的病变分类为良性裂隙旁结节 |'
- en: '| van Ginneken et al. ([2015](#bib.bib295)) | Detects nodules with pre-trained
    CNN features from orthogonal patches around candidate, classified with SVM |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| van Ginneken 等人 ([2015](#bib.bib295)) | 使用预训练 CNN 特征从候选结节周围的正交补丁中检测结节，使用
    SVM 进行分类 |'
- en: '| Shen et al. ([2015b](#bib.bib256)) | Three CNNs at different scales estimate
    nodule malignancy scores of radiologists (LIDC-IDRI data set) |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| Shen 等人 ([2015b](#bib.bib256)) | 三个不同尺度的 CNN 估计放射科医生的结节恶性评分（LIDC-IDRI 数据集）
    |'
- en: '| Chen et al. ([2016e](#bib.bib56)) | Combines features from CNN, SDAE and
    classical features to characterize nodules from LIDC-IDRI data set |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人 ([2016e](#bib.bib56)) | 结合 CNN、SDAE 和经典特征来表征 LIDC-IDRI 数据集中的结节 |'
- en: '| Ciompi et al. ([2016](#bib.bib67)) | Multi-stream CNN to classify nodules
    into subtypes: solid, part-solid, non-solid, calcified, spiculated, perifissural
    |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| Ciompi 等人 ([2016](#bib.bib67)) | 多流 CNN 将结节分类为亚型：实性、部分实性、非实性、钙化、刺状、裂隙旁'
- en: '| Dou et al. ([2016b](#bib.bib82)) | Uses 3D CNN around nodule candidates;
    ranks #1 in LUNA16 nodule detection challenge |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| Dou 等人 ([2016b](#bib.bib82)) | 使用 3D CNN 处理结节候选；在 LUNA16 结节检测挑战中排名第一 |'
- en: '| Li et al. ([2016a](#bib.bib171)) | Detects nodules with 2D CNN that processes
    small patches around a nodule |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| Li 等人 ([2016a](#bib.bib171)) | 使用 2D CNN 检测结节，该 CNN 处理结节周围的小补丁 |'
- en: '| Setio et al. ([2016](#bib.bib249)) | Detects nodules with end-to-end trained
    multi-stream CNN with 9 patches per candidate |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| Setio 等人 ([2016](#bib.bib249)) | 使用端到端训练的多流 CNN 检测结节，每个候选有 9 个补丁 |'
- en: '| Shen et al. ([2016](#bib.bib255)) | 3D CNN classifies volume centered on
    nodule as benign/malignant, results are combined to patient level prediction |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| Shen 等人 ([2016](#bib.bib255)) | 3D CNN 将围绕结节的体积分类为良性/恶性，结果合并到患者级别预测 |'
- en: '| Sun et al. ([2016b](#bib.bib280)) | Same dataset as Shen et al. ([2015b](#bib.bib256)),
    compares CNN, DBN, SDAE and classical computer-aided diagnosis schemes |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| Sun 等人 ([2016b](#bib.bib280)) | 使用与 Shen 等人 ([2015b](#bib.bib256)) 相同的数据集，比较
    CNN、DBN、SDAE 和经典计算机辅助诊断方案 |'
- en: '| Teramoto et al. ([2016](#bib.bib289)) | Combines features extracted from
    2 orthogonal CT patches and a PET patch |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| Teramoto 等人 ([2016](#bib.bib289)) | 结合从两个正交 CT 补丁和一个 PET 补丁中提取的特征 |'
- en: '| Interstitial lung disease |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 间质性肺疾病 |'
- en: '| Anthimopoulos et al. ([2016](#bib.bib10)) | Classification of 2D patches
    into interstitial lung texture classes using a standard CNN |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| Anthimopoulos 等人 ([2016](#bib.bib10)) | 使用标准 CNN 将 2D 补丁分类为间质性肺纹理类别 |'
- en: '| Christodoulidis et al. ([2017](#bib.bib64)) | 2D interstitial pattern classification
    with CNNs pre-trained with a variety of texture data sets |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| Christodoulidis 等人 ([2017](#bib.bib64)) | 使用预训练的 CNN 进行 2D 间质模式分类，训练数据集包含多种纹理数据
    |'
- en: '| Gao et al. ([2016c](#bib.bib102)) | Propagates manually drawn segmentations
    using CNN and CRF for more accurate interstitial lung disease reference |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| Gao 等人 ([2016c](#bib.bib102)) | 使用 CNN 和 CRF 传播手动绘制的分割以获得更准确的间质性肺疾病参考 |'
- en: '| Gao et al. ([2016a](#bib.bib100)) | AlexNet applied to large parts of 2D
    CT slices to detect presence of interstitial patterns |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| Gao 等人 ([2016a](#bib.bib100)) | 将 AlexNet 应用于大范围的 2D CT 切片以检测间质模式的存在 |'
- en: '| Gao et al. ([2016b](#bib.bib101)) | Uses regression to predict area covered
    in 2D slice with a particular interstitial pattern |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| Gao 等人 ([2016b](#bib.bib101)) | 使用回归预测特定间质模式在 2D 切片中覆盖的区域 |'
- en: '| Tarando et al. ([2016](#bib.bib287)) | Combines existing computer-aided diagnosis
    system and CNN to classify lung texture patterns. |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| Tarando 等人 ([2016](#bib.bib287)) | 结合现有的计算机辅助诊断系统和 CNN 对肺纹理模式进行分类。'
- en: '| van Tulder and de Bruijne ([2016](#bib.bib297)) | Classification of lung
    texture and airways using an optimal set of filters derived from DBNs and RBMs
    |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| van Tulder 和 de Bruijne ([2016](#bib.bib297)) | 使用从 DBNs 和 RBMs 导出的最佳滤波器集对肺纹理和气道进行分类
    |'
- en: '| Other applications |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| 其他应用 |'
- en: '| Tajbakhsh et al. ([2015a](#bib.bib284)) | Multi-stream CNN to detect pulmonary
    embolism from candidates obtained from a tobogganing algorithm |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| Tajbakhsh 等人 ([2015a](#bib.bib284)) | 多流 CNN 用于检测从滑雪算法获得的肺栓塞候选区域 |'
- en: '| Carneiro et al. ([2016](#bib.bib44)) | Predicts 5-year mortality from thick
    slice CT scans and segmentation masks |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| Carneiro 等人 ([2016](#bib.bib44)) | 从厚切 CT 扫描和分割掩膜中预测 5 年死亡率 |'
- en: '| de Vos et al. ([2016a](#bib.bib77)) | Identifies the slice of interest and
    determine the distance between CT slices |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| de Vos 等人 ([2016a](#bib.bib77)) | 识别感兴趣的切片并确定 CT 切片之间的距离 |'
- en: 4.2 Eye
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 眼科
- en: 'Ophthalmic imaging has developed rapidly over the past years, but only recently
    are deep learning algorithms being applied to eye image understanding. As summarized
    in Table [2](#S3.T2 "Table 2 ‣ 3.5.2 Image Generation and Enhancement ‣ 3.5 Other
    tasks in medical imaging ‣ 3 Deep Learning Uses in Medical Imaging ‣ A Survey
    on Deep Learning in Medical Image Analysis"), most works employ simple CNNs for
    the analysis of color fundus imaging (CFI). A wide variety of applications are
    addressed: segmentation of anatomical structures, segmentation and detection of
    retinal abnormalities, diagnosis of eye diseases, and image quality assessment.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 眼科影像学在过去几年中迅速发展，但直到最近，深度学习算法才被应用于眼部图像理解。如表[2](#S3.T2 "Table 2 ‣ 3.5.2 Image
    Generation and Enhancement ‣ 3.5 Other tasks in medical imaging ‣ 3 Deep Learning
    Uses in Medical Imaging ‣ A Survey on Deep Learning in Medical Image Analysis")所总结，大多数工作使用简单的
    CNN 来分析彩色视网膜影像 (CFI)。解决了各种应用问题：解剖结构分割、视网膜异常的分割和检测、眼科疾病诊断以及图像质量评估。
- en: 'In 2015, Kaggle organized a diabetic retinopathy detection competition: Over
    35,000 color fundus images were provided to train algorithms to predict the severity
    of disease in 53,000 test images. The majority of the 661 teams that entered the
    competition applied deep learning and four teams achieved performance above that
    of humans, all using end-to-end CNNs. Recently Gulshan et al. ([2016](#bib.bib115))
    performed a thorough analysis of the performance of a Google Inception v3 network
    for diabetic retinopathy detection, showing performance comparable to a panel
    of seven certified ophthalmologists.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 2015年，Kaggle 组织了一次糖尿病视网膜病变检测竞赛：提供了超过 35,000 张彩色视网膜图像，用于训练算法预测 53,000 张测试图像中的疾病严重程度。参加比赛的
    661 支队伍中大多数应用了深度学习，有四支队伍的表现超过了人类水平，所有队伍均使用了端到端的 CNN。最近，Gulshan 等人 ([2016](#bib.bib115))
    对 Google Inception v3 网络在糖尿病视网膜病变检测中的表现进行了彻底分析，结果显示其表现与七名认证眼科医生的表现相当。
- en: 'Table 5: Overview of papers using deep learning for digital pathology images.
    The staining and imaging modality abbreviations used in the table are as follows:
    H&E: hematoxylin and eosin staining, TIL: Tumor-infiltrating lymphocytes, BCC:
    Basal cell carcinoma, IHC: immunohistochemistry, RM: Romanowsky, EM: Electron
    microscopy, PC: Phase contrast, FL: Fluorescent, IFL: Immunofluorescent, TPM:
    Two-photon microscopy, CM: Confocal microscopy, Pap: Papanicolaou.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：使用深度学习技术处理数字病理图像的论文概述。表中使用的染色和成像模态缩写如下：H&E：苏木精-伊红染色，TIL：肿瘤浸润淋巴细胞，BCC：基底细胞癌，IHC：免疫组织化学，RM：罗马诺夫斯基，EM：电子显微镜，PC：相位对比，FL：荧光，IFL：免疫荧光，TPM：双光子显微镜，CM：共聚焦显微镜，Pap：巴氏涂片。
- en: '| Reference | Topic | Staining\Modality | Method |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 参考 | 主题 | 染色\模态 | 方法 |'
- en: '| Nucleus detection, segmentation, and classification |  |  |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 细胞核检测、分割和分类 |  |  |'
- en: '| Cireşan et al. ([2013](#bib.bib69)) | Mitosis detection | H&E | CNN-based
    pixel classifier |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| Cireşan et al. ([2013](#bib.bib69)) | 有丝分裂检测 | H&E | 基于CNN的像素分类器 |'
- en: '| Cruz-Roa et al. ([2013](#bib.bib74)) | Detection of basal cell carcinoma
    | H&E | Convolutional auto-encoder neural network |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| Cruz-Roa et al. ([2013](#bib.bib74)) | 基底细胞癌检测 | H&E | 卷积自编码神经网络 |'
- en: '| Malon and Cosatto ([2013](#bib.bib186)) | Mitosis detection | H&E | Combines
    shape‑based features with CNN |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| Malon and Cosatto ([2013](#bib.bib186)) | 有丝分裂检测 | H&E | 结合基于形状的特征与CNN |'
- en: '| Wang et al. ([2014](#bib.bib305)) | Mitosis detection | H&E | Cascaded ensemble
    of CNN and handcrafted features |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| Wang et al. ([2014](#bib.bib305)) | 有丝分裂检测 | H&E | CNN和手工特征的级联集成 |'
- en: '| Ferrari et al. ([2015](#bib.bib92)) | Bacterial colony counting | Culture
    plate | CNN-based patch classifier |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| Ferrari et al. ([2015](#bib.bib92)) | 细菌菌落计数 | 培养皿 | 基于CNN的图像块分类器 |'
- en: '| Ronneberger et al. ([2015](#bib.bib232)) | Cell segmentation | EM | U-Net
    with deformation augmentation |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| Ronneberger et al. ([2015](#bib.bib232)) | 细胞分割 | EM | 带有形变增强的U-Net |'
- en: '| Shkolyar et al. ([2015](#bib.bib262)) | Mitosis detection | Live-imaging
    | CNN-based patch classifier |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| Shkolyar et al. ([2015](#bib.bib262)) | 有丝分裂检测 | 实时成像 | 基于CNN的图像块分类器 |'
- en: '| Song et al. ([2015](#bib.bib269)) | Segmentation of cytoplasm and nuclei
    | H&E | Multi-scale CNN and graph-partitioning-based method |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| Song et al. ([2015](#bib.bib269)) | 胞质和细胞核分割 | H&E | 多尺度CNN和图分割方法 |'
- en: '| Xie et al. ([2015a](#bib.bib315)) | Nucleus detection | Ki-67 | CNN model
    that learns the voting offset vectors and voting confidence |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| Xie et al. ([2015a](#bib.bib315)) | 细胞核检测 | Ki-67 | 学习投票偏移向量和投票置信度的CNN模型
    |'
- en: '| Xie et al. ([2015b](#bib.bib316)) | Nucleus detection | H&E, Ki-67 | CNN-based
    structured regression model for cell detection |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| Xie et al. ([2015b](#bib.bib316)) | 细胞核检测 | H&E, Ki-67 | 基于CNN的结构回归模型用于细胞检测
    |'
- en: '| Akram et al. ([2016](#bib.bib3)) | Cell segmentation | FL, PC, H&E | fCNN
    for cell bounding box proposal and CNN for segmentation |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| Akram et al. ([2016](#bib.bib3)) | 细胞分割 | FL, PC, H&E | 用于细胞边界框提议的fCNN和用于分割的CNN
    |'
- en: '| Albarqouni et al. ([2016](#bib.bib6)) | Mitosis detection | H&E | Incorporated
    ‘crowd sourcing’ layer into the CNN framework |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| Albarqouni et al. ([2016](#bib.bib6)) | 有丝分裂检测 | H&E | 将‘众包’层融入CNN框架 |'
- en: '| Bauer et al. ([2016](#bib.bib23)) | Nucleus classification | IHC | CNN-based
    patch classifier |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| Bauer et al. ([2016](#bib.bib23)) | 细胞核分类 | IHC | 基于CNN的图像块分类器 |'
- en: '| Chen et al. ([2016b](#bib.bib53)) | Mitosis detection | H&E | Deep regression
    network (DRN) |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| Chen et al. ([2016b](#bib.bib53)) | 有丝分裂检测 | H&E | 深度回归网络（DRN） |'
- en: '| Gao et al. ([2016e](#bib.bib105)) | Nucleus classification | IFL | Classification
    of Hep2-cells with CNN |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| Gao et al. ([2016e](#bib.bib105)) | 细胞核分类 | IFL | 使用CNN的Hep2细胞分类 |'
- en: '| Han et al. ([2016](#bib.bib120)) | Nucleus classification | IFL | Classification
    of Hep2-cells with CNN |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| Han et al. ([2016](#bib.bib120)) | 细胞核分类 | IFL | 使用CNN的Hep2细胞分类 |'
- en: '| Janowczyk et al. ([2016b](#bib.bib141)) | Nucleus segmentation | H&E | Resolution
    adaptive deep hierarchical learning scheme |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| Janowczyk et al. ([2016b](#bib.bib141)) | 细胞核分割 | H&E | 分辨率自适应深度层次学习方案 |'
- en: '| Kashif et al. ([2016](#bib.bib150)) | Nucleus detection | H&E | Combination
    of CNN and hand-crafted features |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| Kashif et al. ([2016](#bib.bib150)) | 细胞核检测 | H&E | CNN与手工特征的结合 |'
- en: '| Mao and Yin ([2016](#bib.bib189)) | Mitosis detection | PC | Hierarchical
    CNNs for patch sequence classification |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| Mao and Yin ([2016](#bib.bib189)) | 有丝分裂检测 | PC | 用于图像块序列分类的层次CNN |'
- en: '| Mishra et al. ([2016](#bib.bib195)) | Classification of mitochondria | EM
    | CNN-based patch classifier |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| Mishra et al. ([2016](#bib.bib195)) | 线粒体分类 | EM | 基于CNN的图像块分类器 |'
- en: '| Phan et al. ([2016](#bib.bib215)) | Nucleus classification | FL | Classification
    of Hep2-cells using transfer learning (pre-trained CNN) |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| Phan 等人 ([2016](#bib.bib215)) | 核分类 | FL | 使用迁移学习（预训练 CNN）的 Hep2 细胞分类 |'
- en: '| Romo-Bucheli et al. ([2016](#bib.bib231)) | Tubule nuclei detection | H&E
    | CNN-based classification of pre-selected candidate nuclei |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| Romo-Bucheli 等人 ([2016](#bib.bib231)) | 管状核检测 | H&E | 基于 CNN 的预选候选核分类 |'
- en: '| Sirinukunwattana et al. ([2016](#bib.bib265)) | Nucleus detection and classification
    | H&E | CNN with spatially constrained regression |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| Sirinukunwattana 等人 ([2016](#bib.bib265)) | 核检测和分类 | H&E | 带有空间约束回归的 CNN
    |'
- en: '| Song et al. ([2017](#bib.bib268)) | Cell segmentation | H&E | Multi-scale
    CNN |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| Song 等人 ([2017](#bib.bib268)) | 细胞分割 | H&E | 多尺度 CNN |'
- en: '| Turkki et al. ([2016](#bib.bib292)) | TIL detection | H&E | CNN-based classification
    of superpixels |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| Turkki 等人 ([2016](#bib.bib292)) | TIL 检测 | H&E | 基于 CNN 的超像素分类 |'
- en: '| Veta et al. ([2016](#bib.bib298)) | Nuclear area measurement | H&E | A CNN
    directly measures nucleus area without requiring segmentation |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| Veta 等人 ([2016](#bib.bib298)) | 核面积测量 | H&E | CNN 直接测量细胞核面积，无需分割 |'
- en: '| Wang et al. ([2016d](#bib.bib308)) | Subtype cell detection | H&E | Combination
    of two CNNs for joint cell detection and classification |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等人 ([2016d](#bib.bib308)) | 亚型细胞检测 | H&E | 两个 CNN 结合用于联合细胞检测和分类 |'
- en: '| Xie et al. ([2016a](#bib.bib314)) | Nucleus detection and cell counting |
    FL and H&E | Microscopy cell counting with fully convolutional regression networks
    |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| Xie 等人 ([2016a](#bib.bib314)) | 核检测和细胞计数 | FL 和 H&E | 使用全卷积回归网络的显微镜细胞计数 |'
- en: '| Xing et al. ([2016](#bib.bib318)) | Nucleus segmentation | H&E, IHC | CNN
    and selection-based sparse shape model |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| Xing 等人 ([2016](#bib.bib318)) | 核分割 | H&E, IHC | CNN 和基于选择的稀疏形状模型 |'
- en: '| Xu et al. ([2016b](#bib.bib320)) | Nucleus detection | H&E | Stacked sparse
    auto-encoders (SSAE) |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| Xu 等人 ([2016b](#bib.bib320)) | 核检测 | H&E | 堆叠稀疏自编码器 (SSAE) |'
- en: '| Xu and Huang ([2016](#bib.bib324)) | Nucleus detection | Various | General
    deep learning framework to detect cells in whole-slide images |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| Xu 和 Huang ([2016](#bib.bib324)) | 核检测 | 各种 | 通用深度学习框架用于检测全切片图像中的细胞 |'
- en: '| Yang et al. ([2016b](#bib.bib329)) | Glial cell segmentation | TPM | fCNN
    with an iterative k-terminal cut algorithm |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| Yang 等人 ([2016b](#bib.bib329)) | 胶质细胞分割 | TPM | 带有迭代 k-terminal cut 算法的 fCNN
    |'
- en: '| Yao et al. ([2016](#bib.bib332)) | Nucleus classification | H&E | Classifies
    cellular tissue into tumor, lymphocyte, and stromal |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| Yao 等人 ([2016](#bib.bib332)) | 核分类 | H&E | 将细胞组织分类为肿瘤、淋巴细胞和基质 |'
- en: '| Zhao et al. ([2016](#bib.bib344)) | Classification of leukocytes | RM | CNN-based
    patch classifier |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| Zhao 等人 ([2016](#bib.bib344)) | 白细胞分类 | RM | 基于 CNN 的补丁分类器 |'
- en: '| Large organ segmentation |  |  |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| 大型器官分割 |  |  |'
- en: '| Ciresan et al. ([2012](#bib.bib70)) | Segmentation of neuronal membranes
    | EM | Ensemble of several CNNs with different architectures |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| Ciresan 等人 ([2012](#bib.bib70)) | 神经膜分割 | EM | 多种架构的 CNN 集成 |'
- en: '| Kainz et al. ([2015](#bib.bib145)) | Segmentation of colon glands | H&E |
    Used two CNNs to segment glands and their separating structures |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| Kainz 等人 ([2015](#bib.bib145)) | 结肠腺体分割 | H&E | 使用两个 CNN 分割腺体及其分隔结构 |'
- en: '| Apou et al. ([2016](#bib.bib12)) | Detection of lobular structures in breast
    | IHC | Combined the outputs of a CNN and a texture classification system |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| Apou 等人 ([2016](#bib.bib12)) | 乳腺小叶结构检测 | IHC | 结合了 CNN 和纹理分类系统的输出 |'
- en: '| BenTaieb and Hamarneh ([2016](#bib.bib31)) | Segmentation of colon glands
    | H&E | fCNN with a loss accounting for smoothness and object interactions |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| BenTaieb 和 Hamarneh ([2016](#bib.bib31)) | 结肠腺体分割 | H&E | 带有平滑性和对象交互损失的 fCNN
    |'
- en: '| BenTaieb et al. ([2016](#bib.bib32)) | Segmentation of colon glands | H&E
    | A multi-loss fCNN to perform both segmentation and classification |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| BenTaieb 等人 ([2016](#bib.bib32)) | 结肠腺体分割 | H&E | 多损失 fCNN 同时执行分割和分类 |'
- en: '| Chen et al. ([2016d](#bib.bib55)) | Neuronal membrane and fungus segmentation
    | EM | Combination of bi-directional LSTM-RNNs and kU-Nets |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人 ([2016d](#bib.bib55)) | 神经膜和真菌分割 | EM | 双向 LSTM-RNNs 和 kU-Nets 的结合
    |'
- en: '| Chen et al. ([2017](#bib.bib51)) | Segmentation of colon glands | H&E | Deep
    contour-aware CNN |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人 ([2017](#bib.bib51)) | 结肠腺体分割 | H&E | 深度轮廓感知 CNN |'
- en: '| Çiçek et al. ([2016](#bib.bib65)) | Segmentation of xenopus kidney | CM |
    3D U-Net |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| Çiçek 等人 ([2016](#bib.bib65)) | 非洲爪蟾肾脏分割 | CM | 3D U-Net |'
- en: '| Drozdzal et al. ([2016](#bib.bib85)) | Segmentation of neuronal structures
    | EM | fCNN with skip connections |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| Drozdzal 等人 ([2016](#bib.bib85)) | 神经结构分割 | EM | 带有跳跃连接的 fCNN |'
- en: '| Li et al. ([2016b](#bib.bib173)) | Segmentation of colon glands | H&E | Compares
    CNN with an SVM using hand-crafted features |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| Li等人 ([2016b](#bib.bib173)) | 结肠腺体的分割 | H&E | 比较CNN与使用手工特征的SVM |'
- en: '| Teikari et al. ([2016](#bib.bib288)) | Volumetric vascular segmentation |
    FL | Hybrid 2D-3D CNN architecture |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| Teikari等人 ([2016](#bib.bib288)) | 体积血管分割 | FL | 混合2D-3D CNN架构 |'
- en: '| Wang et al. ([2016c](#bib.bib307)) | Segmentation of messy and muscle regions
    | H&E | Conditional random field jointly trained with an fCNN |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 王等人 ([2016c](#bib.bib307)) | 杂乱和肌肉区域的分割 | H&E | 与fCNN联合训练的条件随机场 |'
- en: '| Xie et al. ([2016b](#bib.bib317)) | Perimysium segmentation | H&E | 2D spatial
    clockwork RNN |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| Xie等人 ([2016b](#bib.bib317)) | 周围肌膜分割 | H&E | 2D空间时钟RNN |'
- en: '| Xu et al. ([2016d](#bib.bib322)) | Segmentation of colon glands | H&E | Used
    three CNNs to predict gland and contour pixels |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 徐等人 ([2016d](#bib.bib322)) | 结肠腺体的分割 | H&E | 使用三个CNN预测腺体和轮廓像素 |'
- en: '| Xu et al. ([2016a](#bib.bib319)) | Segmenting epithelium & stroma | H&E,
    IHC | CNNs applied to over-segmented image regions (superpixels) |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| 徐等人 ([2016a](#bib.bib319)) | 上皮和基质的分割 | H&E, IHC | 应用CNN于过分割的图像区域（超像素） |'
- en: '| Detection and classification of disease |  |  |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| 疾病检测与分类 |  |  |'
- en: '| Cruz-Roa et al. ([2014](#bib.bib73)) | Detection of invasive ductal carcinoma
    | H&E | CNN-based patch classifier |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| Cruz-Roa等人 ([2014](#bib.bib73)) | 入侵性导管癌检测 | H&E | 基于CNN的补丁分类器 |'
- en: '| Xu et al. ([2014](#bib.bib323)) | Patch-level classification of colon cancer
    | H&E | Multiple instance learning framework with CNN features |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| 徐等人 ([2014](#bib.bib323)) | 结肠癌的补丁级分类 | H&E | 使用CNN特征的多实例学习框架 |'
- en: '| Bychkov et al. ([2016](#bib.bib39)) | Outcome prediction of colorectal cancer
    | H&E | Extracted CNN features from epithelial tissue for prediction |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| Bychkov等人 ([2016](#bib.bib39)) | 结直肠癌预后预测 | H&E | 从上皮组织中提取CNN特征进行预测 |'
- en: '| Chang et al. ([2017](#bib.bib46)) | Multiple cancer tissue classification
    | Various | Transfer learning using multi-Scale convolutional sparse coding |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| Chang等人 ([2017](#bib.bib46)) | 多种癌症组织分类 | 各种 | 使用多尺度卷积稀疏编码的迁移学习 |'
- en: '| Günhan Ertosun and Rubin ([2015](#bib.bib117)) | Grading glioma | H&E | Ensemble
    of CNNs |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| Günhan Ertosun和Rubin ([2015](#bib.bib117)) | 胶质瘤分级 | H&E | CNN集成 |'
- en: '| Källén et al. ([2016](#bib.bib146)) | Predicting Gleason score | H&E | OverFeat
    pre-trained network as feature extractor |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| Källén等人 ([2016](#bib.bib146)) | 预测Gleason评分 | H&E | 使用OverFeat预训练网络作为特征提取器
    |'
- en: '| Kim et al. ([2016a](#bib.bib155)) | Thyroid cytopathology classification
    | H&E, RM & Pap | Fine-tuning pre-trained AlexNet |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| Kim等人 ([2016a](#bib.bib155)) | 甲状腺细胞病理分类 | H&E, RM & Pap | 微调预训练的AlexNet
    |'
- en: '| Litjens et al. ([2016](#bib.bib176)) | Detection of prostate and breast cancer
    | H&E | fCNN-based pixel classifier |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| Litjens等人 ([2016](#bib.bib176)) | 前列腺和乳腺癌检测 | H&E | 基于fCNN的像素分类器 |'
- en: '| Quinn et al. ([2016](#bib.bib223)) | Malaria, tuberculosis and parasites
    detection | Light microscopy | CNN-based patch classifier |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| Quinn等人 ([2016](#bib.bib223)) | 疟疾、结核和寄生虫检测 | 光学显微镜 | 基于CNN的补丁分类器 |'
- en: '| Rezaeilouyeh et al. ([2016](#bib.bib230)) | Gleason grading and breast cancer
    detection | H&E | The system incorporates shearlet features inside a CNN |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| Rezaeilouyeh等人 ([2016](#bib.bib230)) | Gleason分级和乳腺癌检测 | H&E | 系统将剪切波特征融入CNN中
    |'
- en: '| Schaumberg et al. ([2016](#bib.bib246)) | SPOP mutation prediction of prostate
    cancer | H&E | Ensemble of ResNets |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| Schaumberg等人 ([2016](#bib.bib246)) | 前列腺癌SPOP突变预测 | H&E | ResNets集成 |'
- en: '| Wang et al. ([2016b](#bib.bib303)) | Metastases detection in lymph node |
    H&E | Ensemble of CNNs with hard negative mining |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| 王等人 ([2016b](#bib.bib303)) | 淋巴结中的转移检测 | H&E | 结合硬负样本挖掘的CNN集成 |'
- en: '| Other pathology applications |  |  |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| 其他病理应用 |  |  |'
- en: '| Janowczyk et al. ([2016a](#bib.bib140)) | Stain normalization | H&E | Used
    SAE for classifying tissue and subsequent histogram matching |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| Janowczyk等人 ([2016a](#bib.bib140)) | 染色标准化 | H&E | 使用SAE进行组织分类和后续直方图匹配 |'
- en: '| Janowczyk and Madabhushi ([2016](#bib.bib142)) | Deep learning tutorial |
    Various | Covers different detecting, segmentation, and classification tasks |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| Janowczyk和Madabhushi ([2016](#bib.bib142)) | 深度学习教程 | 各种 | 涵盖不同的检测、分割和分类任务
    |'
- en: '| Sethi et al. ([2016](#bib.bib248)) | Comparison of normalization algorithms
    | H&E | Presents effectiveness of stain normalization for application of CNNs
    |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| Sethi等人 ([2016](#bib.bib248)) | 标准化算法的比较 | H&E | 展示染色标准化在CNN应用中的效果 |'
- en: 4.3 Chest
  id: totrans-384
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 胸部
- en: In thoracic image analysis of both radiography and computed tomography, the
    detection, characterization, and classification of nodules is the most commonly
    addressed application. Many works add features derived from deep networks to existing
    feature sets or compare CNNs with classical machine learning approaches using
    handcrafted features. In chest X-ray, several groups detect multiple diseases
    with a single system. In CT the detection of textural patterns indicative of interstitial
    lung diseases is also a popular research topic.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 在胸部影像分析中，无论是放射摄影还是计算机断层扫描，结节的检测、特征描述和分类都是最常涉及的应用。许多研究在现有特征集上增加了从深度网络中提取的特征，或将卷积神经网络（CNN）与使用手工特征的经典机器学习方法进行比较。在胸部
    X 光中，一些团队使用单一系统检测多种疾病。在计算机断层扫描（CT）中，检测表明间质性肺病的纹理模式也是一个热门的研究主题。
- en: Chest radiography is the most common radiological exam; several works use a
    large set of images with text reports to train systems that combine CNNs for image
    analysis and RNNs for text analysis. This is a branch of research we expect to
    see more of in the near future.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 胸部放射摄影是最常见的放射检查；一些研究使用大量的图像和文本报告来训练结合 CNN 的图像分析系统和 RNN 的文本分析系统。这是我们预计在不久的将来会看到更多的研究方向。
- en: 'In a recent challenge for nodule detection in CT, LUNA16, CNN architectures
    were used by all top performing systems. This is in contrast with a previous lung
    nodule detection challenge, ANODE09, where handcrafted features were used to classify
    nodule candidates. The best systems in LUNA16 still rely on nodule candidates
    computed by rule-based image processing, but systems that use deep networks for
    candidate detection also performed very well (e.g. U-net). Estimating the probability
    that an individual has lung cancer from a CT scan is an important topic: It is
    the objective of the Kaggle Data Science Bowl 2017, with $1 million in prizes
    and more than one thousand participating teams.'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近的 CT 结节检测挑战赛 LUNA16 中，所有表现最好的系统都使用了 CNN 架构。这与之前的肺结节检测挑战赛 ANODE09 相比有所不同，在
    ANODE09 中，使用了手工特征来分类结节候选体。LUNA16 中表现最好的系统仍然依赖于基于规则的图像处理计算的结节候选体，但使用深度网络进行候选体检测的系统也表现得非常好（例如
    U-net）。从 CT 扫描中估计个体是否患有肺癌是一个重要的话题：这是 Kaggle 数据科学大赛 2017 的目标，奖金高达 100 万美元，参赛团队超过一千个。
- en: 'Table 6: Overview of papers using deep learning techniques for breast image
    analysis. MG = mammography; TS = tomosynthesis; US = ultrasound; ADN = Adaptive
    Deconvolution Network.'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：使用深度学习技术进行乳腺影像分析的文献概览。MG = 乳腺摄影；TS = 断层合成；US = 超声；ADN = 自适应去卷积网络。
- en: '| Reference | Modality | Method | Application; remarks |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 模态 | 方法 | 应用；备注 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Sahiner et al. ([1996](#bib.bib242)) | MG | CNN | First application of a
    CNN to mammography |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| Sahiner 等 ([1996](#bib.bib242)) | MG | CNN | 首次将 CNN 应用于乳腺摄影 |'
- en: '| Jamieson et al. ([2012](#bib.bib139)) | MG, US | ADN | Four layer ADN, an
    early form of CNN for mass classification |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| Jamieson 等 ([2012](#bib.bib139)) | MG, US | ADN | 四层 ADN，早期形式的 CNN 用于肿块分类
    |'
- en: '| Fonseca et al. ([2015](#bib.bib93)) | MG | CNN | Pre-trained network extracted
    features classified with SVM for breast density estimation |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| Fonseca 等 ([2015](#bib.bib93)) | MG | CNN | 预训练网络提取的特征通过 SVM 分类用于乳腺密度估计 |'
- en: '| Akselrod-Ballin et al. ([2016](#bib.bib4)) | MG | CNN | Use a modified region
    proposal CNN (R-CNN) for the localization and classification of masses |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| Akselrod-Ballin 等 ([2016](#bib.bib4)) | MG | CNN | 使用修改过的区域提议 CNN (R-CNN)
    进行肿块的定位和分类 |'
- en: '| Arevalo et al. ([2016](#bib.bib13)) | MG | CNN | Lesion classification, combination
    with hand-crafted features gave the best performance |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| Arevalo 等 ([2016](#bib.bib13)) | MG | CNN | 病变分类，与手工特征的结合表现最好 |'
- en: '| Dalmis et al. ([2017](#bib.bib75)) | MRI | CNN | Breast and fibroglandular
    tissue segmentation |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| Dalmis 等 ([2017](#bib.bib75)) | MRI | CNN | 乳腺和纤维腺组织分割 |'
- en: '| Dubrovina et al. ([2016](#bib.bib86)) | MG | CNN | Tissue classification
    using regular CNNs |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| Dubrovina 等 ([2016](#bib.bib86)) | MG | CNN | 使用常规 CNN 进行组织分类 |'
- en: '| Dhungel et al. ([2016](#bib.bib80)) | MG | CNN | Combination of different
    CNNs combined with hand-crafted features |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| Dhungel 等 ([2016](#bib.bib80)) | MG | CNN | 结合不同的 CNN 和手工特征的组合 |'
- en: '| Fotin et al. ([2016](#bib.bib95)) | TS | CNN | Improved state-of-the art
    for mass detection in tomosynthesis |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| Fotin 等 ([2016](#bib.bib95)) | TS | CNN | 改进的前沿技术用于断层合成中的肿块检测 |'
- en: '| Hwang and Kim ([2016](#bib.bib136)) | MG | CNN | Weakly supervised CNN for
    localization of masses |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| Hwang 和 Kim ([2016](#bib.bib136)) | MG | CNN | 用于肿块定位的弱监督 CNN |'
- en: '| Huynh et al. ([2016](#bib.bib135)) | MG | CNN | Pre-trained CNN on natural
    image patches applied to mass classification |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| Huynh 等 ([2016](#bib.bib135)) | MG | CNN | 预训练 CNN 在自然图像块上应用于肿块分类 |'
- en: '| Kallenberg et al. ([2016](#bib.bib147)) | MG | SAE | Unsupervised CNN feature
    learning with SAE for breast density classification |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| Kallenberg 等 ([2016](#bib.bib147)) | MG | SAE | 无监督 CNN 特征学习与 SAE 结合用于乳腺密度分类
    |'
- en: '| Kisilev et al. ([2016](#bib.bib159)) | MG | CNN | R-CNN combined with multi-class
    loss trained on semantic descriptions of potential masses |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| Kisilev 等 ([2016](#bib.bib159)) | MG | CNN | 结合多类损失的 R-CNN 训练于潜在肿块的语义描述 |'
- en: '| Kooi et al. ([2016](#bib.bib162)) | MG | CNN | Improved the state-of-the
    art for mass detection and show human performance on a patch level |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| Kooi 等 ([2016](#bib.bib162)) | MG | CNN | 改进了肿块检测的最先进技术，并在图像块级别展示了人类表现 |'
- en: '| Qiu et al. ([2016](#bib.bib222)) | MG | CNN | CNN for direct classification
    of future risk of developing cancer based on negative mammograms |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| Qiu 等 ([2016](#bib.bib222)) | MG | CNN | 基于负乳腺 X 光图像的未来癌症风险直接分类 CNN |'
- en: '| Samala et al. ([2016a](#bib.bib243)) | TS | CNN | Microcalcification detection
    |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| Samala 等 ([2016a](#bib.bib243)) | TS | CNN | 微钙化检测 |'
- en: '| Samala et al. ([2016b](#bib.bib244)) | TS | CNN | Pre-trained CNN on mammographic
    masses transfered to tomosynthesis |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| Samala 等 ([2016b](#bib.bib244)) | TS | CNN | 预训练 CNN 在乳腺 X 光图像上的迁移应用于断层合成
    |'
- en: '| Sun et al. ([2016a](#bib.bib279)) | MG | CNN | Semi-supervised CNN for classification
    of masses |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| Sun 等 ([2016a](#bib.bib279)) | MG | CNN | 半监督 CNN 用于肿块分类 |'
- en: '| Zhang et al. ([2016c](#bib.bib341)) | US | RBM | Classification benign vs.
    malignant with shear wave elastography |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| Zhang 等 ([2016c](#bib.bib341)) | US | RBM | 利用剪切波弹性成像进行良恶性分类 |'
- en: '| Kooi et al. ([2017](#bib.bib163)) | MG | CNN | Pre-trained CNN on mass/normal
    patches to discriminate malignant masses from (benign) cysts |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| Kooi 等 ([2017](#bib.bib163)) | MG | CNN | 预训练 CNN 用于在肿块/正常图像上区分恶性肿块和（良性）囊肿
    |'
- en: '| Wang et al. ([2017](#bib.bib306)) | MG | CNN | Detection of cardiovascular
    disease based on vessel calcification |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等 ([2017](#bib.bib306)) | MG | CNN | 基于血管钙化的心血管疾病检测 |'
- en: 4.4 Digital pathology and microscopy
  id: totrans-412
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 数字病理学和显微镜
- en: 'The growing availability of large scale gigapixel whole-slide images (WSI)
    of tissue specimen has made digital pathology and microscopy a very popular application
    area for deep learning techniques. The developed techniques applied to this domain
    focus on three broad challenges: (1) Detecting, segmenting, or classifying nuclei,
    (2) segmentation of large organs, and (3) detecting and classifying the disease
    of interest at the lesion- or WSI-level. Table [5](#S4.T5 "Table 5 ‣ 4.2 Eye ‣
    4 Anatomical application areas ‣ A Survey on Deep Learning in Medical Image Analysis")
    presents an overview for each of these categories.'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模千兆像素全切片图像（WSI）的日益可用性使得数字病理学和显微镜成为深度学习技术的热门应用领域。应用于该领域的技术集中在三个广泛的挑战上：（1）检测、分割或分类细胞核，（2）大器官的分割，以及（3）在病变或
    WSI 级别检测和分类感兴趣的疾病。表 [5](#S4.T5 "Table 5 ‣ 4.2 Eye ‣ 4 Anatomical application areas
    ‣ A Survey on Deep Learning in Medical Image Analysis") 提供了每个类别的概述。
- en: Deep learning techniques have also been applied for normalization of histopathology
    images. Color normalization is an important research area in histopathology image
    analysis. In Janowczyk et al. ([2016a](#bib.bib140)), a method for stain normalization
    of hematoxylin and eosin (H&E) stained histopathology images was presented based
    on deep sparse auto-encoders. Recently, the importance of color normalization
    was demonstrated by Sethi et al. ([2016](#bib.bib248)) for CNN based tissue classification
    in H&E stained images.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习技术还被应用于组织病理图像的标准化。颜色标准化是组织病理图像分析中的一个重要研究领域。在 Janowczyk 等 ([2016a](#bib.bib140))
    的研究中，提出了一种基于深度稀疏自编码器的血红素和伊红（H&E）染色组织病理图像的染色标准化方法。最近，Sethi 等 ([2016](#bib.bib248))
    展示了颜色标准化在 H&E 染色图像中的 CNN 基础组织分类中的重要性。
- en: 'The introduction of grand challenges in digital pathology has fostered the
    development of computerized digital pathology techniques. The challenges that
    evaluated existing and new approaches for analysis of digital pathology images
    are: EM segmentation challenge 2012 for the 2D segmentation of neuronal processes,
    mitosis detection challenges in ICPR 2012 and AMIDA 2013, GLAS for gland segmentation
    and, CAMELYON16 and TUPAC for processing breast cancer tissue samples.'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 引入数字病理学中的重大挑战促进了计算机化数字病理学技术的发展。这些挑战评估了现有和新方法在数字病理图像分析中的应用，包括：2012年EM分割挑战，用于2D神经过程的分割，2012年ICPR和2013年AMIDA的有丝分裂检测挑战，GLAS用于腺体分割，以及CAMELYON16和TUPAC用于处理乳腺癌组织样本。
- en: In both ICPR 2012 and the AMIDA13 challenges on mitosis detection the IDSIA
    team outperformed other algorithms with a CNN based approach (Cireşan et al.,
    [2013](#bib.bib69)). The same team had the highest performing system in EM 2012
    (Ciresan et al., [2012](#bib.bib70)) for 2D segmentation of neuronal processes.
    In their approach, the task of segmenting membranes of neurons was performed by
    mild smoothing and thresholding of the output of a CNN, which computes pixel probabilities.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 在ICPR 2012和AMIDA13有丝分裂检测挑战中，IDSIA团队采用基于CNN的方法超越了其他算法（Cireşan et al., [2013](#bib.bib69)）。同一团队在EM
    2012（Ciresan et al., [2012](#bib.bib70)）中在2D神经过程分割方面也拥有最高性能的系统。他们的方法通过对CNN输出进行轻微平滑和阈值处理来分割神经膜，CNN计算像素概率。
- en: GLAS addressed the problem of gland instance segmentation in colorectal cancer
    tissue samples. Xu et al. ([2016d](#bib.bib322)) achieved the highest rank using
    three CNN models. The first CNN classifies pixels as gland versus non-gland. From
    each feature map of the first CNN, edge information is extracted using the holistically
    nested edge technique, which uses side convolutions to produce an edge map. Finally,
    a third CNN merges gland and edge maps to produce the final segmentation.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: GLAS解决了结直肠癌组织样本中腺体实例分割的问题。Xu et al. ([2016d](#bib.bib322))使用三个CNN模型取得了最高排名。第一个CNN将像素分类为腺体与非腺体。通过使用全面嵌套边缘技术从第一个CNN的每个特征图中提取边缘信息，该技术使用侧卷积生成边缘图。最后，第三个CNN合并腺体图和边缘图以生成最终分割。
- en: CAMELYON16 was the first challenge to provide participants with WSIs. Contrary
    to other medical imaging applications, the availability of large amount of annotated
    data in this challenge allowed for training very deep models such as 22-layer
    GoogLeNet (Szegedy et al., [2014](#bib.bib282)), 16-layer VGG-Net (Simonyan and
    Zisserman, [2014](#bib.bib264)), and 101-layer ResNet (He et al., [2015](#bib.bib124)).
    The top-five performing systems used one of these architectures. The best performing
    solution in the Camelyon16 challenge was presented in Wang et al. ([2016b](#bib.bib303)).
    This method is based on an ensemble of two GoogLeNet architectures, one trained
    with and one without hard-negative mining to tackle the challenge. The latest
    submission of this team using the WSI standardization algorithm by Ehteshami Bejnordi
    et al. ([2016](#bib.bib87)) achieved an AUC of 0.9935, for task 2, which outperformed
    the AUC of a pathologist (AUC = 0.966) who independently scored the complete test
    set.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: CAMELYON16是第一个向参与者提供WSI的挑战。与其他医学成像应用不同，这个挑战中大量的标注数据使得训练非常深的模型成为可能，如22层的GoogLeNet（Szegedy
    et al., [2014](#bib.bib282)）、16层的VGG-Net（Simonyan and Zisserman, [2014](#bib.bib264)）和101层的ResNet（He
    et al., [2015](#bib.bib124)）。表现最好的五个系统中使用了这些架构之一。Camelyon16挑战中表现最佳的解决方案由Wang et
    al. ([2016b](#bib.bib303))提出。这种方法基于两个GoogLeNet架构的集成，一个使用硬负样本挖掘进行训练，另一个则没有。该团队最新提交的使用WSI标准化算法的结果（Ehteshami
    Bejnordi et al., [2016](#bib.bib87)）在任务2中的AUC达到了0.9935，超过了独立评分完整测试集的病理学家（AUC =
    0.966）的AUC。
- en: 'The recently held TUPAC challenge addressed detection of mitosis in breast
    cancer tissue, and prediction of tumor grading at the WSI level. The top performing
    system by Paeng et al. ([2016](#bib.bib210)) achieved the highest performance
    in all tasks. The method has three main components: (1) Finding high cell density
    regions, (2) using a CNN to detect mitoses in the regions of interest, (3) converting
    the results of mitosis detection to a feature vector for each WSI and using an
    SVM classifier to compute the tumor proliferation and molecular data scores.'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 最近举行的 TUPAC 挑战解决了乳腺癌组织中有丝分裂的检测，并预测了WSI级别的肿瘤分级。由 Paeng 等人（[2016](#bib.bib210)）开发的表现最佳系统在所有任务中表现最好。该方法有三个主要组成部分：（1）查找高细胞密度区域，（2）使用
    CNN 在感兴趣区域检测有丝分裂，（3）将有丝分裂检测结果转换为每个WSI的特征向量，并使用 SVM 分类器计算肿瘤增殖和分子数据分数。
- en: 'Table 7: Overview of papers using deep learning techniques for cardiac image
    analysis.'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：使用深度学习技术进行心脏图像分析的论文概述。
- en: '| Reference | Modality | Method | Application; remarks |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| 参考 | 模态 | 方法 | 应用；备注 |'
- en: '| Emad et al. ([2015](#bib.bib88)) | MRI | CNN | Left ventricle slice detection;
    simple CNN indicates if structure is present |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| Emad 等人（[2015](#bib.bib88)） | MRI | CNN | 左心室切片检测；简单CNN指示结构是否存在 |'
- en: '| Avendi et al. ([2016](#bib.bib15)) | MRI | CNN | Left ventricle segmentation;
    AE used to initialize filters because training data set was small |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| Avendi 等人（[2016](#bib.bib15)） | MRI | CNN | 左心室分割；AE 用于初始化滤波器，因为训练数据集较小 |'
- en: '| Kong et al. ([2016](#bib.bib161)) | MRI | RNN | Identification of end-diastole
    and end-systole frames from cardiac sequences |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| Kong 等人（[2016](#bib.bib161)） | MRI | RNN | 从心脏序列中识别舒张末期和收缩末期帧 |'
- en: '| Oktay et al. ([2016](#bib.bib208)) | MRI | CNN | Super-resolution; U-net/ResNet
    hybrid, compares favorably with standard superresolution methods |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| Oktay 等人（[2016](#bib.bib208)） | MRI | CNN | 超分辨率；U-net/ResNet 混合，与标准超分辨率方法相比具有优势
    |'
- en: '| Poudel et al. ([2016](#bib.bib218)) | MRI | RNN | Left ventricle segmentation;
    RNN processes stack of slices, evaluated on several public datasets |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| Poudel 等人（[2016](#bib.bib218)） | MRI | RNN | 左心室分割；RNN 处理切片堆栈，在多个公共数据集上进行评估
    |'
- en: '| Rupprecht et al. ([2016](#bib.bib240)) | MRI | CNN | Cardiac structure segmentation;
    patch-based CNNs integrated in active contour framework |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| Rupprecht 等人（[2016](#bib.bib240)） | MRI | CNN | 心脏结构分割；基于补丁的CNN集成在活动轮廓框架中
    |'
- en: '| Tran ([2016](#bib.bib291)) | MRI | CNN | Left and right ventricle segmentation;
    2D fCNN architecture, evaluated on several public data sets |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| Tran（[2016](#bib.bib291)） | MRI | CNN | 左右心室分割；2D fCNN 结构，评估了多个公共数据集 |'
- en: '| Yang et al. ([2016a](#bib.bib328)) | MRI | CNN | Left ventricle segmentation;
    CNN combined with multi-atlas segmentation |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| Yang 等人（[2016a](#bib.bib328)） | MRI | CNN | 左心室分割；CNN 结合多阿特拉斯分割 |'
- en: '| Zhang et al. ([2016b](#bib.bib340)) | MRI | CNN | Identifying presence of
    apex and base slices in cardiac exam for quality assessment |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| Zhang 等人（[2016b](#bib.bib340)） | MRI | CNN | 识别心脏检查中顶点和底部切片的存在，用于质量评估 |'
- en: '| Ngo et al. ([2017](#bib.bib203)) | MRI | DBN | Left ventricle segmentation;
    DBN is used to initialize a level set framework |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| Ngo 等人（[2017](#bib.bib203)） | MRI | DBN | 左心室分割；DBN 用于初始化水平集框架 |'
- en: '| Carneiro et al. ([2012](#bib.bib43)) | US | DBN | Left ventricle segmentation;
    DBN embedded in system using landmarks and non-rigid registration |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| Carneiro 等人（[2012](#bib.bib43)） | 美国 | DBN | 左心室分割；DBN嵌入系统中使用地标和非刚性配准 |'
- en: '| Carneiro and Nascimento ([2013](#bib.bib42)) | US | DBN | Left ventricle
    tracking; extension of Carneiro et al. ([2012](#bib.bib43)) for tracking |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| Carneiro 和 Nascimento（[2013](#bib.bib42)） | 美国 | DBN | 左心室跟踪；Carneiro 等人（[2012](#bib.bib43)）的扩展用于跟踪
    |'
- en: '| Chen et al. ([2016c](#bib.bib54)) | US | CNN | Structure segmentation in
    5 different 2D views; uses transfer learning |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人（[2016c](#bib.bib54)） | 美国 | CNN | 在5种不同的2D视图中进行结构分割；采用迁移学习 |'
- en: '| Ghesu et al. ([2016b](#bib.bib110)) | US | CNN | 3D aortic valve detection
    and segmentation; uses shallow and deeper sparse networks |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| Ghesu 等人（[2016b](#bib.bib110)） | 美国 | CNN | 3D 主动脉瓣检测和分割；使用浅层和深层稀疏网络 |'
- en: '| Nascimento and Carneiro ([2016](#bib.bib202)) | US | DBN | Left ventricle
    segmentation; DBN applied to patches steers multi-atlas segmentation process |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| Nascimento 和 Carneiro（[2016](#bib.bib202)） | 美国 | DBN | 左心室分割；DBN 应用于路径指导多阿特拉斯分割过程
    |'
- en: '| Moradi et al. ([2016a](#bib.bib199)) | US | CNN | Automatic generation of
    text descriptions for Doppler US images of cardiac valves using doc2vec |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| Moradi 等人（[2016a](#bib.bib199)） | 美国 | CNN | 使用 doc2vec 自动为心脏瓣膜的多普勒超声图像生成文本描述
    |'
- en: '| Gülsün et al. ([2016](#bib.bib116)) | CT | CNN | Coronary centerline extraction;
    CNN classifies paths as correct or leakages |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| Gülsün 等 ([2016](#bib.bib116)) | CT | CNN | 冠状动脉中心线提取；CNN 分类路径为正确或泄漏 |'
- en: '| Lessmann et al. ([2016](#bib.bib169)) | CT | CNN | Coronary calcium detection
    in low dose ungated CT using multi-stream CNN (3 views) |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| Lessmann 等 ([2016](#bib.bib169)) | CT | CNN | 使用多流 CNN (3 个视角) 在低剂量非门控 CT
    中检测冠状动脉钙 |'
- en: '| Moradi et al. ([2016b](#bib.bib200)) | CT | CNN | Labeling of 2D slices from
    cardiac CT exams; comparison with handcrafted features |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| Moradi 等 ([2016b](#bib.bib200)) | CT | CNN | 标注心脏 CT 检查的 2D 切片；与手工特征比较 |'
- en: '| de Vos et al. ([2016b](#bib.bib78)) | CT | CNN | Detect bounding boxes by
    slice classification and combining 3 orthogonal 2D CNNs |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| de Vos 等 ([2016b](#bib.bib78)) | CT | CNN | 通过切片分类和结合 3 个正交的 2D CNN 检测边界框
    |'
- en: '| Wolterink et al. ([2016](#bib.bib310)) | CT | CNN | Coronary calcium detection
    in gated CTA; compares 3D CNN with multi-stream 2D CNNs |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| Wolterink 等 ([2016](#bib.bib310)) | CT | CNN | 在门控 CTA 中检测冠状动脉钙；比较 3D CNN
    和多流 2D CNN |'
- en: '| Zreik et al. ([2016](#bib.bib350)) | CT | CNN | Left ventricle segmentation;
    multi-stream CNN (3 views) voxel classification |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| Zreik 等 ([2016](#bib.bib350)) | CT | CNN | 左心室分割；多流 CNN (3 个视角) 体素分类 |'
- en: 4.5 Breast
  id: totrans-444
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 乳腺
- en: 'One of the earliest DNN applications from Sahiner et al. ([1996](#bib.bib242))
    was on breast imaging. Recently, interest has returned which resulted in significant
    advances over the state of the art, achieving the performance of human readers
    on ROIs (Kooi et al., [2016](#bib.bib162)). Since most breast imaging techniques
    are two dimensional, methods successful in natural images can easily be transferred.
    With one exception, the only task addressed is the detection of breast cancer;
    this consisted of three subtasks: (1) detection and classification of mass-like
    lesions, (2) detection and classification of micro-calcifications, and (3) breast
    cancer risk scoring of images. Mammography is by far the most common modality
    and has consequently enjoyed the most attention. Work on tomosynthesis, US, and
    shear wave elastography is still scarce, and we have only one paper that analyzed
    breast MRI with deep learning; these other modalities will likely receive more
    attention in the next few years. Table [6](#S4.T6 "Table 6 ‣ 4.3 Chest ‣ 4 Anatomical
    application areas ‣ A Survey on Deep Learning in Medical Image Analysis") summarizes
    the literature and main messages.'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: Sahiner 等 ([1996](#bib.bib242)) 早期的 DNN 应用之一是乳腺成像。最近，兴趣恢复，带来了显著的进展，达到了在感兴趣区域
    (Kooi 等，[2016](#bib.bib162)) 的人类读者性能。由于大多数乳腺成像技术是二维的，因此成功于自然图像的方法可以轻松转移。除了一个例外，唯一处理的任务是乳腺癌检测；这包括三个子任务：（1）质量样本病变的检测和分类，（2）微钙化的检测和分类，以及（3）乳腺癌风险评分。乳腺摄影是最常见的方式，因此也受到了最多的关注。关于断层合成、超声和剪切波弹性成像的研究仍然稀少，我们只有一篇论文分析了乳腺
    MRI 和深度学习；这些其他方式可能在未来几年得到更多关注。表 [6](#S4.T6 "Table 6 ‣ 4.3 Chest ‣ 4 Anatomical
    application areas ‣ A Survey on Deep Learning in Medical Image Analysis") 总结了文献和主要信息。
- en: Since many countries have screening initiatives for breast cancer, there should
    be massive amounts of data available, especially for mammography, and therefore
    enough opportunities for deep models to flourish. Unfortunately, large public
    digital databases are unavailable and consequently older scanned screen-film data
    sets are still in use. Challenges such as the recently launched DREAM challenge
    have not yet had the desired success.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 由于许多国家都开展了乳腺癌筛查计划，因此应该有大量的数据可用，尤其是乳腺摄影，因此也为深度模型的应用提供了足够的机会。不幸的是，缺乏大型公共数字数据库，导致较旧的扫描胶卷数据集仍在使用。诸如最近推出的DREAM挑战等挑战尚未取得预期的成功。
- en: As a result, many papers used small data sets resulting in mixed performance.
    Several projects have addressed this issue by exploring semi-supervised learning
    (Sun et al., [2016a](#bib.bib279)), weakly supervised learning (Hwang and Kim,
    [2016](#bib.bib136)), and transfer learning (Kooi et al., [2017](#bib.bib163);
    Samala et al., [2016b](#bib.bib244))). Another method combines deep models with
    handcrafted features (Dhungel et al., [2016](#bib.bib80)), which have been shown
    to be complementary still, even for very big data sets (Kooi et al., [2016](#bib.bib162)).
    State of the art techniques for mass-like lesion detection and classification
    tend to follow a two-stage pipeline with a candidate detector; this design reduces
    the image to a set of potentially malignant lesions, which are fed to a deep CNN
    (Fotin et al., [2016](#bib.bib95); Kooi et al., [2016](#bib.bib162)). Alternatives
    use a region proposal network (R-CNN) that bypasses the cascaded approach (Akselrod-Ballin
    et al., [2016](#bib.bib4); Kisilev et al., [2016](#bib.bib159)).
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，许多论文使用了小数据集，导致表现混合。一些项目通过探索半监督学习（Sun 等人，[2016a](#bib.bib279)）、弱监督学习（Hwang
    和 Kim，[2016](#bib.bib136)）以及迁移学习（Kooi 等人，[2017](#bib.bib163)；Samala 等人，[2016b](#bib.bib244)）来解决这个问题。另一种方法将深度模型与手工特征相结合（Dhungel
    等人，[2016](#bib.bib80)），即使对于非常大的数据集（Kooi 等人，[2016](#bib.bib162)），也显示出互补效果。最先进的大规模病变检测和分类技术往往采用两个阶段的流程，首先使用候选检测器；这种设计将图像减少为一组潜在的恶性病变，然后将这些病变输入深度
    CNN（Fotin 等人，[2016](#bib.bib95)；Kooi 等人，[2016](#bib.bib162)）。替代方法使用区域建议网络（R-CNN）来绕过级联方法（Akselrod-Ballin
    等人，[2016](#bib.bib4)；Kisilev 等人，[2016](#bib.bib159)）。
- en: When large data sets are available, good results can be obtained. At the SPIE
    Medical Imaging conference of 2016, a researcher from a leading company in the
    mammography CAD field told a packed conference room how a few weeks of experiments
    with a standard architecture (AlexNet) - trained on the company’s proprietary
    database - yielded a performance that was superior to what years of engineering
    handcrafted feature systems had achieved (Fotin et al., [2016](#bib.bib95)).
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据集较大时，可以获得良好的结果。在 2016 年的 SPIE 医学成像会议上，来自领先乳腺 CAD 领域公司的研究员在座无虚席的会议室里介绍了使用标准架构（AlexNet）在公司专有数据库上进行几周实验的结果，该结果优于多年的手工特征系统工程成果（Fotin
    等人，[2016](#bib.bib95)）。
- en: 'Table 8: Overview of papers using deep learning for abdominal image analysis.'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：使用深度学习进行腹部图像分析的论文概述。
- en: '| Reference | Topic | Modality | Method | Remarks |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 主题 | 模态 | 方法 | 备注 |'
- en: '| Multiple |  |  |  |  |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| 多个 |  |  |  |  |'
- en: '| Hu et al. ([2016a](#bib.bib132)) | Segmentation | CT | CNN | 3D CNN with
    time-implicit level sets for segmentation of liver, spleen and kidneys |'
  id: totrans-452
  prefs: []
  type: TYPE_TB
  zh: '| Hu 等人 ([2016a](#bib.bib132)) | 分割 | CT | CNN | 具有时间隐式水平集的 3D CNN，用于肝脏、脾脏和肾脏的分割
    |'
- en: '| Segmentation tasks in liver imaging |  |  |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
  zh: '| 肝脏成像中的分割任务 |  |  |'
- en: '| Li et al. ([2015](#bib.bib172)) | Lesion | CT | CNN | 2D 17$\times$17 patch-based
    classification, Ben-Cohen et al. ([2016](#bib.bib25)) repeats this approach |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '| Li 等人 ([2015](#bib.bib172)) | 病变 | CT | CNN | 基于 2D 17$\times$17 补丁的分类，Ben-Cohen
    等人 ([2016](#bib.bib25)) 重复了这种方法 |'
- en: '| Vivanti et al. ([2015](#bib.bib300)) | Lesion | CT | CNN | 2D CNN for liver
    tumor segmentation in follow-up CT taking baseline CT as input |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| Vivanti 等人 ([2015](#bib.bib300)) | 病变 | CT | CNN | 用于肝肿瘤分割的 2D CNN，将基线 CT
    作为输入用于后续 CT |'
- en: '| Ben-Cohen et al. ([2016](#bib.bib25)) | Liver | CT | CNN | 2D CNN similar
    to U-net, but without cross-connections; good results on SLIVER07 |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '| Ben-Cohen 等人 ([2016](#bib.bib25)) | 肝脏 | CT | CNN | 类似于 U-net 的 2D CNN，但没有交叉连接；在
    SLIVER07 上表现良好 |'
- en: '| Christ et al. ([2016](#bib.bib63)) | Liver & tumor | CT | CNN | U-net, cascaded
    fCNN and dense 3D CRF |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| Christ 等人 ([2016](#bib.bib63)) | 肝脏与肿瘤 | CT | CNN | U-net、级联 fCNN 和密集 3D
    CRF |'
- en: '| Dou et al. ([2016a](#bib.bib81)) | Liver | CT | CNN | 3D CNN with conditional
    random field; good results on SLIVER07 |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| Dou 等人 ([2016a](#bib.bib81)) | 肝脏 | CT | CNN | 具有条件随机场的 3D CNN；在 SLIVER07
    上表现良好 |'
- en: '| Hoogi et al. ([2016](#bib.bib130)) | Lesion | CT/MRI | CNN | 2D CNN obtained
    probabilities are used to drive active contour model |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| Hoogi 等人 ([2016](#bib.bib130)) | 病变 | CT/MRI | CNN | 2D CNN 获得的概率用于驱动主动轮廓模型
    |'
- en: '| Hu et al. ([2016b](#bib.bib133)) | Liver | CT | CNN | 3D CNN with surface
    evolution of a shape prior; good results on SLIVER07 |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '| Hu 等人 ([2016b](#bib.bib133)) | 肝脏 | CT | CNN | 具有形状先验的表面演变的 3D CNN；在 SLIVER07
    上表现良好 |'
- en: '| Lu et al. ([2017](#bib.bib182)) | Liver | CT | CNN | 3D CNN, competitive
    results on SLIVER07 |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
  zh: '| Lu 等人 ([2017](#bib.bib182)) | 肝脏 | CT | CNN | 3D CNN，在 SLIVER07 上表现竞争力 |'
- en: '| Kidneys |  |  |  |  |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '| 肾脏 |  |  |  |  |'
- en: '| Lu et al. ([2016](#bib.bib183)) | Localization | CT | CNN | Combines local
    patch and slice based CNN |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '| Lu 等 ([2016](#bib.bib183)) | 定位 | CT | CNN | 结合局部补丁和切片基础的CNN |'
- en: '| Ravishankar et al. ([2016b](#bib.bib229)) | Localization | US | CNN | Combines
    CNN with classical features to detect regions around kidneys |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '| Ravishankar 等 ([2016b](#bib.bib229)) | 定位 | US | CNN | 结合CNN与经典特征检测肾脏周围区域
    |'
- en: '| Thong et al. ([2016](#bib.bib290)) | Segmentation | CT | CNN | 2D CCN with
    43$\times$43 patches, tested on 20 scans |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '| Thong 等 ([2016](#bib.bib290)) | 分割 | CT | CNN | 43$\times$43补丁的2D CCN，在20个扫描中测试
    |'
- en: '| Pancreas segmentation in CT |  |  |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '| CT中的胰腺分割 |  |  |'
- en: '| Farag et al. ([2015](#bib.bib91)) | Segmentation | CT | CNN | Approach with
    elements similar to Roth et al. ([2015b](#bib.bib234)) |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
  zh: '| Farag 等 ([2015](#bib.bib91)) | 分割 | CT | CNN | 方法类似于 Roth 等 ([2015b](#bib.bib234))
    的研究 |'
- en: '| Roth et al. ([2015b](#bib.bib234)) | Segmentation | CT | CNN | Orthogonal
    patches from superpixel regions are fed into CNNs in three different ways |'
  id: totrans-468
  prefs: []
  type: TYPE_TB
  zh: '| Roth 等 ([2015b](#bib.bib234)) | 分割 | CT | CNN | 从超像素区域中提取的正交补丁以三种不同方式输入CNN
    |'
- en: '| Cai et al. ([2016a](#bib.bib40)) | Segmentation | CT | CNN | 2 CNNs detect
    inside and boundary of organ, initializes conditional random field |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| Cai 等 ([2016a](#bib.bib40)) | 分割 | CT | CNN | 2个CNN检测器官的内部和边界，初始化条件随机场 |'
- en: '| Roth et al. ([2016a](#bib.bib235)) | Segmentation | CT | CNN | 2 CNNs detect
    inside and boundary of pancreas, combined with random forests |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| Roth 等 ([2016a](#bib.bib235)) | 分割 | CT | CNN | 2个CNN检测胰腺内部和边界，结合随机森林 |'
- en: '| Colon |  |  |  |  |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| 结肠 |  |  |  |  |'
- en: '| Tajbakhsh et al. ([2015b](#bib.bib285)) | Polyp detection | Colonoscopy |
    CNN | CNN computes additional features, improving existing scheme |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| Tajbakhsh 等 ([2015b](#bib.bib285)) | 息肉检测 | 胶囊内镜 | CNN | CNN计算附加特征，改进现有方案
    |'
- en: '| Liu et al. ([2016a](#bib.bib177)) | Colitis detection | CT | CNN | Pre-trained
    ImageNet CNN generates features for linear SVM |'
  id: totrans-473
  prefs: []
  type: TYPE_TB
  zh: '| Liu 等 ([2016a](#bib.bib177)) | 结肠炎检测 | CT | CNN | 预训练的ImageNet CNN生成特征供线性SVM使用
    |'
- en: '| Nappi et al. ([2016](#bib.bib201)) | Polyp detection | CT | CNN | Substantial
    reduction of false positives using pre-trained and fine-tuned CNN |'
  id: totrans-474
  prefs: []
  type: TYPE_TB
  zh: '| Nappi 等 ([2016](#bib.bib201)) | 息肉检测 | CT | CNN | 使用预训练和微调的CNN大幅减少假阳性 |'
- en: '| Tachibana et al. ([2016](#bib.bib283)) | Electronic cleansing | CT | CNN
    | Voxel classification in dual energy CT, material other than soft tissue is removed
    |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
  zh: '| Tachibana 等 ([2016](#bib.bib283)) | 电子清除 | CT | CNN | 在双能CT中，去除除软组织以外的材料
    |'
- en: '| Zhang et al. ([2017](#bib.bib342)) | Polyp detection | Colonoscopy | CNN
    | Pre-trained ImageNet CNN for feature extraction, two SVMs for cascaded classification
    |'
  id: totrans-476
  prefs: []
  type: TYPE_TB
  zh: '| Zhang 等 ([2017](#bib.bib342)) | 息肉检测 | 胶囊内镜 | CNN | 预训练的ImageNet CNN用于特征提取，两个SVM进行级联分类
    |'
- en: '| Prostate segmentation in MRI |  |  |'
  id: totrans-477
  prefs: []
  type: TYPE_TB
  zh: '| MRI中的前列腺分割 |  |  |'
- en: '| Liao et al. ([2013](#bib.bib174)) | Application of stacked independent subspace
    analysis networks |'
  id: totrans-478
  prefs: []
  type: TYPE_TB
  zh: '| Liao 等 ([2013](#bib.bib174)) | 应用堆叠独立子空间分析网络 |'
- en: '| Cheng et al. ([2016b](#bib.bib59)) | CNN produces energy map for 2D slice
    based active appearance segmentation |'
  id: totrans-479
  prefs: []
  type: TYPE_TB
  zh: '| Cheng 等 ([2016b](#bib.bib59)) | CNN生成2D切片基础的活动外观分割的能量图 |'
- en: '| Guo et al. ([2016](#bib.bib118)) | Stacked sparse auto-encoders extract features
    from patches, input to atlas matching and a deformable model |'
  id: totrans-480
  prefs: []
  type: TYPE_TB
  zh: '| Guo 等 ([2016](#bib.bib118)) | 堆叠稀疏自编码器从补丁中提取特征，输入到图谱匹配和变形模型 |'
- en: '| Milletari et al. ([2016b](#bib.bib194)) | 3D U-net based CNN architecture
    with objective function that directly optimizes Dice coefficient, ranks #5 in
    PROMISE12 |'
  id: totrans-481
  prefs: []
  type: TYPE_TB
  zh: '| Milletari 等 ([2016b](#bib.bib194)) | 基于3D U-net的CNN架构，目标函数直接优化Dice系数，在PROMISE12中排名第5
    |'
- en: '| Yu et al. ([2017](#bib.bib337)) | 3D fully convolutional network, hybrid
    between a ResNet and U-net architecture, ranks #1 on PROMISE12 |'
  id: totrans-482
  prefs: []
  type: TYPE_TB
  zh: '| Yu 等 ([2017](#bib.bib337)) | 3D完全卷积网络，结合ResNet和U-net架构，在PROMISE12中排名第1 |'
- en: '| Prostate |  |  |  |  |'
  id: totrans-483
  prefs: []
  type: TYPE_TB
  zh: '| 前列腺 |  |  |  |  |'
- en: '| Azizi et al. ([2016](#bib.bib16))) | Lesion classification | US | DBN | DBN
    learns features from temporal US to classify prostate lesions benign/malignant
    |'
  id: totrans-484
  prefs: []
  type: TYPE_TB
  zh: '| Azizi 等 ([2016](#bib.bib16))) | 病灶分类 | US | DBN | DBN从时间序列US中学习特征，以分类前列腺病灶为良性/恶性
    |'
- en: '| Shah et al. ([2016](#bib.bib251)) | CBIR | MRI | CNN | Features from pre-trained
    CNN combined with features from hashing forest |'
  id: totrans-485
  prefs: []
  type: TYPE_TB
  zh: '| Shah 等 ([2016](#bib.bib251)) | CBIR | MRI | CNN | 从预训练的CNN中提取的特征与哈希森林中的特征结合
    |'
- en: '| Zhu et al. ([2017](#bib.bib348)) | Lesion classification | MRI | SAE | Learns
    features from multiple modalities, hierarchical random forest for classification
    |'
  id: totrans-486
  prefs: []
  type: TYPE_TB
  zh: '| Zhu 等 ([2017](#bib.bib348)) | 病灶分类 | MRI | SAE | 从多个模态中学习特征，使用分层随机森林进行分类
    |'
- en: '| Bladder |  |  |  |  |'
  id: totrans-487
  prefs: []
  type: TYPE_TB
  zh: '| 膀胱 |  |  |  |  |'
- en: '| Cha et al. ([2016](#bib.bib45)) | Segmentation | CT | CNN | CNN patch classification
    used as initialization for level set |'
  id: totrans-488
  prefs: []
  type: TYPE_TB
  zh: '| Cha 等人 ([2016](#bib.bib45)) | 分割 | CT | 用于初始化级别集的 CNN 补丁分类 |'
- en: 4.6 Cardiac
  id: totrans-489
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 心脏
- en: 'Deep learning has been applied to many aspects of cardiac image analysis; the
    literature is summarized in Table [7](#S4.T7 "Table 7 ‣ 4.4 Digital pathology
    and microscopy ‣ 4 Anatomical application areas ‣ A Survey on Deep Learning in
    Medical Image Analysis"). MRI is the most researched modality and left ventricle
    segmentation the most common task, but the number of applications is highly diverse:
    segmentation, tracking, slice classification, image quality assessment, automated
    calcium scoring and coronary centerline tracking, and super-resolution.'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习已应用于心脏图像分析的许多方面；文献总结见表 [7](#S4.T7 "Table 7 ‣ 4.4 Digital pathology and microscopy
    ‣ 4 Anatomical application areas ‣ A Survey on Deep Learning in Medical Image
    Analysis")。MRI 是研究最广泛的模式，左心室分割是最常见的任务，但应用种类非常多样：分割、跟踪、切片分类、图像质量评估、自动钙评分和冠状中心线跟踪，以及超分辨率。
- en: 'Most papers used simple 2D CNNs and analyzed the 3D and often 4D data slice
    by slice; the exception is Wolterink et al. ([2016](#bib.bib310)) where 3D CNNs
    were used. DBNs are used in four papers, but these all originated from the same
    author group. The DBNs are only used for feature extraction and are integrated
    in compound segmentation frameworks. Two papers are exceptional because they combined
    CNNs with RNNs: Poudel et al. ([2016](#bib.bib218)) introduced a recurrent connection
    within the U-net architecture to segment the left ventricle slice by slice and
    learn what information to remember from the previous slices when segmenting the
    next one. Kong et al. ([2016](#bib.bib161)) used an architecture with a standard
    2D CNN and an LSTM to perform temporal regression to identify specific frames
    and a cardiac sequence. Many papers use publicly available data. The largest challenge
    in this field was the 2015 Kaggle Data Science Bowl where the goal was to automatically
    measure end-systolic and end-diastolic volumes in cardiac MRI. 192 teams competed
    for $200,000 in prize money and the top ranking teams all used deep learning,
    in particular fCNN or U-net segmentation schemes.'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数论文使用简单的 2D CNN，并逐片分析 3D 和通常的 4D 数据；唯一的例外是 Wolterink 等人 ([2016](#bib.bib310))
    使用了 3D CNN。DBN 在四篇论文中使用，但这些都源自同一作者组。DBN 仅用于特征提取，并集成在复合分割框架中。两篇论文是例外，因为它们将 CNN
    与 RNN 结合：Poudel 等人 ([2016](#bib.bib218)) 在 U-net 架构中引入了递归连接，以逐片分割左心室，并在分割下一片时学习从前一片中记住哪些信息。Kong
    等人 ([2016](#bib.bib161)) 使用了一个包含标准 2D CNN 和 LSTM 的架构，以进行时间回归，识别特定帧和心脏序列。许多论文使用公开数据。这个领域最大的挑战是
    2015 年 Kaggle 数据科学大奖赛，其目标是自动测量心脏 MRI 中的舒张末期和收缩末期体积。192 支队伍争夺 20 万美元的奖金，排名前列的队伍都使用了深度学习，特别是
    fCNN 或 U-net 分割方案。
- en: 4.7 Abdomen
  id: totrans-492
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7 腹部
- en: 'Most papers on the abdomen aimed to localize and segment organs, mainly the
    liver, kidneys, bladder, and pancreas (Table [8](#S4.T8 "Table 8 ‣ 4.5 Breast
    ‣ 4 Anatomical application areas ‣ A Survey on Deep Learning in Medical Image
    Analysis")). Two papers address liver tumor segmentation. The main modality is
    MRI for prostate analysis and CT for all other organs. The colon is the only area
    where various applications were addressed, but always in a straightforward manner:
    A CNN was used as a feature extractor and these features were used for classification.'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数关于腹部的论文旨在定位和分割器官，主要是肝脏、肾脏、膀胱和胰腺（表 [8](#S4.T8 "Table 8 ‣ 4.5 Breast ‣ 4 Anatomical
    application areas ‣ A Survey on Deep Learning in Medical Image Analysis")）。两篇论文涉及肝脏肿瘤分割。主要模式是用于前列腺分析的
    MRI 和用于所有其他器官的 CT。结肠是唯一一个涉及各种应用的区域，但总是以直接的方式：CNN 被用作特征提取器，这些特征被用于分类。
- en: It is interesting to note that in two segmentation challenges - SLIVER07 for
    liver and PROMISE12 for prostate - more traditional image analysis methods were
    dominant up until 2016\. In PROMISE12, the current second and third in rank among
    the automatic methods used active appearance models. The algorithm from IMorphics
    was ranked first for almost five years (now ranked second). However, a 3D fCNN
    similar to U-net (Yu et al., [2017](#bib.bib337)) has recently taken the top position.
    This paper has an interesting approach where a sum-operation was used instead
    of the concatenation operation used in U-net, making it a hybrid between a ResNet
    and U-net architecture. Also in SLIVER07 - a 10-year-old liver segmentation challenge
    - CNNs have started to appear in 2016 at the top of the leaderboard, replacing
    previously dominant methods focused on shape and appearance modeling.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，在两个分割挑战中——SLIVER07 针对肝脏和 PROMISE12 针对前列腺——直到 2016 年，更传统的图像分析方法占据主导地位。在
    PROMISE12 中，目前自动方法中的第二和第三名使用了主动外观模型。IMorphics 的算法几乎连续五年排名第一（现在排名第二）。然而，类似 U-net
    的 3D fCNN 最近取得了最高位置。该论文采用了一种有趣的方法，即使用加和操作代替了 U-net 中的拼接操作，使其成为 ResNet 和 U-net
    架构之间的混合体。在 SLIVER07 中——一个已有 10 年历史的肝脏分割挑战——CNN 从 2016 年开始出现在排行榜的顶部，取代了以前专注于形状和外观建模的主导方法。
- en: 4.8 Musculoskeletal
  id: totrans-495
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.8 骨骼肌肉系统
- en: 'Table 9: Overview of papers using deep learning for musculoskeletal image analysis.'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：使用深度学习进行骨骼肌肉图像分析的论文概述。
- en: '| Reference | Modality | Application; remarks |'
  id: totrans-497
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 成像方式 | 应用；备注 |'
- en: '| --- | --- | --- |'
  id: totrans-498
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Prasoon et al. ([2013](#bib.bib219)) | MRI | Knee cartilage segmentation
    using multi-stream CNNs |'
  id: totrans-499
  prefs: []
  type: TYPE_TB
  zh: '| Prasoon 等人 ([2013](#bib.bib219)) | MRI | 使用多流 CNN 进行膝关节软骨分割 |'
- en: '| Chen et al. ([2015c](#bib.bib52)) | CT | Vertebrae localization; joint learning
    of vertebrae appearance and dependency on neighbors using CNN |'
  id: totrans-500
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人 ([2015c](#bib.bib52)) | CT | 椎骨定位；使用 CNN 进行椎骨外观和邻域依赖的联合学习 |'
- en: '| Roth et al. ([2015c](#bib.bib239)) | CT | Sclerotic metastases detection;
    random 2D views are analyzed by CNN and aggregated |'
  id: totrans-501
  prefs: []
  type: TYPE_TB
  zh: '| Roth 等人 ([2015c](#bib.bib239)) | CT | 硬化转移灶检测；CNN 分析随机的 2D 图像并进行聚合 |'
- en: '| Shen et al. ([2015a](#bib.bib254)) | CT | Vertebrae localization and segmentation;
    CNN for segmenting vertebrae and for center detection |'
  id: totrans-502
  prefs: []
  type: TYPE_TB
  zh: '| Shen 等人 ([2015a](#bib.bib254)) | CT | 椎骨定位和分割；CNN 用于椎骨分割和中心检测 |'
- en: '| Suzani et al. ([2015](#bib.bib281)) | MRI | Vertebrae localization, identification
    and segmentation of vertebrae; CNN used for initial localization |'
  id: totrans-503
  prefs: []
  type: TYPE_TB
  zh: '| Suzani 等人 ([2015](#bib.bib281)) | MRI | 椎骨定位、识别和分割；CNN 用于初步定位 |'
- en: '| Yang et al. ([2015](#bib.bib327)) | MRI | Anatomical landmark detection;
    uses CNN for slice classification for presence of landmark |'
  id: totrans-504
  prefs: []
  type: TYPE_TB
  zh: '| Yang 等人 ([2015](#bib.bib327)) | MRI | 解剖标志检测；使用 CNN 对切片进行分类以检测标志的存在 |'
- en: '| Antony et al. ([2016](#bib.bib11)) | X-ray | Osteoarthritis grading; pre-trained
    ImageNet CNN fine-tuned on knee X-rays |'
  id: totrans-505
  prefs: []
  type: TYPE_TB
  zh: '| Antony 等人 ([2016](#bib.bib11)) | X-ray | 骨关节炎分级；预训练的 ImageNet CNN 在膝关节 X
    光片上进行微调 |'
- en: '| Cai et al. ([2016b](#bib.bib41)) | CT, MRI | Vertebrae localization; RBM
    determines position, orientation and label of vertebrae |'
  id: totrans-506
  prefs: []
  type: TYPE_TB
  zh: '| Cai 等人 ([2016b](#bib.bib41)) | CT, MRI | 椎骨定位；RBM 确定椎骨的位置、方向和标签 |'
- en: '| Golan et al. ([2016](#bib.bib111)) | US | Hip dysplasia detection; CNN with
    adversarial component detects structures and performs measurements |'
  id: totrans-507
  prefs: []
  type: TYPE_TB
  zh: '| Golan 等人 ([2016](#bib.bib111)) | US | 髋关节发育不良检测；带对抗组件的 CNN 检测结构并进行测量 |'
- en: '| Korez et al. ([2016](#bib.bib164)) | MRI | Vertebral bodies segmentation;
    voxel probabilities obtained with a 3D CNN are input to deformable model |'
  id: totrans-508
  prefs: []
  type: TYPE_TB
  zh: '| Korez 等人 ([2016](#bib.bib164)) | MRI | 椎体分割；使用 3D CNN 获得的体素概率输入到可变形模型中 |'
- en: '| Jamaludin et al. ([2016](#bib.bib138)) | MRI | Automatic spine scoring; VGG-19
    CNN analyzes vertebral discs and finds lesion hotspots |'
  id: totrans-509
  prefs: []
  type: TYPE_TB
  zh: '| Jamaludin 等人 ([2016](#bib.bib138)) | MRI | 自动脊柱评分；VGG-19 CNN 分析椎间盘并寻找病灶热点
    |'
- en: '| Miao et al. ([2016](#bib.bib192)) | X-ray | Total Knee Arthroplasty kinematics
    by real-time 2D/3D registration using CNN |'
  id: totrans-510
  prefs: []
  type: TYPE_TB
  zh: '| Miao 等人 ([2016](#bib.bib192)) | X-ray | 通过 CNN 实时 2D/3D 配准进行全膝关节置换术运动学分析
    |'
- en: '| Roth et al. ([2016c](#bib.bib238)) | CT | Posterior-element fractures detection;
    CNN for 2.5D patch-based analysis |'
  id: totrans-511
  prefs: []
  type: TYPE_TB
  zh: '| Roth 等人 ([2016c](#bib.bib238)) | CT | 后元素骨折检测；CNN 用于 2.5D 基于补丁的分析 |'
- en: '| Štern et al. ([2016](#bib.bib272)) | MRI | Hand age estimation; 2D regression
    CNN analyzes 13 bones |'
  id: totrans-512
  prefs: []
  type: TYPE_TB
  zh: '| Štern 等人 ([2016](#bib.bib272)) | MRI | 手部年龄估计；2D 回归 CNN 分析 13 块骨骼 |'
- en: '| Forsberg et al. ([2017](#bib.bib94)) | MRI | Vertebrae detection and labeling;
    outputs of two CNNs are input to graphical model |'
  id: totrans-513
  prefs: []
  type: TYPE_TB
  zh: '| Forsberg 等人 ([2017](#bib.bib94)) | MRI | 椎骨检测与标记；两个 CNN 的输出作为图形模型的输入 |'
- en: '| Spampinato et al. ([2017](#bib.bib270)) | X-ray | Skeletal bone age assessment;
    comparison among several deep learning approaches for the task at hand |'
  id: totrans-514
  prefs: []
  type: TYPE_TB
  zh: '| Spampinato 等人 ([2017](#bib.bib270)) | X 光 | 骨龄评估；比较多种深度学习方法在此任务中的表现 |'
- en: Musculoskeletal images have also been analyzed by deep learning algorithms for
    segmentation and identification of bone, joint, and associated soft tissue abnormalities
    in diverse imaging modalities. The works are summarized in Table [9](#S4.T9 "Table
    9 ‣ 4.8 Musculoskeletal ‣ 4 Anatomical application areas ‣ A Survey on Deep Learning
    in Medical Image Analysis").
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 骨骼肌肉图像也通过深度学习算法进行了分析，以分割和识别骨骼、关节及相关软组织的异常，涉及多种成像模式。这些工作总结在表 [9](#S4.T9 "表 9
    ‣ 4.8 骨骼肌肉 ‣ 4 解剖应用领域 ‣ 医学图像分析中的深度学习综述") 中。
- en: A surprising number of complete applications with promising results are available;
    one that stands out is Jamaludin et al. ([2016](#bib.bib138)) who trained their
    system with 12K discs and claimed near-human performances across four different
    radiological scoring tasks.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 大量具有良好结果的完整应用程序令人惊讶，其中一个突出的例子是 Jamaludin 等人 ([2016](#bib.bib138))，他们用 12K 个磁盘训练了他们的系统，并声称在四种不同的放射学评分任务中达到了接近人类的表现。
- en: 4.9 Other
  id: totrans-517
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.9 其他
- en: 'Table 10: Overview of papers using a single deep learning approach for different
    tasks. DQN = Deep Q-Network'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10：使用单一深度学习方法处理不同任务的文献概述。DQN = 深度 Q 网络
- en: '| Reference | Task | Modality | Method | Remarks |'
  id: totrans-519
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 任务 | 模态 | 方法 | 备注 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-520
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Shin et al. ([2013](#bib.bib259)) | Heart, kidney, liver segmentation | MRI
    | SAE | SAE to learn temporal/spatial features on 2D + time DCE-MRI |'
  id: totrans-521
  prefs: []
  type: TYPE_TB
  zh: '| Shin 等人 ([2013](#bib.bib259)) | 心脏、肾脏、肝脏分割 | MRI | SAE | SAE 用于学习 2D + 时间
    DCE-MRI 上的时空特征 |'
- en: '| Roth et al. ([2015a](#bib.bib233)) | 2D slice classification | CT | CNN |
    Automatically classifying slices in 5 anatomical regions |'
  id: totrans-522
  prefs: []
  type: TYPE_TB
  zh: '| Roth 等人 ([2015a](#bib.bib233)) | 2D 切片分类 | CT | CNN | 自动分类 5 个解剖区域中的切片 |'
- en: '| Shin et al. ([2015](#bib.bib258)) | 2D key image labeling | CT, MRI | CNN
    | Text and 2D image analysis on a diverse set of 780 thousand images |'
  id: totrans-523
  prefs: []
  type: TYPE_TB
  zh: '| Shin 等人 ([2015](#bib.bib258)) | 2D 关键图像标记 | CT, MRI | CNN | 对 78 万张图像集进行文本和
    2D 图像分析 |'
- en: '| Cheng et al. ([2016a](#bib.bib58)) | Various detection tasks | US, CT | AE,
    CNN | Detection of breast lesions in US and pulmonary nodules in CT |'
  id: totrans-524
  prefs: []
  type: TYPE_TB
  zh: '| Cheng 等人 ([2016a](#bib.bib58)) | 各种检测任务 | US, CT | AE, CNN | 检测 US 中的乳腺病变和
    CT 中的肺结节 |'
- en: '| Ghesu et al. ([2016a](#bib.bib109)) | Landmark detection | US, CT, MRI |
    CNN, DQN | Reinforcement learning with CNN features, cardiac MR/US, head&neck
    CT |'
  id: totrans-525
  prefs: []
  type: TYPE_TB
  zh: '| Ghesu 等人 ([2016a](#bib.bib109)) | 标志点检测 | US, CT, MRI | CNN, DQN | 使用 CNN
    特征的强化学习，涉及心脏 MR/US、头颈 CT |'
- en: '| Liu et al. ([2016b](#bib.bib178)) | Image retrieval | X-ray | CNN | Combines
    CNN feature with Radon transform, evaluated on IRMA database |'
  id: totrans-526
  prefs: []
  type: TYPE_TB
  zh: '| Liu 等人 ([2016b](#bib.bib178)) | 图像检索 | X 光 | CNN | 结合 CNN 特征与 Radon 变换，在
    IRMA 数据库上进行评估 |'
- en: '| Merkow et al. ([2016](#bib.bib191)) | Vascular network segmentation | CT,
    MRI | CNN | Framework to find various vascular networks |'
  id: totrans-527
  prefs: []
  type: TYPE_TB
  zh: '| Merkow 等人 ([2016](#bib.bib191)) | 血管网络分割 | CT, MRI | CNN | 发现各种血管网络的框架 |'
- en: '| Moeskops et al. ([2016b](#bib.bib197)) | Various segmentation tasks | MRI,
    CT | CNN | Single architecture to segment 6 brain tissues, pectoral muscle & coronaries
    |'
  id: totrans-528
  prefs: []
  type: TYPE_TB
  zh: '| Moeskops 等人 ([2016b](#bib.bib197)) | 各种分割任务 | MRI, CT | CNN | 单一架构分割 6 种脑组织、胸肌及冠状动脉
    |'
- en: '| Roth et al. ([2016b](#bib.bib236)) | Various detection tasks | CT | CNN |
    Multi-stream CNN to detect sclerotic lesions, lymph nodes and polyps |'
  id: totrans-529
  prefs: []
  type: TYPE_TB
  zh: '| Roth 等人 ([2016b](#bib.bib236)) | 各种检测任务 | CT | CNN | 多流 CNN 用于检测硬化性病变、淋巴结和息肉
    |'
- en: '| Shin et al. ([2016b](#bib.bib261)) | Abnormality detection | CT | CNN | Compares
    architectures for detecting interstitial disease and lymph nodes |'
  id: totrans-530
  prefs: []
  type: TYPE_TB
  zh: '| Shin 等人 ([2016b](#bib.bib261)) | 异常检测 | CT | CNN | 比较检测间质疾病和淋巴结的架构 |'
- en: '| Tajbakhsh et al. ([2016](#bib.bib286)) | Abnormality detection | CT, US |
    CNN | Compares pre-trained with fully trained networks for three detection tasks
    |'
  id: totrans-531
  prefs: []
  type: TYPE_TB
  zh: '| Tajbakhsh 等人 ([2016](#bib.bib286)) | 异常检测 | CT, US | CNN | 比较预训练网络与完全训练网络在三个检测任务中的表现
    |'
- en: '| Wang et al. ([2016e](#bib.bib309)) | 2D key image labeling | CT, MRI | CNN
    | Text concept clustering, related to Shin et al. ([2015](#bib.bib258)) |'
  id: totrans-532
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等人 ([2016e](#bib.bib309)) | 2D 关键图像标记 | CT, MRI | CNN | 文本概念聚类，与 Shin
    等人 ([2015](#bib.bib258)) 相关 |'
- en: '| Yan et al. ([2016](#bib.bib326)) | 2D slice classification | CT | CNN | Automatically
    classifying CT slices in 12 anatomical regions |'
  id: totrans-533
  prefs: []
  type: TYPE_TB
  zh: '| Yan 等人 ([2016](#bib.bib326)) | 2D 切片分类 | CT | CNN | 自动分类 CT 切片在 12 个解剖区域中
    |'
- en: '| Zhou et al. ([2016](#bib.bib347)) | Thorax-abdomen segmentation | CT | CNN
    | 21 structures are segmented with 3 orthogonal 2D fCNNs and majority voting |'
  id: totrans-534
  prefs: []
  type: TYPE_TB
  zh: '| Zhou 等人 ([2016](#bib.bib347)) | 胸腹部分割 | CT | CNN | 使用 3 个正交的 2D fCNN 和多数投票分割
    21 个结构 |'
- en: 'Table 11: Overview of papers using deep learning for various image analysis
    tasks.'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: '表 11: 使用深度学习进行各种图像分析任务的论文概述。'
- en: '| Reference | Task | Modality | Method | Remarks |'
  id: totrans-536
  prefs: []
  type: TYPE_TB
  zh: '| 参考 | 任务 | 模态 | 方法 | 备注 |'
- en: '| Fetal imaging |  |  |  |  |'
  id: totrans-537
  prefs: []
  type: TYPE_TB
  zh: '| 胎儿成像 |  |  |  |  |'
- en: '| Chen et al. ([2015b](#bib.bib50)) | Frame labeling | US | CNN | Locates abdominal
    plane from fetal ultrasound videos |'
  id: totrans-538
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人 ([2015b](#bib.bib50)) | 帧标注 | US | CNN | 从胎儿超声视频中定位腹部平面 |'
- en: '| Chen et al. ([2015a](#bib.bib48)) | Frame labeling | US | RNN | Same task
    as Chen et al. ([2015b](#bib.bib50)), now using RNNs |'
  id: totrans-539
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人 ([2015a](#bib.bib48)) | 帧标注 | US | RNN | 与 Chen 等人 ([2015b](#bib.bib50))
    相同的任务，现在使用 RNN |'
- en: '| Baumgartner et al. ([2016](#bib.bib24)) | Frame labeling | US | CNN | Labeling
    12 standard frames in 1003 mid pregnancy fetal US videos |'
  id: totrans-540
  prefs: []
  type: TYPE_TB
  zh: '| Baumgartner 等人 ([2016](#bib.bib24)) | 帧标注 | US | CNN | 在 1003 个中期妊娠胎儿超声视频中标注
    12 个标准帧 |'
- en: '| Gao et al. ([2016d](#bib.bib104)) | Frame labeling | US | CNN | 4 class frame
    classification using transfer learning with pre-trained networks |'
  id: totrans-541
  prefs: []
  type: TYPE_TB
  zh: '| Gao 等人 ([2016d](#bib.bib104)) | 帧标注 | US | CNN | 使用转移学习和预训练网络进行 4 类帧分类 |'
- en: '| Kumar et al. ([2016](#bib.bib166)) | Frame labeling | US | CNN | 12 standard
    anatomical planes, CNN extracts features for support vector machine |'
  id: totrans-542
  prefs: []
  type: TYPE_TB
  zh: '| Kumar 等人 ([2016](#bib.bib166)) | 帧标注 | US | CNN | 12 个标准解剖平面，CNN 提取特征用于支持向量机
    |'
- en: '| Rajchl et al. ([2016b](#bib.bib225)) | Segmentation with non expert labels
    | MRI | CNN | Crowd-sourcing annotation efforts to segment brain structures |'
  id: totrans-543
  prefs: []
  type: TYPE_TB
  zh: '| Rajchl 等人 ([2016b](#bib.bib225)) | 使用非专家标签进行分割 | MRI | CNN | 众包注释工作用于分割脑结构
    |'
- en: '| Rajchl et al. ([2016a](#bib.bib224)) | Segmentation given bounding box |
    MRI | CNN | CNN and CRF for segmentation of structures |'
  id: totrans-544
  prefs: []
  type: TYPE_TB
  zh: '| Rajchl 等人 ([2016a](#bib.bib224)) | 给定边界框的分割 | MRI | CNN | CNN 和 CRF 用于结构的分割
    |'
- en: '| Ravishankar et al. ([2016a](#bib.bib228)) | Quantification | US | CNN | Hybrid
    system using CNN and texture features to find abdominal circumference |'
  id: totrans-545
  prefs: []
  type: TYPE_TB
  zh: '| Ravishankar 等人 ([2016a](#bib.bib228)) | 量化 | US | CNN | 使用 CNN 和纹理特征的混合系统来查找腹围
    |'
- en: '| Yu et al. ([2016b](#bib.bib336)) | Left ventricle segmentation | US | CNN
    | Frame-by-frame segmentation by dynamically fine-tuning CNN to the latest frame
    |'
  id: totrans-546
  prefs: []
  type: TYPE_TB
  zh: '| Yu 等人 ([2016b](#bib.bib336)) | 左心室分割 | US | CNN | 逐帧分割，通过动态微调 CNN 到最新帧 |'
- en: '| Dermatology |  |  |  |  |'
  id: totrans-547
  prefs: []
  type: TYPE_TB
  zh: '| 皮肤科 |  |  |  |  |'
- en: '| Codella et al. ([2015](#bib.bib71)) | Melanoma detection in dermoscopic images
    | CNN | Features from pre-trained CNN combined with other features |'
  id: totrans-548
  prefs: []
  type: TYPE_TB
  zh: '| Codella 等人 ([2015](#bib.bib71)) | 皮肤镜图像中的黑色素瘤检测 | CNN | 结合预训练 CNN 特征和其他特征
    |'
- en: '| Demyanov et al. ([2016](#bib.bib79)) | Pattern identification in dermoscopic
    images | CNN | Comparison to simpler networks and simple machine learning |'
  id: totrans-549
  prefs: []
  type: TYPE_TB
  zh: '| Demyanov 等人 ([2016](#bib.bib79)) | 在皮肤镜图像中进行模式识别 | CNN | 与更简单的网络和简单的机器学习方法进行比较
    |'
- en: '| Kawahara et al. ([2016a](#bib.bib151)) | 5 and 10-class classification photographic
    images | CNN | Pre-trained CNN for feature extraction at two image resolutions
    |'
  id: totrans-550
  prefs: []
  type: TYPE_TB
  zh: '| Kawahara 等人 ([2016a](#bib.bib151)) | 5 类和 10 类分类摄影图像 | CNN | 预训练的 CNN 用于两个图像分辨率的特征提取
    |'
- en: '| Kawahara and Hamarneh ([2016](#bib.bib153)) | 10-class classification photographic
    images | CNN | Extending Kawahara et al. ([2016a](#bib.bib151)) now training multi-resolution
    CNN end-to-end |'
  id: totrans-551
  prefs: []
  type: TYPE_TB
  zh: '| Kawahara 和 Hamarneh ([2016](#bib.bib153)) | 10 类分类摄影图像 | CNN | 扩展了 Kawahara
    等人 ([2016a](#bib.bib151))，现在训练多分辨率 CNN 端到端 |'
- en: '| Yu et al. ([2016a](#bib.bib335)) | Melanoma detection in dermoscopic images
    | CNN | Deep residual networks for lesion segmentation and classification, winner
    ISIC16 |'
  id: totrans-552
  prefs: []
  type: TYPE_TB
  zh: '| Yu 等人 ([2016a](#bib.bib335)) | 皮肤镜图像中的黑色素瘤检测 | CNN | 深度残差网络用于病变分割和分类，ISIC16
    比赛获胜者 |'
- en: '| Menegola et al. ([2016](#bib.bib190)) | Classification of dermoscopic images
    | CNN | Various pre-training and fine-tuning strategies are compared |'
  id: totrans-553
  prefs: []
  type: TYPE_TB
  zh: '| Menegola 等人 ([2016](#bib.bib190)) | 皮肤镜图像分类 | CNN | 比较了各种预训练和微调策略 |'
- en: '| Esteva et al. ([2017](#bib.bib89)) | Classification of photographic and dermoscopic
    images | CNN | Inception CNN trained on 129k images; compares favorably to 29
    dermatologists |'
  id: totrans-554
  prefs: []
  type: TYPE_TB
  zh: '| Esteva 等人 ([2017](#bib.bib89)) | 摄影图像和皮肤镜图像分类 | CNN | 在 129k 图像上训练的 Inception
    CNN；与 29 名皮肤科医生的表现相当 |'
- en: '| Lymph nodes |  |  |  |  |'
  id: totrans-555
  prefs: []
  type: TYPE_TB
  zh: '| 淋巴结 |  |  |  |  |'
- en: '| Roth et al. ([2014](#bib.bib237)) | Lymph node detection | CT | CNN | Introduces
    multi-stream framework of 2D CNNs with orthogonal patches |'
  id: totrans-556
  prefs: []
  type: TYPE_TB
  zh: '| Roth et al. ([2014](#bib.bib237)) | 淋巴结检测 | CT | CNN | 引入了具有正交补丁的2D CNN的多流框架
    |'
- en: '| Barbu et al. ([2016](#bib.bib21)) | Lymph node detection | CT | CNN | Compares
    effect of different loss functions |'
  id: totrans-557
  prefs: []
  type: TYPE_TB
  zh: '| Barbu et al. ([2016](#bib.bib21)) | 淋巴结检测 | CT | CNN | 比较不同损失函数的效果 |'
- en: '| Nogues et al. ([2016](#bib.bib207)) | Lymph node detection | CT | CNN | 2
    fCNNs, for inside and for contour of lymph nodes, are combined in a CRF |'
  id: totrans-558
  prefs: []
  type: TYPE_TB
  zh: '| Nogues et al. ([2016](#bib.bib207)) | 淋巴结检测 | CT | CNN | 2个fCNN，用于淋巴结的内部和轮廓，在CRF中组合
    |'
- en: '| Other |  |  |  |  |'
  id: totrans-559
  prefs: []
  type: TYPE_TB
  zh: '| Other |  |  |  |  |'
- en: '| Wang et al. ([2015](#bib.bib302)) | Wound segmentation | photographs | CNN
    | Additional detection of infection risk and healing progress |'
  id: totrans-560
  prefs: []
  type: TYPE_TB
  zh: '| Wang et al. ([2015](#bib.bib302)) | 创伤分割 | 照片 | CNN | 附加感染风险和愈合进展的检测 |'
- en: '| Ypsilantis et al. ([2015](#bib.bib334)) | Chemotherapy response prediction
    | PET | CNN | CNN outperforms classical radiomics features in patients with esophageal
    cancer |'
  id: totrans-561
  prefs: []
  type: TYPE_TB
  zh: '| Ypsilantis et al. ([2015](#bib.bib334)) | 化疗反应预测 | PET | CNN | CNN在食道癌患者中的表现优于传统放射组学特征
    |'
- en: '| Zheng et al. ([2015](#bib.bib346)) | Carotid artery bifurcation detection
    | CT | CNN | Two stage detection process, CNNs combined with Haar features |'
  id: totrans-562
  prefs: []
  type: TYPE_TB
  zh: '| Zheng et al. ([2015](#bib.bib346)) | 颈动脉分叉检测 | CT | CNN | 两阶段检测过程，CNN与Haar特征结合
    |'
- en: '| Alansary et al. ([2016](#bib.bib5)) | Placenta segmentation | MRI | CNN |
    3D multi-stream CNN with extension for motion correction |'
  id: totrans-563
  prefs: []
  type: TYPE_TB
  zh: '| Alansary et al. ([2016](#bib.bib5)) | 胎盘分割 | MRI | CNN | 具有运动校正扩展的3D多流CNN
    |'
- en: '| Fritscher et al. ([2016](#bib.bib96)) | Head&Neck tumor segmentation | CT
    | CNN | 3 orthogonal patches in 2D CNNs, combined with other features |'
  id: totrans-564
  prefs: []
  type: TYPE_TB
  zh: '| Fritscher et al. ([2016](#bib.bib96)) | 头颈部肿瘤分割 | CT | CNN | 2D CNN中的3个正交补丁，结合其他特征
    |'
- en: '| Jaumard-Hakoun et al. ([2016](#bib.bib143)) | Tongue contour extraction |
    US | RBM | Analysis of tongue motion during speech, combines auto-encoders with
    RBMs |'
  id: totrans-565
  prefs: []
  type: TYPE_TB
  zh: '| Jaumard-Hakoun et al. ([2016](#bib.bib143)) | 舌头轮廓提取 | 超声 | RBM | 分析说话过程中的舌头运动，将自编码器与RBM结合
    |'
- en: '| Payer et al. ([2016](#bib.bib213)) | Hand landmark detection | X-ray | CNN
    | Various architectures are compared |'
  id: totrans-566
  prefs: []
  type: TYPE_TB
  zh: '| Payer et al. ([2016](#bib.bib213)) | 手部标志检测 | X光 | CNN | 比较了各种架构 |'
- en: '| Quinn et al. ([2016](#bib.bib223)) | Disease detection | microscopy | CNN
    | Smartphone mounted on microscope detects malaria, tuberculosis & parasite eggs
    |'
  id: totrans-567
  prefs: []
  type: TYPE_TB
  zh: '| Quinn et al. ([2016](#bib.bib223)) | 疾病检测 | 显微镜 | CNN | 安装在显微镜上的智能手机检测疟疾、结核病和寄生虫卵
    |'
- en: '| Smistad and Løvstakken ([2016](#bib.bib266)) | Vessel detection and segmentation
    | US | CNN | Femoral and carotid vessels analyzed with standard fCNN |'
  id: totrans-568
  prefs: []
  type: TYPE_TB
  zh: '| Smistad and Løvstakken ([2016](#bib.bib266)) | 血管检测与分割 | 超声 | CNN | 股动脉和颈动脉用标准fCNN进行分析
    |'
- en: '| Twinanda et al. ([2017](#bib.bib293)) | Task recognition in laparoscopy |
    Videos | CNN | Fine-tuned AlexNet applied to video frames |'
  id: totrans-569
  prefs: []
  type: TYPE_TB
  zh: '| Twinanda et al. ([2017](#bib.bib293)) | 腹腔镜下任务识别 | 视频 | CNN | 应用微调的AlexNet于视频帧
    |'
- en: '| Xu et al. ([2016c](#bib.bib321)) | Cervical dysplasia | cervigrams | CNN
    | Fine-tuned pre-trained network with added non-imaging features |'
  id: totrans-570
  prefs: []
  type: TYPE_TB
  zh: '| Xu et al. ([2016c](#bib.bib321)) | 宫颈上皮内瘤变 | cervigrams | CNN | 微调的预训练网络，增加了非成像特征
    |'
- en: '| Xue et al. ([2016](#bib.bib325)) | Esophageal microvessel classification
    | Microscopy | CNN | Simple CNN used for feature extraction |'
  id: totrans-571
  prefs: []
  type: TYPE_TB
  zh: '| Xue et al. ([2016](#bib.bib325)) | 食管微血管分类 | 显微镜 | CNN | 用于特征提取的简单CNN |'
- en: '| Zhang et al. ([2016a](#bib.bib339)) | Image reconstruction | CT | CNN | Reconstructing
    from limited angle measurements, reducing reconstruction artefacts |'
  id: totrans-572
  prefs: []
  type: TYPE_TB
  zh: '| Zhang et al. ([2016a](#bib.bib339)) | 图像重建 | CT | CNN | 从有限角度测量中重建，减少重建伪影
    |'
- en: '| Lekadir et al. ([2017](#bib.bib168)) | Carotid plaque classification | US
    | CNN | Simple CNN for characterization of carotid plaque composition in ultrasound
    |'
  id: totrans-573
  prefs: []
  type: TYPE_TB
  zh: '| Lekadir et al. ([2017](#bib.bib168)) | 颈动脉斑块分类 | 超声 | CNN | 用于超声中颈动脉斑块组成特征描述的简单CNN
    |'
- en: '| Ma et al. ([2017](#bib.bib184)) | Thyroid nodule detection | US | CNN | CNN
    and standard features combines for 2D US analysis |'
  id: totrans-574
  prefs: []
  type: TYPE_TB
  zh: '| Ma et al. ([2017](#bib.bib184)) | 甲状腺结节检测 | 超声 | CNN | CNN与标准特征结合用于2D超声分析
    |'
- en: This final section lists papers that address multiple applications (Table [10](#S4.T10
    "Table 10 ‣ 4.9 Other ‣ 4 Anatomical application areas ‣ A Survey on Deep Learning
    in Medical Image Analysis")) and a variety of other applications (Table [11](#S4.T11
    "Table 11 ‣ 4.9 Other ‣ 4 Anatomical application areas ‣ A Survey on Deep Learning
    in Medical Image Analysis")).
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 本节列出了涉及多种应用的论文（表 [10](#S4.T10 "Table 10 ‣ 4.9 Other ‣ 4 Anatomical application
    areas ‣ A Survey on Deep Learning in Medical Image Analysis)") 和各种其他应用的论文（表 [11](#S4.T11
    "Table 11 ‣ 4.9 Other ‣ 4 Anatomical application areas ‣ A Survey on Deep Learning
    in Medical Image Analysis)")。
- en: It is remarkable that one single architecture or approach based on deep learning
    can be applied without modifications to different tasks; this illustrates the
    versatility of deep learning and its general applicability. In some works, pre-trained
    architectures are used, sometimes trained with images from a completely different
    domain. Several authors analyze the effect of fine-tuning a network by training
    it with a small data set of images from the intended application domain. Combining
    features extracted by a CNN with ‘traditional’ features is also commonly seen.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，基于深度学习的单一架构或方法可以在不同任务中应用而无需修改，这说明了深度学习的多样性及其广泛适用性。在一些工作中，使用了预训练的架构，有时这些架构是用来自完全不同领域的图像进行训练的。几位作者分析了通过用小数据集的图像对网络进行微调的效果。将
    CNN 提取的特征与“传统”特征结合的情况也很常见。
- en: From Table [11](#S4.T11 "Table 11 ‣ 4.9 Other ‣ 4 Anatomical application areas
    ‣ A Survey on Deep Learning in Medical Image Analysis"), the large number of papers
    that address obstetric applications stand out. Most papers address the groundwork,
    such as selecting an appropriate frame from an US stream. More work on automated
    measurements with deep learning in these US sequences is likely to follow.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 从表 [11](#S4.T11 "Table 11 ‣ 4.9 Other ‣ 4 Anatomical application areas ‣ A Survey
    on Deep Learning in Medical Image Analysis") 可以看出，大量处理产科应用的论文尤为突出。大多数论文涉及基础工作，例如从超声波流中选择适当的帧。预计会有更多关于在这些超声序列中使用深度学习进行自动测量的工作。
- en: The second area where CNNs are rapidly improving the state of the art is dermoscopic
    image analysis. For a long time, diagnosing skin cancer from photographs was considered
    very difficult and out of reach for computers. Many studies focused only on images
    obtained with specialized cameras, and recent systems based on deep networks produced
    promising results. A recent work by Esteva et al. ([2017](#bib.bib89)) demonstrated
    excellent results with training a recent standard architecture (Google’s Inception
    v3) on a data set of both dermoscopic and standard photographic images. This data
    set was two orders of magnitude larger than what was used in literature before.
    In a thorough evaluation, the proposed system performed on par with 30 board certified
    dermatologists.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 在皮肤镜图像分析领域的快速进展是另一个提高艺术水平的领域。长期以来，从照片中诊断皮肤癌被认为是非常困难的，并且超出了计算机的能力范围。许多研究仅关注使用专用相机获得的图像，近期基于深度网络的系统产生了有希望的结果。Esteva
    等人的一项近期工作（[2017](#bib.bib89)）通过在包括皮肤镜图像和标准照片图像的数据集上训练一种最新的标准架构（Google 的 Inception
    v3），展示了卓越的结果。该数据集的规模比以前文献中使用的要大两个数量级。在彻底评估中，所提出的系统的表现与 30 位认证皮肤科医生相当。
- en: 5 Discussion
  id: totrans-579
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 讨论
- en: Overview
  id: totrans-580
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 概述
- en: 'From the 308 papers reviewed in this survey, it is evident that deep learning
    has pervaded every aspect of medical image analysis. This has happened extremely
    quickly: the vast majority of contributions, 242 papers, were published in 2016
    or the first month of 2017\. A large diversity of deep architectures are covered.
    The earliest studies used pre-trained CNNs as feature extractors. The fact that
    these pre-trained networks could simply be downloaded and directly applied to
    any medical image facilitated their use. Moreover, in this approach already existing
    systems based on handcrafted features could simply be extended. In the last two
    years, however, we have seen that end-to-end trained CNNs have become the preferred
    approach for medical imaging interpretation (see Figure [1](#S1.F1 "Figure 1 ‣
    1 Introduction ‣ A Survey on Deep Learning in Medical Image Analysis")). Such
    CNNs are often integrated into existing image analysis pipelines and replace traditional
    handcrafted machine learning methods. This is the approach followed by the largest
    group of papers in this survey and we can confidently state that this is the current
    standard practice.'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 从本次调查中审阅的308篇论文来看，深度学习已经渗透到医学图像分析的每个方面。这一变化发生得非常迅速：绝大多数的贡献，即242篇论文，发表于2016年或2017年的第一个月。涵盖了各种各样的深度架构。最早的研究使用了预训练的CNN作为特征提取器。这些预训练的网络可以直接下载并应用于任何医学图像，这一事实促进了它们的使用。此外，这种方法可以简单地扩展到已经存在的基于手工特征的系统中。然而，在过去两年中，我们看到端到端训练的CNN已经成为医学成像解读的首选方法（见图
    [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ A Survey on Deep Learning in Medical Image
    Analysis")）。这些CNN通常集成到现有的图像分析流程中，并取代传统的手工机器学习方法。这是本次调查中最大一组论文所采用的方法，我们可以自信地说，这已经是当前的标准实践。
- en: Key aspects of successful deep learning methods
  id: totrans-582
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 成功的深度学习方法的关键方面
- en: After reviewing so many papers one would expect to be able to distill the perfect
    deep learning method and architecture for each individual task and application
    area. Although convolutional neural networks (and derivatives) are now clearly
    the top performers in most medical image analysis competitions, one striking conclusion
    we can draw is that the exact architecture is not the most important determinant
    in getting a good solution. We have seen, for example in challenges like the Kaggle
    Diabetic Retinopathy Challenge, that many researchers use the exact same architectures,
    the same type of networks, but have widely varying results. A key aspect that
    is often overlooked is that expert knowledge about the task to be solved can provide
    advantages that go beyond adding more layers to a CNN. Groups and researchers
    that obtain good performance when applying deep learning algorithms often differentiate
    themselves in aspects outside of the deep network, like novel data preprocessing
    or augmentation techniques. An example is that the best performing method in the
    CAMELYON16-challenge improved significantly (AUC from 0.92 to 0.99) by adding
    a stain normalization pre-processing step to improve generalization without changing
    the CNN. Other papers focus on data augmentation strategies to make networks more
    robust, and they report that these strategies are essential to obtain good performance.
    An example is the elastic deformations that were applied in the original U-Net
    paper (Ronneberger et al., [2015](#bib.bib232)).
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 在审阅了这么多论文后，人们可能会期望能够提炼出适用于每个单独任务和应用领域的完美深度学习方法和架构。尽管卷积神经网络（及其衍生品）现在显然是大多数医学图像分析竞赛中的顶尖表现者，但我们可以得出一个显著的结论：精确的架构并不是获得良好解决方案的最重要决定因素。例如，在像Kaggle糖尿病视网膜病变挑战这样的竞赛中，我们看到许多研究者使用完全相同的架构、相同类型的网络，却有着广泛不同的结果。一个经常被忽视的关键方面是，对任务的专家知识可以提供超越增加更多CNN层的优势。应用深度学习算法时获得良好表现的团队和研究者，通常在深度网络之外的方面有所区别，如新颖的数据预处理或增强技术。例如，在CAMELYON16挑战赛中，最佳表现的方法通过添加一个染色标准化预处理步骤来显著提高了泛化能力（AUC从0.92提升到0.99），而没有更改CNN。其他论文则关注于数据增强策略，以使网络更加稳健，并报告这些策略对于获得良好表现至关重要。例如，在原始U-Net论文（Ronneberger等人，[2015](#bib.bib232)）中应用了弹性变形。
- en: Augmentation and pre-processing are, of course, not the only key contributors
    to good solutions. Several researchers have shown that designing architectures
    incorporating unique task-specific properties can obtain better results than straightforward
    CNNs. Two examples which we encountered several times are multi-view and multi-scale
    networks. Other, often underestimated, parts of network design are the network
    input size and receptive field (i.e. the area in input space that contributes
    to a single output unit). Input sizes should be selected considering for example
    the required resolution and context to solve a problem. One might increase the
    size of the patch to obtain more context, but without changing the receptive field
    of the network this might not be beneficial. As a standard sanity check researchers
    could perform the same task themselves via visual assessment of the network input.
    If they, or domain experts, cannot achieve good performance, the chance that you
    need to modify your network input or architecture is high.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 增强和预处理当然不是获得良好解决方案的唯一关键因素。一些研究人员已经表明，设计包含独特任务特定属性的架构可以比简单的 CNN 获得更好的结果。我们遇到过的两个例子是多视图和多尺度网络。网络设计中其他常常被低估的部分包括网络输入大小和感受野（即对单一输出单元有贡献的输入空间区域）。输入大小应考虑所需的分辨率和上下文以解决问题。例如，可能需要增加补丁的大小以获得更多上下文，但如果不改变网络的感受野，这可能不会带来好处。作为标准的合理性检查，研究人员可以通过对网络输入进行视觉评估来完成相同的任务。如果他们或领域专家无法获得良好的性能，则需要修改网络输入或架构的可能性很高。
- en: The last aspect we want to touch on is model hyper-parameter optimization (e.g. learning
    rate, dropout rate), which can help squeeze out extra performance from a network.
    We believe this is of secondary importance with respect to performance to the
    previously discussed topics and training data quality. Disappointingly, no clear
    recipe can be given to obtain the best set of hyper-parameters as it is a highly
    empirical exercise. Most researchers fall back to an intuition-based random search
    (Bergstra and Bengio, [2012](#bib.bib33)), which often seems to work well enough.
    Some basic tips have been covered before by Bengio ([2012](#bib.bib26)). Researchers
    have also looked at Bayesian methods for hyper-parameter optimization (Snoek et al.,
    [2012](#bib.bib267)), but this has not been applied in medical image analysis
    as far as we are aware of.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最后想讨论的一个方面是模型超参数优化（例如学习率、丢弃率），这可以帮助从网络中挤出额外的性能。我们认为与之前讨论的主题和训练数据质量相比，这在性能上是次要的。令人失望的是，没有明确的配方可以获得最佳的超参数组合，因为这是一项高度经验性的工作。大多数研究人员回归到基于直觉的随机搜索（Bergstra
    和 Bengio，[2012](#bib.bib33)），这通常效果不错。Bengio（[2012](#bib.bib26)）之前已覆盖了一些基本提示。研究人员还研究了贝叶斯方法用于超参数优化（Snoek
    等，[2012](#bib.bib267)），但据我们了解，这在医学图像分析中尚未得到应用。
- en: Unique challenges in medical image analysis
  id: totrans-586
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 医学图像分析中的独特挑战
- en: 'It is clear that applying deep learning algorithms to medical image analysis
    presents several unique challenges. The lack of large training data sets is often
    mentioned as an obstacle. However, this notion is only partially correct. The
    use of PACS systems in radiology has been routine in most western hospitals for
    at least a decade and these are filled with millions of images. There are few
    other domains where this magnitude of imaging data, acquired for specific purposes,
    are digitally available in well-structured archives. PACS-like systems are not
    as broadly used for other specialties in medicine, like ophthalmology and pathology,
    but this is changing as imaging becomes more prevalent across disciplines. We
    are also seeing that increasingly large public data sets are made available: Esteva
    et al. ([2017](#bib.bib89)) used 18 public data sets and more than $10^{5}$ training
    images; in the Kaggle diabetic retinopathy competition a similar number of retinal
    images were released; and several chest x-ray studies used more than $10^{4}$
    images.'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，将深度学习算法应用于医学图像分析面临着几个独特的挑战。缺乏大型训练数据集通常被提到作为障碍。然而，这一观点仅部分正确。放射学中 PACS 系统的使用在大多数西方医院已经常规使用了至少十年，这些系统中充满了数百万张图像。很少有其他领域具有这种规模的成像数据，为特定目的而获取，并且在结构良好的档案中数字化可用。PACS
    类系统在医学的其他专业领域，如眼科和病理学中并不那么广泛使用，但随着成像在各学科中变得越来越普遍，这种情况正在改变。我们还看到，越来越多的大型公共数据集被公开：Esteva
    等人（[2017](#bib.bib89)）使用了 18 个公共数据集和超过 $10^{5}$ 张训练图像；在 Kaggle 糖尿病视网膜病变比赛中发布了类似数量的视网膜图像；几个胸部
    X 光研究使用了超过 $10^{4}$ 张图像。
- en: The main challenge is thus not the availability of image data itself, but the
    acquisition of relevant annotations/labeling for these images. Traditionally PACS
    systems store free-text reports by radiologists describing their findings. Turning
    these reports into accurate annotations or structured labels in an automated manner
    requires sophisticated text-mining methods, which is an important field of study
    in itself where deep learning is also widely used nowadays. With the introduction
    of structured reporting into several areas of medicine, extracting labels to data
    is expected to become easier in the future. For example, there are already papers
    appearing which directly leverage BI-RADS categorizations by radiologist to train
    deep networks (Kisilev et al., [2016](#bib.bib159)) or semantic descriptions in
    analyzing optical coherence tomography images (Schlegl et al., [2015](#bib.bib247)).
    We expect the amount of research in optimally leveraging free-text and structured
    reports for network training to increase in the near future.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，主要挑战不在于图像数据本身的可用性，而在于获取这些图像的相关注释/标签。传统上，PACS系统存储放射科医师描述其发现的自由文本报告。将这些报告转换为准确的注释或结构化标签的自动化方法需要复杂的文本挖掘方法，这本身就是一个重要的研究领域，而深度学习现在也被广泛应用于此。随着结构化报告在医学多个领域的引入，预计未来提取数据标签将变得更加容易。例如，已经有论文直接利用放射科医师的BI-RADS分类来训练深度网络（Kisilev
    et al., [2016](#bib.bib159)）或在分析光学相干断层扫描图像中的语义描述（Schlegl et al., [2015](#bib.bib247)）。我们预计在不久的将来，利用自由文本和结构化报告进行网络训练的研究量将会增加。
- en: Given the complexity of leveraging free-text reports from PACS or similar systems
    to train algorithms, generally researchers request domain experts (e.g. radiologist,
    pathologists) to make task-specific annotations for the image data. Labeling a
    sufficiently large dataset can take a significant amount of time, and this is
    problematic. For example, to train deep learning systems for segmentation in radiology
    often 3D, slice-by-slice annotations need to be made and this is very time consuming.
    Thus, learning efficiently from limited data is an important area of research
    in medical image analysis. A recent paper focused on training a deep learning
    segmentation system for 3D segmentation using only sparse 2D segmentations (Çiçek
    et al., [2016](#bib.bib65)). Multiple-instance or active learning approaches might
    also offer benefit in some cases, and have recently been pursued in the context
    of deep learning (Yan et al., [2016](#bib.bib326)). One can also consider leveraging
    non-expert labels via crowd-sourcing (Rajchl et al., [2016b](#bib.bib225)). Other
    potential solutions can be found within the medical field itself; in histopathology
    one can sometimes use specific immunohistochemical stains to highlight regions
    of interest, reducing the need for expert experience (Turkki et al., [2016](#bib.bib292)).
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于从PACS或类似系统中利用自由文本报告来训练算法的复杂性，研究人员通常会要求领域专家（如**放射科医师**、**病理学家**）为图像数据做特定任务的标注。标注一个足够大的数据集可能需要大量时间，这一点非常棘手。例如，为了训练放射学中的深度学习系统进行分割，通常需要逐切片进行3D标注，这非常耗时。因此，从有限数据中高效学习是医学图像分析中的一个重要研究领域。最近的一篇论文专注于使用稀疏的2D分割训练深度学习分割系统进行3D分割（Çiçek
    et al., [2016](#bib.bib65)）。多实例或主动学习方法在某些情况下也可能有益，最近也在深度学习的背景下进行研究（Yan et al.,
    [2016](#bib.bib326)）。还可以考虑通过众包利用非专家标签（Rajchl et al., [2016b](#bib.bib225)）。在医学领域内部也可以找到其他潜在的解决方案；在组织病理学中，有时可以使用特定的免疫组化染色来突出兴趣区域，从而减少对专家经验的需求（Turkki
    et al., [2016](#bib.bib292)）。
- en: Even when data is annotated by domain expert, label noise can be a significant
    limiting factor in developing algorithms, whereas in computer vision the noise
    in the labeling of images is typically relatively low. To give an example, a widely
    used dataset for evaluating image analysis algorithms to detect nodules in lung
    CT is the LIDC-IDRI dataset (Armato et al., [2011](#bib.bib14)). In this dataset
    pulmonary nodules were annotated by four radiologists independently. Subsequently
    the readers reviewed each others annotations but no consensus was forced. It turned
    out that the number of nodules they did not unanimously agreed on to be a nodule,
    was three times larger than the number they did fully agree on. Training a deep
    learning system on such data requires careful consideration of how to deal with
    noise and uncertainty in the reference standard. One could think of solutions
    like incorporating labeling uncertainty directly in the loss function, but this
    is still an open challenge.
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 即使数据是由领域专家注释的，标签噪声也可能成为开发算法的重要限制因素，而在计算机视觉中，图像标签的噪声通常相对较低。例如，用于评估图像分析算法以检测肺部CT结节的广泛使用的数据集是LIDC-IDRI数据集（Armato
    et al., [2011](#bib.bib14)）。在这个数据集中，肺结节由四位放射科医生独立注释。随后，读者们审阅了彼此的注释，但没有强制达成共识。结果发现，他们未能一致同意的结节数量是完全一致同意的结节数量的三倍。对这样的数据进行深度学习系统的训练需要仔细考虑如何处理参考标准中的噪声和不确定性。可以考虑将标签不确定性直接纳入损失函数中，但这仍然是一个未解决的挑战。
- en: 'In medical imaging often classification or segmentation is presented as a binary
    task: normal versus abnormal, object versus background. However, this is often
    a gross simplification as both classes can be highly heterogeneous. For example,
    the normal category often consists of completely normal tissue but also several
    categories of benign findings, which can be rare, and may occasionally include
    a wide variety of imaging artifacts. This often leads to systems that are extremely
    good at excluding the most common normal subclasses, but fail miserably on several
    rare ones. A straightforward solution would be to turn the deep learning system
    in a multi-class system by providing it with detailed annotations of all possible
    subclasses. Obviously this again compounds the issue of limited availability of
    expert time for annotating and is therefore often simply not feasible. Some researchers
    have specifically looked into tackling this imbalance by incorporating intelligence
    in the training process itself, by applying selective sampling (van Grinsven et al.,
    [2016](#bib.bib296)) or hard negative mining (Wang et al., [2016b](#bib.bib303)).
    However, such strategies typically fail when there is substantial noise in the
    reference standard. Additional methods for dealing with within-class heterogeneity
    would be highly welcome.'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 在医学成像中，分类或分割通常被呈现为二分类任务：正常与异常、对象与背景。然而，这往往是一个粗略的简化，因为这两个类别可能具有很大的异质性。例如，正常类别通常包括完全正常的组织，但也包括几种良性发现，这些发现可能很少见，并且有时可能包括各种影像伪影。这通常导致系统在排除最常见的正常子类方面非常有效，但在一些稀有子类上表现糟糕。一个简单的解决方案是将深度学习系统转变为多类别系统，提供所有可能子类的详细注释。显然，这又加剧了专家注释时间有限的问题，因此通常不切实际。一些研究人员专门研究通过在训练过程中引入智能来解决这种不平衡，采用选择性采样（van
    Grinsven et al., [2016](#bib.bib296)）或困难负样本挖掘（Wang et al., [2016b](#bib.bib303)）。然而，这些策略通常在参考标准中存在大量噪声时效果不佳。额外的处理类内异质性的方法将非常受欢迎。
- en: Another data-related challenge is class imbalance. In medical imaging, images
    for the abnormal class might be challenging to find, depending on the task at
    hand. As an example, the implementation of breast cancer screening programs has
    resulted in vast databases of mammograms that have been established at many locations
    world-wide. However, the majority of these images are normal and do not contain
    any suspicious lesions. When a mammogram does contain a suspicious lesion this
    is often not cancerous, and even most cancerous lesions will not lead to the death
    of a patient. Designing deep learning systems that are adept at handling this
    class imbalance is another important area of research. A typical strategy we encountered
    in current literature is the application of specific data augmentation algorithms
    to just the underrepresented class, for example scaling and rotation transforms
    to generate new lesions. Pereira et al. ([2016](#bib.bib214)) performed a thorough
    evaluation of data augmentation strategies for brain lesion segmentation to combat
    class imbalance.
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个与数据相关的挑战是类别不平衡。在医学影像中，根据具体任务，异常类别的图像可能很难找到。例如，乳腺癌筛查项目的实施在全球多个地点建立了大量乳腺X光照片数据库。然而，这些图像中的大多数都是正常的，并且不包含任何可疑的病变。当乳腺X光照片确实包含可疑病变时，这通常并非癌症，而且即使大多数癌性病变也不会导致患者死亡。设计能够处理这种类别不平衡的深度学习系统是另一个重要的研究领域。我们在当前文献中遇到的一个典型策略是对仅代表性不足的类别应用特定的数据增强算法，例如缩放和旋转变换以生成新的病变。Pereira等人（[2016](#bib.bib214)）对用于脑部病变分割的数据增强策略进行了全面评估，以应对类别不平衡问题。
- en: In medical image analysis useful information is not just contained within the
    images themselves. Physicians often leverage a wealth of data on patient history,
    age, demographics and others to arrive at better decisions. Some authors have
    already investigated combining this information into deep learning networks in
    a straightforward manner (Kooi et al., [2017](#bib.bib163)). However, as these
    authors note, the improvements that were obtained were not as large as expected.
    One of the challenges is to balance the number of imaging features in the deep
    learning network (typically thousands) with the number of clinical features (typically
    only a handful) to prevent the clinical features from being drowned out. Physicians
    often also need to use anatomical information to come to an accurate diagnosis.
    However, many deep learning systems in medical imaging are still based on patch
    classification, where the anatomical location of the patch is often unknown to
    network. One solution would be to feed the entire image to the deep network and
    use a different type of evaluation to drive learning, as was done by, for example,
    Milletari et al. ([2016b](#bib.bib194)), who designed a loss function based on
    the Dice coefficient. This also takes advantage of the fact that medical images
    are often acquired using a relatively static protocol, where the anatomy is always
    roughly in the same position and at the same scale. However, as mentioned above,
    if the receptive field of the network is small feeding in the entire image offers
    no benefit. Furthermore, feeding full images to the network is not always feasible
    due to, for example, memory constraints. In some cases this might be solved in
    the near future due to advances in GPU technology, but in others, for example
    digital pathology with its gigapixel-sized images, other strategies have to be
    invented.
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 在医学图像分析中，有用的信息不仅仅存在于图像本身。医生通常会利用关于患者病史、年龄、人口统计信息等大量数据来做出更好的决策。一些作者已经研究了将这些信息以直接的方式融入深度学习网络（Kooi等人，[2017](#bib.bib163)）。然而，正如这些作者所指出的，所获得的改进并没有达到预期的程度。一个挑战是平衡深度学习网络中的成像特征数量（通常为数千个）与临床特征数量（通常仅有几个），以防止临床特征被淹没。医生们通常还需要使用解剖信息来进行准确诊断。然而，许多医学影像中的深度学习系统仍基于补丁分类，其中补丁的解剖位置网络往往是未知的。一个解决方案是将整个图像输入深度网络，并使用不同类型的评估来驱动学习，例如Milletari等人（[2016b](#bib.bib194)）设计了一种基于Dice系数的损失函数。这也利用了医学图像通常使用相对静态的协议进行采集的事实，其中解剖结构总是大致处于相同的位置和相同的尺度。然而，如上所述，如果网络的感受野较小，输入整个图像没有任何好处。此外，由于内存限制，将完整图像输入网络并不总是可行。在某些情况下，这可能由于GPU技术的进步而在不久的将来得到解决，但在其他情况下，例如具有千兆像素图像的数字病理学，则需要发明其他策略。
- en: Outlook
  id: totrans-594
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 展望
- en: Although most of the challenges mentioned above have not been adequately tackled
    yet, several high-profile successes of deep learning in medical imaging have been
    reported, such as the work by Esteva et al. ([2017](#bib.bib89)) and Gulshan et al.
    ([2016](#bib.bib115)) in the fields of dermatology and ophthalmology. Both papers
    show that it is possible to outperform medical experts in certain tasks using
    deep learning for image classification. However, we feel it is important to put
    these papers into context relative to medical image analysis in general, as most
    tasks can by no means be considered ’solved’. One aspect to consider is that both
    Esteva et al. ([2017](#bib.bib89)) and Gulshan et al. ([2016](#bib.bib115)) focus
    on small 2D color image classification, which is relatively similar to the tasks
    that have been tackled in computer vision (e.g. ImageNet). This allows them to
    take advantage of well-explored network architectures like ResNet and VGG-Net
    which have shown to have excellent results in these tasks. However, there is no
    guarantee that these architectures are optimal in for example regressions/detection
    tasks. It also allowed the authors to use networks that were pre-trained on a
    very well-labeled dataset of millions of natural images, which helps combat the
    lack of similarly large, labeled medical datasets. In contrast, in most medical
    imaging tasks 3D gray-scale or multi-channel images are used for which pre-trained
    networks or architectures don’t exist. In addition this data typically has very
    specific challenges, like anisotropic voxel sizes, small registration errors between
    varying channels (e.g. in multi-parametric MRI) or varying intensity ranges. Although
    many tasks in medical image analysis can be postulated as a classification problem,
    this might not always be the optimal strategy as it typically requires some form
    of post-processing with non-deep learning methods (e.g. counting, segmentation
    or regression tasks). An interesting example is the paper by Sirinukunwattana
    et al. ([2016](#bib.bib265)), which details a method directly predicting the center
    locations of nuclei and shows that this outperforms classification-based center
    localization. Nonetheless, the papers by Esteva et al. ([2017](#bib.bib89)) and
    Gulshan et al. ([2016](#bib.bib115)) do show what ideally is possible with deep
    learning methods that are well-engineered for specific medical image analysis
    tasks.
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管上述大多数挑战尚未得到充分解决，但已有多项关于深度学习在医学影像中的成功案例被报道，例如Esteva等人（[2017](#bib.bib89)）和Gulshan等人（[2016](#bib.bib115)）在皮肤科和眼科领域的研究。两篇论文都显示，利用深度学习进行图像分类在某些任务上可以超越医学专家。然而，我们认为有必要将这些论文放在医学影像分析的一般背景中，因为大多数任务还远未被认为是“解决了”的。一方面需要考虑的是，Esteva等人（[2017](#bib.bib89)）和Gulshan等人（[2016](#bib.bib115)）都专注于小型2D彩色图像分类，这与计算机视觉中处理的任务（例如ImageNet）相对相似。这使得他们能够利用像ResNet和VGG-Net这样的成熟网络架构，这些架构在这些任务中表现出色。然而，这些架构在回归/检测任务中是否最优尚无保证。此外，这还使得作者能够使用在大量标记良好的自然图像数据集上预训练的网络，这有助于应对医学数据集的标记不足。相比之下，大多数医学影像任务使用的是3D灰度图像或多通道图像，对于这些图像，尚不存在预训练的网络或架构。此外，这些数据通常面临特定的挑战，如各向异性体素尺寸、不同通道之间的小注册误差（例如在多参数MRI中）或不同的强度范围。尽管许多医学影像分析任务可以被看作分类问题，但这可能不是最佳策略，因为这通常需要一些形式的后处理（例如计数、分割或回归任务）。一个有趣的例子是Sirinukunwattana等人（[2016](#bib.bib265)）的论文，该论文详细描述了一种直接预测细胞核中心位置的方法，并表明这种方法优于基于分类的中心定位。然而，Esteva等人（[2017](#bib.bib89)）和Gulshan等人（[2016](#bib.bib115)）的论文确实展示了在特定医学影像分析任务中，深度学习方法在理想情况下的潜力。
- en: 'Looking at current trends in the machine learning community with respect to
    deep learning, we identify a key area which can be highly relevant for medical
    imaging and is receiving (renewed) interest: unsupervised learning. The renaissance
    of neural networks started around 2006 with the popularization of greedy layer-wise
    pre-training of neural networks in an unsupervised manner. This was quickly superseded
    by fully supervised methods which became the standard after the success of AlexNet
    during the ImageNet competition of 2012, and most papers in this survey follow
    a supervised approach. However, interest in unsupervised training strategies has
    remained and recently has regained traction.'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 从当前深度学习领域的趋势来看，我们识别出一个对医学成像具有高度相关性的关键领域，并且正在受到（重新）关注：无监督学习。神经网络的复兴始于2006年，当时无监督方式下神经网络的贪婪层次预训练开始普及。这很快被完全监督的方法所取代，后者在2012年ImageNet比赛中AlexNet的成功后成为了标准，而本次调查中的大多数论文都采用了监督方法。然而，对无监督训练策略的兴趣依然存在，并且最近重新获得了关注。
- en: Unsupervised methods are attractive as they allow (initial) network training
    with the wealth of unlabeled data available in the world. Another reason to assume
    that unsupervised methods will still have a significant role to play is the analogue
    to human learning, which seems to be much more data efficient and also happens
    to some extent in an unsupervised manner; we can learn to recognize objects and
    structures without knowing the specific label. We only need very limited supervision
    to categorize these recognized objects into classes. Two novel unsupervised strategies
    which we expect to have an impact in medical imaging are variational auto-encoders
    (VAEs), introduced by Kingma and Welling ([2013](#bib.bib158)) and generative
    adversarial networks (GANs), introduced by Goodfellow et al. ([2014](#bib.bib113)).
    The former merges variational Bayesian graphical models with neural networks as
    encoders/decoders. The latter uses two competing convolutional neural networks
    where one is generating artificial data samples and the other is discriminating
    artificial from real samples. Both have stochastic components and are generative
    networks. Most importantly, they can be trained end-to-end and learn representative
    features in a completely unsupervised manner. As we discussed in previous paragraphs,
    obtaining large amounts of unlabeled medical data is generally much easier than
    labeled data and unsupervised methods like VAEs and GANs could optimally leverage
    this wealth of information.
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督方法具有吸引力，因为它们允许使用世界上丰富的未标记数据进行（初步）网络训练。另一个认为无监督方法仍将发挥重要作用的原因是类比于人类学习，人类学习似乎更加高效，且在某种程度上是以无监督的方式进行的；我们可以在不知道具体标签的情况下学习识别对象和结构。我们只需要非常有限的监督即可将这些识别出的对象分类到不同类别中。我们预计在医学成像中会产生影响的两种新型无监督策略是变分自编码器（VAEs），由Kingma和Welling（[2013](#bib.bib158)）提出，以及生成对抗网络（GANs），由Goodfellow等（[2014](#bib.bib113)）提出。前者将变分贝叶斯图模型与神经网络作为编码器/解码器相结合。后者使用两个竞争的卷积神经网络，一个生成人工数据样本，另一个则区分人工样本与真实样本。两者都有随机组件，并且都是生成网络。最重要的是，它们可以端到端地训练，并以完全无监督的方式学习代表性特征。正如我们在前面的段落中讨论的那样，获取大量未标记的医学数据通常比获取标记数据容易得多，而无监督方法如VAEs和GANs可以充分利用这一信息财富。
- en: Finally, deep learning methods have often been described as ‘black boxes’. Especially
    in medicine, where accountability is important and can have serious legal consequences,
    it is often not enough to have a good prediction system. This system also has
    to be able to articulate itself in a certain way. Several strategies have been
    developed to understand what intermediate layers of convolutional networks are
    responding to, for example deconvolution networks (Zeiler and Fergus, [2014](#bib.bib338)),
    guided back-propagation (Springenberg et al., [2014](#bib.bib271)) or deep Taylor
    composition (Montavon et al., [2017](#bib.bib198)). Other researchers have tied
    prediction to textual representations of the image (i.e. captioning) (Karpathy
    and Fei-Fei, [2015](#bib.bib149)), which is another useful avenue to understand
    what a network is perceiving. Last, some groups have tried to combine Bayesian
    statistics with deep networks to obtain true network uncertainty estimates Kendall
    and Gal ([2017](#bib.bib154)). This would allow physicians to assess when the
    network is giving unreliable predictions. Leveraging these techniques in the application
    of deep learning methods to medical image analysis could accelerate acceptance
    of deep learning applications among clinicians, and among patients. We also foresee
    deep learning approaches will be used for related tasks in medical imaging, mostly
    unexplored, such as image reconstruction (Wang, [2016](#bib.bib304)). Deep learning
    will thus not only have a great impact in medical image analysis, but in medical
    imaging as a whole.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，深度学习方法常被描述为“黑箱”。特别是在医学领域，其中责任至关重要，并且可能带来严重的法律后果，拥有一个好的预测系统往往还不够。该系统还必须以某种方式进行自我表述。已经开发了几种策略来理解卷积网络的中间层响应，例如反卷积网络（Zeiler
    和 Fergus，[2014](#bib.bib338)）、引导反向传播（Springenberg 等，[2014](#bib.bib271)）或深度泰勒分解（Montavon
    等，[2017](#bib.bib198)）。其他研究者将预测与图像的文本表示（即图像说明）相关联（Karpathy 和 Fei-Fei，[2015](#bib.bib149)），这也是理解网络感知内容的另一种有用途径。最后，一些小组尝试将贝叶斯统计与深度网络结合，以获得真实的网络不确定性估计（Kendall
    和 Gal，[2017](#bib.bib154)）。这将使医生能够评估网络何时提供不可靠的预测。利用这些技术应用于医学图像分析中的深度学习方法，可能会加速临床医生和患者对深度学习应用的接受。我们还预见到深度学习方法将用于医学影像中相关的、主要未被探索的任务，例如图像重建（Wang，[2016](#bib.bib304)）。因此，深度学习不仅会对医学图像分析产生重大影响，也会对医学影像整体产生影响。
- en: Acknowledgments
  id: totrans-599
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: The authors would like to thank members of the Diagnostic Image Analysis Group
    for discussions and suggestions. This research was funded by grants KUN 2012-5577,
    KUN 2014-7032, and KUN 2015-7970 of the Dutch Cancer Society.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们感谢诊断影像分析组的成员们的讨论和建议。本研究由荷兰癌症协会的资助（KUN 2012-5577, KUN 2014-7032, 和 KUN 2015-7970）资助。
- en: 'Appendix A: Literature selection'
  id: totrans-601
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A：文献选择
- en: 'PubMed was searched for papers containing ”convolutional” OR ”deep learning”
    in any field. We specifically did not include the term neural network here as
    this would result in an enormous amount of ’false positive’ papers covering brain
    research. This search initially gave over 700 hits. ArXiv was searched for papers
    mentioning one of a set of terms related to medical imaging. The exact search
    string was: ’abs:((medical OR mri OR ”magnetic resonance” OR CT OR ”computed tomography”
    OR ultrasound OR pathology OR xray OR x-ray OR radiograph OR mammography OR fundus
    OR OCT) AND (”deep learning” OR convolutional OR cnn OR ”neural network”))’. Conference
    proceedings for MICCAI (including workshops), SPIE, ISBI and EMBC were searched
    based on titles of papers. Again we looked for mentions of ’deep learning’ or
    ’convolutional’ or ’neural network’. We went over all these papers and excluded
    the ones that did not discuss medical imaging (e.g. applications to genetics,
    chemistry), only used handcrafted features in combination with neural networks,
    or only referenced deep learning as future work. When in doubt whether a paper
    should be included we read the abstract and when the exact methodology was still
    unclear we read the paper itself. We checked references in all selected papers
    iteratively and consulted colleagues to identify any papers which were missed
    by our initial search. When largely overlapping work had been reported in multiple
    publications, only the publication deemed most important was included. A typical
    example here was arXiv preprints that were subsequently published or conference
    contributions which were expanded and published in journals.'
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 在 PubMed 中搜索包含“convolutional” OR “deep learning”的任何领域的论文。我们特意没有包含“neural network”这个术语，因为这会导致大量‘假阳性’论文涉及脑部研究。这次搜索最初得到了700多个结果。ArXiv
    中搜索提到一组与医学影像相关的术语的论文。确切的搜索字符串是：’abs:((medical OR mri OR “magnetic resonance” OR
    CT OR “computed tomography” OR ultrasound OR pathology OR xray OR x-ray OR radiograph
    OR mammography OR fundus OR OCT) AND (“deep learning” OR convolutional OR cnn
    OR “neural network”))’。根据论文标题搜索了MICCAI（包括研讨会）、SPIE、ISBI 和 EMBC 的会议论文集。再次寻找提到“deep
    learning”或“convolutional”或“neural network”的论文。我们查阅了所有这些论文，并排除了那些没有讨论医学影像的论文（例如，应用于遗传学、化学的论文），仅使用手工特征与神经网络结合的论文，或者仅将深度学习提及为未来工作的论文。在不确定论文是否应包含时，我们会阅读摘要，当确切的方法仍不清楚时，我们会阅读论文本身。我们迭代检查所有选定论文中的参考文献，并咨询同事以确定是否遗漏了我们初次搜索的论文。当在多篇出版物中报告了大致重叠的工作时，只包含了被认为最重要的出版物。一个典型的例子是，arXiv
    预印本随后被发表或会议贡献被扩展并在期刊上发表的情况。
- en: References
  id: totrans-603
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: References
  id: totrans-604
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Abadi et al. (2016) Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z.,
    Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow,
    I., Harp, A., Irving, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur,
    M., Levenberg, J., Mane, D., Monga, R., Moore, S., Murray, D., Olah, C., Schuster,
    M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke,
    V., Vasudevan, V., Viegas, F., Vinyals, O., Warden, P., Wattenberg, M., Wicke,
    M., Yu, Y., Zheng, X., 2016\. Tensorflow: Large-scale machine learning on heterogeneous
    distributed systems. arXiv:1603.04467.'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Abadi 等（2016）Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro,
    C., Corrado, G. S., Davis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow,
    I., Harp, A., Irving, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur,
    M., Levenberg, J., Mane, D., Monga, R., Moore, S., Murray, D., Olah, C., Schuster,
    M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke,
    V., Vasudevan, V., Viegas, F., Vinyals, O., Warden, P., Wattenberg, M., Wicke,
    M., Yu, Y., Zheng, X., 2016\. Tensorflow: 大规模机器学习在异构分布式系统上的应用。arXiv:1603.04467。'
- en: Abràmoff et al. (2016) Abràmoff, M. D., Lou, Y., Erginay, A., Clarida, W., Amelon,
    R., Folk, J. C., Niemeijer, M., 2016\. Improved automated detection of diabetic
    retinopathy on a publicly available dataset through integration of deep learning.
    Invest Ophthalmol Vis Sci 57 (13), 5200–5206.
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abràmoff 等（2016）Abràmoff, M. D., Lou, Y., Erginay, A., Clarida, W., Amelon,
    R., Folk, J. C., Niemeijer, M., 2016\. 通过深度学习的整合，在一个公开可用的数据集上改进了糖尿病视网膜病变的自动检测。Invest
    Ophthalmol Vis Sci 57 (13), 5200–5206。
- en: 'Akram et al. (2016) Akram, S. U., Kannala, J., Eklund, L., Heikkilä, J., 2016\.
    Cell segmentation proposal network for microscopy image analysis. In: DLMIA. Vol.
    10008 of Lect Notes Comput Sci. pp. 21–29.'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Akram 等（2016）Akram, S. U., Kannala, J., Eklund, L., Heikkilä, J., 2016\. 用于显微镜图像分析的细胞分割提案网络。载于：DLMIA。第10008卷的
    Lect Notes Comput Sci，第21–29页。
- en: 'Akselrod-Ballin et al. (2016) Akselrod-Ballin, A., Karlinsky, L., Alpert, S.,
    Hasoul, S., Ben-Ari, R., Barkan, E., 2016\. A region based convolutional network
    for tumor detection and classification in breast mammography. In: DLMIA. Vol.
    10008 of Lect Notes Comput Sci. pp. 197–205.'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Akselrod-Ballin等（2016）Akselrod-Ballin, A., Karlinsky, L., Alpert, S., Hasoul,
    S., Ben-Ari, R., Barkan, E., 2016\. 基于区域的卷积网络用于乳腺X光中的肿瘤检测和分类。发表于：DLMIA。第10008卷，Lect
    Notes Comput Sci。第197–205页。
- en: 'Alansary et al. (2016) Alansary, A., Kamnitsas, K., Davidson, A., Khlebnikov,
    R., Rajchl, M., Malamateniou, C., Rutherford, M., Hajnal, J. V., Glocker, B.,
    Rueckert, D., Kainz, B., 2016\. Fast fully automatic segmentation of the human
    placenta from motion corrupted MRI. In: Med Image Comput Comput Assist Interv.
    Vol. 9901 of Lect Notes Comput Sci. pp. 589–597.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alansary等（2016）Alansary, A., Kamnitsas, K., Davidson, A., Khlebnikov, R., Rajchl,
    M., Malamateniou, C., Rutherford, M., Hajnal, J. V., Glocker, B., Rueckert, D.,
    Kainz, B., 2016\. 快速全自动分割运动干扰下的胎盘MRI。发表于：Med Image Comput Comput Assist Interv。第9901卷，Lect
    Notes Comput Sci。第589–597页。
- en: 'Albarqouni et al. (2016) Albarqouni, S., Baur, C., Achilles, F., Belagiannis,
    V., Demirci, S., Navab, N., 2016\. AggNet: Deep learning from crowds for mitosis
    detection in breast cancer histology images. IEEE Trans Med Imaging 35, 1313–1321.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Albarqouni等（2016）Albarqouni, S., Baur, C., Achilles, F., Belagiannis, V., Demirci,
    S., Navab, N., 2016\. AggNet：基于人群的深度学习用于乳腺癌组织学图像中的有丝分裂检测。IEEE Trans Med Imaging
    35, 1313–1321。
- en: 'Anavi et al. (2015) Anavi, Y., Kogan, I., Gelbart, E., Geva, O., Greenspan,
    H., 2015\. A comparative study for chest radiograph image retrieval using binary
    texture and deep learning classification. In: Conf Proc IEEE Eng Med Biol Soc.
    pp. 2940–2943.'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anavi等（2015）Anavi, Y., Kogan, I., Gelbart, E., Geva, O., Greenspan, H., 2015\.
    使用二值纹理和深度学习分类的胸部X光图像检索比较研究。发表于：Conf Proc IEEE Eng Med Biol Soc。第2940–2943页。
- en: 'Anavi et al. (2016) Anavi, Y., Kogan, I., Gelbart, E., Geva, O., Greenspan,
    H., 2016\. Visualizing and enhancing a deep learning framework using patients
    age and gender for chest X-ray image retrieval. In: Medical Imaging. Vol. 9785
    of Proceedings of the SPIE. p. 978510.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anavi等（2016）Anavi, Y., Kogan, I., Gelbart, E., Geva, O., Greenspan, H., 2016\.
    使用患者年龄和性别可视化和增强深度学习框架用于胸部X光图像检索。发表于：Medical Imaging。第9785卷，Proceedings of the
    SPIE。第978510页。
- en: 'Andermatt et al. (2016) Andermatt, S., Pezold, S., Cattin, P., 2016\. Multi-dimensional
    gated recurrent units for the segmentation of biomedical 3D-data. In: DLMIA. Vol.
    10008 of Lect Notes Comput Sci. pp. 142–151.'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Andermatt等（2016）Andermatt, S., Pezold, S., Cattin, P., 2016\. 用于生物医学三维数据分割的多维门控递归单元。发表于：DLMIA。第10008卷，Lect
    Notes Comput Sci。第142–151页。
- en: Anthimopoulos et al. (2016) Anthimopoulos, M., Christodoulidis, S., Ebner, L.,
    Christe, A., Mougiakakou, S., 2016\. Lung pattern classification for interstitial
    lung diseases using a deep convolutional neural network. IEEE Trans Med Imaging
    35 (5), 1207–1216.
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthimopoulos等（2016）Anthimopoulos, M., Christodoulidis, S., Ebner, L., Christe,
    A., Mougiakakou, S., 2016\. 使用深度卷积神经网络的间质性肺疾病肺部模式分类。IEEE Trans Med Imaging 35
    (5), 1207–1216。
- en: Antony et al. (2016) Antony, J., McGuinness, K., Connor, N. E. O., Moran, K.,
    2016\. Quantifying radiographic knee osteoarthritis severity using deep convolutional
    neural networks. arXiv:1609.02469.
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Antony等（2016）Antony, J., McGuinness, K., Connor, N. E. O., Moran, K., 2016\.
    使用深度卷积神经网络量化X光膝关节骨关节炎的严重程度。arXiv:1609.02469。
- en: Apou et al. (2016) Apou, G., Schaadt, N. S., Naegel, B., Forestier, G., Schönmeyer,
    R., Feuerhake, F., Wemmert, C., Grote, A., 2016\. Detection of lobular structures
    in normal breast tissue. Comput Biol Med 74, 91–102.
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apou等（2016）Apou, G., Schaadt, N. S., Naegel, B., Forestier, G., Schönmeyer,
    R., Feuerhake, F., Wemmert, C., Grote, A., 2016\. 正常乳腺组织中的小叶结构检测。Comput Biol Med
    74, 91–102。
- en: Arevalo et al. (2016) Arevalo, J., González, F. A., Ramos-Pollán, R., Oliveira,
    J. L., Guevara Lopez, M. A., 2016\. Representation learning for mammography mass
    lesion classification with convolutional neural networks. Comput Methods Programs
    Biomed 127, 248–257.
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arevalo等（2016）Arevalo, J., González, F. A., Ramos-Pollán, R., Oliveira, J. L.,
    Guevara Lopez, M. A., 2016\. 使用卷积神经网络进行乳腺X光筛查肿块病变分类的表征学习。Comput Methods Programs
    Biomed 127, 248–257。
- en: 'Armato et al. (2011) Armato, S. G., McLennan, G., Bidaut, L., McNitt-Gray,
    M. F., Meyer, C. R., Reeves, A. P., Zhao, B., Aberle, D. R., Henschke, C. I.,
    Hoffman, E. A., Kazerooni, E. A., MacMahon, H., Beek, E. J. R. V., Yankelevitz,
    D., Biancardi, A. M., Bland, P. H., Brown, M. S., Engelmann, R. M., Laderach,
    G. E., Max, D., Pais, R. C., Qing, D. P. Y., Roberts, R. Y., Smith, A. R., Starkey,
    A., Batrah, P., Caligiuri, P., Farooqi, A., Gladish, G. W., Jude, C. M., Munden,
    R. F., Petkovska, I., Quint, L. E., Schwartz, L. H., Sundaram, B., Dodd, L. E.,
    Fenimore, C., Gur, D., Petrick, N., Freymann, J., Kirby, J., Hughes, B., Casteele,
    A. V., Gupte, S., Sallamm, M., Heath, M. D., Kuhn, M. H., Dharaiya, E., Burns,
    R., Fryd, D. S., Salganicoff, M., Anand, V., Shreter, U., Vastagh, S., Croft,
    B. Y., 2011\. The lung image database consortium (LIDC) and image database resource
    initiative (IDRI): a completed reference database of lung nodules on CT scans.
    Med Phys 38, 915–931.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Armato 等（2011）Armato, S. G., McLennan, G., Bidaut, L., McNitt-Gray, M. F., Meyer,
    C. R., Reeves, A. P., Zhao, B., Aberle, D. R., Henschke, C. I., Hoffman, E. A.,
    Kazerooni, E. A., MacMahon, H., Beek, E. J. R. V., Yankelevitz, D., Biancardi,
    A. M., Bland, P. H., Brown, M. S., Engelmann, R. M., Laderach, G. E., Max, D.,
    Pais, R. C., Qing, D. P. Y., Roberts, R. Y., Smith, A. R., Starkey, A., Batrah,
    P., Caligiuri, P., Farooqi, A., Gladish, G. W., Jude, C. M., Munden, R. F., Petkovska,
    I., Quint, L. E., Schwartz, L. H., Sundaram, B., Dodd, L. E., Fenimore, C., Gur,
    D., Petrick, N., Freymann, J., Kirby, J., Hughes, B., Casteele, A. V., Gupte,
    S., Sallamm, M., Heath, M. D., Kuhn, M. H., Dharaiya, E., Burns, R., Fryd, D.
    S., Salganicoff, M., Anand, V., Shreter, U., Vastagh, S., Croft, B. Y., 2011\.
    肺部影像数据库联盟（LIDC）和影像数据库资源倡议（IDRI）：一个完整的 CT 扫描肺结节参考数据库。医学物理 38, 915–931。
- en: Avendi et al. (2016) Avendi, M., Kheradvar, A., Jafarkhani, H., 2016\. A combined
    deep-learning and deformable-model approach to fully automatic segmentation of
    the left ventricle in cardiac MRI. Med Image Anal 30, 108–119.
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Avendi 等（2016）Avendi, M., Kheradvar, A., Jafarkhani, H., 2016\. 结合深度学习和可变形模型的方法进行心脏
    MRI 左心室的完全自动分割。医学图像分析 30, 108–119。
- en: 'Azizi et al. (2016) Azizi, S., Imani, F., Ghavidel, S., Tahmasebi, A., Kwak,
    J. T., Xu, S., Turkbey, B., Choyke, P., Pinto, P., Wood, B., Mousavi, P., Abolmaesumi,
    P., 2016\. Detection of prostate cancer using temporal sequences of ultrasound
    data: a large clinical feasibility study. Int J Comput Assist Radiol Surg 11 (6),
    947–956.'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azizi 等（2016）Azizi, S., Imani, F., Ghavidel, S., Tahmasebi, A., Kwak, J. T.,
    Xu, S., Turkbey, B., Choyke, P., Pinto, P., Wood, B., Mousavi, P., Abolmaesumi,
    P., 2016\. 使用超声数据的时间序列检测前列腺癌：一项大型临床可行性研究。计算辅助放射学与外科杂志 11 (6), 947–956。
- en: 'Bahrami et al. (2016) Bahrami, K., Shi, F., Rekik, I., Shen, D., 2016\. Convolutional
    neural network for reconstruction of 7T-like images from 3T MRI using appearance
    and anatomical features. In: DLMIA. Vol. 10008 of Lect Notes Comput Sci. pp. 39–47.'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bahrami 等（2016）Bahrami, K., Shi, F., Rekik, I., Shen, D., 2016\. 基于外观和解剖特征的卷积神经网络，用于从
    3T MRI 重建 7T 类图像。见：DLMIA。第10008卷，计算机科学讲义笔记。第39–47页。
- en: 'Bao and Chung (2016) Bao, S., Chung, A. C., 2016\. Multi-scale structured CNN
    with label consistency for brain MR image segmentation. Computer Methods in Biomechanics
    and Biomedical Engineering: Imaging & Visualization, 1–5.'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bao 和 Chung（2016）Bao, S., Chung, A. C., 2016\. 多尺度结构化卷积神经网络与标签一致性用于脑部 MR 图像分割。计算方法在生物力学和生物医学工程：成像与可视化，1–5。
- en: 'Bar et al. (2015) Bar, Y., Diamant, I., Wolf, L., Greenspan, H., 2015\. Deep
    learning with non-medical training used for chest pathology identification. In:
    Medical Imaging. Vol. 9414 of Proceedings of the SPIE. p. 94140V.'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bar 等（2015）Bar, Y., Diamant, I., Wolf, L., Greenspan, H., 2015\. 使用非医学训练的深度学习进行胸部病理识别。见：医学成像。第9414卷，SPIE会议录。第94140V页。
- en: 'Bar et al. (2016) Bar, Y., Diamant, I., Wolf, L., Lieberman, S., Konen, E.,
    Greenspan, H., 2016. Chest pathology identification using deep feature selection
    with non-medical training. Computer Methods in Biomechanics and Biomedical Engineering:
    Imaging & Visualization, 1–5.'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bar 等（2016）Bar, Y., Diamant, I., Wolf, L., Lieberman, S., Konen, E., Greenspan,
    H., 2016\. 使用深度特征选择和非医学训练的胸部病理识别。计算方法在生物力学和生物医学工程：成像与可视化，1–5。
- en: 'Barbu et al. (2016) Barbu, A., Lu, L., Roth, H., Seff, A., Summers, R. M.,
    2016\. An analysis of robust cost functions for CNN in computer-aided diagnosis.
    Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization
    2016, 1–6.'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barbu 等（2016）Barbu, A., Lu, L., Roth, H., Seff, A., Summers, R. M., 2016\. 用于计算机辅助诊断的卷积神经网络鲁棒成本函数分析。计算方法在生物力学和生物医学工程：成像与可视化
    2016，1–6。
- en: 'Bastien et al. (2012) Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J.,
    Goodfellow, I., Bergeron, A., Bouchard, N., Warde-Farley, D., Bengio, Y., 2012\.
    Theano: new features and speed improvements. In: Deep Learning and Unsupervised
    Feature Learning NIPS 2012 Workshop.'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bastien 等（2012）Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow,
    I., Bergeron, A., Bouchard, N., Warde-Farley, D., Bengio, Y., 2012\. Theano：新特性与速度提升。载于：深度学习与无监督特征学习
    NIPS 2012 研讨会。
- en: Bauer et al. (2016) Bauer, S., Carion, N., Schäffler, P., Fuchs, T., Wild, P.,
    Buhmann, J. M., 2016\. Multi-organ cancer classification and survival analysis.
    arXiv:1606.00897.
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bauer 等（2016）Bauer, S., Carion, N., Schäffler, P., Fuchs, T., Wild, P., Buhmann,
    J. M., 2016\. 多脏器癌症分类和生存分析。arXiv:1606.00897。
- en: 'Baumgartner et al. (2016) Baumgartner, C. F., Kamnitsas, K., Matthew, J., Smith,
    S., Kainz, B., Rueckert, D., 2016\. Real-time standard scan plane detection and
    localisation in fetal ultrasound using fully convolutional neural networks. In:
    Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp.
    203–211.'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baumgartner 等（2016）Baumgartner, C. F., Kamnitsas, K., Matthew, J., Smith, S.,
    Kainz, B., Rueckert, D., 2016\. 使用全卷积神经网络进行胎儿超声实时标准扫描平面检测与定位。载于：医学图像计算与计算机辅助干预。Lecture
    Notes in Computer Science 第 9901 卷，第 203–211 页。
- en: 'Ben-Cohen et al. (2016) Ben-Cohen, A., Diamant, I., Klang, E., Amitai, M.,
    Greenspan, H., 2016\. Dlmia. In: International Workshop on Large-Scale Annotation
    of Biomedical Data and Expert Label Synthesis. Vol. 10008 of Lect Notes Comput
    Sci. pp. 77–85.'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ben-Cohen 等（2016）Ben-Cohen, A., Diamant, I., Klang, E., Amitai, M., Greenspan,
    H., 2016\. DLMIA。载于：大规模生物医学数据标注与专家标签合成国际研讨会。Lecture Notes in Computer Science
    第 10008 卷，第 77–85 页。
- en: 'Bengio (2012) Bengio, Y., 2012\. Practical recommendations for gradient-based
    training of deep architectures. In: Neural Networks: Tricks of the Trade. Springer
    Berlin Heidelberg, pp. 437–478.'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengio（2012）Bengio, Y., 2012\. 基于梯度的深度架构训练的实用建议。载于：神经网络：实用技巧。Springer Berlin
    Heidelberg，第 437–478 页。
- en: 'Bengio et al. (2013) Bengio, Y., Courville, A., Vincent, P., 2013\. Representation
    learning: A review and new perspectives. IEEE Trans Pattern Anal Mach Intell 35 (8),
    1798–1828.'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengio 等（2013）Bengio, Y., Courville, A., Vincent, P., 2013\. 表征学习：综述与新视角。IEEE
    Trans Pattern Anal Mach Intell 35 (8), 1798–1828。
- en: 'Bengio et al. (2007) Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H.,
    2007\. Greedy layer-wise training of deep networks. In: Advances in Neural Information
    Processing Systems. pp. 153–160.'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengio 等（2007）Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., 2007\.
    深度网络的贪婪逐层训练。载于：神经信息处理系统进展。第 153–160 页。
- en: Bengio et al. (1994) Bengio, Y., Simard, P., Frasconi, P., 1994\. Learning long-term
    dependencies with gradient descent is difficult. IEEE Trans Neural Netw 5, 157–166.
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengio 等（1994）Bengio, Y., Simard, P., Frasconi, P., 1994\. 使用梯度下降学习长期依赖关系是困难的。IEEE
    Trans Neural Netw 5, 157–166。
- en: 'Benou et al. (2016) Benou, A., Veksler, R., Friedman, A., Raviv, T. R., 2016\.
    De-noising of contrast-enhanced mri sequences by an ensemble of expert deep neural
    networks. In: DLMIA. Vol. 10008 of Lect Notes Comput Sci. pp. 95–110.'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Benou 等（2016）Benou, A., Veksler, R., Friedman, A., Raviv, T. R., 2016\. 通过专家深度神经网络集成去噪对比增强
    MRI 序列。载于：DLMIA。Lecture Notes in Computer Science 第 10008 卷，第 95–110 页。
- en: 'BenTaieb and Hamarneh (2016) BenTaieb, A., Hamarneh, G., 2016\. Topology aware
    fully convolutional networks for histology gland segmentation. In: Med Image Comput
    Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp. 460–468.'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BenTaieb 和 Hamarneh（2016）BenTaieb, A., Hamarneh, G., 2016\. 顶层感知全卷积网络用于组织腺体分割。载于：医学图像计算与计算机辅助干预。Lecture
    Notes in Computer Science 第 9901 卷，第 460–468 页。
- en: 'BenTaieb et al. (2016) BenTaieb, A., Kawahara, J., Hamarneh, G., 2016\. Multi-loss
    convolutional networks for gland analysis in microscopy. In: IEEE Int Symp Biomedical
    Imaging. pp. 642–645.'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BenTaieb 等（2016）BenTaieb, A., Kawahara, J., Hamarneh, G., 2016\. 用于显微镜腺体分析的多损失卷积网络。载于：IEEE
    生物医学影像国际研讨会。第 642–645 页。
- en: Bergstra and Bengio (2012) Bergstra, J., Bengio, Y., 2012\. Random search for
    hyper-parameter optimization. J Mach Learn Res 13 (1), 281–305.
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bergstra 和 Bengio（2012）Bergstra, J., Bengio, Y., 2012\. 超参数优化的随机搜索。J Mach Learn
    Res 13 (1), 281–305。
- en: 'Birenbaum and Greenspan (2016) Birenbaum, A., Greenspan, H., 2016\. Longitudinal
    multiple sclerosis lesion segmentation using multi-view convolutional neural networks.
    In: DLMIA. Vol. 10008 of Lect Notes Comput Sci. pp. 58–67.'
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Birenbaum 和 Greenspan（2016）Birenbaum, A., Greenspan, H., 2016\. 使用多视角卷积神经网络的纵向多发性硬化损伤分割。载于：DLMIA。Lecture
    Notes in Computer Science 第 10008 卷，第 58–67 页。
- en: 'Brosch and Tam (2013) Brosch, T., Tam, R., 2013\. Manifold learning of brain
    MRIs by deep learning. In: Med Image Comput Comput Assist Interv. Vol. 8150 of
    Lect Notes Comput Sci. pp. 633–640.'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brosch 和 Tam（2013）Brosch, T., Tam, R., 2013\. 通过深度学习的脑 MRI 流形学习。载于：医学图像计算与计算机辅助干预。Lecture
    Notes in Computer Science 第 8150 卷，第 633–640 页。
- en: Brosch et al. (2016) Brosch, T., Tang, L. Y., Yoo, Y., Li, D. K., Traboulsee,
    A., Tam, R., 2016. Deep 3D convolutional encoder networks with shortcuts for multiscale
    feature integration applied to Multiple Sclerosis lesion segmentation. IEEE Trans
    Med Imaging 35 (5), 1229–1239.
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brosch等（2016）Brosch, T., Tang, L. Y., Yoo, Y., Li, D. K., Traboulsee, A., Tam,
    R., 2016. 深度3D卷积编码网络结合短路用于多尺度特征集成，应用于多发性硬化病灶分割。IEEE医学影像学报 35 (5), 1229–1239。
- en: 'Brosch et al. (2014) Brosch, T., Yoo, Y., Li, D. K. B., Traboulsee, A., Tam,
    R., 2014\. Modeling the variability in brain morphology and lesion distribution
    in multiple sclerosis by deep learning. In: Med Image Comput Comput Assist Interv.
    Vol. 8674 of Lect Notes Comput Sci. pp. 462–469.'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brosch等（2014）Brosch, T., Yoo, Y., Li, D. K. B., Traboulsee, A., Tam, R., 2014\.
    通过深度学习建模多发性硬化中的脑形态学和病灶分布变异性。见：医学影像计算与计算机辅助干预。计算机科学讲义第8674卷，第462–469页。
- en: 'Burlina et al. (2016) Burlina, P., Freund, D. E., Joshi, N., Wolfson, Y., Bressler,
    N. M., 2016. Detection of age-related macular degeneration via deep learning.
    In: IEEE Int Symp Biomedical Imaging. pp. 184–188.'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Burlina等（2016）Burlina, P., Freund, D. E., Joshi, N., Wolfson, Y., Bressler,
    N. M., 2016. 通过深度学习检测年龄相关性黄斑变性。见：IEEE生物医学影像国际研讨会，第184–188页。
- en: 'Bychkov et al. (2016) Bychkov, D., Turkki, R., Haglund, C., Linder, N., Lundin,
    J., 2016\. Deep learning for tissue microarray image-based outcome prediction
    in patients with colorectal cancer. In: Medical Imaging. Vol. 9791 of Proceedings
    of the SPIE. p. 979115.'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bychkov等（2016）Bychkov, D., Turkki, R., Haglund, C., Linder, N., Lundin, J.,
    2016\. 基于组织微阵列图像的结直肠癌患者深度学习预后预测。见：医学影像。SPIE会议论文集第9791卷，第979115页。
- en: 'Cai et al. (2016a) Cai, J., Lu, L., Zhang, Z., Xing, F., Yang, L., Yin, Q.,
    2016a. Pancreas segmentation in mri using graph-based decision fusion on convolutional
    neural networks. In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect
    Notes Comput Sci. pp. 442–450.'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cai等（2016a）Cai, J., Lu, L., Zhang, Z., Xing, F., Yang, L., Yin, Q., 2016a. 使用基于图的决策融合的卷积神经网络进行MRI中的胰腺分割。见：医学影像计算与计算机辅助干预。计算机科学讲义第9901卷，第442–450页。
- en: Cai et al. (2016b) Cai, Y., Landis, M., Laidley, D. T., Kornecki, A., Lum, A.,
    Li, S., 2016b. Multi-modal vertebrae recognition using transformed deep convolution
    network. Comput Med Imaging Graph 51, 11–19.
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cai等（2016b）Cai, Y., Landis, M., Laidley, D. T., Kornecki, A., Lum, A., Li, S.,
    2016b. 使用变换深度卷积网络进行多模态椎体识别。计算机医学影像图形 51, 11–19。
- en: Carneiro and Nascimento (2013) Carneiro, G., Nascimento, J. C., 2013\. Combining
    multiple dynamic models and deep learning architectures for tracking the left
    ventricle endocardium in ultrasound data. IEEE Trans Pattern Anal Mach Intell
    35, 2592–2607.
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carneiro和Nascimento（2013）Carneiro, G., Nascimento, J. C., 2013\. 结合多个动态模型和深度学习架构用于超声数据中左心室内膜的追踪。IEEE模式分析与机器智能学报
    35, 2592–2607。
- en: Carneiro et al. (2012) Carneiro, G., Nascimento, J. C., Freitas, A., 2012\.
    The segmentation of the left ventricle of the heart from ultrasound data using
    deep learning architectures and derivative-based search methods. IEEE Trans Image
    Process, 968–982.
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carneiro等（2012）Carneiro, G., Nascimento, J. C., Freitas, A., 2012\. 使用深度学习架构和基于导数的搜索方法对超声数据中的左心室进行分割。IEEE图像处理学报,
    968–982。
- en: Carneiro et al. (2016) Carneiro, G., Oakden-Rayner, L., Bradley, A. P., Nascimento,
    J., Palmer, L., 2016\. Automated 5-year mortality prediction using deep learning
    and radiomics features from chest computed tomography. arXiv:1607.00267.
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carneiro等（2016）Carneiro, G., Oakden-Rayner, L., Bradley, A. P., Nascimento,
    J., Palmer, L., 2016\. 使用深度学习和放射组学特征从胸部CT图像自动预测5年死亡率。arXiv:1607.00267。
- en: 'Cha et al. (2016) Cha, K. H., Hadjiiski, L. M., Samala, R. K., Chan, H.-P.,
    Cohan, R. H., Caoili, E. M., Paramagul, C., Alva, A., Weizer, A. Z., Dec. 2016\.
    Bladder cancer segmentation in CT for treatment response assessment: Application
    of deep-learning convolution neural network-a pilot study. Tomography 2, 421–429.'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cha等（2016）Cha, K. H., Hadjiiski, L. M., Samala, R. K., Chan, H.-P., Cohan, R.
    H., Caoili, E. M., Paramagul, C., Alva, A., Weizer, A. Z., 2016年12月。用于治疗反应评估的膀胱癌CT图像分割：深度学习卷积神经网络的应用——初步研究。断层扫描
    2, 421–429。
- en: Chang et al. (2017) Chang, H., Han, J., Zhong, C., Snijders, A., Mao, J.-H.,
    Jan. 2017. Unsupervised transfer learning via multi-scale convolutional sparse
    coding for biomedical applications. IEEE transactions on pattern analysis and
    machine intelligence.
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chang等（2017）Chang, H., Han, J., Zhong, C., Snijders, A., Mao, J.-H., 2017年1月。通过多尺度卷积稀疏编码进行无监督迁移学习，用于生物医学应用。IEEE模式分析与机器智能学报。
- en: Charbonnier et al. (2017) Charbonnier, J., van Rikxoort, E., Setio, A., Schaefer-Prokop,
    C., van Ginneken, B., Ciompi, F., 2017\. Improving airway segmentation in computed
    tomography using leak detection with convolutional networks. Med Image Anal 36,
    52–60.
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 夏尔博尼耶等（2017）夏尔博尼耶，范瑞克索特，塞提奥，谢弗-普罗科普，范金根，乔姆皮，2017。使用卷积网络的泄漏检测改进计算机断层扫描中的气道分割。Med
    Image Anal 36，52–60。
- en: 'Chen et al. (2015a) Chen, H., Dou, Q., Ni, D., Cheng, J.-Z., Qin, J., Li, S.,
    Heng, P.-A., 2015a. Automatic fetal ultrasound standard plane detection using
    knowledge transferred recurrent neural networks. In: Med Image Comput Comput Assist
    Interv. Vol. 9349 of Lect Notes Comput Sci. Cham, pp. 507–514.'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2015a）陈赫，窦强，倪丹，程军泽，秦洁，李舒，恒鹏安，2015a。使用知识迁移的递归神经网络进行自动胎儿超声标准平面检测。发表于：Med Image
    Comput Comput Assist Interv。第 9349 卷 Lect Notes Comput Sci。Cham，页码 507–514。
- en: 'Chen et al. (2016a) Chen, H., Dou, Q., Yu, L., Heng, P.-A., 2016a. VoxResNet:
    Deep voxelwise residual networks for volumetric brain segmentation. arXiv:1608.05895.'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2016a）陈赫，窦强，俞丽，恒鹏安，2016a。VoxResNet：用于体积脑分割的深度体素残差网络。arXiv:1608.05895。
- en: Chen et al. (2015b) Chen, H., Ni, D., Qin, J., Li, S., Yang, X., Wang, T., Heng,
    P. A., 2015b. Standard plane localization in fetal ultrasound via domain transferred
    deep neural networks. IEEE J Biomed Health Inform 19 (5), 1627–1636.
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2015b）陈赫，倪丹，秦洁，李舒，杨晓，王腾，恒鹏安，2015b。通过领域迁移的深度神经网络进行胎儿超声标准平面定位。IEEE J Biomed
    Health Inform 19 (5)，1627–1636。
- en: 'Chen et al. (2017) Chen, H., Qi, X., Yu, L., Heng, P.-A., 2017\. DCAN: Deep
    contour-aware networks for accurate gland segmentation. Med Image Anal 36, 135–146.'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2017）陈赫，齐晓，俞丽，恒鹏安，2017。DCAN：用于准确腺体分割的深度轮廓感知网络。Med Image Anal 36，135–146。
- en: 'Chen et al. (2015c) Chen, H., Shen, C., Qin, J., Ni, D., Shi, L., Cheng, J.
    C. Y., Heng, P.-A., 2015c. Automatic localization and identification of vertebrae
    in spine CT via a joint learning model with deep neural networks. In: Med Image
    Comput Comput Assist Interv. Vol. 9349 of Lect Notes Comput Sci. pp. 515–522.'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2015c）陈赫，申超，秦洁，倪丹，史磊，程建伟，恒鹏安，2015c。通过与深度神经网络联合学习模型的脊柱 CT 中椎骨的自动定位和识别。发表于：Med
    Image Comput Comput Assist Interv。第 9349 卷 Lect Notes Comput Sci。页码 515–522。
- en: 'Chen et al. (2016b) Chen, H., Wang, X., Heng, P. A., 2016b. Automated mitosis
    detection with deep regression networks. In: IEEE Int Symp Biomedical Imaging.
    pp. 1204–1207.'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2016b）陈赫，王旭，恒鹏安，2016b。基于深度回归网络的自动有丝分裂检测。发表于：IEEE Int Symp Biomedical Imaging。页码
    1204–1207。
- en: 'Chen et al. (2016c) Chen, H., Zheng, Y., Park, J.-H., Heng, P.-A., Zhou, S. K.,
    2016c. Iterative multi-domain regularized deep learning for anatomical structure
    detection and segmentation from ultrasound images. In: Med Image Comput Comput
    Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp. 487–495.'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2016c）陈赫，郑勇，朴志豪，恒鹏安，周书康，2016c。迭代多领域正则化深度学习用于从超声图像中检测和分割解剖结构。发表于：Med Image
    Comput Comput Assist Interv。第 9901 卷 Lect Notes Comput Sci。页码 487–495。
- en: 'Chen et al. (2016d) Chen, J., Yang, L., Zhang, Y., Alber, M., Chen, D. Z.,
    2016d. Combining fully convolutional and recurrent neural networks for 3D biomedical
    image segmentation. In: Advances in Neural Information Processing Systems. pp.
    3036–3044.'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2016d）陈骏，杨亮，张彦，阿尔伯特，陈丹祖，2016d。结合全卷积网络和递归神经网络进行 3D 生物医学图像分割。发表于：Advances in
    Neural Information Processing Systems。页码 3036–3044。
- en: 'Chen et al. (2016e) Chen, S., Qin, J., Ji, X., Lei, B., Wang, T., Ni, D., Cheng,
    J.-Z., 2016e. Automatic scoring of multiple semantic attributes with multi-task
    feature leverage: A study on pulmonary nodules in CT images. IEEE Trans Med Imaging,
    in press.'
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2016e）陈晟，秦洁，季鑫，雷斌，王腾，倪丹，程军泽，2016e。利用多任务特征利用的自动评分多个语义属性：关于 CT 图像中的肺结节的研究。IEEE
    Trans Med Imaging，待出版。
- en: 'Chen et al. (2015d) Chen, X., Xu, Y., Wong, D. W. K., Wong, T. Y., Liu, J.,
    2015d. Glaucoma detection based on deep convolutional neural network. In: Conf
    Proc IEEE Eng Med Biol Soc. pp. 715–718.'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2015d）陈曦，徐杨，黄大伟，黄天宇，刘杰，2015d。基于深度卷积神经网络的青光眼检测。发表于：Conf Proc IEEE Eng Med
    Biol Soc。页码 715–718。
- en: 'Cheng et al. (2016a) Cheng, J.-Z., Ni, D., Chou, Y.-H., Qin, J., Tiu, C.-M.,
    Chang, Y.-C., Huang, C.-S., Shen, D., Chen, C.-M., 2016a. Computer-Aided Diagnosis
    with deep learning architecture: Applications to breast lesions in US images and
    pulmonary nodules in CT scans. Nat Sci Rep 6, 24454.'
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程等（2016a）程军泽，倪丹，周玉华，秦洁，涂承敏，张艺涵，黄昌盛，申东，陈超铭，2016a。基于深度学习架构的计算机辅助诊断：应用于超声图像中的乳腺病变和
    CT 扫描中的肺结节。Nat Sci Rep 6，24454。
- en: 'Cheng et al. (2016b) Cheng, R., Roth, H. R., Lu, L., Wang, S., Turkbey, B.,
    Gandler, W., McCreedy, E. S., Agarwal, H. K., Choyke, P., Summers, R. M., McAuliffe,
    M. J., 2016b. Active appearance model and deep learning for more accurate prostate
    segmentation on MRI. In: Medical Imaging. Vol. 9784 of Proceedings of the SPIE.
    p. 97842I.'
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 等（2016b） Cheng, R., Roth, H. R., Lu, L., Wang, S., Turkbey, B., Gandler,
    W., McCreedy, E. S., Agarwal, H. K., Choyke, P., Summers, R. M., McAuliffe, M.
    J., 2016b. 主动外观模型和深度学习在 MRI 上实现更精确的前列腺分割。见：Medical Imaging. Proceedings of the
    SPIE 第 9784 卷，p. 97842I.
- en: Cheng et al. (2015) Cheng, X., Zhang, L., Zheng, Y., 2015\. Deep similarity
    learning for multimodal medical images. Computer Methods in Biomechanics and Biomedical
    Engineering, 1–5.
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 等（2015） Cheng, X., Zhang, L., Zheng, Y., 2015\. 多模态医学图像的深度相似性学习。Computer
    Methods in Biomechanics and Biomedical Engineering, 1–5.
- en: Cho et al. (2014) Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D.,
    Bougares, F., Schwenk, H., Bengio, Y., 2014\. Learning phrase representations
    using rnn encoder-decoder for statistical machine translation. arXiv:1406.1078.
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cho 等（2014） Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares,
    F., Schwenk, H., Bengio, Y., 2014\. 使用 RNN 编码器-解码器进行统计机器翻译的短语表示学习。arXiv:1406.1078.
- en: Choi and Jin (2016) Choi, H., Jin, K. H., 2016\. Fast and robust segmentation
    of the striatum using deep convolutional neural networks. Journal of Neuroscience
    Methods 274, 146–153.
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Choi 和 Jin（2016） Choi, H., Jin, K. H., 2016\. 使用深度卷积神经网络对纹状体进行快速而稳健的分割。Journal
    of Neuroscience Methods 274, 146–153.
- en: 'Christ et al. (2016) Christ, P. F., Elshaer, M. E. A., Ettlinger, F., Tatavarty,
    S., Bickel, M., Bilic, P., Rempfler, M., Armbruster, M., Hofmann, F., D’Anastasi,
    M., et al., 2016\. Automatic liver and lesion segmentation in CT using cascaded
    fully convolutional neural networks and 3D conditional random fields. In: Med
    Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp. 415–423.'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Christ 等（2016） Christ, P. F., Elshaer, M. E. A., Ettlinger, F., Tatavarty, S.,
    Bickel, M., Bilic, P., Rempfler, M., Armbruster, M., Hofmann, F., D’Anastasi,
    M., 等，2016\. 使用级联全卷积神经网络和 3D 条件随机场进行 CT 中的肝脏和病灶分割。见：Med Image Comput Comput Assist
    Interv. Lect Notes Comput Sci 第 9901 卷，pp. 415–423.
- en: Christodoulidis et al. (2017) Christodoulidis, S., Anthimopoulos, M., Ebner,
    L., Christe, A., Mougiakakou, S., 2017\. Multi-source transfer learning with convolutional
    neural networks for lung pattern analysis. IEEE J Biomed Health Inform 21, 76–84.
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Christodoulidis 等（2017） Christodoulidis, S., Anthimopoulos, M., Ebner, L., Christe,
    A., Mougiakakou, S., 2017\. 使用卷积神经网络进行肺部模式分析的多源迁移学习。IEEE J Biomed Health Inform
    21, 76–84.
- en: 'Çiçek et al. (2016) Çiçek, Ö., Abdulkadir, A., Lienkamp, S. S., Brox, T., Ronneberger,
    O., 2016\. 3D U-Net: Learning dense volumetric segmentation from sparse annotation.
    In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci.
    Springer, pp. 424–432.'
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Çiçek 等（2016） Çiçek, Ö., Abdulkadir, A., Lienkamp, S. S., Brox, T., Ronneberger,
    O., 2016\. 3D U-Net：从稀疏注释中学习密集体积分割。见：Med Image Comput Comput Assist Interv. Lect
    Notes Comput Sci 第 9901 卷，Springer，pp. 424–432.
- en: Cicero et al. (2016) Cicero, M., Bilbily, A., Colak, E., Dowdell, T., Gray,
    B., Perampaladas, K., Barfett, J., 2016\. Training and validating a deep convolutional
    neural network for computer-aided detection and classification of abnormalities
    on frontal chest radiographs. Invest Radiol, in press.
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cicero 等（2016） Cicero, M., Bilbily, A., Colak, E., Dowdell, T., Gray, B., Perampaladas,
    K., Barfett, J., 2016\. 训练和验证深度卷积神经网络以辅助检测和分类正面胸部 X 光片中的异常。Invest Radiol, in press.
- en: Ciompi et al. (2016) Ciompi, F., Chung, K., van Riel, S. J., Setio, A. A. A.,
    Gerke, P. K., Jacobs, C., Scholten, E. T., Schaefer-Prokop, C. M., Wille, M. M. W.,
    Marchiano, A., Pastorino, U., Prokop, M., van Ginneken, B., 2016\. Towards automatic
    pulmonary nodule management in lung cancer screening with deep learning. arXiv:1610.09157.
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ciompi 等（2016） Ciompi, F., Chung, K., van Riel, S. J., Setio, A. A. A., Gerke,
    P. K., Jacobs, C., Scholten, E. T., Schaefer-Prokop, C. M., Wille, M. M. W., Marchiano,
    A., Pastorino, U., Prokop, M., van Ginneken, B., 2016\. 面向肺癌筛查中肺结节自动管理的深度学习。arXiv:1610.09157.
- en: Ciompi et al. (2015) Ciompi, F., de Hoop, B., van Riel, S. J., Chung, K., Scholten,
    E. T., Oudkerk, M., de Jong, P. A., Prokop, M., van Ginneken, B., 2015\. Automatic
    classification of pulmonary peri-fissural nodules in computed tomography using
    an ensemble of 2D views and a convolutional neural network out-of-the-box. Med
    Image Anal 26, 195–202.
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ciompi 等（2015） Ciompi, F., de Hoop, B., van Riel, S. J., Chung, K., Scholten,
    E. T., Oudkerk, M., de Jong, P. A., Prokop, M., van Ginneken, B., 2015\. 使用 2D
    视图的集成和卷积神经网络进行计算机断层扫描中肺部裂隙周围结节的自动分类。Med Image Anal 26, 195–202.
- en: 'Cireşan et al. (2013) Cireşan, D. C., Giusti, A., Gambardella, L. M., Schmidhuber,
    J., 2013. Mitosis detection in breast cancer histology images with deep neural
    networks. In: Med Image Comput Comput Assist Interv. Vol. 8150 of Lect Notes Comput
    Sci. pp. 411–418.'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cireşan等（2013）Cireşan, D. C., Giusti, A., Gambardella, L. M., Schmidhuber, J.,
    2013。利用深度神经网络检测乳腺癌组织学图像中的有丝分裂。载于：医学图像计算与计算机辅助干预。计算机科学讲义第8150卷。第411–418页。
- en: 'Ciresan et al. (2012) Ciresan, D., Giusti, A., Gambardella, L. M., Schmidhuber,
    J., 2012\. Deep neural networks segment neuronal membranes in electron microscopy
    images. In: Advances in Neural Information Processing Systems. pp. 2843–2851.'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ciresan等（2012）Ciresan, D., Giusti, A., Gambardella, L. M., Schmidhuber, J.,
    2012。深度神经网络在电子显微镜图像中分割神经膜。载于：神经信息处理系统进展。第2843–2851页。
- en: 'Codella et al. (2015) Codella, N., Cai, J., Abedini, M., Garnavi, R., Halpern,
    A., Smith, J. R., 2015\. Deep learning, sparse coding, and svm for melanoma recognition
    in dermoscopy images. In: International Workshop on Machine Learning in Medical
    Imaging. pp. 118–126.'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Codella等（2015）Codella, N., Cai, J., Abedini, M., Garnavi, R., Halpern, A., Smith,
    J. R., 2015。深度学习、稀疏编码和SVM用于皮肤镜图像中的黑色素瘤识别。载于：国际医学成像中的机器学习研讨会。第118–126页。
- en: 'Collobert et al. (2011) Collobert, R., Kavukcuoglu, K., Farabet, C., 2011\.
    Torch7: A matlab-like environment for machine learning. In: Advances in Neural
    Information Processing Systems.'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Collobert等（2011）Collobert, R., Kavukcuoglu, K., Farabet, C., 2011。Torch7：一个类似MATLAB的机器学习环境。载于：神经信息处理系统进展。
- en: 'Cruz-Roa et al. (2014) Cruz-Roa, A., Basavanhally, A., González, F., Gilmore,
    H., Feldman, M., Ganesan, S., Shih, N., Tomaszewski, J., Madabhushi, A., 2014\.
    Automatic detection of invasive ductal carcinoma in whole slide images with convolutional
    neural networks. In: Medical Imaging. Vol. 9041 of Proceedings of the SPIE. p.
    904103.'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cruz-Roa等（2014）Cruz-Roa, A., Basavanhally, A., González, F., Gilmore, H., Feldman,
    M., Ganesan, S., Shih, N., Tomaszewski, J., Madabhushi, A., 2014。利用卷积神经网络在整个幻灯片图像中自动检测侵袭性导管癌。载于：医学成像。SPIE会议论文集第9041卷。第904103页。
- en: 'Cruz-Roa et al. (2013) Cruz-Roa, A. A., Ovalle, J. E. A., Madabhushi, A., Osorio,
    F. A. G., 2013\. A deep learning architecture for image representation, visual
    interpretability and automated basal-cell carcinoma cancer detection. In: Med
    Image Comput Comput Assist Interv. Vol. 8150 of Lect Notes Comput Sci. pp. 403–410.'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cruz-Roa等（2013）Cruz-Roa, A. A., Ovalle, J. E. A., Madabhushi, A., Osorio, F.
    A. G., 2013。用于图像表示、视觉可解释性和自动化基底细胞癌检测的深度学习架构。载于：医学图像计算与计算机辅助干预。计算机科学讲义第8150卷。第403–410页。
- en: Dalmis et al. (2017) Dalmis, M., Litjens, G., Holland, K., Setio, A., Mann,
    R., Karssemeijer, N., Gubern-Mérida, A., Feb. 2017\. Using deep learning to segment
    breast and fibroglandular tissue in mri volumes. Medical physics 44, 533–546.
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dalmis等（2017）Dalmis, M., Litjens, G., Holland, K., Setio, A., Mann, R., Karssemeijer,
    N., Gubern-Mérida, A., 2017年2月。使用深度学习分割MRI体积中的乳腺和纤维腺体组织。医学物理学44，533–546。
- en: 'de Brebisson and Montana (2015) de Brebisson, A., Montana, G., 2015\. Deep
    neural networks for anatomical brain segmentation. In: Comput Vis Pattern Recognit.
    pp. 20–28.'
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de Brebisson和Montana（2015）de Brebisson, A., Montana, G., 2015。用于解剖脑分割的深度神经网络。载于：计算机视觉模式识别。第20–28页。
- en: 'de Vos et al. (2016a) de Vos, B. D., Viergever, M. A., de Jong, P. A., Išgum,
    I., 2016a. Automatic slice identification in 3D medical images with a ConvNet
    regressor. In: DLMIA. Vol. 10008 of Lect Notes Comput Sci. pp. 161–169.'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de Vos等（2016a）de Vos, B. D., Viergever, M. A., de Jong, P. A., Išgum, I., 2016a.
    在3D医学图像中使用ConvNet回归器进行自动切片识别。载于：DLMIA。计算机科学讲义第10008卷。第161–169页。
- en: 'de Vos et al. (2016b) de Vos, B. D., Wolterink, J. M., de Jong, P. A., Viergever,
    M. A., Išgum, I., 2016b. 2D image classification for 3D anatomy localization:
    employing deep convolutional neural networks. In: Medical Imaging. Vol. 9784 of
    Proceedings of the SPIE. p. 97841Y.'
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de Vos等（2016b）de Vos, B. D., Wolterink, J. M., de Jong, P. A., Viergever, M.
    A., Išgum, I., 2016b. 2D图像分类用于3D解剖定位：采用深度卷积神经网络。载于：医学成像。SPIE会议论文集第9784卷。第97841Y页。
- en: 'Demyanov et al. (2016) Demyanov, S., Chakravorty, R., Abedini, M., Halpern,
    A., Garnavi, R., 2016. Classification of dermoscopy patterns using deep convolutional
    neural networks. In: IEEE Int Symp Biomedical Imaging. pp. 364–368.'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Demyanov等（2016）Demyanov, S., Chakravorty, R., Abedini, M., Halpern, A., Garnavi,
    R., 2016. 使用深度卷积神经网络分类皮肤镜模式。载于：IEEE国际生物医学成像研讨会。第364–368页。
- en: 'Dhungel et al. (2016) Dhungel, N., Carneiro, G., Bradley, A. P., 2016\. The
    automated learning of deep features for breast mass classification from mammograms.
    In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci.
    Springer, pp. 106–114.'
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dhungel et al. (2016) Dhungel, N., Carneiro, G., Bradley, A. P., 2016. 从乳腺X光图像中自动学习深度特征以进行乳腺肿块分类。In:
    Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. Springer,
    pp. 106–114。'
- en: Dou et al. (2016a) Dou, Q., Chen, H., Jin, Y., Yu, L., Qin, J., Heng, P.-A.,
    2016a. 3D deeply supervised network for automatic liver segmentation from CT volumes.
    arXiv:1607.00582.
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dou et al. (2016a) Dou, Q., Chen, H., Jin, Y., Yu, L., Qin, J., Heng, P.-A.,
    2016a. 基于3D深度监督网络的CT体积自动肝脏分割。arXiv:1607.00582。
- en: Dou et al. (2016b) Dou, Q., Chen, H., Yu, L., Qin, J., Heng, P. A., 2016b. Multi-level
    contextual 3D CNNs for false positive reduction in pulmonary nodule detection,
    in press.
  id: totrans-686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dou et al. (2016b) Dou, Q., Chen, H., Yu, L., Qin, J., Heng, P. A., 2016b. 用于肺结节检测中假阳性减少的多级上下文3D
    CNNs，正在印刷中。
- en: Dou et al. (2015) Dou, Q., Chen, H., Yu, L., Shi, L., Wang, D., Mok, V. C.,
    Heng, P. A., 2015. Automatic cerebral microbleeds detection from MR images via
    independent subspace analysis based hierarchical features. Conf Proc IEEE Eng
    Med Biol Soc, 7933–7936.
  id: totrans-687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dou et al. (2015) Dou, Q., Chen, H., Yu, L., Shi, L., Wang, D., Mok, V. C.,
    Heng, P. A., 2015. 基于独立子空间分析的层次特征从MR图像中自动检测脑微出血。Conf Proc IEEE Eng Med Biol Soc,
    7933–7936。
- en: Dou et al. (2016c) Dou, Q., Chen, H., Yu, L., Zhao, L., Qin, J., Wang, D., Mok,
    V. C., Shi, L., Heng, P.-A., 2016c. Automatic detection of cerebral microbleeds
    from MR images via 3D convolutional neural networks. IEEE Trans Med Imaging 35,
    1182–1195.
  id: totrans-688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dou et al. (2016c) Dou, Q., Chen, H., Yu, L., Zhao, L., Qin, J., Wang, D., Mok,
    V. C., Shi, L., Heng, P.-A., 2016c. 通过3D卷积神经网络自动检测脑微出血。IEEE Trans Med Imaging
    35, 1182–1195。
- en: 'Drozdzal et al. (2016) Drozdzal, M., Vorontsov, E., Chartrand, G., Kadoury,
    S., Pal, C., 2016\. The importance of skip connections in biomedical image segmentation.
    In: DLMIA. Vol. 10008 of Lect Notes Comput Sci. pp. 179–187.'
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Drozdzal et al. (2016) Drozdzal, M., Vorontsov, E., Chartrand, G., Kadoury,
    S., Pal, C., 2016. 跳跃连接在生物医学图像分割中的重要性。In: DLMIA. Vol. 10008 of Lect Notes Comput
    Sci. pp. 179–187。'
- en: 'Dubrovina et al. (2016) Dubrovina, A., Kisilev, P., Ginsburg, B., Hashoul,
    S., Kimmel, R., 2016. Computational mammography using deep neural networks. Computer
    Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization, 1–5.'
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dubrovina et al. (2016) Dubrovina, A., Kisilev, P., Ginsburg, B., Hashoul, S.,
    Kimmel, R., 2016. 使用深度神经网络的计算机化乳腺摄影。计算方法在生物力学和生物医学工程中的应用：成像与可视化，1–5。
- en: Ehteshami Bejnordi et al. (2016) Ehteshami Bejnordi, B., Litjens, G., Timofeeva,
    N., Otte-Holler, I., Homeyer, A., Karssemeijer, N., van der Laak, J., Sep 2016\.
    Stain specific standardization of whole-slide histopathological images. IEEE Trans
    Med Imaging 35 (2), 404–415.
  id: totrans-691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ehteshami Bejnordi et al. (2016) Ehteshami Bejnordi, B., Litjens, G., Timofeeva,
    N., Otte-Holler, I., Homeyer, A., Karssemeijer, N., van der Laak, J., 2016年9月。全滑动组织病理图像的染色特异性标准化。IEEE
    Trans Med Imaging 35 (2), 404–415。
- en: URL [http://dx.doi.org/10.1109/TMI.2015.2476509](http://dx.doi.org/10.1109/TMI.2015.2476509)
  id: totrans-692
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [http://dx.doi.org/10.1109/TMI.2015.2476509](http://dx.doi.org/10.1109/TMI.2015.2476509)
- en: 'Emad et al. (2015) Emad, O., Yassine, I. A., Fahmy, A. S., 2015\. Automatic
    localization of the left ventricle in cardiac MRI images using deep learning.
    In: Conf Proc IEEE Eng Med Biol Soc. pp. 683–686.'
  id: totrans-693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Emad et al. (2015) Emad, O., Yassine, I. A., Fahmy, A. S., 2015. 使用深度学习在心脏MRI图像中自动定位左心室。In:
    Conf Proc IEEE Eng Med Biol Soc. pp. 683–686。'
- en: Esteva et al. (2017) Esteva, A., Kuprel, B., Novoa, R. A., Ko, J., Swetter,
    S. M., Blau, H. M., Thrun, S., 2017\. Dermatologist-level classification of skin
    cancer with deep neural networks. Nature 542, 115–118.
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Esteva et al. (2017) Esteva, A., Kuprel, B., Novoa, R. A., Ko, J., Swetter,
    S. M., Blau, H. M., Thrun, S., 2017. 皮肤癌的皮肤科医生级分类使用深度神经网络。Nature 542, 115–118。
- en: Farabet et al. (2013) Farabet, C., Couprie, C., Najman, L., LeCun, Y., 2013\.
    Learning hierarchical features for scene labeling. IEEE Trans Pattern Anal Mach
    Intell 35 (8), 1915–1929.
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Farabet et al. (2013) Farabet, C., Couprie, C., Najman, L., LeCun, Y., 2013.
    学习用于场景标注的层次特征。IEEE Trans Pattern Anal Mach Intell 35 (8), 1915–1929。
- en: Farag et al. (2015) Farag, A., Lu, L., Roth, H. R., Liu, J., Turkbey, E., Summers,
    R. M., 2015\. A bottom-up approach for pancreas segmentation using cascaded superpixels
    and (deep) image patch labeling. arXiv:1505.06236.
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Farag et al. (2015) Farag, A., Lu, L., Roth, H. R., Liu, J., Turkbey, E., Summers,
    R. M., 2015. 使用级联超级像素和（深度）图像补丁标注的胰腺分割自下而上的方法。arXiv:1505.06236。
- en: Ferrari et al. (2015) Ferrari, A., Lombardi, S., Signoroni, A., 2015\. Bacterial
    colony counting by convolutional neural networks. Conf Proc IEEE Eng Med Biol
    Soc, 7458–7461.
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ferrari et al. (2015) Ferrari, A., Lombardi, S., Signoroni, A., 2015. 使用卷积神经网络的细菌菌落计数。Conf
    Proc IEEE Eng Med Biol Soc, 7458–7461。
- en: 'Fonseca et al. (2015) Fonseca, P., Mendoza, J., Wainer, J., Ferrer, J., Pinto,
    J., Guerrero, J.and Castaneda, B., 2015\. Automatic breast density classification
    using a convolutional neural network architecture search procedure. In: Medical
    Imaging. Vol. 9413 of Proceedings of the SPIE. p. 941428.'
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fonseca et al. (2015) Fonseca, P., Mendoza, J., Wainer, J., Ferrer, J., Pinto,
    J., Guerrero, J.and Castaneda, B., 2015. 使用卷积神经网络架构搜索程序进行自动乳腺密度分类。发表于《医学成像》。第
    9413 卷，SPIE 会议录。第 941428 页。
- en: Forsberg et al. (2017) Forsberg, D., Sjöblom, E., Sunshine, J. L., 2017\. Detection
    and labeling of vertebrae in MR images using deep learning with clinical annotations
    as training data. J Digit Imaging, in press.
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Forsberg et al. (2017) Forsberg, D., Sjöblom, E., Sunshine, J. L., 2017. 使用深度学习和临床注释作为训练数据检测和标记
    MR 图像中的脊椎。《数字成像期刊》，待刊。
- en: 'Fotin et al. (2016) Fotin, S. V., Yin, Y., Haldankar, H., Hoffmeister, J. W.,
    Periaswamy, S., 2016. Detection of soft tissue densities from digital breast tomosynthesis:
    comparison of conventional and deep learning approaches. In: Medical Imaging.
    Vol. 9785 of Proceedings of the SPIE. p. 97850X.'
  id: totrans-700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fotin et al. (2016) Fotin, S. V., Yin, Y., Haldankar, H., Hoffmeister, J. W.,
    Periaswamy, S., 2016. 从数字乳腺断层合成图像中检测软组织密度：传统方法与深度学习方法的比较。发表于《医学成像》。第 9785 卷，SPIE
    会议录。第 97850X 页。
- en: 'Fritscher et al. (2016) Fritscher, K., Raudaschl, P., Zaffino, P., Spadea,
    M. F., Sharp, G. C., Schubert, R., 2016\. Deep neural networks for fast segmentation
    of 3D medical images. In: Med Image Comput Comput Assist Interv. Vol. 9901 of
    Lect Notes Comput Sci. pp. 158–165.'
  id: totrans-701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fritscher et al. (2016) Fritscher, K., Raudaschl, P., Zaffino, P., Spadea, M.
    F., Sharp, G. C., Schubert, R., 2016. 用于快速分割 3D 医学图像的深度神经网络。发表于《医学图像计算与计算机辅助干预》。第
    9901 卷，《计算机科学讲义》。第 158–165 页。
- en: 'Fu et al. (2016a) Fu, H., Xu, Y., Lin, S., Kee Wong, D. W., Liu, J., 2016a.
    Deepvessel: Retinal vessel segmentation via?deep learning and conditional random?field.
    In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci.
    pp. 132–139.'
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu et al. (2016a) Fu, H., Xu, Y., Lin, S., Kee Wong, D. W., Liu, J., 2016a.
    Deepvessel：通过深度学习和条件随机场进行视网膜血管分割。发表于《医学图像计算与计算机辅助干预》。第 9901 卷，《计算机科学讲义》。第 132–139
    页。
- en: 'Fu et al. (2016b) Fu, H., Xu, Y., Wong, D. W. K., Liu, J., 2016b. Retinal vessel
    segmentation via deep learning network and fully-connected conditional random
    fields. In: IEEE Int Symp Biomedical Imaging. pp. 698–701.'
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu et al. (2016b) Fu, H., Xu, Y., Wong, D. W. K., Liu, J., 2016b. 通过深度学习网络和全连接条件随机场进行视网膜血管分割。发表于《IEEE
    国际生物医学成像研讨会》。第 698–701 页。
- en: 'Fukushima (1980) Fukushima, K., 1980\. Neocognitron: A self-organizing neural
    network model for a mechanism of pattern recognition unaffected by shift in position.
    Biol Cybern 36 (4), 193–202.'
  id: totrans-704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fukushima (1980) Fukushima, K., 1980. Neocognitron：一种自组织神经网络模型，用于不受位置变化影响的模式识别机制。《生物网络》36
    (4), 193–202。
- en: 'Gao et al. (2016a) Gao, M., Bagci, U., Lu, L., Wu, A., Buty, M., Shin, H.-C.,
    Roth, H., Papadakis, G. Z., Depeursinge, A., Summers, R. M., Xu, Z., Mollura,
    D. J., 2016a. Holistic classification of CT attenuation patterns for interstitial
    lung diseases via deep convolutional neural networks. Computer Methods in Biomechanics
    and Biomedical Engineering: Imaging & Visualization, 1–6.'
  id: totrans-705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao et al. (2016a) Gao, M., Bagci, U., Lu, L., Wu, A., Buty, M., Shin, H.-C.,
    Roth, H., Papadakis, G. Z., Depeursinge, A., Summers, R. M., Xu, Z., Mollura,
    D. J., 2016a. 通过深度卷积神经网络对间质性肺疾病的 CT 衰减模式进行整体分类。《计算方法在生物力学和生物医学工程：成像与可视化》，第 1–6
    页。
- en: 'Gao et al. (2016b) Gao, M., Xu, Z., Lu, L., Harrison, A. P., Summers, R. M.,
    Mollura, D. J., 2016b. Multi-label deep regression and unordered pooling for holistic
    interstitial lung disease pattern detection. In: Machine Learning in Medical Imaging.
    Vol. 10019 of Lect Notes Comput Sci. pp. 147–155.'
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao et al. (2016b) Gao, M., Xu, Z., Lu, L., Harrison, A. P., Summers, R. M.,
    Mollura, D. J., 2016b. 多标签深度回归和无序池化用于整体间质性肺疾病模式检测。发表于《医学成像中的机器学习》。第 10019 卷，《计算机科学讲义》。第
    147–155 页。
- en: 'Gao et al. (2016c) Gao, M., Xu, Z., Lu, L., Nogues, I., Summers, R., Mollura,
    D., 2016c. Segmentation label propagation using deep convolutional neural networks
    and dense conditional random field. In: IEEE Int Symp Biomedical Imaging. pp.
    1265–1268.'
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao et al. (2016c) Gao, M., Xu, Z., Lu, L., Nogues, I., Summers, R., Mollura,
    D., 2016c. 使用深度卷积神经网络和密集条件随机场的分割标签传播。发表于《IEEE 国际生物医学成像研讨会》。第 1265–1268 页。
- en: Gao et al. (2015) Gao, X., Lin, S., Wong, T. Y., 2015\. Automatic feature learning
    to grade nuclear cataracts based on deep learning. IEEE Trans Biomed Eng 62 (11),
    2693–2701.
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao et al. (2015) Gao, X., Lin, S., Wong, T. Y., 2015. 基于深度学习的自动特征学习来分级核性白内障。《IEEE
    生物医学工程汇刊》62 (11), 2693–2701。
- en: 'Gao et al. (2016d) Gao, Y., Maraci, M. A., Noble, J. A., 2016d. Describing
    ultrasound video content using deep convolutional neural networks. In: IEEE Int
    Symp Biomedical Imaging. pp. 787–790.'
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等人 (2016d) Gao, Y., Maraci, M. A., Noble, J. A., 2016d. 使用深度卷积神经网络描述超声视频内容。在：IEEE
    国际生物医学成像研讨会。pp. 787–790。
- en: Gao et al. (2016e) Gao, Z., Wang, L., Zhou, L., Zhang, J., 2016e. Hep-2 cell
    image classification with deep convolutional neural networks. Journal of Biomedical
    and Health Informatics.
  id: totrans-710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等人 (2016e) Gao, Z., Wang, L., Zhou, L., Zhang, J., 2016e. 深度卷积神经网络在 Hep-2
    细胞图像分类中的应用。生物医学与健康信息学杂志。
- en: 'Ghafoorian et al. (2017) Ghafoorian, M., Karssemeijer, N., Heskes, T., Bergkamp,
    M., Wissink, J., Obels, J., Keizer, K., de Leeuw, F.-E., van Ginneken, B., Marchiori,
    E., Platel, B., 2017\. Deep multi-scale location-aware 3d convolutional neural
    networks for automated detection of lacunes of presumed vascular origin. NeuroImage:
    Clinical, in press.'
  id: totrans-711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ghafoorian 等人 (2017) Ghafoorian, M., Karssemeijer, N., Heskes, T., Bergkamp,
    M., Wissink, J., Obels, J., Keizer, K., de Leeuw, F.-E., van Ginneken, B., Marchiori,
    E., Platel, B., 2017\. 多尺度位置感知 3D 深度卷积神经网络用于自动检测疑似血管性原因的脑梗死。神经影像学：临床，待发表。
- en: Ghafoorian et al. (2016a) Ghafoorian, M., Karssemeijer, N., Heskes, T., van
    Uden, I., Sanchez, C., Litjens, G., de Leeuw, F.-E., van Ginneken, B., Marchiori,
    E., Platel, B., 2016a. Location sensitive deep convolutional neural networks for
    segmentation of white matter hyperintensities. arXiv:1610.04834.
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ghafoorian 等人 (2016a) Ghafoorian, M., Karssemeijer, N., Heskes, T., van Uden,
    I., Sanchez, C., Litjens, G., de Leeuw, F.-E., van Ginneken, B., Marchiori, E.,
    Platel, B., 2016a. 位置敏感的深度卷积神经网络用于白质高信号灶的分割。arXiv:1610.04834.
- en: 'Ghafoorian et al. (2016b) Ghafoorian, M., Karssemeijer, N., Heskes, T., van
    Uden, I. W. M., de Leeuw, F.-E., Marchiori, E., van Ginneken, B., Platel, B.,
    2016b. Non-uniform patch sampling with deep convolutional neural networks for
    white matter hyperintensity segmentation. In: IEEE Int Symp Biomedical Imaging.
    pp. 1414–1417.'
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ghafoorian 等人 (2016b) Ghafoorian, M., Karssemeijer, N., Heskes, T., van Uden,
    I. W. M., de Leeuw, F.-E., Marchiori, E., van Ginneken, B., Platel, B., 2016b.
    使用深度卷积神经网络进行非均匀补丁采样的白质高信号灶分割。在：IEEE 国际生物医学成像研讨会。pp. 1414–1417。
- en: 'Ghesu et al. (2016a) Ghesu, F. C., Georgescu, B., Mansi, T., Neumann, D., Hornegger,
    J., Comaniciu, D., 2016a. An artificial agent for anatomical landmark detection
    in medical images. In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect
    Notes Comput Sci.'
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ghesu 等人 (2016a) Ghesu, F. C., Georgescu, B., Mansi, T., Neumann, D., Hornegger,
    J., Comaniciu, D., 2016a. 医学图像中解剖标志检测的人工智能代理。在：医学图像计算机辅助干预国际会议。计算机科学讲座文集第 9901
    卷。
- en: 'Ghesu et al. (2016b) Ghesu, F. C., Krubasik, E., Georgescu, B., Singh, V.,
    Zheng, Y., Hornegger, J., Comaniciu, D., 2016b. Marginal space deep learning:
    Efficient architecture for volumetric image parsing. IEEE Trans Med Imaging 35,
    1217–1228.'
  id: totrans-715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ghesu 等人 (2016b) Ghesu, F. C., Krubasik, E., Georgescu, B., Singh, V., Zheng,
    Y., Hornegger, J., Comaniciu, D., 2016b. 边缘空间深度学习：用于体积图像分析的高效架构。IEEE 医学影像学期刊，35，1217–1228。
- en: 'Golan et al. (2016) Golan, D., Donner, Y., Mansi, C., Jaremko, J., Ramachandran,
    M., 2016\. Fully automating Graf‘s method for DDH diagnosis using deep convolutional
    neural networks. In: DLMIA. Vol. 10008 of Lect Notes Comput Sci. pp. 130–141.'
  id: totrans-716
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Golan 等人 (2016) Golan, D., Donner, Y., Mansi, C., Jaremko, J., Ramachandran,
    M., 2016\. 使用深度卷积神经网络完全自动化 Graf 方法进行 DDH 诊断。在：DLMIA. 计算机科学讲座文集第 10008 卷，pp. 130–141。
- en: 'Golkov et al. (2016) Golkov, V., Dosovitskiy, A., Sperl, J., Menzel, M., Czisch,
    M., Samann, P., Brox, T., Cremers, D., 2016\. q-Space deep learning: Twelve-fold
    shorter and model-free diffusion MRI scans. IEEE Trans Med Imaging 35, 1344 –
    1351.'
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Golkov 等人 (2016) Golkov, V., Dosovitskiy, A., Sperl, J., Menzel, M., Czisch,
    M., Samann, P., Brox, T., Cremers, D., 2016\. q 空间深度学习：十二倍速度更快且无模型的扩散 MRI 扫描。IEEE
    医学影像学期刊，35，1344–1351。
- en: Goodfellow et al. (2014) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,
    Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., 2014\. Generative adversarial
    nets. arXiv:1406.2661.
  id: totrans-718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等人 (2014) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley,
    D., Ozair, S., Courville, A., Bengio, Y., 2014\. 生成对抗网络。arXiv:1406.2661.
- en: 'Greenspan et al. (2016) Greenspan, H., Summers, R. M., van Ginneken, B., 2016\.
    Deep learning in medical imaging: Overview and future promise of an exciting new
    technique. IEEE Trans Med Imaging 35 (5), 1153–1159.'
  id: totrans-719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Greenspan 等人 (2016) Greenspan, H., Summers, R. M., van Ginneken, B., 2016\.
    医学影像中的深度学习：一种令人兴奋的新技术的概述和未来前景。IEEE 医学影像学期刊，35 (5)，1153–1159。
- en: Gulshan et al. (2016) Gulshan, V., Peng, L., Coram, M., Stumpe, M. C., Wu, D.,
    Narayanaswamy, A., Venugopalan, S., Widner, K., Madams, T., Cuadros, J., Kim,
    R., Raman, R., Nelson, P. C., Mega, J. L., Webster, D. R., Dec. 2016\. Development
    and validation of a deep learning algorithm for detection of diabetic retinopathy
    in retinal fundus photographs. JAMA 316, 2402–2410.
  id: totrans-720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gulshan et al. (2016) Gulshan, V., Peng, L., Coram, M., Stumpe, M. C., Wu, D.,
    Narayanaswamy, A., Venugopalan, S., Widner, K., Madams, T., Cuadros, J., Kim,
    R., Raman, R., Nelson, P. C., Mega, J. L., Webster, D. R., Dec. 2016. 开发和验证用于检测视网膜基金照片中糖尿病视网膜病变的深度学习算法。JAMA
    316, 2402–2410。
- en: 'Gülsün et al. (2016) Gülsün, M. A., Funka-Lea, G., Sharma, P., Rapaka, S.,
    Zheng, Y., 2016. Coronary centerline extraction via optimal flow paths and CNN
    path pruning. In: Med Image Comput Comput Assist Interv. Vol. 9902 of Lect Notes
    Comput Sci. Springer, pp. 317–325.'
  id: totrans-721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gülsün et al. (2016) Gülsün, M. A., Funka-Lea, G., Sharma, P., Rapaka, S.,
    Zheng, Y., 2016. 通过最佳流路径和CNN路径修剪提取冠状动脉中心线。在: Med Image Comput Comput Assist Interv.
    Vol. 9902 of Lect Notes Comput Sci. Springer, pp. 317–325。'
- en: 'Günhan Ertosun and Rubin (2015) Günhan Ertosun, M., Rubin, D. L., 2015\. Automated
    grading of gliomas using deep learning in digital pathology images: a modular
    approach with ensemble of convolutional neural networks. In: AMIA Annual Symposium.
    pp. 1899–1908.'
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Günhan Ertosun and Rubin (2015) Günhan Ertosun, M., Rubin, D. L., 2015. 使用深度学习在数字病理图像中自动分级胶质瘤：一种具有卷积神经网络集成的模块化方法。在:
    AMIA年会。pp. 1899–1908。'
- en: Guo et al. (2016) Guo, Y., Gao, Y., Shen, D., 2016\. Deformable MR prostate
    segmentation via deep feature learning and sparse patch matching. IEEE Trans Med
    Imaging 35 (4), 1077–1089.
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo et al. (2016) Guo, Y., Gao, Y., Shen, D., 2016. 基于深度特征学习和稀疏补丁匹配的可变形MR前列腺分割。IEEE
    Trans Med Imaging 35 (4), 1077–1089。
- en: 'Guo et al. (2014) Guo, Y., Wu, G., Commander, L. A., Szary, S., Jewells, V.,
    Lin, W., Shen, D., 2014\. Segmenting hippocampus from infant brains by sparse
    patch matching with deep-learned features. In: Med Image Comput Comput Assist
    Interv. Vol. 8674 of Lect Notes Comput Sci. pp. 308–315.'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guo et al. (2014) Guo, Y., Wu, G., Commander, L. A., Szary, S., Jewells, V.,
    Lin, W., Shen, D., 2014. 通过深度学习特征的稀疏补丁匹配从婴儿大脑中分割海马体。在: Med Image Comput Comput
    Assist Interv. Vol. 8674 of Lect Notes Comput Sci. pp. 308–315。'
- en: 'Han et al. (2016) Han, X.-H., Lei, J., Chen, Y.-W., 2016\. HEp-2 cell classification
    using K-support spatial pooling in deep CNNs. In: DLMIA. Vol. 10008 of Lect Notes
    Comput Sci. pp. 3–11.'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Han et al. (2016) Han, X.-H., Lei, J., Chen, Y.-W., 2016. 使用深度CNN中的K支持空间池化进行HEp-2细胞分类。在:
    DLMIA. Vol. 10008 of Lect Notes Comput Sci. pp. 3–11。'
- en: 'Haugeland (1985) Haugeland, J., 1985\. Artificial intelligence: the very idea.
    The MIT Press, Cambridge, Mass.'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haugeland (1985) Haugeland, J., 1985. 人工智能：一个非常的想法。MIT出版社，剑桥，马萨诸塞州。
- en: Havaei et al. (2016a) Havaei, M., Davy, A., Warde-Farley, D., Biard, A., Courville,
    A., Bengio, Y., Pal, C., Jodoin, P.-M., Larochelle, H., 2016a. Brain tumor segmentation
    with Deep Neural Networks. Med Image Anal 35, 18–31.
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Havaei et al. (2016a) Havaei, M., Davy, A., Warde-Farley, D., Biard, A., Courville,
    A., Bengio, Y., Pal, C., Jodoin, P.-M., Larochelle, H., 2016a. 使用深度神经网络进行脑肿瘤分割。Med
    Image Anal 35, 18–31。
- en: 'Havaei et al. (2016b) Havaei, M., Guizard, N., Chapados, N., Bengio, Y., 2016b.
    HeMIS: Hetero-modal image segmentation. In: Med Image Comput Comput Assist Interv.
    Vol. 9901 of Lect Notes Comput Sci. pp. 469–477.'
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Havaei et al. (2016b) Havaei, M., Guizard, N., Chapados, N., Bengio, Y., 2016b.
    HeMIS: 异质模态图像分割。在: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes
    Comput Sci. pp. 469–477。'
- en: He et al. (2015) He, K., Zhang, X., Ren, S., Sun, J., 2015\. Deep residual learning
    for image recognition. arXiv:1512.03385.
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. (2015) He, K., Zhang, X., Ren, S., Sun, J., 2015. 用于图像识别的深度残差学习。arXiv:1512.03385。
- en: Hinton (2010) Hinton, G., 2010\. A practical guide to training restricted Boltzmann
    machines. Momentum 9 (1), 926.
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton (2010) Hinton, G., 2010. 限制玻尔兹曼机的训练实用指南。Momentum 9 (1), 926。
- en: Hinton et al. (2006) Hinton, G. E., Osindero, S., Teh, Y.-W., 2006\. A fast
    learning algorithm for deep belief nets. Neural Comput 18, 1527–1554.
  id: totrans-731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton et al. (2006) Hinton, G. E., Osindero, S., Teh, Y.-W., 2006. 一种快速的深度信念网络学习算法。Neural
    Comput 18, 1527–1554。
- en: Hinton and Salakhutdinov (2006) Hinton, G. E., Salakhutdinov, R. R., 2006\.
    Reducing the dimensionality of data with neural networks. Science 313, 504–507.
  id: totrans-732
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton and Salakhutdinov (2006) Hinton, G. E., Salakhutdinov, R. R., 2006. 使用神经网络减少数据的维度。Science
    313, 504–507。
- en: Hochreiter and Schmidhuber (1997) Hochreiter, S., Schmidhuber, J., 1997\. Long
    short-term memory. Neural Computation 9 (8), 1735–1780.
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hochreiter and Schmidhuber (1997) Hochreiter, S., Schmidhuber, J., 1997. 长短期记忆。Neural
    Computation 9 (8), 1735–1780。
- en: 'Hoffmann et al. (2016) Hoffmann, N., Koch, E., Steiner, G., Petersohn, U.,
    Kirsch, M., 2016\. Learning thermal process representations for intraoperative
    analysis of cortical perfusion during ischemic strokes. In: DLMIA. Vol. 10008
    of Lect Notes Comput Sci. pp. 152–160.'
  id: totrans-734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hoffmann等（2016）Hoffmann, N., Koch, E., Steiner, G., Petersohn, U., Kirsch,
    M., 2016\. 为缺血性中风期间的皮层灌注术中分析学习热过程表示。In: DLMIA. Vol. 10008 of Lect Notes Comput
    Sci. pp. 152–160。'
- en: Hoogi et al. (2016) Hoogi, A., Subramaniam, A., Veerapaneni, R., Rubin, D.,
    2016\. Adaptive estimation of active contour parameters using convolutional neural
    networks and texture analysis. IEEE Trans Med Imaging.
  id: totrans-735
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hoogi等（2016）Hoogi, A., Subramaniam, A., Veerapaneni, R., Rubin, D., 2016\. 使用卷积神经网络和纹理分析的主动轮廓参数自适应估计。IEEE
    Trans Med Imaging。
- en: Hosseini-Asl et al. (2016) Hosseini-Asl, E., Gimel’farb, G., El-Baz, A., 2016\.
    Alzheimer’s disease diagnostics by a deeply supervised adaptable 3D convolutional
    network. arXiv:1607.00556.
  id: totrans-736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hosseini-Asl等（2016）Hosseini-Asl, E., Gimel’farb, G., El-Baz, A., 2016\. 基于深度监督可适应3D卷积网络的阿尔茨海默病诊断。arXiv:1607.00556。
- en: Hu et al. (2016a) Hu, P., Wu, F., Peng, J., Bao, Y., Chen, F., Kong, D., Nov.
    2016a. Automatic abdominal multi-organ segmentation using deep convolutional neural
    network and time-implicit level sets. Int J Comput Assist Radiol Surg.
  id: totrans-737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu等（2016a）Hu, P., Wu, F., Peng, J., Bao, Y., Chen, F., Kong, D., 2016年11月。使用深度卷积神经网络和时间隐式水平集的自动腹部多脏器分割。Int
    J Comput Assist Radiol Surg。
- en: Hu et al. (2016b) Hu, P., Wu, F., Peng, J., Liang, P., Kong, D., Dec. 2016b.
    Automatic 3D liver segmentation based on deep learning and globally optimized
    surface evolution. Phys Med Biol 61, 8676–8698.
  id: totrans-738
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu等（2016b）Hu, P., Wu, F., Peng, J., Liang, P., Kong, D., 2016年12月。基于深度学习和全局优化表面演化的自动3D肝脏分割。Phys
    Med Biol 61, 8676–8698。
- en: 'Huang et al. (2016) Huang, H., Hu, X., Han, J., Lv, J., Liu, N., Guo, L., Liu,
    T., 2016\. Latent source mining in FMRI data via deep neural network. In: IEEE
    Int Symp Biomedical Imaging. pp. 638–641.'
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang等（2016）Huang, H., Hu, X., Han, J., Lv, J., Liu, N., Guo, L., Liu, T.,
    2016\. 通过深度神经网络在FMRI数据中的潜在源挖掘。In: IEEE Int Symp Biomedical Imaging. pp. 638–641。'
- en: Huynh et al. (2016) Huynh, B. Q., Li, H., Giger, M. L., Jul 2016\. Digital mammographic
    tumor classification using transfer learning from deep convolutional neural networks.
    J Med Imaging 3, 034501.
  id: totrans-740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huynh等（2016）Huynh, B. Q., Li, H., Giger, M. L., 2016年7月。使用来自深度卷积神经网络的迁移学习的数字乳腺肿瘤分类。J
    Med Imaging 3, 034501。
- en: Hwang and Kim (2016) Hwang, S., Kim, H., 2016\. Self-transfer learning for fully
    weakly supervised object localization. arXiv:1602.01625.
  id: totrans-741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hwang和Kim（2016）Hwang, S., Kim, H., 2016\. 完全弱监督目标定位的自我迁移学习。arXiv:1602.01625。
- en: 'Hwang et al. (2016) Hwang, S., Kim, H.-E., Jeong, J., Kim, H.-J., 2016\. A
    novel approach for tuberculosis screening based on deep convolutional neural networks.
    In: Medical Imaging. Vol. 9785 of Proceedings of the SPIE. pp. 97852W–1.'
  id: totrans-742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hwang等（2016）Hwang, S., Kim, H.-E., Jeong, J., Kim, H.-J., 2016\. 基于深度卷积神经网络的结核病筛查新方法。In:
    Medical Imaging. Vol. 9785 of Proceedings of the SPIE. pp. 97852W–1。'
- en: 'Jamaludin et al. (2016) Jamaludin, A., Kadir, T., Zisserman, A., 2016\. SpineNet:
    Automatically pinpointing classification evidence in spinal MRIs. In: Med Image
    Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp. 166–175.'
  id: totrans-743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jamaludin等（2016）Jamaludin, A., Kadir, T., Zisserman, A., 2016\. SpineNet: 自动定位脊柱MRI中的分类证据。In:
    Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp.
    166–175。'
- en: 'Jamieson et al. (2012) Jamieson, A. R., Drukker, K., Giger, M. L., 2012\. Breast
    image feature learning with adaptive deconvolutional networks. In: Medical Imaging.
    Vol. 8315 of Proceedings of the SPIE. p. 831506.'
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jamieson等（2012）Jamieson, A. R., Drukker, K., Giger, M. L., 2012\. 使用自适应反卷积网络的乳腺图像特征学习。In:
    Medical Imaging. Vol. 8315 of Proceedings of the SPIE. p. 831506。'
- en: 'Janowczyk et al. (2016a) Janowczyk, A., Basavanhally, A., Madabhushi, A., 2016a.
    Stain normalization using sparse autoencoders (StaNoSA): Application to digital
    pathology. Comput Med Imaging Graph, in press.'
  id: totrans-745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Janowczyk等（2016a）Janowczyk, A., Basavanhally, A., Madabhushi, A., 2016a. 使用稀疏自编码器（StaNoSA）的染色体归一化：应用于数字病理学。Comput
    Med Imaging Graph, in press。
- en: 'Janowczyk et al. (2016b) Janowczyk, A., Doyle, S., Gilmore, H., Madabhushi,
    A., 2016b. A resolution adaptive deep hierarchical (RADHicaL) learning scheme
    applied to nuclear segmentation of digital pathology images. Computer Methods
    in Biomechanics and Biomedical Engineering: Imaging & Visualization, 1–7.'
  id: totrans-746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Janowczyk等（2016b）Janowczyk, A., Doyle, S., Gilmore, H., Madabhushi, A., 2016b.
    应用于数字病理图像核分割的分辨率自适应深层层次（RADHicaL）学习方案。Computer Methods in Biomechanics and Biomedical
    Engineering: Imaging & Visualization, 1–7。'
- en: 'Janowczyk and Madabhushi (2016) Janowczyk, A., Madabhushi, A., 2016\. Deep
    learning for digital pathology image analysis: A comprehensive tutorial with selected
    use cases. Journal of pathology informatics 7, 29.'
  id: totrans-747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Janowczyk和Madabhushi（2016年）Janowczyk, A., Madabhushi, A., 2016年。数字病理学图像分析的深度学习：带有选定用例的全面教程。病理学信息学杂志7,
    29。
- en: Jaumard-Hakoun et al. (2016) Jaumard-Hakoun, A., Xu, K., Roussel-Ragot, P.,
    Dreyfus, G., Denby, B., 2016. Tongue contour extraction from ultrasound images
    based on deep neural network. arXiv:1605.05912.
  id: totrans-748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaumard-Hakoun等人（2016年）Jaumard-Hakoun, A., Xu, K., Roussel-Ragot, P., Dreyfus,
    G., Denby, B., 2016年。基于深度神经网络的超声图像舌轮廓提取。arXiv:1605.05912。
- en: 'Jia et al. (2014) Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J.,
    Girshick, R., Guadarrama, S., Darrell, T., 2014\. Caffe: Convolutional architecture
    for fast feature embedding. In: Proceedings of the 22nd ACM International Conference
    on Multimedia. pp. 675–678.'
  id: totrans-749
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jia等人（2014年）Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick,
    R., Guadarrama, S., Darrell, T., 2014年。Caffe：用于快速特征嵌入的卷积架构。在：第22届ACM国际多媒体会议。pp.
    675–678。
- en: Kainz et al. (2015) Kainz, P., Pfeiffer, M., Urschler, M., 2015\. Semantic segmentation
    of colon glands with deep convolutional neural networks and total variation segmentation.
    arXiv:1511.06919.
  id: totrans-750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kainz等人（2015年）Kainz, P., Pfeiffer, M., Urschler, M., 2015年。使用深度卷积神经网络和总变分分割的结肠腺体语义分割。arXiv:1511.06919。
- en: 'Källén et al. (2016) Källén, H., Molin, J., Heyden, A., Lundstr, C., Aström,
    K., 2016\. Towards grading gleason score using generically trained deep convolutional
    neural networks. In: IEEE Int Symp Biomedical Imaging. pp. 1163–1167.'
  id: totrans-751
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Källén等人（2016年）Källén, H., Molin, J., Heyden, A., Lundstr, C., Aström, K., 2016年。使用通用训练的深度卷积神经网络评分格利森分数。在：IEEE国际生物医学成像研讨会。pp.
    1163–1167。
- en: Kallenberg et al. (2016) Kallenberg, M., Petersen, K., Nielsen, M., Ng, A.,
    Diao, P., Igel, C., Vachon, C., Holland, K., Karssemeijer, N., Lillholm, M., 2016\.
    Unsupervised deep learning applied to breast density segmentation and mammographic
    risk scoring. IEEE Trans Med Imaging 35, 1322–1331.
  id: totrans-752
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kallenberg等人（2016年）Kallenberg, M., Petersen, K., Nielsen, M., Ng, A., Diao,
    P., Igel, C., Vachon, C., Holland, K., Karssemeijer, N., Lillholm, M., 2016年。无监督深度学习应用于乳房密度分割和乳腺X线摄影风险评分。IEEE医学成像期刊35,
    1322–1331。
- en: Kamnitsas et al. (2017) Kamnitsas, K., Ledig, C., Newcombe, V. F., Simpson,
    J. P., Kane, A. D., Menon, D. K., Rueckert, D., Glocker, B., 2017\. Efficient
    multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation.
    Med Image Anal 36, 61–78.
  id: totrans-753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kamnitsas等人（2017年）Kamnitsas, K., Ledig, C., Newcombe, V. F., Simpson, J. P.,
    Kane, A. D., Menon, D. K., Rueckert, D., Glocker, B., 2017年。高效多尺度3D CNN结合全连接CRF用于精确的脑损伤分割。医学图像分析36,
    61–78。
- en: 'Karpathy and Fei-Fei (2015) Karpathy, A., Fei-Fei, L., June 2015\. Deep visual-semantic
    alignments for generating image descriptions. In: Comput Vis Pattern Recognit.
    ArXiv:1412.2306.'
  id: totrans-754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karpathy和Fei-Fei（2015年）Karpathy, A., Fei-Fei, L., 2015年6月。用于生成图像描述的深度视觉-语义对齐。在：计算机视觉和模式识别会议。ArXiv:1412.2306。
- en: 'Kashif et al. (2016) Kashif, M. N., Raza, S. E. A., Sirinukunwattana, K., Arif,
    M., Rajpoot, N., 2016\. Handcrafted features with convolutional neural networks
    for detection of tumor cells in histology images. In: IEEE Int Symp Biomedical
    Imaging. pp. 1029–1032.'
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kashif等人（2016年）Kashif, M. N., Raza, S. E. A., Sirinukunwattana, K., Arif, M.,
    Rajpoot, N., 2016年。手工特征与卷积神经网络在组织学图像中检测肿瘤细胞。在：IEEE国际生物医学成像研讨会。pp. 1029–1032。
- en: 'Kawahara et al. (2016a) Kawahara, J., BenTaieb, A., Hamarneh, G., 2016a. Deep
    features to classify skin lesions. In: IEEE Int Symp Biomedical Imaging. pp. 1397–1400.'
  id: totrans-756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kawahara等人（2016a年）Kawahara, J., BenTaieb, A., Hamarneh, G., 2016a年。深度特征用于分类皮肤病变。在：IEEE国际生物医学成像研讨会。pp.
    1397–1400。
- en: 'Kawahara et al. (2016b) Kawahara, J., Brown, C. J., Miller, S. P., Booth, B. G.,
    Chau, V., Grunau, R. E., Zwicker, J. G., Hamarneh, G., 2016b. BrainNetCNN: Convolutional
    neural networks for brain networks; towards predicting neurodevelopment. NeuroImage.'
  id: totrans-757
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kawahara等人（2016b年）Kawahara, J., Brown, C. J., Miller, S. P., Booth, B. G., Chau,
    V., Grunau, R. E., Zwicker, J. G., Hamarneh, G., 2016b年。BrainNetCNN：用于大脑网络的卷积神经网络；朝着预测神经发育。神经影像。
- en: 'Kawahara and Hamarneh (2016) Kawahara, J., Hamarneh, G., 2016\. Multi-resolution-tract
    CNN with hybrid pretrained and skin-lesion trained layers. In: Machine Learning
    in Medical Imaging. Vol. 10019 of Lect Notes Comput Sci. pp. 164–171.'
  id: totrans-758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kawahara和Hamarneh（2016年）Kawahara, J., Hamarneh, G., 2016年。多分辨率轨迹CNN与混合预训练和皮肤病变训练层。在：医学成像中的机器学习。Lect
    Notes Comput Sci的第10019卷。pp. 164–171。
- en: Kendall and Gal (2017) Kendall, A., Gal, Y., 2017\. What uncertainties do we
    need in bayesian deep learning for computer vision? arXiv:1703.04977.
  id: totrans-759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kendall和Gal（2017年）Kendall, A., Gal, Y., 2017年。在计算机视觉中贝叶斯深度学习需要哪些不确定性？arXiv:1703.04977。
- en: 'Kim et al. (2016a) Kim, E., Cortre-Real, M., Baloch, Z., 2016a. A deep semantic
    mobile application for thyroid cytopathology. In: Medical Imaging. Vol. 9789 of
    Proceedings of the SPIE. p. 97890A.'
  id: totrans-760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 等人（2016a）Kim, E., Cortre-Real, M., Baloch, Z., 2016a\. 用于甲状腺细胞病理学的深度语义移动应用。在：医学成像。《SPIE会议论文集》第
    9789 卷。p. 97890A.
- en: Kim and Hwang (2016) Kim, H., Hwang, S., 2016\. Scale-invariant feature learning
    using deconvolutional neural networks for weakly-supervised semantic segmentation.
    arXiv:1602.04984.
  id: totrans-761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 和 Hwang（2016）Kim, H., Hwang, S., 2016\. 使用反卷积神经网络进行尺度不变特征学习，用于弱监督语义分割。arXiv:1602.04984.
- en: 'Kim et al. (2016b) Kim, J., Calhoun, V. D., Shim, E., Lee, J.-H., 2016b. Deep
    neural network with weight sparsity control and pre-training extracts hierarchical
    features and enhances classification performance: Evidence from whole-brain resting-state
    functional connectivity patterns of schizophrenia. NeuroImage 124, 127–146.'
  id: totrans-762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 等人（2016b）Kim, J., Calhoun, V. D., Shim, E., Lee, J.-H., 2016b\. 具有权重稀疏控制和预训练的深度神经网络提取分层特征，并增强分类性能：基于精神分裂症整个脑部静息态功能连接模式的证据。《神经影像》124,
    127–146.
- en: Kingma and Welling (2013) Kingma, D. P., Welling, M., 2013\. Auto-encoding variational
    bayes. arXiv:1312.6114.
  id: totrans-763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma 和 Welling（2013）Kingma, D. P., Welling, M., 2013\. 自编码变分贝叶斯。arXiv:1312.6114.
- en: 'Kisilev et al. (2016) Kisilev, P., Sason, E., Barkan, E., Hashoul, S., 2016\.
    Medical image description using multi-task-loss CNN. In: International Workshop
    on Large-Scale Annotation of Biomedical Data and Expert Label Synthesis. Springer,
    pp. 121–129.'
  id: totrans-764
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kisilev 等人（2016）Kisilev, P., Sason, E., Barkan, E., Hashoul, S., 2016\. 使用多任务损失CNN进行医学图像描述。在：生物医学数据大规模注释和专家标签综合国际研讨会。Springer,
    pp. 121–129.
- en: 'Kleesiek et al. (2016) Kleesiek, J., Urban, G., Hubert, A., Schwarz, D., Maier-Hein,
    K., Bendszus, M., Biller, A., 2016\. Deep MRI brain extraction: A 3D convolutional
    neural network for skull stripping. NeuroImage 129, 460–469.'
  id: totrans-765
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kleesiek 等人（2016）Kleesiek, J., Urban, G., Hubert, A., Schwarz, D., Maier-Hein,
    K., Bendszus, M., Biller, A., 2016\. 深度MRI脑部提取：用于颅骨去除的3D卷积神经网络。《神经影像》129, 460–469.
- en: 'Kong et al. (2016) Kong, B., Zhan, Y., Shin, M., Denny, T., Zhang, S., 2016\.
    Recognizing end-diastole and end-systole frames via deep temporal regression network.
    In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci.
    pp. 264–272.'
  id: totrans-766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kong 等人（2016）Kong, B., Zhan, Y., Shin, M., Denny, T., Zhang, S., 2016\. 通过深度时间回归网络识别舒张末期和收缩末期帧。在：医学图像计算机辅助干预。《计算机科学讲义》第
    9901 卷。pp. 264–272.
- en: Kooi et al. (2016) Kooi, T., Litjens, G., van Ginneken, B., Gubern-Mérida, A.,
    Sánchez, C. I., Mann, R., den Heeten, A., Karssemeijer, N., 2016\. Large scale
    deep learning for computer aided detection of mammographic lesions. Med Image
    Anal 35, 303–312.
  id: totrans-767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kooi 等人（2016）Kooi, T., Litjens, G., van Ginneken, B., Gubern-Mérida, A., Sánchez,
    C. I., Mann, R., den Heeten, A., Karssemeijer, N., 2016\. 大规模深度学习用于乳腺摄影病变的计算机辅助检测。《医学图像分析》35,
    303–312.
- en: Kooi et al. (2017) Kooi, T., van Ginneken, B., Karssemeijer, N., den Heeten,
    A., 2017. Discriminating solitary cysts from soft tissue lesions in mammography
    using a pretrained deep convolutional neural network. Medical Physics.
  id: totrans-768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kooi 等人（2017）Kooi, T., van Ginneken, B., Karssemeijer, N., den Heeten, A., 2017\.
    使用预训练的深度卷积神经网络在乳房X线摄影中区分孤立囊肿和软组织病变。《医学物理学》。
- en: 'Korez et al. (2016) Korez, R., Likar, B., Pernuš, F., Vrtovec, T., 2016\. Model-based
    segmentation of vertebral bodies from MR images with 3D CNNs. In: Med Image Comput
    Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. Springer, pp. 433–441.'
  id: totrans-769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Korez 等人（2016）Korez, R., Likar, B., Pernuš, F., Vrtovec, T., 2016\. 基于模型的MR图像中椎体分割，使用3D
    CNN。在：医学图像计算机辅助干预。《计算机科学讲义》第 9901 卷。Springer, pp. 433–441.
- en: 'Krizhevsky et al. (2012) Krizhevsky, A., Sutskever, I., Hinton, G., 2012\.
    Imagenet classification with deep convolutional neural networks. In: Advances
    in Neural Information Processing Systems. pp. 1097–1105.'
  id: totrans-770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky 等人（2012）Krizhevsky, A., Sutskever, I., Hinton, G., 2012\. 使用深度卷积神经网络进行Imagenet分类。在：神经信息处理系统进展。pp.
    1097–1105.
- en: 'Kumar et al. (2016) Kumar, A., Sridar, P., Quinton, A., Kumar, R. K., Feng,
    D., Nanan, R., Kim, J., 2016\. Plane identification in fetal ultrasound images
    using saliency maps and convolutional neural networks. In: IEEE Int Symp Biomedical
    Imaging. pp. 791–794.'
  id: totrans-771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kumar 等人（2016）Kumar, A., Sridar, P., Quinton, A., Kumar, R. K., Feng, D., Nanan,
    R., Kim, J., 2016\. 使用显著性图和卷积神经网络在胎儿超声图像中识别平面。在：IEEE国际生物医学成像研讨会。pp. 791–794.
- en: LeCun et al. (1998) LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., 1998\. Gradient-based
    learning applied to document recognition. Proceedings of the IEEE 86, 2278–2324.
  id: totrans-772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun 等人（1998）LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., 1998\. 基于梯度的文档识别应用。《IEEE会议论文集》86,
    2278–2324.
- en: Lekadir et al. (2017) Lekadir, K., Galimzianova, A., Betriu, A., Del Mar Vila,
    M., Igual, L., Rubin, D. L., Fernandez, E., Radeva, P., Napel, S., Jan. 2017\.
    A convolutional neural network for automatic characterization of plaque composition
    in carotid ultrasound. IEEE J Biomed Health Inform 21, 48–55.
  id: totrans-773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lekadir 等（2017）Lekadir, K., Galimzianova, A., Betriu, A., Del Mar Vila, M.,
    Igual, L., Rubin, D. L., Fernandez, E., Radeva, P., Napel, S., 2017年1月。用于自动表征颈动脉超声中斑块成分的卷积神经网络。IEEE
    J Biomed Health Inform 21, 48–55。
- en: 'Lessmann et al. (2016) Lessmann, N., Isgum, I., Setio, A. A., de Vos, B. D.,
    Ciompi, F., de Jong, P. A., Oudkerk, M., Mali, W. P. T. M., Viergever, M. A.,
    van Ginneken, B., 2016\. Deep convolutional neural networks for automatic coronary
    calcium scoring in a screening study with low-dose chest CT. In: Medical Imaging.
    Vol. 9785 of Proceedings of the SPIE. pp. 978511–1 – 978511–6.'
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lessmann 等（2016）Lessmann, N., Isgum, I., Setio, A. A., de Vos, B. D., Ciompi,
    F., de Jong, P. A., Oudkerk, M., Mali, W. P. T. M., Viergever, M. A., van Ginneken,
    B., 2016。用于低剂量胸部CT筛查研究中的自动冠状动脉钙评分的深度卷积神经网络。在：Medical Imaging。第9785卷的Proceedings
    of the SPIE。第978511–1至978511–6页。
- en: 'Li et al. (2014) Li, R., Zhang, W., Suk, H.-I., Wang, L., Li, J., Shen, D.,
    Ji, S., 2014\. Deep learning based imaging data completion for improved brain
    disease diagnosis. In: Med Image Comput Comput Assist Interv. Vol. 8675 of Lect
    Notes Comput Sci. pp. 305–312.'
  id: totrans-775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2014）Li, R., Zhang, W., Suk, H.-I., Wang, L., Li, J., Shen, D., Ji, S.,
    2014。基于深度学习的成像数据补全以改进脑部疾病诊断。在：Med Image Comput Comput Assist Interv。第8675卷的Lect
    Notes Comput Sci。第305–312页。
- en: Li et al. (2016a) Li, W., Cao, P., Zhao, D., Wang, J., 2016a. Pulmonary nodule
    classification with deep convolutional neural networks on computed tomography
    images. Computational and Mathematical Methods in Medicine, 6215085.
  id: totrans-776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2016a）Li, W., Cao, P., Zhao, D., Wang, J., 2016a。基于深度卷积神经网络的肺结节分类。Computational
    and Mathematical Methods in Medicine, 6215085。
- en: Li et al. (2015) Li, W., Jia, F., Hu, Q., 2015\. Automatic segmentation of liver
    tumor in CT images with deep convolutional neural networks. Journal of Computer
    and Communications 3 (11), 146–151.
  id: totrans-777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2015）Li, W., Jia, F., Hu, Q., 2015。使用深度卷积神经网络在CT图像中自动分割肝肿瘤。Journal of Computer
    and Communications 3 (11), 146–151。
- en: 'Li et al. (2016b) Li, W., Manivannan, S., Akbar, S., Zhang, J., Trucco, E.,
    McKenna, S. J., 2016b. Gland segmentation in colon histology images using hand-crafted
    features and convolutional neural networks. In: IEEE Int Symp Biomedical Imaging.
    pp. 1405–1408.'
  id: totrans-778
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2016b）Li, W., Manivannan, S., Akbar, S., Zhang, J., Trucco, E., McKenna,
    S. J., 2016b。使用手工特征和卷积神经网络在结肠组织学图像中进行腺体分割。在：IEEE Int Symp Biomedical Imaging。第1405–1408页。
- en: 'Liao et al. (2013) Liao, S., Gao, Y., Oto, A., Shen, D., 2013\. Representation
    learning: A unified deep learning framework for automatic prostate mr segmentation.
    In: Med Image Comput Comput Assist Interv. Vol. 8150 of Lect Notes Comput Sci.
    pp. 254–261.'
  id: totrans-779
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liao 等（2013）Liao, S., Gao, Y., Oto, A., Shen, D., 2013年。表征学习：一种统一的深度学习框架用于自动前列腺MR分割。在：Med
    Image Comput Comput Assist Interv。第8150卷的Lect Notes Comput Sci。第254–261页。
- en: Lin et al. (2013) Lin, M., Chen, Q., Yan, S., 2013\. Network in network. arXiv:1312.4400.
  id: totrans-780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等（2013）Lin, M., Chen, Q., Yan, S., 2013。网络中的网络。arXiv:1312.4400。
- en: Litjens et al. (2016) Litjens, G., Sánchez, C. I., Timofeeva, N., Hermsen, M.,
    Nagtegaal, I., Kovacs, I., Hulsbergen-van de Kaa, C., Bult, P., van Ginneken,
    B., van der Laak, J., 2016\. Deep learning as a tool for increased accuracy and
    efficiency of histopathological diagnosis. Nat Sci Rep 6, 26286.
  id: totrans-781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Litjens 等（2016）Litjens, G., Sánchez, C. I., Timofeeva, N., Hermsen, M., Nagtegaal,
    I., Kovacs, I., Hulsbergen-van de Kaa, C., Bult, P., van Ginneken, B., van der
    Laak, J., 2016。深度学习作为提高组织病理学诊断准确性和效率的工具。Nat Sci Rep 6, 26286。
- en: 'Liu et al. (2016a) Liu, J., Wang, D., Wei, Z., Lu, L., Kim, L., Turkbey, E.,
    Summers, R. M., 2016a. Colitis detection on computed tomography using regional
    convolutional neural networks. In: IEEE Int Symp Biomedical Imaging. pp. 863–866.'
  id: totrans-782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等（2016a）Liu, J., Wang, D., Wei, Z., Lu, L., Kim, L., Turkbey, E., Summers,
    R. M., 2016a。使用区域卷积神经网络在计算机断层扫描中检测结肠炎。在：IEEE Int Symp Biomedical Imaging。第863–866页。
- en: 'Liu et al. (2016b) Liu, X., Tizhoosh, H. R., Kofman, J., 2016b. Generating
    binary tags for fast medical image retrieval based on convolutional nets and Radon
    transform. In: International Joint Conference on Neural Networks. ArXiv:1604.04676.'
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等（2016b）Liu, X., Tizhoosh, H. R., Kofman, J., 2016b。基于卷积网络和Radon变换的快速医学图像检索的二值标签生成。在：International
    Joint Conference on Neural Networks。ArXiv:1604.04676。
- en: Liu et al. (2017) Liu, Y., Gadepalli, K., Norouzi, M., Dahl, G. E., Kohlberger,
    T., Boyko, A., Venugopalan, S., Timofeev, A., Nelson, P. Q., Corrado, G. S., Hipp,
    J. D., Peng, L., Stumpe, M. C., 2017\. Detecting cancer metastases on gigapixel
    pathology images. arXiv:1703.02442.
  id: totrans-784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等（2017）Liu, Y., Gadepalli, K., Norouzi, M., Dahl, G. E., Kohlberger, T.,
    Boyko, A., Venugopalan, S., Timofeev, A., Nelson, P. Q., Corrado, G. S., Hipp,
    J. D., Peng, L., Stumpe, M. C., 2017年。检测千兆像素病理图像中的癌症转移。arXiv:1703.02442。
- en: Lo et al. (1995) Lo, S.-C., Lou, S.-L., Lin, J.-S., Freedman, M. T., Chien,
    M. V., Mun, S. K., 1995\. Artificial convolution neural network techniques and
    applications for lung nodule detection. IEEE Trans Med Imaging 14, 711–718.
  id: totrans-785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lo等（1995）Lo, S.-C., Lou, S.-L., Lin, J.-S., Freedman, M. T., Chien, M. V., Mun,
    S. K., 1995年。人工卷积神经网络技术及其在肺结节检测中的应用。《IEEE医学成像学报》，14卷，711–718页。
- en: Long et al. (2015) Long, J., Shelhamer, E., Darrell, T., 2015\. Fully convolutional
    networks for semantic segmentation. arXiv:1411.4038.
  id: totrans-786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Long等（2015）Long, J., Shelhamer, E., Darrell, T., 2015年。用于语义分割的全卷积网络。arXiv:1411.4038。
- en: Lu et al. (2017) Lu, F., Wu, F., Hu, P., Peng, Z., Kong, D., Feb. 2017\. Automatic
    3D liver location and segmentation via convolutional neural network and graph
    cut. Int J Comput Assist Radiol Surg 12, 171–182.
  id: totrans-787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu等（2017）Lu, F., Wu, F., Hu, P., Peng, Z., Kong, D., 2017年2月。通过卷积神经网络和图切割进行自动3D肝脏定位和分割。《计算辅助放射外科国际期刊》，12卷，171–182页。
- en: 'Lu et al. (2016) Lu, X., Xu, D., Liu, D., 2016\. Robust 3d organ localization
    with dual learning architectures and fusion. In: DLMIA. Vol. 10008 of Lect Notes
    Comput Sci. pp. 12–20.'
  id: totrans-788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu等（2016）Lu, X., Xu, D., Liu, D., 2016年。通过双重学习架构和融合进行鲁棒的3D器官定位。在《DLMIA》中，第10008卷，《计算机科学讲义》系列，12–20页。
- en: Ma et al. (2017) Ma, J., Wu, F., Zhu, J., Xu, D., Kong, D., Jan 2017\. A pre-trained
    convolutional neural network based method for thyroid nodule diagnosis. Ultrasonics
    73, 221–230.
  id: totrans-789
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma等（2017）Ma, J., Wu, F., Zhu, J., Xu, D., Kong, D., 2017年1月。基于预训练卷积神经网络的方法用于甲状腺结节诊断。《超声学》，73卷，221–230页。
- en: 'Mahapatra et al. (2016) Mahapatra, D., Roy, P. K., Sedai, S., Garnavi, R.,
    2016\. Retinal image quality classification using saliency maps and CNNs. In:
    Machine Learning in Medical Imaging. Vol. 10019 of Lect Notes Comput Sci. pp.
    172–179.'
  id: totrans-790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahapatra等（2016）Mahapatra, D., Roy, P. K., Sedai, S., Garnavi, R., 2016年。使用显著性图和CNN进行视网膜图像质量分类。在《医学成像中的机器学习》中，第10019卷，《计算机科学讲义》系列，172–179页。
- en: Malon and Cosatto (2013) Malon, C. D., Cosatto, E., 2013\. Classification of
    mitotic figures with convolutional neural networks and seeded blob features. Journal
    of pathology informatics.
  id: totrans-791
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Malon和Cosatto（2013）Malon, C. D., Cosatto, E., 2013年。使用卷积神经网络和种子斑点特征进行有丝分裂图像分类。《病理学信息学杂志》。
- en: 'Maninis et al. (2016) Maninis, K.-K., Pont-Tuset, J., Arbeláez, P., Gool, L.,
    2016\. Deep retinal image understanding. In: Med Image Comput Comput Assist Interv.
    Vol. 9901 of Lect Notes Comput Sci. pp. 140–148.'
  id: totrans-792
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maninis等（2016）Maninis, K.-K., Pont-Tuset, J., Arbeláez, P., Gool, L., 2016年。深度视网膜图像理解。在《医学图像计算与计算辅助干预》中，第9901卷，《计算机科学讲义》系列，140–148页。
- en: Mansoor et al. (2016) Mansoor, A., Cerrolaza, J., Idrees, R., Biggs, E., Alsharid,
    M., Avery, R., Linguraru, M. G., 2016\. Deep learning guided partitioned shape
    model for anterior visual pathway segmentation. IEEE Trans Med Imaging 35 (8),
    1856–1865.
  id: totrans-793
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mansoor等（2016）Mansoor, A., Cerrolaza, J., Idrees, R., Biggs, E., Alsharid, M.,
    Avery, R., Linguraru, M. G., 2016年。深度学习指导的分区形状模型用于前视觉通路分割。《IEEE医学成像学报》，35卷（8），1856–1865页。
- en: 'Mao and Yin (2016) Mao, Y., Yin, Z., 2016\. A hierarchical convolutional neural
    network for mitosis detection in phase-contrast microscopy images. In: Med Image
    Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp. 685–692.'
  id: totrans-794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mao和Yin（2016）Mao, Y., Yin, Z., 2016年。在相位对比显微镜图像中用于有丝分裂检测的层次卷积神经网络。在《医学图像计算与计算辅助干预》中，第9901卷，《计算机科学讲义》系列，685–692页。
- en: 'Menegola et al. (2016) Menegola, A., Fornaciali, M., Pires, R., Avila, S.,
    Valle, E., 2016\. Towards automated melanoma screening: Exploring transfer learning
    schemes. arXiv:1609.01228.'
  id: totrans-795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Menegola等（2016）Menegola, A., Fornaciali, M., Pires, R., Avila, S., Valle, E.,
    2016年。迈向自动化黑色素瘤筛查：探索迁移学习方案。arXiv:1609.01228。
- en: Merkow et al. (2016) Merkow, J., Kriegman, D., Marsden, A., Tu, Z., 2016\. Dense
    volume-to-volume vascular boundary detection. arXiv:1605.08401.
  id: totrans-796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Merkow等（2016）Merkow, J., Kriegman, D., Marsden, A., Tu, Z., 2016年。密集体积到体积血管边界检测。arXiv:1605.08401。
- en: Miao et al. (2016) Miao, S., Wang, Z. J., Liao, R., 2016\. A CNN regression
    approach for real-time 2D/3D registration. IEEE Trans Med Imaging 35 (5), 1352–1363.
  id: totrans-797
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miao等（2016）Miao, S., Wang, Z. J., Liao, R., 2016年。用于实时2D/3D配准的CNN回归方法。《IEEE医学成像学报》，35卷（5），1352–1363页。
- en: 'Milletari et al. (2016a) Milletari, F., Ahmadi, S.-A., Kroll, C., Plate, A.,
    Rozanski, V., Maiostre, J., Levin, J., Dietrich, O., Ertl-Wagner, B., Bötzel,
    K., Navab, N., 2016a. Hough-CNN: Deep learning for segmentation of deep brain
    regions in MRI and ultrasound. arXiv:1601.07014.'
  id: totrans-798
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Milletari 等（2016a）Milletari, F., Ahmadi, S.-A., Kroll, C., Plate, A., Rozanski,
    V., Maiostre, J., Levin, J., Dietrich, O., Ertl-Wagner, B., Bötzel, K., Navab,
    N., 2016a. Hough-CNN：用于 MRI 和超声中深脑区域分割的深度学习。arXiv:1601.07014。
- en: 'Milletari et al. (2016b) Milletari, F., Navab, N., Ahmadi, S.-A., 2016b. V-Net:
    Fully convolutional neural networks for volumetric medical image segmentation.
    arXiv:1606.04797.'
  id: totrans-799
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Milletari 等（2016b）Milletari, F., Navab, N., Ahmadi, S.-A., 2016b. V-Net：用于体积医学图像分割的全卷积神经网络。arXiv:1606.04797。
- en: 'Mishra et al. (2016) Mishra, M., Schmitt, S., Wang, L., Strasser, M. K., Marr,
    C., Navab, N., Zischka, H., Peng, T., 2016\. Structure-based assessment of cancerous
    mitochondria using deep networks. In: IEEE Int Symp Biomedical Imaging. pp. 545–548.'
  id: totrans-800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mishra 等（2016）Mishra, M., Schmitt, S., Wang, L., Strasser, M. K., Marr, C.,
    Navab, N., Zischka, H., Peng, T., 2016. 使用深度网络的基于结构的癌性线粒体评估。 In: IEEE Int Symp
    Biomedical Imaging. pp. 545–548。'
- en: Moeskops et al. (2016a) Moeskops, P., Viergever, M. A., Mendrik, A. M., de Vries,
    L. S., Benders, M. J. N. L., Isgum, I., 2016a. Automatic segmentation of MR brain
    images with a convolutional neural network. IEEE Trans Med Imaging 35 (5), 1252–1262.
  id: totrans-801
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moeskops 等（2016a）Moeskops, P., Viergever, M. A., Mendrik, A. M., de Vries, L.
    S., Benders, M. J. N. L., Isgum, I., 2016a. 使用卷积神经网络自动分割 MR 脑图像。IEEE Trans Med
    Imaging 35 (5), 1252–1262。
- en: 'Moeskops et al. (2016b) Moeskops, P., Wolterink, J. M., Velden, B. H. M., Gilhuijs,
    K. G. A., Leiner, T., Viergever, M. A., Isgum, I., 2016b. Deep learning for multi-task
    medical image segmentation in multiple modalities. In: Med Image Comput Comput
    Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp. 478–486.'
  id: totrans-802
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Moeskops 等（2016b）Moeskops, P., Wolterink, J. M., Velden, B. H. M., Gilhuijs,
    K. G. A., Leiner, T., Viergever, M. A., Isgum, I., 2016b. 深度学习用于多任务医学图像分割的多模态应用。
    In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci.
    pp. 478–486。'
- en: Montavon et al. (2017) Montavon, G., Lapuschkin, S., Binder, A., Samek, W.,
    Müller, K.-R., 2017. Explaining nonlinear classification decisions with deep taylor
    decomposition. Pattern Recognition 65, 211–222.
  id: totrans-803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Montavon 等（2017）Montavon, G., Lapuschkin, S., Binder, A., Samek, W., Müller,
    K.-R., 2017. 使用深度泰勒分解解释非线性分类决策。Pattern Recognition 65, 211–222。
- en: 'Moradi et al. (2016a) Moradi, M., Guo, Y., Gur, Y., Negahdar, M., Syeda-Mahmood,
    T., 2016a. A cross-modality neural network transform for semi-automatic medical
    image annotation. In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect
    Notes Comput Sci. pp. 300–307.'
  id: totrans-804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Moradi 等（2016a）Moradi, M., Guo, Y., Gur, Y., Negahdar, M., Syeda-Mahmood, T.,
    2016a. 跨模态神经网络变换用于半自动医学图像注释。 In: Med Image Comput Comput Assist Interv. Vol. 9901
    of Lect Notes Comput Sci. pp. 300–307。'
- en: 'Moradi et al. (2016b) Moradi, M., Gur, Y., Wang, H., Prasanna, P., Syeda-Mahmood,
    T., 2016b. A hybrid learning approach for semantic labeling of cardiac CT slices
    and recognition of body position. In: IEEE Int Symp Biomedical Imaging.'
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Moradi 等（2016b）Moradi, M., Gur, Y., Wang, H., Prasanna, P., Syeda-Mahmood,
    T., 2016b. 一种用于心脏 CT 切片语义标注和身体位置识别的混合学习方法。 In: IEEE Int Symp Biomedical Imaging。'
- en: 'Nappi et al. (2016) Nappi, J. J., Hironaka, T., Regge, D., Yoshida, H., 2016\.
    Deep transfer learning of virtual endoluminal views for the detection of polyps
    in CT colonography. In: Medical Imaging. Proceedings of the SPIE. p. 97852B.'
  id: totrans-806
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nappi 等（2016）Nappi, J. J., Hironaka, T., Regge, D., Yoshida, H., 2016. 虚拟内腔视图的深度迁移学习用于
    CT 结肠造影中的息肉检测。 In: Medical Imaging. Proceedings of the SPIE. p. 97852B。'
- en: 'Nascimento and Carneiro (2016) Nascimento, J. C., Carneiro, G., 2016\. Multi-atlas
    segmentation using manifold learning with deep belief networks. In: IEEE Int Symp
    Biomedical Imaging. pp. 867–871.'
  id: totrans-807
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nascimento 和 Carneiro（2016）Nascimento, J. C., Carneiro, G., 2016. 使用流形学习和深度置信网络的多图谱分割。
    In: IEEE Int Symp Biomedical Imaging. pp. 867–871。'
- en: Ngo et al. (2017) Ngo, T. A., Lu, Z., Carneiro, G., 2017\. Combining deep learning
    and level set for the automated segmentation of the left ventricle of the heart
    from cardiac cine magnetic resonance. Med Image Anal 35, 159–171.
  id: totrans-808
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ngo 等（2017）Ngo, T. A., Lu, Z., Carneiro, G., 2017. 结合深度学习和水平集用于自动分割心脏磁共振成像的左心室。Med
    Image Anal 35, 159–171。
- en: 'Nie et al. (2016a) Nie, D., Cao, X., Gao, Y., Wang, L., Shen, D., 2016a. Estimating
    CT image from MRI data using 3D fully convolutional networks. In: DLMIA. Vol.
    10008 of Lect Notes Comput Sci. pp. 170–178.'
  id: totrans-809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nie 等（2016a）Nie, D., Cao, X., Gao, Y., Wang, L., Shen, D., 2016a. 使用 3D 全卷积网络从
    MRI 数据估计 CT 图像。 In: DLMIA. Vol. 10008 of Lect Notes Comput Sci. pp. 170–178。'
- en: 'Nie et al. (2016b) Nie, D., Wang, L., Gao, Y., Shen, D., 2016b. Fully convolutional
    networks for multi-modality isointense infant brain image segmentation. In: IEEE
    Int Symp Biomedical Imaging. pp. 1342–1345.'
  id: totrans-810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nie 等人（2016b）Nie, D., Wang, L., Gao, Y., Shen, D., 2016b. 用于多模态等强信号婴儿脑图像分割的全卷积网络。在：IEEE
    Int Symp Biomedical Imaging. 第1342–1345页。
- en: 'Nie et al. (2016c) Nie, D., Zhang, H., Adeli, E., Liu, L., Shen, D., 2016c.
    3D deep learning for multi-modal imaging-guided survival time prediction of brain
    tumor patients. In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes
    Comput Sci. pp. 212–220.'
  id: totrans-811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nie 等人（2016c）Nie, D., Zhang, H., Adeli, E., Liu, L., Shen, D., 2016c. 用于多模态成像引导的脑肿瘤患者生存时间预测的3D深度学习。在：Med
    Image Comput Comput Assist Interv. Lect Notes Comput Sci 第9901卷，第212–220页。
- en: 'Nogues et al. (2016) Nogues, I., Lu, L., Wang, X., Roth, H., Bertasius, G.,
    Lay, N., Shi, J., Tsehay, Y., Summers, R. M., 2016\. Automatic lymph node cluster
    segmentation using holistically-nested neural networks and structured optimization
    in CT images. In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes
    Comput Sci. pp. 388–397.'
  id: totrans-812
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nogues 等人（2016）Nogues, I., Lu, L., Wang, X., Roth, H., Bertasius, G., Lay, N.,
    Shi, J., Tsehay, Y., Summers, R. M., 2016\. 使用整体嵌套神经网络和结构优化在CT图像中自动淋巴结群分割。在：Med
    Image Comput Comput Assist Interv. Lect Notes Comput Sci 第9901卷，第388–397页。
- en: 'Oktay et al. (2016) Oktay, O., Bai, W., Lee, M., Guerrero, R., Kamnitsas, K.,
    Caballero, J., Marvao, A., Cook, S., O’Regan, D., Rueckert, D., 2016\. Multi-input
    cardiac image super-resolution using convolutional neural networks. In: Med Image
    Comput Comput Assist Interv. Vol. 9902 of Lect Notes Comput Sci. pp. 246–254.'
  id: totrans-813
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oktay 等人（2016）Oktay, O., Bai, W., Lee, M., Guerrero, R., Kamnitsas, K., Caballero,
    J., Marvao, A., Cook, S., O’Regan, D., Rueckert, D., 2016\. 使用卷积神经网络进行多输入心脏图像超分辨率。在：Med
    Image Comput Comput Assist Interv. Lect Notes Comput Sci 第9902卷，第246–254页。
- en: Ortiz et al. (2016) Ortiz, A., Munilla, J., Górriz, J. M., Ramírez, J., 2016\.
    Ensembles of deep learning architectures for the early diagnosis of the Alzheimer’s
    disease. International Journal of Neural Systems 26, 1650025.
  id: totrans-814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ortiz 等人（2016）Ortiz, A., Munilla, J., Górriz, J. M., Ramírez, J., 2016\. 深度学习架构集成用于早期诊断阿尔茨海默病。International
    Journal of Neural Systems 第26卷，1650025页。
- en: Paeng et al. (2016) Paeng, K., Hwang, S., Park, S., Kim, M., Kim, S., 2016\.
    A unified framework for tumor proliferation score prediction in breast histopathology.
    arXiv:1612.07180.
  id: totrans-815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Paeng 等人（2016）Paeng, K., Hwang, S., Park, S., Kim, M., Kim, S., 2016\. 乳腺组织病理学中肿瘤增殖评分预测的统一框架。arXiv:1612.07180。
- en: 'Pan et al. (2015) Pan, Y., Huang, W., Lin, Z., Zhu, W., Zhou, J., Wong, J.,
    Ding, Z., 2015\. Brain tumor grading based on neural networks and convolutional
    neural networks. In: Conf Proc IEEE Eng Med Biol Soc. pp. 699–702.'
  id: totrans-816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan 等人（2015）Pan, Y., Huang, W., Lin, Z., Zhu, W., Zhou, J., Wong, J., Ding,
    Z., 2015\. 基于神经网络和卷积神经网络的脑肿瘤分级。在：Conf Proc IEEE Eng Med Biol Soc. 第699–702页。
- en: 'Payan and Montana (2015) Payan, A., Montana, G., 2015\. Predicting Alzheimer’s
    disease: a neuroimaging study with 3D convolutional neural networks. arXiv:1502.02506.'
  id: totrans-817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Payan 和 Montana（2015）Payan, A., Montana, G., 2015\. 预测阿尔茨海默病：一项带有三维卷积神经网络的神经影像学研究。arXiv:1502.02506。
- en: 'Payer et al. (2016) Payer, C., Stern, D., Bischof, H., Urschler, M., 2016\.
    Regressing heatmaps for multiple landmark localization using CNNs. In: Med Image
    Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp. 230–238.'
  id: totrans-818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Payer 等人（2016）Payer, C., Stern, D., Bischof, H., Urschler, M., 2016\. 使用卷积神经网络回归热图进行多个地标定位。在：Med
    Image Comput Comput Assist Interv. Lect Notes Comput Sci 第9901卷，第230–238页。
- en: Pereira et al. (2016) Pereira, S., Pinto, A., Alves, V., Silva, C. A., 2016\.
    Brain tumor segmentation using convolutional neural networks in MRI images. IEEE
    Trans Med Imaging.
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pereira 等人（2016）Pereira, S., Pinto, A., Alves, V., Silva, C. A., 2016\. MRI图像中使用卷积神经网络进行脑肿瘤分割。IEEE
    Trans Med Imaging.
- en: 'Phan et al. (2016) Phan, H. T. H., Kumar, A., Kim, J., Feng, D., 2016\. Transfer
    learning of a convolutional neural network for HEp-2 cell image classification.
    In: IEEE Int Symp Biomedical Imaging. pp. 1208–1211.'
  id: totrans-820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Phan 等人（2016）Phan, H. T. H., Kumar, A., Kim, J., Feng, D., 2016\. 转移学习用于HEp-2细胞图像分类的卷积神经网络。在：IEEE
    Int Symp Biomedical Imaging. 第1208–1211页。
- en: Pinaya et al. (2016) Pinaya, W. H. L., Gadelha, A., Doyle, O. M., Noto, C.,
    Zugman, A., Cordeiro, Q., Jackowski, A. P., Bressan, R. A., Sato, J. R., Dec.
    2016\. Using deep belief network modelling to characterize differences in brain
    morphometry in schizophrenia. Nat Sci Rep 6, 38897.
  id: totrans-821
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pinaya 等人（2016）Pinaya, W. H. L., Gadelha, A., Doyle, O. M., Noto, C., Zugman,
    A., Cordeiro, Q., Jackowski, A. P., Bressan, R. A., Sato, J. R., 2016年12月. 利用深度信念网络模型表征精神分裂症脑形态学差异。Nat
    Sci Rep 第6卷，38897页。
- en: 'Plis et al. (2014) Plis, S. M., Hjelm, D. R., Salakhutdinov, R., Allen, E. A.,
    Bockholt, H. J., Long, J. D., Johnson, H. J., Paulsen, J. S., Turner, J. A., Calhoun,
    V. D., 2014\. Deep learning for neuroimaging: a validation study. Frontiers in
    Neuroscience.'
  id: totrans-822
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Plis 等人（2014）Plis, S. M., Hjelm, D. R., Salakhutdinov, R., Allen, E. A., Bockholt,
    H. J., Long, J. D., Johnson, H. J., Paulsen, J. S., Turner, J. A., Calhoun, V. D.,
    2014年。神经影像学的深度学习：验证研究。《Frontiers in Neuroscience》。
- en: Poudel et al. (2016) Poudel, R. P. K., Lamata, P., Montana, G., 2016\. Recurrent
    fully convolutional neural networks for multi-slice MRI cardiac segmentation.
    arXiv:1608.03974.
  id: totrans-823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Poudel 等人（2016）Poudel, R. P. K., Lamata, P., Montana, G., 2016年。用于多层MRI心脏分割的递归完全卷积神经网络。arXiv:1608.03974。
- en: 'Prasoon et al. (2013) Prasoon, A., Petersen, K., Igel, C., Lauze, F., Dam,
    E., Nielsen, M., 2013. Deep feature learning for knee cartilage segmentation using
    a triplanar convolutional neural network. In: Med Image Comput Comput Assist Interv.
    Vol. 8150 of Lect Notes Comput Sci. pp. 246–253.'
  id: totrans-824
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prasoon 等人（2013）Prasoon, A., Petersen, K., Igel, C., Lauze, F., Dam, E., Nielsen,
    M., 2013年。使用三平面卷积神经网络进行膝关节软骨分割的深度特征学习。在：Med Image Comput Comput Assist Interv。《Lect
    Notes Comput Sci》，第8150卷，页246–253。
- en: Prentasic et al. (2016) Prentasic, P., Heisler, M., Mammo, Z., Lee, S., Merkur,
    A., Navajas, E., Beg, M. F., Sarunic, M., Loncaric, S., 2016\. Segmentation of
    the foveal microvasculature using deep learning networks. Journal of Biomedical
    Optics 21, 75008.
  id: totrans-825
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prentasic 等人（2016）Prentasic, P., Heisler, M., Mammo, Z., Lee, S., Merkur, A.,
    Navajas, E., Beg, M. F., Sarunic, M., Loncaric, S., 2016年。使用深度学习网络分割中央凹微血管。《Journal
    of Biomedical Optics》，21，75008。
- en: Prentasic and Loncaric (2016) Prentasic, P., Loncaric, S., 2016\. Detection
    of exudates in fundus photographs using deep neural networks and anatomical landmark
    detection fusion. Comput Methods Programs Biomed 137, 281–292.
  id: totrans-826
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prentasic 和 Loncaric（2016）Prentasic, P., Loncaric, S., 2016年。使用深度神经网络和解剖标志检测融合检测眼底照片中的渗出物。《Comput
    Methods Programs Biomed》，137，281–292。
- en: 'Qiu et al. (2016) Qiu, Y., Wang, Y., Yan, S., Tan, M., Cheng, S., Liu, H.,
    Zheng, B., 2016\. An initial investigation on developing a new method to predict
    short-term breast cancer risk based on deep learning technology. In: Medical Imaging.
    Vol. 9785 of Proceedings of the SPIE. p. 978521.'
  id: totrans-827
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qiu 等人（2016）Qiu, Y., Wang, Y., Yan, S., Tan, M., Cheng, S., Liu, H., Zheng,
    B., 2016年。关于基于深度学习技术预测短期乳腺癌风险新方法的初步研究。在：医学成像。《SPIE会议录》，第9785卷，第978521页。
- en: Quinn et al. (2016) Quinn, J. A., Nakasi, R., Mugagga, P. K. B., Byanyima, P.,
    Lubega, W., Andama, A., 2016\. Deep convolutional neural networks for microscopy-based
    point of care diagnostics. arXiv:1608.02989.
  id: totrans-828
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Quinn 等人（2016）Quinn, J. A., Nakasi, R., Mugagga, P. K. B., Byanyima, P., Lubega,
    W., Andama, A., 2016年。基于显微镜的点滴诊断的深度卷积神经网络。arXiv:1608.02989。
- en: 'Rajchl et al. (2016a) Rajchl, M., Lee, M. C., Oktay, O., Kamnitsas, K., Passerat-Palmbach,
    J., Bai, W., Kainz, B., Rueckert, D., 2016a. DeepCut: Object segmentation from
    bounding box annotations using convolutional neural networks. IEEE Trans Med Imaging,
    in press.'
  id: totrans-829
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajchl 等人（2016a）Rajchl, M., Lee, M. C., Oktay, O., Kamnitsas, K., Passerat-Palmbach,
    J., Bai, W., Kainz, B., Rueckert, D., 2016a. DeepCut：使用卷积神经网络从边界框注释中进行对象分割。《IEEE
    Trans Med Imaging》，即将发表。
- en: Rajchl et al. (2016b) Rajchl, M., Lee, M. C., Schrans, F., Davidson, A., Passerat-Palmbach,
    J., Tarroni, G., Alansary, A., Oktay, O., Kainz, B., Rueckert, D., 2016b. Learning
    under distributed weak supervision. arXiv:1606.01100.
  id: totrans-830
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajchl 等人（2016b）Rajchl, M., Lee, M. C., Schrans, F., Davidson, A., Passerat-Palmbach,
    J., Tarroni, G., Alansary, A., Oktay, O., Kainz, B., Rueckert, D., 2016b. 基于分布式弱监督学习。arXiv:1606.01100。
- en: Rajkomar et al. (2017) Rajkomar, A., Lingam, S., Taylor, A. G., Blum, M., Mongan,
    J., 2017. High-throughput classification of radiographs using deep convolutional
    neural networks. J Digit Imaging 30, 95–101.
  id: totrans-831
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajkomar 等人（2017）Rajkomar, A., Lingam, S., Taylor, A. G., Blum, M., Mongan,
    J., 2017年。使用深度卷积神经网络对放射图像进行高通量分类。《J Digit Imaging》，30，95–101。
- en: Ravi et al. (2017) Ravi, D., Wong, C., Deligianni, F., Berthelot, M., Andreu-Perez,
    J., Lo, B., Yang, G.-Z., Jan. 2017\. Deep learning for health informatics. IEEE
    J Biomed Health Inform 21, 4–21.
  id: totrans-832
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ravi 等人（2017）Ravi, D., Wong, C., Deligianni, F., Berthelot, M., Andreu-Perez,
    J., Lo, B., Yang, G.-Z., 2017年1月。健康信息学的深度学习。《IEEE J Biomed Health Inform》，21，4–21。
- en: 'Ravishankar et al. (2016a) Ravishankar, H., Prabhu, S. M., Vaidya, V., Singhal,
    N., 2016a. Hybrid approach for automatic segmentation of fetal abdomen from ultrasound
    images using deep learning. In: IEEE Int Symp Biomedical Imaging. pp. 779–782.'
  id: totrans-833
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ravishankar 等人（2016a）Ravishankar, H., Prabhu, S. M., Vaidya, V., Singhal, N.,
    2016a。混合方法自动分割胎儿腹部超声图像中的深度学习。在：IEEE Int Symp Biomedical Imaging。页779–782。
- en: 'Ravishankar et al. (2016b) Ravishankar, H., Sudhakar, P., Venkataramani, R.,
    Thiruvenkadam, S., Annangi, P., Babu, N., Vaidya, V., 2016b. Understanding the
    mechanisms of deep transfer learning for medical images. In: DLMIA. Vol. 10008
    of Lect Notes Comput Sci. pp. 188–196.'
  id: totrans-834
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ravishankar等（2016b）Ravishankar, H., Sudhakar, P., Venkataramani, R., Thiruvenkadam,
    S., Annangi, P., Babu, N., Vaidya, V., 2016b. 理解深度迁移学习在医学图像中的机制。见于：DLMIA. Lect
    Notes Comput Sci第10008卷，第188–196页。
- en: Rezaeilouyeh et al. (2016) Rezaeilouyeh, H., Mollahosseini, A., Mahoor, M. H.,
    2016\. Microscopic medical image classification framework via deep learning and
    shearlet transform. Journal of Medical Imaging 3 (4), 044501.
  id: totrans-835
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rezaeilouyeh等（2016）Rezaeilouyeh, H., Mollahosseini, A., Mahoor, M. H., 2016.
    通过深度学习和剪切波变换的显微医学图像分类框架。Journal of Medical Imaging第3卷（第4期），044501。
- en: Romo-Bucheli et al. (2016) Romo-Bucheli, D., Janowczyk, A., Gilmore, H., Romero,
    E., Madabhushi, A., Sep 2016\. Automated tubule nuclei quantification and correlation
    with Oncotype DX risk categories in ER+ breast cancer whole slide images. Nat
    Sci Rep 6, 32706.
  id: totrans-836
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Romo-Bucheli等（2016）Romo-Bucheli, D., Janowczyk, A., Gilmore, H., Romero, E.,
    Madabhushi, A., 2016年9月。自动管状核定量及与ER+乳腺癌全切片图像中的Oncotype DX风险类别的相关性。Nat Sci Rep第6卷，32706。
- en: 'Ronneberger et al. (2015) Ronneberger, O., Fischer, P., Brox, T., 2015\. U-net:
    Convolutional networks for biomedical image segmentation. In: Med Image Comput
    Comput Assist Interv. Vol. 9351 of Lect Notes Comput Sci. pp. 234–241.'
  id: totrans-837
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ronneberger等（2015）Ronneberger, O., Fischer, P., Brox, T., 2015. U-net: 用于生物医学图像分割的卷积网络。见于：Med
    Image Comput Comput Assist Interv. Lect Notes Comput Sci第9351卷，第234–241页。'
- en: 'Roth et al. (2015a) Roth, H. R., Lee, C. T., Shin, H.-C., Seff, A., Kim, L.,
    Yao, J., Lu, L., Summers, R. M., 2015a. Anatomy-specific classification of medical
    images using deep convolutional nets. In: IEEE Int Symp Biomedical Imaging. pp.
    101–104.'
  id: totrans-838
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roth等（2015a）Roth, H. R., Lee, C. T., Shin, H.-C., Seff, A., Kim, L., Yao, J.,
    Lu, L., Summers, R. M., 2015a. 使用深度卷积网络进行解剖特定的医学图像分类。见于：IEEE Int Symp Biomedical
    Imaging，第101–104页。
- en: 'Roth et al. (2015b) Roth, H. R., Lu, L., Farag, A., Shin, H.-C., Liu, J., Turkbey,
    E. B., Summers, R. M., 2015b. DeepOrgan: Multi-level deep convolutional networks
    for automated pancreas segmentation. In: Med Image Comput Comput Assist Interv.
    Vol. 9349 of Lect Notes Comput Sci. pp. 556–564.'
  id: totrans-839
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Roth等（2015b）Roth, H. R., Lu, L., Farag, A., Shin, H.-C., Liu, J., Turkbey,
    E. B., Summers, R. M., 2015b. DeepOrgan: 多层深度卷积网络用于自动胰腺分割。见于：Med Image Comput
    Comput Assist Interv. Lect Notes Comput Sci第9349卷，第556–564页。'
- en: 'Roth et al. (2016a) Roth, H. R., Lu, L., Farag, A., Sohn, A., Summers, R. M.,
    2016a. Spatial aggregation of holistically-nested networks for automated pancreas
    segmentation. In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes
    Comput Sci. pp. 451–459.'
  id: totrans-840
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roth等（2016a）Roth, H. R., Lu, L., Farag, A., Sohn, A., Summers, R. M., 2016a.
    全面嵌套网络的空间聚合用于自动胰腺分割。见于：Med Image Comput Comput Assist Interv. Lect Notes Comput
    Sci第9901卷，第451–459页。
- en: Roth et al. (2016b) Roth, H. R., Lu, L., Liu, J., Yao, J., Seff, A., Cherry,
    K., Kim, L., Summers, R. M., 2016b. Improving computer-aided detection using convolutional
    neural networks and random view aggregation. IEEE Trans Med Imaging 35 (5), 1170–1181.
  id: totrans-841
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roth等（2016b）Roth, H. R., Lu, L., Liu, J., Yao, J., Seff, A., Cherry, K., Kim,
    L., Summers, R. M., 2016b. 使用卷积神经网络和随机视图聚合改进计算机辅助检测。IEEE Trans Med Imaging第35卷（第5期），1170–1181。
- en: 'Roth et al. (2014) Roth, H. R., Lu, L., Seff, A., Cherry, K. M., Hoffman, J.,
    Wang, S., Liu, J., Turkbey, E., Summers, R. M., 2014\. A new 2.5D representation
    for lymph node detection using random sets of deep convolutional neural network
    observations. In: Med Image Comput Comput Assist Interv. Vol. 8673 of Lect Notes
    Comput Sci. pp. 520–527.'
  id: totrans-842
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roth等（2014）Roth, H. R., Lu, L., Seff, A., Cherry, K. M., Hoffman, J., Wang,
    S., Liu, J., Turkbey, E., Summers, R. M., 2014. 使用深度卷积神经网络观察的随机集合进行淋巴结检测的新2.5D表示。见于：Med
    Image Comput Comput Assist Interv. Lect Notes Comput Sci第8673卷，第520–527页。
- en: 'Roth et al. (2016c) Roth, H. R., Wang, Y., Yao, J., Lu, L., Burns, J. E., Summers,
    R. M., 2016c. Deep convolutional networks for automated detection of posterior-element
    fractures on spine CT. In: Medical Imaging. Vol. 9785 of Proceedings of the SPIE.
    p. 97850P.'
  id: totrans-843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roth等（2016c）Roth, H. R., Wang, Y., Yao, J., Lu, L., Burns, J. E., Summers, R.
    M., 2016c. 深度卷积网络用于自动检测脊柱CT上的后元素骨折。见于：Medical Imaging. SPIE会议录第9785卷，第97850P页。
- en: 'Roth et al. (2015c) Roth, H. R., Yao, J., Lu, L., Stieger, J., Burns, J. E.,
    Summers, R. M., 2015c. Detection of sclerotic spine metastases via random aggregation
    of deep convolutional?neural network classifications. In: Recent Advances in Computational
    Methods and Clinical Applications for Spine Imaging. Vol. 20 of Lecture Notes
    in Computational Vision and Biomechanics. pp. 3–12.'
  id: totrans-844
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roth 等 (2015c) Roth, H. R., Yao, J., Lu, L., Stieger, J., Burns, J. E., Summers,
    R. M., 2015c. 通过深度卷积神经网络分类的随机聚合检测硬化性脊柱转移瘤。收录于：脊柱成像的计算方法与临床应用最新进展。计算视觉与生物力学讲义第20卷，第3–12页。
- en: Rupprecht et al. (2016) Rupprecht, C., Huaroc, E., Baust, M., Navab, N., 2016\.
    Deep active contours. arXiv:1607.05074.
  id: totrans-845
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rupprecht 等 (2016) Rupprecht, C., Huaroc, E., Baust, M., Navab, N., 2016. 深度主动轮廓。arXiv:1607.05074。
- en: Russakovsky et al. (2014) Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh,
    S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A. C., Fei-Fei,
    L., 2014. ImageNet large scale visual recognition challenge. Int J Comput Vis
    115 (3), 1–42.
  id: totrans-846
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russakovsky 等 (2014) Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh,
    S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A. C., Fei-Fei,
    L., 2014. ImageNet 大规模视觉识别挑战。计算机视觉国际杂志 115 (3), 1–42。
- en: 'Sahiner et al. (1996) Sahiner, B., Chan, H.-P., Petrick, N., Wei, D., Helvie,
    M. A., Adler, D. D., Goodsitt, M. M., 1996\. Classification of mass and normal
    breast tissue: a convolution neural network classifier with spatial domain and
    texture images. IEEE Trans Med Imaging 15, 598–610.'
  id: totrans-847
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sahiner 等 (1996) Sahiner, B., Chan, H.-P., Petrick, N., Wei, D., Helvie, M.
    A., Adler, D. D., Goodsitt, M. M., 1996. 肿块与正常乳腺组织的分类：结合空间域和纹理图像的卷积神经网络分类器。IEEE
    医学成像汇刊 15, 598–610。
- en: 'Samala et al. (2016a) Samala, R. K., Chan, H.-P., Hadjiiski, L., Cha, K., Helvie,
    M. A., 2016a. Deep-learning convolution neural network for computer-aided detection
    of microcalcifications in digital breast tomosynthesis. In: Medical Imaging. Vol.
    9785 of Proceedings of the SPIE. p. 97850Y.'
  id: totrans-848
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Samala 等 (2016a) Samala, R. K., Chan, H.-P., Hadjiiski, L., Cha, K., Helvie,
    M. A., 2016a. 深度学习卷积神经网络用于数字乳腺断层合成中微钙化的计算机辅助检测。收录于：医学成像。SPIE会议录第9785卷，第97850Y页。
- en: 'Samala et al. (2016b) Samala, R. K., Chan, H.-P., Hadjiiski, L., Helvie, M. A.,
    Wei, J., Cha, K., 2016b. Mass detection in digital breast tomosynthesis: Deep
    convolutional neural network with transfer learning from mammography. Medical
    Physics 43 (12), 6654–6666.'
  id: totrans-849
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Samala 等 (2016b) Samala, R. K., Chan, H.-P., Hadjiiski, L., Helvie, M. A., Wei,
    J., Cha, K., 2016b. 数字乳腺断层合成中的肿块检测：深度卷积神经网络结合乳腺摄影的迁移学习。医学物理 43 (12), 6654–6666。
- en: Sarraf and Tofighi (2016) Sarraf, S., Tofighi, G., 2016\. Classification of
    Alzheimer’s disease using fMRI data and deep learning convolutional neural networks.
    arXiv:1603.08631.
  id: totrans-850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sarraf 和 Tofighi (2016) Sarraf, S., Tofighi, G., 2016. 使用fMRI数据和深度学习卷积神经网络对阿尔茨海默病进行分类。arXiv:1603.08631。
- en: Schaumberg et al. (2016) Schaumberg, A. J., Rubin, M. A., Fuchs, T. J., 2016\.
    H&E-stained whole slide deep learning predicts SPOP mutation state in prostate
    cancer. bioRxiv:064279.
  id: totrans-851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schaumberg 等 (2016) Schaumberg, A. J., Rubin, M. A., Fuchs, T. J., 2016. H&E染色全切片深度学习预测前列腺癌中的SPOP突变状态。bioRxiv:064279。
- en: 'Schlegl et al. (2015) Schlegl, T., Waldstein, S. M., Vogl, W.-D., Schmidt-Erfurth,
    U., Langs, G., 2015\. Predicting semantic descriptions from medical images with
    convolutional neural networks. In: Inf Process Med Imaging. Vol. 9123 of Lect
    Notes Comput Sci. pp. 437–448.'
  id: totrans-852
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schlegl 等 (2015) Schlegl, T., Waldstein, S. M., Vogl, W.-D., Schmidt-Erfurth,
    U., Langs, G., 2015. 从医学图像中预测语义描述的卷积神经网络。收录于：医学成像信息处理。计算机科学讲义第9123卷，第437–448页。
- en: Sethi et al. (2016) Sethi, A., Sha, L., Vahadane, A. R., Deaton, R. J., Kumar,
    N., Macias, V., Gann, P. H., 2016\. Empirical comparison of color normalization
    methods for epithelial-stromal classification in H and E images. J Pathol Inform
    7, 17.
  id: totrans-853
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sethi 等 (2016) Sethi, A., Sha, L., Vahadane, A. R., Deaton, R. J., Kumar, N.,
    Macias, V., Gann, P. H., 2016. 颜色标准化方法在H和E图像上用于上皮-间质分类的经验比较。病理信息学杂志 7, 17。
- en: 'Setio et al. (2016) Setio, A. A. A., Ciompi, F., Litjens, G., Gerke, P., Jacobs,
    C., van Riel, S., Wille, M. W., Naqibullah, M., Sanchez, C., van Ginneken, B.,
    2016\. Pulmonary nodule detection in CT images: false positive reduction using
    multi-view convolutional networks. IEEE Trans Med Imaging 35 (5), 1160–1169.'
  id: totrans-854
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Setio 等 (2016) Setio, A. A. A., Ciompi, F., Litjens, G., Gerke, P., Jacobs,
    C., van Riel, S., Wille, M. W., Naqibullah, M., Sanchez, C., van Ginneken, B.,
    2016. CT图像中的肺结节检测：利用多视图卷积网络减少假阳性。IEEE 医学成像汇刊 35 (5), 1160–1169。
- en: 'Sevetlidis et al. (2016) Sevetlidis, V., Giuffrida, M. V., Tsaftaris, S. A.,
    Jan. 2016\. Whole image synthesis using a deep encoder-decoder network. In: Simulation
    and Synthesis in Medical Imaging. Vol. 9968 of Lect Notes Comput Sci. pp. 127–137.'
  id: totrans-855
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sevetlidis 等人 (2016) Sevetlidis, V., Giuffrida, M. V., Tsaftaris, S. A., 2016
    年 1 月。使用深度编码器-解码器网络的整体图像合成。在：医学成像中的模拟与合成。第 9968 卷，Lect Notes Comput Sci。第 127–137
    页。
- en: 'Shah et al. (2016) Shah, A., Conjeti, S., Navab, N., Katouzian, A., 2016\.
    Deeply learnt hashing forests for content based image retrieval in prostate MR
    images. In: Medical Imaging. Vol. 9784 of Proceedings of the SPIE. p. 978414.'
  id: totrans-856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shah 等人 (2016) Shah, A., Conjeti, S., Navab, N., Katouzian, A., 2016。用于前列腺 MR
    图像内容检索的深度学习哈希森林。在：医学成像。第 9784 卷，SPIE 会议录。第 978414 页。
- en: 'Shakeri et al. (2016) Shakeri, M., Tsogkas, S., Ferrante, E., Lippe, S., Kadoury,
    S., Paragios, N., Kokkinos, I., 2016\. Sub-cortical brain structure segmentation
    using F-CNNs. In: IEEE Int Symp Biomedical Imaging. pp. 269–272.'
  id: totrans-857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shakeri 等人 (2016) Shakeri, M., Tsogkas, S., Ferrante, E., Lippe, S., Kadoury,
    S., Paragios, N., Kokkinos, I., 2016。使用 F-CNNs 的皮层下脑结构分割。在：IEEE 生物医学成像国际研讨会。第
    269–272 页。
- en: Shen et al. (2017) Shen, D., Wu, G., Suk, H.-I., Mar. 2017\. Deep learning in
    medical image analysis. Annu Rev Biomed Eng.
  id: totrans-858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等人 (2017) Shen, D., Wu, G., Suk, H.-I., 2017 年 3 月。深度学习在医学图像分析中的应用。Annu
    Rev Biomed Eng。
- en: 'Shen et al. (2015a) Shen, W., Yang, F., Mu, W., Yang, C., Yang, X., Tian, J.,
    2015a. Automatic localization of vertebrae based on convolutional neural networks.
    In: Medical Imaging. Vol. 9413 of Proceedings of the SPIE. p. 94132E.'
  id: totrans-859
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等人 (2015a) Shen, W., Yang, F., Mu, W., Yang, C., Yang, X., Tian, J., 2015a.
    基于卷积神经网络的自动脊椎定位。在：医学成像。第 9413 卷，SPIE 会议录。第 94132E 页。
- en: 'Shen et al. (2016) Shen, W., Zhou, M., Yang, F., Dong, D., Yang, C., Zang,
    Y., Tian, J., 2016. Learning from experts: Developing transferable deep features
    for patient-level lung cancer prediction. In: Med Image Comput Comput Assist Interv.
    Vol. 9901 of Lect Notes Comput Sci. pp. 124–131.'
  id: totrans-860
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等人 (2016) Shen, W., Zhou, M., Yang, F., Dong, D., Yang, C., Zang, Y., Tian,
    J., 2016. 从专家中学习：开发可转移的深度特征用于患者级别的肺癌预测。在：医学图像计算与计算机辅助干预。第 9901 卷，Lect Notes Comput
    Sci。第 124–131 页。
- en: 'Shen et al. (2015b) Shen, W., Zhou, M., Yang, F., Yang, C., Tian, J., 2015b.
    Multi-scale convolutional neural networks for lung nodule classification. In:
    Inf Process Med Imaging. Vol. 9123 of Lect Notes Comput Sci. pp. 588–599.'
  id: totrans-861
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等人 (2015b) Shen, W., Zhou, M., Yang, F., Yang, C., Tian, J., 2015b. 用于肺结节分类的多尺度卷积神经网络。在：医学图像处理。第
    9123 卷，Lect Notes Comput Sci。第 588–599 页。
- en: Shi et al. (2017) Shi, J., Zheng, X., Li, Y., Zhang, Q., Ying, S., Jan. 2017\.
    Multimodal neuroimaging feature learning with multimodal stacked deep polynomial
    networks for diagnosis of Alzheimer’s disease. IEEE J Biomed Health Inform, in
    press.
  id: totrans-862
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等人 (2017) Shi, J., Zheng, X., Li, Y., Zhang, Q., Ying, S., 2017 年 1 月。用于阿尔茨海默病诊断的多模态神经影像特征学习与多模态堆叠深度多项式网络。IEEE
    J Biomed Health Inform, 即将发表。
- en: 'Shin et al. (2015) Shin, H.-C., Lu, L., Kim, L., Seff, A., Yao, J., Summers,
    R. M., 2015. Interleaved text/image deep mining on a very large-scale radiology
    database. In: Comput Vis Pattern Recognit. pp. 1090–1099.'
  id: totrans-863
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shin 等人 (2015) Shin, H.-C., Lu, L., Kim, L., Seff, A., Yao, J., Summers, R.
    M., 2015. 在大规模放射数据库上进行交错的文本/图像深度挖掘。在：计算机视觉与模式识别。第 1090–1099 页。
- en: Shin et al. (2013) Shin, H.-C., Orton, M. R., Collins, D. J., Doran, S. J.,
    Leach, M. O., 2013. Stacked autoencoders for unsupervised feature learning and
    multiple organ detection in a pilot study using 4D patient data. IEEE Trans Pattern
    Anal Mach Intell 35, 1930–1943.
  id: totrans-864
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shin 等人 (2013) Shin, H.-C., Orton, M. R., Collins, D. J., Doran, S. J., Leach,
    M. O., 2013. 堆叠自编码器用于无监督特征学习和在使用 4D 患者数据的试点研究中的多脏器检测。IEEE Trans Pattern Anal Mach
    Intell 35, 1930–1943。
- en: 'Shin et al. (2016a) Shin, H.-C., Roberts, K., Lu, L., Demner-Fushman, D., Yao,
    J., Summers, R. M., 2016a. Learning to read chest x-rays: Recurrent neural cascade
    model for automated image annotation. arXiv:1603.08486.'
  id: totrans-865
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shin 等人 (2016a) Shin, H.-C., Roberts, K., Lu, L., Demner-Fushman, D., Yao, J.,
    Summers, R. M., 2016a. 学习解读胸部 X 光片：用于自动化图像注释的递归神经级联模型。arXiv:1603.08486。
- en: 'Shin et al. (2016b) Shin, H.-C., Roth, H. R., Gao, M., Lu, L., Xu, Z., Nogues,
    I., Yao, J., Mollura, D., Summers, R. M., 2016b. Deep convolutional neural networks
    for computer-aided detection: CNN architectures, dataset characteristics and transfer
    learning. IEEE Trans Med Imaging 35 (5), 1285–1298.'
  id: totrans-866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shin 等人 (2016b) Shin, H.-C., Roth, H. R., Gao, M., Lu, L., Xu, Z., Nogues, I.,
    Yao, J., Mollura, D., Summers, R. M., 2016b. 用于计算机辅助检测的深度卷积神经网络：CNN 架构、数据集特征和迁移学习。IEEE
    Trans Med Imaging 35 (5), 1285–1298。
- en: 'Shkolyar et al. (2015) Shkolyar, A., Gefen, A., Benayahu, D., Greenspan, H.,
    2015\. Automatic detection of cell divisions (mitosis) in live-imaging microscopy
    images using convolutional neural networks. In: Conf Proc IEEE Eng Med Biol Soc.
    pp. 743–746.'
  id: totrans-867
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shkolyar 等（2015）Shkolyar, A., Gefen, A., Benayahu, D., Greenspan, H., 2015\.
    使用卷积神经网络自动检测活体显微成像图像中的细胞分裂（有丝分裂）。发表于：Conf Proc IEEE Eng Med Biol Soc. pp. 743–746。
- en: 'Simonovsky et al. (2016) Simonovsky, M., Gutiérrez-Becker, B., Mateus, D.,
    Navab, N., Komodakis, N., 2016\. A deep metric for multimodal registration. In:
    Med Image Comput Comput Assist Interv. Vol. 9902 of Lect Notes Comput Sci. pp.
    10–18.'
  id: totrans-868
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simonovsky 等（2016）Simonovsky, M., Gutiérrez-Becker, B., Mateus, D., Navab, N.,
    Komodakis, N., 2016\. 用于多模态配准的深度度量。发表于：Med Image Comput Comput Assist Interv.
    Vol. 9902 of Lect Notes Comput Sci. pp. 10–18。
- en: Simonyan and Zisserman (2014) Simonyan, K., Zisserman, A., 2014\. Very deep
    convolutional networks for large-scale image recognition. arXiv:1409.1556.
  id: totrans-869
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simonyan 和 Zisserman（2014）Simonyan, K., Zisserman, A., 2014\. 用于大规模图像识别的非常深的卷积网络。arXiv:1409.1556。
- en: Sirinukunwattana et al. (2016) Sirinukunwattana, K., Raza, S. E. A., Tsang,
    Y.-W., Snead, D. R., Cree, I. A., Rajpoot, N. M., 2016\. Locality sensitive deep
    learning for detection and classification of nuclei in routine colon cancer histology
    images. IEEE Trans Med Imaging 35 (5), 1196–1206.
  id: totrans-870
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sirinukunwattana 等（2016）Sirinukunwattana, K., Raza, S. E. A., Tsang, Y.-W.,
    Snead, D. R., Cree, I. A., Rajpoot, N. M., 2016\. 用于例行结肠癌组织学图像中核检测和分类的局部敏感深度学习。IEEE
    Trans Med Imaging 35 (5), 1196–1206。
- en: 'Smistad and Løvstakken (2016) Smistad, E., Løvstakken, L., 2016\. Vessel detection
    in ultrasound images using deep convolutional neural networks. In: DLMIA. Vol.
    10008 of Lect Notes Comput Sci. pp. 30–38.'
  id: totrans-871
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Smistad 和 Løvstakken（2016）Smistad, E., Løvstakken, L., 2016\. 使用深度卷积神经网络在超声图像中检测血管。发表于：DLMIA.
    Vol. 10008 of Lect Notes Comput Sci. pp. 30–38。
- en: 'Snoek et al. (2012) Snoek, J., Larochelle, H., Adams, R. P., 2012\. Practical
    bayesian optimization of machine learning algorithms. In: Advances in Neural Information
    Processing Systems. pp. 2951–2959.'
  id: totrans-872
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Snoek 等（2012）Snoek, J., Larochelle, H., Adams, R. P., 2012\. 机器学习算法的实用贝叶斯优化。发表于：Neural
    Information Processing Systems 进展. pp. 2951–2959。
- en: Song et al. (2017) Song, Y., Tan, E.-L., Jiang, X., Cheng, J.-Z., Ni, D., Chen,
    S., Lei, B., Wang, T., Sep 2017\. Accurate cervical cell segmentation from overlapping
    clumps in pap smear images. IEEE Trans Med Imaging 36, 288–300.
  id: totrans-873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song 等（2017）Song, Y., Tan, E.-L., Jiang, X., Cheng, J.-Z., Ni, D., Chen, S.,
    Lei, B., Wang, T., 2017年9月\. 从重叠的团块中准确分割宫颈细胞。IEEE Trans Med Imaging 36, 288–300。
- en: Song et al. (2015) Song, Y., Zhang, L., Chen, S., Ni, D., Lei, B., Wang, T.,
    2015\. Accurate segmentation of cervical cytoplasm and nuclei based on multiscale
    convolutional network and graph partitioning. IEEE Trans Biomed Eng 62 (10), 2421–2433.
  id: totrans-874
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song 等（2015）Song, Y., Zhang, L., Chen, S., Ni, D., Lei, B., Wang, T., 2015\.
    基于多尺度卷积网络和图划分的宫颈细胞质和细胞核的准确分割。IEEE Trans Biomed Eng 62 (10), 2421–2433。
- en: Spampinato et al. (2017) Spampinato, C., Palazzo, S., Giordano, D., Aldinucci,
    M., Leonardi, R., Feb. 2017\. Deep learning for automated skeletal bone age assessment
    in X-ray images. Med Image Anal 36, 41–51.
  id: totrans-875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spampinato 等（2017）Spampinato, C., Palazzo, S., Giordano, D., Aldinucci, M.,
    Leonardi, R., 2017年2月\. 用于 X 光图像中自动骨龄评估的深度学习。Med Image Anal 36, 41–51。
- en: 'Springenberg et al. (2014) Springenberg, J. T., Dosovitskiy, A., Brox, T.,
    Riedmiller, M., 2014\. Striving for simplicity: The all convolutional net. arXiv
    preprint arXiv:1412.6806.'
  id: totrans-876
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Springenberg 等（2014）Springenberg, J. T., Dosovitskiy, A., Brox, T., Riedmiller,
    M., 2014\. 追求简洁：全卷积网络。arXiv 预印本 arXiv:1412.6806。
- en: 'Štern et al. (2016) Štern, D., Payer, C., Lepetit, V., Urschler, M., 2016\.
    Automated age estimation from hand MRI volumes using deep learning. In: Med Image
    Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp. 194–202.'
  id: totrans-877
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Štern 等（2016）Štern, D., Payer, C., Lepetit, V., Urschler, M., 2016\. 使用深度学习从手部
    MRI 体积中自动估计年龄。发表于：Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes
    Comput Sci. pp. 194–202。
- en: 'Stollenga et al. (2015) Stollenga, M. F., Byeon, W., Liwicki, M., Schmidhuber,
    J., 2015\. Parallel multi-dimensional LSTM, with application to fast biomedical
    volumetric image segmentation. In: Advances in Neural Information Processing Systems.
    pp. 2998–3006.'
  id: totrans-878
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stollenga 等（2015）Stollenga, M. F., Byeon, W., Liwicki, M., Schmidhuber, J.,
    2015\. 并行多维 LSTM，应用于快速生物医学体积图像分割。发表于：Neural Information Processing Systems 进展.
    pp. 2998–3006。
- en: Suk et al. (2014) Suk, H.-I., Lee, S.-W., Shen, D., 2014\. Hierarchical feature
    representation and multimodal fusion with deep learning for AD/MCI diagnosis.
    NeuroImage 101, 569–582.
  id: totrans-879
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suk 等（2014）Suk, H.-I., Lee, S.-W., Shen, D., 2014\. 层次特征表示和深度学习的多模态融合用于 AD/MCI
    诊断。NeuroImage 101, 569–582。
- en: Suk et al. (2015) Suk, H.-I., Lee, S.-W., Shen, D., 2015\. Latent feature representation
    with stacked auto-encoder for AD/MCI diagnosis. Brain Struct Funct 220, 841–859.
  id: totrans-880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suk 等 (2015) Suk, H.-I., Lee, S.-W., Shen, D., 2015\. 使用堆叠自编码器的潜在特征表示进行 AD/MCI
    诊断。脑结构与功能 220, 841–859。
- en: 'Suk and Shen (2013) Suk, H.-I., Shen, D., 2013\. Deep learning-based feature
    representation for AD/MCI classification. In: Med Image Comput Comput Assist Interv.
    Vol. 8150 of Lect Notes Comput Sci. pp. 583–590.'
  id: totrans-881
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suk 和 Shen (2013) Suk, H.-I., Shen, D., 2013\. 基于深度学习的特征表示用于 AD/MCI 分类。在：医学图像计算与计算机辅助干预。计算机科学讲义第
    8150 卷，第 583–590 页。
- en: 'Suk and Shen (2016) Suk, H.-I., Shen, D., 2016\. Deep ensemble sparse regression
    network for Alzheimer’s disease diagnosis. In: Med Image Comput Comput Assist
    Interv. Vol. 10019 of Lect Notes Comput Sci. pp. 113–121.'
  id: totrans-882
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suk 和 Shen (2016) Suk, H.-I., Shen, D., 2016\. 用于阿尔茨海默病诊断的深度集成稀疏回归网络。在：医学图像计算与计算机辅助干预。计算机科学讲义第
    10019 卷，第 113–121 页。
- en: Suk et al. (2016) Suk, H.-I., Wee, C.-Y., Lee, S.-W., Shen, D., 2016\. State-space
    model with deep learning for functional dynamics estimation in resting-state fMRI.
    NeuroImage 129, 292–307.
  id: totrans-883
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suk 等 (2016) Suk, H.-I., Wee, C.-Y., Lee, S.-W., Shen, D., 2016\. 基于深度学习的状态空间模型用于静息态
    fMRI 的功能动态估计。神经影像 129, 292–307。
- en: Sun et al. (2016a) Sun, W., Tseng, T.-L. B., Zhang, J., Qian, W., 2016a. Enhancing
    deep convolutional neural network scheme for breast cancer diagnosis with unlabeled
    data. Comput Med Imaging Graph.
  id: totrans-884
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等 (2016a) Sun, W., Tseng, T.-L. B., Zhang, J., Qian, W., 2016a. 使用未标记数据增强深度卷积神经网络方案进行乳腺癌诊断。计算机医学成像与图形。
- en: 'Sun et al. (2016b) Sun, W., Zheng, B., Qian, W., 2016b. Computer aided lung
    cancer diagnosis with deep learning algorithms. In: Medical Imaging. Vol. 9785
    of Proceedings of the SPIE. p. 97850Z.'
  id: totrans-885
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等 (2016b) Sun, W., Zheng, B., Qian, W., 2016b. 使用深度学习算法的计算机辅助肺癌诊断。在：医学成像。SPIE
    会议录第 9785 卷，第 97850Z 页。
- en: 'Suzani et al. (2015) Suzani, A., Rasoulian, A., Seitel, A., Fels, S., Rohling,
    R., Abolmaesumi, P., 2015\. Deep learning for automatic localization, identification,
    and segmentation of vertebral bodies in volumetric mr images. In: Medical Imaging.
    Vol. 9415 of Proceedings of the SPIE. p. 941514.'
  id: totrans-886
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suzani 等 (2015) Suzani, A., Rasoulian, A., Seitel, A., Fels, S., Rohling, R.,
    Abolmaesumi, P., 2015\. 深度学习用于自动定位、识别和分割体积 MR 图像中的脊椎体。在：医学成像。SPIE 会议录第 9415 卷，第
    941514 页。
- en: Szegedy et al. (2014) Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.,
    Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A., 2014\. Going deeper with
    convolutions. arXiv:1409.4842.
  id: totrans-887
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等 (2014) Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov,
    D., Erhan, D., Vanhoucke, V., Rabinovich, A., 2014\. 通过卷积深入学习。arXiv:1409.4842。
- en: 'Tachibana et al. (2016) Tachibana, R., Näppi, J. J., Hironaka, T., Kim, S. H.,
    Yoshida, H., 2016. Deep learning for electronic cleansing in dual-energy ct colonography.
    In: Medical Imaging. Vol. 9785 of Proceedings of the SPIE. p. 97851M.'
  id: totrans-888
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tachibana 等 (2016) Tachibana, R., Näppi, J. J., Hironaka, T., Kim, S. H., Yoshida,
    H., 2016. 用于双能 CT 结肠成像的电子清洗深度学习。在：医学成像。SPIE 会议录第 9785 卷，第 97851M 页。
- en: 'Tajbakhsh et al. (2015a) Tajbakhsh, N., Gotway, M. B., Liang, J., 2015a. Computer-aided
    pulmonary embolism detection using a novel vessel-aligned multi-planar image representation
    and convolutional neural networks. In: Med Image Comput Comput Assist Interv.
    Vol. 9350 of Lect Notes Comput Sci. pp. 62–69.'
  id: totrans-889
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tajbakhsh 等 (2015a) Tajbakhsh, N., Gotway, M. B., Liang, J., 2015a. 使用新型血管对齐多平面图像表示和卷积神经网络进行计算机辅助肺栓塞检测。在：医学图像计算与计算机辅助干预。计算机科学讲义第
    9350 卷，第 62–69 页。
- en: 'Tajbakhsh et al. (2015b) Tajbakhsh, N., Gurudu, S. R., Liang, J., 2015b. A
    comprehensive computer-aided polyp detection system for colonoscopy videos. In:
    Inf Process Med Imaging. Vol. 9123 of Lect Notes Comput Sci. pp. 327–338.'
  id: totrans-890
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tajbakhsh 等 (2015b) Tajbakhsh, N., Gurudu, S. R., Liang, J., 2015b. 一种用于结肠镜视频的综合计算机辅助息肉检测系统。在：信息处理医学成像。计算机科学讲义第
    9123 卷，第 327–338 页。
- en: 'Tajbakhsh et al. (2016) Tajbakhsh, N., Shin, J. Y., Gurudu, S. R., Hurst, R. T.,
    Kendall, C. B., Gotway, M. B., Liang, J., 2016\. Convolutional neural networks
    for medical image analysis: Fine tuning or full training? IEEE Trans Med Imaging
    35 (5), 1299–1312.'
  id: totrans-891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tajbakhsh 等 (2016) Tajbakhsh, N., Shin, J. Y., Gurudu, S. R., Hurst, R. T.,
    Kendall, C. B., Gotway, M. B., Liang, J., 2016\. 用于医学图像分析的卷积神经网络：微调还是完全训练？IEEE
    医学成像学报 35 (5), 1299–1312。
- en: 'Tarando et al. (2016) Tarando, S. R., Fetita, C., Faccinetto, A., Yves, P.,
    2016\. Increasing CAD system efficacy for lung texture analysis using a convolutional
    network. In: Medical Imaging. Vol. 9785 of Proceedings of the SPIE. pp. 97850Q–97850Q.'
  id: totrans-892
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tarando 等 (2016) Tarando, S. R., Fetita, C., Faccinetto, A., Yves, P., 2016\.
    使用卷积网络提高 CAD 系统在肺部纹理分析中的效能。在：医学成像。SPIE 会议录第 9785 卷，第 97850Q–97850Q 页。
- en: Teikari et al. (2016) Teikari, P., Santos, M., Poon, C., Hynynen, K., 2016\.
    Deep learning convolutional networks for multiphoton microscopy vasculature segmentation.
    arXiv:1606.02382.
  id: totrans-893
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Teikari 等 (2016) Teikari, P., Santos, M., Poon, C., Hynynen, K., 2016\. 深度学习卷积网络用于多光子显微镜血管分割。arXiv:1606.02382.
- en: 'Teramoto et al. (2016) Teramoto, A., Fujita, H., Yamamuro, O., Tamaki, T.,
    2016\. Automated detection of pulmonary nodules in PET/CT images: Ensemble false-positive
    reduction using a convolutional neural network technique. Med Phys 43, 2821–2827.'
  id: totrans-894
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Teramoto 等 (2016) Teramoto, A., Fujita, H., Yamamuro, O., Tamaki, T., 2016\.
    在PET/CT图像中自动检测肺结节：使用卷积神经网络技术的集成假阳性减少。Med Phys 43, 2821–2827.
- en: 'Thong et al. (2016) Thong, W., Kadoury, S., Piché, N., Pal, C. J., 2016\. Convolutional
    networks for kidney segmentation in contrast-enhanced CT scans. Computer Methods
    in Biomechanics and Biomedical Engineering: Imaging & Visualization, 1–6.'
  id: totrans-895
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thong 等 (2016) Thong, W., Kadoury, S., Piché, N., Pal, C. J., 2016\. 用于对比增强CT扫描中的肾脏分割的卷积网络。计算方法在生物力学和生物医学工程：成像与可视化,
    1–6.
- en: Tran (2016) Tran, P. V., 2016\. A fully convolutional neural network for cardiac
    segmentation in short-axis MRI. arXiv:1604.00494.
  id: totrans-896
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tran (2016) Tran, P. V., 2016\. 用于短轴MRI中的心脏分割的全卷积神经网络。arXiv:1604.00494.
- en: Turkki et al. (2016) Turkki, R., Linder, N., Kovanen, P. E., Pellinen, T., Lundin,
    J., 2016. Antibody-supervised deep learning for quantification of tumor-infiltrating
    immune cells in hematoxylin and eosin stained breast cancer samples. Journal of
    pathology informatics 7, 38.
  id: totrans-897
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Turkki 等 (2016) Turkki, R., Linder, N., Kovanen, P. E., Pellinen, T., Lundin,
    J., 2016. 抗体监督深度学习用于在苏木精-伊红染色的乳腺癌样本中量化肿瘤浸润免疫细胞。病理信息学杂志 7, 38.
- en: 'Twinanda et al. (2017) Twinanda, A. P., Shehata, S., Mutter, D., Marescaux,
    J., de Mathelin, M., Padoy, N., 2017\. Endonet: A deep architecture for recognition
    tasks on laparoscopic videos. IEEE Trans Med Imaging 36, 86–97.'
  id: totrans-898
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Twinanda 等 (2017) Twinanda, A. P., Shehata, S., Mutter, D., Marescaux, J., de
    Mathelin, M., Padoy, N., 2017\. Endonet：一种用于腹腔镜视频识别任务的深度架构。IEEE Trans Med Imaging
    36, 86–97.
- en: van der Burgh et al. (2017) van der Burgh, H. K., Schmidt, R., Westeneng, H.-J.,
    de Reus, M. A., van den Berg, L. H., van den Heuvel, M. P., 2017\. Deep learning
    predictions of survival based on MRI in amyotrophic lateral sclerosis. NeuroImage.
    Clinical 13, 361–369.
  id: totrans-899
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: van der Burgh 等 (2017) van der Burgh, H. K., Schmidt, R., Westeneng, H.-J.,
    de Reus, M. A., van den Berg, L. H., van den Heuvel, M. P., 2017\. 基于MRI的渐冻症存活预测的深度学习。NeuroImage.
    Clinical 13, 361–369.
- en: 'van Ginneken et al. (2015) van Ginneken, B., Setio, A. A., Jacobs, C., Ciompi,
    F., 2015\. Off-the-shelf convolutional neural network features for pulmonary nodule
    detection in computed tomography scans. In: IEEE Int Symp Biomedical Imaging.
    pp. 286–289.'
  id: totrans-900
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'van Ginneken 等 (2015) van Ginneken, B., Setio, A. A., Jacobs, C., Ciompi, F.,
    2015\. 使用现成卷积神经网络特征进行计算机断层扫描中的肺结节检测。In: IEEE Int Symp Biomedical Imaging. pp.
    286–289.'
- en: 'van Grinsven et al. (2016) van Grinsven, M. J. J. P., van Ginneken, B., Hoyng,
    C. B., Theelen, T., Sánchez, C. I., 2016\. Fast convolutional neural network training
    using selective data sampling: Application to hemorrhage detection in color fundus
    images. IEEE Trans Med Imaging 35 (5), 1273–1284.'
  id: totrans-901
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: van Grinsven 等 (2016) van Grinsven, M. J. J. P., van Ginneken, B., Hoyng, C.
    B., Theelen, T., Sánchez, C. I., 2016\. 使用选择性数据采样的快速卷积神经网络训练：应用于彩色视网膜图像中的出血检测。IEEE
    Trans Med Imaging 35 (5), 1273–1284.
- en: van Tulder and de Bruijne (2016) van Tulder, G., de Bruijne, M., 2016\. Combining
    generative and discriminative representation learning for lung CT analysis with
    convolutional Restricted Boltzmann Machines. IEEE Trans Med Imaging 35 (5), 1262–1272.
  id: totrans-902
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: van Tulder 和 de Bruijne (2016) van Tulder, G., de Bruijne, M., 2016\. 结合生成和判别表示学习用于卷积限制玻尔兹曼机的肺部CT分析。IEEE
    Trans Med Imaging 35 (5), 1262–1272.
- en: 'Veta et al. (2016) Veta, M., van Diest, P. J., Pluim, J. P. W., 2016\. Cutting
    out the middleman: measuring nuclear area in histopathology slides without segmentation.
    In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci.
    pp. 632–639.'
  id: totrans-903
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Veta 等 (2016) Veta, M., van Diest, P. J., Pluim, J. P. W., 2016\. 去除中间人：在组织病理学切片中无分割测量核面积。In:
    Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp.
    632–639.'
- en: 'Vincent et al. (2010) Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y.,
    Manzagol, P.-A., 2010. Stacked denoising autoencoders: Learning useful representations
    in a deep network with a local denoising criterion. J Mach Learn Res 11, 3371–3408.'
  id: totrans-904
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vincent 等 (2010) Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol,
    P.-A., 2010. 堆叠去噪自编码器：在深度网络中使用局部去噪标准学习有用表示。J Mach Learn Res 11, 3371–3408.
- en: 'Vivanti et al. (2015) Vivanti, R., Ephrat, A., Joskowicz, L., Karaaslan, O.,
    Lev-Cohain, N., Sosna, J., 2015\. Automatic liver tumor segmentation in follow-up
    ct studies using convolutional neural networks. In: Proc. Patch-Based Methods
    in Medical Image Processing Workshop, MICCAI.–2015\. pp. 54–61.'
  id: totrans-905
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vivanti等（2015）Vivanti, R., Ephrat, A., Joskowicz, L., Karaaslan, O., Lev-Cohain,
    N., Sosna, J., 2015年。使用卷积神经网络在后续CT研究中自动分割肝肿瘤。见：Proc. Patch-Based Methods in Medical
    Image Processing Workshop, MICCAI–2015，第54–61页。
- en: Wang et al. (2016a) Wang, C., Elazab, A., Wu, J., Hu, Q., Nov. 2016a. Lung nodule
    classification using deep feature fusion in chest radiography. Comput Med Imaging
    Graph.
  id: totrans-906
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等（2016a）Wang, C., Elazab, A., Wu, J., Hu, Q., 2016年11月。胸部X光中使用深度特征融合进行肺结节分类。《计算机医学成像与图形学》。
- en: 'Wang et al. (2015) Wang, C., Yan, X., Smith, M., Kochhar, K., Rubin, M., Warren,
    S. M., Wrobel, J., Lee, H., 2015\. A unified framework for automatic wound segmentation
    and analysis with deep convolutional neural networks. In: Conf Proc IEEE Eng Med
    Biol Soc. pp. 2415–2418.'
  id: totrans-907
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等（2015）Wang, C., Yan, X., Smith, M., Kochhar, K., Rubin, M., Warren, S.
    M., Wrobel, J., Lee, H., 2015年。使用深度卷积神经网络的自动伤口分割与分析统一框架。见：Conf Proc IEEE Eng Med
    Biol Soc，第2415–2418页。
- en: Wang et al. (2016b) Wang, D., Khosla, A., Gargeya, R., Irshad, H., Beck, A. H.,
    2016b. Deep learning for identifying metastatic breast cancer. arXiv:1606.05718.
  id: totrans-908
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等（2016b）Wang, D., Khosla, A., Gargeya, R., Irshad, H., Beck, A. H., 2016年。用于识别转移性乳腺癌的深度学习。arXiv:1606.05718。
- en: Wang (2016) Wang, G., 2016\. A perspective on deep imaging. IEEE Access 4, 8914–8924.
  id: totrans-909
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang（2016）Wang, G., 2016年。关于深度成像的展望。《IEEE Access》4卷，第8914–8924页。
- en: Wang et al. (2014) Wang, H., Cruz-Roa, A., Basavanhally, A., Gilmore, H., Shih,
    N., Feldman, M., Tomaszewski, J., Gonzalez, F., Madabhushi, A., 2014\. Mitosis
    detection in breast cancer pathology images by combining handcrafted and convolutional
    neural network features. J Med Imaging 1, 034003.
  id: totrans-910
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等（2014）Wang, H., Cruz-Roa, A., Basavanhally, A., Gilmore, H., Shih, N.,
    Feldman, M., Tomaszewski, J., Gonzalez, F., Madabhushi, A., 2014年。通过结合手工特征和卷积神经网络特征进行乳腺癌病理图像的有丝分裂检测。《医学成像》1卷，第034003页。
- en: Wang et al. (2017) Wang, J., Ding, H., Azamian, F., Zhou, B., Iribarren, C.,
    Molloi, S., Baldi, P., 2017\. Detecting cardiovascular disease from mammograms
    with deep learning. IEEE Trans Med Imaging.
  id: totrans-911
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等（2017）Wang, J., Ding, H., Azamian, F., Zhou, B., Iribarren, C., Molloi,
    S., Baldi, P., 2017年。使用深度学习从乳腺X光片中检测心血管疾病。《IEEE医学成像汇刊》。
- en: 'Wang et al. (2016c) Wang, J., MacKenzie, J. D., Ramachandran, R., Chen, D. Z.,
    2016c. A deep learning approach for semantic segmentation in histology tissue
    images. In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput
    Sci. Springer, pp. 176–184.'
  id: totrans-912
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等（2016c）Wang, J., MacKenzie, J. D., Ramachandran, R., Chen, D. Z., 2016年。用于组织学图像语义分割的深度学习方法。见：Med
    Image Comput Comput Assist Interv。Lecture Notes Comput Sci第9901卷，Springer，第176–184页。
- en: 'Wang et al. (2016d) Wang, S., Yao, J., Xu, Z., Huang, J., 2016d. Subtype cell
    detection with an accelerated deep convolution neural network. In: Med Image Comput
    Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp. 640–648.'
  id: totrans-913
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等（2016d）Wang, S., Yao, J., Xu, Z., Huang, J., 2016年。使用加速深度卷积神经网络进行亚型细胞检测。见：Med
    Image Comput Comput Assist Interv。Lecture Notes Comput Sci第9901卷，第640–648页。
- en: Wang et al. (2016e) Wang, X., Lu, L., Shin, H.-c., Kim, L., Nogues, I., Yao,
    J., Summers, R., 2016e. Unsupervised category discovery via looped deep pseudo-task
    optimization using a large scale radiology image database. arXiv:1603.07965.
  id: totrans-914
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等（2016e）Wang, X., Lu, L., Shin, H.-c., Kim, L., Nogues, I., Yao, J., Summers,
    R., 2016年。通过循环深度伪任务优化与大规模放射学图像数据库进行无监督类别发现。arXiv:1603.07965。
- en: Wolterink et al. (2016) Wolterink, J. M., Leiner, T., de Vos, B. D., van Hamersvelt,
    R. W., Viergever, M. A., Isgum, I., 2016\. Automatic coronary artery calcium scoring
    in cardiac CT angiography using paired convolutional neural networks. Med Image
    Anal 34, 123–136.
  id: totrans-915
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wolterink等（2016）Wolterink, J. M., Leiner, T., de Vos, B. D., van Hamersvelt,
    R. W., Viergever, M. A., Isgum, I., 2016年。使用配对卷积神经网络的心脏CT血管钙评分自动化。《医学图像分析》34卷，第123–136页。
- en: 'Worrall et al. (2016) Worrall, D. E., Wilson, C. M., Brostow, G. J., 2016\.
    Automated retinopathy of prematurity case detection with convolutional neural
    networks. In: DLMIA. Vol. 10008 of Lect Notes Comput Sci. pp. 68–76.'
  id: totrans-916
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Worrall等（2016）Worrall, D. E., Wilson, C. M., Brostow, G. J., 2016年。使用卷积神经网络的早产视网膜病自动检测。见：DLMIA。Lecture
    Notes Comput Sci第10008卷，第68–76页。
- en: 'Wu et al. (2016) Wu, A., Xu, Z., Gao, M., Buty, M., Mollura, D. J., 2016\.
    Deep vessel tracking: A generalized probabilistic approach via deep learning.
    In: IEEE Int Symp Biomedical Imaging. pp. 1363–1367.'
  id: totrans-917
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu等（2016）Wu, A., Xu, Z., Gao, M., Buty, M., Mollura, D. J., 2016年。深度血管跟踪：通过深度学习的广义概率方法。见：IEEE
    Int Symp Biomedical Imaging，第1363–1367页。
- en: 'Wu et al. (2013) Wu, G., Kim, M., Wang, Q., Gao, Y., Liao, S., Shen, D., 2013\.
    Unsupervised deep feature learning for deformable registration of MR brain images.
    In: Med Image Comput Comput Assist Interv. Vol. 8150 of Lect Notes Comput Sci.
    pp. 649–656.'
  id: totrans-918
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2013）Wu, G., Kim, M., Wang, Q., Gao, Y., Liao, S., Shen, D., 2013. 无监督的深度特征学习用于MR脑图像的可变形配准。在：医学图像计算机辅助干预。第8150卷
    计算机科学讲义，pp. 649–656。
- en: 'Xie et al. (2016a) Xie, W., Noble, J. A., Zisserman, A., 2016a. Microscopy
    cell counting and detection with fully convolutional regression networks. Computer
    Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization, 1–10.'
  id: totrans-919
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人（2016a）Xie, W., Noble, J. A., Zisserman, A., 2016a. 利用完全卷积回归网络进行显微镜细胞计数和检测。生物力学和生物医学工程方法：成像与可视化，1–10。
- en: 'Xie et al. (2015a) Xie, Y., Kong, X., Xing, F., Liu, F., Su, H., Yang, L.,
    2015a. Deep voting: A robust approach toward nucleus localization in microscopy
    images. In: Med Image Comput Comput Assist Interv. Vol. 9351 of Lect Notes Comput
    Sci. pp. 374–382.'
  id: totrans-920
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人（2015a）Xie, Y., Kong, X., Xing, F., Liu, F., Su, H., Yang, L., 2015a.
    深度投票：显微镜图像中细胞核定位的稳健方法。在：医学图像计算机辅助干预。第9351卷 计算机科学讲义，pp. 374–382。
- en: 'Xie et al. (2015b) Xie, Y., Xing, F., Kong, X., Su, H., Yang, L., 2015b. Beyond
    classification: Structured regression for robust cell detection using convolutional
    neural network. In: Med Image Comput Comput Assist Interv. Vol. 9351 of Lect Notes
    Comput Sci. pp. 358–365.'
  id: totrans-921
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人（2015b）Xie, Y., Xing, F., Kong, X., Su, H., Yang, L., 2015b. 超越分类：利用卷积神经网络进行稳健细胞检测的结构化回归。在：医学图像计算机辅助干预。第9351卷
    计算机科学讲义，pp. 358–365。
- en: 'Xie et al. (2016b) Xie, Y., Zhang, Z., Sapkota, M., Yang, L., 2016b. Spatial
    clockwork recurrent neural network for muscle perimysium segmentation. In: International
    Conference on Medical Image Computing and Computer-Assisted Intervention. Vol.
    9901 of Lect Notes Comput Sci. Springer, pp. 185–193.'
  id: totrans-922
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人（2016b）Xie, Y., Zhang, Z., Sapkota, M., Yang, L., 2016b. 用于肌肉周围结膜分割的空间钟摆递归神经网络。在：医学图像计算机辅助干预。第9901卷
    计算机科学讲义，Springer，pp. 185–193。
- en: Xing et al. (2016) Xing, F., Xie, Y., Yang, L., 2016\. An automatic learning-based
    framework for robust nucleus segmentation. IEEE Trans Med Imaging 35 (2), 550–566.
  id: totrans-923
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xing 等人（2016）Xing, F., Xie, Y., Yang, L., 2016. 一种用于稳健细胞核分割的自动学习框架。IEEE交易医学成像
    35（2），550–566。
- en: Xu et al. (2016a) Xu, J., Luo, X., Wang, G., Gilmore, H., Madabhushi, A., 2016a.
    A deep convolutional neural network for segmenting and classifying epithelial
    and stromal regions in histopathological images. Neurocomputing 191, 214–223.
  id: totrans-924
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人（2016a）Xu, J., Luo, X., Wang, G., Gilmore, H., Madabhushi, A., 2016a. 用于分割和分类组织上皮和基质区域的深度卷积神经网络。神经计算
    191，214–223。
- en: Xu et al. (2016b) Xu, J., Xiang, L., Liu, Q., Gilmore, H., Wu, J., Tang, J.,
    Madabhushi, A., 2016b. Stacked sparse autoencoder (ssae) for nuclei detection
    on breast cancer histopathology images. IEEE Trans Med Imaging 35, 119–130.
  id: totrans-925
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人（2016b）Xu, J., Xiang, L., Liu, Q., Gilmore, H., Wu, J., Tang, J., Madabhushi,
    A., 2016b. 堆叠稀疏自编码器（SSAE）用于乳腺癌组织病理图像中的细胞核检测。IEEE交易医学成像 35, 119–130。
- en: 'Xu et al. (2016c) Xu, T., Zhang, H., Huang, X., Zhang, S., Metaxas, D. N.,
    2016c. Multimodal deep learning for cervical dysplasia diagnosis. In: Med Image
    Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp. 115–123.'
  id: totrans-926
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人（2016c）Xu, T., Zhang, H., Huang, X., Zhang, S., Metaxas, D. N., 2016c.
    宫颈畸形诊断的多模态深度学习。在：医学图像计算机辅助干预。第9901卷 计算机科学讲义，pp. 115–123。
- en: Xu et al. (2016d) Xu, Y., Li, Y., Liu, M., Wang, Y., Lai, M., Chang, E. I.-C.,
    2016d. Gland instance segmentation by deep multichannel side supervision. arXiv:1607.03222.
  id: totrans-927
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人（2016d）Xu, Y., Li, Y., Liu, M., Wang, Y., Lai, M., Chang, E. I.-C., 2016d.
    深度多通道侧面监督用于腺体实例分割。arXiv:1607.03222。
- en: 'Xu et al. (2014) Xu, Y., Mo, T., Feng, Q., Zhong, P., Lai, M., Chang, E. I. C.,
    2014\. Deep learning of feature representation with multiple instance learning
    for medical image analysis. In: IEEE International Conference on Acoustics, Speech
    and Signal Processing (ICASSP). pp. 1626–1630.'
  id: totrans-928
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人（2014）Xu, Y., Mo, T., Feng, Q., Zhong, P., Lai, M., Chang, E. I. C., 2014.
    利用多实例学习进行医学图像分析的特征表示深度学习。在：IEEE国际会议声学、语音和信号处理（ICASSP）。pp. 1626–1630。
- en: 'Xu and Huang (2016) Xu, Z., Huang, J., 2016\. Detecting 10,000 Cells in one
    second. In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput
    Sci. pp. 676–684.'
  id: totrans-929
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 和黄（2016）Xu, Z., Huang, J., 2016. 一秒钟检测10,000个细胞。在：医学图像计算机辅助干预。第9901卷 计算机科学讲义，pp.
    676–684。
- en: Xue et al. (2016) Xue, D.-X., Zhang, R., Feng, H., Wang, Y.-L., 2016\. CNN-SVM
    for microvascular morphological type recognition with data augmentation. J Med
    Biol Eng 36, 755–764.
  id: totrans-930
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xue 等人（2016）Xue, D.-X., Zhang, R., Feng, H., Wang, Y.-L., 2016年。利用数据增强的CNN-SVM微血管形态类型识别。J
    Med Biol Eng 36, 755–764。
- en: 'Yan et al. (2016) Yan, Z., Zhan, Y., Peng, Z., Liao, S., Shinagawa, Y., Zhang,
    S., Metaxas, D. N., Zhou, X. S., 2016\. Multi-instance deep learning: Discover
    discriminative local anatomies for bodypart recognition. IEEE Trans Med Imaging
    35 (5), 1332–1343.'
  id: totrans-931
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yan 等人（2016）Yan, Z., Zhan, Y., Peng, Z., Liao, S., Shinagawa, Y., Zhang, S.,
    Metaxas, D. N., Zhou, X. S., 2016年。多实例深度学习：发现用于身体部位识别的区分性局部解剖结构。IEEE Trans Med
    Imaging 35 (5), 1332–1343。
- en: 'Yang et al. (2015) Yang, D., Zhang, S., Yan, Z., Tan, C., Li, K., Metaxas,
    D., 2015\. Automated anatomical landmark detection on distal femur surface using
    convolutional neural network. In: IEEE Int Symp Biomedical Imaging. pp. 17–21.'
  id: totrans-932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2015）Yang, D., Zhang, S., Yan, Z., Tan, C., Li, K., Metaxas, D., 2015年。利用卷积神经网络对远端股骨表面的自动解剖标志检测。在：IEEE
    Int Symp Biomedical Imaging. 页码17–21。
- en: 'Yang et al. (2016a) Yang, H., Sun, J., Li, H., Wang, L., Xu, Z., 2016a. Deep
    fusion net for multi-atlas segmentation: Application to cardiac mr images. In:
    Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. pp.
    521–528.'
  id: totrans-933
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2016a）Yang, H., Sun, J., Li, H., Wang, L., Xu, Z., 2016年。用于多图谱分割的深度融合网络：应用于心脏MR图像。在：Med
    Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. 页码521–528。
- en: 'Yang et al. (2016b) Yang, L., Zhang, Y., Guldner, I. H., Zhang, S., Chen, D. Z.,
    2016b. 3d segmentation of glial cells using fully convolutional networks and k-terminal
    cut. In: Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput
    Sci. Springer, pp. 658–666.'
  id: totrans-934
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2016b）Yang, L., Zhang, Y., Guldner, I. H., Zhang, S., Chen, D. Z., 2016年。利用全卷积网络和k-terminal
    cut对胶质细胞进行三维分割。在：Med Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes
    Comput Sci. Springer，页码658–666。
- en: Yang et al. (2016c) Yang, W., Chen, Y., Liu, Y., Zhong, L., Qin, G., Lu, Z.,
    Feng, Q., Chen, W., 2016c. Cascade of multi-scale convolutional neural networks
    for bone suppression of chest radiographs in gradient domain. Med Image Anal 35,
    421–433.
  id: totrans-935
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2016c）Yang, W., Chen, Y., Liu, Y., Zhong, L., Qin, G., Lu, Z., Feng,
    Q., Chen, W., 2016年。用于胸部X光片骨骼抑制的多尺度卷积神经网络级联。Med Image Anal 35, 421–433。
- en: 'Yang et al. (2016d) Yang, X., Kwitt, R., Niethammer, M., 2016d. Fast predictive
    image registration. In: DLMIA. Vol. 10008 of Lect Notes Comput Sci. pp. 48–57.'
  id: totrans-936
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2016d）Yang, X., Kwitt, R., Niethammer, M., 2016年。快速预测图像配准。在：DLMIA. Vol.
    10008 of Lect Notes Comput Sci. 页码48–57。
- en: 'Yao et al. (2016) Yao, J., Wang, S., Zhu, X., Huang, J., 2016\. Imaging biomarker
    discovery for lung cancer survival prediction. In: Med Image Comput Comput Assist
    Interv. Vol. 9901 of Lect Notes Comput Sci. pp. 649–657.'
  id: totrans-937
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 等人（2016）Yao, J., Wang, S., Zhu, X., Huang, J., 2016年。肺癌生存预测的影像生物标志物发现。在：Med
    Image Comput Comput Assist Interv. Vol. 9901 of Lect Notes Comput Sci. 页码649–657。
- en: 'Yoo et al. (2016) Yoo, Y., Tang, L. W., Brosch, T., Li, D. K. B., Metz, L.,
    Traboulsee, A., Tam, R., 2016\. Deep learning of brain lesion patterns for predicting
    future disease activity in patients with early symptoms of multiple sclerosis.
    In: DLMIA. Vol. 10008 of Lect Notes Comput Sci. pp. 86–94.'
  id: totrans-938
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yoo 等人（2016）Yoo, Y., Tang, L. W., Brosch, T., Li, D. K. B., Metz, L., Traboulsee,
    A., Tam, R., 2016年。利用深度学习预测多发性硬化早期症状患者的未来疾病活动。In: DLMIA. Vol. 10008 of Lect Notes
    Comput Sci. 页码86–94。'
- en: Ypsilantis et al. (2015) Ypsilantis, P.-P., Siddique, M., Sohn, H.-M., Davies,
    A., Cook, G., Goh, V., Montana, G., 2015\. Predicting response to neoadjuvant
    chemotherapy with pet imaging using convolutional neural networks. PLoS ONE 10 (9),
    1–18.
  id: totrans-939
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ypsilantis 等人（2015）Ypsilantis, P.-P., Siddique, M., Sohn, H.-M., Davies, A.,
    Cook, G., Goh, V., Montana, G., 2015年。利用卷积神经网络通过PET成像预测新辅助化疗的反应。PLoS ONE 10 (9),
    1–18。
- en: Yu et al. (2016a) Yu, L., Chen, H., Dou, Q., Qin, J., Heng, P. A., 2016a. Automated
    melanoma recognition in dermoscopy images via very deep residual networks. IEEE
    Trans Med Imaging, in press.
  id: totrans-940
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等人（2016a）Yu, L., Chen, H., Dou, Q., Qin, J., Heng, P. A., 2016年。通过非常深度残差网络在皮肤镜图像中自动识别黑色素瘤。IEEE
    Trans Med Imaging，待发表。
- en: Yu et al. (2016b) Yu, L., Guo, Y., Wang, Y., Yu, J., Chen, P., Nov. 2016b. Segmentation
    of fetal left ventricle in echocardiographic sequences based on dynamic convolutional
    neural networks. IEEE Trans Biomed Eng, in press.
  id: totrans-941
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等人（2016b）Yu, L., Guo, Y., Wang, Y., Yu, J., Chen, P., 2016年11月。基于动态卷积神经网络的胎儿左心室超声序列分割。IEEE
    Trans Biomed Eng，待发表。
- en: 'Yu et al. (2017) Yu, L., Yang, X., Chen, H., Qin, J., Heng, P. A., 2017\. Volumetric
    convnets with mixed residual connections for automated prostate segmentation from
    3D MR images. In: Thirty-First AAAI Conference on Artificial Intelligence.'
  id: totrans-942
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu et al. (2017) Yu, L., Yang, X., Chen, H., Qin, J., Heng, P. A., 2017年。具有混合残差连接的体积卷积网络，用于自动化前列腺分割从3D
    MR图像中。在：第31届AAAI人工智能大会。
- en: 'Zeiler and Fergus (2014) Zeiler, M. D., Fergus, R., 2014\. Visualizing and
    understanding convolutional networks. In: European Conference on Computer Vision.
    pp. 818–833.'
  id: totrans-943
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeiler and Fergus (2014) Zeiler, M. D., Fergus, R., 2014年。可视化和理解卷积网络。在：欧洲计算机视觉会议。pp.
    818–833。
- en: Zhang et al. (2016a) Zhang, H., Li, L., Qiao, K., Wang, L., Yan, B., Li, L.,
    Hu, G., 2016a. Image prediction for limited-angle tomography via deep learning
    with convolutional neural network. arXiv:1607.08707.
  id: totrans-944
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2016a) Zhang, H., Li, L., Qiao, K., Wang, L., Yan, B., Li, L.,
    Hu, G., 2016年。通过卷积神经网络进行有限角度层析成像的图像预测。arXiv:1607.08707。
- en: 'Zhang et al. (2016b) Zhang, L., Gooya, A., Dong, B. H. R., Petersen, S. E.,
    Medrano-Gracia, K. P., Frangi, A. F., 2016b. Automated quality assessment of cardiac
    MR images using convolutional neural networks. In: SASHIMI. Vol. 9968 of Lect
    Notes Comput Sci. pp. 138–145.'
  id: totrans-945
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2016b) Zhang, L., Gooya, A., Dong, B. H. R., Petersen, S. E.,
    Medrano-Gracia, K. P., Frangi, A. F., 2016年。使用卷积神经网络自动评估心脏磁共振图像质量。在：SASHIMI。《计算机科学讲义》第9968卷。pp.
    138–145。
- en: Zhang et al. (2016c) Zhang, Q., Xiao, Y., Dai, W., Suo, J., Wang, C., Shi, J.,
    Zheng, H., 2016c. Deep learning based classification of breast tumors with shear-wave
    elastography. Ultrasonics 72, 150–157.
  id: totrans-946
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2016c) Zhang, Q., Xiao, Y., Dai, W., Suo, J., Wang, C., Shi, J.,
    Zheng, H., 2016年。基于深度学习的剪切波弹性成像乳腺肿瘤分类。《超声波》72, 150–157。
- en: Zhang et al. (2017) Zhang, R., Zheng, Y., Mak, T. W. C., Yu, R., Wong, S. H.,
    Lau, J. Y. W., Poon, C. C. Y., Jan. 2017\. Automatic detection and classification
    of colorectal polyps by transferring low-level CNN features from nonmedical domain.
    IEEE J Biomed Health Inform 21, 41–47.
  id: totrans-947
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2017) Zhang, R., Zheng, Y., Mak, T. W. C., Yu, R., Wong, S. H.,
    Lau, J. Y. W., Poon, C. C. Y., 2017年1月。通过从非医学领域传输低级别CNN特征的方法进行结肠息肉的自动检测和分类。《IEEE生物医学与健康信息学》21,
    41–47。
- en: Zhang et al. (2015) Zhang, W., Li, R., Deng, H., Wang, L., Lin, W., Ji, S.,
    Shen, D., 2015\. Deep convolutional neural networks for multi-modality isointense
    infant brain image segmentation. NeuroImage 108, 214–224.
  id: totrans-948
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2015) Zhang, W., Li, R., Deng, H., Wang, L., Lin, W., Ji, S.,
    Shen, D., 2015年。多模态等强信号婴儿脑图像分割的深度卷积神经网络。《神经影像》108, 214–224。
- en: Zhao et al. (2016) Zhao, J., Zhang, M., Zhou, Z., Chu, J., Cao, F., Nov. 2016\.
    Automatic detection and classification of leukocytes using convolutional neural
    networks. Medical & Biological Engineering & Computing.
  id: totrans-949
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao et al. (2016) Zhao, J., Zhang, M., Zhou, Z., Chu, J., Cao, F., 2016年11月。使用卷积神经网络自动检测和分类白细胞。《医学与生物工程与计算》。
- en: Zhao and Jia (2016) Zhao, L., Jia, K., 2016\. Multiscale CNNs for brain tumor
    segmentation and diagnosis. Computational and Mathematical Methods in Medicine
    2016, 8356294.
  id: totrans-950
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao and Jia (2016) Zhao, L., Jia, K., 2016年。多尺度卷积神经网络用于脑肿瘤分割和诊断。《计算和数学方法在医学》2016,
    8356294。
- en: 'Zheng et al. (2015) Zheng, Y., Liu, D., Georgescu, B., Nguyen, H., Comaniciu,
    D., 2015\. 3D deep learning for efficient and robust landmark detection in volumetric
    data. In: Med Image Comput Comput Assist Interv. Vol. 9349 of Lect Notes Comput
    Sci. pp. 565–572.'
  id: totrans-951
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2015) Zheng, Y., Liu, D., Georgescu, B., Nguyen, H., Comaniciu,
    D., 2015年。用于体积数据中高效和稳健的地标检测的三维深度学习。在：医学图像计算辅助干预。《计算机科学讲义》第9349卷。pp. 565–572。
- en: 'Zhou et al. (2016) Zhou, X., Ito, T., Takayama, R., Wang, S., Hara, T., Fujita,
    H., 2016. Three-dimensional CT image segmentation by combining 2D fully convolutional
    network with 3D majority voting. In: DLMIA. Vol. 10008 of Lect Notes Comput Sci.
    pp. 111–120.'
  id: totrans-952
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou et al. (2016) Zhou, X., Ito, T., Takayama, R., Wang, S., Hara, T., Fujita,
    H., 2016年。通过将2D全卷积网络与3D多数投票结合进行的三维CT图像分割。在：DLMIA。《计算机科学讲义》第10008卷。pp. 111–120。
- en: Zhu et al. (2017) Zhu, Y., Wang, L., Liu, M., Qian, C., Yousuf, A., Oto, A.,
    Shen, D., Jan. 2017. MRI based prostate cancer detection with high-level representation
    and hierarchical classification. Med Phys, in press.
  id: totrans-953
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu et al. (2017) Zhu, Y., Wang, L., Liu, M., Qian, C., Yousuf, A., Oto, A.,
    Shen, D., 2017年1月。基于MRI的前列腺癌检测与高级表征和分层分类。《医学物理学》，待出版。
- en: Zilly et al. (2017) Zilly, J., Buhmann, J. M., Mahapatra, D., 2017\. Glaucoma
    detection using entropy sampling and ensemble learning for automatic optic cup
    and disc segmentation. Comput Med Imaging Graph 55, 28–41.
  id: totrans-954
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zilly et al. (2017) Zilly, J., Buhmann, J. M., Mahapatra, D., 2017年。使用熵采样和集成学习进行青光眼检测，用于自动视盘和视盘分割。《计算医学影像与图形学》55,
    28–41。
- en: 'Zreik et al. (2016) Zreik, M., Leiner, T., de Vos, B., van Hamersvelt, R.,
    Viergever, M., Isgum, I., 2016\. Automatic segmentation of the left ventricle
    in cardiac CT angiography using convolutional neural networks. In: IEEE Int Symp
    Biomedical Imaging. pp. 40–43.'
  id: totrans-955
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zreik 等（2016）Zreik, M., Leiner, T., de Vos, B., van Hamersvelt, R., Viergever,
    M., Isgum, I., 2016\. 使用卷积神经网络在心脏 CT 血管造影中自动分割左心室。载于：IEEE 国际生物医学影像学会议。第 40–43
    页。
