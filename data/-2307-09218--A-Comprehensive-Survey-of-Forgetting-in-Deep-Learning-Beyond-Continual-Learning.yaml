- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-06 19:37:54'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 19:37:54'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2307.09218] A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual
    Learning'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2307.09218] 深度学习中遗忘的全面调查：超越持续学习'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2307.09218](https://ar5iv.labs.arxiv.org/html/2307.09218)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2307.09218](https://ar5iv.labs.arxiv.org/html/2307.09218)
- en: A Comprehensive Survey of Forgetting in
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习中的全面调查
- en: Deep Learning Beyond Continual Learning
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习超越持续学习
- en: Zhenyi Wang, Enneng Yang, Li Shen, Heng Huang Zhenyi Wang and Heng Huang are
    with the Department of Computer Science, University of Maryland, College Park,
    MD 20742, USA.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 王振毅、恩能·杨、李申、黄恒。王振毅和黄恒在美国马里兰大学计算机科学系工作，邮政地址：MD 20742，大学公园，马里兰州，美国。
- en: 'E-mail: wangzhenyineu@gmail.com; heng@umd.edu Enneng Yang is with Northeastern
    University, China. E-mail: ennengyang@stumail.neu.edu.cn Li Shen is with JD Explore
    Academy, China. E-mail: mathshenli@gmail.com. Manuscript received July 15, 2023;
    revised July 15, 2023.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 电子邮件：wangzhenyineu@gmail.com; heng@umd.edu。恩能·杨在中国东北大学工作。电子邮件：ennengyang@stumail.neu.edu.cn。李申在中国京东探索学院工作。电子邮件：mathshenli@gmail.com。稿件接收于2023年7月15日；修订于2023年7月15日。
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Forgetting refers to the loss or deterioration of previously acquired information
    or knowledge. While the existing surveys on forgetting have primarily focused
    on continual learning, forgetting is a prevalent phenomenon observed in various
    other research domains within deep learning. Forgetting manifests in research
    fields such as generative models due to generator shifts, and federated learning
    due to heterogeneous data distributions across clients. Addressing forgetting
    encompasses several challenges, including balancing the retention of old task
    knowledge with fast learning of new tasks, managing task interference with conflicting
    goals, and preventing privacy leakage, etc. Moreover, most existing surveys on
    continual learning implicitly assume that forgetting is always harmful. In contrast,
    our survey argues that forgetting is a double-edged sword and can be beneficial
    and desirable in certain cases, such as privacy-preserving scenarios. By exploring
    forgetting in a broader context, we aim to present a more nuanced understanding
    of this phenomenon and highlight its potential advantages. Through this comprehensive
    survey, we aspire to uncover potential solutions by drawing upon ideas and approaches
    from various fields that have dealt with forgetting. By examining forgetting beyond
    its conventional boundaries, in future work, we hope to encourage the development
    of novel strategies for mitigating, harnessing, or even embracing forgetting in
    real applications. A comprehensive list of papers about forgetting in various
    research fields is available at [https://github.com/EnnengYang/Awesome-Forgetting-in-Deep-Learning](https://github.com/EnnengYang/Awesome-Forgetting-in-Deep-Learning).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 遗忘指的是以前获得的信息或知识的丧失或退化。虽然现有的遗忘调查主要集中在持续学习上，但遗忘在深度学习的其他研究领域中也是一种普遍现象。遗忘在生成模型（由于生成器变化）和联邦学习（由于客户端之间的异质数据分布）等研究领域表现出来。应对遗忘面临多个挑战，包括平衡旧任务知识的保留与新任务的快速学习、管理具有冲突目标的任务干扰以及防止隐私泄露等。此外，大多数现有的持续学习调查隐含地认为遗忘总是有害的。相反，我们的调查认为遗忘是把双刃剑，在某些情况下（如隐私保护场景）可以是有益和可取的。通过在更广泛的背景下探索遗忘，我们旨在呈现对这一现象更为细致的理解，并突出其潜在优势。通过这项全面调查，我们希望借鉴各个领域对遗忘的处理，揭示潜在解决方案。通过超越传统界限检查遗忘，我们期望在未来的工作中鼓励开发新策略，以减轻、利用或甚至拥抱现实应用中的遗忘。关于各种研究领域遗忘的文献全面列表可在
    [https://github.com/EnnengYang/Awesome-Forgetting-in-Deep-Learning](https://github.com/EnnengYang/Awesome-Forgetting-in-Deep-Learning)
    查阅。
- en: 'Index Terms:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Beneficial Forgetting, Harmful Forgetting, Memorization, Distribution Shift,
    Cross-Disciplinary Research
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 有益遗忘、害处遗忘、记忆化、分布变化、跨学科研究
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Forgetting [[1](#bib.bib1)] refers to the phenomenon where previously acquired
    information or knowledge in a machine learning system degrades over time. In the
    early days of neural networks, the focus was primarily on training models on static
    datasets. Forgetting was not a significant concern in these settings since the
    models were trained and evaluated on fixed datasets. The concept of catastrophic
    forgetting was first formally introduced by McCloskey and Cohen [[1](#bib.bib1)].
    They demonstrated that neural networks when trained sequentially on different
    tasks, tend to forget previously learned tasks when new tasks are learned. This
    observation highlighted the need for addressing forgetting in sequential learning
    scenarios. Later, addressing the issue of forgetting was formalized as continual
    learning (CL). Nowadays, forgetting has garnered significant attention not only
    within the CL domain but also in the broader machine learning community, which
    has evolved into a fundamental problem in the field of machine learning as a whole.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 遗忘[[1](#bib.bib1)] 指的是在机器学习系统中，先前获得的信息或知识随时间退化的现象。在神经网络的早期，重点主要是对静态数据集进行模型训练。在这些设置中，遗忘并不是一个显著的问题，因为模型是在固定数据集上进行训练和评估的。灾难性遗忘的概念首先由McCloskey和Cohen正式引入[[1](#bib.bib1)]。他们展示了当神经网络在不同任务上进行顺序训练时，新任务的学习会使其忘记先前学习的任务。这一观察突显了在顺序学习场景中解决遗忘问题的必要性。后来，解决遗忘问题被正式化为持续学习（CL）。如今，遗忘不仅在CL领域引起了广泛关注，也在更广泛的机器学习社区中，成为了整个机器学习领域的一个根本性问题。
- en: Existing surveys on forgetting have primarily focused on CL [[2](#bib.bib2),
    [3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7),
    [8](#bib.bib8), [9](#bib.bib9)]. However, these surveys tend to concentrate solely
    on the harmful effects of forgetting and lack a comprehensive discussion on the
    topic. In contrast, our survey aims to provide a more holistic understanding of
    forgetting. We highlight its dual nature as a double-edged sword, emphasizing
    both its benefits and harms. Additionally, our survey extends beyond the scope
    of CL and covers the forgetting issue in various other domains, including foundation
    models, domain adaptation, meta-learning, test-time adaptation, generative models,
    reinforcement learning and federated learning. By doing so, we offer a comprehensive
    examination of forgetting that encompasses a broader range of contexts and applications.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现有关于遗忘的调查主要集中于CL[[2](#bib.bib2), [3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5),
    [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8), [9](#bib.bib9)]。然而，这些调查往往仅关注遗忘的有害影响，缺乏对该主题的全面讨论。相比之下，我们的调查旨在提供对遗忘的更全面理解。我们突出了其作为双刃剑的双重性质，强调其益处和危害。此外，我们的调查超越了CL的范围，涵盖了在其他各种领域中的遗忘问题，包括基础模型、领域适应、元学习、测试时适应、生成模型、强化学习和联邦学习。通过这样做，我们提供了一个涵盖更广泛背景和应用的遗忘问题的全面审视。
- en: 'TABLE I: Harmful Forgetting: Comparisons among different problem settings.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '表 I: 有害遗忘：不同问题设置的比较。'
- en: Problem Setting Goal Source of Forgetting Continual Learning learn non-stationary
    data distribution without forgetting previous knowledge data-distribution shift
    during training Foundation Model unsupervised learning on large-scale unlabeled
    data data-distribution shift in pre-training, fine-tuning Domain Adaptation adapt
    to target domain while maintaining performance on source domain target domain
    sequentially shift over time Test-time Adaptation mitigate the distribution gap
    between training and testing adaptation to the test data distribution during testing
    Meta Learning learn adaptable knowledge to new tasks incrementally meta-learn
    new classes / task-distribution shift Generative Model learn a generator to approximate
    real data distribution generator shift / data-distribution shift Reinforcement
    Learning maximize accumulate rewards state, action, reward and state transition
    dynamics shift Federated Learning decentralized training without sharing data
    model average; non-i.i.d data; data-distribution shift
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 问题设定 目标 忘记源 连续学习 在不遗忘以前知识的情况下学习非静态数据分布 训练过程中的数据分布变化 基础模型 在大规模无标签数据上进行无监督学习 预训练和微调中的数据分布变化
    领域适应 在保持源领域性能的同时适应目标领域 目标领域随时间逐渐变化 测试时间适应 缓解训练与测试之间的分布差异 在测试期间适应测试数据分布 元学习 学习可适应新任务的知识
    逐步元学习新类别 / 任务分布变化 生成模型 学习生成器以逼近真实数据分布 生成器变化 / 数据分布变化 强化学习 最大化累积奖励 状态、动作、奖励和状态转移动态变化
    联邦学习 去中心化训练，无需共享数据 模型平均；非独立同分布数据；数据分布变化
- en: 'TABLE II: Beneficial Forgetting: Comparisons among different problem settings.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：有益的遗忘：不同问题设置的比较。
- en: Problem Setting Goal Mitigate Overfitting mitigate memorization of training
    data through selective forgetting Debias and Forget Irrelevant Information forget
    biased information to achieve better performance or remove irrelevant information
    to learn new tasks Machine Unlearning forget some specified training data to protect
    user privacy
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 问题设定 目标 缓解过拟合 通过选择性遗忘来减少对训练数据的记忆 去偏见和遗忘无关信息 遗忘有偏见的信息以获得更好的性能或移除无关信息以学习新任务 机器遗忘
    遗忘某些特定的训练数据以保护用户隐私
- en: 'In this survey, we classify forgetting in machine learning into two categories:
    harmful forgetting and beneficial forgetting, based on the specific application
    scenarios. Harmful forgetting occurs when we desire the machine learning model
    to retain previously learned knowledge while adapting to new tasks, domains, or
    environments. In such scenarios, it is crucial to prevent and mitigate knowledge
    forgetting. Conversely, there are many cases where beneficial forgetting becomes
    necessary. For example: (1) Overfitting to the training data hinders generalization.
    (2) Irrelevant and noisy information impedes the model’s ability to effectively
    learn new tasks and knowledge. (3) Pre-trained model contains private information
    that could potentially lead to privacy leakage. In these situations, forgetting
    becomes desirable as it serves several important purposes. Firstly, forgetting
    can mitigate overfitting, as it allows the model to forget irrelevant details
    and focus on the most pertinent patterns in the training data. Additionally, by
    discarding unnecessary information, forgetting facilitates the learning of new
    knowledge, as the model can make better use of its capacity to acquire and adapt
    to novel information. Lastly, forgetting helps protect privacy by discarding sensitive
    user information, ensuring that such data is not retained in the model’s memory.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项调查中，我们将机器学习中的遗忘分为两个类别：有害的遗忘和有益的遗忘，基于具体的应用场景。有害的遗忘发生在我们希望机器学习模型在适应新任务、领域或环境的同时保留以前学到的知识时。在这种情况下，防止和减轻知识遗忘是至关重要的。相反，有许多情况下有益的遗忘变得必要。例如：（1）过拟合训练数据会阻碍泛化。（2）无关和噪声信息妨碍模型有效学习新任务和知识。（3）预训练模型包含的私人信息可能导致隐私泄露。在这些情况下，遗忘变得有利，因为它服务于几个重要的目的。首先，遗忘可以缓解过拟合，因为它允许模型忘记无关的细节，专注于训练数据中最相关的模式。此外，通过丢弃不必要的信息，遗忘有助于学习新知识，因为模型可以更好地利用其能力来获取和适应新信息。最后，遗忘有助于保护隐私，通过丢弃敏感的用户信息，确保这些数据不会保留在模型的记忆中。
- en: 1.1 Harmful Forgetting
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 有害的遗忘
- en: Harmful forgetting has been observed not only in CL but also in various other
    research areas, including foundation model, domain adaptation, meta-learning,
    test-time adaptation, generative model, reinforcement learning and federated learning.
    While existing surveys have predominantly focused on forgetting in the context
    of CL, they often overlook a comprehensive examination of these other related
    research areas. This survey aims to fill this gap by offering an overview of forgetting
    in different learning scenarios, encompassing the aforementioned research areas.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有害遗忘不仅在CL中被观察到，还在其他各种研究领域中出现，包括基础模型、领域适应、元学习、测试时适应、生成模型、强化学习和联邦学习。虽然现有的调查主要集中在CL背景下的遗忘，但它们常常忽视了对这些其他相关研究领域的全面检查。本次调查旨在填补这一空白，通过概述不同学习场景中的遗忘，包括上述研究领域。
- en: 'Forgetting in these research fields can be attributed to various factors. In
    the context of continual learning, forgetting occurs due to the shift in data
    distribution across different tasks. In meta-learning, forgetting is a consequence
    of the shift in task distribution. In federated learning, forgetting is caused
    by the heterogeneity of data distribution among different clients, commonly known
    as client drift. In domain adaptation, forgetting happens because of domain shift.
    In test-time adaptation, forgetting is a result of adapting to the test data distribution
    during testing. In generative models, forgetting occurs due to the shift in the
    generator over time or when learning non-stationary data distribution. In reinforcement
    learning, forgetting can occur as a result of shifts in state, action, reward,
    and state transition dynamics over time. These changes in the underlying factors
    of the environment can lead to the loss or alteration of previously learned knowledge
    in the reinforcement learning process. In the case of foundation models, forgetting
    can be attributed to three different reasons: fine-tuning forgetting, incremental
    streaming data pre-training, and the utilization of foundation models for downstream
    CL tasks.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些研究领域，遗忘可以归因于各种因素。在持续学习的背景下，遗忘发生是由于不同任务间数据分布的变化。在元学习中，遗忘是任务分布变化的结果。在联邦学习中，遗忘是由不同客户端之间数据分布的异质性引起的，通常称为客户端漂移。在领域适应中，遗忘发生是因为领域转移。在测试时适应中，遗忘是由于在测试期间适应测试数据分布的结果。在生成模型中，遗忘发生是由于生成器随时间的变化或学习非平稳数据分布。在强化学习中，遗忘可能由于状态、行动、奖励和状态转移动态随时间变化的结果。这些环境中潜在因素的变化可能导致在强化学习过程中已学知识的丧失或改变。在基础模型的情况下，遗忘可以归因于三种不同的原因：微调遗忘、增量流数据预训练以及利用基础模型进行下游CL任务。
- en: To facilitate clarity and comparison of various settings related to forgetting,
    we present a comprehensive analysis of harmful forgetting in Table [I](#S1.T1
    "TABLE I ‣ 1 Introduction ‣ A Comprehensive Survey of Forgetting in Deep Learning
    Beyond Continual Learning"), highlighting the distinctions among different settings.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于清晰和比较与遗忘相关的各种设置，我们在表格[I](#S1.T1 "TABLE I ‣ 1 Introduction ‣ A Comprehensive
    Survey of Forgetting in Deep Learning Beyond Continual Learning")中呈现了有害遗忘的综合分析，突出了不同设置之间的区别。
- en: 1.2 Beneficial Forgetting
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2 有益的遗忘
- en: 'While the prevailing belief in most existing works is that forgetting is harmful,
    we have come to recognize that forgetting is a double-edged sword. There are many
    instances where it is advantageous to forget certain knowledge within learned
    neural networks. Intentional forgetting proves beneficial in several scenarios:
    (1) selective forgetting could help mitigate overfitting; (2) to enhance model
    generalization or facilitate learning of new tasks/knowledge, it is imperative
    to eliminate biased or irrelevant information from previously learned knowledge;
    and (3) machine unlearning, which prevents data privacy leakage.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大多数现有工作的主流观点认为遗忘是有害的，但我们已经认识到遗忘是一把双刃剑。在某些情况下，遗忘已学习神经网络中的特定知识是有利的。故意遗忘在几种场景中证明是有益的：（1）选择性遗忘可以帮助减轻过拟合；（2）为了增强模型的泛化能力或促进新任务/知识的学习，必须消除先前学习知识中的偏见或无关信息；（3）机器遗忘，防止数据隐私泄露。
- en: First, overfitting has remained a fundamental challenge in machine learning,
    as it arises when a model excessively memorizes the training data but struggles
    to generalize effectively to new, unseen test data. To improve generalization,
    it is crucial for the model to avoid the mere memorization of training data and
    instead should prioritize learning the true underlying relationship between the
    input data and corresponding labels. One important technique to enhance generalization
    is selective forgetting, which plays a significant role in removing irrelevant
    or noisy information learned from the training data. By selectively discarding
    such irrelevant details, the model can focus on the most pertinent patterns and
    features, leading to improved generalization performance on unseen data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，过拟合仍然是机器学习中的一个基本挑战，因为它发生在模型过度记忆训练数据但难以有效地对新、未见过的测试数据进行泛化时。为了提高泛化能力，模型必须避免仅仅记忆训练数据，而应该优先学习输入数据与对应标签之间的真实潜在关系。增强泛化能力的一项重要技术是选择性遗忘，它在移除从训练数据中学到的无关或噪声信息方面发挥了重要作用。通过有选择地丢弃这些无关细节，模型可以专注于最相关的模式和特征，从而提高在未见过的数据上的泛化性能。
- en: Second, when the goal is to learn new tasks or knowledge, the previously acquired
    knowledge may not always be relevant or beneficial for improving future learning
    on new information. When the model holds on to outdated or unrelated knowledge,
    it can hinder its ability to effectively learn and generalize from new data. In
    such situations, it becomes necessary to discard irrelevant information that is
    still retained in the model’s memory. By freeing up capacity within the model,
    it becomes more receptive and adaptive to acquiring new knowledge. The process
    of discarding irrelevant information is crucial for preventing interference between
    old and new knowledge.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，当目标是学习新任务或知识时，先前获得的知识可能并不总是对提高对新信息的未来学习有用或有益。当模型保留过时或不相关的知识时，它可能会阻碍其有效学习和从新数据中泛化的能力。在这种情况下，必须丢弃模型记忆中仍保留的无关信息。通过释放模型内的容量，模型将更易于接收和适应新知识。丢弃无关信息的过程对于防止旧知识与新知识之间的干扰至关重要。
- en: Lastly, machine learning model users may request the removal of not only their
    training data from the database but also any traces within the pre-trained model
    itself, exercising their Right to Be Forgotten [[10](#bib.bib10)]. To address
    this concern, researchers have explored the concept of machine unlearning, which
    allows for the intentional forgetting of undesirable private training data. Furthermore,
    certain privacy attacks exploit the memorization effect of machine learning models
    to extract private information from pre-trained models. Membership inference attacks
    [[11](#bib.bib11)], for example, can determine whether a data point belongs to
    the training data associated with a pre-trained model. These privacy attacks can
    be successful in practice due to the memorization effect of neural networks. In
    such cases, intentional forgetting of private knowledge becomes beneficial in
    protecting privacy and preventing information leakage.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，机器学习模型的用户可能会要求从数据库中删除他们的训练数据，以及在预训练模型本身中的任何痕迹，行使他们的“被遗忘权”[[10](#bib.bib10)]。为了解决这个问题，研究人员探讨了机器“遗忘”的概念，这允许有意地忘记不需要的私有训练数据。此外，某些隐私攻击利用机器学习模型的记忆效应从预训练模型中提取私人信息。例如，成员推断攻击[[11](#bib.bib11)]可以确定数据点是否属于与预训练模型相关的训练数据。这些隐私攻击在实践中可能成功，因为神经网络的记忆效应。在这种情况下，有意遗忘私人知识对保护隐私和防止信息泄漏变得尤为重要。
- en: To facilitate comparisons, we also provide a comparative analysis in Table [II](#S1.T2
    "TABLE II ‣ 1 Introduction ‣ A Comprehensive Survey of Forgetting in Deep Learning
    Beyond Continual Learning") for beneficial forgetting, encompassing the above
    mentioned diverse settings for reference.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于比较，我们还在表格[II](#S1.T2 "TABLE II ‣ 1 Introduction ‣ A Comprehensive Survey
    of Forgetting in Deep Learning Beyond Continual Learning")中提供了有关有益遗忘的比较分析，涵盖了上述提到的各种设置供参考。
- en: 1.3 Challenges in Addressing Forgetting
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3 解决遗忘问题的挑战
- en: 'Addressing forgetting faces numerous challenges that vary across different
    research fields. These challenges include:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 解决遗忘问题面临着众多挑战，这些挑战在不同的研究领域中各不相同。这些挑战包括：
- en: 'Data Availability: Data availability is a significant challenge in various
    scenarios and greatly complicates the task of addressing forgetting. On one hand,
    the availability of previous task data may be limited due to storage constraints
    or data privacy concerns when learning new tasks. This challenge is prevalent
    in continual learning, meta-learning, domain adaptation, generative model and
    reinforcement learning, where access to past task data is crucial for mitigating
    forgetting and leveraging prior knowledge. On the other hand, some scenarios prohibit
    the use of raw data. For instance, in federated learning, only the parameters
    of a pre-trained model are transmitted to a central server, without sharing the
    underlying training data.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可用性：数据可用性是各种场景中的一个重大挑战，并极大地复杂化了解决遗忘问题的任务。一方面，由于存储限制或数据隐私问题，学习新任务时，先前任务的数据可能有限。这种挑战在持续学习、元学习、领域适应、生成模型和强化学习中普遍存在，其中获取过去任务数据对于减轻遗忘和利用先前知识至关重要。另一方面，一些场景禁止使用原始数据。例如，在联邦学习中，只有预训练模型的参数会传输到中央服务器，而不会共享底层训练数据。
- en: 'Resource Constraints: Resource-limited environments, such as those with constraints
    on memory and computation, present challenges in effectively addressing forgetting.
    In online continual learning and meta-learning, where data or tasks are typically
    processed only once, these challenges are particularly pronounced. In addition,
    the learning agent has limited access to past data and experiences, which restricts
    the opportunities to reinforce previously learned tasks. This limited exposure
    to past data makes it difficult to retain knowledge and effectively mitigate forgetting.
    Furthermore, online learning often operates in resource-constrained environments
    with limited memory or computation capabilities. These constraints pose additional
    hurdles for addressing forgetting in an online setting.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 资源限制：资源有限的环境，如内存和计算受限的环境，给有效解决遗忘问题带来了挑战。在在线持续学习和元学习中，由于数据或任务通常只处理一次，这些挑战尤为突出。此外，学习智能体对过去数据和经验的访问有限，这限制了强化之前学习任务的机会。对过去数据的有限接触使得保留知识和有效减轻遗忘变得困难。此外，在线学习通常在资源受限的环境中进行，内存或计算能力有限。这些限制为在线环境中的遗忘问题增加了额外的障碍。
- en: 'Adaption to New Environments/Distribution: In various domains such as continual
    learning, foundation model, reinforcement learning, domain adaptation, test-time
    adaptation, meta-learning, and generative model, the target environment or data
    distribution can change over time. It becomes necessary for the learning agent
    to adapt to these new environments or scenarios. This adaptation can occur either
    during the training phase or during the testing phase. However, the forgetting
    challenge arises when the learning agent adapts to new scenarios and environments.
    The agent tends to lose previously acquired knowledge or performance on earlier
    tasks due to the shift in data distribution.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 新环境/分布适应：在各种领域，如持续学习、基础模型、强化学习、领域适应、测试时间适应、元学习和生成模型中，目标环境或数据分布可能会随时间变化。因此，学习智能体需要适应这些新环境或场景。这种适应可以发生在训练阶段或测试阶段。然而，当学习智能体适应新场景和环境时，会出现遗忘挑战。由于数据分布的变化，智能体往往会丧失先前获得的知识或在早期任务上的表现。
- en: 'Task Interference/Inconsistency: Conflicting and incompatible goals among different
    tasks can lead to task interference, posing challenges in preventing forgetting.
    This issue is observed in various contexts, including continual learning and federated
    learning. In continual learning, sequentially observed tasks may have conflicting
    goals, making it difficult for the network to balance its performance across multiple
    tasks. As the network learns new tasks, the interference from these conflicting
    goals can exacerbate the forgetting problem. Similarly, in federated learning,
    models trained on different clients can exhibit inconsistencies [[12](#bib.bib12)]
    due to the heterogeneous data distribution across clients. These inconsistencies
    can lead to task or client interference, further aggravating the forgetting issue.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 任务干扰/不一致性：不同任务之间的目标冲突和不兼容可能导致任务干扰，给防止遗忘带来挑战。这一问题在各种背景中都可以观察到，包括持续学习和联邦学习。在持续学习中，连续观察到的任务可能具有冲突的目标，使得网络在多个任务之间平衡其性能变得困难。随着网络学习新任务，这些冲突目标的干扰可能会加剧遗忘问题。同样，在联邦学习中，由于客户端之间的数据分布异质性[[12](#bib.bib12)]，在不同客户端上训练的模型可能表现出不一致性。这些不一致性可能导致任务或客户端干扰，进一步加重遗忘问题。
- en: 'Privacy-Leakage Prevention: In certain scenarios, retaining old knowledge can
    raise privacy concerns as it may inadvertently expose private information. Consequently,
    it is essential to address these privacy risks and prevent the unintended disclosure
    of sensitive data. In this context, the objective shifts towards forgetting or
    erasing the traces of training data rather than memorizing them, thereby safeguarding
    user privacy. This specific challenge is encountered in the field of machine unlearning
    [[13](#bib.bib13)], which focuses on developing techniques to effectively forget
    or remove the training data traces from machine learning models.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 隐私泄露预防：在某些情况下，保留旧知识可能会引发隐私问题，因为这可能无意中暴露私人信息。因此，必须解决这些隐私风险，并防止敏感数据的意外泄露。在这种情况下，目标转向遗忘或抹去训练数据的痕迹，而不是记住它们，从而保护用户隐私。这一特定挑战出现在机器遗忘领域[[13](#bib.bib13)]，该领域专注于开发有效遗忘或去除机器学习模型中训练数据痕迹的技术。
- en: 1.4 Survey Scope, Contributions and Organization
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4 调查范围、贡献与组织
- en: Survey Scope Our primary objective is to provide a comprehensive overview of
    forgetting in the main research directions within the aforementioned fields. These
    fields have been chosen as representative research directions where forgetting
    plays a significant role. By covering these areas, we aim to shed light on the
    existence and impact of forgetting in these research domains.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 调查范围 我们的主要目标是对上述领域中的主要研究方向中的遗忘现象提供全面概述。这些领域被选择为代表性研究方向，其中遗忘扮演着重要角色。通过覆盖这些领域，我们旨在揭示这些研究领域中遗忘的存在及其影响。
- en: 'Our contributions can be summarized into three fold:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献可以总结为三点：
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We provide a more systematic survey on CL compared to existing surveys. Our
    survey includes a more systematic categorization of CL problem settings and methods,
    offering a more thorough overview of the field.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相比现有的调查，我们提供了更系统的持续学习调查。我们的调查包括对持续学习问题设置和方法的更系统分类，提供了该领域的更全面概述。
- en: •
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In addition to CL, our survey extends its scope to encompass forgetting in other
    research fields such as foundation model, meta-learning, domain adaptation, test
    time adaptation, generative model, federated learning, reinforcement learning
    and machine unlearning. This broader coverage provides a comprehensive understanding
    of forgetting across various research fields.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 除了持续学习，我们的调查还将范围扩展到其他研究领域，如基础模型、元学习、领域适应、测试时适应、生成模型、联邦学习、强化学习和机器遗忘。这一更广泛的覆盖范围提供了对不同研究领域中遗忘现象的全面理解。
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Our survey, in contrast to existing surveys on CL and forgetting, reveals that
    forgetting can be viewed as a double-edged sword. While it is often seen as a
    challenge, we highlight that forgetting also has desirable implications in privacy-preserving
    scenarios.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们的调查与现有的关于持续学习（CL）和遗忘的调查相比，揭示了遗忘可以被视为一把双刃剑。尽管它通常被视为一种挑战，我们强调遗忘在隐私保护场景中也具有积极的影响。
- en: Organization The structure of this paper is as follows. In Sections [2](#S2
    "2 Forgetting in Continual Learning ‣ A Comprehensive Survey of Forgetting in
    Deep Learning Beyond Continual Learning")-[9](#S9 "9 Forgetting in Federated Learning
    ‣ A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"),
    we provide a comprehensive survey on the phenomenon of harmful forgetting in various
    machine learning domains. These include continual learning, foundation model,
    domain adaptation, test-time adaptation, meta-learning, generative model, reinforcement
    learning, and federated learning. Each section explores the occurrence and impact
    of forgetting within these specific fields. In Section [10](#S10 "10 Beneficial
    Forgetting ‣ A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual
    Learning"), we delve into the concept of beneficial forgetting and its role in
    enhancing model generalization performance and facilitating machine unlearning.
    This section highlights the positive aspects of forgetting in specific learning
    scenarios. In Section [11](#S11 "11 Discussion and Future Prospect ‣ A Comprehensive
    Survey of Forgetting in Deep Learning Beyond Continual Learning"), we present
    the current research trends and offer insights into the potential future developments
    in the field.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 组织 本文的结构如下。在章节 [2](#S2 "2 持续学习中的遗忘 ‣ 深度学习中超越持续学习的遗忘综合调查")-[9](#S9 "9 联邦学习中的遗忘
    ‣ 深度学习中超越持续学习的遗忘综合调查")中，我们提供了有关各种机器学习领域中有害遗忘现象的综合调查。这些领域包括持续学习、基础模型、领域适应、测试时适应、元学习、生成模型、强化学习和联邦学习。每一章探讨了这些特定领域内遗忘的发生和影响。在章节
    [10](#S10 "10 有益遗忘 ‣ 深度学习中超越持续学习的遗忘综合调查")中，我们深入探讨了有益遗忘的概念及其在提升模型泛化性能和促进机器遗忘中的作用。本章强调了遗忘在特定学习场景中的积极方面。在章节
    [11](#S11 "11 讨论和未来展望 ‣ 深度学习中超越持续学习的遗忘综合调查")中，我们展示了当前的研究趋势，并提供了对该领域潜在未来发展的见解。
- en: 2 Forgetting in Continual Learning
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 持续学习中的遗忘
- en: 'TABLE III: Content outline in CL. Based on different problem setting categorization
    criteria, the CL setting can be classified into various scenarios, as presented
    in the following table:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 表III：CL中的内容大纲。根据不同的问题设置分类标准，CL设置可以分为各种场景，如下表所示：
- en: Section Problem Setting Categorization Criterion Section [2.1](#S2.SS1 "2.1
    Task-Aware and Task-Free CL ‣ 2 Forgetting in Continual Learning ‣ A Comprehensive
    Survey of Forgetting in Deep Learning Beyond Continual Learning") Task-aware and
    Task-free CL whether explicit task splits/information are available or not during
    training Section [2.2](#S2.SS2 "2.2 Online CL ‣ 2 Forgetting in Continual Learning
    ‣ A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning")
    Online CL the model processes the data in a single pass or multiple passes Section
    [2.3](#S2.SS3 "2.3 Semi-supervised, Few-shot and Unsupervised CL ‣ 2 Forgetting
    in Continual Learning ‣ A Comprehensive Survey of Forgetting in Deep Learning
    Beyond Continual Learning") Semi-supervised, Few-shot and Unsupervised CL the
    amount of labeled data used in CL
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 问题设置分类标准章节 [2.1](#S2.SS1 "2.1 任务感知和任务无关CL ‣ 2 持续学习中的遗忘 ‣ 深度学习中超越持续学习的遗忘综合调查")
    任务感知和任务无关CL 是否在训练过程中提供了明确的任务拆分/信息 章节 [2.2](#S2.SS2 "2.2 在线CL ‣ 2 持续学习中的遗忘 ‣ 深度学习中超越持续学习的遗忘综合调查")
    在线CL 模型以单次或多次传递处理数据 章节 [2.3](#S2.SS3 "2.3 半监督、少样本和无监督CL ‣ 2 持续学习中的遗忘 ‣ 深度学习中超越持续学习的遗忘综合调查")
    半监督、少样本和无监督CL CL中使用的标记数据量
- en: The goal of continual learning (CL) is to learn on a sequence of tasks ${\mathcal{T}}_{1},{\mathcal{T}}_{2},\cdots,{\mathcal{T}}_{N}$
    without forgetting the knowledge on previous tasks. It can be formulated with
    the following optimization objective. Suppose when learning task $t$, the goal
    is to minimize the risk on all the seen tasks so far, i.e.,
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 持续学习（CL）的目标是在一系列任务${\mathcal{T}}_{1},{\mathcal{T}}_{2},\cdots,{\mathcal{T}}_{N}$中进行学习，而不会遗忘之前任务的知识。它可以通过以下优化目标进行表述。假设在学习任务$t$时，目标是最小化到目前为止所有已见任务的风险，即：
- en: '|  | $\small{\mathcal{L}}({\bm{\theta}}_{t})=\sum_{t=1}^{N}{\mathbb{E}}_{({\bm{x}},y)\sim{\mathcal{D}}_{{\mathcal{T}}_{t}}}{\mathcal{L}}_{{\bm{\theta}}_{t}}({\bm{x}},y),$
    |  | (1) |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|  | $\small{\mathcal{L}}({\bm{\theta}}_{t})=\sum_{t=1}^{N}{\mathbb{E}}_{({\bm{x}},y)\sim{\mathcal{D}}_{{\mathcal{T}}_{t}}}{\mathcal{L}}_{{\bm{\theta}}_{t}}({\bm{x}},y),$
    |  | (1) |'
- en: where ${\bm{\theta}}_{t}$ are the parameters when learning task $t$, and ${\mathcal{D}}_{{\mathcal{T}}_{t}}$
    represents the training data associated with task $t$.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ${\bm{\theta}}_{t}$ 是在学习任务 $t$ 时的参数，${\mathcal{D}}_{{\mathcal{T}}_{t}}$ 表示与任务
    $t$ 相关的训练数据。
- en: The CL problem can be categorized in several different ways. Firstly, according
    to whether explicit task splits/information are available or not during training,
    CL can be divided into task-aware and task-free scenarios. Task-aware can be further
    classified into task/domain/class incremental learning. Addressing forgetting
    in task-aware CL is relatively straightforward due to the availability of task
    information. This task information can be leveraged to design and implement various
    strategies to mitigate forgetting. With knowledge of the specific tasks involved,
    CL learner can utilize task-specific cues or labels to guide its learning process
    and manage forgetting. However, addressing forgetting in task-free CL is more
    challenging. In task-free CL, there are no explicit task splits or task-specific
    information available to the learning system. As a result, the learning system
    must autonomously identify and adapt to changes or shifts in the data distribution
    without any task-specific cues or labels. This requires the development of robust
    and adaptive mechanisms that can detect and respond to changes in the data distribution,
    effectively managing forgetting in the absence of explicit task information.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: CL 问题可以以几种不同的方式进行分类。首先，根据在训练过程中是否提供了明确的任务拆分/信息，CL 可以分为任务感知和无任务感知场景。任务感知可以进一步分为任务/领域/类别增量学习。由于有任务信息可用，解决任务感知
    CL 中的遗忘相对简单。可以利用这些任务信息来设计和实施各种策略，以减轻遗忘。了解具体的任务后，CL 学习者可以利用任务特定的提示或标签来指导其学习过程并管理遗忘。然而，解决无任务感知
    CL 中的遗忘则更具挑战性。在无任务感知 CL 中，学习系统没有明确的任务拆分或任务特定信息。因此，学习系统必须自主识别和适应数据分布中的变化或偏移，而没有任何任务特定的提示或标签。这需要开发能够检测和响应数据分布变化的强大而自适应的机制，在没有明确任务信息的情况下有效管理遗忘。
- en: Secondly, depending on whether the model processes the data in a single pass
    or multiple passes, CL can be categorized as online and offline CL. Offline CL
    has been extensively studied due to its availability of abundant computing and
    storage resources. However, online CL presents unique challenges. In online CL,
    the agent has limited access to past data and experiences, which restricts the
    opportunities to revisit and reinforce previously learned tasks. This limited
    exposure to past data makes it challenging to retain knowledge and effectively
    mitigate forgetting. Furthermore, online learning often operates in resource-constrained
    environments with limited memory or processing capabilities. These resource limitations
    pose additional hurdles for addressing forgetting in online CL. Storing and processing
    large amounts of data becomes more difficult due to the restricted resources,
    impeding the development and implementation of effective strategies to mitigate
    forgetting.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，根据模型是以单次还是多次处理数据，CL 可以分为在线 CL 和离线 CL。由于离线 CL 拥有丰富的计算和存储资源，它已经得到了广泛研究。然而，在线
    CL 面临着独特的挑战。在在线 CL 中，代理对过去数据和经验的访问有限，这限制了重新访问和强化之前学习任务的机会。这种对过去数据的有限接触使得知识保留和有效减少遗忘变得具有挑战性。此外，在线学习通常在资源受限的环境中进行，内存或处理能力有限。这些资源限制对解决在线
    CL 中的遗忘问题提出了额外的难题。由于资源受限，存储和处理大量数据变得更加困难，从而阻碍了有效策略的开发和实施，以减轻遗忘。
- en: 'Lastly, according to the amount of labeled data used in CL, they could be categorized
    into supervised, semi-supervised, few-shot, and unsupervised CL. Supervised CL
    is generally considered the easiest case since the availability of labeled data
    provides clear task boundaries and evaluation signals. However, challenges arise
    in other forms of CL. For semi-supervised CL: the challenge lies in selecting
    useful knowledge from unlabeled data to mitigate forgetting. Not all unlabeled
    data may be beneficial for addressing forgetting, making the selection process
    challenging. In few-shot CL: with only a limited number of labeled data points
    available for learning, few-shot CL poses additional challenges. The scarcity
    of labeled data requires the learning agent to effectively utilize the available
    information to minimize forgetting and adapt to new tasks. In the case of unsupervised
    CL: unsupervised CL is the most challenging due to the absence of explicit task
    boundaries. Defining when a new task begins and differentiating it from previous
    tasks becomes difficult. The lack of task boundaries complicates the identification
    and management of forgetting, as the learning agent needs to adapt to new data
    streams without clear task transitions. Furthermore, the absence of labeled data
    in unsupervised CL results in a scarcity of feedback and evaluation signals for
    measuring forgetting. This absence of explicit task labels or ground truth information
    makes it challenging to quantify the extent of forgetting and evaluate the performance
    of unsupervised CL algorithms.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，根据 CL 中使用的标记数据量，它们可以分为监督、半监督、少样本和无监督 CL。监督 CL 通常被认为是最简单的情况，因为标记数据的可用性提供了明确的任务边界和评估信号。然而，其他形式的
    CL 也面临挑战。对于半监督 CL：挑战在于从未标记数据中选择有用的知识以减轻遗忘。并非所有未标记的数据都可能对解决遗忘有帮助，这使得选择过程充满挑战。在少样本
    CL 中：由于只有有限数量的标记数据点可用于学习，少样本 CL 造成了额外的挑战。标记数据的稀缺要求学习代理有效利用现有信息，以最小化遗忘并适应新任务。在无监督
    CL 的情况下：由于缺乏明确的任务边界，无监督 CL 是最具挑战性的。定义何时开始新任务并与先前任务区分开来变得困难。任务边界的缺乏使得遗忘的识别和管理变得复杂，因为学习代理需要适应没有明确任务过渡的新数据流。此外，缺乏标记数据导致无监督
    CL 中缺乏反馈和评估信号来衡量遗忘。缺乏明确的任务标签或真实信息使得量化遗忘的程度和评估无监督 CL 算法的性能变得具有挑战性。
- en: Below, we present the details of each problem setting and its corresponding
    related works. To make content organization clear, we provide a Table [III](#S2.T3
    "TABLE III ‣ 2 Forgetting in Continual Learning ‣ A Comprehensive Survey of Forgetting
    in Deep Learning Beyond Continual Learning") to summarize the problem setting
    categorization in the following sections.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 下面，我们展示每个问题设置的详细信息及其相关工作。为了使内容组织清晰，我们提供了一个表格 [III](#S2.T3 "TABLE III ‣ 2 Forgetting
    in Continual Learning ‣ A Comprehensive Survey of Forgetting in Deep Learning
    Beyond Continual Learning") 来总结以下章节中的问题设置分类。
- en: 2.1 Task-Aware and Task-Free CL
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 任务感知与任务自由的 CL
- en: 2.1.1 Task-aware CL
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.1 任务感知 CL
- en: Task-aware CL focuses on addressing scenarios where explicit task definitions,
    such as task IDs or labels, are available during the CL process. The three most
    common CL scenarios within task-aware settings are task-incremental learning,
    domain-incremental learning, and class-incremental learning [[3](#bib.bib3)].
    In domain-incremental learning, tasks sequentially arrive with the same label
    space but different input data distributions. This means that the tasks share
    a common set of labels or categories, but the distribution of the input data may
    vary across tasks. Task-incremental learning refers to the scenario where tasks
    arrive sequentially, and each task has its own disjoint label space. During testing,
    the presence of explicit task identification is considered, allowing the model
    to identify the specific task at hand. Class-incremental learning is similar to
    task-incremental learning but without explicit task identification during testing.
    Instead, the model needs to incrementally learn new classes without forgetting
    previously learned classes.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 任务感知 CL 侧重于解决在 CL 过程中有明确任务定义（例如任务 ID 或标签）时的场景。在任务感知设置中，最常见的三种 CL 场景是任务递增学习、领域递增学习和类别递增学习
    [[3](#bib.bib3)]。在领域递增学习中，任务按顺序到来，具有相同的标签空间但不同的输入数据分布。这意味着任务共享一组标签或类别，但输入数据的分布可能在任务之间有所不同。任务递增学习指的是任务按顺序到来，每个任务具有自己的不重叠标签空间。在测试期间，考虑到明确的任务识别，使模型能够识别当前任务。类别递增学习类似于任务递增学习，但在测试期间没有明确的任务识别。相反，模型需要逐步学习新类别，而不忘记之前学到的类别。
- en: 'Problem Setup: We consider the standard CL problem of learning a sequence of
    $N$ tasks denoted as ${\mathcal{D}}^{tr}=\{{\mathcal{D}}_{1}^{tr},{\mathcal{D}}_{2}^{tr},\cdots,{\mathcal{D}}_{N}^{tr}\}$.
    The training data of $k$-th task ${\mathcal{D}}_{k}^{tr}$ consists of a set of
    triplets $\{({\bm{x}}_{i}^{k},y_{i}^{k},{\mathcal{T}}_{k})_{i=1}^{n_{k}}\}$, where
    ${\bm{x}}_{i}^{k}$ is the $i$-th task data example, $y_{i}^{k}$ is the data label
    associated with ${\bm{x}}_{i}^{k}$, and ${\mathcal{T}}_{k}$ is the task identifier.
    The goal is to learn a neural network with parameters ${\bm{\theta}}$, i.e., $f_{{\bm{\theta}}}$,
    on the training task sequence ${\mathcal{D}}^{tr}$ so that it performs well on
    the test set of all the learned tasks ${\mathcal{D}}^{te}=\{{\mathcal{D}}_{1}^{te},{\mathcal{D}}_{2}^{te},\cdots,{\mathcal{D}}_{N}^{te}\}$
    without forgetting the knowledge of previous tasks.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 问题设置：我们考虑标准的 CL 问题，即学习一个由 $N$ 个任务组成的序列，记作 ${\mathcal{D}}^{tr}=\{{\mathcal{D}}_{1}^{tr},{\mathcal{D}}_{2}^{tr},\cdots,{\mathcal{D}}_{N}^{tr}\}$。第
    $k$ 个任务 ${\mathcal{D}}_{k}^{tr}$ 的训练数据由一组三元组 $\{({\bm{x}}_{i}^{k},y_{i}^{k},{\mathcal{T}}_{k})_{i=1}^{n_{k}}\}$
    组成，其中 ${\bm{x}}_{i}^{k}$ 是第 $i$ 个任务数据样本，$y_{i}^{k}$ 是与 ${\bm{x}}_{i}^{k}$ 相关的数据标签，而
    ${\mathcal{T}}_{k}$ 是任务标识符。目标是学习一个具有参数 ${\bm{\theta}}$ 的神经网络，即 $f_{{\bm{\theta}}}$，在训练任务序列
    ${\mathcal{D}}^{tr}$ 上，以便它在所有学习任务的测试集 ${\mathcal{D}}^{te}=\{{\mathcal{D}}_{1}^{te},{\mathcal{D}}_{2}^{te},\cdots,{\mathcal{D}}_{N}^{te}\}$
    上表现良好，而不会忘记先前任务的知识。
- en: '![Refer to caption](img/8975b93df69e70404b27cc051cb231be.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8975b93df69e70404b27cc051cb231be.png)'
- en: 'Figure 1: Categorization of existing continual learning approach.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: 现有持续学习方法的分类。'
- en: 'Existing methods on task-aware CL have explored five main branches: memory-based,
    architecture-based, regularization-based, subspace-based, and Bayesian-based methods.
    An overall framework depicting these branches is provided in Figure [1](#S2.F1
    "Figure 1 ‣ 2.1.1 Task-aware CL ‣ 2.1 Task-Aware and Task-Free CL ‣ 2 Forgetting
    in Continual Learning ‣ A Comprehensive Survey of Forgetting in Deep Learning
    Beyond Continual Learning"). For a more comprehensive understanding of the methods
    within each category, please refer to Appendix [A.1](#A1.SS1 "A.1 Task-aware CL
    ‣ Appendix A Continual Learning ‣ A Comprehensive Survey of Forgetting in Deep
    Learning Beyond Continual Learning"), where we provide detailed descriptions.
    Below, we provide a brief overview of each class method.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的任务感知 CL 方法探索了五个主要分支：基于记忆的、基于架构的、基于正则化的、基于子空间的和基于贝叶斯的。图 [1](#S2.F1 "图 1 ‣
    2.1.1 任务感知 CL ‣ 2.1 任务感知和任务自由 CL ‣ 2 持续学习中的遗忘 ‣ 深度学习中遗忘的全面调查") 提供了这些分支的总体框架。有关每个类别方法的更全面了解，请参阅附录
    [A.1](#A1.SS1 "A.1 任务感知 CL ‣ 附录 A 持续学习 ‣ 深度学习中遗忘的全面调查")，其中提供了详细描述。下面，我们简要概述每种方法。
- en: Memory-based Method
  id: totrans-66
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于记忆的方法
- en: 'Memory-based method keeps a *memory buffer* that stores the data examples from
    previous tasks and replays those examples during learning new tasks. It can be
    further categorized into: raw memory replay; memory sample selection; generative
    replay; and compressed memory replay. Next, we discuss each direction in detail.
    (1) Raw Sample Replay: These methods randomly save a small amount of raw data
    from previous tasks and train the model together with the new task data. When
    the new task updates the model, the old task data is used as a constraint [[14](#bib.bib14),
    [15](#bib.bib15)] or directly mixed with the new data to form a batch [[16](#bib.bib16)]
    to update the model, thereby alleviating forgetting. (2) Memory Sample Selection:
    Randomly selecting samples for replay ignores the amount of information in each
    sample, which can lead to suboptimal performance [[17](#bib.bib17), [18](#bib.bib18)].
    Therefore, heuristic selection selects samples to be stored according to certain
    rules. For example, select the representative sample closest to the cluster center [[19](#bib.bib19)],
    the samples with higher diversity [[20](#bib.bib20), [21](#bib.bib21)], or the
    difficult sample closer to the decision boundary [[22](#bib.bib22), [23](#bib.bib23)].
    (3) Generative Replay: When privacy concerns restrict the storage of raw memory
    data, generative replay provides an alternative approach in CL to replay previous
    task data. The main concept behind generative replay is to train a generative
    model capable of capturing and remembering the data distribution from previous
    tasks. The representative works in this line involve using different generative
    models, including GAN-based [[24](#bib.bib24), [25](#bib.bib25)], AutoEncoder-based [[26](#bib.bib26)],
    Diffusion-based [[27](#bib.bib27)], and Model-inversion [[28](#bib.bib28)]. (4)
    Compressed Memory Replay: In scenarios with strict storage constraints on edge
    devices, memory efficiency becomes a critical consideration. Different strategies
    have been proposed to improve memory efficiency in CL learning. For example, storing
    feature representations [[29](#bib.bib29), [30](#bib.bib30)] or low-fidelity images [[31](#bib.bib31),
    [32](#bib.bib32)] instead of original images, or learning a set of condensed images [[33](#bib.bib33),
    [34](#bib.bib34)] using dataset distillation [[35](#bib.bib35)].'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 基于记忆的方法保留一个*记忆缓冲区*，用于存储来自先前任务的数据示例，并在学习新任务时重放这些示例。它可以进一步细分为：原始记忆重放；记忆样本选择；生成重放；和压缩记忆重放。接下来，我们将详细讨论每个方向。
    (1) 原始样本重放：这些方法随机保存少量来自先前任务的原始数据，并将模型与新任务数据一起训练。当新任务更新模型时，旧任务数据作为约束[[14](#bib.bib14),
    [15](#bib.bib15)]或直接与新数据混合形成一个批次[[16](#bib.bib16)]以更新模型，从而减轻遗忘。 (2) 记忆样本选择：随机选择样本进行重放忽略了每个样本的信息量，这可能导致性能不佳[[17](#bib.bib17),
    [18](#bib.bib18)]。因此，启发式选择根据特定规则选择要存储的样本。例如，选择最接近簇中心的代表性样本[[19](#bib.bib19)]，具有更高多样性的样本[[20](#bib.bib20),
    [21](#bib.bib21)]，或接近决策边界的困难样本[[22](#bib.bib22), [23](#bib.bib23)]。 (3) 生成重放：当隐私问题限制原始记忆数据的存储时，生成重放提供了一种在CL中重放先前任务数据的替代方法。生成重放的主要概念是训练一个生成模型，能够捕捉和记住先前任务的数据分布。这方面的代表性工作包括使用不同的生成模型，包括基于GAN的[[24](#bib.bib24),
    [25](#bib.bib25)]、基于自编码器的[[26](#bib.bib26)]、基于扩散的[[27](#bib.bib27)]和模型反演的[[28](#bib.bib28)]。
    (4) 压缩记忆重放：在边缘设备存储限制严格的场景中，记忆效率成为一个关键考虑因素。已经提出了不同的策略来提高CL学习中的记忆效率。例如，存储特征表示[[29](#bib.bib29),
    [30](#bib.bib30)]或低保真度图像[[31](#bib.bib31), [32](#bib.bib32)]，而不是原始图像，或者使用数据集蒸馏[[35](#bib.bib35)]学习一组压缩图像[[33](#bib.bib33),
    [34](#bib.bib34)]。
- en: Architecture-based Method
  id: totrans-68
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于架构的方法
- en: 'Architecture-based methods in CL [[36](#bib.bib36), [37](#bib.bib37), [38](#bib.bib38)]
    involve updating the network architecture during the learning process to retain
    previously acquired knowledge. These methods aim to adapt the model’s architecture
    to acquire new tasks while preserving the knowledge from previous tasks. Based
    on whether the model parameters expand with the number of tasks, architecture-based
    methods can be categorized into two types: fixed-capacity and capacity-increasing
    methods. (1) Fixed-Capacity: In these methods, the amount of CL model’s parameters
    does not increase with the number of tasks, and each task selects a sub-network
    from the CL model to achieve knowledge transfer and reduce the forgetting caused
    by sub-network updates. Common subnetwork selection techniques include masking [[39](#bib.bib39),
    [40](#bib.bib40), [41](#bib.bib41)], and pruning [[42](#bib.bib42), [43](#bib.bib43),
    [44](#bib.bib44)]. (2) Capacity-Increasing: As the number of tasks increases,
    fixed-capacity CL models may face limitations in accommodating new tasks. To overcome
    this challenge, dynamic capacity methods are proposed [[36](#bib.bib36), [38](#bib.bib38),
    [45](#bib.bib45), [46](#bib.bib46)]. These methods ensure that old tasks are not
    forgotten and adapt to new tasks by introducing new task-specific parameters for
    each new task, while freezing parameters related to old tasks.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: CL中的基于架构的方法[[36](#bib.bib36), [37](#bib.bib37), [38](#bib.bib38)]涉及在学习过程中更新网络架构，以保留以前获得的知识。这些方法旨在调整模型的架构，以在保留先前任务的知识的同时获取新任务。根据模型参数是否随任务数量增加，基于架构的方法可以分为两种类型：固定容量和容量增加的方法。(1)
    固定容量：在这些方法中，CL模型的参数量不会随着任务数量的增加而增加，每个任务从CL模型中选择一个子网络以实现知识转移，并减少由于子网络更新而造成的遗忘。常见的子网络选择技术包括掩蔽[[39](#bib.bib39),
    [40](#bib.bib40), [41](#bib.bib41)]和剪枝[[42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44)]。(2)
    容量增加：随着任务数量的增加，固定容量的CL模型可能面临无法容纳新任务的限制。为克服这一挑战，提出了动态容量方法[[36](#bib.bib36), [38](#bib.bib38),
    [45](#bib.bib45), [46](#bib.bib46)]。这些方法通过为每个新任务引入新的任务特定参数，同时冻结与旧任务相关的参数，确保旧任务不会被遗忘，并适应新任务。
- en: Regularization-based Method
  id: totrans-70
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于正则化的方法
- en: 'These methods in CL involve the addition of regularization loss terms to the
    training objective to prevent forgetting previously learned knowledge [[47](#bib.bib47),
    [48](#bib.bib48), [49](#bib.bib49)]. It can be further divided into two subcategories:
    penalizing important parameter updates and knowledge distillation using a previous
    model as a teacher. (1) Penalize Parameter Updates: These methods use the Fisher
    information matrix [[47](#bib.bib47)], the cumulative update amount of parameters [[50](#bib.bib50)],
    etc. as a measure of the importance of old task parameters. On the one hand, when
    new tasks update important parameters, a large penalty is imposed in order to
    keep the knowledge of old tasks from being forgotten. On the other hand, imposing
    a small penalty on unimportant parameter updates can learn new task’s knowledge [[48](#bib.bib48),
    [51](#bib.bib51), [22](#bib.bib22)]. (2) Knowledge-Distillation-Based: Inspired
    by knowledge distillation [[52](#bib.bib52)], several methods in CL incorporate
    a distillation loss between the network of the previous task (referred to as the
    teacher) and the network of the current task (referred to as the student) to mitigate
    forgetting [[53](#bib.bib53), [54](#bib.bib54), [55](#bib.bib55)]. It should be
    mentioned that the ideal scenario would involve using raw data from old tasks
    to extract the knowledge of the teacher model and refine it into a student model.
    However, accessing raw data of old tasks is often not feasible due to data privacy
    concerns. Therefore, existing methods utilize proxy data, such as new task data [[53](#bib.bib53)]
    or large-scale unlabeled data [[56](#bib.bib56)], as a substitute for distillation.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法在**CL**中涉及在训练目标中添加正则化损失项，以防止遗忘之前学到的知识[[47](#bib.bib47), [48](#bib.bib48),
    [49](#bib.bib49)]。这可以进一步分为两个子类别：惩罚重要参数更新和使用先前模型进行知识蒸馏。 (1) 惩罚参数更新：这些方法使用**Fisher信息矩阵**[[47](#bib.bib47)]、参数的累计更新量[[50](#bib.bib50)]等作为旧任务参数重要性的衡量标准。一方面，当新任务更新重要参数时，施加较大的惩罚，以防止旧任务的知识被遗忘。另一方面，对不重要的参数更新施加较小的惩罚，以便学习新任务的知识[[48](#bib.bib48),
    [51](#bib.bib51), [22](#bib.bib22)]。 (2) 基于知识蒸馏：受知识蒸馏的启发[[52](#bib.bib52)]，**CL**中的一些方法在先前任务的网络（称为教师）和当前任务的网络（称为学生）之间引入了蒸馏损失，以减轻遗忘[[53](#bib.bib53),
    [54](#bib.bib54), [55](#bib.bib55)]。值得一提的是，理想的情况是使用旧任务的原始数据提取教师模型的知识，并将其精炼为学生模型。然而，由于数据隐私问题，获取旧任务的原始数据通常不可行。因此，现有方法使用代理数据，如新任务数据[[53](#bib.bib53)]或大规模未标记数据[[56](#bib.bib56)]，作为蒸馏的替代品。
- en: Subspace-based Method
  id: totrans-72
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 子空间方法
- en: 'Subspace-based methods in CL aim to address the issue of interference between
    multiple tasks by conducting learning in separate and disjoint subspaces, thus
    reducing old task forgetting. Subspace-based methods can be categorized into two
    types based on how the subspaces are constructed: orthogonal gradient subspace
    and orthogonal feature subspace methods. (1) Orthogonal Gradient Subspace: These
    methods require that the parameter update direction of the new task is orthogonal
    to the gradient subspace of the old tasks [[57](#bib.bib57), [58](#bib.bib58),
    [59](#bib.bib59)], ensuring minimal interference between tasks. (2) Orthogonal
    Feature Subspace: Similarly, these require that the parameter update direction
    of the new task is orthogonal to the subspace spanned by the input (feature) of
    the old tasks [[60](#bib.bib60), [61](#bib.bib61), [62](#bib.bib62), [63](#bib.bib63)].'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**CL**中的子空间方法旨在通过在独立且不相交的子空间中进行学习来解决多个任务之间的干扰问题，从而减少旧任务的遗忘。子空间方法可以根据子空间的构建方式分为两种类型：正交梯度子空间方法和正交特征子空间方法。
    (1) 正交梯度子空间：这些方法要求新任务的参数更新方向与旧任务的梯度子空间正交[[57](#bib.bib57), [58](#bib.bib58), [59](#bib.bib59)]，以确保任务之间的干扰最小化。
    (2) 正交特征子空间：类似地，这些方法要求新任务的参数更新方向与旧任务输入（特征）所张成的子空间正交[[60](#bib.bib60), [61](#bib.bib61),
    [62](#bib.bib62), [63](#bib.bib63)]。'
- en: Bayesian Method
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 贝叶斯方法
- en: 'These Bayesian approaches offer effective strategies to mitigate forgetting
    by incorporating uncertainty estimation and regularization techniques, thereby
    enhancing the adaptability of the learning process. Bayesian methods can be classified
    into three categories: methods that constrain the update of weight parameter distributions,
    methods that constrain the update in function space, and methods that dynamically
    grow the CL model architecture in an adaptive and Bayesian manner. Specifically,
    (1) Weight Space Regularization: These methods model the parameter update uncertainty
    and enforce the model parameter (weight space) distribution when learning the
    new task is close to that of all the previously learned tasks, including [[64](#bib.bib64),
    [65](#bib.bib65), [66](#bib.bib66), [67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69)].
    (2) Function Space Regularization: Different from weight space regularization
    which constrains the weight update, the function space regularization regulates
    the CL function update in the function space. They achieve this goal by enforcing
    the posterior distribution over the function space [[70](#bib.bib70)], constraining
    neural network predictions [[71](#bib.bib71)], modeling the cross-task covariances
    [[72](#bib.bib72)] or sequential function-space variational inference [[73](#bib.bib73)].
    (3) Bayesian Architecture Expansion: Bayesian architecture growing methods employ
    a probabilistic and Bayesian approach to dynamically expand the CL model. By leveraging
    Bayesian principles, these methods enable the CL model to incrementally grow and
    adapt to new tasks or data while preserving previously learned knowledge. This
    probabilistic framework facilitates the flexible and principled expansion of the
    model’s architecture, allowing it to accommodate increasing complexity and variability
    in the learning process, including [[74](#bib.bib74), [75](#bib.bib75)].'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这些贝叶斯方法通过引入不确定性估计和正则化技术，提供了有效的策略来减轻遗忘，从而增强学习过程的适应性。贝叶斯方法可以分为三类：（1）权重空间正则化：这些方法建模参数更新的不确定性，并在学习新任务时强制模型参数（权重空间）分布接近于所有先前学习任务的分布，包括[[64](#bib.bib64),
    [65](#bib.bib65), [66](#bib.bib66), [67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69)]。
    （2）函数空间正则化：不同于权重空间正则化约束权重更新，函数空间正则化调节 CL 函数在函数空间中的更新。它们通过强制函数空间上的后验分布[[70](#bib.bib70)]、约束神经网络预测[[71](#bib.bib71)]、建模跨任务协方差[[72](#bib.bib72)]
    或顺序函数空间变分推断[[73](#bib.bib73)]来实现这一目标。 （3）贝叶斯架构扩展：贝叶斯架构扩展方法采用概率和贝叶斯方法动态扩展 CL 模型。通过利用贝叶斯原理，这些方法使
    CL 模型能够逐步增长和适应新任务或数据，同时保留先前学习的知识。这种概率框架促进了模型架构的灵活和原则性扩展，使其能够容纳学习过程中的复杂性和变异性，包括[[74](#bib.bib74),
    [75](#bib.bib75)]。
- en: 2.1.2 Task-free CL
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.2 无任务 CL
- en: 'Task-free CL refers to a specific scenario that the learning system does not
    have access to any explicit task information. Unlike the task-aware CL setting,
    where a sequence of tasks is defined, task-free CL aims to perform adaptation
    without explicit task boundaries or labels. The system needs to adapt and generalize
    its knowledge over time, continually updating its model or representation to accommodate
    new information while retaining previously learned knowledge. The absence of explicit
    task information in task-free CL poses significantly more challenges, as the learning
    system must autonomously identify and adapt to changes or shifts in the data distribution
    without any task-specific cues or labels. Existing approaches for task-free CL
    can be categorized into two classes: memory-based methods and network expansion-based
    methods.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 无任务 CL（Task-free CL）指的是在学习系统无法获取任何明确任务信息的特定场景。与任务感知 CL 设置（在这种设置中定义了一系列任务）不同，无任务
    CL 旨在在没有明确任务边界或标签的情况下进行适应。系统需要随时间适应和概括其知识，持续更新其模型或表示，以容纳新信息，同时保留之前学到的知识。在无任务 CL
    中，缺乏明确的任务信息带来了更大的挑战，因为学习系统必须自主识别和适应数据分布中的变化或转变，而没有任何任务特定的提示或标签。现有的无任务 CL 方法可以分为两类：基于记忆的方法和网络扩展的方法。
- en: Memory-based method
  id: totrans-78
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于记忆的方法
- en: Memory-based methods [[20](#bib.bib20), [23](#bib.bib23), [76](#bib.bib76),
    [15](#bib.bib15)] involve storing a small subset of previous data and replaying
    them alongside new mini-batch data. MIR [[23](#bib.bib23)] selects and replays
    samples that are most prone to interference. This selective replay aims to prioritize
    samples that are most relevant for retaining previously learned knowledge. Building
    upon MIR, GEN-MIR [[23](#bib.bib23)] incorporates generative models to synthesize
    memory examples during replay. GSS [[20](#bib.bib20)] focuses on storing diverse
    examples. GMED [[77](#bib.bib77)], proposes a method for editing the memory examples
    to promote forgetting and discourage memorization. While GMED focuses on editing
    memory examples, Wang et al. [[78](#bib.bib78)] propose a Distributionally Robust
    Optimization framework that considers population- and distribution-level evolution
    to address memory overfitting.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 基于记忆的方法 [[20](#bib.bib20), [23](#bib.bib23), [76](#bib.bib76), [15](#bib.bib15)]
    涉及存储先前数据的一个小子集，并在新的小批量数据中重播它们。MIR [[23](#bib.bib23)] 选择并重播最容易干扰的样本。这种选择性重播旨在优先考虑对保留先前学到的知识最相关的样本。在MIR的基础上，GEN-MIR
    [[23](#bib.bib23)] 结合生成模型在重播过程中合成记忆示例。GSS [[20](#bib.bib20)]专注于存储多样化的示例。GMED [[77](#bib.bib77)]
    提出了一种编辑记忆示例以促进遗忘和阻止记忆化的方法。虽然GMED专注于编辑记忆示例，但王等人 [[78](#bib.bib78)]提出了一个考虑人口和分布演变的分布鲁棒最优化框架来解决记忆过拟合问题。
- en: Expansion-based method
  id: totrans-80
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于扩展的方法
- en: In the context of architecture expansion-based methods, several approaches have
    been proposed to address the forgetting issue and facilitate continual adaptation.
    CN-DPM [[79](#bib.bib79)] introduces a method that expands the network structure
    based on the Dirichlet process mixture model. This approach allows for the automatic
    expansion of the network to accommodate new data distributions or concepts while
    preserving previously learned knowledge. VariGrow [[80](#bib.bib80)] proposes
    a variational architecture growing method based on Bayesian novelty to mitigate
    forgetting. This method leverages Bayesian techniques to identify novel information
    and dynamically expand the network architecture to accommodate new knowledge.
    ODDL [[81](#bib.bib81)] proposes a dynamical architecture expansion method based
    on estimating the discrepancy between the probabilistic representation of the
    memory buffer data and the accumulated knowledge.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于架构扩展的方法的背景下，有几种方法被提出来解决遗忘问题并促进持续适应。CN-DPM [[79](#bib.bib79)]介绍了一种基于狄利克雷过程混合模型扩展网络结构的方法。这种方法允许网络自动扩展以适应新的数据分布或概念，同时保留先前学到的知识。VariGrow
    [[80](#bib.bib80)]提出了一种基于贝叶斯新颖性的变分架构增长方法来减轻遗忘问题。这种方法利用贝叶斯技术来识别新颖信息，并动态地扩展网络架构以适应新知识。ODDL
    [[81](#bib.bib81)]提出了一种基于估计内存缓冲数据的概率表示和累积知识之间差异的动态架构扩展方法。
- en: 2.2 Online CL
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 在线持续学习
- en: 2.2.1 Approaches for Online CL
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1 在线持续学习的方法
- en: The online CL setting presents additional challenges compared to offline CL.
    In online CL, the learner is only allowed to process the data for each task once
     [[5](#bib.bib5)]. Existing works addressing forgetting in online CL are mainly
    based on rehearsal replay [[23](#bib.bib23), [20](#bib.bib20), [82](#bib.bib82),
    [83](#bib.bib83)]. MIR [[23](#bib.bib23)] suggests replaying the samples that
    exhibit the maximum increase in loss. OCS [[84](#bib.bib84)] proposes to select
    samples with high affinity for old tasks. DVC [[85](#bib.bib85)] introduces a
    technique that involves selecting samples whose gradients are most interfered
    with new incoming samples to store in memory buffer. ASER [[82](#bib.bib82)] introduces
    an adversarial Shapley value scoring method that assigns scores to memory data
    samples. These scores are used to evaluate the contribution of memory samples
    to the performance of forgetting. La-MAML [[86](#bib.bib86)] utilizes a meta-learning
    algorithm to tackle online CL by leveraging a small episodic memory. GPS [[87](#bib.bib87)]
    formulates the memory construction problem in experience replay as a combinatorial
    optimization problem, and simulates the forgetting mode of the current task by
    creating future pseudo-tasks. However, in cases where memory constraints are stringent,
    replay-based online CL approaches have limited effectiveness. Some studies have
    proposed the utilization of regularization-based strategies to prevent forgetting [[88](#bib.bib88),
    [89](#bib.bib89)].
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在线CL设置相比于离线CL面临额外的挑战。在在线CL中，学习者仅被允许对每个任务的数据进行一次处理[[5](#bib.bib5)]。现有的解决在线CL中遗忘问题的工作主要基于重演回放[[23](#bib.bib23),
    [20](#bib.bib20), [82](#bib.bib82), [83](#bib.bib83)]。MIR [[23](#bib.bib23)]建议重演损失最大增加的样本。OCS
    [[84](#bib.bib84)]提出选择与旧任务具有高度关联的样本。DVC [[85](#bib.bib85)]引入了一种选择与新来的样本干扰梯度最大样本的方法，将其存储在内存缓冲区中。ASER
    [[82](#bib.bib82)]引入了一种对抗Shapley值评分方法，为内存数据样本分配评分。这些评分用于评估内存样本对遗忘表现的贡献。La-MAML
    [[86](#bib.bib86)]利用元学习算法通过利用小型情景记忆来解决在线CL问题。GPS [[87](#bib.bib87)]将经验回放中的内存构建问题公式化为组合优化问题，并通过创建未来伪任务来模拟当前任务的遗忘模式。然而，在内存约束严格的情况下，基于回放的在线CL方法效果有限。一些研究提出利用基于正则化的策略来防止遗忘[[88](#bib.bib88),
    [89](#bib.bib89)]。
- en: 2.2.2 Imbalanced Class Issue in Online CL
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2 在线CL中的类别不平衡问题
- en: 'The presence of imbalanced data streams in online CL has drawn significant
    attention, primarily due to its prevalence in real-world application scenarios [[90](#bib.bib90),
    [91](#bib.bib91), [92](#bib.bib92), [93](#bib.bib93)]. Addressing the issue of
    class imbalance can be approached through two main strategies: (1) learning a
    model that effectively balances the learning of both old and new classes during
    the training phase, or (2) employing post-processing techniques to calibrate the
    biases inherent in the model.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在线CL中类别不平衡数据流的存在引起了显著关注，这主要由于其在现实世界应用场景中的普遍性[[90](#bib.bib90), [91](#bib.bib91),
    [92](#bib.bib92), [93](#bib.bib93)]。解决类别不平衡问题可以通过两种主要策略： (1) 训练阶段学习一个有效平衡新旧类别的模型，或
    (2) 采用后处理技术来校准模型中固有的偏差。
- en: Balance Learning Between New and Old Classes
  id: totrans-87
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 新旧类别之间的平衡学习
- en: Balancing in the training phase involves heuristically selecting a balanced
    memory to tune the model [[90](#bib.bib90), [91](#bib.bib91), [94](#bib.bib94),
    [95](#bib.bib95)]. Chrysakis et al. [[94](#bib.bib94)] propose class-balancing
    reservoir sampling (CBRS) to tackle this issue. PRS [[95](#bib.bib95)] suggests
    a partitioning reservoir sampling strategy to address this issue. Kim et al. [[96](#bib.bib96)]
    introduces a stochastic information-theoretic reservoir sampler to select memory
    points from the imbalanced data stream. E2E [[90](#bib.bib90)] proposes to alleviate
    the imbalance problem by adopting a balanced fine-tuning strategy at the end of
    each incremental stage. GDumb [[91](#bib.bib91)] found that the downsampling strategy
    can well solve the problem of imbalance between old and new classes.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 训练阶段的平衡涉及启发式地选择一个平衡的记忆来调整模型[[90](#bib.bib90), [91](#bib.bib91), [94](#bib.bib94),
    [95](#bib.bib95)]。Chrysakis等人[[94](#bib.bib94)]提出了类别平衡的蓄水池抽样（CBRS）来解决这个问题。PRS
    [[95](#bib.bib95)]建议采用分区蓄水池抽样策略来解决这个问题。Kim等人[[96](#bib.bib96)]介绍了一种随机信息理论的蓄水池采样器，从不平衡的数据流中选择记忆点。E2E
    [[90](#bib.bib90)]建议通过在每个增量阶段末尾采用平衡微调策略来缓解不平衡问题。GDumb [[91](#bib.bib91)]发现下采样策略可以很好地解决新旧类别之间的不平衡问题。
- en: Post-Processing Calibration Techniques
  id: totrans-89
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 后处理校准技术
- en: Post-processing calibration methods perform bias calibration on the classifier
    of the model during the inference phase [[92](#bib.bib92), [97](#bib.bib97), [98](#bib.bib98)].
    BiC [[92](#bib.bib92)] introduces a two-stage training where they perform the
    main training in the first stage, followed by a linear transformation to mitigate
    bias in the second stage. WA [[98](#bib.bib98)] reduces the imbalance between
    old and new classes by aligning the logits output from the model on the old and
    new classes. OBC [[99](#bib.bib99)] provides both theoretical and empirical explanations
    of how replay can introduce a bias towards the most recently observed data stream.
    They address this issue by modifying the model’s output layer, aiming to mitigate
    the effects of this online bias.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理校准方法在推理阶段对模型的分类器进行偏差校准[[92](#bib.bib92), [97](#bib.bib97), [98](#bib.bib98)]。BiC[[92](#bib.bib92)]引入了两阶段训练，在第一阶段进行主要训练，然后在第二阶段进行线性变换以减轻偏差。WA[[98](#bib.bib98)]通过对齐模型在旧类和新类上的logits输出，减少旧类和新类之间的不平衡。OBC[[99](#bib.bib99)]提供了回放如何引入对最近观察到的数据流的偏见的理论和实证解释。他们通过修改模型的输出层来解决这个问题，旨在减轻这种在线偏差的影响。
- en: 2.3 Semi-supervised, Few-shot and Unsupervised CL
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 半监督、Few-shot和无监督CL
- en: 2.3.1 Semi-supervised CL
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1 半监督CL
- en: Semi-supervised CL is an extension of traditional CL that allows each task to
    incorporate unlabeled data as well.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督CL是传统CL的扩展，它允许每个任务同时结合未标记的数据。
- en: Existing works on semi-supervised CL, mainly include generative replay [[100](#bib.bib100),
    [101](#bib.bib101)] and distillation [[56](#bib.bib56), [102](#bib.bib102)] to
    avoid forgetting. Specifically, ORDisCo [[101](#bib.bib101)] maintains a relatively
    constant-sized network, and it simultaneously trains a classifier and a conditional
    GAN, and learns the classifier by replaying data sampled from the GAN in an online
    fashion. SDSL [[100](#bib.bib100)] is also based on the generation-replay framework.
    GD [[56](#bib.bib56)] and DistillMatch [[102](#bib.bib102)] are distillation-based
    approaches. DistillMatch performs knowledge distillation by assigning pseudo-labels
    and data augmentation to the unlabeled data to reduce forgetting.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的半监督CL研究主要包括生成重放[[100](#bib.bib100), [101](#bib.bib101)]和蒸馏[[56](#bib.bib56),
    [102](#bib.bib102)]以避免遗忘。具体来说，ORDisCo[[101](#bib.bib101)]维持一个相对固定大小的网络，同时训练分类器和条件GAN，并通过在线方式重放从GAN中采样的数据来训练分类器。SDSL[[100](#bib.bib100)]也是基于生成重放框架的。GD[[56](#bib.bib56)]和DistillMatch[[102](#bib.bib102)]是基于蒸馏的方法。DistillMatch通过为未标记数据分配伪标签和数据增强来进行知识蒸馏，以减少遗忘。
- en: 2.3.2 Few-shot CL
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.2 Few-shot CL
- en: Few-shot CL refers to the scenario where a model needs to learn new tasks with
    only a limited number of labeled examples per task while retaining knowledge from
    previously encountered tasks. The challenge lies in effectively leveraging the
    limited labeled data and previously learned knowledge to adapt to new tasks while
    avoiding forgetting.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Few-shot CL指的是模型需要在每个任务只有有限数量的标记样本的情况下学习新任务，同时保留之前遇到的任务中的知识。挑战在于有效利用有限的标记数据和以前学到的知识以适应新任务，同时避免遗忘。
- en: 'Compared to traditional CL, few-shot CL faces the challenge of overfitting
    due to the limited number of examples available per task [[103](#bib.bib103),
    [104](#bib.bib104)]. To tackle the forgetting problem in few-shot CL, existing
    approaches employ various techniques, including metric learning, meta-learning,
    and parameter regularization. Due to limited pages, we provide details of these
    methods in Appendix. [A.2](#A1.SS2 "A.2 Few-shot CL ‣ Appendix A Continual Learning
    ‣ A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning").
    Below, we briefly explain each method: (1) Metric Learning-Based: These methods
    perform classification by class prototypes. To avoid forgetting, the prototype
    of the new class should be separable from the old class [[105](#bib.bib105), [106](#bib.bib106),
    [107](#bib.bib107)], and the prototype of the old class should not change drastically
    during the adjustment process of the new class [[107](#bib.bib107), [103](#bib.bib103)].
    (2) Meta-Learning-Based: These methods simulate the inference phase during training
    so that CL models can quickly adapt to unseen new classes to solve few-shot CL.
    For example, LIMIT [[108](#bib.bib108)] and MetaFSCIL [[109](#bib.bib109)] split
    the base task into multiple ’fake’-incremental tasks, so that the model has the
    learning ability of few-shot CL tasks. By reducing the loss associated with the
    meta-objective, they minimize forgetting of the old tasks. (3) Parameter Regularization-Based:
    These methods employ various strategies to address the forgetting problem by penalizing
    parameter updates that are important for old tasks [[110](#bib.bib110), [111](#bib.bib111)].'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的CL相比，少样本CL面临着由于每个任务可用示例数量有限而导致的过拟合问题[[103](#bib.bib103), [104](#bib.bib104)]。为了应对少样本CL中的遗忘问题，现有的方法采用了各种技术，包括度量学习、元学习和参数正则化。由于页数有限，我们在附录中提供了这些方法的详细信息。[A.2](#A1.SS2
    "A.2 Few-shot CL ‣ Appendix A Continual Learning ‣ A Comprehensive Survey of Forgetting
    in Deep Learning Beyond Continual Learning")。以下是对每种方法的简要说明：（1）基于度量学习：这些方法通过类别原型进行分类。为了避免遗忘，新类别的原型应与旧类别的原型可分隔[[105](#bib.bib105),
    [106](#bib.bib106), [107](#bib.bib107)]，且旧类别的原型在调整新类别的过程中不应发生剧烈变化[[107](#bib.bib107),
    [103](#bib.bib103)]。（2）基于元学习：这些方法在训练过程中模拟推理阶段，以便CL模型能够迅速适应未见过的新类别，从而解决少样本CL问题。例如，LIMIT[[108](#bib.bib108)]和MetaFSCIL[[109](#bib.bib109)]将基础任务拆分为多个“伪”增量任务，使模型具备少样本CL任务的学习能力。通过减少与元目标相关的损失，它们最小化了旧任务的遗忘。（3）基于参数正则化：这些方法通过惩罚对旧任务重要的参数更新，采用各种策略来解决遗忘问题[[110](#bib.bib110),
    [111](#bib.bib111)]。
- en: 2.3.3 Unsupervised CL
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.3 无监督CL
- en: Unsupervised CL [[112](#bib.bib112), [113](#bib.bib113)] is a rapidly growing
    research area that emphasizes learning from unlabeled data alone. Unlike traditional
    supervised CL relying on labeled data, unsupervised CL explores techniques that
    enable learning and adaptation using only unlabeled data.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督CL[[112](#bib.bib112), [113](#bib.bib113)]是一个快速发展的研究领域，强调仅从未标记数据中学习。与依赖于标记数据的传统监督CL不同，无监督CL探索了仅使用未标记数据进行学习和适应的技术。
- en: Existing unsupervised CL methods mainly rely on representation-based contrastive
    learning techniques [[112](#bib.bib112), [114](#bib.bib114), [113](#bib.bib113),
    [115](#bib.bib115)]. CURL [[112](#bib.bib112)] is the first offline continual
    unsupervised representation learning framework with unknown task labels and boundaries.
    Co2l [[114](#bib.bib114)] finds that self-supervised loss is generally more robust
    to forgetting than cross-entropy loss in CL. LUMP [[113](#bib.bib113)] observes
    that unsupervised CL models have a flatter loss landscape than supervised CL models,
    and additionally, it performs Mixup [[116](#bib.bib116)] between old task samples
    and new task samples to reduce forgetting. Prob [[115](#bib.bib115)] revisits
    the phenomenon of representational forgetting in both supervised and unsupervised
    CL settings, and shows that using observed accuracy to measure forgetting is a
    misleading metric.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的无监督CL方法主要依赖于基于表示的对比学习技术[[112](#bib.bib112), [114](#bib.bib114), [113](#bib.bib113),
    [115](#bib.bib115)]。CURL[[112](#bib.bib112)]是第一个离线持续无监督表示学习框架，处理未知任务标签和边界。Co2l[[114](#bib.bib114)]发现自监督损失通常比交叉熵损失对CL中的遗忘更具鲁棒性。LUMP[[113](#bib.bib113)]观察到无监督CL模型的损失景观比监督CL模型更平坦，并且，它在旧任务样本和新任务样本之间执行Mixup[[116](#bib.bib116)]以减少遗忘。Prob[[115](#bib.bib115)]重新审视了在监督和无监督CL设置中表示遗忘的现象，并显示使用观测准确性来衡量遗忘是一种误导性指标。
- en: 2.4 Theoretical Analysis
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 理论分析
- en: The theoretical analysis of CL is quite a few. Pentina et al. [[117](#bib.bib117)]
    provide a generalization bound in the PAC-Bayesian framework for CL. Karakida
    et al. [[118](#bib.bib118)] conduct a theoretical analysis of the generalization
    performance within a solvable case of CL. They utilized a statistical mechanical
    analysis of kernel ridge-less regression to provide insights into the understanding
    of the generalization capabilities in CL scenarios. Kim et al. [[119](#bib.bib119)]
    study class-incremental learning and provides a theoretical justification for
    decomposing the problem into task-id prediction and within-task prediction. Evron
    et al. [[120](#bib.bib120)] theoretically study the CL on a sequence of separable
    linear classification tasks with binary classes. Peng et al. [[121](#bib.bib121)]
    propose Ideal Continual Learner (ICL), which unifies multiple existing well-established
    CL solutions, and gives the generalization boundary of ICL.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 关于CL的理论分析相对较少。Pentina等人 [[117](#bib.bib117)] 在PAC-Bayesian框架中提供了CL的一般化界限。Karakida等人
    [[118](#bib.bib118)] 对CL的可解情况中的一般化性能进行了理论分析。他们利用核岭回归的统计力学分析来提供对CL场景中一般化能力的理解。Kim等人
    [[119](#bib.bib119)] 研究了类别增量学习，并为将问题分解为任务ID预测和任务内预测提供了理论依据。Evron等人 [[120](#bib.bib120)]
    在一系列可分线性分类任务中理论研究了CL。Peng等人 [[121](#bib.bib121)] 提出了理想连续学习者（ICL），该模型统一了多个现有的成熟CL解决方案，并给出了ICL的一般化界限。
- en: 3 Forgetting in Foundation Model
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 遗忘在基础模型中的表现
- en: The forgetting in foundation models manifests in several distinct directions.
    Firstly, when fine-tuning a foundation model, there is a tendency to forget the
    pre-trained knowledge, resulting in sub-optimal performance on downstream tasks.
    This implies that the model may not effectively leverage the general knowledge
    it acquired during pre-training, leading to a decrease in overall performance.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型中的遗忘表现出几个不同的方向。首先，在微调基础模型时，往往会遗忘预训练知识，从而导致下游任务的表现不佳。这意味着模型可能无法有效利用在预训练过程中获得的一般知识，从而导致整体性能的下降。
- en: Secondly, foundation models are typically trained on a dataset for a single
    pass  [[122](#bib.bib122), [123](#bib.bib123)], resulting in two types of forgetting.
    Firstly, in the case of streaming data, the challenge lies in retaining previous
    pre-trained knowledge as unlabeled data arrives sequentially [[124](#bib.bib124)].
    This type of forgetting is undesirable as it can hinder the model’s ability to
    leverage prior knowledge effectively. Conversely, the earlier examples encountered
    during pre-training may be overwritten or forgotten more quickly than the later
    examples. While this characteristic of forgetting can be seen as a disadvantage
    in some contexts, it can be advantageous in privacy-preserving scenarios. By discarding
    or attenuating sensitive information from the initial training examples, the model
    can enhance privacy protection. Therefore, foundation models exhibit both challenges
    and potential benefits associated with forgetting.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，基础模型通常在单次通过的数据集上进行训练 [[122](#bib.bib122), [123](#bib.bib123)]，导致两种类型的遗忘。首先，在流数据的情况下，挑战在于随着未标记数据按顺序到达，如何保留之前的预训练知识
    [[124](#bib.bib124)]。这种类型的遗忘是不理想的，因为它可能会阻碍模型有效利用先前知识的能力。相反，预训练期间遇到的早期示例可能会被更快地覆盖或遗忘。虽然这种遗忘的特征在某些情况下可能被视为劣势，但在隐私保护场景中，它可能具有优势。通过丢弃或减弱初始训练示例中的敏感信息，模型可以增强隐私保护。因此，基础模型在遗忘方面表现出既有挑战也有潜在的好处。
- en: Lastly, foundation models have the ability to extract features with a strong
    feature extractor, which makes foundation models increasingly popular for CL approaches,
    aiming to achieve excellent performance across multiple tasks without forgetting
    previously learned knowledge. By leveraging the powerful feature extraction capabilities
    of foundation models, researchers have explored new avenues for advancing CL techniques.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，基础模型具有强大的特征提取能力，这使得基础模型在CL方法中越来越受欢迎，旨在实现多个任务上的出色性能，同时避免遗忘之前学到的知识。通过利用基础模型强大的特征提取能力，研究人员探索了推动CL技术的新途径。
- en: Below, we will delve into each research direction in more detail, examining
    the challenges and opportunities they present in the context of foundation models.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将更详细地探讨每个研究方向，考察它们在基础模型背景下所呈现的挑战和机遇。
- en: 3.1 Forgetting in Fine-Tuning Foundation Models
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 微调基础模型中的遗忘
- en: Fine-tuning the foundation model could achieve impressive performance on downstream
    tasks. However, fine-tuning a foundation model can result in the forgetting of
    pre-trained knowledge, which may lead to sub-optimal performance on downstream
    tasks. Forgetting occurs when the target model deviates significantly from the
    pre-trained model during the fine-tuning process  [[125](#bib.bib125)]. This deviation
    increases the likelihood of overfitting to a small fine-tuning set  [[126](#bib.bib126)],
    which can contribute to forgetting.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对基础模型进行微调可以在下游任务中实现令人印象深刻的表现。然而，微调基础模型可能导致预训练知识的遗忘，从而可能导致下游任务的表现不佳。遗忘发生在目标模型在微调过程中与预训练模型显著偏离时[[125](#bib.bib125)]。这种偏离增加了对小型微调集过拟合的可能性[[126](#bib.bib126)]，这可能促成遗忘。
- en: There are several simple and effective strategies to mitigate forgetting during
    the fine-tuning process. These include techniques such as learning rate decreasing [[126](#bib.bib126)],
    weight decay [[127](#bib.bib127), [128](#bib.bib128)], and Mixout regularization [[125](#bib.bib125)].
    Furthermore, Fatemi et al. [[129](#bib.bib129)] find that in the study of mitigating
    the gender bias of the pre-trained language model, the pre-trained knowledge will
    be forgotten when the small neutral data is fine-tuned, which will hurt the downstream
    task performance. Dong et al. [[130](#bib.bib130)] observe that adversarial fine-tuning
    of pre-trained language models is prone to severe catastrophic forgetting, causing
    the loss of previously captured general and robust linguistic features. To address
    these issues, they propose a Robust Informative Fine-Tuning method from an information-theoretical
    perspective. In addition, an approach called Recall and Learn, proposed in Chen
    et al. [[131](#bib.bib131)], addresses the forgetting issue by utilizing Pretraining
    Simulation and Objective Shifting. This approach enables multi-task fine-tuning
    without relying on the data from the pretraining tasks.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种简单有效的策略可以减轻微调过程中的遗忘，包括学习率下降[[126](#bib.bib126)]、权重衰减[[127](#bib.bib127),
    [128](#bib.bib128)]和Mixout正则化[[125](#bib.bib125)]。此外，Fatemi等人[[129](#bib.bib129)]发现，在缓解预训练语言模型的性别偏见研究中，当对少量中立数据进行微调时，预训练知识会被遗忘，这会影响下游任务的表现。Dong等人[[130](#bib.bib130)]观察到，预训练语言模型的对抗性微调容易导致严重的灾难性遗忘，从而丧失先前捕获的通用且稳健的语言特征。为了解决这些问题，他们从信息理论的角度提出了一种鲁棒信息微调方法。此外，Chen等人[[131](#bib.bib131)]提出了一种称为“回忆与学习”的方法，通过利用预训练模拟和目标转移来解决遗忘问题。这种方法使得多任务微调无需依赖预训练任务的数据。
- en: 3.2 Forgetting in One-Epoch Pre-training
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 一轮预训练中的遗忘
- en: 3.2.1 Forgetting Previous Knowledge in Pre-training
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 预训练中的遗忘旧知识
- en: Foundation model is typically trained using self-supervised learning, and self-supervised
    learning with streaming data has become a significant research area due to the
    storage and time costs associated with storing and training on large amounts of
    unlabeled data. In this context, Hu et al.[[132](#bib.bib132)] propose a sequential
    training method for self-supervised learning, demonstrating that self-supervised
    learning exhibits less forgetting compared to its supervised learning counterpart.
    Similarly, Purushwalkam et al.[[133](#bib.bib133)] perform self-supervised learning
    on a continuous non-iid data stream and introduce a minimum redundancy (MinRed)
    buffer approach to mitigate catastrophic forgetting. Furthermore, Lin et al. [[134](#bib.bib134)]
    develop a rehearsal-based framework that incorporates their proposed sampling
    strategies and self-supervised knowledge distillation to address the forgetting
    problem in streaming self-supervised learning.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型通常使用自监督学习进行训练，而自监督学习与流数据结合已成为一个重要的研究领域，因为存储和训练大量未标记数据的存储和时间成本。在这种背景下，Hu等人[[132](#bib.bib132)]提出了一种自监督学习的顺序训练方法，证明自监督学习相比于其监督学习对遗忘的表现较少。类似地，Purushwalkam等人[[133](#bib.bib133)]在连续的非独立同分布数据流上进行自监督学习，并引入了一种最小冗余（MinRed）缓冲区方法来缓解灾难性遗忘。此外，Lin等人[[134](#bib.bib134)]开发了一种基于回放的框架，结合了他们提出的采样策略和自监督知识蒸馏，以解决流式自监督学习中的遗忘问题。
- en: 3.2.2 Beneficial Forgetting in Pre-training
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 预训练中的有益遗忘
- en: 'The memorization and forgetting of large foundation model have attracted much
    attention, some emerging work [[124](#bib.bib124)] studies the connection between
    the memorization of training data and different types of forgetting. Foundation
    models display two seemingly conflicting occurrences: the memorization of training
    data and different types of forgetting. Memorization refers to models excessively
    fitting to specific training examples, making them vulnerable to privacy leakage,
    e.g., inferring whether a data point belong to the training data associated with
    the pre-trained model. Some researches have shown that this phenomenon of leakage
    personally identifiable information in language model [[135](#bib.bib135), [136](#bib.bib136)],
    which is undesible in practice. On the other hand, forgetting involves the gradual
    loss of information about examples encountered early in training. The study in
    [[124](#bib.bib124)] establishes a connection between these phenomena and introduce
    a method to quantify the degree to which models "forget" specific details of training
    examples. This leads to reduced susceptibility to privacy attacks on examples
    that have not been recently encountered. Different from CL, which measures the
    forgetting as apposed to retain the knowledge from previously learned knowledge.
    In contrast, the study conducted by [[124](#bib.bib124)] examines a task-specific
    model and investigates the degree of forgetting exhibited towards specific training
    examples.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 大型基础模型的记忆和遗忘问题引起了广泛关注，一些新兴的研究[[124](#bib.bib124)]探讨了训练数据的记忆与不同类型遗忘之间的关系。基础模型表现出两种看似矛盾的现象：训练数据的记忆和不同类型的遗忘。记忆指的是模型过度拟合特定训练示例，使其容易受到隐私泄露的影响，例如推断某数据点是否属于与预训练模型相关的训练数据。一些研究显示了语言模型中泄露个人身份信息的现象[[135](#bib.bib135),
    [136](#bib.bib136)]，这种现象在实践中是不可接受的。另一方面，遗忘涉及到在训练早期遇到的示例信息的逐渐丧失。[[124](#bib.bib124)]的研究建立了这些现象之间的联系，并引入了一种方法来量化模型“遗忘”训练示例的特定细节的程度。这导致了对那些最近没有遇到的示例的隐私攻击的减少。与CL不同，CL测量的是遗忘而不是保留之前学习的知识。相反，[[124](#bib.bib124)]的研究考察了特定任务模型，并调查了对特定训练示例的遗忘程度。
- en: 3.3 CL in Foundation Model
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 基础模型中的CL
- en: Recently, researchers have explored the use of foundation models to tackle continual
    learning (CL) problems. CL based on foundation or pre-trained models has shown
    promise, particularly in the domain of natural language processing (NLP). Studies
    such as [[137](#bib.bib137), [138](#bib.bib138)] delve into the effective application
    of pre-trained models in CL for NLP tasks. Furthermore, [[139](#bib.bib139)] demonstrates
    the capability of fine-tuned pre-trained language models to act as continual learners.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，研究人员探索了利用基础模型解决持续学习（CL）问题的方法。基于基础或预训练模型的CL显示出了前景，特别是在自然语言处理（NLP）领域。诸如[[137](#bib.bib137),
    [138](#bib.bib138)]的研究深入探讨了预训练模型在NLP任务中的CL的有效应用。此外，[[139](#bib.bib139)]展示了微调的预训练语言模型作为持续学习者的能力。
- en: Given the remarkable success of the Transformer model  [[140](#bib.bib140)]
    in computer vision tasks  [[141](#bib.bib141)], many studies in the field have
    started exploring the application of CL using foundational model. Ostapenko et
    al. [[142](#bib.bib142)] study the efficacy of pre-trained vision models as a
    foundation for downstream CL tasks. Mehta et al. [[143](#bib.bib143)] explain
    why pretrained models are more helpful in mitigating forgetting from a loss landscape
    perspective. They find that pretrained models drive weights to converge to wider
    minima, which usually indicates better generalization. Ramasesh et al. [[144](#bib.bib144)]
    observe that pretrained models are more resistant to forgetting than randomly
    initialized models, and this capability increases with the size of pretrained
    model and data.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到Transformer模型[[140](#bib.bib140)]在计算机视觉任务中的显著成功[[141](#bib.bib141)]，许多领域的研究开始探索使用基础模型进行CL的应用。Ostapenko等[[142](#bib.bib142)]研究了预训练视觉模型作为下游CL任务的基础的有效性。Mehta等[[143](#bib.bib143)]解释了为什么预训练模型在减轻遗忘方面从损失景观的角度更具帮助。他们发现，预训练模型使权重收敛到更宽的最小值，这通常表示更好的泛化能力。Ramasesh等[[144](#bib.bib144)]观察到，预训练模型比随机初始化的模型更能抵御遗忘，这种能力随着预训练模型和数据的规模增加而增加。
- en: 'In addition to the aforementioned studies, many researchers have explored the
    fine-tuning of pre-trained models to enhance their adaptation to downstream tasks
    in CL. These efforts primarily revolve around parameter-efficient fine-tuning
    techniques, such as Adapters [[145](#bib.bib145), [146](#bib.bib146)] and Prompts [[147](#bib.bib147),
    [148](#bib.bib148), [149](#bib.bib149), [150](#bib.bib150)]. (1) Adapter-based
    methods: ADAM [[145](#bib.bib145)] demonstrates that utilizing a frozen base model
    to generate generalizable embeddings and setting classifier weights as prototype
    features can outperform state-of-the-art CL methods. Additionally, performing
    model adaptation on downstream tasks further enhances performance. ADA [[146](#bib.bib146)],
    on the other hand, adopts a different approach by learning a single adapter for
    each new task instead of adjusting the entire CL model. The new adapter is then
    fused with the existing adapter to maintain a fixed capacity. (2) Prompts-based
    methods: L2P [[147](#bib.bib147)] introduces a dynamic instance-level learning
    approach to determine the matched expert-prompt for each new task, while freezing
    the pre-trained model. DualPrompt [[148](#bib.bib148)] builds upon L2P by appending
    complementary prompts (shared general-prompt and matched expert-prompt) on a pre-trained
    backbone. S-Prompt [[149](#bib.bib149)] focuses on exemplar-free domain-incremental
    learning. It independently learns prompts for each domain and stores them in a
    pool to prevent forgetting. Progressive Prompts [[150](#bib.bib150)] also learns
    a prompt for each new task, but it freezes the prompts of old tasks and incorporates
    them into the new task to encourage the transfer of knowledge in a forward manner.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述研究，许多研究人员还探索了微调预训练模型以增强其在CL下游任务中的适应性。这些努力主要围绕参数高效的微调技术，如Adapters [[145](#bib.bib145),
    [146](#bib.bib146)] 和 Prompts [[147](#bib.bib147), [148](#bib.bib148), [149](#bib.bib149),
    [150](#bib.bib150)]。 (1) 基于适配器的方法：ADAM [[145](#bib.bib145)] 证明了利用冻结的基础模型生成通用嵌入并将分类器权重设为原型特征，可以超越最先进的CL方法。此外，在下游任务上进行模型适配进一步提高了性能。ADA
    [[146](#bib.bib146)] 则采用了不同的方法，通过为每个新任务学习一个单独的适配器，而不是调整整个CL模型。然后将新的适配器与现有适配器融合，以保持固定的容量。
    (2) 基于提示的方法：L2P [[147](#bib.bib147)] 介绍了一种动态实例级学习方法，以确定每个新任务的匹配专家提示，同时冻结预训练模型。DualPrompt
    [[148](#bib.bib148)] 在L2P的基础上，通过在预训练骨干网络上附加补充提示（共享的通用提示和匹配的专家提示）进行扩展。S-Prompt
    [[149](#bib.bib149)] 专注于无示例的领域增量学习。它独立地为每个领域学习提示，并将它们存储在池中以防止遗忘。Progressive Prompts
    [[150](#bib.bib150)] 也为每个新任务学习一个提示，但冻结旧任务的提示，并将它们纳入新任务中，以鼓励知识的前向转移。
- en: 4 Forgetting in Domain Adaptation
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 域适应中的遗忘
- en: The objective of domain adaptation is to transfer knowledge from a source domain
    to a target domain. A domain represents the joint distribution of the input space
    ${\mathcal{X}}$ and the output space ${\mathcal{Y}}$. Specifically, the source
    domain is defined as ${\mathcal{P}}^{S}({\bm{x}},y)$, where ${\bm{x}}$ belongs
    to the input space ${\mathcal{X}}^{S}$ and $y$ belongs to the output space ${\mathcal{Y}}^{S}$.
    Similarly, the target domain is defined as ${\mathcal{P}}^{T}({\bm{x}},y)$, where
    ${\bm{x}}$ belongs to the input space ${\mathcal{X}}^{T}$ and $y$ belongs to the
    output space ${\mathcal{Y}}^{T}$.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 域适应的目标是将知识从源域转移到目标域。一个域表示输入空间${\mathcal{X}}$和输出空间${\mathcal{Y}}$的联合分布。具体来说，源域定义为${\mathcal{P}}^{S}({\bm{x}},y)$，其中${\bm{x}}$属于输入空间${\mathcal{X}}^{S}$，$y$属于输出空间${\mathcal{Y}}^{S}$。同样，目标域定义为${\mathcal{P}}^{T}({\bm{x}},y)$，其中${\bm{x}}$属于输入空间${\mathcal{X}}^{T}$，$y$属于输出空间${\mathcal{Y}}^{T}$。
- en: 'In the context of continual domain adaptation (CDA) [[151](#bib.bib151)], the
    focus is primarily on the covariate shift setting. Covariate shift refers to a
    situation where the distribution of input data, ${\mathcal{X}}$, differs between
    the source and target domains, while the conditional distribution of the output,
    ${\mathcal{Y}}$, remains the same. This setting assumes that the relationship
    between inputs and outputs remains consistent across domains, but the distributions
    of the input data vary. This is formally defined as the following:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在持续域适应（CDA） [[151](#bib.bib151)] 的背景下，重点主要是协变量移位设置。协变量移位指的是输入数据${\mathcal{X}}$的分布在源域和目标域之间不同，而输出的条件分布${\mathcal{Y}}$保持不变。这种设置假设输入和输出之间的关系在各个域中保持一致，但输入数据的分布有所不同。其正式定义如下：
- en: '|  | $\small{\mathcal{P}}^{S}(X={\bm{x}})\neq{\mathcal{P}}^{T}(X={\bm{x}}),{\mathcal{P}}^{S}(y&#124;X={\bm{x}})={\mathcal{P}}^{T}(y&#124;X={\bm{x}}).$
    |  | (2) |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '|  | $\small{\mathcal{P}}^{S}(X={\bm{x}})\neq{\mathcal{P}}^{T}(X={\bm{x}}),{\mathcal{P}}^{S}(y&#124;X={\bm{x}})={\mathcal{P}}^{T}(y&#124;X={\bm{x}}).$
    |  | (2) |'
- en: CDA and traditional CL have distinct characteristics and goals. On the one hand,
    CDA differs from traditional CL in terms of the availability of source domain
    data for transferring knowledge across the target domain sequence. In CDA, the
    source domain data is accessible, and the objective is to adapt the model from
    the source domain to the target domain, leveraging the available source domain
    data. However, the target domain may only provide unlabeled data, requiring the
    model to adapt to the new domain without explicit supervision. On the other hand,
    traditional CL aims to learn and adapt the model to a sequence of tasks without
    accessing previous task-specific labeled data. Labeled data is typically provided
    for each task in traditional CL.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: CDA 和传统的 CL 具有不同的特征和目标。一方面，CDA 在跨目标领域序列转移知识的源领域数据的可用性方面与传统 CL 不同。在 CDA 中，源领域数据是可获取的，目标是将模型从源领域适应到目标领域，利用可用的源领域数据。然而，目标领域可能只提供未标记的数据，这要求模型在没有明确监督的情况下适应新领域。另一方面，传统的
    CL 旨在学习和调整模型以应对一系列任务，而不访问以前任务的标签数据。在传统 CL 中，通常会为每个任务提供标记数据。
- en: 'Problem Setup: Suppose we have a pre-trained model $f_{{\bm{\theta}}}$ that
    has been trained on a set of source domain data ${\mathcal{P}}^{S}({\bm{x}},y)$,
    where ${\bm{x}}$ belongs to the source domain input space ${\mathcal{X}}^{S}$
    and $y$ belongs to the source domain label space ${\mathcal{Y}}^{S}$. Additionally,
    we have a sequence of evolving target distributions ${\mathcal{P}}_{t}^{T}({\bm{x}},y)$,
    where ${\bm{x}}$ belongs to the input space ${\mathcal{X}}^{T}_{t}$ of the target
    domain $t$. $y$ belongs to the label space ${\mathcal{Y}}^{T}_{t}$ of the target
    domain $t$. $t$ represents the domain index ranging from 1 to $N$. The objective
    of CDA, as proposed in [[151](#bib.bib151)], is to train $f_{{\bm{\theta}}}$ in
    such a way that it performs well on all the domains ${\mathcal{P}}_{t}^{T}({\bm{x}},y)$
    in the evolving target domain sequence, defined as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 问题设置：假设我们有一个经过预训练的模型 $f_{{\bm{\theta}}}$，它在一组源领域数据 ${\mathcal{P}}^{S}({\bm{x}},y)$
    上进行训练，其中 ${\bm{x}}$ 属于源领域输入空间 ${\mathcal{X}}^{S}$，$y$ 属于源领域标签空间 ${\mathcal{Y}}^{S}$。此外，我们还有一系列不断演变的目标分布
    ${\mathcal{P}}_{t}^{T}({\bm{x}},y)$，其中 ${\bm{x}}$ 属于目标领域 $t$ 的输入空间 ${\mathcal{X}}^{T}_{t}$。$y$
    属于目标领域 $t$ 的标签空间 ${\mathcal{Y}}^{T}_{t}$。$t$ 代表领域索引，范围从 1 到 $N$。CDA 的目标，如 [[151](#bib.bib151)]
    所提出的，是以这样的方式训练 $f_{{\bm{\theta}}}$，使其在不断演变的目标领域序列中的所有领域 ${\mathcal{P}}_{t}^{T}({\bm{x}},y)$
    上表现良好，定义如下：
- en: '|  | $\small\min_{{\bm{\theta}}}\mathbb{E}_{t\in[1,\ldots,N]}\mathbb{E}_{{\bm{x}}^{T}\sim
    P^{T}_{t},{\bm{x}}^{S}\sim P^{S}}\mathcal{L}\left(f_{{\bm{\theta}}}({\bm{x}}^{T}),f_{{\bm{\theta}}}({\bm{x}}^{S})\right).$
    |  | (3) |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '|  | $\small\min_{{\bm{\theta}}}\mathbb{E}_{t\in[1,\ldots,N]}\mathbb{E}_{{\bm{x}}^{T}\sim
    P^{T}_{t},{\bm{x}}^{S}\sim P^{S}}\mathcal{L}\left(f_{{\bm{\theta}}}({\bm{x}}^{T}),f_{{\bm{\theta}}}({\bm{x}}^{S})\right).$
    |  | (3) |'
- en: When dealing with new target domains, it is important to note that their data
    distributions differ from that of the source domain. As a result, adapting the
    model to these new domains can inadvertently result in forgetting the knowledge
    acquired from the previous domains. To mitigate this issue, various approaches
    have been developed to tackle the problem of catastrophic forgetting in domain
    adaptation.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理新目标领域时，需要注意的是它们的数据分布与源领域不同。因此，将模型适应这些新领域可能会无意中导致忘记从以前领域获得的知识。为了解决这个问题，已经开发了各种方法来应对领域适应中的灾难性遗忘问题。
- en: When the source domain data is available, most of the works avoid forgetting
    by replaying the source domain data [[152](#bib.bib152), [153](#bib.bib153), [154](#bib.bib154)],
    and a few works are based on regularization [[155](#bib.bib155)], or meta-learning [[156](#bib.bib156)].
    First, Replay-based methods are effective in preventing forgetting by incorporating
    data or knowledge from previous domains. One approach, CUA [[152](#bib.bib152)],
    addresses the issue by randomly selecting samples from previous domains and storing
    them in a memory buffer. Another method called UCL-GV [[157](#bib.bib157)] utilizes
    a First-In, First-Out (FIFO) buffer to replay episodic memory. AuCID [[153](#bib.bib153)]
    tackles the problem of continual unsupervised domain adaptation by consolidating
    the learned internal distribution. It achieves this by storing a fixed number
    of confident samples for each class per domain, which are later replayed during
    the adaptation process. Then, GRCL [[155](#bib.bib155)] utilizes the gradient
    direction of samples from the previous domain as a regularization term. This constraint
    ensures that the model can be updated with new target domain data without negatively
    affecting the performance of the previous domain. Finally, Meta-DR [[156](#bib.bib156)]
    proposes a meta-learning and domain randomization approach to mitigate forgetting
    and retain knowledge from previous domains during CDA.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当源领域数据可用时，大多数工作通过重放源领域数据来避免遗忘[[152](#bib.bib152), [153](#bib.bib153), [154](#bib.bib154)]，而少数工作则基于正则化[[155](#bib.bib155)]或元学习[[156](#bib.bib156)]。首先，基于重放的方法通过结合来自先前领域的数据或知识来有效地防止遗忘。一种方法，CUA[[152](#bib.bib152)]，通过随机选择来自先前领域的样本并将其存储在记忆缓冲区中来解决这一问题。另一种方法叫做
    UCL-GV[[157](#bib.bib157)]，利用先进先出（FIFO）缓冲区来重放情景记忆。AuCID[[153](#bib.bib153)] 通过巩固学习到的内部分布来解决持续无监督领域适应的问题。它通过为每个类别每个领域存储固定数量的自信样本来实现这一点，这些样本随后在适应过程中被重放。然后，GRCL[[155](#bib.bib155)]
    利用来自先前领域样本的梯度方向作为正则化项。这一约束确保了模型可以使用新的目标领域数据进行更新而不会对先前领域的性能产生负面影响。最后，Meta-DR[[156](#bib.bib156)]
    提出了元学习和领域随机化的方法，以减轻遗忘并在 CDA 过程中保留来自先前领域的知识。
- en: Recently, few works have focused on source-free approaches [[158](#bib.bib158)]
    that aim to protect the privacy of the source domain data, which is often inaccessible
    in many scenarios [[159](#bib.bib159), [160](#bib.bib160)]. CoSDA [[159](#bib.bib159)]
    introduces a knowledge distillation method that employs a dual-speed teacher-student
    structure. The slow-updating teacher preserves the long-term knowledge of previous
    domains, while the fast-updating student quickly adapts to the target domain.
    C-SUDA [[160](#bib.bib160)] achieves continual adaptation by synthesizing source-style
    images to avoid forgetting the source domain.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，一些工作开始关注无源领域的方法[[158](#bib.bib158)]，这些方法旨在保护源领域数据的隐私，而源领域数据在许多情况下往往无法获取[[159](#bib.bib159),
    [160](#bib.bib160)]。CoSDA[[159](#bib.bib159)] 引入了一种知识蒸馏方法，该方法采用双速教师-学生结构。更新较慢的教师保留了先前领域的长期知识，而更新较快的学生则迅速适应目标领域。C-SUDA[[160](#bib.bib160)]
    通过合成源领域风格的图像实现持续适应，以避免遗忘源领域。
- en: 5 Forgetting in Test Time Adaptation
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 测试时间适应中的遗忘
- en: Test time adaptation (TTA) refers to the process of adapting a pre-trained model
    on-the-fly to unlabeled test data during inference or testing [[161](#bib.bib161),
    [162](#bib.bib162), [163](#bib.bib163), [164](#bib.bib164), [165](#bib.bib165)].
    Unlike domain adaptation, test time adaptation occurs during the deployment phase
    rather than during the training phase. This approach allows the model to adapt
    to specific instances or conditions encountered at test time to improve the model
    generalization performance. TTA can involve updating certain parameters or features
    of the model based on additional information or feedback obtained during inference.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 测试时间适应（TTA）指的是在推理或测试过程中将预训练模型即时适应于未标记测试数据的过程[[161](#bib.bib161), [162](#bib.bib162),
    [163](#bib.bib163), [164](#bib.bib164), [165](#bib.bib165)]。与领域适应不同，测试时间适应发生在部署阶段而非训练阶段。这种方法允许模型在测试时适应遇到的特定实例或条件，从而提高模型的泛化性能。TTA
    可能涉及根据推理过程中获得的额外信息或反馈更新模型的某些参数或特征。
- en: In traditional machine learning scenarios, during testing, it is typically assumed
    that the test data ${\mathcal{D}}_{test}$ follows the same distribution as the
    training data. However, in real-world applications, it is common for the test
    data distribution to deviate from the training data distribution. To address the
    distribution shift between the training and testing phases, TTA is employed. TTA
    involves adapting the pre-trained model on the unlabeled testing data ${\bm{x}}$
    using an unsupervised adaptation loss function. This adaptation aims to minimize
    the loss function ${\mathcal{L}}({\bm{x}},{\bm{\theta}})$ with respect to the
    parameters ${\bm{\theta}}$. It is important to note that ${\bm{x}}$ is sampled
    from the testing dataset, ${\mathcal{D}}_{test}$. Subsequently, the adapted model
    utilizes the updated parameters to make predictions for the test input ${\bm{x}}$.
    This allows the model to account for the distribution shift between the training
    and testing phases, and hopefully improve its performance on the test data.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的机器学习场景中，通常假设测试数据${\mathcal{D}}_{test}$与训练数据遵循相同的分布。然而，在实际应用中，测试数据分布常常与训练数据分布有所偏离。为了解决训练和测试阶段之间的分布偏移，采用了TTA。TTA涉及使用无监督适配损失函数在未标记的测试数据${\bm{x}}$上适配预训练模型。这种适配旨在最小化关于参数${\bm{\theta}}$的损失函数${\mathcal{L}}({\bm{x}},{\bm{\theta}})$。需要注意的是，${\bm{x}}$是从测试数据集${\mathcal{D}}_{test}$中抽样得到的。随后，适配后的模型利用更新后的参数对测试输入${\bm{x}}$进行预测。这使得模型能够考虑训练和测试阶段之间的分布偏移，并有望提高其在测试数据上的表现。
- en: 'Existing Works: The Tent method [[161](#bib.bib161)] presents a test-time entropy
    minimization approach to enhance model generalization. This method focuses on
    minimizing the entropy of model predictions on test data, thereby improving the
    model’s ability to generalize to unseen examples. Another approach, known as MECTA
    [[166](#bib.bib166)], aims to improve the memory efficiency of test time adaptation.
    MECTA proposes techniques to adapt the model during testing while optimizing memory
    usage, ensuring efficient and effective adaptation to the test data distribution.
    In a different vein, MEMO [[167](#bib.bib167)] proposes a method that applies
    various data augmentations to a test data point. Subsequently, all model parameters
    are adapted by minimizing the entropy of the model’s output distribution across
    the augmented samples.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现有方法：Tent方法[[161](#bib.bib161)]提出了一种在测试时最小化熵的方法，以增强模型的泛化能力。该方法专注于最小化模型在测试数据上的预测熵，从而提高模型对未见示例的泛化能力。另一种方法，称为MECTA[[166](#bib.bib166)]，旨在提高测试时适配的记忆效率。MECTA提出了在测试过程中调整模型的技术，同时优化内存使用，确保高效且有效地适应测试数据分布。另一种方法，MEMO[[167](#bib.bib167)]，提出了一种对测试数据点应用各种数据增强的方法。随后，通过最小化模型输出分布在增强样本上的熵来调整所有模型参数。
- en: When a pre-trained model is adapted to new unlabeled test data, the model shifts
    to the new data, potentially causing it to forget crucial information previously
    learned from the source domain data. This phenomenon can result in a substantial
    loss of knowledge and adversely affect the model’s overall performance [[162](#bib.bib162),
    [168](#bib.bib168)]. To address this issue, existing approaches primarily adopt
    two strategies.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个预训练模型被适配到新的未标记测试数据时，该模型会转向新数据，这可能导致其忘记之前从源域数据中学到的关键信息。这种现象可能导致知识的大量丧失，并对模型的整体性能产生不利影响[[162](#bib.bib162),
    [168](#bib.bib168)]。为了解决这个问题，现有方法主要采用两种策略。
- en: Firstly, one intuitive approach to prevent the model from forgetting the knowledge
    acquired from the source domain is to employ a two-step process. Initially, the
    model trained on the source data is frozen. Subsequently, new learnable parameters
    are introduced to adapt the model to the test-time data [[169](#bib.bib169), [170](#bib.bib170)].
    For instance, VDP [[169](#bib.bib169)] prevents forgetting by freezing the source
    domain model parameters and instead learns a set of visual prompts tailored to
    the test data. These prompts help the model adapt effectively to the target domain.
    Similarly, EcoTTA [[170](#bib.bib170)] freezes the pre-trained network from the
    source domain and introduces a lightweight meta-network to facilitate adaptation
    to the target domain while retaining the valuable source domain knowledge.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，防止模型遗忘从源领域获得知识的一种直观方法是采用两步过程。最初，冻结在源数据上训练的模型。随后，引入新的可学习参数，以使模型适应测试时数据 [[169](#bib.bib169),
    [170](#bib.bib170)]。例如，VDP [[169](#bib.bib169)] 通过冻结源领域模型参数来防止遗忘，而是学习一组针对测试数据的视觉提示。这些提示有助于模型有效地适应目标领域。类似地，EcoTTA
    [[170](#bib.bib170)] 冻结源领域的预训练网络，并引入一个轻量级的元网络，以便在保留有价值的源领域知识的同时，促进对目标领域的适应。
- en: Secondly, another common approach to prevent forgetting in TTA is by constraining
    the update of important parameters, thereby avoiding the introduction of new parameters.
    Tent [[161](#bib.bib161)] specifically focuses on preserving the previous knowledge
    by updating only the BatchNorm layer in the network. On the other hand, CoTTA [[168](#bib.bib168)]
    proposes a different strategy. In each iteration of the adaptation process, CoTTA
    randomly restores the weights of certain neurons to the weights that were originally
    trained in the source domain. This restoration mechanism helps in retaining the
    knowledge acquired from the source domain, preventing it from being forgotten
    during the adaptation to the target domain. Other approaches in TTA employ techniques
    similar to regularization-based approaches commonly used in traditional CL. These
    methods penalize the updating of parameters that are deemed important to the source
    data during the adaptation process [[171](#bib.bib171), [162](#bib.bib162), [172](#bib.bib172)].
    For instance, EATA  [[162](#bib.bib162)] calculates the importance using the Fisher
    information matrix and utilizes this measure as a penalty when updating parameters
    during adaptation.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，TTA中防止遗忘的另一种常见方法是通过限制重要参数的更新，从而避免引入新的参数。Tent [[161](#bib.bib161)] 主要通过仅更新网络中的BatchNorm层来保持以前的知识。另一方面，CoTTA
    [[168](#bib.bib168)] 提出了不同的策略。在适应过程的每次迭代中，CoTTA 随机恢复某些神经元的权重到原始在源领域中训练的权重。这种恢复机制有助于保留从源领域获得的知识，防止在适应目标领域过程中被遗忘。TTA中的其他方法采用类似于传统CL中常用的正则化方法的技术。这些方法在适应过程中对被认为对源数据重要的参数更新施加惩罚
    [[171](#bib.bib171), [162](#bib.bib162), [172](#bib.bib172)]。例如，EATA [[162](#bib.bib162)]
    通过计算Fisher信息矩阵来评估重要性，并利用这一度量在适应过程中更新参数时作为惩罚。
- en: 6 Forgetting in Meta-Learning
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 元学习中的遗忘
- en: Meta-learning, also known as learning to learn, focuses on developing algorithms
    and models that can learn from previous learning experiences to improve their
    ability to learn new tasks or adapt to new domains more efficiently and effectively.
    In meta-learning, the goal is to enable a learning system, often referred to as
    the meta-learner or the meta-model, to acquire general knowledge or "meta-knowledge"
    from a set of related learning tasks or domains. This meta-knowledge is then leveraged
    to facilitate faster learning, better generalization, and improved adaptation
    to new, unseen tasks or domains.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 元学习，也称为学习如何学习，专注于开发能够从先前的学习经验中学习，以提高其学习新任务或适应新领域的能力的算法和模型。在元学习中，目标是使学习系统（通常称为元学习者或元模型）从一组相关的学习任务或领域中获取通用知识或“元知识”。然后，利用这些元知识来促进更快的学习、更好的泛化和对新任务或领域的更好适应。
- en: 'Formally, let’s consider a distribution of tasks, denoted as $P({\mathcal{T}})$.
    For a specific task ${\mathcal{T}}_{t}$, which consists of a training dataset
    ${\mathcal{D}}_{\text{train}}$ and a validation dataset ${\mathcal{D}}_{\text{val}}$,
    sampled from the task distribution $P({\mathcal{T}})$. The loss function for task
    ${\mathcal{T}}_{t}$ with meta-parameters ${\bm{\theta}}$ is defined as:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 从形式上讲，考虑一个任务分布，记作 $P({\mathcal{T}})$。对于特定任务 ${\mathcal{T}}_{t}$，它由从任务分布 $P({\mathcal{T}})$
    中抽样的训练数据集 ${\mathcal{D}}_{\text{train}}$ 和验证数据集 ${\mathcal{D}}_{\text{val}}$ 组成。任务
    ${\mathcal{T}}_{t}$ 的损失函数与元参数 ${\bm{\theta}}$ 定义如下：
- en: '|  | $\small{\mathcal{L}}({\mathcal{T}}_{t})=\log P({\mathcal{D}}_{\text{val}}&#124;{\mathcal{D}}_{\text{train}};{\bm{\theta}}).$
    |  | (4) |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '|  | $\small{\mathcal{L}}({\mathcal{T}}_{t})=\log P({\mathcal{D}}_{\text{val}}|{\mathcal{D}}_{\text{train}};{\bm{\theta}}).$
    |  | (4) |'
- en: 'The objective of meta-learning is to optimize the meta loss function, given
    by:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 元学习的目标是优化元损失函数，定义如下：
- en: '|  | $\small\min_{{\bm{\theta}}}\mathbb{E}_{{\mathcal{T}}_{t}\sim P({\mathcal{T}})}{\mathcal{L}}({\mathcal{T}}_{t}).$
    |  | (5) |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|  | $\small\min_{{\bm{\theta}}}\mathbb{E}_{{\mathcal{T}}_{t}\sim P({\mathcal{T}})}{\mathcal{L}}({\mathcal{T}}_{t}).$
    |  | (5) |'
- en: In other words, the aim is to find the optimal meta-parameters ${\bm{\theta}}$
    that minimize the expected loss across tasks, where tasks are sampled from the
    task distribution $P({\mathcal{T}})$.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，目标是找到最优的元参数 ${\bm{\theta}}$，以最小化在任务间的期望损失，其中任务是从任务分布 $P({\mathcal{T}})$
    中抽样的。
- en: However, forgetting can still occur in the context of meta-learning, and it
    can be classified into two distinct research directions. The first research direction
    focuses on Incremental Few-Shot Learning (IFSL), where the objective is to meta-learn
    new classes in addition to the pre-trained base classes. In this scenario, forgetting
    arises from the loss of information related to the pre-trained base classes. The
    challenge lies in retaining the knowledge of both the base classes and the newly
    introduced classes during the learning process. The second research direction
    deals with Continual Meta-Learning, where the agent encounters non-stationary
    task distributions over time while learning new tasks. Unlike IFSL, the goal here
    is not to remember the specific base classes. Instead, the objective is to retain
    the meta-knowledge acquired from previous task distributions. We will present
    the details of each direction in the following.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在元学习的背景下，仍然可能发生遗忘，这可以被分为两个不同的研究方向。第一个研究方向集中于增量式少样本学习（IFSL），其目标是除了预训练的基础类别外，还要元学习新类别。在这种情况下，遗忘来源于与预训练基础类别相关的信息丧失。挑战在于在学习过程中保留基础类别和新引入类别的知识。第二个研究方向处理持续性元学习，其中代理在学习新任务的同时遇到非平稳的任务分布。与IFSL不同，此处的目标不是记住特定的基础类别，而是保留从以前任务分布中获得的元知识。我们将在下面详细介绍每个方向。
- en: 6.1 Incremental Few-Shot Learning
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 增量式少样本学习
- en: Incremental few-shot learning (IFSL) [[173](#bib.bib173), [174](#bib.bib174)]
    focuses on the challenge of learning new categories with limited labeled data
    while retaining knowledge about previously learned categories. In this scenario,
    a standard classification network has previously undergone training to recognize
    a predefined set of base classes. After that, the focus is on incorporating additional
    novel classes, each accompanied by only a small number of labeled examples. Subsequently,
    the model is tested on its classification performance, considering both the base
    and novel classes.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 增量式少样本学习（IFSL）[[173](#bib.bib173), [174](#bib.bib174)] 专注于在保留对先前学习类别的知识的同时，用有限的标记数据学习新类别。在这种情况下，标准分类网络已经经过训练，以识别预定义的一组基础类别。之后，重点是纳入额外的新类别，每个类别仅附带少量标记示例。随后，模型会在基础类别和新类别上进行分类性能测试。
- en: 'Existing Works: Gidaris et al. [[173](#bib.bib173)] propose the IFSL problem
    and an attention-based solution to mitigate the forgetting in IFSL. The Attention
    Attractor Network, proposed by Ren et al. [[174](#bib.bib174)], is an alternative
    approach where the per-episode training objective during the incremental meta-learning
    stage is regulated using an attention mechanism to attend the set of base classes.
    In contrast to previous approaches that extract a fixed representation for each
    task, XtarNet [[175](#bib.bib175)] emphasizes the extraction of task-adaptive
    representations by combining novel and base features to enhance the adaptability
    of the representations. Shi et al. [[176](#bib.bib176)] suggest putting more effort
    into the base classifier pretraining stage rather than the later few-shot learning
    stage. As a result, they propose to seek flat local minima of the base classifier
    training objective function and subsequently fine-tune the model parameters within
    that flat region when faced with new tasks. In addition, C-FSCIL [[106](#bib.bib106)]
    incorporates a trainable fixed-size fully connected layer and a rewritable dynamically
    growing memory buffer to mitigate forgetting. This memory buffer can store a vector
    for each class encountered up to that point in the learning process.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现有研究：Gidaris 等人 [[173](#bib.bib173)] 提出了 IFSL 问题以及一种基于注意力的解决方案，以减轻 IFSL 中的遗忘。Ren
    等人 [[174](#bib.bib174)] 提出的注意力吸引网络是一种替代方法，其中在增量元学习阶段，每个训练目标通过注意力机制进行调整，以关注基础类别的集合。与之前的方法不同，XtarNet
    [[175](#bib.bib175)] 强调通过结合新颖特征和基础特征来提取任务自适应表示，从而增强表示的适应性。Shi 等人 [[176](#bib.bib176)]
    建议在基础分类器的预训练阶段投入更多精力，而不是在后续的少样本学习阶段。因此，他们建议在面对新任务时，寻找基础分类器训练目标函数的平坦局部最小值，并在该平坦区域内微调模型参数。此外，C-FSCIL
    [[106](#bib.bib106)] 结合了一个可训练的固定大小全连接层和一个可重写的动态增长记忆缓冲区，以减轻遗忘。这个记忆缓冲区可以存储学习过程中遇到的每个类别的向量。
- en: 6.2 Continual Meta-Learning
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 持续元学习
- en: The goal of continual meta-learning (CML) is to address the challenge of forgetting
    in non-stationary task distributions. Traditional meta-learning approaches typically
    focus on a single task distribution. However, CML extends this concept to handle
    a sequence of task distributions, denoted as $P_{1}({\mathcal{T}}),P_{2}({\mathcal{T}}),\cdots,P_{N}({\mathcal{T}})$.
    In CML, the objective is to develop meta-learning algorithms that can effectively
    adapt and generalize to new task distributions as they arise over time. These
    task distributions can represent different environments, domains, or contexts.
    It aims to mitigate the forgetting of previously learned task distributions while
    efficiently adapting to new tasks.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 持续元学习（CML）的目标是解决在非静态任务分布中遗忘的问题。传统的元学习方法通常集中于单一任务分布。然而，CML 扩展了这一概念，以处理任务分布的序列，表示为
    $P_{1}({\mathcal{T}}),P_{2}({\mathcal{T}}),\cdots,P_{N}({\mathcal{T}})$。在 CML
    中，目标是开发能够有效适应和推广到新任务分布的元学习算法。这些任务分布可以代表不同的环境、领域或上下文。其目的是在有效适应新任务的同时，减轻对先前学习的任务分布的遗忘。
- en: 'Existing Works: Online meta-learning (OML) [[177](#bib.bib177)] is a framework
    that assumes tasks arrive sequentially and aims to improve performance on future
    tasks. Jerfel et al. [[178](#bib.bib178)] extended the Model-Agnostic Meta-Learning
    [[179](#bib.bib179)] approach and utilized Dirichlet process mixtures to group
    similar training tasks together. However, this method is not scalable to large-scale
    non-stationary distributions due to the requirement of independent parameters
    for each component. Yap et al. [[180](#bib.bib180)] proposed an approach to model
    the posterior distribution of meta-parameters using Laplace approximation [[64](#bib.bib64)].
    Zhang et al. [[181](#bib.bib181)] further extended this framework by employing
    a dynamical mixture model to learn the distribution of meta-parameters instead
    of a single distribution. Additionally, they used structural variational inference
    techniques to infer latent variables in the model. Wang et al. [[182](#bib.bib182),
    [183](#bib.bib183), [184](#bib.bib184)] introduced a large-scale benchmark for
    sequential domain meta-learning. They proposed different settings, including supervised
    learning, imbalanced domains, and semi-supervised settings, to evaluate the performance
    of various methods in sequential domain meta-learning.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现有工作：在线元学习（OML） [[177](#bib.bib177)] 是一个假设任务按顺序到达并旨在提高未来任务性能的框架。Jerfel 等人 [[178](#bib.bib178)]
    扩展了模型无关元学习 [[179](#bib.bib179)] 方法，并利用 Dirichlet 过程混合来将相似的训练任务分组。然而，由于每个组件需要独立的参数，这种方法在大规模非平稳分布中不可扩展。Yap
    等人 [[180](#bib.bib180)] 提出了使用拉普拉斯近似 [[64](#bib.bib64)] 建模元参数后验分布的方法。Zhang 等人 [[181](#bib.bib181)]
    通过采用动态混合模型进一步扩展了该框架，以学习元参数的分布，而不是单一分布。此外，他们还使用结构变分推断技术来推断模型中的潜在变量。Wang 等人 [[182](#bib.bib182),
    [183](#bib.bib183), [184](#bib.bib184)] 引入了一个大规模的顺序领域元学习基准。他们提出了包括监督学习、不平衡领域和半监督设置在内的不同设置，以评估各种方法在顺序领域元学习中的性能。
- en: 7 Forgetting in Generative Model
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 生成模型中的遗忘
- en: 'The goal of a generative model is to learn a generator that can generate samples
    from a target distribution. In the context of generative models, research related
    to forgetting can be categorized into two main categories: (1) GAN training itself
    can be viewed as CL; (2) lifelong learning generative model on non-stationary
    distributions.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型的目标是学习一个可以从目标分布中生成样本的生成器。在生成模型的背景下，与遗忘相关的研究可以分为两个主要类别：（1）GAN 训练本身可以被视为 CL；（2）在非平稳分布上进行终身学习的生成模型。
- en: 7.1 GAN Training is a Continual Learning Problem
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 GAN 训练是一个持续学习问题
- en: Thanh-Tung et al. [[185](#bib.bib185)] approach GAN training as a CL problem.
    They consider the discriminator as learning a sequence of tasks, with each task
    representing the data distribution generated by a specific generator. To address
    the issue of catastrophic forgetting, they propose the use of momentum or gradient
    penalties on the discriminator. By incorporating these techniques, they aim to
    prevent forgetting of previously learned tasks, leading to improved convergence
    and reduced mode collapse in GAN training. Similarly, Liang et al. [[186](#bib.bib186)]
    adopt Elastic Weight Consolidation (EWC) [[47](#bib.bib47)] or Synaptic Intelligence
    (SI) [[48](#bib.bib48)] to mitigate forgetting in the discriminator during GAN
    training.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Thanh-Tung 等人 [[185](#bib.bib185)] 将 GAN 训练视为 CL 问题。他们认为判别器在学习一系列任务，每个任务代表由特定生成器生成的数据分布。为了应对灾难性遗忘的问题，他们建议在判别器上使用动量或梯度惩罚。通过结合这些技术，他们旨在防止遗忘以前学习的任务，从而改善收敛性并减少
    GAN 训练中的模式崩溃。类似地，Liang 等人 [[186](#bib.bib186)] 采用弹性权重巩固（EWC） [[47](#bib.bib47)]
    或突触智能（SI） [[48](#bib.bib48)] 来缓解 GAN 训练过程中判别器的遗忘。
- en: One application of viewing GAN training as CL is in the context of data-free
    knowledge distillation (DFKD) [[187](#bib.bib187)]. DFKD aims to extract a compact
    student model from a pretrained teacher model when the original training data
    of the teacher model is unavailable. The basic approach in DFKD involves using
    a generative model to reconstruct or generate hard examples as input to the pretrained
    model, thereby distilling knowledge from the teacher model. However, forgetting
    poses a significant challenge in DFKD. Forgetting occurs in DFKD due to the non-stationary
    distribution of pseudo-samples generated by the pseudo-data generator, as the
    generator evolves over time. To mitigate this forgetting issue, Binici et al.
    [[188](#bib.bib188)] propose the use of a memory buffer that dynamically collects
    generated samples over time. By preserving past samples, the memory buffer helps
    to alleviate forgetting in DFKD. Binici et al. [[189](#bib.bib189)] utilize generative
    replay, which involves remembering previous data distributions, to further mitigate
    forgetting in DFKD. Another approach to address forgetting in DFKD is MAD [[190](#bib.bib190)]
    proposed by Do et al, which maintains an exponential moving average of the generator,
    preventing drastic changes in the generated data distribution and preserving previous
    knowledge. Patel et al. [[191](#bib.bib191)] propose a meta-learning-inspired
    framework to tackle the forgetting issue in DFKD.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 视GAN训练为CL的一种应用是在无数据知识蒸馏（DFKD）的背景下[[187](#bib.bib187)]。DFKD旨在从预训练的教师模型中提取一个紧凑的学生模型，当教师模型的原始训练数据不可用时。DFKD的基本方法涉及使用生成模型重建或生成难例作为预训练模型的输入，从而从教师模型中蒸馏知识。然而，遗忘在DFKD中构成了一个重大挑战。由于伪数据生成器生成的伪样本的非平稳分布，遗忘在DFKD中发生，因为生成器随时间演变。为缓解这个遗忘问题，Binici等人[[188](#bib.bib188)]提出使用一个内存缓冲区，动态收集生成的样本。通过保存过去的样本，内存缓冲区有助于减轻DFKD中的遗忘。Binici等人[[189](#bib.bib189)]利用生成重放，通过记住先前的数据分布，进一步减轻DFKD中的遗忘。另一种解决DFKD中遗忘问题的方法是Do等人提出的MAD
    [[190](#bib.bib190)]，它维护生成器的指数移动平均，防止生成的数据分布发生剧烈变化，保留以前的知识。Patel等人[[191](#bib.bib191)]提出了一种受元学习启发的框架，以解决DFKD中的遗忘问题。
- en: 7.2 Lifelong Learning of Generative Models
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 生成模型的终身学习
- en: Lifelong learning of generative models seeks to enable generative models to
    generate data for new tasks while preserving the ability to generate data for
    previously learned tasks without forgetting. The goal is to develop generative
    models that can continually generate high-quality samples for both new and previously
    encountered tasks. The proposed approaches in lifelong learning of generative
    models encompass both Generative Adversarial Networks (GAN)-based and Variational
    Autoencoders (VAE)-based methods.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型的终身学习旨在使生成模型能够为新任务生成数据，同时保留生成以前学过的任务数据的能力，避免遗忘。目标是开发能够持续生成高质量样本的生成模型，适用于新任务和以前遇到的任务。终身学习生成模型的方法包括基于生成对抗网络（GAN）和基于变分自编码器（VAE）的方法。
- en: In the realm of GAN-based approaches, Zhai et al. [[192](#bib.bib192), [193](#bib.bib193)]
    have proposed lifelong GAN, which allows for conditioned image generation while
    avoiding the problem of forgetting previously acquired knowledge. In the context
    of VAE-based approaches, Ramapuram et al. [[194](#bib.bib194)] introduce a teacher-student
    architecture. Furthermore, Ye et al. propose network expansion [[195](#bib.bib195)]
    and dynamic optimal transport formulation [[196](#bib.bib196)] to address the
    continual VAE.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于GAN的方法领域，Zhai等人[[192](#bib.bib192), [193](#bib.bib193)]提出了终身GAN，它允许条件图像生成，同时避免遗忘以前获得的知识。在基于VAE的方法中，Ramapuram等人[[194](#bib.bib194)]引入了教师-学生架构。此外，Ye等人提出了网络扩展[[195](#bib.bib195)]和动态最优传输公式[[196](#bib.bib196)]来解决持续的VAE。
- en: 'Intentional Forgetting in Diffusion Model: The advancement of text-to-image
    diffusion models [[197](#bib.bib197), [198](#bib.bib198)] has sparked significant
    concerns regarding data privacy, copyright infringement, and safety related to
    generative models, primarily because of the memorization effect observed in large
    generative models. This effect leads to the learning and generation of unauthorized
    and potentially harmful content, contributing to the creation and dissemination
    of unregulated material. To address these concerns, the Forget-Me-Not approach
    [[199](#bib.bib199)] and Selective Amnesia (SA) [[200](#bib.bib200)] have emerged,
    aiming to mitigate the presence of potentially harmful or unauthorized content.
    These approaches achieve this by leveraging forgetting mechanisms to eliminate
    unwanted information, thereby promoting diversity in generated outputs and protecting
    data privacy.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 扩散模型中的有意遗忘：文本到图像扩散模型的进展[[197](#bib.bib197), [198](#bib.bib198)]引发了对数据隐私、版权侵犯以及与生成模型相关的安全性的重大关注，主要是由于在大型生成模型中观察到的记忆效应。这种效应导致了对未经授权和潜在有害内容的学习和生成，从而促进了不受监管材料的创建和传播。为了解决这些问题，提出了“遗忘我”方法[[199](#bib.bib199)]和选择性遗忘（SA）[[200](#bib.bib200)]，旨在减少潜在有害或未经授权内容的存在。这些方法通过利用遗忘机制来消除不需要的信息，从而促进生成输出的多样性，并保护数据隐私。
- en: 8 Forgetting in Reinforcement Learning
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 强化学习中的遗忘
- en: While most existing CL methods primarily tackle the issue of forgetting in image
    classification, it is important to note that forgetting also widely occurs in
    reinforcement learning (RL), known as continual RL. Addressing catastrophic forgetting
    in RL is vital for the advancement of intelligent agents that can continuously
    learn and adapt to new tasks and environments [[201](#bib.bib201)].
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然大多数现有的持续学习（CL）方法主要解决图像分类中的遗忘问题，但值得注意的是，遗忘在强化学习（RL）中也广泛发生，这被称为持续强化学习。解决RL中的灾难性遗忘对于智能体能够持续学习并适应新任务和环境至关重要[[201](#bib.bib201)]。
- en: Standard RL formulation could be defined as the following. We denote ${\mathcal{S}}$
    as the state space, ${\mathcal{A}}$ as the action space, and a reward function
    is $r:{\mathcal{S}}\times{\mathcal{A}}\rightarrow R$. At each time step $t$, the
    agent sample action from a policy function which output the optimal action or
    the distributions over the action space. The deterministic policy takes the current
    state $s$ as input, and outputs the action according to $a_{t}=\mu(s_{t})$. A
    stochastic policy takes the state $s_{t}$ as input, outputs the optimal action
    distribution according to $a_{t}\sim\pi(\cdot|s_{t})$. Then, the state transition
    function takes the state $s_{t}$ and $a_{t}$ as input and outputs the next action
    either deterministically $s_{t+1}=f(s_{t},a_{t})$ or stochastically $s_{t+1}\sim
    p(\cdot|s_{t},a_{t})$. The goal of RL agent is to accumulate as much reward as
    possible.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的强化学习公式可以定义如下。我们将${\mathcal{S}}$表示为状态空间，将${\mathcal{A}}$表示为动作空间，奖励函数为$r:{\mathcal{S}}\times{\mathcal{A}}\rightarrow
    R$。在每个时间步骤$t$，智能体从策略函数中采样动作，该函数输出最佳动作或动作空间的分布。确定性策略以当前状态$s$作为输入，并根据$a_{t}=\mu(s_{t})$输出动作。随机策略以状态$s_{t}$作为输入，根据$a_{t}\sim\pi(\cdot|s_{t})$输出最佳动作分布。然后，状态转换函数将状态$s_{t}$和$a_{t}$作为输入，并以确定性$s_{t+1}=f(s_{t},a_{t})$或随机性$s_{t+1}\sim
    p(\cdot|s_{t},a_{t})$输出下一个状态。RL智能体的目标是尽可能多地累积奖励。
- en: 'Following [[201](#bib.bib201)], the general continual RL can be formulated
    as the following:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[[201](#bib.bib201)]，一般的持续强化学习可以被表述为以下形式：
- en: Definition 8.1
  id: totrans-164
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 8.1
- en: '(General Continual RL): Given a state space ${\mathcal{S}}$, action space ${\mathcal{A}}$
    and observation space ${\mathcal{O}}$. A reward function is $r:{\mathcal{S}}\times{\mathcal{A}}\rightarrow
    R$; A transition function is $p:{\mathcal{S}}\times{\mathcal{A}}\rightarrow{\mathcal{S}}$;
    An observation function is $x:{\mathcal{S}}\rightarrow{\mathcal{O}}$. The general
    continual RL can be formulated as'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: （一般的持续强化学习）：给定一个状态空间${\mathcal{S}}$、动作空间${\mathcal{A}}$和观察空间${\mathcal{O}}$。一个奖励函数是$r:{\mathcal{S}}\times{\mathcal{A}}\rightarrow
    R$；一个转换函数是$p:{\mathcal{S}}\times{\mathcal{A}}\rightarrow{\mathcal{S}}$；一个观察函数是$x:{\mathcal{S}}\rightarrow{\mathcal{O}}$。一般的持续强化学习可以被表述为
- en: '|  | $\small{\mathcal{M}}\overset{def}{=}\langle{\mathcal{S}}(t),{\mathcal{A}}(t),r(t),p(t),x(t),{\mathcal{O}}(t)\rangle.$
    |  | (6) |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '|  | $\small{\mathcal{M}}\overset{def}{=}\langle{\mathcal{S}}(t),{\mathcal{A}}(t),r(t),p(t),x(t),{\mathcal{O}}(t)\rangle.$
    |  | (6) |'
- en: Definition [8.1](#S8.Thmtheorem1 "Definition 8.1 ‣ 8 Forgetting in Reinforcement
    Learning ‣ A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual
    Learning") highlights that in continual RL, various components such as the state,
    action, reward, observation, and more, undergo changes over time. This emphasizes
    the dynamic nature of the RL process in continual settings.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 [8.1](#S8.Thmtheorem1 "Definition 8.1 ‣ 8 Forgetting in Reinforcement Learning
    ‣ A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning")
    强调了在持续强化学习（RL）中，状态、行动、奖励、观察等各种组件随时间发生变化。这强调了持续设置中RL过程的动态性质。
- en: 'Continual RL approach. The existing continual RL methods can be categorized
    into four main groups: (1) regularization-based methods. These approaches employ
    techniques such as knowledge distillation to alleviate forgetting [[202](#bib.bib202)],
    (2) rehearsal-based methods. These methods utilize rehearsal or experience replay
    to mitigate forgetting [[203](#bib.bib203)], (3) architecture-based methods. These
    approaches focus on learning a shared structure, such as network modularity or
    composition, to facilitate continual learning [[204](#bib.bib204)] and (4) meta-learning-based
    methods [[179](#bib.bib179)].'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 持续强化学习方法。现有的持续强化学习方法可以分为四大类：（1）基于正则化的方法。这些方法采用诸如知识蒸馏等技术来减轻遗忘[[202](#bib.bib202)]，（2）基于重演的方法。这些方法利用重演或经验回放来缓解遗忘[[203](#bib.bib203)]，（3）基于架构的方法。这些方法专注于学习共享结构，如网络模块化或组合，以促进持续学习[[204](#bib.bib204)]，（4）基于元学习的方法[[179](#bib.bib179)]。
- en: 9 Forgetting in Federated Learning
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 联邦学习中的遗忘问题
- en: Federated learning (FL) is a decentralized machine learning approach where the
    training process takes place on local devices or edge servers instead of a centralized
    server. In federated learning, instead of sending raw data to a central server,
    the model is distributed to multiple client devices or servers. Each client device
    performs training on its local data, and only the model updates are sent back
    to the central server. The central server aggregates these updates from multiple
    clients to update the global model. This collaborative learning process enables
    privacy preservation as the raw data remains on the local devices, reducing the
    risks associated with data sharing.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习（FL）是一种去中心化的机器学习方法，其中训练过程发生在本地设备或边缘服务器上，而不是中心化服务器。在联邦学习中，模型被分发到多个客户端设备或服务器，而不是将原始数据发送到中心服务器。每个客户端设备在其本地数据上进行训练，仅将模型更新发送回中心服务器。中心服务器将这些来自多个客户端的更新聚合，以更新全球模型。这种协作学习过程可以保护隐私，因为原始数据保持在本地设备上，从而减少了数据共享相关的风险。
- en: We can classify the forgetting issue in federated learning (FL) into two branches.
    The first branch pertains to the forgetting problem caused by the inherent non-IID
    (not identically and independently distributed) data among different clients participating
    in FL. In this scenario, each client’s data distribution may vary significantly,
    leading to challenges in preserving previously learned knowledge when aggregating
    model updates from multiple clients. The second branch addresses the issue of
    continual learning within each individual client in the federated learning process,
    which results in forgetting at the overall FL level. This branch is referred to
    as federated continual learning (FCL) [[205](#bib.bib205)]. FCL involves the continual
    learning and adaptation of models on each client while participating in federated
    learning, potentially leading to forgetting of previously learned knowledge at
    the global FL level. We will provide a detailed explanation for each research
    direction in the following.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将联邦学习（FL）中的遗忘问题分为两个分支。第一个分支涉及由于参与FL的不同客户端之间固有的非IID（非独立同分布）数据导致的遗忘问题。在这种情况下，每个客户端的数据分布可能会显著不同，从而在从多个客户端聚合模型更新时面临保留先前学习知识的挑战。第二个分支则解决了联邦学习过程中每个客户端的持续学习问题，这导致了整体FL水平上的遗忘。这个分支被称为联邦持续学习（FCL）[[205](#bib.bib205)]。FCL涉及在参与联邦学习的过程中对每个客户端的模型进行持续学习和适应，可能导致在全球FL水平上遗忘先前学习的知识。我们将在接下来的内容中对每个研究方向进行详细解释。
- en: 9.1 Forgetting Due to Non-IID Data in FL
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1 由于非IID数据引起的遗忘问题
- en: The problem of client drift [[206](#bib.bib206)] in federated learning pertains
    to the scenario where there is a substantial variation in the data distribution
    across individual clients. In federated learning, each client conducts local training
    using its own data, and subsequently, the model updates are aggregated to construct
    a global model. However, when there are significant variations in the data distribution
    among clients, it leads to each client updating its model in different directions,
    ultimately resulting in a drift among the client models. This drift can lead to
    performance degradation or instability in the global model. In other words, forgetting
    in federated learning occurs during the model averaging process on the server
    side and is primarily driven by the inconsistency of models among clients [[12](#bib.bib12)].
    This inconsistency arises due to the presence of heterogeneous data distributions
    across clients.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习中的客户端漂移问题[[206](#bib.bib206)]涉及数据分布在各个客户端之间存在显著差异的情况。在联邦学习中，每个客户端使用自己的数据进行本地训练，随后将模型更新聚合以构建全球模型。然而，当客户端之间的数据分布存在显著差异时，会导致每个客户端以不同的方向更新其模型，最终导致客户端模型之间的漂移。这种漂移可能导致全球模型性能下降或不稳定。换句话说，联邦学习中的遗忘发生在服务器端的模型平均过程中，并主要由客户端模型之间的不一致性驱动[[12](#bib.bib12)]。这种不一致性源于客户端之间存在异质数据分布。
- en: Shoham et al. [[207](#bib.bib207)] provide an interpretation of the client drift
    issue in FL by relating it to the concept of forgetting in continual learning.
    They propose a regularization-based approach specifically designed to address
    client drift in federated learning settings, particularly in the non-IID data
    setting. Their method aims to mitigate the effects of forgetting and preserve
    previously learned knowledge during the training process in federated learning.
    Subsequently, multiple methods have been proposed to alleviate the issue of forgetting
    by integrating penalty or regularization terms that account for client model shifts
     [[208](#bib.bib208), [209](#bib.bib209), [210](#bib.bib210)]. FCCL [[208](#bib.bib208)]
    utilizes two teachers, the optimal model pre-trained on the client’s private data
    and the model after the server’s collaborative update, and applies knowledge distillation
    to constrain the client model update, thereby alleviating forgetting. FedReg [[209](#bib.bib209)]
    addresses forgetting by using generated pseudo data to regularize the parameter
    update during client training, noting that solving forgetting in federated learning
    can enhance the convergence speed of the algorithm. FedNTD [[210](#bib.bib210)]
    employs knowledge distillation to mitigate knowledge forgetting, but focuses only
    on distilling mispredicted classes while disregarding well-predicted ones. Additionally,
    inspired by the GEM [[14](#bib.bib14)] and OGD [[57](#bib.bib57)], GradMA [[211](#bib.bib211)]
    employs gradient information from the previous local model and the centralized
    model to restrict the gradient direction of the local model update. By rethinking
    the design of the models used in federated learning, Qu et al. [[212](#bib.bib212)]
    propose architectural strategies to mitigate forgetting and improve the overall
    performance and stability of federated learning systems.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Shoham等人[[207](#bib.bib207)]通过将客户端漂移问题与持续学习中的遗忘概念相关联，提供了对FL中客户端漂移问题的解释。他们提出了一种基于正则化的方法，专门设计用于解决联邦学习设置中的客户端漂移问题，特别是在非IID数据设置中。他们的方法旨在减轻遗忘的影响，并在联邦学习的训练过程中保持先前学习的知识。随后，提出了多种方法，通过整合惩罚或正则化项来缓解遗忘问题，这些方法考虑了客户端模型的偏移[[208](#bib.bib208)、[209](#bib.bib209)、[210](#bib.bib210)]。FCCL
    [[208](#bib.bib208)]利用两个教师，即在客户端私有数据上预训练的最优模型和服务器协作更新后的模型，并应用知识蒸馏来约束客户端模型的更新，从而减轻遗忘。FedReg
    [[209](#bib.bib209)]通过使用生成的伪数据来正则化客户端训练中的参数更新来解决遗忘问题，指出解决联邦学习中的遗忘可以提高算法的收敛速度。FedNTD
    [[210](#bib.bib210)]采用知识蒸馏来减轻知识遗忘，但仅关注于蒸馏错误预测的类别，而忽略了预测准确的类别。此外，受GEM [[14](#bib.bib14)]
    和OGD [[57](#bib.bib57)]的启发，GradMA [[211](#bib.bib211)]利用来自先前本地模型和集中式模型的梯度信息来限制本地模型更新的梯度方向。通过重新思考联邦学习中使用的模型设计，Qu等人[[212](#bib.bib212)]提出了建筑策略，以减轻遗忘并提高联邦学习系统的整体性能和稳定性。
- en: 9.2 Federated Continual Learning
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2 联邦持续学习
- en: In traditional federated learning, the focus is primarily on aggregating model
    updates from different clients without considering the long-term retention of
    knowledge across multiple training rounds. However, in scenarios where clients
    encounter non-stationary distribution, it becomes necessary to incorporate continual
    learning techniques to avoid catastrophic forgetting and retain knowledge from
    previous training rounds. In standard CL, an agent learns a sequence of tasks,
    denoted as ${{\mathcal{T}}_{1},\cdots,{\mathcal{T}}_{N}}$. However, in federated
    continual learning (FCL), each client learns its own private task sequence.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的联邦学习中，重点主要放在从不同客户端聚合模型更新，而没有考虑跨多个训练轮次的长期知识保留。然而，在客户端遇到非平稳分布的情况下，有必要结合持续学习技术，以避免灾难性遗忘并保留以前训练轮次的知识。在标准的CL中，代理学习一系列任务，表示为${{\mathcal{T}}_{1},\cdots,{\mathcal{T}}_{N}}$。然而，在联邦持续学习（FCL）中，每个客户端学习自己的私有任务序列。
- en: 'FCL is more complicated than traditional FL or CL because non-iid and catastrophic
    forgetting problems need to be solved simultaneously. FedWeIT [[205](#bib.bib205)]
    first formally introduced the FCL setting from the perspective of CL. Solving
    forgetting in FCL is very challenging due to two reasons: (1) non-stationary data
    distribution in each client; and (2) model average in the server. Existing methods
    of addressing forgetting can be divided into three classes. (1) Parameter Isolation
    Method [[205](#bib.bib205)]: FedWeIT [[205](#bib.bib205)] decomposes the parameters
    of each client into global and sparse local task adaptation parameters to reduce
    inter-client interference and thus alleviate forgetting. (2) Replay-based Method [[213](#bib.bib213),
    [214](#bib.bib214)]: inspired by traditional memory-based CL, some methods address
    the forgetting problem by replaying the client’s old data. (3) Knowledge Distillation
    Method [[215](#bib.bib215)]: CFeD [[215](#bib.bib215)] assumes that there is an
    unlabeled wild dataset in the clients and server. It proposes a distillation-based
    method that utilizes an unlabeled surrogate dataset to aggregate clients and avoids
    forgetting by rehearsing old data.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: FCL比传统的FL或CL更复杂，因为需要同时解决非独立同分布和灾难性遗忘问题。FedWeIT [[205](#bib.bib205)]首次从CL的角度正式介绍了FCL设置。解决FCL中的遗忘问题非常具有挑战性，原因有二：（1）每个客户端的数据分布非平稳；（2）服务器中的模型平均。现有的解决遗忘问题的方法可以分为三类：（1）参数隔离方法 [[205](#bib.bib205)]：FedWeIT [[205](#bib.bib205)]将每个客户端的参数分解为全局和稀疏的本地任务适应参数，以减少客户端之间的干扰，从而缓解遗忘。（2）基于重放的方法 [[213](#bib.bib213),
    [214](#bib.bib214)]：受传统基于记忆的CL启发，一些方法通过重放客户端的旧数据来解决遗忘问题。（3）知识蒸馏方法 [[215](#bib.bib215)]：CFeD [[215](#bib.bib215)]假设客户端和服务器中存在一个未标记的野外数据集。它提出了一种基于蒸馏的方法，利用未标记的代理数据集来聚合客户端，并通过复习旧数据来避免遗忘。
- en: 10 Beneficial Forgetting
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 有益的遗忘
- en: Forgetting is not always harmful; in fact, intentional forgetting can prove
    beneficial in many cases. In this section, we explore the concept of beneficial
    forgetting within various learning scenarios. We begin by discussing selective
    forgetting and its positive impact on mitigating overfitting, as outlined in Section
    [10.1](#S10.SS1 "10.1 Combat Overfitting Through Forgetting ‣ 10 Beneficial Forgetting
    ‣ A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning").
    Next, we highlight the importance of discarding old, irrelevant knowledge when
    acquiring new knowledge, which we explore in Section [10.2](#S10.SS2 "10.2 Learning
    New Knowledge Through Forgetting Previous Knowledge ‣ 10 Beneficial Forgetting
    ‣ A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning").
    Additionally, we delve into the field of machine unlearning in Section [10.3](#S10.SS3
    "10.3 Machine Unlearning ‣ 10 Beneficial Forgetting ‣ A Comprehensive Survey of
    Forgetting in Deep Learning Beyond Continual Learning"), which specifically focuses
    on the task of erasing private user data from pre-trained models. This area of
    research aims to address privacy concerns by effectively removing sensitive information
    from models that have been trained on user data. By discussing machine unlearning,
    we shed light on the techniques and strategies employed to achieve secure and
    privacy-preserving machine learning models.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 遗忘并不总是有害的；事实上，有意的遗忘在许多情况下可以证明是有益的。在本节中，我们探讨了在各种学习场景中有益遗忘的概念。我们首先讨论选择性遗忘及其在减轻过拟合方面的积极影响，如[10.1](#S10.SS1
    "10.1 Combat Overfitting Through Forgetting ‣ 10 Beneficial Forgetting ‣ A Comprehensive
    Survey of Forgetting in Deep Learning Beyond Continual Learning")节中所述。接下来，我们强调在获取新知识时丢弃旧的、不相关的知识的重要性，这在[10.2](#S10.SS2
    "10.2 Learning New Knowledge Through Forgetting Previous Knowledge ‣ 10 Beneficial
    Forgetting ‣ A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual
    Learning")节中探讨。此外，我们在[10.3](#S10.SS3 "10.3 Machine Unlearning ‣ 10 Beneficial
    Forgetting ‣ A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual
    Learning")节中深入探讨了机器遗忘领域，该领域专注于从预训练模型中删除私人用户数据。该研究领域旨在通过有效去除从用户数据中训练的模型中的敏感信息来解决隐私问题。通过讨论机器遗忘，我们揭示了实现安全且保护隐私的机器学习模型所采用的技术和策略。
- en: 10.1 Combat Overfitting Through Forgetting
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1 通过遗忘来应对过拟合
- en: Overfitting in neural networks occurs when the model excessively memorizes the
    training data, leading to poor generalization. To address overfitting, it is necessary
    to selectively forget irrelevant or noisy information [[216](#bib.bib216)]. One
    strategy to mitigate overfitting is selective forgetting, as proposed by Shibata
    et al. [[217](#bib.bib217)]. This approach involves identifying and discarding
    less relevant or noisy information from the training data, enabling the model
    to focus on the most important patterns and improve its ability to generalize
    to unseen data. Current methodologies, including techniques such as $l_{1}$ normalization,
    feature selection, and early stopping, can be considered as forms of selective
    forgetting. These methods play an important role in removing less informative
    components from the model’s memory. By applying $l_{1}$ normalization, the model’s
    parameters are encouraged to become sparse, effectively forgetting less relevant
    features. Feature selection techniques focus on identifying and retaining only
    the most informative features while discarding the rest. Additionally, early stopping
    halts the training process when the model’s performance on a validation set starts
    to deteriorate, preventing further memorization of noise or irrelevant patterns.
    Furthermore, Nikishin et al. [[218](#bib.bib218)] overcome the overfitting to
    early experiences in reinforcement learning by resetting the last few layers of
    the RL agent. All of these methods contribute to selective forgetting by discarding
    less informative components and promoting the retention of more relevant information
    in the model’s memory.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络中的过拟合发生在模型过度记忆训练数据，从而导致泛化性能差。为了解决过拟合问题，需要选择性地遗忘不相关或噪声信息 [[216](#bib.bib216)]。一种减轻过拟合的策略是选择性遗忘，如Shibata等人
    [[217](#bib.bib217)] 提出的。这种方法涉及识别并丢弃训练数据中不太相关或带有噪声的信息，使模型能够集中于最重要的模式，从而提高其对未见数据的泛化能力。当前的方法，包括如
    $l_{1}$ 归一化、特征选择和早停等技术，都可以视为选择性遗忘的形式。这些方法在从模型记忆中删除不太有信息量的组件方面发挥了重要作用。通过应用 $l_{1}$
    归一化，模型的参数被鼓励变得稀疏，从而有效地遗忘不相关的特征。特征选择技术则侧重于识别并保留最有信息量的特征，同时丢弃其余部分。此外，早停在模型在验证集上的性能开始恶化时停止训练，从而防止进一步记忆噪声或不相关的模式。此外，Nikishin等人
    [[218](#bib.bib218)] 通过重置RL代理的最后几层，克服了强化学习中对早期经验的过拟合。所有这些方法都有助于选择性遗忘，通过丢弃不太有信息量的组件并促进在模型记忆中保留更相关的信息。
- en: In the context of learning from noisy labeled data, the memorization and overfitting
    to noisy labeled data can detrimentally impact the model’s generalization performance.
    SIGUA [[219](#bib.bib219)] proposes a method to selectively forget the undesired
    memorization of noisy labeled data, reinforcing the desired memorization and improving
    the model’s overall performance.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在从带噪声标签数据中学习的背景下，对带噪声标签数据的记忆和过拟合可能会对模型的泛化性能产生不利影响。SIGUA [[219](#bib.bib219)]
    提出了一种选择性遗忘不需要的噪声标签数据记忆的方法，以增强所需的记忆并改善模型的整体性能。
- en: Adversarial forgetting, as described in the work by Jaiswal et al. [[220](#bib.bib220)],
    offers a mechanism to mitigate overfitting to unwanted and nuisance factors present
    in the training data. This approach involves selectively forgetting irrelevant
    information to promote the learning of invariant representations, thus reducing
    the impact of irrelevant factors on the model’s performance.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗遗忘，如Jaiswal等人 [[220](#bib.bib220)] 的研究所述，提供了一种机制来减轻对训练数据中存在的不必要和干扰因素的过拟合。这种方法涉及选择性遗忘不相关的信息，以促进对不变表示的学习，从而减少不相关因素对模型性能的影响。
- en: 10.2 Learning New Knowledge Through Forgetting Previous Knowledge
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2 通过遗忘先前知识学习新知识
- en: Numerous studies in psychology and neuroscience have revealed the interconnected
    nature of forgetting and learning [[221](#bib.bib221)]. In the field of machine
    learning, the Learn to Forget approach proposed by Baik et al. [[222](#bib.bib222)]
    highlights that not all prior knowledge acquired through meta-learning is beneficial
    for learning new tasks. They propose selectively forgetting certain aspects of
    prior knowledge to facilitate faster learning of new tasks. In a different line
    of research, Zhou et al. [[223](#bib.bib223)] introduce a forget-and-relearn paradigm.
    They show that adding a forgetting step can improve the generalization and effectiveness
    of model relearning. Another approach, Learning Not to Learn (LNL) [[224](#bib.bib224)],
    focuses on forgetting biased information. LNL aims to minimize the mutual information
    between feature embeddings and bias, thereby enhancing performance during test
    time by reducing the influence of biased or irrelevant information. Bevan et al.
    [[225](#bib.bib225)] leverage the concept of forgetting biased information for
    Melanoma Classification. They explore the idea of selectively forgetting certain
    biased information that might be present in the dataset to improve the accuracy
    and effectiveness of melanoma classification models. Chen et al. [[226](#bib.bib226)]
    delve into the learn-forget paradigm in the context of optimal task selection
    for meta-learning. Their research investigates how the selective learning and
    forgetting of tasks can contribute to achieving optimal task selection in meta-learning
    scenarios. Moreover, in the context of continual learning, Wang et al. [[227](#bib.bib227)]
    identify that when old knowledge interferes with the learning of new tasks, accurate
    preservation of the old knowledge can exacerbate the interference. To address
    this issue, they propose an active forgetting mechanism that selectively discards
    old knowledge that hinders the learning of new tasks. By doing so, they demonstrate
    the potential benefits of active forgetting in CL.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 心理学和神经科学的众多研究揭示了遗忘与学习之间的相互关联[[221](#bib.bib221)]。在机器学习领域，Baik等人提出的“学习遗忘”方法[[222](#bib.bib222)]强调，并非所有通过元学习获得的先前知识对学习新任务都是有益的。他们建议选择性地遗忘某些先前知识的方面，以促进新任务的更快学习。在另一条研究路线中，Zhou等人[[223](#bib.bib223)]引入了遗忘与重新学习的范式。他们展示了添加遗忘步骤可以提高模型重新学习的泛化性和有效性。另一种方法，学习不学习（LNL）[[224](#bib.bib224)]，集中于遗忘偏倚信息。LNL旨在最小化特征嵌入与偏倚之间的互信息，从而通过减少偏倚或无关信息的影响来提高测试时的表现。Bevan等人[[225](#bib.bib225)]利用遗忘偏倚信息的概念进行黑色素瘤分类。他们探讨了选择性遗忘数据集中可能存在的某些偏倚信息的想法，以提高黑色素瘤分类模型的准确性和有效性。Chen等人[[226](#bib.bib226)]深入研究了在元学习的最佳任务选择背景下的学习-遗忘范式。他们的研究调查了任务的选择性学习和遗忘如何有助于在元学习情境中实现最佳任务选择。此外，在持续学习的背景下，Wang等人[[227](#bib.bib227)]发现，当旧知识干扰新任务的学习时，准确保留旧知识可能会加剧这种干扰。为了解决这个问题，他们提出了一种主动遗忘机制，该机制选择性地丢弃阻碍新任务学习的旧知识。通过这样做，他们展示了主动遗忘在持续学习中的潜在好处。
- en: 10.3 Machine Unlearning
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3 机器遗忘
- en: 10.3.1 Problem Overview
  id: totrans-187
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 10.3.1 问题概述
- en: Machine unlearning [[13](#bib.bib13), [228](#bib.bib228), [229](#bib.bib229)],
    a recent area of research, addresses the need to forget previously learned training
    data in order to protect user data privacy and aligns with privacy regulations
    such as the European Union’s General Data Protection Regulation [[230](#bib.bib230)]
    and the Right to Be Forgotten [[10](#bib.bib10)]. These regulations require companies
    and organizations to provide users with the ability to remove their data under
    specific circumstances.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 机器遗忘[[13](#bib.bib13), [228](#bib.bib228), [229](#bib.bib229)]是一个近期的研究领域，旨在忘记先前学习的训练数据，以保护用户数据隐私，并符合如欧盟通用数据保护条例[[230](#bib.bib230)]和被遗忘权[[10](#bib.bib10)]等隐私法规。这些法规要求公司和组织在特定情况下为用户提供删除其数据的能力。
- en: 'Interestingly, machine unlearning demonstrates two distinct phenomena related
    to forgetting. On one hand, it involves forgetting specific training data memorized
    by the pre-trained model. The problem of machine unlearning can be categorized
    into two main types: exact unlearning and approximate unlearning. In Section [10.3.2](#S10.SS3.SSS2
    "10.3.2 Exact Unlearning ‣ 10.3 Machine Unlearning ‣ 10 Beneficial Forgetting
    ‣ A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"),
    we will delve into the details of exact unlearning, while in Section [10.3.3](#S10.SS3.SSS3
    "10.3.3 Approximate Unlearning ‣ 10.3 Machine Unlearning ‣ 10 Beneficial Forgetting
    ‣ A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"),
    we will focus on the concept of approximate unlearning. On the other hand, machine
    unlearning can lead to catastrophic forgetting of knowledge on data other than
    the targeted forgotten training set. The gradual updating of the pre-trained model
    to achieve unlearning is responsible for this second type of forgetting. In Section
    [10.3.4](#S10.SS3.SSS4 "10.3.4 Catastrophic Forgetting Other Normal Examples ‣
    10.3 Machine Unlearning ‣ 10 Beneficial Forgetting ‣ A Comprehensive Survey of
    Forgetting in Deep Learning Beyond Continual Learning"), we will provide a comprehensive
    exploration of catastrophic forgetting in machine unlearning and its implications.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，机器遗忘展示了与遗忘相关的两种不同现象。一方面，它涉及到预训练模型记忆的特定训练数据的遗忘。机器遗忘问题可以分为两大类：精确遗忘和近似遗忘。在[10.3.2](#S10.SS3.SSS2
    "10.3.2 精确遗忘 ‣ 10.3 机器遗忘 ‣ 10 有益的遗忘 ‣ 深度学习中超越持续学习的遗忘全面调查")部分，我们将详细探讨精确遗忘的细节，而在[10.3.3](#S10.SS3.SSS3
    "10.3.3 近似遗忘 ‣ 10.3 机器遗忘 ‣ 10 有益的遗忘 ‣ 深度学习中超越持续学习的遗忘全面调查")部分，我们将重点讨论近似遗忘的概念。另一方面，机器遗忘可能导致对目标遗忘训练集以外的数据知识的灾难性遗忘。逐步更新预训练模型以实现遗忘是导致这种第二种遗忘的原因。在[10.3.4](#S10.SS3.SSS4
    "10.3.4 灾难性遗忘其他正常示例 ‣ 10.3 机器遗忘 ‣ 10 有益的遗忘 ‣ 深度学习中超越持续学习的遗忘全面调查")部分，我们将全面探讨机器遗忘中的灾难性遗忘及其影响。
- en: 10.3.2 Exact Unlearning
  id: totrans-190
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 10.3.2 精确遗忘
- en: Exact unlearning refers to the scenario where the distribution of the model
    obtained by training on the remaining dataset is identical to the distribution
    of the unlearned model. Let $P({\mathbb{A}}({\mathcal{D}}))$ denote the model
    distribution trained on dataset ${\mathcal{D}}$ with algorithm ${\mathbb{A}}$.
    Let ${\mathcal{F}}$ denote the dataset to be removed in the pre-trained model.
    $P({\mathbb{A}}({\mathcal{D}}\backslash{\mathcal{F}}))$ denote the model distribution
    by training on the remaining dataset ${\mathcal{D}}\backslash{\mathcal{F}}$. $P({\mathcal{U}}({\mathcal{D}},{\mathcal{F}},{\mathbb{A}}({\mathcal{D}})))$
    denote the unlearned model distribution. This concept can be defined as follows.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 精确遗忘指的是这样一种情形：通过在剩余数据集上训练得到的模型分布与未遗忘模型的分布完全相同。令 $P({\mathbb{A}}({\mathcal{D}}))$
    表示使用算法 ${\mathbb{A}}$ 在数据集 ${\mathcal{D}}$ 上训练得到的模型分布。令 ${\mathcal{F}}$ 表示在预训练模型中需要移除的数据集。$P({\mathbb{A}}({\mathcal{D}}\backslash{\mathcal{F}}))$
    表示在剩余数据集 ${\mathcal{D}}\backslash{\mathcal{F}}$ 上训练得到的模型分布。$P({\mathcal{U}}({\mathcal{D}},{\mathcal{F}},{\mathbb{A}}({\mathcal{D}})))$
    表示遗忘后的模型分布。这个概念可以定义如下。
- en: Definition 10.1 (exact unlearning)
  id: totrans-192
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 10.1（精确遗忘）
- en: 'For a learning algorithm ${\mathbb{A}}$, a dataset ${\mathcal{D}}$ and a dataset
    ${\mathcal{F}}$ to be forgotten, the exact unlearning ${\mathcal{U}}$ can be defined
    as following:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 对于学习算法 ${\mathbb{A}}$、数据集 ${\mathcal{D}}$ 和要遗忘的数据集 ${\mathcal{F}}$，精确遗忘 ${\mathcal{U}}$
    可以定义如下：
- en: '|  | $\small P({\mathbb{A}}({\mathcal{D}}\backslash{\mathcal{F}}))=P({\mathcal{U}}({\mathcal{D}},{\mathcal{F}},{\mathbb{A}}({\mathcal{D}}))).$
    |  | (7) |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '|  | $\small P({\mathbb{A}}({\mathcal{D}}\backslash{\mathcal{F}}))=P({\mathcal{U}}({\mathcal{D}},{\mathcal{F}},{\mathbb{A}}({\mathcal{D}}))).$
    |  | (7) |'
- en: One straightforward approach to achieve exact unlearning of targeted training
    data from a machine learning model is to retrain the model using the remaining
    dataset as defined earlier. This method effectively removes all information associated
    with the deletion set. However, this approach can be computationally expensive,
    especially in the case of large-scale pre-trained models and datasets.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 实现从机器学习模型中精确遗忘目标训练数据的一种直接方法是使用之前定义的剩余数据集重新训练模型。这种方法有效地移除与删除集相关的所有信息。然而，这种方法在计算上可能会非常昂贵，特别是在大规模预训练模型和数据集的情况下。
- en: Existing works. To address the above challenges, DeltaGrad [[231](#bib.bib231)]
    cache the model parameters and gradients at each training iteration during the
    learning process to speed up the retraining on the remaining dataset. SISA [[228](#bib.bib228)]
    involves partitioning the dataset into distinct shards or subsets and maintaining
    multiple independent models by training the model on each subset. During inference,
    the predictions of these individual models are combined or aggregated. Upon receiving
    deletion requests, SISA approach retraining process focuses solely on the constituent
    model that originally trained on the subset containing this data point. This methodology
    ensures the elimination of all information associated with the removed data points.
    Sekhari et al. [[232](#bib.bib232)] explores on machine unlearning with a focus
    on population risk minimization instead of previous work focus on empirical risk
    minimization. Ullah et al. [[233](#bib.bib233)] further propose an exact unlearning
    method based on the notion of total variation (TV) stability. ARCANE [[234](#bib.bib234)]
    is an approach that leverages ensemble learning to address the retraining cost
    associated with unlearning. Instead of performing a full retraining process, ARCANE
    transforms it into multiple one-class classification tasks. By doing so, it reduces
    the computational and resource requirements while still maintaining the desired
    model performance.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现有工作。为了应对上述挑战，DeltaGrad [[231](#bib.bib231)] 在学习过程中缓存模型参数和梯度，以加速对剩余数据集的重新训练。SISA
    [[228](#bib.bib228)] 涉及将数据集分割成不同的片段或子集，并通过在每个子集上训练模型来维护多个独立模型。在推理过程中，这些单独模型的预测结果会被结合或聚合。在接收到删除请求时，SISA
    方法的重新训练过程仅关注最初在包含该数据点的子集上训练的模型。这一方法确保了所有与移除的数据点相关的信息被清除。Sekhari 等人 [[232](#bib.bib232)]
    探讨了机器遗忘，重点关注人口风险最小化，而不是之前工作的经验风险最小化。Ullah 等人 [[233](#bib.bib233)] 进一步提出了一种基于总变差
    (TV) 稳定性的精确遗忘方法。ARCANE [[234](#bib.bib234)] 是一种利用集成学习来应对与遗忘相关的重新训练成本的方法。ARCANE
    将完全重新训练过程转化为多个单类分类任务，从而减少计算和资源需求，同时保持所需的模型性能。
- en: 10.3.3 Approximate Unlearning
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 10.3.3 近似遗忘
- en: 'As discussed above, exact unlearning can be computationally and memory intensive,
    especially in the case of large-scale pre-trained models and datasets. Additionally,
    it poses a challenge to validate whether the distribution of the model after unlearning
    matches that of a fully retrained model using the remaining dataset. As a result,
    recent research has embraced the concept of approximate unlearning [[235](#bib.bib235)].
    This concept allows for a more efficient and feasible approach to unlearning,
    offering a balance between computational resources and the desired level of forgetting.
    The concept of "approximate unlearning" is defined in the following:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，精确遗忘在计算和内存方面可能非常消耗资源，尤其是在大规模预训练模型和数据集的情况下。此外，验证遗忘后的模型分布是否与使用剩余数据集完全重新训练的模型分布匹配也是一个挑战。因此，最近的研究接受了近似遗忘的概念
    [[235](#bib.bib235)]。这一概念允许更高效、可行的遗忘方法，提供了计算资源和所需遗忘水平之间的平衡。"近似遗忘" 的概念定义如下：
- en: Definition 10.2 (approximate unlearning [[235](#bib.bib235)])
  id: totrans-199
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 10.2（近似遗忘 [[235](#bib.bib235)]）
- en: 'Given a $\epsilon$, for a learning algorithm ${\mathbb{A}}$, a dataset ${\mathcal{D}}$
    and a dataset ${\mathcal{F}}$ to be forgotten, the unlearning algorithm ${\mathcal{U}}$
    performs $\epsilon$ certified removal to remove the influence of ${\bm{z}}$ defined
    as the following:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个 $\epsilon$，对于一个学习算法 ${\mathbb{A}}$、一个数据集 ${\mathcal{D}}$ 和一个需要遗忘的数据集 ${\mathcal{F}}$，遗忘算法
    ${\mathcal{U}}$ 执行 $\epsilon$ 认证移除操作以去除 ${\bm{z}}$ 的影响，如下所定义：
- en: '|  | $\small log&#124;&#124;P({\mathbb{A}}({\mathcal{D}}\backslash{\bm{z}}))-P({\mathcal{U}}({\mathcal{D}},{\bm{z}},{\mathbb{A}}({\mathcal{D}})))&#124;&#124;\leq\epsilon.$
    |  | (8) |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '|  | $\small log\|\|P({\mathbb{A}}({\mathcal{D}}\backslash{\bm{z}}))-P({\mathcal{U}}({\mathcal{D}},{\bm{z}},{\mathbb{A}}({\mathcal{D}})))\|\|\leq\epsilon.$
    |  | (8) |'
- en: Intuitively, the definition of approximate unlearning strives to minimize the
    disparity between the parameter distribution of the unlearned model and the model
    obtained through full retraining on the remaining dataset. Instead of enforcing
    an exact match, approximate unlearning relaxes the requirement by focusing on
    bringing their distributions closer together. This relaxation allows for a more
    practical approach to unlearning, acknowledging that achieving an exact replication
    of the fully trained model on the remaining dataset may not always be feasible
    or necessary.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，近似遗忘的定义力求最小化未学习模型的参数分布与通过在剩余数据集上完全重新训练获得的模型之间的差距。近似遗忘并不强求完全匹配，而是通过将它们的分布拉得更近来放宽要求。这种放宽允许更实用的遗忘方法，承认在剩余数据集上实现完全训练模型的精确复制可能并不总是可行或必要的。
- en: Existing works. Certified Removal [[235](#bib.bib235)] introduces a theoretical
    framework for approximate unlearning. It offers a compelling assurance that a
    model, from which specific data has been removed, is indistinguishable from a
    model that has never encountered that data in the first place. This theoretical
    guarantee provides a strong foundation for the effectiveness of the unlearning
    process. By ensuring that the model’s behavior remains consistent with a model
    that lacks knowledge of the removed data, Certified Removal offers a high level
    of confidence in the privacy and security of the unlearning procedure. The scrubbing
    procedure [[236](#bib.bib236)] offers an alternative framework for machine unlearning
    by leveraging a generalized and weaker form of Differential Privacy. It modifies
    neural network weights to eliminate or "scrub" information related to specific
    training data. Variational Bayesian Unlearning (VBU) [[237](#bib.bib237)] is a
    probabilistic framework for approximate unlearning. It aims to minimize the KL-divergence
    between the approximate posterior of model parameters obtained through direct
    unlearning and the exact posterior from retraining the model with full data. VBU
    strikes a balance between completely forgetting the erased data and retaining
    essential knowledge captured by the model’s posterior belief when trained on the
    full data. In a subsequent study, L-CODEC [[238](#bib.bib238)] is an approximate
    unlearning method that identifies a specific subset of model parameters with the
    highest semantic overlap on an individual sample level. This subset of parameters
    is then utilized in the context of machine unlearning to achieve more efficient
    and targeted unlearning.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现有工作。**Certified Removal** [[235](#bib.bib235)] 引入了一个理论框架用于近似遗忘。它提供了一个有力的保证，表明从中删除了特定数据的模型与从未遇到过这些数据的模型无法区分。这一理论保证为遗忘过程的有效性提供了坚实的基础。通过确保模型的行为与缺乏已删除数据知识的模型保持一致，**Certified
    Removal** 提供了对遗忘程序隐私和安全性的高度信心。**Scrubbing Procedure** [[236](#bib.bib236)] 提供了另一种机器遗忘的框架，通过利用更一般化且较弱形式的**差分隐私**。它修改神经网络权重以消除或“清除”与特定训练数据相关的信息。**Variational
    Bayesian Unlearning (VBU)** [[237](#bib.bib237)] 是一个用于近似遗忘的概率框架。它旨在最小化通过直接遗忘获得的模型参数的近似后验与通过使用完整数据重新训练模型获得的精确后验之间的**KL散度**。**VBU**
    在完全遗忘擦除的数据和保留在完整数据上训练的模型的后验信念捕获的核心知识之间取得平衡。在随后的研究中，**L-CODEC** [[238](#bib.bib238)]
    是一种近似遗忘方法，识别在个体样本级别上具有最高语义重叠的特定模型参数子集。然后在机器遗忘的背景下利用这个参数子集，以实现更高效和更有针对性的遗忘。
- en: 10.3.4 Catastrophic Forgetting Other Normal Examples
  id: totrans-204
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 10.3.4 灾难性遗忘其他正常示例
- en: Catastrophic forgetting in machine unlearning refers to the unintended decrease
    in the log posterior probability of the remaining dataset, denoted as $\small
    P({\bm{\theta}}\mid{\mathcal{D}}\backslash{\mathcal{F}})$, as a result of unlearning
    [[239](#bib.bib239)]. This phenomenon leads to a degradation in the performance
    of the unlearned model on data other than the targeted samples, which is undesirable.
    The significance of catastrophic forgetting increases as more data is unlearned.
    It is important to note that this concept differs from the objective of machine
    unlearning, which focuses solely on forgetting specific samples. In the UNLEARN
    method proposed by [[239](#bib.bib239)], the update magnitude of new parameter
    values to the old values is constrained, and a memory buffer is maintained to
    store previous examples. The Forsaken method [[240](#bib.bib240)] introduces a
    dynamic gradient penalty term to restrict parameter changes on normal data, effectively
    mitigating the issue of catastrophic forgetting. A Bayesian unlearning framework
    proposed by [[237](#bib.bib237)] provides a natural trade-off interpretation between
    fully unlearning from erased data and retaining posterior beliefs by learning
    on the entire dataset. Additionally, scrubbing procedure [[236](#bib.bib236)]
    minimizes loss on the remaining data while maximizing forgetting on the target
    forgetting dataset by introducing random noise to the model weights, allowing
    for forgetting on the specified dataset while retaining knowledge on the remaining
    data. Furthermore, PUMA [[241](#bib.bib241)], aims to mitigate the potential negative
    impact caused by the removal of targeted training data. PUMA achieves this by
    optimally reweighting the remaining data, ensuring that the model’s performance
    is not excessively affected when unlearning specific samples.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器遗忘中的灾难性遗忘指的是由于遗忘[[239](#bib.bib239)]所导致的剩余数据集的对数后验概率（记作 $\small P({\bm{\theta}}\mid{\mathcal{D}}\backslash{\mathcal{F}})$）的无意减少。这种现象会导致遗忘模型在目标样本以外的数据上的性能下降，这是不希望出现的。灾难性遗忘的重要性随着遗忘数据量的增加而增加。需要注意的是，这一概念与机器遗忘的目标不同，后者仅关注于遗忘特定样本。在[[239](#bib.bib239)]提出的UNLEARN方法中，新参数值与旧值的更新幅度受到限制，并且维护了一个存储先前示例的内存缓冲区。Forsaken方法[[240](#bib.bib240)]引入了动态梯度惩罚项，以限制对正常数据的参数变化，有效缓解了灾难性遗忘的问题。[[237](#bib.bib237)]提出的贝叶斯遗忘框架提供了一个自然的权衡解释，介于从已删除数据中完全遗忘与通过在整个数据集上学习保持后验信念之间。此外，清理过程[[236](#bib.bib236)]通过向模型权重引入随机噪声来最小化剩余数据上的损失，同时最大化目标遗忘数据集上的遗忘，从而允许在指定数据集上遗忘，同时保留对剩余数据的知识。此外，PUMA[[241](#bib.bib241)]旨在减轻删除目标训练数据可能造成的负面影响。PUMA通过对剩余数据进行最佳加权来实现这一点，确保在遗忘特定样本时模型的性能不会受到过度影响。
- en: Finally, it is evident that we cannot simply erase an excessive number of data
    points, as doing so would eventually lead to a decrease in performance on the
    test set. In a study by Sekhari et al. [[232](#bib.bib232)], the authors conduct
    a theoretical analysis to determine the maximum number of samples that can be
    deleted from a pre-trained model without compromising the performance on the test
    set. This analysis provides insights into the trade-off between machine unlearning
    on a specific subset of training set and maintaining the generalization performance
    on test set.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，显而易见的是，我们不能简单地删除过多的数据点，因为这样做最终会导致测试集性能下降。在Sekhari等人[[232](#bib.bib232)]的研究中，作者进行了理论分析，以确定可以从预训练模型中删除的最大样本数量，而不会影响测试集的性能。这项分析提供了有关特定训练集子集的机器遗忘与保持测试集上泛化性能之间权衡的见解。
- en: 10.3.5 Application of Machine Unlearning
  id: totrans-207
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 10.3.5 机器遗忘的应用
- en: Machine unlearning techniques find application in various domains, including
    backdoor attack defense and defending against membership inference attacks. In
    the context of backdoor attack defense [[242](#bib.bib242)], machine unlearning
    can be used to erase the backdoor trigger that has been injected into a trained
    model. By selectively unlearning the specific information related to the backdoor
    trigger, the model can be cleansed of its malicious behavior. Similarly, machine
    unlearning can also serve as a defense mechanism [[241](#bib.bib241), [235](#bib.bib235)]
    against membership inference attacks. By removing the specific training data from
    a pre-trained model, the traces or characteristics of these data are eliminated,
    making it harder for attackers to infer membership or extract sensitive information.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 机器遗忘技术在多个领域找到应用，包括后门攻击防御和防御成员推断攻击。在后门攻击防御的背景下 [[242](#bib.bib242)]，机器遗忘可以用来擦除已注入训练模型中的后门触发器。通过有选择地遗忘与后门触发器相关的特定信息，模型可以去除其恶意行为。类似地，机器遗忘也可以作为对抗成员推断攻击的防御机制
    [[241](#bib.bib241), [235](#bib.bib235)]。通过从预训练模型中移除特定训练数据，这些数据的痕迹或特征被消除，使攻击者更难推断成员资格或提取敏感信息。
- en: 11 Discussion and Future Prospect
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11 讨论与未来展望
- en: 11.1 Summary and Research Trends
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1 总结与研究趋势
- en: 'Cross Discipline Research About Forgetting: Cross-disciplinary research is
    vital for advancing machine learning disciplines. Various fields offer valuable
    insights and innovations through cross-disciplinary research. This exploration
    encompasses both the application of techniques from CL to address challenges in
    other research domains and applications of techniques from various fields to solve
    problems in CL. These interdisciplinary research efforts pave the way for the
    advancements in different research areas. In future work, we anticipate that actively
    promoting collaboration and facilitating idea exchange across diverse research
    areas will be crucial in overcoming disciplinary barriers.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 关于遗忘的跨学科研究：跨学科研究对推动机器学习领域至关重要。通过跨学科研究，各领域提供了宝贵的见解和创新。这些探索包括从CL（常见学习）领域应用技术解决其他研究领域中的挑战，以及将各领域的技术应用于CL中的问题。这些跨学科研究努力为不同研究领域的进展铺平了道路。在未来的工作中，我们预期积极推动合作和促进各研究领域之间的思想交流将是克服学科障碍的关键。
- en: 'Intentional Forgetting in Machine Learning: Intentional forgetting has emerged
    as a promising approach to enhance model performance and address data privacy
    concerns in recent studies. On one hand, intentional forgetting proves valuable
    in eliminating biased and irrelevant information during model training, thereby
    mitigating overfitting and improving generalization. On the other hand, in the
    context of machine unlearning, forgetting plays a crucial role in removing private
    data to safeguard data privacy.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的有意遗忘：有意遗忘在近期研究中已成为提升模型性能和解决数据隐私问题的有前景的方法。一方面，有意遗忘在模型训练过程中消除偏见和无关信息，减少过拟合，提高泛化能力。另一方面，在机器遗忘的背景下，遗忘在移除私人数据以保护数据隐私方面发挥了关键作用。
- en: 'Growing Trend for Theoretical Analysis: Recently, there is an emerging trend
    towards conducting theoretical analyses to delve deeper into the understanding
    and analysis of forgetting across diverse research fields. These theoretical analyses
    aim to provide more valuable insights and uncover fundamental principles that
    govern forgetting.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 理论分析的增长趋势：最近，进行理论分析的趋势日益明显，以深入理解和分析各研究领域中的遗忘现象。这些理论分析旨在提供更有价值的见解，并揭示支配遗忘的基本原则。
- en: 'Addressing Forgetting with Foundation Models: The foundation model has demonstrated
    promising potential in tackling forgetting across various research fields, making
    it an active and promising area of research.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 解决遗忘问题的基础模型：基础模型在应对各研究领域的遗忘问题上展现了良好的潜力，成为一个活跃且有前景的研究领域。
- en: 11.2 Open Research Questions and Future Prospect
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2 开放的研究问题与未来展望
- en: In the following, we prospect several potential research directions for future
    study.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 以下，我们展望了未来研究的几个潜在方向。
- en: 'In-depth Theoretical Analysis of Forgetting: The majority of existing methods
    are empirical in nature, lacking theoretical guarantees and comprehensive analysis.
    Therefore, there is a pressing need for more thorough theoretical analysis across
    different learning domains. Future research efforts should aim to bridge this
    gap by incorporating rigorous theoretical analysis of forgetting.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 对忘记的深入理论分析：现有的大多数方法本质上是经验性的，缺乏理论保障和全面分析。因此，迫切需要在不同学习领域进行更为彻底的理论分析。未来的研究应着力于通过严格的理论分析来弥补这一空白。
- en: 'Trustworthiness of Forgetting: Most existing studies on forgetting primarily
    concentrate on its impact on model performance while overlooking other crucial
    aspects such as robustness, fairness, transparency, etc. To bridge this research
    gap, future investigations should dedicate more efforts to analyze and understand
    the effects of forgetting on these trustworthiness properties.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 忘记的可信度：大多数现有的关于忘记的研究主要集中在其对模型性能的影响上，而忽略了其他重要方面，例如鲁棒性、公平性、透明度等。为了填补这一研究空白，未来的研究应更多地致力于分析和理解忘记对这些可信度属性的影响。
- en: 'Proper Trade-off Between Memorization and Forgetting: Striking a balance between
    remembering previous knowledge and protecting privacy poses a critical research
    problem. Remembering more previous knowledge can increase the risk of memorizing
    private information, potentially compromising privacy. Conversely, prioritizing
    privacy protection may result in sacrificing performance on previous tasks. Achieving
    an appropriate equilibrium between memorization and forgetting is crucial to address
    this challenge effectively. Future research should focus on developing methodologies
    and techniques that enable effective management of knowledge retention while ensuring
    privacy preservation, thereby striking the optimal balance between the two.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆与遗忘之间的适当权衡：在记住以前的知识和保护隐私之间取得平衡是一个关键的研究问题。记住更多的以前的知识可能会增加记忆私人信息的风险，可能会损害隐私。相反，优先考虑隐私保护可能会导致在以前任务上的表现下降。实现记忆与遗忘之间的适当平衡对有效应对这一挑战至关重要。未来的研究应关注开发能够有效管理知识保留同时确保隐私保护的方法和技术，从而在两者之间找到最佳平衡点。
- en: 12 Conclusion
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12 结论
- en: Forgetting is a prevalent phenomenon across various machine learning fields,
    driven by different factors. This survey aims to offer a comprehensive examination
    of the forgetting issue in diverse machine learning domains, such as continual
    learning, foundation model, meta-learning, domain adaptation, test time adaptation,
    generative model, federated learning, reinforcement learning and machine unlearning.
    Our survey aims to provide a thorough overview and understanding of the research
    progress on forgetting, with the intention of inspiring future investigations
    into intriguing and innovative research directions and methods. While existing
    surveys on continual learning often emphasize the harmful aspects of forgetting,
    our survey argues that forgetting can also be beneficial. We present application
    scenarios where selective forgetting improves generalization performance and learns
    new tasks, and intentional forgetting of memorized examples helps safeguard the
    privacy of machine learning systems.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 忘记是各种机器学习领域中普遍存在的现象，由不同因素驱动。此调查旨在对不同机器学习领域中的忘记问题进行全面审查，例如持续学习、基础模型、元学习、领域适应、测试时间适应、生成模型、联邦学习、强化学习和机器学习去忘记。我们的调查旨在提供对忘记研究进展的全面概述和理解，意在激发未来对有趣且创新的研究方向和方法的探索。虽然现有的关于持续学习的调查通常强调忘记的有害方面，但我们的调查认为，忘记也可以是有益的。我们展示了选择性忘记改善泛化性能和学习新任务的应用场景，并且故意忘记记忆中的示例有助于保护机器学习系统的隐私。
- en: References
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] M. McCloskey and N. J. Cohen, “Catastrophic interference in connectionist
    networks: The sequential learning problem,” *Psychology of learning and motivation*,
    1989.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] M. McCloskey 和 N. J. Cohen， “连接主义网络中的灾难性干扰：序列学习问题，” *学习与动机心理学*，1989年。'
- en: '[2] G. I. Parisi, R. Kemker, J. L. Part, C. Kanan, and S. Wermter, “Continual
    lifelong learning with neural networks: A review,” *Neural Networks*, 2019.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] G. I. Parisi, R. Kemker, J. L. Part, C. Kanan, 和 S. Wermter，“使用神经网络的持续终身学习：综述，”
    *神经网络*，2019年。'
- en: '[3] G. M. van de Ven and A. S. Tolias, “Three scenarios for continual learning,”
    2019.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] G. M. van de Ven 和 A. S. Tolias，“持续学习的三种情境，”2019年。'
- en: '[4] M. De Lange, R. Aljundi, M. Masana, S. Parisot, X. Jia, A. Leonardis, G. Slabaugh,
    and T. Tuytelaars, “A continual learning survey: Defying forgetting in classification
    tasks,” *TPAMI*, 2022.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] M. De Lange, R. Aljundi, M. Masana, S. Parisot, X. Jia, A. Leonardis, G.
    Slabaugh, 和 T. Tuytelaars，“持续学习调查：在分类任务中挑战遗忘”，*TPAMI*，2022年。'
- en: '[5] Z. Mai, R. Li, J. Jeong, D. Quispe, H. Kim, and S. Sanner, “Online continual
    learning in image classification: An empirical survey,” *Neurocomputing*, 2022.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Z. Mai, R. Li, J. Jeong, D. Quispe, H. Kim, 和 S. Sanner，“图像分类中的在线持续学习：一项实证调查”，*Neurocomputing*，2022年。'
- en: '[6] M. Masana, X. Liu, B. Twardowski, M. Menta, A. D. Bagdanov, and J. van de
    Weijer, “Class-incremental learning: survey and performance evaluation on image
    classification,” *TPAMI*, 2022.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] M. Masana, X. Liu, B. Twardowski, M. Menta, A. D. Bagdanov, 和 J. van de
    Weijer，“类别增量学习：调查与图像分类性能评估”，*TPAMI*，2022年。'
- en: '[7] D.-W. Zhou, Q.-W. Wang, Z.-H. Qi, H.-J. Ye, D.-C. Zhan, and Z. Liu, “Deep
    class-incremental learning: A survey,” 2023.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] D.-W. Zhou, Q.-W. Wang, Z.-H. Qi, H.-J. Ye, D.-C. Zhan, 和 Z. Liu，“深度类别增量学习：一项调查”，2023年。'
- en: '[8] J. A. Mendez and E. Eaton, “How to reuse and compose knowledge for a lifetime
    of tasks: A survey on continual learning and functional composition,” *Transactions
    on Machine Learning Research*, 2023.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] J. A. Mendez 和 E. Eaton，“如何重用和组合知识以完成终身任务：关于持续学习和功能组合的调查”，*Transactions
    on Machine Learning Research*，2023年。'
- en: '[9] L. Wang, X. Zhang, H. Su, and J. Zhu, “A comprehensive survey of continual
    learning: Theory, method and application,” 2023.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] L. Wang, X. Zhang, H. Su, 和 J. Zhu，“持续学习的全面调查：理论、方法与应用”，2023年。'
- en: '[10] A. Ginart, M. Guan, G. Valiant, and J. Y. Zou, “Making ai forget you:
    Data deletion in machine learning,” *NeurIPS*, 2019.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] A. Ginart, M. Guan, G. Valiant, 和 J. Y. Zou，“让 AI 忘记你：机器学习中的数据删除”，*NeurIPS*，2019年。'
- en: '[11] R. Shokri, M. Stronati, C. Song, and V. Shmatikov, “Membership inference
    attacks against machine learning models,” in *SP*, 2017.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] R. Shokri, M. Stronati, C. Song, 和 V. Shmatikov，“针对机器学习模型的成员身份推断攻击”，在*SP*，2017年。'
- en: '[12] Y. Shi, L. Shen, K. Wei, Y. Sun, B. Yuan, X. Wang, and D. Tao, “Improving
    the model consistency of decentralized federated learning,” *ICML*, 2023.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Y. Shi, L. Shen, K. Wei, Y. Sun, B. Yuan, X. Wang, 和 D. Tao，“提高去中心化联邦学习的模型一致性”，*ICML*，2023年。'
- en: '[13] Y. Cao and J. Yang, “Towards making systems forget with machine unlearning,”
    in *2015 IEEE symposium on security and privacy*, 2015.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Y. Cao 和 J. Yang，“通过机器遗忘实现系统遗忘”，在*2015 IEEE 安全与隐私研讨会*，2015年。'
- en: '[14] D. Lopez-Paz and M. Ranzato, “Gradient episodic memory for continual learning,”
    *NeurIPS*, 2017.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] D. Lopez-Paz 和 M. Ranzato，“用于持续学习的梯度记忆”，*NeurIPS*，2017年。'
- en: '[15] A. Chaudhry, M. Ranzato, M. Rohrbach, and M. Elhoseiny, “Efficient lifelong
    learning with a-gem,” *ICLR*, 2019.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] A. Chaudhry, M. Ranzato, M. Rohrbach, 和 M. Elhoseiny，“使用 A-GEM 的高效终身学习”，*ICLR*，2019年。'
- en: '[16] P. Buzzega, M. Boschini, A. Porrello, D. Abati, and S. Calderara, “Dark
    experience for general continual learning: a strong, simple baseline,” *NeurIPS*,
    2020.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] P. Buzzega, M. Boschini, A. Porrello, D. Abati, 和 S. Calderara，“用于一般持续学习的黑暗经验：一个强大且简单的基准”，*NeurIPS*，2020年。'
- en: '[17] R. Tiwari, K. Killamsetty, R. Iyer, and P. Shenoy, “Gcr: Gradient coreset
    based replay buffer selection for continual learning,” in *CVPR*, 2022.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] R. Tiwari, K. Killamsetty, R. Iyer, 和 P. Shenoy，“GCR：基于梯度的核心集重放缓冲区选择用于持续学习”，在*CVPR*，2022年。'
- en: '[18] Z. Sun, Y. Mu, and G. Hua, “Regularizing second-order influences for continual
    learning,” in *CVPR*, 2023.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Z. Sun, Y. Mu, 和 G. Hua，“为持续学习正则化二阶影响”，在*CVPR*，2023年。'
- en: '[19] S.-A. Rebuffi, A. Kolesnikov, G. Sperl, and C. H. Lampert, “icarl: Incremental
    classifier and representation learning,” in *CVPR*, 2017.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] S.-A. Rebuffi, A. Kolesnikov, G. Sperl, 和 C. H. Lampert，“iCarl：增量分类器和表征学习”，在*CVPR*，2017年。'
- en: '[20] R. Aljundi, M. Lin, B. Goujaud, and Y. Bengio, “Gradient based sample
    selection for online continual learning,” in *NeurIPS*, 2019.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] R. Aljundi, M. Lin, B. Goujaud, 和 Y. Bengio，“基于梯度的样本选择用于在线持续学习”，在*NeurIPS*，2019年。'
- en: '[21] J. Bang, H. Kim, Y. Yoo, J.-W. Ha, and J. Choi, “Rainbow memory: Continual
    learning with a memory of diverse samples,” in *CVPR*, 2021.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] J. Bang, H. Kim, Y. Yoo, J.-W. Ha, 和 J. Choi，“彩虹记忆：具有多样样本记忆的持续学习”，在*CVPR*，2021年。'
- en: '[22] A. Chaudhry, P. K. Dokania, T. Ajanthan, and P. H. Torr, “Riemannian walk
    for incremental learning: Understanding forgetting and intransigence,” in *ECCV*,
    2018.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] A. Chaudhry, P. K. Dokania, T. Ajanthan, 和 P. H. Torr，“增量学习的黎曼步态：理解遗忘与顽固性”，在*ECCV*，2018年。'
- en: '[23] R. Aljundi, E. Belilovsky, T. Tuytelaars, L. Charlin, M. Caccia, M. Lin,
    and L. Page-Caccia, “Online continual learning with maximal interfered retrieval,”
    *NeurIPS*, 2019.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] R. Aljundi, E. Belilovsky, T. Tuytelaars, L. Charlin, M. Caccia, M. Lin,
    和 L. Page-Caccia，“具有最大干扰检索的在线持续学习”，*NeurIPS*，2019年。'
- en: '[24] W. Chenshen, L. Herranz, L. Xialei *et al.*, “Memory replay gans: Learning
    to generate images from new categories without forgetting,” in *NeurIPS*, 2018.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] W. Chenshen, L. Herranz, L. Xialei *等*，“Memory replay gans：学习从新类别生成图像而不遗忘”，发表于*NeurIPS*，2018年。'
- en: '[25] Y. Xiang, Y. Fu, P. Ji, and H. Huang, “Incremental learning using conditional
    adversarial networks,” in *ICCV*, 2019.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Y. Xiang, Y. Fu, P. Ji 和 H. Huang，“使用条件对抗网络的增量学习”，发表于*ICCV*，2019年。'
- en: '[26] R. Kemker and C. Kanan, “Fearnet: Brain-inspired model for incremental
    learning,” in *ICLR*, 2018.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] R. Kemker 和 C. Kanan，“Fearnet：用于增量学习的脑启发模型”，发表于*ICLR*，2018年。'
- en: '[27] Q. Jodelet, X. Liu, Y. J. Phua, and T. Murata, “Class-incremental learning
    using diffusion model for distillation and replay,” *CoRR*, 2023.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Q. Jodelet, X. Liu, Y. J. Phua 和 T. Murata，“使用扩散模型进行蒸馏和重放的类增量学习”，*CoRR*，2023年。'
- en: '[28] J. Smith, Y.-C. Hsu, J. Balloch, Y. Shen, H. Jin, and Z. Kira, “Always
    be dreaming: A new approach for data-free class-incremental learning,” in *ICCV*,
    2021.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] J. Smith, Y.-C. Hsu, J. Balloch, Y. Shen, H. Jin 和 Z. Kira，“Always be
    dreaming：一种新的数据无关增量学习方法”，发表于*ICCV*，2021年。'
- en: '[29] G. M. Van de Ven, H. T. Siegelmann, and A. S. Tolias, “Brain-inspired
    replay for continual learning with artificial neural networks,” *Nature communications*,
    2020.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] G. M. Van de Ven, H. T. Siegelmann 和 A. S. Tolias，“用于持续学习的脑启发重放与人工神经网络”，*Nature
    communications*，2020年。'
- en: '[30] K. Jeeveswaran, P. Bhat, B. Zonooz, and E. Arani, “Birt: Bio-inspired
    replay in vision transformers for continual learning,” *ICML*, 2023.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] K. Jeeveswaran, P. Bhat, B. Zonooz 和 E. Arani，“Birt：在视觉变换器中进行生物启发的重放以支持持续学习”，*ICML*，2023年。'
- en: '[31] L. Wang, X. Zhang, K. Yang, L. Yu, C. Li, L. HONG, S. Zhang, Z. Li, Y. Zhong,
    and J. Zhu, “Memory replay with data compression for continual learning,” in *ICLR*,
    2022.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] L. Wang, X. Zhang, K. Yang, L. Yu, C. Li, L. HONG, S. Zhang, Z. Li, Y.
    Zhong 和 J. Zhu，“带有数据压缩的记忆重放用于持续学习”，发表于*ICLR*，2022年。'
- en: '[32] Z. Luo, Y. Liu, B. Schiele, and Q. Sun, “Class-incremental exemplar compression
    for class-incremental learning,” in *CVPR*, 2023.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Z. Luo, Y. Liu, B. Schiele 和 Q. Sun，“用于类增量学习的类增量样本压缩”，发表于*CVPR*，2023年。'
- en: '[33] Y. Liu, Y. Su, A. Liu, B. Schiele, and Q. Sun, “Mnemonics training: Multi-class
    incremental learning without forgetting,” in *CVPR*, 2020.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Y. Liu, Y. Su, A. Liu, B. Schiele 和 Q. Sun，“Mnemonics training：无需遗忘的多类增量学习”，发表于*CVPR*，2020年。'
- en: '[34] Z. Deng and O. Russakovsky, “Remember the past: Distilling datasets into
    addressable memories for neural networks,” in *NeurIPS*, 2022.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Z. Deng 和 O. Russakovsky，“Remember the past：将数据集蒸馏为神经网络的可寻址记忆”，发表于*NeurIPS*，2022年。'
- en: '[35] G. Cazenavette, T. Wang, A. Torralba, A. A. Efros, and J.-Y. Zhu, “Dataset
    distillation by matching training trajectories,” in *CVPR*, 2022.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] G. Cazenavette, T. Wang, A. Torralba, A. A. Efros 和 J.-Y. Zhu，“通过匹配训练轨迹进行数据集蒸馏”，发表于*CVPR*，2022年。'
- en: '[36] A. A. Rusu, N. C. Rabinowitz, G. Desjardins, H. Soyer, J. Kirkpatrick,
    K. Kavukcuoglu, R. Pascanu, and R. Hadsell, “Progressive neural networks,” 2016.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] A. A. Rusu, N. C. Rabinowitz, G. Desjardins, H. Soyer, J. Kirkpatrick,
    K. Kavukcuoglu, R. Pascanu 和 R. Hadsell，“Progressive neural networks”，2016年。'
- en: '[37] C. Fernando, D. Banarse, C. Blundell, Y. Zwols, D. Ha, A. A. Rusu, A. Pritzel,
    and D. Wierstra, “Pathnet: Evolution channels gradient descent in super neural
    networks,” *arXiv preprint arXiv:1701.08734*, 2017.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] C. Fernando, D. Banarse, C. Blundell, Y. Zwols, D. Ha, A. A. Rusu, A.
    Pritzel 和 D. Wierstra，“Pathnet：在超神经网络中进化梯度下降”，*arXiv preprint arXiv:1701.08734*，2017年。'
- en: '[38] J. Yoon, E. Yang, J. Lee, and S. J. Hwang, “Lifelong learning with dynamically
    expandable networks,” *ICLR*, 2018.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] J. Yoon, E. Yang, J. Lee 和 S. J. Hwang，“使用动态可扩展网络进行终身学习”，*ICLR*，2018年。'
- en: '[39] J. Serrá, D. Surís, M. Miron, and A. Karatzoglou, “Overcoming catastrophic
    forgetting with hard attention to the task,” in *ICML*, 2018.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] J. Serrá, D. Surís, M. Miron 和 A. Karatzoglou，“通过对任务的强注意力克服灾难性遗忘”，发表于*ICML*，2018年。'
- en: '[40] G. Bellec, D. Kappel, W. Maass, and R. Legenstein, “Deep rewiring: Training
    very sparse deep networks,” in *ICLR*, 2018.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] G. Bellec, D. Kappel, W. Maass 和 R. Legenstein，“Deep rewiring：训练非常稀疏的深度网络”，发表于*ICLR*，2018年。'
- en: '[41] Z. Wang, Z. Zhan, Y. Gong, G. Yuan, W. Niu, T. Jian, B. Ren, S. Ioannidis,
    Y. Wang, and J. Dy, “Sparcl: Sparse continual learning on the edge,” in *NeurIPS*,
    2022.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Z. Wang, Z. Zhan, Y. Gong, G. Yuan, W. Niu, T. Jian, B. Ren, S. Ioannidis,
    Y. Wang 和 J. Dy，“Sparcl：边缘稀疏持续学习”，发表于*NeurIPS*，2022年。'
- en: '[42] A. Mallya, D. Davis, and S. Lazebnik, “Piggyback: Adapting a single network
    to multiple tasks by learning to mask weights,” in *ECCV*, 2018.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] A. Mallya, D. Davis 和 S. Lazebnik，“Piggyback：通过学习掩蔽权重将单个网络适应多个任务”，发表于*ECCV*，2018年。'
- en: '[43] A. Mallya and S. Lazebnik, “Packnet: Adding multiple tasks to a single
    network by iterative pruning,” in *CVPR*, 2018.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] A. Mallya 和 S. Lazebnik，“Packnet：通过迭代剪枝将多个任务添加到单个网络中”，发表于*CVPR*，2018年。'
- en: '[44] C.-Y. Hung, C.-H. Tu, C.-E. Wu, C.-H. Chen, Y.-M. Chan, and C.-S. Chen,
    “Compacting, picking and growing for unforgetting continual learning,” *NeurIPS*,
    2019.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] C.-Y. Hung, C.-H. Tu, C.-E. Wu, C.-H. Chen, Y.-M. Chan 和 C.-S. Chen，“压缩、挑选和增长以实现无遗忘持续学习”，*NeurIPS*，2019年。'
- en: '[45] X. Li, Y. Zhou, T. Wu, R. Socher, and C. Xiong, “Learn to grow: A continual
    structure learning framework for overcoming catastrophic forgetting,” in *ICML*,
    2019.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] X. Li, Y. Zhou, T. Wu, R. Socher 和 C. Xiong，“学会增长：克服灾难性遗忘的持续结构学习框架”，发表于
    *ICML*，2019年。'
- en: '[46] S. Yan, J. Xie, and X. He, “Der: Dynamically expandable representation
    for class incremental learning,” in *CVPR*, 2021.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] S. Yan, J. Xie 和 X. He，“Der：用于类增量学习的动态可扩展表示”，发表于 *CVPR*，2021年。'
- en: '[47] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A.
    Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska, D. Hassabis, C. Clopath,
    D. Kumaran, and R. Hadsell, “Overcoming catastrophic forgetting in neural networks,”
    *Proceedings of the national academy of sciences*, 2017.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A.
    Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska, D. Hassabis, C. Clopath,
    D. Kumaran 和 R. Hadsell，“克服神经网络中的灾难性遗忘”，*Proceedings of the national academy of
    sciences*，2017年。'
- en: '[48] F. Zenke, B. Poole, and S. Ganguli, “Continual learning through synaptic
    intelligence,” in *ICML*, 2017.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] F. Zenke, B. Poole 和 S. Ganguli，“通过突触智能实现持续学习”，发表于 *ICML*，2017年。'
- en: '[49] J. von Oswald, C. Henning, J. Sacramento, and B. F. Grewe, “Continual
    learning with hypernetworks,” 2019.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] J. von Oswald, C. Henning, J. Sacramento 和 B. F. Grewe，“利用超网络进行持续学习”，2019年。'
- en: '[50] R. Aljundi, F. Babiloni, M. Elhoseiny, M. Rohrbach, and T. Tuytelaars,
    “Memory aware synapses: Learning what (not) to forget,” in *ECCV*, 2018.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] R. Aljundi, F. Babiloni, M. Elhoseiny, M. Rohrbach 和 T. Tuytelaars，“记忆感知突触：学习忘记什么（不该忘记的东西）”，发表于
    *ECCV*，2018年。'
- en: '[51] H. Ahn, S. Cha, D. Lee, and T. Moon, “Uncertainty-based continual learning
    with adaptive regularization,” *NeurIPS*, 2019.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] H. Ahn, S. Cha, D. Lee 和 T. Moon，“基于不确定性的持续学习与自适应正则化”，*NeurIPS*，2019年。'
- en: '[52] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural
    network,” *arXiv preprint arXiv:1503.02531*, 2015.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] G. Hinton, O. Vinyals 和 J. Dean，“提炼神经网络中的知识”，*arXiv preprint arXiv:1503.02531*，2015年。'
- en: '[53] Z. Li and D. Hoiem, “Learning without forgetting,” *TPAMI*, 2018.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] Z. Li 和 D. Hoiem，“无遗忘学习”，*TPAMI*，2018年。'
- en: '[54] P. Dhar, R. V. Singh, K.-C. Peng, Z. Wu, and R. Chellappa, “Learning without
    memorizing,” in *CVPR*, 2019.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] P. Dhar, R. V. Singh, K.-C. Peng, Z. Wu 和 R. Chellappa，“无记忆学习”，发表于 *CVPR*，2019年。'
- en: '[55] I. Fostiropoulos, J. Zhu, and L. Itti, “Batch model consolidation: A multi-task
    model consolidation framework,” in *CVPR*, 2023.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] I. Fostiropoulos, J. Zhu 和 L. Itti，“批量模型整合：一个多任务模型整合框架”，发表于 *CVPR*，2023年。'
- en: '[56] K. Lee, K. Lee, J. Shin, and H. Lee, “Overcoming catastrophic forgetting
    with unlabeled data in the wild,” in *ICCV*, 2019.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] K. Lee, K. Lee, J. Shin 和 H. Lee，“利用野外未标记数据克服灾难性遗忘”，发表于 *ICCV*，2019年。'
- en: '[57] M. Farajtabar, N. Azizan, A. Mott, and A. Li, “Orthogonal gradient descent
    for continual learning,” 2020.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] M. Farajtabar, N. Azizan, A. Mott 和 A. Li，“用于持续学习的正交梯度下降”，2020年。'
- en: '[58] T. Doan, M. A. Bennani, B. Mazoure, G. Rabusseau, and P. Alquier, “A theoretical
    analysis of catastrophic forgetting through the NTK overlap matrix,” in *AISTATS*,
    2021.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] T. Doan, M. A. Bennani, B. Mazoure, G. Rabusseau 和 P. Alquier，“通过 NTK
    重叠矩阵对灾难性遗忘的理论分析”，发表于 *AISTATS*，2021年。'
- en: '[59] A. Chaudhry, N. Khan, P. K. Dokania, and P. H. Torr, “Continual learning
    in low-rank orthogonal subspaces,” in *NeurIPS*, 2020.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] A. Chaudhry, N. Khan, P. K. Dokania 和 P. H. Torr，“低秩正交子空间中的持续学习”，发表于 *NeurIPS*，2020年。'
- en: '[60] G. Zeng, Y. Chen, B. Cui, and S. Yu, “Continual learning of context-dependent
    processing in neural networks,” *Nature Machine Intelligence*, 2019.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] G. Zeng, Y. Chen, B. Cui 和 S. Yu，“神经网络中上下文依赖处理的持续学习”，*Nature Machine Intelligence*，2019年。'
- en: '[61] G. Saha, I. Garg, and K. Roy, “Gradient projection memory for continual
    learning,” *ICLR*, 2021.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] G. Saha, I. Garg 和 K. Roy，“用于持续学习的梯度投影记忆”，*ICLR*，2021年。'
- en: '[62] D. DENG, G. Chen, J. HAO, Q. Wang, and P.-A. Heng, “Flattening sharpness
    for dynamic gradient projection memory benefits continual learning,” in *NeurIPS*,
    2021.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] D. DENG, G. Chen, J. HAO, Q. Wang 和 P.-A. Heng，“通过动态梯度投影记忆的平滑化来促进持续学习”，发表于
    *NeurIPS*，2021年。'
- en: '[63] S. Lin, L. Yang, D. Fan, and J. Zhang, “TRGP: Trust region gradient projection
    for continual learning,” in *ICLR*, 2022.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] S. Lin, L. Yang, D. Fan 和 J. Zhang，“TRGP：用于持续学习的信任区域梯度投影”，发表于 *ICLR*，2022年。'
- en: '[64] C. V. Nguyen, Y. Li, T. D. Bui, and R. E. Turner, “Variational continual
    learning,” *ICLR*, 2018.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] C. V. Nguyen, Y. Li, T. D. Bui 和 R. E. Turner，“变分持续学习”，*ICLR*，2018年。'
- en: '[65] S.-W. Lee, J.-H. Kim, J. Jun, J.-W. Ha, and B.-T. Zhang, “Overcoming catastrophic
    forgetting by incremental moment matching,” *NeurIPS*, 2017.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] S.-W. Lee, J.-H. Kim, J. Jun, J.-W. Ha, 和 B.-T. Zhang，“通过增量矩匹配克服灾难性遗忘”，*NeurIPS*，2017。'
- en: '[66] T. Adel, H. Zhao, and R. E. Turner, “Continual learning with adaptive
    weights (claw),” in *ICLR*, 2020.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] T. Adel, H. Zhao, 和 R. E. Turner，“使用自适应权重（claw）的持续学习”，发表于 *ICLR*，2020。'
- en: '[67] R. Kurle, B. Cseke, A. Klushyn, P. van der Smagt, and S. Günnemann, “Continual
    learning with bayesian neural networks for non-stationary data,” in *ICLR*, 2020.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] R. Kurle, B. Cseke, A. Klushyn, P. van der Smagt, 和 S. Günnemann，“使用贝叶斯神经网络进行非平稳数据的持续学习”，发表于
    *ICLR*，2020。'
- en: '[68] C. Henning, M. Cervera, F. D’Angelo, J. V. Oswald, R. Traber, B. Ehret,
    S. Kobayashi, B. F. Grewe, and J. Sacramento, “Posterior meta-replay for continual
    learning,” in *NeurIPS*, 2021.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] C. Henning, M. Cervera, F. D’Angelo, J. V. Oswald, R. Traber, B. Ehret,
    S. Kobayashi, B. F. Grewe, 和 J. Sacramento，“用于持续学习的后验元重放”，发表于 *NeurIPS*，2021。'
- en: '[69] T.-C. Kao, K. Jensen, G. van de Ven, A. Bernacchia, and G. Hennequin,
    “Natural continual learning: success is a journey, not (just) a destination,”
    *NeurIPS*, 2021.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] T.-C. Kao, K. Jensen, G. van de Ven, A. Bernacchia, 和 G. Hennequin，“自然持续学习：成功是一个旅程，而不仅仅是一个目的地”，*NeurIPS*，2021。'
- en: '[70] P. Pan, S. Swaroop, A. Immer, R. Eschenhagen, R. Turner, and M. E. E.
    Khan, “Continual deep learning by functional regularisation of memorable past,”
    *NeurIPS*, 2020.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] P. Pan, S. Swaroop, A. Immer, R. Eschenhagen, R. Turner, 和 M. E. E. Khan，“通过对可记忆的过去进行功能正则化实现持续深度学习”，*NeurIPS*，2020。'
- en: '[71] M. K. Titsias, J. Schwarz, A. G. d. G. Matthews, R. Pascanu, and Y. W.
    Teh, “Functional regularisation for continual learning with gaussian processes,”
    in *ICLR*, 2020.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] M. K. Titsias, J. Schwarz, A. G. d. G. Matthews, R. Pascanu, 和 Y. W. Teh，“用于持续学习的高斯过程功能正则化”，发表于
    *ICLR*，2020。'
- en: '[72] S. Kapoor, T. Karaletsos, and T. D. Bui, “Variational auto-regressive
    gaussian processes for continual learning,” in *ICML*, 2021.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] S. Kapoor, T. Karaletsos, 和 T. D. Bui，“用于持续学习的变分自回归高斯过程”，发表于 *ICML*，2021。'
- en: '[73] T. G. Rudner, F. B. Smith, Q. Feng, Y. W. Teh, and Y. Gal, “Continual
    learning via sequential function-space variational inference,” in *ICML*, 2022.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] T. G. Rudner, F. B. Smith, Q. Feng, Y. W. Teh, 和 Y. Gal，“通过序列函数空间变分推断进行持续学习”，发表于
    *ICML*，2022。'
- en: '[74] A. Kumar, S. Chatterjee, and P. Rai, “Bayesian structural adaptation for
    continual learning,” in *ICML*, 2021.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] A. Kumar, S. Chatterjee, 和 P. Rai，“用于持续学习的贝叶斯结构适应”，发表于 *ICML*，2021。'
- en: '[75] N. Mehta, K. Liang, V. K. Verma, and L. Carin, “Continual learning using
    a bayesian nonparametric dictionary of weight factors,” in *AISTATS*, 2021.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] N. Mehta, K. Liang, V. K. Verma, 和 L. Carin，“使用贝叶斯非参数字典的权重因子进行持续学习”，发表于
    *AISTATS*，2021。'
- en: '[76] A. Chaudhry, M. Rohrbach, M. Elhoseiny, T. Ajanthan, P. K. Dokania, P. H. S.
    Torr, and M. Ranzato, “Continual learning with tiny episodic memories,” 2019.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] A. Chaudhry, M. Rohrbach, M. Elhoseiny, T. Ajanthan, P. K. Dokania, P.
    H. S. Torr, 和 M. Ranzato，“带有微小情节记忆的持续学习”，2019。'
- en: '[77] X. Jin, A. Sadhu, J. Du, and X. Ren, “Gradient-based editing of memory
    examples for online task-free continual learning,” *NeurIPS*, 2021.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] X. Jin, A. Sadhu, J. Du, 和 X. Ren，“基于梯度的记忆示例编辑用于在线无任务持续学习”，*NeurIPS*，2021。'
- en: '[78] Z. Wang, L. Shen, L. Fang, Q. Suo, T. Duan, and M. Gao, “Improving task-free
    continual learning by distributionally robust memory evolution,” in *ICML*, 2022.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] Z. Wang, L. Shen, L. Fang, Q. Suo, T. Duan, 和 M. Gao，“通过分布鲁棒记忆演化改进无任务持续学习”，发表于
    *ICML*，2022。'
- en: '[79] S. Lee, J. Ha, D. Zhang, and G. Kim, “A neural dirichlet process mixture
    model for task-free continual learning,” in *ICLR*, 2020.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] S. Lee, J. Ha, D. Zhang, 和 G. Kim，“用于无任务持续学习的神经狄利克雷过程混合模型”，发表于 *ICLR*，2020。'
- en: '[80] R. Ardywibowo, Z. Huo, Z. Wang, B. J. Mortazavi, S. Huang, and X. Qian,
    “VariGrow: Variational architecture growing for task-agnostic continual learning
    based on Bayesian novelty,” in *ICML*, 2022.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] R. Ardywibowo, Z. Huo, Z. Wang, B. J. Mortazavi, S. Huang, 和 X. Qian，“VariGrow：基于贝叶斯新颖性的任务无关持续学习的变分架构生长”，发表于
    *ICML*，2022。'
- en: '[81] F. Ye and A. G. Bors, “Task-free continual learning via online discrepancy
    distance learning,” in *NeurIPS*, 2022.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] F. Ye 和 A. G. Bors，“通过在线差异距离学习实现无任务持续学习”，发表于 *NeurIPS*，2022。'
- en: '[82] D. Shim, Z. Mai, J. Jeong, S. Sanner, H. Kim, and J. Jang, “Online class-incremental
    continual learning with adversarial shapley value,” in *AAAI*, 2021.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] D. Shim, Z. Mai, J. Jeong, S. Sanner, H. Kim, 和 J. Jang，“带有对抗Shapley值的在线类增量持续学习”，发表于
    *AAAI*，2021。'
- en: '[83] Y. Guo, B. Liu, and D. Zhao, “Online continual learning through mutual
    information maximization,” in *ICML*, 2022.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] Y. Guo, B. Liu, 和 D. Zhao，“通过互信息最大化进行在线持续学习”，发表于 *ICML*，2022。'
- en: '[84] J. Yoon, D. Madaan, E. Yang, and S. J. Hwang, “Online coreset selection
    for rehearsal-based continual learning,” in *ICLR*, 2022.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] J. Yoon, D. Madaan, E. Yang, 和 S. J. Hwang，“用于基于重演的持续学习的在线核心集选择，”发表于 *ICLR*，2022。'
- en: '[85] Y. Gu, X. Yang, K. Wei, and C. Deng, “Not just selection, but exploration:
    Online class-incremental continual learning via dual view consistency,” in *CVPR*,
    2022.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] Y. Gu, X. Yang, K. Wei, 和 C. Deng，“不仅仅是选择，而是探索：通过双视图一致性进行在线类别增量持续学习，”发表于
    *CVPR*，2022。'
- en: '[86] G. Gupta, K. Yadav, and L. Paull, “La-maml: Look-ahead meta learning for
    continual learning,” in *NeurIPS*, 2020.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] G. Gupta, K. Yadav, 和 L. Paull，“La-maml：面向持续学习的前瞻性元学习，”发表于 *NeurIPS*，2020。'
- en: '[87] Y. Liu, W. Zhu, and S. Ren, “Navigating memory construction by global
    pseudo-task simulation for continual learning,” in *NeurIPS*, 2022.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] Y. Liu, W. Zhu, 和 S. Ren，“通过全球伪任务模拟来导航记忆构建以进行持续学习，”发表于 *NeurIPS*，2022。'
- en: '[88] E. Fini, S. Lathuiliere, E. Sangineto, M. Nabi, and E. Ricci, “Online
    continual learning under extreme memory constraints,” in *ECCV*, 2020.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] E. Fini, S. Lathuiliere, E. Sangineto, M. Nabi, 和 E. Ricci，“在极端内存限制下的在线持续学习，”发表于
    *ECCV*，2020。'
- en: '[89] J. Schwarz, J. Luketina, W. M. Czarnecki, A. Grabska-Barwinska, Y. W.
    Teh, R. Pascanu, and R. Hadsell, “Progress and compress: A scalable framework
    for continual learning,” in *ICML*, 2018.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] J. Schwarz, J. Luketina, W. M. Czarnecki, A. Grabska-Barwinska, Y. W.
    Teh, R. Pascanu, 和 R. Hadsell，“进步与压缩：一种可扩展的持续学习框架，”发表于 *ICML*，2018。'
- en: '[90] F. M. Castro, M. J. Marín-Jiménez, N. Guil, C. Schmid, and K. Alahari,
    “End-to-end incremental learning,” in *ECCV*, 2018.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] F. M. Castro, M. J. Marín-Jiménez, N. Guil, C. Schmid, 和 K. Alahari，“端到端增量学习，”发表于
    *ECCV*，2018。'
- en: '[91] A. Prabhu, P. H. Torr, and P. K. Dokania, “Gdumb: A simple approach that
    questions our progress in continual learning,” in *ECCV*, 2020.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] A. Prabhu, P. H. Torr, 和 P. K. Dokania，“GDumb：一种质疑我们持续学习进展的简单方法，”发表于 *ECCV*，2020。'
- en: '[92] Y. Wu, Y. Chen, L. Wang, Y. Ye, Z. Liu, Y. Guo, and Y. Fu, “Large scale
    incremental learning,” in *CVPR*, 2019.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] Y. Wu, Y. Chen, L. Wang, Y. Ye, Z. Liu, Y. Guo, 和 Y. Fu，“大规模增量学习，”发表于
    *CVPR*，2019。'
- en: '[93] H. Ahn, J. Kwak, S. Lim, H. Bang, H. Kim, and T. Moon, “Ss-il: Separated
    softmax for incremental learning,” in *ICCV*, 2021.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] H. Ahn, J. Kwak, S. Lim, H. Bang, H. Kim, 和 T. Moon，“SS-IL：用于增量学习的分离软最大值，”发表于
    *ICCV*，2021。'
- en: '[94] A. Chrysakis and M.-F. Moens, “Online continual learning from imbalanced
    data,” in *ICML*, 2020.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] A. Chrysakis 和 M.-F. Moens，“来自不平衡数据的在线持续学习，”发表于 *ICML*，2020。'
- en: '[95] C. D. Kim, J. Jeong, and G. Kim, “Imbalanced continual learning with partitioning
    reservoir sampling,” in *ECCV*, 2020.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] C. D. Kim, J. Jeong, 和 G. Kim，“带有分区的池化抽样的不平衡持续学习，”发表于 *ECCV*，2020。'
- en: '[96] S. Sun, D. Calandriello, H. Hu, A. Li, and M. Titsias, “Information-theoretic
    online memory selection for continual learning,” in *ICLR*, 2022.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] S. Sun, D. Calandriello, H. Hu, A. Li, 和 M. Titsias，“用于持续学习的信息论在线记忆选择，”发表于
    *ICLR*，2022。'
- en: '[97] E. Belouadah and A. Popescu, “Il2m: Class incremental learning with dual
    memory,” in *ICCV*, 2019.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] E. Belouadah 和 A. Popescu，“IL2M：具有双重记忆的类别增量学习，”发表于 *ICCV*，2019。'
- en: '[98] B. Zhao, X. Xiao, G. Gan, B. Zhang, and S.-T. Xia, “Maintaining discrimination
    and fairness in class incremental learning,” in *CVPR*, 2020.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] B. Zhao, X. Xiao, G. Gan, B. Zhang, 和 S.-T. Xia，“在类别增量学习中维护辨别性和公平性，”发表于
    *CVPR*，2020。'
- en: '[99] A. Chrysakis and M.-F. Moens, “Online bias correction for task-free continual
    learning,” in *ICLR*, 2023.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] A. Chrysakis 和 M.-F. Moens，“任务无关持续学习的在线偏差校正，”发表于 *ICLR*，2023。'
- en: '[100] W. Ren, P. Wang, X. Li, C. E. Hughes, and Y. Fu, “Semi-supervised drifted
    stream learning with short lookback,” in *SIGKDD*, 2022.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] W. Ren, P. Wang, X. Li, C. E. Hughes, 和 Y. Fu，“带短回顾的半监督漂移流学习，”发表于 *SIGKDD*，2022。'
- en: '[101] L. Wang, K. Yang, C. Li, L. Hong, Z. Li, and J. Zhu, “Ordisco: Effective
    and efficient usage of incremental unlabeled data for semi-supervised continual
    learning,” in *CVPR*, 2021.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] L. Wang, K. Yang, C. Li, L. Hong, Z. Li, 和 J. Zhu，“Ordisco：半监督持续学习中增量未标记数据的有效与高效使用，”发表于
    *CVPR*，2021。'
- en: '[102] J. Smith, J. Balloch, Y.-C. Hsu, and Z. Kira, “Memory-efficient semi-supervised
    continual learning: The world is its own replay buffer,” in *IJCNN*, 2021.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] J. Smith, J. Balloch, Y.-C. Hsu, 和 Z. Kira，“记忆高效的半监督持续学习：世界是它自己的重播缓冲区，”发表于
    *IJCNN*，2021。'
- en: '[103] B. Yang, M. Lin, Y. Zhang, B. Liu, X. Liang, R. Ji, and Q. Ye, “Dynamic
    support network for few-shot class incremental learning,” *TPAMI*, 2022.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] B. Yang, M. Lin, Y. Zhang, B. Liu, X. Liang, R. Ji, 和 Q. Ye，“用于少样本类别增量学习的动态支持网络，”*TPAMI*，2022。'
- en: '[104] X. Tao, X. Hong, X. Chang, S. Dong, X. Wei, and Y. Gong, “Few-shot class-incremental
    learning,” in *CVPR*, 2020.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] X. Tao, X. Hong, X. Chang, S. Dong, X. Wei, 和 Y. Gong，“少样本类别增量学习，”发表于
    *CVPR*，2020。'
- en: '[105] K. Zhu, Y. Cao, W. Zhai, J. Cheng, and Z.-J. Zha, “Self-promoted prototype
    refinement for few-shot class-incremental learning,” in *CVPR*, 2021.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] K. Zhu, Y. Cao, W. Zhai, J. Cheng, 和 Z.-J. Zha，“自我促进的原型精炼用于少样本类增量学习”，发表于
    *CVPR*，2021年。'
- en: '[106] M. Hersche, G. Karunaratne, G. Cherubini, L. Benini, A. Sebastian, and
    A. Rahimi, “Constrained few-shot class-incremental learning,” in *CVPR*, 2022.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] M. Hersche, G. Karunaratne, G. Cherubini, L. Benini, A. Sebastian, 和
    A. Rahimi，“受限的少样本类增量学习”，发表于 *CVPR*，2022年。'
- en: '[107] Y. Yang, H. Yuan, X. Li, Z. Lin, P. Torr, and D. Tao, “Neural collapse
    inspired feature-classifier alignment for few-shot class-incremental learning,”
    in *ICLR*, 2023.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] Y. Yang, H. Yuan, X. Li, Z. Lin, P. Torr, 和 D. Tao，“神经崩溃启发的特征-分类器对齐用于少样本类增量学习”，发表于
    *ICLR*，2023年。'
- en: '[108] D.-W. Zhou, H.-J. Ye, L. Ma, D. Xie, S. Pu, and D.-C. Zhan, “Few-shot
    class-incremental learning by sampling multi-phase tasks,” *TPAMI*, 2022.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] D.-W. Zhou, H.-J. Ye, L. Ma, D. Xie, S. Pu, 和 D.-C. Zhan，“通过采样多阶段任务进行少样本类增量学习”，*TPAMI*，2022年。'
- en: '[109] Z. Chi, L. Gu, H. Liu, Y. Wang, Y. Yu, and J. Tang, “Metafscil: a meta-learning
    approach for few-shot class incremental learning,” in *CVPR*, 2022.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] Z. Chi, L. Gu, H. Liu, Y. Wang, Y. Yu, 和 J. Tang，“Metafscil：一种用于少样本类增量学习的元学习方法”，发表于
    *CVPR*，2022年。'
- en: '[110] P. Mazumder, P. Singh, and P. Rai, “Few-shot lifelong learning,” in *AAAI*,
    2021.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] P. Mazumder, P. Singh, 和 P. Rai，“少样本终身学习”，发表于 *AAAI*，2021年。'
- en: '[111] D.-Y. Kim, D.-J. Han, J. Seo, and J. Moon, “Warping the space: Weight
    space rotation for class-incremental few-shot learning,” in *ICLR*, 2023.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] D.-Y. Kim, D.-J. Han, J. Seo, 和 J. Moon，“扭曲空间：用于类增量少样本学习的权重空间旋转”，发表于
    *ICLR*，2023年。'
- en: '[112] D. Rao, F. Visin, A. A. Rusu, Y. W. Teh, R. Pascanu, and R. Hadsell,
    “Continual unsupervised representation learning,” in *NeurIPS*, 2019.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] D. Rao, F. Visin, A. A. Rusu, Y. W. Teh, R. Pascanu, 和 R. Hadsell，“持续的无监督表示学习”，发表于
    *NeurIPS*，2019年。'
- en: '[113] D. Madaan, J. Yoon, Y. Li, Y. Liu, and S. J. Hwang, “Representational
    continuity for unsupervised continual learning,” in *ICLR*, 2022.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] D. Madaan, J. Yoon, Y. Li, Y. Liu, 和 S. J. Hwang，“无监督持续学习的表征连续性”，发表于
    *ICLR*，2022年。'
- en: '[114] H. Cha, J. Lee, and J. Shin, “Co2l: Contrastive continual learning,”
    in *ICCV*, 2021.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] H. Cha, J. Lee, 和 J. Shin，“Co2l：对比持续学习”，发表于 *ICCV*，2021年。'
- en: '[115] M. Davari, N. Asadi, S. Mudur, R. Aljundi, and E. Belilovsky, “Probing
    representation forgetting in supervised and unsupervised continual learning,”
    in *CVPR*, 2022.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] M. Davari, N. Asadi, S. Mudur, R. Aljundi, 和 E. Belilovsky，“探测监督和无监督持续学习中的表征遗忘”，发表于
    *CVPR*，2022年。'
- en: '[116] H. Zhang, M. Cissé, Y. N. Dauphin, and D. Lopez-Paz, “mixup: Beyond empirical
    risk minimization,” in *ICLR*, 2018.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] H. Zhang, M. Cissé, Y. N. Dauphin, 和 D. Lopez-Paz，“mixup：超越经验风险最小化”，发表于
    *ICLR*，2018年。'
- en: '[117] A. Pentina and C. Lampert, “A pac-bayesian bound for lifelong learning,”
    in *ICML*, 2014.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] A. Pentina 和 C. Lampert，“终身学习的pac-bayesian界限”，发表于 *ICML*，2014年。'
- en: '[118] R. Karakida and S. Akaho, “Learning curves for continual learning in
    neural networks: Self-knowledge transfer and forgetting,” in *ICLR*, 2022.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] R. Karakida 和 S. Akaho，“神经网络中持续学习的学习曲线：自我知识转移与遗忘”，发表于 *ICLR*，2022年。'
- en: '[119] G. Kim, C. Xiao, T. Konishi, Z. Ke, and B. Liu, “A theoretical study
    on solving continual learning,” in *NeurIPS*, 2022.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] G. Kim, C. Xiao, T. Konishi, Z. Ke, 和 B. Liu，“关于解决持续学习的理论研究”，发表于 *NeurIPS*，2022年。'
- en: '[120] I. Evron, E. Moroshko, G. Buzaglo, M. Khriesh, B. Marjieh, N. Srebro,
    and D. Soudry, “Continual learning in linear classification on separable data,”
    in *ICML*, 2023.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] I. Evron, E. Moroshko, G. Buzaglo, M. Khriesh, B. Marjieh, N. Srebro,
    和 D. Soudry，“可分数据上的线性分类中的持续学习”，发表于 *ICML*，2023年。'
- en: '[121] L. Peng, P. V. Giampouras, and R. Vidal, “The ideal continual learner:
    An agent that never forgets,” in *ICML*, 2023.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] L. Peng, P. V. Giampouras, 和 R. Vidal，“理想的持续学习者：一个永远不会遗忘的智能体”，发表于 *ICML*，2023年。'
- en: '[122] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts,
    P. Barham, H. W. Chung, C. Sutton, S. Gehrmann *et al.*, “Palm: Scaling language
    modeling with pathways,” *arXiv preprint arXiv:2204.02311*, 2022.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts,
    P. Barham, H. W. Chung, C. Sutton, S. Gehrmann *等*，“Palm：通过路径扩展语言建模”，*arXiv 预印本
    arXiv:2204.02311*，2022年。'
- en: '[123] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix,
    B. Rozière, N. Goyal, E. Hambro, F. Azhar *et al.*, “Llama: Open and efficient
    foundation language models,” *arXiv preprint arXiv:2302.13971*, 2023.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix,
    B. Rozière, N. Goyal, E. Hambro, F. Azhar *等*，“Llama：开放而高效的基础语言模型”，*arXiv 预印本
    arXiv:2302.13971*，2023年。'
- en: '[124] M. Jagielski, O. Thakkar, F. Tramer, D. Ippolito, K. Lee, N. Carlini,
    E. Wallace, S. Song, A. G. Thakurta, N. Papernot, and C. Zhang, “Measuring forgetting
    of memorized training examples,” in *ICLR*, 2023.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] M. Jagielski, O. Thakkar, F. Tramer, D. Ippolito, K. Lee, N. Carlini,
    E. Wallace, S. Song, A. G. Thakurta, N. Papernot, 和 C. Zhang，“测量记忆化训练样本的遗忘，”发表于
    *ICLR*，2023年。'
- en: '[125] C. Lee, K. Cho, and W. Kang, “Mixout: Effective regularization to finetune
    large-scale pretrained language models,” in *ICLR*, 2020.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] C. Lee, K. Cho, 和 W. Kang，“Mixout：有效的正则化方法以微调大规模预训练语言模型，”发表于 *ICLR*，2020年。'
- en: '[126] J. Howard and S. Ruder, “Universal language model fine-tuning for text
    classification,” in *ACL*, 2018.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] J. Howard 和 S. Ruder，“通用语言模型微调用于文本分类，”发表于 *ACL*，2018年。'
- en: '[127] C. Chelba and A. Acero, “Adaptation of maximum entropy capitalizer: Little
    data can help a lot,” *Computer Speech & Language*, 2006.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] C. Chelba 和 A. Acero，“最大熵资本化器的适应：少量数据可以有很大帮助，” *计算机语音与语言*，2006年。'
- en: '[128] T. Zhang, F. Wu, A. Katiyar, K. Q. Weinberger, and Y. Artzi, “Revisiting
    few-sample bert fine-tuning,” in *ICLR*, 2020.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] T. Zhang, F. Wu, A. Katiyar, K. Q. Weinberger, 和 Y. Artzi，“重新审视少样本BERT微调，”发表于
    *ICLR*，2020年。'
- en: '[129] Z. Fatemi, C. Xing, W. Liu, and C. Xiong, “Improving gender fairness
    of pre-trained language models without catastrophic forgetting,” in *ACL*, 2023.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] Z. Fatemi, C. Xing, W. Liu, 和 C. Xiong，“在不发生灾难性遗忘的情况下提高预训练语言模型的性别公平性，”发表于
    *ACL*，2023年。'
- en: '[130] X. Dong, A. T. Luu, M. Lin, S. Yan, and H. Zhang, “How should pre-trained
    language models be fine-tuned towards adversarial robustness?” *NeurIPS*, 2021.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] X. Dong, A. T. Luu, M. Lin, S. Yan, 和 H. Zhang，“如何将预训练语言模型微调至对抗鲁棒性？”
    *NeurIPS*，2021年。'
- en: '[131] S. Chen, Y. Hou, Y. Cui, W. Che, T. Liu, and X. Yu, “Recall and learn:
    Fine-tuning deep pretrained language models with less forgetting,” in *EMNLP*,
    2020.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] S. Chen, Y. Hou, Y. Cui, W. Che, T. Liu, 和 X. Yu，“回忆与学习：通过减少遗忘来微调深度预训练语言模型，”发表于
    *EMNLP*，2020年。'
- en: '[132] D. Hu, S. Yan, Q. Lu, L. HONG, H. Hu, Y. Zhang, Z. Li, X. Wang, and J. Feng,
    “How well does self-supervised pre-training perform with streaming data?” in *ICLR*,
    2022.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] D. Hu, S. Yan, Q. Lu, L. HONG, H. Hu, Y. Zhang, Z. Li, X. Wang, 和 J.
    Feng，“自监督预训练在流数据上的表现如何？”发表于 *ICLR*，2022年。'
- en: '[133] S. Purushwalkam, P. Morgado, and A. Gupta, “The challenges of continuous
    self-supervised learning,” in *ECCV*, 2022.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] S. Purushwalkam, P. Morgado, 和 A. Gupta，“持续自监督学习的挑战，”发表于 *ECCV*，2022年。'
- en: '[134] Z. Lin, Y. Wang, and H. Lin, “Continual contrastive learning for image
    classification,” in *ICME*, 2022.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] Z. Lin, Y. Wang, 和 H. Lin，“用于图像分类的持续对比学习，”发表于 *ICME*，2022年。'
- en: '[135] N. Lukas, A. Salem, R. Sim, S. Tople, L. Wutschitz, and S. Zanella-Béguelin,
    “Analyzing leakage of personally identifiable information in language models,”
    *S&P*, 2023.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] N. Lukas, A. Salem, R. Sim, S. Tople, L. Wutschitz, 和 S. Zanella-Béguelin，“分析语言模型中的个人身份信息泄露，”
    *S&P*，2023年。'
- en: '[136] N. Carlini, D. Ippolito, M. Jagielski, K. Lee, F. Tramer, and C. Zhang,
    “Quantifying memorization across neural language models,” in *ICLR*, 2023.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] N. Carlini, D. Ippolito, M. Jagielski, K. Lee, F. Tramer, 和 C. Zhang，“量化神经语言模型的记忆，”发表于
    *ICLR*，2023年。'
- en: '[137] Z. Ke, B. Liu, N. Ma, H. Xu, and L. Shu, “Achieving forgetting prevention
    and knowledge transfer in continual learning,” *NeurIPS*, 2021.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] Z. Ke, B. Liu, N. Ma, H. Xu, 和 L. Shu，“在持续学习中实现遗忘预防和知识转移，” *NeurIPS*，2021年。'
- en: '[138] T. Wu, M. Caccia, Z. Li, Y.-F. Li, G. Qi, and G. Haffari, “Pretrained
    language model in continual learning: A comparative study,” in *ICLR*, 2022.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] T. Wu, M. Caccia, Z. Li, Y.-F. Li, G. Qi, 和 G. Haffari，“持续学习中的预训练语言模型：比较研究，”发表于
    *ICLR*，2022年。'
- en: '[139] T. Scialom, T. Chakrabarty, and S. Muresan, “Fine-tuned language models
    are continual learners,” in *EMNLP*, 2022.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] T. Scialom, T. Chakrabarty, 和 S. Muresan，“微调后的语言模型是持续学习者，”发表于 *EMNLP*，2022年。'
- en: '[140] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” *NeurIPS*, 2017.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, 和 I. Polosukhin，“注意力即一切，” *NeurIPS*，2017年。'
- en: '[141] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner,
    M. Dehghani, M. Minderer, G. Heigold, S. Gelly *et al.*, “An image is worth 16x16
    words: Transformers for image recognition at scale,” in *ICLR*, 2021.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T.
    Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly *等*，“图像的价值相当于16x16个词：大规模图像识别的变换器，”发表于
    *ICLR*，2021年。'
- en: '[142] O. Ostapenko, T. Lesort, P. Rodríguez, M. R. Arefin, A. Douillard, I. Rish,
    and L. Charlin, “Continual learning with foundation models: An empirical study
    of latent replay,” in *Conference on Lifelong Learning Agents*, 2022.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] O. Ostapenko, T. Lesort, P. Rodríguez, M. R. Arefin, A. Douillard, I.
    Rish, 和 L. Charlin，“使用基础模型进行持续学习：潜在回放的实证研究，”发表于 *终身学习代理大会*，2022年。'
- en: '[143] S. V. Mehta, D. Patil, S. Chandar, and E. Strubell, “An empirical investigation
    of the role of pre-training in lifelong learning,” *ICML*, 2021.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] S. V. Mehta, D. Patil, S. Chandar, 和 E. Strubell, “预训练在终身学习中的作用的实证研究，”
    *ICML*，2021。'
- en: '[144] V. V. Ramasesh, A. Lewkowycz, and E. Dyer, “Effect of scale on catastrophic
    forgetting in neural networks,” in *ICLR*, 2022.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] V. V. Ramasesh, A. Lewkowycz, 和 E. Dyer, “规模对神经网络灾难性遗忘的影响，” 发表在 *ICLR*，2022。'
- en: '[145] D.-W. Zhou, H.-J. Ye, D.-C. Zhan, and Z. Liu, “Revisiting class-incremental
    learning with pre-trained models: Generalizability and adaptivity are all you
    need,” *arXiv preprint arXiv:2303.07338*, 2023.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] D.-W. Zhou, H.-J. Ye, D.-C. Zhan, 和 Z. Liu, “重新审视使用预训练模型的类增量学习：你只需要泛化能力和适应性，”
    *arXiv 预印本 arXiv:2303.07338*，2023。'
- en: '[146] B. Ermis, G. Zappella, M. Wistuba, A. Rawal, and C. Archambeau, “Memory
    efficient continual learning with transformers,” in *NeurIPS*, 2022.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] B. Ermis, G. Zappella, M. Wistuba, A. Rawal, 和 C. Archambeau, “基于变换器的记忆高效持续学习，”
    发表在 *NeurIPS*，2022。'
- en: '[147] Z. Wang, Z. Zhang, C.-Y. Lee, H. Zhang, R. Sun, X. Ren, G. Su, V. Perot,
    J. Dy, and T. Pfister, “Learning to prompt for continual learning,” in *CVPR*,
    2022.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] Z. Wang, Z. Zhang, C.-Y. Lee, H. Zhang, R. Sun, X. Ren, G. Su, V. Perot,
    J. Dy, 和 T. Pfister, “学习提示以支持持续学习，” 发表在 *CVPR*，2022。'
- en: '[148] Z. Wang, Z. Zhang, S. Ebrahimi, R. Sun, H. Zhang, C. Lee, X. Ren, G. Su,
    V. Perot, J. G. Dy, and T. Pfister, “Dualprompt: Complementary prompting for rehearsal-free
    continual learning,” in *ECCV*, 2022.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] Z. Wang, Z. Zhang, S. Ebrahimi, R. Sun, H. Zhang, C. Lee, X. Ren, G.
    Su, V. Perot, J. G. Dy, 和 T. Pfister, “Dualprompt：无需复习的补充提示持续学习，” 发表在 *ECCV*，2022。'
- en: '[149] Y. Wang, Z. Huang, and X. Hong, “S-prompts learning with pre-trained
    transformers: An occam’s razor for domain incremental learning,” in *NeurIPS*,
    2022.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] Y. Wang, Z. Huang, 和 X. Hong, “基于预训练变换器的 S-prompts 学习：领域增量学习的奥卡姆剃刀，”
    发表在 *NeurIPS*，2022。'
- en: '[150] A. Razdaibiedina, Y. Mao, R. Hou, M. Khabsa, M. Lewis, and A. Almahairi,
    “Progressive prompts: Continual learning for language models,” in *ICLR*, 2023.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] A. Razdaibiedina, Y. Mao, R. Hou, M. Khabsa, M. Lewis, 和 A. Almahairi,
    “渐进提示：语言模型的持续学习，” 发表在 *ICLR*，2023。'
- en: '[151] H. Liu, M. Long, J. Wang, and Y. Wang, “Learning to adapt to evolving
    domains,” *NeurIPS*, 2020.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] H. Liu, M. Long, J. Wang, 和 Y. Wang, “学习适应不断演变的领域，” *NeurIPS*，2020。'
- en: '[152] A. Bobu, E. Tzeng, J. Hoffman, and T. Darrell, “Adapting to continuously
    shifting domains,” 2018.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] A. Bobu, E. Tzeng, J. Hoffman, 和 T. Darrell, “适应不断变化的领域，” 2018。'
- en: '[153] M. Rostami, “Lifelong domain adaptation via consolidated internal distribution,”
    in *NeurIPS*, 2021.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] M. Rostami, “通过合并内部分布进行终身领域适应，” 发表在 *NeurIPS*，2021。'
- en: '[154] T. Panagiotakopoulos, P. L. Dovesi, L. Härenstam-Nielsen, and M. Poggi,
    “Online domain adaptation for semantic segmentation in ever-changing conditions,”
    in *ECCV*, 2022.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] T. Panagiotakopoulos, P. L. Dovesi, L. Härenstam-Nielsen, 和 M. Poggi,
    “在不断变化的条件下进行语义分割的在线领域适应，” 发表在 *ECCV*，2022。'
- en: '[155] S. Tang, P. Su, D. Chen, and W. Ouyang, “Gradient regularized contrastive
    learning for continual domain adaptation,” in *AAAI*, 2021.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] S. Tang, P. Su, D. Chen, 和 W. Ouyang, “用于持续领域适应的梯度正则化对比学习，” 发表在 *AAAI*，2021。'
- en: '[156] R. Volpi, D. Larlus, and G. Rogez, “Continual adaptation of visual representations
    via domain randomization and meta-learning,” in *CVPR*, 2021.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] R. Volpi, D. Larlus, 和 G. Rogez, “通过领域随机化和元学习进行视觉表征的持续适应，” 发表在 *CVPR*，2021。'
- en: '[157] A. M. N. Taufique, C. S. Jahan, and A. Savakis, “Unsupervised continual
    learning for gradually varying domains,” in *CVPR Workshops*, 2022.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] A. M. N. Taufique, C. S. Jahan, 和 A. Savakis, “针对逐渐变化领域的无监督持续学习，” 发表在
    *CVPR Workshops*，2022。'
- en: '[158] S. Yang, Y. Wang, J. Van De Weijer, L. Herranz, and S. Jui, “Generalized
    source-free domain adaptation,” in *ICCV*, 2021.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] S. Yang, Y. Wang, J. Van De Weijer, L. Herranz, 和 S. Jui, “广义源无关领域适应，”
    发表在 *ICCV*，2021。'
- en: '[159] H. Feng, Z. Yang, H. Chen, T. Pang, C. Du, M. Zhu, W. Chen, and S. Yan,
    “Cosda: Continual source-free domain adaptation,” *arXiv preprint arXiv:2304.06627*,
    2023.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[159] H. Feng, Z. Yang, H. Chen, T. Pang, C. Du, M. Zhu, W. Chen, 和 S. Yan,
    “Cosda: 连续源无关领域适应，” *arXiv 预印本 arXiv:2304.06627*，2023。'
- en: '[160] W. Ahmed, P. Morerio, and V. Murino, “Continual source-free unsupervised
    domain adaptation,” *arXiv preprint arXiv:2304.07374*, 2023.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[160] W. Ahmed, P. Morerio, 和 V. Murino, “持续源无关无监督领域适应，” *arXiv 预印本 arXiv:2304.07374*，2023。'
- en: '[161] D. Wang, E. Shelhamer, S. Liu, B. Olshausen, and T. Darrell, “Tent: Fully
    test-time adaptation by entropy minimization,” in *ICLR*, 2021.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[161] D. Wang, E. Shelhamer, S. Liu, B. Olshausen, 和 T. Darrell, “Tent：通过熵最小化进行完全测试时间适应，”
    发表在 *ICLR*，2021。'
- en: '[162] S. Niu, J. Wu, Y. Zhang, Y. Chen, S. Zheng, P. Zhao, and M. Tan, “Efficient
    test-time model adaptation without forgetting,” in *ICML*, 2022.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[162] S. Niu, J. Wu, Y. Zhang, Y. Chen, S. Zheng, P. Zhao, 和 M. Tan, “高效的测试时间模型适应而不遗忘，”
    发表在 *ICML*，2022。'
- en: '[163] T. Gong, J. Jeong, T. Kim, Y. Kim, J. Shin, and S.-J. Lee, “Note: Robust
    continual test-time adaptation against temporal correlation,” *NeurIPS*, 2022.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[163] T. Gong, J. Jeong, T. Kim, Y. Kim, J. Shin, 和 S.-J. Lee，“注：对抗时间相关的鲁棒连续测试时间适应，”
    *NeurIPS*，2022年。'
- en: '[164] S. Niu, J. Wu, Y. Zhang, Z. Wen, Y. Chen, P. Zhao, and M. Tan, “Towards
    stable test-time adaptation in dynamic wild world,” in *ICLR*, 2023.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[164] S. Niu, J. Wu, Y. Zhang, Z. Wen, Y. Chen, P. Zhao, 和 M. Tan，“在动态野外世界中实现稳定的测试时间适应，”发表于
    *ICLR*，2023年。'
- en: '[165] J. Liang, R. He, and T. Tan, “A comprehensive survey on test-time adaptation
    under distribution shifts,” 2023.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[165] J. Liang, R. He, 和 T. Tan，“关于分布变化下的测试时间适应的综合调查，”2023年。'
- en: '[166] J. Hong, L. Lyu, J. Zhou, and M. Spranger, “MECTA: Memory-economic continual
    test-time model adaptation,” in *ICLR*, 2023.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[166] J. Hong, L. Lyu, J. Zhou, 和 M. Spranger，“MECTA: 记忆经济连续测试时间模型适应，”发表于 *ICLR*，2023年。'
- en: '[167] M. M. Zhang, S. Levine, and C. Finn, “MEMO: Test time robustness via
    adaptation and augmentation,” in *NeurIPS*, 2022.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[167] M. M. Zhang, S. Levine, 和 C. Finn，“MEMO：通过适应和增强实现测试时间鲁棒性，”发表于 *NeurIPS*，2022年。'
- en: '[168] Q. Wang, O. Fink, L. Van Gool, and D. Dai, “Continual test-time domain
    adaptation,” in *CVPR*, 2022.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[168] Q. Wang, O. Fink, L. Van Gool, 和 D. Dai，“连续测试时间领域适应，”发表于 *CVPR*，2022年。'
- en: '[169] Y. Gan, X. Ma, Y. Lou, Y. Bai, R. Zhang, N. Shi, and L. Luo, “Decorate
    the newcomers: Visual domain prompt for continual test time adaptation,” *AAAI*,
    2023.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[169] Y. Gan, X. Ma, Y. Lou, Y. Bai, R. Zhang, N. Shi, 和 L. Luo，“装饰新来者：用于连续测试时间适应的视觉领域提示，”
    *AAAI*，2023年。'
- en: '[170] J. Song, J. Lee, I. S. Kweon, and S. Choi, “Ecotta: Memory-efficient
    continual test-time adaptation via self-distilled regularization,” in *CVPR*,
    2023, pp. 11 920–11 929.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[170] J. Song, J. Lee, I. S. Kweon, 和 S. Choi，“Ecotta：通过自我蒸馏正则化实现记忆高效的连续测试时间适应，”发表于
    *CVPR*，2023年，第11 920–11 929页。'
- en: '[171] S. Choi, S. Yang, S. Choi, and S. Yun, “Improving test-time adaptation
    via shift-agnostic weight regularization and nearest source prototypes,” in *ECCV*,
    2022.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[171] S. Choi, S. Yang, S. Choi, 和 S. Yun，“通过无关转移的权重正则化和最近源原型改进测试时间适应，”发表于
    *ECCV*，2022年。'
- en: '[172] D. Brahma and P. Rai, “A probabilistic framework for lifelong test-time
    adaptation,” in *CVPR*, 2023.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[172] D. Brahma 和 P. Rai，“用于终身测试时间适应的概率框架，”发表于 *CVPR*，2023年。'
- en: '[173] S. Gidaris and N. Komodakis, “Dynamic few-shot visual learning without
    forgetting,” *CVPR*, 2018.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[173] S. Gidaris 和 N. Komodakis，“无遗忘的动态少样本视觉学习，” *CVPR*，2018年。'
- en: '[174] M. Ren, R. Liao, E. Fetaya, and R. S. Zemel, “Incremental few-shot learning
    with attention attractor networks,” *NeurIPS*, 2019.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[174] M. Ren, R. Liao, E. Fetaya, 和 R. S. Zemel，“通过注意力吸引子网络进行增量式少样本学习，” *NeurIPS*，2019年。'
- en: '[175] S. W. Yoon, D.-Y. Kim, J. Seo, and J. Moon, “Xtarnet: Learning to extract
    task-adaptive representation for incremental few-shot learning,” *ICML*, 2020.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[175] S. W. Yoon, D.-Y. Kim, J. Seo, 和 J. Moon，“Xtarnet：学习提取任务适应表示以进行增量式少样本学习，”
    *ICML*，2020年。'
- en: '[176] G. SHI, J. Chen, W. Zhang, L.-M. Zhan, and X.-M. Wu, “Overcoming catastrophic
    forgetting in incremental few-shot learning by finding flat minima,” in *NeurIPS*,
    2021.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[176] G. SHI, J. Chen, W. Zhang, L.-M. Zhan, 和 X.-M. Wu，“通过寻找平坦极小值克服增量式少样本学习中的灾难性遗忘，”发表于
    *NeurIPS*，2021年。'
- en: '[177] C. Finn, A. Rajeswaran, S. Kakade, and S. Levine, “Online meta-learning,”
    in *ICML*, 2019.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[177] C. Finn, A. Rajeswaran, S. Kakade, 和 S. Levine，“在线元学习，”发表于 *ICML*，2019年。'
- en: '[178] G. Jerfel, E. Grant, T. L. Griffiths, and K. Heller, “Reconciling meta-learning
    and continual learning with online mixtures of tasks,” *NeurIPS*, 2019.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[178] G. Jerfel, E. Grant, T. L. Griffiths, 和 K. Heller，“通过在线任务混合调和元学习和持续学习，”
    *NeurIPS*，2019年。'
- en: '[179] C. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning for
    fast adaptation of deep networks,” *ICML*, 2017.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[179] C. Finn, P. Abbeel, 和 S. Levine，“面向深度网络快速适应的模型无关元学习，” *ICML*，2017年。'
- en: '[180] P. Yap, H. Ritter, and D. Barber, “Addressing catastrophic forgetting
    in few-shot problems,” in *ICML*, 2020.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[180] P. Yap, H. Ritter, 和 D. Barber，“解决少样本问题中的灾难性遗忘，”发表于 *ICML*，2020年。'
- en: '[181] Q. Zhang, J. Fang, Z. Meng, S. Liang, and E. Yilmaz, “Variational continual
    bayesian meta-learning,” in *NeurIPS*, 2021.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[181] Q. Zhang, J. Fang, Z. Meng, S. Liang, 和 E. Yilmaz，“变分连续贝叶斯元学习，”发表于 *NeurIPS*，2021年。'
- en: '[182] Z. Wang, L. Shen, T. Duan, D. Zhan, L. Fang, and M. Gao, “Learning to
    learn and remember super long multi-domain task sequence,” in *CVPR*, 2022.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[182] Z. Wang, L. Shen, T. Duan, D. Zhan, L. Fang, 和 M. Gao，“学习学习和记忆超级长多领域任务序列，”发表于
    *CVPR*，2022年。'
- en: '[183] Z. Wang, T. Duan, L. Fang, Q. Suo, and M. Gao, “Meta learning on a sequence
    of imbalanced domains with difficulty awareness,” in *ICCV*, 2021.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[183] Z. Wang, T. Duan, L. Fang, Q. Suo, 和 M. Gao，“在具有困难感知的失衡领域序列上进行元学习，”发表于
    *ICCV*，2021年。'
- en: '[184] Z. Wang, L. Shen, L. Fang, Q. Suo, D. Zhan, T. Duan, and M. Gao, “Meta-learning
    with less forgetting on large-scale non-stationary task distributions,” in *ECCV*,
    2022.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[184] Z. Wang, L. Shen, L. Fang, Q. Suo, D. Zhan, T. Duan, 和 M. Gao，“在大规模非平稳任务分布中进行元学习，减少遗忘”，发表于
    *ECCV*，2022年。'
- en: '[185] H. Thanh-Tung and T. Tran, “On catastrophic forgetting and mode collapse
    in generative adversarial networks,” in *IJCNN*, 2020.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[185] H. Thanh-Tung 和 T. Tran，“关于生成对抗网络中的灾难性遗忘和模式崩溃”，发表于 *IJCNN*，2020年。'
- en: '[186] K. J. Liang, C. Li, G. Wang, and L. Carin, “Generative adversarial network
    training is a continual learning problem,” *arXiv preprint arXiv:1811.11083*,
    2018.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[186] K. J. Liang, C. Li, G. Wang, 和 L. Carin，“生成对抗网络训练是一个持续学习问题”，*arXiv 预印本
    arXiv:1811.11083*，2018年。'
- en: '[187] H. Chen, Y. Wang, C. Xu, Z. Yang, C. Liu, B. Shi, C. Xu, C. Xu, and Q. Tian,
    “Data-free learning of student networks,” in *ICCV*, 2019.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[187] H. Chen, Y. Wang, C. Xu, Z. Yang, C. Liu, B. Shi, C. Xu, C. Xu, 和 Q.
    Tian，“学生网络的无数据学习”，发表于 *ICCV*，2019年。'
- en: '[188] K. Binici, N. T. Pham, T. Mitra, and K. Leman, “Preventing catastrophic
    forgetting and distribution mismatch in knowledge distillation via synthetic data,”
    in *WACV*, 2022.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[188] K. Binici, N. T. Pham, T. Mitra, 和 K. Leman，“通过合成数据防止知识蒸馏中的灾难性遗忘和分布不匹配”，发表于
    *WACV*，2022年。'
- en: '[189] K. Binici, S. Aggarwal, N. T. Pham, K. Leman, and T. Mitra, “Robust and
    resource-efficient data-free knowledge distillation by generative pseudo replay,”
    in *AAAI*, 2022.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[189] K. Binici, S. Aggarwal, N. T. Pham, K. Leman, 和 T. Mitra，“通过生成伪重放实现鲁棒且资源高效的数据无知识蒸馏”，发表于
    *AAAI*，2022年。'
- en: '[190] K. Do, T. H. Le, D. Nguyen, D. Nguyen, H. Harikumar, T. Tran, S. Rana,
    and S. Venkatesh, “Momentum adversarial distillation: Handling large distribution
    shifts in data-free knowledge distillation,” *NeurIPS*, 2022.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[190] K. Do, T. H. Le, D. Nguyen, D. Nguyen, H. Harikumar, T. Tran, S. Rana,
    和 S. Venkatesh，“动量对抗蒸馏：处理数据无知识蒸馏中的大规模分布偏移”，*NeurIPS*，2022年。'
- en: '[191] G. Patel, K. R. Mopuri, and Q. Qiu, “Learning to retain while acquiring:
    Combating distribution-shift in adversarial data-free knowledge distillation,”
    in *CVPR*, 2023.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[191] G. Patel, K. R. Mopuri, 和 Q. Qiu，“在获取的同时学习保留：应对对抗数据无知识蒸馏中的分布偏移”，发表于 *CVPR*，2023年。'
- en: '[192] M. Zhai, L. Chen, F. Tung, J. He, M. Nawhal, and G. Mori, “Lifelong gan:
    Continual learning for conditional image generation,” in *ICCV*, 2019.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[192] M. Zhai, L. Chen, F. Tung, J. He, M. Nawhal, 和 G. Mori，“终身生成对抗网络：条件图像生成的持续学习”，发表于
    *ICCV*，2019年。'
- en: '[193] M. Zhai, L. Chen, and G. Mori, “Hyper-lifelonggan: Scalable lifelong
    learning for image conditioned generation,” in *CVPR*, 2021.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[193] M. Zhai, L. Chen, 和 G. Mori，“超终身生成对抗网络：可扩展的终身学习用于图像条件生成”，发表于 *CVPR*，2021年。'
- en: '[194] J. Ramapuram, M. Gregorova, and A. Kalousis, “Lifelong generative modeling,”
    *Neurocomputing*, 2020.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[194] J. Ramapuram, M. Gregorova, 和 A. Kalousis，“终身生成建模”，*神经计算*，2020年。'
- en: '[195] F. Ye and A. G. Bors, “Lifelong mixture of variational autoencoders,”
    *TNNLS*, 2021.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[195] F. Ye 和 A. G. Bors，“终身变分自编码器的混合”，*TNNLS*，2021年。'
- en: '[196] ——, “Continual variational autoencoder learning via online cooperative
    memorization,” in *ECCV*, 2022.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[196] ——，“通过在线合作记忆进行持续变分自编码器学习”，发表于 *ECCV*，2022年。'
- en: '[197] J. Ho, A. Jain, and P. Abbeel, “Denoising diffusion probabilistic models,”
    *NeurIPS*, 2020.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[197] J. Ho, A. Jain, 和 P. Abbeel，“去噪扩散概率模型”，发表于 *NeurIPS*，2020年。'
- en: '[198] C. Saharia, W. Chan, S. Saxena, L. Li, J. Whang, E. L. Denton, K. Ghasemipour,
    R. Gontijo Lopes, B. Karagol Ayan, T. Salimans *et al.*, “Photorealistic text-to-image
    diffusion models with deep language understanding,” *NeurIPS*, 2022.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[198] C. Saharia, W. Chan, S. Saxena, L. Li, J. Whang, E. L. Denton, K. Ghasemipour,
    R. Gontijo Lopes, B. Karagol Ayan, T. Salimans *等*，“具备深度语言理解的真实感文本到图像扩散模型”，*NeurIPS*，2022年。'
- en: '[199] E. Zhang, K. Wang, X. Xu, Z. Wang, and H. Shi, “Forget-me-not: Learning
    to forget in text-to-image diffusion models,” *arXiv preprint arXiv:2303.17591*,
    2023.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[199] E. Zhang, K. Wang, X. Xu, Z. Wang, 和 H. Shi，“不要忘记我：在文本到图像扩散模型中学习遗忘”，*arXiv
    预印本 arXiv:2303.17591*，2023年。'
- en: '[200] A. Heng and H. Soh, “Selective amnesia: A continual learning approach
    to forgetting in deep generative models,” *arXiv preprint arXiv:2305.10120*, 2023.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[200] A. Heng 和 H. Soh，“选择性遗忘：一种在深度生成模型中进行遗忘的持续学习方法”，*arXiv 预印本 arXiv:2305.10120*，2023年。'
- en: '[201] K. Khetarpal, M. Riemer, I. Rish, and D. Precup, “Towards continual reinforcement
    learning: A review and perspectives,” *Journal of Artificial Intelligence Research*,
    vol. 75, 2022.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[201] K. Khetarpal, M. Riemer, I. Rish, 和 D. Precup，“迈向持续强化学习：综述与展望”，*人工智能研究杂志*，第75卷，2022年。'
- en: '[202] M. Igl, G. Farquhar, J. Luketina, W. Boehmer, and S. Whiteson, “Transient
    non-stationarity and generalisation in deep reinforcement learning,” in *ICLR*,
    2021.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[202] M. Igl, G. Farquhar, J. Luketina, W. Boehmer, 和 S. Whiteson， “深度强化学习中的瞬态非平稳性和泛化”，发表于
    *ICLR*，2021年。'
- en: '[203] Z. Daniels, A. Raghavan, J. Hostetler, A. Rahman, I. Sur, M. Piacentino,
    and A. Divakaran, “Model-free generative replay for lifelong reinforcement learning:
    Application to starcraft-2,” 2022.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[203] Z. Daniels, A. Raghavan, J. Hostetler, A. Rahman, I. Sur, M. Piacentino,
    和 A. Divakaran, “无模型生成重放用于终身强化学习：应用于星际争霸2，”2022年。'
- en: '[204] J.-B. Gaya, T. Doan, L. Caccia, L. Soulier, L. Denoyer, and R. Raileanu,
    “Building a subspace of policies for scalable continual learning,” in *ICLR*,
    2023.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[204] J.-B. Gaya, T. Doan, L. Caccia, L. Soulier, L. Denoyer, 和 R. Raileanu,
    “为可扩展持续学习构建策略子空间，”发表于*ICLR*，2023年。'
- en: '[205] J. Yoon, W. Jeong, G. Lee, E. Yang, and S. J. Hwang, “Federated continual
    learning with weighted inter-client transfer,” in *ICML*, 2021.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[205] J. Yoon, W. Jeong, G. Lee, E. Yang, 和 S. J. Hwang, “具有加权客户端间转移的联邦持续学习，”发表于*ICML*，2021年。'
- en: '[206] S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T. Suresh,
    “Scaffold: Stochastic controlled averaging for federated learning,” in *ICML*,
    2020.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[206] S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, 和 A. T. Suresh,
    “Scaffold: 用于联邦学习的随机控制平均，”发表于*ICML*，2020年。'
- en: '[207] N. Shoham, T. Avidor, A. Keren, N. Israel, D. Benditkis, L. Mor-Yosef,
    and I. Zeitak, “Overcoming forgetting in federated learning on non-iid data,”
    *NeurIPS Workshop*, 2019.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[207] N. Shoham, T. Avidor, A. Keren, N. Israel, D. Benditkis, L. Mor-Yosef,
    和 I. Zeitak, “克服非独立同分布数据中的联邦学习遗忘，”*NeurIPS Workshop*，2019年。'
- en: '[208] W. Huang, M. Ye, and B. Du, “Learn from others and be yourself in heterogeneous
    federated learning,” in *CVPR*, 2022.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[208] W. Huang, M. Ye, 和 B. Du, “在异构联邦学习中从他人身上学习并做自己，”发表于*CVPR*，2022年。'
- en: '[209] C. Xu, Z. Hong, M. Huang, and T. Jiang, “Acceleration of federated learning
    with alleviated forgetting in local training,” in *ICLR*, 2022.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[209] C. Xu, Z. Hong, M. Huang, 和 T. Jiang, “通过减轻本地训练中的遗忘加速联邦学习，”发表于*ICLR*，2022年。'
- en: '[210] G. Lee, M. Jeong, Y. Shin, S. Bae, and S.-Y. Yun, “Preservation of the
    global knowledge by not-true distillation in federated learning,” *NeurIPS*, 2022.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[210] G. Lee, M. Jeong, Y. Shin, S. Bae, 和 S.-Y. Yun, “通过非真实蒸馏保护联邦学习中的全球知识，”*NeurIPS*，2022年。'
- en: '[211] K. Luo, X. Li, Y. Lan, and M. Gao, “Gradma: A gradient-memory-based accelerated
    federated learning with alleviated catastrophic forgetting,” in *CVPR*, 2023.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[211] K. Luo, X. Li, Y. Lan, 和 M. Gao, “Gradma: 基于梯度记忆的加速联邦学习，减轻灾难性遗忘，”发表于*CVPR*，2023年。'
- en: '[212] L. Qu, Y. Zhou, P. P. Liang, Y. Xia, F. Wang, E. Adeli, L. Fei-Fei, and
    D. Rubin, “Rethinking architecture design for tackling data heterogeneity in federated
    learning,” in *CVPR*, 2022.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[212] L. Qu, Y. Zhou, P. P. Liang, Y. Xia, F. Wang, E. Adeli, L. Fei-Fei, 和
    D. Rubin, “重新思考应对联邦学习中数据异质性的架构设计，”发表于*CVPR*，2022年。'
- en: '[213] J. Dong, L. Wang, Z. Fang, G. Sun, S. Xu, X. Wang, and Q. Zhu, “Federated
    class-incremental learning,” in *CVPR*, 2022.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[213] J. Dong, L. Wang, Z. Fang, G. Sun, S. Xu, X. Wang, 和 Q. Zhu, “联邦类别增量学习，”发表于*CVPR*，2022年。'
- en: '[214] D. Qi, H. Zhao, and S. Li, “Better generative replay for continual federated
    learning,” in *ICLR*, 2023.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[214] D. Qi, H. Zhao, 和 S. Li, “更好的生成重放以支持持续联邦学习，”发表于*ICLR*，2023年。'
- en: '[215] Y. Ma, Z. Xie, J. Wang, K. Chen, and L. Shou, “Continual federated learning
    based on knowledge distillation,” in *IJCAI*, 2022.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[215] Y. Ma, Z. Xie, J. Wang, K. Chen, 和 L. Shou, “基于知识蒸馏的持续联邦学习，”发表于*IJCAI*，2022年。'
- en: '[216] K. Audhkhasi, G. Saon, Z. Tüske, B. Kingsbury, and M. Picheny, “Forget
    a bit to learn better: Soft forgetting for ctc-based automatic speech recognition.”
    in *Interspeech*, 2019.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[216] K. Audhkhasi, G. Saon, Z. Tüske, B. Kingsbury, 和 M. Picheny, “忘记一点以更好地学习：用于基于CTC的自动语音识别的软遗忘。”发表于*Interspeech*，2019年。'
- en: '[217] T. Shibata, G. Irie, D. Ikami, and Y. Mitsuzumi, “Learning with selective
    forgetting.” in *IJCAI*, 2021.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[217] T. Shibata, G. Irie, D. Ikami, 和 Y. Mitsuzumi, “带有选择性遗忘的学习。”发表于*IJCAI*，2021年。'
- en: '[218] E. Nikishin, M. Schwarzer, P. D’Oro, P.-L. Bacon, and A. Courville, “The
    primacy bias in deep reinforcement learning,” in *ICML*, 2022.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[218] E. Nikishin, M. Schwarzer, P. D’Oro, P.-L. Bacon, 和 A. Courville, “深度强化学习中的首因偏差，”发表于*ICML*，2022年。'
- en: '[219] B. Han, G. Niu, X. Yu, Q. Yao, M. Xu, I. Tsang, and M. Sugiyama, “Sigua:
    Forgetting may make learning with noisy labels more robust,” in *ICML*, 2020.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[219] B. Han, G. Niu, X. Yu, Q. Yao, M. Xu, I. Tsang, 和 M. Sugiyama, “Sigua:
    遗忘可能使带噪标签的学习更具鲁棒性，”发表于*ICML*，2020年。'
- en: '[220] A. Jaiswal, D. Moyer, G. Ver Steeg, W. AbdAlmageed, and P. Natarajan,
    “Invariant representations through adversarial forgetting,” in *AAAI*, 2020.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[220] A. Jaiswal, D. Moyer, G. Ver Steeg, W. AbdAlmageed, 和 P. Natarajan, “通过对抗性遗忘获得不变表示，”发表于*AAAI*，2020年。'
- en: '[221] L. Gravitz, “The importance of forgetting,” *Nature*, 2019.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[221] L. Gravitz, “遗忘的重要性，”*自然*，2019年。'
- en: '[222] S. Baik, S. Hong, and K. M. Lee, “Learning to forget for meta-learning,”
    in *CVPR*, 2020.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[222] S. Baik, S. Hong, 和 K. M. Lee, “为元学习学习遗忘，”发表于*CVPR*，2020年。'
- en: '[223] H. Zhou, A. Vani, H. Larochelle, and A. Courville, “Fortuitous forgetting
    in connectionist networks,” in *ICLR*, 2022.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[223] H. Zhou, A. Vani, H. Larochelle, 和 A. Courville, “连接主义网络中的偶然遗忘，” 在 *ICLR*，2022。'
- en: '[224] B. Kim, H. Kim, K. Kim, S. Kim, and J. Kim, “Learning not to learn: Training
    deep neural networks with biased data,” in *CVPR*, 2019.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[224] B. Kim, H. Kim, K. Kim, S. Kim, 和 J. Kim, “学习如何不学习：用偏倚数据训练深度神经网络，” 在
    *CVPR*，2019。'
- en: '[225] P. J. Bevan and A. Atapour-Abarghouei, “Skin deep unlearning: Artefact
    and instrument debiasing in the context of melanoma classification,” in *ICML*,
    2022.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[225] P. J. Bevan 和 A. Atapour-Abarghouei, “肤浅去学习：在黑色素瘤分类背景下的伪影和工具去偏倚，” 在 *ICML*，2022。'
- en: '[226] Y. Chen, S. Zhang, and B. K. H. Low, “Near-optimal task selection for
    meta-learning with mutual information and online variational bayesian unlearning,”
    in *AISTATS*, 2022.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[226] Y. Chen, S. Zhang, 和 B. K. H. Low, “通过互信息和在线变分贝叶斯去学习进行近优任务选择，” 在 *AISTATS*，2022。'
- en: '[227] L. Wang, M. Zhang, Z. Jia, Q. Li, C. Bao, K. Ma, J. Zhu, and Y. Zhong,
    “Afec: Active forgetting of negative transfer in continual learning,” *NeurIPS*,
    2021.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[227] L. Wang, M. Zhang, Z. Jia, Q. Li, C. Bao, K. Ma, J. Zhu, 和 Y. Zhong,
    “Afec: 持续学习中负迁移的主动遗忘，” *NeurIPS*，2021。'
- en: '[228] L. Bourtoule, V. Chandrasekaran, C. A. Choquette-Choo, H. Jia, A. Travers,
    B. Zhang, D. Lie, and N. Papernot, “Machine unlearning,” in *SSP*, 2021.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[228] L. Bourtoule, V. Chandrasekaran, C. A. Choquette-Choo, H. Jia, A. Travers,
    B. Zhang, D. Lie, 和 N. Papernot, “机器去学习，” 在 *SSP*，2021。'
- en: '[229] T. T. Nguyen, T. T. Huynh, P. L. Nguyen, A. W.-C. Liew, H. Yin, and Q. V. H.
    Nguyen, “A survey of machine unlearning,” 2022.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[229] T. T. Nguyen, T. T. Huynh, P. L. Nguyen, A. W.-C. Liew, H. Yin, 和 Q.
    V. H. Nguyen, “机器去学习综述，” 2022。'
- en: '[230] A. Mantelero, “The eu proposal for a general data protection regulation
    and the roots of the ‘right to be forgotten’,” *Computer Law & Security Review*,
    2013.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[230] A. Mantelero, “欧盟关于一般数据保护条例的提案及‘被遗忘权’的根源，” *计算机法律与安全评论*，2013。'
- en: '[231] Y. Wu, E. Dobriban, and S. Davidson, “DeltaGrad: Rapid retraining of
    machine learning models,” in *ICML*, 2020.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[231] Y. Wu, E. Dobriban, 和 S. Davidson, “DeltaGrad：机器学习模型的快速再训练，” 在 *ICML*，2020。'
- en: '[232] A. Sekhari, J. Acharya, G. Kamath, and A. T. Suresh, “Remember what you
    want to forget: Algorithms for machine unlearning,” *NeurIPS*, 2021.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[232] A. Sekhari, J. Acharya, G. Kamath, 和 A. T. Suresh, “记住你想忘记的：机器去学习的算法，”
    *NeurIPS*，2021。'
- en: '[233] E. Ullah, T. Mai, A. Rao, R. A. Rossi, and R. Arora, “Machine unlearning
    via algorithmic stability,” in *COLT*, 2021.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[233] E. Ullah, T. Mai, A. Rao, R. A. Rossi, 和 R. Arora, “通过算法稳定性进行机器去学习，”
    在 *COLT*，2021。'
- en: '[234] H. Yan, X. Li, Z. Guo, H. Li, F. Li, and X. Lin, “Arcane: An efficient
    architecture for exact machine unlearning,” in *IJCAI*, 2022.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[234] H. Yan, X. Li, Z. Guo, H. Li, F. Li, 和 X. Lin, “Arcane：一种高效的确切机器去学习架构，”
    在 *IJCAI*，2022。'
- en: '[235] C. Guo, T. Goldstein, A. Hannun, and L. van der Maaten, “Certified data
    removal from machine learning models,” in *ICML*, 2020.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[235] C. Guo, T. Goldstein, A. Hannun, 和 L. van der Maaten, “从机器学习模型中认证数据移除，”
    在 *ICML*，2020。'
- en: '[236] A. Golatkar, A. Achille, and S. Soatto, “Eternal sunshine of the spotless
    net: Selective forgetting in deep networks,” in *CVPR*, 2020.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[236] A. Golatkar, A. Achille, 和 S. Soatto, “洁净网络的永恒阳光：深度网络中的选择性遗忘，” 在 *CVPR*，2020。'
- en: '[237] Q. P. Nguyen, B. K. H. Low, and P. Jaillet, “Variational bayesian unlearning,”
    *NeurIPS*, 2020.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[237] Q. P. Nguyen, B. K. H. Low, 和 P. Jaillet, “变分贝叶斯去学习，” *NeurIPS*，2020。'
- en: '[238] R. Mehta, S. Pal, V. Singh, and S. N. Ravi, “Deep unlearning via randomized
    conditionally independent hessians,” in *CVPR*, 2022.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[238] R. Mehta, S. Pal, V. Singh, 和 S. N. Ravi, “通过随机条件独立的 Hessians 进行深度去学习，”
    在 *CVPR*，2022。'
- en: '[239] M. Du, Z. Chen, C. Liu, R. Oak, and D. Song, “Lifelong anomaly detection
    through unlearning,” in *SIGSAC*, 2019.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[239] M. Du, Z. Chen, C. Liu, R. Oak, 和 D. Song, “通过去学习进行终身异常检测，” 在 *SIGSAC*，2019。'
- en: '[240] Z. Ma, Y. Liu, X. Liu, J. Liu, J. Ma, and K. Ren, “Learn to forget: Machine
    unlearning via neuron masking,” *IEEE Transactions on Dependable and Secure Computing*,
    2022.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[240] Z. Ma, Y. Liu, X. Liu, J. Liu, J. Ma, 和 K. Ren, “学会忘记：通过神经元屏蔽进行机器去学习，”
    *IEEE 可靠性与安全计算学报*，2022。'
- en: '[241] G. Wu, M. Hashemi, and C. Srinivasa, “Puma: Performance unchanged model
    augmentation for training data removal,” in *AAAI*, 2022.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[241] G. Wu, M. Hashemi, 和 C. Srinivasa, “Puma：用于训练数据移除的性能不变模型增强，” 在 *AAAI*，2022。'
- en: '[242] Y. Liu, M. Fan, C. Chen, X. Liu, Z. Ma, L. Wang, and J. Ma, “Backdoor
    defense with machine unlearning,” in *IEEE INFOCOM 2022*, 2022.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[242] Y. Liu, M. Fan, C. Chen, X. Liu, Z. Ma, L. Wang, 和 J. Ma, “利用机器去学习进行后门防御，”
    在 *IEEE INFOCOM 2022*，2022。'
- en: '[243] H. Shin, J. K. Lee, J. Kim, and J. Kim, “Continual learning with deep
    generative replay,” *NeurIPS*, vol. 30, 2017.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[243] H. Shin, J. K. Lee, J. Kim, 和 J. Kim, “通过深度生成重放进行持续学习，” *NeurIPS*，第30卷，2017。'
- en: '[244] M. Riemer, I. Cases, R. Ajemian, M. Liu, I. Rish, Y. Tu, and G. Tesauro,
    “Learning to learn without forgetting by maximizing transfer and minimizing interference,”
    *ICLR*, 2019.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[244] M. Riemer, I. Cases, R. Ajemian, M. Liu, I. Rish, Y. Tu, 和 G. Tesauro，
    “通过最大化迁移和最小化干扰来学习如何学习而不遗忘，” *ICLR*，2019年。'
- en: '[245] Y. Liu, B. Schiele, and Q. Sun, “Rmm: Reinforced memory management for
    class-incremental learning,” *NeurIPS*, 2021.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[245] Y. Liu, B. Schiele, 和 Q. Sun， “Rmm: 用于类增量学习的强化记忆管理，” *NeurIPS*，2021年。'
- en: '[246] F.-K. Sun, C.-H. Ho, and H.-Y. Lee, “Lamol: Language modeling for lifelong
    language learning,” in *ICLR*, 2020.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[246] F.-K. Sun, C.-H. Ho, 和 H.-Y. Lee， “Lamol: 终身语言学习的语言建模，” 见于 *ICLR*，2020年。'
- en: '[247] A. Iscen, J. Zhang, S. Lazebnik, and C. Schmid, “Memory-efficient incremental
    learning through feature adaptation,” in *ECCV*, 2020.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[247] A. Iscen, J. Zhang, S. Lazebnik, 和 C. Schmid， “通过特征适配进行内存高效的增量学习，” 见于
    *ECCV*，2020年。'
- en: '[248] F. Zhu, X.-Y. Zhang, C. Wang, F. Yin, and C.-L. Liu, “Prototype augmentation
    and self-supervision for incremental learning,” in *CVPR*, 2021.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[248] F. Zhu, X.-Y. Zhang, C. Wang, F. Yin, 和 C.-L. Liu， “原型增强和自监督用于增量学习，”
    见于 *CVPR*，2021年。'
- en: '[249] K. Zhu, W. Zhai, Y. Cao, J. Luo, and Z. Zha, “Self-sustaining representation
    expansion for non-exemplar class-incremental learning,” in *CVPR*, 2022.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[249] K. Zhu, W. Zhai, Y. Cao, J. Luo, 和 Z. Zha， “自我维持的表示扩展用于非样本类增量学习，” 见于
    *CVPR*，2022年。'
- en: '[250] B. Zhao, K. R. Mopuri, and H. Bilen, “Dataset condensation with gradient
    matching,” in *ICLR*, 2021.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[250] B. Zhao, K. R. Mopuri, 和 H. Bilen， “通过梯度匹配进行数据集浓缩，” 见于 *ICLR*，2021年。'
- en: '[251] M. Wortsman, V. Ramanujan, R. Liu, A. Kembhavi, M. Rastegari, J. Yosinski,
    and A. Farhadi, “Supermasks in superposition,” *NeurIPS*, 2020.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[251] M. Wortsman, V. Ramanujan, R. Liu, A. Kembhavi, M. Rastegari, J. Yosinski,
    和 A. Farhadi， “超面具的超叠加，” *NeurIPS*，2020年。'
- en: '[252] T. Konishi, M. Kurokawa, C. Ono, Z. Ke, G. Kim, and B. Liu, “Parameter-level
    soft-masking for continual learning,” *ICML*, 2023.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[252] T. Konishi, M. Kurokawa, C. Ono, Z. Ke, G. Kim, 和 B. Liu， “用于终身学习的参数级软掩蔽，”
    *ICML*，2023年。'
- en: '[253] H. Kang, R. J. L. Mina, S. R. H. Madjid, J. Yoon, M. Hasegawa-Johnson,
    S. J. Hwang, and C. D. Yoo, “Forget-free continual learning with winning subnetworks,”
    in *ICML*, 2022.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[253] H. Kang, R. J. L. Mina, S. R. H. Madjid, J. Yoon, M. Hasegawa-Johnson,
    S. J. Hwang, 和 C. D. Yoo， “无遗忘的终身学习与胜出的子网络，” 见于 *ICML*，2022年。'
- en: '[254] J. Frankle and M. Carbin, “The lottery ticket hypothesis: Finding sparse,
    trainable neural networks,” in *ICLR*, 2019.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[254] J. Frankle 和 M. Carbin， “彩票票据假设：寻找稀疏的可训练神经网络，” 见于 *ICLR*，2019年。'
- en: '[255] M. B. Gurbuz and C. Dovrolis, “Nispa: Neuro-inspired stability-plasticity
    adaptation for continual learning in sparse networks,” in *ICML*, 2022.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[255] M. B. Gurbuz 和 C. Dovrolis， “Nispa: 神经启发的稳定性-可塑性适应用于稀疏网络中的终身学习，” 见于 *ICML*，2022年。'
- en: '[256] R. Aljundi, P. Chakravarty, and T. Tuytelaars, “Expert gate: Lifelong
    learning with a network of experts,” in *CVPR*, 2017.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[256] R. Aljundi, P. Chakravarty, 和 T. Tuytelaars， “专家门控：利用专家网络进行终身学习，” 见于
    *CVPR*，2017年。'
- en: '[257] D.-W. Zhou, Q.-W. Wang, H.-J. Ye, and D.-C. Zhan, “A model or 603 exemplars:
    Towards memory-efficient class-incremental learning,” in *ICLR*, 2023.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[257] D.-W. Zhou, Q.-W. Wang, H.-J. Ye, 和 D.-C. Zhan， “一个模型还是603个样本：走向内存高效的类增量学习，”
    见于 *ICLR*，2023年。'
- en: '[258] Z. Hu, Y. Li, J. Lyu, D. Gao, and N. Vasconcelos, “Dense network expansion
    for class incremental learning,” in *CVPR*, 2023, pp. 11 858–11 867.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[258] Z. Hu, Y. Li, J. Lyu, D. Gao, 和 N. Vasconcelos， “用于类增量学习的稠密网络扩展，” 见于
    *CVPR*，2023年，第11 858–11 867页。'
- en: '[259] Y. Wen, D. Tran, and J. Ba, “Batchensemble: an alternative approach to
    efficient ensemble and lifelong learning,” in *ICLR*, 2023.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[259] Y. Wen, D. Tran, 和 J. Ba， “Batchensemble: 高效集成和终身学习的另一种方法，” 见于 *ICLR*，2023年。'
- en: '[260] S. Jung, H. Ahn, S. Cha, and T. Moon, “Continual learning with node-importance
    based adaptive group sparse regularization,” *NeurIPS*, 2020.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[260] S. Jung, H. Ahn, S. Cha, 和 T. Moon， “基于节点重要性的自适应组稀疏正则化的终身学习，” *NeurIPS*，2020年。'
- en: '[261] Y. Guo, W. Hu, D. Zhao, and B. Liu, “Adaptive orthogonal projection for
    batch and online continual learning,” in *AAAI*, 2022.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[261] Y. Guo, W. Hu, D. Zhao, 和 B. Liu， “自适应正交投影用于批量和在线终身学习，” 见于 *AAAI*，2022年。'
- en: '[262] A. F. Akyürek, E. Akyürek, D. Wijaya, and J. Andreas, “Subspace regularizers
    for few-shot class incremental learning,” in *ICLR*, 2022.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[262] A. F. Akyürek, E. Akyürek, D. Wijaya, 和 J. Andreas， “用于少量样本类增量学习的子空间正则化，”
    见于 *ICLR*，2022年。'
- en: Appendix A Continual Learning
  id: totrans-485
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 终身学习
- en: A.1 Task-aware CL
  id: totrans-486
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 任务感知的终身学习
- en: 'Existing works proposed for solving task-aware CL have five major research
    branches: memory-based, architecture-based, regularization-based, subspace-based,
    and Bayesian-based CL methods. We give an overall framework in Fig. [1](#S2.F1
    "Figure 1 ‣ 2.1.1 Task-aware CL ‣ 2.1 Task-Aware and Task-Free CL ‣ 2 Forgetting
    in Continual Learning ‣ A Comprehensive Survey of Forgetting in Deep Learning
    Beyond Continual Learning"). We present the details of each class method in the
    following.'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 为解决任务感知的连续学习，现有工作提出了五个主要的研究分支：基于记忆的、基于架构的、基于正则化的、基于子空间的和基于贝叶斯的连续学习方法。我们在图[1](#S2.F1
    "Figure 1 ‣ 2.1.1 Task-aware CL ‣ 2.1 Task-Aware and Task-Free CL ‣ 2 Forgetting
    in Continual Learning ‣ A Comprehensive Survey of Forgetting in Deep Learning
    Beyond Continual Learning")中给出了整体框架。我们将在以下内容中详细介绍每类方法。
- en: Memory-based Method
  id: totrans-488
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于记忆的方法
- en: 'Memory-based method keeps a *memory buffer* that stores the data examples from
    previous tasks and replay those examples during learning new tasks, representative
    works include [[243](#bib.bib243), [15](#bib.bib15), [244](#bib.bib244), [76](#bib.bib76),
    [23](#bib.bib23)]. It can be further categorized into: (1) raw memory replay;
    (2) memory sample selection; (3) generative replay; (4) compressed memory replay.
    Next, we discuss each direction in detail.'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 基于记忆的方法保持一个*记忆缓冲区*，该缓冲区存储来自先前任务的数据示例，并在学习新任务时重放这些示例，代表性的工作包括[[243](#bib.bib243),
    [15](#bib.bib15), [244](#bib.bib244), [76](#bib.bib76), [23](#bib.bib23)]。它可以进一步分为：(1)
    原始记忆重放；(2) 记忆样本选择；(3) 生成重放；(4) 压缩记忆重放。接下来，我们详细讨论每个方向。
- en: 'Raw Sample Replay: These methods save a small amount of data from previous
    tasks and trains the model with the new task. A key issue in this type of approach
    is how to select raw samples to store in the memory buffer. Current research works
    contain random selection [[76](#bib.bib76)] and selection based on heuristic rules [[22](#bib.bib22),
    [23](#bib.bib23)]. The random selection method randomly saves some raw samples
    into the memory, and performs replay [[76](#bib.bib76)] or constraints [[14](#bib.bib14),
    [15](#bib.bib15)] when learning a new task. For example, GEM [[14](#bib.bib14)]
    and A-GEM [[15](#bib.bib15)] use the memory buffer data losses as inequality constraints
    to constrain their increase but allow their decrease to mitigate forgetting. Meta
    Experience Replay (MER) [[244](#bib.bib244)] uses meta-learning to encourage information
    transfer from previous tasks and minimize interference. DER++ [[16](#bib.bib16)]
    found that replaying old data with soft labels is significantly better than one-hot
    labels.'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 原始样本重放：这些方法保存少量来自先前任务的数据，并用新任务训练模型。这种方法的关键问题在于如何选择要存储在记忆缓冲区中的原始样本。目前的研究工作包括随机选择[[76](#bib.bib76)]和基于启发式规则的选择[[22](#bib.bib22),
    [23](#bib.bib23)]。随机选择方法将一些原始样本随机保存到记忆中，并在学习新任务时进行重放[[76](#bib.bib76)]或约束[[14](#bib.bib14),
    [15](#bib.bib15)]。例如，GEM[[14](#bib.bib14)]和A-GEM[[15](#bib.bib15)]将记忆缓冲区的数据损失作为不等式约束，限制其增加但允许其减少以减轻遗忘。Meta
    Experience Replay (MER) [[244](#bib.bib244)]利用元学习来鼓励从先前任务中传递信息并最小化干扰。DER++ [[16](#bib.bib16)]发现，使用软标签重放旧数据显著优于使用独热标签。
- en: 'Memory Sample Selection: These simplest methods to mitigate forgetting is to
    randomly store some examples for replay. However, this may lead to sub-optimal
    performance since random selection overlooks the informativeness of each sample.
    The heuristic selection selects samples for storage based on certain rules. e.g.,
    iCaRL [[19](#bib.bib19)] selects the samples closest to each category cluster
    center. Some works choose the samples closest to the decision boundary of each
    class [[22](#bib.bib22), [23](#bib.bib23)] or make the sample diversity in memory
    the highest [[20](#bib.bib20), [21](#bib.bib21)]. GCR [[17](#bib.bib17)] selects
    the corset that best represents the gradients produced by past data. Sun et al. [[18](#bib.bib18)]
    model and regularize the influence of each selected example on the future. In
    addition, the above schemes of static memory allocation (fixed total capacity
    or storing a specific number of samples per class) may also lead to suboptimal
    performance. RMM [[245](#bib.bib245)] proposes a reinforcement learning based
    strategy to automatically allocate capacity for old and new classes.'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆样本选择：最简单的减轻遗忘的方法是随机存储一些示例以便重放。然而，这可能导致次优性能，因为随机选择忽略了每个样本的信息量。启发式选择根据某些规则选择存储的样本。例如，iCaRL[[19](#bib.bib19)]选择最接近每个类别簇中心的样本。一些工作选择最接近每个类别决策边界的样本[[22](#bib.bib22),
    [23](#bib.bib23)]，或使记忆中的样本多样性最高[[20](#bib.bib20), [21](#bib.bib21)]。GCR[[17](#bib.bib17)]选择最能代表过去数据产生的梯度的样本。Sun等人[[18](#bib.bib18)]对每个选定示例对未来的影响进行建模和正则化。此外，上述静态记忆分配方案（固定总容量或每类存储特定数量的样本）也可能导致次优性能。RMM[[245](#bib.bib245)]提出了一种基于强化学习的策略，以自动分配旧类别和新类别的容量。
- en: 'Generative Replay: When privacy concerns restrict the storage of raw memory
    data, generative replay provides an alternative approach in CL to replay previous
    task data. The main concept behind generative replay is to train a generative
    model capable of capturing and remembering the data distribution from previous
    tasks. Instead of storing raw samples, the generative model is used to generate
    synthetic samples representative of the old tasks  [[246](#bib.bib246)]. The representative
    works in this line involve using different generative models, include GAN-based
    methods [[24](#bib.bib24), [25](#bib.bib25)], AutoEncoder-based methods [[26](#bib.bib26)],
    Diffusion-based model [[27](#bib.bib27)], and Model-inversion [[28](#bib.bib28)].'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 生成回放：当隐私问题限制了原始记忆数据的存储时，生成回放提供了一种在CL中重放以前任务数据的替代方法。生成回放的主要概念是训练一个生成模型，能够捕捉和记住来自以前任务的数据分布。与其存储原始样本，不如使用生成模型生成代表旧任务的合成样本[[246](#bib.bib246)]。该领域的代表性工作涉及使用不同的生成模型，包括基于GAN的方法[[24](#bib.bib24),
    [25](#bib.bib25)]，基于AutoEncoder的方法[[26](#bib.bib26)]，基于扩散模型的方法[[27](#bib.bib27)]，以及模型反演[[28](#bib.bib28)]。
- en: 'Compressed Memory Replay: In scenarios where storage constraints are stringent
    on edge devices, memory efficiency becomes a crucial consideration. Several research
    efforts have aimed to improve memory efficiency in CL by employing different strategies.
    For example, instead of directly storing high-resolution images, one approach
    is to store feature representations  [[29](#bib.bib29), [247](#bib.bib247), [30](#bib.bib30)]
    or feature prototype extracted from the image  [[248](#bib.bib248), [249](#bib.bib249)],
    or compress the high-fidelity image into a low-fidelity image (JPEG) for storage [[31](#bib.bib31),
    [32](#bib.bib32)]. Recently, dataset condensation has emerged as a promising approach
    for compressing and condensing datasets, as demonstrated by works such as [[250](#bib.bib250),
    [35](#bib.bib35)]. Drawing inspiration from data distillation techniques, many
    CL methods adopt the strategy of storing condensed samples from old tasks in memory
    for replay  [[33](#bib.bib33), [34](#bib.bib34)].'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 压缩记忆回放：在边缘设备存储限制严格的情况下，记忆效率成为一个关键考虑因素。几个研究工作旨在通过采用不同策略来提高CL中的记忆效率。例如，与其直接存储高分辨率图像，不如存储特征表示[[29](#bib.bib29),
    [247](#bib.bib247), [30](#bib.bib30)]或从图像中提取的特征原型[[248](#bib.bib248), [249](#bib.bib249)]，或者将高保真图像压缩成低保真图像（JPEG）以便存储[[31](#bib.bib31),
    [32](#bib.bib32)]。最近，数据集浓缩作为压缩和浓缩数据集的一种有前途的方法出现了，如[[250](#bib.bib250), [35](#bib.bib35)]所示。受到数据蒸馏技术的启发，许多CL方法采用了将来自旧任务的浓缩样本存储在记忆中以便重放的策略[[33](#bib.bib33),
    [34](#bib.bib34)]。
- en: Architecture-based Method
  id: totrans-494
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于架构的方法
- en: 'Architecture-based methods in CL [[36](#bib.bib36), [37](#bib.bib37), [38](#bib.bib38)]
    involve updating the network architecture during the learning process to retain
    previously acquired knowledge. These methods aim to adapt the model’s architecture
    to accommodate new tasks while preserving the knowledge from previous tasks. Based
    on whether the model parameters expand with the number of tasks, architecture-based
    methods can be categorized into two types: fixed-capacity and capacity-increasing
    methods.'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: CL中的基于架构的方法[[36](#bib.bib36), [37](#bib.bib37), [38](#bib.bib38)]涉及在学习过程中更新网络架构，以保留之前获得的知识。这些方法旨在调整模型的架构以适应新任务，同时保留先前任务的知识。根据模型参数是否随着任务数量的增加而扩展，基于架构的方法可以分为两种类型：固定容量和容量增长方法。
- en: 'Fixed-Capacity: In these methods, the amount of CL model’s parameters does
    not increase with the number of tasks, and each task selects a sub-network from
    the CL model to achieve knowledge transfer and reduce the forgetting caused by
    sub-network updates. Common subnetwork selection techniques include masking [[39](#bib.bib39),
    [40](#bib.bib40), [41](#bib.bib41)], and pruning [[42](#bib.bib42), [43](#bib.bib43),
    [44](#bib.bib44)]. On the one hand, the mask-based method isolates the update
    of important neurons or parameters of old tasks during the backpropagation of
    the new task, thereby alleviating the forgetting of old tasks. A representative
    method, HAT [[39](#bib.bib39)] proposes a task-based binary/hard attention mask
    mechanism on neurons instead of parameters. Unlike HAT, which requires task identification
    during testing, SupSup [[251](#bib.bib251)] proposes a gradient-based optimization
    strategy, which can automatically infer tasks and find the learned optimal mask
    during testing. In addition, different from the above-mentioned hard mask methods
    that monopolize the sub-network, which hinders knowledge transfer and has the
    problem of excessive consumption of network capacity by old tasks, SPG [[252](#bib.bib252)]
    proposes a soft mask mechanism that uses the importance of old task parameters
    as a mask to constrain the back-propagation gradient flow updates to important
    parameters. On the other hand, similar to the mask mechanism, the pruning-based
    method freezes important parameters to avoid forgetting after the old tasks are
    learned, and reinitializes unimportant parameters to learn new tasks. PackNet [[43](#bib.bib43)]
    iteration performs pruning of a well-trained base network and maintains the binary
    sparse mask. Similarly, WSN [[253](#bib.bib253)] selects an optimal sub-network
    (winning ticket) for each task based on the Lottery Ticket Hypothesis [[254](#bib.bib254)].
    Finally, unlike all the above methods that start masking or pruning from a densely
    connected network, although NISPA [[255](#bib.bib255)] also fixes the total number
    of neurons, it only starts learning tasks from a sparsely connected network, and
    then continuously increases the connections between neurons to learn new tasks.'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 固定容量：在这些方法中，CL模型的参数数量不会随着任务数量的增加而增加，每个任务从CL模型中选择一个子网络来实现知识迁移，并减少由子网络更新引起的遗忘。常见的子网络选择技术包括掩码[[39](#bib.bib39),
    [40](#bib.bib40), [41](#bib.bib41)]和剪枝[[42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44)]。一方面，基于掩码的方法在新任务的反向传播过程中隔离了旧任务的重要神经元或参数的更新，从而减轻了旧任务的遗忘。一个代表性的方法，HAT[[39](#bib.bib39)]提出了一种基于任务的二进制/硬注意力掩码机制作用于神经元而不是参数。与HAT需要在测试期间进行任务识别不同，SupSup[[251](#bib.bib251)]提出了一种基于梯度的优化策略，可以在测试期间自动推断任务并找到学习到的最优掩码。此外，不同于上述垄断子网络的硬掩码方法，这会阻碍知识迁移并导致旧任务过度消耗网络容量，SPG[[252](#bib.bib252)]提出了一种软掩码机制，利用旧任务参数的重要性作为掩码来约束反向传播梯度流更新到重要参数。另一方面，类似于掩码机制，基于剪枝的方法冻结重要参数以避免在学习旧任务后遗忘，并重新初始化不重要的参数以学习新任务。PackNet[[43](#bib.bib43)]迭代执行对训练良好的基础网络进行剪枝，并保持二进制稀疏掩码。类似地，WSN[[253](#bib.bib253)]基于彩票票假设[[254](#bib.bib254)]为每个任务选择一个最佳子网络（获胜票）。最后，不同于所有上述方法从密集连接网络开始掩码或剪枝，尽管NISPA[[255](#bib.bib255)]也固定了神经元的总数，但它仅从稀疏连接网络开始学习任务，然后不断增加神经元之间的连接以学习新任务。
- en: 'Capacity-Increasing: a fixed capacity CL model may face limitations in accommodating
    new tasks as the number of tasks increases. This can restrict the plasticity of
    new tasks due to insufficient remaining network capacity. To overcome this challenge,
    dynamic capacity methods have been proposed. These methods augment the CL model
    by introducing task-specific new parameters for each new task while freezing the
    parameters associated with old tasks. By doing so, dynamic capacity methods aim
    to prevent forgetting while allowing the model to adapt and learn new tasks effectively [[36](#bib.bib36),
    [38](#bib.bib38), [45](#bib.bib45), [46](#bib.bib46)]. For example, PNN [[36](#bib.bib36)]
    employs an independent network branch for each task, where the input of the new
    task branch is the output from the old task branch, enabling knowledge transfer
    between tasks. ExpertGate [[256](#bib.bib256)], MEMO [[257](#bib.bib257)], and
    DNE [[258](#bib.bib258)] also add task-specialized experts/blocks/layers for each
    new task, respectively. BatchEnsemble [[259](#bib.bib259)] freezes the backbone
    network after learning the first task, and learns two independent rank-one matrices
    for each new task. However, it also limits knowledge transfer between tasks starting
    from the second task.'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 增加容量：固定容量的 CL 模型可能会面临在任务数量增加时难以容纳新任务的限制。这可能会由于剩余网络容量不足而限制新任务的可塑性。为克服这一挑战，已经提出了动态容量方法。这些方法通过为每个新任务引入特定任务的新参数，同时冻结与旧任务相关的参数，从而增强
    CL 模型。通过这种方式，动态容量方法旨在防止遗忘，同时使模型能够有效地适应和学习新任务 [[36](#bib.bib36), [38](#bib.bib38),
    [45](#bib.bib45), [46](#bib.bib46)]。例如，PNN [[36](#bib.bib36)] 为每个任务采用独立的网络分支，其中新任务分支的输入是旧任务分支的输出，从而实现任务之间的知识转移。ExpertGate [[256](#bib.bib256)]、MEMO [[257](#bib.bib257)]
    和 DNE [[258](#bib.bib258)] 还分别为每个新任务添加了特定任务的专家/模块/层。BatchEnsemble [[259](#bib.bib259)]
    在学习第一个任务后冻结了骨干网络，并为每个新任务学习两个独立的秩一矩阵。然而，它也限制了从第二个任务开始的任务间知识转移。
- en: Regularization-based Method
  id: totrans-498
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于正则化的方法
- en: 'Regularization-based methods in CL involve the addition of regularization loss
    terms to the training objective to prevent forgetting of previously learned knowledge
    [[47](#bib.bib47), [48](#bib.bib48), [49](#bib.bib49)]. These methods aim to constrain
    the model’s parameter updates during the learning process to ensure that valuable
    information from past tasks is retained. Regularization-based methods can be further
    divided into two subcategories: penalizing important parameter updates and knowledge
    distillation using a previous model as a teacher.'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 基于正则化的方法涉及在训练目标中添加正则化损失项，以防止之前学习的知识被遗忘 [[47](#bib.bib47), [48](#bib.bib48),
    [49](#bib.bib49)]。这些方法旨在在学习过程中约束模型的参数更新，以确保保留过去任务中的有价值信息。基于正则化的方法可以进一步分为两个子类别：惩罚重要的参数更新和使用先前模型作为教师的知识蒸馏。
- en: 'Penalize Parameter Updates: Some works alleviate forgetting by penalizing parameter
    updates that are important for old tasks. For example, EWC [[47](#bib.bib47)]
    calculates regularization terms by approximating Fisher information matrix (FIM).
    MAS [[50](#bib.bib50)] takes the cumulative update of the parameters as a penalty
    term. SI [[48](#bib.bib48)] computes parameter importance using the path integral
    of gradient vector fields during parameter updating. Rwalk [[22](#bib.bib22)]
    can be seen as a generalized version of SI and EWC++. UCL [[51](#bib.bib51)] proposes
    an uncertain regularization based on the Bayesian online learning framework. AGS-CL [[260](#bib.bib260)]
    proposes two group sparsity penalties based on node importance as regularization
    terms.'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 惩罚参数更新：一些研究通过惩罚对旧任务重要的参数更新来缓解遗忘。例如，EWC [[47](#bib.bib47)] 通过近似费舍尔信息矩阵 (FIM)
    来计算正则化项。MAS [[50](#bib.bib50)] 将参数的累积更新作为惩罚项。SI [[48](#bib.bib48)] 通过在参数更新过程中计算梯度向量场的路径积分来评估参数的重要性。Rwalk [[22](#bib.bib22)]
    可以被视为 SI 和 EWC++ 的一种推广版本。UCL [[51](#bib.bib51)] 提出了基于贝叶斯在线学习框架的不确定正则化。AGS-CL [[260](#bib.bib260)]
    提出了两种基于节点重要性的组稀疏惩罚作为正则化项。
- en: 'Knowledge-Distillation-Based: Inspired by knowledge distillation [[52](#bib.bib52)],
    several methods in CL incorporate a distillation loss between the network of the
    previous task (referred to as the teacher) and the network of the current task
    (referred to as the student) to mitigate forgetting. One method that follows this
    approach is Learning without Forgetting (LwF) [[53](#bib.bib53)], which considers
    the soft targets generated by the teacher network as additional learning objectives
    for the student model. By treating the soft targets as valuable information, LwF
    enables the current model to learn from the knowledge of the previous model, reducing
    the risk of forgetting. Building upon LwF, LwM [[54](#bib.bib54)] leverages the
    attention mechanism of the previous network to guide the training of the current
    network. The attention of the teacher network helps the student model focus on
    relevant features and retain important knowledge from past tasks. Another method,
    BMC [[55](#bib.bib55)], takes a different approach by training multiple expert
    models simultaneously on disjoint sets of tasks. These expert models are then
    aggregated through knowledge distillation, which involves transferring knowledge
    from the expert models to a single student model. On the other hand, in distillation-based
    CL methods, the ideal scenario would involve using the raw data of old tasks to
    extract the knowledge of the teacher model and distill it to the student model.
    However, accessing the raw data of old tasks is often not feasible due to data
    privacy concerns. Consequently, existing approaches utilize proxy data as a substitute
    for distillation. One such method is LwF [[53](#bib.bib53)], which uses the current
    task data as a proxy for distillation. Another approach, GD [[56](#bib.bib56)],
    utilizes large-scale unlabeled data from the wild as a proxy for distillation.'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 基于知识蒸馏的方法：受知识蒸馏[[52](#bib.bib52)]的启发，CL中的几种方法在前一个任务的网络（称为教师网络）和当前任务的网络（称为学生网络）之间引入了蒸馏损失，以减轻遗忘。其中一种方法是**无遗忘学习**（LwF）[[53](#bib.bib53)]，它将教师网络生成的软目标视为学生模型的额外学习目标。通过将软目标视为有价值的信息，LwF使当前模型能够从前一个模型的知识中学习，从而降低遗忘的风险。在LwF的基础上，**LwM**[[54](#bib.bib54)]利用前一个网络的注意机制来指导当前网络的训练。教师网络的注意力帮助学生模型关注相关特征并保留过去任务中的重要知识。另一种方法，**BMC**[[55](#bib.bib55)]，则采取不同的方法，通过在不同任务集合上同时训练多个专家模型，然后通过知识蒸馏将这些专家模型的知识转移到单一的学生模型上。然而，在基于蒸馏的CL方法中，理想的情况是使用旧任务的原始数据来提取教师模型的知识并蒸馏到学生模型中。然而，由于数据隐私问题，访问旧任务的原始数据通常不可行。因此，现有的方法使用代理数据作为蒸馏的替代品。**LwF**[[53](#bib.bib53)]就是一种方法，它使用当前任务数据作为蒸馏的代理。另一种方法，**GD**[[56](#bib.bib56)]，则利用来自外部的大规模无标签数据作为蒸馏的代理。
- en: Subspace-based Method
  id: totrans-502
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 子空间方法
- en: 'Subspace-based methods in CL aim to address the issue of interference between
    multiple tasks by conducting learning in separate and disjoint subspaces. Subspace-based
    methods can be categorized into two types based on how the subspaces are constructed:
    orthogonal gradient subspace and orthogonal feature subspace methods.'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: CL中的子空间方法旨在通过在分开的子空间中进行学习来解决多个任务之间的干扰问题。子空间方法可以根据子空间的构建方式分为两种类型：正交梯度子空间方法和正交特征子空间方法。
- en: 'Orthogonal Gradient Subspace: These methods require that the parameter update
    direction of the new task is orthogonal to the gradient subspace of the old tasks,
    ensuring minimal interference between tasks. OGD [[57](#bib.bib57)] proposes updating
    the CL model in a gradient subspace orthogonal to the subspace of the old tasks.
    PCAOGD [[58](#bib.bib58)] is an extension of OGD that only stores the top principal
    components of gradients for each task. ORTHOG-SUBSPACE [[59](#bib.bib59)] learns
    different tasks in different orthogonal (low-rank) subspaces to minimize interference.'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 正交梯度子空间：这些方法要求新任务的参数更新方向与旧任务的梯度子空间正交，从而确保任务之间的干扰最小化。**OGD**[[57](#bib.bib57)]提出在一个正交于旧任务子空间的梯度子空间中更新CL模型。**PCAOGD**[[58](#bib.bib58)]是OGD的扩展，它只存储每个任务的梯度的前几个主成分。**ORTHOG-SUBSPACE**[[59](#bib.bib59)]在不同的正交（低秩）子空间中学习不同的任务，以最小化干扰。
- en: 'Orthogonal Feature Subspace: These require that the parameter update direction
    of the new task is orthogonal to the subspace crossed by the input (feature) of
    the old task. OWM [[60](#bib.bib60)] proposes that when learning a new task, network
    parameters are only updated in a direction orthogonal to the subspace spanned
    by the inputs of all previous tasks. AOP [[261](#bib.bib261)] solves the problem
    of inaccurate input space estimation in OWM. GPM [[61](#bib.bib61)] proposes to
    construct subspace for past tasks, the network updates the network parameters
    taking gradient steps in the orthogonal direction to the gradient subspaces that
    are important for the past learned tasks. Deng et al.[[62](#bib.bib62)] propose
    a Flattening Sharpness for Dynamic Gradient Projection Memory (FS-DGPM) with soft
    weight on the basis of GPM to improve new task learning. TRGP [[63](#bib.bib63)]
    introduces a trust-region variant of GPM to tackle the challenge of balancing
    the learning of new tasks with preserving the knowledge of old tasks.'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 正交特征子空间：这些方法要求新任务的参数更新方向与旧任务输入（特征）所跨越的子空间正交。OWM[[60](#bib.bib60)]提出在学习新任务时，网络参数仅在与所有先前任务的输入所构成的子空间正交的方向上更新。AOP[[261](#bib.bib261)]解决了OWM中输入空间估计不准确的问题。GPM[[61](#bib.bib61)]提出为过去的任务构造子空间，网络在对过去学习任务重要的梯度子空间的正交方向上进行梯度更新。Deng等人[[62](#bib.bib62)]在GPM的基础上提出了一种动态梯度投影记忆（FS-DGPM）方法，通过软权重来改进新任务学习。TRGP[[63](#bib.bib63)]引入了GPM的信任区域变体，以应对平衡新任务学习与保持旧任务知识的挑战。
- en: Bayesian Method
  id: totrans-506
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 贝叶斯方法
- en: 'Bayesian methods provide a principled probabilistic framework for addressing
    CF and can be classified into three categories: (1) methods that constrain the
    update of weight parameter distributions, (2) methods that constrain the update
    in function space, and (3) methods that dynamically grow the CL model architecture
    in an adaptive and Bayesian manner. These Bayesian approaches offer effective
    strategies to mitigate CF by incorporating uncertainty estimation and regularization
    techniques, thereby enhancing the adaptability of the learning process. In the
    following paragraphs, we provide a detailed discussion of each research direction.'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯方法提供了一个有原则的概率框架来解决CF问题，可以分为三类：（1）限制权重参数分布更新的方法，（2）限制函数空间更新的方法，以及（3）以自适应和贝叶斯方式动态扩展CL模型架构的方法。这些贝叶斯方法通过结合不确定性估计和正则化技术，提供了有效的策略来缓解CF，从而增强学习过程的适应性。在接下来的段落中，我们将详细讨论每个研究方向。
- en: 'Weight Space Regularization: Weight space regularization based methods model
    the parameter update uncertainty and enforce the model parameter (weight space)
    distribution when learning the new task is close to that of all the previously
    learned tasks, including [[64](#bib.bib64), [65](#bib.bib65), [66](#bib.bib66)].
    Gaussian Residual Scoring (GRS) [[67](#bib.bib67)] extends Bayesian neural network
    to the non-stationary streaming data. Different from previous work, which updates
    the parameter posterior distribution recursively over the task sequence, posterior
    meta-replay [[68](#bib.bib68)] which learns the task-specific posteriors via a
    single shared meta-model, improving the flexibility in representing the current
    task and previous tasks. Natural Continual Learning (NCL) [[69](#bib.bib69)] combines
    Bayesian inference with gradient projection methods.'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 权重空间正则化：权重空间正则化基于方法通过建模参数更新的不确定性，并强制学习新任务时的模型参数（权重空间）分布接近于所有先前学习任务的分布，包括[[64](#bib.bib64),
    [65](#bib.bib65), [66](#bib.bib66)]。高斯残差评分（GRS）[[67](#bib.bib67)]将贝叶斯神经网络扩展到非平稳流数据中。与之前的方法不同，后验元重放[[68](#bib.bib68)]通过一个共享的元模型学习任务特定的后验，从而提高了表示当前任务和先前任务的灵活性。自然持续学习（NCL）[[69](#bib.bib69)]将贝叶斯推断与梯度投影方法相结合。
- en: 'Function Space Regularization: Different from weight space regularization which
    constrains the weight update, the function space regularization regulates the
    CL function update in the function space. Functional Regularisation of Memorable
    Past (FROMP) [[70](#bib.bib70)] enforce the posterior distribution over function
    space (instead of weight space) of the new task to be close to that of the all
    the previously learned task with Gaussian process. In contrast to previous works
    that primarily emphasize either parameter or function space regularization, Functional
    Regularized Continual Learning (FRCL) [[71](#bib.bib71)] takes a different approach
    by focusing on constraining neural network predictions to prevent significant
    deviations from solutions to previous tasks. Variational Auto-Regressive Gaussian
    Processes (VAR-GPs) [[72](#bib.bib72)] further proposes a framework through a
    principled posterior updating mechanism to naturally model the cross-task covariances.
    Sequential function-space variational inference (S-FSVI) [[73](#bib.bib73)] presents
    a framework for addressing CL by formulating it as sequential function-space variational
    inference. This approach offers several advantages, including the ability to employ
    more flexible variational distributions and more effective regularization techniques.'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 函数空间正则化：不同于限制权重更新的权重空间正则化，函数空间正则化在函数空间中调节CL函数更新。记忆过去功能的函数正则化（FROMP）[[70](#bib.bib70)]强制新的任务在函数空间中的后验分布（而不是权重空间）接近所有先前学习任务的高斯过程。与以前主要强调参数或函数空间正则化的研究相比，功能正则化持续学习（FRCL）[[71](#bib.bib71)]采取了不同的方法，专注于限制神经网络预测，以防止与先前任务解决方案的显著偏差。变分自回归高斯过程（VAR-GPs）[[72](#bib.bib72)]进一步提出了一种通过有原则的后验更新机制来自然建模跨任务协方差的框架。序列函数空间变分推断（S-FSVI）[[73](#bib.bib73)]提出了一种将CL作为序列函数空间变分推断来解决的框架。这种方法提供了几个优点，包括能够使用更灵活的变分分布和更有效的正则化技术。
- en: 'Bayesian Architecture Expansion: Bayesian architecture growing methods employ
    a probabilistic and Bayesian approach to dynamically expand the CL model. By leveraging
    Bayesian principles, these methods enable the CL model to incrementally grow and
    adapt to new tasks or data while preserving previously learned knowledge. This
    probabilistic framework facilitates the flexible and principled expansion of the
    model’s architecture, allowing it to accommodate increasing complexity and variability
    in the learning process. Kumar et al. [[74](#bib.bib74)] introduce a principled
    framework for CL that incorporates both variational Bayes and a nonparametric
    Bayesian modeling paradigm. Their approach enables the continual learning of neural
    network structures, offering a systematic methodology for adapting and expanding
    the network architecture over time. Moreover, the work by Mehta et al. [[75](#bib.bib75)]
    introduces IBP-WF, a method that leverages a principled Bayesian nonparametric
    approach, to dynamically expand the network architecture based on the task complexity.
    This approach allows the model to scale and accommodate increasing demands and
    intricacies of the learning tasks, ensuring efficient and effective adaptation
    throughout the CL process.'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯架构扩展：贝叶斯架构扩展方法采用概率和贝叶斯方法来动态扩展CL模型。通过利用贝叶斯原理，这些方法使CL模型能够逐步增长并适应新任务或数据，同时保留先前学习的知识。这种概率框架促进了模型架构的灵活而有原则的扩展，使其能够适应学习过程中不断增加的复杂性和变异性。Kumar等人[[74](#bib.bib74)]引入了一种结合变分贝叶斯和非参数贝叶斯建模范式的CL原则框架。他们的方法使神经网络结构能够持续学习，提供了一种系统的方法来随时间调整和扩展网络架构。此外，Mehta等人[[75](#bib.bib75)]的研究引入了IBP-WF，这是一种利用有原则的贝叶斯非参数方法来动态扩展网络架构的方法。该方法使模型能够扩展以适应学习任务不断增加的需求和复杂性，确保在整个CL过程中高效而有效的适应。
- en: A.2 Few-shot CL
  id: totrans-511
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 少样本CL
- en: In order to tackle the forgetting problem within the context of few-shot CL,
    existing approaches employ various techniques, including metric learning, meta-learning,
    and parameter regularization. These techniques will be elaborated upon in the
    following.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决少样本CL中的遗忘问题，现有的方法采用了各种技术，包括度量学习、元学习和参数正则化。这些技术将在下面详细介绍。
- en: Metric Learning-Based
  id: totrans-513
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于度量学习
- en: These methods perform classification by class prototypes. To avoid forgetting,
    the prototype of the new class should be separable from the old class [[105](#bib.bib105)],
    and the prototype of the old class should not change drastically during the adjustment
    process of the new class [[107](#bib.bib107)]. TOPIC [[104](#bib.bib104)] first
    defines the benchmark-setting of few-shot class-incremental learning (FSCIL),
    which represents the topological structure of different classes in the feature
    space, and alleviates the forgetting of old classes by keeping the topology stable.
    To alleviate forgetting, DSN [[103](#bib.bib103)] estimates the distribution of
    classes in the current task. In a new task, feature vectors are sampled from old
    class distributions for replay. Another two approaches, C-FSCIL  [[106](#bib.bib106)]
    and FSCIL [[107](#bib.bib107)] try to reduce interference between prototypes.
    C-FSCIL maps input images to quasi-orthogonal prototypes to minimize task interference.
    Also, FSCIL pre-assigns and fixes the feature prototype classifier, and trains
    a projection layer to project the sample features of each class onto the assigned
    prototype, thereby avoiding the interference between classes and the problem of
    forgetting.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法通过类别原型进行分类。为了避免遗忘，新类别的原型应与旧类别的原型可分 [[105](#bib.bib105)]，并且旧类别的原型在调整新类别的过程中不应发生剧烈变化 [[107](#bib.bib107)]。TOPIC [[104](#bib.bib104)]
    首先定义了少样本类别增量学习（FSCIL）的基准设置，这表示特征空间中不同类别的拓扑结构，并通过保持拓扑结构的稳定来减轻旧类别的遗忘。为了减轻遗忘，DSN [[103](#bib.bib103)]
    估计当前任务中类别的分布。在新任务中，从旧类别的分布中采样特征向量进行重放。还有两种方法，C-FSCIL [[106](#bib.bib106)]和FSCIL [[107](#bib.bib107)]，尝试减少原型之间的干扰。C-FSCIL将输入图像映射到准正交原型，以最小化任务干扰。此外，FSCIL预先分配并固定特征原型分类器，并训练一个投影层，将每个类别的样本特征投影到分配的原型上，从而避免类别之间的干扰和遗忘问题。
- en: Meta-Learning-Based
  id: totrans-515
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于元学习
- en: These methods simulate the inference phase during training so that CL models
    can quickly adapt to unseen new classes to solve few-shot CL. LIMIT [[108](#bib.bib108)]
    and MetaFSCIL [[109](#bib.bib109)] split the base task into multiple ’fake’-incremental
    tasks, so that the model has the learning ability of FSCIL tasks. Specifically,
    MetaFSCIL directly considers the adaptability of new tasks and the stability of
    old tasks as its primary objectives for meta-learning. When MetaFSCIL trains on
    a new class, it evaluates the performance on all encountered classes as a meta-objective.
    By reducing the loss associated with the meta-objective, MetaFSCIL minimizes forgetting
    of the old tasks.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法在训练期间模拟推断阶段，以便CL模型能够快速适应未见的新类别，从而解决少样本CL问题。LIMIT [[108](#bib.bib108)]和MetaFSCIL [[109](#bib.bib109)]将基本任务拆分为多个“伪”增量任务，使模型具备FSCIL任务的学习能力。具体而言，MetaFSCIL直接将新任务的适应性和旧任务的稳定性作为其元学习的主要目标。当MetaFSCIL在新类别上进行训练时，它将评估所有遇到的类别的表现作为元目标。通过减少与元目标相关的损失，MetaFSCIL最大限度地减少旧任务的遗忘。
- en: Parameter Regularization-Based
  id: totrans-517
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于参数正则化
- en: These methods employ various strategies to address the forgetting problem by
    penalizing parameter updates that are important for old tasks. For example, FSLL [[110](#bib.bib110)]
    and WaRP [[111](#bib.bib111)] adopt an approach where certain crucial parameters
    are frozen during training, while the remaining parameters are fine-tuned specifically
    for the few-shot task. Another approach, Subspace Regularization [[262](#bib.bib262)],
    introduces a subspace regularization that encourages the weights of new classes
    to be close to the subspace spanned by the weights of existing classes.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法采用了各种策略来解决遗忘问题，通过惩罚对旧任务重要的参数更新。例如，FSLL [[110](#bib.bib110)]和WaRP [[111](#bib.bib111)]采用了一种方法，在训练过程中冻结某些关键参数，同时针对少样本任务对其余参数进行微调。另一种方法，子空间正则化 [[262](#bib.bib262)]，引入了一种子空间正则化，鼓励新类别的权重接近由现有类别权重所张成的子空间。
