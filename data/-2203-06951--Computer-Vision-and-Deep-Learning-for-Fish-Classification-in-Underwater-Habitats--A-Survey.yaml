- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-06 19:47:43'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-06 19:47:43'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2203.06951] Computer Vision and Deep Learning for Fish Classification in Underwater
    Habitats: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2203.06951] 水下栖息地的鱼类分类的计算机视觉和深度学习：一项调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2203.06951](https://ar5iv.labs.arxiv.org/html/2203.06951)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2203.06951](https://ar5iv.labs.arxiv.org/html/2203.06951)
- en: \UseRawInputEncoding\corraddress
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \UseRawInputEncoding\corraddress
- en: Mostafa Rahimi Azghadi, PhD, College of Science and Engineering, James Cook
    University, Townsville, QLD, Australia \corremailmostafa.rahimiazghadi@jcu.edu.au
    \presentadd[]College of Science and Engineering, James Cook University, Townsville,
    QLD, Australia \fundinginfoThis research is supported by an Australian Research
    Training Program (RTP) Scholarship, and the Australian Research Council funding
    through their Industrial Transformation Research Program.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Mostafa Rahimi Azghadi博士，澳大利亚昆士兰州汤斯维尔詹姆斯库克大学科学与工程学院\corremailmostafa.rahimiazghadi@jcu.edu.au
    \presentadd[]澳大利亚昆士兰州汤斯维尔詹姆斯库克大学科学与工程学院\fundinginfo这项研究得到了澳大利亚研究培训计划（RTP）奖学金以及澳大利亚研究理事会通过其工业转型研究计划的资助。
- en: 'Computer Vision and Deep Learning for Fish Classification in Underwater Habitats:
    A Survey'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 水下栖息地的鱼类分类的计算机视觉和深度学习：一项调查
- en: Alzayat Saleh College of Science and Engineering, James Cook University, Townsville,
    QLD, Australia Marcus Sheaves College of Science and Engineering, James Cook University,
    Townsville, QLD, Australia Mostafa Rahimi Azghadi College of Science and Engineering,
    James Cook University, Townsville, QLD, Australia ARC Research Hub for Supercharging
    Tropical Aquaculture through Genetic Solutions, James Cook University, Townsville,
    QLD, Australia
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Alzayat Saleh，澳大利亚昆士兰州汤斯维尔詹姆斯库克大学科学与工程学院 Marcus Sheaves，澳大利亚昆士兰州汤斯维尔詹姆斯库克大学科学与工程学院
    Mostafa Rahimi Azghadi，澳大利亚昆士兰州汤斯维尔詹姆斯库克大学科学与工程学院 ARC Research Hub for Supercharging
    Tropical Aquaculture through Genetic Solutions，澳大利亚昆士兰州汤斯维尔詹姆斯库克大学
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Marine scientists use remote underwater image and video recording to survey
    fish species in their natural habitats. This helps them get a step closer toward
    understanding and predicting how fish respond to climate change, habitat degradation,
    and fishing pressure. This information is essential for developing sustainable
    fisheries for human consumption, and for preserving the environment. However,
    the enormous volume of collected videos makes extracting useful information a
    daunting and time-consuming task for a human. A promising method to address this
    problem is the cutting-edge Deep Learning ( Deep Learning (DL)) technology. DL
    can help marine scientists parse large volumes of video promptly and efficiently,
    unlocking niche information that cannot be obtained using conventional manual
    monitoring methods. In this paper, we first provide a survey of Computer Visions
    (CV) and DL studies conducted between 2003-2021 on fish classification in underwater
    habitats. We then give an overview of the key concepts of DL, while analyzing
    and synthesizing DL studies. We also discuss the main challenges faced when developing
    DL for underwater image processing and propose approaches to address them. Finally,
    we provide insights into the marine habitat monitoring research domain and shed
    light on what the future of DL for underwater image processing may hold. This
    paper aims to inform marine scientists who would like to gain a high-level understanding
    of essential DL concepts and survey state-of-the-art DL-based fish classification
    in their underwater habitat.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 海洋科学家利用远程水下图像和视频记录来调查鱼类在其自然栖息地中的物种。这有助于他们更接近地了解和预测鱼类对气候变化、栖息地退化和捕捞压力的响应。这些信息对于开发人类消费的可持续渔业以及环境保护至关重要。然而，庞大的视频数量使得从中提取有用信息对于人类而言是一个令人望而却步和耗时的任务。解决这一问题的一个有前途的方法是先进的深度学习（Deep
    Learning (DL)）技术。DL可以帮助海洋科学家迅速有效地解析大量视频，解锁传统手动监测方法无法获得的精细信息。在本文中，我们首先对2003-2021年在水下栖息地对鱼类分类进行的计算机视觉（CV）和DL研究进行调查。然后，我们概述DL的关键概念，并分析和综合DL研究。我们还讨论了开发水下图像处理的DL时所面临的主要挑战，并提出了解决方法。最后，我们对海洋栖息地监测研究领域提供了见解，并展望了水下图像处理的DL的未来。本文旨在向希望对DL的基本概念有高层次了解并调查水下栖息地的最新DL鱼类分类的海洋科学家提供信息。
- en: 'keywords:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '关键词： '
- en: Fish Habitat, Monitoring, Computer Vision, Deep Learning.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 鱼类栖息地、监测、计算机视觉、深度学习
- en: Nomenclature
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 术语
- en: '| AI | Artificial Intelligence |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| AI | 人工智能 |'
- en: '| ANN | Artificial Neural Networks |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| ANN | 人工神经网络 |'
- en: '| AUV | Autonomous Underwater Vehicle |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| AUV | 自主水下车辆 |'
- en: '| CNN | Convolutional Neural Network |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 卷积神经网络 |'
- en: '| CV | Computer Vision |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| CV | 计算机视觉 |'
- en: '| DL | Deep Learning |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| DL | 深度学习 |'
- en: '| DNN | Deep Neural Networks |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| DNN | 深度神经网络 |'
- en: '| FCN | Fully Convolutional Network |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| FCN | 完全卷积网络 |'
- en: '| LSTM | Long short-term memory |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| LSTM | 长短期记忆'
- en: '| ML | Machine Learning |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| ML | 机器学习 |'
- en: '| OCR | Optical character recognition |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| OCR | 光学字符识别 |'
- en: '| RNN | Recurrent Neural Network |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| RNN | 循环神经网络 |'
- en: '| ROV | Remotely Operated Vehicles |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| ROV | 遥控操作车辆 |'
- en: '| RUV | Remote Underwater Video |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| RUV | 远程水下视频 |'
- en: 1 Introduction
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Understanding and modelling how fish respond to climate change, habitat degradation,
    and fishing pressure are critical for environmental protection, and are crucial
    steps toward ensuring sustainable natural fisheries, to support ever-growing human
    consumption [[138](#bib.bib138)]. Effective monitoring is a vital first step underpinning
    decision support mechanisms for identifying problems and planning actions to preserve
    and restore the habitats. However, there is still a gap between the complexity
    of marine ecosystems and the available monitoring mechanisms.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 理解和建模鱼类如何响应气候变化、栖息地退化和渔业压力对于环境保护至关重要，也是确保自然渔业可持续的关键步骤，以支持日益增长的人类消费[[138](#bib.bib138)]。有效的监测是支撑决策支持机制的一个重要第一步，用于识别问题和规划行动，以保护和恢复栖息地。然而，海洋生态系统的复杂性与现有的监测机制之间仍存在差距。
- en: Marine scientists use underwater cameras to record, model, and understand fish
    habitats and fish behaviour. Remote Underwater Video (RUV) recording in marine
    applications [[138](#bib.bib138)] has shown great potential for fisheries, ecosystem
    management, and conservation programs [[95](#bib.bib95)]. With the introduction
    of consumer-grade high-definition cameras, it is now feasible to deploy a large
    number of RUVs or Autonomous Underwater Vehicles (AUVs) to collect substantial
    volumes of data and to perform more effective monitoring [[97](#bib.bib97), [102](#bib.bib102),
    [125](#bib.bib125)]. However, underwater habitats introduce diverse video monitoring
    challenges such as adverse water conditions, high similarity between fish species,
    cluttered backgrounds, and occlusions among fish. In addition, the volume of data
    generated by deployed RUVs and AUVs rapidly surpasses the capacity of human video
    viewers, making video analysis prohibitively expensive [[58](#bib.bib58)]. Moreover,
    humans are more prone to error than a well-designed machine-centred monitoring
    algorithm. Therefore, an automated, comprehensive monitoring system could significantly
    reduce labour expenses while improving throughput and accuracy, increasing the
    precision in estimates of fish stocks, fish distribution and biodiversity in general
    [[37](#bib.bib37)]. Implementing such systems necessitates effective Computer
    Vision (CV) processes. As a result, significant research has been conducted on
    implementing monitoring tools and techniques that build upon CV algorithms for
    determining how fish exploit various maritime environments and differentiating
    between fish species [[142](#bib.bib142)].
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 海洋科学家使用水下摄像机记录、建模和理解鱼类栖息地和行为。水下远程视频（RUV）记录在海洋应用中[[138](#bib.bib138)]显示出对渔业、生态系统管理和保护计划的巨大潜力[[95](#bib.bib95)]。随着消费级高清摄像机的引入，现在可以部署大量的RUV或自主水下车辆（AUV）来收集大量数据，并进行更有效的监测[[97](#bib.bib97),
    [102](#bib.bib102), [125](#bib.bib125)]。然而，水下栖息地带来了多种视频监测挑战，如不良的水质条件、鱼类物种之间的高度相似性、混乱的背景和鱼类之间的遮挡。此外，部署的RUV和AUV生成的数据量迅速超过了人类视频观众的容量，使得视频分析变得过于昂贵[[58](#bib.bib58)]。此外，人类比精心设计的机器中心监测算法更容易出错。因此，自动化的全面监测系统可以显著降低劳动成本，同时提高产出和准确性，从而提高对鱼类数量、分布和生物多样性的估计精度[[37](#bib.bib37)]。实施此类系统需要有效的计算机视觉（CV）过程。因此，已经进行了大量研究，以基于CV算法开发监测工具和技术，确定鱼类如何利用各种海洋环境以及区分鱼类物种[[142](#bib.bib142)]。
- en: '![Refer to caption](img/0e3428ea740d3e409e7b1723cf0f286b.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/0e3428ea740d3e409e7b1723cf0f286b.png)'
- en: 'Figure 1: Illustration of four typical types of CV tasks From left: Image Classification
    (i.e. is there a fish in the image, or what type (class) of fish is in the image?),
    Object Detection/Localisation, Semantic Segmentation, Instance Segmentation.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：四种典型计算机视觉任务的示意图 从左：图像分类（即图像中是否有鱼，或图像中是什么类型（类别）的鱼？）、物体检测/定位、语义分割、实例分割。
- en: In image analysis and CV domains, Deep Learning (DL) approaches have consistently
    produced state-of-the-art results in a variety of applications from agriculture
    [[88](#bib.bib88)] to medicine [[108](#bib.bib108), [5](#bib.bib5)] using Deep
    Neural Networks [[140](#bib.bib140), [81](#bib.bib81), [83](#bib.bib83)]. Notably,
    a video is inherently composed of images or frames, which are processed using
    image analysis techniques. Therefore, image- and video-based monitoring tasks
    can be done using DL models such as Convolutional Neural Networks that receive
    an image (frame) as their input. Therefore, the methods mentioned for image-based
    tasks are useful for both images and videos.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像分析和计算机视觉领域，深度学习（DL）方法在从农业[[88](#bib.bib88)]到医学[[108](#bib.bib108), [5](#bib.bib5)]的各种应用中一贯产生了最先进的结果，使用了深度神经网络[[140](#bib.bib140),
    [81](#bib.bib81), [83](#bib.bib83)]。值得注意的是，视频本质上由图像或帧组成，这些图像通过图像分析技术进行处理。因此，基于图像和视频的监测任务可以使用DL模型，如卷积神经网络，这些网络以图像（帧）作为输入。因此，用于图像任务的方法也适用于图像和视频。
- en: Many of DNN-based approaches outperform conventional methods in marine applications,
    including ecological and habitat monitoring, using video trap data [[134](#bib.bib134),
    [121](#bib.bib121)]. DL is a technique that mimics how people acquire knowledge
    by continuous analysis of input data. The main drivers of DNN success over the
    past decade have been architectural progress by a large community of computer
    scientists, more powerful computers and processors, and access to massive amounts
    of data, which is critical for developing successful generalizable DL applications.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 许多基于DNN的方法在海洋应用中超越了传统方法，包括生态和栖息地监测，使用视频陷阱数据[[134](#bib.bib134), [121](#bib.bib121)]。深度学习（DL）是一种通过对输入数据进行持续分析来模仿人类知识获取的技术。过去十年DNN成功的主要驱动因素包括计算机科学家大社区的架构进展、更强大的计算机和处理器以及对大量数据的访问，这对开发成功的通用DL应用至关重要。
- en: DNNs have been successfully employed in many CV applications such as object
    classification, identification, and segmentation as a result of the invention
    of CNN. CNN is a class of DNN, most commonly applied to visual analyses. For instance,
    CNNs have been successfully used for analysis of fish habitats [[136](#bib.bib136),
    [58](#bib.bib58), [97](#bib.bib97)]. In comparison to other image recognition
    algorithms, CNNs have the significant benefit that they require limited pre-processing.
    CNNs are not hand-engineered but uncover and learn hidden features in the data
    on their own. They learn level-by-level with various levels of abstraction. For
    instance, they learn simple shapes (edges, lines, etc.) in the first few layers,
    understand more sophisticated patterns in their next layers, and learn classes
    of objects in their final layers.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: DNN在许多计算机视觉（CV）应用中得到了成功应用，如物体分类、识别和分割，这要归功于卷积神经网络（CNN）的发明。CNN是一类DNN，最常用于视觉分析。例如，CNN已成功用于鱼类栖息地的分析[[136](#bib.bib136),
    [58](#bib.bib58), [97](#bib.bib97)]。与其他图像识别算法相比，CNN的显著优势在于它们只需有限的预处理。CNN不是手工设计的，而是自主发现和学习数据中的隐藏特征。它们逐层学习，具备不同层次的抽象能力。例如，它们在前几层学习简单的形状（边缘、线条等），在后续层理解更复杂的模式，并在最终层学习物体类别。
- en: A putative challenge with CNNs is that they require a large number of images
    to be fully trained and generalise their learning to unseen scenarios. On the
    other hand, CNNs have an interesting and powerful feature that enables transfer
    of their learning and knowledge across different domains. This means that they
    can be fine-tuned to work on new datasets (e.g. fish datasets) other than the
    one that they have been trained on (e.g. general objects). However, fine-tuning
    with annotated datasets specific for a given domain implies cost/effort/time needed
    to generate the annotations, and also requires a larger set of data which may
    not always be available.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一个假设性的挑战是，卷积神经网络（CNNs）需要大量的图像来进行充分的训练，并将其学习推广到未见过的场景中。另一方面，CNNs 具有一个有趣且强大的特性，使得它们能够将其学习和知识转移到不同的领域。这意味着它们可以被微调以适应新的数据集（例如鱼类数据集），而不是它们已经训练过的数据集（例如一般物体）。然而，使用特定领域的标注数据集进行微调意味着需要花费成本/精力/时间来生成标注，并且还需要更大规模的数据集，这些数据集可能并不总是可用的。
- en: Equipping CV algorithms with the powerful learning and inference capabilities
    of CNNs can provide marine scientists and ecologists with powerful tools to help
    them better understand and manage marine environments. However, although DL, and
    its variants such as CNNs, have been applied to various applications across a
    multitude of domains [[25](#bib.bib25), [92](#bib.bib92), [82](#bib.bib82)], their
    use in conjunction with computer vision for marine science and fish habitat monitoring
    is not broadly appreciated, meaning they remain under utilised. To address this,
    in this paper, we introduce key concepts and typical architectures of DL, and
    provide a comprehensive survey of key CV techniques for underwater fish habitat
    monitoring. In addition, we provide insights into challenges and opportunities
    in the underwater fish habitat monitoring domain. It is worth noting that our
    article is written to provide a general and high-level, as opposed to detailed,
    introduction of deep learning and its relevant contexts for marine scientists.
    This is useful in understanding the follow-up discussions on the use of deep learning
    in the marine task of underwater fish classification.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为计算机视觉算法提供CNNs强大的学习和推理能力，可以为海洋科学家和生态学家提供强有力的工具，帮助他们更好地理解和管理海洋环境。然而，尽管深度学习及其变体如CNNs已被应用于各种领域的多个应用[[25](#bib.bib25),
    [92](#bib.bib92), [82](#bib.bib82)]，它们在海洋科学和鱼类栖息地监测中与计算机视觉结合的使用并不被广泛认可，这意味着它们仍然未被充分利用。为了解决这个问题，本文介绍了深度学习的关键概念和典型架构，并提供了针对水下鱼类栖息地监测的关键计算机视觉技术的全面调查。此外，我们还提供了水下鱼类栖息地监测领域中的挑战和机遇的见解。值得注意的是，我们的文章旨在为海洋科学家提供一个一般性和高层次的介绍，而不是详细的介绍，这对于理解后续关于深度学习在水下鱼类分类中的应用讨论是有用的。
- en: Although a recent survey reviews deep learning techniques for marine ecology
    [[35](#bib.bib35)] and briefly discusses DL-based fish image analysis, to the
    best of our knowledge, no comprehensive survey and overview of deep learning with
    a specific focus on fish classification in underwater habitats currently exists.
    Our paper tries to address this gap and to facilitate the application of modern
    deep learning approaches into the challenging underwater fish images analysis
    and monitoring domains. We do this by comprehensively reviewing and analysing
    the literature providing information about the DL model the previous works have
    used, their training dataset, their annotation techniques, their performance and
    a comparison to other similar works. This detailed analysis is not provided in
    [[35](#bib.bib35)].
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管最近的调查回顾了用于海洋生态学的深度学习技术[[35](#bib.bib35)]，并简要讨论了基于深度学习的鱼类图像分析，但据我们所知，目前尚无专门针对水下栖息地鱼类分类的深度学习的全面调查和综述。我们的论文试图填补这一空白，促进现代深度学习方法在挑战性的水下鱼类图像分析和监测领域的应用。我们通过全面回顾和分析文献，提供有关深度学习模型的使用情况、其训练数据集、标注技术、性能以及与其他类似工作的比较。这种详细的分析在[[35](#bib.bib35)]中并未提供。
- en: In addition, another survey [[71](#bib.bib71)] exists that focuses on five different
    tasks of classification, detection, counting, behaviour recognition, and biomass
    estimation. Compared to [[71](#bib.bib71)], we provide a different analysis and
    review of the literature because we mainly focus on the classification of fish
    in underwater images. Li and Du’s work [[71](#bib.bib71)] fits mostly in the domain
    of aquaculture, while our paper is mostly a review of "fish classification techniques
    in underwater habitats" and the challenges they bring. Li and Du introduce a background
    to many different DL architectures, one of which is CNN, which is the focus of
    our paper. Also, the challenges and opportunities that Li and Du introduce are
    different to our paper, which is mainly about underwater fish classification in
    their natural habitat.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有另一项调查[[71](#bib.bib71)]专注于分类、检测、计数、行为识别和生物量估计五个不同任务。与[[71](#bib.bib71)]相比，我们提供了不同的分析和文献回顾，因为我们主要关注水下图像中的鱼类分类。李和杜的工作[[71](#bib.bib71)]主要适用于水产养殖领域，而我们的论文主要回顾了“水下栖息地中的鱼类分类技术”及其带来的挑战。李和杜介绍了多种不同的DL架构背景，其中一个是CNN，这也是我们论文的重点。此外，李和杜介绍的挑战和机遇与我们的论文不同，我们的论文主要关于其自然栖息地中的水下鱼类分类。
- en: Furthermore, we provide a historical review of the CV and DL research using
    underwater cameras for fish classification, and analyse how their accuracy has
    evolved over years. This is not covered by previous works including [[35](#bib.bib35),
    [71](#bib.bib71)].
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们提供了使用水下相机进行鱼类分类的CV和DL研究的历史回顾，并分析了它们的准确性如何随时间演变。这些内容未被包括在先前的研究中[[35](#bib.bib35)、[71](#bib.bib71)]。
- en: 2 Background To Computer Vision and Machine Learning
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 计算机视觉与机器学习背景
- en: 'Humans, have a natural ability to comprehend the three-dimensional structure
    of the world around us. Vision scientists [[89](#bib.bib89)] have spent decades
    attempting to understand how the human visual system functions [[131](#bib.bib131)].
    Inspired by their findings, CV researchers [[7](#bib.bib7), [44](#bib.bib44),
    [117](#bib.bib117)] have also been working on ways to recover the 3D shape and
    appearance of objects from photos. The automatic retrieval, interpretation, and
    comprehension of useful information from a single image or collection of images
    can be referred to as CV. In another definition, CV is a field of Artificial Intelligence
    (AI) that focuses on training computers to detect, recognise, and understand images
    similarly to processes used by humans. This necessitates the development of logical
    and algorithmic foundations for automated visual understanding [[77](#bib.bib77)].
    This understanding can include image classification, object localisation, object
    recognition, semantic segmentation, and instance segmentation, as shown in Figure
    [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Computer Vision and Deep Learning for
    Fish Classification in Underwater Habitats: A Survey"). Today, computers with
    CV powers can extract, analyse, and interpret significant information from a single
    image or a sequence of images.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '人类具有自然理解周围世界三维结构的能力。视觉科学家[[89](#bib.bib89)]已经花了几十年试图理解人类视觉系统如何运作[[131](#bib.bib131)]。受到他们研究结果的启发，CV研究人员[[7](#bib.bib7)、[44](#bib.bib44)、[117](#bib.bib117)]也在致力于从照片中恢复物体的3D形状和外观。从单张图像或图像集合中自动检索、解释和理解有用信息的过程被称为CV。另一个定义是，CV是人工智能（AI）的一个领域，专注于训练计算机以类似于人类的方式检测、识别和理解图像。这需要为自动视觉理解发展逻辑和算法基础[[77](#bib.bib77)]。这种理解可以包括图像分类、物体定位、物体识别、语义分割和实例分割，如图[1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Computer Vision and Deep Learning for Fish Classification
    in Underwater Habitats: A Survey")所示。如今，具备CV能力的计算机可以从单张图像或图像序列中提取、分析和解释重要信息。'
- en: Despite this progress, the goal of making a computer to understand a picture
    at the same level as a two-year-old child remains unattainable. This is due, in
    part, to the fact that CV is an inverse problem in which we attempt to recover
    specific unknowns despite having inadequate knowledge to completely describe the
    solution. In CV applications, the cause is usually an exploration process, while
    the effects are the observed data. The corresponding forward problems then consist
    of predicting empirical data given complete knowledge of the exploration process.
    In some sense, solving inverse problems means \saycomputing backwards, which is
    usually more difficult than forward problem solving [[38](#bib.bib38)].
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管取得了这些进展，但让计算机理解图片的水平与两岁小孩相当的目标仍然无法实现。这部分原因在于计算机视觉（CV）是一个逆向问题，我们试图在知识不足以完全描述解决方案的情况下恢复特定的未知量。在计算机视觉应用中，原因通常是一个探索过程，而效果是观察到的数据。相应的正向问题则包括在完全了解探索过程的情况下预测经验数据。从某种意义上讲，解决逆向问题意味着*向后计算*，这通常比正向问题解决更困难[[38](#bib.bib38)]。
- en: '![Refer to caption](img/e3f68cca741ab749523c640306869cc6.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e3f68cca741ab749523c640306869cc6.png)'
- en: 'Figure 2: Comparison between ML and DL. In ML techniques, the features need
    to be extracted by domain expert while DL relies on layers of artificial neural
    networks to extract these features.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：机器学习（ML）与深度学习（DL）的比较。在机器学习技术中，特征需要由领域专家提取，而深度学习依赖于人工神经网络的层来提取这些特征。
- en: 'The problem of backward computation was eased by the introduction of ML techniques
    more than 6 decades ago. However, in conventional ML approaches, the majority
    of complex features of the learning subject must be identified by a domain expert
    in order to decrease the complexity of the data and make patterns more evident
    for successful learning (see Figure [2](#S2.F2 "Figure 2 ‣ 2 Background To Computer
    Vision and Machine Learning ‣ Computer Vision and Deep Learning for Fish Classification
    in Underwater Habitats: A Survey")-top). However, DL offered a fundamentally new
    method to ML. Most DL algorithms possess the ground-breaking ability of automatically
    learning high-level features from data with minimal or no human intervention (see
    Figure [2](#S2.F2 "Figure 2 ‣ 2 Background To Computer Vision and Machine Learning
    ‣ Computer Vision and Deep Learning for Fish Classification in Underwater Habitats:
    A Survey")-bottom).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 60多年前，机器学习技术的引入缓解了逆向计算的问题。然而，在传统的机器学习方法中，大多数复杂的学习特征必须由领域专家识别，以减少数据的复杂性，使模式更加明显，从而成功学习（参见图
    [2](#S2.F2 "图 2 ‣ 2 计算机视觉和机器学习背景 ‣ 水下栖息地鱼类分类的计算机视觉与深度学习：综述")-top）。然而，深度学习提供了一种根本上新的机器学习方法。大多数深度学习算法具有自动从数据中学习高级特征的突破性能力，几乎不需要或无需人工干预（参见图
    [2](#S2.F2 "图 2 ‣ 2 计算机视觉和机器学习背景 ‣ 水下栖息地鱼类分类的计算机视觉与深度学习：综述")-bottom）。
- en: DL is based on neural networks, which are general-purpose functions that can
    learn almost any data type that can be represented by many instances. When you
    feed a neural network a large number of labelled instances of a certain type of
    data, it will be able to uncover common patterns between those examples and turn
    them into a mathematical equation that will assist in categorising future data.
    Empowered by this fundamental feature, DL and DNN have progressed from theory
    to practice as a result of advancements in hardware and cloud computing resources
    [[5](#bib.bib5)]. In recent years, DL approaches have outperformed previous state-of-the-art
    ML techniques in a variety of areas, with CV being one of the most notable examples.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）基于神经网络，神经网络是通用函数，能够学习几乎任何可以通过多个实例表示的数据类型。当你将大量标记实例的特定类型数据输入到神经网络中时，它将能够揭示这些示例之间的共同模式，并将其转化为数学方程，帮助对未来的数据进行分类。在这一基本特性的驱动下，深度学习和深度神经网络（DNN）由于硬件和云计算资源的进步，从理论转向了实践[[5](#bib.bib5)]。近年来，深度学习方法在各种领域中超越了以往的最先进的机器学习技术，其中计算机视觉是最显著的例子之一。
- en: 'Before the introduction of DL, the capabilities of CV were severely limited,
    necessitating a great deal of manual coding and effort. However, owing to improved
    research in DL and neural networks, CV is now able to outperform humans in several
    tasks related to object recognition and classification [[110](#bib.bib110), [109](#bib.bib109),
    [100](#bib.bib100), [120](#bib.bib120)]. CV equipped with DL, is being used today
    in a wide variety of real-world applications, that include, but are not limited
    to:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在引入深度学习（DL）之前，计算机视觉的能力受到严重限制，需要大量的手动编码和工作。然而，由于深度学习和神经网络研究的进展，计算机视觉现在能够在与对象识别和分类相关的多个任务中超越人类
    [[110](#bib.bib110)、[109](#bib.bib109)、[100](#bib.bib100)、[120](#bib.bib120)]。配备深度学习的计算机视觉今天被广泛应用于各种实际应用中，包括但不限于：
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Optical character recognition (OCR) [[94](#bib.bib94)]: automatic number plate
    recognition and reading handwritten postal codes on letters;'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 光学字符识别（OCR） [[94](#bib.bib94)]：自动车牌识别和读取信件上的手写邮政编码；
- en: •
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Machine inspection [[91](#bib.bib91)]: fast quality assurance inspection of
    components using stereo vision with advanced lighting to assess tolerance levels
    on aircraft wings or car body parts, or to spot flaws in steel castings using
    X-ray technology;'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 机器检测 [[91](#bib.bib91)]：利用立体视觉和先进照明进行组件的快速质量保证检测，以评估飞机机翼或汽车车身部件的公差水平，或使用 X 射线技术检测钢铸件中的缺陷；
- en: •
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Retail [[126](#bib.bib126)]: object detection for automatic checkout lanes;'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 零售 [[126](#bib.bib126)]：自动结账通道的物体检测；
- en: •
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Medical imaging [[29](#bib.bib29)]: registration of preoperative and intra-operative
    imaging or long-term analyses of human brain anatomy as they age;'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 医学影像 [[29](#bib.bib29)]：术前和术中影像的配准或对人脑解剖结构随年龄变化的长期分析；
- en: •
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Automotive safety [[30](#bib.bib30)]: detection of unforeseen objects such
    as pedestrians on the street (e.g. fully autonomously driving vehicles);'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 汽车安全 [[30](#bib.bib30)]：检测街道上意外出现的物体，例如行人（如完全自主驾驶车辆）；
- en: •
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Surveillance [[14](#bib.bib14)]: Monitoring of trespassers, studies of highway
    traffic, and monitoring pools for drowning victims;'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 监控 [[14](#bib.bib14)]：监控入侵者、高速公路交通研究以及监控游泳池以防溺水；
- en: •
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Fingerprint recognition and bio-metrics [[56](#bib.bib56)]: For both automatic
    entry authentication and forensic software.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指纹识别和生物识别 [[56](#bib.bib56)]：用于自动入场认证和法医软件。
- en: This demonstrates the significant impact of DL on CV and demonstrates its potential
    for marine visual analysis applications.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了深度学习对计算机视觉的显著影响，并展示了其在海洋视觉分析应用中的潜力。
- en: '![Refer to caption](img/69035e4297dd885ea26c6ebfc236a9a6.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/69035e4297dd885ea26c6ebfc236a9a6.png)'
- en: 'Figure 3: A popular CNN architecture, named UNET [[104](#bib.bib104)] is demonstrated.
    The first component of UNET is the encoder, which is used to extract features
    from the input image. The second component is the decoder that outputs per-pixel
    scores. The network is composed of five different layers including convolutional
    (Conv Layer), Rectified Linear Unit (ReLU), Pooling, Deconvolutional (DeConv),
    and Softmax.Here, the task of the DNN layers has been to give a high score to
    only the pixels in the input image that belong to the fish body, resulting in
    the demonstrated white blobs output, showing where the fish are.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：展示了一种名为 UNET 的流行 CNN 架构 [[104](#bib.bib104)]。UNET 的第一个组件是编码器，用于从输入图像中提取特征。第二个组件是解码器，它输出每个像素的分数。该网络由五个不同的层组成，包括卷积层（Conv
    Layer）、修正线性单元（ReLU）、池化层、反卷积层（DeConv）和 Softmax。这里，DNN 层的任务是仅对输入图像中属于鱼体的像素给出高分，从而产生所示的白色斑块输出，显示鱼的位置。
- en: 3 The evolution of Computer vision approaches to fish classification
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算机视觉方法在鱼类分类中的演变
- en: The last two decades have witnessed the emergence of novel computer vision approaches
    for fish classification including the design and evaluation of complex algorithms
    that could not be applied before and became possible with the availability of
    sufficiently large data and the use of powerful Graphical Processing Units (GPUs).
    Here, we perform a systematic literature review of the evolution of computer vision
    applications and their different approaches over the past two decades.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 过去二十年见证了新型计算机视觉方法在鱼类分类中的出现，这些方法包括设计和评估复杂的算法，这些算法在数据量足够大以及使用强大的图形处理单元（GPU）之前无法应用，但现在已变得可能。在这里，我们对计算机视觉应用的发展及其不同方法在过去二十年的演变进行了系统的文献综述。
- en: 3.1 Search and Selection Criteria
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 搜索和选择标准
- en: We systematically reviewed the literature for underwater fish classification
    using computer vision from 2003 to 2021\. The search terms used included "underwater
    fish classification", "Deep Learning", "Computer Vision", "Machine vision". The
    databases searched included Wiley Online Library, IEEE Xplore, Elsevier/ScienceDirect,
    and ACM Digital Library. We believe that combining these four databases accurately
    represents global research on this topic.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们系统地回顾了2003年至2021年间使用计算机视觉进行水下鱼类分类的文献。使用的检索词包括“水下鱼类分类”、“深度学习”、“计算机视觉”、“机器视觉”。检索的数据库包括Wiley
    Online Library、IEEE Xplore、Elsevier/ScienceDirect和ACM Digital Library。我们认为结合这四个数据库可以准确代表这一主题的全球研究。
- en: 'We divided the search into two stages. First, we queried the databases for
    articles with the above-mentioned keywords in their titles and contents. Secondly,
    we independently reviewed the titles and abstracts of each article in order to
    check its relevance to our research topic. After the individual title and abstract
    reviews, we considered 64 articles for full-text reading. In the full-reading
    phase, we extracted information relevant to our research topic. In this phase,
    it became clear that 21 papers were not relevant to our work and therefore were
    excluded. This left us with 43 papers for fish classification, 26 of which were
    classical Computer Vision methods, and 17 Deep Learning papers. Figure [4](#S3.F4
    "Figure 4 ‣ 3.1 Search and Selection Criteria ‣ 3 The evolution of Computer vision
    approaches to fish classification ‣ Computer Vision and Deep Learning for Fish
    Classification in Underwater Habitats: A Survey") presents an overview of the
    methods used in the identified studies and classifies them into several groups,
    based on their classification algorithms that can be categorized into two general
    category of conventional CV, and modern DL models.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将检索过程分为两个阶段。首先，我们在数据库中查询了标题和内容中包含上述关键词的文章。其次，我们独立审阅了每篇文章的标题和摘要，以检查其与我们的研究主题的相关性。在个别标题和摘要审阅后，我们考虑了64篇文章进行全文阅读。在全文阅读阶段，我们提取了与我们研究主题相关的信息。在这一阶段，显然有21篇论文与我们的工作不相关，因此被排除。这使我们剩下43篇关于鱼类分类的论文，其中26篇为经典计算机视觉方法，17篇为深度学习论文。图[4](#S3.F4
    "图4 ‣ 3.1 搜索和选择标准 ‣ 3 计算机视觉方法在鱼类分类中的演变 ‣ 水下栖息地中鱼类分类的计算机视觉与深度学习：综述")展示了所识别研究中使用的方法，并将其分类为几组，基于其分类算法，这些算法可以分为传统的CV和现代的DL模型。
- en: '![Refer to caption](img/1f3a03c7ef2487a120f1143d25ab781a.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1f3a03c7ef2487a120f1143d25ab781a.png)'
- en: 'Figure 4: An overview of the methods used for fish classification using different
    Computer Vision techniques from 2003 to 2021\. It is evident from the graph that
    DL and its CNNs have attracted more attention than classical ML methods.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：2003年至2021年间使用不同计算机视觉技术进行鱼类分类的方法概述。从图中可以明显看出，深度学习及其卷积神经网络（CNN）比经典的机器学习方法吸引了更多的关注。
- en: '![Refer to caption](img/b9926b8e096ed4feb9efe0052d3488ad.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b9926b8e096ed4feb9efe0052d3488ad.png)'
- en: 'Figure 5: An overview of the publication trend and performance of an extensive
    range of fish classification Computer Vision (CV) and Deep Learning (DL) models
    from 2003 to 2021\. Here the bars show the cumulative number of publications over
    years and the growth thereof, while the line graphs demonstrate the highest classification
    accuracy in each year in literature on the right-hand-side vertical axis.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：2003年至2021年间，鱼类分类计算机视觉（CV）和深度学习（DL）模型的出版趋势和性能概述。这里的条形图显示了多年来累计的出版数量及其增长，而折线图展示了文献中每年的最高分类准确率，位于右侧纵轴。
- en: 3.2 The Evolution of Fish Classification Algorithms over Two Decades
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 两十年来鱼类分类算法的演变
- en: 'The publication trend for fish classification studies is summarized in Fig.[5](#S3.F5
    "Figure 5 ‣ 3.1 Search and Selection Criteria ‣ 3 The evolution of Computer vision
    approaches to fish classification ‣ Computer Vision and Deep Learning for Fish
    Classification in Underwater Habitats: A Survey"). The figure shows the cumulative
    number of publications and how the studies evolved over the past two decades.
    It is evident that the number of publications has been gradually increasing, but
    in 2016, when the first few studies using deep learning were combined with CV
    methods, the study numbers have seen the highest increase and a fast upward trajectory
    for a few years (2015-2019) after DL burgeoned in fish classification, and before
    slowing down.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '鱼类分类研究的出版趋势总结见图[5](#S3.F5 "Figure 5 ‣ 3.1 Search and Selection Criteria ‣ 3
    The evolution of Computer vision approaches to fish classification ‣ Computer
    Vision and Deep Learning for Fish Classification in Underwater Habitats: A Survey")。图中展示了出版物的累计数量以及过去二十年来研究的发展情况。显然，出版物的数量逐渐增加，但在2016年，当最初几项使用深度学习结合计算机视觉方法的研究出现时，研究数量出现了最大增幅，并且在深度学习在鱼类分类中兴起后的几年（2015-2019）经历了快速的上升轨迹，然后开始放缓。'
- en: 'Fig. [5](#S3.F5 "Figure 5 ‣ 3.1 Search and Selection Criteria ‣ 3 The evolution
    of Computer vision approaches to fish classification ‣ Computer Vision and Deep
    Learning for Fish Classification in Underwater Habitats: A Survey") also shows
    the highest classification accuracy achieved in each year, as a quality assessment
    metric. It is evident that since 2016, when DL techniques were first proposed
    for fish classification, the accuracy has seen its highest value. At the same
    time, it can be seen that there are large differences in the accuracies achieved
    over years. The main reasons for this difference include (i) using different classification
    and CV methods, and (ii) using different fish image sources that were captured
    differently and in different environments. These bring huge variations among studies,
    such as different image resolutions and inconsistent resolutions and image qualities
    across time. For example, some fish image datasets are in grayscale [[19](#bib.bib19),
    [20](#bib.bib20), [55](#bib.bib55)], while others are in colour [[144](#bib.bib144),
    [143](#bib.bib143), [113](#bib.bib113)]. Some datasets contain only images [[46](#bib.bib46),
    [55](#bib.bib55)], while others include videos [[74](#bib.bib74), [22](#bib.bib22),
    [39](#bib.bib39)]. Also, some datasets [[43](#bib.bib43)] used low-quality images
    from the internet, which negatively affects the accuracy, due to their wide range
    of resolutions, colours, and angles. They are also taken at random locations.
    Due to these factors in various studies, direct comparison of accuracy values
    is unfeasible, though the accuracy trend can be still observed in Fig. [5](#S3.F5
    "Figure 5 ‣ 3.1 Search and Selection Criteria ‣ 3 The evolution of Computer vision
    approaches to fish classification ‣ Computer Vision and Deep Learning for Fish
    Classification in Underwater Habitats: A Survey").'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '图[5](#S3.F5 "Figure 5 ‣ 3.1 Search and Selection Criteria ‣ 3 The evolution
    of Computer vision approaches to fish classification ‣ Computer Vision and Deep
    Learning for Fish Classification in Underwater Habitats: A Survey")还显示了每年达到的最高分类准确率，作为质量评估指标。显然，自2016年首次提出深度学习技术用于鱼类分类以来，准确率达到了最高值。同时可以看到，不同年份的准确率存在较大差异。这些差异的主要原因包括（i）使用了不同的分类和计算机视觉方法，和（ii）使用了不同的鱼类图像来源，这些图像在捕捉方式和环境上存在差异。这些因素导致了研究之间的巨大变异，例如不同的图像分辨率以及时间上的分辨率和图像质量的不一致。例如，一些鱼类图像数据集是灰度的[[19](#bib.bib19),
    [20](#bib.bib20), [55](#bib.bib55)]，而其他数据集是彩色的[[144](#bib.bib144), [143](#bib.bib143),
    [113](#bib.bib113)]。一些数据集仅包含图像[[46](#bib.bib46), [55](#bib.bib55)]，而其他数据集包括视频[[74](#bib.bib74),
    [22](#bib.bib22), [39](#bib.bib39)]。另外，一些数据集[[43](#bib.bib43)]使用了来自互联网的低质量图像，这些图像由于分辨率、颜色和角度的广泛变化，对准确性产生了负面影响。这些图像也是在随机地点拍摄的。由于这些各种研究中的因素，直接比较准确率值是不切实际的，但准确率的趋势仍然可以在图[5](#S3.F5
    "Figure 5 ‣ 3.1 Search and Selection Criteria ‣ 3 The evolution of Computer vision
    approaches to fish classification ‣ Computer Vision and Deep Learning for Fish
    Classification in Underwater Habitats: A Survey")中观察到。'
- en: 'Computer vision for fish classification in the early 2000s and up to 2016,
    when first DL works started, has been mainly to manually extract fish features
    and then build classifiers that recognize these features. These conventional studies
    are listed, in a chronological order, in Table [1](#S3.T1 "Table 1 ‣ 3.2 The Evolution
    of Fish Classification Algorithms over Two Decades ‣ 3 The evolution of Computer
    vision approaches to fish classification ‣ Computer Vision and Deep Learning for
    Fish Classification in Underwater Habitats: A Survey"). Although there are many
    existing models, most of the classical non-DL models are based on local and engineered
    features. These include works using Haar features [[84](#bib.bib84)], Scale-Invariant
    Feature Transform (SIFT) [[72](#bib.bib72)], and Histogram of Oriented Gradient
    (HOG) [[23](#bib.bib23)], which need hand-engineered algorithms. Because these
    algorithms are not suitable for recognizing images of untrained animals and cannot
    capture fish features from complex backgrounds, they usually use a large number
    of manually extracted samples to build classifiers.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '在2000年代初至2016年，计算机视觉用于鱼类分类主要是通过手动提取鱼类特征，然后构建识别这些特征的分类器。这些传统研究按时间顺序列在表[1](#S3.T1
    "Table 1 ‣ 3.2 The Evolution of Fish Classification Algorithms over Two Decades
    ‣ 3 The evolution of Computer vision approaches to fish classification ‣ Computer
    Vision and Deep Learning for Fish Classification in Underwater Habitats: A Survey")中。虽然存在许多模型，但大多数经典的非深度学习模型基于局部和工程特征。这些包括使用Haar特征[[84](#bib.bib84)]、尺度不变特征变换（SIFT）[[72](#bib.bib72)]和方向梯度直方图（HOG）[[23](#bib.bib23)]的研究，这些方法需要手工设计的算法。由于这些算法不适合识别未经训练的动物图像，并且无法从复杂背景中捕捉鱼类特征，它们通常使用大量手工提取的样本来构建分类器。'
- en: 'As shown in Table [1](#S3.T1 "Table 1 ‣ 3.2 The Evolution of Fish Classification
    Algorithms over Two Decades ‣ 3 The evolution of Computer vision approaches to
    fish classification ‣ Computer Vision and Deep Learning for Fish Classification
    in Underwater Habitats: A Survey"), support vector machines [[105](#bib.bib105),
    [42](#bib.bib42), [31](#bib.bib31), [43](#bib.bib43), [20](#bib.bib20), [87](#bib.bib87),
    [39](#bib.bib39), [132](#bib.bib132), [46](#bib.bib46)] were one of the most commonly
    used classifiers for fish recognition, but they are prone to overfitting when
    trained with too many samples. This problem limits the scale of application. Another
    popular classification technique used in early works was backpropagation to train
    a simple feed-forward shallow neural network [[4](#bib.bib4), [3](#bib.bib3),
    [98](#bib.bib98), [6](#bib.bib6), [13](#bib.bib13)]. Although this technique can
    handle simple samples, it is difficult to scale because of the neural network
    shallow layers, which will be explained in the next Section. Naive Bayes [[85](#bib.bib85),
    [143](#bib.bib143), [144](#bib.bib144), [55](#bib.bib55)] have also been used
    to classify fish since the early 2000s and up to 2017\. The technique does not
    require much training data, and as shown in Table [1](#S3.T1 "Table 1 ‣ 3.2 The
    Evolution of Fish Classification Algorithms over Two Decades ‣ 3 The evolution
    of Computer vision approaches to fish classification ‣ Computer Vision and Deep
    Learning for Fish Classification in Underwater Habitats: A Survey") can reach
    good accuracy levels. Table [1](#S3.T1 "Table 1 ‣ 3.2 The Evolution of Fish Classification
    Algorithms over Two Decades ‣ 3 The evolution of Computer vision approaches to
    fish classification ‣ Computer Vision and Deep Learning for Fish Classification
    in Underwater Habitats: A Survey") also shows some other CV classification techniques,
    which while not as popular as the above-mentioned methods, could demonstrate good
    performance. However, it should be noted that, most of the CV techniques in Table
    [1](#S3.T1 "Table 1 ‣ 3.2 The Evolution of Fish Classification Algorithms over
    Two Decades ‣ 3 The evolution of Computer vision approaches to fish classification
    ‣ Computer Vision and Deep Learning for Fish Classification in Underwater Habitats:
    A Survey"), were carefully engineered for their target datasets and are not capable
    of showing a similar performance level if used for another similar dataset. They
    will perhaps require an overhaul in their design, starting from manual feature
    engineering, to designing the detailed classification models.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '如表格 [1](#S3.T1 "Table 1 ‣ 3.2 The Evolution of Fish Classification Algorithms
    over Two Decades ‣ 3 The evolution of Computer vision approaches to fish classification
    ‣ Computer Vision and Deep Learning for Fish Classification in Underwater Habitats:
    A Survey") 所示，支持向量机 [[105](#bib.bib105), [42](#bib.bib42), [31](#bib.bib31), [43](#bib.bib43),
    [20](#bib.bib20), [87](#bib.bib87), [39](#bib.bib39), [132](#bib.bib132), [46](#bib.bib46)]
    是鱼类识别中最常用的分类器之一，但在用样本过多时容易过拟合。这一问题限制了应用规模。早期工作中另一种常用的分类技术是反向传播，用于训练简单的前馈浅层神经网络
    [[4](#bib.bib4), [3](#bib.bib3), [98](#bib.bib98), [6](#bib.bib6), [13](#bib.bib13)]。虽然该技术可以处理简单样本，但由于神经网络的浅层结构，难以扩展，这将在下一节中解释。朴素贝叶斯
    [[85](#bib.bib85), [143](#bib.bib143), [144](#bib.bib144), [55](#bib.bib55)] 自2000年代初至2017年也被用于鱼类分类。这种技术不需要大量的训练数据，且如表格
    [1](#S3.T1 "Table 1 ‣ 3.2 The Evolution of Fish Classification Algorithms over
    Two Decades ‣ 3 The evolution of Computer vision approaches to fish classification
    ‣ Computer Vision and Deep Learning for Fish Classification in Underwater Habitats:
    A Survey") 所示，可以达到良好的准确性水平。表格 [1](#S3.T1 "Table 1 ‣ 3.2 The Evolution of Fish
    Classification Algorithms over Two Decades ‣ 3 The evolution of Computer vision
    approaches to fish classification ‣ Computer Vision and Deep Learning for Fish
    Classification in Underwater Habitats: A Survey") 还展示了一些其他计算机视觉分类技术，虽然它们不像上述方法那样流行，但也能表现出良好的性能。然而，需要注意的是，表格
    [1](#S3.T1 "Table 1 ‣ 3.2 The Evolution of Fish Classification Algorithms over
    Two Decades ‣ 3 The evolution of Computer vision approaches to fish classification
    ‣ Computer Vision and Deep Learning for Fish Classification in Underwater Habitats:
    A Survey") 中的大多数计算机视觉技术都是针对其目标数据集精心设计的，如果用于其他类似的数据集，则可能无法表现出类似的性能。它们可能需要从手动特征工程到设计详细的分类模型等方面进行全面的调整。'
- en: In contrast, deep learning can extract features and perform classification tasks
    automatically. The features are invariant to data scaling, translation, rotation,
    and distortion. Because these features are better for classification, the classification
    performance can be better than that conventional CV tasks using manually designed
    features. Also, DL classification models, compared to traditional CV one, usually
    require a simpler redesign procedure to work on a new similar dataset, due to
    the ability to extract features on their own.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，深度学习可以自动提取特征并执行分类任务。这些特征对数据缩放、平移、旋转和失真具有不变性。由于这些特征更适合分类，分类性能通常优于使用手工设计特征的传统计算机视觉任务。此外，与传统的计算机视觉方法相比，深度学习分类模型通常需要更简单的重新设计程序来处理新的相似数据集，因为它们能够自主提取特征。
- en: 'Although DL emerged in 2012 [[62](#bib.bib62)], its first use for underwater
    fish classification was in 2016 [[109](#bib.bib109)]. After that, 16 other works
    also used DL and its CNNs, as shown in Fig. [4](#S3.F4 "Figure 4 ‣ 3.1 Search
    and Selection Criteria ‣ 3 The evolution of Computer vision approaches to fish
    classification ‣ Computer Vision and Deep Learning for Fish Classification in
    Underwater Habitats: A Survey"), to develop models that learn features from large
    amounts of data without manual interference. These studies have shown that, by
    using deep learning, some of the usual fish image classification challenges such
    as image noise reduction, classification of difficult or rare-seen fish, and classifying
    small fish, can be solved.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度学习于 2012 年出现 [[62](#bib.bib62)]，但其首次用于水下鱼类分类是在 2016 年 [[109](#bib.bib109)]。之后，另外
    16 项工作也使用了深度学习及其卷积神经网络，如图 [4](#S3.F4 "图 4 ‣ 3.1 搜索和选择标准 ‣ 3 计算机视觉方法的发展 ‣ 水下栖息地中的鱼类分类：计算机视觉和深度学习的调查")
    所示，开发了从大量数据中学习特征的模型，而无需人工干预。这些研究表明，通过使用深度学习，一些常见的鱼类图像分类挑战，如图像噪声减少、难度大或稀有鱼类的分类，以及小鱼的分类，可以得到解决。
- en: In the following parts of this paper, we mainly focus on deep learning, how
    it works, and how it can be applied to develop efficient and high-performance
    underwater fish classifiers. We will also critically analyse the 17 DL studies
    found as part of our systematic literature review described earlier.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的后续部分，我们主要关注深度学习，它的工作原理以及如何应用于开发高效且高性能的水下鱼类分类器。我们还将批判性地分析作为我们系统文献综述一部分发现的
    17 个深度学习研究。
- en: 'Table 1: A list of computer vision studies for underwater fish classification
    between 2003-2021 using conventional classifiers and based on engineered features.
    The last column presents the work’s achieved accuracy.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：2003-2021 年间使用传统分类器和基于工程特征的水下鱼类分类的计算机视觉研究列表。最后一列展示了工作的准确率。
- en: '| Article | Year | Classification Method | AC |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | 年份 | 分类方法 | 准确率 |'
- en: '| An Automated Fish Species Classification and Migration Monitoring System
    [[70](#bib.bib70)] | 2003 | Feature vector Classification | 92 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 自动鱼类物种分类和迁徙监测系统 [[70](#bib.bib70)] | 2003 | 特征向量分类 | 92 |'
- en: '| Determining the appropriate feature set for fish classification tasks [[85](#bib.bib85)]
    | 2005 | Naive Bayes | 90 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 确定鱼类分类任务的适当特征集 [[85](#bib.bib85)] | 2005 | 朴素贝叶斯 | 90 |'
- en: '| Real-time underwater sorting of edible fish species [[143](#bib.bib143)]
    | 2006 | Naive Bayes | 98 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 实时水下可食用鱼种分类 [[143](#bib.bib143)] | 2006 | 朴素贝叶斯 | 98 |'
- en: '| One Fish, Two Fish, Butterfish, Trumpeter: Recognizing Fish in Underwater
    Video [[105](#bib.bib105)] | 2007 | Support vector machine | 90 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 一鱼、两鱼、黄油鱼、号角鱼：识别水下视频中的鱼 [[105](#bib.bib105)] | 2007 | 支持向量机 | 90 |'
- en: '| Classification of guppies’ (Poecilia reticulata) gender by computer vision
    [[144](#bib.bib144)] | 2008 | Naive Bayes | 96 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 通过计算机视觉分类孔雀鱼（Poecilia reticulata）的性别 [[144](#bib.bib144)] | 2008 | 朴素贝叶斯
    | 96 |'
- en: '| Automatic Fish Classification for Underwater Species Behavior Understanding
    [[118](#bib.bib118)] | 2010 | Discriminant Analysis Classification | 92 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 自动鱼类分类用于水下物种行为理解 [[118](#bib.bib118)] | 2010 | 判别分析分类 | 92 |'
- en: '| Fish Recognition Based on Robust Features Extraction from Size and Shape
    Measurements Using Neural Network [[4](#bib.bib4)] | 2010 | Backpropagation |
    86 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 基于神经网络的从尺寸和形状测量中提取鲁棒特征的鱼类识别 [[4](#bib.bib4)] | 2010 | 反向传播 | 86 |'
- en: '| Fish Classification Based on Robust Features Extraction From Color Signature
    Using Back-Propagation Classifier [[3](#bib.bib3)] | 2011 | Backpropagation |
    84 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 基于颜色特征签名的鲁棒特征提取的鱼类分类使用反向传播分类器 [[3](#bib.bib3)] | 2011 | 反向传播 | 84 |'
- en: '| Fish species classification by color, texture and multi-class support vector
    machine using computer vision [[42](#bib.bib42)] | 2012 | Support vector machine
    | 97 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 基于颜色、纹理和多类支持向量机的鱼类物种分类，使用计算机视觉 [[42](#bib.bib42)] | 2012 | 支持向量机 | 97 |'
- en: '| Real-world underwater fish recognition and identification, using sparse representation
    [[40](#bib.bib40)] | 2013 | Sparse representation classification | 81 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 使用稀疏表示进行现实世界水下鱼类识别和鉴定 [[40](#bib.bib40)] | 2013 | 稀疏表示分类 | 81 |'
- en: '| A research tool for long-term and continuous analysis of fish assemblage
    in coral-reefs using underwater camera footage [[10](#bib.bib10)] | 2013 | Gaussian
    Mixture Model | 97 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 使用水下摄像头视频进行长期连续鱼群分析的研究工具 [[10](#bib.bib10)] | 2013 | 高斯混合模型 | 97 |'
- en: '| Automatic Nile Tilapia Fish Classification Approach using Machine Learning
    Techniques [[31](#bib.bib31)] | 2013 | Support vector machine | 94 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 基于机器学习技术的尼罗罗非鱼自动分类方法 [[31](#bib.bib31)] | 2013 | 支持向量机 | 94 |'
- en: '| Shape- and Texture-Based Fish Image Recognition System [[98](#bib.bib98)]
    | 2013 | Backpropagation | 90 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 基于形状和纹理的鱼类图像识别系统 [[98](#bib.bib98)] | 2013 | 反向传播 | 90 |'
- en: '| A General Fish Classification Methodology Using Meta-heuristic Algorithm
    With Back Propagation Classifier [[6](#bib.bib6)] | 2014 | Backpropagation | 80
    |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 一种使用元启发式算法和反向传播分类器的通用鱼类分类方法 [[6](#bib.bib6)] | 2014 | 反向传播 | 80 |'
- en: '| GMM improves the reject option in hierarchical classification for fish recognition
    [[43](#bib.bib43)] | 2014 | Support vector machine | 74 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| GMM改进了鱼类识别中的层次分类的拒绝选项 [[43](#bib.bib43)] | 2014 | 支持向量机 | 74 |'
- en: '| Supervised and Unsupervised Feature Extraction Methods for Underwater Fish
    Species Recognition [[19](#bib.bib19)] | 2014 | Hierarchical Partial Classifier
    | 93 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 用于水下鱼类物种识别的监督和非监督特征提取方法 [[19](#bib.bib19)] | 2014 | 层次部分分类器 | 93 |'
- en: '| A Feature Learning and Object Recognition Framework for Underwater Fish Images
    [[20](#bib.bib20)] | 2015 | Support vector machine | 98 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 用于水下鱼类图像的特征学习和物体识别框架 [[20](#bib.bib20)] | 2015 | 支持向量机 | 98 |'
- en: '| A novel tool for ground truth data generation for video-based object classification
    [[74](#bib.bib74)] | 2015 | K-means algorithm | 93 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 一种用于基于视频的物体分类的地面真实数据生成新工具 [[74](#bib.bib74)] | 2015 | K-means算法 | 93 |'
- en: '| Automated detection of rockfish in unconstrained underwater videos using
    Haar cascades and a new image dataset: labeled fishes in the wild [[22](#bib.bib22)]
    | 2015 | Haar cascade classifiers | 89 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 使用Haar级联和新的图像数据集（标记的野生鱼类）在不受约束的水下视频中自动检测岩鱼 [[22](#bib.bib22)] | 2015 | Haar级联分类器
    | 89 |'
- en: '| Fish Classification Using Support Vector Machine [[87](#bib.bib87)] | 2015
    | Support vector machine | 79 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 使用支持向量机进行鱼类分类 [[87](#bib.bib87)] | 2015 | 支持向量机 | 79 |'
- en: '| Fish identification from videos captured in uncontrolled underwater environments
    [[113](#bib.bib113)] | 2016 | Sparse Approximated Nearest Point | 94 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 从不受控水下环境中拍摄的视频中识别鱼类 [[113](#bib.bib113)] | 2016 | 稀疏近似最近点 | 94 |'
- en: '| Fish Activity Tracking and Species Identification in Underwater Video [[39](#bib.bib39)]
    | 2016 | Support vector machine | 91 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 水下视频中的鱼类活动追踪与物种识别 [[39](#bib.bib39)] | 2016 | 支持向量机 | 91 |'
- en: '| Koi Fish Classification based on HSV Color Space [[55](#bib.bib55)] | 2016
    | Naive Bayes | 97 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 基于HSV颜色空间的锦鲤分类 [[55](#bib.bib55)] | 2016 | 朴素贝叶斯 | 97 |'
- en: '| Optical Fish Classification Using Statistics of Parts [[13](#bib.bib13)]
    | 2016 | Backpropagation | 95 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 使用部件统计的光学鱼类分类 [[13](#bib.bib13)] | 2016 | 反向传播 | 95 |'
- en: '| Shrinking Encoding with Two-Level Codebook Learning for Fine-Grained Fish
    Recognition [[132](#bib.bib132)] | 2017 | Support vector machine | 98 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 使用双层代码本学习进行细粒度鱼类识别的收缩编码 [[132](#bib.bib132)] | 2017 | 支持向量机 | 98 |'
- en: '| Indigenous Fish Classification of Bangladesh using Hybrid Features with SVM
    Classifier [[46](#bib.bib46)] | 2019 | Support vector machine | 94 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 使用混合特征和SVM分类器对孟加拉国土著鱼类进行分类 [[46](#bib.bib46)] | 2019 | 支持向量机 | 94 |'
- en: 4 Background To Deep Learning
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习背景
- en: Deep Learning (DL) [[34](#bib.bib34), [68](#bib.bib68)] is a subset of ML algorithms
    that employs a neural network with several layers to very loosely replicate the
    function of the human brain by enabling it to "learn" from huge quantities of
    data. The learning happens when the neural network extracts higher-level features
    from input training data. The term "deep" refers to the usage of several layers
    in the neural network. Lower layers, for example in image processing, could detect
    edges, whereas higher layers might identify parts of the object.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）[[34](#bib.bib34), [68](#bib.bib68)] 是机器学习（ML）算法的一个子集，它通过使用具有多层的神经网络来非常松散地模拟人脑的功能，使其能够从大量数据中“学习”。这种学习发生在神经网络从输入训练数据中提取更高层次的特征时。术语“深度”指的是神经网络中使用了多个层次。较低的层次，例如在图像处理中的层次，可能检测到边缘，而较高的层次可能识别对象的部分。
- en: 4.1 How Deep Learning differs from Machine Learning
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 深度学习与机器学习的区别
- en: 'Machine Learning (ML) is usually referred to as a class of algorithms that
    can recognise patterns in data and create prediction models automatically. Deep
    Learning (DL) is a subclass of standard ML because it uses the same type of data
    and learning methods that ML applies. However, when dealing with unstructured
    data, e.g. text and images, ML usually goes through some pre-processing to convert
    it to a structured format for learning. DL, on the other hand, does not usually
    require the data pre-processing needed by ML. It is capable of recognising and
    analysing unstructured data, as well as automating feature extraction, significantly
    reducing the need for human knowledge (see Figure [2](#S2.F2 "Figure 2 ‣ 2 Background
    To Computer Vision and Machine Learning ‣ Computer Vision and Deep Learning for
    Fish Classification in Underwater Habitats: A Survey")-bottom).'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）通常被称为能够识别数据模式并自动创建预测模型的一类算法。深度学习（DL）是标准ML的一个子类，因为它使用与ML相同类型的数据和学习方法。然而，在处理非结构化数据时，例如文本和图像，ML通常需要经过一些预处理，以将数据转换为结构化格式进行学习。相反，DL通常不需要ML所需的数据预处理。它能够识别和分析非结构化数据，并自动进行特征提取，从而显著减少对人工知识的需求（见图
    [2](#S2.F2 "图 2 ‣ 计算机视觉与机器学习背景 ‣ 深度学习在水下栖息地鱼类分类中的应用：一项调查")-底部）。
- en: For example, to recognise fish in an image, ML requires that specific fish features
    (such as shape, colour, size, and patterns) be explicitly defined in terms of
    pixel patterns. This may be a challenge for non-ML specialists because it typically
    requires a deep grasp of the domain knowledge and good programming skills. DL
    techniques, on the other hand, skip this step entirely. Using general learning
    techniques, DL systems can automatically recognise and extract features from data.
    This means that we just need to tell a DL algorithm whether a fish is present
    in an image, and it will be able to figure out what a fish looks like given enough
    examples. Decomposing the data into layers with varying levels of abstraction
    enables the algorithm to learn complex traits defining the data, allowing for
    an automatic learning approach. DL algorithms may be able to determine which features
    (such as fishtail) are most important in differentiating one animal from another.
    Prior to DL, this feature hierarchy needed to be determined and created by hand
    by an ML expert.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要在图像中识别鱼类，ML需要明确地定义特定鱼类特征（如形状、颜色、大小和模式），这些特征以像素模式的形式表示。这对于非ML专家可能是一个挑战，因为这通常需要深入的领域知识和良好的编程技能。而DL技术则完全跳过了这一过程。通过使用通用学习技术，DL系统可以自动识别和提取数据中的特征。这意味着我们只需要告诉DL算法图像中是否存在鱼类，给定足够的示例，它将能够弄清楚鱼类的样子。将数据分解为具有不同抽象层次的层，使算法能够学习定义数据的复杂特征，从而实现自动学习方法。DL算法可能能够确定哪些特征（如鱼尾）在区分不同动物时最为重要。在DL出现之前，这种特征层次结构需要由ML专家手动确定和创建。
- en: 4.2 How Deep Learning works
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 深度学习如何工作
- en: 'Deep Neural Network (DNN), also known as artificial neural network, is the
    basis of deep learning. DNNs use a mix of data inputs, weights, and biases to
    learn the data, by properly detecting, categorising, and characterising objects
    in a given dataset of interest. DNNs are made up of several layers of linked nodes,
    each of which improves and refines the network prediction or categorisation capabilities.
    For instance, Fig. [3](#S2.F3 "Figure 3 ‣ 2 Background To Computer Vision and
    Machine Learning ‣ Computer Vision and Deep Learning for Fish Classification in
    Underwater Habitats: A Survey") shows a popular DNN architecture for image processing,
    called UNET [[104](#bib.bib104)]. UNET, which is a fairly complex deep learning
    architecture, is composed of a few different components and layers, to achieve
    a specific learning goal, i.e. to segment fish body in an input image.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络（DNN），也称为人工神经网络，是深度学习的基础。DNN通过适当地检测、分类和特征化给定数据集中的对象，使用数据输入、权重和偏置的组合来学习数据。DNN由多个连接的节点层组成，每一层都提高和优化了网络的预测或分类能力。例如，图[3](#S2.F3
    "图 3 ‣ 2 计算机视觉与机器学习背景 ‣ 计算机视觉和深度学习在水下栖息地鱼类分类中的应用：综述")展示了一种用于图像处理的流行DNN架构，称为UNET
    [[104](#bib.bib104)]。UNET是一个相当复杂的深度学习架构，由几个不同的组件和层组成，旨在实现一个特定的学习目标，即在输入图像中分割鱼体。
- en: 'Any DNN is composed of three types of layers, namely input, output, and hidden
    layers. The visible layers are the input and output layers (see Figure [6](#S4.F6
    "Figure 6 ‣ 4.2 How Deep Learning works ‣ 4 Background To Deep Learning ‣ Computer
    Vision and Deep Learning for Fish Classification in Underwater Habitats: A Survey")).
    The DL model gets the data for processing in the input layer, and the final prediction
    or classification is generated in the output layer. In a typical neural network,
    including a DNN, the learning happens through two general processes, i.e. forward
    and backward propagations. Forward propagation refers to the propagation of input
    data through the network layers to generate a prediction or classification result.
    Backward propagation or, backpropagation in short, is where the learning happens
    in the network. Backpropagation uses a training model that determines prediction
    errors and then changes the weights and biases of the neural network by going
    backwards through its layers. Forward propagation and backpropagation work together
    to allow a neural network to generate predictions and reduce the network errors.
    Through many iterations of backward and forward propagation, the neural network
    prediction or classification accuracy improves.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 任何深度神经网络（DNN）由三种类型的层组成，即输入层、输出层和隐藏层。可见的层是输入层和输出层（见图[6](#S4.F6 "图 6 ‣ 4.2 深度学习如何工作
    ‣ 4 深度学习背景 ‣ 计算机视觉和深度学习在水下栖息地鱼类分类中的应用：综述")）。深度学习模型在输入层接收数据进行处理，最终的预测或分类在输出层生成。在典型的神经网络中，包括DNN，学习通过两个一般过程进行，即前向传播和反向传播。前向传播指的是输入数据通过网络层传播以生成预测或分类结果。反向传播，简称反向传播，是网络学习发生的地方。反向传播使用训练模型来确定预测错误，然后通过反向传递的方式改变神经网络的权重和偏置。前向传播和反向传播共同工作，使神经网络能够生成预测并减少网络错误。通过多次前向传播和反向传播迭代，神经网络的预测或分类准确性得到提高。
- en: Almost all DNNs work on and through the same principles described above. However,
    different DL networks and architectures are used to solve different tasks. For
    instance, CNNs, which are commonly used in computer vision and image classification
    applications, can recognise characteristics and patterns within an image, allowing
    tasks such as object detection and recognition to be accomplished. However, in
    tasks with a different nature, such as natural language processing, speech recognition,
    or timeseries forecasting [[49](#bib.bib49)], Recurrent Neural Networks (RNNs)
    are commonly employed. Despite the differences in their architectures, many DL
    techniques, use the concept of supervised learning to process their input data
    and accomplish different tasks.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有DNN都基于上述相同的原理进行工作。然而，不同的深度学习网络和架构用于解决不同的任务。例如，CNNs通常用于计算机视觉和图像分类应用中，可以识别图像中的特征和模式，从而完成对象检测和识别等任务。然而，对于具有不同性质的任务，如自然语言处理、语音识别或时间序列预测
    [[49](#bib.bib49)]，常常使用递归神经网络（RNNs）。尽管它们的架构有所不同，许多深度学习技术都使用监督学习的概念来处理输入数据并完成不同的任务。
- en: '![Refer to caption](img/c92c3ebd2489331055f3cc6a1ed0db4d.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c92c3ebd2489331055f3cc6a1ed0db4d.png)'
- en: 'Figure 6: A diagram of a single-layer neural network, composed of input, hidden,
    and output layers.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：一个单层神经网络的示意图，由输入层、隐藏层和输出层组成。
- en: 4.3 Supervised Learning
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 监督学习
- en: Supervised learning is a method used to enable finding and optimising a function
    that maps an input to its corresponding output in an input-output object pair,
    also known as training example [[61](#bib.bib61)]. Supervised learning uses a
    set of training examples based on manually-labelled training data prepared by
    human observers or ’supervisors’, hence the name for the learning method.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习是一种用于寻找和优化将输入映射到其对应输出的函数的方法，也称为训练样本[[61](#bib.bib61)]。监督学习使用基于人工标注的训练数据集，这些数据集由人工观察者或“监督者”准备，因此得名。
- en: The aim of supervised learning is to generate an inferred function, $f$, that
    maps to the training examples, and can then be used to map to new examples outside
    of the training examples. In order to accomplish any general task, a computer
    can be programmed to find function $f$ to map $X$ to $Y$, i.e. ($f:X\mapsto Y$),
    where $X$ is an input domain and $Y$ is an output domain. For example, in an image
    classification task, $X$ is the dataset of images and $Y$ is a set of corresponding
    classification labels, which determine whether an object is present in the respective
    image in the dataset or not.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的目标是生成一个推断函数 $f$，该函数映射到训练样本，然后可以用于映射到训练样本之外的新样本。为了完成任何一般任务，计算机可以被编程找到函数
    $f$ 以将 $X$ 映射到 $Y$，即（$f:X\mapsto Y$），其中 $X$ 是输入域，$Y$ 是输出域。例如，在图像分类任务中，$X$ 是图像数据集，$Y$
    是一组对应的分类标签，决定图像数据集中是否存在一个对象。
- en: To determine the function $f$ that can recognise, for instance, a fish in an
    image using DL, one solution is to do feature engineering. However, it is usually
    very difficult to perform this, i.e. hand-pick features of the fish, based on
    the domain knowledge that comes from the training dataset. In addition, most of
    the time, the hand-picked features need to be pruned to reduce their pixel dimensionality.
    Comparatively, it is often more feasible to collect a large dataset of $(x,y)\in
    X\times Y$ to find the mapping function $f$, and this affords supervised learning
    advantage as an alternative mapping technique compared with direct feature engineering.
    Specifically, in the fish classification task, a large dataset of fish images
    is collected, where each image $x$ is labelled with $y$ that shows the presence
    or absence of a fish, without the need to hand-pick its features.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定能够识别图像中鱼类的函数 $f$，例如，使用深度学习（DL）的一种解决方案是进行特征工程。然而，通常很难执行这一操作，即根据训练数据集中的领域知识手动挑选鱼的特征。此外，大多数情况下，手动挑选的特征需要被修剪以减少其像素维度。相比之下，收集大量的
    $(x,y)\in X\times Y$ 数据集以寻找映射函数 $f$ 通常更为可行，这相较于直接的特征工程，提供了监督学习的优势。具体来说，在鱼类分类任务中，收集了一大批鱼类图像数据集，其中每张图像
    $x$ 都用 $y$ 标记，显示鱼的存在与否，而无需手动挑选其特征。
- en: One of the main supervised learning approaches is training a neural network,
    which is the foundation of deep learning, especially for computer vision applications
    such as fish image processing. We, therefore, dedicate the next subsection to
    neural networks and their underlying working principles.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的监督学习方法之一是训练神经网络，这是深度学习的基础，特别是用于计算机视觉应用如鱼类图像处理。因此，我们将接下来的子节专门用于神经网络及其基本工作原理。
- en: 4.4 Neural Networks
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 神经网络
- en: 'A ’neural network’ [[21](#bib.bib21)] is a computer program originally conceived
    by mimicking actual cerebral neural networks that make up the brain’s grey matter.
    A computer’s neural network, a.k.a. an artificial neural network, "learns" to
    do a specific task by using a large amount of data, usually through supervised
    network training that does not involve any task-specific rules. As briefly mentioned,
    a neural network is constructed from three types of layers: an input layer, hidden
    or latent layers, and an output layer (see Figure [6](#S4.F6 "Figure 6 ‣ 4.2 How
    Deep Learning works ‣ 4 Background To Deep Learning ‣ Computer Vision and Deep
    Learning for Fish Classification in Underwater Habitats: A Survey")). These layers
    include processing neurons within them (coloured circles in Figure [6](#S4.F6
    "Figure 6 ‣ 4.2 How Deep Learning works ‣ 4 Background To Deep Learning ‣ Computer
    Vision and Deep Learning for Fish Classification in Underwater Habitats: A Survey")),
    and connecting synapses (weights) between them (edges in the figure).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '“神经网络”[[21](#bib.bib21)]是一个计算机程序，其最初的构思是模仿构成大脑灰质的实际脑神经网络。计算机的神经网络，即人工神经网络，通过使用大量数据来“学习”执行特定任务，通常是通过不涉及任何任务特定规则的监督网络训练。如简要提到的，神经网络由三种类型的层构成：输入层、隐藏层或潜在层和输出层（见图
    [6](#S4.F6 "Figure 6 ‣ 4.2 How Deep Learning works ‣ 4 Background To Deep Learning
    ‣ Computer Vision and Deep Learning for Fish Classification in Underwater Habitats:
    A Survey")）。这些层中包含处理神经元（图 [6](#S4.F6 "Figure 6 ‣ 4.2 How Deep Learning works ‣
    4 Background To Deep Learning ‣ Computer Vision and Deep Learning for Fish Classification
    in Underwater Habitats: A Survey")中的彩色圆圈）以及它们之间的连接突触（权重）（图中的边）。'
- en: The input layer is the gate to the network. It provides information to the network
    from outside data, and no calculation is made in this layer. Instead, input nodes
    pass the information on to the hidden layer. This layer is not visible to the
    outside world and serves as an abstraction of the inputs, independent of the neural
    network structure. The hidden layer (layers) processes the data received from
    the input layer and transfers the results to the output layer. Finally, the output
    layer brings the information that the network has learned into the outside world.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 输入层是网络的门户。它从外部数据提供信息给网络，并且在此层中不进行任何计算。相反，输入节点将信息传递给隐藏层。此层对外界不可见，作为输入的抽象，与神经网络结构无关。隐藏层（层）处理从输入层接收的数据，并将结果传递到输出层。最后，输出层将网络所学到的信息带到外部世界。
- en: Learning in a neural network happens through minimising a loss function. Generally,
    a loss function is a function that returns a scalar value to represent how well
    the network performs a specific task. For example, in image classification, the
    network is expected to correctly classify all the images containing a fish as
    fish, and all those not including a fish, as no fish, returning a loss value of
    zero. During learning, the network receives a large amount of input data, e.g.
    thousands of fish images, and eventually learns to minimise the loss between its
    predicted output and the true target value. In the case of supervised learning,
    these true target values are provided to the network, to find function $f$ described
    in the previous section, to minimise the loss function. This minimisation happens
    through optimising $f$ using an algorithm such as Stochastic Gradient Descent
    (SGD) [[75](#bib.bib75)] that helps find network weights/parameters that minimise
    the loss.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络中的学习是通过最小化损失函数来实现的。通常，损失函数是一个返回标量值的函数，用于表示网络执行特定任务的效果。例如，在图像分类中，网络期望正确地将所有包含鱼的图像分类为鱼，将所有不包含鱼的图像分类为非鱼，损失值为零。在学习过程中，网络接收大量输入数据，例如成千上万的鱼类图像，并最终学会最小化预测输出与真实目标值之间的损失。在监督学习的情况下，这些真实目标值提供给网络，以寻找上一节中描述的函数
    $f$，以最小化损失函数。这种最小化通过使用诸如随机梯度下降（SGD）[[75](#bib.bib75)]等算法来优化 $f$，帮助找到最小化损失的网络权重/参数。
- en: '![Refer to caption](img/c26d482447bfe621c5b31551302155ce.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c26d482447bfe621c5b31551302155ce.png)'
- en: 'Figure 7: Schematic diagram of pooling layer: (Left) single feature map spatially
    downsampled from a representation block with shape $224\times 224\times 1$ to
    a new representation of shape $112\times 112\times 1$. (Right) types of pooling
    layer (max-pooling and average-pooling).'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：池化层的示意图：（左）从形状为$224\times 224\times 1$的表示块中空间下采样得到的新表示，形状为$112\times 112\times
    1$。（右）池化层的类型（最大池化和平均池化）。
- en: 4.5 Convolutional Neural Network
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 卷积神经网络
- en: CNNs are probably the most commonly used artificial neural networks. They have
    been the dominant deep learning tool in computer vision and have been widely used
    in underwater marine habitat monitoring [[107](#bib.bib107)]. CNNs are broadly
    designed after the neuronal architecture of the human cortex but on much smaller
    scales [[111](#bib.bib111)]. A CNN [[69](#bib.bib69)] is specifically designed
    for dealing with datasets that have some spatial or topological features (e.g.
    images, videos), where each of the neurons are placed in such a manner that they
    overlap and thus react to multiple spots in the visual field. A CNN neuron is
    a simple mathematical design of the human brain’s neuron that is utilised to transform
    nonlinear relationships between inputs and outputs in parallel. There are two
    primary layer types in a CNN, i.e. convolutional layers and pooling layers, which
    generate feature maps, as explained in the following subsections.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 可能是最常用的人工神经网络。它们在计算机视觉领域一直是主要的深度学习工具，并且被广泛应用于水下海洋栖息地监测 [[107](#bib.bib107)]。CNN
    的设计灵感来源于人脑皮层的神经元结构，但规模要小得多 [[111](#bib.bib111)]。CNN [[69](#bib.bib69)] 特别设计用于处理具有某些空间或拓扑特征的数据集（例如图像、视频），其中每个神经元的布置方式使得它们重叠，从而对视觉领域中的多个点做出反应。CNN
    神经元是对人脑神经元的简单数学设计，利用这种设计并行转换输入和输出之间的非线性关系。CNN 中有两种主要的层类型，即卷积层和池化层，它们生成特征图，详细说明见以下小节。
- en: 4.5.1 Convolutional Layer
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.1 卷积层
- en: In this layer, the convolutional processes (i.e., the multiplication of a small
    matrix of the input neurons by a small array of weights called filter) are used
    on limited fields (which depend on the size of the filter) to avoid the need to
    learn billions of weights (parameters), which would be required if all the neurons
    in one layer are connected to all the neurons in the next layer. This excessive
    computation is avoided through the weight-sharing of convolutional layers combined
    with filters for their corresponding feature maps. In a convolution operation,
    a small matrix of the input neurons is multiplied in its same-sized matrix, called
    a filter. In a convolutional layer, this convolution operation happens by sliding
    the filter on the entire input neurons, generating a feature map. Filters work
    on a reduced area of the input (convolutional kernel). Convolutional layers can
    either use the same kernel size or they can use different kernel sizes, which
    makes it possible to extract complex features from the input using fewer parameters.
    In addition, weight-sharing is useful in avoiding model overfitting, i.e. memorising
    the training data, [[1](#bib.bib1)], while also reducing computing memory requirements
    and enhancing learning performance [[60](#bib.bib60)].
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一层中，卷积过程（即将输入神经元的小矩阵与称为滤波器的小权重数组相乘）被应用于有限的领域（取决于滤波器的大小），以避免需要学习数十亿个权重（参数），如果一层中的所有神经元都连接到下一层的所有神经元，就会需要这些权重。通过卷积层的权重共享和与其对应特征图的滤波器的结合，避免了这种过度计算。在卷积操作中，将输入神经元的小矩阵与其同样大小的矩阵，即滤波器相乘。在卷积层中，这一卷积操作通过在整个输入神经元上滑动滤波器来进行，生成特征图。滤波器作用于输入的缩小区域（卷积核）。卷积层可以使用相同的卷积核大小，也可以使用不同的卷积核大小，这使得通过较少的参数从输入中提取复杂特征成为可能。此外，权重共享有助于避免模型过拟合，即记忆训练数据
    [[1](#bib.bib1)]，同时减少计算内存需求，并提高学习性能 [[60](#bib.bib60)]。
- en: 4.5.2 Pooling Layer
  id: totrans-138
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.2 池化层
- en: 'This layer is used to reduce the spatial dimension (not depth) of the input
    features and add control for avoiding overfitting by reducing the number of representations
    with a specified spatial size. Pooling operations can be done in two different
    ways, i.e. Max and Average pooling. In both methods (see Figure [7](#S4.F7 "Figure
    7 ‣ 4.4 Neural Networks ‣ 4 Background To Deep Learning ‣ Computer Vision and
    Deep Learning for Fish Classification in Underwater Habitats: A Survey")), an
    input image is down-scaled in size, by taking the maximum of 4 pixels and down-sampling
    them to one pixel. Pooling layers are systematically implemented between convolutional
    layers in conventional CNN architectures. The pooling layers work on each channel
    (activation map) individually and downsample them spatially. By having fewer spatial
    information, pooling layers make a CNN more computationally efficient.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '这一层用于减少输入特征的空间维度（非深度），并通过减少具有指定空间大小的表示的数量来增加避免过拟合的控制。池化操作可以通过两种不同的方式进行，即最大池化和平均池化。在这两种方法中（见图
    [7](#S4.F7 "Figure 7 ‣ 4.4 Neural Networks ‣ 4 Background To Deep Learning ‣ Computer
    Vision and Deep Learning for Fish Classification in Underwater Habitats: A Survey")），通过取
    4 个像素中的最大值并将其下采样为一个像素来缩小输入图像的大小。池化层在传统 CNN 架构中的卷积层之间系统地实施。池化层对每个通道（激活图）单独操作，并在空间上对其进行下采样。通过减少空间信息，池化层使
    CNN 更具计算效率。'
- en: 4.5.3 Feature Maps
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.3 特征图
- en: 'Feature Maps, also called Activation Maps, are the result of applying convolutional
    filters or feature detectors to the preceding layer image. The filters are moved
    on the preceding layer by a specified number of pixels. For instance, in Figure
    [8](#S5.F8 "Figure 8 ‣ 5 Applications of Deep Learning in Fish-Habitat Monitoring
    ‣ Computer Vision and Deep Learning for Fish Classification in Underwater Habitats:
    A Survey"), there are 37 filters of the size $3\times 3$ that move across the
    input image with a stride of 1 and result in 37 feature maps.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '特征图，也称为激活图，是对前一层图像应用卷积滤波器或特征检测器的结果。滤波器以指定数量的像素在前一层上移动。例如，在图 [8](#S5.F8 "Figure
    8 ‣ 5 Applications of Deep Learning in Fish-Habitat Monitoring ‣ Computer Vision
    and Deep Learning for Fish Classification in Underwater Habitats: A Survey") 中，有
    37 个大小为 $3\times 3$ 的滤波器以步长 1 移动于输入图像，并产生 37 个特征图。'
- en: 'The majority of CNN layers are convolutional layers. These layers are used
    to apply the same convolutional filtering operation to different parts of the
    image, creating \sayneurons that can then be used to detect features, like the
    edges and corners. A collection of weights connects each neuron in a convolutional
    layer to the preceding layer’s feature maps, or to the input layer image. The
    feature maps help visualise the features that the CNN is learning to give an understanding
    of the network learning process, as shown in Figure [8](#S5.F8 "Figure 8 ‣ 5 Applications
    of Deep Learning in Fish-Habitat Monitoring ‣ Computer Vision and Deep Learning
    for Fish Classification in Underwater Habitats: A Survey").'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 'CNN 层的绝大多数是卷积层。这些层用于对图像的不同部分应用相同的卷积滤波操作，从而创建出可以用于检测特征的*神经元*，例如边缘和角落。卷积层中的每个神经元通过一组权重与前一层的特征图或输入层图像连接。特征图有助于可视化
    CNN 正在学习的特征，从而理解网络学习过程，如图 [8](#S5.F8 "Figure 8 ‣ 5 Applications of Deep Learning
    in Fish-Habitat Monitoring ‣ Computer Vision and Deep Learning for Fish Classification
    in Underwater Habitats: A Survey") 所示。'
- en: 5 Applications of Deep Learning in Fish-Habitat Monitoring
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 深度学习在鱼类栖息地监测中的应用
- en: In a recent special issue titled "Applications of machine learning and artificial
    intelligence in marine science" published in the International Council for the
    Exploration of the Sea (ICES) journal of marine science [[99](#bib.bib99)], many
    uses of deep learning and CNNs have been shown. These include identifying the
    species of harvested fish [[76](#bib.bib76)], analysis of fisheries surveillance
    videos [[32](#bib.bib32)], and natural mortality estimation [[73](#bib.bib73)].
    Other published works have used CNN for other marine applications such as automatic
    vessel detection [[18](#bib.bib18)], and analysis of deep-sea mineral exploration
    [[54](#bib.bib54)]. However, in this paper we focus on using CNNs for CV tasks.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近出版的国际海洋探索委员会 (ICES) 海洋科学期刊的特刊 "机器学习和人工智能在海洋科学中的应用" [[99](#bib.bib99)] 中，展示了深度学习和
    CNN 的许多应用。这些应用包括识别捕捞鱼类的物种 [[76](#bib.bib76)]、分析渔业监控视频 [[32](#bib.bib32)] 和自然死亡率估计
    [[73](#bib.bib73)]。其他已发表的工作则使用 CNN 进行其他海洋应用，如自动船只检测 [[18](#bib.bib18)] 和深海矿产资源勘探分析
    [[54](#bib.bib54)]。然而，在本文中，我们重点关注 CNN 在计算机视觉任务中的应用。
- en: These tasks are mainly designed to extract knowledge from underwater videos
    and images. Despite the recent use of CNNs for various visual analysis tasks such
    as segmentation [[33](#bib.bib33), [2](#bib.bib2), [47](#bib.bib47), [139](#bib.bib139)],
    localisation [[119](#bib.bib119), [51](#bib.bib51), [57](#bib.bib57)], and counting
    [[124](#bib.bib124), [112](#bib.bib112), [28](#bib.bib28)], the most common and
    the widest studied CV task in underwater fish habitat monitoring has been classification.
    Therefore, in this paper, we focus mainly on classification of underwater fish
    images. We survey some of the latest works on fish classification and provide
    a high-level technical discussion of these works.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这些任务主要旨在从水下视频和图像中提取知识。尽管最近已使用卷积神经网络（CNN）进行各种视觉分析任务，如分割 [[33](#bib.bib33), [2](#bib.bib2),
    [47](#bib.bib47), [139](#bib.bib139)]、定位 [[119](#bib.bib119), [51](#bib.bib51),
    [57](#bib.bib57)] 和计数 [[124](#bib.bib124), [112](#bib.bib112), [28](#bib.bib28)]，但在水下鱼类栖息地监测中，最常见且研究最广泛的计算机视觉任务是分类。因此，本文主要集中在水下鱼类图像的分类上。我们调查了一些最新的鱼类分类研究，并对这些研究进行了高层次的技术讨论。
- en: The task of classification is defined as classifying the input samples into
    different categories, usually based on the presence or absence of a certain object/class,
    in binary classification; or the presence of several different objects belonging
    to different classes, in multi-class classification [[48](#bib.bib48)]. Similarly,
    image classification is concerned with assigning a label to a whole image based
    on the objects in that image. Conceivably, an image can be labelled as fish, when
    there is a fish present in it, or negative when no fish is present. Similarly,
    images of different species should be automatically assigned to their respective
    classes or given a label representing their class.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 分类任务定义为将输入样本分类到不同的类别中，通常基于二分类中某一对象/类别的存在或缺失；或者在多类别分类中，基于属于不同类别的多个不同对象的存在 [[48](#bib.bib48)]。同样，图像分类则涉及根据图像中的对象为整个图像分配标签。可以设想，当图像中存在鱼时，可以将其标记为鱼，若无鱼则标记为负样本。同样，不同物种的图像应自动分配到各自的类别中或赋予代表其类别的标签。
- en: Classification is a difficult process if done manually, because an image may
    need to be categorised into more than one class. In addition, there may be thousands
    of images to be classified, which makes the task very time-consuming and prone
    to human error. Consequently, automation can help perform classification quicker
    and more efficiently.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如果手动进行分类，这是一个困难的过程，因为图像可能需要被分类为多个类别。此外，可能有成千上万的图像需要分类，这使得任务非常耗时且容易出错。因此，自动化可以帮助更快、更高效地完成分类任务。
- en: '![Refer to caption](img/ab4faffc5a586dc1feeab07316ad4b57.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/ab4faffc5a586dc1feeab07316ad4b57.png)'
- en: 'Figure 8: Schematic diagram of feature maps of the CNN used in the classification
    task. The feature map is a two-dimensional representation of an input image. Here
    $(3\times 3)$ is the size of the filter slid over the entire image to generate
    feature maps.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：用于分类任务的卷积神经网络（CNN）特征图示意图。特征图是输入图像的二维表示。这里 $(3\times 3)$ 是滑过整个图像以生成特征图的滤波器的大小。
- en: In the context of fish and marine habitat monitoring, CV offers a low-cost,
    long-term, and non-destructive observation opportunity. One of the initial tasks
    performed using deep learning on CV-collected marine habitat images is fish classification,
    which is a key component of any intelligent fish monitoring systems, because it
    may activate further processing on the fish image. However, underwater monitoring
    based on image and video processing pose numerous challenges related to the hostile
    condition under which the fish images are collected. These include poor underwater
    image quality due to low light and water turbidity, which result in low resolution
    and contrast. Additionally, fish movements in an uncontrolled environment can
    create distortion, deformations, occlusion, and overlapping. Many previous works
    [[11](#bib.bib11), [122](#bib.bib122), [26](#bib.bib26)] have tried to address
    these challenges. Some of these works focused on devising new methods to properly
    extract traditional low-level features such as colours and textures using mean
    shift algorithm [[12](#bib.bib12)], in the presence of the challenges. However,
    these works have not been very successful compared to DL approaches.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在鱼类和海洋栖息地监测的背景下，计算机视觉（CV）提供了一个低成本、长期且非破坏性的观察机会。使用深度学习对CV收集的海洋栖息地图像进行的初步任务之一是鱼类分类，这是一切智能鱼类监测系统的关键组成部分，因为它可能会激活对鱼类图像的进一步处理。然而，基于图像和视频处理的水下监测面临许多挑战，这些挑战与鱼类图像收集时的恶劣条件相关。这些挑战包括由于光线不足和水体浑浊导致的水下图像质量差，从而导致分辨率和对比度低。此外，在不受控制的环境中，鱼类的运动可能会造成失真、变形、遮挡和重叠。许多早期研究[[11](#bib.bib11),
    [122](#bib.bib122), [26](#bib.bib26)]尝试解决这些挑战。其中一些研究专注于在挑战存在的情况下，使用均值漂移算法[[12](#bib.bib12)]来正确提取传统的低级特征，如颜色和纹理。然而，与深度学习方法相比，这些研究并不十分成功。
- en: 'With the inception of CNNs, many researchers utilised them to extract both
    high-level and low-level features of input images. These features, which can be
    automatically detected by the CNN, carry extensive semantic information that can
    be applied to recognise objects in an image. In addition, CNNs have the ability
    to address the challenges outlined above. Therefore, they are currently the main
    underwater image processing tool in literature for fish classification, as shown
    in Tables [2](#S5.T2 "Table 2 ‣ 5 Applications of Deep Learning in Fish-Habitat
    Monitoring ‣ Computer Vision and Deep Learning for Fish Classification in Underwater
    Habitats: A Survey") and [3](#S5.T3 "Table 3 ‣ 5 Applications of Deep Learning
    in Fish-Habitat Monitoring ‣ Computer Vision and Deep Learning for Fish Classification
    in Underwater Habitats: A Survey"). These tables list some of the latest classification
    works, while providing details about the DL models used and the framework within
    which the model was implemented. It also provides information about the data source,
    as well as the pre-processing of the data and its labels, while reporting the
    Classification Accuracy (CA) and a short comparison with other methods if the
    reviewed work has provided it. One of the main metrics when comparing different
    methods for classification is their CA, which is defined as the percentage of
    correct predictions by the network.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '随着卷积神经网络（CNN）的出现，许多研究人员利用它们来提取输入图像的高级和低级特征。这些特征可以被CNN自动检测，携带丰富的语义信息，可以用于识别图像中的物体。此外，CNN具有应对上述挑战的能力。因此，它们目前是文献中用于鱼类分类的主要水下图像处理工具，如表[2](#S5.T2
    "Table 2 ‣ 5 Applications of Deep Learning in Fish-Habitat Monitoring ‣ Computer
    Vision and Deep Learning for Fish Classification in Underwater Habitats: A Survey")和表[3](#S5.T3
    "Table 3 ‣ 5 Applications of Deep Learning in Fish-Habitat Monitoring ‣ Computer
    Vision and Deep Learning for Fish Classification in Underwater Habitats: A Survey")所示。这些表格列出了一些最新的分类工作，同时提供了所使用的深度学习模型和模型实施框架的详细信息。它还提供了数据源的信息，以及数据及其标签的预处理，同时报告分类准确率（CA）和与其他方法的简要比较（如果所评审的工作提供了这些信息）。比较不同分类方法时的主要指标之一是其CA，它定义为网络正确预测的百分比。'
- en: '|  | $CA=(TP+TN)/(TP+TN+FP+FN),$ |  | (1) |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '|  | $CA=(TP+TN)/(TP+TN+FP+FN),$ |  | (1) |'
- en: where TP (True Positive) and TN (True Negative) represent the number of correctly
    classified instances, while FP (False Positive) and FN (False Negative) represent
    the number of incorrectly classified instances. For multi-class classification,
    CA is averaged among all the classes.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 其中TP（真正例）和TN（真负例）表示正确分类实例的数量，而FP（假正例）和FN（假负例）表示错误分类实例的数量。对于多类分类，CA在所有类别中进行平均。
- en: DL algorithms are gaining momentum in their growing accuracy in different applications.
    However, they have inherent limitations, which should be considered before choosing
    a DL algorithm for a given application. This is because accuracy, for example
    in a fish classification task, may significantly differ from true accuracy due
    to the distribution of samples in the training and testing populations. To address
    this limitation of classification accuracy, the Receiver Operating Characteristics
    (ROC) [[63](#bib.bib63)] and Area Under The Curve (AUC) [[52](#bib.bib52)] are
    widely used as a standard measure for determining the performance of a model in
    a binary classification setting. Their definition is very similar to accuracy
    but they help one understand the probability that the classifier produces correct
    outputs with desired levels of true positives and false negatives, using a certain
    classification threshold.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: DL 算法在不同应用中的准确性不断提高。然而，它们也存在固有的局限性，在为特定应用选择 DL 算法之前应加以考虑。这是因为在鱼类分类任务中，例如，由于训练和测试样本的分布，准确性可能与真实准确性有显著差异。为了解决分类准确性的局限性，接收操作特性（ROC）[[63](#bib.bib63)]和曲线下面积（AUC）[[52](#bib.bib52)]被广泛作为标准度量，用于确定模型在二分类环境中的性能。它们的定义与准确性非常相似，但它们帮助我们理解分类器在给定分类阈值下产生正确输出的概率，包括期望的真正例和假负例。
- en: 'The works in Tables [2](#S5.T2 "Table 2 ‣ 5 Applications of Deep Learning in
    Fish-Habitat Monitoring ‣ Computer Vision and Deep Learning for Fish Classification
    in Underwater Habitats: A Survey") and [3](#S5.T3 "Table 3 ‣ 5 Applications of
    Deep Learning in Fish-Habitat Monitoring ‣ Computer Vision and Deep Learning for
    Fish Classification in Underwater Habitats: A Survey") can be divided into two
    general categories. The first category deals with designing effective CNNs that
    address the challenge of unconstrained, complex, and noisy underwater scenes,
    while the second category also tries to address the usual problem of limited fish
    training datasets.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [2](#S5.T2 "Table 2 ‣ 5 Applications of Deep Learning in Fish-Habitat Monitoring
    ‣ Computer Vision and Deep Learning for Fish Classification in Underwater Habitats:
    A Survey") 和 [3](#S5.T3 "Table 3 ‣ 5 Applications of Deep Learning in Fish-Habitat
    Monitoring ‣ Computer Vision and Deep Learning for Fish Classification in Underwater
    Habitats: A Survey") 中的工作可以分为两个主要类别。第一个类别涉及设计有效的 CNN，解决无约束、复杂且噪声较多的水下场景的挑战，而第二个类别则尝试解决通常存在的鱼类训练数据集有限的问题。'
- en: As mentioned, when processing unconstrained underwater scenes specific attention
    should be paid to implementing a classification approach that is capable of handling
    variations in light intensity, fish orientation, and background environments,
    and similarity in shape and patterns among fish of various species. In order to
    overcome these challenge and to improve classification accuracy, various works
    have devised different methodologies. In [[128](#bib.bib128)], the authors used
    different activation functions to examine the most suitable for fish classification,
    while in [[110](#bib.bib110)] different number of convolutional layers and different
    filter sizes were examined. In [[109](#bib.bib109)], the authors used a CNN model
    in a hierarchical feature combination setup to learn species-dependent visual
    features for better accuracy. In another work [[100](#bib.bib100)], principal-component
    analysis was used in two convolutional layers, followed by binary hashing in the
    non-linear layer and block-wise histograms in the feature pooling layer. Furthermore,
    a single-image super-resolution method was used in [[120](#bib.bib120)] to resolve
    the problem of limited discriminative information of low-resolution images. Moreover,
    [[17](#bib.bib17)] used two independent classification branches, with the first
    branch aiming to handle the variation of pose and scale of fish and extract discriminative
    features, and the second branch making use of context information to accurately
    infer the type of fish. The reviewed works show that depending on the type of
    environment and fish species similarities in the dataset under consideration,
    various techniques should be considered and investigated to find the best classification
    accuracy.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在处理无约束的水下场景时，应该特别关注实施一种能够处理光强度变化、鱼的方向和背景环境以及各种鱼类之间形状和模式相似性的分类方法。为了克服这些挑战并提高分类准确性，已有多种方法被提出。在[[128](#bib.bib128)]中，作者使用了不同的激活函数来检验哪种最适合鱼类分类，而在[[110](#bib.bib110)]中，则研究了不同数量的卷积层和不同的滤波器大小。在[[109](#bib.bib109)]中，作者使用了一个层次特征组合的CNN模型，以学习特定物种的视觉特征，从而提高准确性。在另一项工作[[100](#bib.bib100)]中，使用了主成分分析于两个卷积层中，之后在非线性层进行了二进制哈希处理，在特征池化层中使用了块状直方图。此外，[[120](#bib.bib120)]中使用了单图像超分辨率方法来解决低分辨率图像的有限判别信息问题。此外，[[17](#bib.bib17)]使用了两个独立的分类分支，第一个分支旨在处理鱼的姿态和尺度变化并提取判别特征，而第二个分支则利用上下文信息准确推断鱼的类型。这些研究表明，根据环境类型和数据集中鱼类物种的相似性，应考虑并研究各种技术，以找到最佳的分类准确性。
- en: As already mentioned, data gathering in the wild is sometimes very difficult
    and challenging, thus to maximize the success rate of training, it is essential
    to consider gathering field data from the beginning of the project. This ensures
    that the collected training dataset has good sample diversity including samples
    collected at different environmental conditions such as water turbidity and salinity,
    and it captures fish species similarities. Diversity and comprehensiveness in
    the dataset is one of the key factors in reaching high classification accuracies
    when the model is deployed in the real world. Data augmentation is another important
    method that can help improve the classification accuracy, through increasing the
    dataset size and diversity. An alternative to data augmentation is transfer learning,
    but the model should be always fine-tuned to the new dataset to maximize accuracy.
    Image pre-processing is another important technique that can help improve classification
    accuracy, and should be considered when working with new fish datasets.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在野外数据收集有时非常困难且具有挑战性，因此，为了最大化训练的成功率，必须从项目开始时就考虑收集现场数据。这确保了收集的训练数据集具有良好的样本多样性，包括在不同环境条件下（如水体浑浊度和盐度）收集的样本，并且能够捕捉鱼类物种的相似性。数据集的多样性和全面性是模型在实际应用中达到高分类准确率的关键因素之一。数据增强是另一种重要的方法，通过增加数据集的大小和多样性来帮助提高分类准确性。数据增强的替代方法是迁移学习，但模型应始终进行微调以适应新数据集，以最大化准确性。图像预处理是另一种可以帮助提高分类准确性的技术，处理新鱼类数据集时应予以考虑。
- en: Dataset limitation, i.e. having limited number of fish images from different
    species, and/or having few numbers of different fish etc, is another challenge
    in underwater fish habitat monitoring in general and in fish classification, in
    specific. This challenge has been addressed in [[107](#bib.bib107), [53](#bib.bib53),
    [103](#bib.bib103), [123](#bib.bib123)] using transfer learning.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集限制，即鱼类图像数量有限，以及不同鱼类数量少等，是水下鱼类栖息地监测中普遍存在的挑战，特别是在鱼类分类中。[[107](#bib.bib107)、[53](#bib.bib53)、[103](#bib.bib103)、[123](#bib.bib123)]利用迁移学习解决了这一挑战。
- en: Transfer learning is a ML method that works by transferring information obtained
    while learning one problem or domain to a different but related problem or domain.
    Comparing a randomly initialised classifier with another one pre-trained on ImageNet
    [[106](#bib.bib106)], Saleh et al. [[107](#bib.bib107)] achieved a fish classification
    accuracy of $99\%$, outperforming the randomly-initialised classifier, significantly.
    This finding shows that transfer learning can bring learned information from the
    ImageNet learning domain to fish classification domain and can be a useful and
    crucial method for evaluating fish environments. Transfer learning was also used
    in [[59](#bib.bib59)] where general-domain above-water fish image learning was
    transfered and used for underwater fish classification. In the same way, to train
    large-scale models that are able to generate reasonable results, [[141](#bib.bib141)]
    collected 1000 fish categories with 54,459 unconstrained images from various professional
    fish websites and Google engine.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是一种机器学习方法，通过将学习一个问题或领域时获得的信息转移到不同但相关的问题或领域来工作。将一个随机初始化的分类器与一个在ImageNet[[106](#bib.bib106)]上预训练的分类器进行比较，Saleh等人[[107](#bib.bib107)]实现了$99\%$的鱼类分类准确率，显著优于随机初始化的分类器。这一发现表明，迁移学习可以将从ImageNet学习领域获得的信息带入鱼类分类领域，并且可以成为评估鱼类环境的有用且关键的方法。迁移学习还在[[59](#bib.bib59)]中使用，其中将一般领域的水上鱼类图像学习转移并用于水下鱼类分类。以相同的方式，为了训练能够生成合理结果的大规模模型，[[141](#bib.bib141)]收集了来自各种专业鱼类网站和Google引擎的1000个鱼类类别，共54,459张非约束图像。
- en: In addition to transfer learning, some works have developed specific machine
    learning techniques suiting their applications. For instance, in a previous study
    [[116](#bib.bib116)], a pre-trained CNN was used as a generalised feature extractor
    to avoid the need for a large amount of training data. The authors showed that
    by feeding the CNN-extracted features to a Support Vector Machine (SVM) classifier
    [[96](#bib.bib96)], a CA of $94.3\%$ for fish species classification can be achieved,
    which significantly outperforms a stand-alone CNN achieving an accuracy of 53.5%.
    Also, [[24](#bib.bib24)] used the same techniques in [[116](#bib.bib116)] to achieve
    a CA of $98.79\%$. In addition, [[45](#bib.bib45)] developed a new technique for
    fish classification by modifying AlexNet [[62](#bib.bib62)] model with fewer number
    of layers. Moreover, [[58](#bib.bib58)] presented a labelling efficient method
    of training a CNN-based fish-detector on a small dataset by adding 27,000 above-water
    and underwater fish images.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 除了迁移学习外，一些研究还开发了适应其应用的特定机器学习技术。例如，在之前的一项研究[[116](#bib.bib116)]中，使用了预训练的CNN作为通用特征提取器，以避免大量训练数据的需求。作者展示了通过将CNN提取的特征输入到支持向量机（SVM）分类器[[96](#bib.bib96)]中，可以实现鱼类分类的$94.3\%$的分类准确率，这显著优于单独使用CNN所得到的53.5%的准确率。此外，[[24](#bib.bib24)]使用了[[116](#bib.bib116)]中的相同技术，实现了$98.79\%$的分类准确率。此外，[[45](#bib.bib45)]通过修改AlexNet[[62](#bib.bib62)]模型的层数，开发了一种新的鱼类分类技术。此外，[[58](#bib.bib58)]通过增加27,000张水上和水下鱼类图像，提出了一种在小数据集上训练CNN鱼类检测器的高效标注方法。
- en: CNNs are sometimes capable of surpassing human performance in identifying fish
    in underwater images. By training a CNN on $900,000$ images, Villon et al. [[129](#bib.bib129)]
    could achieve a CA of $94.9\%$ while human CA was only $89.3\%$. This result was
    achieved mainly because the CNN was able to successfully distinguish fish that
    were partially occluded by corals or other fish, while human could not. Furthermore,
    the best CNN model developed in [[129](#bib.bib129)] takes $0.06$ seconds on average
    to identify each fish using typical hardware (Titan X GPU). This demonstrates
    that DL techniques can conduct accurate fish classification on underwater images
    cost-effectively and efficiently. This facilitates monitoring underwater fish
    and can advance marine studies concerned with fish ecology.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 有时能够在识别水下图像中的鱼类时超越人类表现。通过对 $900,000$ 张图像进行训练，Villon 等人 [[129](#bib.bib129)]
    达到了 $94.9\%$ 的分类准确率，而人类的准确率仅为 $89.3\%$。这个结果主要是因为 CNN 能够成功区分被珊瑚或其他鱼类部分遮挡的鱼，而人类则无法做到。此外，[[129](#bib.bib129)]
    中开发的最佳 CNN 模型在使用典型硬件（Titan X GPU）时，平均每条鱼的识别时间为 $0.06$ 秒。这表明深度学习技术可以以高效且经济的方式进行准确的水下鱼类分类。这有助于监测水下鱼类，并推进与鱼类生态相关的海洋研究。
- en: If DL methods are going to be deployed widely for different marine applications
    such as fish classification, there is a need to implement them efficiently, so
    that they can run on low-power embedded systems, which can run in real-time on
    mobile devices such as underwater drones. To that end, Meng et al. [[80](#bib.bib80)]
    have developed an underwater drone with a panoramic camera for recognising fish
    species in a natural lake to help protect the environment. They have trained an
    efficient CNN for fish recognition and achieved $87\%$ accuracy while requiring
    only $6$ seconds to identify 115 images. This promising result shows that, DL
    can be used to classify underwater fish while also satisfying the real-time conditions
    of mobile monitoring devices. In addition, other efficient hardware design approaches
    that have proven useful in reducing power consumption and increasing speed in
    classification task in other domains such as agriculture  [[66](#bib.bib66)] can
    be adopted on edge underwater processors.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果深度学习方法要在鱼类分类等不同的海洋应用中广泛部署，则需要高效地实现它们，以便它们能够在低功耗的嵌入式系统上运行，这些系统可以在水下无人机等移动设备上实时运行。为此，Meng
    等人 [[80](#bib.bib80)] 开发了一种带有全景摄像头的水下无人机，用于识别自然湖中的鱼类，以帮助保护环境。他们训练了一种高效的 CNN 进行鱼类识别，并在识别
    115 张图像时仅需 $6$ 秒，达到了 $87\%$ 的准确率。这一有前景的结果表明，深度学习可以用于分类水下鱼类，同时满足移动监测设备的实时条件。此外，其他在农业等领域证明有效的减少功耗和提高分类任务速度的高效硬件设计方法
    [[66](#bib.bib66)] 也可以在边缘水下处理器上采用。
- en: In DL applications, video storage is currently a bottleneck that may be bypassed
    with real-time algorithms, because they only need to store some and not all the
    video frames in memory and process them in-situ, as they become available. This
    eliminates the time it takes for all the frames to be stored and retrieved from
    memory. This is helpful in situations where large amounts of data have to be processed
    quickly, for example, in an underwater fish observation camera, where frames are
    collected continuously and should either be stored locally or transfered to surface,
    which are both costly and mostly impossible. Using real-time processing algorithms,
    the frames are processed and only the information obtained, i.e. the number of
    fish in a frame are sent or stored, which is much lighter than the entire frame.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习应用中，视频存储目前是一个瓶颈，可以通过实时算法来绕过，因为它们只需要在内存中存储部分视频帧，并在帧可用时就地处理。这消除了将所有帧存储和从内存中检索所需的时间。这在需要快速处理大量数据的情况下很有帮助，例如在水下鱼类观察摄像头中，帧不断收集，必须存储在本地或转移到水面，这两种方式都很昂贵且大多不可能。使用实时处理算法，可以处理帧并仅发送或存储获得的信息，即帧中的鱼类数量，这比整个帧要轻得多。
- en: 'Table 2: Classification'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：分类
- en: '| Article | DL Model | Framework | Data | Annotation/Pre-processing/Augmentation
    | Classes and Labels | Perf. Metric | Metric Value | Comparisons with other methods
    |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | 深度学习模型 | 框架 | 数据 | 注释/预处理/增强 | 类别和标签 | 性能指标 | 指标值 | 与其他方法的比较 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Recognition of Fish Categories Using Deep Learning Technique [[128](#bib.bib128)]
    | CNN | Keras, Tensorflow | Authors-created dataset containing  560 fish images,
    400 training and 160 test images. | Each image is assigned the fish species name
    as a label | 10 classes of 10 different fish species | CA | 95% | NA |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 使用深度学习技术的鱼类类别识别 [[128](#bib.bib128)] | CNN | Keras, Tensorflow | 作者创建的数据集包含
    560 张鱼类图像，其中 400 张用于训练，160 张用于测试。 | 每张图像被标记为鱼类种类名称 | 10 种不同鱼类的 10 个类别 | CA | 95%
    | NA |'
- en: '| Comparison of Different DL Structures for Fish Classification [[110](#bib.bib110)]
    | CNN | Torch | The public QUT fish dataset contains 3960 images of 468 fish species
    in different environments. | Each image is assigned the fish species name as a
    label | 468 classes of 468 different fish species | CA | 46.02% | NA |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 不同 DL 结构在鱼类分类中的比较 [[110](#bib.bib110)] | CNN | Torch | 公开的 QUT 鱼类数据集包含 3960
    张不同环境中的 468 种鱼类的图像。 | 每张图像被标记为鱼类种类名称 | 468 种不同鱼类的 468 个类别 | CA | 46.02% | NA |'
- en: '| Fish Species Classification in Unconstrained Underwater Environments Based
    on DL [[109](#bib.bib109)] | CNN | NA | The images are from the public Fish4Knowledge
    dataset (LifeCLEF 2014, LifeCLEF 2015) | Each image is assigned the fish species
    name as a label | 25 classes of 25 different fish species | CA | 96.75% | Comparison
    with the conventional SVM machine learning tool that achieved 83.94% |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 基于 DL 的非约束水下环境中的鱼类分类 [[109](#bib.bib109)] | CNN | NA | 图像来自公开的 Fish4Knowledge
    数据集（LifeCLEF 2014, LifeCLEF 2015） | 每张图像被标记为鱼类种类名称 | 25 种不同鱼类的 25 个类别 | CA | 96.75%
    | 与传统的 SVM 机器学习工具比较，该工具达到了 83.94% |'
- en: '| Deep-Fish: Accurate Underwater Live Fish Recognition with a DL Architecture
    [[100](#bib.bib100)] | CNN | Matlab | The images are from the public Fish4Knowledge
    dataset | Each image is assigned the fish species name as a label | 23 classes
    of 23 Different fish species | CA | 98.64% | Comparison with conventional machine
    learning tools as baseline methods achieving 93.58% |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| Deep-Fish: 基于 DL 架构的准确水下活鱼识别 [[100](#bib.bib100)] | CNN | Matlab | 图像来自公开的
    Fish4Knowledge 数据集 | 每张图像被标记为鱼类种类名称 | 23 种不同鱼类的 23 个类别 | CA | 98.64% | 与常规机器学习工具比较，基线方法达到了
    93.58% |'
- en: '| Fish Recognition from Low-resolution Underwater Images [[120](#bib.bib120)]
    | CNN | NA | 93 videos from LifeCLEF 2015 fish dataset | Each image was annotated
    by drawing a bounding box and labelling by species name | 15 classes of 15 different
    fish species | CA | 76.57% | Authors used the traditional gabor features and dense
    sift features that generated CA of 38.28% and 28.63%, respectively. |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 从低分辨率水下图像中识别鱼类 [[120](#bib.bib120)] | CNN | NA | 93 个来自 LifeCLEF 2015 鱼类数据集的视频
    | 每张图像通过绘制边界框并按种类名称标注 | 15 种不同鱼类的 15 个类别 | CA | 76.57% | 作者使用了传统的 Gabor 特征和稠密
    SIFT 特征，分别生成了 38.28% 和 28.63% 的 CA。 |'
- en: '| Automatic Fish Classification System Using DL [[17](#bib.bib17)] | CNN |
    NA | Eight target categories: Albacore tuna, Bigeye tuna, Yellowfin tuna, Mahi
    Mahi, Opah, Sharks, Other. | Each image is assigned the fish species name as a
    label | 8 classes of 8 different fish species | CE | 0.578, 1.387 | Ranked 17th
    on Kaggle leaderboard on test set at stage 1 and 16th at stage 2. |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 基于 DL 的自动鱼类分类系统 [[17](#bib.bib17)] | CNN | NA | 八个目标类别：黄鳍金枪鱼、大眼金枪鱼、黄鳍金枪鱼、马鲛鱼、月鱼、鲨鱼、其他。
    | 每张图像被标记为鱼类种类名称 | 8 种不同鱼类的 8 个类别 | CE | 0.578, 1.387 | 在 Kaggle 测试集的第 1 阶段排名第
    17 位，第 2 阶段排名第 16 位。 |'
- en: '| A Realistic Fish-habitat Dataset to Evaluate DL Algorithms For Underwater
    Visual Analysis [[107](#bib.bib107)] | ResNet-50 CNN | Pytorch | Authors-created
    database containing 39,766 images from 20 habitats in remote coastal marine environments
    of tropical Australia | point-level and semantic segmentation labels | 20 classes
    of 20 different fish species | CA | 0.99 | NA |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 评估 DL 算法用于水下视觉分析的现实鱼类栖息地数据集 [[107](#bib.bib107)] | ResNet-50 CNN | Pytorch
    | 作者创建的数据库包含来自热带澳大利亚偏远沿海海洋环境中的 20 个栖息地的 39,766 张图像 | 点级和语义分割标签 | 20 种不同鱼类的 20
    个类别 | CA | 0.99 | NA |'
- en: '| Deep Learning for Underwater Image Recognition in Small Sample Size Situations
    [[53](#bib.bib53)] | CNN | Caffe | The images are from the public Fish4Knowledge
    dataset | Each image is assigned the fish species name as a label | 10 classes
    of 10 different fish species | CA | 85.08% | NA |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 深度学习在小样本量情况下的水下图像识别 [[53](#bib.bib53)] | CNN | Caffe | 图像来自公开的 Fish4Knowledge
    数据集 | 每张图像被标记为鱼类种类名称 | 10 种不同鱼类的 10 个类别 | CA | 85.08% | NA |'
- en: '| Underwater Fish Species Classification using CNN and DL [[103](#bib.bib103)]
    | CNN | NA | 27000 images from the public Fish4Knowledge dataset | Each image
    is assigned the fish species name as a label | 23 fish classes | CA | 96.29% |
    NA |  Table 3: Classification'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '| 使用CNN和DL进行水下鱼类物种分类 [[103](#bib.bib103)] | CNN | NA | 27000张来自公开Fish4Knowledge数据集的图像
    | 每张图像都被分配了鱼类物种名称作为标签 | 23个鱼类类别 | CA | 96.29% | NA | 表3：分类'
- en: '| Article | DL Model | Framework | Data | Annotation/Pre-processing/Augmentation
    | Classes and Labels | Perf. Metric | Matric Value | Comparisons with other methods
    |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | DL模型 | 框架 | 数据 | 注释/预处理/数据增强 | 类别和标签 | 性能指标 | 指标值 | 与其他方法的比较 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Underwater Live Fish Recognition by Deep Learning [[123](#bib.bib123)] |
    AlexNet CNN | Matlab | 27000 images from the public Fish4Knowledge dataset | Each
    image is assigned the fish species name as a label | 23 classes of 23 different
    fish species | CA | 99.45% | NA |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 通过深度学习进行水下活鱼识别 [[123](#bib.bib123)] | AlexNet CNN | Matlab | 27000张来自公开Fish4Knowledge数据集的图像
    | 每张图像都被分配了鱼类物种名称作为标签 | 23类23种不同的鱼类 | CA | 99.45% | NA |'
- en: '| WildFish++: A Comprehensive Fish Benchmark for Multimedia Research [[141](#bib.bib141)]
    | CNN | NA | Authors-created dataset of 54,459 labelled images from various professional
    websites and Google engine | Each image is assigned the fish species name as a
    label | 100 classes of 1000 different fish species | CA | 74.7% | Comparison with
    other state-of-the-art approaches |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| WildFish++：多媒体研究的综合鱼类基准 [[141](#bib.bib141)] | CNN | NA | 作者创建的数据集，包含来自各种专业网站和Google引擎的54,459张标注图像
    | 每张图像都被分配了鱼类物种名称作为标签 | 100类1000种不同的鱼类 | CA | 74.7% | 与其他先进方法进行比较 |'
- en: '| Automatic Fish Species Classification in Underwater Videos: Exploiting Pre-trained
    DNN Models to Compensate for Limited Labelled Data [[116](#bib.bib116)] | CNN
    | MATLAB | The dataset contains 50 to 120 10-second video clips of 16 species
    from Western Australia during 2011 to 2013. | Each image is assigned the fish
    species name as a label | 16 classes of 16 Different fish species | CA | 89.0%
    | Comparison of their proposed method of CNN+SVM achieving a CA of 89.0% with
    two previous works; SRC (Hsiao et al. [[41](#bib.bib41)]) 49.1% and CNN (Salman
    et al. [[109](#bib.bib109)]) 53.5% |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 水下视频中的自动鱼类物种分类：利用预训练的DNN模型弥补标签数据不足 [[116](#bib.bib116)] | CNN | MATLAB |
    数据集包含2011到2013年西澳大利亚16个物种的50到120个10秒视频片段。 | 每张图像都被分配了鱼类物种名称作为标签 | 16类16种不同的鱼类
    | CA | 89.0% | 将他们提出的CNN+SVM方法（CA为89.0%）与两个先前的工作进行比较；SRC（Hsiao等 [[41](#bib.bib41)])
    49.1% 和 CNN（Salman等 [[109](#bib.bib109)]) 53.5% |'
- en: '| Underwater Fish Species Recognition using Deep Learning Techniques [[24](#bib.bib24)]
    | CNN | Keras, Tensorflow | 35000 images from the public Fish4Knowledge dataset
    | Each image is assigned the fish species name as a label | 23 classes of 23 different
    fish species | CA | 98.79% | NA |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 使用深度学习技术进行水下鱼类物种识别 [[24](#bib.bib24)] | CNN | Keras, Tensorflow | 35000张来自公开Fish4Knowledge数据集的图像
    | 每张图像都被分配了鱼类物种名称作为标签 | 23类23种不同的鱼类 | CA | 98.79% | NA |'
- en: '| Automatic Fish Species Classification Using Deep Convolutional Neural Networks
    [[45](#bib.bib45)] | modified AlexNet CNN | Tensorflow | The images are from two
    public datasets: QUT fish dataset and LifeClef-15 | Each image is assigned the
    fish species name as a label | 6 classes of 6 different fish species | CA | 90.48%
    | Comparing their proposed modified AlexNet achieving a CA of 90.48% with original
    AlexNet CA of 86.65% |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 使用深度卷积神经网络进行自动鱼类物种分类 [[45](#bib.bib45)] | 修改版AlexNet CNN | Tensorflow | 图像来自两个公开数据集：QUT鱼类数据集和LifeClef-15
    | 每张图像都被分配了鱼类物种名称作为标签 | 6类6种不同的鱼类 | CA | 90.48% | 将他们提出的修改版AlexNet（CA为90.48%）与原始AlexNet（CA为86.65%）进行比较
    |'
- en: '| Underwater Fish Detection with Weak Multi-Domain Supervision [[58](#bib.bib58)]
    | CNN | Keras, Tensorflow | Authors-created dataset of 40000 labelled fish images
    from video sequences | Each image is labelled as Fish or no fish | 2 classes |
    CA | 99.94% | NA |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 使用弱多域监督进行水下鱼类检测 [[58](#bib.bib58)] | CNN | Keras, Tensorflow | 作者创建的数据集，包含40000张从视频序列中标注的鱼类图像
    | 每张图像标注为鱼类或非鱼类 | 2类 | CA | 99.94% | NA |'
- en: '| A Deep Learning Method for Accurate and Fast Identification of Coral Reef
    Fishes in Underwater Images [[129](#bib.bib129)] | GoogLeNet CNN | Caffe | Authors-created
    dataset containing 450,000 images from over 50 reef sites around the Mayotte island
    | Annotation included drawing a rectangle around a single fish and associating
    the species name as label. | 20 classes of 20 different fish species | CA | 94.9%
    | Comparing accuracy to human experts. The rate of correct identification was
    94.9%, greater than the rate of correct identification by humans (89.3%). |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 用于水下图像中准确快速识别珊瑚礁鱼类的深度学习方法 [[129](#bib.bib129)] | GoogLeNet CNN | Caffe |
    作者创建的数据集包含来自马约特岛周围50多个珊瑚礁点的450,000张图像 | 注释包括在单个鱼周围画一个矩形，并将物种名称作为标签。 | 20种鱼类的20个类别
    | CA | 94.9% | 与人类专家的准确率比较。正确识别的比率为94.9%，高于人类的正确识别率（89.3%）。 |'
- en: '| Underwater-Drone With Panoramic Camera for Automatic Fish Recognition Based
    on Deep Learning [[80](#bib.bib80)] | CNN | NA | Authors-created dataset of 100
    labelled images from Google search engine | Each image is assigned the fish species
    name as a label | 4 classes of 4 different fish species. | CA | 87% | NA |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 基于深度学习的水下无人机全景相机自动鱼类识别 [[80](#bib.bib80)] | CNN | NA | 作者创建的包含100张通过Google搜索引擎标记的图像的数据集
    | 每张图像都分配了鱼类物种名称作为标签 | 4种鱼类的4个类别。 | CA | 87% | NA |'
- en: 6 Challenges and Approaches to Address them
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 个挑战及其应对方法
- en: Despite the rapid improvement of DL for marine habitat monitoring through visual
    analysis, four main challenges still exist. The first challenge is to develop
    models that can generalise their learning and perform well on new unseen data
    samples. The second challenge is limited datasets available for general DL tasks,
    and in particular for marine visual processing tasks. The third challenge is lower
    image quality in underwater scenarios. The fourth challenge is the gap between
    DL and ecology.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度学习在通过视觉分析进行海洋栖息地监测方面取得了快速进展，但仍存在四个主要挑战。第一个挑战是开发能够泛化学习并在新未见过的数据样本上表现良好的模型。第二个挑战是有限的数据集，特别是对于海洋视觉处理任务。第三个挑战是水下场景中的图像质量较低。第四个挑战是深度学习与生态学之间的差距。
- en: To address these challenges, various computer algorithms and techniques have
    been developed. In the following subsections, we explain the challenges in detail
    and briefly review various approaches to address them. However, we do not intend
    to include details of these approaches as they are out of the scope of this paper.
    The interested reader is invited to refer to relevant DL materials and the cited
    papers.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为应对这些挑战，已经开发了各种计算机算法和技术。在以下子节中，我们将详细解释这些挑战，并简要回顾应对这些挑战的各种方法。然而，我们不打算详细介绍这些方法，因为它们超出了本文的范围。感兴趣的读者可以参考相关的深度学习资料和引用的论文。
- en: 6.1 Model Generalisation
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 模型泛化
- en: One of the most difficult challenges in DL is to improve deep convolutional
    networks generalisation abilities. This refers to the gap between a model’s performance
    on previously observed data (i.e. training data) and data it has never seen before
    (i.e. testing data). A wide gap between the training and validation accuracy is
    usually a sign of overfitting. Overfitting occurs when the model accurately predicts
    the training data, mostly because it has memorised the training data instead of
    learning their features.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习（DL）中，最困难的挑战之一是提高深度卷积网络的泛化能力。这指的是模型在之前观察过的数据（即训练数据）与从未见过的数据（即测试数据）之间的性能差距。训练准确率和验证准确率之间的差距通常是过拟合的迹象。过拟合发生在模型准确地预测训练数据时，主要是因为它记住了训练数据，而不是学习其特征。
- en: One way to monitor overfitting is by plotting the training and validation accuracy
    at each epoch during training. That way, we will see that if the gap between the
    validation and training acuuracy/error is widening (over- or under-fitting) or
    narrowing (learning). A well-known and effective method for improving the generalisability
    of a DL model is to use regularisation [[64](#bib.bib64)]. Some of the regularisation
    methods applied to fish and marine habitat monitoring domains include transfer
    learning [[145](#bib.bib145)], batch normalisation [[47](#bib.bib47)], dropout
    [[45](#bib.bib45)], and using a regularisation term [[124](#bib.bib124)].
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 监控过拟合的一种方法是绘制每个训练周期的训练和验证准确性。通过这种方式，我们可以看到如果验证和训练准确性/误差之间的差距在扩大（过拟合或欠拟合）或缩小（学习）。一种提高深度学习模型泛化能力的知名有效方法是使用正则化[[64](#bib.bib64)]。一些应用于鱼类和海洋栖息地监测领域的正则化方法包括迁移学习[[145](#bib.bib145)]、批量归一化[[47](#bib.bib47)]、dropout[[45](#bib.bib45)]和使用正则化项[[124](#bib.bib124)]。
- en: 6.2 Dataset Limitation
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 数据集限制
- en: Another challenge of training DL models is the limited dataset. DL models require
    enormous datasets for training. Unfortunately, most datasets are large, expensive,
    and time-consuming to build. For this reason, model training is usually conducted
    by collecting samples from a small number of datasets, rather than from a large
    number of datasets.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 训练深度学习（DL）模型的另一个挑战是数据集的有限性。深度学习模型需要大量的数据集进行训练。不幸的是，大多数数据集都很大、成本高昂且耗时。因此，模型训练通常是通过从少量数据集中收集样本进行的，而不是从大量数据集中收集样本。
- en: 'A dataset can be categorised into two parts: labelled data and unlabeled data.
    The labelled data is the set of data that needs the labelling of classes, e.g.
    fish species in an image, or absence or presence of fish in an image. The unlabeled
    data is the set of data that has not been processed. The labelled data forms the
    training set whose size is closely related to the accuracy of the trained model.
    The larger the training set, the more accurate the trained model. Large training
    set, however, are expensive to build. They require a large number of resources,
    such as people-hours, space, and money, making it very difficult for many researchers
    to achieve them, and in turn hinders their research.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以分为两个部分：标记数据和未标记数据。标记数据是需要标注类别的数据集，例如图像中的鱼种，或者图像中是否存在鱼。未标记数据是尚未处理的数据集。标记数据形成了训练集，其大小与训练模型的准确性密切相关。训练集越大，训练模型的准确性越高。然而，大型训练集的构建成本很高。它们需要大量的资源，如人力、空间和资金，这使得许多研究人员难以实现，从而阻碍了他们的研究。
- en: Since it is difficult to obtain a large labelled dataset, various techniques
    have been proposed to address this challenge. Some of the techniques applied to
    the fish and marine habitat monitoring domains include transfer learning [[101](#bib.bib101)],
    data augmentation [[107](#bib.bib107), [110](#bib.bib110)], using hybrid features
    [[78](#bib.bib78), [15](#bib.bib15), [9](#bib.bib9)], weakly supervised learning
    [[67](#bib.bib67)], and active learning [[86](#bib.bib86)].
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 由于难以获得大规模标记数据集，已经提出了各种技术来应对这一挑战。一些应用于鱼类和海洋栖息地监测领域的技术包括迁移学习[[101](#bib.bib101)]、数据增强[[107](#bib.bib107),
    [110](#bib.bib110)]、使用混合特征[[78](#bib.bib78), [15](#bib.bib15), [9](#bib.bib9)]、弱监督学习[[67](#bib.bib67)]和主动学习[[86](#bib.bib86)]。
- en: 6.3 Image Quality
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 图像质量
- en: Underwater image recognition’s average accuracy lags significantly behind that
    of terrestrial image recognition. This is mostly owing to the low quality of underwater
    photos, which frequently exhibit blurring, and colour deterioration, caused by
    the physical characteristics of the water and the hostile underwater environment.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 水下图像识别的平均准确性显著低于陆地图像识别。这主要归因于水下照片的低质量，这些照片常常由于水的物理特性和恶劣的水下环境而出现模糊和颜色退化。
- en: Most CV applications perform some initial preprocessing of images before feeding
    them to their image processor. In underwater scenarios, these preprocessing techniques
    are typically used to enhance the image quality. Preprocessing can also help with
    the red channel information loss problem, which is required for obtaining relevant
    colour data. The red channel information loss problem is about losing the actual
    intensity of the red colour in the scene, for instance, compared to the blue and
    green colour channels. This is more pronounced in the underwater environment and
    as the depth increases, which attenuates red channel values more strongly than
    the other colour channels. We should, therefore, consider that the red channel
    value depends not only on the distance from the subject but also on the intensity
    of the light reflected by the subject, as the reflection of intense light is typically
    much stronger than that of a light of a very low intensity. Another issue that
    arises in the detection of a specific target in an underwater image is the fact
    that multiple pixels can potentially be activated in the image in theform of an
    object. For example, sunlight shining through a periscope lens can cause spurious
    activation of a given pixel. There is a need for a reliable method and system
    for determining whether a given pixel in a remote underwater image is activated
    by some cause other than the presence of a target in the area of the image.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数计算机视觉应用在将图像输入到图像处理器之前会进行一些初步的图像预处理。在水下场景中，这些预处理技术通常用于增强图像质量。预处理还可以帮助解决红色通道信息丢失的问题，这对于获取相关的颜色数据是必要的。红色通道信息丢失的问题是指在场景中红色的实际强度丧失，例如，与蓝色和绿色通道相比。这在水下环境中更为明显，且随着深度的增加，红色通道值比其他颜色通道衰减得更强。因此，我们应该考虑到红色通道值不仅取决于与主体的距离，还取决于主体反射的光强，因为强光的反射通常比低强度光的反射要强。另一个在水下图像中检测特定目标时出现的问题是，多个像素可能会在图像中被激活，形成一个对象。例如，阳光通过潜望镜镜头照射可能会导致某个像素的虚假激活。需要一种可靠的方法和系统来确定远程水下图像中的特定像素是否由于目标存在而被激活，还是由于其他原因。
- en: Preprocessing of underwater photos has been extensively researched, and several
    solutions have been devised for correcting typical underwater image artefacts
    [[16](#bib.bib16), [65](#bib.bib65)]. However, the image quality produced by these
    approaches is subjective to the observer, and because acquisition settings vary
    so widely, these methods may not be applicable to all datasets. According to empirical
    results [[8](#bib.bib8), [114](#bib.bib114)], the current tendency appears to
    be to perform picture repair and enhancement processes based on the dataset, i.e.
    determining the most appropriate preprocessing strategy for a specific dataset.
    This strategy also depends on the purpose (e.g labelling, classification or both)
    of the images in the dataset.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 水下照片的预处理已被广泛研究，并且已提出了几种解决方案来纠正典型的水下图像伪影[[16](#bib.bib16), [65](#bib.bib65)]。然而，这些方法产生的图像质量对观察者来说是主观的，并且由于采集设置的差异，这些方法可能不适用于所有数据集。根据实证结果[[8](#bib.bib8),
    [114](#bib.bib114)]，当前的趋势似乎是根据数据集执行图像修复和增强处理，即确定针对特定数据集的最合适的预处理策略。这一策略还取决于数据集中图像的用途（例如标记、分类或两者兼有）。
- en: In addition, basic image enhancement techniques have been shown to be effective
    in improving image quality. For instance, in [[15](#bib.bib15)] increasing the
    uniformity of the background was used to boost picture contrast in underwater
    images for marine animal classification. This is a strong indicator that simple
    enhancing approaches might result in increased performance. Furthermore, some
    recent studies have employed DL algorithms to enhance image quality using low-quality
    images. In [[36](#bib.bib36)], for example, end-to-end mapping is performed between
    low-resolution and high-resolution images.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，基本的图像增强技术已被证明在提高图像质量方面有效。例如，在[[15](#bib.bib15)]中，通过增加背景的均匀性来提升水下图像的对比度，以用于海洋动物分类。这表明简单的增强方法可能会导致性能的提高。此外，一些近期的研究采用了深度学习算法，通过低质量图像来增强图像质量。例如，在[[36](#bib.bib36)]中，进行了低分辨率与高分辨率图像之间的端到端映射。
- en: When compared to state-of-the-art handcrafted and traditional image enhancement
    methods, DL-based algorithms typically perform better in addressing picture quality
    in terrestrial photos. However, significant new research is required to customise
    these DL-based techniques for underwater images and maritime datasets. This poses
    as a future research opportunity for image quality enhancement in fish monitoring
    applications. Below, we discuss some more opportunities.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 相较于最先进的手工制作和传统图像增强方法，基于深度学习（DL）的算法在处理地面照片的图像质量方面通常表现更好。然而，需要进行大量新的研究以定制这些基于DL的技术以适应水下图像和海洋数据集。这为鱼类监测应用中的图像质量增强提供了未来的研究机会。以下，我们讨论一些其他的机会。
- en: 6.4 Deep Learning Gap
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 深度学习差距
- en: DL is an emerging field that has a lot to offer in terms of ecology. The first
    and most obvious ecological applications are fish classification or fish count.
    However, there is still a gap between the DL-predicted fish counts and, for example,
    absolute abundance (fish per area or volume unit). The existing DL literature
    discusses mainly the use of CNNs for the ecological problems of species classification
    or fish counting. However, the absolute abundance of fish is important for ecological
    research and species conservation.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）是一个新兴领域，在生态学方面有很多潜力。第一个也是最明显的生态应用是鱼类分类或鱼类计数。然而，DL预测的鱼类计数与绝对丰度（每单位面积或体积的鱼类数量）之间仍然存在差距。现有的DL文献主要讨论了卷积神经网络（CNN）在物种分类或鱼类计数等生态问题中的应用。然而，鱼类的绝对丰度对生态研究和物种保护非常重要。
- en: Another important problem in ecological research is fish population dynamics.
    A step in addressing this problem is to analyze long-term data on fish movements
    and fish densities. However, such long-term datasets are relatively rare and expensive
    to obtain. Hence, there is a need to obtain as much information as possible from
    the small amount of data given. This requires novel methods to give an accurate
    long-term estimate of fish densities or, even better, an estimate of the absolute
    abundance of fish.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 生态研究中的另一个重要问题是鱼类种群动态。解决这个问题的一步是分析鱼类运动和鱼类密度的长期数据。然而，这类长期数据集相对稀少且获取成本高。因此，需要从有限的数据中尽可能多地获取信息。这需要创新的方法来准确估计鱼类密度，或者更好的是，估计鱼类的绝对丰度。
- en: Other exemplar ecological questions that can be addressed using DL include species
    habitat selection, or the relationship between the physical environment and the
    life history of species [[127](#bib.bib127), [115](#bib.bib115), [130](#bib.bib130)].
    DL methods can help us with this because they can take advantage of all the available
    information. The current state of DL research can be improved by considering alternative
    network architectures, more complex training algorithms, and more detailed knowledge
    of the problem domain. The existing DL literature suggests that we may see many
    new methods in the future. Most of them still do not have sufficient data to prove
    that they can outperform existing methods. There are, however, examples of successful
    applications, such as fish classification. For many ecological problems, a DL
    method can give very accurate predictions of fish densities or absolute abundance.
    However, it remains unclear whether this accuracy can be obtained only with the
    appropriate method or whether this is a property of the particular dataset on
    which the method was trained. From this perspective, the development of a general
    method for predicting fish densities and absolute abundance from very little data
    is a major problem in ecology.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 其他可以使用DL解决的典型生态问题包括物种栖息地选择，或者物理环境与物种生命周期之间的关系[[127](#bib.bib127), [115](#bib.bib115),
    [130](#bib.bib130)]。DL方法可以帮助我们，因为它们可以利用所有可用的信息。目前的DL研究状态可以通过考虑替代网络架构、更复杂的训练算法以及更详细的问题领域知识来改进。现有的DL文献表明，未来可能会出现许多新方法。其中大多数尚未拥有足够的数据来证明它们能够超越现有方法。然而，也有成功应用的例子，如鱼类分类。对于许多生态问题，DL方法可以提供非常准确的鱼类密度或绝对丰度预测。然而，目前尚不清楚这种准确性是否只能通过适当的方法获得，还是这是某个特定数据集的特性。从这个角度来看，开发一种能够从极少量数据中预测鱼类密度和绝对丰度的一般方法是生态学中的一个主要问题。
- en: One potential approach to solving this problem is to take advantage of DL models
    trained on other datasets, as long as they are related to the fish density/abundance
    problem. The ecological literature suggests that the relationship between the
    physical environment and the life history of species (e.g., fish density) is likely
    to be complex because the physical environment differs from species to species.
    Therefore, we may be able to find many similar datasets on other related problems
    (e.g., environmental science or engineering). In addition to developing and testing
    general methods to estimate the absolute abundance of fish from very little data,
    there is a need to develop general methods that can take advantage of the ecological
    knowledge and domain-specific data from a particular problem.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的一个潜在方法是利用在其他数据集上训练的深度学习模型，只要这些数据集与鱼类密度/丰度问题相关。生态文献表明，物理环境与物种生命周期（例如鱼类密度）之间的关系可能是复杂的，因为物理环境因物种而异。因此，我们可能能够在其他相关问题（例如环境科学或工程）中找到许多类似的数据集。除了开发和测试从极少数据中估计鱼类绝对丰度的通用方法外，还需要开发能够利用生态知识和特定问题领域数据的通用方法。
- en: 7 Opportunities in application of DL to fish habitat monitoring
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 深度学习在鱼类栖息地监测中的应用机会
- en: New methods and techniques will need to be devised to improve the accuracy of
    deep learning models for various marine habitat monitoring applications and to
    bring them closer to their terrestrial counterparts.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 需要制定新的方法和技术，以提高深度学习模型在各种海洋栖息地监测应用中的准确性，并使其更接近陆地环境中的模型。
- en: 7.1 Spatio-temporal and Image Data Fusion
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 时空与图像数据融合
- en: Most of the current marine habitat monitoring and visual processing tools only
    use image-based data to train their model to understand the habitats and monitor
    the environment. In such tools, each frame or image is separately processed and
    spatiotemporal correlations across neighbouring frames are simply overlooked.
    Exploiting this extra information and fusing it with the image-processing model
    can be beneficial [[137](#bib.bib137)]. For instance, fusing a master-slave camera
    setup with LSTM [[133](#bib.bib133)] can help to learn the kinematic model of
    fish in a 3D fish tracking system. Future works should consider including spatiotemporal
    information in training their model and understanding the scene. In particular,
    approaches similar to Long short-term memory (LSTM) networks or other RNN models
    can be used in conjunction with CNNs, to obtain improved classification or prediction
    outcomes by taking advantage of the time-domain information. For example, An RNN
    and a CNN model are combined in [[79](#bib.bib79)] to achieve better performance
    for salmon feeding action recognition from underwater videos. In [[93](#bib.bib93)],
    the authors propose a spatio-temporal recurrent network to classify behavioural
    patterns. Similar schemes have been proposed in [[135](#bib.bib135)]. However,
    their performance and complexity heavily rely on the ability of the RNN to track
    the temporal relations of the frames and on the effectiveness of the CNN.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 目前大多数海洋栖息地监测和视觉处理工具仅使用基于图像的数据来训练其模型，以理解栖息地和监测环境。在这些工具中，每一帧或图像都是单独处理的，邻近帧之间的时空相关性往往被忽视。利用这些额外信息并将其与图像处理模型融合可能会带来好处[[137](#bib.bib137)]。例如，将主从相机设置与LSTM
    [[133](#bib.bib133)] 融合，可以帮助在3D鱼类追踪系统中学习鱼类的运动模型。未来的工作应考虑在训练模型和理解场景时包括时空信息。特别是，类似于长短期记忆（LSTM）网络或其他RNN模型的方法可以与CNN结合使用，通过利用时间域信息来获得更好的分类或预测结果。例如，[[79](#bib.bib79)]中将RNN和CNN模型结合起来，以实现对水下视频中鲑鱼进食动作的更好识别。在[[93](#bib.bib93)]中，作者提出了一种时空递归网络来分类行为模式。类似的方案在[[135](#bib.bib135)]中也有提出。然而，它们的性能和复杂性在很大程度上依赖于RNN跟踪帧的时间关系的能力以及CNN的有效性。
- en: For instance, estimating and monitoring fish development based on previous continuous
    observations, and analysing fish behaviour are some of the applications where
    time domain information will be not only useful but also critical. Such models
    can also be used to build novel video-based protocols for the surveillance of
    critically endangered reef fish biodiversity.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，根据之前的连续观察来估计和监测鱼类的发展，以及分析鱼类行为，都是需要时间域信息的应用，这些信息不仅有用，而且至关重要。这些模型还可以用于构建新的基于视频的协议，以监测极度濒危的珊瑚礁鱼类的生物多样性。
- en: 7.2 Underwater Embedded and Edge Processing
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 水下嵌入式和边缘处理
- en: DNNs have proven to be successful in both industry and research in recent years,
    particularly for CV tasks. Specifically, large-scale DL models have had a lot
    of success in real-world scenarios with large-scale data. This is mainly due to
    their capacity to encode vast amounts of data and handle millions of model parameters
    that enhance generalisation performance when new data is evaluated. However, this
    high computational complexity and substantial storage requirement makes them difficult
    to use in real-time applications, especially on devices with restricted resources
    (e.g. embedded devices and underwater edge processors for online monitoring).
    One approach to address this is to use compressed networks such as binarised neural
    networks, which have shown promise toward reaching low-power and high-speed edge
    inference engines [[66](#bib.bib66)], for near-underwater-sensor processing. This
    can significantly improve underwater image analysis capabilities, because the
    collected large-volume images do not need to be transferred to surface for processing,
    and only the low-volume results can be communicated to shore. This also solves
    another problem, which is the challenging underwater communication [[50](#bib.bib50)].
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络（DNNs）近年来在工业和研究中均表现出成功，特别是在计算机视觉（CV）任务中。具体而言，大规模深度学习模型在处理大规模数据的实际场景中取得了很大成功。这主要得益于它们编码大量数据的能力和处理数百万个模型参数的能力，这些能力在评估新数据时增强了泛化性能。然而，这种高计算复杂性和大量存储需求使得它们在实时应用中难以使用，尤其是在资源受限的设备上（例如嵌入式设备和水下边缘处理器用于在线监测）。一种解决方法是使用压缩网络，如二值神经网络，这些网络在实现低功耗和高速边缘推理引擎[[66](#bib.bib66)]方面显示出前景，用于近水下传感器处理。这可以显著提高水下图像分析能力，因为收集的大容量图像不需要传输到地面进行处理，只需将少量结果传输到岸上。这也解决了另一个问题，即具有挑战性的水下通信[[50](#bib.bib50)]。
- en: 7.3 Combining Data from Multiple Platforms
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 结合多平台数据
- en: The use of different data collection platforms such as autonomous underwater
    vehicles (AUVs) or occupied submarines, can provide different image data from
    different perspectives of the same or different underwater habitats, to train
    more effective DNNs. In addition, using simultaneous data from multiple platforms
    can give more monitoring information, for instance, of fish distribution patterns,
    especially in situations where the number of platforms is limited. However, combining
    data from multiple platforms introduces some challenges such as the lack of ground
    truth (e.g., the number of fish in the sampled area for all the platforms), and
    the need to develop techniques that can integrate these data in a robust manner.
    Future research can work toward addressing these challenges to exploit the significant
    benefits of multiple platform data combination.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不同的数据采集平台，如自主水下航行器（AUVs）或有人潜艇，可以提供来自相同或不同水下栖息地的不同视角的图像数据，以训练更有效的深度神经网络（DNNs）。此外，使用来自多个平台的同步数据可以提供更多监测信息，例如鱼类分布模式，特别是在平台数量有限的情况下。然而，结合多个平台的数据引入了一些挑战，如缺乏真实数据（例如所有平台采样区域中的鱼数），以及需要开发能够以稳健方式整合这些数据的技术。未来的研究可以致力于解决这些挑战，以充分发挥多平台数据组合的显著优势。
- en: 7.4 Automated Fish Measurement and Monitoring
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4 自动化鱼类测量和监测
- en: DL can be used to achieve automated fish measurements, which may be useful in
    underwater fish monitoring, for instance to survey fish growth [[137](#bib.bib137)]
    through monitoring of fish length [[90](#bib.bib90)] and abundance [[27](#bib.bib27)].
    Here, abundance means the number of fish in an image or video frame, and not the
    fish count per area or volume unit. In addition, automated measurements can realise
    remote fish assessments, for example when the monitoring locations are remote,
    or the environmental conditions and or potential hazards do not allow frequent
    underwater scouting by human.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）可用于实现自动化鱼类测量，这可能在水下鱼类监测中非常有用，例如通过监测鱼类长度[[90](#bib.bib90)]和数量[[27](#bib.bib27)]来调查鱼类生长[[137](#bib.bib137)]。这里，数量指的是图像或视频帧中的鱼的数量，而不是每单位面积或体积的鱼数。此外，自动化测量可以实现远程鱼类评估，例如当监测地点较为偏远，或环境条件和潜在危险不允许人类频繁进行水下侦察时。
- en: DL can also be used for automation of monitoring of other fish biological variables
    such as their movement dynamics, present species, and their abundance and biomass.
    On top of these, DL can be used to automate understanding of environmental and
    habitat features. To achieve these, new datasets should be collected, and new
    or existing DL techniques should be devised or customised in future research.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）也可以用于自动化监测其他鱼类生物变量，如其运动动态、现存物种及其丰度和生物量。除此之外，DL还可以用于自动化理解环境和栖息地特征。为了实现这些目标，应收集新的数据集，并在未来的研究中开发或定制新的或现有的DL技术。
- en: 8 Conclusion
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: Deep Learning (DL) sits at the forefront of the machine learning technologies
    providing the processing power needed to enable underwater video to fulfill its
    promise as a critical tool for visual sampling of fish. It offers efficient and
    accurate solutions to the challenges of adverse water conditions, high similarity
    between fish species, cluttered backgrounds, occlusions among fish, that have
    limited the spatio-temporal consistency of underwater video quality. As a result,
    DL, complemented by many other advances in monitoring hardware and underwater
    communication technologies, opens the way for underwater video to provide comprehensive
    fish sampling. This can span from shallow fresh and marine waters to the deep
    ocean, opening the way for the development of the truly comparative understanding
    of marine and aquatic fish fauna and ecosystems that has hitherto been impossible.
    At least as importantly, DL solves the problem of handling the vast quantities
    of data produced by underwater video in a consistent and cost-effective way, converting
    a prohibitively expensive activity into a simple issue of computer processing.
    By enabling the processing of vast quantities of data, DL allows underwater fish
    video surveys to be conducted with unprecedented levels of spatial and temporal
    replication enabling the massive knowledge advances that flow from the ability
    of underwater videos to be deployed contemporaneously across many habitats, and
    at many spatial scales, or to provide continuous data over time.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）处于机器学习技术的最前沿，提供了实现水下视频作为鱼类视觉采样工具所需的处理能力。它为应对恶劣水质条件、鱼类物种间高度相似性、杂乱背景、鱼类间遮挡等挑战提供了高效且准确的解决方案，这些挑战限制了水下视频质量的时空一致性。因此，DL结合监测硬件和水下通信技术的诸多进展，为水下视频提供了全面的鱼类采样途径。这可以涵盖从浅水淡水和海洋到深海的范围，为真正比较理解海洋和水生鱼类及生态系统铺平了道路，这在过去是无法实现的。同样重要的是，DL解决了处理水下视频产生的大量数据的问题，以一致且具有成本效益的方式，将一种极其昂贵的活动转变为简单的计算机处理问题。通过处理大量数据，DL使水下鱼类视频调查得以在前所未有的空间和时间重复水平上进行，实现了水下视频在多个栖息地和多个空间尺度上的同步部署，或提供连续数据，从而带来了巨大的知识进步。
- en: DL, and associated techniques, have the potential for widespread use in marine
    habitat monitoring for (1) data classification and feature extraction to improve
    the quality of automatic monitoring tools; or (2) to provide a reliable means
    of surveying fish habitats and understanding their movement dynamics. While this
    will allow marine ecosystem researchers and practitioners to increase the efficiency
    of their monitoring efforts, effective development of DL will require concentrated
    and coordinated data collection, model development, and model deployment efforts,
    as well as transparent and reproducible research data and tools, which help us
    reach our target sooner.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: DL及相关技术在海洋栖息地监测中具有广泛应用的潜力，(1)用于数据分类和特征提取，以提高自动监测工具的质量；或(2)提供可靠的方式来调查鱼类栖息地并理解其运动动态。虽然这将使海洋生态系统研究人员和从业者提高监测效率，但DL的有效发展将需要集中协调的数据收集、模型开发和模型部署工作，以及透明且可重复的研究数据和工具，这将帮助我们更快地实现目标。
- en: Acknowledgement
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This research is supported by an Australian Research Training Program (RTP)
    Scholarship. We acknowledge the Australian Research Council for funding awarded
    under their Industrial Transformation Research Program.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了澳大利亚研究培训计划（RTP）奖学金的支持。我们感谢澳大利亚研究委员会根据其工业转型研究计划提供的资助。
- en: Conflict of Interest
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利益冲突
- en: All authors declare that they have no conflicts of interest.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 所有作者声明他们没有利益冲突。
- en: Data Availability Statement
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据可用性声明
- en: Data sharing is not applicable to this article as no data sets were generated
    or analysed during the current study.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 数据共享不适用于本文，因为在当前研究中没有生成或分析数据集。
- en: ORCID
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ORCID
- en: Alzayat Saleh [0000-0001-6973-019X](https://orcid.org/0000-0001-6973-019X)
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Alzayat Saleh [0000-0001-6973-019X](https://orcid.org/0000-0001-6973-019X)
- en: Marcus Sheaves [0000-0003-0662-3439](https://orcid.org/0000-0003-0662-3439)
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Marcus Sheaves [0000-0003-0662-3439](https://orcid.org/0000-0003-0662-3439)
- en: Mostafa Rahimi Azghadi [0000-0001-7975-3985](https://orcid.org/0000-0001-7975-3985)
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: Mostafa Rahimi Azghadi [0000-0001-7975-3985](https://orcid.org/0000-0001-7975-3985)
- en: \printendnotes
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: \printendnotes
- en: References
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Abdel-Hamid et al. [2013] Abdel-Hamid, O., Deng, L. and Yu, D. (2013) Exploring
    convolutional neural network structures and optimization techniques for speech
    recognition. In Interspeech, vol. 11, 73–75.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abdel-Hamid 等人 [2013] Abdel-Hamid, O., Deng, L. 和 Yu, D. (2013) 探索用于语音识别的卷积神经网络结构和优化技术。见
    Interspeech，第 11 卷，73–75。
- en: Alshdaifat et al. [2020] Alshdaifat, N. F. F., Talib, A. Z. and Osman, M. A.
    (2020) Improved deep learning framework for fish segmentation in underwater videos.
    Ecological Informatics, 59, 101121.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alshdaifat 等人 [2020] Alshdaifat, N. F. F., Talib, A. Z. 和 Osman, M. A. (2020)
    改进的深度学习框架用于水下视频中的鱼类分割。生态信息学，59，101121。
- en: Alsmadi et al. [2011] Alsmadi, M. K., Omar, K. B. and Mohd Noah, S. A. (2011)
    Fish classification based on robust features extraction from color signature using
    back-propagation classifier. Journal of Computer Science, 7, 52–58.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alsmadi 等人 [2011] Alsmadi, M. K., Omar, K. B. 和 Mohd Noah, S. A. (2011) 基于从颜色特征中提取的鲁棒特征的鱼类分类，使用反向传播分类器。计算机科学杂志，7，52–58。
- en: Alsmadi et al. [2010] Alsmadi, M. K., Omar, K. B., Noah, S. A. and Almarashdeh,
    I. (2010) Fish recognition based on robust features extraction from size and shape
    measurements using neural network. Journal of Computer Science, 6, 1088–1094.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alsmadi 等人 [2010] Alsmadi, M. K., Omar, K. B., Noah, S. A. 和 Almarashdeh, I.
    (2010) 基于从大小和形状测量中提取的鲁棒特征的鱼类识别，使用神经网络。计算机科学杂志，6，1088–1094。
- en: Azghadi et al. [2020] Azghadi, M. R., Lammie, C., Eshraghian, J. K., Payvand,
    M., Donati, E., Linares-Barranco, B. and Indiveri, G. (2020) Hardware Implementation
    of Deep Network Accelerators towards Healthcare and Biomedical Applications. IEEE
    Transactions on Biomedical Circuits and Systems, 14, 1138–1159.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azghadi 等人 [2020] Azghadi, M. R., Lammie, C., Eshraghian, J. K., Payvand, M.,
    Donati, E., Linares-Barranco, B. 和 Indiveri, G. (2020) 深度网络加速器的硬件实现，面向医疗保健和生物医学应用。IEEE
    生物医学电路与系统汇刊，14，1138–1159。
- en: Badawi and Alsmadi [2014] Badawi, U. A. and Alsmadi, M. K. (2014) A general
    fish classification methodology using meta-heuristic algorithm with back propagation
    classifier. Journal of Theoretical and Applied Information Technology, 66, 803–812.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Badawi 和 Alsmadi [2014] Badawi, U. A. 和 Alsmadi, M. K. (2014) 一种通用的鱼类分类方法，使用具有反向传播分类器的元启发式算法。理论与应用信息技术杂志，66，803–812。
- en: 'Ballard and Brown [1982] Ballard, D. H. and Brown, C. M. (1982) Computer Vision.
    Prentice Hall. URL: [https://archive.org/details/computervision0000ball](https://archive.org/details/computervision0000ball).'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ballard 和 Brown [1982] Ballard, D. H. 和 Brown, C. M. (1982) 计算机视觉。普伦蒂斯霍尔。网址：[https://archive.org/details/computervision0000ball](https://archive.org/details/computervision0000ball)。
- en: Beijbom et al. [2012] Beijbom, O., Edmunds, P. J., Kline, D. I., Mitchell, B. G.
    and Kriegman, D. (2012) Automated annotation of coral reef survey images. In Proceedings
    of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,
    1170–1177.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beijbom 等人 [2012] Beijbom, O., Edmunds, P. J., Kline, D. I., Mitchell, B. G.
    和 Kriegman, D. (2012) 珊瑚礁调查图像的自动注释。见 IEEE 计算机协会计算机视觉与模式识别会议论文集，1170–1177。
- en: Blanchet et al. [2016] Blanchet, J.-N., Déry, S., Landry, J.-A. and Osborne,
    K. (2016) Automated annotation of corals in natural scene images using multiple
    texture representations. PeerJ.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blanchet 等人 [2016] Blanchet, J.-N., Déry, S., Landry, J.-A. 和 Osborne, K. (2016)
    使用多种纹理表示对自然场景图像中的珊瑚进行自动注释。PeerJ。
- en: Boom et al. [2014] Boom, B. J., He, J., Palazzo, S., Huang, P. X., Beyan, C.,
    Chou, H.-M., Lin, F.-P., Spampinato, C. and Fisher, R. B. (2014) A research tool
    for long-term and continuous analysis of fish assemblage in coral-reefs using
    underwater camera footage. Ecological Informatics, 23, 83–97.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boom 等人 [2014] Boom, B. J., He, J., Palazzo, S., Huang, P. X., Beyan, C., Chou,
    H.-M., Lin, F.-P., Spampinato, C. 和 Fisher, R. B. (2014) 一种研究工具，用于对珊瑚礁中的鱼群进行长期和持续分析，使用水下摄像机录像。生态信息学，23，83–97。
- en: Boom et al. [2012] Boom, B. J., Huang, P. X., Beyan, C., Spampinato, C., Palazzo,
    S., He, J., Beauxis-Aussalet, E., Lin, S. I., Chou, H. M., Nadarajan, G., Chen-Burger,
    Y. H., van Ossenbruggen, J., Giordano, D., Hardman, L., Lin, F. P. and Fisher,
    R. B. (2012) Long-term underwater camera surveillance for monitoring and analysis
    of fish populations. Workshop on Visual observation and Analysis of Animal and
    Insect Behavior (VAIB), in conjunction with ICPR 2012.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boom et al. [2012] Boom, B. J., Huang, P. X., Beyan, C., Spampinato, C., Palazzo,
    S., He, J., Beauxis-Aussalet, E., Lin, S. I., Chou, H. M., Nadarajan, G., Chen-Burger,
    Y. H., van Ossenbruggen, J., Giordano, D., Hardman, L., Lin, F. P. 和 Fisher, R.
    B. (2012) 长期水下摄像机监控以监测和分析鱼类群体。动物和昆虫行为视觉观察与分析研讨会 (VAIB)，与 ICPR 2012 相关联。
- en: 'Boudhane and Nsiri [2016] Boudhane, M. and Nsiri, B. (2016) Underwater image
    processing method for fish localization and detection in submarine environment.
    Journal of Visual Communication and Image Representation, 39, 226–238. URL: [https://linkinghub.elsevier.com/retrieve/pii/S1047320316300840](https://linkinghub.elsevier.com/retrieve/pii/S1047320316300840).'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boudhane 和 Nsiri [2016] Boudhane, M. 和 Nsiri, B. (2016) 水下图像处理方法用于在潜艇环境中定位和检测鱼类。《视觉通信与图像表现学报》，39，226–238。网址：[https://linkinghub.elsevier.com/retrieve/pii/S1047320316300840](https://linkinghub.elsevier.com/retrieve/pii/S1047320316300840)。
- en: Boudhane et al. [2016] Boudhane, M., Nsiri, B. and Toulni, H. (2016) Optical
    fish classification using statistics of parts. International Journal of Mathematics
    and Computers in Simulation, 10, 18–22.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boudhane et al. [2016] Boudhane, M., Nsiri, B. 和 Toulni, H. (2016) 使用部件统计进行光学鱼类分类。《数学与计算机模拟国际期刊》，10，18–22。
- en: 'Brunetti et al. [2018] Brunetti, A., Buongiorno, D., Trotta, G. F. and Bevilacqua,
    V. (2018) Computer vision and deep learning techniques for pedestrian detection
    and tracking: A survey. Neurocomputing.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brunetti et al. [2018] Brunetti, A., Buongiorno, D., Trotta, G. F. 和 Bevilacqua,
    V. (2018) 行人检测和跟踪的计算机视觉与深度学习技术：一项综述。《神经计算》。
- en: Cao et al. [2016] Cao, Z., Principe, J. C., Ouyang, B., Dalgleish, F. and Vuorenkoski,
    A. (2016) Marine animal classification using combined CNN and hand-designed image
    features. In OCEANS 2015 - MTS/IEEE Washington.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao et al. [2016] Cao, Z., Principe, J. C., Ouyang, B., Dalgleish, F. 和 Vuorenkoski,
    A. (2016) 使用结合 CNN 和手工设计的图像特征进行海洋动物分类。见于 OCEANS 2015 - MTS/IEEE Washington。
- en: 'Carlevaris-Bianco et al. [2010] Carlevaris-Bianco, N., Mohan, A. and Eustice,
    R. M. (2010) Initial results in underwater single image dehazing. In OCEANS 2010
    MTS/IEEE SEATTLE, 1–8\. IEEE. URL: [http://ieeexplore.ieee.org/document/5664428/](http://ieeexplore.ieee.org/document/5664428/).'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carlevaris-Bianco et al. [2010] Carlevaris-Bianco, N., Mohan, A. 和 Eustice,
    R. M. (2010) 水下单幅图像去雾的初步结果。见于 OCEANS 2010 MTS/IEEE SEATTLE，1–8。IEEE。网址：[http://ieeexplore.ieee.org/document/5664428/](http://ieeexplore.ieee.org/document/5664428/)。
- en: Chen et al. [2018] Chen, G., Sun, P. and Shang, Y. (2018) Automatic fish classification
    system using deep learning. In Proceedings - International Conference on Tools
    with Artificial Intelligence, ICTAI.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2018] Chen, G., Sun, P. 和 Shang, Y. (2018) 使用深度学习的自动鱼类分类系统。见于国际人工智能工具会议论文集，ICTAI。
- en: 'Chen et al. [2019] Chen, L., Xia, Y., Pan, D. and Wang, C. (2019) Deep learning
    based active monitoring for anti-collision between vessels and bridges. In IABSE
    Symposium, Guimaraes 2019: Towards a Resilient Built Environment Risk and Asset
    Management - Report.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2019] Chen, L., Xia, Y., Pan, D. 和 Wang, C. (2019) 基于深度学习的主动监控系统，用于船只与桥梁之间的防碰撞。见于
    IABSE 研讨会，Guimaraes 2019：迈向弹性建筑环境风险与资产管理 - 报告。
- en: 'Chuang et al. [2014] Chuang, M. C., Hwang, J. N., Kuo, F. F., Shan, M. K. and
    Williams, K. (2014) Recognizing live fish species by hierarchical partial classification
    based on the exponential benefit. In Proc. Int. Conf. Image Process., 5232–5236\.
    Paris, France: IEEE.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chuang et al. [2014] Chuang, M. C., Hwang, J. N., Kuo, F. F., Shan, M. K. 和
    Williams, K. (2014) 通过基于指数收益的分层部分分类识别活鱼种类。见于《国际图像处理会议论文集》，5232–5236。法国巴黎：IEEE。
- en: Chuang et al. [2016] Chuang, M. C., Hwang, J. N. and Williams, K. (2016) A feature
    learning and object recognition framework for underwater fish images. IEEE Trans.
    Image Process., 25, 1862–1872.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chuang et al. [2016] Chuang, M. C., Hwang, J. N. 和 Williams, K. (2016) 水下鱼类图像的特征学习和目标识别框架。《IEEE图像处理学报》，25，1862–1872。
- en: 'Cook [2020] Cook, T. R. (2020) Neural Networks. In Advanced Studies in Theoretical
    and Applied Econometrics, 161–189. URL: [http://link.springer.com/10.1007/978-3-030-31150-6_6](http://link.springer.com/10.1007/978-3-030-31150-6_6).'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cook [2020] Cook, T. R. (2020) 神经网络。见于《理论与应用计量经济学高级研究》，161–189。网址：[http://link.springer.com/10.1007/978-3-030-31150-6_6](http://link.springer.com/10.1007/978-3-030-31150-6_6)。
- en: 'Cutter et al. [2015] Cutter, G., Stierhoff, K. and Zeng, J. (2015) Automated
    detection of rockfish in unconstrained underwater videos using haar cascades and
    a new image dataset: Labeled fishes in the wild. In Proceedings - 2015 IEEE Winter
    Conference on Applications of Computer Vision Workshops, WACVW 2015, 57–62.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cutter 等人 [2015] Cutter, G., Stierhoff, K. 和 Zeng, J. (2015) 使用 Haar 级联和新的图像数据集在无约束的水下视频中自动检测岩鱼：野外标记鱼类。发表于
    - 2015 IEEE 冬季计算机视觉应用研讨会，WACVW 2015，57–62。
- en: Dalal and Triggs [2005] Dalal, N. and Triggs, B. (2005) Histograms of oriented
    gradients for human detection. In Proceedings - 2005 IEEE Computer Society Conference
    on Computer Vision and Pattern Recognition, CVPR 2005, vol. I, 886–893.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dalal 和 Triggs [2005] Dalal, N. 和 Triggs, B. (2005) 用于人类检测的方向梯度直方图。发表于 - 2005
    IEEE 计算机协会计算机视觉与模式识别会议，CVPR 2005，第 I 卷，886–893。
- en: Deep and Dash [2019] Deep, B. V. and Dash, R. (2019) Underwater Fish Species
    Recognition Using Deep Learning Techniques. In 2019 6th International Conference
    on Signal Processing and Integrated Networks, SPIN 2019.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deep 和 Dash [2019] Deep, B. V. 和 Dash, R. (2019) 使用深度学习技术进行水下鱼类物种识别。发表于 2019
    第六届信号处理与集成网络国际会议，SPIN 2019。
- en: 'Deng and Yu [2013] Deng, L. and Yu, D. (2013) Deep learning: Methods and applications.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng 和 Yu [2013] Deng, L. 和 Yu, D. (2013) 深度学习：方法与应用。
- en: 'Martinez-de Dios et al. [2003] Martinez-de Dios, J. R., Serna, C. and Ollero,
    A. (2003) Computer vision and robotics techniques in fish farms. Robotica, 21,
    233–243. URL: [https://www.cambridge.org/core/product/identifier/S0263574702004733/type/journal_article](https://www.cambridge.org/core/product/identifier/S0263574702004733/type/journal_article).'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Martinez-de Dios 等人 [2003] Martinez-de Dios, J. R., Serna, C. 和 Ollero, A. (2003)
    鱼场中的计算机视觉和机器人技术。Robotica, 21, 233–243。网址：[https://www.cambridge.org/core/product/identifier/S0263574702004733/type/journal_article](https://www.cambridge.org/core/product/identifier/S0263574702004733/type/journal_article)。
- en: 'Ditria et al. [2019] Ditria, E., Lopez-Marcano, S., Sievers, M., Jinks, E.,
    Brown, C. and Connolly, R. (2019) Automating the analysis of fish abundance using
    object detection: optimising animal ecology with deep learning. Frontiers in Marine
    Science.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ditria 等人 [2019] Ditria, E., Lopez-Marcano, S., Sievers, M., Jinks, E., Brown,
    C. 和 Connolly, R. (2019) 使用对象检测自动分析鱼类丰度：通过深度学习优化动物生态学。Frontiers in Marine Science。
- en: 'Ditria et al. [2021] Ditria, E. M., Connolly, R. M., Jinks, E. L. and Lopez-Marcano,
    S. (2021) Annotated Video Footage for Automated Identification and Counting of
    Fish in Unconstrained Seagrass Habitats. Frontiers in Marine Science, 8. URL:
    [https://www.frontiersin.org/articles/10.3389/fmars.2021.629485/full](https://www.frontiersin.org/articles/10.3389/fmars.2021.629485/full).'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ditria 等人 [2021] Ditria, E. M., Connolly, R. M., Jinks, E. L. 和 Lopez-Marcano,
    S. (2021) 用于自动识别和计数鱼类的带注释视频资料在无约束的海草栖息地中。Frontiers in Marine Science, 8。网址：[https://www.frontiersin.org/articles/10.3389/fmars.2021.629485/full](https://www.frontiersin.org/articles/10.3389/fmars.2021.629485/full)。
- en: 'Erickson et al. [2017] Erickson, B. J., Korfiatis, P., Akkus, Z. and Kline,
    T. L. (2017) Machine Learning for Medical Imaging. RadioGraphics, 37, 505–515.
    URL: [http://pubs.rsna.org/doi/10.1148/rg.2017160130](http://pubs.rsna.org/doi/10.1148/rg.2017160130).'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Erickson 等人 [2017] Erickson, B. J., Korfiatis, P., Akkus, Z. 和 Kline, T. L.
    (2017) 医学影像中的机器学习。RadioGraphics, 37, 505–515。网址：[http://pubs.rsna.org/doi/10.1148/rg.2017160130](http://pubs.rsna.org/doi/10.1148/rg.2017160130)。
- en: 'Falcini et al. [2017] Falcini, F., Lami, G. and Costanza, A. M. (2017) Deep
    Learning in Automotive Software. IEEE Software, 34, 56–63. URL: [https://ieeexplore.ieee.org/document/7927925/](https://ieeexplore.ieee.org/document/7927925/).'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Falcini 等人 [2017] Falcini, F., Lami, G. 和 Costanza, A. M. (2017) 汽车软件中的深度学习。IEEE
    Software, 34, 56–63。网址：[https://ieeexplore.ieee.org/document/7927925/](https://ieeexplore.ieee.org/document/7927925/)。
- en: Fouad et al. [2014] Fouad, M. M. M., Zawbaa, H. M., El-Bendary, N. and Hassanien,
    A. E. (2014) Automatic Nile Tilapia fish classification approach using machine
    learning techniques. In 13th International Conference on Hybrid Intelligent Systems,
    HIS 2013, 173–178.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fouad 等人 [2014] Fouad, M. M. M., Zawbaa, H. M., El-Bendary, N. 和 Hassanien,
    A. E. (2014) 使用机器学习技术的自动尼罗罗非鱼分类方法。发表于第十三届国际混合智能系统会议，HIS 2013，173–178。
- en: 'French et al. [2020] French, G., Mackiewicz, M., Fisher, M., Holah, H., Kilburn,
    R., Campbell, N. and Needle, C. (2020) Deep neural networks for analysis of fisheries
    surveillance video and automated monitoring of fish discards. ICES Journal of
    Marine Science, 77, 1340–1353. URL: [https://academic.oup.com/icesjms/article/77/4/1340/5542623](https://academic.oup.com/icesjms/article/77/4/1340/5542623).'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'French 等 [2020] French, G., Mackiewicz, M., Fisher, M., Holah, H., Kilburn,
    R., Campbell, N. 和 Needle, C. (2020) 用于分析渔业监控视频和自动化鱼类弃置监测的深度神经网络。ICES 海洋科学期刊，77，1340–1353。网址:
    [https://academic.oup.com/icesjms/article/77/4/1340/5542623](https://academic.oup.com/icesjms/article/77/4/1340/5542623)。'
- en: '[33] Garcia, R., Prados, R., Quintana, J., Tempelaar, A., Gracias, N., Rosen,
    S., Vågstøl, H., Løvall, K., Vagstol, H. and Lovall, K. () Automatic segmentation
    of fish using deep learning with application to fish size measurement. ICES Journal
    of Marine Science, 77, 1354–1366. URL: [https://doi.org/10.1093/icesjms/fsz186](https://doi.org/10.1093/icesjms/fsz186).'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Garcia, R., Prados, R., Quintana, J., Tempelaar, A., Gracias, N., Rosen,
    S., Vågstøl, H., Løvall, K., Vagstol, H. 和 Lovall, K. () 使用深度学习自动分割鱼类及其在鱼体大小测量中的应用。ICES
    海洋科学期刊，77，1354–1366。网址: [https://doi.org/10.1093/icesjms/fsz186](https://doi.org/10.1093/icesjms/fsz186)。'
- en: Goodfellow et al. [2016] Goodfellow, I., Bengio, Y., Courville, A. and Bengio,
    Y. (2016) Deep learning, vol. 1. MIT Press.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等 [2016] Goodfellow, I., Bengio, Y., Courville, A. 和 Bengio, Y. (2016)
    深度学习，第1卷。麻省理工学院出版社。
- en: 'Goodwin et al. [2022] Goodwin, M., Halvorsen, K. T., Jiao, L., Knausgård, K. M.,
    Martin, A. H., Moyano, M., Oomen, R. A., Rasmussen, J. H., Sørdalen, T. K. and
    Thorbjørnsen, S. H. (2022) Unlocking the potential of deep learning for marine
    ecology: overview, applications, and outlook. ICES Journal of Marine Science,
    79, 319–336. URL: [https://arxiv.org/abs/2109.14737v1](https://arxiv.org/abs/2109.14737v1).'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Goodwin 等 [2022] Goodwin, M., Halvorsen, K. T., Jiao, L., Knausgård, K. M.,
    Martin, A. H., Moyano, M., Oomen, R. A., Rasmussen, J. H., Sørdalen, T. K. 和 Thorbjørnsen,
    S. H. (2022) 解锁深度学习在海洋生态学中的潜力：概述、应用与展望。ICES 海洋科学期刊，79，319–336。网址: [https://arxiv.org/abs/2109.14737v1](https://arxiv.org/abs/2109.14737v1)。'
- en: He and Li [2019] He, T. and Li, X. (2019) Image quality recognition technology
    based on deep learning. Journal of Visual Communication and Image Representation,
    65.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 和 Li [2019] He, T. 和 Li, X. (2019) 基于深度学习的图像质量识别技术。视觉通信与图像表示期刊，65。
- en: 'Hilborn and Walters [1992] Hilborn, R. and Walters, C. J. (1992) Quantitative
    fisheries stock assessment: Choice, dynamics and uncertainty. Reviews in Fish
    Biology and Fisheries, 2, 177–178. URL: [http://link.springer.com/10.1007/BF00042883](http://link.springer.com/10.1007/BF00042883).'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hilborn 和 Walters [1992] Hilborn, R. 和 Walters, C. J. (1992) 定量渔业资源评估：选择、动态和不确定性。鱼类生物学与渔业评论，2，177–178。网址:
    [http://link.springer.com/10.1007/BF00042883](http://link.springer.com/10.1007/BF00042883)。'
- en: 'Hohage et al. [2020] Hohage, T., Sprung, B. and Weidling, F. (2020) Inverse
    Problems. In Topics in Applied Physics, 145–164. URL: [http://link.springer.com/10.1007/978-3-030-34413-9_5](http://link.springer.com/10.1007/978-3-030-34413-9_5).'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hohage 等 [2020] Hohage, T., Sprung, B. 和 Weidling, F. (2020) 反问题。在应用物理学专题中，145–164。网址:
    [http://link.springer.com/10.1007/978-3-030-34413-9_5](http://link.springer.com/10.1007/978-3-030-34413-9_5)。'
- en: Hossain et al. [2016] Hossain, E., Alam, S. M., Ali, A. A. and Amin, M. A. (2016)
    Fish activity tracking and species identification in underwater video. In 2016
    5th International Conference on Informatics, Electronics and Vision, ICIEV 2016,
    62–66.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hossain 等 [2016] Hossain, E., Alam, S. M., Ali, A. A. 和 Amin, M. A. (2016) 水下视频中的鱼类活动跟踪与物种识别。2016年第五届信息学、电子学与视觉国际会议，ICIEV
    2016，62–66。
- en: Hsiao et al. [2014a] Hsiao, Y. H., Chen, C. C., Lin, S. I. and Lin, F. P. (2014a)
    Real-world underwater fish recognition and identification, using sparse representation.
    Ecological Informatics, 23, 13–21.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hsiao 等 [2014a] Hsiao, Y. H., Chen, C. C., Lin, S. I. 和 Lin, F. P. (2014a) 现实世界中的水下鱼类识别与鉴定，采用稀疏表示。生态信息学，23，13–21。
- en: Hsiao et al. [2014b] Hsiao, Y.-H., Chen, C.-C., Lin, S.-I. and Lin, F.-P. (2014b)
    Real-world underwater fish recognition and identification, using sparse representation.
    Ecological Informatics, 23, 13–21.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hsiao 等 [2014b] Hsiao, Y.-H., Chen, C.-C., Lin, S.-I. 和 Lin, F.-P. (2014b) 现实世界中的水下鱼类识别与鉴定，采用稀疏表示。生态信息学，23，13–21。
- en: Hu et al. [2012] Hu, Y., Mian, A. S. and Owens, R. (2012) Face Recognition Using
    Sparse Approximated Nearest Points between Image Sets. IEEE Transactions on Pattern
    Analysis and Machine Intelligence, 34, 1992–2004.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等 [2012] Hu, Y., Mian, A. S. 和 Owens, R. (2012) 使用稀疏近似最近点进行面部识别。IEEE 模式分析与机器智能期刊，34，1992–2004。
- en: 'Huang et al. [2014] Huang, P. X., Boom, B. J. and Fisher, R. B. (2014) GMM
    improves the reject option in hierarchical classification for fish recognition.
    In IEEE Winter Conference on Applications of Computer Vision, 371–376\. IEEE.
    URL: [https://ieeexplore.ieee.org/document/6836076](https://ieeexplore.ieee.org/document/6836076).'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang 等人 [2014] Huang, P. X., Boom, B. J. 和 Fisher, R. B. (2014) GMM 改进了鱼类识别中的分层分类拒绝选项。在
    IEEE 冬季计算机视觉应用会议, 371–376。IEEE。网址: [https://ieeexplore.ieee.org/document/6836076](https://ieeexplore.ieee.org/document/6836076)。'
- en: 'Huang [1996] Huang, T. (1996) Computer Vision : Evolution And Promise. Geneva:
    CERN. URL: [http://cds.cern.ch/record/400313/files/p21.pdf](http://cds.cern.ch/record/400313/files/p21.pdf).'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang [1996] Huang, T. (1996) 计算机视觉：演变与承诺。日内瓦：CERN。网址: [http://cds.cern.ch/record/400313/files/p21.pdf](http://cds.cern.ch/record/400313/files/p21.pdf)。'
- en: Iqbal et al. [2021] Iqbal, M. A., Wang, Z., Ali, Z. A. and Riaz, S. (2021) Automatic
    Fish Species Classification Using Deep Convolutional Neural Networks. Wireless
    Personal Communications.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iqbal 等人 [2021] Iqbal, M. A., Wang, Z., Ali, Z. A. 和 Riaz, S. (2021) 基于深度卷积神经网络的自动鱼类分类。无线个人通信。
- en: Islam et al. [2019] Islam, M. A., Howlader, M. R., Habiba, U., Faisal, R. H.
    and Rahman, M. M. (2019) Indigenous Fish Classification of Bangladesh using Hybrid
    Features with SVM Classifier. In 5th International Conference on Computer, Communication,
    Chemical, Materials and Electronic Engineering, IC4ME2 2019.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Islam 等人 [2019] Islam, M. A., Howlader, M. R., Habiba, U., Faisal, R. H. 和 Rahman,
    M. M. (2019) 使用混合特征和 SVM 分类器的孟加拉国本土鱼类分类。在第五届国际计算机、通信、化学、材料与电子工程会议, IC4ME2 2019。
- en: 'Islam et al. [2020] Islam, M. J., Edge, C., Xiao, Y., Luo, P., Mehtaz, M.,
    Morse, C., Enan, S. S. and Sattar, J. (2020) Semantic Segmentation of Underwater
    Imagery: Dataset and Benchmark. http://arxiv.org/abs/2004.01241. URL: [http://arxiv.org/abs/2004.01241](http://arxiv.org/abs/2004.01241).'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Islam 等人 [2020] Islam, M. J., Edge, C., Xiao, Y., Luo, P., Mehtaz, M., Morse,
    C., Enan, S. S. 和 Sattar, J. (2020) 水下图像的语义分割：数据集和基准测试。http://arxiv.org/abs/2004.01241。网址:
    [http://arxiv.org/abs/2004.01241](http://arxiv.org/abs/2004.01241)。'
- en: 'Ismail Fawaz et al. [2019] Ismail Fawaz, H., Forestier, G., Weber, J., Idoumghar,
    L. and Muller, P.-A. (2019) Deep learning for time series classification: a review.
    Data Mining and Knowledge Discovery, 33, 917–963. URL: [https://link.springer.com/10.1007/s10618-019-00619-1](https://link.springer.com/10.1007/s10618-019-00619-1).'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ismail Fawaz 等人 [2019] Ismail Fawaz, H., Forestier, G., Weber, J., Idoumghar,
    L. 和 Muller, P.-A. (2019) 时序分类的深度学习：综述。数据挖掘与知识发现, 33, 917–963。网址: [https://link.springer.com/10.1007/s10618-019-00619-1](https://link.springer.com/10.1007/s10618-019-00619-1)。'
- en: 'Jahanbakht et al. [2022] Jahanbakht, M., Xiang, W. and Azghadi, M. R. (2022)
    Sea Surface Temperature Forecasting With Ensemble of Stacked Deep Neural Networks.
    IEEE Geoscience and Remote Sensing Letters, 19, 1–5. URL: [https://ieeexplore.ieee.org/document/9507522/](https://ieeexplore.ieee.org/document/9507522/).'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jahanbakht 等人 [2022] Jahanbakht, M., Xiang, W. 和 Azghadi, M. R. (2022) 基于堆叠深度神经网络的海表温度预测。IEEE
    地球科学与遥感快报, 19, 1–5。网址: [https://ieeexplore.ieee.org/document/9507522/](https://ieeexplore.ieee.org/document/9507522/)。'
- en: 'Jahanbakht et al. [2021] Jahanbakht, M., Xiang, W., Hanzo, L. and Azghadi,
    M. R. (2021) Internet of Underwater Things and Big Marine Data Analytics - A Comprehensive
    Survey. IEEE Communications Surveys and Tutorials, 23, 904–956. URL: [https://ieeexplore.ieee.org/document/9328873/](https://ieeexplore.ieee.org/document/9328873/).'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jahanbakht 等人 [2021] Jahanbakht, M., Xiang, W., Hanzo, L. 和 Azghadi, M. R.
    (2021) 水下物联网与大规模海洋数据分析 - 综合调查。IEEE 通信调查与教程, 23, 904–956。网址: [https://ieeexplore.ieee.org/document/9328873/](https://ieeexplore.ieee.org/document/9328873/)。'
- en: Jalal et al. [2020] Jalal, A., Salman, A., Mian, A., Shortis, M. and Shafait,
    F. (2020) Fish detection and species classification in underwater environments
    using deep learning with temporal information. Ecological Informatics, 57, 101088.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jalal 等人 [2020] Jalal, A., Salman, A., Mian, A., Shortis, M. 和 Shafait, F. (2020)
    使用具有时间信息的深度学习在水下环境中进行鱼类检测和种类分类。生态信息学, 57, 101088。
- en: 'Janssens and Martens [2020] Janssens, A. C. J. and Martens, F. K. (2020) Reflection
    on modern methods: Revisiting the area under the ROC Curve. International Journal
    of Epidemiology, 49, 1397–1403.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Janssens 和 Martens [2020] Janssens, A. C. J. 和 Martens, F. K. (2020) 现代方法的反思：重新审视
    ROC 曲线下面积。国际流行病学杂志, 49, 1397–1403。
- en: Jin and Liang [2017] Jin, L. and Liang, H. (2017) Deep learning for underwater
    image recognition in small sample size situations. In OCEANS 2017 - Aberdeen.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin 和 Liang [2017] Jin, L. 和 Liang, H. (2017) 小样本情况下水下图像识别的深度学习。在 OCEANS 2017
    - 阿伯丁。
- en: Juliani and Juliani [2021] Juliani, C. and Juliani, E. (2021) Deep learning
    of terrain morphology and pattern discovery via network-based representational
    similarity analysis for deep-sea mineral exploration. Ore Geology Reviews.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Juliani 和 Juliani [2021] Juliani, C. 和 Juliani, E. (2021) 通过基于网络的表征相似性分析进行深度海洋矿产勘探的地形形态和模式发现。矿产地质学评论。
- en: Kartika and Herumurti [2017] Kartika, D. S. Y. and Herumurti, D. (2017) Koi
    fish classification based on HSV color space. In Proceedings of 2016 International
    Conference on Information and Communication Technology and Systems, ICTS 2016,
    96–100.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kartika 和 Herumurti [2017] Kartika, D. S. Y. 和 Herumurti, D. (2017) 基于 HSV 颜色空间的锦鲤分类。发表于
    2016 国际信息与通信技术与系统会议（ICTS 2016）论文集，96–100。
- en: 'Kim et al. [2016] Kim, S., Park, B., Song, B. S. and Yang, S. (2016) Deep belief
    network based statistical feature learning for fingerprint liveness detection.
    Pattern Recognition Letters, 77, 58–65. URL: [https://linkinghub.elsevier.com/retrieve/pii/S0167865516300198](https://linkinghub.elsevier.com/retrieve/pii/S0167865516300198).'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 等 [2016] Kim, S., Park, B., Song, B. S. 和 Yang, S. (2016) 基于深度信念网络的指纹活性检测统计特征学习。模式识别快报，77，58–65。网址：[https://linkinghub.elsevier.com/retrieve/pii/S0167865516300198](https://linkinghub.elsevier.com/retrieve/pii/S0167865516300198/)。
- en: 'Knausgård et al. [2021] Knausgård, K. M., Wiklund, A., Sørdalen, T. K., Halvorsen,
    K. T., Kleiven, A. R., Jiao, L. and Goodwin, M. (2021) Temperate fish detection
    and classification: a deep learning based approach. Applied Intelligence.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Knausgård 等 [2021] Knausgård, K. M., Wiklund, A., Sørdalen, T. K., Halvorsen,
    K. T., Kleiven, A. R., Jiao, L. 和 Goodwin, M. (2021) 温带鱼检测与分类：一种基于深度学习的方法。应用智能。
- en: 'Konovalov et al. [2019a] Konovalov, D. A., Saleh, A., Bradley, M., Sankupellay,
    M., Marini, S. and Sheaves, M. (2019a) Underwater Fish Detection with Weak Multi-Domain
    Supervision. In 2019 International Joint Conference on Neural Networks (IJCNN),
    vol. 2019-July, 1–8\. IEEE. URL: [https://ieeexplore.ieee.org/document/8851907/](https://ieeexplore.ieee.org/document/8851907/).'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Konovalov 等 [2019a] Konovalov, D. A., Saleh, A., Bradley, M., Sankupellay, M.,
    Marini, S. 和 Sheaves, M. (2019a) 使用弱多领域监督的水下鱼类检测。发表于 2019 国际联合神经网络大会（IJCNN），第
    2019 年 7 月卷，1–8。IEEE。网址：[https://ieeexplore.ieee.org/document/8851907/](https://ieeexplore.ieee.org/document/8851907/)。
- en: 'Konovalov et al. [2019b] — (2019b) Underwater Fish Detection with Weak Multi-Domain
    Supervision. In 2019 International Joint Conference on Neural Networks (IJCNN),
    vol. 2019-July, 1–8\. IEEE. URL: [https://ieeexplore.ieee.org/document/8851907/](https://ieeexplore.ieee.org/document/8851907/).'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Konovalov 等 [2019b] — (2019b) 使用弱多领域监督的水下鱼类检测。发表于 2019 国际联合神经网络大会（IJCNN），第 2019
    年 7 月卷，1–8。IEEE。网址：[https://ieeexplore.ieee.org/document/8851907/](https://ieeexplore.ieee.org/document/8851907/)。
- en: Korekado et al. [2003] Korekado, K., Morie, T., Nomura, O., Ando, H., Nakano,
    T., Matsugu, M. and Iwata, A. (2003) A convolutional neural network VLSI for image
    recognition using merged/mixed analog-digital architecture. In International Conference
    on Knowledge-Based and Intelligent Information and Engineering Systems, 169–176\.
    Springer.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Korekado 等 [2003] Korekado, K., Morie, T., Nomura, O., Ando, H., Nakano, T.,
    Matsugu, M. 和 Iwata, A. (2003) 一种用于图像识别的卷积神经网络 VLSI，采用融合/混合模拟-数字架构。发表于国际知识基础与智能信息工程系统会议，169–176。Springer.
- en: 'Kotsiantis [2007] Kotsiantis, S. B. (2007) Supervised machine learning: A review
    of classification techniques.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kotsiantis [2007] Kotsiantis, S. B. (2007) 监督机器学习：分类技术综述。
- en: Krizhevsky et al. [2012] Krizhevsky, A., Sutskever, I. and Hinton, G. E. (2012)
    ImageNet Classification with Deep Convolutional Neural Networks. In Advances in
    Neural Information Processing Systems 25 (eds. F. Pereira, C. J. C. Burges, L. Bottou
    and K. Q. Weinberger), 1097–1105\. Curran Associates, Inc.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky 等 [2012] Krizhevsky, A., Sutskever, I. 和 Hinton, G. E. (2012) 使用深度卷积神经网络进行
    ImageNet 分类。发表于《神经信息处理系统进展》第 25 卷（编辑：F. Pereira, C. J. C. Burges, L. Bottou 和
    K. Q. Weinberger），1097–1105。Curran Associates, Inc.
- en: Krupinski [2017] Krupinski, E. A. (2017) Receiver operating characteristic (Roc)
    analysis. Frontline Learning Research, 5, 31–42.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krupinski [2017] Krupinski, E. A. (2017) 受试者工作特征（ROC）分析。前沿学习研究，5，31–42。
- en: 'Kukačka et al. [2017] Kukačka, J., Golkov, V. and Cremers, D. (2017) Regularization
    for deep learning: A taxonomy. arXiv preprint arXiv:1710.10686.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kukačka 等 [2017] Kukačka, J., Golkov, V. 和 Cremers, D. (2017) 深度学习的正则化：一个分类学。arXiv
    预印本 arXiv:1710.10686.
- en: 'Kumar and Prabhaka [2011] Kumar, C. and Prabhaka, P. (2011) An Image Based
    Technique for Enhancement of Underwater Images. Inernational Journal of Machine
    Intelligence, 3, 217–224. URL: [http://arxiv.org/ftp/arxiv/papers/1212/1212.0291.pdf](http://arxiv.org/ftp/arxiv/papers/1212/1212.0291.pdf).'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kumar 和 Prabhaka [2011] Kumar, C. 和 Prabhaka, P. (2011) 一种基于图像的水下图像增强技术。International
    Journal of Machine Intelligence, 3, 217–224。网址: [http://arxiv.org/ftp/arxiv/papers/1212/1212.0291.pdf](http://arxiv.org/ftp/arxiv/papers/1212/1212.0291.pdf)。'
- en: Lammie et al. [2019] Lammie, C., Olsen, A., Carrick, T. and Rahimi Azghadi,
    M. (2019) Low-power and high-speed deep FPGA inference engines for weed classification
    at the edge. IEEE Access.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lammie 等人 [2019] Lammie, C., Olsen, A., Carrick, T. 和 Rahimi Azghadi, M. (2019)
    边缘设备上的低功耗高速深度 FPGA 推理引擎用于杂草分类。IEEE Access。
- en: 'Laradji et al. [2021] Laradji, I. H., Saleh, A., Rodriguez, P., Nowrouzezahrai,
    D., Azghadi, M. R. and Vazquez, D. (2021) Weakly supervised underwater fish segmentation
    using affinity LCFCN. Scientific reports, 11, 17379. URL: [https://www.nature.com/articles/s41598-021-96610-2http://www.ncbi.nlm.nih.gov/pubmed/34462458http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC8405733](https://www.nature.com/articles/s41598-021-96610-2http://www.ncbi.nlm.nih.gov/pubmed/34462458http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC8405733).'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Laradji 等人 [2021] Laradji, I. H., Saleh, A., Rodriguez, P., Nowrouzezahrai,
    D., Azghadi, M. R. 和 Vazquez, D. (2021) 基于亲和力 LCFCN 的弱监督水下鱼类分割。Scientific Reports,
    11, 17379。网址: [https://www.nature.com/articles/s41598-021-96610-2http://www.ncbi.nlm.nih.gov/pubmed/34462458http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC8405733](https://www.nature.com/articles/s41598-021-96610-2http://www.ncbi.nlm.nih.gov/pubmed/34462458http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC8405733)。'
- en: 'LeCun et al. [2015] LeCun, Y., Bengio, Y. and Hinton, G. (2015) Deep learning.
    Nature, 521, 436–444. URL: [http://www.nature.com/articles/nature14539](http://www.nature.com/articles/nature14539).'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'LeCun 等人 [2015] LeCun, Y., Bengio, Y. 和 Hinton, G. (2015) 深度学习。Nature, 521,
    436–444。网址: [http://www.nature.com/articles/nature14539](http://www.nature.com/articles/nature14539)。'
- en: LeCun et al. [1998] LeCun, Y., Bottou, L., Bengio, Y., Haffner, P. and others
    (1998) Gradient-based learning applied to document recognition. Proceedings of
    the IEEE, 86, 2278–2324.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun 等人 [1998] LeCun, Y., Bottou, L., Bengio, Y., Haffner, P. 和其他人 (1998) 基于梯度的学习应用于文档识别。Proceedings
    of the IEEE, 86, 2278–2324。
- en: Lee et al. [2003] Lee, D. J., Redd, S., Schoenberger, R., Xu, X. and Zhan, P.
    (2003) An Automated Fish Species Classification and Migration Monitoring System.
    In IECON Proceedings (Industrial Electronics Conference), vol. 2, 1080–1085.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee 等人 [2003] Lee, D. J., Redd, S., Schoenberger, R., Xu, X. 和 Zhan, P. (2003)
    自动化鱼类物种分类和迁徙监测系统。在 IECON 会议论文集 (工业电子学会议), 第 2 卷, 1080–1085。
- en: 'Li and Du [2021] Li, D. and Du, L. (2021) Recent advances of deep learning
    algorithms for aquacultural machine vision systems with emphasis on fish. Artificial
    Intelligence Review, 1–40. URL: [https://link.springer.com/article/10.1007/s10462-021-10102-3https://link.springer.com/10.1007/s10462-021-10102-3](https://link.springer.com/article/10.1007/s10462-021-10102-3https://link.springer.com/10.1007/s10462-021-10102-3).'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 和 Du [2021] Li, D. 和 Du, L. (2021) 深度学习算法在水产机器视觉系统中的近期进展，重点关注鱼类。Artificial
    Intelligence Review, 1–40。网址: [https://link.springer.com/article/10.1007/s10462-021-10102-3https://link.springer.com/10.1007/s10462-021-10102-3](https://link.springer.com/article/10.1007/s10462-021-10102-3https://link.springer.com/10.1007/s10462-021-10102-3)。'
- en: 'Lindeberg [2012] Lindeberg, T. (2012) Scale Invariant Feature Transform. Scholarpedia,
    7, 10491. URL: [http://www.scholarpedia.org/article/Scale_Invariant_Feature_Transform](http://www.scholarpedia.org/article/Scale_Invariant_Feature_Transform).'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lindeberg [2012] Lindeberg, T. (2012) 尺度不变特征变换。Scholarpedia, 7, 10491。网址: [http://www.scholarpedia.org/article/Scale_Invariant_Feature_Transform](http://www.scholarpedia.org/article/Scale_Invariant_Feature_Transform)。'
- en: 'Liu et al. [2020] Liu, C., Zhou, S., Wang, Y. G. and Hu, Z. (2020) Natural
    mortality estimation using tree-based ensemble learning models. ICES Journal of
    Marine Science, 77, 1414–1426. URL: [https://academic.oup.com/icesjms/article/77/4/1414/5854079](https://academic.oup.com/icesjms/article/77/4/1414/5854079).'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等人 [2020] Liu, C., Zhou, S., Wang, Y. G. 和 Hu, Z. (2020) 使用基于树的集成学习模型进行自然死亡率估计。ICES
    Journal of Marine Science, 77, 1414–1426。网址: [https://academic.oup.com/icesjms/article/77/4/1414/5854079](https://academic.oup.com/icesjms/article/77/4/1414/5854079)。'
- en: Lopez-Villa et al. [2015] Lopez-Villa, J. S., Insuasti-Ceballos, H. D., Molina-Giraldo,
    S., Alvarez-Meza, A. and Castellanos-Dominguez, G. (2015) A novel tool for ground
    truth data generation for video-based object classification. In 2015 20th Symposium
    on Signal Processing, Images and Computer Vision, STSIVA 2015 - Conference Proceedings.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lopez-Villa 等人 [2015] Lopez-Villa, J. S., Insuasti-Ceballos, H. D., Molina-Giraldo,
    S., Alvarez-Meza, A. 和 Castellanos-Dominguez, G. (2015) 一种用于视频对象分类的地面真实数据生成的新工具。在
    2015 年第 20 届信号处理、图像和计算机视觉研讨会，STSIVA 2015 - 会议论文集中。
- en: 'Loshchilov and Hutter [2017] Loshchilov, I. and Hutter, F. (2017) SGDR: Stochastic
    Gradient Descent with Warm Restarts. In International Conference on Learning Representations.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Loshchilov 和 Hutter [2017] Loshchilov, I. 和 Hutter, F. (2017) SGDR: 带有热重启的随机梯度下降。在国际学习表征会议上。'
- en: 'Lu et al. [2020] Lu, Y. C., Tung, C. and Kuo, Y. F. (2020) Identifying the
    species of harvested tuna and billfish using deep convolutional neural networks.
    ICES Journal of Marine Science, 77, 1318–1329. URL: [https://academic.oup.com/icesjms/article/77/4/1318/5509966](https://academic.oup.com/icesjms/article/77/4/1318/5509966).'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu 等人 [2020] Lu, Y. C., Tung, C. 和 Kuo, Y. F. (2020) 使用深度卷积神经网络识别捕获的金枪鱼和剑鱼的种类。ICES
    海洋科学期刊，77，1318–1329。网址：[https://academic.oup.com/icesjms/article/77/4/1318/5509966](https://academic.oup.com/icesjms/article/77/4/1318/5509966)。
- en: Mader et al. [2018] Mader, A. O., Lorenz, C., Bergtholdt, M., von Berg, J.,
    Schramm, H., Modersitzki, J. and Meyer, C. (2018) Detection and localization of
    spatially correlated point landmarks in medical images using an automatically
    learned conditional random field. Computer Vision and Image Understanding.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mader 等人 [2018] Mader, A. O., Lorenz, C., Bergtholdt, M., von Berg, J., Schramm,
    H., Modersitzki, J. 和 Meyer, C. (2018) 使用自动学习的条件随机场在医学图像中检测和定位空间相关的点标记。计算机视觉与图像理解。
- en: Mahmood et al. [2016] Mahmood, A., Bennamoun, M., An, S., Sohel, F., Boussaid,
    F., Hovey, R., Kendrick, G. and Fisher, R. B. (2016) Coral classification with
    hybrid feature representations. In Proceedings - International Conference on Image
    Processing, ICIP.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahmood 等人 [2016] Mahmood, A., Bennamoun, M., An, S., Sohel, F., Boussaid, F.,
    Hovey, R., Kendrick, G. 和 Fisher, R. B. (2016) 使用混合特征表示进行珊瑚分类。在《国际图像处理会议论文集》中，ICIP。
- en: Måløy et al. [2019] Måløy, H., Aamodt, A. and Misimi, E. (2019) A spatio-temporal
    recurrent network for salmon feeding action recognition from underwater videos
    in aquaculture. Computers and Electronics in Agriculture, 167, 105087.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Måløy 等人 [2019] Måløy, H., Aamodt, A. 和 Misimi, E. (2019) 用于水产养殖中通过水下视频识别鲑鱼进食动作的时空递归网络。《计算机与电子农业》，167，105087。
- en: Meng et al. [2018] Meng, L., Hirayama, T. and Oyanagi, S. (2018) Underwater-Drone
    with Panoramic Camera for Automatic Fish Recognition Based on Deep Learning. IEEE
    Access.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meng 等人 [2018] Meng, L., Hirayama, T. 和 Oyanagi, S. (2018) 基于深度学习的全景摄像头水下无人机自动鱼类识别。IEEE
    Access。
- en: 'Miikkulainen et al. [2019] Miikkulainen, R., Liang, J., Meyerson, E., Rawal,
    A., Fink, D., Francon, O., Raju, B., Shahrzad, H., Navruzyan, A., Duffy, N. and
    Hodjat, B. (2019) Evolving Deep Neural Networks. In Artificial Intelligence in
    the Age of Neural Networks and Brain Computing, 293–312\. Elsevier. URL: [https://linkinghub.elsevier.com/retrieve/pii/B9780128154809000153](https://linkinghub.elsevier.com/retrieve/pii/B9780128154809000153).'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miikkulainen 等人 [2019] Miikkulainen, R., Liang, J., Meyerson, E., Rawal, A.,
    Fink, D., Francon, O., Raju, B., Shahrzad, H., Navruzyan, A., Duffy, N. 和 Hodjat,
    B. (2019) 进化深度神经网络。在《神经网络与脑计算时代的人工智能》中，293–312。Elsevier。网址：[https://linkinghub.elsevier.com/retrieve/pii/B9780128154809000153](https://linkinghub.elsevier.com/retrieve/pii/B9780128154809000153)。
- en: Min et al. [2017] Min, S., Lee, B. and Yoon, S. (2017) Deep learning in bioinformatics.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Min 等人 [2017] Min, S., Lee, B. 和 Yoon, S. (2017) 生物信息学中的深度学习。
- en: Montavon et al. [2018] Montavon, G., Samek, W. and Müller, K. R. (2018) Methods
    for interpreting and understanding deep neural networks. Digital Signal Processing,
    73, 1–15.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Montavon 等人 [2018] Montavon, G., Samek, W. 和 Müller, K. R. (2018) 理解和解释深度神经网络的方法。数字信号处理，73，1–15。
- en: Mutneja and Singh [2021] Mutneja, V. and Singh, S. (2021) Haar-features training
    parameters analysis in boosting based machine learning for improved face detection.
    International Journal of Advanced Technology and Engineering Exploration, 8, 919–931.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mutneja 和 Singh [2021] Mutneja, V. 和 Singh, S. (2021) 基于提升的机器学习中的 Haar 特征训练参数分析，以改进人脸检测。《先进技术与工程探索国际期刊》，8，919–931。
- en: Nery et al. [2005] Nery, M. S., Machado, A. M., Campos, M. F., Pádua, F. L.,
    Carceroni, R. and Queiroz-Neto, J. P. (2005) Determining the appropriate feature
    set for fish classification tasks. In Brazilian Symposium of Computer Graphic
    and Image Processing, vol. 2005, 173–180.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nery 等人 [2005] Nery, M. S., Machado, A. M., Campos, M. F., Pádua, F. L., Carceroni,
    R. 和 Queiroz-Neto, J. P. (2005) 确定鱼类分类任务的合适特征集。在《巴西计算机图形与图像处理研讨会》中，第2005卷，173–180。
- en: Nilssen et al. [2017] Nilssen, I., Moller, T. and Nattkemper, T. W. (2017) Active
    Learning for the Classification of Species in Underwater Images from a Fixed Observatory.
    In Proceedings - 2017 IEEE International Conference on Computer Vision Workshops,
    ICCVW 2017, vol. 2018-Janua, 2891–2897.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nilssen 等 [2017] Nilssen, I., Moller, T. 和 Nattkemper, T. W. (2017) 针对固定观察点水下图像物种分类的主动学习。见
    Proceedings - 2017 IEEE 国际计算机视觉会议研讨会, ICCVW 2017, vol. 2018-Janua, 2891–2897.
- en: Ogunlana et al. [2015] Ogunlana, S. O., Olabode, O. and Oluwadare, S. A. A.
    (2015) Fish Classification Using Support Vector Machine. African Journal of Computing
    & ICT, 8, 75–82.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ogunlana 等 [2015] Ogunlana, S. O., Olabode, O. 和 Oluwadare, S. A. A. (2015)
    使用支持向量机进行鱼类分类。非洲计算与信息通信技术期刊, 8, 75–82.
- en: 'Olsen et al. [2019] Olsen, A., Konovalov, D. A., Philippa, B., Ridd, P., Wood,
    J. C., Johns, J., Banks, W., Girgenti, B., Kenny, O., Whinney, J., Calvert, B.,
    Azghadi, M. R. and White, R. D. (2019) DeepWeeds: A Multiclass Weed Species Image
    Dataset for Deep Learning. Scientific Reports, 9, 2058. URL: [https://www.nature.com/articles/s41598-018-38343-3http://www.nature.com/articles/s41598-018-38343-3](https://www.nature.com/articles/s41598-018-38343-3http://www.nature.com/articles/s41598-018-38343-3).'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Olsen 等 [2019] Olsen, A., Konovalov, D. A., Philippa, B., Ridd, P., Wood, J.
    C., Johns, J., Banks, W., Girgenti, B., Kenny, O., Whinney, J., Calvert, B., Azghadi,
    M. R. 和 White, R. D. (2019) DeepWeeds: 用于深度学习的多类杂草物种图像数据集。科学报告, 9, 2058. 网址: [https://www.nature.com/articles/s41598-018-38343-3http://www.nature.com/articles/s41598-018-38343-3](https://www.nature.com/articles/s41598-018-38343-3http://www.nature.com/articles/s41598-018-38343-3).'
- en: 'Oomes [2001] Oomes, A. H. J. (2001) Perception: Theory, Development and Organisation.
    Optometry and Vision Science, 78, 477. URL: [http://journals.lww.com/00006324-200107000-00005](http://journals.lww.com/00006324-200107000-00005).'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Oomes [2001] Oomes, A. H. J. (2001) 知觉：理论、发展与组织。视光学与视觉科学, 78, 477. 网址: [http://journals.lww.com/00006324-200107000-00005](http://journals.lww.com/00006324-200107000-00005).'
- en: 'Palmer et al. [2022] Palmer, M., Álvarez-Ellacuría, A., Moltó, V. and Catalán,
    I. A. (2022) Automatic, operational, high-resolution monitoring of fish length
    and catch numbers from landings using deep learning. Fisheries Research, 246,
    106166. URL: [https://linkinghub.elsevier.com/retrieve/pii/S0165783621002940](https://linkinghub.elsevier.com/retrieve/pii/S0165783621002940).'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Palmer 等 [2022] Palmer, M., Álvarez-Ellacuría, A., Moltó, V. 和 Catalán, I.
    A. (2022) 使用深度学习对鱼类长度和捕捞数量的自动、操作性、高分辨率监测。渔业研究, 246, 106166. 网址: [https://linkinghub.elsevier.com/retrieve/pii/S0165783621002940](https://linkinghub.elsevier.com/retrieve/pii/S0165783621002940).'
- en: Park et al. [2016] Park, J. K., Kwon, B. K., Park, J. H. and Kang, D. J. (2016)
    Machine learning-based imaging system for surface defect inspection. International
    Journal of Precision Engineering and Manufacturing - Green Technology.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等 [2016] Park, J. K., Kwon, B. K., Park, J. H. 和 Kang, D. J. (2016) 基于机器学习的表面缺陷检测成像系统。精密工程与制造
    - 绿色技术国际期刊.
- en: 'Pathak et al. [2018] Pathak, A. R., Pandey, M. and Rautaray, S. (2018) Application
    of Deep Learning for Object Detection. Procedia Computer Science, 132, 1706–1717.
    URL: [https://linkinghub.elsevier.com/retrieve/pii/S1877050918308767](https://linkinghub.elsevier.com/retrieve/pii/S1877050918308767).'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pathak 等 [2018] Pathak, A. R., Pandey, M. 和 Rautaray, S. (2018) 深度学习在目标检测中的应用。Procedia
    计算机科学, 132, 1706–1717. 网址: [https://linkinghub.elsevier.com/retrieve/pii/S1877050918308767](https://linkinghub.elsevier.com/retrieve/pii/S1877050918308767).'
- en: Peng et al. [2019] Peng, Y., Kondo, N., Fujiura, T., Suzuki, T., Wulandari,
    Yoshioka, H. and Itoyama, E. (2019) Classification of multiple cattle behavior
    patterns using a recurrent neural network with long short-term memory and inertial
    measurement units. Computers and Electronics in Agriculture, 157, 247–253.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng 等 [2019] Peng, Y., Kondo, N., Fujiura, T., Suzuki, T., Wulandari, Yoshioka,
    H. 和 Itoyama, E. (2019) 使用长短期记忆和惯性测量单元的递归神经网络分类多种牛行为模式。农业计算与电子学, 157, 247–253.
- en: 'Permaloff and Grafton [1992] Permaloff, A. and Grafton, C. (1992) Optical Character
    Recognition. PS: Political Science and Politics, 25, 523. URL: [https://www.jstor.org/stable/419444?origin=crossref](https://www.jstor.org/stable/419444?origin=crossref).'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Permaloff 和 Grafton [1992] Permaloff, A. 和 Grafton, C. (1992) 光学字符识别。PS: 政治科学与政治,
    25, 523. 网址: [https://www.jstor.org/stable/419444?origin=crossref](https://www.jstor.org/stable/419444?origin=crossref).'
- en: 'Piggott et al. [2020] Piggott, C. V., Depczynski, M., Gagliano, M. and Langlois,
    T. J. (2020) Remote video methods for studying juvenile fish populations in challenging
    environments. Journal of Experimental Marine Biology and Ecology, 532, 151454.
    URL: [https://linkinghub.elsevier.com/retrieve/pii/S0022098119304319](https://linkinghub.elsevier.com/retrieve/pii/S0022098119304319).'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Piggott et al. [2020] Piggott, C. V., Depczynski, M., Gagliano, M. 和 Langlois,
    T. J. (2020) 在挑战性环境中研究幼鱼种群的远程视频方法。《实验海洋生物学与生态学杂志》，532，151454。网址: [https://linkinghub.elsevier.com/retrieve/pii/S0022098119304319](https://linkinghub.elsevier.com/retrieve/pii/S0022098119304319)。'
- en: 'Pisner and Schnyer [2019] Pisner, D. A. and Schnyer, D. M. (2019) Support vector
    machine. In Machine Learning: Methods and Applications to Brain Disorders.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pisner and Schnyer [2019] Pisner, D. A. 和 Schnyer, D. M. (2019) 支持向量机。发表于《机器学习：方法及其在脑部疾病中的应用》。
- en: Pope et al. [2010] Pope, K. L., Lochmann, S. E. and Young, M. K. (2010) Methods
    for Assessing Fish Populations. Inland fisheries management in North America.
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pope et al. [2010] Pope, K. L., Lochmann, S. E. 和 Young, M. K. (2010) 鱼类种群评估方法。《北美内陆渔业管理》。
- en: Pornpanomchai et al. [2013] Pornpanomchai, C., Lurstwut, B., Leerasakultham,
    P. and Kitiyanan, W. (2013) Shape- and texture-based fish image recognition system.
    Kasetsart Journal - Natural Science, 47, 624–634.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pornpanomchai et al. [2013] Pornpanomchai, C., Lurstwut, B., Leerasakultham,
    P. 和 Kitiyanan, W. (2013) 基于形状和纹理的鱼类图像识别系统。《Kasetsart期刊 - 自然科学》，47，624–634。
- en: 'Proud et al. [2020] Proud, R., Mangeni-Sande, R., Kayanda, R. J., Cox, M. J.,
    Nyamweya, C., Ongore, C., Natugonza, V., Everson, I., Elison, M., Hobbs, L., Kashindye,
    B. B., Mlaponi, E. W., Taabu-Munyaho, A., Mwainge, V. M., Kagoya, E., Pegado,
    A., Nduwayesu, E. and Brierley, A. S. (2020) Applications of machine learning
    and artificial intelligence in marine science: all articles. ICES Journal of Marine
    Science, 77, 1267–1455. URL: [https://academic.oup.com/icesjms/article/77/4/1267/5873749](https://academic.oup.com/icesjms/article/77/4/1267/5873749).'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Proud et al. [2020] Proud, R., Mangeni-Sande, R., Kayanda, R. J., Cox, M. J.,
    Nyamweya, C., Ongore, C., Natugonza, V., Everson, I., Elison, M., Hobbs, L., Kashindye,
    B. B., Mlaponi, E. W., Taabu-Munyaho, A., Mwainge, V. M., Kagoya, E., Pegado,
    A., Nduwayesu, E. 和 Brierley, A. S. (2020) 机器学习和人工智能在海洋科学中的应用：所有文章。《ICES海洋科学杂志》，77，1267–1455。网址:
    [https://academic.oup.com/icesjms/article/77/4/1267/5873749](https://academic.oup.com/icesjms/article/77/4/1267/5873749)。'
- en: 'Qin et al. [2016] Qin, H., Li, X., Liang, J., Peng, Y. and Zhang, C. (2016)
    DeepFish: Accurate underwater live fish recognition with a deep architecture.
    Neurocomputing, 187, 49–58. URL: [https://linkinghub.elsevier.com/retrieve/pii/S0925231215017312](https://linkinghub.elsevier.com/retrieve/pii/S0925231215017312).'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qin et al. [2016] Qin, H., Li, X., Liang, J., Peng, Y. 和 Zhang, C. (2016) DeepFish：一种具有深度结构的准确水下活鱼识别方法。《神经计算》，187，49–58。网址:
    [https://linkinghub.elsevier.com/retrieve/pii/S0925231215017312](https://linkinghub.elsevier.com/retrieve/pii/S0925231215017312)。'
- en: Qiu et al. [2018] Qiu, C., Zhang, S., Wang, C., Yu, Z., Zheng, H. and Zheng,
    B. (2018) Improving transfer learning and squeeze- and-excitation networks for
    small-scale fine-grained fish image classification. IEEE Access, 6, 78503–78512.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qiu et al. [2018] Qiu, C., Zhang, S., Wang, C., Yu, Z., Zheng, H. 和 Zheng, B.
    (2018) 改进小规模细粒度鱼类图像分类的迁移学习和挤压激励网络。《IEEE Access》，6，78503–78512。
- en: Rasmussen and Morrissey [2008] Rasmussen, R. S. and Morrissey, M. T. (2008)
    Methods for the Commercial Fish and Seafood Species. Comprehensive reviews in
    food science and food safety.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rasmussen and Morrissey [2008] Rasmussen, R. S. 和 Morrissey, M. T. (2008) 商业鱼类和海鲜物种的方法。《食品科学与食品安全的综合评论》。
- en: 'Rathi et al. [2017] Rathi, D., Jain, S. and Indu, S. (2017) Underwater Fish
    Species Classification using Convolutional Neural Network and Deep Learning. 2017
    Ninth International Conference on Advances in Pattern Recognition (ICAPR). URL:
    [http://dx.doi.org/10.1109/icapr.2017.8593044](http://dx.doi.org/10.1109/icapr.2017.8593044).'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rathi et al. [2017] Rathi, D., Jain, S. 和 Indu, S. (2017) 使用卷积神经网络和深度学习的水下鱼类物种分类。2017年第九届模式识别国际会议（ICAPR）。网址:
    [http://dx.doi.org/10.1109/icapr.2017.8593044](http://dx.doi.org/10.1109/icapr.2017.8593044)。'
- en: 'Ronneberger et al. [2015] Ronneberger, O., Fischer, P. and Brox, T. (2015)
    U-net: Convolutional networks for biomedical image segmentation. In International
    Conference on Medical image computing and computer-assisted intervention, 234–241.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ronneberger et al. [2015] Ronneberger, O., Fischer, P. 和 Brox, T. (2015) U-net：用于生物医学图像分割的卷积网络。发表于国际医学图像计算与计算机辅助手术会议，234–241。
- en: 'Rova et al. [2007] Rova, A., Mori, G. and Dill, L. M. (2007) One fish, two
    fish, butterfish, trumpeter: Recognizing fish in underwater video. In Proceedings
    of IAPR Conference on Machine Vision Applications, MVA 2007, 404–407.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rova et al. [2007] Rova, A., Mori, G. 和 Dill, L. M. (2007) 一鱼、二鱼、黄油鱼、号角鱼：在水下视频中识别鱼类。发表于IAPR会议上的机器视觉应用，MVA
    2007，404–407。
- en: Russakovsky et al. [2015] Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh,
    S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A. C. and
    Fei-Fei, L. (2015) ImageNet Large Scale Visual Recognition Challenge. International
    Journal of Computer Vision (IJCV), 115.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russakovsky et al. [2015] Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh,
    S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A. C. 和
    Fei-Fei, L. (2015) ImageNet 大规模视觉识别挑战赛。International Journal of Computer Vision
    (IJCV), 115。
- en: 'Saleh et al. [2020] Saleh, A., Laradji, I. H., Konovalov, D. A., Bradley, M.,
    Vazquez, D. and Sheaves, M. (2020) A realistic fish-habitat dataset to evaluate
    algorithms for underwater visual analysis. Scientific Reports, 10, 14671. URL:
    [http://www.ncbi.nlm.nih.gov/pubmed/32887922http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC7473859https://www.nature.com/articles/s41598-020-71639-x](http://www.ncbi.nlm.nih.gov/pubmed/32887922http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC7473859https://www.nature.com/articles/s41598-020-71639-x).'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Saleh et al. [2020] Saleh, A., Laradji, I. H., Konovalov, D. A., Bradley, M.,
    Vazquez, D. 和 Sheaves, M. (2020) 用于评估水下视觉分析算法的现实鱼类栖息地数据集。Scientific Reports, 10,
    14671。URL: [http://www.ncbi.nlm.nih.gov/pubmed/32887922http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC7473859https://www.nature.com/articles/s41598-020-71639-x](http://www.ncbi.nlm.nih.gov/pubmed/32887922http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC7473859https://www.nature.com/articles/s41598-020-71639-x)。'
- en: 'Saleh et al. [2021] Saleh, A., Laradji, I. H., Lammie, C., Vazquez, D., Flavell,
    C. A. and Azghadi, M. R. (2021) A Deep Learning Localization Method for Measuring
    Abdominal Muscle Dimensions in Ultrasound Images. IEEE Journal of Biomedical and
    Health Informatics, 25, 3865–3873. URL: [https://ieeexplore.ieee.org/document/9444630/](https://ieeexplore.ieee.org/document/9444630/).'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Saleh et al. [2021] Saleh, A., Laradji, I. H., Lammie, C., Vazquez, D., Flavell,
    C. A. 和 Azghadi, M. R. (2021) 用于测量腹部肌肉尺寸的深度学习定位方法。IEEE Journal of Biomedical and
    Health Informatics, 25, 3865–3873。URL: [https://ieeexplore.ieee.org/document/9444630/](https://ieeexplore.ieee.org/document/9444630/)。'
- en: 'Salman et al. [2016] Salman, A., Jalal, A., Shafait, F., Mian, A., Shortis,
    M., Seager, J. and Harvey, E. (2016) Fish species classification in unconstrained
    underwater environments based on deep learning. Limnology and Oceanography: Methods,
    14, 570–585.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Salman et al. [2016] Salman, A., Jalal, A., Shafait, F., Mian, A., Shortis,
    M., Seager, J. 和 Harvey, E. (2016) 基于深度学习的无约束水下环境中的鱼类物种分类。Limnology and Oceanography:
    Methods, 14, 570–585。'
- en: Sarigül and Avci [2017] Sarigül, M. and Avci, M. (2017) Comparison of Different
    Deep Structures for Fish Classification. International Journal of Computer Theory
    and Engineering.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sarigül 和 Avci [2017] Sarigül, M. 和 Avci, M. (2017) 鱼类分类的不同深度结构比较。International
    Journal of Computer Theory and Engineering。
- en: 'Schmidhuber [2015] Schmidhuber, J. (2015) Deep learning in neural networks:
    An overview. Neural Networks, 61, 85–117. URL: [http://dx.doi.org/10.1016/j.neunet.2014.09.003](http://dx.doi.org/10.1016/j.neunet.2014.09.003).'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schmidhuber [2015] Schmidhuber, J. (2015) 神经网络中的深度学习：概述。Neural Networks, 61,
    85–117。URL: [http://dx.doi.org/10.1016/j.neunet.2014.09.003](http://dx.doi.org/10.1016/j.neunet.2014.09.003)。'
- en: 'Schneider and Zhuang [2020] Schneider, S. and Zhuang, A. (2020) Counting Fish
    and Dolphins in Sonar Images Using Deep Learning. arXiv preprint arXiv:2007.12808.
    URL: [http://arxiv.org/abs/2007.12808](http://arxiv.org/abs/2007.12808).'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schneider 和 Zhuang [2020] Schneider, S. 和 Zhuang, A. (2020) 使用深度学习在声纳图像中计数鱼类和海豚。arXiv
    预印本 arXiv:2007.12808。URL: [http://arxiv.org/abs/2007.12808](http://arxiv.org/abs/2007.12808)。'
- en: Shafait et al. [2016] Shafait, F., Mian, A., Shortis, M., Ghanem, B., Culverhouse,
    P. F., Edgington, D., Cline, D., Ravanbakhsh, M., Seager, J. and Harvey, E. S.
    (2016) Fish identification from videos captured in uncontrolled underwater environments.
    ICES Journal of Marine Science, 73, 2737–2746.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shafait et al. [2016] Shafait, F., Mian, A., Shortis, M., Ghanem, B., Culverhouse,
    P. F., Edgington, D., Cline, D., Ravanbakhsh, M., Seager, J. 和 Harvey, E. S. (2016)
    从非受控水下环境中捕获的视频中识别鱼类。ICES Journal of Marine Science, 73, 2737–2746。
- en: 'Shihavuddin et al. [2013] Shihavuddin, A., Gracias, N., Garcia, R., Gleason,
    A. and Gintert, B. (2013) Image-Based Coral Reef Classification and Thematic Mapping.
    Remote Sensing, 5, 1809–1841. URL: [http://www.mdpi.com/2072-4292/5/4/1809](http://www.mdpi.com/2072-4292/5/4/1809).'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shihavuddin et al. [2013] Shihavuddin, A., Gracias, N., Garcia, R., Gleason,
    A. 和 Gintert, B. (2013) 基于图像的珊瑚礁分类与专题制图。Remote Sensing, 5, 1809–1841。URL: [http://www.mdpi.com/2072-4292/5/4/1809](http://www.mdpi.com/2072-4292/5/4/1809)。'
- en: Shryock et al. [2014] Shryock, D. F., Defalco, L. A. and Esque, T. C. (2014)
    Life-history traits predict perennial species response to fire in a desert ecosystem.
    Ecology and Evolution, 4, 3046–3059.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shryock et al. [2014] Shryock, D. F., Defalco, L. A. 和 Esque, T. C. (2014) 生活史特征预测沙漠生态系统中多年生物种对火灾的反应。Ecology
    and Evolution, 4, 3046–3059。
- en: 'Siddiqui et al. [2018] Siddiqui, S. A., Salman, A., Malik, M. I., Shafait,
    F., Mian, A., Shortis, M. R. and Harvey, E. S. (2018) Automatic fish species classification
    in underwater videos: Exploiting pre-trained deep neural network models to compensate
    for limited labelled data. ICES Journal of Marine Science.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Siddiqui 等人 [2018] Siddiqui, S. A., Salman, A., Malik, M. I., Shafait, F., Mian,
    A., Shortis, M. R. 和 Harvey, E. S. (2018) 水下视频中的自动鱼类物种分类：利用预训练深度神经网络模型弥补有限标记数据的不足。ICES
    海洋科学杂志。
- en: Sonka et al. [2008] Sonka, M., Hlavac, V. and Boyle, R. (2008) Image Processing,
    Analysis, and Machine Vision. Thomson.
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sonka 等人 [2008] Sonka, M., Hlavac, V. 和 Boyle, R. (2008) 图像处理、分析与机器视觉。汤姆森出版社。
- en: 'Spampinato et al. [2010] Spampinato, C., Giordano, D., Di Salvo, R., Chen-Burger,
    Y.-H. J., Fisher, R. B. and Nadarajan, G. (2010) Automatic fish classification
    for underwater species behavior understanding. In Proc. 1st Int. Worksh. Anal.
    Retriev. Tracked Events Motion Imagery Streams, 45–50\. Firenze, Italy: ACM.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Spampinato 等人 [2010] Spampinato, C., Giordano, D., Di Salvo, R., Chen-Burger,
    Y.-H. J., Fisher, R. B. 和 Nadarajan, G. (2010) 自动鱼类分类用于水下物种行为理解。在第1届国际研讨会论文集中，分析检索跟踪事件运动图像流，45–50.
    意大利佛罗伦萨: ACM.'
- en: Su et al. [2020] Su, Y., Guo, L., Jin, Z. and Fu, X. (2020) A mobile-beacon
    based iterative localization mechanism in large-scale underwater acoustic sensor
    networks. IEEE Internet Things J.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Su 等人 [2020] Su, Y., Guo, L., Jin, Z. 和 Fu, X. (2020) 基于移动信标的大规模水下声学传感器网络中的迭代定位机制。IEEE互联网事物杂志。
- en: Sun et al. [2017] Sun, C., Shrivastava, A., Singh, S. and Gupta, A. (2017) Revisiting
    Unreasonable Effectiveness of Data in Deep Learning Era. In Proceedings of the
    IEEE International Conference on Computer Vision, vol. 2017-Octob, 843–852.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等人 [2017] Sun, C., Shrivastava, A., Singh, S. 和 Gupta, A. (2017) 重访深度学习时代数据的非凡有效性。在IEEE计算机视觉国际会议论文集中，卷2017年10月,
    843–852.
- en: 'Tabak et al. [2019] Tabak, M. A., Norouzzadeh, M. S., Wolfson, D. W., Sweeney,
    S. J., Vercauteren, K. C., Snow, N. P., Halseth, J. M., Di Salvo, P. A., Lewis,
    J. S., White, M. D., Teton, B., Beasley, J. C., Schlichting, P. E., Boughton,
    R. K., Wight, B., Newkirk, E. S., Ivan, J. S., Odell, E. A., Brook, R. K., Lukacs,
    P. M., Moeller, A. K., Mandeville, E. G., Clune, J. and Miller, R. S. (2019) Machine
    learning to classify animal species in camera trap images: Applications in ecology.
    Methods in Ecology and Evolution.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tabak 等人 [2019] Tabak, M. A., Norouzzadeh, M. S., Wolfson, D. W., Sweeney, S.
    J., Vercauteren, K. C., Snow, N. P., Halseth, J. M., Di Salvo, P. A., Lewis, J.
    S., White, M. D., Teton, B., Beasley, J. C., Schlichting, P. E., Boughton, R.
    K., Wight, B., Newkirk, E. S., Ivan, J. S., Odell, E. A., Brook, R. K., Lukacs,
    P. M., Moeller, A. K., Mandeville, E. G., Clune, J. 和 Miller, R. S. (2019) 机器学习用于分类相机陷阱图像中的动物物种：生态学中的应用。生态学与进化方法。
- en: 'Takada et al. [2014] Takada, Y., Koyama, K. and Usami, T. (2014) Position Estimation
    of Small Robotic Fish Based on Camera Information and Gyro Sensors. Robotics,
    3, 149–162. URL: [http://www.mdpi.com/2218-6581/3/2/149](http://www.mdpi.com/2218-6581/3/2/149).'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Takada 等人 [2014] Takada, Y., Koyama, K. 和 Usami, T. (2014) 基于相机信息和陀螺仪传感器的小型机器人鱼位置估计。机器人学,
    3, 149–162. URL: [http://www.mdpi.com/2218-6581/3/2/149](http://www.mdpi.com/2218-6581/3/2/149).'
- en: Tamou et al. [2018] Tamou, A. B., Benzinou, A., Nasreddine, K. and Ballihi,
    L. (2018) Underwater live fish recognition by deep learning. In Lecture Notes
    in Computer Science (including subseries Lecture Notes in Artificial Intelligence
    and Lecture Notes in Bioinformatics).
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tamou 等人 [2018] Tamou, A. B., Benzinou, A., Nasreddine, K. 和 Ballihi, L. (2018)
    通过深度学习进行水下活鱼识别。在计算机科学讲义（包括人工智能讲义和生物信息学讲义）中。
- en: 'Tarling et al. [2021] Tarling, P., Cantor, M., Clapés, A. and Escalera, S.
    (2021) DEEP LEARNING WITH SELF-SUPERVISION AND UNCERTAINTY REGULARIZATION TO COUNT
    FISH IN UNDERWATER IMAGES. Tech. rep., Other. URL: [http://www.echoview.com.](http://www.echoview.com.)'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tarling 等人 [2021] Tarling, P., Cantor, M., Clapés, A. 和 Escalera, S. (2021)
    使用自监督和不确定性正则化的深度学习来计数水下图像中的鱼类。技术报告，其他. URL: [http://www.echoview.com.](http://www.echoview.com.)'
- en: Thorstad et al. [2013] Thorstad, E. B., Rikardsen, A. H., Alp, A. and Okland,
    F. (2013) The Use of Electronic Tags in Fish Research - An Overview of Fish Telemetry
    Methods. Turkish Journal of Fisheries and Aquatic Sciences.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thorstad 等人 [2013] Thorstad, E. B., Rikardsen, A. H., Alp, A. 和 Okland, F. (2013)
    电子标签在鱼类研究中的应用 - 鱼类遥测方法概述。土耳其渔业与水产科学杂志。
- en: Trinh et al. [2012] Trinh, H., Fan, Q., Gabbur, P. and Pankanti, S. (2012) Hand
    tracking by binary quadratic programming and its application to retail activity
    recognition. In Proceedings of the IEEE Computer Society Conference on Computer
    Vision and Pattern Recognition.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trinh 等人 [2012] Trinh, H., Fan, Q., Gabbur, P. 和 Pankanti, S. (2012) 通过二次规划进行手部追踪及其在零售活动识别中的应用。在IEEE计算机视觉与模式识别会议论文集中。
- en: 'Van Allen et al. [2012] Van Allen, B. G., Dunham, A. E., Asquith, C. M. and
    Rudolf, V. H. (2012) Life history predicts risk of species decline in a stochastic
    world. Proceedings of the Royal Society B: Biological Sciences, 279, 2691–2697.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Van Allen 等 [2012] Van Allen, B. G., Dunham, A. E., Asquith, C. M. 和 Rudolf,
    V. H. (2012) 生命史预测在随机世界中物种衰退的风险。皇家学会B辑：生物科学，279，2691–2697。
- en: Varalakshmi and Julanta Leela Rachel [2019] Varalakshmi, P. and Julanta Leela Rachel,
    J. (2019) Recognition of Fish Categories Using Deep Learning Technique. In 2019
    Proceedings of the 3rd International Conference on Computing and Communications
    Technologies, ICCCT 2019.
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Varalakshmi 和 Julanta Leela Rachel [2019] Varalakshmi, P. 和 Julanta Leela Rachel,
    J. (2019) 使用深度学习技术识别鱼类类别。载于 2019 年第 3 届国际计算与通信技术会议论文集，ICCCT 2019。
- en: Villon et al. [2018] Villon, S., Mouillot, D., Chaumont, M., Darling, E. S.,
    Subsol, G., Claverie, T. and Villéger, S. (2018) A Deep learning method for accurate
    and fast identification of coral reef fishes in underwater images. Ecological
    Informatics.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Villon 等 [2018] Villon, S., Mouillot, D., Chaumont, M., Darling, E. S., Subsol,
    G., Claverie, T. 和 Villéger, S. (2018) 一种用于精确快速识别珊瑚礁鱼类的深度学习方法。生态信息学。
- en: Vincenzi et al. [2019] Vincenzi, S., Crivelli, A. J., Jeseňsek, D., Campbell,
    E. and Garza, J. C. (2019) Effects of species invasion on population dynamics,
    vital rates and life histories of the native species. Population Ecology, 61,
    25–34.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vincenzi 等 [2019] Vincenzi, S., Crivelli, A. J., Jeseňsek, D., Campbell, E.
    和 Garza, J. C. (2019) 物种入侵对本土物种的种群动态、重要生理指标和生命史的影响。种群生态学，61，25–34。
- en: 'Wang and Weiland [2017] Wang, B. and Weiland, J. D. (2017) Visual system. In
    Neuroprosthetics: Theory and Practice: Second Edition.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 和 Weiland [2017] Wang, B. 和 Weiland, J. D. (2017) 视觉系统。载于《神经假体学：理论与实践：第二版》。
- en: Wang et al. [2017a] Wang, G., Hwang, J. N., Williams, K., Wallace, F. and Rose,
    C. S. (2017a) Shrinking encoding with two-level codebook learning for fine-grained
    fish recognition. In Proceedings - 2nd Workshop on Computer Vision for Analysis
    of Underwater Imagery, CVAUI 2016 - In Conjunction with International Conference
    on Pattern Recognition, ICPR 2016, 31–36.
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 [2017a] Wang, G., Hwang, J. N., Williams, K., Wallace, F. 和 Rose, C.
    S. (2017a) 用于细粒度鱼类识别的双层代码本学习的压缩编码。载于《计算机视觉分析水下图像的第二届研讨会论文集》，CVAUI 2016 - 与国际模式识别大会
    ICPR 2016 联合举办，31–36。
- en: 'Wang et al. [2017b] Wang, S. H., Zhao, J., Liu, X., Qian, Z.-M., Liu, Y. and
    Chen, Y. Q. (2017b) 3D tracking swimming fish school with learned kinematic model
    using LSTM network. In 2017 IEEE International Conference on Acoustics, Speech
    and Signal Processing (ICASSP), 1068–1072\. IEEE. URL: [http://ieeexplore.ieee.org/document/7952320/](http://ieeexplore.ieee.org/document/7952320/).'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 [2017b] Wang, S. H., Zhao, J., Liu, X., Qian, Z.-M., Liu, Y. 和 Chen,
    Y. Q. (2017b) 使用 LSTM 网络的学习运动学模型对游动鱼群进行 3D 跟踪。载于 2017 IEEE 国际声学、语音与信号处理会议（ICASSP），1068–1072。IEEE。网址：[http://ieeexplore.ieee.org/document/7952320/](http://ieeexplore.ieee.org/document/7952320/)。
- en: 'Willi et al. [2019] Willi, M., Pitman, R. T., Cardoso, A. W., Locke, C., Swanson,
    A., Boyer, A., Veldthuis, M. and Fortson, L. (2019) Identifying animal species
    in camera trap images using deep learning and citizen science. Methods in Ecology
    and Evolution, 10, 80–91. URL: [https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13099](https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13099).'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Willi 等 [2019] Willi, M., Pitman, R. T., Cardoso, A. W., Locke, C., Swanson,
    A., Boyer, A., Veldthuis, M. 和 Fortson, L. (2019) 使用深度学习和公民科学在相机陷阱图像中识别动物物种。生态与进化方法，10，80–91。网址：[https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13099](https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13099)。
- en: 'Xu et al. [2021] Xu, J.-L., Hugelier, S., Zhu, H. and Gowen, A. A. (2021) Deep
    learning for classification of time series spectral images using combined multi-temporal
    and spectral features. Analytica Chimica Acta, 1143, 9–20. URL: [https://linkinghub.elsevier.com/retrieve/pii/S0003267020311429](https://linkinghub.elsevier.com/retrieve/pii/S0003267020311429).'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等 [2021] Xu, J.-L., Hugelier, S., Zhu, H. 和 Gowen, A. A. (2021) 使用结合多时态和光谱特征的深度学习进行时间序列光谱图像分类。分析化学学报，1143，9–20。网址：[https://linkinghub.elsevier.com/retrieve/pii/S0003267020311429](https://linkinghub.elsevier.com/retrieve/pii/S0003267020311429)。
- en: 'Xu et al. [2019] Xu, L., Bennamoun, M., An, S., Sohel, F. and Boussaid, F.
    (2019) Deep learning for marine species recognition. In Smart Innovation, Systems
    and Technologies, vol. 136, 129–145\. Springer Science and Business Media Deutschland
    GmbH. URL: [http://link.springer.com/10.1007/978-3-030-11479-4_7](http://link.springer.com/10.1007/978-3-030-11479-4_7).'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xu 等 [2019] Xu, L., Bennamoun, M., An, S., Sohel, F. 和 Boussaid, F. (2019)
    深度学习用于海洋物种识别。见《智能创新、系统与技术》，第 136 卷，129–145 页。Springer Science and Business Media
    Deutschland GmbH。网址: [http://link.springer.com/10.1007/978-3-030-11479-4_7](http://link.springer.com/10.1007/978-3-030-11479-4_7)。'
- en: 'Yang et al. [2020] Yang, X., Zhang, S., Liu, J., Gao, Q., Dong, S. and Zhou,
    C. (2020) Deep learning for smart fish farming: applications, opportunities and
    challenges.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等 [2020] Yang, X., Zhang, S., Liu, J., Gao, Q., Dong, S. 和 Zhou, C. (2020)
    深度学习在智能鱼类养殖中的应用、机会与挑战。
- en: 'Zarco-Perello and Enríquez [2019] Zarco-Perello, S. and Enríquez, S. (2019)
    Remote underwater video reveals higher fish diversity and abundance in seagrass
    meadows, and habitat differences in trophic interactions. Scientific reports,
    9, 6596. URL: [http://www.ncbi.nlm.nih.gov/pubmed/31036932http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6488625](http://www.ncbi.nlm.nih.gov/pubmed/31036932http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6488625).'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zarco-Perello 和 Enríquez [2019] Zarco-Perello, S. 和 Enríquez, S. (2019) 遥控水下视频揭示了海草床中鱼类的更高多样性和丰富度，以及营养相互作用中的栖息地差异。Scientific
    reports，第 9 卷，6596 页。网址: [http://www.ncbi.nlm.nih.gov/pubmed/31036932http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6488625](http://www.ncbi.nlm.nih.gov/pubmed/31036932http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6488625)。'
- en: 'Zhang et al. [2022] Zhang, W., Wu, C. and Bao, Z. (2022) DPANet: Dual Pooling-aggregated
    Attention Network for fish segmentation. IET Computer Vision, 16, 67–82. URL:
    [https://onlinelibrary.wiley.com/doi/10.1049/cvi2.12065](https://onlinelibrary.wiley.com/doi/10.1049/cvi2.12065).'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang 等 [2022] Zhang, W., Wu, C. 和 Bao, Z. (2022) DPANet: 用于鱼类分割的双池聚合注意力网络。IET
    计算机视觉，第 16 卷，67–82 页。网址: [https://onlinelibrary.wiley.com/doi/10.1049/cvi2.12065](https://onlinelibrary.wiley.com/doi/10.1049/cvi2.12065)。'
- en: 'Zheng et al. [2020] Zheng, H., Wang, R., Ji, W., Zong, M., Wong, W. K., Lai,
    Z. and Lv, H. (2020) Discriminative deep multi-task learning for facial expression
    recognition. Information Sciences, 533, 60–71. URL: [https://linkinghub.elsevier.com/retrieve/pii/S0020025520303601](https://linkinghub.elsevier.com/retrieve/pii/S0020025520303601).'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zheng 等 [2020] Zheng, H., Wang, R., Ji, W., Zong, M., Wong, W. K., Lai, Z.
    和 Lv, H. (2020) 用于面部表情识别的辨别性深度多任务学习。信息科学，第 533 卷，60–71 页。网址: [https://linkinghub.elsevier.com/retrieve/pii/S0020025520303601](https://linkinghub.elsevier.com/retrieve/pii/S0020025520303601)。'
- en: 'Zhuang et al. [2020] Zhuang, P., Wang, Y. and Qiao, Y. (2020) WildFish++: A
    Comprehensive Fish Benchmark for Multimedia Research. IEEE Transactions on Multimedia.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhuang 等 [2020] Zhuang, P., Wang, Y. 和 Qiao, Y. (2020) WildFish++: 一个用于多媒体研究的全面鱼类基准。IEEE
    多媒体学报。'
- en: 'Zion [2012] Zion, B. (2012) The use of computer vision technologies in aquaculture
    – A review. Computers and Electronics in Agriculture, 88, 125–132. URL: [https://linkinghub.elsevier.com/retrieve/pii/S0168169912001950](https://linkinghub.elsevier.com/retrieve/pii/S0168169912001950).'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zion [2012] Zion, B. (2012) 计算机视觉技术在水产养殖中的应用 – 综述。计算机与电子农业，第 88 卷，125–132 页。网址:
    [https://linkinghub.elsevier.com/retrieve/pii/S0168169912001950](https://linkinghub.elsevier.com/retrieve/pii/S0168169912001950)。'
- en: 'Zion et al. [2007] Zion, B., Alchanatis, V., Ostrovsky, V., Barki, A. and Karplus,
    I. (2007) Real-time underwater sorting of edible fish species. Computers and Electronics
    in Agriculture, 56, 34–45. URL: [https://linkinghub.elsevier.com/retrieve/pii/S0168169906001244](https://linkinghub.elsevier.com/retrieve/pii/S0168169906001244).'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zion 等 [2007] Zion, B., Alchanatis, V., Ostrovsky, V., Barki, A. 和 Karplus,
    I. (2007) 实时水下可食鱼类物种分拣。计算机与电子农业，第 56 卷，34–45 页。网址: [https://linkinghub.elsevier.com/retrieve/pii/S0168169906001244](https://linkinghub.elsevier.com/retrieve/pii/S0168169906001244)。'
- en: Zion et al. [2008] — (2008) Classification of guppies’ (Poecilia reticulata)
    gender by computer vision. Aquacultural Engineering, 38, 97–104.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zion 等 [2008] — (2008) 利用计算机视觉分类孔雀鱼（Poecilia reticulata）的性别。水产工程，第 38 卷，97–104
    页。
- en: Zurowietz and Nattkemper [2020] Zurowietz, M. and Nattkemper, T. W. (2020) Unsupervised
    Knowledge Transfer for Object Detection in Marine Environmental Monitoring and
    Exploration. IEEE Access, 8, 143558–143568.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zurowietz 和 Nattkemper [2020] Zurowietz, M. 和 Nattkemper, T. W. (2020) 用于海洋环境监测和探索的无监督知识迁移。IEEE
    Access，第 8 卷，143558–143568 页。
