- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:00:43'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:00:43
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2006.11391] Computer Vision with Deep Learning for Plant Phenotyping in Agriculture:
    A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2006.11391] 计算机视觉与深度学习在农业植物表型中的应用：调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2006.11391](https://ar5iv.labs.arxiv.org/html/2006.11391)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2006.11391](https://ar5iv.labs.arxiv.org/html/2006.11391)
- en: '¹¹institutetext:          ¹Indian Institute of Technology           ²The University
    of Tokyo'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ¹¹机构文本：          ¹印度理工学院           ²东京大学
- en: Hyderabad
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 海得拉巴
- en: 'Computer Vision with Deep Learning for Plant Phenotyping in Agriculture: A
    Survey'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉与深度学习在农业植物表型中的应用：调查
- en: Akshay L Chandra^(†1)    Sai Vikas Desai^(†1)    Wei Guo²
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Akshay L Chandra^(†1)    Sai Vikas Desai^(†1)    Wei Guo²
- en: Vineeth N Balasubramanian¹
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Vineeth N Balasubramanian¹
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: In light of growing challenges in agriculture with ever growing food demand
    across the world, efficient crop management techniques are necessary to increase
    crop yield. Precision agriculture techniques allow the stakeholders to make effective
    and customized crop management decisions based on data gathered from monitoring
    crop environments. Plant phenotyping techniques play a major role in accurate
    crop monitoring. Advancements in deep learning have made previously difficult
    phenotyping tasks possible. This survey aims to introduce the reader to the state
    of the art research in deep plant phenotyping.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于全球对食品需求不断增长，农业面临着越来越大的挑战，高效的作物管理技术对于提高作物产量至关重要。精准农业技术使利益相关者能够根据从作物环境监测中获得的数据做出有效且定制化的作物管理决策。植物表型技术在准确的作物监测中发挥着重要作用。深度学习的进步使以前难以完成的表型任务变得可能。本次调查旨在介绍深度植物表型领域的最新研究成果。
- en: ^†^† $\dagger$Equal Contribution
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ^†^† $\dagger$等贡献
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: Population growth, increasing incomes, and rapid urbanization in developing
    countries are expected to cause a drastic hike [[1](#bib.bib1)] in food demand.
    This projected rise in food demand poses several challenges to agriculture. Owing
    to a continuous decline in global cultivable land [[2](#bib.bib2)], increasing
    the productivity of the existing agricultural land is highly necessary. This need
    has led to the scientific community focusing their efforts [[3](#bib.bib3), [4](#bib.bib4),
    [5](#bib.bib5)] on developing efficient and sustainable ways to increase crop
    yield. To this end, precision agriculture techniques have attracted a lot of attention.
    Precision agriculture is a set of methods to monitor crops, gather data, and carry
    out informed crop management tasks such as applying the optimum amount of water,
    selecting suitable pesticides, and reducing environmental impact. These methods
    involve the usage of specialized devices such as sensors, UAVs, and static cameras
    to monitor the crops. Accurate crop monitoring goes a long way in assisting farmers
    in making the right choices to obtain the maximum yield. Plant phenotyping, a
    rapidly emerging research area, plays a significant role in understanding crop-related
    traits. Plant phenotyping is the science of characterizing and quantifying the
    physical and physiological traits of a plant. It provides a quantitative assessment
    of the plant’s properties and its behavior in various environmental conditions.
    Understanding these properties is crucial in performing effective crop management.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 人口增长、收入增加以及发展中国家的快速城市化预计将导致食品需求的急剧上升[[1](#bib.bib1)]。这一预期的食品需求增长给农业带来了若干挑战。由于全球可耕地面积持续减少[[2](#bib.bib2)]，提高现有农业用地的生产力变得非常必要。这一需求促使科学界将努力集中在开发高效且可持续的方式以提高作物产量上[[3](#bib.bib3),
    [4](#bib.bib4), [5](#bib.bib5)]。为此，精准农业技术吸引了大量关注。精准农业是一组用于监测作物、收集数据和执行知情作物管理任务的方法，例如施用最佳水量、选择合适的农药以及减少环境影响。这些方法涉及使用传感器、无人机和静态摄像头等专业设备来监测作物。准确的作物监测对于帮助农民做出正确的决策以获得最大产量至关重要。植物表型学作为一个快速发展的研究领域，在理解作物相关特征中发挥着重要作用。植物表型学是对植物的物理和生理特征进行描述和量化的科学。它提供了植物在各种环境条件下的属性及其行为的定量评估。理解这些属性对于有效进行作物管理至关重要。
- en: Research in plant phenotyping has grown rapidly thanks to the availability of
    cost-effective and easy to use digital imaging devices such as RGB, multispectral,
    and hyperspectral cameras, which have facilitated the collection of large amounts
    of data. This influx of data coupled with the usage of machine learning algorithms
    has fueled the development of various high throughput phenotyping tools [refs]
    for tasks such as weed detection, fruit/organ counting, disease detection and
    yield estimation. A machine learning pipeline typically consists of feature extraction
    followed by a classification/regression module for prediction. While machine learning
    techniques have helped build sophisticated phenotyping tools, they are known to
    lack robustness. They rely heavily on handcrafted feature extraction techniques
    and manual hyperparameter tuning methods. As a result, if feature extraction is
    not carefully done under a domain expert’s supervision, they tend to perform poorly
    in uncontrolled environments such as agricultural fields where factors such as
    lighting, weather, exposure, etc. often cannot be regulated. Hence, feature extraction
    from data has been one of the major bottlenecks in the development of efficient
    high throughput plant phenotyping systems.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 植物表型研究迅速增长，这得益于成本效益高且易于使用的数字成像设备的普及，如RGB、多光谱和高光谱相机，这些设备促进了大量数据的收集。这些数据的涌入加上机器学习算法的使用，推动了各种高通量表型工具的开发[refs]，用于杂草检测、果实/器官计数、疾病检测和产量估算等任务。一个机器学习管道通常包括特征提取，随后是分类/回归模块进行预测。尽管机器学习技术帮助构建了复杂的表型工具，但它们通常缺乏鲁棒性。它们严重依赖于手工特征提取技术和手动超参数调优方法。因此，如果特征提取没有在领域专家的监督下仔细进行，它们往往在无法控制的环境中表现不佳，例如农业领域，其中照明、天气、曝光等因素通常无法调节。因此，从数据中提取特征一直是开发高效高通量植物表型系统的主要瓶颈之一。
- en: 'Advancements in deep learning, a sub-field of machine learning which allows
    for automatic feature extraction and prediction on large scale data, has led to
    a surge in the development of visual plant phenotyping methods. Deep learning
    is particularly well-known for its effectiveness in handling vision-based tasks
    such as image classification, object detection, semantic segmentation, and scene
    understanding. Coincidentally, many of these tasks form the backbone for various
    plant phenotyping tasks such as disease detection, fruit detection, and yield
    estimation. Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Computer Vision with
    Deep Learning for Plant Phenotyping in Agriculture: A Survey") illustrates the
    difference between machine learning based plant phenotyping and deep learning
    based plant phenotyping. We believe that the expressive power and robustness of
    deep learning systems can be effectively leveraged by plant researchers to identify
    complex patterns from raw data and devise efficient precision agriculture methodologies.
    The purpose of this survey is to enable the readers to get a bird’s eye view of
    the advancements in the field of deep learning based plant phenotyping, understand
    the existing issues, and become familiar with some of the open problems which
    warrant further research.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的进步，作为机器学习的一个子领域，允许在大规模数据上进行自动特征提取和预测，导致了视觉植物表型方法的发展激增。深度学习特别以其在处理基于视觉的任务（如图像分类、目标检测、语义分割和场景理解）方面的有效性而闻名。巧合的是，这些任务中的许多形成了各种植物表型任务的基础，如疾病检测、果实检测和产量估算。图
    [1](#S1.F1 "图 1 ‣ 1 介绍 ‣ 使用深度学习进行植物表型的计算机视觉：调查") 说明了基于机器学习的植物表型与基于深度学习的植物表型之间的区别。我们相信深度学习系统的表达能力和鲁棒性可以被植物研究人员有效利用，从原始数据中识别复杂模式，并制定高效的精准农业方法。此调查的目的是让读者全面了解深度学习基于植物表型领域的进展，理解现有问题，并熟悉一些需要进一步研究的开放问题。
- en: '![Refer to caption](img/a009c3449459fe7eff47d8d3217a3452.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a009c3449459fe7eff47d8d3217a3452.png)'
- en: 'Figure 1: Difference between ML and DL based Plant Phenotyping.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：基于机器学习和深度学习的植物表型之间的区别。
- en: 2 Background
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景
- en: 2.1 Plant Phenotyping
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 植物表型
- en: 'Plant phenotyping is the science of quantifying the physical and physiological
    traits of a plant. Plant phenotyping mainly benefits two communities: farmers
    and plant breeders. By better understanding the traits of the crop, a farmer can
    optimize crop yield by making informed crop management decisions. Similarly, understanding
    the crop’s behavior is crucial for plant breeders to select the best possible
    crop variety for a given location and environment. In the past, plant phenotyping
    was a manual endeavor. The process of manually observing a small set of crop samples
    and reporting observations periodically was slow, labor intensive and inefficient.
    The low throughput nature of these methods has impeded the progress in plant breeding
    research. However, the advent of modern data acquisition methods with various
    sensors, cameras and UAVs (Unmanned Aerial Vehicles) coupled with advances in
    machine learning techniques have resulted in the development of high-throughput
    plant phenotyping methods to be effectively used for precision agriculture.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 植物表型学是量化植物的物理和生理特征的科学。植物表型学主要惠及两个群体：农民和植物育种者。通过更好地理解作物的特征，农民可以通过做出明智的作物管理决策来优化作物产量。同样，理解作物的行为对植物育种者选择最适合给定地点和环境的作物品种至关重要。在过去，植物表型学是一项手动工作。手动观察少量作物样本并定期报告观察结果的过程缓慢、劳动密集且效率低下。这些方法的低通量特性阻碍了植物育种研究的进展。然而，现代数据采集方法的出现以及各种传感器、摄像头和无人机（UAVs）的进步，再加上机器学习技术的发展，已经导致高通量植物表型方法的发展，这些方法能够有效地用于精准农业。
- en: 'Depending on the method of data collection, plant phenotyping techniques can
    be classified into ground based, aerial and satellite based methods. In ground
    based phenotyping, high precision sensors are embedded in handheld devices or
    mounted on movable vehicles to measure useful traits such as plant height, plant
    biomass, crop development stage, crop yield etc. Fig. [6](#S3.F6 "Figure 6 ‣ Crop
    Identification and Classification ‣ 3.1 Ground-Based Remote Sensing for Plant
    Phenotyping ‣ 3 Application of Deep Learning in Plant Phenotyping ‣ Computer Vision
    with Deep Learning for Plant Phenotyping in Agriculture: A Survey") contracts
    the discussed classifcations. Movable phenotyping vehicles like BoniRob [[6](#bib.bib6)]
    have been developed where RGB cameras, hyperspectral cameras, LIDAR sensors, GPS
    receivers and other sensors can be mounted. Aerial based methods typically involve
    the usage of Unmanned Aerial Vehicles (UAVs) for crop monitoring. The recent advancements
    in UAVs and high resolution cameras have allowed the researchers to obtain high
    quality crop images. Tasks such as weed mapping, crop yield estimation, plant
    disease detection and pesticide spraying have been effectively carried out by
    UAVs. Satellite based plant phenotyping involves remote sensing of agricultural
    plots from satellites such as Landsat-8 and WorldView-3\. Satellite based methods
    have been typically used for crop health monitoring over a large scale area such
    as a region/country. However, the cost of obtaining satellite images, the effect
    of clouds and the time gap between capturing and obtaining images inhibits its
    applicability for high throughput plant phenotyping in precision agriculture.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '根据数据收集的方法，植物表型技术可以分为地面基础、航空和卫星基础方法。在地面基础表型中，高精度传感器被嵌入到手持设备或安装在可移动的车辆上，以测量有用的特征，如植物高度、植物生物量、作物发育阶段、作物产量等。图[6](#S3.F6
    "Figure 6 ‣ Crop Identification and Classification ‣ 3.1 Ground-Based Remote Sensing
    for Plant Phenotyping ‣ 3 Application of Deep Learning in Plant Phenotyping ‣
    Computer Vision with Deep Learning for Plant Phenotyping in Agriculture: A Survey")总结了讨论的分类。可移动的表型车辆如BoniRob
    [[6](#bib.bib6)] 已经被开发，其中可以安装RGB摄像头、超光谱摄像头、LIDAR传感器、GPS接收器和其他传感器。航空基础方法通常涉及使用无人机（UAVs）进行作物监测。无人机和高分辨率摄像头的最新进展使研究人员能够获取高质量的作物图像。无人机已经有效地执行了除草图谱绘制、作物产量估计、植物疾病检测和农药喷洒等任务。卫星基础植物表型涉及从如Landsat-8和WorldView-3等卫星遥感农业地块。卫星基础方法通常用于大规模区域如地区/国家的作物健康监测。然而，获取卫星图像的成本、云层的影响以及拍摄和获取图像之间的时间差限制了其在精准农业中的高通量植物表型应用。'
- en: With a variety of data collection tools at our disposal, large amounts of image
    and sensor data have been made available for plant phenotyping research. The next
    section introduces deep learning, a set of methods which can effectively recognize
    useful patterns in huge datasets.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 借助各种数据收集工具，大量的图像和传感器数据已经被提供用于植物表型研究。下一部分介绍深度学习，一种可以有效识别大量数据集中有用模式的方法。
- en: 2.2 Deep Learning
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 深度学习
- en: 'Machine Learning (ML) is a subset of Artificial Intelligence (AI), that deals
    with an algorithmic approach of learning from observational data without being
    explicitly programmed. ML has unimaginably revolutionized several fields in the
    last few decades. Neural Networks (NN) [[7](#bib.bib7), [8](#bib.bib8), [9](#bib.bib9)]
    is a sub-field of ML and it was this sub-field that spawned Deep Learning (DL).
    Among the most prominent factors that contributed to the huge boost of deep learning
    are the appearance of large, high-quality, publicly available labelled datasets,
    along with the empowerment of parallel GPU computing, which enabled the transition
    from CPU-based to GPU-based training thus allowing for signifcant acceleration
    in deep models’ training. Since its redemption in 2006 [[10](#bib.bib10)], DL
    community has been creating ever more complex and intelligent algorithms, showing
    better than human performances in several intelligent tasks. The deep in deep
    learning comes from the deep architectures of learning or the hierarchical nature
    of its algorithms. DL algorithms stack several layers of non-linear information
    processing units between input and output layer, called Artificial Neurons (AN).
    The stacking of these ANs in a hierarchical fashion allows for exploitation of
    feature learning and pattern recognition through efficient learning algorithms.
    It is proven that NNs are universal approximator of any function[[9](#bib.bib9)],
    making DL task agnostic [[11](#bib.bib11)]. Fig. [2](#S2.F2 "Figure 2 ‣ 2.2 Deep
    Learning ‣ 2 Background ‣ Computer Vision with Deep Learning for Plant Phenotyping
    in Agriculture: A Survey") depicts the taxonomy of AI.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '机器学习（ML）是人工智能（AI）的一个子集，处理的是通过观察数据进行学习的算法方法，而不是通过明确编程来实现。机器学习在过去几十年里极大地革新了多个领域。神经网络（NN）[[7](#bib.bib7),
    [8](#bib.bib8), [9](#bib.bib9)] 是机器学习的一个子领域，正是这个子领域催生了深度学习（DL）。深度学习显著提升的主要因素之一是大量高质量、公开可用的标记数据集的出现，以及并行GPU计算的提升，这使得从基于CPU的训练转向基于GPU的训练，从而显著加速了深度模型的训练。自2006年复兴以来[[10](#bib.bib10)]，深度学习领域一直在创建越来越复杂和智能的算法，在多个智能任务中表现优于人类。深度学习中的“深度”源于学习的深层架构或其算法的层次性质。深度学习算法在输入层和输出层之间堆叠多个非线性信息处理单元，这些单元称为人工神经元（AN）。这些人工神经元以层次化的方式堆叠，允许通过有效的学习算法利用特征学习和模式识别。已经证明，神经网络是任何函数的通用近似器[[9](#bib.bib9)]，这使得深度学习任务具有任务不可知性[[11](#bib.bib11)]。图[2](#S2.F2
    "Figure 2 ‣ 2.2 Deep Learning ‣ 2 Background ‣ Computer Vision with Deep Learning
    for Plant Phenotyping in Agriculture: A Survey")展示了人工智能的分类。'
- en: '![Refer to caption](img/b7ff9634a99d51403ebe8f80f3704625.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b7ff9634a99d51403ebe8f80f3704625.png)'
- en: 'Figure 2: The taxonomy of AI [[12](#bib.bib12)]. AI: Artificial Intelligence;
    ML: Machine Learning; NN: Neural Networks; DL:Deep Learning; SNN: Spiking Neural
    Networks.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：人工智能的分类[[12](#bib.bib12)]。AI：人工智能；ML：机器学习；NN：神经网络；DL：深度学习；SNN：尖峰神经网络。
- en: 'Deep learning approaches may be categorized as follows: Supervised, semi-supervised
    or partially supervised, and unsupervised¹¹1Reinforcement Learning (RL) or Deep
    RL (DRL) is often treated as a semi-supervised or sometimes unsupervised approach..
    Supervised learning techniques use labeled data. In supervised DL, the environment
    includes sets of input and corresponding output pairs (often in large amounts),
    a criterion that evaluates model performance at all times called cost or loss
    function, an optimizing algorithm that minimizes the cost function with respect
    to the given data. Semi-supervised learning techniques use only partially labeled
    datasets (usually small amounts of label data, large amounts of unlabeled data).
    The popular Generative Adversarial Networks (GAN) [[13](#bib.bib13)] are semi-supervised
    learning techniques. Unsupervised learning systems function without the presence
    of labeled data. In this case, the system learns the internal representation or
    important features to discover unknown relationships or structure within the input
    data. Often clustering, dimensionality reduction, and generative techniques are
    considered as unsupervised learning approaches.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习方法可以分为以下几类：监督学习、半监督或部分监督学习以及无监督学习¹¹1 强化学习（RL）或深度 RL（DRL）通常被视为半监督或有时是无监督方法。监督学习技术使用标记数据。在监督深度学习中，环境包括输入和对应输出对（通常是大量的），一个随时评估模型性能的标准称为成本或损失函数，一个优化算法用于最小化成本函数。半监督学习技术仅使用部分标记数据集（通常是少量标记数据，大量未标记数据）。流行的生成对抗网络（GAN）[[13](#bib.bib13)]是半监督学习技术。无监督学习系统在没有标记数据的情况下工作。在这种情况下，系统学习内部表示或重要特征，以发现输入数据中的未知关系或结构。通常，聚类、降维和生成技术被视为无监督学习方法。
- en: 2.3 Deep Learning for Computer Vision
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 计算机视觉中的深度学习
- en: Convolutional Neural Networks
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: '![Refer to caption](img/bc9aa7c6bbebbd6219d4f084aa2171dd.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/bc9aa7c6bbebbd6219d4f084aa2171dd.png)'
- en: 'Figure 3: The structure of a CNN [[14](#bib.bib14)], consisting of convolutional,
    pooling, and fully-connected layers.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: CNN 的结构 [[14](#bib.bib14)]，由卷积层、池化层和全连接层组成。'
- en: 'Convolutional Neural Networks (CNN) is a subclass of neural networks that takes
    advantage of the spatial structure of the inputs. This network structure was first
    proposed by Fukushima in 1988 [[15](#bib.bib15)]. It was not widely used then,
    however, due to limits of computation hardware for training the network. In the
    1990s, LeCun et al. [[16](#bib.bib16)] applied a gradient-based learning algorithm
    to CNNs and obtained successful results for the handwritten digit classification
    problem. CNNs have been extremely successful in computer vision applications,
    such as face recognition, object detection, powering vision in robotics, and self-driving
    cars. CNN models have a standard structure consisting of alternating convolutional
    layers and pooling layers (often each pooling layer is placed after a convolutional
    layer). The last layers are a small number of fully-connected layers, and the
    final layer is a softmax classifier as shown in Fig. [3](#S2.F3 "Figure 3 ‣ Convolutional
    Neural Networks ‣ 2.3 Deep Learning for Computer Vision ‣ 2 Background ‣ Computer
    Vision with Deep Learning for Plant Phenotyping in Agriculture: A Survey"). Every
    layer of a CNN transforms the input volume to an output volume of neuron activation,
    eventually leading to the final fully connected layers, resulting in a mapping
    of the input data to a 1D feature vector. In a nutshell, CNN comprises three main
    types of neural layers, namely, (i) convolutional layers, (ii) pooling layers,
    and (iii) fully connected layers. Each type of layer plays a diferent role.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '卷积神经网络（CNN）是利用输入的空间结构的神经网络子类。这个网络结构最初由福岛于 1988 年提出 [[15](#bib.bib15)]。当时由于计算硬件训练网络的限制，未被广泛使用。在
    1990 年代，LeCun 等人 [[16](#bib.bib16)] 将基于梯度的学习算法应用于 CNN，并在手写数字分类问题上获得了成功的结果。CNN
    在计算机视觉应用中非常成功，如人脸识别、物体检测、机器人视觉和自动驾驶汽车。CNN 模型具有标准结构，包括交替的卷积层和池化层（通常每个池化层位于卷积层之后）。最后几层是少量的全连接层，最终层是一个
    softmax 分类器，如图 [3](#S2.F3 "Figure 3 ‣ Convolutional Neural Networks ‣ 2.3 Deep
    Learning for Computer Vision ‣ 2 Background ‣ Computer Vision with Deep Learning
    for Plant Phenotyping in Agriculture: A Survey") 所示。CNN 的每一层将输入体积转换为神经元激活的输出体积，最终导致最终的全连接层，从而将输入数据映射到
    1D 特征向量。简而言之，CNN 包括三种主要类型的神经层，即（i）卷积层，（ii）池化层，和（iii）全连接层。每种类型的层发挥不同的作用。'
- en: '![Refer to caption](img/f4cae84cb8254a276ae73b87e3565baf.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f4cae84cb8254a276ae73b87e3565baf.png)'
- en: 'Figure 4: In a fully connected layer (left), each unit is connected to all
    units of the previous layers. In a convolutional layer (right), each unit is connected
    to a constant number of units in a local region of the previous layer. Furthermore,
    in a convolutional layer, the units all share the weights for these connections,
    as indicated by the shared linetypes. Figure and description are taken from [[17](#bib.bib17)].'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：在完全连接层（左）中，每个单元与前一层的所有单元相连。在卷积层（右）中，每个单元仅与前一层的局部区域中的固定数量单元相连。此外，在卷积层中，这些连接的权重是共享的，如共享的线型所示。图示及描述摘自[[17](#bib.bib17)]。
- en: '(i) Convolution Layers. In the convolutional layers, a CNN convolves the whole
    image as well as the intermediate feature maps with different kernels, generating
    various feature maps. Exploiting the advantages of the convolution operation,
    several works have proposed it as a substitute for fully connected layers with
    a view to attaining faster learning times. Difference between a fully connected
    layer and a convolutional layer is shown in Fig. [4](#S2.F4 "Figure 4 ‣ Convolutional
    Neural Networks ‣ 2.3 Deep Learning for Computer Vision ‣ 2 Background ‣ Computer
    Vision with Deep Learning for Plant Phenotyping in Agriculture: A Survey").'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: (i) 卷积层。在卷积层中，CNN对整个图像以及中间特征图进行不同内核的卷积，生成各种特征图。利用卷积操作的优势，多个研究提出用卷积层替代完全连接层，以实现更快的学习时间。完全连接层和卷积层之间的区别见图[4](#S2.F4
    "图 4 ‣ 卷积神经网络 ‣ 2.3 计算机视觉的深度学习 ‣ 2 背景 ‣ 基于深度学习的植物表型计算机视觉：综述")。
- en: (ii) Pooling Layers. Pooling layers handle the reduction of the spatial dimensions
    of the input volume for the convolutional layers that immediately follow. The
    pooling layer does not affect the depth dimension of the volume. The operation
    performed by this layer is also called subsampling or downsampling, as the reduction
    of size leads to a simultaneous loss of information. However, such a loss is beneficial
    for the network because the network is forced to learn only meaningful feature
    representation. On top of that, the decrease in size leads to less computational
    overhead for the upcoming layers of the network, and also it works against overfitting.
    Average pooling and max pooling are the most commonly used strategies. In [[18](#bib.bib18)]
    a detailed theoretical analysis of max pooling and average pooling performances
    is given, whereas in [[19](#bib.bib19)] it was shown that max pooling can lead
    to faster convergence, select superior invariant features, and improve generalization.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: (ii) 池化层。池化层负责减少卷积层输入体积的空间维度，而卷积层紧接在池化层之后。池化层不会影响体积的深度维度。该层执行的操作也称为下采样或降采样，因为大小的减少会导致信息的同时丧失。然而，这种损失对网络是有益的，因为网络被迫只学习有意义的特征表示。此外，尺寸的减少会减少后续网络层的计算开销，并且有助于防止过拟合。平均池化和最大池化是最常用的策略。在[[18](#bib.bib18)]中对最大池化和平均池化的性能进行了详细的理论分析，而[[19](#bib.bib19)]中则表明最大池化可以导致更快的收敛，选择更优的不变特征，并提高泛化能力。
- en: (iii) Fully Connected Layers. Following several convolutional and pooling layers,
    the high-level reasoning in the neural network is performed via fully connected
    layers. Neurons in a fully connected layer have full connections to all activation
    in the previous layer, as their name implies. Their activation can hence be computed
    with a matrix multiplication followed by a bias offset. Fully connected layers
    eventually convert the 2D feature maps into a 1D feature vector. The learned vector
    representations either could be fed forward for classification or could be used
    as feature vectors for further processing.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: (iii) 完全连接层。在若干卷积层和池化层之后，神经网络中的高级推理是通过完全连接层进行的。完全连接层中的神经元与前一层的所有激活有完全连接，正如其名称所示。因此，它们的激活可以通过矩阵乘法加上偏置偏移来计算。完全连接层最终将2D特征图转换为1D特征向量。学习到的向量表示可以用于分类或作为进一步处理的特征向量。
- en: Object Detection and Segmentation
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 目标检测与分割
- en: 'Object detection and segmentation are two of the most important and challenging
    branches of computer vision, which have been widely applied in real-world applications,
    such as monitoring security, autonomous driving and so on, with the purpose of
    locating instances of semantic objects of a certain class. In a nutshell, object
    detection is the task of identifying locating objects (with bounding boxes) in
    images. While the task of segmentation is to classify each pixel of images with
    objects (dog, cat, airplane, etc.). We refer readers to [[20](#bib.bib20), [21](#bib.bib21)]
    for more information on these tasks. Fig. [5](#S2.F5 "Figure 5 ‣ Object Detection
    and Segmentation ‣ 2.3 Deep Learning for Computer Vision ‣ 2 Background ‣ Computer
    Vision with Deep Learning for Plant Phenotyping in Agriculture: A Survey") visually
    contrasts the difference between these tasks.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 目标检测和分割是计算机视觉中最重要和最具挑战性的两个分支，它们已广泛应用于现实世界的应用中，例如监控安全、自动驾驶等，目的是定位某一类别语义对象的实例。简而言之，目标检测是识别图像中的对象（带有边界框）的任务。而分割任务是将图像中的每个像素分类为对象（狗、猫、飞机等）。有关这些任务的更多信息，我们参考
    [[20](#bib.bib20), [21](#bib.bib21)]。图 [5](#S2.F5 "图 5 ‣ 目标检测与分割 ‣ 2.3 计算机视觉中的深度学习
    ‣ 2 背景 ‣ 农业中植物表型分析的深度学习计算机视觉：综述") 直观地对比了这些任务之间的差异。
- en: '![Refer to caption](img/f29fddebc707fb598025bbc650869e72.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f29fddebc707fb598025bbc650869e72.png)'
- en: 'Figure 5: Visual illustration of difference between tasks - Image Classification,
    Object Detection and Instance Segmentation. Example taken from MS-COCO Dataset
    [[22](#bib.bib22)].'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：图示显示任务之间的差异 - 图像分类、目标检测和实例分割。示例取自 MS-COCO 数据集 [[22](#bib.bib22)]。
- en: 3 Application of Deep Learning in Plant Phenotyping
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习在植物表型分析中的应用
- en: 3.1 Ground-Based Remote Sensing for Plant Phenotyping
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 基于地面的植物表型遥感
- en: Automation in agriculture and robotic precision agriculture activities demand
    a lot of information about the environment, the field, the condition and the phenotype
    of individual plants. An increase in availability of data allowed for successful
    usage of such robotic tools in real-world conditions. Taking advantage of the
    available data, combined with the availability of robots such as BoniRob [[6](#bib.bib6)]
    that navigate autonomously in fields, computer vision with deep learning has played
    a prominent role in realizing autonomous farming. Previously laborious jobs of
    actively tracking certain measurements of interest such as plant growth rate,
    plant stem position, biomass amount, leaf count, leaf area, inter crop spacing,
    crop plant count and others can now be done almost seamlessly.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 农业自动化和机器人精密农业活动需要大量关于环境、田地、植物条件和植物表型的信息。数据的增加使得这些机器人工具在实际条件下的成功应用成为可能。利用现有数据，加上如
    BoniRob [[6](#bib.bib6)] 等自主导航的机器人，深度学习中的计算机视觉在实现自主农业中发挥了重要作用。以前需要大量劳动的任务，如植物生长速度、植物茎位置、生物量、叶片数量、叶片面积、作物间距、作物植株数量等，现在几乎可以无缝完成。
- en: Crop Identification and Classification
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 作物识别与分类
- en: A crucial prerequisite for selective and plant-specific treatments is that farming
    robots need to be equipped with an effective plant identification and classification
    system providing the robot with the information where and when to trigger its
    actuators to perform the desired action in real-time. For example, weeds generally
    have no useful value in terms of food, nutrition or medicine yet they have accelerated
    growth and parasitically compete with actual crops for nutrients and space. Inefficient
    processes such as hand weeding has led to significant losses and increasing costs
    due to manual labour [[23](#bib.bib23)], which is why a lot of research is being
    done on crop vs weed classification and weed identification [[24](#bib.bib24),
    [25](#bib.bib25), [26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28), [29](#bib.bib29)]
    and plant seedlings classification [[30](#bib.bib30), [31](#bib.bib31)]. This
    is extremely useful in improving the efficiency of precision farming techniques
    on weed control by modulating herbicide spraying appropriately to the level of
    weeds infestation.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于选择性和植物特定的处理，一个关键的前提是农业机器人需要配备有效的植物识别和分类系统，为机器人提供何时何地触发其执行器以实时执行所需动作的信息。例如，杂草在食品、营养或药物方面通常没有实用价值，但它们的生长速度较快，并且寄生性地与实际作物竞争养分和空间。由于人工除草等低效过程导致了显著损失和因人工劳动而增加的成本
    [[23](#bib.bib23)]，因此大量的研究集中在作物与杂草分类和杂草识别 [[24](#bib.bib24), [25](#bib.bib25),
    [26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28), [29](#bib.bib29)] 以及植物幼苗分类
    [[30](#bib.bib30), [31](#bib.bib31)]。这对于通过适当调节除草剂喷洒以应对杂草侵染水平，从而提高精确农业技术在杂草控制中的效率是非常有用的。
- en: '![Refer to caption](img/c06780ce766521220b85f46bbc9ecc47.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c06780ce766521220b85f46bbc9ecc47.png)'
- en: 'Figure 6: Top row of (a) shows BoniRob [[6](#bib.bib6)] a ground-based remote
    sensing robot, (b) shows an unmanned aerial vehicle [[32](#bib.bib32)], (c) shows
    a satellite scanning large areas of land respectively. Bottom row across (a),
    (b), and (c) shows corresponding example images acquired. Satellite Image Credits:
    NASA.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：（a）的顶 row 显示了 BoniRob [[6](#bib.bib6)]，一个地面遥感机器人；（b）显示了一架无人机 [[32](#bib.bib32)]；（c）显示了一颗卫星扫描大面积土地的图像。底
    row 跨（a）、（b）和（c）显示了相应的示例图像。卫星图像来源：NASA。
- en: Crop Detection and Segmentation
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 作物检测与分割
- en: 'Crop detection in the wild is arguably the most crucial step in the pipeline
    of several farm management tasks such as visual crop categorization [[33](#bib.bib33)],
    real-time plant disease and pest recognition [[34](#bib.bib34)], picking and harvesting
    automatic robots [[35](#bib.bib35)], healthy and quality monitoring of crop growing
    [[36](#bib.bib36)] and yield estimation [[37](#bib.bib37)]. However, existing
    deep learning networks achieving state-of-the-art performance in other research
    fields are not suitable for agricultural tasks of crop management such as irrigation
    [[38](#bib.bib38)], picking [[39](#bib.bib39)], pesticide spraying [[40](#bib.bib40)],
    and fertilization [[41](#bib.bib41)]. The dominating cause is lack of diverse
    set of public benchmark datasets that are specifically designed for various agricultural
    missions. Some of the few rich datasets available are CropDeep [[42](#bib.bib42)]
    for detection, multi-modal datasets like Rosette plant or Arabidopsis datasets
    [[43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45)], Sorghum-Head [[37](#bib.bib37)],
    Wheat-Panicle [[46](#bib.bib46)], Crop/Weed segmentation [[24](#bib.bib24)], and
    Crop/Tassle segmentation [[47](#bib.bib47)]. Fig. [7](#S3.F7 "Figure 7 ‣ Crop
    Detection and Segmentation ‣ 3.1 Ground-Based Remote Sensing for Plant Phenotyping
    ‣ 3 Application of Deep Learning in Plant Phenotyping ‣ Computer Vision with Deep
    Learning for Plant Phenotyping in Agriculture: A Survey") contains some examples
    from the CropDeep [[42](#bib.bib42)] dataset. Fig. [8](#S3.F8 "Figure 8 ‣ Crop
    Detection and Segmentation ‣ 3.1 Ground-Based Remote Sensing for Plant Phenotyping
    ‣ 3 Application of Deep Learning in Plant Phenotyping ‣ Computer Vision with Deep
    Learning for Plant Phenotyping in Agriculture: A Survey") depicts multi-modal
    annotations provided in the Rosette Plant Phenotyping dataset [[43](#bib.bib43),
    [44](#bib.bib44)] i.e., annotations for detection, segmentation, leaf center along
    with otherwise rarely found meta data.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '在野外作物检测可以说是多个农场管理任务中的关键步骤，例如视觉作物分类[[33](#bib.bib33)]、实时植物病害和害虫识别[[34](#bib.bib34)]、自动化采摘和收割机器人[[35](#bib.bib35)]、作物生长的健康和质量监测[[36](#bib.bib36)]以及产量估算[[37](#bib.bib37)]。然而，目前在其他研究领域取得先进性能的深度学习网络并不适用于作物管理等农业任务，例如灌溉[[38](#bib.bib38)]、采摘[[39](#bib.bib39)]、喷洒农药[[40](#bib.bib40)]和施肥[[41](#bib.bib41)]。主要原因是缺乏专门为各种农业任务设计的公共基准数据集。现有的少量丰富数据集包括用于检测的CropDeep
    [[42](#bib.bib42)]、多模态数据集如Rosette植物或拟南芥数据集[[43](#bib.bib43), [44](#bib.bib44),
    [45](#bib.bib45)]、高粱头数据集[[37](#bib.bib37)]、小麦穗数据集[[46](#bib.bib46)]、作物/杂草分割数据集[[24](#bib.bib24)]和作物/穗分割数据集[[47](#bib.bib47)]。图[7](#S3.F7
    "Figure 7 ‣ Crop Detection and Segmentation ‣ 3.1 Ground-Based Remote Sensing
    for Plant Phenotyping ‣ 3 Application of Deep Learning in Plant Phenotyping ‣
    Computer Vision with Deep Learning for Plant Phenotyping in Agriculture: A Survey")展示了来自CropDeep
    [[42](#bib.bib42)]数据集的一些示例。图[8](#S3.F8 "Figure 8 ‣ Crop Detection and Segmentation
    ‣ 3.1 Ground-Based Remote Sensing for Plant Phenotyping ‣ 3 Application of Deep
    Learning in Plant Phenotyping ‣ Computer Vision with Deep Learning for Plant Phenotyping
    in Agriculture: A Survey")则展示了Rosette植物表型数据集[[43](#bib.bib43), [44](#bib.bib44)]中提供的多模态注释，即检测、分割、叶片中心以及其他少见的元数据。'
- en: '![Refer to caption](img/021c33b9857c0d8e77b81c37fc191e4a.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/021c33b9857c0d8e77b81c37fc191e4a.png)'
- en: 'Figure 7: Some annotation examples from CropDeep dataset [[42](#bib.bib42)].'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：CropDeep数据集[[42](#bib.bib42)]中的一些注释示例。
- en: Efficient yield estimation from images is also one of the key tasks for farmers
    and plant breeders to accurately quantify the overall throughput of their ecosystem.
    Recent efforts in panicle or spike detection [[48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50), [37](#bib.bib37)], leaf counting [[51](#bib.bib51)], fruit detection
    [[52](#bib.bib52)] as well as pixel-wise segmentation-based tasks such as panicle
    segmentation [[53](#bib.bib53), [54](#bib.bib54)] show very promising results
    in this direction.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 从图像中高效估算产量也是农民和植物育种者准确量化其生态系统整体产出的关键任务之一。近期在穗或 spike 检测[[48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50), [37](#bib.bib37)]、叶片计数[[51](#bib.bib51)]、果实检测[[52](#bib.bib52)]以及像素级分割任务如穗分割[[53](#bib.bib53),
    [54](#bib.bib54)]方面的努力显示出了非常有前景的结果。
- en: '![Refer to caption](img/8fd34e27ba1ca9bcb438d099a6fd9b52.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/8fd34e27ba1ca9bcb438d099a6fd9b52.png)'
- en: 'Figure 8: Visual illustration of all types of annotations available in [[43](#bib.bib43),
    [44](#bib.bib44)] dataset.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：展示[[43](#bib.bib43), [44](#bib.bib44)]数据集中所有类型注释的视觉示例。
- en: Crop Disease and Pest Recognition
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 作物病害和害虫识别
- en: Modern technologies have given human society the ability to produce enough food
    to meet the demand of more than 7 billion people. However, food security remains
    threatened by a number of factors including climate change [[55](#bib.bib55)],
    the decline in pollinators [[56](#bib.bib56)], plant diseases [[57](#bib.bib57)],
    and others. Plant diseases are not only a threat to food security at the global
    scale, but can also have disastrous consequences for smallholder farmers whose
    livelihoods depend on healthy crops. India loses 35% of the annual crop yield
    due to plant diseases [[58](#bib.bib58)]. In the developing world, more than 80
    percent of the agricultural production is generated by smallholder farmers [[59](#bib.bib59)],
    and reports of yield loss of more than 50% due to pests and diseases are frequent
    [[60](#bib.bib60)]. Furthermore, the largest fraction of hungry people (50%) live
    in smallholder farming households [[61](#bib.bib61)], making smallholder farmers
    a group that’s particularly vulnerable to pathogen-derived disruptions in food
    supply.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现代技术赋予了人类社会生产足够食物以满足超过70亿人口需求的能力。然而，食物安全仍受到许多因素的威胁，包括气候变化[[55](#bib.bib55)]、授粉者数量减少[[56](#bib.bib56)]、植物疾病[[57](#bib.bib57)]等。植物疾病不仅对全球范围的食物安全构成威胁，而且对依赖健康作物生计的小农户造成灾难性的后果。印度因植物疾病每年损失35%的作物产量[[58](#bib.bib58)]。在发展中国家，超过80%的农业生产由小农户提供[[59](#bib.bib59)]，而因病虫害造成50%以上产量损失的报告频繁出现[[60](#bib.bib60)]。此外，最多的饥饿人口（50%）生活在小农户家庭中[[61](#bib.bib61)]，使得小农户成为特别容易受到病原体干扰食品供应的群体。
- en: 'Owing to these factors, timely disease and pest recognition becomes a priority
    task for farmers. In addition to that, farmers do not have many options other
    than consulting other fellow farmers or seeking help from government funded helplines
    [[62](#bib.bib62)]. Availability of public datasets such as PlantVillage [[63](#bib.bib63)],
    PlantDoc [[58](#bib.bib58)] allowed for progress in the area of disease and pest
    detection. Recent research works in pest and insect detection [[64](#bib.bib64),
    [65](#bib.bib65), [66](#bib.bib66), [67](#bib.bib67), [68](#bib.bib68)], invasive
    species detection in marine aquaculture [[69](#bib.bib69)] and disease detection
    in plant leafs [[70](#bib.bib70), [71](#bib.bib71), [72](#bib.bib72), [73](#bib.bib73),
    [74](#bib.bib74)], Rice [[75](#bib.bib75), [76](#bib.bib76), [77](#bib.bib77)],
    Tomato [[34](#bib.bib34), [78](#bib.bib78), [79](#bib.bib79), [80](#bib.bib80)],
    Banana [[81](#bib.bib81)], Grape [[82](#bib.bib82)], Sugarcane [[83](#bib.bib83)],
    Eggplant [[84](#bib.bib84)], Cucumber [[85](#bib.bib85)], Soybean [[86](#bib.bib86)],
    Olive [[87](#bib.bib87)], Tea [[88](#bib.bib88)], Coffee [[89](#bib.bib89)] and
    other similar works take encouraging steps towards disease-free agriculture. Fig.
    [9](#S3.F9 "Figure 9 ‣ Crop Disease and Pest Recognition ‣ 3.1 Ground-Based Remote
    Sensing for Plant Phenotyping ‣ 3 Application of Deep Learning in Plant Phenotyping
    ‣ Computer Vision with Deep Learning for Plant Phenotyping in Agriculture: A Survey")
    depicts banana diseases and pest detection outputs from [[81](#bib.bib81)]. This
    work [[90](#bib.bib90)] reports solutions to extant limitations in plant disease
    detection.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '由于这些因素，及时识别疾病和虫害成为农民的优先任务。除此之外，农民没有太多选择，只能咨询其他农民或寻求政府资助的热线帮助[[62](#bib.bib62)]。像PlantVillage[[63](#bib.bib63)]、PlantDoc[[58](#bib.bib58)]这样的公共数据集的可用性推动了疾病和虫害检测领域的发展。最近的研究在虫害和昆虫检测[[64](#bib.bib64)、[65](#bib.bib65)、[66](#bib.bib66)、[67](#bib.bib67)、[68](#bib.bib68)]、海洋水产养殖中的入侵物种检测[[69](#bib.bib69)]以及植物叶片中的疾病检测[[70](#bib.bib70)、[71](#bib.bib71)、[72](#bib.bib72)、[73](#bib.bib73)、[74](#bib.bib74)]、水稻[[75](#bib.bib75)、[76](#bib.bib76)、[77](#bib.bib77)]、番茄[[34](#bib.bib34)、[78](#bib.bib78)、[79](#bib.bib79)、[80](#bib.bib80)]、香蕉[[81](#bib.bib81)]、葡萄[[82](#bib.bib82)]、甘蔗[[83](#bib.bib83)]、茄子[[84](#bib.bib84)]、黄瓜[[85](#bib.bib85)]、大豆[[86](#bib.bib86)]、橄榄[[87](#bib.bib87)]、茶[[88](#bib.bib88)]、咖啡[[89](#bib.bib89)]以及其他类似工作的研究，向无病害农业迈出了鼓舞人心的步伐。图[9](#S3.F9
    "Figure 9 ‣ Crop Disease and Pest Recognition ‣ 3.1 Ground-Based Remote Sensing
    for Plant Phenotyping ‣ 3 Application of Deep Learning in Plant Phenotyping ‣
    Computer Vision with Deep Learning for Plant Phenotyping in Agriculture: A Survey")展示了来自[[81](#bib.bib81)]的香蕉疾病和虫害检测结果。此工作[[90](#bib.bib90)]报告了植物疾病检测中现有局限性的解决方案。'
- en: '![Refer to caption](img/db4e55dbe745d207c6955fe6ba496f0e.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/db4e55dbe745d207c6955fe6ba496f0e.png)'
- en: 'Figure 9: Detected classes and expected output of the trained disease detection
    model. a Entire plant afected by banana bunchy top virus (BBTV), b leaves affected
    by black sigatoka (BS), c cut pseudostem of Xanthomonas wilt (BXW) afected plant
    showing yellow bacterial ooze, d fruit bunch afected by Xanthomonas wilt (BXW),
    e cut fruit afected by Xanthomonas wilt (BXW), f corm afected by banana corm weevil
    (BCW). Figure and description taken from [[81](#bib.bib81)].'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：经过训练的疾病检测模型的检测类别和预期输出。a 受香蕉簇顶病毒（BBTV）影响的整个植物，b 受黑斑病（BS）影响的叶子，c 受黄单胞菌枯萎病（BXW）影响的切割假茎显示黄色细菌渗出物，d
    受黄单胞菌枯萎病（BXW）影响的果串，e 受黄单胞菌枯萎病（BXW）影响的切割水果，f 受香蕉茎象甲（BCW）影响的块茎。图和描述摘自[[81](#bib.bib81)]。
- en: 3.2 Unmanned Aircraft Vehicles for Plant Phenotyping
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 无人机用于植物表型分析
- en: 'The past few decades have witnessed the great progress of unmanned aircraft
    vehicles (UAVs) in civilian fields, especially in photogrammetry and remote sensing.
    In contrast with the platforms of manned aircraft and satellite, the UAV platform
    holds many promising characteristics: flexibility, efficiency, high spatial/temporal
    resolution, low cost, easy operation, etc., which make it an effective complement
    to other remote-sensing platforms and a cost-effective means for remote sensing.
    We refer reader to literary works [[91](#bib.bib91), [92](#bib.bib92)] for the
    detailed reports of techniques and applications of UAVs in precision agriculture,
    remote sensing, search and rescue, construction and infrastructure inspection
    and discuss other market opportunities. UAVs can be utilized in precision agriculture
    (PA) for crop management and monitoring [[93](#bib.bib93), [94](#bib.bib94)],
    weed detection [[95](#bib.bib95)], irrigation scheduling [[96](#bib.bib96)], agricultural
    pattern detection [[97](#bib.bib97)], pesticide spraying [[93](#bib.bib93)], cattle
    detection [[98](#bib.bib98)], disease detection [[99](#bib.bib99), [100](#bib.bib100)],
    insect detection [[101](#bib.bib101)] and data collection from ground sensors
    (moisture, soil properties, etc.,) [[102](#bib.bib102)]. The deployment of UAVs
    in PA is a cost-effective and time saving technology which can help for improving
    crop yields, farms productivity and profitability in farming systems. Moreover,
    UAVs facilitate agricultural management, weed monitoring, and pest damage, thereby
    they help to meet these challenges quickly [[103](#bib.bib103)].'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 过去几十年见证了无人机（UAV）在民用领域的巨大进步，尤其是在摄影测量和遥感方面。与载人飞机和卫星平台相比，无人机平台具有许多有前景的特性：灵活性、高效性、高空间/时间分辨率、低成本、操作简便等，这些使其成为其他遥感平台的有效补充和成本效益高的遥感手段。我们建议读者参考文献[[91](#bib.bib91),
    [92](#bib.bib92)]以了解无人机在精准农业、遥感、搜救、建设和基础设施检查中的技术和应用的详细报告，并探讨其他市场机会。无人机可以用于精准农业（PA）的作物管理和监测[[93](#bib.bib93),
    [94](#bib.bib94)]、杂草检测[[95](#bib.bib95)]、灌溉调度[[96](#bib.bib96)]、农业模式检测[[97](#bib.bib97)]、农药喷洒[[93](#bib.bib93)]、牲畜检测[[98](#bib.bib98)]、疾病检测[[99](#bib.bib99),
    [100](#bib.bib100)]、昆虫检测[[101](#bib.bib101)]和地面传感器数据收集（湿度、土壤属性等）[[102](#bib.bib102)]。在精准农业中部署无人机是一种具有成本效益和节省时间的技术，有助于提高作物产量、农场生产力和农业系统的盈利能力。此外，无人机还促进了农业管理、杂草监测和病虫害防治，从而有助于快速应对这些挑战[[103](#bib.bib103)]。
- en: UAVs can also be utilized to monitor and quantify several factors of irrigation
    such as availability of soil water, crop water need (which represents the amount
    of water needed by the various crops to grow optimally), rainfall amount, efficiency
    of the irrigation system [[104](#bib.bib104)]. In this work [[105](#bib.bib105)],
    UAVs are currently being utilized to estimate the spatial distribution of surface
    soil moisture high-resolution multi-spectral imagery in combination with ground
    sampling. UAVs are also being used for thermal remote sensing to monitor the spatial
    and temporal patterns of crop diseases during various disease development phases
    which reduces crop losses for farmers. This work [[106](#bib.bib106)] detects
    early stage development of soil-borne fungus in UAV imagery. Soil texture can
    be an indicative of soil quality which in turn influences crop productivity. Hence,
    UAV thermal images are being utilized to quantify soil texture at a regional scale
    by measuring the differences in land surface temperature under a relatively homogeneous
    climatic condition [[107](#bib.bib107), [108](#bib.bib108)]. Accurate assessment
    of crop residue is crucial for proper implementation of conservation tillage practices
    since crop residues provide a protective layer on agricultural fields that shields
    soil from wind and water. In [[109](#bib.bib109)], the authors demonstrated that
    aerial thermal images can explain more than 95% of the variability in crop residue
    cover amount compared to 77% using visible and near IR images.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 无人机还可以用于监测和量化灌溉的几个因素，如土壤水分的可用性、作物水分需求（表示各种作物生长所需的水量）、降雨量、灌溉系统的效率 [[104](#bib.bib104)]。在这项工作
    [[105](#bib.bib105)] 中，无人机正被用于估计表层土壤湿度的空间分布，通过高分辨率多光谱影像结合地面采样。无人机还被用于热遥感，以监测作物病害在不同病害发展阶段的空间和时间模式，从而减少农民的作物损失。这项工作
    [[106](#bib.bib106)] 检测了无人机影像中土壤传染真菌的早期阶段发展。土壤质地可以作为土壤质量的指示，这反过来影响作物生产力。因此，无人机热图像被用来在区域尺度上量化土壤质地，通过测量在相对均匀的气候条件下土地表面温度的差异
    [[107](#bib.bib107), [108](#bib.bib108)]。准确评估作物残余对于正确实施保护性耕作实践至关重要，因为作物残余为农田提供了保护层，防止土壤受到风和水的侵蚀。在
    [[109](#bib.bib109)] 中，作者证明了与使用可见光和近红外图像的77%相比，航空热图像可以解释作物残余覆盖量的95%以上的变异性。
- en: Farmers must monitor crop maturity to determine the harvesting time of their
    crops. UAVs can be a practical solution to this problem [[110](#bib.bib110)].
    Farmers require accurate, early estimation of crop yield for a number of reasons,
    including crop insurance, planning of harvest and storage requirements, and cash
    flow budgeting. In [[111](#bib.bib111)], UAV images were utilized to estimate
    yield and total biomass of rice crop in Thailand. In [[112](#bib.bib112)], UAV
    images were also utilized to predict corn grain yields in the early to midseason
    crop growth stages in Germany.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 农民必须监测作物的成熟度以确定收获时间。无人机可以是解决这个问题的实用方案 [[110](#bib.bib110)]。农民需要准确的早期作物产量估计，原因包括作物保险、收获和储存需求的规划以及现金流预算。在
    [[111](#bib.bib111)] 中，无人机影像被用于估计泰国稻米作物的产量和总生物量。在 [[112](#bib.bib112)] 中，无人机影像也被用于预测德国早期到中期生长阶段的玉米粒产量。
- en: There have also been successful efforts that seamlessly combine aerial and ground
    based system for precision agriculture [[113](#bib.bib113)]. With relaxed flight
    regulations and drastic improvement in machine learning techniques, geo-referencing,
    mosaicing, and other related algorithms, UAVs can provide a great potential for
    soil and crop monitoring [[114](#bib.bib114)]. More precision agricultural researches
    are encouraged to design and implement special types of cameras and sensors on-board
    UAVs, which have the ability of remote crop monitoring and detection of soil and
    other agricultural characteristics in real time scenarios.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 也有成功的努力无缝结合了空中和地面系统以实现精确农业 [[113](#bib.bib113)]。随着飞行法规的放宽以及机器学习技术、地理参考、镶嵌和其他相关算法的显著改进，无人机在土壤和作物监测方面具有巨大潜力
    [[114](#bib.bib114)]。鼓励更多精确农业研究设计和实施专用类型的相机和传感器安装在无人机上，以便能够在实时场景中进行远程作物监测和土壤及其他农业特征的检测。
- en: 3.3 Satellites for Plant Phenotyping
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 卫星在植物表型研究中的应用
- en: The impact of climate change and its unforeseeable nature, has caused majority
    of the agricultural crops to be affected in terms of their production and maintenance.
    With more than seven billion mouths to feed greater demands are being put on agriculture
    than ever before, at the same time as land is being degraded by factors such as
    soil erosion, mineral exhaustion and drought. It becomes the utmost priority for
    governments to support farmers by providing crucial information about changing
    weather conditions, soil conditions and more. Currently, satellite imagery is
    making agriculture more efficient by reducing scouting efforts of farmers, by
    optimizing use of nitrogen based on variable rate of application, by optimizing
    water schedules, identifying field performance and benchmark fields, etc [[115](#bib.bib115)].
    India alone has 7 satellites specially designed for benefits of farmers [[116](#bib.bib116)].
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 气候变化及其不可预测性已经导致大多数农业作物在生产和维护方面受到影响。随着超过七十亿人口对粮食的需求增加，农业面临的压力比以往任何时候都要大，同时土地还受到土壤侵蚀、矿物耗竭和干旱等因素的退化。政府优先支持农民，提供有关天气变化、土壤条件等重要信息成为首要任务。目前，卫星影像通过减少农民的勘察工作、优化氮肥使用（根据施用的可变速率）、优化用水计划、识别田间表现和基准田等方式，使农业变得更加高效
    [[115](#bib.bib115)]。仅印度就有7颗特别设计用于农民利益的卫星 [[116](#bib.bib116)]。
- en: Satellites and their imagery are being applied to agriculture in several ways,
    initially as a means of estimating crop yields [[117](#bib.bib117)] and crop types
    [[118](#bib.bib118)], soil salinity, soil moisture, soil pH [[119](#bib.bib119),
    [120](#bib.bib120), [121](#bib.bib121)]. Optical and radar sensors can provide
    an accurate picture of the acreage being cultivated, while also differentiating
    between crop types and determining their health and maturity. Optical satellite
    sensors can detect visible and near-infrared wavelengths of light, reflected from
    agricultural land below. It is these wavelengths which combined, can be manipulated
    to help us understand the condition of the crops. This information helps to inform
    the market, and provide early warning of crop failure or famine.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 卫星及其影像在农业中有多种应用，最初用于估算作物产量 [[117](#bib.bib117)] 和作物类型 [[118](#bib.bib118)]、土壤盐度、土壤湿度、土壤pH
    [[119](#bib.bib119), [120](#bib.bib120), [121](#bib.bib121)]。光学和雷达传感器能够准确描绘耕种面积，同时区分作物类型，并确定其健康状况和成熟度。光学卫星传感器可以检测从农业土地反射的可见光和近红外波长。这些波长的结合可以被操作，以帮助我们了解作物的状况。这些信息有助于市场的了解，并提供作物失败或饥荒的早期预警。
- en: By extension, satellites are also used as a management tool through the practice
    of PA, where satellite images are used to characterise a farmer’s fields in detail,
    often used in combination with geographical information systems (GIS), to allow
    more intensive and efficient cultivation practices. For instance, different crops
    might be recommended for different fields while the farmer’s use of fertiliser
    is optimised in a more economic and environmentally-friendly fashion. Providing
    access to satellite imagery also becomes very important for building trust among
    the involved parties (farmers and government and private bodies involved). Web-based
    platforms such as Google Earth Engine, Planet.com, Earth Data Search by NASA,
    LandViewer by Earth Observing System, Geocento [[122](#bib.bib122)] and others
    [[123](#bib.bib123)] provide access to past and present (even daily) satellite
    imagery of your interest.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步说，卫星也被用作精细农业的管理工具，通过卫星图像详细描绘农田，通常与地理信息系统（GIS）结合使用，以实现更高效、更集中的耕作实践。例如，可能会建议不同的作物在不同的田地中种植，同时以更经济和环保的方式优化农民的肥料使用。提供卫星影像的访问也对建立农民、政府和参与的私人机构之间的信任非常重要。基于网络的平台，如Google
    Earth Engine、Planet.com、NASA的Earth Data Search、Earth Observing System的LandViewer、Geocento
    [[122](#bib.bib122)] 等，提供了你感兴趣的过去和现在（甚至是每日）的卫星影像。
- en: Agricultural monitoring is also increasingly being applied to forestry, both
    for forest management and as a way of characterising forests as carbon sinks to
    help minimise climate change – notably as part of the UN’s REDD programme [[124](#bib.bib124)].
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 农业监测也越来越多地应用于林业，不仅用于森林管理，还作为表征森林碳汇以帮助减少气候变化的一种方式——特别是在联合国的REDD计划中 [[124](#bib.bib124)]。
- en: 4 Plant Phenotyping with Limited Labeled Data
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 有限标记数据的植物表型分析
- en: While deep learning based plant phenotyping has shown great promise, requirement
    of large labeled datasets still remains to be the bottleneck. Phenotyping tasks
    are often specific to the environmental and genetic conditions, finding large
    datasets with such conditions is not always possible. This results in researchers
    needing to acquire their own dataset and label it, which is often a arduous and
    expensive affair. Moreover, small datasets often lead to models that overfit.
    Deep learning approaches optimized for working with limited labeled data would
    immensely help the plant phenotyping community, since this would encourage many
    more farmers, breeders, and researchers to employ reliable plant phenotyping techniques
    to optimize crop yield. To this end, we list out some of the recent efforts in
    the area of deep plant phenotyping with limited labeled data.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于深度学习的植物表型分析显示出巨大的潜力，但对大规模标注数据集的需求仍然是瓶颈。表型分析任务通常特定于环境和遗传条件，找到符合这些条件的大数据集并不总是可能。这导致研究人员需要获取自己的数据集并进行标注，这通常是一项繁重且昂贵的工作。此外，小数据集常常导致模型过拟合。针对有限标注数据的深度学习方法将极大地帮助植物表型分析社区，因为这将鼓励更多的农民、育种者和研究人员采用可靠的植物表型分析技术，以优化作物产量。为此，我们列出了一些在有限标注数据下进行深度植物表型分析的最新努力。
- en: Data Augmentation
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据增强
- en: 'The computer vision community has long been employing dataset augmentation
    techniques to grow the amount of data using artificial transformations. Artificially
    perturbing the original dataset with affine transformations (e.g., rotation, scale,
    translation) is considered a common practice now. However, this approach has some
    constraints: the augmented data only capture the variability of the available
    training set (e.g., if the dataset doesn’t include a unique colored fruit, the
    particular unique case will never be learnt). To overcome this, several data augmentation
    methods proposed take advantage of recent advancements in the image generation
    space. In this work [[125](#bib.bib125)], the authors use Generative Adversarial
    Network (GAN) [[126](#bib.bib126)] to generate Arabidopsis plant images (called
    ARIGAN) with unique desirable traits (over 7 leaves) that were originally less
    frequent in the dataset. Fig. [10](#S4.F10 "Figure 10 ‣ Data Augmentation ‣ 4
    Plant Phenotyping with Limited Labeled Data ‣ Computer Vision with Deep Learning
    for Plant Phenotyping in Agriculture: A Survey") (a) shows examples of images
    generated by ARIGAN. Other latest works [[127](#bib.bib127), [128](#bib.bib128)]
    use more advanced variants of GANs to generate realistic plant images with particularly
    favorable leaf segmentations of interest to boost leaf counting accuracy of the
    learning models. In [[129](#bib.bib129)], the authors proposed an unsupervised
    image translation technique to improve plant disease recognition performance.
    LeafGAN [[130](#bib.bib130)], an image-to-image translation model, generates leaf
    images with various plant diseases and boosts diagnostic performance by a great
    margin. Two sets of example images generated by LeafGAN are shown in Fig. [10](#S4.F10
    "Figure 10 ‣ Data Augmentation ‣ 4 Plant Phenotyping with Limited Labeled Data
    ‣ Computer Vision with Deep Learning for Plant Phenotyping in Agriculture: A Survey")
    (b). Other data enhancement techniques are also being employed by researchers
    to train plant disease diagnosis models on generated lesions [[131](#bib.bib131)].'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '计算机视觉领域一直在使用数据集增强技术，通过人工变换来增加数据量。使用仿射变换（例如旋转、缩放、平移）对原始数据集进行人工扰动现在被视为一种常见做法。然而，这种方法有一些限制：增强的数据仅捕捉到可用训练集的变异性（例如，如果数据集中不包含一种特有颜色的水果，那么这种特有情况将永远不会被学习）。为了解决这个问题，提出了几种数据增强方法，这些方法利用了图像生成领域的最新进展。在这项工作[[125](#bib.bib125)]中，作者使用生成对抗网络（GAN）[[126](#bib.bib126)]生成具有特定期望特征（例如超过7片叶子）的阿拉伯芥植物图像（称为ARIGAN），这些特征在数据集中原本较少见。图[10](#S4.F10
    "Figure 10 ‣ Data Augmentation ‣ 4 Plant Phenotyping with Limited Labeled Data
    ‣ Computer Vision with Deep Learning for Plant Phenotyping in Agriculture: A Survey")
    (a)展示了ARIGAN生成的图像示例。其他最新的工作[[127](#bib.bib127), [128](#bib.bib128)]使用更先进的GAN变体生成现实的植物图像，特别是具有有利的叶片分割，这有助于提高学习模型的叶片计数准确性。在[[129](#bib.bib129)]中，作者提出了一种无监督图像翻译技术，以提高植物疾病识别性能。LeafGAN
    [[130](#bib.bib130)]，一种图像到图像的翻译模型，生成各种植物疾病的叶片图像，并大幅提高了诊断性能。图[10](#S4.F10 "Figure
    10 ‣ Data Augmentation ‣ 4 Plant Phenotyping with Limited Labeled Data ‣ Computer
    Vision with Deep Learning for Plant Phenotyping in Agriculture: A Survey") (b)展示了LeafGAN生成的两组示例图像。其他数据增强技术也正被研究人员使用，以训练植物疾病诊断模型，针对生成的病变[[131](#bib.bib131)]。'
- en: The effort to provide finely annotated data has enabled great improvement of
    the state of the art on segmentation performance. Some researches have started
    working on effectively transferring the knowledge obtained from RGB images on
    annotated plants either to other species or other modalities of imaging. In this
    work [[132](#bib.bib132)], the authors successfully transfer the knowledge gained
    from annotated leaves of Arabidopsis thaliana in RGB to images of the same plant
    in chlorophyll fluorescence imaging.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 提供精细注释数据的努力已显著提高了分割性能的最新水平。一些研究已经开始致力于将从标注植物的RGB图像中获得的知识有效地转移到其他物种或其他成像模式上。在这项工作[[132](#bib.bib132)]中，作者成功地将从RGB图像中的拟南芥标注叶片获得的知识转移到同一植物的叶绿素荧光成像图像中。
- en: '![Refer to caption](img/1e5c11bc7a340f6688f914d02e643151.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/1e5c11bc7a340f6688f914d02e643151.png)'
- en: 'Figure 10: (a) shows Arabidopsis plant images generated by ARIGAN [[125](#bib.bib125)].
    Bottom-right numbers refer to the leaf count. (b) shows two sets of healthy leafs
    and their corresponding disease prone leaves generated by LeafGAN [[130](#bib.bib130)].'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '图 10: (a) 显示了ARIGAN生成的拟南芥植物图像[[125](#bib.bib125)]。右下角的数字表示叶片数量。 (b) 显示了由LeafGAN生成的两组健康叶片及其对应的易病叶片[[130](#bib.bib130)]。'
- en: Weakly Supervised Learning
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 弱监督学习
- en: Fruit/organ counting is a well explored task by the plant phenotyping community.
    However, many vision-based solutions we have currently require highly accurate
    instance and density labels of fruits and organs in diverse set of environments.
    The labeling procedures are often very burdensome and error prone and, in many
    agricultural scenarios, it may be impossible to acquire a sufficient number of
    labelled samples to achieve consistent performance that are robust to image noise
    or other forms of covariate shift. This is why using only weak labels can be crucial
    for cost-effective plant phenotyping.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 果实/器官计数是植物表型研究社区中一个研究较为深入的任务。然而，目前我们拥有的许多基于视觉的解决方案需要在各种环境中对果实和器官进行高度准确的实例和密度标注。这些标注过程通常非常繁琐且容易出错，在许多农业场景中，可能无法获得足够数量的标注样本以实现对图像噪声或其他形式的协变量变化具有鲁棒性的稳定性能。这就是为什么仅使用弱标注对于具有成本效益的植物表型研究至关重要的原因。
- en: Recently, a lot of attention has been placed on engineering weakly supervised
    learning frameworks for plant phenotyping. In [[48](#bib.bib48)], the authors
    created a weakly supervised framework for the sorghum head detection task where
    annotators label the data only until the model reaches a desired performance level.
    After that, model outputs are directly passed as data labels leading to a exponential
    reduction in annotation costs with minimal loss in model accuracy. In other work
    [[133](#bib.bib133)], the authors proposed a strategy which is able to learn to
    count fruits without requiring task-specific supervision labels, such as manually
    labelled object bounding boxes or total instance count. In [[134](#bib.bib134)],
    the authors use a trained CNN on defect classification data and use it’s activate
    maps to segment infected regions on potatoes. Segmentation task requires really
    rich labels (each pixel of the image is annotated) so this task effectively bypasses
    the labeling for segmentation altogether. On another note, rice heading date estimation
    greatly assists the breeders to understand the adaptability of the crop to various
    environmental and genetic conditions. Accurate estimation of heading date requires
    monitoring the increase in number of rice panicles in the crop. Detecting rice
    panicles from crop images usually requires training an object detection model
    such as Faster R-CNN or YOLO, which requires costly bounding box annotations.
    However, a recently proposed method [[49](#bib.bib49)] uses a sliding window based
    detector which requires training an image classifier, for which annotations are
    much easier to obtain.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，很多关注被放在了用于植物表型研究的弱监督学习框架上。在[[48](#bib.bib48)]中，作者创建了一个用于高粱穗检测任务的弱监督框架，其中标注者仅在模型达到所需性能水平之前标注数据。之后，模型输出直接作为数据标签，从而实现了注释成本的指数级降低，同时模型准确性损失最小。在其他工作[[133](#bib.bib133)]中，作者提出了一种无需任务特定监督标签（如手动标记的目标边界框或总实例计数）的水果计数学习策略。在[[134](#bib.bib134)]中，作者使用在缺陷分类数据上训练的CNN，并利用其激活图来分割土豆上的感染区域。分割任务需要非常详细的标签（图像的每个像素都需要标注），因此该任务实际上完全绕过了分割的标注。另一方面，水稻抽穗日期的准确估计大大帮助育种者了解作物对不同环境和遗传条件的适应能力。准确的抽穗日期估计需要监测稻穗数量的增加。从作物图像中检测稻穗通常需要训练目标检测模型，如Faster
    R-CNN或YOLO，这需要昂贵的边界框标注。然而，最近提出的方法[[49](#bib.bib49)]使用基于滑动窗口的检测器，只需训练图像分类器，标注更容易获取。
- en: '![Refer to caption](img/a39e8b38102cb4f63b456574c79ac06b.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a39e8b38102cb4f63b456574c79ac06b.png)'
- en: 'Figure 11: (a) Standard pool-based active learning framework (b) Proposed framework
    [[135](#bib.bib135)] which interleaves weak supervision in the active learning
    process. This novel framework includes an adaptive supervision module which allows
    switching to a stronger form of supervision as required when training the model.
    The oracle is the source of labels a.k.a annotator.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：（a）标准池化式主动学习框架（b）提出的框架[[135](#bib.bib135)]，在主动学习过程中交替使用弱监督。这一新颖的框架包含一个自适应监督模块，允许在训练模型时根据需要切换到更强的监督形式。oracle
    是标签来源，也就是标注者。
- en: Transfer Learning
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 迁移学习
- en: Transfer learning is a type of learning that enables using knowledge gained
    while solving one problem and applying it to a different but related problem i.e.,
    a model trained on one phenotyping task (say potato leaf classification) being
    able to assist another phenotyping (tomato leaf classification) task. Transfer
    learning is a very well explored area of machine learning. As part of the first
    steps of adopting existing transfer learning techniques for plant phenotyping,
    the authors of [[136](#bib.bib136)] use CNNs (AlexNet, GoogleNet and VGGNet) pretrained
    on ImageNet dataset [[137](#bib.bib137)] and fine tune on the plant dataset used
    in LifeCLEF [[138](#bib.bib138)] 2015 challenge. With the help of transfer learning,
    they were able to beat then existing state-of-the-art LifeCLEF performance by
    15% points. Similary in [[139](#bib.bib139)], the authors report better than human
    results in segmentation task with the help of transfer learning where they transfer
    learn a model trained on peanut root dataset for switchgrass root dataset (they
    also report results using ImageNet pretrained models). Leaf disease detection
    and treatment recommendation performance is also shown to be boosted with transfer
    learning [[140](#bib.bib140)]. In [[141](#bib.bib141)], the authors interestingly
    combined a State-of-the-Art weakly-supervised fruit counting model with an unsupervised
    style transfer method for fruit counting. They used Cycle-Generative Adversarial
    Network (C-GAN) to perform unsupervised domain adaptation from one fruit dataset
    to another and train it alongside with a Presence-Absence Classifier (PAC) that
    discriminates images containing fruits or not and ultimately achieved better performance
    than fully supervised models.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是一种学习类型，能够将解决一个问题时获得的知识应用到不同但相关的问题上，即一个在某种表型任务（如土豆叶分类）上训练的模型能够协助另一个表型（如番茄叶分类）任务。迁移学习是机器学习领域一个非常成熟的研究方向。在采用现有迁移学习技术进行植物表型分析的第一步中，[[136](#bib.bib136)]
    的作者使用了在 ImageNet 数据集 [[137](#bib.bib137)] 上预训练的 CNN（AlexNet、GoogleNet 和 VGGNet），并在
    LifeCLEF [[138](#bib.bib138)] 2015 挑战中使用的植物数据集上进行微调。在迁移学习的帮助下，他们能够将当时现有的 LifeCLEF
    最佳表现提高 15%。类似地，在 [[139](#bib.bib139)] 中，作者报告了在分割任务中迁移学习的帮助下取得比人类更好的结果，其中他们将训练于花生根数据集的模型迁移至
    switchgrass 根数据集（他们还报告了使用 ImageNet 预训练模型的结果）。叶病检测和治疗推荐的性能也在 [[140](#bib.bib140)]
    中显示了在迁移学习的帮助下得到了提升。在 [[141](#bib.bib141)] 中，作者有趣地将一种最先进的弱监督水果计数模型与一种无监督风格迁移方法相结合，用于水果计数。他们使用
    Cycle-Generative Adversarial Network（C-GAN）进行从一个水果数据集到另一个的无监督领域适应，并与一种存在-缺失分类器（PAC）一起训练，该分类器区分包含水果的图像与不包含水果的图像，最终取得了比完全监督模型更好的表现。
- en: '![Refer to caption](img/8923fe412134ea2ec3156e3e9c1ab2a5.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8923fe412134ea2ec3156e3e9c1ab2a5.png)'
- en: 'Figure 12: Proposed point supervision framework [[142](#bib.bib142)] into the
    pool-based active learning cycle. In this framework, strong supervision is queried
    for images only after deemed informative based on point supervision of those images.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '图 12: 提出的点监督框架 [[142](#bib.bib142)] 进入基于池的主动学习循环。在这个框架中，仅在根据图像的点监督被认为具有信息量后，才会查询强监督。'
- en: Active Learning
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 主动学习
- en: 'Active learning [[143](#bib.bib143)], an iterative training approach that curiously
    selects the best samples to train, has been shown to reduce labeled data requirement
    when training deep classification networks [[144](#bib.bib144), [145](#bib.bib145),
    [146](#bib.bib146)]. Research in the area of active learning for object detection
    [[147](#bib.bib147), [148](#bib.bib148), [149](#bib.bib149)] has been, arguably,
    limited. However, numerous plant phenotyping tasks such as detection and quantification
    of crop yield and fruit counting are directly dependent on object detection. Keeping
    this in mind, an active learning method has been proposed [[135](#bib.bib135)]
    for training deep object detection models where the model can selectively query
    either weak labels (pointing at the object) or strong labels (drawing a box around
    the object). By introducing a switching module for weak labels and strong labels,
    the authors were able to save 24% of annotation time while training a wheat head
    detection [[46](#bib.bib46)] model. Fig. [11](#S4.F11 "Figure 11 ‣ Weakly Supervised
    Learning ‣ 4 Plant Phenotyping with Limited Labeled Data ‣ Computer Vision with
    Deep Learning for Plant Phenotyping in Agriculture: A Survey") illustrates the
    difference between regular active learning cycle and proposed active learning
    cycle. This method demonstrates the applicability of active learning to plant
    phenotyping methods where obtaining labeled data is often difficult. Along the
    same lines, to alleviate the labeled data requirement for training object detection
    models for cereal crop detection, a weak supervision based active learning method
    [[142](#bib.bib142)] was proposed recently. In this active learning approach,
    the model constantly interacts with a human annotator by iteratively querying
    the labels for only the most informative images, as opposed to all images in a
    dataset. Fig. [12](#S4.F12 "Figure 12 ‣ Transfer Learning ‣ 4 Plant Phenotyping
    with Limited Labeled Data ‣ Computer Vision with Deep Learning for Plant Phenotyping
    in Agriculture: A Survey") visually illustrates the proposed framework. The active
    query method is specifically designed for cereal crops which usually tend to have
    panicles with low variance in appearance. This training method has been shown
    to reduce over 50% of annotation costs on sorghum head and wheat spike detection
    datasets. We expect to see more research works using active learning for limited
    labeled data based plant phenotyping in the near future.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**主动学习**[[143](#bib.bib143)]是一种迭代训练方法，通过有针对性地选择最佳样本进行训练，已被证明可以减少训练深度分类网络时对标注数据的需求[[144](#bib.bib144),
    [145](#bib.bib145), [146](#bib.bib146)]。在物体检测领域的主动学习研究[[147](#bib.bib147), [148](#bib.bib148),
    [149](#bib.bib149)]可以说是有限的。然而，许多植物表型分析任务，如作物产量的检测与量化以及果实计数，都直接依赖于物体检测。考虑到这一点，已有研究提出了一种**主动学习**方法[[135](#bib.bib135)]，用于训练深度物体检测模型，其中模型可以选择性地查询弱标注（指向物体）或强标注（围绕物体绘制框）。通过引入一个用于弱标注和强标注的切换模块，作者在训练小麦穗检测[[46](#bib.bib46)]模型时节省了24%的标注时间。图[11](#S4.F11
    "Figure 11 ‣ Weakly Supervised Learning ‣ 4 Plant Phenotyping with Limited Labeled
    Data ‣ Computer Vision with Deep Learning for Plant Phenotyping in Agriculture:
    A Survey")展示了常规主动学习周期和提议的主动学习周期之间的区别。这种方法展示了主动学习在植物表型分析中的适用性，因为获取标注数据往往非常困难。同样，为了减轻用于训练作物检测模型的标注数据需求，最近提出了一种基于弱监督的主动学习方法[[142](#bib.bib142)]。在这种主动学习方法中，模型通过迭代查询仅最具信息量的图像的标签，而不是数据集中所有图像的标签，从而不断与人工标注者互动。图[12](#S4.F12
    "Figure 12 ‣ Transfer Learning ‣ 4 Plant Phenotyping with Limited Labeled Data
    ‣ Computer Vision with Deep Learning for Plant Phenotyping in Agriculture: A Survey")直观展示了所提框架。这种主动查询方法专门为谷物作物设计，这些作物通常具有外观变化较小的穗部。这种训练方法已被证明可以减少在高粱穗和小麦穗检测数据集上的标注成本超过50%。我们期待在不久的将来看到更多使用主动学习来处理有限标注数据的植物表型分析研究。'
- en: 5 Challenges and Open Problems
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 个挑战和待解决的问题
- en: In this section, we describe some of the challenges present in plant phenotyping
    methods which warrant further research.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们描述了植物表型分析方法中存在的一些挑战，这些挑战需要进一步研究。
- en: The Training Data Bottleneck
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练数据瓶颈
- en: Modern phenotyping methods rely on deep learning which is notorious for requiring
    large amounts of labeled data. While some progress has been made in developing
    data efficient models for phenotyping, reducing the labeling efforts for training
    efficient phenotyping tools is still an open problem. We believe that effectively
    adapting techniques from deep learning such as unsupervised, self supervised,
    weakly supervised, active and semi-supervised learning will greatly benefit the
    phenotyping community in observing plant traits with small datasets.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现代表型方法依赖于深度学习，深度学习以需要大量标注数据而闻名。虽然在开发数据高效的表型模型方面取得了一些进展，但减少训练高效表型工具的标注工作仍然是一个开放问题。我们相信，有效地适应深度学习技术，如无监督、自监督、弱监督、主动学习和半监督学习，将极大地惠及表型社区，使其能够在小数据集下观察植物特征。
- en: Explainability
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可解释性
- en: Deep neural networks are generally considered as black boxes which produce predictions
    without sufficient justification. This makes debugging a neural network difficult
    i.e., it can be tough to understand what caused a wrong prediction. Crop management
    decisions based on incorrect phenotyping results can cause financial losses. Hence,
    developing explainable models for plant phenotyping is one of the open problems
    in this field. Obtaining the reasons behind a given set of plant traits using
    explainable models has the potential to achieve breakthroughs in our understanding
    of plant behavior in various genetic and environmental conditions.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络通常被认为是黑箱模型，它们在没有足够理由的情况下给出预测。这使得神经网络的调试变得困难，即很难理解错误预测的原因。基于不准确表型结果的作物管理决策可能会导致经济损失。因此，开发可解释的植物表型模型是该领域的一个开放问题。利用可解释模型获取特定植物特征背后的原因有可能在理解植物在不同遗传和环境条件下的行为方面取得突破。
- en: Data collection
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集
- en: Vision based plant phenotyping suffers from challenges such as occlusion, inaccuracies
    in 3D reconstruction of crops and bad lighting conditions caused by the changing
    weather. It is therefore necessary to develop phenotyping tools which are robust
    to visual variations.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 基于视觉的植物表型学面临诸如遮挡、作物3D重建不准确和天气变化造成的光照条件差等挑战。因此，开发对视觉变化具有鲁棒性的表型工具是必要的。
- en: 6 Conclusions
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: High throughput plant phenotyping methods have shown great promise in efficiently
    monitoring crops for plant breeding and agricultural crop management. Research
    in deep learning has accelerated the progress in plant phenotyping research which
    resulted in the development of various image analysis tools to observe plant traits.
    However, wide applicability of high throughput phenotyping tools is limited by
    some issues such as 1) dependence of deep networks on large datasets, which are
    difficult to curate, 2) large variations of field environment which cannot always
    be captured, and 3) capital and maintenance which can be prohibitively expensive
    to be widely used in developing countries. With many open problems in plant phenotyping
    warranting further studies, it is indeed a great time to study plant phenotyping
    and achieve rapid progress by utilizing the advances in deep learning.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 高通量植物表型方法在高效监测作物以进行植物育种和农业作物管理方面显示了巨大的潜力。深度学习的研究加速了植物表型研究的进展，导致了各种图像分析工具的开发，以观察植物特征。然而，高通量表型工具的广泛应用受限于一些问题，如：1)
    深度网络对大量数据集的依赖，这些数据集难以策划；2) 田间环境的巨大变化无法始终捕捉；3) 资本和维护费用在发展中国家可能过于昂贵。鉴于植物表型学中许多开放问题需要进一步研究，现在确实是利用深度学习进步来研究植物表型并取得快速进展的最佳时机。
- en: References
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Hunter, M., Smith, R., Schipanski, M., Atwood, L., Mortensen, D.: Agriculture
    in 2050: Recalibrating targets for sustainable intensification. BioScience 67
    (02 2017)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] 汉特，史密斯，施皮根斯基，阿特伍德，莫滕森：2050年的农业：重新校准可持续强化的目标。生物科学 67 (02 2017)'
- en: '[2] Wu, X., Guo, J., Han, M., Chen, G.: An overview of arable land use for
    the world economy: From source to sink via the global supply chain. Land Use Policy
    76 (2018) 201 – 214'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] 吴晓光，郭建平，韩梅，陈光辉：全球经济耕地利用概述：通过全球供应链从源头到终点。土地利用政策 76 (2018) 201 – 214'
- en: '[3] Gago, J., Douthe, C., Coopman, R., Gallego, P., Ribas-Carbo, M., Flexas,
    J., Escalona, J., Medrano, H.: Uavs challenge to assess water stress for sustainable
    agriculture. Agricultural Water Management 153 (2015) 9 – 19'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] 加戈，杜特，库普曼，加列戈，里巴斯-卡博，弗莱克萨斯，埃斯卡隆，梅德拉诺：无人机在评估水分胁迫以实现可持续农业中的挑战。农业水管理 153 (2015)
    9 – 19'
- en: '[4] Aubert, B.A., Schroeder, A., Grimaudo, J.: It as enabler of sustainable
    farming: An empirical analysis of farmers’ adoption decision of precision agriculture
    technology. Decision Support Systems 54(1) (2012) 510 – 520'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Aubert, B.A., Schroeder, A., Grimaudo, J.: 作为可持续农业的推动者：对农民采用精准农业技术决策的实证分析。决策支持系统
    54(1) (2012) 510 – 520'
- en: '[5] Sladojevic, S., Arsenovic, M., Anderla, A., Culibrk, D., Stefanovic, D.:
    Deep neural networks based recognition of plant diseases by leaf image classification.
    In: Comp. Int. and Neurosc. (2016)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Sladojevic, S., Arsenovic, M., Anderla, A., Culibrk, D., Stefanovic, D.:
    基于深度神经网络的植物疾病识别，通过叶片图像分类。见：计算智能与神经科学 (2016)'
- en: '[6] Ruckelshausen, A., Biber, P., Dorna, M., Gremmes, H., Klose, R., Linz,
    A., Rahe, R., Resch, R., Thiel, M., Trautz, D., Weiss, U.: Bonirob: An autonomous
    field robot platform for individual plant phenotyping. Precision Agriculture 9
    (01 2009) 841–847'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Ruckelshausen, A., Biber, P., Dorna, M., Gremmes, H., Klose, R., Linz,
    A., Rahe, R., Resch, R., Thiel, M., Trautz, D., Weiss, U.: Bonirob：一个用于个体植物表型分析的自主田间机器人平台。精准农业
    9 (01 2009) 841–847'
- en: '[7] Fitch, F.B.: Warren s. mcculloch and walter pitts. a logical calculus of
    the ideas immanent in nervous activity. bulletin of mathematical biophysics, vol.
    5 (1943), pp. 115–133. Journal of Symbolic Logic 9(2) (1944) 49–50'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Fitch, F.B.: Warren S. McCulloch 和 Walter Pitts。神经活动中固有思想的逻辑演算。数学生物物理学公报，第5卷
    (1943)，第115–133页。符号逻辑期刊 9(2) (1944) 49–50'
- en: '[8] Rosenblatt, F.F.: The perceptron: a probabilistic model for information
    storage and organization in the brain. Psychological review 65 6 (1958) 386–408'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Rosenblatt, F.F.: 感知器：一种用于信息存储和组织的大脑中的概率模型。心理学评论 65 6 (1958) 386–408'
- en: '[9] Hornik, K., Stinchcombe, M., White, H.: Multilayer feedforward networks
    are universal approximators. Neural Netw. 2(5) (July 1989) 359–366'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Hornik, K., Stinchcombe, M., White, H.: 多层前馈网络是通用逼近器。神经网络 2(5) (1989年7月)
    359–366'
- en: '[10] Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Montreal, U.: Greedy
    layer-wise training of deep networks. Volume 19\. (01 2007)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Montreal, U.: 贪婪的逐层训练深度网络。第19卷
    (01 2007)'
- en: '[11] Bengio, Y.: Learning deep architectures for ai. Foundations 2 (01 2009)
    1–55'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Bengio, Y.: 为人工智能学习深度架构。基础 2 (01 2009) 1–55'
- en: '[12] Alom, M.Z., Taha, T.M., Yakopcic, C., Westberg, S., Sidike, P., Nasrin,
    M.S., Hasan, M., Van Essen, B.C., Awwal, A.A.S., Asari, V.K.: A state-of-the-art
    survey on deep learning theory and architectures. Electronics 8(3) (Mar 2019)
    292'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Alom, M.Z., Taha, T.M., Yakopcic, C., Westberg, S., Sidike, P., Nasrin,
    M.S., Hasan, M., Van Essen, B.C., Awwal, A.A.S., Asari, V.K.: 深度学习理论与架构的最新研究。电子学
    8(3) (2019年3月) 292'
- en: '[13] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
    Ozair, S., Courville, A., Bengio, Y.: Generative adversarial nets. In Ghahramani,
    Z., Welling, M., Cortes, C., Lawrence, N.D., Weinberger, K.Q., eds.: Advances
    in Neural Information Processing Systems 27. Curran Associates, Inc. (2014) 2672–2680'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
    Ozair, S., Courville, A., Bengio, Y.: 生成对抗网络。见 Ghahramani, Z., Welling, M., Cortes,
    C., Lawrence, N.D., Weinberger, K.Q., 编：神经信息处理系统进展 27. Curran Associates, Inc.
    (2014) 2672–2680'
- en: '[14] : A framework for designing the architectures of deep convolutional neural
    networks. Entropy 19(6) (May 2017) 242'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] : 深度卷积神经网络架构设计的框架。熵 19(6) (2017年5月) 242'
- en: '[15] Fukushima, K.: Neocognitron: A hierarchical neural network capable of
    visual pattern recognition. Neural Networks 1 (1988) 119–130'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Fukushima, K.: Neocognitron：一种能够进行视觉模式识别的分层神经网络。神经网络 1 (1988) 119–130'
- en: '[16] Lecun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning
    applied to document recognition. Proceedings of the IEEE 86(11) (Nov 1998) 2278–2324'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Lecun, Y., Bottou, L., Bengio, Y., Haffner, P.: 基于梯度的学习应用于文档识别。IEEE 会议记录
    86(11) (1998年11月) 2278–2324'
- en: '[17] Itay Lieder, Yehezkel S. Resheff, T.H.: Learning tensorflow. (2017) Chapter
    4'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Itay Lieder, Yehezkel S. Resheff, T.H.: 学习 TensorFlow. (2017) 第4章'
- en: '[18] Boureau, Y.L., Ponce, J., Lecun, Y.: A theoretical analysis of feature
    pooling in visual recognition. (11 2010) 111–118'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Boureau, Y.L., Ponce, J., Lecun, Y.: 特征池化在视觉识别中的理论分析。 (2010年11月) 111–118'
- en: '[19] Scherer, D., Müller, A., Behnke, S.: Evaluation of pooling operations
    in convolutional architectures for object recognition. In Diamantaras, K., Duch,
    W., Iliadis, L.S., eds.: Artificial Neural Networks – ICANN 2010, Berlin, Heidelberg,
    Springer Berlin Heidelberg (2010) 92–101'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Scherer, D., Müller, A., Behnke, S.: 卷积架构中池化操作的评估。见 Diamantaras, K., Duch,
    W., Iliadis, L.S., 编：人工神经网络 – ICANN 2010，柏林，海德堡，Springer Berlin Heidelberg (2010)
    92–101'
- en: '[20] Jiao, L., Zhang, F., Liu, F., Yang, S., Li, L., Feng, Z., Qu, R.: A survey
    of deep learning-based object detection. IEEE Access 7 (2019) 128837–128868'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Jiao, L., Zhang, F., Liu, F., Yang, S., Li, L., Feng, Z., Qu, R.: 基于深度学习的目标检测调查。IEEE
    Access 7（2019年）128837–128868'
- en: '[21] Lu, Z., Xu, H., Liu, G.: A survey of object co-segmentation. IEEE Access
    PP (05 2019) 1–1'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Lu, Z., Xu, H., Liu, G.: 目标共同分割调查。IEEE Access PP（2019年5月）1–1'
- en: '[22] Lin, T.Y., Maire, M., Belongie, S.J., Hays, J., Perona, P., Ramanan, D.,
    Dollár, P., Zitnick, C.L.: Microsoft coco: Common objects in context. In: ECCV.
    (2014)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Lin, T.Y., Maire, M., Belongie, S.J., Hays, J., Perona, P., Ramanan, D.,
    Dollár, P., Zitnick, C.L.: 微软COCO：上下文中的常见物体。见：ECCV.（2014年）'
- en: '[23] Y. Gharde, P. Singh, R.D., Gupta, P.: Assessment of yield and economic
    losses in agriculture due to weeds in india. Volume 107\. (2018) 12–18'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Y. Gharde, P. Singh, R.D., Gupta, P.: 印度农业中由于杂草导致的产量和经济损失评估。第107卷。（2018年）12–18'
- en: '[24] Haug, S., Ostermann, J.: A crop/weed field image dataset for the evaluation
    of computer vision based precision agriculture tasks. In: ECCV Workshops. (2014)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Haug, S., Ostermann, J.: 用于评估基于计算机视觉的精准农业任务的作物/杂草田地图像数据集。见：ECCV Workshops.（2014年）'
- en: '[25] Binguitcha-Fare, A.A., Sharma, P.: Crops and weeds classification using
    convolutional neural networks via optimization of transfer learning parameters'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Binguitcha-Fare, A.A., Sharma, P.: 使用卷积神经网络进行作物和杂草分类，通过优化迁移学习参数'
- en: '[26] Fawakherji, M., Youssef, A., Bloisi, D.D., Pretto, A., Nardi, D.: Crop
    and weeds classification for precision agriculture using context-independent pixel-wise
    segmentation. 2019 Third IEEE International Conference on Robotic Computing (IRC)
    (2019) 146–152'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Fawakherji, M., Youssef, A., Bloisi, D.D., Pretto, A., Nardi, D.: 用于精准农业的作物和杂草分类，基于上下文无关的像素级分割。2019年第三届IEEE国际机器人计算会议（IRC）（2019年）146–152'
- en: '[27] Guerrero, J.M., Pajares, G., Montalvo, M., Romeo, J., Guijarro, M.: Support
    vector machines for crop/weeds identification in maize fields. Expert Syst. Appl.
    39 (2012) 11149–11155'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Guerrero, J.M., Pajares, G., Montalvo, M., Romeo, J., Guijarro, M.: 用于玉米田作物/杂草识别的支持向量机。专家系统与应用
    39（2012年）11149–11155'
- en: '[28] Sa, I., Chen, Z., Popovic, M., Khanna, R., Liebisch, F., Nieto, J., Siegwart,
    R.: weednet: Dense semantic weed classification using multispectral images and
    mav for smart farming. IEEE Robotics and Automation Letters 3 (2017) 588–595'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Sa, I., Chen, Z., Popovic, M., Khanna, R., Liebisch, F., Nieto, J., Siegwart,
    R.: WeedNet：使用多光谱图像和MAV进行智能农业的密集语义杂草分类。IEEE机器人与自动化快报 3（2017年）588–595'
- en: '[29] Rani, K., Supriya, P., Sarath, T.V.: Computer vision based segregation
    of carrot and curry leaf plants with weed identification in carrot field. 2017
    International Conference on Computing Methodologies and Communication (ICCMC)
    (2017) 185–188'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Rani, K., Supriya, P., Sarath, T.V.: 基于计算机视觉的胡萝卜和咖喱叶植物分离及胡萝卜田中的杂草识别。2017年国际计算方法与通信会议（ICCMC）（2017年）185–188'
- en: '[30] Nkemelu, D.K., Omeiza, D., Lubalo, N.: Deep convolutional neural network
    for plant seedlings classification. ArXiv abs/1811.08404 (2018)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Nkemelu, D.K., Omeiza, D., Lubalo, N.: 用于植物幼苗分类的深度卷积神经网络。ArXiv abs/1811.08404（2018年）'
- en: '[31] Elnemr, H.A.: Convolutional neural network architecture for plant seedling
    classification. (2019)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Elnemr, H.A.: 用于植物幼苗分类的卷积神经网络架构。（2019年）'
- en: '[32] Xiang, T.Z., Xia, G.S., Zhang, L.: Mini-uav-based remote sensing: Techniques,
    applications and prospectives (12 2018)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Xiang, T.Z., Xia, G.S., Zhang, L.: 基于迷你无人机的遥感：技术、应用和前景（2018年12月）'
- en: '[33] Patrício, D.I., Rieder, R.: Computer vision and artificial intelligence
    in precision agriculture for grain crops: A systematic review. Comput. Electron.
    Agric. 153 (2018) 69–81'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Patrício, D.I., Rieder, R.: 粮食作物精准农业中的计算机视觉和人工智能：系统评审。计算机与电子农业 153（2018年）69–81'
- en: '[34] Fuentes, A., Yoon, S., Kim, S.C., Park, D.S.: A robust deep-learning-based
    detector for real-time tomato plant diseases and pests recognition. In: Sensors.
    (2017)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Fuentes, A., Yoon, S., Kim, S.C., Park, D.S.: 一种基于深度学习的鲁棒检测器，用于实时番茄植物疾病和害虫识别。见：传感器。（2017年）'
- en: '[35] Bachche, S.: Deliberation on design strategies of automatic harvesting
    systems: A survey. Robotics 4 (2015) 194–222'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Bachche, S.: 关于自动收割系统设计策略的探讨：一项调查。机器人学 4（2015年）194–222'
- en: '[36] Allende, A., Monaghan, J.M., Uyttendaele, M., Franz, E., Schlüter, O.:
    Irrigation water quality for leafy crops: A perspective of risks and potential
    solutions. In: International journal of environmental research and public health.
    (2015)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Allende, A., Monaghan, J.M., Uyttendaele, M., Franz, E., Schlüter, O.:
    绿叶作物的灌溉水质：风险与潜在解决方案的视角。见：国际环境研究与公共健康杂志。（2015年）'
- en: '[37] Guo, W., Zheng, B., Potgieter, A.B., Diot, J., Watanabe, K., Noshita,
    K., Jordan, D.R., Wang, X., Watson, J., Ninomiya, S., Chapman, S.C.: Aerial Imagery
    Analysis – Quantifying Appearance and Number of Sorghum Heads for Applications
    in Breeding and Agronomy. Frontiers in Plant Science 9(October) (2018) 1–9'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Guo, W., Zheng, B., Potgieter, A.B., Diot, J., Watanabe, K., Noshita,
    K., Jordan, D.R., Wang, X., Watson, J., Ninomiya, S., Chapman, S.C.: 航空影像分析 –
    量化高粱穗的外观和数量，用于育种和农业应用。植物科学前沿 9(10月) (2018年) 1–9'
- en: '[38] Chai, Q., Gan, Y., Zhao, C., Xu, H.l., Waskom, R., Niu, Y., Siddique,
    K.: Regulated deficit irrigation for crop production under drought stress. a review.
    Agronomy for Sustainable Development 36 (03 2016)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Chai, Q., Gan, Y., Zhao, C., Xu, H.l., Waskom, R., Niu, Y., Siddique,
    K.: 干旱压力下作物生产的调控缺水灌溉。综述。可持续发展农业学报 36 (2016年03月)'
- en: '[39] Zhao, D., Liu, X., Chen, Y., Ji, W., Jia, W., Hu, C.: Image recognition
    at night for apple picking robot. Nongye Jixie Xuebao/Transactions of the Chinese
    Society for Agricultural Machinery 46 (03 2015) 15–22'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Zhao, D., Liu, X., Chen, Y., Ji, W., Jia, W., Hu, C.: 夜间图像识别用于苹果采摘机器人。农业机械学报/中国农业机械学会学报
    46 (2015年03月) 15–22'
- en: '[40] Yamane, S., Miyazaki, M.: Study on electrostatic pesticide spraying system
    for low-concentration, high-volume applications. (2017)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Yamane, S., Miyazaki, M.: 低浓度、高容量应用的静电喷雾系统研究。 (2017年)'
- en: '[41] Oktay, K., Bedoschi, G., Pacheco, F., Turan, V., Emirdar, V.: First pregnancies,
    livebirth and in vitro fertilization outcomes after transplantation of frozen-banked
    ovarian tissue with a human extracellular matrix scaffold using robot-assisted
    minimally invasive surgery. American Journal of Obstetrics and Gynecology 214
    (11 2015)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Oktay, K., Bedoschi, G., Pacheco, F., Turan, V., Emirdar, V.: 冻存卵巢组织与人类细胞外基质支架联合移植后的首次妊娠、活产和体外受精结果，采用机器人辅助手术。美国妇产科杂志
    214 (2015年11月)'
- en: '[42] Zheng, Y.Y., Kong, J.L., bo Jin, X., Wang, X.Y., Su, T.L., Zuo, M.: Cropdeep:
    The crop vision dataset for deep-learning-based classification and detection in
    precision agriculture. In: Sensors. (2019)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Zheng, Y.Y., Kong, J.L., bo Jin, X., Wang, X.Y., Su, T.L., Zuo, M.: Cropdeep:
    精准农业中基于深度学习的分类和检测作物视觉数据集。传感器杂志. (2019年)'
- en: '[43] Minervini, M., Fischbach, A., Scharr, H., Tsaftaris, S.: Finely-grained
    annotated datasets for image-based plant phenotyping. Pattern Recognition Letters
    81 (11 2015)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Minervini, M., Fischbach, A., Scharr, H., Tsaftaris, S.: 细粒度标注数据集用于基于图像的植物表型分析。模式识别快报
    81 (2015年11月)'
- en: '[44] Scharr, H., Minervini, M., Fischbach, A., Tsaftaris, S.: Annotated image
    datasets of rosette plants (07 2014)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Scharr, H., Minervini, M., Fischbach, A., Tsaftaris, S.: 玫瑰植物的标注图像数据集
    (2014年07月)'
- en: '[45] Cruz, J., Yin, X., Liu, X., Imran, S., Morris, D., Kramer, D., Chen, J.:
    Multi-modality imagery database for plant phenotyping. Machine Vision and Applications
    27 (07 2016)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] Cruz, J., Yin, X., Liu, X., Imran, S., Morris, D., Kramer, D., Chen, J.:
    多模态影像数据库用于植物表型分析。机器视觉与应用 27 (2016年07月)'
- en: '[46] Madec, S., Jin, X., Lu, H., de Solan, B., Liu, S., Duyme, F., Heritier,
    E., Frederic, B.: Ear density estimation from high resolution rgb imagery using
    deep learning technique. Agricultural and Forest Meteorology 264 (01 2019) 225–234'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] Madec, S., Jin, X., Lu, H., de Solan, B., Liu, S., Duyme, F., Heritier,
    E., Frederic, B.: 使用深度学习技术从高分辨率 RGB 图像中估算耳密度。农业与森林气象学 264 (2019年01月) 225–234'
- en: '[47] Lu, H., Cao, Z.G., Xiao, Y., Li, Y., Zhu, Y.: Joint crop and tassel segmentation
    in the wild. (11 2015)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Lu, H., Cao, Z.G., Xiao, Y., Li, Y., Zhu, Y.: 野外作物和花序的联合分割。 (2015年11月)'
- en: '[48] Ghosal, S., Zheng, B., Chapman, S.C., Potgieter, A.B., Jordan, D., Wang,
    X., Singh, A.K., Singh, A., Hirafuji, M., Ninomiya, S., Ganapathysubramanian,
    B., Sarkar, S., Guo, W.: A weakly supervised deep learning framework for sorghum
    head detection and counting. (2019)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Ghosal, S., Zheng, B., Chapman, S.C., Potgieter, A.B., Jordan, D., Wang,
    X., Singh, A.K., Singh, A., Hirafuji, M., Ninomiya, S., Ganapathysubramanian,
    B., Sarkar, S., Guo, W.: 一种弱监督的深度学习框架用于高粱穗的检测与计数。 (2019年)'
- en: '[49] Desai, S.V., Balasubramanian, V.N., Fukatsu, T., Ninomiya, S., Guo, W.:
    Automatic estimation of heading date of paddy rice using deep learning. Plant
    Methods 15(1) (2019)  76'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] Desai, S.V., Balasubramanian, V.N., Fukatsu, T., Ninomiya, S., Guo, W.:
    使用深度学习自动估算水稻的抽穗日期。植物方法 15(1) (2019年) 76'
- en: '[50] Hasan, M.M., Chopin, J.P., Laga, H., Miklavcic, S.J.: Detection and analysis
    of wheat spikes using convolutional neural networks. Plant Methods 14(1) (Nov
    2018) 100'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] Hasan, M.M., Chopin, J.P., Laga, H., Miklavcic, S.J.: 使用卷积神经网络检测和分析小麦穗。植物方法
    14(1) (2018年11月) 100'
- en: '[51] Ubbens, J., Cieslak, M., Prusinkiewicz, P., Stavness, I.: The use of plant
    models in deep learning: an application to leaf counting in rosette plants. In:
    Plant Methods. (2018)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] 乌本斯, J., 赛斯拉克, M., 普鲁辛基维奇, P., 斯塔夫内斯, I.: 植物模型在深度学习中的应用：以玫瑰植物叶子计数为例。发表于：植物方法。（2018）'
- en: '[52] Sa, I., Ge, Z., Dayoub, F., Upcroft, B., Perez, T., McCool, C.: Deepfruits:
    A fruit detection system using deep neural networks. In: Sensors. (2016)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] 萨伊, I., 葛志, Z., 达尤布, F., 阿普克罗夫特, B., 佩雷斯, T., 麦库尔, C.: Deepfruits：一种使用深度神经网络的水果检测系统。发表于：传感器。（2016）'
- en: '[53] Xiong, X., Duan, L., Liu, L., Tu, H., Yang, P., Wu, D., Chen, G., Xiong,
    L., Yang, W., Liu, Q.: Panicle-seg: a robust image segmentation method for rice
    panicles in the field based on deep learning and superpixel optimization. Plant
    Methods 13(1) (Nov 2017) 104'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] 熊熙, 段莉, 刘磊, 涂华, 杨鹏, 吴迪, 陈光, 熊力, 杨伟, 刘青: Panicle-seg：基于深度学习和超像素优化的稻穗田间图像分割方法。植物方法
    13(1) (2017年11月) 104'
- en: '[54] Oh, M.h., Olsen, P., Ramamurthy, K.N.: Counting and Segmenting Sorghum
    Heads. (may 2019)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] 哦, M.h., 奥尔森, P., 拉马穆尔西, K.N.: 粟米穗的计数与分割。（2019年5月）'
- en: '[55] Tai, A., Val Martin, M., Heald, C.: Threat to future global food security
    from climate change and ozone air pollution. Nature Climate Change 4 (07 2014)
    817–821'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] 泰, A., 瓦尔·马丁, M., 希尔德, C.: 气候变化和臭氧空气污染对未来全球粮食安全的威胁。自然气候变化 4 (2014年7月)
    817–821'
- en: '[56] Unknown: Pollinators vital to our food supply under threat. Volume Press
    Release., Intergovernmental Platform on Biodiversity and Ecosystem Services (2016)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] 未知: 传粉者对我们食品供应至关重要，面临威胁。国际生物多样性与生态系统服务政府间平台新闻稿。（2016）'
- en: '[57] Strange, R., Scott, P.: Plant disease: A threat to global food security.
    Annual review of phytopathology 43 (02 2005) 83–116'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] 斯特兰奇, R., 斯科特, P.: 植物病害：对全球粮食安全的威胁。植物病理学年鉴 43 (2005年2月) 83–116'
- en: '[58] Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., Batra, N.: Plantdoc:
    A dataset for visual plant disease detection. In: CoDS COMAD 2020\. (2020)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] 辛格, D., 贾恩, N., 贾恩, P., 卡亚尔, P., 库马瓦特, S., 巴特拉, N.: Plantdoc：用于视觉植物病害检测的数据集。发表于：CoDS
    COMAD 2020。（2020）'
- en: '[59] Walpole, M., Smith, J., Rosser, A., Brown, C., Schulte-Herbruggen, B.,
    Booth, H., Sassen, M., Mapendembe, A., Fancourt, M., Bieri, M., Glaser, S., Corrigan,
    C., Narloch, U., Runsten, L., Jenkins, M., Gomera, M., Hutton, J.: Smallholders,
    food security, and the environment (03 2013)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] 沃尔波尔, M., 史密斯, J., 罗瑟, A., 布朗, C., 舒尔特-赫布鲁根, B., 布斯, H., 萨森, M., 马本登贝,
    A., 方克特, M., 比耶里, M., 格拉泽, S., 科里根, C., 纳洛赫, U., 伦斯滕, L., 詹金斯, M., 戈梅拉, M., 哈顿,
    J.: 小农户、粮食安全与环境（2013年3月）'
- en: '[60] Harvey Celia A., Rakotobe Zo Lalaina, R.N.S.D.R.R.H.R.R.H.R.H., L., M.J.:
    Extreme vulnerability of smallholder farmers to agricultural risks and climate
    change in madagascar (04 2014)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] 哈维·塞利亚·A., 拉科托贝·佐·拉莱纳, R.N.S.D.R.R.H.R.R.H.R.H., L., M.J.: 马达加斯加小农户对农业风险和气候变化的极端脆弱性（2014年4月）'
- en: '[61] Sanchez, P., Swaminathan, M.: Cutting world hunger in half. Science (New
    York, N.Y.) 307 (02 2005) 357–9'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] 桑切斯, P., 斯瓦米那坦, M.: 将世界饥饿减少一半。科学（纽约, N.Y.）307 (2005年2月) 357–9'
- en: '[62] MinistryOfAgriculture: Government of india 2019\. kisaan knowledge management
    system. (2019)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] 农业部: 印度政府2019年。kisaan知识管理系统。（2019）'
- en: '[63] Hughes, D., Salathe, M.: An open access repository of images on plant
    health to enable the development of mobile disease diagnostics through machine
    learning and crowdsourcing. (11 2015)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] 休斯, D., 萨拉特, M.: 开放访问的植物健康图像库，以支持通过机器学习和众包技术开发移动疾病诊断工具。（2015年11月）'
- en: '[64] Liu, B., Zhuhua, H., Zhao, Y., Bai, Y., Wang, Y.: Recognition of pyralidae
    insects using intelligent monitoring autonomous robot vehicle in natural farm
    scene (01 2019)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] 刘博, 朱华, 赵宇, 白杨, 王勇: 使用智能监测自主机器人在自然农田场景中识别鳞翅目昆虫（2019年1月）'
- en: '[65] Deng, L., Wang, Y., Han, Z., Yu, R.: Research on insect pest image detection
    and recognition based on bio-inspired methods. (2018)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] 邓丽, 王勇, 韩志, 于荣: 基于生物启发方法的昆虫害虫图像检测与识别研究。（2018）'
- en: '[66] Javed, M.H., Humair, M., Yaqoob, B., Noor, N., Arshad, T.: K-means based
    automatic pests detection and classification for pesticides spraying. International
    Journal of Advanced Computer Science and Applications 8 (01 2017)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] 贾维德, M.H., 赫马伊尔, M., 雅库布, B., 诺尔, N., 阿尔沙德, T.: 基于K-means的自动害虫检测与分类用于喷洒农药。国际高级计算机科学与应用期刊
    8 (2017年1月)'
- en: '[67] Liu, T., Chen, W., Wu, W., Sun, C., Guo, W., Zhu, X.: Detection of aphids
    in wheat fields using a computer vision technique. Biosystems Engineering 141
    (01 2016) 82–93'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] 刘涛, 陈伟, 吴伟, 孙超, 郭伟, 朱欣: 使用计算机视觉技术检测小麦田中的蚜虫。生物系统工程 141 (2016年1月) 82–93'
- en: '[68] Zhong, Y., Gao, J., Lei, Q., Zhou, Y.: A vision-based counting and recognition
    system for flying insects in intelligent agriculture. In: Sensors. (2018)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] Zhong, Y., Gao, J., Lei, Q., Zhou, Y.: 一种基于视觉的飞行昆虫计数与识别系统用于智能农业。见：Sensors。（2018）'
- en: '[69] Galloway, A., Taylor, G.W., Ramsay, A., Moussa, M.A.: The ciona17 dataset
    for semantic segmentation of invasive species in a marine aquaculture environment.
    2017 14th Conference on Computer and Robot Vision (CRV) (2017) 361–366'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] Galloway, A., Taylor, G.W., Ramsay, A., Moussa, M.A.: ciona17数据集用于海洋水产环境中入侵物种的语义分割。2017年第十四届计算机与机器人视觉会议（CRV）（2017）361–366'
- en: '[70] Zhang, S., Wu, X., You, Z.H., Zhang, L.: Leaf image based cucumber disease
    recognition using sparse representation classification. Comput. Electron. Agric.
    134 (2017) 135–141'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] Zhang, S., Wu, X., You, Z.H., Zhang, L.: 基于叶片图像的黄瓜病害识别使用稀疏表示分类。计算机与电子农业
    134（2017）135–141'
- en: '[71] Ferentinos, K.P.: Deep learning models for plant disease detection and
    diagnosis. Comput. Electron. Agric. 145 (2018) 311–318'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] Ferentinos, K.P.: 用于植物病害检测和诊断的深度学习模型。计算机与电子农业 145（2018）311–318'
- en: '[72] Pallagani, V., Khandelwal, V., Chandra, B., Udutalapally, V., Das, D.,
    Mohanty, S.P.: dcrop: A deep-learning based framework for accurate prediction
    of diseases of crops in smart agriculture. 2019 IEEE International Symposium on
    Smart Electronic Systems (iSES) (Formerly iNiS) (2019) 29–33'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] Pallagani, V., Khandelwal, V., Chandra, B., Udutalapally, V., Das, D.,
    Mohanty, S.P.: dcrop：一个基于深度学习的框架，用于智能农业中作物疾病的准确预测。2019 IEEE国际智能电子系统研讨会（iSES）（原iNiS）（2019）29–33'
- en: '[73] Mohanty, S.P., Hughes, D.P., Salathé, M.: Using deep learning for image-based
    plant disease detection. In: Front. Plant Sci. (2016)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] Mohanty, S.P., Hughes, D.P., Salathé, M.: 使用深度学习进行基于图像的植物病害检测。见：Front.
    Plant Sci.（2016）'
- en: '[74] Francis, M., Deisy, C.: Disease detection and classification in agricultural
    plants using convolutional neural networks — a visual understanding. 2019 6th
    International Conference on Signal Processing and Integrated Networks (SPIN) (2019)
    1063–1068'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] Francis, M., Deisy, C.: 使用卷积神经网络进行农业植物的疾病检测与分类——视觉理解。2019年第六届信号处理与集成网络国际会议（SPIN）（2019）1063–1068'
- en: '[75] Li, D., Wang, R., Xie, C., Liu, L., Zhang, J., Li, R., Wang, F., Zhou,
    M., Liu, W.: A recognition method for rice plant diseases and pests video detection
    based on deep convolutional neural network. Sensors 20 3 (2020)'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] Li, D., Wang, R., Xie, C., Liu, L., Zhang, J., Li, R., Wang, F., Zhou,
    M., Liu, W.: 基于深度卷积神经网络的水稻植物病害和害虫视频检测识别方法。传感器 20 3（2020）'
- en: '[76] jie Liang, W., Zhang, H., feng Zhang, G., xin Cao, H.: Rice blast disease
    recognition using a deep convolutional neural network. In: Scientific Reports.
    (2019)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] jie Liang, W., Zhang, H., feng Zhang, G., xin Cao, H.: 基于深度卷积神经网络的水稻稻瘟病识别。见：Scientific
    Reports。（2019）'
- en: '[77] Zhou, G., Zhang, W., Chen, A., He, M., Ma, X.: Rapid detection of rice
    disease based on fcm-km and faster r-cnn fusion. IEEE Access 7 (2019) 143190–143206'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] Zhou, G., Zhang, W., Chen, A., He, M., Ma, X.: 基于fcm-km和faster r-cnn融合的水稻病害快速检测。IEEE
    Access 7（2019）143190–143206'
- en: '[78] Maeda-Gutiérrez, V., Galván Tejada, C., Zanella Calzada, L., Celaya Padilla,
    J., Galván Tejada, J., Gamboa-Rosales, H., Luna-Garcia, H., Magallanes-Quintanar,
    R., Carlos, G.M., Olvera-Olvera, C.: Comparison of convolutional neural network
    architectures for classification of tomato plant diseases. Applied Sciences 10
    (02 2020) 1245'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] Maeda-Gutiérrez, V., Galván Tejada, C., Zanella Calzada, L., Celaya Padilla,
    J., Galván Tejada, J., Gamboa-Rosales, H., Luna-Garcia, H., Magallanes-Quintanar,
    R., Carlos, G.M., Olvera-Olvera, C.: 卷积神经网络架构在番茄植物病害分类中的比较。应用科学 10（02 2020）1245'
- en: '[79] Fuentes, A., Yoon, S., Lee, J., Park, D.S.: High-performance deep neural
    network-based tomato plant diseases and pests diagnosis system with refinement
    filter bank. In: Front. Plant Sci. (2018)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] Fuentes, A., Yoon, S., Lee, J., Park, D.S.: 高性能深度神经网络基础的番茄植物病害与害虫诊断系统，配有精细化滤波器组。见：Front.
    Plant Sci.（2018）'
- en: '[80] Gutierrez, A., Ansuategi, A., Susperregi, L., Tubío, C., Rankić, I., Lenža,
    L.: A benchmarking of learning strategies for pest detection and identification
    on tomato plants for autonomous scouting robots using internal databases. Journal
    of Sensors 2019 (05 2019) 1–15'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] Gutierrez, A., Ansuategi, A., Susperregi, L., Tubío, C., Rankić, I., Lenža,
    L.: 针对番茄植物的害虫检测与识别的学习策略基准，适用于使用内部数据库的自主巡逻机器人。传感器杂志 2019（05 2019）1–15'
- en: '[81] Michael Gomez Selvaraj, Alejandro Vergara, H.R.N.S.S.E.W.O.G.B.: Ai-powered
    banana diseases and pest detection. Plant Methods 2019 (08 2019)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] Michael Gomez Selvaraj, Alejandro Vergara, H.R.N.S.S.E.W.O.G.B.: 人工智能驱动的香蕉病害和害虫检测。植物方法
    2019（08 2019）'
- en: '[82] Aravind, K.R., Raja, P., Aniirudh, R., Mukesh, K.V., Ashiwin, R., Vikas,
    G.: Grape crop disease classification using transfer learning approach. (2018)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] Aravind, K.R., Raja, P., Aniirudh, R., Mukesh, K.V., Ashiwin, R., Vikas,
    G.: 使用迁移学习方法进行葡萄作物病害分类。(2018)'
- en: '[83] Shadab, M., Dwivedi, M., S N, O., Javed, T., Bakey, A., Raqib, M., Chakravarthy,
    A.: Disease recognition in sugarcane crop using deep learning (09 2019)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] Shadab, M., Dwivedi, M., S N, O., Javed, T., Bakey, A., Raqib, M., Chakravarthy,
    A.: 使用深度学习对甘蔗作物进行病害识别 (09 2019)'
- en: '[84] Rangarajan, A.K., Purushothaman, R.: Disease classification in eggplant
    using pre-trained vgg16 and msvm. Scientific Reports 10 (2020)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] Rangarajan, A.K., Purushothaman, R.: 使用预训练的vgg16和msvm进行茄子病害分类。科学报告 10
    (2020)'
- en: '[85] Zhang, S., Wu, X., You, Z.H., Zhang, L.: Leaf image based cucumber disease
    recognition using sparse representation classification. Comput. Electron. Agric.
    134 (2017) 135–141'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] Zhang, S., Wu, X., You, Z.H., Zhang, L.: 基于叶片图像的黄瓜病害识别使用稀疏表示分类。计算机电子农业
    134 (2017) 135–141'
- en: '[86] Kaur, S., Pandey, S., Goel, S.: Semi-automatic leaf disease detection
    and classification system for soybean culture. IET Image Processing 12 (2018)
    1038–1048'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] Kaur, S., Pandey, S., Goel, S.: 半自动化豆类叶病检测与分类系统。IET 图像处理 12 (2018) 1038–1048'
- en: '[87] Cruz, A.C., Luvisi, A., Bellis, L.D., Ampatzidis, Y.: X-fido: An effective
    application for detecting olive quick decline syndrome with deep learning and
    data fusion. In: Front. Plant Sci. (2017)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] Cruz, A.C., Luvisi, A., Bellis, L.D., Ampatzidis, Y.: X-fido: 一种利用深度学习和数据融合检测橄榄快速衰退综合症的有效应用。在：前沿植物科学.
    (2017)'
- en: '[88] Chen, J., Liu, Q., Gao, L.: Visual tea leaf disease recognition using
    a convolutional neural network model. Symmetry 11 (2019) 343'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] Chen, J., Liu, Q., Gao, L.: 使用卷积神经网络模型的视觉茶叶病害识别。对称性 11 (2019) 343'
- en: '[89] Esgario, J., Krohling, R., Ventura, J.: Deep learning for classification
    and severity estimation of coffee leaf biotic stress (07 2019)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] Esgario, J., Krohling, R., Ventura, J.: 深度学习在咖啡叶生物应激分类和严重程度估计中的应用 (07
    2019)'
- en: '[90] Arsenovic, M., Karanovic, M., Sladojevic, S., Anderla, A., Stefanovic,
    D.: Solving current limitations of deep learning based approaches for plant disease
    detection. Symmetry 11 (2019) 939'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] Arsenovic, M., Karanovic, M., Sladojevic, S., Anderla, A., Stefanovic,
    D.: 解决基于深度学习的方法在植物病害检测中的当前局限性。对称性 11 (2019) 939'
- en: '[91] Shakhatreh, H., Sawalmeh, A.H., Al-Fuqaha, A., Dou, Z., Almaita, E., Khalil,
    I.M., Othman, N.S., Khreishah, A., Guizani, M.: Unmanned aerial vehicles (uavs):
    A survey on civil applications and key research challenges. IEEE Access 7 (2019)
    48572–48634'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] Shakhatreh, H., Sawalmeh, A.H., Al-Fuqaha, A., Dou, Z., Almaita, E., Khalil,
    I.M., Othman, N.S., Khreishah, A., Guizani, M.: 无人驾驶航空器（UAVs）：民用应用与关键研究挑战的综述。IEEE
    Access 7 (2019) 48572–48634'
- en: '[92] Xiang, T., Xia, G.S., Zhang, L.: Mini-unmanned aerial vehicle-based remote
    sensing: Techniques, applications, and prospects. IEEE Geoscience and Remote Sensing
    Magazine 7 (2019) 29–63'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] Xiang, T., Xia, G.S., Zhang, L.: 基于迷你无人机的遥感：技术、应用和前景。IEEE 地球科学与遥感杂志 7
    (2019) 29–63'
- en: '[93] Huang, Y., Thomson, S.J., Hoffmann, W.C., Lan, Y., Fritz, B.K.: Development
    and prospect of unmanned aerial vehicle technologies for agricultural production
    management. (2013)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] Huang, Y., Thomson, S.J., Hoffmann, W.C., Lan, Y., Fritz, B.K.: 无人机技术在农业生产管理中的发展与前景。(2013)'
- en: '[94] Dastgheibifard, S., Asnafi, M.: A review on potential applications of
    unmanned aerial vehicle for construction industry. (07 2018)'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] Dastgheibifard, S., Asnafi, M.: 关于无人机在建筑行业潜在应用的综述。(07 2018)'
- en: '[95] Kazmi, W., Bisgaard, M., Garcia-Ruiz, F.J., Hansen, K.D., la Cour-Harbo,
    A.: Adaptive surveying and early treatment of crops with a team of autonomous
    vehicles. In: ECMR. (2011)'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] Kazmi, W., Bisgaard, M., Garcia-Ruiz, F.J., Hansen, K.D., la Cour-Harbo,
    A.: 使用自主车辆团队对作物进行适应性调查和早期处理。在：ECMR. (2011)'
- en: '[96] V. Gonzalez-Dugo, P. Zarco-Tejada, E.N.P.N.J.A.D.I., Fereres, E.: Using
    high resolution uav thermal imagery to assess the variability in the water status
    of five fruit tree species within a commercial orchard. Precision Agriculture
    14(6) (12 2013) 660–678'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] V. Gonzalez-Dugo, P. Zarco-Tejada, E.N.P.N.J.A.D.I., Fereres, E.: 使用高分辨率无人机热成像评估商业果园内五种果树物种的水分状态变化。精准农业
    14(6) (12 2013) 660–678'
- en: '[97] Chiu, M.T., Xu, X., Wei, Y., Huang, Z., Schwing, A.G., Brunner, R., Khachatrian,
    H., Karapetyan, H., Dozier, I., Rose, G., Wilson, D., Tudor, A.P., Hovakimyan,
    N., Huang, T.S., Shi, H.: Agriculture-vision: A large aerial image database for
    agricultural pattern analysis. ArXiv abs/2001.01306 (2020)'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] Chiu, M.T., Xu, X., Wei, Y., Huang, Z., Schwing, A.G., Brunner, R., Khachatrian,
    H., Karapetyan, H., Dozier, I., Rose, G., Wilson, D., Tudor, A.P., Hovakimyan,
    N., Huang, T.S., Shi, H.: 农业视觉：一个用于农业模式分析的大型航空影像数据库。ArXiv abs/2001.01306 (2020)'
- en: '[98] Barbedo, J., Koenigkan, L., Santos, T., Santos, P.: A study on the detection
    of cattle in uav images using deep learning. Sensors 19 (12 2019) 5436'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] Barbedo, J., Koenigkan, L., Santos, T., Santos, P.：基于深度学习的无人机图像中牛的检测研究。传感器
    19 (2019年12月) 5436'
- en: '[99] Garcia-Ruiz, F., Sankaran, S., Maja, J.M., Lee, W.S., Rasmussen, J., Ehsani,
    R.: Comparison of two aerial imaging platforms for identification of huanglongbing-infected
    citrus trees. Computers and Electronics in Agriculture 91 (02 2013) 106–115'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] Garcia-Ruiz, F., Sankaran, S., Maja, J.M., Lee, W.S., Rasmussen, J., Ehsani,
    R.：两种航空成像平台在识别黄龙病感染的柑橘树方面的比较。计算机与电子农业 91 (2013年02月) 106–115'
- en: '[100] Kerkech, M., Hafiane, A., Canals, R.: Vine disease detection in uav multispectral
    images with deep learning segmentation approach. (2019)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] Kerkech, M., Hafiane, A., Canals, R.：基于深度学习分割方法在无人机多光谱图像中检测葡萄疾病。(2019年)'
- en: '[101] Stumph, B., Virto, M.H., Medeiros, H., Tabb, A., Wolford, S., Rice, K.,
    Leskey, T.C.: Detecting invasive insects with unmanned aerial vehicles. 2019 International
    Conference on Robotics and Automation (ICRA) (2019) 648–654'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] Stumph, B., Virto, M.H., Medeiros, H., Tabb, A., Wolford, S., Rice, K.,
    Leskey, T.C.：利用无人机检测入侵昆虫。2019国际机器人与自动化会议 (ICRA) (2019年) 648–654'
- en: '[102] Mathur, P., Nielsen, R.H., Prasad, N.R., Prasad, R.: Data collection
    using miniature aerial vehicles in wireless sensor networks. IET Wireless Sensor
    Systems 6 (2016) 17–25'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] Mathur, P., Nielsen, R.H., Prasad, N.R., Prasad, R.：在无线传感器网络中使用微型无人机进行数据收集。IET无线传感器系统
    6 (2016年) 17–25'
- en: '[103] Primicerio, J., Di Gennaro, S., Fiorillo, E., Genesio, L., Lugato, E.,
    Matese, A., Vaccari, F.: A flexible unmanned aerial vehicle for precision agriculture.
    Precision Agriculture (08 2012)'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] Primicerio, J., Di Gennaro, S., Fiorillo, E., Genesio, L., Lugato, E.,
    Matese, A., Vaccari, F.：用于精准农业的灵活无人机。精准农业 (2012年08月)'
- en: '[104] F. M. Rhoads, C.D.Y.: Irrigation scheduling for corn—why and how. National
    Corn Handbook (2000)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] F. M. Rhoads, C.D.Y.：玉米灌溉调度——为何以及如何。国家玉米手册 (2000年)'
- en: '[105] Hassan-Esfahani, L., Torres-Rua, A., Jensen, A., McKee, M.: Assessment
    of surface soil moisture using high-resolution multi-spectral imagery and artificial
    neural networks. Remote Sensing 7 (03 2015) 2627–2646'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] Hassan-Esfahani, L., Torres-Rua, A., Jensen, A., McKee, M.：使用高分辨率多光谱影像和人工神经网络评估表层土壤湿度。遥感
    7 (2015年03月) 2627–2646'
- en: '[106] Calderón Madrid, R., Navas Cortés, J., Lucena, C., Zarco-Tejada, P.:
    High-resolution airborne hyperspectral and thermal imagery for early detection
    of verticillium wilt of olive using fluorescence, temperature and narrow-band
    spectral indices. Remote Sensing of Environment 139 (09 2013) 231–245'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] Calderón Madrid, R., Navas Cortés, J., Lucena, C., Zarco-Tejada, P.：利用荧光、温度和窄带光谱指数，通过高分辨率航空高光谱和热成像技术对橄榄树黄萎病进行早期检测。环境遥感
    139 (2013年09月) 231–245'
- en: '[107] Wang, D.C., Zhang, G.L., Pan, X., Zhao, Y.G., Zhao, M.S., Wang, G.F.:
    Mapping soil texture of a plain area using fuzzy-c-means clustering method based
    on land surface diurnal temperature difference. Pedosphere 22 (06 2012) 394–403'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] Wang, D.C., Zhang, G.L., Pan, X., Zhao, Y.G., Zhao, M.S., Wang, G.F.：基于地表日温差的模糊C均值聚类方法对平原地区土壤纹理的映射。土壤圈
    22 (2012年06月) 394–403'
- en: '[108] Wang, D.C., Zhang, G.L., Zhao, M.S., Pan, X., Zhao, Y.G., Li, D.C., Macmillan,
    B.: Retrieval and mapping of soil texture based on land surface diurnal temperature
    range data from modis. PLOS ONE 10 (06 2015) e0129977'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] Wang, D.C., Zhang, G.L., Zhao, M.S., Pan, X., Zhao, Y.G., Li, D.C., Macmillan,
    B.：基于MODIS数据的地表日温差范围数据对土壤纹理的检索与映射。PLOS ONE 10 (2015年06月) e0129977'
- en: '[109] Sullivan, D., Shaw, J., Mask, P., Rickman, D., Guertal, E., Luvall, J.,
    Wersinger, J.: Evaluation of multispectral data for rapid assessment of wheat
    straw residue cover. Soil Science Society of America Journal 68 (11 2004)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] Sullivan, D., Shaw, J., Mask, P., Rickman, D., Guertal, E., Luvall, J.,
    Wersinger, J.：多光谱数据在小麦秸秆残留覆盖快速评估中的应用。美国土壤科学学会期刊 68 (2004年11月)'
- en: '[110] Jensen, T., Apan, A., Zeller, L.: Crop maturity mapping using a low-cost
    low-altitude remote sensing system. (2009)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] Jensen, T., Apan, A., Zeller, L.：使用低成本低空遥感系统进行作物成熟度映射。(2009年)'
- en: '[111] Swain, K., Thomson, S., Jayasuriya, H.: Adoption of an unmanned helicopter
    for low-altitude remote sensing to estimate yield and total biomass of a rice
    crop. Transactions of the ASABE 53 (01 2010)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] Swain, K., Thomson, S., Jayasuriya, H.：采用无人直升机进行低空遥感，以估算稻作的产量和总生物量。ASABE学报
    53 (2010年01月)'
- en: '[112] Geipel, J., Link, J., Claupein, W.: Combined spectral and spatial modeling
    of corn yield based on aerial images and crop surface models acquired with an
    unmanned aircraft system. Remote Sensing 6 (11 2014) 10335–10355'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] Geipel, J., Link, J., Claupein, W.: 基于无人机系统获取的航拍图像和作物表面模型的玉米产量的光谱与空间建模结合。遥感
    6（11 2014）10335–10355'
- en: '[113] Pretto, A., Aravecchia, S., Burgard, W., Chebrolu, N., Dornhege, C.,
    Falck, T., Fleckenstein, F.V., Fontenla, A., Imperoli, M., Khanna, R., Liebisch,
    F., Lottes, P., Milioto, A., Nardi, D., Nardi, S., Pfeifer, J., Popovic, M., Potena,
    C., Pradalier, C., Rothacker-Feder, E., Sa, I., Schaefer, A., Siegwart, R., Stachniss,
    C., Walter, A., Winterhalter, W., Wu, X.L., Nieto, J.: Building an aerial-ground
    robotics system for precision farming. ArXiv abs/1911.03098 (2019)'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] Pretto, A., Aravecchia, S., Burgard, W., Chebrolu, N., Dornhege, C.,
    Falck, T., Fleckenstein, F.V., Fontenla, A., Imperoli, M., Khanna, R., Liebisch,
    F., Lottes, P., Milioto, A., Nardi, D., Nardi, S., Pfeifer, J., Popovic, M., Potena,
    C., Pradalier, C., Rothacker-Feder, E., Sa, I., Schaefer, A., Siegwart, R., Stachniss,
    C., Walter, A., Winterhalter, W., Wu, X.L., Nieto, J.: 建立一个用于精准农业的空中-地面机器人系统。ArXiv
    abs/1911.03098（2019）'
- en: '[114] Primicerio, J., Di Gennaro, S., Fiorillo, E., Genesio, L., Lugato, E.,
    Matese, A., Vaccari, F.: A flexible unmanned aerial vehicle for precision agriculture.
    Precision Agriculture (08 2012)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] Primicerio, J., Di Gennaro, S., Fiorillo, E., Genesio, L., Lugato, E.,
    Matese, A., Vaccari, F.: 一种灵活的无人机用于精准农业。精准农业（08 2012）'
- en: '[115] Press: How satellites are making agriculture more efficient. Gamaya Blog
    Post (2017)'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] Press: 卫星如何提高农业效率。Gamaya 博客文章（2017）'
- en: '[116] Press: Satellites designed for benefit of farmers. Government of India,
    Department of Space (2016)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] Press: 为农民利益设计的卫星。印度政府，空间部（2016）'
- en: '[117] Unknown: Farmers benefit from satellite coverage. ESA Earth Online'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] Unknown: 农民从卫星覆盖中受益。ESA Earth Online'
- en: '[118] Rußwurm, M., Lefèvre, S., Körner, M.: Breizhcrops: A satellite time series
    dataset for crop type identification. ArXiv abs/1905.11893 (2019)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] Rußwurm, M., Lefèvre, S., Körner, M.: Breizhcrops: 用于作物类型识别的卫星时间序列数据集。ArXiv
    abs/1905.11893（2019）'
- en: '[119] Ghazali, M., Wikantika, K., Harto, A., Kondoh, A.: Generating soil salinity,
    soil moisture, soil ph from satellite imagery and its analysis. Information Processing
    in Agriculture (08 2019)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] Ghazali, M., Wikantika, K., Harto, A., Kondoh, A.: 从卫星图像生成土壤盐碱度、土壤湿度、土壤pH值及其分析。农业信息处理（08
    2019）'
- en: '[120] Sheffield, K., Morse-McNabb, E.: Using satellite imagery to asses trends
    in soil and crop productivity across landscapes. IOP Conference Series: Earth
    and Environmental Science 25 (07 2015) 012013'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] Sheffield, K., Morse-McNabb, E.: 使用卫星图像评估跨区域土壤和作物生产力趋势。IOP 会议系列：地球与环境科学
    25（07 2015）012013'
- en: '[121] Kumar, N., Anouncia, S., Madhavan, P.: Application of satellite remote
    sensing to find soil fertilization by using soil colour. International Journal
    of Online Engineering 9 (05 2013)'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] Kumar, N., Anouncia, S., Madhavan, P.: 应用卫星遥感通过土壤颜色寻找土壤施肥情况。国际在线工程期刊
    9（05 2013）'
- en: '[122] Geocento: Online provider of satellite and drone imagery'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] Geocento: 在线卫星和无人机图像提供商'
- en: '[123] Unknown: 7 top free satellite imagery sources in 2019. Earth Observatory
    System (2019)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] Unknown: 2019年7大免费卫星图像资源。地球观测系统（2019）'
- en: '[124] Unknown: Agriculture overview. ESA Earth Online'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] Unknown: 农业概述。ESA Earth Online'
- en: '[125] Giuffrida, M.V., Scharr, H., Tsaftaris, S.A.: Arigan: Synthetic arabidopsis
    plants using generative adversarial network. 2017 IEEE International Conference
    on Computer Vision Workshops (ICCVW) (2017) 2064–2071'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] Giuffrida, M.V., Scharr, H., Tsaftaris, S.A.: Arigan：利用生成对抗网络合成的拟南芥植物。2017
    IEEE 计算机视觉国际会议研讨会（ICCVW）（2017）2064–2071'
- en: '[126] Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley,
    D., Ozair, S., Courville, A.C., Bengio, Y.: Generative adversarial networks. ArXiv
    abs/1406.2661 (2014)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley,
    D., Ozair, S., Courville, A.C., Bengio, Y.: 生成对抗网络。ArXiv abs/1406.2661（2014）'
- en: '[127] Zhu, Y., Aoun, M., Krijn, M., Vanschoren, J.: Data augmentation using
    conditional generative adversarial networks for leaf counting in arabidopsis plants.
    In: BMVC. (2018)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] Zhu, Y., Aoun, M., Krijn, M., Vanschoren, J.: 使用条件生成对抗网络进行数据增强，用于拟南芥植物的叶片计数。在:
    BMVC。（2018）'
- en: '[128] Kuznichov, D., Zvirin, A., Honen, Y., Kimmel, R.: Data augmentation for
    leaf segmentation and counting tasks in rosette plants. In: CVPR Workshops. (2019)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] Kuznichov, D., Zvirin, A., Honen, Y., Kimmel, R.: 用于叶片分割和计数任务的数据增强，针对玫瑰花植物。在:
    CVPR 研讨会。（2019）'
- en: '[129] Nazki, H., Yoon, S., Fuentes, A., Park, D.S.: Unsupervised image translation
    using adversarial networks for improved plant disease recognition. Comput. Electron.
    Agric. 168 (2019)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] Nazki, H., Yoon, S., Fuentes, A., Park, D.S.: 使用对抗网络进行的无监督图像翻译，以改善植物病害识别。Comput.
    Electron. Agric. 168 (2019)'
- en: '[130] Cap, Q.H., Uga, H., Kagiwada, S., Iyatomi, H.: Leafgan: An effective
    data augmentation method for practical plant disease diagnosis. (2020)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] Cap, Q.H., Uga, H., Kagiwada, S., Iyatomi, H.: Leafgan：一种有效的数据增强方法，用于实际的植物病害诊断。
    (2020)'
- en: '[131] Sun, R., Zhang, M., Yang, K.: Data enhancement for plant disease classification
    using generated lesions. (2020)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] Sun, R., Zhang, M., Yang, K.: 使用生成病斑的数据增强进行植物病害分类。 (2020)'
- en: '[132] Sapoukhina, N., Samiei, S., Rasti, P., Rousseau, D.: Data augmentation
    from rgb to chlorophyll fluorescence imaging application to leaf segmentation
    of arabidopsis thaliana from top view images. In: CVPR Workshops. (2019)'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] Sapoukhina, N., Samiei, S., Rasti, P., Rousseau, D.: 从RGB到叶绿素荧光成像的数据增强应用于从顶视图图像中分割拟南芥。
    在：CVPR Workshops。 (2019)'
- en: '[133] Bellocchio, E., Ciarfuglia, T., Costante, G., Valigi, P.: Weakly supervised
    fruit counting for yield estimation using spatial consistency. IEEE Robotics and
    Automation Letters PP (03 2019) 1–1'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] Bellocchio, E., Ciarfuglia, T., Costante, G., Valigi, P.: 利用空间一致性的弱监督水果计数用于产量估算。IEEE
    Robotics and Automation Letters PP (03 2019) 1–1'
- en: '[134] Marino, S., Beauseroy, P., Smolarz, A.: Weakly-supervised learning approach
    for potato defects segmentation. Engineering Applications of Artificial Intelligence
    85 (07 2019) 337–346'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] Marino, S., Beauseroy, P., Smolarz, A.: 用于土豆缺陷分割的弱监督学习方法。人工智能工程应用 85
    (07 2019) 337–346'
- en: '[135] Desai, S.V., Chandra, A.L., Guo, W., Ninomiya, S., Balasubramanian, V.N.:
    An adaptive supervision framework for active learning in object detection. British
    Machine Vision Conference (2019)'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] Desai, S.V., Chandra, A.L., Guo, W., Ninomiya, S., Balasubramanian, V.N.:
    一种用于目标检测的主动学习的自适应监督框架。英国机器视觉会议 (2019)'
- en: '[136] Mehdipour-Ghazi, M., Yanikoglu, B.A., Aptoula, E.: Plant identification
    using deep neural networks via optimization of transfer learning parameters. Neurocomputing
    235 (2017) 228–235'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] Mehdipour-Ghazi, M., Yanikoglu, B.A., Aptoula, E.: 通过优化迁移学习参数的深度神经网络进行植物识别。Neurocomputing
    235 (2017) 228–235'
- en: '[137] Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Li, F.F.: Imagenet:
    a large-scale hierarchical image database. (06 2009) 248–255'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Li, F.F.: Imagenet：一个大规模的层次化图像数据库。
    (06 2009) 248–255'
- en: '[138] Joly, A., Goëau, H., Spampinato, C., Bonnet, P., Vellinga, W.P., Planqué,
    R., Rauber, A., Palazzo, S., Fisher, B., Müller, H.: Lifeclef 2015: Multimedia
    life species identification challenges. (09 2015)'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] Joly, A., Goëau, H., Spampinato, C., Bonnet, P., Vellinga, W.P., Planqué,
    R., Rauber, A., Palazzo, S., Fisher, B., Müller, H.: Lifeclef 2015：多媒体生命物种识别挑战。
    (09 2015)'
- en: '[139] Xu, W., Yu, G., Zare, A., Zurweller, B., Rowland, D., Reyes-Cabrera,
    J., Fritschi, F.B., Matamala, R., Juenger, T.E.: Overcoming small minirhizotron
    datasets using transfer learning. ArXiv abs/1903.09344 (2019)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] Xu, W., Yu, G., Zare, A., Zurweller, B., Rowland, D., Reyes-Cabrera,
    J., Fritschi, F.B., Matamala, R., Juenger, T.E.: 使用迁移学习克服小型微根孔数据集。ArXiv abs/1903.09344
    (2019)'
- en: '[140] Malpe, S.: Automated leaf disease detection and treatment recommendation
    using transfer learning. (2019)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] Malpe, S.: 使用迁移学习的自动化叶片病害检测和治疗推荐。 (2019)'
- en: '[141] Bellocchio, E., Costante, G., Cascianelli, S., Fravolini, m., Valigi,
    P.: Combining domain adaptation and spatial consistency for unseen fruits counting:
    A quasi-unsupervised approach. IEEE Robotics and Automation Letters 5 (01 2020)
    1–1'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] Bellocchio, E., Costante, G., Cascianelli, S., Fravolini, m., Valigi,
    P.: 结合领域适应和空间一致性进行未见水果计数：一种准无监督的方法。IEEE Robotics and Automation Letters 5 (01
    2020) 1–1'
- en: '[142] Chandra, A.L., Desai, S.V., Balasubramanian, V.N., Ninomiya, S., Guo,
    W.: Active learning with point supervision for cost-effective panicle detection
    in cereal crops. BMC Plant Methods (2020)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] Chandra, A.L., Desai, S.V., Balasubramanian, V.N., Ninomiya, S., Guo,
    W.: 带有点监督的主动学习，用于谷物作物中的经济高效的穗检测。BMC Plant Methods (2020)'
- en: '[143] Settles, B.: Active learning literature survey. Technical report, University
    of Wisconsin–Madison (2010)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] Settles, B.: 主动学习文献综述。技术报告，威斯康星大学麦迪逊分校 (2010)'
- en: '[144] Gal, Y., Islam, R., Ghahramani, Z.: Deep bayesian active learning with
    image data. In: ICML. (2017)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] Gal, Y., Islam, R., Ghahramani, Z.: 基于图像数据的深度贝叶斯主动学习。在：ICML。 (2017)'
- en: '[145] Sener, O., Savarese, S.: Active learning for convolutional neural networks:
    A core-set approach. In: ICLR 2018\. (2018)'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] Sener, O., Savarese, S.: 用于卷积神经网络的主动学习：一种核心集方法。在：ICLR 2018。 (2018)'
- en: '[146] Wang, K., Zhang, D., Li, Y., Zhang, R., Lin, L.: Cost-effective active
    learning for deep image classification. IEEE Trans. Cir. and Sys. for Video Technol.
    27(12) (December 2017) 2591–2600'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] Wang, K., Zhang, D., Li, Y., Zhang, R., Lin, L.：用于深度图像分类的成本效益高的主动学习。《IEEE视频技术电路与系统汇刊》27(12)（2017年12月）2591–2600'
- en: '[147] Brust, C., Käding, C., Denzler, J.: Active learning for deep object detection.
    CoRR abs/1809.09875 (2018)'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] Brust, C., Käding, C., Denzler, J.：深度目标检测的主动学习。CoRR abs/1809.09875（2018年）'
- en: '[148] Roy, S., Unmesh, A., Namboodiri, V.P.: Deep active learning for object
    detection. In: BMVC. (2018)'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] Roy, S., Unmesh, A., Namboodiri, V.P.：用于目标检测的深度主动学习。会议论文：BMVC。（2018年）'
- en: '[149] Vijayanarasimhan, S., Grauman, K.: Large-scale live active learning:
    Training object detectors with crawled data and crowds. International Journal
    of Computer Vision 108(1) (May 2014) 97–114'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] Vijayanarasimhan, S., Grauman, K.：大规模实时主动学习：利用抓取的数据和众包训练目标检测器。《计算机视觉国际期刊》108(1)（2014年5月）97–114'
