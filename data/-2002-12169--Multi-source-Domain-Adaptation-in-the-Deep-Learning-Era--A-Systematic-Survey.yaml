- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:02:20'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:02:20
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2002.12169] Multi-source Domain Adaptation in the Deep Learning Era: A Systematic
    Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2002.12169] 深度学习时代的多源领域适应：系统综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2002.12169](https://ar5iv.labs.arxiv.org/html/2002.12169)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2002.12169](https://ar5iv.labs.arxiv.org/html/2002.12169)
- en: 'Multi-source Domain Adaptation in the Deep Learning Era:'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习时代的多源领域适应：
- en: A Systematic Survey
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 系统综述
- en: Sicheng Zhao¹    Bo Li¹    Colorado Reed¹    Pengfei Xu²    Kurt Keutzer¹
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 孙成赵¹    李博¹    科罗拉多·里德¹    许鹏飞²    库尔特·凯策¹
- en: ¹University of California, Berkeley, USA      ²Didi Chuxing, China
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ¹加州大学伯克利分校，美国      ²滴滴出行，中国
- en: schzhao@gmail.com, drluodian@gmail.com, cjrd@cs.berkeley.edu,
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: schzhao@gmail.com, drluodian@gmail.com, cjrd@cs.berkeley.edu,
- en: xupengfeipf@didiglobal.com, keutzer@berkeley.edu
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: xupengfeipf@didiglobal.com, keutzer@berkeley.edu
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: In many practical applications, it is often difficult and expensive to obtain
    enough large-scale labeled data to train deep neural networks to their full capability.
    Therefore, transferring the learned knowledge from a separate, labeled source
    domain to an unlabeled or sparsely labeled target domain becomes an appealing
    alternative. However, direct transfer often results in significant performance
    decay due to *domain shift*. Domain adaptation (DA) addresses this problem by
    minimizing the impact of domain shift between the source and target domains. Multi-source
    domain adaptation (MDA) is a powerful extension in which the labeled data may
    be collected from multiple sources with different distributions. Due to the success
    of DA methods and the prevalence of multi-source data, MDA has attracted increasing
    attention in both academia and industry. In this survey, we define various MDA
    strategies and summarize available datasets for evaluation. We also compare modern
    MDA methods in the deep learning era, including latent space transformation and
    intermediate domain generation. Finally, we discuss future research directions
    for MDA.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多实际应用中，通常很难且昂贵地获得足够的大规模标注数据，以充分训练深度神经网络。因此，将从单独的标注源领域获得的知识迁移到未标注或稀疏标注的目标领域成为一种有吸引力的替代方案。然而，直接迁移往往会因*领域偏移*而导致显著的性能下降。领域适应（DA）通过最小化源领域和目标领域之间领域偏移的影响来解决这一问题。多源领域适应（MDA）是一种强大的扩展，其中标注数据可以来自具有不同分布的多个来源。由于DA方法的成功以及多源数据的普遍存在，MDA在学术界和工业界都受到越来越多的关注。在本综述中，我们定义了各种MDA策略并总结了用于评估的现有数据集。我们还比较了深度学习时代的现代MDA方法，包括潜在空间变换和中间领域生成。最后，我们讨论了MDA的未来研究方向。
- en: 1 Background and Motivation
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 背景和动机
- en: The availability of large-scale labeled training data, such as ImageNet, has
    enabled deep neural networks (DNNs) to achieve remarkable success in many learning
    tasks, ranging from computer vision to natural language processing. For example,
    the classification error of the “Classification + localization with provided training
    data” task in the Large Scale Visual Recognition Challenge has reduced from 0.28
    in 2010 to 0.0225 in 2017¹¹1[http://image-net.org/challenges/LSVRC/2017](http://image-net.org/challenges/LSVRC/2017),
    outperforming even human classification. However, in many practical applications,
    obtaining labeled training data is often expensive, time-consuming, or even impossible.
    For example, in fine-grained recognition, only the experts can provide reliable
    labels Gebru et al. ([2017](#bib.bib10)); in semantic segmentation, it takes about
    90 minutes to label each Cityscapes image Cordts et al. ([2016](#bib.bib6)); in
    autonomous driving, it is difficult to label point-wise 3D LiDAR point clouds Wu
    et al. ([2019](#bib.bib49)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模标注训练数据的可用性，如ImageNet，已使深度神经网络（DNNs）在许多学习任务中取得了显著成功，从计算机视觉到自然语言处理。例如，在大规模视觉识别挑战赛中，“分类
    + 提供的训练数据定位”任务的分类错误率已从2010年的0.28降至2017年的0.0225¹¹1[http://image-net.org/challenges/LSVRC/2017](http://image-net.org/challenges/LSVRC/2017)，甚至超过了人类分类。然而，在许多实际应用中，获取标注训练数据通常是昂贵、耗时甚至不可能的。例如，在细粒度识别中，只有专家才能提供可靠的标签Gebru
    et al. ([2017](#bib.bib10))；在语义分割中，标注每个Cityscapes图像需要约90分钟Cordts et al. ([2016](#bib.bib6))；在自动驾驶中，标注逐点3D
    LiDAR点云是困难的Wu et al. ([2019](#bib.bib49))。
- en: '![Refer to caption](img/f948c1eb7f96cf11f8fe10793a1a7a99.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f948c1eb7f96cf11f8fe10793a1a7a99.png)'
- en: 'Figure 1: An example of *domain shift* in the single-source scenario. The models
    trained on the labeled source domain do not perform well when directly transferring
    to the target domain.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：单一来源场景中*领域偏移*的示例。在标注的源领域上训练的模型在直接转移到目标领域时表现不佳。
- en: 'One potential solution is to transfer a model trained on a separate, labeled
    source domain to the desired unlabeled or sparsely labeled target domain. But
    as Figure [1](#S1.F1 "Figure 1 ‣ 1 Background and Motivation ‣ Multi-source Domain
    Adaptation in the Deep Learning Era: A Systematic Survey") demonstrates, the direct
    transfer of models across domains leads to poor performance. Figure [1](#S1.F1
    "Figure 1 ‣ 1 Background and Motivation ‣ Multi-source Domain Adaptation in the
    Deep Learning Era: A Systematic Survey")(a) shows that even for the simple task
    of digit recognition, training on the MNIST source domain LeCun et al. ([1998](#bib.bib21))
    for digit classification in the MNIST-M target domain  Ganin and Lempitsky ([2015](#bib.bib8))
    leads to a digit classification accuracy decrease from 96.0% to 52.3% when training
    a LeNet-5 model LeCun et al. ([1998](#bib.bib21)). Figure [1](#S1.F1 "Figure 1
    ‣ 1 Background and Motivation ‣ Multi-source Domain Adaptation in the Deep Learning
    Era: A Systematic Survey")(b) shows a more realistic example of training a semantic
    segmentation model on a synthetic source dataset GTA Richter et al. ([2016](#bib.bib35))
    and conducting pixel-wise segmentation on a real target dataset Cityscapes Cordts
    et al. ([2016](#bib.bib6)) using the FCN model Long et al. ([2015a](#bib.bib26)).
    If we train on the real data, we obtain a mean intersection-over-union (mIoU)
    of 62.6%; but if we train on synthetic data, the mIoU drops significantly to 21.7%.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '一种潜在的解决方案是将训练于一个独立标注源领域的模型转移到所需的未标注或稀疏标注的目标领域。但正如图[1](#S1.F1 "Figure 1 ‣ 1
    Background and Motivation ‣ Multi-source Domain Adaptation in the Deep Learning
    Era: A Systematic Survey")所示，模型在领域间的直接转移会导致性能差。图[1](#S1.F1 "Figure 1 ‣ 1 Background
    and Motivation ‣ Multi-source Domain Adaptation in the Deep Learning Era: A Systematic
    Survey")(a)显示，即使是简单的数字识别任务，在MNIST源领域上训练LeCun等人（[1998](#bib.bib21)）的LeNet-5模型，用于MNIST-M目标领域的数字分类时，准确率从96.0%降至52.3%。图[1](#S1.F1
    "Figure 1 ‣ 1 Background and Motivation ‣ Multi-source Domain Adaptation in the
    Deep Learning Era: A Systematic Survey")(b)显示了一个更现实的例子，即在合成源数据集GTA Richter等人（[2016](#bib.bib35)）上训练语义分割模型，并在真实目标数据集Cityscapes
    Cordts等人（[2016](#bib.bib6)）上进行像素级分割，使用FCN模型 Long等人（[2015a](#bib.bib26)）。如果我们在真实数据上训练，得到的平均交并比（mIoU）为62.6%；但如果我们在合成数据上训练，mIoU显著降至21.7%。'
- en: '![Refer to caption](img/323f587cc2833042cdc7a23950abb24b.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/323f587cc2833042cdc7a23950abb24b.png)'
- en: 'Figure 2: An example of *domain shift* in the multi-source scenario. Combining
    multiple sources into one source and directly performing single-source domain
    adaptation on the entire dataset does not guarantee better performance compared
    to just using the best individual source domain.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：多来源场景中*领域偏移*的示例。将多个来源合并为一个来源，并直接对整个数据集进行单一来源领域适配，并不能保证比仅使用最佳单一源领域有更好的表现。
- en: 'The poor performance from directly transferring models across domains stems
    from a phenomenon known as *domain shift* Torralba and Efros ([2011](#bib.bib44));
    Zhao et al. ([2018b](#bib.bib57)): whereby the joint probability distributions
    of observed data and labels are different in the two domains. Domain shift exists
    in many forms, such as from dataset to dataset, from simulation to real-world,
    from RGB images to depth, and from CAD models to real images.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在领域间直接转移的低性能源于一种称为*领域偏移*的现象 Torralba和Efros（[2011](#bib.bib44)）；赵等人（[2018b](#bib.bib57)）：即在两个领域中的观察数据和标签的联合概率分布不同。领域偏移存在多种形式，如数据集间、模拟到现实、RGB图像到深度图像，以及CAD模型到真实图像。
- en: 'The phenomenon of domain shift motivates the research on domain adaptation
    (DA), which aims to learn a model from a labeled source domain that can generalize
    well to a different, but related, target domain. Existing DA methods mainly focus
    on the single-source scenario. In the deep learning era, recent single-source
    DA (SDA) methods usually employ a conjoined architecture with two approaches to
    respectively represent the models for the source and target domains. One approach
    aims to learn a task model based on the labeled source data using corresponding
    task losses, such as cross-entropy loss for classification. The other approach
    aims to deal with the domain shift by aligning the target and source domains.
    Based on the alignment strategies, deep SDA methods can be classified into four
    categories:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 域迁移现象激发了对领域适应（DA）的研究，其旨在从标记的源领域中学习一个能够在不同但相关的目标领域中良好泛化的模型。现有的 DA 方法主要集中在单源场景下。在深度学习时代，最近的单源
    DA（SDA）方法通常采用一个联合架构，分别表示源领域和目标领域的模型。一种方法旨在基于标记的源数据使用相应的任务损失来学习任务模型，例如分类的交叉熵损失。另一种方法旨在通过对齐目标领域和源领域来处理领域迁移。根据对齐策略，深度
    SDA 方法可以分为四类：
- en: '1.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: '*Discrepancy-based methods* try to align the features by explicitly measuring
    the discrepancy on corresponding activation layers, such as maximum mean discrepancy
    (MMD) Long et al. ([2015b](#bib.bib27)), correlation alignment Sun et al. ([2017](#bib.bib43)),
    and contrastive domain discrepancy Kang et al. ([2019](#bib.bib20)).'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*差异性基础方法*尝试通过显式测量对应激活层上的差异来对齐特征，例如最大均值差异（MMD）Long 等人（[2015b](#bib.bib27)），相关对齐
    Sun 等人（[2017](#bib.bib43)），以及对比领域差异 Kang 等人（[2019](#bib.bib20)）。'
- en: '2.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: '*Adversarial generative methods* generate fake data to align the source and
    target domains at pixel-level based on Generative Adversarial Network (GAN) Goodfellow
    et al. ([2014](#bib.bib13)) and its variants, such as CycleGAN Zhu et al. ([2017](#bib.bib61));
    Zhao et al. ([2019b](#bib.bib59)).'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*对抗生成方法*基于生成对抗网络（GAN）Goodfellow 等人（[2014](#bib.bib13)）及其变体，如 CycleGAN Zhu 等人（[2017](#bib.bib61)）；Zhao
    等人（[2019b](#bib.bib59)）生成虚假数据，以在像素级别对齐源和目标领域。'
- en: '3.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: '*Adversarial discriminative methods* employ an adversarial objective with a
    domain discriminator to align the features Tzeng et al. ([2017](#bib.bib46));
    Tsai et al. ([2018](#bib.bib45)).'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*对抗判别方法*采用对抗目标与领域判别器来对齐特征 Tzeng 等人（[2017](#bib.bib46)）；Tsai 等人（[2018](#bib.bib45)）。'
- en: '4.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: '*Reconstruction based methods* aim to reconstruct the target input from the
    extracted features using the source task model Ghifary et al. ([2016](#bib.bib11)).'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*重建基础方法*旨在使用源任务模型 Ghifary 等人（[2016](#bib.bib11)）从提取的特征中重建目标输入。'
- en: 'In practice, the labeled data may be collected from multiple sources with different
    distributions Sun et al. ([2015](#bib.bib42)); Bhatt et al. ([2016](#bib.bib2)).
    In such cases, the aforementioned SDA methods could be trivially applied by combining
    the sources into a single source: an approach we refer to as *source-combined
    DA*. However, source-combined DA oftentimes results in a poorer performance than
    simply using one of the sources and discarding the others. As illustrated in Figure [2](#S1.F2
    "Figure 2 ‣ 1 Background and Motivation ‣ Multi-source Domain Adaptation in the
    Deep Learning Era: A Systematic Survey"), the accuracy on the best single source
    digit recognition adaptation using DANN Ganin et al. ([2016](#bib.bib9)) is 71.3%,
    while the source-combined accuracy drops to 70.8%. For segmentation adaptation
    using CyCADA Hoffman et al. ([2018b](#bib.bib18)), the mIoU of source-combined
    DA (37.3%) is also lower than that of SDA from GTA (38.7%). Because the domain
    shift not only exists between each source and target, but also exists among different
    sources, the source-combined data from different sources may interfere with each
    other during the learning process Riemer et al. ([2019](#bib.bib36)). Therefore,
    multi-source domain adaptation (MDA) is needed in order to leverage all of the
    available data.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '实际中，标注数据可能来自多个具有不同分布的源 Sun 等 ([2015](#bib.bib42))；Bhatt 等 ([2016](#bib.bib2))。在这种情况下，前述
    SDA 方法可以通过将源组合成一个单一源来简单应用：我们称之为 *源合并 DA*。然而，源合并 DA 往往比仅使用其中一个源而丢弃其他源的表现更差。如图 [2](#S1.F2
    "Figure 2 ‣ 1 Background and Motivation ‣ Multi-source Domain Adaptation in the
    Deep Learning Era: A Systematic Survey") 所示，使用 DANN Ganin 等 ([2016](#bib.bib9))
    进行的最佳单一源数字识别适应的准确率为 71.3%，而源合并准确率降至 70.8%。对于使用 CyCADA Hoffman 等 ([2018b](#bib.bib18))
    的分割适应，源合并 DA 的 mIoU（37.3%）也低于来自 GTA 的 SDA（38.7%）。由于领域偏移不仅存在于每个源和目标之间，还存在于不同源之间，因此来自不同源的源合并数据可能在学习过程中相互干扰
    Riemer 等 ([2019](#bib.bib36))。因此，需要多源领域适应（MDA）以利用所有可用数据。'
- en: The early MDA methods mainly focus on shallow models Sun et al. ([2015](#bib.bib42)),
    either learning a latent feature space for different domains Sun et al. ([2011](#bib.bib41));
    Duan et al. ([2012](#bib.bib7)) or combining pre-learned source classifiers Schweikert
    et al. ([2009](#bib.bib40)). Recently, the emphasis on MDA has shifted to deep
    learning architectures. In this paper, we systematically survey recent progress
    on deep learning based MDA, summarize and compare similarities and differences
    in the approaches, and discuss potential future research directions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的 MDA 方法主要集中在浅层模型上 Sun 等 ([2015](#bib.bib42))，要么学习不同领域的潜在特征空间 Sun 等 ([2011](#bib.bib41));
    Duan 等 ([2012](#bib.bib7))，要么结合预先学习的源分类器 Schweikert 等 ([2009](#bib.bib40))。最近，MDA
    的重点已转向深度学习架构。在本文中，我们系统地调查了基于深度学习的 MDA 的最新进展，总结并比较了方法的相似性和差异，并讨论了潜在的未来研究方向。
- en: 2 Problem Definition
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 问题定义
- en: In the typical MDA setting, there are multiple source domains $S_{1},S_{2},\cdots,S_{M}$
    ($M$ is the number of sources) and one target domain $T$. Suppose the observed
    data and corresponding labels²²2The label could be any type, such as object classes,
    bounding boxes, semantic segmentation, etc. in the $i^{\text{th}}$ source $S_{i}$
    are drawn from distribution $p_{i}(\mathbf{x},\mathbf{y})$ are $\textbf{X}_{i}=\{\textbf{x}_{i}^{j}\}_{j=1}^{N_{i}}$
    and $Y_{i}=\{\mathbf{y}_{i}^{j}\}_{j=1}^{N_{i}}$, respectively, where $N_{i}$
    is the number of source samples. Let $X_{T}=\{\mathbf{x}_{T}^{j}\}_{j=1}^{N_{T}}$
    and $Y_{T}=\{\mathbf{y}_{T}^{j}\}_{j=1}^{N_{T}}$ denote the target data and corresponding
    labels drawn from the target distribution $P_{T}(\textbf{x},\mathbf{y})$, where
    $N_{T}$ is the number of target samples.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在典型的 MDA 设置中，有多个源领域 $S_{1},S_{2},\cdots,S_{M}$ （$M$ 是源的数量）和一个目标领域 $T$。假设在第 $i^{\text{th}}$
    个源 $S_{i}$ 中观察到的数据和相应的标签²²2 标签可以是任何类型，例如物体类别、边界框、语义分割等，它们来自分布 $p_{i}(\mathbf{x},\mathbf{y})$，分别为
    $\textbf{X}_{i}=\{\textbf{x}_{i}^{j}\}_{j=1}^{N_{i}}$ 和 $Y_{i}=\{\mathbf{y}_{i}^{j}\}_{j=1}^{N_{i}}$，其中
    $N_{i}$ 是源样本的数量。令 $X_{T}=\{\mathbf{x}_{T}^{j}\}_{j=1}^{N_{T}}$ 和 $Y_{T}=\{\mathbf{y}_{T}^{j}\}_{j=1}^{N_{T}}$
    表示从目标分布 $P_{T}(\textbf{x},\mathbf{y})$ 中抽取的目标数据和相应的标签，其中 $N_{T}$ 是目标样本的数量。
- en: 'Suppose the number of labeled target samples is $N_{TL}$, the MDA problem can
    be classified into different categories:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 假设标注目标样本的数量为 $N_{TL}$，MDA 问题可以分类为不同的类别：
- en: •
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*unsupervised MDA*, when $N_{TL}=0$;'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*无监督 MDA*，当 $N_{TL}=0$；'
- en: •
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*fully supervised MDA*, when $N_{TL}=N_{T}$;'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*完全监督 MDA*，当 $N_{TL}=N_{T}$；'
- en: •
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*semi-supervised MDA*, otherwise.'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*半监督 MDA*，否则。'
- en: '| Area | Task | Dataset | Reference | #D | #S | Labels | Short description
    |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 区域 | 任务 | 数据集 | 参考文献 | #D | #S | 标签 | 简短描述 |'
- en: '| CV | digit recognition | Digits-five (D) | [LeCun et al.](#bib.bib21); [Netzer
    et al.](#bib.bib31) | 5 | 145,298 | 10 classes | handwritten, synthetic, and street-image
    digits |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| CV | 数字识别 | Digits-five (D) | [LeCun et al.](#bib.bib21); [Netzer et al.](#bib.bib31)
    | 5 | 145,298 | 10 类别 | 手写、合成和街道图像数字 |'
- en: '| [Hull](#bib.bib19); [Ganin and Lempitsky](#bib.bib8) |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| [Hull](#bib.bib19); [Ganin and Lempitsky](#bib.bib8) |'
- en: '| object classification | Office-31 (O) | [Saenko et al.](#bib.bib39) | 3 |
    4,110 | 31 classes | images from amazon and taken by different cameras |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 对象分类 | Office-31 (O) | [Saenko et al.](#bib.bib39) | 3 | 4,110 | 31 类别 |
    来自亚马逊的图像和不同相机拍摄的图像 |'
- en: '| Office-Caltech (OC) | [Gong et al.](#bib.bib12) | 4 | 2,533 | 10 classes
    | overlapping categories from Office-31 and C |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| Office-Caltech (OC) | [Gong et al.](#bib.bib12) | 4 | 2,533 | 10 类别 | 来自
    Office-31 和 C 的重叠类别 |'
- en: '| Office-Home (OH) | [Venkateswara et al.](#bib.bib47) | 4 | 15,500 | 65 classes
    | artistic, clipart, product, and real objects |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| Office-Home (OH) | [Venkateswara et al.](#bib.bib47) | 4 | 15,500 | 65 类别
    | 艺术品、剪贴画、产品和真实物体 |'
- en: '| ImageCLEF (IC) | Challenge^([3](#footnote3 "footnote 3 ‣ 3 Datasets ‣ Multi-source
    Domain Adaptation in the Deep Learning Era: A Systematic Survey")) | 3 | 1,800
    | 12 classes | shared categories from 3 datasets |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| ImageCLEF (IC) | 挑战^([3](#footnote3 "脚注 3 ‣ 3 数据集 ‣ 深度学习时代的多源领域适应：系统综述"))
    | 3 | 1,800 | 12 类别 | 来自 3 个数据集的共享类别 |'
- en: '| PACS (P) | [Li et al.](#bib.bib22) | 4 | 9,991 | 7 classes | photographic,
    artistic, cartoon, and sketchy objects |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| PACS (P) | [Li et al.](#bib.bib22) | 4 | 9,991 | 7 类别 | 摄影、艺术、卡通和草图物体 |'
- en: '| DomainNet (DN) | [Peng et al.](#bib.bib32) | 6 | 600,000 | 345 classes |
    clipart, infographic, artistic, quickdrawn, real, and sketchy objects |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| DomainNet (DN) | [Peng et al.](#bib.bib32) | 6 | 600,000 | 345 类别 | 剪贴画、信息图、艺术品、快速绘图、真实物体和草图物体
    |'
- en: '| sentiment classification | SentiImage (SI) | [Machajdik and Hanbury](#bib.bib28)
    | 4 | 25,986 | 2 classes | artistic and social images on visual sentiment |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 情感分类 | SentiImage (SI) | [Machajdik and Hanbury](#bib.bib28) | 4 | 25,986
    | 2 类别 | 关于视觉情感的艺术和社交图像 |'
- en: '| [You et al.](#bib.bib52); [You et al.](#bib.bib51); [Borth et al.](#bib.bib4)
    |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| [You et al.](#bib.bib52); [You et al.](#bib.bib51); [Borth et al.](#bib.bib4)
    |'
- en: '|  | vehicle counting | WebCamT (W) | [Zhang et al.](#bib.bib55) | 8 | 16,000
    | vehicle counts | each camera used as one domain |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|  | 车辆计数 | WebCamT (W) | [Zhang et al.](#bib.bib55) | 8 | 16,000 | 车辆计数 |
    每个相机作为一个领域 |'
- en: '|  | semantic segmentation | Sim2RealSeg (S2R) | [Cordts et al.](#bib.bib6);
    [Yu et al.](#bib.bib53) | 4 | 49,366 | 16 classes | simulation-to-real adaptation
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | 语义分割 | Sim2RealSeg (S2R) | [Cordts et al.](#bib.bib6); [Yu et al.](#bib.bib53)
    | 4 | 49,366 | 16 类别 | 模拟到真实的适应 |'
- en: '|  | [Richter et al.](#bib.bib35); [Ros et al.](#bib.bib37) | for pixel-wise
    predictions |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  | [Richter et al.](#bib.bib35); [Ros et al.](#bib.bib37) | 用于像素级预测 |'
- en: '| NLP | sentiment classification | AmazonReviews (AR) | [Chen et al.](#bib.bib5)
    | 4 | $\approx$12,000 | 2 classes | reviews on four kinds of products |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| NLP | 情感分类 | AmazonReviews (AR) | [Chen et al.](#bib.bib5) | 4 | $\approx$12,000
    | 2 类别 | 四种产品的评论 |'
- en: '| MediaReviews (MR) | [Liu et al.](#bib.bib25) | 5 | 6897 | 2 classes | reviews
    on products and movies |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| MediaReviews (MR) | [Liu et al.](#bib.bib25) | 5 | 6897 | 2 类别 | 产品和电影的评论
    |'
- en: '| part-of-speech tagging | SANCL (S) | [Petrov and McDonald](#bib.bib33) |
    5 | 5250 | tags | part-of-speech tagging in 5 web domains |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 词性标注 | SANCL (S) | [Petrov and McDonald](#bib.bib33) | 5 | 5250 | 标签 | 在
    5 个网页领域中的词性标注 |'
- en: 'Table 1: Released and freely available datasets for MDA, where ‘#D’ and ‘#S’
    represent the number of domains and the total number of samples usually used for
    MDA, respectively.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：用于 MDA 的公开和免费数据集，其中“#D”和“#S”分别表示领域数量和通常用于 MDA 的样本总数。
- en: 'Suppose $\textbf{x}_{i}^{j}\in\mathds{R}^{d_{i}}$ and $\textbf{x}_{T}^{j}\in\mathds{R}^{d_{T}}$
    are an observation in source $S_{i}$ and target $T$, we can classify MDA into:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 $\textbf{x}_{i}^{j}\in\mathds{R}^{d_{i}}$ 和 $\textbf{x}_{T}^{j}\in\mathds{R}^{d_{T}}$
    是源 $S_{i}$ 和目标 $T$ 中的观察值，我们可以将 MDA 分类为：
- en: •
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*homogeneous MDA*, when $d_{1}=\cdots=d_{M}=d_{T}$;'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*同质 MDA*，当 $d_{1}=\cdots=d_{M}=d_{T}$；'
- en: •
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*heterogeneous MDA*, otherwise.'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*异质 MDA*，否则。'
- en: 'Suppose $\mathcal{C}_{i}$ and $\mathcal{C}_{T}$ are the label set for source
    $S_{i}$ and target $T$, we can define different MDA strategies:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 $\mathcal{C}_{i}$ 和 $\mathcal{C}_{T}$ 是源 $S_{i}$ 和目标 $T$ 的标签集，我们可以定义不同的 MDA
    策略：
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*closed set MDA*, when $\mathcal{C}_{1}=\cdots=\mathcal{C}_{M}=\mathcal{C}_{T}$;'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*闭集 MDA*，当 $\mathcal{C}_{1}=\cdots=\mathcal{C}_{M}=\mathcal{C}_{T}$；'
- en: •
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*open set MDA*, for at least one $\mathcal{C}_{i}$, $\mathcal{C}_{i}\cap\mathcal{C}_{T}\subset\mathcal{C}_{T}$;'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*开集 MDA*，对于至少一个 $\mathcal{C}_{i}$，$\mathcal{C}_{i}\cap\mathcal{C}_{T}\subset\mathcal{C}_{T}$；'
- en: •
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*partial MDA*, for at least one $\mathcal{C}_{i}$, $\mathcal{C}_{T}\subset\mathcal{C}_{i}$;'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*部分 MDA*，对于至少一个 $\mathcal{C}_{i}$，$\mathcal{C}_{T}\subset\mathcal{C}_{i}$；'
- en: •
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*universal MDA*, when no prior knowledge of the label sets is available;'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*通用 MDA*，当没有标签集的先验知识时；'
- en: where $\cap$ and $\subset$ indicate the intersection set and proper subset between
    two sets.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\cap$ 和 $\subset$ 表示两个集合之间的交集和真子集。
- en: 'Suppose the number of labeled source samples is $N_{iL}$ for source $S_{i}$,
    the MDA problem can be classified into:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 假设标记源样本的数量是 $N_{iL}$ 对于源 $S_{i}$，MDA 问题可以分类为：
- en: •
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*strongly supervised MDA*, when $N_{iL}=N_{i}$ for $i=1\cdots M$;'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*强监督 MDA*，当 $N_{iL}=N_{i}$ 对于 $i=1\cdots M$；'
- en: •
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*weakly supervised MDA*, otherwise.'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*弱监督 MDA*，否则。'
- en: When adapting to multiple target domains simultaneously, the task becomes multi-target
    MDA. When the target data is unavailable during training Yue et al. ([2019](#bib.bib54)),
    the task is often called multi-source domain generalization or zero-shot MDA.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当同时适应多个目标领域时，任务变成多目标 MDA。当目标数据在训练过程中不可用时，Yue 等人 ([2019](#bib.bib54))，该任务通常称为多源领域泛化或零样本
    MDA。
- en: 3 Datasets
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 数据集
- en: 'The datasets for evaluating MDA models usually contain multiple domains with
    different styles, such as synthetic vs. real, artistic vs. sketchy, which impose
    large domain shift among different domains. Here we summarize the commonly employed
    datasets in both computer vision (CV) and natural language processing (NLP) areas,
    as shown in Table [1](#S2.T1 "Table 1 ‣ 2 Problem Definition ‣ Multi-source Domain
    Adaptation in the Deep Learning Era: A Systematic Survey").'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '用于评估 MDA 模型的数据集通常包含具有不同风格的多个领域，例如合成与真实、艺术与草图，这些都会在不同领域之间产生大的领域偏移。这里我们总结了在计算机视觉
    (CV) 和自然语言处理 (NLP) 领域中常用的数据集，如表 [1](#S2.T1 "Table 1 ‣ 2 Problem Definition ‣ Multi-source
    Domain Adaptation in the Deep Learning Era: A Systematic Survey") 所示。'
- en: Digit recognition. Digits-five includes 5 digit image datasets sampled from
    different domains, including *handwritten* MNIST (mt) LeCun et al. ([1998](#bib.bib21)),
    *combined* MNIST-M (mm) Ganin and Lempitsky ([2015](#bib.bib8)) from MNIST and
    randomly extracted color patches, *street image* SVHN (sv) Netzer et al. ([2011](#bib.bib31)),
    Synthetic Digits (sy) Ganin and Lempitsky ([2015](#bib.bib8)) generated from Windows
    fonts by various conditions, and *handwritten* USPS (up) Hull ([1994](#bib.bib19)).
    Usually, 25,000 images are sampled for training and 9,000 for testing in mt, mm,
    sv, and sy. The entire 9,298 images in up are selected.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 数字识别。Digits-five 包含来自不同领域的 5 个数字图像数据集，包括 *手写* MNIST (mt) LeCun 等人 ([1998](#bib.bib21))、*合成*
    MNIST-M (mm) Ganin 和 Lempitsky ([2015](#bib.bib8)) 从 MNIST 和随机提取的彩色补丁、*街景图像* SVHN
    (sv) Netzer 等人 ([2011](#bib.bib31))、由不同条件下的 Windows 字体生成的 Synthetic Digits (sy)
    Ganin 和 Lempitsky ([2015](#bib.bib8))，以及 *手写* USPS (up) Hull ([1994](#bib.bib19))。通常，mt、mm、sv
    和 sy 中的训练图像为 25,000 张，测试图像为 9,000 张。up 中的 9,298 张图像被全部选用。
- en: 'Object classification. Office-31 Saenko et al. ([2010](#bib.bib39)) contains
    4,110 images in 31 categories collected from office environments in 3 domains:
    Amazon (A) with 2,817 images downloaded from amazon.com, Webcam (W) and DSLR (D)
    with 795 and 498 images taken by web camera and digital SLR camera with different
    photographical settings.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对象分类。Office-31 Saenko 等人 ([2010](#bib.bib39)) 包含 31 个类别中的 4,110 张图像，这些图像来自 3
    个领域的办公室环境：Amazon (A) 包含 2,817 张从 amazon.com 下载的图像，Webcam (W) 和 DSLR (D) 分别包含 795
    和 498 张由网络摄像头和数码单反相机拍摄的图像，这些图像具有不同的摄影设置。
- en: Office-Caltech Gong et al. ([2013](#bib.bib12)) consists of the 10 overlapping
    categories shared by Office-31 Saenko et al. ([2010](#bib.bib39)) and Caltech-256
    (C) Griffin et al. ([2007](#bib.bib14)). Totally there are 2,533 images.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Office-Caltech Gong 等人 ([2013](#bib.bib12)) 包含了 Office-31 Saenko 等人 ([2010](#bib.bib39))
    和 Caltech-256 (C) Griffin 等人 ([2007](#bib.bib14)) 共享的 10 个重叠类别。总共有 2,533 张图像。
- en: 'Office-Home Venkateswara et al. ([2017](#bib.bib47)) consists of about 15,500
    images from 65 categories of everyday objects in office and home settings. There
    are 4 different domains: Artistic images (Ar), Clip Art (Cl), Product images (Pr)
    and Real-World images (Rw).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Office-Home Venkateswara 等人 ([2017](#bib.bib47)) 包含了约 15,500 张来自办公室和家庭环境中 65
    个日常物品类别的图像。共有 4 个不同的领域：艺术图像 (Ar)、剪贴画 (Cl)、产品图像 (Pr) 和现实世界图像 (Rw)。
- en: ImageCLEF, originated from ImageCLEF 2014 domain adaptation challenge³³3[http://imageclef.org/2014/adaptation](http://imageclef.org/2014/adaptation),
    consists of 12 object categories shared by ImageNet ILSVRC 2012 (I), Pascal VOC
    2012 (P), and C. Totally there are 600 images for each domain with 50 for each
    category.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ImageCLEF，源于ImageCLEF 2014领域适应挑战³³3[http://imageclef.org/2014/adaptation](http://imageclef.org/2014/adaptation)，包含12个对象类别，这些类别在ImageNet
    ILSVRC 2012 (I)、Pascal VOC 2012 (P) 和 C 中共享。每个领域总共有600张图片，每个类别50张。
- en: 'PACS Li et al. ([2017](#bib.bib22)) contains 9,991 images of 7 object categories
    extracted from 4 different domains: Photo (P), Art paintings (A), Cartoon (C)
    and Sketch (S).'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: PACS Li 等人（[2017](#bib.bib22)）包含了7个对象类别的9,991张图片，这些图片来自4个不同领域：照片 (P)、艺术画作 (A)、卡通
    (C) 和素描 (S)。
- en: 'DomainNet Peng et al. ([2019](#bib.bib32)), the largest DA dataset to date
    for object classification, contains about 600K images from 6 domains: Clipart,
    Infograph, Painting, Quickdraw, Real, and Sketch. There are totally 345 object
    categories.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: DomainNet Peng 等人（[2019](#bib.bib32)），目前为止最大的对象分类领域适应数据集，包含约60万张图片，来自6个领域：剪贴画、信息图、绘画、快速绘制、现实和素描。共有345个对象类别。
- en: 'Sentiment classification of images. SentiImage Lin et al. ([2020](#bib.bib24))
    is a DA dataset with 4 domains for binary sentiment classification of images:
    social Flickr and Instagram (FI) You et al. ([2016](#bib.bib52)), artistic ArtPhoto
    (AP) Machajdik and Hanbury ([2010](#bib.bib28)), social Twitter I (TI) You et
    al. ([2015](#bib.bib51)), and social Twitter II (TII) Borth et al. ([2013](#bib.bib4)).
    There are 23,308, 806, 1,269, and 603 images in these 4 domains, respectively.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图像情感分类。SentiImage Lin 等人（[2020](#bib.bib24)）是一个用于图像二分类情感分析的DA数据集，包含4个领域：社交Flickr和Instagram
    (FI) You 等人（[2016](#bib.bib52)）、艺术ArtPhoto (AP) Machajdik 和 Hanbury（[2010](#bib.bib28)）、社交Twitter
    I (TI) You 等人（[2015](#bib.bib51)）、社交Twitter II (TII) Borth 等人（[2013](#bib.bib4)）。这4个领域分别有23,308、806、1,269和603张图片。
- en: Vehicle counting. WebCamT Zhang et al. ([2017](#bib.bib55)) is a vehicle counting
    dataset from large-scale city camera videos with low resolution, low frame rate,
    and high occlusion. Totally there are 60,000 frames with vehicle bounding box
    and count annotations. For MDA, 8 cameras located in different intersections are
    selected, each with more than 2,000 labeled images. We can view each camera as
    a domain.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 车辆计数。WebCamT Zhang 等人（[2017](#bib.bib55)）是一个来自大型城市摄像头视频的低分辨率、低帧率和高遮挡的车辆计数数据集。共有60,000帧带有车辆边界框和计数注释。对于MDA，选择了8个位于不同交叉口的摄像头，每个摄像头有超过2,000张标注图片。我们可以将每个摄像头视为一个领域。
- en: '![Refer to caption](img/3c76a53bc577c0d4207ec684da90b5e9.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/3c76a53bc577c0d4207ec684da90b5e9.png)'
- en: 'Figure 3: Illustration of widely employed framework for MDA. The solid arrows
    and dashed dot arrows indicate the training of latent space transformation and
    intermediate domain generation, respectively. The dashed arrows represent the
    reference process. Most existing MDA methods can be obtained by employing different
    component details, enforcing some constraints, or slightly changing the architecture.
    Best viewed in color.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：广泛应用于MDA的框架示意图。实线箭头和虚线点状箭头分别表示潜在空间转换的训练和中间领域生成。虚线箭头表示参考过程。大多数现有MDA方法可以通过采用不同的组件细节、施加一些约束或稍微改变架构来实现。最佳效果为彩色显示。
- en: Scene segmentation. Sim2RealSeg contains 2 synthetic datasets (GTA, SYNTHIA)
    and 2 real datasets (Cityscapes, BDDS) for segmentation. Cityscapes (CS) Cordts
    et al. ([2016](#bib.bib6)) contains vehicle-centric urban street images collected
    from a moving vehicle in 50 cities from Germany and neighboring countries. There
    are 5,000 images with pixel-wise annotations into 19 classes. BDDS Yu et al. ([2018](#bib.bib53))
    contains 10,000 real-world dash cam video frames with a compatible label space
    with Cityscapes. GTA Richter et al. ([2016](#bib.bib35)) is a vehicle-egocentric
    image dataset collected in the high-fidelity rendered computer game GTA-V. It
    contains 24,966 images (video frames) with 19 classes as Cityscapes. SYNTHIA Ros
    et al. ([2016](#bib.bib37)) is a large synthetic dataset. To pair with Cityscapes,
    a subset, named SYNTHIA-RANDCITYSCAPES, is designed with 9,400 images which are
    automatically annotated with 16 compatible Cityscapes classes, one void class,
    and some unnamed classes. The common 16 classes are used for MDA.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 场景分割。Sim2RealSeg 包含 2 个合成数据集 (GTA、SYNTHIA) 和 2 个真实数据集 (Cityscapes、BDDS) 用于分割。Cityscapes
    (CS) Cordts 等人 ([2016](#bib.bib6)) 包含从德国及其邻国 50 个城市的移动车辆收集的以车辆为中心的城市街道图像。共有 5,000
    张图像，像素级注释为 19 个类别。BDDS Yu 等人 ([2018](#bib.bib53)) 包含 10,000 张现实世界的行车记录仪视频帧，与 Cityscapes
    具有兼容的标签空间。GTA Richter 等人 ([2016](#bib.bib35)) 是一个在高保真度渲染计算机游戏 GTA-V 中收集的车辆自我中心图像数据集。它包含
    24,966 张图像（视频帧），类别与 Cityscapes 相同，为 19 个类别。SYNTHIA Ros 等人 ([2016](#bib.bib37))
    是一个大型合成数据集。为了与 Cityscapes 配对，设计了一个名为 SYNTHIA-RANDCITYSCAPES 的子集，包含 9,400 张图像，这些图像自动标注为
    16 个与 Cityscapes 兼容的类别、一个空白类别和一些未命名的类别。共有 16 个类别用于 MDA。
- en: 'Sentiment classification of natural languages. Amazon Reviews Chen et al. ([2012](#bib.bib5))
    is a dataset of reviews on four kinds of products: Books (B), DVDs (D), Electronics
    (E), and Kitchen appliances (K). Reviews are encoded as 5,000 dimensional feature
    vectors of unigrams and bigrams and are labeled with binary sentiment. Each source
    has 2,000 labeled examples, and the target test set has 3,000 to 6,000 examples.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言的情感分类。亚马逊评论 Chen 等人 ([2012](#bib.bib5)) 是一个包含四种产品评论的数据集：书籍 (B)、DVD (D)、电子产品
    (E) 和厨房电器 (K)。评论被编码为 5,000 维的单词和二元组特征向量，并标记为二元情感。每个来源有 2,000 个标记示例，目标测试集有 3,000
    到 6,000 个示例。
- en: Media Reviews Liu et al. ([2017](#bib.bib25)) contains 16 domains of product
    reviews and movie reviews for binary sentiment classification. 5 domains with
    6,897 labeled samples are usually employed for MDA, including Apparel, Baby, Books,
    Camera taken from Amazon and MR from Rotten Tomato.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 媒体评论 Liu 等人 ([2017](#bib.bib25)) 包含 16 个产品评论和电影评论领域，用于二元情感分类。通常使用 5 个领域，共 6,897
    个标记样本进行 MDA，包括来自亚马逊的服装、婴儿用品、书籍、相机和来自 Rotten Tomato 的 MR。
- en: 'Part-of-speech tagging. The SANCL dataset Petrov and McDonald ([2012](#bib.bib33))
    contains part-of-speech tagging annotations in 5 web domains: Emails (E), Weblogs
    (W), Answers (A), Newsgroups (N), and Reviews (R). 750 sentences from each source
    are used for training.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 词性标注。SANCL 数据集 Petrov 和 McDonald ([2012](#bib.bib33)) 包含 5 个网页领域的词性标注：电子邮件 (E)、博客
    (W)、回答 (A)、新闻组 (N) 和评论 (R)。每个来源的 750 个句子用于训练。
- en: Unless otherwise specified, each domain is selected as the target and the rest
    domains are considered as the sources. For WebCamT, 2 domains are randomly selected
    as the target. For Sim2RealSeg, MDA is often performed using the simulation-to-real
    setting Zhao et al. ([2019a](#bib.bib58)), i.e. from synthetic GTA, SYNTHIA to
    real Cityscapes, BDDS. For SANCL, N, R, and A are used as target domains, while
    E and W are used as target domains Guo et al. ([2018](#bib.bib15)).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，每个领域被选择为目标，其余领域被视为来源。对于 WebCamT，随机选择 2 个领域作为目标。对于 Sim2RealSeg，MDA 通常在模拟到现实的设置下执行
    Zhao 等人 ([2019a](#bib.bib58))，即从合成的 GTA、SYNTHIA 到真实的 Cityscapes、BDDS。对于 SANCL，N、R
    和 A 用作目标领域，而 E 和 W 用作目标领域 Guo 等人 ([2018](#bib.bib15))。
- en: '| Reference | Feature | Feature | Feature | Feature | Classifier | #C | Classifier
    | Task | Dataset | Result |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 参考 | 特征 | 特征 | 特征 | 特征 | 分类器 | #C | 分类器 | 任务 | 数据集 | 结果 |'
- en: '| extractor | alignment method | alignment loss | alignment domains | alignment
    | weight | backbone |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 提取器 | 对齐方法 | 对齐损失 | 对齐领域 | 对齐 | 权重 | 骨干网 |'
- en: '| Mancini et al. ([2018](#bib.bib29)) | shared | — | — | — | CT loss | 1 |
    — | AlexNet | O, OC, P | 83.6, 91.8, 85.3 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| Mancini 等人 ([2018](#bib.bib29)) | 共享 | — | — | — | CT 损失 | 1 | — | AlexNet
    | O、OC、P | 83.6、91.8、85.3 |'
- en: '| Guo et al. ([2018](#bib.bib15)) | shared | discrepancy | MMD | target and
    each source | — | $M$ | PoS metric | AlexNet | AR, S | 84.8, 90.1 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| Guo 等人 ([2018](#bib.bib15)) | 共享 | 差异 | MMD | 目标和每个来源 | — | $M$ | PoS 评估指标
    | AlexNet | AR、S | 84.8、90.1 |'
- en: '| Hoffman et al. ([2018a](#bib.bib17)) | shared | discrepancy | Rényi-divergence
    | target and each source | CT loss | 1 | — | AlexNet | O | 87.6 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| Hoffman 等人 ([2018a](#bib.bib17)) | 共享 | 差异 | Rényi-散度 | 目标和每个源 | CT 损失 |
    1 | — | AlexNet | O | 87.6 |'
- en: '| Zhu et al. ([2019](#bib.bib62)) | shared | discrepancy | MMD | target and
    each source | $\mathcal{L}1$ loss | $M$ | uniform | ResNet-50 | O, OH, IC | 90.2,
    89.4, 74.1 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| Zhu 等人 ([2019](#bib.bib62)) | 共享 | 差异 | MMD | 目标和每个源 | $\mathcal{L}1$ 损失
    | $M$ | 均匀 | ResNet-50 | O, OH, IC | 90.2, 89.4, 74.1 |'
- en: '| Rakshit et al. ([2019](#bib.bib34)) | unshared | discrepancy | $\mathcal{L}2$
    distance | pairwise all domains | CT loss | 1 | — | ResNet-50 | O, OC, IC | 88.3,
    97.5, 91.2 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Rakshit 等人 ([2019](#bib.bib34)) | 不共享 | 差异 | $\mathcal{L}2$ 距离 | 成对所有领域 |
    CT 损失 | 1 | — | ResNet-50 | O, OC, IC | 88.3, 97.5, 91.2 |'
- en: '| Peng et al. ([2019](#bib.bib32)) | shared | discrepancy | moment distance
    | pairwise all domains | $\mathcal{L}1$ loss | $M$ | relative error | LeNet-5
    | D | 87.7 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| Peng 等人 ([2019](#bib.bib32)) | 共享 | 差异 | 矩量距离 | 成对所有领域 | $\mathcal{L}1$ 损失
    | $M$ | 相对误差 | LeNet-5 | D | 87.7 |'
- en: '| ResNet-101 | OC | 96.4 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| ResNet-101 | OC | 96.4 |'
- en: '| ResNet-101 | DN | 42.6 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| ResNet-101 | DN | 42.6 |'
- en: '| Guo et al. ([2020](#bib.bib16)) | shared | discrepancy | mixture distance
    | target and each source | CT loss | 1 | — | BiLSTM | MR | 79.3 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| Guo 等人 ([2020](#bib.bib16)) | 共享 | 差异 | 混合距离 | 目标和每个源 | CT 损失 | 1 | — | BiLSTM
    | MR | 79.3 |'
- en: '| Xu et al. ([2018](#bib.bib50)) | shared | discriminator | GAN loss | target
    and each source | — | $M$ | perplexity score | AlexNet | D, O, IC | 74.2, 83.8,
    80.8 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| Xu 等人 ([2018](#bib.bib50)) | 共享 | 判别器 | GAN 损失 | 目标和每个源 | — | $M$ | 困惑度评分
    | AlexNet | D, O, IC | 74.2, 83.8, 80.8 |'
- en: '| Li et al. ([2018](#bib.bib23)) | shared | discriminator | Wasserstein | pairwise
    all domains | CT loss | 1 | — | AlexNet | D | 79.9 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| Li 等人 ([2018](#bib.bib23)) | 共享 | 判别器 | Wasserstein | 成对所有领域 | CT 损失 | 1
    | — | AlexNet | D | 79.9 |'
- en: '| Zhao et al. ([2018a](#bib.bib56)) | shared | discriminator | $\mathcal{H}$-divergence
    | target and each source | CT loss | 1 | — | BiLSTM | AR | 82.7 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| Zhao 等人 ([2018a](#bib.bib56)) | 共享 | 判别器 | $\mathcal{H}$-散度 | 目标和每个源 | CT
    损失 | 1 | — | BiLSTM | AR | 82.7 |'
- en: '| AlexNet | D | 76.6 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| AlexNet | D | 76.6 |'
- en: '| FCN8s | W | 1.4 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| FCN8s | W | 1.4 |'
- en: '| Wang et al. ([2019](#bib.bib48)) | shared | discriminator | Wasserstein |
    pairwise all domains | CT loss | 1 | — | BiLSTM | AR | 84.5 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等人 ([2019](#bib.bib48)) | 共享 | 判别器 | Wasserstein | 成对所有领域 | CT 损失 |
    1 | — | BiLSTM | AR | 84.5 |'
- en: '| AlexNet | D | 83.4 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| AlexNet | D | 83.4 |'
- en: '| Zhao et al. ([2020](#bib.bib60)) | unshared | discriminator | Wasserstein
    | target and each source | — | $M$ | Wasserstein | LeNet-5 | D | 88.1 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| Zhao 等人 ([2020](#bib.bib60)) | 不共享 | 判别器 | Wasserstein | 目标和每个源 | — | $M$
    | Wasserstein | LeNet-5 | D | 88.1 |'
- en: '| AlexNet | O | 84.2 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| AlexNet | O | 84.2 |'
- en: 'Table 2: Comparison of different latent space transformation methods for MDA,
    where ‘#C’, ‘CT loss’, and ‘MMD’ are short for the number of classifiers during
    reference ($M$ is the number of source domains), combined task loss, and maximum
    mean discrepancy, respectively. ‘Result’ is the average performance of all target
    domains measured by accuracy for classification and counting error for vehicle
    counting.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：MDA不同潜在空间变换方法的比较，其中‘#C’、‘CT 损失’和‘MMD’分别是指参考时的分类器数量（$M$ 是源领域的数量）、组合任务损失和最大均值散度。‘结果’是所有目标领域在分类准确性和车辆计数误差方面的平均性能。
- en: 4 Deep Multi-source Domain Adaptation
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 深度多源领域适应
- en: Existing methods on deep MDA primarily focus on the unsupervised, homogeneous,
    closed set, strongly supervised, one target, and target data available settings.
    That is, there is one target domain, the target data is unlabeled but available
    during the training process, the source data is fully labeled, the source and
    target data are observed in the same data space, and the label sets of all sources
    and the target are the same. In this paper, we focus on MDA methods under these
    settings.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的深度多源领域适应（MDA）方法主要关注无监督、同质、封闭集合、强监督、单目标和目标数据可用的设置。也就是说，存在一个目标领域，目标数据在训练过程中是未标记的但可用，源数据是完全标记的，源数据和目标数据在相同的数据空间中观察，并且所有源和目标的标签集是相同的。本文集中讨论这些设置下的MDA方法。
- en: There are some theoretical analysis to support existing MDA algorithms. Most
    theories are based on the seminal theoretical model Blitzer et al. ([2008](#bib.bib3));
    Ben-David et al. ([2010](#bib.bib1)). [Mansour et al.](#bib.bib30) Mansour et
    al. ([2009](#bib.bib30)) assumed that the target distribution can be approximated
    by a mixture of the $M$ source distributions. Therefore, weighted combination
    of source classifiers has been widely employed for MDA. Moreover, tighter cross
    domain generalization bound and more accurate measurements on domain discrepancy
    can provide intuitions to derive effective MDA algorithms. [Hoffman et al.](#bib.bib17) Hoffman
    et al. ([2018a](#bib.bib17)) derived a novel bound using DC-programming and calculated
    more accurate combination weights. [Zhao et al.](#bib.bib56) Zhao et al. ([2018a](#bib.bib56))
    extended the generalization bound of seminal theoretical model to multiple sources
    under both classification and regression settings. Besides the domain discrepancy
    between the target and each source Hoffman et al. ([2018a](#bib.bib17)); Zhao
    et al. ([2018a](#bib.bib56)), [Li et al.](#bib.bib23) Li et al. ([2018](#bib.bib23))
    also considered the relationship between pairwise sources and derived a tighter
    bound on weighted multi-source discrepancy. Based on this bound, more relevant
    source domains can be picked out.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 一些理论分析支持现有的MDA算法。大多数理论基于开创性的理论模型 Blitzer 等人 ([2008](#bib.bib3)); Ben-David 等人
    ([2010](#bib.bib1))。 [Mansour 等人](#bib.bib30) Mansour 等人 ([2009](#bib.bib30))
    假设目标分布可以通过 $M$ 个源分布的混合来近似。因此，加权源分类器已被广泛用于MDA。此外，更紧密的跨域泛化界限和对领域差异的更准确测量可以提供推导有效MDA算法的直觉。
    [Hoffman 等人](#bib.bib17) Hoffman 等人 ([2018a](#bib.bib17)) 通过DC编程推导了一种新颖的界限，并计算了更准确的组合权重。
    [Zhao 等人](#bib.bib56) Zhao 等人 ([2018a](#bib.bib56)) 将开创性理论模型的泛化界限扩展到多源下的分类和回归设置。除了目标域和每个源之间的领域差异，Hoffman
    等人 ([2018a](#bib.bib17)); Zhao 等人 ([2018a](#bib.bib56))， [Li 等人](#bib.bib23) Li
    等人 ([2018](#bib.bib23)) 还考虑了成对源之间的关系，并推导了加权多源差异的更紧密界限。基于这一界限，可以挑选出更相关的源域。
- en: 'Typically, some task models (e.g. classifiers) are learned based on the labeled
    source data with corresponding task loss, such as cross-entropy loss for classification.
    Meanwhile, specific alignments among the source and target domains are conducted
    to bridge the domain shift so that the learned task models can be better transferred
    to the target domain. Based on the different alignment strategies, we can classify
    MDA into different categories. *Latent space transformation* tries to align the
    latent space (e.g. features) of different domains based on optimizing the discrepancy
    loss or adversarial loss. *Intermediate domain generation* explicitly generates
    an intermediate adapted domain for each source that is indistinguishable from
    the target domain. The task models are then trained on the adapted domain. Figure [3](#S3.F3
    "Figure 3 ‣ 3 Datasets ‣ Multi-source Domain Adaptation in the Deep Learning Era:
    A Systematic Survey") summarizes the common overall framework of existing MDA
    methods.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '通常，一些任务模型（例如分类器）是基于带标签的源数据和相应的任务损失进行学习的，例如分类任务中的交叉熵损失。同时，进行源域和目标域之间的特定对齐，以桥接域间的差异，使得学习到的任务模型能够更好地迁移到目标域。根据不同的对齐策略，我们可以将多源领域适应（MDA）分类为不同的类别。*潜在空间变换*试图通过优化差异损失或对抗损失来对齐不同领域的潜在空间（例如特征）。*中间域生成*明确地为每个源生成一个与目标域不可区分的中间适应域。然后在适应域上训练任务模型。图 [3](#S3.F3
    "Figure 3 ‣ 3 Datasets ‣ Multi-source Domain Adaptation in the Deep Learning Era:
    A Systematic Survey") 总结了现有MDA方法的常见整体框架。'
- en: 4.1 Latent Space Transformation
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 潜在空间变换
- en: 'The two common methods for aligning the latent spaces of different domains
    are discrepancy-based methods and adversarial methods. We discuss these two methods
    below, and Table [2](#S3.T2 "Table 2 ‣ 3 Datasets ‣ Multi-source Domain Adaptation
    in the Deep Learning Era: A Systematic Survey") summarizes key examples of each
    method.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '对齐不同领域的潜在空间的两种常见方法是基于差异的方法和对抗方法。我们将在下面讨论这两种方法，表 [2](#S3.T2 "Table 2 ‣ 3 Datasets
    ‣ Multi-source Domain Adaptation in the Deep Learning Era: A Systematic Survey")
    总结了每种方法的关键示例。'
- en: Discrepancy-based methods explicitly measure the discrepancy of the latent spaces
    (typically features) from different domains by optimizing some specific discrepancy
    losses, such as maximum mean discrepancy (MMD) Guo et al. ([2018](#bib.bib15));
    Zhu et al. ([2019](#bib.bib62)), Rényi-divergence Hoffman et al. ([2018a](#bib.bib17)),
    $\mathcal{L}2$ distance Rakshit et al. ([2019](#bib.bib34)), and moment distance Peng
    et al. ([2019](#bib.bib32)). [Guo et al.](#bib.bib16) Guo et al. ([2020](#bib.bib16))
    claimed that different discrepancies or distances can only provide specific estimates
    of domain similarities and that each distance has its pathological cases. Therefore,
    they consider the mixture of several distances Guo et al. ([2020](#bib.bib16)),
    including $\mathcal{L}2$ distance, Cosine distance, MMD, Fisher linear discriminant,
    and Correlation alignment. Minimizing the discrepancy to align the features among
    the source and target domains does not introduce any new parameters that must
    be learned.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 基于差异的方法通过优化一些特定的差异损失（如最大均值差异（MMD） Guo et al. ([2018](#bib.bib15)); Zhu et al.
    ([2019](#bib.bib62))、Rényi-散度 Hoffman et al. ([2018a](#bib.bib17))、$\mathcal{L}2$距离
    Rakshit et al. ([2019](#bib.bib34)) 和矩量距离 Peng et al. ([2019](#bib.bib32))）来显式地测量不同领域的潜在空间（通常是特征）的差异。[Guo
    et al.](#bib.bib16) Guo et al. ([2020](#bib.bib16)) 声称不同的差异或距离只能提供领域相似性的特定估计，并且每种距离都有其病态情况。因此，他们考虑了几种距离的混合
    Guo et al. ([2020](#bib.bib16))，包括$\mathcal{L}2$距离、余弦距离、MMD、Fisher线性判别和相关对齐。最小化差异以对齐源领域和目标领域中的特征不会引入任何必须学习的新参数。
- en: Adversarial methods try to align the features by making them indistinguishable
    to a discriminator. Some representative optimized objectives include GAN loss Xu
    et al. ([2018](#bib.bib50)), $\mathcal{H}$-divergence Zhao et al. ([2018a](#bib.bib56)),
    Wasserstein distance Li et al. ([2018](#bib.bib23)); Wang et al. ([2019](#bib.bib48));
    Zhao et al. ([2020](#bib.bib60)). These methods aim to confuse the discriminator’s
    ability to distinguishing whether the features from multiple sources were drawn
    from the same distribution. Compared with GAN loss and $\mathcal{H}$-divergence,
    Wasserstein distance can provide more stable gradients even when the target and
    source distributions do not overlap Zhao et al. ([2020](#bib.bib60)). The discriminator
    is often implemented as a network, which leads to new parameters that must be
    learned.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗方法通过使特征对鉴别器不可区分来尝试对齐这些特征。一些代表性的优化目标包括GAN损失 Xu et al. ([2018](#bib.bib50))、$\mathcal{H}$-散度
    Zhao et al. ([2018a](#bib.bib56))、Wasserstein距离 Li et al. ([2018](#bib.bib23));
    Wang et al. ([2019](#bib.bib48)); Zhao et al. ([2020](#bib.bib60))。这些方法旨在混淆鉴别器区分特征是否来自于相同分布的能力。与GAN损失和$\mathcal{H}$-散度相比，Wasserstein距离即使在目标和源分布不重叠时也能提供更稳定的梯度
    Zhao et al. ([2020](#bib.bib60))。鉴别器通常实现为一个网络，这会导致必须学习的新参数。
- en: There are many modular implementation details for both types of methods, such
    as how to align the target and multiple sources, whether the feature extractors
    are shared, how to select the more relevant sources, and how to combine the multiple
    predictions from different classifiers.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这两类方法，都存在许多模块化的实现细节，例如如何对齐目标和多个源、特征提取器是否共享、如何选择更相关的源以及如何结合来自不同分类器的多个预测。
- en: Alignment domains. There are different ways to align the target and multiple
    sources. The most common method is to pairwise align the target with each source Xu
    et al. ([2018](#bib.bib50)); Guo et al. ([2018](#bib.bib15)); Zhao et al. ([2018a](#bib.bib56));
    Hoffman et al. ([2018a](#bib.bib17)); Zhu et al. ([2019](#bib.bib62)); Zhao et
    al. ([2020](#bib.bib60)); Guo et al. ([2020](#bib.bib16)). Since domain shift
    also exists among different sources, several methods enforce pairwise alignment
    between every domain in both the source and target domains Li et al. ([2018](#bib.bib23));
    Rakshit et al. ([2019](#bib.bib34)); Peng et al. ([2019](#bib.bib32)); Wang et
    al. ([2019](#bib.bib48)).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 对齐领域。有不同的方法来对齐目标和多个源。最常见的方法是将目标与每个源逐对对齐 Xu et al. ([2018](#bib.bib50)); Guo
    et al. ([2018](#bib.bib15)); Zhao et al. ([2018a](#bib.bib56)); Hoffman et al.
    ([2018a](#bib.bib17)); Zhu et al. ([2019](#bib.bib62)); Zhao et al. ([2020](#bib.bib60));
    Guo et al. ([2020](#bib.bib16))。由于不同源之间也存在领域偏移，一些方法在源领域和目标领域之间强制执行每个领域的逐对对齐 Li
    et al. ([2018](#bib.bib23)); Rakshit et al. ([2019](#bib.bib34)); Peng et al.
    ([2019](#bib.bib32)); Wang et al. ([2019](#bib.bib48))。
- en: '| Reference | Domain | Pixel | Feature | Feature | #C | Classifier | Task |
    Dataset | Task | Result |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 参考 | 领域 | 像素 | 特征 | 特征 | #C | 分类器 | 任务 | 数据集 | 任务 | 结果 |'
- en: '| generator | alignment domains | alignment loss | alignment domains | weight
    | backbone |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 生成器 | 对齐领域 | 对齐损失 | 对齐领域 | 权重 | 主干网络 |'
- en: '| Russo et al. ([2019](#bib.bib38)) | CoGAN | target and each source | GAN
    loss | target and each source | $M$ | uniform | DeepLabV2 | S2R-CS | seg | 42.8
    |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| Russo et al. ([2019](#bib.bib38)) | CoGAN | 目标和每个源 | GAN损失 | 目标和每个源 | $M$
    | 均匀 | DeepLabV2 | S2R-CS | seg | 42.8 |'
- en: '| shared |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 共享 |'
- en: '| Zhao et al. ([2019a](#bib.bib58)) | CycleGAN | target and aggregated source
    | GAN loss | target and each source | 1 | — | FCN8s | S2R-CS | seg | 41.4 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| Zhao et al. ([2019a](#bib.bib58)) | CycleGAN | 目标和聚合源 | GAN损失 | 目标和每个源 |
    1 | — | FCN8s | S2R-CS | seg | 41.4 |'
- en: '| shared | S2R-BDDS | 36.3 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 共享 | S2R-BDDS | 36.3 |'
- en: '| Lin et al. ([2020](#bib.bib24)) | VAE+CycleGAN | target and combined source
    | — | — | 1 | — | ResNet-18 | SI | cls | 68.1 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| Lin et al. ([2020](#bib.bib24)) | VAE+CycleGAN | 目标和组合源 | — | — | 1 | — |
    ResNet-18 | SI | cls | 68.1 |'
- en: '| unshared |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 非共享 |'
- en: 'Table 3: Comparison of different intermediate domain generation methods for
    MDA, where ‘#C’, ‘seg’, and ‘cls’ are short for the number of classifiers during
    reference ($M$ is the number of source domains), segmentation, and classification,
    respectively. ‘Result’ is the average performance of all target domains measured
    by accuracy for classification and mean intersection-over-union (mIoU) for segmentation.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：不同中间领域生成方法在MDA中的比较，其中‘#C’，‘seg’和‘cls’分别表示参考中的分类器数量（$M$是源领域的数量）、分割和分类。‘Result’是所有目标领域的平均性能，通过分类的准确率和分割的平均交并比（mIoU）来衡量。
- en: Weight sharing of feature extractor. Most methods employ shared feature extractors
    to learn domain-invariant features. However, domain invariance may be detrimental
    to discriminative power. On the contrary, [Rakshit et al.](#bib.bib34) Rakshit
    et al. ([2019](#bib.bib34)) adopted one feature extractor for each source and
    target pair with unshared weights, while [Zhao et al.](#bib.bib60) Zhao et al.
    ([2020](#bib.bib60)) first pre-trained one feature extractor for each source and
    then mapped the target into the feature space of each source. Correspondingly,
    there are $M$ and $2M$ feature extractors. Although unshared feature extractors
    can better align the target and sources in the latent space, this substantially
    increases the number of parameters in the model.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提取器的权重共享。大多数方法采用共享特征提取器来学习领域不变的特征。然而，领域不变性可能会对区分能力产生负面影响。相反，[Rakshit et al.](#bib.bib34)
    Rakshit et al. ([2019](#bib.bib34)) 为每个源和目标对采用了具有非共享权重的一个特征提取器，而[Zhao et al.](#bib.bib60)
    Zhao et al. ([2020](#bib.bib60)) 首先为每个源预训练一个特征提取器，然后将目标映射到每个源的特征空间中。因此，有$M$和$2M$个特征提取器。尽管非共享特征提取器可以更好地对齐潜在空间中的目标和源，但这大大增加了模型中的参数数量。
- en: Classifier alignment. Intuitively, the classifiers trained on different sources
    may result in misaligned predictions for the target samples that are close to
    the domain boundary. By minimizing specific classifier discrepancy, such as $\mathcal{L}$1
    loss Zhu et al. ([2019](#bib.bib62)); Peng et al. ([2019](#bib.bib32)), the classifiers
    are better aligned, which can learn a generalized classification boundary for
    target samples mentioned above. Instead of explicitly training one classifier
    for each source, many methods focus on training a compound classifier based on
    specific combined task loss, such as normalized activations Mancini et al. ([2018](#bib.bib29))
    and bandit controller Guo et al. ([2020](#bib.bib16)).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器对齐。从直观上看，训练于不同源的分类器可能导致对接近领域边界的目标样本做出错位预测。通过最小化特定分类器的差异，例如$\mathcal{L}$1损失
    Zhu et al. ([2019](#bib.bib62)); Peng et al. ([2019](#bib.bib32))，分类器得到更好的对齐，这可以学习到上述目标样本的泛化分类边界。许多方法专注于训练基于特定组合任务损失的复合分类器，例如标准化激活
    Mancini et al. ([2018](#bib.bib29)) 和赌注控制器 Guo et al. ([2020](#bib.bib16))，而不是显式地为每个源训练一个分类器。
- en: Target prediction. After aligning the features of target and source domains
    in the latent space, the classifiers trained based on the labeled source samples
    can be used to predict the labels of a target sample. Since there are multiple
    sources, it is possible that they will yield different target predictions. One
    way to reconcile these different predictions is to uniformly average the predictions
    from different source classifiers Zhu et al. ([2019](#bib.bib62)). However, different
    sources may have different relationships with the target, e.g. one source might
    better align with the target, so a non-uniform, weighted averaging of the predictions
    leads to better results. Weighting strategies, known as a *source selection process*,
    include uniform weight Zhu et al. ([2019](#bib.bib62)), perplexity score based
    on adversarial loss Xu et al. ([2018](#bib.bib50)), point-to-set (PoS) metric
    using Mahalanobis distance Guo et al. ([2018](#bib.bib15)), relative error based
    on source-only accuracy Peng et al. ([2019](#bib.bib32)), and Wasserstein distance
    based weights Zhao et al. ([2020](#bib.bib60)).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 目标预测。在潜在空间中对目标和源领域的特征进行对齐后，可以使用基于标记源样本训练的分类器来预测目标样本的标签。由于存在多个源，可能会产生不同的目标预测。调和这些不同预测的一种方法是均匀地平均来自不同源分类器的预测 [朱等人](#bib.bib62)（[2019](#bib.bib62)）。然而，不同的源可能与目标有不同的关系，例如一个源可能与目标的对齐效果更好，因此，非均匀的加权平均预测会得到更好的结果。加权策略，称为*源选择过程*，包括均匀权重 [朱等人](#bib.bib62)（[2019](#bib.bib62)），基于对抗损失的困惑度评分 [徐等人](#bib.bib50)（[2018](#bib.bib50)），使用Mahalanobis距离的点到集（PoS）度量 [郭等人](#bib.bib15)（[2018](#bib.bib15)），基于仅源准确度的相对误差 [彭等人](#bib.bib32)（[2019](#bib.bib32)），以及基于Wasserstein距离的权重 [赵等人](#bib.bib60)（[2020](#bib.bib60)）。
- en: Besides the source importance, [Zhao et al.](#bib.bib60) Zhao et al. ([2020](#bib.bib60))
    also considered the sample importance, i.e. different samples from the same source
    may still have different similarities from the target samples. The source samples
    that are closer to the target are distilled (based on a manually selected Wasserstein
    distance threshold) to fine-tune the source classifiers. Automatically and adaptively
    selecting the most relevant training samples for each source remains an open research
    problem.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 除了源领域的重要性，[赵等人](#bib.bib60) 赵等人（[2020](#bib.bib60)）还考虑了样本的重要性，即来自同一来源的不同样本可能与目标样本的相似性不同。与目标更接近的源样本会被提炼（基于手动选择的Wasserstein距离阈值）以微调源分类器。自动且自适应地选择每个源的最相关训练样本仍然是一个未解决的研究问题。
- en: 4.2 Intermediate Domain Generation
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 中间领域生成
- en: Feature-level alignment only aligns high-level information, which is insufficient
    for fine-grained predictions, such as pixel-wise semantic segmentation Zhao et
    al. ([2019a](#bib.bib58)). Generating an intermediate adapted domain with pixel-level
    alignment, typically via GANs Goodfellow et al. ([2014](#bib.bib13)), can help
    address this problem.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 特征级对齐仅对齐高层信息，这对于像像素级语义分割 [赵等人](#bib.bib58)（[2019a](#bib.bib58)）这样的细粒度预测是不够的。通过像素级对齐生成一个中间适配领域，通常通过GANs [Goodfellow
    et al.](#bib.bib13)（[2014](#bib.bib13)），可以帮助解决这个问题。
- en: Domain generator. Since the original GAN is highly under-constrained, some improved
    versions are employed, such as Coupled GAN (CoGAN) in Russo et al. ([2019](#bib.bib38))
    and CycleGAN in MADAN Zhao et al. ([2019a](#bib.bib58)). Instead of directly taking
    the original source data as input to the generator Russo et al. ([2019](#bib.bib38));
    Zhao et al. ([2019a](#bib.bib58)), [Lin et al.](#bib.bib24) Lin et al. ([2020](#bib.bib24))
    used a variational autoencoder to map all source and target domains to a latent
    space and then generated an adapted domain from the latent space. [Russo et al.](#bib.bib38) Russo
    et al. ([2019](#bib.bib38)) then tried to align the target and each adapted domain,
    while [Lin et al.](#bib.bib24) Lin et al. ([2020](#bib.bib24)) aligned the target
    and combined adapted domain from the latent space. [Zhao et al.](#bib.bib58) Zhao
    et al. ([2019a](#bib.bib58)) proposed to aggregate different adapted domains using
    a sub-domain aggregation discriminator and cross-domain cycle discriminator, where
    the pixel-level alignment is then conducted between the aggregated and target
    domains. [Zhao et al.](#bib.bib58) Zhao et al. ([2019a](#bib.bib58)) and [Lin
    et al.](#bib.bib24) Lin et al. ([2020](#bib.bib24)) showed that the semantics
    might change in the intermediate representation, and that enforcing a semantic
    consistency before and after generation can help preserve the labels.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 域生成器。由于原始GAN的约束条件较少，一些改进版本被采用，例如 Russo et al. ([2019](#bib.bib38))中的Coupled
    GAN (CoGAN)和MADAN Zhao et al. ([2019a](#bib.bib58))中的CycleGAN。 Russo et al. ([2019](#bib.bib38));
    Zhao et al. ([2019a](#bib.bib58))直接将原始源数据作为生成器的输入，而[Lin et al.](#bib.bib24) Lin
    et al. ([2020](#bib.bib24))使用变分自编码器将所有源和目标领域映射到潜在空间，然后从潜在空间生成一个适应领域。[Russo et
    al.](#bib.bib38) Russo et al. ([2019](#bib.bib38)) 然后尝试对齐目标和每个适应领域，而[Lin et al.](#bib.bib24) Lin
    et al. ([2020](#bib.bib24))对齐目标和从潜在空间获得的组合适应领域。[Zhao et al.](#bib.bib58) Zhao
    et al. ([2019a](#bib.bib58)) 提出了使用子领域聚合鉴别器和跨领域循环鉴别器来聚合不同的适应领域，其中像素级别的对齐在聚合领域和目标领域之间进行。[Zhao
    et al.](#bib.bib58) Zhao et al. ([2019a](#bib.bib58)) 和[Lin et al.](#bib.bib24) Lin
    et al. ([2020](#bib.bib24)) 表明，中间表示中的语义可能会发生变化，并且在生成之前和之后强制保持语义一致性可以帮助保持标签。
- en: 'Feature alignment and target prediction. Feature-level alignment is often jointly
    considered with pixel-level alignment. Both alignments are usually achieved by
    minimizing the GAN loss with a discriminator. One classifier is trained on each
    adapted domain Russo et al. ([2019](#bib.bib38)) and the multiple predictions
    for a given target sample are averaged. Only one classifier is trained on the
    aggregated domain Zhao et al. ([2020](#bib.bib60)) or on the combined adapted
    domain Lin et al. ([2020](#bib.bib24)) which is obtained by a unique generator
    from the latent space for all source domains. The comparison of these methods
    are summarized in Table [3](#S4.T3 "Table 3 ‣ 4.1 Latent Space Transformation
    ‣ 4 Deep Multi-source Domain Adaptation ‣ Multi-source Domain Adaptation in the
    Deep Learning Era: A Systematic Survey").'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '特征对齐和目标预测。特征级别的对齐通常与像素级别的对齐共同考虑。这两种对齐通常通过最小化带有鉴别器的GAN损失来实现。每个适应领域训练一个分类器 Russo
    et al. ([2019](#bib.bib38))，并且对给定目标样本的多个预测结果进行平均。仅在聚合领域 Zhao et al. ([2020](#bib.bib60))
    或在由所有源领域的潜在空间唯一生成器获得的组合适应领域 Lin et al. ([2020](#bib.bib24)) 上训练一个分类器。这些方法的比较总结在表 [3](#S4.T3
    "Table 3 ‣ 4.1 Latent Space Transformation ‣ 4 Deep Multi-source Domain Adaptation
    ‣ Multi-source Domain Adaptation in the Deep Learning Era: A Systematic Survey")中。'
- en: 5 Conclusion and Future Directions
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论与未来方向
- en: 'In this paper, we provided a survey of recent MDA developments in the deep
    learning era. We motivated MDA, defined different MDA strategies, and summarized
    the datasets that are commonly used for performing MDA evaluation. Our survey
    focused on a typical MDA setting, i.e. unsupervised, homogeneous, closed set,
    and one target MDA. We classified these methods into different categories, and
    compared the representative ones technically and experimentally. We conclude with
    several open research directions:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提供了对深度学习时代近期MDA发展的综述。我们阐述了MDA的动机，定义了不同的MDA策略，并总结了常用于执行MDA评估的数据集。我们的综述集中在一个典型的MDA设置上，即无监督、同质、封闭集和一个目标MDA。我们将这些方法分类，并在技术和实验上对代表性方法进行了比较。我们总结了若干开放的研究方向：
- en: 'Specific MDA strategy implementation. As introduced in Section [2](#S2 "2 Problem
    Definition ‣ Multi-source Domain Adaptation in the Deep Learning Era: A Systematic
    Survey"), there are many types of MDA strategies, and implementing an MDA strategy
    according to the specific problem requirement would likely yield better results
    than a one-size-fits-all MDA approach. Further investigation is needed to determine
    which MDA strategies work the best for which types of problems. Also, real-world
    applications may have a small amount of labeled target data; determining how to
    include this data and what fraction of this data is needed for a certain performance
    remains an open question.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '特定 MDA 策略实施。如第 [2](#S2 "2 Problem Definition ‣ Multi-source Domain Adaptation
    in the Deep Learning Era: A Systematic Survey") 节所介绍，有许多类型的 MDA 策略，根据具体问题要求实施
    MDA 策略可能会比一刀切的 MDA 方法取得更好的结果。还需要进一步调查哪些 MDA 策略对哪些类型的问题最有效。此外，现实世界应用可能只有少量标记的目标数据；如何包含这些数据以及需要多少比例的数据以达到某种性能仍然是一个未解之谜。'
- en: Multi-modal MDA. The labeled source data may be of different modalities, such
    as LiDAR, radar, and image. Further research is needed to find techniques for
    fusing different data modalities in MDA. A further extension of this idea is to
    have varied modalities in defferent sources as well as partially labeled, multi-modal
    sources.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态 MDA。标记的源数据可能来自不同的模态，如 LiDAR、雷达和图像。需要进一步研究以找到在 MDA 中融合不同数据模态的技术。这个想法的进一步扩展是拥有不同源中的多样化模态以及部分标记的多模态源。
- en: Incremental and online MDA. Designing incremental and online MDA algorithms
    remains largely unexplored and may provide great benefit for real-world scenarios,
    such as updating deployed MDA models when new source or target data becomes available.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 增量和在线 MDA。设计增量和在线 MDA 算法仍然大多未被探索，这可能对现实世界场景带来巨大的好处，例如在新源或目标数据可用时更新已部署的 MDA 模型。
- en: References
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Ben-David et al. [2010] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza,
    Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different
    domains. In Machine Learning, 2010.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ben-David 等人 [2010] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza,
    Fernando Pereira, 和 Jennifer Wortman Vaughan。从不同领域学习的理论。发表于 Machine Learning,
    2010。
- en: Bhatt et al. [2016] Himanshu S Bhatt, Arun Rajkumar, and Shourya Roy. Multi-source
    iterative adaptation for cross-domain classification. In IJCAI, 2016.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bhatt 等人 [2016] Himanshu S Bhatt, Arun Rajkumar, 和 Shourya Roy。跨域分类的多源迭代适应。发表于
    IJCAI, 2016。
- en: Blitzer et al. [2008] John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira,
    and Jennifer Wortman Vaughan. Learning bounds for domain adaptation. In NIPS,
    2008.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blitzer 等人 [2008] John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira,
    和 Jennifer Wortman Vaughan。领域适应的学习界限。发表于 NIPS, 2008。
- en: Borth et al. [2013] Damian Borth, Rongrong Ji, Tao Chen, Thomas Breuel, and
    Shih-Fu Chang. Large-scale visual sentiment ontology and detectors using adjective
    noun pairs. In ACM MM, 2013.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Borth 等人 [2013] Damian Borth, Rongrong Ji, Tao Chen, Thomas Breuel, 和 Shih-Fu
    Chang。使用形容词名词对的大规模视觉情感本体及探测器。发表于 ACM MM, 2013。
- en: Chen et al. [2012] Minmin Chen, Zhixiang Xu, Kilian Q Weinberger, and Fei Sha.
    Marginalized denoising autoencoders for domain adaptation. In ICML, 2012.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 [2012] Minmin Chen, Zhixiang Xu, Kilian Q Weinberger, 和 Fei Sha。用于领域适应的边际去噪自编码器。发表于
    ICML, 2012。
- en: Cordts et al. [2016] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld,
    Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele.
    The cityscapes dataset for semantic urban scene understanding. In CVPR, 2016.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cordts 等人 [2016] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld,
    Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, 和 Bernt Schiele。用于语义城市场景理解的
    cityscapes 数据集。发表于 CVPR, 2016。
- en: 'Duan et al. [2012] Lixin Duan, Dong Xu, and Shih-Fu Chang. Exploiting web images
    for event recognition in consumer videos: A multiple source domain adaptation
    approach. In CVPR, 2012.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Duan 等人 [2012] Lixin Duan, Dong Xu, 和 Shih-Fu Chang。利用网页图像进行消费视频事件识别：一种多源领域适应方法。发表于
    CVPR, 2012。
- en: Ganin and Lempitsky [2015] Yaroslav Ganin and Victor Lempitsky. Unsupervised
    domain adaptation by backpropagation. In ICML, 2015.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ganin 和 Lempitsky [2015] Yaroslav Ganin 和 Victor Lempitsky。通过反向传播进行无监督领域适应。发表于
    ICML, 2015。
- en: Ganin et al. [2016] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain,
    Hugo Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial
    training of neural networks. JMLR, 2016.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ganin 等人 [2016] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain,
    Hugo Larochelle, François Laviolette, Mario Marchand, 和 Victor Lempitsky。神经网络的领域对抗训练。JMLR,
    2016。
- en: 'Gebru et al. [2017] Timnit Gebru, Judy Hoffman, and Li Fei-Fei. Fine-grained
    recognition in the wild: A multi-task domain adaptation approach. In ICCV, 2017.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gebru et al. [2017] Timnit Gebru, Judy Hoffman, 和 Li Fei-Fei. 野外的细粒度识别：一种多任务领域适应方法。在
    ICCV，2017。
- en: Ghifary et al. [2016] Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang, David
    Balduzzi, and Wen Li. Deep reconstruction-classification networks for unsupervised
    domain adaptation. In ECCV, 2016.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ghifary et al. [2016] Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang, David
    Balduzzi, 和 Wen Li. 用于无监督领域适应的深度重构分类网络。在 ECCV，2016。
- en: 'Gong et al. [2013] Boqing Gong, Kristen Grauman, and Fei Sha. Connecting the
    dots with landmarks: Discriminatively learning domain-invariant features for unsupervised
    domain adaptation. In ICML, 2013.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gong et al. [2013] Boqing Gong, Kristen Grauman, 和 Fei Sha. 用地标连接点：区分性地学习领域不变特征以进行无监督领域适应。在
    ICML，2013。
- en: Goodfellow et al. [2014] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
    Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative
    adversarial nets. In NIPS, 2014.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow et al. [2014] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
    Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, 和 Yoshua Bengio. 生成对抗网络。在
    NIPS，2014。
- en: Griffin et al. [2007] Gregory Griffin, Alex Holub, and Pietro Perona. Caltech-256
    object category dataset. 2007.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Griffin et al. [2007] Gregory Griffin, Alex Holub, 和 Pietro Perona. Caltech-256
    物体类别数据集。2007。
- en: Guo et al. [2018] Jiang Guo, Darsh Shah, and Regina Barzilay. Multi-source domain
    adaptation with mixture of experts. In EMNLP, 2018.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo et al. [2018] Jiang Guo, Darsh Shah, 和 Regina Barzilay. 具有专家混合的多源领域适应。在
    EMNLP，2018。
- en: Guo et al. [2020] Han Guo, Ramakanth Pasunuru, and Mohit Bansal. Multi-source
    domain adaptation for text classification via distancenet-bandits. In AAAI, 2020.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo et al. [2020] Han Guo, Ramakanth Pasunuru, 和 Mohit Bansal. 通过 distancenet-bandits
    进行文本分类的多源领域适应。在 AAAI，2020。
- en: Hoffman et al. [2018a] Judy Hoffman, Mehryar Mohri, and Ningshan Zhang. Algorithms
    and theory for multiple-source adaptation. In NeurIPS, 2018.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hoffman et al. [2018a] Judy Hoffman, Mehryar Mohri, 和 Ningshan Zhang. 多源适应的算法和理论。在
    NeurIPS，2018。
- en: 'Hoffman et al. [2018b] Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu,
    Phillip Isola, Kate Saenko, Alexei A Efros, and Trevor Darrell. Cycada: Cycle-consistent
    adversarial domain adaptation. In ICML, 2018.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hoffman et al. [2018b] Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu,
    Phillip Isola, Kate Saenko, Alexei A Efros, 和 Trevor Darrell. Cycada：循环一致的对抗领域适应。在
    ICML，2018。
- en: Hull [1994] Jonathan J. Hull. A database for handwritten text recognition research.
    TPAMI, 1994.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hull [1994] Jonathan J. Hull. 手写文本识别研究的数据库。TPAMI，1994。
- en: Kang et al. [2019] Guoliang Kang, Lu Jiang, Yi Yang, and Alexander G Hauptmann.
    Contrastive adaptation network for unsupervised domain adaptation. In CVPR, 2019.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang et al. [2019] Guoliang Kang, Lu Jiang, Yi Yang, 和 Alexander G Hauptmann.
    用于无监督领域适应的对比适应网络。在 CVPR，2019。
- en: LeCun et al. [1998] Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner,
    et al. Gradient-based learning applied to document recognition. PIEEE, 1998.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun et al. [1998] Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner
    等。基于梯度的学习应用于文档识别。PIEEE，1998。
- en: Li et al. [2017] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales.
    Deeper, broader and artier domain generalization. In ICCV, 2017.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2017] Da Li, Yongxin Yang, Yi-Zhe Song, 和 Timothy M Hospedales. 更深、更广、更艺术的领域泛化。在
    ICCV，2017。
- en: Li et al. [2018] Yitong Li, Michael Andrew Murias, Samantha Major, Geraldine
    Dawson, and David E Carlson. Extracting relationships by multi-domain matching.
    In NeurIPS, 2018.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2018] Yitong Li, Michael Andrew Murias, Samantha Major, Geraldine
    Dawson, 和 David E Carlson. 通过多领域匹配提取关系。在 NeurIPS，2018。
- en: Lin et al. [2020] Chuang Lin, Sicheng Zhao, Lei Meng, and Tat-Seng Chua. Multi-source
    domain adaptation for visual sentiment classification. In AAAI, 2020.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin et al. [2020] Chuang Lin, Sicheng Zhao, Lei Meng, 和 Tat-Seng Chua. 用于视觉情感分类的多源领域适应。在
    AAAI，2020。
- en: Liu et al. [2017] Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. Adversarial multi-task
    learning for text classification. In ACL, 2017.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. [2017] Pengfei Liu, Xipeng Qiu, 和 Xuanjing Huang. 用于文本分类的对抗多任务学习。在
    ACL，2017。
- en: Long et al. [2015a] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully
    convolutional networks for semantic segmentation. In CVPR, 2015.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Long et al. [2015a] Jonathan Long, Evan Shelhamer, 和 Trevor Darrell. 用于语义分割的全卷积网络。在
    CVPR，2015。
- en: Long et al. [2015b] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan.
    Learning transferable features with deep adaptation networks. In ICML, 2015.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Long et al. [2015b] Mingsheng Long, Yue Cao, Jianmin Wang, 和 Michael Jordan.
    通过深度适应网络学习可迁移特征。在 ICML，2015。
- en: Machajdik and Hanbury [2010] Jana Machajdik and Allan Hanbury. Affective image
    classification using features inspired by psychology and art theory. In ACM MM,
    2010.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Machajdik and Hanbury [2010] Jana Machajdik 和 Allan Hanbury. 使用受心理学和艺术理论启发的特征进行情感图像分类。在
    ACM MM，2010。
- en: Mancini et al. [2018] Massimiliano Mancini, Lorenzo Porzi, Samuel Rota Bulò,
    Barbara Caputo, and Elisa Ricci. Boosting domain adaptation by discovering latent
    domains. In CVPR, 2018.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mancini 等 [2018] Massimiliano Mancini, Lorenzo Porzi, Samuel Rota Bulò, Barbara
    Caputo 和 Elisa Ricci。通过发现潜在领域来提升领域适应。发表于 CVPR, 2018。
- en: Mansour et al. [2009] Yishay Mansour, Mehryar Mohri, and Afshin. Rostamizadeh.
    Domain adaptation with multiple sources. In NIPS, 2009.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mansour 等 [2009] Yishay Mansour, Mehryar Mohri 和 Afshin Rostamizadeh。具有多个源的领域适应。发表于
    NIPS, 2009。
- en: Netzer et al. [2011] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco,
    Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature
    learning. In NIPS Workshops, 2011.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Netzer 等 [2011] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo
    Wu 和 Andrew Y Ng。通过无监督特征学习读取自然图像中的数字。发表于 NIPS Workshops, 2011。
- en: Peng et al. [2019] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko,
    and Bo Wang. Moment matching for multi-source domain adaptation. In ICCV, 2019.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng 等 [2019] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko
    和 Bo Wang。用于多源领域适应的时刻匹配。发表于 ICCV, 2019。
- en: Petrov and McDonald [2012] Slav Petrov and Ryan McDonald. Overview of the 2012
    shared task on parsing the web. In SANCL, 2012.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Petrov 和 McDonald [2012] Slav Petrov 和 Ryan McDonald。2012 年网络解析共享任务概述。发表于 SANCL,
    2012。
- en: Rakshit et al. [2019] Sayan Rakshit, Biplab Banerjee, Gemma Roig, and Subhasis
    Chaudhuri. Unsupervised multi-source domain adaptation driven by deep adversarial
    ensemble learning. In GCPR, 2019.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rakshit 等 [2019] Sayan Rakshit, Biplab Banerjee, Gemma Roig 和 Subhasis Chaudhuri。通过深度对抗集成学习驱动的无监督多源领域适应。发表于
    GCPR, 2019。
- en: 'Richter et al. [2016] Stephan R Richter, Vibhav Vineet, Stefan Roth, and Vladlen
    Koltun. Playing for data: Ground truth from computer games. In ECCV, 2016.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Richter 等 [2016] Stephan R Richter, Vibhav Vineet, Stefan Roth 和 Vladlen Koltun。为数据而玩：来自计算机游戏的真实数据。发表于
    ECCV, 2016。
- en: Riemer et al. [2019] Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu,
    Irina Rish, Yuhai Tu, and Gerald Tesauro. Learning to learn without forgetting
    by maximizing transfer and minimizing interference. In ICLR, 2019.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Riemer 等 [2019] Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina
    Rish, Yuhai Tu 和 Gerald Tesauro。通过最大化迁移和最小化干扰来学习而不遗忘。发表于 ICLR, 2019。
- en: 'Ros et al. [2016] German Ros, Laura Sellart, Joanna Materzynska, David Vazquez,
    and Antonio M Lopez. The synthia dataset: A large collection of synthetic images
    for semantic segmentation of urban scenes. In CVPR, 2016.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ros 等 [2016] German Ros, Laura Sellart, Joanna Materzynska, David Vazquez 和
    Antonio M Lopez。Synthia 数据集：用于城市场景语义分割的大规模合成图像集合。发表于 CVPR, 2016。
- en: Russo et al. [2019] Paolo Russo, Tatiana Tommasi, and Barbara Caputo. Towards
    multi-source adaptive semantic segmentation. In ICIAP, 2019.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russo 等 [2019] Paolo Russo, Tatiana Tommasi 和 Barbara Caputo。朝着多源自适应语义分割的方向发展。发表于
    ICIAP, 2019。
- en: Saenko et al. [2010] Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell.
    Adapting visual category models to new domains. In ECCV, 2010.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saenko 等 [2010] Kate Saenko, Brian Kulis, Mario Fritz 和 Trevor Darrell。将视觉类别模型适应到新领域。发表于
    ECCV, 2010。
- en: Schweikert et al. [2009] Gabriele Schweikert, Gunnar Rätsch, Christian Widmer,
    and Bernhard Schölkopf. An empirical analysis of domain adaptation algorithms
    for genomic sequence analysis. In NIPS, 2009.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schweikert 等 [2009] Gabriele Schweikert, Gunnar Rätsch, Christian Widmer 和 Bernhard
    Schölkopf。基因组序列分析领域适应算法的实证分析。发表于 NIPS, 2009。
- en: Sun et al. [2011] Qian Sun, Rita Chattopadhyay, Sethuraman Panchanathan, and
    Jieping Ye. A two-stage weighting framework for multi-source domain adaptation.
    In NIPS, 2011.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等 [2011] Qian Sun, Rita Chattopadhyay, Sethuraman Panchanathan 和 Jieping
    Ye。用于多源领域适应的两阶段加权框架。发表于 NIPS, 2011。
- en: Sun et al. [2015] Shiliang Sun, Honglei Shi, and Yuanbin Wu. A survey of multi-source
    domain adaptation. Information Fusion, 2015.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等 [2015] Shiliang Sun, Honglei Shi 和 Yuanbin Wu。多源领域适应综述。信息融合, 2015。
- en: Sun et al. [2017] Baochen Sun, Jiashi Feng, and Kate Saenko. Correlation alignment
    for unsupervised domain adaptation. In Domain Adaptation in Computer Vision Applications.
    2017.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等 [2017] Baochen Sun, Jiashi Feng 和 Kate Saenko。用于无监督领域适应的相关性对齐。发表于《计算机视觉应用中的领域适应》，2017。
- en: Torralba and Efros [2011] Antonio Torralba and Alexei A Efros. Unbiased look
    at dataset bias. In CVPR, 2011.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Torralba 和 Efros [2011] Antonio Torralba 和 Alexei A Efros。对数据集偏差的无偏见观察。发表于 CVPR,
    2011。
- en: Tsai et al. [2018] Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn,
    Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output
    space for semantic segmentation. In CVPR, 2018.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tsai 等 [2018] Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn, Ming-Hsuan
    Yang 和 Manmohan Chandraker。学习适应结构化输出空间以进行语义分割。发表于 CVPR, 2018。
- en: Tzeng et al. [2017] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.
    Adversarial discriminative domain adaptation. In CVPR, 2017.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tzeng 等人 [2017] Eric Tzeng、Judy Hoffman、Kate Saenko 和 Trevor Darrell。对抗性判别领域适应。发表于
    CVPR，2017年。
- en: Venkateswara et al. [2017] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty,
    and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation.
    In CVPR, 2017.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Venkateswara 等人 [2017] Hemanth Venkateswara、Jose Eusebio、Shayok Chakraborty
    和 Sethuraman Panchanathan。用于无监督领域适应的深度哈希网络。发表于 CVPR，2017年。
- en: 'Wang et al. [2019] Haotian Wang, Wenjing Yang, Zhipeng Lin, and Yue Yu. Tmda:
    Task-specific multi-source domain adaptation via clustering embedded adversarial
    training. In ICDM, 2019.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2019] Haotian Wang、Wenjing Yang、Zhipeng Lin 和 Yue Yu。Tmda：通过嵌入式对抗训练的任务特定多源领域适应。发表于
    ICDM，2019年。
- en: 'Wu et al. [2019] Bichen Wu, Xuanyu Zhou, Sicheng Zhao, Xiangyu Yue, and Kurt
    Keutzer. Squeezesegv2: Improved model structure and unsupervised domain adaptation
    for road-object segmentation from a lidar point cloud. In ICRA, 2019.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人 [2019] Bichen Wu、Xuanyu Zhou、Sicheng Zhao、Xiangyu Yue 和 Kurt Keutzer。Squeezesegv2：改进的模型结构和用于从激光雷达点云进行路面物体分割的无监督领域适应。发表于
    ICRA，2019年。
- en: 'Xu et al. [2018] Ruijia Xu, Ziliang Chen, Wangmeng Zuo, Junjie Yan, and Liang
    Lin. Deep cocktail network: Multi-source unsupervised domain adaptation with category
    shift. In CVPR, 2018.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人 [2018] Ruijia Xu、Ziliang Chen、Wangmeng Zuo、Junjie Yan 和 Liang Lin。深度鸡尾酒网络：具有类别偏移的多源无监督领域适应。发表于
    CVPR，2018年。
- en: You et al. [2015] Quanzeng You, Jiebo Luo, Hailin Jin, and Jianchao Yang. Robust
    image sentiment analysis using progressively trained and domain transferred deep
    networks. In AAAI, 2015.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: You 等人 [2015] Quanzeng You、Jiebo Luo、Hailin Jin 和 Jianchao Yang。使用渐进训练和领域迁移的深度网络进行鲁棒的图像情感分析。发表于
    AAAI，2015年。
- en: 'You et al. [2016] Quanzeng You, Jiebo Luo, Hailin Jin, and Jianchao Yang. Building
    a large scale dataset for image emotion recognition: The fine print and the benchmark.
    In AAAI, 2016.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: You 等人 [2016] Quanzeng You、Jiebo Luo、Hailin Jin 和 Jianchao Yang。构建大规模图像情感识别数据集：细节和基准。发表于
    AAAI，2016年。
- en: 'Yu et al. [2018] Fisher Yu, Wenqi Xian, Yingying Chen, Fangchen Liu, Mike Liao,
    Vashisht Madhavan, and Trevor Darrell. Bdd100k: A diverse driving video database
    with scalable annotation tooling. arXiv:1805.04687, 2018.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等人 [2018] Fisher Yu、Wenqi Xian、Yingying Chen、Fangchen Liu、Mike Liao、Vashisht
    Madhavan 和 Trevor Darrell。Bdd100k：一个具有可扩展注释工具的多样化驾驶视频数据库。arXiv:1805.04687，2018年。
- en: 'Yue et al. [2019] Xiangyu Yue, Yang Zhang, Sicheng Zhao, Alberto Sangiovanni-Vincentelli,
    Kurt Keutzer, and Boqing Gong. Domain randomization and pyramid consistency: Simulation-to-real
    generalization without accessing target domain data. In ICCV, 2019.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yue 等人 [2019] Xiangyu Yue、Yang Zhang、Sicheng Zhao、Alberto Sangiovanni-Vincentelli、Kurt
    Keutzer 和 Boqing Gong。领域随机化与金字塔一致性：无需访问目标领域数据的模拟到现实的泛化。发表于 ICCV，2019年。
- en: Zhang et al. [2017] Shanghang Zhang, Guanhang Wu, Joao P Costeira, and Jose MF
    Moura. Understanding traffic density from large-scale web camera data. In CVPR,
    2017.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 [2017] Shanghang Zhang、Guanhang Wu、Joao P Costeira 和 Jose MF Moura。从大规模网络摄像头数据中理解交通密度。发表于
    CVPR，2017年。
- en: Zhao et al. [2018a] Han Zhao, Shanghang Zhang, Guanhang Wu, José MF Moura, Joao P
    Costeira, and Geoffrey J Gordon. Adversarial multiple source domain adaptation.
    In NeurIPS, 2018.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人 [2018a] Han Zhao、Shanghang Zhang、Guanhang Wu、José MF Moura、Joao P Costeira
    和 Geoffrey J Gordon。对抗性多源领域适应。发表于 NeurIPS，2018年。
- en: 'Zhao et al. [2018b] Sicheng Zhao, Xin Zhao, Guiguang Ding, and Kurt Keutzer.
    Emotiongan: Unsupervised domain adaptation for learning discrete probability distributions
    of image emotions. In ACM MM, 2018.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人 [2018b] Sicheng Zhao、Xin Zhao、Guiguang Ding 和 Kurt Keutzer。Emotiongan：用于学习图像情感离散概率分布的无监督领域适应。发表于
    ACM MM，2018年。
- en: Zhao et al. [2019a] Sicheng Zhao, Bo Li, Xiangyu Yue, Yang Gu, Pengfei Xu, Runbo
    Hu, Hua Chai, and Kurt Keutzer. Multi-source domain adaptation for semantic segmentation.
    In NeurIPS, 2019.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人 [2019a] Sicheng Zhao、Bo Li、Xiangyu Yue、Yang Gu、Pengfei Xu、Runbo Hu、Hua
    Chai 和 Kurt Keutzer。用于语义分割的多源领域适应。发表于 NeurIPS，2019年。
- en: 'Zhao et al. [2019b] Sicheng Zhao, Chuang Lin, Pengfei Xu, Sendong Zhao, Yuchen
    Guo, Ravi Krishna, Guiguang Ding, and Kurt Keutzer. Cycleemotiongan: Emotional
    semantic consistency preserved cyclegan for adapting image emotions. In AAAI,
    2019.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人 [2019b] Sicheng Zhao、Chuang Lin、Pengfei Xu、Sendong Zhao、Yuchen Guo、Ravi
    Krishna、Guiguang Ding 和 Kurt Keutzer。Cycleemotiongan：情感语义一致性保持的 cyclegan 用于适应图像情感。发表于
    AAAI，2019年。
- en: Zhao et al. [2020] Sicheng Zhao, Guangzhi Wang, Shanghang Zhang, Yang Gu, Yaxian
    Li, Zhichao Song, Pengfei Xu, Runbo Hu, Hua Chai, and Kurt Keutzer. Multi-source
    distilling domain adaptation. In AAAI, 2020.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人 [2020] Sicheng Zhao、Guangzhi Wang、Shanghang Zhang、Yang Gu、Yaxian Li、Zhichao
    Song、Pengfei Xu、Runbo Hu、Hua Chai 和 Kurt Keutzer。多源蒸馏领域适应。发表于 AAAI，2020年。
- en: Zhu et al. [2017] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros.
    Unpaired image-to-image translation using cycle-consistent adversarial networks.
    In ICCV, 2017.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu et al. [2017] 军彦·朱、太成·朴、菲利普·伊索拉和亚历克谢·A·埃夫罗斯。在 ICCV 2017 中，使用循环一致对抗网络进行无配对图像到图像的转换。
- en: Zhu et al. [2019] Yongchun Zhu, Fuzhen Zhuang, and Deqing Wang. Aligning domain-specific
    distribution and classifier for cross-domain classification from multiple sources.
    In AAAI, 2019.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu et al. [2019] 永春·朱、富臻·庄和德庆·王。在 AAAI 2019 中，跨域分类中的领域特定分布和分类器对齐。
