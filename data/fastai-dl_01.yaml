- en: 'Deep Learning 2: Part 1 Lesson 1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习 2：第 1 部分 第 1 课
- en: 原文：[https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197](https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197)'
- en: '*My personal notes from* [*fast.ai course*](http://www.fast.ai/)*. These notes
    will continue to be updated and improved as I continue to review the course to
    “really” understand it. Much appreciation to* [*Jeremy*](https://twitter.com/jeremyphoward)
    *and* [*Rachel*](https://twitter.com/math_rachel) *who gave me this opportunity
    to learn.*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*我从* [*fast.ai 课程*](http://www.fast.ai/)* 中的个人笔记。随着我继续复习课程以“真正”理解它，这些笔记将继续更新和改进。非常感谢*
    [*Jeremy*](https://twitter.com/jeremyphoward) *和* [*Rachel*](https://twitter.com/math_rachel)
    *给了我这个学习的机会。*'
- en: '[Lesson 1](http://forums.fast.ai/t/wiki-lesson-1/9398/1)'
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[第一课](http://forums.fast.ai/t/wiki-lesson-1/9398/1)'
- en: 'Getting started [[0:00](https://youtu.be/IPBSB1HLNLo)]:'
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始 [[0:00](https://youtu.be/IPBSB1HLNLo)]：
- en: In order to train a neural network, you will most certainly need Graphics Processing
    Unit (GPU) — specifically NVIDIA GPU because it is the only one that supports
    CUDA (the language and framework that nearly all deep learning libraries and practitioners
    use).
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了训练神经网络，您几乎肯定需要图形处理单元（GPU） —— 具体来说是 NVIDIA GPU，因为它是唯一支持 CUDA（几乎所有深度学习库和从业者使用的语言和框架）的GPU。
- en: 'There are several ways to rent GPU: Crestle [[04:06](https://youtu.be/IPBSB1HLNLo?t=4m6s)],
    Paperspace [[06:10](https://youtu.be/IPBSB1HLNLo?t=6m10s)]'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有几种租用 GPU 的方法：Crestle [[04:06](https://youtu.be/IPBSB1HLNLo?t=4m6s)], Paperspace
    [[06:10](https://youtu.be/IPBSB1HLNLo?t=6m10s)]
- en: '[Introduction to Jupyter Notebook and Dogs vs. Cats](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb)
    [[12:39](https://youtu.be/IPBSB1HLNLo?t=12m39s)]'
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[Jupyter Notebook 和 猫狗分类简介](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb)
    [[12:39](https://youtu.be/IPBSB1HLNLo?t=12m39s)]'
- en: You can run a cell by selecting it and hitting `shift+enter` (you can hold down
    `shift` and hit `enter` multiple times to keep going down the cells), or you can
    click on Run button at the top. A cell can contain code, text, picture, video,
    etc.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以通过选择单元格并按`shift+enter`来运行单元格（您可以按住`shift`并多次按`enter`以继续向下移动单元格），或者您可以点击顶部的运行按钮。一个单元格可以包含代码、文本、图片、视频等。
- en: Fast.ai requires Python 3
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fast.ai 需要 Python 3
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**First look at pictures [**[**15:39**](https://youtu.be/IPBSB1HLNLo?t=15m40s)**]**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**首先看图片 [**[**15:39**](https://youtu.be/IPBSB1HLNLo?t=15m40s)**]**'
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`!` tells to use bash (shell) instead of python'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`!` 告诉使用 bash（shell）而不是 python'
- en: If you are not familiar with training set and validation set, check out Practical
    Machine Learning class (or read [Rachel’s blog](http://www.fast.ai/2017/11/13/validation-sets/))
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您不熟悉训练集和验证集，请查看实用机器学习课程（或阅读[Rachel的博客](http://www.fast.ai/2017/11/13/validation-sets/)）
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This folder structure is the most common approach for how image classification
    dataset is shared and provided. Each folder tells you the label (e.g. `dogs` or
    `cats`).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个文件夹结构是共享和提供图像分类数据集的最常见方法。每个文件夹告诉您标签（例如`dogs`或`cats`）。
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`f’{PATH}valid/cats/{files[0]}’` — This is a Python 3.6\. format string which
    is a convenient to format a string.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`f’{PATH}valid/cats/{files[0]}’` — 这是 Python 3.6\. 格式化字符串，是一种方便的格式化字符串的方法。'
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`img` is a 3 dimensional array (a.k.a. rank 3 tensor)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`img` 是一个三维数组（也称为秩为3的张量）。'
- en: The three items (e.g. `[29, 20, 23]`) represents Red Green Blue pixel values
    between 0 and 255
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这三个项目（例如`[29, 20, 23]`）代表介于 0 和 255 之间的红绿蓝像素值。
- en: The idea is to take these numbers and use them to predict whether those numbers
    represent a cat or a dog based on looking at lots of pictures of cats and dogs.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个想法是拿这些数字并使用它们来预测这些数字是否代表一只猫还是一只狗，基于查看大量猫和狗的图片。
- en: This dataset comes from [Kaggle competition](https://www.kaggle.com/c/dogs-vs-cats),
    and when it was released (back in 2013) the state-of-the-art was 80% accurate.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个数据集来自[Kaggle 竞赛](https://www.kaggle.com/c/dogs-vs-cats)，当它发布时（2013年），最先进的技术准确率为
    80%。
- en: '**Let’s train a model [**[**20:21**](https://youtu.be/IPBSB1HLNLo?t=20m21s)**]**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**让我们训练一个模型 [**[**20:21**](https://youtu.be/IPBSB1HLNLo?t=20m21s)**]**'
- en: 'Here are the three lines of code necessary to train a model:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这是训练模型所需的三行代码：
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This will do 3 **epochs** which means it is going to look at the entire set
    of images three times.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这将进行 3 **轮**，这意味着它将三次查看整个图像集。
- en: The last of three numbers in the output is the accuracy on the validation set.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出中的三个数字中的最后一个是验证集上的准确率。
- en: The first two are the value of loss function (in this case the cross-entropy
    loss) for the training set and the validation set.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前两个是训练集和验证集的损失函数值（在本例中是交叉熵损失）。
- en: The start (e.g. `0.`, `1.`) is the epoch number.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 起始（例如`0.`、`1.`）是轮数。
- en: We achieved ~99% (which would have won the Kaggle competition back in 2013)
    in 17 seconds with 3 lines of code! [[21:49](https://youtu.be/IPBSB1HLNLo?t=21m49s)]
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在 17 秒内用 3 行代码实现了约 99% 的准确率（这在2013年将赢得 Kaggle 竞赛）！[[21:49](https://youtu.be/IPBSB1HLNLo?t=21m49s)]
- en: A lot of people assume that deep learning takes a huge amount of time, lots
    of resources, and lots of data — that, in general, is not true!
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很多人认为深度学习需要大量时间、资源和数据 —— 总的来说，这并不是真的！
- en: Fast.ai Library [[22:24](https://youtu.be/IPBSB1HLNLo?t=22m24s)]
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Fast.ai 库 [[22:24](https://youtu.be/IPBSB1HLNLo?t=22m24s)]
- en: The library takes all of the best practices and approaches they can find — each
    time a paper comes out that looks interesting, they test it out and if it works
    well for a variety of datasets and they can figure out how to tune it, it gets
    implement it in the library.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该库采用了他们能找到的所有最佳实践和方法 —— 每次有一篇看起来有趣的论文出来时，他们会测试它，如果它在各种数据集上表现良好并且他们能够找出如何调整它，那么它就会被实现在库中。
- en: Fast.ai curates all these best practices and packages up for you, and most of
    the time, figures out the best way to handle things automatically.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fast.ai 为您整理了所有这些最佳实践并打包起来，大多数情况下，会自动找出最佳处理方式。
- en: Fast.ai sits on top of a library called PyTorch which is a really flexible deep
    learning, machine learning, and GPU computation library written by Facebook.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fast.ai建立在一个名为PyTorch的库之上，这是一个由Facebook编写的非常灵活的深度学习、机器学习和GPU计算库。
- en: Most people are more familiar with TensorFlow than PyTorch, but most of the
    top researchers Jeremy knows nowadays have switched across to PyTorch.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数人对TensorFlow比PyTorch更熟悉，但Jeremy现在认识的大多数顶尖研究人员已经转向PyTorch。
- en: Fast.ai is flexible that you can use all these curated best practices as much
    or as little as you want. It is easy to hook in at any point and write your own
    data augmentation, loss function, network architecture, etc, and we will learn
    all that in this course.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fast.ai非常灵活，您可以根据需要使用所有这些精心策划的最佳实践。您可以轻松地在任何时候连接并编写自己的数据增强、损失函数、网络架构等，我们将在本课程中学习所有这些。
- en: Analyzing results [[24:21](https://youtu.be/IPBSB1HLNLo?t=24m12s)]
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析结果[[24:21](https://youtu.be/IPBSB1HLNLo?t=24m12s)]
- en: 'This is what the validation dataset label (think of it as the correct answers)
    looks like:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是验证数据集标签（将其视为正确答案）的样子：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: What do these 0’s and 1’s represents?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些0和1代表什么？
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`data` contains the validation and training data'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data`包含验证和训练数据'
- en: '`learn` contains the model'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learn`包含模型'
- en: 'Let’s make predictions for the validation set (predictions are in log scale):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对验证集进行预测（预测以对数刻度表示）：
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The output represents a prediction for cats, and prediction for dogs
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出表示对猫的预测和对狗的预测
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In PyTorch and Fast.ai, most models return the log of the predictions rather
    than the probabilities themselves (we will learn why later in the course). For
    now, just know that to get probabilities, you have to do `np.exp()`
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在PyTorch和Fast.ai中，大多数模型返回预测的对数而不是概率本身（我们将在课程中稍后学习原因）。现在，只需知道要获得概率，您必须执行`np.exp()`
- en: Make sure you familiarize yourself with numpy (`np`)
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保您熟悉numpy（`np`）
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The number above the image is the probability of being a dog
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像上方的数字是狗的概率
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'More interestingly, here are what the model thought it was definitely a dog
    but turns out to be a cat, or vice versa:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 更有趣的是，以下是模型认为肯定是狗的东西，但结果是猫，反之亦然：
- en: '[PRE14]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Why is it important to look at these images? The first thing Jeremy does after
    he builds a model is to find a way to visualize what it has built. Because if
    he wants to make the model better, then he needs to take advantage of the things
    that is doing well and fix the things that is doing badly.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么查看这些图像很重要？Jeremy在构建模型后的第一件事是找到一种可视化其构建内容的方法。因为如果他想让模型更好，那么他需要利用做得好的事情并修复做得不好的事情。
- en: In this case, we have learned something about the dataset itself which is that
    there are some images that are in here that probably should not be. But it is
    also clear that this model has room to improve (e.g. data augmentation — which
    we will learn later).
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这种情况下，我们已经了解了数据集本身的一些信息，即这里有一些可能不应该存在的图像。但很明显，这个模型还有改进的空间（例如数据增强 - 我们将在以后学习）。
- en: Now you are ready to build your own image classifier (for regular photos — maybe
    not CT scan)! For example, [here](https://towardsdatascience.com/fun-with-small-image-data-sets-8c83d95d0159)
    is what one of the students did.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，您已经准备好构建自己的图像分类器（用于常规照片 - 也许不是CT扫描）！例如，[这里](https://towardsdatascience.com/fun-with-small-image-data-sets-8c83d95d0159)是一个学生的示例。
- en: Check out [this forum post](http://forums.fast.ai/t/understanding-softmax-probabilities-output-on-a-multi-class-classification-problem/8194)
    for different way of visualizing the results (e.g. when there are more than 2
    categories, etc)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看[此论坛帖子](http://forums.fast.ai/t/understanding-softmax-probabilities-output-on-a-multi-class-classification-problem/8194)以了解不同的可视化结果方式（例如，当存在超过2个类别时等）
- en: Top-down vs Bottom-up [[30:52](https://youtu.be/IPBSB1HLNLo?t=30m52s)]
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自上而下 vs 自下而上[[30:52](https://youtu.be/IPBSB1HLNLo?t=30m52s)]
- en: 'Bottom-up: learn each building block you need, and eventually put them together'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 自下而上：学习您需要的每个构建块，最终将它们组合在一起
- en: Hard to maintain motivation
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 难以保持动力
- en: Hard to know the “big picture”
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 难以了解“全局图景”
- en: Hard to know which pieces you’ll actually need
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 难以知道您实际需要哪些部分
- en: 'fast.ai: Get students using a neural net right away, getting results ASAP'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: fast.ai：让学生立即使用神经网络，尽快获得结果
- en: Gradually peel back the layers, modify, look under the hood
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐渐剥开层，修改，查看内部
- en: Course Structure [[33:53](https://youtu.be/IPBSB1HLNLo?t=33m53s)]
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课程结构[[33:53](https://youtu.be/IPBSB1HLNLo?t=33m53s)]
- en: Image classifier with deep learning (with fewest lines of code)
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用深度学习的图像分类器（代码行数最少）
- en: Multi-label classification and different kinds of images (e.g. satellite images)
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 多标签分类和不同类型的图像（例如卫星图像）
- en: Structured data (e.g. sales forecasting) — structured data is what comes from
    database or spreadsheet
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结构化数据（例如销售预测）- 结构化数据来自数据库或电子表格
- en: 'Language: NLP classifier (e.g. movie review classification)'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 语言：NLP分类器（例如电影评论分类）
- en: Collaborative filtering (e.g. recommendation engine)
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 协同过滤（例如推荐引擎）
- en: 'Generative language model: How to write your own Nietzsche philosophy from
    scratch character by character'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成语言模型：如何逐个字符从头开始编写您自己的尼采哲学
- en: Back to computer vision — not just recognize a cat photo, but find where the
    cat is in the photo (heat map) and also learn how to write our own architecture
    from scratch (ResNet)
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回到计算机视觉 - 不仅识别猫照片，还要找到照片中的猫所在位置（热图），并学习如何从头开始编写我们自己的架构（ResNet）
- en: 'Image Classifier Examples:'
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像分类器示例：
- en: Image classification algorithm is useful for lots and lots of things.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类算法对许多事物非常有用。
- en: 'For example, AlphaGo [[42:20](https://youtu.be/IPBSB1HLNLo?t=42m20s)] looked
    at thousands and thousands of go boards and each one had a label saying whether
    the go board ended up being the winning or the losing player’s. So it learnt an
    image classification that was able to look at a go board and figure out whether
    it was a good or bad — which is the most important step in playing go well: to
    know which move is better.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，AlphaGo[[42:20](https://youtu.be/IPBSB1HLNLo?t=42m20s)]查看了成千上万个围棋棋盘，每个棋盘上都有一个标签，说明这个棋盘最终是赢家还是输家。因此，它学会了一种能够查看围棋棋盘并判断它是好还是坏的图像分类——这是打好围棋最重要的一步：知道哪一步走得更好。
- en: Another example is an earlier student created [an image classifier of mouse
    movement images](https://www.splunk.com/blog/2017/04/18/deep-learning-with-splunk-and-tensorflow-for-security-catching-the-fraudster-in-neural-networks-with-behavioral-biometrics.html)
    and detected fraudulent transactions.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个例子是一个早期的学生创建了[一个鼠标移动图像分类器](https://www.splunk.com/blog/2017/04/18/deep-learning-with-splunk-and-tensorflow-for-security-catching-the-fraudster-in-neural-networks-with-behavioral-biometrics.html)并检测到欺诈交易。
- en: Deep Learning ≠Machine Learning [[44:26](https://youtu.be/IPBSB1HLNLo?t=44m26s)]
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习≠机器学习[[44:26](https://youtu.be/IPBSB1HLNLo?t=44m26s)]
- en: Deep learning is a kind of machine learning
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习是一种机器学习
- en: Machine learning was invented by Arthur Samuel. In the late 50s, he got an IBM
    mainframe to play checkers better than he could by inventing machine learning.
    He made the mainframe to play against itself lots of times and figure out which
    kind of things led to victories, and used that to, in a way, write its own program.
    In 1962, Arthur Samuel said one day, the vast majority of computer software would
    be written using this machine learning approach rather than written by hand.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习是由Arthur Samuel发明的。在50年代末，他让IBM大型机比他更擅长下棋，发明了机器学习。他让大型机反复对弈，并找出导致胜利的种种因素，然后利用这些因素，以某种方式编写自己的程序。1962年，Arthur
    Samuel说，未来绝大多数计算机软件将使用这种机器学习方法编写，而不是手工编写。
- en: C-Path (Computational Pathologist)[[45:42](https://youtu.be/IPBSB1HLNLo?t=45m42s)]
    is an example of traditional machine learning approach. He took pathology slides
    of breast cancer biopsies, consulted many pathologists on ideas about what kinds
    of patterns or features might be associated with long-term survival. Then they
    wrote specialist algorithms to calculate these features, run through logistic
    regression, and predicted the survival rate. It outperformed pathologists, but
    it took domain experts and computer experts many years of work to build.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C-Path（计算病理学家）[[45:42](https://youtu.be/IPBSB1HLNLo?t=45m42s)]是传统机器学习方法的一个例子。他拍摄了乳腺癌活检的病理学切片，咨询了许多病理学家关于与长期生存相关的模式或特征可能是什么。然后，他们编写了专家算法来计算这些特征，通过逻辑回归进行运算，并预测了生存率。它胜过了病理学家，但需要领域专家和计算机专家多年的工作才能构建。
- en: A better way [[47:35](https://youtu.be/IPBSB1HLNLo?t=47m35s)]
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更好的方法[[47:35](https://youtu.be/IPBSB1HLNLo?t=47m35s)]
- en: A class of algorithm that have these three properties is Deep Learning.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有这三个特性的算法类别是深度学习。
- en: 'Infinitely flexible function: Neural Network [[48:43](https://youtu.be/IPBSB1HLNLo?t=48m43s)]'
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无限灵活的函数：神经网络[[48:43](https://youtu.be/IPBSB1HLNLo?t=48m43s)]
- en: 'Underlying function that deep learning uses is called the neural network:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习使用的基础函数称为神经网络：
- en: All you need to know for now is that it consists of a number of simple linear
    layers interspersed with a number of simple non-linear layers. When you intersperse
    these layers, you get something called the universal approximation theorem. What
    universal approximation theorem says is that this kind of function can solve any
    given problem to arbitrarily close accuracy as long as you add enough parameters.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在你需要知道的是，它由许多简单的线性层和许多简单的非线性层组成。当你交错这些层时，你会得到一个称为通用逼近定理的东西。通用逼近定理所说的是，只要添加足够的参数，这种函数可以解决任何给定的问题，达到任意接近的精度。
- en: 'All purpose parameter fitting: Gradient Descent [[49:39](https://youtu.be/IPBSB1HLNLo?t=49m39s)]'
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全能参数拟合：梯度下降[[49:39](https://youtu.be/IPBSB1HLNLo?t=49m39s)]
- en: 'Fast and scalable: GPU [[51:05](https://youtu.be/IPBSB1HLNLo?t=51m5s)]'
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速且可扩展：GPU[[51:05](https://youtu.be/IPBSB1HLNLo?t=51m5s)]
- en: The neural network example shown above has one hidden layer. Something what
    we learned in the past few years is that these kind of neural network was not
    fast or scalable unless we added multiple hidden layers — hence called “Deep”
    learning.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 上面显示的神经网络示例有一个隐藏层。我们在过去几年学到的一些东西是，这种神经网络如果不添加多个隐藏层，就不会快速或可扩展，因此被称为“深度”学习。
- en: Putting all together [[53:40](https://youtu.be/IPBSB1HLNLo?t=53m40s)]
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将所有内容放在一起[[53:40](https://youtu.be/IPBSB1HLNLo?t=53m40s)]
- en: 'Here are some of the examples:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些例子：
- en: '[https://research.googleblog.com/2015/11/computer-respond-to-this-email.html](https://research.googleblog.com/2015/11/computer-respond-to-this-email.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://research.googleblog.com/2015/11/computer-respond-to-this-email.html](https://research.googleblog.com/2015/11/computer-respond-to-this-email.html)'
- en: '[https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/](https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/](https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/)'
- en: '[https://www.skype.com/en/features/skype-translator/](https://www.skype.com/en/features/skype-translator/)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.skype.com/en/features/skype-translator/](https://www.skype.com/en/features/skype-translator/)'
- en: '[https://arxiv.org/abs/1603.01768](https://arxiv.org/abs/1603.01768)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/abs/1603.01768](https://arxiv.org/abs/1603.01768)'
- en: Diagnosing lung cancer [[56:55](https://youtu.be/IPBSB1HLNLo?t=56m55s)]
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 诊断肺癌[[56:55](https://youtu.be/IPBSB1HLNLo?t=56m55s)]
- en: 'Other current applications:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 其他当前应用：
- en: Convolutional Neural Network [[59:13](https://youtu.be/IPBSB1HLNLo?t=59m13s)]
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络[[59:13](https://youtu.be/IPBSB1HLNLo?t=59m13s)]
- en: Linear Layer
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性层
- en: '[http://setosa.io/ev/image-kernels/](http://setosa.io/ev/image-kernels/)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://setosa.io/ev/image-kernels/](http://setosa.io/ev/image-kernels/)'
- en: Nonlinear Layer [[01:02:12](https://youtu.be/IPBSB1HLNLo?t=1h2m12s)]
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非线性层[[01:02:12](https://youtu.be/IPBSB1HLNLo?t=1h2m12s)]
- en: '[](http://neuralnetworksanddeeplearning.com/chap4.html?source=post_page-----602f73869197--------------------------------)
    [## Neural networks and deep learning'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[](http://neuralnetworksanddeeplearning.com/chap4.html?source=post_page-----602f73869197--------------------------------)
    [## 神经网络和深度学习'
- en: In this chapter I give a simple and mostly visual explanation of the universality
    theorem. We'll go step by step…
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在这一章中，我给出了普适性定理的简单且大部分是可视化的解释。我们将一步一步地进行...
- en: neuralnetworksanddeeplearning.com](http://neuralnetworksanddeeplearning.com/chap4.html?source=post_page-----602f73869197--------------------------------)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络与深度学习.com](http://neuralnetworksanddeeplearning.com/chap4.html?source=post_page-----602f73869197--------------------------------)
- en: Sigmoid and ReLU
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid和ReLU
- en: A combination of linear layer followed by an element-wise nonlinear function
    allows us to create arbitrarily complex shapes — this is the essence of the universal
    approximation theorem.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性层和逐元素非线性函数的组合使我们能够创建任意复杂的形状 — 这是普适性定理的本质。
- en: How to set these parameters to solve problems [[01:04:25](https://youtu.be/IPBSB1HLNLo?t=1h4m25s)]
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何设置这些参数来解决问题[[01:04:25](https://youtu.be/IPBSB1HLNLo?t=1h4m25s)]
- en: Stochastic Gradient Descent — we take small steps down the hill. The step size
    is called **learning rate**
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机梯度下降 — 我们沿着山坡小步前进。步长被称为**学习率**
- en: If learning rate is too large, it will diverge instead of converge
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果学习率太大，它会发散而不是收敛
- en: If learning rate is too small, it will take forever
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果学习率太小，将需要很长时间
- en: Visualizing and Understanding Convolutional Networks [[01:08:27](https://youtu.be/IPBSB1HLNLo?t=1h8m27s)]
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化和理解卷积网络[[01:08:27](https://youtu.be/IPBSB1HLNLo?t=1h8m27s)]
- en: We started with something incredibly simple but if we use it as a big enough
    scale, thanks to the universal approximation theorem and the use of multiple hidden
    layers in deep learning, we actually get the very very rich capabilities. This
    is actually what we used when we used when we trained our dog vs cat recognizer.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一些非常简单的东西开始，但如果我们将其用作足够大的规模，由于普适性定理和深度学习中多个隐藏层的使用，我们实际上获得了非常丰富的能力。这实际上是我们在训练狗和猫识别器时使用的方法。
- en: Dog vs. Cat Revisited — Choosing a learning rate [[01:11:41](https://youtu.be/IPBSB1HLNLo?t=1h11m41s)]
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 狗 vs. 猫再访——选择学习率[[01:11:41](https://youtu.be/IPBSB1HLNLo?t=1h11m41s)]
- en: '[PRE17]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The first number `0.01` is the learning rate.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个数字`0.01`是学习率。
- en: The *learning rate* determines how quickly or how slowly you want to update
    the *weights* (or *parameters*). Learning rate is one of the most difficult parameters
    to set, because it significantly affect model performance.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学习率*决定了你想要多快或多慢地更新*权重*（或*参数*）。学习率是最难设置的参数之一，因为它会显著影响模型性能。'
- en: The method `learn.lr_find()` helps you find an optimal learning rate. It uses
    the technique developed in the 2015 paper [Cyclical Learning Rates for Training
    Neural Networks](http://arxiv.org/abs/1506.01186), where we simply keep increasing
    the learning rate from a very small value, until the loss stops decreasing. We
    can plot the learning rate across batches to see what this looks like.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法`learn.lr_find()`可以帮助你找到一个最佳的学习率。它使用了2015年的论文[Cyclical Learning Rates for
    Training Neural Networks](http://arxiv.org/abs/1506.01186)中开发的技术，我们简单地从一个非常小的值开始不断增加学习率，直到损失停止减少。我们可以绘制跨批次的学习率，看看这是什么样子。
- en: '[PRE18]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Our `learn` object contains an attribute `sched` that contains our learning
    rate scheduler, and has some convenient plotting functionality including this
    one:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`learn`对象包含一个包含我们学习率调度器的属性`sched`，并具有一些方便的绘图功能，包括这个：
- en: '[PRE19]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Jeremy is currently experimenting with increasing the learning rate exponentially
    vs. linearly.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jeremy目前正在尝试指数增加学习率与线性增加学习率。
- en: 'We can see the plot of loss versus learning rate to see where our loss stops
    decreasing:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到损失与学习率的图表，以查看我们的损失何时停止减少：
- en: '[PRE20]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We then pick the learning rate where the loss is still clearly improving — in
    this case `1e-2` (0.01)
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们选择损失仍然明显改善的学习率 — 在这种情况下是`1e-2`（0.01）
- en: Choosing number of epochs [[1:18:49](https://youtu.be/IPBSB1HLNLo?t=1h18m49s)]
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择迭代次数[[1:18:49](https://youtu.be/IPBSB1HLNLo?t=1h18m49s)]
- en: '[PRE21]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: As many as you would like, but accuracy might start getting worse if you run
    it for too long. It is something called “overfitting” and we will learn more about
    it later.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要多少都可以，但如果运行时间太长，准确性可能会开始变差。这被称为“过拟合”，我们稍后会更多地了解它。
- en: Another consideration is the time available to you.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个考虑因素是你可用的时间。
- en: Tips and Tricks [[1:21:40](https://youtu.be/IPBSB1HLNLo?t=1h21m40s)]
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技巧和窍门[[1:21:40](https://youtu.be/IPBSB1HLNLo?t=1h21m40s)]
- en: '**1.**`Tab` — it will do an auto complete when you cannot remember the function
    name'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.**`Tab` — 当你记不住函数名时，它会自动完成'
- en: '**2.** `Shift + Tab` — it will show you the arguments of a function'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.** `Shift + Tab` — 它会显示函数的参数'
- en: '**3.** `Shift + Tab + Tab` — it will bring up a documentation (i.e. docstring)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**3.** `Shift + Tab + Tab` — 它会显示文档（即docstring）'
- en: '**4.** `Shift + Tab + Tab + Tab` — it will open a separate window with the
    same information.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**4.** `Shift + Tab + Tab + Tab` — 它会打开一个带有相同信息的单独窗口。'
- en: Typing `?` followed by a function name in a cell and running it will do the
    same as `shift + tab (3 times)`
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在单元格中键入`?`后跟一个函数名并运行它将与`shift + tab（3次）`相同
- en: '**5.** Typing two question mark will display the source code'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**5.** 输入两个问号将显示源代码'
- en: '**6\.** Typing `H` in Jupyter Notebook will open up a window with keyboard
    shortcuts. Try learning 4 or 5 shortcuts a day'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**6\.** 在Jupyter Notebook中键入`H`将打开一个带有键盘快捷键的窗口。尝试每天学习4或5个快捷键'
- en: '**7\.** Stop Paperspace, Crestle, AWS — otherwise you’ll be charged $$'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**7\.** 停止Paperspace、Crestle、AWS — 否则你将被收费$$'
- en: '**8\.** Please remember about the [forum](http://forums.fast.ai/) and [http://course.fast.ai/](http://course.fast.ai/)
    (for each lesson) for up-to-date information.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**8\.** 请记住关于[论坛](http://forums.fast.ai/)和[http://course.fast.ai/](http://course.fast.ai/)（每节课）的最新信息。'
