- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 19:37:46'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:37:46
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2307.15615] A survey on deep learning in medical image registration: new technologies,
    uncertainty, evaluation metrics, and beyond'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2307.15615] 深度学习在医学图像配准中的调查：新技术、不确定性、评估指标及其他'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2307.15615](https://ar5iv.labs.arxiv.org/html/2307.15615)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2307.15615](https://ar5iv.labs.arxiv.org/html/2307.15615)
- en: 'A survey on deep learning in medical image registration: new technologies,
    uncertainty, evaluation metrics, and beyond'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在医学图像配准中的调查：新技术、不确定性、评估指标及其他
- en: Junyu Chen¹¹1Contributed equally to this work. Yihao Liu²²2Contributed equally
    to this work. Shuwen Wei³³3Contributed equally to this work. Zhangxing Bian Shalini
    Subramanian Aaron Carass Jerry L. Prince Yong Du Department of Radiology and Radiological
    Science, Johns Hopkins School of Medicine, MD, USA Department of Electrical and
    Computer Engineering, Johns Hopkins University, MD, USA
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 陈俊宇¹¹1对本文贡献相同。刘一豪²²2对本文贡献相同。魏书文³³3对本文贡献相同。边章兴 Shalini Subramanian Aaron Carass
    Jerry L. Prince Yong Du 约翰斯·霍普金斯医学院放射学与放射科学系，美国马里兰州 约翰斯·霍普金斯大学电气与计算机工程系，美国马里兰州
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep learning technologies have dramatically reshaped the field of medical image
    registration over the past decade. The initial developments, such as ResNet-based
    and U-Net-based networks, established the foundation for deep learning in image
    registration. Subsequent progress has been made in various aspects of deep learning-based
    registration, including similarity measures, deformation regularizations, and
    uncertainty estimation. These advancements have not only enriched the field of
    image registration but have also facilitated its application in a wide range of
    tasks, including atlas construction, multi-atlas segmentation, motion estimation,
    and 2D-3D registration. In this paper, we present a comprehensive overview of
    the most recent advancements in deep learning-based image registration. We begin
    with a concise introduction to the core concepts of deep learning-based image
    registration. Then, we delve into innovative network architectures, loss functions
    specific to registration, and methods for estimating registration uncertainty.
    Additionally, this paper explores appropriate evaluation metrics for assessing
    the performance of deep learning models in registration tasks. Finally, we highlight
    the practical applications of these novel techniques in medical imaging and discuss
    the future prospects of deep learning-based image registration.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 过去十年中，深度学习技术已经彻底改变了医学图像配准领域。最初的进展，如基于ResNet和U-Net的网络，为深度学习在图像配准中的应用奠定了基础。随后的进展涉及深度学习基础的配准的各个方面，包括相似性度量、变形正则化和不确定性估计。这些进展不仅丰富了图像配准的领域，还促进了其在多种任务中的应用，包括图谱构建、多图谱分割、运动估计和2D-3D配准。本文全面概述了深度学习基础的图像配准中的最新进展。我们首先简要介绍了深度学习基础的图像配准的核心概念。然后，我们深入探讨了创新的网络架构、特定于配准的损失函数以及估计配准不确定性的方法。此外，本文还探讨了评估深度学习模型在配准任务中表现的适当评估指标。最后，我们强调了这些新技术在医学影像中的实际应用，并讨论了深度学习基础的图像配准的未来前景。
- en: 'keywords:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: \KWDImage Registration, Deep Neural Networks, Medical Imaging\DeclareMathOperator
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: \KWD图像配准、深度神经网络、医学影像\DeclareMathOperator
- en: '*\argmaxarg max \DeclareMathOperator*\argminarg min'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*\argmaxarg max \DeclareMathOperator*\argminarg min'
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Medical image registration involves estimating the optimal spatial transformation
    to align the structures of interest in a pair of fixed and moving images. The
    choice of spatial transformation depends on the specific application and can be
    categorized as either rigid/affine or non-rigid/deformable. In rigid/affine registration,
    all spatial coordinates are transformed using the same rigid/affine matrix. On
    the other hand, non-rigid/deformable registration employs independent transformations
    for individual local regions of spatial coordinates. Both types of registration
    are of great importance to many medical imaging tasks. Rigid registration is commonly
    used when the rigid body assumption holds. For example, it is used to align a
    structural scan—*e.g.*, magnetic resonance image (MRI) or computed tomography (CT)—with
    a functional scan—*e.g.*, functional magnetic resonance image (fMRI) or positron
    emission tomography (PET)—of the same patient for attenuation correction [[139](#bib.bib139)]
    or interpretation of functional activities [[309](#bib.bib309)]. On the other
    hand, deformable image registration (DIR) is often used in cases where more complex,
    spatially varying deformations are needed. Examples of such applications include
    constructing deformable templates for a patient cohort [[51](#bib.bib51), [100](#bib.bib100)]
    or registering atlases to a patient image for multi-atlas segmentation [[270](#bib.bib270),
    [30](#bib.bib30), [2](#bib.bib2)].
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 医学图像配准涉及估计最佳的空间变换，以对齐一对固定图像和移动图像中的感兴趣结构。空间变换的选择取决于具体应用，可以分为刚性/仿射或非刚性/可变形。对于刚性/仿射配准，所有空间坐标都使用相同的刚性/仿射矩阵进行变换。另一方面，非刚性/可变形配准则为空间坐标的每个局部区域采用独立的变换。这两种配准类型对于许多医学成像任务都非常重要。刚性配准通常在刚体假设成立时使用。例如，它用于将结构扫描—*例如*，磁共振成像（MRI）或计算机断层扫描（CT）—与功能扫描—*例如*，功能性磁共振成像（fMRI）或正电子发射断层扫描（PET）—对齐，以进行衰减校正[[139](#bib.bib139)]或功能活动的解释[[309](#bib.bib309)]。另一方面，当需要更复杂、空间变化的变形时，通常使用可变形图像配准（DIR）。这类应用的示例包括为患者队列构建可变形模板[[51](#bib.bib51),
    [100](#bib.bib100)]或将图谱配准到患者图像以进行多图谱分割[[270](#bib.bib270), [30](#bib.bib30), [2](#bib.bib2)]。
- en: '![Refer to caption](img/970ecd8b4d7822b2a98b8528ba966857.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/970ecd8b4d7822b2a98b8528ba966857.png)'
- en: 'Fig. 1: Statistics of the articles investigated in this survey paper. The left
    panel displays a histogram of the number of papers by year; the vast majority
    of the surveyed papers were proposed within the last five years. The right panel
    illustrates the sources of the investigated articles, demonstrating that our survey
    draws from sources associated with the field of medical image analysis.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：本调查论文中所研究文章的统计数据。左侧面板显示了按年份划分的论文数量直方图；绝大多数被调查的论文是在过去五年内提出的。右侧面板展示了所调查文章的来源，表明我们的调查来源于与医学图像分析领域相关的资源。
- en: Traditionally, image registration has been accomplished by iteratively solving
    an optimization problem (*e.g.*, demons [[323](#bib.bib323)], LDDMM [[18](#bib.bib18)],
    SyN [[9](#bib.bib9)], DARTEL [[6](#bib.bib6)], and Elastix [[176](#bib.bib176)]).
    These methods are well-established and supported by strong mathematical theory.
    However, they can be computationally expensive and slow in practice, as the optimization
    problem must be solved for each individual pair of moving and fixed images. Several
    review papers have covered traditional medical image registration methods extensively [[220](#bib.bib220),
    [135](#bib.bib135), [288](#bib.bib288), [90](#bib.bib90), [306](#bib.bib306),
    [245](#bib.bib245), [325](#bib.bib325)]. Interested readers can refer to these
    references for more information on these methods. In the last decade, deep learning-based
    methods have shown promise in improving the accuracy and efficiency of image registration.
    Unlike traditional methods, deep learning-based methods train a general network
    by optimizing a global objective function on a training dataset. Then in the testing
    phase, the trained network is directly applied to each image pair with fixed network
    weights, resulting in a significant speedup compared to traditional methods. Initially,
    ResNet-like network architectures [[122](#bib.bib122)], which consist of a convolutional
    encoder and a multilayer perceptron [[344](#bib.bib344), [226](#bib.bib226)],
    were explored. During the training process, ground truth transformations have
    to be provided for direct supervision. In rigid/affine transformations, the ground
    truth is represented as a transformation matrix; while a dense displacement field
    is often used for deformable registration. With the introduction of spatial transformer
    networks [[156](#bib.bib156)] and the success of U-Net [[279](#bib.bib279)] in
    medical imaging applications, learning-based deformable registration methods adopted
    an encoder-decoder design in either supervised [[362](#bib.bib362), [275](#bib.bib275)]
    or unsupervised [[330](#bib.bib330), [188](#bib.bib188), [14](#bib.bib14), [172](#bib.bib172),
    [37](#bib.bib37)] training schemes. These methods typically output a high-resolution
    dense deformation field. On the other hand, learning-based rigid/affine registration
    methods continue to adopt encoder-only networks [[226](#bib.bib226), [147](#bib.bib147),
    [59](#bib.bib59), [46](#bib.bib46), [37](#bib.bib37), [233](#bib.bib233)], with
    the output being the rigid or affine parameters. While there are papers that provide
    general reviews of learning-based registration methods [[95](#bib.bib95), [45](#bib.bib45),
    [348](#bib.bib348), [384](#bib.bib384)], it is important to note that these reviews
    may not be fully up-to-date due to the rapid advancement of the field of deep
    learning. Recent advancements, including learning-based similarity metrics and
    regularizers, novel network architectures, and innovative evaluation metrics and
    uncertainty estimation methods, have demonstrated promising potential for medical
    image registration. This paper provides a timely review of learning-based methods
    in medical image registration, highlighting the latest technologies that have
    been proposed and discussing their respective characteristics and applications.
    In addition, we investigate and formally define registration uncertainty for deep
    learning-based image registration and address the appropriate evaluation metrics
    for these methods that have been overlooked in previous review papers. For simplicity,
    we refer to deep learning-based methods as learning-based methods throughout the
    paper.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，图像配准通过迭代求解优化问题来实现（*例如*，demons [[323](#bib.bib323]，LDDMM [[18](#bib.bib18]，SyN [[9](#bib.bib9]，DARTEL [[6](#bib.bib6]，和Elastix [[176](#bib.bib176]）。这些方法已经得到充分的理论支持，但在实践中计算开销较大且速度较慢，因为优化问题必须对每对移动图像和固定图像进行求解。几篇综述文章详细讨论了传统医学图像配准方法 [[220](#bib.bib220]，[135](#bib.bib135]，[288](#bib.bib288]，[90](#bib.bib90]，[306](#bib.bib306]，[245](#bib.bib245]，[325](#bib.bib325]）。感兴趣的读者可以参考这些文献获取更多信息。在过去十年中，基于深度学习的方法在提高图像配准的准确性和效率方面表现出了良好的前景。与传统方法不同，深度学习方法通过在训练数据集上优化全局目标函数来训练一个通用网络。然后，在测试阶段，训练好的网络以固定的网络权重直接应用于每对图像，从而显著加快了速度。最初，探讨了类似ResNet的网络架构 [[122](#bib.bib122]，这些架构包括卷积编码器和多层感知器 [[344](#bib.bib344]，[226](#bib.bib226]）。在训练过程中，需要提供真实的变换以进行直接监督。在刚性/仿射变换中，真实变换表示为变换矩阵；而在可变形配准中，通常使用稠密位移场。随着空间变换网络 [[156](#bib.bib156]的引入以及U-Net [[279](#bib.bib279]在医学成像应用中的成功，基于学习的可变形配准方法采用了编码器-解码器设计，无论是在监督 [[362](#bib.bib362]，[275](#bib.bib275]还是非监督 [[330](#bib.bib330]，[188](#bib.bib188]，[14](#bib.bib14]，[172](#bib.bib172]，[37](#bib.bib37]训练方案中。这些方法通常输出高分辨率的稠密变形场。另一方面，基于学习的刚性/仿射配准方法继续采用仅编码器的网络 [[226](#bib.bib226]，[147](#bib.bib147]，[59](#bib.bib59]，[46](#bib.bib46]，[37](#bib.bib37]，[233](#bib.bib233]，其输出为刚性或仿射参数。虽然有一些论文提供了基于学习的配准方法的总体综述 [[95](#bib.bib95]，[45](#bib.bib45]，[348](#bib.bib348]，[384](#bib.bib384]，但需要注意的是，由于深度学习领域的快速发展，这些综述可能未完全更新。最近的进展，包括基于学习的相似度度量和正则化器、新型网络架构以及创新的评估指标和不确定性估计方法，展示了医学图像配准的良好潜力。本文及时回顾了医学图像配准中的基于学习的方法，突出了最新提出的技术，并讨论了它们的特性和应用。此外，我们调查并正式定义了基于深度学习的图像配准的不确定性，并针对这些方法提出了适当的评估指标，这些指标在以前的综述文章中被忽视。为简便起见，本文中我们将基于深度学习的方法称为基于学习的方法。
- en: 'In this paper, we surveyed over 250 articles on learning-based medical image
    registration. As depicted in Fig. [1](#S1.F1 "Fig. 1 ‣ 1 Introduction ‣ A survey
    on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond"), the focus is primarily on recent advancements
    proposed in the last five years. Our search covers well-established medical imaging
    journals, such as Medical Image Analysis, IEEE Transactions on Medical Imaging,
    Medical Physics, and NeuroImage, as well as conference proceedings related to
    medical imaging and image registration, such as MICCAI, IPMI, WBIR, CVPR, ECCV,
    ICCV, and NeurIPS. The remainder of the paper is organized as follows: Section [2](#S2
    "2 Fundamentals of Learning-based Image Registration ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond") offers a brief overview of the fundamentals of learning-based image
    registration. Section [3](#S3 "3 Loss Functions ‣ A survey on deep learning in
    medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond") explores widely-used loss functions for learning-based registration
    methods which resemble objective functions in traditional methods, and discusses
    other novel loss functions enabled by deep learning. Section [4](#S4 "4 Network
    Architectures ‣ A survey on deep learning in medical image registration: new technologies,
    uncertainty, evaluation metrics, and beyond") investigates network architectures
    developed for medical image registration, with a focus on recent developments.
    Section [5](#S5 "5 Uncertainty in Learning-based Registration ‣ A survey on deep
    learning in medical image registration: new technologies, uncertainty, evaluation
    metrics, and beyond") delves into methods for estimating registration uncertainty
    in learning-based registration. Section [6](#S6 "6 Registration Evaluation Metrics
    ‣ A survey on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond") considers appropriate evaluation metrics for
    learning-based methods and examines methods for quantifying the regularity of
    generated deformation fields. Section [7](#S7 "7 Applications of Medical Image
    Registration ‣ A survey on deep learning in medical image registration: new technologies,
    uncertainty, evaluation metrics, and beyond") summarizes recent applications of
    learning-based registration in medical imaging. Finally, Section [8](#S8 "8 Challenges
    and Future Perspectives ‣ A survey on deep learning in medical image registration:
    new technologies, uncertainty, evaluation metrics, and beyond") discusses current
    challenges and provides future perspectives for deep learning in medical image
    registration.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们调查了超过250篇关于基于学习的医学图像配准的文章。如图[1](#S1.F1 "图 1 ‣ 1 引言 ‣ 关于医学图像配准中的深度学习：新技术、不确定性、评价指标及其他")所示，重点主要集中在过去五年内提出的最新进展。我们的搜索覆盖了知名的医学影像期刊，如《医学图像分析》、《IEEE医学影像学报》、《医学物理》和《神经影像》，以及与医学影像和图像配准相关的会议论文集，如MICCAI、IPMI、WBIR、CVPR、ECCV、ICCV和NeurIPS。本文其余部分的组织如下：第[2](#S2
    "2 基于学习的图像配准基础 ‣ 关于医学图像配准中的深度学习：新技术、不确定性、评价指标及其他")节简要概述了基于学习的图像配准的基础知识。第[3](#S3
    "3 损失函数 ‣ 关于医学图像配准中的深度学习：新技术、不确定性、评价指标及其他")节探讨了广泛使用的基于学习的配准方法的损失函数，这些函数类似于传统方法中的目标函数，并讨论了深度学习所启用的其他新颖损失函数。第[4](#S4
    "4 网络架构 ‣ 关于医学图像配准中的深度学习：新技术、不确定性、评价指标及其他")节调查了为医学图像配准开发的网络架构，重点关注近期的发展。第[5](#S5
    "5 基于学习的配准中的不确定性 ‣ 关于医学图像配准中的深度学习：新技术、不确定性、评价指标及其他")节深入探讨了在基于学习的配准中估计配准不确定性的方法。第[6](#S6
    "6 配准评价指标 ‣ 关于医学图像配准中的深度学习：新技术、不确定性、评价指标及其他")节考虑了基于学习的方法的适当评价指标，并研究了量化生成变形场规律性的方法。第[7](#S7
    "7 医学图像配准的应用 ‣ 关于医学图像配准中的深度学习：新技术、不确定性、评价指标及其他")节总结了基于学习的配准在医学影像中的近期应用。最后，第[8](#S8
    "8 挑战与未来展望 ‣ 关于医学图像配准中的深度学习：新技术、不确定性、评价指标及其他")节讨论了当前的挑战，并提供了深度学习在医学图像配准中的未来展望。
- en: 2 Fundamentals of Learning-based Image Registration
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 基于学习的图像配准基础
- en: 'Image registration aims to estimate the optimal coordinate transformation that
    minimizes an energy function of the form:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图像配准旨在估计最优坐标变换，以最小化如下形式的能量函数：
- en: '|  | $\hat{\phi}=\operatorname*{\argmin}_{\phi}E(I_{f},I_{m}\circ\phi)+\lambda
    R(\phi),$ |  | (1) |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\phi}=\operatorname*{\argmin}_{\phi}E(I_{f},I_{m}\circ\phi)+\lambda
    R(\phi),$ |  | (1) |'
- en: where $I_{f}$ and $I_{m}$ denote the fixed and moving image, respectively, $\phi$
    represents the deformation field that maps $I_{m}$ to $I_{f}$, and $R$ is a functional
    of $\phi$. The first term in the energy function measures the image similarity
    between the fixed image and the transformed moving image. The second term enforces
    regularization on the deformation field, with $\lambda$ being a hyperparameter
    that determines the trade-off between image similarity and deformation field regularity.
    The purpose of the image similarity measure is to quantify the discrepancy between
    the fixed image and the transformed moving image. The regularization term is typically
    used in DIR, as it allows for the integration of prior knowledge about the desired
    characteristics of the deformation field, such as spatial smoothness. Moreover,
    regularization prevents the deformation field from exhibiting physically implausible
    behaviors, such as “folding” or rearranging of voxels [[276](#bib.bib276)]. This
    is particularly important for medical images because such unrealistic behavior
    does not accurately reflect the way that organs deform in reality and may lead
    to a misinterpretation of the registration results. Regularization is often not
    required for rigid/affine registration because the deformation field is guaranteed
    to be spatially uniform.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $I_{f}$ 和 $I_{m}$ 分别表示固定图像和移动图像，$\phi$ 表示将 $I_{m}$ 映射到 $I_{f}$ 的变形场，$R$ 是
    $\phi$ 的一个函数。能量函数中的第一项测量了固定图像与变换后的移动图像之间的图像相似度。第二项对变形场施加正则化，$\lambda$ 是一个超参数，用于确定图像相似度与变形场正则化之间的权衡。图像相似度测量的目的是量化固定图像与变换后的移动图像之间的差异。正则化项通常用于
    DIR，因为它允许结合关于变形场所需特性的先验知识，如空间平滑性。此外，正则化可以防止变形场出现物理上不合理的行为，例如“折叠”或体素的重新排列[[276](#bib.bib276)]。这对医学图像尤为重要，因为这种不现实的行为不能准确反映器官在现实中的变形方式，可能导致配准结果的误解。刚性/仿射配准通常不需要正则化，因为变形场保证是空间均匀的。
- en: '![Refer to caption](img/8ca9c65f73dfd24489682cf2d11dc142.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8ca9c65f73dfd24489682cf2d11dc142.png)'
- en: 'Fig. 2: Overview of learning-based image registration. The top panel depicts
    the common pipeline for supervised learning in medical image registration, which
    necessitates ground truth transformations. The bottom panel demonstrates the unsupervised
    learning pipeline, wherein the network learns to perform registration using only
    input images. The left panel presents the learning-based DIR pipeline, typically
    employing an encoder-decoder-style network architecture. The right panel exhibits
    the learning-based rigid/affine registration, which usually involves only an encoder.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：基于学习的图像配准概述。上方面板展示了医学图像配准中有监督学习的常见流程，这需要真实的变换数据。下方面板展示了无监督学习流程，其中网络仅使用输入图像来执行配准。左侧面板展示了基于学习的
    DIR 流程，通常采用编码器-解码器风格的网络架构。右侧面板展示了基于学习的刚性/仿射配准，通常仅涉及编码器。
- en: 2.1 Supervised vs. Unsupervised Learning
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 有监督学习与无监督学习
- en: Learning-based registration methods can be broadly categorized as supervised
    and unsupervised. In the machine learning paradigm, supervised learning typically
    refers to the use of extrinsic information during learning (such as labels) whereas
    unsupervised methods are concerned with discovering properties intrinsic to the
    data. Both supervised and unsupervised learning-based registration methods require
    a training stage that uses pairs of inputs and their corresponding target outputs.
    Supervised registration methods use ground truth transformations as target output
    during the training process. Unsupervised methods refer to those that do not require
    ground truth transformations. Yet, methods that employ landmark correspondences
    or anatomical label maps during their training phase are still categorized under
    supervised learning. This is because landmark correspondences are a sparse representation
    of the ground truth transformations, and matching label maps act as a surrogate
    for evaluating registration performance. When this extrinsic information is used
    alongside the image data to aim learning, these methods are referred to as semi-supervised.
    In certain contexts, the term "unsupervised" might be misleading. A more precise
    term could be “self-supervised” to underscore the training aspect of deep learning.
    However, for the purposes of clarity and consistency in this discussion, we will
    use conventional terminology and refer to methods that do not require supervision
    from extrinsic information as unsupervised.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 基于学习的配准方法可以大致分为有监督和无监督。在机器学习范式中，有监督学习通常指在学习过程中使用外部信息（如标签），而无监督方法则关注发现数据本身的固有属性。有监督和无监督的学习-based
    配准方法都需要一个训练阶段，使用输入对及其对应的目标输出。有监督配准方法在训练过程中使用真实变换作为目标输出。无监督方法则是指那些不需要真实变换的方法。然而，使用标记对应或解剖标签图进行训练的那些方法仍被归类为有监督学习。这是因为标记对应是对真实变换的稀疏表示，而匹配标签图则作为评估配准性能的替代品。当这种外部信息与图像数据一起用于学习时，这些方法被称为半监督。在某些背景下，“无监督”这一术语可能会产生误导。一个更精确的术语可能是“自监督”，以强调深度学习的训练方面。然而，为了讨论的清晰性和一致性，我们将使用传统术语，并将不需要外部信息监督的方法称为无监督。
- en: During the early stages of development, the majority of learning-based registration
    methods were supervised. The ground truth transformations required for the training
    process are typically generated using traditional registration methods, such as
    [[362](#bib.bib362), [275](#bib.bib275), [31](#bib.bib31), [148](#bib.bib148),
    [85](#bib.bib85)]. However, generating ground-truth transformations this way is
    a time-consuming process, which is a notable drawback of such methods. In addition,
    since these networks are trained to mimic the function of traditional methods,
    their registration performance may not surpass that of the methods they are based
    on. In some cases, post-processing of the deformation fields may be required to
    further improve registration accuracy [[362](#bib.bib362)]. Alternatively, artificial
    deformations can also be used as ground truth transformations in certain cases [[226](#bib.bib226),
    [178](#bib.bib178), [303](#bib.bib303), [82](#bib.bib82), [79](#bib.bib79)].
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发的早期阶段，大多数基于学习的配准方法都是有监督的。训练过程中所需的真实变换通常是使用传统配准方法生成的，例如[[362](#bib.bib362),
    [275](#bib.bib275), [31](#bib.bib31), [148](#bib.bib148), [85](#bib.bib85)]。然而，以这种方式生成真实变换是一个耗时的过程，这是这些方法的一个显著缺点。此外，由于这些网络被训练来模仿传统方法的功能，它们的配准性能可能不超过其所基于的方法。在某些情况下，可能需要对变形场进行后处理以进一步提高配准准确性[[362](#bib.bib362)]。另外，在某些情况下，人工变形也可以用作真实变换[[226](#bib.bib226),
    [178](#bib.bib178), [303](#bib.bib303), [82](#bib.bib82), [79](#bib.bib79)]。
- en: More recently, the introduction of spatial transformer networks [[156](#bib.bib156)]
    has led to a shift towards developing unsupervised methods that do not rely on
    ground-truth transformation [[330](#bib.bib330), [188](#bib.bib188), [59](#bib.bib59),
    [14](#bib.bib14), [56](#bib.bib56), [229](#bib.bib229), [230](#bib.bib230), [232](#bib.bib232),
    [172](#bib.bib172), [37](#bib.bib37), [38](#bib.bib38)]. These methods use the
    difference between the deformed moving image and the fixed image to update the
    network, enabling end-to-end training. By removing the reliance on ground truth
    transformation, these methods offer greater flexibility in modeling different
    properties of the deformation fields (*e.g.*, smoothness, invertibility).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，空间变换网络 [[156](#bib.bib156)] 的引入促使了向无监督方法的开发转变，这些方法不依赖于真实的变换 [[330](#bib.bib330)，[188](#bib.bib188)，[59](#bib.bib59)，[14](#bib.bib14)，[56](#bib.bib56)，[229](#bib.bib229)，[230](#bib.bib230)，[232](#bib.bib232)，[172](#bib.bib172)，[37](#bib.bib37)，[38](#bib.bib38)]。这些方法利用变形的移动图像与固定图像之间的差异来更新网络，实现端到端的训练。通过去除对真实变换的依赖，这些方法在建模不同的变形场特性上提供了更大的灵活性（*例如*，平滑性、可逆性）。
- en: 2.2 Paradigm for Learning-based Registration
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 基于学习的配准范式
- en: 'Recent progress in the field of learning-based medical image registration has
    been focusing on exploring different ways to improve registration accuracy, such
    as through modifications to network architectures, loss functions, and training
    methods, which will be discussed in detail in subsequent sections. Despite these
    efforts, the fundamental principles of learning-based registration have remained
    unchanged. Figure [2](#S2.F2 "Fig. 2 ‣ 2 Fundamentals of Learning-based Image
    Registration ‣ A survey on deep learning in medical image registration: new technologies,
    uncertainty, evaluation metrics, and beyond") illustrates the conventional paradigms
    of learning-based rigid/affine and DIR. Typically, these paradigms consist of
    the following components:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，在基于学习的医学图像配准领域的进展集中于探索提高配准准确性的方法，例如通过对网络架构、损失函数和训练方法的修改，这些将在后续章节中详细讨论。尽管有这些努力，基于学习的配准的基本原理仍未改变。图 [2](#S2.F2
    "图 2 ‣ 2 基于学习的图像配准基础 ‣ 关于医学图像配准的深度学习：新技术、不确定性、评估指标及其他") 展示了基于学习的刚性/仿射和DIR的传统范式。通常，这些范式包括以下组件：
- en: '1.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Moving and fixed images as input
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 移动图像和固定图像作为输入
- en: '2.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: A deep neural network
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度神经网络
- en: '3.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: The spatial transformer (for unsupervised methods)
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 空间变换器（对于无监督方法）
- en: '4.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: A loss function
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 损失函数
- en: The way in which moving and fixed images are inputted into deep neural networks (DNNs)
    varies depending on the architecture of the network. They can either be concatenated
    and sent in as a single input (*e.g.*, VoxelMorph [[14](#bib.bib14)]) or each
    image can be processed separately by the DNN, with the feature maps being combined
    in a deeper stage (*e.g.*, Quicksilver [[362](#bib.bib362)]).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 移动图像和固定图像输入到深度神经网络（DNNs）的方式根据网络架构有所不同。它们可以被连接在一起作为单一输入（*例如*，VoxelMorph [[14](#bib.bib14)]），或者每个图像可以由DNN单独处理，特征图在更深的阶段进行结合（*例如*，Quicksilver [[362](#bib.bib362)]）。
- en: The architecture of DNNs can vary depending on the specific task they are designed
    to perform and the learning method they will undergo. For affine/rigid registration
    methods, DNN encoders are used for feature extraction and fully connected layers
    are used to output the parameters of the predicted transformation. DIR methods
    use DNNs with both an encoder and decoder, and the result is a deformation field
    of equal sizes to the input images. In the supervised setting, the network output
    is compared to ground truth transformations (generated from synthetic transformations
    or traditional image registration methods) or landmark correspondences using a
    loss function. In the unsupervised setting, the predicted transformation is used
    by the spatial transformer [[156](#bib.bib156)] to warp the moving image, and
    the transformed image is then evaluated against the fixed image using a loss function
    that incorporates an image similarity measure. When anatomical label maps for
    the fixed and moving images are available, the warped moving label map can also
    be produced by using the predicted transformation and the spatial transformer.
    An anatomy loss can be computed using the warped moving label map and the fixed
    label maps to provide extra guidance during network training.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: DNN的架构可以根据其设计执行的特定任务和将采用的学习方法而有所不同。对于仿射/刚性配准方法，DNN编码器用于特征提取，全连接层用于输出预测变换的参数。DIR方法使用具有编码器和解码器的DNN，结果是与输入图像大小相等的变形场。在监督设置中，网络输出与真实变换（由合成变换或传统图像配准方法生成）或地标对应关系使用损失函数进行比较。在无监督设置中，空间变换器[[156](#bib.bib156)]使用预测的变换来扭曲移动图像，然后使用包含图像相似性度量的损失函数将变换后的图像与固定图像进行评估。当固定图像和移动图像的解剖标签图可用时，还可以使用预测的变换和空间变换器生成扭曲的移动标签图。可以使用扭曲的移动标签图和固定标签图计算**解剖损失**，以在网络训练期间提供额外的指导。
- en: 'There is a diverse range of loss functions to choose from, depending on the
    learning mode. These are thoroughly discussed in Section [3](#S3 "3 Loss Functions
    ‣ A survey on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond"). The networks are trained by globally optimizing
    the loss function during the training stage using a training dataset. The trained
    networks are then applied to unseen testing images for inference.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '根据学习模式的不同，有各种各样的损失函数可供选择。这些在[3](#S3 "3 Loss Functions ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond")节中进行了详细讨论。网络通过在训练阶段使用训练数据集全局优化损失函数进行训练。训练后的网络随后应用于未见过的测试图像进行推断。'
- en: Due to the self-supervised nature of image registration, the difference between
    the transformed moving image and the fixed image can be further reduced at test
    time. This is commonly known as instance-specific optimization [[14](#bib.bib14),
    [294](#bib.bib294), [234](#bib.bib234), [127](#bib.bib127), [39](#bib.bib39)].
    Specifically, the network weights can be optimized during test time to reduce
    the dissimilarity of each fixed and moving image pair in the test dataset and
    further boost the performance. Registration networks can also be specifically
    designed to produce diffeomorphic transformations, which are highly desirable
    in DIR methods and will be discussed further in the next subsection.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图像配准的自监督性质，在测试时可以进一步减少变换后的移动图像与固定图像之间的差异。这通常被称为实例特定优化[[14](#bib.bib14), [294](#bib.bib294),
    [234](#bib.bib234), [127](#bib.bib127), [39](#bib.bib39)]。具体来说，可以在测试时优化网络权重，以减少测试数据集中每对固定图像和移动图像的差异，从而进一步提升性能。配准网络还可以特别设计为产生**光滑的变换**，这在DIR方法中非常受欢迎，下一小节将对此进行进一步讨论。
- en: 2.3 Diffeomorphic Image Registration
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 **光滑的图像配准**
- en: 'Many learning-based DIR methods follow a small deformation model [[14](#bib.bib14),
    [172](#bib.bib172), [59](#bib.bib59), [303](#bib.bib303), [232](#bib.bib232),
    [124](#bib.bib124), [148](#bib.bib148)]. In this model, $\phi$ in Eqn. [1](#S2.E1
    "In 2 Fundamentals of Learning-based Image Registration ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond") is represented by a displacement field, $v$, expressed as $\phi=id+v$,
    where the displacement is added to the identity transform, $id$. Since $\phi$
    may not be a one-to-one mapping, this model does not guarantee the invertibility
    of the deformation. In some cases, the "inverse" transformation is roughly approximated
    by subtracting the displacement [[6](#bib.bib6)]. In many applications (*e.g.*,
    Avants et al. [[9](#bib.bib9)], Oishi et al. [[244](#bib.bib244)], Christensen
    et al. [[50](#bib.bib50)]), diffeomorphic image registration is highly desirable
    because it provides transformation invertibility and topological preservation.
    Diffeomorphic transformations are defined as smooth and continuous one-to-one
    mappings with a smooth and continuous inverse (*i.e.*, positive Jacobian determinants).
    They are achieved mainly through two approaches: the time-dependent velocity field [[18](#bib.bib18),
    [9](#bib.bib9)] or the time-stationary velocity field [[5](#bib.bib5), [6](#bib.bib6),
    [323](#bib.bib323), [134](#bib.bib134)] approach.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '许多基于学习的DIR方法遵循小变形模型[[14](#bib.bib14), [172](#bib.bib172), [59](#bib.bib59),
    [303](#bib.bib303), [232](#bib.bib232), [124](#bib.bib124), [148](#bib.bib148)]。在该模型中，方程[1](#S2.E1
    "In 2 Fundamentals of Learning-based Image Registration ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond")中的$\phi$由位移场$v$表示，表达式为$\phi=id+v$，其中位移添加到单位变换$id$中。由于$\phi$可能不是一一映射，这种模型不能保证变形的可逆性。在某些情况下，“逆”变换通过减去位移粗略近似[[6](#bib.bib6)]。在许多应用中（*例如*，Avants
    et al. [[9](#bib.bib9)], Oishi et al. [[244](#bib.bib244)], Christensen et al.
    [[50](#bib.bib50)]），可微分图像配准是非常理想的，因为它提供了变换的可逆性和拓扑保留。可微分变换被定义为具有光滑且连续的逆（*即*，正雅可比行列式）的光滑且连续的一一映射。它们主要通过两种方法实现：时间依赖速度场[[18](#bib.bib18),
    [9](#bib.bib9)]或时间驻留速度场[[5](#bib.bib5), [6](#bib.bib6), [323](#bib.bib323), [134](#bib.bib134)]方法。'
- en: 'The time-dependent velocity field approach involves integrating sufficiently
    smooth velocity fields that change over time. The diffeomorphism is established
    by using a velocity field $v^{(t)}$ at time $t$, and evolving it through [[18](#bib.bib18)]:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 时间依赖速度场方法涉及积分随时间变化的足够平滑的速度场。通过在时间$t$使用速度场$v^{(t)}$并通过[[18](#bib.bib18)]演变来建立可微分变换：
- en: '|  | $\frac{d\phi^{(t)}}{dt}=v^{(t)}(\phi^{(t)}).$ |  | (2) |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{d\phi^{(t)}}{dt}=v^{(t)}(\phi^{(t)}).$ |  | (2) |'
- en: 'The diffeomorphic transformation is achieved by starting with an identity transformation,
    *i.e.* $\phi^{(0)}=id$, and integrating over the unit time period:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从单位变换开始，即*即* $\phi^{(0)}=id$，并在单位时间周期内进行积分来实现可微分变换：
- en: '|  | $\phi^{(1)}=\phi^{(0)}+\int^{1}_{0}v^{(t)}(\phi^{(t)})dt.$ |  | (3) |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|  | $\phi^{(1)}=\phi^{(0)}+\int^{1}_{0}v^{(t)}(\phi^{(t)})dt.$ |  | (3) |'
- en: However, the complexity of the differential equations involved in the time-varying
    setting has led to limited use of this approach in current learning-based registration
    models. Only a handful of studies, such as [[268](#bib.bib268), [253](#bib.bib253),
    [290](#bib.bib290), [362](#bib.bib362), [361](#bib.bib361), [117](#bib.bib117),
    [334](#bib.bib334)], have integrated it into a DNN framework. These studies primarily
    involve using a DNN to predict an initial momentum field and then updating it
    through geodesic shooting [[228](#bib.bib228), [371](#bib.bib371)] to derive the
    velocity fields. As a result, end-to-end training is not feasible without re-implementing
    the geodesic shooting framework with modern DNN libraries. To date, only one previous
    work has achieved this for medical image registration [[290](#bib.bib290)].
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，涉及时间变化设置的微分方程的复杂性导致当前基于学习的配准模型中这种方法的使用有限。只有少数几项研究，如[[268](#bib.bib268), [253](#bib.bib253),
    [290](#bib.bib290), [362](#bib.bib362), [361](#bib.bib361), [117](#bib.bib117),
    [334](#bib.bib334)]，将其集成到DNN框架中。这些研究主要涉及使用DNN预测初始动量场，然后通过测地射击[[228](#bib.bib228),
    [371](#bib.bib371)]更新动量场以推导速度场。因此，除非重新实现现代DNN库中的测地射击框架，否则无法进行端到端训练。迄今为止，只有一项先前的工作实现了这一点用于医学图像配准[[290](#bib.bib290)]。
- en: 'The time-stationary velocity field approach considers velocity fields that
    remain constant throughout time. By using this setting, the evolution of the diffeomorphism
    in Eqn. [2](#S2.E2 "In 2.3 Diffeomorphic Image Registration ‣ 2 Fundamentals of
    Learning-based Image Registration ‣ A survey on deep learning in medical image
    registration: new technologies, uncertainty, evaluation metrics, and beyond")
    can be rewritten as:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 时间平稳速度场方法考虑了速度场在整个时间内保持不变的情况。利用这种设置，可以将公式 [2](#S2.E2 "在 2.3 可变形图像配准 ‣ 2 基于学习的图像配准基础
    ‣ 关于医学图像配准的深度学习调查：新技术、不确定性、评估指标及其他") 的变形演变重写为：
- en: '|  | $\frac{d\phi^{(t)}}{dt}=v(\phi^{(t)}),$ |  | (4) |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{d\phi^{(t)}}{dt}=v(\phi^{(t)}),$ |  | (4) |'
- en: 'where the velocity field, $v$, is now independent of time. Dalca et al. [[56](#bib.bib56)] were
    the first to use this setting in a DNN model through the scaling-and-squaring
    method [[5](#bib.bib5), [6](#bib.bib6)]. This method has since become dominant
    in learning-based diffeomorphic registration models [[229](#bib.bib229), [37](#bib.bib37),
    [230](#bib.bib230), [115](#bib.bib115), [374](#bib.bib374), [266](#bib.bib266),
    [375](#bib.bib375), [177](#bib.bib177)]. The scaling-and-squaring method considers
    the velocity field as a member of the Lie algebra and the deformation field as
    a member of the Lie group. The velocity field lies in the tangent space of the
    identity element in the Lie group and its connection to the deformation field
    is described by an exponential map:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 其中速度场$v$现在与时间无关。Dalca 等人 [[56](#bib.bib56)] 是首批在 DNN 模型中使用这种设置的，他们采用了缩放与平方的方法
    [[5](#bib.bib5), [6](#bib.bib6)]。这一方法随后在基于学习的可变形配准模型中成为主流 [[229](#bib.bib229),
    [37](#bib.bib37), [230](#bib.bib230), [115](#bib.bib115), [374](#bib.bib374),
    [266](#bib.bib266), [375](#bib.bib375), [177](#bib.bib177)]。缩放与平方的方法将速度场视为李代数的成员，将变形场视为李群的成员。速度场位于李群单位元素的切空间中，并且其与变形场的关系由指数映射描述：
- en: '|  | $\phi=\exp{(v)},$ |  | (5) |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|  | $\phi=\exp{(v)},$ |  | (5) |'
- en: which is equivalent to integrating along the velocity field over the unit time
    period. An alternative perspective is that the Jacobian determinant of a deformation
    resulting from exponentiating the velocity field is always positive, similar to
    how the derivative of the exponential of a real number is always positive [[6](#bib.bib6)].
    For further information on the implementation of this method, we direct interested
    readers to the references cited [[6](#bib.bib6), [5](#bib.bib5), [56](#bib.bib56)].
    It is important to note that the scaling-and-squaring method cannot guarantee
    a folding-free transformation in the digital domain when measured by the finite
    difference approximated Jacobian determinant. This is because the scaling-and-squaring
    method involves bilinear or trilinear interpolation that is inconsistent with
    the piecewise linear transformation assumed by the finite difference based Jacobian
    determinant computation [[198](#bib.bib198)].
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这等同于在单位时间内沿速度场进行积分。另一种观点是，结果中由于速度场指数化而产生的变形的雅可比行列式总是正的，类似于实数的指数导数总是正的 [[6](#bib.bib6)]。有关这种方法实现的更多信息，请参考所引用的文献
    [[6](#bib.bib6), [5](#bib.bib5), [56](#bib.bib56)]。需要注意的是，缩放与平方的方法无法保证在数字领域进行有限差分近似的雅可比行列式测量时的无折叠变换。这是因为缩放与平方的方法涉及的双线性或三线性插值与有限差分基于雅可比行列式计算所假设的分段线性变换不一致
    [[198](#bib.bib198)]。
- en: 3 Loss Functions
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 损失函数
- en: 'Table 1: A compilation of unsupervised deformable image registration models
    (models are listed in alphabetical order). The table summarizes the models’ choices
    of similarity and auxiliary loss functions, regularization techniques, accuracy
    measures, and regularity measures.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 无监督可变形图像配准模型的汇总（模型按字母顺序列出）。表格总结了模型对相似性和辅助损失函数、正则化技术、准确性度量和正则性度量的选择。'
- en: '|       | Similarity Loss     | Aux. Loss     | Regularizer     | Accuracy
    Measure     | Regularity Measure |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|       | 相似性损失     | 辅助损失     | 正则化项     | 准确性度量     | 正则性度量 |'
- en: '|     |  MSE  |  NCC  |  Correlation  |  NGF  |  MI  |  MIND-SSC     |  Anatomy  |  Landmark
        |  Diffusion  |  Curvature  |  Bending  |  Jacobian  |  Consistency     |  TRE  |  MSE  |  SSIM  |  Dice  |  HdD
        |  $\%\text{of}&#124;J_{\phi}\leq 0$  |  $\#\text{of}&#124;J_{\phi}&#124;\leq
    0$  |  std.$(&#124;J_{\phi}&#124;)$  |  $&#124;\nabla J_{\phi}&#124;$  |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '|     | MSE  | NCC  | 相关性  | NGF  | MI  | MIND-SSC     | 解剖学  | 标志性点     |
    扩散  | 曲率  | 弯曲  | 雅可比  | 一致性     | TRE  | MSE  | SSIM  | Dice  | HdD     | $\%\text{of}&#124;J_{\phi}\leq
    0$  | $\#\text{of}&#124;J_{\phi}&#124;\leq 0$  | std.$(&#124;J_{\phi}&#124;)$  |  $&#124;\nabla
    J_{\phi}&#124;$  |'
- en: '|   ADMIR [[312](#bib.bib312)] |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |  |  |  |  |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|   ADMIR [[312](#bib.bib312)] |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |  |  |  |  |'
- en: '| Attention-Reg [[305](#bib.bib305)]     |  |  |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| Attention-Reg [[305](#bib.bib305)]     |  |  |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
- en: '| BIRNet [[85](#bib.bib85)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     |  |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| BIRNet [[85](#bib.bib85)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     |  |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
- en: '| CondLapIRN [[232](#bib.bib232)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| CondLapIRN [[232](#bib.bib232)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
- en: '| CycleMorph [[172](#bib.bib172)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |    
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| CycleMorph [[172](#bib.bib172)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |    
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
- en: '| de Vos *et al.* [[329](#bib.bib329)]     |  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |
        |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
        | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| de Vos *et al.* [[329](#bib.bib329)]     |  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |
        |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
        | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
- en: '| Deformer [[42](#bib.bib42)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| Deformer [[42](#bib.bib42)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
- en: '| DiffuseMorph [[171](#bib.bib171)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| DiffuseMorph [[171](#bib.bib171)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
- en: '| DIRNet [[60](#bib.bib60)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     |  |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| DIRNet [[60](#bib.bib60)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     |  |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
- en: '| DLIR [[59](#bib.bib59)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
        | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| DLIR [[59](#bib.bib59)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
        | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
- en: '| DNVF [[115](#bib.bib115)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| DNVF [[115](#bib.bib115)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
- en: '| DTN [[374](#bib.bib374)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| DTN [[374](#bib.bib374)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |'
- en: '| Dual-PRNet [[146](#bib.bib146)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| Dual-PRNet [[146](#bib.bib146)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
- en: '| Dual-PRNet++ [[167](#bib.bib167)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| Dual-PRNet++ [[167](#bib.bib167)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
- en: '| FAIM [[180](#bib.bib180)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| FAIM [[180](#bib.bib180)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
- en: '| Fan *et al.* [[83](#bib.bib83)]     |  |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
        |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| Fan *et al.* [[83](#bib.bib83)]     |  |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
        |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
- en: '| Fourier-Net [[159](#bib.bib159)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |    
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| Fourier-Net [[159](#bib.bib159)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |    
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
- en: '| GraformerDIR [[360](#bib.bib360)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| GraformerDIR [[360](#bib.bib360)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
- en: '| Han *et al.* [[116](#bib.bib116)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| Han *et al.* [[116](#bib.bib116)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
- en: '| Hering *et al.* [[132](#bib.bib132)]     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
        | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| Hering *et al.* [[132](#bib.bib132)]     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
        | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
- en: '| HyperMorph [[142](#bib.bib142)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| HyperMorph [[142](#bib.bib142)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
- en: '| im2grid [[199](#bib.bib199)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| im2grid [[199](#bib.bib199)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |'
- en: '| Krebs *et al.* [[177](#bib.bib177)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| Krebs *et al.* [[177](#bib.bib177)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |'
- en: '| LapIRN [[230](#bib.bib230)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| LapIRN [[230](#bib.bib230)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
- en: '| LKU-Net [[160](#bib.bib160)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| LKU-Net [[160](#bib.bib160)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |'
- en: '| Li *et al.* [[188](#bib.bib188)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| Li *et al.* [[188](#bib.bib188)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
- en: '| Liu *et al.* [[195](#bib.bib195)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     |  |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| Liu *et al.* [[195](#bib.bib195)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     |  |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
- en: '| MIDIR [[266](#bib.bib266)]     |  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |
        |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| MIDIR [[266](#bib.bib266)]     |  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |
        |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |'
- en: '| MS-DIRNet [[186](#bib.bib186)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |     |  |  |  |  |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| MS-DIRNet [[186](#bib.bib186)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |     |  |  |  |  |'
- en: '| MS-ODENet [[352](#bib.bib352)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| MS-ODENet [[352](#bib.bib352)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  |  |  |'
- en: '| NODEO [[347](#bib.bib347)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| NODEO [[347](#bib.bib347)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
- en: '| PDD-Net 2.5D [[126](#bib.bib126)]     |  |  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
        | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| PDD-Net 2.5D [[126](#bib.bib126)]     |  |  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
        | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |'
- en: '| PDD-Net 3D [[124](#bib.bib124)]     |  |  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| PDD-Net 3D [[124](#bib.bib124)]     |  |  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |'
- en: '| PC-SwinMorph [[196](#bib.bib196)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$     |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  |  |  |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| PC-SwinMorph [[196](#bib.bib196)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$     |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  |  |  |'
- en: '| SDHNet [[379](#bib.bib379)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| SDHNet [[379](#bib.bib379)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
- en: '| Shao *et al.* [[289](#bib.bib289)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |
        |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| Shao *et al.* [[289](#bib.bib289)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |
        |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
- en: '| SVF-R2Net [[165](#bib.bib165)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| SVF-R2Net [[165](#bib.bib165)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
- en: '| SYMNet [[229](#bib.bib229)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
        |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| SYMNet [[229](#bib.bib229)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
        |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
- en: '| SymTrans [[212](#bib.bib212)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| SymTrans [[212](#bib.bib212)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
- en: '| SynthMorph [[138](#bib.bib138)]     |  |  |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| SynthMorph [[138](#bib.bib138)]     |  |  |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
- en: '| TM-DCA [[40](#bib.bib40)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| TM-DCA [[40](#bib.bib40)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
- en: '| TM-TVF [[36](#bib.bib36)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| TM-TVF [[36](#bib.bib36)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |'
- en: '| TransMorph [[37](#bib.bib37)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| TransMorph [[37](#bib.bib37)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
- en: '| ViT-V-Net [[38](#bib.bib38)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| ViT-V-Net [[38](#bib.bib38)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
- en: '| VoxelMorph [[14](#bib.bib14)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| VoxelMorph [[14](#bib.bib14)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
- en: '| VoxelMorph-diff [[56](#bib.bib56)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |    
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| VoxelMorph-diff [[56](#bib.bib56)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |    
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |     |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |'
- en: '| VoxelMorph++ [[127](#bib.bib127)]     |  |  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |
        |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| VoxelMorph++ [[127](#bib.bib127)]     |  |  |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |
        |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |'
- en: '| VR-Net [[161](#bib.bib161)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| VR-Net [[161](#bib.bib161)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |'
- en: '| VTN [[377](#bib.bib377)]     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| VTN [[377](#bib.bib377)]     |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$  |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |'
- en: '| XMorpher [[291](#bib.bib291)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$     |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| XMorpher [[291](#bib.bib291)]     |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$     |  |  |  |
    $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |'
- en: '| Zhang *et al.* [[372](#bib.bib372)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| Zhang *et al.* [[372](#bib.bib372)]     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  |  |  |     |  |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |     |  |  |  | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$
    |     | $\mathbin{\vbox{\hbox{\scalebox{1.5}{$\bullet$}}}}$ |  |  |  |'
- en: '|       |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '|       |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: 'Table [1](#S3.T1 "Table 1 ‣ 3 Loss Functions ‣ A survey on deep learning in
    medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond") provides a compilation of unsupervised DIR models, summarizing the
    similarity and auxiliary loss functions, as well as other details. See the text
    for complete details and discussion.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [1](#S3.T1 "Table 1 ‣ 3 Loss Functions ‣ A survey on deep learning in medical
    image registration: new technologies, uncertainty, evaluation metrics, and beyond")
    提供了一份无监督 DIR 模型的汇编，概述了相似性和辅助损失函数，以及其他细节。有关详细信息和讨论，请参见文本。'
- en: 3.1 Supervised Learning
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 监督学习
- en: In supervised learning, where the ground truth transformation is used, the loss
    function is typically easy to define, with the mean square error (MSE) [[226](#bib.bib226),
    [178](#bib.bib178), [79](#bib.bib79), [275](#bib.bib275), [31](#bib.bib31), [85](#bib.bib85)],
    the equivalent end-point-error (EPE), and mean absolute error (MAE) [[362](#bib.bib362),
    [303](#bib.bib303)] being the most popular choices.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在有监督学习中，使用真实的转换时，损失函数通常容易定义，均方误差 (MSE) [[226](#bib.bib226), [178](#bib.bib178),
    [79](#bib.bib79), [275](#bib.bib275), [31](#bib.bib31), [85](#bib.bib85)]、等效终点误差
    (EPE) 和平均绝对误差 (MAE) [[362](#bib.bib362), [303](#bib.bib303)] 是最常见的选择。
- en: 3.2 Unsupervised & Semi-supervised Learning
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 无监督与半监督学习
- en: 'In unsupervised learning, where there is no ground truth transformation to
    reference, regularization is usually used to enforce smoothness in the transformation.
    As a result, the loss function is often similar to the energy function used in
    traditional methods (*i.e.*, Eqn. [1](#S2.E1 "In 2 Fundamentals of Learning-based
    Image Registration ‣ A survey on deep learning in medical image registration:
    new technologies, uncertainty, evaluation metrics, and beyond")), which includes
    an image similarity measure and a transformation regularizer. The following subsections
    provide a summary of commonly used and recently proposed loss functions for image
    registration.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '在无监督学习中，由于没有真实的转换参考，通常使用正则化来强制转换的平滑性。因此，损失函数通常类似于传统方法中使用的能量函数（*即*，方程 [1](#S2.E1
    "In 2 Fundamentals of Learning-based Image Registration ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond")），其中包括图像相似度度量和转换正则化项。以下小节总结了用于图像配准的常用和最近提出的损失函数。'
- en: 3.3 Similarity Measure
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 相似度度量
- en: Mono-modality. The choice of image similarity measure can vary depending on
    each specific application. For mono-modal registration, MSE is still a popular
    choice and has the advantage of having a straightforward probabilistic interpretation
    of the Gaussian likelihood approximation [[56](#bib.bib56), [37](#bib.bib37),
    [172](#bib.bib172), [14](#bib.bib14), [223](#bib.bib223), [161](#bib.bib161),
    [199](#bib.bib199)]. However, a disadvantage of MSE is that it averages the difference
    across all voxels in the image, making it sensitive to local intensity variations
    within the image. Normalized cross-correlation (NCC) is known to be more robust
    to local intensity variations and has been found to be superior in brain MR registration
    applications [[9](#bib.bib9)]. NCC has been extended as a loss function for training
    learning-based models, with the local window computation often being done through
    convolution operations [[180](#bib.bib180), [37](#bib.bib37), [172](#bib.bib172),
    [14](#bib.bib14), [370](#bib.bib370), [229](#bib.bib229), [230](#bib.bib230),
    [232](#bib.bib232)]. One disadvantage of NCC is its higher computing cost in comparison
    to MSE, which is mainly attributable to the comparatively large convolution kernel
    size (typically chosen between $5\times 5\times 5$ and $9\times 9\times 9$ voxels [[9](#bib.bib9),
    [14](#bib.bib14), [229](#bib.bib229)]). The structural similarity index (SSIM) [[336](#bib.bib336)]
    has also been demonstrated to be an effective loss function for mono-modal image
    registration [[39](#bib.bib39), [216](#bib.bib216), [282](#bib.bib282)]. SSIM
    takes into account luminance, contrast, and structure. It can be thought of as
    an extension of the NCC, with the structure term in SSIM being the square root
    of NCC. This allows SSIM to capture more information about the similarity of two
    images beyond just the degree of correlation between them.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 单模态。图像相似性度量的选择可以根据具体应用而有所不同。对于单模态配准，均方误差（MSE）仍然是一个受欢迎的选择，并且具有简单的高斯似然近似的概率解释 [[56](#bib.bib56),
    [37](#bib.bib37), [172](#bib.bib172), [14](#bib.bib14), [223](#bib.bib223), [161](#bib.bib161),
    [199](#bib.bib199)]。然而，MSE 的一个缺点是它对图像中所有体素的差异进行平均，这使得它对图像中的局部强度变化敏感。归一化互相关（NCC）被认为对局部强度变化更为鲁棒，并且在脑部
    MR 配准应用中表现优越 [[9](#bib.bib9)]。NCC 已被扩展为训练学习模型的损失函数，其中局部窗口的计算通常通过卷积操作完成 [[180](#bib.bib180),
    [37](#bib.bib37), [172](#bib.bib172), [14](#bib.bib14), [370](#bib.bib370), [229](#bib.bib229),
    [230](#bib.bib230), [232](#bib.bib232)]。NCC 的一个缺点是与 MSE 相比计算成本较高，这主要归因于相对较大的卷积核尺寸（通常选择在
    $5\times 5\times 5$ 和 $9\times 9\times 9$ 体素之间 [[9](#bib.bib9), [14](#bib.bib14),
    [229](#bib.bib229)]）。结构相似性指数（SSIM） [[336](#bib.bib336)] 也被证明是单模态图像配准的有效损失函数 [[39](#bib.bib39),
    [216](#bib.bib216), [282](#bib.bib282)]。SSIM 考虑了亮度、对比度和结构。它可以被视为 NCC 的扩展，其中 SSIM
    中的结构项是 NCC 的平方根。这使得 SSIM 能够捕捉到关于两幅图像的相似性的信息，超越了它们之间的相关程度。
- en: Multi-modality. For multi-modal applications, traditional methods often use
    mutual information (MI) [[326](#bib.bib326)], correlation ratio [[274](#bib.bib274)],
    self-similarity context (SSC) [[129](#bib.bib129)], or normalized gradient fields (NGF) [[114](#bib.bib114)]
    as similarity measures. Both MI and correlation ratio evaluate the relationship
    between the two images by calculating intensity statistics, such as intensity
    histograms, to measure statistical dependence. However, the standard method for
    calculating intensity histograms, which involves counting, is not differentiable,
    so a Parzen window formulation [[316](#bib.bib316)] is often used to allow the
    loss to be backpropagated during network training. Parzen-window-based MI has
    been employed as a loss function in many multi-modal applications [[266](#bib.bib266),
    [329](#bib.bib329), [238](#bib.bib238), [111](#bib.bib111), [138](#bib.bib138)],
    but it can be relatively difficult to implement and also sensitive to factors
    such as the number of intensity bins and the smoothness of the Gaussian function.
    As far as we are aware, the correlation ratio has not been used in learning-based
    medical image registration. It should be noted that these intensity-statistic-based
    measurements do not take into account local structural information, making them
    more suitable for rigid/affine registration and less suitable for deformable registration
    applications [[259](#bib.bib259), [129](#bib.bib129)]. SSC is another commonly
    used loss function for multi-modal applications, and it is an improvement on the
    modality-independent neighborhood descriptor (MIND) [[128](#bib.bib128)]. Both
    SSC and MIND operate by calculating the descriptor between a voxel and its neighboring
    voxels within a given image, turning an image of any modality into a feature representation
    of these descriptors. The similarity is determined by summing the absolute differences
    between the descriptors of the two images. As SSC and MIND consider local structural
    information, they are not limited in the same way as MI or correlation ratio,
    making them more useful for multi-modal deformable registration [[119](#bib.bib119),
    [231](#bib.bib231), [357](#bib.bib357), [354](#bib.bib354), [24](#bib.bib24)].
    NGF compares images by focusing on the intensity changes, or edges, in the images.
    The similarity between the two images is determined by the presence of intensity
    changes at the same locations, regardless of the modalities of the images being
    compared. NGF was originally developed for multi-modal applications like brain
    MR T1-to-T2 and PET-to-CT [[114](#bib.bib114)]. However, it is now mostly used
    in learning-based registration models for lung CT registration [[131](#bib.bib131),
    [132](#bib.bib132), [231](#bib.bib231)]. This is because the complex structure
    of the lung, including bronchi, fissures, and vessels, can hinder accurate registration [[132](#bib.bib132)].
    NGF focuses on edges rather than intensity values, making it a more suitable measure
    for this purpose.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态性。在多模态应用中，传统方法通常使用互信息（MI）[[326](#bib.bib326)]、相关比率[[274](#bib.bib274)]、自相似性上下文（SSC）[[129](#bib.bib129)]或归一化梯度场（NGF）[[114](#bib.bib114)]作为相似性度量。MI和相关比率通过计算强度统计量（如强度直方图）来评估两个图像之间的关系，从而测量统计依赖性。然而，计算强度直方图的标准方法（即计数）是不可微的，因此通常使用Parzen窗口公式[[316](#bib.bib316)]来允许在网络训练过程中进行反向传播。基于Parzen窗口的MI已被作为损失函数应用于许多多模态应用中[[266](#bib.bib266)、[329](#bib.bib329)、[238](#bib.bib238)、[111](#bib.bib111)、[138](#bib.bib138)]，但其实现相对困难，并且对强度区间数和高斯函数的平滑度等因素较为敏感。据我们了解，相关比率在基于学习的医学图像配准中尚未使用。需要注意的是，这些基于强度统计量的度量不考虑局部结构信息，使其更适合刚性/仿射配准，而不适合变形配准应用[[259](#bib.bib259)、[129](#bib.bib129)]。SSC是另一种常用于多模态应用的损失函数，它是对模态独立邻域描述符（MIND）[[128](#bib.bib128)]的改进。SSC和MIND通过计算体素及其邻近体素之间的描述符来操作，将任何模态的图像转化为这些描述符的特征表示。相似性通过对两个图像描述符之间的绝对差异进行求和来确定。由于SSC和MIND考虑了局部结构信息，因此它们不像MI或相关比率那样受限，使其在多模态变形配准[[119](#bib.bib119)、[231](#bib.bib231)、[357](#bib.bib357)、[354](#bib.bib354)、[24](#bib.bib24)]中更为有用。NGF通过关注图像中的强度变化或边缘来比较图像。两个图像之间的相似性由相同位置的强度变化的存在决定，而不考虑被比较图像的模态。NGF最初是为多模态应用如脑部MR
    T1到T2和PET到CT[[114](#bib.bib114)]开发的，但现在主要用于基于学习的配准模型，如肺CT配准[[131](#bib.bib131)、[132](#bib.bib132)、[231](#bib.bib231)]。这是因为肺部的复杂结构，包括支气管、裂缝和血管，会影响准确配准[[132](#bib.bib132)]。NGF关注边缘而不是强度值，使其更适合于这一目的。
- en: Recent Advancements. There have been many efforts to improve upon or propose
    new loss functions due to some limitations of the aforementioned similarity measures.
    Terpstra et al. [[314](#bib.bib314)] showed that the $\ell^{2}$ loss (equivalent
    to MSE) is not optimal for MRI applications, because it does not fully leverage
    the magnitude and phase information contained in the complex data of MRI. The
    authors introduced $\bot$-loss, a loss function that is based on the polar representation
    of complex numbers and promotes symmetry in the overall loss landscape. They demonstrated
    that a network trained with a combination of $\bot$-loss and $\ell^{2}$ loss outperforms
    a network trained with $\ell^{2}$ loss alone in terms of registration performance.
    Czolbe et al. [[54](#bib.bib54)] leveraged a ConvNet feature extractor to obtain
    image features from the deformed and fixed images, and then computed the NCC between
    these features as a similarity measure. The benefit of this approach is that the
    features produced by the ConvNet feature extractor have less noise, resulting
    in a more consistent similarity measure in areas with noise which leads to a smoother
    transformation. Haskins et al. [[121](#bib.bib121)] were the first to propose
    using a ConvNet to learn a similarity measure for image registration. However,
    this method relies on having ground truth target registration error for the training
    dataset to learn such a similarity measure. Grzech et al. [[108](#bib.bib108)] went
    one step further and introduced a technique for learning a similarity measure
    using a variational Bayesian method. The method involves initializing the convolution
    kernels in the network architecture to model MSE and NCC, and then using variational
    inference to learn a similarity measure that optimizes the likelihood of the images
    in the dataset when aligning them to the atlas. Building on the success of adversarial
    networks in computer vision [[221](#bib.bib221), [106](#bib.bib106)], researchers
    have developed a number of techniques for image registration that leverage adversarial
    training [[83](#bib.bib83), [217](#bib.bib217), [208](#bib.bib208)]. These methods
    can be used standalone or in conjunction with a traditional similarity measure.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的进展。由于之前提到的相似性度量存在一些局限性，很多努力致力于改进或提出新的损失函数。Terpstra 等人 [[314](#bib.bib314)]
    证明了 $\ell^{2}$ 损失（等同于 MSE）在 MRI 应用中并非最佳，因为它没有充分利用 MRI 复杂数据中的幅度和相位信息。作者介绍了 $\bot$-loss，一种基于复数极坐标表示并促进整体损失景观对称性的损失函数。他们展示了，使用
    $\bot$-loss 和 $\ell^{2}$ 损失组合训练的网络在配准性能上优于仅使用 $\ell^{2}$ 损失训练的网络。Czolbe 等人 [[54](#bib.bib54)]
    利用 ConvNet 特征提取器从变形图像和固定图像中提取特征，然后计算这些特征之间的 NCC 作为相似性度量。这种方法的好处在于 ConvNet 特征提取器产生的特征噪声更少，从而在噪声区域得到更一致的相似性度量，导致更平滑的变换。Haskins
    等人 [[121](#bib.bib121)] 首次提出使用 ConvNet 学习图像配准的相似性度量。然而，这种方法依赖于拥有地面真实目标配准误差的数据集来学习这种相似性度量。Grzech
    等人 [[108](#bib.bib108)] 更进一步，介绍了一种使用变分贝叶斯方法学习相似性度量的技术。该方法包括初始化网络架构中的卷积核以建模 MSE
    和 NCC，然后使用变分推断来学习优化数据集中图像对齐到图谱的似然性的相似性度量。基于对抗网络在计算机视觉中的成功 [[221](#bib.bib221),
    [106](#bib.bib106)]，研究人员开发了多种利用对抗训练的图像配准技术 [[83](#bib.bib83), [217](#bib.bib217),
    [208](#bib.bib208)]。这些方法可以单独使用或与传统相似性度量结合使用。
- en: 3.4 Deformation Regularizer
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 变形正则化器
- en: 'A deformation regularizer, as the terminology implies, is used for DIR, with
    its usage being not necessary for rigid/affine transformations. For DIR algorithms,
    producing smooth deformations is not only a desirable property but a necessary
    requirement: while diffeomorphic transformations may not be required for certain
    applications, smoothness remains imperative in almost all cases to avoid trivial
    solutions such as rearranging voxels [[276](#bib.bib276)], with which an almost
    perfect similarity measure can be achieved but result in unrealistic transformation (also
    see Section [6](#S6 "6 Registration Evaluation Metrics ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond")). The regularizer can be considered as a prior in a maximum a posteriori (MAP)
    framework, while the similarity measure acts as the data likelihood (*e.g.*, in
    the case of MSE, the data likelihood becomes a Gaussian likelihood). The diffusion
    regularizer is a commonly employed deformation regularizer, as demonstrated by
    its frequent appearance in Table [1](#S3.T1 "Table 1 ‣ 3 Loss Functions ‣ A survey
    on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond"). This regularization computes the squared $\ell^{2}$-norm
    of the gradients of the displacement field, effectively penalizing the disparities
    between adjacent displacements. Other alternatives for regularization include
    using the $\ell^{1}$-norm instead of the $\ell^{2}$-norm to impart equal penalties
    on the neighboring disparities, or penalizing the second derivative of the displacements,
    commonly referred to as bending energy [[280](#bib.bib280)]. It is important to
    note that since bending energy and curvature-based regularizers penalize the second
    derivatives, thereby zeroing out any affine contributions, pre-affine alignment
    prior to the deformable registration step may not be necessary, as demonstrated
    in [[68](#bib.bib68), [89](#bib.bib89)]. These conventional regularizers enforce
    an isotropic regularization on the displacement field [[248](#bib.bib248)]. As
    a result, they discourage discontinuities in the displacements in applications
    where sliding motion may occur in organs, such as registering exhale and inhale
    CT scans of the lung. Historically, various improvements have been made to address
    this issue, including the isotropic Total Variation (TV) regularization [[327](#bib.bib327)],
    anisotropic diffusion regularization [[248](#bib.bib248)], and adaptive bilateral
    filtering-based regularization [[250](#bib.bib250)]. However, these regularization
    techniques have not been widely adopted in learning-based image registration.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '形变正则化器，顾名思义，用于DIR（可变形图像注册），而对刚性/仿射变换并非必需。对于DIR算法，生成平滑的形变不仅是一个理想特性，更是一个必要要求：虽然某些应用中可能不需要
    diffeomorphic 变换，但在几乎所有情况下，平滑性仍然是至关重要的，以避免诸如重新排列体素[[276](#bib.bib276)]等简单解决方案，虽然可以获得几乎完美的相似性度量，但会导致不现实的变换（另见第[6](#S6
    "6 Registration Evaluation Metrics ‣ A survey on deep learning in medical image
    registration: new technologies, uncertainty, evaluation metrics, and beyond")节）。正则化器可以视为最大后验（MAP）框架中的先验，而相似性度量则充当数据的可能性（*例如*，在MSE的情况下，数据的可能性变为高斯可能性）。扩散正则化器是一种常用的形变正则化器，如在表[1](#S3.T1
    "Table 1 ‣ 3 Loss Functions ‣ A survey on deep learning in medical image registration:
    new technologies, uncertainty, evaluation metrics, and beyond")中频繁出现的情况所示。该正则化计算位移场梯度的平方
    $\ell^{2}$-范数，有效地惩罚相邻位移之间的差异。其他正则化选择包括使用 $\ell^{1}$-范数代替 $\ell^{2}$-范数，以对邻近差异施加相等的惩罚，或惩罚位移的二阶导数，通常称为弯曲能量[[280](#bib.bib280)]。值得注意的是，由于弯曲能量和基于曲率的正则化器惩罚二阶导数，从而消除任何仿射贡献，因此在变形配准步骤之前进行仿射预对齐可能不是必要的，如[[68](#bib.bib68),
    [89](#bib.bib89)]所示。这些传统正则化器对位移场施加各向同性的正则化[[248](#bib.bib248)]。因此，它们在可能发生滑动运动的应用中，如肺部的呼气和吸气CT扫描的配准，抑制位移中的不连续性。历史上，已经做出了各种改进以解决此问题，包括各向同性总变差（TV）正则化[[327](#bib.bib327)]、各向异性扩散正则化[[248](#bib.bib248)]和基于自适应双边滤波的正则化[[250](#bib.bib250)]。然而，这些正则化技术在基于学习的图像配准中并未被广泛采用。'
- en: Recent Advancements. Enforcing spatial smoothness alone is insufficient to ensure
    the regularity of the transformations. A different strategy is to penalize the
    “folding” of voxels directly during training, in addition to applying the aforementioned
    regularizers to enforce smoothness in the deformation. These foldings can be evaluated
    using local Jacobian determinants, where the magnitude of the Jacobian determinant
    indicates if the volume is expanding or shrinking near the voxel location. A non-positive
    Jacobian determinant represents a locally non-invertible transformation. Several
    regularization methods based on local Jacobian determinants have been proposed
    to penalize such transformations [[180](#bib.bib180), [229](#bib.bib229)]. Meanwhile,
    with the advent of deep learning, new methods have emerged that leverage the deep
    learning of deformation regularization from data. One such method by Niethammer
    et al. [[242](#bib.bib242)], introduced a method that learns a spatially-varying
    deformation regularization using training data. Spatially-varying regularization
    offers the advantage of accommodating variations in deformation that may be required
    for different regions within an image, such as the movement of the lungs in relation
    to other organs (*e.g.*, rib cage) due to respiratory processes. The technique
    proposed by Niethammer *et al.* involves training a registration network to produce
    not only a deformation field but also a set of weight maps, each of which corresponds
    to the weight of a Gaussian smoothing kernel in a multi-Gaussian kernel configuration.
    The weighted multi-Gaussian kernel is then applied to the deformation field via
    convolution. To further impose spatial smoothness, an optimal mass transport (OMT)
    loss function was introduced to encourage the network to assign larger weights
    to Gaussian kernels with larger variances. While this method was developed for
    a time-stationary velocity field setting, Shen et al. [[290](#bib.bib290)] later
    expanded upon it by incorporating it into a time-varying velocity field setting.
    In this setup, a different set of weight maps are produced for each time point.
    More recently, Chen et al. [[41](#bib.bib41)] introduced a weighted diffusion
    regularizer that applies spatially-varying regularization to the deformation field.
    The neural network generates a weight volume, assigning a unique regularization
    weight to each voxel and thus allows for spatially-varying levels of regularization
    strength. As the diffusion regularizer is related to Gaussian smoothing, using
    spatially-varying strengths of diffusion regularization can be considered equivalent
    to employing a multi-Gaussian kernel, as originally proposed by Niethammer et al.
    [[242](#bib.bib242)]. This is because the convolution of multiple Gaussian kernels
    still results in a Gaussian kernel. To promote the overall smoothness of the deformation,
    they further applied a log loss to the weight volume, which encourages the maximum
    regularization strength when possible. In a different approach, Wang et al. [[335](#bib.bib335)] employed
    a regression network to learn the optimal regularization parameter for an optimization-based
    method, specifically Flash [[371](#bib.bib371)]. Flash is a geodesic shooting
    method in the Fourier space that requires only the initial velocity field to compute
    the time-dependent transformation. Wang *et al.* generated ground truth optimal
    regularization parameters by assuming the prior of the initial velocity field
    given the regularization parameter as a multivariate Gaussian distribution. Using
    gradient descent, they obtained the optimal regularization parameter for each
    image pair through MAP estimation. A ConvNet regression encoder then estimates
    the optimal regularization parameter based on the image pair. This approach achieved
    registration performance comparable to Flash while significantly improving runtime
    and memory efficiency. Alternatively, Laves et al. [[184](#bib.bib184)] were inspired
    by the deep image prior [[320](#bib.bib320)]. They used a randomly initialized
    ConvNet as a regularization prior. They then fed a random image (*i.e.*, a noise
    image) as input and the network gradually transformed it into a smooth deformation
    field through iterative optimization. The deep image prior provided by the ConvNet
    enables the network to produce a smooth deformation in the early iterations, then
    gradually adds non-smooth high-frequency deformations. As a result, early stopping
    is used for the network to generate a smooth deformation field without the need
    for explicitly encouraging smoothness in the loss function.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最新进展。仅仅强制施加空间平滑不足以确保变换的规则性。一种不同的策略是，在训练期间直接惩罚体素的“折叠”，除了应用上述正则化器以强制变形的平滑。这些折叠可以使用局部雅可比行列式来评估，其中雅可比行列式的大小指示体素位置附近的体积是否在扩张或收缩。非正雅可比行列式代表局部不可逆变换。已经提出了几种基于局部雅可比行列式的正则化方法来惩罚此类变换 [[180](#bib.bib180),
    [229](#bib.bib229)]。同时，随着深度学习的出现，利用数据中的变形正则化进行深度学习的新方法也应运而生。Niethammer等人提出了一种方法，通过训练数据学习空间变化的变形正则化[[242](#bib.bib242)]。空间变化正则化具有适应图像中不同区域变形变化的优势，例如肺部相对于其他器官（*例如*，胸廓）的运动，由于呼吸过程引起。Niethammer *et
    al.*提出的技术包括训练一个配准网络，不仅生成变形场，还生成一组权重图，每个权重图对应于多高斯核配置中的高斯平滑核的权重。然后，通过卷积将加权的多高斯核应用于变形场。为了进一步施加空间平滑，提出了一种最优质量传输（OMT）损失函数，以鼓励网络为具有较大方差的高斯核分配更大的权重。虽然该方法是为时间静态速度场设置开发的，Shen等人后来通过将其扩展到时间变化速度场设置来进行了扩展[[290](#bib.bib290)]。在这种设置中，为每个时间点生成一组不同的权重图。最近，Chen等人引入了一种加权扩散正则化器，将空间变化正则化应用于变形场[[41](#bib.bib41)]。神经网络生成一个权重体积，为每个体素分配唯一的正则化权重，从而允许空间变化的正则化强度。由于扩散正则化器与高斯平滑相关，使用空间变化的扩散正则化强度可以被认为等同于使用多高斯核，正如最初由 Niethammer等人提出的那样[[242](#bib.bib242)]。这是因为多个高斯核的卷积仍然会产生一个高斯核。为了促进变形的整体平滑，他们进一步对权重体积应用了对数损失，鼓励在可能的情况下最大化正则化强度。在另一种方法中，Wang等人使用回归网络学习优化基方法的最优正则化参数，特别是Flash[[371](#bib.bib371)]。Flash是一种傅里叶空间中的测地线发射方法，仅需初始速度场即可计算时间相关的变换。Wang *et
    al.*通过假设给定正则化参数的初始速度场的先验为多元高斯分布，生成了真实的最优正则化参数。通过梯度下降，他们通过MAP估计获得了每对图像的最优正则化参数。然后，ConvNet回归编码器根据图像对估计最优正则化参数。这种方法在提高运行时间和内存效率的同时，实现了与Flash相当的配准性能。另一种方法，Laves等人受到深度图像先验[[320](#bib.bib320)]的启发。他们使用一个随机初始化的ConvNet作为正则化先验。然后，他们输入随机图像（*即*，噪声图像），网络通过迭代优化将其逐渐转化为平滑的变形场。ConvNet提供的深度图像先验使网络能够在早期迭代中生成平滑的变形，然后逐渐添加不平滑的高频变形。因此，早期停止用于生成平滑的变形场，而无需在损失函数中明确鼓励平滑。
- en: Transformations can also be implicitly regularized by imposing invertibility
    constraints. This is achieved by using a symmetric consistency loss or cycle consistency
    loss. Symmetric consistency typically uses a single DNN to output both the forward
    and reverse deformation fields, which transform the moving image to the fixed
    image and vice versa, respectively. The similarity between the warped image and
    the target image is then calculated and backpropagated to update the network [[229](#bib.bib229),
    [196](#bib.bib196)]. Alternatively, a consistency loss can be calculated by composing
    the network-generated forward and backward deformation fields, and then comparing
    the outcome with the identity transformation [[107](#bib.bib107), [317](#bib.bib317)].
    The underlying concept is that, theoretically, an invertible mapping should cancel
    itself when composed with its inverse. Such an approach by itself imposes invertibility
    but does not explicitly enforce spatial smoothness over the deformation field.
    Greer et al. [[107](#bib.bib107)] demonstrated that incorporating such a loss
    within a DNN framework implicitly imposes spatial regularity on the deformation
    field without necessitating an additional regularizer to enforce smoothness. The
    authors showed that the errors of the DNN in computing the inverse, combined with
    the implicit bias of DNN favoring more regular outputs, enable such a consistency
    loss to entail a $H^{1}-$ or Sobolev-type regularization over the deformation
    field, thereby implicitly enforcing spatial smoothness. Later, Tian et al. [[317](#bib.bib317)] expanded
    on this regularizer and proposed to regularize deviations of the Jacobian of the
    composition from the identity matrix. This improved regularizer led to faster
    convergence while offering greater flexibility, while maintaining an approximated
    diffeomorphic transformation.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 变换也可以通过施加可逆性约束来隐式正则化。这是通过使用对称一致性损失或循环一致性损失来实现的。对称一致性通常使用一个单一的深度神经网络（DNN）来输出前向和反向变形场，分别将移动图像转换为固定图像，反之亦然。然后计算变形图像与目标图像之间的相似性，并通过反向传播更新网络 [[229](#bib.bib229),
    [196](#bib.bib196)]。或者，也可以通过将网络生成的前向和反向变形场进行组合来计算一致性损失，然后将结果与恒等变换进行比较 [[107](#bib.bib107),
    [317](#bib.bib317)]。其基本概念是，理论上，可逆映射在与其逆映射组合时应该会互相抵消。这样的做法本身施加了可逆性，但并未显式强制变形场的空间平滑。Greer等人
    [[107](#bib.bib107)] 证明了在DNN框架中引入这样的损失隐式地对变形场施加了空间正则性，而无需额外的正则化器来强制平滑。作者展示了DNN在计算逆变换时的误差，加上DNN隐式偏向更规则输出的偏差，使得这种一致性损失能够实现$H^{1}-$或Sobolev类型的正则化，从而隐式地强制空间平滑。随后，Tian等人
    [[317](#bib.bib317)] 扩展了这种正则化器，提出对组合的Jacobian偏离恒等矩阵进行正则化。这种改进的正则化器在保持近似同胚变换的同时，提高了收敛速度并提供了更大的灵活性。
- en: On the other hand, cycle consistency employs two identical networks, where the
    first network generates a forward deformation field that deforms the moving image
    and the second network produces a reverse field that aims to warp the deformed
    image back to the original moving image [[377](#bib.bib377), [179](#bib.bib179),
    [172](#bib.bib172)]. Both consistency losses have been shown to improve the registration
    performance and provide regularization to the deformation field. However, since
    this regularization is not explicitly applied to the deformation fields, a separate
    deformation regularizer is often required in addition to the consistency loss.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，循环一致性使用两个相同的网络，其中第一个网络生成一个前向变形场，对移动图像进行变形，而第二个网络生成一个反向变形场，旨在将变形后的图像扭曲回原始移动图像 [[377](#bib.bib377),
    [179](#bib.bib179), [172](#bib.bib172)]。这两种一致性损失已被证明可以改善配准性能，并为变形场提供正则化。然而，由于这种正则化并未显式应用于变形场，通常需要一个单独的变形正则化器，此外还有一致性损失。
- en: 3.5 Auxiliary Anatomical Information
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 辅助解剖信息
- en: 'The overlap of anatomical label maps of the fixed and transformed moving images
    is a widely used evaluation metric for image registration. Hence, to improve registration
    performance on this metric, learning-based methods often incorporate an anatomy
    loss in their network training. Various loss functions used in image segmentation
    tasks, such as Dice loss, cross-entropy, and focal loss (see Ma et al. [[210](#bib.bib210)] for
    a comprehensive review of such loss functions), can be borrowed as the choice
    of anatomy loss. Despite the availability of different loss functions, Dice loss
    remains the most commonly used loss function in learning-based image registration,
    as evidenced by Table [1](#S3.T1 "Table 1 ‣ 3 Loss Functions ‣ A survey on deep
    learning in medical image registration: new technologies, uncertainty, evaluation
    metrics, and beyond"). This is likely because Dice loss is confined within the
    range of $[0,1]$, like NCC, which makes it easier to adjust hyperparameters when
    used in conjunction with NCC.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '固定图像和变换运动图像的解剖标签图的重叠是图像配准中广泛使用的评估指标。因此，为了提高这一指标上的配准性能，基于学习的方法通常在其网络训练中融入了解剖学损失。各种用于图像分割任务的损失函数，如
    Dice 损失、交叉熵和焦点损失（有关这些损失函数的全面回顾，请参见 Ma 等人 [[210](#bib.bib210)]），可以作为解剖学损失的选择。尽管有多种损失函数可供选择，Dice
    损失仍然是基于学习的图像配准中最常用的损失函数，这一点在表 [1](#S3.T1 "Table 1 ‣ 3 Loss Functions ‣ A survey
    on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond") 中得到了证实。这可能是因为 Dice 损失和 NCC 一样，限制在 $[0,1]$ 范围内，这使得在与
    NCC 结合使用时更容易调整超参数。'
- en: When anatomical landmarks are present in both the moving and fixed images, the
    transformation generated by the DNN can be applied to the landmarks of the moving
    image. The resulting transformed landmarks can then be compared with the landmarks
    of the fixed image to create a loss. This landmark supervision has been utilized
    in optimization-based registration methods to improve performance, as demonstrated
    in a number of studies  [[77](#bib.bib77), [261](#bib.bib261), [281](#bib.bib281),
    [125](#bib.bib125), [88](#bib.bib88)]. Hering et al. [[132](#bib.bib132)] were
    the first to incorporate landmark supervision into a DNN framework by comparing
    the MSE between the transformed and target landmarks, which resulted in a substantial
    improvement in the target registration error of the landmark. Subsequently, [[127](#bib.bib127)] confirmed
    the superiority of landmark supervision on multiple benchmark datasets in their
    work. It is worth mentioning that the landmarks can be generated automatically
    before or during the training stage without manual labeling using automatic landmark
    detection algorithms [[125](#bib.bib125), [281](#bib.bib281), [261](#bib.bib261)],
    making it straightforward to integrate into most learning-based registration frameworks.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 当运动图像和固定图像中都存在解剖标志时，可以将 DNN 生成的变换应用于运动图像的标志。然后，可以将生成的变换标志与固定图像的标志进行比较，以创建损失。这种标志监督已被应用于基于优化的配准方法中，以提高性能，如多个研究所示 
    [[77](#bib.bib77), [261](#bib.bib261), [281](#bib.bib281), [125](#bib.bib125),
    [88](#bib.bib88)]。Hering 等人 [[132](#bib.bib132)] 是首个通过比较变换后的标志与目标标志之间的均方误差（MSE）将标志监督纳入
    DNN 框架的人，这大大改善了标志的目标配准误差。随后，[[127](#bib.bib127)] 在他们的工作中确认了标志监督在多个基准数据集上的优越性。值得一提的是，标志可以在训练阶段之前或期间自动生成，而无需手动标注，使用自动标志检测算法 [[125](#bib.bib125),
    [281](#bib.bib281), [261](#bib.bib261)]，这使得它容易集成到大多数基于学习的配准框架中。
- en: 'The combination of anatomy loss and deformation regularization without an intensity-based
    similarity measure is also common, and in these cases, the anatomy loss serves
    as a modality-independent similarity measure [[148](#bib.bib148), [305](#bib.bib305),
    [23](#bib.bib23)]. However, the drawback of using anatomy loss without a similarity
    measure is clear: it does not penalize deformations in areas where anatomical
    labels are missing or ambiguous. Thus, to achieve accurate and realistic deformations,
    the anatomical labels should be as detailed as possible, ideally with a unique
    label for each organ or structure. However, obtaining such detailed labels is
    often challenging as anatomical label maps in medical imaging are usually manually
    delineated, which is a time-consuming and expensive process.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 结合解剖学损失和形变正则化而没有基于强度的相似性度量也很常见，在这些情况下，解剖学损失作为模态无关的相似性度量[[148](#bib.bib148),
    [305](#bib.bib305), [23](#bib.bib23)]。然而，使用解剖学损失而没有相似性度量的缺点是显而易见的：它不会惩罚解剖标签缺失或模糊的区域的形变。因此，为了实现准确且真实的形变，解剖标签应尽可能详细，理想情况下每个器官或结构都有唯一的标签。然而，获取如此详细的标签通常具有挑战性，因为医学影像中的解剖标签图通常是手动描绘的，这是一项耗时且昂贵的过程。
- en: 4 Network Architectures
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 网络架构
- en: The application of ConvNets has been the dominant trend in learning-based image
    registration since its inception. Among different ConvNets architectures, the
    U-Net-like architectures [[279](#bib.bib279)], which were initially designed for
    image segmentation tasks, have played an important role. Many noteworthy ConvNet-based
    registration models, including RegNet [[303](#bib.bib303)], DIRNet [[60](#bib.bib60)],
    QuickSilver [[362](#bib.bib362)]VoxelMorph [[14](#bib.bib14), [56](#bib.bib56)],
    VTN [[377](#bib.bib377)], DeepFlash [[334](#bib.bib334)], and CycleMorph [[172](#bib.bib172)],
    have demonstrated promising performance in various registration applications.
    More recently, registration neural networks have witnessed notable advancements
    beyond the conventional ConvNet designs, owing to the progress of DNN architectures
    in computer vision and the development of architectures that are specifically
    tailored for registration tasks. Notably, models such as Transformers, diffusion
    models, and Neural ODEs are gaining increasing attention in the field of image
    registration. This section provides a comprehensive overview of these recent advancements.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ConvNets 的应用自其诞生以来一直是基于学习的图像配准中的主导趋势。在不同的 ConvNets 架构中，最初设计用于图像分割任务的 U-Net 类架构[[279](#bib.bib279)]，发挥了重要作用。许多值得注意的基于
    ConvNet 的配准模型，包括 RegNet [[303](#bib.bib303)]、DIRNet [[60](#bib.bib60)]、QuickSilver
    [[362](#bib.bib362)]、VoxelMorph [[14](#bib.bib14), [56](#bib.bib56)]、VTN [[377](#bib.bib377)]、DeepFlash
    [[334](#bib.bib334)] 和 CycleMorph [[172](#bib.bib172)]，在各种配准应用中表现出色。最近，由于计算机视觉中
    DNN 架构的进展以及专门为配准任务量身定制的架构的发展，配准神经网络经历了显著的进展。值得注意的是，诸如 Transformers、扩散模型和神经 ODEs
    的模型在图像配准领域获得了越来越多的关注。本节提供了这些近期进展的全面概述。
- en: 4.1 Adversarial Learning
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 对抗学习
- en: The majority of adversarial learning applied to image registration relies on
    the foundational principles of generative adversarial networks (GANs). The concept
    of GANs is derived from a two-player zero-sum game involving a generator and a
    discriminator [[106](#bib.bib106)]. The objective of the generator is to generate
    new samples by learning the data distribution, while the discriminator functions
    as a binary classifier, aiming to accurately distinguish between real and generated
    samples. In the context of image registration, the registration network acts as
    the generator, producing a deformation field and subsequently warping the moving
    image. Meanwhile, the discriminator functions as an image similarity measure,
    distinguishing between the warped image and the fixed image. This offers the advantage
    of alleviating the need for an explicit similarity measure, making the approach
    adaptable to both mono- and multi-modality applications.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 应用于图像配准的大多数对抗学习依赖于生成对抗网络（GANs）的基础原理。GANs 的概念源自涉及生成器和判别器的双人零和博弈[[106](#bib.bib106)]。生成器的目标是通过学习数据分布生成新样本，而判别器作为二分类器，旨在准确区分真实样本和生成样本。在图像配准的背景下，配准网络作为生成器，产生一个形变场，并随后扭曲移动图像。同时，判别器作为图像相似性度量，区分扭曲图像和固定图像。这种方法的优点是缓解了对显式相似性度量的需求，使得该方法适用于单模态和多模态应用。
- en: In early applications of adversarial learning to image registration, Fan et al.
    [[84](#bib.bib84)] and Yan et al. [[356](#bib.bib356)] adhered to the aforementioned
    approach. The former utilized the generator to produce a deformation field, while
    the latter employed a ConvNet encoder to generate affine transformation parameters.
    Subsequently, a binary discriminator served as a similarity measure between the
    transformed and fixed images. In a similar vein, Mahapatra *et al.* [[216](#bib.bib216),
    [218](#bib.bib218), [217](#bib.bib217)] applied adversarial learning to multi-modal
    image registration, with the additional implementation of CycleGAN [[382](#bib.bib382),
    [264](#bib.bib264)] to further ensure the inverse consistency of the generated
    deformation field. Elmahdy et al. [[78](#bib.bib78)] proposed incorporating anatomical
    label maps into a Wasserstein-GAN (WGAN) to enhance the segmentation performance
    of the registration network. Their generator was a U-Net-based network that generated
    a deformation field, which warped both the moving image and the associated anatomical
    label map. The discriminator’s role was to evaluate the alignment between the
    warped and fixed image, as well as the warped and fixed label maps. In their approach,
    image and anatomical similarity measures were still employed, while the discriminator
    served as an additional measure of the alignment. Similar approaches can be found
    in Duan et al. [[75](#bib.bib75)], Li and Ogino [[192](#bib.bib192)], and Luo
    et al. [[208](#bib.bib208)], where the authors used the discriminator in conjunction
    with image similarity measures as additional alignment indicators. In another
    study, Fan et al. [[83](#bib.bib83)] proposed a GAN-based registration framework
    applicable to both mono- and multi-modality registration. Their generator was
    also a registration network based on U-Net, with the discriminator serving as
    the sole measure of image alignment. However, the definition of positive pairs
    sent to the discriminator deviated from previous methods. Ideally, in mono-modality
    registration, a positive pair would consist of identical images, but this strict
    requirement is impractical. Given this observation, the authors proposed that
    the positive pair comprise the fixed image and an alpha-blended image created
    from the fixed and moving images. For multi-modality registration, a positive
    pair consisted of pre-aligned multi-modal images from the same patient. The method
    was evaluated on mono-modal brain MRI registration and multi-modal pelvic MR and
    CT registration tasks, demonstrating favorable performance compared to the state-of-the-art
    at the time.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期对抗学习应用于图像配准的研究中，Fan等人[[84](#bib.bib84)]和Yan等人[[356](#bib.bib356)]遵循了上述方法。前者利用生成器产生变形场，而后者使用了ConvNet编码器生成仿射变换参数。随后，二分类鉴别器作为变换后图像和固定图像之间的相似性度量。类似地，Mahapatra
    *等人*[[216](#bib.bib216), [218](#bib.bib218), [217](#bib.bib217)]将对抗学习应用于多模态图像配准，并额外实现了CycleGAN[[382](#bib.bib382),
    [264](#bib.bib264)]以进一步确保生成的变形场的逆一致性。Elmahdy等人[[78](#bib.bib78)]提出将解剖标签图纳入Wasserstein-GAN（WGAN）以提高配准网络的分割性能。他们的生成器是基于U-Net的网络，生成一个变形场，这个变形场会同时扭曲移动图像和相关的解剖标签图。鉴别器的角色是评估扭曲后的图像与固定图像之间的对齐，以及扭曲后的标签图与固定标签图之间的对齐。在他们的方法中，图像和解剖相似性度量仍然被使用，而鉴别器则作为对齐的额外度量。类似的方法可以在Duan等人[[75](#bib.bib75)]、Li和Ogino[[192](#bib.bib192)]以及Luo等人[[208](#bib.bib208)]的研究中找到，作者们在图像相似性度量的基础上使用了鉴别器作为额外的对齐指标。在另一项研究中，Fan等人[[83](#bib.bib83)]提出了一种基于GAN的配准框架，适用于单模态和多模态配准。他们的生成器同样是基于U-Net的配准网络，鉴别器作为图像对齐的唯一度量。然而，送入鉴别器的正样本对的定义偏离了之前的方法。理想情况下，在单模态配准中，正样本对应由相同的图像组成，但这一严格要求并不实际。鉴于这一观察，作者们提出正样本对由固定图像和从固定图像与移动图像合成的alpha混合图像组成。对于多模态配准，正样本对由来自同一患者的预对齐的多模态图像组成。该方法在单模态脑MRI配准和多模态盆腔MR与CT配准任务上进行了评估，相较于当时的最先进技术表现出良好的性能。
- en: Given the promising results GANs have demonstrated in image translation, i.e.,
    synthesizing one image modality into another, researchers have made efforts to
    leverage their capabilities in addressing multi-modal image registration. This
    approach involves first synthesizing multi-modal images into the same modality
    and then applying a registration network to perform the image registration task.
    Xu et al. [[354](#bib.bib354)] tackled the challenge of multi-modal registration
    of CT and MR images using a CycleGAN-based approach to translate CT images into
    MR images. To ensure that the translated images maintained anatomical consistency
    with the original images, the authors introduced additional loss functions, including
    MIND and identity loss, alongside the standard CycleGAN loss. They then employed
    a three-stage registration framework to align the original and translated images.
    In the first stage, a U-Net-based registration network learned the multi-modal
    registration between CT and MR images. In the second stage, a network with the
    same architecture learned the mono-modal registration between the translated CT
    and the target MR images. Finally, the deformation fields created by both registration
    networks were fused using a convolutional layer to produce the final deformation
    field. A similar concept was presented in Wei et al. [[339](#bib.bib339)], where
    mutual information was used instead of MIND to enforce structural consistency.
    Zheng et al. [[378](#bib.bib378)] integrated an image translation network within
    a GAN-based image registration framework, where the modality of the moving image
    was first translated to the modality of the target image before a registration
    network was applied to register the two images. The discriminator in this approach
    acted as an image similarity metric for both the registration and image translation
    networks. Additionally, this approach employed a symmetric pipeline that reversed
    the order of the moving and fixed images, ensuring symmetric consistency in the
    resulting synthesized and deformation images. More recently, Han et al. [[116](#bib.bib116)] proposed
    tackling the multi-modal registration between CT and MR images using a dual-channel
    framework. Within each channel, an imaging modality was transformed into a target
    modality using a probabilistic CycleGAN, which was then followed by a registration
    network that predicted the deformation in the target modality. The deformation
    fields from both channels were then fused, taking advantage of the uncertainty
    weighting generated by the synthesis networks. This proposed dual-channel framework
    can be trained end-to-end, resulting in improved registration accuracy and faster
    runtime compared to baseline methods.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于生成对抗网络（GAN）在图像翻译中的良好表现，即将一种图像模态合成到另一种图像模态，研究人员致力于利用其能力来解决多模态图像配准问题。这种方法首先将多模态图像合成到相同的模态中，然后应用配准网络来执行图像配准任务。Xu
    等人 [[354](#bib.bib354)] 使用基于 CycleGAN 的方法来将 CT 图像翻译成 MR 图像，从而应对 CT 和 MR 图像的多模态配准挑战。为了确保翻译后的图像与原始图像在解剖学上保持一致，作者引入了包括
    MIND 和身份损失在内的附加损失函数，以及标准的 CycleGAN 损失。然后，他们采用了三阶段的配准框架来对齐原始图像和翻译后的图像。在第一阶段，基于
    U-Net 的配准网络学习 CT 和 MR 图像之间的多模态配准。在第二阶段，具有相同架构的网络学习翻译后的 CT 图像和目标 MR 图像之间的单模态配准。最后，两个配准网络创建的变形场通过卷积层融合，以生成最终的变形场。Wei
    等人 [[339](#bib.bib339)] 提出了类似的概念，在该方法中，使用互信息代替 MIND 来强制执行结构一致性。Zheng 等人 [[378](#bib.bib378)]
    在基于 GAN 的图像配准框架中集成了图像翻译网络，其中移动图像的模态首先被翻译成目标图像的模态，然后应用配准网络对两幅图像进行配准。在这种方法中，判别器作为图像相似性度量，应用于配准和图像翻译网络。此外，该方法采用了一个对称的流水线，逆转了移动图像和固定图像的顺序，以确保合成图像和变形图像在结果中的对称一致性。最近，Han
    等人 [[116](#bib.bib116)] 提出了使用双通道框架处理 CT 和 MR 图像之间的多模态配准。在每个通道中，使用概率 CycleGAN 将成像模态转换为目标模态，然后由配准网络预测目标模态中的变形。然后，将两个通道中的变形场进行融合，利用合成网络生成的不确定性加权。该双通道框架可以端到端训练，与基线方法相比，具有更高的配准准确性和更快的运行时间。
- en: Adversarial learning has also been employed for knowledge distillation, enabling
    the transfer of information from a larger teacher network to a smaller student
    network (*i.e.*, in terms of the number of parameters). Tran et al. [[318](#bib.bib318)] aimed
    to compress the size of a registration network by transferring information from
    a computationally expensive VTN [[377](#bib.bib377)] to a smaller registration
    network with only one-tenth of its parameters. The training process for the student
    network involved calculating a correlation-based image similarity measure [[377](#bib.bib377)]
    between the warped image generated by the student network and the fixed image.
    Meanwhile, a discriminator was used to differentiate the deformation field created
    by the student network and the pre-trained teacher network. After training, the
    teacher network was discarded, and only the lightweight student network was used
    for inference. Despite having only one-tenth of the network parameters, the lightweight
    registration network demonstrated comparable performance to baseline learning-based
    methods with larger parameter sizes, in terms of both anatomical overlaps and
    deformation smoothness.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗学习也被用于知识蒸馏，允许将信息从较大的教师网络转移到较小的学生网络（*即*，在参数数量方面）。Tran等人[[318](#bib.bib318)]旨在通过将信息从计算成本高昂的VTN[[377](#bib.bib377)]转移到只有其十分之一参数的较小配准网络来压缩配准网络的规模。学生网络的训练过程涉及计算学生网络生成的变形图像与固定图像之间的基于相关性的图像相似度度量[[377](#bib.bib377)]。同时，使用判别器来区分学生网络和预训练教师网络创建的变形场。训练后，教师网络被丢弃，仅使用轻量级的学生网络进行推理。尽管仅有十分之一的网络参数，轻量级配准网络在解剖重叠和变形平滑度方面表现出与参数规模更大的基准学习方法相当的性能。
- en: 4.2 Contrastive Learning
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 对比学习
- en: The principle of contrastive learning enables DNNs to learn by comparing various
    examples instead of focusing on single data points independently. This comparison
    process typically involves examining positive pairs of similar inputs and negative
    pairs of dissimilar inputs. For a comprehensive understanding of this concept
    and a detailed overview of the evolution of contrastive learning, we recommend
    interested readers refer to Le-Khac et al. [[185](#bib.bib185)]. In the context
    of image registration, contrastive learning could be particularly beneficial as
    an alternative to using explicit image similarity metrics, which can be challenging
    to optimize due to their task-specific nature. For example, different similarity
    metrics may be preferred for lung CT registration versus brain MRI registration
    or multi-modal versus mono-modal registration tasks. Whereas, contrastive learning
    empowers the DNN to determine whether two images are registered or not without
    relying on a specific image similarity metric, making it a more versatile approach
    for handling different registration tasks.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 对比学习的原理使得深度神经网络（DNN）通过比较各种示例来进行学习，而不是独立地关注单个数据点。这一比较过程通常涉及检查相似输入的正样本对和不相似输入的负样本对。为了全面理解这一概念并详细了解对比学习的演变，我们建议感兴趣的读者参考Le-Khac等人的文献[[185](#bib.bib185)]。在图像配准的背景下，对比学习作为使用明确图像相似度度量的替代方法可能特别有益，因为后者由于任务特定的性质往往难以优化。例如，不同的相似度度量可能在肺部CT配准与脑部MRI配准，或多模态与单模态配准任务中有所不同。而对比学习使得DNN能够判断两张图像是否配准，而无需依赖于特定的图像相似度度量，使其成为处理不同配准任务的更具通用性的方法。
- en: Hu et al. [[145](#bib.bib145)] were the pioneers in applying contrastive learning
    to multi-modal affine registration, concentrating on the inter-patient alignment
    of 2D CT and MR scans for patients with Nasopharyngeal Cancer. Their method involved
    using an automatic keypoint detecting algorithm to identify keypoints in the CT
    and MR scans. Subsequently, they extracted a patch centered on each keypoint and
    employed a Siamese network to minimize the contrastive loss, which minimized the
    distance between corresponding keypoints and maximized the distance between non-corresponding
    keypoints. In the testing phase, after establishing correspondences between all
    keypoints in the CT and MR scans, the optimal affine transformation parameter
    was determined by means of least-squares fitting. In another study, Pielawski
    et al. [[257](#bib.bib257)] applied contrastive learning to transform multi-modal
    images into similar contrastive representations with equivariant properties. Their
    method used two independent U-Nets to learn the representations for each modality
    such that the InfoNCE-based [[246](#bib.bib246)] loss between the learned representations
    is minimized. This minimization can be understood as maximizing the mutual information
    between the two learned representations. Finally, conventional affine registration
    methods were used to align the learned representations as if they had undergone
    a mono-modal registration task. Wetzer et al. [[342](#bib.bib342)] later investigated
    the contrastive learning approach proposed in Pielawski et al. [[257](#bib.bib257)] to
    determine whether applying contrastive learning supervisions to the U-Nets’ intermediate
    layers could improve multi-modal image registration performance. However, they
    concluded that the best representations for the evaluated registration task were
    achieved when the contrastive loss was applied only to the features of the final
    layers. Casamitjana et al. [[33](#bib.bib33)] proposed a contrastive learning-based
    approach for multi-modal deformable registration. They introduced a synthesis-by-registration
    method, where they trained a registration network for mono-modal registration
    on the target modality domain, and then froze the network’s weight for training
    an image synthesis network using a loss function that leverages the registration
    network. The image synthesis network’s ability to accurately translate the moving
    image into the target modality directly influenced the performance of the registration
    network. To enhance synthesis performance and ensure geometric consistency, a
    PatchNCE-based [[252](#bib.bib252)] contrastive loss was used, maximizing the
    mutual information between pre- and post-synthesis images at the patch level.
    This method demonstrated promising results in multi-modal brain MRI registration
    applications, outperforming both MI-based registration and other image synthesis-based
    registration methods. Dey et al. [[62](#bib.bib62)] also addressed the multi-modal
    registration task using contrastive loss. In their method, feature-extracting
    autoencoders were first pre-trained for each modality to derive modality-specific
    features. These autoencoders were then used on the deformed moving image and the
    fixed image to extract features for a PatchNCE-based [[252](#bib.bib252)] contrastive
    loss. In order to optimize contrastive learning, a single positive pair was sampled,
    corresponding to the multi-scale feature patches of the same spatial location
    across both modalities, while multiple negative pairs were sampled, corresponding
    to the feature patches of different spatial locations.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Hu 等人 [[145](#bib.bib145)] 是将对比学习应用于多模态仿射配准的先驱，专注于鼻咽癌患者 2D CT 和 MR 扫描的患者间对齐。他们的方法包括使用自动关键点检测算法来识别
    CT 和 MR 扫描中的关键点。随后，他们提取了以每个关键点为中心的补丁，并使用 Siamese 网络来最小化对比损失，这样可以最小化对应关键点之间的距离，并最大化非对应关键点之间的距离。在测试阶段，在
    CT 和 MR 扫描中建立了所有关键点之间的对应关系后，通过最小二乘拟合确定了最佳仿射变换参数。在另一项研究中，Pielawski 等人 [[257](#bib.bib257)]
    将对比学习应用于将多模态图像转化为具有等变性质的相似对比表示。他们的方法使用了两个独立的 U-Net 来学习每种模态的表示，从而最小化学习表示之间基于 InfoNCE
    的 [[246](#bib.bib246)] 损失。这种最小化可以理解为最大化两个学习表示之间的互信息。最后，使用传统的仿射配准方法对学习到的表示进行对齐，就像它们经历了单模态配准任务一样。Wetzer
    等人 [[342](#bib.bib342)] 后来研究了 Pielawski 等人 [[257](#bib.bib257)] 提出的对比学习方法，以确定将对比学习监督应用于
    U-Net 的中间层是否可以改善多模态图像配准性能。然而，他们得出结论，评估的配准任务中最佳的表示是在对比损失仅应用于最终层的特征时实现的。Casamitjana
    等人 [[33](#bib.bib33)] 提出了一个基于对比学习的多模态可变形配准方法。他们引入了一种合成配准方法，其中他们首先在目标模态域上训练了一个用于单模态配准的网络，然后冻结该网络的权重以训练一个图像合成网络，使用利用配准网络的损失函数。图像合成网络准确地将移动图像翻译为目标模态的能力直接影响了配准网络的性能。为了提高合成性能并确保几何一致性，使用了基于
    PatchNCE [[252](#bib.bib252)] 的对比损失，在补丁级别最大化合成前后图像之间的互信息。这种方法在多模态脑 MRI 配准应用中表现出良好的结果，优于基于
    MI 的配准和其他基于图像合成的配准方法。Dey 等人 [[62](#bib.bib62)] 也使用对比损失解决了多模态配准任务。在他们的方法中，首先为每种模态预训练了特征提取自编码器，以提取模态特定的特征。这些自编码器随后用于变形的移动图像和固定图像，以提取用于基于
    PatchNCE [[252](#bib.bib252)] 的对比损失的特征。为了优化对比学习，采样了一个正样本对，对应于两个模态中的相同空间位置的多尺度特征补丁，同时采样了多个负样本对，对应于不同空间位置的特征补丁。
- en: Until now, the methods based on contrastive learning have been centered on multi-modal
    image registration. However, Liu et al. [[194](#bib.bib194)] proposed the integration
    of contrastive learning in the intermediate stages of the network architecture
    for mono-modal brain MRI registration. In their method, two identical ConvNet
    encoders of shared weights were applied to the moving and fixed images, each followed
    by a fully-connected layer to project ConvNet extracted features onto a latent
    space where the contrastive loss is applied. The positive pair for computing the
    contrastive loss consists of the unregistered moving and fixed image pair, while
    any other pair apart from the current image pair under registration is considered
    a negative pair. In an extension of their work, Liu et al. [[196](#bib.bib196)] proposed
    to compute the contrastive loss in a similar way, but between patches of the moving
    and fixed images. However, it is important to note that the positive pair used
    in these two methods contained structural dissimilarities as it was the unregistered
    image pair, as opposed to the registered images used in the methods mentioned
    earlier. The authors argued that this was because the image contents, including
    the number of brain structures, were consistent for brain registration. Nonetheless,
    further research is needed to fully uncover the potential of these methods.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 直到现在，基于对比学习的方法主要集中在多模态图像配准上。然而，刘等人[[194](#bib.bib194)]提出了在单模态脑MRI配准的网络结构中集成对比学习的方法。在他们的方法中，对移动图像和固定图像应用了两个相同权重的ConvNet编码器，每个编码器后面跟着一个全连接层，将ConvNet提取的特征投影到一个潜在空间，在该空间中应用对比损失。计算对比损失的正样本对由未配准的移动图像和固定图像对组成，而除了当前配准图像对之外的任何其他图像对被视为负样本对。在他们工作的扩展中，刘等人[[196](#bib.bib196)]提出了以类似的方式计算对比损失，但在移动图像和固定图像的补丁之间进行。然而，需要注意的是，这两种方法中使用的正样本对包含了结构上的不相似性，因为它们是未配准的图像对，而不是之前提到的方法中使用的已配准图像。作者认为这是因为脑注册中的图像内容，包括脑结构的数量，是一致的。然而，仍需进一步研究以充分揭示这些方法的潜力。
- en: 4.3 Transformers
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 Transformers
- en: One of the key factors in designing ConvNets is the size of the receptive fields.
    While incorporating consecutive convolutional layers and pooling operations can
    increase the theoretical receptive fields of ConvNets, its effective receptive
    fields are still limited [[207](#bib.bib207)]. This makes them less effective
    at capturing long-range spatial correspondence, which is important to image registration
    since it aims to identify the correspondence between different parts of the images.
    In contrast, Transformers are widely acknowledged for their superior ability to
    capture long-range dependencies and achieve exceptional performance when trained
    on large datasets [[189](#bib.bib189)]. Transformers differ from ConvNets in that
    they employ the self-attention mechanism, in which each local part of an image
    is compared in relation to the other parts, guiding the network on where to focus.
    Originally developed for natural language processing tasks [[322](#bib.bib322)],
    Transformers have recently become prevalent in various computer vision applications [[72](#bib.bib72),
    [200](#bib.bib200), [202](#bib.bib202), [35](#bib.bib35), [369](#bib.bib369),
    [71](#bib.bib71), [32](#bib.bib32)]. Inspired by their success, many Transformer-based
    models have been proposed and have demonstrated promising performance in medical
    imaging applications. For a comprehensive review of the current Transformer-based
    models in medical imaging, interested readers are directed to a review paper by Li
    et al. [[189](#bib.bib189)]. Despite their potential, Transformers have certain
    drawbacks, such as larger computational complexity and a lack of inductive bias
    when compared to ConvNets, hindering the training process. To address these shortcomings,
    Transformers are commonly used in conjunction with ConvNets in medical image registration
    applications. Chen et al. [[38](#bib.bib38)] were the first to utilize Transformers
    for registration-based tasks. They proposed ViT-V-Net, which employs a ConvNet
    for extracting high-level features, followed by a Vision Transformer (ViT) [[73](#bib.bib73)]
    and a ConvNet decoder to generate a dense displacement field. Subsequently, they
    proposed TransMorph [[37](#bib.bib37)], which employs a Swin Transformer [[200](#bib.bib200)]
    in the encoder, replacing the ConvNet feature extractor and ViT. TransMorph is
    capable of both affine registration and deformable registration. The study provided
    empirical evidence that Transformer-based models have larger effective receptive
    fields than baseline ConvNets. In inter-subject and atlas-to-subject brain MRI
    registration, as well as XCAT-to-CT abdomen registration applications, TransMorph
    achieved significantly improved registration performance when compared to top-performing
    traditional and ConvNet-based registration models. Zhang et al. [[374](#bib.bib374)] proposed
    DTN, which consists of two encoder branches with identical architecture. Each
    branch contains a ConvNet feature extractor and a ViT. In DTN, the moving and
    fixed images are first fed consecutively into one encoder branch, then concatenated
    and sent to the other branch. The encoder outputs are then concatenated and sent
    to a ConvNet decoder to produce a deformation field. Mok and Chung [[233](#bib.bib233)] introduced
    a Transformer encoder, C2FViT, specifically designed to tackle the affine registration
    problem. Their Transformer architecture was inspired by ViT, but with augmented
    patch embedding and feed-forward layers to introduce locality into the model.
    C2FViT adopts a coarse-to-fine strategy with an image pyramid for affine registration.
    The registration process is carried out in multiple stages of ViTs with identical
    architectures, each corresponding to a different resolution of the fixed and moving
    images. The affine parameters are estimated in each stage, and the moving image
    is affine-transformed using the parameters from the previous stage to refine the
    registration progressively. C2FViT was evaluated on several benchmark datasets
    and demonstrated superior performance compared to multiple ConvNet-based and traditional
    affine registration methods. Chen et al. [[42](#bib.bib42)] proposed a Deformer
    module, which leverages the attention mechanism on feature maps produced by a
    ConvNet encoder. The authors argued that the Deformer module facilitated the image-to-spatial
    transformation mapping process by estimating the displacement vector prediction
    as a weighted sum of multiple bases. Employing a coarse-to-fine strategy, the
    proposed model outperformed both the ConvNet and Transformer models in the comparative
    analysis. Song et al. [[305](#bib.bib305)] introduced Attention-Reg, a model that
    adopts cross-attention to correlate features extracted from multi-modal input
    images by a ConvNet encoder. To expedite the training process, they applied a
    contrastive pre-training strategy to the ConvNet feature extractor, allowing for
    the extraction of similar features from different modality images. The Dice loss
    was used as the multi-modal similarity measure, and they developed both rigid
    and deformable variations of the model. The results showed that Attention-Reg
    performed favorably against several learning-based rigid and deformable registration
    models. Similarly, Shi et al. [[291](#bib.bib291)] introduced XMorpher, a full
    Transformer architecture featuring dual parallel feature extractors that exchange
    information via a cross-attention mechanism. The cross-attention module developed
    in their study is based on a Swin Transformer, where attention is computed between
    base windows of one image and searching windows of another image with differing
    sizes. This cross-attention mechanism exhibited improved performance compared
    to self-attention-based Transformers and ConvNet models. Chen et al. [[40](#bib.bib40)] made
    further improvements to the cross-attention technique used in XMorpher. They proposed
    a novel deformable cross-attention module that enables tokens to be sampled from
    regions beyond the conventional rectangular window, while also reducing computational
    complexity. A lightweight ConvNet was introduced to deform the sampling window
    in a reference. The attention is then computed between the tokens sampled from
    the deformed window in the reference and those sampled from a rectangular window
    in a base. This enables tokens sampled from a larger reference region to guide
    the network on where to focus within each local window in the base. The proposed
    network includes two encoding paths. In one path, the moving and fixed images
    are used as the base and reference, respectively. In the other path, the roles
    of the base and reference are switched, with the moving image used as the reference
    and the fixed image used as the base. A ConvNet decoder then fuses the features
    extracted from the two encoders to generate a deformation field. Their method
    was evaluated on brain MRI registration tasks, and it performed favorably against
    self-attention, cross-attention, and ConvNet-based models. Liu et al. [[199](#bib.bib199)] proposed
    im2grid, a model that uses cross-attention to explicitly guide the neural network
    in comprehending the coordinate system for image registration, which is usually
    learned implicitly from data. Their approach uses ConvNet encoders to independently
    extract hierarchical features from the fixed and moving images. Subsequently,
    their proposed coordinate translator block computes a softmax score function by
    comparing the extracted fixed image feature at a voxel location with the features
    of the moving image within a search window. Spatial correspondence between the
    voxel location in the fixed and moving images is established by linearly combining
    the coordinates of all voxel locations weighted by the score function. Their approach
    is implemented as cross-attention with coordinates as one of the inputs. This
    model was evaluated on inter-patient brain MRI registration tasks using publicly
    available datasets and demonstrated superior performance compared to the comparative
    ConvNets and Transformer-based models.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 设计ConvNets的关键因素之一是感受野的大小。虽然通过加入连续的卷积层和池化操作可以增加ConvNets的理论感受野，但其有效感受野仍然有限[[207](#bib.bib207)]。这使得它们在捕捉长程空间对应关系方面不够有效，而这对于图像配准至关重要，因为它旨在识别图像不同部分之间的对应关系。相比之下，Transformers因其卓越的长程依赖捕捉能力而广受认可，并且在大型数据集上训练时表现出色[[189](#bib.bib189)]。Transformers与ConvNets的不同之处在于它们采用了自注意力机制，其中图像的每个局部部分与其他部分进行比较，从而指导网络关注重点。Transformers最初是为自然语言处理任务开发的[[322](#bib.bib322)]，但最近在各种计算机视觉应用中变得广泛应用[[72](#bib.bib72),
    [200](#bib.bib200), [202](#bib.bib202), [35](#bib.bib35), [369](#bib.bib369),
    [71](#bib.bib71), [32](#bib.bib32)]。受到其成功的启发，许多基于Transformers的模型被提出，并在医学成像应用中展示了良好的性能。有关当前基于Transformer的医学成像模型的全面综述，读者可参考Li等人撰写的综述论文[[189](#bib.bib189)]。尽管Transformers具有潜力，但与ConvNets相比，它们也有某些缺点，如计算复杂度较高和缺乏归纳偏差，这阻碍了训练过程。为了解决这些缺点，Transformers通常与ConvNets结合使用于医学图像配准应用中。Chen等人[[38](#bib.bib38)]率先将Transformers用于基于配准的任务。他们提出了ViT-V-Net，该模型采用ConvNet提取高层特征，然后使用Vision
    Transformer（ViT）[[73](#bib.bib73)]和ConvNet解码器生成密集的位移场。随后，他们提出了TransMorph[[37](#bib.bib37)]，该模型在编码器中采用了Swin
    Transformer[[200](#bib.bib200)]，替换了ConvNet特征提取器和ViT。TransMorph能够进行仿射配准和可变形配准。研究提供了实证证据，表明基于Transformer的模型比基线ConvNets具有更大的有效感受野。在被试间和图谱到被试脑MRI配准以及XCAT到CT腹部配准应用中，与顶级传统和ConvNet-based配准模型相比，TransMorph取得了显著改善的配准性能。Zhang等人[[374](#bib.bib374)]提出了DTN，该模型包括两个具有相同架构的编码器分支。每个分支包含一个ConvNet特征提取器和一个ViT。在DTN中，移动图像和固定图像首先依次输入到一个编码器分支中，然后连接并发送到另一个分支。编码器输出然后连接并发送到ConvNet解码器以生成变形场。Mok和Chung[[233](#bib.bib233)]引入了一个Transformer编码器C2FViT，专门设计用于解决仿射配准问题。他们的Transformer架构受ViT启发，但通过增强的补丁嵌入和前馈层将局部性引入模型。C2FViT采用了自粗到细的策略，使用图像金字塔进行仿射配准。配准过程在多个具有相同架构的ViT阶段中进行，每个阶段对应固定图像和移动图像的不同分辨率。在每个阶段中估计仿射参数，并使用前一阶段的参数对移动图像进行仿射变换，以逐步精炼配准。C2FViT在多个基准数据集上进行了评估，并在与多个ConvNet-based和传统仿射配准方法的比较中表现出色。Chen等人[[42](#bib.bib42)]提出了Deformer模块，该模块利用注意力机制在由ConvNet编码器生成的特征图上。作者认为，Deformer模块通过将位移向量预测估计为多个基的加权和，从而促进了图像到空间变换映射过程。采用自粗到细策略，所提模型在比较分析中优于ConvNet和Transformer模型。Song等人[[305](#bib.bib305)]介绍了Attention-Reg，一个采用交叉注意力来关联ConvNet编码器提取的多模态输入图像特征的模型。为了加快训练过程，他们对ConvNet特征提取器应用了对比预训练策略，从不同模态图像中提取相似特征。Dice损失被用作多模态相似性度量，他们开发了模型的刚性和可变形变体。结果表明，Attention-Reg在与多个学习基础的刚性和可变形配准模型的比较中表现良好。同样，Shi等人[[291](#bib.bib291)]介绍了XMorpher，这是一种全Transformer架构，具有双并行特征提取器，通过交叉注意力机制交换信息。他们研究中开发的交叉注意力模块基于Swin
    Transformer，其中计算了一个图像的基本窗口与另一个图像的搜索窗口之间的注意力，窗口大小不同。该交叉注意力机制在性能上优于基于自注意力的Transformers和ConvNet模型。Chen等人[[40](#bib.bib40)]进一步改进了XMorpher中使用的交叉注意力技术。他们提出了一种新型的可变形交叉注意力模块，允许从常规矩形窗口之外的区域采样标记，同时减少计算复杂性。引入了一个轻量级ConvNet来在参考中变形采样窗口。然后计算从参考中变形窗口采样的标记与从基准中的矩形窗口采样的标记之间的注意力。这使得从更大参考区域采样的标记能够指导网络在基准中的每个局部窗口中关注的位置。所提网络包括两个编码路径。在一个路径中，移动和固定图像分别用作基准和参考。在另一个路径中，基准和参考的角色交换，移动图像用作参考，固定图像用作基准。然后，ConvNet解码器融合从两个编码器提取的特征，以生成变形场。他们的方法在脑MRI配准任务中进行了评估，并在自注意力、交叉注意力和ConvNet-based模型的比较中表现良好。Liu等人[[199](#bib.bib199)]提出了im2grid，一个模型使用交叉注意力明确指导神经网络理解图像配准的坐标系统，这通常从数据中隐式学习。他们的方法使用ConvNet编码器独立提取固定和移动图像的层次特征。随后，他们提出的坐标转换块通过比较在体素位置提取的固定图像特征与移动图像内的搜索窗口中的特征，计算softmax分数函数。通过将所有体素位置的坐标线性组合，并由分数函数加权，建立了固定图像和移动图像中体素位置之间的空间对应关系。他们的方法实现为交叉注意力，其中坐标作为输入之一。该模型在使用公开数据集进行的患者间脑MRI配准任务中进行了评估，并在与比较的ConvNets和基于Transformer的模型的比较中表现优异。
- en: The mechanisms of Transformers have inspired various ConvNet designs in computer
    vision, leading to a debate on whether Transformers could replace ConvNets for
    image-related tasks [[189](#bib.bib189)]. ConvNet models such as ConvNeXt [[201](#bib.bib201)]
    and RepLKNet [[64](#bib.bib64)] have built upon Transformer concepts and demonstrated
    performance comparable to Transformers. Inspired by these models, Jia et al. [[160](#bib.bib160)] proposed
    a U-Net with increased kernel sizes to expand the effective receptive field of
    the U-Net. Their method compared favorable against several Transformer-based registration
    methods. Currently, ConvNets still possess inherent advantages over Transformers,
    such as their invariance to input image sizes and the incorporation of inductive
    bias due to the nature of the convolution operation. Therefore, there has been
    a growing interest in advancing ConvNets using Transformer concepts in computer
    vision. It is anticipated that further research in this area will lead to improved
    ConvNet architectures for medical image registration applications.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 的机制激发了计算机视觉领域各种卷积网络（ConvNet）设计的产生，这引发了关于 Transformer 是否能够取代卷积网络在图像相关任务中的争论 [[189](#bib.bib189)]。例如，ConvNeXt [[201](#bib.bib201)]
    和 RepLKNet [[64](#bib.bib64)] 等卷积网络模型基于 Transformer 的概念，并展示了与 Transformer 相当的性能。受到这些模型的启发，贾等人
    [[160](#bib.bib160)] 提出了一个增加了卷积核大小的 U-Net，以扩展 U-Net 的有效感受野。他们的方法在与几种基于 Transformer
    的配准方法比较时表现良好。目前，卷积网络仍然具有比 Transformer 更固有的优势，例如对输入图像尺寸的不变性和由于卷积操作的特性而引入的归纳偏置。因此，计算机视觉领域对利用
    Transformer 概念改进卷积网络的兴趣日益增长。预计这一领域的进一步研究将推动卷积网络在医学图像配准应用中的架构改进。
- en: 4.4 Diffusion Models
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 扩散模型
- en: In recent years, diffusion models [[301](#bib.bib301), [136](#bib.bib136)] have
    garnered significant research interest in computer vision. Initially designed
    for generative tasks, such as image synthesis, inpainting, and super-resolution,
    diffusion models have now been widely explored in various applications in the
    field of medical image analysis (see Kazerouni et al. [[168](#bib.bib168)] for
    a survey). In contrast to other generative models like GANs and VAEs, which are
    either confined to data with limited variability or generating low-quality samples [[136](#bib.bib136),
    [168](#bib.bib168)], diffusion models have no such restrictions, making them an
    attractive alternative. The goal of diffusion models is to use the known forward
    process of gradual diffusion of information caused by noise to learn the reverse
    process of recovery of information from noise. The forward process is similar
    to the behavior of particles in thermodynamics, where particles spread (*i.e.*,
    diffuse) from areas of high concentration to those of low concentration [[175](#bib.bib175),
    [301](#bib.bib301)]. The existing diffusion models use iterative steps of diffusion,
    which can include up to several thousand steps, to carry out the diffusion process.
    As a result, inference with these models, which requires the reverse diffusion
    process, is time-consuming. To date, only Kim et al. [[171](#bib.bib171)] have
    used a diffusion model in medical image registration. They proposed DiffuseMorph,
    which involves a diffusion network and a deformation network. The diffusion network
    learns a conditional score function (*i.e.*, the added noise), while the deformation
    network uses the latent feature in the reverse diffusion process to estimate the
    deformation field. The registration process of DiffuseMorph is a one-step procedure
    as the fixed image is the target image at the end of the reverse diffusion process (*i.e.*,
    $t=0$), and it is already given. As a result, there is no need for time-consuming
    reverse diffusion steps to synthesize a target image from the moving image. Furthermore,
    DiffuseMorph offers the added capability of producing continuous deformations
    through the interpolation of the learned latent space. The method demonstrated
    promising results when compared to several ConvNet-based methods on a publicly
    available Cardiac MRI dataset and a human facial expression dataset. However,
    since their forward process adopts the strategy of adding Gaussian noise to the
    fixed image, their diffusion network learns a conditional score function for the
    fixed images instead of the deformation between the fixed and moving images. Hence,
    additional exploration is imperative to gain a more comprehensive insight into
    the benefits of diffusion models.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，扩散模型 [[301](#bib.bib301), [136](#bib.bib136)] 在计算机视觉领域引起了显著的研究兴趣。最初设计用于生成任务，如图像合成、修补和超分辨率，扩散模型现在已在医学图像分析领域的各种应用中得到了广泛探索（参见
    Kazerouni 等人 [[168](#bib.bib168)] 的综述）。与 GANs 和 VAEs 等其他生成模型相比，这些模型要么局限于数据的变异性较小，要么生成低质量样本
    [[136](#bib.bib136), [168](#bib.bib168)]，扩散模型没有这些限制，使其成为一种有吸引力的替代选择。扩散模型的目标是利用已知的由噪声引起的信息逐渐扩散的正向过程来学习从噪声中恢复信息的反向过程。正向过程类似于热力学中粒子的行为，粒子从高浓度区域扩散到低浓度区域
    [[175](#bib.bib175), [301](#bib.bib301)]。现有的扩散模型使用多达数千步的扩散迭代步骤来进行扩散过程。因此，使用这些模型进行推理（需要反向扩散过程）是耗时的。迄今为止，只有
    Kim 等人 [[171](#bib.bib171)] 在医学图像配准中使用了扩散模型。他们提出了 DiffuseMorph，其中包括一个扩散网络和一个变形网络。扩散网络学习一个条件得分函数（*即*，添加的噪声），而变形网络在反向扩散过程中使用潜在特征来估计变形场。DiffuseMorph
    的配准过程是一个一步程序，因为固定图像是反向扩散过程结束时的目标图像（*即*，$t=0$），且已给出。因此，无需耗时的反向扩散步骤来从移动图像合成目标图像。此外，DiffuseMorph
    还提供了通过学习的潜在空间的插值生成连续变形的附加能力。该方法在与多个基于 ConvNet 的方法在公开的心脏 MRI 数据集和人脸表情数据集上的比较中表现出了良好的结果。然而，由于其正向过程采用了向固定图像添加高斯噪声的策略，因此其扩散网络学习了固定图像的条件得分函数，而不是固定图像与移动图像之间的变形。因此，需要进一步探索以获得对扩散模型的更多全面的理解。
- en: 4.5 Neural ODEs
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 神经常微分方程
- en: 'Inspired by Euler’s method for discretizing the derivative of ordinary differential
    equations (ODEs) into discrete time step updates, Chen et al. [[44](#bib.bib44)]
    proposed a new family of DNN models called Neural ODEs. In their method, DNN elements
    that progressively update their input (*e.g.*, residual connections, or recurrent
    networks) are interpreted as updates of time steps in Euler’s method. Consequently,
    a chain of these elements in a neural network is essentially a solution of the
    ODE with Euler’s method of the form:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 受欧拉法将常微分方程（ODEs）的导数离散化为离散时间步更新的启发，陈等人[[44](#bib.bib44)]提出了一类新的DNN模型，称为Neural
    ODEs。在他们的方法中，逐步更新其输入的DNN元素 (*例如*，残差连接或递归网络) 被解释为欧拉法中的时间步更新。因此，神经网络中的这些元素链本质上是ODE的欧拉法形式的解：
- en: '|  | $\frac{dh(t)}{dt}=f_{\theta}(h(t),t),$ |  | (6) |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{dh(t)}{dt}=f_{\theta}(h(t),t),$ |  | (6) |'
- en: and
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '|  | $h(t+1)=h(t)+f_{\theta}(h(t),t),$ |  | (7) |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '|  | $h(t+1)=h(t)+f_{\theta}(h(t),t),$ |  | (7) |'
- en: where $h(t)$ represents the $t$-th element, which may be a residual block or
    a network. The final output at $t=T$ can be computed by integrating $f$ over the
    time interval $[0,T]$, which is evaluated by a numerical solver taking many small
    time steps, thus approximating a neural network with infinite depth.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$h(t)$表示第$t$个元素，可以是一个残差块或网络。最终输出在$t=T$时可以通过对时间区间$[0,T]$上的$f$进行积分来计算，这个积分由数值求解器进行，数值求解器采取许多小的时间步，从而近似一个无限深度的神经网络。
- en: The first application of the NeuralODE framework for medical image registration
    was introduced by Xu et al. [[352](#bib.bib352)]. They proposed MS-ODENet, which
    parameterizes $h$ at the final time point $T$ (*i.e.*, $h(T)$) as the deformation
    field that warps the moving image to the fixed image, and $\frac{dh(t)}{dt}$ as
    the small increment of deformation produced by a network at state $t$ from the
    preceding state $h(t-1)$. To alleviate the computational burden of numerical solvers
    and accelerate the runtime, they proposed solving ODEs at different resolutions
    in a coarse-to-fine manner. However, the loss function, consisting of a similarity
    measure and a deformation regularizer, is applied only to the final deformation
    field $h(T)$. Similarly, Wu et al. [[347](#bib.bib347)] proposed NODEO, which
    formulated $h(t)$ as the voxel movement at time $t$ and the trajectory of the
    movement as the solution to the ODE. Drawing inspiration from dynamical systems,
    they expressed the ODE as $\frac{dh(t)}{dt}=\mathcal{K}v_{\theta}(h(t),t)$, where
    $\mathcal{K}$ is a Gaussian smoothing kernel, $v_{\theta}$ denotes the velocity
    of the voxel movement produced by a neural network, and the initial condition
    $h(0)$ is an identity. It is noteworthy that this formulation bears similarities
    to LDDMM [[18](#bib.bib18)], an influential optimization-based method that considers
    image registration as an energy-minimizing flow of particles over time. In contrast
    to MS-ODENet [[352](#bib.bib352)], which applies loss solely to the deformation
    at $t=T$, NODEO optimizes image similarity at each $t$ while minimizing the energy
    of the flow and encouraging spatial smoothness and regularity of the velocity
    fields through the Gaussian kernel, diffusion regularizer, and Jacobian determinant
    loss. The authors compared NODEO to various widely-used traditional methods and
    a ConvNet model on brain MRI registration tasks. It demonstrated superior registration
    performance measured by Dice while attaining diffeomorphic registration.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 神经ODE框架在医学图像配准中的首次应用由徐等人提出[[352](#bib.bib352)]。他们提出了MS-ODENet，该方法将最终时间点$T$处的$h$
    (*即*，$h(T)$) 参数化为将移动图像变形到固定图像的变形场，并将$\frac{dh(t)}{dt}$ 视为在状态$t$下由网络从前一个状态$h(t-1)$产生的小变形增量。为了减轻数值求解器的计算负担并加速运行时间，他们提出了以粗到细的方式在不同分辨率下求解ODE。然而，损失函数仅应用于最终变形场$h(T)$，该损失函数由相似度度量和变形正则化器组成。类似地，吴等人[[347](#bib.bib347)]提出了NODEO，将$h(t)$公式化为时间$t$处的体素移动，并将移动轨迹表示为ODE的解。受到动态系统的启发，他们将ODE表达为$\frac{dh(t)}{dt}=\mathcal{K}v_{\theta}(h(t),t)$，其中$\mathcal{K}$是高斯平滑核，$v_{\theta}$表示由神经网络产生的体素移动速度，初始条件$h(0)$为单位矩阵。值得注意的是，这种公式化与LDDMM
    [[18](#bib.bib18)]有相似之处，后者是一种有影响力的基于优化的方法，将图像配准视为随时间变化的粒子能量最小化流。与MS-ODENet [[352](#bib.bib352)]仅在$t=T$时应用损失不同，NODEO在每个$t$时优化图像相似度，同时最小化流的能量，并通过高斯核、扩散正则化器和雅可比行列式损失鼓励速度场的空间平滑性和规律性。作者将NODEO与各种广泛使用的传统方法以及用于脑MRI配准任务的ConvNet模型进行了比较。结果表明，NODEO在Dice测量中表现出优越的配准性能，同时实现了同胚配准。
- en: 4.6 Implicit Neural Representations
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 隐式神经表示
- en: 'Image registration can be formulated as an implicit problem of the form:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图像配准可以被表述为一种隐式问题，形式为：
- en: '|  | $\mathcal{C}(\pmb{x},\psi)=0,\ \ \psi:\pmb{x}\rightarrow\psi(\pmb{x}),$
    |  | (8) |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{C}(\pmb{x},\psi)=0,\ \ \psi:\pmb{x}\rightarrow\psi(\pmb{x}),$
    |  | (8) |'
- en: 'where $\pmb{x}\in\mathbb{R}^{2,3}$ is the 2D or 3D spatial coordinate (*i.e.*,
    from an integer grid), and $\psi$ represents a neural network that maps each coordinate
    $\pmb{x}$ to a value of interest, subject to the constraint $\mathcal{C}$. In
    the context of image registration, $\psi$ typically maps the coordinate $\pmb{x}$
    to its deformation $\psi(\pmb{x})$, while $\mathcal{C}$ comprises a similarity
    measure and a deformation regularizer. The neural network $\psi$ can be considered
    as an implicit function of $\pmb{x}$, defined by the relation modeled by $\mathcal{C}$
    (Eqn. [8](#S4.E8 "In 4.6 Implicit Neural Representations ‣ 4 Network Architectures
    ‣ A survey on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond")). This concept is commonly referred to as implicit
    neural representations in computer vision [[299](#bib.bib299), [225](#bib.bib225),
    [240](#bib.bib240), [227](#bib.bib227)]. Although $\pmb{x}$’s used during training
    are discrete, the implicit function $\psi(\pmb{x})$ parameterized by a neural
    network is a continuous and differentiable function. As a result, implicit neural
    representations provide a more compact representation of a continuous function
    and facilitate smooth manipulation of that function.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\pmb{x}\in\mathbb{R}^{2,3}$ 是 2D 或 3D 空间坐标（*即*，来自整数网格），而 $\psi$ 代表一个神经网络，该网络将每个坐标
    $\pmb{x}$ 映射到一个感兴趣的值，受制于约束 $\mathcal{C}$。在图像配准的背景下，$\psi$ 通常将坐标 $\pmb{x}$ 映射到其变形
    $\psi(\pmb{x})$，而 $\mathcal{C}$ 包括相似性度量和变形正则化项。神经网络 $\psi$ 可以被视为 $\pmb{x}$ 的一个隐式函数，由
    $\mathcal{C}$ 模拟的关系定义（参见 Eqn. [8](#S4.E8 "在 4.6 隐式神经表示 ‣ 4 网络架构 ‣ 深度学习在医学图像配准中的新技术、不确定性、评估指标等的综述")）。这个概念在计算机视觉中通常被称为隐式神经表示
    [[299](#bib.bib299), [225](#bib.bib225), [240](#bib.bib240), [227](#bib.bib227)]。尽管训练过程中使用的
    $\pmb{x}$ 是离散的，但由神经网络参数化的隐式函数 $\psi(\pmb{x})$ 是一个连续且可微的函数。因此，隐式神经表示提供了一个更紧凑的连续函数表示，并促进了该函数的平滑操作。
- en: 'Han et al. [[115](#bib.bib115)] proposed to parameterize a continuous deformation
    field using a multi-layer perceptron (MLP) introduced in [[299](#bib.bib299)],
    given an integer grid representing the spatial coordinates of the voxels. The
    MLP thus serves as the implicit function of the integer grid. Since the MLP is
    not conditioned on the images and the only input is the coordinates that are deterministic
    for all images of the same resolution, optimization of the MLP is carried out
    iteratively and pair-wise for each image pair (similar to how the traditional
    registration methods are performed). To further improve the registration performance,
    the authors proposed a cascade framework that combines the benefits of learning-based
    registration DNNs with the optimization-based implicit neural representations
    provided by the MLP. Within this framework, the learning-based DNN predicts an
    initial deformation field, while the MLP produces the residual deformation that
    refines the initial deformation field, leading to an enhanced overall registration
    performance. However, the proposed method shares the same limitation as traditional
    methods in that the optimization is done pair-wise without learning from a dataset.
    Therefore, it cannot benefit from the supervision provided by anatomical label
    maps if these maps are not available during inference. Meanwhile, Sun et al. [[310](#bib.bib310)] applied
    implicit neural representations to a task of organ shape registration. Their approach
    was based on the idea of DeepSDF [[251](#bib.bib251)], where an auto-decoder maps
    a latent code representing a unique organ shape and the 3D coordinates of a sampled
    point to a signed distance function (SDF). The value of an SDF determines whether
    the point lies inside ($<0$), outside ($>0$), or on the surface ($=0$) of the
    shape, consequently providing an implicit description of the organ shapes. The
    resulting SDF is a continuous function, and the auto-decoder serves as the implicit
    neural representation of the discrete coordinates. To register points from different
    organ shapes, the authors modeled the trajectory of the point movement in space
    as the solution to an ODE, akin to the formulation proposed in NODEO [[347](#bib.bib347)].
    In this formulation, the time derivative corresponds to the velocity of the point
    movement at time $t$. The authors solved this ODE using a NeuralODE solver (as
    briefly discussed in section [4.5](#S4.SS5 "4.5 Neural ODEs ‣ 4 Network Architectures
    ‣ A survey on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond")), resulting in a diffeomorphic mapping between
    shapes.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 'Han等人[[115](#bib.bib115)]提出了利用多层感知器（MLP）对连续变形场进行参数化的方法，该MLP在[[299](#bib.bib299)]中被介绍，给定一个表示体素空间坐标的整数网格。这样，MLP充当了整数网格的隐式函数。由于MLP不以图像为条件，唯一输入的是对所有相同分辨率图像的确定性坐标，因此MLP的优化是迭代进行的，并且是逐对进行的（类似于传统配准方法的操作方式）。为了进一步提高配准性能，作者提出了一种级联框架，将基于学习的配准DNN的优点与MLP提供的基于优化的隐式神经表示相结合。在这个框架内，基于学习的DNN预测初始变形场，而MLP生成残余变形，进一步优化初始变形场，从而提升整体配准性能。然而，该方法与传统方法一样存在相同的限制，即优化是逐对进行的，而没有从数据集中学习。因此，如果在推理过程中没有解剖标签图，这种方法无法受益于提供的监督。与此同时，Sun等人[[310](#bib.bib310)]将隐式神经表示应用于器官形状配准任务。他们的方法基于DeepSDF的思想[[251](#bib.bib251)]，其中一个自编码器将表示唯一器官形状的潜在代码和一个采样点的3D坐标映射到带符号距离函数（SDF）。SDF的值决定了点是否位于形状内部（$<0$）、外部（$>0$）或表面（$=0$），从而提供了器官形状的隐式描述。结果SDF是一个连续函数，自编码器充当离散坐标的隐式神经表示。为了配准不同器官形状的点，作者将点在空间中的运动轨迹建模为一个ODE的解，类似于NODEO[[347](#bib.bib347)]中提出的公式。在这个公式中，时间导数对应于点在时间$t$的运动速度。作者使用NeuralODE求解器解决了这个ODE（在[4.5](#S4.SS5
    "4.5 Neural ODEs ‣ 4 Network Architectures ‣ A survey on deep learning in medical
    image registration: new technologies, uncertainty, evaluation metrics, and beyond")中简要讨论），得到了形状之间的差分同胚映射。'
- en: 4.7 Hyperparameter Conditioning
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7 超参数条件化
- en: Inspired by HyperNetworks [[113](#bib.bib113)] and Hyperparameter Optimization [[92](#bib.bib92)],
    recent research has introduced methods that integrate hyperparameters directly
    into the architecture of the registration DNNs. This allows for the capturing
    of a wide range of hyperparameters within a single training process, consequently
    speeding up the hyperparameter tuning process without requiring multiple networks
    to be trained from scratch for each hyperparameter value. In the training process
    of these methods, a distinct hyperparameter value is randomly selected, and the
    network generates a deformation field associated with that value. Subsequently,
    the registration loss is calculated using the same hyperparameter value, which
    is then used to update the network parameters. The hyperparameter being conditioned
    typically relates to the weight of the deformation regularizer, which affects
    the smoothness of the deformation produced by the network.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 受 HyperNetworks [[113](#bib.bib113)] 和超参数优化 [[92](#bib.bib92)] 的启发，近期研究引入了将超参数直接集成到配准
    DNNs 架构中的方法。这允许在单次训练过程中捕获广泛的超参数，从而加速超参数调整过程，而不需要为每个超参数值从头训练多个网络。在这些方法的训练过程中，随机选择一个特定的超参数值，网络生成与该值相关的变形场。随后，使用相同的超参数值计算配准损失，然后用于更新网络参数。被调节的超参数通常与变形正则化器的权重相关，这影响网络生成的变形的平滑度。
- en: 'Hoopes et al. [[142](#bib.bib142)] introduced HyperMorph, which is based on
    the concept of HyperNetworks [[113](#bib.bib113)]. HyperMorph comprises two ConvNets:
    a hypernetwork and a U-Net-like registration network (i.e.VoxelMorph [[14](#bib.bib14)]).
    The hypernetwork estimates the weights of the U-Net based on the provided hyperparameter
    value for the diffusion regularizer, while the U-Net generates a deformation field
    to warp the moving image. In each training step, the hyperparameter value is randomly
    sampled from a uniform distribution, and the loss is computed using the same sampled
    value. After training, the best-performing hyperparameter value is acquired using
    gradient descent. In this process, the network weights are fixed, and an optimizer
    iteratively updates the hyperparameter based on a target objective function (commonly
    the Dice score) applied to a validation dataset. In a parallel work, Mok and Chung
    [[232](#bib.bib232)] proposed conditioning the regularization hyperparameter through
    conditional instance normalization [[76](#bib.bib76)]. In this approach, the feature
    map statistics within the regularization network are normalized and shifted according
    to two affine parameters. These affine parameters are generated by a lightweight
    mapping network, which takes the sampled hyperparameter value as input. Later,
    Chen et al. [[41](#bib.bib41)] expanded the conditional instance normalization
    to a conditional layer normalization for application in Transformer-based registration
    models. The training processes in both [[232](#bib.bib232), [41](#bib.bib41)]
    are similar to the one used in HyperMorph, where the hyperparameter value is sampled
    from a uniform distribution and then employed for loss computation. However, it
    is worth noting that Mok and Chung [[232](#bib.bib232)] and Chen et al. [[41](#bib.bib41)]
    obtain the best-performing hyperparameter value through a grid search, whereas
    HyperMorph acquires it via gradient descent.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Hoopes 等人 [[142](#bib.bib142)] 引入了 HyperMorph，该方法基于 HyperNetworks 的概念 [[113](#bib.bib113)]。HyperMorph
    包含两个 ConvNet：一个超网络和一个类似于 U-Net 的配准网络（即 VoxelMorph [[14](#bib.bib14)]）。超网络根据提供的扩散正则化器的超参数值估计
    U-Net 的权重，而 U-Net 生成一个变形场来扭曲移动图像。在每个训练步骤中，超参数值是从均匀分布中随机采样的，损失使用相同的采样值进行计算。训练后，通过梯度下降获取最佳性能的超参数值。在此过程中，网络权重保持固定，优化器根据应用于验证数据集的目标函数（通常是
    Dice 分数）迭代更新超参数。相关工作中，Mok 和 Chung [[232](#bib.bib232)] 提出了通过条件实例归一化 [[76](#bib.bib76)]
    来调节正则化超参数。在这种方法中，正则化网络中的特征图统计数据根据两个仿射参数进行归一化和偏移。这些仿射参数由一个轻量级映射网络生成，该网络以采样的超参数值作为输入。后来，Chen
    等人 [[41](#bib.bib41)] 将条件实例归一化扩展到条件层归一化，以应用于基于 Transformer 的配准模型。[[232](#bib.bib232)]
    和 [[41](#bib.bib41)] 的训练过程类似于 HyperMorph，其中超参数值从均匀分布中采样，然后用于损失计算。然而，值得注意的是，Mok
    和 Chung [[232](#bib.bib232)] 以及 Chen 等人 [[41](#bib.bib41)] 通过网格搜索获得最佳性能的超参数值，而
    HyperMorph 则通过梯度下降获得。
- en: 4.8 Discontinuity Permitting Network
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.8 允许不连续性的网络
- en: 'To facilitate a spatially discontinuous deformation, which is important for
    many registration applications as delineated in Section [3](#S3 "3 Loss Functions
    ‣ A survey on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond"), Chen et al. [[47](#bib.bib47)] proposed an alternative
    approach. Rather than employing a discontinuity-permitted deformation regularization
    (as briefly mentioned in Section [3](#S3 "3 Loss Functions ‣ A survey on deep
    learning in medical image registration: new technologies, uncertainty, evaluation
    metrics, and beyond")), the authors proposed using anatomical label maps to segregate
    the moving and fixed images into different regions of interest and subsequently
    generate deformation fields for each region using multiple registration networks.
    These deformation fields are then combined to yield a final deformation via addition.
    However, this method has an immediate drawback in necessitating the anatomical
    label maps throughout both the training and inference stages. When label maps
    are not available, this method becomes infeasible.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '为了实现空间上不连续的变形，这对于许多配准应用非常重要，如第[3](#S3 "3 Loss Functions ‣ A survey on deep
    learning in medical image registration: new technologies, uncertainty, evaluation
    metrics, and beyond")节中所述，Chen等人[[47](#bib.bib47)]提出了一种替代方法。与第[3](#S3 "3 Loss
    Functions ‣ A survey on deep learning in medical image registration: new technologies,
    uncertainty, evaluation metrics, and beyond")节中简要提到的允许不连续变形的正则化不同，作者提出使用解剖标签图将移动图像和固定图像分隔成不同的感兴趣区域，并随后为每个区域生成变形场，这些变形场通过多个配准网络生成。然后将这些变形场结合起来，通过加法得到最终的变形。然而，该方法的一个直接缺点是需要在训练和推断阶段都使用解剖标签图。当标签图不可用时，该方法就变得不可行。'
- en: 4.9 Correlation Layer
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.9 相关性层
- en: 'Optical flow is the name given by the computer vision community to image registration.
    In learning-based optical flow, it is common to employ a correlation layer [[74](#bib.bib74)]
    to aid neural networks in pinpointing explicit correspondences between points
    in images. This involves computing the correlation between the neighboring features
    of a spatial location in the moving image and the neighboring features of a range
    of spatial locations in the fixed image. The correlation is computed between two
    feature patches centered at $\pmb{x}_{m}$ and $\pmb{x}_{f}$ in the moving and
    fixed images, respectively, using the following equation:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 光流是计算机视觉社区对图像配准的称谓。在基于学习的光流中，通常会使用相关性层[[74](#bib.bib74)]来帮助神经网络准确确定图像中点之间的对应关系。这涉及计算移动图像中空间位置的邻近特征与固定图像中一系列空间位置的邻近特征之间的相关性。相关性是通过以下方程计算的，涉及在移动图像和固定图像中分别以
    $\pmb{x}_{m}$ 和 $\pmb{x}_{f}$ 为中心的两个特征块之间的相关性：
- en: '|  | $c(\pmb{x}_{m},\pmb{x}_{f})=\sum_{\pmb{o}\in[-k,k]}\langle F_{m}(\pmb{x}_{m}+\pmb{o}),F_{f}(\pmb{x}_{f}+\pmb{o})\rangle,$
    |  | (9) |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|  | $c(\pmb{x}_{m},\pmb{x}_{f})=\sum_{\pmb{o}\in[-k,k]}\langle F_{m}(\pmb{x}_{m}+\pmb{o}),F_{f}(\pmb{x}_{f}+\pmb{o})\rangle,$
    |  | (9) |'
- en: where $F_{m}$ and $F_{f}$ denote the feature patches of the moving and fixed
    images, respectively, and $k$ defines the patch size. The selection of locations
    $\pmb{x}_{m}$ and $\pmb{x}_{f}$ is based on a maximum displacement $d$, meaning
    that for each $\pmb{x}_{m}$, the range of $\pmb{x}_{f}$ is limited to the locations
    that are at most $d$ distance away. The output of the correlation layer is a set
    of correlation values that represent the correlation between one feature patch
    in the moving image and another feature patch in the fixed image. The output has
    a size of $H\times W\times D\times d$, where $H\times W\times D$ represents the
    size of the feature maps.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $F_{m}$ 和 $F_{f}$ 分别表示移动图像和固定图像的特征块，而 $k$ 定义了块的大小。位置 $\pmb{x}_{m}$ 和 $\pmb{x}_{f}$
    的选择基于最大位移 $d$，这意味着对于每个 $\pmb{x}_{m}$，$\pmb{x}_{f}$ 的范围仅限于距离最多为 $d$ 的位置。相关性层的输出是一组相关值，表示移动图像中一个特征块与固定图像中另一个特征块之间的相关性。输出的大小为
    $H\times W\times D\times d$，其中 $H\times W\times D$ 代表特征图的大小。
- en: 'Although the concept of directing networks with explicit correspondences between
    voxels or patches has been employed in computer vision since 2015, it was only
    recently embraced in medical image registration. This delay can be attributed
    to the potential computational challenges introduced by Eqn. [9](#S4.E9 "In 4.9
    Correlation Layer ‣ 4 Network Architectures ‣ A survey on deep learning in medical
    image registration: new technologies, uncertainty, evaluation metrics, and beyond").
    Since medical images are typically volumetric, the search space for each voxel
    location would be in a 3D volume, quickly becoming unmanageable as the search
    distance $d$ grows. [[124](#bib.bib124)] was the first to implement a correlation
    layer in their network design by introducing the PDD-net. Instead of calculating
    the scalar product between two features as done in Eqn. [9](#S4.E9 "In 4.9 Correlation
    Layer ‣ 4 Network Architectures ‣ A survey on deep learning in medical image registration:
    new technologies, uncertainty, evaluation metrics, and beyond"), PDD-net computes
    the correlation as the mean squared error between feature patches centered at
    each control point in the moving and fixed images:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管自2015年以来，计算机视觉中已经采用了带有体素或补丁之间显式对应关系的网络结构，但这一方法直到最近才在医学图像配准中被采纳。这一延迟可以归因于由公式[9](#S4.E9
    "In 4.9 Correlation Layer ‣ 4 Network Architectures ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond")引入的潜在计算挑战。由于医学图像通常是体积数据，因此每个体素位置的搜索空间会在一个3D体积中，随着搜索距离$d$的增长，迅速变得难以管理。[[124](#bib.bib124)]是第一个通过引入PDD-net在其网络设计中实现相关层的研究者。PDD-net并没有像公式[9](#S4.E9
    "In 4.9 Correlation Layer ‣ 4 Network Architectures ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond")中那样计算两个特征之间的标量积，而是将相关性计算为移动图像和固定图像中每个控制点处的特征补丁之间的均方误差：'
- en: '|  | $c(\pmb{x}_{m},\pmb{x}_{f})=\sum_{\pmb{o}\in[-k,k]}\&#124;F_{m}(\pmb{x}_{m}+\pmb{o})-F_{f}(\pmb{x}_{f}+\pmb{o})\&#124;^{2}.$
    |  | (10) |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '|  | $c(\pmb{x}_{m},\pmb{x}_{f})=\sum_{\pmb{o}\in[-k,k]}\&#124;F_{m}(\pmb{x}_{m}+\pmb{o})-F_{f}(\pmb{x}_{f}+\pmb{o})\&#124;^{2}.$
    |  | (10) |'
- en: 'Moreover, in their correlation layer, the search distance is represented by
    a 3D matrix, $\pmb{d}^{3}$, with each element in the vector, $\pmb{d}$, defining
    a discrete displacement distance from the current center of the feature patch.
    This correlation layer produces a 6D matrix, where the first three dimensions
    outline the shape of the feature maps, and the final three dimensions describe
    the shape of the search space. Due to the sparsity of the control points in comparison
    to the image size, the computational burden of this correlation layer remains
    relatively low. The correlation layer is applied to features independently extracted
    from the moving and fixed images using a ConvNet that incorporated deformable
    convolutional layers as introduced in Heinrich et al. [[130](#bib.bib130)]. Subsequently,
    min-convolutions and mean-field inference are employed to spatially smooth the
    dissimilarities produced by the correlation layer. A softmax operation is then
    applied to the 6D matrix, converting the dissimilarities into pseudo-probabilities.
    The displacement field is subsequently generated by multiplying the probabilities
    with the displacement distance in $\pmb{d}^{3}$, resulting in a weighted average
    of these probabilistic estimates for the 3D displacement field. The deformation
    field is then trilinearly interpolated to align with the image resolution. Heinrich
    and Hansen [[126](#bib.bib126)] later extended this approach by proposing a 2.5D
    approximation of the quantized 3D displacement, significantly reducing the memory
    burden of the original Pdd-net. Instead of creating a 6D dissimilarity matrix,
    they generated three 5D matrices (i.e., the 2.5D dissimilarity matrices), with
    each matrix representing the dissimilarities computed for two out of the three
    dimensions. The 2.5D probabilities produced at the end of the network are interpolated
    to 3D using B-splines. To minimize the error during the conversion from 2.5D to
    3D, a two-step instance normalization is applied for each pair of test scans using
    gradient descent. More recently, Heinrich and Hansen [[127](#bib.bib127)] further
    expanded the concept of probabilistic displacement and incorporated keypoint supervision
    into VoxelMorph [[14](#bib.bib14)] through the introduction of VoxelMorph++. They
    advanced VoxelMorph in two respects: probabilistic displacement via heatmap prediction
    and multi-channel instance optimization using one-hot embeddings of the anatomical
    label maps generated by a segmentation network. In their model, high-level features
    are initially extracted from the VoxelMorph decoder, and feature vectors are then
    sampled at given keypoint locations. These feature vectors are converted into
    larger heatmap patches through a convolution block followed by a softmax operation.
    Consequently, each heatmap represents the probabilistic displacements of the corresponding
    keypoint. The final displacement field is generated as the sum of the displacements
    weighted by the heatmap. During the testing phase for each image pair, an instance
    optimization strategy [[293](#bib.bib293)] refines the displacement field using
    the supervision provided by the anatomical labels generated from a segmentation
    network. The methods discussed in this subsection were evaluated on abdomen and
    lung CT datasets, where large deformations are necessary for accurate registration.
    The architectures proposed in these methods proved to be efficient and demonstrated
    superior performance compared to traditional methods and learning-based networks
    that only generate dense displacement fields.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在它们的相关层中，搜索距离由一个3D矩阵$\pmb{d}^{3}$表示，向量$\pmb{d}$中的每个元素定义了从当前特征补丁中心的离散位移距离。这个相关层生成一个6D矩阵，其中前三维描绘特征图的形状，最后三维描述搜索空间的形状。由于控制点的稀疏性与图像大小相比，该相关层的计算负担相对较低。该相关层独立应用于从移动图像和固定图像中提取的特征，使用了包含可变形卷积层的ConvNet，如Heinrich等人所述[[130](#bib.bib130)]。随后，使用最小卷积和均场推理来空间平滑相关层产生的差异。接着，对6D矩阵应用softmax操作，将差异转换为伪概率。然后，通过将这些概率与$\pmb{d}^{3}$中的位移距离相乘，生成位移场，从而得到3D位移场的加权平均。这一变形场随后通过三线性插值对齐到图像分辨率。Heinrich和Hansen
    [[126](#bib.bib126)] 后来通过提出量化3D位移的2.5D近似来扩展这种方法，显著减少了原始Pdd-net的内存负担。他们没有创建6D差异矩阵，而是生成了三个5D矩阵（即2.5D差异矩阵），每个矩阵表示在三个维度中的两个维度的差异。网络末端生成的2.5D概率通过B样条插值到3D。为了最小化从2.5D到3D转换过程中的误差，应用了逐步实例归一化，并使用梯度下降方法对每对测试扫描进行归一化。最近，Heinrich和Hansen
    [[127](#bib.bib127)] 进一步扩展了概率位移的概念，并将关键点监督引入VoxelMorph [[14](#bib.bib14)]，通过引入VoxelMorph++。他们在两个方面推进了VoxelMorph：通过热图预测实现概率位移，以及使用由分割网络生成的解剖标签图的one-hot嵌入进行多通道实例优化。在他们的模型中，高层特征最初从VoxelMorph解码器中提取，然后在给定的关键点位置对特征向量进行采样。这些特征向量通过卷积块和softmax操作转换成较大的热图补丁。因此，每个热图代表了相应关键点的概率位移。最终的位移场作为热图加权位移的总和生成。在每对图像的测试阶段，实例优化策略[[293](#bib.bib293)]
    使用分割网络生成的解剖标签提供的监督来优化位移场。本节讨论的方法在腹部和肺部CT数据集上进行了评估，在这些数据集中，大变形对于准确配准是必要的。这些方法中提出的架构被证明是高效的，并且在性能上优于传统方法和仅生成稠密位移场的学习网络。
- en: 4.10 Progressive and Pyramid Registration
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.10 渐进式和金字塔配准
- en: Recent research has also demonstrated that employing a network to progressively
    warp a moving image towards a fixed image, or performing registration through
    a multi-scale image pyramid employing a coarse-to-fine technique, may significantly
    improve registration performance. Zhao et al. [[377](#bib.bib377)] introduced
    the VTN, which leverages cascade registration networks to align moving images
    with fixed images. Drawing inspiration from FlowNet2.0 [[153](#bib.bib153)], each
    subnetwork is responsible for aligning the current moving image with the fixed
    image, with the resulting warped image sent into the subsequent subnetwork as
    the new moving image. The final deformation field is the composition of the intermediate
    deformation fields produced by the subnetworks. This approach has been shown effective
    in handling large displacements. In a similar fashion, Chen et al. [[36](#bib.bib36)] proposed
    a method for progressive image alignment within a single network. Their method
    employs multiple convolution blocks in the decoding stage, each responsible for
    aligning the current moving image to the fixed image.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究还表明，采用网络逐步将移动图像扭曲到固定图像，或通过使用从粗到细的多尺度图像金字塔进行配准，可能会显著提高配准性能。赵等人[[377](#bib.bib377)]引入了VTN，这种方法利用级联配准网络将移动图像与固定图像对齐。受到FlowNet2.0[[153](#bib.bib153)]的启发，每个子网络负责将当前的移动图像与固定图像对齐，并将结果扭曲后的图像作为新的移动图像传递给下一个子网络。最终的变形场是由子网络生成的中间变形场的组合。这种方法已被证明在处理大位移时有效。类似地，陈等人[[36](#bib.bib36)]提出了一种在单个网络中进行渐进图像对齐的方法。他们的方法在解码阶段使用了多个卷积块，每个卷积块负责将当前的移动图像对齐到固定图像上。
- en: Concurrently, there have been efforts to apply progressive registration using
    a multi-scale image pyramid approach. Given the widespread adoption of hourglass-shaped
    network architectures in image registration, convolution blocks within the decoder
    generate deformation fields at multiple resolutions in a coarse-to-fine manner.
    These deformation fields at different resolutions are subsequently upsampled and
    composited to form the final deformation field. Notable methods that adopt this
    scheme include [[163](#bib.bib163), [167](#bib.bib167), [199](#bib.bib199), [209](#bib.bib209)].
    In addition to network architecture, the coarse-to-fine training scheme has also
    been adopted in learning-based image registration. Taking inspiration from conventional
    registration methods that often employ multiple stages with varying resolutions,
    De Vos et al. [[59](#bib.bib59)] pioneered a multi-scale training strategy for
    deformable image registration. Their approach involves sequentially training the
    ConvNet in each stage for a specific image resolution by optimizing the image
    similarity measure. Notably, a B-spline framework is adopted thus alleviating
    the need for a deformation regularizer. During training, the weights of the preceding
    ConvNets are held fixed, and after training, the registration is performed through
    a single pass of input images to the multi-stage ConvNets. Eppenhof et al. [[80](#bib.bib80)] proposed
    a novel progressive and multi-scale training scheme for learning-based image registration.
    Instead of training a large network on the registration task all at once, they
    first train smaller versions of the network on lower-resolution images. The resolution
    of the training images is then gradually increased, and additional convolutional
    layers are added to increase the network size. Similarly, Mok and Chung [[230](#bib.bib230)] proposed
    LapIRN, which adopts a similar pyramid training scheme. However, unlike the previous
    training approach, which progressively increases the image resolution and network
    size of the same network, LapIRN employs three different networks, each producing
    a deformation field for a specific resolution. Each network is equipped with a
    skip connection that propagates feature embeddings from a lower-resolution network
    to a higher-resolution network. The networks are trained in a coarse-to-fine manner,
    with each network producing a deformation field that refines the upsampled deformation
    field from the previous resolution. However, using multiple networks to generate
    a pyramid of deformation fields can be computationally inefficient and increase
    the network size, which can hinder training. To address this issue, Hu et al.
    [[144](#bib.bib144)] proposed a self-recursive contextual network that employs
    a single feature extractor to produce features at different resolutions. Then,
    a weight-sharing deformation generator and receptive module are then used to recursively
    generate and refine deformation fields in a coarse-to-fine manner. Since the network
    weights are shared between resolutions, this method reduces the computational
    burden and the size of the network, resulting in more efficient training. Zhou
    et al. [[379](#bib.bib379)] proposed a novel network architecture to leverage
    progressive registration at both single and multi-scale resolution. The proposed
    method iteratively refines the deformation field generated from the previous iteration,
    with each iteration composing deformation fields of various resolutions to form
    the new deformation field.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，已经有一些努力在使用多尺度图像金字塔方法来应用渐进式配准。鉴于钟形网络架构在图像配准中的广泛采用，解码器中的卷积块以粗到细的方式生成多个分辨率的变形场。这些不同分辨率的变形场随后被上采样和合成形成最终的变形场。采用这一方案的著名方法包括[[163](#bib.bib163)、[167](#bib.bib167)、[199](#bib.bib199)、[209](#bib.bib209)]。除了网络架构外，粗到细的训练方案也被应用于基于学习的图像配准。受到传统配准方法的启发，这些方法通常使用具有不同分辨率的多个阶段，De
    Vos等人[[59](#bib.bib59)] 开创了一种多尺度训练策略用于可变形图像配准。他们的方法涉及通过优化图像相似性度量在每个阶段按顺序训练ConvNet以处理特定的图像分辨率。值得注意的是，采用了B-spline框架，从而减轻了对变形正则化器的需求。在训练过程中，前面ConvNet的权重保持固定，训练后，通过一次输入图像到多阶段ConvNet来执行配准。Eppenhof等人[[80](#bib.bib80)]
    提出了用于基于学习的图像配准的新型渐进式和多尺度训练方案。他们没有一次性训练一个大型网络来完成配准任务，而是首先在低分辨率图像上训练网络的小型版本。然后，逐渐增加训练图像的分辨率，并增加额外的卷积层以扩大网络规模。同样，Mok和Chung[[230](#bib.bib230)]
    提出了LapIRN，采用了类似的金字塔训练方案。然而，与之前的训练方法不同，LapIRN使用三个不同的网络，每个网络产生特定分辨率的变形场。每个网络配备了跳跃连接，将低分辨率网络的特征嵌入传播到高分辨率网络。这些网络以粗到细的方式进行训练，每个网络生成一个变形场，精炼来自前一分辨率的上采样变形场。然而，使用多个网络生成一系列变形场可能在计算上效率低下，并增加网络规模，从而影响训练。为了解决这一问题，Hu等人[[144](#bib.bib144)]
    提出了一个自递归上下文网络，使用单一特征提取器在不同分辨率下生成特征。然后，使用权重共享的变形生成器和感受模块以粗到细的方式递归生成和精炼变形场。由于网络权重在分辨率之间共享，这种方法减少了计算负担和网络规模，从而提高了训练效率。Zhou等人[[379](#bib.bib379)]
    提出了一个新型网络架构，以在单尺度和多尺度分辨率下利用渐进式配准。所提出的方法逐步精炼从前一次迭代生成的变形场，每次迭代将不同分辨率的变形场组合成新的变形场。
- en: The registration methods discussed in this subsection have demonstrated the
    efficacy of decomposing the registration process into multiple steps, where each
    step refines the deformation fields from the previous step. These approaches have
    consistently shown significant performance gains while enforcing a smoother deformation
    field for image registration tasks compared to using a single network to generate
    a deformation field all at once.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 本小节讨论的配准方法已经展示了将配准过程分解为多个步骤的有效性，每个步骤都从前一个步骤中优化变形场。这些方法通常在执行图像配准任务时，相比于一次性生成变形场的单一网络，能显著提高性能，同时使变形场更加平滑。
- en: 5 Uncertainty in Learning-based Registration
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 基于学习的配准中的不确定性
- en: DNNs are capable of learning complex representations. However, their predictions
    are typically deterministic and assumed to be accurate, which is usually not the
    case. Estimating the uncertainty is important for evaluating what the models learn
    from the data and helps reduce risk in decision-making based on the model prediction.
    In medical image analysis, uncertainty estimation has been widely used in tasks
    such as image segmentation, image classification, and image registration. For
    example, registration uncertainty empowers surgeons to evaluate the surgical risk
    tied to the registration model’s prediction, thereby avoiding undesirable consequences.
    Prior to the deep learning-based registration, traditional registration uncertainty
    is based on the framework of probabilistic registration, where the probabilistic
    distribution of the transformation parameters is estimated.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: DNNs能够学习复杂的表示。然而，它们的预测通常是确定性的，并假设是准确的，但实际情况通常并非如此。估计不确定性对于评估模型从数据中学到的内容以及帮助减少基于模型预测的决策风险是非常重要的。在医学图像分析中，不确定性估计被广泛应用于图像分割、图像分类和图像配准等任务。例如，配准不确定性使外科医生能够评估与配准模型预测相关的手术风险，从而避免不良后果。在基于深度学习的配准之前，传统的配准不确定性是基于概率配准框架，其中估计变换参数的概率分布。
- en: In this section, we focus on registration uncertainty estimation using deep
    learning methods, though many concepts have been drawn from traditional registration
    uncertainty estimation methods. We start with the general framework for estimating
    uncertainty using deep learning methods. Next, we formally define the different
    types of registration uncertainty and elaborate on how the uncertainty estimation
    methods are used in learning-based registration. Finally, we provide a summary
    of the methods used for evaluating the quality of uncertainty estimation.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们专注于使用深度学习方法进行配准不确定性估计，尽管许多概念都源自传统的配准不确定性估计方法。我们从使用深度学习方法估计不确定性的通用框架开始。接下来，我们正式定义不同类型的配准不确定性，并详细说明不确定性估计方法在基于学习的配准中的应用。最后，我们总结了评估不确定性估计质量的方法。
- en: 5.1 Bayesian Deep Learning
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 贝叶斯深度学习
- en: '![Refer to caption](img/b8612fba4d7f2ca1dfa34132252f40ce.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/b8612fba4d7f2ca1dfa34132252f40ce.png)'
- en: 'Fig. 3: Various types of registration uncertainty can be estimated using DNNs.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：各种类型的配准不确定性可以使用深度神经网络（DNNs）进行估计。
- en: 'As shown in Fig. [3](#S5.F3 "Fig. 3 ‣ 5.1 Bayesian Deep Learning ‣ 5 Uncertainty
    in Learning-based Registration ‣ A survey on deep learning in medical image registration:
    new technologies, uncertainty, evaluation metrics, and beyond"), in general, uncertainty
    can be categorized into two types: aleatoric and epistemic uncertainty [[169](#bib.bib169)].
    Aleatoric uncertainty, also known as data uncertainty or inherent uncertainty,
    refers to the inherent randomness or variability present in observed data. It
    can be thought of as the variability of the data given the underlying true data
    generation model due to factors such as measurement errors, sensor noise, or the
    intrinsic stochastic nature of the data generation process. Epistemic uncertainty,
    also known as model uncertainty or knowledge uncertainty, refers to variability
    present in the model structure, model parameters, and model assumptions. It arises
    due to our limited knowledge or understanding of the underlying model. Aleatoric
    uncertainty may be reduced by improving the data quality, while epistemic uncertainty
    may be mitigated by improving model selection, refining parameter estimation,
    or acquiring additional relevant information.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [3](#S5.F3 "图 3 ‣ 5.1 贝叶斯深度学习 ‣ 5 基于学习的配准中的不确定性 ‣ 关于医学图像配准中的深度学习：新技术、不确定性、评估指标及更多")
    所示，一般来说，不确定性可以分为两类：aleatoric 不确定性和 epistemic 不确定性 [[169](#bib.bib169)]。Aleatoric
    不确定性，也称为数据不确定性或固有不确定性，指的是观察数据中存在的固有随机性或变异性。它可以被认为是给定潜在真实数据生成模型的数据变异性，这种变异性由于测量误差、传感器噪声或数据生成过程的固有随机性等因素而产生。Epistemic
    不确定性，也称为模型不确定性或知识不确定性，指的是模型结构、模型参数和模型假设中存在的变异性。它源于我们对潜在模型知识或理解的有限性。Aleatoric 不确定性可以通过提高数据质量来减少，而
    epistemic 不确定性则可以通过改进模型选择、精炼参数估计或获取额外的相关信息来减轻。
- en: 'To predict aleatoric and epistemic uncertainty using deep learning, we train
    a model $W$ using data set $D$ that takes an input $x$ to generate an output $y(x,W)$
    and a variance prediction $\sigma^{2}(x,W)$. Aleatoric uncertainty describes the
    uncertainty that is inherent in the training data $D$. It is expressed as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用深度学习预测 aleatoric 和 epistemic 不确定性，我们使用数据集 $D$ 训练模型 $W$，该模型接收输入 $x$ 生成输出
    $y(x,W)$ 和方差预测 $\sigma^{2}(x,W)$。Aleatoric 不确定性描述了训练数据 $D$ 中固有的不确定性。它表示如下：
- en: '|  | $u_{a}=E_{p(W&#124;D)}\left[\sigma^{2}(x,W)\right],$ |  | (11) |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '|  | $u_{a}=E_{p(W\|D)}\left[\sigma^{2}(x,W)\right],$ |  | (11) |'
- en: 'where $E$ represents taking the average of $\sigma^{2}(x,W)$ over the distribution
    $p(W|D)$. Epistemic uncertainty describes the uncertainty of the model $W$. It
    is represented as follows:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $E$ 代表对分布 $p(W|D)$ 下的 $\sigma^{2}(x,W)$ 取平均。Epistemic 不确定性描述了模型 $W$ 的不确定性。它表示如下：
- en: '|  | $u_{e}=V_{p(W&#124;D)}\left[y(x,W)\right],$ |  | (12) |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '|  | $u_{e}=V_{p(W\|D)}\left[y(x,W)\right],$ |  | (12) |'
- en: 'where $V$ represents taking the variance of $y(x,W)$ over the distribution
    $p(W|D)$. Directly computing aleatoric uncertainty using Eqn. [11](#S5.E11 "In
    5.1 Bayesian Deep Learning ‣ 5 Uncertainty in Learning-based Registration ‣ A
    survey on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond") and epistemic uncertainty using Eqn. [12](#S5.E12
    "In 5.1 Bayesian Deep Learning ‣ 5 Uncertainty in Learning-based Registration
    ‣ A survey on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond") is usually impractical, as it requires the integration
    of high dimensional numerical functions. Instead, these uncertainties are approximated
    from a set of outputs by using the model weights $W$ sampled from the posterior
    distribution $p(W|D)$.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $V$ 代表在分布 $p(W|D)$ 下对 $y(x,W)$ 取方差。直接使用方程 [11](#S5.E11 "在 5.1 贝叶斯深度学习 ‣ 5
    基于学习的配准中的不确定性 ‣ 关于医学图像配准中的深度学习：新技术、不确定性、评估指标及更多") 计算aleatoric不确定性和使用方程 [12](#S5.E12
    "在 5.1 贝叶斯深度学习 ‣ 5 基于学习的配准中的不确定性 ‣ 关于医学图像配准中的深度学习：新技术、不确定性、评估指标及更多") 计算epistemic不确定性通常是不切实际的，因为这需要高维数值函数的积分。相反，这些不确定性是通过使用从后验分布
    $p(W|D)$ 中采样的模型权重 $W$ 从一组输出中进行近似的。
- en: In theory, the posterior distribution $p(W|D)$ can be obtained through Bayes’
    rule,
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，后验分布 $p(W|D)$ 可以通过贝叶斯规则获得，
- en: '|  | $p(W&#124;D)=\frac{p(D&#124;W)p(W)}{p(D)},$ |  | (13) |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '|  | $p(W\|D)=\frac{p(D\|W)p(W)}{p(D)},$ |  | (13) |'
- en: 'where $p(W)$ is an assumed prior. However, it is not feasible to obtain $p(D)$
    in the denominator due to the intractable integral. As an alternative, variational
    inference is used to approximate $p(W|D)$ as a distribution $q_{\theta}(W)$ with
    parameter $\theta$ by minimizing the Kullback-Leibler (KL) divergence between
    them. This process can be simplified as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p(W)$ 是一个假设的先验。然而，由于难以处理的积分，无法获得分母中的 $p(D)$。作为替代方案，使用变分推断将 $p(W|D)$ 近似为一个具有参数
    $\theta$ 的分布 $q_{\theta}(W)$，通过最小化它们之间的 Kullback-Leibler (KL) 散度来实现。这个过程可以简化如下：
- en: '|  | $\hat{\theta}=\argmin_{\theta}D_{KL}\Big{[}q_{\theta}(W)\&#124;p(W)\Big{]}-E_{q_{\theta}}\Big{[}\log{p(D&#124;W)}\Big{]},$
    |  | (14) |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\theta}=\argmin_{\theta}D_{KL}\Big{[}q_{\theta}(W)\&#124;p(W)\Big{]}-E_{q_{\theta}}\Big{[}\log{p(D&#124;W)}\Big{]},$
    |  | (14) |'
- en: 'where $D_{KL}$ represents KL divergence and $E_{q_{\theta}}$ represents taking
    the average over the distribution $q_{\theta}(W)$. With this, the aleatoric uncertainty
    in Eqn. [11](#S5.E11 "In 5.1 Bayesian Deep Learning ‣ 5 Uncertainty in Learning-based
    Registration ‣ A survey on deep learning in medical image registration: new technologies,
    uncertainty, evaluation metrics, and beyond") and the epistemic uncertainty in
    Eqn. [12](#S5.E12 "In 5.1 Bayesian Deep Learning ‣ 5 Uncertainty in Learning-based
    Registration ‣ A survey on deep learning in medical image registration: new technologies,
    uncertainty, evaluation metrics, and beyond") can be approximated by sampling
    $W$ from $q_{\hat{\theta}}(W)$.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $D_{KL}$ 代表KL散度，$E_{q_{\theta}}$ 代表对分布 $q_{\theta}(W)$ 进行取平均。通过这种方法，可以通过从
    $q_{\hat{\theta}}(W)$ 中采样 $W$ 来近似 Eqn. [11](#S5.E11 "在5.1 贝叶斯深度学习 ‣ 5 基于学习的配准中的不确定性
    ‣ 深度学习在医学图像配准中的应用：新技术、不确定性、评估指标及更多") 中的偶然不确定性和 Eqn. [12](#S5.E12 "在5.1 贝叶斯深度学习
    ‣ 5 基于学习的配准中的不确定性 ‣ 深度学习在医学图像配准中的应用：新技术、不确定性、评估指标及更多") 中的知识不确定性。
- en: Many sampling methods can be used for uncertainty estimation, including Monte
    Carlo dropout, bootstrap, and snapshot techniques. The Monte Carlo dropout sampling
    method operates under the assumption that $q_{\theta}(W)$ follows a Bernoulli
    distribution [[99](#bib.bib99)]. It leverages dropout layers during the testing
    phase to perform multiple forward inferences. This method is widely used in learning-based
    registration models, likely due to its straightforward implementation [[361](#bib.bib361),
    [362](#bib.bib362), [214](#bib.bib214), [37](#bib.bib37), [353](#bib.bib353)].
    Bootstrap sampling, a traditional method, involves training the registration model
    multiple times on independent training sets to produce multiple inferences [[181](#bib.bib181)].
    Snapshot sampling uses the cyclic learning rate in one training process for perturbing
    the model to converge to multiple different local minimums [[150](#bib.bib150)].
    It has shown that snapshot sampling performs better uncertainty estimation than
    other methods for the medical image registration use case [[105](#bib.bib105)].
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 许多采样方法可以用于不确定性估计，包括蒙特卡洛 dropout、bootstrap 和 snapshot 技术。蒙特卡洛 dropout 采样方法的操作基于
    $q_{\theta}(W)$ 遵循伯努利分布的假设[[99](#bib.bib99)]。它利用测试阶段的 dropout 层执行多次前向推理。由于其实现简单，这种方法在基于学习的配准模型中被广泛使用[[361](#bib.bib361),
    [362](#bib.bib362), [214](#bib.bib214), [37](#bib.bib37), [353](#bib.bib353)]。传统的
    bootstrap 采样方法涉及在独立训练集上多次训练配准模型以产生多个推理[[181](#bib.bib181)]。snapshot 采样使用一个训练过程中的周期学习率来扰动模型，使其收敛到多个不同的局部最小值[[150](#bib.bib150)]。研究表明，对于医学图像配准任务，snapshot
    采样在不确定性估计方面优于其他方法[[105](#bib.bib105)]。
- en: 5.2 Registration Uncertainty Estimation for DNN
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 DNN的配准不确定性估计
- en: Both aleatoric and epistemic uncertainty are present in image registration.
    Aleatoric uncertainty in image registration may arise from factors such as image
    noise, image artifacts, lack of image features or image contrast, and natural
    anatomical variation between images. There may be two types of aleatoric uncertainty
    in image registration. One is that given the underlying true deformation field,
    two aligned images may not be exactly the same due to different image noise, image
    artifacts or natural anatomical variation between images. Another type is that
    multiple deformation fields may align two images with similar performance due
    to lack of image features or image contrast. On the other hand, epistemic uncertainty
    represents the limitations inherent in the modeling process. In image registration,
    this relates to the limited ability of the model to precisely capture the complex
    deformation field. This form of uncertainty can be attributed to factors like
    inadequate training data, choices in model architecture, or the inherent complexity
    posed by the inverse problem of estimating the deformation fields. The following
    subsections provide details on each type of uncertainty.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图像配准中存在**随机不确定性**和**知识性不确定性**。图像配准中的**随机不确定性**可能来自图像噪声、图像伪影、图像特征或图像对比度的缺乏，以及图像之间的自然解剖变异。图像配准中可能存在两种类型的**随机不确定性**。一种是给定真实的变形场时，由于不同的图像噪声、图像伪影或图像之间的自然解剖变异，两幅对齐的图像可能不会完全相同。另一种是由于图像特征或图像对比度的缺乏，多个变形场可能以相似的表现对齐两幅图像。另一方面，**知识性不确定性**代表了建模过程中的固有限制。在图像配准中，这与模型准确捕捉复杂变形场的能力有限有关。这种形式的不确定性可以归因于数据不足、模型架构选择或估计变形场的逆问题所带来的固有复杂性等因素。以下小节详细介绍了每种类型的不确定性。
- en: 5.2.1 Aleatoric Uncertainty
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1 **随机不确定性**
- en: In medical image registration, the output of the network is usually a deformation
    field $\phi(I_{f},I_{m},W)$ as a function of the fixed image $I_{f}$, the moving
    image $I_{m}$ and the model $W$. To help the model estimate the aleatoric uncertainty
    inherent from data, the model needs to predict a variance $\sigma(I_{f},I_{m},W)$
    of the output. Assuming the deformation field $\phi$ follows a voxel-wise Gaussian
    distribution, the model $W$ can be trained by minimizing the loss function,
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在医学图像配准中，网络的输出通常是一个变形场 $\phi(I_{f},I_{m},W)$，它是固定图像 $I_{f}$、移动图像 $I_{m}$ 和模型
    $W$ 的函数。为了帮助模型估计数据中固有的**随机不确定性**，模型需要预测输出的方差 $\sigma(I_{f},I_{m},W)$。假设变形场 $\phi$
    遵循体素级的高斯分布，模型 $W$ 可以通过最小化损失函数来进行训练。
- en: '|  | $\mathcal{L}=\sum_{p}\frac{(\phi(p)-\phi^{*}(p))^{2}}{\sigma^{2}(p)}+\log{\sigma^{2}(p)},$
    |  | (15) |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}=\sum_{p}\frac{(\phi(p)-\phi^{*}(p))^{2}}{\sigma^{2}(p)}+\log{\sigma^{2}(p)},$
    |  | (15) |'
- en: 'where $\phi^{*}$ is the ground truth for the deformation field. However, in
    unsupervised learning-based image registration, the ground truth deformation $\phi^{*}$
    is unavailable, and the loss may be calculated in the image domain (*i.e.*, in
    the form of image similarity measure) rather than directly comparing the deformation
    fields as in Eqn. [15](#S5.E15 "In 5.2.1 Aleatoric Uncertainty ‣ 5.2 Registration
    Uncertainty Estimation for DNN ‣ 5 Uncertainty in Learning-based Registration
    ‣ A survey on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond"). To overcome this issue, the aleatoric uncertainty
    for image registration is frequently estimated using a variational inference strategy,
    which optimizes a global neural network to produce distributions of deformation
    fields [[56](#bib.bib56), [108](#bib.bib108), [338](#bib.bib338), [300](#bib.bib300),
    [52](#bib.bib52), [177](#bib.bib177)]. This approach circumvents the direct computation
    of the intractable posterior $p(\phi|I_{f};I_{m})$ by introducing an approximate
    posterior $q_{\theta}(\phi)$, where the parameter $\theta$ can be predicted by
    a network based on the inputs $I_{f}$ and $I_{m}$. The KL divergence between the
    two posteriors is then minimized, which maximizes the evidence lower bound (ELBO):'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $\phi^{*}$ 是变形场的真实值。然而，在基于无监督学习的图像配准中，真实的变形 $\phi^{*}$ 是不可用的，损失可能在图像域中计算（*即*，以图像相似性度量的形式）而不是直接比较变形场，如公式
    [15](#S5.E15 "在 5.2.1 Aleatoric Uncertainty ‣ 5.2 Registration Uncertainty Estimation
    for DNN ‣ 5 Uncertainty in Learning-based Registration ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond") 所示。为了解决这个问题，图像配准的偶然不确定性通常使用变分推断策略进行估计，该策略优化一个全局神经网络以生成变形场的分布 [[56](#bib.bib56),
    [108](#bib.bib108), [338](#bib.bib338), [300](#bib.bib300), [52](#bib.bib52),
    [177](#bib.bib177)]。这种方法通过引入一个近似后验 $q_{\theta}(\phi)$，避免了对难以处理的后验 $p(\phi|I_{f};I_{m})$
    的直接计算，其中参数 $\theta$ 可以通过基于输入 $I_{f}$ 和 $I_{m}$ 的网络进行预测。然后最小化两个后验之间的KL散度，从而最大化证据下界（ELBO）：'
- en: '|  | $\hat{\theta}=\argmin_{\theta}D_{KL}\Big{[}q_{\theta}(\phi)\&#124;p(\phi)\Big{]}-E_{q_{\theta}}\Big{[}\log
    p(I_{f}&#124;\phi;I_{m})\Big{]},$ |  | (16) |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\theta}=\argmin_{\theta}D_{KL}\Big{[}q_{\theta}(\phi)\&#124;p(\phi)\Big{]}-E_{q_{\theta}}\Big{[}\log
    p(I_{f}&#124;\phi;I_{m})\Big{]},$ |  | (16) |'
- en: where $D_{KL}$ represents KL divergence and $E_{q_{\theta}}$ represents taking
    the average over the distribution $q_{\theta}(\phi)$. Here, the approximate posterior
    $q_{\theta}(\phi)$ is frequently modeled as a multivariate normal distribution
    (i.e., $\phi\sim\mathcal{N}(\mu_{\phi},\sigma_{\phi}^{2})$). Moreover, the conditional
    probability $p(I_{f}|\phi;I_{m})$ typically takes the Gaussian form (i.e., $I_{f}\sim\mathcal{N}(I_{m}\circ\phi,\sigma_{I}^{2})$).
    In practical applications, the mean $\mu_{\phi}$ and the standard deviation $\sigma_{\phi}$
    of the deformation field can be predicted by the registration network, in a similar
    manner to a variational autoencoder. In this case, the variance $\sigma^{2}_{\phi}$
    represents the aleatoric uncertainty associated with the deformation field, given
    the input images $I_{f}$ and $I_{m}$.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $D_{KL}$ 表示KL散度，$E_{q_{\theta}}$ 表示对分布 $q_{\theta}(\phi)$ 取平均。在这里，近似后验 $q_{\theta}(\phi)$
    通常建模为多元正态分布（*即*，$\phi\sim\mathcal{N}(\mu_{\phi},\sigma_{\phi}^{2})$）。此外，条件概率 $p(I_{f}|\phi;I_{m})$
    通常呈高斯形式（*即*，$I_{f}\sim\mathcal{N}(I_{m}\circ\phi,\sigma_{I}^{2})$）。在实际应用中，变形场的均值
    $\mu_{\phi}$ 和标准差 $\sigma_{\phi}$ 可以由配准网络预测，类似于变分自编码器。在这种情况下，方差 $\sigma^{2}_{\phi}$
    表示与输入图像 $I_{f}$ 和 $I_{m}$ 相关的变形场的偶然不确定性。
- en: 5.2.2 Epistemic Uncertainty
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2 知识不确定性
- en: 'As illustrated in Fig. [3](#S5.F3 "Fig. 3 ‣ 5.1 Bayesian Deep Learning ‣ 5
    Uncertainty in Learning-based Registration ‣ A survey on deep learning in medical
    image registration: new technologies, uncertainty, evaluation metrics, and beyond"),
    the epistemic uncertainty in registration can be divided into two different measures
    [[206](#bib.bib206), [353](#bib.bib353), [37](#bib.bib37)]: transformation uncertainty
    and appearance uncertainty. These measures refer to the uncertainty in generating
    the transformation and the plausibility of the transformation, respectively [[22](#bib.bib22)].
    The former quantifies the uncertainty in the deformation space and tends to be
    large when the model is uncertain about establishing specific correspondences,
    such as when registering regions with piecewise constant intensity. In contrast,
    the latter is often based on the assumption that high image similarity indicates
    correct alignment. Consequently, this uncertainty would be large when the appearance
    differences between the warped and fixed images are significant.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '如图 [3](#S5.F3 "Fig. 3 ‣ 5.1 Bayesian Deep Learning ‣ 5 Uncertainty in Learning-based
    Registration ‣ A survey on deep learning in medical image registration: new technologies,
    uncertainty, evaluation metrics, and beyond") 所示，配准中的知识不确定性可以分为两种不同的度量[[206](#bib.bib206),
    [353](#bib.bib353), [37](#bib.bib37)]：变换不确定性和外观不确定性。这些度量分别指生成变换的过程中的不确定性和变换的合理性[[22](#bib.bib22)]。前者量化了形变空间中的不确定性，当模型对建立特定的对应关系不确定时，如在配准具有分段常数强度的区域时，这种不确定性往往较大。相反，后者通常基于这样的假设：高图像相似度表明对齐正确。因此，当扭曲图像和固定图像之间的外观差异较大时，这种不确定性也会较大。'
- en: 'Transformation uncertainty can be described as the variance of the sampled
    deformation fields, which derives from Eqn. [12](#S5.E12 "In 5.1 Bayesian Deep
    Learning ‣ 5 Uncertainty in Learning-based Registration ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond") by stochastic sampling:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '变换不确定性可以描述为采样的形变场的方差，这源自方程 [12](#S5.E12 "In 5.1 Bayesian Deep Learning ‣ 5
    Uncertainty in Learning-based Registration ‣ A survey on deep learning in medical
    image registration: new technologies, uncertainty, evaluation metrics, and beyond")
    通过随机采样：'
- en: '|  | $u_{e,trans}=\frac{1}{N}\sum_{i=1}^{N}(\phi_{i}-\frac{1}{N}\sum_{j=1}^{N}\phi_{j})^{2},$
    |  | (17) |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '|  | $u_{e,trans}=\frac{1}{N}\sum_{i=1}^{N}(\phi_{i}-\frac{1}{N}\sum_{j=1}^{N}\phi_{j})^{2},$
    |  | (17) |'
- en: 'where $\phi_{i}$ is generated by using the model weight $W_{i}$ sampled from
    the estimated variational distribution $q_{\hat{\theta}}(W)$ with the parameter
    $\hat{\theta}$ optimized by Eqn. [14](#S5.E14 "In 5.1 Bayesian Deep Learning ‣
    5 Uncertainty in Learning-based Registration ‣ A survey on deep learning in medical
    image registration: new technologies, uncertainty, evaluation metrics, and beyond"),
    and $N$ is the total sampling number. Appearance uncertainty is expressed as the
    variance of the warped images, which are created using the sampled deformation
    fields [[206](#bib.bib206), [353](#bib.bib353)]:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $\phi_{i}$ 是使用从估计变分分布 $q_{\hat{\theta}}(W)$ 中采样的模型权重 $W_{i}$ 生成的，参数 $\hat{\theta}$
    通过方程 [14](#S5.E14 "In 5.1 Bayesian Deep Learning ‣ 5 Uncertainty in Learning-based
    Registration ‣ A survey on deep learning in medical image registration: new technologies,
    uncertainty, evaluation metrics, and beyond") 优化得到，$N$ 是总采样数。外观不确定性表示为扭曲图像的方差，这些图像是使用采样的形变场创建的[[206](#bib.bib206),
    [353](#bib.bib353)]：'
- en: '|  | $u_{e,appea}=\frac{1}{N}\sum_{i=1}^{N}(I_{m}\circ\phi_{i}-\frac{1}{N}\sum_{j=1}^{N}I_{m}\circ\phi_{j})^{2},$
    |  | (18) |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '|  | $u_{e,appea}=\frac{1}{N}\sum_{i=1}^{N}(I_{m}\circ\phi_{i}-\frac{1}{N}\sum_{j=1}^{N}I_{m}\circ\phi_{j})^{2},$
    |  | (18) |'
- en: 'where $\phi_{i}$ is generated by using the sampled $W_{i}$ as the model, $N$
    is the total sampling number and $I_{m}$ is the moving image. However, it should
    be noted that the uncertainty estimated using this equation for appearance uncertainty
    can be biased due to overfitting, as shown in Chen et al. [[37](#bib.bib37)].
    To correct this, the authors suggest using the following formulation instead:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\phi_{i}$ 是使用采样的 $W_{i}$ 作为模型生成的，$N$ 是总采样数，$I_{m}$ 是移动图像。然而，需要注意的是，使用此方程估计的外观不确定性可能会由于过拟合而产生偏差，如
    Chen 等人所示[[37](#bib.bib37)]。为纠正这一点，作者建议使用以下公式：
- en: '|  | $u_{e,appea}=\frac{1}{N}\sum_{i=1}^{N}(I_{m}\circ\phi_{i}-I_{f})^{2},$
    |  | (19) |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '|  | $u_{e,appea}=\frac{1}{N}\sum_{i=1}^{N}(I_{m}\circ\phi_{i}-I_{f})^{2},$
    |  | (19) |'
- en: where the predictive mean is replaced by the fixed image $I_{f}$.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 其中预测均值被固定图像 $I_{f}$ 替代。
- en: 5.3 Uncertainty Evaluation in Registration
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 配准中的不确定性评估
- en: One significant challenge in uncertainty estimation lies in its evaluation due
    to the absence of ground truth, especially in unsupervised learning-based registration.
    To access the quality of uncertainty, sparsification plots are usually used for
    voxel-wise uncertainty evaluation [[213](#bib.bib213), [337](#bib.bib337), [152](#bib.bib152)].
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定性估计中的一个重要挑战在于评估，因为缺乏真实的基准，特别是在基于无监督学习的配准中。为了评估不确定性的质量，通常使用稀疏化图来进行体素级不确定性评估 [[213](#bib.bib213),
    [337](#bib.bib337), [152](#bib.bib152)]。
- en: Sparsification plots demonstrate how the registration error changes by gradually
    removing voxels ranked by the uncertainty measure. It is anticipated that removing
    a voxel with higher uncertainty will result in a greater reduction in registration
    error, and the opposite holds true for voxels with lower uncertainty. If all voxels
    are arranged in descending order of uncertainty, and the uncertainty ranking matches
    the actual registration error ranking, the accumulated registration error under
    the sparsification plot will be small. Therefore, the area under sparsification
    plots is also used as an evaluation metric to gauge the quality of the uncertainty
    estimation.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏化图展示了通过逐渐移除按不确定性测量排名的体素，配准误差是如何变化的。预计移除具有较高不确定性的体素将导致配准误差的显著减少，反之亦然。如果所有体素按不确定性降序排列，并且不确定性排名与实际配准误差排名匹配，则稀疏化图下的累积配准误差将很小。因此，稀疏化图下的面积也作为评估指标来衡量不确定性估计的质量。
- en: 6 Registration Evaluation Metrics
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 配准评估指标
- en: Manual correspondences are usually regarded as the gold standard for evaluating
    the performance of a registration algorithm [[255](#bib.bib255)]. Landmark correspondences
    are the most frequently used type, although surfaces or lines may also serve as
    manual correspondences. The evaluation of registration performance using landmark
    correspondences is relatively simple for rigid and affine transformations, since
    these transformations can be expressed as matrix multiplication and the ground
    truth transformation can be determined through several pairs of manual landmark
    correspondences. In contrast, determining the parameters of deformable transformations
    requires dense manual landmark correspondences, which are typically not obtainable.
    Even in cases where manual landmark correspondences are available, they are often
    restricted to highly selective intensity features [[34](#bib.bib34)] and neglect
    regions with homogeneous intensities. Therefore, validating deformable registration
    algorithms is still considered a non-trivial task [[325](#bib.bib325)]. In current
    literature, the performance of deformable registration algorithms is most commonly
    evaluated in terms of accuracy and regularity.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 手动标志点对应通常被视为评估配准算法性能的金标准 [[255](#bib.bib255)]。标志点对应是最常用的类型，虽然表面或线条也可以作为手动对应。使用标志点对应评估配准性能对于刚性和仿射变换相对简单，因为这些变换可以表示为矩阵乘法，并且可以通过若干对手动标志点对应来确定真实的变换。相比之下，确定可变形变换的参数需要密集的手动标志点对应，这通常是不可获得的。即使在手动标志点对应可用的情况下，它们通常仅限于高度选择性的强度特征 [[34](#bib.bib34)]，并忽略了具有均匀强度的区域。因此，验证可变形配准算法仍然被认为是一个复杂的任务 [[325](#bib.bib325)]。在当前文献中，可变形配准算法的性能通常以准确性和规律性来评估。
- en: 6.1 Accuracy Measures
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 准确性度量
- en: When the manual landmark correspondences are available, the accuracy of the
    transformation can be evaluated by target registration error (TRE),
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 当手动标志点对应可用时，可以通过目标配准误差 (TRE) 来评估变换的准确性。
- en: '|  | $\text{TRE}_{\text{forward}}=\sum_{i=1}^{N}&#124;&#124;T_{\text{forward}}(l_{m}^{i})-l_{f}^{i}&#124;&#124;_{k},$
    |  | (20) |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|  | $\text{TRE}_{\text{forward}}=\sum_{i=1}^{N}&#124;&#124;T_{\text{forward}}(l_{m}^{i})-l_{f}^{i}&#124;&#124;_{k},$
    |  | (20) |'
- en: 'where $T_{\text{forward}}$ is the estimated forward transformation that takes
    the moving image to the fixed image; $l_{m}^{i}$ and $l_{f}^{i}$ are the $i^{\,\text{th}}$
    pair of landmarks in the moving and fixed image, and $k\in\{1,2\}$ denoting either
    the $\ell^{1}$-norm or $\ell^{2}$-norm. Both $l_{m}^{i}$ and $l_{f}^{i}$ as well
    as the warped moving landmark $T(l_{m}^{i})$ can be non-integer locations. Note
    that we used the forward transformation $T_{\text{forward}}$ in Eqn. [20](#S6.E20
    "In 6.1 Accuracy Measures ‣ 6 Registration Evaluation Metrics ‣ A survey on deep
    learning in medical image registration: new technologies, uncertainty, evaluation
    metrics, and beyond"), but it is more common in practice to estimate the transformation
    $T_{\text{backward}}$ that maps the fixed image to the moving image. In order
    to generate the warped image, $T_{\text{backward}}^{-1}$ can be applied in place
    of $T_{\text{forward}}$. Both $T_{\text{forward}}$ and $T_{\text{backward}}$ are
    mappings from integer locations to non-integer locations. The difference between
    these two schemes is manifested when rendering the warped image. When $T_{\text{forward}}$
    is applied to $I_{m}$, integer locations are mapped to non-integer locations,
    which necessitates interpolating scattered data [[53](#bib.bib53), [383](#bib.bib383)].
    On the other hand, $T_{\text{backward}}^{-1}$ maps non-integer locations back
    to integer locations. Thus, rendering the warped image only requires interpolating
    the moving image, which is defined on a regular grid. For algorithms that only
    output $T_{\text{backward}}$, TRE can be computed as'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $T_{\text{forward}}$ 是估计的前向变换，将移动图像转换为固定图像；$l_{m}^{i}$ 和 $l_{f}^{i}$ 是移动图像和固定图像中的第
    $i^{\,\text{th}}$ 对地标，$k\in\{1,2\}$ 表示 $\ell^{1}$-范数或 $\ell^{2}$-范数。$l_{m}^{i}$
    和 $l_{f}^{i}$ 以及变形后的移动地标 $T(l_{m}^{i})$ 可以是非整数位置。注意，我们在方程 [20](#S6.E20 "In 6.1
    Accuracy Measures ‣ 6 Registration Evaluation Metrics ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond") 中使用了前向变换 $T_{\text{forward}}$，但在实践中，更常见的是估计将固定图像映射到移动图像的变换 $T_{\text{backward}}$。为了生成变形图像，可以用
    $T_{\text{backward}}^{-1}$ 替代 $T_{\text{forward}}$。$T_{\text{forward}}$ 和 $T_{\text{backward}}$
    都是从整数位置映射到非整数位置。这两种方案的区别体现在渲染变形图像时。当 $T_{\text{forward}}$ 应用于 $I_{m}$ 时，整数位置被映射到非整数位置，这需要对散乱数据进行插值[[53](#bib.bib53),
    [383](#bib.bib383)]。另一方面，$T_{\text{backward}}^{-1}$ 将非整数位置映射回整数位置。因此，渲染变形图像只需对移动图像进行插值，该图像定义在规则网格上。对于仅输出
    $T_{\text{backward}}$ 的算法，TRE 可以计算为'
- en: '|  | $\text{TRE}_{\text{backward}}=\sum_{i=1}^{N}&#124;&#124;l_{m}^{i}-T_{\text{backward}}(l_{f}^{i})&#124;&#124;_{k}.$
    |  | (21) |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '|  | $\text{TRE}_{\text{backward}}=\sum_{i=1}^{N}&#124;&#124;l_{m}^{i}-T_{\text{backward}}(l_{f}^{i})&#124;&#124;_{k}.$
    |  | (21) |'
- en: Landmark correspondences can also be generated using artificial deformations [[17](#bib.bib17),
    [286](#bib.bib286), [103](#bib.bib103)]. Different from manual landmark correspondences,
    artificial deformation can produce dense correspondences that are not limited
    to regions with highly selective intensity features. However, the performance
    of algorithms on artificial deformation may not accurately reflect their actual
    performance due to the discrepancy between the artificial and real deformations [[243](#bib.bib243),
    [260](#bib.bib260)]. To overcome this issue, many works have been focused on generating
    deformations that are more akin to those observed in practical applications. For
    instance, Lobachev et al. [[203](#bib.bib203)] proposed a pipeline for simulating
    sectioning-induced deformation fields. Vlachopoulos et al. [[328](#bib.bib328)] used
    a thin-plate kernel spline model to simulate lung deformations arising from respiration.
    Biomechanical simulation [[98](#bib.bib98), [315](#bib.bib315)] and phantoms [[346](#bib.bib346),
    [13](#bib.bib13)] are other techniques used to generate artificial deformations.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 地标对应关系也可以通过人工变形生成[[17](#bib.bib17), [286](#bib.bib286), [103](#bib.bib103)]。与手动地标对应关系不同，人工变形可以生成密集的对应关系，这些对应关系不局限于具有高度选择性强度特征的区域。然而，由于人工变形和实际变形之间的差异，算法在人工变形上的表现可能无法准确反映其实际性能[[243](#bib.bib243),
    [260](#bib.bib260)]。为了克服这一问题，许多研究集中在生成更接近实际应用中观察到的变形。例如，Lobachev等人[[203](#bib.bib203)]提出了一个模拟切割引起的变形场的管道。Vlachopoulos等人[[328](#bib.bib328)]使用薄板样条模型模拟由呼吸引起的肺变形。生物力学模拟[[98](#bib.bib98),
    [315](#bib.bib315)]和模型[[346](#bib.bib346), [13](#bib.bib13)]是生成人工变形的其他技术。
- en: In situations where manual landmark correspondences are not available, surrogate
    measures are used to evaluate accuracy. The most straightforward measures of this
    kind include absolute intensity differences and the root-mean-square intensity
    difference between the warped image and the fixed image. Other similarity measures
    such as mutual information, structural similarity index (SSIM) can also be used.
    When anatomic labels are available, evaluating the overlaps between the warped
    and fixed label images is a popular technique. The Dice coefficient and Jaccard
    Index are examples of such measures. However, Rohlfing [[276](#bib.bib276)] demonstrated
    that by simply reordering the voxels from the moving image based on the intensity
    values ranking without any geometrical constraints, one can achieve significantly
    better performance compared with the state-of-the-art registration algorithms
    in most of the surrogate measures. They concluded that surrogate measures might
    still be useful to detect inaccurate registrations but many times they do not
    provide sufficient positive evidence for accurate registrations. Only the overlap
    of sufficiently local labels among the surrogate measures was found to distinguish
    between reasonable and poor registrations in their experiments.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在无法获得手动标记对应的情况下，使用替代度量来评估准确性。这类度量中最直接的包括变形图像和固定图像之间的绝对强度差异以及均方根强度差异。其他相似度量如互信息、结构相似性指数（SSIM）也可以使用。当有解剖标签时，评估变形标签图像与固定标签图像之间的重叠是一种常见的技术。Dice系数和Jaccard指数是这类度量的例子。然而，Rohlfing[[276](#bib.bib276)]证明，通过仅根据强度值排序重新排列移动图像中的体素，在没有任何几何约束的情况下，可以在大多数替代度量中实现比最先进的配准算法显著更好的性能。他们得出结论，替代度量可能仍然对检测不准确的配准有用，但很多时候它们没有提供足够的积极证据来确认准确的配准。他们的实验发现，只有在替代度量中充分局部的标签重叠才能区分合理的和较差的配准。
- en: Label surface distances from segmentation maps offers an alternative to overlap
    measures. Dalca et al. [[56](#bib.bib56)] converted segmentation maps into signed
    distance functions to approximate the distance between the fixed and warped surfaces.
    They also showed that incorporating a similar surface distance loss during network
    training enhanced the surface alignment of anatomical structures. Cheng et al.
    [[48](#bib.bib48)] used the mean minimum distance (MMD), computed as the average
    Euclidean distance between manually defined surface points of anatomical structures
    and their corresponding nearest points on the warped surface, to measure the discrepancy
    between the surfaces. Additionally, the Hausdorff distance has been extensively
    used [[133](#bib.bib133)].
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 从分割图中标记表面距离提供了与重叠度量的另一种替代方法。Dalca等人[[56](#bib.bib56)]将分割图转换为带符号的距离函数，以近似固定表面与变形表面之间的距离。他们还展示了在网络训练过程中引入类似的表面距离损失能够提高解剖结构的表面对齐。Cheng等人[[48](#bib.bib48)]使用了均值最小距离（MMD），计算为手动定义的解剖结构表面点与其对应的变形表面上最近点之间的平均欧氏距离，以衡量表面之间的差异。此外，Hausdorff距离也被广泛使用[[133](#bib.bib133)]。
- en: Previous studies [[205](#bib.bib205), [302](#bib.bib302)] have explored the
    use of machine learning algorithms for quantifying registration errors. Compared
    to manual landmark correspondences, those methods provide dense error estimations
    that can be easily visualized. More recently, several deep learning techniques
    have been employed, offering a speed advantage over traditional machine learning
    algorithms, especially when a graphical processing unit (GPU) is available [[304](#bib.bib304)].
    Most of these methods were trained to predict the registration errors between
    a fixed and a warped image inputs. During training, artificial deformations are
    used to produce the warped image and the accuracy of these methods were validated
    using manual landmark correspondences [[81](#bib.bib81), [304](#bib.bib304)].
    Additionally, these techniques can also be applied to inter-modality registration
    tasks by incorporating an extra image synthesis step [[21](#bib.bib21)].
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 以往的研究 [[205](#bib.bib205), [302](#bib.bib302)] 探讨了使用机器学习算法量化配准误差的方法。与手动标记点对应关系相比，这些方法提供了可以轻松可视化的密集误差估计。最近，几种深度学习技术被采用，相较于传统机器学习算法，尤其是在有图形处理单元（GPU）可用时，具有速度优势
    [[304](#bib.bib304)]。这些方法大多被训练来预测固定图像和变形图像之间的配准误差。在训练过程中，使用人工变形来生成变形图像，这些方法的准确性通过手动标记点对应关系进行了验证
    [[81](#bib.bib81), [304](#bib.bib304)]。此外，这些技术还可以通过引入额外的图像合成步骤应用于不同模态的配准任务 [[21](#bib.bib21)]。
- en: 6.2 Regularity Measures
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 正则性度量
- en: Given the challenge of acquiring dense manual landmark correspondences and the
    aforementioned limitation of surrogate measures, the regularity of the transformations
    is often used alongside accuracy measures to obtain a more comprehensive understanding
    of the transformations. The underlying assumption is that accurate transformations
    should be spatially smooth. Particularly, transformations that fold the space
    result in physically un-realistic anatomy structures, which usually indicate errors.
    For continuous transformations, their Jacobian determinant $|J|$ must be positive
    everywhere to avoid folding of space. This concept is extended to digital transformations
    where the number or the percentage of voxels with non-positive Jacobian determinant
    $|J|\leq 0$ are reported to measure the irregularity [[223](#bib.bib223), [199](#bib.bib199),
    [235](#bib.bib235), [62](#bib.bib62), [42](#bib.bib42), [229](#bib.bib229), [161](#bib.bib161),
    [347](#bib.bib347)]. For a 3D transformation $T(x,y,z)=[T_{x},T_{y},T_{z}]$, the
    Jacobian is defined as
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 由于获取密集的手动标记点对应关系的挑战以及上述代理度量的限制，变换的正则性通常与准确度量一起使用，以获得对变换的更全面理解。基本假设是，准确的变换应当在空间上平滑。特别是，折叠空间的变换会导致物理上不真实的解剖结构，这通常表明存在错误。对于连续变换，其雅可比行列式
    $|J|$ 必须在所有地方为正，以避免空间的折叠。这个概念扩展到了数字变换中，其中报告了具有非正雅可比行列式 $|J|\leq 0$ 的体素的数量或百分比，以测量不规则性
    [[223](#bib.bib223), [199](#bib.bib199), [235](#bib.bib235), [62](#bib.bib62),
    [42](#bib.bib42), [229](#bib.bib229), [161](#bib.bib161), [347](#bib.bib347)]。对于一个
    3D 变换 $T(x,y,z)=[T_{x},T_{y},T_{z}]$，雅可比行列式定义为
- en: '|  | <math   alttext="J=\vmatrix\frac{\partial T_{x}}{\partial x}&amp;\frac{\partial
    T_{x}}{\partial y}\frac{\partial T_{x}}{\partial z}\\ \frac{\partial T_{y}}{\partial
    x}\frac{\partial T_{y}}{\partial y}\frac{\partial T_{y}}{\partial z}\\'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math alttext="J=\vmatrix\frac{\partial T_{x}}{\partial x}&amp;\frac{\partial
    T_{x}}{\partial y}\frac{\partial T_{x}}{\partial z}\\ \frac{\partial T_{y}}{\partial
    x}\frac{\partial T_{y}}{\partial y}\frac{\partial T_{y}}{\partial z}\\'
- en: \frac{\partial T_{z}}{\partial x}\frac{\partial T_{z}}{\partial y}\frac{\partial
    T_{z}}{\partial z}\\
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: \frac{\partial T_{z}}{\partial x}\frac{\partial T_{z}}{\partial y}\frac{\partial
    T_{z}}{\partial z}\\
- en: ." display="block"><semantics ><mrow  ><mrow ><mi >J</mi><mo  >=</mo><mrow ><merror
    class="ltx_ERROR undefined undefined"  ><mtext >{vmatrix}</mtext></merror><mo
    lspace="0em" rspace="0em"  >​</mo><mfrac ><mrow ><mo rspace="0em" >∂</mo><msub
    ><mi  >T</mi><mi >x</mi></msub></mrow><mrow ><mo rspace="0em" >∂</mo><mi >x</mi></mrow></mfrac><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathvariant="normal"  >&</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mfrac ><mrow ><mo rspace="0em" >∂</mo><msub ><mi  >T</mi><mi
    >x</mi></msub></mrow><mrow ><mo rspace="0em" >∂</mo><mi >y</mi></mrow></mfrac><mo
    lspace="0em" rspace="0em"  >​</mo><mfrac ><mrow ><mo rspace="0em" >∂</mo><msub
    ><mi  >T</mi><mi >x</mi></msub></mrow><mrow ><mo rspace="0em" >∂</mo><mi >z</mi></mrow></mfrac><mo
    lspace="0em" rspace="0em"  >​</mo><mfrac ><mrow ><mo rspace="0em" >∂</mo><msub
    ><mi  >T</mi><mi >y</mi></msub></mrow><mrow ><mo rspace="0em" >∂</mo><mi >x</mi></mrow></mfrac><mo
    lspace="0em" rspace="0em"  >​</mo><mfrac ><mrow ><mo rspace="0em" >∂</mo><msub
    ><mi  >T</mi><mi >y</mi></msub></mrow><mrow ><mo rspace="0em" >∂</mo><mi >y</mi></mrow></mfrac><mo
    lspace="0em" rspace="0em"  >​</mo><mfrac ><mrow ><mo rspace="0em" >∂</mo><msub
    ><mi  >T</mi><mi >y</mi></msub></mrow><mrow ><mo rspace="0em" >∂</mo><mi >z</mi></mrow></mfrac><mo
    lspace="0em" rspace="0em"  >​</mo><mfrac ><mrow ><mo rspace="0em" >∂</mo><msub
    ><mi  >T</mi><mi >z</mi></msub></mrow><mrow ><mo rspace="0em" >∂</mo><mi >x</mi></mrow></mfrac><mo
    lspace="0em" rspace="0em"  >​</mo><mfrac ><mrow ><mo rspace="0em" >∂</mo><msub
    ><mi  >T</mi><mi >z</mi></msub></mrow><mrow ><mo rspace="0em" >∂</mo><mi >y</mi></mrow></mfrac><mo
    lspace="0em" rspace="0em"  >​</mo><mfrac ><mrow ><mo rspace="0em" >∂</mo><msub
    ><mi  >T</mi><mi >z</mi></msub></mrow><mrow ><mo rspace="0em" >∂</mo><mi >z</mi></mrow></mfrac></mrow></mrow><mo
    lspace="0em"  >.</mo></mrow><annotation-xml encoding="MathML-Content" ><apply
    ><ci  >𝐽</ci><apply ><ci ><merror ><mtext  >{vmatrix}</mtext></merror></ci><apply
    ><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑇</ci><ci
    >𝑥</ci></apply></apply><apply ><ci >𝑥</ci></apply></apply><ci >&</ci><apply  ><apply
    ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑇</ci><ci >𝑥</ci></apply></apply><apply
    ><ci  >𝑦</ci></apply></apply><apply ><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑇</ci><ci >𝑥</ci></apply></apply><apply ><ci >𝑧</ci></apply></apply><apply ><apply  ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑇</ci><ci >𝑦</ci></apply></apply><apply
    ><ci >𝑥</ci></apply></apply><apply ><apply  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑇</ci><ci >𝑦</ci></apply></apply><apply ><ci >𝑦</ci></apply></apply><apply ><apply  ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑇</ci><ci >𝑦</ci></apply></apply><apply
    ><ci >𝑧</ci></apply></apply><apply ><apply  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑇</ci><ci >𝑧</ci></apply></apply><apply ><ci >𝑥</ci></apply></apply><apply ><apply  ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑇</ci><ci >𝑧</ci></apply></apply><apply
    ><ci >𝑦</ci></apply></apply><apply ><apply  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑇</ci><ci >𝑧</ci></apply></apply><apply ><ci >𝑧</ci></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >J=\vmatrix\frac{\partial T_{x}}{\partial x}&\frac{\partial
    T_{x}}{\partial y}\frac{\partial T_{x}}{\partial z}\\ \frac{\partial T_{y}}{\partial
    x}\frac{\partial T_{y}}{\partial y}\frac{\partial T_{y}}{\partial z}\\ \frac{\partial
    T_{z}}{\partial x}\frac{\partial T_{z}}{\partial y}\frac{\partial T_{z}}{\partial
    z}\\ .</annotation></semantics></math> |  | (22) |
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: \( J = \begin{vmatrix}
- en: '![Refer to caption](img/23f7f39f0785585a6ad3c91d33dedb6a.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/23f7f39f0785585a6ad3c91d33dedb6a.png)'
- en: 'Fig. 4: Examples of the checkerboard problem (a) and the self-intersection
    problem (b) for the central difference approximated Jacobian determinant $|J|$
    on a $3\times 3$ grid. The transformations are visualized as a displacement field
    and the displacement of the center pixel is highlighted in red. In (a), the central
    difference approximated $|J|$ for the center pixel equals one but the displacement
    of the center pixel is *not* involved in the computation. Even if the center pixel
    moves outside the field of view, the central difference approximated $|J|$ still
    equals one. In (b), the transformation around the center pixel already introduced
    folding in space regardless of the displacement of the center pixel but the central
    difference approximated $|J|$ is positive.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：中心差分近似的雅可比行列式 $|J|$ 在 $3\times 3$ 网格上的棋盘格问题 (a) 和自交问题 (b) 的示例。变换被可视化为位移场，中心像素的位移用红色突出显示。在
    (a) 中，中心像素的中心差分近似 $|J|$ 等于 1，但中心像素的位移 *未* 参与计算。即使中心像素移出了视野，中心差分近似的 $|J|$ 仍然等于
    1。在 (b) 中，中心像素周围的变换已经引入了空间的折叠，而不管中心像素的位移如何，但中心差分近似的 $|J|$ 是正的。
- en: 'Ashburner et al. [[7](#bib.bib7)] considered the transformations to be locally
    affine, and the Jacobian determinant could be computed using singular value decomposition.
    More generally, the Jacobian of a dense nonlinear transformation is estimated
    through numerical approximation using finite difference methods. In a recent study, Liu
    et al. [[198](#bib.bib198)] showed that when approximating the Jacobian using
    forward or backward difference, it is implicitly assumed that the digital transformations
    are linearly interpolated on a tetrahedron mesh grid. Importantly, they showed
    that the Jacobian determinant, when approximated using central difference, results
    in the checkerboard and self-intersection problems. Consequently, it consistently
    underestimates non-diffeomorphic spaces. Figure [4](#S6.F4 "Fig. 4 ‣ 6.2 Regularity
    Measures ‣ 6 Registration Evaluation Metrics ‣ A survey on deep learning in medical
    image registration: new technologies, uncertainty, evaluation metrics, and beyond")
    shows examples of the checkerboard problem and the self-intersection problem in
    2D. In both cases, the central difference approximated Jacobian determinants are
    positive, but the underlying transformations introduce folding of space (under
    the assumption that the digital transformations are piecewise linear). They conclude
    that for a 2D transformation, four unique finite difference approximations of
    $|J|$’s must be positive to ensure the entire domain is invertible and free of
    folding; in 3D, ten unique finite differences approximations of $|J|$’s are required
    to be positive. Note that their method is closely related to simplex counting [[140](#bib.bib140)]
    used in deformation-based volumetric change estimation. Because of the issues
    associated with central difference approximation of $|J|$’s, Liu et al. [[198](#bib.bib198)]
    recommend using non-diffeomorphic volume to accurately reflect the non-diffeomorphism
    introduced by transformations.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 'Ashburner 等人 [[7](#bib.bib7)] 认为这些变换在局部是仿射的，并且雅可比行列式可以通过奇异值分解来计算。更一般地，密集非线性变换的雅可比矩阵是通过使用有限差分方法的数值近似来估算的。在最近的一项研究中，Liu
    等人 [[198](#bib.bib198)] 表明，当使用前向或后向差分来近似雅可比矩阵时，隐含假设数字变换在四面体网格上是线性插值的。重要的是，他们展示了当使用中心差分近似时，雅可比行列式会导致棋盘格和自交问题。因此，它一贯低估了非微分同胚空间。图
    [4](#S6.F4 "Fig. 4 ‣ 6.2 Regularity Measures ‣ 6 Registration Evaluation Metrics
    ‣ A survey on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond") 显示了 2D 中棋盘格问题和自交问题的示例。在这两种情况下，中心差分近似的雅可比行列式都是正的，但基础变换引入了空间的折叠（假设数字变换是分段线性的）。他们得出结论，对于
    2D 变换，必须有四个唯一的有限差分近似 $|J|$ 为正，以确保整个领域是可逆的且没有折叠；在 3D 中，需要十个唯一的有限差分近似 $|J|$ 为正。请注意，他们的方法与用于基于形变的体积变化估计的单纯形计数
    [[140](#bib.bib140)] 密切相关。由于与 $|J|$ 的中心差分近似相关的问题，Liu 等人 [[198](#bib.bib198)] 推荐使用非微分同胚体积来准确反映变换引入的非微分同胚性。'
- en: The logarithm of the Jacobian determinant is also an important measure, especially
    for applications where it requires the volume of the underlying anatomy to be
    preserved [[277](#bib.bib277), [162](#bib.bib162)]. The logarithm is used to symmetrically
    weight local expansion and compression [[277](#bib.bib277), [183](#bib.bib183)].
    In recent works such as [[133](#bib.bib133), [37](#bib.bib37), [62](#bib.bib62),
    [42](#bib.bib42), [305](#bib.bib305)], the standard deviation of the logarithm
    of the Jacobian determinant has been used to quantify the smoothness of the displacement
    field. Additionally, the statistical distribution of the logarithm of the Jacobian
    determinant can be used as a visualization tool to reveal differences between
    registration algorithms [[187](#bib.bib187), [183](#bib.bib183)].
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 雅可比行列式的对数也是一个重要的衡量标准，特别是在需要保持基础解剖结构体积的应用中[[277](#bib.bib277), [162](#bib.bib162)]。对数用于对局部扩展和压缩进行对称加权[[277](#bib.bib277),
    [183](#bib.bib183)]。在近期的研究中，如[[133](#bib.bib133), [37](#bib.bib37), [62](#bib.bib62),
    [42](#bib.bib42), [305](#bib.bib305)]，雅可比行列式对数的标准差被用于量化位移场的平滑度。此外，雅可比行列式对数的统计分布可以作为可视化工具，揭示注册算法之间的差异[[187](#bib.bib187),
    [183](#bib.bib183)]。
- en: Similar to many surrogate measures, the regularity of the transformations can
    detect inaccurate transformations, but by itself, it is insufficient to provide
    adequate positive evidence for accurate transformations. For example, the identity
    transformation would be deemed a perfectly regularized transformation, but it
    would not provide a meaningful registration.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多替代度量类似，变换的规律性可以检测不准确的变换，但仅凭此不足以提供准确变换的充分正面证据。例如，身份变换将被视为完全规则化的变换，但它不会提供有意义的注册。
- en: 7 Applications of Medical Image Registration
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 医学图像配准的应用
- en: 7.1 Atlas Construction
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 图谱构建
- en: In computational anatomy, atlases have been an essential tool for investigating
    the variability of human organs across populations and facilitating the segmentation
    of organs in individual patients. Typically, atlases are constructed through an
    iterative averaging process (*i.e.*, procrustean averaging [[211](#bib.bib211)])
    using a population of patient images [[3](#bib.bib3), [58](#bib.bib58), [110](#bib.bib110),
    [166](#bib.bib166), [211](#bib.bib211), [10](#bib.bib10)]. This procedure commences
    with the registration of images to a common frame of reference, followed by the
    computation of an average based on the registered images, which serves as the
    atlas for the current iteration. The iteration cycle continues until convergence
    has been achieved, resulting in the final atlas. However, these traditional methods
    tend to blur regions exhibiting high-frequency deformations [[61](#bib.bib61)].
    This shortcoming arises from the averaging of intensities when constructing the
    atlas, which invariably results in the loss of high-frequency information essential
    for capturing anatomical details.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算解剖学中，图谱是研究人类器官在不同人群中变异性以及促进个体患者器官分割的关键工具。通常，图谱是通过迭代平均过程（*即*，普罗克鲁斯特平均[[211](#bib.bib211)]）来构建的，使用患者图像的集合[[3](#bib.bib3),
    [58](#bib.bib58), [110](#bib.bib110), [166](#bib.bib166), [211](#bib.bib211),
    [10](#bib.bib10)]。该过程从图像的注册开始，接着计算基于已注册图像的平均值，该平均值作为当前迭代的图谱。迭代周期持续直到收敛，得到最终图谱。然而，这些传统方法往往会模糊显示高频变形的区域[[61](#bib.bib61)]。这一缺陷源于构建图谱时对强度的平均，这不可避免地导致了捕捉解剖细节所需的高频信息的丢失。
- en: Recent advancements in learning-based registration have demonstrated significant
    improvements in the quality of constructed atlases while concurrently expediting
    the atlas construction process. Dalca et al. [[55](#bib.bib55)] pioneered the
    development of a brain atlas within a deep learning framework, in which an initial
    approximation of the atlas is derived from the mean of the brain images under
    study. This atlas is then jointly optimized with a registration network, employing
    the VoxelMorph architecture to align the atlas with individual patient images.
    Throughout the training process, both the atlas and the registration network weights
    are updated. To promote an unbiased atlas and enhance spatial smoothness in the
    resulting deformation fields, the authors introduce a Gaussian-inspired prior.
    This prior serves to penalize sharp deformation changes while simultaneously encouraging
    minimal average deformation across the entire dataset. Moreover, patient demographic
    information is conditioned into the network architecture, facilitating the generation
    of conditional atlases that vary according to the specific attributes of different
    individuals. This work has inspired a variety of applications. For instance, Cheng
    et al. [[49](#bib.bib49)] establish continuous spatio-temporal cortical surface
    atlases for neonatal brains. Similarly, both Zhao et al. [[376](#bib.bib376)]
    and Bastiaansen et al. [[16](#bib.bib16)] construct continuous spatio-temporal
    atlases for fetal and infant brains. Zhao *et al.* developed a multi-scale spherical
    registration network featuring group-wise registration, while Bastiaansen *et
    al.* applied group-wise registration to volumetric ultrasound images. Alternatively, Yu
    et al. [[366](#bib.bib366)] constructed an unconditional and universal atlas while
    incorporating demographic information into the displacement field generation.
    This approach explicitly models morphological changes related to attributes as
    a diffeomorphic deformation, which captures variations in shape and size. Recognizing
    that the necessity for images to be affinely aligned in a preprocessing step as
    suggested in [[55](#bib.bib55)] could not adequately capture the dynamic size
    and shape development of fetal brain structures, Chen et al. [[43](#bib.bib43)]
    proposed incorporating an affine network, conditioned on patient demographic data,
    to register the constructed atlas to individual patient images. This approach
    preserves the dynamic size and shape variations of patients at different ages.
    Li et al. [[190](#bib.bib190)] proposed integrating the segmentation produced
    by a segmentation network into the atlas construction method proposed in [[55](#bib.bib55)].
    This method enables the joint training of segmentation and registration networks
    while simultaneously constructing both image and segmentation atlases. Similarly, Sinclair
    et al. [[298](#bib.bib298)] embraced the concept of jointly training segmentation
    and registration networks. They were motivated by the observation that segmentation
    networks often yield spurious voxel-wise predictions. By warping the label map
    of the constructed atlas to match the segmentation prediction through learning-based
    diffeomorphic registration, the topology of the original anatomical structure
    can be preserved, thus avoiding the potential segmentation errors produced by
    the segmentation network. Drawing inspiration from Dalca et al. [[55](#bib.bib55)]
    and Shu et al. [[292](#bib.bib292)], Siebert et al. [[295](#bib.bib295)] proposed
    using a shared encoder to extract features from input images, followed by two
    decoders. One decoder generates an unconditional atlas, while the other produces
    deformation fields that warp the atlas to individual images. To improve registration
    performance and enforce unbiased atlas construction, they introduced an inverse
    consistency and a bias reduction loss, in addition to the commonly seen similarity
    measure and deformation regularizer. In a related study, Wu et al. [[345](#bib.bib345)]
    proposed a closed-form update for constructing the atlas by leveraging pre-trained
    registration networks as a priori knowledge of the deformation field. Their approach
    involves an alternating update process for both the deformation field, which warps
    the atlas, and the atlas itself. This method results in an atlas construction
    framework that is independent of the registration model choice, offering flexibility
    in its application.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 最近在基于学习的配准技术方面的进展显示，构建的图谱质量有了显著提高，同时加快了图谱构建过程。Dalca等人[[55](#bib.bib55)] 开创了在深度学习框架内开发脑图谱的方法，其中图谱的初步近似是通过研究中的脑图像均值获得的。然后，这个图谱与配准网络共同优化，使用VoxelMorph架构将图谱与单个患者图像对齐。在训练过程中，图谱和配准网络的权重都会更新。为了促进图谱的公正性并增强结果变形场的空间平滑性，作者引入了一种受高斯启发的先验。该先验旨在惩罚尖锐的变形变化，同时鼓励整个数据集的平均变形最小化。此外，患者的人口统计信息被纳入网络架构中，促进了条件图谱的生成，这些图谱根据不同个体的特定属性而有所变化。这项工作激发了各种应用。例如，Cheng等人[[49](#bib.bib49)]
    为新生儿大脑建立了连续的时空皮层表面图谱。类似地，Zhao等人[[376](#bib.bib376)] 和Bastiaansen等人[[16](#bib.bib16)]
    为胎儿和婴儿大脑构建了连续的时空图谱。Zhao *et al.* 开发了一个多尺度球形配准网络，具有组间配准功能，而Bastiaansen *et al.*
    将组间配准应用于体积超声图像。或者，Yu等人[[366](#bib.bib366)] 在构建无条件和通用图谱时，将人口统计信息融入位移场生成中。这种方法明确地将与属性相关的形态变化建模为一个
    diffeomorphic 变形，从而捕捉形状和大小的变化。认识到[[55](#bib.bib55)]中建议的图像在预处理步骤中需要仿射对齐这一必要条件无法充分捕捉胎儿大脑结构的动态大小和形状发展，Chen等人[[43](#bib.bib43)]
    提出了将以患者人口统计数据为条件的仿射网络纳入到图谱配准中，以将构建的图谱注册到单个患者图像中。这种方法保留了不同年龄患者的动态大小和形状变化。Li等人[[190](#bib.bib190)]
    提出了将由分割网络生成的分割结果整合到[[55](#bib.bib55)] 提出的图谱构建方法中。这种方法允许在同时构建图像和分割图谱的同时联合训练分割和配准网络。类似地，Sinclair等人[[298](#bib.bib298)]
    采用了联合训练分割和配准网络的概念。他们受到分割网络常常产生虚假体素级预测的观察启发。通过基于学习的 diffeomorphic 配准将构建的图谱的标签图像扭曲以匹配分割预测，可以保留原始解剖结构的拓扑，从而避免分割网络产生的潜在分割错误。受到Dalca等人[[55](#bib.bib55)]
    和Shu等人[[292](#bib.bib292)] 的启发，Siebert等人[[295](#bib.bib295)] 提出了使用共享编码器从输入图像中提取特征，然后使用两个解码器。一个解码器生成无条件图谱，而另一个生成将图谱扭曲到单个图像的变形场。为了提高配准性能并强制公正的图谱构建，他们引入了反向一致性和偏差减少损失，此外还包括常见的相似性度量和变形正则化器。在一项相关研究中，Wu等人[[345](#bib.bib345)]
    提出了利用预训练配准网络作为变形场先验知识来构建图谱的闭式更新方法。他们的方法涉及变形场（扭曲图谱）和图谱本身的交替更新过程。这种方法产生了一个独立于配准模型选择的图谱构建框架，提供了应用的灵活性。
- en: Researchers have explored various strategies to enhance the quality of the constructed
    atlases. Dey et al. [[61](#bib.bib61)] improved the constructed atlas by incorporating
    adversarial learning, which improved both the sharpness and centrality of the
    resulting atlas. In a similar vein, He and Chung [[123](#bib.bib123)] aimed to
    improve the atlas’ sharpness through adversarial learning and by integrating edge
    information derived from anatomical label maps. Additionally, Pei et al. [[254](#bib.bib254)]
    leveraged anatomical label maps to improve the quality of the constructed atlas
    by applying anatomical consistency supervision. However, Ding and Niethammer [[68](#bib.bib68)]
    contended that the importance of atlas sharpness is secondary to the registration
    model’s ability to align corresponding points between images in the atlas space.
    Therefore, they focused on the registration model upon which the atlas construction
    is based and proposed using the constructed atlas as a bridge. In their method,
    an image is first warped to align with an atlas and then further warped to match
    the target image using the registration network. This process facilitates a direct
    comparison between the warped image and the target image while enabling the construction
    and evaluation of the atlas without requiring segmentation of the atlas itself.
    Inspired by implicit neural shape representations [[225](#bib.bib225)],  Yang
    et al. [[359](#bib.bib359)] proposed constructing atlases of anatomical shapes
    using a continuous occupancy grid instead of representing them in a voxel-based
    manner. Given the latent representation of the shape, this alternative approach
    constructs an atlas based on the linear combination of a learned template matrix.
    Their method offers a novel perspective on atlas representation, diverging from
    traditional voxel-based representations.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员探索了各种策略来提升构建图谱的质量。Dey 等人 [[61](#bib.bib61)] 通过引入对抗性学习改进了构建的图谱，这不仅提高了图谱的清晰度，还提升了其中心性。类似地，He
    和 Chung [[123](#bib.bib123)] 通过对抗性学习和整合来自解剖标签图的边缘信息来提高图谱的清晰度。此外，Pei 等人 [[254](#bib.bib254)]
    通过应用解剖一致性监督利用解剖标签图提升了构建图谱的质量。然而，Ding 和 Niethammer [[68](#bib.bib68)] 认为图谱清晰度的重要性次于注册模型在图谱空间中对齐图像间对应点的能力。因此，他们关注于图谱构建所依赖的注册模型，并提出使用构建的图谱作为桥梁。在他们的方法中，首先将图像变形以对齐图谱，然后使用注册网络进一步变形以匹配目标图像。这个过程使得变形后的图像与目标图像之间的直接比较成为可能，同时在不需要对图谱进行分割的情况下构建和评估图谱。受到隐式神经形状表示
    [[225](#bib.bib225)] 的启发，Yang 等人 [[359](#bib.bib359)] 提出了使用连续占据网格来构建解剖形状的图谱，而不是采用基于体素的方式。考虑到形状的潜在表示，这种替代方法基于学习的模板矩阵的线性组合来构建图谱。他们的方法为图谱表示提供了一种新颖的视角，偏离了传统的基于体素的表示。
- en: Advancements in learning-based atlas construction methods have facilitated the
    fast construction of high-quality atlases. The following subsection explores the
    application of the atlases and learning-based image registration in achieving
    the goal of image segmentation.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 基于学习的图谱构建方法的进步促进了高质量图谱的快速构建。以下小节探讨了图谱和基于学习的图像配准在实现图像分割目标中的应用。
- en: 7.2 Multi-atlas Segmentation
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 多图谱分割
- en: Multi-atlas segmentation is a well-established registration-based segmentation
    technique in existence for several decades [[278](#bib.bib278), [151](#bib.bib151)].
    The typical approach involves registering atlas images or their patches to a target
    image and fusing the propagated atlas labels. For deformable registration-based
    multi-atlas methods, the process of pairwise registration between atlas images
    and the target image can be computationally expensive and time-consuming. However,
    recent advancements in deep learning-based deformable registration algorithms
    provide a promising solution to address the speed issue and potentially improve
    the accuracy of registration, which can subsequently improve the accuracy of multi-atlas
    segmentation. While many works have explored the use of deep networks to improve
    the fusion of multiple registered atlas images [[381](#bib.bib381), [86](#bib.bib86),
    [349](#bib.bib349), [350](#bib.bib350), [358](#bib.bib358)], there are relatively
    few studies that incorporate deep learning-based deformable registration algorithms
    into their pipeline.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 多图谱分割是一种基于配准的分割技术，已经存在了几十年[[278](#bib.bib278), [151](#bib.bib151)]。典型的方法包括将图谱图像或其片段与目标图像进行配准，并融合传播的图谱标签。对于基于可变形配准的多图谱方法，图谱图像与目标图像之间的成对配准过程可能计算量大且耗时。然而，最近在基于深度学习的可变形配准算法方面的进展提供了一个有希望的解决方案，可以解决速度问题，并有可能提高配准的准确性，从而提高多图谱分割的准确性。虽然许多研究已经探索了使用深度网络来改善多个注册图谱图像的融合[[381](#bib.bib381),
    [86](#bib.bib86), [349](#bib.bib349), [350](#bib.bib350), [358](#bib.bib358)]，但相对较少的研究将基于深度学习的可变形配准算法纳入其流程中。
- en: Ding *et al.* [[65](#bib.bib65), [66](#bib.bib66)] proposed VoteNet, which predicts
    a voxel probability of the agreement between registered atlas images and the segmentation
    target image. They adopted Quicksilver [[362](#bib.bib362)] as their registration
    algorithm to speed up the pairwise registration process. Their follow-up work [[67](#bib.bib67)]
    experimented with improving the initial registration results from Quicksilver
    by incorporating a registration refinement step. The results showed that registration
    accuracy is a critical factor in achieving accurate multi-atlas segmentation.
    In Ding et al. [[63](#bib.bib63)], the authors addressed the challenging problem
    of cross-modality multi-atlas segmentation. They proposed a deep network that
    learns the bi-directional registration between atlas images and the target image,
    as well as a second network that estimates the weights for label fusion. To account
    for the modality differences between the atlas and target images, they used Dice
    loss as a similarity measure to train their registration network and conditional
    entropy to train the fusion network. For registering 3D first-trimester ultrasound
    images, Bastiaansen et al. [[15](#bib.bib15)] proposed a two-stage network for
    learning an affine transformation. They then applied the VoxelMorph architecture
    to perform deformable registration on the affinely aligned images. The segmentation
    of the target images was achieved by propagating the labels of the atlas images
    and combining them using majority voting.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Ding *et al.* [[65](#bib.bib65), [66](#bib.bib66)] 提出了 VoteNet，该方法预测注册图谱图像与分割目标图像之间的体素一致性概率。他们采用了
    Quicksilver [[362](#bib.bib362)] 作为配准算法，以加快成对配准过程。他们的后续工作[[67](#bib.bib67)] 通过引入配准精细化步骤，实验了改进
    Quicksilver 的初始配准结果。结果显示，配准准确性是实现准确多图谱分割的关键因素。在 Ding et al. [[63](#bib.bib63)]
    的研究中，作者解决了跨模态多图谱分割的挑战性问题。他们提出了一个深度网络，学习图谱图像与目标图像之间的双向配准，以及一个第二个网络来估计标签融合的权重。为了考虑图谱和目标图像之间的模态差异，他们使用
    Dice 损失作为相似性度量来训练其配准网络，并使用条件熵来训练融合网络。为了配准 3D 第一孕期超声图像，Bastiaansen et al. [[15](#bib.bib15)]
    提出了一个两阶段网络来学习仿射变换。然后，他们应用 VoxelMorph 架构对仿射对齐的图像进行可变形配准。通过传播图谱图像的标签并使用多数投票将其结合，达到了目标图像的分割。
- en: 'The good performance of supervised training in image segmentation could be
    a reason for the relative lack of research on deep learning-based registration
    in multi-atlas segmentation. Deep neural networks have demonstrated impressive
    results in supervised image segmentation tasks, making them a popular choice for
    many researchers. However, the performance of single atlas segmentation is often
    used to evaluate the accuracy of a registration algorithm, as discussed in Section [3.5](#S3.SS5
    "3.5 Auxiliary Anatomical Information ‣ 3 Loss Functions ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond"). Due to the close relationship between registration and segmentation,
    there is an increasing interest in exploring the possibility of integrating the
    learning of segmentation and registration [[298](#bib.bib298), [170](#bib.bib170),
    [355](#bib.bib355)]. Overall, the use of deep learning-based registration in multi-atlas
    segmentation is still in its early stages, and there is a significant opportunity
    for further research.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 监督训练在图像分割中的良好表现可能是多图谱分割中基于深度学习的配准研究相对不足的原因。深度神经网络在监督图像分割任务中展示了令人印象深刻的结果，使其成为许多研究者的热门选择。然而，单图谱分割的表现常用于评估配准算法的准确性，如第[3.5](#S3.SS5
    "3.5 辅助解剖信息 ‣ 3 损失函数 ‣ 关于深度学习在医学图像配准中的应用：新技术、不确定性、评估指标及其他")节所述。由于配准与分割之间的紧密关系，越来越多的研究者对探索分割与配准学习整合的可能性表示兴趣[[298](#bib.bib298),
    [170](#bib.bib170), [355](#bib.bib355)]。总体而言，基于深度学习的多图谱分割中的配准仍处于初期阶段，还有很大的进一步研究机会。
- en: 7.3 Uncertainty
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 不确定性
- en: Accurate registration is critical for many medical image analysis applications,
    such as image-guided surgery, radiation therapy, and longitudinal studies. However,
    registration uncertainty can arise due to factors such as training data artifacts
    or predictive model variances. To address this issue, incorporating registration
    uncertainty into medical image analysis can help guide the interpretation of the
    registration results and improve the reliability of various analysis tasks.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 精确的配准对许多医学图像分析应用至关重要，例如图像引导手术、放射治疗和纵向研究。然而，配准不确定性可能由于训练数据伪影或预测模型变异等因素而出现。为了解决这一问题，将配准不确定性纳入医学图像分析中可以帮助指导配准结果的解释，并提高各种分析任务的可靠性。
- en: In clinical decision-making, understanding registration uncertainty is critical
    for image-guided surgery and radiation therapy. The absence of proper registration
    uncertainty awareness may lead surgeons to presume a substantial registration
    error throughout the entire region based on a large error in a single location,
    resulting in the total disregard of registration. Furthermore, the lack of registration
    uncertainty may also cause surgeons to place unwarranted confidence in regions
    with inaccurate registration, resulting in potentially severe consequences.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在临床决策中，了解配准不确定性对于图像引导手术和放射治疗至关重要。缺乏对配准不确定性的正确认识可能导致外科医生根据某一位置的大误差假设整个区域存在显著的配准误差，从而完全忽视配准。此外，配准不确定性的缺乏还可能使外科医生对配准不准确的区域过度自信，从而导致潜在的严重后果。
- en: For image-guided surgery, Risholm et al. [[272](#bib.bib272)] showed that the
    registration uncertainty increased at the site of resection using clinical data
    from neurosurgery for resection of brain tumors, which demonstrated the potential
    utility of registration uncertainty in recognizing the surgical regions and guiding
    surgery. For radiation therapy, Risholm et al. [[271](#bib.bib271)] had previously
    presented a probabilistic framework to estimate the accumulated radiation dose
    and corresponding dose uncertainty delivered to significant anatomical structures
    during radiation therapy, such as the primary tumor and healthy surrounding organs.
    The uncertainty in the estimated dose directly results from registration uncertainty
    in the deformation used to align daily cone-beam CT images with planning CT. The
    accumulated radiation dose is an important metric to monitor during treatment,
    potentially requiring treatment plan adaptation to conform to the current patient
    anatomy.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像引导手术，Risholm 等人[[272](#bib.bib272)]展示了使用神经外科脑肿瘤切除的临床数据，配准不确定性在切除部位增加，这展示了配准不确定性在识别手术区域和引导手术中的潜在实用性。对于放射治疗，Risholm
    等人[[271](#bib.bib271)] 之前提出了一种概率框架来估计积累的辐射剂量及其对应的不确定性，涵盖了在放射治疗期间施加于主要肿瘤和健康周围器官的显著解剖结构的剂量。不确定性在估计剂量中直接来源于用于将每日锥束
    CT 图像与规划 CT 对齐的变形中的配准不确定性。积累的辐射剂量是治疗期间需要监控的重要指标，可能需要调整治疗计划以适应当前患者的解剖结构。
- en: A study by Nenoff et al. [[239](#bib.bib239)] employed six different deformable
    registration algorithms to analyze dose uncertainty in proton therapy and investigate
    their impact on dose accumulation for non-small cell lung cancer patients with
    inter-fractional anatomy variations. The results show that dose degradation caused
    by anatomical changes was more pronounced than the uncertainty arising from using
    different deformable image registration algorithms for dose accumulation. However,
    accumulated dose variations between these algorithms can still be substantial,
    leading to additional dose uncertainty.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: Nenoff 等人[[239](#bib.bib239)]采用六种不同的可变形配准算法分析了质子治疗中的剂量不确定性，并调查了它们对非小细胞肺癌患者因间隙解剖变化而剂量积累的影响。结果表明，解剖变化导致的剂量退化比使用不同的可变形图像配准算法进行剂量积累所产生的不确定性更为明显。然而，这些算法之间积累的剂量变化仍然可能很大，导致额外的剂量不确定性。
- en: In longitudinal medical image analysis, registration is an essential step because
    it enables the comparison of measurements taken at different time points, which
    is necessary for correcting anatomical variability and tracking changes over time.
    Registration uncertainty estimation can be beneficial for longitudinal image processing
    tasks, such as image smoothing, segmentation prior propagation, joint label fusion,
    and others. Simpson et al. [[297](#bib.bib297)] proposed an approach to calculate
    the deformable registration uncertainty using a probabilistic registration framework,
    integrating the uncertainty into spatially normalized statistics for adaptive
    image smoothing. This method showed improved classification results in longitudinal
    MR brain images acquired from Alzheimer’s Disease Neuroimaging Initiative compared
    to not smoothing or using a straightforward Gaussian filter kernel.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在纵向医学图像分析中，配准是一个关键步骤，因为它使得可以比较在不同时间点采集的测量数据，这对于纠正解剖变化和跟踪时间变化是必要的。估计配准不确定性对纵向图像处理任务，如图像平滑、分割先验传播、联合标签融合等，有益。Simpson
    等人[[297](#bib.bib297)]提出了一种使用概率配准框架计算可变形配准不确定性的方法，将不确定性集成到空间标准化统计中以实现自适应图像平滑。与不进行平滑或使用简单的高斯滤波器核相比，该方法在阿尔茨海默病神经影像学倡议中获得的纵向
    MR 脑图像中显示出改进的分类结果。
- en: In summary, incorporating registration uncertainty into medical image registration
    can facilitate interpreting registration results and improve the reliability of
    various medical image analysis tasks. It is crucial for clinicians to understand
    registration uncertainty and its potential applications in clinical decision-making.
    Further research is needed to explore other potential applications of registration
    uncertainty.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，将注册不确定性纳入医学图像配准可以帮助解读配准结果，并提高各种医学图像分析任务的可靠性。临床医生理解注册不确定性及其在临床决策中的潜在应用至关重要。进一步的研究需要探索注册不确定性的其他潜在应用。
- en: 7.4 Motion Estimation
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4 运动估计
- en: In the context of medical images, deep learning-based motion estimation has
    been closely associated with the unsupervised optical flow [[164](#bib.bib164),
    [308](#bib.bib308), [19](#bib.bib19)] and point tracking [[182](#bib.bib182),
    [120](#bib.bib120), [269](#bib.bib269), [19](#bib.bib19)] techniques within the
    computer vision domain. However, the application of motion estimation in medical
    imaging presents unique challenges, including limited training data, heterogeneous
    patient data for testing, and special desired properties on the motion field,
    such as diffeomorphism (to preserve anatomical relationships) and incompressibility (to
    preserve anatomical integrity). Deep learning-based registration has demonstrated
    successful outcomes in estimating motion for various organs, such as the human
    heart, brain, lungs, and tongue. Registration-based motion estimation plays a
    significant role in enabling the assessment of changes in the position, shape,
    and size of organs over time. Multiple dynamic imaging modalities are used for
    motion estimation in medical imaging, including but not limited to cine images,
    tagged-MRI [[11](#bib.bib11), [12](#bib.bib12)], and echocardiography.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在医学图像的背景下，基于深度学习的运动估计与计算机视觉领域中的无监督光流[[164](#bib.bib164)、[308](#bib.bib308)、[19](#bib.bib19)]和点跟踪[[182](#bib.bib182)、[120](#bib.bib120)、[269](#bib.bib269)、[19](#bib.bib19)]技术密切相关。然而，运动估计在医学成像中的应用面临独特挑战，包括训练数据有限、用于测试的异质患者数据以及运动场的特殊期望特性，如微分同胚性（以保留解剖关系）和不可压缩性（以保留解剖完整性）。基于深度学习的配准在估计各种器官的运动方面表现出了成功的结果，例如人类的心脏、大脑、肺和舌头。基于配准的运动估计在评估器官随时间的位移、形状和大小变化方面发挥了重要作用。多种动态成像模式被用于医学成像中的运动估计，包括但不限于运动影像、标记MRI[[11](#bib.bib11)、[12](#bib.bib12)]和超声心动图。
- en: Cine images are a temporal sequence of MR images captured in quick succession,
    allowing for the monitoring of organ movement and deformation over time. Recent
    research [[263](#bib.bib263), [236](#bib.bib236), [224](#bib.bib224), [368](#bib.bib368),
    [265](#bib.bib265), [204](#bib.bib204), [367](#bib.bib367)] has successfully applied
    deep learning-based registration techniques to cine images. For example, FOAL [[368](#bib.bib368)]
    proposed online optimization to mitigate distribution mismatch between the training
    and testing datasets for motion estimation, using meta-learning techniques to
    enable more efficient online optimization with fewer gradient descent steps and
    smaller data samples, which differs from instance-specific optimization [[14](#bib.bib14)].
    Yu et al. [[367](#bib.bib367)] applied similarity and smoothness loss to multiple
    scales of motion fields (pyramid) using a deep supervision strategy.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 运动影像是快速连续捕捉的MR图像的时间序列，允许监测器官的运动和变形。近期研究[[263](#bib.bib263)、[236](#bib.bib236)、[224](#bib.bib224)、[368](#bib.bib368)、[265](#bib.bib265)、[204](#bib.bib204)、[367](#bib.bib367)]
    已成功将基于深度学习的配准技术应用于运动影像。例如，FOAL [[368](#bib.bib368)] 提出了在线优化方法，以减轻训练和测试数据集之间的分布不匹配，使用元学习技术实现更高效的在线优化，减少梯度下降步骤和样本量，这与实例特定优化[[14](#bib.bib14)]不同。Yu
    *等* [[367](#bib.bib367)] 将相似性和光滑性损失应用于运动场的多个尺度（金字塔），使用深度监督策略。
- en: The relatively uniform signal within tissues from cine images and the lack of
    reliable, identifiable landmarks have motivated the exploration of additional
    regularization methods for estimating motion that is biologically plausible and
    clinically reliable. For example, Qin *et al.* [[265](#bib.bib265)] trained a
    variational autoencoder-based generative model to capture the prior of biomechanically
    plausible deformations by reconstructing simulated deformations using finite element
    models. This prior is then used as regularization during the training of the registration
    network. Lopez *et al.* [[204](#bib.bib204)] incorporated hyperelastic regularization
    terms into the framework of physics-informed neural networks [[267](#bib.bib267)]
    to estimate incompressible motion fields.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 运动影像中组织内信号相对均匀以及缺乏可靠、可识别的标志物激发了对额外正则化方法的探索，以估计生物学上合理和临床上可靠的运动。例如，Qin *等* [[265](#bib.bib265)]
    训练了一种基于变分自编码器的生成模型，通过使用有限元模型重建模拟变形来捕捉生物力学上合理的变形先验。这个先验随后被用作训练配准网络时的正则化。Lopez *等*
    [[204](#bib.bib204)] 将超弹性正则化项纳入物理信息神经网络[[267](#bib.bib267)]的框架中，以估计不可压缩的运动场。
- en: Tagged-MRI, on the other hand, employs a spatially modulated periodic pattern
    to magnetize tissue temporarily, producing transient tags in the image sequence
    that move with the tissue and capture motion information. It allows for tracking
    the motion of inner tissue where the region does not have contrast on cine images.
    DeepTag [[364](#bib.bib364)] takes raw 2D tagged images as input and estimates
    the incremental motion between two consecutive frames using a bi-directional registration
    network. Then it composes the incremental motion field to estimate motion between
    any two time frames. Harmonic phase images [[247](#bib.bib247)] have been found
    to be more robust to tag fading and imaging artifacts during motion tracking than
    raw tagged images. DRIMET [[20](#bib.bib20)] proposed a simple sinusoidal transformation
    on the harmonic phase images, enabling end-to-end training for estimating a 3D
    dense motion field from tagged-MRI. It also incorporates a Jacobian determinant-based
    loss that penalizes symmetrically for contraction and expansion to estimate a
    biologically-plaussible incompressible motion field. DRIMET shows promising results
    in terms of superior registration accuracy, a comparable degree of incompressibility,
    and faster speed over its traditional iterative-based counterparts [[351](#bib.bib351),
    [222](#bib.bib222)].
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，标记MRI采用空间调制的周期性模式来暂时磁化组织，在图像序列中产生随组织移动的瞬态标签并捕捉运动信息。它允许跟踪内层组织的运动，即使该区域在Cine图像上没有对比度。DeepTag
    [[364](#bib.bib364)] 以原始2D标记图像作为输入，并使用双向配准网络估计两个连续帧之间的增量运动。然后，它将增量运动场组合起来，以估计任意两个时间帧之间的运动。与原始标记图像相比，谐波相位图像
    [[247](#bib.bib247)] 在运动跟踪过程中对标签褪色和成像伪影更具鲁棒性。DRIMET [[20](#bib.bib20)] 提出了对谐波相位图像进行简单的正弦变换，使得从标记MRI中估计3D密集运动场的端到端训练成为可能。它还结合了基于雅可比行列式的损失，针对收缩和膨胀对称惩罚，以估计生物学上合理的不可压缩运动场。DRIMET
    在注册精度、不可压缩性程度和速度方面显示出优于传统迭代方法的有希望的结果 [[351](#bib.bib351), [222](#bib.bib222)]。
- en: Numerous deep learning-based techniques have been devised to estimate 2D motion,
    and although this may be adequate for certain applications, tracking dense 3D
    motion is typically necessary or highly desirable when estimating the motion of
    biological structures. To address this issue, Meng *et al.* [[224](#bib.bib224)]
    integrate features extracted from multi-view 2D cine CMR images captured in both
    short-axis and long-axis planes to learn a 3D motion field of the heart. The edge
    map of myocardial wall is used as a shape regularization of the estimated motion
    field. Alternatively, DRIMET [[20](#bib.bib20)] uses sparsely acquired tagged
    images and interpolates them onto an isotropic grid with a resolution based on
    the in-plane resolution. This approach is based on the observation that the tag
    pattern changes slowly in the through-plane direction and therefore will not cause
    aliasing issues during sampling. By doing so, DRIMET is capable of tracking dense
    3D motion.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 许多基于深度学习的技术已经被开发出来用于估计2D运动，尽管这对于某些应用可能足够，但在估计生物结构运动时，跟踪密集的3D运动通常是必要的或非常期望的。为了解决这个问题，孟*等人*
    [[224](#bib.bib224)] 整合了从短轴和长轴平面捕获的多视角2D Cine CMR图像中提取的特征，以学习心脏的3D运动场。心肌壁的边缘图被用作估计运动场的形状正则化。或者，DRIMET
    [[20](#bib.bib20)] 使用稀疏获取的标记图像，并将它们插值到基于平面分辨率的各向同性网格上。这种方法基于观察到标记模式在穿平面方向上变化缓慢，因此在采样过程中不会造成混叠问题。通过这样做，DRIMET
    能够跟踪密集的3D运动。
- en: Recent studies have shown that joint learning of segmentation and motion estimation
    can be mutually beneficial [[263](#bib.bib263), [311](#bib.bib311), [1](#bib.bib1)].
    For instance, Qin *et al.* [[263](#bib.bib263)] employ a dual-branch framework
    consisting of a segmentation branch and a motion estimation branch to simultaneously
    estimate motion and segmentation from a sequence of cardiac cine images. During
    training, a shared feature encoder is learned under the premise that joint features
    can complement both tasks. In contrast, Ta *et al.* [[311](#bib.bib311)] and Ahn [[1](#bib.bib1)]
    adopt a task-level approach to jointly tackle motion estimation and segmentation
    in the context of estimating cardiac motion from echocardiography. Specifically,
    they warp the segmentation (of one time frame) using the estimated motion field
    and regularize the motion field by incorporating shape information obtained from
    the segmentation. This approach differs from previous studies which couple motion
    estimation and segmentation at the feature-level, and may offer a novel perspective
    on joint learning of these tasks.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 近期研究表明，分割与运动估计的联合学习可以互相促进 [[263](#bib.bib263), [311](#bib.bib311), [1](#bib.bib1)]。例如，秦*等人* [[263](#bib.bib263)]
    采用了一个由分割分支和运动估计分支组成的双分支框架，以同时从一系列心脏电影图像中估计运动和分割。在训练过程中，在联合特征能够互补这两个任务的前提下，学习一个共享特征编码器。相比之下，塔*等人* [[311](#bib.bib311)]
    和安*[[1](#bib.bib1)] 采取了一种任务级的方法，在估计心脏运动的回声心动图的背景下，联合处理运动估计和分割。具体而言，他们使用估计的运动场来扭曲（一个时间帧的）分割，并通过结合从分割中获得的形状信息来对运动场进行正则化。这种方法不同于之前在特征级别上耦合运动估计和分割的研究，可能为这两项任务的联合学习提供了新的视角。
- en: In addition to MRIs and echocardiography, numerous deep learning-based algorithms
    have been developed for motion estimation with 4D-CT [[96](#bib.bib96), [137](#bib.bib137),
    [343](#bib.bib343), [87](#bib.bib87), [132](#bib.bib132), [158](#bib.bib158)].
    4D-CT imaging captures images at different phases of respiratory or cardiac cycles,
    providing valuable insights for lung imaging applications, including radiation
    therapy planning and lung function assessment. DIR-LAB [[34](#bib.bib34)] is a
    widely-used dataset, containing 4D CT images of ten patients, to evaluate 4D-CT
    registration techniques, with the aim of registering inspiration images to expiration
    images. This task is challenging due to the superimposed motion of the heart and
    lungs, which is larger in scale than the small lung structures being studied.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 MRI 和回声心动图之外，已经开发了众多基于深度学习的算法用于 4D-CT 的运动估计 [[96](#bib.bib96), [137](#bib.bib137),
    [343](#bib.bib343), [87](#bib.bib87), [132](#bib.bib132), [158](#bib.bib158)]。4D-CT
    成像在呼吸或心脏周期的不同阶段捕获图像，为肺部成像应用提供了宝贵的见解，包括放射治疗规划和肺功能评估。DIR-LAB [[34](#bib.bib34)]
    是一个广泛使用的数据集，包含十位患者的 4D CT 图像，用于评估 4D-CT 配准技术，目标是将吸气图像配准到呼气图像。由于心脏和肺部的运动叠加，超出了正在研究的小肺结构的规模，这一任务具有挑战性。
- en: LungRegNet [[96](#bib.bib96)] trains two separate networks to handle large lung
    motion. One network predicts large motion on a coarse scale, and the other network
    takes the coarsely warped image and fixed image as input to predict fine motion.
    In addition to similarity and smoothness losses, an adversarial loss is applied
    as extra regularization to prevent unrealistic deformed images. Hering *et al.* [[132](#bib.bib132)]
    employs a coarse-to-fine multi-level optimization strategy. The deformations of
    coarse levels provide an initial guess for subsequent finer levels. Networks are
    trained progressively, with each handling one level and initialized with parameters
    from the previous level. It incorporates a penalty for volume change and utilizes
    an $l2$ loss function to match corresponding keypoints that are automatically
    detected. Ho *et al.* [[137](#bib.bib137)] applied cycle-consistent training [[179](#bib.bib179)]
    to reduce foldings using two networks. After the first network’s forward pass,
    the warped and moving images are sent to the second network to predict inverse
    deformation, with a similarity loss applied to maximize the similarity between
    the moving images and inversely-deformed moving images. IDIR [[343](#bib.bib343)]
    use a multi-layer perceptron to represent the transformation function of coordinates
    and demonstrate the ability to incorporate the Jacobian regularizer, hyperelastic
    regularizer [[29](#bib.bib29)], and bending energy [[280](#bib.bib280)] into the
    framework. The resulting deformation is void of foldings and achieves a mean target
    registration error (TRE) of 1.07 mm on DIR-LAB datasets. However, this method
    requires more time compared to CNN-based approaches, prompting researchers to
    consider acceleration as a potential future direction.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: LungRegNet [[96](#bib.bib96)] 训练了两个独立的网络以处理大范围的肺部运动。一个网络在粗略尺度上预测大范围运动，另一个网络则将粗略变形的图像和固定图像作为输入来预测细微运动。除了相似性和光滑度损失外，还应用了对抗损失作为额外的正则化，以防止不现实的变形图像。Hering
    *et al.* [[132](#bib.bib132)] 采用了粗到细的多级优化策略。粗糙级别的变形提供了后续更精细级别的初步猜测。网络是逐级训练的，每个网络处理一个级别，并以来自前一级别的参数初始化。它包含了体积变化的惩罚，并利用
    $l2$ 损失函数来匹配自动检测到的相应关键点。Ho *et al.* [[137](#bib.bib137)] 应用了循环一致性训练 [[179](#bib.bib179)]
    以减少折叠问题，使用两个网络。经过第一个网络的前向传播后，变形的和移动的图像被发送到第二个网络，以预测逆变形，并应用相似性损失以最大化移动图像与逆变形移动图像之间的相似性。IDIR
    [[343](#bib.bib343)] 使用多层感知器来表示坐标的变换函数，并展示了将雅可比正则化器、超弹性正则化器 [[29](#bib.bib29)]
    和弯曲能量 [[280](#bib.bib280)] 纳入框架的能力。最终的变形没有折叠，并在 DIR-LAB 数据集上实现了 1.07 毫米的平均目标配准误差（TRE）。然而，与基于
    CNN 的方法相比，这种方法需要更多的时间，这促使研究人员考虑加速作为未来的潜在方向。
- en: In order to accurately register previously unseen images outside of training
    datasets, the application of one-shot learning has been employed for the estimation
    of lung motion [[87](#bib.bib87), [158](#bib.bib158)]. Fechter *et al.* [[87](#bib.bib87)]
    concatenated images captured at different phases in the channel dimension in order
    to leverage temporal information. To minimize memory requirements, they partitioned
    images into non-overlapping patches and applied a boundary smoothness constraint
    on the transitions between patches. Additionally, they utilized a coarse-to-fine
    approach by constructing an image pyramid, where the estimated vector fields of
    finer scales were added to the upsampled vector fields of coarser scales. The
    proposed method showed a competitive performance without the need for training
    in advance.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准确配准训练数据集之外的先前未见过的图像，应用了一次性学习方法来估计肺部运动 [[87](#bib.bib87), [158](#bib.bib158)]。Fechter
    *et al.* [[87](#bib.bib87)] 将不同阶段捕获的图像在通道维度上进行拼接，以利用时间信息。为了减少内存需求，他们将图像划分为不重叠的块，并在块之间的过渡上施加了边界光滑性约束。此外，他们通过构建图像金字塔采用了粗到细的方法，其中较细尺度的估计矢量场被添加到较粗尺度的上采样矢量场中。该方法在无需提前训练的情况下表现出了竞争力。
- en: 7.5 2D-3D Registration
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5 2D-3D 配准
- en: Recent progress in the field of interventional procedures for invasive treatment
    protocols has been associated with high precision in surgeries performed at a
    reasonable cost [[256](#bib.bib256), [69](#bib.bib69)]. In these procedures, 2D-3D
    registration plays a significant role in determining the spatial relationship
    between the 3D anatomical structures and 2D images, such as X-Ray fluoroscopic
    images, ultrasound image frames, or endoscopic images. 2D-3D medical image registration
    primarily involves registering 2D interventional images to 3D pre-operative CT/MR
    images, *i.e.*, to obtain the 3D geometric transformation that aligns with the
    2D view available. Conventional 2D-3D registration methods involve iterative optimization
    methods with similarity metrics [[215](#bib.bib215)] based on image intensity
    as the objective function. Due to the sparsity of spatial information derived
    from 2D images, the problem is non-convex, which may lead to convergence at a
    local minimum if the initial estimate is not sufficiently close to the correct
    one. 2D-3D registration is a problem with a minimum of six degrees of freedom
    which may also lead to registration ambiguity as the spatial information along
    each projection line is compressed to a single point in the 2D plane. This high-dimensional
    optimization problem increases the difficulty of determining the parameters associated
    with the depth of anatomical features in the 3D volume. Alternatively, deep-learning-based
    methods have gained popularity for this application as they do not require explicit
    functional mappings [[321](#bib.bib321)]. In this discussion, we briefly highlight
    recent advancements in 2D-3D registration, while directing interested readers
    to [[321](#bib.bib321)] for a comprehensive review of the influence of various
    learning-based methods in this area.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在侵入性治疗方案的介入程序领域的最新进展与在合理成本下进行的高精度手术相关[[256](#bib.bib256), [69](#bib.bib69)]。在这些程序中，2D-3D配准在确定3D解剖结构与2D图像（例如X光荧光图像、超声图像帧或内窥镜图像）之间的空间关系方面发挥了重要作用。2D-3D医学图像配准主要涉及将2D介入图像配准到3D术前CT/MR图像，即获取与可用2D视图对齐的3D几何变换。传统的2D-3D配准方法涉及基于图像强度的相似性度量的迭代优化方法[[215](#bib.bib215)]，这些方法以图像强度作为目标函数。由于从2D图像中获得的空间信息稀疏，这个问题是非凸的，如果初始估计离正确答案不够接近，可能会导致在局部最小值处收敛。2D-3D配准是一个至少具有六自由度的问题，这也可能导致配准模糊，因为沿每个投影线的空间信息被压缩到2D平面上的一个点。这种高维优化问题增加了确定与3D体积中解剖特征深度相关的参数的难度。作为替代，基于深度学习的方法在这方面变得越来越受欢迎，因为它们不需要显式的函数映射[[321](#bib.bib321)]。在这次讨论中，我们简要介绍了2D-3D配准的最新进展，同时建议感兴趣的读者参考[[321](#bib.bib321)]，以全面了解各种学习方法在这一领域的影响。
- en: Common 2D-3D registration applications and examples include registration of
    2D fluoroscopic/angiography images to 3D CT/MR images of pelvic, lung, or brain
    regions [[109](#bib.bib109), [193](#bib.bib193), [102](#bib.bib102), [101](#bib.bib101),
    [157](#bib.bib157), [149](#bib.bib149)], registering endoscopy images to CT/MR
    images [[197](#bib.bib197), [25](#bib.bib25)], and registering 2D Ultrasound (US)
    frames to 3D MR images to facilitate interventional procedures, such as liver
    tumor ablation [[340](#bib.bib340)] or prostate cancer biopsy[[112](#bib.bib112)].
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的2D-3D配准应用和实例包括将2D荧光镜/血管造影图像配准到骨盆、肺部或脑部区域的3D CT/MR图像[[109](#bib.bib109), [193](#bib.bib193),
    [102](#bib.bib102), [101](#bib.bib101), [157](#bib.bib157), [149](#bib.bib149)]，将内窥镜图像配准到CT/MR图像[[197](#bib.bib197),
    [25](#bib.bib25)]，以及将2D超声（US）帧配准到3D MR图像，以便于介入操作，例如肝脏肿瘤消融[[340](#bib.bib340)]或前列腺癌活检[[112](#bib.bib112)]。
- en: In [[109](#bib.bib109), [340](#bib.bib340), [149](#bib.bib149)], the 2D-3D registration
    problem was modeled as a regression learning problem where the network is trained
    to directly predict the desired geometric parameters. These models are trained
    by completely relying on the data, *i.e.*, it has little to no tie to the actual
    image formation physics involved. Specifically, in [[109](#bib.bib109)] a 2D X-Ray
    image is registered to a 3D CT volume using a ConvNet, which takes the X-Ray image
    and a digitally reconstructed radiograph (DRR) from the CT volume at some known
    pose as input. The ConvNet regresses a geodesic loss function over the geometric
    parameter space to estimate the relative pose between the fixed X-ray image and
    the DRR from the CT volume without the need for accurate pose initialization.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[109](#bib.bib109)，[340](#bib.bib340)，[149](#bib.bib149)]中，2D-3D配准问题被建模为回归学习问题，其中网络被训练以直接预测所需的几何参数。这些模型完全依赖于数据进行训练，*即*，与实际图像形成物理过程几乎没有联系。具体而言，在[[109](#bib.bib109)]中，使用ConvNet将2D
    X射线图像配准到3D CT体积中，ConvNet以X射线图像和CT体积中某些已知姿态的数字重建射线照片（DRR）作为输入。ConvNet在几何参数空间上回归地理损失函数，以估计固定X射线图像与CT体积中DRR之间的相对姿态，而无需准确的姿态初始化。
- en: In [[340](#bib.bib340)], Wei *et al.* propose a two-step registration process
    to determine the position and orientation of the ultrasound plane in the 3D MR
    volume data. In the first step, a ResNet-18 network is employed to determine the
    US probe orientation. Following this, a U-Net is used to regress a weighted dice
    loss function, which facilitates the determination of the orientation and position
    of the corresponding XY plane in the resampled 3D MR volume associated with the
    US frame. In [[149](#bib.bib149)], Huang *et al.* also implemented a two-step
    registration process for aligning 3D MR vessel wall images (VWI) with 2D Digital
    Subtraction Angiography (DSA) images. This approach encompasses a ConvNet regressor [[226](#bib.bib226)]
    that estimates the initial pose, followed by an instance-based centroid alignment,
    which serves to further minimize parameter estimation errors between the images.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[340](#bib.bib340)]中，魏*等人*提出了一个两步配准过程，以确定超声平面在3D MR体积数据中的位置和方向。第一步使用ResNet-18网络来确定超声探头的方向。接着，使用U-Net回归加权骰子损失函数，从而帮助确定与超声帧相关的重采样3D
    MR体积中相应XY平面的方向和位置。在[[149](#bib.bib149)]中，黄*等人*也实现了一个两步配准过程，用于将3D MR血管壁图像（VWI）与2D数字减影血管造影（DSA）图像对齐。这种方法包括一个ConvNet回归器[[226](#bib.bib226)]，用于估计初始姿态，随后进行基于实例的质心对齐，以进一步减少图像之间的参数估计误差。
- en: As an alternative to formulating registration as a regression problem that necessitates
    ground truth transformation parameters, several recent studies [[193](#bib.bib193),
    [102](#bib.bib102), [101](#bib.bib101), [157](#bib.bib157), [112](#bib.bib112)]
    have explored framing it as an unsupervised optimization problem. In such a formulation,
    the cost function is determined by a similarity metric measured between the transformed
    and fixed images. Liao *et al.* [[193](#bib.bib193)] trained a network to track
    a set of points of interest (POIs) derived from the 3D CT volume in the 2D DRR
    and in the multi-view fluoroscopic 2D images (used as fixed images), enabling
    the network to learn the spatial correspondences between the POIs. In this method,
    a Siamese U-Net architecture is employed to extract features from the DRRs and
    fixed images, subsequently tracking the POIs within the extracted features. A
    triangulation layer is incorporated to pinpoint the locations of the tracked POIs
    within the fixed image in 3D space. Finally, the geometric transformation between
    the estimated locations of POIs derived from the fixed image and their true positions
    is determined analytically. In [[102](#bib.bib102)], Gao *et al.* proposed a novel
    differential volume rendering transformer network combined with a feature extraction
    encoder to approximate the image similarity metric in a manner that renders the
    geometric parameter estimation as a convex problem with respect to the pose parameters.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 作为将配准问题公式化为回归问题的替代方案，若干近期研究[[193](#bib.bib193), [102](#bib.bib102), [101](#bib.bib101),
    [157](#bib.bib157), [112](#bib.bib112)]探讨了将其作为无监督优化问题的框架。在这种公式化中，成本函数由转换后图像与固定图像之间的相似性度量确定。*Liao
    et al.* [[193](#bib.bib193)] 训练了一个网络，以跟踪在2D DRR和多视角透视2D图像（用作固定图像）中提取的兴趣点（POIs），使网络能够学习POIs之间的空间对应关系。在这种方法中，采用了Siamese
    U-Net架构来从DRR和固定图像中提取特征，随后在提取的特征中追踪POIs。加入了一个三角测量层，以确定3D空间中固定图像中POIs的跟踪位置。最后，通过解析方法确定从固定图像中估算的POIs位置与其真实位置之间的几何变换。在[[102](#bib.bib102)]中，*Gao
    et al.* 提出了一个新颖的差分体积渲染变换器网络，结合了特征提取编码器，以一种将几何参数估计呈现为相对于姿态参数的凸问题的方式近似图像相似性度量。
- en: The examples and applications discussed thus far have primarily focused on rigid
    2D-3D registration. However, non-rigid 2D-3D registration is essential in certain
    applications, such as cephalometry [[191](#bib.bib191)] and lung tumor tracking
    in radiation therapy [[91](#bib.bib91), [70](#bib.bib70)]. Cephalometry, for instance,
    involves formulating the problem as deformed 2D-3D registration with the objective
    of generating a 3D volumetric image from a 2D X-ray image using a 3D skull atlas.
    Li *et al.* [[191](#bib.bib191)] developed a convolutional encoder that uniquely
    codes the cephalogram image into a volumetric image. The network is trained by
    minimizing the NCC between the synthesized DRR originating from the volumetric
    image and the 2D cephalogram.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止讨论的示例和应用主要集中在刚性2D-3D配准上。然而，非刚性2D-3D配准在某些应用中至关重要，如头部测量[[191](#bib.bib191)]和放射治疗中的肺部肿瘤追踪[[91](#bib.bib91),
    [70](#bib.bib70)]。例如，头部测量涉及将问题制定为变形的2D-3D配准，目标是利用3D头骨图谱从2D X光图像生成3D体积图像。*Li et
    al.* [[191](#bib.bib191)] 开发了一种卷积编码器，将头部X光图像独特地编码为体积图像。该网络通过最小化源自体积图像的合成DRR与2D头部X光图像之间的NCC来进行训练。
- en: Numerous deep learning-based models and metrics have been developed to improve
    the performance of 2D-3D registration in specific applications, although these
    methods are specialized and not as versatile as traditional optimization methods.
    Nonetheless, Machine Learning/Deep Learning has been instrumental in tackling
    the persistent challenges associated with algorithmic approaches. These techniques
    have tackled a narrow optimal range of parameters, while also decreasing registration
    ambiguity. CNN-based approaches are also comparably fast. These factors encourage
    users to further improve learning-based 2D-3D registration pipeline.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管已有众多基于深度学习的模型和度量标准被开发出来以提高特定应用中2D-3D配准的性能，但这些方法具有专业性，并不如传统优化方法那样通用。尽管如此，机器学习/深度学习在应对与算法方法相关的持久挑战方面发挥了重要作用。这些技术处理了参数的狭窄最优范围，同时减少了配准歧义。基于CNN的方法也相对较快。这些因素鼓励用户进一步改进基于学习的2D-3D配准管道。
- en: 8 Challenges and Future Perspectives
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 挑战与未来展望
- en: 'Over the past decade, learning-based registration models have been attracting
    increasing research interest. As illustrated in the left panel of Fig. [5](#S8.F5
    "Fig. 5 ‣ 8 Challenges and Future Perspectives ‣ A survey on deep learning in
    medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond"), there has been a growing trend in developing and applying these
    models since 2013\. Unlike other medical image analysis tasks, such as segmentation
    or classification, which typically necessitate labor-intensive and time-consuming
    manual annotations to develop high-performing models, registration is inherently
    a self-supervised task. Traditional registration models have predominantly been
    unsupervised, requiring only moving and fixed images to execute registration.
    While traditional registration models are typically unsupervised, learning-based
    registration models initially began as a supervised process, generating ground
    truth deformation fields using traditional registration methods. However, these
    supervised models often could not surpass the performance of traditional methods.
    Instead, they often served as an intermediate step to expedite conventional approaches
    like geodetic shooting [[290](#bib.bib290)], FLASH [[334](#bib.bib334)], etc.
    Despite traditional methods providing appealing deformation properties such as
    time-dependent diffeomorphic transformations, researchers have recently begun
    exploring the unsupervised nature of learning-based registration (as seen in the
    left panel of Fig. [5](#S8.F5 "Fig. 5 ‣ 8 Challenges and Future Perspectives ‣
    A survey on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond")). By training DNNs using loss functions adapted
    from traditional methods’ objective functions, these methods aim to improve both
    registration accuracy and speed. Incorporating segmentation and landmark correspondences
    during training can further enhance registration accuracy, providing capabilities
    not achievable with traditional methods. Given the rapid progress of deep learning
    and its growing adoption in medical applications, we anticipate an increasing
    focus on learning-based medical image registration.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '在过去十年中，基于学习的配准模型越来越受到研究者的关注。如图[5](#S8.F5 "Fig. 5 ‣ 8 Challenges and Future
    Perspectives ‣ A survey on deep learning in medical image registration: new technologies,
    uncertainty, evaluation metrics, and beyond")左侧面板所示，自2013年以来，开发和应用这些模型的趋势不断增长。与其他医学图像分析任务（如分割或分类）不同，这些任务通常需要耗费大量时间和精力的手动标注来开发高性能模型，而配准本质上是一个自监督任务。传统的配准模型主要是无监督的，只需要移动和固定图像来执行配准。虽然传统的配准模型通常是无监督的，但基于学习的配准模型最初开始是一个有监督的过程，通过使用传统配准方法生成真实的变形场。然而，这些有监督的模型通常无法超越传统方法的性能。相反，它们通常作为加速传统方法（如大地测量射击[[290](#bib.bib290)]，FLASH[[334](#bib.bib334)]等）的中间步骤。尽管传统方法提供了令人满意的变形特性，如时间依赖的
    diffeomorphic 变换，但研究人员最近开始探索基于学习的配准的无监督特性（如图[5](#S8.F5 "Fig. 5 ‣ 8 Challenges
    and Future Perspectives ‣ A survey on deep learning in medical image registration:
    new technologies, uncertainty, evaluation metrics, and beyond")左侧面板所示）。通过使用从传统方法的目标函数中调整的损失函数来训练DNN，这些方法旨在提高配准的准确性和速度。在训练过程中加入分割和地标对应关系可以进一步提升配准的准确性，提供传统方法无法实现的能力。鉴于深度学习的快速进展及其在医学应用中的日益普及，我们预计对基于学习的医学图像配准的关注将会增加。'
- en: In this section, we provide future perspectives and discuss potential avenues
    for advancing learning-based medical image registration. Our discussion will focus
    on the development of registration models, assessment of registration uncertainty,
    and prospective applications.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们提供未来的展望，并讨论推动基于学习的医学图像配准的潜在途径。我们的讨论将集中在配准模型的开发、配准不确定性的评估以及未来的应用上。
- en: '![Refer to caption](img/b19a9986819a5a8e32592aea00b7c98e.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b19a9986819a5a8e32592aea00b7c98e.png)'
- en: 'Fig. 5: The statistics of the paper count from PubMed (as of Fed. 13th, 2023)
    are depicted in two figures. The first figure displays the statistics obtained
    by counting the number of papers that have the keywords "Image Registration" and
    "Neural Networks" in their title or abstract. The second figure presents the statistics
    obtained by counting the papers that include the keywords "Image Registration"
    and either "Unsupervised" or "End-to-end" in their title or abstract.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：论文数量的统计数据来自 PubMed（截至 2023 年 2 月 13 日），分为两个图。第一个图展示了通过计算标题或摘要中包含关键词“图像配准”和“神经网络”的论文数量所获得的统计数据。第二个图呈现了通过计算标题或摘要中包含关键词“图像配准”和“无监督”或“端到端”的论文数量所获得的统计数据。
- en: 8.1 Deep Learning-based Registration Models
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1 基于深度学习的配准模型
- en: 8.1.1 Network Architecture
  id: totrans-273
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.1.1 网络架构
- en: 'Network architectures employed in image registration occasionally draw inspiration
    from other image analysis tasks, such as segmentation. For instance, VoxelMorph [[14](#bib.bib14)],
    CycleMorph [[172](#bib.bib172)], SYMNet [[229](#bib.bib229)], and DiffuseMorph [[171](#bib.bib171)]
    all borrow U-Net-like architectures, originally developed for image segmentation.
    In such cases, they often generate deformation fields at a single resolution.
    In contrast, traditional registration algorithms have demonstrated the benefits
    of adopting a multi-resolution registration strategy, which decomposes deformations
    across multiple scales. This method not only improves registration performance
    but also imparts beneficial deformation properties, such as the ability to enforce
    larger deformations. This aspect can be particularly beneficial for lung or abdominal
    organ registration, where organ displacement between scans can be significant.
    As discussed in section [4.10](#S4.SS10 "4.10 Progressive and Pyramid Registration
    ‣ 4 Network Architectures ‣ A survey on deep learning in medical image registration:
    new technologies, uncertainty, evaluation metrics, and beyond"), there has been
    a growing interest in integrating multi-resolution strategies into network architecture,
    and these methods have consistently demonstrated notable performance improvements
    compared to using a single resolution alone. It is worth noting that this finding
    has parallels with observations in other image analysis fields, where adopting
    deep supervision can significantly boost performance [[380](#bib.bib380), [154](#bib.bib154)].'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '图像配准中使用的网络架构有时会借鉴其他图像分析任务的灵感，例如分割。例如，VoxelMorph [[14](#bib.bib14)]、CycleMorph
    [[172](#bib.bib172)]、SYMNet [[229](#bib.bib229)] 和 DiffuseMorph [[171](#bib.bib171)]
    都借用了最初为图像分割开发的 U-Net 类似架构。在这种情况下，它们通常在单一分辨率下生成变形场。相比之下，传统的配准算法展示了采用多分辨率配准策略的好处，这种策略在多个尺度上分解变形。这种方法不仅提高了配准性能，还赋予了有益的变形属性，例如强制施加较大变形的能力。这一方面在肺部或腹部器官配准中尤其有利，因为扫描之间的器官位移可能很大。如第
    [4.10](#S4.SS10 "4.10 Progressive and Pyramid Registration ‣ 4 Network Architectures
    ‣ A survey on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond") 节所述，近年来将多分辨率策略融入网络架构的兴趣日益增加，这些方法在性能提升方面相较于仅使用单一分辨率的方法表现出显著的改进。值得注意的是，这一发现与其他图像分析领域的观察相似，在这些领域，采用深度监督可以显著提升性能
    [[380](#bib.bib380), [154](#bib.bib154)]。'
- en: Moreover, registration task is intrinsically different from other tasks, as
    it requires the network to capture the correspondences between images rather than
    comprehending the context contained within the images themselves. This concept
    is exemplified by a recent work, SynthMorph [[138](#bib.bib138)], where the authors
    demonstrated that training a viable medical image registration network does not
    strictly require medical images. Instead, random shapes or synthetic images can
    also serve as training datasets for registration networks. Consequently, when
    designing network architectures for image registration, the primary focus should
    be on their ability to capture spatial correspondences between images. Architectures
    such as Transformers (particularly cross-attention Transformers), contrastive
    learning, Siamese networks, and correlation layers, which leverage comparisons
    between moving and fixed images, are of special interest for image registration.
    We expect to see an increasing number of studies incorporating these designs in
    the future, along with other advancements in deep learning applied to image registration.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，配准任务本质上不同于其他任务，因为它要求网络捕捉图像之间的对应关系，而不是理解图像本身包含的上下文。这一概念在近期的工作SynthMorph [[138](#bib.bib138)]中得到了体现，作者们展示了训练一个有效的医学图像配准网络并不严格需要医学图像。相反，随机形状或合成图像也可以作为配准网络的训练数据集。因此，在设计图像配准的网络架构时，主要关注点应放在其捕捉图像之间空间对应关系的能力上。诸如Transformers（特别是跨注意力Transformers）、对比学习、Siamese网络和相关层等架构，通过比较移动图像和固定图像，对于图像配准具有特别的兴趣。我们预计未来会有越来越多的研究将这些设计纳入其中，并结合其他深度学习在图像配准中的应用进展。
- en: 8.1.2 Loss Function
  id: totrans-276
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.1.2 损失函数
- en: 'In unsupervised models, the image similarity measures predominantly used for
    mono-modal registration are MSE and NCC, as shown in Table [1](#S3.T1 "Table 1
    ‣ 3 Loss Functions ‣ A survey on deep learning in medical image registration:
    new technologies, uncertainty, evaluation metrics, and beyond"). NCC is generally
    considered a better choice than MSE, as it is locally adaptive and less sensitive
    to local intensity variations [[9](#bib.bib9)]. For multi-modal registration,
    MI has historically been the preferred choice [[215](#bib.bib215), [341](#bib.bib341)].
    However, to auto-differentiate MI using modern deep learning frameworks for end-to-end
    training, joint and marginal probabilities are often approximated using the Parzen
    window. A notable drawback of this approximation is the increased computational
    burden. In actual implementation, each voxel location expands to include a vector,
    with the elements in the vector representing the probability of the voxel belonging
    to each intensity bin. Increasing the number of intensity bins effectively results
    in an increased channel dimension, ultimately leading to a higher computational
    burden. Conversely, using a small number of bins often limits the registration
    performance. Recent learning-based methods have explored surrogates to tackle
    multi-modal registration problems. For instance, given the advantage of learning,
    anatomical loss functions like Dice can serve as a modality-independent loss function
    for training the registration network [[138](#bib.bib138)]. The trained network
    can then be applied to images without requiring anatomical segmentation, offering
    an advantage that traditional methods cannot provide. Multi-modal registration
    can also be addressed using advanced learning methods, such as contrastive learning
    and adversarial learning, as discussed in sections [4.2](#S4.SS2 "4.2 Contrastive
    Learning ‣ 4 Network Architectures ‣ A survey on deep learning in medical image
    registration: new technologies, uncertainty, evaluation metrics, and beyond")
    and [4.1](#S4.SS1 "4.1 Adversarial Learning ‣ 4 Network Architectures ‣ A survey
    on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond"). These methods guide the neural network in understanding
    similarities and dissimilarities between images across different modalities using
    paired data without requiring explicit multi-modal similarity measures. We expect
    future research to continue to develop more efficient and innovative approaches
    to tackle multi-modal registration.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督
- en: 'Regarding the use of regularization in learning-based deformable registration,
    there is currently an inadequate emphasis on the development and application of
    spatially-varying regularization. Despite being a significant area of research
    historically [[284](#bib.bib284), [283](#bib.bib283), [324](#bib.bib324), [307](#bib.bib307),
    [313](#bib.bib313), [258](#bib.bib258), [104](#bib.bib104), [296](#bib.bib296),
    [248](#bib.bib248), [237](#bib.bib237), [250](#bib.bib250), [97](#bib.bib97),
    [273](#bib.bib273), [249](#bib.bib249)], spatially-varying regularization has
    been largely overshadowed by the rise of learning-based registration, with only
    a few studies addressing it within a deep learning framework framework [[242](#bib.bib242),
    [290](#bib.bib290), [41](#bib.bib41), [47](#bib.bib47)]. As illustrated in Table
    [1](#S3.T1 "Table 1 ‣ 3 Loss Functions ‣ A survey on deep learning in medical
    image registration: new technologies, uncertainty, evaluation metrics, and beyond"),
    most methods opt for a simple spatially-invariant regularization, predominantly
    employing the diffusion regularizer. However, as outlined in section [3.4](#S3.SS4
    "3.4 Deformation Regularizer ‣ 3 Loss Functions ‣ A survey on deep learning in
    medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond"), spatially-varying regularization provides the advantage of accommodating
    spatially-varying deformations, preserving discontinuities, and facilitating sliding
    motion, all of which are essential for a variety of applications. Advancements
    in modeling spatially-varying regularization within or through deep learning frameworks
    are eagerly anticipated in the future.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '关于学习型可变形注册中正则化的使用，目前对空间变化正则化的开发和应用的重视不够。尽管这是一个历史上重要的研究领域 [[284](#bib.bib284),
    [283](#bib.bib283), [324](#bib.bib324), [307](#bib.bib307), [313](#bib.bib313),
    [258](#bib.bib258), [104](#bib.bib104), [296](#bib.bib296), [248](#bib.bib248),
    [237](#bib.bib237), [250](#bib.bib250), [97](#bib.bib97), [273](#bib.bib273),
    [249](#bib.bib249)], 空间变化正则化在学习型注册的兴起中被很大程度上忽视，只有少数研究在深度学习框架中对其进行了探讨 [[242](#bib.bib242),
    [290](#bib.bib290), [41](#bib.bib41), [47](#bib.bib47)]。如表 [1](#S3.T1 "Table 1
    ‣ 3 Loss Functions ‣ A survey on deep learning in medical image registration:
    new technologies, uncertainty, evaluation metrics, and beyond")所示，大多数方法选择简单的空间不变正则化，主要使用扩散正则化器。然而，如第
    [3.4](#S3.SS4 "3.4 Deformation Regularizer ‣ 3 Loss Functions ‣ A survey on deep
    learning in medical image registration: new technologies, uncertainty, evaluation
    metrics, and beyond")节所述，空间变化正则化具有适应空间变化变形、保持不连续性和促进滑动运动的优势，这些对于各种应用都是至关重要的。未来对在深度学习框架中建模空间变化正则化的进展充满期待。'
- en: 8.2 Registration Uncertainty
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2 注册不确定性
- en: Registration uncertainty in medical image analysis is an ongoing challenge and
    opportunity. On the one hand, advancements in deep learning have the potential
    to improve registration accuracy and reduce registration uncertainty by extracting
    features that are robust to noise and other artifacts. On the other hand, uncertainty
    can be estimated for use in interpreting the registration results and providing
    valuable information for clinical decision-making.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 医学图像分析中的注册不确定性是一个持续的挑战和机遇。一方面，深度学习的进步有可能通过提取对噪声和其他伪影具有鲁棒性的特征，来提高注册精度并减少注册不确定性。另一方面，可以估计不确定性以用于解释注册结果，并为临床决策提供宝贵信息。
- en: However, there are several limitations that restrict the further usage of uncertainty
    estimation in various applications. One significant limitation is the lack of
    ground truth for evaluating the quality of uncertainty estimation. Without ground
    truth, it is challenging to validate the accuracy of uncertainty estimation directly.
    Instead, most existing evaluation methods rely on indirect proofs such as sparsification
    analysis. This not only affects the reliability of uncertainty estimation, but
    also limits further developments for better uncertainty estimations. Another limitation
    is the computational complexity of estimating uncertainty, which can be time-consuming
    and may limit its usage in real-time clinical applications. Additionally, interpreting
    uncertainty estimates can be challenging for clinicians, as some statistical measures
    are not always straightforward. This can limit the adoption of uncertainty estimation
    in clinical decision-making, where clear and concise information is essential
    for making informed decisions.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有几个限制因素限制了不确定性估计在各种应用中的进一步使用。一个重要的限制是缺乏用于评估不确定性估计质量的真实值。没有真实值，就难以直接验证不确定性估计的准确性。相反，大多数现有的评估方法依赖于间接证明，如稀疏化分析。这不仅影响了不确定性估计的可靠性，还限制了进一步开发更好不确定性估计的可能性。另一个限制是估计不确定性的计算复杂性，这可能非常耗时，并且可能限制其在实时临床应用中的使用。此外，解释不确定性估计对临床医生来说可能是具有挑战性的，因为一些统计测量方法并不总是直接明了。这可能限制了不确定性估计在临床决策中的应用，而明确且简洁的信息对于做出明智的决策至关重要。
- en: To overcome these limitations, it may be helpful to develop improved evaluation
    methods that rely on direct validation rather than indirect proofs, such as the
    creation of synthetic data or the use of simulation frameworks where the ground
    truth is known. This could enhance the accuracy and reliability of uncertainty
    estimation. Moreover, new computational techniques and algorithms such as incorporating
    Markov Chain Monte Carlo into a multilevel framework [[285](#bib.bib285)] and
    quantifying image registration uncertainty based on a low dimensional representation
    of geometric deformations [[332](#bib.bib332)] can reduce the computational workload.
    Last, efforts should be made to provide clinicians with more accessible and intuitive
    ways to interpret uncertainty estimates, such as visual aids or simpler statistic
    measures.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这些局限性，开发依赖于直接验证而非间接证明的改进评估方法可能会有所帮助，例如创建合成数据或使用已知真实值的模拟框架。这可以提高不确定性估计的准确性和可靠性。此外，新的计算技术和算法，如将马尔可夫链蒙特卡罗方法纳入多层框架[[285](#bib.bib285)]以及基于几何变形的低维表示来量化图像配准不确定性[[332](#bib.bib332)]，可以减少计算工作量。最后，应努力为临床医生提供更易于访问和直观的方式来解释不确定性估计，例如视觉辅助工具或更简单的统计测量方法。
- en: In addition to the limitations of uncertainty estimation in medical image analysis,
    there are also many potential applications of registration uncertainty that remain
    unexplored. One promising area of application is atlas-based segmentation, where
    registration is often used to align an atlas image to a target image for the purpose
    of segmenting anatomical structures. In this context, registration uncertainty
    can be used as a criterion for generating a soft segmentation mask, where the
    probability of each voxel belonging to a particular anatomical structure is weighted
    by the uncertainty estimate. Another potential application of registration uncertainty
    is multi-atlas-based segmentation, where multiple atlases are registered to a
    target image and combined to produce a final segmentation result. In this context,
    registration uncertainty can be used to weight different segmentation results,
    producing a more reliable segmentation. This approach could be particularly useful
    in cases where some atlases are more appropriate for a particular image than others.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 除了医疗图像分析中不确定性估计的局限性外，还有许多未探索的配准不确定性的潜在应用。其中一个有前景的应用领域是基于图谱的分割，在这种情况下，配准通常用于将图谱图像对齐到目标图像，以便分割解剖结构。在这种背景下，配准不确定性可以作为生成软分割掩模的标准，其中每个体素属于特定解剖结构的概率由不确定性估计加权。另一个潜在的应用是多图谱分割，其中多个图谱被配准到目标图像并组合生成最终的分割结果。在这种情况下，配准不确定性可以用来加权不同的分割结果，从而生成更可靠的分割。这种方法在一些图谱对特定图像比其他图谱更合适的情况下可能特别有用。
- en: Overall, these limitations and potential applications of registration uncertainty
    in medical image analysis offer an exciting range of opportunities for future
    research, and it is likely that continued progress in this area will have a substantial
    impact on the field of medical image analysis and beyond.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这些医疗图像分析中配准不确定性的限制和潜在应用提供了一系列令人兴奋的未来研究机会，未来在这一领域的持续进展很可能对医疗图像分析及其他相关领域产生深远的影响。
- en: 8.3 Towards Zero-shot Registration
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3 零样本配准的进展
- en: Classical registration algorithms, while potentially slower, are usually available
    for immediate use and provide end-users with the flexibility to choose the similarity
    measure and weighting of regularization terms that best meet their needs. In contrast,
    deep learning algorithms are susceptible to the domain shift problem, which arises
    when a trained network struggles to perform well when presented with input images
    from a different distribution than the training data. Several sources of domain
    shift can arise in learning-based registration algorithms, such as changes in
    the input image modality, different populations of subjects, or variations in
    the direction of registration. To address this challenge, researchers have explored
    several methods to improve the generalizability of registration networks. For
    instance, SynthMorph [[138](#bib.bib138)] uses synthetic images to force the network
    to learn contrast-invariant features, while HyperMorph [[143](#bib.bib143)] uses
    a hypernetwork to enable the adjustment of the regularization term during test
    time. Although these approaches have shown promising results, they have not yet
    been widely adopted, and further studies and validations are necessary to establish
    their effectiveness in real-world scenarios.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的配准算法虽然可能较慢，但通常可以立即使用，并且为终端用户提供了选择相似性度量和正则化项加权的灵活性，以最好地满足他们的需求。相比之下，深度学习算法容易受到领域转移问题的影响，这种问题发生在训练过的网络在处理来自与训练数据分布不同的输入图像时表现不佳。学习型配准算法中可能出现的领域转移来源包括输入图像模态的变化、不同的受试者群体或配准方向的变化。为了应对这一挑战，研究人员探索了几种方法来提高配准网络的泛化能力。例如，SynthMorph
    [[138](#bib.bib138)] 使用合成图像来迫使网络学习对比度不变特征，而 HyperMorph [[143](#bib.bib143)] 使用超网络在测试时调整正则化项。尽管这些方法显示出了有希望的结果，但尚未被广泛采用，进一步的研究和验证仍然必要，以确定它们在实际场景中的有效性。
- en: Recent developments in zero-shot learning offer a promising avenue for further
    improving the generalizability of learning-based registration algorithms. In particular,
    Foundation models that are pretrained on a broad range of data have shown competitive
    or even superior zero-shot performance compared to prior supervised models in
    various tasks [[174](#bib.bib174), [28](#bib.bib28)], without requiring specific
    training data for each new task. Leveraging these techniques can potentially reduce
    the time and resource requirements for developing deep learning registration algorithms
    in clinical pipelines, making the existing registration algorithms more accessible
    and useful to a wider range of users.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 最近零样本学习的发展为进一步提高基于学习的配准算法的泛化能力提供了一个有前景的途径。特别是，在广泛数据上预训练的基础模型在各种任务中表现出了竞争力甚至优于先前监督模型的零样本性能
    [[174](#bib.bib174), [28](#bib.bib28)]，而不需要针对每个新任务的特定训练数据。利用这些技术可以潜在地减少开发深度学习配准算法在临床流程中的时间和资源需求，使现有的配准算法对更广泛的用户群体变得更加可及和有用。
- en: 8.4 Metamorphic Image Registration
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4 变形图像配准
- en: 'As outlined in Section [2.3](#S2.SS3 "2.3 Diffeomorphic Image Registration
    ‣ 2 Fundamentals of Learning-based Image Registration ‣ A survey on deep learning
    in medical image registration: new technologies, uncertainty, evaluation metrics,
    and beyond"), diffeomorphic registration is a bijective mapping that preserves
    topology. In clinical scenarios, however, registration often involves the deformation
    of a healthy control or an atlas to fit patient images that may contain tumors
    or other anomalies. For example, longitudinal scans of the same patient with a
    tumor may need to be mapped to one another to facilitate the study of the tumor
    progression or response. Such situations violate the one-to-one mapping assumption
    of diffeomorphisms due to topological changes between scans. To address this challenge,
    alternative registration methods such as metamorphic registration models [[27](#bib.bib27),
    [287](#bib.bib287), [241](#bib.bib241), [141](#bib.bib141), [93](#bib.bib93)]
    have been proposed, which can accommodate changes in topology and appearance.
    For a mathematical definition of metamorphosis, readers can refer to [[319](#bib.bib319),
    [365](#bib.bib365)]. However, these methods often require manual segmentation
    of the anomalies and are optimization-based, which can be time-consuming and computationally
    expensive, thereby limiting their practical adoption.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '如第[2.3](#S2.SS3 "2.3 Diffeomorphic Image Registration ‣ 2 Fundamentals of Learning-based
    Image Registration ‣ A survey on deep learning in medical image registration:
    new technologies, uncertainty, evaluation metrics, and beyond")节所述， diffeomorphic
    配准是一种保留拓扑的双射映射。然而，在临床场景中，配准通常涉及将健康对照或图谱变形以适应可能包含肿瘤或其他异常的患者图像。例如，同一患者的肿瘤的纵向扫描可能需要互相映射，以便研究肿瘤的进展或反应。这些情况由于扫描之间的拓扑变化而违反了
    diffeomorphisms 的一对一映射假设。为了应对这一挑战，提出了诸如 metamorphic 配准模型[[27](#bib.bib27), [287](#bib.bib287),
    [241](#bib.bib241), [141](#bib.bib141), [93](#bib.bib93)]等替代配准方法，这些方法可以适应拓扑和外观的变化。有关
    metamorphosis 的数学定义，读者可以参考[[319](#bib.bib319), [365](#bib.bib365)]。然而，这些方法通常需要手动分割异常区域，并且基于优化，这可能既耗时又计算密集，从而限制了它们的实际应用。'
- en: Recently proposed learning-based metamorphic registration methods [[333](#bib.bib333),
    [118](#bib.bib118), [26](#bib.bib26), [219](#bib.bib219)] have been built upon
    a metamorphic framework [[319](#bib.bib319), [365](#bib.bib365)], which adds time-varying
    intensity variations on top of the diffeomorphic flow, thereby enabling topological
    changes over time. The registration networks learn to disentangle geometric and
    appearance changes and sometimes leverage available segmentation to constrain
    changes within a desired location (e.g., a tumor). With the success of learning-based
    image segmentation, the time-consuming manual segmentation previously required
    by classical methods to guide the metamorphosis can now be addressed using segmentation
    networks. Several recent approaches take advantage of segmentation networks through
    joint training [[333](#bib.bib333)] or by integrating segmentation capabilities
    directly into the registration network [[118](#bib.bib118)]. Alternatively, some
    studies learn to disentangle appearance and shape changes directly from data without
    requiring to explicitly define a region [[26](#bib.bib26), [219](#bib.bib219)].
    Despite these recent advancements, learning-based metamorphic registration is
    still in its infancy. Successfully capturing topological changes still greatly
    depends on the accuracy of the segmentation network. Meanwhile, the effective
    modeling of time-varying diffeomorphic flow using DNNs continues to be an area
    of ongoing research. Considering the practical potential of metamorphic registration,
    metamorphic registration represents an appealing direction for future investigation
    in learning-based registration research.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 最近提出的基于学习的变形配准方法[[333](#bib.bib333), [118](#bib.bib118), [26](#bib.bib26), [219](#bib.bib219)]
    基于变形框架[[319](#bib.bib319), [365](#bib.bib365)]，该框架在流形变换的基础上增加了时间变化的强度变化，从而实现了随时间的拓扑变化。配准网络学习解开几何和外观变化，有时利用现有的分割来约束变化在期望的位置（例如肿瘤）内。随着基于学习的图像分割的成功，以前由经典方法所需的耗时手动分割现在可以通过分割网络解决。最近的一些方法通过联合训练[[333](#bib.bib333)]或将分割能力直接集成到配准网络中[[118](#bib.bib118)]来利用分割网络。或者，一些研究直接从数据中学习解开外观和形状变化，而不需要明确定义区域[[26](#bib.bib26),
    [219](#bib.bib219)]。尽管有这些最新进展，基于学习的变形配准仍处于初期阶段。成功捕捉拓扑变化仍然在很大程度上依赖于分割网络的准确性。同时，使用深度神经网络有效建模时间变化的流形变换仍然是一个持续研究的领域。考虑到变形配准的实际潜力，变形配准代表了未来基于学习的配准研究的一个有吸引力的方向。
- en: 8.4.1 Spatial-temporal Image Registration
  id: totrans-291
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.4.1 时空图像配准
- en: 'Learning-based image registration methods have primarily been centered around
    aligning just one pair of images. Yet, there is a crucial but underexplored need
    in medical imaging applications: tracking tissue motion across multiple frames.
    This is particularly relevant in modalities such as tagged/cine MRIs, 4D-CT, and
    echocardiography.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 基于学习的图像配准方法主要集中在对齐单对图像。然而，在医学成像应用中存在一个关键但尚未充分探索的需求：跟踪多帧中的组织运动。这在标记/动态 MRI、4D
    CT 和超声心动图等成像方式中尤为相关。
- en: Addressing the challenge of motion tracking involves overcoming several challenges
    and taking into account key questions that require careful consideration. For
    instance, how can one ensure the preservation of desired properties, such as smoothness,
    diffeomorphism, and incompressibility, throughout temporally long-range tracking?
    Achieving accurate 4D tracking while maintaining a reasonable computational burden
    in terms of both temporal and spatial complexity poses another challenge. Moreover,
    how can varying input frame lengths be effectively managed? These questions demand
    further exploration and investigation in order to advance our understanding and
    capability in motion tracking. Encouragingly, recent advancements in computer
    vision, particularly in the context of natural video, have demonstrated promising
    results. Methods such as correspondence learning [[155](#bib.bib155), [19](#bib.bib19),
    [373](#bib.bib373), [4](#bib.bib4)] and spatial-temporal representation learning [[173](#bib.bib173),
    [363](#bib.bib363), [331](#bib.bib331), [262](#bib.bib262), [57](#bib.bib57)]
    may offer valuable insights to tackle these challenges we face. By building upon
    these recent advancements, we may pave the way for more effective and efficient
    motion-tracking methods for medical imaging applications.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 解决运动跟踪的挑战涉及克服多个困难，并考虑需要仔细思考的关键问题。例如，如何确保在时间跨度较长的跟踪过程中保持所需的属性，如平滑性、微分同胚性和不可压缩性？在保持合理的计算负担的同时实现准确的4D跟踪，既要考虑时间复杂度，也要考虑空间复杂度，这是另一个挑战。此外，如何有效管理变化的输入帧长度？这些问题需要进一步探索和研究，以推进我们对运动跟踪的理解和能力。令人鼓舞的是，计算机视觉的最新进展，特别是在自然视频的背景下，已经显示出令人期待的成果。诸如对应学习[[155](#bib.bib155),
    [19](#bib.bib19), [373](#bib.bib373), [4](#bib.bib4)]和时空表示学习[[173](#bib.bib173),
    [363](#bib.bib363), [331](#bib.bib331), [262](#bib.bib262), [57](#bib.bib57)]等方法可能为应对我们面临的挑战提供宝贵的见解。通过在这些最新进展的基础上进行研究，我们可能为医疗成像应用开发更有效、更高效的运动跟踪方法铺平道路。
- en: 8.4.2 Spatial Normalization
  id: totrans-294
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.4.2 空间标准化
- en: 'Spatial normalization is the process of aligning medical images to a common
    atlas to reduce anatomical variations [[8](#bib.bib8), [94](#bib.bib94)]. This
    process facilitates voxel-based analysis, allowing for comparisons between individual
    patients as well as between a patient and a larger population. Additionally, it
    is useful for mitigating anatomical differences that arise due to factors like
    motion across various image modalities from the same patient. However, a primary
    challenge of this approach is achieving accurate registration, often hindered
    by significant anatomical differences among patients. Moreover, traditionally
    constructed atlases tend to be of subpar quality, primarily because conventional
    atlas construction methods usually involve averaging, leading to significant blurring
    of anatomical features. However, as discussed in section [7.1](#S7.SS1 "7.1 Atlas
    Construction ‣ 7 Applications of Medical Image Registration ‣ A survey on deep
    learning in medical image registration: new technologies, uncertainty, evaluation
    metrics, and beyond"), deep learning is currently playing a transformative role.
    It is not only accelerating the atlas construction process but also significantly
    enhancing the quality of the atlases in aspects like contrast and sharpness. Historically,
    atlases have been largely used in brain research owing to the comparatively smaller
    anatomical differences among patients. But with the advancements introduced by
    deep learning, combined with learning-based registration models, there is potential
    to broaden their application beyond just the brain to include other body parts.
    Such an expansion can be invaluable in various medical imaging applications, from
    cancer treatment planning and monitoring tumor progression or therapy response,
    to the creation of patient-specific digital twins.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '空间归一化是将医学图像与共同图谱对齐以减少解剖差异的过程[[8](#bib.bib8), [94](#bib.bib94)]。这个过程有助于基于像素的分析，允许对个体患者以及患者与较大人群进行比较。此外，它对于缓解同一患者在不同图像模态之间的运动导致的解剖差异也非常有用。然而，这种方法的一个主要挑战是实现准确的配准，往往受到患者之间显著的解剖差异的阻碍。此外，传统构建的图谱往往质量较差，主要是因为传统的图谱构建方法通常涉及平均化，导致解剖特征显著模糊。然而，正如在第[7.1](#S7.SS1
    "7.1 Atlas Construction ‣ 7 Applications of Medical Image Registration ‣ A survey
    on deep learning in medical image registration: new technologies, uncertainty,
    evaluation metrics, and beyond")节中讨论的那样，深度学习目前正在发挥变革的作用。它不仅加速了图谱构建过程，还在对比度和清晰度等方面显著提高了图谱的质量。在历史上，由于患者之间的解剖差异相对较小，图谱主要用于脑研究。但是，随着深度学习引入的进展以及基于学习的配准模型的结合，有潜力将其应用扩展到除了脑部以外的其他身体部位。这种扩展对于各种医学影像应用非常有价值，从癌症治疗计划和监测肿瘤发展或治疗反应，到创建个体化的患者数字模型。'
- en: 9 Conclusion
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 结论
- en: In this survey, we presented a thorough examination of deep learning for medical
    image registration. In contrast to existing review papers, which might not fully
    capture the most recent advancements and tend to be systematic in nature with
    a limited focus on technical aspects, our comprehensive survey analyzed over 250
    papers with an emphasis on the most recent technological advancements. Beginning
    with a review of the fundamentals of learning-based image registration, our investigation
    incorporated widely-used and novel loss functions, as well as network architectures
    for image registration. We also thoroughly investigated the estimation methods
    of registration uncertainty and appropriate metrics of registration accuracy and
    regularity. Furthermore, we provided insights into potential clinical applications,
    future perspectives, and challenges, aiming to guide future research in this rapidly
    evolving field.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在本调查中，我们对医学图像配准的深度学习进行了深入研究。与现有的综述文章相比，这些文章可能无法完全捕捉到最新的进展，并且往往以系统性为特点，对技术方面的关注有限。我们的综合调查分析了超过250篇文章，并重点关注最新的技术进展。从基于学习的图像配准的基本原理开始，我们的研究还涉及了广泛使用和新颖的损失函数，以及图像配准的网络架构。我们还对配准不确定性的估计方法和配准精度和规律性的适当度量进行了仔细研究。此外，我们还提供了对潜在临床应用、未来展望和挑战的见解，旨在指导对这一快速发展领域的未来研究。
- en: Acknowledgments
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: 'Junyu Chen and Yong Du were supported by grants from the National Institutes
    of Health (NIH), United States, U01-CA140204 (PI: Y. Du), R01-EB031023 (PI: Y. Du),
    and U01-EB031798 (PI: G. Sgouros). Yihao Liu, Shuwen Wei, Zhangxing Bian, Aaron
    Carass, and Jerry L. Prince were supported by the NIH from National Eye Institute
    grants R01-EY024655 (PI: J.L. Prince) and R01-EY032284 (PI: J.L. Prince), as well
    as the National Science Foundation grant 1819326 (Co-PI: S. Scott, Co-PI: A. Carass).
    The views expressed in written conference materials or publications and by speakers
    and moderators do not necessarily reflect the official policies of the NIH; nor
    does mention by trade names, commercial practices, or organizations imply endorsement
    by the U.S. Government.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 'Junyu Chen 和 Yong Du 得到了美国国立卫生研究院（NIH）资助，U01-CA140204（PI: Y. Du），R01-EB031023（PI:
    Y. Du），以及 U01-EB031798（PI: G. Sgouros）。Yihao Liu, Shuwen Wei, Zhangxing Bian,
    Aaron Carass 和 Jerry L. Prince 得到了 NIH 的资助，包括国家眼科研究所资助 R01-EY024655（PI: J.L. Prince）和
    R01-EY032284（PI: J.L. Prince），以及国家科学基金会资助 1819326（Co-PI: S. Scott, Co-PI: A. Carass）。在书面会议材料或出版物以及演讲者和主持人所表达的观点不一定反映
    NIH 的官方政策；提及商标、商业实践或组织并不意味着美国政府的认可。'
- en: References
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Ahn et al. [2020] Ahn, S.S., Ta, K., Lu, A., Stendahl, J.C., Sinusas, A.J.,
    Duncan, J.S., 2020. Unsupervised motion tracking of left ventricle in echocardiography,
    in: Medical imaging 2020: Ultrasonic imaging and tomography, SPIE. pp. 196–202.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ahn 等 [2020] Ahn, S.S., Ta, K., Lu, A., Stendahl, J.C., Sinusas, A.J., Duncan,
    J.S., 2020. 在超声心动图中对左心室进行无监督运动追踪，见：医学成像 2020：超声成像和断层扫描，SPIE. 第 196–202 页.
- en: 'Aljabar et al. [2009] Aljabar, P., Heckemann, R.A., Hammers, A., Hajnal, J.V.,
    Rueckert, D., 2009. Multi-atlas based segmentation of brain images: atlas selection
    and its effect on accuracy. NeuroImage 46, 726–738.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aljabar 等 [2009] Aljabar, P., Heckemann, R.A., Hammers, A., Hajnal, J.V., Rueckert,
    D., 2009. 基于多图谱的大脑图像分割：图谱选择及其对准确性的影响。NeuroImage 46, 726–738.
- en: 'Allassonnière et al. [2007] Allassonnière, S., Amit, Y., Trouvé, A., 2007.
    Towards a coherent statistical framework for dense deformable template estimation.
    Journal of the Royal Statistical Society: Series B (Statistical Methodology) 69,
    3–29.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Allassonnière 等 [2007] Allassonnière, S., Amit, Y., Trouvé, A., 2007. 朝着一致的统计框架进行密集可变形模板估计。皇家统计学会杂志：B
    系列（统计方法）69, 3–29.
- en: Araslanov et al. [2021] Araslanov, N., Schaub-Meyer, S., Roth, S., 2021. Dense
    unsupervised learning for video segmentation. Advances in Neural Information Processing
    Systems 34, 25308–25319.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Araslanov 等 [2021] Araslanov, N., Schaub-Meyer, S., Roth, S., 2021. 用于视频分割的密集无监督学习。神经信息处理系统进展
    34, 25308–25319.
- en: 'Arsigny et al. [2006] Arsigny, V., Commowick, O., Pennec, X., Ayache, N., 2006.
    A log-euclidean framework for statistics on diffeomorphisms, in: 9${}^{\mbox{\tiny{th}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2006),
    Springer. pp. 924–931.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arsigny 等 [2006] Arsigny, V., Commowick, O., Pennec, X., Ayache, N., 2006. 用于可微分变换的对数欧几里得框架，见：第
    9 届医学图像计算与计算机辅助干预国际会议（MICCAI 2006），Springer. 第 924–931 页.
- en: Ashburner [2007] Ashburner, J., 2007. A fast diffeomorphic image registration
    algorithm. NeuroImage 38, 95–113.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ashburner [2007] Ashburner, J., 2007. 一种快速的可微分图像配准算法。NeuroImage 38, 95–113.
- en: Ashburner et al. [1999] Ashburner, J., Andersson, J.L., Friston, K.J., 1999.
    High-dimensional image registration using symmetric priors. NeuroImage 9, 619–628.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ashburner 等 [1999] Ashburner, J., Andersson, J.L., Friston, K.J., 1999. 使用对称先验的高维图像配准。NeuroImage
    9, 619–628.
- en: Ashburner and Friston [1999] Ashburner, J., Friston, K.J., 1999. Nonlinear spatial
    normalization using basis functions. Human brain mapping 7, 254–266.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ashburner 和 Friston [1999] Ashburner, J., Friston, K.J., 1999. 使用基函数的非线性空间归一化。人脑成像
    7, 254–266.
- en: 'Avants et al. [2008] Avants, B.B., Epstein, C.L., Grossman, M., Gee, J.C.,
    2008. Symmetric diffeomorphic image registration with cross-correlation: evaluating
    automated labeling of elderly and neurodegenerative brain. Medical Image Analysis
    12, 26–41.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Avants 等 [2008] Avants, B.B., Epstein, C.L., Grossman, M., Gee, J.C., 2008.
    通过交叉相关的对称可微分图像配准：评估老年和神经退行性大脑的自动标记。医学图像分析 12, 26–41.
- en: Avants et al. [2010] Avants, B.B., Yushkevich, P., Pluta, J., Minkoff, D., Korczykowski,
    M., Detre, J., Gee, J.C., 2010. The optimal template effect in hippocampus studies
    of diseased populations. NeuroImage 49, 2457–2466.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Avants 等 [2010] Avants, B.B., Yushkevich, P., Pluta, J., Minkoff, D., Korczykowski,
    M., Detre, J., Gee, J.C., 2010. 在患病人群的海马体研究中的最佳模板效应。NeuroImage 49, 2457–2466.
- en: 'Axel and Dougherty [1989a] Axel, L., Dougherty, L., 1989a. Heart wall motion:
    Improved method of spatial modulation of magnetization for MR imaging. Radiology
    172, 349–350.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Axel 和 Dougherty [1989a] Axel, L., Dougherty, L., 1989a. 心脏壁运动：用于MR成像的空间磁化调制改进方法。放射学
    172, 349–350。
- en: Axel and Dougherty [1989b] Axel, L., Dougherty, L., 1989b. MR imaging of motion
    with spatial modulation of magnetization. Radiology 171, 841–845.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Axel 和 Dougherty [1989b] Axel, L., Dougherty, L., 1989b. 具有空间磁化调制的运动MR成像。放射学
    171, 841–845。
- en: Ayyalusamy et al. [2021] Ayyalusamy, A., Vellaiyan, S., Subramanian, S., Satpathy,
    S., 2021. Performance of a deformable image registration algorithm for CT and
    cone beam CT using physical multi-density geometric and digital anatomic phantoms.
    La Radiologia Medica 126, 106–116.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ayyalusamy 等 [2021] Ayyalusamy, A., Vellaiyan, S., Subramanian, S., Satpathy,
    S., 2021. 针对CT和锥形束CT的可变形图像配准算法性能研究，使用物理多密度几何和数字解剖模型。医学放射学 126, 106–116。
- en: 'Balakrishnan et al. [2019] Balakrishnan, G., Zhao, A., Sabuncu, M.R., Guttag,
    J., Dalca, A.V., 2019. Voxelmorph: a learning framework for deformable medical
    image registration. IEEE Trans. Med. Imag. 38, 1788–1800.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Balakrishnan 等 [2019] Balakrishnan, G., Zhao, A., Sabuncu, M.R., Guttag, J.,
    Dalca, A.V., 2019. Voxelmorph：一种用于可变形医学图像配准的学习框架。IEEE 医学成像汇刊 38, 1788–1800。
- en: Bastiaansen et al. [2022a] Bastiaansen, W.A., Rousian, M., Steegers-Theunissen,
    R.P., Niessen, W.J., Koning, A.H., Klein, S., 2022a. Multi-atlas segmentation
    and spatial alignment of the human embryo in first trimester 3d ultrasound. arXiv
    preprint arXiv:2202.06599 .
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bastiaansen 等 [2022a] Bastiaansen, W.A., Rousian, M., Steegers-Theunissen, R.P.,
    Niessen, W.J., Koning, A.H., Klein, S., 2022a. 第一孕期三维超声下人胚的多图谱分割和空间对齐。arXiv 预印本
    arXiv:2202.06599。
- en: 'Bastiaansen et al. [2022b] Bastiaansen, W.A., Rousian, M., Steegers-Theunissen,
    R.P., Niessen, W.J., Koning, A.H., Klein, S., 2022b. Towards a 4d spatio-temporal
    atlas of the embryonic and fetal brain using a deep learning approach for groupwise
    image registration, in: Biomedical Image Registration: 10th International Workshop,
    WBIR 2022, Munich, Germany, July 10–12, 2022, Proceedings, Springer. pp. 29–34.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bastiaansen 等 [2022b] Bastiaansen, W.A., Rousian, M., Steegers-Theunissen, R.P.,
    Niessen, W.J., Koning, A.H., Klein, S., 2022b. 基于深度学习方法进行组间图像配准的胚胎和胎儿大脑 4D 时空图谱的研究，见：生物医学图像配准：第十届国际研讨会，WBIR
    2022，德国慕尼黑，2022年7月10–12日，会议录，Springer。第29–34页。
- en: Bauer et al. [2021] Bauer, D.F., Russ, T., Waldkirch, B.I., Tönnes, C., Segars,
    W.P., Schad, L.R., Zöllner, F.G., Golla, A.K., 2021. Generation of annotated multimodal
    ground truth datasets for abdominal medical image registration. International
    journal of computer assisted radiology and surgery 16, 1277–1285.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bauer 等 [2021] Bauer, D.F., Russ, T., Waldkirch, B.I., Tönnes, C., Segars, W.P.,
    Schad, L.R., Zöllner, F.G., Golla, A.K., 2021. 生成标注的多模态地面真实数据集用于腹部医学图像配准。国际计算机辅助放射学与外科杂志
    16, 1277–1285。
- en: Beg et al. [2005] Beg, M.F., Miller, M.I., Trouvé, A., Younes, L., 2005. Computing
    large deformation metric mappings via geodesic flows of diffeomorphisms. International
    Journal of Computer Vision 61, 139–157.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beg 等 [2005] Beg, M.F., Miller, M.I., Trouvé, A., Younes, L., 2005. 通过流形的测地流计算大变形度量映射。国际计算机视觉杂志
    61, 139–157。
- en: 'Bian et al. [2022] Bian, Z., Jabri, A., Efros, A.A., Owens, A., 2022. Learning
    pixel trajectories with multiscale contrastive random walks, in: Proceedings of
    the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6508–6519.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bian 等 [2022] Bian, Z., Jabri, A., Efros, A.A., Owens, A., 2022. 使用多尺度对比随机游走学习像素轨迹，见：IEEE/CVF
    计算机视觉与模式识别会议论文集，第6508–6519页。
- en: Bian et al. [2023] Bian, Z., Xing, F., Yu, J., Shao, M., Liu, Y., Carass, A.,
    Woo, J., Prince, J.L., 2023. Deep Unsupervised Phase-based 3D Incompressible Motion
    Estimation in Tagged-MRI. arXiv preprint arXiv:2301.07234 .
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bian 等 [2023] Bian, Z., Xing, F., Yu, J., Shao, M., Liu, Y., Carass, A., Woo,
    J., Prince, J.L., 2023. 深度无监督基于相位的 3D 不可压缩运动估计在标记MRI中的应用。arXiv 预印本 arXiv:2301.07234。
- en: Bierbrier et al. [2023] Bierbrier, J., Eskandari, M., Di Giovanni, D.A., Collins,
    D.L., 2023. Towards Estimating MRI-Ultrasound Registration Error in Image-Guided
    Neurosurgery. IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency
    Control .
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bierbrier 等 [2023] Bierbrier, J., Eskandari, M., Di Giovanni, D.A., Collins,
    D.L., 2023. 针对图像引导神经外科的MRI-超声配准误差估计。IEEE 超声、电介质和频率控制汇刊。
- en: 'Bierbrier et al. [2022] Bierbrier, J., Gueziri, H.E., Collins, D.L., 2022.
    Estimating medical image registration error and confidence: A taxonomy and scoping
    review. Medical Image Analysis , 102531.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bierbrier 等 [2022] Bierbrier, J., Gueziri, H.E., Collins, D.L., 2022. 估计医学图像配准误差和置信度：一种分类和范围审查。医学图像分析，102531。
- en: Blendowski et al. [2020] Blendowski, M., Bouteldja, N., Heinrich, M.P., 2020.
    Multimodal 3D medical image registration guided by shape encoder–decoder networks.
    International journal of computer assisted radiology and surgery 15, 269–276.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blendowski等人 [2020] Blendowski, M., Bouteldja, N., Heinrich, M.P., 2020. 由形状编码器-解码器网络引导的多模态3D医学图像配准。国际计算机辅助放射学与外科杂志
    15, 269–276。
- en: Blendowski et al. [2021] Blendowski, M., Hansen, L., Heinrich, M.P., 2021. Weakly-supervised
    learning of multi-modal features for regularised iterative descent in 3D image
    registration. Medical Image Analysis 67, 101822.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blendowski等人 [2021] Blendowski, M., Hansen, L., Heinrich, M.P., 2021. 弱监督学习用于3D图像配准中的正则化迭代下降的多模态特征。医学图像分析
    67, 101822。
- en: Bobrow et al. [2022] Bobrow, T.L., Golhar, M., Vijayan, R., Akshintala, V.S.,
    Garcia, J.R., Durr, N.J., 2022. Colonoscopy 3D Video Dataset with Paired Depth
    from 2D-3D Registration. arXiv preprint arXiv:2206.08903 .
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bobrow等人 [2022] Bobrow, T.L., Golhar, M., Vijayan, R., Akshintala, V.S., Garcia,
    J.R., Durr, N.J., 2022. 具有2D-3D配准的配对深度的结肠镜3D视频数据集。arXiv预印本 arXiv:2206.08903。
- en: 'Bône et al. [2020] Bône, A., Vernhet, P., Colliot, O., Durrleman, S., 2020.
    Learning joint shape and appearance representations with metamorphic auto-encoders,
    in: 23${}^{\mbox{\tiny{rd}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2020), Springer. pp. 202–211.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bône等人 [2020] Bône, A., Vernhet, P., Colliot, O., Durrleman, S., 2020. 使用变形自编码器学习联合形状和外观表示，在：第23${}^{\mbox{\tiny{届}}}$医学图像计算与计算机辅助干预国际会议
    (MICCAI 2020)，Springer. pp. 202–211。
- en: Brett et al. [2001] Brett, M., Leff, A.P., Rorden, C., Ashburner, J., 2001.
    Spatial normalization of brain images with focal lesions using cost function masking.
    NeuroImage 14, 486–500.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brett等人 [2001] Brett, M., Leff, A.P., Rorden, C., Ashburner, J., 2001. 使用代价函数遮蔽进行脑部图像的空间标准化。NeuroImage
    14, 486–500。
- en: Brown et al. [2020] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D.,
    Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020.
    Language models are few-shot learners. Advances in Neural Information Processing
    Systems 33, 1877–1901.
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown等人 [2020] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal,
    P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., 等，2020. 语言模型是少样本学习者。神经信息处理系统进展
    33, 1877–1901。
- en: Burger et al. [2013] Burger, M., Modersitzki, J., Ruthotto, L., 2013. A hyperelastic
    regularization energy for image registration. SIAM Journal on Scientific Computing
    35, B132–B148.
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Burger等人 [2013] Burger, M., Modersitzki, J., Ruthotto, L., 2013. 用于图像配准的超弹性正则化能量。SIAM科学计算期刊
    35, B132–B148。
- en: Cabezas et al. [2011] Cabezas, M., Oliver, A., Lladó, X., Freixenet, J., Cuadra,
    M.B., 2011. A review of atlas-based segmentation for magnetic resonance brain
    images. Computer Methods and Programs in Biomedicine 104, e158–e177.
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cabezas等人 [2011] Cabezas, M., Oliver, A., Lladó, X., Freixenet, J., Cuadra,
    M.B., 2011. 基于图谱的磁共振脑部图像分割综述。生物医学计算方法与程序 104, e158–e177。
- en: 'Cao et al. [2017] Cao, X., Yang, J., Zhang, J., Nie, D., Kim, M., Wang, Q.,
    Shen, D., 2017. Deformable image registration based on similarity-steered cnn
    regression, in: 20${}^{\mbox{\tiny{th}}}$ International Conference on Medical
    Image Computing and Computer Assisted Intervention (MICCAI 2017), Springer. pp.
    300–308.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao等人 [2017] Cao, X., Yang, J., Zhang, J., Nie, D., Kim, M., Wang, Q., Shen,
    D., 2017. 基于相似性引导的cnn回归的可变形图像配准，在：第20${}^{\mbox{\tiny{届}}}$医学图像计算与计算机辅助干预国际会议
    (MICCAI 2017)，Springer. pp. 300–308。
- en: 'Carion et al. [2020] Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov,
    A., Zagoruyko, S., 2020. End-to-end object detection with transformers, in: Computer
    Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings,
    Part I 16, Springer. pp. 213–229.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Carion等人 [2020] Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov,
    A., Zagoruyko, S., 2020. 基于变换器的端到端目标检测，在：计算机视觉–ECCV 2020: 第16届欧洲会议，英国格拉斯哥，2020年8月23-28日，会议录，第I部分
    16, Springer. pp. 213–229。'
- en: 'Casamitjana et al. [2021] Casamitjana, A., Mancini, M., Iglesias, J.E., 2021.
    Synth-by-reg (sbr): Contrastive learning for synthesis-based registration of paired
    images, in: Simulation and Synthesis in Medical Imaging: 6th International Workshop,
    SASHIMI 2021, Held in Conjunction with MICCAI 2021, Strasbourg, France, September
    27, 2021, Proceedings 6, Springer. pp. 44–54.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Casamitjana等人 [2021] Casamitjana, A., Mancini, M., Iglesias, J.E., 2021. Synth-by-reg
    (sbr): 基于合成的图像配对对比学习，在：医学成像中的模拟与合成：第6届国际研讨会，SASHIMI 2021，MICCAI 2021附属，法国斯特拉斯堡，2021年9月27日，会议录
    6, Springer. pp. 44–54。'
- en: Castillo et al. [2009] Castillo, R., Castillo, E., Guerra, R., Johnson, V.E.,
    McPhail, T., Garg, A.K., Guerrero, T., 2009. A framework for evaluation of deformable
    image registration spatial accuracy using large landmark point sets. Physics in
    Medicine & Biology 54, 1849.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Castillo等人 [2009] Castillo, R., Castillo, E., Guerra, R., Johnson, V.E., McPhail,
    T., Garg, A.K., Guerrero, T., 2009. 使用大规模标志点集评估可变形图像配准空间准确性的框架。医学与生物学物理学 54, 1849。
- en: 'Chen et al. [2021a] Chen, C.F.R., Fan, Q., Panda, R., 2021a. Crossvit: Cross-attention
    multi-scale vision transformer for image classification, in: Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 357–366.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen等人 [2021a] Chen, C.F.R., Fan, Q., Panda, R., 2021a. Crossvit: 用于图像分类的交叉注意力多尺度视觉变换器，载于：IEEE/CVF计算机视觉与模式识别会议论文集，第357–366页。'
- en: 'Chen et al. [2022a] Chen, J., Frey, E.C., Du, Y., 2022a. Unsupervised learning
    of diffeomorphic image registration via transmorph, in: Biomedical Image Registration:
    10th International Workshop, WBIR 2022, Munich, Germany, July 10–12, 2022, Proceedings,
    Springer. pp. 96–102.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人 [2022a] Chen, J., Frey, E.C., Du, Y., 2022a. 通过Transmorph进行的无监督流形图像配准，载于：生物医学图像配准：第10届国际研讨会，WBIR
    2022，德国慕尼黑，2022年7月10–12日，会议论文集，Springer。第96–102页。
- en: 'Chen et al. [2022b] Chen, J., Frey, E.C., He, Y., Segars, W.P., Li, Y., Du,
    Y., 2022b. Transmorph: Transformer for unsupervised medical image registration.
    Medical Image Analysis 82, 102615.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen等人 [2022b] Chen, J., Frey, E.C., He, Y., Segars, W.P., Li, Y., Du, Y.,
    2022b. Transmorph: 用于无监督医学图像配准的变换器。医学图像分析 82, 102615。'
- en: 'Chen et al. [2021b] Chen, J., He, Y., Frey, E., Li, Y., Du, Y., 2021b. Vit-v-net:
    Vision transformer for unsupervised volumetric medical image registration, in:
    Medical Imaging with Deep Learning.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen等人 [2021b] Chen, J., He, Y., Frey, E., Li, Y., Du, Y., 2021b. Vit-v-net:
    用于无监督体积医学图像配准的视觉变换器，载于：深度学习医学成像。'
- en: Chen et al. [2020] Chen, J., Li, Y., Du, Y., Frey, E.C., 2020. Generating anthropomorphic
    phantoms using fully unsupervised deformable image registration with convolutional
    neural networks. Medical physics 47, 6366–6380.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人 [2020] Chen, J., Li, Y., Du, Y., Frey, E.C., 2020. 使用完全无监督的可变形图像配准与卷积神经网络生成拟人化幻影。医学物理
    47, 6366–6380。
- en: Chen et al. [2023a] Chen, J., Liu, Y., He, Y., Du, Y., 2023a. Deformable cross-attention
    transformer for medical image registration. arXiv preprint arXiv:2303.06179 .
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人 [2023a] Chen, J., Liu, Y., He, Y., Du, Y., 2023a. 用于医学图像配准的可变形交叉注意力变换器。arXiv预印本
    arXiv:2303.06179。
- en: Chen et al. [2023b] Chen, J., Liu, Y., He, Y., Du, Y., 2023b. Spatially-varying
    regularization with conditional transformer for unsupervised image registration.
    arXiv preprint arXiv:2303.06168 .
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人 [2023b] Chen, J., Liu, Y., He, Y., Du, Y., 2023b. 使用条件变换器进行无监督图像配准的空间变异正则化。arXiv预印本
    arXiv:2303.06168。
- en: 'Chen et al. [2022c] Chen, J., Lu, D., Zhang, Y., Wei, D., Ning, M., Shi, X.,
    Xu, Z., Zheng, Y., 2022c. Deformer: Towards displacement field learning for unsupervised
    medical image registration, in: 25${}^{\mbox{\tiny{th}}}$ International Conference
    on Medical Image Computing and Computer Assisted Intervention (MICCAI 2022), Springer.
    pp. 141–151.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen等人 [2022c] Chen, J., Lu, D., Zhang, Y., Wei, D., Ning, M., Shi, X., Xu,
    Z., Zheng, Y., 2022c. Deformer: 旨在为无监督医学图像配准学习位移场，载于：第25届医学图像计算与计算机辅助手术国际会议（MICCAI
    2022），Springer。第141–151页。'
- en: 'Chen et al. [2021c] Chen, L., Wu, Z., Hu, D., Pei, Y., Zhao, F., Sun, Y., Wang,
    Y., Lin, W., Wang, L., Li, G., et al., 2021c. Construction of longitudinally consistent
    4d infant cerebellum atlases based on deep learning, in: 24${}^{\mbox{\tiny{th}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2021),
    Springer. pp. 139–149.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人 [2021c] Chen, L., Wu, Z., Hu, D., Pei, Y., Zhao, F., Sun, Y., Wang, Y.,
    Lin, W., Wang, L., Li, G., 等, 2021c. 基于深度学习的纵向一致4D婴儿小脑图谱构建，载于：第24届医学图像计算与计算机辅助手术国际会议（MICCAI
    2021），Springer。第139–149页。
- en: Chen et al. [2018] Chen, R.T., Rubanova, Y., Bettencourt, J., Duvenaud, D.K.,
    2018. Neural ordinary differential equations. Advances in Neural Information Processing
    Systems 31.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人 [2018] Chen, R.T., Rubanova, Y., Bettencourt, J., Duvenaud, D.K., 2018.
    神经常微分方程。神经信息处理系统进展 31。
- en: Chen et al. [2021d] Chen, X., Diaz-Pinto, A., Ravikumar, N., Frangi, A.F., 2021d.
    Deep learning in medical image registration. Progress in Biomedical Engineering
    3, 012003.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人 [2021d] Chen, X., Diaz-Pinto, A., Ravikumar, N., Frangi, A.F., 2021d.
    医学图像配准中的深度学习。生物医学工程进展 3, 012003。
- en: 'Chen et al. [2021e] Chen, X., Meng, Y., Zhao, Y., Williams, R., Vallabhaneni,
    S.R., Zheng, Y., 2021e. Learning unsupervised parameter-specific affine transformation
    for medical images registration, in: 24${}^{\mbox{\tiny{th}}}$ International Conference
    on Medical Image Computing and Computer Assisted Intervention (MICCAI 2021), Springer.
    pp. 24–34.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 [2021e] Chen, X., Meng, Y., Zhao, Y., Williams, R., Vallabhaneni, S.R.,
    Zheng, Y., 2021e. 学习无监督参数特定的仿射变换用于医学图像配准，见：第24届医学图像计算与计算机辅助手术国际会议 (MICCAI 2021)，Springer.
    页 24–34。
- en: 'Chen et al. [2021f] Chen, X., Xia, Y., Ravikumar, N., Frangi, A.F., 2021f.
    A deep discontinuity-preserving image registration network, in: 24${}^{\mbox{\tiny{th}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2021),
    Springer. pp. 46–55.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 [2021f] Chen, X., Xia, Y., Ravikumar, N., Frangi, A.F., 2021f. 一种深度断点保持图像配准网络，见：第24届医学图像计算与计算机辅助手术国际会议
    (MICCAI 2021)，Springer. 页 46–55。
- en: Cheng et al. [2020a] Cheng, J., Dalca, A.V., Fischl, B., Zöllei, L., Alzheimer’s
    Disease Neuroimaging Initiative, et al., 2020a. Cortical surface registration
    using unsupervised learning. NeuroImage 221, 117161.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 等人 [2020a] Cheng, J., Dalca, A.V., Fischl, B., Zöllei, L., 阿尔茨海默病神经影像学倡议等,
    2020a. 使用无监督学习的皮层表面配准。神经影像 221, 117161。
- en: 'Cheng et al. [2020b] Cheng, J., Dalca, A.V., Zöllei, L., 2020b. Unbiased atlas
    construction for neonatal cortical surfaces via unsupervised learning, in: Medical
    Ultrasound, and Preterm, Perinatal and Paediatric Image Analysis: First International
    Workshop, ASMUS 2020, and 5th International Workshop, PIPPI 2020, Held in Conjunction
    with MICCAI 2020, Lima, Peru, October 4-8, 2020, Proceedings 1, Springer. pp.
    334–342.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 等人 [2020b] Cheng, J., Dalca, A.V., Zöllei, L., 2020b. 通过无监督学习构建新生儿皮层表面的无偏图谱，见：医学超声以及早产、围产期和儿科图像分析：第一届国际研讨会，ASMUS
    2020，以及第五届国际研讨会，PIPPI 2020，与MICCAI 2020联合举办，秘鲁利马，2020年10月4-8日，会议录 1, Springer.
    页 334–342。
- en: Christensen et al. [1997] Christensen, G.E., Joshi, S.C., Miller, M.I., 1997.
    Volumetric transformation of brain anatomy. IEEE Trans. Med. Imag. 16, 864–877.
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Christensen 等人 [1997] Christensen, G.E., Joshi, S.C., Miller, M.I., 1997. 大脑解剖的体积变换。IEEE
    医学成像交易 16, 864–877。
- en: Christensen et al. [1996] Christensen, G.E., Rabbitt, R.D., Miller, M.I., 1996.
    Deformable templates using large deformation kinematics. IEEE transactions on
    image processing 5, 1435–1447.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Christensen 等人 [1996] Christensen, G.E., Rabbitt, R.D., Miller, M.I., 1996.
    使用大变形运动学的可变形模板。IEEE 图像处理交易 5, 1435–1447。
- en: 'Croquet et al. [2021] Croquet, B., Christiaens, D., Weinberg, S.M., Bronstein,
    M., Vandermeulen, D., Claes, P., 2021. Unsupervised diffeomorphic surface registration
    and non-linear modelling, in: Medical Image Computing and Computer Assisted Intervention–MICCAI
    2021: 24th International Conference, Strasbourg, France, September 27–October
    1, 2021, Proceedings, Part IV 24, Springer. pp. 118–128.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Croquet 等人 [2021] Croquet, B., Christiaens, D., Weinberg, S.M., Bronstein,
    M., Vandermeulen, D., Claes, P., 2021. 无监督同胚表面配准与非线性建模，见：医学图像计算与计算机辅助手术–MICCAI
    2021: 第24届国际会议，法国斯特拉斯堡，2021年9月27日–10月1日，会议录，第IV部分 24, Springer. 页 118–128。'
- en: 'Crum et al. [2007] Crum, W.R., Camara, O., Hawkes, D.J., 2007. Methods for
    inverting dense displacement fields: Evaluation in brain image registration, in:
    10${}^{\mbox{\tiny{th}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2007), Springer. pp. 900–907.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Crum 等人 [2007] Crum, W.R., Camara, O., Hawkes, D.J., 2007. 反转稠密位移场的方法：在脑图像配准中的评估，见：第10届医学图像计算与计算机辅助手术国际会议
    (MICCAI 2007)，Springer. 页 900–907。
- en: 'Czolbe et al. [2021] Czolbe, S., Krause, O., Feragen, A., 2021. Semantic similarity
    metrics for learned image registration, in: Medical Imaging with Deep Learning,
    PMLR. pp. 105–118.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Czolbe 等人 [2021] Czolbe, S., Krause, O., Feragen, A., 2021. 用于学习图像配准的语义相似性度量，见：深度学习医学成像，PMLR.
    页 105–118。
- en: Dalca et al. [2019a] Dalca, A., Rakic, M., Guttag, J., Sabuncu, M., 2019a. Learning
    conditional deformable templates with convolutional networks. Advances in Neural
    Information Processing Systems 32.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dalca 等人 [2019a] Dalca, A., Rakic, M., Guttag, J., Sabuncu, M., 2019a. 使用卷积网络学习条件可变形模板。神经信息处理系统进展
    32。
- en: Dalca et al. [2019b] Dalca, A.V., Balakrishnan, G., Guttag, J., Sabuncu, M.R.,
    2019b. Unsupervised learning of probabilistic diffeomorphic registration for images
    and surfaces. Medical Image Analysis 57, 226–236.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dalca 等人 [2019b] Dalca, A.V., Balakrishnan, G., Guttag, J., Sabuncu, M.R., 2019b.
    无监督学习图像和表面的概率同胚配准。医学图像分析 57, 226–236。
- en: 'Dave et al. [2022] Dave, I., Gupta, R., Rizve, M.N., Shah, M., 2022. Tclr:
    Temporal contrastive learning for video representation. Computer Vision and Image
    Understanding 219, 103406.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dave et al. [2022] Dave, I., Gupta, R., Rizve, M.N., Shah, M., 2022. Tclr：用于视频表示的时间对比学习。计算机视觉与图像理解
    219, 103406。
- en: 'Davis et al. [2004] Davis, B., Lorenzen, P., Joshi, S.C., 2004. Large deformation
    minimum mean squared error template estimation for computational anatomy., in:
    2${}^{\mbox{\tiny{nd}}}$ International Symposium on Biomedical Imaging (ISBI 2004),
    pp. 173–176.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Davis et al. [2004] Davis, B., Lorenzen, P., Joshi, S.C., 2004. 大变形最小均方差模板估计用于计算解剖学，见：第2届生物医学成像国际研讨会（ISBI
    2004），页码173–176。
- en: De Vos et al. [2019] De Vos, B.D., Berendsen, F.F., Viergever, M.A., Sokooti,
    H., Staring, M., Išgum, I., 2019. A deep learning framework for unsupervised affine
    and deformable image registration. Medical Image Analysis 52, 128–143.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: De Vos et al. [2019] De Vos, B.D., Berendsen, F.F., Viergever, M.A., Sokooti,
    H., Staring, M., Išgum, I., 2019. 一种用于无监督仿射和变形图像配准的深度学习框架。医学图像分析 52, 128–143。
- en: 'De Vos et al. [2017] De Vos, B.D., Berendsen, F.F., Viergever, M.A., Staring,
    M., Išgum, I., 2017. End-to-end unsupervised deformable image registration with
    a convolutional neural network, in: Deep Learning in Medical Image Analysis and
    Multimodal Learning for Clinical Decision Support: Third International Workshop,
    DLMIA 2017, and 7th International Workshop, ML-CDS 2017, Held in Conjunction with
    MICCAI 2017, Québec City, QC, Canada, September 14, Proceedings 3, Springer. pp.
    204–212.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: De Vos et al. [2017] De Vos, B.D., Berendsen, F.F., Viergever, M.A., Staring,
    M., Išgum, I., 2017. 基于卷积神经网络的端到端无监督变形图像配准，见：医学图像分析中的深度学习与临床决策支持的多模态学习：第三届国际研讨会，DLMIA
    2017，以及第七届国际研讨会，ML-CDS 2017，MICCAI 2017期间举办，魁北克市，加拿大，9月14日，Proceedings 3，Springer出版社。页码204–212。
- en: 'Dey et al. [2021] Dey, N., Ren, M., Dalca, A.V., Gerig, G., 2021. Generative
    adversarial registration for improved conditional deformable templates, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3929–3941.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dey et al. [2021] Dey, N., Ren, M., Dalca, A.V., Gerig, G., 2021. 生成对抗配准以改进条件变形模板，见：IEEE/CVF计算机视觉与模式识别大会论文集，页码3929–3941。
- en: 'Dey et al. [2022] Dey, N., Schlemper, J., Salehi, S.S.M., Zhou, B., Gerig,
    G., Sofka, M., 2022. Contrareg: Contrastive learning of multi-modality unsupervised
    deformable image registration, in: 25${}^{\mbox{\tiny{th}}}$ International Conference
    on Medical Image Computing and Computer Assisted Intervention (MICCAI 2022), Springer.
    pp. 66–77.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dey et al. [2022] Dey, N., Schlemper, J., Salehi, S.S.M., Zhou, B., Gerig, G.,
    Sofka, M., 2022. Contrareg：多模态无监督变形图像配准的对比学习，见：第25届医学图像计算与计算机辅助干预国际会议（MICCAI 2022），Springer出版社。页码66–77。
- en: Ding et al. [2022a] Ding, W., Li, L., Zhuang, X., Huang, L., 2022a. Cross-modality
    multi-atlas segmentation via deep registration and label fusion. IEEE Journal
    of Biomedical and Health Informatics 26, 3104–3115.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding et al. [2022a] Ding, W., Li, L., Zhuang, X., Huang, L., 2022a. 通过深度配准和标签融合进行跨模态多图谱分割。IEEE生物医学与健康信息学杂志
    26, 3104–3115。
- en: 'Ding et al. [2022b] Ding, X., Zhang, X., Han, J., Ding, G., 2022b. Scaling
    up your kernels to 31x31: Revisiting large kernel design in cnns, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 11963–11975.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding et al. [2022b] Ding, X., Zhang, X., Han, J., Ding, G., 2022b. 将你的核扩展到31x31：重新审视CNN中的大核设计，见：IEEE/CVF计算机视觉与模式识别大会论文集，页码11963–11975。
- en: 'Ding et al. [2019] Ding, Z., Han, X., Niethammer, M., 2019. Votenet: A deep
    learning label fusion method for multi-atlas segmentation, in: 22${}^{\mbox{\tiny{nd}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2019),
    Springer. pp. 202–210.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding et al. [2019] Ding, Z., Han, X., Niethammer, M., 2019. Votenet：一种用于多图谱分割的深度学习标签融合方法，见：第22届医学图像计算与计算机辅助干预国际会议（MICCAI
    2019），Springer出版社。页码202–210。
- en: 'Ding et al. [2020] Ding, Z., Han, X., Niethammer, M., 2020. Votenet+: An improved
    deep learning label fusion method for multi-atlas segmentation, in: 17${}^{\mbox{\tiny{th}}}$
    International Symposium on Biomedical Imaging (ISBI 2020), IEEE. pp. 363–367.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding et al. [2020] Ding, Z., Han, X., Niethammer, M., 2020. Votenet+：一种改进的深度学习标签融合方法用于多图谱分割，见：第17届生物医学成像国际研讨会（ISBI
    2020），IEEE出版社。页码363–367。
- en: 'Ding and Niethammer [2021] Ding, Z., Niethammer, M., 2021. Votenet++: Registration
    refinement for multi-atlas segmentation, in: 18${}^{\mbox{\tiny{th}}}$ International
    Symposium on Biomedical Imaging (ISBI 2021), IEEE. pp. 275–279.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding and Niethammer [2021] Ding, Z., Niethammer, M., 2021. Votenet++：多图谱分割的配准精化，见：第18届生物医学成像国际研讨会（ISBI
    2021），IEEE出版社。页码275–279。
- en: 'Ding and Niethammer [2022] Ding, Z., Niethammer, M., 2022. Aladdin: Joint atlas
    building and diffeomorphic registration learning with pairwise alignment, in:
    Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    pp. 20784–20793.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding和Niethammer [2022] Ding, Z., Niethammer, M., 2022. Aladdin：使用成对对齐进行联合图谱构建和光滑配准学习，见：IEEE/CVF计算机视觉与模式识别会议论文集，pp.
    20784–20793。
- en: Dlouhy et al. [2014] Dlouhy, B.J., Rao, R.C., Page, P., Julià, D., Gómez, N.,
    Codina-Cazador, A., 2014. Surgical skill and complication rates after bariatric
    surgery. The New England journal of medicine 370, 285–285.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dlouhy等人 [2014] Dlouhy, B.J., Rao, R.C., Page, P., Julià, D., Gómez, N., Codina-Cazador,
    A., 2014. 胃肠手术后的手术技能和并发症发生率。《新英格兰医学杂志》370, 285–285。
- en: Dong et al. [2023] Dong, G., Dai, J., Li, N., Zhang, C., He, W., Liu, L., Chan,
    Y., Li, Y., Xie, Y., Liang, X., 2023. 2D/3D Non-Rigid Image Registration via Two
    Orthogonal X-ray Projection Images for Lung Tumor Tracking. Bioengineering 10,
    144.
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong等人 [2023] Dong, G., Dai, J., Li, N., Zhang, C., He, W., Liu, L., Chan, Y.,
    Li, Y., Xie, Y., Liang, X., 2023. 通过两张正交X射线投影图像进行2D/3D非刚性图像配准以跟踪肺肿瘤。《生物工程》10,
    144。
- en: 'Dong et al. [2022] Dong, X., Bao, J., Chen, D., Zhang, W., Yu, N., Yuan, L.,
    Chen, D., Guo, B., 2022. Cswin transformer: A general vision transformer backbone
    with cross-shaped windows, in: Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition, pp. 12124–12134.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong等人 [2022] Dong, X., Bao, J., Chen, D., Zhang, W., Yu, N., Yuan, L., Chen,
    D., Guo, B., 2022. Cswin transformer：一种具有交叉形窗口的通用视觉变换器主干，见：IEEE/CVF计算机视觉与模式识别会议论文集，pp.
    12124–12134。
- en: 'Dosovitskiy et al. [2021] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,
    D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly,
    S., Uszkoreit, J., Houlsby, N., 2021. An image is worth 16x16 words: Transformers
    for image recognition at scale, in: International Conference on Learning Representations.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dosovitskiy等人 [2021] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,
    D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly,
    S., Uszkoreit, J., Houlsby, N., 2021. 一张图胜过16x16个词：用于大规模图像识别的变换器，见：国际学习表征会议。
- en: 'Dosovitskiy et al. [2020] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,
    D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly,
    S., et al., 2020. An image is worth 16x16 words: Transformers for image recognition
    at scale. arXiv preprint arXiv:2010.11929 .'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dosovitskiy等人 [2020] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,
    D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly,
    S., 等人, 2020. 一张图胜过16x16个词：用于大规模图像识别的变换器。arXiv预印本 arXiv:2010.11929。
- en: 'Dosovitskiy et al. [2015] Dosovitskiy, A., Fischer, P., Ilg, E., Hausser, P.,
    Hazirbas, C., Golkov, V., Van Der Smagt, P., Cremers, D., Brox, T., 2015. Flownet:
    Learning optical flow with convolutional networks, in: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, pp. 2758–2766.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dosovitskiy等人 [2015] Dosovitskiy, A., Fischer, P., Ilg, E., Hausser, P., Hazirbas,
    C., Golkov, V., Van Der Smagt, P., Cremers, D., Brox, T., 2015. Flownet：使用卷积网络学习光流，见：IEEE/CVF计算机视觉与模式识别会议论文集，pp.
    2758–2766。
- en: Duan et al. [2019] Duan, L., Yuan, G., Gong, L., Fu, T., Yang, X., Chen, X.,
    Zheng, J., 2019. Adversarial learning for deformable registration of brain MR
    image using a multi-scale fully convolutional network. Biomedical Signal Processing
    and Control 53, 101562.
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Duan等人 [2019] Duan, L., Yuan, G., Gong, L., Fu, T., Yang, X., Chen, X., Zheng,
    J., 2019. 用于脑部MR图像的多尺度全卷积网络的对抗性学习。生物医学信号处理与控制 53, 101562。
- en: 'Dumoulin et al. [2017] Dumoulin, V., Shlens, J., Kudlur, M., 2017. A learned
    representation for artistic style, in: International Conference on Learning Representations.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dumoulin等人 [2017] Dumoulin, V., Shlens, J., Kudlur, M., 2017. 艺术风格的学习表征，见：国际学习表征会议。
- en: Ehrhardt et al. [2010] Ehrhardt, J., Werner, R., Schmidt-Richberg, A., Handels,
    H., 2010. Automatic landmark detection and non-linear landmark-and surface-based
    registration of lung CT images. Medical Image Analysis for the Clinic-A Grand
    Challenge, MICCAI 2010, 165–174.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ehrhardt等人 [2010] Ehrhardt, J., Werner, R., Schmidt-Richberg, A., Handels, H.,
    2010. 肺CT图像的自动标志物检测和非线性标志物与表面配准。《医学图像分析的临床应用-重大挑战》，MICCAI 2010, 165–174。
- en: 'Elmahdy et al. [2019] Elmahdy, M.S., Wolterink, J.M., Sokooti, H., Išgum, I.,
    Staring, M., 2019. Adversarial optimization for joint registration and segmentation
    in prostate CT radiotherapy, in: 22${}^{\mbox{\tiny{nd}}}$ International Conference
    on Medical Image Computing and Computer Assisted Intervention (MICCAI 2019), Springer.
    pp. 366–374.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elmahdy等人 [2019] Elmahdy, M.S., Wolterink, J.M., Sokooti, H., Išgum, I., Staring,
    M., 2019. 前列腺CT放射治疗中联合配准和分割的对抗优化，见：第22届国际医学图像计算与计算机辅助手术会议（MICCAI 2019），Springer，pp.
    366–374。
- en: 'Eppenhof et al. [2018] Eppenhof, K.A., Lafarge, M.W., Moeskops, P., Veta, M.,
    Pluim, J.P., 2018. Deformable image registration using convolutional neural networks,
    in: Medical Imaging 2018: Image Processing, SPIE. pp. 192–197.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eppenhof et al. [2018] Eppenhof, K.A., Lafarge, M.W., Moeskops, P., Veta, M.,
    Pluim, J.P., 2018. 使用卷积神经网络的可变形图像配准，发表于：医学影像2018：图像处理，SPIE出版社。第192–197页。
- en: Eppenhof et al. [2019] Eppenhof, K.A., Lafarge, M.W., Veta, M., Pluim, J.P.,
    2019. Progressively trained convolutional neural networks for deformable image
    registration. IEEE Trans. Med. Imag. 39, 1594–1604.
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eppenhof et al. [2019] Eppenhof, K.A., Lafarge, M.W., Veta, M., Pluim, J.P.,
    2019. 用于可变形图像配准的渐进训练卷积神经网络。《IEEE医学影像学杂志》39, 1594–1604。
- en: Eppenhof and Pluim [2018a] Eppenhof, K.A., Pluim, J.P., 2018a. Error estimation
    of deformable image registration of pulmonary CT scans using convolutional neural
    networks. Journal of Medical Imaging 5, 024003–024003.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eppenhof and Pluim [2018a] Eppenhof, K.A., Pluim, J.P., 2018a. 使用卷积神经网络对肺部CT扫描的可变形图像配准进行误差估计。《医学影像学杂志》5,
    024003–024003。
- en: Eppenhof and Pluim [2018b] Eppenhof, K.A., Pluim, J.P., 2018b. Pulmonary CT
    registration through supervised learning with convolutional neural networks. IEEE
    Trans. Med. Imag. 38, 1097–1105.
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eppenhof and Pluim [2018b] Eppenhof, K.A., Pluim, J.P., 2018b. 通过卷积神经网络的监督学习进行肺部CT配准。《IEEE医学影像学杂志》38,
    1097–1105。
- en: Fan et al. [2019a] Fan, J., Cao, X., Wang, Q., Yap, P.T., Shen, D., 2019a. Adversarial
    learning for mono-or multi-modal registration. Medical Image Analysis 58, 101545.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan et al. [2019a] Fan, J., Cao, X., Wang, Q., Yap, P.T., Shen, D., 2019a. 单模态或多模态配准的对抗学习。《医学图像分析》58,
    101545。
- en: 'Fan et al. [2018] Fan, J., Cao, X., Xue, Z., Yap, P.T., Shen, D., 2018. Adversarial
    similarity network for evaluating image alignment in deep learning based registration,
    in: 21${}^{\mbox{\tiny{st}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2018), Springer. pp. 739–746.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan et al. [2018] Fan, J., Cao, X., Xue, Z., Yap, P.T., Shen, D., 2018. 用于评估深度学习基础配准中的图像对齐的对抗相似性网络，发表于：第21届医学图像计算与计算机辅助手术国际会议（MICCAI
    2018），Springer出版社。第739–746页。
- en: 'Fan et al. [2019b] Fan, J., Cao, X., Yap, P.T., Shen, D., 2019b. Birnet: Brain
    image registration using dual-supervised fully convolutional networks. Medical
    Image Analysis 54, 193–206.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan et al. [2019b] Fan, J., Cao, X., Yap, P.T., Shen, D., 2019b. Birnet：使用双重监督全卷积网络的脑部图像配准。《医学图像分析》54,
    193–206。
- en: Fang et al. [2019] Fang, L., Zhang, L., Nie, D., Cao, X., Rekik, I., Lee, S.W.,
    He, H., Shen, D., 2019. Automatic brain labeling via multi-atlas guided fully
    convolutional networks. Medical Image Analysis 51, 157–168.
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fang et al. [2019] Fang, L., Zhang, L., Nie, D., Cao, X., Rekik, I., Lee, S.W.,
    He, H., Shen, D., 2019. 通过多图谱引导全卷积网络进行自动脑部标注。《医学图像分析》51, 157–168。
- en: Fechter and Baltas [2020] Fechter, T., Baltas, D., 2020. One-shot learning for
    deformable medical image registration and periodic motion tracking. IEEE Trans.
    Med. Imag. 39, 2506–2517.
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fechter and Baltas [2020] Fechter, T., Baltas, D., 2020. 用于可变形医学图像配准和周期性运动跟踪的一次性学习。《IEEE医学影像学杂志》39,
    2506–2517。
- en: 'Fischer and Modersitzki [2003a] Fischer, B., Modersitzki, J., 2003a. Combination
    of automatic non-rigid and landmark-based registration: the best of both worlds,
    in: Medical Imaging 2003: Image Processing, SPIE. pp. 1037–1048.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fischer and Modersitzki [2003a] Fischer, B., Modersitzki, J., 2003a. 结合自动非刚性配准和基于标志的配准：两者的最佳结合，发表于：医学影像2003：图像处理，SPIE出版社。第1037–1048页。
- en: Fischer and Modersitzki [2003b] Fischer, B., Modersitzki, J., 2003b. Curvature
    based image registration. Journal of Mathematical Imaging and Vision 18, 81–85.
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fischer and Modersitzki [2003b] Fischer, B., Modersitzki, J., 2003b. 基于曲率的图像配准。《数学成像与视觉杂志》18,
    81–85。
- en: Fluck et al. [2011] Fluck, O., Vetter, C., Wein, W., Kamen, A., Preim, B., Westermann,
    R., 2011. A survey of medical image registration on graphics hardware. Computer
    Methods and Programs in Biomedicine 104, e45–e57.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluck et al. [2011] Fluck, O., Vetter, C., Wein, W., Kamen, A., Preim, B., Westermann,
    R., 2011. 基于图形硬件的医学图像配准调查。《生物医学计算方法与程序》104, e45–e57。
- en: 'Foote et al. [2019] Foote, M.D., Zimmerman, B.E., Sawant, A., Joshi, S.C.,
    2019. Real-time 2D-3D deformable registration with deep learning and application
    to lung radiotherapy targeting, in: Information Processing in Medical Imaging:
    26th International Conference, IPMI 2019, Hong Kong, China, June 2–7, 2019, Proceedings
    26, Springer. pp. 265–276.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Foote et al. [2019] Foote, M.D., Zimmerman, B.E., Sawant, A., Joshi, S.C., 2019.
    实时2D-3D可变形配准与深度学习及其在肺部放射治疗靶向中的应用，发表于：医学影像信息处理：第26届国际会议，IPMI 2019，香港，中国，2019年6月2日至7日，会议录26，Springer出版社。第265–276页。
- en: 'Franceschi et al. [2018] Franceschi, L., Frasconi, P., Salzo, S., Grazzi, R.,
    Pontil, M., 2018. Bilevel programming for hyperparameter optimization and meta-learning,
    in: 35${}^{\mbox{\tiny{th}}}$ International Conference on Machine Learning (ICML 2016),
    PMLR. pp. 1568–1577.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Franceschi 等人 [2018] Franceschi, L., Frasconi, P., Salzo, S., Grazzi, R., Pontil,
    M., 2018. 超参数优化和元学习的双层规划，见：第 35${}^{\mbox{\tiny{届}}}$ 国际机器学习大会 (ICML 2016)，PMLR。第
    1568–1577 页。
- en: 'François et al. [2022] François, A., Maillard, M., Oppenheim, C., Pallud, J.,
    Bloch, I., Gori, P., Glaunès, J., 2022. Weighted metamorphosis for registration
    of images with different topologies, in: Biomedical Image Registration: 10th International
    Workshop, WBIR 2022, Munich, Germany, July 10–12, 2022, Proceedings, Springer.
    pp. 8–17.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: François 等人 [2022] François, A., Maillard, M., Oppenheim, C., Pallud, J., Bloch,
    I., Gori, P., Glaunès, J., 2022. 用于不同拓扑图像配准的加权变形，见：生物医学图像配准：第 10 届国际研讨会，WBIR 2022，德国慕尼黑，2022
    年 7 月 10–12 日，会议录，Springer。第 8–17 页。
- en: Friston et al. [1995] Friston, K.J., Ashburner, J., Frith, C.D., Poline, J.B.,
    Heather, J.D., Frackowiak, R.S., 1995. Spatial registration and normalization
    of images. Human brain mapping 3, 165–189.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Friston 等人 [1995] Friston, K.J., Ashburner, J., Frith, C.D., Poline, J.B., Heather,
    J.D., Frackowiak, R.S., 1995. 图像的空间配准和标准化。人脑映射 3, 165–189。
- en: 'Fu et al. [2020a] Fu, Y., Lei, Y., Wang, T., Curran, W.J., Liu, T., Yang, X.,
    2020a. Deep learning in medical image registration: a review. Physics in Medicine
    & Biology 65, 20TR01.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu 等人 [2020a] Fu, Y., Lei, Y., Wang, T., Curran, W.J., Liu, T., Yang, X., 2020a.
    医学图像配准中的深度学习：综述。医学与生物学物理学 65, 20TR01。
- en: 'Fu et al. [2020b] Fu, Y., Lei, Y., Wang, T., Higgins, K., Bradley, J.D., Curran,
    W.J., Liu, T., Yang, X., 2020b. LungRegNet: an unsupervised deformable image registration
    method for 4D-CT lung. Medical physics 47, 1763–1774.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu 等人 [2020b] Fu, Y., Lei, Y., Wang, T., Higgins, K., Bradley, J.D., Curran,
    W.J., Liu, T., Yang, X., 2020b. LungRegNet：一种用于 4D-CT 肺部的无监督可变形图像配准方法。医学物理学 47,
    1763–1774。
- en: Fu et al. [2018] Fu, Y., Liu, S., Li, H.H., Li, H., Yang, D., 2018. An adaptive
    motion regularization technique to support sliding motion in deformable image
    registration. Medical physics 45, 735–747.
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu 等人 [2018] Fu, Y., Liu, S., Li, H.H., Li, H., Yang, D., 2018. 一种自适应运动正则化技术以支持可变形图像配准中的滑动运动。医学物理学
    45, 735–747。
- en: Fu et al. [2021] Fu, Y., Wang, T., Lei, Y., Patel, P., Jani, A.B., Curran, W.J.,
    Liu, T., Yang, X., 2021. Deformable MR-CBCT prostate registration using biomechanically
    constrained deep learning networks. Medical Physics 48, 253–263.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu 等人 [2021] Fu, Y., Wang, T., Lei, Y., Patel, P., Jani, A.B., Curran, W.J.,
    Liu, T., Yang, X., 2021. 使用生物力学约束的深度学习网络进行可变形 MR-CBCT 前列腺配准。医学物理学 48, 253–263。
- en: 'Gal and Ghahramani [2016] Gal, Y., Ghahramani, Z., 2016. Dropout as a bayesian
    approximation: Representing model uncertainty in deep learning, in: 33${}^{\mbox{\tiny{rd}}}$
    International Conference on Machine Learning (ICML 2016), PMLR. pp. 1050–1059.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gal 和 Ghahramani [2016] Gal, Y., Ghahramani, Z., 2016. Dropout 作为贝叶斯近似：在深度学习中表示模型不确定性，见：第
    33${}^{\mbox{\tiny{届}}}$ 国际机器学习大会 (ICML 2016)，PMLR。第 1050–1059 页。
- en: Ganser et al. [2004] Ganser, K.A., Dickhaus, H., Metzner, R., Wirtz, C.R., 2004.
    A deformable digital brain atlas system according to talairach and tournoux. Medical
    Image Analysis 8, 3–22.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ganser 等人 [2004] Ganser, K.A., Dickhaus, H., Metzner, R., Wirtz, C.R., 2004.
    一种根据 Talairach 和 Tournoux 的可变形数字脑图谱系统。医学图像分析 8, 3–22。
- en: 'Gao et al. [2020a] Gao, C., Grupp, R.B., Unberath, M., Taylor, R.H., Armand,
    M., 2020a. Fiducial-free 2D/3D registration of the proximal femur for robot-assisted
    femoroplasty, in: Medical Imaging 2020: Image-Guided Procedures, Robotic Interventions,
    and Modeling, SPIE. pp. 350–355.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等人 [2020a] Gao, C., Grupp, R.B., Unberath, M., Taylor, R.H., Armand, M.,
    2020a. 无需标记的 2D/3D 近端股骨配准用于机器人辅助股骨成形术，见：医学成像 2020：图像引导程序、机器人干预和建模，SPIE。第 350–355
    页。
- en: 'Gao et al. [2020b] Gao, C., Liu, X., Gu, W., Killeen, B., Armand, M., Taylor,
    R., Unberath, M., 2020b. Generalizing spatial transformers to projective geometry
    with applications to 2D/3D registration, in: 23${}^{\mbox{\tiny{rd}}}$ International
    Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2020),
    Springer. pp. 329–339.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等人 [2020b] Gao, C., Liu, X., Gu, W., Killeen, B., Armand, M., Taylor, R.,
    Unberath, M., 2020b. 将空间变换器推广到投影几何及其在 2D/3D 配准中的应用，见：第 23${}^{\mbox{\tiny{届}}}$
    国际医学图像计算与计算机辅助干预会议 (MICCAI 2020)，Springer。第 329–339 页。
- en: Ger et al. [2017] Ger, R.B., Yang, J., Ding, Y., Jacobsen, M.C., Fuller, C.D.,
    Howell, R.M., Li, H., Jason Stafford, R., Zhou, S., Court, L.E., 2017. Accuracy
    of deformable image registration on magnetic resonance images in digital and physical
    phantoms. Medical Physics 44, 5153–5161.
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ger 等人 [2017] Ger, R.B., Yang, J., Ding, Y., Jacobsen, M.C., Fuller, C.D., Howell,
    R.M., Li, H., Jason Stafford, R., Zhou, S., Court, L.E., 2017. 在数字和物理幻影中的磁共振图像上变形图像配准的准确性。医学物理学
    44, 第5153–5161页。
- en: 'Gerig et al. [2014] Gerig, T., Shahim, K., Reyes, M., Vetter, T., Lüthi, M.,
    2014. Spatially varying registration using gaussian processes, in: 17${}^{\mbox{\tiny{th}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2014),
    Springer. pp. 413–420.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gerig 等人 [2014] Gerig, T., Shahim, K., Reyes, M., Vetter, T., Lüthi, M., 2014.
    使用高斯过程的空间变异配准, in: 第17届医学图像计算与计算机辅助干预国际会议 (MICCAI 2014), Springer. 第413–420页。'
- en: 'Gong et al. [2022] Gong, X., Khaidem, L., Zhu, W., Zhang, B., Doermann, D.,
    2022. Uncertainty learning towards unsupervised deformable medical image registration,
    in: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer
    Vision, pp. 2484–2493.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gong 等人 [2022] Gong, X., Khaidem, L., Zhu, W., Zhang, B., Doermann, D., 2022.
    走向无监督变形医学图像配准的不确定性学习, in: IEEE/CVF 冬季计算机视觉应用会议论文集, 第2484–2493页。'
- en: Goodfellow et al. [2020] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,
    Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., 2020. Generative adversarial
    networks. Communications of the ACM 63, 139–144.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等人 [2020] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley,
    D., Ozair, S., Courville, A., Bengio, Y., 2020. 生成对抗网络。ACM 通讯 63, 第139–144页。
- en: 'Greer et al. [2021] Greer, H., Kwitt, R., Vialard, F.X., Niethammer, M., 2021.
    Icon: Learning regular maps through inverse consistency, in: Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3396–3405.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Greer 等人 [2021] Greer, H., Kwitt, R., Vialard, F.X., Niethammer, M., 2021.
    Icon: 通过逆一致性学习常规映射, in: IEEE/CVF 计算机视觉与模式识别会议论文集, 第3396–3405页。'
- en: 'Grzech et al. [2022] Grzech, D., Azampour, M.F., Glocker, B., Schnabel, J.,
    Navab, N., Kainz, B., Le Folgoc, L., 2022. A variational bayesian method for similarity
    learning in non-rigid image registration, in: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 119–128.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Grzech 等人 [2022] Grzech, D., Azampour, M.F., Glocker, B., Schnabel, J., Navab,
    N., Kainz, B., Le Folgoc, L., 2022. 用于非刚性图像配准的变分贝叶斯方法, in: IEEE/CVF 计算机视觉与模式识别会议论文集,
    第119–128页。'
- en: Gu et al. [2020] Gu, W., Gao, C., Grupp, R., Fotouhi, J., Unberath, M., 2020.
    Extended Capture Range of Rigid 2D/3D Registration by Estimating Riemannian Pose
    Gradients. Machine learning in medical imaging. MLMI 12436, 281–291.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu 等人 [2020] Gu, W., Gao, C., Grupp, R., Fotouhi, J., Unberath, M., 2020. 通过估计黎曼位姿梯度扩展的刚性2D/3D配准范围。医学影像中的机器学习。MLMI
    12436, 第281–291页。
- en: 'Guimond et al. [2000] Guimond, A., Meunier, J., Thirion, J.P., 2000. Average
    brain models: A convergence study. Computer Vision and Image Understanding 77,
    192–210.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guimond 等人 [2000] Guimond, A., Meunier, J., Thirion, J.P., 2000. 平均脑模型：收敛性研究。计算机视觉与图像理解
    77, 第192–210页。
- en: Guo [2019] Guo, C.K., 2019. Multi-modal image registration with unsupervised
    deep learning. Ph.D. thesis. Massachusetts Institute of Technology.
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo [2019] Guo, C.K., 2019. 使用无监督深度学习进行多模态图像配准。博士论文。麻省理工学院。
- en: Guo et al. [2022] Guo, H., Xu, X., Song, X., Xu, S., Chao, H., Myers, J., Turkbey,
    B., Pinto, P.A., Wood, B.J., Yan, P., 2022. Ultrasound frame-to-volume registration
    via deep learning for interventional guidance. IEEE Transactions on Ultrasonics,
    Ferroelectrics, and Frequency Control .
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等人 [2022] Guo, H., Xu, X., Song, X., Xu, S., Chao, H., Myers, J., Turkbey,
    B., Pinto, P.A., Wood, B.J., Yan, P., 2022. 通过深度学习进行超声帧到体积的配准用于干预指导。IEEE 超声波、电介质与频率控制汇刊。
- en: 'Ha et al. [2017] Ha, D., Dai, A.M., Le, Q.V., 2017. Hypernetworks, in: International
    Conference on Learning Representations.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ha 等人 [2017] Ha, D., Dai, A.M., Le, Q.V., 2017. Hypernetworks, in: 国际学习表征会议。'
- en: 'Haber and Modersitzki [2006] Haber, E., Modersitzki, J., 2006. Intensity gradient
    based registration and fusion of multi-modal images, in: 9${}^{\mbox{\tiny{th}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2006),
    Springer. pp. 726–733.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Haber 和 Modersitzki [2006] Haber, E., Modersitzki, J., 2006. 基于强度梯度的配准和多模态图像融合,
    in: 第9届医学图像计算与计算机辅助干预国际会议 (MICCAI 2006), Springer. 第726–733页。'
- en: 'Han et al. [2023] Han, K., Sun, S., Yan, X., You, C., Tang, H., Naushad, J.,
    Ma, H., Kong, D., Xie, X., 2023. Diffeomorphic image registration with neural
    velocity field, in: Proceedings of the IEEE/CVF Winter Conference on Applications
    of Computer Vision, pp. 1869–1879.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等 [2023] Han, K., Sun, S., Yan, X., You, C., Tang, H., Naushad, J., Ma,
    H., Kong, D., Xie, X., 2023. 基于神经速度场的微分同胚图像配准，发表于IEEE/CVF冬季计算机视觉应用会议论文集，第1869–1879页。
- en: Han et al. [2022] Han, R., Jones, C.K., Lee, J., Wu, P., Vagdargi, P., Uneri,
    A., Helm, P.A., Luciano, M., Anderson, W.S., Siewerdsen, J.H., 2022. Deformable
    mr-ct image registration using an unsupervised, dual-channel network for neurosurgical
    guidance. Medical image analysis 75, 102292.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等 [2022] Han, R., Jones, C.K., Lee, J., Wu, P., Vagdargi, P., Uneri, A.,
    Helm, P.A., Luciano, M., Anderson, W.S., Siewerdsen, J.H., 2022. 使用无监督的双通道网络进行可变形MR-CT图像配准以用于神经外科引导。医学图像分析
    75, 102292。
- en: Han et al. [2021] Han, X., Hong, J., Reyngold, M., Crane, C., Cuaron, J., Hajj,
    C., Mann, J., Zinovoy, M., Greer, H., Yorke, E., et al., 2021. Deep-learning-based
    image registration and automatic segmentation of organs-at-risk in cone-beam CT
    scans from high-dose radiation treatment of pancreatic cancer. Medical physics
    48, 3084–3095.
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等 [2021] Han, X., Hong, J., Reyngold, M., Crane, C., Cuaron, J., Hajj, C.,
    Mann, J., Zinovoy, M., Greer, H., Yorke, E., 等，2021. 基于深度学习的图像配准和在高剂量辐射治疗胰腺癌的圆锥束CT扫描中自动分割风险器官。医学物理
    48, 3084–3095。
- en: 'Han et al. [2020] Han, X., Shen, Z., Xu, Z., Bakas, S., Akbari, H., Bilello,
    M., Davatzikos, C., Niethammer, M., 2020. A deep network for joint registration
    and reconstruction of images with pathologies, in: Machine Learning in Medical
    Imaging: 11th International Workshop, MLMI 2020, Held in Conjunction with MICCAI
    2020, Lima, Peru, October 4, 2020, Proceedings 11, Springer. pp. 342–352.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等 [2020] Han, X., Shen, Z., Xu, Z., Bakas, S., Akbari, H., Bilello, M.,
    Davatzikos, C., Niethammer, M., 2020. 用于病理图像的联合配准与重建的深度网络，发表于医学影像中的机器学习：第11届国际研讨会，MLMI
    2020，与MICCAI 2020同时举行，秘鲁利马，2020年10月4日，会议论文集11，Springer. 第342–352页。
- en: 'Hansen and Heinrich [2021] Hansen, L., Heinrich, M.P., 2021. GraphRegNet: Deep
    graph regularisation networks on sparse keypoints for dense registration of 3D
    lung CTs. IEEE Trans. Med. Imag. 40, 2246–2257.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hansen 和 Heinrich [2021] Hansen, L., Heinrich, M.P., 2021. GraphRegNet: 基于稀疏关键点的深度图正则化网络，用于3D肺CT的密集配准。IEEE
    Trans. Med. Imag. 40, 2246–2257。'
- en: 'Harley et al. [2022] Harley, A.W., Fang, Z., Fragkiadaki, K., 2022. Particle
    video revisited: Tracking through occlusions using point trajectories, in: Computer
    Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022,
    Proceedings, Part XXII, Springer. pp. 59–75.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Harley 等 [2022] Harley, A.W., Fang, Z., Fragkiadaki, K., 2022. 粒子视频再探：使用点轨迹跟踪遮挡，发表于计算机视觉–ECCV
    2022：第17届欧洲会议，特拉维夫，以色列，2022年10月23–27日，会议论文集，第XXII部分，Springer. 第59–75页。
- en: Haskins et al. [2019] Haskins, G., Kruecker, J., Kruger, U., Xu, S., Pinto,
    P.A., Wood, B.J., Yan, P., 2019. Learning deep similarity metric for 3D MR–TRUS
    image registration. International journal of computer assisted radiology and surgery
    14, 417–425.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haskins 等 [2019] Haskins, G., Kruecker, J., Kruger, U., Xu, S., Pinto, P.A.,
    Wood, B.J., Yan, P., 2019. 学习深度相似性度量进行3D MR-TRUS图像配准。计算机辅助放射学与手术国际期刊 14, 417–425。
- en: 'He et al. [2016] He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning
    for image recognition, in: Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition, pp. 770–778.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等 [2016] He, K., Zhang, X., Ren, S., Sun, J., 2016. 图像识别的深度残差学习，发表于IEEE/CVF计算机视觉与模式识别会议论文集，第770–778页。
- en: 'He and Chung [2021] He, Z., Chung, A.C., 2021. Learning-based template synthesis
    for groupwise image registration, in: Simulation and Synthesis in Medical Imaging:
    6th International Workshop, SASHIMI 2021, Held in Conjunction with MICCAI 2021,
    Strasbourg, France, September 27, 2021, Proceedings 6, Springer. pp. 55–66.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 和 Chung [2021] He, Z., Chung, A.C., 2021. 基于学习的模板合成用于组图像配准，发表于医学影像中的仿真与合成：第6届国际研讨会，SASHIMI
    2021，与MICCAI 2021同时举行，法国斯特拉斯堡，2021年9月27日，会议论文集6，Springer. 第55–66页。
- en: 'Heinrich [2019] Heinrich, M.P., 2019. Closing the gap between deep and conventional
    image registration using probabilistic dense displacement networks, in: 22${}^{\mbox{\tiny{nd}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2019),
    Springer. pp. 50–58.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heinrich [2019] Heinrich, M.P., 2019. 利用概率密集位移网络缩小深度图像配准与传统图像配准之间的差距，发表于第22${}^{\mbox{\tiny{nd}}}$届医学图像计算与计算机辅助干预国际会议
    (MICCAI 2019)，Springer. 第50–58页。
- en: 'Heinrich et al. [2015] Heinrich, M.P., Handels, H., Simpson, I.J., 2015. Estimating
    large lung motion in copd patients by symmetric regularised correspondence fields,
    in: 18${}^{\mbox{\tiny{th}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2015), Springer. pp. 338–345.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heinrich 等 [2015] Heinrich, M.P., Handels, H., Simpson, I.J., 2015. 通过对称正则化对应场估计
    COPD 患者的大范围肺部运动，见于：第18届国际医学图像计算与计算机辅助手术会议 (MICCAI 2015)，Springer。第338-345页。
- en: 'Heinrich and Hansen [2020] Heinrich, M.P., Hansen, L., 2020. Highly accurate
    and memory efficient unsupervised learning-based discrete CT registration using
    2.5 D displacement search, in: 23${}^{\mbox{\tiny{rd}}}$ International Conference
    on Medical Image Computing and Computer Assisted Intervention (MICCAI 2020), Springer.
    pp. 190–200.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heinrich 和 Hansen [2020] Heinrich, M.P., Hansen, L., 2020. 高精度且内存高效的无监督学习离散
    CT 配准，使用 2.5 D 位移搜索，见于：第23届国际医学图像计算与计算机辅助手术会议 (MICCAI 2020)，Springer。第190-200页。
- en: 'Heinrich and Hansen [2022] Heinrich, M.P., Hansen, L., 2022. Voxelmorph++ going
    beyond the cranial vault with keypoint supervision and multi-channel instance
    optimisation, in: Biomedical Image Registration: 10th International Workshop,
    WBIR 2022, Munich, Germany, July 10–12, 2022, Proceedings, Springer. pp. 85–95.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heinrich 和 Hansen [2022] Heinrich, M.P., Hansen, L., 2022. Voxelmorph++ 超越颅骨的关键点监督和多通道实例优化，见于：生物医学图像配准：第10届国际研讨会，WBIR
    2022，德国慕尼黑，2022年7月10-12日，会议论文集，Springer。第85-95页。
- en: 'Heinrich et al. [2012] Heinrich, M.P., Jenkinson, M., Bhushan, M., Matin, T.,
    Gleeson, F.V., Brady, M., Schnabel, J.A., 2012. Mind: Modality independent neighbourhood
    descriptor for multi-modal deformable registration. Medical Image Analysis 16,
    1423–1435.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Heinrich 等 [2012] Heinrich, M.P., Jenkinson, M., Bhushan, M., Matin, T., Gleeson,
    F.V., Brady, M., Schnabel, J.A., 2012. Mind: 模态独立邻域描述符用于多模态可变形配准。医学图像分析 16, 1423–1435。'
- en: 'Heinrich et al. [2013] Heinrich, M.P., Jenkinson, M., Papież, B.W., Brady,
    S.M., Schnabel, J.A., 2013. Towards realtime multimodal fusion for image-guided
    interventions using self-similarities, in: 16${}^{\mbox{\tiny{th}}}$ International
    Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2013),
    Springer. pp. 187–194.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heinrich 等 [2013] Heinrich, M.P., Jenkinson, M., Papież, B.W., Brady, S.M.,
    Schnabel, J.A., 2013. 向实时多模态融合迈进，用于图像引导干预，使用自相似性，见于：第16届国际医学图像计算与计算机辅助手术会议 (MICCAI
    2013)，Springer。第187-194页。
- en: 'Heinrich et al. [2019] Heinrich, M.P., Oktay, O., Bouteldja, N., 2019. OBELISK-Net:
    Fewer layers to solve 3D multi-organ segmentation with sparse deformable convolutions.
    Medical Image Analysis 54, 1–9.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Heinrich 等 [2019] Heinrich, M.P., Oktay, O., Bouteldja, N., 2019. OBELISK-Net:
    更少的层解决 3D 多脏器分割问题，采用稀疏可变形卷积。医学图像分析 54, 1–9。'
- en: 'Hering et al. [2019] Hering, A., Ginneken, B.v., Heldmann, S., 2019. mlvirnet:
    Multilevel variational image registration network, in: 22${}^{\mbox{\tiny{nd}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2019),
    Springer. pp. 257–265.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hering 等 [2019] Hering, A., Ginneken, B.v., Heldmann, S., 2019. mlvirnet: 多级变分图像配准网络，见于：第22届国际医学图像计算与计算机辅助手术会议
    (MICCAI 2019)，Springer。第257-265页。'
- en: Hering et al. [2021] Hering, A., Häger, S., Moltz, J., Lessmann, N., Heldmann,
    S., van Ginneken, B., 2021. CNN-based lung CT registration with multiple anatomical
    constraints. Medical Image Analysis 72, 102139.
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hering 等 [2021] Hering, A., Häger, S., Moltz, J., Lessmann, N., Heldmann, S.,
    van Ginneken, B., 2021. 基于 CNN 的肺部 CT 配准与多重解剖约束。医学图像分析 72, 102139。
- en: 'Hering et al. [2022] Hering, A., Hansen, L., Mok, T.C., Chung, A.C., Siebert,
    H., Häger, S., Lange, A., Kuckertz, S., Heldmann, S., Shao, W., et al., 2022.
    Learn2reg: comprehensive multi-task medical image registration challenge, dataset
    and evaluation in the era of deep learning. IEEE Trans. Med. Imag. .'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hering 等 [2022] Hering, A., Hansen, L., Mok, T.C., Chung, A.C., Siebert, H.,
    Häger, S., Lange, A., Kuckertz, S., Heldmann, S., Shao, W., 等，2022. Learn2reg:
    全面的多任务医学图像配准挑战，数据集和评估在深度学习时代。IEEE 医学影像学期刊。'
- en: Hernandez et al. [2009] Hernandez, M., Bossa, M.N., Olmos, S., 2009. Registration
    of anatomical images using paths of diffeomorphisms parameterized with stationary
    vector field flows. International Journal of Computer Vision 85, 291–306.
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hernandez 等 [2009] Hernandez, M., Bossa, M.N., Olmos, S., 2009. 使用流形路径的解剖图像配准，流形参数化为静态向量场流。计算机视觉国际期刊
    85, 291–306。
- en: Hill et al. [2001] Hill, D.L., Batchelor, P.G., Holden, M., Hawkes, D.J., 2001.
    Medical image registration. Physics in Medicine & Biology 46, R1.
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hill 等 [2001] Hill, D.L., Batchelor, P.G., Holden, M., Hawkes, D.J., 2001. 医学图像配准。医学与生物学物理学
    46, R1。
- en: Ho et al. [2020] Ho, J., Jain, A., Abbeel, P., 2020. Denoising diffusion probabilistic
    models. Advances in Neural Information Processing Systems 33, 6840–6851.
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ho et al. [2020] Ho, J., Jain, A., Abbeel, P., 2020. 去噪扩散概率模型。Advances in Neural
    Information Processing Systems 33, 6840–6851.
- en: Ho et al. [2023] Ho, T.T., Kim, W.J., Lee, C.H., Jin, G.Y., Chae, K.J., Choi,
    S., 2023. An unsupervised image registration method employing chest computed tomography
    images and deep neural networks. Computers in Biology and Medicine 154, 106612.
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ho et al. [2023] Ho, T.T., Kim, W.J., Lee, C.H., Jin, G.Y., Chae, K.J., Choi,
    S., 2023. 一种利用胸部计算机断层扫描图像和深度神经网络的无监督图像配准方法。Computers in Biology and Medicine 154,
    106612.
- en: 'Hoffmann et al. [2021] Hoffmann, M., Billot, B., Greve, D.N., Iglesias, J.E.,
    Fischl, B., Dalca, A.V., 2021. Synthmorph: learning contrast-invariant registration
    without acquired images. IEEE Trans. Med. Imag. 41, 543–558.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hoffmann et al. [2021] Hoffmann, M., Billot, B., Greve, D.N., Iglesias, J.E.,
    Fischl, B., Dalca, A.V., 2021. Synthmorph: 在没有获取图像的情况下学习对比不变性配准。IEEE Trans. Med.
    Imag. 41, 543–558.'
- en: 'Hofmann et al. [2008] Hofmann, M., Steinke, F., Scheel, V., Charpiat, G., Farquhar,
    J., Aschoff, P., Brady, M., Schölkopf, B., Pichler, B.J., 2008. MRI-based attenuation
    correction for PET/MRI: a novel approach combining pattern recognition and atlas
    registration. Journal of nuclear medicine 49, 1875–1883.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hofmann et al. [2008] Hofmann, M., Steinke, F., Scheel, V., Charpiat, G., Farquhar,
    J., Aschoff, P., Brady, M., Schölkopf, B., Pichler, B.J., 2008. 基于MRI的PET/MRI衰减校正：一种结合模式识别和图谱配准的新方法。Journal
    of nuclear medicine 49, 1875–1883.
- en: Holland et al. [2011] Holland, D., Dale, A.M., Alzheimer’s Disease Neuroimaging
    Initiative, et al., 2011. Nonlinear registration of longitudinal images and measurement
    of change in regions of interest. Medical Image Analysis 15, 489–497.
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Holland et al. [2011] Holland, D., Dale, A.M., Alzheimer’s Disease Neuroimaging
    Initiative, et al., 2011. 非线性配准纵向图像及感兴趣区域变化的测量。Medical Image Analysis 15, 489–497.
- en: 'Hong et al. [2012] Hong, Y., Joshi, S., Sanchez, M., Styner, M., Niethammer,
    M., 2012. Metamorphic geodesic regression, in: 15${}^{\mbox{\tiny{th}}}$ International
    Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2012),
    Springer. pp. 197–205.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong et al. [2012] Hong, Y., Joshi, S., Sanchez, M., Styner, M., Niethammer,
    M., 2012. 变形几何回归，见：第15届医学图像计算与计算机辅助干预国际会议（MICCAI 2012），Springer。pp. 197–205.
- en: Hoopes et al. [2022] Hoopes, A., Hoffman, M., Greve, D.N., Fischl, B., Guttag,
    J., Dalca, A.V., 2022. Learning the effect of registration hyperparameters with
    hypermorph. Machine Learning for Biomedical Imaging 1, 1–30.
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hoopes et al. [2022] Hoopes, A., Hoffman, M., Greve, D.N., Fischl, B., Guttag,
    J., Dalca, A.V., 2022. 通过hypermorph学习配准超参数的影响。机器学习在生物医学影像中的应用 1, 1–30.
- en: 'Hoopes et al. [2021] Hoopes, A., Hoffmann, M., Fischl, B., Guttag, J., Dalca,
    A.V., 2021. Hypermorph: Amortized hyperparameter learning for image registration,
    in: Information Processing in Medical Imaging: 27th International Conference,
    IPMI 2021, Virtual Event, June 28–June 30, 2021, Proceedings 27, Springer. pp.
    3–17.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hoopes et al. [2021] Hoopes, A., Hoffmann, M., Fischl, B., Guttag, J., Dalca,
    A.V., 2021. Hypermorph：用于图像配准的摊销超参数学习，见：医学影像处理信息：第27届国际会议，IPMI 2021，虚拟会议，2021年6月28日至6月30日，会议论文集27，Springer。pp.
    3–17.
- en: 'Hu et al. [2020] Hu, B., Zhou, S., Xiong, Z., Wu, F., 2020. Self-recursive
    contextual network for unsupervised 3D medical image registration, in: Machine
    Learning in Medical Imaging: 11th International Workshop, MLMI 2020, Held in Conjunction
    with MICCAI 2020, Lima, Peru, October 4, 2020, Proceedings 11, Springer. pp. 60–69.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. [2020] Hu, B., Zhou, S., Xiong, Z., Wu, F., 2020. 用于无监督3D医学图像配准的自递归上下文网络，见：机器学习在医学影像中的应用：第11届国际研讨会，MLMI
    2020，与MICCAI 2020联合举办，2020年10月4日，秘鲁利马，会议论文集11，Springer。pp. 60–69.
- en: Hu et al. [2019a] Hu, J., Sun, S., Yang, X., Zhou, S., Wang, X., Fu, Y., Zhou,
    J., Yin, Y., Cao, K., Song, Q., et al., 2019a. Towards accurate and robust multi-modal
    medical image registration using contrastive metric learning. IEEE Access 7, 132816–132827.
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. [2019a] Hu, J., Sun, S., Yang, X., Zhou, S., Wang, X., Fu, Y., Zhou,
    J., Yin, Y., Cao, K., Song, Q., et al., 2019a. 通过对比度度量学习实现准确且稳健的多模态医学图像配准。IEEE
    Access 7, 132816–132827.
- en: 'Hu et al. [2019b] Hu, X., Kang, M., Huang, W., Scott, M.R., Wiest, R., Reyes,
    M., 2019b. Dual-stream pyramid registration network, in: 22${}^{\mbox{\tiny{nd}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2019),
    Springer. pp. 382–390.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. [2019b] Hu, X., Kang, M., Huang, W., Scott, M.R., Wiest, R., Reyes,
    M., 2019b. 双流金字塔配准网络，见：第22届医学图像计算与计算机辅助干预国际会议（MICCAI 2019），Springer。pp. 382–390.
- en: 'Hu et al. [2018a] Hu, Y., Modat, M., Gibson, E., Ghavami, N., Bonmati, E.,
    Moore, C.M., Emberton, M., Noble, J.A., Barratt, D.C., Vercauteren, T., 2018a.
    Label-driven weakly-supervised learning for multimodal deformable image registration,
    in: 15${}^{\mbox{\tiny{th}}}$ International Symposium on Biomedical Imaging (ISBI 2018),
    IEEE. pp. 1070–1074.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等 [2018a] Hu, Y., Modat, M., Gibson, E., Ghavami, N., Bonmati, E., Moore,
    C.M., Emberton, M., Noble, J.A., Barratt, D.C., Vercauteren, T., 2018a. 基于标签的弱监督学习用于多模态变形图像配准，见：第15届国际生物医学成像研讨会（ISBI
    2018），IEEE. pp. 1070–1074。
- en: Hu et al. [2018b] Hu, Y., Modat, M., Gibson, E., Li, W., Ghavami, N., Bonmati,
    E., Wang, G., Bandula, S., Moore, C.M., Emberton, M., et al., 2018b. Weakly-supervised
    convolutional neural networks for multimodal image registration. Medical Image
    Analysis 49, 1–13.
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等 [2018b] Hu, Y., Modat, M., Gibson, E., Li, W., Ghavami, N., Bonmati, E.,
    Wang, G., Bandula, S., Moore, C.M., Emberton, M., 等，2018b. 弱监督卷积神经网络用于多模态图像配准。医学图像分析
    49, 1–13。
- en: 'Huang et al. [2022] Huang, D.X., Zhou, X.H., Xie, X.L., Liu, S.Q., Feng, Z.Q.,
    Hao, J.L., Hou, Z.G., Ma, N., Yan, L., 2022. A Novel Two-Stage Framework for 2D/3D
    Registration in Neurological Interventions, in: 2022 IEEE International Conference
    on Robotics and Biomimetics (ROBIO), IEEE. pp. 266–271.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等 [2022] Huang, D.X., Zhou, X.H., Xie, X.L., Liu, S.Q., Feng, Z.Q., Hao,
    J.L., Hou, Z.G., Ma, N., Yan, L., 2022. 一种新型的两阶段框架用于神经学干预中的 2D/3D 配准，见：2022 IEEE
    国际机器人与仿生学会议（ROBIO），IEEE. pp. 266–271。
- en: 'Huang et al. [2017] Huang, G., Li, Y., Pleiss, G., Liu, Z., Hopcroft, J.E.,
    Weinberger, K.Q., 2017. Snapshot ensembles: Train 1, get m for free, in: International
    Conference on Learning Representations.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等 [2017] Huang, G., Li, Y., Pleiss, G., Liu, Z., Hopcroft, J.E., Weinberger,
    K.Q., 2017. 快照集成：训练 1 个，免费获得 m 个，见：国际学习表征会议。
- en: 'Iglesias and Sabuncu [2015] Iglesias, J.E., Sabuncu, M.R., 2015. Multi-atlas
    segmentation of biomedical images: a survey. Medical Image Analysis 24, 205–219.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iglesias 和 Sabuncu [2015] Iglesias, J.E., Sabuncu, M.R., 2015. 生物医学图像的多图谱分割：综述。医学图像分析
    24, 205–219。
- en: 'Ilg et al. [2018] Ilg, E., Cicek, O., Galesso, S., Klein, A., Makansi, O.,
    Hutter, F., Brox, T., 2018. Uncertainty estimates and multi-hypotheses networks
    for optical flow, in: Proceedings of the European Conference on Computer Vision
    (ECCV), pp. 652–667.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ilg 等 [2018] Ilg, E., Cicek, O., Galesso, S., Klein, A., Makansi, O., Hutter,
    F., Brox, T., 2018. 光流的误差估计和多假设网络，见：欧洲计算机视觉会议（ECCV）论文集，pp. 652–667。
- en: 'Ilg et al. [2017] Ilg, E., Mayer, N., Saikia, T., Keuper, M., Dosovitskiy,
    A., Brox, T., 2017. Flownet 2.0: Evolution of optical flow estimation with deep
    networks, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp. 2462–2470.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ilg 等 [2017] Ilg, E., Mayer, N., Saikia, T., Keuper, M., Dosovitskiy, A., Brox,
    T., 2017. Flownet 2.0：基于深度网络的光流估计演变，见：IEEE/CVF 计算机视觉与模式识别会议论文集，pp. 2462–2470。
- en: 'Isensee et al. [2021] Isensee, F., Jaeger, P.F., Kohl, S.A., Petersen, J.,
    Maier-Hein, K.H., 2021. nnU-Net: a self-configuring method for deep learning-based
    biomedical image segmentation. Nature Methods 18, 203–211.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Isensee 等 [2021] Isensee, F., Jaeger, P.F., Kohl, S.A., Petersen, J., Maier-Hein,
    K.H., 2021. nnU-Net：一种自配置的深度学习生物医学图像分割方法。自然方法 18, 203–211。
- en: Jabri et al. [2020] Jabri, A., Owens, A., Efros, A., 2020. Space-time correspondence
    as a contrastive random walk. Advances in Neural Information Processing Systems
    33, 19545–19560.
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jabri 等 [2020] Jabri, A., Owens, A., Efros, A., 2020. 时空对应作为对比随机游走。神经信息处理系统进展
    33, 19545–19560。
- en: Jaderberg et al. [2015] Jaderberg, M., Simonyan, K., Zisserman, A., et al.,
    2015. Spatial transformer networks. Advances in Neural Information Processing
    Systems 28.
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaderberg 等 [2015] Jaderberg, M., Simonyan, K., Zisserman, A., 等，2015. 空间变换网络。神经信息处理系统进展
    28。
- en: 'Jaganathan et al. [2023] Jaganathan, S., Kukla, M., Wang, J., Shetty, K., Maier,
    A., 2023. Self-Supervised 2D/3D Registration for X-Ray to CT Image Fusion, in:
    Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision,
    pp. 2788–2798.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaganathan 等 [2023] Jaganathan, S., Kukla, M., Wang, J., Shetty, K., Maier,
    A., 2023. 自监督 2D/3D 配准用于 X 射线与 CT 图像融合，见：IEEE/CVF 计算机视觉应用冬季会议论文集，pp. 2788–2798。
- en: 'Ji et al. [2022] Ji, Y., Zhu, Z., Wei, Y., 2022. A One-shot Lung 4D-CT Image
    Registration Method with Temporal-spatial Features, in: 2022 IEEE Biomedical Circuits
    and Systems Conference (BioCAS), IEEE. pp. 203–207.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ji 等 [2022] Ji, Y., Zhu, Z., Wei, Y., 2022. 一种基于时间空间特征的一次性肺部 4D-CT 图像配准方法，见：2022
    IEEE 生物医学电路与系统会议（BioCAS），IEEE. pp. 203–207。
- en: 'Jia et al. [2022a] Jia, X., Bartlett, J., Chen, W., Song, S., Zhang, T., Cheng,
    X., Lu, W., Qiu, Z., Duan, J., 2022a. Fourier-net: Fast image registration with
    band-limited deformation. arXiv preprint arXiv:2211.16342 .'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jia 等 [2022a] Jia, X., Bartlett, J., Chen, W., Song, S., Zhang, T., Cheng,
    X., Lu, W., Qiu, Z., Duan, J., 2022a. Fourier-net: 带带限变形的快速图像配准。arXiv 预印本 arXiv:2211.16342。'
- en: 'Jia et al. [2022b] Jia, X., Bartlett, J., Zhang, T., Lu, W., Qiu, Z., Duan,
    J., 2022b. U-net vs transformer: Is u-net outdated in medical image registration?,
    in: Machine Learning in Medical Imaging: 13th International Workshop, MLMI 2022,
    Held in Conjunction with MICCAI 2022, Singapore, September 18, 2022, Proceedings,
    Springer. pp. 151–160.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jia 等 [2022b] Jia, X., Bartlett, J., Zhang, T., Lu, W., Qiu, Z., Duan, J.,
    2022b. U-net vs transformer: U-net 在医学图像配准中是否已过时?, 见: 医学影像中的机器学习: 第 13 届国际研讨会,
    MLMI 2022, 与 MICCAI 2022 联合举行, 新加坡, 2022 年 9 月 18 日, 论文集, Springer. 第 151–160
    页。'
- en: Jia et al. [2021] Jia, X., Thorley, A., Chen, W., Qiu, H., Shen, L., Styles,
    I.B., Chang, H.J., Leonardis, A., De Marvao, A., O’Regan, D.P., et al., 2021.
    Learning a model-driven variational network for deformable image registration.
    IEEE Trans. Med. Imag. 41, 199–212.
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jia 等 [2021] Jia, X., Thorley, A., Chen, W., Qiu, H., Shen, L., Styles, I.B.,
    Chang, H.J., Leonardis, A., De Marvao, A., O’Regan, D.P., 等, 2021. 学习模型驱动的变分网络用于可变形图像配准。IEEE
    医学影像学报 41, 199–212。
- en: 'Jian et al. [2022] Jian, B., Azampour, M.F., De Benetti, F., Oberreuter, J.,
    Bukas, C., Gersing, A.S., Foreman, S.C., Dietrich, A.S., Rischewski, J., Kirschke,
    J.S., et al., 2022. Weakly-supervised Biomechanically-constrained CT/MRI Registration
    of the Spine, in: 25${}^{\mbox{\tiny{th}}}$ International Conference on Medical
    Image Computing and Computer Assisted Intervention (MICCAI 2022), Springer. pp.
    227–236.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jian 等 [2022] Jian, B., Azampour, M.F., De Benetti, F., Oberreuter, J., Bukas,
    C., Gersing, A.S., Foreman, S.C., Dietrich, A.S., Rischewski, J., Kirschke, J.S.,
    等, 2022. 弱监督的生物力学约束 CT/MRI 脊柱配准, 见: 第 25${}^{\mbox{\tiny{th}}}$ 届国际医学图像计算与计算机辅助手术会议
    (MICCAI 2022), Springer. 第 227–236 页。'
- en: Jiang et al. [2020] Jiang, Z., Yin, F.F., Ge, Y., Ren, L., 2020. A multi-scale
    framework with unsupervised joint training of convolutional neural networks for
    pulmonary deformable image registration. Physics in Medicine & Biology 65, 015011.
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等 [2020] Jiang, Z., Yin, F.F., Ge, Y., Ren, L., 2020. 一种多尺度框架与卷积神经网络的无监督联合训练用于肺部可变形图像配准。医学物理与生物学
    65, 015011。
- en: 'Jonschkowski et al. [2020] Jonschkowski, R., Stone, A., Barron, J.T., Gordon,
    A., Konolige, K., Angelova, A., 2020. What matters in unsupervised optical flow,
    in: Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28,
    2020, Proceedings, Part II 16, Springer. pp. 557–572.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jonschkowski 等 [2020] Jonschkowski, R., Stone, A., Barron, J.T., Gordon, A.,
    Konolige, K., Angelova, A., 2020. 无监督光流中的关键因素, 见: 计算机视觉–ECCV 2020: 第 16 届欧洲会议,
    格拉斯哥, 英国, 2020 年 8 月 23–28 日, 论文集, 第 II 部分 16, Springer. 第 557–572 页。'
- en: 'Joshi and Hong [2022] Joshi, A., Hong, Y., 2022. Diffeomorphic image registration
    using lipschitz continuous residual networks, in: International Conference on
    Medical Imaging with Deep Learning, PMLR. pp. 605–617.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Joshi 和 Hong [2022] Joshi, A., Hong, Y., 2022. 使用 Lipschitz 连续残差网络的 diffeomorphic
    图像配准, 见: 国际医学影像与深度学习会议, PMLR. 第 605–617 页。'
- en: Joshi et al. [2004] Joshi, S., Davis, B., Jomier, M., Gerig, G., 2004. Unbiased
    diffeomorphic atlas construction for computational anatomy. NeuroImage 23, S151–S160.
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Joshi 等 [2004] Joshi, S., Davis, B., Jomier, M., Gerig, G., 2004. 用于计算解剖学的无偏差
    diffeomorphic 图谱构建。神经影像 23, S151–S160。
- en: Kang et al. [2022] Kang, M., Hu, X., Huang, W., Scott, M.R., Reyes, M., 2022.
    Dual-stream pyramid registration network. Medical Image Analysis 78, 102379.
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang 等 [2022] Kang, M., Hu, X., Huang, W., Scott, M.R., Reyes, M., 2022. 双流金字塔配准网络。医学图像分析
    78, 102379。
- en: 'Kazerouni et al. [2022] Kazerouni, A., Aghdam, E.K., Heidari, M., Azad, R.,
    Fayyaz, M., Hacihaliloglu, I., Merhof, D., 2022. Diffusion models for medical
    image analysis: A comprehensive survey. arXiv preprint arXiv:2211.07804 .'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kazerouni 等 [2022] Kazerouni, A., Aghdam, E.K., Heidari, M., Azad, R., Fayyaz,
    M., Hacihaliloglu, I., Merhof, D., 2022. 医学图像分析中的扩散模型: 综合调查。arXiv 预印本 arXiv:2211.07804。'
- en: Kendall and Gal [2017] Kendall, A., Gal, Y., 2017. What uncertainties do we
    need in bayesian deep learning for computer vision? Advances in Neural Information
    Processing Systems 30.
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kendall 和 Gal [2017] Kendall, A., Gal, Y., 2017. 我们在计算机视觉的贝叶斯深度学习中需要哪些不确定性?
    神经信息处理系统进展 30。
- en: Khor et al. [2023] Khor, H.G., Ning, G., Sun, Y., Lu, X., Zhang, X., Liao, H.,
    2023. Anatomically constrained and attention-guided deep feature fusion for joint
    segmentation and deformable medical image registration. Medical Image Analysis
    , 102811.
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khor 等 [2023] Khor, H.G., Ning, G., Sun, Y., Lu, X., Zhang, X., Liao, H., 2023.
    解剖约束和注意力引导的深度特征融合用于联合分割和可变形医学图像配准。医学图像分析, 102811。
- en: 'Kim et al. [2022] Kim, B., Han, I., Ye, J.C., 2022. Diffusemorph: Unsupervised
    deformable image registration using diffusion model, in: Proceedings of the European
    Conference on Computer Vision (ECCV), Springer. pp. 347–364.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim et al. [2022] Kim, B., Han, I., Ye, J.C., 2022. Diffusemorph：使用扩散模型的无监督可变形图像配准，见：欧洲计算机视觉会议（ECCV）论文集，Springer.
    pp. 347–364。
- en: 'Kim et al. [2021] Kim, B., Kim, D.H., Park, S.H., Kim, J., Lee, J.G., Ye, J.C.,
    2021. Cyclemorph: cycle consistent unsupervised deformable image registration.
    Medical Image Analysis 71, 102036.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim et al. [2021] Kim, B., Kim, D.H., Park, S.H., Kim, J., Lee, J.G., Ye, J.C.,
    2021. Cyclemorph：循环一致的无监督可变形图像配准。Medical Image Analysis 71, 102036。
- en: 'Kim et al. [2019] Kim, D., Cho, D., Kweon, I.S., 2019. Self-supervised video
    representation learning with space-time cubic puzzles, in: Proceedings of the
    AAAI conference on artificial intelligence, pp. 8545–8552.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim et al. [2019] Kim, D., Cho, D., Kweon, I.S., 2019. 自监督视频表示学习与时空立方体谜题，见：AAAI人工智能会议论文集，pp.
    8545–8552。
- en: Kirillov et al. [2023] Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland,
    C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A.C., Lo, W.Y., et al., 2023.
    Segment anything. arXiv preprint arXiv:2304.02643 .
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kirillov et al. [2023] Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland,
    C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A.C., Lo, W.Y., 等，2023. Segment
    anything。arXiv预印本 arXiv:2304.02643。
- en: Kirkwood et al. [1960] Kirkwood, J.G., Baldwin, R.L., Dunlop, P.J., Gosting,
    L.J., Kegeles, G., 1960. Flow equations and frames of reference for isothermal
    diffusion in liquids. The Journal of Chemical Physics 33, 1505–1513.
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kirkwood et al. [1960] Kirkwood, J.G., Baldwin, R.L., Dunlop, P.J., Gosting,
    L.J., Kegeles, G., 1960. 等温扩散的流动方程和参考框架。The Journal of Chemical Physics 33, 1505–1513。
- en: 'Klein et al. [2009] Klein, S., Staring, M., Murphy, K., Viergever, M.A., Pluim,
    J.P., 2009. Elastix: a toolbox for intensity-based medical image registration.
    IEEE Trans. Med. Imag. 29, 196–205.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Klein et al. [2009] Klein, S., Staring, M., Murphy, K., Viergever, M.A., Pluim,
    J.P., 2009. Elastix：一个基于强度的医学图像配准工具箱。IEEE Trans. Med. Imag. 29, 196–205。
- en: Krebs et al. [2019] Krebs, J., Delingette, H., Mailhé, B., Ayache, N., Mansi,
    T., 2019. Learning a probabilistic model for diffeomorphic registration. IEEE
    Trans. Med. Imag. 38, 2165–2176.
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krebs et al. [2019] Krebs, J., Delingette, H., Mailhé, B., Ayache, N., Mansi,
    T., 2019. 学习用于微分同胚配准的概率模型。IEEE Trans. Med. Imag. 38, 2165–2176。
- en: 'Krebs et al. [2017] Krebs, J., Mansi, T., Delingette, H., Zhang, L., Ghesu,
    F.C., Miao, S., Maier, A.K., Ayache, N., Liao, R., Kamen, A., 2017. Robust non-rigid
    registration through agent-based action learning, in: 20${}^{\mbox{\tiny{th}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2017),
    Springer. pp. 344–352.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krebs et al. [2017] Krebs, J., Mansi, T., Delingette, H., Zhang, L., Ghesu,
    F.C., Miao, S., Maier, A.K., Ayache, N., Liao, R., Kamen, A., 2017. 通过基于代理的动作学习进行鲁棒非刚性配准，见：第20届医学图像计算与计算机辅助干预国际会议（MICCAI
    2017），Springer. pp. 344–352。
- en: 'Kuang [2019] Kuang, D., 2019. Cycle-consistent training for reducing negative
    jacobian determinant in deep registration networks, in: Simulation and Synthesis
    in Medical Imaging: 4th International Workshop, SASHIMI 2019, Held in Conjunction
    with MICCAI 2019, Shenzhen, China, October 13, 2019, Proceedings 4, Springer.
    pp. 120–129.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuang [2019] Kuang, D., 2019. 循环一致训练用于减少深度配准网络中的负雅可比行列式，见：医学成像中的模拟与合成：第4届国际研讨会，SASHIMI
    2019，MICCAI 2019附带会议，深圳，中国，2019年10月13日，论文集4，Springer. pp. 120–129。
- en: 'Kuang and Schmah [2019] Kuang, D., Schmah, T., 2019. Faim–a convnet method
    for unsupervised 3D medical image registration, in: International Workshop on
    Machine Learning in Medical Imaging, Springer. pp. 646–654.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuang and Schmah [2019] Kuang, D., Schmah, T., 2019. Faim–一种用于无监督3D医学图像配准的卷积网络方法，见：医学影像中的机器学习国际研讨会，Springer.
    pp. 646–654。
- en: Kybic [2009] Kybic, J., 2009. Bootstrap resampling for image registration uncertainty
    estimation without ground truth. IEEE Transactions on Image Processing 19, 64–73.
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kybic [2009] Kybic, J., 2009. 自助重采样用于图像配准不确定性估计，无需真实数据。IEEE Transactions on
    Image Processing 19, 64–73。
- en: Lai and Xie [2019] Lai, Z., Xie, W., 2019. Self-supervised learning for video
    correspondence flow. arXiv preprint arXiv:1905.00875 .
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lai and Xie [2019] Lai, Z., Xie, W., 2019. 视频对应流的自监督学习。arXiv预印本 arXiv:1905.00875。
- en: 'Lange et al. [2020] Lange, F.J., Ashburner, J., Smith, S.M., Andersson, J.L.,
    2020. A symmetric prior for the regularisation of elastic deformations: Improved
    anatomical plausibility in nonlinear image registration. NeuroImage 219, 116962.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lange et al. [2020] Lange, F.J., Ashburner, J., Smith, S.M., Andersson, J.L.,
    2020. 用于弹性变形的对称先验：改进非线性图像配准中的解剖学合理性。NeuroImage 219, 116962。
- en: 'Laves et al. [2019] Laves, M.H., Ihler, S., Ortmaier, T., 2019. Deformable
    medical image registration using a randomly-initialized CNN as regularization
    prior, in: Medical Imaging with Deep Learning.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Laves 等人 [2019] Laves, M.H., Ihler, S., Ortmaier, T., 2019. 使用随机初始化 CNN 作为正则化先验的可变形医学图像配准，见于：深度学习医学影像学。
- en: 'Le-Khac et al. [2020] Le-Khac, P.H., Healy, G., Smeaton, A.F., 2020. Contrastive
    representation learning: A framework and review. IEEE Access 8, 193907–193934.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Le-Khac 等人 [2020] Le-Khac, P.H., Healy, G., Smeaton, A.F., 2020. 对比表示学习：一个框架与综述。IEEE
    Access 8，193907–193934。
- en: Lei et al. [2020] Lei, Y., Fu, Y., Wang, T., Liu, Y., Patel, P., Curran, W.J.,
    Liu, T., Yang, X., 2020. 4D-CT deformable image registration using multiscale
    unsupervised deep learning. Physics in Medicine & Biology 65, 085003.
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lei 等人 [2020] Lei, Y., Fu, Y., Wang, T., Liu, Y., Patel, P., Curran, W.J., Liu,
    T., Yang, X., 2020. 使用多尺度无监督深度学习的 4D-CT 变形图像配准。医学与生物学物理学 65，085003。
- en: Leow et al. [2007] Leow, A.D., Yanovsky, I., Chiang, M.C., Lee, A.D., Klunder,
    A.D., Lu, A., Becker, J.T., Davis, S.W., Toga, A.W., Thompson, P.M., 2007. Statistical
    properties of jacobian maps and the realization of unbiased large-deformation
    nonlinear image registration. IEEE Trans. Med. Imag. 26, 822–832.
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Leow 等人 [2007] Leow, A.D., Yanovsky, I., Chiang, M.C., Lee, A.D., Klunder, A.D.,
    Lu, A., Becker, J.T., Davis, S.W., Toga, A.W., Thompson, P.M., 2007. 雅可比图的统计特性与无偏大变形非线性图像配准的实现。IEEE
    医学影像学杂志 26，822–832。
- en: 'Li and Fan [2018] Li, H., Fan, Y., 2018. Non-rigid image registration using
    self-supervised fully convolutional networks without training data, in: 15${}^{\mbox{\tiny{th}}}$
    International Symposium on Biomedical Imaging (ISBI 2018), IEEE. pp. 1075–1078.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 和 Fan [2018] Li, H., Fan, Y., 2018. 使用自监督全卷积网络进行非刚性图像配准，无需训练数据，见于：第 15${}^{\mbox{\tiny{th}}}$
    届生物医学影像国际研讨会（ISBI 2018），IEEE，第 1075–1078 页。
- en: Li et al. [2023] Li, J., Chen, J., Tang, Y., Wang, C., Landman, B.A., Zhou,
    S.K., 2023. Transforming medical imaging with transformers? a comparative review
    of key properties, current progresses, and future perspectives. Medical Image
    Analysis , 102762.
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 [2023] Li, J., Chen, J., Tang, Y., Wang, C., Landman, B.A., Zhou, S.K.,
    2023. 用变换器变革医学影像？关键特性、当前进展和未来展望的比较综述。医学图像分析，102762。
- en: 'Li et al. [2021] Li, L., Sinclair, M., Makropoulos, A., Hajnal, J.V., David Edwards,
    A., Kainz, B., Rueckert, D., Alansary, A., 2021. CAS-Net: conditional atlas generation
    and brain segmentation for fetal MRI, in: Uncertainty for Safe Utilization of
    Machine Learning in Medical Imaging, and Perinatal Imaging, Placental and Preterm
    Image Analysis: 3rd International Workshop, UNSURE 2021, and 6th International
    Workshop, PIPPI 2021, Held in Conjunction with MICCAI 2021, Strasbourg, France,
    October 1, 2021, Proceedings 3, Springer. pp. 221–230.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 [2021] Li, L., Sinclair, M., Makropoulos, A., Hajnal, J.V., David Edwards,
    A., Kainz, B., Rueckert, D., Alansary, A., 2021. CAS-Net：用于胎儿 MRI 的条件 atlas 生成和脑部分割，见于：医学影像中机器学习的不确定性与安全利用，以及围产期影像、胎盘和早产图像分析：第三届国际研讨会，UNSURE
    2021 和第六届国际研讨会，PIPPI 2021，与 MICCAI 2021 一同举办，法国斯特拉斯堡，2021 年 10 月 1 日，会议录第 3 卷，Springer，第
    221–230 页。
- en: 'Li et al. [2020] Li, P., Pei, Y., Guo, Y., Ma, G., Xu, T., Zha, H., 2020. Non-Rigid
    2D-3D Registration Using Convolutional Autoencoders, in: 17${}^{\mbox{\tiny{th}}}$
    International Symposium on Biomedical Imaging (ISBI 2020), pp. 700–704. doi:[10.1109/ISBI45749.2020.9098602](http://dx.doi.org/10.1109/ISBI45749.2020.9098602).'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 [2020] Li, P., Pei, Y., Guo, Y., Ma, G., Xu, T., Zha, H., 2020. 使用卷积自编码器的非刚性
    2D-3D 配准，见于：第 17${}^{\mbox{\tiny{th}}}$ 届生物医学影像国际研讨会（ISBI 2020），第 700–704 页。doi：[10.1109/ISBI45749.2020.9098602](http://dx.doi.org/10.1109/ISBI45749.2020.9098602)。
- en: 'Li and Ogino [2019] Li, Z., Ogino, M., 2019. Adversarial learning for deformable
    image registration: Application to 3d ultrasound image fusion, in: Smart Ultrasound
    Imaging and Perinatal, Preterm and Paediatric Image Analysis: First International
    Workshop, SUSI 2019, and 4th International Workshop, PIPPI 2019, Held in Conjunction
    with MICCAI 2019, Shenzhen, China, October 13 and 17, 2019, Proceedings 4, Springer.
    pp. 56–64.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 和 Ogino [2019] Li, Z., Ogino, M., 2019. 用于变形图像配准的对抗学习：应用于 3D 超声图像融合，见于：智能超声影像与围产期、早产及儿科图像分析：首届国际研讨会，SUSI
    2019 和第四届国际研讨会，PIPPI 2019，与 MICCAI 2019 一同举办，中国深圳，2019 年 10 月 13 和 17 日，会议录第 4
    卷，Springer，第 56–64 页。
- en: 'Liao et al. [2019] Liao, H., Lin, W.A., Zhang, J., Zhang, J., Luo, J., Zhou,
    S.K., 2019. Multiview 2D/3D rigid registration via a point-of-interest network
    for tracking and triangulation, in: Proceedings of the IEEE/CVF Conference on
    Computer Vision and Pattern Recognition, pp. 12638–12647.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liao 等人 [2019] Liao, H., Lin, W.A., Zhang, J., Zhang, J., Luo, J., Zhou, S.K.,
    2019. 通过兴趣点网络进行多视角 2D/3D 刚性配准，用于跟踪和三角测量，见于：IEEE/CVF 计算机视觉与模式识别会议论文集，第 12638–12647
    页。
- en: Liu et al. [2020a] Liu, L., Aviles-Rivero, A.I., Schönlieb, C.B., 2020a. Contrastive
    registration for unsupervised medical image segmentation. arXiv preprint arXiv:2011.08894
    .
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等 [2020a] 刘磊、阿维莱斯-里维罗、施恩利布，2020a。无监督医学图像分割的对比配准。arXiv预印本 arXiv:2011.08894。
- en: 'Liu et al. [2019] Liu, L., Hu, X., Zhu, L., Heng, P.A., 2019. Probabilistic
    multilayer regularization network for unsupervised 3d brain image registration,
    in: 22${}^{\mbox{\tiny{nd}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2019), Springer. pp. 346–354.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等 [2019] 刘磊、胡晓、朱琳、横鹏安，2019。用于无监督3D脑图像配准的概率多层正则化网络，见：第22届医学图像计算与计算机辅助干预国际会议（MICCAI
    2019），Springer。pp. 346–354。
- en: 'Liu et al. [2022a] Liu, L., Huang, Z., Liò, P., Schönlieb, C.B., Aviles-Rivero,
    A.I., 2022a. Pc-swinmorph: patch representation for unsupervised medical image
    registration and segmentation. arXiv preprint arXiv:2203.05684 .'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等 [2022a] 刘磊、黄正、利奥、施恩利布，2022a。Pc-swinmorph：用于无监督医学图像配准和分割的补丁表示。arXiv预印本 arXiv:2203.05684。
- en: 'Liu et al. [2020b] Liu, X., Zheng, Y., Killeen, B., Ishii, M., Hager, G.D.,
    Taylor, R.H., Unberath, M., 2020b. Extremely dense point correspondences using
    a learned feature descriptor, in: Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition, pp. 4847–4856.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等 [2020b] 刘轩、郑亚、基林、石井美、哈格、泰勒、安贝拉赫，2020b。使用学习的特征描述符的极度密集点对应，见：IEEE/CVF计算机视觉与模式识别会议论文集，pp.
    4847–4856。
- en: Liu et al. [2022b] Liu, Y., Chen, J., Wei, S., Carass, A., Prince, J., 2022b.
    On finite difference jacobian computation in deformable image registration. arXiv
    preprint arXiv:2212.06060 .
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等 [2022b] 刘洋、陈建、魏生、卡拉斯、普林斯，2022b。在可变形图像配准中的有限差分雅可比计算。arXiv预印本 arXiv:2212.06060。
- en: 'Liu et al. [2022c] Liu, Y., Zuo, L., Han, S., Xue, Y., Prince, J.L., Carass,
    A., 2022c. Coordinate translator for learning deformable medical image registration,
    in: International Workshop on Multiscale Multimodal Medical Imaging, Springer.
    pp. 98–109.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等 [2022c] 刘洋、左磊、韩松、薛云、普林斯，2022c。用于学习可变形医学图像配准的坐标转换器，见：国际多尺度多模态医学成像研讨会，Springer。pp.
    98–109。
- en: 'Liu et al. [2021] Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin,
    S., Guo, B., 2021. Swin transformer: Hierarchical vision transformer using shifted
    windows, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp. 10012–10022.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等 [2021] 刘震、林一、曹阳、胡辉、魏洋、张志、林森、郭博，2021。Swin Transformer：使用位移窗口的层次化视觉变换器，见：IEEE/CVF计算机视觉与模式识别会议论文集，pp.
    10012–10022。
- en: 'Liu et al. [2022d] Liu, Z., Mao, H., Wu, C.Y., Feichtenhofer, C., Darrell,
    T., Xie, S., 2022d. A convnet for the 2020s, in: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 11976–11986.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等 [2022d] 刘震、毛浩、吴崇宇、费希腾霍费、达雷尔、谢思，2022d。2020年代的卷积网络，见：IEEE/CVF计算机视觉与模式识别会议论文集，pp.
    11976–11986。
- en: 'Liu et al. [2022e] Liu, Z., Ning, J., Cao, Y., Wei, Y., Zhang, Z., Lin, S.,
    Hu, H., 2022e. Video swin transformer, in: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 3202–3211.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等 [2022e] 刘震、宁杰、曹阳、魏洋、张志、林森、胡辉，2022e。视频Swin变换器，见：IEEE/CVF计算机视觉与模式识别会议论文集，pp.
    3202–3211。
- en: Lobachev et al. [2021] Lobachev, O., Funatomi, T., Pfaffenroth, A., Förster,
    R., Knudsen, L., Wrede, C., Guthe, M., Haberthür, D., Hlushchuk, R., Salaets,
    T., et al., 2021. Evaluating registrations of serial sections with distortions
    of the ground truths. IEEE Access 9, 152514–152535.
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 洛巴切夫等 [2021] 洛巴切夫、藤原、法芬罗特、福斯特、克努森、弗雷德、古特、哈贝图尔、赫鲁什楚克、萨拉茨等，2021。评估具有地面真实扭曲的序列切片配准。IEEE
    Access 9, 152514–152535。
- en: 'López et al. [2022] López, P.A., Mella, H., Uribe, S., Hurtado, D.E., Costabal,
    F.S., 2022. WarpPINN: Cine-MR image registration with physics-informed neural
    networks. arXiv preprint arXiv:2211.12549 .'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 洛佩斯等 [2022] 洛佩斯、梅拉、乌里贝、乌尔塔多、科斯塔巴尔，2022。WarpPINN：具有物理知识的神经网络的Cine-MR图像配准。arXiv预印本
    arXiv:2211.12549。
- en: 'Lotfi et al. [2013] Lotfi, T., Tang, L., Andrews, S., Hamarneh, G., 2013. Improving
    probabilistic image registration via reinforcement learning and uncertainty evaluation,
    in: Machine Learning in Medical Imaging: 4th International Workshop, MLMI 2013,
    Held in Conjunction with MICCAI 2013, Nagoya, Japan, September 22, 2013\. Proceedings
    4, Springer. pp. 187–194.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lotfi 等人 [2013] Lotfi, T., Tang, L., Andrews, S., Hamarneh, G., 2013. 通过强化学习和不确定性评估提高概率图像配准,
    见: 医学影像中的机器学习: 第 4 届国际研讨会, MLMI 2013, 与 MICCAI 2013 联合举办, 日本名古屋, 2013年9月22日. 论文集
    4, Springer. 第 187–194 页。'
- en: 'Luo et al. [2019] Luo, J., Sedghi, A., Popuri, K., Cobzas, D., Zhang, M., Preiswerk,
    F., Toews, M., Golby, A., Sugiyama, M., Wells, W.M., et al., 2019. On the applicability
    of registration uncertainty, in: MICCAI19, Springer. pp. 410–419.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Luo 等人 [2019] Luo, J., Sedghi, A., Popuri, K., Cobzas, D., Zhang, M., Preiswerk,
    F., Toews, M., Golby, A., Sugiyama, M., Wells, W.M., 等人, 2019. 关于配准不确定性的适用性, 见:
    MICCAI19, Springer. 第 410–419 页。'
- en: Luo et al. [2016] Luo, W., Li, Y., Urtasun, R., Zemel, R., 2016. Understanding
    the effective receptive field in deep convolutional neural networks. Advances
    in Neural Information Processing Systems 29.
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luo 等人 [2016] Luo, W., Li, Y., Urtasun, R., Zemel, R., 2016. 理解深度卷积神经网络中的有效感受野.
    神经信息处理系统进展 29。
- en: Luo et al. [2021] Luo, Y., Cao, W., He, Z., Zou, W., He, Z., 2021. Deformable
    adversarial registration network with multiple loss constraints. Computerized
    Medical Imaging and Graphics 91, 101931.
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luo 等人 [2021] Luo, Y., Cao, W., He, Z., Zou, W., He, Z., 2021. 具有多重损失约束的可变形对抗配准网络.
    计算机医学成像与图形 91, 101931。
- en: Lv et al. [2022] Lv, J., Wang, Z., Shi, H., Zhang, H., Wang, S., Wang, Y., Li,
    Q., 2022. Joint progressive and coarse-to-fine registration of brain MRI via deformation
    field integration and non-rigid feature fusion. IEEE Trans. Med. Imag. 41, 2788–2802.
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lv 等人 [2022] Lv, J., Wang, Z., Shi, H., Zhang, H., Wang, S., Wang, Y., Li, Q.,
    2022. 通过变形场融合和非刚性特征融合进行脑 MRI 的联合渐进和粗到细配准. IEEE 医学影像学报 41, 2788–2802。
- en: Ma et al. [2021] Ma, J., Chen, J., Ng, M., Huang, R., Li, Y., Li, C., Yang,
    X., Martel, A.L., 2021. Loss odyssey in medical image segmentation. Medical Image
    Analysis 71, 102035.
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma 等人 [2021] Ma, J., Chen, J., Ng, M., Huang, R., Li, Y., Li, C., Yang, X.,
    Martel, A.L., 2021. 医学图像分割中的损失历程. 医学图像分析 71, 102035。
- en: Ma et al. [2008] Ma, J., Miller, M.I., Trouvé, A., Younes, L., 2008. Bayesian
    template estimation in computational anatomy. NeuroImage 42, 252–261.
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma 等人 [2008] Ma, J., Miller, M.I., Trouvé, A., Younes, L., 2008. 计算解剖学中的贝叶斯模板估计.
    神经影像 42, 252–261。
- en: Ma et al. [2022] Ma, M., Xu, Y., Song, L., Liu, G., 2022. Symmetric transformer-based
    network for unsupervised image registration. Knowledge-Based Systems 257, 109959.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma 等人 [2022] Ma, M., Xu, Y., Song, L., Liu, G., 2022. 基于对称变换器的无监督图像配准网络. 知识型系统
    257, 109959。
- en: Mac Aodha et al. [2012] Mac Aodha, O., Humayun, A., Pollefeys, M., Brostow,
    G.J., 2012. Learning a confidence measure for optical flow. IEEE transactions
    on pattern analysis and machine intelligence 35, 1107–1120.
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mac Aodha 等人 [2012] Mac Aodha, O., Humayun, A., Pollefeys, M., Brostow, G.J.,
    2012. 学习光流的置信度度量. IEEE 模式分析与机器智能事务 35, 1107–1120。
- en: 'Madsen et al. [2020] Madsen, D., Morel-Forster, A., Kahr, P., Rahbani, D.,
    Vetter, T., Lüthi, M., 2020. A closest point proposal for mcmc-based probabilistic
    surface registration, in: Computer Vision–ECCV 2020: 16th European Conference,
    Glasgow, UK, August 23–28, 2020, Proceedings, Part XVII 16, Springer. pp. 281–296.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Madsen 等人 [2020] Madsen, D., Morel-Forster, A., Kahr, P., Rahbani, D., Vetter,
    T., Lüthi, M., 2020. 基于 mcmc 的概率表面配准的最近点提议, 见: 计算机视觉–ECCV 2020: 第 16 届欧洲会议, 英国格拉斯哥,
    2020年8月23–28日, 论文集, 第 XVII 部分 16, Springer. 第 281–296 页。'
- en: Maes et al. [1997] Maes, F., Collignon, A., Vandermeulen, D., Marchal, G., Suetens,
    P., 1997. Multimodality image registration by maximization of mutual information.
    IEEE Trans. Med. Imag. 16, 187–198.
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maes 等人 [1997] Maes, F., Collignon, A., Vandermeulen, D., Marchal, G., Suetens,
    P., 1997. 通过最大化互信息进行多模态图像配准. IEEE 医学影像学报 16, 187–198。
- en: 'Mahapatra et al. [2018a] Mahapatra, D., Antony, B., Sedai, S., Garnavi, R.,
    2018a. Deformable medical image registration using generative adversarial networks,
    in: 15${}^{\mbox{\tiny{th}}}$ International Symposium on Biomedical Imaging (ISBI 2018),
    IEEE. pp. 1449–1453.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mahapatra 等人 [2018a] Mahapatra, D., Antony, B., Sedai, S., Garnavi, R., 2018a.
    使用生成对抗网络的可变形医学图像配准, 见: 第 15 届国际生物医学成像研讨会 (ISBI 2018), IEEE. 第 1449–1453 页。'
- en: Mahapatra and Ge [2020] Mahapatra, D., Ge, Z., 2020. Training data independent
    image registration using generative adversarial networks and domain adaptation.
    Pattern Recognition 100, 107109.
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahapatra 和 Ge [2020] Mahapatra, D., Ge, Z., 2020. 使用生成对抗网络和领域适应的训练数据独立图像配准.
    模式识别 100, 107109。
- en: 'Mahapatra et al. [2018b] Mahapatra, D., Ge, Z., Sedai, S., Chakravorty, R.,
    2018b. Joint registration and segmentation of xray images using generative adversarial
    networks, in: Machine Learning in Medical Imaging: 9th International Workshop,
    MLMI 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16,
    2018, Proceedings 9, Springer. pp. 73–80.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahapatra 等 [2018b] Mahapatra, D., Ge, Z., Sedai, S., Chakravorty, R., 2018b.
    使用生成对抗网络的 X 射线图像的联合配准和分割，发表于医学影像中的机器学习：第 9 届国际研讨会，MLMI 2018，MICCAI 2018 附属会议，西班牙格拉纳达，2018
    年 9 月 16 日，论文集 9，Springer，第 73–80 页。
- en: 'Maillard et al. [2022] Maillard, M., François, A., Glaunès, J., Bloch, I.,
    Gori, P., 2022. A deep residual learning implementation of metamorphosis, in:
    19${}^{\mbox{\tiny{th}}}$ International Symposium on Biomedical Imaging (ISBI 2022),
    IEEE. pp. 1–4.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maillard 等 [2022] Maillard, M., François, A., Glaunès, J., Bloch, I., Gori,
    P., 2022. 元变形的深度残差学习实现，发表于第 19 届国际生物医学成像研讨会 (ISBI 2022)，IEEE，第 1–4 页。
- en: Maintz and Viergever [1998] Maintz, J.A., Viergever, M.A., 1998. A survey of
    medical image registration. Medical Image Analysis 2, 1–36.
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maintz 和 Viergever [1998] Maintz, J.A., Viergever, M.A., 1998. 医学图像配准综述。医学图像分析
    2, 1–36。
- en: Makhzani et al. [2015] Makhzani, A., Shlens, J., Jaitly, N., Goodfellow, I.,
    Frey, B., 2015. Adversarial autoencoders. arXiv preprint arXiv:1511.05644 .
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Makhzani 等 [2015] Makhzani, A., Shlens, J., Jaitly, N., Goodfellow, I., Frey,
    B., 2015. 对抗自编码器。arXiv 预印本 arXiv:1511.05644。
- en: 'Mansi et al. [2011] Mansi, T., Pennec, X., Sermesant, M., Delingette, H., Ayache,
    N., 2011. iLogDemons: A demons-based registration algorithm for tracking incompressible
    elastic biological tissues. International Journal of Computer Vision 92, 92–111.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mansi 等 [2011] Mansi, T., Pennec, X., Sermesant, M., Delingette, H., Ayache,
    N., 2011. iLogDemons：一种基于 Demons 的配准算法，用于追踪不可压缩弹性生物组织。计算机视觉国际杂志 92, 92–111。
- en: Meng et al. [2022a] Meng, M., Bi, L., Fulham, M., Feng, D.D., Kim, J., 2022a.
    Enhancing medical image registration via appearance adjustment networks. NeuroImage
    259, 119444.
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meng 等 [2022a] Meng, M., Bi, L., Fulham, M., Feng, D.D., Kim, J., 2022a. 通过外观调整网络增强医学图像配准。NeuroImage
    259, 119444。
- en: 'Meng et al. [2022b] Meng, Q., Qin, C., Bai, W., Liu, T., de Marvao, A., O’Regan,
    D.P., Rueckert, D., 2022b. MulViMotion: Shape-aware 3D Myocardial Motion Tracking
    from Multi-View Cardiac MRI. IEEE Trans. Med. Imag. 41, 1961–1974.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meng 等 [2022b] Meng, Q., Qin, C., Bai, W., Liu, T., de Marvao, A., O’Regan,
    D.P., Rueckert, D., 2022b. MulViMotion：基于形状的 3D 心肌运动追踪来自多视角心脏 MRI。IEEE 医学影像学报
    41, 1961–1974。
- en: 'Mescheder et al. [2019] Mescheder, L., Oechsle, M., Niemeyer, M., Nowozin,
    S., Geiger, A., 2019. Occupancy networks: Learning 3D reconstruction in function
    space, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp. 4460–4470.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mescheder 等 [2019] Mescheder, L., Oechsle, M., Niemeyer, M., Nowozin, S., Geiger,
    A., 2019. 占用网络：在函数空间中学习 3D 重建，发表于 IEEE/CVF 计算机视觉与模式识别会议论文集，第 4460–4470 页。
- en: Miao et al. [2016] Miao, S., Wang, Z.J., Liao, R., 2016. A CNN regression approach
    for real-time 2D/3D registration. IEEE Trans. Med. Imag. 35, 1352–1363.
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miao 等 [2016] Miao, S., Wang, Z.J., Liao, R., 2016. 一种用于实时 2D/3D 配准的 CNN 回归方法。IEEE
    医学影像学报 35, 1352–1363。
- en: 'Mildenhall et al. [2021] Mildenhall, B., Srinivasan, P.P., Tancik, M., Barron,
    J.T., Ramamoorthi, R., Ng, R., 2021. Nerf: Representing scenes as neural radiance
    fields for view synthesis. Communications of the ACM 65, 99–106.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mildenhall 等 [2021] Mildenhall, B., Srinivasan, P.P., Tancik, M., Barron, J.T.,
    Ramamoorthi, R., Ng, R., 2021. Nerf：将场景表示为神经辐射场以进行视图合成。ACM 通讯 65, 99–106。
- en: Miller et al. [2006] Miller, M.I., Trouvé, A., Younes, L., 2006. Geodesic shooting
    for computational anatomy. Journal of Mathematical Imaging and Vision 24, 209–228.
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miller 等 [2006] Miller, M.I., Trouvé, A., Younes, L., 2006. 用于计算解剖学的测地线射击。数学成像与视觉杂志
    24, 209–228。
- en: 'Mok and Chung [2020a] Mok, T.C., Chung, A., 2020a. Fast symmetric diffeomorphic
    image registration with convolutional neural networks, in: Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4644–4653.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mok 和 Chung [2020a] Mok, T.C., Chung, A., 2020a. 使用卷积神经网络的快速对称微分同胚图像配准，发表于 IEEE/CVF
    计算机视觉与模式识别会议论文集，第 4644–4653 页。
- en: 'Mok and Chung [2020b] Mok, T.C., Chung, A., 2020b. Large deformation diffeomorphic
    image registration with laplacian pyramid networks, in: 23${}^{\mbox{\tiny{rd}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2020),
    Springer. pp. 211–221.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mok 和 Chung [2020b] Mok, T.C., Chung, A., 2020b. 使用拉普拉斯金字塔网络的大变形微分同胚图像配准，发表于第
    23 届国际医学图像计算与计算机辅助干预会议 (MICCAI 2020)，Springer，第 211–221 页。
- en: 'Mok and Chung [2021a] Mok, T.C., Chung, A., 2021a. Conditional deep laplacian
    pyramid image registration network in learn2reg challenge, in: 24${}^{\mbox{\tiny{th}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2021),
    Springer. pp. 161–167.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mok 和 Chung [2021a] Mok, T.C., Chung, A., 2021a. 在 learn2reg 挑战中的条件深度拉普拉斯金字塔图像配准网络，收录于：第24${}^{\mbox{\tiny{th}}}$届国际医学图像计算与计算机辅助干预会议（MICCAI
    2021），Springer。第 161–167 页。
- en: 'Mok and Chung [2021b] Mok, T.C., Chung, A., 2021b. Conditional deformable image
    registration with convolutional neural network, in: 24${}^{\mbox{\tiny{th}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2021),
    Springer. pp. 35–45.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mok 和 Chung [2021b] Mok, T.C., Chung, A., 2021b. 使用卷积神经网络的条件可变形图像配准，收录于：第24${}^{\mbox{\tiny{th}}}$届国际医学图像计算与计算机辅助干预会议（MICCAI
    2021），Springer。第 35–45 页。
- en: 'Mok and Chung [2022a] Mok, T.C., Chung, A., 2022a. Affine medical image registration
    with coarse-to-fine vision transformer, in: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 20835–20844.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mok 和 Chung [2022a] Mok, T.C., Chung, A., 2022a. 使用粗到细视觉变换器的仿射医学图像配准，收录于：IEEE/CVF
    计算机视觉与模式识别会议论文集，第 20835–20844 页。
- en: Mok and Chung [2022b] Mok, T.C., Chung, A., 2022b. Robust Image Registration
    with Absent Correspondences in Pre-operative and Follow-up Brain MRI Scans of
    Diffuse Glioma Patients. arXiv preprint arXiv:2210.11045 .
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mok 和 Chung [2022b] Mok, T.C., Chung, A., 2022b. 在弥漫性胶质瘤患者的术前和随访脑 MRI 扫描中，具有缺失对应点的鲁棒图像配准。arXiv
    预印本 arXiv:2210.11045。
- en: 'Mok and Chung [2022c] Mok, T.C., Chung, A.C., 2022c. Unsupervised Deformable
    Image Registration with Absent Correspondences in Pre-operative and Post-recurrence
    Brain Tumor MRI Scans, in: 25${}^{\mbox{\tiny{th}}}$ International Conference
    on Medical Image Computing and Computer Assisted Intervention (MICCAI 2022), Springer.
    pp. 25–35.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mok 和 Chung [2022c] Mok, T.C., Chung, A.C., 2022c. 在术前和复发后脑肿瘤 MRI 扫描中具有缺失对应点的无监督可变形图像配准，收录于：第25${}^{\mbox{\tiny{th}}}$届国际医学图像计算与计算机辅助干预会议（MICCAI
    2022），Springer。第 25–35 页。
- en: 'Morales et al. [2019] Morales, M.A., Izquierdo-Garcia, D., Aganj, I., Kalpathy-Cramer,
    J., Rosen, B.R., Catana, C., 2019. Implementation and validation of a three-dimensional
    cardiac motion estimation network. Radiology: Artificial Intelligence 1, e180080.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Morales 等人 [2019] Morales, M.A., Izquierdo-Garcia, D., Aganj, I., Kalpathy-Cramer,
    J., Rosen, B.R., Catana, C., 2019. 三维心脏运动估计网络的实现和验证。放射学：人工智能 1, e180080。
- en: Myronenko and Song [2010] Myronenko, A., Song, X., 2010. Intensity-based image
    registration by minimizing residual complexity. IEEE Trans. Med. Imag. 29, 1882–1891.
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Myronenko 和 Song [2010] Myronenko, A., Song, X., 2010. 通过最小化残差复杂度进行基于强度的图像配准。IEEE
    医学成像汇刊 29, 1882–1891。
- en: 'Nan et al. [2020] Nan, A., Tennant, M., Rubin, U., Ray, N., 2020. Drmime: Differentiable
    mutual information and matrix exponential for multi-resolution image registration,
    in: Medical Imaging with Deep Learning, PMLR. pp. 527–543.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nan 等人 [2020] Nan, A., Tennant, M., Rubin, U., Ray, N., 2020. Drmime: 用于多分辨率图像配准的可微分互信息和矩阵指数，收录于：深度学习医学成像，PMLR。第
    527–543 页。'
- en: Nenoff et al. [2020] Nenoff, L., Ribeiro, C.O., Matter, M., Hafner, L., Josipovic,
    M., Langendijk, J.A., Persson, G.F., Walser, M., Weber, D.C., Lomax, A.J., et al.,
    2020. Deformable image registration uncertainty for inter-fractional dose accumulation
    of lung cancer proton therapy. Radiotherapy and Oncology 147, 178–185.
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nenoff 等人 [2020] Nenoff, L., Ribeiro, C.O., Matter, M., Hafner, L., Josipovic,
    M., Langendijk, J.A., Persson, G.F., Walser, M., Weber, D.C., Lomax, A.J., 等人,
    2020. 肺癌质子治疗的可变形图像配准不确定性用于分次剂量累积。放射治疗与肿瘤学 147, 178–185。
- en: 'Niemeyer et al. [2019] Niemeyer, M., Mescheder, L., Oechsle, M., Geiger, A.,
    2019. Occupancy flow: 4d reconstruction by learning particle dynamics, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 5379–5389.'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Niemeyer 等人 [2019] Niemeyer, M., Mescheder, L., Oechsle, M., Geiger, A., 2019.
    占用流：通过学习粒子动力学进行 4D 重建，收录于：IEEE/CVF 计算机视觉与模式识别会议论文集，第 5379–5389 页。
- en: 'Niethammer et al. [2011] Niethammer, M., Hart, G.L., Pace, D.F., Vespa, P.M.,
    Irimia, A., Van Horn, J.D., Aylward, S.R., 2011. Geometric metamorphosis, in:
    14${}^{\mbox{\tiny{th}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2011), NIH Public Access. p. 639.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Niethammer 等人 [2011] Niethammer, M., Hart, G.L., Pace, D.F., Vespa, P.M., Irimia,
    A., Van Horn, J.D., Aylward, S.R., 2011. 几何变形，收录于：第14${}^{\mbox{\tiny{th}}}$届国际医学图像计算与计算机辅助干预会议（MICCAI
    2011），NIH 公共访问。第 639 页。
- en: 'Niethammer et al. [2019] Niethammer, M., Kwitt, R., Vialard, F.X., 2019. Metric
    learning for image registration, in: Proceedings of the IEEE/CVF Conference on
    Computer Vision and Pattern Recognition, pp. 8463–8472.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Niethammer等人[2019] Niethammer, M., Kwitt, R., Vialard, F.X., 2019. 图像配准的度量学习，见：IEEE/CVF计算机视觉与模式识别会议论文集，pp.
    8463–8472。
- en: Obeidat et al. [2016] Obeidat, M., Narayanasamy, G., Cline, K., Stathakis, S.,
    Pouliot, J., Kim, H., Kirby, N., 2016. Comparison of different qa methods for
    deformable image registration to the known errors for prostate and head-and-neck
    virtual phantoms. Biomedical Physics & Engineering Express 2, 067002.
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Obeidat等人[2016] Obeidat, M., Narayanasamy, G., Cline, K., Stathakis, S., Pouliot,
    J., Kim, H., Kirby, N., 2016. 不同QA方法对已知前列腺和头颈部虚拟模型图像配准的误差比较。生物医学物理与工程快报 2, 067002。
- en: 'Oishi et al. [2009] Oishi, K., Faria, A., Jiang, H., Li, X., Akhter, K., Zhang,
    J., Hsu, J.T., Miller, M.I., van Zijl, P.C., Albert, M., et al., 2009. Atlas-based
    whole brain white matter analysis using large deformation diffeomorphic metric
    mapping: application to normal elderly and Alzheimer’s disease participants. NeuroImage
    46, 486–499.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oishi等人[2009] Oishi, K., Faria, A., Jiang, H., Li, X., Akhter, K., Zhang, J.,
    Hsu, J.T., Miller, M.I., van Zijl, P.C., Albert, M., 等人，2009. 基于图谱的全脑白质分析，使用大变形同胚度量映射：应用于正常老年人和阿尔茨海默病参与者。NeuroImage
    46, 486–499。
- en: 'Oliveira and Tavares [2014] Oliveira, F.P., Tavares, J.M.R., 2014. Medical
    image registration: a review. Computer Methods in Biomechanics and Biomedical
    Engineering 17, 73–93.'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oliveira和Tavares [2014] Oliveira, F.P., Tavares, J.M.R., 2014. 医学图像配准：综述。计算机方法在生物力学和生物医学工程中的应用
    17, 73–93。
- en: Oord et al. [2018] Oord, A.v.d., Li, Y., Vinyals, O., 2018. Representation learning
    with contrastive predictive coding. arXiv preprint arXiv:1807.03748 .
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oord等人[2018] Oord, A.v.d., Li, Y., Vinyals, O., 2018. 使用对比预测编码的表征学习。arXiv预印本
    arXiv:1807.03748 。
- en: Osman et al. [1999] Osman, N.F., Kerwin, W.S., McVeigh, E.R., Prince, J.L.,
    1999. Cardiac motion tracking using CINE harmonic phase (HARP) magnetic resonance
    imaging. Mag. Reson. Med. 42, 1048–1060.
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Osman等人[1999] Osman, N.F., Kerwin, W.S., McVeigh, E.R., Prince, J.L., 1999.
    使用CINE谐波相位（HARP）磁共振成像跟踪心脏运动。Mag. Reson. Med. 42, 1048–1060。
- en: Pace et al. [2013] Pace, D.F., Aylward, S.R., Niethammer, M., 2013. A locally
    adaptive regularization based on anisotropic diffusion for deformable image registration
    of sliding organs. IEEE Trans. Med. Imag. 32, 2114–2126.
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pace等人[2013] Pace, D.F., Aylward, S.R., Niethammer, M., 2013. 基于各向异性扩散的局部自适应正则化，用于滑动器官的可变形图像配准。IEEE
    Trans. Med. Imag. 32, 2114–2126。
- en: 'Papież et al. [2015] Papież, B.W., Franklin, J., Heinrich, M.P., Gleeson, F.V.,
    Schnabel, J.A., 2015. Liver motion estimation via locally adaptive over-segmentation
    regularization, in: 18${}^{\mbox{\tiny{th}}}$ International Conference on Medical
    Image Computing and Computer Assisted Intervention (MICCAI 2015), Springer. pp.
    427–434.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Papież等人[2015] Papież, B.W., Franklin, J., Heinrich, M.P., Gleeson, F.V., Schnabel,
    J.A., 2015. 通过局部自适应过度分割正则化估计肝脏运动，见：第18${}^{\mbox{\tiny{th}}}$届医学图像计算与计算机辅助手术国际会议(MICCAI
    2015)，Springer. pp. 427–434。
- en: Papież et al. [2014] Papież, B.W., Heinrich, M.P., Fehrenbach, J., Risser, L.,
    Schnabel, J.A., 2014. An implicit sliding-motion preserving regularisation via
    bilateral filtering for deformable image registration. Medical Image Analysis
    18, 1299–1311.
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Papież等人[2014] Papież, B.W., Heinrich, M.P., Fehrenbach, J., Risser, L., Schnabel,
    J.A., 2014. 通过双边滤波进行隐式滑动运动保持正则化，用于可变形图像配准。医学图像分析 18, 1299–1311。
- en: 'Park et al. [2019] Park, J.J., Florence, P., Straub, J., Newcombe, R., Lovegrove,
    S., 2019. Deepsdf: Learning continuous signed distance functions for shape representation,
    in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    pp. 165–174.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park等人[2019] Park, J.J., Florence, P., Straub, J., Newcombe, R., Lovegrove,
    S., 2019. Deepsdf：学习用于形状表示的连续符号距离函数，见：IEEE/CVF计算机视觉与模式识别会议论文集，pp. 165–174。
- en: 'Park et al. [2020] Park, T., Efros, A.A., Zhang, R., Zhu, J.Y., 2020. Contrastive
    learning for unpaired image-to-image translation, in: Computer Vision–ECCV 2020:
    16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part IX
    16, Springer. pp. 319–345.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park等人[2020] Park, T., Efros, A.A., Zhang, R., Zhu, J.Y., 2020. 用于非配对图像到图像翻译的对比学习，见：计算机视觉–ECCV
    2020：第16届欧洲会议，英国格拉斯哥，2020年8月23–28日，会议论文集，第IX部分16，Springer. pp. 319–345。
- en: 'Pathan and Hong [2018] Pathan, S., Hong, Y., 2018. Predictive image regression
    for longitudinal studies with missing data, in: Medical Imaging with Deep Learning.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pathan和Hong [2018] Pathan, S., Hong, Y., 2018. 针对缺失数据的纵向研究的预测图像回归，见：医学影像与深度学习。
- en: 'Pei et al. [2021] Pei, Y., Chen, L., Zhao, F., Wu, Z., Zhong, T., Wang, Y.,
    Chen, C., Wang, L., Zhang, H., Wang, L., et al., 2021. Learning spatiotemporal
    probabilistic atlas of fetal brains with anatomically constrained registration
    network, in: 24${}^{\mbox{\tiny{th}}}$ International Conference on Medical Image
    Computing and Computer Assisted Intervention (MICCAI 2021), Springer. pp. 239–248.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pei et al. [2021] Pei, Y., Chen, L., Zhao, F., Wu, Z., Zhong, T., Wang, Y.,
    Chen, C., Wang, L., Zhang, H., Wang, L., 等，2021. 使用解剖约束配准网络学习胎儿大脑的时空概率图谱，见：第24${}^{\mbox{\tiny{届}}}$国际医学图像计算与计算机辅助干预会议
    (MICCAI 2021)，Springer. 页 239–248。
- en: Peter et al. [2021] Peter, L., Alexander, D.C., Magnain, C., Iglesias, J.E.,
    2021. Uncertainty-aware annotation protocol to evaluate deformable registration
    algorithms. IEEE Trans. Med. Imag. 40, 2053–2065.
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peter et al. [2021] Peter, L., Alexander, D.C., Magnain, C., Iglesias, J.E.,
    2021. 评估可变形配准算法的带有不确定性意识的注释协议。IEEE 医学影像学报 40，2053–2065。
- en: 'Pfandler et al. [2019] Pfandler, M., Stefan, P., Mehren, C., Lazarovici, M.,
    Weigl, M., 2019. Technical and nontechnical skills in surgery: a simulated operating
    room environment study. Spine 44, E1396–E1400.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pfandler et al. [2019] Pfandler, M., Stefan, P., Mehren, C., Lazarovici, M.,
    Weigl, M., 2019. 外科手术中的技术与非技术技能：一个模拟手术室环境研究。脊柱 44，E1396–E1400。
- en: 'Pielawski et al. [2020] Pielawski, N., Wetzer, E., Öfverstedt, J., Lu, J.,
    Wählby, C., Lindblad, J., Sladoje, N., 2020. Comir: Contrastive multimodal image
    representation for registration. Advances in Neural Information Processing Systems
    33, 18433–18444.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pielawski et al. [2020] Pielawski, N., Wetzer, E., Öfverstedt, J., Lu, J., Wählby,
    C., Lindblad, J., Sladoje, N., 2020. Comir：用于配准的对比多模态图像表示。神经信息处理系统进展 33，18433–18444。
- en: Pitiot and Guimond [2008] Pitiot, A., Guimond, A., 2008. Geometrical regularization
    of displacement fields for histological image registration. Medical Image Analysis
    12, 16–25.
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pitiot and Guimond [2008] Pitiot, A., Guimond, A., 2008. 用于组织学图像配准的位移场几何正则化。医学图像分析
    12，16–25。
- en: Pluim et al. [2000] Pluim, J., Maintz, J., Viergever, M., 2000. Image registration
    by maximization of combined mutual information and gradient information. IEEE
    Trans. Med. Imag. 19, 809–814.
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pluim et al. [2000] Pluim, J., Maintz, J., Viergever, M., 2000. 通过最大化联合互信息和梯度信息进行图像配准。IEEE
    医学影像学报 19，809–814。
- en: 'Pluim et al. [2016] Pluim, J.P., Muenzing, S.E., Eppenhof, K.A., Murphy, K.,
    2016. The truth is hard to make: Validation of medical image registration, in:
    2016 23rd International Conference on Pattern Recognition (ICPR), IEEE. pp. 2294–2300.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pluim et al. [2016] Pluim, J.P., Muenzing, S.E., Eppenhof, K.A., Murphy, K.,
    2016. 真相难以确认：医学图像配准的验证，见：2016年第23届国际模式识别大会 (ICPR)，IEEE. 页 2294–2300。
- en: 'Polzin et al. [2013] Polzin, T., Rühaak, J., Werner, R., Strehlow, J., Heldmann,
    S., Handels, H., Modersitzki, J., 2013. Combining automatic landmark detection
    and variational methods for lung CT registration, in: Fifth international workshop
    on pulmonary image analysis, pp. 85–96.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Polzin et al. [2013] Polzin, T., Rühaak, J., Werner, R., Strehlow, J., Heldmann,
    S., Handels, H., Modersitzki, J., 2013. 结合自动地标检测和变分方法进行肺 CT 配准，见：第五届国际肺部图像分析研讨会，页
    85–96。
- en: 'Qian et al. [2021] Qian, R., Meng, T., Gong, B., Yang, M.H., Wang, H., Belongie,
    S., Cui, Y., 2021. Spatiotemporal contrastive video representation learning, in:
    Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    pp. 6964–6974.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian et al. [2021] Qian, R., Meng, T., Gong, B., Yang, M.H., Wang, H., Belongie,
    S., Cui, Y., 2021. 时空对比视频表示学习，见：IEEE/CVF 计算机视觉与模式识别会议论文集，页 6964–6974。
- en: 'Qin et al. [2018] Qin, C., Bai, W., Schlemper, J., Petersen, S.E., Piechnik,
    S.K., Neubauer, S., Rueckert, D., 2018. Joint learning of motion estimation and
    segmentation for cardiac MR image sequences, in: 21${}^{\mbox{\tiny{st}}}$ International
    Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2018),
    Springer. pp. 472–480.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin et al. [2018] Qin, C., Bai, W., Schlemper, J., Petersen, S.E., Piechnik,
    S.K., Neubauer, S., Rueckert, D., 2018. 运动估计与心脏 MR 图像序列分割的联合学习，见：第21${}^{\mbox{\tiny{届}}}$国际医学图像计算与计算机辅助干预会议
    (MICCAI 2018)，Springer. 页 472–480。
- en: 'Qin et al. [2019] Qin, C., Shi, B., Liao, R., Mansi, T., Rueckert, D., Kamen,
    A., 2019. Unsupervised deformable registration for multi-modal images via disentangled
    representations, in: Information Processing in Medical Imaging: 26th International
    Conference, IPMI 2019, Hong Kong, China, June 2–7, 2019, Proceedings 26, Springer.
    pp. 249–261.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin et al. [2019] Qin, C., Shi, B., Liao, R., Mansi, T., Rueckert, D., Kamen,
    A., 2019. 通过解耦表示进行多模态图像的无监督可变形配准，见：医学影像处理信息：第26届国际会议，IPMI 2019，中国香港，2019年6月2–7日，论文集
    26，Springer. 页 249–261。
- en: Qin et al. [2023] Qin, C., Wang, S., Chen, C., Bai, W., Rueckert, D., 2023.
    Generative myocardial motion tracking via latent space exploration with biomechanics-informed
    prior. Medical Image Analysis 83, 102682.
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin 等人 [2023] Qin, C., Wang, S., Chen, C., Bai, W., Rueckert, D., 2023. 通过潜在空间探索和生物力学信息先验进行生成性心肌运动跟踪。医学图像分析
    83，102682。
- en: 'Qiu et al. [2021] Qiu, H., Qin, C., Schuh, A., Hammernik, K., Rueckert, D.,
    2021. Learning diffeomorphic and modality-invariant registration using b-splines,
    in: Medical Imaging with Deep Learning.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qiu 等人 [2021] Qiu, H., Qin, C., Schuh, A., Hammernik, K., Rueckert, D., 2021.
    使用 b-splines 学习可微分和模态不变的配准，发表于：医学成像与深度学习。
- en: 'Raissi et al. [2019] Raissi, M., Perdikaris, P., Karniadakis, G.E., 2019. Physics-informed
    neural networks: A deep learning framework for solving forward and inverse problems
    involving nonlinear partial differential equations. Journal of Computational physics
    378, 686–707.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raissi 等人 [2019] Raissi, M., Perdikaris, P., Karniadakis, G.E., 2019. 物理信息神经网络：一个用于解决涉及非线性偏微分方程的正向和反向问题的深度学习框架。计算物理学杂志
    378，686–707。
- en: 'Ramon et al. [2022] Ramon, U., Hernandez, M., Mayordomo, E., 2022. Lddmm meets
    gans: Generative adversarial networks for diffeomorphic registration, in: Biomedical
    Image Registration: 10th International Workshop, WBIR 2022, Munich, Germany, July
    10–12, 2022, Proceedings, Springer. pp. 18–28.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ramon 等人 [2022] Ramon, U., Hernandez, M., Mayordomo, E., 2022. Lddmm 遇上 gans：用于可微分配准的生成对抗网络，发表于：生物医学图像配准：第10届国际研讨会，WBIR
    2022，德国慕尼黑，2022年7月10–12日，论文集，Springer，第18–28页。
- en: 'Ranjan et al. [2019] Ranjan, A., Jampani, V., Balles, L., Kim, K., Sun, D.,
    Wulff, J., Black, M.J., 2019. Competitive collaboration: Joint unsupervised learning
    of depth, camera motion, optical flow and motion segmentation, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 12240–12249.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ranjan 等人 [2019] Ranjan, A., Jampani, V., Balles, L., Kim, K., Sun, D., Wulff,
    J., Black, M.J., 2019. 竞争性协作：深度、相机运动、光流和运动分割的联合无监督学习，发表于：IEEE/CVF 计算机视觉与模式识别大会论文集，第12240–12249页。
- en: Reed et al. [2009] Reed, V.K., Woodward, W.A., Zhang, L., Strom, E.A., Perkins,
    G.H., Tereffe, W., Oh, J.L., Yu, T.K., Bedrosian, I., Whitman, G.J., et al., 2009.
    Automatic segmentation of whole breast using atlas approach and deformable image
    registration. International Journal of Radiation Oncology* Biology* Physics 73,
    1493–1500.
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reed 等人 [2009] Reed, V.K., Woodward, W.A., Zhang, L., Strom, E.A., Perkins,
    G.H., Tereffe, W., Oh, J.L., Yu, T.K., Bedrosian, I., Whitman, G.J., 等，2009. 使用图谱方法和可变形图像配准的全乳自动分割。国际放射肿瘤*生物学*物理学杂志
    73，1493–1500。
- en: 'Risholm et al. [2011] Risholm, P., Balter, J., Wells, W.M., 2011. Estimation
    of delivered dose in radiotherapy: the influence of registration uncertainty,
    in: 14${}^{\mbox{\tiny{th}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2011), Springer. pp. 548–555.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Risholm 等人 [2011] Risholm, P., Balter, J., Wells, W.M., 2011. 放射治疗中剂量估计：配准不确定性的影响，发表于：第14届医学图像计算与计算机辅助干预国际会议
    (MICCAI 2011)，Springer，第548–555页。
- en: Risholm et al. [2013] Risholm, P., Janoos, F., Norton, I., Golby, A.J., Wells III,
    W.M., 2013. Bayesian characterization of uncertainty in intra-subject non-rigid
    registration. Medical Image Analysis 17, 538–555.
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Risholm 等人 [2013] Risholm, P., Janoos, F., Norton, I., Golby, A.J., Wells III,
    W.M., 2013. 内主观非刚性配准中的贝叶斯不确定性表征。医学图像分析 17，538–555。
- en: 'Risser et al. [2013] Risser, L., Vialard, F.X., Baluwala, H.Y., Schnabel, J.A.,
    2013. Piecewise-diffeomorphic image registration: Application to the motion estimation
    between 3D CT lung images with sliding conditions. Medical Image Analysis 17,
    182–193.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Risser 等人 [2013] Risser, L., Vialard, F.X., Baluwala, H.Y., Schnabel, J.A.,
    2013. 分段可微分图像配准：应用于具有滑动条件的 3D CT 肺部图像之间的运动估计。医学图像分析 17，182–193。
- en: 'Roche et al. [1998] Roche, A., Malandain, G., Pennec, X., Ayache, N., 1998.
    The correlation ratio as a new similarity measure for multimodal image registration,
    in: 1${}^{\mbox{\tiny{st}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 1998), Springer. pp. 1115–1124.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roche 等人 [1998] Roche, A., Malandain, G., Pennec, X., Ayache, N., 1998. 相关比作为多模态图像配准的新相似性度量，发表于：第1届医学图像计算与计算机辅助干预国际会议
    (MICCAI 1998)，Springer，第1115–1124页。
- en: 'Rohé et al. [2017] Rohé, M.M., Datar, M., Heimann, T., Sermesant, M., Pennec,
    X., 2017. Svf-net: learning deformable image registration using shape matching,
    in: 20${}^{\mbox{\tiny{th}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2017), Springer. pp. 266–274.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rohé 等人 [2017] Rohé, M.M., Datar, M., Heimann, T., Sermesant, M., Pennec, X.,
    2017. Svf-net：使用形状匹配学习可变形图像配准，见：第20${}^{\mbox{\tiny{th}}}$ 医学图像计算与计算机辅助干预国际会议（MICCAI
    2017），Springer。第266–274页。
- en: 'Rohlfing [2011] Rohlfing, T., 2011. Image similarity and tissue overlaps as
    surrogates for image registration accuracy: widely used but unreliable. IEEE Trans.
    Med. Imag. 31, 153–163.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rohlfing [2011] Rohlfing, T., 2011. 图像相似性和组织重叠作为图像配准准确性的替代指标：广泛使用但不可靠。IEEE Trans.
    Med. Imag. 31, 153–163。
- en: Rohlfing et al. [2003a] Rohlfing, T., Maurer, C.R., Bluemke, D.A., Jacobs, M.A.,
    2003a. Volume-preserving nonrigid registration of MR breast images using free-form
    deformation with an incompressibility constraint. IEEE Trans. Med. Imag. 22, 730–741.
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rohlfing 等人 [2003a] Rohlfing, T., Maurer, C.R., Bluemke, D.A., Jacobs, M.A.,
    2003a. 使用自由形状变形和不可压缩性约束的 MR 乳腺图像体积保持非刚性配准。IEEE Trans. Med. Imag. 22, 730–741。
- en: 'Rohlfing et al. [2003b] Rohlfing, T., Russakoff, D.B., Maurer, C.R., 2003b.
    Expectation maximization strategies for multi-atlas multi-label segmentation,
    in: 18${}^{\mbox{\tiny{th}}}$ Inf. Proc. in Med. Imaging (IPMI 2003), Springer.
    pp. 210–221.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rohlfing 等人 [2003b] Rohlfing, T., Russakoff, D.B., Maurer, C.R., 2003b. 多图谱多标签分割的期望最大化策略，见：第18${}^{\mbox{\tiny{th}}}$
    医学影像信息处理会议（IPMI 2003），Springer。第210–221页。
- en: 'Ronneberger et al. [2015] Ronneberger, O., Fischer, P., Brox, T., 2015. U-net:
    Convolutional networks for biomedical image segmentation, in: 18${}^{\mbox{\tiny{th}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2015),
    Springer. pp. 234–241.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ronneberger 等人 [2015] Ronneberger, O., Fischer, P., Brox, T., 2015. U-net：用于生物医学图像分割的卷积网络，见：第18${}^{\mbox{\tiny{th}}}$
    医学图像计算与计算机辅助干预国际会议（MICCAI 2015），Springer。第234–241页。
- en: 'Rueckert et al. [1999] Rueckert, D., Sonoda, L.I., Hayes, C., Hill, D.L., Leach,
    M.O., Hawkes, D.J., 1999. Nonrigid registration using free-form deformations:
    application to breast MR images. IEEE Trans. Med. Imag. 18, 712–721.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rueckert 等人 [1999] Rueckert, D., Sonoda, L.I., Hayes, C., Hill, D.L., Leach,
    M.O., Hawkes, D.J., 1999. 使用自由形状变形进行非刚性配准：应用于乳腺 MR 图像。IEEE Trans. Med. Imag. 18,
    712–721。
- en: Rühaak et al. [2017] Rühaak, J., Polzin, T., Heldmann, S., Simpson, I.J., Handels,
    H., Modersitzki, J., Heinrich, M.P., 2017. Estimation of large motion in lung
    CT by integrating regularized keypoint correspondences into dense deformable registration.
    IEEE Trans. Med. Imag. 36, 1746–1757.
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rühaak 等人 [2017] Rühaak, J., Polzin, T., Heldmann, S., Simpson, I.J., Handels,
    H., Modersitzki, J., Heinrich, M.P., 2017. 通过将正则化关键点对应关系集成到密集变形配准中来估计肺 CT 中的大范围运动。IEEE
    Trans. Med. Imag. 36, 1746–1757。
- en: 'Sandkühler et al. [2018] Sandkühler, R., Jud, C., Andermatt, S., Cattin, P.C.,
    2018. Airlab: autograd image registration laboratory. arXiv preprint arXiv:1806.09907
    .'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sandkühler 等人 [2018] Sandkühler, R., Jud, C., Andermatt, S., Cattin, P.C., 2018.
    Airlab：自动梯度图像配准实验室。arXiv 预印本 arXiv:1806.09907。
- en: 'Schmah et al. [2013] Schmah, T., Risser, L., Vialard, F.X., 2013. Left-invariant
    metrics for diffeomorphic image registration with spatially-varying regularisation,
    in: 16${}^{\mbox{\tiny{th}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2013), Springer. pp. 203–210.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schmah 等人 [2013] Schmah, T., Risser, L., Vialard, F.X., 2013. 用于具有空间变化正则化的同胚图像配准的左不变度量，见：第16${}^{\mbox{\tiny{th}}}$
    医学图像计算与计算机辅助干预国际会议（MICCAI 2013），Springer。第203–210页。
- en: 'Schnabel et al. [2016] Schnabel, J.A., Heinrich, M.P., Papież, B.W., Brady,
    J.M., 2016. Advances and challenges in deformable image registration: from image
    fusion to complex motion modelling.'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schnabel 等人 [2016] Schnabel, J.A., Heinrich, M.P., Papież, B.W., Brady, J.M.,
    2016. 变形图像配准的进展与挑战：从图像融合到复杂运动建模。
- en: 'Schultz et al. [2018] Schultz, S., Handels, H., Ehrhardt, J., 2018. A multilevel
    markov chain monte carlo approach for uncertainty quantification in deformable
    registration, in: Medical Imaging 2018: Image Processing, SPIE. pp. 162–169.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schultz 等人 [2018] Schultz, S., Handels, H., Ehrhardt, J., 2018. 一种用于变形配准不确定性量化的多级马尔可夫链蒙特卡罗方法，见：医学影像2018：图像处理，SPIE。第162–169页。
- en: Sdika [2008] Sdika, M., 2008. A fast nonrigid image registration with constraints
    on the jacobian using large scale constrained optimization. IEEE Trans. Med. Imag.
    27, 271–281.
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sdika [2008] Sdika, M., 2008. 一种快速的非刚性图像配准方法，通过大规模约束优化对雅可比矩阵施加约束。IEEE Trans.
    Med. Imag. 27, 271–281。
- en: Sdika and Pelletier [2009] Sdika, M., Pelletier, D., 2009. Nonrigid registration
    of multiple sclerosis brain images using lesion inpainting for morphometry or
    lesion mapping. Technical Report. Wiley Online Library.
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sdika 和 Pelletier [2009] Sdika, M., Pelletier, D., 2009. 使用病灶修复的多发性硬化脑图像的非刚性配准，用于形态测量或病灶映射。技术报告。Wiley在线图书馆。
- en: Shams et al. [2010] Shams, R., Sadeghi, P., Kennedy, R.A., Hartley, R.I., 2010.
    A survey of medical image registration on multicore and the gpu. IEEE signal processing
    magazine 27, 50–60.
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shams 等 [2010] Shams, R., Sadeghi, P., Kennedy, R.A., Hartley, R.I., 2010. 多核和GPU上的医学图像配准调查。IEEE信号处理杂志
    27，50–60页。
- en: Shao et al. [2022] Shao, S., Pei, Z., Chen, W., Zhu, W., Wu, X., Zhang, B.,
    2022. A multi-scale unsupervised learning for deformable image registration. International
    Journal of Computer Assisted Radiology and Surgery , 1–10.
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shao 等 [2022] Shao, S., Pei, Z., Chen, W., Zhu, W., Wu, X., Zhang, B., 2022.
    一种用于变形图像配准的多尺度无监督学习。计算机辅助放射学与手术国际期刊，1–10页。
- en: Shen et al. [2019] Shen, Z., Vialard, F.X., Niethammer, M., 2019. Region-specific
    diffeomorphic metric mapping. Advances in Neural Information Processing Systems
    32.
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等 [2019] Shen, Z., Vialard, F.X., Niethammer, M., 2019. 区域特定的微分同胚度量映射。神经信息处理系统进展
    32。
- en: 'Shi et al. [2022] Shi, J., He, Y., Kong, Y., Coatrieux, J.L., Shu, H., Yang,
    G., Li, S., 2022. Xmorpher: Full transformer for deformable medical image registration
    via cross attention, in: 25${}^{\mbox{\tiny{th}}}$ International Conference on
    Medical Image Computing and Computer Assisted Intervention (MICCAI 2022), Springer.
    pp. 217–226.'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等 [2022] Shi, J., He, Y., Kong, Y., Coatrieux, J.L., Shu, H., Yang, G.,
    Li, S., 2022. Xmorpher：用于变形医学图像配准的全变换器，通过交叉注意力，见于：第25届医学图像计算与计算机辅助干预国际会议（MICCAI
    2022），Springer出版社，第217–226页。
- en: 'Shu et al. [2018] Shu, Z., Sahasrabudhe, M., Guler, R.A., Samaras, D., Paragios,
    N., Kokkinos, I., 2018. Deforming autoencoders: Unsupervised disentangling of
    shape and appearance, in: Proceedings of the European Conference on Computer Vision
    (ECCV), pp. 650–665.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shu 等 [2018] Shu, Z., Sahasrabudhe, M., Guler, R.A., Samaras, D., Paragios,
    N., Kokkinos, I., 2018. 变形自编码器：形状与外观的无监督解缠，见于：欧洲计算机视觉会议（ECCV）论文集，第650–665页。
- en: 'Siebert et al. [2022] Siebert, H., Hansen, L., Heinrich, M.P., 2022. Fast 3D
    registration with accurate optimisation and little learning for Learn2Reg 2021,
    in: Biomedical Image Registration, Domain Generalisation and Out-of-Distribution
    Analysis: MICCAI 2021 Challenges: MIDOG 2021, MOOD 2021, and Learn2Reg 2021, Held
    in Conjunction with MICCAI 2021, Strasbourg, France, September 27–October 1, 2021,
    Proceedings. Springer, pp. 174–179.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Siebert 等 [2022] Siebert, H., Hansen, L., Heinrich, M.P., 2022. 快速3D配准，具有精确优化和少量学习，见于：生物医学图像配准、领域泛化和分布外分析：MICCAI
    2021挑战：MIDOG 2021、MOOD 2021和Learn2Reg 2021，MICCAI 2021会议附属，法国斯特拉斯堡，2021年9月27日–10月1日，会议录，Springer出版社，第174–179页。
- en: 'Siebert and Heinrich [2022] Siebert, H., Heinrich, M.P., 2022. Learn to fuse
    input features for large-deformation registration with differentiable convex-discrete
    optimisation, in: Biomedical Image Registration: 10th International Workshop,
    WBIR 2022, Munich, Germany, July 10–12, 2022, Proceedings, Springer. pp. 119–123.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Siebert 和 Heinrich [2022] Siebert, H., Heinrich, M.P., 2022. 学习融合输入特征用于大变形配准，采用可微分凸离散优化，见于：生物医学图像配准：第十届国际研讨会，WBIR
    2022，德国慕尼黑，2022年7月10–12日，会议录，Springer出版社，第119–123页。
- en: 'Siebert et al. [2021] Siebert, H., Rajamani, K.T., Heinrich, M.P., 2021. Learning
    inverse consistent 3d groupwise registration with deforming autoencoders, in:
    Medical Imaging 2021: Image Processing, SPIE. pp. 89–95.'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Siebert 等 [2021] Siebert, H., Rajamani, K.T., Heinrich, M.P., 2021. 学习反向一致的3D组配准，采用变形自编码器，见于：医学成像2021：图像处理，SPIE出版社，第89–95页。
- en: Simpson et al. [2015] Simpson, I.J., Cardoso, M.J., Modat, M., Cash, D.M., Woolrich,
    M.W., Andersson, J.L., Schnabel, J.A., Ourselin, S., Initiative, A.D.N., et al.,
    2015. Probabilistic non-linear registration with spatially adaptive regularisation.
    Medical Image Analysis 26, 203–216.
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simpson 等 [2015] Simpson, I.J., Cardoso, M.J., Modat, M., Cash, D.M., Woolrich,
    M.W., Andersson, J.L., Schnabel, J.A., Ourselin, S., Initiative, A.D.N., 等，2015.
    带有空间自适应正则化的概率非线性配准。医学图像分析 26，203–216页。
- en: 'Simpson et al. [2011] Simpson, I.J., Woolrich, M., Groves, A.R., Schnabel,
    J.A., 2011. Longitudinal brain MRI analysis with uncertain registration, in: 14${}^{\mbox{\tiny{th}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2011),
    Springer. pp. 647–654.'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simpson 等 [2011] Simpson, I.J., Woolrich, M., Groves, A.R., Schnabel, J.A.,
    2011. 不确定配准的纵向脑MRI分析，见于：第14届医学图像计算与计算机辅助干预国际会议（MICCAI 2011），Springer出版社，第647–654页。
- en: 'Sinclair et al. [2022] Sinclair, M., Schuh, A., Hahn, K., Petersen, K., Bai,
    Y., Batten, J., Schaap, M., Glocker, B., 2022. Atlas-istn: joint segmentation,
    registration and atlas construction with image-and-spatial transformer networks.
    Medical Image Analysis 78, 102383.'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sinclair 等人 [2022] Sinclair, M., Schuh, A., Hahn, K., Petersen, K., Bai, Y.,
    Batten, J., Schaap, M., Glocker, B., 2022. Atlas-istn：结合图像和空间变换网络的联合分割、配准和图谱构建。医学图像分析
    78, 102383。
- en: Sitzmann et al. [2020] Sitzmann, V., Martel, J., Bergman, A., Lindell, D., Wetzstein,
    G., 2020. Implicit neural representations with periodic activation functions.
    Advances in Neural Information Processing Systems 33, 7462–7473.
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sitzmann 等人 [2020] Sitzmann, V., Martel, J., Bergman, A., Lindell, D., Wetzstein,
    G., 2020. 带有周期性激活函数的隐式神经表示。神经信息处理系统进展 33, 7462–7473。
- en: 'Smolders et al. [2022] Smolders, A., Lomax, T., Weber, D., Albertini, F., 2022.
    Deformable image registration uncertainty quantification using deep learning for
    dose accumulation in adaptive proton therapy, in: Biomedical Image Registration:
    10th International Workshop, WBIR 2022, Munich, Germany, July 10–12, 2022, Proceedings,
    Springer. pp. 57–66.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Smolders 等人 [2022] Smolders, A., Lomax, T., Weber, D., Albertini, F., 2022.
    使用深度学习进行变形图像配准不确定性量化，用于适应性质子治疗中的剂量积累，发表于：生物医学图像配准：第 10 届国际研讨会，WBIR 2022，德国慕尼黑，2022
    年 7 月 10–12 日，会议论文集，Springer，页码 57–66。
- en: 'Sohl-Dickstein et al. [2015] Sohl-Dickstein, J., Weiss, E., Maheswaranathan,
    N., Ganguli, S., 2015. Deep unsupervised learning using nonequilibrium thermodynamics,
    in: 32${}^{\mbox{\tiny{nd}}}$ International Conference on Machine Learning (ICML 2016),
    PMLR. pp. 2256–2265.'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sohl-Dickstein 等人 [2015] Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N.,
    Ganguli, S., 2015. 使用非平衡热力学的深度无监督学习，发表于：第 32 届机器学习国际会议（ICML 2016），PMLR，页码 2256–2265。
- en: 'Sokooti et al. [2016] Sokooti, H., Saygili, G., Glocker, B., Lelieveldt, B.P.,
    Staring, M., 2016. Accuracy estimation for medical image registration using regression
    forests, in: 19${}^{\mbox{\tiny{th}}}$ International Conference on Medical Image
    Computing and Computer Assisted Intervention (MICCAI 2016), Springer. pp. 107–115.'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sokooti 等人 [2016] Sokooti, H., Saygili, G., Glocker, B., Lelieveldt, B.P., Staring,
    M., 2016. 使用回归森林进行医学图像配准的精度估计，发表于：第 19 届医学图像计算与计算机辅助手术国际会议（MICCAI 2016），Springer，页码
    107–115。
- en: 'Sokooti et al. [2017] Sokooti, H., Vos, B.d., Berendsen, F., Lelieveldt, B.P.,
    Išgum, I., Staring, M., 2017. Nonrigid image registration using multi-scale 3D
    convolutional neural networks, in: 20${}^{\mbox{\tiny{th}}}$ International Conference
    on Medical Image Computing and Computer Assisted Intervention (MICCAI 2017), Springer.
    pp. 232–239.'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sokooti 等人 [2017] Sokooti, H., Vos, B.d., Berendsen, F., Lelieveldt, B.P., Išgum,
    I., Staring, M., 2017. 使用多尺度 3D 卷积神经网络进行非刚性图像配准，发表于：第 20 届医学图像计算与计算机辅助手术国际会议（MICCAI
    2017），Springer，页码 232–239。
- en: 'Sokooti et al. [2021] Sokooti, H., Yousefi, S., Elmahdy, M.S., Lelieveldt,
    B.P., Staring, M., 2021. Hierarchical prediction of registration misalignment
    using a convolutional LSTM: Application to chest CT scans. IEEE Access 9, 62008–62020.'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sokooti 等人 [2021] Sokooti, H., Yousefi, S., Elmahdy, M.S., Lelieveldt, B.P.,
    Staring, M., 2021. 使用卷积 LSTM 进行配准误差的分层预测：应用于胸部 CT 扫描。IEEE Access 9, 62008–62020。
- en: Song et al. [2022] Song, X., Chao, H., Xu, X., Guo, H., Xu, S., Turkbey, B.,
    Wood, B.J., Sanford, T., Wang, G., Yan, P., 2022. Cross-modal attention for multi-modal
    image registration. Medical Image Analysis 82, 102612.
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song 等人 [2022] Song, X., Chao, H., Xu, X., Guo, H., Xu, S., Turkbey, B., Wood,
    B.J., Sanford, T., Wang, G., Yan, P., 2022. 跨模态注意力用于多模态图像配准。医学图像分析 82, 102612。
- en: 'Sotiras et al. [2013] Sotiras, A., Davatzikos, C., Paragios, N., 2013. Deformable
    medical image registration: A survey. IEEE Trans. Med. Imag. 32, 1153–1190.'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sotiras 等人 [2013] Sotiras, A., Davatzikos, C., Paragios, N., 2013. 变形医学图像配准：综述。IEEE
    医学影像学会期刊 32, 1153–1190。
- en: Stefanescu et al. [2004] Stefanescu, R., Pennec, X., Ayache, N., 2004. Grid
    powered nonlinear image registration with locally adaptive regularization. Medical
    Image Analysis 8, 325–342.
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stefanescu 等人 [2004] Stefanescu, R., Pennec, X., Ayache, N., 2004. 基于网格的非线性图像配准与局部自适应正则化。医学图像分析
    8, 325–342。
- en: 'Stone et al. [2021] Stone, A., Maurer, D., Ayvaci, A., Angelova, A., Jonschkowski,
    R., 2021. Smurf: Self-teaching multi-frame unsupervised raft with full-image warping,
    in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    pp. 3887–3896.'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Stone 等人 [2021] Stone, A., Maurer, D., Ayvaci, A., Angelova, A., Jonschkowski,
    R., 2021. Smurf: 自我教学的多帧无监督 RAFT 结合全图像变形，发表于：IEEE/CVF 计算机视觉与模式识别会议论文集，页码 3887–3896。'
- en: Studholme et al. [2000] Studholme, C., Constable, R.T., Duncan, J.S., 2000.
    Accurate alignment of functional EPI data to anatomical MRI using a physics-based
    distortion model. IEEE Trans. Med. Imag. 19, 1115–1127.
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Studholme 等人 [2000] Studholme, C., Constable, R.T., Duncan, J.S., 2000. 使用基于物理的畸变模型对功能性
    EPI 数据与解剖 MRI 进行准确对齐。IEEE Trans. Med. Imag. 19, 1115–1127。
- en: 'Sun et al. [2022] Sun, S., Han, K., Kong, D., Tang, H., Yan, X., Xie, X., 2022.
    Topology-preserving shape reconstruction and registration via neural diffeomorphic
    flow, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp. 20845–20855.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等人 [2022] Sun, S., Han, K., Kong, D., Tang, H., Yan, X., Xie, X., 2022.
    通过神经微分流保持拓扑形状重建和配准，见：IEEE/CVF 计算机视觉与模式识别会议论文集，页 20845–20855。
- en: 'Ta et al. [2020] Ta, K., Ahn, S.S., Stendahl, J.C., Sinusas, A.J., Duncan,
    J.S., 2020. A semi-supervised joint network for simultaneous left ventricular
    motion tracking and segmentation in 4d echocardiography, in: 23${}^{\mbox{\tiny{rd}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2020),
    Springer. pp. 468–477.'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ta 等人 [2020] Ta, K., Ahn, S.S., Stendahl, J.C., Sinusas, A.J., Duncan, J.S.,
    2020. 一种半监督联合网络，用于 4D 超声心动图中左心室运动跟踪和分割的同步，见：第 23${}^{\mbox{\tiny{rd}}}$ 届医学图像计算与计算机辅助干预国际会议
    (MICCAI 2020)，Springer. 页 468–477。
- en: Tang et al. [2020] Tang, K., Li, Z., Tian, L., Wang, L., Zhu, Y., 2020. Admir–affine
    and deformable medical image registration for drug-addicted brain images. IEEE
    Access 8, 70960–70968.
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang 等人 [2020] Tang, K., Li, Z., Tian, L., Wang, L., Zhu, Y., 2020. 针对药物成瘾大脑图像的
    Admir–affine 和可变形医学图像配准。IEEE Access 8, 70960–70968。
- en: 'Tang et al. [2010] Tang, L., Hamarneh, G., Abugharbieh, R., 2010. Reliability-driven,
    spatially-adaptive regularization for deformable registration, in: Biomedical
    Image Registration: 4th International Workshop, WBIR 2010, Lübeck, Germany, July
    11-13, 2010\. Proceedings 4, Springer. pp. 173–185.'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang 等人 [2010] Tang, L., Hamarneh, G., Abugharbieh, R., 2010. 以可靠性驱动的空间自适应正则化用于可变形配准，见：生物医学图像配准：第
    4 届国际研讨会，WBIR 2010，德国吕贝克，2010年7月11-13日。会议论文集 4, Springer. 页 173–185。
- en: 'Terpstra et al. [2022] Terpstra, M.L., Maspero, M., Sbrizzi, A., van den Berg,
    C.A., 2022. $\bot$-loss: a symmetric loss function for magnetic resonance imaging
    reconstruction and image registration with deep learning. Medical Image Analysis
    , 102509.'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Terpstra 等人 [2022] Terpstra, M.L., Maspero, M., Sbrizzi, A., van den Berg, C.A.,
    2022. $\bot$-损失：用于磁共振成像重建和图像配准的对称损失函数，结合深度学习。医学图像分析 , 102509。
- en: Teske et al. [2017] Teske, H., Bartelheimer, K., Meis, J., Bendl, R., Stoiber,
    E.M., Giske, K., 2017. Construction of a biomechanical head and neck motion model
    as a guide to evaluation of deformable image registration. Physics in Medicine
    & Biology 62, N271.
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Teske 等人 [2017] Teske, H., Bartelheimer, K., Meis, J., Bendl, R., Stoiber, E.M.,
    Giske, K., 2017. 生物力学头颈运动模型的构建，作为可变形图像配准评估的指导。医学与生物学物理 62, N271。
- en: Thévenaz and Unser [2000] Thévenaz, P., Unser, M., 2000. Optimization of mutual
    information for multiresolution image registration. IEEE transactions on image
    processing 9, 2083–2099.
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thévenaz 和 Unser [2000] Thévenaz, P., Unser, M., 2000. 用于多分辨率图像配准的互信息优化。IEEE
    transactions on image processing 9, 2083–2099。
- en: 'Tian et al. [2022] Tian, L., Greer, H., Vialard, F.X., Kwitt, R., Estépar,
    R.S.J., Niethammer, M., 2022. Gradicon: Approximate diffeomorphisms via gradient
    inverse consistency. arXiv preprint arXiv:2206.05897 .'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tian 等人 [2022] Tian, L., Greer, H., Vialard, F.X., Kwitt, R., Estépar, R.S.J.,
    Niethammer, M., 2022. Gradicon: 通过梯度逆一致性获得近似的微分同胚。arXiv 预印本 arXiv:2206.05897。'
- en: Tran et al. [2022] Tran, M.Q., Do, T., Tran, H., Tjiputra, E., Tran, Q.D., Nguyen,
    A., 2022. Light-weight deformable registration using adversarial learning with
    distilling knowledge. IEEE Trans. Med. Imag. 41, 1443–1453.
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tran 等人 [2022] Tran, M.Q., Do, T., Tran, H., Tjiputra, E., Tran, Q.D., Nguyen,
    A., 2022. 使用对抗学习和知识蒸馏的轻量级可变形配准。IEEE Trans. Med. Imag. 41, 1443–1453。
- en: Trouvé and Younes [2005] Trouvé, A., Younes, L., 2005. Metamorphoses through
    lie group action. Foundations of computational mathematics 5, 173–198.
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trouvé 和 Younes [2005] Trouvé, A., Younes, L., 2005. 通过 Lie 群动作的变形。计算数学基础 5,
    173–198。
- en: 'Ulyanov et al. [2018] Ulyanov, D., Vedaldi, A., Lempitsky, V., 2018. Deep image
    prior, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp. 9446–9454.'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ulyanov 等人 [2018] Ulyanov, D., Vedaldi, A., Lempitsky, V., 2018. 深度图像先验，见：IEEE/CVF
    计算机视觉与模式识别会议论文集，页 9446–9454。
- en: 'Unberath et al. [2021] Unberath, M., Gao, C., Hu, Y., Judish, M., Taylor, R.H.,
    Armand, M., Grupp, R., 2021. The impact of machine learning on 2D/3D registration
    for image-guided interventions: A systematic review and perspective. Frontiers
    in Robotics and AI 8, 716007.'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Unberath et al. [2021] Unberath, M., Gao, C., Hu, Y., Judish, M., Taylor, R.H.,
    Armand, M., Grupp, R., 2021. 机器学习对图像引导干预的2D/3D配准的影响：系统综述与展望。机器人与人工智能前沿 8, 716007。
- en: Vaswani et al. [2017] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,
    L., Gomez, A.N., Kaiser, Ł., Polosukhin, I., 2017. Attention is all you need.
    Advances in Neural Information Processing Systems 30.
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani et al. [2017] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,
    L., Gomez, A.N., Kaiser, Ł., Polosukhin, I., 2017. 注意力即一切。神经信息处理系统进展 30。
- en: 'Vercauteren et al. [2009] Vercauteren, T., Pennec, X., Perchant, A., Ayache,
    N., 2009. Diffeomorphic demons: Efficient non-parametric image registration. NeuroImage
    45, S61–S72.'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vercauteren et al. [2009] Vercauteren, T., Pennec, X., Perchant, A., Ayache,
    N., 2009. 微分同胚恶魔：高效的非参数图像配准。神经影像 45, S61–S72。
- en: 'Vialard and Risser [2014] Vialard, F.X., Risser, L., 2014. Spatially-varying
    metric learning for diffeomorphic image registration: A variational framework,
    in: 17${}^{\mbox{\tiny{th}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2014), Springer. pp. 227–234.'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vialard and Risser [2014] Vialard, F.X., Risser, L., 2014. 用于微分图像配准的空间变化度量学习：一种变分框架，见于：第17${}^{\mbox{\tiny{th}}}$届医学图像计算与计算机辅助干预国际会议（MICCAI
    2014），Springer。第227–234页。
- en: Viergever et al. [2016] Viergever, M.A., Maintz, J.A., Klein, S., Murphy, K.,
    Staring, M., Pluim, J.P., 2016. A survey of medical image registration–under review.
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Viergever et al. [2016] Viergever, M.A., Maintz, J.A., Klein, S., Murphy, K.,
    Staring, M., Pluim, J.P., 2016. 医学图像配准综述–正在审阅中。
- en: Viola and Wells III [1997] Viola, P., Wells III, W.M., 1997. Alignment by maximization
    of mutual information. International Journal of Computer Vision 24, 137–154.
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Viola and Wells III [1997] Viola, P., Wells III, W.M., 1997. 通过最大化互信息进行对齐。计算机视觉国际杂志
    24, 137–154。
- en: Vishnevskiy et al. [2016] Vishnevskiy, V., Gass, T., Szekely, G., Tanner, C.,
    Goksel, O., 2016. Isotropic total variation regularization of displacements in
    parametric image registration. IEEE Trans. Med. Imag. 36, 385–395.
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vishnevskiy et al. [2016] Vishnevskiy, V., Gass, T., Szekely, G., Tanner, C.,
    Goksel, O., 2016. 参数图像配准中位移的各向同性全变分正则化。IEEE医学影像学报 36, 385–395。
- en: Vlachopoulos et al. [2015] Vlachopoulos, G., Korfiatis, P., Skiadopoulos, S.,
    Kazantzi, A., Kalogeropoulou, C., Pratikakis, I., Costaridou, L., 2015. Selecting
    registration schemes in case of interstitial lung disease follow-up in CT. Medical
    physics 42, 4511–4525.
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vlachopoulos et al. [2015] Vlachopoulos, G., Korfiatis, P., Skiadopoulos, S.,
    Kazantzi, A., Kalogeropoulou, C., Pratikakis, I., Costaridou, L., 2015. CT中间质肺病随访的配准方案选择。医学物理
    42, 4511–4525。
- en: 'de Vos et al. [2020] de Vos, B.D., van der Velden, B.H., Sander, J., Gilhuijs,
    K.G., Staring, M., Išgum, I., 2020. Mutual information for unsupervised deep learning
    image registration, in: Medical Imaging 2020: Image Processing, SPIE. pp. 155–161.'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'de Vos et al. [2020] de Vos, B.D., van der Velden, B.H., Sander, J., Gilhuijs,
    K.G., Staring, M., Išgum, I., 2020. 用于无监督深度学习图像配准的互信息，见于: 医学影像2020：图像处理，SPIE。第155–161页。'
- en: 'Vos et al. [2017] Vos, B.D.d., Berendsen, F.F., Viergever, M.A., Staring, M.,
    Išgum, I., 2017. End-to-end unsupervised deformable image registration with a
    convolutional neural network, in: Deep learning in medical image analysis and
    multimodal learning for clinical decision support. Springer, pp. 204–212.'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Vos et al. [2017] Vos, B.D.d., Berendsen, F.F., Viergever, M.A., Staring, M.,
    Išgum, I., 2017. 使用卷积神经网络的端到端无监督变形图像配准，见于: 医学图像分析中的深度学习与临床决策支持的多模态学习。Springer，第204–212页。'
- en: 'Wang et al. [2019a] Wang, J., Jiao, J., Bao, L., He, S., Liu, Y., Liu, W.,
    2019a. Self-supervised spatio-temporal representation learning for videos by predicting
    motion and appearance statistics, in: Proceedings of the IEEE/CVF Conference on
    Computer Vision and Pattern Recognition, pp. 4006–4015.'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. [2019a] Wang, J., Jiao, J., Bao, L., He, S., Liu, Y., Liu, W., 2019a.
    通过预测运动和外观统计进行视频的自监督时空表示学习，见于：IEEE/CVF计算机视觉与模式识别会议论文集，第4006–4015页。
- en: Wang et al. [2019b] Wang, J., Wells III, W.M., Golland, P., Zhang, M., 2019b.
    Registration uncertainty quantification via low-dimensional characterization of
    geometric deformations. Magnetic resonance imaging 64, 122–131.
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. [2019b] Wang, J., Wells III, W.M., Golland, P., Zhang, M., 2019b.
    通过低维几何变形特征化量化配准不确定性。磁共振成像 64, 122–131。
- en: 'Wang et al. [2023] Wang, J., Xing, J., Druzgal, J., Wells III, W.M., Zhang,
    M., 2023. Metamorph: Learning metamorphic image transformation with appearance
    changes. arXiv preprint arXiv:2303.04849 .'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '王等[2023] 王, J., 邢, J., 德鲁兹加尔, J., 韦尔斯III, W.M., 张, M., 2023. Metamorph: 学习形态变化的图像变换，arXiv预印本arXiv:2303.04849。'
- en: 'Wang and Zhang [2020] Wang, J., Zhang, M., 2020. Deepflash: An efficient network
    for learning-based medical image registration, in: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, pp. 4444–4452.'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '王及张[2020] 王, J., 张, M., 2020. Deepflash: 一种高效的基于学习的医学图像配准网络，发表于：IEEE/CVF计算机视觉与模式识别会议论文集，第4444–4452页。'
- en: Wang et al. [2022] Wang, J., Zhang, M., et al., 2022. Deep learning for regularization
    prediction in diffeomorphic image registration. Machine Learning for Biomedical
    Imaging 1, 1–10.
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等[2022] 王, J., 张, M., 等, 2022. 深度学习用于 diffeomorphic 图像配准中的正则化预测。生物医学成像的机器学习
    1, 1–10。
- en: 'Wang et al. [2004] Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., 2004.
    Image quality assessment: from error visibility to structural similarity. IEEE
    transactions on image processing 13, 600–612.'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等[2004] 王, Z., 博维克, A.C., 谢赫, H.R., 西蒙切利, E.P., 2004. 图像质量评估：从错误可见性到结构相似性。IEEE图像处理学报
    13, 600–612。
- en: 'Wannenwetsch et al. [2017] Wannenwetsch, A.S., Keuper, M., Roth, S., 2017.
    Probflow: Joint optical flow and uncertainty estimation, in: Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1173–1182.'
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '万嫩维特施等[2017] 万嫩维特施, A.S., 克佩尔, M., 罗思, S., 2017. Probflow: 联合光流和不确定性估计，发表于：IEEE/CVF计算机视觉与模式识别会议论文集，第1173–1182页。'
- en: Wei et al. [2021a] Wei, D., Ahmad, S., Guo, Y., Chen, L., Huang, Y., Ma, L.,
    Wu, Z., Li, G., Wang, L., Lin, W., et al., 2021a. Recurrent tissue-aware network
    for deformable registration of infant brain mr images. IEEE transactions on medical
    imaging 41, 1219–1229.
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 魏等[2021a] 魏, D., 阿赫迈德, S., 郭, Y., 陈, L., 黄, Y., 马, L., 吴, Z., 李, G., 王, L.,
    林, W., 等, 2021a. 递归组织感知网络用于婴儿脑MR图像的变形配准。IEEE医学成像学报 41, 1219–1229。
- en: 'Wei et al. [2019] Wei, D., Ahmad, S., Huo, J., Peng, W., Ge, Y., Xue, Z., Yap,
    P.T., Li, W., Shen, D., Wang, Q., 2019. Synthesis and inpainting-based MR-CT registration
    for image-guided thermal ablation of liver tumors, in: 22${}^{\mbox{\tiny{nd}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2019),
    Springer. pp. 512–520.'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 魏等[2019] 魏, D., 阿赫迈德, S., 霍, J., 彭, W., 葛, Y., 薛, Z., 叶, P.T., 李, W., 沈, D.,
    王, Q., 2019. 基于合成与修补的MR-CT配准用于图像引导的肝肿瘤热消融，发表于：第22${}^{\mbox{\tiny{nd}}}$届医学图像计算与计算机辅助干预国际会议（MICCAI
    2019），Springer，第512–520页。
- en: Wei et al. [2021b] Wei, W., Haishan, X., Alpers, J., Rak, M., Hansen, C., 2021b.
    A deep learning approach for 2D ultrasound and 3D CT/MR image registration in
    liver tumor ablation. Computer Methods and Programs in Biomedicine 206, 106117.
    doi:[10.1016/j.cmpb.2021.106117](http://dx.doi.org/10.1016/j.cmpb.2021.106117).
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 魏等[2021b] 魏, W., 海山, X., 阿尔珀斯, J., 拉克, M., 汉森, C., 2021b. 一种深度学习方法用于肝肿瘤消融中的2D超声和3D
    CT/MR图像配准。生物医学计算方法与程序 206, 106117. doi:[10.1016/j.cmpb.2021.106117](http://dx.doi.org/10.1016/j.cmpb.2021.106117)。
- en: Wells III et al. [1996] Wells III, W.M., Viola, P., Atsumi, H., Nakajima, S.,
    Kikinis, R., 1996. Multi-modal volume registration by maximization of mutual information.
    Medical Image Analysis 1, 35–51.
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 韦尔斯III等[1996] 韦尔斯III, W.M., 维奥拉, P., 厚志, H., 中岛, S., 基基尼斯, R., 1996. 通过最大化互信息进行多模态体积配准。医学图像分析
    1, 35–51。
- en: Wetzer et al. [2023] Wetzer, E., Lindblad, J., Sladoje, N., 2023. Can representation
    learning for multimodal image registration be improved by supervision of intermediate
    layers? arXiv preprint arXiv:2303.00403 .
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 韦策尔等[2023] 韦策尔, E., 林德布拉德, J., 斯拉多耶, N., 2023. 多模态图像配准的表征学习是否可以通过中间层的监督来改进？arXiv预印本arXiv:2303.00403。
- en: 'Wolterink et al. [2022] Wolterink, J.M., Zwienenberg, J.C., Brune, C., 2022.
    Implicit neural representations for deformable image registration, in: International
    Conference on Medical Imaging with Deep Learning, PMLR. pp. 1349–1359.'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 沃尔特林克等[2022] 沃尔特林克, J.M., 兹维嫩伯格, J.C., 布鲁恩, C., 2022. 用于变形图像配准的隐式神经表示，发表于：医学成像与深度学习国际会议，PMLR，第1349–1359页。
- en: 'Wu et al. [2013] Wu, G., Kim, M., Wang, Q., Gao, Y., Liao, S., Shen, D., 2013.
    Unsupervised deep feature learning for deformable registration of MR brain images,
    in: 16${}^{\mbox{\tiny{th}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2013), Springer. pp. 649–656.'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吴等[2013] 吴, G., 金, M., 王, Q., 高, Y., 廖, S., 沈, D., 2013. 无监督深度特征学习用于MR脑图像的变形配准，发表于：第16${}^{\mbox{\tiny{th}}}$届医学图像计算与计算机辅助干预国际会议（MICCAI
    2013），Springer，第649–656页。
- en: 'Wu et al. [2022a] Wu, N., Wang, J., Zhang, M., Zhang, G., Peng, Y., Shen, C.,
    2022a. Hybrid atlas building with deep registration priors, in: 19${}^{\mbox{\tiny{th}}}$
    International Symposium on Biomedical Imaging (ISBI 2022), IEEE. pp. 1–5.'
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu等人[2022a] Wu, N., Wang, J., Zhang, M., Zhang, G., Peng, Y., Shen, C., 2022a.
    结合深度配准先验的混合图谱构建，在：第19届国际生物医学成像研讨会 (ISBI 2022)，IEEE。第1–5页。
- en: Wu et al. [2019] Wu, R.Y., Liu, A.Y., Wisdom, P., Zhu, X.R., Frank, S.J., Fuller,
    C.D., Gunn, G.B., Palmer, M.B., Wages, C.A., Gillin, M.T., et al., 2019. Characterization
    of a new physical phantom for testing rigid and deformable image registration.
    Journal of Applied Clinical Medical Physics 20, 145–153.
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu等人[2019] Wu, R.Y., Liu, A.Y., Wisdom, P., Zhu, X.R., Frank, S.J., Fuller,
    C.D., Gunn, G.B., Palmer, M.B., Wages, C.A., Gillin, M.T., 等人, 2019. 新型物理模拟体的特征用于测试刚性和可变形图像配准。应用临床医学物理学杂志
    20, 145–153。
- en: 'Wu et al. [2022b] Wu, Y., Jiahao, T.Z., Wang, J., Yushkevich, P.A., Hsieh,
    M.A., Gee, J.C., 2022b. Nodeo: A neural ordinary differential equation based optimization
    framework for deformable image registration, in: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 20804–20813.'
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu等人[2022b] Wu, Y., Jiahao, T.Z., Wang, J., Yushkevich, P.A., Hsieh, M.A., Gee,
    J.C., 2022b. Nodeo：一种基于神经常微分方程的变形图像配准优化框架，在：IEEE/CVF计算机视觉与模式识别会议论文集，第20804–20813页。
- en: Xiao et al. [2021] Xiao, H., Teng, X., Liu, C., Li, T., Ren, G., Yang, R., Shen,
    D., Cai, J., 2021. A review of deep learning-based three-dimensional medical image
    registration methods. Quantitative Imaging in Medicine and Surgery 11, 4895.
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiao等人[2021] Xiao, H., Teng, X., Liu, C., Li, T., Ren, G., Yang, R., Shen, D.,
    Cai, J., 2021. 基于深度学习的三维医学图像配准方法综述。医学与手术定量成像 11, 4895。
- en: 'Xie et al. [2019] Xie, L., Wang, J., Dong, M., Wolk, D.A., Yushkevich, P.A.,
    2019. Improving multi-atlas segmentation by convolutional neural network based
    patch error estimation, in: 22${}^{\mbox{\tiny{nd}}}$ International Conference
    on Medical Image Computing and Computer Assisted Intervention (MICCAI 2019), Springer.
    pp. 347–355.'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie等人[2019] Xie, L., Wang, J., Dong, M., Wolk, D.A., Yushkevich, P.A., 2019.
    通过基于卷积神经网络的补丁误差估计改进多图谱分割，在：第22届医学图像计算与计算机辅助干预国际会议 (MICCAI 2019)，Springer。第347–355页。
- en: 'Xie et al. [2023] Xie, L., Wisse, L.E., Wang, J., Ravikumar, S., Khandelwal,
    P., Glenn, T., Luther, A., Lim, S., Wolk, D.A., Yushkevich, P.A., 2023. Deep label
    fusion: A generalizable hybrid multi-atlas and deep convolutional neural network
    for medical image segmentation. Medical Image Analysis 83, 102683.'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie等人[2023] Xie, L., Wisse, L.E., Wang, J., Ravikumar, S., Khandelwal, P., Glenn,
    T., Luther, A., Lim, S., Wolk, D.A., Yushkevich, P.A., 2023. 深度标签融合：一种通用的混合多图谱和深度卷积神经网络用于医学图像分割。医学图像分析
    83, 102683。
- en: Xing et al. [2017] Xing, F., Woo, J., Gomez, A.D., Pham, D.L., Bayly, P.V.,
    Stone, M., Prince, J.L., 2017. Phase vector incompressible registration algorithm
    for motion estimation from tagged magnetic resonance images. IEEE Trans. Med.
    Imag. 36, 2116–2128.
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xing等人[2017] Xing, F., Woo, J., Gomez, A.D., Pham, D.L., Bayly, P.V., Stone,
    M., Prince, J.L., 2017. 相位矢量不可压缩配准算法用于从标记磁共振图像中估计运动。IEEE医学成像汇刊 36, 2116–2128。
- en: 'Xu et al. [2021] Xu, J., Chen, E.Z., Chen, X., Chen, T., Sun, S., 2021. Multi-scale
    neural odes for 3D medical image registration, in: 24${}^{\mbox{\tiny{th}}}$ International
    Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2021),
    Springer. pp. 213–223.'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu等人[2021] Xu, J., Chen, E.Z., Chen, X., Chen, T., Sun, S., 2021. 用于3D医学图像配准的多尺度神经常微分方程，在：第24届医学图像计算与计算机辅助干预国际会议
    (MICCAI 2021)，Springer。第213–223页。
- en: 'Xu et al. [2022] Xu, Z., Luo, J., Lu, D., Yan, J., Frisken, S., Jagadeesan,
    J., Wells III, W.M., Li, X., Zheng, Y., Tong, R.K.y., 2022. Double-uncertainty
    guided spatial and temporal consistency regularization weighting for learning-based
    abdominal registration, in: MICCAI22, Springer. pp. 14–24.'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu等人[2022] Xu, Z., Luo, J., Lu, D., Yan, J., Frisken, S., Jagadeesan, J., Wells
    III, W.M., Li, X., Zheng, Y., Tong, R.K.y., 2022. 双重不确定性引导的空间和时间一致性正则化加权用于基于学习的腹部配准，在：MICCAI22，Springer。第14–24页。
- en: 'Xu et al. [2020] Xu, Z., Luo, J., Yan, J., Pulya, R., Li, X., Wells, W., Jagadeesan,
    J., 2020. Adversarial uni-and multi-modal stream networks for multimodal image
    registration, in: 23${}^{\mbox{\tiny{rd}}}$ International Conference on Medical
    Image Computing and Computer Assisted Intervention (MICCAI 2020), Springer. pp.
    222–232.'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu等人[2020] Xu, Z., Luo, J., Yan, J., Pulya, R., Li, X., Wells, W., Jagadeesan,
    J., 2020. 对抗性单模态和多模态流网络用于多模态图像配准，在：第23届医学图像计算与计算机辅助干预国际会议 (MICCAI 2020)，Springer。第222–232页。
- en: 'Xu and Niethammer [2019] Xu, Z., Niethammer, M., 2019. Deepatlas: Joint semi-supervised
    learning of image registration and segmentation, in: 22${}^{\mbox{\tiny{nd}}}$
    International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2019),
    Springer. pp. 420–429.'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 和 Niethammer [2019] Xu, Z., Niethammer, M., 2019. Deepatlas：图像配准和分割的联合半监督学习，收录于《第22届医学图像计算与计算机辅助手术国际会议
    (MICCAI 2019)》，Springer。页码 420–429。
- en: 'Yan et al. [2018] Yan, P., Xu, S., Rastinehad, A.R., Wood, B.J., 2018. Adversarial
    image registration with application for MR and TRUS image fusion, in: Machine
    Learning in Medical Imaging: 9th International Workshop, MLMI 2018, Held in Conjunction
    with MICCAI 2018, Granada, Spain, September 16, 2018, Proceedings 9, Springer.
    pp. 197–204.'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yan 等人 [2018] Yan, P., Xu, S., Rastinehad, A.R., Wood, B.J., 2018. 对抗性图像配准及其在
    MR 和 TRUS 图像融合中的应用，收录于《医学影像中的机器学习：第九届国际研讨会，MLMI 2018，与 MICCAI 2018 同期举办，西班牙格拉纳达，2018年9月16日，论文集9》，Springer。页码
    197–204。
- en: Yang et al. [2020] Yang, H., Sun, J., Carass, A., Zhao, C., Lee, J., Prince,
    J.L., Xu, Z., 2020. Unsupervised MR-to-CT synthesis using structure-constrained
    CycleGAN. IEEE Trans. Med. Imag. 39, 4249–4261.
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 [2020] Yang, H., Sun, J., Carass, A., Zhao, C., Lee, J., Prince, J.L.,
    Xu, Z., 2020. 使用结构约束的 CycleGAN 进行无监督 MR-to-CT 合成。IEEE 医学影像学报 39, 4249–4261。
- en: 'Yang et al. [2018] Yang, H., Sun, J., Li, H., Wang, L., Xu, Z., 2018. Neural
    multi-atlas label fusion: Application to cardiac MR images. Medical Image Analysis
    49, 60–75.'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 [2018] Yang, H., Sun, J., Li, H., Wang, L., Xu, Z., 2018. 神经多图谱标签融合：应用于心脏
    MR 图像。医学图像分析 49, 60–75。
- en: 'Yang et al. [2022a] Yang, J., Wickramasinghe, U., Ni, B., Fua, P., 2022a. Implicitatlas:
    learning deformable shape templates in medical imaging, in: Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 15861–15871.'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 [2022a] Yang, J., Wickramasinghe, U., Ni, B., Fua, P., 2022a. Implicitatlas：在医学影像中学习可变形形状模板，收录于《IEEE/CVF
    计算机视觉与模式识别会议论文集》，页码 15861–15871。
- en: 'Yang et al. [2022b] Yang, T., Bai, X., Cui, X., Gong, Y., Li, L., 2022b. Graformerdir:
    Graph convolution transformer for deformable image registration. Computers in
    Biology and Medicine 147, 105799.'
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 [2022b] Yang, T., Bai, X., Cui, X., Gong, Y., Li, L., 2022b. Graformerdir：用于可变形图像配准的图卷积变换器。计算机与生物医学
    147, 105799。
- en: 'Yang et al. [2016] Yang, X., Kwitt, R., Niethammer, M., 2016. Fast predictive
    image registration, in: Deep Learning and Data Labeling for Medical Applications:
    First International Workshop, LABELS 2016, and Second International Workshop,
    DLMIA 2016, Held in Conjunction with MICCAI 2016, Athens, Greece, October 21,
    2016, Proceedings 1, Springer. pp. 48–57.'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 [2016] Yang, X., Kwitt, R., Niethammer, M., 2016. 快速预测图像配准，收录于《医学应用中的深度学习与数据标注：第一次国际研讨会
    LABELS 2016 和第二次国际研讨会 DLMIA 2016，与 MICCAI 2016 同期举办，希腊雅典，2016年10月21日，论文集1》，Springer。页码
    48–57。
- en: 'Yang et al. [2017] Yang, X., Kwitt, R., Styner, M., Niethammer, M., 2017. Quicksilver:
    Fast predictive image registration–a deep learning approach. NeuroImage 158, 378–396.'
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 [2017] Yang, X., Kwitt, R., Styner, M., Niethammer, M., 2017. Quicksilver：快速预测图像配准——一种深度学习方法。NeuroImage
    158, 378–396。
- en: 'Yao et al. [2020] Yao, Y., Liu, C., Luo, D., Zhou, Y., Ye, Q., 2020. Video
    playback rate perception for self-supervised spatio-temporal representation learning,
    in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    pp. 6548–6557.'
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 等人 [2020] Yao, Y., Liu, C., Luo, D., Zhou, Y., Ye, Q., 2020. 自监督时空表示学习的视频回放速率感知，收录于《IEEE/CVF
    计算机视觉与模式识别会议论文集》，页码 6548–6557。
- en: 'Ye et al. [2021] Ye, M., Kanski, M., Yang, D., Chang, Q., Yan, Z., Huang, Q.,
    Axel, L., Metaxas, D., 2021. DeepTag: An unsupervised deep learning method for
    motion tracking on cardiac tagging magnetic resonance images, in: 2021 IEEE Conference
    on Computer Vision and Pattern Recognition (CVPR), pp. 7261–7271.'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ye 等人 [2021] Ye, M., Kanski, M., Yang, D., Chang, Q., Yan, Z., Huang, Q., Axel,
    L., Metaxas, D., 2021. DeepTag：一种用于心脏标记磁共振图像运动追踪的无监督深度学习方法，收录于《2021 IEEE 计算机视觉与模式识别会议
    (CVPR)》，页码 7261–7271。
- en: Younes [2010] Younes, L., 2010. Shapes and diffeomorphisms. volume 171. Springer.
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Younes [2010] Younes, L., 2010. 形状与微分同胚。卷 171。Springer。
- en: 'Yu et al. [2020a] Yu, E.M., Dalca, A.V., Sabuncu, M.R., 2020a. Learning conditional
    deformable shape templates for brain anatomy, in: Machine Learning in Medical
    Imaging: 11th International Workshop, MLMI 2020, Held in Conjunction with MICCAI
    2020, Lima, Peru, October 4, 2020, Proceedings 11, Springer. pp. 353–362.'
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等人 [2020a] Yu, E.M., Dalca, A.V., Sabuncu, M.R., 2020a. 为脑部解剖学学习条件性可变形形状模板，收录于《医学影像中的机器学习：第十一届国际研讨会，MLMI
    2020，与 MICCAI 2020 同期举办，秘鲁利马，2020年10月4日，论文集11》，Springer。页码 353–362。
- en: 'Yu et al. [2020b] Yu, H., Chen, X., Shi, H., Chen, T., Huang, T.S., Sun, S.,
    2020b. Motion pyramid networks for accurate and efficient cardiac motion estimation,
    in: 23${}^{\mbox{\tiny{rd}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2020), Springer. pp. 436–446.'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等 [2020b] Yu, H., Chen, X., Shi, H., Chen, T., Huang, T.S., Sun, S., 2020b.
    动作金字塔网络用于准确且高效的心脏运动估计，见于：23${}^{\mbox{\tiny{rd}}}$ 国际医学图像计算与计算机辅助手术会议（MICCAI 2020），Springer.
    pp. 436–446.
- en: 'Yu et al. [2020c] Yu, H., Sun, S., Yu, H., Chen, X., Shi, H., Huang, T.S.,
    Chen, T., 2020c. Foal: Fast online adaptive learning for cardiac motion estimation,
    in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    pp. 4313–4323.'
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yu 等 [2020c] Yu, H., Sun, S., Yu, H., Chen, X., Shi, H., Huang, T.S., Chen,
    T., 2020c. FOAL: 快速在线自适应学习用于心脏运动估计，见于：IEEE/CVF 计算机视觉与模式识别会议论文集，pp. 4313–4323.'
- en: 'Yuan et al. [2021] Yuan, L., Chen, Y., Wang, T., Yu, W., Shi, Y., Jiang, Z.H.,
    Tay, F.E., Feng, J., Yan, S., 2021. Tokens-to-token vit: Training vision transformers
    from scratch on imagenet, in: Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition, pp. 558–567.'
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yuan 等 [2021] Yuan, L., Chen, Y., Wang, T., Yu, W., Shi, Y., Jiang, Z.H., Tay,
    F.E., Feng, J., Yan, S., 2021. Tokens-to-token vit: 从头开始在 imagenet 上训练视觉变换器，见于：IEEE/CVF
    计算机视觉与模式识别会议论文集，pp. 558–567.'
- en: Zhang [2018] Zhang, J., 2018. Inverse-consistent deep networks for unsupervised
    deformable image registration. arXiv preprint arXiv:1809.03443 .
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang [2018] Zhang, J., 2018. 反向一致深度网络用于无监督可变形图像配准. arXiv 预印本 arXiv:1809.03443.
- en: Zhang and Fletcher [2019] Zhang, M., Fletcher, P.T., 2019. Fast diffeomorphic
    image registration via fourier-approximated lie algebras. International Journal
    of Computer Vision 127, 61–73.
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 和 Fletcher [2019] Zhang, M., Fletcher, P.T., 2019. 通过傅里叶近似李代数实现快速微分同胚图像配准.
    International Journal of Computer Vision 127, 61–73.
- en: Zhang et al. [2020] Zhang, S., Liu, P.X., Zheng, M., Shi, W., 2020. A diffeomorphic
    unsupervised method for deformable soft tissue image registration. Computers in
    Biology and Medicine 120, 103708.
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等 [2020] Zhang, S., Liu, P.X., Zheng, M., Shi, W., 2020. 一种用于可变形软组织图像配准的微分同胚无监督方法.
    Computers in Biology and Medicine 120, 103708.
- en: Zhang et al. [2023] Zhang, Y., Li, L., Wang, W., Xie, R., Song, L., Zhang, W.,
    2023. Boosting video object segmentation via space-time correspondence learning.
    arXiv preprint arXiv:2304.06211 .
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等 [2023] Zhang, Y., Li, L., Wang, W., Xie, R., Song, L., Zhang, W., 2023.
    通过时空对应学习提升视频对象分割. arXiv 预印本 arXiv:2304.06211.
- en: 'Zhang et al. [2021] Zhang, Y., Pei, Y., Zha, H., 2021. Learning dual transformer
    network for diffeomorphic registration, in: 24${}^{\mbox{\tiny{th}}}$ International
    Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2021),
    Springer. pp. 129–138.'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等 [2021] Zhang, Y., Pei, Y., Zha, H., 2021. 学习双重变换网络用于微分同胚配准，见于：24${}^{\mbox{\tiny{th}}}$
    国际医学图像计算与计算机辅助手术会议（MICCAI 2021），Springer. pp. 129–138.
- en: 'Zhao et al. [2021a] Zhao, F., Wu, Z., Wang, F., Lin, W., Xia, S., Shen, D.,
    Wang, L., Li, G., 2021a. S3reg: Superfast spherical surface registration based
    on deep learning. IEEE Trans. Med. Imag. 40, 1964–1976.'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao 等 [2021a] Zhao, F., Wu, Z., Wang, F., Lin, W., Xia, S., Shen, D., Wang,
    L., Li, G., 2021a. S3reg: 基于深度学习的超快速球面表面配准. IEEE Trans. Med. Imag. 40, 1964–1976.'
- en: 'Zhao et al. [2021b] Zhao, F., Wu, Z., Wang, L., Lin, W., Xia, S., Li, G., Consortium,
    U.B.C.P., 2021b. Learning 4d infant cortical surface atlas with unsupervised spherical
    networks, in: 24${}^{\mbox{\tiny{th}}}$ International Conference on Medical Image
    Computing and Computer Assisted Intervention (MICCAI 2021), Springer. pp. 262–272.'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等 [2021b] Zhao, F., Wu, Z., Wang, L., Lin, W., Xia, S., Li, G., Consortium,
    U.B.C.P., 2021b. 使用无监督球面网络学习 4d 婴儿皮质表面图谱，见于：24${}^{\mbox{\tiny{th}}}$ 国际医学图像计算与计算机辅助手术会议（MICCAI
    2021），Springer. pp. 262–272.
- en: Zhao et al. [2019] Zhao, S., Lau, T., Luo, J., Eric, I., Chang, C., Xu, Y.,
    2019. Unsupervised 3D end-to-end medical image registration with volume tweening
    network. IEEE Journal of Biomedical and Health Informatics 24, 1394–1404.
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等 [2019] Zhao, S., Lau, T., Luo, J., Eric, I., Chang, C., Xu, Y., 2019.
    使用体积过渡网络进行无监督 3D 端到端医学图像配准. IEEE Journal of Biomedical and Health Informatics
    24, 1394–1404.
- en: 'Zheng et al. [2021] Zheng, Y., Sui, X., Jiang, Y., Che, T., Zhang, S., Yang,
    J., Li, H., 2021. Symreg-gan: symmetric image registration with generative adversarial
    networks. IEEE transactions on pattern analysis and machine intelligence 44, 5631–5646.'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zheng 等 [2021] Zheng, Y., Sui, X., Jiang, Y., Che, T., Zhang, S., Yang, J.,
    Li, H., 2021. Symreg-gan: 使用生成对抗网络进行对称图像配准. IEEE transactions on pattern analysis
    and machine intelligence 44, 5631–5646.'
- en: Zhou et al. [2023] Zhou, S., Hu, B., Xiong, Z., Wu, F., 2023. Self-distilled
    hierarchical network for unsupervised deformable image registration. IEEE Trans.
    Med. Imag. .
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 周等人 [2023] 周思，胡斌，熊志，吴飞，2023年。用于无监督变形图像配准的自我蒸馏层次网络。IEEE医学影像学报。
- en: 'Zhou et al. [2019] Zhou, Z., Siddiquee, M.M.R., Tajbakhsh, N., Liang, J., 2019.
    Unet++: Redesigning skip connections to exploit multiscale features in image segmentation.
    IEEE Trans. Med. Imag. 39, 1856–1867.'
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 周等人 [2019] 周震，席迪克，塔杰巴赫什，梁静，2019年。Unet++：重新设计跳跃连接以利用图像分割中的多尺度特征。IEEE医学影像学报 39，第1856–1867页。
- en: Zhu et al. [2020] Zhu, H., Adeli, E., Shi, F., Shen, D., Initiative, A.D.N.,
    2020. Fcn based label correction for multi-atlas guided organ segmentation. NeuroImage
    18, 319–331.
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朱等人 [2020] 朱宏，阿德里，石飞，沈磊，阿尔茨海默病倡议，2020年。基于FCN的标签校正用于多图谱指导的器官分割。神经影像 18，第319–331页。
- en: 'Zhu et al. [2017] Zhu, J.Y., Park, T., Isola, P., Efros, A.A., 2017. Unpaired
    image-to-image translation using cycle-consistent adversarial networks, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2223–2232.'
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朱等人 [2017] 朱俊义，朴宰熙，伊索拉，艾弗罗斯，2017年。使用循环一致对抗网络的无配对图像到图像翻译，见：IEEE/CVF计算机视觉与模式识别会议论文集，第2223–2232页。
- en: 'Zhuang et al. [2008] Zhuang, X., Rhode, K., Arridge, S., Razavi, R., Hill,
    D., Hawkes, D., Ourselin, S., 2008. An atlas-based segmentation propagation framework
    using locally affine registration–application to automatic whole heart segmentation,
    in: 11${}^{\mbox{\tiny{th}}}$ International Conference on Medical Image Computing
    and Computer Assisted Intervention (MICCAI 2008), Springer. pp. 425–433.'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 庄等人 [2008] 庄晓伟，罗德，阿里奇，拉扎维，希尔，霍克斯，欧尔斯林，2008年。基于图谱的分割传播框架使用局部仿射注册——应用于自动全心脏分割，见：第11${}^{\mbox{\tiny{th}}}$届医学图像计算与计算机辅助手术国际会议（MICCAI
    2008），施普林格。第425–433页。
- en: Zou et al. [2022] Zou, J., Gao, B., Song, Y., Qin, J., 2022. A review of deep
    learning-based deformable medical image registration. Frontiers in Oncology 12.
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邹等人 [2022] 邹杰，高斌，宋毅，秦骏，2022年。基于深度学习的变形医学图像配准综述。肿瘤学前沿 12。
