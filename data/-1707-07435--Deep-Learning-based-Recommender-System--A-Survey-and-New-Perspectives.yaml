- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-06 20:08:54'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-06 20:08:54'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1707.07435] Deep Learning based Recommender System: A Survey and New Perspectives'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1707.07435] 基于深度学习的推荐系统：综述与新视角'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1707.07435](https://ar5iv.labs.arxiv.org/html/1707.07435)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1707.07435](https://ar5iv.labs.arxiv.org/html/1707.07435)
- en: 'Deep Learning based Recommender System: A Survey and New Perspectives'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于深度学习的推荐系统：综述与新视角
- en: Shuai Zhang [1234-5678-9012](https://orcid.org/1234-5678-9012 "ORCID identifier")
    University of New South WalesK17, CSE, UNSWSydneyNSW2052Australia [shuai.zhang@unsw.edu.au](mailto:shuai.zhang@unsw.edu.au)
    ,  Lina Yao University of New South WalesK17, CSE, UNSWSydneyNSW2052Australia
    [lina.yao@unsw.edu.au](mailto:lina.yao@unsw.edu.au) ,  Aixin Sun Nanyang Technological
    UniversitySingapore [axsun@ntu.edu.sg](mailto:axsun@ntu.edu.sg)  and  Yi Tay Nanyang
    Technological UniversitySingapore [ytay017@e.ntu.edu.sg](mailto:ytay017@e.ntu.edu.sg)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Shuai Zhang [1234-5678-9012](https://orcid.org/1234-5678-9012 "ORCID identifier")
    新南威尔士大学K17, CSE, UNSWSydneyNSW2052Australia [shuai.zhang@unsw.edu.au](mailto:shuai.zhang@unsw.edu.au)
    , Lina Yao 新南威尔士大学K17, CSE, UNSWSydneyNSW2052Australia [lina.yao@unsw.edu.au](mailto:lina.yao@unsw.edu.au)
    , Aixin Sun 南洋理工大学新加坡 [axsun@ntu.edu.sg](mailto:axsun@ntu.edu.sg) 和 Yi Tay 南洋理工大学新加坡
    [ytay017@e.ntu.edu.sg](mailto:ytay017@e.ntu.edu.sg)
- en: Abstract.
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: With the ever-growing volume of online information, recommender systems have
    been an effective strategy to overcome such information overload. The utility
    of recommender systems cannot be overstated, given its widespread adoption in
    many web applications, along with its potential impact to ameliorate many problems
    related to over-choice. In recent years, deep learning has garnered considerable
    interest in many research fields such as computer vision and natural language
    processing, owing not only to stellar performance but also the attractive property
    of learning feature representations from scratch. The influence of deep learning
    is also pervasive, recently demonstrating its effectiveness when applied to information
    retrieval and recommender systems research. Evidently, the field of deep learning
    in recommender system is flourishing. This article aims to provide a comprehensive
    review of recent research efforts on deep learning based recommender systems.
    More concretely, we provide and devise a taxonomy of deep learning based recommendation
    models, along with providing a comprehensive summary of the state-of-the-art.
    Finally, we expand on current trends and provide new perspectives pertaining to
    this new exciting development of the field.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着在线信息量的不断增长，推荐系统已成为应对信息过载的有效策略。推荐系统的效用不容小觑，鉴于其在许多网络应用中的广泛应用以及其改善过度选择相关问题的潜力。近年来，深度学习在计算机视觉和自然语言处理等多个研究领域引起了广泛关注，这不仅因为其卓越的表现，还因为其从头开始学习特征表示的吸引力特性。深度学习的影响也很广泛，最近在信息检索和推荐系统研究中显示了其有效性。显然，深度学习在推荐系统中的领域正在蓬勃发展。本文旨在提供对基于深度学习的推荐系统的近期研究工作的全面回顾。更具体地说，我们提供并设计了基于深度学习的推荐模型的分类体系，并提供了最前沿技术的全面总结。最后，我们扩展了当前趋势，并提供了关于该领域新兴发展的一些新视角。
- en: 'Recommender System; Deep Learning; SurveyYi Tay is added as an author later
    to help revise the paper for the major revision.Author’s addresses: S. Zhang and
    L. Yao, University of New South Wales; emails: shuai.zhang@unsw.edu.au; lina.yao@unsw.edu.au;
    A. Sun and Y. Tay, Nanyang Technological University; email: axsun@ntu.edu.sg;
    ytay017@e.ntu.edu.sg;^†^†journal: CSUR^†^†journalvolume: 1^†^†journalnumber: 1^†^†article:
    1^†^†journalyear: 2018^†^†publicationmonth: 7^†^†articleseq: 1^†^†copyright: usgovmixed^†^†doi:
    0000001.0000001^†^†ccs: Information systems Recommender systems'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统；深度学习；综述 Yi Tay 后来被添加为作者，帮助修订论文以进行重大修订。作者地址：S. Zhang 和 L. Yao，新南威尔士大学；电子邮件：shuai.zhang@unsw.edu.au；lina.yao@unsw.edu.au；A.
    Sun 和 Y. Tay，南洋理工大学；电子邮件：axsun@ntu.edu.sg；ytay017@e.ntu.edu.sg；^†^†期刊：CSUR^†^†期刊卷号：1^†^†期刊号：1^†^†文章：1^†^†期刊年份：2018^†^†出版月份：7^†^†文章序号：1^†^†版权：usgovmixed^†^†doi：0000001.0000001^†^†ccs：信息系统
    推荐系统
- en: 1\. Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: Recommender systems are an intuitive line of defense against consumer over-choice.
    Given the explosive growth of information available on the web, users are often
    greeted with more than countless products, movies or restaurants. As such, personalization
    is an essential strategy for facilitating a better user experience. All in all,
    these systems have been playing a vital and indispensable role in various information
    access systems to boost business and facilitate decision-making process (Jannach
    et al., [2010](#bib.bib70); Ricci et al., [2015](#bib.bib122)) and are pervasive
    across numerous web domains such as e-commerce and/or media websites.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统是消费者在面对无数产品、电影或餐馆时的直观选择防线。因此，在网络上可获取的信息爆炸性增长的情况下，个性化是促进更好用户体验的关键策略。总之，这些系统在提升业务和促进决策过程中发挥了至关重要和不可替代的作用（Jannach等，[2010](#bib.bib70);
    Ricci等，[2015](#bib.bib122)），并且在电子商务和/或媒体网站等多个网络领域广泛存在。
- en: In general, recommendation lists are generated based on user preferences, item
    features, user-item past interactions and some other additional information such
    as temporal (e.g., sequence-aware recommender) and spatial (e.g., POI recommender)
    data. Recommendation models are mainly categorized into collaborative filtering,
    content-based recommender system and hybrid recommender system based on the types
    of input data (Adomavicius and Tuzhilin, [2005](#bib.bib2)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，推荐列表是基于用户偏好、物品特征、用户-物品过去互动以及一些其他额外信息（如时间（例如，序列感知推荐系统）和空间（例如，POI推荐系统）数据）生成的。根据输入数据类型，推荐模型主要分为协同过滤、基于内容的推荐系统和混合推荐系统（Adomavicius和Tuzhilin，[2005](#bib.bib2))。
- en: Deep learning enjoys a massive hype at the moment. The past few decades have
    witnessed the tremendous success of the deep learning (DL) in many application
    domains such as computer vision and speech recognition. The academia and industry
    have been in a race to apply deep learning to a wider range of applications due
    to its capability in solving many complex tasks while providing start-of-the-art
    results (Covington et al., [2016](#bib.bib28)). Recently, deep learning has been
    revolutionizing the recommendation architectures dramatically and brings more
    opportunities to improve the performance of recommender. Recent advances in deep
    learning based recommender systems have gained significant attention by overcoming
    obstacles of conventional models and achieving high recommendation quality. Deep
    learning is able to effectively capture the non-linear and non-trivial user-item
    relationships, and enable the codification of more complex abstractions as data
    representations in the higher layers. Furthermore, it catches the intricate relationships
    within the data itself, from abundant accessible data sources such as contextual,
    textual and visual information.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习目前正处于极大的热潮之中。过去几十年见证了深度学习（DL）在计算机视觉和语音识别等许多应用领域取得的巨大成功。学术界和工业界一直在竞相将深度学习应用于更广泛的应用程序，因为它在解决许多复杂任务并提供最先进结果方面具有能力（Covington等，[2016](#bib.bib28)）。最近，深度学习显著革新了推荐架构，并带来了更多提升推荐性能的机会。基于深度学习的推荐系统的最新进展通过克服传统模型的障碍并实现高推荐质量而引起了重大关注。深度学习能够有效捕捉非线性和非平凡的用户-物品关系，并在更高层次的数据表示中实现更复杂的抽象编码。此外，它能够捕捉数据本身内部的复杂关系，例如来自上下文、文本和视觉信息等丰富的可访问数据源。
- en: Pervasiveness and ubiquity of deep learning in recommender systems. In industry,
    recommender systems are critical tools to enhance user experience and promote
    sales/services for many online websites and mobile applications (Gomez-Uribe and
    Hunt, [2016](#bib.bib44); Davidson et al., [2010](#bib.bib31); Covington et al.,
    [2016](#bib.bib28); Cheng et al., [2016](#bib.bib21); Okura et al., [2017](#bib.bib114)).
    For example, 80 percent of movies watched on Netflix came from recommendations (Gomez-Uribe
    and Hunt, [2016](#bib.bib44)), 60 percent of video clicks came from home page
    recommendation in YouTube (Davidson et al., [2010](#bib.bib31)). Recently, many
    companies employ deep learning for further enhancing their recommendation quality (Covington
    et al., [2016](#bib.bib28); Cheng et al., [2016](#bib.bib21); Okura et al., [2017](#bib.bib114)).
    Covington et al. (Covington et al., [2016](#bib.bib28)) presented a deep neural
    network based recommendation algorithm for video recommendation on YouTube. Cheng
    et al. (Cheng et al., [2016](#bib.bib21)) proposed an App recommender system for
    Google Play with a wide & deep model. Shumpei et al. (Okura et al., [2017](#bib.bib114))
    presented a RNN based news recommender system for Yahoo News. All of these models
    have stood the online testing and shown significant improvement over traditional
    models. Thus, we can see that deep learning has driven a remarkable revolution
    in industrial recommender applications.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在推荐系统中的普遍性和广泛性。在工业界，推荐系统是许多在线网站和移动应用程序中提升用户体验和促进销售/服务的关键工具（Gomez-Uribe 和
    Hunt, [2016](#bib.bib44); Davidson 等, [2010](#bib.bib31); Covington 等, [2016](#bib.bib28);
    Cheng 等, [2016](#bib.bib21); Okura 等, [2017](#bib.bib114)）。例如，Netflix 上观看的电影中有80%是通过推荐获得的（Gomez-Uribe
    和 Hunt, [2016](#bib.bib44)），YouTube 上的60%视频点击来源于主页推荐（Davidson 等, [2010](#bib.bib31)）。最近，许多公司采用深度学习进一步提升推荐质量（Covington
    等, [2016](#bib.bib28); Cheng 等, [2016](#bib.bib21); Okura 等, [2017](#bib.bib114)）。Covington
    等（Covington 等, [2016](#bib.bib28)）提出了一种基于深度神经网络的视频推荐算法用于 YouTube 的推荐。Cheng 等（Cheng
    等, [2016](#bib.bib21)）提出了一种基于宽度和深度模型的 Google Play 应用推荐系统。Shumpei 等（Okura 等, [2017](#bib.bib114)）提出了一种基于
    RNN 的 Yahoo 新闻推荐系统。所有这些模型都经过了在线测试，并且显示出相比传统模型有显著的改进。因此，我们可以看到深度学习在工业推荐应用中引发了一场显著的革命。
- en: The number of research publications on deep learning based recommendation methods
    has increased exponentially in these years, providing strong evidence of the inevitable
    pervasiveness of deep learning in recommender system research. The leading international
    conference on recommender system, RecSys¹¹1https://recsys.acm.org/, started to
    organize regular workshop on deep learning for recommender system²²2http://dlrs-workshop.org/
    since the year 2016\. This workshop aims to promote research and encourage applications
    of deep learning based recommender system.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 基于深度学习的推荐方法的研究出版物数量这些年来呈指数增长，这强有力地证明了深度学习在推荐系统研究中不可避免的普及。国际领先的推荐系统会议 RecSys¹¹1https://recsys.acm.org/，自2016年起开始组织关于推荐系统深度学习的定期研讨会²²2http://dlrs-workshop.org/。该研讨会旨在促进研究并鼓励基于深度学习的推荐系统的应用。
- en: The success of deep learning for recommendation both in academia and in industry
    requires a comprehensive review and summary for successive researchers and practitioners
    to better understand the strength and weakness, and application scenarios of these
    models.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在推荐系统领域的成功，无论是在学术界还是工业界，都需要对这些模型的优势、劣势和应用场景进行全面的回顾和总结，以便后续研究人员和从业者更好地理解。
- en: What are the differences between this survey and former ones? Plenty of research
    has been done in the field of deep learning based recommendation. However, to
    the best of our knowledge, there are very few systematic reviews which well shape
    this area and position existing works and current progresses. Although some works
    have explored the recommender applications built on deep learning techniques and
    have attempted to formalize this research field, few has sought to provide an
    in-depth summary of current efforts or detail the open problems present in the
    area. This survey seeks to provide such a comprehensive summary of current research
    on deep learning based recommender systems, to identify open problems currently
    limiting real-world implementations and to point out future directions along this
    dimension.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这项调查与之前的调查有什么不同？深度学习推荐领域已经进行了大量研究。然而，尽我们所知，目前很少有系统性的综述能够很好地概括该领域，定位现有工作和当前进展。虽然有些研究探索了基于深度学习技术的推荐应用，并尝试将该研究领域系统化，但很少有研究提供对当前努力的深入总结或详细描述该领域存在的开放问题。本调查旨在提供对深度学习推荐系统当前研究的全面总结，识别当前限制现实世界实施的开放问题，并指出未来的研究方向。
- en: In the last few years, a number of surveys in traditional recommender systems
    have been presented. For example, Su et al. (Su and Khoshgoftaar, [2009](#bib.bib139))
    presented a systematic review on collaborative filtering techniques; Burke et
    al. (Burke, [2002](#bib.bib9)) proposed a comprehensive survey on hybrid recommender
    system; Fernández-Tobías et al. (Fernández-Tobías et al., [2012](#bib.bib41))
    and Khan et al. (Khan et al., [2017](#bib.bib75)) reviewed the cross-domain recommendation
    models; to name a few. However, there is a lack of extensive review on deep learning
    based recommender system. To the extent of our knowledge, only two related short
    surveys (Liu and Wu, [2017](#bib.bib98); Betru et al., [2017](#bib.bib8)) are
    formally published. Betru et al. (Betru et al., [2017](#bib.bib8)) introduced
    three deep learning based recommendation models (Salakhutdinov et al., [2007](#bib.bib124);
    Wang et al., [2015b](#bib.bib160); Van den Oord et al., [2013](#bib.bib154)),
    although these three works are influential in this research area, this survey
    lost sight of other emerging high quality works. Liu et al. (Liu and Wu, [2017](#bib.bib98))
    reviewed 13 papers on deep learning for recommendation, and proposed to classify
    these models based on the form of inputs (approaches using content information
    and approaches without content information) and outputs (rating and ranking).
    However, with the constant advent of novel research works, this classification
    framework is no longer suitable and a new inclusive framework is required for
    better understanding of this research field. Given the rising popularity and potential
    of deep learning applied in recommender system, a systematic survey will be of
    high scientific and practical values. We analyzed these works from different perspectives
    and presented some new insights toward this area. To this end, over 100 studies
    were shortlisted and classified in this survey.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，传统推荐系统的调查已经呈现出一些。例如，Su等人（Su和Khoshgoftaar，[2009](#bib.bib139)）对协同过滤技术进行了系统性的综述；Burke等人（Burke，[2002](#bib.bib9)）提出了关于混合推荐系统的全面调查；Fernández-Tobías等人（Fernández-Tobías等人，[2012](#bib.bib41)）和Khan等人（Khan等人，[2017](#bib.bib75)）回顾了跨领域推荐模型，仅举几例。然而，对基于深度学习的推荐系统缺乏广泛的综述。根据我们的知识，目前仅有两篇相关的简短调查（Liu和Wu，[2017](#bib.bib98)；Betru等人，[2017](#bib.bib8)）正式发布。Betru等人（Betru等人，[2017](#bib.bib8)）介绍了三种基于深度学习的推荐模型（Salakhutdinov等人，[2007](#bib.bib124)；Wang等人，[2015b](#bib.bib160)；Van
    den Oord等人，[2013](#bib.bib154)），尽管这三项工作在该研究领域具有影响力，但该调查忽视了其他新兴的高质量工作。Liu等人（Liu和Wu，[2017](#bib.bib98)）回顾了13篇关于推荐的深度学习论文，并建议根据输入形式（使用内容信息的方法和不使用内容信息的方法）和输出（评分和排序）对这些模型进行分类。然而，随着新研究工作的不断出现，这一分类框架已不再适用，需要新的综合框架以更好地理解这一研究领域。鉴于深度学习在推荐系统中的日益普及和潜力，系统性的综述将具有很高的科学和实际价值。我们从不同的角度分析了这些工作，并提出了一些对该领域的新见解。为此，本调查精选并分类了100多项研究。
- en: 'How do we collect the papers? In this survey, we collected over a hundred of
    related papers. We used Google Scholar as the main search engine, we also adopted
    the database, Web of Science, as an important tool to discover related papers.
    In addition, we screened most of the related high-profile conferences such as
    NIPS, ICML, ICLR, KDD, WWW, SIGIR, WSDM, RecSys, etc., just to name a few, to
    find out the recent work. The major keywords we used including: recommender system,
    recommendation, deep learning, neural networks, collaborative filtering, matrix
    factorization, etc.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何收集论文？在本调查中，我们收集了超过一百篇相关论文。我们使用了Google Scholar作为主要搜索引擎，还采用了Web of Science数据库作为发现相关论文的重要工具。此外，我们筛选了大多数相关的高水平会议，如NIPS、ICML、ICLR、KDD、WWW、SIGIR、WSDM、RecSys等，仅举几例，以了解最新的工作。我们使用的主要关键词包括：推荐系统、推荐、深度学习、神经网络、协同过滤、矩阵分解等。
- en: 'Contributions of this survey. The goal of this survey is to thoroughly review
    literature on the advances of deep learning based recommender system. It provides
    a panorama with which readers can quickly understand and step into the field of
    deep learning based recommendation. This survey lays the foundations to foster
    innovations in the area of recommender system and tap into the richness of this
    research area. This survey serves the researchers, practitioners, and educators
    who are interested in recommender system, with the hope that they will have a
    rough guideline when it comes to choosing the deep neural networks to solve recommendation
    tasks at hand. To summarize, the key contributions of this survey are three-folds:
    (1) We conduct a systematic review for recommendation models based on deep learning
    techniques and propose a classification scheme to position and organize the current
    work; (2) We provide an overview and summary for the state-of-the-arts. (3) We
    discuss the challenges and open issues, and identify the new trends and future
    directions in this research field to share the vision and expand the horizons
    of deep learning based recommender system research.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查的贡献。本调查的目标是全面回顾深度学习基推荐系统的进展文献。它提供了一个全景，使读者可以快速理解并进入深度学习推荐领域。本调查奠定了促进推荐系统领域创新的基础，并挖掘了该研究领域的丰富性。本调查服务于对推荐系统感兴趣的研究人员、从业者和教育工作者，希望他们在选择解决推荐任务的深度神经网络时能有一个粗略的指导。总结起来，本调查的关键贡献有三点：（1）我们系统地回顾了基于深度学习技术的推荐模型，并提出了一个分类方案来定位和组织当前的工作；（2）我们提供了对最先进技术的概述和总结；（3）我们讨论了挑战和开放问题，并识别了这一研究领域的新趋势和未来方向，以分享愿景和拓展深度学习推荐系统研究的视野。
- en: 'The remaining of this article is organized as follows: Section 2 introduces
    the preliminaries for recommender systems and deep neural networks, we also discuss
    the advantages and disadvantages of deep neural network based recommendation models.
    Section 3 firstly presents our classification framework and then gives detailed
    introduction to the state-of-the-art. Section 4 discusses the challenges and prominent
    open research issues. Section 5 concludes the paper.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的其余部分组织如下：第2节介绍了推荐系统和深度神经网络的基础知识，我们还讨论了基于深度神经网络的推荐模型的优缺点。第3节首先介绍了我们的分类框架，然后详细介绍了最先进的技术。第4节讨论了挑战和显著的开放研究问题。第5节总结了论文。
- en: 2\. Overview of Recommender Systems and Deep Learning
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 推荐系统和深度学习概述
- en: Before we dive into the details of this survey, we start with an introduction
    to the basic terminology and concepts regarding recommender system and deep learning
    techniques. We also discuss the reasons and motivations of introducing deep neural
    networks to recommender systems.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入调查的细节之前，我们从对推荐系统和深度学习技术的基本术语和概念的介绍开始。我们还讨论了将深度神经网络引入推荐系统的原因和动机。
- en: 2.1\. Recommender Systems
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 推荐系统
- en: 'Recommender systems estimate users’ preference on items and recommend items
    that users might like to them proactively (Adomavicius and Tuzhilin, [2005](#bib.bib2);
    Ricci et al., [2015](#bib.bib122)). Recommendation models are usually classified
    into three categories (Adomavicius and Tuzhilin, [2005](#bib.bib2); Jannach et al.,
    [2010](#bib.bib70)): collaborative filtering, content based and hybrid recommender
    system. Collaborative filtering makes recommendations by learning from user-item
    historical interactions, either explicit (e.g. user’s previous ratings) or implicit
    feedback (e.g. browsing history). Content-based recommendation is based primarily
    on comparisons across items’ and users’ auxiliary information. A diverse range
    of auxiliary information such as texts, images and videos can be taken into account.
    Hybrid model refers to recommender system that integrates two or more types of
    recommendation strategies (Burke, [2002](#bib.bib9); Jannach et al., [2010](#bib.bib70)).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统估计用户对项目的偏好，并主动推荐用户可能喜欢的项目（Adomavicius和Tuzhilin，[2005](#bib.bib2)；Ricci等人，[2015](#bib.bib122)）。推荐模型通常分为三类（Adomavicius和Tuzhilin，[2005](#bib.bib2)；Jannach等人，[2010](#bib.bib70)）：协同过滤、基于内容和混合推荐系统。协同过滤通过学习用户-项目历史交互来进行推荐，既可以是显式的（如用户的以前评分），也可以是隐式反馈（如浏览历史）。基于内容的推荐主要基于项目和用户的辅助信息进行比较。可以考虑各种辅助信息，如文本、图像和视频。混合模型指的是集成了两种或更多种推荐策略的推荐系统（Burke，[2002](#bib.bib9)；Jannach等人，[2010](#bib.bib70)）。
- en: Suppose we have $M$ users and $N$ items, and $R$ denotes the interaction matrix
    and $\hat{R}$ denotes the predicted interaction matrix. Let $r_{ui}$ denote the
    preference of user $u$ to item $i$, and $\hat{r}_{ui}$ denote the predicted score.
    Meanwhile, we use a partially observed vector (rows of $R$) $\textbf{r}^{(u)}=\{r^{u1},...,r^{uN}\}$
    to represent each user $u$, and partially observed vector (columns of $R$) $\textbf{r}^{(i)}=\{r^{1i},...,r^{Mi}\}$
    to represent each item $i$. $\mathcal{O}$ and $\mathcal{O^{-}}$ denote the observed
    and unobserved interaction set. we use $U\in\mathcal{R}^{M\times k}$ and $V\in\mathcal{R}^{N\times
    k}$ to denote user and item latent factor. $k$ is the dimension of latent factors.
    In addition, sequence information such as timestamp can also be considered to
    make sequence-aware recommendations. Other notations and denotations will be introduced
    in corresponding sections.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有$M$个用户和$N$个项目，$R$表示交互矩阵，$\hat{R}$表示预测的交互矩阵。设$r_{ui}$表示用户$u$对项目$i$的偏好，$\hat{r}_{ui}$表示预测的分数。同时，我们使用部分观测向量（$R$的行）$\textbf{r}^{(u)}=\{r^{u1},...,r^{uN}\}$来表示每个用户$u$，使用部分观测向量（$R$的列）$\textbf{r}^{(i)}=\{r^{1i},...,r^{Mi}\}$来表示每个项目$i$。$\mathcal{O}$和$\mathcal{O^{-}}$分别表示观测和未观测的交互集。我们使用$U\in\mathcal{R}^{M\times
    k}$和$V\in\mathcal{R}^{N\times k}$来表示用户和项目的潜在因素。$k$是潜在因素的维度。此外，时间戳等序列信息也可以考虑，以实现序列感知推荐。其他符号和标记将在相应部分中介绍。
- en: 2.2\. Deep Learning Techniques
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 深度学习技术
- en: Deep learning can be generally considered to be sub-field of machine learning.
    The typical defining essence of deep learning is that it learns deep representations,
    i.e., learning multiple levels of representations and abstractions from data.
    For practical reasons, we consider any neural differentiable architecture as ‘deep
    learning‘ as long as it optimizes a differentiable objective function using a
    variant of stochastic gradient descent (SGD). Neural architectures have demonstrated
    tremendous success in both supervised and unsupervised learning tasks (Deng et al.,
    [2014](#bib.bib32)). In this subsection, we clarify a diverse array of architectural
    paradigms that are closely related to this survey.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习通常被认为是机器学习的一个子领域。深度学习的典型定义本质在于它学习深层表示，即从数据中学习多个层次的表示和抽象。出于实际原因，我们将任何神经可微架构视为‘深度学习’，只要它使用随机梯度下降（SGD）的一种变体来优化一个可微的目标函数。神经架构在监督学习和无监督学习任务中都取得了巨大的成功（Deng等人，[2014](#bib.bib32)）。在本小节中，我们将阐明与本调查密切相关的各种架构范式。
- en: •
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Multilayer Perceptron (MLP) is a feed-forward neural network with multiple (one
    or more) hidden layers between the input layer and output layer. Here, the perceptron
    can employ arbitrary activation function and does not necessarily represent strictly
    binary classifier. MLPs can be intrepreted as stacked layers of nonlinear transformations,
    learning hierarchical feature representations. MLPs are also known to be universal
    approximators.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多层感知机（MLP）是一种具有多个（一个或多个）隐藏层的前馈神经网络，位于输入层和输出层之间。感知机可以使用任意的激活函数，并不一定表示严格的二元分类器。MLP
    可以被解释为堆叠的非线性转换层，学习分层特征表示。MLP 也被称为通用逼近器。
- en: •
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Autoencoder (AE) is an unsupervised model attempting to reconstruct its input
    data in the output layer. In general, the bottleneck layer (the middle-most layer)
    is used as a salient feature representation of the input data. There are many
    variants of autoencoders such as denoising autoencoder, marginalized denoising
    autoencoder, sparse autoencoder, contractive autoencoder and variational autoencoder
    (VAE) (Goodfellow et al., [2016](#bib.bib46); Chen et al., [2012](#bib.bib16)).
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自编码器（AE）是一种无监督模型，试图在输出层中重构其输入数据。通常，瓶颈层（中间最深的层）被用作输入数据的显著特征表示。自编码器有许多变体，如去噪自编码器、边缘化去噪自编码器、稀疏自编码器、收缩自编码器和变分自编码器（VAE）（Goodfellow等人，[2016](#bib.bib46);
    Chen等人，[2012](#bib.bib16)）。
- en: •
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Convolutional Neural Network (CNN) (Goodfellow et al., [2016](#bib.bib46)) is
    a special kind of feedforward neural network with convolution layers and pooling
    operations. It can capture the global and local features and significantly enhancing
    the efficiency and accuracy. It performs well in processing data with grid-like
    topology.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）（Goodfellow等人，[2016](#bib.bib46)）是一种特殊的前馈神经网络，具有卷积层和池化操作。它能捕捉全局和局部特征，并显著提高效率和准确性。在处理具有网格拓扑结构的数据时表现良好。
- en: •
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Recurrent Neural Network (RNN) (Goodfellow et al., [2016](#bib.bib46)) is suitable
    for modelling sequential data. Unlike feedforward neural network, there are loops
    and memories in RNN to remember former computations. Variants such as Long Short
    Term Memory (LSTM) and Gated Recurrent Unit (GRU) network are often deployed in
    practice to overcome the vanishing gradient problem.
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 循环神经网络（RNN）（Goodfellow等人，[2016](#bib.bib46)）适用于建模序列数据。与前馈神经网络不同，RNN 中有循环和记忆以记住先前的计算。在实践中，像长短期记忆（LSTM）和门控循环单元（GRU）网络等变体经常被用来克服梯度消失问题。
- en: •
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Restricted Boltzmann Machine (RBM) is a two layer neural network consisting
    of a visible layer and a hidden layer. It can be easily stacked to a deep net.
    Restricted here means that there are no intra-layer communications in visible
    layer or hidden layer.
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 受限玻尔兹曼机（RBM）是一个两层神经网络，由可见层和隐藏层组成。它可以轻松堆叠成深度网络。这里的"受限"意味着在可见层或隐藏层内部没有层间通信。
- en: •
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Neural Autoregressive Distribution Estimation (NADE) (Larochelle and Murray,
    [2011](#bib.bib82); Uria et al., [2016](#bib.bib153)) is an unsupervised neural
    network built atop autoregressive model and feedforward neural networks. It is
    a tractable and efficient estimator for modelling data distribution and densities.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 神经自回归分布估计（NADE）（Larochelle和Murray，[2011](#bib.bib82); Uria等人，[2016](#bib.bib153)）是建立在自回归模型和前馈神经网络之上的无监督神经网络。它是一种可计算且高效的估计器，用于建模数据分布和密度。
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Adversarial Networks (AN) (Goodfellow et al., [2014](#bib.bib47)) is a generative
    neural network which consists of a discriminator and a generator. The two neural
    networks are trained simultaneously by competing with each other in a minimax
    game framework.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对抗网络（AN）（Goodfellow等人，[2014](#bib.bib47)）是一种生成神经网络，由鉴别器和生成器组成。这两个神经网络通过在极小极大博弈框架中相互竞争同时进行训练。
- en: •
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Attentional Models (AM) are differentiable neural architectures that operate
    based on soft content addressing over an input sequence (or image). Attention
    mechanism is typically ubiquitous and was incepted in Computer Vision and Natural
    Language Processing domains. However, it has also been an emerging trend in deep
    recommender system research.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力模型（AM）是可微分的神经结构，基于输入序列（或图像）进行软内容寻址。注意机制通常普遍存在于计算机视觉和自然语言处理领域，并且在深度推荐系统研究中也是一种新兴趋势。
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Deep Reinforcement Learning (DRL) (Mnih et al., [2015](#bib.bib107)). Reinforcement
    learning operates on a trial-and-error paradigm. The whole framework mainly consists
    of the following components: agents, environments, states, actions and rewards.
    The combination between deep neural networks and reinforcement learning formulate
    DRL which have achieved human-level performance across multiple domains such as
    games and self-driving cars. Deep neural networks enable the agent to get knowledge
    from raw data and derive efficient representations without handcrafted features
    and domain heuristics.'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度强化学习（DRL）（Mnih et al., [2015](#bib.bib107)）。强化学习基于试错范式。整个框架主要由以下组件组成：代理、环境、状态、动作和奖励。深度神经网络与强化学习的结合形成了DRL，这在多个领域如游戏和自动驾驶汽车中达到了人类水平的表现。深度神经网络使代理能够从原始数据中获取知识，并在不依赖手工特征和领域启发式的情况下得出有效的表示。
- en: Note that there are numerous advanced model emerging each year, here we only
    briefly listed some important ones. Readers who are interested in the details
    or more advanced models are referred to (Goodfellow et al., [2016](#bib.bib46)).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，每年都会出现大量先进模型，这里我们仅简要列出了一些重要的模型。对详细信息或更高级模型感兴趣的读者可以参考（Goodfellow et al.,
    [2016](#bib.bib46)）。
- en: 2.3\. Why Deep Neural Networks for Recommendation?
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 为什么对推荐系统使用深度神经网络？
- en: Before diving into the details of recent advances, it is beneficial to understand
    the reasons of applying deep learning techniques to recommender systems. It is
    evident that numerous deep recommender systems have been proposed in a short span
    of several years. The field is indeed bustling with innovation. At this point,
    it would be easy to question the need for so many different architectures and/or
    possibly even the utility of neural networks for the problem domain. Along the
    same tangent, it would be apt to provide a clear rationale of why each proposed
    architecture and to which scenario it would be most beneficial for. All in all,
    this question is highly relevant to the issue of task, domains and recommender
    scenarios. One of the most attractive properties of neural architectures is that
    they are (1) end-to-end differentiable and (2) provide suitable inductive biases
    catered to the input data type. As such, if there is an inherent structure that
    the model can exploit, then deep neural networks ought to be useful. For instance,
    CNNs and RNNs have long exploited the instrinsic structure in vision (and/or human
    language). Similarly, the sequential structure of session or click-logs are highly
    suitable for the inductive biases provided by recurrent/convolutional models (Tang
    and Wang, [2018a](#bib.bib144); Hidasi et al., [2015](#bib.bib57); Wu et al.,
    [2017](#bib.bib176)).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解最近的进展之前，理解将深度学习技术应用于推荐系统的原因是有益的。显然，短短几年内已经提出了大量的深度推荐系统。该领域确实充满了创新。在这一点上，很容易质疑如此多不同架构的必要性以及神经网络在该问题领域中的实用性。同样，有必要明确每个提出的架构的合理性以及它最适合的场景。总的来说，这个问题与任务、领域和推荐场景紧密相关。神经架构最吸引人的特性之一是它们（1）端到端可微分，（2）提供适合输入数据类型的适当归纳偏置。因此，如果模型可以利用固有结构，那么深度神经网络应该是有用的。例如，CNNs和RNNs长期以来利用了视觉（和/或人类语言）的内在结构。同样，session或点击日志的序列结构非常适合递归/卷积模型提供的归纳偏置（Tang和Wang，[2018a](#bib.bib144)；Hidasi
    et al., [2015](#bib.bib57)；Wu et al., [2017](#bib.bib176)）。
- en: Moreover, deep neural networks are also composite in the sense that multiple
    neural building blocks can be composed into a single (gigantic) differentiable
    function and trained end-to-end. The key advantage here is when dealing with content-based
    recommendation. This is inevitable when modeling users/items on the web, where
    multi-modal data is commonplace. For instance, when dealing with textual data
    (reviews (Zheng et al., [2017](#bib.bib203)), tweets (Gong and Zhang, [2016](#bib.bib45))
    etc.), image data (social posts, product images), CNNs/RNNs become indispensable
    neural building blocks. Here, the traditional alternative (designing modality-specific
    features etc.) becomes significantly less attractive and consequently, the recommender
    system cannot take advantage of joint (end-to-end) representation learning. In
    some sense, developments in the field of recommender systems are also tightly
    coupled with advances research in related modalities (such as vision or language
    communities). For example, to process reviews, one would have to perform costly
    preprocessing (e.g., keyphrase extraction, topic modeling etc.) whilst newer deep
    learning-based approaches are able to ingest all textual information end-to-end
    (Zheng et al., [2017](#bib.bib203)). All in all, the capabilities of deep learning
    in this aspect can be regarded as paradigm-shifting and the ability to represent
    images, text and interactions in a unified joint framework (Zhang et al., [2017](#bib.bib198))
    is not possible without these recent advances.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，深度神经网络在某种意义上也是复合的，因为多个神经构建块可以组成一个单一的（巨大的）可微函数，并进行端到端的训练。这里的关键优势在于处理基于内容的推荐。这在建模网络上的用户/项目时是不可避免的，因为多模态数据已成为常态。例如，在处理文本数据（如评论（Zheng
    et al., [2017](#bib.bib203)）、推文（Gong and Zhang, [2016](#bib.bib45)）等）、图像数据（社交帖子、产品图片）时，CNNs/RNNs
    成为不可或缺的神经构建块。在这里，传统的替代方案（如设计特定模态的特征等）显得显著不那么有吸引力，因此推荐系统无法利用联合（端到端）表示学习。在某种意义上，推荐系统领域的发展也与相关模态（如视觉或语言社区）的研究进展紧密相关。例如，为了处理评论，必须进行昂贵的预处理（如关键词提取、主题建模等），而更新的深度学习方法能够端到端地处理所有文本信息（Zheng
    et al., [2017](#bib.bib203)）。总的来说，深度学习在这一方面的能力可以被视为范式转变，而在统一的联合框架中表示图像、文本和交互的能力（Zhang
    et al., [2017](#bib.bib198)）在没有这些最新进展的情况下是不可能实现的。
- en: Pertaining to the interaction-only setting (i.e., matrix completion or collaborative
    ranking problem), the key idea here is that deep neural networks are justified
    when there is a huge amount of complexity or when there is a large number of training
    instances. In (He et al., [2017](#bib.bib54)), the authors used a MLP to approximate
    the interaction function and showed reasonable performance gains over traditional
    methods such as MF. While these neural models perform better, we also note that
    standard machine learning models such as BPR, MF and CML are known to perform
    reasonably well when trained with momentum-based gradient descent on interaction-only
    data (Tay et al., [2018a](#bib.bib146)). However, we can also consider these models
    to be also neural architectures as well, since they take advantage of recent deep
    learning advances such as Adam, Dropout or Batch Normalization (He et al., [2017](#bib.bib54);
    Zhang et al., [2018](#bib.bib196)). It is also easy to see that, traditional recommender
    algorithms (matrix factorization, factorization machines, etc.) can also be expressed
    as neural/differentiable architectures (He et al., [2017](#bib.bib54); He and
    Tat-Seng, [2017](#bib.bib55)) and trained efficiently with a framework such as
    Tensorflow or Pytorch, enabling efficient GPU-emabled training and free automatic
    differentiation. Hence, in today’s research climate (and even industrial), there
    is completely no reason to not used deep learning based tools for development
    of any recommender system.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 关于仅涉及交互的设置（即矩阵补全或协同排序问题），这里的关键想法是，当存在大量复杂性或大量训练实例时，深度神经网络是合理的选择。在（He等人，[2017](#bib.bib54)）中，作者们使用MLP来近似交互函数，并显示出相对传统方法如MF的性能提升。虽然这些神经模型表现更好，我们也注意到，标准的机器学习模型如BPR、MF和CML在仅基于交互数据进行动量梯度下降训练时也表现得相当不错（Tay等人，[2018a](#bib.bib146)）。然而，我们也可以将这些模型视为神经架构，因为它们利用了Adam、Dropout或Batch
    Normalization等最新的深度学习进展（He等人，[2017](#bib.bib54); Zhang等人，[2018](#bib.bib196)）。同时，传统的推荐算法（如矩阵分解、因子分解机等）也可以表达为神经/可微分架构（He等人，[2017](#bib.bib54);
    He和Tat-Seng，[2017](#bib.bib55)），并且可以在Tensorflow或Pytorch等框架下高效地进行GPU加速训练和自动微分。因此，在当今的研究氛围中（甚至是工业领域），没有理由不使用基于深度学习的工具来开发任何推荐系统。
- en: To recapitulate, we summarize the strengths of deep learning based recommendation
    models that readers might bear in mind when try to employ them for practice use.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们总结了基于深度学习的推荐模型的优势，读者在尝试实际应用时可能要牢记这些优点。
- en: •
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Nonlinear Transformation. Contrary to linear models, deep neural networks is
    capable of modelling the non-linearity in data with nonlinear activations such
    as relu, sigmoid, tanh, etc. This property makes it possible to capture the complex
    and intricate user item interaction patterns. Conventional methods such as matrix
    factorization, factorization machine, sparse linear model are essentially linear
    models. For example, matrix factorization models the user-item interaction by
    linearly combining user and item latent factors (He et al., [2017](#bib.bib54));
    Factorization machine is a member of multivariate linear family (He and Tat-Seng,
    [2017](#bib.bib55)); Obviously, SLIM is a linear regression model with sparsity
    constraints. The linear assumption, acting as the basis of many traditional recommenders,
    is oversimplified and will greatly limit their modelling expressiveness. It is
    well-established that neural networks are able to approximate any continuous function
    with an arbitrary precision by varying the activation choices and combinations (Hornik
    et al., [1989](#bib.bib60); Hornik, [1991](#bib.bib59)). This property makes it
    possible to deal with complex interaction patterns and precisely reflect user’s
    preference.
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 非线性变换。与线性模型相反，深度神经网络能够利用非线性激活函数（如relu、sigmoid、tanh等）对数据中的非线性进行建模。这个特性使得它能够捕捉复杂和复杂的用户物品交互模式。传统方法如矩阵分解、因子分解机、稀疏线性模型本质上是线性模型。例如，矩阵分解通过线性组合用户和物品的潜在因子来建模用户-物品交互（He等人，[2017](#bib.bib54)）；因子分解机是多元线性家族的一员（He和Tat-Seng，[2017](#bib.bib55)）；显然，SLIM是一个具有稀疏约束的线性回归模型。线性假设作为许多传统推荐系统的基础，过于简化并且会大大限制它们的建模表达能力。众所周知，神经网络可以通过变化的激活选择和组合以任意精度逼近任何连续函数（Hornik等人，[1989](#bib.bib60);
    Hornik，[1991](#bib.bib59)）。这个特性使得它能够处理复杂的交互模式，并精确反映用户的偏好。
- en: •
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Representation Learning. Deep neural networks is efficacious in learning the
    underlying explanatory factors and useful representations from input data. In
    general, a large amount of descriptive information about items and users is available
    in real-world applications. Making use of this information provides a way to advance
    our understanding of items and users, thus, resulting in a better recommender.
    As such, it is a natural choice to apply deep neural networks to representation
    learning in recommendation models. The advantages of using deep neural networks
    to assist representation learning are in two-folds: (1) it reduces the efforts
    in hand-craft feature design. Feature engineering is a labor intensive work, deep
    neural networks enable automatically feature learning from raw data in unsupervised
    or supervised approach; (2) it enables recommendation models to include heterogeneous
    content information such as text, images, audio and even video. Deep learning
    networks have made breakthroughs in multimedia data processing and shown potentials
    in representations learning from various sources.'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 表示学习。深度神经网络在从输入数据中学习潜在解释因素和有用表示方面非常有效。一般来说，现实应用中有大量关于项目和用户的描述性信息。利用这些信息提供了推进我们对项目和用户理解的途径，从而生成更好的推荐。因此，将深度神经网络应用于推荐模型中的表示学习是自然的选择。使用深度神经网络辅助表示学习的优势有两个方面：（1）它减少了手工特征设计的工作量。特征工程是一项劳动密集型工作，深度神经网络能够从原始数据中自动学习特征，无论是无监督还是有监督的方法；（2）它使推荐模型能够包括异质内容信息，如文本、图像、音频甚至视频。深度学习网络在多媒体数据处理方面取得了突破，并在从各种来源中学习表示方面展示了潜力。
- en: •
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Sequence Modelling. Deep neural networks have shown promising results on a number
    of sequential modelling tasks such as machine translation, natural language understanding,
    speech recognition, chatbots, and many others. RNN and CNN play critical roles
    in these tasks. RNN achives this with internal memory states while CNN achieves
    this with filters sliding along with time. Both of them are widely applicable
    and flexible in mining sequential structure in data. Modelling sequential signals
    is an important topic for mining the temporal dynamics of user behaviour and item
    evolution. For example, next-item/basket prediction and session based recommendation
    are typical applications. As such, deep neural networks become a perfect fit for
    this sequential pattern mining task. This
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 序列建模。深度神经网络在许多序列建模任务中表现出令人鼓舞的结果，如机器翻译、自然语言理解、语音识别、聊天机器人等。RNN 和 CNN 在这些任务中扮演了关键角色。RNN
    通过内部记忆状态来实现这一点，而 CNN 通过时间上滑动的滤波器来实现。它们都在挖掘数据中的序列结构方面具有广泛的适用性和灵活性。建模序列信号是挖掘用户行为的时间动态和项目演变的重要主题。例如，下一项/购物篮预测和基于会话的推荐是典型的应用。因此，深度神经网络非常适合这个序列模式挖掘任务。
- en: •
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Flexibility. Deep learning techniques possess high flexibility, especially with
    the advent of many popular deep learning frameworks such as Tensorflow³³3https://www.tensorflow.org/,
    Keras⁴⁴4https://keras.io/, Caffe⁵⁵5http://caffe.berkeleyvision.org/, MXnet⁶⁶6https://mxnet.apache.org/,
    DeepLearning4j⁷⁷7https://deeplearning4j.org/, PyTorch⁸⁸8https://pytorch.org/,
    Theano⁹⁹9http://deeplearning.net/software/theano/, etc. Most of these tools are
    developed in a modular way and have active community and professional support.
    The good modularization makes development and engineering a lot more efficient.
    For example, it is easy to combine different neural structures to formulate powerful
    hybrid models, or replace one module with others. Thus, we could easily build
    hybrid and composite recommendation models to simultaneously capture different
    characteristics and factors.
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 灵活性。深度学习技术具有很高的灵活性，特别是随着许多流行深度学习框架的出现，如 Tensorflow³³3https://www.tensorflow.org/、Keras⁴⁴4https://keras.io/、Caffe⁵⁵5http://caffe.berkeleyvision.org/、MXnet⁶⁶6https://mxnet.apache.org/、DeepLearning4j⁷⁷7https://deeplearning4j.org/、PyTorch⁸⁸8https://pytorch.org/、Theano⁹⁹9http://deeplearning.net/software/theano/
    等。这些工具大多以模块化方式开发，并且具有活跃的社区和专业支持。良好的模块化使得开发和工程效率大大提高。例如，可以轻松地将不同的神经结构组合以形成强大的混合模型，或用其他模块替换一个模块。因此，我们可以轻松地构建混合和复合推荐模型，以同时捕捉不同的特征和因素。
- en: 2.4\. On Potential Limitations
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4\. 关于潜在的局限性
- en: Are there really any drawbacks and limitations with using deep learning for
    recommendation? In this section, we aim to tackle several commonly cited arguments
    against the usage of deep learning for recommender systems research.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用深度学习进行推荐是否真的存在缺点和限制？在这一部分，我们旨在解决几个针对深度学习在推荐系统研究中使用的常见论点。
- en: •
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Interpretability. Despite its success, deep learning is well-known to behave
    as black boxes, and providing explainable predictions seem to be a really challenging
    task. A common argument against deep neural networks is that the hidden weights
    and activations are generally non-interpretable, limiting explainability. However,
    this concern has generally been eased with the advent of neural attention models
    and have paved the world for deep neural models that enjoy improved interpretability
    (Seo et al., [2017a](#bib.bib127); Xiao et al., [2017](#bib.bib179); Tay et al.,
    [2018b](#bib.bib147)). While interpreting individual neurons still pose a challenge
    for neural models (not only in recommender systems), present state-of-the-art
    models are already capable of some extent of interpretability, enabling explainable
    recommendation. We discuss this issue in more detail in the open issues section.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可解释性。尽管取得了成功，深度学习仍然被认为是黑箱，提供可解释的预测似乎是一项非常具有挑战性的任务。一个反对深度神经网络的常见论点是隐藏的权重和激活通常是不可解释的，限制了可解释性。然而，随着神经注意力模型的出现，这一担忧通常得到了缓解，并为具有更好可解释性的深度神经模型铺平了道路（Seo
    等，[2017a](#bib.bib127)；Xiao 等，[2017](#bib.bib179)；Tay 等，[2018b](#bib.bib147)）。虽然解释单个神经元仍然对神经模型（不仅仅是推荐系统）构成挑战，但目前的最先进模型已经具备了一定程度的可解释性，能够实现可解释的推荐。我们将在开放问题部分更详细地讨论这一问题。
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Data Requirement. A second possible limitation is that deep learning is known
    to be data-hungry, in the sense that it requires sufficient data in order to fully
    support its rich parameterization. However, as compared with other domains (such
    as language or vision) in which labeled data is scarce, it is relatively easy
    to garner a significant amount of data within the context of recommender systems
    research. Million/billion scale datasets are commonplace not only in industry
    but also released as academic datasets.
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据需求。第二个可能的限制是深度学习被认为是数据密集型的，即它需要足够的数据以充分支持其丰富的参数化。然而，与其他数据稀缺的领域（如语言或视觉）相比，在推荐系统研究的背景下相对容易获取大量数据。百万/十亿规模的数据集在行业中司空见惯，同时也被作为学术数据集发布。
- en: •
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Extensive Hyperparameter Tuning. A third well-established argument against deep
    learning is the need for extensive hyperparameter tuning. However, we note that
    hyperparameter tuning is not an exclusive problem of deep learning but machine
    learning in general (e.g., regularization factors and learning rate similarly
    have to be tuned for traditional matrix factorization etc) Granted, deep learning
    may introduce additional hyperparameters in some cases. For example, a recent
    work (Tay et al., [2018a](#bib.bib146)), attentive extension of the traditional
    metric learning algorithm (Hsieh et al., [2017](#bib.bib61)) only introduces a
    single hyperparameter.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大规模的超参数调优。一个反对深度学习的第三个普遍论点是需要大量的超参数调优。然而，我们注意到超参数调优并不是深度学习独有的问题，而是机器学习的普遍问题（例如，传统矩阵分解等同样需要调整正则化因子和学习率）。诚然，深度学习在某些情况下可能会引入额外的超参数。例如，一项最近的研究（Tay
    等，[2018a](#bib.bib146)）对传统度量学习算法（Hsieh 等，[2017](#bib.bib61)）进行了有关注扩展，仅引入了一个超参数。
- en: '3\. Deep Learning Based Recommendation: State-of-the-art'
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 基于深度学习的推荐：最先进技术
- en: In this section, we we firstly introduce the categories of deep learning based
    recommendation models and then highlight state-of-the-art research prototypes,
    aiming to identify the most notable and promising advancement in recent years.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们首先介绍基于深度学习的推荐模型的类别，然后重点介绍最先进的研究原型，旨在识别近年来最显著和最有前景的进展。
- en: 3.1\. Categories of deep learning based recommendation models
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 基于深度学习的推荐模型类别
- en: '![Refer to caption](img/5da35c108b978175aebbf6a95cb1a7d5.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5da35c108b978175aebbf6a95cb1a7d5.png)'
- en: Figure 1\. Categories of deep neural network based recommendation models.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1\. 基于深度神经网络的推荐模型类别。
- en: 'To provide a bird-eye’s view of this field, we classify the existing models
    based the types of employed deep learning techniques. We further divide deep learning
    based recommendation models into the following two categories. Figure [1](#S3.F1
    "Figure 1 ‣ 3.1\. Categories of deep learning based recommendation models ‣ 3\.
    Deep Learning Based Recommendation: State-of-the-art ‣ Deep Learning based Recommender
    System: A Survey and New Perspectives") summarizes the classification scheme.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '为了提供该领域的鸟瞰视角，我们根据采用的深度学习技术类型对现有模型进行分类。我们进一步将基于深度学习的推荐模型分为以下两类。图表 [1](#S3.F1
    "Figure 1 ‣ 3.1\. Categories of deep learning based recommendation models ‣ 3\.
    Deep Learning Based Recommendation: State-of-the-art ‣ Deep Learning based Recommender
    System: A Survey and New Perspectives") 总结了分类方案。'
- en: Table 1\. A lookup table for reviewed publications.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 1\. 已审查出版物的查找表。
- en: '| Categories | Publications |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 出版物 |'
- en: '| --- | --- |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| MLP |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 多层感知器（MLP） |'
- en: '&#124; (Huang et al., [2015](#bib.bib67); Yang et al., [2017](#bib.bib186);
    Alashkar et al., [2017](#bib.bib3); Vuurens et al., [2016](#bib.bib158); Wang
    et al., [2017](#bib.bib167); He et al., [2017](#bib.bib54); Chen et al., [2017](#bib.bib14);
    Ebesu and Fang, [2017](#bib.bib39); Cheng et al., [2016](#bib.bib21); Lian et al.,
    [2017](#bib.bib93); Covington et al., [2016](#bib.bib28); Guo et al., [2017](#bib.bib48);
    Liang et al., [2015](#bib.bib96); He and Tat-Seng, [2017](#bib.bib55)), &#124;'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (黄等人，[2015](#bib.bib67); 杨等人，[2017](#bib.bib186); 阿拉什卡尔等人，[2017](#bib.bib3);
    维伦斯等人，[2016](#bib.bib158); 王等人，[2017](#bib.bib167); 何等人，[2017](#bib.bib54); 陈等人，[2017](#bib.bib14);
    埃贝苏和方，[2017](#bib.bib39); 程等人，[2016](#bib.bib21); 连等人，[2017](#bib.bib93); 科温顿等人，[2016](#bib.bib28);
    郭等人，[2017](#bib.bib48); 梁等人，[2015](#bib.bib96); 何和塔特-森，[2017](#bib.bib55)), &#124;'
- en: '&#124; (Elkahky et al., [2015](#bib.bib40); Song et al., [2018](#bib.bib135);
    Chen et al., [2017](#bib.bib13); Xu et al., [2016](#bib.bib183), [2017](#bib.bib184);
    Niu et al., [2018](#bib.bib113); Lian et al., [2018](#bib.bib94); Vartak et al.,
    [2017](#bib.bib155)) &#124;'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (埃尔卡赫等人，[2015](#bib.bib40); 宋等人，[2018](#bib.bib135); 陈等人，[2017](#bib.bib13);
    许等人，[2016](#bib.bib183), [2017](#bib.bib184); 牛等人，[2018](#bib.bib113); 连等人，[2018](#bib.bib94);
    瓦尔塔克等人，[2017](#bib.bib155)) &#124;'
- en: '|'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Autoencoder |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 自编码器（Autoencoder） |'
- en: '&#124; (Ouyang et al., [2014](#bib.bib115); Sedhain et al., [2015](#bib.bib126);
    Strub and Mary, [2015](#bib.bib138); Wu et al., [2016a](#bib.bib178); Strub et al.,
    [2016](#bib.bib137); Yi et al., [2016](#bib.bib188); Zhuang et al., [2017a](#bib.bib208);
    Suzuki and Ozaki, [2017](#bib.bib141); Pana et al., [2017](#bib.bib117); Wang
    et al., [2015b](#bib.bib160); Li and She, [2017](#bib.bib90); Li et al., [2015](#bib.bib89);
    Dong et al., [2017](#bib.bib35)), &#124;'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (欧阳等人，[2014](#bib.bib115); 谢代海等人，[2015](#bib.bib126); 斯特鲁布和玛丽，[2015](#bib.bib138);
    吴等人，[2016a](#bib.bib178); 斯特鲁布等人，[2016](#bib.bib137); 易等人，[2016](#bib.bib188);
    庄等人，[2017a](#bib.bib208); 铃木和尾崎，[2017](#bib.bib141); 帕纳等人，[2017](#bib.bib117);
    王等人，[2015b](#bib.bib160); 李和佘，[2017](#bib.bib90); 李等人，[2015](#bib.bib89); 董等人，[2017](#bib.bib35)),
    &#124;'
- en: '&#124; (Zhuang et al., [2017b](#bib.bib209); Wang et al., [2015a](#bib.bib159);
    Bai et al., [2017](#bib.bib5); Ying et al., [2016](#bib.bib189); Zhang et al.,
    [2017](#bib.bib197); Wei et al., [2016](#bib.bib171), [2017](#bib.bib172); Unger,
    [2015](#bib.bib151); Cao et al., [2017](#bib.bib11); Zuo et al., [2016](#bib.bib210);
    Unger et al., [2016](#bib.bib152); Deng et al., [2017](#bib.bib33); Liang et al.,
    [2018](#bib.bib95)) &#124;'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (庄等人，[2017b](#bib.bib209); 王等人，[2015a](#bib.bib159); 白等人，[2017](#bib.bib5);
    英等人，[2016](#bib.bib189); 张等人，[2017](#bib.bib197); 魏等人，[2016](#bib.bib171), [2017](#bib.bib172);
    乌格尔，[2015](#bib.bib151); 曹等人，[2017](#bib.bib11); 左等人，[2016](#bib.bib210); 乌格尔等人，[2016](#bib.bib152);
    邓等人，[2017](#bib.bib33); 梁等人，[2018](#bib.bib95)) &#124;'
- en: '|'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| CNNs |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 卷积神经网络（CNNs） |'
- en: '&#124; (Kim et al., [2016](#bib.bib76), [2017](#bib.bib77); Zheng et al., [2017](#bib.bib203);
    Van den Oord et al., [2013](#bib.bib154); Seo et al., [2017b](#bib.bib128); Liu
    et al., [2017](#bib.bib99); Chu and Tsai, [2017](#bib.bib26); Shen et al., [2016](#bib.bib131);
    Zhou et al., [2016](#bib.bib207); McAuley et al., [2015](#bib.bib106); He and
    McAuley, [2016a](#bib.bib50), [b](#bib.bib51); Wen et al., [2016](#bib.bib173);
    Wang et al., [2017](#bib.bib166)), &#124;'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (金等人，[2016](#bib.bib76), [2017](#bib.bib77); 郑等人，[2017](#bib.bib203);
    范登·奥尔德等人，[2013](#bib.bib154); SEO等人，[2017b](#bib.bib128); 刘等人，[2017](#bib.bib99);
    朱和蔡，[2017](#bib.bib26); 沈等人，[2016](#bib.bib131); 周等人，[2016](#bib.bib207); 麦考利等人，[2015](#bib.bib106);
    何和麦考利，[2016a](#bib.bib50), [b](#bib.bib51); 温等人，[2016](#bib.bib173); 王等人，[2017](#bib.bib166)),
    &#124;'
- en: '&#124; (Gong and Zhang, [2016](#bib.bib45); Nguyen et al., [2017](#bib.bib111);
    Wang et al., [2017a](#bib.bib170); Yu et al., [2018](#bib.bib192); He et al.,
    [2018a](#bib.bib52); Tang and Wang, [2018a](#bib.bib144); Tuan and Phuong, [2017](#bib.bib149);
    Ying et al., [2018a](#bib.bib191); Berg et al., [2017](#bib.bib7); Lee et al.,
    [2018](#bib.bib84); Seo et al., [2017a](#bib.bib127)) &#124;'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (Gong和Zhang，[2016](#bib.bib45)；阮等，[2017](#bib.bib111)；王等，[2017a](#bib.bib170)；于等，[2018](#bib.bib192)；何等，[2018a](#bib.bib52)；Tang和Wang，[2018a](#bib.bib144)；Tuan和Phuong，[2017](#bib.bib149)；Ying等，[2018a](#bib.bib191)；Berg等，[2017](#bib.bib7)；李等，[2018](#bib.bib84)；Seo等，[2017a](#bib.bib127))
    &#124;'
- en: '|'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| RNNs |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| RNNs |'
- en: '&#124; (Bansal et al., [2016](#bib.bib6); Ko et al., [2016](#bib.bib79); Smirnova
    and Vasile, [2017](#bib.bib133); Dai et al., [2016a](#bib.bib29); Li et al., [2016](#bib.bib91);
    Tan et al., [2016b](#bib.bib143); Wu et al., [2016](#bib.bib175); Jing and Smola,
    [2017](#bib.bib74); Hidasi et al., [2016](#bib.bib58); Wu et al., [2016b](#bib.bib177),
    [2017](#bib.bib176); Hidasi et al., [2015](#bib.bib57); Suglia et al., [2017](#bib.bib140);
    Quadrana et al., [2017](#bib.bib118); Donkers et al., [2017](#bib.bib36)), &#124;'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (Bansal等，[2016](#bib.bib6)；Ko等，[2016](#bib.bib79)；Smirnova和Vasile，[2017](#bib.bib133)；戴等，[2016a](#bib.bib29)；李等，[2016](#bib.bib91)；Tan等，[2016b](#bib.bib143)；吴等，[2016](#bib.bib175)；Jing和Smola，[2017](#bib.bib74)；Hidasi等，[2016](#bib.bib58)；吴等，[2016b](#bib.bib177)，[2017](#bib.bib176)；Hidasi等，[2015](#bib.bib57)；Suglia等，[2017](#bib.bib140)；Quadrana等，[2017](#bib.bib118)；Donkers等，[2017](#bib.bib36))
    &#124;'
- en: '&#124; (Tan et al., [2016a](#bib.bib142); Musto et al., [2016](#bib.bib109);
    Xie et al., [2016a](#bib.bib180); Wu et al., [2016c](#bib.bib174); Devooght and
    Bersini, [2016](#bib.bib34); Soh et al., [2017](#bib.bib134); Dai et al., [2016b](#bib.bib30);
    Twardowski, [2016](#bib.bib150); Okura et al., [2017](#bib.bib114); Hidasi and
    Karatzoglou, [2017](#bib.bib56); Jannach and Ludewig, [2017](#bib.bib69); Li et al.,
    [2018](#bib.bib92); Christakopoulou et al., [2018](#bib.bib25)) &#124;'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (Tan等，[2016a](#bib.bib142)；Musto等，[2016](#bib.bib109)；谢等，[2016a](#bib.bib180)；吴等，[2016c](#bib.bib174)；Devooght和Bersini，[2016](#bib.bib34)；Soh等，[2017](#bib.bib134)；戴等，[2016b](#bib.bib30)；Twardowski，[2016](#bib.bib150)；Okura等，[2017](#bib.bib114)；Hidasi和Karatzoglou，[2017](#bib.bib56)；Jannach和Ludewig，[2017](#bib.bib69)；李等，[2018](#bib.bib92)；Christakopoulou等，[2018](#bib.bib25))
    &#124;'
- en: '|'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| RBM |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| RBM |'
- en: '&#124; (Salakhutdinov et al., [2007](#bib.bib124); Georgiev and Nakov, [2013](#bib.bib43);
    Liu et al., [2015](#bib.bib101); Xie et al., [2016b](#bib.bib181); Jia et al.,
    [2016](#bib.bib72); Wang and Wang, [2014](#bib.bib168); Jia et al., [2015](#bib.bib73))
    &#124;'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (Salakhutdinov等，[2007](#bib.bib124)；Georgiev和Nakov，[2013](#bib.bib43)；刘等，[2015](#bib.bib101)；谢等，[2016b](#bib.bib181)；贾等，[2016](#bib.bib72)；王和王，[2014](#bib.bib168)；贾等，[2015](#bib.bib73))
    &#124;'
- en: '|'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| NADE | (Zheng et al., [2016](#bib.bib205), [2016](#bib.bib204); Du et al.,
    [2016](#bib.bib37)) |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| NADE | (郑等，[2016](#bib.bib205)，[2016](#bib.bib204)；杜等，[2016](#bib.bib37))
    |'
- en: '| Neural Attention |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 神经注意力 |'
- en: '&#124; (Chen et al., [2017b](#bib.bib15); Tay et al., [2018a](#bib.bib146);
    Jhamb et al., [2018](#bib.bib71); Gong and Zhang, [2016](#bib.bib45); Seo et al.,
    [2017b](#bib.bib128); Wang et al., [2017a](#bib.bib170); Li et al., [2016](#bib.bib91);
    Loyola et al., [2017a](#bib.bib102); Liu et al., [2018](#bib.bib100); Ying et al.,
    [2018b](#bib.bib190); Zhou et al., [2017](#bib.bib206); Zhang et al., [2018](#bib.bib195)),
    &#124;'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (陈等，[2017b](#bib.bib15)；Tay等，[2018a](#bib.bib146)；Jhamb等，[2018](#bib.bib71)；Gong和Zhang，[2016](#bib.bib45)；Seo等，[2017b](#bib.bib128)；王等，[2017a](#bib.bib170)；李等，[2016](#bib.bib91)；Loyola等，[2017a](#bib.bib102)；刘等，[2018](#bib.bib100)；Ying等，[2018b](#bib.bib190)；周等，[2017](#bib.bib206)；张等，[2018](#bib.bib195))
    &#124;'
- en: '&#124; (Tay et al., [2018b](#bib.bib147); [Zhang et al.,](#bib.bib194) ; Hu
    et al., [2018](#bib.bib63)) &#124;'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (Tay等，[2018b](#bib.bib147)；[张等，](#bib.bib194)；胡等，[2018](#bib.bib63))
    &#124;'
- en: '|'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Adversary Network | (Wang et al., [2017b](#bib.bib163); He et al., [2018b](#bib.bib53);
    Cai et al., [2018](#bib.bib10); Wang et al., [2018](#bib.bib165)) |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 对抗网络 | (王等，[2017b](#bib.bib163)；何等，[2018b](#bib.bib53)；蔡等，[2018](#bib.bib10)；王等，[2018](#bib.bib165))
    |'
- en: '| DRL | (Zhao et al., [2018a](#bib.bib199), [b](#bib.bib200); Zheng et al.,
    [2018](#bib.bib201); Munemasa et al., [2018](#bib.bib108); Choi et al., [2018](#bib.bib22);
    Wang et al., [2014](#bib.bib169); Chen et al., [2018](#bib.bib17)) |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| DRL | (赵等，[2018a](#bib.bib199)，[b](#bib.bib200)；郑等，[2018](#bib.bib201)；宗政等，[2018](#bib.bib108)；崔等，[2018](#bib.bib22)；王等，[2014](#bib.bib169)；陈等，[2018](#bib.bib17))
    |'
- en: '| Hybrid Models |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 混合模型 |'
- en: '&#124; (Lei et al., [2016](#bib.bib85); Rawat and Kankanhalli, [2016](#bib.bib119);
    [Zhang et al.,](#bib.bib194) ; Song et al., [2016](#bib.bib136); Zhang et al.,
    [2016](#bib.bib193); Ebesu and Fang, [2017](#bib.bib39); Li et al., [2017](#bib.bib88);
    Lee et al., [2016](#bib.bib83); Gao et al., [2014](#bib.bib42); Wang et al., [2016](#bib.bib161);
    Chen et al., [2017a](#bib.bib18)) &#124;'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (雷等人，[2016](#bib.bib85); Rawat和Kankanhalli，[2016](#bib.bib119); [张等人，](#bib.bib194)
    ; 宋等人，[2016](#bib.bib136); 张等人，[2016](#bib.bib193); Ebesu和Fang，[2017](#bib.bib39);
    李等人，[2017](#bib.bib88); 李等人，[2017](#bib.bib83); 高等人，[2014](#bib.bib42); 王等人，[2016](#bib.bib161);
    陈等人，[2017a](#bib.bib18)) &#124;'
- en: '|'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: •
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Recommendation with Neural Building Blocks. In this category, models are divided
    into eight subcategories in conformity with the aforementioned eight deep learning
    models: MLP, AE, CNNs, RNNs, RBM, NADE, AM, AN and DRL based recommender system.
    The deep learning technique in use determines the applicability of recommendation
    model. For instance, MLP can easily model the non-linear interactions between
    users and items; CNNs are capable of extracting local and global representations
    from heterogeneous data sources such as textual and visual information; RNNs enable
    the recommender system to model the temporal dynamics and sequential evolution
    of content information.'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 采用神经网络构建推荐的方式。在这一类别中，模型根据前述的八种深度学习模型被分成八个子类别：MLP、AE、CNN、RNN、RBM、NADE、AM、AN和基于DRL的推荐系统。所采用的深度学习技术决定了推荐模型的适用性。例如，MLP能轻松建模用户和物品之间的非线性交互；CNN能从文本和视觉等异构数据源中提取局部和全局表示；RNN使得推荐系统能够建模内容信息的时间动态和顺序演变。
- en: •
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Recommendation with Deep Hybrid Models. Some deep learning based recommendation
    models utilize more than one deep learning technique. The flexibility of deep
    neural networks makes it possible to combine several neural building blocks together
    to complement one another and form a more powerful hybrid model. There are many
    possible combinations of these night deep learning techniques but not all have
    been exploited. Note that it is different from the hybrid deep networks in (Deng
    et al., [2014](#bib.bib32)) which refer to the deep architectures that make use
    of both generative and discriminative components.
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 采用深度混合模型的推荐。一些基于深度学习的推荐模型利用了多种深度学习技术。深度神经网络的灵活性使得能够将多个神经网络模块结合起来互补，形成更强大的混合模型。这些深度学习技术的组合方式有很多种，但并非所有都已被利用。请注意，这与（邓等人，[2014](#bib.bib32)）中提到的混合深度网络不同，后者指的是利用了生成和判别组件的深度结构。
- en: Table 2\. Deep neural network based recommendation models in specific application
    fields.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 表2\. 特定应用领域中基于深度神经网络的推荐模型。
- en: '|'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Data &#124;'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 数据 &#124;'
- en: '&#124; Sources/Tasks &#124;'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 来源/任务 &#124;'
- en: '| Notes | Publications |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 注释 | 出版物 |'
- en: '| Sequential Information | w/t User ID | (Zhang et al., [2018](#bib.bib195);
    Quadrana et al., [2017](#bib.bib118); Jing and Smola, [2017](#bib.bib74); Tang
    and Wang, [2018a](#bib.bib144); Ying et al., [2018b](#bib.bib190); Donkers et al.,
    [2017](#bib.bib36); Soh et al., [2017](#bib.bib134); Wu et al., [2016c](#bib.bib174),
    [2017](#bib.bib176); Devooght and Bersini, [2016](#bib.bib34); Dai et al., [2016b](#bib.bib30);
    Li et al., [2018](#bib.bib92); Zhou et al., [2017](#bib.bib206); Zhao et al.,
    [2018a](#bib.bib199); Chen et al., [2018](#bib.bib17); Wang et al., [2016](#bib.bib161))
    |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 顺序信息 | 无用户ID | (张等人，[2018](#bib.bib195); Quadrana等人，[2017](#bib.bib118);
    Jing和Smola，[2017](#bib.bib74); 唐和王，[2018a](#bib.bib144); Ying等人，[2018b](#bib.bib190);
    Donkers等人，[2017](#bib.bib36); Soh等人，[2017](#bib.bib134); 吴等人，[2016c](#bib.bib174),
    [2017](#bib.bib176); Devooght和Bersini，[2016](#bib.bib34); 戴等人，[2016b](#bib.bib30);
    李等人，[2018](#bib.bib92); 周等人，[2017](#bib.bib206); 赵等人，[2018a](#bib.bib199); 陈等人，[2018](#bib.bib17);
    王等人，[2016](#bib.bib161)) |'
- en: '|'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Session based &#124;'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于会话 &#124;'
- en: '&#124; w/o User ID &#124;'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 无用户ID &#124;'
- en: '| (Hidasi et al., [2015](#bib.bib57); Tan et al., [2016b](#bib.bib143); Twardowski,
    [2016](#bib.bib150); Hidasi et al., [2016](#bib.bib58); Jing and Smola, [2017](#bib.bib74);
    Hidasi and Karatzoglou, [2017](#bib.bib56); Quadrana et al., [2017](#bib.bib118);
    Loyola et al., [2017b](#bib.bib103), [a](#bib.bib102); Liu et al., [2018](#bib.bib100);
    Jannach and Ludewig, [2017](#bib.bib69); Tuan and Phuong, [2017](#bib.bib149))
    |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| (Hidasi等人，[2015](#bib.bib57); 谭等人，[2016b](#bib.bib143); Twardowski，[2016](#bib.bib150);
    Hidasi等人，[2016](#bib.bib58); Jing和Smola，[2017](#bib.bib74); Hidasi和Karatzoglou，[2017](#bib.bib56);
    Quadrana等人，[2017](#bib.bib118); Loyola等人，[2017b](#bib.bib103), [a](#bib.bib102);
    刘等人，[2018](#bib.bib100); Jannach和Ludewig，[2017](#bib.bib69); Tuan和Phuong，[2017](#bib.bib149))
    |'
- en: '| Check-In, POI | (Yang et al., [2017](#bib.bib186); Wang et al., [2017](#bib.bib166);
    Unger, [2015](#bib.bib151); Unger et al., [2016](#bib.bib152)) |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| Check-In, POI | (Yang等人，[2017](https://bib.bib186); Wang等人，[2017](https://bib.bib166);
    Unger，[2015](https://bib.bib151); Unger等人，[2016](https://bib.bib152)) |'
- en: '| Text | Hash Tags | ([Zhang et al.,](#bib.bib194) ; Rawat and Kankanhalli,
    [2016](#bib.bib119); Gong and Zhang, [2016](#bib.bib45); Wang et al., [2015a](#bib.bib159);
    Xu et al., [2017](#bib.bib184), [2016](#bib.bib183); Zuo et al., [2016](#bib.bib210);
    Nguyen et al., [2017](#bib.bib111)) |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 哈希标签 | ([Zhang等人](https://bib.bib194) ; Rawat和Kankanhalli，[2016](https://bib.bib119);
    Gong和Zhang，[2016](https://bib.bib45); Wang等人，[2015a](https://bib.bib159); Xu等人，[2017](https://bib.bib184),
    [2016](https://bib.bib183); Zuo等人，[2016](https://bib.bib210); Nguyen等人，[2017](https://bib.bib111))
    |'
- en: '| News | (Chen et al., [2017](#bib.bib13); Wang et al., [2017a](#bib.bib170);
    Okura et al., [2017](#bib.bib114); Song et al., [2016](#bib.bib136); Zheng et al.,
    [2018](#bib.bib201); Cao et al., [2017](#bib.bib11)) |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 新闻 | (Chen等人，[2017](https://bib.bib13); Wang等人，[2017a](https://bib.bib170);
    Okura等人，[2017](https://bib.bib114); Song等人，[2016](https://bib.bib136); Zheng等人，[2018](https://bib.bib201);
    Cao等人，[2017](https://bib.bib11)) |'
- en: '| Review texts | (Zheng et al., [2017](#bib.bib203); Catherine and Cohen, [2017](#bib.bib12);
    Tay et al., [2018b](#bib.bib147); Zhang et al., [2017](#bib.bib198); Li et al.,
    [2017](#bib.bib88); Wu et al., [2016](#bib.bib175); Seo et al., [2017a](#bib.bib127))
    |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 评论文本 | (Zheng等人，[2017](https://bib.bib203); Catherine和Cohen，[2017](https://bib.bib12);
    Tay等人，[2018b](https://bib.bib147); Zhang等人，[2017](https://bib.bib198); Li等人，[2017](https://bib.bib88);
    Wu等人，[2016](https://bib.bib175); Seo等人，[2017a](https://bib.bib127)) |'
- en: '| Quotes | (Lee et al., [2016](#bib.bib83); Tan et al., [2016a](#bib.bib142))
    |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 引用 | (Lee等人，[2016](https://bib.bib83); Tan等人，[2016a](https://bib.bib142))
    |'
- en: '| Images | Visual features | (Zhang et al., [2017](#bib.bib198); Lei et al.,
    [2016](#bib.bib85); Wen et al., [2016](#bib.bib173); Xie et al., [2016a](#bib.bib180);
    Yu et al., [2018](#bib.bib192); Niu et al., [2018](#bib.bib113); Wang et al.,
    [2017](#bib.bib166); McAuley et al., [2015](#bib.bib106); He and McAuley, [2016a](#bib.bib50);
    Alashkar et al., [2017](#bib.bib3); Liu et al., [2017](#bib.bib99); Chu and Tsai,
    [2017](#bib.bib26); Zhou et al., [2016](#bib.bib207); He and McAuley, [2016b](#bib.bib51);
    Chen et al., [2017b](#bib.bib15); Zhang et al., [2016](#bib.bib193)) |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 图像 | 视觉特征 | (Zhang等人，[2017](https://bib.bib198); Lei等人，[2016](https://bib.bib85);
    Wen等人，[2016](https://bib.bib173); Xie等人，[2016a](https://bib.bib180); Yu等人，[2018](https://bib.bib192);
    Niu等人，[2018](https://bib.bib113); Wang等人，[2017](https://bib.bib166); McAuley等人，[2015](https://bib.bib106);
    He和McAuley，[2016a](https://bib.bib50); Alashkar等人，[2017](https://bib.bib3); Liu等人，[2017](https://bib.bib99);
    Chu和Tsai，[2017](https://bib.bib26); Zhou等人，[2016](https://bib.bib207); He和McAuley，[2016b](https://bib.bib51);
    Chen等人，[2017b](https://bib.bib15); Zhang等人，[2016](https://bib.bib193)) |'
- en: '| Audio | Music | (Van den Oord et al., [2013](#bib.bib154); Liang et al.,
    [2015](#bib.bib96); Wang and Wang, [2014](#bib.bib168); Wang et al., [2014](#bib.bib169))
    |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 音频 | 音乐 | (Van den Oord等人，[2013](https://bib.bib154); Liang等人，[2015](https://bib.bib96);
    Wang和Wang，[2014](https://bib.bib168); Wang等人，[2014](https://bib.bib169)) |'
- en: '| Video | Videos | (Chen et al., [2017a](#bib.bib18); Lee et al., [2018](#bib.bib84);
    Covington et al., [2016](#bib.bib28); Chen et al., [2017b](#bib.bib15)) |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 视频 | 视频 | (Chen等人，[2017a](https://bib.bib18); Lee等人，[2018](https://bib.bib84);
    Covington等人，[2016](https://bib.bib28); Chen等人，[2017b](https://bib.bib15)) |'
- en: '| Networks | Citation Network | (Ebesu and Fang, [2017](#bib.bib39); Huang
    et al., [2015](#bib.bib67); Cai et al., [2018](#bib.bib10)) |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 网络 | 引用网络 | (Ebesu和Fang，[2017](https://bib.bib39); Huang等人，[2015](https://bib.bib67);
    Cai等人，[2018](https://bib.bib10)) |'
- en: '| Social Network | (Wang et al., [2017](#bib.bib167); Deng et al., [2017](#bib.bib33);
    Pana et al., [2017](#bib.bib117)) |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 社交网络 | (Wang等人，[2017](https://bib.bib167); Deng等人，[2017](https://bib.bib33);
    Pana等人，[2017](https://bib.bib117)) |'
- en: '| Cross Domain | (Lian et al., [2017](#bib.bib93); Elkahky et al., [2015](#bib.bib40);
    Wang et al., [2017](#bib.bib167)) |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 跨域 | (Lian等人，[2017](https://bib.bib93); Elkahky等人，[2015](https://bib.bib40);
    Wang等人，[2017](https://bib.bib167)) |'
- en: '| Others | Cold-start | (Vartak et al., [2017](#bib.bib155); Volkovs et al.,
    [2017](#bib.bib157); Wei et al., [2016](#bib.bib171), [2017](#bib.bib172)) |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 其他 | 冷启动 | (Vartak等人，[2017](https://bib.bib155); Volkovs等人，[2017](https://bib.bib157);
    Wei等人，[2016](https://bib.bib171), [2017](https://bib.bib172)) |'
- en: '| Multitask | (Bansal et al., [2016](#bib.bib6); Li et al., [2017](#bib.bib88);
    Jing and Smola, [2017](#bib.bib74); Wu et al., [2016](#bib.bib175); Yi et al.,
    [2016](#bib.bib188)) |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 多任务 | (Bansal等人，[2016](https://bib.bib6); Li等人，[2017](https://bib.bib88);
    Jing和Smola，[2017](https://bib.bib74); Wu等人，[2016](https://bib.bib175); Yi等人，[2016](https://bib.bib188))
    |'
- en: '| Explainability | (Li et al., [2017](#bib.bib88); Seo et al., [2017a](#bib.bib127))
    |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 可解释性 | (Li等人，[2017](https://bib.bib88); Seo等人，[2017a](https://bib.bib127))
    |'
- en: 'Table [1](#S3.T1 "Table 1 ‣ 3.1\. Categories of deep learning based recommendation
    models ‣ 3\. Deep Learning Based Recommendation: State-of-the-art ‣ Deep Learning
    based Recommender System: A Survey and New Perspectives") lists all the reviewed
    models, we organize them following the aforementioned classification scheme. Additionally,
    we also summarize some of the publications from the task perspective in Table
    [2](#S3.T2 "Table 2 ‣ 3.1\. Categories of deep learning based recommendation models
    ‣ 3\. Deep Learning Based Recommendation: State-of-the-art ‣ Deep Learning based
    Recommender System: A Survey and New Perspectives"). The reviewed publications
    are concerned with a variety of tasks. Some of the tasks have started to gain
    attention due to use of deep neural networks such as session-based recommendation,
    image, video recommendations. Some of the tasks might not be novel to the recommendation
    research area (a detail review on the side information for recommender systems
    can be found in (Shi et al., [2014](#bib.bib132)) ), but DL provides more possibility
    to find better solutions. For example, dealing with images and videos would be
    tough task without the help of deep learning techniques. The sequence modelling
    capability of deep neural networks makes it easy to capture the sequential patterns
    of user behaviors. Some of the specific tasks will be discussed in the following
    text.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [1](#S3.T1 "Table 1 ‣ 3.1\. Categories of deep learning based recommendation
    models ‣ 3\. Deep Learning Based Recommendation: State-of-the-art ‣ Deep Learning
    based Recommender System: A Survey and New Perspectives") 列出了所有审查过的模型，我们按照前述的分类方案对它们进行了整理。此外，我们还总结了一些从任务角度出发的出版物，见表
    [2](#S3.T2 "Table 2 ‣ 3.1\. Categories of deep learning based recommendation models
    ‣ 3\. Deep Learning Based Recommendation: State-of-the-art ‣ Deep Learning based
    Recommender System: A Survey and New Perspectives")。审查过的出版物涉及多种任务。一些任务由于使用了深度神经网络而开始受到关注，例如基于会话的推荐、图像、视频推荐等。一些任务可能对推荐研究领域并不新鲜（推荐系统的边缘信息详细审查可参见
    (Shi 等人，[2014](#bib.bib132))），但深度学习提供了更多找到更好解决方案的可能性。例如，处理图像和视频将是一项艰巨的任务，如果没有深度学习技术的帮助。深度神经网络的序列建模能力使得捕捉用户行为的序列模式变得容易。下文将讨论一些具体的任务。'
- en: 3.2\. Multilayer Perceptron based Recommendation
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 基于多层感知器的推荐
- en: MLP is a concise but effective network which has been demonstrated to be able
    to approximate any measurable function to any desired degree of accuracy (Hornik
    et al., [1989](#bib.bib60)). As such, it is the basis of numerous advanced approaches
    and is widely used in many areas.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: MLP 是一种简洁而有效的网络，已被证明能够以任意精度逼近任何可测函数（Hornik 等人，[1989](#bib.bib60)）。因此，它是许多高级方法的基础，并广泛应用于许多领域。
- en: Neural Extension of Traditional Recommendation Methods. Many existing recommendation
    models are essentially linear methods. MLP can be used to add nonlinear transformation
    to existing RS approaches and interpret them into neural extensions.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 传统推荐方法的神经扩展。许多现有的推荐模型本质上是线性方法。MLP 可以用于对现有的 RS 方法进行非线性变换，并将其解释为神经扩展。
- en: '![Refer to caption](img/cdd59278f9ea0d09aee83de010947a19.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/cdd59278f9ea0d09aee83de010947a19.png)'
- en: (a)
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/5548a1bdb397a2d960e37ff940bdcffe.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/5548a1bdb397a2d960e37ff940bdcffe.png)'
- en: (b)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 2\. Illustration of: (a) Neural Collaborative Filtering; (b) Deep Factorization
    Machine.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. 示意图：(a) 神经协同过滤；(b) 深度因子分解机。
- en: 'Neural Collaborative Filtering. In most cases, recommendation is deemed to
    be a two-way interaction between users preferences and items features. For example,
    matrix factorization decomposes the rating matrix into low-dimensional user/item
    latent factors. It is natural to construct a dual neural network to model the
    two-way interaction between users and items. Neural Network Matrix Factorization
    (NNMF) (Dziugaite and Roy, [2015](#bib.bib38)) and Neural Collaborative Filtering
    (NCF) (He et al., [2017](#bib.bib54)) are two representative works. Figure [2](#S3.F2
    "Figure 2 ‣ 3.2\. Multilayer Perceptron based Recommendation ‣ 3\. Deep Learning
    Based Recommendation: State-of-the-art ‣ Deep Learning based Recommender System:
    A Survey and New Perspectives")a shows the NCF architecture. Let $s_{u}^{user}$
    and $s_{i}^{item}$ denote the side information (e.g. user profiles and item features),
    or just one-hot identifier of user $u$ and item $i$. The scoring function is defined
    as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 神经协同过滤。在大多数情况下，推荐被认为是用户偏好和物品特征之间的双向交互。例如，矩阵因子化将评分矩阵分解为低维用户/物品潜在因子。自然而然地构建一个双重神经网络来模拟用户和物品之间的双向交互。神经网络矩阵因子化（NNMF）（Dziugaite和Roy，[2015](#bib.bib38)）和神经协同过滤（NCF）（何等人，[2017](#bib.bib54)）是两个典型的工作。图
    [2](#S3.F2 "图 2 ‣ 3.2\. 基于多层感知器的推荐 ‣ 3\. 基于深度学习的推荐：最新技术 ‣ 基于深度学习的推荐系统：调查和新视角")a
    显示了NCF架构。让 $s_{u}^{用户}$ 和 $s_{i}^{项目}$ 表示边缘信息（例如用户概况和物品特征），或者仅表示用户 $u$ 和物品 $i$
    的单热识别符。评分函数定义如下：
- en: '| (1) |  | $\hat{r}_{ui}=f(U^{T}\cdot s_{u}^{user},V^{T}\cdot s_{i}^{item}&#124;U,V,\theta)$
    |  |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| (1) |  | $\hat{r}_{ui}=f(U^{T}\cdot s_{u}^{用户},V^{T}\cdot s_{i}^{项目}\vert
    U,V,\theta)$ |  |'
- en: 'where function $f(\cdot)$ represents the multilayer perceptron, and $\theta$
    is the parameters of this network. Traditional MF can be viewed as a special case
    of NCF. Therefore, it is convenient to fuse the neural interpretation of matrix
    factorization with MLP to formulate a more general model which makes use of both
    linearity of MF and non-linearity of MLP to enhance recommendation quality. The
    whole network can be trained with weighted square loss (for explicit feedback)
    or binary cross-entropy loss (for implicit feedback). The cross-entropy loss is
    defined as:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 其中函数 $f(\cdot)$ 表示多层感知器，$\theta$ 是该网络的参数。传统MF可以看作是NCF的特例。因此，将矩阵因子分解的神经解释与MLP融合，以构建一个更通用的模型，既利用了MF的线性特性，又利用了MLP的非线性特性来提升推荐质量是方便的。整个网络可以用加权平方损失（对显式反馈）或二元交叉熵损失（对隐式反馈）进行训练。交叉熵损失定义如下：
- en: '| (2) |  | $\mathcal{L}=-\sum_{(u,i)\in\mathcal{O}\cup\mathcal{O^{-}}}r_{ui}\log\hat{r}_{ui}+(1-r_{ui})\log(1-\hat{r}_{ui})$
    |  |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| (2) |  | $\mathcal{L}=-\sum_{(u,i)\in\mathcal{O}\cup\mathcal{O^{-}}}r_{ui}\log\hat{r}_{ui}+(1-r_{ui})\log(1-\hat{r}_{ui})$
    |  |'
- en: Negative sampling approaches can be used to reduce the number of training unobserved
    instances. Follow-up work (Niu et al., [2018](#bib.bib113); Song et al., [2018](#bib.bib135))
    proposed using pairwise ranking loss to enhance the performance. He et al. (Wang
    et al., [2017](#bib.bib167); Lian et al., [2017](#bib.bib93)) extended the NCF
    model to cross-domain recommendations. Xue et al. (Xue et al., [2017](#bib.bib185))
    and Zhang et al. (Zhang et al., [2018](#bib.bib196)) showed that the one-hot identifier
    can be replaced with columns or rows of the interaction matrix to retain the user-item
    interaction patterns.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 负采样方法可以用于减少训练中未观察到的实例数量。后续研究（牛等人，[2018](#bib.bib113); 宋等人，[2018](#bib.bib135)）提出使用成对排名损失来增强性能。何等人（王等人，[2017](#bib.bib167);
    廉等人，[2017](#bib.bib93)）扩展了NCF模型以进行跨领域推荐。薛等人（薛等人，[2017](#bib.bib185)）和张等人（张等人，[2018](#bib.bib196)）表明，可以用交互矩阵的列或行替换单热识别符以保留用户-物品交互模式。
- en: 'Deep Factorization Machine. DeepFM (Guo et al., [2017](#bib.bib48)) is an end-to-end
    model which seamlessly integrates factorization machine and MLP. It is able to
    model the high-order feature interactions via deep neural network and low-order
    interactions with factorization machine. Factorization machine (FM) utilizes addition
    and inner product operations to capture the linear and pairwise interactions between
    features (refer to Equation (1) in (Rendle, [2010](#bib.bib120)) for more details).
    MLP leverages the non-linear activations and deep structure to model the high-order
    interactions. The way of combining MLP with FM is enlightened by wide & deep network.
    It replaces the wide component with a neural interpretation of factorization machine.
    Compared to wide & deep model, DeepFM does not require tedious feature engineering.
    Figure [2](#S3.F2 "Figure 2 ‣ 3.2\. Multilayer Perceptron based Recommendation
    ‣ 3\. Deep Learning Based Recommendation: State-of-the-art ‣ Deep Learning based
    Recommender System: A Survey and New Perspectives")b illustrates the structure
    of DeepFM. The input of DeepFM $x$ is an $m$-fields data consisting of pairs $(u,i)$
    (identity and features of user and item). For simplicity, the outputs of FM and
    MLP are denoted as $y_{FM}(x)$ and $y_{MLP}(x)$ respectively. The prediction score
    is calculated by:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '深度因子分解机。DeepFM（Guo et al., [2017](#bib.bib48)）是一个端到端模型，无缝集成了因子分解机和 MLP。它能够通过深度神经网络模拟高阶特征交互，并使用因子分解机模拟低阶交互。因子分解机（FM）利用加法和内积操作捕获特征之间的线性和成对交互（详情参见（Rendle,
    [2010](#bib.bib120)）中的方程（1））。MLP利用非线性激活和深层结构来模拟高阶交互。将 MLP 与 FM 结合的方式受到广泛与深度网络的启发。它用神经网络解释因子分解机来替换宽部件。与宽与深模型相比，DeepFM
    不需要繁琐的特征工程。图 [2](#S3.F2 "Figure 2 ‣ 3.2\. Multilayer Perceptron based Recommendation
    ‣ 3\. Deep Learning Based Recommendation: State-of-the-art ‣ Deep Learning based
    Recommender System: A Survey and New Perspectives")b 展示了 DeepFM 的结构。DeepFM 的输入
    $x$ 是一个包含用户和物品标识及特征对 $(u,i)$ 的 $m$-字段数据。为简单起见，FM 和 MLP 的输出分别记为 $y_{FM}(x)$ 和 $y_{MLP}(x)$。预测分数通过以下公式计算：'
- en: '| (3) |  | $\hat{r}_{ui}=\sigma(y_{FM}(x)+y_{MLP}(x))$ |  |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| (3) |  | $\hat{r}_{ui}=\sigma(y_{FM}(x)+y_{MLP}(x))$ |  |'
- en: where $\sigma(\cdot)$ is the sigmoid activation function.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\sigma(\cdot)$ 是 sigmoid 激活函数。
- en: Lian et al. (Lian et al., [2018](#bib.bib94)) improved DeepMF by proposing a
    eXtreme deep factorization machine to jointly model the explicit and implicit
    feature interactions. The explicit high-order feature interactions are learned
    via a compressed interaction network. A parallel work proposed by He et al. (He
    and Tat-Seng, [2017](#bib.bib55)) replaces the second-order interactions with
    MLP and proposed regularizing the model with dropout and batch normalization.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Lian 等人（Lian et al., [2018](#bib.bib94)）通过提出极端深度因子分解机（eXtreme deep factorization
    machine）共同建模显式和隐式特征交互来改进 DeepMF。显式高阶特征交互通过压缩交互网络进行学习。He 等人（He and Tat-Seng, [2017](#bib.bib55)）提出的并行工作用
    MLP 替换了二阶交互，并建议使用 dropout 和批归一化对模型进行正则化。
- en: Feature Representation Learning with MLP. Using MLP for feature representation
    is very straightforward and highly efficient, even though it might not be as expressive
    as autoencoder, CNNs and RNNs.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 MLP 进行特征表示学习非常直观且高效，尽管可能不像自编码器、CNN 和 RNN 那样表达丰富。
- en: 'Wide & Deep Learning. This general model (shown in Figure [3](#S3.F3 "Figure
    3 ‣ 3.2\. Multilayer Perceptron based Recommendation ‣ 3\. Deep Learning Based
    Recommendation: State-of-the-art ‣ Deep Learning based Recommender System: A Survey
    and New Perspectives")a) can solve both regression and classification problems,
    but initially introduced for App recommendation in Google play (Cheng et al.,
    [2016](#bib.bib21)). The wide learning component is a single layer perceptron
    which can also be regarded as a generalized linear model. The deep learning component
    is multilayer perceptron. The rationale of combining these two learning techniques
    is that it enables the recommender to capture both memorization and generalization.
    Memorization achieved by the wide learning component represents the capability
    of catching the direct features from historical data. Meanwhile, the deep learning
    component catches the generalization by producing more general and abstract representations.
    This model can improve the accuracy as well as the diversity of recommendation.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '宽度 & 深度学习。这个通用模型（如图 [3](#S3.F3 "Figure 3 ‣ 3.2\. Multilayer Perceptron based
    Recommendation ‣ 3\. Deep Learning Based Recommendation: State-of-the-art ‣ Deep
    Learning based Recommender System: A Survey and New Perspectives")a) 可以解决回归和分类问题，但最初是为了
    Google Play 中的应用推荐而提出的 (Cheng et al., [2016](#bib.bib21))。宽度学习组件是一个单层感知机，也可以看作是广义线性模型。深度学习组件是多层感知机。结合这两种学习技术的原理在于，它使推荐系统能够同时捕捉记忆和泛化。宽度学习组件实现的记忆代表了从历史数据中捕捉直接特征的能力。同时，深度学习组件通过生成更一般和抽象的表示来捕捉泛化。这种模型可以提高推荐的准确性和多样性。'
- en: 'Formally, the wide learning is defined as: $y=W^{T}_{wide}\{x,\phi(x)\}+b$,
    where $W^{T}_{wide}$, $b$ are the model parameters. The input $\{x,\phi(x)\}$
    is the concatenated feature set consisting of raw input feature $x$ and transformed
    (e.g. cross-product transformation to capture the correlations between features)
    feature $\phi(x)$. Each layer of the deep neural component is in the form of $\alpha^{(l+1)}=f(W^{(l)}_{deep}a^{(l)}+b^{(l)})$,
    where $l$ indicates the $l^{th}$ layer, and $f(\cdot)$ is the activation function.
    $W^{(l)}_{deep}$ and $b^{(l)}$ are weight and bias terms. The wide & deep learning
    model is attained by fusing these two models:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 从形式上讲，宽度学习定义为：$y=W^{T}_{wide}\{x,\phi(x)\}+b$，其中 $W^{T}_{wide}$ 和 $b$ 是模型参数。输入
    $\{x,\phi(x)\}$ 是由原始输入特征 $x$ 和经过转换（例如，通过交叉乘积转换以捕捉特征间的相关性）的特征 $\phi(x)$ 组成的连接特征集。深度神经组件的每一层形式为
    $\alpha^{(l+1)}=f(W^{(l)}_{deep}a^{(l)}+b^{(l)})$，其中 $l$ 表示第 $l^{th}$ 层，$f(\cdot)$
    是激活函数。$W^{(l)}_{deep}$ 和 $b^{(l)}$ 是权重和偏置项。宽度 & 深度学习模型通过融合这两种模型获得：
- en: '| (4) |  | $P(\hat{r}_{ui}=1&#124;x)=\sigma(W^{T}_{wide}\{x,\phi(x)\}+W^{T}_{deep}a^{(l_{f})}+bias)$
    |  |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| (4) |  | $P(\hat{r}_{ui}=1&#124;x)=\sigma(W^{T}_{wide}\{x,\phi(x)\}+W^{T}_{deep}a^{(l_{f})}+bias)$
    |  |'
- en: where $\sigma(\cdot)$ is the sigmoid function, $\hat{r}_{ui}$ is the binary
    rating label, $a^{(l_{f})}$ is the final activation. This joint model is optimized
    with stochastic back-propagation ( follow-the-regularized-leader algorithm). Recommending
    list is generated based on the predicted scores.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\sigma(\cdot)$ 是 sigmoid 函数，$\hat{r}_{ui}$ 是二值评分标签，$a^{(l_{f})}$ 是最终激活。该联合模型通过随机反向传播（follow-the-regularized-leader
    算法）进行优化。推荐列表是基于预测评分生成的。
- en: By extending this model, Chen et al. (Chen et al., [2017](#bib.bib14)) devised
    a locally-connected wide & deep learning model for large scale industrial-level
    recommendation task. It employs the efficient locally-connected network to replace
    the deep learning component, which decreases the running time by one order of
    magnitude. An important step of deploying wide & deep learning is selecting features
    for wide and deep parts. In other word, the system should be able to determine
    which features are memorized or generalized. Moreover, the cross-product transformation
    also is required to be manually designed. These pre-steps will greatly influence
    the utility of this model. The above mentioned deep factorization based model
    can alleviate the effort in feature engineering.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 通过扩展此模型，Chen et al. (Chen et al., [2017](#bib.bib14)) 设计了一种用于大规模工业级推荐任务的局部连接宽度
    & 深度学习模型。它采用高效的局部连接网络替代深度学习组件，从而将运行时间减少了一个数量级。部署宽度 & 深度学习的一个重要步骤是选择宽度和深度部分的特征。换句话说，系统应该能够确定哪些特征是被记忆的或被泛化的。此外，交叉乘积转换也需要手动设计。这些预步骤将极大地影响该模型的实用性。上述基于深度分解的模型可以减轻特征工程的工作量。
- en: 'Covington et al. (Covington et al., [2016](#bib.bib28)) explored applying MLP
    in YouTube recommendation. This system divides the recommendation task into two
    stages: candidate generation and candidate ranking. The candidate generation network
    retrieves a subset (hundreds) from all video corpus. The ranking network generates
    a top-n list (dozens) based on the nearest neighbors scores from the candidates.
    We notice that the industrial world cares more about feature engineering (e.g.
    transformation, normalization, crossing) and scalability of recommendation models.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Covington等人（Covington et al., [2016](#bib.bib28)）探索了在YouTube推荐中应用MLP。该系统将推荐任务分为两个阶段：候选生成和候选排名。候选生成网络从所有视频语料库中检索出一个子集（数百个）。排名网络根据候选项的最近邻分数生成一个前n名列表（数十个）。我们注意到工业界更关心特征工程（如转换、归一化、交叉）和推荐模型的可扩展性。
- en: Alashkar et al. (Alashkar et al., [2017](#bib.bib3)) proposed a MLP based model
    for makeup recommendation. This work uses two identical MLPs to model labeled
    examples and expert rules respectively. Parameters of these two networks are updated
    simultaneously by minimizing the differences between their outputs. It demonstrates
    the efficacy of adopting expert knowledge to guide the learning process of the
    recommendation model in a MLP framework. It is highly precise even though the
    expertise acquisition needs a lot of human involvements.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Alashkar等人（Alashkar et al., [2017](#bib.bib3)）提出了基于MLP的化妆品推荐模型。该工作使用两个相同的MLP分别建模标记示例和专家规则。这两个网络的参数通过最小化它们输出之间的差异来同时更新。它展示了在MLP框架中采用专家知识指导推荐模型学习过程的有效性。尽管专业知识获取需要大量人力投入，但其精度非常高。
- en: '![Refer to caption](img/32fc5dc3d2df9311daef20577aa30f27.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/32fc5dc3d2df9311daef20577aa30f27.png)'
- en: (a)
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/27c8eaa4496b938a7a77037ac09ba93d.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/27c8eaa4496b938a7a77037ac09ba93d.png)'
- en: (b)
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 3\. Illustration of: (a) Wide & Deep Learning; (b) Multi-View Deep Neural
    Network.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图3. 描述：(a) Wide & Deep Learning; (b) 多视角深度神经网络。
- en: Collaborative Metric Learning (CML). CML (Hsieh et al., [2017](#bib.bib61))
    replaces the dot product of MF with Euclidean distance because dot product does
    not satisfy the triangle inequality of distance function. The user and item embeddings
    are learned via maximizing the distance between users and their disliked items
    and minimizing that between users and their preferred items. In CML, MLP is used
    to learn representations from item features such as text, images and tags.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 协同度量学习（CML）。CML（Hsieh et al., [2017](#bib.bib61)）用欧几里得距离取代了MF的点积，因为点积不满足距离函数的三角不等式。用户和物品嵌入通过最大化用户与其不喜欢的物品之间的距离和最小化用户与其喜欢的物品之间的距离来学习。在CML中，MLP用于从项目特征（如文本、图像和标签）中学习表示。
- en: Recommendation with Deep Structured Semantic Model. Deep Structured Semantic
    Model (DSSM) (Huang et al., [2013](#bib.bib66)) is a deep neural network for learning
    semantic representations of entities in a common continuous semantic space and
    measuring their semantic similarities. It is widely used in information retrieval
    area and is supremely suitable for top-n recommendation (Elkahky et al., [2015](#bib.bib40);
    Xu et al., [2016](#bib.bib183)). DSSM projects different entities into a common
    low-dimensional space, and computes their similarities with cosine function. Basic
    DSSM is made up of MLP so we put it in this section. Note that, more advanced
    neural layers such as convolution and max-pooling layers can also be easily integrated
    into DSSM.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 带有深度结构化语义模型的推荐。深度结构化语义模型（DSSM）（Huang et al., [2013](#bib.bib66)）是一个用于学习实体在共同连续语义空间中语义表示并测量它们语义相似性的深度神经网络。它被广泛应用于信息检索领域，并且非常适合于前n推荐（Elkahky
    et al., [2015](#bib.bib40); Xu et al., [2016](#bib.bib183)）。DSSM将不同实体投射到一个共同的低维空间，并用余弦函数计算它们之间的相似性。基本的DSSM由MLP组成，因此我们将其放在本节中。请注意，更高级的神经层，如卷积和最大池化层，也可以轻松集成到DSSM中。
- en: 'Deep Semantic Similarity based Personalized Recommendation (DSPR) (Xu et al.,
    [2016](#bib.bib183)) is a tag-aware personalized recommender where each user $x_{u}$
    and item $x_{i}$ are represented by tag annotations and mapped into a common tag
    space. Cosine similarity $sim(u,i)$ are applied to decide the relevance of items
    and users (or user’s preference over the item). The loss function of DSPR is defined
    as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 基于深度语义相似性的个性化推荐（DSPR）（Xu et al., [2016](#bib.bib183)）是一种标签感知的个性化推荐器，其中每个用户$x_{u}$和物品$x_{i}$都由标签注释表示，并映射到一个共同的标签空间中。余弦相似度$sim(u,i)$用于决定物品和用户之间的相关性（或用户对物品的偏好）。DSPR的损失函数定义如下：
- en: '| (5) |  | $\mathcal{L}=-\sum_{(u,i*)}[log(e^{sim(u,i*)})-log(\sum_{(u,i^{-})\in
    D^{-}}e^{sim(u,i^{-})})]$ |  |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| (5) |  | $\mathcal{L}=-\sum_{(u,i*)}[log(e^{sim(u,i*)})-log(\sum_{(u,i^{-})\in
    D^{-}}e^{sim(u,i^{-})})]$ |  |'
- en: where $(u,i^{-})$ are negative samples which are randomly sampled from the negative
    user item pairs. The authors. (Xu et al., [2017](#bib.bib184)) further improved
    DSPR using autoencoder to learn low-dimensional representations from user/item
    profiles.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $(u,i^{-})$ 是从负用户物品对中随机抽样的负样本。作者（Xu 等，[2017](#bib.bib184)）进一步改进了DSP使用自编码器来从用户/物品档案中学习低维表示。
- en: 'Multi-View Deep Neural Network (MV-DNN) (Elkahky et al., [2015](#bib.bib40))
    is designed for cross domain recommendation. It treats users as the pivot view
    and each domain (suppose we have $Z$ domains) as auxiliary view. Apparently, there
    are $Z$ similarity scores for $Z$ user-domain pairs. Figure [3](#S3.F3 "Figure
    3 ‣ 3.2\. Multilayer Perceptron based Recommendation ‣ 3\. Deep Learning Based
    Recommendation: State-of-the-art ‣ Deep Learning based Recommender System: A Survey
    and New Perspectives")b illustrates the structure of MV-DNN. The loss function
    of MV-DNN is defined as:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 多视图深度神经网络（MV-DNN）（Elkahky 等，[2015](#bib.bib40)）设计用于跨域推荐。它将用户视为核心视图，将每个领域（假设我们有
    $Z$ 个领域）视为辅助视图。显然，对于 $Z$ 个用户-领域对，有 $Z$ 个相似度评分。图[3](#S3.F3 "图 3 ‣ 3.2\. 基于多层感知器的推荐
    ‣ 3\. 深度学习推荐：前沿技术 ‣ 深度学习推荐系统：综述与新视角")b 说明了MV-DNN的结构。MV-DNN的损失函数定义为：
- en: '| (6) |  | $\mathcal{L}=\underset{\theta}{argmin}\sum_{j=1}^{Z}\frac{exp(\gamma\cdot
    cosine(Y_{u},Y_{a,j}))}{\sum_{X^{\prime}\in R^{da}}exp(\gamma\cdot cosine(Y_{u},f_{a}(X^{\prime})))}$
    |  |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| (6) |  | $\mathcal{L}=\underset{\theta}{argmin}\sum_{j=1}^{Z}\frac{exp(\gamma\cdot
    cosine(Y_{u},Y_{a,j}))}{\sum_{X^{\prime}\in R^{da}}exp(\gamma\cdot cosine(Y_{u},f_{a}(X^{\prime})))}$
    |  |'
- en: where $\theta$ is the model parameters, $\gamma$ is the smoothing factor, $Y_{u}$
    is the output of user view, $a$ is the index of active view. $R^{da}$ is the input
    domain of view $a$. MV-DNN is capable of scaling up to many domains. However,
    it is based on the hypothesis that users have similar tastes in one domain should
    have similar tastes in other domains. Intuitively, this assumption might be unreasonable
    in many cases. Therefore, we should have some preliminary knowledge on the correlations
    across different domains to make the most of MV-DNN.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\theta$ 是模型参数，$\gamma$ 是平滑因子，$Y_{u}$ 是用户视图的输出，$a$ 是活跃视图的索引。$R^{da}$ 是视图
    $a$ 的输入域。MV-DNN 能够扩展到多个领域。然而，它基于的假设是用户在一个领域的相似口味应在其他领域中也具有相似口味。从直觉上讲，这个假设在许多情况下可能是不合理的。因此，我们需要对不同领域之间的相关性有一些初步了解，以充分利用MV-DNN。
- en: 3.3\. Autoencoder based Recommendation
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 基于自编码器的推荐
- en: 'There exist two general ways of applying autoencoder to recommender system:
    (1) using autoencoder to learn lower-dimensional feature representations at the
    bottleneck layer; or (2) filling the blanks of the interaction matrix directly
    in the reconstruction layer. Almost all the autoencoder variants such as denoising
    autoencoder, variational autoencoder, contactive autoencoder and marginalized
    autoencoder can be applied to recommendation task. Table [3](#S3.T3 "Table 3 ‣
    3.3\. Autoencoder based Recommendation ‣ 3\. Deep Learning Based Recommendation:
    State-of-the-art ‣ Deep Learning based Recommender System: A Survey and New Perspectives")
    summarizes the recommendation models based on the types of autoencoder in use.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 应用自编码器到推荐系统通常有两种方法：（1）使用自编码器在瓶颈层学习低维特征表示；或（2）直接在重构层填补交互矩阵中的空缺。几乎所有自编码器变体，如去噪自编码器、变分自编码器、对比自编码器和边际自编码器，都可以应用于推荐任务。表[3](#S3.T3
    "表 3 ‣ 3.3\. 基于自编码器的推荐 ‣ 3\. 深度学习推荐：前沿技术 ‣ 深度学习推荐系统：综述与新视角")总结了基于自编码器类型的推荐模型。
- en: Autoencoder based Collaborative Filtering. One of the successful application
    is to consider the collaborative filtering from Autoencoder perspective.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 基于自编码器的协同过滤。一个成功的应用是从自编码器的角度考虑协同过滤。
- en: 'AutoRec (Sedhain et al., [2015](#bib.bib126)) takes user partial vectors $\textbf{r}^{(u)}$
    or item partial vectors $\textbf{r}^{(i)}$ as input, and aims to reconstruct them
    in the output layer. Apparently, it has two variants: item-based AutoRec (I-AutoRec)
    and user-based AutoRec (U-AutoRec), corresponding to the two types of inputs.
    Here, we only introduce I-AutoRec, while U-AutoRec can be easily derived accordingly.
    Figure [4](#S3.F4 "Figure 4 ‣ 3.3\. Autoencoder based Recommendation ‣ 3\. Deep
    Learning Based Recommendation: State-of-the-art ‣ Deep Learning based Recommender
    System: A Survey and New Perspectives")a illustrates the structure of I-AutoRec.
    Given input $\textbf{r}^{(i)}$, the reconstruction is: $h(\textbf{r}^{(i)};\theta)=f(W\cdot
    g(V\cdot\textbf{r}^{(i)}+\mu)+b)$, where $f(\cdot)$ and $g(\cdot)$ are the activation
    functions, parameter $\theta=\{W,V,\mu,b\}$. The objective function of I-AutoRec
    is formulated as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 'AutoRec （Sedhain 等人，[2015](#bib.bib126)）将用户部分向量 $\textbf{r}^{(u)}$ 或项部分向量 $\textbf{r}^{(i)}$
    作为输入，并旨在在输出层重建它们。显然，它有两个变体：基于项目的 AutoRec（I-AutoRec）和基于用户的 AutoRec（U-AutoRec），对应于两种输入类型。在这里，我们只介绍
    I-AutoRec，而 U-AutoRec 可以相应地推导出来。图 [4](#S3.F4 "Figure 4 ‣ 3.3\. Autoencoder based
    Recommendation ‣ 3\. Deep Learning Based Recommendation: State-of-the-art ‣ Deep
    Learning based Recommender System: A Survey and New Perspectives")a 说明了 I-AutoRec
    的结构。给定输入 $\textbf{r}^{(i)}$，重建为：$h(\textbf{r}^{(i)};\theta)=f(W\cdot g(V\cdot\textbf{r}^{(i)}+\mu)+b)$，其中
    $f(\cdot)$ 和 $g(\cdot)$ 是激活函数，参数 $\theta=\{W,V,\mu,b\}$。I-AutoRec 的目标函数如下所示：'
- en: '| (7) |  | $\underset{\theta}{argmin}\sum_{i=1}^{N}\parallel\textbf{r}^{(i)}-h(\textbf{r}^{(i)};\theta)\parallel_{\mathcal{O}}^{2}+\lambda\cdot\textit{reg}$
    |  |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| (7) |  | $\underset{\theta}{argmin}\sum_{i=1}^{N}\parallel\textbf{r}^{(i)}-h(\textbf{r}^{(i)};\theta)\parallel_{\mathcal{O}}^{2}+\lambda\cdot\textit{reg}$
    |  |'
- en: 'Here $\parallel\cdot\parallel_{\mathcal{O}}^{2}$ means that it only considers
    observed ratings. The objective function can be optimized by resilient propagation
    (converges faster and produces comparable results) or L-BFGS (Limited-memory Broyden
    Fletcher Goldfarb Shanno algorithm). There are four important points about AutoRec
    that worth noticing before deployment: (1) I-AutoRec performs better than U-AutoRec,
    which may be due to the higher variance of user partially observed vectors. (2)
    Different combination of activation functions $f(\cdot)$ and $g(\cdot)$ will influence
    the performance considerably. (3) Increasing the hidden unit size moderately will
    improve the result as expanding the hidden layer dimensionality gives AutoRec
    more capacity to model the characteristics of the input. (4) Adding more layers
    to formulate a deep network can lead to slightly improvement.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 $\parallel\cdot\parallel_{\mathcal{O}}^{2}$ 表示仅考虑观察到的评分。目标函数可以通过弹性传播（收敛速度更快且结果可比）或
    L-BFGS（有限记忆 Broyden Fletcher Goldfarb Shanno 算法）进行优化。在部署前，有四点关于 AutoRec 的重要事项值得注意：（1）I-AutoRec
    的性能优于 U-AutoRec，这可能是由于用户部分观察向量的方差较高。（2）激活函数 $f(\cdot)$ 和 $g(\cdot)$ 的不同组合会显著影响性能。（3）适度增加隐藏单元的大小将改善结果，因为扩展隐藏层的维度为
    AutoRec 提供了更多建模输入特征的能力。（4）增加更多层以构建深度网络可以带来轻微的改进。
- en: '![Refer to caption](img/317aea444be25a36e544b80adc725aab.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/317aea444be25a36e544b80adc725aab.png)'
- en: (a)
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/24363b7ee15e19063618d5dbff934e63.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/24363b7ee15e19063618d5dbff934e63.png)'
- en: (b)
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: '![Refer to caption](img/c101d9c2df5dcf57ec44421858e666b9.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c101d9c2df5dcf57ec44421858e666b9.png)'
- en: (c)
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: (c)
- en: 'Figure 4\. Illustration of: (a) Item based AutoRec; (b) Collaborative denoising
    autoencoder; (c) Deep collaborative filtering framework.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4\. 说明： (a) 基于项目的 AutoRec； (b) 协同去噪自编码器； (c) 深度协同过滤框架。
- en: 'CFN (Strub et al., [2016](#bib.bib137); Strub and Mary, [2015](#bib.bib138))
    is an extension of AutoRec, and posses the following two advantages: (1) it deploys
    the denoising techniques, which makes CFN more robust; (2) it incorporates the
    side information such as user profiles and item descriptions to mitigate the sparsity
    and cold start influence. The input of CFN is also partial observed vectors, so
    it also has two variants: I-CFN and U-CFN, taking $\textbf{r}^{(i)}$ and $\textbf{r}^{(u)}$
    as input respectively. Masking noise is imposed as a strong regularizer to better
    deal with missing elements (their values are zero). The authors introduced three
    widely used corruption approaches to corrupt the input: Gaussian noise, masking
    noise and salt-and-pepper noise. Further extension of CFN also incorporates side
    information. However, instead of just integrating side information in the first
    layer, CFN injects side information in every layer. Thus, the reconstruction becomes:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: CFN (Strub et al., [2016](#bib.bib137); Strub and Mary, [2015](#bib.bib138))
    是 AutoRec 的扩展，并具有以下两个优势：（1）它应用了去噪技术，使 CFN 更加鲁棒；（2）它融合了诸如用户资料和项目描述等附加信息，以减轻稀疏性和冷启动的影响。CFN
    的输入也是部分观测向量，因此它还有两个变种：I-CFN 和 U-CFN，分别以 $\textbf{r}^{(i)}$ 和 $\textbf{r}^{(u)}$
    作为输入。强正则化的掩码噪声被施加以更好地处理缺失元素（其值为零）。作者引入了三种广泛使用的破坏方法来扰动输入：高斯噪声、掩码噪声和盐与胡椒噪声。CFN 的进一步扩展也融合了附加信息。然而，与仅在第一层中整合附加信息不同，CFN
    在每一层中都注入附加信息。因此，重建过程变为：
- en: '| (8) |  | $h(\{\tilde{\textbf{r}}^{(i)},\textbf{s}_{i}\})=f(W_{2}\cdot\{g(W_{1}\cdot\{\textbf{r}^{(i)},\textbf{s}_{i}\}+\mu),\textbf{s}_{i}\}+b)$
    |  |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| (8) |  | $h(\{\tilde{\textbf{r}}^{(i)},\textbf{s}_{i}\})=f(W_{2}\cdot\{g(W_{1}\cdot\{\textbf{r}^{(i)},\textbf{s}_{i}\}+\mu),\textbf{s}_{i}\}+b)$
    |  |'
- en: where $\textbf{s}_{i}$ is side information, $\{\tilde{\textbf{r}}^{(i)},\textbf{s}_{i}\}$
    indicates the concatenation of $\tilde{\textbf{r}}^{(i)}$ and $\textbf{s}_{i}$.
    Incorporating side information improves the prediction accuracy, speeds up the
    training process and enables the model to be more robust.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\textbf{s}_{i}$ 是附加信息，$\{\tilde{\textbf{r}}^{(i)},\textbf{s}_{i}\}$ 表示 $\tilde{\textbf{r}}^{(i)}$
    和 $\textbf{s}_{i}$ 的拼接。融入附加信息提高了预测准确性，加快了训练过程，并使模型更加鲁棒。
- en: Table 3\. Summary of four autoencoder based recommendation models
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3\. 四种基于自编码器的推荐模型总结
- en: '| Vanilla/Denoising AE | Variational AE | Contractive AE | Marginalized AE
    |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| Vanilla/Denoising AE | Variational AE | Contractive AE | Marginalized AE
    |'
- en: '| --- | --- | --- | --- |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; (Sedhain et al., [2015](#bib.bib126); Strub et al., [2016](#bib.bib137);
    Strub and Mary, [2015](#bib.bib138); Ouyang et al., [2014](#bib.bib115); Wu et al.,
    [2016a](#bib.bib178); Wang et al., [2015b](#bib.bib160)) &#124;'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (Sedhain et al., [2015](#bib.bib126); Strub et al., [2016](#bib.bib137);
    Strub and Mary, [2015](#bib.bib138); Ouyang et al., [2014](#bib.bib115); Wu et
    al., [2016a](#bib.bib178); Wang et al., [2015b](#bib.bib160)) &#124;'
- en: '&#124; (Ying et al., [2016](#bib.bib189); Pana et al., [2017](#bib.bib117);
    Jhamb et al., [2018](#bib.bib71); Wei et al., [2016](#bib.bib171), [2017](#bib.bib172))
    &#124;'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (Ying et al., [2016](#bib.bib189); Pana et al., [2017](#bib.bib117);
    Jhamb et al., [2018](#bib.bib71); Wei et al., [2016](#bib.bib171), [2017](#bib.bib172))
    &#124;'
- en: '| (Liang et al., [2018](#bib.bib95); Li and She, [2017](#bib.bib90); Chen and
    de Rijke, [2018](#bib.bib20)) | (Zhang et al., [2017](#bib.bib197)) | (Li et al.,
    [2015](#bib.bib89)) |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| (Liang et al., [2018](#bib.bib95); Li and She, [2017](#bib.bib90); Chen and
    de Rijke, [2018](#bib.bib20)) | (Zhang et al., [2017](#bib.bib197)) | (Li et al.,
    [2015](#bib.bib89)) |'
- en: 'Collaborative Denoising Auto-Encoder (CDAE). The three models reviewed earlier
    are mainly designed for rating prediction, while CDAE (Wu et al., [2016a](#bib.bib178))
    is principally used for ranking prediction. The input of CDAE is user partially
    observed implicit feedback $\textbf{r}^{(u)}_{pref}$. The entry value is 1 if
    the user likes the movie, otherwise 0\. It can also be regarded as a preference
    vector which reflects user’s interests to items. Figure [4](#S3.F4 "Figure 4 ‣
    3.3\. Autoencoder based Recommendation ‣ 3\. Deep Learning Based Recommendation:
    State-of-the-art ‣ Deep Learning based Recommender System: A Survey and New Perspectives")b
    illustrates the structure of CDAE. The input of CDAE is corrupted by Gaussian
    noise. The corrupted input $\tilde{\textbf{r}}^{(u)}_{pref}$ is drawn from a conditional
    Gaussian distribution $p(\tilde{\textbf{r}}^{(u)}_{pref}|\textbf{r}^{(u)}_{pref})$.
    The reconstruction is defined as:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 协同去噪自编码器（CDAE）。之前审查的三种模型主要用于评分预测，而 CDAE（Wu et al., [2016a](#bib.bib178)）主要用于排序预测。CDAE
    的输入是用户部分观察到的隐式反馈 $\textbf{r}^{(u)}_{pref}$。如果用户喜欢电影，则条目值为 1，否则为 0。它也可以被视为反映用户对项目兴趣的偏好向量。图
    [4](#S3.F4 "图 4 ‣ 3.3\. 基于自编码器的推荐 ‣ 3\. 基于深度学习的推荐：前沿技术 ‣ 基于深度学习的推荐系统：综述与新视角")b
    说明了 CDAE 的结构。CDAE 的输入受到高斯噪声的污染。受污染的输入 $\tilde{\textbf{r}}^{(u)}_{pref}$ 是从条件高斯分布
    $p(\tilde{\textbf{r}}^{(u)}_{pref}|\textbf{r}^{(u)}_{pref})$ 中抽取的。重构定义为：
- en: '| (9) |  | $h(\tilde{\textbf{r}}^{(u)}_{pref})=f(W_{2}\cdot g(W_{1}\cdot\tilde{\textbf{r}}^{(u)}_{pref}+V_{u}+b_{1})+b_{2})$
    |  |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| (9) |  | $h(\tilde{\textbf{r}}^{(u)}_{pref})=f(W_{2}\cdot g(W_{1}\cdot\tilde{\textbf{r}}^{(u)}_{pref}+V_{u}+b_{1})+b_{2})$
    |  |'
- en: 'where $V_{u}\in\mathbb{R}^{K}$ denotes the weight matrix for user node (see
    figure [4](#S3.F4 "Figure 4 ‣ 3.3\. Autoencoder based Recommendation ‣ 3\. Deep
    Learning Based Recommendation: State-of-the-art ‣ Deep Learning based Recommender
    System: A Survey and New Perspectives")b). This weight matrix is unique for each
    user and has significant influence on the model performance. Parameters of CDAE
    are also learned by minimizing the reconstruction error:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $V_{u}\in\mathbb{R}^{K}$ 表示用户节点的权重矩阵（参见图 [4](#S3.F4 "图 4 ‣ 3.3\. 基于自编码器的推荐
    ‣ 3\. 基于深度学习的推荐：前沿技术 ‣ 基于深度学习的推荐系统：综述与新视角")b）。该权重矩阵对每个用户都是独特的，并且对模型性能有显著影响。CDAE
    的参数也是通过最小化重构误差来学习的：
- en: '| (10) |  | $\underset{W_{1},W_{2},V,b_{1},b_{2}}{argmin}\frac{1}{M}\sum_{u=1}^{M}\mathbf{E}_{p(\tilde{\textbf{r}}^{(u)}_{pref}&#124;\textbf{r}^{(u)}_{pref})}[\ell(\tilde{\textbf{r}}^{(u)}_{pref},h(\tilde{\textbf{r}}^{(u)}_{pref}))]+\lambda\cdot\textit{reg}$
    |  |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| (10) |  | $\underset{W_{1},W_{2},V,b_{1},b_{2}}{argmin}\frac{1}{M}\sum_{u=1}^{M}\mathbf{E}_{p(\tilde{\textbf{r}}^{(u)}_{pref}\mid\textbf{r}^{(u)}_{pref})}[\ell(\tilde{\textbf{r}}^{(u)}_{pref},h(\tilde{\textbf{r}}^{(u)}_{pref}))]+\lambda\cdot\textit{reg}$
    |  |'
- en: where the loss function $\ell(\cdot)$ can be square loss or logistic loss.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 其中损失函数 $\ell(\cdot)$ 可以是平方损失或逻辑损失。
- en: CDAE initially updates its parameters using SGD over all feedback. However,
    the authors argued that it is impractical to take all ratings into consideration
    in real world applications, so they proposed a negative sampling technique to
    sample a small subset from the negative set (items with which the user has not
    interacted), which reduces the time complexity substantially without degrading
    the ranking quality.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: CDAE 最初通过 SGD 更新其参数，遍历所有反馈。然而，作者认为在实际应用中考虑所有评分是不切实际的，因此他们提出了一种负采样技术，从负样本集中（用户未互动的项目）中采样一个小子集，这大大减少了时间复杂度而不降低排名质量。
- en: Muli-VAE and Multi-DAE (Liang et al., [2018](#bib.bib95)) proposed a variant
    of varitional autoencoder for recommendation with implicit data, showing better
    performance than CDAE. The authors introduced a principled Bayesian inference
    approach for parameters estimation and show favorable results than commonly used
    likelihood functions.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: Muli-VAE 和 Multi-DAE（Liang et al., [2018](#bib.bib95)）提出了一种变分自编码器的变体，用于处理隐式数据的推荐，表现优于
    CDAE。作者引入了一种有原则的贝叶斯推断方法进行参数估计，并显示出比常用的似然函数更为有利的结果。
- en: 'To the extent of our knowledge, Autoencoder-based Collaborative Filtering (ACF) (Ouyang
    et al., [2014](#bib.bib115)) is the first autoencoder based collaborative recommendation
    model. Instead of using the original partial observed vectors, it decomposes them
    by integer ratings. For example, if the rating score is integer in the range of
    [1-5], each $\textbf{r}^{(i)}$ will be divided into five partial vectors. Similar
    to AutoRec and CFN, the cost function of ACF aims at reducing the mean squared
    error. However, there are two demerits of ACF: (1) it fails to deal with non-integer
    ratings; (2) the decomposition of partial observed vectors increases the sparseness
    of input data and leads to worse prediction accuracy.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的了解，基于自编码器的协同过滤（ACF）（Ouyang 等，[2014](#bib.bib115)）是首个基于自编码器的协同推荐模型。它不是使用原始的部分观察向量，而是通过整数评分来分解这些向量。例如，如果评分在
    [1-5] 范围内，每个 $\textbf{r}^{(i)}$ 将被分解成五个部分向量。类似于 AutoRec 和 CFN，ACF 的成本函数旨在减少均方误差。然而，ACF
    有两个缺点：（1）它无法处理非整数评分；（2）部分观察向量的分解增加了输入数据的稀疏性，从而导致预测准确度下降。
- en: Feature Representation Learning with Autoencoder. Autoencoder is a class of
    powerful feature representation learning approach. As such, it can also be used
    in recommender systems to learn feature representations from user/item content
    features.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自编码器的特征表示学习。自编码器是一类强大的特征表示学习方法。因此，它也可以用于推荐系统，从用户/项目内容特征中学习特征表示。
- en: 'Collaborative Deep Learning (CDL). CDL (Wang et al., [2015b](#bib.bib160))
    is a hierarchical Bayesian model which integrates stacked denoising autoencoder
    (SDAE) into probabilistic matrix factorization. To seamlessly combine deep learning
    and recommendation model, the authors proposed a general Bayesian deep learning
    framework (Wang and Yeung, [2016](#bib.bib162)) consisting of two tightly hinged
    components: perception component (deep neural network) and task-specific component.
    Specifically, the perception component of CDL is a probabilistic interpretation
    of ordinal SDAE, and PMF acts as the task-specific component. This tight combination
    enables CDL to balance the influences of side information and interaction history.
    The generative process of CDL is as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 协同深度学习（CDL）。CDL（Wang 等，[2015b](#bib.bib160)）是一个层次贝叶斯模型，将堆叠去噪自编码器（SDAE）整合到概率矩阵分解中。为了无缝结合深度学习和推荐模型，作者提出了一个通用贝叶斯深度学习框架（Wang
    和 Yeung，[2016](#bib.bib162)），由两个紧密结合的组件组成：感知组件（深度神经网络）和任务特定组件。具体来说，CDL 的感知组件是序数
    SDAE 的概率解释，而 PMF 作为任务特定组件。这种紧密结合使得 CDL 能够平衡侧面信息和交互历史的影响。CDL 的生成过程如下：
- en: (1)
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: 'For each layer $l$ of the SDAE: (a) For each column $n$ of weight matrix $W_{l}$,
    draw $W_{l,*n}\sim\mathcal{N}(0,\lambda_{w}^{-1}\textbf{I}_{D_{l}})$; (b) Draw
    the bias vector $b_{l}\sim\mathcal{N}(0,\lambda_{w}^{-1}\textbf{I}_{D_{l}})$;
    (c) For each row $i$ of $X_{l}$, draw $X_{l,i*}\sim\mathcal{N}(\sigma(X_{l-1,i*}W_{l}+b_{l}),\lambda_{s}^{-1}\textbf{I}_{D_{l}})$.'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于 SDAE 的每一层 $l$：（a）对于权重矩阵 $W_{l}$ 的每一列 $n$，抽取 $W_{l,*n}\sim\mathcal{N}(0,\lambda_{w}^{-1}\textbf{I}_{D_{l}})$；（b）抽取偏置向量
    $b_{l}\sim\mathcal{N}(0,\lambda_{w}^{-1}\textbf{I}_{D_{l}})$；（c）对于 $X_{l}$ 的每一行
    $i$，抽取 $X_{l,i*}\sim\mathcal{N}(\sigma(X_{l-1,i*}W_{l}+b_{l}),\lambda_{s}^{-1}\textbf{I}_{D_{l}})$。
- en: (2)
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: 'For each item $i$: (a) Draw a clean input $X_{c,i*}\sim\mathcal{N}(X_{L,i*},\lambda_{n}^{-1}\textbf{I}_{I_{i}})$;
    (b) Draw a latent offset vector $\epsilon_{i}\sim\mathcal{N}(0,\lambda_{v}^{-1}\textbf{I}_{D})$
    and set the latent item vector: $V_{i}=\epsilon_{i}+X_{\frac{L}{2},i*}^{T}$.'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于每个项目 $i$：（a）抽取一个干净的输入 $X_{c,i*}\sim\mathcal{N}(X_{L,i*},\lambda_{n}^{-1}\textbf{I}_{I_{i}})$；（b）抽取一个潜在偏移向量
    $\epsilon_{i}\sim\mathcal{N}(0,\lambda_{v}^{-1}\textbf{I}_{D})$ 并设置潜在项目向量：$V_{i}=\epsilon_{i}+X_{\frac{L}{2},i*}^{T}$。
- en: (3)
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: Draw a latent user vector for each user $u$, $U_{u}\sim\mathcal{N}(0,\lambda_{u}^{-1}\textbf{I}_{D})$.
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为每个用户 $u$ 抽取一个潜在用户向量 $U_{u}\sim\mathcal{N}(0,\lambda_{u}^{-1}\textbf{I}_{D})$。
- en: (4)
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: Draw a rating $r_{ui}$ for each user-item pair $(u,i)$, $r_{ui}\sim\mathcal{N}(U_{u}^{T}V_{i},C_{ui}^{-1})$.
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于每个用户-项目对 $(u,i)$，抽取一个评分 $r_{ui}$，$r_{ui}\sim\mathcal{N}(U_{u}^{T}V_{i},C_{ui}^{-1})$。
- en: 'where $W_{l}$ and $b_{l}$ are the weight matrix and biases vector for layer
    $l$, $X_{l}$ represents layer $l$. $\lambda_{w}$, $\lambda_{s}$, $\lambda_{n}$,
    $\lambda_{v}$, $\lambda_{u}$ are hyper-parameters, $C_{ui}$ is a confidence parameter
    for determining the confidence to observations (Hu et al., [2008](#bib.bib64)).
    Figure [5](#S3.F5 "Figure 5 ‣ 3.3\. Autoencoder based Recommendation ‣ 3\. Deep
    Learning Based Recommendation: State-of-the-art ‣ Deep Learning based Recommender
    System: A Survey and New Perspectives")(left) illustrates the graphical model
    of CDL. The authors exploited an EM-style algorithm to learn the parameters. In
    each iteration, it updates $U$ and $V$ first, and then updates $W$ and $b$ by
    fixing $U$ and $V$. The authors also introduced a sampling-based algorithm (Wang
    and Yeung, [2016](#bib.bib162)) to avoid the local optimum.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $W_{l}$ 和 $b_{l}$ 是第 $l$ 层的权重矩阵和偏置向量，$X_{l}$ 代表第 $l$ 层。$\lambda_{w}$, $\lambda_{s}$,
    $\lambda_{n}$, $\lambda_{v}$, $\lambda_{u}$ 是超参数，$C_{ui}$ 是用于确定观察置信度的参数 (Hu等人，[2008](https://bib.bib64))。图
    [5](#S3.F5 "Figure 5 ‣ 3.3\. Autoencoder based Recommendation ‣ 3\. Deep Learning
    Based Recommendation: State-of-the-art ‣ Deep Learning based Recommender System:
    A Survey and New Perspectives")（左）说明了CDL的图形模型。作者采用了一种类似EM的算法来学习参数。在每次迭代中，首先更新
    $U$ 和 $V$，然后在固定 $U$ 和 $V$ 的情况下更新 $W$ 和 $b$。作者还引入了一种基于抽样的算法 (Wang和Yeung，[2016](https://bib.bib162))
    来避免局部最优解。'
- en: Before CDL, Wang et al. (Wang et al., [2015a](#bib.bib159)) proposed a similar
    model, relational stacked denoising autoencoders (RSDAE), for tag recommendation.
    The difference of CDL and RSDAE is that RSDAE replaces the PMF with a relational
    information matrix. Another extension of CDL is collaborative variational autoencoder
    (CVAE) (Li and She, [2017](#bib.bib90)), which replaces the deep neural component
    of CDL with a variational autoencoder. CVAE learns probabilistic latent variables
    for content information and can easily incorporate multimedia (video, images)
    data sources.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在 CDL 之前，Wang 等人 (Wang等人，[2015a](https://bib.bib159)) 提出了一个类似模型，关系叠加去噪自编码器（RSDAE），用于标签推荐。CDL
    与 RSDAE 的区别在于，RSDAE 用关系信息矩阵替换了 PMF。CDL 的另一个扩展是协作变分自编码器（CVAE） (Li和She，[2017](https://bib.bib90))，它用变分自编码器替换了
    CDL 的深度神经组件。CVAE 为内容信息学习了概率潜变量，并可以轻松整合多媒体（视频、图像）数据源。
- en: '![Refer to caption](img/788c9197a4f415728938c61a62d6e820.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/788c9197a4f415728938c61a62d6e820.png)'
- en: Figure 5\. Graphical model of collaborative deep learning (left) and collaborative
    deep ranking (right).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图5\. 协作深度学习的图形模型（左）和协作深度排名（右）。
- en: 'Collaborative Deep Ranking (CDR). CDR (Ying et al., [2016](#bib.bib189)) is
    devised specifically in a pairwise framework for top-n recommendation. Some studies
    have demonstrated that pairwise model is more suitable for ranking lists generation (Wu
    et al., [2016a](#bib.bib178); Ying et al., [2016](#bib.bib189); Rendle et al.,
    [2009](#bib.bib121)). Experimental results also show that CDR outperforms CDL
    in terms of ranking prediction. Figure [5](#S3.F5 "Figure 5 ‣ 3.3\. Autoencoder
    based Recommendation ‣ 3\. Deep Learning Based Recommendation: State-of-the-art
    ‣ Deep Learning based Recommender System: A Survey and New Perspectives")(right)
    presents the structure of CDR. The first and second generative process steps of
    CDR are the same as CDL. The third and fourth steps are replaced by the following
    step:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '协作深度排名（CDR）。CDR (Ying等人，[2016](https://bib.bib189)) 是专门设计用于排名推荐的成对框架。一些研究表明，成对模型更适合于生成排名列表 (Wu等人，[2016a](https://bib.bib178);
    Ying等人，[2016](https://bib.bib189); Rendle等人，[2009](https://bib.bib121))。实验结果还表明，CDR
    在排名预测方面优于 CDL。图 [5](#S3.F5 "Figure 5 ‣ 3.3\. Autoencoder based Recommendation
    ‣ 3\. Deep Learning Based Recommendation: State-of-the-art ‣ Deep Learning based
    Recommender System: A Survey and New Perspectives")（右）展示了CDR的结构。CDR的第一和第二生成过程步骤与
    CDL 相同。第三和第四步骤被以下步骤所取代：'
- en: •
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'For each user $u$: (a) Draw a latent user vector for $u$, $U_{u}\sim\mathcal{N}(0,\lambda_{u}^{-1}\textbf{I}_{D})$;
    (b) For each pair-wise preference $(i,j)\in P_{i}$, where $P_{i}=\{(i,j):r_{ui}-r_{uj}>0\}$,
    draw the estimator, $\delta_{uij}\sim\mathcal{N}(U_{u}^{T}V_{i}-U_{u}^{T}V_{j},C_{uij}^{-1})$.'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于每个用户 $u$：（a）为 $u$ 绘制潜在用户向量，$U_{u}\sim\mathcal{N}(0,\lambda_{u}^{-1}\textbf{I}_{D})$；（b）对于每对偏好
    $(i,j)\in P_{i}$，其中 $P_{i}=\{(i,j):r_{ui}-r_{uj}>0\}$，绘制估计器 $\delta_{uij}\sim\mathcal{N}(U_{u}^{T}V_{i}-U_{u}^{T}V_{j},C_{uij}^{-1})$。
- en: where $\delta_{uij}=r_{ui}-r_{uj}$ represents the pairwise relationship of user’s
    preference on item $i$ and item $j$, $C_{uij}^{-1}$ is a confidence value which
    indicates how much user $u$ prefers item $i$ than item $j$. The optimization process
    is performed in the same manner as CDL.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\delta_{uij}=r_{ui}-r_{uj}$ 表示用户对物品 $i$ 和物品 $j$ 偏好的成对关系，$C_{uij}^{-1}$ 是一个置信度值，表明用户
    $u$ 更偏好物品 $i$ 而不是物品 $j$。优化过程与 CDL 相同。
- en: 'Deep Collaborative Filtering Framework. It is a general framework for unifying
    deep learning approaches with collaborative filtering model (Li et al., [2015](#bib.bib89)).
    This framework makes it easily to utilize deep feature learning techniques to
    build hybrid collaborative models. The aforementioned work such as  (Wang et al.,
    [2015b](#bib.bib160); Wang and Wang, [2014](#bib.bib168); Van den Oord et al.,
    [2013](#bib.bib154)) can be viewed as special cases of this general framework.
    Formally, the deep collaborative filtering framework is defined as follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 深度协同过滤框架。这是一个将深度学习方法与协同过滤模型统一的通用框架（Li 等人，[2015](#bib.bib89)）。该框架使得利用深度特征学习技术构建混合协同模型变得更加容易。前述的工作如（Wang
    等人，[2015b](#bib.bib160); Wang 和 Wang，[2014](#bib.bib168); Van den Oord 等人，[2013](#bib.bib154)）可以视为这一通用框架的特例。具体来说，深度协同过滤框架定义如下：
- en: '| (11) |  | $\underset{U,V}{\arg\min}\ell(R,U,V)+\beta(\parallel U\parallel_{F}^{2}+\parallel
    V\parallel_{F}^{2})+\gamma\mathcal{L}(X,U)+\delta\mathcal{L}(Y,V)$ |  |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| (11) |  | $\underset{U,V}{\arg\min}\ell(R,U,V)+\beta(\parallel U\parallel_{F}^{2}+\parallel
    V\parallel_{F}^{2})+\gamma\mathcal{L}(X,U)+\delta\mathcal{L}(Y,V)$ |  |'
- en: 'where $\beta$, $\gamma$ and $\delta$ are trade-off parameters to balance the
    influences of these three components, $X$ and $Y$ are side information, $\ell(\cdot)$
    is the loss of collaborative filtering model. $\mathcal{L}(X,U)$ and $\mathcal{L}(Y,V)$
    act as hinges for connecting deep learning and collaborative models and link side
    information with latent factors. On top of this framework, the authors proposed
    the marginalized denoising autoencoder based collaborative filtering model (mDA-CF).
    Compared to CDL, mDA-CF explores a more computationally efficient variants of
    autoencoder: marginalized denoising autoencoder (Chen et al., [2012](#bib.bib16)).
    It saves the computational costs for searching sufficient corrupted version of
    input by marginalizing out the corrupted input, which makes mDA-CF more scalable
    than CDL. In addition, mDA-CF embeds content information of items and users while
    CDL only considers the effects of item features.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\beta$, $\gamma$ 和 $\delta$ 是平衡这三个组成部分影响的权衡参数，$X$ 和 $Y$ 是辅助信息，$\ell(\cdot)$
    是协同过滤模型的损失函数。$\mathcal{L}(X,U)$ 和 $\mathcal{L}(Y,V)$ 充当深度学习和协同模型的连接点，将辅助信息与潜在因子关联起来。在这个框架之上，作者提出了基于边缘去噪自编码器的协同过滤模型（mDA-CF）。与
    CDL 相比，mDA-CF 探索了更为高效的自编码器变体：边缘去噪自编码器（Chen 等人，[2012](#bib.bib16)）。通过边缘化损坏输入来节省计算成本，使得
    mDA-CF 比 CDL 更具可扩展性。此外，mDA-CF 嵌入了物品和用户的内容信息，而 CDL 只考虑了物品特征的影响。
- en: 'AutoSVD++ (Zhang et al., [2017](#bib.bib197)) makes use of contractive autoencoder (Rifai
    et al., [2011](#bib.bib123)) to learn item feature representations, then integrates
    them into the classic recommendation model, SVD++ (Koren, [2008](#bib.bib80)).
    The proposed model posses the following advantages: (1) compared to other autoencoders
    variants, contractive autoencoder captures the infinitesimal input variations;
    (2) it models the implicit feedback to further enhance the accuracy; (3) an efficient
    training algorithm is designed to reduce the training time.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: AutoSVD++（Zhang 等人，[2017](#bib.bib197)）利用收缩自编码器（Rifai 等人，[2011](#bib.bib123)）学习物品特征表示，然后将其集成到经典推荐模型
    SVD++ 中。该模型具有以下优势：（1）与其他自编码器变体相比，收缩自编码器捕捉了微小的输入变化；（2）模型了解隐式反馈以进一步提高准确性；（3）设计了有效的训练算法以减少训练时间。
- en: HRCD (Wei et al., [2016](#bib.bib171), [2017](#bib.bib172)) is a hybrid collaborative
    model based on autoencoder and timeSVD++ (Koren, [2010](#bib.bib81)). It is a
    time-aware model which uses SDAE to learn item representations from raw features
    and aims at solving the cold item problem.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: HRCD（Wei 等人，[2016](#bib.bib171), [2017](#bib.bib172)）是基于自编码器和 timeSVD++ 的混合协同模型（Koren，[2010](#bib.bib81)）。它是一个考虑时间因素的模型，利用
    SDAE 从原始特征学习物品表示，并旨在解决冷启动问题。
- en: 3.4\. Convolutional Neural Networks based Recommendation
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4\. 基于卷积神经网络的推荐系统
- en: Convolution Neural Networks are powerful in processing unstructured multimedia
    data with convolution and pool operations. Most of the CNNs based recommendation
    models utilize CNNs for feature extraction.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络在处理未结构化的多媒体数据时非常强大，通过卷积和池化操作实现。大多数基于 CNN 的推荐模型利用 CNNs 进行特征提取。
- en: Feature Representation Learning with CNNs. CNNs can be used for feature representation
    learning from multiple sources such as image, text, audio, video, etc.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 特征表示学习与 CNNs。CNNs 可以用于从多种来源（如图像、文本、音频、视频等）进行特征表示学习。
- en: 'CNNs for Image Feature Extraction. Wang et al. (Wang et al., [2017](#bib.bib166))
    investigated the influences of visual features to Point-of-Interest (POI) recommendation,
    and proposed a visual content enhanced POI recommender system (VPOI). VPOI adopts
    CNNs to extract image features. The recommendation model is built on PMF by exploring
    the interactions between: (1) visual content and latent user factor; (2) visual
    content and latent location factor. Chu et al. (Chu and Tsai, [2017](#bib.bib26))
    exploited the effectiveness of visual information (e.g. images of food and furnishings
    of the restaurant) in restaurant recommendation. The visual features extracted
    by CNN joint with the text representation are input into MF, BPRMF and FM to test
    their performance. Results show that visual information improves the performance
    to some degree but not significant. He et al. (He and McAuley, [2016b](#bib.bib51))
    designed a visual Bayesian personalized ranking (VBPR) algorithm by incorporating
    visual features (learned via CNNs) into matrix factorization. He et al. (He and
    McAuley, [2016a](#bib.bib50)) extended VBPR with exploring user’s fashion awareness
    and the evolution of visual factors that user considers when selecting items.
    Yu et al. (Yu et al., [2018](#bib.bib192)) proposed a coupled matrix and tensor
    factorization model for aesthetic-based clothing recommendation, in which CNNs
    is used to learn the images features and aesthetic features. Nguyen et al. (Nguyen
    et al., [2017](#bib.bib111)) proposed a personalized tag recommendation model
    based on CNNs. It utilizes the convolutional and max-pooling layer to get visual
    features from patches of images. User information is injected for generating personalized
    recommendation. To optimize this network, the BPR objective is adopted to maximize
    the differences between the relevant and irrelevant tags. Lei et al. (Lei et al.,
    [2016](#bib.bib85)) proposed a comparative deep leaning model with CNNs for image
    recommendation. This network consists of two CNNs which are used for image representation
    learning and a MLP for user preferences modelling. It compares two images (one
    positive image user likes and one negative image user dislikes) against a user.
    The training data is made up of triplets: $t$ (user $U_{t}$, positive image $I^{+}_{t}$,
    negative image $I^{-}_{t}$). Assuming that the distance between user and positive
    image $D(\pi(U_{t}),\phi(I^{+}_{t}))$ should be closer than the distance between
    user and negative images $D(\pi(U_{t}),\phi(I^{-}_{t}))$, where $D(\cdot)$ is
    the distance metric (e.g. Euclidean distance). ConTagNet (Rawat and Kankanhalli,
    [2016](#bib.bib119)) is a context-aware tag recommender system. The image features
    are learned by CNNs. The context representations are processed by a two layers
    fully-connected feedforward neural network. The outputs of two neural networks
    are concatenated and fed into a softmax funcation to predict the probability of
    candidate tags.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图像特征提取中的CNNs。Wang 等人（Wang et al., [2017](#bib.bib166)）研究了视觉特征对兴趣点（POI）推荐的影响，并提出了一种视觉内容增强的POI推荐系统（VPOI）。VPOI
    采用 CNNs 提取图像特征。推荐模型基于 PMF，探索了以下两个方面的交互关系：（1）视觉内容与潜在用户因子；（2）视觉内容与潜在位置因子。Chu 等人（Chu
    and Tsai, [2017](#bib.bib26)）利用了视觉信息（例如餐厅的食物图片和装潢）在餐厅推荐中的有效性。将 CNN 提取的视觉特征与文本表示结合，输入到
    MF、BPRMF 和 FM 中以测试其性能。结果表明，视觉信息在一定程度上改善了性能，但提升不显著。He 等人（He and McAuley, [2016b](#bib.bib51)）设计了一种视觉贝叶斯个性化排名（VBPR）算法，通过将视觉特征（通过
    CNNs 学习）纳入矩阵分解中。He 等人（He and McAuley, [2016a](#bib.bib50)）扩展了 VBPR，探索了用户的时尚意识及其在选择项目时考虑的视觉因素的演变。Yu
    等人（Yu et al., [2018](#bib.bib192)）提出了一种结合矩阵和张量分解的美学基础服装推荐模型，其中 CNNs 用于学习图像特征和美学特征。Nguyen
    等人（Nguyen et al., [2017](#bib.bib111)）提出了一种基于 CNNs 的个性化标签推荐模型。该模型利用卷积层和最大池化层从图像片段中提取视觉特征。通过注入用户信息生成个性化推荐。为了优化该网络，采用了
    BPR 目标，以最大化相关标签和无关标签之间的差异。Lei 等人（Lei et al., [2016](#bib.bib85)）提出了一种结合 CNNs 的比较深度学习模型用于图像推荐。该网络由两个
    CNN 组成，用于图像表示学习，以及一个 MLP 用于用户偏好建模。它比较了两张图像（用户喜欢的正面图像和用户不喜欢的负面图像）。训练数据由三元组组成：$t$（用户
    $U_{t}$，正面图像 $I^{+}_{t}$，负面图像 $I^{-}_{t}$）。假设用户与正面图像 $D(\pi(U_{t}),\phi(I^{+}_{t}))$
    之间的距离应比用户与负面图像 $D(\pi(U_{t}),\phi(I^{-}_{t}))$ 之间的距离更近，其中 $D(\cdot)$ 是距离度量（例如欧几里得距离）。ConTagNet（Rawat
    and Kankanhalli, [2016](#bib.bib119)）是一个上下文感知的标签推荐系统。图像特征由 CNNs 学习。上下文表示由两层全连接前馈神经网络处理。两个神经网络的输出被连接并输入到
    softmax 函数中，以预测候选标签的概率。
- en: CNNs for Text Feature Extraction. DeepCoNN (Zheng et al., [2017](#bib.bib203))
    adopts two parallel CNNs to model user behaviors and item properties from review
    texts. This model alleviates the sparsity problem and enhances the model interpretability
    by exploiting rich semantic representations of review texts with CNNs. It utilizes
    a word embedding technique to map the review texts into a lower-dimensional semantic
    space as well as keep the words sequences information. The extracted review representations
    then pass through a convolutional layer with different kernels, a max-pooling
    layer, and a full-connected layer consecutively. The output of the user network
    $x_{u}$ and item network $x_{i}$ are finally concatenated as the input of the
    prediction layer where the factorization machine is applied to capture their interactions
    for rating prediction. Catherine et al. (Catherine and Cohen, [2017](#bib.bib12))
    mentioned that DeepCoNN only works well when the review text written by the target
    user for the target item is available at test time, which is unreasonable. As
    such, they extended it by introducing a latent layer to represent the target user-target-item
    pair. This model does not access the reviews during validation/test and can still
    remain good accuracy. Shen et al. (Shen et al., [2016](#bib.bib131)) built an
    e-learning resources recommendation model. It uses CNNs to extract item features
    from text information of learning resources such as introduction and content of
    learning material, and follows the same procedure of (Van den Oord et al., [2013](#bib.bib154))
    to perform recommendation. ConvMF (Kim et al., [2016](#bib.bib76)) combines CNNs
    with PMF in a similar way as CDL. CDL uses autoencoder to learn the item feature
    representations, while ConvMF employs CNNs to learn high level item representations.
    The main advantage of ConvMF over CDL is that CNNs is able to capture more accurate
    contextual information of items via word embedding and convolutional kernels.
    Tuan et al. (Tuan and Phuong, [2017](#bib.bib149)) proposed using CNNs to learn
    feature representations form item content information (e.g., name, descriptions,
    identifier and category) to enhance the accuracy of session based recommendation.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 文本特征提取的CNNs。DeepCoNN（Zheng等人，[2017](#bib.bib203)）采用两个并行CNN来建模来自评论文本的用户行为和物品属性。该模型通过利用CNN对评论文本的丰富语义表示，缓解了稀疏问题，并增强了模型的可解释性。它利用词嵌入技术将评论文本映射到较低维度的语义空间，并保留词序列信息。提取的评论表示然后依次通过卷积层、最大池化层和全连接层。最终用户网络的输出$x_{u}$和物品网络的输出$x_{i}$被串联作为预测层的输入，在此处应用因子分解机以捕捉它们的交互以进行评分预测。Catherine等人（Catherine和Cohen，[2017](#bib.bib12)）提到DeepCoNN只在测试时目标用户对目标物品的评论文本可用时才表现良好，这是不合理的。因此，他们通过引入潜在层来扩展它以表示目标用户-目标物品对。该模型在验证/测试期间不访问评论仍然能保持良好的准确性。Shen等人（Shen等人，[2016](#bib.bib131)）构建了一个电子学习资源推荐模型。它使用CNN从学习资源的文本信息（如学习材料的介绍和内容）中提取物品特征，并按照Van den
    Oord等人（[2013](#bib.bib154)）的相同过程进行推荐。ConvMF（Kim等人，[2016](#bib.bib76)）以与CDL类似的方式将CNN与PMF结合。CDL使用自编码器学习物品特征表示，而ConvMF则利用CNN学习高级别的物品表示。ConvMF相对于CDL的主要优势在于，CNN能够通过词嵌入和卷积核捕捉更精确的物品上下文信息。Tuan等人（Tuan和Phuong，[2017](#bib.bib149)）提出使用CNN来学习物品内容信息（例如名称、描述、标识符和类别）的特征表示，以增强基于会话的推荐的准确性。
- en: CNNs for Audio and Video Feature Extraction. Van et al. (Van den Oord et al.,
    [2013](#bib.bib154)) proposed using CNNs to extract features from music signals.
    The convolutional kernels and pooling layers allow operations at multiple timescales.
    This content-based model can alleviate the cold start problem (music has not been
    consumed) of music recommendation. Lee et al. (Lee et al., [2018](#bib.bib84))
    proposed extracting audio features with the prominent CNNs model ResNet. The recommendation
    is performed in the collaborative metric learning framework similar to CML.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 音频和视频特征提取的CNNs。Van等人（Van den Oord等人，[2013](#bib.bib154)）提出使用CNN从音乐信号中提取特征。卷积核和池化层允许在多个时间尺度上进行操作。这种基于内容的模型可以缓解音乐推荐的冷启动问题（音乐尚未被消费）。Lee等人（Lee等人，[2018](#bib.bib84)）提出使用突出的CNN模型ResNet提取音频特征。推荐是在类似于CML的协作度量学习框架中执行。
- en: CNNs based Collaborative filtering. Directly applying CNNs to vanilla collaborative
    filtering is also viable. For example, He et al. (He et al., [2018a](#bib.bib52))
    proposed using CNNs to improve NCF and presented the ConvNCF. It uses outer product
    instead of dot product to model the user item interaction patterns. CNNs are applied
    over the result of outer product and could capture the high-order correlations
    among embeddings dimensions. Tang et al. (Tang and Wang, [2018a](#bib.bib144))
    presented sequential recommendation (with user identifier) with CNNs, where two
    CNNs (hierarchical and vertical) are used to model the union-level sequential
    patterns and skip behaviors for sequence-aware recommendation.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 CNN 的协同过滤。直接将 CNN 应用于传统协同过滤也是可行的。例如，He 等人（He 等人，[2018a](#bib.bib52)）提出使用
    CNN 改进 NCF，并介绍了 ConvNCF。该方法使用外积代替点积来建模用户与项目的交互模式。CNN 应用于外积的结果上，能够捕捉嵌入维度之间的高阶相关性。Tang
    等人（Tang 和 Wang，[2018a](#bib.bib144)）提出了基于 CNN 的序列推荐（使用用户标识符），其中使用两个 CNN（层级和垂直）来建模联合级别的序列模式和跳过行为，以实现对序列的感知推荐。
- en: 'Graph CNNs for Recommendation. Graph convolutional Networks is a powerful tool
    for non-Eulcidean data such as: social networks, knowledge graphs, protein-interaction
    networks, etc (Kipf and Welling, [2016](#bib.bib78)). Interactions in recommendation
    area can also be viewed as a such structured dataset (bipartite graph). Thus,
    it can also be applied to recommendation tasks. For example, Berg et al. (Berg
    et al., [2017](#bib.bib7)) proposed considering the recommendation problem as
    a link prediction task with graph CNNs. This framework makes it easy to integrate
    user/item side information such as social networks and item relationships into
    recommendation model. Ying et al. (Ying et al., [2018a](#bib.bib191)) proposed
    using graph CNNs for recommendations in Pinterest^(10)^(10)10https://www.pinterest.com.
    This model generates item embeddings from both graph structure as well item feature
    information with random walk and graph CNNs, and is suitable for very large-scale
    web recommender. The proposed model has been deployed in Pinterest to address
    a variety of real-world recommendation tasks.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图卷积网络用于推荐系统。图卷积网络是处理非欧几里得数据（如社交网络、知识图谱、蛋白质互动网络等）的强大工具（Kipf 和 Welling，[2016](#bib.bib78)）。推荐领域中的交互也可以视为这样的结构化数据集（双分图）。因此，它也可以应用于推荐任务。例如，Berg
    等人（Berg 等人，[2017](#bib.bib7)）提出将推荐问题视为带图卷积网络的链接预测任务。这一框架使得将用户/项目侧信息（如社交网络和项目关系）整合到推荐模型中变得容易。Ying
    等人（Ying 等人，[2018a](#bib.bib191)）建议在 Pinterest^(10)^(10)10https://www.pinterest.com
    使用图卷积网络进行推荐。该模型从图结构和项目特征信息中生成项目嵌入，结合随机游走和图卷积网络，适用于大规模网页推荐。该模型已在 Pinterest 部署，以解决各种现实世界的推荐任务。
- en: 3.5\. Recurrent Neural Networks based Recommendation
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于递归神经网络的推荐
- en: RNNs are extremely suitable for sequential data processing. As such, it becomes
    a natural choice for dealing with the temporal dynamics of interactions and sequential
    patterns of user behaviours, as well as side information with sequential signals,
    such as texts, audio, etc.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: RNN 非常适合处理序列数据。因此，它成为处理交互的时间动态和用户行为的序列模式，以及带有序列信号的侧信息（如文本、音频等）的自然选择。
- en: Session-based Recommendation without User Identifier. In many real world applications
    or websites, the system usually does not bother users to log in so that it has
    no access to user’s identifier and her long period consumption habits or long-term
    interests. However, the session or cookie mechanisms enables those systems to
    get user’s short term preferences. This is a relatively unappreciated task in
    recommender systems due to the extreme sparsity of training data. Recent advancements
    have demonstrated the efficacy of RNNs in solving this issue (Hidasi et al., [2015](#bib.bib57);
    Tan et al., [2016b](#bib.bib143); Wu et al., [2016b](#bib.bib177)).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 基于会话的推荐而不使用用户标识符。在许多现实世界的应用或网站中，系统通常不会要求用户登录，因此无法访问用户的标识符及其长期消费习惯或长期兴趣。然而，会话或
    Cookie 机制使这些系统能够获取用户的短期偏好。这是推荐系统中一个相对不被重视的任务，因为训练数据的稀疏性极高。最近的进展已经证明了 RNN 在解决这个问题上的有效性（Hidasi
    等人，[2015](#bib.bib57)；Tan 等人，[2016b](#bib.bib143)；Wu 等人，[2016b](#bib.bib177)）。
- en: 'GRU4Rec. Hidasi et al. (Hidasi et al., [2015](#bib.bib57)) proposed a session-based
    recommendation model, GRU4Rec, based GRU (shown in Figure [6](#S3.F6 "Figure 6
    ‣ 3.5\. Recurrent Neural Networks based Recommendation ‣ 3\. Deep Learning Based
    Recommendation: State-of-the-art ‣ Deep Learning based Recommender System: A Survey
    and New Perspectives")a). The input is the actual state of session with 1-of-$N$
    encoding, where $N$ is the number of items. The coordinate will be 1 if the corresponding
    item is active in this session, otherwise 0\. The output is the likelihood of
    being the next in the session for each item. To efficiently train the proposed
    framework, the authors proposed a session-parallel mini-batches algorithm and
    a sampling method for output. The ranking loss which is also coined TOP1 and has
    the following form:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 'GRU4Rec。Hidasi 等人 (Hidasi et al., [2015](#bib.bib57)) 提出了一个基于会话的推荐模型 GRU4Rec，该模型基于
    GRU (如图 [6](#S3.F6 "Figure 6 ‣ 3.5\. Recurrent Neural Networks based Recommendation
    ‣ 3\. Deep Learning Based Recommendation: State-of-the-art ‣ Deep Learning based
    Recommender System: A Survey and New Perspectives")a) 。输入是会话的实际状态，使用 1-of-$N$
    编码，其中 $N$ 是物品的数量。如果相应的物品在此会话中处于活动状态，则坐标为 1，否则为 0。输出是每个物品在会话中成为下一个物品的可能性。为了有效地训练所提出的框架，作者提出了一种会话并行小批量算法和输出采样方法。排名损失也称为
    TOP1，具有以下形式：'
- en: '| (12) |  | $\mathcal{L}_{s}=\frac{1}{S}\sum_{j=1}^{S}\sigma(\hat{r}_{sj}-\hat{r}_{si})+\sigma(\hat{r}_{sj}^{2})$
    |  |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| (12) |  | $\mathcal{L}_{s}=\frac{1}{S}\sum_{j=1}^{S}\sigma(\hat{r}_{sj}-\hat{r}_{si})+\sigma(\hat{r}_{sj}^{2})$
    |  |'
- en: 'where $S$ is the sample size, $\hat{r}_{si}$ and $\hat{r}_{sj}$ are the scores
    on negative item $i$ and positive item $j$ at session $s$, $\sigma$ is the logistic
    sigmoid function. The last term is used as a regularization. Note that, BPR loss
    is also viable. A recent work (Hidasi and Karatzoglou, [2017](#bib.bib56)) found
    that the original TOP1 loss and BPR loss defined in (Hidasi et al., [2015](#bib.bib57))
    suffer from the gradient vanishing problem, as such, two novel loss functions:
    TOP1-max and BPR-max are proposed.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $S$ 是样本大小，$\hat{r}_{si}$ 和 $\hat{r}_{sj}$ 分别是会话 $s$ 中负物品 $i$ 和正物品 $j$ 的得分，$\sigma$
    是逻辑 sigmoid 函数。最后一项用作正则化。注意，BPR 损失也是可行的。最近的工作 (Hidasi 和 Karatzoglou, [2017](#bib.bib56))
    发现原始的 TOP1 损失和 BPR 损失在 (Hidasi et al., [2015](#bib.bib57)) 中存在梯度消失问题，因此提出了两种新颖的损失函数：TOP1-max
    和 BPR-max。
- en: 'The follow-up work (Tan et al., [2016b](#bib.bib143)) proposed several strategies
    to further improve this model: (1) augment the click sequences with sequence preprocessing
    and dropout regularization; (2) adapt to temporal changes by pre-training with
    full training data and fine-tuning the model with more recent click-sequences;
    (3) distillation the model with privileged information with a teacher model; (4)
    using item embedding to decrease the number of parameters for faster computation.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 后续工作 (Tan et al., [2016b](#bib.bib143)) 提出了几种策略来进一步改进该模型：(1) 通过序列预处理和 dropout
    正则化来增强点击序列；(2) 通过用完整的训练数据进行预训练，并用最新的点击序列进行微调来适应时间变化；(3) 使用教师模型对模型进行蒸馏，以获取特权信息；(4)
    使用物品嵌入以减少参数数量，从而加快计算速度。
- en: Wu et al. (Wu et al., [2016b](#bib.bib177)) designed a session-based recommendation
    model for real-world e-commerce website. It utilizes the basic RNNs to predict
    what user will buy next based on the click history. To minimize the computation
    costs, it only keeps a finite number of the latest states while collapsing the
    older states into a single history state. This method helps to balance the trade-off
    between computation costs and prediction accuracy. Quadrana et al. (Quadrana et al.,
    [2017](#bib.bib118)) presented a hierarchical recurrent neural network for session-based
    recommendation. This model can deal with both session-aware recommendation when
    user identifiers are present.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: Wu 等人 (Wu et al., [2016b](#bib.bib177)) 设计了一个基于会话的推荐模型，用于现实世界的电子商务网站。它利用基本的
    RNNs 预测用户下一个购买的物品，基于点击历史。为了减少计算成本，它仅保留有限数量的最新状态，同时将较旧的状态合并为一个单一的历史状态。这种方法有助于平衡计算成本和预测准确性的权衡。Quadrana
    等人 (Quadrana et al., [2017](#bib.bib118)) 提出了一个用于基于会话推荐的层次递归神经网络。该模型可以处理存在用户标识符的会话感知推荐。
- en: The aforementioned three session-based models do not consider any side information.
    Two extensions (Hidasi et al., [2016](#bib.bib58); Smirnova and Vasile, [2017](#bib.bib133))
    demonstrate that side information has effect on enhancing session recommendation
    quality. Hidasi et al. (Hidasi et al., [2016](#bib.bib58)) introduced a parallel
    architecture for session-based recommendation which utilizes three GRUs to learn
    representations from identity one-hot vectors, image feature vectors and text
    feature vectors. The outputs of these three GRUs are weightedly concatenated and
    fed into a non-linear activation to predict the next items in that session. Smirnova
    et al. (Smirnova and Vasile, [2017](#bib.bib133)) proposed a context-aware session-based
    recommender system based on conditional RNNs. It injects context information into
    input and output layers. Experimental results of these two models suggest that
    models incorporated additional information outperform those solely based on historical
    interactions.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 前述的三种会话模型并未考虑任何附加信息。两个扩展研究（Hidasi et al., [2016](#bib.bib58)；Smirnova and Vasile,
    [2017](#bib.bib133)）证明了附加信息对提高会话推荐质量的影响。Hidasi等人（Hidasi et al., [2016](#bib.bib58)）引入了一种会话推荐的并行架构，该架构利用三个GRU从身份独热向量、图像特征向量和文本特征向量中学习表示。这三个GRU的输出被加权拼接，并输入到非线性激活函数中，以预测该会话中的下一个项目。Smirnova等人（Smirnova
    and Vasile, [2017](#bib.bib133)）提出了一种基于条件RNN的上下文感知会话推荐系统。该系统将上下文信息注入输入层和输出层。这两种模型的实验结果表明，融入附加信息的模型在性能上优于那些仅基于历史交互的模型。
- en: Despite the success of RNNs in session-based recommendation, Jannach et al. (Jannach
    and Ludewig, [2017](#bib.bib69)) indicated that simple neighbourhood approach
    could achieve same accuracy results as GRU4Rec. Combining the neighbourhood with
    RNNs methods can usually lead to best performance. This work suggests that some
    baselines in recent works are not well-justified and correctly evaluated. A more
    comprehensive discussion can be found in (Ludewig and Jannach, [2018](#bib.bib104)).
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管RNN在会话推荐中取得了成功，Jannach等人（Jannach and Ludewig, [2017](#bib.bib69)）指出，简单的邻域方法可以达到与GRU4Rec相同的准确度结果。将邻域方法与RNN方法结合通常能得到最佳性能。这项工作表明，一些最近工作的基线并没有得到充分的合理化和正确评估。更全面的讨论可以参考（Ludewig
    and Jannach, [2018](#bib.bib104)）。
- en: Sequential Recommendation with User Identifier. Unlike session-based recommender
    where user identifiers are usually not present. The following studies deal with
    the sequential recommendation task with known user identifications.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 带有用户标识的序列推荐。与通常不包含用户标识的会话推荐系统不同。以下研究处理的是已知用户标识的序列推荐任务。
- en: 'Recurrent Recommender Network (RRN) (Wu et al., [2017](#bib.bib176)) is a non-parametric
    recommendation model built on RNNs (shown in Figure [6](#S3.F6 "Figure 6 ‣ 3.5\.
    Recurrent Neural Networks based Recommendation ‣ 3\. Deep Learning Based Recommendation:
    State-of-the-art ‣ Deep Learning based Recommender System: A Survey and New Perspectives")b).
    It is capable of modelling the seasonal evolution of items and changes of user
    preferences over time. RRN uses two LSTM networks as the building block to model
    dynamic user state $u_{ut}$ and item state $v_{it}$. In the meantime, considering
    the fixed properties such as user long-term interests and item static features,
    the model also incorporates the stationary latent attributes of user and item:
    $u_{u}$ and $v_{i}$. The predicted rating of item $j$ given by user $i$ at time
    $t$ is defined as:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '循环推荐网络（RRN）（Wu et al., [2017](#bib.bib176)）是一个基于RNN的非参数推荐模型（见图 [6](#S3.F6 "Figure
    6 ‣ 3.5\. Recurrent Neural Networks based Recommendation ‣ 3\. Deep Learning Based
    Recommendation: State-of-the-art ‣ Deep Learning based Recommender System: A Survey
    and New Perspectives")b）。它能够建模物品的季节性演变和用户偏好的变化。RRN使用两个LSTM网络作为构建块来建模动态用户状态 $u_{ut}$
    和物品状态 $v_{it}$。同时，考虑到用户长期兴趣和物品静态特征等固定属性，该模型还融入了用户和物品的固定潜在属性：$u_{u}$ 和 $v_{i}$。用户
    $i$ 在时间 $t$ 对物品 $j$ 的预测评分定义为：'
- en: '| (13) |  | $\hat{r}_{ui&#124;t}=f(u_{ut},v_{it},u_{u},v_{i})$ |  |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| (13) |  | $\hat{r}_{ui&#124;t}=f(u_{ut},v_{it},u_{u},v_{i})$ |  |'
- en: where $u_{ut}$ and $v_{it}$ are learned from LSTM, $u_{u}$ and $v_{i}$ are learned
    by the standard matrix factorization. The optimization is to minimize the square
    error between predicted and actual rating values.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$u_{ut}$ 和 $v_{it}$ 从LSTM中学习得到，$u_{u}$ 和 $v_{i}$ 则通过标准矩阵分解学习得到。优化目标是最小化预测值与实际评分值之间的平方误差。
- en: 'Wu et al. (Wu et al., [2016](#bib.bib175)) further improved the RRNs model
    by modelling text reviews and ratings simultaneously. Unlike most text review
    enhanced recommendation models (Zheng et al., [2017](#bib.bib203); Seo et al.,
    [2017b](#bib.bib128)), this model aims to generate reviews with a character-level
    LSTM network with user and item latent states. The review generation task can
    be viewed as an auxiliary task to facilitate rating prediction. This model is
    able to improve the rating prediction accuracy, but cannot generate coherent and
    readable review texts. NRT (Li et al., [2017](#bib.bib88)) which will be introduced
    in the following text can generate readable review tips. Jing et al. (Jing and
    Smola, [2017](#bib.bib74)) proposed a multi-task learning framework to simultaneously
    predict the returning time of users and recommend items. The returning time prediction
    is motivated by a survival analysis model designed for estimating the probability
    of survival of patients. The authors modified this model by using LSTM to estimate
    the returning time of costumers. The item recommendation is also performed via
    LSTM from user’s past session actions. Unlike aforementioned session-based recommendations
    which focus on recommending in the same session, this model aims to provide inter-session
    recommendations. Li et al. (Li et al., [2018](#bib.bib92)) presented a behavior-intensive
    model for sequential recommendation. This model consists of two components: neural
    item embedding and discriminative behaviors learning. The latter part is made
    up of two LSTMs for session and preference behaviors learning respectively. Christakopoulou
    et al. (Christakopoulou et al., [2018](#bib.bib25)) designed an interactive recommender
    with RNNs. The proposed framework aims to address two critical tasks in interactive
    recommender: ask and respond. RNNs are used to tackle both tasks: predict questions
    that the user might ask based on her recent behaviors(e.g, watch event) and predict
    the responses. Donkers et al. (Donkers et al., [2017](#bib.bib36)) designed a
    novel type of Gated Recurrent Unit to explicit represent individual user for next
    item recommendation.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 吴等人（Wu et al., [2016](#bib.bib175)）通过同时建模文本评论和评分进一步改进了RRNs模型。与大多数增强文本评论推荐模型不同 （Zheng
    et al., [2017](#bib.bib203); Seo et al., [2017b](#bib.bib128)）, 这个模型旨在利用基于字符级LSTM网络的用户和项目潜在状态来生成评论。评论生成任务可视为促进评分预测的辅助任务。这个模型能够提高评分预测的准确性，但不能生成连贯和可读的评论文本。接下来将介绍的NRT （Li
    et al., [2017](#bib.bib88)）能够生成可读的评论提示。荆等人（Jing and Smola, [2017](#bib.bib74)）提出了一个多任务学习框架，同时预测用户的返回时间和推荐项目。返回时间预测受到生存分析模型的启发，该模型设计用于估计患者生存的概率。作者通过使用LSTM来估计顾客的返回时间来修改此模型。项目推荐也通过LSTM从用户过去的会话操作中进行。与侧重于在同一会话中推荐的前述会话推荐不同，这个模型旨在提供会话间推荐。李等人（Li
    et al., [2018](#bib.bib92)）提出了一个行为密集型顺序推荐模型。该模型由两部分组成：神经项目嵌入和区分行为学习。后者由两个LSTM分别用于会话和偏好行为学习。克里斯塔科普洛（Christakopoulou
    et al., [2018](#bib.bib25)）设计了一个带有RNN的交互式推荐系统。提出的框架旨在解决交互式推荐系统中的两个关键任务：提问和回应。RNN被用于处理两个任务：基于用户最近行为（例如观看事件）预测用户可能会提出的问题，并预测回应。唐克斯等人（Donkers
    et al., [2017](#bib.bib36)）设计了一种新型门控循环单元，明确表示个别用户用于下一个项目推荐。
- en: '![Refer to caption](img/d372f566330bc0079081b64bb1be9472.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/d372f566330bc0079081b64bb1be9472.png)'
- en: (a)
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/ea508cc8d34d25cc3f928cee7048e72f.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/ea508cc8d34d25cc3f928cee7048e72f.png)'
- en: (b)
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: '![Refer to caption](img/224f4cd5049cdfc7b6e684ec407fdd0e.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/224f4cd5049cdfc7b6e684ec407fdd0e.png)'
- en: (c)
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: (c)
- en: 'Figure 6\. Illustration of: (a) Session-based recommendation with RNN; (b)
    Recurrent recommender network; (c) Restricted Boltzmann Machine based Collaborative
    Filtering.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图6\. 描述：(a) 基于会话的推荐与RNN; (b) 循环推荐网络; (c) 基于受限玻尔兹曼机的协同过滤。
- en: Feature Representation Learning with RNNs. For side information with sequential
    patterns, using RNNs as the representation learning tool is an advisable choice.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 使用RNN进行特征表示学习。对于具有序列模式的侧信息，使用RNN作为表示学习工具是一个明智的选择。
- en: Dai et al. (Dai et al., [2016b](#bib.bib30)) presented a co-evolutionary latent
    model to capture the co-evolution nature of users’ and items’ latent features.
    The interactions between users and items play an important role in driving the
    changes of user preferences and item status. To model the historical interactions,
    the author proposed using RNNs to automatically learn representations of the influences
    from drift, evolution and co-evolution of user and item features.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: Dai等人（Dai et al., [2016b](#bib.bib30)）提出了一种共演化潜在模型，以捕捉用户和项目潜在特征的共演化特性。用户和项目之间的互动在推动用户偏好和项目状态变化方面起着重要作用。为了建模历史互动，作者建议使用RNNs自动学习用户和项目特征的漂移、演变和共演化的影响表示。
- en: Bansal et al. (Bansal et al., [2016](#bib.bib6)) proposed using GRUs to encode
    the text sequences into latent factor model. This hybrid model solves both warm-start
    and cold-start problems. Furthermore, the authors adopted a multi-task regularizer
    to prevent overfitting and alleviate the sparsity of training data. The main task
    is rating prediction while the auxiliary task is item meta-data (e.g. tags, genres)
    prediction.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: Bansal等人（Bansal et al., [2016](#bib.bib6)）提出使用GRUs将文本序列编码为潜在因素模型。该混合模型解决了温启动和冷启动问题。此外，作者采用了多任务正则化器，以防止过拟合并缓解训练数据的稀疏性。主要任务是评分预测，而辅助任务是项目元数据（例如标签、类别）预测。
- en: Okura et al. (Okura et al., [2017](#bib.bib114)) proposed using GRUs to learn
    more expressive aggregation for user browsing history (browsed news), and recommend
    news articles with latent factor model. The results show a significant improvement
    compared with the traditional word-based approach. The system has been fully deployed
    to online production services and serving over ten million unique users everyday.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: Okura等人（Okura et al., [2017](#bib.bib114)）提出使用GRUs来学习用户浏览历史（浏览过的新闻）的更具表现力的聚合，并推荐基于潜在因素模型的新闻文章。结果显示，与传统的基于词的方法相比，显著提高了性能。该系统已全面部署到在线生产服务中，每天为超过一千万个独立用户提供服务。
- en: Li et al. (Li et al., [2017](#bib.bib88)) presented a multitask learning framework,
    NRT, for predicting ratings as well as generating textual tips for users simultaneously.
    The generated tips provide concise suggestions and anticipate user’s experience
    and feelings on certain products. The rating prediction task is modelled by non-linear
    layers over item and user latent factors $U\in\mathbb{R}^{k_{u}\times M}$, $V\in\mathbb{R}^{k_{v}\times
    M}$, where $k_{u}$ and $k_{v}$ (not necessarily equal) are latent factor dimensions
    for users and items. The predicted rating $r_{ui}$ and two latent factor matrices
    are fed into a GRU for tips generation. Here, $r_{ui}$ is used as context information
    to decide the sentiment of the generated tips. The multi-task learning framework
    enables the whole model to be trained efficiently in an end-to-end paradigm.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: Li等人（Li et al., [2017](#bib.bib88)）提出了一种多任务学习框架NRT，用于同时预测评分和生成用户的文本建议。生成的建议提供简洁的建议，并预测用户对某些产品的体验和感受。评分预测任务通过对项目和用户潜在因素
    $U\in\mathbb{R}^{k_{u}\times M}$、$V\in\mathbb{R}^{k_{v}\times M}$ 上的非线性层进行建模，其中
    $k_{u}$ 和 $k_{v}$（不一定相等）是用户和项目的潜在因素维度。预测评分 $r_{ui}$ 和两个潜在因素矩阵被输入到GRU中以生成建议。在这里，$r_{ui}$
    用作上下文信息，以决定生成建议的情感。多任务学习框架使整个模型能够在端到端范式下高效训练。
- en: Song et al. (Song et al., [2016](#bib.bib136)) designed a temporal DSSM model
    which integrates RNNs into DSSM for recommendation. Based on traditional DSSM,
    TDSSM replace the left network with item static features, and the right network
    with two sub-networks to modelling user static features (with MLP) and user temporal
    features (with RNNs).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: Song等人（Song et al., [2016](#bib.bib136)）设计了一种时间序列DSSM模型，将RNNs集成到DSSM中以进行推荐。基于传统DSSM，TDSSM将左网络替换为项目静态特征，将右网络替换为两个子网络，以建模用户静态特征（使用MLP）和用户时间特征（使用RNNs）。
- en: 3.6\. Restricted Boltzmann Machine based Recommendation
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.6\. 基于限制玻尔兹曼机的推荐
- en: 'Salakhutdinov et al. (Salakhutdinov et al., [2007](#bib.bib124)) proposed a
    restricted Boltzmann machine based recommender (shown in Figure [6](#S3.F6 "Figure
    6 ‣ 3.5\. Recurrent Neural Networks based Recommendation ‣ 3\. Deep Learning Based
    Recommendation: State-of-the-art ‣ Deep Learning based Recommender System: A Survey
    and New Perspectives")c). To the best of our knowledge, it is the first recommendation
    model that built on neural networks. The visible unit of RBM is limited to binary
    values, therefore, the rating score is represented in a one-hot vector to adapt
    to this restriction. For example, [0,0,0,1,0] represents that the user gives a
    rating score 4 to this item. Let $h_{j},j=1,...,F$ denote the hidden units with
    fixed size $F$. Each user has a unique RBM with shared parameters. Suppose a user
    rated $m$ movies, the number of visible units is $m$, Let $X$ be a $K\times m$
    matrix where $x_{i}^{y}=1$ if user $u$ rated movie $i$ as $y$ and $x_{i}^{y}=0$
    otherwise. Then:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: Salakhutdinov 等人 (Salakhutdinov et al., [2007](https://doi.org/10.1162/neco.2009.10-08-881))
    提出了基于受限玻尔兹曼机的推荐系统（见图 [6](#S3.F6 "图 6 ‣ 3.5\. 基于递归神经网络的推荐 ‣ 3\. 基于深度学习的推荐：现状 ‣
    基于深度学习的推荐系统：调查与新视角")c）。据我们所知，这是建立在神经网络上的第一个推荐模型。RBM 的可见单元仅限于二进制值，因此评分分数用一个独热向量表示以适应这一限制。例如，[0,0,0,1,0]
    表示用户给这个物品评分 4。设 $h_{j},j=1,...,F$ 表示具有固定大小 $F$ 的隐藏单元。每个用户都有一个带有共享参数的独特 RBM。假设一个用户评价了
    $m$ 部电影，则可见单元的数量为 $m$。设 $X$ 是一个 $K\times m$ 矩阵，其中如果用户 $u$ 给电影 $i$ 评分为 $y$，则 $x_{i}^{y}=1$，否则
    $x_{i}^{y}=0$。那么：
- en: '| (14) |  | $p(v_{i}^{y}=1&#124;h)=\frac{exp(b_{i}^{y}+\sum_{j=1}^{F}h_{j}W_{ij}^{y})}{\sum_{l=1}^{K}exp(b_{i}^{l}+\sum_{j=1}^{F}h_{j}W_{ij}^{l})}\,\,\,\,\,,\,\,\,\,\,p(h_{j}=1&#124;X)=\sigma(b_{j}+\sum_{i=1}^{m}\sum_{y=1}^{K}x_{i}^{y}W_{ij}^{y})$
    |  |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| (14) |  | $p(v_{i}^{y}=1&#124;h)=\frac{exp(b_{i}^{y}+\sum_{j=1}^{F}h_{j}W_{ij}^{y})}{\sum_{l=1}^{K}exp(b_{i}^{l}+\sum_{j=1}^{F}h_{j}W_{ij}^{l})}\,\,\,\,\,,\,\,\,\,\,p(h_{j}=1&#124;X)=\sigma(b_{j}+\sum_{i=1}^{m}\sum_{y=1}^{K}x_{i}^{y}W_{ij}^{y})$
    |  |'
- en: where $W_{ij}^{y}$ represents the weight on the connection between the rating
    $y$ of movie $i$ and the hidden unit $j$, $b_{i}^{y}$ is the bias of rating $y$
    for movie $i$, $b_{j}$ is the bias of hidden unit $j$. RBM is not tractable, but
    the parameters can be learned via the Contrastive Divergence (CD) algorithm (Goodfellow
    et al., [2016](#bib.bib46)). The authors further proposed using a conditional
    RBM to incorporate the implicit feedback. The essence here is that users implicitly
    tell their preferences by giving ratings, regardless of how they rate items.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $W_{ij}^{y}$ 表示电影 $i$ 的评分 $y$ 与隐藏单元 $j$ 之间的连接权重，$b_{i}^{y}$ 是电影 $i$ 的评分 $y$
    的偏置，$b_{j}$ 是隐藏单元 $j$ 的偏置。RBM 不易处理，但可以通过对比散度（CD）算法学习参数 (Goodfellow et al., [2016](https://doi.org/10.1016/j.dss.2020.113437))。作者进一步建议使用条件RBM来结合隐式反馈。这里的要点是，用户通过给予评分隐式表达了他们的偏好，而不管他们如何评价物品。
- en: 'The above RBM-CF is user-based where a given user’s rating is clamped on the
    visible layer. Similarity, we can easily design an item-based RBM-CF if we clamp
    a given item’s rating on the visible layer. Georgiev et al. (Georgiev and Nakov,
    [2013](#bib.bib43)) proposed to combine the user-based and item-based RBM-CF in
    a unified framework. In the case, the visible units are determined both by user
    and item hidden units. Liu et al. (Liu et al., [2015](#bib.bib101)) designed a
    hybrid RBM-CF which incorporates item features (item categories). This model is
    also based on conditional RBM. There are two differences between this hybrid model
    with the conditional RBM-CF with implicit feedback: (1) the conditional layer
    here is modelled with the binary item genres; (2) the conditional layer affects
    both the hidden layer and the visible layer with different connected weights.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 上述的 RBM-CF 是基于用户的，其中给定用户的评分固定在可见层上。类似地，如果我们在可见层上固定给定物品的评分，我们可以轻松设计基于物品的 RBM-CF。Georgiev
    等人 (Georgiev and Nakov, [2013](https://doi.org/10.1007/978-3-642-30220-6_32))
    提出将基于用户和基于物品的 RBM-CF 结合到统一的框架中。在这种情况下，可见单元由用户和物品的隐藏单元共同确定。Liu 等人 (Liu et al.,
    [2015](https://doi.org/10.1109/ICDM.2015.22)) 设计了一种混合 RBM-CF，该模型结合了物品特征（物品类别）。此模型还基于条件
    RBM。这种混合模型与具有隐式反馈的条件 RBM-CF 有两个不同之处：（1）这里的条件层使用了二进制物品流派来建模；（2）条件层影响了隐藏层和可见层，并且具有不同的连接权重。
- en: Table 4\. Categories of neural attention based recommendation models.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 4\. 基于神经注意力的推荐模型的分类。
- en: '| Vanilla Attention | Co-Attention |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: 原生注意力 | 协同注意力 |
- en: '| --- | --- |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| (Chen et al., [2017b](#bib.bib15); Tay et al., [2018a](#bib.bib146); Jhamb
    et al., [2018](#bib.bib71); Gong and Zhang, [2016](#bib.bib45); Seo et al., [2017b](#bib.bib128);
    Wang et al., [2017a](#bib.bib170); Li et al., [2016](#bib.bib91); Loyola et al.,
    [2017a](#bib.bib102); Liu et al., [2018](#bib.bib100); Ying et al., [2018b](#bib.bib190))
    | (Zhou et al., [2017](#bib.bib206); Zhang et al., [2018](#bib.bib195); Tay et al.,
    [2018b](#bib.bib147); [Zhang et al.,](#bib.bib194) ; Hu et al., [2018](#bib.bib63))
    |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| (Chen等，[2017b](#bib.bib15)；Tay等，[2018a](#bib.bib146)；Jhamb等，[2018](#bib.bib71)；Gong和Zhang，[2016](#bib.bib45)；Seo等，[2017b](#bib.bib128)；Wang等，[2017a](#bib.bib170)；Li等，[2016](#bib.bib91)；Loyola等，[2017a](#bib.bib102)；Liu等，[2018](#bib.bib100)；Ying等，[2018b](#bib.bib190))
    | (Zhou等，[2017](#bib.bib206)；Zhang等，[2018](#bib.bib195)；Tay等，[2018b](#bib.bib147)；[Zhang等，](#bib.bib194)；Hu等，[2018](#bib.bib63))
    |'
- en: 3.7\. Neural Attention based Recommendation
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.7\. 基于神经注意力的推荐系统
- en: Attention mechanism is motivated by human visual attention. For example, people
    only need to focus on specific parts of the visual inputs to understand or recognize
    them. Attention mechanism is capable of filtering out the uninformative features
    from raw inputs and reduce the side effects of noisy data. It is an intuitive
    but effective technique and has garnered considerable attention over the recent
    years across areas such as computer vision (Ba et al., [2014](#bib.bib4)), natural
    language processing (Vaswani et al., [2017](#bib.bib156); Luong et al., [2015](#bib.bib105))
    and speech recognition (Chorowski et al., [2015](#bib.bib24), [2014](#bib.bib23)).
    Neural attention can not only used in conjunction with MLP, CNNs and RNNs, but
    also address some tasks independently (Vaswani et al., [2017](#bib.bib156)). Integrating
    attention mechanism into RNNs enables the RNNs to process long and noisy inputs (Chorowski
    et al., [2015](#bib.bib24)). Although LSTM can solve the long memory problem theoretically,
    it is still problematic when dealing with long-range dependencies. Attention mechanism
    provides a better solution and helps the network to better memorize inputs. Attention-based
    CNNs are capable of capturing the most informative elements of the inputs (Seo
    et al., [2017b](#bib.bib128)). By applying attention mechanism to recommender
    system, one could leverage attention mechanism to filter out uninformative content
    and select the most representative items (Chen et al., [2017b](#bib.bib15)) while
    providing good interpretability. Although neural attention mechanism is not exactly
    a standalone deep neural technique, it is still worthwhile to discuss it separately
    due to its widespread use.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制的灵感来自于人类视觉注意力。例如，人们只需专注于视觉输入的特定部分即可理解或识别它们。注意力机制能够从原始输入中过滤掉无信息的特征，并减少噪声数据的副作用。这是一种直观但有效的技术，近年来在计算机视觉（Ba等，[2014](#bib.bib4)）、自然语言处理（Vaswani等，[2017](#bib.bib156)；Luong等，[2015](#bib.bib105)）和语音识别（Chorowski等，[2015](#bib.bib24)，[2014](#bib.bib23)）等领域引起了相当大的关注。神经注意力不仅可以与MLP、CNNs和RNNs结合使用，还可以独立解决一些任务（Vaswani等，[2017](#bib.bib156)）。将注意力机制集成到RNNs中使RNNs能够处理长且嘈杂的输入（Chorowski等，[2015](#bib.bib24)）。虽然LSTM在理论上可以解决长时记忆问题，但在处理长范围依赖时仍然存在问题。注意力机制提供了更好的解决方案，帮助网络更好地记忆输入。基于注意力的CNNs能够捕捉输入中最具信息量的元素（Seo等，[2017b](#bib.bib128)）。通过将注意力机制应用于推荐系统，可以利用注意力机制过滤掉无信息的内容，选择最具代表性的项目（Chen等，[2017b](#bib.bib15)），同时提供良好的可解释性。尽管神经注意力机制不完全是独立的深度神经技术，但由于其广泛应用，仍然值得单独讨论。
- en: 'Attention model learns to attend to the input with attention scores. Calculating
    the attention scores lives at the heart of neural attention models. Based on the
    way for calculating the attention scores, we classify the neural attention models
    into (1) standard vanilla attention and (2) co-attention. Vanilla attention utilizes
    a parameterized context vector to learn to attend while co-attention is concerned
    with learning attention weights from two-sequences. Self-attention is a special
    case of co-attention. Recent works (Chen et al., [2017b](#bib.bib15); Gong and
    Zhang, [2016](#bib.bib45); Seo et al., [2017b](#bib.bib128)) demonstrate the capability
    of attention mechanism in enhancing recommendation performance. Table [4](#S3.T4
    "Table 4 ‣ 3.6\. Restricted Boltzmann Machine based Recommendation ‣ 3\. Deep
    Learning Based Recommendation: State-of-the-art ‣ Deep Learning based Recommender
    System: A Survey and New Perspectives") summarizes the attention based recommendation
    models.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '注意力模型通过注意力分数学习关注输入。计算注意力分数是神经注意力模型的核心。根据计算注意力分数的方式，我们将神经注意力模型分为（1）标准的普通注意力和（2）共同注意力。普通注意力利用参数化的上下文向量进行学习，而共同注意力则关注于从两个序列中学习注意力权重。自注意力是共同注意力的一个特殊情况。最近的工作（陈等人，[2017b](#bib.bib15)；龚和张，[2016](#bib.bib45)；肖等人，[2017b](#bib.bib128)）展示了注意力机制在增强推荐性能方面的能力。表格
    [4](#S3.T4 "Table 4 ‣ 3.6\. Restricted Boltzmann Machine based Recommendation
    ‣ 3\. Deep Learning Based Recommendation: State-of-the-art ‣ Deep Learning based
    Recommender System: A Survey and New Perspectives") 总结了基于注意力的推荐模型。'
- en: Recommendation with Vanilla Attention
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 使用普通注意力的推荐
- en: Chen et al. (Chen et al., [2017b](#bib.bib15)) proposed an attentive collaborative
    filtering model by introducing a two-level attention mechanism to latent factor
    model. It consists of item-level and component-level attention. The item-level
    attention is used to select the most representative items to characterize users.
    The component-level attention aims to capture the most informative features from
    multimedia auxiliary information for each user. Tay et al. (Tay et al., [2018a](#bib.bib146))
    proposed a memory-based attention for collaborative metric learning. It introduces
    a latent relation vector learned via attention to CML. Jhamb et al. (Jhamb et al.,
    [2018](#bib.bib71)) proposed using attention mechanism to improve the performance
    of autoencoder based CF. Liu et al. (Liu et al., [2018](#bib.bib100)) proposed
    a short-term attention and memory priority based model, in which both long and
    short term user interests are intergrated for session based recommendation. Ying
    et al. (Ying et al., [2018b](#bib.bib190)) proposed a hierarchical attention model
    for sequential recommendation. Two attention networks are used to model user long-term
    and short-term interests.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 陈等人（陈等人，[2017b](#bib.bib15)）提出了一种引入两级注意力机制的协同过滤模型。该模型包括项目级和组件级注意力。项目级注意力用于选择最具代表性的项目来描述用户。组件级注意力旨在从多媒体辅助信息中捕捉每个用户最具信息性的特征。泰等人（泰等人，[2018a](#bib.bib146)）提出了一种基于记忆的注意力用于协同度量学习。它通过注意力引入了一个潜在的关系向量到CML。詹姆布等人（詹姆布等人，[2018](#bib.bib71)）提出了使用注意力机制来提高基于自编码器的协同过滤的性能。刘等人（刘等人，[2018](#bib.bib100)）提出了一种短期注意力和记忆优先级模型，其中将长期和短期用户兴趣整合用于会话推荐。应等人（应等人，[2018b](#bib.bib190)）提出了一种用于序列推荐的分层注意力模型。两个注意力网络用于建模用户的长期和短期兴趣。
- en: Introducing attention mechanism to RNNs could significantly improve their performance.
    Li et al. (Li et al., [2016](#bib.bib91)) proposed such an attention-based LSTM
    model for hashtag recommendation. This work takes the advantages of both RNNs
    and attention mechanism to capture the sequential property and recognize the informative
    words from microblog posts. Loyala et al. (Loyola et al., [2017a](#bib.bib102))
    proposed an encoder-decoder architecture with attention for user session and intents
    modelling. This model consists of two RNNs and could capture the transition regularities
    in a more expressive way.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 引入注意力机制到RNN中可以显著提高其性能。李等人（李等人，[2016](#bib.bib91)）提出了一种基于注意力的LSTM模型用于标签推荐。这项工作结合了RNN和注意力机制的优点，以捕捉序列特性并识别来自微博帖子中的信息性词汇。洛约拉等人（洛约拉等人，[2017a](#bib.bib102)）提出了一种带有注意力的编码器-解码器架构，用于用户会话和意图建模。该模型由两个RNN组成，可以以更具表现力的方式捕捉过渡规律。
- en: Vanilla attention can also work in conjunction with CNNs for recommender tasks.
    Gong et al. (Gong and Zhang, [2016](#bib.bib45)) proposed an attention based CNNs
    system for hashtag recommendation in microblog. It treats hashtag recommendation
    as a multi-label classification problem. The proposed model consists of a global
    channel and a local attention channel. The global channel is made up of convolution
    filters and max-pooling layers. All words are encoded in the input of global channel.
    The local attention channel has an attention layer with given window size and
    threshold to select informative words (known as trigger words in this work). Hence,
    only trigger words are at play in the subsequent layers. In the follow-up work (Seo
    et al., [2017b](#bib.bib128)), Seo et al. made use of two neural networks same
    as (Gong and Zhang, [2016](#bib.bib45)) (without the last two layers) to learn
    feature representations from user and item review texts, and predict rating scores
    with dot product in the final layer. Wang et al. (Wang et al., [2017a](#bib.bib170))
    presented a combined model for article recommendation, in which CNNs is used to
    learn article representations and attention is utilized to deal with the diverse
    variance of editors’s selection behavior.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: Vanilla attention 还可以与 CNN 结合用于推荐任务。Gong 等人（Gong 和 Zhang，[2016](#bib.bib45)）提出了一种基于注意力的
    CNN 系统，用于微博的标签推荐。它将标签推荐视为一个多标签分类问题。所提出的模型由一个全局通道和一个局部注意力通道组成。全局通道由卷积滤波器和最大池化层组成。所有单词都在全局通道的输入中编码。局部注意力通道具有一个具有给定窗口大小和阈值的注意力层，用于选择信息量大的单词（在这项工作中称为触发词）。因此，只有触发词在后续层中起作用。在后续工作（Seo
    等人，[2017b](#bib.bib128)）中，Seo 等人利用与（Gong 和 Zhang，[2016](#bib.bib45)）相同的两个神经网络（去掉最后两层）来学习用户和项目评论文本的特征表示，并在最终层通过点积预测评分。Wang
    等人（Wang 等人，[2017a](#bib.bib170)）提出了一种结合模型用于文章推荐，其中 CNN 用于学习文章表示，而注意力则用于处理编辑选择行为的多样性。
- en: Recommendation with Co-Attention Zhang et al. (Zhang et al., [2018](#bib.bib195))
    proposed a combined model, AttRec, which improves the sequential recommendation
    performance by capitalizing the strength of both self-attention and metric learning.
    It uses self-attention to learn user short-term intents from her recent interactions
    and takes the advantages of metric learning to learn more expressive user and
    item embemddings. Zhou et al. (Zhou et al., [2017](#bib.bib206)) proposed using
    self-attention for user heterogeneous behaviour modelling. Self-attention is simple
    yet effective mechanism and has shown superior performance than CNNs and RNNs
    in terms of sequential recommendation task. We believe that it has the capability
    to replace many complex neural models and more investigation is expected. Tay
    et al. (Tay et al., [2018b](#bib.bib147)) proposed a review based recommendation
    system with multi-pointer co-attention. The co-attention enables the model to
    select information reviews via co-learning from both user and item reviews. Zhang
    et al. ([Zhang et al.,](#bib.bib194) ) proposed a co-atention based hashtag recommendation
    model that integrates both visual and textual information. Shi et al. (Hu et al.,
    [2018](#bib.bib63)) proposed a neural co-attention model for personalized ranking
    task with meta-path.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 使用共同注意力的推荐 Zhang 等人（Zhang 等人，[2018](#bib.bib195)）提出了一种结合模型 AttRec，通过利用自注意力和度量学习的优势来提高序列推荐性能。它使用自注意力从用户的最近互动中学习短期意图，并利用度量学习来学习更具表现力的用户和项目嵌入。Zhou
    等人（Zhou 等人，[2017](#bib.bib206)）提出了使用自注意力进行用户异质行为建模。自注意力是一种简单而有效的机制，在序列推荐任务中表现出比
    CNN 和 RNN 更优越的性能。我们相信它有能力替代许多复杂的神经模型，期待更多的研究。Tay 等人（Tay 等人，[2018b](#bib.bib147)）提出了一种基于评论的推荐系统，具有多指针共同注意力。共同注意力使模型能够通过从用户和项目评论中共同学习来选择信息评论。Zhang
    等人（[Zhang 等人，](#bib.bib194)）提出了一种基于共同注意力的标签推荐模型，结合了视觉和文本信息。Shi 等人（Hu 等人，[2018](#bib.bib63)）提出了一种用于个性化排名任务的神经共同注意力模型。
- en: 3.8\. Neural AutoRegressive based Recommendation
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8\. 基于神经自回归的推荐
- en: 'As mentioned above, RBM is not tractable, thus we usually use the Contrastive
    Divergence algorithm to approximate the log-likelihood gradient on the parameters (Larochelle
    and Murray, [2011](#bib.bib82)), which also limits the usage of RBM-CF. The so-called
    Neural Autoregressive Distribution Estimator (NADE) is a tractable distribution
    estimator which provides a desirable alternative to RBM. Inspired by RBM-CF, Zheng
    et al. (Zheng et al., [2016](#bib.bib205)) proposed a NADE based collaborative
    filtering model (CF-NADE). CF-NADE models the distribution of user ratings. Here,
    we present a detailed example to illustrate how the CF-NADE works. Suppose we
    have 4 movies: m1 (rating is 4), m2 (rating is 2), m3 (rating is 3) and m4 (rating
    is 5). The CF-NADE models the joint probability of the rating vector $r$ by the
    chain rule: $p(\textbf{r})=\prod_{i=1}^{D}p(r_{m_{o_{i}}}|\textbf{r}_{m_{o_{<i}}})$,where
    $D$ is the number of items that the user has rated, $o$ is the $D$-tuple in the
    permutations of $(1,2,...,D)$, $m_{i}$ is the index of the $\textit{i}^{th}$ rated
    item, $r_{m_{o_{i}}}$ is the rating that the user gives to item $m_{o_{i}}$. More
    specifically, the procedure goes as follows: (1) the probability that the user
    gives $m1$ 4-star conditioned on nothing; (2) the probability that the user gives
    $m2$ 2-star conditioned on giving $m1$ 4-star; (3) the probability that the user
    gives $m3$ 3-star conditioned on giving $m1$ 4-star and $m2$ 2-star; (4) the probability
    that the user gives $m4$ 5-star conditioned on giving $m1$ 4-star, $m2$ 2-star
    and $m3$ 3-star.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，RBM（受限玻尔兹曼机）不可解，因此我们通常使用对比散度算法来近似参数上的对数似然梯度（Larochelle 和 Murray，[2011](#bib.bib82)），这也限制了RBM-CF的使用。所谓的神经自回归分布估计器（NADE）是一种可解的分布估计器，为RBM提供了一个理想的替代方案。受RBM-CF启发，郑等人（Zheng
    et al., [2016](#bib.bib205)）提出了一种基于NADE的协同过滤模型（CF-NADE）。CF-NADE对用户评分的分布进行建模。这里，我们展示一个详细的例子来说明CF-NADE的工作原理。假设我们有4部电影：m1（评分为4），m2（评分为2），m3（评分为3）和m4（评分为5）。CF-NADE通过链式规则对评分向量$r$的联合概率进行建模：$p(\textbf{r})=\prod_{i=1}^{D}p(r_{m_{o_{i}}}|\textbf{r}_{m_{o_{<i}}})$，其中$D$是用户评分的项目数量，$o$是$(1,2,...,D)$的排列中的$D$-元组，$m_{i}$是第$\textit{i}^{th}$个评分项目的索引，$r_{m_{o_{i}}}$是用户给项目$m_{o_{i}}$的评分。更具体地，程序如下：（1）用户在没有任何条件下给$m1$打4星的概率；（2）在给$m1$打4星的条件下，用户给$m2$打2星的概率；（3）在给$m1$打4星和$m2$打2星的条件下，用户给$m3$打3星的概率；（4）在给$m1$打4星、$m2$打2星和$m3$打3星的条件下，用户给$m4$打5星的概率。
- en: Ideally, the order of movies should follow the time-stamps of ratings. However,
    empirical study shows that random drawing also yields good performances. This
    model can be further extended to a deep model. In the follow-up paper, Zheng et
    al. (Zheng et al., [2016](#bib.bib204)) proposed incorporating implicit feedback
    to overcome the sparsity problem of rating matrix. Du et al. (Du et al., [2016](#bib.bib37))
    further imporved this model with a user-item co-autoregressive approach, which
    ahieves better performance in both rating estimation and personalized ranking
    tasks.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，电影的顺序应遵循评分的时间戳。然而，经验研究表明，随机抽样也能获得良好的表现。该模型可以进一步扩展为深度模型。在后续论文中，郑等人（Zheng
    et al., [2016](#bib.bib204)）提出了结合隐式反馈以克服评分矩阵的稀疏问题。杜等人（Du et al., [2016](#bib.bib37)）进一步改进了该模型，采用了用户-项目协同自回归方法，在评分估计和个性化排序任务中均取得了更好的性能。
- en: 3.9\. Deep Reinforcement Learning for Recommendation
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.9\. 深度强化学习推荐
- en: 'Most recommendation models consider the recommendation process as a static
    process, which makes it difficult to capture user’s temporal intentions and to
    respond in a timely manner. In recent years, DRL has begun to garner attention (Zhao
    et al., [2018a](#bib.bib199), [b](#bib.bib200); Zheng et al., [2018](#bib.bib201);
    Munemasa et al., [2018](#bib.bib108); Choi et al., [2018](#bib.bib22); Wang et al.,
    [2014](#bib.bib169)) in making personalized recommendation. Zhao et al. (Zhao
    et al., [2018b](#bib.bib200)) proposed a DRL framework, DEERS, for recommendation
    with both negative and positive feedback in a sequential interaction setting.
    Zhao et al. (Zhao et al., [2018a](#bib.bib199)) explored the page-wise recommendation
    scenario with DRL, the proposed framework DeepPage is able to adaptively optimize
    a page of items based on user’s real-time actions. Zheng et al. (Zheng et al.,
    [2018](#bib.bib201)) proposed a news recommendation system, DRN, with DRL to tackle
    the following three challenges: (1) dynamic changes of news content and user preference;
    (2) incorporating return patterns (to the service) of users; (3) increase diversity
    of recommendations. Chen et al. (Chen et al., [2018](#bib.bib17)) proposed a robust
    deep Q-learning algorithm to address the unstable reward estimation issue with
    two strategies: stratified sampling replay and approximate regretted reward. Choi
    et al. (Choi et al., [2018](#bib.bib22)) proposed solving the cold-start problem
    with RL and bi-clustering. Munemasa et al (Munemasa et al., [2018](#bib.bib108))
    proposed using DRL for stores recommendation.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数推荐模型将推荐过程视为一个静态过程，这使得捕捉用户的时间意图和及时响应变得困难。近年来，DRL 开始受到关注 (Zhao et al., [2018a](#bib.bib199),
    [b](#bib.bib200); Zheng et al., [2018](#bib.bib201); Munemasa et al., [2018](#bib.bib108);
    Choi et al., [2018](#bib.bib22); Wang et al., [2014](#bib.bib169)) 在个性化推荐方面。Zhao
    et al. (Zhao et al., [2018b](#bib.bib200)) 提出了一个 DRL 框架 DEERS，用于在顺序交互设置中处理正反馈和负反馈。Zhao
    et al. (Zhao et al., [2018a](#bib.bib199)) 探索了利用 DRL 的页面级推荐场景，提出的框架 DeepPage 能够基于用户的实时行为自适应地优化一个页面的项目。Zheng
    et al. (Zheng et al., [2018](#bib.bib201)) 提出了一个新闻推荐系统 DRN，使用 DRL 解决以下三个挑战：（1）新闻内容和用户偏好的动态变化；（2）用户的返回模式（到服务的返回）；（3）增加推荐的多样性。Chen
    et al. (Chen et al., [2018](#bib.bib17)) 提出了一个鲁棒的深度 Q 学习算法，采用分层采样重放和近似遗憾奖励两种策略来解决不稳定的奖励估计问题。Choi
    et al. (Choi et al., [2018](#bib.bib22)) 提出了通过 RL 和双聚类解决冷启动问题。Munemasa et al (Munemasa
    et al., [2018](#bib.bib108)) 提出了使用 DRL 进行商店推荐。
- en: Reinforcement Learning techniques such as contextual-bandit approach (Li et al.,
    [2010](#bib.bib87)) had shown superior recommendation performance in real-world
    applications. Deep neural networks increase the practicality of RL and make it
    possible to model various of extra information for designing real-time recommendation
    strategies.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习技术，如上下文赌博机方法 (Li et al., [2010](#bib.bib87)) 在现实应用中显示出了优越的推荐性能。深度神经网络增加了
    RL 的实用性，并使得建模各种额外信息以设计实时推荐策略成为可能。
- en: 3.10\. Adversarial Network based Recommendation
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.10\. 基于对抗网络的推荐
- en: 'IRGAN (Wang et al., [2017b](#bib.bib163)) is the first model which applies
    GAN to information retrieval area. Specifically, the authors demonstrated its
    capability in three information retrieval tasks, including: web search, item recommendation
    and question answering. In this survey, we mainly focus on how to use IRGAN to
    recommend items.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: IRGAN (Wang et al., [2017b](#bib.bib163)) 是第一个将 GAN 应用于信息检索领域的模型。具体而言，作者展示了其在三个信息检索任务中的能力，包括：网页搜索、项目推荐和问答。在这项调查中，我们主要关注如何使用
    IRGAN 来推荐项目。
- en: Firstly, we introduce the general framework of IRGAN. Traditional GAN consists
    of a discriminator and a generator. Likely, there are two schools of thinking
    in information retrieval, that is, generative retrieval and discriminative retrieval.
    Generative retrieval assumes that there is an underlying generative process between
    documents and queries, and retrieval tasks can be achieved by generating relevant
    document $d$ given a query $q$. Discriminative retrieval learns to predict the
    relevance score $r$ given labelled relevant query-document pairs. The aim of IRGAN
    is to combine these two thoughts into a unified model, and make them to play a
    minimax game like generator and discriminator in GAN. The generative retrieval
    aims to generate relevant documents similar to ground truth to fool the discriminative
    retrieval model.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们介绍了 IRGAN 的一般框架。传统的 GAN 包括一个判别器和一个生成器。类似地，信息检索领域有两种思路，即生成检索和判别检索。生成检索假设文档和查询之间存在潜在的生成过程，检索任务可以通过生成给定查询
    $q$ 的相关文档 $d$ 来实现。判别检索学习预测给定标记的相关查询-文档对的相关性分数 $r$。IRGAN 的目标是将这两种思路结合成一个统一模型，并使它们像
    GAN 中的生成器和判别器一样进行极小极大博弈。生成检索的目标是生成类似于地面真实的相关文档，以欺骗判别检索模型。
- en: 'Formally, let $p_{true}(d|q_{n},r)$ refer to the user’s relevance (preference)
    distribution. The generative retrieval model $p_{\theta}(d|q_{n},r)$ tries to
    approximate the true relevance distribution. Discriminative retrieval $f_{\phi}(q,d)$
    tries to distinguish between relevant documents and non-relevant documents. Similar
    to the objective function of GAN, the overall objective is formulated as follows:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上，让 $p_{true}(d|q_{n},r)$ 指代用户的相关性（偏好）分布。生成检索模型 $p_{\theta}(d|q_{n},r)$ 尝试近似真实的相关性分布。判别检索
    $f_{\phi}(q,d)$ 尝试区分相关文档和非相关文档。类似于 GAN 的目标函数，总体目标被表述如下：
- en: '| (15) |  | $J^{G^{*},D^{*}}=\underset{\theta}{min}\ \underset{\phi}{max}\sum_{n=1}^{N}(\mathbb{E}_{d\sim
    p_{true}(d&#124;q_{n},r)}[logD(d&#124;q_{n})]+\mathbb{E}_{d\sim p_{\theta}(d&#124;q_{n},r)}[log(1-D(d&#124;q_{n}))])$
    |  |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| (15) |  | $J^{G^{*},D^{*}}=\underset{\theta}{min}\ \underset{\phi}{max}\sum_{n=1}^{N}(\mathbb{E}_{d\sim
    p_{true}(d|q_{n},r)}[logD(d|q_{n})]+\mathbb{E}_{d\sim p_{\theta}(d|q_{n},r)}[log(1-D(d|q_{n}))])$
    |  |'
- en: where $D(d|q_{n})=\sigma(f_{\phi}(q,d))$, $\sigma$ represents the sigmoid function,
    $\theta$ and $\phi$ are the parameters for generative and discriminative retrieval
    respectively. Parameter $\theta$ and $\phi$ can be learned alternately with gradient
    descent.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $D(d|q_{n})=\sigma(f_{\phi}(q,d))$，$\sigma$ 代表 sigmoid 函数，$\theta$ 和 $\phi$
    分别是生成和判别检索的参数。参数 $\theta$ 和 $\phi$ 可以通过梯度下降交替学习。
- en: 'The above objective equation is constructed for pointwise relevance estimation.
    In some specific tasks, it should be in pairwise paradigm to generate higher quality
    ranking lists. Here, suppose $p_{\theta}(d|q_{n},r)$ is given by a softmax function:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 上述客观方程用于逐点相关性估计。在某些特定任务中，应采用成对范式以生成更高质量的排名列表。假设 $p_{\theta}(d|q_{n},r)$ 由 softmax
    函数给出：
- en: '| (16) |  | $p_{\theta}(d_{i}&#124;q,r)=\frac{exp(g_{\theta}(q,d_{i}))}{\sum_{d_{j}}exp(g_{\theta}(q,d_{j}))}$
    |  |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| (16) |  | $p_{\theta}(d_{i}|q,r)=\frac{exp(g_{\theta}(q,d_{i}))}{\sum_{d_{j}}exp(g_{\theta}(q,d_{j}))}$
    |  |'
- en: '$g_{\theta}(q,d)$ is the chance of document $d$ being generated from query
    $q$. In real-word retrieval system, both $g_{\theta}(q,d)$ and $f_{\phi}(q,d)$
    are task-specific. They can either have the same or different formulations. The
    authors modelled them with the same function for convenience, and define them
    as: $g_{\theta}(q,d)=s_{\theta}(q,d)$ and $f_{\phi}(q,d)=s_{\phi}(q,d)$. In the
    item recommendation scenario, the authors adopted the matrix factorization to
    formulate $s(\cdot)$. It can be substituted with other advanced models such as
    factorization machine or neural network.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: $g_{\theta}(q,d)$ 表示文档 $d$ 从查询 $q$ 生成的概率。在真实世界的检索系统中，$g_{\theta}(q,d)$ 和 $f_{\phi}(q,d)$
    都是任务特定的。它们可以具有相同或不同的表达方式。作者为方便起见采用相同函数对它们进行建模，并定义为：$g_{\theta}(q,d)=s_{\theta}(q,d)$
    和 $f_{\phi}(q,d)=s_{\phi}(q,d)$。在物品推荐场景中，作者采用矩阵分解来形成 $s(\cdot)$。它可以用其他高级模型如因子分解机或神经网络替代。
- en: He et al. (He et al., [2018b](#bib.bib53)) proposed an adversarial personalized
    ranking approach which enhances the Bayesian personalized ranking with adversarial
    training. It plays a minimax game between the original BPR objective and the adversary
    which add noises or permutations to maximize the BPR loss. Cai et al. (Cai et al.,
    [2018](#bib.bib10)) proposed a GAN based representation learning approach for
    heterogeneous bibliographic network, which can effectively address the personalized
    citation recommendation task. Wang et al. (Wang et al., [2018](#bib.bib165)) proposed
    using GAN to generate negative samples for the memory network based streaming
    recommender. Experiments show that the proposed GAN based sampler could significantly
    improve the performance.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: He et al. (He et al., [2018b](#bib.bib53)) 提出了一个对抗性个性化排名方法，该方法通过对抗训练增强了贝叶斯个性化排名。它在原始
    BPR 目标与对手之间进行最小化最大化博弈，对手通过添加噪声或排列来最大化 BPR 损失。Cai et al. (Cai et al., [2018](#bib.bib10))
    提出了基于 GAN 的异质文献网络表示学习方法，该方法能有效解决个性化引用推荐任务。Wang et al. (Wang et al., [2018](#bib.bib165))
    提出了使用 GAN 为基于记忆网络的流式推荐器生成负样本。实验表明，所提出的基于 GAN 的采样器能显著提高性能。
- en: 3.11\. Deep Hybrid Models for Recommendation
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.11\. 深度混合模型用于推荐系统
- en: With the good flexibility of deep neural networks, many neural building blocks
    can be intergrated to formalize more powerful and expressive models. Despite the
    abundant possible ways of combination, we suggest that the hybrid model should
    be reasonably and carefully designed for the specific tasks. Here, we summarize
    the existing models that has been proven to be effective in some application fields.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 由于深度神经网络的良好灵活性，许多神经网络模块可以集成以形成更强大和更具表现力的模型。尽管组合方式众多，但我们建议混合模型应针对特定任务进行合理和谨慎的设计。在这里，我们总结了在某些应用领域已被证明有效的现有模型。
- en: CNNs and Autoencoder. Collaborative Knowledge Based Embedding (CKE) (Zhang et al.,
    [2016](#bib.bib193)) combines CNNs with autoencoder for images feature extraction.
    CKE can be viewed as a further step of CDL. CDL only considers item text information
    (e.g. abstracts of articles and plots of movies), while CKE leverages structural
    content, textual content and visual content with different embedding techniques.
    Structural information includes the attributes of items and the relationships
    among items and users. CKE adopts the TransR (Lin et al., [2015](#bib.bib97)),
    a heterogeneous network embedding method, for interpreting structural information.
    Similarly, CKE employs SDAE to learn feature representations from textual information.
    As for visual information, CKE adopts a stacked convolutional auto-encoders (SCAE).
    SCAE makes efficient use of convolution by replacing the fully-connected layers
    of SDAE with convolutional layers. The recommendation process is done in a probabilistic
    form similar to CDL.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 和自编码器。基于协同知识的嵌入（CKE）(Zhang et al., [2016](#bib.bib193)) 将 CNN 与自编码器结合用于图像特征提取。CKE
    可以视为 CDL 的进一步发展。CDL 仅考虑项目文本信息（例如文章摘要和电影情节），而 CKE 利用结构内容、文本内容和视觉内容，采用不同的嵌入技术。结构信息包括项目的属性以及项目与用户之间的关系。CKE
    采用 TransR (Lin et al., [2015](#bib.bib97))，一种异构网络嵌入方法，用于解释结构信息。同样，CKE 使用 SDAE
    从文本信息中学习特征表示。对于视觉信息，CKE 采用堆叠卷积自编码器（SCAE）。SCAE 通过用卷积层替换 SDAE 的全连接层来高效利用卷积。推荐过程以类似
    CDL 的概率形式进行。
- en: CNNs and RNNs. Lee et al. (Lee et al., [2016](#bib.bib83)) proposed a deep hybrid
    model with RNNs and CNNs for quotes recommendation. Quote recommendation is viewed
    as a task of generating a ranked list of quotes given the query texts or dialogues
    (each dialogue contains a sequence of tweets). It applies CNN sto learn significant
    local semantics from tweets and maps them to a distributional vectors. These distributional
    vectors are further processed by LSTM to compute the relevance of target quotes
    to the given tweet dialogues. The overall architecture is shown in Figure 12(a).
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 和 RNN。Lee et al. (Lee et al., [2016](#bib.bib83)) 提出了一个结合 RNN 和 CNN 的深度混合模型，用于引用推荐。引用推荐被视为根据查询文本或对话（每个对话包含一系列推文）生成排名列表的任务。它应用
    CNN 来学习推文中的重要局部语义，并将其映射到分布向量。这些分布向量进一步由 LSTM 处理，以计算目标引用与给定推文对话的相关性。整体架构如图 12(a)
    所示。
- en: Zhang et al. ([Zhang et al.,](#bib.bib194) ) proposed a CNNs and RNNs based
    hybrid model for hashtag recommendation. Given a tweet with corresponding images,
    the authors utilized CNNs to extract features from images and LSTM to learn text
    features from tweets. Meanwhile, the authors proposed a co-attention mechanism
    to model the correlation influences and balance the contribution of texts and
    images.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: Zhang 等人（[Zhang et al.,](#bib.bib194)）提出了一个基于 CNNs 和 RNNs 的混合模型用于 hashtag 推荐。给定一个带有相应图像的推文，作者利用
    CNNs 从图像中提取特征，并用 LSTM 从推文中学习文本特征。同时，作者提出了一种共同注意机制来建模文本和图像的相关影响，并平衡它们的贡献。
- en: Ebsesu et al. (Ebesu and Fang, [2017](#bib.bib39)) presented a neural citation
    network which integrates CNNs with RNNs in a encoder-decoder framework for citation
    recommendation. In this model, CNNs act as the encoder that captures the long-term
    dependencies from citation context. The RNNs work as a decoder which learns the
    probability of a word in the cited paper’s title given all previous words together
    with representations attained by CNNs.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: Ebsesu 等人（Ebesu and Fang, [2017](#bib.bib39)）提出了一个神经引用网络，它将 CNNs 和 RNNs 集成在编码器-解码器框架中用于引用推荐。在这个模型中，CNNs
    作为编码器捕捉引用上下文中的长期依赖关系。RNNs 作为解码器，学习在给定所有先前单词及 CNNs 获得的表示的情况下，引用论文标题中单词的概率。
- en: Chen et al. (Chen et al., [2017a](#bib.bib18)) proposed an intergrated framework
    with CNNs and RNNs for personalized key frame (in videos) recommendation, in which
    CNNs are used to learn feature representations from key frame images and RNNs
    are used to process the textual features.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: Chen 等人（Chen et al., [2017a](#bib.bib18)）提出了一个集成了 CNNs 和 RNNs 的框架用于个性化关键帧（视频中的）推荐，其中
    CNNs 用于从关键帧图像中学习特征表示，RNNs 用于处理文本特征。
- en: RNNs and Autoencoder. The former mentioned collaborative deep learning model
    is lack of robustness and incapable of modelling the sequences of text information.
    Wang et al. (Wang et al., [2016](#bib.bib161)) further exploited integrating RNNs
    and denoising autoencoder to overcome this limitations. The authors first designed
    a generalization of RNNs named robust recurrent network. Based on the robust recurrent
    network, the authors proposed the hierarchical Bayesian recommendation model called
    CRAE. CRAE also consists of encoding and decoding parts, but it replaces feedforward
    neural layers with RNNs, which enables CRAE to capture the sequential information
    of item content information. Furthermore, the authors designed a wildcard denoising
    and a beta-pooling technique to prevent the model from overfitting.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: RNNs 和自编码器。前面提到的协同深度学习模型缺乏鲁棒性，不能建模文本信息的序列。Wang 等人（Wang et al., [2016](#bib.bib161)）进一步探讨了将
    RNNs 和去噪自编码器结合起来以克服这些限制。作者首先设计了一种名为鲁棒递归网络的 RNNs 泛化模型。在鲁棒递归网络的基础上，作者提出了一个分层贝叶斯推荐模型，称为
    CRAE。CRAE 也包括编码和解码部分，但它用 RNNs 替代了前馈神经层，使 CRAE 能够捕捉项目内容信息的序列信息。此外，作者设计了一个通配符去噪和一个
    beta-pooling 技术来防止模型过拟合。
- en: RNNs with DRL. Wang et al. (Wang et al., [2018](#bib.bib164)) proposed combining
    supervised deep reinforcement learning wth RNNs for treatment recommendation.
    The framework can learn the prescription policy from the indicator signal and
    evaluation signal. Experiments demonstrate that this system could infer and discover
    the optimal treatments automatically. We believe that this a valuable topic and
    benefits the social good.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: RNNs 与 DRL。Wang 等人（Wang et al., [2018](#bib.bib164)）提出了将监督深度强化学习与 RNNs 结合用于治疗推荐的框架。该框架可以从指标信号和评估信号中学习处方策略。实验表明，该系统可以自动推断和发现最佳治疗方案。我们认为这是一个有价值的主题，对社会有益。
- en: 4\. Future Research Directions and Open Issues
  id: totrans-307
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 未来研究方向与开放性问题
- en: Whilst existing works have established a solid foundation for deep recommender
    systems research, this section outlines several promising prospective research
    directions. We also elaborate on several open issues, which we believe is critical
    to the present state of the field.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管现有的工作为深度推荐系统研究奠定了坚实的基础，本节概述了几个有前途的未来研究方向。我们还详细阐述了几个开放性问题，我们认为这些问题对于当前领域的状态至关重要。
- en: 4.1\. Joint Representation Learning from User and Item Content Information
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 从用户和项目内容信息中进行联合表示学习
- en: Making accurate recommendations requires deep understanding of item characteristics
    and user’s actual demands and preferences (Leskovec, [2015](#bib.bib86); Adomavicius
    and Tuzhilin, [2005](#bib.bib2)). Naturally, this can be achieved by exploiting
    the abundant auxiliary information. For example, context information tailors services
    and products according to user’s circumstances and surroundings (Unger et al.,
    [2016](#bib.bib152)), and mitigate cold start influence; Implicit feedback indicates
    users’ implicit intention and is easier to collect while gathering explicit feedback
    is a resource-demanding task. Although existing works have investigated the efficacy
    of deep learning model in mining user and item profiles (Zhang et al., [2017](#bib.bib197);
    Lian et al., [2017](#bib.bib93)), implicit feedback (Ying et al., [2016](#bib.bib189);
    Zheng et al., [2016](#bib.bib204); He and McAuley, [2016b](#bib.bib51); Zhang
    et al., [2017](#bib.bib197)), contextual information (Unger et al., [2016](#bib.bib152);
    Kim et al., [2016](#bib.bib76); Rawat and Kankanhalli, [2016](#bib.bib119); Twardowski,
    [2016](#bib.bib150); Ebesu and Fang, [2017](#bib.bib39)), and review texts (Zheng
    et al., [2017](#bib.bib203); Seo et al., [2017b](#bib.bib128); Wu et al., [2016](#bib.bib175);
    Li et al., [2017](#bib.bib88)) for recommendation, they do not utilize these various
    side information in a comprehensive manner and take the full advantages of the
    available data. Moreover, there are few works investigating users’ footprints
    (e.g. Tweets or Facebook posts) from social media (Hsieh et al., [2016](#bib.bib62))
    and physical world (e.g. Internet of things) (Yao et al., [2016](#bib.bib187)).
    One can infer user’s temporal interests or intentions from these side data resources
    while deep learning method is a desirable and powerful tool for integrating these
    additional information. The capability of deep learning in processing heterogeneous
    data sources also brings more opportunities in recommending diverse items with
    unstructured data such as textual, visual, audio and video features.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 精确的推荐需要深入了解项目特性以及用户的实际需求和偏好（Leskovec, [2015](#bib.bib86); Adomavicius 和 Tuzhilin,
    [2005](#bib.bib2)）。自然地，这可以通过利用丰富的辅助信息来实现。例如，环境信息根据用户的情况和周围环境量身定制服务和产品（Unger 等,
    [2016](#bib.bib152)），并减轻冷启动的影响；隐式反馈指示用户的隐含意图，并且比收集显式反馈更易于获取，而收集显式反馈则是一个资源密集型任务。尽管现有工作已经研究了深度学习模型在挖掘用户和项目档案中的效果（Zhang
    等, [2017](#bib.bib197); Lian 等, [2017](#bib.bib93)），隐式反馈（Ying 等, [2016](#bib.bib189);
    Zheng 等, [2016](#bib.bib204); He 和 McAuley, [2016b](#bib.bib51); Zhang 等, [2017](#bib.bib197)），上下文信息（Unger
    等, [2016](#bib.bib152); Kim 等, [2016](#bib.bib76); Rawat 和 Kankanhalli, [2016](#bib.bib119);
    Twardowski, [2016](#bib.bib150); Ebesu 和 Fang, [2017](#bib.bib39)），以及评论文本（Zheng
    等, [2017](#bib.bib203); Seo 等, [2017b](#bib.bib128); Wu 等, [2016](#bib.bib175);
    Li 等, [2017](#bib.bib88)）在推荐中的应用，它们并未全面利用这些多样的辅助信息，也没有充分发挥可用数据的优势。此外，关于从社交媒体（例如推文或
    Facebook 帖子）（Hsieh 等, [2016](#bib.bib62)）和物理世界（例如物联网）（Yao 等, [2016](#bib.bib187)）中研究用户足迹的工作较少。可以从这些辅助数据资源中推断用户的时间兴趣或意图，而深度学习方法是整合这些额外信息的理想且强大的工具。深度学习在处理异构数据源的能力也带来了更多的机会，用于推荐带有非结构化数据的多样化项目，例如文本、视觉、音频和视频特征。
- en: Additionally, feature engineering has not been fully studied in the recommendation
    research community, but it is essential and widely employed in industrial applications (Covington
    et al., [2016](#bib.bib28); Cheng et al., [2016](#bib.bib21)). However, most of
    the existing models require manually crafted and selected features, which is time-consuming
    and tedious. Deep neural network is a promising tool for automatic feature crafting
    by reducing manual intervention (Shan et al., [2016](#bib.bib130)). There is also
    an added advantage of representation learning from free texts, images or data
    that exists in the ‘wild’ without having to design intricate feature engineering
    pipelines. More intensive studies on deep feature engineering specific for recommender
    systems are expected to save human efforts as well as improve recommendation quality.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，特征工程在推荐研究社区中尚未得到充分研究，但它在工业应用中至关重要且被广泛使用（Covington 等, [2016](#bib.bib28);
    Cheng 等, [2016](#bib.bib21)）。然而，大多数现有模型需要手工制作和选择特征，这既耗时又繁琐。深度神经网络是通过减少人工干预来进行自动特征制作的有前途的工具（Shan
    等, [2016](#bib.bib130)）。从自由文本、图像或“野外”数据中进行表示学习还有一个额外的好处，即无需设计复杂的特征工程管道。预计对推荐系统特定的深度特征工程进行更多的深入研究将节省人力并提高推荐质量。
- en: An interesting forward looking research problem is how to design neural architectures
    that best exploits the availability of other modes of data. One recent work potentially
    paving the way towards models of this nature is the Joint Representation Learning
    framework (Zhang et al., [2017](#bib.bib198)). Learning joint (possibly multi-modal
    representations) of user and items will likely become a next emerging trend in
    recommender systems research. To this end, a deep learning taking on this aspect
    would be how to design better inductive biases (hybrid neural architectures) in
    an end-to-end fashion. For example, reasoning over different modalities (text,
    images, interaction) data for better recommendation performance.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的前瞻性研究问题是如何设计最好利用其他数据模式可用性的神经结构。一项最近的工作可能为这种类型的模型铺平了道路，即联合表示学习框架（Zhang 等人，[2017](#bib.bib198)）。学习用户和项目的联合（可能是多模态的）表示很可能成为推荐系统研究的下一个新兴趋势。为此，一个涉及这一方面的深度学习将是如何设计更好的归纳偏差（混合神经结构）的端到端方法。例如，通过不同模态（文本、图像、互动）数据进行推理，以提高推荐性能。
- en: 4.2\. Explainable Recommendation with Deep Learning
  id: totrans-313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 深度学习中的可解释推荐
- en: A common interpretation is that deep neural networks are highly non-interpretable.
    As such, making explainable recommendations seem to be an uphill task. Along the
    same vein, it would be also natural to assume that big, complex neural models
    are just fitting the data with any true understanding (see subsequent section
    on machine reasoning for recommendation). This is precisely why this direction
    is both exciting and also crucial. There are mainly two ways that explainable
    deep learning is important. The first, is to make explainable predictions to users,
    allowing them to understand the factors behind the network’s recommendations (i.e.,
    why was this item/service recommended?) (Xiao et al., [2017](#bib.bib179); Seo
    et al., [2017a](#bib.bib127)). The second track is mainly focused on explain-ability
    to the practitioner, probing weights and activations to understand more about
    the model (Tay et al., [2018a](#bib.bib146)).
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络通常被认为是高度不可解释的。因此，做出可解释的推荐似乎是一项艰巨的任务。在同一条路线上，也很自然地假设，大型复杂的神经模型只是在拟合数据，而没有真正的理解（见推荐机器推理的后续部分）。这正是为什么这个方向既令人兴奋又至关重要的原因。解释性深度学习的重要性主要体现在两个方面。第一，是向用户提供可解释的预测，使他们能够理解网络推荐背后的因素（即，为什么推荐这个项目/服务？）（Xiao
    等人，[2017](#bib.bib179); Seo 等人，[2017a](#bib.bib127)）。第二个方向主要集中在向从业者解释能力，探究权重和激活以更多了解模型（Tay
    等人，[2018a](#bib.bib146)）。
- en: As of today, attentional models (Tay et al., [2018b](#bib.bib147); Seo et al.,
    [2017a](#bib.bib127); Xiao et al., [2017](#bib.bib179)) have more or less eased
    the non-interpretable concerns of neural models. If anything, attention models
    have instead led to greater extents of interpretability since the attention weights
    not only give insights about the inner workings of the model but are also able
    to provide explainable results to users. While this has been an existing direction
    of research ‘pre deep learning’, attentional models are not only capable of enhancing
    performance but enjoys greater explainability. This further motivates the usage
    of deep learning for recommendation.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 就目前而言，注意力模型（Tay 等人，[2018b](#bib.bib147); Seo 等人，[2017a](#bib.bib127); Xiao 等人，[2017](#bib.bib179)）已经或多或少地缓解了神经模型的不可解释性问题。如果说有什么，注意力模型反而引领了更深入的可解释性，因为注意力权重不仅提供了关于模型内部工作的见解，还能为用户提供可解释的结果。虽然这已经是研究的现有方向‘深度学习前’，但注意力模型不仅能够提升性能，而且享有更大的可解释性。这进一步促使了深度学习在推荐中的使用。
- en: Notably, it is both intuitive and natural that a model’s explainabiity and interpretability
    strongly relies on the application domain and usage of content information. For
    example (Seo et al., [2017a](#bib.bib127); Tay et al., [2018b](#bib.bib147)) mainly
    use reviews as a medium of interpretability (which reviews led to making which
    predictions). Many other mediums/modalities can be considered, such as image (Chen
    et al., [2018](#bib.bib19)).
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，模型的可解释性和可解释性强烈依赖于应用领域和内容信息的使用。例如（Seo 等人，[2017a](#bib.bib127); Tay 等人，[2018b](#bib.bib147)）主要使用评论作为解释的媒介（哪些评论导致了哪些预测）。许多其他媒体/模态也可以被考虑，如图像（Chen
    等人，[2018](#bib.bib19)）。
- en: To this end, a promising direction and next step would to be to design better
    attentional mechanisms, possibly to the level of providing conversational or generative
    explanations (along the likes of (Li et al., [2017](#bib.bib88))). Given that
    models are already capable of highlighting what contributes to the decision, we
    believe that this is the next frontier.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，一个有前景的方向和下一步是设计更好的注意机制，可能达到提供对话式或生成性解释的水平（类似于 (Li 等, [2017](#bib.bib88) )）。鉴于模型已经能够突出显示影响决策的因素，我们相信这是下一个前沿。
- en: 4.3\. Going Deeper for Recommendation
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 推荐的深入探讨
- en: From former studies (He et al., [2017](#bib.bib54), [2017](#bib.bib54); Wu et al.,
    [2016a](#bib.bib178); Zhang et al., [2018](#bib.bib196)), we found that the performance
    of most neural CF models plateaus at three to four layers. Going deeper has shown
    promising performance over shallow networks in many tasks (He et al., [2016](#bib.bib49);
    Huang et al., [2017](#bib.bib65)), nonetheless, going deeper in the context of
    deep neural network based RS remains largely unclear. If going deeper give favorable
    results, how do we train the deep architecture? If not, what is the reason behind
    this? A possibility is to look into auxiliary losses at different layers in similar
    spirit to (Trinh et al., [2018](#bib.bib148)) albeit hierarchically instead of
    sequentially. Another possibility is to vary layer-wise learning rates for each
    layer of the deep network or apply some residual strategies.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 从以前的研究（He 等, [2017](#bib.bib54), [2017](#bib.bib54); Wu 等, [2016a](#bib.bib178);
    Zhang 等, [2018](#bib.bib196)）中，我们发现大多数神经协同过滤模型的性能在三到四层时趋于平稳。虽然在许多任务中，深入层次的网络比浅层网络表现出更有前途的性能（He
    等, [2016](#bib.bib49); Huang 等, [2017](#bib.bib65)），然而，在深度神经网络推荐系统的背景下，深入层次仍然
    largely unclear。如果深入层次能带来良好的结果，我们如何训练深度架构？如果不能，背后的原因是什么？一种可能性是类似于（Trinh 等, [2018](#bib.bib148)）的方法，但在层次结构上而非顺序上查看不同层次的辅助损失。另一种可能性是为深度网络的每一层变更逐层学习率或应用一些残差策略。
- en: 4.4\. Machine Reasoning for Recommendation
  id: totrans-320
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4\. 推荐的机器推理
- en: There have been numerous recent advances in machine reasoning in deep learning,
    often involving reasoning over natural language or visual input (Hudson and Manning,
    [2018](#bib.bib68); Santoro et al., [2017](#bib.bib125); Xiong et al., [2016](#bib.bib182)).
    We believe that tasks like machine reading, reasoning, question answering or even
    visual reasoning will have big impacts on the field of recommender systems. These
    tasks are often glazed over, given that they seem completely arbitrary and irrelevant
    with respect to recommender systems. However, it is imperative that recommendater
    systems often requires reasoning over a single (or multiple) modalities (reviews,
    text, images, meta-data) which would eventually require borrowing (and adapting)
    techniques from these related fields. Fundamentally, recommendation and reasoning
    (e.g., question answering) are highly related in the sense that they are both
    information retrieval problems.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，在深度学习领域，机器推理有了众多的进展，这些进展通常涉及对自然语言或视觉输入的推理（Hudson 和 Manning, [2018](#bib.bib68);
    Santoro 等, [2017](#bib.bib125); Xiong 等, [2016](#bib.bib182)）。我们相信，像机器阅读、推理、问答甚至视觉推理这样的任务将对推荐系统领域产生重大影响。这些任务通常被忽视，因为它们似乎与推荐系统完全无关。然而，推荐系统往往需要对单一（或多个）模态（评论、文本、图像、元数据）进行推理，这最终需要借鉴（并适应）这些相关领域的技术。从根本上说，推荐和推理（例如，问答）在信息检索问题的意义上是高度相关的。
- en: The single most impactful architectural innovation with neural architectures
    that are capable of machine reasoning is the key idea of attention (Vaswani et al.,
    [2017](#bib.bib156); Xiong et al., [2016](#bib.bib182)). Notably, this key intuition
    have already (and very recently) demonstrated effectiveness on several recommender
    problems. Tay et al. (Tay et al., [2018b](#bib.bib147)) proposed an co-attentive
    architecture for reasoning over reviews, and showed that different recommendation
    domains have different ‘evidence aggregation’ patterns. For interaction-only recommendation,
    similar reasoning architectures have utilized similar co-attentive mechanisms
    for reasoning over meta-paths (Hu et al., [2018](#bib.bib63)). To this end, a
    next frontier for recommender systems is possibly to adapt to situations that
    require multi-step inference and reasoning. A simple example would to reason over
    a user’s social profile, purchases etc., reasoning over multiple modalities to
    recommend a product. All in all, we can expect that reasoning architectures to
    start to take the foreground in recommender system research.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络架构中最具影响力的架构创新是注意力机制的关键思想（Vaswani 等，[2017](#bib.bib156)；Xiong 等，[2016](#bib.bib182)）。值得注意的是，这一关键直觉已在几个推荐问题上（且非常最近）展示了有效性。Tay
    等（Tay 等，[2018b](#bib.bib147)）提出了一种用于评论推理的共注意力架构，并展示了不同推荐领域具有不同的“证据聚合”模式。对于仅基于交互的推荐，类似的推理架构已经利用类似的共注意力机制来推理元路径（Hu
    等，[2018](#bib.bib63)）。为此，推荐系统的下一个前沿可能是适应需要多步骤推理和推断的情况。一个简单的例子是对用户的社交资料、购买等进行推理，通过多模态推理来推荐产品。总的来说，我们可以预期推理架构将开始在推荐系统研究中占据重要地位。
- en: 4.5\. Cross Domain Recommendation with Deep Neural Networks
  id: totrans-323
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5\. 使用深度神经网络的跨领域推荐
- en: Nowadays, many large companies offer diversified products or services to customers.
    For example, Google provides us with web searches, mobile applications and news
    services; We can buy books, electronics and clothes from Amazon. Single domain
    recommender system only focuses on one domain while ignores the user interests
    on other domains, which also exacerbates sparsity and cold start problems (Khan
    et al., [2017](#bib.bib75)). Cross domain recommender system, which assists target
    domain recommendation with the knowledge learned from source domains, provides
    a desirable solution for these problems. One of the most widely studied topics
    in cross domain recommendation is transfer learning which aims to improve learning
    tasks in one domain by using knowledge transferred from other domains (Fernández-Tobías
    et al., [2012](#bib.bib41); Pan et al., [2010](#bib.bib116)). Deep learning is
    well suited to transfer learning as it learn high-level abstractions that disentangle
    the variation of different domains. Several existing works (Elkahky et al., [2015](#bib.bib40);
    Lian et al., [2017](#bib.bib93)) indicate the efficacy of deep learning in catching
    the generalizations and differences across different domains and generating better
    recommendations on cross-domain platforms. Therefore, it is a promising but largely
    under-explored area where mores studies are expected.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，许多大型公司向客户提供多样化的产品或服务。例如，Google 提供网页搜索、移动应用和新闻服务；我们可以在 Amazon 上购买书籍、电子产品和衣物。单一领域的推荐系统只关注一个领域，而忽略了用户在其他领域的兴趣，这也加剧了稀疏性和冷启动问题（Khan
    等，[2017](#bib.bib75)）。跨领域推荐系统通过利用源领域学到的知识来辅助目标领域的推荐，为这些问题提供了理想的解决方案。跨领域推荐中的一个广泛研究的主题是迁移学习，它旨在通过利用从其他领域转移来的知识来改善一个领域中的学习任务（Fernández-Tobías
    等，[2012](#bib.bib41)；Pan 等，[2010](#bib.bib116)）。深度学习非常适合迁移学习，因为它学习的高级抽象可以解开不同领域的变化。现有的几项工作（Elkahky
    等，[2015](#bib.bib40)；Lian 等，[2017](#bib.bib93)）表明，深度学习在捕捉不同领域之间的普遍性和差异方面效果显著，并能在跨领域平台上生成更好的推荐。因此，这是一个有前景但仍然未被充分探索的领域，期望有更多的研究。
- en: 4.6\. Deep Multi-Task Learning for Recommendation
  id: totrans-325
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6\. 用于推荐的深度多任务学习
- en: 'Multi-task learning has led to successes in many deep learning tasks, from
    computer vision to natural language processing (Deng et al., [2014](#bib.bib32);
    Collobert and Weston, [2008](#bib.bib27)). Among the reviewed studies, several
    works (Jing and Smola, [2017](#bib.bib74); Bansal et al., [2016](#bib.bib6); Li
    et al., [2017](#bib.bib88); Yi et al., [2016](#bib.bib188)) also applied multi-task
    learning to recommender system in a deep neural framework and achieved some improvements
    over single task learning. The advantages of applying deep neural network based
    multi-task learning are three-fold: (1) learning several tasks at a time can prevent
    overfitting by generalizing the shared hidden representations; (2) auxiliary task
    provides interpretable output for explaining the recommendation; (3) multi-task
    provides an implicit data augmentation for alleviating the sparsity problem. Multitask
    can be utilized in traditional recommender system (Ning and Karypis, [2010](#bib.bib112)),
    while deep learning enables them to be integrated in a tighter fashion. Apart
    from introducing side tasks, we can also deploy the multitask learning for cross
    domain recommendation with each specific task generating recommendation for each
    domain.'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务学习已经在许多深度学习任务中取得了成功，从计算机视觉到自然语言处理（Deng等人，[2014](#bib.bib32); Collobert和Weston，[2008](#bib.bib27)）。在审查的研究中，一些工作（Jing和Smola，[2017](#bib.bib74);
    Bansal等人，[2016](#bib.bib6); Li等人，[2017](#bib.bib88); Yi等人，[2016](#bib.bib188)）也在深度神经框架中将多任务学习应用于推荐系统，并在单任务学习上取得了一些改进。应用基于深度神经网络的多任务学习的优点有三个方面：（1）同时学习多个任务可以通过泛化共享隐藏表示来防止过拟合；（2）辅助任务提供可解释的输出，用于解释推荐结果；（3）多任务为减轻稀疏问题提供了隐式数据增强。多任务可以在传统推荐系统中利用（Ning和Karypis，[2010](#bib.bib112)），而深度学习使它们能够更紧密地集成。除了引入附加任务外，我们还可以将多任务学习用于跨领域推荐，每个特定任务生成每个领域的推荐。
- en: 4.7\. Scalability of Deep Neural Networks for Recommendation
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7\. 深度神经网络在推荐系统中的可扩展性
- en: 'The increasing data volumes in the big data era poses challenges to real-world
    applications. Consequently, scalability is critical to the usefulness of recommendation
    models in real-world systems, and the time complexity will also be a principal
    consideration for choosing models. Fortunately, deep learning has demonstrated
    to be very effective and promising in big data analytics (Najafabadi et al., [2015](#bib.bib110))
    especially with the increase of GPU computation power. However, more future works
    should be studied on how to recommend efficiently by exploring the following problems:
    (1) incremental learning for non-stationary and streaming data such as large volume
    of incoming users and items; (2) computation efficiency for high-dimensional tensors
    and multimedia data sources; (3) balancing of the model complexity and scalability
    with the exponential growth of parameters. A promising area of research in this
    area involves knowledge distillation which have been explored in (Tang and Wang,
    [2018b](#bib.bib145)) for learning small/compact models for inference in recommender
    systems. The key idea is to train a smaller student model that absorbs knowledge
    from the large teacher model. Given that inference time is crucial for real time
    applications at a million/billion user scale, we believe that this is another
    promising direction which warrants further investigation. Another promising direction
    involves compression techniques (Serrà and Karatzoglou, [2017](#bib.bib129)).
    The high-dimensional input data can be compressed to compact embedding to reduce
    the space and computation time during model learning.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在大数据时代，不断增长的数据量给实际应用带来了挑战。因此，推荐模型的可扩展性对于实际系统的实用性至关重要，同时时间复杂度也是选择模型的主要考虑因素。幸运的是，深度学习已经证明在大数据分析中（Najafabadi等人，[2015](#bib.bib110)）特别有效和有前景，尤其是随着GPU计算能力的增强。然而，未来需要更多的研究来有效地解决以下问题：（1）增量学习，适用于非稳态和流式数据，例如大量的新用户和物品；（2）高维张量和多媒体数据源的计算效率；（3）在参数指数增长的情况下，模型复杂性和可扩展性的平衡。在这一领域的一个有前景的研究方向涉及知识蒸馏，这在（Tang和Wang，[2018b](#bib.bib145)）中已经探索，用于学习推荐系统中推理的小型/紧凑模型。关键思想是训练一个较小的学生模型，从大型教师模型中吸收知识。鉴于推理时间对百万/亿级用户规模的实时应用至关重要，我们相信这是另一个有前景的方向，值得进一步研究。另一个有前景的方向涉及压缩技术（Serrà和Karatzoglou，[2017](#bib.bib129)）。高维输入数据可以压缩为紧凑的嵌入，以减少模型学习期间的空间和计算时间。
- en: 4.8\. The Field Needs Better, More Unified and Harder Evaluation
  id: totrans-329
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.8\. 该领域需要更好、更统一和更严格的评估。
- en: Each time a new model is proposed, it is expected that the publication offers
    evaluation and comparisons against several baselines. The selection of baselines
    and datasets on most papers are seemingly arbitrary and authors generally have
    free reign over the choices of datasets/baselines. There are several issues with
    this.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 每次提出新模型时，期望出版物能提供与几个基线的评估和比较。大多数论文中基线和数据集的选择似乎是任意的，作者通常可以自由选择数据集/基线。这其中存在几个问题。
- en: Firstly, this creates an inconsistent reporting of scores, with each author
    reporting their own assortment of results. Till this day, there is seemingly on
    consensus on a general ranking of models (Notably, we acknowledge that the no
    free lunch theorem exists). Occasionally, we find that results can be conflicting
    and relative positions change very frequently. For example, the scores of NCF
    in (Zheng et al., [2018](#bib.bib202)) is relatively ranked very low as compared
    to the original paper that proposed the model (He et al., [2017](#bib.bib54)).
    This makes the relative benchmark of new neural models extremely challenging.
    The question is how do we solve this? Looking into neighbouring fields (computer
    vision or natural language processing), this is indeed perplexing. Why is there
    no MNIST, ImageNet or SQuAD for recommender systems? As such, we believe that
    a suite of standardized evaluation datasets should be proposed.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，这导致了分数报告的不一致，每个作者报告他们自己的一组结果。直到今天，似乎没有对模型的一般排名达成共识（值得注意的是，我们承认无免费午餐定理的存在）。有时，我们发现结果可能存在冲突，相对位置变化非常频繁。例如，NCF在（郑等，[2018](#bib.bib202)）中的分数与提出该模型的原始论文（贺等，[2017](#bib.bib54)）相比，排名相对较低。这使得新的神经模型的相对基准极具挑战性。问题是我们如何解决这个问题？观察邻近领域（计算机视觉或自然语言处理），这确实令人困惑。为什么推荐系统没有MNIST、ImageNet或SQuAD？因此，我们认为应该提出一套标准化的评估数据集。
- en: We also note that datasets such as MovieLens are commonly used by many practioners
    in evaluating their models. However, test splits are often arbitrary (randomized).
    The second problem is that there is no control over the evaluation procedure.
    To this end, we urge the recommender systems community to follow the CV/NLP communities
    and establish a hidden/blinded test set in which prediction results can be only
    submitted via a web interface (such as Kaggle).
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还注意到，像MovieLens这样的数据集被许多从业者用来评估他们的模型。然而，测试拆分通常是任意的（随机化）。第二个问题是对评估过程没有控制。为此，我们呼吁推荐系统社区效仿计算机视觉/NLP社区，建立一个隐藏/盲测集，预测结果只能通过网页接口（如Kaggle）提交。
- en: Finally, a third recurring problem is that there is no control over the difficulty
    of test samples in recommender system result. Is splitting by time the best? How
    do we know if test samples are either too trivial or impossible to infer? Without
    designing proper test sets, we argue that it is in fact hard to estimate and measure
    progress of the field. To this end, we believe that the field of recommender systems
    have a lot to learn from computer vision or NLP communities.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，第三个反复出现的问题是对推荐系统结果中测试样本的难度没有控制。按时间拆分是否最佳？我们如何知道测试样本是否过于简单或无法推断？没有设计适当的测试集，我们认为很难估计和衡量该领域的进展。为此，我们相信推荐系统领域有很多可以向计算机视觉或NLP社区学习的地方。
- en: 5\. Conclusion
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5. 结论
- en: In this article, we provided an extensive review of the most notable works to
    date on deep learning based recommender systems. We proposed a classification
    scheme for organizing and clustering existing publications, and highlighted a
    bunch of influential research prototypes. We also discussed the advantages/disadvantages
    of using deep learning techniques for recommendation tasks. Additionally, we detail
    some of the most pressing open problems and promising future extensions. Both
    deep learning and recommender systems are ongoing hot research topics in the recent
    decades. There are a large number of new developing techniques and emerging models
    each year. We hope this survey can provide readers with a comprehensive understanding
    towards the key aspects of this field, clarify the most notable advancements and
    shed some light on future studies.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提供了迄今为止关于基于深度学习的推荐系统的最重要工作的广泛回顾。我们提出了一个分类方案来组织和聚类现有的出版物，并突出了一些有影响力的研究原型。我们还讨论了使用深度学习技术进行推荐任务的优缺点。此外，我们详细介绍了一些最紧迫的未解决问题和有前景的未来扩展。深度学习和推荐系统是近几十年来持续热门的研究主题。每年都有大量新兴的技术和模型。我们希望这项调查能够为读者提供对该领域关键方面的全面理解，澄清最显著的进展，并为未来的研究提供一些启示。
- en: References
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （1）
- en: 'Adomavicius and Tuzhilin (2005) Gediminas Adomavicius and Alexander Tuzhilin.
    2005. Toward the next generation of recommender systems: A survey of the state-of-the-art
    and possible extensions. IEEE transactions on knowledge and data engineering 17,
    6 (2005), 734–749.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adomavicius 和 Tuzhilin（2005）Gediminas Adomavicius 和 Alexander Tuzhilin. 2005.
    面向下一代推荐系统：现状调查及可能的扩展。IEEE 知识与数据工程学报 17, 6 (2005), 734–749。
- en: Alashkar et al. (2017) Taleb Alashkar, Songyao Jiang, Shuyang Wang, and Yun
    Fu. 2017. Examples-Rules Guided Deep Neural Network for Makeup Recommendation.
    In AAAI. 941–947.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alashkar 等（2017）Taleb Alashkar, Songyao Jiang, Shuyang Wang 和 Yun Fu. 2017.
    基于示例规则引导的深度神经网络化妆推荐。在 AAAI 会议中。941–947。
- en: Ba et al. (2014) Jimmy Ba, Volodymyr Mnih, and Koray Kavukcuoglu. 2014. Multiple
    object recognition with visual attention. arXiv preprint arXiv:1412.7755 (2014).
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ba 等（2014）Jimmy Ba, Volodymyr Mnih 和 Koray Kavukcuoglu. 2014. 具有视觉注意的多目标识别。arXiv
    预印本 arXiv:1412.7755（2014）。
- en: 'Bai et al. (2017) Bing Bai, Yushun Fan, Wei Tan, and Jia Zhang. 2017. DLTSR:
    A Deep Learning Framework for Recommendation of Long-tail Web Services. IEEE Transactions
    on Services Computing (2017).'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai 等（2017）Bing Bai, Yushun Fan, Wei Tan 和 Jia Zhang. 2017. DLTSR：一种深度学习框架用于推荐长尾网页服务。IEEE
    服务计算学报（2017）。
- en: 'Bansal et al. (2016) Trapit Bansal, David Belanger, and Andrew McCallum. 2016.
    Ask the gru: Multi-task learning for deep text recommendations. In Proceedings
    of the 10th ACM Conference on Recommender Systems. 107–114.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bansal 等（2016）Trapit Bansal, David Belanger 和 Andrew McCallum. 2016. 询问 gru：用于深度文本推荐的多任务学习。在第10届
    ACM 推荐系统会议中。107–114。
- en: Berg et al. (2017) Rianne van den Berg, Thomas N Kipf, and Max Welling. 2017.
    Graph convolutional matrix completion. arXiv preprint arXiv:1706.02263 (2017).
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Berg 等（2017）Rianne van den Berg, Thomas N Kipf 和 Max Welling. 2017. 图卷积矩阵补全。arXiv
    预印本 arXiv:1706.02263（2017）。
- en: 'Betru et al. (2017) Basiliyos Tilahun Betru, Charles Awono Onana, and Bernabe
    Batchakui. 2017. Deep Learning Methods on Recommender System: A Survey of State-of-the-art.
    International Journal of Computer Applications 162, 10 (Mar 2017).'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Betru 等（2017）Basiliyos Tilahun Betru, Charles Awono Onana 和 Bernabe Batchakui.
    2017. 推荐系统中的深度学习方法：最先进技术的调查。国际计算机应用期刊 162, 10 (2017年3月)。
- en: 'Burke (2002) Robin Burke. 2002. Hybrid recommender systems: Survey and experiments.
    User modeling and user-adapted interaction 12, 4 (2002), 331–370.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Burke（2002）Robin Burke. 2002. 混合推荐系统：调查与实验。用户建模与用户适应互动 12, 4 (2002), 331–370。
- en: Cai et al. (2018) Xiaoyan Cai, Junwei Han, and Libin Yang. 2018. Generative
    Adversarial Network Based Heterogeneous Bibliographic Network Representation for
    Personalized Citation Recommendation. In AAAI.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cai 等（2018）Xiaoyan Cai, Junwei Han 和 Libin Yang. 2018. 基于生成对抗网络的异质文献网络表示用于个性化引用推荐。在
    AAAI 会议中。
- en: Cao et al. (2017) S. Cao, N. Yang, and Z. Liu. 2017. Online news recommender
    based on stacked auto-encoder. In ICIS. 721–726.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等（2017）S. Cao, N. Yang 和 Z. Liu. 2017. 基于堆叠自编码器的在线新闻推荐系统。在 ICIS 会议中。721–726。
- en: 'Catherine and Cohen (2017) Rose Catherine and William Cohen. 2017. Transnets:
    Learning to transform for recommendation. In Recsys. 288–296.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Catherine 和 Cohen（2017）Rose Catherine 和 William Cohen. 2017. Transnets：学习转换以进行推荐。在
    Recsys 会议中。288–296。
- en: Chen et al. (2017) Cheng Chen, Xiangwu Meng, Zhenghua Xu, and Thomas Lukasiewicz.
    2017. Location-Aware Personalized News Recommendation With Deep Semantic Analysis.
    IEEE Access 5 (2017), 1624–1638.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2017) Cheng Chen, Xiangwu Meng, Zhenghua Xu 和 Thomas Lukasiewicz.
    2017. 基于深度语义分析的位置感知个性化新闻推荐。IEEE Access 5 (2017), 1624–1638.
- en: Chen et al. (2017) Cen Chen, Peilin Zhao, Longfei Li, Jun Zhou, Xiaolong Li,
    and Minghui Qiu. 2017. Locally Connected Deep Learning Framework for Industrial-scale
    Recommender Systems. In WWW.
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2017) Cen Chen, Peilin Zhao, Longfei Li, Jun Zhou, Xiaolong Li
    和 Minghui Qiu. 2017. 工业规模推荐系统的局部连接深度学习框架。在 WWW 中。
- en: 'Chen et al. (2017b) Jingyuan Chen, Hanwang Zhang, Xiangnan He, Liqiang Nie,
    Wei Liu, and Tat-Seng Chua. 2017b. Attentive Collaborative Filtering: Multimedia
    Recommendation with Item- and Component-Level Attention. (2017).'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2017b) Jingyuan Chen, Hanwang Zhang, Xiangnan He, Liqiang Nie,
    Wei Liu 和 Tat-Seng Chua. 2017b. 注意力协同过滤：多媒体推荐与项目和组件级注意力。 (2017).
- en: Chen et al. (2012) Minmin Chen, Zhixiang Xu, Kilian Weinberger, and Fei Sha.
    2012. Marginalized denoising autoencoders for domain adaptation. arXiv preprint
    arXiv:1206.4683 (2012).
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2012) Minmin Chen, Zhixiang Xu, Kilian Weinberger 和 Fei Sha. 2012.
    用于域适应的边缘去噪自动编码器。arXiv 预印本 arXiv:1206.4683 (2012).
- en: Chen et al. (2018) Shi-Yong Chen, Yang Yu, Qing Da, Jun Tan, Hai-Kuan Huang,
    and Hai-Hong Tang. 2018. Stabilizing reinforcement learning in dynamic environment
    with application to online recommendation. In SIGKDD. 1187–1196.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2018) Shi-Yong Chen, Yang Yu, Qing Da, Jun Tan, Hai-Kuan Huang
    和 Hai-Hong Tang. 2018. 在动态环境中稳定强化学习，并应用于在线推荐。在 SIGKDD 中。1187–1196.
- en: Chen et al. (2017a) Xu Chen, Yongfeng Zhang, Qingyao Ai, Hongteng Xu, Junchi
    Yan, and Zheng Qin. 2017a. Personalized Key Frame Recommendation. In SIGIR.
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2017a) Xu Chen, Yongfeng Zhang, Qingyao Ai, Hongteng Xu, Junchi
    Yan 和 Zheng Qin. 2017a. 个性化关键帧推荐。在 SIGIR 中。
- en: Chen et al. (2018) Xu Chen, Yongfeng Zhang, Hongteng Xu, Yixin Cao, Zheng Qin,
    and Hongyuan Zha. 2018. Visually Explainable Recommendation. arXiv preprint arXiv:1801.10288
    (2018).
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2018) Xu Chen, Yongfeng Zhang, Hongteng Xu, Yixin Cao, Zheng Qin
    和 Hongyuan Zha. 2018. 可视化可解释推荐。arXiv 预印本 arXiv:1801.10288 (2018).
- en: Chen and de Rijke (2018) Yifan Chen and Maarten de Rijke. 2018. A Collective
    Variational Autoencoder for Top-$N$ Recommendation with Side Information. arXiv
    preprint arXiv:1807.05730 (2018).
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen and de Rijke (2018) Yifan Chen 和 Maarten de Rijke. 2018. 使用侧面信息的 Top-$N$
    推荐的集体变分自动编码器。arXiv 预印本 arXiv:1807.05730 (2018).
- en: Cheng et al. (2016) Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked,
    Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa
    Ispir, and others. 2016. Wide & deep learning for recommender systems. In Recsys.
    7–10.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng et al. (2016) Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked,
    Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa
    Ispir 等。2016. 宽深度学习用于推荐系统。在 Recsys 中。7–10.
- en: Choi et al. (2018) Sungwoon Choi, Heonseok Ha, Uiwon Hwang, Chanju Kim, Jung-Woo
    Ha, and Sungroh Yoon. 2018. Reinforcement Learning based Recommender System using
    Biclustering Technique. arXiv preprint arXiv:1801.05532 (2018).
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Choi et al. (2018) Sungwoon Choi, Heonseok Ha, Uiwon Hwang, Chanju Kim, Jung-Woo
    Ha 和 Sungroh Yoon. 2018. 使用双聚类技术的强化学习推荐系统。arXiv 预印本 arXiv:1801.05532 (2018).
- en: 'Chorowski et al. (2014) Jan Chorowski, Dzmitry Bahdanau, Kyunghyun Cho, and
    Yoshua Bengio. 2014. End-to-end continuous speech recognition using attention-based
    recurrent NN: first results. arXiv preprint arXiv:1412.1602 (2014).'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chorowski et al. (2014) Jan Chorowski, Dzmitry Bahdanau, Kyunghyun Cho 和 Yoshua
    Bengio. 2014. 基于注意力的循环神经网络端到端连续语音识别：首次结果。arXiv 预印本 arXiv:1412.1602 (2014).
- en: Chorowski et al. (2015) Jan K Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk,
    Kyunghyun Cho, and Yoshua Bengio. 2015. Attention-based models for speech recognition.
    In Advances in Neural Information Processing Systems. 577–585.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chorowski et al. (2015) Jan K Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk,
    Kyunghyun Cho 和 Yoshua Bengio. 2015. 基于注意力的模型用于语音识别。在神经信息处理系统进展中。577–585.
- en: 'Christakopoulou et al. (2018) Konstantina Christakopoulou, Alex Beutel, Rui
    Li, Sagar Jain, and Ed H Chi. 2018. Q&R: A Two-Stage Approach toward Interactive
    Recommendation. In SIGKDD. 139–148.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Christakopoulou et al. (2018) Konstantina Christakopoulou, Alex Beutel, Rui
    Li, Sagar Jain 和 Ed H Chi. 2018. Q&R：一种向交互式推荐迈进的两阶段方法。在 SIGKDD 中。139–148.
- en: Chu and Tsai (2017) Wei-Ta Chu and Ya-Lun Tsai. 2017. A hybrid recommendation
    system considering visual information for predicting favorite restaurants. WWWJ
    (2017), 1–19.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chu and Tsai (2017) Wei-Ta Chu 和 Ya-Lun Tsai. 2017. 考虑视觉信息的混合推荐系统，以预测喜爱的餐馆。WWWJ
    (2017)，1–19.
- en: 'Collobert and Weston (2008) Ronan Collobert and Jason Weston. 2008. A unified
    architecture for natural language processing: Deep neural networks with multitask
    learning. In Proceedings of the 25th international conference on Machine learning.
    160–167.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Collobert and Weston (2008) Ronan Collobert 和 Jason Weston. 2008. 自然语言处理的统一架构：具有多任务学习的深度神经网络。In
    第25届国际机器学习会议论文集。160–167。
- en: Covington et al. (2016) Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep
    neural networks for youtube recommendations. In Recsys. 191–198.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Covington et al. (2016) Paul Covington, Jay Adams, 和 Emre Sargin. 2016. YouTube
    推荐的深度神经网络。In Recsys. 191–198。
- en: 'Dai et al. (2016a) Hanjun Dai, Yichen Wang, Rakshit Trivedi, and Le Song. 2016a.
    Deep coevolutionary network: Embedding user and item features for recommendation.
    arXiv preprint. arXiv preprint arXiv:1609.03675 (2016).'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dai et al. (2016a) Hanjun Dai, Yichen Wang, Rakshit Trivedi, 和 Le Song. 2016a.
    深度共演化网络：嵌入用户和项目特征以进行推荐。arXiv 预印本。arXiv 预印本 arXiv:1609.03675 (2016)。
- en: Dai et al. (2016b) Hanjun Dai, Yichen Wang, Rakshit Trivedi, and Le Song. 2016b.
    Recurrent coevolutionary latent feature processes for continuous-time recommendation.
    In Recsys. 29–34.
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dai et al. (2016b) Hanjun Dai, Yichen Wang, Rakshit Trivedi, 和 Le Song. 2016b.
    连续时间推荐的递归共演化潜在特征过程。In Recsys. 29–34。
- en: Davidson et al. (2010) James Davidson, Benjamin Liebald, Junning Liu, Palash
    Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake
    Livingston, and Dasarathi Sampath. 2010. The YouTube Video Recommendation System.
    In Recsys.
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Davidson et al. (2010) James Davidson, Benjamin Liebald, Junning Liu, Palash
    Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake
    Livingston, 和 Dasarathi Sampath. 2010. YouTube 视频推荐系统。In Recsys。
- en: 'Deng et al. (2014) Li Deng, Dong Yu, and others. 2014. Deep learning: methods
    and applications. Foundations and Trends® in Signal Processing 7, 3–4 (2014),
    197–387.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng et al. (2014) Li Deng, Dong Yu, 和其他人。2014. 深度学习：方法与应用。Foundations and Trends®
    in Signal Processing 7, 3–4 (2014), 197–387。
- en: Deng et al. (2017) Shuiguang Deng, Longtao Huang, Guandong Xu, Xindong Wu, and
    Zhaohui Wu. 2017. On deep learning for trust-aware recommendations in social networks.
    IEEE transactions on neural networks and learning systems 28, 5 (2017), 1164–1177.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng et al. (2017) Shuiguang Deng, Longtao Huang, Guandong Xu, Xindong Wu, 和
    Zhaohui Wu. 2017. 关于社交网络中信任感知推荐的深度学习。IEEE 神经网络与学习系统交易 28, 5 (2017), 1164–1177。
- en: Devooght and Bersini (2016) Robin Devooght and Hugues Bersini. 2016. Collaborative
    filtering with recurrent neural networks. arXiv preprint arXiv:1608.07400 (2016).
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Devooght and Bersini (2016) Robin Devooght 和 Hugues Bersini. 2016. 使用递归神经网络的协同过滤。arXiv
    预印本 arXiv:1608.07400 (2016)。
- en: Dong et al. (2017) Xin Dong, Lei Yu, Zhonghuo Wu, Yuxia Sun, Lingfeng Yuan,
    and Fangxi Zhang. 2017. A Hybrid Collaborative Filtering Model with Deep Structure
    for Recommender Systems. In AAAI. 1309–1315.
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong et al. (2017) Xin Dong, Lei Yu, Zhonghuo Wu, Yuxia Sun, Lingfeng Yuan,
    和 Fangxi Zhang. 2017. 具有深度结构的混合协同过滤模型用于推荐系统。In AAAI. 1309–1315。
- en: Donkers et al. (2017) Tim Donkers, Benedikt Loepp, and Jürgen Ziegler. 2017.
    Sequential user-based recurrent neural network recommendations. In Recsys. 152–160.
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Donkers et al. (2017) Tim Donkers, Benedikt Loepp, 和 Jürgen Ziegler. 2017. 基于用户的递归神经网络推荐。In
    Recsys. 152–160。
- en: Du et al. (2016) Chao Du, Chongxuan Li, Yin Zheng, Jun Zhu, and Bo Zhang. 2016.
    Collaborative Filtering with User-Item Co-Autoregressive Models. arXiv preprint
    arXiv:1612.07146 (2016).
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du et al. (2016) Chao Du, Chongxuan Li, Yin Zheng, Jun Zhu, 和 Bo Zhang. 2016.
    基于用户-项目共自回归模型的协同过滤。arXiv 预印本 arXiv:1612.07146 (2016)。
- en: Dziugaite and Roy (2015) Gintare Karolina Dziugaite and Daniel M Roy. 2015.
    Neural network matrix factorization. arXiv preprint arXiv:1511.06443 (2015).
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dziugaite and Roy (2015) Gintare Karolina Dziugaite 和 Daniel M Roy. 2015. 神经网络矩阵分解。arXiv
    预印本 arXiv:1511.06443 (2015)。
- en: Ebesu and Fang (2017) Travis Ebesu and Yi Fang. 2017. Neural Citation Network
    for Context-Aware Citation Recommendation. (2017).
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ebesu and Fang (2017) Travis Ebesu 和 Yi Fang. 2017. 神经引文网络用于上下文感知的引文推荐。 (2017)。
- en: Elkahky et al. (2015) Ali Mamdouh Elkahky, Yang Song, and Xiaodong He. 2015.
    A multi-view deep learning approach for cross domain user modeling in recommendation
    systems. In WWW. 278–288.
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elkahky et al. (2015) Ali Mamdouh Elkahky, Yang Song, 和 Xiaodong He. 2015. 跨域用户建模的多视角深度学习方法。In
    WWW. 278–288。
- en: 'Fernández-Tobías et al. (2012) Ignacio Fernández-Tobías, Iván Cantador, Marius
    Kaminskas, and Francesco Ricci. 2012. Cross-domain recommender systems: A survey
    of the state of the art. In Spanish Conference on Information Retrieval. 24.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fernández-Tobías et al. (2012) Ignacio Fernández-Tobías, Iván Cantador, Marius
    Kaminskas, 和 Francesco Ricci. 2012. 跨域推荐系统：现状调查。In 西班牙信息检索会议。24。
- en: Gao et al. (2014) Jianfeng Gao, Li Deng, Michael Gamon, Xiaodong He, and Patrick
    Pantel. 2014. Modeling interestingness with deep neural networks. (June 13 2014).
    US Patent App. 14/304,863.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao et al. (2014) Jianfeng Gao, Li Deng, Michael Gamon, Xiaodong He, 和 Patrick
    Pantel. 2014. 使用深度神经网络建模兴趣度. (2014年6月13日). 美国专利申请号 14/304,863。
- en: Georgiev and Nakov (2013) Kostadin Georgiev and Preslav Nakov. 2013. A non-iid
    framework for collaborative filtering with restricted boltzmann machines. In ICML.
    1148–1156.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Georgiev and Nakov (2013) Kostadin Georgiev 和 Preslav Nakov. 2013. 一种用于协同过滤的非独立同分布框架，基于限制玻尔兹曼机.
    在ICML会议上. 1148–1156。
- en: 'Gomez-Uribe and Hunt (2016) Carlos A Gomez-Uribe and Neil Hunt. 2016. The netflix
    recommender system: Algorithms, business value, and innovation. TMIS 6, 4 (2016),
    13.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gomez-Uribe and Hunt (2016) Carlos A Gomez-Uribe 和 Neil Hunt. 2016. Netflix推荐系统：算法、商业价值与创新.
    TMIS 6, 4 (2016), 13。
- en: Gong and Zhang (2016) Yuyun Gong and Qi Zhang. 2016. Hashtag Recommendation
    Using Attention-Based Convolutional Neural Network.. In IJCAI. 2782–2788.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gong and Zhang (2016) Yuyun Gong 和 Qi Zhang. 2016. 使用基于注意力的卷积神经网络的标签推荐. 在IJCAI会议上.
    2782–2788。
- en: Goodfellow et al. (2016) Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
    2016. Deep Learning. MIT Press. [http://www.deeplearningbook.org](http://www.deeplearningbook.org).
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow et al. (2016) Ian Goodfellow, Yoshua Bengio, 和 Aaron Courville. 2016.
    深度学习. MIT Press. [http://www.deeplearningbook.org](http://www.deeplearningbook.org)。
- en: Goodfellow et al. (2014) Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
    Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014.
    Generative adversarial nets. In NIPS. 2672–2680.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow et al. (2014) Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
    Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, 和 Yoshua Bengio. 2014.
    生成对抗网络. 在NIPS会议上. 2672–2680。
- en: 'Guo et al. (2017) Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang
    He. 2017. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction.
    In IJCAI. 2782–2788.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo et al. (2017) Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, 和 Xiuqiang
    He. 2017. DeepFM：基于因子分解机的CTR预测神经网络. 在IJCAI会议上. 2782–2788。
- en: He et al. (2016) Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.
    Deep residual learning for image recognition. In Proceedings of the IEEE conference
    on computer vision and pattern recognition. 770–778.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. (2016) Kaiming He, Xiangyu Zhang, Shaoqing Ren, 和 Jian Sun. 2016.
    图像识别的深度残差学习. 在IEEE计算机视觉与模式识别会议论文集. 770–778。
- en: 'He and McAuley (2016a) Ruining He and Julian McAuley. 2016a. Ups and downs:
    Modeling the visual evolution of fashion trends with one-class collaborative filtering.
    In WWW. 507–517.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He and McAuley (2016a) Ruining He 和 Julian McAuley. 2016a. 起伏：利用一类协同过滤建模时尚趋势的视觉演变.
    在WWW会议上. 507–517。
- en: 'He and McAuley (2016b) Ruining He and Julian McAuley. 2016b. VBPR: Visual Bayesian
    Personalized Ranking from Implicit Feedback. In AAAI. 144–150.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He and McAuley (2016b) Ruining He 和 Julian McAuley. 2016b. VBPR：基于隐式反馈的视觉贝叶斯个性化排序.
    在AAAI会议上. 144–150。
- en: He et al. (2018a) Xiangnan He, Xiaoyu Du, Xiang Wang, Feng Tian, Jinhui Tang,
    and Tat-Seng Chua. 2018a. Outer Product-based Neural Collaborative Filtering.
    (2018).
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. (2018a) Xiangnan He, Xiaoyu Du, Xiang Wang, Feng Tian, Jinhui Tang,
    和 Tat-Seng Chua. 2018a. 基于外积的神经协同过滤. (2018)。
- en: He et al. (2018b) Xiangnan He, Zhankui He, Xiaoyu Du, and Tat-Seng Chua. 2018b.
    Adversarial Personalized Ranking for Recommendation. In SIGIR. 355–364.
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. (2018b) Xiangnan He, Zhankui He, Xiaoyu Du, 和 Tat-Seng Chua. 2018b.
    针对推荐的对抗性个性化排序. 在SIGIR会议上. 355–364。
- en: He et al. (2017) Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu,
    and Tat-Seng Chua. 2017. Neural collaborative filtering. In WWW. 173–182.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. (2017) Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu,
    和 Tat-Seng Chua. 2017. 神经协同过滤. 在WWW会议上. 173–182。
- en: He and Tat-Seng (2017) Xiangnan He and Chua Tat-Seng. 2017. Neural Factorization
    Machines for Sparse Predictive Analytics. (2017).
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He and Tat-Seng (2017) Xiangnan He 和 Chua Tat-Seng. 2017. 稀疏预测分析的神经因子分解机. (2017)。
- en: Hidasi and Karatzoglou (2017) Balázs Hidasi and Alexandros Karatzoglou. 2017.
    Recurrent neural networks with top-k gains for session-based recommendations.
    arXiv preprint arXiv:1706.03847 (2017).
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hidasi and Karatzoglou (2017) Balázs Hidasi 和 Alexandros Karatzoglou. 2017.
    带有top-k增益的递归神经网络用于基于会话的推荐. arXiv预印本 arXiv:1706.03847 (2017)。
- en: Hidasi et al. (2015) Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas,
    and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks.
    International Conference on Learning Representations (2015).
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hidasi et al. (2015) Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas,
    和 Domonkos Tikk. 2015. 基于会话的推荐系统与递归神经网络. 国际学习表征会议 (2015)。
- en: Hidasi et al. (2016) Balázs Hidasi, Massimo Quadrana, Alexandros Karatzoglou,
    and Domonkos Tikk. 2016. Parallel recurrent neural network architectures for feature-rich
    session-based recommendations. In Recsys. 241–248.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hidasi 等人（2016）Balázs Hidasi、Massimo Quadrana、Alexandros Karatzoglou 和 Domonkos
    Tikk。2016年。用于特征丰富的会话推荐的并行递归神经网络架构。发表于 Recsys。241–248。
- en: Hornik (1991) Kurt Hornik. 1991. Approximation capabilities of multilayer feedforward
    networks. Neural networks 4, 2 (1991), 251–257.
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hornik（1991）Kurt Hornik。1991年。多层前馈网络的逼近能力。神经网络 4, 2（1991），251–257。
- en: Hornik et al. (1989) Kurt Hornik, Maxwell Stinchcombe, and Halbert White. 1989.
    Multilayer feedforward networks are universal approximators. Neural networks 2,
    5 (1989), 359–366.
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hornik 等人（1989）Kurt Hornik、Maxwell Stinchcombe 和 Halbert White。1989年。多层前馈网络是普适逼近器。神经网络
    2, 5（1989），359–366。
- en: Hsieh et al. (2017) Cheng-Kang Hsieh, Longqi Yang, Yin Cui, Tsung-Yi Lin, Serge
    Belongie, and Deborah Estrin. 2017. Collaborative metric learning. In WWW. 193–201.
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hsieh 等人（2017）Cheng-Kang Hsieh、Longqi Yang、Yin Cui、Tsung-Yi Lin、Serge Belongie
    和 Deborah Estrin。2017年。协同度量学习。发表于 WWW。193–201。
- en: 'Hsieh et al. (2016) Cheng-Kang Hsieh, Longqi Yang, Honghao Wei, Mor Naaman,
    and Deborah Estrin. 2016. Immersive recommendation: News and event recommendations
    using personal digital traces. In WWW. 51–62.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hsieh 等人（2016）Cheng-Kang Hsieh、Longqi Yang、Honghao Wei、Mor Naaman 和 Deborah
    Estrin。2016年。沉浸式推荐：基于个人数字痕迹的新闻和事件推荐。发表于 WWW。51–62。
- en: Hu et al. (2018) Binbin Hu, Chuan Shi, Wayne Xin Zhao, and Philip S Yu. 2018.
    Leveraging Meta-path based Context for Top-N Recommendation with A Neural Co-Attention
    Model. In SIGKDD. 1531–1540.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人（2018）Binbin Hu、Chuan Shi、Wayne Xin Zhao 和 Philip S Yu。2018年。利用基于元路径的上下文进行
    Top-N 推荐，使用神经共注意力模型。发表于 SIGKDD。1531–1540。
- en: Hu et al. (2008) Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative
    Filtering for Implicit Feedback Datasets. In ICDM.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人（2008）Yifan Hu、Yehuda Koren 和 Chris Volinsky。2008年。用于隐式反馈数据集的协同过滤。发表于 ICDM。
- en: Huang et al. (2017) Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q
    Weinberger. 2017. Densely Connected Convolutional Networks.. In CVPR, Vol. 1.
    3.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2017）Gao Huang、Zhuang Liu、Laurens Van Der Maaten 和 Kilian Q Weinberger。2017年。密集连接卷积网络。发表于
    CVPR，第 1 卷。3。
- en: Huang et al. (2013) Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero,
    and Larry Heck. 2013. Learning deep structured semantic models for web search
    using clickthrough data. In CIKM. 2333–2338.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2013）Po-Sen Huang、Xiaodong He、Jianfeng Gao、Li Deng、Alex Acero 和 Larry
    Heck。2013年。使用点击数据学习深度结构语义模型进行网络搜索。发表于 CIKM。2333–2338。
- en: Huang et al. (2015) Wenyi Huang, Zhaohui Wu, Liang Chen, Prasenjit Mitra, and
    C Lee Giles. 2015. A Neural Probabilistic Model for Context Based Citation Recommendation.
    In AAAI. 2404–2410.
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2015）Wenyi Huang、Zhaohui Wu、Liang Chen、Prasenjit Mitra 和 C Lee Giles。2015年。一种用于基于上下文的引用推荐的神经概率模型。发表于
    AAAI。2404–2410。
- en: Hudson and Manning (2018) Drew A Hudson and Christopher D Manning. 2018. Compositional
    attention networks for machine reasoning. arXiv preprint arXiv:1803.03067 (2018).
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hudson 和 Manning（2018）Drew A Hudson 和 Christopher D Manning。2018年。用于机器推理的组合注意力网络。arXiv
    预印本 arXiv:1803.03067（2018）。
- en: Jannach and Ludewig (2017) Dietmar Jannach and Malte Ludewig. 2017. When Recurrent
    Neural Networks Meet the Neighborhood for Session-Based Recommendation. In Recsys.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jannach 和 Ludewig（2017）Dietmar Jannach 和 Malte Ludewig。2017年。当递归神经网络遇上邻域时的会话推荐。发表于
    Recsys。
- en: 'Jannach et al. (2010) Dietmar Jannach, Markus Zanker, Alexander Felfernig,
    and Gerhard Friedrich. 2010. Recommender systems: an introduction.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jannach 等人（2010）Dietmar Jannach、Markus Zanker、Alexander Felfernig 和 Gerhard
    Friedrich。2010年。推荐系统：导论。
- en: Jhamb et al. (2018) Yogesh Jhamb, Travis Ebesu, and Yi Fang. 2018. Attentive
    Contextual Denoising Autoencoder for Recommendation. (2018).
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jhamb 等人（2018）Yogesh Jhamb、Travis Ebesu 和 Yi Fang。2018年。用于推荐的注意力上下文去噪自编码器。（2018）。
- en: Jia et al. (2016) X. Jia, X. Li, K. Li, V. Gopalakrishnan, G. Xun, and A. Zhang.
    2016. Collaborative restricted Boltzmann machine for social event recommendation.
    In ASONAM. 402–405.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jia 等人（2016）X. Jia、X. Li、K. Li、V. Gopalakrishnan、G. Xun 和 A. Zhang。2016年。用于社交事件推荐的协同限制玻尔兹曼机。发表于
    ASONAM。402–405。
- en: Jia et al. (2015) Xiaowei Jia, Aosen Wang, Xiaoyi Li, Guangxu Xun, Wenyao Xu,
    and Aidong Zhang. 2015. Multi-modal learning for video recommendation based on
    mobile application usage. In 2015 IEEE International Conference on Big Data (Big
    Data). 837–842.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jia 等人（2015）Xiaowei Jia、Aosen Wang、Xiaoyi Li、Guangxu Xun、Wenyao Xu 和 Aidong
    Zhang。2015年。基于移动应用使用的多模态视频推荐学习。发表于 2015 IEEE 国际大数据会议（Big Data）。837–842。
- en: Jing and Smola (2017) How Jing and Alexander J Smola. 2017. Neural survival
    recommender. In WSDM. 515–524.
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jing 和 Smola（2017）How Jing 和 Alexander J Smola。2017年。神经生存推荐器。发表于 WSDM。515–524。
- en: 'Khan et al. (2017) Muhammad Murad Khan, Roliana Ibrahim, and Imran Ghani. 2017.
    Cross Domain Recommender Systems: A Systematic Literature Review. ACM Comput.
    Surv. 50, 3 (June 2017).'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan et al. (2017) Muhammad Murad Khan, Roliana Ibrahim, 和 Imran Ghani. 2017.
    跨领域推荐系统：系统文献综述。ACM计算机调查。50, 3 (2017年6月)。
- en: Kim et al. (2016) Donghyun Kim, Chanyoung Park, Jinoh Oh, Sungyoung Lee, and
    Hwanjo Yu. 2016. Convolutional matrix factorization for document context-aware
    recommendation. In Recsys. 233–240.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim et al. (2016) Donghyun Kim, Chanyoung Park, Jinoh Oh, Sungyoung Lee, 和 Hwanjo
    Yu. 2016. 用于文档上下文感知推荐的卷积矩阵分解。在Recsys会议上。233–240。
- en: Kim et al. (2017) Donghyun Kim, Chanyoung Park, Jinoh Oh, and Hwanjo Yu. 2017.
    Deep Hybrid Recommender Systems via Exploiting Document Context and Statistics
    of Items. Information Sciences (2017).
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim et al. (2017) Donghyun Kim, Chanyoung Park, Jinoh Oh, 和 Hwanjo Yu. 2017.
    通过利用文档上下文和项的统计数据的深度混合推荐系统。信息科学（2017）。
- en: Kipf and Welling (2016) Thomas N Kipf and Max Welling. 2016. Semi-supervised
    classification with graph convolutional networks. arXiv preprint arXiv:1609.02907
    (2016).
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kipf and Welling (2016) Thomas N Kipf 和 Max Welling. 2016. 使用图卷积网络的半监督分类。arXiv预印本
    arXiv:1609.02907 (2016)。
- en: Ko et al. (2016) Young-Jun Ko, Lucas Maystre, and Matthias Grossglauser. 2016.
    Collaborative recurrent neural networks for dynamic recommender systems. In Asian
    Conference on Machine Learning. 366–381.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ko et al. (2016) Young-Jun Ko, Lucas Maystre, 和 Matthias Grossglauser. 2016.
    用于动态推荐系统的协同递归神经网络。在亚洲机器学习会议上。366–381。
- en: 'Koren (2008) Yehuda Koren. 2008. Factorization meets the neighborhood: a multifaceted
    collaborative filtering model. In SIGKDD. 426–434.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koren (2008) Yehuda Koren. 2008. 因子分解遇上邻域：一种多面协同过滤模型。在SIGKDD会议上。426–434。
- en: Koren (2010) Yehuda Koren. 2010. Collaborative filtering with temporal dynamics.
    Commun. ACM 53, 4 (2010), 89–97.
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koren (2010) Yehuda Koren. 2010. 具有时间动态的协同过滤。Commun. ACM 53, 4 (2010), 89–97。
- en: Larochelle and Murray (2011) Hugo Larochelle and Iain Murray. 2011. The neural
    autoregressive distribution estimator. In Proceedings of the Fourteenth International
    Conference on Artificial Intelligence and Statistics. 29–37.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Larochelle and Murray (2011) Hugo Larochelle 和 Iain Murray. 2011. 神经自回归分布估计器。在第十四届国际人工智能与统计会议论文集中。29–37。
- en: Lee et al. (2016) Hanbit Lee, Yeonchan Ahn, Haejun Lee, Seungdo Ha, and Sang-goo
    Lee. 2016. Quote Recommendation in Dialogue using Deep Neural Network. In SIGIR.
    957–960.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee et al. (2016) Hanbit Lee, Yeonchan Ahn, Haejun Lee, Seungdo Ha, 和 Sang-goo
    Lee. 2016. 使用深度神经网络的对话推荐。 在SIGIR会议上。957–960。
- en: Lee et al. (2018) Joonseok Lee, Sami Abu-El-Haija, Balakrishnan Varadarajan,
    and Apostol Paul Natsev. 2018. Collaborative Deep Metric Learning for Video Understanding.
    (2018).
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee et al. (2018) Joonseok Lee, Sami Abu-El-Haija, Balakrishnan Varadarajan,
    和 Apostol Paul Natsev. 2018. 用于视频理解的协同深度度量学习。（2018）。
- en: Lei et al. (2016) Chenyi Lei, Dong Liu, Weiping Li, Zheng-Jun Zha, and Houqiang
    Li. 2016. Comparative Deep Learning of Hybrid Representations for Image Recommendations.
    In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.
    2545–2553.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lei et al. (2016) Chenyi Lei, Dong Liu, Weiping Li, Zheng-Jun Zha, 和 Houqiang
    Li. 2016. 图像推荐的混合表示的比较深度学习。在IEEE计算机视觉与模式识别会议论文集中。2545–2553。
- en: Leskovec (2015) Jure Leskovec. 2015. New Directions in Recommender Systems.
    In WSDM.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Leskovec (2015) Jure Leskovec. 2015. 推荐系统的新方向。在WSDM会议上。
- en: Li et al. (2010) Lihong Li, Wei Chu, John Langford, and Robert E Schapire. 2010.
    A contextual-bandit approach to personalized news article recommendation. In Proceedings
    of the 19th international conference on World wide web. 661–670.
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2010) Lihong Li, Wei Chu, John Langford, 和 Robert E Schapire. 2010.
    基于上下文的赌博策略用于个性化新闻文章推荐。在第19届国际万维网会议论文集中。661–670。
- en: Li et al. (2017) Piji Li, Zihao Wang, Zhaochun Ren, Lidong Bing, and Wai Lam.
    2017. Neural Rating Regression with Abstractive Tips Generation for Recommendation.
    (2017).
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2017) Piji Li, Zihao Wang, Zhaochun Ren, Lidong Bing, 和 Wai Lam.
    2017. 带有抽象提示生成的神经评分回归推荐。（2017）。
- en: Li et al. (2015) Sheng Li, Jaya Kawale, and Yun Fu. 2015. Deep collaborative
    filtering via marginalized denoising auto-encoder. In CIKM. 811–820.
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2015) Sheng Li, Jaya Kawale, 和 Yun Fu. 2015. 通过边缘去噪自编码器的深度协同过滤。在CIKM会议上。811–820。
- en: Li and She (2017) Xiaopeng Li and James She. 2017. Collaborative Variational
    Autoencoder for Recommender Systems. In SIGKDD.
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li and She (2017) Xiaopeng Li 和 James She. 2017. 用于推荐系统的协同变分自编码器。在SIGKDD会议上。
- en: Li et al. (2016) Yang Li, Ting Liu, Jing Jiang, and Liang Zhang. 2016. Hashtag
    recommendation with topical attention-based LSTM. In COLING.
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2016) Yang Li, Ting Liu, Jing Jiang, 和 Liang Zhang. 2016. 基于主题注意力的LSTM的标签推荐。在COLING会议上。
- en: 'Li et al. (2018) Zhi Li, Hongke Zhao, Qi Liu, Zhenya Huang, Tao Mei, and Enhong
    Chen. 2018. Learning from History and Present: Next-item Recommendation via Discriminatively
    Exploiting User Behaviors. In SIGKDD. 1734–1743.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2018) Zhi Li, Hongke Zhao, Qi Liu, Zhenya Huang, Tao Mei, 和 Enhong Chen.
    2018. 从历史和现在中学习：通过区分性利用用户行为进行下一个项目推荐. 在 SIGKDD. 1734–1743.
- en: 'Lian et al. (2017) Jianxun Lian, Fuzheng Zhang, Xing Xie, and Guangzhong Sun.
    2017. CCCFNet: A Content-Boosted Collaborative Filtering Neural Network for Cross
    Domain Recommender Systems. In WWW. 817–818.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lian 等 (2017) Jianxun Lian, Fuzheng Zhang, Xing Xie, 和 Guangzhong Sun. 2017.
    CCCFNet: 一种内容增强的协同过滤神经网络用于跨领域推荐系统. 在 WWW. 817–818.'
- en: 'Lian et al. (2018) Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen,
    Xing Xie, and Guangzhong Sun. 2018. xDeepFM: Combining Explicit and Implicit Feature
    Interactions for Recommender Systems. arXiv preprint arXiv:1803.05170 (2018).'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lian 等 (2018) Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing
    Xie, 和 Guangzhong Sun. 2018. xDeepFM: 结合显式和隐式特征交互的推荐系统. arXiv 预印本 arXiv:1803.05170
    (2018).'
- en: Liang et al. (2018) Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony
    Jebara. 2018. Variational Autoencoders for Collaborative Filtering. arXiv preprint
    arXiv:1802.05814 (2018).
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang 等 (2018) Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, 和 Tony Jebara.
    2018. 用于协同过滤的变分自编码器. arXiv 预印本 arXiv:1802.05814 (2018).
- en: Liang et al. (2015) Dawen Liang, Minshu Zhan, and Daniel PW Ellis. 2015. Content-Aware
    Collaborative Music Recommendation Using Pre-trained Neural Networks.. In ISMIR.
    295–301.
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang 等 (2015) Dawen Liang, Minshu Zhan, 和 Daniel PW Ellis. 2015. 使用预训练神经网络的内容感知协同音乐推荐.
    在 ISMIR. 295–301.
- en: Lin et al. (2015) Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu.
    2015. Learning Entity and Relation Embeddings for Knowledge Graph Completion.
    In AAAI. 2181–2187.
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等 (2015) Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, 和 Xuan Zhu. 2015.
    学习实体和关系嵌入以完成知识图谱. 在 AAAI. 2181–2187.
- en: 'Liu and Wu (2017) Juntao Liu and Caihua Wu. 2017. Deep Learning Based Recommendation:
    A Survey.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 和 Wu (2017) Juntao Liu 和 Caihua Wu. 2017. 基于深度学习的推荐：综述.
- en: 'Liu et al. (2017) Qiang Liu, Shu Wu, and Liang Wang. 2017. DeepStyle: Learning
    User Preferences for Visual Recommendation. (2017).'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等 (2017) Qiang Liu, Shu Wu, 和 Liang Wang. 2017. DeepStyle: 学习用户偏好以进行视觉推荐.
    (2017).'
- en: 'Liu et al. (2018) Qiao Liu, Yifu Zeng, Refuoe Mokhosi, and Haibin Zhang. 2018.
    STAMP: Short-Term Attention/Memory Priority Model for Session-based Recommendation.
    In SIGKDD. 1831–1839.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等 (2018) Qiao Liu, Yifu Zeng, Refuoe Mokhosi, 和 Haibin Zhang. 2018. STAMP:
    短期注意力/记忆优先模型用于基于会话的推荐. 在 SIGKDD. 1831–1839.'
- en: Liu et al. (2015) Xiaomeng Liu, Yuanxin Ouyang, Wenge Rong, and Zhang Xiong.
    2015. Item Category Aware Conditional Restricted Boltzmann Machine Based Recommendation.
    In International Conference on Neural Information Processing. 609–616.
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 (2015) Xiaomeng Liu, Yuanxin Ouyang, Wenge Rong, 和 Zhang Xiong. 2015.
    项目类别感知条件限制玻尔兹曼机推荐. 在国际神经信息处理会议. 609–616.
- en: Loyola et al. (2017a) Pablo Loyola, Chen Liu, and Yu Hirate. 2017a. Modeling
    User Session and Intent with an Attention-based Encoder-Decoder Architecture.
    In Recsys. 147–151.
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Loyola 等 (2017a) Pablo Loyola, Chen Liu, 和 Yu Hirate. 2017a. 使用基于注意力的编码器-解码器架构建模用户会话和意图.
    在 Recsys. 147–151.
- en: Loyola et al. (2017b) Pablo Loyola, Chen Liu, and Yu Hirate. 2017b. Modeling
    User Session and Intent with an Attention-based Encoder-Decoder Architecture.
    In Recsys (RecSys ’17).
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Loyola 等 (2017b) Pablo Loyola, Chen Liu, 和 Yu Hirate. 2017b. 使用基于注意力的编码器-解码器架构建模用户会话和意图.
    在 Recsys (RecSys ’17).
- en: Ludewig and Jannach (2018) Malte Ludewig and Dietmar Jannach. 2018. Evaluation
    of Session-based Recommendation Algorithms. CoRR abs/1803.09587 (2018).
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ludewig 和 Jannach (2018) Malte Ludewig 和 Dietmar Jannach. 2018. 会话基础推荐算法的评估.
    CoRR abs/1803.09587 (2018).
- en: Luong et al. (2015) Minh-Thang Luong, Hieu Pham, and Christopher D Manning.
    2015. Effective approaches to attention-based neural machine translation. arXiv
    preprint arXiv:1508.04025 (2015).
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luong 等 (2015) Minh-Thang Luong, Hieu Pham, 和 Christopher D Manning. 2015. 基于注意力的神经机器翻译的有效方法.
    arXiv 预印本 arXiv:1508.04025 (2015).
- en: McAuley et al. (2015) Julian McAuley, Christopher Targett, Qinfeng Shi, and
    Anton Van Den Hengel. 2015. Image-based recommendations on styles and substitutes.
    In SIGIR. 43–52.
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McAuley 等 (2015) Julian McAuley, Christopher Targett, Qinfeng Shi, 和 Anton Van
    Den Hengel. 2015. 基于图像的风格和替代品推荐. 在 SIGIR. 43–52.
- en: Mnih et al. (2015) Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A
    Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K
    Fidjeland, Georg Ostrovski, and others. 2015. Human-level control through deep
    reinforcement learning. Nature 518, 7540 (2015), 529.
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mnih 等 (2015) Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu,
    Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland,
    Georg Ostrovski, 和其他人。2015. 通过深度强化学习实现人类水平的控制。自然 518, 7540 (2015), 529。
- en: Munemasa et al. (2018) Isshu Munemasa, Yuta Tomomatsu, Kunioki Hayashi, and
    Tomohiro Takagi. 2018. Deep Reinforcement Learning for Recommender Systems. (2018).
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Munemasa 等 (2018) Isshu Munemasa, Yuta Tomomatsu, Kunioki Hayashi, 和 Tomohiro
    Takagi. 2018. 推荐系统的深度强化学习。（2018）。
- en: 'Musto et al. (2016) Cataldo Musto, Claudio Greco, Alessandro Suglia, and Giovanni
    Semeraro. 2016. Ask Me Any Rating: A Content-based Recommender System based on
    Recurrent Neural Networks. In IIR.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Musto 等 (2016) Cataldo Musto, Claudio Greco, Alessandro Suglia, 和 Giovanni
    Semeraro. 2016. 任何评分都问我: 基于递归神经网络的内容推荐系统。发表于 IIR。'
- en: Najafabadi et al. (2015) Maryam M Najafabadi, Flavio Villanustre, Taghi M Khoshgoftaar,
    Naeem Seliya, Randall Wald, and Edin Muharemagic. 2015. Deep learning applications
    and challenges in big data analytics. Journal of Big Data 2, 1 (2015), 1.
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Najafabadi 等 (2015) Maryam M Najafabadi, Flavio Villanustre, Taghi M Khoshgoftaar,
    Naeem Seliya, Randall Wald, 和 Edin Muharemagic. 2015. 深度学习在大数据分析中的应用与挑战。大数据期刊
    2, 1 (2015), 1。
- en: Nguyen et al. (2017) Hanh T. H. Nguyen, Martin Wistuba, Josif Grabocka, Lucas Rego
    Drumond, and Lars Schmidt-Thieme. 2017. Personalized Deep Learning for Tag Recommendation.
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nguyen 等 (2017) Hanh T. H. Nguyen, Martin Wistuba, Josif Grabocka, Lucas Rego
    Drumond, 和 Lars Schmidt-Thieme. 2017. 个性化深度学习用于标签推荐。
- en: Ning and Karypis (2010) Xia Ning and George Karypis. 2010. Multi-task learning
    for recommender system. In Proceedings of 2nd Asian Conference on Machine Learning.
    269–284.
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ning 和 Karypis (2010) Xia Ning 和 George Karypis. 2010. 推荐系统的多任务学习。发表于第二届亚洲机器学习会议论文集。269–284。
- en: Niu et al. (2018) Wei Niu, James Caverlee, and Haokai Lu. 2018. Neural Personalized
    Ranking for Image Recommendation. In Proceedings of the Eleventh ACM International
    Conference on Web Search and Data Mining. 423–431.
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Niu 等 (2018) Wei Niu, James Caverlee, 和 Haokai Lu. 2018. 基于神经网络的个性化图像推荐排序。发表于第十一届
    ACM 国际网络搜索与数据挖掘会议论文集。423–431。
- en: Okura et al. (2017) Shumpei Okura, Yukihiro Tagami, Shingo Ono, and Akira Tajima.
    2017. Embedding-based News Recommendation for Millions of Users. In SIGKDD.
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Okura 等 (2017) Shumpei Okura, Yukihiro Tagami, Shingo Ono, 和 Akira Tajima. 2017.
    基于嵌入的新闻推荐系统，服务于百万用户。发表于 SIGKDD。
- en: Ouyang et al. (2014) Yuanxin Ouyang, Wenqi Liu, Wenge Rong, and Zhang Xiong.
    2014. Autoencoder-based collaborative filtering. In International Conference on
    Neural Information Processing. 284–291.
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ouyang 等 (2014) Yuanxin Ouyang, Wenqi Liu, Wenge Rong, 和 Zhang Xiong. 2014.
    基于自编码器的协同过滤。发表于神经信息处理国际会议。284–291。
- en: Pan et al. (2010) Weike Pan, Evan Wei Xiang, Nathan Nan Liu, and Qiang Yang.
    2010. Transfer Learning in Collaborative Filtering for Sparsity Reduction. In
    AAAI, Vol. 10\. 230–235.
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan 等 (2010) Weike Pan, Evan Wei Xiang, Nathan Nan Liu, 和 Qiang Yang. 2010.
    协同过滤中的迁移学习用于稀疏性减少。发表于 AAAI, Vol. 10。230–235。
- en: Pana et al. (2017) Yiteng Pana, Fazhi Hea, and Haiping Yua. 2017. Trust-aware
    Collaborative Denoising Auto-Encoder for Top-N Recommendation. arXiv preprint
    arXiv:1703.01760 (2017).
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pana 等 (2017) Yiteng Pana, Fazhi Hea, 和 Haiping Yua. 2017. 可信任的协同去噪自编码器用于Top-N推荐。arXiv
    预印本 arXiv:1703.01760 (2017)。
- en: Quadrana et al. (2017) Massimo Quadrana, Alexandros Karatzoglou, Balázs Hidasi,
    and Paolo Cremonesi. 2017. Personalizing session-based recommendations with hierarchical
    recurrent neural networks. In Recsys. 130–137.
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Quadrana 等 (2017) Massimo Quadrana, Alexandros Karatzoglou, Balázs Hidasi, 和
    Paolo Cremonesi. 2017. 使用层次递归神经网络个性化基于会话的推荐。发表于 Recsys。130–137。
- en: 'Rawat and Kankanhalli (2016) Yogesh Singh Rawat and Mohan S Kankanhalli. 2016.
    ConTagNet: exploiting user context for image tag recommendation. In Proceedings
    of the 2016 ACM on Multimedia Conference. 1102–1106.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rawat 和 Kankanhalli (2016) Yogesh Singh Rawat 和 Mohan S Kankanhalli. 2016.
    ConTagNet: 利用用户上下文进行图像标签推荐。发表于 2016 ACM 多媒体会议论文集。1102–1106。'
- en: Rendle (2010) S. Rendle. 2010. Factorization Machines. In 2010 IEEE International
    Conference on Data Mining.
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rendle (2010) S. Rendle. 2010. 因子分解机。发表于 2010 IEEE 国际数据挖掘会议。
- en: 'Rendle et al. (2009) Steffen Rendle, Christoph Freudenthaler, Zeno Gantner,
    and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit
    feedback. In Proceedings of the twenty-fifth conference on uncertainty in artificial
    intelligence. 452–461.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rendle 等 (2009) Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, 和 Lars
    Schmidt-Thieme. 2009. BPR: 基于隐式反馈的贝叶斯个性化排序。发表于第二十五届人工智能不确定性会议论文集。452–461。'
- en: 'Ricci et al. (2015) Francesco Ricci, Lior Rokach, and Bracha Shapira. 2015.
    Recommender systems: introduction and challenges. In Recommender systems handbook.
    1–34.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ricci et al. (2015) 弗朗切斯科·里奇、利奥尔·罗卡赫和布拉查·夏皮拉。2015年。推荐系统：介绍和挑战。发表于推荐系统手册，1–34。
- en: 'Rifai et al. (2011) Salah Rifai, Pascal Vincent, Xavier Muller, Xavier Glorot,
    and Yoshua Bengio. 2011. Contractive auto-encoders: Explicit invariance during
    feature extraction. In ICML. 833–840.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rifai et al. (2011) 萨拉赫·里法伊、帕斯卡尔·文森特、泽维尔·穆勒、泽维尔·格洛罗和约书亚·本吉奥。2011年。收缩自编码器：特征提取中的显式不变性。发表于ICML，833–840。
- en: Salakhutdinov et al. (2007) Ruslan Salakhutdinov, Andriy Mnih, and Geoffrey
    Hinton. 2007. Restricted Boltzmann machines for collaborative filtering. In ICML.
    791–798.
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salakhutdinov et al. (2007) 鲁斯兰·萨拉胡丁诺夫、安德烈·姆尼赫和杰弗里·辛顿。2007年。用于协同过滤的限制玻尔兹曼机。发表于ICML，791–798。
- en: Santoro et al. (2017) Adam Santoro, David Raposo, David G Barrett, Mateusz Malinowski,
    Razvan Pascanu, Peter Battaglia, and Tim Lillicrap. 2017. A simple neural network
    module for relational reasoning. In NIPS. 4967–4976.
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Santoro et al. (2017) 亚当·桑托罗、大卫·拉波索、大卫·G·巴雷特、马特乌什·马利诺夫斯基、拉兹万·帕斯卡努、彼得·巴塔利亚和蒂姆·利利克拉普。2017年。用于关系推理的简单神经网络模块。发表于NIPS，4967–4976。
- en: 'Sedhain et al. (2015) Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and
    Lexing Xie. 2015. Autorec: Autoencoders meet collaborative filtering. In WWW.
    111–112.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sedhain et al. (2015) 苏瓦什·塞戴因、阿迪蒂亚·克里希纳·梅农、斯科特·桑纳和莱辛·谢。2015年。Autorec：自编码器遇上协同过滤。发表于WWW，111–112。
- en: Seo et al. (2017a) Sungyong Seo, Jing Huang, Hao Yang, and Yan Liu. 2017a. Interpretable
    convolutional neural networks with dual local and global attention for review
    rating prediction. In Recsys. 297–305.
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Seo et al. (2017a) 崔永镕、景黄、郝洋和阎柳。2017a年。具有双重局部和全局注意力的可解释卷积神经网络用于评论评分预测。发表于Recsys，297–305。
- en: Seo et al. (2017b) Sungyong Seo, Jing Huang, Hao Yang, and Yan Liu. 2017b. Representation
    Learning of Users and Items for Review Rating Prediction Using Attention-based
    Convolutional Neural Network. In MLRec.
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Seo et al. (2017b) 崔永镕、景黄、郝洋和阎柳。2017b年。基于注意力的卷积神经网络用户和项目的表示学习用于评论评分预测。发表于MLRec。
- en: 'Serrà and Karatzoglou (2017) Joan Serrà and Alexandros Karatzoglou. 2017. Getting
    deep recommenders fit: Bloom embeddings for sparse binary input/output networks.
    In Recsys. 279–287.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Serrà and Karatzoglou (2017) 乔安·塞拉和亚历山德罗斯·卡拉佐格卢。2017年。让深度推荐适应：稀疏二进制输入/输出网络的Bloom嵌入。发表于Recsys，279–287。
- en: 'Shan et al. (2016) Ying Shan, T Ryan Hoens, Jian Jiao, Haijing Wang, Dong Yu,
    and JC Mao. 2016. Deep Crossing: Web-scale modeling without manually crafted combinatorial
    features. In SIGKDD. 255–262.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shan et al. (2016) 营珊、T·瑞安·霍恩斯、简·焦和海静·王。2016年。Deep Crossing：无需手动设计组合特征的网页规模建模。发表于SIGKDD，255–262。
- en: Shen et al. (2016) Xiaoxuan Shen, Baolin Yi, Zhaoli Zhang, Jiangbo Shu, and
    Hai Liu. 2016. Automatic Recommendation Technology for Learning Resources with
    Convolutional Neural Network. In International Symposium on Educational Technology.
    30–34.
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen et al. (2016) 邪晓轩、鲍林·易、赵力·张、蒋波·舒和海刘。2016年。用于学习资源的自动推荐技术与卷积神经网络。发表于国际教育技术研讨会，30–34。
- en: 'Shi et al. (2014) Yue Shi, Martha Larson, and Alan Hanjalic. 2014. Collaborative
    filtering beyond the user-item matrix: A survey of the state of the art and future
    challenges. ACM Computing Surveys (CSUR) 47, 1 (2014), 3.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi et al. (2014) 岳·施、玛莎·拉尔森和艾伦·汉贾利奇。2014年。超越用户-项目矩阵的协同过滤：现状调查及未来挑战。ACM计算调查（CSUR）47,
    1（2014），3。
- en: Smirnova and Vasile (2017) Elena Smirnova and Flavian Vasile. 2017. Contextual
    Sequence Modeling for Recommendation with Recurrent Neural Networks. (2017).
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Smirnova and Vasile (2017) 埃琳娜·斯米尔诺娃和弗拉维安·瓦西勒。2017年。用于推荐的上下文序列建模与递归神经网络。 (2017)。
- en: Soh et al. (2017) Harold Soh, Scott Sanner, Madeleine White, and Greg Jamieson.
    2017. Deep Sequential Recommendation for Personalized Adaptive User Interfaces.
    In Proceedings of the 22nd International Conference on Intelligent User Interfaces.
    589–593.
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Soh et al. (2017) 哈罗德·索、斯科特·桑纳、玛德琳·怀特和格雷格·贾米森。2017年。个性化自适应用户界面的深度序列推荐。发表于第22届国际智能用户界面会议，589–593。
- en: Song et al. (2018) Bo Song, Xin Yang, Yi Cao, and Congfu Xu. 2018. Neural Collaborative
    Ranking. arXiv preprint arXiv:1808.04957 (2018).
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song et al. (2018) 博·宋、辛·杨、易·曹和从福·徐。2018年。神经协作排序。arXiv预印本arXiv:1808.04957（2018）。
- en: Song et al. (2016) Yang Song, Ali Mamdouh Elkahky, and Xiaodong He. 2016. Multi-rate
    deep learning for temporal recommendation. In SIGIR. 909–912.
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song et al. (2016) 杨松、阿里·曼杜赫·艾尔卡基和肖栋·赫。2016年。用于时间推荐的多速率深度学习。发表于SIGIR，909–912。
- en: Strub et al. (2016) Florian Strub, Romaric Gaudel, and Jérémie Mary. 2016. Hybrid
    Recommender System based on Autoencoders. In Proceedings of the 1st Workshop on
    Deep Learning for Recommender Systems. 11–16.
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Strub et al. (2016) Florian Strub, Romaric Gaudel, 和 Jérémie Mary. 2016. 基于自编码器的混合推荐系统。发表于第1届深度学习推荐系统研讨会。11–16。
- en: Strub and Mary (2015) Florian Strub and Jeremie Mary. 2015. Collaborative Filtering
    with Stacked Denoising AutoEncoders and Sparse Inputs. In NIPS Workshop.
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Strub and Mary (2015) Florian Strub 和 Jeremie Mary. 2015. 使用堆叠去噪自编码器和稀疏输入的协同过滤。发表于NIPS研讨会。
- en: Su and Khoshgoftaar (2009) Xiaoyuan Su and Taghi M Khoshgoftaar. 2009. A survey
    of collaborative filtering techniques. Advances in artificial intelligence 2009
    (2009), 4.
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Su and Khoshgoftaar (2009) Xiaoyuan Su 和 Taghi M Khoshgoftaar. 2009. 协同过滤技术的综述。人工智能进展
    2009 (2009), 4。
- en: Suglia et al. (2017) Alessandro Suglia, Claudio Greco, Cataldo Musto, Marco
    de Gemmis, Pasquale Lops, and Giovanni Semeraro. 2017. A Deep Architecture for
    Content-based Recommendations Exploiting Recurrent Neural Networks. In Proceedings
    of the 25th Conference on User Modeling, Adaptation and Personalization. 202–211.
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suglia et al. (2017) Alessandro Suglia, Claudio Greco, Cataldo Musto, Marco
    de Gemmis, Pasquale Lops, 和 Giovanni Semeraro. 2017. 利用递归神经网络的内容推荐深度架构。发表于第25届用户建模、适应和个性化会议。202–211。
- en: Suzuki and Ozaki (2017) Yosuke Suzuki and Tomonobu Ozaki. 2017. Stacked Denoising
    Autoencoder-Based Deep Collaborative Filtering Using the Change of Similarity.
    In WAINA. 498–502.
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suzuki and Ozaki (2017) Yosuke Suzuki 和 Tomonobu Ozaki. 2017. 基于堆叠去噪自编码器的深度协同过滤，利用相似度的变化。发表于WAINA。498–502。
- en: Tan et al. (2016a) Jiwei Tan, Xiaojun Wan, and Jianguo Xiao. 2016a. A Neural
    Network Approach to Quote Recommendation in Writings. In Proceedings of the 25th
    ACM International on Conference on Information and Knowledge Management. 65–74.
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan et al. (2016a) Jiwei Tan, Xiaojun Wan, 和 Jianguo Xiao. 2016a. 一种用于文献中的引文推荐的神经网络方法。发表于第25届ACM国际信息与知识管理会议。65–74。
- en: Tan et al. (2016b) Yong Kiam Tan, Xinxing Xu, and Yong Liu. 2016b. Improved
    recurrent neural networks for session-based recommendations. In Recsys. 17–22.
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan et al. (2016b) Yong Kiam Tan, Xinxing Xu, 和 Yong Liu. 2016b. 改进的递归神经网络用于会话推荐。发表于Recsys。17–22。
- en: Tang and Wang (2018a) Jiaxi Tang and Ke Wang. 2018a. Personalized top-n sequential
    recommendation via convolutional sequence embedding. In WSDM. 565–573.
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang and Wang (2018a) Jiaxi Tang 和 Ke Wang. 2018a. 通过卷积序列嵌入进行个性化的 top-n 序列推荐。发表于WSDM。565–573。
- en: 'Tang and Wang (2018b) Jiaxi Tang and Ke Wang. 2018b. Ranking Distillation:
    Learning Compact Ranking Models With High Performance for Recommender System.
    In SIGKDD.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang and Wang (2018b) Jiaxi Tang 和 Ke Wang. 2018b. 排名蒸馏：为推荐系统学习高性能的紧凑排名模型。发表于SIGKDD。
- en: Tay et al. (2018a) Yi Tay, Luu Anh Tuan, and Siu Cheung Hui. 2018a. Latent Relational
    Metric Learning via Memory-based Attention for Collaborative Ranking. In WWW.
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tay et al. (2018a) Yi Tay, Luu Anh Tuan, 和 Siu Cheung Hui. 2018a. 通过基于记忆的注意力进行潜在关系度量学习，以进行协同排名。发表于WWW。
- en: Tay et al. (2018b) Yi Tay, Anh Tuan Luu, and Siu Cheung Hui. 2018b. Multi-Pointer
    Co-Attention Networks for Recommendation. In SIGKDD.
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tay et al. (2018b) Yi Tay, Anh Tuan Luu, 和 Siu Cheung Hui. 2018b. 用于推荐的多指针协同注意力网络。发表于SIGKDD。
- en: Trinh et al. (2018) Trieu H Trinh, Andrew M Dai, Thang Luong, and Quoc V Le.
    2018. Learning longer-term dependencies in rnns with auxiliary losses. arXiv preprint
    arXiv:1803.00144 (2018).
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trinh et al. (2018) Trieu H Trinh, Andrew M Dai, Thang Luong, 和 Quoc V Le. 2018.
    使用辅助损失学习递归神经网络中的长期依赖。arXiv预印本 arXiv:1803.00144 (2018)。
- en: Tuan and Phuong (2017) Trinh Xuan Tuan and Tu Minh Phuong. 2017. 3D Convolutional
    Networks for Session-based Recommendation with Content Features. In Recsys. 138–146.
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tuan and Phuong (2017) Trinh Xuan Tuan 和 Tu Minh Phuong. 2017. 具有内容特征的会话推荐的3D卷积网络。发表于Recsys。138–146。
- en: Twardowski (2016) Bartlomiej Twardowski. 2016. Modelling Contextual Information
    in Session-Aware Recommender Systems with Neural Networks. In Recsys.
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Twardowski (2016) Bartlomiej Twardowski. 2016. 使用神经网络建模会话感知推荐系统中的上下文信息。发表于Recsys。
- en: Unger (2015) Moshe Unger. 2015. Latent Context-Aware Recommender Systems. In
    Recsys. 383–386.
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Unger (2015) Moshe Unger. 2015. 潜在上下文感知推荐系统。发表于Recsys。383–386。
- en: Unger et al. (2016) Moshe Unger, Ariel Bar, Bracha Shapira, and Lior Rokach.
    2016. Towards latent context-aware recommendation systems. Knowledge-Based Systems
    104 (2016), 165–178.
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Unger et al. (2016) Moshe Unger, Ariel Bar, Bracha Shapira, 和 Lior Rokach. 2016.
    面向潜在上下文感知推荐系统的研究。知识基础系统 104 (2016), 165–178。
- en: Uria et al. (2016) Benigno Uria, Marc-Alexandre Côté, Karol Gregor, Iain Murray,
    and Hugo Larochelle. 2016. Neural autoregressive distribution estimation. Journal
    of Machine Learning Research 17, 205 (2016), 1–37.
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Uria等人（2016）Benigno Uria，Marc-Alexandre Côté，Karol Gregor，Iain Murray和Hugo Larochelle。2016。神经自回归分布估计。机器学习研究杂志17,
    205（2016），1–37。
- en: Van den Oord et al. (2013) Aaron Van den Oord, Sander Dieleman, and Benjamin
    Schrauwen. 2013. Deep content-based music recommendation. In NIPS. 2643–2651.
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Van den Oord等人（2013）Aaron Van den Oord，Sander Dieleman和Benjamin Schrauwen。2013。基于内容的深度音乐推荐。在NIPS。2643–2651。
- en: Vartak et al. (2017) Manasi Vartak, Arvind Thiagarajan, Conrado Miranda, Jeshua
    Bratman, and Hugo Larochelle. 2017. A Meta-Learning Perspective on Cold-Start
    Recommendations for Items. In Advances in Neural Information Processing Systems.
    6904–6914.
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vartak等人（2017）Manasi Vartak，Arvind Thiagarajan，Conrado Miranda，Jeshua Bratman和Hugo
    Larochelle。2017。冷启动项目推荐的元学习视角。在神经信息处理系统进展中。6904–6914。
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention
    is all you need. In Advances in Neural Information Processing Systems. 5998–6008.
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani等人（2017）Ashish Vaswani，Noam Shazeer，Niki Parmar，Jakob Uszkoreit，Llion
    Jones，Aidan N Gomez，Łukasz Kaiser和Illia Polosukhin。2017。注意力就是一切。在神经信息处理系统进展中。5998–6008。
- en: 'Volkovs et al. (2017) Maksims Volkovs, Guangwei Yu, and Tomi Poutanen. 2017.
    DropoutNet: Addressing Cold Start in Recommender Systems. In Advances in Neural
    Information Processing Systems. 4957–4966.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Volkovs等人（2017）Maksims Volkovs，Guangwei Yu和Tomi Poutanen。2017。DropoutNet：解决推荐系统中的冷启动问题。在神经信息处理系统进展中。4957–4966。
- en: 'Vuurens et al. (2016) Jeroen B. P. Vuurens, Martha Larson, and Arjen P. de
    Vries. 2016. Exploring Deep Space: Learning Personalized Ranking in a Semantic
    Space. In Recsys.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vuurens等人（2016）Jeroen B. P. Vuurens，Martha Larson和Arjen P. de Vries。2016。探索深空：在语义空间中学习个性化排名。在Recsys。
- en: Wang et al. (2015a) Hao Wang, Xingjian Shi, and Dit-Yan Yeung. 2015a. Relational
    Stacked Denoising Autoencoder for Tag Recommendation.. In AAAI. 3052–3058.
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2015a）Hao Wang，Xingjian Shi和Dit-Yan Yeung。2015a。关系堆叠去噪自编码器用于标签推荐。在AAAI。3052–3058。
- en: Wang et al. (2015b) Hao Wang, Naiyan Wang, and Dit-Yan Yeung. 2015b. Collaborative
    deep learning for recommender systems. In SIGKDD. 1235–1244.
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2015b）Hao Wang，Naiyan Wang和Dit-Yan Yeung。2015b。面向推荐系统的协作深度学习。在SIGKDD。1235–1244。
- en: 'Wang et al. (2016) Hao Wang, SHI Xingjian, and Dit-Yan Yeung. 2016. Collaborative
    recurrent autoencoder: Recommend while learning to fill in the blanks. In NIPS.
    415–423.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2016）Hao Wang，SHI Xingjian和Dit-Yan Yeung。2016。协作递归自编码器：边学边推荐。在NIPS。415–423。
- en: 'Wang and Yeung (2016) Hao Wang and Dit-Yan Yeung. 2016. Towards Bayesian deep
    learning: A framework and some existing methods. TKDE 28, 12 (2016), 3395–3408.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang和Yeung（2016）Hao Wang和Dit-Yan Yeung。2016。向贝叶斯深度学习迈进：框架和一些现有方法。TKDE 28, 12（2016），3395–3408。
- en: 'Wang et al. (2017b) Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu,
    Benyou Wang, Peng Zhang, and Dell Zhang. 2017b. IRGAN: A Minimax Game for Unifying
    Generative and Discriminative Information Retrieval Models. (2017).'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2017b）Jun Wang，Lantao Yu，Weinan Zhang，Yu Gong，Yinghui Xu，Benyou Wang，Peng
    Zhang和Dell Zhang。2017b。IRGAN：统一生成和判别信息检索模型的极小极大博弈。（2017）。
- en: Wang et al. (2018) Lu Wang, Wei Zhang, Xiaofeng He, and Hongyuan Zha. 2018.
    Supervised Reinforcement Learning with Recurrent Neural Network for Dynamic Treatment
    Recommendation. In SIGKDD. 2447–2456.
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2018）Lu Wang，Wei Zhang，Xiaofeng He和Hongyuan Zha。2018。用于动态治疗推荐的监督强化学习与递归神经网络。在SIGKDD。2447–2456。
- en: Wang et al. (2018) Qinyong Wang, Hongzhi Yin, Zhiting Hu, Defu Lian, Hao Wang,
    and Zi Huang. 2018. Neural Memory Streaming Recommender Networks with Adversarial
    Training. In SIGKDD.
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2018）Qinyong Wang，Hongzhi Yin，Zhiting Hu，Defu Lian，Hao Wang和Zi Huang。2018。神经记忆流推荐网络与对抗训练。在SIGKDD。
- en: 'Wang et al. (2017) Suhang Wang, Yilin Wang, Jiliang Tang, Kai Shu, Suhas Ranganath,
    and Huan Liu. 2017. What Your Images Reveal: Exploiting Visual Contents for Point-of-Interest
    Recommendation. In WWW.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2017）Suhang Wang，Yilin Wang，Jiliang Tang，Kai Shu，Suhas Ranganath和Huan
    Liu。2017。你的图像揭示了什么：利用视觉内容进行兴趣点推荐。在WWW。
- en: 'Wang et al. (2017) Xiang Wang, Xiangnan He, Liqiang Nie, and Tat-Seng Chua.
    2017. Item Silk Road: Recommending Items from Information Domains to Social Users.
    (2017).'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2017）Xiang Wang，Xiangnan He，Liqiang Nie和Tat-Seng Chua。2017。商品丝绸之路：从信息领域推荐到社交用户。（2017）。
- en: Wang and Wang (2014) Xinxi Wang and Ye Wang. 2014. Improving content-based and
    hybrid music recommendation using deep learning. In MM. 627–636.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang和Wang（2014）Xinxi Wang和Ye Wang。2014。利用深度学习改进基于内容和混合音乐推荐。在MM。627–636。
- en: 'Wang et al. (2014) Xinxi Wang, Yi Wang, David Hsu, and Ye Wang. 2014. Exploration
    in interactive personalized music recommendation: a reinforcement learning approach.
    TOMM 11, 1 (2014), 7.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2014）Xinxi Wang，Yi Wang，David Hsu 和 Ye Wang。2014。交互式个性化音乐推荐中的探索：一种强化学习方法。TOMM
    11, 1（2014），7。
- en: Wang et al. (2017a) Xuejian Wang, Lantao Yu, Kan Ren, Guangyu Tao, Weinan Zhang,
    Yong Yu, and Jun Wang. 2017a. Dynamic Attention Deep Model for Article Recommendation
    by Learning Human Editors’ Demonstration. In SIGKDD.
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2017a）Xuejian Wang，Lantao Yu，Kan Ren，Guangyu Tao，Weinan Zhang，Yong Yu
    和 Jun Wang。2017a。通过学习人类编辑示范的动态注意深度模型进行文章推荐。在SIGKDD中。
- en: Wei et al. (2016) Jian Wei, Jianhua He, Kai Chen, Yi Zhou, and Zuoyin Tang.
    2016. Collaborative filtering and deep learning based hybrid recommendation for
    cold start problem. IEEE, 874–877.
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人（2016）Jian Wei，Jianhua He，Kai Chen，Yi Zhou 和 Zuoyin Tang。2016。基于协同过滤和深度学习的混合推荐系统解决冷启动问题。IEEE，874–877。
- en: Wei et al. (2017) Jian Wei, Jianhua He, Kai Chen, Yi Zhou, and Zuoyin Tang.
    2017. Collaborative filtering and deep learning based recommendation system for
    cold start items. Expert Systems with Applications 69 (2017), 29–39.
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人（2017）Jian Wei，Jianhua He，Kai Chen，Yi Zhou 和 Zuoyin Tang。2017。基于协同过滤和深度学习的推荐系统解决冷启动问题。Expert
    Systems with Applications 69（2017），29–39。
- en: Wen et al. (2016) Jiqing Wen, Xiaopeng Li, James She, Soochang Park, and Ming
    Cheung. 2016. Visual background recommendation for dance performances using dancer-shared
    images. 521–527.
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wen 等人（2016）Jiqing Wen，Xiaopeng Li，James She，Soochang Park 和 Ming Cheung。2016。使用舞者共享图像为舞蹈表演进行视觉背景推荐。521–527。
- en: Wu et al. (2016c) Caihua Wu, Junwei Wang, Juntao Liu, and Wenyu Liu. 2016c.
    Recurrent neural network based recommendation for time heterogeneous feedback.
    Knowledge-Based Systems 109 (2016), 90–103.
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2016c）Caihua Wu，Junwei Wang，Juntao Liu 和 Wenyu Liu。2016c。基于递归神经网络的时间异构反馈推荐。知识基础系统109（2016），90–103。
- en: Wu et al. (2016) Chao-Yuan Wu, Amr Ahmed, Alex Beutel, and Alexander J Smola.
    2016. Joint Training of Ratings and Reviews with Recurrent Recommender Networks.
    (2016).
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2016）Chao-Yuan Wu，Amr Ahmed，Alex Beutel 和 Alexander J Smola。2016。用递归推荐网络联合训练评分和评论。（2016）。
- en: Wu et al. (2017) Chao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander J Smola, and
    How Jing. 2017. Recurrent recommender networks. In WSDM. 495–503.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2017）Chao-Yuan Wu，Amr Ahmed，Alex Beutel，Alexander J Smola 和 How Jing。2017。递归推荐网络。在WSDM中。495–503。
- en: Wu et al. (2016b) Sai Wu, Weichao Ren, Chengchao Yu, Gang Chen, Dongxiang Zhang,
    and Jingbo Zhu. 2016b. Personal recommendation using deep recurrent neural networks
    in NetEase. In ICDE. 1218–1229.
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2016b）Sai Wu，Weichao Ren，Chengchao Yu，Gang Chen，Dongxiang Zhang 和 Jingbo
    Zhu。2016b。网易中使用深度递归神经网络进行个性化推荐。在ICDE中。1218–1229。
- en: Wu et al. (2016a) Yao Wu, Christopher DuBois, Alice X Zheng, and Martin Ester.
    2016a. Collaborative denoising auto-encoders for top-n recommender systems. In
    WSDM. 153–162.
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2016a）Yao Wu，Christopher DuBois，Alice X Zheng 和 Martin Ester。2016a。协同去噪自编码器用于前n推荐系统。在WSDM中。153–162。
- en: 'Xiao et al. (2017) Jun Xiao, Hao Ye, Xiangnan He, Hanwang Zhang, Fei Wu, and
    Tat-Seng Chua. 2017. Attentional factorization machines: Learning the weight of
    feature interactions via attention networks. arXiv preprint arXiv:1708.04617 (2017).'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiao 等人（2017）Jun Xiao，Hao Ye，Xiangnan He，Hanwang Zhang，Fei Wu 和 Tat-Seng Chua。2017。注意力因子分解机：通过注意力网络学习特征交互的权重。arXiv预印本arXiv:1708.04617（2017）。
- en: Xie et al. (2016a) Ruobing Xie, Zhiyuan Liu, Rui Yan, and Maosong Sun. 2016a.
    Neural Emoji Recommendation in Dialogue Systems. arXiv preprint arXiv:1612.04609
    (2016).
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人（2016a）Ruobing Xie，Zhiyuan Liu，Rui Yan 和 Maosong Sun。2016a。对话系统中的神经表情符号推荐。arXiv预印本arXiv:1612.04609（2016）。
- en: Xie et al. (2016b) Weizhu Xie, Yuanxin Ouyang, Jingshuai Ouyang, Wenge Rong,
    and Zhang Xiong. 2016b. User Occupation Aware Conditional Restricted Boltzmann
    Machine Based Recommendation. 454–461.
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人（2016b）Weizhu Xie，Yuanxin Ouyang，Jingshuai Ouyang，Wenge Rong 和 Zhang Xiong。2016b。基于用户职业感知的条件限制玻尔兹曼机推荐。454–461。
- en: Xiong et al. (2016) Caiming Xiong, Victor Zhong, and Richard Socher. 2016. Dynamic
    coattention networks for question answering. arXiv preprint arXiv:1611.01604 (2016).
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiong 等人（2016）Caiming Xiong，Victor Zhong 和 Richard Socher。2016。动态协同注意力网络用于问答。arXiv预印本arXiv:1611.01604（2016）。
- en: Xu et al. (2016) Zhenghua Xu, Cheng Chen, Thomas Lukasiewicz, Yishu Miao, and
    Xiangwu Meng. 2016. Tag-aware personalized recommendation using a deep-semantic
    similarity model with negative sampling. In CIKM. 1921–1924.
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人（2016）Zhenghua Xu，Cheng Chen，Thomas Lukasiewicz，Yishu Miao 和 Xiangwu Meng。2016。使用深度语义相似度模型和负采样的标签感知个性化推荐。在CIKM中。1921–1924。
- en: Xu et al. (2017) Zhenghua Xu, Thomas Lukasiewicz, Cheng Chen, Yishu Miao, and
    Xiangwu Meng. 2017. Tag-aware personalized recommendation using a hybrid deep
    model. (2017).
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2017) Zhenghua Xu, Thomas Lukasiewicz, Cheng Chen, Yishu Miao, 和
    Xiangwu Meng. 2017. 基于标签的个性化推荐使用混合深度模型。(2017)。
- en: Xue et al. (2017) Hong-Jian Xue, Xinyu Dai, Jianbing Zhang, Shujian Huang, and
    Jiajun Chen. 2017. Deep Matrix Factorization Models for Recommender Systems..
    In IJCAI. 3203–3209.
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xue et al. (2017) Hong-Jian Xue, Xinyu Dai, Jianbing Zhang, Shujian Huang, 和
    Jiajun Chen. 2017. 用于推荐系统的深度矩阵分解模型。发表于 IJCAI. 3203–3209。
- en: 'Yang et al. (2017) Carl Yang, Lanxiao Bai, Chao Zhang, Quan Yuan, and Jiawei
    Han. 2017. Bridging Collaborative Filtering and Semi-Supervised Learning: A Neural
    Approach for POI Recommendation. In SIGKDD.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2017) Carl Yang, Lanxiao Bai, Chao Zhang, Quan Yuan, 和 Jiawei Han.
    2017. 桥接协同过滤和半监督学习：一种用于POI推荐的神经方法。发表于 SIGKDD。
- en: Yao et al. (2016) Lina Yao, Quan Z Sheng, Anne HH Ngu, and Xue Li. 2016. Things
    of interest recommendation by leveraging heterogeneous relations in the internet
    of things. ACM Transactions on Internet Technology (TOIT) 16, 2 (2016), 9.
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2016) Lina Yao, Quan Z Sheng, Anne HH Ngu, 和 Xue Li. 2016. 利用物联网中的异构关系进行兴趣推荐。ACM
    互联网技术论文 (TOIT) 16, 2 (2016), 9。
- en: Yi et al. (2016) Baolin Yi, Xiaoxuan Shen, Zhaoli Zhang, Jiangbo Shu, and Hai
    Liu. 2016. Expanded autoencoder recommendation framework and its application in
    movie recommendation. In SKIMA. 298–303.
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yi et al. (2016) Baolin Yi, Xiaoxuan Shen, Zhaoli Zhang, Jiangbo Shu, 和 Hai
    Liu. 2016. 扩展自编码器推荐框架及其在电影推荐中的应用。发表于 SKIMA. 298–303。
- en: 'Ying et al. (2016) Haochao Ying, Liang Chen, Yuwen Xiong, and Jian Wu. 2016.
    Collaborative deep ranking: a hybrid pair-wise recommendation algorithm with implicit
    feedback. In PAKDD. 555–567.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ying et al. (2016) Haochao Ying, Liang Chen, Yuwen Xiong, 和 Jian Wu. 2016. 协同深度排序：一种具有隐式反馈的混合对偶推荐算法。发表于
    PAKDD. 555–567。
- en: Ying et al. (2018b) Haochao Ying, Fuzhen Zhuang, Fuzheng Zhang, Yanchi Liu,
    Guandong Xu, Xing Xie, Hui Xiong, and Jian Wu. 2018b. Sequential Recommender System
    based on Hierarchical Attention Networks. In IJCAI.
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ying et al. (2018b) Haochao Ying, Fuzhen Zhuang, Fuzheng Zhang, Yanchi Liu,
    Guandong Xu, Xing Xie, Hui Xiong, 和 Jian Wu. 2018b. 基于层次注意力网络的序列推荐系统。发表于 IJCAI。
- en: Ying et al. (2018a) Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L
    Hamilton, and Jure Leskovec. 2018a. Graph Convolutional Neural Networks for Web-Scale
    Recommender Systems. arXiv preprint arXiv:1806.01973 (2018).
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ying et al. (2018a) Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William
    L Hamilton, 和 Jure Leskovec. 2018a. 用于网页规模推荐系统的图卷积神经网络。arXiv 预印本 arXiv:1806.01973
    (2018)。
- en: Yu et al. (2018) Wenhui Yu, Huidi Zhang, Xiangnan He, Xu Chen, Li Xiong, and
    Zheng Qin. 2018. Aesthetic-based clothing recommendation. In WWW. 649–658.
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu et al. (2018) Wenhui Yu, Huidi Zhang, Xiangnan He, Xu Chen, Li Xiong, 和 Zheng
    Qin. 2018. 基于审美的服装推荐。发表于 WWW. 649–658。
- en: Zhang et al. (2016) Fuzheng Zhang, Nicholas Jing Yuan, Defu Lian, Xing Xie,
    and Wei-Ying Ma. 2016. Collaborative knowledge base embedding for recommender
    systems. In SIGKDD. 353–362.
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2016) Fuzheng Zhang, Nicholas Jing Yuan, Defu Lian, Xing Xie,
    和 Wei-Ying Ma. 2016. 协同知识库嵌入推荐系统。发表于 SIGKDD. 353–362。
- en: (194) Qi Zhang, Jiawen Wang, Haoran Huang, Xuanjing Huang, and Yeyun Gong. Hashtag
    Recommendation for Multimodal Microblog Using Co-Attention Network. In IJCAI.
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (194) Qi Zhang, Jiawen Wang, Haoran Huang, Xuanjing Huang, 和 Yeyun Gong. 多模态微博的标签推荐使用共同注意力网络。发表于
    IJCAI。
- en: Zhang et al. (2018) Shuai Zhang, Yi Tay, Lina Yao, and Aixin Sun. 2018. Next
    Item Recommendation with Self-Attention. arXiv preprint arXiv:1808.06414 (2018).
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2018) Shuai Zhang, Yi Tay, Lina Yao, 和 Aixin Sun. 2018. 使用自注意力的下一个项目推荐。arXiv
    预印本 arXiv:1808.06414 (2018)。
- en: 'Zhang et al. (2018) Shuai Zhang, Lina Yao, Aixin Sun, Sen Wang, Guodong Long,
    and Manqing Dong. 2018. NeuRec: On Nonlinear Transformation for Personalized Ranking.
    arXiv preprint arXiv:1805.03002 (2018).'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2018) Shuai Zhang, Lina Yao, Aixin Sun, Sen Wang, Guodong Long,
    和 Manqing Dong. 2018. NeuRec：个性化排序的非线性变换。arXiv 预印本 arXiv:1805.03002 (2018)。
- en: 'Zhang et al. (2017) Shuai Zhang, Lina Yao, and Xiwei Xu. 2017. AutoSVD++: An
    Efficient Hybrid Collaborative Filtering Model via Contractive Auto-encoders.
    (2017).'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2017) Shuai Zhang, Lina Yao, 和 Xiwei Xu. 2017. AutoSVD++：一种通过收缩自编码器的高效混合协同过滤模型。(2017)。
- en: Zhang et al. (2017) Yongfeng Zhang, Qingyao Ai, Xu Chen, and W Bruce Croft.
    2017. Joint representation learning for top-n recommendation with heterogeneous
    information sources. In CIKM. 1449–1458.
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2017) Yongfeng Zhang, Qingyao Ai, Xu Chen, 和 W Bruce Croft. 2017.
    结合异构信息源的 top-n 推荐联合表示学习。发表于 CIKM. 1449–1458。
- en: Zhao et al. (2018a) Xiangyu Zhao, Long Xia, Liang Zhang, Zhuoye Ding, Dawei
    Yin, and Jiliang Tang. 2018a. Deep Reinforcement Learning for Page-wise Recommendations.
    arXiv preprint arXiv:1805.02343 (2018).
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao et al. (2018a) Xiangyu Zhao, Long Xia, Liang Zhang, Zhuoye Ding, Dawei
    Yin, 和 Jiliang Tang. 2018a. 用于页面级推荐的深度强化学习. arXiv 预印本 arXiv:1805.02343 (2018).
- en: Zhao et al. (2018b) Xiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang
    Tang, and Dawei Yin. 2018b. Recommendations with Negative Feedback via Pairwise
    Deep Reinforcement Learning. arXiv preprint arXiv:1802.06501 (2018).
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao et al. (2018b) Xiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang
    Tang, 和 Dawei Yin. 2018b. 通过成对深度强化学习的负反馈推荐. arXiv 预印本 arXiv:1802.06501 (2018).
- en: 'Zheng et al. (2018) Guanjie Zheng, Fuzheng Zhang, Zihan Zheng, Yang Xiang,
    Nicholas Jing Yuan, Xing Xie, and Zhenhui Li. 2018. DRN: A Deep Reinforcement
    Learning Framework for News Recommendation. In WWW. 167–176.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zheng et al. (2018) Guanjie Zheng, Fuzheng Zhang, Zihan Zheng, Yang Xiang,
    Nicholas Jing Yuan, Xing Xie, 和 Zhenhui Li. 2018. DRN: 用于新闻推荐的深度强化学习框架. 在 WWW.
    167–176.'
- en: 'Zheng et al. (2018) Lei Zheng, Chun-Ta Lu, Lifang He, Sihong Xie, Vahid Noroozi,
    He Huang, and Philip S Yu. 2018. MARS: Memory Attention-Aware Recommender System.
    arXiv preprint arXiv:1805.07037 (2018).'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zheng et al. (2018) Lei Zheng, Chun-Ta Lu, Lifang He, Sihong Xie, Vahid Noroozi,
    He Huang, 和 Philip S Yu. 2018. MARS: 记忆注意力感知推荐系统. arXiv 预印本 arXiv:1805.07037 (2018).'
- en: Zheng et al. (2017) Lei Zheng, Vahid Noroozi, and Philip S. Yu. 2017. Joint
    Deep Modeling of Users and Items Using Reviews for Recommendation. In WSDM.
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2017) Lei Zheng, Vahid Noroozi, 和 Philip S. Yu. 2017. 使用评论的用户和项目的联合深度建模用于推荐.
    在 WSDM.
- en: Zheng et al. (2016) Yin Zheng, Cailiang Liu, Bangsheng Tang, and Hanning Zhou.
    2016. Neural Autoregressive Collaborative Filtering for Implicit Feedback. In
    Recsys.
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2016) Yin Zheng, Cailiang Liu, Bangsheng Tang, 和 Hanning Zhou.
    2016. 神经自回归协同过滤用于隐式反馈. 在 Recsys.
- en: Zheng et al. (2016) Yin Zheng, Bangsheng Tang, Wenkui Ding, and Hanning Zhou.
    2016. A Neural Autoregressive Approach to Collaborative Filtering. In ICML.
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2016) Yin Zheng, Bangsheng Tang, Wenkui Ding, 和 Hanning Zhou.
    2016. 一种神经自回归方法用于协同过滤. 在 ICML.
- en: 'Zhou et al. (2017) Chang Zhou, Jinze Bai, Junshuai Song, Xiaofei Liu, Zhengchao
    Zhao, Xiusi Chen, and Jun Gao. 2017. ATRank: An Attention-Based User Behavior
    Modeling Framework for Recommendation. arXiv preprint arXiv:1711.06632 (2017).'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou et al. (2017) Chang Zhou, Jinze Bai, Junshuai Song, Xiaofei Liu, Zhengchao
    Zhao, Xiusi Chen, 和 Jun Gao. 2017. ATRank: 基于注意力的用户行为建模框架用于推荐. arXiv 预印本 arXiv:1711.06632
    (2017).'
- en: Zhou et al. (2016) Jiang Zhou, Cathal Gurrin, and Rami Albatal. 2016. Applying
    visual user interest profiles for recommendation & personalisation. (2016).
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou et al. (2016) Jiang Zhou, Cathal Gurrin, 和 Rami Albatal. 2016. 应用视觉用户兴趣档案进行推荐和个性化.
    (2016).
- en: Zhuang et al. (2017a) Fuzhen Zhuang, Dan Luo, Nicholas Jing Yuan, Xing Xie,
    and Qing He. 2017a. Representation Learning with Pair-wise Constraints for Collaborative
    Ranking. In WSDM. 567–575.
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhuang et al. (2017a) Fuzhen Zhuang, Dan Luo, Nicholas Jing Yuan, Xing Xie,
    和 Qing He. 2017a. 带有成对约束的表示学习用于协同排序. 在 WSDM. 567–575.
- en: Zhuang et al. (2017b) Fuzhen Zhuang, Zhiqiang Zhang, Mingda Qian, Chuan Shi,
    Xing Xie, and Qing He. 2017b. Representation learning via Dual-Autoencoder for
    recommendation. Neural Networks 90 (2017), 83–89.
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhuang et al. (2017b) Fuzhen Zhuang, Zhiqiang Zhang, Mingda Qian, Chuan Shi,
    Xing Xie, 和 Qing He. 2017b. 通过双重自编码器的表示学习用于推荐. Neural Networks 90 (2017), 83–89.
- en: Zuo et al. (2016) Yi Zuo, Jiulin Zeng, Maoguo Gong, and Licheng Jiao. 2016.
    Tag-aware recommender systems based on deep neural networks. Neurocomputing 204
    (2016), 51–60.
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zuo et al. (2016) Yi Zuo, Jiulin Zeng, Maoguo Gong, 和 Licheng Jiao. 2016. 基于深度神经网络的标签感知推荐系统.
    Neurocomputing 204 (2016), 51–60.
