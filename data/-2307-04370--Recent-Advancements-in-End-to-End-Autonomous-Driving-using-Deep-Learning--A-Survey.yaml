- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:38:11'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:38:11
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2307.04370] Recent Advancements in End-to-End Autonomous Driving using Deep
    Learning: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2307.04370] 使用深度学习的端到端自动驾驶的最新进展：一项综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2307.04370](https://ar5iv.labs.arxiv.org/html/2307.04370)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2307.04370](https://ar5iv.labs.arxiv.org/html/2307.04370)
- en: '[type=editor, auid=000,bioid=1, prefix=, orcid=0000-0003-4930-3937]'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[type=editor, auid=000,bioid=1, prefix=, orcid=0000-0003-4930-3937]'
- en: 1]organization=Department of Computer Science and Engineering, Indian Institute
    of Technology Roorkee, city=Roorkee, state=Uttarakhand, country=India
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 1]组织=印度理工学院鲁尔基计算机科学与工程系，城市=鲁尔基，州=乌塔拉坎德，国家=印度
- en: '[type=editor, auid=000,bioid=1, prefix=, orcid=0000-0003-1001-2219]'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[type=editor, auid=000,bioid=1, prefix=, orcid=0000-0003-1001-2219]'
- en: \cormark
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: \cormark
- en: '[1]'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]'
- en: \cortext
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: \cortext
- en: '[cor1]Corresponding author: Pravendra Singh'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[cor1]通讯作者：Pravendra Singh'
- en: 'Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度学习的端到端自动驾驶的最新进展：一项综述
- en: Pranav Singh Chib [    Pravendra Singh pravendra.singh@cs.iitr.ac.in
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Pranav Singh Chib [    Pravendra Singh pravendra.singh@cs.iitr.ac.in
- en: Abstract
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: End-to-End driving is a promising paradigm as it circumvents the drawbacks associated
    with modular systems, such as their overwhelming complexity and propensity for
    error propagation. Autonomous driving transcends conventional traffic patterns
    by proactively recognizing critical events in advance, ensuring passengers safety
    and providing them with comfortable transportation, particularly in highly stochastic
    and variable traffic settings. This paper presents a comprehensive review of the
    End-to-End autonomous driving stack. It provides a taxonomy of automated driving
    tasks wherein neural networks have been employed in an End-to-End manner, encompassing
    the entire driving process from perception to control. Recent developments in
    End-to-End autonomous driving are analyzed, and research is categorized based
    on underlying principles, methodologies, and core functionality. These categories
    encompass sensorial input, main and auxiliary output, learning approaches ranging
    from imitation to reinforcement learning, and model evaluation techniques. The
    survey incorporates a detailed discussion of the explainability and safety aspects.
    Furthermore, it assesses the state-of-the-art, identifies challenges, and explores
    future possibilities. We maintain the latest advancements and their corresponding
    open-source implementations at this [link](https://github.com/Pranav-chib/End-to-End-Autonomous-Driving).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端驾驶是一种有前景的范式，因为它绕过了模块化系统所固有的缺陷，如其复杂性和错误传播的倾向。自动驾驶超越了传统的交通模式，通过主动提前识别关键事件，确保乘客安全，并在高度随机和多变的交通环境中提供舒适的运输。本论文对端到端自动驾驶系统进行了全面的综述。它提供了一个自动化驾驶任务的分类法，其中神经网络以端到端的方式应用，涵盖了从感知到控制的整个驾驶过程。分析了端到端自动驾驶的最新发展，并根据基本原理、方法论和核心功能对研究进行了分类。这些类别包括感知输入、主要和辅助输出、从模仿到强化学习的学习方法以及模型评估技术。调查中详细讨论了可解释性和安全性方面。此外，还评估了最新的进展，识别了挑战，并探索了未来的可能性。我们在此[链接](https://github.com/Pranav-chib/End-to-End-Autonomous-Driving)维护最新的进展及其开源实现。
- en: 'keywords:'
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Autonomous Driving \sepEnd-to-End Driving \sepDeep Learning \sepDeep Neural
    Network
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 自动驾驶 \sep 端到端驾驶 \sep 深度学习 \sep 深度神经网络
- en: 1 Introduction
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Autonomous driving refers to the capability of a vehicle to drive partly or
    entirely without human intervention. The modular architecture [[1](#bib.bib1),
    [2](#bib.bib2), [3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5)] is a widely used
    approach in autonomous driving systems, which divides the driving pipeline into
    discrete sub-tasks. This architecture relies on individual sensors and algorithms
    to process data and generate control outputs. It encompasses interconnected modules,
    including perception, planning, and control. However, the modular architecture
    has certain drawbacks that impede further advancements in autonomous driving (AD).
    One significant limitation is its susceptibility to error propagation. For instance,
    errors in the perception module of a self-driving vehicle, such as misclassification,
    can propagate to subsequent planning and control modules, potentially leading
    to unsafe behaviors. Additionally, the complexity of managing interconnected modules
    and the computational inefficiency of processing data at each stage pose additional
    challenges associated with the modular approach. To address these shortcomings,
    an alternative approach called End-to-End driving [[6](#bib.bib6), [7](#bib.bib7),
    [8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11)] has emerged.
    This approach aims to overcome the limitations of the modular architecture.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 自动驾驶是指车辆在部分或完全没有人工干预的情况下驾驶的能力。模块化架构[[1](#bib.bib1), [2](#bib.bib2), [3](#bib.bib3),
    [4](#bib.bib4), [5](#bib.bib5)] 是自动驾驶系统中广泛使用的一种方法，它将驾驶流程划分为离散的子任务。这种架构依赖于各个传感器和算法来处理数据并生成控制输出。它包括相互关联的模块，如感知、规划和控制。然而，模块化架构存在一些缺陷，阻碍了自动驾驶（AD）的进一步发展。其中一个主要的限制是其易受错误传播的影响。例如，自驾车感知模块中的错误，如误分类，可能会传播到随后的规划和控制模块，从而导致不安全的行为。此外，管理互连模块的复杂性和每个阶段数据处理的计算效率低下，也带来了与模块化方法相关的额外挑战。为了解决这些问题，出现了一种称为端到端驾驶的替代方法[[6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11)]。这种方法旨在克服模块化架构的局限性。
- en: '![Refer to caption](img/15b87b3910b5c50dae8e4d25a022ac6c.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/15b87b3910b5c50dae8e4d25a022ac6c.png)'
- en: 'Figure 1: The number of articles in the Web of Science database containing
    the keywords ‘End-to-End’ and ‘Autonomous Driving’ from 2014 to 2022 illustrates
    the increasing trend in the research community.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：Web of Science数据库中包含关键词“End-to-End”和“Autonomous Driving”的文章数量，从2014年到2022年，显示了研究界不断增长的趋势。
- en: 'The End-to-End approach streamlines the system, improving efficiency and robustness
    by directly mapping sensory input to control outputs. The benefits of End-to-End
    autonomous driving have garnered significant attention in the research community
    as shown in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Recent Advancements in
    End-to-End Autonomous Driving using Deep Learning: A Survey"). Firstly, End-to-End
    driving addresses the issue of error propagation, as it involves a single learning
    task pipeline [[12](#bib.bib12), [13](#bib.bib13)] that learns task-specific features,
    thereby reducing the likelihood of error propagation. Secondly, End-to-End driving
    offers computational advantages. Modular pipelines often entail redundant computations,
    as each module is trained for task-specific outputs [[4](#bib.bib4), [5](#bib.bib5)].
    This results in unnecessary and prolonged computation. In contrast, End-to-End
    driving focuses on the specific task of generating the control signal, reducing
    the need for unnecessary computations and streamlining the overall process. End-to-End
    models were previously regarded as “black boxes", lacking transparency. However,
    recent methodologies have improved interpretability in End-to-End models by generating
    auxiliary outputs [[7](#bib.bib7), [13](#bib.bib13)], attention maps [[14](#bib.bib14),
    [15](#bib.bib15), [16](#bib.bib16), [9](#bib.bib9), [17](#bib.bib17), [18](#bib.bib18)],
    and interpretable maps [[18](#bib.bib18), [19](#bib.bib19), [8](#bib.bib8), [20](#bib.bib20),
    [12](#bib.bib12), [21](#bib.bib21)]. This enhanced interpretability provides insights
    into the root causes of errors and model decision-making. Furthermore, End-to-End
    driving demonstrates resilience to adversarial attacks. Adversarial attacks [[22](#bib.bib22)]
    involve manipulating sensor inputs to deceive or confuse autonomous driving systems.
    In End-to-End models, it is challenging to identify and manipulate the specific
    driving behavior triggers as it is unknown what causes specific driving patterns.
    Lastly, End-to-End driving offers ease of training. Modular pipelines require
    separate training and optimization of each task-driven module, necessitating domain-specific
    knowledge and expertise. In contrast, End-to-End models can learn relevant features
    and patterns [[23](#bib.bib23), [24](#bib.bib24)] directly from raw sensor data,
    reducing the need for extensive engineering and expertise.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '端到端方法通过将感官输入直接映射到控制输出，简化了系统，提高了效率和鲁棒性。端到端自动驾驶的好处在研究界引起了显著关注，如图[1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey")所示。首先，端到端驾驶解决了误差传播的问题，因为它涉及一个单一的学习任务管道[[12](#bib.bib12),
    [13](#bib.bib13)]，该管道学习任务特定的特征，从而减少了误差传播的可能性。其次，端到端驾驶提供了计算优势。模块化管道通常涉及冗余计算，因为每个模块都是针对任务特定的输出进行训练的[[4](#bib.bib4),
    [5](#bib.bib5)]。这导致了不必要和延长的计算。相比之下，端到端驾驶专注于生成控制信号的特定任务，减少了不必要的计算，并简化了整体过程。端到端模型以前被认为是“黑箱”，缺乏透明性。然而，近期的方法通过生成辅助输出[[7](#bib.bib7),
    [13](#bib.bib13)]、注意力图[[14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16), [9](#bib.bib9),
    [17](#bib.bib17), [18](#bib.bib18)]和可解释的图[[18](#bib.bib18), [19](#bib.bib19),
    [8](#bib.bib8), [20](#bib.bib20), [12](#bib.bib12), [21](#bib.bib21)]，提高了端到端模型的可解释性。这种增强的可解释性提供了对错误根本原因和模型决策的洞察。此外，端到端驾驶展示了对对抗攻击的抵抗力。对抗攻击[[22](#bib.bib22)]涉及操控传感器输入，以欺骗或混淆自动驾驶系统。在端到端模型中，识别和操控特定驾驶行为触发点是具有挑战性的，因为具体的驾驶模式的触发原因是不明确的。最后，端到端驾驶具有训练的便利性。模块化管道需要对每个任务驱动模块进行单独的训练和优化，这需要领域特定的知识和专业技能。相比之下，端到端模型可以直接从原始传感器数据中学习相关特征和模式[[23](#bib.bib23),
    [24](#bib.bib24)]，减少了对广泛工程和专业知识的需求。'
- en: '![Refer to caption](img/0f7d2e7c417d0f4b755c81ba1e307a59.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0f7d2e7c417d0f4b755c81ba1e307a59.png)'
- en: 'Figure 2: The charts illustrate statistics of the papers included in this survey
    according to learning approaches (section [6](#S6 "6 Learning approaches for End-to-End
    system ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning:
    A Survey")), environment being utilized for training (sections [10](#S10 "10 Evaluation
    ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey"), [11](#S11 "11 Datasets and simulator ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")), input modality (section [4](#S4
    "4 Input modalities in End-to-End system ‣ Recent Advancements in End-to-End Autonomous
    Driving using Deep Learning: A Survey")), and output modality (section [5](#S5
    "5 Output modalities in End-to-End system ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '图2：这些图表展示了本调查中论文的统计数据，按学习方法（第[6](#S6 "6 Learning approaches for End-to-End
    system ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning:
    A Survey")节）、用于训练的环境（第[10](#S10 "10 Evaluation ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")节、第[11](#S11 "11 Datasets and
    simulator ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning:
    A Survey")节）、输入模态（第[4](#S4 "4 Input modalities in End-to-End system ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey")节）和输出模态（第[5](#S5
    "5 Output modalities in End-to-End system ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")节）进行分类。'
- en: 'Related Surveys: A number of related surveys are available, though their emphasis
    differs from ours. The author Yurtsever et al. [[25](#bib.bib25)] covers the autonomous
    driving domain with a primary emphasis on the modular methodology. Several past
    surveys center around specific learning techniques, such as imitation learning
    [[26](#bib.bib26)] and reinforcement learning [[27](#bib.bib27)]. A few end-to-end
    surveys, including the work by Tampuu et al. [[28](#bib.bib28)], provide an architectural
    overview of the complete end-to-end driving pipeline. Recently, Chen et al. [[29](#bib.bib29)]
    discuss the methodology and challenges in end-to-end autonomous driving in their
    survey. Our focus, however, is on the latest advancements, including modalities,
    learning principles, safety, explainability, and evaluation (see Table LABEL:literature).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 相关调查：虽然有许多相关调查，但它们的重点与我们的不同。作者Yurtsever等人[[25](#bib.bib25)]主要关注于模块化方法的自动驾驶领域。一些早期的调查集中在特定的学习技术上，例如模仿学习[[26](#bib.bib26)]和强化学习[[27](#bib.bib27)]。一些端到端的调查，包括Tampuu等人的工作[[28](#bib.bib28)]，提供了完整端到端驾驶管线的架构概述。最近，Chen等人[[29](#bib.bib29)]在他们的调查中讨论了端到端自动驾驶的方法论和挑战。然而，我们的重点是最新的进展，包括模态、学习原理、安全性、可解释性和评估（见表格LABEL:literature）。
- en: 'Motivation and Contributions: The End-to-End architectures have significantly
    enhanced autonomous driving systems. As elaborated earlier, these architectures
    have overcome the limitations of modular approaches. Motivated by these developments,
    we present a survey on recent advancements in End-to-End autonomous driving. The
    key contributions of this paper are threefold. First, this survey exclusively
    explores End-to-End autonomous driving using deep learning. We provide a comprehensive
    analysis of the underlying principles, methodologies, and functionality, delving
    into the latest state-of-the-art advancements in this domain. Second, we present
    a detailed investigation in terms of modality, learning, safety, explainability,
    and results, and provide a quantitative summary in Table LABEL:literature. Third,
    we present an evaluation framework based on both open and closed-loop assessments
    and compile a summarized list of available datasets and simulators.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 动机与贡献：端到端架构显著提升了自动驾驶系统的性能。如前所述，这些架构克服了模块化方法的局限。受到这些发展的激励，我们呈现了一项关于端到端自动驾驶最新进展的调查。本文的主要贡献有三方面。首先，本调查专门探讨了使用深度学习的端到端自动驾驶。我们提供了对基础原理、方法论和功能的全面分析，深入探讨了该领域最新的前沿进展。第二，我们在模态、学习、安全性、可解释性和结果方面进行了详细调查，并在表格LABEL:literature中提供了定量总结。第三，我们基于开放和闭环评估提出了评估框架，并编制了可用数据集和模拟器的总结列表。
- en: 'Paper Organization: The survey is organized as per the underlying principles
    and methodologies (see Fig. [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey")). We present
    the background of modular systems in Section [2](#S2 "2 Modular system architecture
    ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey"). Section [3](#S3 "3 End-to-End system architecture ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey") provides an overview
    of the End-to-End autonomous driving pipeline architecture. This is followed by
    sections [4](#S4 "4 Input modalities in End-to-End system ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey") and [5](#S5 "5
    Output modalities in End-to-End system ‣ Recent Advancements in End-to-End Autonomous
    Driving using Deep Learning: A Survey"), which discuss the input and output modalities
    of the End-to-End system. Section [6](#S6 "6 Learning approaches for End-to-End
    system ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning:
    A Survey") comprehensively covers End-to-End learning methods, from imitation
    learning to reinforcement learning. The domain adaptation is explained in section
    [7](#S7 "7 Learning domain adaptation from simulator to real ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey"). Next, we explore
    the safety aspect of End-to-End approaches in section [8](#S8 "8 Safety ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey").
    The importance of explainability and interpretability is discussed in section
    [9](#S9 "9 Explainability ‣ Recent Advancements in End-to-End Autonomous Driving
    using Deep Learning: A Survey"). The evaluation of the End-to-End system consists
    of open and closed-loop evaluations, which are discussed in section [10](#S10
    "10 Evaluation ‣ Recent Advancements in End-to-End Autonomous Driving using Deep
    Learning: A Survey"). The relevant datasets and the simulator are presented in
    section [11](#S11 "11 Datasets and simulator ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey"). Finally, sections [12](#S12
    "12 Future research directions ‣ Recent Advancements in End-to-End Autonomous
    Driving using Deep Learning: A Survey") and [13](#S13 "13 Conclusion ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey")
    provide the future research direction and conclusion, respectively.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '论文组织：本调查按基础原则和方法组织（参见图 [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey")）。在第 [2](#S2 "2
    Modular system architecture ‣ Recent Advancements in End-to-End Autonomous Driving
    using Deep Learning: A Survey") 节中，我们介绍了模块化系统的背景。第 [3](#S3 "3 End-to-End system
    architecture ‣ Recent Advancements in End-to-End Autonomous Driving using Deep
    Learning: A Survey") 节提供了端到端自动驾驶管道架构的概述。接下来是第 [4](#S4 "4 Input modalities in End-to-End
    system ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning:
    A Survey") 和 [5](#S5 "5 Output modalities in End-to-End system ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey") 节，讨论了端到端系统的输入和输出模式。第
    [6](#S6 "6 Learning approaches for End-to-End system ‣ Recent Advancements in
    End-to-End Autonomous Driving using Deep Learning: A Survey") 节全面涵盖了端到端学习方法，从模仿学习到强化学习。领域适应在第
    [7](#S7 "7 Learning domain adaptation from simulator to real ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey") 节中进行了解释。接下来，我们在第
    [8](#S8 "8 Safety ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey") 节中探讨端到端方法的安全性方面。第 [9](#S9 "9 Explainability ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey")
    节讨论了解释性和可解释性的重要性。端到端系统的评估包括开放和闭环评估，这些内容在第 [10](#S10 "10 Evaluation ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey") 节中进行了讨论。相关数据集和模拟器在第
    [11](#S11 "11 Datasets and simulator ‣ Recent Advancements in End-to-End Autonomous
    Driving using Deep Learning: A Survey") 节中进行了介绍。最后，第 [12](#S12 "12 Future research
    directions ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning:
    A Survey") 和 [13](#S13 "13 Conclusion ‣ Recent Advancements in End-to-End Autonomous
    Driving using Deep Learning: A Survey") 节分别提供了未来研究方向和结论。'
- en: 2 Modular system architecture
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 模块化系统架构
- en: 'The modular pipeline [[30](#bib.bib30), [31](#bib.bib31), [32](#bib.bib32),
    [2](#bib.bib2), [3](#bib.bib3), [33](#bib.bib33), [34](#bib.bib34)] begins by
    inputting the raw sensory data into the perception module for obstacle detection
    and localization via the localization module, followed by planning and prediction
    for the optimal and safe trajectory of the vehicle. Finally, the motor controller
    outputs the control signals. The standard modules of the modular driving pipeline
    are listed below:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 模块化管道[[30](#bib.bib30), [31](#bib.bib31), [32](#bib.bib32), [2](#bib.bib2),
    [3](#bib.bib3), [33](#bib.bib33), [34](#bib.bib34)]首先将原始传感数据输入感知模块，以进行障碍物检测和通过定位模块定位，然后进行规划和预测，以获得车辆的最佳和安全轨迹。最后，电机控制器输出控制信号。模块化驾驶管道的标准模块如下：
- en: 2.1 Components of modular pipeline
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 模块化管道的组件
- en: 'Preception:'
  id: totrans-32
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 感知：
- en: 'The perception module seeks to achieve a better understanding [[32](#bib.bib32)]
    of the scene. It is built on top of algorithms such as object detection and lane
    detection. The perception module is responsible for sensor fusion, information
    extraction, and acts as a mediator between the low-level sensor input and the
    high-level decision module. It fuses heterogeneous sensors to capture and generalize
    the environment. The primary tasks of the perception module include: (i) Object
    detection (ii) Object tracking (iii) Road and lane detection'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 感知模块力求更好地理解场景[[32](#bib.bib32)]。它建立在物体检测和车道检测等算法之上。感知模块负责传感器融合、信息提取，并充当低级传感器输入与高级决策模块之间的中介。它融合异质传感器以捕捉和概括环境。感知模块的主要任务包括：（i）物体检测
    （ii）物体跟踪 （iii）道路和车道检测
- en: '![Refer to caption](img/62b671d371b6bfca375ab56c92b6267a.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/62b671d371b6bfca375ab56c92b6267a.png)'
- en: 'Figure 3: The perception module receives and processes various raw sensor inputs,
    which are then utilized by the localization and mapping module.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：感知模块接收并处理各种原始传感器输入，然后由定位和映射模块使用。
- en: 'Localization and mapping:'
  id: totrans-36
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 定位与映射：
- en: Localization is the next important module, which is responsible for determining
    the position of the ego vehicle and the corresponding road agents [[35](#bib.bib35)].
    It is crucial for accurately positioning the vehicle and enabling safe maneuvers
    in diverse traffic scenarios. The end product of the localization module is an
    accurate map. Some of the localization techniques include High Definition map
    (HD map) and Simultaneous Localization And Mapping (SLAM), which serve as the
    online map and localize the traffic agents at different time stamps. The localization
    mapping can further be utilized for driving policy and control commands.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 定位是下一个重要模块，它负责确定自我车辆的位置以及相应的道路代理[[35](#bib.bib35)]。这对准确定位车辆并在各种交通场景中实现安全操作至关重要。定位模块的最终产品是准确的地图。一些定位技术包括高清地图（HD
    map）和同时定位与地图构建（SLAM），它们作为在线地图并在不同时间戳本地化交通代理。定位映射还可以进一步用于驾驶策略和控制命令。
- en: 'Planning and driving policy:'
  id: totrans-38
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 规划与驾驶策略：
- en: 'The planning and driving policy module [[36](#bib.bib36)] is responsible for
    computing a motion-level command that determines the control signal based on the
    localization map provided by the previous module. It predicts the optimal future
    trajectory [[37](#bib.bib37)] based on past traffic patterns. The categorization
    of trajectory prediction techniques (Table [1](#S2.T1 "Table 1 ‣ Planning and
    driving policy: ‣ 2.1 Components of modular pipeline ‣ 2 Modular system architecture
    ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey")) is as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 规划与驾驶策略模块[[36](#bib.bib36)]负责计算运动级命令，根据前一模块提供的定位地图确定控制信号。它根据过去的交通模式预测最佳未来轨迹[[37](#bib.bib37)]。轨迹预测技术的分类如下：
- en: •
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Physics-based methods: These methods are suitable for vehicle motion that can
    be accurately characterized by kinematics or dynamics models. They can simulate
    various scenarios quickly with minimal computational cost.'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于物理的方法：这些方法适用于可以通过运动学或动力学模型准确描述的车辆运动。它们可以快速模拟各种场景，计算成本低。
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Classic machine learning-based methods: Compared to physics-based approaches,
    this class of methods can consider more variables, provide reasonable accuracy,
    and have a longer forecasting span, but at a higher computing cost. Most of these
    techniques use historical motion data to estimate future trajectories.'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 经典机器学习方法：与基于物理的方法相比，这类方法能够考虑更多变量，提供合理的准确性，并具有更长的预测跨度，但计算成本更高。大多数这些技术使用历史运动数据来估计未来轨迹。
- en: •
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Deep learning-based methods: Deep learning algorithms are capable of reliable
    prediction over a wider range of prediction horizons. In contrast, standard trajectory
    prediction methods are only suited for basic scenes and short-term prediction.
    Deep learning-based systems can make precise predictions across a wider time horizon.
    As shown in Table [2](#S2.T2 "Table 2 ‣ Planning and driving policy: ‣ 2.1 Components
    of modular pipeline ‣ 2 Modular system architecture ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey"), deep learning utilizes RNN,
    CNN, GNN, and other networks for feature extraction, calculating interaction strength,
    and incorporating map information.'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '基于深度学习的方法：深度学习算法在更广泛的预测范围内能够提供可靠的预测。相比之下，标准的轨迹预测方法仅适用于基本场景和短期预测。深度学习系统能够在更广的时间范围内做出准确预测。如表
    [2](#S2.T2 "表 2 ‣ 规划和驾驶策略: ‣ 2.1 模块化管道的组成部分 ‣ 2 模块化系统架构 ‣ 基于深度学习的端到端自动驾驶的最新进展：综述")
    所示，深度学习利用 RNN、CNN、GNN 等网络进行特征提取、计算交互强度，并整合地图信息。'
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Reinforcement learning-based methods: These methods aim to mimic how people
    make decisions and learn the reward function by studying expert demonstrations
    to produce the best driving strategy. However, most of these techniques are computationally
    costly.'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于强化学习的方法：这些方法旨在模拟人们如何做出决策，通过研究专家示范来学习奖励函数，从而生成最佳驾驶策略。然而，大多数这些技术计算成本较高。
- en: 'Table 1: Performance of different driving policy approaches: PB (Physics-Based),
    CML (Classical Machine Learning), DL (Deep Learning), RL (Reinforcement Learning).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 不同驾驶策略方法的性能：PB（基于物理）、CML（经典机器学习）、DL（深度学习）、RL（强化学习）。'
- en: '| Techniques | Accuracy | Computation cost | Prediction distance |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 技术 | 准确性 | 计算成本 | 预测距离 |'
- en: '| PB | Medium | Low | Short |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| PB | 中等 | 低 | 短 |'
- en: '| CML | Low | Medium | Medium |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| CML | 低 | 中等 | 中等 |'
- en: '| DL | Highly accurate | High | Wide |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| DL | 高精度 | 高 | 广 |'
- en: '| RL | Highly accurate | High | Wide |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| RL | 高精度 | 高 | 广 |'
- en: 'Table 2: Summary of deep learning-based approaches for motion prediction utilizing
    different backbone networks.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 利用不同主干网络进行运动预测的深度学习方法总结。'
- en: '| Methods | Detail | Classification |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 细节 | 分类 |'
- en: '&#124; Agent and context &#124;'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 代理和上下文 &#124;'
- en: '&#124; encoder &#124;'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 编码器 &#124;'
- en: '| Context encoder | Decoder |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 上下文编码器 | 解码器 |'
- en: '| CoverNet [[38](#bib.bib38)] |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| CoverNet [[38](#bib.bib38)] |'
- en: '&#124; Formulation of &#124;'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 公式化 &#124;'
- en: '&#124; classification problem &#124;'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 分类问题 &#124;'
- en: '&#124; over the set of diverse trajectories &#124;'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在多样化轨迹集上 &#124;'
- en: '| CNN | CNN | CNN |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| CNN | CNN | CNN |'
- en: '&#124; Trajectory set &#124;'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 轨迹集 &#124;'
- en: '&#124; generator &#124;'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 生成器 &#124;'
- en: '|'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| HOME [[39](#bib.bib39)] |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| HOME [[39](#bib.bib39)] |'
- en: '&#124; It outputs the &#124;'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 输出 &#124;'
- en: '&#124; 2D top view representation &#124;'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2D 顶视图表示 &#124;'
- en: '&#124; of agent possible future &#124;'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 代理可能的未来 &#124;'
- en: '| CNN | CNN,GRU | CNN | CNN |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| CNN | CNN,GRU | CNN | CNN |'
- en: '| TPCN [[40](#bib.bib40)] |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| TPCN [[40](#bib.bib40)] |'
- en: '&#124; Splitting of trajectory prediction &#124;'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 轨迹预测的分割 &#124;'
- en: '&#124; into both temporal and &#124;'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在时间和 &#124;'
- en: '&#124; spatial dimension &#124;'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 空间维度 &#124;'
- en: '| CNN | PointNET ++ | PointNET++ |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| CNN | PointNET ++ | PointNET++ |'
- en: '&#124; Displacement &#124;'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 位移 &#124;'
- en: '&#124; prediction &#124;'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 预测 &#124;'
- en: '|'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; MHA-JAM &#124;'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; MHA-JAM &#124;'
- en: '&#124; [[41](#bib.bib41)] &#124;'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [[41](#bib.bib41)] &#124;'
- en: '|'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Attention head is used &#124;'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 使用注意力头 &#124;'
- en: '&#124; to generate distinct &#124;'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 生成不同的 &#124;'
- en: '&#124; future trajectories &#124;'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未来轨迹 &#124;'
- en: '&#124; while addressing multimodality &#124;'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 同时处理多模态性 &#124;'
- en: '| Attention | LSTM | CNN | LSTM |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 注意力 | LSTM | CNN | LSTM |'
- en: '|'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; MMTransformer &#124;'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; MMTransformer &#124;'
- en: '&#124; [[42](#bib.bib42)] &#124;'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [[42](#bib.bib42)] &#124;'
- en: '|'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Network architecture &#124;'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 网络架构 &#124;'
- en: '&#124; based on stacked &#124;'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于堆叠 &#124;'
- en: '&#124; transformer to model the &#124;'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; transformer 建模 &#124;'
- en: '&#124; feature multimodality &#124;'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 特征多模态性 &#124;'
- en: '| Attention | Transformer | VectorNet | MLP |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| Attention | Transformer | VectorNet | MLP |'
- en: '| DenseTNT [[43](#bib.bib43)] |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| DenseTNT [[43](#bib.bib43)] |'
- en: '&#124; It is a anchor-free model which &#124;'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 这是一个无锚点模型，其 &#124;'
- en: '&#124; directly outputs from &#124;'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 直接输出自 &#124;'
- en: '&#124; the dense goal candidates &#124;'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 密集目标候选 &#124;'
- en: '| GNN | VectorNet | VectorNet |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| GNN | VectorNet | VectorNet |'
- en: '&#124; Goal Bases &#124;'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 目标基础 &#124;'
- en: '&#124; multi-trajectory &#124;'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 多轨迹 &#124;'
- en: '&#124; prediction &#124;'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 预测 &#124;'
- en: '|'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| TS-GAN [[44](#bib.bib44)] |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| TS-GAN [[44](#bib.bib44)] |'
- en: '&#124; Collaborative learning &#124;'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 协作学习 &#124;'
- en: '&#124; and GAN for modeling &#124;'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和 GAN 用于建模 &#124;'
- en: '&#124; motion behavior &#124;'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 运动行为 &#124;'
- en: '|'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Generative &#124;'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 生成式 &#124;'
- en: '&#124; model &#124;'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模型 &#124;'
- en: '| LSTM | - | LSTM |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| LSTM | - | LSTM |'
- en: '| PRIME [[44](#bib.bib44)] |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| PRIME [[44](#bib.bib44)] |'
- en: '&#124; Utilizes the model generator and &#124;'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 利用模型生成器和 &#124;'
- en: '&#124; learning based evaluator &#124;'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于学习的评估器 &#124;'
- en: '|'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Generative &#124;'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 生成式 &#124;'
- en: '&#124; model &#124;'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模型 &#124;'
- en: '| CNN,LSTM | LSTM |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| CNN,LSTM | LSTM |'
- en: '&#124; Model-based &#124;'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于模型的 &#124;'
- en: '&#124; generator &#124;'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 生成器 &#124;'
- en: '|'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; MotionDiff &#124;'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; MotionDiff &#124;'
- en: '&#124; [[45](#bib.bib45)] &#124;'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [[45](#bib.bib45)] &#124;'
- en: '|'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Diffusion probability based &#124;'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于扩散概率的 &#124;'
- en: '&#124; kinematics model to diffuse &#124;'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 运动学模型以扩散 &#124;'
- en: '&#124; original states to &#124;'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原始状态到 &#124;'
- en: '&#124; noise distribution &#124;'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 噪声分布 &#124;'
- en: '| CNN |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| CNN |'
- en: '&#124; Spatial &#124;'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 空间 &#124;'
- en: '&#124; transformer, &#124;'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; transformer, &#124;'
- en: '&#124; GRU &#124;'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GRU &#124;'
- en: '|'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Spatial &#124;'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 空间 &#124;'
- en: '&#124; transformer, &#124;'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; transformer, &#124;'
- en: '&#124; GRU &#124;'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GRU &#124;'
- en: '| MLP |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| MLP |'
- en: '| ScePT [[10](#bib.bib10)] |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| ScePT [[10](#bib.bib10)] |'
- en: '&#124; A policy planning &#124;'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 策略规划 &#124;'
- en: '&#124; based trajectory prediction for &#124;'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于轨迹预测的 &#124;'
- en: '&#124; accurate motion planning. &#124;'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 精确的运动规划。&#124;'
- en: '| GNN | LSTM | CNN | GRU, PonitNET |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| GNN | LSTM | CNN | GRU, PonitNET |'
- en: 'Control:'
  id: totrans-147
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 控制：
- en: The motion planner generates the trajectory, which is then updated by the obstacle
    subsystem and sent to the controller subsystem. The computed command is sent to
    the actuators of the driving components, including the throttle, brakes, and steering,
    to follow the desired trajectory, which is optimized and safer in real-world scenarios.
    The Proportional Integral Derivative (PID) [[5](#bib.bib5)] and Model Predictive
    Control (MPC) [[4](#bib.bib4)] are some of the controllers used to generate the
    aforementioned control signals.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 运动规划器生成轨迹，随后由障碍物子系统更新，并发送到控制器子系统。计算出的命令被发送到驱动组件的执行器，包括油门、刹车和方向盘，以跟随所需的轨迹，这些轨迹在实际场景中经过优化，更加安全。比例积分微分（PID）[[5](#bib.bib5)]
    和模型预测控制（MPC）[[4](#bib.bib4)] 是用于生成上述控制信号的一些控制器。
- en: 2.2 Input and output modality of modular pipeline
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 模块化管道的输入和输出模式
- en: The output modality of each module is designed to be compatible with the input
    modality of subsequent modules in the pipeline to ensure that information is correctly
    propagated through the modular system.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模块的输出模式被设计为与管道中后续模块的输入模式兼容，以确保信息在模块化系统中正确传播。
- en: 'Sensory data:'
  id: totrans-151
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 感知数据：
- en: 'At this level (Fig. [3](#S2.F3 "Figure 3 ‣ Preception: ‣ 2.1 Components of
    modular pipeline ‣ 2 Modular system architecture ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")), the raw data from the embedded
    multi-sensor array is retrieved, filtered, and processed for semantic mapping.
    LiDAR, RADAR, Camera, GPS, and Odometer are some of the sensor inputs to the perception
    stack. LiDAR and RADAR are used for depth analysis, while cameras are employed
    for detection. The INU, GPS, and Odometer sensors capture and map the vehicle’s
    position, state, and the corresponding environment, which can be further utilized
    by decision-level stages.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个层级（图 [3](#S2.F3 "图 3 ‣ 感知： ‣ 2.1 模块化管道的组成部分 ‣ 2 模块化系统架构 ‣ 基于深度学习的端到端自动驾驶的最新进展：一项调查")），从嵌入式多传感器阵列中提取原始数据，对其进行过滤和处理，以进行语义映射。LiDAR、RADAR、相机、GPS
    和里程表是感知堆栈的一些传感器输入。LiDAR 和 RADAR 用于深度分析，而相机用于检测。INU、GPS 和里程表传感器捕捉并映射车辆的位置、状态和相应环境，这些数据可以在决策级别阶段进一步利用。
- en: 'Input to the mapping and localization:'
  id: totrans-153
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 输入到映射和定位：
- en: Localization aims to estimate the vehicle’s position at each time stamp. Utilizing
    information from the perception module, the vehicle’s position and the environment
    are mapped based on parameters such as position, orientation, pose, speed, and
    acceleration. Localization techniques [[3](#bib.bib3)] allow for the integration
    of multiple objects and the identification of their relationships, resulting in
    a more comprehensive, augmented, and enriched representation.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 定位旨在估计每个时间戳下车辆的位置。利用感知模块的信息，基于位置、方向、姿态、速度和加速度等参数来映射车辆的位置和环境。定位技术 [[3](#bib.bib3)]
    允许整合多个对象并识别其关系，从而获得更全面、增强和丰富的表示。
- en: 'As shown in Fig. [4](#S2.F4 "Figure 4 ‣ Input to the mapping and localization:
    ‣ 2.2 Input and output modality of modular pipeline ‣ 2 Modular system architecture
    ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey"), we define $X_{t}$ as the vehicle’s position estimate at time $t$, and
    $M$ as the environment map. These variables can be estimated using control inputs
    $C_{t}$, which are typically derived from wheel encoders or sensors capable of
    estimating the vehicle’s displacement. The measurements derived from sensor readings
    are denoted by $S_{t}$ and are used to aid in the estimation of the vehicle’s
    pose.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [4](#S2.F4 "图 4 ‣ 输入到映射和定位： ‣ 2.2 模块化管道的输入和输出模式 ‣ 2 模块化系统架构 ‣ 使用深度学习的端到端自主驾驶的最新进展：综述")
    所示，我们定义 $X_{t}$ 为时间 $t$ 下的车辆位置估计值，$M$ 为环境地图。这些变量可以使用控制输入 $C_{t}$ 来估计，这些控制输入通常来自轮编码器或能够估计车辆位移的传感器。传感器读取的测量值用
    $S_{t}$ 表示，用于辅助估计车辆的姿态。
- en: '![Refer to caption](img/fee2674117aa2ebd417362496131a674.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/fee2674117aa2ebd417362496131a674.png)'
- en: 'Figure 4: Visualization of temporal correlations from localization that can
    be used to identify specific behaviors and predict future positions.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：定位中时间相关性的可视化，这些相关性可以用于识别特定行为并预测未来位置。
- en: 'Input to the path planning and decision module:'
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 路径规划和决策模块的输入：
- en: Path planning is broadly categorized into local and global path planners. The
    purpose of the local planner is to execute the goals set by the global path planner.
    It is responsible for finding trajectories that avoid obstacles and satisfy optimization
    requirements within the vehicle’s operational space.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 路径规划通常分为局部路径规划器和全局路径规划器。局部规划器的目的是执行全局路径规划器设定的目标。它负责寻找避开障碍物并满足优化要求的轨迹，且这些轨迹位于车辆的操作空间内。
- en: The problem of local trajectory prediction can be formulated as estimating the
    future states ($t_{f}$) of various traffic actors ($R^{t}$) in a given scenario
    based on their current and past states ($t_{h}$). The state of traffic actors
    includes vehicles or pedestrians with historical trajectories at different time
    stamps.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 局部轨迹预测问题可以表述为在给定情境下，根据各种交通参与者（$R^{t}$）的当前和过去状态（$t_{h}$）来估计未来状态（$t_{f}$）。交通参与者的状态包括在不同时间戳的历史轨迹的车辆或行人。
- en: '|  | $Input=\{R^{1},R^{2},R^{3},R^{3}.\;.\;.\;.\;.\;.,R^{t_{h}}\}$ |  | (1)
    |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|  | $Input=\{R^{1},R^{2},R^{3},R^{3}.\;.\;.\;.\;.\;.,R^{t_{h}}\}$ |  | (1)
    |'
- en: where $R^{t}$ contains the coordinates of different traffic actors at each time
    stamp $t$ (up to $h$ past time stamps).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$R^{t}$ 包含每个时间戳 $t$ 下不同交通参与者的坐标（最多到 $h$ 个过去的时间戳）。
- en: '|  | $R^{t}=\{x_{0}^{t},y_{0}^{t},x_{1}^{t},y_{1}^{t}\;.\;.\;.\;x_{n}^{t},y_{n}^{t}\}$
    |  | (2) |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '|  | $R^{t}=\{x_{0}^{t},y_{0}^{t},x_{1}^{t},y_{1}^{t}\;.\;.\;.\;x_{n}^{t},y_{n}^{t}\}$
    |  | (2) |'
- en: where $n$ represents all traffic vehicles detected by the ego vehicle; ($x_{i}^{t},y_{i}^{t}$)
    are the coordinates of the vehicle at the $t$ time stamp. $X$ is the input to
    the path planning module, and the vehicle trajectory $Y$ is predicted from the
    model at future time stamp $t_{f}$.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$n$ 表示由自车检测到的所有交通车辆；($x_{i}^{t},y_{i}^{t}$) 是车辆在 $t$ 时间戳下的坐标。$X$ 是路径规划模块的输入，而车辆轨迹
    $Y$ 是从模型中预测出的未来时间戳 $t_{f}$ 下的轨迹。
- en: '|  | $Y=\left\{R^{t_{h}+1},R^{t_{h}+2},R^{t_{h}+3}\cdot\cdot\cdot R^{t_{h}+t_{f}}\right\}$
    |  | (3) |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '|  | $Y=\left\{R^{t_{h}+1},R^{t_{h}+2},R^{t_{h}+3}\cdot\cdot\cdot R^{t_{h}+t_{f}}\right\}$
    |  | (3) |'
- en: 'Input to the control module:'
  id: totrans-166
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 控制模块的输入：
- en: 'There are two primary forms of trajectory command that the controller receives:
    (i) as a series of commands ($T_{c}$) and (ii) as a series of states ($T_{s}$).
    Controller subsystems that receive a $T_{s}$ trajectory may be categorized as
    path tracking techniques, while those that receive a $T_{c}$ trajectory can be
    classified as direct hardware actuation control methods.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器接收的轨迹命令主要有两种形式：（i）作为一系列命令（$T_{c}$）和（ii）作为一系列状态（$T_{s}$）。接收$T_{s}$轨迹的控制器子系统可以归类为路径跟踪技术，而接收$T_{c}$轨迹的则可以归类为直接硬件驱动控制方法。
- en: •
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Direct hardware actuation control methods: The Proportional Integral Derivative
    (PID) [[5](#bib.bib5)] control system is a commonly used hardware actuation technique
    for self-driving automobiles. It involves determining a desired hardware input
    and an error measure gauging how much the output deviates from the desired outcome.'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 直接硬件驱动控制方法：比例积分微分（PID）[[5](#bib.bib5)] 控制系统是一种常用的自驾车硬件驱动技术。它涉及确定所需的硬件输入以及一个误差测量值，以衡量输出与期望结果的偏差程度。
- en: •
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Path tracking methods: Model Predictive Control (MPC) [[4](#bib.bib4)] is a
    path-tracking approach that involves choosing control command inputs that will
    result in desirable hardware outputs, then simulating and optimizing those outputs
    using the motion model of the car over a future prediction horizon.'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 路径跟踪方法：模型预测控制（MPC）[[4](#bib.bib4)] 是一种路径跟踪方法，它涉及选择控制命令输入，以获得期望的硬件输出，然后使用汽车的运动模型在未来预测范围内对这些输出进行模拟和优化。
- en: 3 End-to-End system architecture
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 端到端系统架构
- en: 'In general, modular systems are referred to as the mediated paradigm and are
    constructed as a pipeline of discrete components (Fig. [5](#S3.F5 "Figure 5 ‣
    3 End-to-End system architecture ‣ Recent Advancements in End-to-End Autonomous
    Driving using Deep Learning: A Survey")) that connect sensory inputs and motor
    outputs. The core processes of a modular system include perception, localization,
    mapping, planning, and vehicle control [[1](#bib.bib1)]. The modular pipeline
    starts by inputting raw sensory data to the perception module for obstacle detection
    [[46](#bib.bib46)] and localization via the localization module [[3](#bib.bib3)].
    This is followed by planning and prediction [[44](#bib.bib44)] to determine the
    optimal and safe trajectory for the vehicle. Finally, the motor controller generates
    commands for safe maneuvering.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '通常，模块化系统被称为中介范式，并构建为离散组件的管道（图 [5](#S3.F5 "Figure 5 ‣ 3 End-to-End system architecture
    ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey)")，这些组件连接感知输入和运动输出。模块化系统的核心过程包括感知、定位、映射、规划和车辆控制[[1](#bib.bib1)]。模块化管道首先将原始传感数据输入到感知模块中进行障碍物检测[[46](#bib.bib46)]
    和通过定位模块进行定位[[3](#bib.bib3)]。接下来是规划和预测[[44](#bib.bib44)]，以确定车辆的最佳安全轨迹。最后，电动机控制器生成安全操控的指令。'
- en: 'On the other hand, direct perception or End-to-End driving directly generates
    ego-motion from the sensory input. It optimizes the driving pipeline (Fig. [5](#S3.F5
    "Figure 5 ‣ 3 End-to-End system architecture ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")) by bypassing the sub-tasks
    related to perception and planning, allowing for continuous learning to sense
    and act, similar to humans. The first attempt at End-to-End driving was made by
    Pomerleau Alvinn [[47](#bib.bib47)], which trained a 3-layer sensorimotor fully
    connected network to output the car’s direction. End-to-End driving generates
    ego-motion based on sensory input, which can be of various modalities. However,
    the prominent ones are the camera [[48](#bib.bib48), [49](#bib.bib49), [50](#bib.bib50)],
    Light Detection and Ranging (LiDAR) [[6](#bib.bib6), [10](#bib.bib10), [7](#bib.bib7)],
    navigation commands [[51](#bib.bib51), [49](#bib.bib49), [23](#bib.bib23)], and
    vehicle dynamics, such as speed [[52](#bib.bib52), [53](#bib.bib53), [50](#bib.bib50)].
    This sensory information is utilized as the input to the backbone model, which
    is responsible for generating control signals. Ego-motion can involve different
    types of motions, such as acceleration, turning, steering, and pedaling. Additionally,
    many models also output additional information, such as a cost map for safe maneuvers,
    interpretable outputs, and other auxiliary outputs.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，直接感知或端到端驾驶直接从传感器输入生成自我运动。它通过绕过与感知和规划相关的子任务来优化驾驶管道（图 [5](#S3.F5 "图 5 ‣ 3
    端到端系统架构 ‣ 端到端自动驾驶中的最新进展：深度学习的调查")），实现类似于人类的持续学习以感知和行动。端到端驾驶的首次尝试由Pomerleau Alvinn
    [[47](#bib.bib47)]进行，它训练了一个3层的传感器运动完全连接网络来输出汽车的方向。端到端驾驶基于传感器输入生成自我运动，输入可以是各种模态。然而，主要的输入包括摄像头
    [[48](#bib.bib48), [49](#bib.bib49), [50](#bib.bib50)]，激光雷达（LiDAR） [[6](#bib.bib6),
    [10](#bib.bib10), [7](#bib.bib7)]，导航命令 [[51](#bib.bib51), [49](#bib.bib49), [23](#bib.bib23)]，以及车辆动态，如速度
    [[52](#bib.bib52), [53](#bib.bib53), [50](#bib.bib50)]。这些传感器信息被用作骨干模型的输入，骨干模型负责生成控制信号。自我运动可以涉及不同类型的运动，如加速、转向、操控和踏板。此外，许多模型还输出额外的信息，如安全机动的代价图、可解释的输出和其他辅助输出。
- en: '![Refer to caption](img/6422eadd317dd38196b119e9509c620f.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6422eadd317dd38196b119e9509c620f.png)'
- en: 'Figure 5: Comparison between End-to-End and modular pipelines. End-to-End is
    a single pipeline that generates the control signal directly from perception input,
    whereas a modular pipeline consists of various sub-modules, each with task-specific
    functionalities.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：端到端与模块化管道的比较。端到端是一个单一的管道，直接从感知输入生成控制信号，而模块化管道由各种子模块组成，每个子模块具有特定任务的功能。
- en: 'There are two main approaches for End-to-End driving: either the driving model
    is explored and improved via Reinforcement Learning (RL) [[54](#bib.bib54), [53](#bib.bib53),
    [55](#bib.bib55), [56](#bib.bib56), [21](#bib.bib21), [57](#bib.bib57)], or it
    is trained in a supervised manner using Imitation Learning (IL) [[18](#bib.bib18),
    [6](#bib.bib6), [19](#bib.bib19), [15](#bib.bib15), [17](#bib.bib17), [58](#bib.bib58),
    [7](#bib.bib7)] to resemble human driving behavior. The supervised learning paradigm
    aims to learn the driving style from expert demonstrations, which serve as training
    examples for the model. However, expanding an autonomous driving system based
    on IL [[23](#bib.bib23)] is challenging since it is impossible to cover every
    instance during the learning phase. On the other hand, RL works by maximizing
    cumulative rewards [[59](#bib.bib59), [55](#bib.bib55)] over time through interaction
    with the environment, and the network makes driving decisions to obtain rewards
    or penalties based on its actions. While RL model training occurs online and allows
    exploration of the environment during training, it is less effective in utilizing
    data compared to imitation learning. Table LABEL:literature summarizes recent
    methods in End-to-End driving.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端驾驶有两种主要方法：一种是通过强化学习（RL）[[54](#bib.bib54), [53](#bib.bib53), [55](#bib.bib55),
    [56](#bib.bib56), [21](#bib.bib21), [57](#bib.bib57)] 探索和改进驾驶模型，另一种是使用模仿学习（IL）[[18](#bib.bib18),
    [6](#bib.bib6), [19](#bib.bib19), [15](#bib.bib15), [17](#bib.bib17), [58](#bib.bib58),
    [7](#bib.bib7)] 以监督的方式训练模型，使其模拟人类驾驶行为。监督学习范式旨在通过专家示范来学习驾驶风格，这些示范作为模型的训练示例。然而，基于IL
    [[23](#bib.bib23)] 扩展自动驾驶系统具有挑战性，因为在学习阶段不可能覆盖所有实例。另一方面，RL通过与环境互动来最大化累积奖励 [[59](#bib.bib59),
    [55](#bib.bib55)]，网络根据其行为做出驾驶决策以获取奖励或处罚。虽然RL模型训练是在在线进行的，并且允许在训练期间探索环境，但与模仿学习相比，它在数据利用方面的效果较差。表格
    LABEL:literature 总结了端到端驾驶中的最新方法。
- en: 4 Input modalities in End-to-End system
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 输入方式在端到端系统中的应用
- en: 'The following section explores the input modalities essential for end-to-end
    autonomous driving. These encompass cameras for visual insights, LiDAR for precise
    3D point clouds, multi-modal inputs, and navigational inputs. Fig. [6](#S5.F6
    "Figure 6 ‣ 5.1 Waypoints ‣ 5 Output modalities in End-to-End system ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey")
    illustrates some of the input and output modalities.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分探讨了实现端到端自动驾驶所必需的输入方式。这些方式包括用于视觉洞察的摄像头、用于精确3D点云的激光雷达、多模态输入以及导航输入。图 [6](#S5.F6
    "图 6 ‣ 5.1 路点 ‣ 5 端到端系统中的输出方式 ‣ 基于深度学习的端到端自动驾驶最新进展：综述") 说明了一些输入和输出方式。
- en: 4.1 Camera
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 摄像头
- en: 'Camera-based methods [[14](#bib.bib14), [9](#bib.bib9), [6](#bib.bib6), [23](#bib.bib23),
    [49](#bib.bib49), [60](#bib.bib60), [50](#bib.bib50), [53](#bib.bib53), [12](#bib.bib12),
    [13](#bib.bib13)] have shown promising results in End-to-End driving. For instance,
    Toromanoff et al. [[53](#bib.bib53)] demonstrated their capabilities by winning
    the CARLA 2019 autonomous driving challenge using vision-based approaches in an
    urban context. The use of monocular [[13](#bib.bib13), [11](#bib.bib11), [61](#bib.bib61),
    [53](#bib.bib53)] and stereo vision [[58](#bib.bib58), [17](#bib.bib17), [15](#bib.bib15)]
    camera views is a natural input modality for image-to-control End-to-End driving.
    Xiao et al. [[62](#bib.bib62)] employed inputs consisting of a monocular RGB image
    from a forward-facing camera and the vehicle speed. Chen et al. LAV [[10](#bib.bib10)]
    utilize only the camera image input as shown in Fig. [6](#S5.F6 "Figure 6 ‣ 5.1
    Waypoints ‣ 5 Output modalities in End-to-End system ‣ Recent Advancements in
    End-to-End Autonomous Driving using Deep Learning: A Survey")(d). Wu et al. [[15](#bib.bib15)],
    Xiao et al. [[17](#bib.bib17)], Zhang et al. [[58](#bib.bib58)] utilize camera-only
    modality to generate high-level instructions for lane following, turning, stopping
    and going straight using imitation learning.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '基于相机的方法 [[14](#bib.bib14), [9](#bib.bib9), [6](#bib.bib6), [23](#bib.bib23),
    [49](#bib.bib49), [60](#bib.bib60), [50](#bib.bib50), [53](#bib.bib53), [12](#bib.bib12),
    [13](#bib.bib13)] 在端到端驾驶中显示出良好的前景。例如，Toromanoff 等人 [[53](#bib.bib53)] 通过使用基于视觉的方法在城市环境中赢得了
    CARLA 2019 自动驾驶挑战赛，展示了他们的能力。使用单目 [[13](#bib.bib13), [11](#bib.bib11), [61](#bib.bib61),
    [53](#bib.bib53)] 和立体视觉 [[58](#bib.bib58), [17](#bib.bib17), [15](#bib.bib15)]
    相机视图是图像到控制的端到端驾驶的自然输入方式。Xiao 等人 [[62](#bib.bib62)] 采用了来自前视相机的单目 RGB 图像和车辆速度作为输入。Chen
    等人 LAV [[10](#bib.bib10)] 仅使用相机图像输入，如图 [6](#S5.F6 "Figure 6 ‣ 5.1 Waypoints ‣
    5 Output modalities in End-to-End system ‣ Recent Advancements in End-to-End Autonomous
    Driving using Deep Learning: A Survey")(d) 所示。Wu 等人 [[15](#bib.bib15)]、Xiao 等人
    [[17](#bib.bib17)] 和 Zhang 等人 [[58](#bib.bib58)] 采用仅相机的模式，通过模仿学习生成车道跟随、转弯、停车和直行的高级指令。'
- en: 4.2 LiDAR
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 LiDAR
- en: Another significant input source in self-driving is the Light Detection and
    Ranging (LiDAR) sensor. LiDAR [[63](#bib.bib63), [64](#bib.bib64), [65](#bib.bib65),
    [20](#bib.bib20)] is resistant to lighting conditions and offers accurate distance
    estimates. Compared to other perception sensors, LiDAR data is the richest and
    provides the most comprehensive spatial information. It utilizes laser light to
    detect distances and generates PointClouds, which are 3D representations of space
    where each point includes the $(x,y,z)$ coordinates of the surface that reflected
    the sensor’s laser beam. When localizing a vehicle, generating odometry measurements
    is critical. Many techniques utilize LiDAR for feature mapping in Birds Eye View
    (BEV) [[9](#bib.bib9), [19](#bib.bib19), [16](#bib.bib16)], High Definition (HD)
    map [[20](#bib.bib20), [66](#bib.bib66)], and Simultaneous Localization and Mapping
    (SLAM) [[67](#bib.bib67)]. Shenoi et al. [[68](#bib.bib68)] have shown that adding
    depth and semantics via LiDAR has the potential to enhance driving performance.
    Liang et al. [[69](#bib.bib69), [70](#bib.bib70)] utilized point flow to learn
    the driving policy in an End-to-End manner.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 自驾车中另一个重要的输入来源是光学雷达（LiDAR）传感器。LiDAR [[63](#bib.bib63), [64](#bib.bib64), [65](#bib.bib65),
    [20](#bib.bib20)] 对光照条件具有很强的抵抗力，并提供准确的距离估算。与其他感知传感器相比，LiDAR 数据是最丰富的，提供了最全面的空间信息。它利用激光光线检测距离并生成点云（PointClouds），这是空间的三维表示，每个点包括反射传感器激光束的表面的
    $(x,y,z)$ 坐标。在定位车辆时，生成里程测量是至关重要的。许多技术利用 LiDAR 进行鸟瞰视图（BEV） [[9](#bib.bib9), [19](#bib.bib19),
    [16](#bib.bib16)]、高清地图（HD map） [[20](#bib.bib20), [66](#bib.bib66)] 和同时定位与地图构建（SLAM）
    [[67](#bib.bib67)]。Shenoi 等人 [[68](#bib.bib68)] 证明通过 LiDAR 添加深度和语义有潜力提升驾驶性能。Liang
    等人 [[69](#bib.bib69), [70](#bib.bib70)] 采用点流（point flow）以端到端的方式学习驾驶策略。
- en: 4.3 Multi-modal
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 多模态
- en: 'Multimodality [[8](#bib.bib8), [18](#bib.bib18), [10](#bib.bib10), [16](#bib.bib16),
    [71](#bib.bib71)] outperforms single modality in crucial perception tasks and
    is particularly well-suited for autonomous driving applications, as it combines
    multi-sensor data. There are three broad categorizations for utilizing information
    depending on when to combine multi-sensor information. In early fusion, sensor
    data is combined before feeding them into the learnable End-to-End system. Chen
    et al. [[10](#bib.bib10)] as shown in Fig. [6](#S5.F6 "Figure 6 ‣ 5.1 Waypoints
    ‣ 5 Output modalities in End-to-End system ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")(d) use a network that accepts
    (RGB + Depth) channel inputs, Xiao et al. [[62](#bib.bib62)] model also input
    the same modality. The network modifies just the first convolutional layer to
    account for the additional input channel, while the remaining network remains
    unchanged. Renz et al. [[18](#bib.bib18)] fuse object-level input representation
    using a transformer encoder. The author combinedly represents a set of objects
    as vehicles and segments of the routes.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '多模态 [[8](#bib.bib8), [18](#bib.bib18), [10](#bib.bib10), [16](#bib.bib16),
    [71](#bib.bib71)] 在关键感知任务中优于单一模态，尤其适合于自动驾驶应用，因为它结合了多传感器数据。根据何时组合多传感器信息，有三种广泛的分类。在早期融合中，传感器数据在输入到可学习的端到端系统之前被结合。正如图[6](#S5.F6
    "Figure 6 ‣ 5.1 Waypoints ‣ 5 Output modalities in End-to-End system ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey")(d)所示，Chen等人[[10](#bib.bib10)]
    使用了一个接受 (RGB + Depth) 通道输入的网络，Xiao等人[[62](#bib.bib62)] 的模型也输入了相同的模态。该网络仅修改了第一个卷积层以适应额外的输入通道，而其余网络保持不变。Renz等人[[18](#bib.bib18)]
    使用变压器编码器融合对象级输入表示。作者将一组对象合并表示为车辆和路线段。'
- en: 'In mid-fusion, information fusion is done either after some preprocessing stages
    or after some feature extraction. Zhou et al. [[72](#bib.bib72)] perform information
    fusion at the mid-level by leveraging the complementary information provided by
    both the bird’s-eye view (BEV) and perspective views of the LiDAR point cloud.
    Transfuser [[7](#bib.bib7)] as shown in Fig. [6](#S5.F6 "Figure 6 ‣ 5.1 Waypoints
    ‣ 5 Output modalities in End-to-End system ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")(a) addresses the integration
    of image and LiDAR modalities using self-attention layers. They utilized multiple
    transformer modules at multiple resolutions to fuse intermediate features. Obtained
    feature vector forms a concise representation which an MLP then processes before
    passing to an auto-regressive waypoint prediction network. In late fusion, inputs
    are processed separately, and their output is fused and further processed by another
    layer. Some authors [[73](#bib.bib73), [69](#bib.bib69), [70](#bib.bib70), [62](#bib.bib62)]
    use a late fusion architecture for LiDAR and visual modalities, in which each
    input stream is encoded separately and concatenated.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '在中期融合中，信息融合是在某些预处理阶段之后或在某些特征提取之后进行的。Zhou等人[[72](#bib.bib72)] 通过利用鸟瞰图（BEV）和激光雷达点云的透视视图提供的互补信息，在中级别执行信息融合。正如图[6](#S5.F6
    "Figure 6 ‣ 5.1 Waypoints ‣ 5 Output modalities in End-to-End system ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey")(a)所示，Transfuser
    [[7](#bib.bib7)] 解决了使用自注意力层集成图像和激光雷达模态的问题。他们利用了多个变压器模块在多个分辨率下融合中间特征。得到的特征向量形成了一个简明的表示，然后由一个MLP处理，再传递给自回归路线点预测网络。在晚期融合中，输入分别处理，然后其输出被融合并由另一层进一步处理。一些作者[[73](#bib.bib73),
    [69](#bib.bib69), [70](#bib.bib70), [62](#bib.bib62)] 使用了晚期融合架构来处理激光雷达和视觉模态，其中每个输入流被单独编码并进行拼接。'
- en: 4.4 Navigational inputs
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 导航输入
- en: 'End-to-End navigation input can originate from the route planner [[8](#bib.bib8),
    [14](#bib.bib14), [74](#bib.bib74)] and navigation commands [[48](#bib.bib48),
    [75](#bib.bib75), [76](#bib.bib76), [77](#bib.bib77)]. Routes are defined by a
    sequence of discrete endpoint locations in Global Positioning System (GPS) coordinates
    provided by a global planner [[14](#bib.bib14)]. The TCP model [[13](#bib.bib13)]
    as illustrated in Fig. [6](#S5.F6 "Figure 6 ‣ 5.1 Waypoints ‣ 5 Output modalities
    in End-to-End system ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey")(c) is provided with correlated navigation directives
    like lane keeping, left/right turns, and the destination. This information is
    used to produce the control actions.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 'End-to-End导航输入可以来源于路线规划器[[8](#bib.bib8), [14](#bib.bib14), [74](#bib.bib74)]和导航命令[[48](#bib.bib48),
    [75](#bib.bib75), [76](#bib.bib76), [77](#bib.bib77)]。路线由全局规划器[[14](#bib.bib14)]提供的GPS坐标中的一系列离散终点位置定义。TCP模型[[13](#bib.bib13)]如图[c](#S5.F6
    "Figure 6 ‣ 5.1 Waypoints ‣ 5 Output modalities in End-to-End system ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey")所示，提供了相关的导航指令，如车道保持、左/右转和目的地。这些信息用于生成控制动作。'
- en: Shao et al. [[8](#bib.bib8)] propose a technique that guides driving using these
    sparse destination locations instead of explicitly defining discrete navigation
    directives. PlanT [[18](#bib.bib18)] utilizes point-to-point navigation based
    on the input of the goal location. FlowDriveNet [[78](#bib.bib78)] considers both
    the global planner’s discrete navigation command and the coordinates of the navigation
    target. Hubschneider et al. [[75](#bib.bib75)] include a turn indicator command
    in the driving model, while Codevilla et al. [[76](#bib.bib76)] utilize a CNN
    block for specific navigation tasks and a second block for subset navigation.
    In addition to the aforementioned inputs, End-to-End models also incorporate vehicle
    dynamics, such as ego-vehicle speed [[52](#bib.bib52), [49](#bib.bib49), [53](#bib.bib53),
    [12](#bib.bib12)].
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: Shao等人[[8](#bib.bib8)]提出了一种技术，该技术通过这些稀疏的目的地位置来指导驾驶，而不是明确地定义离散的导航指令。PlanT[[18](#bib.bib18)]利用基于目标位置输入的点对点导航。FlowDriveNet[[78](#bib.bib78)]考虑了全局规划器的离散导航指令和导航目标的坐标。Hubschneider等人[[75](#bib.bib75)]在驾驶模型中包括了一个转向指示器命令，而Codevilla等人[[76](#bib.bib76)]则利用CNN块处理特定的导航任务，另一个块处理子集导航。除了上述输入外，End-to-End模型还整合了车辆动态，例如自车速度[[52](#bib.bib52),
    [49](#bib.bib49), [53](#bib.bib53), [12](#bib.bib12)]。
- en: 5 Output modalities in End-to-End system
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 End-to-End系统中的输出模式
- en: Usually, an End-to-End autonomous driving system outputs control commands, waypoints,
    or trajectories. In addition, it may also produce additional representations,
    such as a cost map and auxiliary outputs.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，End-to-End自动驾驶系统输出控制命令、航点或轨迹。此外，它还可能生成额外的表示，例如成本地图和辅助输出。
- en: 5.1 Waypoints
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 航点
- en: Predicting future waypoints is a higher-level output modality. Several authors
    [[10](#bib.bib10), [6](#bib.bib6), [7](#bib.bib7), [79](#bib.bib79)] use an auto-regressive
    waypoint network to predict differential waypoints. Trajectories [[8](#bib.bib8),
    [74](#bib.bib74), [80](#bib.bib80), [13](#bib.bib13), [19](#bib.bib19)] can also
    represent sequences of waypoints in the coordinate frame. The network’s output
    waypoints are converted into low-level steering and acceleration using Model Predictive
    Control (MPC) [[4](#bib.bib4)] and Proportional Integral Derivative (PID) [[5](#bib.bib5)].
    The longitudinal controller considers the magnitude of a weighted average of vectors
    between successive time-step waypoints, while the lateral controller considers
    their direction. The ideal waypoint [[53](#bib.bib53)] relies on desired speed,
    position, and rotation.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 预测未来的航点是一种更高级的输出模式。一些作者[[10](#bib.bib10), [6](#bib.bib6), [7](#bib.bib7), [79](#bib.bib79)]使用自回归航点网络来预测差分航点。轨迹[[8](#bib.bib8),
    [74](#bib.bib74), [80](#bib.bib80), [13](#bib.bib13), [19](#bib.bib19)]也可以表示坐标框架中的航点序列。网络输出的航点通过模型预测控制（MPC）[[4](#bib.bib4)]和比例积分微分（PID）[[5](#bib.bib5)]转换为低级别的转向和加速。纵向控制器考虑了连续时间步航点之间向量的加权平均值的大小，而横向控制器考虑它们的方向。理想的航点[[53](#bib.bib53)]依赖于期望的速度、位置和旋转。
- en: '| ![Refer to caption](img/eb2e5aaa029ff4697a2a2640409f565d.png) |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| ![参考标题](img/eb2e5aaa029ff4697a2a2640409f565d.png) |'
- en: '| (a) Fusion Transformer |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| (a) 融合变换器 |'
- en: '| ![Refer to caption](img/c4827c2289fa912c57412469b23c0859.png) |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| ![参考标题](img/c4827c2289fa912c57412469b23c0859.png) |'
- en: '| b) NEAT |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| b) NEAT |'
- en: '| ![Refer to caption](img/7e812c2a17e075895a32c9edc3e20d09.png) |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| ![参考标题](img/7e812c2a17e075895a32c9edc3e20d09.png) |'
- en: '| (c) TCP |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| (c) TCP |'
- en: '| ![Refer to caption](img/6a112e3e2a0caee3f00229131c193b39.png) |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| ![参考说明](img/6a112e3e2a0caee3f00229131c193b39.png) |'
- en: '| (d) LAV |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| (d) LAV |'
- en: '| ![Refer to caption](img/b17323a3f2721171ba6af5bcf237a2cf.png) |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| ![参考说明](img/b17323a3f2721171ba6af5bcf237a2cf.png) |'
- en: '| (e) UniAD |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| (e) UniAD |'
- en: '| ![Refer to caption](img/114fb18b8a661aec75251768f9e37b0d.png) |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| ![参考说明](img/114fb18b8a661aec75251768f9e37b0d.png) |'
- en: '| (f) ST-P3 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| (f) ST-P3 |'
- en: 'Figure 6: The input-output representation of various End-to-End models: (a)
    Considered RGB image and LiDAR BEV representations as inputs to the multi-modal
    fusion transformer [[7](#bib.bib7)] and predicts the differential ego-vehicle
    waypoints. (b) NEAT [[12](#bib.bib12)] inputs the image patch and velocity features
    to obtain a waypoint for each time-step used by PID controllers for driving. (c)
    TCP [[13](#bib.bib13)] takes input image i, navigation information g, current
    speed v, to generate the control actions guided by the trajectory branch and control
    branch. (d) LAV [[10](#bib.bib10)] uses an image-only input and predicts multi-modal
    future trajectories used for braking and handling traffic signs and obstacles.
    (e) UniAD [[9](#bib.bib9)] generates attention mask visualization which shows
    how much attention is paid to the goal lane as well as the critical agents that
    are yielding to the ego-vehicle.(f) ST-P3 [[20](#bib.bib20)] outputs the sub cost
    map from the prediction module (darker color indicates a smaller cost value).
    By incorporating the occupancy probability field and leveraging pre-existing knowledge,
    the cost function effectively balances safety considerations for the final trajectory.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：各种端到端模型的输入输出表示：（a）考虑RGB图像和LiDAR BEV表示作为多模态融合变换器[[7](#bib.bib7)]的输入，并预测差分自车路标。（b）NEAT[[12](#bib.bib12)]输入图像块和速度特征，以获得由PID控制器用于驾驶的每个时间步的路标。（c）TCP[[13](#bib.bib13)]接收输入图像i、导航信息g、当前速度v，生成由轨迹分支和控制分支指导的控制动作。（d）LAV[[10](#bib.bib10)]使用仅图像输入并预测用于刹车和处理交通标志和障碍物的多模态未来轨迹。（e）UniAD[[9](#bib.bib9)]生成注意力掩码可视化，显示对目标车道以及让行给自车的关键代理的关注程度。（f）ST-P3[[20](#bib.bib20)]从预测模块输出子成本图（颜色越深表示成本值越小）。通过结合占用概率场和利用已有知识，成本函数有效平衡了最终轨迹的安全考虑。
- en: 'The lateral distance and angle must be minimized to maximize the reward (or
    minimize the deviation). The benefit of utilizing waypoints as an output is that
    they are not affected by vehicle geometry. Additionally, waypoints are easier
    to analyze by the controller for control commands such as steering. Waypoints
    in continuous form can be transformed into a specific trajectory. Zhang et al.
    [[54](#bib.bib54)] and Zhou et al. [[74](#bib.bib74)] utilize a motion planner
    to generate a series of waypoints that describe the future trajectory. LAV [[10](#bib.bib10)]
    predicts multi-modal future trajectories (Fig. [6](#S5.F6 "Figure 6 ‣ 5.1 Waypoints
    ‣ 5 Output modalities in End-to-End system ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")(d)) for all detected vehicles,
    including the ego-vehicle. They use future waypoints to represent the motion plan.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 需要最小化横向距离和角度以最大化奖励（或最小化偏差）。使用路标作为输出的好处在于它们不受车辆几何形状的影响。此外，路标更容易被控制器分析以生成控制命令，如转向。连续形式的路标可以转化为特定的轨迹。Zhang
    et al.[[54](#bib.bib54)]和Zhou et al.[[74](#bib.bib74)]利用运动规划器生成一系列描述未来轨迹的路标。LAV[[10](#bib.bib10)]预测所有检测到的车辆（包括自车）的多模态未来轨迹（图[6](#S5.F6
    "图6 ‣ 5.1 路标 ‣ 5 端到端系统中的输出模态 ‣ 基于深度学习的端到端自动驾驶的最新进展调查")(d)）。他们使用未来的路标来表示运动计划。
- en: 5.2 Cost function
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 成本函数
- en: 'Many trajectories and waypoints are possible for the safe maneuvering of the
    vehicle. The cost [[20](#bib.bib20), [81](#bib.bib81), [56](#bib.bib56), [21](#bib.bib21),
    [80](#bib.bib80), [82](#bib.bib82)] is used to select the optimal one among the
    possibilities. It assigns a weight (positive or negative score) to each trajectory
    based on parameters defined by the end user, such as safety, distance traveled,
    comfort, and others. Rhinehart et al. [[83](#bib.bib83)] and Chen et al. [[10](#bib.bib10)]
    refine control using the predictive consistency map, which updates knowledge at
    test time. They also evaluate the trajectory using an ensemble expert likelihood
    model. Prakash et al. [[14](#bib.bib14)] utilize object-level representations
    to analyze collision-free routes. Zeng et al. [[84](#bib.bib84)] employ a neural
    motion planner that uses a cost volume to predict future trajectories. Hu et al.
    [[20](#bib.bib20)] employ a cost function illustrated in Fig. [6](#S5.F6 "Figure
    6 ‣ 5.1 Waypoints ‣ 5 Output modalities in End-to-End system ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey")(f) that takes
    advantage of the learned occupancy probability field, represented by segmentation
    maps, and prior knowledge such as traffic rules to select the trajectory with
    the minimum cost. Regarding safety cost functions, Zhao et al. [[50](#bib.bib50)],
    Chen et al. [[85](#bib.bib85)], and Shao et al. [[8](#bib.bib8)] employ safety
    maps. They analyze actions within the safe set to create causal insights regarding
    hazardous driving situations.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '车辆的安全操控可能有许多轨迹和路径点。成本 [[20](#bib.bib20), [81](#bib.bib81), [56](#bib.bib56),
    [21](#bib.bib21), [80](#bib.bib80), [82](#bib.bib82)] 用于在这些可能性中选择最佳方案。它根据最终用户定义的参数（如安全性、行驶距离、舒适度等）给每个轨迹分配一个权重（正分或负分）。Rhinehart
    等 [[83](#bib.bib83)] 和 Chen 等 [[10](#bib.bib10)] 使用预测一致性图更新测试时的知识，并通过集成专家似然模型评估轨迹。Prakash
    等 [[14](#bib.bib14)] 利用对象级别表示分析无碰撞路径。Zeng 等 [[84](#bib.bib84)] 使用神经运动规划器，通过成本体积预测未来轨迹。Hu
    等 [[20](#bib.bib20)] 使用图 [6](#S5.F6 "Figure 6 ‣ 5.1 Waypoints ‣ 5 Output modalities
    in End-to-End system ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey")(f) 所示的成本函数，利用学习到的占用概率场（由分割图表示）和交通规则等先验知识，选择成本最低的轨迹。关于安全成本函数，赵等
    [[50](#bib.bib50)], 陈等 [[85](#bib.bib85)] 和邵等 [[8](#bib.bib8)] 使用安全图分析安全集内的操作，提供有关危险驾驶情况的因果洞察。'
- en: '| ![Refer to caption](img/80c800d5920866fbb836aa652602ab76.png) |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| ![参考说明](img/80c800d5920866fbb836aa652602ab76.png) |'
- en: 'Figure 7: Vehicle maneuvers, represented by a triplet of steering angle, throttle,
    and brake, depend on a high-level route navigation command (e.g., turn-left, turn-right,
    go-straight, continue), as well as perception data (e.g., RGB image) and vehicle
    state measurements (e.g., speed). These inputs guide the specific actions taken
    by the vehicle, enabling it to navigate the environment effectively through conditional
    imitation learning [[62](#bib.bib62)].'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：车辆操控由转向角度、油门和刹车三元组表示，这取决于高级路线导航命令（例如，左转、右转、直行、继续）以及感知数据（例如，RGB 图像）和车辆状态测量（例如，速度）。这些输入指导车辆采取具体的操作，使其通过条件模仿学习
    [[62](#bib.bib62)] 有效地导航环境。
- en: 5.3 Direct control and acceleration
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 直接控制与加速
- en: Most of the End-to-End models [[83](#bib.bib83), [74](#bib.bib74), [53](#bib.bib53),
    [48](#bib.bib48), [23](#bib.bib23), [75](#bib.bib75), [76](#bib.bib76), [77](#bib.bib77),
    [48](#bib.bib48)] provide the steering angle and speed as outputs at a specific
    timestamp. The output control needs to be calibrated based on the vehicle’s dynamics,
    determining the appropriate steering angle for turning and the necessary braking
    for stopping at a measurable distance.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数端到端模型 [[83](#bib.bib83), [74](#bib.bib74), [53](#bib.bib53), [48](#bib.bib48),
    [23](#bib.bib23), [75](#bib.bib75), [76](#bib.bib76), [77](#bib.bib77), [48](#bib.bib48)]
    在特定时间戳提供转向角度和速度作为输出。输出控制需要根据车辆的动态进行校准，以确定适当的转向角度和为在可测量距离内停车所需的刹车。
- en: 5.4 Auxiliary output
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 辅助输出
- en: 'The auxiliary output can provide additional information for the model’s operation
    and the determination of driving actions. Several types of auxiliary outputs include
    the segmentation map [[9](#bib.bib9), [7](#bib.bib7)] (Fig. [6](#S5.F6 "Figure
    6 ‣ 5.1 Waypoints ‣ 5 Output modalities in End-to-End system ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey")(e)), BEV map
    [[12](#bib.bib12), [9](#bib.bib9), [19](#bib.bib19), [16](#bib.bib16)], future
    occupancy [[18](#bib.bib18), [9](#bib.bib9), [84](#bib.bib84), [82](#bib.bib82)]
    of the vehicle (Fig. [6](#S5.F6 "Figure 6 ‣ 5.1 Waypoints ‣ 5 Output modalities
    in End-to-End system ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey")(e)), and interpretable feature map [[18](#bib.bib18),
    [8](#bib.bib8), [7](#bib.bib7), [20](#bib.bib20), [12](#bib.bib12), [81](#bib.bib81)]
    (Fig. [6](#S5.F6 "Figure 6 ‣ 5.1 Waypoints ‣ 5 Output modalities in End-to-End
    system ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning:
    A Survey")(b)(f)). These outputs provide additional functionality to the End-to-End
    pipeline and help the model learn better representations. The auxiliary output
    also facilitates the explanation of the model’s behavior [[7](#bib.bib7), [82](#bib.bib82)],
    as one can comprehend the information and infer the reasons behind the model’s
    decisions.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '辅助输出可以为模型的操作和驾驶动作的确定提供额外的信息。几种类型的辅助输出包括分割图 [[9](#bib.bib9), [7](#bib.bib7)]（图
    [6](#S5.F6 "Figure 6 ‣ 5.1 Waypoints ‣ 5 Output modalities in End-to-End system
    ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey")(e)），BEV 图 [[12](#bib.bib12), [9](#bib.bib9), [19](#bib.bib19), [16](#bib.bib16)]，未来占用情况
    [[18](#bib.bib18), [9](#bib.bib9), [84](#bib.bib84), [82](#bib.bib82)]（图 [6](#S5.F6
    "Figure 6 ‣ 5.1 Waypoints ‣ 5 Output modalities in End-to-End system ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey")(e)），以及可解释的特征图
    [[18](#bib.bib18), [8](#bib.bib8), [7](#bib.bib7), [20](#bib.bib20), [12](#bib.bib12),
    [81](#bib.bib81)]（图 [6](#S5.F6 "Figure 6 ‣ 5.1 Waypoints ‣ 5 Output modalities
    in End-to-End system ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey")(b)(f)）。这些输出为端到端管道提供了额外的功能，帮助模型学习更好的表示。辅助输出还便利了对模型行为的解释
    [[7](#bib.bib7), [82](#bib.bib82)]，因为可以理解信息并推断模型决策背后的原因。'
- en: 6 Learning approaches for End-to-End system
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 端到端系统的学习方法
- en: The following sections discuss various learning approaches in End-to-End Driving,
    including imitation learning and reinforcement learning.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的章节讨论了端到端驾驶中的各种学习方法，包括模仿学习和强化学习。
- en: 6.1 Imitation learning
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 模仿学习
- en: Imitation learning (IL) [[10](#bib.bib10), [18](#bib.bib18), [13](#bib.bib13),
    [14](#bib.bib14), [86](#bib.bib86)] is based on the principle of learning from
    expert demonstrations. These demonstrations train the system to mimic the expert’s
    behavior in various driving scenarios. Large-scale expert driving datasets are
    readily available, which can be leveraged by imitation learning [[62](#bib.bib62)]
    to train models that perform at human-like standards.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 模仿学习（IL）[[10](#bib.bib10), [18](#bib.bib18), [13](#bib.bib13), [14](#bib.bib14),
    [86](#bib.bib86)] 基于从专家演示中学习的原理。这些演示训练系统在各种驾驶场景中模仿专家的行为。大规模的专家驾驶数据集随时可用，模仿学习 [[62](#bib.bib62)]
    可以利用这些数据集训练出达到类似人类标准的模型。
- en: 'The main objective is to train a policy $\pi_{\theta}(s)$ that maps each given
    state to a corresponding action (Fig. [7](#S5.F7 "Figure 7 ‣ 5.2 Cost function
    ‣ 5 Output modalities in End-to-End system ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")) as closely as possible to
    the given expert policy $\pi^{*}$, given an expert dataset with state action pair
    $\left(s,a\right)$:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '主要目标是训练一个策略 $\pi_{\theta}(s)$，使其尽可能接近给定的专家策略 $\pi^{*}$，将每个给定状态映射到相应的动作（图 [7](#S5.F7
    "Figure 7 ‣ 5.2 Cost function ‣ 5 Output modalities in End-to-End system ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey")），前提是有一个包含状态动作对
    $\left(s,a\right)$ 的专家数据集。'
- en: '|  | $\arg\min_{\theta}E_{s}\sim_{P(s\mid\theta)}L(\pi^{*}(s),\pi_{\theta}(s))$
    |  | (4) |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '|  | $\arg\min_{\theta}E_{s}\sim_{P(s\mid\theta)}L(\pi^{*}(s),\pi_{\theta}(s))$
    |  | (4) |'
- en: where $P(s\mid\theta)$ represents the state distribution of the trained policy
    $\pi_{\theta}$.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $P(s\mid\theta)$ 表示训练策略 $\pi_{\theta}$ 的状态分布。
- en: Behavioural Cloning (BC), Direct Policy Learning (DPL), and Inverse Reinforcement
    Learning (IRL) are extensions of imitation learning in the domain of autonomous
    driving.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 行为克隆（BC）、直接策略学习（DPL）和逆向强化学习（IRL）是自主驾驶领域模仿学习的扩展。
- en: 6.1.1 Behavioural cloning
  id: totrans-224
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.1 行为克隆
- en: 'Behavioural cloning [[87](#bib.bib87), [7](#bib.bib7), [13](#bib.bib13), [12](#bib.bib12),
    [49](#bib.bib49), [23](#bib.bib23), [88](#bib.bib88)] is the supervised imitation
    learning task where the goal is to treat each state-action combination in expert
    distribution as an Independent and Identically Distributed (I.I.D) example and
    minimise imitation loss for the trained policy:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 行为克隆 [[87](#bib.bib87), [7](#bib.bib7), [13](#bib.bib13), [12](#bib.bib12),
    [49](#bib.bib49), [23](#bib.bib23), [88](#bib.bib88)] 是一种监督模仿学习任务，目标是将专家分布中的每个状态-动作组合视为独立同分布（I.I.D）示例，并最小化训练策略的模仿损失：
- en: '|  | $\arg\min_{\theta}E_{(s,a^{*})}\sim_{P^{*}}L(a^{*},\pi_{\theta}(s))$ |  |
    (5) |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '|  | $\arg\min_{\theta}E_{(s,a^{*})}\sim_{P^{*}}L(a^{*},\pi_{\theta}(s))$ |  |
    (5) |'
- en: where $p^{*}(s\mid\pi^{*})$ is an expert policy state distribution, and (state
    s, action $a^{*}$) is provided by expert policy $p^{*}$.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p^{*}(s\mid\pi^{*})$ 是专家策略状态分布，(状态 s，动作 $a^{*}$) 由专家策略 $p^{*}$ 提供。
- en: '![Refer to caption](img/fef3ca59d83dbc67f13923175dab47f9.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/fef3ca59d83dbc67f13923175dab47f9.png)'
- en: 'Figure 8: Behavior cloning [[49](#bib.bib49)] is a perception-to-action driving
    model that learns behavior reflex for various driving scenarios. The agent acquires
    the ability to integrate expert policies in a context-dependent and task-optimized
    manner, allowing it to drive confidently.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：行为克隆 [[49](#bib.bib49)] 是一种从感知到动作的驾驶模型，用于学习各种驾驶场景的行为反射。该智能体能够以上下文相关和任务优化的方式整合专家策略，从而自信地进行驾驶。
- en: 'Prakash et al. [[14](#bib.bib14)], Chitta et al. [[7](#bib.bib7)], NEAT [[12](#bib.bib12)],
    Ohn et al. [[49](#bib.bib49)] utilize a policy that maps input frames to low-level
    control signals in terms of waypoints. These waypoints are then fed into a PID
    to obtain the steering, throttle, and brake commands based on the predicted waypoints.
    Behavior cloning [[49](#bib.bib49)] assumes that the expert’s actions can be fully
    explained by observation, as it trains a model to directly map from input to output
    based on the training dataset (Fig. [8](#S6.F8 "Figure 8 ‣ 6.1.1 Behavioural cloning
    ‣ 6.1 Imitation learning ‣ 6 Learning approaches for End-to-End system ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey")).
    However, this leads to the distribution shift problem, where the actual observations
    diverge from the training observations. Many latent variables impact and govern
    driving agent’s actions in real-world scenarios. Therefore, it is essential to
    learn these variables effectively.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Prakash 等人 [[14](#bib.bib14)]、Chitta 等人 [[7](#bib.bib7)]、NEAT [[12](#bib.bib12)]、Ohn
    等人 [[49](#bib.bib49)] 使用了一种将输入帧映射到低级控制信号（例如路标点）的策略。这些路标点随后被输入到 PID 控制器中，以根据预测的路标点获得转向、油门和刹车命令。行为克隆
    [[49](#bib.bib49)] 假设专家的动作可以通过观察完全解释，因为它训练了一个模型，以便直接从输入映射到输出，基于训练数据集（图 [8](#S6.F8
    "图 8 ‣ 6.1.1 行为克隆 ‣ 6.1 模仿学习 ‣ 6 端到端系统的学习方法 ‣ 深度学习在端到端自主驾驶中的最新进展：一项综述")）。然而，这会导致分布漂移问题，即实际观察与训练观察之间的差异。许多潜在变量影响并支配现实世界场景中的驾驶智能体的行为。因此，有效学习这些变量至关重要。
- en: 6.1.2 Direct policy learning
  id: totrans-231
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.2 直接策略学习
- en: Within the context of BC, which maps sensor inputs to control commands and is
    limited by the training dataset, DLP aims to learn an optimal policy [[48](#bib.bib48)]
    directly that maps inputs to driving actions. The DLP algorithm obtains expert
    evaluations [[56](#bib.bib56)] during runtime to gather more training data, particularly
    for scenarios where the initial policy falls short. It combines an expert dataset
    with Imitation Learning for initial training and iteratively augments the dataset
    with additional trajectories collected by the trained policy. The agent can explore
    its surroundings and discover novel and efficient driving policies.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在行为克隆（BC）的背景下，它将传感器输入映射到控制命令，并受到训练数据集的限制，DLP 旨在直接学习一个最优策略 [[48](#bib.bib48)]，将输入映射到驾驶动作。DLP
    算法在运行时获取专家评估 [[56](#bib.bib56)] 以收集更多训练数据，特别是对于初始策略不足的场景。它结合了专家数据集和模仿学习进行初步训练，并通过训练策略收集的额外轨迹迭代增加数据集。该智能体可以探索周围环境，发现新颖且高效的驾驶策略。
- en: The online imitation learning algorithm DAGGER [[89](#bib.bib89)] provides robustness
    against cascading errors and accumulates additional training instances. Chen et
    al. [[10](#bib.bib10)] introduced automated dagger-like monitoring, where the
    privileged agent’s supervision is collected through online learning and transformed
    into an agent that provides on-policy supervision. However, the main drawback
    of direct policy learning is the continuous need for expert access during the
    training process, which is both costly and inefficient.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在线模仿学习算法 DAGGER [[89](#bib.bib89)] 提供了对级联错误的鲁棒性，并积累了额外的训练实例。陈等人 [[10](#bib.bib10)]
    引入了自动化的 dagger-like 监控，其中通过在线学习收集特权代理的监督，并转化为提供在政策监督的代理。然而，直接政策学习的主要缺点是训练过程中持续需要专家的访问，这既昂贵又低效。
- en: 6.1.3 Inverse reinforcement learning
  id: totrans-234
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.3 逆强化学习
- en: Inverse Reinforcement Learning (IRL) [[90](#bib.bib90), [48](#bib.bib48)] aims
    to deduce the underlying specific behaviours through the reward function. Expert
    demonstrations $D=\left\{\zeta_{1},\zeta_{2},\zeta_{3},......,\zeta_{n}\right\}$
    are fed into IRL. Each $\zeta_{i}=\left\{(s_{1},a_{2}),(s_{2},a_{2}),.....(s_{n},a_{n})\right\}$
    consists of a state-action pair. The principal goal is to get the underlying reward
    which can be used to replicate the expert behaviour. Feature-based IRL [[91](#bib.bib91)]
    teaches the different driving styles in the highway scenario. The human-provided
    examples are used to learn different reward functions and capabilities of interaction
    with road users. Maximum Entropy (MaxEnt) inverse reinforcement learning [[92](#bib.bib92)]
    is an extension of the feature-based IRL based on the principle of maximum entropy.
    This paradigm robustly addresses reward ambiguity and handles sub-optimization.
    The major drawback is that IRL algorithms are expensive to run. They are also
    computationally demanding, unstable during training, and may take longer to converge
    on smaller datasets.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 逆强化学习（IRL）[[90](#bib.bib90), [48](#bib.bib48)] 旨在通过奖励函数推断潜在的具体行为。专家演示 $D=\left\{\zeta_{1},\zeta_{2},\zeta_{3},......,\zeta_{n}\right\}$
    被输入到 IRL 中。每个 $\zeta_{i}=\left\{(s_{1},a_{2}),(s_{2},a_{2}),.....(s_{n},a_{n})\right\}$
    由状态-行动对组成。主要目标是获得潜在的奖励，这些奖励可以用来复制专家行为。基于特征的 IRL [[91](#bib.bib91)] 在高速公路场景中教授不同的驾驶风格。人类提供的示例被用来学习不同的奖励函数以及与道路用户互动的能力。最大熵（MaxEnt）逆强化学习
    [[92](#bib.bib92)] 是基于最大熵原理的基于特征的 IRL 的扩展。这一范式稳健地解决了奖励模糊性并处理了次优化。主要缺点是 IRL 算法运行成本高。它们计算要求高，训练过程中不稳定，并且在较小数据集上可能需要更长时间才能收敛。
- en: '| ![Refer to caption](img/9cb6d83305fbeb7a7b453c101d16880e.png) |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| ![参考说明](img/9cb6d83305fbeb7a7b453c101d16880e.png) |'
- en: '| (a) Roach Expert Supervision |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| (a) Roach 专家监督 |'
- en: '| ![Refer to caption](img/7947edc360a4459d797c8f533168c570.png) |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| ![参考说明](img/7947edc360a4459d797c8f533168c570.png) |'
- en: '| (b) Human Copilot Learning |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| (b) 人工副驾驶学习 |'
- en: 'Figure 9: RL-based learning method for training the agent to drive optimally:
    (a) Illustrating the reinforcement learning expert [[54](#bib.bib54)] that maps
    the BEV to the low-level driving actions; the expert can also provide supervision
    to the imitation learning agent. (b) Human-in-the-loop learning [[55](#bib.bib55)]
    allows the agent to explore the environment, and in danger scenarios, the human
    expert takes over the control and provides the safe demonstration.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：基于 RL 的学习方法用于训练代理以最佳方式驾驶：（a）展示了将 BEV 映射到低级驾驶动作的强化学习专家 [[54](#bib.bib54)]；专家还可以为模仿学习代理提供监督。（b）人机互动学习
    [[55](#bib.bib55)] 允许代理探索环境，在危险场景中，人类专家接管控制并提供安全演示。
- en: 6.2 Reinforcement learning
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 强化学习
- en: Reinforcement Learning (RL) [[93](#bib.bib93), [57](#bib.bib57), [56](#bib.bib56),
    [53](#bib.bib53)] is a promising approach to address the distribution shift problem.
    It aims to maximize cumulative rewards [[94](#bib.bib94)] over time by interacting
    with the environment, and the network makes driving decisions to obtain rewards
    or penalties based on its actions. IL cannot handle novel situations significantly
    different from the training dataset, RL is robust to this issue as it explores
    scenario under given environment. Reinforcement learning encompasses various models,
    including value-based models such as Deep Q-Networks (DQN) [[95](#bib.bib95)],
    actor-critic based models like Deep Deterministic Policy Gradient (DDPG) and Asynchronous
    Advantage Actor Critic (A3C) [[95](#bib.bib95)], maximum entropy models [[92](#bib.bib92)]
    such as Soft Actor Critic (SAC) [[96](#bib.bib96)], and policy-based optimization
    methods such as Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization
    (PPO) [[97](#bib.bib97)].
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习（RL）[[93](#bib.bib93), [57](#bib.bib57), [56](#bib.bib56), [53](#bib.bib53)]
    是解决分布偏移问题的一个有前景的方法。它旨在通过与环境互动来最大化累计奖励[[94](#bib.bib94)]，网络根据其行动做出驾驶决策以获得奖励或惩罚。与训练数据集显著不同的新情况，IL
    处理起来较为困难，而 RL 对这一问题具有鲁棒性，因为它在给定环境下探索场景。强化学习包括多种模型，包括基于价值的模型如深度 Q 网络（DQN）[[95](#bib.bib95)]，基于演员-评论员的模型如深度确定性策略梯度（DDPG）和异步优势演员评论员（A3C）[[95](#bib.bib95)]，最大熵模型[[92](#bib.bib92)]如软演员评论员（SAC）[[96](#bib.bib96)]，以及基于策略的优化方法如信赖域策略优化（TRPO）和近端策略优化（PPO）[[97](#bib.bib97)]。
- en: Liang et al. [[98](#bib.bib98)] demonstrated the first effective RL approach
    for vision-based driving pipelines that outperformed the modular pipeline at the
    time. Their method is based on the Deep Deterministic Policy Gradient (DDPG),
    an extended version of the actor-critic algorithm. Chen et al. [[99](#bib.bib99)]
    uses tabular-RL to first learn an expert policy and then uses policy distillation
    to learn a student policy in an imitation learning approach.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 梁等人 [[98](#bib.bib98)] 展示了首个有效的用于基于视觉的驾驶管道的 RL 方法，该方法超越了当时的模块化管道。他们的方法基于深度确定性策略梯度（DDPG），这是演员-评论员算法的扩展版本。陈等人
    [[99](#bib.bib99)] 使用表格 RL 首先学习专家策略，然后使用策略蒸馏在模仿学习方法中学习学生策略。
- en: Recently, Human-In-The-Loop (HITL) approaches [[100](#bib.bib100), [55](#bib.bib55),
    [56](#bib.bib56), [54](#bib.bib54), [14](#bib.bib14)] have gained attention in
    the literature. These approaches are based on the premise that expert demonstrations
    provide valuable guidance for achieving high-reward policies. Several studies
    have focused on incorporating human expertise into the training process of traditional
    RL or IL paradigms. One such example is EGPO [[56](#bib.bib56)], which aims to
    develop an expert-guided policy optimization technique where an expert policy
    supervises the learning agent.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，文献中对人机协作（HITL）方法[[100](#bib.bib100), [55](#bib.bib55), [56](#bib.bib56),
    [54](#bib.bib54), [14](#bib.bib14)]的关注增加。这些方法基于专家演示提供宝贵指导以实现高奖励策略的前提。几项研究集中于将人类专业知识融入传统
    RL 或 IL 模型的训练过程。一个例子是 EGPO [[56](#bib.bib56)]，其目标是开发一种由专家指导的策略优化技术，其中专家策略监督学习代理。
- en: 'HACO [[55](#bib.bib55)] allows the agent to explore hazardous environments
    while ensuring training safety. In this approach, a human expert can intervene
    and guide the agent to avoid potentially harmful situations or irrelevant actions
    (see Fig. [9](#S6.F9 "Figure 9 ‣ 6.1.3 Inverse reinforcement learning ‣ 6.1 Imitation
    learning ‣ 6 Learning approaches for End-to-End system ‣ Recent Advancements in
    End-to-End Autonomous Driving using Deep Learning: A Survey")(b)). Another reinforcement
    learning expert, Roach [[54](#bib.bib54)], translates bird’s-eye view images into
    continuous low-level actions (see Fig. [9](#S6.F9 "Figure 9 ‣ 6.1.3 Inverse reinforcement
    learning ‣ 6.1 Imitation learning ‣ 6 Learning approaches for End-to-End system
    ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey")(a)). Experts can provide high-level supervision for imitation learning
    or reinforcement learning in general. Policies can be initially taught using imitation
    learning and then refined using reinforcement learning, which helps reduce the
    extensive training period required for RL. Jia et al. [[19](#bib.bib19)] utilize
    features extracted from Roach to learn the ground-truth action/trajectory, providing
    supervision in their study. Therefore, reinforcement learning provides a solution
    to address the challenges of imitation learning by enabling agents to actively
    explore and learn from their environment. There are also associated challenges,
    such as sample inefficiency, exploration difficulties leading to suboptimal behaviors,
    and difficulties generalizing learned policies to new scenarios.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 'HACO [[55](#bib.bib55)] 允许代理在确保训练安全的同时探索危险环境。在这种方法中，专家可以介入并指导代理，避免潜在的有害情况或不相关的动作（参见图
    [9](#S6.F9 "Figure 9 ‣ 6.1.3 Inverse reinforcement learning ‣ 6.1 Imitation learning
    ‣ 6 Learning approaches for End-to-End system ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")(b)）。另一位强化学习专家 Roach [[54](#bib.bib54)]
    将鸟瞰图像转换为连续的低级动作（参见图 [9](#S6.F9 "Figure 9 ‣ 6.1.3 Inverse reinforcement learning
    ‣ 6.1 Imitation learning ‣ 6 Learning approaches for End-to-End system ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey")(a)）。专家可以为模仿学习或强化学习提供高层次的监督。策略可以通过模仿学习初步教授，然后通过强化学习进行优化，这有助于减少强化学习所需的长时间训练。Jia
    等人 [[19](#bib.bib19)] 利用从 Roach 中提取的特征来学习真实的动作/轨迹，为他们的研究提供监督。因此，强化学习通过使代理能够主动探索和从环境中学习，提供了应对模仿学习挑战的解决方案。同时也存在相关挑战，如样本低效、探索困难导致的次优行为，以及将学到的策略推广到新场景中的困难。'
- en: 7 Learning domain adaptation from simulator to real
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 从模拟器到现实的学习领域适应
- en: Large-scale virtual scenarios can be constructed in virtual engines, enabling
    the collection of a significant quantity of data more readily. However, there
    still exist significant domain disparities between virtual and real-world data,
    which pose challenges in creating and implementing virtual datasets. By leveraging
    the principle of domain adaptation, we can extract critical features directly
    from the simulator and transfer the knowledge learned from the source domain to
    the target domain, consisting of accurate real-world data.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模虚拟场景可以在虚拟引擎中构建，从而更容易收集大量数据。然而，虚拟数据和真实世界数据之间仍然存在显著的领域差异，这给创建和实施虚拟数据集带来了挑战。通过利用领域适应原理，我们可以直接从模拟器中提取关键特征，并将从源领域学到的知识转移到目标领域，即准确的真实世界数据。
- en: The H-Divergence framework [[101](#bib.bib101)] resolves the domain gap at both
    the visual and instance levels by adversarially learning a domain classifier and
    a detector simultaneously. Zhang et al. [[102](#bib.bib102)] propose a simulator-real
    interaction strategy that leverages disparities between the source domain and
    the target domain. The authors create two components to align differences at the
    global and local levels and ensure overall consistency between them. The realistic-looking
    synthetic images may subsequently be used to train an End-to-End model. A number
    of techniques rely on an open pipeline that introduces obstacles in the current
    environment. PlaceNet [[103](#bib.bib103)] places objects into the image space
    for detection and segmentation operations. GeoSim [[104](#bib.bib104)] is a geometry-aware
    approach that dynamically inserts objects using LiDAR and HD maps. DummyNet [[105](#bib.bib105)]
    is a pedestrian augmentation framework based on a GAN architecture that takes
    the background image as input and inserts pedestrians with consistent alignment.
    Some works take advantage of virtual LiDAR data [[106](#bib.bib106), [107](#bib.bib107),
    [108](#bib.bib108)]. Sallab et al. [[106](#bib.bib106)] perform learning on virtual
    LiDAR point clouds from CARLA [[109](#bib.bib109)] and utilize CycleGAN to transfer
    styles from the virtual domain to the real KITTI [[110](#bib.bib110)] dataset.
    Fang et al. [[107](#bib.bib107)] propose a LiDAR simulator that
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: H-Divergence 框架 [[101](#bib.bib101)] 通过对抗性地同时学习领域分类器和检测器来解决视觉和实例层面的领域差距。 Zhang
    等人 [[102](#bib.bib102)] 提出了一个模拟器-真实交互策略，该策略利用源领域和目标领域之间的差异。作者创建了两个组件以对齐全局和局部差异，并确保它们之间的整体一致性。现实感合成图像随后可用于训练端到端模型。一些技术依赖于引入当前环境障碍物的开放管道。
    PlaceNet [[103](#bib.bib103)] 将物体放置到图像空间以进行检测和分割操作。 GeoSim [[104](#bib.bib104)]
    是一种几何感知方法，通过 LiDAR 和高清地图动态插入物体。 DummyNet [[105](#bib.bib105)] 是一个基于 GAN 架构的行人增强框架，它以背景图像为输入，并插入对齐一致的行人。一些工作利用虚拟
    LiDAR 数据 [[106](#bib.bib106), [107](#bib.bib107), [108](#bib.bib108)]。Sallab 等人
    [[106](#bib.bib106)] 在来自 CARLA [[109](#bib.bib109)] 的虚拟 LiDAR 点云上进行学习，并利用 CycleGAN
    将虚拟领域的风格转移到真实的 KITTI [[110](#bib.bib110)] 数据集。Fang 等人 [[107](#bib.bib107)] 提出了一个
    LiDAR 模拟器，该模拟器
- en: 'Table 3: RECENT METHODS IN END-TO-END AUTONOMOUS DRIVING'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: 端到端自动驾驶中的近期方法'
- en: '| Paper, Year | Environment | Input modality | Output modality | Learning |
    Evaluation | Explaibility | Safety | Results | Data |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 论文, 年份 | 环境 | 输入模态 | 输出模态 | 学习 | 评估 | 可解释性 | 安全性 | 结果 | 数据 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '|'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PAD [[9](#bib.bib9)], &#124;'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PAD [[9](#bib.bib9)], &#124;'
- en: '&#124; 2023 &#124;'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2023 &#124;'
- en: '| NuScenes |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| NuScenes |'
- en: '&#124; 6 Multi-camera &#124;'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 6 多摄像头 &#124;'
- en: '&#124; images &#124;'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 图像 &#124;'
- en: '|'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Segmentation map, &#124;'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 分割图, &#124;'
- en: '&#124; agent future trajectories, &#124;'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 代理未来轨迹, &#124;'
- en: '&#124; future &#124;'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未来 &#124;'
- en: '&#124; occupancy &#124;'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 占用 &#124;'
- en: '|'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Multi-task &#124;'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 多任务 &#124;'
- en: '&#124; learning. &#124;'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习。 &#124;'
- en: '|'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; min ADE, &#124;'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 最小 ADE, &#124;'
- en: '&#124; min FDE, IoU, L2 &#124;'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 最小 FDE, IoU, L2 &#124;'
- en: '&#124; error &#124;'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 误差 &#124;'
- en: '|'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Exp. Via attention mask &#124;'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过注意力掩码的实验 &#124;'
- en: '&#124; in planner module &#124;'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在规划模块中 &#124;'
- en: '|'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Lowest collision rate, &#124;'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 最低碰撞率, &#124;'
- en: '&#124; lowest L2 error, Safety &#124;'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 最低 L2 误差, 安全性 &#124;'
- en: '&#124; boost via goal planner. &#124;'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过目标规划器提升。 &#124;'
- en: '|'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; L2: 1.65 &#124;'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; L2: 1.65 &#124;'
- en: '&#124; CR: 0.71 &#124;'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CR: 0.71 &#124;'
- en: '|'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Perception training: 6 epochs &#124;'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 感知训练: 6 轮次 &#124;'
- en: '&#124; Joint training: 20 epochs &#124;'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 联合训练: 20 轮次 &#124;'
- en: '|'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; ReasonNet [[16](#bib.bib16)], &#124;'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ReasonNet [[16](#bib.bib16)], &#124;'
- en: '&#124; 2023 &#124;'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2023 &#124;'
- en: '| CARLA |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Vehicle measurements &#124;'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 车辆测量 &#124;'
- en: '&#124; navigation, &#124;'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 导航, &#124;'
- en: '&#124; LiDAR, RGB &#124;'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LiDAR, RGB &#124;'
- en: '|'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Steering, speed, BEV, &#124;'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向, 速度, BEV, &#124;'
- en: '&#124; brake &#124;'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刹车 &#124;'
- en: '| Multi-task learning |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 多任务学习 |'
- en: '&#124; DOS and &#124;'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DOS 和 &#124;'
- en: '&#124; LeaderBoard &#124;'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 排行榜 &#124;'
- en: '| Attention map | - |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| 注意力图 | - |'
- en: '&#124; DS: 79.95 &#124;'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 79.95 &#124;'
- en: '&#124; RC: 89.89 &#124;'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 89.89 &#124;'
- en: '&#124; IS: 0.89 &#124;'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.89 &#124;'
- en: '|'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 2M frames (eight Towns) &#124;'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 2M 帧（八个城镇） &#124;'
- en: '&#124; Test: Town05 &#124;'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: Town05 &#124;'
- en: '|'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Policy Pre-Training [[111](#bib.bib111)], &#124;'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 策略预训练 [[111](#bib.bib111)], &#124;'
- en: '&#124; 2023 &#124;'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2023 &#124;'
- en: '|'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NuScenes, &#124;'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NuScenes, &#124;'
- en: '&#124; CARLA &#124;'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '| Camera and intrinsics | Steering, throttle | Imitation learning |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 摄像头和内参 | 转向, 油门 | 模仿学习 |'
- en: '&#124; Longest6, &#124;'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 最长6, &#124;'
- en: '&#124; collision rate &#124;'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 碰撞率 &#124;'
- en: '|'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Attention &#124;'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 注意力 &#124;'
- en: '&#124; activation map &#124;'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 激活图 &#124;'
- en: '|'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Handles cases where the &#124;'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 处理情况的 &#124;'
- en: '&#124; agent needs to stop &#124;'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 代理需要停止 &#124;'
- en: '|'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 47.4$\pm$5.6 &#124;'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 47.4$\pm$5.6 &#124;'
- en: '&#124; RC: 65.05$\pm$5.1 &#124;'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 65.05$\pm$5.1 &#124;'
- en: '&#124; IS: 0.79$\pm$0.08 &#124;'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.79$\pm$0.08 &#124;'
- en: '&#124; L2: 3.01, &#124;'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; L2: 3.01, &#124;'
- en: '&#124; CR: 0.94 &#124;'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CR: 0.94 &#124;'
- en: '|'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 40K &#124;'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 列车: 40K &#124;'
- en: '&#124; (Town01, 03, 04, 06) &#124;'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (Town01, 03, 04, 06) &#124;'
- en: '&#124; Test: 50 routes &#124;'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: 50条路线 &#124;'
- en: '|'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Think Twice [[19](#bib.bib19)], &#124;'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 深思熟虑 [[19](#bib.bib19)], &#124;'
- en: '&#124; 2023 &#124;'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2023 &#124;'
- en: '| CARLA | RGB camera, LiDAR |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| CARLA | RGB 摄像头, LiDAR |'
- en: '&#124; BEV feature map, &#124;'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BEV特征图, &#124;'
- en: '&#124; agent future trajectories, &#124;'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 代理未来轨迹, &#124;'
- en: '&#124; control actions &#124;'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 控制动作 &#124;'
- en: '|'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Open-loop imitation &#124;'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 开环模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '| Longest6 |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| 最长6 |'
- en: '&#124; Explainable via &#124;'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过 &#124;'
- en: '&#124; expert BEV feature map &#124;'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 专家BEV特征图 &#124;'
- en: '|'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Safety-critical regions, &#124;'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全关键区域, &#124;'
- en: '&#124; anticipate &#124;'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 预测 &#124;'
- en: '&#124; future motion &#124;'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未来运动 &#124;'
- en: '&#124; to avoid collisions &#124;'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 避免碰撞 &#124;'
- en: '|'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 70.9$\pm$3.4 &#124;'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 70.9$\pm$3.4 &#124;'
- en: '&#124; RC: 95.5$\pm$2.6 &#124;'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 95.5$\pm$2.6 &#124;'
- en: '&#124; IS: 0.75$\pm$0.05 &#124;'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.75$\pm$0.05 &#124;'
- en: '|'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Training: 189K data on four Towns, &#124;'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 189K 数据在四个城镇, &#124;'
- en: '&#124; Roach based teaching &#124;'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Roach 基础教学 &#124;'
- en: '|'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Scaling Vision-based [[17](#bib.bib17)], &#124;'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 扩展基于视觉的 [[17](#bib.bib17)], &#124;'
- en: '&#124; 2023 &#124;'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2023 &#124;'
- en: '| CARLA | Three cameras (views) |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| CARLA | 三个摄像头 (视图) |'
- en: '&#124; Ego-vehicle’s &#124;'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 自车的 &#124;'
- en: '&#124; steering angle and &#124;'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向角度和 &#124;'
- en: '&#124; acceleration &#124;'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 加速度 &#124;'
- en: '|'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Self-supervised &#124;'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 自监督 &#124;'
- en: '&#124; imitation learning &#124;'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿学习 &#124;'
- en: '|'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NoCrash, &#124;'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NoCrash, &#124;'
- en: '&#124; Leaderboard &#124;'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 排行榜 &#124;'
- en: '| Attention map |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| 注意力图 |'
- en: '&#124; Pedestrians caused strong &#124;'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 行人导致强烈 &#124;'
- en: '&#124; braking (0.794), &#124;'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刹车 (0.794), &#124;'
- en: '&#124; despite &#124;'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 尽管 &#124;'
- en: '&#124; green light &#124;'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 绿灯 &#124;'
- en: '|'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 98$\pm$1.7 &#124;'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 98$\pm$1.7 &#124;'
- en: '&#124; RC: 68$\pm$2.7 &#124;'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 68$\pm$2.7 &#124;'
- en: '|'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 15 hours (540K frames) &#124;'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 列车: 15小时 (540K 帧) &#124;'
- en: '&#124; Test: 25 hours ( 900k frames) &#124;'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: 25小时 ( 900k 帧) &#124;'
- en: '|'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Coaching a Teachable [[58](#bib.bib58)], &#124;'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 教练可教的 [[58](#bib.bib58)], &#124;'
- en: '&#124; 2023 &#124;'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2023 &#124;'
- en: '| CARLA |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Navigation, &#124;'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 导航, &#124;'
- en: '&#124; 3 RGB cameras &#124;'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 3个RGB摄像头 &#124;'
- en: '|'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Waypoints, &#124;'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 路点, &#124;'
- en: '&#124; control commands &#124;'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 控制命令 &#124;'
- en: '|'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Knowledge &#124;'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 知识 &#124;'
- en: '&#124; distillation, &#124;'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 蒸馏, &#124;'
- en: '&#124; imitation learning &#124;'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿学习 &#124;'
- en: '|'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Longest6, &#124;'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 最长6, &#124;'
- en: '&#124; ADE, FDE &#124;'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ADE, FDE &#124;'
- en: '| - |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '&#124; Attend to safety-critical &#124;'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 注意安全关键 &#124;'
- en: '&#124; entities &#124;'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 实体 &#124;'
- en: '|'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 73.30$\pm$1.07 &#124;'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 73.30$\pm$1.07 &#124;'
- en: '&#124; RC: 87.44$\pm$0.28 &#124;'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 87.44$\pm$0.28 &#124;'
- en: '&#124; ADE: 0.41 &#124;'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ADE: 0.41 &#124;'
- en: '&#124; FDE: 0.36 &#124;'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FDE: 0.36 &#124;'
- en: '| Train: Town01 - Town06 |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| 列车: Town01 - Town06 |'
- en: '|'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Hidden Biases of [[71](#bib.bib71)], &#124;'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 隐藏偏差 [[71](#bib.bib71)], &#124;'
- en: '&#124; 2023 &#124;'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2023 &#124;'
- en: '| CARLA |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Speed, &#124;'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 速度, &#124;'
- en: '&#124; camera and &#124;'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 摄像头和 &#124;'
- en: '&#124; LiDAR &#124;'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LiDAR &#124;'
- en: '|'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Steer, throttle, and brake, &#124;'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向, 油门和刹车, &#124;'
- en: '&#124; waypoints, path &#124;'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 路点, 路径 &#124;'
- en: '| Imitation learning | Longest6 | - |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| 模仿学习 | 最长6 | - |'
- en: '&#124; Larger safety distance, &#124;'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 更大的安全距离, &#124;'
- en: '&#124; safety area &#124;'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全区域 &#124;'
- en: '|'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 72 $\pm$3 &#124;'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 72 $\pm$3 &#124;'
- en: '&#124; RC: 95 $\pm$ 2 &#124;'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 95 $\pm$ 2 &#124;'
- en: '| Train: variable size 185k and 555k |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| 列车: 可变大小 185k 和 555k |'
- en: '|'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; KING [[6](#bib.bib6)], &#124;'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; KING [[6](#bib.bib6)], &#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| CARLA |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Front-facing &#124;'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 前向 &#124;'
- en: '&#124; camera and &#124;'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 摄像头和 &#124;'
- en: '&#124; LiDAR &#124;'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LiDAR &#124;'
- en: '| Throttle and steering | Behaviour cloning |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| 油门和转向 | 行为克隆 |'
- en: '&#124; Closed-loop (CR), &#124;'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 闭环 (CR), &#124;'
- en: '&#124; (RC), (IS), (DS) &#124;'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (RC), (IS), (DS) &#124;'
- en: '| - |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '&#124; Safety-critical &#124;'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全关键 &#124;'
- en: '&#124; driving &#124;'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 驾驶 &#124;'
- en: '&#124; scenarios and &#124;'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 场景和 &#124;'
- en: '&#124; stress-testing. &#124;'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 压力测试. &#124;'
- en: '|'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 90.20$\pm$0.00 &#124;'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 90.20$\pm$0.00 &#124;'
- en: '&#124; RC: 94.42$\pm$0.36 &#124;'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 94.42$\pm$0.36 &#124;'
- en: '&#124; IS: 0.96$\pm$0.36 &#124;'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.96$\pm$0.36 &#124;'
- en: '|'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 4 GPU &#124;'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 4 GPU &#124;'
- en: '&#124; hours 80 routes &#124;'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 小时 80 路径 &#124;'
- en: '&#124; on Town 3,4,5,6. &#124;'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在 Town 3,4,5,6. &#124;'
- en: '|'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; LAV [[10](#bib.bib10)], &#124;'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LAV [[10](#bib.bib10)], &#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| CARLA |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Front-facing camera, &#124;'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 前向相机, &#124;'
- en: '&#124; LiDAR &#124;'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LiDAR &#124;'
- en: '|'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Single steering and &#124;'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 单一转向和 &#124;'
- en: '&#124; acceleration command &#124;'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 加速命令 &#124;'
- en: '|'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Knowledge &#124;'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 知识 &#124;'
- en: '&#124; distillation, &#124;'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 蒸馏, &#124;'
- en: '&#124; imitation learning &#124;'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿学习 &#124;'
- en: '|'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Longest6 (DS), &#124;'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Longest6 (DS), &#124;'
- en: '&#124; (RC),(IS), &#124;'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (RC),(IS), &#124;'
- en: '&#124; (CR), (PC), &#124;'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (CR), (PC), &#124;'
- en: '&#124; (LC), (RV) &#124;'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (LC), (RV) &#124;'
- en: '| Spatial feature 2D map |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '| 空间特征 2D 地图 |'
- en: '&#124; Scenario such &#124;'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 场景如 &#124;'
- en: '&#124; as pedestrians crossing, &#124;'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 如行人过马路, &#124;'
- en: '&#124; lane change &#124;'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 车道变化 &#124;'
- en: '&#124; are modeled &#124;'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 被建模 &#124;'
- en: '|'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 61.85 &#124;'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 61.85 &#124;'
- en: '&#124; RC: 94.46 &#124;'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 94.46 &#124;'
- en: '&#124; IS: 0.64 &#124;'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.64 &#124;'
- en: '|'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: Four Towns, 186K frames &#124;'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 四个城镇, 186K 帧 &#124;'
- en: '&#124; Test: Town02 and Town05 &#124;'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: Town02 和 Town05 &#124;'
- en: '|'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; TransFuse [[7](#bib.bib7)], &#124;'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; TransFuse [[7](#bib.bib7)], &#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| CARLA |'
  id: totrans-482
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; RGB, &#124;'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RGB, &#124;'
- en: '&#124; LiDAR &#124;'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LiDAR &#124;'
- en: '|'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Waypoints, steer, throttle, &#124;'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 路径点, 转向, 油门, &#124;'
- en: '&#124; and brake &#124;'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和刹车 &#124;'
- en: '| Behaviour cloning |'
  id: totrans-488
  prefs: []
  type: TYPE_TB
  zh: '| 行为克隆 |'
- en: '&#124; Longest 6 (DS), &#124;'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Longest 6 (DS), &#124;'
- en: '&#124; (RC), (IPK), (IS) &#124;'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (RC), (IPK), (IS) &#124;'
- en: '|'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Explainable via auxiliary &#124;'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可通过辅助解释 &#124;'
- en: '&#124; output like depth, &#124;'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 输出如深度, &#124;'
- en: '&#124; semantic, HD map, &#124;'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 语义, HD 地图, &#124;'
- en: '&#124; planner A* &#124;'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 规划 A* &#124;'
- en: '| Global safety heuristic |'
  id: totrans-496
  prefs: []
  type: TYPE_TB
  zh: '| 全局安全启发式 |'
- en: '&#124; DS: 61.18 &#124;'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 61.18 &#124;'
- en: '&#124; RC: 86.69 &#124;'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 86.69 &#124;'
- en: '&#124; IS: 0.71 &#124;'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.71 &#124;'
- en: '|'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 2500 routes on eight &#124;'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 2500 路径在八个 &#124;'
- en: '&#124; Towns, 228k frames &#124;'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 城镇, 228k 帧 &#124;'
- en: '&#124; Test: 36 route &#124;'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: 36 路径 &#124;'
- en: '|'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Learning to Drive [[11](#bib.bib11)], &#124;'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习驾驶 [[11](#bib.bib11)], &#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '|'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NuScenes, &#124;'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NuScenes, &#124;'
- en: '&#124; youtube &#124;'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; youtube &#124;'
- en: '| Front-facing camera |'
  id: totrans-511
  prefs: []
  type: TYPE_TB
  zh: '| 前向相机 |'
- en: '&#124; Steering, throttle, &#124;'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向, 油门, &#124;'
- en: '&#124; brake, &#124;'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刹车, &#124;'
- en: '&#124; and velocity &#124;'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和速度 &#124;'
- en: '|'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Conditional &#124;'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 条件性 &#124;'
- en: '&#124; behavior cloning &#124;'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 行为克隆 &#124;'
- en: '|'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA benchmark, &#124;'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA 基准, &#124;'
- en: '&#124; F1 metric &#124;'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; F1 指标 &#124;'
- en: '| - | - |'
  id: totrans-521
  prefs: []
  type: TYPE_TB
  zh: '| - | - |'
- en: '&#124; F1 : 75.0 &#124;'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; F1 : 75.0 &#124;'
- en: '&#124; 7 perc. increase in RC &#124;'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC 增加 7% &#124;'
- en: '|'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 120 hour YouTube, &#124;'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 120 小时 YouTube, &#124;'
- en: '&#124; Test: Town01 and &#124;'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: Town01 和 &#124;'
- en: '&#124; Town02 with &#124;'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Town02 与 &#124;'
- en: '&#124; 40K transition &#124;'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 40K 过渡 &#124;'
- en: '|'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; HACO [[55](#bib.bib55)], &#124;'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; HACO [[55](#bib.bib55)], &#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| CARLA |'
  id: totrans-533
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Current state, &#124;'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 当前状态, &#124;'
- en: '&#124; navigation &#124;'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 导航 &#124;'
- en: '&#124; information &#124;'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 信息 &#124;'
- en: '|'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Acceleration, brake &#124;'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 加速, 刹车 &#124;'
- en: '&#124; and steering &#124;'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和转向 &#124;'
- en: '|'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Reinforcement &#124;'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 强化学习 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Safety violation &#124;'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全违规 &#124;'
- en: '&#124; data usage, &#124;'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 数据使用, &#124;'
- en: '&#124; success rate &#124;'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 成功率 &#124;'
- en: '| - |'
  id: totrans-547
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '&#124; Safety violation &#124;'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全违规 &#124;'
- en: '&#124; cost the episode &#124;'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 成本为每集 &#124;'
- en: '|'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; SV: 11.84 &#124;'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SV: 11.84 &#124;'
- en: '&#124; SR: 0.35 &#124;'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SR: 0.35 &#124;'
- en: '|'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 50 min &#124;'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 50 分钟 &#124;'
- en: '&#124; HACO training. &#124;'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; HACO 训练. &#124;'
- en: '&#124; 35k transition &#124;'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 35k 过渡 &#124;'
- en: '|'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PlanT [[18](#bib.bib18)], &#124;'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PlanT [[18](#bib.bib18)], &#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| CARLA |'
  id: totrans-561
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Camera , &#124;'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 相机 , &#124;'
- en: '&#124; LiDAR, &#124;'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LiDAR, &#124;'
- en: '&#124; route, object &#124;'
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 路径, 物体 &#124;'
- en: '|'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Waypoints, predicting &#124;'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 路径点, 预测 &#124;'
- en: '&#124; the future attributes of &#124;'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未来属性的 &#124;'
- en: '&#124; other vehicles &#124;'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 其他车辆 &#124;'
- en: '|'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Imitation &#124;'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Longest6 CARLA &#124;'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 最长6 CARLA &#124;'
- en: '&#124; (DS),(RC), &#124;'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (DS)、(RC)，&#124;'
- en: '&#124; (IS), (IPK), &#124;'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (IS)、(IPK)，&#124;'
- en: '&#124; (IT) &#124;'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (IT) &#124;'
- en: '|'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Post hoc explanations, &#124;'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 事后解释，&#124;'
- en: '&#124; attention weights for &#124;'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 注意力权重用于 &#124;'
- en: '&#124; identify relevant objects. &#124;'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 识别相关对象。 &#124;'
- en: '|'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Identification of collision &#124;'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 碰撞识别 &#124;'
- en: '&#124; free routes, &#124;'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 自由路线，&#124;'
- en: '&#124; RFDS algorithm &#124;'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RFDS 算法 &#124;'
- en: '&#124; for collision avoidance &#124;'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 用于碰撞避免 &#124;'
- en: '|'
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 81.36$\pm$6.54 &#124;'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 81.36$\pm$6.54 &#124;'
- en: '&#124; RC: 93.55$\pm$2.62 &#124;'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 93.55$\pm$2.62 &#124;'
- en: '&#124; IS: 0.87$\pm$0.05 &#124;'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.87$\pm$0.05 &#124;'
- en: '|'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 3.2 hours on PlanT, &#124;'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：在 PlanT 上 3.2 小时，&#124;'
- en: '&#124; 95 hours of &#124;'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 95 小时的 &#124;'
- en: '&#124; driving. &#124;'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 驾驶。 &#124;'
- en: '|'
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Trajectory-guided [[13](#bib.bib13)], &#124;'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 轨迹引导 [[13](#bib.bib13)]，&#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| CARLA |'
  id: totrans-598
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Monocular &#124;'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 单目 &#124;'
- en: '&#124; camera &#124;'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 摄像头 &#124;'
- en: '|'
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Steering, &#124;'
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向，&#124;'
- en: '&#124; throttle and brake &#124;'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 油门和刹车 &#124;'
- en: '|'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Behaviour &#124;'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 行为 &#124;'
- en: '&#124; cloning &#124;'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 克隆 &#124;'
- en: '|'
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA (DS), &#124;'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA（DS），&#124;'
- en: '&#124; (RC), (IS) &#124;'
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (RC)，(IS) &#124;'
- en: '|'
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Auxiliary tasks &#124;'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 辅助任务 &#124;'
- en: '&#124; include value &#124;'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 包含价值 &#124;'
- en: '&#124; and speed head &#124;'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和速度头 &#124;'
- en: '|'
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Reduce collision via long &#124;'
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过长时间减少碰撞 &#124;'
- en: '&#124; prediction, &#124;'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 预测，&#124;'
- en: '&#124; less infraction, &#124;'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 更少的违规，&#124;'
- en: '&#124; control model preform good &#124;'
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 控制模型表现良好 &#124;'
- en: '|'
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 75.14 &#124;'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 75.14 &#124;'
- en: '&#124; RC: 85.63 &#124;'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 85.63 &#124;'
- en: '&#124; IS: 0.87 &#124;'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.87 &#124;'
- en: '|'
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: Town01, 03, 04, 06 &#124;'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：Town01，03，04，06 &#124;'
- en: '&#124; Test: Town02, 05 &#124;'
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：Town02，05 &#124;'
- en: '|'
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Safety- Enhanced &#124;'
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全增强 &#124;'
- en: '&#124; Autonomous &#124;'
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 自动驾驶 &#124;'
- en: '&#124; Driving [[8](#bib.bib8)], &#124;'
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 驾驶 [[8](#bib.bib8)]，&#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| CARLA |'
  id: totrans-632
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; 3 RGB, &#124;'
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 3 RGB，&#124;'
- en: '&#124; 1 LiDAR &#124;'
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 1 个 LiDAR &#124;'
- en: '|'
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; 10 Waypoints, &#124;'
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 10 个航点，&#124;'
- en: '&#124; steering, &#124;'
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向，&#124;'
- en: '&#124; acceleration &#124;'
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 加速度 &#124;'
- en: '| InterFuser |'
  id: totrans-639
  prefs: []
  type: TYPE_TB
  zh: '| InterFuser |'
- en: '&#124; CARLA leaderboard, &#124;'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA 排行榜，&#124;'
- en: '&#124; CARLA 42 Routes &#124;'
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA 42 路径 &#124;'
- en: '&#124; benchmark, &#124;'
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基准测试，&#124;'
- en: '&#124; (RC),(IS),(DS) &#124;'
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (RC)、(IS)、(DS) &#124;'
- en: '|'
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Intermediate interpretable &#124;'
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 中间可解释的 &#124;'
- en: '&#124; features output from &#124;'
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 特征输出来自 &#124;'
- en: '&#124; transformer decoder &#124;'
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转换器解码器 &#124;'
- en: '&#124; (safety map, object density) &#124;'
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (安全地图，物体密度) &#124;'
- en: '|'
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Safe set contain only &#124;'
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全集仅包含 &#124;'
- en: '&#124; safe actions, safety sensitive &#124;'
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全动作，安全敏感 &#124;'
- en: '&#124; output via InterFuser &#124;'
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过 InterFuser 输出 &#124;'
- en: '|'
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 76.18 &#124;'
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 76.18 &#124;'
- en: '&#124; RC: 88.23 &#124;'
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 88.23 &#124;'
- en: '&#124; IS: 0.84 &#124;'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.84 &#124;'
- en: '|'
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 3M frames or &#124;'
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：3M 帧或 &#124;'
- en: '&#124; 410 hours (eight Towns) &#124;'
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 410 小时（八个城镇） &#124;'
- en: '|'
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; ST-P3 [[20](#bib.bib20)], &#124;'
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ST-P3 [[20](#bib.bib20)]，&#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '|'
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NuScenes, &#124;'
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NuScenes，&#124;'
- en: '&#124; CARLA &#124;'
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '|'
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; 6 Camera(NuScenes), &#124;'
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 6 个摄像头 (NuScenes)，&#124;'
- en: '&#124; 4 cameras (CARLA), &#124;'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 4 个摄像头 (CARLA)，&#124;'
- en: '&#124; navigation command &#124;'
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 导航命令 &#124;'
- en: '|'
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Steering, &#124;'
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向，&#124;'
- en: '&#124; throttle and brake &#124;'
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 油门和刹车 &#124;'
- en: '| ST-P3 |'
  id: totrans-674
  prefs: []
  type: TYPE_TB
  zh: '| ST-P3 |'
- en: '&#124; Open loop: IOU, PQ, &#124;'
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 开放循环：IOU，PQ，&#124;'
- en: '&#124; RQ, SQ, &#124;'
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RQ，SQ，&#124;'
- en: '&#124; L2 error &#124;'
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; L2 错误 &#124;'
- en: '&#124; Closed: (DS), (RC) &#124;'
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 关闭：（DS）、（RC） &#124;'
- en: '|'
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Interpretable map &#124;'
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可解释的地图 &#124;'
- en: '&#124; lanes and &#124;'
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 车道和 &#124;'
- en: '&#124; area which is drivable &#124;'
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可驾驶区域 &#124;'
- en: '|'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Safety Cost function &#124;'
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全成本函数 &#124;'
- en: '&#124; for the jerk action &#124;'
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对于加速度动作 &#124;'
- en: '&#124; penalize &#124;'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 惩罚 &#124;'
- en: '|'
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 55.14 &#124;'
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 55.14 &#124;'
- en: '&#124; RC: 86.74 &#124;'
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 86.74 &#124;'
- en: '&#124; L2: 2.90, CR: 1.27 &#124;'
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; L2: 2.90，CR: 1.27 &#124;'
- en: '|'
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 26124 samples &#124;'
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：26124 个样本 &#124;'
- en: '&#124; Validation: 5719 samples &#124;'
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 验证：5719 个样本 &#124;'
- en: '|'
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-695
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Safe Driving via &#124;'
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过 &#124;'
- en: '&#124; Expert Guided &#124;'
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 专家引导 &#124;'
- en: '&#124; Policy optimization [[56](#bib.bib56)], &#124;'
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 策略优化 [[56](#bib.bib56)]，&#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| MetaDrive | Camera | Control signal |'
  id: totrans-700
  prefs: []
  type: TYPE_TB
  zh: '| MetaDrive | 摄像头 | 控制信号 |'
- en: '&#124; Expert-in-the-loop &#124;'
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 专家参与的循环 &#124;'
- en: '&#124; reinforcement &#124;'
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 强化 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '| MetaDriv benchmark | - |'
  id: totrans-704
  prefs: []
  type: TYPE_TB
  zh: '| MetaDrive 基准 | - |'
- en: '&#124; Guardian to ensure &#124;'
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 监护人确保 &#124;'
- en: '&#124; training safety &#124;'
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练安全性 &#124;'
- en: '|'
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; ER: 388.37 $\pm$10.01 &#124;'
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误率: 388.37 $\pm$10.01 &#124;'
- en: '&#124; EC: 0.56 $\pm$0.35 &#124;'
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 误差率: 0.56 $\pm$0.35 &#124;'
- en: '&#124; SR: 0.85 $\pm$0.05 &#124;'
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 成功率: 0.85 $\pm$0.05 &#124;'
- en: '|'
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 100 scenes &#124;'
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 100 场景 &#124;'
- en: '&#124; Test: 50 scenes &#124;'
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: 50 场景 &#124;'
- en: '|'
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; COOPERNAUT [[88](#bib.bib88)] , &#124;'
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; COOPERNAUT [[88](#bib.bib88)] , &#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| CARLA |'
  id: totrans-718
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Front-facing camera, &#124;'
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 前视摄像头, &#124;'
- en: '&#124; LiDAR &#124;'
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 激光雷达 &#124;'
- en: '| Control signal |'
  id: totrans-721
  prefs: []
  type: TYPE_TB
  zh: '| 控制信号 |'
- en: '&#124; Behaviour &#124;'
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 行为 &#124;'
- en: '&#124; cloning &#124;'
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 克隆 &#124;'
- en: '| AUTOCASTSIM | - |'
  id: totrans-724
  prefs: []
  type: TYPE_TB
  zh: '| AUTOCASTSIM | - |'
- en: '&#124; Reduces safety &#124;'
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 减少安全性 &#124;'
- en: '&#124; hazards &#124;'
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 危险 &#124;'
- en: '&#124; for line-of &#124;'
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 用于线条检测的 &#124;'
- en: '&#124; sight sensing. &#124;'
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 视觉感知。 &#124;'
- en: '|'
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; SR: 90.5$\pm$1.2 &#124;'
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 成功率: 90.5$\pm$1.2 &#124;'
- en: '&#124; CR: 4.5$\pm$3.1 &#124;'
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 复杂度评分: 4.5$\pm$3.1 &#124;'
- en: '|'
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 12 traces + 84 traces &#124;'
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 12 条轨迹 + 84 条轨迹 &#124;'
- en: '&#124; Test : 27 accident &#124;'
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: 27 次事故 &#124;'
- en: '&#124; prone traces &#124;'
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 容易发生的轨迹 &#124;'
- en: '|'
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Human-AI Shared &#124;'
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 人工智能共享 &#124;'
- en: '&#124; Control via Policy [[21](#bib.bib21)], &#124;'
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于策略的控制 [[21](#bib.bib21)], &#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| MetaDrive |'
  id: totrans-741
  prefs: []
  type: TYPE_TB
  zh: '| MetaDrive |'
- en: '&#124; Current state, &#124;'
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 当前状态, &#124;'
- en: '&#124; goal state &#124;'
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 目标状态 &#124;'
- en: '| Control signal |'
  id: totrans-744
  prefs: []
  type: TYPE_TB
  zh: '| 控制信号 |'
- en: '&#124; Reinforcement &#124;'
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 强化学习 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; MetaDrive and &#124;'
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; MetaDrive 和 &#124;'
- en: '&#124; Pybullet-A1 &#124;'
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Pybullet-A1 &#124;'
- en: '|'
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Interpretable control &#124;'
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可解释的控制 &#124;'
- en: '&#124; interface &#124;'
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 界面 &#124;'
- en: '|'
  id: totrans-753
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Human-AI, &#124;'
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 人工智能, &#124;'
- en: '&#124; safety guarantee &#124;'
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全保障 &#124;'
- en: '&#124; 95 percentage &#124;'
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 95 百分比 &#124;'
- en: '&#124; success rate &#124;'
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 成功率 &#124;'
- en: '|'
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; EC: 0.05 $\pm$0.08 &#124;'
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 误差率: 0.05 $\pm$0.08 &#124;'
- en: '&#124; SR: 0.95 $\pm$ 0.02 &#124;'
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 成功率: 0.95 $\pm$ 0.02 &#124;'
- en: '|'
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 50 training scenario &#124;'
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 50 个训练场景 &#124;'
- en: '&#124; Test: 20 test scene &#124;'
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: 20 个测试场景 &#124;'
- en: '|'
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-765
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; MMFN: Multi-Modal &#124;'
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; MMFN: 多模态 &#124;'
- en: '&#124; Fusion-Net for [[66](#bib.bib66)], &#124;'
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Fusion-Net 参考 [[66](#bib.bib66)], &#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-768
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| CARLA |'
  id: totrans-769
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; HD map and &#124;'
  id: totrans-770
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 高清地图和 &#124;'
- en: '&#124; radar on top of the &#124;'
  id: totrans-771
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 雷达安装在 &#124;'
- en: '&#124; LiDAR and &#124;'
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 激光雷达和 &#124;'
- en: '&#124; camera &#124;'
  id: totrans-773
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 摄像头 &#124;'
- en: '|'
  id: totrans-774
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Steering, &#124;'
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向, &#124;'
- en: '&#124; throttle and brake &#124;'
  id: totrans-776
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 油门和刹车 &#124;'
- en: '|'
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Imitation &#124;'
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; LeaderBoard &#124;'
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 排行榜 &#124;'
- en: '| - |'
  id: totrans-783
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '&#124; Expert has more &#124;'
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 专家有更多 &#124;'
- en: '&#124; awareness of safe &#124;'
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对安全的认知 &#124;'
- en: '&#124; driving &#124;'
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 驾驶 &#124;'
- en: '|'
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 22.8 &#124;'
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 数据集: 22.8 &#124;'
- en: '&#124; RC: 47.22 &#124;'
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 47.22 &#124;'
- en: '|'
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 207K frames &#124;'
  id: totrans-791
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 207K 帧 &#124;'
- en: '&#124; Test: 20 routes &#124;'
  id: totrans-792
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: 20 路线 &#124;'
- en: '|'
  id: totrans-793
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-794
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CADRE: A Cascade &#124;'
  id: totrans-795
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CADRE: 一个级联 &#124;'
- en: '&#124; Deep Reinforcement [[57](#bib.bib57)], &#124;'
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 深度强化学习 [[57](#bib.bib57)], &#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| CARLA |'
  id: totrans-798
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Front-view camera, &#124;'
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 前视摄像头, &#124;'
- en: '&#124; position, &#124;'
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 位置, &#124;'
- en: '&#124; orientation &#124;'
  id: totrans-801
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 定向 &#124;'
- en: '&#124; and speed &#124;'
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和速度 &#124;'
- en: '| Control signal |'
  id: totrans-803
  prefs: []
  type: TYPE_TB
  zh: '| 控制信号 |'
- en: '&#124; Imitation &#124;'
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-805
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; NoCrash &#124;'
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 无碰撞 &#124;'
- en: '| - | - |'
  id: totrans-809
  prefs: []
  type: TYPE_TB
  zh: '| - | - |'
- en: '&#124; VA: 81/81 &#124;'
  id: totrans-810
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 验证准确率: 81/81 &#124;'
- en: '&#124; PA: 76/78 &#124;'
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 性能: 76/78 &#124;'
- en: '|'
  id: totrans-812
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train:25 training routes &#124;'
  id: totrans-813
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 25 个训练路线 &#124;'
- en: '&#124; Test: Town02 &#124;'
  id: totrans-814
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: Town02 &#124;'
- en: '|'
  id: totrans-815
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-816
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Model-Based Imitation &#124;'
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于模型的模仿 &#124;'
- en: '&#124; Learning for [[112](#bib.bib112)], &#124;'
  id: totrans-818
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习参考 [[112](#bib.bib112)], &#124;'
- en: '&#124; 2022 &#124;'
  id: totrans-819
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2022 &#124;'
- en: '| CARLA | RGB image, route |'
  id: totrans-820
  prefs: []
  type: TYPE_TB
  zh: '| CARLA | RGB 图像, 路线 |'
- en: '&#124; Vehicle control, &#124;'
  id: totrans-821
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 车辆控制, &#124;'
- en: '&#124; BEV Segmentation &#124;'
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BEV 分割 &#124;'
- en: '|'
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Model-based &#124;'
  id: totrans-824
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于模型的 &#124;'
- en: '&#124; imitation learning &#124;'
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿学习 &#124;'
- en: '|'
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; LeaderBoard &#124;'
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 排行榜 &#124;'
- en: '|'
  id: totrans-829
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; BEV semantic &#124;'
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BEV 语义 &#124;'
- en: '&#124; segmentation for &#124;'
  id: totrans-831
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 分割用于 &#124;'
- en: '&#124; interpretability &#124;'
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可解释性 &#124;'
- en: '| - |'
  id: totrans-833
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '&#124; DS: 61.1 $\pm$ 3.2 &#124;'
  id: totrans-834
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 数据集: 61.1 $\pm$ 3.2 &#124;'
- en: '&#124; RC: 97.4$\pm$ 0.8 &#124;'
  id: totrans-835
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 97.4$\pm$ 0.8 &#124;'
- en: '&#124; IS: 63.0 $\pm$ 3.0 &#124;'
  id: totrans-836
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 输入分数: 63.0 $\pm$ 3.0 &#124;'
- en: '|'
  id: totrans-837
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Test: Town05, routes &#124;'
  id: totrans-838
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: Town05, 路线 &#124;'
- en: '&#124; Train: Four different training &#124;'
  id: totrans-839
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：四种不同的训练 &#124;'
- en: '&#124; towns total &#124;'
  id: totrans-840
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 城镇总计 &#124;'
- en: '&#124; of 2.9M frames. &#124;'
  id: totrans-841
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2.9M 帧。 &#124;'
- en: '|'
  id: totrans-842
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-843
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; LookOut: Diverse &#124;'
  id: totrans-844
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LookOut：多样 &#124;'
- en: '&#124; Multi-Future &#124;'
  id: totrans-845
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 多未来 &#124;'
- en: '&#124; Prediction and Planning [[80](#bib.bib80)], &#124;'
  id: totrans-846
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 预测和规划 [[80](#bib.bib80)]， &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '|'
  id: totrans-848
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; ATG4D, &#124;'
  id: totrans-849
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ATG4D， &#124;'
- en: '&#124; Lidarsim &#124;'
  id: totrans-850
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Lidarsim &#124;'
- en: '|'
  id: totrans-851
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; LiDAR, &#124;'
  id: totrans-852
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LiDAR， &#124;'
- en: '&#124; navigation. &#124;'
  id: totrans-853
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 导航。 &#124;'
- en: '|'
  id: totrans-854
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Trajectory, &#124;'
  id: totrans-855
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 轨迹， &#124;'
- en: '&#124; vehicle control &#124;'
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 车辆控制 &#124;'
- en: '| Cost learning |'
  id: totrans-857
  prefs: []
  type: TYPE_TB
  zh: '| 成本学习 |'
- en: '&#124; Open loop: mAP, &#124;'
  id: totrans-858
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 开环：mAP， &#124;'
- en: '&#124; mSADE, &#124;'
  id: totrans-859
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; mSADE， &#124;'
- en: '&#124; mSADE, PlanASD &#124;'
  id: totrans-860
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; mSADE，PlanASD &#124;'
- en: '&#124; Cloose loop: Lidarsim &#124;'
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 闭环：Lidarsim &#124;'
- en: '| - |'
  id: totrans-862
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '&#124; Cost function include &#124;'
  id: totrans-863
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 成本函数包括 &#124;'
- en: '&#124; driving including &#124;'
  id: totrans-864
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 驾驶包括 &#124;'
- en: '&#124; safety, comfort, &#124;'
  id: totrans-865
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全，舒适， &#124;'
- en: '&#124; traffic-rules. &#124;'
  id: totrans-866
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 交通规则。 &#124;'
- en: '|'
  id: totrans-867
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CR: 7.93 &#124;'
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CR: 7.93 &#124;'
- en: '&#124; Progress:62.65 &#124;'
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 进展：62.65 &#124;'
- en: '&#124; Jerk: 4.69 &#124;'
  id: totrans-870
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Jerk: 4.69 &#124;'
- en: '|'
  id: totrans-871
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: one million frames &#124;'
  id: totrans-872
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：一百万帧 &#124;'
- en: '&#124; Test: Lidarsim &#124;'
  id: totrans-873
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：Lidarsim &#124;'
- en: '|'
  id: totrans-874
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-875
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; MP3: A Unified Model &#124;'
  id: totrans-876
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; MP3：统一模型 &#124;'
- en: '&#124; to Map, Perceive, &#124;'
  id: totrans-877
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 到映射、感知， &#124;'
- en: '&#124; Predict and Plan [[82](#bib.bib82)], &#124;'
  id: totrans-878
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 预测和规划 [[82](#bib.bib82)]， &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-879
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '| URBANEXPERT |'
  id: totrans-880
  prefs: []
  type: TYPE_TB
  zh: '| URBANEXPERT |'
- en: '&#124; Raw sensor data &#124;'
  id: totrans-881
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原始传感器数据 &#124;'
- en: '&#124; and a high-level &#124;'
  id: totrans-882
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 以及高级 &#124;'
- en: '&#124; command &#124;'
  id: totrans-883
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 命令 &#124;'
- en: '|'
  id: totrans-884
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Control command, &#124;'
  id: totrans-885
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 控制命令， &#124;'
- en: '&#124; dynamic occupancy &#124;'
  id: totrans-886
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 动态占用 &#124;'
- en: '&#124; field &#124;'
  id: totrans-887
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 场 &#124;'
- en: '| MP3 |'
  id: totrans-888
  prefs: []
  type: TYPE_TB
  zh: '| MP3 |'
- en: '&#124; Closed-loop: Lidarsim &#124;'
  id: totrans-889
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 闭环：Lidarsim &#124;'
- en: '&#124; Open loop: L2 &#124;'
  id: totrans-890
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 开环：L2 &#124;'
- en: '|'
  id: totrans-891
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Interpretable cost &#124;'
  id: totrans-892
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可解释的成本 &#124;'
- en: '&#124; functions, dynamic &#124;'
  id: totrans-893
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 函数，动态 &#124;'
- en: '&#124; occupancy field, &#124;'
  id: totrans-894
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 占用场， &#124;'
- en: '&#124; Interpretable Scene repr. &#124;'
  id: totrans-895
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可解释的场景表示 &#124;'
- en: '|'
  id: totrans-896
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Penalize trajectories &#124;'
  id: totrans-897
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 惩罚轨迹 &#124;'
- en: '&#124; where the SDV overlaps &#124;'
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SDV 重叠处 &#124;'
- en: '&#124; occupied regions, penalize &#124;'
  id: totrans-899
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 占用区域，惩罚 &#124;'
- en: '&#124; jerk, lateral acceleration &#124;'
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Jerk，横向加速度 &#124;'
- en: '|'
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; L2: 12.95 &#124;'
  id: totrans-902
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; L2：12.95 &#124;'
- en: '&#124; Collision: 1037.08 &#124;'
  id: totrans-903
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 碰撞：1037.08 &#124;'
- en: '&#124; Jerk: 1.64 &#124;'
  id: totrans-904
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Jerk: 1.64 &#124;'
- en: '&#124; Success Pre: 74.39 &#124;'
  id: totrans-905
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 成功前：74.39 &#124;'
- en: '|'
  id: totrans-906
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 5000 scenarios &#124;'
  id: totrans-907
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：5000 个场景 &#124;'
- en: '&#124; Test: 1000 &#124;'
  id: totrans-908
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：1000 &#124;'
- en: '|'
  id: totrans-909
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-910
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Object-Aware &#124;'
  id: totrans-911
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对象感知 &#124;'
- en: '&#124; Regularization &#124;'
  id: totrans-912
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 正则化 &#124;'
- en: '&#124; for Addressing Causal [[113](#bib.bib113)], &#124;'
  id: totrans-913
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 用于处理因果关系 [[113](#bib.bib113)]， &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-914
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '| CARLA | RGB image | Control signal |'
  id: totrans-915
  prefs: []
  type: TYPE_TB
  zh: '| CARLA | RGB 图像 | 控制信号 |'
- en: '&#124; Behaviour &#124;'
  id: totrans-916
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 行为 &#124;'
- en: '&#124; cloning &#124;'
  id: totrans-917
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 克隆 &#124;'
- en: '|'
  id: totrans-918
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Atari environment, &#124;'
  id: totrans-919
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Atari 环境， &#124;'
- en: '&#124; CARLA . &#124;'
  id: totrans-920
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA。 &#124;'
- en: '| - | Policy safe adaptation. |'
  id: totrans-921
  prefs: []
  type: TYPE_TB
  zh: '| - | 策略安全适应。 |'
- en: '&#124; Straight: 87$\pm$4.4 &#124;'
  id: totrans-922
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 直线：87$\pm$4.4 &#124;'
- en: '&#124; turn: 70.0$\pm$ 7.2 &#124;'
  id: totrans-923
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向：70.0$\pm$ 7.2 &#124;'
- en: '&#124; Nav: 35.7$\pm$10.2 &#124;'
  id: totrans-924
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Nav: 35.7$\pm$10.2 &#124;'
- en: '|'
  id: totrans-925
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 150 demonstrations &#124;'
  id: totrans-926
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：150 个演示 &#124;'
- en: '&#124; Test : 25 routes &#124;'
  id: totrans-927
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：25 条路线 &#124;'
- en: '|'
  id: totrans-928
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-929
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; GRI: General Reinforced &#124;'
  id: totrans-930
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GRI：通用强化 &#124;'
- en: '&#124; Imitation and its &#124;'
  id: totrans-931
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿及其 &#124;'
- en: '&#124; application to vision-based [[100](#bib.bib100)], &#124;'
  id: totrans-932
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 应用于基于视觉的 [[100](#bib.bib100)]， &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-933
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '| CARLA | 3 RGB camera view | Control signal |'
  id: totrans-934
  prefs: []
  type: TYPE_TB
  zh: '| CARLA | 3 RGB 摄像头视角 | 控制信号 |'
- en: '&#124; Off-policy &#124;'
  id: totrans-935
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 离策略 &#124;'
- en: '&#124; reinforcement &#124;'
  id: totrans-936
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 强化学习 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-937
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-938
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA Leaderboard, &#124;'
  id: totrans-939
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA 排行榜， &#124;'
- en: '&#124; NoCrash, &#124;'
  id: totrans-940
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NoCrash， &#124;'
- en: '&#124; Mujoco benchmark &#124;'
  id: totrans-941
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Mujoco 基准 &#124;'
- en: '| - | - |'
  id: totrans-942
  prefs: []
  type: TYPE_TB
  zh: '| - | - |'
- en: '&#124; DS: 36.79 &#124;'
  id: totrans-943
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 36.79 &#124;'
- en: '&#124; RC: 61.85 &#124;'
  id: totrans-944
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 61.85 &#124;'
- en: '&#124; IS: 0.60 &#124;'
  id: totrans-945
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.60 &#124;'
- en: '|'
  id: totrans-946
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 60M steps &#124;'
  id: totrans-947
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：60M 步骤 &#124;'
- en: '&#124; Test: with 12M and 16M steps &#124;'
  id: totrans-948
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：12M 和 16M 步骤 &#124;'
- en: '|'
  id: totrans-949
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-950
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Multi-Modal &#124;'
  id: totrans-951
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 多模态 &#124;'
- en: '&#124; Fusion [[14](#bib.bib14)], &#124;'
  id: totrans-952
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 融合 [[14](#bib.bib14)]， &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-953
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '| CARLA |'
  id: totrans-954
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Front-facing &#124;'
  id: totrans-955
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 面向前方 &#124;'
- en: '&#124; camera and &#124;'
  id: totrans-956
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 摄像头和 &#124;'
- en: '&#124; LiDAR &#124;'
  id: totrans-957
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LiDAR &#124;'
- en: '|'
  id: totrans-958
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; 4 Waypoints, &#124;'
  id: totrans-959
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 4 个航点， &#124;'
- en: '&#124; steer, throttle, &#124;'
  id: totrans-960
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向，油门， &#124;'
- en: '&#124; and brake &#124;'
  id: totrans-961
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和刹车 &#124;'
- en: '|'
  id: totrans-962
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Imitation &#124;'
  id: totrans-963
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-964
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-965
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-966
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; LeaderBoard &#124;'
  id: totrans-967
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 排行榜 &#124;'
- en: '|'
  id: totrans-968
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Attention map &#124;'
  id: totrans-969
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 注意力图 &#124;'
- en: '&#124; visualizations &#124;'
  id: totrans-970
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可视化 &#124;'
- en: '|'
  id: totrans-971
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Handle adversarial &#124;'
  id: totrans-972
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 处理对抗性 &#124;'
- en: '&#124; scenarios in urban &#124;'
  id: totrans-973
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 城市场景 &#124;'
- en: '&#124; driving, &#124;'
  id: totrans-974
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 驾驶, &#124;'
- en: '&#124; e.g., hard turnings. &#124;'
  id: totrans-975
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 例如，困难的转弯。 &#124;'
- en: '|'
  id: totrans-976
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 33.15 $\pm$ 4.04 &#124;'
  id: totrans-977
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 33.15 $\pm$ 4.04 &#124;'
- en: '&#124; RC: 56.36 $\pm$ 7.14 &#124;'
  id: totrans-978
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 56.36 $\pm$ 7.14 &#124;'
- en: '|'
  id: totrans-979
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 7 towns &#124;'
  id: totrans-980
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 7 个城镇 &#124;'
- en: '&#124; Test: Twon05 &#124;'
  id: totrans-981
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: Twon05 &#124;'
- en: '|'
  id: totrans-982
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-983
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Learning by &#124;'
  id: totrans-984
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过学习 &#124;'
- en: '&#124; Watching [[51](#bib.bib51)], &#124;'
  id: totrans-985
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 观看 [[51](#bib.bib51)], &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-986
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '| CARLA |'
  id: totrans-987
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Speed, &#124;'
  id: totrans-988
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 速度, &#124;'
- en: '&#124; high-level &#124;'
  id: totrans-989
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 高级 &#124;'
- en: '&#124; navigation &#124;'
  id: totrans-990
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 导航 &#124;'
- en: '|'
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Waypoints, &#124;'
  id: totrans-992
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 路径点, &#124;'
- en: '&#124; steer, throttle, &#124;'
  id: totrans-993
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向, 油门, &#124;'
- en: '&#124; and brake &#124;'
  id: totrans-994
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和刹车 &#124;'
- en: '|'
  id: totrans-995
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Imitation &#124;'
  id: totrans-996
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-997
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-998
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-999
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; NoCrash &#124;'
  id: totrans-1000
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NoCrash &#124;'
- en: '&#124; benchmarks &#124;'
  id: totrans-1001
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基准 &#124;'
- en: '| BEV visibility map |'
  id: totrans-1002
  prefs: []
  type: TYPE_TB
  zh: '| BEV 可视化图 |'
- en: '&#124; Avoid an unsafe &#124;'
  id: totrans-1003
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 避免不安全的 &#124;'
- en: '&#124; maneuver. &#124;'
  id: totrans-1004
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 操作。 &#124;'
- en: '|'
  id: totrans-1005
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NC-R: 92 &#124;'
  id: totrans-1006
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-R: 92 &#124;'
- en: '&#124; NC-D: 24 &#124;'
  id: totrans-1007
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-D: 24 &#124;'
- en: '&#124; OB: 92 &#124;'
  id: totrans-1008
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; OB: 92 &#124;'
- en: '|'
  id: totrans-1009
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: Town 1 &#124;'
  id: totrans-1010
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: Town 1 &#124;'
- en: '&#124; Test: Town 2 &#124;'
  id: totrans-1011
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: Town 2 &#124;'
- en: '|'
  id: totrans-1012
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1013
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NEAT [[12](#bib.bib12)], &#124;'
  id: totrans-1014
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NEAT [[12](#bib.bib12)], &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-1015
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '| CARLA |'
  id: totrans-1016
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; RGB cameras, &#124;'
  id: totrans-1017
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RGB 摄像头, &#124;'
- en: '&#124; and intrinsics, &#124;'
  id: totrans-1018
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和内在, &#124;'
- en: '&#124; locations,speed &#124;'
  id: totrans-1019
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 位置, 速度 &#124;'
- en: '|'
  id: totrans-1020
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Waypoints, &#124;'
  id: totrans-1021
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 路径点, &#124;'
- en: '&#124; BEV as a &#124;'
  id: totrans-1022
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BEV 作为 &#124;'
- en: '&#124; auxiliary output &#124;'
  id: totrans-1023
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 辅助输出 &#124;'
- en: '|'
  id: totrans-1024
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Behaviour &#124;'
  id: totrans-1025
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 行为 &#124;'
- en: '&#124; cloning &#124;'
  id: totrans-1026
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 克隆 &#124;'
- en: '|'
  id: totrans-1027
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-1028
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; Leaderboard. &#124;'
  id: totrans-1029
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 排行榜。 &#124;'
- en: '&#124; (RC), (IS), (DS) &#124;'
  id: totrans-1030
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (RC), (IS), (DS) &#124;'
- en: '|'
  id: totrans-1031
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NEAT intermediate &#124;'
  id: totrans-1032
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NEAT 中间 &#124;'
- en: '&#124; representations provides &#124;'
  id: totrans-1033
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 表示提供了 &#124;'
- en: '&#124; interpretable attention map &#124;'
  id: totrans-1034
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可解释的注意力图 &#124;'
- en: '|'
  id: totrans-1035
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; At that time highest safety &#124;'
  id: totrans-1036
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 当时最高安全性 &#124;'
- en: '&#124; among other &#124;'
  id: totrans-1037
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 以及其他 &#124;'
- en: '&#124; methods on the CARLA. &#124;'
  id: totrans-1038
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA 上的方法。 &#124;'
- en: '|'
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 24.08$\pm$3.30 &#124;'
  id: totrans-1040
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 24.08$\pm$3.30 &#124;'
- en: '&#124; RC: 59.94$\pm$0.50 &#124;'
  id: totrans-1041
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 59.94$\pm$0.50 &#124;'
- en: '&#124; IS: 0.49$\pm$0.02 &#124;'
  id: totrans-1042
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.49$\pm$0.02 &#124;'
- en: '|'
  id: totrans-1043
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 8 towns &#124;'
  id: totrans-1044
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 8 个城镇 &#124;'
- en: '&#124; Test: (Town01- &#124;'
  id: totrans-1045
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: (Town01- &#124;'
- en: '&#124; Town 06) &#124;'
  id: totrans-1046
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Town 06) &#124;'
- en: '&#124; 100 secret routes &#124;'
  id: totrans-1047
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 100 个秘密路线 &#124;'
- en: '|'
  id: totrans-1048
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1049
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; End-to-End Urban &#124;'
  id: totrans-1050
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 端到端城市 &#124;'
- en: '&#124; Driving [[54](#bib.bib54)], &#124;'
  id: totrans-1051
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 驾驶 [[54](#bib.bib54)], &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-1052
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '| CARLA |'
  id: totrans-1053
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Wide-angle camera &#124;'
  id: totrans-1054
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 广角相机 &#124;'
- en: '&#124; image with a &#124;'
  id: totrans-1055
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 带有 &#124;'
- en: '&#124; 100 degree &#124;'
  id: totrans-1056
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 100 度 &#124;'
- en: '&#124; horizontal FOV &#124;'
  id: totrans-1057
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 水平视场 &#124;'
- en: '|'
  id: totrans-1058
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Steering, &#124;'
  id: totrans-1059
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向, &#124;'
- en: '&#124; throttle and brake &#124;'
  id: totrans-1060
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 油门和刹车 &#124;'
- en: '|'
  id: totrans-1061
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Reinforcement &#124;'
  id: totrans-1062
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 强化学习 &#124;'
- en: '&#124; learning expert, &#124;'
  id: totrans-1063
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习专家, &#124;'
- en: '&#124; imitation learning &#124;'
  id: totrans-1064
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿学习 &#124;'
- en: '|'
  id: totrans-1065
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-1066
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; NoCrash and &#124;'
  id: totrans-1067
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NoCrash 和 &#124;'
- en: '&#124; LeaderBoard &#124;'
  id: totrans-1068
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 排行榜 &#124;'
- en: '| - | - |'
  id: totrans-1069
  prefs: []
  type: TYPE_TB
  zh: '| - | - |'
- en: '&#124; DS: 55.27$\pm$1.43 &#124;'
  id: totrans-1070
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 55.27$\pm$1.43 &#124;'
- en: '&#124; RC: 88.16$\pm$1.52 &#124;'
  id: totrans-1071
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 88.16$\pm$1.52 &#124;'
- en: '&#124; IS: 0.62$\pm$0.02 &#124;'
  id: totrans-1072
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.62$\pm$0.02 &#124;'
- en: '|'
  id: totrans-1073
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Off-policy &#124;'
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 离线策略 &#124;'
- en: '&#124; dataset 80 episodes, &#124;'
  id: totrans-1075
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 数据集 80 轮, &#124;'
- en: '&#124; Train: 50 routes &#124;'
  id: totrans-1076
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 50 路线 &#124;'
- en: '&#124; Test: 26 routes &#124;'
  id: totrans-1077
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: 26 路线 &#124;'
- en: '|'
  id: totrans-1078
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1079
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Learning to drive &#124;'
  id: totrans-1080
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习驾驶 &#124;'
- en: '&#124; from [[52](#bib.bib52)], &#124;'
  id: totrans-1081
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 来源 [[52](#bib.bib52)], &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-1082
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '| CARLA |'
  id: totrans-1083
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; RGB images &#124;'
  id: totrans-1084
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RGB 图像 &#124;'
- en: '&#124; and &#124;'
  id: totrans-1085
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和 &#124;'
- en: '&#124; speed readings &#124;'
  id: totrans-1086
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 速度读数 &#124;'
- en: '|'
  id: totrans-1087
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Steering, &#124;'
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向, &#124;'
- en: '&#124; throttle and &#124;'
  id: totrans-1089
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 油门和 &#124;'
- en: '&#124; brake &#124;'
  id: totrans-1090
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刹车 &#124;'
- en: '|'
  id: totrans-1091
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Reinforcement &#124;'
  id: totrans-1092
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 强化学习 &#124;'
- en: '&#124; learning, policy &#124;'
  id: totrans-1093
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习, 策略 &#124;'
- en: '&#124; distillation &#124;'
  id: totrans-1094
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 蒸馏 &#124;'
- en: '|'
  id: totrans-1095
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-1096
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; LeaderBoard &#124;'
  id: totrans-1097
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 排行榜 &#124;'
- en: '| - |'
  id: totrans-1098
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '&#124; Action-values &#124;'
  id: totrans-1099
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 动作值 &#124;'
- en: '&#124; based on the &#124;'
  id: totrans-1100
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于 &#124;'
- en: '&#124; current ego-vehicle &#124;'
  id: totrans-1101
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 当前自车 &#124;'
- en: '&#124; state &#124;'
  id: totrans-1102
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 状态 &#124;'
- en: '|'
  id: totrans-1103
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DS: 17.36$\pm$2.95 &#124;'
  id: totrans-1104
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DS: 17.36$\pm$2.95 &#124;'
- en: '&#124; RC: 43.46$\pm$2.99 &#124;'
  id: totrans-1105
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RC: 43.46$\pm$2.99 &#124;'
- en: '&#124; IS: 0.54$\pm$0.06 &#124;'
  id: totrans-1106
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IS: 0.54$\pm$0.06 &#124;'
- en: '|'
  id: totrans-1107
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 69 hours &#124;'
  id: totrans-1108
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：69 小时 &#124;'
- en: '&#124; about 1m frames &#124;'
  id: totrans-1109
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 约 1m 帧 &#124;'
- en: '&#124; Test: 270K frames &#124;'
  id: totrans-1110
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：270K 帧 &#124;'
- en: '|'
  id: totrans-1111
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1112
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Safe Local Motion &#124;'
  id: totrans-1113
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全局部运动 &#124;'
- en: '&#124; Planning with &#124;'
  id: totrans-1114
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 规划 &#124;'
- en: '&#124; Self-Supervised [[63](#bib.bib63)], &#124;'
  id: totrans-1115
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 自监督 [[63](#bib.bib63)], &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-1116
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '|'
  id: totrans-1117
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NuScenes, &#124;'
  id: totrans-1118
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NuScenes, &#124;'
- en: '&#124; CARLA &#124;'
  id: totrans-1119
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '| LiDAR |'
  id: totrans-1120
  prefs: []
  type: TYPE_TB
  zh: '| LiDAR |'
- en: '&#124; Control signal, &#124;'
  id: totrans-1121
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 控制信号, &#124;'
- en: '&#124; BEV &#124;'
  id: totrans-1122
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BEV &#124;'
- en: '|'
  id: totrans-1123
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Behaviour &#124;'
  id: totrans-1124
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 行为 &#124;'
- en: '&#124; cloning &#124;'
  id: totrans-1125
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 克隆 &#124;'
- en: '| CARLA NoCrash |'
  id: totrans-1126
  prefs: []
  type: TYPE_TB
  zh: '| CARLA NoCrash |'
- en: '&#124; Object-centric &#124;'
  id: totrans-1127
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 以对象为中心 &#124;'
- en: '&#124; representation &#124;'
  id: totrans-1128
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 表示 &#124;'
- en: '|'
  id: totrans-1129
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Safe planner, maintaining &#124;'
  id: totrans-1130
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全规划器，维持 &#124;'
- en: '&#124; a wide safety margin, avoid &#124;'
  id: totrans-1131
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 广泛的安全边际，避免 &#124;'
- en: '&#124; safety critical situations &#124;'
  id: totrans-1132
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全关键情境 &#124;'
- en: '|'
  id: totrans-1133
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; (Success rate) &#124;'
  id: totrans-1134
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; （成功率）&#124;'
- en: '&#124; NC-E:66 $\pm$ 3 &#124;'
  id: totrans-1135
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-E:66 $\pm$ 3 &#124;'
- en: '&#124; NC-R: 73$\pm$ 1 &#124;'
  id: totrans-1136
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-R: 73$\pm$ 1 &#124;'
- en: '&#124; NC-D: 44 $\pm$ 5 &#124;'
  id: totrans-1137
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-D: 44 $\pm$ 5 &#124;'
- en: '|'
  id: totrans-1138
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: Town 1 &#124;'
  id: totrans-1139
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：Town 1 &#124;'
- en: '&#124; Test: Town 2 &#124;'
  id: totrans-1140
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：Town 2 &#124;'
- en: '&#124; Train: 850 scenes(NuScenes) &#124;'
  id: totrans-1141
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：850 场景（NuScenes） &#124;'
- en: '&#124; Test: 150 scenes &#124;'
  id: totrans-1142
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：150 场景 &#124;'
- en: '|'
  id: totrans-1143
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1144
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Carl-Lead: Lidar-based &#124;'
  id: totrans-1145
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Carl-Lead: 基于激光雷达 &#124;'
- en: '&#124; End-to-End &#124;'
  id: totrans-1146
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 端到端 &#124;'
- en: '&#124; Autonomous [[64](#bib.bib64)], &#124;'
  id: totrans-1147
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 自主 [[64](#bib.bib64)], &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-1148
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '| CARLA | LiDAR |'
  id: totrans-1149
  prefs: []
  type: TYPE_TB
  zh: '| CARLA | LiDAR |'
- en: '&#124; Steering, &#124;'
  id: totrans-1150
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向, &#124;'
- en: '&#124; throttle, brake, &#124;'
  id: totrans-1151
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 油门, 刹车, &#124;'
- en: '&#124; HD map &#124;'
  id: totrans-1152
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; HD 地图 &#124;'
- en: '|'
  id: totrans-1153
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Reinforcement &#124;'
  id: totrans-1154
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 强化学习 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-1155
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '| CARLA NoCrash |'
  id: totrans-1156
  prefs: []
  type: TYPE_TB
  zh: '| CARLA NoCrash |'
- en: '&#124; Saliency maps for &#124;'
  id: totrans-1157
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 重要性图 &#124;'
- en: '&#124; visualizing &#124;'
  id: totrans-1158
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可视化 &#124;'
- en: '&#124; model predictions &#124;'
  id: totrans-1159
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模型预测 &#124;'
- en: '|'
  id: totrans-1160
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Collision reward &#124;'
  id: totrans-1161
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 碰撞奖励 &#124;'
- en: '&#124; punishment for unsafe &#124;'
  id: totrans-1162
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对不安全情况的惩罚 &#124;'
- en: '&#124; driving &#124;'
  id: totrans-1163
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 驾驶 &#124;'
- en: '|'
  id: totrans-1164
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; (Success rate) &#124;'
  id: totrans-1165
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; （成功率）&#124;'
- en: '&#124; NC-R: 93.50 &#124;'
  id: totrans-1166
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-R: 93.50 &#124;'
- en: '&#124; NC-D: 93.00 &#124;'
  id: totrans-1167
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-D: 93.00 &#124;'
- en: '|'
  id: totrans-1168
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 677.7K interaction steps &#124;'
  id: totrans-1169
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：677.7K 互动步骤 &#124;'
- en: '&#124; Test: 14,400 episodes &#124;'
  id: totrans-1170
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：14,400 集 &#124;'
- en: '|'
  id: totrans-1171
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1172
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; A Versatile and &#124;'
  id: totrans-1173
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 多功能和 &#124;'
- en: '&#124; Efficient &#124;'
  id: totrans-1174
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 高效 &#124;'
- en: '&#124; Reinforcement Learning [[93](#bib.bib93)], &#124;'
  id: totrans-1175
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 强化学习 [[93](#bib.bib93)], &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-1176
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '|'
  id: totrans-1177
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA, &#124;'
  id: totrans-1178
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA, &#124;'
- en: '&#124; BDD100k &#124;'
  id: totrans-1179
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BDD100k &#124;'
- en: '| RGB image | Control signal |'
  id: totrans-1180
  prefs: []
  type: TYPE_TB
  zh: '| RGB 图像 | 控制信号 |'
- en: '&#124; Reinforcement &#124;'
  id: totrans-1181
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 强化学习 &#124;'
- en: '&#124; learning, &#124;'
  id: totrans-1182
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习, &#124;'
- en: '&#124; imitation learning &#124;'
  id: totrans-1183
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿学习 &#124;'
- en: '| NoGap on CARLA |'
  id: totrans-1184
  prefs: []
  type: TYPE_TB
  zh: '| CARLA 无缝 |'
- en: '&#124; Interpretable &#124;'
  id: totrans-1185
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可解释 &#124;'
- en: '&#124; segmentation &#124;'
  id: totrans-1186
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 分割 &#124;'
- en: '&#124; map &#124;'
  id: totrans-1187
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 地图 &#124;'
- en: '|'
  id: totrans-1188
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Move the vehicle &#124;'
  id: totrans-1189
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 移动车辆 &#124;'
- en: '&#124; to safe state &#124;'
  id: totrans-1190
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 到安全状态 &#124;'
- en: '|'
  id: totrans-1191
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; MPI (m): Turn:7.2, &#124;'
  id: totrans-1192
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; MPI (m): 转弯: 7.2, &#124;'
- en: '&#124; Straight : 4.1 &#124;'
  id: totrans-1193
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 直线：4.1 &#124;'
- en: '&#124; SR: Turn: 53.2 &#124;'
  id: totrans-1194
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SR: 转弯: 53.2 &#124;'
- en: '&#124; Straight: 16.7 &#124;'
  id: totrans-1195
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 直线：16.7 &#124;'
- en: '&#124; Close loop : MPI: &#124;'
  id: totrans-1196
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 闭环：MPI: &#124;'
- en: '&#124; RL: 332.6, IL:180.9 &#124;'
  id: totrans-1197
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RL: 332.6, IL:180.9 &#124;'
- en: '|'
  id: totrans-1198
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 28h of driving &#124;'
  id: totrans-1199
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：28小时驾驶 &#124;'
- en: '&#124; and 2.5M RL steps &#124;'
  id: totrans-1200
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 以及 2.5M RL 步骤 &#124;'
- en: '|'
  id: totrans-1201
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1202
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Multi-task Learning &#124;'
  id: totrans-1203
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 多任务学习 &#124;'
- en: '&#124; with Attention &#124;'
  id: totrans-1204
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 带注意力机制 &#124;'
- en: '&#124; for End-to-end [[61](#bib.bib61)], &#124;'
  id: totrans-1205
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 端到端 [[61](#bib.bib61)], &#124;'
- en: '&#124; 2021 &#124;'
  id: totrans-1206
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2021 &#124;'
- en: '| CARLA |'
  id: totrans-1207
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Monocular RGB, &#124;'
  id: totrans-1208
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 单目 RGB, &#124;'
- en: '&#124; velocity &#124;'
  id: totrans-1209
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 速度 &#124;'
- en: '|'
  id: totrans-1210
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Steering, &#124;'
  id: totrans-1211
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向, &#124;'
- en: '&#124; throttle and &#124;'
  id: totrans-1212
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 油门和 &#124;'
- en: '&#124; brake &#124;'
  id: totrans-1213
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刹车 &#124;'
- en: '|'
  id: totrans-1214
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Conditional &#124;'
  id: totrans-1215
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 条件式 &#124;'
- en: '&#124; imitation learning, &#124;'
  id: totrans-1216
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿学习, &#124;'
- en: '&#124; multitask learning &#124;'
  id: totrans-1217
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 多任务学习 &#124;'
- en: '|'
  id: totrans-1218
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA NoCrash , &#124;'
  id: totrans-1219
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA NoCrash, &#124;'
- en: '&#124; CoRL2017 &#124;'
  id: totrans-1220
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CoRL2017 &#124;'
- en: '&#124; benchmark &#124;'
  id: totrans-1221
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基准 &#124;'
- en: '| - | - |'
  id: totrans-1222
  prefs: []
  type: TYPE_TB
  zh: '| - | - |'
- en: '&#124; Straight :99 $\pm$ 1 &#124;'
  id: totrans-1223
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 直线：99 $\pm$ 1 &#124;'
- en: '&#124; One Turn: 99 $\pm$ 1 &#124;'
  id: totrans-1224
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 一次转弯：99 $\pm$ 1 &#124;'
- en: '&#124; NC-E: 81$\pm$ 11 &#124;'
  id: totrans-1225
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-E: 81$\pm$ 11 &#124;'
- en: '&#124; NC-R :67 $\pm$ 9 &#124;'
  id: totrans-1226
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-R :67 $\pm$ 9 &#124;'
- en: '&#124; NC-D:23 $\pm$ 5 &#124;'
  id: totrans-1227
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-D:23 $\pm$ 5 &#124;'
- en: '|'
  id: totrans-1228
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: Town01 &#124;'
  id: totrans-1229
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：Town01 &#124;'
- en: '&#124; (466,000 frames) &#124;'
  id: totrans-1230
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; （466,000 帧）&#124;'
- en: '&#124; Test: Town02 &#124;'
  id: totrans-1231
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：Town02 &#124;'
- en: '|'
  id: totrans-1232
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1233
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; End-to-End Model- &#124;'
  id: totrans-1234
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 端到端模型- &#124;'
- en: '&#124; Free Reinforcement [[53](#bib.bib53)], &#124;'
  id: totrans-1235
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 自由强化学习 [[53](#bib.bib53)], &#124;'
- en: '&#124; 2020 &#124;'
  id: totrans-1236
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2020 &#124;'
- en: '| CARLA |'
  id: totrans-1237
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Front-facing &#124;'
  id: totrans-1238
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 前向摄像头 &#124;'
- en: '&#124; camera , &#124;'
  id: totrans-1239
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 相机, &#124;'
- en: '&#124; speed &#124;'
  id: totrans-1240
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 速度 &#124;'
- en: '|'
  id: totrans-1241
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; 5 steer actions, &#124;'
  id: totrans-1242
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 5 个转向动作, &#124;'
- en: '&#124; 3 values for &#124;'
  id: totrans-1243
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 3 个值用于 &#124;'
- en: '&#124; throttle, &#124;'
  id: totrans-1244
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 油门, &#124;'
- en: '&#124; one for brake &#124;'
  id: totrans-1245
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刹车 &#124;'
- en: '|'
  id: totrans-1246
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Reinforcement &#124;'
  id: totrans-1247
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 强化学习 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-1248
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-1249
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-1250
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; NoCrash, &#124;'
  id: totrans-1251
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NoCrash, &#124;'
- en: '&#124; LeaderBoard &#124;'
  id: totrans-1252
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LeaderBoard &#124;'
- en: '|'
  id: totrans-1253
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Coin implicit &#124;'
  id: totrans-1254
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 隐式奖赏 &#124;'
- en: '&#124; affordances &#124;'
  id: totrans-1255
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可用性 &#124;'
- en: '| - |'
  id: totrans-1256
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '&#124; NC-R: 96 &#124;'
  id: totrans-1257
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-R: 96 &#124;'
- en: '&#124; NC-D:70 &#124;'
  id: totrans-1258
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-D:70 &#124;'
- en: '&#124; NC-E: 100 &#124;'
  id: totrans-1259
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-E: 100 &#124;'
- en: '|'
  id: totrans-1260
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 20M &#124;'
  id: totrans-1261
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 20M &#124;'
- en: '&#124; iterations Town05 &#124;'
  id: totrans-1262
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 迭代 Town05 &#124;'
- en: '&#124; Test: Town02 &#124;'
  id: totrans-1263
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: Town02 &#124;'
- en: '|'
  id: totrans-1264
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1265
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Learning by &#124;'
  id: totrans-1266
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习通过 &#124;'
- en: '&#124; cheating [[48](#bib.bib48)], &#124;'
  id: totrans-1267
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 作弊 [[48](#bib.bib48)], &#124;'
- en: '&#124; 2020 &#124;'
  id: totrans-1268
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2020 &#124;'
- en: '| CARLA |'
  id: totrans-1269
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Front-facing &#124;'
  id: totrans-1270
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 前向摄像头 &#124;'
- en: '&#124; camera , speed, &#124;'
  id: totrans-1271
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 相机, 速度, &#124;'
- en: '&#124; navigation &#124;'
  id: totrans-1272
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 导航 &#124;'
- en: '&#124; command &#124;'
  id: totrans-1273
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 命令 &#124;'
- en: '|'
  id: totrans-1274
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Steering, &#124;'
  id: totrans-1275
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向, &#124;'
- en: '&#124; throttle and &#124;'
  id: totrans-1276
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 油门和 &#124;'
- en: '&#124; brake &#124;'
  id: totrans-1277
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刹车 &#124;'
- en: '|'
  id: totrans-1278
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; On-policy &#124;'
  id: totrans-1279
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在线策略 &#124;'
- en: '&#124; imitation &#124;'
  id: totrans-1280
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-1281
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-1282
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-1283
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; NoCrash &#124;'
  id: totrans-1284
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NoCrash &#124;'
- en: '&#124; and &#124;'
  id: totrans-1285
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和 &#124;'
- en: '&#124; LeaderBoard &#124;'
  id: totrans-1286
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LeaderBoard &#124;'
- en: '| Map representation |'
  id: totrans-1287
  prefs: []
  type: TYPE_TB
  zh: '| 地图表示 |'
- en: '&#124; Conduct a &#124;'
  id: totrans-1288
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 进行一个 &#124;'
- en: '&#124; separate &#124;'
  id: totrans-1289
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 分离 &#124;'
- en: '&#124; infraction analysis &#124;'
  id: totrans-1290
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 违规分析 &#124;'
- en: '|'
  id: totrans-1291
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NC-E: 100 &#124;'
  id: totrans-1292
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-E: 100 &#124;'
- en: '&#124; NC-R: 94$\pm$4 &#124;'
  id: totrans-1293
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-R: 94$\pm$4 &#124;'
- en: '&#124; NC-D: 85$\pm$1 &#124;'
  id: totrans-1294
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-D: 85$\pm$1 &#124;'
- en: '|'
  id: totrans-1295
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DAgger training. &#124;'
  id: totrans-1296
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DAgger 训练. &#124;'
- en: '&#124; Train: 157K frames, &#124;'
  id: totrans-1297
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 157K 帧, &#124;'
- en: '&#124; 4 hours driving Town1, &#124;'
  id: totrans-1298
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 4 小时驾驶 Town1, &#124;'
- en: '&#124; Test: Town2 &#124;'
  id: totrans-1299
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: Town2 &#124;'
- en: '|'
  id: totrans-1300
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1301
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Learning Situational &#124;'
  id: totrans-1302
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习情境 &#124;'
- en: '&#124; Driving [[49](#bib.bib49)], &#124;'
  id: totrans-1303
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 驾驶 [[49](#bib.bib49)], &#124;'
- en: '&#124; 2020 &#124;'
  id: totrans-1304
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2020 &#124;'
- en: '| CARLA |'
  id: totrans-1305
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Front-facing camera , &#124;'
  id: totrans-1306
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 前向摄像头, &#124;'
- en: '&#124; speed, navigation &#124;'
  id: totrans-1307
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 速度, 导航 &#124;'
- en: '&#124; command &#124;'
  id: totrans-1308
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 命令 &#124;'
- en: '|'
  id: totrans-1309
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Longitudinal &#124;'
  id: totrans-1310
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 纵向 &#124;'
- en: '&#124; and lateral &#124;'
  id: totrans-1311
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和横向 &#124;'
- en: '&#124; control values &#124;'
  id: totrans-1312
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 控制值 &#124;'
- en: '|'
  id: totrans-1313
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Behaviour &#124;'
  id: totrans-1314
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 行为 &#124;'
- en: '&#124; cloning &#124;'
  id: totrans-1315
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 克隆 &#124;'
- en: '|'
  id: totrans-1316
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-1317
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; NoCrash, &#124;'
  id: totrans-1318
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NoCrash, &#124;'
- en: '&#124; LeaderBoard &#124;'
  id: totrans-1319
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LeaderBoard &#124;'
- en: '|'
  id: totrans-1320
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Situation-specific &#124;'
  id: totrans-1321
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 情境特定 &#124;'
- en: '&#124; predictions can be &#124;'
  id: totrans-1322
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 预测可以是 &#124;'
- en: '&#124; inspected &#124;'
  id: totrans-1323
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检查 &#124;'
- en: '&#124; at test time &#124;'
  id: totrans-1324
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在测试时 &#124;'
- en: '|'
  id: totrans-1325
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Learned agent to adhere &#124;'
  id: totrans-1326
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习代理以遵守 &#124;'
- en: '&#124; to traffic rules and &#124;'
  id: totrans-1327
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对交通规则的 &#124;'
- en: '&#124; safety &#124;'
  id: totrans-1328
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全 &#124;'
- en: '|'
  id: totrans-1329
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NC-R: 64 &#124;'
  id: totrans-1330
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-R: 64 &#124;'
- en: '&#124; NC-D: 32 &#124;'
  id: totrans-1331
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-D: 32 &#124;'
- en: '|'
  id: totrans-1332
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: Town1 &#124;'
  id: totrans-1333
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: Town1 &#124;'
- en: '&#124; Test: Town2 &#124;'
  id: totrans-1334
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: Town2 &#124;'
- en: '|'
  id: totrans-1335
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1336
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; SAM [[50](#bib.bib50)], &#124;'
  id: totrans-1337
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SAM [[50](#bib.bib50)], &#124;'
- en: '&#124; 2020 &#124;'
  id: totrans-1338
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2020 &#124;'
- en: '| CARLA |'
  id: totrans-1339
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Image, &#124;'
  id: totrans-1340
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 图像, &#124;'
- en: '&#124; self-speed, &#124;'
  id: totrans-1341
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 自速, &#124;'
- en: '&#124; turning command &#124;'
  id: totrans-1342
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向命令 &#124;'
- en: '|'
  id: totrans-1343
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Brake, &#124;'
  id: totrans-1344
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刹车, &#124;'
- en: '&#124; gas, and &#124;'
  id: totrans-1345
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 油门, 和 &#124;'
- en: '&#124; steering angle &#124;'
  id: totrans-1346
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向角度 &#124;'
- en: '|'
  id: totrans-1347
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Conditional &#124;'
  id: totrans-1348
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 条件 &#124;'
- en: '&#124; imitation &#124;'
  id: totrans-1349
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-1350
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-1351
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Traffic-school &#124;'
  id: totrans-1352
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 交通学校 &#124;'
- en: '&#124; benchmark, &#124;'
  id: totrans-1353
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基准, &#124;'
- en: '&#124; CARLA NoCrash &#124;'
  id: totrans-1354
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA NoCrash &#124;'
- en: '| - |'
  id: totrans-1355
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '&#124; Stop intentions help &#124;'
  id: totrans-1356
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 停车意图有助于 &#124;'
- en: '&#124; avoid &#124;'
  id: totrans-1357
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 避免 &#124;'
- en: '&#124; hazardous traffic &#124;'
  id: totrans-1358
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 危险交通 &#124;'
- en: '&#124; situations &#124;'
  id: totrans-1359
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 情境 &#124;'
- en: '|'
  id: totrans-1360
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NC-E: 83$\pm$1 &#124;'
  id: totrans-1361
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-E: 83$\pm$1 &#124;'
- en: '&#124; NC-R: 68$\pm$7 &#124;'
  id: totrans-1362
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-R: 68$\pm$7 &#124;'
- en: '&#124; NC-D: 29$\pm$2 &#124;'
  id: totrans-1363
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-D: 29$\pm$2 &#124;'
- en: '|'
  id: totrans-1364
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train : 10 hours &#124;'
  id: totrans-1365
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 10 小时 &#124;'
- en: '&#124; (360K frames) Town01. &#124;'
  id: totrans-1366
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (360K 帧) Town01. &#124;'
- en: '|'
  id: totrans-1367
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1368
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Multi-task Learning with &#124;'
  id: totrans-1369
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 多任务学习与 &#124;'
- en: '&#124; Future States &#124;'
  id: totrans-1370
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未来状态 &#124;'
- en: '&#124; for Vision [[86](#bib.bib86)], &#124;'
  id: totrans-1371
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对视觉 [[86](#bib.bib86)], &#124;'
- en: '&#124; 2020 &#124;'
  id: totrans-1372
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2020 &#124;'
- en: '| CARLA |'
  id: totrans-1373
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Three RGB &#124;'
  id: totrans-1374
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 三个 RGB &#124;'
- en: '&#124; cameras &#124;'
  id: totrans-1375
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 摄像头 &#124;'
- en: '| Control signal |'
  id: totrans-1376
  prefs: []
  type: TYPE_TB
  zh: '| 控制信号 |'
- en: '&#124; Multi-task learning, &#124;'
  id: totrans-1377
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 多任务学习, &#124;'
- en: '&#124; conditional &#124;'
  id: totrans-1378
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 条件性 &#124;'
- en: '&#124; imitation learning &#124;'
  id: totrans-1379
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿学习 &#124;'
- en: '|'
  id: totrans-1380
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NoCrash, &#124;'
  id: totrans-1381
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NoCrash, &#124;'
- en: '&#124; AnyWeather &#124;'
  id: totrans-1382
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; AnyWeather &#124;'
- en: '| - |'
  id: totrans-1383
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '&#124; Localization tasks is &#124;'
  id: totrans-1384
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 定位任务是 &#124;'
- en: '&#124; useful for safe &#124;'
  id: totrans-1385
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对安全有用的 &#124;'
- en: '&#124; driving. &#124;'
  id: totrans-1386
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 驾驶。 &#124;'
- en: '|'
  id: totrans-1387
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NC-E: 92, &#124;'
  id: totrans-1388
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-E: 92, &#124;'
- en: '&#124; NC-R 66, &#124;'
  id: totrans-1389
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-R 66, &#124;'
- en: '&#124; NC-D: 32, &#124;'
  id: totrans-1390
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-D: 32, &#124;'
- en: '&#124; SR: 93.2 &#124;'
  id: totrans-1391
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SR: 93.2 &#124;'
- en: '| Train: 100 hours |'
  id: totrans-1392
  prefs: []
  type: TYPE_TB
  zh: '| 训练: 100 小时 |'
- en: '|'
  id: totrans-1393
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DSDNet [[65](#bib.bib65)], &#124;'
  id: totrans-1394
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DSDNet [[65](#bib.bib65)], &#124;'
- en: '&#124; 2020 &#124;'
  id: totrans-1395
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2020 &#124;'
- en: '|'
  id: totrans-1396
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NuScenes, &#124;'
  id: totrans-1397
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NuScenes, &#124;'
- en: '&#124; ATG4D, &#124;'
  id: totrans-1398
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ATG4D, &#124;'
- en: '&#124; CARLA &#124;'
  id: totrans-1399
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '|'
  id: totrans-1400
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; LiDAR, &#124;'
  id: totrans-1401
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LiDAR, &#124;'
- en: '&#124; HD map &#124;'
  id: totrans-1402
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; HD 地图 &#124;'
- en: '| Steering, speed |'
  id: totrans-1403
  prefs: []
  type: TYPE_TB
  zh: '| 转向，速度 |'
- en: '&#124; Imitation &#124;'
  id: totrans-1404
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-1405
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-1406
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CR, L2, &#124;'
  id: totrans-1407
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CR, L2, &#124;'
- en: '&#124; CARLA &#124;'
  id: totrans-1408
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '|'
  id: totrans-1409
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Learn interpretable &#124;'
  id: totrans-1410
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习可解释的 &#124;'
- en: '&#124; intermediate &#124;'
  id: totrans-1411
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 中级 &#124;'
- en: '&#124; results &#124;'
  id: totrans-1412
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 结果 &#124;'
- en: '|'
  id: totrans-1413
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Safer planning by &#124;'
  id: totrans-1414
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过 &#124;'
- en: '&#124; cost function &#124;'
  id: totrans-1415
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 成本函数 &#124;'
- en: '|'
  id: totrans-1416
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; L2: 1.22, &#124;'
  id: totrans-1417
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; L2: 1.22, &#124;'
- en: '&#124; Lane vio: 1.55 &#124;'
  id: totrans-1418
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 车道违规: 1.55 &#124;'
- en: '&#124; IOU: 55.4 &#124;'
  id: totrans-1419
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IOU: 55.4 &#124;'
- en: '&#124; Min MSD: 0.213 &#124;'
  id: totrans-1420
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 最小 MSD: 0.213 &#124;'
- en: '|'
  id: totrans-1421
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 60K, 1000, 5000 samples &#124;'
  id: totrans-1422
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 60K, 1000, 5000 样本 &#124;'
- en: '&#124; Test: 17K, 500 samples &#124;'
  id: totrans-1423
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: 17K, 500 样本 &#124;'
- en: '|'
  id: totrans-1424
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1425
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Perceive, Predict, and &#124;'
  id: totrans-1426
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 感知、预测，并 &#124;'
- en: '&#124; Plan: Safe Motion [[90](#bib.bib90)], &#124;'
  id: totrans-1427
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 计划: 安全运动 [[90](#bib.bib90)], &#124;'
- en: '&#124; 2020 &#124;'
  id: totrans-1428
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2020 &#124;'
- en: '| Real scenario |  &#124; Raw sensor data, &#124; &#124; HD map, &#124;'
  id: totrans-1429
  prefs: []
  type: TYPE_NORMAL
  zh: '| 真实场景 |  &#124; 原始传感器数据, &#124; &#124; HD 地图, &#124;'
- en: '&#124; high level route &#124;  | Control action |'
  id: totrans-1430
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 高级路线 &#124;  | 控制动作 |'
- en: '&#124; Imitation learning, &#124;'
  id: totrans-1431
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿学习， &#124;'
- en: '&#124; inverse RL &#124;'
  id: totrans-1432
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 逆向强化学习 &#124;'
- en: '|'
  id: totrans-1433
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; L2, CR, &#124;'
  id: totrans-1434
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; L2, CR, &#124;'
- en: '&#124; jerk and &#124;'
  id: totrans-1435
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刹车和 &#124;'
- en: '&#124; lateral acceleration &#124;'
  id: totrans-1436
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 侧向加速度 &#124;'
- en: '|'
  id: totrans-1437
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Interpretable &#124;'
  id: totrans-1438
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可解释的 &#124;'
- en: '&#124; Semantic &#124;'
  id: totrans-1439
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 语义 &#124;'
- en: '&#124; Representations &#124;'
  id: totrans-1440
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 表示 &#124;'
- en: '&#124; (occupancy map) &#124;'
  id: totrans-1441
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; （占用图） &#124;'
- en: '|'
  id: totrans-1442
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Planner learn &#124;'
  id: totrans-1443
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 规划器学习 &#124;'
- en: '&#124; safety cost, &#124;'
  id: totrans-1444
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全成本， &#124;'
- en: '&#124; safety buffer &#124;'
  id: totrans-1445
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全缓冲区 &#124;'
- en: '|'
  id: totrans-1446
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CR: 1.78 &#124;'
  id: totrans-1447
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CR: 1.78 &#124;'
- en: '&#124; L2:3.34 &#124;'
  id: totrans-1448
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; L2:3.34 &#124;'
- en: '&#124; Jerk: 1.27 &#124;'
  id: totrans-1449
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刹车: 1.27 &#124;'
- en: '&#124; Lat. acc: 2.89 &#124;'
  id: totrans-1450
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 经度加速度: 2.89 &#124;'
- en: '|'
  id: totrans-1451
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 6100 scenarios &#124;'
  id: totrans-1452
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 6100 个场景 &#124;'
- en: '&#124; Test: 1500 scenarios. &#124;'
  id: totrans-1453
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: 1500 个场景。 &#124;'
- en: '|'
  id: totrans-1454
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1455
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Urban driving &#124;'
  id: totrans-1456
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 城市驾驶 &#124;'
- en: '&#124; with condition &#124;'
  id: totrans-1457
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 带条件的 &#124;'
- en: '&#124; imitation learning [[24](#bib.bib24)], &#124;'
  id: totrans-1458
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿学习 [[24](#bib.bib24)], &#124;'
- en: '&#124; 2020 &#124;'
  id: totrans-1459
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2020 &#124;'
- en: '| Real scenario |'
  id: totrans-1460
  prefs: []
  type: TYPE_TB
  zh: '| 真实场景 |'
- en: '&#124; Camera , &#124;'
  id: totrans-1461
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 相机 , &#124;'
- en: '&#124; navigation &#124;'
  id: totrans-1462
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 导航 &#124;'
- en: '&#124; command &#124;'
  id: totrans-1463
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 命令 &#124;'
- en: '| Steering, speed |'
  id: totrans-1464
  prefs: []
  type: TYPE_TB
  zh: '| 转向，速度 |'
- en: '&#124; Imitation &#124;'
  id: totrans-1465
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-1466
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-1467
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Successful turns, &#124;'
  id: totrans-1468
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 成功的转弯， &#124;'
- en: '&#124; CR,TV &#124;'
  id: totrans-1469
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CR,TV &#124;'
- en: '|'
  id: totrans-1470
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Using pre trained &#124;'
  id: totrans-1471
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 使用预训练的 &#124;'
- en: '&#124; perception &#124;'
  id: totrans-1472
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 感知 &#124;'
- en: '| Safety-driver in loop | MAE: 0.0715 |'
  id: totrans-1473
  prefs: []
  type: TYPE_TB
  zh: '| 安全驾驶员循环 | MAE: 0.0715 |'
- en: '&#124; Train: 30h &#124;'
  id: totrans-1474
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 30h &#124;'
- en: '&#124; Test: 26 routes &#124;'
  id: totrans-1475
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: 26 条路线 &#124;'
- en: '|'
  id: totrans-1476
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1477
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Exploring the &#124;'
  id: totrans-1478
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 探索 &#124;'
- en: '&#124; Limitations of Behavior [[23](#bib.bib23)], &#124;'
  id: totrans-1479
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 行为的局限性 [[23](#bib.bib23)], &#124;'
- en: '&#124; 2019 &#124;'
  id: totrans-1480
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2019 &#124;'
- en: '| CARLA |'
  id: totrans-1481
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Image, &#124;'
  id: totrans-1482
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 图像， &#124;'
- en: '&#124; self-speed, &#124;'
  id: totrans-1483
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 自速度， &#124;'
- en: '&#124; turning command &#124;'
  id: totrans-1484
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向命令 &#124;'
- en: '|'
  id: totrans-1485
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Waypoints, &#124;'
  id: totrans-1486
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 路径点， &#124;'
- en: '&#124; steer, throttle, &#124;'
  id: totrans-1487
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向，油门, &#124;'
- en: '&#124; and brake &#124;'
  id: totrans-1488
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和刹车 &#124;'
- en: '|'
  id: totrans-1489
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Behaviour &#124;'
  id: totrans-1490
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 行为 &#124;'
- en: '&#124; cloning &#124;'
  id: totrans-1491
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 克隆 &#124;'
- en: '|'
  id: totrans-1492
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-1493
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; NoCrash, &#124;'
  id: totrans-1494
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NoCrash, &#124;'
- en: '&#124; LeaderBoard &#124;'
  id: totrans-1495
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 排行榜 &#124;'
- en: '| - |'
  id: totrans-1496
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '&#124; Potentially inconsistent &#124;'
  id: totrans-1497
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可能不一致 &#124;'
- en: '&#124; put the &#124;'
  id: totrans-1498
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 放置 &#124;'
- en: '&#124; vehicle back &#124;'
  id: totrans-1499
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 车辆后方 &#124;'
- en: '&#124; to a safe state &#124;'
  id: totrans-1500
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 到安全状态 &#124;'
- en: '|'
  id: totrans-1501
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; NC-E: 90$\pm$2 &#124;'
  id: totrans-1502
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-E: 90$\pm$2 &#124;'
- en: '&#124; NC-R: 56$\pm$2 &#124;'
  id: totrans-1503
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-R: 56$\pm$2 &#124;'
- en: '&#124; NC-D: 24$\pm$8 &#124;'
  id: totrans-1504
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; NC-D: 24$\pm$8 &#124;'
- en: '|'
  id: totrans-1505
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 100 hours dataset &#124;'
  id: totrans-1506
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练: 100 小时数据集 &#124;'
- en: '&#124; Test: 80 hours dataset &#124;'
  id: totrans-1507
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试: 80 小时数据集 &#124;'
- en: '|'
  id: totrans-1508
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1509
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Learning &#124;'
  id: totrans-1510
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '&#124; to drive from &#124;'
  id: totrans-1511
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 从 &#124;'
- en: '&#124; from simulation without [[114](#bib.bib114)], &#124;'
  id: totrans-1512
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 从仿真中 [[114](#bib.bib114)], &#124;'
- en: '&#124; 2019 &#124;'
  id: totrans-1513
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2019 &#124;'
- en: '|'
  id: totrans-1514
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Simulation &#124;'
  id: totrans-1515
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 仿真 &#124;'
- en: '&#124; + Real &#124;'
  id: totrans-1516
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 实际 &#124;'
- en: '&#124; scenario &#124;'
  id: totrans-1517
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 场景 &#124;'
- en: '|'
  id: totrans-1518
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Single frontal &#124;'
  id: totrans-1519
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 单一前视 &#124;'
- en: '&#124; camera &#124;'
  id: totrans-1520
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 相机 &#124;'
- en: '| Steering |'
  id: totrans-1521
  prefs: []
  type: TYPE_TB
  zh: '| 转向 |'
- en: '&#124; Imitation &#124;'
  id: totrans-1522
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-1523
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-1524
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Average distance &#124;'
  id: totrans-1525
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均距离 &#124;'
- en: '&#124; per intervention &#124;'
  id: totrans-1526
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 每次干预 &#124;'
- en: '|'
  id: totrans-1527
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Bi-directional &#124;'
  id: totrans-1528
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 双向 &#124;'
- en: '&#124; image translator &#124;'
  id: totrans-1529
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 图像翻译器 &#124;'
- en: '| - |'
  id: totrans-1530
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '&#124; Sim MAE: 0.017 &#124;'
  id: totrans-1531
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 仿真MAE：0.017 &#124;'
- en: '&#124; Real MAE: 0.081 &#124;'
  id: totrans-1532
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 实际MAE：0.081 &#124;'
- en: '|'
  id: totrans-1533
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train and Test: &#124;'
  id: totrans-1534
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练和测试：&#124;'
- en: '&#124; 60K frames &#124;'
  id: totrans-1535
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 60K帧 &#124;'
- en: '|'
  id: totrans-1536
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1537
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Learning accurate, &#124;'
  id: totrans-1538
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习准确的，&#124;'
- en: '&#124; comfortable &#124;'
  id: totrans-1539
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 舒适的 &#124;'
- en: '&#124; and human-like driving[[115](#bib.bib115)], &#124;'
  id: totrans-1540
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 以及类人的驾驶[[115](#bib.bib115)]，&#124;'
- en: '&#124; 2019 &#124;'
  id: totrans-1541
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2019 &#124;'
- en: '| Real scenario |'
  id: totrans-1542
  prefs: []
  type: TYPE_TB
  zh: '| 实际场景 |'
- en: '&#124; Single frontal &#124;'
  id: totrans-1543
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 单一前视 &#124;'
- en: '&#124; camera &#124;'
  id: totrans-1544
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 相机 &#124;'
- en: '| Steering, speed |'
  id: totrans-1545
  prefs: []
  type: TYPE_TB
  zh: '| 转向，速度 |'
- en: '&#124; Imitation &#124;'
  id: totrans-1546
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-1547
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-1548
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; L1, comfort measure, &#124;'
  id: totrans-1549
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; L1，舒适度测量，&#124;'
- en: '&#124; driving accuracy, &#124;'
  id: totrans-1550
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 驾驶准确性，&#124;'
- en: '&#124; human-likeness &#124;'
  id: totrans-1551
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 类人度 &#124;'
- en: '&#124; score &#124;'
  id: totrans-1552
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 分数 &#124;'
- en: '| HERE map | - |'
  id: totrans-1553
  prefs: []
  type: TYPE_TB
  zh: '| HERE地图 | - |'
- en: '&#124; AS: 7.96 &#124;'
  id: totrans-1554
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; AS：7.96 &#124;'
- en: '&#124; HL: 29.3 &#124;'
  id: totrans-1555
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; HL：29.3 &#124;'
- en: '|'
  id: totrans-1556
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 60h, &#124;'
  id: totrans-1557
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：60小时，&#124;'
- en: '&#124; Test: 10h &#124;'
  id: totrans-1558
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：10小时 &#124;'
- en: '|'
  id: totrans-1559
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1560
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Learning to &#124;'
  id: totrans-1561
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '&#124; drive in a day [[59](#bib.bib59)], &#124;'
  id: totrans-1562
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 一天内驾驶[[59](#bib.bib59)]，&#124;'
- en: '&#124; 2019 &#124;'
  id: totrans-1563
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2019 &#124;'
- en: '|'
  id: totrans-1564
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Real + &#124;'
  id: totrans-1565
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 实际 + &#124;'
- en: '&#124; Unreal Engine 4 &#124;'
  id: totrans-1566
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 虚幻引擎4 &#124;'
- en: '|'
  id: totrans-1567
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Single frontal &#124;'
  id: totrans-1568
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 单一前视 &#124;'
- en: '&#124; camera &#124;'
  id: totrans-1569
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 相机 &#124;'
- en: '|'
  id: totrans-1570
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Steering, &#124;'
  id: totrans-1571
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向，&#124;'
- en: '&#124; throttle and &#124;'
  id: totrans-1572
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 油门和 &#124;'
- en: '&#124; brake &#124;'
  id: totrans-1573
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刹车 &#124;'
- en: '|'
  id: totrans-1574
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Reinforcement &#124;'
  id: totrans-1575
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 强化学习 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-1576
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-1577
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Distance travel &#124;'
  id: totrans-1578
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 距离旅行 &#124;'
- en: '&#124; reward &#124;'
  id: totrans-1579
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 奖励 &#124;'
- en: '| - | Safer reward function |'
  id: totrans-1580
  prefs: []
  type: TYPE_TB
  zh: '| - | 更安全的奖励函数 |'
- en: '&#124; Meter/Disengagement &#124;'
  id: totrans-1581
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 米/脱离 &#124;'
- en: '&#124; (250m): 0 &#124;'
  id: totrans-1582
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (250米)：0 &#124;'
- en: '|'
  id: totrans-1583
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train: 10 episode &#124;'
  id: totrans-1584
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：10集 &#124;'
- en: '&#124; Test : 250 meters &#124;'
  id: totrans-1585
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：250米 &#124;'
- en: '|'
  id: totrans-1586
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1587
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Multimodal &#124;'
  id: totrans-1588
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 多模态 &#124;'
- en: '&#124; end-to-end &#124;'
  id: totrans-1589
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 端到端 &#124;'
- en: '&#124; autonomous driving [[62](#bib.bib62)], &#124;'
  id: totrans-1590
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 自动驾驶 [[62](#bib.bib62)]，&#124;'
- en: '&#124; 2019 &#124;'
  id: totrans-1591
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2019 &#124;'
- en: '| CARLA |'
  id: totrans-1592
  prefs: []
  type: TYPE_TB
  zh: '| CARLA |'
- en: '&#124; Front-facing &#124;'
  id: totrans-1593
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 前视 &#124;'
- en: '&#124; camera and &#124;'
  id: totrans-1594
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 相机和 &#124;'
- en: '&#124; LiDAR &#124;'
  id: totrans-1595
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LiDAR &#124;'
- en: '|'
  id: totrans-1596
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Steering, &#124;'
  id: totrans-1597
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 转向，&#124;'
- en: '&#124; throttle and &#124;'
  id: totrans-1598
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 油门和 &#124;'
- en: '&#124; brake &#124;'
  id: totrans-1599
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刹车 &#124;'
- en: '|'
  id: totrans-1600
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Conditional &#124;'
  id: totrans-1601
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 条件 &#124;'
- en: '&#124; imitation &#124;'
  id: totrans-1602
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-1603
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '| CARLA | - | - | SR: 94 |'
  id: totrans-1604
  prefs: []
  type: TYPE_TB
  zh: '| CARLA | - | - | SR：94 |'
- en: '&#124; Train: 25h &#124;'
  id: totrans-1605
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：25小时 &#124;'
- en: '&#124; Test : Town 1 and 2 &#124;'
  id: totrans-1606
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：城镇1和2 &#124;'
- en: '|'
  id: totrans-1607
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1608
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; End-to-end &#124;'
  id: totrans-1609
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 端到端 &#124;'
- en: '&#124; interpretable neural &#124;'
  id: totrans-1610
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可解释的神经网络 &#124;'
- en: '&#124; motion planner[[81](#bib.bib81)], &#124;'
  id: totrans-1611
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 动作规划器[[81](#bib.bib81)]，&#124;'
- en: '&#124; 2019 &#124;'
  id: totrans-1612
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2019 &#124;'
- en: '| Real scenario |'
  id: totrans-1613
  prefs: []
  type: TYPE_TB
  zh: '| 实际场景 |'
- en: '&#124; Front-facing &#124;'
  id: totrans-1614
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 前视 &#124;'
- en: '&#124; camera , &#124;'
  id: totrans-1615
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 相机，&#124;'
- en: '&#124; speed. &#124;'
  id: totrans-1616
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 速度。 &#124;'
- en: '|'
  id: totrans-1617
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Cost volume, &#124;'
  id: totrans-1618
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 成本体积，&#124;'
- en: '&#124; future trajectories, &#124;'
  id: totrans-1619
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未来轨迹，&#124;'
- en: '&#124; Object location &#124;'
  id: totrans-1620
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 物体位置 &#124;'
- en: '|'
  id: totrans-1621
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Imitation &#124;'
  id: totrans-1622
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模仿 &#124;'
- en: '&#124; learning &#124;'
  id: totrans-1623
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 学习 &#124;'
- en: '|'
  id: totrans-1624
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Collision rate, &#124;'
  id: totrans-1625
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 碰撞率，&#124;'
- en: '&#124; traffic violation rate &#124;'
  id: totrans-1626
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 交通违规率 &#124;'
- en: '|'
  id: totrans-1627
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Interpretable &#124;'
  id: totrans-1628
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可解释的 &#124;'
- en: '&#124; intermediate representations &#124;'
  id: totrans-1629
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 中间表示 &#124;'
- en: '|'
  id: totrans-1630
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Cost volume can &#124;'
  id: totrans-1631
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 成本体积可以 &#124;'
- en: '&#124; generate safer planning &#124;'
  id: totrans-1632
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 生成更安全的规划 &#124;'
- en: '|'
  id: totrans-1633
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; L2(3sec): 2.353 &#124;'
  id: totrans-1634
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; L2(3秒)：2.353 &#124;'
- en: '&#124; Colli rate: 0.78 &#124;'
  id: totrans-1635
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 碰撞率：0.78 &#124;'
- en: '|'
  id: totrans-1636
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Train : 50000 scenarios &#124;'
  id: totrans-1637
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练：50000场景 &#124;'
- en: '&#124; Val: 500 scenarios &#124;'
  id: totrans-1638
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 验证：500场景 &#124;'
- en: '&#124; Test: 1000 scenarios &#124;'
  id: totrans-1639
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试：1000场景 &#124;'
- en: '|'
  id: totrans-1640
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: •
  id: totrans-1641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Route Completion (RC), Infraction Score/penalty (IS), Driving score (DS), Collisions
    pedestrians (CP)/(PC), Collisions vehicles (CV), Collisions layout (CL)/(LC),
    Red light infractions (RLI), Red light violation (RV), Stop sign infractions (SSI),
    Off-road infractions (OI), Route deviations (RD), Agent blocked (AB).
  id: totrans-1642
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 路线完成（RC），违规/罚分（IS），驾驶评分（DS），碰撞行人（CP）/（PC），碰撞车辆（CV），碰撞布局（CL）/（LC），红灯违规（RLI），红灯违章（RV），停车标志违规（SSI），越野违规（OI），路线偏差（RD），代理阻塞（AB）。
- en: •
  id: totrans-1643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Average Displacement Error (ADE), Final Displacement Error (FDE), Intersection
    over Union (IOU), Panoptic Quality (PQ), Recognition Quality (RQ), Segmentation
    Quality (SQ), Instance Contrastive Pair (ICP), Action Contrastive Pair (ACP),
    Driving in Occlusion Simulation (DOS), Episodic Cost (EC), Success Rate (SR).
  id: totrans-1644
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平均位移误差（ADE），最终位移误差（FDE），交并比（IOU），全景质量（PQ），识别质量（RQ），分割质量（SQ），实例对比对（ICP），动作对比对（ACP），遮挡模拟驾驶（DOS），阶段成本（EC），成功率（SR）。
- en: •
  id: totrans-1645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Collision Rate (CR), Safety Violation (SV), Episodic Return (ER), Episodic Cost
    (EC), Vehicle Avoidance (VA), Pedestrian Avoidance (PA), Meters Per Intervention(MPI),
    Reinforcement Learning (RL), Imitation Learning (IL), NoCrash Regular Traffic
    (NC-R), NoCrash Dense Traffic (NC-D), NoCrash Empty (NC-E) .
  id: totrans-1646
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 碰撞率（CR），安全违规（SV），阶段回报（ER），阶段成本（EC），车辆避让（VA），行人避让（PA），每次干预的米数（MPI），强化学习（RL），模仿学习（IL），无碰撞常规交通（NC-R），无碰撞密集交通（NC-D），无碰撞空旷（NC-E）。
- en: augments real point clouds with artificial obstacles by blending them appropriately
    into the surroundings. Regarding planning and decision disparity, Pan et al. [[116](#bib.bib116)]
    propose learning driving policies in a simulated setting with realistic frames
    before applying them in the real world. Osinski et al. [[117](#bib.bib117)] propose
    a driving policy using a simulator, where a segmentation network is developed
    using annotated real-world data, while the driving controller is learned using
    synthetic images and their semantics. Mitchell et al. [[118](#bib.bib118)] and
    Stocco et al. [[119](#bib.bib119)] enable robust online policy learning adaptation
    through a mixed-reality arrangement, which includes an actual vehicle and other
    virtual cars and obstacles, allowing the real car to learn from simulated collisions
    and test scenarios.
  id: totrans-1647
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将真实点云与人工障碍物混合并适当地融入周围环境来增强真实点云。关于规划和决策差异，Pan等人[[116](#bib.bib116)] 提出在模拟环境中学习驾驶策略，然后将其应用于现实世界。Osinski等人[[117](#bib.bib117)]
    提出了使用模拟器的驾驶策略，其中通过注释的真实数据开发了分割网络，而驾驶控制器则使用合成图像及其语义进行学习。Mitchell等人[[118](#bib.bib118)]
    和Stocco等人[[119](#bib.bib119)] 通过混合现实安排实现了强大的在线策略学习适应，其中包括一辆实际车辆和其他虚拟车辆及障碍物，使得真实车辆可以从模拟碰撞和测试场景中学习。
- en: '| ![Refer to caption](img/7e482e7104608cf902e9dda39219152b.png) |'
  id: totrans-1648
  prefs: []
  type: TYPE_TB
  zh: '| ![参见说明](img/7e482e7104608cf902e9dda39219152b.png) |'
- en: '| (a) InterFuser |'
  id: totrans-1649
  prefs: []
  type: TYPE_TB
  zh: '| (a) InterFuser |'
- en: '| ![Refer to caption](img/2c722b6cf4caad6a3014c8f939ed3035.png) |'
  id: totrans-1650
  prefs: []
  type: TYPE_TB
  zh: '| ![参见说明](img/2c722b6cf4caad6a3014c8f939ed3035.png) |'
- en: '| (b) KING Lane Merger Scenario |'
  id: totrans-1651
  prefs: []
  type: TYPE_TB
  zh: '| (b) KING车道合并场景 |'
- en: '| ![Refer to caption](img/ca697c32435f144ff38b060d49603eb3.png) |'
  id: totrans-1652
  prefs: []
  type: TYPE_TB
  zh: '| ![参见说明](img/ca697c32435f144ff38b060d49603eb3.png) |'
- en: '| (c) KING Collision Avoidance |'
  id: totrans-1653
  prefs: []
  type: TYPE_TB
  zh: '| (c) KING碰撞避免 |'
- en: 'Figure 10: Demonstration of safe driving methods: (a) InterFuser [[8](#bib.bib8)]
    processes multisensorial information to detect adversarial events, which are then
    used by the controller to constrain driving actions within safe sets. (b) KING
    [[6](#bib.bib6)] improves collision avoidance using scenario generation. The image
    shows the ego vehicle (shown in red) maintaining a safe distance during a lane
    merge in the presence of an adversarial agent (shown in blue). (c) In the same
    context, the image illustrates the vehicle slowing down to avoid collision.'
  id: totrans-1654
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：安全驾驶方法的演示：（a）InterFuser [[8](#bib.bib8)] 处理多传感器信息以检测对抗事件，然后由控制器使用这些信息将驾驶行为限制在安全集合中。（b）KING
    [[6](#bib.bib6)] 通过场景生成改进碰撞避免。图像显示了在对抗代理（显示为蓝色）存在的情况下，自车（显示为红色）在车道合并过程中保持安全距离。（c）在相同背景下，图像展示了车辆减速以避免碰撞。
- en: 8 Safety
  id: totrans-1655
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 安全
- en: 'Table 4: END-TO-END DRIVING TESTING TO ENSURE SAFETY'
  id: totrans-1656
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：端到端驾驶测试以确保安全
- en: '| Methods | Summary | Literature |'
  id: totrans-1657
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 总结 | 文献 |'
- en: '|  |'
  id: totrans-1658
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '&#124; Generating neuron coverage to &#124;'
  id: totrans-1659
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 生成神经元覆盖率以&#124;'
- en: '&#124; identify false actions &#124;'
  id: totrans-1660
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 识别错误动作&#124;'
- en: '| [[120](#bib.bib120)] |'
  id: totrans-1661
  prefs: []
  type: TYPE_TB
  zh: '| [[120](#bib.bib120)] |'
- en: '|  |'
  id: totrans-1662
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '&#124; Designing an diverse and critical &#124;'
  id: totrans-1663
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 设计多样化和关键的&#124;'
- en: '&#124; unsafe test cases &#124;'
  id: totrans-1664
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 不安全测试案例&#124;'
- en: '| [[6](#bib.bib6)] |'
  id: totrans-1665
  prefs: []
  type: TYPE_TB
  zh: '| [[6](#bib.bib6)] |'
- en: '| Search-based testing |'
  id: totrans-1666
  prefs: []
  type: TYPE_TB
  zh: '| 基于搜索的测试 |'
- en: '&#124; Objective function to search safety &#124;'
  id: totrans-1667
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 目标函数以搜索安全 &#124;'
- en: '&#124; sensitive output &#124;'
  id: totrans-1668
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 敏感输出 &#124;'
- en: '| [[84](#bib.bib84)] |'
  id: totrans-1669
  prefs: []
  type: TYPE_TB
  zh: '| [[84](#bib.bib84)] |'
- en: '|  |'
  id: totrans-1670
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '&#124; Place the original object with an &#124;'
  id: totrans-1671
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 用 &#124; 的原始物体'
- en: '&#124; adversarial one &#124;'
  id: totrans-1672
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性的一种 &#124;'
- en: '| [[103](#bib.bib103)] |'
  id: totrans-1673
  prefs: []
  type: TYPE_TB
  zh: '| [[103](#bib.bib103)] |'
- en: '| Optimization- based attack |'
  id: totrans-1674
  prefs: []
  type: TYPE_TB
  zh: '| 基于优化的攻击 |'
- en: '&#124; Virtual obstacles to generate &#124;'
  id: totrans-1675
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 生成虚拟障碍物 &#124;'
- en: '&#124; adversarial attack in natural environment &#124;'
  id: totrans-1676
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 自然环境中的对抗攻击 &#124;'
- en: '| [[22](#bib.bib22)] |'
  id: totrans-1677
  prefs: []
  type: TYPE_TB
  zh: '| [[22](#bib.bib22)] |'
- en: '|  |'
  id: totrans-1678
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '&#124; Generate the adversarial realistic-looking &#124;'
  id: totrans-1679
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 生成对抗性逼真的 &#124;'
- en: '&#124; representations based on images &#124;'
  id: totrans-1680
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于图像的表示 &#124;'
- en: '| [[121](#bib.bib121)] |'
  id: totrans-1681
  prefs: []
  type: TYPE_TB
  zh: '| [[121](#bib.bib121)] |'
- en: '|  |'
  id: totrans-1682
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '&#124; Generate pedestrian augmentation from &#124;'
  id: totrans-1683
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 从 &#124; 生成行人增强数据'
- en: '&#124; inserting pedestrians in image &#124;'
  id: totrans-1684
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在图像中插入行人 &#124;'
- en: '| [[122](#bib.bib122)] |'
  id: totrans-1685
  prefs: []
  type: TYPE_TB
  zh: '| [[122](#bib.bib122)] |'
- en: '| GAN-based attack |'
  id: totrans-1686
  prefs: []
  type: TYPE_TB
  zh: '| 基于 GAN 的攻击 |'
- en: '&#124; Designing an objective function to search &#124;'
  id: totrans-1687
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 设计一个目标函数以搜索 &#124;'
- en: '&#124; for the diverse unsafe test cases &#124;'
  id: totrans-1688
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 针对各种不安全测试案例 &#124;'
- en: '| [[8](#bib.bib8)] |'
  id: totrans-1689
  prefs: []
  type: TYPE_TB
  zh: '| [[8](#bib.bib8)] |'
- en: 'Table 5: END-TO-END TESTING ORACLE MEASURES CORRECT CONTROL DECISION AT DIFFERENT
    SCENARIOS'
  id: totrans-1690
  prefs: []
  type: TYPE_NORMAL
  zh: '表 5: 端到端测试预言机在不同场景下的正确控制决策'
- en: '| Test Oracle | Detail | Literature |'
  id: totrans-1691
  prefs: []
  type: TYPE_TB
  zh: '| 测试预言机 | 详细信息 | 文献 |'
- en: '|'
  id: totrans-1692
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Metamorphic &#124;'
  id: totrans-1693
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 变形 &#124;'
- en: '&#124; testing &#124;'
  id: totrans-1694
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试 &#124;'
- en: '|'
  id: totrans-1695
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; The control signal should not get alter &#124;'
  id: totrans-1696
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 控制信号不应被更改 &#124;'
- en: '&#124; in different condition &#124;'
  id: totrans-1697
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在不同条件下 &#124;'
- en: '| [[6](#bib.bib6)] |'
  id: totrans-1698
  prefs: []
  type: TYPE_TB
  zh: '| [[6](#bib.bib6)] |'
- en: '|'
  id: totrans-1699
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Differential &#124;'
  id: totrans-1700
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 微分 &#124;'
- en: '&#124; testing &#124;'
  id: totrans-1701
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测试 &#124;'
- en: '|'
  id: totrans-1702
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; The End-to-End system must give the same &#124;'
  id: totrans-1703
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 端到端系统必须给出相同的 &#124;'
- en: '&#124; safe control for same scenario &#124;'
  id: totrans-1704
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对于相同场景的安全控制 &#124;'
- en: '| [[50](#bib.bib50)] |'
  id: totrans-1705
  prefs: []
  type: TYPE_TB
  zh: '| [[50](#bib.bib50)] |'
- en: '|'
  id: totrans-1706
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Model-based &#124;'
  id: totrans-1707
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于模型 &#124;'
- en: '&#124; oracle &#124;'
  id: totrans-1708
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 预言机 &#124;'
- en: '|'
  id: totrans-1709
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Predicting the critical scenario that &#124;'
  id: totrans-1710
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 预测 &#124; 的关键场景'
- en: '&#124; cause system failure &#124;'
  id: totrans-1711
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 造成系统故障 &#124;'
- en: '| [[23](#bib.bib23)] |'
  id: totrans-1712
  prefs: []
  type: TYPE_TB
  zh: '| [[23](#bib.bib23)] |'
- en: 'Table 6: POPULAR SAFETY METRICS USED FOR SAFETY EVALUATION OF DRIVING SYSTEM'
  id: totrans-1713
  prefs: []
  type: TYPE_NORMAL
  zh: '表 6: 驾驶系统安全评估中使用的流行安全指标'
- en: '| Classification | Critical Metrics | Literature | Description |'
  id: totrans-1714
  prefs: []
  type: TYPE_TB
  zh: '| 分类 | 关键指标 | 文献 | 描述 |'
- en: '|  | Time to Collision (TTC) | [[123](#bib.bib123)] |'
  id: totrans-1715
  prefs: []
  type: TYPE_TB
  zh: '|  | 碰撞时间 (TTC) | [[123](#bib.bib123)] |'
- en: '&#124; It defines the minimum time interval that the two agents &#124;'
  id: totrans-1716
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 它定义了两个代理 &#124; 的最小时间间隔'
- en: '&#124; will collide &#124;'
  id: totrans-1717
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 将发生碰撞 &#124;'
- en: '|'
  id: totrans-1718
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | Worst Time to Collision (WTTC) | [[124](#bib.bib124)] |'
  id: totrans-1719
  prefs: []
  type: TYPE_TB
  zh: '|  | 最差碰撞时间 (WTTC) | [[124](#bib.bib124)] |'
- en: '&#124; The WTTC metric is an extension of the traditional TTC that &#124;'
  id: totrans-1720
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; WTTC 指标是传统 TTC 的扩展，&#124;'
- en: '&#124; takes numerous traces of actors into consideration &#124;'
  id: totrans-1721
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 考虑到多个演员的痕迹 &#124;'
- en: '|'
  id: totrans-1722
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | Time to Maneuver (TTM) | [[123](#bib.bib123)] |'
  id: totrans-1723
  prefs: []
  type: TYPE_TB
  zh: '|  | 驾驶时间 (TTM) | [[123](#bib.bib123)] |'
- en: '&#124; The TTM yields the latest time in the range [0, TTC] at which an &#124;'
  id: totrans-1724
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; TTM 给出的是范围 [0, TTC] 内的最新时间点，其中 &#124;'
- en: '&#124; expert actor may conduct a movement that avoids a collision &#124;'
  id: totrans-1725
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 专家演员可能会进行避免碰撞的动作 &#124;'
- en: '|'
  id: totrans-1726
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | Time to React (TTR) | [[120](#bib.bib120)] |'
  id: totrans-1727
  prefs: []
  type: TYPE_TB
  zh: '|  | 反应时间 (TTR) | [[120](#bib.bib120)] |'
- en: '&#124; TTR metric provides an approximation of the latest time before a &#124;'
  id: totrans-1728
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; TTR 指标提供对 &#124; 的最新时间的近似'
- en: '&#124; reaction is necessary &#124;'
  id: totrans-1729
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 反应是必要的 &#124;'
- en: '|'
  id: totrans-1730
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Temporal metrics | Time Headway (THW) | [[123](#bib.bib123)] |'
  id: totrans-1731
  prefs: []
  type: TYPE_TB
  zh: '| 时间指标 | 时间间隔 (THW) | [[123](#bib.bib123)] |'
- en: '&#124; The THW measure determines the amount of time it will take an &#124;'
  id: totrans-1732
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; THW 测量确定需要的时间量 &#124;'
- en: '&#124; actor to get to the location of other vehicle &#124;'
  id: totrans-1733
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 演员到达其他车辆的位置 &#124;'
- en: '|'
  id: totrans-1734
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | Deceleration Safety Time (DST) | [[125](#bib.bib125)] |'
  id: totrans-1735
  prefs: []
  type: TYPE_TB
  zh: '|  | 减速度安全时间 (DST) | [[125](#bib.bib125)] |'
- en: '&#124; It calculates the deceleration required to maintain the &#124;'
  id: totrans-1736
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 它计算保持 &#124; 所需的减速度'
- en: '&#124; safe distance &#124;'
  id: totrans-1737
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 安全距离 &#124;'
- en: '|'
  id: totrans-1738
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | Stopping Distance (SD) | [[126](#bib.bib126)] |'
  id: totrans-1739
  prefs: []
  type: TYPE_TB
  zh: '|  | 停车距离 (SD) | [[126](#bib.bib126)] |'
- en: '&#124; Minimum stopping distance at the time of &#124;'
  id: totrans-1740
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在 &#124; 的最小停车距离'
- en: '&#124; deceleration &#124;'
  id: totrans-1741
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 减速度 &#124;'
- en: '|'
  id: totrans-1742
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | Crash Potential Index (CPI) | [[127](#bib.bib127)] |'
  id: totrans-1743
  prefs: []
  type: TYPE_TB
  zh: '|  | 碰撞潜力指数 (CPI) | [[127](#bib.bib127)] |'
- en: '&#124; It measures the probability that the vehicle cannot avoid the &#124;'
  id: totrans-1744
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 测量车辆无法避免 &#124;'
- en: '&#124; collision by deceleration &#124;'
  id: totrans-1745
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过减速度发生碰撞 &#124;'
- en: '|'
  id: totrans-1746
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Non-Temporal metrics | Conflict Index (CI) | [[127](#bib.bib127)] |'
  id: totrans-1747
  prefs: []
  type: TYPE_TB
  zh: '| 非时间度量 | 冲突指数 (CI) | [[127](#bib.bib127)] |'
- en: '&#124; It estimates the collision probability and the severity &#124;'
  id: totrans-1748
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 它估计碰撞概率及其严重性 &#124;'
- en: '&#124; factors &#124;'
  id: totrans-1749
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 因素 &#124;'
- en: '|'
  id: totrans-1750
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'Ensuring safety in End-to-End autonomous driving systems is a complex challenge.
    While these systems offer high-performance potential, several considerations and
    approaches are essential for maintaining safety throughout the pipeline. First,
    training the system with diverse and high-quality data that covers a wide range
    of scenarios, including rare and critical situations. Hanselmann et al. [[6](#bib.bib6)],
    Chen et al. [[10](#bib.bib10)], Chitta et al. [[7](#bib.bib7)], Xiao et al. [[14](#bib.bib14)],
    and Ohn-Bar et al. [[49](#bib.bib49)] demonstrate that training on critical scenarios
    helps the system learn robust and safe behaviors and prepares it for environmental
    conditions and potential hazards. These scenarios include unprotected turnings
    at intersections, pedestrians emerging from occluded regions, aggressive lane-changing,
    and other safety heuristics, as shown in Fig. [10](#S7.F10 "Figure 10 ‣ 7 Learning
    domain adaptation from simulator to real ‣ Recent Advancements in End-to-End Autonomous
    Driving using Deep Learning: A Survey")(b) and Fig. [10](#S7.F10 "Figure 10 ‣
    7 Learning domain adaptation from simulator to real ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")(c). Hanselmann et al. [[6](#bib.bib6)]
    focus on improving robustness by inducing adversarial scenarios (collision scenarios)
    and collecting an observation-waypoint dataset using experts, which is then used
    to fine-tune the policy.'
  id: totrans-1751
  prefs: []
  type: TYPE_NORMAL
  zh: 确保端到端自动驾驶系统的安全是一个复杂的挑战。虽然这些系统提供了高性能的潜力，但在整个流程中保持安全需要多个考虑和方法。首先，需用涵盖广泛场景的数据对系统进行训练，包括稀有和关键情况。Hanselmann
    等人 [[6](#bib.bib6)]、Chen 等人 [[10](#bib.bib10)]、Chitta 等人 [[7](#bib.bib7)]、Xiao
    等人 [[14](#bib.bib14)] 和 Ohn-Bar 等人 [[49](#bib.bib49)] 证明，在关键场景下的训练有助于系统学习稳健和安全的行为，并为环境条件和潜在危险做好准备。这些场景包括交叉口的无保护转弯、从遮挡区域出现的行人、激进的变道和其他安全启发式方法，如图[10](#S7.F10
    "图 10 ‣ 7 从模拟器到现实的领域适应 ‣ 基于深度学习的端到端自动驾驶的最新进展：综述")(b) 和图[10](#S7.F10 "图 10 ‣ 7
    从模拟器到现实的领域适应 ‣ 基于深度学习的端到端自动驾驶的最新进展：综述")(c)所示。Hanselmann 等人 [[6](#bib.bib6)] 通过引入对抗场景（碰撞场景）和使用专家收集观察点数据集，集中于提高鲁棒性，然后用这些数据集来微调策略。
- en: 'Integrating safety constraints and rules into the End-to-End system is another
    vital aspect. The system can prioritize safe behavior by incorporating safety
    considerations during learning or post-processing system outputs. Safety constraints
    include a safety cost function [[80](#bib.bib80), [82](#bib.bib82), [65](#bib.bib65),
    [90](#bib.bib90)], avoiding unsafe maneuvers [[11](#bib.bib11), [19](#bib.bib19)],
    and collision avoidance strategies [[58](#bib.bib58), [13](#bib.bib13), [50](#bib.bib50)].
    Zeng et al. [[84](#bib.bib84)] define the cost volume responsible for safe planning;
    Kendall et al. [[59](#bib.bib59)] propose a practical safety reward function for
    safety-sensitive outputs. Li et al. [[55](#bib.bib55)] and Hu et al. [[20](#bib.bib20)]
    demonstrate safety by utilizing the Safety Cost function that penalizes jerk,
    significant acceleration, and safety violations. To avoid unsafe maneuvers, Zhang
    et al. [[51](#bib.bib51)] eliminate unsafe waypoints, and Shao et al. [[8](#bib.bib8)]
    introduce InterFuser (Fig. [10](#S7.F10 "Figure 10 ‣ 7 Learning domain adaptation
    from simulator to real ‣ Recent Advancements in End-to-End Autonomous Driving
    using Deep Learning: A Survey")(a)), which constrains only the actions within
    the safety set and steers only the safest action. The above constraints ensure
    that the system operates within predefined safety boundaries.'
  id: totrans-1752
  prefs: []
  type: TYPE_NORMAL
  zh: 将安全约束和规则整合到端到端系统中是另一个重要方面。通过在学习过程中或后处理系统输出时纳入安全考虑，系统可以优先考虑安全行为。安全约束包括安全成本函数
    [[80](#bib.bib80), [82](#bib.bib82), [65](#bib.bib65), [90](#bib.bib90)]、避免不安全的操作
    [[11](#bib.bib11), [19](#bib.bib19)] 和碰撞避免策略 [[58](#bib.bib58), [13](#bib.bib13),
    [50](#bib.bib50)]。Zeng 等 [[84](#bib.bib84)] 定义了负责安全规划的成本体积；Kendall 等 [[59](#bib.bib59)]
    提出了一个实用的安全奖励函数，用于安全敏感的输出。Li 等 [[55](#bib.bib55)] 和 Hu 等 [[20](#bib.bib20)] 通过利用安全成本函数来演示安全性，该函数对颠簸、显著加速和安全违规进行惩罚。为了避免不安全的操作，Zhang
    等 [[51](#bib.bib51)] 消除了不安全的路径点，Shao 等 [[8](#bib.bib8)] 引入了 InterFuser（图 [10](#S7.F10
    "图 10 ‣ 7 从模拟器到真实环境的学习领域适应 ‣ 端到端自主驾驶的深度学习近期进展：综述")(a)），该方法仅在安全集合内约束动作，并引导系统选择最安全的动作。上述约束确保系统在预定义的安全边界内运行。
- en: 'Implementing additional safety modules and testing mechanisms (Tables [4](#S8.T4
    "Table 4 ‣ 8 Safety ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey"), [5](#S8.T5 "Table 5 ‣ 8 Safety ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey")) enhances the
    system’s safety. Real-time monitoring of the system’s behavior allows for detecting
    abnormalities or deviations from safe operation. Hu et al. [[9](#bib.bib9)], Renz
    et al. [[18](#bib.bib18)], Wu et al. [[13](#bib.bib13)], and Hawke et al. [[24](#bib.bib24)]
    implement a planner that identifies collision-free routes, reduces possible infractions,
    and compensates for potential failures or inaccuracies. Renz et al. [[18](#bib.bib18)]
    use a rule-based expert algorithm for their planner, while Wu et al. [[13](#bib.bib13)]
    propose a trajectory + control model that predicts a safe trajectory over the
    long horizon. Hu et al. [[9](#bib.bib9)] also employ a goal planner to ensure
    safety. Codevilla et al. [[23](#bib.bib23)] demonstrate the system’s ability to
    respond appropriately and return the vehicle to a safe state when encountering
    potential inconsistencies. Similarly, Zhao et al. [[50](#bib.bib50)] incorporate
    stop intentions to help avoid hazardous traffic situations and respond appropriately.
    These mechanisms ensure that the system can detect and respond to abnormal or
    unexpected situations, thereby reducing the risk of accidents or unsafe behavior.'
  id: totrans-1753
  prefs: []
  type: TYPE_NORMAL
  zh: 实施额外的安全模块和测试机制（表 [4](#S8.T4 "表 4 ‣ 8 安全 ‣ 端到端自主驾驶的深度学习近期进展：综述"), [5](#S8.T5
    "表 5 ‣ 8 安全 ‣ 端到端自主驾驶的深度学习近期进展：综述")）提升了系统的安全性。对系统行为的实时监控可以检测到异常或偏离安全操作的情况。Hu 等
    [[9](#bib.bib9)]、Renz 等 [[18](#bib.bib18)]、Wu 等 [[13](#bib.bib13)] 和 Hawke 等 [[24](#bib.bib24)]
    实施了一个规划器，用于识别无碰撞的路线、减少可能的违规行为，并补偿潜在的故障或不准确性。Renz 等 [[18](#bib.bib18)] 为他们的规划器使用了基于规则的专家算法，而
    Wu 等 [[13](#bib.bib13)] 提出了一个轨迹 + 控制模型，该模型预测了长期的安全轨迹。Hu 等 [[9](#bib.bib9)] 还使用了目标规划器以确保安全。Codevilla
    等 [[23](#bib.bib23)] 演示了系统在遇到潜在不一致时能够适当地响应并将车辆恢复到安全状态的能力。类似地，Zhao 等 [[50](#bib.bib50)]
    纳入了停车意图，以帮助避免危险的交通状况并做出适当响应。这些机制确保系统能够检测和响应异常或意外情况，从而减少事故或不安全行为的风险。
- en: 'Adversarial attack [[22](#bib.bib22)] methods, as shown in the Table [4](#S8.T4
    "Table 4 ‣ 8 Safety ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey"), are utilized in driving testing to evaluate the correctness
    of the output control signal. These testing methodologies aim to identify vulnerabilities
    and assess the robustness against adversaries. The End-to-End testing oracle (Table [5](#S8.T5
    "Table 5 ‣ 8 Safety ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey")) determines the correct control decision within a given
    scenario. Metamorphic testing tackles the oracle problem by verifying the consistency
    of the steering angle [[6](#bib.bib6)] across various weather and lighting conditions.
    It provides a reliable way to ensure that the steering angle remains stable and
    unaffected by these factors. Differential testing [[50](#bib.bib50)] exposes inconsistencies
    among different DNN models by comparing their inference results for the same scenario.
    If the models produce different outcomes, it indicates unexpected behavior and
    potential issues in the system. The model-based oracle employs a trained probabilistic
    model to assess and predict potential risks [[23](#bib.bib23)] in real scenarios.
    By monitoring the environment, it can identify situations that the system may
    not adequately handle.'
  id: totrans-1754
  prefs: []
  type: TYPE_NORMAL
  zh: '对抗攻击[[22](#bib.bib22)]方法，如表[4](#S8.T4 "Table 4 ‣ 8 Safety ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey")所示，在驾驶测试中用于评估输出控制信号的正确性。这些测试方法旨在识别系统漏洞，并评估对抗者的鲁棒性。端到端测试oracle（表[5](#S8.T5
    "Table 5 ‣ 8 Safety ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey")）在给定场景中确定正确的控制决策。变形测试通过验证在各种天气和光照条件下的转向角度[[6](#bib.bib6)]的一致性来解决oracle问题。它提供了一种可靠的方法，以确保转向角度在这些因素下保持稳定且不受影响。差分测试[[50](#bib.bib50)]通过比较不同DNN模型在相同场景下的推理结果，暴露出模型之间的不一致性。如果模型产生不同的结果，则表明系统中可能存在意外行为和潜在问题。基于模型的oracle利用训练的概率模型来评估和预测现实场景中的潜在风险[[23](#bib.bib23)]。通过监控环境，它可以识别系统可能无法充分处理的情况。'
- en: 'Safety metrics provide quantitative measures to evaluate the performance of
    autonomous driving systems and assess how well the system functions in terms of
    safety. Time to Collision (TTC), Conflict Index (CI), Crash Potential Index (CPI),
    Time to React (TTR), and others are some of the metrics that can provide additional
    objective comparisons between the safety performance of various approaches and
    identify areas that require improvement. A description of these metrics is provided
    in Table [6](#S8.T6 "Table 6 ‣ 8 Safety ‣ Recent Advancements in End-to-End Autonomous
    Driving using Deep Learning: A Survey").'
  id: totrans-1755
  prefs: []
  type: TYPE_NORMAL
  zh: '安全指标提供了量化措施，用于评估自动驾驶系统的性能，并评估系统在安全性方面的功能。碰撞时间（TTC）、冲突指数（CI）、碰撞潜力指数（CPI）、反应时间（TTR）等是一些可以提供额外客观比较不同方法安全性能的指标，并识别需要改进的领域。这些指标的描述见表[6](#S8.T6
    "Table 6 ‣ 8 Safety ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey")。'
- en: 9 Explainability
  id: totrans-1756
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 可解释性
- en: 'Explainability [[128](#bib.bib128)] refers to the ability to understand the
    logic of an agent and is focused on how a user interprets the relationships between
    the input and output of a model. It encompasses two main concepts: interpretability,
    which relates to the understandability of explanations, and completeness, which
    pertains to exhaustively defining the behavior of the model through explanations.
    Choi et al. [[129](#bib.bib129)] distinguish three types of confidence in autonomous
    vehicles: transparency, which refers to the person’s ability to foresee and comprehend
    vehicle operation; technical competence, which relates to understanding vehicle
    performance; and situation management, which involves the notion that the user
    can regain vehicle control at any time. According to Haspiel et al. [[130](#bib.bib130)],
    explanations play a crucial role when humans are involved, as the ability to explain
    an autonomous vehicle’s actions significantly impacts consumer trust, which is
    essential for the widespread acceptance of this technology.'
  id: totrans-1757
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性 [[128](#bib.bib128)] 指的是理解代理逻辑的能力，重点是用户如何解读模型的输入和输出之间的关系。它包括两个主要概念：解释性，即解释的可理解性；以及完整性，即通过解释全面定义模型行为。Choi
    等人 [[129](#bib.bib129)] 区分了自动驾驶车辆中的三种信心类型：透明性，即预测和理解车辆操作的能力；技术能力，即理解车辆性能；以及情况管理，即用户能够随时重新控制车辆的概念。Haspiel
    等人 [[130](#bib.bib130)] 表示，当涉及人类时，解释发挥着关键作用，因为解释自动驾驶车辆行动的能力对消费者信任有显著影响，而这种信任对技术的广泛接受至关重要。
- en: '![Refer to caption](img/d874e76a44b72e12ebcd36a4b3bd223a.png)'
  id: totrans-1758
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/d874e76a44b72e12ebcd36a4b3bd223a.png)'
- en: 'Figure 11: Categorization of Explainability Approaches.'
  id: totrans-1759
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：可解释性方法的分类。
- en: 'In the context of explainability for end-to-end autonomous driving systems,
    we can categorize explanation approaches into two main types (Fig. [11](#S9.F11
    "Figure 11 ‣ 9 Explainability ‣ Recent Advancements in End-to-End Autonomous Driving
    using Deep Learning: A Survey")): local explanations and global explanations.
    A local explanation aims to describe the rationale behind the predictions of the
    model. On the other hand, global explanations aim to comprehensively comprehend
    the model’s behavior by describing the underlying knowledge. As of now, there
    is no available research on global explanations in the context of end-to-end autonomous
    driving [[131](#bib.bib131)]. Therefore, future research should focus on addressing
    this gap.'
  id: totrans-1760
  prefs: []
  type: TYPE_NORMAL
  zh: '在端到端自动驾驶系统的可解释性背景下，我们可以将解释方法分为两种主要类型（见图 [11](#S9.F11 "Figure 11 ‣ 9 Explainability
    ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey)")）：局部解释和全局解释。局部解释旨在描述模型预测背后的理由。另一方面，全局解释旨在通过描述基础知识来全面理解模型的行为。目前，在端到端自动驾驶的背景下尚无关于全局解释的研究
    [[131](#bib.bib131)]。因此，未来的研究应集中在解决这一空白上。'
- en: '| ![Refer to caption](img/319c21348d6dc9656d390bc516e84dab.png) |'
  id: totrans-1761
  prefs: []
  type: TYPE_TB
  zh: '| ![参见标题](img/319c21348d6dc9656d390bc516e84dab.png) |'
- en: '| (a) PlanT agent’s attention |'
  id: totrans-1762
  prefs: []
  type: TYPE_TB
  zh: '| (a) PlanT 代理的注意力 |'
- en: '| ![Refer to caption](img/14cce2a15adb137905884e8f5eefccdc.png) |'
  id: totrans-1763
  prefs: []
  type: TYPE_TB
  zh: '| ![参见标题](img/14cce2a15adb137905884e8f5eefccdc.png) |'
- en: '| (b) InterFuser failure explanation |'
  id: totrans-1764
  prefs: []
  type: TYPE_TB
  zh: '| (b) InterFuser 失败解释 |'
- en: 'Figure 12: Explainability Methods: (a) PlanT [[18](#bib.bib18)] visualization
    showing the attention given to the agent in various scenarios. (b) Using InterFuser
    [[8](#bib.bib8)], failure cases can be visualized by integrating three RGB views
    and a predicted object density map. The orange boxes indicate objects that pose
    a collision risk to the ego-vehicle. The object density map offers predictions
    for the current traffic scene ($t_{0}$) and future traffic scenes at 1-second
    ($t_{1}$) and 2-second ($t_{2}$) intervals.'
  id: totrans-1765
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：可解释性方法：（a）PlanT [[18](#bib.bib18)] 可视化展示了在各种场景中给予代理的注意力。（b）通过使用 InterFuser
    [[8](#bib.bib8)]，可以通过集成三种 RGB 视图和预测的对象密度图来可视化失败案例。橙色框表示对自车有碰撞风险的对象。对象密度图提供了当前交通场景（$t_{0}$）以及
    1 秒（$t_{1}$）和 2 秒（$t_{2}$）间隔后的未来交通场景的预测。
- en: 9.1 Local explanations
  id: totrans-1766
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1 局部解释
- en: 'A local explanation describes why the model $f$ produces its prediction $y=f(x)$
    given an input $x$. There are two approaches: in [9.1.1](#S9.SS1.SSS1 "9.1.1 Post-hoc
    saliency methods ‣ 9.1 Local explanations ‣ 9 Explainability ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey"), we determine
    which visual region has the most impact, and in [9.1.2](#S9.SS1.SSS2 "9.1.2 Counterfactual
    explanation ‣ 9.1 Local explanations ‣ 9 Explainability ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey"), we identify
    the factors that caused the model to predict $f(x)$.'
  id: totrans-1767
  prefs: []
  type: TYPE_NORMAL
  zh: 局部解释描述了为什么模型 $f$ 在给定输入 $x$ 时会产生其预测 $y=f(x)$。有两种方法：在 [9.1.1](#S9.SS1.SSS1 "9.1.1
    后验显著性方法 ‣ 9.1 局部解释 ‣ 9 解释性 ‣ 深度学习在端到端自动驾驶中的最新进展：综述") 中，我们确定哪个视觉区域具有最大的影响，而在 [9.1.2](#S9.SS1.SSS2
    "9.1.2 反事实解释 ‣ 9.1 局部解释 ‣ 9 解释性 ‣ 深度学习在端到端自动驾驶中的最新进展：综述") 中，我们确定导致模型预测 $f(x)$
    的因素。
- en: 9.1.1 Post-hoc saliency methods
  id: totrans-1768
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.1.1 后验显著性方法
- en: A post-hoc saliency technique attempts to explain which portions of the input
    space have the most effect on the model’s output. These approaches provide a saliency
    map that illustrates the locations where the model made the most significant decisions.
  id: totrans-1769
  prefs: []
  type: TYPE_NORMAL
  zh: 后验显著性技术试图解释输入空间的哪些部分对模型输出产生了最大的影响。这些方法提供了一个显著性图，展示了模型做出最重要决策的位置。
- en: 'Post-hoc saliency methods primarily focus on the perception component of the
    driving architecture. Bojarski et al. [[132](#bib.bib132)] introduced the first
    post-hoc saliency approach for visualizing the impact of inputs in autonomous
    driving. Renz et al. [[18](#bib.bib18)] proposed the PlanT method (Fig. [12](#S9.F12
    "Figure 12 ‣ 9 Explainability ‣ Recent Advancements in End-to-End Autonomous Driving
    using Deep Learning: A Survey")(a)), which utilizes an attention mechanism for
    post-hoc saliency visualization to provide object-level representations using
    the attention weights of the transformer to identify the most relevant objects.
    Mori et al. [[133](#bib.bib133)] proposed an attention mechanism that utilizes
    the model’s predictions of steering angle and throttle. These local predictions
    are employed as visual attention maps and combined with learned parameters using
    a linear combination to make the final decision. While attention-based methods
    are often believed to improve the transparency of neural networks, it should be
    noted that learned attention weights may exhibit weak correlations with several
    features. The attention weights can provide accurate predictions when measuring
    different input features during driving. Overall, evaluating the post-hoc effectiveness
    of attention mechanisms is challenging and often relies on subjective human evaluation.'
  id: totrans-1770
  prefs: []
  type: TYPE_NORMAL
  zh: 后验显著性方法主要关注驾驶架构的感知组件。Bojarski 等人 [[132](#bib.bib132)] 介绍了第一个后验显著性方法，用于可视化输入在自动驾驶中的影响。Renz
    等人 [[18](#bib.bib18)] 提出了 PlanT 方法（图 [12](#S9.F12 "图 12 ‣ 9 解释性 ‣ 深度学习在端到端自动驾驶中的最新进展：综述")(a)），该方法利用注意力机制进行后验显著性可视化，通过变换器的注意力权重提供对象级表示，以识别最相关的对象。Mori
    等人 [[133](#bib.bib133)] 提出了利用模型的转向角度和油门预测的注意力机制。这些局部预测作为视觉注意力图使用，并通过线性组合与学习到的参数结合，以做出最终决策。虽然基于注意力的方法常被认为能提高神经网络的透明性，但需要注意的是，学习到的注意力权重可能与多个特征的相关性较弱。注意力权重可以在驾驶过程中测量不同输入特征时提供准确的预测。总体而言，评估注意力机制的后验有效性具有挑战性，通常依赖于主观的人类评估。
- en: 9.1.2 Counterfactual explanation
  id: totrans-1771
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.1.2 反事实解释
- en: Saliency approaches focus on answering the ‘where’ question, identifying influential
    input locations for the model’s decision. In contrast, counterfactual explanations
    address the ‘what’ question by seeking small changes in the input that alter the
    model’s prediction. Counterfactual analysis aims to identify features $X$ within
    the input $x$ that led to the outcome $y=f(x)$ by creating a new input instance
    $x^{\prime}$ where $X$ is modified, resulting in a different outcome $y^{\prime}$.
    The modified input instance $x^{\prime}$ serves as the counterfactual example,
    and $y^{\prime}$ represents the contrasting class, such as ‘What changes in the
    traffic scenario would cause the vehicle to stop moving?’ It could be a red light.
  id: totrans-1772
  prefs: []
  type: TYPE_NORMAL
  zh: 重要性方法专注于回答“哪里”这个问题，识别对模型决策有影响的输入位置。与此不同的是，反事实解释通过寻求输入中能够改变模型预测的小变化来解决“什么”这个问题。反事实分析旨在通过创建一个新的输入实例
    $x^{\prime}$，其中 $X$ 被修改，从而导致不同的结果 $y^{\prime}$，来识别输入 $x$ 中的特征 $X$，这些特征导致了结果 $y=f(x)$。修改后的输入实例
    $x^{\prime}$ 作为反事实示例，而 $y^{\prime}$ 代表对比类别，例如“交通场景的哪些变化会导致车辆停止移动？”这可能是红灯。
- en: Since the input space consists of semantic dimensions and is modifiable, assessing
    the causality of input components is straightforward. Li et al. [[125](#bib.bib125)]
    proposed a causal inference technique for identifying risky objects. Steex [[134](#bib.bib134)]
    developed a counterfactual method that modifies the style of the region to explain
    the visual model. The semantic input provides a high-level object representation,
    making it more interpretable compared to pixel-level representations.
  id: totrans-1773
  prefs: []
  type: TYPE_NORMAL
  zh: 由于输入空间由语义维度构成且可修改，因此评估输入组件的因果关系很简单。Li等人[[125](#bib.bib125)] 提出了一种用于识别风险对象的因果推断技术。Steex
    [[134](#bib.bib134)] 开发了一种反事实方法，通过修改区域的风格来解释视觉模型。语义输入提供了高层次的对象表示，使其比像素级表示更易于解释。
- en: Bansal et al. [[135](#bib.bib135)] explore the underlying causes of particular
    outcomes by examining the ChauffeurNet model using manually crafted inputs that
    involve omitting particular objects.
  id: totrans-1774
  prefs: []
  type: TYPE_NORMAL
  zh: Bansal等人[[135](#bib.bib135)] 通过检查ChauffeurNet模型，使用手动创建的输入（涉及省略特定对象），探索特定结果的潜在原因。
- en: 'In End-to-End driving, the steering, throttle, and brake driving outputs can
    be complemented with auxiliary outputs such as the occupancy and interpretable
    semantics to demonstrate a specific degree of counterfactual understandability.
    Chitta et al. [[7](#bib.bib7)] introduce an auxiliary output (semantics map) that
    employs the A* planner to address a counterfactual inquiry of “What is the possibility
    of a collision without braking". Shao et al. [[8](#bib.bib8)] designed a system,
    as shown in Fig. [12](#S9.F12 "Figure 12 ‣ 9 Explainability ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey")(b), which infers
    counterfactual reasoning for the potential failures with the assistance of an
    intermediate object density map. Sadat et al. [[90](#bib.bib90)] generate a probabilistic
    semantic occupancy map over space and time, capturing the positions of diverse
    road agents. Occupancy maps provide a counterfactual explanation as they act as
    an intermediary representation to the motion planning system, higher occupancy
    probabilities will discourages the maneuvers while lower occupancy will encourage
    them.'
  id: totrans-1775
  prefs: []
  type: TYPE_NORMAL
  zh: '在端到端驾驶中，方向盘、油门和刹车的驾驶输出可以通过辅助输出（如占用率和可解释语义）来补充，以展示特定程度的反事实可解释性。Chitta等人[[7](#bib.bib7)]
    引入了一个辅助输出（语义图），使用A*规划器来处理“在不刹车的情况下碰撞的可能性”这一反事实问题。Shao等人[[8](#bib.bib8)] 设计了一个系统，如图
    [12](#S9.F12 "Figure 12 ‣ 9 Explainability ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")(b) 所示，利用中间对象密度图推断潜在失败的反事实推理。Sadat等人[[90](#bib.bib90)]
    生成了一个跨空间和时间的概率语义占用图，捕捉各种道路代理的位置。占用图提供了反事实解释，因为它们作为运动规划系统的中介表示，较高的占用概率会阻碍操作，而较低的占用概率会鼓励操作。'
- en: 9.2 Global explanations
  id: totrans-1776
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2 全球解释
- en: 'Global explanations aim to provide an overall understanding of a model’s behavior
    by describing the knowledge it possesses. They are classified into model translation
    ([9.2.1](#S9.SS2.SSS1 "9.2.1 Model translation ‣ 9.2 Global explanations ‣ 9 Explainability
    ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey")) and representation explanation techniques ([9.2.2](#S9.SS2.SSS2 "9.2.2
    Explaining representations ‣ 9.2 Global explanations ‣ 9 Explainability ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey"))
    for analyzing global explanations.'
  id: totrans-1777
  prefs: []
  type: TYPE_NORMAL
  zh: '全局解释旨在通过描述模型所具备的知识来提供对模型行为的整体理解。它们被分类为模型翻译（[9.2.1](#S9.SS2.SSS1 "9.2.1 Model
    translation ‣ 9.2 Global explanations ‣ 9 Explainability ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey")）和表示解释技术（[9.2.2](#S9.SS2.SSS2
    "9.2.2 Explaining representations ‣ 9.2 Global explanations ‣ 9 Explainability
    ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey")）来分析全局解释。'
- en: 9.2.1 Model translation
  id: totrans-1778
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.2.1 模型翻译
- en: The objective of model translation is to transfer the information from the original
    model to a different model that is inherently interpretable. This involves training
    an explainable model to mimic the input-output relationship. Recent studies have
    explored translating deep learning models into decision trees [[136](#bib.bib136)],
    rule-based models [[137](#bib.bib137)], or causal models [[138](#bib.bib138)].
    However, one limitation of this approach is the potential discrepancies between
    the interpretable translated model and the original self-driving model.
  id: totrans-1779
  prefs: []
  type: TYPE_NORMAL
  zh: 模型翻译的目标是将原始模型中的信息转移到一个本质上可解释的不同模型中。这涉及到训练一个可解释模型来模拟输入输出关系。近期的研究探讨了将深度学习模型转化为决策树[[136](#bib.bib136)]、基于规则的模型[[137](#bib.bib137)]或因果模型[[138](#bib.bib138)]。然而，这种方法的一个局限是可解释翻译模型与原始自动驾驶模型之间可能存在的差异。
- en: 9.2.2 Explaining representations
  id: totrans-1780
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.2.2 解释表示
- en: Explaining representations aims to explain the information captured by the model’s
    structures at various scales. Zhang et al. [[139](#bib.bib139)] and Bau et al.
    [[140](#bib.bib140)] make efforts to gain insights into what the neurons capture.
    The activation of a neuron can be understood by examining input patterns that
    maximize its activity. For example, one can sample the input using gradient ascent
    [[141](#bib.bib141)] or generative networks [[142](#bib.bib142)]. Tian et al.
    [[120](#bib.bib120)] employ the concept of neuron coverage to identify false actions
    that could potentially lead to fatalities. They partition the input space based
    on neuron coverage, assuming that inputs with the same neuron coverage will result
    in the same model decision. Their objective is to increase neuron coverage through
    transformations such as linear changes in image intensity and affine transformations
    like rotation and convolution.
  id: totrans-1781
  prefs: []
  type: TYPE_NORMAL
  zh: 解释表示旨在解释模型在不同尺度下结构捕捉的信息。张等人[[139](#bib.bib139)]和Bau等人[[140](#bib.bib140)]努力深入了解神经元捕捉到的内容。通过检查能够最大化其活动的输入模式，可以理解一个神经元的激活。例如，可以使用梯度上升[[141](#bib.bib141)]或生成网络[[142](#bib.bib142)]对输入进行采样。Tian等人[[120](#bib.bib120)]运用神经元覆盖的概念来识别可能导致致命错误的虚假动作。他们基于神经元覆盖对输入空间进行划分，假设具有相同神经元覆盖的输入会导致相同的模型决策。他们的目标是通过图像强度的线性变化和旋转、卷积等仿射变换来增加神经元覆盖。
- en: 'Table 7: CARLA AUTONOMOUS DRIVING LEADERBOARD 1.0 SUBMISSION UNTIL AUGUST 2023'
  id: totrans-1782
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：CARLA 自动驾驶排行榜 1.0 截止至 2023 年 8 月的提交情况
- en: '| Rank | Submission | DS | RC | IP | CP | CV | CL | RLI | SSI | OI | RD | AB
    | Type |'
  id: totrans-1783
  prefs: []
  type: TYPE_TB
  zh: '| 排名 | 提交 | DS | RC | IP | CP | CV | CL | RLI | SSI | OI | RD | AB | 类型 |'
- en: '|  |  | % | % | [0,1] | infractions/km | E/M |'
  id: totrans-1784
  prefs: []
  type: TYPE_TB
  zh: '|  |  | % | % | [0,1] | 违规/km | E/M |'
- en: '| 1 | ReasonNet [[16](#bib.bib16)] | 79.95 | 89.89 | 0.89 | 0.02 | 0.13 | 0.01
    | 0.08 | 0.00 | 0.04 | 0.00 | 0.33 | E |'
  id: totrans-1785
  prefs: []
  type: TYPE_TB
  zh: '| 1 | ReasonNet [[16](#bib.bib16)] | 79.95 | 89.89 | 0.89 | 0.02 | 0.13 | 0.01
    | 0.08 | 0.00 | 0.04 | 0.00 | 0.33 | E |'
- en: '| 1 | InterFuser [[8](#bib.bib8)] | 76.18 | 88.23 | 0.84 | 0.04 | 0.37 | 0.14
    | 0.22 | 0.00 | 0.13 | 0.00 | 0.43 | E |'
  id: totrans-1786
  prefs: []
  type: TYPE_TB
  zh: '| 1 | InterFuser [[8](#bib.bib8)] | 76.18 | 88.23 | 0.84 | 0.04 | 0.37 | 0.14
    | 0.22 | 0.00 | 0.13 | 0.00 | 0.43 | E |'
- en: '| 2 | TCP [[13](#bib.bib13)] | 75.14 | 85.63 | 0.87 | 0.00 | 0.32 | 0.00 |
    0.09 | 0.00 | 0.04 | 0.00 | 0.54 | E |'
  id: totrans-1787
  prefs: []
  type: TYPE_TB
  zh: '| 2 | TCP [[13](#bib.bib13)] | 75.14 | 85.63 | 0.87 | 0.00 | 0.32 | 0.00 |
    0.09 | 0.00 | 0.04 | 0.00 | 0.54 | E |'
- en: '| 3 | TF++ [[71](#bib.bib71)] | 66.32 | 78.57 | 0.84 | 0.00 | 0.50 | 0.00 |
    0.01 | 0.00 | 0.12 | 0.00 | 0.71 | E |'
  id: totrans-1788
  prefs: []
  type: TYPE_TB
  zh: '| 3 | TF++ [[71](#bib.bib71)] | 66.32 | 78.57 | 0.84 | 0.00 | 0.50 | 0.00 |
    0.01 | 0.00 | 0.12 | 0.00 | 0.71 | E |'
- en: '| 3 | LAV [[10](#bib.bib10)] | 61.85 | 94.46 | 0.64 | 0.04 | 0.70 | 0.02 |
    0.17 | 0.00 | 0.25 | 0.09 | 0.10 | E |'
  id: totrans-1789
  prefs: []
  type: TYPE_TB
  zh: '| 3 | LAV [[10](#bib.bib10)] | 61.85 | 94.46 | 0.64 | 0.04 | 0.70 | 0.02 |
    0.17 | 0.00 | 0.25 | 0.09 | 0.10 | E |'
- en: '| 4 | TransFuser [[7](#bib.bib7)] | 61.18 | 86.69 | 0.71 | 0.04 | 0.81 | 0.01
    | 0.05 | 0.00 | 0.23 | 0.00 | 0.43 | E |'
  id: totrans-1790
  prefs: []
  type: TYPE_TB
  zh: '| 4 | TransFuser [[7](#bib.bib7)] | 61.18 | 86.69 | 0.71 | 0.04 | 0.81 | 0.01
    | 0.05 | 0.00 | 0.23 | 0.00 | 0.43 | E |'
- en: '| 5 | Latent TransFuser [[7](#bib.bib7)] | 45.20 | 66.31 | 0.72 | 0.02 | 1.11
    | 0.02 | 0.05 | 0.00 | 0.16 | 0.00 | 1.82 | E |'
  id: totrans-1791
  prefs: []
  type: TYPE_TB
  zh: '| 5 | Latent TransFuser [[7](#bib.bib7)] | 45.20 | 66.31 | 0.72 | 0.02 | 1.11
    | 0.02 | 0.05 | 0.00 | 0.16 | 0.00 | 1.82 | E |'
- en: '| 6 | GRIAD [[100](#bib.bib100)] | 36.79 | 61.85 | 0.60 | 0.00 | 2.77 | 0.41
    | 0.48 | 0.00 | 1.39 | 1.11 | 0.84 | E |'
  id: totrans-1792
  prefs: []
  type: TYPE_TB
  zh: '| 6 | GRIAD [[100](#bib.bib100)] | 36.79 | 61.85 | 0.60 | 0.00 | 2.77 | 0.41
    | 0.48 | 0.00 | 1.39 | 1.11 | 0.84 | E |'
- en: '| 7 | TransFuser+ [[7](#bib.bib7)] | 34.58 | 69.84 | 0.56 | 0.04 | 0.70 | 0.03
    | 0.75 | 0.00 | 0.18 | 0.00 | 2.41 | E |'
  id: totrans-1793
  prefs: []
  type: TYPE_TB
  zh: '| 7 | TransFuser+ [[7](#bib.bib7)] | 34.58 | 69.84 | 0.56 | 0.04 | 0.70 | 0.03
    | 0.75 | 0.00 | 0.18 | 0.00 | 2.41 | E |'
- en: '| 8 | World on Rails [[99](#bib.bib99)] | 31.37 | 57.65 | 0.56 | 0.61 | 1.35
    | 1.02 | 0.79 | 0.00 | 0.96 | 1.69 | 0.47 | E |'
  id: totrans-1794
  prefs: []
  type: TYPE_TB
  zh: '| 8 | World on Rails [[99](#bib.bib99)] | 31.37 | 57.65 | 0.56 | 0.61 | 1.35
    | 1.02 | 0.79 | 0.00 | 0.96 | 1.69 | 0.47 | E |'
- en: '| 9 | MaRLn [[53](#bib.bib53)] | 24.98 | 46.97 | 0.52 | 0.00 | 2.33 | 2.47
    | 0.55 | 0.00 | 1.82 | 1.44 | 0.94 | E |'
  id: totrans-1795
  prefs: []
  type: TYPE_TB
  zh: '| 9 | MaRLn [[53](#bib.bib53)] | 24.98 | 46.97 | 0.52 | 0.00 | 2.33 | 2.47
    | 0.55 | 0.00 | 1.82 | 1.44 | 0.94 | E |'
- en: '| 10 | NEAT [[12](#bib.bib12)] | 21.83 | 41.71 | 0.65 | 0.04 | 0.74 | 0.62
    | 0.70 | 0.00 | 2.68 | 0.00 | 5.22 | E |'
  id: totrans-1796
  prefs: []
  type: TYPE_TB
  zh: '| 10 | NEAT [[12](#bib.bib12)] | 21.83 | 41.71 | 0.65 | 0.04 | 0.74 | 0.62
    | 0.70 | 0.00 | 2.68 | 0.00 | 5.22 | E |'
- en: '| 11 | AIM-MT [[12](#bib.bib12)] | 19.38 | 67.02 | 0.39 | 0.18 | 1.53 | 0.12
    | 1.55 | 0.00 | 0.35 | 0.00 | 2.11 | E |'
  id: totrans-1797
  prefs: []
  type: TYPE_TB
  zh: '| 11 | AIM-MT [[12](#bib.bib12)] | 19.38 | 67.02 | 0.39 | 0.18 | 1.53 | 0.12
    | 1.55 | 0.00 | 0.35 | 0.00 | 2.11 | E |'
- en: '| 12 | TransFuser [[14](#bib.bib14)] | 16.93 | 51.82 | 0.42 | 0.91 | 1.09 |
    0.19 | 1.26 | 0.00 | 0.57 | 0.00 | 1.96 | E |'
  id: totrans-1798
  prefs: []
  type: TYPE_TB
  zh: '| 12 | TransFuser [[14](#bib.bib14)] | 16.93 | 51.82 | 0.42 | 0.91 | 1.09 |
    0.19 | 1.26 | 0.00 | 0.57 | 0.00 | 1.96 | E |'
- en: '| 13 | CNN-Planner [[143](#bib.bib143)] | 15.40 | 50.05 | 0.41 | 0.08 | 4.67
    | 0.42 | 0.35 | 0.00 | 2.78 | 0.12 | 4.63 | M |'
  id: totrans-1799
  prefs: []
  type: TYPE_TB
  zh: '| 13 | CNN-Planner [[143](#bib.bib143)] | 15.40 | 50.05 | 0.41 | 0.08 | 4.67
    | 0.42 | 0.35 | 0.00 | 2.78 | 0.12 | 4.63 | M |'
- en: '| 14 | Learning by [[48](#bib.bib48)] | 8.94 | 17.54 | 0.73 | 0.00 | 0.40 |
    1.16 | 0.71 | 0.00 | 1.52 | 0.03 | 4.69 | E |'
  id: totrans-1800
  prefs: []
  type: TYPE_TB
  zh: '| 14 | Learning by [[48](#bib.bib48)] | 8.94 | 17.54 | 0.73 | 0.00 | 0.40 |
    1.16 | 0.71 | 0.00 | 1.52 | 0.03 | 4.69 | E |'
- en: '| 15 | MaRLn [[53](#bib.bib53)] | 5.56 | 24.72 | 0.36 | 0.77 | 3.25 | 13.23
    | 0.85 | 0.00 | 10.73 | 2.97 | 11.41 | E |'
  id: totrans-1801
  prefs: []
  type: TYPE_TB
  zh: '| 15 | MaRLn [[53](#bib.bib53)] | 5.56 | 24.72 | 0.36 | 0.77 | 3.25 | 13.23
    | 0.85 | 0.00 | 10.73 | 2.97 | 11.41 | E |'
- en: '| 16 | CILRS [[12](#bib.bib12)] | 5.37 | 14.40 | 0.55 | 2.69 | 1.48 | 2.35
    | 1.62 | 0.00 | 4.55 | 4.14 | 4.28 | E |'
  id: totrans-1802
  prefs: []
  type: TYPE_TB
  zh: '| 16 | CILRS [[12](#bib.bib12)] | 5.37 | 14.40 | 0.55 | 2.69 | 1.48 | 2.35
    | 1.62 | 0.00 | 4.55 | 4.14 | 4.28 | E |'
- en: '| 17 | CaRINA [[144](#bib.bib144)] | 4.56 | 23.80 | 0.41 | 0.01 | 7.56 | 51.52
    | 20.64 | 0.00 | 14.32 | 0.00 | 10055.99 | M |'
  id: totrans-1803
  prefs: []
  type: TYPE_TB
  zh: '| 17 | CaRINA [[144](#bib.bib144)] | 4.56 | 23.80 | 0.41 | 0.01 | 7.56 | 51.52
    | 20.64 | 0.00 | 14.32 | 0.00 | 10055.99 | M |'
- en: •
  id: totrans-1804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Route Completion (RC), Infraction Score/penalty (IS), Driving score (DS), Collisions
    pedestrians (CP)/(PC), Collisions vehicles (CV), Collisions layout (CL)/(LC),
    Red light infractions (RLI), Red light violation (RV), Stop sign infractions (SSI),
    Off-road infractions (OI), Route deviations (RD), Agent blocked (AB), End-to-End
    Architecture (E), Modular Architecture (M).
  id: totrans-1805
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 路径完成（RC）、违规评分/处罚（IS）、驾驶评分（DS）、碰撞行人（CP）/（PC）、碰撞车辆（CV）、碰撞布局（CL）/（LC）、红灯违规（RLI）、红灯违章（RV）、停车标志违规（SSI）、越野违规（OI）、路径偏差（RD）、代理被阻塞（AB）、端到端架构（E）、模块化架构（M）。
- en: 10 Evaluation
  id: totrans-1806
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 评估
- en: The evaluation of the End-to-End system consists of open-loop evaluation and
    closed-loop evaluation. The open loop is assessed using real-world benchmark datasets
    such as KITTI [[110](#bib.bib110)] and nuScenes [[145](#bib.bib145)]. It compares
    the system’s driving behavior with expert actions and measures the deviation.
    Measures such as MinADE, MinFDE [[9](#bib.bib9)], L2 error [[20](#bib.bib20)],
    and collision rate [[84](#bib.bib84)] are some of the evaluation metrics presented
    in Table LABEL:literature. In contrast the closed-loop evaluation directly assesses
    the system in controlled real-world or simulated settings by allowing it to drive
    independently and learn safe driving maneuvers.
  id: totrans-1807
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端系统的评估包括开放环评估和闭环评估。开放环评估使用真实世界的基准数据集，例如 KITTI [[110](#bib.bib110)] 和 nuScenes
    [[145](#bib.bib145)]。它比较系统的驾驶行为与专家操作，并测量偏差。最小 ADE、最小 FDE [[9](#bib.bib9)]、L2误差
    [[20](#bib.bib20)] 和碰撞率 [[84](#bib.bib84)] 等测量指标是表 LABEL:literature 中呈现的一些评估指标。相比之下，闭环评估通过允许系统独立驾驶并学习安全驾驶操作，直接在受控的真实世界或模拟环境中评估系统。
- en: In the open-loop evaluation of End-to-End driving systems, the system’s inputs,
    such as camera images or LiDAR data, are provided to the system. The resulting
    outputs, such as steering commands and vehicle speed, are evaluated against predefined
    driving behaviors. The evaluation metrics commonly used in the open-loop evaluation
    include measures of the system’s ability to follow the desired trajectory or driving
    behaviors, such as the mean squared error [[50](#bib.bib50)], L2 [[9](#bib.bib9),
    [82](#bib.bib82)] between the predicted and actual trajectories or the percentage
    of time the system remains within a certain distance of the desired trajectory
    [[13](#bib.bib13)]. Other evaluation metrics may also be employed to assess the
    system’s performance in specific driving scenarios [[14](#bib.bib14), [6](#bib.bib6)],
    such as the system’s capability to navigate intersections, handle obstacles, or
    perform lane changes. The open loop provides faster initial assessment based on
    functionalities and is also helpful for testing specific components or behaviors
    in isolation. However, they inherit drawbacks from the benchmark datasets as they
    cannot generalize to wider geographical distribution.
  id: totrans-1808
  prefs: []
  type: TYPE_NORMAL
  zh: 在端到端驾驶系统的开环评估中，系统的输入，例如相机图像或激光雷达数据，被提供给系统。生成的输出，例如转向指令和车辆速度，会与预定义的驾驶行为进行对比评估。开环评估中常用的评估指标包括系统跟随期望轨迹或驾驶行为的能力测量，如均方误差
    [[50](#bib.bib50)]、预测轨迹与实际轨迹之间的L2 [[9](#bib.bib9), [82](#bib.bib82)] 距离，或系统保持在期望轨迹一定距离内的时间百分比
    [[13](#bib.bib13)]。还可以使用其他评估指标来评估系统在特定驾驶场景中的表现 [[14](#bib.bib14), [6](#bib.bib6)]，如系统在交叉路口导航、处理障碍物或执行变道的能力。开环提供了基于功能的更快初步评估，并且对于测试特定组件或行为是有帮助的。然而，它们继承了基准数据集的缺点，因为它们无法推广到更广泛的地理分布。
- en: 'Most of the recent End-to-End systems are evaluated in closed-loop settings
    such as LEADERBOARD and NOCRASH [[109](#bib.bib109)]. Table [7](#S9.T7 "Table
    7 ‣ 9.2.2 Explaining representations ‣ 9.2 Global explanations ‣ 9 Explainability
    ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey") compares all the state-of-the-art methods on the CARLA public leaderboard.
    The CARLA leaderboard analyzes autonomous driving systems in unanticipated environments.
    Vehicles are tasked with completing a set of specified routes, incorporating risky
    scenarios such as unexpectedly crossing pedestrians or sudden lane changes. The
    leaderboard measures how far the vehicle has successfully traveled on the given
    Town route within a time constraint and how many times it has incurred infractions.
    Several metrics provide a comprehensive understanding of the driving system, which
    are mentioned below:'
  id: totrans-1809
  prefs: []
  type: TYPE_NORMAL
  zh: '最近的大多数端到端系统在闭环环境中进行评估，如LEADERBOARD和NOCRASH [[109](#bib.bib109)]。表[7](#S9.T7
    "Table 7 ‣ 9.2.2 Explaining representations ‣ 9.2 Global explanations ‣ 9 Explainability
    ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A
    Survey") 比较了CARLA公共排行榜上的所有先进方法。CARLA排行榜分析了在意外环境中的自动驾驶系统。车辆需要完成一系列指定的路线，涉及诸如意外出现的行人或突然的车道变更等风险场景。排行榜衡量了车辆在规定时间内成功行驶的距离，以及它发生违章的次数。几个指标提供了对驾驶系统的全面理解，具体如下：'
- en: •
  id: totrans-1810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Route Completion (RC): [[7](#bib.bib7), [10](#bib.bib10), [18](#bib.bib18),
    [13](#bib.bib13), [8](#bib.bib8)] measures the percentage of the distance that
    an agent can complete.'
  id: totrans-1811
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 路线完成率（RC）：[[7](#bib.bib7), [10](#bib.bib10), [18](#bib.bib18), [13](#bib.bib13),
    [8](#bib.bib8)] 衡量代理能够完成的距离百分比。
- en: •
  id: totrans-1812
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Infraction Score/penalty (IS): [[14](#bib.bib14), [51](#bib.bib51), [12](#bib.bib12)]
    is a geometric series that tracks infractions and aggregates the infraction penalties.
    It measures how often an agent drives without causing infractions.'
  id: totrans-1813
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 违章得分/处罚（IS）：[[14](#bib.bib14), [51](#bib.bib51), [12](#bib.bib12)] 是一个几何级数，用于跟踪违章并汇总违章处罚。它衡量了代理在不造成违章的情况下驾驶的频率。
- en: •
  id: totrans-1814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Driving score (DS): [[54](#bib.bib54), [52](#bib.bib52), [49](#bib.bib49)]
    is a primary metric calculated as the multiplication of the route completion and
    the infraction penalty. It measures the route completion rate weighted by infractions
    per route.'
  id: totrans-1815
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 驾驶得分（DS）：[[54](#bib.bib54), [52](#bib.bib52), [49](#bib.bib49)] 是一个主要指标，通过将路线完成率与违章处罚相乘来计算。它衡量了每条路线的违章加权后的完成率。
- en: There are specific metrics that evaluate infractions; each metric has penalty
    coefficients applied every time an infraction takes place. Collisions with pedestrians,
    collisions with other vehicles, collisions with static elements, collisions layout,
    red light infractions, stop sign infractions, and off-road infractions are some
    of the metrics used [[143](#bib.bib143)]. Closed-loop evaluation provides dynamic
    testing adaptability where one can provide customized configuration and sensor
    settings. The feedback loop in it allows for iterative refinement, enabling the
    system to learn and improve from mistakes and experiences. However, several challenges
    are associated with closed-loop. These include the complexity of the initial setup
    and the domain gap, which might require additional fine-tuning.
  id: totrans-1816
  prefs: []
  type: TYPE_NORMAL
  zh: 有特定的指标来评估违规行为；每个指标在每次违规发生时都会应用罚款系数。与行人发生碰撞、与其他车辆发生碰撞、与静态元素发生碰撞、碰撞布局、红灯违规、停车标志违规和离道路违规是一些使用的指标
    [[143](#bib.bib143)]。闭环评估提供了动态测试的适应性，可以提供自定义配置和传感器设置。闭环中的反馈环允许进行迭代改进，使系统能够从错误和经验中学习和改进。然而，闭环也面临一些挑战，包括初始设置的复杂性和领域差距，可能需要额外的微调。
- en: 11 Datasets and simulator
  id: totrans-1817
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11 数据集和模拟器
- en: 11.1 Datasets
  id: totrans-1818
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1 数据集
- en: 'In End-to-End models, the quality and richness of data are critical aspects
    of model training. Instead of using different hyperparameters, the training data
    is the most crucial factor influencing the model’s performance. The amount of
    information fed into the model determines the kind of outcomes it produces. We
    summarized the self-driving dataset based on their sensor modalities, including
    camera, LiDAR, GNSS, and dynamics. The content of the datasets includes urban
    driving, traffic, and different road conditions. Weather conditions also influence
    the model’s performance. Some datasets, such as ApolloScape [[146](#bib.bib146)],
    capture all weather conditions from sunny to snowy. The details are provided in
    Table [8](#S12.T8 "Table 8 ‣ 12.4 Collaboration perception systems ‣ 12 Future
    research directions ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey").'
  id: totrans-1819
  prefs: []
  type: TYPE_NORMAL
  zh: '在端到端模型中，数据的质量和丰富性是模型训练的关键方面。与使用不同的超参数相比，训练数据是影响模型性能的最重要因素。输入到模型中的信息量决定了它产生的结果。我们根据传感器模式总结了自动驾驶数据集，包括摄像头、LiDAR、GNSS和动态数据。数据集的内容包括城市驾驶、交通和不同的道路条件。天气条件也会影响模型的性能。一些数据集，如
    ApolloScape [[146](#bib.bib146)]，捕捉了从晴天到雪天的所有天气条件。详细信息请参见表 [8](#S12.T8 "Table
    8 ‣ 12.4 Collaboration perception systems ‣ 12 Future research directions ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey")。'
- en: 11.2 Simulators and toolsets
  id: totrans-1820
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2 模拟器和工具集
- en: Standard testing of End-to-End driving and learning pipelines requires advanced
    software simulators to process information and make conclusions for their various
    functionalities. Experimenting with such driving systems is expensive, and conducting
    tests on public roads is heavily restricted. Simulation environments assist in
    training specific algorithms/modules before road testing. Simulators like Carla
    [[109](#bib.bib109)] offer flexibility to simulate the environment based on experimental
    requirements, including weather conditions, traffic flow, road agents, etc. Simulators
    play a crucial role in generating safety-critical scenarios and contribute to
    model generalization for detecting and preventing such scenarios.
  id: totrans-1821
  prefs: []
  type: TYPE_NORMAL
  zh: 对于端到端驾驶和学习管道的标准测试，需要先进的软件模拟器来处理信息并对其各种功能做出结论。实验这种驾驶系统的成本很高，而在公共道路上进行测试受到严格限制。模拟环境有助于在道路测试之前训练特定的算法/模块。像
    Carla [[109](#bib.bib109)] 这样的模拟器提供了根据实验要求模拟环境的灵活性，包括天气条件、交通流量、道路代理等。模拟器在生成安全关键场景方面发挥了至关重要的作用，并有助于模型的泛化，以检测和预防此类场景。
- en: 'Widely used platforms for training End-to-End driving pipelines are compared
    in Table [9](#S12.T9 "Table 9 ‣ 12.4 Collaboration perception systems ‣ 12 Future
    research directions ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey"). MATLAB/Simulink [[147](#bib.bib147)] is used for various
    settings; it contains efficient plot functions and has the ability to co-simulate
    with other software, such as CarSim [[148](#bib.bib148)], which simplifies the
    creation of different settings. PreScan [[149](#bib.bib149)] can mimic real-world
    environments, including weather conditions, which MATLAB and CarSim lack. It also
    supports the MATLAB Simulink interface, making modeling more effective. Gazebo
    [[150](#bib.bib150)] is well-known for its high versatility and easy connection
    with ROS. In contrast to the CARLA and LGSVL [[151](#bib.bib151)] simulators,
    creating a simulated environment with Gazebo requires mechanical effort. CARLA
    and LGSVL offer high-quality simulation frameworks that require a GPU processing
    unit to operate at a decent speed and frame rate. CARLA is built on the Unreal
    Engine, while LGSVL is based on the Unity game engine. The API allows users to
    access various capabilities in CARLA and LGSVL, from developing customizable sensors
    to map generation. LGSVL generally links to the driving stack through various
    bridges, and CARLA allows built-in bridge connections via ROS and Autoware.'
  id: totrans-1822
  prefs: []
  type: TYPE_NORMAL
  zh: '常用的端到端驾驶管道训练平台在[9表](#S12.T9 "Table 9 ‣ 12.4 Collaboration perception systems
    ‣ 12 Future research directions ‣ Recent Advancements in End-to-End Autonomous
    Driving using Deep Learning: A Survey")中进行了比较。MATLAB/Simulink [[147](#bib.bib147)]用于各种设置；它包含高效的绘图函数，并且能够与其他软件进行协同仿真，如CarSim
    [[148](#bib.bib148)]，简化了不同设置的创建。PreScan [[149](#bib.bib149)]能够模拟现实世界的环境，包括天气条件，而MATLAB和CarSim则不具备这一功能。它还支持MATLAB
    Simulink接口，使建模更加有效。Gazebo [[150](#bib.bib150)]以其高兼容性和与ROS的便捷连接而闻名。与CARLA和LGSVL
    [[151](#bib.bib151)]模拟器相比，使用Gazebo创建模拟环境需要更多的机械工作。CARLA和LGSVL提供了高质量的模拟框架，需要GPU处理单元才能以适当的速度和帧率运行。CARLA基于虚幻引擎，而LGSVL则基于Unity游戏引擎。API允许用户在CARLA和LGSVL中访问各种功能，从开发可定制的传感器到地图生成。LGSVL通常通过各种桥接与驾驶系统连接，而CARLA则允许通过ROS和Autoware进行内置桥接连接。'
- en: 12 Future research directions
  id: totrans-1823
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12 未来研究方向
- en: This section will highlight the possible research directions that can drive
    future advancements in the domain from the perspective of learning principles,
    safety, explainability, and others.
  id: totrans-1824
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将从学习原理、安全性、解释性等角度突显推动该领域未来发展的可能研究方向。
- en: 12.1 Learning robustness
  id: totrans-1825
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1 学习鲁棒性
- en: 'Current research in End-to-End autonomous driving mainly focuses on reinforcement
    learning (Section [6.2](#S6.SS2 "6.2 Reinforcement learning ‣ 6 Learning approaches
    for End-to-End system ‣ Recent Advancements in End-to-End Autonomous Driving using
    Deep Learning: A Survey")) and imitation learning (Section [6.1](#S6.SS1 "6.1
    Imitation learning ‣ 6 Learning approaches for End-to-End system ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey")) methods. RL
    trains agents by interacting with simulated environments, while IL learns from
    expert agents without extensive environmental interaction. However, challenges
    like distribution shift in IL and computational instability in RL highlight the
    need for further improvements.'
  id: totrans-1826
  prefs: []
  type: TYPE_NORMAL
  zh: '当前关于端到端自动驾驶的研究主要集中在强化学习（见[6.2节](#S6.SS2 "6.2 Reinforcement learning ‣ 6 Learning
    approaches for End-to-End system ‣ Recent Advancements in End-to-End Autonomous
    Driving using Deep Learning: A Survey")）和模仿学习（见[6.1节](#S6.SS1 "6.1 Imitation learning
    ‣ 6 Learning approaches for End-to-End system ‣ Recent Advancements in End-to-End
    Autonomous Driving using Deep Learning: A Survey")）方法上。强化学习通过与模拟环境的互动来训练代理，而模仿学习则通过专家代理的学习而无需广泛的环境互动。然而，模仿学习中的分布转移和强化学习中的计算不稳定性等挑战突显了进一步改进的必要性。'
- en: 12.2 Enhanced safety
  id: totrans-1827
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2 提升安全性
- en: 'Ensuring the behavioral safety of vehicles and accurately predicting uncertain
    behaviors are key aspects in safety research as discussed in Section [8](#S8 "8
    Safety ‣ Recent Advancements in End-to-End Autonomous Driving using Deep Learning:
    A Survey"). An effective system should be capable of handling various driving
    situations, contributing to comfortable and reliable transportation. To facilitate
    the widespread adoption of End-to-End approaches, it is essential to refine safety
    constraints and enhance their effectiveness.'
  id: totrans-1828
  prefs: []
  type: TYPE_NORMAL
  zh: '确保车辆行为安全和准确预测不确定行为是安全研究中的关键方面，如[8节](#S8 "8 Safety ‣ Recent Advancements in
    End-to-End Autonomous Driving using Deep Learning: A Survey")所讨论的。一个有效的系统应能处理各种驾驶情况，从而实现舒适和可靠的交通。为了促进端到端方法的广泛采用，有必要优化安全约束并提高其有效性。'
- en: 12.3 Advancing model explainability
  id: totrans-1829
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3 提升模型可解释性
- en: 'The lack of interpretability poses a new challenge for the advancement of End-to-End
    driving. However, ongoing efforts (Section [9](#S9 "9 Explainability ‣ Recent
    Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey"))
    are being made to address this issue by designing and generating interpretable
    features. These efforts have shown promising improvements in both performance
    and explainability. However, further exploration is required in global explanation
    strategies, including designing novel approaches to explain model actions leading
    to failures and suggesting potential solutions. Future research can also explore
    ways to improve feedback mechanisms, allowing users to understand the decision-making
    process and infuse confidence in the reliability of End-to-End driving systems.'
  id: totrans-1830
  prefs: []
  type: TYPE_NORMAL
  zh: '可解释性的缺乏对端到端驾驶的进步提出了新的挑战。然而，目前正在进行的努力（第[9节](#S9 "9 Explainability ‣ Recent Advancements
    in End-to-End Autonomous Driving using Deep Learning: A Survey")）致力于通过设计和生成可解释的特征来解决这一问题。这些努力在性能和可解释性方面都显示出了有希望的改进。然而，在全球解释策略方面仍需进一步探索，包括设计新的方法来解释模型在失败时的动作，并提出潜在的解决方案。未来的研究还可以探索改进反馈机制的方法，让用户理解决策过程，并增强对端到端驾驶系统可靠性的信心。'
- en: 12.4 Collaboration perception systems
  id: totrans-1831
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4 协作感知系统
- en: Vehicles can communicate directly utilizing collaborative perception to observe
    surroundings beyond their line of sight and field of view. This approach addresses
    issues related to occlusion and limited receptive fields. Cooperative or collaborative
    perception enables vehicles in the same area to communicate and jointly assess
    the scene.
  id: totrans-1832
  prefs: []
  type: TYPE_NORMAL
  zh: 车辆可以通过协作感知直接通信，从而观察超出其视线和视野范围的环境。这种方法解决了遮挡和有限感受字段的问题。合作或协作感知使得在同一地区的车辆能够通信并共同评估场景。
- en: 'Table 8: CUMULATIVE LIST OF DATASETS WITH THEIR DYNAMICS FOR END-TO-END TRAINING'
  id: totrans-1833
  prefs: []
  type: TYPE_NORMAL
  zh: '表 8: 数据集累计清单及其动态，用于端到端训练'
- en: '| Datasets | Year | Sensors Modalities | Content | Weather | Size | Location
    | License |'
  id: totrans-1834
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 年份 | 传感器模态 | 内容 | 天气 | 尺寸 | 位置 | 许可证 |'
- en: '|  |  |  Cameras  |  LiDAR  |  GNSS  |  Steering  |  Speed,'
  id: totrans-1835
  prefs: []
  type: TYPE_NORMAL
  zh: '|  |  | 相机 | LiDAR | GNSS | 转向 | 速度'
- en: Acceleration  |  Navigational
  id: totrans-1836
  prefs: []
  type: TYPE_NORMAL
  zh: 加速度 | 导航
- en: command  |  Route planner  |  Obstacles  |  Traffic  |  Raods  |  Sunny  |  Rain  |  Snow
    or Fog  |  |  |  |
  id: totrans-1837
  prefs: []
  type: TYPE_NORMAL
  zh: 指令 | 路线规划器 | 障碍物 | 交通 | 道路 | 晴天 | 雨天 | 雪天或雾天 |  |  |  |
- en: '| Udacity [[152](#bib.bib152)] | 2016 | ✓ | ✓ | ✓ | ✓ | ✓ |  |  | ✓ | ✓ |  |
    ✓ |  |  | 5h | Mountain View | MIT |'
  id: totrans-1838
  prefs: []
  type: TYPE_TB
  zh: '| Udacity [[152](#bib.bib152)] | 2016 | ✓ | ✓ | ✓ | ✓ | ✓ |  |  | ✓ | ✓ |  |
    ✓ |  |  | 5h | 山景城 | MIT |'
- en: '| Drive360 [[153](#bib.bib153)] | 2019 | ✓ |  | ✓ | ✓ | ✓ |  | ✓ | ✓ |  |  |
    ✓ | ✓ |  | 55h | Switzerland | Academic |'
  id: totrans-1839
  prefs: []
  type: TYPE_TB
  zh: '| Drive360 [[153](#bib.bib153)] | 2019 | ✓ |  | ✓ | ✓ | ✓ |  | ✓ | ✓ |  |  |
    ✓ | ✓ |  | 55h | 瑞士 | Academic |'
- en: '| Comma.ai 2016 [[154](#bib.bib154)] | 2016 | ✓ |  | ✓ | ✓ | ✓ |  |  |  |  |  |
    ✓ |  |  | 7h 15min | San Francisco | CC BY-NC-SA 3.0 |'
  id: totrans-1840
  prefs: []
  type: TYPE_TB
  zh: '| Comma.ai 2016 [[154](#bib.bib154)] | 2016 | ✓ |  | ✓ | ✓ | ✓ |  |  |  |  |  |
    ✓ |  |  | 7h 15min | 旧金山 | CC BY-NC-SA 3.0 |'
- en: '| Comma.ai 2019 [[155](#bib.bib155)] | 2019 | ✓ |  | ✓ | ✓ | ✓ |  |  |  |  |  |
    ✓ |  |  | 30h | San Jose California | MIT |'
  id: totrans-1841
  prefs: []
  type: TYPE_TB
  zh: '| Comma.ai 2019 [[155](#bib.bib155)] | 2019 | ✓ |  | ✓ | ✓ | ✓ |  |  |  |  |  |
    ✓ |  |  | 30h | 加州圣荷西 | MIT |'
- en: '| BDD 100 [[156](#bib.bib156)] | 2018 | ✓ |  | ✓ |  |  |  |  | ✓ | ✓ |  | ✓
    | ✓ |  | 1100h | US | Berkley |'
  id: totrans-1842
  prefs: []
  type: TYPE_TB
  zh: '| BDD 100 [[156](#bib.bib156)] | 2018 | ✓ |  | ✓ |  |  |  |  | ✓ | ✓ |  | ✓
    | ✓ |  | 1100h | 美国 | 伯克利 |'
- en: '| Oxford RobotCar [[2](#bib.bib2)] | 2019 | ✓ | ✓ | ✓ |  |  |  |  | ✓ | ✓ |  |
    ✓ | ✓ | ✓ | 214h | Oxford | CC BY-NC-SA 4.0 |'
  id: totrans-1843
  prefs: []
  type: TYPE_TB
  zh: '| Oxford RobotCar [[2](#bib.bib2)] | 2019 | ✓ | ✓ | ✓ |  |  |  |  | ✓ | ✓ |  |
    ✓ | ✓ | ✓ | 214h | 牛津 | CC BY-NC-SA 4.0 |'
- en: '| HDD [[157](#bib.bib157)] | 2018 | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |  | ✓ | ✓ | ✓ |  |  |  |
    104h | San Francisco | Academic |'
  id: totrans-1844
  prefs: []
  type: TYPE_TB
  zh: '| HDD [[157](#bib.bib157)] | 2018 | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |  | ✓ | ✓ | ✓ |  |  |  |
    104h | 旧金山 | Academic |'
- en: '| Brain4Cars [[158](#bib.bib158)] | 2016 | ✓ |  | ✓ |  | ✓ |  |  | ✓ | ✓ |  |  |  |  |
    1180 miles | US | Academic |'
  id: totrans-1845
  prefs: []
  type: TYPE_TB
  zh: '| Brain4Cars [[158](#bib.bib158)] | 2016 | ✓ |  | ✓ |  | ✓ |  |  | ✓ | ✓ |  |  |  |  |
    1180 miles | 美国 | Academic |'
- en: '| Li-Vi [[159](#bib.bib159), [160](#bib.bib160)] | 2018 | ✓ | ✓ | ✓ | ✓ | ✓
    |  |  |  |  |  |  |  |  | 10h | China | Academic |'
  id: totrans-1846
  prefs: []
  type: TYPE_TB
  zh: '| Li-Vi [[159](#bib.bib159), [160](#bib.bib160)] | 2018 | ✓ | ✓ | ✓ | ✓ | ✓
    |  |  |  |  |  |  |  |  | 10h | 中国 | Academic |'
- en: '| DDD17 [[161](#bib.bib161)] | 2017 | ✓ |  | ✓ | ✓ | ✓ |  |  | ✓ | ✓ |  | ✓
    | ✓ |  | 12h | Switzerland, Germany | CC-BY-NC-SA-4.0 |'
  id: totrans-1847
  prefs: []
  type: TYPE_TB
  zh: '| DDD17 [[161](#bib.bib161)] | 2017 | ✓ |  | ✓ | ✓ | ✓ |  |  | ✓ | ✓ |  | ✓
    | ✓ |  | 12h | 瑞士，德国 | CC-BY-NC-SA-4.0 |'
- en: '| A2D2 [[162](#bib.bib162)] | 2020 | ✓ | ✓ | ✓ | ✓ | ✓ |  |  | ✓ | ✓ |  | ✓
    |  |  | 390k frames | South of Germany | CC BY-ND 4.0 |'
  id: totrans-1848
  prefs: []
  type: TYPE_TB
  zh: '| A2D2 [[162](#bib.bib162)] | 2020 | ✓ | ✓ | ✓ | ✓ | ✓ |  |  | ✓ | ✓ |  | ✓
    |  |  | 390k 帧 | 德国南部 | CC BY-ND 4.0 |'
- en: '| nuScenes [[145](#bib.bib145)] | 2019 | ✓ | ✓ | ✓ |  |  |  |  | ✓ |  |  |
    ✓ | ✓ |  | 5.5h | Boston, Singapore | Non-commercial |'
  id: totrans-1849
  prefs: []
  type: TYPE_TB
  zh: '| nuScenes [[145](#bib.bib145)] | 2019 | ✓ | ✓ | ✓ |  |  |  |  | ✓ |  |  |
    ✓ | ✓ |  | 5.5小时 | 波士顿、新加坡 | 非商业 |'
- en: '| Waymo [[163](#bib.bib163)] | 2019 | ✓ | ✓ | ✓ | ✓ | ✓ |  |  | ✓ |  |  | ✓
    |  |  | 5.5h | California | Non-commercial |'
  id: totrans-1850
  prefs: []
  type: TYPE_TB
  zh: '| Waymo [[163](#bib.bib163)] | 2019 | ✓ | ✓ | ✓ | ✓ | ✓ |  |  | ✓ |  |  | ✓
    |  |  | 5.5小时 | 加利福尼亚 | 非商业 |'
- en: '| H3D [[46](#bib.bib46)] | 2019 | ✓ | ✓ | ✓ | ✓ | ✓ |  |  |  |  |  | ✓ |  |  |
    N/A | Japan | Academic |'
  id: totrans-1851
  prefs: []
  type: TYPE_TB
  zh: '| H3D [[46](#bib.bib46)] | 2019 | ✓ | ✓ | ✓ | ✓ | ✓ |  |  |  |  |  | ✓ |  |  |
    N/A | 日本 | 学术 |'
- en: '| HAD [[164](#bib.bib164)] | 2019 | ✓ |  | ✓ | ✓ | ✓ | ✓ |  |  | ✓ |  |  |  |  |
    30h | San Francisco | Academic |'
  id: totrans-1852
  prefs: []
  type: TYPE_TB
  zh: '| HAD [[164](#bib.bib164)] | 2019 | ✓ |  | ✓ | ✓ | ✓ | ✓ |  |  | ✓ |  |  |  |  |
    30小时 | 旧金山 | 学术 |'
- en: '| BIT [[165](#bib.bib165)] | 2015 | ✓ |  |  |  |  |  |  | ✓ |  |  | ✓ |  |  |
    9850 frames | Beijing | Academics |'
  id: totrans-1853
  prefs: []
  type: TYPE_TB
  zh: '| BIT [[165](#bib.bib165)] | 2015 | ✓ |  |  |  |  |  |  | ✓ |  |  | ✓ |  |  |
    9850帧 | 北京 | 学术 |'
- en: '| UA-DETRAC [[166](#bib.bib166)] | 2015 | ✓ |  |  |  |  |  |  | ✓ |  |  | ✓
    |  |  | 140k frames | Beijing, Tianjing | CC BY-NC-SA 3.0 |'
  id: totrans-1854
  prefs: []
  type: TYPE_TB
  zh: '| UA-DETRAC [[166](#bib.bib166)] | 2015 | ✓ |  |  |  |  |  |  | ✓ |  |  | ✓
    |  |  | 140千帧 | 北京、天津 | CC BY-NC-SA 3.0 |'
- en: '| DFG [[167](#bib.bib167)] | 2019 | ✓ |  |  |  |  |  |  |  | ✓ |  | ✓ | ✓ |  |
    7k+8k | Slovenia | CC BY-NC-SA 4.0 |'
  id: totrans-1855
  prefs: []
  type: TYPE_TB
  zh: '| DFG [[167](#bib.bib167)] | 2019 | ✓ |  |  |  |  |  |  |  | ✓ |  | ✓ | ✓ |  |
    7千+8千 | 斯洛文尼亚 | CC BY-NC-SA 4.0 |'
- en: '| Bosch [[168](#bib.bib168)] | 2017 | ✓ |  |  |  |  |  |  |  | ✓ |  | ✓ |  |  |
    8334 frames | Germany | Research Only |'
  id: totrans-1856
  prefs: []
  type: TYPE_TB
  zh: '| Bosch [[168](#bib.bib168)] | 2017 | ✓ |  |  |  |  |  |  |  | ✓ |  | ✓ |  |  |
    8334帧 | 德国 | 仅用于研究 |'
- en: '| Tencent 100k [[169](#bib.bib169)] | 2016 | ✓ |  |  |  |  |  |  |  | ✓ |  |
    ✓ |  |  | 30k | China | CC-BY-NC |'
  id: totrans-1857
  prefs: []
  type: TYPE_TB
  zh: '| Tencent 100k [[169](#bib.bib169)] | 2016 | ✓ |  |  |  |  |  |  |  | ✓ |  |
    ✓ |  |  | 30千 | 中国 | CC-BY-NC |'
- en: '| LISA [[170](#bib.bib170)] | 2012 | ✓ |  |  |  |  |  |  |  | ✓ |  | ✓ |  |  |
    20k | California | Research Only |'
  id: totrans-1858
  prefs: []
  type: TYPE_TB
  zh: '| LISA [[170](#bib.bib170)] | 2012 | ✓ |  |  |  |  |  |  |  | ✓ |  | ✓ |  |  |
    20千 | 加利福尼亚 | 仅用于研究 |'
- en: '| STSD [[171](#bib.bib171)] | 2011 | ✓ |  |  |  |  |  |  |  | ✓ |  | ✓ |  |  |
    2503 frames | Sweden | CC BY-SA 4.0 |'
  id: totrans-1859
  prefs: []
  type: TYPE_TB
  zh: '| STSD [[171](#bib.bib171)] | 2011 | ✓ |  |  |  |  |  |  |  | ✓ |  | ✓ |  |  |
    2503帧 | 瑞典 | CC BY-SA 4.0 |'
- en: '| GTSRB [[172](#bib.bib172)] | 2013 | ✓ |  |  |  |  |  |  |  | ✓ |  | ✓ | ✓
    |  | 50k | Germany | CC0 1.0 |'
  id: totrans-1860
  prefs: []
  type: TYPE_TB
  zh: '| GTSRB [[172](#bib.bib172)] | 2013 | ✓ |  |  |  |  |  |  |  | ✓ |  | ✓ | ✓
    |  | 50千 | 德国 | CC0 1.0 |'
- en: '| KUL [[173](#bib.bib173)] | 2013 | ✓ |  |  |  |  |  |  |  | ✓ |  | ✓ |  |  |
    16k | Flanders | CC0 1.0 |'
  id: totrans-1861
  prefs: []
  type: TYPE_TB
  zh: '| KUL [[173](#bib.bib173)] | 2013 | ✓ |  |  |  |  |  |  |  | ✓ |  | ✓ |  |  |
    16千 | 弗拉芒大区 | CC0 1.0 |'
- en: '| Caltech [[174](#bib.bib174)] | 2009 | ✓ |  |  |  |  |  |  | ✓ |  |  | ✓ |  |  |
    10 hours | California | CC4.0 |'
  id: totrans-1862
  prefs: []
  type: TYPE_TB
  zh: '| Caltech [[174](#bib.bib174)] | 2009 | ✓ |  |  |  |  |  |  | ✓ |  |  | ✓ |  |  |
    10小时 | 加利福尼亚 | CC4.0 |'
- en: '| CamVid [[175](#bib.bib175)] | 2009 | ✓ |  |  |  |  |  |  | ✓ | ✓ | ✓ | ✓
    |  |  | 22 min, 14 s | Cambridge | Academic |'
  id: totrans-1863
  prefs: []
  type: TYPE_TB
  zh: '| CamVid [[175](#bib.bib175)] | 2009 | ✓ |  |  |  |  |  |  | ✓ | ✓ | ✓ | ✓
    |  |  | 22分钟14秒 | 剑桥 | 学术 |'
- en: '| Ford[[176](#bib.bib176)] | 2018 | ✓ | ✓ |  |  |  |  |  | ✓ |  |  | ✓ |  |  |
    66 km | Michigan | CC-BY-NC-SA 4.0 |'
  id: totrans-1864
  prefs: []
  type: TYPE_TB
  zh: '| Ford[[176](#bib.bib176)] | 2018 | ✓ | ✓ |  |  |  |  |  | ✓ |  |  | ✓ |  |  |
    66公里 | 密歇根 | CC-BY-NC-SA 4.0 |'
- en: '| KITTI [[110](#bib.bib110)] | 2013 | ✓ | ✓ | ✓ |  |  |  |  | ✓ | ✓ | ✓ | ✓
    |  |  | 43 k | Karlsruhe | Apache License 2.0 |'
  id: totrans-1865
  prefs: []
  type: TYPE_TB
  zh: '| KITTI [[110](#bib.bib110)] | 2013 | ✓ | ✓ | ✓ |  |  |  |  | ✓ | ✓ | ✓ | ✓
    |  |  | 43千 | 卡尔斯鲁厄 | Apache 许可证 2.0 |'
- en: '| CityScapes [[177](#bib.bib177)] | 2016 | ✓ |  | ✓ |  |  |  |  | ✓ | ✓ |  |
    ✓ |  |  | 20+5 K frams | Germany, France, Scotland | Apache License 2.0 |'
  id: totrans-1866
  prefs: []
  type: TYPE_TB
  zh: '| CityScapes [[177](#bib.bib177)] | 2016 | ✓ |  | ✓ |  |  |  |  | ✓ | ✓ |  |
    ✓ |  |  | 20+5千帧 | 德国、法国、苏格兰 | Apache 许可证 2.0 |'
- en: '| Mapillary [[178](#bib.bib178)] | 2017 | ✓ |  |  |  |  |  |  | ✓ |  |  | ✓
    | ✓ | ✓ | 25000 frames | Germany | Research Only |'
  id: totrans-1867
  prefs: []
  type: TYPE_TB
  zh: '| Mapillary [[178](#bib.bib178)] | 2017 | ✓ |  |  |  |  |  |  | ✓ |  |  | ✓
    | ✓ | ✓ | 25000帧 | 德国 | 仅用于研究 |'
- en: '| ApolloScape [[146](#bib.bib146)] | 2018 | ✓ | ✓ |  |  |  |  |  | ✓ | ✓ |  |
    ✓ | ✓ | ✓ | 147 k frames | China | Non-commercial |'
  id: totrans-1868
  prefs: []
  type: TYPE_TB
  zh: '| ApolloScape [[146](#bib.bib146)] | 2018 | ✓ | ✓ |  |  |  |  |  | ✓ | ✓ |  |
    ✓ | ✓ | ✓ | 147千帧 | 中国 | 非商业 |'
- en: '| VERI-Wild [[179](#bib.bib179)] | 2019 | ✓ |  |  |  |  |  |  | ✓ |  |  | ✓
    | ✓ |  | 125, 280 hours | China | Research Only |'
  id: totrans-1869
  prefs: []
  type: TYPE_TB
  zh: '| VERI-Wild [[179](#bib.bib179)] | 2019 | ✓ |  |  |  |  |  |  | ✓ |  |  | ✓
    | ✓ |  | 125, 280小时 | 中国 | 仅用于研究 |'
- en: '| D2 -City [[180](#bib.bib180)] | 2019 | ✓ |  |  |  |  |  |  | ✓ |  | ✓ | ✓
    | ✓ |  | 10000 video | China | Research Only |'
  id: totrans-1870
  prefs: []
  type: TYPE_TB
  zh: '| D2 -City [[180](#bib.bib180)] | 2019 | ✓ |  |  |  |  |  |  | ✓ |  | ✓ | ✓
    | ✓ |  | 10000视频 | 中国 | 仅用于研究 |'
- en: '| DriveSeg [[181](#bib.bib181)] | 2020 | ✓ |  |  |  |  |  |  | ✓ | ✓ | ✓ |
    ✓ |  |  | 500 minutes | Massachusetts | CC BY-NC 4.0 |'
  id: totrans-1871
  prefs: []
  type: TYPE_TB
  zh: '| DriveSeg [[181](#bib.bib181)] | 2020 | ✓ |  |  |  |  |  |  | ✓ | ✓ | ✓ |
    ✓ |  |  | 500分钟 | 马萨诸塞州 | CC BY-NC 4.0 |'
- en: 'Table 9: PROMINENT SIMULATORS USED FOR CREATING VIRTUAL ENVIRONMENTS FOR END-TO-END
    SYSTEMS'
  id: totrans-1872
  prefs: []
  type: TYPE_NORMAL
  zh: '表 9: 用于创建端到端系统虚拟环境的主要模拟器'
- en: '|'
  id: totrans-1873
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Simulators &#124;'
  id: totrans-1874
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Simulators &#124;'
- en: '|'
  id: totrans-1875
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; MATLAB &#124;'
  id: totrans-1876
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; MATLAB &#124;'
- en: '&#124; [[147](#bib.bib147)] &#124;'
  id: totrans-1877
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [[147](#bib.bib147)] &#124;'
- en: '|'
  id: totrans-1878
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CarSim &#124;'
  id: totrans-1879
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CarSim &#124;'
- en: '&#124; [[148](#bib.bib148)] &#124;'
  id: totrans-1880
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [[148](#bib.bib148)] &#124;'
- en: '|'
  id: totrans-1881
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PreScan &#124;'
  id: totrans-1882
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PreScan &#124;'
- en: '&#124; [[149](#bib.bib149)] &#124;'
  id: totrans-1883
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [[149](#bib.bib149)] &#124;'
- en: '|'
  id: totrans-1884
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CARLA &#124;'
  id: totrans-1885
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CARLA &#124;'
- en: '&#124; [[109](#bib.bib109)] &#124;'
  id: totrans-1886
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [[109](#bib.bib109)] &#124;'
- en: '|'
  id: totrans-1887
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; LGSVL &#124;'
  id: totrans-1888
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LGSVL &#124;'
- en: '&#124; [[151](#bib.bib151)] &#124;'
  id: totrans-1889
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [[151](#bib.bib151)] &#124;'
- en: '|'
  id: totrans-1890
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-1891
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Sensors &#124;'
  id: totrans-1892
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 传感器 &#124;'
- en: '&#124; support &#124;'
  id: totrans-1893
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 支持 &#124;'
- en: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-1894
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: '|'
  id: totrans-1895
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Weather &#124;'
  id: totrans-1896
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 天气 &#124;'
- en: '&#124; condition &#124;'
  id: totrans-1897
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 条件 &#124;'
- en: '|  |  | ✓ | ✓ | ✓ |'
  id: totrans-1898
  prefs: []
  type: TYPE_TB
  zh: '|  |  | ✓ | ✓ | ✓ |'
- en: '|'
  id: totrans-1899
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Camera &#124;'
  id: totrans-1900
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 相机 &#124;'
- en: '&#124; calibration &#124;'
  id: totrans-1901
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 校准 &#124;'
- en: '| ✓ |  | ✓ | ✓ |  |'
  id: totrans-1902
  prefs: []
  type: TYPE_TB
  zh: '| ✓ |  | ✓ | ✓ |  |'
- en: '|'
  id: totrans-1903
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Path &#124;'
  id: totrans-1904
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 路径 &#124;'
- en: '&#124; planning &#124;'
  id: totrans-1905
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 规划 &#124;'
- en: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-1906
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: '|'
  id: totrans-1907
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Vehicle &#124;'
  id: totrans-1908
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 车辆 &#124;'
- en: '&#124; dynamics &#124;'
  id: totrans-1909
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 动态 &#124;'
- en: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-1910
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: '|'
  id: totrans-1911
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Virtual &#124;'
  id: totrans-1912
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 虚拟 &#124;'
- en: '&#124; environment &#124;'
  id: totrans-1913
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 环境 &#124;'
- en: '|  | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-1914
  prefs: []
  type: TYPE_TB
  zh: '|  | ✓ | ✓ | ✓ | ✓ |'
- en: '|'
  id: totrans-1915
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Infrastructure &#124;'
  id: totrans-1916
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基础设施 &#124;'
- en: '&#124; fabrication &#124;'
  id: totrans-1917
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 制造 &#124;'
- en: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-1918
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: '|'
  id: totrans-1919
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Scenarios &#124;'
  id: totrans-1920
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 场景 &#124;'
- en: '&#124; simulator &#124;'
  id: totrans-1921
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模拟器 &#124;'
- en: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-1922
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: '|'
  id: totrans-1923
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Ground &#124;'
  id: totrans-1924
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 地面 &#124;'
- en: '&#124; truth &#124;'
  id: totrans-1925
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 真实性 &#124;'
- en: '| ✓ |  |  | ✓ | ✓ |'
  id: totrans-1926
  prefs: []
  type: TYPE_TB
  zh: '| ✓ |  |  | ✓ | ✓ |'
- en: '|'
  id: totrans-1927
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Simulator &#124;'
  id: totrans-1928
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模拟器 &#124;'
- en: '&#124; connectivity &#124;'
  id: totrans-1929
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 连接性 &#124;'
- en: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-1930
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: '|'
  id: totrans-1931
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; System &#124;'
  id: totrans-1932
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 系统 &#124;'
- en: '&#124; scalability &#124;'
  id: totrans-1933
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可扩展性 &#124;'
- en: '|  |  |  | ✓ | ✓ |'
  id: totrans-1934
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | ✓ | ✓ |'
- en: '|'
  id: totrans-1935
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Open &#124;'
  id: totrans-1936
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 开放 &#124;'
- en: '&#124; source &#124;'
  id: totrans-1937
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 来源 &#124;'
- en: '|  |  |  | ✓ | ✓ |'
  id: totrans-1938
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | ✓ | ✓ |'
- en: '|'
  id: totrans-1939
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; System &#124;'
  id: totrans-1940
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 系统 &#124;'
- en: '&#124; stable &#124;'
  id: totrans-1941
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 稳定性 &#124;'
- en: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-1942
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: '|'
  id: totrans-1943
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; System &#124;'
  id: totrans-1944
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 系统 &#124;'
- en: '&#124; portable &#124;'
  id: totrans-1945
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 便携 &#124;'
- en: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-1946
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: '|'
  id: totrans-1947
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; API &#124;'
  id: totrans-1948
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; API &#124;'
- en: '&#124; flexibility &#124;'
  id: totrans-1949
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 灵活性 &#124;'
- en: '| ✓ | ✓ |  | ✓ | ✓ |'
  id: totrans-1950
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ |  | ✓ | ✓ |'
- en: Cooperative perception methods [[182](#bib.bib182), [183](#bib.bib183), [184](#bib.bib184)]
    include V2V (vehicle-to-vehicle), V2I (vehicle-to-infrastructure), and V2X (vehicle-to-everything)
    modes. Future works should focus on enhancing the transmission efficiency within
    collaboration systems while safeguarding data privacy.
  id: totrans-1951
  prefs: []
  type: TYPE_NORMAL
  zh: 合作感知方法 [[182](#bib.bib182), [183](#bib.bib183), [184](#bib.bib184)] 包括 V2V（车与车之间）、V2I（车与基础设施之间）和
    V2X（车与一切之间）模式。未来的工作应关注提升协作系统中的传输效率，同时保护数据隐私。
- en: 12.5 Large language and vision models
  id: totrans-1952
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5 大型语言和视觉模型
- en: Large vision models have emerged as a prominent trend in AI. By harnessing the
    advancements in these models, various domains can benefit from their integration.
    Visual prompts have become essential aids for understanding visuals across diverse
    domains and enhancing model capacity for interpreting visual data. Presently,
    SAM-Track [[185](#bib.bib185)] for object tracking and VIMA [[186](#bib.bib186)]
    for robot action manipulation showcase potential, implying that these large models
    can optimize visual recognition systems. Moreover, we can effectively utilize
    large language and vision models through transfer learning, domain adaptation,
    and fine-tuning. We can transfer insights from a larger model to a smaller one,
    emphasizing the importance of compact transfer of knowledge and applying it to
    novel tasks while upholding performance and adaptability, especially in contexts
    like autonomous driving. Future efforts must focus on designing large vision models
    tailored explicitly to autonomous driving and prompt fine-tuning to guide tasks
    related to perception and control.
  id: totrans-1953
  prefs: []
  type: TYPE_NORMAL
  zh: 大型视觉模型已成为人工智能的一个突出趋势。通过利用这些模型的进步，各个领域都可以从其集成中受益。视觉提示已成为理解各种领域视觉信息和提升模型解释视觉数据能力的关键工具。目前，SAM-Track
    [[185](#bib.bib185)] 用于物体跟踪，VIMA [[186](#bib.bib186)] 用于机器人动作操控，展示了其潜力，暗示这些大型模型可以优化视觉识别系统。此外，我们可以通过迁移学习、领域适应和微调有效地利用大型语言和视觉模型。我们可以将较大模型的见解转移到较小模型上，强调紧凑知识转移的重要性，并将其应用于新任务，同时保持性能和适应性，特别是在自动驾驶等领域。未来的努力必须专注于设计专门针对自动驾驶的大型视觉模型，并进行及时微调以指导感知和控制相关任务。
- en: 13 Conclusion
  id: totrans-1954
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13 结论
- en: Over the past few years, there has been significant interest in End-to-End autonomous
    driving due to the simplicity of its design compared to conventional modular autonomous
    driving. We develop a taxonomy based on modalities, learning, and training methodology
    and investigate the potential of leveraging domain adaptation approaches to optimize
    the training process. Furthermore, the paper explores evaluation framework that
    encompasses both open and closed-loop assessments, enabling a comprehensive analysis
    of system performance. To facilitate further research and development in the domain,
    we compile a summarized list of advancements, publicly available datasets and
    simulators. The paper also explores potential solutions proposed by different
    articles regarding safety and explainability. Despite the impressive performance
    of End-to-End approaches, there is a need for continued exploration and improvement
    in safety and interpretability to achieve broader technology acceptance.
  id: totrans-1955
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，由于相较于传统的模块化自主驾驶设计更为简单，端到端自主驾驶引起了显著的关注。我们基于模态、学习和训练方法开发了一个分类体系，并研究了利用领域适应方法来优化训练过程的潜力。此外，本文探讨了一个评估框架，该框架涵盖了开放和闭环评估，能够对系统性能进行全面分析。为了促进该领域的进一步研究和发展，我们汇总了技术进展、公开可用的数据集和模拟器的总结清单。本文还探讨了不同文献提出的关于安全性和可解释性的潜在解决方案。尽管端到端方法表现出色，但仍需要继续探索和改进安全性和可解释性，以实现更广泛的技术接受。
- en: References
  id: totrans-1956
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] C. Chen, A. Seff, A. Kornhauser, J. Xiao, Deepdriving: Learning affordance
    for direct perception in autonomous driving, in: Proceedings of the IEEE international
    conference on computer vision, 2015, pp. 2722–2730.'
  id: totrans-1957
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] C. Chen, A. Seff, A. Kornhauser, J. Xiao, Deepdriving：学习自主驾驶中的直接感知能力，发表于：IEEE计算机视觉国际会议论文集，2015，pp.
    2722–2730。'
- en: '[2] W. Maddern, G. Pascoe, C. Linegar, P. Newman, 1 year, 1000 km: The oxford
    robotcar dataset, The International Journal of Robotics Research 36 (1) (2017)
    3–15.'
  id: totrans-1958
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] W. Maddern, G. Pascoe, C. Linegar, P. Newman, 1年，1000公里：牛津机器人车数据集，《国际机器人研究杂志》36
    (1) (2017) 3–15。'
- en: '[3] N. Akai, L. Y. Morales, T. Yamaguchi, E. Takeuchi, Y. Yoshihara, H. Okuda,
    T. Suzuki, Y. Ninomiya, Autonomous driving based on accurate localization using
    multilayer lidar and dead reckoning, in: 2017 IEEE 20th International Conference
    on Intelligent Transportation Systems (ITSC), IEEE, 2017, pp. 1–6.'
  id: totrans-1959
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] N. Akai, L. Y. Morales, T. Yamaguchi, E. Takeuchi, Y. Yoshihara, H. Okuda,
    T. Suzuki, Y. Ninomiya, 基于多层激光雷达和航位推算的精准定位自主驾驶，发表于：2017 IEEE第20届智能交通系统国际会议（ITSC），IEEE，2017，pp.
    1–6。'
- en: '[4] J. Kong, M. Pfeiffer, G. Schildbach, F. Borrelli, Kinematic and dynamic
    vehicle models for autonomous driving control design, in: 2015 IEEE intelligent
    vehicles symposium (IV), IEEE, 2015, pp. 1094–1099.'
  id: totrans-1960
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] J. Kong, M. Pfeiffer, G. Schildbach, F. Borrelli, 自主驾驶控制设计中的运动学和动力学车辆模型，发表于：2015
    IEEE智能车辆研讨会（IV），IEEE，2015，pp. 1094–1099。'
- en: '[5] P. Zhao, J. Chen, Y. Song, X. Tao, T. Xu, T. Mei, Design of a control system
    for an autonomous vehicle based on adaptive-pid, International Journal of Advanced
    Robotic Systems 9 (2) (2012) 44.'
  id: totrans-1961
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] P. Zhao, J. Chen, Y. Song, X. Tao, T. Xu, T. Mei, 基于自适应PID的自主车辆控制系统设计，《先进机器人系统国际期刊》9
    (2) (2012) 44。'
- en: '[6] N. Hanselmann, K. Renz, K. Chitta, A. Bhattacharyya, A. Geiger, King: Generating
    safety-critical driving scenarios for robust imitation via kinematics gradients,
    in: Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October
    23–27, 2022, Proceedings, Part XXXVIII, Springer, 2022, pp. 335–352.'
  id: totrans-1962
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] N. Hanselmann, K. Renz, K. Chitta, A. Bhattacharyya, A. Geiger, King：通过运动学梯度生成安全关键驾驶场景用于稳健的模仿，发表于：计算机视觉–ECCV
    2022：第17届欧洲会议，特拉维夫，以色列，2022年10月23–27日，论文集，第三十八部分，Springer，2022，pp. 335–352。'
- en: '[7] K. Chitta, A. Prakash, B. Jaeger, Z. Yu, K. Renz, A. Geiger, Transfuser:
    Imitation with transformer-based sensor fusion for autonomous driving, IEEE Transactions
    on Pattern Analysis and Machine Intelligence (2022).'
  id: totrans-1963
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] K. Chitta, A. Prakash, B. Jaeger, Z. Yu, K. Renz, A. Geiger, Transfuser：基于变换器的传感器融合用于自主驾驶，《IEEE模式分析与机器智能学报》（2022）。'
- en: '[8] H. Shao, L. Wang, R. Chen, H. Li, Y. Liu, Safety-enhanced autonomous driving
    using interpretable sensor fusion transformer, in: Conference on Robot Learning,
    PMLR, 2023, pp. 726–737.'
  id: totrans-1964
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] H. Shao, L. Wang, R. Chen, H. Li, Y. Liu, 安全增强型自主驾驶使用可解释的传感器融合变换器，发表于：机器人学习会议，PMLR，2023，pp.
    726–737。'
- en: '[9] Y. Hu, J. Yang, L. Chen, K. Li, C. Sima, X. Zhu, S. Chai, S. Du, T. Lin,
    W. Wang, L. Lu, X. Jia, Q. Liu, J. Dai, Y. Qiao, H. Li, Planning-oriented autonomous
    driving, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, 2023.'
  id: totrans-1965
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Y. Hu, J. Yang, L. Chen, K. Li, C. Sima, X. Zhu, S. Chai, S. Du, T. Lin,
    W. Wang, L. Lu, X. Jia, Q. Liu, J. Dai, Y. Qiao, H. Li, 面向规划的自动驾驶，收录于《IEEE/CVF计算机视觉与模式识别会议论文集》，2023年。'
- en: '[10] D. Chen, P. Krähenbühl, Learning from all vehicles, in: Proceedings of
    the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp.
    17222–17231.'
  id: totrans-1966
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] D. Chen, P. Krähenbühl, 从所有车辆中学习，收录于《IEEE/CVF计算机视觉与模式识别会议论文集》，2022年，第17222–17231页。'
- en: '[11] Q. Zhang, Z. Peng, B. Zhou, Learning to drive by watching youtube videos:
    Action-conditioned contrastive policy pretraining, in: Computer Vision–ECCV 2022:
    17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings,
    Part XXVI, Springer, 2022, pp. 111–128.'
  id: totrans-1967
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Q. Zhang, Z. Peng, B. Zhou, 通过观看YouTube视频学习驾驶：基于动作的对比策略预训练，收录于《计算机视觉–ECCV
    2022: 第17届欧洲会议》，以色列特拉维夫，2022年10月23日至27日，会议录，第二十六部分，Springer出版社，2022年，第111–128页。'
- en: '[12] K. Chitta, A. Prakash, A. Geiger, Neat: Neural attention fields for end-to-end
    autonomous driving, in: Proceedings of the IEEE/CVF International Conference on
    Computer Vision, 2021, pp. 15793–15803.'
  id: totrans-1968
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] K. Chitta, A. Prakash, A. Geiger, Neat: 用于端到端自动驾驶的神经注意力场，收录于《IEEE/CVF国际计算机视觉会议论文集》，2021年，第15793–15803页。'
- en: '[13] P. Wu, X. Jia, L. Chen, J. Yan, H. Li, Y. Qiao, Trajectory-guided control
    prediction for end-to-end autonomous driving: A simple yet strong baseline, in:
    NeurIPS, 2022.'
  id: totrans-1969
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] P. Wu, X. Jia, L. Chen, J. Yan, H. Li, Y. Qiao, 端到端自动驾驶的轨迹引导控制预测：一种简单却强大的基线，收录于NeurIPS，2022年。'
- en: '[14] A. Prakash, K. Chitta, A. Geiger, Multi-modal fusion transformer for end-to-end
    autonomous driving, in: Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition, 2021, pp. 7077–7087.'
  id: totrans-1970
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] A. Prakash, K. Chitta, A. Geiger, 用于端到端自动驾驶的多模态融合变换器，收录于《IEEE/CVF计算机视觉与模式识别会议论文集》，2021年，第7077–7087页。'
- en: '[15] P. Wu, L. Chen, H. Li, X. Jia, J. Yan, Y. Qiao, Policy pre-training for
    end-to-end autonomous driving via self-supervised geometric modeling, arXiv preprint
    arXiv:2301.01006 (2023).'
  id: totrans-1971
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] P. Wu, L. Chen, H. Li, X. Jia, J. Yan, Y. Qiao, 通过自监督几何建模进行端到端自动驾驶的策略预训练，arXiv预印本
    arXiv:2301.01006（2023年）。'
- en: '[16] H. Shao, L. Wang, R. Chen, S. L. Waslander, H. Li, Y. Liu, Reasonnet:
    End-to-end driving with temporal and global reasoning, in: Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, pp. 13723–13733.'
  id: totrans-1972
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] H. Shao, L. Wang, R. Chen, S. L. Waslander, H. Li, Y. Liu, Reasonnet:
    具有时间和全局推理的端到端驾驶，收录于《IEEE/CVF计算机视觉与模式识别会议论文集》，2023年，第13723–13733页。'
- en: '[17] Y. Xiao, F. Codevilla, D. P. Bustamante, A. M. Lopez, Scaling self-supervised
    end-to-end driving with multi-view attention learning, arXiv preprint arXiv:2302.03198
    (2023).'
  id: totrans-1973
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Y. Xiao, F. Codevilla, D. P. Bustamante, A. M. Lopez, 通过多视角注意力学习扩展自监督端到端驾驶，arXiv预印本
    arXiv:2302.03198（2023年）。'
- en: '[18] K. Renz, K. Chitta, O.-B. Mercea, A. S. Koepke, Z. Akata, A. Geiger, Plant:
    Explainable planning transformers via object-level representations, in: CoRL 2022
    Workshop on Learning, Perception, and Abstraction for Long-Horizon Planning.'
  id: totrans-1974
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] K. Renz, K. Chitta, O.-B. Mercea, A. S. Koepke, Z. Akata, A. Geiger, Plant:
    通过对象级表示实现可解释的规划变换器，收录于CoRL 2022学习、感知与抽象长远规划研讨会。'
- en: '[19] X. Jia, P. Wu, L. Chen, J. Xie, C. He, J. Yan, H. Li, Think twice before
    driving: Towards scalable decoders for end-to-end autonomous driving, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, pp.
    21983–21994.'
  id: totrans-1975
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] X. Jia, P. Wu, L. Chen, J. Xie, C. He, J. Yan, H. Li, 驾驶前三思：面向端到端自动驾驶的可扩展解码器，收录于《IEEE/CVF计算机视觉与模式识别会议论文集》，2023年，第21983–21994页。'
- en: '[20] S. Hu, L. Chen, P. Wu, H. Li, J. Yan, D. Tao, St-p3: End-to-end vision-based
    autonomous driving via spatial-temporal feature learning, in: Computer Vision–ECCV
    2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings,
    Part XXXVIII, Springer, 2022, pp. 533–549.'
  id: totrans-1976
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] S. Hu, L. Chen, P. Wu, H. Li, J. Yan, D. Tao, St-p3: 通过时空特征学习实现端到端的基于视觉的自动驾驶，收录于《计算机视觉–ECCV
    2022: 第17届欧洲会议》，以色列特拉维夫，2022年10月23日至27日，会议录，第三十八部分，Springer出版社，2022年，第533–549页。'
- en: '[21] Q. Li, Z. Peng, H. Wu, L. Feng, B. Zhou, Human-ai shared control via policy
    dissection, Advances in Neural Information Processing Systems 35 (2022) 8853–8867.'
  id: totrans-1977
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Q. Li, Z. Peng, H. Wu, L. Feng, B. Zhou, 通过策略分解实现人机共享控制，《神经信息处理系统进展》第35卷（2022年）第8853–8867页。'
- en: '[22] H. Wu, S. Yunas, S. Rowlands, W. Ruan, J. Wahlstrom, "adversarial driving:
    Attacking end-to-end autonomous driving", in ieee intelligent vehicles symposium
    (iv) (2023).'
  id: totrans-1978
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] H. Wu, S. Yunas, S. Rowlands, W. Ruan, J. Wahlstrom，“对抗性驾驶：攻击端到端自动驾驶”，在IEEE智能车辆研讨会（IV）（2023）。'
- en: '[23] F. Codevilla, E. Santana, A. M. López, A. Gaidon, Exploring the limitations
    of behavior cloning for autonomous driving, in: Proceedings of the IEEE/CVF International
    Conference on Computer Vision, 2019, pp. 9329–9338.'
  id: totrans-1979
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] F. Codevilla, E. Santana, A. M. López, A. Gaidon，探索行为克隆在自动驾驶中的局限性，见：IEEE/CVF国际计算机视觉大会论文集，2019，pp.
    9329–9338。'
- en: '[24] J. Hawke, R. Shen, C. Gurau, S. Sharma, D. Reda, N. Nikolov, P. Mazur,
    S. Micklethwaite, N. Griffiths, A. Shah, et al., Urban driving with conditional
    imitation learning, in: 2020 IEEE International Conference on Robotics and Automation
    (ICRA), IEEE, 2020, pp. 251–257.'
  id: totrans-1980
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] J. Hawke, R. Shen, C. Gurau, S. Sharma, D. Reda, N. Nikolov, P. Mazur,
    S. Micklethwaite, N. Griffiths, A. Shah 等，具有条件模仿学习的城市驾驶，见：2020 IEEE国际机器人与自动化会议（ICRA），IEEE，2020，pp.
    251–257。'
- en: '[25] E. Yurtsever, J. Lambert, A. Carballo, K. Takeda, A survey of autonomous
    driving: Common practices and emerging technologies, IEEE access 8 (2020) 58443–58469.'
  id: totrans-1981
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] E. Yurtsever, J. Lambert, A. Carballo, K. Takeda，自动驾驶综述：常见实践与新兴技术，《IEEE
    Access》8 (2020) 58443–58469。'
- en: '[26] L. Le Mero, D. Yi, M. Dianati, A. Mouzakitis, A survey on imitation learning
    techniques for end-to-end autonomous vehicles, IEEE Transactions on Intelligent
    Transportation Systems 23 (9) (2022) 14128–14147.'
  id: totrans-1982
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] L. Le Mero, D. Yi, M. Dianati, A. Mouzakitis，关于端到端自动驾驶车辆的模仿学习技术的综述，《IEEE智能交通系统期刊》23
    (9) (2022) 14128–14147。'
- en: '[27] Z. Zhu, H. Zhao, A survey of deep rl and il for autonomous driving policy
    learning, IEEE Transactions on Intelligent Transportation Systems 23 (9) (2021)
    14043–14065.'
  id: totrans-1983
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Z. Zhu, H. Zhao，深度强化学习和模仿学习在自动驾驶策略学习中的综述，《IEEE智能交通系统期刊》23 (9) (2021) 14043–14065。'
- en: '[28] A. Tampuu, T. Matiisen, M. Semikin, D. Fishman, N. Muhammad, A survey
    of end-to-end driving: Architectures and training methods, IEEE Transactions on
    Neural Networks and Learning Systems 33 (4) (2020) 1364–1384.'
  id: totrans-1984
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] A. Tampuu, T. Matiisen, M. Semikin, D. Fishman, N. Muhammad，端到端驾驶的综述：架构和训练方法，《IEEE神经网络与学习系统期刊》33
    (4) (2020) 1364–1384。'
- en: '[29] L. Chen, P. Wu, K. Chitta, B. Jaeger, A. Geiger, H. Li, End-to-end autonomous
    driving: Challenges and frontiers, arXiv 2306.16927 (2023).'
  id: totrans-1985
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] L. Chen, P. Wu, K. Chitta, B. Jaeger, A. Geiger, H. Li，端到端自动驾驶：挑战与前沿，arXiv
    2306.16927 (2023)。'
- en: '[30] J. Levinson, J. Askeland, J. Becker, J. Dolson, D. Held, S. Kammel, J. Z.
    Kolter, D. Langer, O. Pink, V. Pratt, et al., Towards fully autonomous driving:
    Systems and algorithms, in: 2011 IEEE intelligent vehicles symposium (IV), IEEE,
    2011, pp. 163–168.'
  id: totrans-1986
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] J. Levinson, J. Askeland, J. Becker, J. Dolson, D. Held, S. Kammel, J.
    Z. Kolter, D. Langer, O. Pink, V. Pratt 等，迈向完全自动驾驶：系统和算法，见：2011 IEEE智能车辆研讨会（IV），IEEE，2011，pp.
    163–168。'
- en: '[31] C. Urmson, J. Anhalt, D. Bagnell, C. Baker, R. Bittner, M. Clark, J. Dolan,
    D. Duggins, T. Galatali, C. Geyer, et al., Autonomous driving in urban environments:
    Boss and the urban challenge, Journal of field Robotics 25 (8) (2008) 425–466.'
  id: totrans-1987
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] C. Urmson, J. Anhalt, D. Bagnell, C. Baker, R. Bittner, M. Clark, J. Dolan,
    D. Duggins, T. Galatali, C. Geyer 等，城市环境中的自动驾驶：Boss和城市挑战，《野外机器人学期刊》25 (8) (2008)
    425–466。'
- en: '[32] J. Wei, J. M. Snider, J. Kim, J. M. Dolan, R. Rajkumar, B. Litkouhi, Towards
    a viable autonomous driving research platform, in: 2013 IEEE Intelligent Vehicles
    Symposium (IV), IEEE, 2013, pp. 763–770.'
  id: totrans-1988
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] J. Wei, J. M. Snider, J. Kim, J. M. Dolan, R. Rajkumar, B. Litkouhi，迈向可行的自动驾驶研究平台，见：2013
    IEEE智能车辆研讨会（IV），IEEE，2013，pp. 763–770。'
- en: '[33] H. Somerville, P. Lienert, A. Sage, Uber’s use of fewer safety sensors
    prompts questions after arizona crash, Business news, Reuters (2018).'
  id: totrans-1989
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] H. Somerville, P. Lienert, A. Sage，Uber减少安全传感器的使用引发亚利桑那州撞车事件后的质疑，《商业新闻》，路透社（2018）。'
- en: '[34] J. Ziegler, P. Bender, M. Schreiber, H. Lategahn, T. Strauss, C. Stiller,
    T. Dang, U. Franke, N. Appenrodt, C. G. Keller, et al., Making bertha drive—an
    autonomous journey on a historic route, IEEE Intelligent transportation systems
    magazine 6 (2) (2014) 8–20.'
  id: totrans-1990
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] J. Ziegler, P. Bender, M. Schreiber, H. Lategahn, T. Strauss, C. Stiller,
    T. Dang, U. Franke, N. Appenrodt, C. G. Keller 等，制作Bertha进行驾驶——在历史路线上的一次自动驾驶之旅，《IEEE智能交通系统杂志》6
    (2) (2014) 8–20。'
- en: '[35] S. Kuutti, S. Fallah, K. Katsaros, M. Dianati, F. Mccullough, A. Mouzakitis,
    A survey of the state-of-the-art localization techniques and their potentials
    for autonomous vehicle applications, IEEE Internet of Things Journal 5 (2) (2018)
    829–846.'
  id: totrans-1991
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] S. Kuutti, S. Fallah, K. Katsaros, M. Dianati, F. Mccullough, A. Mouzakitis，最先进的定位技术及其在自动驾驶应用中的潜力的综述，《IEEE物联网期刊》5
    (2) (2018) 829–846。'
- en: '[36] L. Bergamini, Y. Ye, O. Scheel, L. Chen, C. Hu, L. Del Pero, B. Osiński,
    H. Grimmett, P. Ondruska, Simnet: Learning reactive self-driving simulations from
    real-world observations, in: 2021 IEEE International Conference on Robotics and
    Automation (ICRA), IEEE, 2021, pp. 5119–5125.'
  id: totrans-1992
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] L. Bergamini, Y. Ye, O. Scheel, L. Chen, C. Hu, L. Del Pero, B. Osiński,
    H. Grimmett, P. Ondruska, Simnet: 从真实世界观察中学习反应性自动驾驶模拟，见：2021 IEEE 国际机器人与自动化会议（ICRA），IEEE，2021，第5119–5125页。'
- en: '[37] C.-F. Lin, A. G. Ulsoy, D. J. LeBlanc, Vehicle dynamics and external disturbance
    estimation for vehicle path prediction, IEEE Transactions on Control Systems Technology
    8 (3) (2000) 508–518.'
  id: totrans-1993
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] C.-F. Lin, A. G. Ulsoy, D. J. LeBlanc, 车辆动力学与外部干扰估计用于车辆路径预测，IEEE 控制系统技术汇刊
    8 (3) (2000) 508–518。'
- en: '[38] T. Phan-Minh, E. C. Grigore, F. A. Boulton, O. Beijbom, E. M. Wolff, Covernet:
    Multimodal behavior prediction using trajectory sets, in: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, 2020, pp. 14074–14083.'
  id: totrans-1994
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] T. Phan-Minh, E. C. Grigore, F. A. Boulton, O. Beijbom, E. M. Wolff, Covernet:
    使用轨迹集合的多模态行为预测，见：IEEE/CVF 计算机视觉与模式识别会议论文集，2020，第14074–14083页。'
- en: '[39] T. Gilles, S. Sabatini, D. Tsishkou, B. Stanciulescu, F. Moutarde, Home:
    Heatmap output for future motion estimation, in: 2021 IEEE International Intelligent
    Transportation Systems Conference (ITSC), IEEE, 2021, pp. 500–507.'
  id: totrans-1995
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] T. Gilles, S. Sabatini, D. Tsishkou, B. Stanciulescu, F. Moutarde, Home:
    未来运动估计的热图输出，见：2021 IEEE 国际智能交通系统会议（ITSC），IEEE，2021，第500–507页。'
- en: '[40] M. Ye, T. Cao, Q. Chen, Tpcn: Temporal point cloud networks for motion
    forecasting, in: Proceedings of the IEEE/CVF Conference on Computer Vision and
    Pattern Recognition (CVPR), 2021, pp. 11318–11327.'
  id: totrans-1996
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] M. Ye, T. Cao, Q. Chen, Tpcn: 时序点云网络用于运动预测，见：IEEE/CVF 计算机视觉与模式识别会议（CVPR）论文集，2021，第11318–11327页。'
- en: '[41] M. Ye, T. Cao, Q. Chen, Tpcn: Temporal point cloud networks for motion
    forecasting, in: Proceedings of the IEEE/CVF Conference on Computer Vision and
    Pattern Recognition, 2021, pp. 11318–11327.'
  id: totrans-1997
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] M. Ye, T. Cao, Q. Chen, Tpcn: 时序点云网络用于运动预测，见：IEEE/CVF 计算机视觉与模式识别会议论文集，2021，第11318–11327页。'
- en: '[42] Y. Liu, J. Zhang, L. Fang, Q. Jiang, B. Zhou, Multimodal motion prediction
    with stacked transformers, in: Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition, 2021, pp. 7577–7586.'
  id: totrans-1998
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Y. Liu, J. Zhang, L. Fang, Q. Jiang, B. Zhou, 使用堆叠变换器的多模态运动预测，见：IEEE/CVF
    计算机视觉与模式识别会议论文集，2021，第7577–7586页。'
- en: '[43] J. Gu, C. Sun, H. Zhao, Densetnt: End-to-end trajectory prediction from
    dense goal sets, in: Proceedings of the IEEE/CVF International Conference on Computer
    Vision, 2021, pp. 15303–15312.'
  id: totrans-1999
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] J. Gu, C. Sun, H. Zhao, Densetnt: 从密集目标集合中进行端到端轨迹预测，见：IEEE/CVF 国际计算机视觉会议论文集，2021，第15303–15312页。'
- en: '[44] H. Song, D. Luan, W. Ding, M. Y. Wang, Q. Chen, Learning to predict vehicle
    trajectories with model-based planning, in: Conference on Robot Learning, PMLR,
    2022, pp. 1035–1045.'
  id: totrans-2000
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] H. Song, D. Luan, W. Ding, M. Y. Wang, Q. Chen, 学习通过基于模型的规划预测车辆轨迹，见：机器人学习会议，PMLR，2022，第1035–1045页。'
- en: '[45] D. Wei, H. Sun, B. Li, J. Lu, W. Li, X. Sun, S. Hu, Human joint kinematics
    diffusion-refinement for stochastic motion prediction, arXiv preprint arXiv:2210.05976
    (2022).'
  id: totrans-2001
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] D. Wei, H. Sun, B. Li, J. Lu, W. Li, X. Sun, S. Hu, 人体关节运动学扩散-细化用于随机运动预测，arXiv
    预印本 arXiv:2210.05976 (2022)。'
- en: '[46] A. Patil, S. Malla, H. Gang, Y.-T. Chen, The h3d dataset for full-surround
    3d multi-object detection and tracking in crowded urban scenes, in: 2019 International
    Conference on Robotics and Automation (ICRA), IEEE, 2019, pp. 9552–9557.'
  id: totrans-2002
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] A. Patil, S. Malla, H. Gang, Y.-T. Chen, h3d 数据集用于拥挤城市场景中的全方位 3D 多物体检测与跟踪，见：2019
    国际机器人与自动化会议（ICRA），IEEE，2019，第9552–9557页。'
- en: '[47] D. A. Pomerleau, Alvinn: An autonomous land vehicle in a neural network,
    Advances in neural information processing systems 1 (1988).'
  id: totrans-2003
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] D. A. Pomerleau, Alvinn: 神经网络中的自主地面车辆，神经信息处理系统进展 1 (1988)。'
- en: '[48] D. Chen, B. Zhou, V. Koltun, P. Krähenbühl, Learning by cheating, in:
    Conference on Robot Learning, PMLR, 2020, pp. 66–75.'
  id: totrans-2004
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] D. Chen, B. Zhou, V. Koltun, P. Krähenbühl, 通过作弊进行学习，见：机器人学习会议，PMLR，2020，第66–75页。'
- en: '[49] E. Ohn-Bar, A. Prakash, A. Behl, K. Chitta, A. Geiger, Learning situational
    driving, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, 2020, pp. 11296–11305.'
  id: totrans-2005
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] E. Ohn-Bar, A. Prakash, A. Behl, K. Chitta, A. Geiger, 学习情境驾驶，见：IEEE/CVF
    计算机视觉与模式识别会议论文集，2020，第11296–11305页。'
- en: '[50] A. Zhao, T. He, Y. Liang, H. Huang, G. Van den Broeck, S. Soatto, Sam:
    Squeeze-and-mimic networks for conditional visual driving policy learning, in:
    Conference on Robot Learning, PMLR, 2021, pp. 156–175.'
  id: totrans-2006
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] A. Zhao, T. He, Y. Liang, H. Huang, G. Van den Broeck, S. Soatto, Sam:
    用于条件视觉驾驶政策学习的挤压与模仿网络，发表于：机器人学习会议，PMLR，2021，第156–175页。'
- en: '[51] J. Zhang, E. Ohn-Bar, Learning by watching, in: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, 2021, pp. 12711–12721.'
  id: totrans-2007
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] J. Zhang, E. Ohn-Bar, 通过观察学习，发表于：IEEE/CVF计算机视觉与模式识别会议论文集，2021，第12711–12721页。'
- en: '[52] D. Chen, V. Koltun, P. Krähenbühl, Learning to drive from a world on rails,
    in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021,
    pp. 15590–15599.'
  id: totrans-2008
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] D. Chen, V. Koltun, P. Krähenbühl, 从铁轨上的世界学习驾驶，发表于：IEEE/CVF国际计算机视觉会议论文集，2021，第15590–15599页。'
- en: '[53] M. Toromanoff, E. Wirbel, F. Moutarde, End-to-end model-free reinforcement
    learning for urban driving using implicit affordances, in: Proceedings of the
    IEEE/CVF conference on computer vision and pattern recognition, 2020, pp. 7153–7162.'
  id: totrans-2009
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] M. Toromanoff, E. Wirbel, F. Moutarde, 使用隐式便利性进行城市驾驶的端到端无模型强化学习，发表于：IEEE/CVF计算机视觉与模式识别会议论文集，2020，第7153–7162页。'
- en: '[54] Z. Zhang, A. Liniger, D. Dai, F. Yu, L. Van Gool, End-to-end urban driving
    by imitating a reinforcement learning coach, in: Proceedings of the IEEE/CVF international
    conference on computer vision, 2021, pp. 15222–15232.'
  id: totrans-2010
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] Z. Zhang, A. Liniger, D. Dai, F. Yu, L. Van Gool, 通过模仿强化学习教练进行端到端城市驾驶，发表于：IEEE/CVF国际计算机视觉会议论文集，2021，第15222–15232页。'
- en: '[55] Q. Li, Z. Peng, B. Zhou, Efficient learning of safe driving policy via
    human-ai copilot optimization, in: International Conference on Learning Representations.'
  id: totrans-2011
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Q. Li, Z. Peng, B. Zhou, 通过人类-AI副驾驶优化实现安全驾驶政策的高效学习，发表于：学习表征国际会议。'
- en: '[56] Z. Peng, Q. Li, C. Liu, B. Zhou, Safe driving via expert guided policy
    optimization, in: Conference on Robot Learning, PMLR, 2022, pp. 1554–1563.'
  id: totrans-2012
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Z. Peng, Q. Li, C. Liu, B. Zhou, 通过专家指导的策略优化实现安全驾驶，发表于：机器人学习会议，PMLR，2022，第1554–1563页。'
- en: '[57] Y. Zhao, K. Wu, Z. Xu, Z. Che, Q. Lu, J. Tang, C. H. Liu, Cadre: A cascade
    deep reinforcement learning framework for vision-based autonomous urban driving,
    in: Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 36, 2022,
    pp. 3481–3489.'
  id: totrans-2013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] Y. Zhao, K. Wu, Z. Xu, Z. Che, Q. Lu, J. Tang, C. H. Liu, Cadre: 一个用于基于视觉的城市自主驾驶的级联深度强化学习框架，发表于：AAAI人工智能会议论文集，第36卷，2022，第3481–3489页。'
- en: '[58] J. Zhang, Z. Huang, E. Ohn-Bar, Coaching a teachable student, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, pp.
    7805–7815.'
  id: totrans-2014
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] J. Zhang, Z. Huang, E. Ohn-Bar, 培训可教学生，发表于：IEEE/CVF计算机视觉与模式识别会议论文集，2023，第7805–7815页。'
- en: '[59] A. Kendall, J. Hawke, D. Janz, P. Mazur, D. Reda, J.-M. Allen, V.-D. Lam,
    A. Bewley, A. Shah, Learning to drive in a day, in: 2019 International Conference
    on Robotics and Automation (ICRA), 2019, pp. 8248–8254. [doi:10.1109/ICRA.2019.8793742](https://doi.org/10.1109/ICRA.2019.8793742).'
  id: totrans-2015
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] A. Kendall, J. Hawke, D. Janz, P. Mazur, D. Reda, J.-M. Allen, V.-D. Lam,
    A. Bewley, A. Shah, 一天内学习驾驶，发表于：2019年国际机器人与自动化会议（ICRA），2019，第8248–8254页。 [doi:10.1109/ICRA.2019.8793742](https://doi.org/10.1109/ICRA.2019.8793742)。'
- en: '[60] A. Prakash, A. Behl, E. Ohn-Bar, K. Chitta, A. Geiger, Exploring data
    aggregation in policy learning for vision-based urban autonomous driving, in:
    Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    2020, pp. 11763–11773.'
  id: totrans-2016
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] A. Prakash, A. Behl, E. Ohn-Bar, K. Chitta, A. Geiger, 探索政策学习中的数据聚合用于基于视觉的城市自主驾驶，发表于：IEEE/CVF计算机视觉与模式识别会议论文集，2020，第11763–11773页。'
- en: '[61] K. Ishihara, A. Kanervisto, J. Miura, V. Hautamaki, Multi-task learning
    with attention for end-to-end autonomous driving, in: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, 2021, pp. 2902–2911.'
  id: totrans-2017
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] K. Ishihara, A. Kanervisto, J. Miura, V. Hautamaki, 使用注意力机制的多任务学习进行端到端自主驾驶，发表于：IEEE/CVF计算机视觉与模式识别会议论文集，2021，第2902–2911页。'
- en: '[62] Y. Xiao, F. Codevilla, A. Gurram, O. Urfalioglu, A. M. López, Multimodal
    end-to-end autonomous driving, IEEE Transactions on Intelligent Transportation
    Systems 23 (1) (2020) 537–547.'
  id: totrans-2018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] Y. Xiao, F. Codevilla, A. Gurram, O. Urfalioglu, A. M. López, 多模态端到端自主驾驶，IEEE智能交通系统汇刊，第23卷（1）（2020）第537–547页。'
- en: '[63] P. Hu, A. Huang, J. Dolan, D. Held, D. Ramanan, Safe local motion planning
    with self-supervised freespace forecasting, in: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition (CVPR), 2021, pp. 12732–12741.'
  id: totrans-2019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] P. Hu, A. Huang, J. Dolan, D. Held, D. Ramanan, 通过自监督的自由空间预测进行安全的局部运动规划，发表于：IEEE/CVF计算机视觉与模式识别会议（CVPR）论文集，2021，第12732–12741页。'
- en: '[64] P. Cai, S. Wang, H. Wang, M. Liu, [Carl-lead: Lidar-based end-to-end autonomous
    driving with contrastive deep reinforcement learning](https://api.semanticscholar.org/CorpusID:237563170),
    ArXiv abs/2109.08473 (2021).'
  id: totrans-2020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] P. Cai, S. Wang, H. Wang, M. Liu, [Carl-lead: 基于激光雷达的端到端自主驾驶与对比深度强化学习](https://api.semanticscholar.org/CorpusID:237563170),
    ArXiv abs/2109.08473 (2021)。'
- en: URL [https://api.semanticscholar.org/CorpusID:237563170](https://api.semanticscholar.org/CorpusID:237563170)
  id: totrans-2021
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [https://api.semanticscholar.org/CorpusID:237563170](https://api.semanticscholar.org/CorpusID:237563170)
- en: '[65] W. Zeng, S. Wang, R. Liao, Y. Chen, B. Yang, R. Urtasun, [Dsdnet: Deep
    structured self-driving network](https://api.semanticscholar.org/CorpusID:221112477),
    in: European Conference on Computer Vision, 2020.'
  id: totrans-2022
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] W. Zeng, S. Wang, R. Liao, Y. Chen, B. Yang, R. Urtasun, [Dsdnet: 深度结构化自动驾驶网络](https://api.semanticscholar.org/CorpusID:221112477)，发表于：欧洲计算机视觉会议，2020。'
- en: URL [https://api.semanticscholar.org/CorpusID:221112477](https://api.semanticscholar.org/CorpusID:221112477)
  id: totrans-2023
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [https://api.semanticscholar.org/CorpusID:221112477](https://api.semanticscholar.org/CorpusID:221112477)
- en: '[66] Q. Zhang, M. Tang, R. Geng, F. Chen, R. Xin, L. Wang, Mmfn: Multi-modal-fusion-net
    for end-to-end driving, in: 2022 IEEE/RSJ International Conference on Intelligent
    Robots and Systems (IROS), IEEE, 2022, pp. 8638–8643.'
  id: totrans-2024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] Q. Zhang, M. Tang, R. Geng, F. Chen, R. Xin, L. Wang, Mmfn: 多模态融合网络用于端到端驾驶，发表于：2022
    IEEE/RSJ国际智能机器人与系统会议 (IROS)，IEEE，2022，第8638–8643页。'
- en: '[67] T. Bailey, H. Durrant-Whyte, Simultaneous localization and mapping (slam):
    Part ii, IEEE robotics & automation magazine 13 (3) (2006) 108–117.'
  id: totrans-2025
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] T. Bailey, H. Durrant-Whyte, 同时定位与地图构建 (slam): 第二部分，IEEE机器人与自动化杂志 13 (3)
    (2006) 108–117。'
- en: '[68] A. Shenoi, M. Patel, J. Gwak, P. Goebel, A. Sadeghian, H. Rezatofighi,
    R. Martin-Martin, S. Savarese, Jrmot: A real-time 3d multi-object tracker and
    a new large-scale dataset, in: 2020 IEEE/RSJ International Conference on Intelligent
    Robots and Systems (IROS), IEEE, 2020, pp. 10335–10342.'
  id: totrans-2026
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] A. Shenoi, M. Patel, J. Gwak, P. Goebel, A. Sadeghian, H. Rezatofighi,
    R. Martin-Martin, Jrmot: 一个实时3D多目标跟踪器和一个新的大规模数据集，发表于：2020 IEEE/RSJ国际智能机器人与系统会议
    (IROS)，IEEE，2020，第10335–10342页。'
- en: '[69] M. Liang, B. Yang, Y. Chen, R. Hu, R. Urtasun, Multi-task multi-sensor
    fusion for 3d object detection, in: Proceedings of the IEEE/CVF Conference on
    Computer Vision and Pattern Recognition, 2019, pp. 7345–7353.'
  id: totrans-2027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] M. Liang, B. Yang, Y. Chen, R. Hu, R. Urtasun, 多任务多传感器融合用于3D目标检测，发表于：IEEE/CVF计算机视觉与模式识别会议论文集，2019，第7345–7353页。'
- en: '[70] M. Liang, B. Yang, S. Wang, R. Urtasun, Deep continuous fusion for multi-sensor
    3d object detection, in: Proceedings of the European conference on computer vision
    (ECCV), 2018, pp. 641–656.'
  id: totrans-2028
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] M. Liang, B. Yang, S. Wang, R. Urtasun, 深度连续融合用于多传感器3D目标检测，发表于：欧洲计算机视觉会议
    (ECCV) 论文集，2018，第641–656页。'
- en: '[71] B. Jaeger, K. Chitta, A. Geiger, Hidden biases of end-to-end driving models
    (2023).'
  id: totrans-2029
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] B. Jaeger, K. Chitta, A. Geiger, 端到端驾驶模型的隐藏偏差 (2023)。'
- en: '[72] Y. Zhou, P. Sun, Y. Zhang, D. Anguelov, J. Gao, T. Ouyang, J. Guo, J. Ngiam,
    V. Vasudevan, End-to-end multi-view fusion for 3d object detection in lidar point
    clouds, in: Conference on Robot Learning, PMLR, 2020, pp. 923–932.'
  id: totrans-2030
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] Y. Zhou, P. Sun, Y. Zhang, D. Anguelov, J. Gao, T. Ouyang, J. Guo, J.
    Ngiam, V. Vasudevan, 用于激光雷达点云中3D目标检测的端到端多视角融合，发表于：机器人学习会议，PMLR，2020，第923–932页。'
- en: '[73] I. Sobh, L. Amin, S. Abdelkarim, K. Elmadawy, M. Saeed, O. Abdeltawab,
    M. Gamal, A. El Sallab, End-to-end multi-modal sensors fusion system for urban
    automated driving (2018).'
  id: totrans-2031
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] I. Sobh, L. Amin, S. Abdelkarim, K. Elmadawy, M. Saeed, O. Abdeltawab,
    M. Gamal, A. El Sallab, 面向城市自动驾驶的端到端多模态传感器融合系统 (2018)。'
- en: '[74] B. Zhou, P. Krähenbühl, V. Koltun, Does computer vision matter for action?,
    Science Robotics 4 (30) (2019) eaaw6661.'
  id: totrans-2032
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] B. Zhou, P. Krähenbühl, V. Koltun, 计算机视觉对动作的重要性？《科学机器人》4 (30) (2019) eaaw6661。'
- en: '[75] C. Hubschneider, A. Bauer, M. Weber, J. M. Zöllner, Adding navigation
    to the equation: Turning decisions for end-to-end vehicle control, in: 2017 IEEE
    20th International Conference on Intelligent Transportation Systems (ITSC), IEEE,
    2017, pp. 1–8.'
  id: totrans-2033
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] C. Hubschneider, A. Bauer, M. Weber, J. M. Zöllner, 将导航添加到方程中：端到端车辆控制的决策转换，发表于：2017
    IEEE第20届国际智能交通系统会议 (ITSC)，IEEE，2017，第1–8页。'
- en: '[76] F. Codevilla, M. Müller, A. López, V. Koltun, A. Dosovitskiy, End-to-end
    driving via conditional imitation learning, in: 2018 IEEE international conference
    on robotics and automation (ICRA), IEEE, 2018, pp. 4693–4700.'
  id: totrans-2034
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] F. Codevilla, M. Müller, A. López, V. Koltun, A. Dosovitskiy, 通过条件模仿学习实现端到端驾驶，发表于：2018
    IEEE国际机器人与自动化会议 (ICRA)，IEEE，2018，第4693–4700页。'
- en: '[77] X. Liang, T. Wang, L. Yang, E. Xing, Cirl: Controllable imitative reinforcement
    learning for vision-based self-driving, in: Proceedings of the European conference
    on computer vision (ECCV), 2018, pp. 584–599.'
  id: totrans-2035
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] X. Liang, T. Wang, L. Yang, E. Xing, Cirl：用于基于视觉的自驾车的可控模仿强化学习，载于：欧洲计算机视觉会议（ECCV）论文集，2018年，第584–599页。'
- en: '[78] S. Wang, J. Qin, M. Li, Y. Wang, Flowdrivenet: An end-to-end network for
    learning driving policies from image optical flow and lidar point flow, in: 2021
    IEEE International Conference on Robotics and Automation (ICRA), IEEE, 2021, pp.
    1861–1867.'
  id: totrans-2036
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] S. Wang, J. Qin, M. Li, Y. Wang, Flowdrivenet：一个用于从图像光流和激光雷达点流学习驾驶策略的端到端网络，载于：2021年IEEE国际机器人与自动化会议（ICRA），IEEE，2021年，第1861–1867页。'
- en: '[79] R. Fong, M. Patrick, A. Vedaldi, Understanding deep networks via extremal
    perturbations and smooth masks, in: Proceedings of the IEEE/CVF international
    conference on computer vision, 2019, pp. 2950–2958.'
  id: totrans-2037
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] R. Fong, M. Patrick, A. Vedaldi, 通过极端扰动和光滑掩模理解深度网络，载于：IEEE/CVF国际计算机视觉会议论文集，2019年，第2950–2958页。'
- en: '[80] A. Cui, S. Casas, A. Sadat, R. Liao, R. Urtasun, Lookout: Diverse multi-future
    prediction and planning for self-driving, in: Proceedings of the IEEE/CVF International
    Conference on Computer Vision, 2021, pp. 16107–16116.'
  id: totrans-2038
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] A. Cui, S. Casas, A. Sadat, R. Liao, R. Urtasun, Lookout：多样化的未来预测与自驾规划，载于：IEEE/CVF国际计算机视觉会议论文集，2021年，第16107–16116页。'
- en: '[81] W. Zeng, W. Luo, S. Suo, A. Sadat, B. Yang, S. Casas, R. Urtasun, End-to-end
    interpretable neural motion planner, in: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, 2019, pp. 8660–8669.'
  id: totrans-2039
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] W. Zeng, W. Luo, S. Suo, A. Sadat, B. Yang, S. Casas, R. Urtasun, 端到端可解释的神经运动规划器，载于：IEEE/CVF计算机视觉与模式识别会议论文集，2019年，第8660–8669页。'
- en: '[82] S. Casas, A. Sadat, R. Urtasun, Mp3: A unified model to map, perceive,
    predict and plan, in: Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition, 2021, pp. 14403–14412.'
  id: totrans-2040
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] S. Casas, A. Sadat, R. Urtasun, Mp3：一个统一模型用于映射、感知、预测和规划，载于：IEEE/CVF计算机视觉与模式识别会议论文集，2021年，第14403–14412页。'
- en: '[83] N. Rhinehart, R. McAllister, S. Levine, Deep imitative models for flexible
    inference, planning, and control, in: International Conference on Learning Representations.'
  id: totrans-2041
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] N. Rhinehart, R. McAllister, S. Levine, 用于灵活推理、规划和控制的深度模仿模型，载于：国际学习表征会议。'
- en: '[84] W. Zeng, W. Luo, S. Suo, A. Sadat, B. Yang, S. Casas, R. Urtasun, End-to-end
    interpretable neural motion planner, in: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, 2019, pp. 8660–8669.'
  id: totrans-2042
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] W. Zeng, W. Luo, S. Suo, A. Sadat, B. Yang, S. Casas, R. Urtasun, 端到端可解释的神经运动规划器，载于：IEEE/CVF计算机视觉与模式识别会议论文集，2019年，第8660–8669页。'
- en: '[85] X. Chen, H. Ma, J. Wan, B. Li, T. Xia, Multi-view 3d object detection
    network for autonomous driving, in: Proceedings of the IEEE conference on Computer
    Vision and Pattern Recognition, 2017, pp. 1907–1915.'
  id: totrans-2043
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] X. Chen, H. Ma, J. Wan, B. Li, T. Xia, 多视角3D物体检测网络用于自主驾驶，载于：IEEE计算机视觉与模式识别会议论文集，2017年，第1907–1915页。'
- en: '[86] I. Kim, H. Lee, J. Lee, E. Lee, D. Kim, Multi-task learning with future
    states for vision-based autonomous driving, in: Proceedings of the Asian Conference
    on Computer Vision, 2020.'
  id: totrans-2044
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] I. Kim, H. Lee, J. Lee, E. Lee, D. Kim, 具有未来状态的多任务学习用于基于视觉的自主驾驶，载于：亚洲计算机视觉会议论文集，2020年。'
- en: '[87] M. Bain, C. Sammut, A framework for behavioural cloning., in: Machine
    Intelligence 15, 1995, pp. 103–129.'
  id: totrans-2045
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] M. Bain, C. Sammut, 行为克隆框架，载于：机器智能15，1995年，第103–129页。'
- en: '[88] J. Cui, H. Qiu, D. Chen, P. Stone, Y. Zhu, Coopernaut: End-to-end driving
    with cooperative perception for networked vehicles, in: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, 2022, pp. 17252–17262.'
  id: totrans-2046
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] J. Cui, H. Qiu, D. Chen, P. Stone, Y. Zhu, Coopernaut：具有协作感知的网络车辆端到端驾驶，载于：IEEE/CVF计算机视觉与模式识别会议论文集，2022年，第17252–17262页。'
- en: '[89] S. Ross, G. Gordon, D. Bagnell, A reduction of imitation learning and
    structured prediction to no-regret online learning, in: Proceedings of the fourteenth
    international conference on artificial intelligence and statistics, JMLR Workshop
    and Conference Proceedings, 2011, pp. 627–635.'
  id: totrans-2047
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] S. Ross, G. Gordon, D. Bagnell, 将模仿学习和结构化预测简化为无悔在线学习，载于：第十四届国际人工智能与统计会议论文集，JMLR研讨会与会议论文集，2011年，第627–635页。'
- en: '[90] A. Sadat, S. Casas, M. Ren, X. Wu, P. Dhawan, R. Urtasun, Perceive, predict,
    and plan: Safe motion planning through interpretable semantic representations,
    in: Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28,
    2020, Proceedings, Part XXIII 16, Springer, 2020, pp. 414–430.'
  id: totrans-2048
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] A. Sadat, S. Casas, M. Ren, X. Wu, P. Dhawan, R. Urtasun, 识别、预测与规划：通过可解释的语义表示实现安全运动规划，载于：计算机视觉–ECCV
    2020：第16届欧洲会议，英国格拉斯哥，2020年8月23–28日，会议论文集，第XXIII部分，斯普林格出版社，2020年，页414–430。'
- en: '[91] D. Sadigh, S. Sastry, S. A. Seshia, A. D. Dragan, Planning for autonomous
    cars that leverage effects on human actions., in: Robotics: Science and systems,
    Vol. 2, Ann Arbor, MI, USA, 2016, pp. 1–9.'
  id: totrans-2049
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] D. Sadigh, S. Sastry, S. A. Seshia, A. D. Dragan, 利用对人类行为影响的规划方法用于自主汽车，载于：机器人学：科学与系统，第2卷，美国安娜堡，2016年，页1–9。'
- en: '[92] B. D. Ziebart, A. L. Maas, J. A. Bagnell, A. K. Dey, et al., Maximum entropy
    inverse reinforcement learning., in: Aaai, Vol. 8, Chicago, IL, USA, 2008, pp.
    1433–1438.'
  id: totrans-2050
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] B. D. Ziebart, A. L. Maas, J. A. Bagnell, A. K. Dey, 等，最大熵逆强化学习，载于：Aaai，第8卷，美国芝加哥，2008年，页1433–1438。'
- en: '[93] G. Wang, H. Niu, D. Zhu, J. Hu, X. Zhan, G. Zhou, A versatile and efficient
    reinforcement learning framework for autonomous driving, arXiv preprint arXiv:2110.11573
    (2021).'
  id: totrans-2051
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] G. Wang, H. Niu, D. Zhu, J. Hu, X. Zhan, G. Zhou, 一个多功能高效的强化学习框架用于自动驾驶，[arXiv预印本](https://arxiv.org/abs/2110.11573)
    arXiv:2110.11573 (2021)。'
- en: '[94] R. S. Sutton, A. G. Barto, Reinforcement learning: An introduction, MIT
    press, 2018.'
  id: totrans-2052
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] R. S. Sutton, A. G. Barto, 强化学习：导论，MIT出版社，2018年。'
- en: '[95] L. Chen, X. Hu, B. Tang, Y. Cheng, Conditional dqn-based motion planning
    with fuzzy logic for autonomous driving, IEEE Transactions on Intelligent Transportation
    Systems 23 (4) (2020) 2966–2977.'
  id: totrans-2053
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] L. Chen, X. Hu, B. Tang, Y. Cheng, 基于条件DQN的模糊逻辑运动规划用于自动驾驶，IEEE智能交通系统汇刊23
    (4) (2020) 2966–2977。'
- en: '[96] J. Chen, S. E. Li, M. Tomizuka, Interpretable end-to-end urban autonomous
    driving with latent deep reinforcement learning, IEEE Transactions on Intelligent
    Transportation Systems 23 (6) (2021) 5068–5078.'
  id: totrans-2054
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] J. Chen, S. E. Li, M. Tomizuka, 可解释的端到端城市自动驾驶与潜在深度强化学习，IEEE智能交通系统汇刊23
    (6) (2021) 5068–5078。'
- en: '[97] X. Zhang, Y. Jiang, Y. Lu, X. Xu, Receding-horizon reinforcement learning
    approach for kinodynamic motion planning of autonomous vehicles, IEEE Transactions
    on Intelligent Vehicles 7 (3) (2022) 556–568.'
  id: totrans-2055
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] X. Zhang, Y. Jiang, Y. Lu, X. Xu, 面向自主车辆的递归地平线强化学习运动规划方法，IEEE智能车辆汇刊7 (3)
    (2022) 556–568。'
- en: '[98] X. Liang, T. Wang, L. Yang, E. Xing, Cirl: Controllable imitative reinforcement
    learning for vision-based self-driving, in: Proceedings of the European conference
    on computer vision (ECCV), 2018, pp. 584–599.'
  id: totrans-2056
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] X. Liang, T. Wang, L. Yang, E. Xing, Cirl：基于视觉的自驾车可控模仿强化学习，载于：欧洲计算机视觉会议（ECCV）论文集，2018年，页584–599。'
- en: '[99] D. Chen, V. Koltun, P. Krähenbühl, Learning to drive from a world on rails,
    in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021,
    pp. 15590–15599.'
  id: totrans-2057
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] D. Chen, V. Koltun, P. Krähenbühl, 从轨道世界中学习驾驶，载于：IEEE/CVF国际计算机视觉会议论文集，2021年，页15590–15599。'
- en: '[100] R. Chekroun, M. Toromanoff, S. Hornauer, F. Moutarde, Gri: General reinforced
    imitation and its application to vision-based autonomous driving, in: NeurIPS
    2021, Machine Learning for Autonomous Driving Workshop, 2021.'
  id: totrans-2058
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] R. Chekroun, M. Toromanoff, S. Hornauer, F. Moutarde, Gri：通用强化模仿及其在基于视觉的自动驾驶中的应用，载于：NeurIPS
    2021，自动驾驶机器学习研讨会，2021年。'
- en: '[101] Y. Chen, W. Li, C. Sakaridis, D. Dai, L. V. Gool, Domain adaptive faster
    r-cnn for object detection in the wild (2018). [arXiv:1803.03243](http://arxiv.org/abs/1803.03243).'
  id: totrans-2059
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] Y. Chen, W. Li, C. Sakaridis, D. Dai, L. V. Gool, 面向真实环境的领域自适应Faster
    R-CNN目标检测（2018）。 [arXiv:1803.03243](http://arxiv.org/abs/1803.03243)。'
- en: '[102] H. Zhang, G. Luo, Y. Tian, K. Wang, H. He, F.-Y. Wang, A virtual-real
    interaction approach to object instance segmentation in traffic scenes, IEEE Transactions
    on Intelligent Transportation Systems 22 (2) (2021) 863–875. [doi:10.1109/TITS.2019.2961145](https://doi.org/10.1109/TITS.2019.2961145).'
  id: totrans-2060
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] H. Zhang, G. Luo, Y. Tian, K. Wang, H. He, F.-Y. Wang, 一种虚拟-现实交互方法用于交通场景中的目标实例分割，IEEE智能交通系统汇刊22
    (2) (2021) 863–875。 [doi:10.1109/TITS.2019.2961145](https://doi.org/10.1109/TITS.2019.2961145)。'
- en: '[103] L. Zhang, T. Wen, J. Min, J. Wang, D. Han, J. Shi, [Learning object placement
    by inpainting for compositional data augmentation](https://doi.org/10.1007/978-3-030-58601-0_34),
    in: A. Vedaldi, H. Bischof, T. Brox, J.-M. Frahm (Eds.), Computer Vision - ECCV
    2020 - 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings,
    Part XIII, Vol. 12358 of Lecture Notes in Computer Science, Springer, 2020, pp.
    566–581. [doi:10.1007/978-3-030-58601-0_34](https://doi.org/10.1007/978-3-030-58601-0_34).'
  id: totrans-2061
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] L. Zhang, T. Wen, J. Min, J. Wang, D. Han, J. Shi, [通过修复学习物体放置以进行组合数据增强](https://doi.org/10.1007/978-3-030-58601-0_34)，载于：A.
    Vedaldi, H. Bischof, T. Brox, J.-M. Frahm（编），计算机视觉 - ECCV 2020 - 第16届欧洲会议，英国格拉斯哥，2020年8月23-28日，会议录，第XIII部分，计算机科学讲义笔记第12358卷，Springer，2020年，第566–581页。[doi:10.1007/978-3-030-58601-0_34](https://doi.org/10.1007/978-3-030-58601-0_34)。'
- en: URL [https://doi.org/10.1007/978-3-030-58601-0_34](https://doi.org/10.1007/978-3-030-58601-0_34)
  id: totrans-2062
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [https://doi.org/10.1007/978-3-030-58601-0_34](https://doi.org/10.1007/978-3-030-58601-0_34)
- en: '[104] Y. Chen, F. Rong, S. Duggal, S. Wang, X. Yan, S. Manivasagam, S. Xue,
    E. Yumer, R. Urtasun, Geosim: Realistic video simulation via geometry-aware composition
    for self-driving, in: Proceedings of the IEEE/CVF conference on computer vision
    and pattern recognition, 2021, pp. 7230–7240.'
  id: totrans-2063
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] Y. Chen, F. Rong, S. Duggal, S. Wang, X. Yan, S. Manivasagam, S. Xue,
    E. Yumer, R. Urtasun, Geosim：通过几何感知组合实现真实的视频模拟以用于自动驾驶，载于：IEEE/CVF计算机视觉与模式识别会议论文集，2021年，第7230–7240页。'
- en: '[105] A. Vobeckỳ, D. Hurych, M. Uřičář, P. Pérez, J. Sivic, Artificial dummies
    for urban dataset augmentation, in: Proceedings of the AAAI Conference on Artificial
    Intelligence, Vol. 35, 2021, pp. 2692–2700.'
  id: totrans-2064
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] A. Vobeckỳ, D. Hurych, M. Uřičář, P. Pérez, J. Sivic, 人工假人用于城市数据集增强，载于：AAAI人工智能会议论文集，第35卷，2021年，第2692–2700页。'
- en: '[106] A. E. Sallab, I. Sobh, M. Zahran, M. Shawky, Unsupervised neural sensor
    models for synthetic lidar data augmentation (2019). [arXiv:1911.10575](http://arxiv.org/abs/1911.10575).'
  id: totrans-2065
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] A. E. Sallab, I. Sobh, M. Zahran, M. Shawky, 无监督神经传感器模型用于合成激光雷达数据增强（2019年）。[arXiv:1911.10575](http://arxiv.org/abs/1911.10575)。'
- en: '[107] J. Fang, D. Zhou, F. Yan, T. Zhao, F. Zhang, Y. Ma, L. Wang, R. Yang,
    Augmented lidar simulator for autonomous driving, IEEE Robotics and Automation
    Letters 5 (2) (2020) 1931–1938. [doi:10.1109/LRA.2020.2969927](https://doi.org/10.1109/LRA.2020.2969927).'
  id: totrans-2066
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] J. Fang, D. Zhou, F. Yan, T. Zhao, F. Zhang, Y. Ma, L. Wang, R. Yang,
    增强的激光雷达模拟器用于自主驾驶，《IEEE机器人与自动化快报》第5卷（2）（2020年）1931–1938。[doi:10.1109/LRA.2020.2969927](https://doi.org/10.1109/LRA.2020.2969927)。'
- en: '[108] S. Manivasagam, S. Wang, K. Wong, W. Zeng, M. Sazanovich, S. Tan, B. Yang,
    W.-C. Ma, R. Urtasun, Lidarsim: Realistic lidar simulation by leveraging the real
    world (2020). [arXiv:2006.09348](http://arxiv.org/abs/2006.09348).'
  id: totrans-2067
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] S. Manivasagam, S. Wang, K. Wong, W. Zeng, M. Sazanovich, S. Tan, B.
    Yang, W.-C. Ma, R. Urtasun, Lidarsim：通过利用现实世界进行真实的激光雷达模拟（2020年）。[arXiv:2006.09348](http://arxiv.org/abs/2006.09348)。'
- en: '[109] A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, V. Koltun, Carla: An
    open urban driving simulator, in: Conference on robot learning, PMLR, 2017, pp.
    1–16.'
  id: totrans-2068
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, V. Koltun, Carla: 一种开放的城市驾驶模拟器，载于：机器人学习会议，PMLR，2017年，第1–16页。'
- en: '[110] A. Geiger, P. Lenz, C. Stiller, R. Urtasun, Vision meets robotics: The
    kitti dataset, The International Journal of Robotics Research 32 (11) (2013) 1231–1237.'
  id: totrans-2069
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] A. Geiger, P. Lenz, C. Stiller, R. Urtasun, 视觉遇见机器人：KITTI数据集，《国际机器人研究杂志》第32卷（11）（2013年）1231–1237。'
- en: '[111] P. Wu, L. Chen, H. Li, X. Jia, J. Yan, Y. Qiao, Policy pre-training for
    autonomous driving via self-supervised geometric modeling, in: International Conference
    on Learning Representations, 2023.'
  id: totrans-2070
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] P. Wu, L. Chen, H. Li, X. Jia, J. Yan, Y. Qiao, 自监督几何建模的自主驾驶策略预训练，载于：国际学习表示会议，2023年。'
- en: '[112] A. Hu, G. Corrado, N. Griffiths, Z. Murez, C. Gurau, H. Yeo, A. Kendall,
    R. Cipolla, J. Shotton, Model-based imitation learning for urban driving, Advances
    in Neural Information Processing Systems 35 (2022) 20703–20716.'
  id: totrans-2071
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] A. Hu, G. Corrado, N. Griffiths, Z. Murez, C. Gurau, H. Yeo, A. Kendall,
    R. Cipolla, J. Shotton, 基于模型的城市驾驶模仿学习，《神经信息处理系统进展》第35卷（2022年）20703–20716。'
- en: '[113] J. Park, Y. Seo, C. Liu, L. Zhao, T. Qin, J. Shin, T.-Y. Liu, Object-aware
    regularization for addressing causal confusion in imitation learning, Advances
    in Neural Information Processing Systems 34 (2021) 3029–3042.'
  id: totrans-2072
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] J. Park, Y. Seo, C. Liu, L. Zhao, T. Qin, J. Shin, T.-Y. Liu, 面向对象的正则化用于解决模仿学习中的因果混淆，《神经信息处理系统进展》第34卷（2021年）3029–3042。'
- en: '[114] A. Bewley, J. Rigley, Y. Liu, J. Hawke, R. Shen, V.-D. Lam, A. Kendall,
    Learning to drive from simulation without real world labels, in: 2019 International
    conference on robotics and automation (ICRA), IEEE, 2019, pp. 4818–4824.'
  id: totrans-2073
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] A. Bewley, J. Rigley, Y. Liu, J. Hawke, R. Shen, V.-D. Lam, A. Kendall,
    从模拟中学习驾驶而无需真实世界标签，载于：2019年国际机器人与自动化会议（ICRA），IEEE，2019年，第4818–4824页。'
- en: '[115] S. Hecker, D. Dai, L. Van Gool, Learning accurate, comfortable and human-like
    driving, arXiv preprint arXiv:1903.10995 (2019).'
  id: totrans-2074
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] S. Hecker, D. Dai, L. Van Gool, 学习准确、舒适且类似人类的驾驶，arXiv 预印本 arXiv:1903.10995
    (2019)。'
- en: '[116] X. Pan, Y. You, Z. Wang, C. Lu, Virtual to real reinforcement learning
    for autonomous driving (2017). [arXiv:1704.03952](http://arxiv.org/abs/1704.03952).'
  id: totrans-2075
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] X. Pan, Y. You, Z. Wang, C. Lu, 从虚拟到真实的强化学习用于自动驾驶 (2017). [arXiv:1704.03952](http://arxiv.org/abs/1704.03952)。'
- en: '[117] B. Osiński, A. Jakubowski, P. Miłoś, P. Zięcina, C. Galias, S. Homoceanu,
    H. Michalewski, Simulation-based reinforcement learning for real-world autonomous
    driving (2020). [arXiv:1911.12905](http://arxiv.org/abs/1911.12905).'
  id: totrans-2076
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] B. Osiński, A. Jakubowski, P. Miłoś, P. Zięcina, C. Galias, S. Homoceanu,
    H. Michalewski, 基于仿真的强化学习用于真实世界的自动驾驶 (2020). [arXiv:1911.12905](http://arxiv.org/abs/1911.12905)。'
- en: '[118] R. Mitchell, J. Fletcher, J. Panerati, A. Prorok, Multi-vehicle mixed
    reality reinforcement learning for autonomous multi-lane driving, in: Proceedings
    of the 19th International Conference on Autonomous Agents and MultiAgent Systems,
    2020, pp. 1928–1930.'
  id: totrans-2077
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] R. Mitchell, J. Fletcher, J. Panerati, A. Prorok, 多车混合现实强化学习用于自主多车道驾驶，见：第19届国际自主代理与多代理系统会议论文集，2020，第
    1928–1930 页。'
- en: '[119] A. Stocco, B. Pulfer, P. Tonella, [Mind the gap! a study on the transferability
    of virtual versus physical-world testing of autonomous driving systems](https://doi.org/10.1109.2Ftse.2022.3202311),
    IEEE Transactions on Software Engineering 49 (4) (2023) 1928–1940. [doi:10.1109/tse.2022.3202311](https://doi.org/10.1109/tse.2022.3202311).'
  id: totrans-2078
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] A. Stocco, B. Pulfer, P. Tonella, [注意差距！关于虚拟与物理世界测试自动驾驶系统的可转移性的研究](https://doi.org/10.1109.2Ftse.2022.3202311)，《IEEE
    软件工程汇刊》 49 (4) (2023) 1928–1940。 [doi:10.1109/tse.2022.3202311](https://doi.org/10.1109/tse.2022.3202311)。'
- en: URL [https://doi.org/10.1109.2Ftse.2022.3202311](https://doi.org/10.1109.2Ftse.2022.3202311)
  id: totrans-2079
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [https://doi.org/10.1109.2Ftse.2022.3202311](https://doi.org/10.1109.2Ftse.2022.3202311)
- en: '[120] Y. Tian, K. Pei, S. Jana, B. Ray, Deeptest: Automated testing of deep-neural-network-driven
    autonomous cars, in: Proceedings of the 40th international conference on software
    engineering, 2018, pp. 303–314.'
  id: totrans-2080
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] Y. Tian, K. Pei, S. Jana, B. Ray, Deeptest: 自动化测试深度神经网络驱动的自动驾驶汽车，见：第40届国际软件工程会议论文集，2018，第
    303–314 页。'
- en: '[121] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, Y. Bengio, Generative adversarial networks, Communications of the
    ACM 63 (11) (2020) 139–144.'
  id: totrans-2081
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, Y. Bengio, 生成对抗网络，《ACM 通讯》 63 (11) (2020) 139–144。'
- en: '[122] X. Ouyang, Y. Cheng, Y. Jiang, C.-L. Li, P. Zhou, Pedestrian-synthesis-gan:
    Generating pedestrian data in real scene and beyond (2018). [arXiv:1804.02047](http://arxiv.org/abs/1804.02047).'
  id: totrans-2082
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] X. Ouyang, Y. Cheng, Y. Jiang, C.-L. Li, P. Zhou, Pedestrian-synthesis-gan:
    在真实场景及其之外生成行人数据 (2018). [arXiv:1804.02047](http://arxiv.org/abs/1804.02047)。'
- en: '[123] B. Weng, S. J. Rao, E. Deosthale, S. Schnelle, F. Barickman, Model predictive
    instantaneous safety metric for evaluation of automated driving systems, in: 2020
    IEEE Intelligent Vehicles Symposium (IV), IEEE, 2020, pp. 1899–1906.'
  id: totrans-2083
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] B. Weng, S. J. Rao, E. Deosthale, S. Schnelle, F. Barickman, 用于自动驾驶系统评估的模型预测即时安全指标，见：2020
    IEEE 智能车辆研讨会 (IV)，IEEE，2020，第 1899–1906 页。'
- en: '[124] W. Wachenfeld, P. Junietz, R. Wenzel, H. Winner, The worst-time-to-collision
    metric for situation identification, in: 2016 IEEE intelligent vehicles symposium
    (IV), IEEE, 2016, pp. 729–734.'
  id: totrans-2084
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] W. Wachenfeld, P. Junietz, R. Wenzel, H. Winner, 用于情境识别的最差碰撞时间度量，见：2016
    IEEE 智能车辆研讨会 (IV)，IEEE，2016，第 729–734 页。'
- en: '[125] C. Li, S. H. Chan, Y.-T. Chen, Who make drivers stop? towards driver-centric
    risk assessment: Risk object identification via causal inference, in: 2020 IEEE/RSJ
    International Conference on Intelligent Robots and Systems (IROS), IEEE, 2020,
    pp. 10711–10718.'
  id: totrans-2085
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] C. Li, S. H. Chan, Y.-T. Chen, 谁让司机停下？面向司机的风险评估：通过因果推断识别风险对象，见：2020 IEEE/RSJ
    国际智能机器人与系统会议 (IROS)，IEEE，2020，第 10711–10718 页。'
- en: '[126] G. Li, Y. Li, S. Jha, T. Tsai, M. Sullivan, S. K. S. Hari, Z. Kalbarczyk,
    R. Iyer, Av-fuzzer: Finding safety violations in autonomous driving systems, in:
    2020 IEEE 31st international symposium on software reliability engineering (ISSRE),
    IEEE, 2020, pp. 25–36.'
  id: totrans-2086
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] G. Li, Y. Li, S. Jha, T. Tsai, M. Sullivan, S. K. S. Hari, Z. Kalbarczyk,
    R. Iyer, Av-fuzzer: 在自动驾驶系统中发现安全违规，见：2020 IEEE 第31届软件可靠性工程国际研讨会 (ISSRE)，IEEE，2020，第
    25–36 页。'
- en: '[127] W. K. Alhajyaseen, The integration of conflict probability and severity
    for the safety assessment of intersections, Arabian Journal for Science and Engineering
    40 (2015) 421–430.'
  id: totrans-2087
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] W. K. Alhajyaseen, 交叉口安全评估中的冲突概率与严重性整合，《阿拉伯科学与工程期刊》 40 (2015) 421–430。'
- en: '[128] A. Rosenfeld, A. Richardson, Explainability in human–agent systems, Autonomous
    Agents and Multi-Agent Systems 33 (2019) 673–705.'
  id: totrans-2088
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] A. Rosenfeld, A. Richardson, 人机系统中的可解释性，《自主代理与多代理系统》33（2019）673–705。'
- en: '[129] J. K. Choi, Y. G. Ji, Investigating the importance of trust on adopting
    an autonomous vehicle, International Journal of Human-Computer Interaction 31 (10)
    (2015) 692–702.'
  id: totrans-2089
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] J. K. Choi, Y. G. Ji, 研究信任对采纳自动驾驶汽车的重要性，《国际人机交互杂志》31（10）（2015）692–702。'
- en: '[130] J. Haspiel, N. Du, J. Meyerson, L. P. Robert Jr, D. Tilbury, X. J. Yang,
    A. K. Pradhan, Explanations and expectations: Trust building in automated vehicles,
    in: Companion of the 2018 ACM/IEEE international conference on human-robot interaction,
    2018, pp. 119–120.'
  id: totrans-2090
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] J. Haspiel, N. Du, J. Meyerson, L. P. Robert Jr, D. Tilbury, X. J. Yang,
    A. K. Pradhan, 解释与期望：自动驾驶汽车中的信任建立，收录于：2018年ACM/IEEE国际人机交互会议附录，2018年，第119–120页。'
- en: '[131] Y. Tian, K. Pei, S. Jana, B. Ray, Deeptest: Automated testing of deep-neural-network-driven
    autonomous cars. 2017, arXiv preprint arXiv:1708.08559 (2017).'
  id: totrans-2091
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] Y. Tian, K. Pei, S. Jana, B. Ray, Deeptest：自动测试深度神经网络驱动的自动驾驶汽车。2017年，arXiv
    预印本 arXiv:1708.08559（2017）。'
- en: '[132] M. Bojarski, A. Choromanska, K. Choromanski, B. Firner, L. J. Ackel,
    U. Muller, P. Yeres, K. Zieba, Visualbackprop: Efficient visualization of cnns
    for autonomous driving, in: 2018 IEEE International Conference on Robotics and
    Automation (ICRA), IEEE, 2018, pp. 4701–4708.'
  id: totrans-2092
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] M. Bojarski, A. Choromanska, K. Choromanski, B. Firner, L. J. Ackel,
    U. Muller, P. Yeres, K. Zieba, Visualbackprop：高效可视化CNN用于自动驾驶，收录于：2018年IEEE国际机器人与自动化会议（ICRA），IEEE，2018年，第4701–4708页。'
- en: '[133] K. Mori, H. Fukui, T. Murase, T. Hirakawa, T. Yamashita, H. Fujiyoshi,
    Visual explanation by attention branch network for end-to-end learning-based self-driving,
    in: 2019 IEEE intelligent vehicles symposium (IV), IEEE, 2019, pp. 1577–1582.'
  id: totrans-2093
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] K. Mori, H. Fukui, T. Murase, T. Hirakawa, T. Yamashita, H. Fujiyoshi,
    通过注意力分支网络进行视觉解释，用于端到端学习的自动驾驶，收录于：2019年IEEE智能车辆研讨会（IV），IEEE，2019年，第1577–1582页。'
- en: '[134] P. Jacob, É. Zablocki, H. Ben-Younes, M. Chen, P. Pérez, M. Cord, Steex:
    steering counterfactual explanations with semantics, in: Computer Vision–ECCV
    2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings,
    Part XII, Springer, 2022, pp. 387–403.'
  id: totrans-2094
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] P. Jacob, É. Zablocki, H. Ben-Younes, M. Chen, P. Pérez, M. Cord, Steex：通过语义引导反事实解释，收录于：计算机视觉–ECCV
    2022：第17届欧洲会议，特拉维夫，以色列，2022年10月23–27日，论文集，第十二部分，施普林格，2022年，第387–403页。'
- en: '[135] M. Bansal, A. Krizhevsky, A. Ogale, Chauffeurnet: Learning to drive by
    imitating the best and synthesizing the worst, arXiv preprint arXiv:1812.03079
    (2018).'
  id: totrans-2095
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] M. Bansal, A. Krizhevsky, A. Ogale, Chauffeurnet：通过模仿最佳并合成最差来学习驾驶，arXiv
    预印本 arXiv:1812.03079（2018）。'
- en: '[136] N. Frosst, G. Hinton, Distilling a neural network into a soft decision
    tree, arXiv preprint arXiv:1711.09784 (2017).'
  id: totrans-2096
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] N. Frosst, G. Hinton, 将神经网络蒸馏成软决策树，arXiv 预印本 arXiv:1711.09784（2017）。'
- en: '[137] J. R. Zilke, E. Loza Mencía, F. Janssen, Deepred–rule extraction from
    deep neural networks, in: Discovery Science: 19th International Conference, DS
    2016, Bari, Italy, October 19–21, 2016, Proceedings 19, Springer, 2016, pp. 457–473.'
  id: totrans-2097
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] J. R. Zilke, E. Loza Mencía, F. Janssen, Deepred–从深度神经网络中提取规则，收录于：发现科学：第19届国际会议，DS
    2016，意大利巴里，2016年10月19–21日，论文集19，施普林格，2016年，第457–473页。'
- en: '[138] M. Harradon, J. Druce, B. Ruttenberg, Causal learning and explanation
    of deep neural networks via autoencoded activations, arXiv preprint arXiv:1802.00541
    (2018).'
  id: totrans-2098
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] M. Harradon, J. Druce, B. Ruttenberg, 通过自编码激活对深度神经网络进行因果学习和解释，arXiv 预印本
    arXiv:1802.00541（2018）。'
- en: '[139] Q.-s. Zhang, S.-C. Zhu, Visual interpretability for deep learning: a
    survey, Frontiers of Information Technology & Electronic Engineering 19 (1) (2018)
    27–39.'
  id: totrans-2099
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] Q.-s. Zhang, S.-C. Zhu, 深度学习的视觉可解释性：综述，《信息技术与电子工程前沿》19（1）（2018）27–39。'
- en: '[140] D. Bau, B. Zhou, A. Khosla, A. Oliva, A. Torralba, Network dissection:
    Quantifying interpretability of deep visual representations, in: Proceedings of
    the IEEE conference on computer vision and pattern recognition, 2017, pp. 6541–6549.'
  id: totrans-2100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] D. Bau, B. Zhou, A. Khosla, A. Oliva, A. Torralba, 网络解剖：量化深度视觉表征的可解释性，收录于：IEEE计算机视觉与模式识别会议论文集，2017年，第6541–6549页。'
- en: '[141] K. Simonyan, A. Vedaldi, A. Zisserman, Deep inside convolutional networks:
    visualising image classification models and saliency maps, in: Proceedings of
    the International Conference on Learning Representations (ICLR), ICLR, 2014.'
  id: totrans-2101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] K. Simonyan, A. Vedaldi, A. Zisserman, 深入卷积网络：可视化图像分类模型和显著性图，收录于：国际学习表征会议（ICLR）论文集，ICLR，2014。'
- en: '[142] A. Nguyen, A. Dosovitskiy, J. Yosinski, T. Brox, J. Clune, Synthesizing
    the preferred inputs for neurons in neural networks via deep generator networks,
    Advances in neural information processing systems 29 (2016).'
  id: totrans-2102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] A. Nguyen, A. Dosovitskiy, J. Yosinski, T. Brox, J. Clune, 通过深度生成网络合成神经网络中神经元的优选输入，神经信息处理系统进展
    29 (2016)。'
- en: '[143] L. Rosero, J. Silva, D. Wolf, F. Osório, Cnn-planner: A neural path planner
    based on sensor fusion in the bird’s eye view representation space for mapless
    autonomous driving, in: 2022 Latin American Robotics Symposium (LARS), 2022 Brazilian
    Symposium on Robotics (SBR), and 2022 Workshop on Robotics in Education (WRE),
    2022, pp. 181–186. [doi:10.1109/LARS/SBR/WRE56824.2022.9995888](https://doi.org/10.1109/LARS/SBR/WRE56824.2022.9995888).'
  id: totrans-2103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] L. Rosero, J. Silva, D. Wolf, F. Osório, Cnn-planner: 基于鸟瞰图表示空间的传感器融合的神经路径规划器，用于无地图的自动驾驶，发表于2022年拉丁美洲机器人学研讨会
    (LARS)、2022年巴西机器人学研讨会 (SBR) 和2022年教育机器人研讨会 (WRE) 论文集，2022年，页码181–186。[doi:10.1109/LARS/SBR/WRE56824.2022.9995888](https://doi.org/10.1109/LARS/SBR/WRE56824.2022.9995888)。'
- en: '[144] L. A. Rosero, I. P. Gomes, J. A. R. da Silva, T. C. dos Santos, A. T. M.
    Nakamura, J. Amaro, D. F. Wolf, F. S. Osório, A software architecture for autonomous
    vehicles: Team lrm-b entry in the first carla autonomous driving challenge (2020).
    [arXiv:2010.12598](http://arxiv.org/abs/2010.12598).'
  id: totrans-2104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] L. A. Rosero, I. P. Gomes, J. A. R. da Silva, T. C. dos Santos, A. T.
    M. Nakamura, J. Amaro, D. F. Wolf, F. S. Osório, 自动驾驶车辆的软件架构：团队 LRM-B 在首届 CARLA
    自动驾驶挑战中的参赛作品 (2020)。[arXiv:2010.12598](http://arxiv.org/abs/2010.12598)。'
- en: '[145] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, A. Krishnan,
    Y. Pan, G. Baldan, O. Beijbom, nuscenes: A multimodal dataset for autonomous driving,
    in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,
    2020, pp. 11621–11631.'
  id: totrans-2105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, A. Krishnan,
    Y. Pan, G. Baldan, O. Beijbom, nuscenes：一个用于自动驾驶的多模态数据集，发表于 IEEE/CVF 计算机视觉与模式识别会议论文集，2020年，页码11621–11631。'
- en: '[146] X. Huang, P. Wang, X. Cheng, D. Zhou, Q. Geng, R. Yang, The apolloscape
    open dataset for autonomous driving and its application, IEEE transactions on
    pattern analysis and machine intelligence 42 (10) (2019) 2702–2719.'
  id: totrans-2106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] X. Huang, P. Wang, X. Cheng, D. Zhou, Q. Geng, R. Yang, Apolloscape 开放数据集用于自动驾驶及其应用，IEEE
    模式分析与机器智能汇刊 42 (10) (2019) 2702–2719。'
- en: '[147] [Automated Driving Toolbox](https://in.mathworks.com/products/automated-driving.html).'
  id: totrans-2107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] [Automated Driving Toolbox](https://in.mathworks.com/products/automated-driving.html)。'
- en: URL [https://in.mathworks.com/products/automated-driving.html](https://in.mathworks.com/products/automated-driving.html)
  id: totrans-2108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [https://in.mathworks.com/products/automated-driving.html](https://in.mathworks.com/products/automated-driving.html)
- en: '[148] [Mechanical Simulation](https://www.carsim.com/).'
  id: totrans-2109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] [Mechanical Simulation](https://www.carsim.com/)。'
- en: URL [https://www.carsim.com/](https://www.carsim.com/)
  id: totrans-2110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [https://www.carsim.com/](https://www.carsim.com/)
- en: '[149] [PreScan](https://in.mathworks.com/products/connections/product_detail/prescan.html).'
  id: totrans-2111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] [PreScan](https://in.mathworks.com/products/connections/product_detail/prescan.html)。'
- en: URL [https://in.mathworks.com/products/connections/product_detail/prescan.html](https://in.mathworks.com/products/connections/product_detail/prescan.html)
  id: totrans-2112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [https://in.mathworks.com/products/connections/product_detail/prescan.html](https://in.mathworks.com/products/connections/product_detail/prescan.html)
- en: '[150] [Gazebo](https://classic.gazebosim.org/).'
  id: totrans-2113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] [Gazebo](https://classic.gazebosim.org/)。'
- en: URL [https://classic.gazebosim.org/](https://classic.gazebosim.org/)
  id: totrans-2114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [https://classic.gazebosim.org/](https://classic.gazebosim.org/)
- en: '[151] [SVL Simulator by LG - Autonomous and Robotics real-time sensor Simulation,
    LiDAR, Camera simulation for ROS1, ROS2, Autoware, Baidu Apollo. Perception, Planning,
    Localization, SIL and HIL Simulation, Open Source and Free.](https://www.svlsimulator.com/)'
  id: totrans-2115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] [SVL Simulator by LG - 自动化和机器人实时传感器仿真，LiDAR，摄像头仿真用于 ROS1、ROS2、Autoware、百度
    Apollo。感知、规划、定位、SIL 和 HIL 仿真，开源和免费。](https://www.svlsimulator.com/)'
- en: URL [https://www.svlsimulator.com/](https://www.svlsimulator.com/)
  id: totrans-2116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [https://www.svlsimulator.com/](https://www.svlsimulator.com/)
- en: '[152] Udacity: Public driving dataset, [https://github.com/udacity/self-driving-car/tree/master/datasets](https://github.com/udacity/self-driving-car/tree/master/datasets)
    (2017).'
  id: totrans-2117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] Udacity: 公开驾驶数据集，[https://github.com/udacity/self-driving-car/tree/master/datasets](https://github.com/udacity/self-driving-car/tree/master/datasets)
    (2017)。'
- en: '[153] S. Hecker, D. Dai, L. Van Gool, End-to-end learning of driving models
    with surround-view cameras and route planners, in: Proceedings of the European
    Conference on Computer Vision (ECCV), 2018, pp. 435–453.'
  id: totrans-2118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] S. Hecker, D. Dai, L. Van Gool, 基于环视摄像头和路径规划器的端到端驾驶模型学习，发表于欧洲计算机视觉会议
    (ECCV) 论文集，2018年，页码435–453。'
- en: '[154] E. Santana, G. Hotz, Learning a driving simulator, arXiv preprint arXiv:1608.01230
    (2016).'
  id: totrans-2119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] E. Santana, G. Hotz, 学习驾驶模拟器，arXiv 预印本 arXiv:1608.01230 (2016)。'
- en: '[155] H. Schafer, E. Santana, A. Haden, R. Biasini, A commute in data: The
    comma2k19 dataset, arXiv preprint arXiv:1812.05752 (2018).'
  id: totrans-2120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] H. Schafer, E. Santana, A. Haden, R. Biasini, 数据中的通勤：Comma2k19数据集，arXiv预印本arXiv:1812.05752（2018）。'
- en: '[156] F. Yu, H. Chen, X. Wang, W. Xian, Y. Chen, F. Liu, V. Madhavan, T. Darrell,
    Bdd100k: A diverse driving dataset for heterogeneous multitask learning, in: Proceedings
    of the IEEE/CVF conference on computer vision and pattern recognition, 2020, pp.
    2636–2645.'
  id: totrans-2121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] F. Yu, H. Chen, X. Wang, W. Xian, Y. Chen, F. Liu, V. Madhavan, T. Darrell,
    Bdd100k: 一个多样化的驾驶数据集，用于异构多任务学习，见：《IEEE/CVF计算机视觉与模式识别会议论文集》，2020年，页2636–2645。'
- en: '[157] V. Ramanishka, Y.-T. Chen, T. Misu, K. Saenko, Toward driving scene understanding:
    A dataset for learning driver behavior and causal reasoning, in: Proceedings of
    the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 7699–7707.'
  id: totrans-2122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] V. Ramanishka, Y.-T. Chen, T. Misu, K. Saenko, 驾驶场景理解：用于学习驾驶员行为和因果推理的数据集，见：《IEEE计算机视觉与模式识别会议论文集》，2018年，页7699–7707。'
- en: '[158] A. Jain, H. S. Koppula, B. Raghavan, S. Soh, A. Saxena, Car that knows
    before you do: Anticipating maneuvers via learning temporal driving models, in:
    Proceedings of the IEEE International Conference on Computer Vision, 2015, pp.
    3182–3190.'
  id: totrans-2123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] A. Jain, H. S. Koppula, B. Raghavan, S. Soh, A. Saxena, 车在你之前知道：通过学习时间驾驶模型预测驾驶动作，见：《IEEE国际计算机视觉会议论文集》，2015年，页3182–3190。'
- en: '[159] Y. Chen, J. Wang, J. Li, C. Lu, Z. Luo, H. Xue, C. Wang, Lidar-video
    driving dataset: Learning driving policies effectively, in: Proceedings of the
    IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 5870–5878.'
  id: totrans-2124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[159] Y. Chen, J. Wang, J. Li, C. Lu, Z. Luo, H. Xue, C. Wang, 激光雷达视频驾驶数据集：有效学习驾驶策略，见：《IEEE计算机视觉与模式识别会议论文集》，2018年，页5870–5878。'
- en: '[160] Large-scale driving behavior dataset, [http://www.dbehavior.net/index.html](http://www.dbehavior.net/index.html).'
  id: totrans-2125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[160] 大规模驾驶行为数据集，[http://www.dbehavior.net/index.html](http://www.dbehavior.net/index.html)。'
- en: '[161] Y. Hu, J. Binas, D. Neil, S.-C. Liu, T. Delbruck, Ddd20 end-to-end event
    camera driving dataset: Fusing frames and events with deep learning for improved
    steering prediction, in: 2020 IEEE 23rd International Conference on Intelligent
    Transportation Systems (ITSC), IEEE, 2020, pp. 1–6.'
  id: totrans-2126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[161] Y. Hu, J. Binas, D. Neil, S.-C. Liu, T. Delbruck, Ddd20端到端事件相机驾驶数据集：利用深度学习融合帧和事件以提高转向预测，见：2020年IEEE第23届智能交通系统国际会议（ITSC），IEEE，2020年，页1–6。'
- en: '[162] J. Geyer, Y. Kassahun, M. Mahmudi, X. Ricou, R. Durgesh, A. S. Chung,
    L. Hauswald, V. H. Pham, M. Mhlegg, S. Dorn, et al., A2d2: Aev autonomous driving
    dataset, [https://www.audi-electronics-venture.com/aev/web/en/driving-dataset.html](https://www.audi-electronics-venture.com/aev/web/en/driving-dataset.html)
    (2019).'
  id: totrans-2127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[162] J. Geyer, Y. Kassahun, M. Mahmudi, X. Ricou, R. Durgesh, A. S. Chung,
    L. Hauswald, V. H. Pham, M. Mhlegg, S. Dorn, 等，A2d2: AEV自动驾驶数据集，[https://www.audi-electronics-venture.com/aev/web/en/driving-dataset.html](https://www.audi-electronics-venture.com/aev/web/en/driving-dataset.html)（2019）。'
- en: '[163] P. Sun, H. Kretzschmar, X. Dotiwalla, A. Chouard, V. Patnaik, P. Tsui,
    J. Guo, Y. Zhou, Y. Chai, B. Caine, et al., Scalability in perception for autonomous
    driving: Waymo open dataset, arXiv (2019) arXiv–1912.'
  id: totrans-2128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[163] P. Sun, H. Kretzschmar, X. Dotiwalla, A. Chouard, V. Patnaik, P. Tsui,
    J. Guo, Y. Zhou, Y. Chai, B. Caine, 等，自动驾驶中的感知可扩展性：Waymo开放数据集，arXiv（2019）arXiv–1912。'
- en: '[164] J. Kim, T. Misu, Y.-T. Chen, A. Tawari, J. Canny, Grounding human-to-vehicle
    advice for self-driving vehicles, in: Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition, 2019, pp. 10591–10599.'
  id: totrans-2129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[164] J. Kim, T. Misu, Y.-T. Chen, A. Tawari, J. Canny, 为自驾车提供人机建议的基础，见：《IEEE计算机视觉与模式识别会议论文集》，2019年，页10591–10599。'
- en: '[165] J. Sang, Z. Wu, P. Guo, H. Hu, H. Xiang, Q. Zhang, B. Cai, An improved
    yolov2 for vehicle detection, Sensors 18 (2018) 4272. [doi:10.3390/s18124272](https://doi.org/10.3390/s18124272).'
  id: totrans-2130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[165] J. Sang, Z. Wu, P. Guo, H. Hu, H. Xiang, Q. Zhang, B. Cai, 改进的yolov2用于车辆检测，《传感器》18（2018）4272。[doi:10.3390/s18124272](https://doi.org/10.3390/s18124272)。'
- en: '[166] L. Wen, D. Du, Z. Cai, Z. Lei, M.-C. Chang, H. Qi, J. Lim, M.-H. Yang,
    S. Lyu, Ua-detrac: A new benchmark and protocol for multi-object detection and
    tracking, Computer Vision and Image Understanding 193 (2020) 102907.'
  id: totrans-2131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[166] L. Wen, D. Du, Z. Cai, Z. Lei, M.-C. Chang, H. Qi, J. Lim, M.-H. Yang,
    S. Lyu, Ua-detrac: 一个新的多目标检测和跟踪基准及协议，《计算机视觉与图像理解》193 (2020) 102907。'
- en: '[167] D. Tabernik, D. Skočaj, Deep Learning for Large-Scale Traffic-Sign Detection
    and Recognition, IEEE Transactions on Intelligent Transportation Systems (2019).
    [doi:10.1109/TITS.2019.2913588](https://doi.org/10.1109/TITS.2019.2913588).'
  id: totrans-2132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[167] D. Tabernik, D. Skočaj, 大规模交通标志检测与识别的深度学习，《IEEE智能交通系统汇刊》（2019）。[doi:10.1109/TITS.2019.2913588](https://doi.org/10.1109/TITS.2019.2913588)。'
- en: '[168] K. Behrendt, L. Novak, A deep learning approach to traffic lights: Detection,
    tracking, and classification, in: Robotics and Automation (ICRA), 2017 IEEE International
    Conference on, IEEE.'
  id: totrans-2133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[168] K. Behrendt, L. Novak, 深度学习方法用于交通信号灯：检测、跟踪和分类，发表于：2017年IEEE国际机器人与自动化会议（ICRA），IEEE。'
- en: '[169] Z. Zhu, D. Liang, S. Zhang, X. Huang, B. Li, S. Hu, Traffic-sign detection
    and classification in the wild, in: The IEEE Conference on Computer Vision and
    Pattern Recognition (CVPR), 2016.'
  id: totrans-2134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[169] Z. Zhu, D. Liang, S. Zhang, X. Huang, B. Li, S. Hu, 野外交通标志检测与分类，发表于：2016年IEEE计算机视觉与模式识别会议（CVPR）。'
- en: '[170] M. B. Jensen, M. P. Philipsen, A. Møgelmose, T. B. Moeslund, M. M. Trivedi,
    Vision for looking at traffic lights: Issues, survey, and perspectives, IEEE Transactions
    on Intelligent Transportation Systems 17 (7) (2016) 1800–1815. [doi:10.1109/TITS.2015.2509509](https://doi.org/10.1109/TITS.2015.2509509).'
  id: totrans-2135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[170] M. B. Jensen, M. P. Philipsen, A. Møgelmose, T. B. Moeslund, M. M. Trivedi,
    交通信号灯的视觉：问题、调查和观点，IEEE智能交通系统学报 17 (7) (2016) 1800–1815。 [doi:10.1109/TITS.2015.2509509](https://doi.org/10.1109/TITS.2015.2509509)。'
- en: '[171] F. Larsson, M. Felsberg, Using fourier descriptors and spatial models
    for traffic sign recognition, 2011, pp. 238–249. [doi:10.1007/978-3-642-21227-7_23](https://doi.org/10.1007/978-3-642-21227-7_23).'
  id: totrans-2136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[171] F. Larsson, M. Felsberg, 使用傅里叶描述符和空间模型进行交通标志识别，2011年，第238–249页。 [doi:10.1007/978-3-642-21227-7_23](https://doi.org/10.1007/978-3-642-21227-7_23).'
- en: '[172] J. Stallkamp, M. Schlipsing, J. Salmen, C. Igel, The german traffic sign
    recognition benchmark: a multi-class classification competition, in: The 2011
    international joint conference on neural networks, IEEE, 2011, pp. 1453–1460.'
  id: totrans-2137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[172] J. Stallkamp, M. Schlipsing, J. Salmen, C. Igel, 德国交通标志识别基准：一个多类别分类竞赛，发表于：2011年国际神经网络联合会议，IEEE，第1453–1460页。'
- en: '[173] M. Mathias, R. Timofte, R. Benenson, L. Van Gool, Traffic sign recognition—how
    far are we from the solution?, in: The 2013 international joint conference on
    Neural networks (IJCNN), IEEE, 2013, pp. 1–8.'
  id: totrans-2138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[173] M. Mathias, R. Timofte, R. Benenson, L. Van Gool, 交通标志识别——我们离解决方案还有多远？，发表于：2013年国际神经网络联合会议（IJCNN），IEEE，第1–8页。'
- en: '[174] P. Dollár, C. Wojek, B. Schiele, P. Perona, Pedestrian detection: A benchmark,
    in: 2009 IEEE conference on computer vision and pattern recognition, IEEE, 2009,
    pp. 304–311.'
  id: totrans-2139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[174] P. Dollár, C. Wojek, B. Schiele, P. Perona, 行人检测：一个基准，发表于：2009年IEEE计算机视觉与模式识别会议，IEEE，第304–311页。'
- en: '[175] G. J. Brostow, J. Fauqueur, R. Cipolla, Semantic object classes in video:
    A high-definition ground truth database, Pattern Recognition Letters 30 (2) (2009)
    88–97.'
  id: totrans-2140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[175] G. J. Brostow, J. Fauqueur, R. Cipolla, 视频中的语义对象类别：一个高清地面实况数据库，模式识别快报
    30 (2) (2009) 88–97。'
- en: '[176] S. Agarwal, A. Vora, G. Pandey, W. Williams, H. Kourous, J. McBride,
    [Ford multi-AV seasonal dataset](https://doi.org/10.1177%2F0278364920961451),
    The International Journal of Robotics Research 39 (12) (2020) 1367–1376. [doi:10.1177/0278364920961451](https://doi.org/10.1177/0278364920961451).'
  id: totrans-2141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[176] S. Agarwal, A. Vora, G. Pandey, W. Williams, H. Kourous, J. McBride,
    [Ford multi-AV seasonal dataset](https://doi.org/10.1177%2F0278364920961451)，国际机器人研究杂志
    39 (12) (2020) 1367–1376。 [doi:10.1177/0278364920961451](https://doi.org/10.1177/0278364920961451)。'
- en: URL [https://doi.org/10.1177%2F0278364920961451](https://doi.org/10.1177%2F0278364920961451)
  id: totrans-2142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [https://doi.org/10.1177%2F0278364920961451](https://doi.org/10.1177%2F0278364920961451)
- en: '[177] M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson,
    U. Franke, S. Roth, B. Schiele, The cityscapes dataset for semantic urban scene
    understanding, in: Proceedings of the IEEE conference on computer vision and pattern
    recognition, 2016, pp. 3213–3223.'
  id: totrans-2143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[177] M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson,
    U. Franke, S. Roth, B. Schiele, cityscapes 数据集用于城市场景的语义理解，发表于：2016年IEEE计算机视觉与模式识别会议论文集，第3213–3223页。'
- en: '[178] G. Neuhold, T. Ollmann, S. Rota Bulo, P. Kontschieder, The mapillary
    vistas dataset for semantic understanding of street scenes, in: Proceedings of
    the IEEE international conference on computer vision, 2017, pp. 4990–4999.'
  id: totrans-2144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[178] G. Neuhold, T. Ollmann, S. Rota Bulo, P. Kontschieder, mapillary vistas
    数据集用于街景的语义理解，发表于：2017年IEEE国际计算机视觉会议论文集，第4990–4999页。'
- en: '[179] Y. Lou, Y. Bai, J. Liu, S. Wang, L. Duan, Veri-wild: A large dataset
    and a new method for vehicle re-identification in the wild, in: Proceedings of
    the IEEE/CVF conference on computer vision and pattern recognition, 2019, pp.
    3235–3243.'
  id: totrans-2145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[179] Y. Lou, Y. Bai, J. Liu, S. Wang, L. Duan, Veri-wild：一个大型数据集和用于野外车辆重新识别的新方法，发表于：2019年IEEE/CVF计算机视觉与模式识别会议论文集，第3235–3243页。'
- en: '[180] Z. Che, G. Li, T. Li, B. Jiang, X. Shi, X. Zhang, Y. Lu, G. Wu, Y. Liu,
    J. Ye, D²-city: A large-scale dashcam video dataset of diverse traffic scenarios
    (2019). [arXiv:1904.01975](http://arxiv.org/abs/1904.01975).'
  id: totrans-2146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[180] Z. Che, G. Li, T. Li, B. Jiang, X. Shi, X. Zhang, Y. Lu, G. Wu, Y. Liu,
    J. Ye, “D²-city：大规模行车记录视频数据集中的多样交通场景”（2019）。 [arXiv:1904.01975](http://arxiv.org/abs/1904.01975)'
- en: '[181] L. Ding, J. Terwilliger, R. Sherony, B. Reimer, L. Fridman, [Mit driveseg
    (manual) dataset](https://dx.doi.org/10.21227/mmke-dv03) (2020). [doi:10.21227/mmke-dv03](https://doi.org/10.21227/mmke-dv03).'
  id: totrans-2147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[181] L. Ding, J. Terwilliger, R. Sherony, B. Reimer, L. Fridman, [Mit driveseg
    (manual) 数据集](https://dx.doi.org/10.21227/mmke-dv03) (2020)。 [doi:10.21227/mmke-dv03](https://doi.org/10.21227/mmke-dv03)。'
- en: URL [https://dx.doi.org/10.21227/mmke-dv03](https://dx.doi.org/10.21227/mmke-dv03)
  id: totrans-2148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [https://dx.doi.org/10.21227/mmke-dv03](https://dx.doi.org/10.21227/mmke-dv03)
- en: '[182] Y. L. Yue Hu, R. Xu, W. Xie, Y. W. Siheng Chen, Collaboration helps camera
    overtake lidar in 3d detection, in: The IEEE/CVF Conference on Computer Vision
    and Pattern Recognition (CVPR), 2023.'
  id: totrans-2149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[182] Y. L. Yue Hu, R. Xu, W. Xie, Y. W. Siheng Chen, “合作帮助相机超越激光雷达进行 3D 检测”，在：IEEE/CVF
    计算机视觉与模式识别会议 (CVPR)，2023。'
- en: '[183] H. Xiang, R. Xu, J. Ma, Hm-vit: Hetero-modal vehicle-to-vehicle cooperative
    perception with vision transformer, arXiv preprint arXiv:2304.10628 (2023).'
  id: totrans-2150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[183] H. Xiang, R. Xu, J. Ma, “Hm-vit：使用视觉变换器的异模态车与车合作感知”，arXiv 预印本 arXiv:2304.10628
    (2023)。'
- en: '[184] B. Wang, L. Zhang, Z. Wang, Y. Zhao, T. Zhou, Core: Cooperative reconstruction
    for multi-agent perception, arXiv preprint arXiv:2307.11514 (2023).'
  id: totrans-2151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[184] B. Wang, L. Zhang, Z. Wang, Y. Zhao, T. Zhou, “核心：多智能体感知的合作重建”，arXiv
    预印本 arXiv:2307.11514 (2023)。'
- en: '[185] Y. Cheng, L. Li, Y. Xu, X. Li, Z. Yang, W. Wang, Y. Yang, Segment and
    track anything, arXiv preprint arXiv:2305.06558 (2023).'
  id: totrans-2152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[185] Y. Cheng, L. Li, Y. Xu, X. Li, Z. Yang, W. Wang, Y. Yang, “分割和跟踪一切”，arXiv
    预印本 arXiv:2305.06558 (2023)。'
- en: '[186] Y. Jiang, A. Gupta, Z. Zhang, G. Wang, Y. Dou, Y. Chen, L. Fei-Fei, A. Anandkumar,
    Y. Zhu, L. Fan, Vima: General robot manipulation with multimodal prompts, arXiv
    preprint arXiv:2210.03094 (2022).'
  id: totrans-2153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[186] Y. Jiang, A. Gupta, Z. Zhang, G. Wang, Y. Dou, Y. Chen, L. Fei-Fei, A.
    Anandkumar, Y. Zhu, L. Fan, “Vima：具有多模态提示的通用机器人操作”，arXiv 预印本 arXiv:2210.03094
    (2022)。'
- en: \bio
  id: totrans-2154
  prefs: []
  type: TYPE_NORMAL
  zh: \bio
- en: pranav_photo.jpeg Pranav Singh Chib is a Ph.D. candidate in the Computer Science
    and Engineering department at the Indian Institute of Technology, Roorkee. He
    holds a Post-Graduate Computer Science and Technology Specialization from Jawaharlal
    Nehru University, New Delhi. Pranav’s research interests lie in machine learning,
    computer vision, and autonomous driving. His ongoing doctoral studies focus on
    contributing to advancements in autonomous driving and deep learning. \endbio
  id: totrans-2155
  prefs: []
  type: TYPE_NORMAL
  zh: pranav_photo.jpeg Pranav Singh Chib 是印度理工学院鲁尔基分校计算机科学与工程系的博士候选人。他拥有贾瓦哈拉尔·尼赫鲁大学（新德里）计算机科学与技术专业的研究生学位。Pranav
    的研究兴趣包括机器学习、计算机视觉和自动驾驶。他目前的博士研究致力于推进自动驾驶和深度学习领域的进展。 \endbio
- en: \bio
  id: totrans-2156
  prefs: []
  type: TYPE_NORMAL
  zh: \bio
- en: psingh.jpg Pravendra Singh received his Ph.D. degree from IIT Kanpur. He is
    currently an Assistant Professor in the CSE department at IIT Roorkee, India.
    His research interests include deep learning, machine learning, computer vision,
    and artificial intelligence. He has published papers at internationally reputable
    conferences and journals, including IEEE TPAMI, IJCV, CVPR, ECCV, NeurIPS, AAAI,
    IJCAI, IJCV, Pattern Recognition, Neural Networks, Knowledge-Based Systems, Neurocomputing,
    and others. \endbio
  id: totrans-2157
  prefs: []
  type: TYPE_NORMAL
  zh: psingh.jpg Pravendra Singh 获得了 IIT Kanpur 的博士学位。他目前是印度 IIT Roorkee 计算机科学与工程系的助理教授。他的研究兴趣包括深度学习、机器学习、计算机视觉和人工智能。他在国际知名的会议和期刊上发表了论文，包括
    IEEE TPAMI、IJCV、CVPR、ECCV、NeurIPS、AAAI、IJCAI、IJCV、模式识别、神经网络、知识系统、神经计算等。 \endbio
