- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 19:36:15'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:36:15
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2310.14230] A comprehensive survey on deep active learning and its applications
    in medical image analysis'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2310.14230] 关于深度主动学习及其在医学图像分析中应用的综合综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2310.14230](https://ar5iv.labs.arxiv.org/html/2310.14230)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2310.14230](https://ar5iv.labs.arxiv.org/html/2310.14230)
- en: A comprehensive survey on deep active learning and its applications in medical
    image analysis
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于深度主动学习及其在医学图像分析中应用的综合综述
- en: Haoran Wang Qiuye Jin Shiman Li Siyu Liu Manning Wang Zhijian Song Digital Medical
    Research Center, School of Basic Medical Sciences, Fudan University, Shanghai
    200032, China Shanghai Key Laboratory of Medical Image Computing and Computer
    Assisted Intervention, Shanghai 200032, China Computational Bioscience Research
    Center (CBRC), King Abdullah University of Science and Technology (KAUST), Thuwal
    23955, Saudi Arabia
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Haoran Wang Qiuye Jin Shiman Li Siyu Liu Manning Wang Zhijian Song 数字医学研究中心，基础医学学院，复旦大学，中国上海
    200032 上海医学图像计算与计算机辅助干预重点实验室，中国上海 200032 计算生物科学研究中心（CBRC），阿卜杜拉国王科技大学（KAUST），沙特阿拉伯图瓦尔
    23955
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep learning has achieved widespread success in medical image analysis, leading
    to an increasing demand for large-scale expert-annotated medical image datasets.
    Yet, the high cost of annotating medical images severely hampers the development
    of deep learning in this field. To reduce annotation costs, active learning aims
    to select the most informative samples for annotation and train high-performance
    models with as few labeled samples as possible. In this survey, we review the
    core methods of active learning, including the evaluation of informativeness and
    sampling strategy. For the first time, we provide a detailed summary of the integration
    of active learning with other label-efficient techniques, such as semi-supervised,
    self-supervised learning, and so on. Additionally, we also highlight active learning
    works that are specifically tailored to medical image analysis. In the end, we
    offer our perspectives on the future trends and challenges of active learning
    and its applications in medical image analysis.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在医学图像分析中取得了广泛的成功，导致对大规模专家标注的医学图像数据集的需求不断增加。然而，医学图像标注的高成本严重阻碍了这一领域深度学习的发展。为了降低标注成本，主动学习旨在选择最具信息性的样本进行标注，并以尽可能少的标注样本训练高性能模型。在这项综述中，我们回顾了主动学习的核心方法，包括信息量评估和采样策略。我们首次详细总结了主动学习与其他标签高效技术（如半监督、自监督学习等）的整合。此外，我们还重点介绍了专门针对医学图像分析的主动学习工作。最后，我们提供了对主动学习及其在医学图像分析中应用的未来趋势和挑战的见解。
- en: 'keywords:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Active Learning, Medical Image Analysis, Survey, Deep Learning
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 主动学习、医学图像分析、综述、深度学习
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Medical imaging visualizes anatomical structures and pathological processes.
    It also offers crucial information in lesion detection, diagnosis, treatment planning,
    and surgical intervention. In recent years, the rise of artificial intelligence
    (AI) has led to significant success in medical image analysis. The AI-powered
    systems for medical image analysis have not only approached but even exceeded
    the performance of human experts in certain clinical tasks. Notable examples include
    skin cancer classification [Esteva et al., [2017](#bib.bib46)], lung cancer screening
    with CT scans [Ardila et al., [2019](#bib.bib6)], polyp detection during colonoscopy
    [Wang et al., [2018](#bib.bib189)], and prostate cancer tissue detection in whole-slide
    images [Tolkach et al., [2020](#bib.bib180)]. Therefore, these AI-powered systems
    can be integrated into existing clinical workflows, which helps to improve diagnostic
    accuracy for clinical experts [Sim et al., [2020](#bib.bib169)] and support less-experienced
    clinicians [Tschandl et al., [2020](#bib.bib182)].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 医学成像可视化解剖结构和病理过程。它还提供了在病变检测、诊断、治疗规划和外科干预中的关键数据。近年来，人工智能（AI）的兴起使医学图像分析取得了显著成功。基于AI的医学图像分析系统不仅接近而且在某些临床任务中甚至超越了人类专家的表现。显著的例子包括皮肤癌分类
    [Esteva et al., [2017](#bib.bib46)]、CT扫描肺癌筛查 [Ardila et al., [2019](#bib.bib6)]、结肠镜检查中息肉检测
    [Wang et al., [2018](#bib.bib189)] 以及全切片图像中前列腺癌组织检测 [Tolkach et al., [2020](#bib.bib180)]。因此，这些基于AI的系统可以整合到现有的临床工作流程中，有助于提高临床专家的诊断准确性
    [Sim et al., [2020](#bib.bib169)]，并支持经验不足的临床医生 [Tschandl et al., [2020](#bib.bib182)]。
- en: 'Deep learning (DL) models serve as the core of these AI-powered systems for
    learning complex patterns from raw images and generalizing them to more unseen
    cases. The success of DL often relies on large-scale human-annotated datasets.
    For example, the ImageNet dataset [Deng et al., [2009](#bib.bib41)] contains tens
    of millions of labeled images, and it’s widely used in developing DL models for
    computer vision. The size of medical image datasets keeps expanding, but it is
    still relatively smaller than that of natural image datasets. For example, the
    brain tumor segmentation dataset BraTS [Menze et al., [2014](#bib.bib126), Baid
    et al., [2021](#bib.bib11)] consists of 3D multi-sequence MRI scans. The BraTS
    dataset expanded from 65 patients in 2013 to over 1,200 in 2021. The latter is
    equivalent to more than 700,000 annotated 2D images. However, the high annotation
    cost limits the construction of large-scale medical image datasets, mainly reflected
    in the following two aspects:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）模型作为这些人工智能驱动系统的核心，用于从原始图像中学习复杂模式并将其推广到更多未见的案例中。深度学习的成功往往依赖于大规模人工标注的数据集。例如，ImageNet
    数据集 [Deng et al., [2009](#bib.bib41)] 包含数千万张标注图像，并且广泛用于开发计算机视觉的深度学习模型。医学图像数据集的规模不断扩大，但仍然相对小于自然图像数据集。例如，脑肿瘤分割数据集
    BraTS [Menze et al., [2014](#bib.bib126), Baid et al., [2021](#bib.bib11)] 包含
    3D 多序列 MRI 扫描。BraTS 数据集从 2013 年的 65 名患者扩展到 2021 年的 1200 多名患者。后者相当于超过 70 万张标注的
    2D 图像。然而，高昂的标注成本限制了大规模医学图像数据集的构建，主要体现在以下两个方面：
- en: '![Refer to caption](img/089cdc486770d5b1645061134b100e4b.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![参见图例](img/089cdc486770d5b1645061134b100e4b.png)'
- en: 'Figure 1: Overall framework of this survey.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：本调查的整体框架。
- en: 1\. Fine-grained annotation of medical images is labor-intensive and time-consuming.
    In clinical practice, automatic segmentation helps clinicians outline different
    anatomical structures and lesions more accurately. However, training such a segmentation
    model requires pixel-wise annotation, which is extremely tedious [Rajpurkar et al.,
    [2022](#bib.bib152)]. Another case is in digital pathology. Pathologists usually
    require detailed examinations and interpretations of pathological tissue slices
    under high-magnification microscopes. Due to the complex tissue structures, pathologists
    must continuously adjust the microscope’s magnification. As a result, it usually
    takes 15 to 30 minutes to examine a single slide [Qu et al., [2022](#bib.bib147)].
    Making accurate annotations is even more challenging for pathologists. In conclusion,
    the annotation process in medical image analysis demands a considerable investment
    of time and labor.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 医学图像的细粒度标注工作既费力又耗时。在临床实践中，自动分割有助于临床医生更准确地勾勒出不同的解剖结构和病变。然而，训练这样的分割模型需要逐像素的标注，这非常繁琐[Rajpurkar
    et al., [2022](#bib.bib152)]。另一种情况是在数字病理学中。病理学家通常需要在高倍显微镜下对病理组织切片进行详细检查和解释。由于组织结构复杂，病理学家必须不断调整显微镜的放大倍数。因此，检查单个切片通常需要
    15 到 30 分钟[Qu et al., [2022](#bib.bib147)]。对病理学家而言，做出准确的标注更具挑战性。总之，医学图像分析中的标注过程需要大量的时间和劳动投入。
- en: 2\. The high bar for medical image annotation leads to high costs. In computer
    vision, tasks like object detection and segmentation also require many fine-grained
    annotations. However, the widespread use of crowdsourcing platforms has significantly
    reduced the cost of obtaining high-quality annotations in these tasks [Kovashka
    et al., [2016](#bib.bib102)]. However, crowdsourcing platforms have certain limitations
    in annotating medical images. Firstly, annotating medical images demands both
    medical knowledge and clinical expertise. Some complex cases even require discussions
    among multiple senior experts. Secondly, even in some relatively simple tasks,
    crowdsourcing workers tend to provide annotations of poorer quality than professional
    annotators in medical image analysis. For example, results in Rädsch et al. [[2023](#bib.bib151)]
    supported the conclusion above in annotating the segmentation mask of surgical
    instruments. Finally, crowdsourcing platforms may also raise privacy concerns
    [Rajpurkar et al., [2022](#bib.bib152)]. In summary, high-quality annotations
    often require the involvement of experienced doctors, which inherently increases
    the annotation cost of medical images.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 医学图像标注的高标准导致了高昂的成本。在计算机视觉中，对象检测和分割等任务也需要许多细致的标注。然而，众包平台的广泛使用显著降低了这些任务中获得高质量标注的成本[Kovashka
    et al., [2016](#bib.bib102)]。但众包平台在医学图像标注上存在一定的局限性。首先，医学图像标注要求具备医学知识和临床专业知识。一些复杂的病例甚至需要多位资深专家之间的讨论。其次，即使在一些相对简单的任务中，众包工作者提供的标注质量往往低于专业医学图像分析标注员的水平。例如，Rädsch
    et al. [[2023](#bib.bib151)] 的研究结果支持了在外科器械分割掩膜标注中上述结论。最后，众包平台可能还会引发隐私问题[Rajpurkar
    et al., [2022](#bib.bib152)]。总的来说，高质量的标注往往需要经验丰富的医生参与，这本质上增加了医学图像的标注成本。
- en: The high annotation cost is one of the major bottlenecks of DL in medical image
    analysis. Active learning (AL) is considered one of the most effective solutions
    for reducing annotation costs. The main idea of AL is to select the most informative
    samples for annotation and then train a model with these samples in a supervised
    way. In the general practice of AL, annotating a part of the dataset could reach
    comparable performance of annotating all samples. As a result, AL saves the annotation
    costs by querying as few informative samples for annotation as possible. Specifically,
    we refer to the AL works focusing on training a deep model as deep active learning.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 高昂的标注成本是深度学习在医学图像分析中的主要瓶颈之一。主动学习（AL）被认为是减少标注成本的最有效解决方案之一。AL的主要思想是选择最具信息量的样本进行标注，然后用这些样本以监督方式训练模型。在AL的一般实践中，标注数据集的一部分可以达到与标注所有样本相当的性能。因此，AL通过尽可能少地查询具有信息量的样本来节省标注成本。具体来说，我们将专注于训练深度模型的AL工作称为深度主动学习。
- en: Reviewing AL works in medical image analysis is essential for reducing annotation
    costs. There are already some surveys on AL in machine learning or computer vision.
    Settles [[2009](#bib.bib162)] provided a general introduction and comprehensive
    review of AL works in the machine learning era. After the advent of DL, Ren et al.
    [[2021](#bib.bib154)] reviewed the development of deep active learning and its
    applications in computer vision and natural language processing. Liu et al. [[2022b](#bib.bib113)]
    summarized the model-driven and data-driven sample selectors in deep active learning.
    Zhan et al. [[2022](#bib.bib218)] reimplemented high-impact works in deep active
    learning with fair comparisons. Takezoe et al. [[2023](#bib.bib177)] reviewed
    recent developments of deep active learning in computer vision and its industrial
    applications. Regarding related surveys in medical image analysis, Budd et al.
    [[2021](#bib.bib24)] investigated the role of humans in developing and deploying
    DL in medical image analysis, where AL is considered a vital part of this process.
    In Tajbakhsh et al. [[2020](#bib.bib176)], AL was one of the solutions for training
    high-performance medical image segmentation models with imperfect annotation.
    As one of the methods in label-efficient deep learning for medical image analysis,
    Jin et al. [[2023a](#bib.bib79)] summarized AL methods from model and data uncertainty.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 审查医学图像分析中的主动学习工作对于降低标注成本至关重要。现在已有一些关于机器学习或计算机视觉中的主动学习的调查。Settles [[2009](#bib.bib162)]
    提供了对机器学习时代主动学习工作的概述和全面回顾。在深度学习出现后，Ren et al. [[2021](#bib.bib154)] 回顾了深度主动学习的发展及其在计算机视觉和自然语言处理中的应用。Liu
    et al. [[2022b](#bib.bib113)] 总结了深度主动学习中的模型驱动和数据驱动样本选择器。Zhan et al. [[2022](#bib.bib218)]
    重新实现了深度主动学习中的高影响力工作并进行了公平比较。Takezoe et al. [[2023](#bib.bib177)] 回顾了计算机视觉中深度主动学习的最新进展及其工业应用。关于医学图像分析中的相关调查，Budd
    et al. [[2021](#bib.bib24)] 研究了在医学图像分析中开发和部署深度学习的过程中，人类的作用，其中主动学习被认为是这一过程的重要部分。在Tajbakhsh
    et al. [[2020](#bib.bib176)]中，主动学习被认为是训练具有不完美标注的高性能医学图像分割模型的解决方案之一。作为医学图像分析中标签高效深度学习的方法之一，Jin
    et al. [[2023a](#bib.bib79)] 从模型和数据不确定性角度总结了主动学习方法。
- en: However, the surveys mentioned above have certain limitations. First, new ideas
    and methods are constantly emerging with the rapid development of deep active
    learning. Thus, a more comprehensive survey of AL is needed to cover the latest
    advancements. Second, a recent trend is combining AL with other label-efficient
    techniques, which is also highlighted as a future direction by related surveys
    [Takezoe et al., [2023](#bib.bib177), Budd et al., [2021](#bib.bib24)]. However,
    existing surveys still lack summaries and discussions on this topic. Finally,
    the high annotation cost emphasizes the increased significance of AL in medical
    image analysis, yet related reviews still lack comprehensiveness in this regard.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，以上提到的调查存在一定的局限性。首先，随着深度主动学习的快速发展，新思想和方法不断涌现。因此，需要对主动学习进行更全面的调查，以涵盖最新的进展。其次，最近的趋势是将主动学习与其他标签效率技术结合起来，这也被相关调查[[Takezoe
    et al., [2023](#bib.bib177), Budd et al., [2021](#bib.bib24)]]强调为未来方向。然而，现有调查仍缺乏对此主题的总结和讨论。最后，高昂的标注成本突显了主动学习在医学图像分析中的重要性，但相关综述在这方面仍缺乏全面性。
- en: '![Refer to caption](img/1b6681025e611c587b6401172acca334.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1b6681025e611c587b6401172acca334.png)'
- en: 'Figure 2: Illustration of the process of active learning.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：主动学习过程的插图。
- en: 'This survey comprehensively reviews AL for medical image analysis, including
    core methods, integration with other label-efficient techniques, and AL works
    tailored to medical image analysis. We first searched relevant papers on Google
    Scholar and arXiv platforms using the keyword “Active Learning” and expanded the
    search scope through citations. It should be noted that the included papers in
    this survey mainly belong to the fields of medical image analysis and computer
    vision. AL works on language, time series, tabular data, and graphs are less emphasized.
    Additionally, most works in this survey are published in top-tier journals (including
    TPAMI, TMI, MedIA, JBHI, etc.) and conferences (including CVPR, ICCV, ECCV, ICML,
    ICLR, NeurIPS, MICCAI, ISBI, MIDL, etc.). As a result, this survey involves nearly
    164 relevant AL works with 234 references. The contributions of this paper are
    summarized as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查全面回顾了医学图像分析中的主动学习，包括核心方法、与其他标签高效技术的融合，以及专门针对医学图像分析的主动学习工作。我们首先使用关键词“Active
    Learning”在Google Scholar和arXiv平台上搜索相关论文，并通过引用扩展了搜索范围。需要注意的是，本调查中包含的论文主要属于医学图像分析和计算机视觉领域。对语言、时间序列、表格数据和图形的主动学习工作关注较少。此外，本调查中的大多数工作发表在顶级期刊（包括TPAMI、TMI、MedIA、JBHI等）和会议（包括CVPR、ICCV、ECCV、ICML、ICLR、NeurIPS、MICCAI、ISBI、MIDL等）。因此，本调查涉及近164项相关主动学习工作和234个参考文献。本文的贡献总结如下：
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Through an exhaustive literature search, we provide a comprehensive review and
    a novel taxonomy for AL works, especially those focusing on medical image analysis.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过详尽的文献检索，我们提供了一个全面的回顾和一个新颖的主动学习分类体系，特别是那些专注于医学图像分析的研究。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: While previous surveys mainly focus on evaluating informativeness, we further
    summarize different sampling strategies in deep active learning, such as diversity
    and class-balance strategies, aiming to provide references for future method improvement.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以前的调查主要集中在评估信息量上，我们进一步总结了深度主动学习中的不同采样策略，如多样性和类别平衡策略，旨在为未来方法的改进提供参考。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In line with current trends, this survey is the first to provide a detailed
    review of the integration of AL with other label-efficient techniques, including
    semi-supervised learning, self-supervised learning, domain adaptation, region-based
    active learning, and generative models.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与当前趋势一致，本调查首次详细回顾了主动学习与其他标签高效技术的融合，包括半监督学习、自监督学习、领域适应、基于区域的主动学习和生成模型。
- en: 'The rest of this survey is organized as follows: §[2](#S2 "2 Problem Settings
    and Formulations of Active Learning ‣ A comprehensive survey on deep active learning
    and its applications in medical image analysis") introduces problem settings and
    mathematical formulation of AL, §[3](#S3 "3 Core Methods of Active Learning ‣
    A comprehensive survey on deep active learning and its applications in medical
    image analysis") discusses the core methods of AL, including evaluation of informativeness
    (§[3.1](#S3.SS1 "3.1 Evaluation of Informativeness: Uncertainty ‣ 3 Core Methods
    of Active Learning ‣ A comprehensive survey on deep active learning and its applications
    in medical image analysis") & §[3.2](#S3.SS2 "3.2 Evaluation of Informativeness:
    Representativeness ‣ 3 Core Methods of Active Learning ‣ A comprehensive survey
    on deep active learning and its applications in medical image analysis")) and
    sampling strategies (§[3.3](#S3.SS3 "3.3 Sampling Strategy ‣ 3 Core Methods of
    Active Learning ‣ A comprehensive survey on deep active learning and its applications
    in medical image analysis")), §[4](#S4 "4 Integration of Active Learning and Other
    Label-Efficient Techniques ‣ A comprehensive survey on deep active learning and
    its applications in medical image analysis") reviews the integration of AL with
    other label-efficient techniques, §[5](#S5 "5 Active Learning for Medical Image
    Analysis ‣ 4.5.2 Generative Active Learning ‣ 4.5 Generative Model: Data Augmentation
    and Generative Active Learning ‣ 4.4.3 Region-based Active Domain Adaptation ‣
    4.4 Region-based Active Learning: Smaller Labeling Unit ‣ 4.3 Active Domain Adaptation:
    Tackling Distribution Shift ‣ 4.2.2 Combination of Active Learning and Self-supervised
    Learning ‣ 4.2 Self-supervised Learning: Utilizing Pre-trained Model ‣ 4.1.2 Consistency
    Regularization ‣ 4.1 Semi-supervised Learning: Utilizing Unlabeled Data ‣ 4 Integration
    of Active Learning and Other Label-Efficient Techniques ‣ A comprehensive survey
    on deep active learning and its applications in medical image analysis") summarizes
    AL works tailored to medical image analysis. We discuss existing challenges and
    future directions of AL in §[6](#S6 "6 Challenges and Future Perspectives ‣ 5.3
    Active Learning in Medical Image Reconstruction ‣ 5 Active Learning for Medical
    Image Analysis ‣ 4.5.2 Generative Active Learning ‣ 4.5 Generative Model: Data
    Augmentation and Generative Active Learning ‣ 4.4.3 Region-based Active Domain
    Adaptation ‣ 4.4 Region-based Active Learning: Smaller Labeling Unit ‣ 4.3 Active
    Domain Adaptation: Tackling Distribution Shift ‣ 4.2.2 Combination of Active Learning
    and Self-supervised Learning ‣ 4.2 Self-supervised Learning: Utilizing Pre-trained
    Model ‣ 4.1.2 Consistency Regularization ‣ 4.1 Semi-supervised Learning: Utilizing
    Unlabeled Data ‣ 4 Integration of Active Learning and Other Label-Efficient Techniques
    ‣ A comprehensive survey on deep active learning and its applications in medical
    image analysis") and conclude the whole paper in §[7](#S7 "7 Conclusion ‣ 6.5
    Towards Active Learning with Foundation Models ‣ 6 Challenges and Future Perspectives
    ‣ 5.3 Active Learning in Medical Image Reconstruction ‣ 5 Active Learning for
    Medical Image Analysis ‣ 4.5.2 Generative Active Learning ‣ 4.5 Generative Model:
    Data Augmentation and Generative Active Learning ‣ 4.4.3 Region-based Active Domain
    Adaptation ‣ 4.4 Region-based Active Learning: Smaller Labeling Unit ‣ 4.3 Active
    Domain Adaptation: Tackling Distribution Shift ‣ 4.2.2 Combination of Active Learning
    and Self-supervised Learning ‣ 4.2 Self-supervised Learning: Utilizing Pre-trained
    Model ‣ 4.1.2 Consistency Regularization ‣ 4.1 Semi-supervised Learning: Utilizing
    Unlabeled Data ‣ 4 Integration of Active Learning and Other Label-Efficient Techniques
    ‣ A comprehensive survey on deep active learning and its applications in medical
    image analysis"). The overall framework of this survey is shown in Fig. [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ A comprehensive survey on deep active learning and
    its applications in medical image analysis").'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查的其余部分组织如下：§[2](#S2 "2 问题设置和主动学习的数学公式 ‣ 深度主动学习及其在医学图像分析中的应用的全面调查") 介绍了主动学习（AL）的问题设置和数学公式，§[3](#S3
    "3 主动学习的核心方法 ‣ 深度主动学习及其在医学图像分析中的应用的全面调查") 讨论了AL的核心方法，包括信息量评估（§[3.1](#S3.SS1 "3.1
    信息量评估：不确定性 ‣ 主动学习的核心方法 ‣ 深度主动学习及其在医学图像分析中的应用的全面调查") 和 §[3.2](#S3.SS2 "3.2 信息量评估：代表性
    ‣ 主动学习的核心方法 ‣ 深度主动学习及其在医学图像分析中的应用的全面调查")）以及采样策略（§[3.3](#S3.SS3 "3.3 采样策略 ‣ 主动学习的核心方法
    ‣ 深度主动学习及其在医学图像分析中的应用的全面调查")），§[4](#S4 "4 主动学习与其他标签高效技术的整合 ‣ 深度主动学习及其在医学图像分析中的应用的全面调查")
    回顾了AL与其他标签高效技术的整合，§[5](#S5 "5 医学图像分析中的主动学习 ‣ 4.5.2 生成性主动学习 ‣ 4.5 生成模型：数据增强与生成性主动学习
    ‣ 4.4.3 区域性主动领域适应 ‣ 4.4 区域性主动学习：更小的标记单位 ‣ 4.3 主动领域适应：解决分布偏移 ‣ 4.2.2 主动学习与自监督学习的结合
    ‣ 4.2 自监督学习：利用预训练模型 ‣ 4.1.2 一致性正则化 ‣ 4.1 半监督学习：利用未标记数据 ‣ 4 主动学习与其他标签高效技术的整合 ‣
    深度主动学习及其在医学图像分析中的应用的全面调查") 总结了针对医学图像分析的AL工作。我们在 §[6](#S6 "6 挑战与未来展望 ‣ 5.3 医学图像重建中的主动学习
    ‣ 5 医学图像分析中的主动学习 ‣ 4.5.2 生成性主动学习 ‣ 4.5 生成模型：数据增强与生成性主动学习 ‣ 4.4.3 区域性主动领域适应 ‣ 4.4
    区域性主动学习：更小的标记单位 ‣ 4.3 主动领域适应：解决分布偏移 ‣ 4.2.2 主动学习与自监督学习的结合 ‣ 4.2 自监督学习：利用预训练模型
    ‣ 4.1.2 一致性正则化 ‣ 4.1 半监督学习：利用未标记数据 ‣ 4 主动学习与其他标签高效技术的整合 ‣ 深度主动学习及其在医学图像分析中的应用的全面调查")
    讨论了现有挑战和AL的未来方向，并在 §[7](#S7 "7 结论 ‣ 6.5 基于基础模型的主动学习 ‣ 6 挑战与未来展望 ‣ 5.3 医学图像重建中的主动学习
    ‣ 5 医学图像分析中的主动学习 ‣ 4.5.2 生成性主动学习 ‣ 4.5 生成模型：数据增强与生成性主动学习 ‣ 4.4.3 区域性主动领域适应 ‣ 4.4
    区域性主动学习：更小的标记单位 ‣ 4.3 主动领域适应：解决分布偏移 ‣ 4.2.2 主动学习与自监督学习的结合 ‣ 4.2 自监督学习：利用预训练模型
    ‣ 4.1.2 一致性正则化 ‣ 4.1 半监督学习：利用未标记数据 ‣ 4 主动学习与其他标签高效技术的整合 ‣ 深度主动学习及其在医学图像分析中的应用的全面调查")
    结束整篇论文。该调查的整体框架见图 [1](#S1.F1 "图 1 ‣ 1 介绍 ‣ 深度主动学习及其在医学图像分析中的应用的全面调查")。
- en: Due to the rapid development of AL, many related works are not covered in this
    survey. We refer readers to our constantly updated website¹¹1https://github.com/LightersWang/Awesome-Active-Learning-for-Medical-Image-Analysis
    for the latest progress of AL and its application in medical image analysis.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于主动学习的快速发展，许多相关工作未被覆盖。我们建议读者访问我们不断更新的网站¹¹1https://github.com/LightersWang/Awesome-Active-Learning-for-Medical-Image-Analysis，以获取主动学习及其在医学图像分析中的最新进展。
- en: 2 Problem Settings and Formulations of Active Learning
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 主动学习的问题设置和公式化
- en: 'AL generally involves three problem settings: membership query synthesis, stream-based
    selective sampling, and pool-based active learning [Settles, [2009](#bib.bib162)].
    In the case of membership query synthesis, we can continuously query any samples
    in the input space for annotation, including synthetic samples produced by generative
    models [Angluin, [1988](#bib.bib4), [2004](#bib.bib5)]. We also refer to this
    setting as generative active learning in this survey. Membership query synthesis
    is typically suitable for low-dimensional input spaces. However, when expanded
    to high-dimensional spaces (e.g., images), the queried samples produced by generative
    models could be unidentifiable for human labelers. The recent advances of deep
    generative models have shown great promise in synthesizing realistic medical images,
    and we further discuss its combination with AL in §[4.5](#S4.SS5 "4.5 Generative
    Model: Data Augmentation and Generative Active Learning ‣ 4.4.3 Region-based Active
    Domain Adaptation ‣ 4.4 Region-based Active Learning: Smaller Labeling Unit ‣
    4.3 Active Domain Adaptation: Tackling Distribution Shift ‣ 4.2.2 Combination
    of Active Learning and Self-supervised Learning ‣ 4.2 Self-supervised Learning:
    Utilizing Pre-trained Model ‣ 4.1.2 Consistency Regularization ‣ 4.1 Semi-supervised
    Learning: Utilizing Unlabeled Data ‣ 4 Integration of Active Learning and Other
    Label-Efficient Techniques ‣ A comprehensive survey on deep active learning and
    its applications in medical image analysis"). Stream-based selective sampling
    assumes that samples arrive one by one in a continuous stream, and we need to
    decide whether or not to request annotation for incoming samples [Cohn et al.,
    [1994](#bib.bib38)]. This setting is suitable for scenarios with limited memory,
    such as edge computing, but it neglects sample correlations.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 主动学习（AL）通常涉及三种问题设置：成员查询合成、流式选择性采样和池式主动学习[Settles, [2009](#bib.bib162)]。在成员查询合成的情况下，我们可以持续查询输入空间中的任何样本进行标注，包括生成模型生成的合成样本[Angluin,
    [1988](#bib.bib4), [2004](#bib.bib5)]。在本调查中，我们也称这种设置为生成式主动学习。成员查询合成通常适用于低维输入空间。然而，当扩展到高维空间（例如图像）时，生成模型生成的查询样本可能对人工标注者来说不可辨识。深度生成模型的最新进展在合成真实医学图像方面展现了巨大潜力，我们将在§[4.5](#S4.SS5
    "4.5 生成模型：数据增强与生成式主动学习 ‣ 4.4.3 基于区域的主动领域适应 ‣ 4.4 基于区域的主动学习：较小的标注单元 ‣ 4.3 主动领域适应：应对分布偏移
    ‣ 4.2.2 主动学习与自监督学习的结合 ‣ 4.2 自监督学习：利用预训练模型 ‣ 4.1.2 一致性正则化 ‣ 4.1 半监督学习：利用未标注数据 ‣
    4 主动学习与其他标注高效技术的整合 ‣ 深度主动学习及其在医学图像分析中的应用的综合调查")进一步讨论它与主动学习的结合。流式选择性采样假设样本一个接一个地连续到达，我们需要决定是否对即将到来的样本请求标注[Cohn
    et al., [1994](#bib.bib38)]。这种设置适用于内存有限的场景，如边缘计算，但忽略了样本之间的相关性。
- en: Most AL works follow pool-based active learning, which draw samples from a large
    pool of unlabeled data and requests oracle (e.g., doctors) for annotations. Moreover,
    if multiple samples are selected for labeling at once, we can further call this
    setting “batch-mode”. Deep active learning is in batch-mode by default since retraining
    the model every time a sample is labeled is impractical. Also, one labeled sample
    may not necessarily result in significant performance improvement. Therefore,
    unless otherwise specified, all works in this survey follow the setting of batch-mode
    pool-based active learning.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数主动学习研究遵循池式主动学习，即从大量未标注的数据池中抽取样本，并请求oracle（例如医生）进行标注。此外，如果一次选择多个样本进行标注，我们可以进一步称这种设置为“批量模式”。深度主动学习默认是批量模式，因为每次标注一个样本后重新训练模型是不切实际的。而且，一个标注样本可能不一定导致显著的性能提升。因此，除非另有说明，本调查中的所有工作均遵循批量模式池式主动学习的设置。
- en: 'The flowchart of active learning is illustrated in Fig. [2](#S1.F2 "Figure
    2 ‣ 1 Introduction ‣ A comprehensive survey on deep active learning and its applications
    in medical image analysis"). Assuming a total of $T$ annotation rounds, active
    learning primarily consists of the following steps:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 主动学习的流程图如图[2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ A comprehensive survey on
    deep active learning and its applications in medical image analysis")所示。假设总共有$T$轮标注，主动学习主要包括以下步骤：
- en: '1\. Sample Selection: In the $t$-th round of annotation, $1\leq t\leq T$, an
    acquisition function $A$ is used to evaluate the informativeness of each sample
    in the unlabeled pool $D_{t}^{u}$. Then, a batch of samples is selected with a
    certain sampling strategy $S$. Specifically, the queried dataset of $t$-th round
    $D_{t}^{q}$ is constructed as follow:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 样本选择：在第$t$轮标注中，$1\leq t\leq T$，使用采集函数$A$来评估未标记池$D_{t}^{u}$中每个样本的信息量。然后，采用某种采样策略$S$选择一批样本。具体来说，第$t$轮的查询数据集$D_{t}^{q}$构建如下：
- en: '|  | $D_{t}^{q}=\underset{D_{t}^{q}\subset D_{t}^{u}}{S}\left(\underset{x\in
    D_{t}^{u}}{A}\left(x,f_{\theta_{t-1}}\right),b\right)$ |  | (1) |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|  | $D_{t}^{q}=\underset{D_{t}^{q}\subset D_{t}^{u}}{S}\left(\underset{x\in
    D_{t}^{u}}{A}\left(x,f_{\theta_{t-1}}\right),b\right)$ |  | (1) |'
- en: where $x$ represents sample in the dataset, $D_{t}^{u}$ and $D_{t}^{q}$ are
    unlabeled and queried dataset in round $t$, respectively. $f_{\theta_{t-1}}$ and
    $\theta_{t-1}$ represent the deep model and its parameters from the previous round,
    respectively. The annotation budget $b$ is the number of queried samples for each
    round, far less than the total count of unlabeled samples, i.e., $b=|D_{t}^{q}|\ll|D_{t}^{u}|$.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$x$表示数据集中的样本，$D_{t}^{u}$和$D_{t}^{q}$分别是第$t$轮的未标记数据集和查询数据集。$f_{\theta_{t-1}}$和$\theta_{t-1}$分别表示上一轮的深度模型及其参数。标注预算$b$是每轮查询样本的数量，远小于未标记样本的总数，即$b=|D_{t}^{q}|\ll|D_{t}^{u}|$。
- en: '2\. Annotation by Oracle: After sample selection, the queried set $D_{t}^{q}$
    is sent to oracle (e.g., doctors) for annotation, and newly labeled samples are
    added into the labeled dataset $D_{t}^{l}$. The update of $D_{t}^{l}$ is as follow:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 由Oracle标注：在样本选择后，查询集$D_{t}^{q}$会被送到Oracle（例如医生）进行标注，新增标记样本将被加入到标记数据集$D_{t}^{l}$中。$D_{t}^{l}$的更新如下：
- en: '|  | $D_{t}^{l}=D_{t-1}^{l}\cup\{(x,y)&#124;x\in D_{t}^{q}\}$ |  | (2) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|  | $D_{t}^{l}=D_{t-1}^{l}\cup\{(x,y)\mid x\in D_{t}^{q}\}$ |  | (2) |'
- en: 'where $y$ represents the label of $x$, and $D_{t}^{l}$ and $D_{t-1}^{l}$ denote
    the labeled sets for round $t$ and the previous round, respectively. Besides,
    the queried samples should be removed from the unlabeled set $D_{t}^{u}$:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$y$表示$x$的标签，$D_{t}^{l}$和$D_{t-1}^{l}$分别表示第$t$轮和前一轮的标记集。此外，查询样本应从未标记集$D_{t}^{u}$中移除：
- en: '|  | $D_{t}^{u}=D_{t-1}^{u}\backslash\{(x,y)&#124;x\in D_{t}^{q}\}$ |  | (3)
    |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | $D_{t}^{u}=D_{t-1}^{u}\backslash\{(x,y)\mid x\in D_{t}^{q}\}$ |  | (3)
    |'
- en: '3\. DL Model Training: After oracle annotation, we train the deep model using
    the labeled set of this round $D_{t}^{l}$ in a fully supervised manner. The deep
    model $f_{\theta_{t}}$ is trained on $D_{t}^{l}$ to obtain the optimal parameters
    $\theta_{t}$ for round $t$. The mathematical formulation is as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 深度学习模型训练：在Oracle标注后，我们使用本轮标记集$D_{t}^{l}$以完全监督的方式训练深度模型。深度模型$f_{\theta_{t}}$在$D_{t}^{l}$上进行训练，以获得第$t$轮的最佳参数$\theta_{t}$。数学公式如下：
- en: '|  | $\theta_{t}=\underset{\theta}{\arg\min}\underset{(x,y)\in D_{t}^{l}}{\mathbb{E}}\left[\mathcal{L}(f_{\theta}(x),y)\right]$
    |  | (4) |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '|  | $\theta_{t}=\underset{\theta}{\arg\min}\underset{(x,y)\in D_{t}^{l}}{\mathbb{E}}\left[\mathcal{L}(f_{\theta}(x),y)\right]$
    |  | (4) |'
- en: where $\mathcal{L}$ represents the loss function.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathcal{L}$表示损失函数。
- en: 4\. Repeat steps 1 to 3 until the annotation budget limit is reached.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 重复步骤1至3，直到达到标注预算限制。
- en: 'It is worth noting that the model needs proper initialization to start the
    AL process. If the initial model $f_{\theta_{0}}$ is randomly initialized, it
    could only produce meaningless informativeness. To address this issue, most AL
    works randomly choose some samples as initially labeled dataset $D_{0}^{l}$ and
    train $f_{\theta_{0}}$ upon $D_{0}^{l}$. For more details on better initialization
    of AL using pre-trained models, please refer to §[4.2](#S4.SS2 "4.2 Self-supervised
    Learning: Utilizing Pre-trained Model ‣ 4.1.2 Consistency Regularization ‣ 4.1
    Semi-supervised Learning: Utilizing Unlabeled Data ‣ 4 Integration of Active Learning
    and Other Label-Efficient Techniques ‣ A comprehensive survey on deep active learning
    and its applications in medical image analysis").'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，模型需要适当的初始化才能开始主动学习（AL）过程。如果初始模型 $f_{\theta_{0}}$ 是随机初始化的，它可能只会产生无意义的信息。为了解决这个问题，大多数
    AL 工作会随机选择一些样本作为初始标记数据集 $D_{0}^{l}$ 并在 $D_{0}^{l}$ 上训练 $f_{\theta_{0}}$。有关使用预训练模型更好地初始化
    AL 的详细信息，请参阅 §[4.2](#S4.SS2 "4.2 自监督学习：利用预训练模型 ‣ 4.1.2 一致性正则化 ‣ 4.1 半监督学习：利用未标记数据
    ‣ 4 主动学习与其他标签高效技术的整合 ‣ 深度主动学习及其在医学图像分析中的应用的全面综述")。
- en: 3 Core Methods of Active Learning
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主动学习的 3 个核心方法
- en: 'In this survey, we consider the evaluation of informativeness and sampling
    strategy as the core methods of AL. Informativeness represents the value of annotating
    each sample. Higher informativeness indicates a higher priority to request these
    samples for labeling. Typical metrics of informativeness include uncertainty based
    on model prediction and representativeness based on data distribution. On the
    other hand, the sampling strategy is used to select a small number of unlabeled
    samples for annotation based on their informativeness metrics. Common sampling
    strategies include top-k selection and clustering, etc. Unlike previous surveys,
    we explicitly define sampling strategies as core methods of AL for the first time.
    The rationale is that if a perfect informativeness metric existed, one could simply
    select the samples with the highest value of the informativeness metric according
    to the annotation budget. However, current informativeness metrics are more or
    less flawed to some extent. For instance, redundant and class-imbalanced queries
    are common issues in AL. We need specific sampling strategies to mitigate the
    issues arising from imperfect informativeness metrics. In this section, we reviewed
    uncertainty (§[3.1](#S3.SS1 "3.1 Evaluation of Informativeness: Uncertainty ‣
    3 Core Methods of Active Learning ‣ A comprehensive survey on deep active learning
    and its applications in medical image analysis")), informativeness (§[3.2](#S3.SS2
    "3.2 Evaluation of Informativeness: Representativeness ‣ 3 Core Methods of Active
    Learning ‣ A comprehensive survey on deep active learning and its applications
    in medical image analysis")) and sampling strategy (§[3.3](#S3.SS3 "3.3 Sampling
    Strategy ‣ 3 Core Methods of Active Learning ‣ A comprehensive survey on deep
    active learning and its applications in medical image analysis")). Additionally,
    we provide a summarization of all works in this survey. Methods and basic metrics
    of calculating uncertainty or representativeness and sampling strategies are detailed
    in Table [4](#S4 "4 Integration of Active Learning and Other Label-Efficient Techniques
    ‣ A comprehensive survey on deep active learning and its applications in medical
    image analysis").'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项调查中，我们将信息量评估和采样策略视为主动学习的核心方法。信息量代表了对每个样本进行标注的价值。更高的信息量表明这些样本的标注优先级更高。信息量的典型度量包括基于模型预测的不确定性和基于数据分布的代表性。另一方面，采样策略用于根据样本的信息量度量选择少量未标记样本进行标注。常见的采样策略包括top-k选择和聚类等。与之前的调查不同，我们首次明确将采样策略定义为主动学习的核心方法。其理由是，如果存在完美的信息量度量，可以简单地根据标注预算选择信息量度量值最高的样本。然而，目前的信息量度量在某种程度上或多或少存在缺陷。例如，冗余和类别不平衡查询是主动学习中的常见问题。我们需要具体的采样策略来缓解由于信息量度量不完美而产生的问题。在本节中，我们回顾了不确定性（§[3.1](#S3.SS1
    "3.1 信息量评估：不确定性 ‣ 主动学习的核心方法 ‣ 深度主动学习及其在医学图像分析中的应用的综合调查")）、信息量（§[3.2](#S3.SS2 "3.2
    信息量评估：代表性 ‣ 主动学习的核心方法 ‣ 深度主动学习及其在医学图像分析中的应用的综合调查")）和采样策略（§[3.3](#S3.SS3 "3.3 采样策略
    ‣ 主动学习的核心方法 ‣ 深度主动学习及其在医学图像分析中的应用的综合调查")）。此外，我们提供了对本调查中所有工作的总结。计算不确定性或代表性以及采样策略的方法和基本度量在表[4](#S4
    "4 主动学习与其他标签高效技术的整合 ‣ 深度主动学习及其在医学图像分析中的应用的综合调查")中详细说明。
- en: '3.1 Evaluation of Informativeness: Uncertainty'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 信息量评估：不确定性
- en: Uncertainty is used to assess the reliability of model predictions, with higher
    uncertainty indicating the model may be more prone to errors [Kendall and Gal,
    [2017](#bib.bib90)]. During sample selection in AL, it is challenging to determine
    the correctness of the model’s predictions. Nevertheless, we can highlight samples
    where the model is prone to making errors by uncertainty estimation. Uncertain
    samples often contain knowledge about the model that has not yet been mastered.
    Annotating them can improve the performance. Therefore, uncertainty has become
    one of the most commonly used informativeness metrics in AL.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定性用于评估模型预测的可靠性，更高的不确定性表明模型可能更容易出现错误[Kendall and Gal, [2017](#bib.bib90)]。在主动学习的样本选择过程中，很难确定模型预测的正确性。然而，我们可以通过不确定性估计突出模型容易出错的样本。不确定样本通常包含模型尚未掌握的知识。对这些样本进行标注可以提高性能。因此，不确定性已成为主动学习中最常用的信息量度量之一。
- en: 'The most straightforward uncertainty metrics are based on prediction probabilities,
    including least confidence [Lewis and Catlett, [1994](#bib.bib107)], entropy [Joshi
    et al., [2009](#bib.bib85)], margin [Roth and Small, [2006](#bib.bib156)], and
    mean variance [Gal et al., [2017](#bib.bib52)]. These metrics have been widely
    used in traditional AL, and their formulations are detailed in Table [1](#S3.T1
    "Table 1 ‣ 3.1 Evaluation of Informativeness: Uncertainty ‣ 3 Core Methods of
    Active Learning ‣ A comprehensive survey on deep active learning and its applications
    in medical image analysis"). Confidence is the probability of the highest predicted
    class. We often adopt the least confidence to measure uncertainty, meaning lower
    confidence indicates higher uncertainty. Entropy is the most common measure of
    uncertainty, with higher entropy indicating higher uncertainty. The margin represents
    the difference between the highest and the second-highest predicted probability,
    with a larger margin indicating greater uncertainty. Besides, a larger mean variance
    indicates higher uncertainty.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '最直接的不确定性度量是基于预测概率的，包括最少置信度 [Lewis and Catlett, [1994](#bib.bib107)]、熵 [Joshi
    et al., [2009](#bib.bib85)]、边际 [Roth and Small, [2006](#bib.bib156)] 和均值方差 [Gal
    et al., [2017](#bib.bib52)]。这些度量在传统的主动学习中被广泛使用，它们的公式在表 [1](#S3.T1 "Table 1 ‣ 3.1
    Evaluation of Informativeness: Uncertainty ‣ 3 Core Methods of Active Learning
    ‣ A comprehensive survey on deep active learning and its applications in medical
    image analysis") 中有详细说明。置信度是最高预测类别的概率。我们通常采用最少置信度来衡量不确定性，即较低的置信度表示较高的不确定性。熵是最常用的不确定性度量，较高的熵表示较高的不确定性。边际代表最高和次高预测概率之间的差异，较大的边际表示更大的不确定性。此外，较大的均值方差表示更高的不确定性。'
- en: 'Table 1: Formulations of Uncertainty Metrics based on Prediction Probability.
    $x$ stands for sample, $f$ is the deep model, while $C$ is the number of classes.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 基于预测概率的不确定性度量公式。$x$ 代表样本，$f$ 是深度模型，而 $C$ 是类别数量。'
- en: '| Name | Equations |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 公式 |'
- en: '| Prediction Probability | $p=\text{Softmax}\left(f\left(x\right)\right)\in\mathbb{R}^{C},p=\left[p_{1},p_{2},\cdots,p_{C}\right]$
    |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 预测概率 | $p=\text{Softmax}\left(f\left(x\right)\right)\in\mathbb{R}^{C},p=\left[p_{1},p_{2},\cdots,p_{C}\right]$
    |'
- en: '| Least Confidence | $1-\underset{i}{\max}{p_{i}}$ |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 最少置信度 | $1-\underset{i}{\max}{p_{i}}$ |'
- en: '| Entropy | $-\sum_{i=1}^{C}{p_{i}\log{p_{i}}}$ |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 熵 | $-\sum_{i=1}^{C}{p_{i}\log{p_{i}}}$ |'
- en: '| Margin | $\ \underset{i}{\max}{p_{i}}-\underset{j,j\neq k}{\max}{p_{j}},k=\underset{i}{\arg\max}{p_{i}}$
    |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 边际 | $\ \underset{i}{\max}{p_{i}}-\underset{j,j\neq k}{\max}{p_{j}},k=\underset{i}{\arg\max}{p_{i}}$
    |'
- en: '| Mean Variance | $-\frac{1}{C}\sum_{i=1}^{C}\left(p_{i}-\bar{p}\right)^{2},\bar{p}=-\frac{1}{C}\sum_{i=1}^{C}p_{i}$
    |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 均值方差 | $-\frac{1}{C}\sum_{i=1}^{C}\left(p_{i}-\bar{p}\right)^{2},\bar{p}=-\frac{1}{C}\sum_{i=1}^{C}p_{i}$
    |'
- en: 'The above uncertainty metrics only require a single forward pass in deep learning.
    However, due to the notorious issue of over-confidence in deep neural networks
    [Guo et al., [2017](#bib.bib60)], they cannot be directly transferred to deep
    AL. In deep learning, over-confidence refers to the model having excessively high
    confidence in its predictions, even though they might not be accurate. Over-confidence
    results in high confidence (e.g., 0.99) of the wrong class for misclassified samples.
    For uncertain samples, it may lead to extreme confidence (e.g., 0.99 or 0.01)
    instead of normal one (e.g., 0.6 or 0.4) as it should. Over-confidence may cause
    distorted uncertainty since it affects the predicted probabilities for all classes.
    This section divides the uncertainty-based AL into multiple inference, disagreement-based
    uncertainty, uncertainty-aware models, gradient-based uncertainty, adversarial-based
    uncertainty, and performance estimation. The first three are primarily based on
    prediction probabilities, while the latter three mostly employ other statistics
    of deep models for uncertainty estimation. The taxonomy of uncertainty-based AL
    is shown in Fig. [3](#S3.F3 "Figure 3 ‣ 3.1 Evaluation of Informativeness: Uncertainty
    ‣ 3 Core Methods of Active Learning ‣ A comprehensive survey on deep active learning
    and its applications in medical image analysis").'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '上述不确定性指标只需要在深度学习中进行一次前向传播。然而，由于深度神经网络中著名的过度自信问题 [Guo 等人, [2017](#bib.bib60)]，这些指标不能直接转移到深度
    AL 中。在深度学习中，过度自信指的是模型对其预测有过高的信心，即使预测可能不准确。过度自信导致对错误分类样本的错误类别具有过高的信心（例如 0.99）。对于不确定的样本，它可能导致极端信心（例如
    0.99 或 0.01），而不是正常的信心（例如 0.6 或 0.4）。过度自信可能导致不确定性的扭曲，因为它影响了所有类别的预测概率。本节将基于不确定性的主动学习分为多次推断、基于不一致性的无效、不确定性感知模型、基于梯度的不确定性、基于对抗的不确定性和性能估计。前三者主要基于预测概率，而后者三者大多采用其他深度模型统计数据来进行不确定性估计。基于不确定性的主动学习分类如图
    [3](#S3.F3 "图 3 ‣ 3.1 信息量评估: 不确定性 ‣ 3 主动学习的核心方法 ‣ 深度主动学习及其在医学图像分析中的应用的综合调查")。'
- en: '![Refer to caption](img/ddd3a59b339a0d6c0212d8d971f1b0ea.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ddd3a59b339a0d6c0212d8d971f1b0ea.png)'
- en: 'Figure 3: The taxonomy of uncertainty-based active learning.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 基于不确定性的主动学习分类。'
- en: 3.1.1 Multiple Inferences
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 多次推断
- en: 'To mitigate over-confidence, a common strategy is to run the model multiple
    times with some perturbations and calculate the classic uncertainty metrics with
    the mean probability. The main idea is to reduce the bias introduced by network
    architectures or training data. These biases often contribute to the over-confidence
    issue. Three methods can be employed for multiple inferences: Monte Carlo dropout
    (MC dropout), model ensemble, and data augmentation. The first two perturb the
    model parameters, and the last perturb the input data.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻过度自信，一个常见的策略是对模型进行多次运行，并使用均值概率计算经典的不确定性指标。主要思想是减少由网络架构或训练数据引入的偏差。这些偏差往往导致过度自信问题。可以采用三种方法进行多次推断：蒙特卡洛
    dropout（MC dropout）、模型集成和数据增强。前两种方法扰动模型参数，最后一种方法扰动输入数据。
- en: MC dropout randomly discards some neurons in the deep model during each inference
    [Gal and Ghahramani, [2016](#bib.bib51)]. With MC dropout enabled, the model runs
    multiple times to get different predictions. Gal et al. [[2017](#bib.bib52)] was
    the pioneering work of deep AL. They were also the first to use MC dropout in
    computing uncertainty metrics like entropy, standard deviation, and Bayesian active
    learning disagreement (BALD) [Houlsby et al., [2011](#bib.bib69)]. Results showed
    that MC Dropout could significantly improve the performance of uncertainty-based
    deep AL.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: MC dropout 在每次推断过程中随机丢弃深度模型中的一些神经元 [Gal 和 Ghahramani, [2016](#bib.bib51)]。启用
    MC dropout 后，模型会多次运行以获得不同的预测。Gal 等人 [[2017](#bib.bib52)] 是深度 AL 的开创性工作。他们也是第一个将
    MC dropout 应用于计算不确定性指标，如熵、标准差和贝叶斯主动学习不一致性（BALD）的研究者 [Houlsby 等人, [2011](#bib.bib69)]。结果表明，MC
    Dropout 可以显著提高基于不确定性的深度 AL 的性能。
- en: Model ensemble trains multiple models to get numerous predictions during inference.
    Beluch et al. [[2018](#bib.bib16)] conducted a detailed comparison of models ensemble
    and MC dropout in uncertainty-based AL. Results demonstrated that the model ensemble
    performs better. However, model ensemble requires significant training overhead
    in DL. To reduce the computational costs, snapshot ensemble [Huang et al., [2017](#bib.bib73)]
    obtained multiple models in a single run with cyclic learning rate decay. An early
    attempt in Beluch et al. [[2018](#bib.bib16)] showed that snapshot ensemble leads
    to worse performance than model ensemble. Jung et al. [[2023](#bib.bib86)] improved
    the snapshot ensemble by maintaining the same optimization trajectory in different
    AL rounds, along with parameter regularization. Results showed that the improved
    snapshot ensemble outperforms the model ensemble. Additionally, Nath et al. [[2021](#bib.bib131)]
    employed stein variational gradient descent to train an ensemble of models, aiming
    to ensure diversity among them.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 模型集成训练多个模型以在推断过程中获得多个预测。Beluch等人[[2018](#bib.bib16)] 对模型集成和MC dropout在基于不确定性的主动学习中的表现进行了详细比较。结果表明，模型集成效果更佳。然而，模型集成在深度学习中需要显著的训练开销。为了减少计算成本，snapshot
    ensemble [Huang等人，[2017](#bib.bib73)] 通过循环学习率衰减在一次运行中获得多个模型。Beluch等人[[2018](#bib.bib16)]
    的早期尝试显示，snapshot ensemble的表现不如模型集成。Jung等人[[2023](#bib.bib86)] 通过在不同的主动学习轮次中保持相同的优化轨迹，并进行参数正则化，改进了snapshot
    ensemble。结果显示，改进后的snapshot ensemble优于模型集成。此外，Nath等人[[2021](#bib.bib131)] 采用了Stein变分梯度下降来训练模型集成，旨在确保模型之间的多样性。
- en: Data augmentation produces different versions of input data with random transformations.
    Then, multiple predictions were obtained by running the model with different augmentations
    during inference. In point cloud semantic segmentation, Hu et al. [[2022](#bib.bib71)]
    randomly augmented the input point clouds multiple times, then calculated the
    entropy of average prediction probability for each point after registration and
    correspondence estimation. Liu et al. [[2022a](#bib.bib111)] also applied random
    augmentations to point clouds, but they used variance as the uncertainty metric.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强通过随机变换生成输入数据的不同版本。然后，通过在推断过程中使用不同的增强方式运行模型，从而获得多个预测。在点云语义分割中，Hu等人[[2022](#bib.bib71)]
    多次随机增强输入点云，然后在配准和对应估计后计算每个点的平均预测概率的熵。Liu等人[[2022a](#bib.bib111)] 也对点云应用了随机增强，但他们使用方差作为不确定性度量。
- en: 3.1.2 Disagreement-based Uncertainty
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 基于分歧的不确定性
- en: Disagreements between different inferences of the same sample could also be
    a measure of uncertainty. Samples with higher disagreement indicate higher uncertainty
    and are suitable for annotation. The principle of methods in this section aligns
    with the previous section, which aims to mitigate over-confidence by introducing
    perturbations during multiple inferences. However, methods in the previous section
    focus on improving the uncertainty estimation of classical metrics, while methods
    in this section leverage the disagreements between different prediction results.
    In this line of research, we can build disagreement from the perspective of model
    and data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 相同样本的不同推断之间的分歧也可以作为不确定性的度量。分歧较大的样本表示不确定性较高，适合进行标注。本节的方法原理与前一节一致，旨在通过在多次推断过程中引入扰动来减轻过度自信。然而，前一节的方法侧重于改进经典度量的不确定性估计，而本节的方法则利用不同预测结果之间的分歧。在这一研究方向上，我们可以从模型和数据的角度构建分歧。
- en: 'Model disagreement: We can utilize the disagreement between the outputs of
    different models, also known as Query-by-Committee (QBC) [Seung et al., [1992](#bib.bib163)].
    Suggestive annotation (SA) [Yang et al., [2017](#bib.bib211)] trained multiple
    segmentation networks with bootstrapping. The variance among these models is used
    as the disagreement metric. Mackowiak et al. [[2018](#bib.bib120)] adopted the
    vote entropy between different MC dropout inferences as the disagreement metric.
    Peng et al. [[2021](#bib.bib141)] trained teacher and student models through knowledge
    distillation and used the L2 distance of segmentation predictions as the disagreement
    metric. In polyp segmentation of capsule colonoscopy, Bai et al. [[2022](#bib.bib10)]
    trained multiple decoders using class activation maps (CAMs) [Zhou et al., [2016](#bib.bib229)]
    generated by a classification network. They further proposed model disagreement
    and CAM disagreement for sample selection. Model disagreement included entropy
    of prediction probabilities and Dice between outputs of different decoders, while
    CAM disagreement measured the Dice between CAMs and outputs of all decoders. This
    method selected samples with high model disagreement and CAM disagreement for
    annotation. However, samples with low model disagreement but high CAM disagreement
    were treated as pseudo-labels for semi-supervised training. In rib fracture detection,
    Huang et al. [[2020](#bib.bib75)] adopted Hausdorff distance to measure the disagreements
    between different CAMs.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 模型不一致性：我们可以利用不同模型输出之间的不一致性，也称为 Query-by-Committee (QBC) [Seung et al., [1992](#bib.bib163)]。建议性注释
    (SA) [Yang et al., [2017](#bib.bib211)] 通过引导训练了多个分割网络。这些模型之间的方差被用作不一致性度量。Mackowiak
    et al. [[2018](#bib.bib120)] 采用了不同 MC dropout 推断之间的投票熵作为不一致性度量。Peng et al. [[2021](#bib.bib141)]
    通过知识蒸馏训练了教师和学生模型，并使用分割预测的 L2 距离作为不一致性度量。在胶囊结肠镜的息肉分割中，Bai et al. [[2022](#bib.bib10)]
    使用分类网络生成的类激活图 (CAMs) [Zhou et al., [2016](#bib.bib229)] 训练了多个解码器。他们进一步提出了模型不一致性和
    CAM 不一致性用于样本选择。模型不一致性包括预测概率的熵和不同解码器输出之间的 Dice 系数，而 CAM 不一致性测量 CAMs 和所有解码器输出之间的
    Dice 系数。这种方法选择了具有高模型不一致性和 CAM 不一致性的样本进行注释。然而，低模型不一致性但高 CAM 不一致性的样本被视为伪标签用于半监督训练。在肋骨骨折检测中，Huang
    et al. [[2020](#bib.bib75)] 采用 Hausdorff 距离来测量不同 CAMs 之间的不一致性。
- en: 'Data disagreement: Since training multiple models can be computationally expensive,
    measuring the disagreements between different perturbations of input data is also
    helpful in AL. Kullback-Leibler (KL) divergence is a commonly used metric for
    quantifying disagreement. Wu et al. [[2021b](#bib.bib201)] computed KL divergence
    between different versions of augmentations as the disagreement measure. Siddiqui
    et al. [[2020](#bib.bib168)] measured the disagreement with KL divergence between
    predictions of different viewpoints in 3D scenes. In point cloud segmentation,
    Hu et al. [[2022](#bib.bib71)] employed KL divergence to measure the disagreement
    between predictions of different frames. Additionally, recent works have adopted
    alternative metrics to calculate disagreement. Lyu et al. [[2023](#bib.bib119)]
    proposed input-end committee, which constructs different predictions by randomly
    augmenting the input data. They further measured the classification and localization
    disagreements between different predictions with cross-entropy and variance, respectively.
    Parvaneh et al. [[2022](#bib.bib139)] interpolated the unlabeled samples and labeled
    prototypes in the feature space. If the prediction of the interpolated sample
    disagrees with the label of the prototype, it indicates that the unlabeled samples
    may introduce new features. Then, these unlabeled samples should be sent for annotation.
    Results showed advancements across various datasets and settings. Besides, some
    works explored the prediction disagreement within a local area inside an image.
    In object detection, Aghdam et al. [[2019](#bib.bib3)] assumed that the disagreement
    between probabilities in the neighborhood of wrongly predicted pixels should be
    high. They adopted BALD as the disagreement metric.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分歧：由于训练多个模型可能计算开销很大，测量输入数据不同扰动之间的分歧在主动学习（AL）中也很有帮助。Kullback-Leibler（KL）散度是量化分歧的常用指标。Wu
    等人 [[2021b](#bib.bib201)] 计算了不同增强版本之间的 KL 散度作为分歧度量。Siddiqui 等人 [[2020](#bib.bib168)]
    通过计算 3D 场景中不同视角预测之间的 KL 散度来测量分歧。在点云分割中，Hu 等人 [[2022](#bib.bib71)] 采用 KL 散度来测量不同帧预测之间的分歧。此外，最近的工作采用了替代指标来计算分歧。Lyu
    等人 [[2023](#bib.bib119)] 提出了输入端委员会，通过随机增强输入数据来构建不同的预测。他们进一步用交叉熵和方差分别测量不同预测之间的分类和定位分歧。Parvaneh
    等人 [[2022](#bib.bib139)] 在特征空间中插值无标签样本和有标签原型。如果插值样本的预测与原型的标签不一致，说明无标签样本可能引入了新特征。然后，这些无标签样本应送去标注。结果显示了在各种数据集和设置中的进展。此外，一些工作探索了图像局部区域内的预测分歧。在目标检测中，Aghdam
    等人 [[2019](#bib.bib3)] 假设错误预测像素邻域内概率的分歧应该很高。他们采用了 BALD 作为分歧度量指标。
- en: 3.1.3 Uncertainty-aware Model
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.3 不确定性感知模型
- en: 'The main idea of uncertainty-aware models is to transform commonly used deterministic
    models into probabilistic models. In this way, the network no longer outputs a
    single point estimate but instead provides a distribution of possible predictions,
    thus mitigating over-confidence. This approach only requires a single pass of
    the deep model, significantly reducing computational and time costs during inference.
    Related works mainly fall into two categories: evidential deep learning (EDL)
    and mixture density networks (MDN).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定性感知模型的主要思想是将常用的确定性模型转化为概率模型。这样，网络不再输出单一的点估计，而是提供可能预测的分布，从而缓解过度自信。这种方法只需要对深度模型进行一次传递，大大减少了推断过程中的计算和时间成本。相关工作主要分为两类：证据深度学习（EDL）和混合密度网络（MDN）。
- en: Evidential deep learning replaces the Softmax distribution with a Dirichlet
    distribution [Sensoy et al., [2018](#bib.bib161)]. The network’s output is interpreted
    as the parameters of a Dirichlet distribution, so the predictions followed the
    Dirichlet distribution. The Dirichlet distribution will be sharp if the model
    is confident about the predictions. Otherwise, it will be flat. To make EDL compatible
    with object detection tasks, Park et al. [[2023](#bib.bib138)] introduced a model
    evidence head to scale the parameters of the Dirichlet distribution adaptively,
    which enhanced training stability. They first calculated the epistemic uncertainty
    for each detection box. Then, the sample-level uncertainty was obtained through
    hierarchical uncertainty aggregation. Sun et al. [[2023](#bib.bib175)] also applied
    EDL in scene graph generation, achieving near full-supervision performance with
    only about 10% of the labeling cost.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 证据深度学习用 Dirichlet 分布 [Sensoy et al., [2018](#bib.bib161)] 替代了 Softmax 分布。网络的输出被解释为
    Dirichlet 分布的参数，因此预测遵循 Dirichlet 分布。如果模型对预测有信心，Dirichlet 分布会很尖锐；否则，它会比较平坦。为了使
    EDL 适用于目标检测任务，Park 等人 [[2023](#bib.bib138)] 引入了一个模型证据头，以自适应地调整 Dirichlet 分布的参数，从而提高了训练稳定性。他们首先计算了每个检测框的
    epistemic uncertainty，然后通过分层不确定性聚合获得样本级别的不确定性。Sun 等人 [[2023](#bib.bib175)] 还将
    EDL 应用于场景图生成，使用仅约 10% 的标注成本达到了接近全监督的性能。
- en: 'Mixture density networks: Choi et al. [[2021a](#bib.bib35)] transformed the
    classification and localization heads in object detection networks to the architecture
    of MDN [Bishop, [1994](#bib.bib21)]. Besides the coordinates and class predictions
    of each bounding box, the MDN heads produced the variance of classification and
    localization. They used the variances as uncertainty metrics for sample selection.
    Results showed that this method is competitive with MC dropout and model ensemble
    while significantly reducing the inference time and model size.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 混合密度网络：Choi 等人 [[2021a](#bib.bib35)] 将目标检测网络中的分类和定位头部转变为 MDN 的架构 [Bishop, [1994](#bib.bib21)]。除了每个边界框的坐标和类别预测外，MDN
    头还生成了分类和定位的方差。他们使用这些方差作为样本选择的 uncertainty 指标。结果表明，这种方法在减少推理时间和模型大小的同时，与 MC dropout
    和模型集成相比具有竞争力。
- en: 3.1.4 Gradient-based Uncertainty
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.4 基于梯度的不确定性
- en: 'Gradient-based optimization is essential for deep learning. The gradient of
    each sample reflects its contribution to the change of model parameters. A larger
    gradient length indicates a tremendous change of parameters by the sample, thus
    implying high uncertainty. Furthermore, gradients are independent of predictive
    probabilities, making them less susceptible to over-confidence. In deep active
    learning, three metrics are frequently used as gradient-based uncertainty: gradients,
    Fisher information (FI), and influence functions.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 基于梯度的优化对深度学习至关重要。每个样本的梯度反映了其对模型参数变化的贡献。较大的梯度长度表明样本对参数的变化影响巨大，因此意味着高不确定性。此外，梯度独立于预测概率，使其不易受过度自信的影响。在深度主动学习中，常用的三种基于梯度的不确定性指标是：梯度、Fisher
    信息 (FI) 和影响函数。
- en: 'Gradient: A larger gradient norm (i.e., gradient length) denotes a greater
    influence on model parameters, indicating higher uncertainty in AL. Ash et al.
    [[2020](#bib.bib8)] proposed batch active learning by diverse gradient embeddings
    (BADGE). They calculated the gradients only for the parameters of the network’s
    final layer, with the most confident classes as pseudo labels in gradient computation.
    Then, k-Means++ is performed on gradient embeddings for sample selection. Results
    showed competitive performances of BADGE across diverse datasets, network architectures,
    and hyperparameter settings. Wang et al. [[2022b](#bib.bib192)] proved that a
    larger gradient norm corresponds to a lower upper bound of test loss. Thus, they
    employed expected empirical loss and entropy loss for gradient computation, which
    both obviate the necessity for labels. The former was a sum of the losses for
    each class, which was weighted by the corresponding probability. The latter was
    the entropy of probabilities of all classes. In MRI brain tumor segmentation,
    Dai et al. [[2020](#bib.bib40)] employed gradients for active learning. They first
    trained a variational autoencoder (VAE) [Kingma and Welling, [2013](#bib.bib93)]
    to learn the data manifold. Then, they trained a segmentation model and calculated
    gradients of Dice loss using available labeled data. The sample selection was
    guided by the gradient projected onto the data manifold. Their extended work [Dai
    et al., [2022](#bib.bib39)] further demonstrated superior performance in MRI whole
    brain segmentation.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度：更大的梯度范数（即梯度长度）表示对模型参数的影响更大，表明AL中的不确定性更高。Ash等人[[2020](#bib.bib8)] 提出了通过多样化梯度嵌入（BADGE）的批量主动学习方法。他们仅计算网络最后一层参数的梯度，并以最有信心的类别作为梯度计算中的伪标签。然后，在梯度嵌入上执行k-Means++进行样本选择。结果显示BADGE在各种数据集、网络架构和超参数设置下表现出色。Wang等人[[2022b](#bib.bib192)]
    证明了更大的梯度范数对应于测试损失的较低上界。因此，他们采用了期望经验损失和熵损失进行梯度计算，这两者都无需标签。前者是每个类别的损失之和，由相应的概率加权。后者是所有类别概率的熵。在MRI脑肿瘤分割中，Dai等人[[2020](#bib.bib40)]
    使用梯度进行主动学习。他们首先训练了一个变分自编码器（VAE）[Kingma和Welling，[2013](#bib.bib93)]来学习数据流形。然后，他们训练了一个分割模型，并使用现有标注数据计算Dice损失的梯度。样本选择由投影到数据流形上的梯度指导。他们的扩展工作[Dai等人，[2022](#bib.bib39)]进一步展示了在MRI全脑分割中的卓越表现。
- en: 'Fisher information: As the expectation of the gradient’s covariance matrix,
    FI reflects overall uncertainty according to the data distribution to model parameters.
    Annotating samples with higher FI helps the model converge faster toward optimal
    parameters. FI has already succeeded in AL of machine learning models [Chaudhuri
    et al., [2015](#bib.bib29), Sourati et al., [2017](#bib.bib171)]. However, the
    computation cost of FI grows quadratically with the increase of model parameters,
    which is unacceptable for deep active learning. Sourati et al. [[2018](#bib.bib172)]
    and their extended work [Sourati et al., [2019](#bib.bib173)] were the first to
    incorporate FI into deep active learning. They used the average gradients of each
    layer to calculate the FI matrix, thus reducing the computation cost. This method
    outperformed competitors in brain extraction across different age groups and pathological
    conditions. Additionally, Ash et al. [[2021](#bib.bib7)] only computed the FI
    matrix for the network’s last layer.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Fisher信息：作为梯度协方差矩阵的期望，FI根据数据分布对模型参数反映总体不确定性。标注具有较高FI的样本有助于模型更快地收敛到最优参数。FI已成功应用于机器学习模型的AL中[Chaudhuri等人，[2015](#bib.bib29),
    Sourati等人，[2017](#bib.bib171)]。然而，FI的计算成本随着模型参数的增加而平方增长，这对于深度主动学习来说是不可接受的。Sourati等人[[2018](#bib.bib172)]及其扩展工作[Sourati等人，[2019](#bib.bib173)]
    是首次将FI纳入深度主动学习。他们使用每一层的平均梯度来计算FI矩阵，从而降低了计算成本。这种方法在不同年龄组和病理条件下的大脑提取中优于其他竞争者。此外，Ash等人[[2021](#bib.bib7)]
    仅计算了网络最后一层的FI矩阵。
- en: 'Influence functions: Liu et al. [[2021b](#bib.bib116)] employed influence functions
    [Koh and Liang, [2017](#bib.bib96)] to select samples that bring the most positive
    impact on model performance. The method used expected empirical loss to calculate
    the gradient since influence functions also require gradient computations.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 影响函数：Liu等人[[2021b](#bib.bib116)] 使用影响函数[Koh和Liang，[2017](#bib.bib96)] 选择对模型性能产生最大正面影响的样本。该方法使用期望经验损失来计算梯度，因为影响函数也需要梯度计算。
- en: 3.1.5 Adversarial-based Uncertainty
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.5 基于对抗的不确定性
- en: Uncertainty in AL can also be estimated adversarially, including adversarial
    samples and adversarial training.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: AL中的不确定性也可以通过对抗方式来估计，包括对抗样本和对抗训练。
- en: Adversarial samples are created by adding carefully designed perturbations to
    normal samples by attacking the deep models [Goodfellow et al., [2014b](#bib.bib58)].
    The differences between adversarial and original samples are nearly indiscernible
    to the human eye. However, deep models would produce extremely confident wrong
    predictions for adversarial samples. The reason is that adversarial attacks push
    the original samples to the other side of the decision boundary with minimal cost,
    resulting in visually negligible changes but significantly different predictions.
    From this perspective, the strength of adversarial attacks reflects the sample’s
    distance to the decision boundary [Heo et al., [2019](#bib.bib65)]. A small perturbation
    indicates that the sample is closer to the decision boundary and, thus, is considered
    more uncertain. Ducoffe and Precioso [[2018](#bib.bib45)] adopted the DeepFool
    algorithm [Moosavi-Dezfooli et al., [2016](#bib.bib129)] for adversarial attacks.
    Samples with small adversarial perturbations are requested for labeling. Rangwani
    et al. [[2021](#bib.bib153)] attacked the deep model by maximizing the KL divergence
    between predictions of adversarial and original samples while the strength of
    perturbation is limited.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗样本是通过向正常样本添加精心设计的扰动来创建的，这些扰动是通过攻击深度模型生成的[Goodfellow et al., [2014b](#bib.bib58)]。对抗样本和原始样本之间的差异对人眼几乎不可辨别。然而，深度模型对对抗样本会产生极其自信的错误预测。原因在于，对抗攻击以最小的代价将原始样本推向决策边界的另一侧，导致视觉上几乎没有变化，但预测结果却大相径庭。从这个角度看，对抗攻击的强度反映了样本与决策边界的距离[Heo
    et al., [2019](#bib.bib65)]。小的扰动表示样本距离决策边界更近，因此被认为更不确定。Ducoffe和Precioso [[2018](#bib.bib45)]采用了DeepFool算法[Moosavi-Dezfooli
    et al., [2016](#bib.bib129)]进行对抗攻击。要求标记的小扰动对抗样本。Rangwani等人[[2021](#bib.bib153)]通过最大化对抗样本和原始样本预测之间的KL散度来攻击深度模型，同时限制扰动的强度。
- en: Adversarial training involves alternating training between feature extractors
    and multiple classifiers. The objectives of training feature extractors and classifiers
    are conflicting. Multi-round adversarial training increases the disagreements
    between classifiers, uncovering uncertain samples hidden by over-confidence. In
    object detection, Yuan et al. [[2021](#bib.bib217)] and their extended work [Wan
    et al., [2023](#bib.bib185)] used two classifiers for adversarial training on
    both labeled and unlabeled datasets. The first step is to fix the feature extractor
    and tune the two classifiers. The more classifiers disagreed the more uncertain
    samples were exposed. Then, they fixed the classifiers and tuned the feature extractor
    with opposite objectives, aiming to narrow the distribution gap between labeled
    and unlabeled samples. After multiple rounds of alternating training, samples
    with the highest disagreements between classifiers are sent for annotation. Fu
    et al. [[2021](#bib.bib49)] adversarially trained multiple classifiers to maximize
    their disagreement. The standard deviation between different predictions was considered
    the uncertainty metric.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗训练涉及在特征提取器和多个分类器之间交替训练。特征提取器和分类器的训练目标是相互冲突的。多轮对抗训练增加了分类器之间的分歧，揭示了被过度自信掩盖的不确定样本。在目标检测中，Yuan等人[[2021](#bib.bib217)]及其扩展工作[Wan
    et al., [2023](#bib.bib185)]使用了两个分类器对标记和未标记的数据集进行对抗训练。第一步是固定特征提取器，调整两个分类器。分类器之间的不一致越多，不确定样本暴露得越多。然后，他们固定分类器，调整特征提取器以相反的目标，旨在缩小标记和未标记样本之间的分布差距。经过多轮交替训练后，分类器之间分歧最大样本被送去标注。Fu等人[[2021](#bib.bib49)]对多个分类器进行了对抗训练，以最大化它们之间的分歧。不同预测之间的标准差被认为是不确定性度量。
- en: 3.1.6 Performance Estimation
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.6 性能估计
- en: 'In this section, the uncertainty metrics are direct performance estimations
    of the current task. There are two types of such metrics: test loss or task-specific
    evaluation metrics. These metrics reflect the level of prediction error. For instance,
    a low Dice score suggests the model failed to produce accurate segmentation. Request
    annotations for these samples would be beneficial for improving the model’s performance.
    However, instead of calculating these metrics precisely, we can only estimate
    them without the ground truths. There are primarily two methods for estimating
    performance: surrogate metrics and learnable performance estimation.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，不确定度度量是对当前任务的直接性能估计。这些度量有两种类型：测试损失或任务特定的评估度量。这些度量反映了预测误差的水平。例如，低Dice分数表明模型未能生成准确的分割。请求对这些样本进行标注将有助于提升模型性能。然而，我们只能在没有真实值的情况下估计这些度量，而无法精确计算。主要有两种方法来估计性能：替代度量和可学习性能估计。
- en: Surrogate metrics are widely used in this line of research. For example, these
    metrics may be upper or lower bounds for loss or some evaluation metrics. Huang
    et al. [[2021](#bib.bib74)] found that within limited training iterations, the
    loss of a sample is bounded by the norm of the difference between the initial
    and final network outputs. Inspired by this, they proposed cyclic output discrepancy
    (COD) as the difference in model output between two consecutive annotation rounds.
    Results indicated that a higher COD is associated with higher loss. Therefore,
    they opted for samples with high COD. They may also demonstrate a linear correlation
    with the evaluation metrics with post-hoc validation. Shen et al. [[2020](#bib.bib165)]
    calculated the intersection over union (IoU) of all predictions by MC dropout.
    They found a strong linear correlation between this IoU and the real Dice coefficient.
    Zhao et al. [[2021](#bib.bib226)] calculated the average Dice coefficient between
    the predictions of the intermediate layers and final layer through deep supervision.
    They also found a linear correlation between this average Dice and the real Dice
    coefficient. Results showed competitive performance in skin lesion segmentation
    and X-ray hand bone segmentation.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 替代度量在这类研究中被广泛使用。例如，这些度量可能是损失或某些评估度量的上界或下界。黄等人 [[2021](#bib.bib74)] 发现，在有限的训练迭代内，一个样本的损失受限于初始和最终网络输出之间差异的范数。受到这一发现的启发，他们提出了循环输出差异（COD），作为两个连续标注轮次之间模型输出的差异。结果表明，较高的COD与较高的损失相关。因此，他们选择了具有高COD的样本。这些样本还可能与评估度量具有线性相关性，并通过事后验证加以确认。申等人
    [[2020](#bib.bib165)] 通过MC dropout计算了所有预测的交并比（IoU）。他们发现这一IoU与真实的Dice系数之间存在强烈的线性相关性。赵等人
    [[2021](#bib.bib226)] 通过深度监督计算了中间层和最终层预测之间的平均Dice系数。他们也发现这一平均Dice与真实Dice系数之间具有线性相关性。结果在皮肤病变分割和X光手骨分割中显示了竞争力的表现。
- en: 'Learnable performance estimation: Additionally, we can train auxiliary neural
    network modules to predict the performance metrics. As one of the most representative
    works in this line of research, learning loss for active learning (LL4AL) [Yoo
    and Kweon, [2019](#bib.bib214)] trained an additional module to predict the loss
    value of a sample without its label. Since loss indicates the quality of network
    predictions, the predicted loss is a natural uncertainty metric for sample selection.
    Results showed that predicted and actual losses are strongly correlated. LL4AL
    also outperformed several AL baselines. In lung nodule detection with CT scans,
    Liu et al. [[2020](#bib.bib112)] built upon LL4AL to predict the loss of each
    sample and bounding box. In diagnosing COVID-19, Wu et al. [[2021b](#bib.bib201)]
    adopted both the predicted loss and the disagreements between different predictions
    for sample selection. Since AL focuses only on uncertainty ranking of the unlabeled
    samples, Kim et al. [[2021](#bib.bib92)] relaxed the loss regression to loss ranking
    prediction. Thus, they replaced the loss regressor in LL4AL with the ranker in
    RankCGAN [Saquil et al., [2018](#bib.bib159)]. Results showed that loss ranking
    prediction outperforms LL4AL.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 可学习的性能估计：此外，我们可以训练辅助神经网络模块来预测性能指标。作为这一研究领域中最具代表性的工作之一，主动学习的学习损失（LL4AL）[Yoo and
    Kweon, [2019](#bib.bib214)] 训练了一个额外的模块，以预测样本的损失值，而不需要其标签。由于损失指示了网络预测的质量，预测的损失是样本选择的自然不确定性指标。结果显示，预测损失与实际损失有很强的相关性。LL4AL
    还优于多个主动学习基线。在肺结节检测的 CT 扫描中，Liu 等人 [[2020](#bib.bib112)] 在 LL4AL 的基础上，预测了每个样本和边界框的损失。在
    COVID-19 诊断中，Wu 等人 [[2021b](#bib.bib201)] 采用了预测损失和不同预测之间的分歧来进行样本选择。由于主动学习仅关注未标记样本的不确定性排名，Kim
    等人 [[2021](#bib.bib92)] 将损失回归放宽为损失排名预测。因此，他们将 LL4AL 中的损失回归器替换为 RankCGAN [Saquil
    et al., [2018](#bib.bib159)] 中的排名器。结果显示，损失排名预测优于 LL4AL。
- en: '3.2 Evaluation of Informativeness: Representativeness'
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 信息量评估：代表性
- en: 'While uncertainty methods play a crucial role in deep AL, they still face certain
    challenges: 1\. Outlier selection: The goal of using uncertainty in AL is to improve
    performance by querying hard samples of the current model. However, these methods
    could also select outliers that harm the model training [Karamcheti et al., [2021](#bib.bib87)].
    This happens because uncertainty relies sorely on model predictions and ignores
    the exploration of intrinsic characteristics of the data distribution. Incorporating
    an additional informativeness measure to remove outliers would be beneficial for
    AL. 2\. Distribution misalignment: Samples selected by uncertainty methods are
    often located near the decision boundary in the feature space [Settles, [2009](#bib.bib162)].
    Therefore, the distribution of selected samples by uncertainty-based method may
    differ from the overall data distribution. This discrepancy may introduce dataset
    bias and lead to a performance drop. Therefore, the challenges above compel us
    further to discover the data distribution during the evaluation of informativeness.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管不确定性方法在深度主动学习中发挥了关键作用，但它们仍面临某些挑战：1\. 异常值选择：使用不确定性在主动学习中的目标是通过查询当前模型的困难样本来提高性能。然而，这些方法也可能选择出异常值，从而损害模型训练
    [Karamcheti et al., [2021](#bib.bib87)]。这发生是因为不确定性仅依赖于模型预测，忽略了对数据分布内在特征的探索。引入额外的信息度量以去除异常值将对主动学习有利。2\.
    分布不一致：不确定性方法选择的样本通常位于特征空间的决策边界附近 [Settles, [2009](#bib.bib162)]。因此，由不确定性方法选择的样本的分布可能与整体数据分布不同。这种差异可能引入数据集偏差并导致性能下降。因此，上述挑战促使我们进一步发现数据分布，以评估信息量。
- en: 'Representativeness-based deep AL aims to select a subset of samples that can
    represent the entire dataset. Generally, highly representative samples are located
    in dense regions of the data manifold and contain information about other nearby
    samples. Moreover, these methods require diversity in sampling result. Representative
    samples should be widely distributed across the data manifold rather than concentrated
    in a specific region. Besides, representative samples should be visually distinctive
    in properties like imaging style or visual content. Deep feature representations
    encode such information and are used to calculate the mutual relationships between
    different samples. This section introduces three formulations of representativeness-based
    AL: cover-based, discrepancy-based, and density-based representativeness AL. The
    taxonomy of these methods is shown in Fig. [4](#S3.F4 "Figure 4 ‣ 3.2 Evaluation
    of Informativeness: Representativeness ‣ 3 Core Methods of Active Learning ‣ A
    comprehensive survey on deep active learning and its applications in medical image
    analysis").'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '基于代表性的深度主动学习旨在选择一个能够代表整个数据集的样本子集。通常，高度代表性的样本位于数据流形的密集区域，并包含有关其他邻近样本的信息。此外，这些方法要求采样结果具有多样性。代表性样本应广泛分布在数据流形上，而不是集中在特定区域。此外，代表性样本在成像风格或视觉内容等属性上应具有明显的区别。深度特征表示编码了这些信息，并用于计算不同样本之间的相互关系。本节介绍了三种基于代表性的主动学习的公式：基于覆盖的、基于差异的和基于密度的代表性主动学习。这些方法的分类见图[4](#S3.F4
    "Figure 4 ‣ 3.2 Evaluation of Informativeness: Representativeness ‣ 3 Core Methods
    of Active Learning ‣ A comprehensive survey on deep active learning and its applications
    in medical image analysis")。'
- en: '![Refer to caption](img/a85116cac04f50918a1e67a6fd982d7b.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a85116cac04f50918a1e67a6fd982d7b.png)'
- en: 'Figure 4: The taxonomy of representativeness-based active learning.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: 基于代表性的主动学习的分类。'
- en: 3.2.1 Cover-based Active Learning
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 基于覆盖的主动学习
- en: 'We can formulate representativeness-based AL as a problem of covering. A classic
    example of the covering problem is the facility location, such as covering all
    the city’s streets with some billboards [Farahani and Hekmatfar, [2009](#bib.bib47)].
    Likewise, cover-based AL uses a few samples to cover the entire dataset. Ideally,
    these samples should be representative and contain information from other samples.
    These methods usually involve two settings: set cover and maximum coverage. Both
    settings are NP-hard, meaning they cannot be optimally solved in polynomial time.
    However, near-optimal solutions could be achieved in linear time using greedy
    algorithms. Specifically, the greedy algorithms iteratively select samples that
    cover other samples the most for annotation [Feige, [1998](#bib.bib48)].'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将基于代表性的主动学习（AL）表述为一个覆盖问题。一个经典的覆盖问题的例子是设施位置问题，例如用一些广告牌覆盖城市的所有街道[Farahani
    and Hekmatfar, [2009](#bib.bib47)]。同样，基于覆盖的主动学习使用少量样本来覆盖整个数据集。理想情况下，这些样本应该具有代表性，并包含其他样本的信息。这些方法通常涉及两种设置：集合覆盖和最大覆盖。这两种设置都是NP-hard的，意味着无法在多项式时间内得到最优解。然而，使用贪心算法可以在线性时间内获得近似最优解。具体来说，贪心算法通过迭代选择那些覆盖其他样本最多的样本进行标注[Feige,
    [1998](#bib.bib48)]。
- en: Set cover aims to select as few samples as possible to cover the entire dataset.
    CoreSet [Sener and Savarese, [2018](#bib.bib160)] followed the setting of k-Center
    location [Hochbaum and Shmoys, [1985](#bib.bib67)], which is also a variant of
    the set cover problem. In CoreSet, the L2 distance of deep features measures the
    similarity between different samples. They employed farthest-first traversal to
    solve the k-Center problem for selecting representative samples. Agarwal et al.
    [[2020](#bib.bib2)] introduced contextual diversity for AL, a metric that fused
    uncertainty and diversity of samples spatially and semantically. They replaced
    the L2 distance with contextual diversity and used the same method in CoreSet
    for sample selection. Caramalau et al. [[2021](#bib.bib26)] adopted graph convolutional
    networks (GCN) to model the relationships between labeled and unlabeled samples.
    GCNs improved the feature representation of unlabeled samples with the labeled
    dataset. Enhanced feature representation was further used for CoreSet sampling.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 集合覆盖旨在选择尽可能少的样本来覆盖整个数据集。CoreSet [Sener 和 Savarese, [2018](#bib.bib160)] 遵循了
    k-Center 位置的设置 [Hochbaum 和 Shmoys, [1985](#bib.bib67)]，这也是集合覆盖问题的一种变体。在 CoreSet
    中，深度特征的 L2 距离用于衡量不同样本之间的相似性。他们采用了最远优先遍历来解决 k-Center 问题以选择具有代表性的样本。Agarwal 等人 [[2020](#bib.bib2)]
    为主动学习引入了上下文多样性，这是一种在空间和语义上融合样本不确定性和多样性的度量。他们用上下文多样性替代了 L2 距离，并在 CoreSet 中使用相同的方法进行样本选择。Caramalau
    等人 [[2021](#bib.bib26)] 采用了图卷积网络（GCN）来建模标记样本和未标记样本之间的关系。GCN 改进了未标记样本的特征表示，并利用标记数据集进一步提高特征表示。这一增强的特征表示被用于
    CoreSet 采样。
- en: Maximum coverage selects a given number of samples to cover the entire dataset
    as much as possible. Yehuda et al. [[2022](#bib.bib212)] found that CoreSet tends
    to select outliers, especially when the annotation budget is low. To address this
    issue, they proposed ProbCover, which changed the setting from set cover to maximum
    coverage. They employed a graph-based greedy algorithm for sample selection. With
    the help of self-supervised deep features, ProbCover effectively avoided selecting
    outlier samples. Additionally, SA [Yang et al., [2017](#bib.bib211)] provides
    another formulation of maximum coverage. SA first selected highly uncertain samples
    and then further chose representative samples for annotation. The representativeness
    was based on the cosine similarity of deep features. Specifically, sample $x$
    is represented by the most similar sample from queried dataset $D_{t}^{q}$
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 最大覆盖选择一定数量的样本，以尽可能覆盖整个数据集。Yehuda 等人 [[2022](#bib.bib212)] 发现 CoreSet 倾向于选择离群点，特别是在标注预算较低的情况下。为了解决这个问题，他们提出了
    ProbCover，它将设置从集合覆盖更改为最大覆盖。他们采用了一种基于图的贪心算法来进行样本选择。在自监督深度特征的帮助下，ProbCover 有效地避免了选择离群样本。此外，SA
    [Yang et al., [2017](#bib.bib211)] 提供了另一种最大覆盖的公式。SA 首先选择高度不确定的样本，然后进一步选择具有代表性的样本进行标注。代表性是基于深度特征的余弦相似度。具体来说，样本
    $x$ 由查询数据集 $D_{t}^{q}$ 中最相似的样本表示。
- en: '|  | $r\left(D_{t}^{q},x\right)=\underset{x^{\prime}\in D_{t}^{q}}{\max}{sim\left(x^{\prime},x\right)}$
    |  | (5) |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '|  | $r\left(D_{t}^{q},x\right)=\underset{x^{\prime}\in D_{t}^{q}}{\max}{sim\left(x^{\prime},x\right)}$
    |  | (5) |'
- en: 'where $r$ is the representativeness of sample $x$ with respect to $D_{t}^{q}$
    and $sim(\cdot,\cdot)$ represents cosine similarity. Besides, representativeness
    $R$ between $D_{t}^{q}$ and the unlabeled set $D_{t}^{u}$ is as follow:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $r$ 是样本 $x$ 相对于 $D_{t}^{q}$ 的代表性，$sim(\cdot,\cdot)$ 表示余弦相似度。此外，$D_{t}^{q}$
    与未标记集合 $D_{t}^{u}$ 之间的代表性 $R$ 如下：
- en: '|  | $R\left(D_{t}^{q},D_{t}^{u}\right)=\underset{x\in D_{t}^{u}}{\sum}r\left(D_{t}^{q},x\right)$
    |  | (6) |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '|  | $R\left(D_{t}^{q},D_{t}^{u}\right)=\underset{x\in D_{t}^{u}}{\sum}r\left(D_{t}^{q},x\right)$
    |  | (6) |'
- en: where a larger $R\left(D_{t}^{q},D_{t}^{u}\right)$ indicates that $D_{t}^{q}$
    better represents $D_{t}^{u}$. It should be noted that SA is a generalization
    of the maximum coverage problem since the cosine similarity ranges from 0 to 1.
    But they still employed a greedy algorithm to find sample $x$ that maximizing
    $R\left(D_{t}^{q}\cup x,D_{t}^{u}\right)-R\left(D_{t}^{q},D_{t}^{u}\right)$. SA
    has inspired many subsequent works. Xu et al. [[2018](#bib.bib209)] quantized
    the segmentation networks in SA and found that it improved the accuracy of gland
    segmentation while significantly reducing memory usage. Zheng et al. [[2019](#bib.bib227)]
    proposed representative annotation (RA), which omits the uncertainty query in
    SA. RA trained a VAE for feature extraction and partitioned the feature space
    using hierarchical clustering. They selected representative samples in each cluster
    using a similar strategy to SA. Shen et al. [[2020](#bib.bib165)] changed the
    similarity measure in SA from $sim(\cdot,\cdot)$ to $1-sim(\cdot,\cdot)$, which
    enhanced the diversity of the selected samples. In keypoint detection of medical
    images, Quan et al. [[2022](#bib.bib149)] proposed a representative method to
    select template images for few-shot learning. First, they trained a feature extractor
    using self-supervised learning and applied SIFT for initial keypoint detection.
    Next, they calculated the average cosine similarity between template images and
    the entire dataset. Finally, they picked the template combination with the highest
    similarity for annotation.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 较大的$R\left(D_{t}^{q},D_{t}^{u}\right)$表示$D_{t}^{q}$更好地表示了$D_{t}^{u}$。需要注意的是，SA是最大覆盖问题的一种推广，因为余弦相似度的范围是从0到1。但他们仍然使用贪心算法来寻找使$R\left(D_{t}^{q}\cup
    x,D_{t}^{u}\right)-R\left(D_{t}^{q},D_{t}^{u}\right)$最大化的样本$x$。SA激发了许多后续工作。徐等人
    [[2018](#bib.bib209)] 在SA中对分割网络进行了量化，发现这提高了腺体分割的准确性，同时显著减少了内存使用。郑等人 [[2019](#bib.bib227)]
    提出了代表性注释（RA），省略了SA中的不确定性查询。RA训练了一个VAE用于特征提取，并通过层次聚类对特征空间进行了划分。他们使用与SA类似的策略在每个簇中选择代表性样本。沈等人
    [[2020](#bib.bib165)] 将SA中的相似度度量从$sim(\cdot,\cdot)$改为$1-sim(\cdot,\cdot)$，这增强了所选样本的多样性。在医学图像的关键点检测中，权等人
    [[2022](#bib.bib149)] 提出了一个代表性方法来选择模板图像用于少样本学习。首先，他们使用自监督学习训练了一个特征提取器，并应用SIFT进行初步关键点检测。接着，他们计算了模板图像与整个数据集之间的平均余弦相似度。最后，他们选择了相似度最高的模板组合进行注释。
- en: 'View of submodular functions: Both set cover and maximum coverage can be formulated
    from the perspective of submodular functions [Fujishige, [2005](#bib.bib50)].
    These functions show diminishing marginal returns, meaning each added element
    brings less gain than the previous one as the set gets larger. Generally, each
    submodular function corresponds to a particular optimization problem. If a submodular
    function is monotonic and non-negative, we can use a greedy algorithm to get near-optimal
    solutions in linear time. In cover-based AL, methods like SA and RA followed the
    setting of submodular functions, but the authors didn’t present their methods
    from this perspective. Introducing submodular functions would extend the formulation
    of AL and ensure the selected samples are both representative and diverse. Typical
    steps for this type of method involve calculating sample similarities, constructing
    a submodular optimization problem, and solving it using a greedy algorithm [Wei
    et al., [2015](#bib.bib196)]. Kothawade et al. [[2021](#bib.bib98)] introduced
    an AL framework based on submodular information measures, effectively addressing
    issues such as scarcity of rare class, redundancy, and out-of-distribution data.
    In object detection, Kothawade et al. [[2022a](#bib.bib99)] focused on samples
    of minority classes. They constructed a set of classes of interest and selected
    unlabeled samples similar to these classes for annotation through submodular mutual
    information [Kothawade et al., [2022b](#bib.bib100)].'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 子模函数视角：从子模函数的角度可以将集合覆盖和最大覆盖进行公式化 [Fujishige, [2005](#bib.bib50)]。这些函数显示出递减的边际收益，这意味着随着集合的增大，每增加一个元素带来的增益会比之前的元素少。一般来说，每个子模函数对应一个特定的优化问题。如果一个子模函数是单调的且非负的，我们可以使用贪婪算法在线性时间内得到接近最优的解决方案。在基于覆盖的主动学习中，像SA和RA这样的算法遵循了子模函数的设置，但作者没有从这个角度展示他们的方法。引入子模函数将扩展主动学习的公式化，并确保所选择的样本既具有代表性又具有多样性。这类方法的典型步骤包括计算样本相似性、构建子模优化问题，并使用贪婪算法解决它
    [Wei et al., [2015](#bib.bib196)]。Kothawade等人 [[2021](#bib.bib98)] 引入了一个基于子模信息量度的主动学习框架，有效地解决了稀有类别稀缺、冗余和分布外数据等问题。在目标检测中，Kothawade等人
    [[2022a](#bib.bib99)] 专注于少数类样本。他们构建了一个感兴趣的类别集合，并通过子模互信息选择了与这些类别相似的未标记样本进行注释 [Kothawade
    et al., [2022b](#bib.bib100)]。
- en: 3.2.2 Discrepancy-based Active Learning
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 基于差异的主动学习
- en: 'In discrepancy-based AL, unlabeled samples farthest from the labeled set are
    considered the most representative. The main idea is that if we queried such samples
    for multiple rounds, the discrepancy between the distributions of labeled and
    unlabeled sets would be significantly reduced. Therefore, a small set of samples
    could well represent the entire dataset. The key to these methods is measuring
    the discrepancy (i.e., distance) between two high-dimensional distributions. This
    section presents three metrics for measuring discrepancy: similarity-based discrepancy,
    H-divergence, and Wasserstein distance.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于差异的主动学习中，最远离已标记集合的未标记样本被认为是最具代表性的。主要思想是，如果我们对这些样本进行多轮查询，已标记和未标记集合之间的分布差异将显著减少。因此，一小部分样本可能就能很好地代表整个数据集。这些方法的关键是测量两个高维分布之间的差异（即距离）。本节介绍了三种测量差异的指标：基于相似性的差异、H-发散度和Wasserstein距离。
- en: 'Similarity-based discrepancy: As a practical and easy-to-implement metric,
    we can approximate the distance between distributions based on sample similarity.
    Caramalau et al. [[2021](#bib.bib26)] proposed UncertainGCN, which employed GCN
    to model the relationship between labeled and unlabeled samples. They selected
    the unlabeled samples with the lowest similarity to the labeled set. In gland
    and MRI infant brain segmentation, Li and Yin [[2020](#bib.bib108)] adopted the
    average cosine similarity as the distance between two datasets. They selected
    samples far from the labeled set and close to the unlabeled set. In object detection,
    Wu et al. [[2022a](#bib.bib198)] constructed prototypes with sample features and
    prediction entropy. They selected unlabeled samples that were far from the labeled
    prototype.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 基于相似性的差异：作为一种实际且易于实施的度量，我们可以基于样本相似性来近似分布之间的距离。Caramalau等人 [[2021](#bib.bib26)]
    提出了UncertainGCN，该方法利用GCN建模已标记和未标记样本之间的关系。他们选择了与已标记集合相似性最低的未标记样本。在腺体和MRI婴儿脑分割中，Li和Yin
    [[2020](#bib.bib108)] 采用了平均余弦相似性作为两个数据集之间的距离。他们选择了远离已标记集合且接近未标记集合的样本。在目标检测中，Wu等人
    [[2022a](#bib.bib198)] 构建了具有样本特征和预测熵的原型。他们选择了远离已标记原型的未标记样本。
- en: H-divergence estimates the distance of distribution with the help of the discriminator
    from generative adversarial networks (GAN) [Goodfellow et al., [2014a](#bib.bib57)].
    More specifically, the discriminator tries to distinguish between labeled and
    unlabeled samples, and there is a close relationship between H-divergence and
    the discriminator’s output [Gissin and Shalev-Shwartz, [2019](#bib.bib55)]. Variational
    adversarial active learning (VAAL) [Sinha et al., [2019](#bib.bib170)] combined
    VAE with a discriminator for discrepancy-based AL. In VAAL, the VAE mapped samples
    to a latent space while the discriminator distinguished whether samples were labeled.
    These two are mutually influenced by adversarial training. VAE tried to fool the
    discriminator into judging all samples as labeled while the discriminator attempted
    to correctly differentiate between labeled and unlabeled samples. After multiple
    rounds of adversarial training, VAAL selected samples that the discriminator deemed
    most likely to be unlabeled for annotation. Unlike VAAL, Gissin and Shalev-Shwartz
    [[2019](#bib.bib55)] trained the discriminator without adversarial training. Zhang
    et al. [[2020](#bib.bib219)] replaced the discriminator’s binary label with sample
    uncertainty. They also combined features of VAE with features from the supervised
    model. Wang et al. [[2020b](#bib.bib190)] adopted a neural network module for
    sample selection. To train such a module, they added another discriminator on
    top of VAAL, which aimed to differentiate between the real and VAE-reconstructed
    features for unlabeled samples. After adversarial training of both discriminators,
    the module selected uncertain and representative samples. Kim et al. [[2021](#bib.bib92)]
    combined LL4AL with VAAL, feeding both loss ranking predictions and VAE features
    into the discriminator.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: H-散度通过生成对抗网络（GAN）中的判别器来估计分布之间的距离 [Goodfellow et al., [2014a](#bib.bib57)]。更具体地说，判别器尝试区分有标签和无标签样本，而H-散度与判别器的输出之间存在密切关系
    [Gissin and Shalev-Shwartz, [2019](#bib.bib55)]。变分对抗主动学习（VAAL） [Sinha et al.,
    [2019](#bib.bib170)] 将变分自编码器（VAE）与判别器结合，用于基于差异的主动学习。在VAAL中，VAE将样本映射到潜在空间，而判别器区分样本是否有标签。这两者通过对抗训练相互影响。VAE试图欺骗判别器，使其将所有样本判断为有标签，而判别器则尝试正确区分有标签和无标签样本。在多轮对抗训练后，VAAL选择了判别器认为最有可能是无标签的样本进行标注。与VAAL不同，Gissin和Shalev-Shwartz
    [[2019](#bib.bib55)] 在没有对抗训练的情况下训练了判别器。Zhang等人 [[2020](#bib.bib219)] 用样本不确定性替换了判别器的二元标签。他们还将VAE的特征与监督模型的特征结合在一起。Wang等人
    [[2020b](#bib.bib190)] 采用了一个神经网络模块进行样本选择。为了训练这样的模块，他们在VAAL之上添加了另一个判别器，该判别器旨在区分真实特征与VAE重建特征对于无标签样本的区别。在对这两个判别器进行对抗训练后，该模块选择了不确定和具有代表性的样本。Kim等人
    [[2021](#bib.bib92)] 将LL4AL与VAAL结合，将损失排名预测和VAE特征输入到判别器中。
- en: Wasserstein distance is widely used for computing distribution distances. Shui
    et al. [[2020](#bib.bib167)] indicated that H-divergence may compromise the diversity
    of sample selection, while Wasserstein distance ensures the queried samples are
    representative and diverse. They further proposed Wasserstein adversarial active
    learning (WAAL). Specifically, WAAL was built upon VAAL and adopted an additional
    module for sample selection. They trained this module by minimizing the Wasserstein
    distance between labeled and unlabeled sets. WAAL selected samples that are highly
    uncertain and most likely to be unlabeled for annotation. Mahmood et al. [[2022](#bib.bib124)]
    formulated AL as an optimal transport problem. They aimed at minimizing the Wasserstein
    distance between the labeled and unlabeled sets with self-supervised features.
    They further adopted mixed-integer programming that guarantees global convergence
    for diverse sample selection. Moreover, Xie et al. [[2023b](#bib.bib208)] considered
    the candidates as continuously optimizable variables based on self-supervised
    features. They randomly initialized the candidate samples at first. Then, they
    maximized the similarity between candidates and their nearest neighbors while
    minimizing the similarity between candidates and labeled samples. Finally, they
    selected the nearest neighbors of the final candidates for annotation. They proved
    the objective is equivalent to minimizing the Wasserstein distance between the
    labeled and unlabeled samples.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Wasserstein 距离被广泛用于计算分布距离。Shui 等人 [[2020](#bib.bib167)] 指出 H-散度可能会妨碍样本选择的多样性，而
    Wasserstein 距离则确保查询的样本具有代表性和多样性。他们进一步提出了 Wasserstein 对抗主动学习（WAAL）。具体来说，WAAL 建立在
    VAAL 之上，并采用了一个额外的样本选择模块。他们通过最小化标记集和未标记集之间的 Wasserstein 距离来训练这个模块。WAAL 选择那些高度不确定且最可能未标记的样本进行注释。Mahmood
    等人 [[2022](#bib.bib124)] 将主动学习（AL）公式化为一个最优传输问题。他们的目标是最小化标记集和未标记集之间的 Wasserstein
    距离，同时利用自监督特征。他们进一步采用了混合整数编程，以保证多样样本选择的全局收敛。此外，Xie 等人 [[2023b](#bib.bib208)] 将候选样本视为基于自监督特征的连续可优化变量。他们首先随机初始化候选样本。然后，他们最大化候选样本与其最近邻之间的相似度，同时最小化候选样本与标记样本之间的相似度。最后，他们选择最终候选样本的最近邻进行注释。他们证明了这个目标等同于最小化标记样本和未标记样本之间的
    Wasserstein 距离。
- en: 3.2.3 Density-based Active Learning
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 基于密度的主动学习
- en: Density-based AL employs density estimation to characterize the data distribution
    in a high-dimensional feature space. The likelihood is the estimated density of
    the data distribution, and a more densely populated area indicates a higher likelihood.
    In this case, representative samples are samples with high likelihood. However,
    such methods can easily cause redundancy in sample selection. As a result, techniques
    like clustering are frequently used to improve diversity in sample selection.
    Density-based AL directly estimates the data distribution, which prevents the
    need to solve complex optimization problems. TypiClust [Hacohen et al., [2022](#bib.bib61)]
    projected samples to a high-dimensional feature space via a self-supervised encoder.
    The density of a sample was defined as the reciprocal of the L2 distances to its
    k-nearest neighbors. Additionally, TypiClust performed clustering beforehand to
    ensure the diversity of selected samples. Wang et al. [[2022c](#bib.bib193)] proposed
    two variants of density-based AL. The first variant fixed the feature representation.
    The process was similar to TypiClust, but they maximized the distances between
    selected samples to ensure diversity. The other variant was in an end-to-end fashion.
    Feature representation and sample selection were trained simultaneously. This
    variant used a learnable k-Means clustering to jointly optimize cluster assignment
    and feature representation with a local smoothness constraint.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 基于密度的主动学习（AL）利用密度估计来刻画高维特征空间中的数据分布。似然性是对数据分布的估计密度，更高的密度区域表示更高的似然性。在这种情况下，代表性样本是具有高似然性的样本。然而，这种方法容易导致样本选择中的冗余。因此，像聚类这样的技术经常被用来提高样本选择的多样性。基于密度的主动学习直接估计数据分布，这避免了复杂优化问题的求解。TypiClust
    [Hacohen et al., [2022](#bib.bib61)] 通过自监督编码器将样本投影到高维特征空间。样本的密度被定义为到其k个最近邻的L2距离的倒数。此外，TypiClust在之前进行了聚类，以确保所选样本的多样性。Wang
    et al. [[2022c](#bib.bib193)] 提出了两种基于密度的主动学习变体。第一种变体固定特征表示。该过程类似于TypiClust，但他们最大化了选定样本之间的距离以确保多样性。另一种变体是端到端的。特征表示和样本选择同时进行训练。该变体使用可学习的k均值聚类，以局部平滑约束共同优化簇分配和特征表示。
- en: 'In active domain adaptation, density estimation is also widely used to select
    representative samples in the target domain. Please refer to §[4.3](#S4.SS3 "4.3
    Active Domain Adaptation: Tackling Distribution Shift ‣ 4.2.2 Combination of Active
    Learning and Self-supervised Learning ‣ 4.2 Self-supervised Learning: Utilizing
    Pre-trained Model ‣ 4.1.2 Consistency Regularization ‣ 4.1 Semi-supervised Learning:
    Utilizing Unlabeled Data ‣ 4 Integration of Active Learning and Other Label-Efficient
    Techniques ‣ A comprehensive survey on deep active learning and its applications
    in medical image analysis") for related works.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '在主动领域适应中，密度估计也被广泛用于选择目标领域中的代表性样本。有关相关工作的详细信息，请参见§[4.3](#S4.SS3 "4.3 Active
    Domain Adaptation: Tackling Distribution Shift ‣ 4.2.2 Combination of Active Learning
    and Self-supervised Learning ‣ 4.2 Self-supervised Learning: Utilizing Pre-trained
    Model ‣ 4.1.2 Consistency Regularization ‣ 4.1 Semi-supervised Learning: Utilizing
    Unlabeled Data ‣ 4 Integration of Active Learning and Other Label-Efficient Techniques
    ‣ A comprehensive survey on deep active learning and its applications in medical
    image analysis")。'
- en: 3.3 Sampling Strategy
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 采样策略
- en: Most deep AL works used top-k to select samples with the highest informativeness
    for annotation. However, existing informativeness metrics face several issues,
    such as redundancy and class imbalance in selected samples. Instead of improving
    informativeness, we can introduce simple sampling strategies to resolve these
    issues effectively. Besides, specific sampling strategies can also be used for
    combining multiple informativeness metrics. Furthermore, with the recent development
    of deep AL, more studies directly employ neural networks for sample selection.
    In this context, we no longer evaluate informativeness but directly choose valuable
    samples from the unlabeled pool with neural networks. In summary, sampling strategies
    are crucial in AL, but prior surveys have seldom discussed their specific attributes.
    As one of the contributions of this survey, we systematically summarize different
    sampling strategies in AL, including diversity sampling, class-balanced sampling,
    hybrid sampling, and learnable sampling. The taxonomy of different sampling strategies
    in AL is shown in Fig. [5](#S3.F5 "Figure 5 ‣ 3.3 Sampling Strategy ‣ 3 Core Methods
    of Active Learning ‣ A comprehensive survey on deep active learning and its applications
    in medical image analysis").
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数深度主动学习（AL）工作使用 top-k 选择信息量最高的样本进行标注。然而，现有的信息量度量面临一些问题，如选择样本的冗余性和类别不平衡。我们可以引入简单的采样策略来有效解决这些问题，而不是改进信息量。此外，特定的采样策略也可以用于结合多个信息量度量。此外，随着深度主动学习的近期发展，更多研究直接使用神经网络进行样本选择。在这种情况下，我们不再评估信息量，而是直接从未标记的池中使用神经网络选择有价值的样本。总之，采样策略在主动学习中至关重要，但之前的调查很少讨论它们的具体属性。作为本调查的贡献之一，我们系统地总结了主动学习中的不同采样策略，包括多样性采样、类别平衡采样、混合采样和可学习采样。主动学习中不同采样策略的分类见图
    [5](#S3.F5 "图 5 ‣ 3.3 采样策略 ‣ 主动学习的三大核心方法 ‣ 深度主动学习及其在医学图像分析中的应用的综合调查")。
- en: '![Refer to caption](img/b9d9b65531493cf847699c3e1eea1957.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/b9d9b65531493cf847699c3e1eea1957.png)'
- en: 'Figure 5: The taxonomy of different sampling strategies in active learning.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：主动学习中不同采样策略的分类。
- en: 3.3.1 Diversity Sampling
  id: totrans-116
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1 多样性采样
- en: Diversity strategies aim to reduce redundancy in selected samples. Sampling
    redundancy is a common issue for uncertainty-based and representativeness-based
    methods, meaning some selected samples are highly similar. The lack of diversity
    leads to the waste of the annotation budget. Besides, redundancy in the training
    set may cause deep models to overfit, thus degrading performance. Therefore, many
    AL methods employ diversity sampling to mitigate the redundancy in selected samples.
    In this section, we discuss four strategies of diversity sampling, including clustering,
    farthest-first traversal, determinantal point process (DPP), and specific strategies
    tailored to certain informativeness metrics.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 多样性策略旨在减少所选样本中的冗余性。采样冗余是基于不确定性和代表性的常见问题，这意味着一些所选样本高度相似。缺乏多样性会导致标注预算的浪费。此外，训练集中冗余的数据可能导致深度模型过拟合，从而降低性能。因此，许多主动学习方法采用多样性采样来缓解所选样本中的冗余。在这一部分，我们讨论了四种多样性采样策略，包括聚类、最远优先遍历、确定性点过程（DPP）和针对特定信息量度量的特定策略。
- en: Clustering is one of the most commonly used strategies of diversity sampling.
    It groups the data into several clusters and then queries samples within each
    cluster. This strategy improves the coverage of the entire feature space, thereby
    easily boosting diversity. Ash et al. [[2020](#bib.bib8)] employed k-Means++ clustering
    on gradient embeddings to select diverse uncertain samples. Citovsky et al. [[2021](#bib.bib37)]
    boosted margin-based uncertainty sampling with hierarchical clustering. They selected
    samples with the smallest margins within each cluster. When the number of queries
    exceeded the number of clusters, samples from smaller clusters were prioritized.
    This method can extend to a huge annotation budget (e.g., one million). Jin et al.
    [[2022a](#bib.bib82)] employed BIRCH clustering and chose the samples with maximum
    information density within each cluster for labeling. Compared to k-Means, BIRCH
    clustering is less sensitive to outliers and can further identify noisy samples.
    In connectomics, Lin et al. [[2020](#bib.bib110)] trained two feature extractors
    with labeled and unlabeled samples, respectively. They then selected samples for
    annotation through multiple rounds of clustering. This method achieved excellent
    performance in synapse detection and mitochondria segmentation.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是最常用的多样性采样策略之一。它将数据分成多个簇，然后在每个簇内查询样本。这种策略提高了整个特征空间的覆盖范围，从而更容易提升多样性。Ash等人[[2020](#bib.bib8)]在梯度嵌入上应用了k-Means++聚类，以选择多样化的不确定样本。Citovsky等人[[2021](#bib.bib37)]通过层次聚类提升了基于边界的采样不确定性。他们在每个簇内选择了边界最小的样本。当查询数超过簇数时，优先选择较小簇中的样本。这种方法可以扩展到巨大的标注预算（例如，一百万）。Jin等人[[2022a](#bib.bib82)]采用了BIRCH聚类，并选择了每个簇内信息密度最大的样本进行标注。与k-Means相比，BIRCH聚类对离群值的敏感性较低，并且能进一步识别噪声样本。在连通组学中，Lin等人[[2020](#bib.bib110)]分别用标注样本和未标注样本训练了两个特征提取器。然后，他们通过多轮聚类选择样本进行标注。这种方法在突触检测和线粒体分割中取得了出色的表现。
- en: Farthest-first Traversal is also a widely used strategy for diverse queries.
    The farthest-first traversal requires the distance between sampling points to
    be as large as possible in the feature space. This leads to a more uniform distribution
    of selected samples within the feature space, thus improving the diversity of
    the sampling results. This technique was first adopted by Sener and Savarese [[2018](#bib.bib160)].
    Agarwal et al. [[2020](#bib.bib2)] and Caramalau et al. [[2021](#bib.bib26)] improved
    the diversity with farthest-first traversal, leveraging their proposed contextual
    diversity and GNN-augmented features, respectively. However, when the annotation
    budget is limited, the farthest-first traversal may be biased toward outliers.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**最远点遍历**也是一种广泛使用的多样性查询策略。最远点遍历要求在特征空间中采样点之间的距离尽可能大。这导致了特征空间中选择的样本分布更为均匀，从而改善了采样结果的多样性。这项技术最早由Sener和Savarese[[2018](#bib.bib160)]采用。Agarwal等人[[2020](#bib.bib2)]和Caramalau等人[[2021](#bib.bib26)]通过最远点遍历改进了多样性，分别利用了他们提出的上下文多样性和GNN增强特征。然而，当标注预算有限时，最远点遍历可能会偏向离群值。'
- en: 'Determinantal point process is a stochastic probability model for selecting
    subsets from a larger set. DPP reduces the probability of sampling similar elements
    to ensure diversity in the results. Bıyık et al. [[2019](#bib.bib22)] employed
    two DPPs for sample selection: Uncertainty DPP is based on uncertainty scores,
    while Exploration DPP aims to find samples near decision boundaries. Then, sampling
    results from both DPPs were sent for expert annotation. However, DPP is more computationally
    intensive compared to clustering. Ash et al. [[2020](#bib.bib8)] compared the
    performance and time cost of using k-Means++ and k-DPP. Results showed that their
    performance is similar, but the time cost for k-Means++ is significantly lower
    than that for k-DPP.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**行列式点过程**是一种用于从更大集合中选择子集的随机概率模型。DPP减少了采样类似元素的概率，以确保结果的多样性。Bıyık等人[[2019](#bib.bib22)]使用了两种DPP进行样本选择：不确定性DPP基于不确定性评分，而探索DPP旨在寻找接近决策边界的样本。然后，将两种DPP的采样结果送往专家标注。然而，与聚类相比，DPP在计算上更为密集。Ash等人[[2020](#bib.bib8)]比较了使用k-Means++和k-DPP的性能和时间成本。结果显示，它们的性能相似，但k-Means++的时间成本明显低于k-DPP。'
- en: 'Specific strategies: There are also specific strategies tailored to certain
    informativeness metrics. In uncertainty-based AL, BatchBALD [Kirsch et al., [2019](#bib.bib95)]
    extended BALD-based uncertainty AL to batch mode. Results showed that BatchBALD
    improved the sampling diversity compared to [Gal et al., [2017](#bib.bib52)].
    FI-based methods formulated AL as a semi-definite programming (SDP) problem to
    improve sampling diversity. Different methods were employed for solving SDP. Sourati
    et al. [[2019](#bib.bib173)] used a commercial solver to solve SDP, while Ash
    et al. [[2021](#bib.bib7)] proposed a greedy algorithm to adapt to high-dimensional
    feature space. Moreover, diversity is an essential part of representativeness-based
    AL. Cover-based AL inherently incorporates the considerations of diversity in
    its formulations. In discrepancy-based AL, Wasserstein distance is used for diverse
    query results [Shui et al., [2020](#bib.bib167), Mahmood et al., [2022](#bib.bib124)].
    Density-based methods often employ strategies like clustering to improve diversity.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 具体策略：针对某些信息量度量，还有特定的策略。在基于不确定性的主动学习中，BatchBALD [Kirsch et al., [2019](#bib.bib95)]
    将基于BALD的不确定性主动学习扩展到批量模式。结果表明，与[Gal et al., [2017](#bib.bib52)]相比，BatchBALD提高了采样多样性。基于FI的方法将主动学习制定为半正定规划（SDP）问题以改善采样多样性。不同的方法被用于解决SDP。Sourati
    et al. [[2019](#bib.bib173)] 使用商业求解器解决SDP，而Ash et al. [[2021](#bib.bib7)] 提出了适应高维特征空间的贪婪算法。此外，多样性是基于代表性的主动学习的一个重要部分。基于覆盖的主动学习在其公式中本质上融入了多样性的考虑。在基于离散度的主动学习中，Wasserstein距离用于多样化查询结果[Shui
    et al., [2020](#bib.bib167), Mahmood et al., [2022](#bib.bib124)]。基于密度的方法通常采用聚类等策略来提高多样性。
- en: 3.3.2 Class-balance Sampling
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2 类别平衡采样
- en: Class imbalance is a common issue for DL, where a small set of classes have
    many samples while the others only contain a few samples [Zhang et al., [2023](#bib.bib223)].
    For example, in tasks such as medical image classification, normal samples often
    outnumber abnormal ones. Training on imbalanced datasets can lead to the overfitting
    of the majority classes and underfitting of the minority classes. Apart from dealing
    with class imbalance during training, AL mitigates class imbalance by avoiding
    over-annotation of the majority classes and enhancing the annotation of the minority
    classes during dataset construction.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 类别不平衡是深度学习中的常见问题，其中一小部分类别有许多样本，而其他类别仅包含少量样本[Zhang et al., [2023](#bib.bib223)]。例如，在医学图像分类等任务中，正常样本通常多于异常样本。在不平衡的数据集上训练可能导致主要类别的过拟合和次要类别的欠拟合。除了在训练过程中处理类别不平衡，主动学习通过避免对主要类别的过度标注和在数据集构建过程中增强对次要类别的标注来缓解类别不平衡。
- en: 'Classification: Choi et al. [[2021b](#bib.bib36)] directly estimated the probability
    of a classifier making a mistake for a given sample and decomposed it into three
    terms using Bayesian rules. First, they trained a VAE to estimate the likelihood
    of the data given a predicted class. Then, an additional classifier was trained
    upon VAE features to estimate class prior probabilities and the probability of
    mislabeling a specific class. By considering all three probabilities, they successfully
    mitigated class imbalance in AL. The proposed method achieved good performance
    on stepwise class-imbalanced CIFAR-10 and CIFAR-100 datasets. For uncertainty-based
    methods, Bengar et al. [[2022](#bib.bib17)] introduced an optimization framework
    to maintain class balance. They compensated the query of minority classes with
    the most confident samples of that class, leading to a more balanced class distribution
    in the queried dataset. In classification tasks, Munjal et al. [[2022](#bib.bib130)]
    tested various AL baselines on the long-tailed CIFAR-100 dataset. Results showed
    that no single method outperforms others on all budgets in the class-imbalance
    setting. However, as the number of labeled data increases, the performance gap
    between random sampling and the best AL method decreases. Hacohen et al. [[2022](#bib.bib61)]
    conducted experiments in a class-imbalanced setting similar to Munjal et al. [[2022](#bib.bib130)].
    The proposed TypiClust ensured class balance and outperformed other baseline methods.
    Jin et al. [[2022c](#bib.bib84)] assumed that samples closer to the tail of the
    distribution are more likely to belong to the minority classes. Thus, the tail
    probability is equivalent to the likelihood of minority classes. Specifically,
    they trained a VAE for feature extraction and adopted copula to estimate the tail
    probabilities upon VAE features. Finally, informative samples were selected with
    clustering and unequal probability sampling. The proposed method was validated
    on the ISIC 2020 dataset, which has a long-tailed distribution. Kothawade et al.
    [[2022c](#bib.bib101)] used submodular mutual information to focus more on samples
    of minority classes. They achieved excellent results on medical classification
    datasets in five different modalities, including X-rays, pathology, and dermoscopy.
    Besides, in blood cell detection under microscopy, Sadafi et al. [[2019](#bib.bib157)]
    requested expert annotation of a sample whenever its classification probability
    of the minority class exceeded 0.2.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：Choi等人[[2021b](#bib.bib36)] 直接估计了分类器对给定样本出错的概率，并使用贝叶斯规则将其分解为三个部分。首先，他们训练了一个VAE来估计给定预测类别的数据的可能性。然后，在VAE特征上训练了一个额外的分类器，以估计类别的先验概率和特定类别的错误标记概率。通过考虑这三种概率，他们成功缓解了AL中的类别不平衡。所提出的方法在逐步类别不平衡的CIFAR-10和CIFAR-100数据集上表现良好。对于基于不确定性的方法，Bengar等人[[2022](#bib.bib17)]
    引入了一个优化框架来保持类别平衡。他们通过最可信的样本来补偿少数类别的查询，从而在查询的数据集中实现了更平衡的类别分布。在分类任务中，Munjal等人[[2022](#bib.bib130)]
    在长尾CIFAR-100数据集上测试了各种AL基线。结果表明，在类别不平衡设置下，没有一种方法在所有预算下都优于其他方法。然而，随着标记数据数量的增加，随机采样和最佳AL方法之间的性能差距减少。Hacohen等人[[2022](#bib.bib61)]
    在类似于Munjal等人[[2022](#bib.bib130)]的类别不平衡设置下进行了实验。所提出的TypiClust确保了类别平衡，并优于其他基线方法。Jin等人[[2022c](#bib.bib84)]
    假设分布尾部的样本更可能属于少数类别。因此，尾部概率等同于少数类别的可能性。具体来说，他们训练了一个VAE进行特征提取，并采用copula来估计VAE特征上的尾部概率。最后，通过聚类和不等概率采样选择了有信息的样本。所提出的方法在具有长尾分布的ISIC
    2020数据集上进行了验证。Kothawade等人[[2022c](#bib.bib101)] 使用子模块互信息来更关注少数类别的样本。他们在五种不同模态的医学分类数据集上取得了出色的结果，包括X光、病理学和皮肤镜检查。此外，在显微镜下的血细胞检测中，Sadafi等人[[2019](#bib.bib157)]
    在其少数类别的分类概率超过0.2时请求对样本进行专家标注。
- en: 'Segmentation: Due to some AL methods selecting regions instead of the entire
    image for annotation, there is a need to ensure that the selected regions contain
    rare or small objects (e.g., pedestrians or utility poles in autonomous driving).
    Cai et al. [[2021](#bib.bib25)] and Wu et al. [[2022b](#bib.bib199)] both proposed
    class-balanced sampling strategies for such scenarios, as detailed in §[4.4](#S4.SS4
    "4.4 Region-based Active Learning: Smaller Labeling Unit ‣ 4.3 Active Domain Adaptation:
    Tackling Distribution Shift ‣ 4.2.2 Combination of Active Learning and Self-supervised
    Learning ‣ 4.2 Self-supervised Learning: Utilizing Pre-trained Model ‣ 4.1.2 Consistency
    Regularization ‣ 4.1 Semi-supervised Learning: Utilizing Unlabeled Data ‣ 4 Integration
    of Active Learning and Other Label-Efficient Techniques ‣ A comprehensive survey
    on deep active learning and its applications in medical image analysis").'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 分割：由于一些主动学习方法选择区域而不是整个图像进行标注，因此需要确保所选区域包含稀有或小型物体（例如，自动驾驶中的行人或电线杆）。Cai et al.
    [[2021](#bib.bib25)] 和 Wu et al. [[2022b](#bib.bib199)] 都为这种情况提出了类别平衡采样策略，详细内容见§[4.4](#S4.SS4
    "4.4 基于区域的主动学习：更小的标注单元 ‣ 4.3 主动领域适应：应对分布偏移 ‣ 4.2.2 主动学习与自监督学习的结合 ‣ 4.2 自监督学习：利用预训练模型
    ‣ 4.1.2 一致性正则化 ‣ 4.1 半监督学习：利用未标注数据 ‣ 4 主动学习与其他标注高效技术的结合 ‣ 深度主动学习及其在医学图像分析中的应用的综合综述").
- en: 3.3.3 Hybrid Sampling
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.3 混合采样
- en: In AL, some works may use multiple informativeness metrics simultaneously. Therefore,
    the effective integration of multiple metrics remains a critical issue. This issue
    is addressed by the hybrid sampling strategy discussed in this section. Two approaches
    to hybrid sampling are primarily used, including multi-round sampling and metric
    fusion.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在主动学习中，一些研究可能会同时使用多个信息量指标。因此，有效整合多个指标仍然是一个关键问题。这个问题由本节讨论的混合采样策略解决。主要使用两种混合采样方法，包括多轮采样和指标融合。
- en: Multi-round sampling first selects a subset of samples based on one particular
    informativeness metric and continues sample selection within this subset based
    on another informativeness metric. For example, SA [Yang et al., [2017](#bib.bib211)]
    performed representativeness sampling based on uncertainty to reduce redundancy
    in the sampled set. Xie et al. [[2022b](#bib.bib204)] first selected samples with
    density-based methods and selected the most uncertain samples within each cluster
    of representative samples. In another study, Xie et al. [[2022c](#bib.bib205)]
    introduced distribution and data uncertainty based on EDL, and then a two-stage
    strategy was used for sample selection. Wu et al. [[2022b](#bib.bib199)] employed
    a more complex strategy, which sets dynamic weights to adjust the budget of representativeness
    and uncertainty sampling. The weight of representativeness sampling is larger
    initially, while the situation is reversed in the latter phase. This is because
    representativeness methods can quickly spot typical data, while uncertainty methods
    continuously improve the model by querying samples with erroneous predictions.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 多轮采样首先基于某个特定的信息量指标选择一部分样本，然后在该子集中根据另一个信息量指标继续选择样本。例如，SA [Yang et al., [2017](#bib.bib211)]
    基于不确定性进行代表性采样，以减少采样集中冗余。Xie et al. [[2022b](#bib.bib204)] 首先使用基于密度的方法选择样本，然后在每个代表性样本集群中选择最不确定的样本。在另一项研究中，Xie
    et al. [[2022c](#bib.bib205)] 引入了基于EDL的分布和数据不确定性，然后采用两阶段策略进行样本选择。Wu et al. [[2022b](#bib.bib199)]
    采用了一种更复杂的策略，设定动态权重以调整代表性和不确定性采样的预算。代表性采样的权重初期较大，而后期情况则相反。这是因为代表性方法可以快速识别典型数据，而不确定性方法通过查询错误预测的样本持续改进模型。
- en: Metric fusion is another widely used approach of hybrid sampling. It directly
    combines different informativeness metrics. For example, one could directly sum
    up all metrics and select the samples with the highest values for annotation.
    Ranked batch-mode [Cardoso et al., [2017](#bib.bib27)] can adaptively fuse multiple
    metrics in AL.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 指标融合是混合采样中另一种广泛使用的方法。它直接结合不同的信息量指标。例如，可以直接将所有指标加总，并选择具有最高值的样本进行标注。排名批次模式 [Cardoso
    et al., [2017](#bib.bib27)] 可以在主动学习中自适应地融合多个指标。
- en: 3.3.4 Learnable Sampling
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.4 可学习采样
- en: Previously mentioned AL methods typically follow a “two-step” paradigm, which
    first involves the evaluation of informativeness and then selects samples based
    on specific heuristics (i.e., sampling strategy). However, learnable sampling
    skips the informativeness evaluation and directly uses neural networks for sample
    selection. In this context, the neural network is known as a “neural selector”.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 前面提到的主动学习（AL）方法通常遵循“二步”范式，即首先进行信息性评估，然后根据特定启发式（即采样策略）选择样本。然而，可学习采样跳过了信息性评估，直接使用神经网络进行样本选择。在这种情况下，神经网络被称为“神经选择器”。
- en: One of the most common methods of learnable sampling is to formulate sample
    selection as a reinforcement learning (RL) problem, where the learner and the
    dataset are considered the environment, and the neural selector serves as the
    agent. The agent interacts with the environment by selecting a limited number
    of samples for annotation, and the environment returns a reward to train the neural
    selector. Haußmann et al. [[2019](#bib.bib62)] adopted a probabilistic policy
    network as the neural selector. The rewards returned by the environment encouraged
    the neural selector to choose diverse and representative samples. The neural selector
    is trained using the REINFORCE algorithm [Williams, [1992](#bib.bib197)]. In pedestrian
    re-identification, Liu et al. [[2019](#bib.bib117)] used the annotation uncertainty
    as the reward for training the neural selector. Agarwal et al. [[2020](#bib.bib2)]
    utilized the proposed contextual diversity as RL rewards and trains a bidirectional
    long short-term memory network as the neural selector. In pose estimation, Gong
    et al. [[2022](#bib.bib56)] adopted multiple agents for sample selection and directly
    used the performance improvement of the pose estimator as the reward for training
    these agents. In medical image classification, Wang et al. [[2020a](#bib.bib187)]
    employed an actor-critic framework where the critic network is used to evaluate
    the quality of the samples selected by the neural selector. This method has performed
    excellently in lung CT disease classification and diabetic retinopathy classification
    of fundus images.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的可学习采样方法之一是将样本选择形式化为强化学习（RL）问题，其中学习者和数据集被视为环境，而神经选择器则充当代理。代理通过选择有限数量的样本进行标注与环境互动，环境返回奖励以训练神经选择器。Haußmann
    等人[[2019](#bib.bib62)] 采用了概率策略网络作为神经选择器。环境返回的奖励鼓励神经选择器选择多样且具有代表性的样本。神经选择器使用 REINFORCE
    算法[Williams, [1992](#bib.bib197)]进行训练。在行人重识别中，Liu 等人[[2019](#bib.bib117)]使用标注不确定性作为训练神经选择器的奖励。Agarwal
    等人[[2020](#bib.bib2)] 利用提出的上下文多样性作为 RL 奖励，并训练了一个双向长短期记忆网络作为神经选择器。在姿态估计中，Gong 等人[[2022](#bib.bib56)]
    采用了多个代理进行样本选择，并直接使用姿态估计器的性能提升作为训练这些代理的奖励。在医学图像分类中，Wang 等人[[2020a](#bib.bib187)]采用了演员-评论家框架，其中评论家网络用于评估神经选择器所选择样本的质量。这种方法在肺部
    CT 疾病分类和糖尿病视网膜病变分类方面表现优异。
- en: For more works on learnable sampling in AL, such as formulating AL as few-shot
    learning or training neural selectors by meta-learning, please refer to the survey
    of Liu et al. [[2022b](#bib.bib113)].
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 AL 中可学习采样的更多研究，例如将 AL 形式化为少样本学习或通过元学习训练神经选择器，请参阅 Liu 等人[[2022b](#bib.bib113)]的综述。
- en: 4 Integration of Active Learning and Other Label-Efficient Techniques
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 积极学习与其他标签效率技术的整合
- en: Various methods have been proposed to reduce the large amount of labeled data
    required for training deep models, such as active learning, semi-supervised learning,
    self-supervised learning, etc. These methods are collectively called label-efficient
    deep learning [Jin et al., [2023a](#bib.bib79)]. Label-efficient learning is a
    broad concept that includes all related technologies designed to improve annotation
    efficiency. In §[3](#S3 "3 Core Methods of Active Learning ‣ A comprehensive survey
    on deep active learning and its applications in medical image analysis"), we summarized
    the core methods in AL, including the evaluation of informativeness and sampling
    strategies. However, there is still room for AL to further improve the label efficiency.
    For example, AL has not used unlabeled data for training, has not considered distribution
    shift, and still needs to annotate the whole image in fine-grained tasks such
    as segmentation. Integrating active learning with other label-efficient techniques
    can increase annotation efficiency. While some efforts have been made, existing
    surveys have not yet systematically organized and categorized this line of work.
    Hence, as one of the main contributions of this survey, we comprehensively reviewed
    the integration of AL with other label-efficient techniques, including semi-supervised
    learning, self-supervised learning, domain adaptation, region-based annotation,
    and generative models. Additionally, how each surveyed work integrated with other
    label-efficient techniques is summarized in Table [4](#S4 "4 Integration of Active
    Learning and Other Label-Efficient Techniques ‣ A comprehensive survey on deep
    active learning and its applications in medical image analysis").
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 已提出各种方法以减少训练深度模型所需的大量标记数据，例如主动学习、半监督学习、自监督学习等。这些方法统称为标签高效深度学习 [Jin 等，[2023a](#bib.bib79)]。标签高效学习是一个广泛的概念，包括所有旨在提高注释效率的相关技术。在
    §[3](#S3 "3 Core Methods of Active Learning ‣ A comprehensive survey on deep active
    learning and its applications in medical image analysis")中，我们总结了主动学习中的核心方法，包括信息量评估和采样策略。然而，主动学习在提高标签效率方面仍有改进空间。例如，主动学习尚未利用未标记数据进行训练，尚未考虑分布转移，并且在分割等细粒度任务中仍需标注整个图像。将主动学习与其他标签高效技术结合可以提高注释效率。尽管已有一些努力，但现有的调查尚未系统地组织和分类这方面的工作。因此，作为本调查的主要贡献之一，我们全面回顾了主动学习与其他标签高效技术的整合，包括半监督学习、自监督学习、领域适应、基于区域的注释和生成模型。此外，每项调查工作如何与其他标签高效技术整合的情况总结在表
    [4](#S4 "4 Integration of Active Learning and Other Label-Efficient Techniques
    ‣ A comprehensive survey on deep active learning and its applications in medical
    image analysis")中。
- en: 'Table 2: Methodology summarization of surveyed active learning works.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：调查的主动学习工作的 метод论总结。
- en: '|  | Year | Venues | Uncertainty | Representativeness | Sampling Strategy |
    SemiSL | SelfSL | ADA | Region | Generative |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '|  | 年份 | 会议 | 不确定性 | 代表性 | 采样策略 | SemiSL | SelfSL | ADA | 区域 | 生成 |'
- en: '| 06em. 06em. | Method | Basic Metrics | Method | Basic Metrics |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 06em. 06em. | 方法 | 基本指标 | 方法 | 基本指标 |'
- en: '| Zhu and Bento [[2017](#bib.bib234)] | 2017 | arXiv | Single Model | Distance
    to Decision Boundary | - | - | Top-k |  |  |  |  |  |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| Zhu 和 Bento [[2017](#bib.bib234)] | 2017 | arXiv | 单模型 | 距离决策边界 | - | - |
    Top-k |  |  |  |  |  |'
- en: '| Zhou et al. [[2017](#bib.bib232)] | 2017 | CVPR | Single Model Data Disagreement
    | Entropy KL Divergence | - | - | Hybrid - Fusion |  |  |  |  |  |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| Zhou 等 [[2017](#bib.bib232)] | 2017 | CVPR | 单模型数据不一致 | 熵 KL 散度 | - | - |
    混合 - 融合 |  |  |  |  |  |'
- en: '| Gal et al. [[2017](#bib.bib52)] | 2017 | ICML | Multiple Inferences - MC
    Dropout | Entropy, BALD, Least Confidence, Variance | - | - | Top-k |  |  |  |  |  |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| Gal 等 [[2017](#bib.bib52)] | 2017 | ICML | 多重推断 - MC Dropout | 熵、BALD、最小置信度、方差
    | - | - | Top-k |  |  |  |  |  |'
- en: '| Yang et al. [[2017](#bib.bib211)] | 2017 | MICCAI | Model Disagreement |
    Variance | Cover-based | Cosine Similarity | Hybrid - Multi-round |  |  |  |  |  |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| Yang 等 [[2017](#bib.bib211)] | 2017 | MICCAI | 模型不一致 | 方差 | 覆盖基础 | 余弦相似度
    | 混合 - 多轮 |  |  |  |  |  |'
- en: '| Wang et al. [[2017](#bib.bib188)] | 2017 | TCSVT | Single Model | Least Confidence,
    Margin, Entropy | - | - | Top-k | Pseudo-label |  |  |  |  |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等 [[2017](#bib.bib188)] | 2017 | TCSVT | 单模型 | 最小置信度、边距、熵 | - | - |
    Top-k | 伪标签 |  |  |  |  |'
- en: '| Ducoffe and Precioso [[2018](#bib.bib45)] | 2018 | arXiv | Adversarial Samples
    | Distance to Decision Boundary | - | - | Top-k |  |  |  |  |  |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| Ducoffe 和 Precioso [[2018](#bib.bib45)] | 2018 | arXiv | 对抗样本 | 距离决策边界 |
    - | - | Top-k |  |  |  |  |  |'
- en: '| Mackowiak et al. [[2018](#bib.bib120)] | 2018 | BMVC | Model Disagreement
    | Vote Entropy | - | - | Top-k |  |  |  | Patch |  |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| Mackowiak et al. [[2018](#bib.bib120)] | 2018 | BMVC | 模型不一致 | 投票熵 | - |
    - | Top-k |  |  |  | 区块 |  |'
- en: '| Xu et al. [[2018](#bib.bib209)] | 2018 | CVPR | Multiple Inferences - Model
    Ensemble | Variance | Cover-based | Cosine Similarity | Hybrid - Multi-round |  |  |  |  |  |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| Xu et al. [[2018](#bib.bib209)] | 2018 | CVPR | 多重推断 - 模型集成 | 方差 | 基于覆盖 |
    余弦相似度 | 混合 - 多轮 |  |  |  |  |  |'
- en: '| Beluch et al. [[2018](#bib.bib16)] | 2018 | CVPR | Multiple Inferences -
    Model Ensemble | Entropy, BALD, Least Confidence, Variance | - | - | Top-k |  |  |  |  |  |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| Beluch et al. [[2018](#bib.bib16)] | 2018 | CVPR | 多重推断 - 模型集成 | 熵, BALD,
    最小置信度, 方差 | - | - | Top-k |  |  |  |  |  |'
- en: '| Sourati et al. [[2018](#bib.bib172)] | 2018 | DLMIA | Gradient-based Metrics
    | Fisher Information | - | - | Diversity - Solve Programming Problem |  |  |  |  |  |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| Sourati et al. [[2018](#bib.bib172)] | 2018 | DLMIA | 基于梯度的度量 | 费舍尔信息 | -
    | - | 多样性 - 解决编程问题 |  |  |  |  |  |'
- en: '| Sener and Savarese [[2018](#bib.bib160)] | 2018 | ICLR | - | - | Cover-based
    | L2 Distance | Diversity - Farthest-first Traversal |  |  |  |  |  |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| Sener and Savarese [[2018](#bib.bib160)] | 2018 | ICLR | - | - | 基于覆盖 | L2
    距离 | 多样性 - 最远优先遍历 |  |  |  |  |  |'
- en: '| Kuo et al. [[2018](#bib.bib103)] | 2018 | MICCAI | Model Disagreement | JS
    Divergence | - | - | Diversity - Solve Programming Problem |  |  |  |  |  |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| Kuo et al. [[2018](#bib.bib103)] | 2018 | MICCAI | 模型不一致 | JS 散度 | - | -
    | 多样性 - 解决编程问题 |  |  |  |  |  |'
- en: '| Mahapatra et al. [[2018](#bib.bib121)] | 2018 | MICCAI | Multiple Inferences
    - MC Dropout | Variance | - | - | Top-k |  |  |  |  |  |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| Mahapatra et al. [[2018](#bib.bib121)] | 2018 | MICCAI | 多重推断 - MC Dropout
    | 方差 | - | - | Top-k |  |  |  |  |  |'
- en: '| Haußmann et al. [[2019](#bib.bib62)] | 2019 | IJCAI | - | - | - | - | Learnable
    - Reinforcement Learning |  |  |  |  |  |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| Haußmann et al. [[2019](#bib.bib62)] | 2019 | IJCAI | - | - | - | - | 可学习
    - 强化学习 |  |  |  |  |  |'
- en: '| Zheng et al. [[2019](#bib.bib227)] | 2019 | AAAI | - | - | Cover-based |
    Cosine Similarity | Diversity - Clustering |  |  |  |  |  |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| Zheng et al. [[2019](#bib.bib227)] | 2019 | AAAI | - | - | 基于覆盖 | 余弦相似度 |
    多样性 - 聚类 |  |  |  |  |  |'
- en: '| Gissin and Shalev-Shwartz [[2019](#bib.bib55)] | 2019 | arXiv | - | - | Discrepancy-based
    | H-Divergence | Top-k |  |  |  |  |  |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| Gissin and Shalev-Shwartz [[2019](#bib.bib55)] | 2019 | arXiv | - | - | 基于差异的
    | H-散度 | Top-k |  |  |  |  |  |'
- en: '| Yoo and Kweon [[2019](#bib.bib214)] | 2019 | CVPR | Performance Estimation
    - Learnable | Loss | - | - | Top-k |  |  |  |  |  |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| Yoo and Kweon [[2019](#bib.bib214)] | 2019 | CVPR | 性能估计 - 可学习 | 损失 | - |
    - | Top-k |  |  |  |  |  |'
- en: '| Sinha et al. [[2019](#bib.bib170)] | 2019 | ICCV | - | - | Discrepancy-based
    | H-Divergence | Top-k |  |  |  |  |  |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| Sinha et al. [[2019](#bib.bib170)] | 2019 | ICCV | - | - | 基于差异的 | H-散度 |
    Top-k |  |  |  |  |  |'
- en: '| Liu et al. [[2019](#bib.bib117)] | 2019 | ICCV | - | - | - | - | Learnable
    - Reinforcement Learning |  |  |  |  |  |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| Liu et al. [[2019](#bib.bib117)] | 2019 | ICCV | - | - | - | - | 可学习 - 强化学习
    |  |  |  |  |  |'
- en: '| Aghdam et al. [[2019](#bib.bib3)] | 2019 | ICCV | Data Disagreement | BALD
    | - | - | Top-K |  |  |  |  |  |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| Aghdam et al. [[2019](#bib.bib3)] | 2019 | ICCV | 数据不一致 | BALD | - | - |
    Top-K |  |  |  |  |  |'
- en: '| Tran et al. [[2019](#bib.bib181)] | 2019 | ICML | Multiple Inferences - MC
    Dropout | BALD | - | - | Top-k |  |  |  |  |  |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| Tran et al. [[2019](#bib.bib181)] | 2019 | ICML | 多重推断 - MC Dropout | BALD
    | - | - | Top-k |  |  |  |  |  |'
- en: '| Qi et al. [[2019](#bib.bib145)] | 2019 | JBHI | Single Model | Entropy |
    - | - | Top-k | Pseudo-label |  |  |  |  |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| Qi et al. [[2019](#bib.bib145)] | 2019 | JBHI | 单模型 | 熵 | - | - | Top-k |
    伪标签 |  |  |  |  |'
- en: '| Sadafi et al. [[2019](#bib.bib157)] | 2019 | MICCAI | Multiple Inferences
    - MC Dropout | Average IoU, Class Frequency | - | - | Class-balance Hybrid - Fusion
    |  |  |  |  |  |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Sadafi et al. [[2019](#bib.bib157)] | 2019 | MICCAI | 多重推断 - MC Dropout |
    平均 IoU, 类别频率 | - | - | 类别平衡混合 - 融合 |  |  |  |  |  |'
- en: '| Kirsch et al. [[2019](#bib.bib95)] | 2019 | NeurIPS | Multiple Inferences
    - MC Dropout | BALD | - | - | Top-k |  |  |  |  |  |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| Kirsch et al. [[2019](#bib.bib95)] | 2019 | NeurIPS | 多重推断 - MC Dropout |
    BALD | - | - | Top-k |  |  |  |  |  |'
- en: '| Sourati et al. [[2019](#bib.bib173)] | 2019 | TMI | Gradient-based Metrics
    | Fisher Information | - | - | Diversity - Solve Programming Problem |  |  |  |  |  |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| Sourati et al. [[2019](#bib.bib173)] | 2019 | TMI | 基于梯度的度量 | 费舍尔信息 | - |
    - | 多样性 - 解决编程问题 |  |  |  |  |  |'
- en: '| Kasarla et al. [[2019](#bib.bib88)] | 2019 | WACV | Single Model | Entropy
    | - | - | Top-k |  |  |  | Superpixel |  |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| Kasarla et al. [[2019](#bib.bib88)] | 2019 | WACV | 单模型 | 熵 | - | - | Top-k
    |  |  |  | 超像素 |  |'
- en: '| Zheng et al. [[2020](#bib.bib228)] | 2020 | AAAI | - | - | Cover-based |
    Cosine Similarity | Diversity - Clustering | Pseudo-label |  |  | Slice |  |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| Zheng et al. [[2020](#bib.bib228)] | 2020 | AAAI | - | - | 基于覆盖 | 余弦相似度 |
    多样性 - 聚类 | 伪标签 |  |  | 切片 |  |'
- en: '| Shui et al. [[2020](#bib.bib167)] | 2020 | AISTATS | Single Model | Entropy,
    Least Confidence | Discrepancy-based | Wasserstein Distance | Hybrid - Fusion
    |  |  |  |  |  |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| Shui 等人 [[2020](#bib.bib167)] | 2020 | AISTATS | 单模型 | 熵，最小置信度 | 基于差异的 |
    Wasserstein 距离 | 混合 - 融合 |  |  |  |  |  |'
- en: '| Siddiqui et al. [[2020](#bib.bib168)] | 2020 | CVPR | Multiple Inferences
    - MC Dropout Data Disagreement | Entropy KL Divergence | - | - | Hybrid - Fusion
    |  |  |  | Superpixel |  |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| Siddiqui 等人 [[2020](#bib.bib168)] | 2020 | CVPR | 多重推断 - MC Dropout 数据不一致性
    | 熵 KL 散度 | - | - | 混合 - 融合 |  |  |  | 超像素 |  |'
- en: '| Zhang et al. [[2020](#bib.bib219)] | 2020 | CVPR | Single Model | Variance
    | Discrepancy-based | H-Divergence | Diversity - Farthest-first Traversal |  |  |  |  |  |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| Zhang 等人 [[2020](#bib.bib219)] | 2020 | CVPR | 单模型 | 方差 | 基于差异的 | H-散度 |
    多样性 - 最远优先遍历 |  |  |  |  |  |'
- en: '| Gao et al. [[2020](#bib.bib53)] | 2020 | ECCV | Data Disagreement | Variance
    | - | - | Top-k | Consistency |  |  |  |  |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| Gao 等人 [[2020](#bib.bib53)] | 2020 | ECCV | 数据不一致性 | 方差 | - | - | Top-k |
    一致性 |  |  |  |  |'
- en: '| Wang et al. [[2020b](#bib.bib190)] | 2020 | ECCV | - | - | Discrepancy-based
    | H-Divergence | Learnable |  |  |  |  |  |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等人 [[2020b](#bib.bib190)] | 2020 | ECCV | - | - | 基于差异的 | H-散度 | 可学习
    |  |  |  |  |  |'
- en: '| Agarwal et al. [[2020](#bib.bib2)] | 2020 | ECCV | - | - | Cover-based |
    Contextual Diversity | Diversity - Farthest-first Traversal Learnable - Reinforcement
    Learning |  |  |  |  |  |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| Agarwal 等人 [[2020](#bib.bib2)] | 2020 | ECCV | - | - | 覆盖基的 | 上下文多样性 | 多样性
    - 最远优先遍历 可学习 - 强化学习 |  |  |  |  |  |'
- en: '| Lin et al. [[2020](#bib.bib110)] | 2020 | ECCV | - | - | Clustering | L2
    Distance | Diversity - Clustering |  |  |  |  |  |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| Lin 等人 [[2020](#bib.bib110)] | 2020 | ECCV | - | - | 聚类 | L2 距离 | 多样性 - 聚类
    |  |  |  |  |  |'
- en: '| Ash et al. [[2020](#bib.bib8)] | 2020 | ICLR | Gradient-based Metrics | Gradient
    | - | - | Diversity - Clustering |  |  |  |  |  |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| Ash 等人 [[2020](#bib.bib8)] | 2020 | ICLR | 基于梯度的指标 | 梯度 | - | - | 多样性 - 聚类
    |  |  |  |  |  |'
- en: '| Casanova et al. [[2020](#bib.bib28)] | 2020 | ICLR | - | - | - | - | Learnable
    - Reinforcement Learning |  |  |  | Patch |  |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| Casanova 等人 [[2020](#bib.bib28)] | 2020 | ICLR | - | - | - | - | 可学习 - 强化学习
    |  |  |  | 补丁 |  |'
- en: '| Dai et al. [[2020](#bib.bib40)] | 2020 | MICCAI | Gradient-based Metrics
    | Gradient | - | - | Latent Space Optimization & Nearest Neighbour Search |  |  |  |
    Slice |  |  Table 2: Methodology summarization of surveyed active learning works.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '| Dai 等人 [[2020](#bib.bib40)] | 2020 | MICCAI | 基于梯度的指标 | 梯度 | - | - | 潜在空间优化
    & 最近邻搜索 |  |  |  | 切片 |  |  表 2: 调查的主动学习方法总结。'
- en: '|  | Year | Venues | Uncertainty | Representativeness | Sampling Strategy |
    SemiSL | SelfSL | ADA | Region | Generative |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '|  | 年份 | 会议 | 不确定性 | 代表性 | 采样策略 | SemiSL | SelfSL | ADA | 区域 | 生成 |'
- en: '| 06em. 06em. | Method | Basic Metrics | Method | Basic Metrics |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 06em. 06em. | 方法 | 基本指标 | 方法 | 基本指标 |'
- en: '| Shen et al. [[2020](#bib.bib165)] | 2020 | MICCAI | Multiple Inferences -
    MC Dropout Performance Estimation - Surrogate | Entropy IoU of all result | Cover-based
    | Cosine Similarity | Hybrid - Multi-round |  |  |  |  |  |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| Shen 等人 [[2020](#bib.bib165)] | 2020 | MICCAI | 多重推断 - MC Dropout 性能估计 -
    替代 | 所有结果的熵 IoU | 覆盖基的 | 余弦相似度 | 混合 - 多轮 |  |  |  |  |  |'
- en: '| Liu et al. [[2020](#bib.bib112)] | 2020 | MICCAI | Performance Estimation
    - Learnable | Loss | - | - | Top-k |  |  |  |  |  |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Liu 等人 [[2020](#bib.bib112)] | 2020 | MICCAI | 性能估计 - 可学习 | 损失 | - | - |
    Top-k |  |  |  |  |  |'
- en: '| Li and Yin [[2020](#bib.bib108)] | 2020 | MICCAI | Multiple Inferences -
    Model Ensemble | Margin | Discrepancy-based | Cosine Similarity | Hybrid - Multi-round
    |  |  |  |  |  |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| Li 和 Yin [[2020](#bib.bib108)] | 2020 | MICCAI | 多重推断 - 模型集成 | 边际 | 基于差异的
    | 余弦相似度 | 混合 - 多轮 |  |  |  |  |  |'
- en: '| Wang et al. [[2020a](#bib.bib187)] | 2020 | MICCAI | - | - | - | - | Learnable
    - Reinforcement Learning |  |  |  |  |  |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等人 [[2020a](#bib.bib187)] | 2020 | MICCAI | - | - | - | - | 可学习 - 强化学习
    |  |  |  |  |  |'
- en: '| Hiasa et al. [[2020](#bib.bib66)] | 2020 | TMI | Multiple Inferences - MC
    Dropout | Variance | Cover-based | Cosine Similarity | Hybrid - Multi-round |  |  |  |
    Slice, Pixel |  |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| Hiasa 等人 [[2020](#bib.bib66)] | 2020 | TMI | 多重推断 - MC Dropout | 方差 | 覆盖基的
    | 余弦相似度 | 混合 - 多轮 |  |  |  | 切片，像素 |  |'
- en: '| Huang et al. [[2020](#bib.bib75)] | 2020 | TMI | Model Disagreement | Hausdorff
    Distance | - | - | Top-k |  |  |  |  |  |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| Huang 等人 [[2020](#bib.bib75)] | 2020 | TMI | 模型不一致性 | Hausdorff 距离 | - |
    - | Top-k |  |  |  |  |  |'
- en: '| Su et al. [[2020](#bib.bib174)] | 2020 | WACV | Single Model | Entropy |
    Discrepancy-based | H-Divergence | Hybrid - Fusion |  |  |  |  |  |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| Su 等人 [[2020](#bib.bib174)] | 2020 | WACV | 单模型 | 熵 | 基于差异的 | H-散度 | 混合 -
    融合 |  |  |  |  |  |'
- en: '| Choi et al. [[2021b](#bib.bib36)] | 2021 | CVPR | Probability of Misclassification
    | - | - | Class-balance |  |  |  |  |  |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| Choi 等人 [[2021b](#bib.bib36)] | 2021 | CVPR | 错误分类的概率 | - | - | 类别平衡 |  |  |  |  |  |'
- en: '| Fu et al. [[2021](#bib.bib49)] | 2021 | CVPR | Adversarial Training | Disagreement
    of Classifiers, margin | Discrepancy-based | H-Divergence | Hybrid - Fusion |  |  |  |  |  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| Fu 等人 [[2021](#bib.bib49)] | 2021 | CVPR | 对抗训练 | 分类器的不一致, 边际 | 基于差异 | H-散度
    | 混合 - 融合 |  |  |  |  |  |'
- en: '| Hou et al. [[2021](#bib.bib68)] | 2021 | CVPR | - | - | Clustering | L2 Distance
    | Diversity - Clustering |  |  |  | Point |  |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| Hou 等人 [[2021](#bib.bib68)] | 2021 | CVPR | - | - | 聚类 | L2 距离 | 多样性 - 聚类
    |  |  |  | 点 |  |'
- en: '| Kim et al. [[2021](#bib.bib92)] | 2021 | CVPR | Performance Estimation -
    Learnable | Rank of Loss | Discrepancy-based | H-Divergence | Top-k |  |  |  |  |  |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| Kim 等人 [[2021](#bib.bib92)] | 2021 | CVPR | 性能估计 - 可学习 | 损失的排名 | 基于差异 | H-散度
    | Top-k |  |  |  |  |  |'
- en: '| Yuan et al. [[2021](#bib.bib217)] | 2021 | CVPR | Adversarial Training |
    Disagreement of Classifiers | - | - | Top-k |  |  |  |  |  |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| Yuan 等人 [[2021](#bib.bib217)] | 2021 | CVPR | 对抗训练 | 分类器的不一致 | - | - | Top-k
    |  |  |  |  |  |'
- en: '| Cai et al. [[2021](#bib.bib25)] | 2021 | CVPR | Single Model | BvSB | - |
    - | Class-balance |  |  |  | Superpixel |  |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| Cai 等人 [[2021](#bib.bib25)] | 2021 | CVPR | 单模型 | BvSB | - | - | 类别平衡 |  |  |  |
    超像素 |  |'
- en: '| Caramalau et al. [[2021](#bib.bib26)] | 2021 | CVPR | Single Model (w/ GNN)
    | Margin | Cover-based | L2 Distance of GCN-augmented Features | Top-k Diversity
    - Farthest-first Traversal |  |  |  |  |  |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| Caramalau 等人 [[2021](#bib.bib26)] | 2021 | CVPR | 单模型（带 GNN） | 边际 | 基于覆盖
    | GCN 增强特征的 L2 距离 | Top-k 多样性 - 最远优先遍历 |  |  |  |  |  |'
- en: '| Prabhu et al. [[2021](#bib.bib144)] | 2021 | ICCV | Single Model | Entropy
    | - | - | Diversity - Clustering |  |  |  |  |  |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| Prabhu 等人 [[2021](#bib.bib144)] | 2021 | ICCV | 单模型 | 熵 | - | - | 多样性 - 聚类
    |  |  |  |  |  |'
- en: '| Ning et al. [[2021](#bib.bib135)] | 2021 | ICCV | - | - | Discrepancy-based
    | L2 Distance | Diversity - Clustering |  |  |  |  |  |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| Ning 等人 [[2021](#bib.bib135)] | 2021 | ICCV | - | - | 基于差异 | L2 距离 | 多样性
    - 聚类 |  |  |  |  |  |'
- en: '| Huang et al. [[2021](#bib.bib74)] | 2021 | ICCV | Performance Estimation
    - Surrogate | Temporal Output Discrepancy | - | - | Top-k | Consistency |  |  |  |  |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| Huang 等人 [[2021](#bib.bib74)] | 2021 | ICCV | 性能估计 - 替代 | 时间输出不一致 | - | -
    | Top-k | 一致性 |  |  |  |  |'
- en: '| Du et al. [[2021](#bib.bib44)] | 2021 | ICCV | - | - | Discrepancy-based
    | Semantic and distinctive scores | Hybrid - Fusion |  |  |  |  |  |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| Du 等人 [[2021](#bib.bib44)] | 2021 | ICCV | - | - | 基于差异 | 语义和区分分数 | 混合 -
    融合 |  |  |  |  |  |'
- en: '| Shin et al. [[2021](#bib.bib166)] | 2021 | ICCV | Model Disagreement | Inequality
    | - | - | Diversity - Clustering | Pseudo-label |  |  | Pixel, Point |  |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| Shin 等人 [[2021](#bib.bib166)] | 2021 | ICCV | 模型不一致 | 不平等 | - | - | 多样性 -
    聚类 | 伪标签 |  |  | 像素, 点 |  |'
- en: '| Wu et al. [[2021a](#bib.bib200)] | 2021 | ICCV | Single Model | Entropy |
    Clustering | Color Difference Surface Variation | Diversity - Clustering Hybrid
    - Fusion |  |  |  | Superpixel |  |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| Wu 等人 [[2021a](#bib.bib200)] | 2021 | ICCV | 单模型 | 熵 | 聚类 | 颜色差异表面变化 | 多样性
    - 聚类 混合 - 融合 |  |  |  | 超像素 |  |'
- en: '| Rangwani et al. [[2021](#bib.bib153)] | 2021 | ICCV | Adversarial Samples
    | KL Divergence | Cover-based - Submodular | KL Divergence Bhattacharya Coefficient
    | Hybrid - Fusion |  |  |  |  |  |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| Rangwani 等人 [[2021](#bib.bib153)] | 2021 | ICCV | 对抗样本 | KL 散度 | 基于覆盖 - 子模量
    | KL 散度 Bhattacharya 系数 | 混合 - 融合 |  |  |  |  |  |'
- en: '| Choi et al. [[2021a](#bib.bib35)] | 2021 | ICCV | Uncertainty-aware Models
    - MDN | Variance | - | - | Top-k |  |  |  |  |  |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| Choi 等人 [[2021a](#bib.bib35)] | 2021 | ICCV | 不确定性感知模型 - MDN | 方差 | - | -
    | Top-k |  |  |  |  |  |'
- en: '| Peng et al. [[2021](#bib.bib141)] | 2021 | ICCV | Model Disagreement | L2
    Distance | Cover-based | Cardinal of Difference Set | Hybrid - Fusion |  |  |  |  |  |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| Peng 等人 [[2021](#bib.bib141)] | 2021 | ICCV | 模型不一致 | L2 距离 | 基于覆盖 | 差异集的基数
    | 混合 - 融合 |  |  |  |  |  |'
- en: '| Liu et al. [[2021b](#bib.bib116)] | 2021 | ICCV | Gradient-based Metrics
    | Influence | - | - | Top-k |  |  |  |  |  |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| Liu 等人 [[2021b](#bib.bib116)] | 2021 | ICCV | 基于梯度的度量 | 影响 | - | - | Top-k
    |  |  |  |  |  |'
- en: '| Zhao et al. [[2021](#bib.bib226)] | 2021 | JBHI | Performance Estimation
    - Surrogate | Dice | - | - | Top-k | Pseudo-label |  |  |  |  |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| Zhao 等人 [[2021](#bib.bib226)] | 2021 | JBHI | 性能估计 - 替代 | Dice | - | - |
    Top-k | 伪标签 |  |  |  |  |'
- en: '| Zhou et al. [[2021b](#bib.bib233)] | 2021 | MedIA | Single Model Data Disagreement
    | Entropy KL Divergence | - | - | Hybrid - Fusion |  |  |  |  |  |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| Zhou 等人 [[2021b](#bib.bib233)] | 2021 | MedIA | 单模型数据不一致 | 熵 KL 散度 | - |
    - | 混合 - 融合 |  |  |  |  |  |'
- en: '| Wu et al. [[2021b](#bib.bib201)] | 2021 | MedIA | Performance Estimation
    - Learnable Data Disagreement | Loss KL Divergence | - | - | Hybrid - Fusion |  |  |  |  |  |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 吴等 [[2021b](#bib.bib201)] | 2021 | MedIA | 性能估计 - 可学习的数据不一致 | 损失 KL 散度 |
    - | - | 混合 - 融合 |  |  |  |  |  |'
- en: '| Zhou et al. [[2021a](#bib.bib230)] | 2021 | MICCAI | Performance Estimation
    - Learnable | Dice | - | - | Top-k |  |  |  |  |  |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| 周等 [[2021a](#bib.bib230)] | 2021 | MICCAI | 性能估计 - 可学习 | Dice | - | - | Top-k
    |  |  |  |  |  |'
- en: '| Xu et al. [[2021](#bib.bib210)] | 2021 | MICCAI | Single Model | Distance
    to Mean Probability | - | - | Top-k | Consistency |  |  | Patch |  |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| Xu 等 [[2021](#bib.bib210)] | 2021 | MICCAI | 单一模型 | 距离到均值概率 | - | - | Top-k
    | 一致性 |  |  | 补丁 |  |'
- en: '| Wang and Yin [[2021](#bib.bib195)] | 2021 | MICCAI | Multiple Inferences
    - Model Ensemble | Variance | Discrepancy-based | Cosine Similarity | Diveristy
    - Clustering Hybrid - Multi-round | Consistency |  |  |  |  |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 王和尹 [[2021](#bib.bib195)] | 2021 | MICCAI | 多重推断 - 模型集成 | 方差 | 基于差异 | 余弦相似度
    | 多样性 - 聚类混合 - 多轮次 | 一致性 |  |  |  |  |'
- en: '| Nguyen et al. [[2021](#bib.bib133)] | 2021 | MIDL | Single Model | Entropy
    | Cover-based | L2 Distance | Diversity - Clustering | Pesudo-label |  |  |  |  |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 阮等 [[2021](#bib.bib133)] | 2021 | MIDL | 单一模型 | 熵 | 覆盖基 | L2 距离 | 多样性 - 聚类
    | 伪标签 |  |  |  |  |'
- en: '| Ash et al. [[2021](#bib.bib7)] | 2021 | NeurIPS | Gradient-based Metrics
    | Fisher Information | - | - | Diversity - Solve Programming Problem |  |  |  |  |  |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| Ash 等 [[2021](#bib.bib7)] | 2021 | NeurIPS | 基于梯度的度量 | Fisher 信息 | - | -
    | 多样性 - 求解编程问题 |  |  |  |  |  |'
- en: '| Kothawade et al. [[2021](#bib.bib98)] | 2021 | NeurIPS | - | - | Cover-based
    - Submodular | Gradient | Top-k |  |  |  |  |  |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| Kothawade 等 [[2021](#bib.bib98)] | 2021 | NeurIPS | - | - | 覆盖基 - 次模组 | 梯度
    | Top-k |  |  |  |  |  |'
- en: '| Citovsky et al. [[2021](#bib.bib37)] | 2021 | NeurIPS | Single Model | Margin
    | - | - | Diversity - Clustering |  |  |  |  |  |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| Citovsky 等 [[2021](#bib.bib37)] | 2021 | NeurIPS | 单一模型 | 边距 | - | - | 多样性
    - 聚类 |  |  |  |  |  |'
- en: '| Nath et al. [[2021](#bib.bib131)] | 2021 | TMI | Multiple Inferences - Model
    Ensemble | Entropy | Discrepancy-based | Mutual Information | Hybrid - Fusion
    |  |  |  |  |  |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| Nath 等 [[2021](#bib.bib131)] | 2021 | TMI | 多重推断 - 模型集成 | 熵 | 基于差异 | 互信息
    | 混合 - 融合 |  |  |  |  |  |'
- en: '| Mahapatra et al. [[2021](#bib.bib123)] | 2021 | TMI | - | - | Saliency Maps
    | Kurtosis Multivariate Radiomics Features Deep Saliency Features | Top-k |  |  |  |  |  |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| Mahapatra 等 [[2021](#bib.bib123)] | 2021 | TMI | - | - | 显著性图 | 峰度多变量放射组学特征深度显著性特征
    | Top-k |  |  |  |  |  |'
- en: '| Chen et al. [[2021](#bib.bib30)] | 2021 | TPAMI | Single Model (in Feature
    Space) | Entropy | - | - | Top-k |  |  |  |  |  |  Table 2: Methodology summarization
    of surveyed active learning works.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '| 陈等 [[2021](#bib.bib30)] | 2021 | TPAMI | 单一模型（在特征空间中） | 熵 | - | - | Top-k
    |  |  |  |  |  | 表 2: 调查的主动学习工作的方法总结。'
- en: '|  | Year | Venues | Uncertainty | Representativeness | Sampling Strategy |
    SemiSL | SelfSL | ADA | Region | Generative |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|  | 年份 | 会议 | 不确定性 | 代表性 | 采样策略 | SemiSL | SelfSL | ADA | 区域 | 生成 |'
- en: '| 06em. 06em. | Method | Basic Metrics | Method | Basic Metrics |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 06em. 06em. | 方法 | 基本度量 | 方法 | 基本度量 |'
- en: '| Kothawade et al. [[2022b](#bib.bib100)] | 2022 | AAAI | - | - | Cover-based
    - Submodular | Gradient | Top-k |  |  |  |  |  |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| Kothawade 等 [[2022b](#bib.bib100)] | 2022 | AAAI | - | - | 覆盖基 - 次模组 | 梯度
    | Top-k |  |  |  |  |  |'
- en: '| Xie et al. [[2022b](#bib.bib204)] | 2022 | AAAI | Single Model | Margin |
    Density-based | Energy | Hybrid - Multi-round |  |  |  |  |  |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 谢等 [[2022b](#bib.bib204)] | 2022 | AAAI | 单一模型 | 边距 | 基于密度 | 能量 | 混合 - 多轮次
    |  |  |  |  |  |'
- en: '| Wang et al. [[2022b](#bib.bib192)] | 2022 | AAAI | Gradient-based Metrics
    | Gradient | - | - | Top-k |  |  |  |  |  |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 王等 [[2022b](#bib.bib192)] | 2022 | AAAI | 基于梯度的度量 | 梯度 | - | - | Top-k |  |  |  |  |  |'
- en: '| Liu et al. [[2022a](#bib.bib111)] | 2022 | arXiv | Multiple Inferences -
    Data Augmentations | Variance | - | - | Top-k | Pseudo-label |  |  | Superpixel
    |  |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 刘等 [[2022a](#bib.bib111)] | 2022 | arXiv | 多重推断 - 数据增强 | 方差 | - | - | Top-k
    | 伪标签 |  |  | 超像素 |  |'
- en: '| Gong et al. [[2022](#bib.bib56)] | 2022 | CVPR | - | - | Discrepancy-based
    | MMD | Learnable - Reinforcement Learning & Meta Learning |  |  |  |  |  |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 龚等 [[2022](#bib.bib56)] | 2022 | CVPR | - | - | 基于差异 | MMD | 可学习 - 强化学习与元学习
    |  |  |  |  |  |'
- en: '| Xie et al. [[2022d](#bib.bib206)] | 2022 | CVPR | Single Model | Margin,
    Gradient | - | - | Top-k |  |  |  |  |  |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 谢等 [[2022d](#bib.bib206)] | 2022 | CVPR | 单一模型 | 边距，梯度 | - | - | Top-k |  |  |  |  |  |'
- en: '| Zhang et al. [[2022a](#bib.bib222)] | 2022 | CVPR | Single Model Adversarial
    Samples | Entropy KL Divergence | Density-based | Mean Cosine Similarity of KNN
    | Hybrid - Equal Split | Consistency |  |  |  |  |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 张等 [[2022a](#bib.bib222)] | 2022 | CVPR | 单一模型对抗样本 | 熵 KL 散度 | 基于密度 | KNN
    的平均余弦相似度 | 混合 - 等分 | 一致性 |  |  |  |  |'
- en: '| Zhang et al. [[2022b](#bib.bib224)] | 2022 | CVPR | Single Model | Entropy
    | - | - | Top-k |  |  |  |  |  |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| Zhang 等人 [[2022b](#bib.bib224)] | 2022 | CVPR | 单模型 | 熵 | - | - | Top-k |  |  |  |  |  |'
- en: '| Parvaneh et al. [[2022](#bib.bib139)] | 2022 | CVPR | Data Disagreement |
    Inequality | - | - | Diversity - Clustering |  |  |  |  |  |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| Parvaneh 等人 [[2022](#bib.bib139)] | 2022 | CVPR | 数据不一致 | 不平等 | - | - | 多样性
    - 聚类 |  |  |  |  |  |'
- en: '| Xie et al. [[2022a](#bib.bib203)] | 2022 | CVPR | Single Model | Entropy
    | - | - | Top-k |  |  |  | Patch |  |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| Xie 等人 [[2022a](#bib.bib203)] | 2022 | CVPR | 单模型 | 熵 | - | - | Top-k |  |  |  |
    补丁 |  |'
- en: '| Quan et al. [[2022](#bib.bib149)] | 2022 | CVPR | - | - | Cover-based | Cosine
    Similarity | Top-k |  |  |  |  |  |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| Quan 等人 [[2022](#bib.bib149)] | 2022 | CVPR | - | - | 覆盖基 | 余弦相似度 | Top-k
    |  |  |  |  |  |'
- en: '| Wu et al. [[2022a](#bib.bib198)] | 2022 | CVPR | Single Model | Entropy |
    Discrepancy-based | Cosine Similarity | Class-balance |  |  |  |  |  |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| Wu 等人 [[2022a](#bib.bib198)] | 2022 | CVPR | 单模型 | 熵 | 基于差异的 | 余弦相似度 | 类别平衡
    |  |  |  |  |  |'
- en: '| Wang et al. [[2022c](#bib.bib193)] | 2022 | ECCV | - | - | Density-based
    | KNN Density | Diversity - Clustering w/ Regularization | Consistency |  |  |  |  |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等人 [[2022c](#bib.bib193)] | 2022 | ECCV | - | - | 基于密度的 | KNN密度 | 多样性
    - 带正则化的聚类 | 一致性 |  |  |  |  |'
- en: '| Kothawade et al. [[2022a](#bib.bib99)] | 2022 | ECCV | - | - | Cover-based
    - Submodular | Cosine Similarity | Top-k |  |  |  |  |  |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| Kothawade 等人 [[2022a](#bib.bib99)] | 2022 | ECCV | - | - | 覆盖基 - 子模 | 余弦相似度
    | Top-k |  |  |  |  |  |'
- en: '| Chen et al. [[2022b](#bib.bib34)] | 2022 | ECCV | Gradient-based Metrics
    | Gradient | - | - | Top-k |  |  |  |  |  |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人 [[2022b](#bib.bib34)] | 2022 | ECCV | 基于梯度的指标 | 梯度 | - | - | Top-k
    |  |  |  |  |  |'
- en: '| Hu et al. [[2022](#bib.bib71)] | 2022 | ECCV | Multiple Inferences - Data
    Augmentations Data Disagreement | Entropy KL Divergence | - | - | Hybrid - Multi-round
    | Pseudo-label |  |  | Superpixel |  |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| Hu 等人 [[2022](#bib.bib71)] | 2022 | ECCV | 多重推断 - 数据增强 数据不一致 | 熵KL散度 | -
    | - | 混合 - 多轮 | 伪标签 |  |  | 超像素 |  |'
- en: '| Hwang et al. [[2022](#bib.bib76)] | 2022 | ECCV | Single Model | Margin |
    Discrepancy-based | MMD | Hybrid - Multi-round | Pseudo-label |  |  |  |  |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| Hwang 等人 [[2022](#bib.bib76)] | 2022 | ECCV | 单模型 | 边际 | 基于差异的 | MMD | 混合
    - 多轮 | 伪标签 |  |  |  |  |'
- en: '| Yi et al. [[2022](#bib.bib213)] | 2022 | ECCV | Single Model | Least Confidence
    | Self-supervised Learning | Loss of Pretext Task | Hybrid - Multi-round |  |  |  |  |  |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| Yi 等人 [[2022](#bib.bib213)] | 2022 | ECCV | 单模型 | 最小置信度 | 自监督学习 | 预训练任务的损失
    | 混合 - 多轮 |  |  |  |  |  |'
- en: '| Wu et al. [[2022b](#bib.bib199)] | 2022 | ECCV | Single Model | Entropy |
    Density-based | GMM | Hybrid - Multi-round |  |  |  | Superpixel |  |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| Wu 等人 [[2022b](#bib.bib199)] | 2022 | ECCV | 单模型 | 熵 | 基于密度的 | GMM | 混合 -
    多轮 |  |  |  | 超像素 |  |'
- en: '| Mahmood et al. [[2022](#bib.bib124)] | 2022 | ICLR | - | - | Discrepancy-based
    | Wasserstein Distance | Diversity - Solve Programming Problem |  |  |  |  |  |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| Mahmood 等人 [[2022](#bib.bib124)] | 2022 | ICLR | - | - | 基于差异的 | Wasserstein距离
    | 多样性 - 求解编程问题 |  |  |  |  |  |'
- en: '| Hacohen et al. [[2022](#bib.bib61)] | 2022 | ICML | - | - | Density-based
    | Inverse Average Distance to KNN samples | Diversity - Clustering |  |  |  |  |  |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| Hacohen 等人 [[2022](#bib.bib61)] | 2022 | ICML | - | - | 基于密度的 | 逆平均距离到KNN样本
    | 多样性 - 聚类 |  |  |  |  |  |'
- en: '| Jin et al. [[2022a](#bib.bib82)] | 2022 | Information Sciences | - | - |
    Clustering | Cosine Similarity | Diversity - Clustering |  |  |  |  |  |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| Jin 等人 [[2022a](#bib.bib82)] | 2022 | 信息科学 | - | - | 聚类 | 余弦相似度 | 多样性 - 聚类
    |  |  |  |  |  |'
- en: '| Jin et al. [[2022c](#bib.bib84)] | 2022 | KBS | - | - | Clustering | L2 Distance
    | Class-balance |  |  |  |  |  |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| Jin 等人 [[2022c](#bib.bib84)] | 2022 | KBS | - | - | 聚类 | L2距离 | 类别平衡 |  |  |  |  |  |'
- en: '| Jin et al. [[2022b](#bib.bib83)] | 2022 | KBS | - | - | Clustering | L2 Distance
    | Diversity - Farthest-first Traversal |  |  |  |  |  |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| Jin 等人 [[2022b](#bib.bib83)] | 2022 | KBS | - | - | 聚类 | L2距离 | 多样性 - 最远优先遍历
    |  |  |  |  |  |'
- en: '| Dai et al. [[2022](#bib.bib39)] | 2022 | MedIA | Gradient-based Metrics |
    Gradient | - | - | Latent Space Optimization & Nearest Neighbour Search |  |  |  |
    Slice |  |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| Dai 等人 [[2022](#bib.bib39)] | 2022 | MedIA | 基于梯度的指标 | 梯度 | - | - | 潜在空间优化与最近邻搜索
    |  |  |  | 切片 |  |'
- en: '| Zhou et al. [[2022](#bib.bib231)] | 2022 | MedIA | Performance Estimation
    - Learnable | Dice | - | - | Top-k |  |  |  |  |  |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| Zhou 等人 [[2022](#bib.bib231)] | 2022 | MedIA | 性能估计 - 可学习 | Dice | - | -
    | Top-k |  |  |  |  |  |'
- en: '| Atzeni et al. [[2022](#bib.bib9)] | 2022 | MedIA | Performance Estimation
    - Surrogate | Dice | - | - | Top-k |  |  |  |  |  |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| Atzeni 等人 [[2022](#bib.bib9)] | 2022 | MedIA | 性能估计 - 代理 | Dice | - | - |
    Top-k |  |  |  |  |  |'
- en: '| Nath et al. [[2022](#bib.bib132)] | 2022 | MICCAI | Multiple Inferences -
    MC Dropout | Entropy | - | - | Top-k | Pseudo-label |  |  |  |  |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| Nath 等人 [[2022](#bib.bib132)] | 2022 | MICCAI | 多重推断 - MC Dropout | 熵 | -
    | - | Top-k | 伪标签 |  |  |  |  |'
- en: '| Balaram et al. [[2022](#bib.bib14)] | 2022 | MICCAI | Uncertainty-aware Model
    - EDL | Entropy | - | - | Top-k | Pseudo-label & Consistency |  |  |  |  |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| Balaram 等 [[2022](#bib.bib14)] | 2022 | MICCAI | 关注不确定性的模型 - EDL | 熵 | -
    | - | Top-k | 伪标签 & 一致性 |  |  |  |  |'
- en: '| Wu et al. [[2022c](#bib.bib202)] | 2022 | MICCAI | - | - | Cover-based |
    Cosine Similarity | Diversity - Clustering |  |  |  | Slice |  |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| Wu 等 [[2022c](#bib.bib202)] | 2022 | MICCAI | - | - | 基于覆盖 | 余弦相似度 | 多样性
    - 聚类 |  |  |  | 切片 |  |'
- en: '| Bai et al. [[2022](#bib.bib10)] | 2022 | MICCAI | Model Disagreement | Entropy-weighted
    Dice Distance | - | - | Hybrid - Fusion | Pseudo-label |  |  |  |  |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| Bai 等 [[2022](#bib.bib10)] | 2022 | MICCAI | 模型不一致 | 熵加权的 Dice 距离 | - | -
    | 混合 - 融合 | 伪标签 |  |  |  |  |'
- en: '| Kothawade et al. [[2022c](#bib.bib101)] | 2022 | MICCAIW | - | - | Cover-based
    - Submodular | Gradient | Top-k |  |  |  |  |  |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| Kothawade 等 [[2022c](#bib.bib101)] | 2022 | MICCAIW | - | - | 基于覆盖 - 次模 |
    梯度 | Top-k |  |  |  |  |  |'
- en: '| Yehuda et al. [[2022](#bib.bib212)] | 2022 | NeurIPS | - | - | Cover-based
    | L2 Distance | Graph-based Algorithm |  |  |  |  |  |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| Yehuda 等 [[2022](#bib.bib212)] | 2022 | NeurIPS | - | - | 基于覆盖 | L2 距离 |
    基于图的算法 |  |  |  |  |  |'
- en: '| Mahapatra et al. [[2022](#bib.bib122)] | 2022 | TMI | - | - | Saliency Maps
    | Graph-based Methods | Top-k |  |  |  |  |  |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| Mahapatra 等 [[2022](#bib.bib122)] | 2022 | TMI | - | - | 显著性图 | 基于图的方法 |
    Top-k |  |  |  |  |  |'
- en: '| Li et al. [[2022](#bib.bib109)] | 2022 | TMI | Curriculum Learning & Noisy
    Sample Detection | - | - | Top-k | Pseudo-label |  |  |  |  |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| Li 等 [[2022](#bib.bib109)] | 2022 | TMI | 课程学习 & 噪声样本检测 | - | - | Top-k |
    伪标签 |  |  |  |  |'
- en: '| Bengar et al. [[2022](#bib.bib17)] | 2022 | WACV | Single Model | Entropy
    | - | - | Class-balance |  |  |  |  |  |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| Bengar 等 [[2022](#bib.bib17)] | 2022 | WACV | 单一模型 | 熵 | - | - | 类别平衡 |  |  |  |  |  |'
- en: '| Xie et al. [[2023b](#bib.bib208)] | 2023 | CVPR | - | - | Discrepancy-based
    | Wasserstein Distance | Latent Space Optimization & Nearest Neighbour Search
    |  |  |  |  |  |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| Xie 等 [[2023b](#bib.bib208)] | 2023 | CVPR | - | - | 基于差异 | Wasserstein 距离
    | 潜在空间优化 & 最近邻搜索 |  |  |  |  |  |'
- en: '| Lyu et al. [[2023](#bib.bib119)] | 2023 | CVPR | Data Disagreement | Cross
    Entropy, Variance | - | - | Hybrid - Fusion | Pseudo-label |  |  | Box |  |  Table
    2: Methodology summarization of surveyed active learning works.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '| Lyu 等 [[2023](#bib.bib119)] | 2023 | CVPR | 数据不一致 | 交叉熵，方差 | - | - | 混合 -
    融合 | 伪标签 |  |  | 框 |  |  表 2: 调查的主动学习方法总结。'
- en: '|  | Year | Venues | Uncertainty | Representativeness | Sampling Strategy |
    SemiSL | SelfSL | ADA | Region | Generative |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '|  | 年 | 会议 | 不确定性 | 代表性 | 采样策略 | 半监督学习 | 自监督学习 | ADA | 区域 | 生成 |'
- en: '| 06em. 06em. | Method | Basic Metrics | Method | Basic Metrics |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 06em. 06em. | 方法 | 基本指标 | 方法 | 基本指标 |'
- en: '| Yuan et al. [[2023](#bib.bib215)] | 2023 | CVPR | Single Model | Entropy
    | Discrepancy-based | H-Divergence | Diversity - Clustering |  |  |  |  |  |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| Yuan 等 [[2023](#bib.bib215)] | 2023 | CVPR | 单一模型 | 熵 | 基于差异 | H-散度 | 多样性
    - 聚类 |  |  |  |  |  |'
- en: '| Huang et al. [[2023](#bib.bib72)] | 2023 | CVPR | Single Model | IoU Confidence
    | - | - | Diversity - Clustering |  |  |  |  |  |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| Huang 等 [[2023](#bib.bib72)] | 2023 | CVPR | 单一模型 | IoU 置信度 | - | - | 多样性
    - 聚类 |  |  |  |  |  |'
- en: '| Jung et al. [[2023](#bib.bib86)] | 2023 | ICLR | Multiple Inferences - Model
    Ensemble | Entropy, Variance Ratio, BALD, Margin | - | - | Top-k |  |  |  |  |  |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| Jung 等 [[2023](#bib.bib86)] | 2023 | ICLR | 多重推断 - 模型集成 | 熵，方差比率，BALD，边际
    | - | - | Top-k |  |  |  |  |  |'
- en: '| Xie et al. [[2022c](#bib.bib205)] | 2023 | ICLR | Uncertainty-aware Model
    - EDL | Mutual Information & Entropy Expectation of Dirichlet Distribution | -
    | - | Hybrid - Multi-round |  |  |  |  |  |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| Xie 等 [[2022c](#bib.bib205)] | 2023 | ICLR | 关注不确定性的模型 - EDL | 互信息 & Dirichlet
    分布的熵期望 | - | - | 混合 - 多轮 |  |  |  |  |  |'
- en: '| Kim et al. [[2023](#bib.bib91)] | 2023 | ICCV | Single Model | BvSB | - |
    - | Class-balance |  |  |  | Superpixel |  |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| Kim 等 [[2023](#bib.bib91)] | 2023 | ICCV | 单一模型 | BvSB | - | - | 类别平衡 |  |  |  |
    超像素 |  |'
- en: '| Park et al. [[2023](#bib.bib138)] | 2023 | ICLR | Uncertainty-aware Model
    - EDL | Mutual Information | - | - | Top-k |  |  |  |  |  |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| Park 等 [[2023](#bib.bib138)] | 2023 | ICLR | 关注不确定性的模型 - EDL | 互信息 | - |
    - | Top-k |  |  |  |  |  |'
- en: '| Sun et al. [[2023](#bib.bib175)] | 2023 | ICLR | Uncertainty-aware Model
    - EDL | Evidential Uncertainty | Density-based | Inverse Average Distance | Hybrid
    Fusion |  |  |  |  |  |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| Sun 等 [[2023](#bib.bib175)] | 2023 | ICLR | 关注不确定性的模型 - EDL | 证据不确定性 | 基于密度
    | 逆平均距离 | 混合融合 |  |  |  |  |  |'
- en: '| Sadafi et al. [[2023](#bib.bib158)] | 2023 | ISBI | Multiple Inferences -
    MC Dropout Model Disagreement | Variance Inequality | - | - | Hybrid - Fusion
    |  |  |  |  |  |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| Sadafi 等 [[2023](#bib.bib158)] | 2023 | ISBI | 多重推断 - MC Dropout 模型不一致 |
    方差不等式 | - | - | 混合 - 融合 |  |  |  |  |  |'
- en: '| Chen et al. [[2023](#bib.bib31)] | 2023 | MIDL | - | - | Loss of Self-supervised
    Pretext Tasks | Diversity - Clustering |  |  |  |  |  |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| Chen等人 [[2023](#bib.bib31)] | 2023 | MIDL | - | - | 自监督预训练任务的损失 | 多样性 - 聚类
    |  |  |  |  |  |'
- en: '| Lou et al. [[2023](#bib.bib118)] | 2023 | TMI | - | - | Clustering | Consistency
    | Diversity - Clustering | Pseudo-label |  |  |  |  |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| Lou等人 [[2023](#bib.bib118)] | 2023 | TMI | - | - | 聚类 | 一致性 | 多样性 - 聚类 |
    伪标签 |  |  |  |  |'
- en: '| Du et al. [[2022](#bib.bib43)] | 2023 | TPAMI | - | - | Discrepancy-based
    | Semantic and distinctive scores | Hybrid - Fusion |  |  |  |  |  |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| Du等人 [[2022](#bib.bib43)] | 2023 | TPAMI | - | - | 基于差异性 | 语义和独特性评分 | 混合
    - 融合 |  |  |  |  |  |'
- en: '| Wan et al. [[2023](#bib.bib185)] | 2023 | TPAMI | Adversarial Training |
    Disagreement of Classifiers | - | - | Top-k |  |  |  |  |  |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| Wan等人 [[2023](#bib.bib185)] | 2023 | TPAMI | 对抗训练 | 分类器的不一致性 | - | - | Top-k
    |  |  |  |  |  |'
- en: '4.1 Semi-supervised Learning: Utilizing Unlabeled Data'
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 半监督学习：利用未标记数据
- en: 'Semi-supervised learning [Chen et al., [2022a](#bib.bib33)] aims to boost performance
    by utilizing unlabeled data upon supervised training. AL and semi-supervised learning
    complements each other: AL focuses on constructing an optimal labeled dataset.
    However, massive unlabeled samples are discarded during model training. Therefore,
    we can further leverage unlabeled data to train the deep model. By integrating
    the strengths of both AL and semi-supervised learning, annotation efficiency can
    be further improved. This section will introduce the integration of AL and semi-supervised
    learning from pseudo-labeling and consistency regularization.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习[Chen等人，[2022a](#bib.bib33)]旨在通过利用未标记数据来提高性能。主动学习（AL）和半监督学习相辅相成：主动学习专注于构建最优的标记数据集。然而，大量未标记样本在模型训练过程中被丢弃。因此，我们可以进一步利用未标记数据来训练深度模型。通过结合AL和半监督学习的优势，可以进一步提高标注效率。本节将介绍伪标签和一致性正则化在AL与半监督学习中的结合。
- en: 4.1.1 Pseudo-Labeling
  id: totrans-271
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 伪标签
- en: Pseudo-labeling [Lee et al., [2013](#bib.bib105)] is one of the most straightforward
    methods in semi-supervised learning. It uses the model’s predictions of unlabeled
    data as pseudo-labels and combines them with labeled data for supervised training.
    Although it’s possible to assign pseudo-labels to all unlabeled samples for training,
    it may introduce noise. To mitigate this, Wang et al. [[2017](#bib.bib188)] proposed
    cost-effective active learning (CEAL), integrating pseudo-labeling with uncertainty-based
    AL. Specifically, CEAL sent the most uncertain samples for expert annotation and
    assigned pseudo-labels to the most confident samples. Many subsequent works have
    built upon the ideas of CEAL. In point cloud segmentation, both Hu et al. [[2022](#bib.bib71)]
    and Liu et al. [[2022a](#bib.bib111)] assigned pseudo-labels of the most certain
    regions. In medical image segmentation, Zhao et al. [[2021](#bib.bib226)] refined
    the pseudo-labels with dense conditional random fields. Additionally, Li et al.
    [[2022](#bib.bib109)] proposed a new approach for selecting samples for oracle
    annotation and pseudo-label. Specifically, they employed curriculum learning to
    categorize all samples into hard and easy. Hard samples were all sent for oracle
    annotation. For the easy samples, they evaluated the presence of label noise based
    on the training loss. Easy samples with low training loss were used for pseudo-labels
    to assist training, whereas easy samples with high loss were considered noisy
    and excluded from training.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 伪标签[Lee等人，[2013](#bib.bib105)]是半监督学习中最简单的方法之一。它利用模型对未标记数据的预测作为伪标签，并将这些伪标签与标记数据结合进行监督训练。虽然可以将伪标签分配给所有未标记样本进行训练，但这可能会引入噪声。为缓解这一问题，Wang等人
    [[2017](#bib.bib188)] 提出了成本效益高的主动学习（CEAL），将伪标签与基于不确定性的主动学习相结合。具体来说，CEAL 将最不确定的样本送交专家注释，并将伪标签分配给最自信的样本。许多后续工作在CEAL的基础上进行了扩展。在点云分割中，Hu等人
    [[2022](#bib.bib71)] 和 Liu等人 [[2022a](#bib.bib111)] 将伪标签分配给最确定的区域。在医学图像分割中，Zhao等人
    [[2021](#bib.bib226)] 利用稠密条件随机场改进了伪标签。此外，Li等人 [[2022](#bib.bib109)] 提出了一个新的样本选择方法用于oracle注释和伪标签。具体来说，他们采用了课程学习将所有样本分类为困难样本和简单样本。困难样本全部送交oracle注释。对于简单样本，他们基于训练损失评估标签噪声的存在。低训练损失的简单样本被用于伪标签以辅助训练，而高损失的简单样本被认为是噪声样本并从训练中排除。
- en: 4.1.2 Consistency Regularization
  id: totrans-273
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2 一致性正则化
- en: Consistency regularization is also widely applied in semi-supervised learning.
    Its basic idea is to enforce consistent outputs under perturbations of input data
    or model parameters. Maximizing consistency serves as an unsupervised loss for
    unlabeled samples. Consistency regularization helps improve the robustness and
    reduce overfitting of the model, thus enhancing model performance. Gao et al.
    [[2020](#bib.bib53)] introduced a semi-supervised active learning framework. Consistency
    here was used for both semi-supervised training and evaluating informativeness.
    In this framework, samples are fed into the model multiple times with random augmentations.
    The consistency loss of unlabeled samples was implemented by minimizing the variance
    between multiple outputs. They further selected less consistent samples for annotation.
    Results showed that combining AL with semi-supervised learning significantly improves
    performance.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性正则化在半监督学习中也被广泛应用。其基本思想是在输入数据或模型参数扰动下强制输出的一致性。最大化一致性作为无监督损失用于未标记样本。一致性正则化有助于提高模型的鲁棒性和减少过拟合，从而增强模型性能。Gao
    等人[[2020](#bib.bib53)]提出了一个半监督主动学习框架。在这个框架中，一致性既用于半监督训练，也用于评估信息量。在此框架下，样本通过随机增强多次输入模型。未标记样本的一致性损失通过最小化多个输出之间的方差来实现。他们进一步选择了一致性较差的样本进行标注。结果显示，将主动学习与半监督学习结合显著提高了性能。
- en: Additionally, some works integrated existing consistency-based semi-supervised
    methods into the training process of AL. Huang et al. [[2021](#bib.bib74)] combined
    their proposed COD with MeanTeacher [Tarvainen and Valpola, [2017](#bib.bib179)],
    demonstrating superior performance. Both TypiClust [Hacohen et al., [2022](#bib.bib61)]
    and ProbCover Yehuda et al. [[2022](#bib.bib212)] found that their methods outperformed
    other active learning baselines in low-budget scenarios when combined with FlexMatch
    [Zhang et al., [2021](#bib.bib220)]. Wang et al. [[2022c](#bib.bib193)] combined
    density-based AL with different existing semi-supervised methods. Results showed
    that the proposed method outperforms other active learning methods and excels
    in semi-supervised learning. Zhang et al. [[2022a](#bib.bib222)] combined AL with
    both pseudo-labeling and consistency. The unlabelled images first underwent both
    strong and weak data augmentations. When the confidence level of the weakly augmented
    images exceeded a certain threshold, they used these samples for semi-supervised
    training. Specifically, predictions of the weakly augmented images were assigned
    as pseudo-labels, and the outputs of the strongly augmented images were forced
    to be consistent with the pseudo-labels. However, when the confidence level was
    lower than the threshold, they used these samples for AL. A balanced uncertainty
    selector and an adversarial instability selector were used to select samples for
    oracle annotation. They validated the effectiveness of their proposed method in
    grading metastatic epidural spinal cord compression with MRI images.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些研究将现有的一致性基础半监督方法整合到主动学习的训练过程中。Huang 等人[[2021](#bib.bib74)]将他们提出的 COD 与
    MeanTeacher [Tarvainen 和 Valpola, [2017](#bib.bib179)] 结合，展示了卓越的性能。TypiClust [Hacohen
    等人, [2022](#bib.bib61)] 和 ProbCover Yehuda 等人[[2022](#bib.bib212)]发现，他们的方法在低预算场景下结合
    FlexMatch [Zhang 等人, [2021](#bib.bib220)] 超过了其他主动学习基线。Wang 等人[[2022c](#bib.bib193)]将基于密度的主动学习与不同的现有半监督方法结合。结果表明，提出的方法优于其他主动学习方法，并在半监督学习中表现突出。Zhang
    等人[[2022a](#bib.bib222)]将主动学习与伪标签和一致性结合。未标记图像首先经过强增强和弱增强。当弱增强图像的置信度超过一定阈值时，他们将这些样本用于半监督训练。具体而言，弱增强图像的预测被指定为伪标签，强增强图像的输出被强制与伪标签一致。然而，当置信度低于阈值时，他们将这些样本用于主动学习。使用了平衡不确定性选择器和对抗性不稳定选择器来选择样本进行标注。他们验证了所提方法在使用
    MRI 图像对转移性硬膜外脊髓压迫进行分级的有效性。
- en: '4.2 Self-supervised Learning: Utilizing Pre-trained Model'
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 自监督学习：利用预训练模型
- en: In the last section, we discussed the integration of AL and semi-supervised
    learning, which aimed to utilize unlabeled data for better performance. However,
    the effectiveness of this approach is constrained by the size of dataset. This
    limitation is particularly evident in medical image analysis, where datasets are
    often relatively small. To further improve annotation efficiency, AL can be combined
    with self-supervised learning. Self-supervised learning [Liu et al., [2021a](#bib.bib115)]
    trained the model with the supervision from the data itself, thus allowing pre-training
    on a large dataset. After finetuning on a few randomly selected labeled samples,
    the self-supervised pre-trained models have been shown to achieve impressive performance
    [Chen et al., [2020](#bib.bib32)]. Besides, these models can also provide good
    initialization, thereby solving the cold-start problem in AL. In this section,
    we will first introduce how self-supervised models solve the cold-start problem
    in AL and then explore different ways of integrating active learning with self-supervised
    learning.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了主动学习与半监督学习的结合，旨在利用未标注的数据以提高性能。然而，这种方法的有效性受数据集大小的限制。这种限制在医学图像分析中尤为明显，因为数据集通常相对较小。为了进一步提高标注效率，主动学习可以与自监督学习相结合。自监督学习[Liu
    et al., [2021a](#bib.bib115)]通过数据本身的监督来训练模型，从而允许在大型数据集上进行预训练。在对少量随机选择的标注样本进行微调后，自监督预训练模型已显示出令人印象深刻的性能[Chen
    et al., [2020](#bib.bib32)]。此外，这些模型还可以提供良好的初始化，从而解决主动学习中的冷启动问题。在本节中，我们将首先介绍自监督模型如何解决主动学习中的冷启动问题，然后探索主动学习与自监督学习的不同结合方式。
- en: 4.2.1 Cold-start Problem in Active Learning
  id: totrans-278
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1 主动学习中的冷启动问题
- en: Current AL methods usually require several initial labeled samples to train
    an initial model and ensure reliable informativeness metrics. However, when the
    initial labeled set is small or even absent, the performance of these AL methods
    drops dramatically, sometimes even worse than random sampling [Chen et al., [2023](#bib.bib31),
    Hacohen et al., [2022](#bib.bib61), Yehuda et al., [2022](#bib.bib212)]. This
    is known as the cold-start problem in AL, which is very common in AL. In their
    semi-supervised active learning framework, Gao et al. [[2020](#bib.bib53)] found
    that performance suffered with a smaller labeling budget compared to a larger
    one when initial labels were randomly selected. Bengar et al. [[2021](#bib.bib18)]
    first pre-trained the model with self-supervised learning and then employed some
    AL baselines to select samples for labeling and finetuning. Results showed the
    performance of AL baselines tends to be worse than the random selection under
    the low-budget scenario. Additionally, Xie et al. [[2023a](#bib.bib207)] discovered
    that CoreSet based on self-supervised features is inferior to random sampling.
    Tackling the cold-start problem is vital for improving the efficacy of AL, especially
    when the annotation budget is limited. Moreover, when constructing a new dataset
    from scratch, employing cold-start AL strategies can offer a good initialization,
    thereby boosting performance.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 目前的主动学习方法通常需要若干初始标注样本来训练初始模型并确保信息度量的可靠性。然而，当初始标注集较小甚至不存在时，这些主动学习方法的性能会急剧下降，有时甚至比随机采样还要差[Chen
    et al., [2023](#bib.bib31), Hacohen et al., [2022](#bib.bib61), Yehuda et al.,
    [2022](#bib.bib212)]。这被称为主动学习中的冷启动问题，在主动学习中非常常见。在他们的半监督主动学习框架中，Gao et al. [[2020](#bib.bib53)]发现，当初始标签是随机选择时，较小的标注预算相比于较大的标注预算，性能会受到影响。Bengar
    et al. [[2021](#bib.bib18)]首先通过自监督学习预训练模型，然后使用一些主动学习基准选择样本进行标注和微调。结果显示，在低预算情况下，主动学习基准的性能往往比随机选择更差。此外，Xie
    et al. [[2023a](#bib.bib207)]发现基于自监督特征的CoreSet不如随机采样。解决冷启动问题对提高主动学习的效率至关重要，尤其是当标注预算有限时。此外，在从头开始构建新数据集时，采用冷启动主动学习策略可以提供良好的初始化，从而提升性能。
- en: A key solution to the cold-start problem in AL lies in selecting the optimal
    set of initial labeled samples. Since no initial labels are available, cold-start
    AL requires different strategies than existing AL methods. Self-supervised pre-trained
    models offer a good initialization for effectively tackling the cold-start problem
    in AL. In natural language processing, Yuan et al. [[2020](#bib.bib216)] was the
    first to introduce the cold-start problem in AL. They employed self-supervised
    pre-trained models to address this issue. Yi et al. [[2022](#bib.bib213)] chose
    initial samples based on the loss of self-supervised pretext tasks, showing significant
    advantages over random sampling. Pourahmadi et al. [[2021](#bib.bib143)] proposed
    a straightforward baseline for cold-start active learning. They first performed
    k-Means clustering on existing off-the-shelf self-supervised features, then selected
    cluster centers for annotation. Results indicated that this baseline is very effective
    when the annotation budget is limited. TypiClust [Hacohen et al., [2022](#bib.bib61)]
    found that when the annotation budget is low, querying typical samples is more
    beneficial, whereas when the budget is high, querying hard samples is more beneficial.
    This conclusion suggested different strategies with uncertainty methods for cold-start
    AL. Thus, based on self-supervised features, TypiClust selected samples from high-density
    areas of each k-Means cluster. Yehuda et al. [[2022](#bib.bib212)] employed a
    graph-based greedy algorithm to select the optimal initial samples based on self-supervised
    features. Chen et al. [[2023](#bib.bib31)] found that active learning also suffers
    from a cold-start problem in medical image analysis. The issues arose mainly because
    AL is often biased towards specific classes, resulting in class imbalance. Additionally,
    the models struggled to detect anomalies when only a limited number of initially
    labeled samples exist. They combined clustering and the loss of contrastive learning
    to address the cold-start problem. In CT segmentation, Nath et al. [[2022](#bib.bib132)]
    designed new pretext tasks for self-supervised pre-training. The model was trained
    to learn the threshold segmentation by an abdominal soft-tissue window. Results
    indicated that the proposed method significantly outperforms random sampling in
    selecting initial samples.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在主动学习（AL）中的冷启动问题的关键解决方案在于选择最佳的初始标记样本集。由于没有初始标签，冷启动AL需要不同于现有AL方法的策略。自监督预训练模型为有效解决AL中的冷启动问题提供了良好的初始化。在自然语言处理领域，Yuan等人[[2020](#bib.bib216)]首次引入了AL中的冷启动问题。他们采用了自监督预训练模型来解决这个问题。Yi等人[[2022](#bib.bib213)]基于自监督预训练任务的损失选择了初始样本，显示出相较于随机采样的显著优势。Pourahmadi等人[[2021](#bib.bib143)]提出了一个简单的冷启动主动学习基线。他们首先对现有的自监督特征进行了k-Means聚类，然后选择了聚类中心进行标注。结果表明，当标注预算有限时，这一基线非常有效。TypiClust
    [Hacohen等人，[2022](#bib.bib61)]发现，当标注预算低时，查询典型样本更有益，而当预算高时，查询难样本更有益。这一结论建议在冷启动AL中采用不同的不确定性方法策略。因此，基于自监督特征，TypiClust从每个k-Means簇的高密度区域中选择样本。Yehuda等人[[2022](#bib.bib212)]采用基于图的贪婪算法，根据自监督特征选择最佳初始样本。Chen等人[[2023](#bib.bib31)]发现主动学习在医学图像分析中也遭遇了冷启动问题。这些问题主要是因为AL通常倾向于特定类别，导致类别不平衡。此外，当仅有有限数量的初始标记样本存在时，模型难以检测异常。他们结合了聚类和对比学习的损失来解决冷启动问题。在CT分割中，Nath等人[[2022](#bib.bib132)]设计了新的自监督预训练任务。该模型通过腹部软组织窗口学习阈值分割。结果表明，该方法在选择初始样本方面显著优于随机采样。
- en: Additionally, some works have attempted to use fully supervised pre-trained
    models to address the cold-start problem. Zhou et al. [[2017](#bib.bib232)] and
    their subsequent work [Zhou et al., [2021b](#bib.bib233)] used ImageNet pre-trained
    models to select samples for labeling from completely unlabeled datasets. They
    combined entropy and disagreement as informativeness metrics, where the disagreement
    was the KL divergence of prediction probabilities between different patches of
    the same sample. They also introduced randomness to balance exploration and exploitation.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些研究尝试使用完全监督的预训练模型来解决冷启动问题。Zhou等人[[2017](#bib.bib232)]及其后续研究[Zhou等人，[2021b](#bib.bib233)]使用了ImageNet预训练模型，从完全未标记的数据集中选择样本进行标注。他们将熵和不一致性作为信息量度，其中不一致性是不同补丁之间预测概率的KL散度。他们还引入了随机性来平衡探索与开发。
- en: 4.2.2 Combination of Active Learning and Self-supervised Learning
  id: totrans-282
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2 主动学习与自监督学习的结合
- en: 'Features: The simplest way to integrate AL with self-supervised learning is
    by leveraging the high-quality pre-trained features that effectively capture data
    similarities. In point cloud segmentation, Hou et al. [[2021](#bib.bib68)] performed
    k-Means clustering on the self-supervised features, then selected the points of
    cluster centers for annotation. They improved the annotation efficiency in indoor
    scene point cloud segmentation.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 特征：将主动学习与自监督学习结合的最简单方法是利用高质量的预训练特征，这些特征有效地捕捉数据相似性。在点云分割中，Hou et al. [[2021](#bib.bib68)]
    对自监督特征进行了 k-Means 聚类，然后选择了集群中心的点进行标注。他们提高了室内场景点云分割的标注效率。
- en: 'Pretext tasks: In addition, the pretext tasks in self-supervised learning can
    be used for AL. They are tasks for which the supervision comes directly from the
    data itself. Different pretext tasks correspond to different pre-training paradigms.
    Typical pretext tasks include rotation prediction [Gidaris et al., [2018](#bib.bib54)],
    colorization [Zhang et al., [2016](#bib.bib221)], jigsaw puzzles [Noroozi and
    Favaro, [2016](#bib.bib136)], contrastive learning [He et al., [2020](#bib.bib64)],
    and masked modeling [He et al., [2022](#bib.bib63)], etc. Solving these pretext
    tasks on extensive unlabeled data, the model acquires useful feature representations
    that can indirectly reflect data characteristics. Related works generally employed
    the loss of pretext task for AL. Yi et al. [[2022](#bib.bib213)] found a strong
    correlation between the loss of pretext tasks and the loss of downstream tasks.
    Thus, they initially focused on annotating samples with higher loss of pretext
    tasks and later shifted to those with lower loss. Results showed that rotation
    prediction performed the best among different pretext tasks. In Chen et al. [[2023](#bib.bib31)],
    the loss of contrastive learning was used for AL. They assumed that samples with
    higher losses are more representative of the data distribution. Specifically,
    they pre-trained on the target dataset using MoCo [He et al., [2020](#bib.bib64)]
    for contrastive learning and then used k-Means clustering to partition the unlabeled
    data into multiple clusters, selecting the samples with the highest contrastive
    loss within each cluster for annotation. They then selected samples with the highest
    contrastive loss in each cluster for annotation.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练任务：此外，自监督学习中的预训练任务可以用于主动学习（AL）。这些任务的监督直接来自数据本身。不同的预训练任务对应不同的预训练范式。典型的预训练任务包括旋转预测
    [Gidaris et al., [2018](#bib.bib54)]、颜色化 [Zhang et al., [2016](#bib.bib221)]、拼图
    [Noroozi and Favaro, [2016](#bib.bib136)]、对比学习 [He et al., [2020](#bib.bib64)]
    和掩蔽建模 [He et al., [2022](#bib.bib63)] 等。在大量未标记的数据上解决这些预训练任务，模型会获得有用的特征表示，这些特征表示可以间接反映数据特性。相关研究通常采用预训练任务的损失来进行主动学习。Yi
    et al. [[2022](#bib.bib213)] 发现预训练任务的损失与下游任务的损失之间存在较强的相关性。因此，他们最初专注于标注预训练任务损失较高的样本，后来转向标注损失较低的样本。结果显示，旋转预测在不同的预训练任务中表现最佳。在
    Chen et al. [[2023](#bib.bib31)] 中，使用了对比学习的损失进行主动学习。他们假设损失较高的样本更能代表数据分布。具体来说，他们在目标数据集上使用
    MoCo [He et al., [2020](#bib.bib64)] 进行对比学习的预训练，然后使用 k-Means 聚类将未标记数据划分为多个集群，从每个集群中选择对比损失最高的样本进行标注。然后，他们选择每个集群中对比损失最高的样本进行标注。
- en: 'Others: Furthermore, we can also leverage self-supervised learning in other
    ways for AL. In classification tasks, Zhang et al. [[2022b](#bib.bib224)] introduced
    one-bit annotation into AL for classification tasks. Firstly, they selected informative
    samples through uncertainty metrics. Oracles returned whether the current prediction
    was right or wrong rather than full annotation. Then, contrastive learning was
    adopted to pull the correct predictions closer to their corresponding classes
    and push away wrongly predicted samples from the predicted classes. Results indicated
    that the proposed method outperforms other AL methods regarding bit information.
    Du et al. [[2021](#bib.bib44)] integrated contrastive learning into AL to tackle
    the problem of class distribution mismatch, where unlabeled data often includes
    samples out of the class distribution of the labeled dataset. In this work, contrastive
    learning filtered samples of mismatched classes that differ from the current class
    distribution. Besides, contrastive learning highlighted samples’ informativeness
    by setting carefully designed negative samples. Their extended work Du et al.
    [[2022](#bib.bib43)] provided more theoretical analysis and experimental results
    and further integrated existing label information into the contrastive learning
    framework.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 其他：此外，我们还可以以其他方式在主动学习（AL）中利用自监督学习。在分类任务中，张等人[[2022b](#bib.bib224)]将一位注释引入AL用于分类任务。首先，他们通过不确定性指标选择有信息量的样本。预言者返回当前预测是否正确，而不是完整注释。然后，采用对比学习将正确预测的样本拉近到其对应的类别，同时将错误预测的样本推离预测类别。结果表明，该方法在比特信息方面优于其他AL方法。杜等人[[2021](#bib.bib44)]将对比学习整合到AL中，以解决类别分布不匹配的问题，其中未标记的数据通常包含超出标记数据集类别分布的样本。在这项工作中，对比学习筛选出与当前类别分布不匹配的样本。此外，通过精心设计的负样本，对比学习突出样本的信息量。他们的扩展工作杜等人[[2022](#bib.bib43)]提供了更多的理论分析和实验结果，并进一步将现有标签信息整合到对比学习框架中。
- en: '4.3 Active Domain Adaptation: Tackling Distribution Shift'
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 主动领域适应：应对分布变化
- en: Domain Adaptation (DA) [Guan and Liu, [2021](#bib.bib59)] has wide applications
    in medical image analysis and computer vision. It aims to transfer knowledge from
    the source to the target domain, thus minimizing annotation costs. Currently,
    the most common setting of DA is unsupervised domain adaptation (UDA), in which
    the source domain is labeled while the target domain is unlabeled. However, the
    performance of UDA still lags behind fully supervised learning in the target domain
    [Liu et al., [2023](#bib.bib114)]. To bridge this gap, a natural idea would be
    to employ AL to select and annotate informative samples in the target domain.
    This setting is known as active domain adaptation (ADA). For better queries in
    ADA, one should consider uncertainty and whether the sample represents the target
    domain. The latter is commonly referred to as domainness or targetness in ADA.
    This section reviews the development of ADA and explores various ways of integrating
    AL with DA.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 领域适应（DA）[Guan and Liu, [2021](#bib.bib59)]在医学图像分析和计算机视觉中有广泛的应用。其目标是将知识从源领域转移到目标领域，从而减少注释成本。目前，DA最常见的设置是无监督领域适应（UDA），其中源领域是有标签的，而目标领域是无标签的。然而，UDA在目标领域的表现仍然落后于完全监督学习[Liu
    et al., [2023](#bib.bib114)]。为了弥补这一差距，自然的想法是采用AL在目标领域选择和注释有信息量的样本。这种设置被称为主动领域适应（ADA）。为了更好地进行ADA查询，应该考虑不确定性以及样本是否代表目标领域。后者在ADA中通常称为领域性或目标性。本节回顾了ADA的发展，并探讨了将AL与DA整合的各种方式。
- en: Su et al. [[2020](#bib.bib174)] was the first to introduce the concept of ADA
    and combined domain adversarial learning with AL. Through a domain discriminator
    and task model, they performed importance sampling to select target domain samples
    that are uncertain and highly different from the source domain. Fu et al. [[2021](#bib.bib49)]
    combined query-by-committee, uncertainty, and domainness for selecting the most
    informative samples under distribution shift. They adopted a domain discriminator
    to select samples with high domainness and employed Gaussian kernels to filter
    out anomalous and source-similar samples of the target domain. Random sampling
    was also used to improve diversity. Prabhu et al. [[2021](#bib.bib144)] performed
    k-Means clustering on target domain samples and selected cluster centers for annotation.
    The cluster centers were weighted by uncertainty, thus ensuring that selected
    samples were uncertain and diverse. Rangwani et al. [[2021](#bib.bib153)] formulated
    ADA as a submodular optimization problem. The sum of uncertainty, diversity, and
    representativeness was considered the gain for annotating a sample. Specifically,
    uncertainty was measured by the KL divergence between the original samples and
    their adversarial samples. Diversity was defined as the minimum KL divergence
    from a single sample to a set of samples. The Bhattacharya coefficient between
    samples was used as the representativeness score. They adopted a greedy algorithm
    to iteratively pick samples with the maximum gain. In segmentation tasks, Ning
    et al. [[2021](#bib.bib135)] introduced the idea of anchors in ADA. They concatenated
    features of different classes from the source domain images. Cluster centers of
    these concatenations were referred to as anchors. They then computed the distance
    between each target sample and its nearest anchor. Target samples with the highest
    distance were requested for annotation. Shin et al. [[2021](#bib.bib166)] proposed
    LabOR, which first used a UDA pre-trained model to generate pseudo-labels for
    target samples and trained two segmentation heads with these pseudo-labels. They
    maximized the disagreements between the two heads and annotated regions that exhibited
    the most disagreement. LabOR achieved performance close to full supervision with
    only 2.2% of target domain annotations. Hwang et al. [[2022](#bib.bib76)] first
    selected representative samples in the target domain with maximum mean discrepancy.
    Uncertain ones within these samples were sent for annotation, while the confident
    ones are used for pseudo-labels. Xie et al. [[2022b](#bib.bib204)] introduced
    the concept of energy [LeCun et al., [2006](#bib.bib104)] into ADA. The energy
    is inversely proportional to the likelihood of the data distribution. In this
    work, the model trained on the source domain was used to calculate the energy
    of target domain samples. Samples with high energy were selected for annotation,
    which suggested they are representative of the target domain and substantially
    different from the source data. Xie et al. [[2022d](#bib.bib206)] spotted the
    hard source samples by maximizing margin loss and leveraged these samples to select
    target samples close to the decision boundary. Based on EDL, Xie et al. [[2022c](#bib.bib205)]
    incorporated Dirichlet distribution to mitigate model miscalibration on the target
    domain. Distribution and data uncertainty were both used for sample selection.
    Huang et al. [[2023](#bib.bib72)] selected samples with high uncertainty and prediction
    inconsistency to their nearest prototypes. In 3D object detection, Yuan et al.
    [[2023](#bib.bib215)] adopted a diversity-based strategy to select target domain
    samples. Specifically, they first clustered samples based on similarity and selected
    prototypes of each cluster for annotation.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: Su 等人 [[2020](#bib.bib174)] 首次引入了 ADA 的概念，并将领域对抗学习与主动学习（AL）结合起来。他们通过领域判别器和任务模型执行重要性抽样，以选择那些在目标领域中不确定且与源领域高度不同的样本。Fu
    等人 [[2021](#bib.bib49)] 将查询委员会、不确定性和领域性结合起来，以选择在分布变化下最具信息性的样本。他们采用了领域判别器来选择具有高领域性的样本，并使用高斯核过滤掉目标领域中异常和与源领域相似的样本。同时也使用了随机抽样来提高多样性。Prabhu
    等人 [[2021](#bib.bib144)] 对目标领域样本执行了 k-Means 聚类，并选择了聚类中心进行标注。这些聚类中心根据不确定性进行了加权，从而确保选择的样本是不确定且多样的。Rangwani
    等人 [[2021](#bib.bib153)] 将 ADA 形式化为一个次模优化问题。对样本标注的增益被认为是不确定性、多样性和代表性的总和。具体而言，不确定性通过原始样本和其对抗样本之间的
    KL 散度来衡量。多样性被定义为单个样本与一组样本之间的最小 KL 散度。样本之间的 Bhattacharya 系数被用作代表性分数。他们采用了贪婪算法来迭代地选择具有最大增益的样本。在分割任务中，Ning
    等人 [[2021](#bib.bib135)] 在 ADA 中引入了锚点的概念。他们将源领域图像中不同类别的特征进行连接。这些连接的聚类中心被称为锚点。他们接着计算每个目标样本与其最近锚点之间的距离。请求标注距离最大的目标样本。Shin
    等人 [[2021](#bib.bib166)] 提出了 LabOR，首先使用 UDA 预训练模型生成目标样本的伪标签，并用这些伪标签训练两个分割头。他们最大化两个头之间的不一致，并标注出现最多不一致的区域。LabOR
    在只有 2.2% 目标领域标注的情况下，达到了接近全监督的性能。Hwang 等人 [[2022](#bib.bib76)] 首先在目标领域中选择了具有最大均值差异的代表性样本。在这些样本中，不确定的样本被送去标注，而自信的样本则用于伪标签。Xie
    等人 [[2022b](#bib.bib204)] 将能量 [LeCun 等人，[2006](#bib.bib104)] 引入 ADA。能量与数据分布的可能性成反比。在这项工作中，使用在源领域上训练的模型来计算目标领域样本的能量。具有高能量的样本被选择进行标注，这表明它们代表了目标领域，并与源数据有显著不同。Xie
    等人 [[2022d](#bib.bib206)] 通过最大化边际损失来识别困难的源样本，并利用这些样本选择接近决策边界的目标样本。基于 EDL，Xie 等人
    [[2022c](#bib.bib205)] 结合了 Dirichlet 分布，以减轻目标领域上的模型失调。分布和数据不确定性都被用于样本选择。Huang
    等人 [[2023](#bib.bib72)] 选择了与其最近原型具有高不确定性和预测不一致的样本。在 3D 目标检测中，Yuan 等人 [[2023](#bib.bib215)]
    采用了基于多样性的策略来选择目标领域样本。具体来说，他们首先基于相似性对样本进行聚类，并选择每个聚类的原型进行标注。
- en: '4.4 Region-based Active Learning: Smaller Labeling Unit'
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 基于区域的主动学习：更小的标记单元
- en: 'Most AL works require the oracle to label the full image in medical image analysis
    and computer vision. However, labeling a full image can introduce redundancy in
    fine-grained tasks like segmentation and detection, resulting in an inefficient
    use of the annotation budget. For example, in segmentation tasks of autonomous
    driving, large areas in the image (e.g., roads) do not need exhaustive annotation.
    Instead, those annotation budgets would be better spent on detailed smaller areas,
    such as pedestrians or utility poles. An image can be divided into non-overlap
    regions to further improve annotation efficiency, and experts can opt to annotate
    specific regions within an image. This method is termed as “region-based active
    learning”. This section introduces region-based active learning from three perspectives:
    patches, superpixels, and region-based active domain adaptation.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数主动学习工作要求在医学图像分析和计算机视觉中对整个图像进行标注。然而，对整个图像进行标注可能会在像分割和检测这样的细粒度任务中引入冗余，导致注释预算的使用效率低下。例如，在自动驾驶的分割任务中，图像中的大面积区域（例如道路）不需要详尽的标注。相反，那些注释预算可以更好地用于详细的较小区域，如行人或电力杆。可以将图像划分为不重叠的区域，以进一步提高标注效率，专家可以选择对图像中的特定区域进行标注。这种方法称为“基于区域的主动学习”。本节从三个角度介绍基于区域的主动学习：补丁、超像素和基于区域的主动领域适应。
- en: 4.4.1 Patches
  id: totrans-291
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.1 补丁
- en: Patches are most commonly used in region-based active learning, generally represented
    as square boxes. Mackowiak et al. [[2018](#bib.bib120)] combined uncertainty and
    annotation cost to select the informative patches for annotation. Casanova et al.
    [[2020](#bib.bib28)] employed deep reinforcement learning to automatically select
    informative patches for annotation. In retinal blood vessels segmentation of eye
    images, Xu et al. [[2021](#bib.bib210)] selected patches with the highest uncertainty
    for annotation. Furthermore, they utilized latent-space Mixup to encourage linearization
    between labeled and unlabeled samples, thus leveraging unlabeled data to improve
    performance.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于区域的主动学习中，最常用的是补丁，通常表示为方形框。Mackowiak 等人 [[2018](#bib.bib120)] 结合了不确定性和注释成本，以选择用于注释的信息性补丁。Casanova
    等人 [[2020](#bib.bib28)] 采用深度强化学习自动选择用于注释的信息性补丁。在眼睛图像的视网膜血管分割中，Xu 等人 [[2021](#bib.bib210)]
    选择了具有最高不确定性的补丁进行注释。此外，他们利用潜在空间的 Mixup 来促进标记样本和未标记样本之间的线性化，从而利用未标记数据来提升性能。
- en: 4.4.2 Superpixels
  id: totrans-293
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.2 超像素
- en: Superpixels are also widely used in region-based active learning. Superpixel
    generation algorithms [Achanta et al., [2012](#bib.bib1), Van den Bergh et al.,
    [2012](#bib.bib19)] over-segment images based on color and texture, grouping similar
    pixels into the same superpixel. Superpixel-based AL initially pre-segments the
    images and then calculates the informativeness of each superpixel. The informativeness
    metric of each superpixel is the average of its constituent pixels. Kasarla et al.
    [[2019](#bib.bib88)] introduced a baseline method for selecting superpixels based
    on uncertainty. In multi-view indoor scene segmentation, Siddiqui et al. [[2020](#bib.bib168)]
    adopted uncertainty and disagreement between different viewpoints to select informative
    superpixels for annotation. Cai et al. [[2021](#bib.bib25)] utilized uncertainty
    as the informativeness metric. They introduced a class-balanced sampling strategy
    to better select superpixels containing minority classes. Furthermore, they adopted
    a “dominant labeling” scheme. The dominant labeling is the majority class label
    of all pixels in the superpixel. They assigned the dominant labeling to every
    pixel within a superpixel, thus eliminating the need for detailed delineation.
    Results showed that, with the same number of labeling clicks, dominant labeling
    at the superpixel level significantly outperforms precise labeling at the patch
    level. As a follow-up, Kim et al. [[2023](#bib.bib91)] proposed to adaptively
    merge and split spatially adjacent, similar, and complex superpixels, respectively.
    This approach yielded better performance than [Cai et al., [2021](#bib.bib25)]
    with dominant labeling. In 3D vision, similar over-segmentation has also been
    applied to point clouds segmentation by Wu et al. [[2021a](#bib.bib200)], Hu et al.
    [[2022](#bib.bib71)] and Liu et al. [[2022a](#bib.bib111)]. The former two works
    adopted supervoxel segmentation algorithms, while the latter employed k-Means
    for over-segmentation.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 超像素在基于区域的主动学习中也被广泛使用。超像素生成算法 [Achanta et al., [2012](#bib.bib1), Van den Bergh
    et al., [2012](#bib.bib19)] 基于颜色和纹理对图像进行过度分割，将相似的像素分组到同一个超像素中。基于超像素的主动学习最初对图像进行预分割，然后计算每个超像素的信息量。每个超像素的信息量度量是其组成像素的平均值。Kasarla
    et al. [[2019](#bib.bib88)] 提出了基于不确定性的超像素选择基线方法。在多视角室内场景分割中，Siddiqui et al. [[2020](#bib.bib168)]
    采用不同视角之间的不确定性和分歧来选择用于标注的有信息量的超像素。Cai et al. [[2021](#bib.bib25)] 将不确定性用作信息量度量。他们引入了一个类平衡采样策略，以更好地选择包含少数类的超像素。此外，他们采用了“主导标注”方案。主导标注是超像素中所有像素的主要类标签。他们将主导标注分配给超像素内的每个像素，从而消除了对详细描绘的需求。结果表明，在相同数量的标注点击下，超像素级别的主导标注显著优于补丁级别的精确标注。作为后续工作，Kim
    et al. [[2023](#bib.bib91)] 提出了分别自适应地合并和分割空间上相邻的、相似的和复杂的超像素。这种方法的表现优于 [Cai et
    al., [2021](#bib.bib25)] 的主导标注。在 3D 视觉中，类似的过度分割也被 Wu et al. [[2021a](#bib.bib200)],
    Hu et al. [[2022](#bib.bib71)] 和 Liu et al. [[2022a](#bib.bib111)] 应用于点云分割。前两项工作采用了超体素分割算法，而后者则采用了
    k-Means 进行过度分割。
- en: 4.4.3 Region-based Active Domain Adaptation
  id: totrans-295
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.3 基于区域的主动领域适应
- en: To better utilize the annotation budget, some ADA segmentation works also employed
    patches or superpixels for annotation. In Xie et al. [[2022a](#bib.bib203)], uncertainty
    and regional impurity were used to select and annotate the most informative patches.
    Regional impurity measured the number of unique predicted classes within the neighborhood
    of a pixel, which presents the edge information. They used extremely small patches
    (e.g., size of 3x3) for annotation and achieved performance close to full supervision
    with only 5% of the annotation cost. Wu et al. [[2022b](#bib.bib199)] proposed
    a density-based method to select the most representative superpixels in the target
    domain for annotation. They employed Gaussian mixture models (GMM) as density
    estimators for superpixels in both the source and target domains, aiming to select
    those with high density in the target domain and low density in the source domain.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地利用标注预算，一些 ADA 分割工作还采用了补丁或超像素进行标注。在 Xie et al. [[2022a](#bib.bib203)] 中，使用了不确定性和区域杂质来选择和标注最有信息量的补丁。区域杂质测量了像素邻域内唯一预测类的数量，这反映了边缘信息。他们使用了极小的补丁（例如，3x3
    的大小）进行标注，并且在仅用 5% 的标注成本下达到了接近完全监督的性能。Wu et al. [[2022b](#bib.bib199)] 提出了基于密度的方法来选择目标领域中最具代表性的超像素进行标注。他们采用高斯混合模型
    (GMM) 作为源领域和目标领域超像素的密度估计器，旨在选择在目标领域中密度高而在源领域中密度低的超像素。
- en: '4.5 Generative Model: Data Augmentation and Generative Active Learning'
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 生成模型：数据增强与生成式主动学习
- en: 'In recent years, the advancement of deep generative models enabled high-quality
    generation and flexible conditional generation. For example, a trained model could
    generate the corresponding lung X-ray scan when conditioned on a lung mask. By
    integrating generative models, we can further improve the annotation efficiency
    of AL. In this section, we discuss how AL can be combined with generative models
    from two aspects: data augmentation and generative active learning.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度生成模型的进步使得高质量生成和灵活的条件生成成为可能。例如，当以肺部掩码为条件时，训练好的模型可以生成相应的肺部 X 光扫描图像。通过整合生成模型，我们可以进一步提高主动学习的注释效率。在本节中，我们将从数据增强和生成式主动学习两个方面讨论如何将主动学习与生成模型相结合。
- en: 4.5.1 Synthetic Samples as Data Augmentation
  id: totrans-299
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.1 合成样本作为数据增强
- en: The simplest approach considers the synthetic sample produced by generative
    models as advanced data augmentation. These methods utilize label-conditioned
    generative models. As a result, it’s guaranteed that all synthetic samples are
    correctly labeled since specifying the labels is a prerequisite for data generation.
    This method enables us to acquire more labeled samples without any additional
    annotations. Tran et al. [[2019](#bib.bib181)] argued that most synthetic samples
    produced by generative models are not highly informative. Therefore, they first
    adopted the BALD uncertainty to select samples for annotation, then trained a
    VAE-ACGAN on these labeled data to generate more informative synthetic samples.
    Mahapatra et al. [[2018](#bib.bib121)] used conditional GANs to generate chest
    X-rays with varying diseases to augment the labeled dataset. Then, MC Dropout
    was used to select and annotate highly uncertain samples. With the help of AL
    and synthetic samples, they achieved performance near fully supervised using only
    35% of the data. Training conditional generative models require a large amount
    of labeled data, while the labeled dataset in AL is often relatively small. To
    address this issue, Lou et al. [[2023](#bib.bib118)] proposed a conditional SinGAN
    [Shaham et al., [2019](#bib.bib164)] that only requires one pair of images and
    masks for training. The SinGAN improved the annotation efficiency for nuclei segmentation.
    Additionally, Chen et al. [[2022b](#bib.bib34)] integrated implicit semantic data
    augmentation (ISDA) [Wang et al., [2021](#bib.bib194)] into AL. They initially
    used ISDA to augment unlabeled samples, then selected samples with large diversity
    between different data augmentations for annotation. The model is trained on both
    the original data and its augmentations.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法将生成模型产生的合成样本视为先进的数据增强。这些方法利用了标签条件的生成模型。因此，所有合成样本都能确保被正确标注，因为指定标签是数据生成的先决条件。这种方法使我们能够在没有额外注释的情况下获得更多标注样本。Tran
    等人 [[2019](#bib.bib181)] 认为，大多数由生成模型产生的合成样本信息量不足。因此，他们首先采用 BALD 不确定性来选择样本进行标注，然后在这些标注数据上训练了一个
    VAE-ACGAN，以生成更具信息性的合成样本。Mahapatra 等人 [[2018](#bib.bib121)] 使用条件 GAN 生成具有不同疾病的胸部
    X 光片，以增强标注数据集。然后，使用 MC Dropout 选择并标注高度不确定的样本。在主动学习和合成样本的帮助下，他们仅使用 35% 的数据就达到了接近完全监督的性能。训练条件生成模型需要大量标注数据，而主动学习中的标注数据集通常相对较小。为了解决这个问题，Lou
    等人 [[2023](#bib.bib118)] 提出了一个条件 SinGAN [Shaham 等人，[2019](#bib.bib164)]，只需一对图像和掩码即可进行训练。SinGAN
    改善了细胞核分割的注释效率。此外，Chen 等人 [[2022b](#bib.bib34)] 将隐式语义数据增强 (ISDA) [Wang 等人，[2021](#bib.bib194)]
    集成到主动学习中。他们最初使用 ISDA 增强未标注样本，然后选择不同数据增强之间具有大差异的样本进行标注。模型在原始数据及其增强数据上进行训练。
- en: 4.5.2 Generative Active Learning
  id: totrans-301
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.2 生成式主动学习
- en: Generative active learning selects synthetic samples produced by generative
    models for oracle annotation, thus without requiring a large unlabeled sample
    pool. The advantage of this approach lies in its ability to continuously search
    the data manifold through generative models. It’s worth noting that works in this
    section follow the setting of membership query synthesis, while works in the last
    section follow the setting of pool-based active learning. This distinction arises
    because generative models in the last section were solely utilized to augment
    existing labeled datasets. Zhu and Bento [[2017](#bib.bib234)] attempted to generate
    uncertain samples with GAN for expert annotation. Unfortunately, the quality of
    the generated samples was low and included many samples with indistinguishable
    classes. Since experts find it difficult to annotate low-quality synthetic samples,
    alternative methods are needed to annotate these samples. Chen et al. [[2021](#bib.bib30)]
    first trained a bidirectional GAN to learn the data manifold. They then selected
    uncertain areas in the feature space and generated images within these regions
    using bidirectional GAN. Finally, they used physics-based simulation to provide
    labels for the generated samples. In calcification level prediction in aortic
    stenosis of CT, they improved annotation efficiency by up to 10 times compared
    to random generation.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性主动学习通过生成模型选择合成样本进行人工标注，因此不需要大规模的未标注样本池。这种方法的优势在于能够通过生成模型持续搜索数据流形。值得注意的是，本节中的工作遵循会员查询合成的设置，而上一节中的工作遵循基于池的主动学习设置。这一区别的出现是因为上一节中的生成模型仅用于增强现有标注数据集。Zhu和Bento
    [[2017](#bib.bib234)] 尝试使用GAN生成不确定的样本以供专家标注。不幸的是，生成样本的质量较低，并且包括许多类无法区分的样本。由于专家很难标注低质量的合成样本，因此需要替代方法来标注这些样本。Chen等人
    [[2021](#bib.bib30)] 首先训练了一个双向GAN以学习数据流形。然后，他们在特征空间中选择了不确定区域，并使用双向GAN在这些区域内生成图像。最后，他们使用基于物理的模拟为生成的样本提供标签。在主动学习的计算钙化水平预测中，他们的标注效率比随机生成提高了多达10倍。
- en: 5 Active Learning for Medical Image Analysis
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 医学图像分析中的主动学习
- en: 'Due to the potential of significantly reducing annotation costs, AL is receiving
    increasing attention in medical image analysis. The unique traits of medical imaging
    require us to design specialized AL methods. Building on the foundation of the
    previous two sections, this section will focus on introducing AL works tailored
    to medical image analysis across different tasks, including classification, segmentation,
    and reconstruction. Additionally, in Table [3](#S5.T3b "Table 3 ‣ 5 Active Learning
    for Medical Image Analysis ‣ 4.5.2 Generative Active Learning ‣ 4.5 Generative
    Model: Data Augmentation and Generative Active Learning ‣ 4.4.3 Region-based Active
    Domain Adaptation ‣ 4.4 Region-based Active Learning: Smaller Labeling Unit ‣
    4.3 Active Domain Adaptation: Tackling Distribution Shift ‣ 4.2.2 Combination
    of Active Learning and Self-supervised Learning ‣ 4.2 Self-supervised Learning:
    Utilizing Pre-trained Model ‣ 4.1.2 Consistency Regularization ‣ 4.1 Semi-supervised
    Learning: Utilizing Unlabeled Data ‣ 4 Integration of Active Learning and Other
    Label-Efficient Techniques ‣ A comprehensive survey on deep active learning and
    its applications in medical image analysis"), we list all the AL works related
    to medical image analysis in this survey, providing the name of the used dataset,
    its modality, ROIs, and corresponding clinical and technical tasks.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大幅降低标注成本的潜力，主动学习（AL）在医学图像分析中受到了越来越多的关注。医学成像的独特特性要求我们设计专门的主动学习方法。基于前两部分的基础，本节将重点介绍针对医学图像分析不同任务（包括分类、分割和重建）的主动学习工作。此外，在表[3](#S5.T3b
    "表 3 ‣ 5 医学图像分析中的主动学习 ‣ 4.5.2 生成性主动学习 ‣ 4.5 生成模型：数据增强与生成性主动学习 ‣ 4.4.3 基于区域的主动领域适应
    ‣ 4.4 基于区域的主动学习：更小的标注单元 ‣ 4.3 主动领域适应：应对分布偏移 ‣ 4.2.2 主动学习与自监督学习的结合 ‣ 4.2 自监督学习：利用预训练模型
    ‣ 4.1.2 一致性正则化 ‣ 4.1 半监督学习：利用未标注数据 ‣ 4 主动学习与其他标签高效技术的整合 ‣ 关于深度主动学习及其在医学图像分析中应用的全面调查")中，我们列出了所有与医学图像分析相关的主动学习工作，提供了所用数据集的名称、模式、ROI以及相应的临床和技术任务。
- en: 'Table 3: Surveyed Works of Active Learning related to Medical Image Analysis.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：医学图像分析相关的主动学习调查工作。
- en: '|  | Year | Venues | Modality | ROIs | Dataset | Clinical Task | Technical
    Task |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '|  | 年份 | 场馆 | 模式 | ROI | 数据集 | 临床任务 | 技术任务 |'
- en: '| Zhou et al. [[2017](#bib.bib232)] | 2017 | CVPR | Colonoscopy | Colon | in-house
    | Image Quality Assessment | Classification |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| Zhou 等 [[2017](#bib.bib232)] | 2017 | CVPR | 结肠镜检查 | 结肠 | 自家开发 | 图像质量评估 |
    分类 |'
- en: '| Colonoscopy | Colon | in-house | Polyp Detection | Classification |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| 结肠镜检查 | 结肠 | 自家开发 | 息肉检测 | 分类 |'
- en: '| CT | Lung | in-house | Pulmonary Embolism Detection | Classification |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| CT | 肺部 | 自家开发 | 肺栓塞检测 | 分类 |'
- en: '| Gal et al. [[2017](#bib.bib52)] | 2017 | ICML | Dermscopy | Skin | ISIC 2016
    | Skin Cancer Diagnosis | Classification |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| Gal 等 [[2017](#bib.bib52)] | 2017 | ICML | 皮肤镜 | 皮肤 | ISIC 2016 | 皮肤癌诊断 |
    分类 |'
- en: '| Yang et al. [[2017](#bib.bib211)] | 2017 | MICCAI | Histopathology | Colon
    | Glas | Gland Segmentation | Segmentation |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| Yang 等 [[2017](#bib.bib211)] | 2017 | MICCAI | 组织病理学 | 结肠 | Glas | 腺体分割 |
    分割 |'
- en: '| Ultrasound | Lymoh Node | in-house | Lymoh Node Segmentation | Segmentation
    |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 超声波 | 淋巴结 | 自家开发 | 淋巴结分割 | 分割 |'
- en: '| Beluch et al. [[2018](#bib.bib16)] | 2018 | CVPR | Fundus | Eye | EyePacs
    | Diabetic Retinopathy Detection | Classification |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| Beluch 等 [[2018](#bib.bib16)] | 2018 | CVPR | 视网膜 | 眼睛 | EyePacs | 糖尿病视网膜病变检测
    | 分类 |'
- en: '| Xu et al. [[2018](#bib.bib209)] | 2018 | CVPR | Histopathology | Colon |
    Glas | Gland Segmentation | Segmentation |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| Xu 等 [[2018](#bib.bib209)] | 2018 | CVPR | 组织病理学 | 结肠 | Glas | 腺体分割 | 分割
    |'
- en: '| Sourati et al. [[2018](#bib.bib172)] | 2018 | DLMIA | MRI | Brain | dHCP
    & in-house | Brain Extraction | Segmentation |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| Sourati 等 [[2018](#bib.bib172)] | 2018 | DLMIA | MRI | 大脑 | dHCP & 自家开发 |
    大脑提取 | 分割 |'
- en: '| Sourati et al. [[2019](#bib.bib173)] | 2019 | TMI |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| Sourati 等 [[2019](#bib.bib173)] | 2019 | TMI |'
- en: '| Kuo et al. [[2018](#bib.bib103)] | 2018 | MICCAI | CT | Head | in-house |
    Intracranial Hemorrhage Detection | Segmentation |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| Kuo 等 [[2018](#bib.bib103)] | 2018 | MICCAI | CT | 头部 | 自家开发 | 颅内出血检测 | 分割
    |'
- en: '| Mahapatra et al. [[2018](#bib.bib121)] | 2018 | MICCAI | X-ray | Chest |
    SCR & Chestx-ray8 | Lung Segmentation | Segmentation |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| Mahapatra 等 [[2018](#bib.bib121)] | 2018 | MICCAI | X射线 | 胸部 | SCR & Chestx-ray8
    | 肺部分割 | 分割 |'
- en: '| Thoracic Disease Diagnosis | Classification |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| 胸部疾病诊断 | 分类 |'
- en: '| Jin et al. [[2019](#bib.bib80)] | 2019 | arXiv | MRI | Heart | Cardiac Atlas
    Project | MRI Reconstruction | Reconstruction |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| Jin 等 [[2019](#bib.bib80)] | 2019 | arXiv | MRI | 心脏 | Cardiac Atlas Project
    | MRI 重建 | 重建 |'
- en: '| Knee | fastMRI | MRI Reconstruction | Reconstruction |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 膝盖 | fastMRI | MRI 重建 | 重建 |'
- en: '| Zheng et al. [[2019](#bib.bib227)] | 2019 | AAAI | Histopathology | Colon
    | Glas | Gland Segmentation | Segmentation |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| Zheng 等 [[2019](#bib.bib227)] | 2019 | AAAI | 组织病理学 | 结肠 | Glas | 腺体分割 |
    分割 |'
- en: '| MRI | Heart | HVSMR 2016 | Whole-heart Segmentation | Segmentation |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| MRI | 心脏 | HVSMR 2016 | 全心分割 | 分割 |'
- en: '| Electron Microscopy | Fungus | in-house | Fungus Segmentation | Segmentation
    |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 电子显微镜 | 真菌 | 自家开发 | 真菌分割 | 分割 |'
- en: '| Zhang et al. [[2019](#bib.bib225)] | 2019 | CVPR | MRI | Knee | fastMRI |
    MRI Reconstruction | Reconstruction |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| Zhang 等 [[2019](#bib.bib225)] | 2019 | CVPR | MRI | 膝盖 | fastMRI | MRI 重建
    | 重建 |'
- en: '| Qi et al. [[2019](#bib.bib145)] | 2019 | JBHI | Histopathology | Breast |
    BreaKHis | Breast Cancer Diagnosis | Classification |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| Qi 等 [[2019](#bib.bib145)] | 2019 | JBHI | 组织病理学 | 乳房 | BreaKHis | 乳腺癌诊断
    | 分类 |'
- en: '| Sadafi et al. [[2019](#bib.bib157)] | 2019 | MICCAI | Mircoscopy | Blood
    | in-house | Red Blood Cell Detection | Object Detection |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| Sadafi 等 [[2019](#bib.bib157)] | 2019 | MICCAI | 显微镜 | 血液 | 自家开发 | 红细胞检测
    | 物体检测 |'
- en: '| Zheng et al. [[2020](#bib.bib228)] | 2020 | AAAI | MRI | Heart | HVSMR 2016
    | Whole-heart Segmentation | Segmentation |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| Zheng 等 [[2020](#bib.bib228)] | 2020 | AAAI | MRI | 心脏 | HVSMR 2016 | 全心分割
    | 分割 |'
- en: '| Electron Microscopy | Mouse | Lee et al. [[2015](#bib.bib106)] | Neuron Boundary
    Segmentation | Segmentation |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| 电子显微镜 | 小鼠 | Lee 等 [[2015](#bib.bib106)] | 神经元边界分割 | 分割 |'
- en: '| Lin et al. [[2020](#bib.bib110)] | 2020 | ECCV | Electron Microscopy | Mouse
    Synapses & Mitochondria | EM-R50 | Synapse Detection & Mitochondria Segmentation
    | Segmentation |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| Lin 等 [[2020](#bib.bib110)] | 2020 | ECCV | 电子显微镜 | 小鼠突触与线粒体 | EM-R50 | 突触检测与线粒体分割
    | 分割 |'
- en: '| Dai et al. [[2020](#bib.bib40)] | 2020 | MICCAI | MRI | Brain | BraTS 2019
    | Brain Tumor Segmentation | Segmentation |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| Dai 等 [[2020](#bib.bib40)] | 2020 | MICCAI | MRI | 大脑 | BraTS 2019 | 脑肿瘤分割
    | 分割 |'
- en: '| Li and Yin [[2020](#bib.bib108)] | 2020 | MICCAI | Histopathology | Colon
    | Glas | Gland Segmentation | Segmentation |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| Li 和 Yin [[2020](#bib.bib108)] | 2020 | MICCAI | 组织病理学 | 结肠 | Glas | 腺体分割
    | 分割 |'
- en: '| MRI | Brain | iSeg | Infant Brain Segmentation | Segmentation |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| MRI | 大脑 | iSeg | 婴儿大脑分割 | 分割 |'
- en: '| Liu et al. [[2020](#bib.bib112)] | 2020 | MICCA | CT | Lung | DeepLesion
    | Pulmonary Nodule Detection | Object Detection |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| Liu 等人 [[2020](#bib.bib112)] | 2020 | MICCA | CT | 肺部 | DeepLesion | 肺结节检测
    | 目标检测 |'
- en: '| Mi et al. [[2020](#bib.bib127)] | 2020 | MICCAI | Electron Microscopy | Mouse
    Cortex | SNEMI3D | Accelerated Acquisition of Electron Microscopy | Reconstruction
    |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| Mi 等人 [[2020](#bib.bib127)] | 2020 | MICCAI | 电子显微镜 | 小鼠皮层 | SNEMI3D | 电子显微镜加速获取
    | 重建 |'
- en: '| Human Cerebrum | in-house | Reconstruction |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| 人脑 | 内部 | 重建 |'
- en: '| Pineda et al. [[2020](#bib.bib142)] | 2020 | MICCAI | MRI | Knee | fastMRI
    | MRI Reconstruction | Reconstruction |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| Pineda 等人 [[2020](#bib.bib142)] | 2020 | MICCAI | MRI | 膝部 | fastMRI | MRI
    重建 | 重建 |'
- en: '| Shen et al. [[2020](#bib.bib165)] | 2020 | MICCAI | Immunohistochemistry
    | Breast | in-house | Breast Cancer Region Segmentation | Segmentation |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| Shen 等人 [[2020](#bib.bib165)] | 2020 | MICCAI | 免疫组化 | 乳房 | 内部 | 乳腺癌区域分割
    | 分割 |'
- en: '| Wang et al. [[2020a](#bib.bib187)] | 2020 | MICCAI | CT | Lung | [Tianchi](https://tianchi.aliyun.com/competition/entrance/231724/introduction)
    | Lung Diease Detection | Classification |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等人 [[2020a](#bib.bib187)] | 2020 | MICCAI | CT | 肺部 | [天池](https://tianchi.aliyun.com/competition/entrance/231724/introduction)
    | 肺病检测 | 分类 |'
- en: '| Fundus | Eye | EyePacs | Diabetic Retinopathy Detection | Classification
    |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| 眼底 | 眼睛 | EyePacs | 糖尿病视网膜病变检测 | 分类 |'
- en: '| Bakker et al. [[2020](#bib.bib13)] | 2020 | NeurIPS | MRI | Knee | fastMRI
    | MRI Reconstruction | Reconstruction |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| Bakker 等人 [[2020](#bib.bib13)] | 2020 | NeurIPS | MRI | 膝部 | fastMRI | MRI
    重建 | 重建 |'
- en: '| Brain | fastMRI | MRI Reconstruction | Reconstruction |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 大脑 | fastMRI | MRI 重建 | 重建 |'
- en: '| Hiasa et al. [[2020](#bib.bib66)] | 2020 | TMI | CT | Hip & Thigh | TCIA
    & in-house | Muscle Segmentation | Segmentation |  Table 3: Methodology summarization
    of surveyed active learning works.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '| Hiasa 等人 [[2020](#bib.bib66)] | 2020 | TMI | CT | 髋部和大腿 | TCIA & 内部 | 肌肉分割
    | 分割 |  表 3: 调查的主动学习工作的 методология 概述。'
- en: '|  | Year | Venues | Modality | ROIs | Dataset | Clinical Task | Technical
    Task |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '|  | 年份 | 会议 | 模态 | ROI | 数据集 | 临床任务 | 技术任务 |'
- en: '| Huang et al. [[2020](#bib.bib75)] | 2020 | TMI | X-ray | Chest | in-house
    | Rib Fracture Recognition | Object Detection |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| Huang 等人 [[2020](#bib.bib75)] | 2020 | TMI | X 射线 | 胸部 | 内部 | 肋骨骨折识别 | 目标检测
    |'
- en: '| Zhao et al. [[2021](#bib.bib226)] | 2021 | JBHI | Dermscopy | Skin | ISIC
    2017 | Skin Lesion Segmentation | Segmentation |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| Zhao 等人 [[2021](#bib.bib226)] | 2021 | JBHI | 皮肤镜检查 | 皮肤 | ISIC 2017 | 皮肤病变分割
    | 分割 |'
- en: '| X-ray | Hand | RSNA Bone Age Dataset | Finger Bone Segmentation | Segmentation
    |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| X 射线 | 手部 | RSNA 骨龄数据集 | 手指骨分割 | 分割 |'
- en: '| Wu et al. [[2021b](#bib.bib201)] | 2021 | MedIA | CT | Lung | CC-CCII | COVID-19
    Diagnosis | Classification |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| Wu 等人 [[2021b](#bib.bib201)] | 2021 | MedIA | CT | 肺部 | CC-CCII | COVID-19
    诊断 | 分类 |'
- en: '| Zhou et al. [[2021b](#bib.bib233)] | 2021 | MedIA | Colonoscopy | Colon |
    in-house | Image Quality Assessment | Classification |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| Zhou 等人 [[2021b](#bib.bib233)] | 2021 | MedIA | 结肠镜检查 | 结肠 | 内部 | 图像质量评估
    | 分类 |'
- en: '| Colonoscopy | Colon | in-house | Polyp Detection | Classification |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 结肠镜检查 | 结肠 | 内部 | 息肉检测 | 分类 |'
- en: '| CT | Lung | in-house | Pulmonary Embolism Detection | Classification |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| CT | 肺部 | 内部 | 肺栓塞检测 | 分类 |'
- en: '| Wang and Yin [[2021](#bib.bib195)] | 2021 | MICCAI | Mircoscopy (Synthetic)
    | Bacterial Cells | VGG Cell | Cell Counting | Keypoint Localization |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| Wang 和 Yin [[2021](#bib.bib195)] | 2021 | MICCAI | 显微镜（合成） | 细菌细胞 | VGG 细胞
    | 细胞计数 | 关键点定位 |'
- en: '| Histopathology | Human Bone Marrow | MBM | Cell Counting | Keypoint Localization
    |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 组织病理学 | 人类骨髓 | MBM | 细胞计数 | 关键点定位 |'
- en: '| Histopathology | Human Adipocyte Cells | ADI | Cell Counting | Keypoint Localization
    |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| 组织病理学 | 人类脂肪细胞 | ADI | 细胞计数 | 关键点定位 |'
- en: '| - | Various Tissues & Species | DCC | Cell Counting | Keypoint Localization
    |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| - | 各种组织和物种 | DCC | 细胞计数 | 关键点定位 |'
- en: '| Xu et al. [[2021](#bib.bib210)] | 2021 | MICCAI | Fundus | Eye | DRIVE |
    Retina Vessel Segmentation | Segmentation |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| Xu 等人 [[2021](#bib.bib210)] | 2021 | MICCAI | 眼底 | 眼睛 | DRIVE | 视网膜血管分割 |
    分割 |'
- en: '| OCTA | Eye | ROSE-1 | Retina Vessel Segmentation | Segmentation |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| OCTA | 眼睛 | ROSE-1 | 视网膜血管分割 | 分割 |'
- en: '| Zhou et al. [[2021a](#bib.bib230)] | 2021 | MICCAI | CT | Lung | MSD | Tumor
    Segmentation | Segmentation |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| Zhou 等人 [[2021a](#bib.bib230)] | 2021 | MICCAI | CT | 肺部 | MSD | 肿瘤分割 | 分割
    |'
- en: '| Colon | MSD | Tumor Segmentation | Segmentation |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 结肠 | MSD | 肿瘤分割 | 分割 |'
- en: '| Kidney | KiTS 19 | Kidney & Tumor Segmentation | Segmentation |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| 肾脏 | KiTS 19 | 肾脏及肿瘤分割 | 分割 |'
- en: '| Nguyen et al. [[2021](#bib.bib133)] | 2021 | MIDL | X-ray | Chest | in-house
    | Diagnosis of Airspace Opacity & Lung Lesion | Classification |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| Nguyen 等人 [[2021](#bib.bib133)] | 2021 | MIDL | X 射线 | 胸部 | 内部 | 空气空间不透明度及肺部病变的诊断
    | 分类 |'
- en: '| Chest | RSNA Pneumonia | Diagnosis of Pneumonia | Classification |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| 胸部 | RSNA肺炎 | 肺炎诊断 | 分类 |'
- en: '| Chest | CheXpert | Detection of Pleural Effusion | Classification |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 胸部 | CheXpert | 胸腔积液检测 | 分类 |'
- en: '| Mahapatra et al. [[2021](#bib.bib123)] | 2021 | TMI | X-ray | Chest | ChestX-ray8
    | Thoracic Disease Diagnosis | Classification |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| Mahapatra et al. [[2021](#bib.bib123)] | 2021 | TMI | X射线 | 胸部 | ChestX-ray8
    | 胸部疾病诊断 | 分类 |'
- en: '| Histopathology | Colon | Glas | Gland Segmentation | Segmentation |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 组织病理学 | 结肠 | Glas | 腺体分割 | 分割 |'
- en: '| Nath et al. [[2021](#bib.bib131)] | 2021 | TMI | CT | Pancreas | MSD | Pancreas
    & Tumor Segmentation | Segmentation |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| Nath et al. [[2021](#bib.bib131)] | 2021 | TMI | CT | 胰腺 | MSD | 胰腺与肿瘤分割
    | 分割 |'
- en: '| MRI | Hippocampus | MSD | Hippocampus Segmentation | Segmentation |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| MRI | 海马体 | MSD | 海马体分割 | 分割 |'
- en: '| Chen et al. [[2021](#bib.bib30)] | 2021 | TPAMI | CT | Heart | in-house |
    Calcification Level Prediction in Aortic Stenosis | Classification |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| Chen et al. [[2021](#bib.bib30)] | 2021 | TPAMI | CT | 心脏 | 内部开发 | 主动脉瓣狭窄钙化水平预测
    | 分类 |'
- en: '| Wang et al. [[2022a](#bib.bib186)] | 2022 | arXiv | CT | Lung | AAPM | CT
    Reconstruction | Reconstruction |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| Wang et al. [[2022a](#bib.bib186)] | 2022 | arXiv | CT | 肺 | AAPM | CT重建
    | 重建 |'
- en: '| Spine | VerSe | CT Reconstruction | Reconstruction |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| 脊柱 | VerSe | CT重建 | 重建 |'
- en: '| Kothawade et al. [[2022b](#bib.bib100)] | 2022 | AAAI | X-ray | Chest | PneumoniaMNIST
    | Pneumonia & Normal Classification | Classification |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| Kothawade et al. [[2022b](#bib.bib100)] | 2022 | AAAI | X射线 | 胸部 | PneumoniaMNIST
    | 肺炎与正常分类 | 分类 |'
- en: '| Quan et al. [[2022](#bib.bib149)] | 2022 | CVPR | X-ray | Head | [Kaggle](https://www.kaggle.com/datasets/jiahongqian/cephalometric-landmarks)
    | Cephalometric Landmark Detection | Keypoint Localization |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| Quan et al. [[2022](#bib.bib149)] | 2022 | CVPR | X射线 | 头部 | [Kaggle](https://www.kaggle.com/datasets/jiahongqian/cephalometric-landmarks)
    | 头面标志检测 | 关键点定位 |'
- en: '| Hand | Payer et al. [[2019](#bib.bib140)] | Hand Landmark Detection | Keypoint
    Localization |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| Hand | Payer et al. [[2019](#bib.bib140)] | 手部标志检测 | 关键点定位 |'
- en: '| Zhang et al. [[2022a](#bib.bib222)] | 2022 | CVPR | MRI | Spine | in-house
    | Diagnosis of Metastatic Epidural Spinal Cord Compression | Classification |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| Zhang et al. [[2022a](#bib.bib222)] | 2022 | CVPR | MRI | 脊柱 | 内部开发 | 转移性硬膜外脊髓压迫诊断
    | 分类 |'
- en: '| Jin et al. [[2022c](#bib.bib84)] | 2022 | Knowledge-based Systems | Dermscopy
    | Skin | ISIC 2020 | Skin Lesion Classification | Classification |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| Jin et al. [[2022c](#bib.bib84)] | 2022 | 基于知识的系统 | 皮肤镜检查 | 皮肤 | ISIC 2020
    | 皮肤病变分类 | 分类 |'
- en: '| Jin et al. [[2022b](#bib.bib83)] | 2022 | Knowledge-based Systems | Dermscopy
    | Skin | ISIC 2018 | Skin Lesion Segmentation | Segmentation |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| Jin et al. [[2022b](#bib.bib83)] | 2022 | 基于知识的系统 | 皮肤镜检查 | 皮肤 | ISIC 2018
    | 皮肤病变分割 | 分割 |'
- en: '| X-ray | Chest | Jaeger et al. [[2013](#bib.bib77)] | Lung Segmentation |
    Segmentation |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| X射线 | 胸部 | Jaeger et al. [[2013](#bib.bib77)] | 肺部分割 | 分割 |'
- en: '| Atzeni et al. [[2022](#bib.bib9)] | 2022 | MedIA | MRI | Brain | SATA | Brain
    Structure Segmentation | Segmentation |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| Atzeni et al. [[2022](#bib.bib9)] | 2022 | MedIA | MRI | 大脑 | SATA | 大脑结构分割
    | 分割 |'
- en: '| Histology | Brain | in-house | Brain Structure Segmentation | Segmentation
    |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| 组织学 | 大脑 | 内部开发 | 大脑结构分割 | 分割'
- en: '| Dai et al. [[2022](#bib.bib39)] | 2022 | MedIA | MRI | Brain | BraTS 2019
    | Brain Tumor Segmentation | Segmentation |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| Dai et al. [[2022](#bib.bib39)] | 2022 | MedIA | MRI | 大脑 | BraTS 2019 |
    脑肿瘤分割 | 分割 |'
- en: '| Brain | MALC | Brain Structure Segmentation | Segmentation |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| 大脑 | MALC | 大脑结构分割 | 分割 |'
- en: '| Zhou et al. [[2022](#bib.bib231)] | 2022 | MedIA | CT | Lung | MSD | Tumor
    Segmentation | Segmentation |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| Zhou et al. [[2022](#bib.bib231)] | 2022 | MedIA | CT | 肺 | MSD | 肿瘤分割 |
    分割 |'
- en: '| CT | Colon | MSD | Tumor Segmentation | Segmentation |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| CT | 结肠 | MSD | 肿瘤分割 | 分割 |'
- en: '| CT | Kidney | KiTS 19 | Kidney & Tumor Segmentation | Segmentation |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| CT | 肾脏 | KiTS 19 | 肾脏与肿瘤分割 | 分割 |'
- en: '| Colonoscopy | Colon | CVC-ClinicDB | Polyp Segmentation | Segmentation |  Table
    3: Methodology summarization of surveyed active learning works.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '| 胶囊内镜 | 结肠 | CVC-ClinicDB | 息肉分割 | 分割 |  表 3: 调查的主动学习方法总结。'
- en: '|  | Year | Venues | Modality | ROIs | Dataset | Clinical Task | Technical
    Task |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '|  | 年份 | 会议 | 模态 | ROI | 数据集 | 临床任务 | 技术任务 |'
- en: '| Nath et al. [[2022](#bib.bib132)] | 2022 | MICCAI | CT | Liver | MSD | Liver
    & Tumor Segmentation | Segmentation |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| Nath et al. [[2022](#bib.bib132)] | 2022 | MICCAI | CT | 肝脏 | MSD | 肝脏与肿瘤分割
    | 分割 |'
- en: '| Hepatic Vessels | MSD | Hepatic Vessels & Tumor Segmentation | Segmentation
    |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| 肝脏血管 | MSD | 肝脏血管与肿瘤分割 | 分割 |'
- en: '| Bai et al. [[2022](#bib.bib10)] | 2022 | MICCAI | Wireless Capsule Endoscopy
    | Colon | CAD-CAP | Polyp Segmentation | Segmentation |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| Bai et al. [[2022](#bib.bib10)] | 2022 | MICCAI | 无线胶囊内镜 | 结肠 | CAD-CAP |
    息肉分割 | 分割 |'
- en: '| Balaram et al. [[2022](#bib.bib14)] | 2022 | MICCAI | X-ray | Chest | Chestx-ray8
    | Thoracic Disease Diagnosis | Classification |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| Balaram 等 [[2022](#bib.bib14)] | 2022 | MICCAI | X光 | 胸部 | Chestx-ray8 |
    胸科疾病诊断 | 分类 |'
- en: '| Wu et al. [[2022c](#bib.bib202)] | 2022 | MICCAI | CT | Liver | LiTS | Liver
    & Tumor Segmentation | Segmentation |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| Wu 等 [[2022c](#bib.bib202)] | 2022 | MICCAI | CT | 肝脏 | LiTS | 肝脏与肿瘤分割 |
    分割 |'
- en: '| CT, MRI | Liver | CHAOS | Liver & Tumor Segmentation | Segmentation |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| CT, MRI | 肝脏 | CHAOS | 肝脏与肿瘤分割 | 分割 |'
- en: '| CT | Liver | Sliver07 | Liver & Tumor Segmentation | Segmentation |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| CT | 肝脏 | Sliver07 | 肝脏与肿瘤分割 | 分割 |'
- en: '| CT | Liver | MSD | Liver & Tumor Segmentation | Segmentation |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| CT | 肝脏 | MSD | 肝脏与肿瘤分割 | 分割 |'
- en: '| Kothawade et al. [[2022c](#bib.bib101)] | 2022 | MICCAIW | X-ray | Chest
    | PneumoniaMNIST | Pneumonia & Normal Classification | Classification |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| Kothawade 等 [[2022c](#bib.bib101)] | 2022 | MICCAIW | X光 | 胸部 | PneumoniaMNIST
    | 肺炎与正常分类 | 分类 |'
- en: '| Histopathology | Colon | PathMNIST | Survival Prediction | Classification
    |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| 组织病理学 | 结肠 | PathMNIST | 生存预测 | 分类 |'
- en: '| Mircoscopy | Peripheral Blood | BloodMNIST | Cell Type Classification | Classification
    |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 显微镜 | 外周血 | BloodMNIST | 细胞类型分类 | 分类 |'
- en: '| Dermscopy | Skin | ISIC 2018 | Skin Lesion Diagnosis | Classification |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 皮肤镜 | 皮肤 | ISIC 2018 | 皮肤病变诊断 | 分类 |'
- en: '| Fundus | Eye | APTOS-2019 | Diabetic Retinopathy Detection | Classification
    |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 眼底 | 眼睛 | APTOS-2019 | 糖尿病视网膜病变检测 | 分类 |'
- en: '| Li et al. [[2022](#bib.bib109)] | 2022 | TMI | Histopathology | Prostate
    | PANDA | Gleason Grading of Prostate Cancer | Classification |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| Li 等 [[2022](#bib.bib109)] | 2022 | TMI | 组织病理学 | 前列腺 | PANDA | 前列腺癌Gleason分级
    | 分类 |'
- en: '| Mahapatra et al. [[2022](#bib.bib122)] | 2022 | TMI | X-ray | Chest | ChestXpert
    | Thoracic Disease Diagnosis | Classification |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| Mahapatra 等 [[2022](#bib.bib122)] | 2022 | TMI | X光 | 胸部 | ChestXpert | 胸科疾病诊断
    | 分类 |'
- en: '| Jin et al. [[2023b](#bib.bib81)] | 2023 | EAAI | Dermscopy | Skin | ISIC
    2018 | Skin Lesion Segmentation | Segmentation |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| Jin 等 [[2023b](#bib.bib81)] | 2023 | EAAI | 皮肤镜 | 皮肤 | ISIC 2018 | 皮肤病变分割
    | 分割 |'
- en: '| X-ray | Chest | Jaeger et al. [[2013](#bib.bib77)] | Lung Segmentation |
    Segmentation |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| X光 | 胸部 | Jaeger 等 [[2013](#bib.bib77)] | 肺部分割 | 分割 |'
- en: '| Sadafi et al. [[2023](#bib.bib158)] | 2023 | ISBI | Histopathology | Breast
    | CAMELYON17 | Detection of Cancer Metastasesin Lymph Nodes | Classification |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| Sadafi 等 [[2023](#bib.bib158)] | 2023 | ISBI | 组织病理学 | 乳腺 | CAMELYON17 |
    检测淋巴结中的癌症转移 | 分类 |'
- en: '| Qu et al. [[2023](#bib.bib148)] | 2023 | MICCAI | Histopathology | Colon
    | NCT-CRC-HE-100K | Colorectal Cancer Diagnosis | Classification |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| Qu 等 [[2023](#bib.bib148)] | 2023 | MICCAI | 组织病理学 | 结肠 | NCT-CRC-HE-100K
    | 结直肠癌诊断 | 分类 |'
- en: '| Chen et al. [[2023](#bib.bib31)] | 2023 | MIDL | Histopathology | Colon |
    PathMNIST | Survival Prediction | Classification |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等 [[2023](#bib.bib31)] | 2023 | MIDL | 组织病理学 | 结肠 | PathMNIST | 生存预测
    | 分类 |'
- en: '| CT | Abdomen | OrganAMNIST | Classification of Body Organs | Classification
    |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| CT | 腹部 | OrganAMNIST | 身体器官分类 | 分类 |'
- en: '| Mircoscopy | Peripheral Blood | BloodMNIST | Cell Type Classification | Classification
    |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| 显微镜 | 外周血 | BloodMNIST | 细胞类型分类 | 分类 |'
- en: '| Lou et al. [[2023](#bib.bib118)] | 2023 | TMI | Histopathology | Seven Organs
    | TCGA-KUMAR | Nuclei Segmentation | Segmentation |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| Lou 等 [[2023](#bib.bib118)] | 2023 | TMI | 组织病理学 | 七个器官 | TCGA-KUMAR | 细胞核分割
    | 分割 |'
- en: '| Breast | TNBC | Nuclei Segmentation | Segmentation |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| 乳腺 | TNBC | 细胞核分割 | 分割 |'
- en: '| Seven Organs | MoNuSeg | Nuclei Segmentation | Segmentation |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 七个器官 | MoNuSeg | 细胞核分割 | 分割 |'
- en: 5.1 Active Learning in Medical Image Classification
  id: totrans-412
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 医学图像分类中的主动学习
- en: Some common clinical tasks, such as disease diagnosis, cancer staging, and prognostic
    prediction, can be formulated as medical image classification. Most AL works in
    medical imaging classification directly employ general methods, such as using
    class-balancing sampling in §[3.3.2](#S3.SS3.SSS2 "3.3.2 Class-balance Sampling
    ‣ 3.3 Sampling Strategy ‣ 3 Core Methods of Active Learning ‣ A comprehensive
    survey on deep active learning and its applications in medical image analysis")
    to mitigate the long-tail effect of medical imaging datasets. However, specialized
    design of AL algorithms is required for certain modalities of medical image classification.
    For example, the classification of chest X-rays often involves the idea of multi-label.
    Besides, classifying pathological whole-slide images typically needs to be formulated
    as a multiple instance learning problem. This section will introduce AL works
    specifically targeted at classification problems in chest X-rays and pathological
    whole-slide images.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的临床任务，如疾病诊断、癌症分期和预后预测，可以表述为医学图像分类。大多数医学图像分类中的 AL 工作直接采用通用方法，例如使用类平衡采样在 §[3.3.2](#S3.SS3.SSS2
    "3.3.2 Class-balance Sampling ‣ 3.3 Sampling Strategy ‣ 3 Core Methods of Active
    Learning ‣ A comprehensive survey on deep active learning and its applications
    in medical image analysis") 中缓解医学影像数据集的长尾效应。然而，对于某些医学图像分类的模态，需要专门设计 AL 算法。例如，胸部
    X 射线的分类通常涉及多标签的概念。此外，对病理全切片图像的分类通常需要被表述为一个多实例学习问题。本节将介绍专门针对胸部 X 射线和病理全切片图像分类问题的
    AL 工作。
- en: 5.1.1 Chest X-ray and Multi-label Classification
  id: totrans-414
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1 胸部 X 射线和多标签分类
- en: Chest X-ray examinations are crucial for screening and diagnosing lung, cardiovascular,
    skeletal, and other thoracic diseases. Computer-aided diagnosis in this domain
    has been extensively researched, including AL works aimed at reducing annotation
    costs for physicians. Mahapatra et al. [[2021](#bib.bib123)] introduced saliency
    maps to select informative samples for annotation. To aggregate the per-pixel
    saliency maps into a single scalar, they explored three different approaches,
    including computing the kurtosis of the saliency map, utilizing multivariate radiomic
    features, and combining deep features of autoencoders and clustering. Results
    demonstrated that the aggregation using deep features performs the best. Nguyen
    et al. [[2021](#bib.bib133)] introduced a gist-set to select samples near the
    decision boundary. Besides, uncertain samples with high entropy were sent for
    annotation, while the confident samples were assigned as pseudo-labels. Additionally,
    they adopted momentum updates to enhance the stability of the sample predictions.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 胸部 X 射线检查对筛查和诊断肺部、心血管、骨骼及其他胸腔疾病至关重要。在这个领域中，计算机辅助诊断已被广泛研究，包括旨在降低医生注释成本的主动学习（AL）工作。Mahapatra
    等人 [[2021](#bib.bib123)] 引入了显著性图以选择用于注释的信息样本。为了将每个像素的显著性图聚合为一个标量，他们探讨了三种不同的方法，包括计算显著性图的峰度、利用多变量放射特征以及结合自编码器的深度特征和聚类。结果表明，使用深度特征的聚合效果最佳。Nguyen
    等人 [[2021](#bib.bib133)] 引入了一个概要集来选择接近决策边界的样本。此外，高熵的不确定样本被送去注释，而自信的样本则被分配为伪标签。此外，他们采用了动量更新以提高样本预测的稳定性。
- en: However, multiple diseases and abnormalities often coexist simultaneously in
    diagnosing chest X-rays. Therefore, multi-label classification has been introduced,
    allowing each sample to be categorized into multiple classes [Baltruschat et al.,
    [2019](#bib.bib15)]. Consequently, AL algorithms for chest X-ray classification
    must adapt to the multi-label setting. Balaram et al. [[2022](#bib.bib14)] modified
    the EDL-based AL to accommodate the multi-label setting. Specifically, they transformed
    the Dirichlet distribution in EDL into multiple Beta distributions, each corresponding
    to one class label. They then calculated the entropy of the Beta distributions
    as the aleatoric uncertainty of the sample. Additionally, they incorporated semi-supervised
    methods like MeanTeacher [Tarvainen and Valpola, [2017](#bib.bib179)], VAT [Miyato
    et al., [2018](#bib.bib128)], and NoTeacher [Unnikrishnan et al., [2021](#bib.bib183)]
    to further reduce annotation costs. Built upon saliency maps, Mahapatra et al.
    [[2022](#bib.bib122)] further introduced GNN to model the inter-relationships
    between different labels. In this work, each class was treated as a node in a
    graph, with the relationships between classes represented as edges. They employed
    various techniques to aggregate information between different classes.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在诊断胸部 X 射线时，多个疾病和异常常常同时存在。因此，引入了多标签分类，使得每个样本可以被分类到多个类别中 [Baltruschat et al.,
    [2019](#bib.bib15)]。因此，胸部 X 射线分类的主动学习（AL）算法必须适应多标签设置。Balaram 等人 [[2022](#bib.bib14)]
    修改了基于 EDL 的主动学习以适应多标签设置。具体而言，他们将 EDL 中的 Dirichlet 分布转换为多个 Beta 分布，每个 Beta 分布对应一个类别标签。然后，他们计算
    Beta 分布的熵作为样本的随机不确定性。此外，他们还结合了 MeanTeacher [Tarvainen and Valpola, [2017](#bib.bib179)]、VAT
    [Miyato et al., [2018](#bib.bib128)] 和 NoTeacher [Unnikrishnan et al., [2021](#bib.bib183)]
    等半监督方法，以进一步降低注释成本。在显著性图的基础上，Mahapatra 等人 [[2022](#bib.bib122)] 进一步引入了 GNN 来建模不同标签之间的相互关系。在这项工作中，每个类别被视为图中的一个节点，类别之间的关系表示为边。他们采用各种技术来聚合不同类别之间的信息。
- en: 5.1.2 Pathological Whole-slide Images and Multiple Instance Learning
  id: totrans-417
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.2 病理全切片图像和多实例学习
- en: Compared to modalities like X-ray, CT, and MRI, pathological whole-slide images
    (WSIs) provide microscopic details at the cellular level, making them critically
    important for tasks such as cancer staging and prognostic prediction. However,
    WSIs are very large, with maximum resolutions reaching $100,000\times 100,000$
    pixels. To handle these large images for deep learning, WSIs are usually divided
    into many small patches. Fully supervised methods require annotations for each
    patch, resulting in high annotation costs. AL can effectively improve annotation
    efficiency. For instance, in classifying breast pathological images, Qi et al.
    [[2019](#bib.bib145)] used entropy as the uncertainty metric. Uncertain patches
    were sent for annotation, whereas those with low entropy were given pseudo-labels
    to assist training.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 与 X 射线、CT 和 MRI 等模式相比，病理全切片图像（WSIs）提供了细胞级别的显微细节，使其在癌症分期和预后预测等任务中至关重要。然而，WSIs
    非常大，最大分辨率可达到 $100,000\times 100,000$ 像素。为了处理这些大型图像进行深度学习，WSIs 通常被划分为许多小块。完全监督的方法需要对每个小块进行注释，从而导致高昂的注释成本。主动学习可以有效提高注释效率。例如，在对乳腺病理图像进行分类时，Qi
    等人 [[2019](#bib.bib145)] 使用熵作为不确定性度量。将不确定的小块送去注释，而那些熵低的则给予伪标签以协助训练。
- en: Nevertheless, pathologists might only provide WSI-level annotations in real-world
    clinical scenarios. Consequently, a prevailing direction in research is to formulate
    WSI classification as the weakly-supervised multi-instance learning (MIL) [Qu
    et al., [2022](#bib.bib147)]. In this framework, the entire WSI is viewed as a
    bag, and patches within each WSI are treated as instances within that bag. A well-trained
    MIL learner can automatically identify relevant patches based on WSI-level labels,
    thus significantly reducing annotation costs. For example, a trained MIL classifier
    can automatically spot related patches by annotating whether or not cancer metastasis
    is present in a WSI. Nonetheless, task-relevant patches are often outnumbered
    by irrelevant ones, making MIL convergence more challenging. In MIL-based pathological
    WSI classification, AL filters out irrelevant patches and selects informative
    patches for annotation. Qu et al. [[2023](#bib.bib148)] found that in addition
    to patches related to the target (e.g., tumors, lymph nodes, and normal cells),
    WSIs contain many irrelevant patches (e.g., fat, stroma, and debris). Therefore,
    they adopted the open-set AL [Ning et al., [2022](#bib.bib134)], in which the
    unlabeled pool contained both target and non-target class samples. They combined
    feature distributions with prediction uncertainty to select informative and relevant
    patches of the target class for annotation. Based on attention-based MIL, Sadafi
    et al. [[2023](#bib.bib158)] adopted MC Dropout to estimate both attention and
    classification uncertainties of each patch, then sent the most uncertain patches
    in each WSI for expert annotation.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，病理学家在实际临床场景中可能只提供WSI级别的注释。因此，当前研究中的一个主要方向是将WSI分类制定为弱监督的多实例学习（MIL）[Qu et
    al., [2022](#bib.bib147)]。在这个框架中，整个WSI被视为一个袋子，WSI中的各个补丁被视为该袋子中的实例。一个训练良好的MIL学习器可以根据WSI级别的标签自动识别相关补丁，从而显著降低注释成本。例如，一个训练过的MIL分类器可以通过注释WSI中是否存在癌症转移来自动识别相关的补丁。然而，与任务相关的补丁往往比不相关的补丁少，使得MIL收敛变得更加困难。在基于MIL的病理WSI分类中，主动学习（AL）过滤掉不相关的补丁，并选择信息量大的补丁进行注释。Qu
    et al. [[2023](#bib.bib148)]发现，除了与目标相关的补丁（例如，肿瘤、淋巴结和正常细胞）外，WSI中还包含许多不相关的补丁（例如，脂肪、间质和碎片）。因此，他们采用了开放集主动学习
    [Ning et al., [2022](#bib.bib134)]，其中未标记池包含目标类和非目标类样本。他们结合了特征分布和预测不确定性来选择目标类的信息性和相关补丁进行注释。基于注意力机制的MIL，Sadafi
    et al. [[2023](#bib.bib158)]采用MC Dropout来估计每个补丁的注意力和分类不确定性，然后将每个WSI中最不确定的补丁送去专家注释。
- en: 5.2 Active Learning in Medical Image Segmentation
  id: totrans-420
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 医学图像分割中的主动学习
- en: Segmentation is one of the most common tasks in medical image analysis, capable
    of precisely locating anatomical structures or pathological lesions. However,
    training a segmentation model requires pixel-level annotation, which is time-consuming
    and labor-intensive for doctors. Therefore, active learning has been widely used
    in medical image segmentation and has become an important method to reduce annotation
    costs. Based on the unique traits of medical imaging, this section will focus
    on specialized designs in AL for medical image segmentation, including slice-based
    annotation, one-shot annotation, and annotation cost.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 分割是医学图像分析中最常见的任务之一，能够精确定位解剖结构或病理损伤。然而，训练一个分割模型需要像素级的注释，这对医生来说是耗时且劳动密集的。因此，主动学习在医学图像分割中得到了广泛应用，成为降低注释成本的重要方法。基于医学成像的独特特征，本节将重点讨论医学图像分割中主动学习的专门设计，包括切片基础注释、一次性注释和注释成本。
- en: 5.2.1 Slice-based Annotation
  id: totrans-422
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1 切片基础注释
- en: In 3D modalities like CT and MRI, adjacent 2D slices often exhibit significant
    semantic redundancy. Consequently, annotating only the key slices of each sample
    can reduce annotation costs. Representativeness-based methods have been widely
    applied in this line of work. For instance, Zheng et al. [[2020](#bib.bib228)]
    utilized autoencoders to learn the semantic features of each slice, then selected
    and annotated key slices from axial, sagittal, and coronal planes with a strategy
    similar to RA. Specifically, they initially trained three 2D segmentation networks
    and one 3D segmentation network, where the inputs for the 2D networks are slices
    from different planes. These segmentation networks were used to generate four
    sets of pseudo-labels and subsequently to train the final 3D segmentation network.
    Results showed that this slice-based strategy outperforms uniform sampling. Building
    upon this method, Wu et al. [[2022c](#bib.bib202)] incorporated a self-attention
    module into the autoencoder to enhance slice-level feature learning. In recent
    years, uncertainty methods have been introduced for selecting key slices. In interactive
    segmentation of 3D medical images, Zhou et al. [[2021a](#bib.bib230)] and their
    subsequent work [Zhou et al., [2022](#bib.bib231)] introduced a quality assessment
    module to provide a predicted average IoU score for each slice. They chose the
    slice with the lowest IoU score in each volume for the next round of interactive
    segmentation. In muscle segmentation of CT images, Hiasa et al. [[2020](#bib.bib66)]
    selected key slices and key regions. This work adopted clustering to select key
    slices and further selected regions with high uncertainty within each key slice
    for annotation.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 在CT和MRI等3D模式中，相邻的2D切片常常表现出显著的语义冗余。因此，仅注释每个样本的关键切片可以降低注释成本。基于代表性的方法在这一领域得到了广泛应用。例如，Zheng等人[[2020](#bib.bib228)]利用自编码器学习每个切片的语义特征，然后从轴向、矢状面和冠状面中选择并注释关键切片，其策略类似于RA。具体而言，他们最初训练了三个2D分割网络和一个3D分割网络，其中2D网络的输入是来自不同平面的切片。这些分割网络用于生成四组伪标签，随后用于训练最终的3D分割网络。结果表明，这种基于切片的策略优于均匀采样。在此方法基础上，Wu等人[[2022c](#bib.bib202)]将自注意力模块纳入自编码器中，以增强切片级特征学习。近年来，引入了不确定性方法来选择关键切片。在3D医学图像的交互式分割中，Zhou等人[[2021a](#bib.bib230)]及其后续工作[Zhou
    et al., [2022](#bib.bib231)]引入了质量评估模块，为每个切片提供预测的平均IoU得分。他们选择每个体积中IoU得分最低的切片进行下一轮交互式分割。在CT图像的肌肉分割中，Hiasa等人[[2020](#bib.bib66)]选择了关键切片和关键区域。这项工作采用了聚类方法选择关键切片，并进一步选择每个关键切片中不确定性较高的区域进行注释。
- en: 5.2.2 One-shot Annotation
  id: totrans-424
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2 一次性注释
- en: Currently, most AL works require multiple rounds of annotation. However, this
    setting may not be practical in medical image segmentation. Multi-round annotation
    requires physicians to be readily available for each round of labeling, which
    is unrealistic in practice. If physicians cannot complete the annotations on time,
    the AL process must be suspended. In contrast, one-shot annotation eliminates
    the need for multiple interactions with physicians. It also allows for selecting
    valuable samples in a single round, thus reducing time costs. Both one-shot annotation
    and cold-start AL aim to select the most optimal initial annotations. However,
    the former allows for a higher annotation budget and strictly limits the number
    of interactions with experts to just one. Most relevant works combine self-supervised
    features and specific sampling strategies to achieve one-shot annotation. For
    example, RA [Zheng et al., [2019](#bib.bib227)] is one of the earliest works in
    one-shot AL for medical image segmentation. They applied the VAE feature and a
    representativeness strategy to select informative samples for annotation in one
    shot. RA performed excellently in segmenting gland of pathological images, whole-heart
    of MRI images, and fungal of electron microscopic images. Jin et al. [[2022b](#bib.bib83)]
    combined features of contrastive learning with farthest-first sampling to achieve
    one-shot annotation. The proposed method demonstrated effectiveness on the ISIC
    2018 and lung segmentation datasets. Additionally, Jin et al. [[2023b](#bib.bib81)]
    utilized auto-encoding transformations for self-supervised feature learning. They
    selected and annotated samples with high density based on reachable distance.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，大多数主动学习（AL）工作需要多轮注释。然而，这种设置在医学图像分割中可能并不实际。多轮注释要求医生在每轮标注时都能随时待命，这在实际操作中是不现实的。如果医生不能按时完成注释，AL
    过程必须被暂停。相比之下，一次性注释消除了与医生多次互动的需要。它还允许在一次轮次中选择有价值的样本，从而减少时间成本。一-shot 注释和冷启动 AL 都旨在选择最优的初始注释。然而，前者允许更高的注释预算，并严格限制与专家的互动次数仅为一次。大多数相关工作结合了自监督特征和特定的采样策略以实现一次性注释。例如，RA
    [Zheng et al., [2019](#bib.bib227)] 是医学图像分割中最早的一个-shot AL 工作之一。他们应用了 VAE 特征和代表性策略以在一次性注释中选择信息丰富的样本。RA
    在病理图像中的腺体分割、MRI 图像中的全心分割以及电子显微镜图像中的真菌分割方面表现优异。Jin 等人 [[2022b](#bib.bib83)] 将对比学习的特征与最远优先采样结合，以实现一次性注释。所提出的方法在
    ISIC 2018 和肺部分割数据集上表现出了有效性。此外，Jin 等人 [[2023b](#bib.bib81)] 利用自编码变换进行自监督特征学习。他们基于可达距离选择并注释了高密度的样本。
- en: 5.2.3 Annotation Cost
  id: totrans-426
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.3 注释成本
- en: Current AL works often assume equal annotation costs for each sample. Yet, this
    is not the case in medical image segmentation, where the time to annotate different
    samples can differ greatly. AL techniques can better support physicians by considering
    annotation costs (e.g., annotation time). Nevertheless, there is still limited
    research in this specific domain. In detecting intracranial hemorrhage of CT scans,
    Kuo et al. [[2018](#bib.bib103)] combined predictive disagreement with annotation
    time to select samples for annotation. Specifically, they adopted the Jensen-Shannon
    divergence to measure the disagreement between the outputs of multiple models.
    Annotation time for each sample was estimated by the length of the segmentation
    boundary and the number of connected components. In this work, AL was framed as
    a 0-1 knapsack problem, and dynamic programming is used to solve this problem
    for selecting informative samples. In brain structure segmentation, Atzeni et al.
    [[2022](#bib.bib9)] further considered the spatial relationships between multiple
    regions of interest to more accurately estimate the annotation cost. Moreover,
    the average Dice coefficient of previous rounds was used to predict the average
    Dice for current segmentation results. They selected and annotated regions that
    can maximize the average Dice.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的 AL 研究通常假设每个样本的标注成本相等。然而，在医学图像分割中情况并非如此，不同样本的标注时间可能差异很大。AL 技术可以通过考虑标注成本（例如标注时间）更好地支持医生。然而，这一特定领域的研究仍然有限。在检测
    CT 扫描的颅内出血时，Kuo et al. [[2018](#bib.bib103)] 将预测不一致与标注时间结合起来，以选择样本进行标注。具体而言，他们采用了
    Jensen-Shannon 散度来测量多个模型输出之间的不一致。每个样本的标注时间通过分割边界的长度和连接组件的数量来估算。在这项工作中，AL 被构建为一个
    0-1 胶囊问题，并使用动态规划来解决这个问题以选择信息量大的样本。在脑结构分割中，Atzeni et al. [[2022](#bib.bib9)] 进一步考虑了多个感兴趣区域之间的空间关系，以更准确地估算标注成本。此外，使用之前轮次的平均
    Dice 系数来预测当前分割结果的平均 Dice。他们选择并标注了可以最大化平均 Dice 的区域。
- en: 5.3 Active Learning in Medical Image Reconstruction
  id: totrans-428
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 医学图像重建中的主动学习
- en: AL can also be applied in medical image reconstruction. AL methods can help
    minimize the observations needed for modalities that require a long imaging time.
    This accelerates the imaging process and shortens the waiting period for patients.
    In this section, we’ll explore the application of AL in the reconstruction of
    MRI, CT, and electron microscopy.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: AL 也可以应用于医学图像重建。AL 方法可以帮助减少需要长时间成像的模态所需的观察量。这加快了成像过程，并缩短了患者的等待时间。在这一部分，我们将探讨
    AL 在 MRI、CT 和电子显微镜重建中的应用。
- en: Deep learning has been applied to accelerate MRI acquisition and reconstruction.
    A common practice is to reduce k-space sampling through a fixed mask and use a
    deep model to reconstruct the undersampled MRI [Qin et al., [2018](#bib.bib146)].
    To further improve the imaging speed, learnable sampling in AL can be applied
    to select the next measurement locations in k-space. For example, Zhang et al.
    [[2019](#bib.bib225)] adopted adversarial learning to train an evaluator for selecting
    the next row in k-space. Pineda et al. [[2020](#bib.bib142)] utilized reinforcement
    learning to train a dual deep Q-network for active sampling in k-space. Bakker
    et al. [[2020](#bib.bib13)] adopted policy gradient in reinforcement learning
    to train a policy network for adaptive sampling in k-space. The reward for the
    policy network was based on the improvement in structural similarity before and
    after the acquisition. Additionally, Bakker et al. [[2022](#bib.bib12)] explored
    how to jointly optimize the reconstruction and acquisition networks.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习已被应用于加速 MRI 获取和重建。常见的做法是通过固定掩膜减少 k 空间采样，并使用深度模型重建欠采样的 MRI [Qin et al., [2018](#bib.bib146)]。为了进一步提高成像速度，可以在
    AL 中应用可学习采样来选择 k 空间中的下一个测量位置。例如，Zhang et al. [[2019](#bib.bib225)] 采用对抗学习训练评估器，以选择
    k 空间中的下一行。Pineda et al. [[2020](#bib.bib142)] 利用强化学习训练了一个双深度 Q 网络，用于在 k 空间中主动采样。Bakker
    et al. [[2020](#bib.bib13)] 采用强化学习中的策略梯度训练了一个策略网络，用于在 k 空间中自适应采样。该策略网络的奖励基于成像前后结构相似性的改进。此外，Bakker
    et al. [[2022](#bib.bib12)] 探索了如何共同优化重建和获取网络。
- en: In addition to MRI imaging, AL has been employed in CT reconstruction as illustrated
    by Wang et al. [[2022a](#bib.bib186)]. They adaptively chose the scanning angles
    tailored to individual patients, leading to a reduction in both radiation exposure
    and scanning duration. In electron microscopy, Mi et al. [[2020](#bib.bib127)]
    initially enhanced low-resolution images to high-resolution and then predicted
    the location of region-of-interest and reconstruction error. A weighted DPP based
    on reconstruction error was applied to select pixels that needed rescanned. Results
    showed that weighted DPP maintained both low reconstruction error and spatial
    diversity.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 MRI 成像，主动学习也被应用于 CT 重建，正如 Wang et al. [[2022a](#bib.bib186)] 所示。他们根据个体患者量身定制扫描角度，从而减少了辐射曝光和扫描时间。在电子显微镜中，Mi
    et al. [[2020](#bib.bib127)] 首先将低分辨率图像提升为高分辨率，然后预测了感兴趣区域的位置和重建误差。基于重建误差的加权 DPP
    被用来选择需要重新扫描的像素。结果显示，加权 DPP 既保持了低重建误差，也保持了空间多样性。
- en: 6 Challenges and Future Perspectives
  id: totrans-432
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 挑战与未来展望
- en: Currently, annotation scarcity is a significant bottleneck hindering the development
    of medical image analysis. AL improves annotation efficiency by selectively querying
    the most informative samples for annotation. This survey reviews the recent developments
    in deep active learning, focusing on the evaluation of informativeness, sampling
    strategies, integration with other label-efficient techniques, and the application
    of AL in medical image analysis. In this section, we will discuss the existing
    challenges faced by AL in medical image analysis and its future perspectives.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，标注稀缺是制约医学图像分析发展的一个重大瓶颈。主动学习通过选择最有信息量的样本进行标注，提高了标注效率。本文综述了深度主动学习的最新发展，重点讨论了信息量评估、采样策略、与其他标注高效技术的结合以及主动学习在医学图像分析中的应用。在本节中，我们将讨论主动学习在医学图像分析中面临的现有挑战以及其未来展望。
- en: 6.1 Towards Active Learning with Better Uncertainty
  id: totrans-434
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 朝着更好不确定性的主动学习
- en: In AL, uncertainty plays a pivotal role. However, it would be beneficial if
    the uncertainty more directly highlighted the model’s mistakes. We can enhance
    the model’s performance by querying samples with inaccurate predictions.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 在主动学习中，不确定性起着关键作用。然而，如果不确定性能够更直接地突出模型的错误，那将更有益。我们可以通过查询预测不准确的样本来提高模型的性能。
- en: Recently, many works have adopted learnable performance estimation for quality
    control of deep model outputs. For instance, the recently proposed segment anything
    model (SAM) [Kirillov et al., [2023](#bib.bib94)] provides IoU estimates for each
    mask to evaluate its quality. In medical image analysis, automated quality control
    is critical to ensure the reliability and safety of the deep model outputs [Kohlberger
    et al., [2012](#bib.bib97)]. For example, Wang et al. [[2020c](#bib.bib191)] employed
    deep generative models for learnable quality control in cardiac MRI segmentation,
    where the predicted Dice scores showed a strong linear relationship with the real
    ones. Additionally, Billot et al. [[2023](#bib.bib20)] used an additional neural
    network to predict the Dice coefficient of brain tissue segmentation results.
    Overall, learnable performance estimation can accurately predict the quality of
    model outputs. Hence, delving deeper into their potential for uncertainty-based
    AL is crucial to effectively tackle the issue of over-confidence.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，许多研究开始采用可学习的性能估计来进行深度模型输出的质量控制。例如，最近提出的分割任意模型（SAM）[Kirillov et al., [2023](#bib.bib94)]
    提供了每个掩膜的 IoU 估计值，以评估其质量。在医学图像分析中，自动化质量控制对于确保深度模型输出的可靠性和安全性至关重要 [Kohlberger et
    al., [2012](#bib.bib97)]。例如，Wang et al. [[2020c](#bib.bib191)] 使用深度生成模型进行心脏 MRI
    分割中的可学习质量控制，其中预测的 Dice 分数与实际分数表现出强烈的线性关系。此外，Billot et al. [[2023](#bib.bib20)]
    使用额外的神经网络来预测脑组织分割结果的 Dice 系数。总体而言，可学习的性能估计能够准确预测模型输出的质量。因此，深入探讨其在不确定性基础上的主动学习潜力对于有效解决过度自信的问题至关重要。
- en: Moreover, improving the probability calibration of model prediction is a promising
    way to mitigate the over-confidence issue. Calibration [Guo et al., [2017](#bib.bib60),
    Mehrtash et al., [2020](#bib.bib125)] reflects the consistency between model prediction
    probabilities and the ground truth. A well-calibrated model should display a strong
    correlation between confidence and accuracy. For instance, if a perfect-calibrated
    polyp classifier gives an average confidence score of 0.9 on a dataset, it means
    that 90% of those samples should indeed have polyps. In reality, deep models generally
    suffer from the issue of over-confidence, which essentially means that they are
    not well-calibrated. Currently, only a few uncertainty-based AL works have considered
    probability calibration. For instance, Beluch et al. [[2018](#bib.bib16)] found
    that the model ensemble has better calibration than MC Dropout. Xie et al. [[2022c](#bib.bib205)]
    mitigated miscalibration by considering all possible prediction outcomes in the
    Dirichlet distribution. However, these methods are limited to proposing a better
    uncertainty metric and validating the calibration quality post-hoc. Existing calibration
    methods [Guo et al., [2017](#bib.bib60), Ding et al., [2021](#bib.bib42)] directly
    adjusted the distribution of prediction probabilities. However, these methods
    require an additional labeled dataset, thus limiting their practical applicability.
    Therefore, integrating probability calibration into uncertainty-based AL represents
    a valuable research direction worth exploring.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，提高模型预测的概率校准是缓解过度自信问题的一个有前景的方式。校准[Guo et al., [2017](#bib.bib60), Mehrtash
    et al., [2020](#bib.bib125)] 反映了模型预测概率与真实情况之间的一致性。一个良好校准的模型应展示出置信度与准确度之间的强相关性。例如，如果一个完全校准的息肉分类器在数据集上的平均置信度得分为0.9，则意味着90%的样本确实应该有息肉。实际上，深度模型通常存在过度自信的问题，这本质上意味着它们没有得到良好的校准。目前，仅有少数基于不确定性的主动学习工作考虑了概率校准。例如，Beluch
    et al. [[2018](#bib.bib16)] 发现模型集成的校准效果优于MC Dropout。Xie et al. [[2022c](#bib.bib205)]
    通过考虑Dirichlet分布中的所有可能预测结果来缓解误校准。然而，这些方法的局限在于仅提出了更好的不确定性度量，并在事后验证校准质量。现有的校准方法[Guo
    et al., [2017](#bib.bib60), Ding et al., [2021](#bib.bib42)] 直接调整预测概率的分布。然而，这些方法需要额外的标记数据集，从而限制了它们的实际应用。因此，将概率校准整合到基于不确定性的主动学习中，代表了一个值得探索的宝贵研究方向。
- en: 6.2 Towards Active Learning with Better Representativeness
  id: totrans-438
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 朝向具有更好代表性的主动学习
- en: Representativeness-based AL effectively utilizes feature representations and
    data distributions for sample selection. Cover-based and diversity-based AL methods
    implicitly capture the data distribution, whereas density-based AL explicitly
    estimates it. However, the latter requires supplementary strategies to ensure
    diversity. As the core of density-based AL, density estimation in high-dimensional
    spaces has always been challenging. Popular density estimation methods, such as
    kernel density estimation and GMM, may face challenges in high-dimensional spaces.
    In future research, we can consider introducing density estimators tailored to
    high-dimensional spaces.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 基于代表性的主动学习（AL）有效利用特征表示和数据分布进行样本选择。覆盖度基础和多样性基础的主动学习方法隐式地捕捉数据分布，而密度基础的主动学习方法则显式地估计数据分布。然而，后者需要额外的策略来确保多样性。作为密度基础主动学习的核心，高维空间中的密度估计一直是一个挑战。流行的密度估计方法，如核密度估计和高斯混合模型（GMM），在高维空间中可能面临挑战。在未来的研究中，我们可以考虑引入针对高维空间量身定制的密度估计器。
- en: 6.3 Towards Active Learning with Weak Annotation
  id: totrans-440
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 朝向具有弱注释的主动学习
- en: 'In §[4.4](#S4.SS4 "4.4 Region-based Active Learning: Smaller Labeling Unit
    ‣ 4.3 Active Domain Adaptation: Tackling Distribution Shift ‣ 4.2.2 Combination
    of Active Learning and Self-supervised Learning ‣ 4.2 Self-supervised Learning:
    Utilizing Pre-trained Model ‣ 4.1.2 Consistency Regularization ‣ 4.1 Semi-supervised
    Learning: Utilizing Unlabeled Data ‣ 4 Integration of Active Learning and Other
    Label-Efficient Techniques ‣ A comprehensive survey on deep active learning and
    its applications in medical image analysis"), we discuss region-based active learning,
    which only requires region-level annotation of a sample. However, annotating all
    pixels within the region is still needed. Some AL works have incorporated weak
    annotations to simplify the task for annotators. In object detection tasks, Vo
    et al. [[2022](#bib.bib184)] trained deep models with image-level annotation.
    They selected samples with box-in-box prediction results and annotated them with
    bounding boxes. Moreover, Lyu et al. [[2023](#bib.bib119)] adopted disagreement
    to choose which objects are worth annotating. Rather than annotating all objects
    within the image, they only required box-level annotations for a subset of objects.
    In AL of instance segmentation, Tang et al. [[2022](#bib.bib178)] only required
    annotations for each object’s class label and bounding box, without the annotation
    of fine-grained segmentation masks. In future research, AL based on weak annotations
    is a direction worthy of in-depth exploration.'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 在§[4.4](#S4.SS4 "4.4 基于区域的主动学习：更小的标注单元 ‣ 4.3 主动领域适应：应对分布偏移 ‣ 4.2.2 主动学习与自监督学习的结合
    ‣ 4.2 自监督学习：利用预训练模型 ‣ 4.1.2 一致性正则化 ‣ 4.1 半监督学习：利用未标注数据 ‣ 4 主动学习与其他标签高效技术的整合 ‣
    深度主动学习及其在医学图像分析中的应用的全面调查")中，我们讨论了基于区域的主动学习，这只需要对样本进行区域级别的标注。然而，仍然需要对区域内的所有像素进行标注。一些主动学习工作已纳入弱标注以简化标注者的任务。在目标检测任务中，Vo
    等人 [[2022](#bib.bib184)] 使用图像级别标注训练了深度模型。他们选择了具有框内预测结果的样本，并用边界框进行了标注。此外，Lyu 等人
    [[2023](#bib.bib119)] 采用了不一致性来选择值得标注的对象。他们不需要对图像中的所有对象进行标注，只需对一部分对象进行框级标注。在实例分割的主动学习中，Tang
    等人 [[2022](#bib.bib178)] 只需对每个对象的类别标签和边界框进行标注，而无需细粒度的分割掩码标注。在未来的研究中，基于弱标注的主动学习是一个值得深入探索的方向。
- en: 6.4 Towards Active Learning with Better Generative Models
  id: totrans-442
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 朝着更好的生成模型的主动学习
- en: 'In §[4.5](#S4.SS5 "4.5 Generative Model: Data Augmentation and Generative Active
    Learning ‣ 4.4.3 Region-based Active Domain Adaptation ‣ 4.4 Region-based Active
    Learning: Smaller Labeling Unit ‣ 4.3 Active Domain Adaptation: Tackling Distribution
    Shift ‣ 4.2.2 Combination of Active Learning and Self-supervised Learning ‣ 4.2
    Self-supervised Learning: Utilizing Pre-trained Model ‣ 4.1.2 Consistency Regularization
    ‣ 4.1 Semi-supervised Learning: Utilizing Unlabeled Data ‣ 4 Integration of Active
    Learning and Other Label-Efficient Techniques ‣ A comprehensive survey on deep
    active learning and its applications in medical image analysis"), we summarize
    the applications of generative models in AL. However, existing works have mainly
    focused on using GANs as sample generators. Recently, diffusion models [Kazerouni
    et al., [2023](#bib.bib89)] have advanced in achieving state-of-the-art generative
    quality. Furthermore, text-to-image diffusion models, represented by Stable Diffusion
    [Rombach et al., [2022](#bib.bib155)], have revolutionized the image generation
    domain. Their high-quality, text-guided generation results enable a more flexible
    image generation. Exploring the potential of diffusion models in deep AL is a
    promising avenue for future research.'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 在§[4.5](#S4.SS5 "4.5 生成模型：数据增强与生成主动学习 ‣ 4.4.3 基于区域的主动领域适应 ‣ 4.4 基于区域的主动学习：更小的标注单元
    ‣ 4.3 主动领域适应：应对分布偏移 ‣ 4.2.2 主动学习与自监督学习的结合 ‣ 4.2 自监督学习：利用预训练模型 ‣ 4.1.2 一致性正则化 ‣
    4.1 半监督学习：利用未标注数据 ‣ 4 主动学习与其他标签高效技术的整合 ‣ 深度主动学习及其在医学图像分析中的应用的全面调查")中，我们总结了生成模型在主动学习中的应用。然而，现有的工作主要集中于使用GANs作为样本生成器。最近，扩散模型
    [Kazerouni et al., [2023](#bib.bib89)] 在实现最先进的生成质量方面取得了进展。此外，以Stable Diffusion
    [Rombach et al., [2022](#bib.bib155)] 为代表的文本到图像扩散模型，已经彻底改变了图像生成领域。其高质量的文本引导生成结果使图像生成变得更加灵活。探索扩散模型在深度主动学习中的潜力是未来研究的一个有前途的方向。
- en: 6.5 Towards Active Learning with Foundation Models
  id: totrans-444
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5 朝着基础模型的主动学习
- en: With the rise of visual foundational models, such as contrastive language-image
    pretraining (CLIP) [Radford et al., [2021](#bib.bib150)] and SAM [Kirillov et al.,
    [2023](#bib.bib94)], and large language models (LLMs) like GPT [OpenAI, [2023](#bib.bib137)],
    deep learning in medical image analysis and computer vision is undergoing a paradigm
    shift. These foundational models [Bommasani et al., [2021](#bib.bib23)] offer
    new opportunities for the development of AL.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 随着视觉基础模型的兴起，如对比语言-图像预训练（CLIP） [Radford et al., [2021](#bib.bib150)] 和SAM [Kirillov
    et al., [2023](#bib.bib94)]，以及大型语言模型（LLMs）如GPT [OpenAI, [2023](#bib.bib137)]，医学图像分析和计算机视觉中的深度学习正经历范式转变。这些基础模型
    [Bommasani et al., [2021](#bib.bib23)] 为主动学习的发展提供了新的机会。
- en: AL is closely related to the training paradigms in deep learning of computer
    vision and medical image analysis. From the initial approach of train-from-scratch
    to the “pretrain-finetune” strategy using supervised or self-supervised pre-trained
    models, these paradigms usually require fine-tuning the entire network. Foundation
    models contain a wealth of knowledge. When combined with recently emerging parameter-efficient
    fine tuning (PEFT) or prompt tuning techniques [Hu et al., [2021](#bib.bib70),
    Jia et al., [2022](#bib.bib78)], we can tune only a minimal subset of model weights
    (for example, 5%) for rapid transfer to downstream tasks. As the number of fine-tuned
    parameters decreases, AL has the potential to further reduce the number of required
    annotated samples. Therefore, it is essential to investigate the applicability
    of existing AL under PEFT or prompt tuning and explore the most suitable AL strategies
    for PEFT.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 主动学习（AL）与计算机视觉和医学图像分析中的深度学习训练范式密切相关。从最初的从头训练方法到使用监督或自监督预训练模型的“预训练-微调”策略，这些范式通常需要对整个网络进行微调。基础模型包含丰富的知识。当结合最近出现的参数高效微调（PEFT）或提示微调技术
    [Hu et al., [2021](#bib.bib70), Jia et al., [2022](#bib.bib78)] 时，我们可以仅微调模型权重的最小子集（例如，5%），以快速转移到下游任务。随着微调参数数量的减少，主动学习有潜力进一步减少所需的标注样本数量。因此，研究现有主动学习在PEFT或提示微调下的适用性，并探索最适合PEFT的主动学习策略是至关重要的。
- en: In natural language processing, LLMs have already taken a dominant role. Since
    most researchers cannot tune the LLMs, they rely on in-context learning, which
    provides LLMs with limited examples to transfer to downstream tasks. We believe
    that visual in-context learning will play a vital role in future research. Therefore,
    selecting the most suitable prompts for visual in-context learning will become
    an important research direction of AL.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然语言处理领域，LLMs（大型语言模型）已经占据了主导地位。由于大多数研究人员无法微调LLMs，他们依赖于上下文学习，这为LLMs提供了有限的示例，以转移到下游任务。我们认为，视觉上下文学习将在未来研究中发挥重要作用。因此，为视觉上下文学习选择最合适的提示将成为主动学习的重要研究方向。
- en: 7 Conclusion
  id: totrans-448
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Active learning is important to deep learning in medical image analysis since
    it effectively reduces the annotation costs incurred by human experts. This survey
    comprehensively reviews the core methods in deep active learning, its integration
    with different label-efficient techniques, and active learning works tailored
    to medical image analysis. We further discuss its current challenges and future
    perspectives. In summary, we believe that deep active learning and its application
    in medical image analysis hold important academic value and clinical potential,
    with ample room for further development.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 主动学习对于医学图像分析中的深度学习至关重要，因为它有效地降低了由人工专家产生的标注成本。本文全面回顾了深度主动学习的核心方法、与不同标签效率技术的集成以及针对医学图像分析的主动学习研究。我们进一步讨论了当前的挑战和未来的展望。总之，我们认为深度主动学习及其在医学图像分析中的应用具有重要的学术价值和临床潜力，还有很大的发展空间。
- en: Acknowledgments
  id: totrans-450
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This study was supported by the National Natural Science Foundation of China
    (Grant 82372097 and 82072021) and the Science and Technology Innovation Plan of
    Shanghai Science and Technology Commission (Grant 23S41900400).
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了中国国家自然科学基金（资助号82372097和82072021）和上海科技委员会科技创新计划（资助号23S41900400）的支持。
- en: References
  id: totrans-452
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Achanta et al. [2012] Achanta, R., Shaji, A., Smith, K., Lucchi, A., Fua, P.,
    Süsstrunk, S., 2012. Slic superpixels compared to state-of-the-art superpixel
    methods. IEEE transactions on pattern analysis and machine intelligence 34, 2274–2282.
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Achanta et al. [2012] Achanta, R., Shaji, A., Smith, K., Lucchi, A., Fua, P.,
    Süsstrunk, S., 2012. Slic超像素与最新超像素方法的比较。IEEE模式分析与机器智能交易 34, 2274–2282。
- en: 'Agarwal et al. [2020] Agarwal, S., Arora, H., Anand, S., Arora, C., 2020. Contextual
    diversity for active learning, in: Computer Vision – ECCV 2020. Springer International
    Publishing, Cham. volume 12361, pp. 137–153. doi:[10.1007/978-3-030-58517-4_9](http://dx.doi.org/10.1007/978-3-030-58517-4_9).'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agarwal 等人 [2020] Agarwal, S., Arora, H., Anand, S., Arora, C., 2020。主动学习的上下文多样性，见：计算机视觉
    – ECCV 2020。施普林格国际出版，Cham，第 12361 卷，第 137–153 页。doi：[10.1007/978-3-030-58517-4_9](http://dx.doi.org/10.1007/978-3-030-58517-4_9)。
- en: 'Aghdam et al. [2019] Aghdam, H.H., Gonzalez-Garcia, A., Weijer, J.v.d., López,
    A.M., 2019. Active learning for deep detection neural networks, in: Proceedings
    of the IEEE/CVF International Conference on Computer Vision, pp. 3672–3680.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aghdam 等人 [2019] Aghdam, H.H., Gonzalez-Garcia, A., Weijer, J.v.d., López, A.M.,
    2019. 深度检测神经网络的主动学习，见：IEEE/CVF 国际计算机视觉会议论文集，第 3672–3680 页。
- en: Angluin [1988] Angluin, D., 1988. Queries and concept learning. Machine Learning
    2, 319–342. doi:[10.1023/A:1022821128753](http://dx.doi.org/10.1023/A:1022821128753).
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Angluin [1988] Angluin, D., 1988。查询与概念学习。《机器学习》 2, 319–342。doi：[10.1023/A:1022821128753](http://dx.doi.org/10.1023/A:1022821128753)。
- en: Angluin [2004] Angluin, D., 2004. Queries revisited. Theoretical Computer Science
    313, 175–194. doi:[10.1016/j.tcs.2003.11.004](http://dx.doi.org/10.1016/j.tcs.2003.11.004).
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Angluin [2004] Angluin, D., 2004。查询的再探讨。《理论计算机科学》 313, 175–194。doi：[10.1016/j.tcs.2003.11.004](http://dx.doi.org/10.1016/j.tcs.2003.11.004)。
- en: Ardila et al. [2019] Ardila, D., Kiraly, A.P., Bharadwaj, S., Choi, B., Reicher,
    J.J., Peng, L., Tse, D., Etemadi, M., Ye, W., Corrado, G., et al., 2019. End-to-end
    lung cancer screening with three-dimensional deep learning on low-dose chest computed
    tomography. Nature medicine 25, 954–961.
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ardila 等人 [2019] Ardila, D., Kiraly, A.P., Bharadwaj, S., Choi, B., Reicher,
    J.J., Peng, L., Tse, D., Etemadi, M., Ye, W., Corrado, G., 等人，2019。基于三维深度学习的端到端肺癌筛查在低剂量胸部计算机断层扫描中的应用。《自然医学》
    25, 954–961。
- en: 'Ash et al. [2021] Ash, J., Goel, S., Krishnamurthy, A., Kakade, S., 2021. Gone
    fishing: Neural active learning with fisher embeddings, in: Advances in Neural
    Information Processing Systems, Curran Associates, Inc.. pp. 8927–8939.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ash 等人 [2021] Ash, J., Goel, S., Krishnamurthy, A., Kakade, S., 2021。去钓鱼：具有
    Fisher 嵌入的神经主动学习，见：神经信息处理系统进展，Curran Associates, Inc.。第 8927–8939 页。
- en: 'Ash et al. [2020] Ash, J.T., Zhang, C., Krishnamurthy, A., Langford, J., Agarwal,
    A., 2020. Deep batch active learning by diverse, uncertain gradient lower bounds,
    in: International Conference on Learning Representations.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ash 等人 [2020] Ash, J.T., Zhang, C., Krishnamurthy, A., Langford, J., Agarwal,
    A., 2020。通过多样化、不确定梯度下界的深度批量主动学习，见：国际学习表示会议。
- en: Atzeni et al. [2022] Atzeni, A., Peter, L., Robinson, E., Blackburn, E., Althonayan,
    J., Alexander, D.C., Iglesias, J.E., 2022. Deep active learning for suggestive
    segmentation of biomedical image stacks via optimisation of dice scores and traced
    boundary length. Medical Image Analysis 81, 102549. doi:[10.1016/j.media.2022.102549](http://dx.doi.org/10.1016/j.media.2022.102549).
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Atzeni 等人 [2022] Atzeni, A., Peter, L., Robinson, E., Blackburn, E., Althonayan,
    J., Alexander, D.C., Iglesias, J.E., 2022。通过优化骰子分数和追踪边界长度的深度主动学习，用于生物医学图像堆栈的建议分割。《医学图像分析》
    81, 102549。doi：[10.1016/j.media.2022.102549](http://dx.doi.org/10.1016/j.media.2022.102549)。
- en: 'Bai et al. [2022] Bai, F., Xing, X., Shen, Y., Ma, H., Meng, M.Q.H., 2022.
    Discrepancy-based active learning for weakly supervised bleeding segmentation
    in wireless capsule endoscopy images, in: Wang, L., Dou, Q., Fletcher, P.T., Speidel,
    S., Li, S. (Eds.), Medical Image Computing and Computer Assisted Intervention
    – MICCAI 2022, Springer Nature Switzerland, Cham. pp. 24–34. doi:[10.1007/978-3-031-16452-1_3](http://dx.doi.org/10.1007/978-3-031-16452-1_3).'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai 等人 [2022] Bai, F., Xing, X., Shen, Y., Ma, H., Meng, M.Q.H., 2022。基于差异性的主动学习用于无线胶囊内窥镜图像中的弱监督出血分割，见：Wang,
    L., Dou, Q., Fletcher, P.T., Speidel, S., Li, S. (Eds.), 医学图像计算与计算机辅助干预 – MICCAI
    2022，施普林格自然瑞士，Cham，第 24–34 页。doi：[10.1007/978-3-031-16452-1_3](http://dx.doi.org/10.1007/978-3-031-16452-1_3)。
- en: Baid et al. [2021] Baid, U., Ghodasara, S., Mohan, S., Bilello, M., Calabrese,
    E., Colak, E., Farahani, K., Kalpathy-Cramer, J., Kitamura, F.C., Pati, S., et al.,
    2021. The rsna-asnr-miccai brats 2021 benchmark on brain tumor segmentation and
    radiogenomic classification. arXiv preprint arXiv:2107.02314 .
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baid 等人 [2021] Baid, U., Ghodasara, S., Mohan, S., Bilello, M., Calabrese, E.,
    Colak, E., Farahani, K., Kalpathy-Cramer, J., Kitamura, F.C., Pati, S., 等人，2021。rsna-asnr-miccai
    brats 2021 基准测试：脑肿瘤分割和放射基因组分类。arXiv 预印本 arXiv:2107.02314。
- en: 'Bakker et al. [2022] Bakker, T., Muckley, M., Romero-Soriano, A., Drozdzal,
    M., Pineda, L., 2022. On learning adaptive acquisition policies for undersampled
    multi-coil mri reconstruction, in: Proceedings of The 5th International Conference
    on Medical Imaging with Deep Learning, PMLR. pp. 63–85.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bakker 等人 [2022] Bakker, T., Muckley, M., Romero-Soriano, A., Drozdzal, M.,
    Pineda, L., 2022. 学习适应性采集策略以进行欠采样多线圈MRI重建，发表于第五届国际医学成像与深度学习会议论文集，PMLR出版社，页码 63–85。
- en: 'Bakker et al. [2020] Bakker, T., van Hoof, H., Welling, M., 2020. Experimental
    design for mri by greedy policy search, in: Advances in Neural Information Processing
    Systems, Curran Associates, Inc.. pp. 18954–18966.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bakker 等人 [2020] Bakker, T., van Hoof, H., Welling, M., 2020. 通过贪婪策略搜索进行MRI的实验设计，发表于神经信息处理系统进展，Curran
    Associates, Inc.出版社，页码 18954–18966。
- en: 'Balaram et al. [2022] Balaram, S., Nguyen, C.M., Kassim, A., Krishnaswamy,
    P., 2022. Consistency-based semi-supervised evidential active learning for diagnostic
    radiograph classification, in: Wang, L., Dou, Q., Fletcher, P.T., Speidel, S.,
    Li, S. (Eds.), Medical Image Computing and Computer Assisted Intervention – MICCAI
    2022, Springer Nature Switzerland, Cham. pp. 675–685. doi:[10.1007/978-3-031-16431-6_64](http://dx.doi.org/10.1007/978-3-031-16431-6_64).'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Balaram 等人 [2022] Balaram, S., Nguyen, C.M., Kassim, A., Krishnaswamy, P., 2022.
    基于一致性的半监督证据主动学习用于诊断X光分类，发表于 Wang, L., Dou, Q., Fletcher, P.T., Speidel, S., Li,
    S.（编），医学图像计算与计算机辅助干预 – MICCAI 2022，Springer Nature Switzerland, Cham. 页码 675–685。doi:[10.1007/978-3-031-16431-6_64](http://dx.doi.org/10.1007/978-3-031-16431-6_64)。
- en: Baltruschat et al. [2019] Baltruschat, I.M., Nickisch, H., Grass, M., Knopp,
    T., Saalbach, A., 2019. Comparison of deep learning approaches for multi-label
    chest x-ray classification. Scientific reports 9, 6381.
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baltruschat 等人 [2019] Baltruschat, I.M., Nickisch, H., Grass, M., Knopp, T.,
    Saalbach, A., 2019. 多标签胸部X光分类的深度学习方法比较。《科学报告》9，6381。
- en: 'Beluch et al. [2018] Beluch, W.H., Genewein, T., Nürnberger, A., Köhler, J.M.,
    2018. The power of ensembles for active learning in image classification, in:
    Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    pp. 9368–9377.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beluch 等人 [2018] Beluch, W.H., Genewein, T., Nürnberger, A., Köhler, J.M., 2018.
    集成方法在图像分类中的主动学习能力，发表于 IEEE 计算机视觉与模式识别大会论文集，页码 9368–9377。
- en: 'Bengar et al. [2022] Bengar, J.Z., van de Weijer, J., Fuentes, L.L., Raducanu,
    B., 2022. Class-balanced active learning for image classification, in: Proceedings
    of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 1536–1545.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengar 等人 [2022] Bengar, J.Z., van de Weijer, J., Fuentes, L.L., Raducanu, B.,
    2022. 类别平衡的主动学习用于图像分类，发表于 IEEE/CVF 冬季计算机视觉应用会议论文集，页码 1536–1545。
- en: 'Bengar et al. [2021] Bengar, J.Z., van de Weijer, J., Twardowski, B., Raducanu,
    B., 2021. Reducing label effort: Self-supervised meets active learning, in: Proceedings
    of the IEEE/CVF International Conference on Computer Vision, pp. 1631–1639.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengar 等人 [2021] Bengar, J.Z., van de Weijer, J., Twardowski, B., Raducanu,
    B., 2021. 降低标签工作量：自监督与主动学习的结合，发表于 IEEE/CVF 国际计算机视觉大会论文集，页码 1631–1639。
- en: 'Van den Bergh et al. [2012] Van den Bergh, M., Boix, X., Roig, G., De Capitani,
    B., Van Gool, L., 2012. Seeds: Superpixels extracted via energy-driven sampling,
    in: Computer Vision–ECCV 2012: 12th European Conference on Computer Vision, Florence,
    Italy, October 7-13, 2012, Proceedings, Part VII 12, Springer. pp. 13–26.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Van den Bergh 等人 [2012] Van den Bergh, M., Boix, X., Roig, G., De Capitani,
    B., Van Gool, L., 2012. Seeds: 通过能量驱动的采样提取的超像素，发表于 计算机视觉–ECCV 2012: 第十二届欧洲计算机视觉大会，意大利佛罗伦萨，2012年10月7-13日，论文集，第七部分
    12，Springer出版社，页码 13–26。'
- en: Billot et al. [2023] Billot, B., Magdamo, C., Cheng, Y., Arnold, S.E., Das,
    S., Iglesias, J.E., 2023. Robust machine learning segmentation for large-scale
    analysis of heterogeneous clinical brain mri datasets. Proceedings of the National
    Academy of Sciences 120, e2216399120.
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Billot 等人 [2023] Billot, B., Magdamo, C., Cheng, Y., Arnold, S.E., Das, S.,
    Iglesias, J.E., 2023. 针对大规模异质临床脑MRI数据集的鲁棒机器学习分割。《国家科学院院刊》120，e2216399120。
- en: Bishop [1994] Bishop, C.M., 1994. Mixture density networks .
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bishop [1994] Bishop, C.M., 1994. 混合密度网络。
- en: Bıyık et al. [2019] Bıyık, E., Wang, K., Anari, N., Sadigh, D., 2019. Batch
    active learning using determinantal point processes. arXiv preprint arXiv:1906.07975
    .
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bıyık 等人 [2019] Bıyık, E., Wang, K., Anari, N., Sadigh, D., 2019. 使用决定性点过程的批量主动学习。arXiv
    预印本 arXiv:1906.07975。
- en: Bommasani et al. [2021] Bommasani, R., Hudson, D.A., Adeli, E., Altman, R.,
    Arora, S., von Arx, S., Bernstein, M.S., Bohg, J., Bosselut, A., Brunskill, E.,
    et al., 2021. On the opportunities and risks of foundation models. arXiv preprint
    arXiv:2108.07258 .
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bommasani 等人 [2021] Bommasani, R., Hudson, D.A., Adeli, E., Altman, R., Arora,
    S., von Arx, S., Bernstein, M.S., Bohg, J., Bosselut, A., Brunskill, E., 等，2021.
    基础模型的机会与风险。arXiv 预印本 arXiv:2108.07258。
- en: Budd et al. [2021] Budd, S., Robinson, E.C., Kainz, B., 2021. A survey on active
    learning and human-in-the-loop deep learning for medical image analysis. Medical
    Image Analysis 71, 102062.
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Budd 等人 [2021] Budd, S., Robinson, E.C., Kainz, B., 2021. 主动学习和人机协作深度学习在医学图像分析中的综述。医学图像分析
    71, 102062。
- en: 'Cai et al. [2021] Cai, L., Xu, X., Liew, J.H., Foo, C.S., 2021. Revisiting
    superpixels for active learning in semantic segmentation with realistic annotation
    costs, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp. 10988–10997.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cai 等人 [2021] Cai, L., Xu, X., Liew, J.H., Foo, C.S., 2021. 重新审视超像素在语义分割中用于主动学习的实际标注成本，见：IEEE/CVF
    计算机视觉与模式识别大会论文集，第10988–10997页。
- en: 'Caramalau et al. [2021] Caramalau, R., Bhattarai, B., Kim, T.K., 2021. Sequential
    graph convolutional network for active learning, in: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, pp. 9583–9592.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caramalau 等人 [2021] Caramalau, R., Bhattarai, B., Kim, T.K., 2021. 用于主动学习的序列图卷积网络，见：IEEE/CVF
    计算机视觉与模式识别大会论文集，第9583–9592页。
- en: Cardoso et al. [2017] Cardoso, T.N.C., Silva, R.M., Canuto, S., Moro, M.M.,
    Gonçalves, M.A., 2017. Ranked batch-mode active learning. Information Sciences
    379, 313–337. doi:[10.1016/j.ins.2016.10.037](http://dx.doi.org/10.1016/j.ins.2016.10.037).
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cardoso 等人 [2017] Cardoso, T.N.C., Silva, R.M., Canuto, S., Moro, M.M., Gonçalves,
    M.A., 2017. 排序批处理模式主动学习。信息科学 379, 313–337。doi：[10.1016/j.ins.2016.10.037](http://dx.doi.org/10.1016/j.ins.2016.10.037)。
- en: 'Casanova et al. [2020] Casanova, A., Pinheiro, P.O., Rostamzadeh, N., Pal,
    C.J., 2020. Reinforced active learning for image segmentation, in: International
    Conference on Learning Representations.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Casanova 等人 [2020] Casanova, A., Pinheiro, P.O., Rostamzadeh, N., Pal, C.J.,
    2020. 强化主动学习用于图像分割，见：国际学习表征会议。
- en: 'Chaudhuri et al. [2015] Chaudhuri, K., Kakade, S.M., Netrapalli, P., Sanghavi,
    S., 2015. Convergence rates of active learning for maximum likelihood estimation,
    in: Advances in Neural Information Processing Systems, Curran Associates, Inc.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chaudhuri 等人 [2015] Chaudhuri, K., Kakade, S.M., Netrapalli, P., Sanghavi, S.,
    2015. 最大似然估计的主动学习收敛速度，见：神经信息处理系统进展，Curran Associates, Inc.
- en: Chen et al. [2021] Chen, J., Xie, Y., Wang, K., Zhang, C., Vannan, M.A., Wang,
    B., Qian, Z., 2021. Active image synthesis for efficient labeling. IEEE Transactions
    on Pattern Analysis and Machine Intelligence 43, 3770–3781. doi:[10.1109/TPAMI.2020.2993221](http://dx.doi.org/10.1109/TPAMI.2020.2993221).
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 [2021] Chen, J., Xie, Y., Wang, K., Zhang, C., Vannan, M.A., Wang, B.,
    Qian, Z., 2021. 高效标注的主动图像合成。IEEE 模式分析与机器智能汇刊 43, 3770–3781。doi：[10.1109/TPAMI.2020.2993221](http://dx.doi.org/10.1109/TPAMI.2020.2993221)。
- en: 'Chen et al. [2023] Chen, L., Bai, Y., Huang, S., Lu, Y., Wen, B., Yuille, A.L.,
    Zhou, Z., 2023. Making your first choice: To address cold start problem in vision
    active learning, in: Medical Imaging with Deep Learning.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 [2023] Chen, L., Bai, Y., Huang, S., Lu, Y., Wen, B., Yuille, A.L.,
    Zhou, Z., 2023. 做出你的第一次选择：解决视觉主动学习中的冷启动问题，见：深度学习医学影像。
- en: Chen et al. [2020] Chen, T., Kornblith, S., Swersky, K., Norouzi, M., Hinton,
    G.E., 2020. Big self-supervised models are strong semi-supervised learners. Advances
    in neural information processing systems 33, 22243–22255.
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 [2020] Chen, T., Kornblith, S., Swersky, K., Norouzi, M., Hinton, G.E.,
    2020. 大型自监督模型是强大的半监督学习者。神经信息处理系统进展 33, 22243–22255。
- en: 'Chen et al. [2022a] Chen, Y., Mancini, M., Zhu, X., Akata, Z., 2022a. Semi-supervised
    and unsupervised deep visual learning: A survey. IEEE transactions on pattern
    analysis and machine intelligence .'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 [2022a] Chen, Y., Mancini, M., Zhu, X., Akata, Z., 2022a. 半监督与无监督深度视觉学习：综述。IEEE
    模式分析与机器智能汇刊。
- en: 'Chen et al. [2022b] Chen, Z., Zhang, J., Wang, P., Chen, J., Li, J., 2022b.
    When active learning meets implicit semantic data augmentation, in: Avidan, S.,
    Brostow, G., Cissé, M., Farinella, G.M., Hassner, T. (Eds.), Computer Vision –
    ECCV 2022\. Springer Nature Switzerland, Cham. volume 13685, pp. 56–72. doi:[10.1007/978-3-031-19806-9_4](http://dx.doi.org/10.1007/978-3-031-19806-9_4).'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 [2022b] Chen, Z., Zhang, J., Wang, P., Chen, J., Li, J., 2022b. 当主动学习遇到隐式语义数据增强，见：Avidan,
    S., Brostow, G., Cissé, M., Farinella, G.M., Hassner, T.（编），计算机视觉 – ECCV 2022\.
    Springer Nature Switzerland, Cham. 卷13685，第56–72页。doi：[10.1007/978-3-031-19806-9_4](http://dx.doi.org/10.1007/978-3-031-19806-9_4)。
- en: 'Choi et al. [2021a] Choi, J., Elezi, I., Lee, H.J., Farabet, C., Alvarez, J.M.,
    2021a. Active learning for deep object detection via probabilistic modeling, in:
    Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 10264–10273.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Choi 等 [2021a] Choi, J., Elezi, I., Lee, H.J., Farabet, C., Alvarez, J.M.,
    2021a. 通过概率建模进行深度目标检测的主动学习, 见于: Proceedings of the IEEE/CVF International Conference
    on Computer Vision, pp. 10264–10273.'
- en: 'Choi et al. [2021b] Choi, J., Yi, K.M., Kim, J., Choo, J., Kim, B., Chang,
    J., Gwon, Y., Chang, H.J., 2021b. Vab-al: Incorporating class imbalance and difficulty
    with variational bayes for active learning, in: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 6749–6758.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Choi 等 [2021b] Choi, J., Yi, K.M., Kim, J., Choo, J., Kim, B., Chang, J., Gwon,
    Y., Chang, H.J., 2021b. Vab-al：结合类别不平衡和难度的变分贝叶斯主动学习, 见于: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, pp. 6749–6758.'
- en: 'Citovsky et al. [2021] Citovsky, G., DeSalvo, G., Gentile, C., Karydas, L.,
    Rajagopalan, A., Rostamizadeh, A., Kumar, S., 2021. Batch active learning at scale,
    in: Advances in Neural Information Processing Systems, Curran Associates, Inc..
    pp. 11933–11944.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Citovsky 等 [2021] Citovsky, G., DeSalvo, G., Gentile, C., Karydas, L., Rajagopalan,
    A., Rostamizadeh, A., Kumar, S., 2021. 大规模批量主动学习, 见于: Advances in Neural Information
    Processing Systems, Curran Associates, Inc. pp. 11933–11944.'
- en: Cohn et al. [1994] Cohn, D., Atlas, L., Ladner, R., 1994. Improving generalization
    with active learning. Machine Learning 15, 201–221. doi:[10.1007/BF00993277](http://dx.doi.org/10.1007/BF00993277).
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cohn 等 [1994] Cohn, D., Atlas, L., Ladner, R., 1994. 通过主动学习提高泛化能力。Machine Learning
    15, 201–221. doi:[10.1007/BF00993277](http://dx.doi.org/10.1007/BF00993277).
- en: Dai et al. [2022] Dai, C., Wang, S., Mo, Y., Angelini, E., Guo, Y., Bai, W.,
    2022. Suggestive annotation of brain mr images with gradient-guided sampling.
    Medical Image Analysis 77, 102373. doi:[10.1016/j.media.2022.102373](http://dx.doi.org/10.1016/j.media.2022.102373).
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dai 等 [2022] Dai, C., Wang, S., Mo, Y., Angelini, E., Guo, Y., Bai, W., 2022.
    基于梯度引导采样的脑部 MR 图像建议注释。Medical Image Analysis 77, 102373. doi:[10.1016/j.media.2022.102373](http://dx.doi.org/10.1016/j.media.2022.102373).
- en: 'Dai et al. [2020] Dai, C., Wang, S., Mo, Y., Zhou, K., Angelini, E., Guo, Y.,
    Bai, W., 2020. Suggestive annotation of brain tumour images with gradient-guided
    sampling, in: Martel, A.L., Abolmaesumi, P., Stoyanov, D., Mateus, D., Zuluaga,
    M.A., Zhou, S.K., Racoceanu, D., Joskowicz, L. (Eds.), Medical Image Computing
    and Computer Assisted Intervention – MICCAI 2020. Springer International Publishing,
    Cham. volume 12264, pp. 156–165. doi:[10.1007/978-3-030-59719-1_16](http://dx.doi.org/10.1007/978-3-030-59719-1_16).'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dai 等 [2020] Dai, C., Wang, S., Mo, Y., Zhou, K., Angelini, E., Guo, Y., Bai,
    W., 2020. 基于梯度引导采样的脑肿瘤图像建议注释, 见于: Martel, A.L., Abolmaesumi, P., Stoyanov, D.,
    Mateus, D., Zuluaga, M.A., Zhou, S.K., Racoceanu, D., Joskowicz, L. (Eds.), Medical
    Image Computing and Computer Assisted Intervention – MICCAI 2020. Springer International
    Publishing, Cham. volume 12264, pp. 156–165. doi:[10.1007/978-3-030-59719-1_16](http://dx.doi.org/10.1007/978-3-030-59719-1_16).'
- en: 'Deng et al. [2009] Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei,
    L., 2009. Imagenet: A large-scale hierarchical image database, in: 2009 IEEE conference
    on computer vision and pattern recognition, Ieee. pp. 248–255.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Deng 等 [2009] Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.,
    2009. Imagenet: 大规模分层图像数据库, 见于: 2009 IEEE conference on computer vision and pattern
    recognition, Ieee. pp. 248–255.'
- en: 'Ding et al. [2021] Ding, Z., Han, X., Liu, P., Niethammer, M., 2021. Local
    temperature scaling for probability calibration, in: Proceedings of the IEEE/CVF
    International Conference on Computer Vision, pp. 6889–6899.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ding 等 [2021] Ding, Z., Han, X., Liu, P., Niethammer, M., 2021. 概率标定的局部温度缩放,
    见于: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp.
    6889–6899.'
- en: Du et al. [2022] Du, P., Chen, H., Zhao, S., Chai, S., Chen, H., Li, C., 2022.
    Contrastive active learning under class distribution mismatch. IEEE Transactions
    on Pattern Analysis and Machine Intelligence , 1–13doi:[10.1109/TPAMI.2022.3188807](http://dx.doi.org/10.1109/TPAMI.2022.3188807).
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du 等 [2022] Du, P., Chen, H., Zhao, S., Chai, S., Chen, H., Li, C., 2022. 类别分布不匹配下的对比主动学习。IEEE
    Transactions on Pattern Analysis and Machine Intelligence , 1–13 doi:[10.1109/TPAMI.2022.3188807](http://dx.doi.org/10.1109/TPAMI.2022.3188807).
- en: 'Du et al. [2021] Du, P., Zhao, S., Chen, H., Chai, S., Chen, H., Li, C., 2021.
    Contrastive coding for active learning under class distribution mismatch, in:
    Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 8927–8936.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Du 等 [2021] Du, P., Zhao, S., Chen, H., Chai, S., Chen, H., Li, C., 2021. 针对类别分布不匹配的对比编码主动学习,
    见于: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp.
    8927–8936.'
- en: 'Ducoffe and Precioso [2018] Ducoffe, M., Precioso, F., 2018. Adversarial active
    learning for deep networks: a margin based approach. arXiv preprint arXiv:1802.09841
    .'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ducoffe 和 Precioso [2018] Ducoffe, M., Precioso, F., 2018. 深度网络的对抗性主动学习：一种基于边际的方法。arXiv
    预印本 arXiv:1802.09841 .
- en: Esteva et al. [2017] Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M.,
    Blau, H.M., Thrun, S., 2017. Dermatologist-level classification of skin cancer
    with deep neural networks. nature 542, 115–118.
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Esteva et al. [2017] Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M.,
    Blau, H.M., Thrun, S., 2017. 使用深度神经网络进行皮肤癌的皮肤科医生级分类. nature 542, 115–118.
- en: 'Farahani and Hekmatfar [2009] Farahani, R.Z., Hekmatfar, M., 2009. Facility
    location: concepts, models, algorithms and case studies. Springer Science & Business
    Media.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Farahani and Hekmatfar [2009] Farahani, R.Z., Hekmatfar, M., 2009. 设施选址：概念、模型、算法与案例研究.
    Springer Science & Business Media.
- en: Feige [1998] Feige, U., 1998. A threshold of ln n for approximating set cover.
    Journal of the ACM (JACM) 45, 634–652.
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feige [1998] Feige, U., 1998. 近似集合覆盖的阈值为 ln n. ACM 杂志 (JACM) 45, 634–652.
- en: 'Fu et al. [2021] Fu, B., Cao, Z., Wang, J., Long, M., 2021. Transferable query
    selection for active domain adaptation, in: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 7272–7281.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fu et al. [2021] Fu, B., Cao, Z., Wang, J., Long, M., 2021. 可转移查询选择用于主动领域适应,
    in: IEEE/CVF 计算机视觉与模式识别大会论文集, pp. 7272–7281.'
- en: Fujishige [2005] Fujishige, S., 2005. Submodular functions and optimization.
    Elsevier.
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fujishige [2005] Fujishige, S., 2005. 子模函数与优化. Elsevier.
- en: 'Gal and Ghahramani [2016] Gal, Y., Ghahramani, Z., 2016. Dropout as a bayesian
    approximation: Representing model uncertainty in deep learning, in: international
    conference on machine learning, PMLR. pp. 1050–1059.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gal and Ghahramani [2016] Gal, Y., Ghahramani, Z., 2016. Dropout作为贝叶斯近似：在深度学习中表示模型不确定性,
    in: 机器学习国际会议, PMLR. pp. 1050–1059.'
- en: 'Gal et al. [2017] Gal, Y., Islam, R., Ghahramani, Z., 2017. Deep bayesian active
    learning with image data, in: Proceedings of the 34th International Conference
    on Machine Learning, PMLR. pp. 1183–1192.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gal et al. [2017] Gal, Y., Islam, R., Ghahramani, Z., 2017. 基于图像数据的深度贝叶斯主动学习,
    in: 第34届国际机器学习会议论文集, PMLR. pp. 1183–1192.'
- en: 'Gao et al. [2020] Gao, M., Zhang, Z., Yu, G., Arık, S.Ö., Davis, L.S., Pfister,
    T., 2020. Consistency-based semi-supervised active learning: Towards minimizing
    labeling cost, in: Vedaldi, A., Bischof, H., Brox, T., Frahm, J.M. (Eds.), Computer
    Vision – ECCV 2020\. Springer International Publishing, Cham. volume 12355, pp.
    510–526. doi:[10.1007/978-3-030-58607-2_30](http://dx.doi.org/10.1007/978-3-030-58607-2_30).'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gao et al. [2020] Gao, M., Zhang, Z., Yu, G., Arık, S.Ö., Davis, L.S., Pfister,
    T., 2020. 基于一致性的半监督主动学习：减少标注成本, in: Vedaldi, A., Bischof, H., Brox, T., Frahm,
    J.M. (Eds.), 计算机视觉 – ECCV 2020\. Springer International Publishing, Cham. volume
    12355, pp. 510–526. doi:[10.1007/978-3-030-58607-2_30](http://dx.doi.org/10.1007/978-3-030-58607-2_30).'
- en: 'Gidaris et al. [2018] Gidaris, S., Singh, P., Komodakis, N., 2018. Unsupervised
    representation learning by predicting image rotations, in: International Conference
    on Learning Representations.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gidaris et al. [2018] Gidaris, S., Singh, P., Komodakis, N., 2018. 通过预测图像旋转进行无监督表示学习,
    in: 代表学习国际会议.'
- en: Gissin and Shalev-Shwartz [2019] Gissin, D., Shalev-Shwartz, S., 2019. Discriminative
    active learning. arXiv preprint arXiv:1907.06347 .
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gissin and Shalev-Shwartz [2019] Gissin, D., Shalev-Shwartz, S., 2019. 判别性主动学习.
    arXiv 预印本 arXiv:1907.06347 .
- en: 'Gong et al. [2022] Gong, J., Fan, Z., Ke, Q., Rahmani, H., Liu, J., 2022. Meta
    agent teaming active learning for pose estimation, in: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, pp. 11079–11089.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gong et al. [2022] Gong, J., Fan, Z., Ke, Q., Rahmani, H., Liu, J., 2022. 元代理团队主动学习用于姿态估计,
    in: IEEE/CVF 计算机视觉与模式识别大会论文集, pp. 11079–11089.'
- en: Goodfellow et al. [2014a] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu,
    B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., 2014a. Generative
    adversarial nets. Advances in neural information processing systems 27.
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow et al. [2014a] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu,
    B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., 2014a. 生成对抗网络. 神经信息处理系统进展
    27.
- en: Goodfellow et al. [2014b] Goodfellow, I.J., Shlens, J., Szegedy, C., 2014b.
    Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572
    .
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow et al. [2014b] Goodfellow, I.J., Shlens, J., Szegedy, C., 2014b.
    解释与利用对抗样本. arXiv 预印本 arXiv:1412.6572 .
- en: 'Guan and Liu [2021] Guan, H., Liu, M., 2021. Domain adaptation for medical
    image analysis: a survey. IEEE Transactions on Biomedical Engineering 69, 1173–1185.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guan and Liu [2021] Guan, H., Liu, M., 2021. 医学图像分析领域的领域适应：综述. IEEE 生物医学工程学报
    69, 1173–1185.
- en: 'Guo et al. [2017] Guo, C., Pleiss, G., Sun, Y., Weinberger, K.Q., 2017. On
    calibration of modern neural networks, in: International conference on machine
    learning, PMLR. pp. 1321–1330.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guo et al. [2017] Guo, C., Pleiss, G., Sun, Y., Weinberger, K.Q., 2017. 现代神经网络的校准,
    in: 机器学习国际会议, PMLR. pp. 1321–1330.'
- en: 'Hacohen et al. [2022] Hacohen, G., Dekel, A., Weinshall, D., 2022. Active learning
    on a budget: Opposite strategies suit high and low budgets, in: International
    Conference on Machine Learning, PMLR. pp. 8175–8195.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hacohen等 [2022] Hacohen, G., Dekel, A., Weinshall, D., 2022. 预算下的主动学习：高低预算的对立策略，见：国际机器学习会议，PMLR，第8175–8195页。
- en: 'Haußmann et al. [2019] Haußmann, M., Hamprecht, F., Kandemir, M., 2019. Deep
    active learning with adaptive acquisition, in: Proceedings of the 28th International
    Joint Conference on Artificial Intelligence, pp. 2470–2476.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haußmann等 [2019] Haußmann, M., Hamprecht, F., Kandemir, M., 2019. 使用自适应获取的深度主动学习，见：第28届国际人工智能联合会议论文集，第2470–2476页。
- en: 'He et al. [2022] He, K., Chen, X., Xie, S., Li, Y., Dollár, P., Girshick, R.,
    2022. Masked autoencoders are scalable vision learners, in: Proceedings of the
    IEEE/CVF conference on computer vision and pattern recognition, pp. 16000–16009.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He等 [2022] He, K., Chen, X., Xie, S., Li, Y., Dollár, P., Girshick, R., 2022.
    掩码自编码器是可扩展的视觉学习者，见：IEEE/CVF计算机视觉与模式识别会议论文集，第16000–16009页。
- en: 'He et al. [2020] He, K., Fan, H., Wu, Y., Xie, S., Girshick, R., 2020. Momentum
    contrast for unsupervised visual representation learning, in: Proceedings of the
    IEEE/CVF conference on computer vision and pattern recognition, pp. 9729–9738.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He等 [2020] He, K., Fan, H., Wu, Y., Xie, S., Girshick, R., 2020. 用于无监督视觉表征学习的动量对比，见：IEEE/CVF计算机视觉与模式识别会议论文集，第9729–9738页。
- en: 'Heo et al. [2019] Heo, B., Lee, M., Yun, S., Choi, J.Y., 2019. Knowledge distillation
    with adversarial samples supporting decision boundary, in: Proceedings of the
    AAAI conference on artificial intelligence, pp. 3771–3778.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heo等 [2019] Heo, B., Lee, M., Yun, S., Choi, J.Y., 2019. 支持决策边界的对抗样本知识蒸馏，见：AAAI人工智能会议论文集，第3771–3778页。
- en: Hiasa et al. [2020] Hiasa, Y., Otake, Y., Takao, M., Ogawa, T., Sugano, N.,
    Sato, Y., 2020. Automated muscle segmentation from clinical ct using bayesian
    u-net for personalized musculoskeletal modeling. IEEE Transactions on Medical
    Imaging 39, 1030–1040. doi:[10.1109/TMI.2019.2940555](http://dx.doi.org/10.1109/TMI.2019.2940555).
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hiasa等 [2020] Hiasa, Y., Otake, Y., Takao, M., Ogawa, T., Sugano, N., Sato,
    Y., 2020. 使用贝叶斯U-Net从临床CT中自动分割肌肉用于个性化的骨骼肌肉建模。IEEE医学影像学汇刊 39, 1030–1040。doi:[10.1109/TMI.2019.2940555](http://dx.doi.org/10.1109/TMI.2019.2940555)。
- en: Hochbaum and Shmoys [1985] Hochbaum, D.S., Shmoys, D.B., 1985. A best possible
    heuristic for the k-center problem. Mathematics of operations research 10, 180–184.
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hochbaum和Shmoys [1985] Hochbaum, D.S., Shmoys, D.B., 1985. k-中心问题的最佳启发式算法。运筹学数学
    10, 180–184。
- en: 'Hou et al. [2021] Hou, J., Graham, B., Niessner, M., Xie, S., 2021. Exploring
    data-efficient 3d scene understanding with contrastive scene contexts, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 15587–15597.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hou等 [2021] Hou, J., Graham, B., Niessner, M., Xie, S., 2021. 探索数据高效的3D场景理解与对比场景上下文，见：IEEE/CVF计算机视觉与模式识别会议论文集，第15587–15597页。
- en: Houlsby et al. [2011] Houlsby, N., Huszár, F., Ghahramani, Z., Lengyel, M.,
    2011. Bayesian active learning for classification and preference learning. arXiv
    preprint arXiv:1112.5745 .
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Houlsby等 [2011] Houlsby, N., Huszár, F., Ghahramani, Z., Lengyel, M., 2011.
    用于分类和偏好学习的贝叶斯主动学习。arXiv 预印本 arXiv:1112.5745。
- en: 'Hu et al. [2021] Hu, E.J., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang,
    L., Chen, W., et al., 2021. Lora: Low-rank adaptation of large language models,
    in: International Conference on Learning Representations.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu等 [2021] Hu, E.J., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L.,
    Chen, W., 等，2021. Lora：大语言模型的低秩适应，见：学习表征国际会议。
- en: 'Hu et al. [2022] Hu, Z., Bai, X., Zhang, R., Wang, X., Sun, G., Fu, H., Tai,
    C.L., 2022. Lidal: Inter-frame uncertainty based active learning for 3d lidar
    semantic segmentation, in: European Conference on Computer Vision, Springer. pp.
    248–265.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu等 [2022] Hu, Z., Bai, X., Zhang, R., Wang, X., Sun, G., Fu, H., Tai, C.L.,
    2022. Lidal：基于帧间不确定性的3D激光雷达语义分割主动学习，见：欧洲计算机视觉会议，Springer，第248–265页。
- en: 'Huang et al. [2023] Huang, D., Li, J., Chen, W., Huang, J., Chai, Z., Li, G.,
    2023. Divide and adapt: Active domain adaptation via customized learning, in:
    Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    pp. 7651–7660.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang等 [2023] Huang, D., Li, J., Chen, W., Huang, J., Chai, Z., Li, G., 2023.
    划分与适应：通过定制学习进行主动领域适应，见：IEEE/CVF计算机视觉与模式识别会议论文集，第7651–7660页。
- en: 'Huang et al. [2017] Huang, G., Li, Y., Pleiss, G., Liu, Z., Hopcroft, J.E.,
    Weinberger, K.Q., 2017. Snapshot ensembles: Train 1, get m for free. arXiv preprint
    arXiv:1704.00109 .'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang等 [2017] Huang, G., Li, Y., Pleiss, G., Liu, Z., Hopcroft, J.E., Weinberger,
    K.Q., 2017. 快照集成：训练1个，免费得到m个。arXiv 预印本 arXiv:1704.00109。
- en: 'Huang et al. [2021] Huang, S., Wang, T., Xiong, H., Huan, J., Dou, D., 2021.
    Semi-supervised active learning with temporal output discrepancy, in: Proceedings
    of the IEEE/CVF International Conference on Computer Vision, pp. 3447–3456.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang等人 [2021] Huang, S., Wang, T., Xiong, H., Huan, J., Dou, D., 2021. 具有时间输出差异的半监督主动学习，载于：IEEE/CVF国际计算机视觉会议论文集，第3447–3456页。
- en: Huang et al. [2020] Huang, Y.J., Liu, W., Wang, X., Fang, Q., Wang, R., Wang,
    Y., Chen, H., Chen, H., Meng, D., Wang, L., 2020. Rectifying supporting regions
    with mixed and active supervision for rib fracture recognition. IEEE Transactions
    on Medical Imaging 39, 3843–3854. doi:[10.1109/TMI.2020.3006138](http://dx.doi.org/10.1109/TMI.2020.3006138).
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang等人 [2020] Huang, Y.J., Liu, W., Wang, X., Fang, Q., Wang, R., Wang, Y.,
    Chen, H., Chen, H., Meng, D., Wang, L., 2020. 通过混合和主动监督纠正支持区域用于肋骨骨折识别。IEEE医学影像学报
    39, 3843–3854. doi:[10.1109/TMI.2020.3006138](http://dx.doi.org/10.1109/TMI.2020.3006138)。
- en: 'Hwang et al. [2022] Hwang, S., Lee, S., Kim, S., Ok, J., Kwak, S., 2022. Combating
    label distribution shift for active domain adaptation, in: European Conference
    on Computer Vision, Springer. pp. 549–566.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hwang等人 [2022] Hwang, S., Lee, S., Kim, S., Ok, J., Kwak, S., 2022. 应对主动领域适应中的标签分布变化，载于：欧洲计算机视觉大会，Springer。第549–566页。
- en: Jaeger et al. [2013] Jaeger, S., Karargyris, A., Candemir, S., Folio, L., Siegelman,
    J., Callaghan, F., Xue, Z., Palaniappan, K., Singh, R.K., Antani, S., et al.,
    2013. Automatic tuberculosis screening using chest radiographs. IEEE transactions
    on medical imaging 33, 233–245.
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaeger等人 [2013] Jaeger, S., Karargyris, A., Candemir, S., Folio, L., Siegelman,
    J., Callaghan, F., Xue, Z., Palaniappan, K., Singh, R.K., Antani, S., 等, 2013.
    使用胸部X光片的自动结核病筛查。IEEE医学影像学报 33, 233–245。
- en: 'Jia et al. [2022] Jia, M., Tang, L., Chen, B.C., Cardie, C., Belongie, S.,
    Hariharan, B., Lim, S.N., 2022. Visual prompt tuning, in: European Conference
    on Computer Vision, Springer. pp. 709–727.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jia等人 [2022] Jia, M., Tang, L., Chen, B.C., Cardie, C., Belongie, S., Hariharan,
    B., Lim, S.N., 2022. 视觉提示调优，载于：欧洲计算机视觉大会，Springer。第709–727页。
- en: 'Jin et al. [2023a] Jin, C., Guo, Z., Lin, Y., Luo, L., Chen, H., 2023a. Label-efficient
    deep learning in medical image analysis: Challenges and future directions. arXiv
    preprint arXiv:2303.12484 .'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin等人 [2023a] Jin, C., Guo, Z., Lin, Y., Luo, L., Chen, H., 2023a. 医学图像分析中的标签高效深度学习：挑战与未来方向。arXiv预印本
    arXiv:2303.12484。
- en: Jin et al. [2019] Jin, K.H., Unser, M., Yi, K.M., 2019. Self-supervised deep
    active accelerated mri. arXiv preprint arXiv:1901.04547 .
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin等人 [2019] Jin, K.H., Unser, M., Yi, K.M., 2019. 自监督深度主动加速MRI。arXiv预印本 arXiv:1901.04547。
- en: Jin et al. [2023b] Jin, Q., Li, S., Du, X., Yuan, M., Wang, M., Song, Z., 2023b.
    Density-based one-shot active learning for image segmentation. Engineering Applications
    of Artificial Intelligence 126, 106805. doi:[10.1016/j.engappai.2023.106805](http://dx.doi.org/10.1016/j.engappai.2023.106805).
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin等人 [2023b] Jin, Q., Li, S., Du, X., Yuan, M., Wang, M., Song, Z., 2023b.
    基于密度的单次主动学习用于图像分割。工程应用人工智能 126, 106805. doi:[10.1016/j.engappai.2023.106805](http://dx.doi.org/10.1016/j.engappai.2023.106805)。
- en: Jin et al. [2022a] Jin, Q., Yuan, M., Li, S., Wang, H., Wang, M., Song, Z.,
    2022a. Cold-start active learning for image classification. Information Sciences
    616, 16–36. doi:[10.1016/j.ins.2022.10.066](http://dx.doi.org/10.1016/j.ins.2022.10.066).
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin等人 [2022a] Jin, Q., Yuan, M., Li, S., Wang, H., Wang, M., Song, Z., 2022a.
    冷启动主动学习用于图像分类。信息科学 616, 16–36. doi:[10.1016/j.ins.2022.10.066](http://dx.doi.org/10.1016/j.ins.2022.10.066)。
- en: Jin et al. [2022b] Jin, Q., Yuan, M., Qiao, Q., Song, Z., 2022b. One-shot active
    learning for image segmentation via contrastive learning and diversity-based sampling.
    Knowledge-Based Systems 241, 108278. doi:[10.1016/j.knosys.2022.108278](http://dx.doi.org/10.1016/j.knosys.2022.108278).
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin等人 [2022b] Jin, Q., Yuan, M., Qiao, Q., Song, Z., 2022b. 基于对比学习和多样性采样的单次主动学习用于图像分割。知识驱动系统
    241, 108278. doi:[10.1016/j.knosys.2022.108278](http://dx.doi.org/10.1016/j.knosys.2022.108278)。
- en: Jin et al. [2022c] Jin, Q., Yuan, M., Wang, H., Wang, M., Song, Z., 2022c. Deep
    active learning models for imbalanced image classification. Knowledge-Based Systems
    257, 109817. doi:[10.1016/j.knosys.2022.109817](http://dx.doi.org/10.1016/j.knosys.2022.109817).
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin等人 [2022c] Jin, Q., Yuan, M., Wang, H., Wang, M., Song, Z., 2022c. 用于不平衡图像分类的深度主动学习模型。知识驱动系统
    257, 109817. doi:[10.1016/j.knosys.2022.109817](http://dx.doi.org/10.1016/j.knosys.2022.109817)。
- en: 'Joshi et al. [2009] Joshi, A.J., Porikli, F., Papanikolopoulos, N., 2009. Multi-class
    active learning for image classification, in: 2009 IEEE Conference on Computer
    Vision and Pattern Recognition, pp. 2372–2379. doi:[10.1109/CVPR.2009.5206627](http://dx.doi.org/10.1109/CVPR.2009.5206627).'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Joshi等人 [2009] Joshi, A.J., Porikli, F., Papanikolopoulos, N., 2009. 用于图像分类的多类别主动学习，载于：2009年IEEE计算机视觉与模式识别大会，第2372–2379页。doi:[10.1109/CVPR.2009.5206627](http://dx.doi.org/10.1109/CVPR.2009.5206627)。
- en: 'Jung et al. [2023] Jung, S., Kim, S., Lee, J., 2023. A simple yet powerful
    deep active learning with snapshots ensembles, in: International Conference on
    Learning Representations.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jung 等 [2023] Jung, S., Kim, S., Lee, J., 2023. 一种简单而强大的深度主动学习方法，使用快照集成，发表于国际学习表征会议。
- en: 'Karamcheti et al. [2021] Karamcheti, S., Krishna, R., Fei-Fei, L., Manning,
    C., 2021. Mind your outliers! investigating the negative impact of outliers on
    active learning for visual question answering, in: Proceedings of the 59th Annual
    Meeting of the Association for Computational Linguistics and the 11th International
    Joint Conference on Natural Language Processing (Volume 1: Long Papers), Association
    for Computational Linguistics, Online. pp. 7265–7281. doi:[10.18653/v1/2021.acl-long.564](http://dx.doi.org/10.18653/v1/2021.acl-long.564).'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karamcheti 等 [2021] Karamcheti, S., Krishna, R., Fei-Fei, L., Manning, C., 2021.
    留意你的离群点！研究离群点对视觉问答主动学习的负面影响，发表于第 59 届计算语言学协会年会暨第 11 届国际联合自然语言处理会议（卷 1：长篇论文），计算语言学协会，在线，第
    7265–7281 页。doi:[10.18653/v1/2021.acl-long.564](http://dx.doi.org/10.18653/v1/2021.acl-long.564)。
- en: 'Kasarla et al. [2019] Kasarla, T., Nagendar, G., Hegde, G.M., Balasubramanian,
    V., Jawahar, C., 2019. Region-based active learning for efficient labeling in
    semantic segmentation, in: 2019 IEEE Winter Conference on Applications of Computer
    Vision (WACV), pp. 1109–1117. doi:[10.1109/WACV.2019.00123](http://dx.doi.org/10.1109/WACV.2019.00123).'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kasarla 等 [2019] Kasarla, T., Nagendar, G., Hegde, G.M., Balasubramanian, V.,
    Jawahar, C., 2019. 基于区域的主动学习用于高效标注语义分割，发表于 2019 IEEE 冬季计算机视觉应用会议 (WACV) 论文集，第
    1109–1117 页。doi:[10.1109/WACV.2019.00123](http://dx.doi.org/10.1109/WACV.2019.00123)。
- en: 'Kazerouni et al. [2023] Kazerouni, A., Aghdam, E.K., Heidari, M., Azad, R.,
    Fayyaz, M., Hacihaliloglu, I., Merhof, D., 2023. Diffusion models in medical imaging:
    A comprehensive survey. Medical Image Analysis , 102846.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kazerouni 等 [2023] Kazerouni, A., Aghdam, E.K., Heidari, M., Azad, R., Fayyaz,
    M., Hacihaliloglu, I., Merhof, D., 2023. 医学成像中的扩散模型：综合调查。医学图像分析, 102846。
- en: Kendall and Gal [2017] Kendall, A., Gal, Y., 2017. What uncertainties do we
    need in bayesian deep learning for computer vision? Advances in neural information
    processing systems 30.
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kendall 和 Gal [2017] Kendall, A., Gal, Y., 2017. 在计算机视觉的贝叶斯深度学习中，我们需要什么不确定性？神经信息处理系统进展
    30。
- en: 'Kim et al. [2023] Kim, H., Oh, M., Hwang, S., Kwak, S., Ok, J., 2023. Adaptive
    superpixel for active learning in semantic segmentation, in: Proceedings of the
    IEEE/CVF International Conference on Computer Vision (ICCV), pp. 943–953.'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 等 [2023] Kim, H., Oh, M., Hwang, S., Kwak, S., Ok, J., 2023. 用于语义分割的自适应超像素主动学习，发表于
    IEEE/CVF 国际计算机视觉会议 (ICCV) 论文集，第 943–953 页。
- en: 'Kim et al. [2021] Kim, K., Park, D., Kim, K.I., Chun, S.Y., 2021. Task-aware
    variational adversarial active learning, in: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 8166–8175.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 等 [2021] Kim, K., Park, D., Kim, K.I., Chun, S.Y., 2021. 任务感知变分对抗主动学习，发表于
    IEEE/CVF 计算机视觉与模式识别会议论文集，第 8166–8175 页。
- en: Kingma and Welling [2013] Kingma, D.P., Welling, M., 2013. Auto-encoding variational
    bayes. arXiv preprint arXiv:1312.6114 .
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma 和 Welling [2013] Kingma, D.P., Welling, M., 2013. 自编码变分贝叶斯。arXiv 预印本
    arXiv:1312.6114。
- en: Kirillov et al. [2023] Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland,
    C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A.C., Lo, W.Y., et al., 2023.
    Segment anything. arXiv preprint arXiv:2304.02643 .
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kirillov 等 [2023] Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C.,
    Gustafson, L., Xiao, T., Whitehead, S., Berg, A.C., Lo, W.Y., 等，2023. 任何物体分割。arXiv
    预印本 arXiv:2304.02643。
- en: 'Kirsch et al. [2019] Kirsch, A., van Amersfoort, J., Gal, Y., 2019. Batchbald:
    Efficient and diverse batch acquisition for deep bayesian active learning, in:
    Advances in Neural Information Processing Systems, Curran Associates, Inc.'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kirsch 等 [2019] Kirsch, A., van Amersfoort, J., Gal, Y., 2019. Batchbald：高效且多样的批量获取用于深度贝叶斯主动学习，发表于神经信息处理系统进展，Curran
    Associates, Inc.
- en: 'Koh and Liang [2017] Koh, P.W., Liang, P., 2017. Understanding black-box predictions
    via influence functions, in: International conference on machine learning, PMLR.
    pp. 1885–1894.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koh 和 Liang [2017] Koh, P.W., Liang, P., 2017. 通过影响函数理解黑箱预测，发表于国际机器学习会议，PMLR，第
    1885–1894 页。
- en: 'Kohlberger et al. [2012] Kohlberger, T., Singh, V., Alvino, C., Bahlmann, C.,
    Grady, L., 2012. Evaluating segmentation error without ground truth, in: International
    Conference on Medical Image Computing and Computer-Assisted Intervention, Springer.
    pp. 528–536.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kohlberger 等 [2012] Kohlberger, T., Singh, V., Alvino, C., Bahlmann, C., Grady,
    L., 2012. 在没有真实标注的情况下评估分割错误，发表于医学图像计算与计算机辅助干预国际会议，Springer，第 528–536 页。
- en: 'Kothawade et al. [2021] Kothawade, S., Beck, N., Killamsetty, K., Iyer, R.,
    2021. Similar: Submodular information measures based active learning in realistic
    scenarios, in: Advances in Neural Information Processing Systems, Curran Associates,
    Inc.. pp. 18685–18697.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kothawade 等 [2021] Kothawade, S., Beck, N., Killamsetty, K., Iyer, R., 2021.
    Similar: 基于子模块信息度量的主动学习在实际场景中的应用，见：神经信息处理系统进展，Curran Associates, Inc. 页码 18685–18697。'
- en: 'Kothawade et al. [2022a] Kothawade, S., Ghosh, S., Shekhar, S., Xiang, Y.,
    Iyer, R., 2022a. Talisman: Targeted active learning for object detection with
    rare classes and slices using submodular mutual information, in: Computer Vision
    – ECCV 2022, Springer, Cham. pp. 1–16. doi:[10.1007/978-3-031-19839-7_1](http://dx.doi.org/10.1007/978-3-031-19839-7_1).'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kothawade 等 [2022a] Kothawade, S., Ghosh, S., Shekhar, S., Xiang, Y., Iyer,
    R., 2022a. Talisman: 针对稀有类别和切片的目标检测主动学习，使用子模块互信息，见：计算机视觉 – ECCV 2022，Springer，Cham.
    页码 1–16. doi:[10.1007/978-3-031-19839-7_1](http://dx.doi.org/10.1007/978-3-031-19839-7_1)。'
- en: 'Kothawade et al. [2022b] Kothawade, S., Kaushal, V., Ramakrishnan, G., Bilmes,
    J., Iyer, R., 2022b. Prism: A rich class of parameterized submodular information
    measures for guided data subset selection, in: Proceedings of the AAAI Conference
    on Artificial Intelligence, pp. 10238–10246.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kothawade 等 [2022b] Kothawade, S., Kaushal, V., Ramakrishnan, G., Bilmes, J.,
    Iyer, R., 2022b. Prism: 一类丰富的参数化子模块信息度量，用于指导数据子集选择，见：人工智能会议论文集，页码 10238–10246。'
- en: 'Kothawade et al. [2022c] Kothawade, S., Savarkar, A., Iyer, V., Ramakrishnan,
    G., Iyer, R., 2022c. Clinical: Targeted active learning for imbalanced medical
    image classification, in: Workshop on Medical Image Learning with Limited and
    Noisy Data, Springer. pp. 119–129.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kothawade 等 [2022c] Kothawade, S., Savarkar, A., Iyer, V., Ramakrishnan, G.,
    Iyer, R., 2022c. 临床：针对不平衡医学图像分类的主动学习，见：有限和噪声数据的医学图像学习研讨会，Springer. 页码 119–129。
- en: Kovashka et al. [2016] Kovashka, A., Russakovsky, O., Fei-Fei, L., Grauman,
    K., et al., 2016. Crowdsourcing in computer vision. Foundations and Trends® in
    computer graphics and Vision 10, 177–243.
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kovashka 等 [2016] Kovashka, A., Russakovsky, O., Fei-Fei, L., Grauman, K., 等，2016.
    计算机视觉中的众包。计算机图形与视觉基础与趋势® 10, 177–243。
- en: 'Kuo et al. [2018] Kuo, W., Häne, C., Yuh, E., Mukherjee, P., Malik, J., 2018.
    Cost-sensitive active learning for intracranial hemorrhage detection, in: Frangi,
    A.F., Schnabel, J.A., Davatzikos, C., Alberola-López, C., Fichtinger, G. (Eds.),
    Medical Image Computing and Computer Assisted Intervention – MICCAI 2018\. Springer
    International Publishing, Cham. volume 11072, pp. 715–723. doi:[10.1007/978-3-030-00931-1_82](http://dx.doi.org/10.1007/978-3-030-00931-1_82).'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuo 等 [2018] Kuo, W., Häne, C., Yuh, E., Mukherjee, P., Malik, J., 2018. 成本敏感的主动学习用于颅内出血检测，见：Frangi,
    A.F., Schnabel, J.A., Davatzikos, C., Alberola-López, C., Fichtinger, G. (编辑)，医学图像计算与计算机辅助干预
    – MICCAI 2018。Springer International Publishing，Cham. 卷 11072，页码 715–723. doi:[10.1007/978-3-030-00931-1_82](http://dx.doi.org/10.1007/978-3-030-00931-1_82)。
- en: LeCun et al. [2006] LeCun, Y., Chopra, S., Hadsell, R., Ranzato, M., Huang,
    F., 2006. A tutorial on energy-based learning. Predicting structured data 1.
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun 等 [2006] LeCun, Y., Chopra, S., Hadsell, R., Ranzato, M., Huang, F., 2006.
    能量基学习教程。预测结构化数据 1。
- en: 'Lee et al. [2013] Lee, D.H., et al., 2013. Pseudo-label: The simple and efficient
    semi-supervised learning method for deep neural networks, in: Workshop on challenges
    in representation learning, ICML, Atlanta. p. 896.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee 等 [2013] Lee, D.H., 等，2013. 伪标签：一种简单高效的半监督学习方法用于深度神经网络，见：表征学习挑战研讨会，ICML，亚特兰大.
    页码 896。
- en: Lee et al. [2015] Lee, K., Zlateski, A., Ashwin, V., Seung, H.S., 2015. Recursive
    training of 2d-3d convolutional networks for neuronal boundary prediction. Advances
    in Neural Information Processing Systems 28.
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee 等 [2015] Lee, K., Zlateski, A., Ashwin, V., Seung, H.S., 2015. 2D-3D 卷积网络的递归训练用于神经边界预测。神经信息处理系统进展
    28。
- en: 'Lewis and Catlett [1994] Lewis, D.D., Catlett, J., 1994. Heterogeneous uncertainty
    sampling for supervised learning, in: Cohen, W.W., Hirsh, H. (Eds.), Machine Learning
    Proceedings 1994. Morgan Kaufmann, San Francisco (CA), pp. 148–156. doi:[10.1016/B978-1-55860-335-6.50026-X](http://dx.doi.org/10.1016/B978-1-55860-335-6.50026-X).'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis 和 Catlett [1994] Lewis, D.D., Catlett, J., 1994. 异质不确定性采样用于监督学习，见：Cohen,
    W.W., Hirsh, H. (编辑)，机器学习会议录 1994。Morgan Kaufmann，旧金山（CA），页码 148–156. doi:[10.1016/B978-1-55860-335-6.50026-X](http://dx.doi.org/10.1016/B978-1-55860-335-6.50026-X)。
- en: 'Li and Yin [2020] Li, H., Yin, Z., 2020. Attention, suggestion and annotation:
    A deep active learning framework for biomedical image segmentation, in: Martel,
    A.L., Abolmaesumi, P., Stoyanov, D., Mateus, D., Zuluaga, M.A., Zhou, S.K., Racoceanu,
    D., Joskowicz, L. (Eds.), Medical Image Computing and Computer Assisted Intervention
    – MICCAI 2020, Springer International Publishing, Cham. pp. 3–13. doi:[10.1007/978-3-030-59710-8_1](http://dx.doi.org/10.1007/978-3-030-59710-8_1).'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 和 Yin [2020] Li, H., Yin, Z., 2020. 注意力、建议与注释：一种用于生物医学图像分割的深度主动学习框架，见：Martel,
    A.L., Abolmaesumi, P., Stoyanov, D., Mateus, D., Zuluaga, M.A., Zhou, S.K., Racoceanu,
    D., Joskowicz, L. (编辑)，医学图像计算与计算机辅助干预 – MICCAI 2020，Springer International Publishing，Cham.
    第 3–13 页。doi：[10.1007/978-3-030-59710-8_1](http://dx.doi.org/10.1007/978-3-030-59710-8_1)。
- en: 'Li et al. [2022] Li, W., Li, J., Wang, Z., Polson, J., Sisk, A.E., Sajed, D.P.,
    Speier, W., Arnold, C.W., 2022. Pathal: An active learning framework for histopathology
    image analysis. IEEE Transactions on Medical Imaging 41, 1176–1187. doi:[10.1109/TMI.2021.3135002](http://dx.doi.org/10.1109/TMI.2021.3135002).'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 [2022] Li, W., Li, J., Wang, Z., Polson, J., Sisk, A.E., Sajed, D.P.,
    Speier, W., Arnold, C.W., 2022. Pathal：用于组织病理学图像分析的主动学习框架。IEEE 医学成像学报 41, 1176–1187。doi：[10.1109/TMI.2021.3135002](http://dx.doi.org/10.1109/TMI.2021.3135002)。
- en: 'Lin et al. [2020] Lin, Z., Wei, D., Jang, W.D., Zhou, S., Chen, X., Wang, X.,
    Schalek, R., Berger, D., Matejek, B., Kamentsky, L., Peleg, A., Haehn, D., Jones,
    T., Parag, T., Lichtman, J., Pfister, H., 2020. Two stream active query suggestion
    for active learning in connectomics, in: Vedaldi, A., Bischof, H., Brox, T., Frahm,
    J.M. (Eds.), Computer Vision – ECCV 2020, Springer International Publishing, Cham.
    pp. 103–120. doi:[10.1007/978-3-030-58523-5_7](http://dx.doi.org/10.1007/978-3-030-58523-5_7).'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等人 [2020] Lin, Z., Wei, D., Jang, W.D., Zhou, S., Chen, X., Wang, X., Schalek,
    R., Berger, D., Matejek, B., Kamentsky, L., Peleg, A., Haehn, D., Jones, T., Parag,
    T., Lichtman, J., Pfister, H., 2020. 用于连接组学中的主动学习的双流主动查询建议，见：Vedaldi, A., Bischof,
    H., Brox, T., Frahm, J.M. (编辑)，计算机视觉 – ECCV 2020，Springer International Publishing，Cham.
    第 103–120 页。doi：[10.1007/978-3-030-58523-5_7](http://dx.doi.org/10.1007/978-3-030-58523-5_7)。
- en: Liu et al. [2022a] Liu, G., van Kaick, O., Huang, H., Hu, R., 2022a. Active
    self-training for weakly supervised 3d scene semantic segmentation. arXiv preprint
    arXiv:2209.07069 .
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2022a] Liu, G., van Kaick, O., Huang, H., Hu, R., 2022a. 用于弱监督三维场景语义分割的主动自训练。arXiv
    预印本 arXiv:2209.07069。
- en: 'Liu et al. [2020] Liu, J., Cao, L., Tian, Y., 2020. Deep active learning for
    effective pulmonary nodule detection, in: Martel, A.L., Abolmaesumi, P., Stoyanov,
    D., Mateus, D., Zuluaga, M.A., Zhou, S.K., Racoceanu, D., Joskowicz, L. (Eds.),
    Medical Image Computing and Computer Assisted Intervention – MICCAI 2020, Springer
    International Publishing, Cham. pp. 609–618. doi:[10.1007/978-3-030-59725-2_59](http://dx.doi.org/10.1007/978-3-030-59725-2_59).'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2020] Liu, J., Cao, L., Tian, Y., 2020. 深度主动学习用于有效的肺结节检测，见：Martel, A.L.,
    Abolmaesumi, P., Stoyanov, D., Mateus, D., Zuluaga, M.A., Zhou, S.K., Racoceanu,
    D., Joskowicz, L. (编辑)，医学图像计算与计算机辅助干预 – MICCAI 2020，Springer International Publishing，Cham.
    第 609–618 页。doi：[10.1007/978-3-030-59725-2_59](http://dx.doi.org/10.1007/978-3-030-59725-2_59)。
- en: 'Liu et al. [2022b] Liu, P., Wang, L., Ranjan, R., He, G., Zhao, L., 2022b.
    A survey on active deep learning: from model driven to data driven. ACM Computing
    Surveys (CSUR) 54, 1–34.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2022b] Liu, P., Wang, L., Ranjan, R., He, G., Zhao, L., 2022b. 主动深度学习的综述：从模型驱动到数据驱动。ACM
    计算调查（CSUR）54, 1–34。
- en: Liu et al. [2023] Liu, S., Yin, S., Qu, L., Wang, M., Song, Z., 2023. A structure-aware
    framework of unsupervised cross-modality domain adaptation via frequency and spatial
    knowledge distillation. IEEE Transactions on Medical Imaging .
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2023] Liu, S., Yin, S., Qu, L., Wang, M., Song, Z., 2023. 一种结构感知的无监督跨模态领域适应框架，通过频率和空间知识蒸馏。IEEE
    医学成像学报。
- en: 'Liu et al. [2021a] Liu, X., Zhang, F., Hou, Z., Mian, L., Wang, Z., Zhang,
    J., Tang, J., 2021a. Self-supervised learning: Generative or contrastive. IEEE
    transactions on knowledge and data engineering 35, 857–876.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2021a] Liu, X., Zhang, F., Hou, Z., Mian, L., Wang, Z., Zhang, J., Tang,
    J., 2021a. 自监督学习：生成还是对比。IEEE 知识与数据工程学报 35, 857–876。
- en: 'Liu et al. [2021b] Liu, Z., Ding, H., Zhong, H., Li, W., Dai, J., He, C., 2021b.
    Influence selection for active learning, in: Proceedings of the IEEE/CVF International
    Conference on Computer Vision, pp. 9274–9283.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2021b] Liu, Z., Ding, H., Zhong, H., Li, W., Dai, J., He, C., 2021b.
    主动学习的影响选择，见：IEEE/CVF 国际计算机视觉大会论文集，第 9274–9283 页。
- en: 'Liu et al. [2019] Liu, Z., Wang, J., Gong, S., Lu, H., Tao, D., 2019. Deep
    reinforcement active learning for human-in-the-loop person re-identification,
    in: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp.
    6122–6131.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2019] Liu, Z., Wang, J., Gong, S., Lu, H., Tao, D., 2019. 深度强化主动学习用于人机互动中的人员再识别，见：IEEE/CVF国际计算机视觉会议论文集，第6122–6131页。
- en: 'Lou et al. [2023] Lou, W., Li, H., Li, G., Han, X., Wan, X., 2023. Which pixel
    to annotate: A label-efficient nuclei segmentation framework. IEEE Transactions
    on Medical Imaging 42, 947–958. doi:[10.1109/TMI.2022.3221666](http://dx.doi.org/10.1109/TMI.2022.3221666).'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lou 等人 [2023] Lou, W., Li, H., Li, G., Han, X., Wan, X., 2023. 选择哪个像素进行标注：一个标签高效的细胞核分割框架。IEEE医学影像学汇刊
    42, 947–958。doi:[10.1109/TMI.2022.3221666](http://dx.doi.org/10.1109/TMI.2022.3221666)。
- en: 'Lyu et al. [2023] Lyu, M., Zhou, J., Chen, H., Huang, Y., Yu, D., Li, Y., Guo,
    Y., Guo, Y., Xiang, L., Ding, G., 2023. Box-level active detection, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 23766–23775.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lyu 等人 [2023] Lyu, M., Zhou, J., Chen, H., Huang, Y., Yu, D., Li, Y., Guo, Y.,
    Guo, Y., Xiang, L., Ding, G., 2023. 框级主动检测，见：IEEE/CVF计算机视觉与模式识别会议论文集，第23766–23775页。
- en: 'Mackowiak et al. [2018] Mackowiak, R., Lenz, P., Ghori, O., Diego, F., Lange,
    O., Rother, C., 2018. Cereals - cost-effective region-based active learning for
    semantic segmentation, in: 29th British Machine Vision Conference.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mackowiak 等人 [2018] Mackowiak, R., Lenz, P., Ghori, O., Diego, F., Lange, O.,
    Rother, C., 2018. 谷物 - 基于区域的成本效益主动学习用于语义分割，见：第29届英国机器视觉会议。
- en: 'Mahapatra et al. [2018] Mahapatra, D., Bozorgtabar, B., Thiran, J.P., Reyes,
    M., 2018. Efficient active learning for image classification and segmentation
    using a sample selection and conditional generative adversarial network, in: Frangi,
    A.F., Schnabel, J.A., Davatzikos, C., Alberola-López, C., Fichtinger, G. (Eds.),
    Medical Image Computing and Computer Assisted Intervention – MICCAI 2018\. Springer
    International Publishing, Cham. volume 11071, pp. 580–588. doi:[10.1007/978-3-030-00934-2_65](http://dx.doi.org/10.1007/978-3-030-00934-2_65).'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahapatra 等人 [2018] Mahapatra, D., Bozorgtabar, B., Thiran, J.P., Reyes, M.,
    2018. 使用样本选择和条件生成对抗网络的高效主动学习用于图像分类和分割，见：Frangi, A.F., Schnabel, J.A., Davatzikos,
    C., Alberola-López, C., Fichtinger, G. (编辑)，医学图像计算与计算机辅助干预 – MICCAI 2018\. Springer
    International Publishing, Cham. 卷11071，第580–588页。doi:[10.1007/978-3-030-00934-2_65](http://dx.doi.org/10.1007/978-3-030-00934-2_65)。
- en: Mahapatra et al. [2022] Mahapatra, D., Poellinger, A., Reyes, M., 2022. Graph
    node based interpretability guided sample selection for active learning. IEEE
    Transactions on Medical Imaging , 1–1doi:[10.1109/TMI.2022.3215017](http://dx.doi.org/10.1109/TMI.2022.3215017).
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahapatra 等人 [2022] Mahapatra, D., Poellinger, A., Reyes, M., 2022. 基于图节点的可解释性引导样本选择用于主动学习。IEEE医学影像学汇刊，1–1。doi:[10.1109/TMI.2022.3215017](http://dx.doi.org/10.1109/TMI.2022.3215017)。
- en: Mahapatra et al. [2021] Mahapatra, D., Poellinger, A., Shao, L., Reyes, M.,
    2021. Interpretability-driven sample selection using self supervised learning
    for disease classification and segmentation. IEEE Transactions on Medical Imaging
    40, 2548–2562. doi:[10.1109/TMI.2021.3061724](http://dx.doi.org/10.1109/TMI.2021.3061724).
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahapatra 等人 [2021] Mahapatra, D., Poellinger, A., Shao, L., Reyes, M., 2021.
    使用自监督学习的可解释性驱动样本选择用于疾病分类和分割。IEEE医学影像学汇刊 40, 2548–2562。doi:[10.1109/TMI.2021.3061724](http://dx.doi.org/10.1109/TMI.2021.3061724)。
- en: 'Mahmood et al. [2022] Mahmood, R., Fidler, S., Law, M.T., 2022. Low-budget
    active learning via wasserstein distance: An integer programming approach, in:
    International Conference on Learning Representations.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahmood 等人 [2022] Mahmood, R., Fidler, S., Law, M.T., 2022. 通过wasserstein距离的低预算主动学习：一种整数规划方法，见：国际学习表征会议。
- en: Mehrtash et al. [2020] Mehrtash, A., Wells, W.M., Tempany, C.M., Abolmaesumi,
    P., Kapur, T., 2020. Confidence calibration and predictive uncertainty estimation
    for deep medical image segmentation. IEEE transactions on medical imaging 39,
    3868–3878.
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mehrtash 等人 [2020] Mehrtash, A., Wells, W.M., Tempany, C.M., Abolmaesumi, P.,
    Kapur, T., 2020. 深度医学图像分割的置信度校准和预测不确定性估计。IEEE医学影像学汇刊 39, 3868–3878。
- en: Menze et al. [2014] Menze, B.H., Jakab, A., Bauer, S., Kalpathy-Cramer, J.,
    Farahani, K., Kirby, J., Burren, Y., Porz, N., Slotboom, J., Wiest, R., et al.,
    2014. The multimodal brain tumor image segmentation benchmark (brats). IEEE transactions
    on medical imaging 34, 1993–2024.
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Menze 等人 [2014] Menze, B.H., Jakab, A., Bauer, S., Kalpathy-Cramer, J., Farahani,
    K., Kirby, J., Burren, Y., Porz, N., Slotboom, J., Wiest, R., 等人，2014. 多模态脑肿瘤图像分割基准（brats）。IEEE医学影像学汇刊
    34, 1993–2024。
- en: 'Mi et al. [2020] Mi, L., Wang, H., Meirovitch, Y., Schalek, R., Turaga, S.C.,
    Lichtman, J.W., Samuel, A.D.T., Shavit, N., 2020. Learning guided electron microscopy
    with active acquisition, in: Martel, A.L., Abolmaesumi, P., Stoyanov, D., Mateus,
    D., Zuluaga, M.A., Zhou, S.K., Racoceanu, D., Joskowicz, L. (Eds.), Medical Image
    Computing and Computer Assisted Intervention – MICCAI 2020, Springer International
    Publishing, Cham. pp. 77–87. doi:[10.1007/978-3-030-59722-1_8](http://dx.doi.org/10.1007/978-3-030-59722-1_8).'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mi 等 [2020] Mi, L., Wang, H., Meirovitch, Y., Schalek, R., Turaga, S.C., Lichtman,
    J.W., Samuel, A.D.T., Shavit, N., 2020. 通过主动获取进行引导的电子显微镜学习，收录于：Martel, A.L., Abolmaesumi,
    P., Stoyanov, D., Mateus, D., Zuluaga, M.A., Zhou, S.K., Racoceanu, D., Joskowicz,
    L. (编辑)，医学图像计算与计算机辅助干预 – MICCAI 2020，Springer International Publishing, Cham.
    pp. 77–87. doi:[10.1007/978-3-030-59722-1_8](http://dx.doi.org/10.1007/978-3-030-59722-1_8)。
- en: 'Miyato et al. [2018] Miyato, T., Maeda, S.i., Koyama, M., Ishii, S., 2018.
    Virtual adversarial training: a regularization method for supervised and semi-supervised
    learning. IEEE transactions on pattern analysis and machine intelligence 41, 1979–1993.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miyato 等 [2018] Miyato, T., Maeda, S.i., Koyama, M., Ishii, S., 2018. 虚拟对抗训练：监督和半监督学习的正则化方法。IEEE
    模式分析与机器智能学报 41, 1979–1993。
- en: 'Moosavi-Dezfooli et al. [2016] Moosavi-Dezfooli, S.M., Fawzi, A., Frossard,
    P., 2016. Deepfool: a simple and accurate method to fool deep neural networks,
    in: Proceedings of the IEEE conference on computer vision and pattern recognition,
    pp. 2574–2582.'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moosavi-Dezfooli 等 [2016] Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., 2016.
    Deepfool：一种简单而准确的欺骗深度神经网络的方法，收录于：IEEE 计算机视觉与模式识别会议论文集，pp. 2574–2582。
- en: 'Munjal et al. [2022] Munjal, P., Hayat, N., Hayat, M., Sourati, J., Khan, S.,
    2022. Towards robust and reproducible active learning using neural networks, in:
    Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    pp. 223–232.'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Munjal 等 [2022] Munjal, P., Hayat, N., Hayat, M., Sourati, J., Khan, S., 2022.
    迈向鲁棒且可重复的神经网络主动学习，收录于：IEEE/CVF 计算机视觉与模式识别会议论文集，pp. 223–232。
- en: 'Nath et al. [2021] Nath, V., Yang, D., Landman, B.A., Xu, D., Roth, H.R., 2021.
    Diminishing uncertainty within the training pool: Active learning for medical
    image segmentation. IEEE Transactions on Medical Imaging 40, 2534–2547. doi:[10.1109/TMI.2020.3048055](http://dx.doi.org/10.1109/TMI.2020.3048055).'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nath 等 [2021] Nath, V., Yang, D., Landman, B.A., Xu, D., Roth, H.R., 2021. 降低训练池中的不确定性：医学图像分割的主动学习。IEEE
    医学成像学报 40, 2534–2547. doi:[10.1109/TMI.2020.3048055](http://dx.doi.org/10.1109/TMI.2020.3048055)。
- en: 'Nath et al. [2022] Nath, V., Yang, D., Roth, H.R., Xu, D., 2022. Warm start
    active learning with proxy labels and selection via semi-supervised fine-tuning,
    in: Wang, L., Dou, Q., Fletcher, P.T., Speidel, S., Li, S. (Eds.), Medical Image
    Computing and Computer Assisted Intervention – MICCAI 2022, Springer Nature Switzerland,
    Cham. pp. 297–308. doi:[10.1007/978-3-031-16452-1_29](http://dx.doi.org/10.1007/978-3-031-16452-1_29).'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nath 等 [2022] Nath, V., Yang, D., Roth, H.R., Xu, D., 2022. 使用代理标签和通过半监督微调的选择进行热启动主动学习，收录于：Wang,
    L., Dou, Q., Fletcher, P.T., Speidel, S., Li, S. (编辑)，医学图像计算与计算机辅助干预 – MICCAI
    2022，Springer Nature Switzerland, Cham. pp. 297–308. doi:[10.1007/978-3-031-16452-1_29](http://dx.doi.org/10.1007/978-3-031-16452-1_29)。
- en: 'Nguyen et al. [2021] Nguyen, C., Huynh, M.T., Tran, M.Q., Nguyen, N.H., Jain,
    M., Ngo, V.D., Vo, T.D., Bui, T., Truong, S.Q.H., 2021. Goal: Gist-set online
    active learning for efficient chest x-ray image annotation, in: Medical Imaging
    with Deep Learning.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nguyen 等 [2021] Nguyen, C., Huynh, M.T., Tran, M.Q., Nguyen, N.H., Jain, M.,
    Ngo, V.D., Vo, T.D., Bui, T., Truong, S.Q.H., 2021. Goal：用于高效胸部X射线图像标注的Gist-set在线主动学习，收录于：深度学习医学成像。
- en: 'Ning et al. [2022] Ning, K.P., Zhao, X., Li, Y., Huang, S.J., 2022. Active
    learning for open-set annotation, in: Proceedings of the IEEE/CVF Conference on
    Computer Vision and Pattern Recognition, pp. 41–49.'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ning 等 [2022] Ning, K.P., Zhao, X., Li, Y., Huang, S.J., 2022. 开放集标注的主动学习，收录于：IEEE/CVF
    计算机视觉与模式识别会议论文集，pp. 41–49。
- en: 'Ning et al. [2021] Ning, M., Lu, D., Wei, D., Bian, C., Yuan, C., Yu, S., Ma,
    K., Zheng, Y., 2021. Multi-anchor active domain adaptation for semantic segmentation,
    in: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp.
    9112–9122.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ning 等 [2021] Ning, M., Lu, D., Wei, D., Bian, C., Yuan, C., Yu, S., Ma, K.,
    Zheng, Y., 2021. 多锚点主动领域适应用于语义分割，收录于：IEEE/CVF 国际计算机视觉大会论文集，pp. 9112–9122。
- en: 'Noroozi and Favaro [2016] Noroozi, M., Favaro, P., 2016. Unsupervised learning
    of visual representations by solving jigsaw puzzles, in: European conference on
    computer vision, Springer. pp. 69–84.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Noroozi 和 Favaro [2016] Noroozi, M., Favaro, P., 2016. 通过解决拼图的无监督视觉表示学习，收录于：欧洲计算机视觉会议，Springer，pp.
    69–84。
- en: OpenAI [2023] OpenAI, 2023. Gpt-4 technical report. [arXiv:2303.08774](http://arxiv.org/abs/2303.08774).
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI [2023] OpenAI, 2023. GPT-4 技术报告。 [arXiv:2303.08774](http://arxiv.org/abs/2303.08774)。
- en: 'Park et al. [2023] Park, Y., Kim, S., Choi, W., Han, D.J., Moon, J., 2023.
    Active learning for object detection with evidential deep learning and hierarchical
    uncertainty aggregation, in: International Conference on Learning Representations.'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等 [2023] Park, Y., Kim, S., Choi, W., Han, D.J., Moon, J., 2023. 结合证据深度学习和层次不确定性聚合的目标检测主动学习，载于：国际学习表征会议。
- en: 'Parvaneh et al. [2022] Parvaneh, A., Abbasnejad, E., Teney, D., Haffari, G.R.,
    van den Hengel, A., Shi, J.Q., 2022. Active learning by feature mixing, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 12237--12246.'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Parvaneh 等 [2022] Parvaneh, A., Abbasnejad, E., Teney, D., Haffari, G.R., van
    den Hengel, A., Shi, J.Q., 2022. 通过特征混合进行主动学习，载于：IEEE/CVF 计算机视觉与模式识别会议论文集，第 12237--12246
    页。
- en: Payer et al. [2019] Payer, C., Štern, D., Bischof, H., Urschler, M., 2019. Integrating
    spatial configuration into heatmap regression based cnns for landmark localization.
    Medical image analysis 54, 207--219.
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Payer 等 [2019] Payer, C., Štern, D., Bischof, H., Urschler, M., 2019. 将空间配置整合到基于热图回归的卷积神经网络中以进行地标定位。医学图像分析
    54, 207--219。
- en: 'Peng et al. [2021] Peng, F., Wang, C., Liu, J., Yang, Z., 2021. Active learning
    for lane detection: A knowledge distillation approach, in: Proceedings of the
    IEEE/CVF International Conference on Computer Vision, pp. 15152--15161.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng 等 [2021] Peng, F., Wang, C., Liu, J., Yang, Z., 2021. 用于车道检测的主动学习：一种知识蒸馏方法，载于：IEEE/CVF
    国际计算机视觉会议论文集，第 15152--15161 页。
- en: 'Pineda et al. [2020] Pineda, L., Basu, S., Romero, A., Calandra, R., Drozdzal,
    M., 2020. Active mr k-space sampling with reinforcement learning, in: Martel,
    A.L., Abolmaesumi, P., Stoyanov, D., Mateus, D., Zuluaga, M.A., Zhou, S.K., Racoceanu,
    D., Joskowicz, L. (Eds.), Medical Image Computing and Computer Assisted Intervention
    – MICCAI 2020, Springer International Publishing, Cham. pp. 23--33. doi:[10.1007/978-3-030-59713-9_3](http://dx.doi.org/10.1007/978-3-030-59713-9_3).'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pineda 等 [2020] Pineda, L., Basu, S., Romero, A., Calandra, R., Drozdzal, M.,
    2020. 基于强化学习的主动磁共振成像 k-空间采样，载于：Martel, A.L., Abolmaesumi, P., Stoyanov, D., Mateus,
    D., Zuluaga, M.A., Zhou, S.K., Racoceanu, D., Joskowicz, L.（编），医学图像计算与计算机辅助干预——MICCAI
    2020，Springer International Publishing，Cham，第 23--33 页。doi：[10.1007/978-3-030-59713-9_3](http://dx.doi.org/10.1007/978-3-030-59713-9_3)。
- en: Pourahmadi et al. [2021] Pourahmadi, K., Nooralinejad, P., Pirsiavash, H., 2021.
    A simple baseline for low-budget active learning. arXiv preprint arXiv:2110.12033
    .
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pourahmadi 等 [2021] Pourahmadi, K., Nooralinejad, P., Pirsiavash, H., 2021.
    低预算主动学习的简单基线。arXiv 预印本 arXiv:2110.12033。
- en: 'Prabhu et al. [2021] Prabhu, V., Chandrasekaran, A., Saenko, K., Hoffman, J.,
    2021. Active domain adaptation via clustering uncertainty-weighted embeddings,
    in: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp.
    8505--8514.'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prabhu 等 [2021] Prabhu, V., Chandrasekaran, A., Saenko, K., Hoffman, J., 2021.
    通过聚类不确定性加权嵌入进行主动领域适应，载于：IEEE/CVF 国际计算机视觉会议论文集，第 8505--8514 页。
- en: Qi et al. [2019] Qi, Q., Li, Y., Wang, J., Zheng, H., Huang, Y., Ding, X., Rohde,
    G.K., 2019. Label-efficient breast cancer histopathological image classification.
    IEEE Journal of Biomedical and Health Informatics 23, 2108--2116. doi:[10.1109/JBHI.2018.2885134](http://dx.doi.org/10.1109/JBHI.2018.2885134).
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qi 等 [2019] Qi, Q., Li, Y., Wang, J., Zheng, H., Huang, Y., Ding, X., Rohde,
    G.K., 2019. 标签高效的乳腺癌组织病理图像分类。IEEE 生物医学与健康信息学杂志 23, 2108--2116。doi：[10.1109/JBHI.2018.2885134](http://dx.doi.org/10.1109/JBHI.2018.2885134)。
- en: Qin et al. [2018] Qin, C., Schlemper, J., Caballero, J., Price, A.N., Hajnal,
    J.V., Rueckert, D., 2018. Convolutional recurrent neural networks for dynamic
    mr image reconstruction. IEEE transactions on medical imaging 38, 280--290.
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin 等 [2018] Qin, C., Schlemper, J., Caballero, J., Price, A.N., Hajnal, J.V.,
    Rueckert, D., 2018. 用于动态磁共振图像重建的卷积递归神经网络。IEEE 医学成像交易 38, 280--290。
- en: 'Qu et al. [2022] Qu, L., Liu, S., Liu, X., Wang, M., Song, Z., 2022. Towards
    label-efficient automatic diagnosis and analysis: a comprehensive survey of advanced
    deep learning-based weakly-supervised, semi-supervised and self-supervised techniques
    in histopathological image analysis. Physics in Medicine & Biology .'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qu 等 [2022] Qu, L., Liu, S., Liu, X., Wang, M., Song, Z., 2022. 迈向标签高效的自动诊断与分析：基于先进深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的全面调查。医学与生物学物理学。
- en: 'Qu et al. [2023] Qu, L., Ma, Y., Yang, Z., Wang, M., Song, Z., 2023. Openal:
    An efficient deep active learning framework for open-set pathology image classification,
    in: International Conference on Medical Image Computing and Computer-Assisted
    Intervention, Springer. pp. 3--13.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qu等人 [2023] Qu, L., Ma, Y., Yang, Z., Wang, M., Song, Z., 2023. Openal：用于开放集病理图像分类的高效深度主动学习框架，见：医学图像计算与计算机辅助干预国际会议，Springer，页码3--13。
- en: 'Quan et al. [2022] Quan, Q., Yao, Q., Li, J., Zhou, S.K., 2022. Which images
    to label for few-shot medical landmark detection?, in: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, pp. 20606--20616.'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Quan等人 [2022] Quan, Q., Yao, Q., Li, J., Zhou, S.K., 2022. 为少样本医学标志检测标注哪些图像？，见：IEEE/CVF计算机视觉与模式识别会议论文集，页码20606--20616。
- en: 'Radford et al. [2021] Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh,
    G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et al., 2021.
    Learning transferable visual models from natural language supervision, in: International
    conference on machine learning, PMLR. pp. 8748--8763.'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford等人 [2021] Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal,
    S., Sastry, G., Askell, A., Mishkin, P., Clark, J., 等人，2021. 从自然语言监督中学习可转移的视觉模型，见：国际机器学习会议，PMLR，页码8748--8763。
- en: Rädsch et al. [2023] Rädsch, T., Reinke, A., Weru, V., Tizabi, M.D., Schreck,
    N., Kavur, A.E., Pekdemir, B., Roß, T., Kopp-Schneider, A., Maier-Hein, L., 2023.
    Labelling instructions matter in biomedical image analysis. Nature Machine Intelligence
    5, 273--283.
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rädsch等人 [2023] Rädsch, T., Reinke, A., Weru, V., Tizabi, M.D., Schreck, N.,
    Kavur, A.E., Pekdemir, B., Roß, T., Kopp-Schneider, A., Maier-Hein, L., 2023.
    标注说明在生物医学图像分析中的重要性。自然机器智能5, 273--283。
- en: Rajpurkar et al. [2022] Rajpurkar, P., Chen, E., Banerjee, O., Topol, E.J.,
    2022. Ai in health and medicine. Nature medicine 28, 31--38.
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajpurkar等人 [2022] Rajpurkar, P., Chen, E., Banerjee, O., Topol, E.J., 2022.
    健康和医学中的人工智能。自然医学28, 31--38。
- en: 'Rangwani et al. [2021] Rangwani, H., Jain, A., Aithal, S.K., Babu, R.V., 2021.
    S3vaada: Submodular subset selection for virtual adversarial active domain adaptation,
    in: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp.
    7516--7525.'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rangwani等人 [2021] Rangwani, H., Jain, A., Aithal, S.K., Babu, R.V., 2021. S3vaada：用于虚拟对抗主动领域适应的子集选择，见：IEEE/CVF国际计算机视觉会议论文集，页码7516--7525。
- en: Ren et al. [2021] Ren, P., Xiao, Y., Chang, X., Huang, P.Y., Li, Z., Gupta,
    B.B., Chen, X., Wang, X., 2021. A survey of deep active learning. ACM computing
    surveys (CSUR) 54, 1--40.
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ren等人 [2021] Ren, P., Xiao, Y., Chang, X., Huang, P.Y., Li, Z., Gupta, B.B.,
    Chen, X., Wang, X., 2021. 深度主动学习综述。ACM计算机调查（CSUR）54, 1--40。
- en: 'Rombach et al. [2022] Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer,
    B., 2022. High-resolution image synthesis with latent diffusion models, in: Proceedings
    of the IEEE/CVF conference on computer vision and pattern recognition, pp. 10684--10695.'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rombach等人 [2022] Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.,
    2022. 使用潜在扩散模型进行高分辨率图像合成，见：IEEE/CVF计算机视觉与模式识别会议论文集，页码10684--10695。
- en: 'Roth and Small [2006] Roth, D., Small, K., 2006. Margin-based active learning
    for structured output spaces, in: Hutchison, D., Kanade, T., Kittler, J., Kleinberg,
    J.M., Mattern, F., Mitchell, J.C., Naor, M., Nierstrasz, O., Pandu Rangan, C.,
    Steffen, B., Sudan, M., Terzopoulos, D., Tygar, D., Vardi, M.Y., Weikum, G., Fürnkranz,
    J., Scheffer, T., Spiliopoulou, M. (Eds.), Machine Learning: ECML 2006. Springer
    Berlin Heidelberg, Berlin, Heidelberg. volume 4212, pp. 413--424. doi:[10.1007/11871842_40](http://dx.doi.org/10.1007/11871842_40).'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roth和Small [2006] Roth, D., Small, K., 2006. 基于边际的结构化输出空间主动学习，见：Hutchison, D.,
    Kanade, T., Kittler, J., Kleinberg, J.M., Mattern, F., Mitchell, J.C., Naor, M.,
    Nierstrasz, O., Pandu Rangan, C., Steffen, B., Sudan, M., Terzopoulos, D., Tygar,
    D., Vardi, M.Y., Weikum, G., Fürnkranz, J., Scheffer, T., Spiliopoulou, M.（编），机器学习：ECML
    2006，Springer Berlin Heidelberg, Berlin, Heidelberg，第4212卷，页码413--424。doi:[10.1007/11871842_40](http://dx.doi.org/10.1007/11871842_40)。
- en: 'Sadafi et al. [2019] Sadafi, A., Koehler, N., Makhro, A., Bogdanova, A., Navab,
    N., Marr, C., Peng, T., 2019. Multiclass deep active learning for detecting red
    blood cell subtypes in brightfield microscopy, in: Shen, D., Liu, T., Peters,
    T.M., Staib, L.H., Essert, C., Zhou, S., Yap, P.T., Khan, A. (Eds.), Medical Image
    Computing and Computer Assisted Intervention – MICCAI 2019, Springer International
    Publishing, Cham. pp. 685--693. doi:[10.1007/978-3-030-32239-7_76](http://dx.doi.org/10.1007/978-3-030-32239-7_76).'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sadafi等人 [2019] Sadafi, A., Koehler, N., Makhro, A., Bogdanova, A., Navab, N.,
    Marr, C., Peng, T., 2019. 用于检测亮场显微镜中红细胞亚型的多类深度主动学习，见：Shen, D., Liu, T., Peters,
    T.M., Staib, L.H., Essert, C., Zhou, S., Yap, P.T., Khan, A.（编），医学图像计算与计算机辅助干预
    - MICCAI 2019，Springer International Publishing, Cham，页码685--693。doi:[10.1007/978-3-030-32239-7_76](http://dx.doi.org/10.1007/978-3-030-32239-7_76)。
- en: 'Sadafi et al. [2023] Sadafi, A., Navab, N., Marr, C., 2023. Active learning
    enhances classification of histopathology whole slide images with attention-based
    multiple instance learning, in: 2023 IEEE 20th International Symposium on Biomedical
    Imaging (ISBI), pp. 1--5. doi:[10.1109/ISBI53787.2023.10230685](http://dx.doi.org/10.1109/ISBI53787.2023.10230685).'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sadafi 等 [2023] Sadafi, A., Navab, N., Marr, C., 2023. 主动学习通过基于注意力的多实例学习提升组织病理学全幻灯片图像的分类，见：2023
    IEEE 第20届生物医学成像国际研讨会（ISBI），页码 1--5。 doi:[10.1109/ISBI53787.2023.10230685](http://dx.doi.org/10.1109/ISBI53787.2023.10230685)。
- en: 'Saquil et al. [2018] Saquil, Y., Kim, K.I., Hall, P., 2018. Ranking cgans:
    Subjective control over semantic image attributes. arXiv preprint arXiv:1804.04082
    .'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saquil 等 [2018] Saquil, Y., Kim, K.I., Hall, P., 2018. 排名 cgans：对语义图像属性的主观控制。arXiv
    预印本 arXiv:1804.04082。
- en: 'Sener and Savarese [2018] Sener, O., Savarese, S., 2018. Active learning for
    convolutional neural networks: A core-set approach, in: International Conference
    on Learning Representations.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sener 和 Savarese [2018] Sener, O., Savarese, S., 2018. 卷积神经网络的主动学习：核心集方法，见：国际学习表示会议。
- en: Sensoy et al. [2018] Sensoy, M., Kaplan, L., Kandemir, M., 2018. Evidential
    deep learning to quantify classification uncertainty. Advances in neural information
    processing systems 31.
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sensoy 等 [2018] Sensoy, M., Kaplan, L., Kandemir, M., 2018. 量化分类不确定性的证据深度学习。神经信息处理系统进展
    31。
- en: Settles [2009] Settles, B., 2009. Active learning literature survey .
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Settles [2009] Settles, B., 2009. 主动学习文献综述。
- en: 'Seung et al. [1992] Seung, H.S., Opper, M., Sompolinsky, H., 1992. Query by
    committee, in: Proceedings of the Fifth Annual Workshop on Computational Learning
    Theory, Association for Computing Machinery, New York, NY, USA. pp. 287--294.
    doi:[10.1145/130385.130417](http://dx.doi.org/10.1145/130385.130417).'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Seung 等 [1992] Seung, H.S., Opper, M., Sompolinsky, H., 1992. 委员会查询，见：第五届年度计算学习理论研讨会论文集，计算机协会，New
    York, NY, USA，页码 287--294。 doi:[10.1145/130385.130417](http://dx.doi.org/10.1145/130385.130417)。
- en: 'Shaham et al. [2019] Shaham, T.R., Dekel, T., Michaeli, T., 2019. Singan: Learning
    a generative model from a single natural image, in: Proceedings of the IEEE/CVF
    international conference on computer vision, pp. 4570--4580.'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shaham 等 [2019] Shaham, T.R., Dekel, T., Michaeli, T., 2019. Singan: 从单一自然图像中学习生成模型，见：IEEE/CVF
    国际计算机视觉会议论文集，页码 4570--4580。'
- en: 'Shen et al. [2020] Shen, H., Tian, K., Dong, P., Zhang, J., Yan, K., Che, S.,
    Yao, J., Luo, P., Han, X., 2020. Deep active learning for breast cancer segmentation
    on immunohistochemistry images, in: Martel, A.L., Abolmaesumi, P., Stoyanov, D.,
    Mateus, D., Zuluaga, M.A., Zhou, S.K., Racoceanu, D., Joskowicz, L. (Eds.), Medical
    Image Computing and Computer Assisted Intervention – MICCAI 2020, Springer International
    Publishing, Cham. pp. 509--518. doi:[10.1007/978-3-030-59722-1_49](http://dx.doi.org/10.1007/978-3-030-59722-1_49).'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等 [2020] Shen, H., Tian, K., Dong, P., Zhang, J., Yan, K., Che, S., Yao,
    J., Luo, P., Han, X., 2020. 基于免疫组织化学图像的乳腺癌分割深度主动学习，见：Martel, A.L., Abolmaesumi,
    P., Stoyanov, D., Mateus, D., Zuluaga, M.A., Zhou, S.K., Racoceanu, D., Joskowicz,
    L. (编辑)，医学图像计算与计算机辅助手术 - MICCAI 2020，Springer International Publishing，Cham，页码
    509--518。 doi:[10.1007/978-3-030-59722-1_49](http://dx.doi.org/10.1007/978-3-030-59722-1_49)。
- en: 'Shin et al. [2021] Shin, I., Kim, D.J., Cho, J.W., Woo, S., Park, K., Kweon,
    I.S., 2021. Labor: Labeling only if required for domain adaptive semantic segmentation,
    in: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp.
    8588--8598.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shin 等 [2021] Shin, I., Kim, D.J., Cho, J.W., Woo, S., Park, K., Kweon, I.S.,
    2021. Labor: 仅在需要时进行标签标注，用于领域自适应语义分割，见：IEEE/CVF 国际计算机视觉会议论文集，页码 8588--8598。'
- en: 'Shui et al. [2020] Shui, C., Zhou, F., Gagné, C., Wang, B., 2020. Deep active
    learning: Unified and principled method for query and training, in: Proceedings
    of the Twenty Third International Conference on Artificial Intelligence and Statistics,
    PMLR. pp. 1308--1318.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shui 等 [2020] Shui, C., Zhou, F., Gagné, C., Wang, B., 2020. 深度主动学习：统一且有原则的查询和训练方法，见：第二十三届国际人工智能与统计会议论文集，PMLR，页码
    1308--1318。
- en: 'Siddiqui et al. [2020] Siddiqui, Y., Valentin, J., Niessner, M., 2020. Viewal:
    Active learning with viewpoint entropy for semantic segmentation, in: 2020 IEEE/CVF
    Conference on Computer Vision and Pattern Recognition (CVPR), IEEE, Seattle, WA,
    USA. pp. 9430--9440. doi:[10.1109/CVPR42600.2020.00945](http://dx.doi.org/10.1109/CVPR42600.2020.00945).'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Siddiqui 等 [2020] Siddiqui, Y., Valentin, J., Niessner, M., 2020. Viewal: 用视角熵进行语义分割的主动学习，见：2020
    IEEE/CVF 计算机视觉与模式识别会议（CVPR），IEEE，Seattle, WA, USA，页码 9430--9440。 doi:[10.1109/CVPR42600.2020.00945](http://dx.doi.org/10.1109/CVPR42600.2020.00945)。'
- en: Sim et al. [2020] Sim, Y., Chung, M.J., Kotter, E., Yune, S., Kim, M., Do, S.,
    Han, K., Kim, H., Yang, S., Lee, D.J., et al., 2020. Deep convolutional neural
    network--based software improves radiologist detection of malignant lung nodules
    on chest radiographs. Radiology 294, 199--209.
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sim 等人 [2020] Sim, Y., Chung, M.J., Kotter, E., Yune, S., Kim, M., Do, S., Han,
    K., Kim, H., Yang, S., Lee, D.J., 等，2020. 基于深度卷积神经网络的软件提高了放射科医生对胸部X光片中恶性肺结节的检测能力。《放射学》294，第199--209页。
- en: 'Sinha et al. [2019] Sinha, S., Ebrahimi, S., Darrell, T., 2019. Variational
    adversarial active learning, in: Proceedings of the IEEE/CVF International Conference
    on Computer Vision, pp. 5972--5981.'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sinha 等人 [2019] Sinha, S., Ebrahimi, S., Darrell, T., 2019. 变分对抗主动学习，见：IEEE/CVF
    国际计算机视觉会议论文集，第5972--5981页。
- en: Sourati et al. [2017] Sourati, J., Akcakaya, M., Leen, T.K., Erdogmus, D., Dy,
    J.G., 2017. Asymptotic analysis of objectives based on fisher information in active
    learning. The Journal of Machine Learning Research 18, 1123--1163.
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sourati 等人 [2017] Sourati, J., Akcakaya, M., Leen, T.K., Erdogmus, D., Dy, J.G.,
    2017. 基于费舍尔信息的目标的渐近分析在主动学习中的应用。《机器学习研究杂志》18，第1123--1163页。
- en: 'Sourati et al. [2018] Sourati, J., Gholipour, A., Dy, J.G., Kurugol, S., Warfield,
    S.K., 2018. Active deep learning with fisher information for patch-wise semantic
    segmentation, in: Stoyanov, D., Taylor, Z., Carneiro, G., Syeda-Mahmood, T., Martel,
    A., Maier-Hein, L., Tavares, J.M.R., Bradley, A., Papa, J.P., Belagiannis, V.,
    Nascimento, J.C., Lu, Z., Conjeti, S., Moradi, M., Greenspan, H., Madabhushi,
    A. (Eds.), Deep Learning in Medical Image Analysis and Multimodal Learning for
    Clinical Decision Support. Springer International Publishing, Cham. volume 11045,
    pp. 83--91. doi:[10.1007/978-3-030-00889-5_10](http://dx.doi.org/10.1007/978-3-030-00889-5_10).'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sourati 等人 [2018] Sourati, J., Gholipour, A., Dy, J.G., Kurugol, S., Warfield,
    S.K., 2018. 基于费舍尔信息的主动深度学习用于补丁级语义分割，见：Stoyanov, D., Taylor, Z., Carneiro, G.,
    Syeda-Mahmood, T., Martel, A., Maier-Hein, L., Tavares, J.M.R., Bradley, A., Papa,
    J.P., Belagiannis, V., Nascimento, J.C., Lu, Z., Conjeti, S., Moradi, M., Greenspan,
    H., Madabhushi, A. (编辑)，《医学图像分析中的深度学习与临床决策支持的多模态学习》。Springer International Publishing，Cham，第11045卷，第83--91页。doi:[10.1007/978-3-030-00889-5_10](http://dx.doi.org/10.1007/978-3-030-00889-5_10)。
- en: Sourati et al. [2019] Sourati, J., Gholipour, A., Dy, J.G., Tomas-Fernandez,
    X., Kurugol, S., Warfield, S.K., 2019. Intelligent labeling based on fisher information
    for medical image segmentation using deep learning. IEEE Transactions on Medical
    Imaging 38, 2642--2653. doi:[10.1109/TMI.2019.2907805](http://dx.doi.org/10.1109/TMI.2019.2907805).
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sourati 等人 [2019] Sourati, J., Gholipour, A., Dy, J.G., Tomas-Fernandez, X.,
    Kurugol, S., Warfield, S.K., 2019. 基于费舍尔信息的智能标注用于深度学习的医学图像分割。《IEEE 医学成像汇刊》38，第2642--2653页。doi:[10.1109/TMI.2019.2907805](http://dx.doi.org/10.1109/TMI.2019.2907805)。
- en: 'Su et al. [2020] Su, J.C., Tsai, Y.H., Sohn, K., Liu, B., Maji, S., Chandraker,
    M., 2020. Active adversarial domain adaptation, in: Proceedings of the IEEE/CVF
    Winter Conference on Applications of Computer Vision, pp. 739--748.'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Su 等人 [2020] Su, J.C., Tsai, Y.H., Sohn, K., Liu, B., Maji, S., Chandraker,
    M., 2020. 主动对抗领域适应，见：IEEE/CVF 冬季计算机视觉应用会议论文集，第739--748页。
- en: 'Sun et al. [2023] Sun, S., Zhi, S., Heikkilä, J., Liu, L., 2023. Evidential
    uncertainty and diversity guided active learning for scene graph generation, in:
    The Eleventh International Conference on Learning Representations.'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等人 [2023] Sun, S., Zhi, S., Heikkilä, J., Liu, L., 2023. 基于证据的不确定性和多样性引导的主动学习用于场景图生成，见：第十一届国际学习表征会议。
- en: 'Tajbakhsh et al. [2020] Tajbakhsh, N., Jeyaseelan, L., Li, Q., Chiang, J.N.,
    Wu, Z., Ding, X., 2020. Embracing imperfect datasets: A review of deep learning
    solutions for medical image segmentation. Medical Image Analysis 63, 101693.'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tajbakhsh 等人 [2020] Tajbakhsh, N., Jeyaseelan, L., Li, Q., Chiang, J.N., Wu,
    Z., Ding, X., 2020. 接受不完美数据集：医学图像分割的深度学习解决方案综述。《医学图像分析》63，101693。
- en: 'Takezoe et al. [2023] Takezoe, R., Liu, X., Mao, S., Chen, M.T., Feng, Z.,
    Zhang, S., Wang, X., et al., 2023. Deep active learning for computer vision: Past
    and future. APSIPA Transactions on Signal and Information Processing 12.'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Takezoe 等人 [2023] Takezoe, R., Liu, X., Mao, S., Chen, M.T., Feng, Z., Zhang,
    S., Wang, X., 等，2023. 计算机视觉中的深度主动学习：过去与未来。《APSIPA 信号与信息处理事务》12。
- en: 'Tang et al. [2022] Tang, C., Xie, L., Zhang, G., Zhang, X., Tian, Q., Hu, X.,
    2022. Active pointly-supervised instance segmentation, in: European Conference
    on Computer Vision, Springer. pp. 606--623.'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang 等人 [2022] Tang, C., Xie, L., Zhang, G., Zhang, X., Tian, Q., Hu, X., 2022.
    主动点监督实例分割，见：欧洲计算机视觉会议，Springer，第606--623页。
- en: 'Tarvainen and Valpola [2017] Tarvainen, A., Valpola, H., 2017. Mean teachers
    are better role models: Weight-averaged consistency targets improve semi-supervised
    deep learning results. Advances in neural information processing systems 30.'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tarvainen 和 Valpola [2017] Tarvainen, A., Valpola, H., 2017. 平均教师是更好的榜样：加权平均一致性目标改善半监督深度学习结果。神经信息处理系统进展
    30。
- en: Tolkach et al. [2020] Tolkach, Y., Dohmgörgen, T., Toma, M., Kristiansen, G.,
    2020. High-accuracy prostate cancer pathology using deep learning. Nature Machine
    Intelligence 2, 411--418.
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tolkach 等人 [2020] Tolkach, Y., Dohmgörgen, T., Toma, M., Kristiansen, G., 2020.
    使用深度学习进行高准确度前列腺癌病理学分析。Nature Machine Intelligence 2, 411--418。
- en: 'Tran et al. [2019] Tran, T., Do, T.T., Reid, I., Carneiro, G., 2019. Bayesian
    generative active deep learning, in: Proceedings of the 36th International Conference
    on Machine Learning, PMLR. pp. 6295--6304.'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tran 等人 [2019] Tran, T., Do, T.T., Reid, I., Carneiro, G., 2019. 贝叶斯生成主动深度学习，见：第
    36 届国际机器学习会议论文集，PMLR。第 6295--6304 页。
- en: Tschandl et al. [2020] Tschandl, P., Rinner, C., Apalla, Z., Argenziano, G.,
    Codella, N., Halpern, A., Janda, M., Lallas, A., Longo, C., Malvehy, J., et al.,
    2020. Human--computer collaboration for skin cancer recognition. Nature Medicine
    26, 1229--1234.
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tschandl 等人 [2020] Tschandl, P., Rinner, C., Apalla, Z., Argenziano, G., Codella,
    N., Halpern, A., Janda, M., Lallas, A., Longo, C., Malvehy, J., 等人, 2020. 人机协作用于皮肤癌识别。Nature
    Medicine 26, 1229--1234。
- en: 'Unnikrishnan et al. [2021] Unnikrishnan, B., Nguyen, C., Balaram, S., Li, C.,
    Foo, C.S., Krishnaswamy, P., 2021. Semi-supervised classification of radiology
    images with noteacher: A teacher that is not mean. Medical Image Analysis 73,
    102148.'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Unnikrishnan 等人 [2021] Unnikrishnan, B., Nguyen, C., Balaram, S., Li, C., Foo,
    C.S., Krishnaswamy, P., 2021. 使用 noteacher 进行放射学图像的半监督分类：一个不刻薄的教师。医学图像分析 73, 102148。
- en: 'Vo et al. [2022] Vo, H.V., Siméoni, O., Gidaris, S., Bursuc, A., Pérez, P.,
    Ponce, J., 2022. Active learning strategies for weakly-supervised object detection,
    in: European Conference on Computer Vision, Springer. pp. 211--230.'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vo 等人 [2022] Vo, H.V., Siméoni, O., Gidaris, S., Bursuc, A., Pérez, P., Ponce,
    J., 2022. 用于弱监督目标检测的主动学习策略，见：欧洲计算机视觉会议，施普林格。第 211--230 页。
- en: Wan et al. [2023] Wan, F., Ye, Q., Yuan, T., Xu, S., Liu, J., Ji, X., Huang,
    Q., 2023. Multiple instance differentiation learning for active object detection.
    IEEE Transactions on Pattern Analysis and Machine Intelligence , 1--15doi:[10.1109/TPAMI.2023.3277738](http://dx.doi.org/10.1109/TPAMI.2023.3277738).
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wan 等人 [2023] Wan, F., Ye, Q., Yuan, T., Xu, S., Liu, J., Ji, X., Huang, Q.,
    2023. 多实例区分学习用于主动目标检测。IEEE 模式分析与机器智能学报 , 1--15 doi:[10.1109/TPAMI.2023.3277738](http://dx.doi.org/10.1109/TPAMI.2023.3277738)。
- en: Wang et al. [2022a] Wang, C., Shang, K., Zhang, H., Zhao, S., Liang, D., Zhou,
    S.K., 2022a. Active ct reconstruction with a learned sampling policy. arXiv preprint
    arXiv:2211.01670 .
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2022a] Wang, C., Shang, K., Zhang, H., Zhao, S., Liang, D., Zhou, S.K.,
    2022a. 具有学习采样策略的主动 CT 重建。arXiv 预印本 arXiv:2211.01670。
- en: 'Wang et al. [2020a] Wang, J., Yan, Y., Zhang, Y., Cao, G., Yang, M., Ng, M.K.,
    2020a. Deep reinforcement active learning for medical image classification, in:
    Martel, A.L., Abolmaesumi, P., Stoyanov, D., Mateus, D., Zuluaga, M.A., Zhou,
    S.K., Racoceanu, D., Joskowicz, L. (Eds.), Medical Image Computing and Computer
    Assisted Intervention – MICCAI 2020, Springer International Publishing, Cham.
    pp. 33--42. doi:[10.1007/978-3-030-59710-8_4](http://dx.doi.org/10.1007/978-3-030-59710-8_4).'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2020a] Wang, J., Yan, Y., Zhang, Y., Cao, G., Yang, M., Ng, M.K., 2020a.
    用于医学图像分类的深度强化主动学习，见：Martel, A.L., Abolmaesumi, P., Stoyanov, D., Mateus, D., Zuluaga,
    M.A., Zhou, S.K., Racoceanu, D., Joskowicz, L.（编），医学图像计算与计算机辅助手术 – MICCAI 2020，施普林格国际出版公司，Cham.
    第 33--42 页。doi:[10.1007/978-3-030-59710-8_4](http://dx.doi.org/10.1007/978-3-030-59710-8_4)。
- en: Wang et al. [2017] Wang, K., Zhang, D., Li, Y., Zhang, R., Lin, L., 2017. Cost-effective
    active learning for deep image classification. IEEE Transactions on Circuits and
    Systems for Video Technology 27, 2591--2600. doi:[10.1109/TCSVT.2016.2589879](http://dx.doi.org/10.1109/TCSVT.2016.2589879).
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2017] Wang, K., Zhang, D., Li, Y., Zhang, R., Lin, L., 2017. 经济高效的深度图像分类主动学习。IEEE
    视听技术电路与系统学报 27, 2591--2600。doi:[10.1109/TCSVT.2016.2589879](http://dx.doi.org/10.1109/TCSVT.2016.2589879)。
- en: Wang et al. [2018] Wang, P., Xiao, X., Glissen Brown, J.R., Berzin, T.M., Tu,
    M., Xiong, F., Hu, X., Liu, P., Song, Y., Zhang, D., et al., 2018. Development
    and validation of a deep-learning algorithm for the detection of polyps during
    colonoscopy. Nature biomedical engineering 2, 741--748.
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2018] Wang, P., Xiao, X., Glissen Brown, J.R., Berzin, T.M., Tu, M.,
    Xiong, F., Hu, X., Liu, P., Song, Y., Zhang, D., 等人, 2018. 开发和验证一种用于在结肠镜检查过程中检测息肉的深度学习算法。Nature
    生物医学工程 2, 741--748。
- en: 'Wang et al. [2020b] Wang, S., Li, Y., Ma, K., Ma, R., Guan, H., Zheng, Y.,
    2020b. Dual adversarial network for deep active learning, in: Vedaldi, A., Bischof,
    H., Brox, T., Frahm, J.M. (Eds.), Computer Vision – ECCV 2020, Springer International
    Publishing, Cham. pp. 680--696. doi:[10.1007/978-3-030-58586-0_40](http://dx.doi.org/10.1007/978-3-030-58586-0_40).'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang等人[2020b] Wang, S., Li, Y., Ma, K., Ma, R., Guan, H., Zheng, Y., 2020b.
    用于深度主动学习的双重对抗网络, 见: Vedaldi, A., Bischof, H., Brox, T., Frahm, J.M. (编), 计算机视觉
    – ECCV 2020, Springer International Publishing, Cham. 页码680--696. doi:[10.1007/978-3-030-58586-0_40](http://dx.doi.org/10.1007/978-3-030-58586-0_40)。'
- en: 'Wang et al. [2020c] Wang, S., Tarroni, G., Qin, C., Mo, Y., Dai, C., Chen,
    C., Glocker, B., Guo, Y., Rueckert, D., Bai, W., 2020c. Deep generative model-based
    quality control for cardiac mri segmentation, in: Medical Image Computing and
    Computer Assisted Intervention--MICCAI 2020: 23rd International Conference, Lima,
    Peru, October 4--8, 2020, Proceedings, Part IV 23, Springer. pp. 88--97.'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang等人[2020c] Wang, S., Tarroni, G., Qin, C., Mo, Y., Dai, C., Chen, C., Glocker,
    B., Guo, Y., Rueckert, D., Bai, W., 2020c. 基于深度生成模型的心脏MRI分割质量控制, 见: 医学图像计算与计算机辅助干预--MICCAI
    2020: 第23届国际会议, 秘鲁利马, 2020年10月4--8日, 论文集, 第IV部分 23, Springer. 页码88--97。'
- en: Wang et al. [2022b] Wang, T., Li, X., Yang, P., Hu, G., Zeng, X., Huang, S.,
    Xu, C.Z., Xu, M., 2022b. Boosting active learning via improving test performance.
    Proceedings of the AAAI Conference on Artificial Intelligence 36, 8566--8574.
    doi:[10.1609/aaai.v36i8.20834](http://dx.doi.org/10.1609/aaai.v36i8.20834).
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人[2022b] Wang, T., Li, X., Yang, P., Hu, G., Zeng, X., Huang, S., Xu, C.Z.,
    Xu, M., 2022b. 通过提高测试性能来提升主动学习. AAAI人工智能会议论文集 36, 8566--8574. doi:[10.1609/aaai.v36i8.20834](http://dx.doi.org/10.1609/aaai.v36i8.20834)。
- en: 'Wang et al. [2022c] Wang, X., Lian, L., Yu, S.X., 2022c. Unsupervised selective
    labeling for more effective semi-supervised learning, in: European Conference
    on Computer Vision, Springer. pp. 427--445.'
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang等人[2022c] Wang, X., Lian, L., Yu, S.X., 2022c. 无监督选择性标注以更有效的半监督学习, 见: 欧洲计算机视觉会议,
    Springer. 页码427--445。'
- en: Wang et al. [2021] Wang, Y., Huang, G., Song, S., Pan, X., Xia, Y., Wu, C.,
    2021. Regularizing deep networks with semantic data augmentation. IEEE Transactions
    on Pattern Analysis and Machine Intelligence 44, 3733--3748.
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人[2021] Wang, Y., Huang, G., Song, S., Pan, X., Xia, Y., Wu, C., 2021.
    通过语义数据增强对深度网络进行正则化. IEEE模式分析与机器智能交易 44, 3733--3748。
- en: 'Wang and Yin [2021] Wang, Z., Yin, Z., 2021. Annotation-efficient cell counting,
    in: de Bruijne, M., Cattin, P.C., Cotin, S., Padoy, N., Speidel, S., Zheng, Y.,
    Essert, C. (Eds.), Medical Image Computing and Computer Assisted Intervention
    – MICCAI 2021, Springer International Publishing, Cham. pp. 405--414. doi:[10.1007/978-3-030-87237-3_39](http://dx.doi.org/10.1007/978-3-030-87237-3_39).'
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang和Yin [2021] Wang, Z., Yin, Z., 2021. 注释高效的细胞计数, 见: de Bruijne, M., Cattin,
    P.C., Cotin, S., Padoy, N., Speidel, S., Zheng, Y., Essert, C. (编), 医学图像计算与计算机辅助干预
    – MICCAI 2021, Springer International Publishing, Cham. 页码405--414. doi:[10.1007/978-3-030-87237-3_39](http://dx.doi.org/10.1007/978-3-030-87237-3_39)。'
- en: 'Wei et al. [2015] Wei, K., Iyer, R., Bilmes, J., 2015. Submodularity in data
    subset selection and active learning, in: Proceedings of the 32nd International
    Conference on Machine Learning, PMLR. pp. 1954--1963.'
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wei等人[2015] Wei, K., Iyer, R., Bilmes, J., 2015. 数据子集选择和主动学习中的子模性, 见: 第32届国际机器学习大会论文集,
    PMLR. 页码1954--1963。'
- en: Williams [1992] Williams, R.J., 1992. Simple statistical gradient-following
    algorithms for connectionist reinforcement learning. Machine learning 8, 229--256.
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Williams [1992] Williams, R.J., 1992. 用于连接主义强化学习的简单统计梯度跟踪算法. 机器学习 8, 229--256。
- en: 'Wu et al. [2022a] Wu, J., Chen, J., Huang, D., 2022a. Entropy-based active
    learning for object detection with progressive diversity constraint, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9397--9406.'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu等人[2022a] Wu, J., Chen, J., Huang, D., 2022a. 基于熵的对象检测主动学习与渐进多样性约束, 见: IEEE/CVF计算机视觉与模式识别会议论文集,
    页码9397--9406。'
- en: 'Wu et al. [2022b] Wu, T.H., Liou, Y.S., Yuan, S.J., Lee, H.Y., Chen, T.I.,
    Huang, K.C., Hsu, W.H., 2022b. D2ada: Dynamic density-aware active domain adaptation
    for semantic segmentation, in: European Conference on Computer Vision, Springer.
    pp. 449--467.'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu等人[2022b] Wu, T.H., Liou, Y.S., Yuan, S.J., Lee, H.Y., Chen, T.I., Huang,
    K.C., Hsu, W.H., 2022b. D2ada: 动态密度感知的主动领域适应用于语义分割, 见: 欧洲计算机视觉会议, Springer. 页码449--467。'
- en: 'Wu et al. [2021a] Wu, T.H., Liu, Y.C., Huang, Y.K., Lee, H.Y., Su, H.T., Huang,
    P.C., Hsu, W.H., 2021a. Redal: Region-based and diversity-aware active learning
    for point cloud semantic segmentation, in: Proceedings of the IEEE/CVF International
    Conference on Computer Vision, pp. 15510--15519.'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等 [2021a] Wu, T.H., Liu, Y.C., Huang, Y.K., Lee, H.Y., Su, H.T., Huang, P.C.,
    Hsu, W.H., 2021a. Redal：基于区域和多样性意识的主动学习用于点云语义分割，发表于：IEEE/CVF 国际计算机视觉会议论文集，第 15510--15519
    页。
- en: 'Wu et al. [2021b] Wu, X., Chen, C., Zhong, M., Wang, J., Shi, J., 2021b. Covid-al:
    The diagnosis of covid-19 with deep active learning. Medical Image Analysis 68,
    101913. doi:[10.1016/j.media.2020.101913](http://dx.doi.org/10.1016/j.media.2020.101913).'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等 [2021b] Wu, X., Chen, C., Zhong, M., Wang, J., Shi, J., 2021b. Covid-al：使用深度主动学习进行
    COVID-19 诊断。《医学图像分析》68, 101913。doi:[10.1016/j.media.2020.101913](http://dx.doi.org/10.1016/j.media.2020.101913)。
- en: 'Wu et al. [2022c] Wu, Y., Zheng, B., Chen, J., Chen, D.Z., Wu, J., 2022c. Self-learning
    and one-shot learning based single-slice annotation for 3d medical image segmentation,
    in: Wang, L., Dou, Q., Fletcher, P.T., Speidel, S., Li, S. (Eds.), Medical Image
    Computing and Computer Assisted Intervention – MICCAI 2022, Springer Nature Switzerland,
    Cham. pp. 244--254. doi:[10.1007/978-3-031-16452-1_24](http://dx.doi.org/10.1007/978-3-031-16452-1_24).'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等 [2022c] Wu, Y., Zheng, B., Chen, J., Chen, D.Z., Wu, J., 2022c. 基于自学习和一次性学习的单切片注释用于
    3D 医学图像分割，发表于：Wang, L., Dou, Q., Fletcher, P.T., Speidel, S., Li, S. (编)，《医学图像计算与计算机辅助干预——MICCAI
    2022》，Springer Nature Switzerland, Cham. 第 244--254 页。doi:[10.1007/978-3-031-16452-1_24](http://dx.doi.org/10.1007/978-3-031-16452-1_24)。
- en: 'Xie et al. [2022a] Xie, B., Yuan, L., Li, S., Liu, C.H., Cheng, X., 2022a.
    Towards fewer annotations: Active learning via region impurity and prediction
    uncertainty for domain adaptive semantic segmentation, in: Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8068--8078.'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等 [2022a] Xie, B., Yuan, L., Li, S., Liu, C.H., Cheng, X., 2022a. 朝着更少的注释：通过区域不纯度和预测不确定性进行主动学习以实现领域自适应语义分割，发表于：IEEE/CVF
    计算机视觉与模式识别会议论文集，第 8068--8078 页。
- en: 'Xie et al. [2022b] Xie, B., Yuan, L., Li, S., Liu, C.H., Cheng, X., Wang, G.,
    2022b. Active learning for domain adaptation: An energy-based approach, in: Proceedings
    of the AAAI Conference on Artificial Intelligence, pp. 8708--8716. doi:[10.1609/aaai.v36i8.20850](http://dx.doi.org/10.1609/aaai.v36i8.20850).'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等 [2022b] Xie, B., Yuan, L., Li, S., Liu, C.H., Cheng, X., Wang, G., 2022b.
    用于领域适应的主动学习：一种基于能量的方法，发表于：AAAI 人工智能会议论文集，第 8708--8716 页。doi:[10.1609/aaai.v36i8.20850](http://dx.doi.org/10.1609/aaai.v36i8.20850)。
- en: 'Xie et al. [2022c] Xie, M., Li, S., Zhang, R., Liu, C.H., 2022c. Dirichlet-based
    uncertainty calibration for active domain adaptation, in: The Eleventh International
    Conference on Learning Representations.'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等 [2022c] Xie, M., Li, S., Zhang, R., Liu, C.H., 2022c. 基于 Dirichlet 的不确定性校准用于主动领域适应，发表于：第十一届国际学习表征会议。
- en: 'Xie et al. [2022d] Xie, M., Li, Y., Wang, Y., Luo, Z., Gan, Z., Sun, Z., Chi,
    M., Wang, C., Wang, P., 2022d. Learning distinctive margin toward active domain
    adaptation, in: Proceedings of the IEEE/CVF Conference on Computer Vision and
    Pattern Recognition, pp. 7993--8002.'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等 [2022d] Xie, M., Li, Y., Wang, Y., Luo, Z., Gan, Z., Sun, Z., Chi, M.,
    Wang, C., Wang, P., 2022d. 学习独特的边际以实现主动领域适应，发表于：IEEE/CVF 计算机视觉与模式识别会议论文集，第 7993--8002
    页。
- en: 'Xie et al. [2023a] Xie, Y., Ding, M., Tomizuka, M., Zhan, W., 2023a. Towards
    free data selection with general-purpose models, in: Thirty-seventh Conference
    on Neural Information Processing Systems. URL: [https://openreview.net/forum?id=KBXcDAaZE7](https://openreview.net/forum?id=KBXcDAaZE7).'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等 [2023a] Xie, Y., Ding, M., Tomizuka, M., Zhan, W., 2023a. 朝向自由数据选择与通用模型，发表于：第三十七届神经信息处理系统会议。网址：[https://openreview.net/forum?id=KBXcDAaZE7](https://openreview.net/forum?id=KBXcDAaZE7)。
- en: 'Xie et al. [2023b] Xie, Y., Lu, H., Yan, J., Yang, X., Tomizuka, M., Zhan,
    W., 2023b. Active finetuning: Exploiting annotation budget in the pretraining-finetuning
    paradigm, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp. 23715--23724.'
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等 [2023b] Xie, Y., Lu, H., Yan, J., Yang, X., Tomizuka, M., Zhan, W., 2023b.
    主动微调：在预训练-微调范式中利用注释预算，发表于：IEEE/CVF 计算机视觉与模式识别会议论文集，第 23715--23724 页。
- en: 'Xu et al. [2018] Xu, X., Lu, Q., Yang, L., Hu, S., Chen, D., Hu, Y., Shi, Y.,
    2018. Quantization of fully convolutional networks for accurate biomedical image
    segmentation, in: Proceedings of the IEEE conference on computer vision and pattern
    recognition, pp. 8300--8308.'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等 [2018] Xu, X., Lu, Q., Yang, L., Hu, S., Chen, D., Hu, Y., Shi, Y., 2018.
    完全卷积网络的量化用于精确的生物医学图像分割，发表于：IEEE 计算机视觉与模式识别会议论文集，第 8300--8308 页。
- en: 'Xu et al. [2021] Xu, Y., Xu, X., Jin, L., Gao, S., Goh, R.S.M., Ting, D.S.W.,
    Liu, Y., 2021. Partially-supervised learning for vessel segmentation in ocular
    images, in: de Bruijne, M., Cattin, P.C., Cotin, S., Padoy, N., Speidel, S., Zheng,
    Y., Essert, C. (Eds.), Medical Image Computing and Computer Assisted Intervention
    – MICCAI 2021, Springer International Publishing, Cham. pp. 271--281. doi:[10.1007/978-3-030-87193-2_26](http://dx.doi.org/10.1007/978-3-030-87193-2_26).'
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人 [2021] Xu, Y., Xu, X., Jin, L., Gao, S., Goh, R.S.M., Ting, D.S.W., Liu,
    Y., 2021. 用于眼部图像血管分割的部分监督学习，见：de Bruijne, M., Cattin, P.C., Cotin, S., Padoy,
    N., Speidel, S., Zheng, Y., Essert, C. (编辑)，《医学图像计算与计算机辅助干预 - MICCAI 2021》，Springer
    国际出版社，Cham。第271--281页。doi：[10.1007/978-3-030-87193-2_26](http://dx.doi.org/10.1007/978-3-030-87193-2_26)。
- en: 'Yang et al. [2017] Yang, L., Zhang, Y., Chen, J., Zhang, S., Chen, D.Z., 2017.
    Suggestive annotation: A deep active learning framework for biomedical image segmentation,
    in: Descoteaux, M., Maier-Hein, L., Franz, A., Jannin, P., Collins, D.L., Duchesne,
    S. (Eds.), Medical Image Computing and Computer Assisted Intervention - MICCAI
    2017, Springer International Publishing, Cham. pp. 399--407. doi:[10.1007/978-3-319-66179-7_46](http://dx.doi.org/10.1007/978-3-319-66179-7_46).'
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang 等人 [2017] Yang, L., Zhang, Y., Chen, J., Zhang, S., Chen, D.Z., 2017.
    Suggestive annotation: 一种用于生物医学图像分割的深度主动学习框架，见：Descoteaux, M., Maier-Hein, L.,
    Franz, A., Jannin, P., Collins, D.L., Duchesne, S. (编辑)，《医学图像计算与计算机辅助干预 - MICCAI
    2017》，Springer 国际出版社，Cham。第399--407页。doi：[10.1007/978-3-319-66179-7_46](http://dx.doi.org/10.1007/978-3-319-66179-7_46)。'
- en: 'Yehuda et al. [2022] Yehuda, O., Dekel, A., Hacohen, G., Weinshall, D., 2022.
    Active learning through a covering lens, in: Advances in Neural Information Processing
    Systems.'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yehuda 等人 [2022] Yehuda, O., Dekel, A., Hacohen, G., Weinshall, D., 2022. 通过覆盖视角进行主动学习，见：神经信息处理系统进展。
- en: 'Yi et al. [2022] Yi, J.S.K., Seo, M., Park, J., Choi, D.G., 2022. Pt4al: Using
    self-supervised pretext tasks for active learning, in: Avidan, S., Brostow, G.,
    Cissé, M., Farinella, G.M., Hassner, T. (Eds.), Computer Vision – ECCV 2022, Springer
    Nature Switzerland, Cham. pp. 596--612. doi:[10.1007/978-3-031-19809-0_34](http://dx.doi.org/10.1007/978-3-031-19809-0_34).'
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yi 等人 [2022] Yi, J.S.K., Seo, M., Park, J., Choi, D.G., 2022. Pt4al: 使用自监督预文本任务进行主动学习，见：Avidan,
    S., Brostow, G., Cissé, M., Farinella, G.M., Hassner, T. (编辑)，《计算机视觉 - ECCV 2022》，Springer
    Nature Switzerland，Cham。第596--612页。doi：[10.1007/978-3-031-19809-0_34](http://dx.doi.org/10.1007/978-3-031-19809-0_34)。'
- en: 'Yoo and Kweon [2019] Yoo, D., Kweon, I.S., 2019. Learning loss for active learning,
    in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    pp. 93--102.'
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yoo 和 Kweon [2019] Yoo, D., Kweon, I.S., 2019. 主动学习中的学习损失，见：IEEE/CVF 计算机视觉与模式识别会议论文集，第93--102页。
- en: 'Yuan et al. [2023] Yuan, J., Zhang, B., Yan, X., Chen, T., Shi, B., Li, Y.,
    Qiao, Y., 2023. Bi3d: Bi-domain active learning for cross-domain 3d object detection,
    in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    pp. 15599--15608.'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yuan 等人 [2023] Yuan, J., Zhang, B., Yan, X., Chen, T., Shi, B., Li, Y., Qiao,
    Y., 2023. Bi3d: 用于跨域 3D 对象检测的双域主动学习，见：IEEE/CVF 计算机视觉与模式识别会议论文集，第15599--15608页。'
- en: 'Yuan et al. [2020] Yuan, M., Lin, H.T., Boyd-Graber, J., 2020. Cold-start active
    learning through self-supervised language modeling, in: Proceedings of the 2020
    Conference on Empirical Methods in Natural Language Processing (EMNLP), Association
    for Computational Linguistics, Online. pp. 7935--7948. doi:[10.18653/v1/2020.emnlp-main.637](http://dx.doi.org/10.18653/v1/2020.emnlp-main.637).'
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan 等人 [2020] Yuan, M., Lin, H.T., Boyd-Graber, J., 2020. 通过自监督语言建模进行冷启动主动学习，见：2020年自然语言处理经验方法会议（EMNLP）论文集，计算语言学协会，在线。第7935--7948页。doi：[10.18653/v1/2020.emnlp-main.637](http://dx.doi.org/10.18653/v1/2020.emnlp-main.637)。
- en: 'Yuan et al. [2021] Yuan, T., Wan, F., Fu, M., Liu, J., Xu, S., Ji, X., Ye,
    Q., 2021. Multiple instance active learning for object detection, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 5330--5339.'
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan 等人 [2021] Yuan, T., Wan, F., Fu, M., Liu, J., Xu, S., Ji, X., Ye, Q., 2021.
    用于对象检测的多实例主动学习，见：IEEE/CVF 计算机视觉与模式识别会议论文集，第5330--5339页。
- en: Zhan et al. [2022] Zhan, X., Wang, Q., Huang, K.h., Xiong, H., Dou, D., Chan,
    A.B., 2022. A comparative survey of deep active learning. arXiv preprint arXiv:2203.13450
    .
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhan 等人 [2022] Zhan, X., Wang, Q., Huang, K.h., Xiong, H., Dou, D., Chan, A.B.,
    2022. 深度主动学习的比较调查。arXiv 预印本 arXiv:2203.13450。
- en: 'Zhang et al. [2020] Zhang, B., Li, L., Yang, S., Wang, S., Zha, Z.J., Huang,
    Q., 2020. State-relabeling adversarial active learning, in: Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8756--8765.'
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 [2020] Zhang, B., Li, L., Yang, S., Wang, S., Zha, Z.J., Huang, Q.,
    2020. 状态重新标记对抗主动学习，见：IEEE/CVF 计算机视觉与模式识别会议论文集，第8756--8765页。
- en: 'Zhang et al. [2021] Zhang, B., Wang, Y., Hou, W., Wu, H., Wang, J., Okumura,
    M., Shinozaki, T., 2021. Flexmatch: Boosting semi-supervised learning with curriculum
    pseudo labeling. Advances in Neural Information Processing Systems 34, 18408--18419.'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. [2021] Zhang, B., Wang, Y., Hou, W., Wu, H., Wang, J., Okumura,
    M., Shinozaki, T., 2021. Flexmatch: 通过课程伪标签提升半监督学习. 神经信息处理系统进展 34, 18408--18419.'
- en: 'Zhang et al. [2016] Zhang, R., Isola, P., Efros, A.A., 2016. Colorful image
    colorization, in: Computer Vision--ECCV 2016: 14th European Conference, Amsterdam,
    The Netherlands, October 11-14, 2016, Proceedings, Part III 14, Springer. pp.
    649--666.'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. [2016] Zhang, R., Isola, P., Efros, A.A., 2016. 色彩丰富的图像着色, 见:
    计算机视觉--ECCV 2016: 第14届欧洲会议, 阿姆斯特丹, 荷兰, 2016年10月11-14日, 会议录, 第三部分 14, Springer.
    第649--666页。'
- en: 'Zhang et al. [2022a] Zhang, W., Zhu, L., Hallinan, J., Zhang, S., Makmur, A.,
    Cai, Q., Ooi, B.C., 2022a. Boostmis: Boosting medical image semi-supervised learning
    with adaptive pseudo labeling and informative active annotation, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 20666--20676.'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. [2022a] Zhang, W., Zhu, L., Hallinan, J., Zhang, S., Makmur, A.,
    Cai, Q., Ooi, B.C., 2022a. Boostmis: 通过自适应伪标签和信息性主动标注提升医学图像半监督学习, 见: IEEE/CVF计算机视觉与模式识别会议录,
    第20666--20676页。'
- en: 'Zhang et al. [2023] Zhang, Y., Kang, B., Hooi, B., Yan, S., Feng, J., 2023.
    Deep long-tailed learning: A survey. IEEE Transactions on Pattern Analysis and
    Machine Intelligence .'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. [2023] Zhang, Y., Kang, B., Hooi, B., Yan, S., Feng, J., 2023.
    深度长尾学习: 综述. IEEE模式分析与机器智能学报.'
- en: 'Zhang et al. [2022b] Zhang, Y., Zhang, X., Xie, L., Li, J., Qiu, R.C., Hu,
    H., Tian, Q., 2022b. One-bit active query with contrastive pairs, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9697--9705.'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. [2022b] Zhang, Y., Zhang, X., Xie, L., Li, J., Qiu, R.C., Hu,
    H., Tian, Q., 2022b. 使用对比对的一比特主动查询, 见: IEEE/CVF计算机视觉与模式识别会议录, 第9697--9705页。'
- en: 'Zhang et al. [2019] Zhang, Z., Romero, A., Muckley, M.J., Vincent, P., Yang,
    L., Drozdzal, M., 2019. Reducing uncertainty in undersampled mri reconstruction
    with active acquisition, in: 2019 IEEE/CVF Conference on Computer Vision and Pattern
    Recognition (CVPR), IEEE, Long Beach, CA, USA. pp. 2049--2053. doi:[10.1109/CVPR.2019.00215](http://dx.doi.org/10.1109/CVPR.2019.00215).'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. [2019] Zhang, Z., Romero, A., Muckley, M.J., Vincent, P., Yang,
    L., Drozdzal, M., 2019. 通过主动获取减少欠采样MRI重建中的不确定性, 见: 2019 IEEE/CVF计算机视觉与模式识别会议 (CVPR),
    IEEE, 洛杉矶, CA, 美国. 第2049--2053页. doi:[10.1109/CVPR.2019.00215](http://dx.doi.org/10.1109/CVPR.2019.00215).'
- en: 'Zhao et al. [2021] Zhao, Z., Zeng, Z., Xu, K., Chen, C., Guan, C., 2021. Dsal:
    Deeply supervised active learning from strong and weak labelers for biomedical
    image segmentation. IEEE Journal of Biomedical and Health Informatics 25, 3744--3751.
    doi:[10.1109/JBHI.2021.3052320](http://dx.doi.org/10.1109/JBHI.2021.3052320).'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao et al. [2021] Zhao, Z., Zeng, Z., Xu, K., Chen, C., Guan, C., 2021. Dsal:
    从强标注者和弱标注者进行深度监督主动学习以用于生物医学图像分割. IEEE生物医学与健康信息学杂志 25, 3744--3751. doi:[10.1109/JBHI.2021.3052320](http://dx.doi.org/10.1109/JBHI.2021.3052320).'
- en: Zheng et al. [2019] Zheng, H., Yang, L., Chen, J., Han, J., Zhang, Y., Liang,
    P., Zhao, Z., Wang, C., Chen, D.Z., 2019. Biomedical image segmentation via representative
    annotation. Proceedings of the AAAI Conference on Artificial Intelligence 33,
    5901--5908. doi:[10.1609/aaai.v33i01.33015901](http://dx.doi.org/10.1609/aaai.v33i01.33015901).
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. [2019] Zheng, H., Yang, L., Chen, J., Han, J., Zhang, Y., Liang,
    P., Zhao, Z., Wang, C., Chen, D.Z., 2019. 通过代表性标注进行生物医学图像分割. AAAI人工智能会议录 33, 5901--5908.
    doi:[10.1609/aaai.v33i01.33015901](http://dx.doi.org/10.1609/aaai.v33i01.33015901).
- en: Zheng et al. [2020] Zheng, H., Zhang, Y., Yang, L., Wang, C., Chen, D.Z., 2020.
    An annotation sparsification strategy for 3d medical image segmentation via representative
    selection and self-training. Proceedings of the AAAI Conference on Artificial
    Intelligence 34, 6925--6932. doi:[10.1609/aaai.v34i04.6175](http://dx.doi.org/10.1609/aaai.v34i04.6175).
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. [2020] Zheng, H., Zhang, Y., Yang, L., Wang, C., Chen, D.Z., 2020.
    一种用于三维医学图像分割的标注稀疏化策略，通过代表性选择和自我训练. AAAI人工智能会议录 34, 6925--6932. doi:[10.1609/aaai.v34i04.6175](http://dx.doi.org/10.1609/aaai.v34i04.6175).
- en: 'Zhou et al. [2016] Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba,
    A., 2016. Learning deep features for discriminative localization, in: Proceedings
    of the IEEE conference on computer vision and pattern recognition, pp. 2921--2929.'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou et al. [2016] Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba,
    A., 2016. 学习用于判别定位的深度特征, 见: IEEE计算机视觉与模式识别会议录, 第2921--2929页。'
- en: 'Zhou et al. [2021a] Zhou, T., Li, L., Bredell, G., Li, J., Konukoglu, E., 2021a.
    Quality-aware memory network for interactive volumetric image segmentation, in:
    de Bruijne, M., Cattin, P.C., Cotin, S., Padoy, N., Speidel, S., Zheng, Y., Essert,
    C. (Eds.), Medical Image Computing and Computer Assisted Intervention – MICCAI
    2021, Springer International Publishing, Cham. pp. 560--570. doi:[10.1007/978-3-030-87196-3_52](http://dx.doi.org/10.1007/978-3-030-87196-3_52).'
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人 [2021a] Zhou, T., Li, L., Bredell, G., Li, J., Konukoglu, E., 2021a.
    质量感知记忆网络用于交互式体积图像分割，在：de Bruijne, M., Cattin, P.C., Cotin, S., Padoy, N., Speidel,
    S., Zheng, Y., Essert, C. (编辑), 医学图像计算与计算机辅助干预 – MICCAI 2021, Springer International
    Publishing, Cham. pp. 560--570. doi:[10.1007/978-3-030-87196-3_52](http://dx.doi.org/10.1007/978-3-030-87196-3_52)。
- en: Zhou et al. [2022] Zhou, T., Li, L., Bredell, G., Li, J., Konukoglu, E., 2022.
    Volumetric memory network for interactive medical image segmentation. Medical
    Image Analysis , 102599doi:[10.1016/j.media.2022.102599](http://dx.doi.org/10.1016/j.media.2022.102599).
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人 [2022] Zhou, T., Li, L., Bredell, G., Li, J., Konukoglu, E., 2022. 用于交互式医学图像分割的体积记忆网络。医学图像分析,
    102599doi:[10.1016/j.media.2022.102599](http://dx.doi.org/10.1016/j.media.2022.102599)。
- en: 'Zhou et al. [2017] Zhou, Z., Shin, J., Zhang, L., Gurudu, S., Gotway, M., Liang,
    J., 2017. Fine-tuning convolutional neural networks for biomedical image analysis:
    Actively and incrementally, in: Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition, pp. 7340--7351.'
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人 [2017] Zhou, Z., Shin, J., Zhang, L., Gurudu, S., Gotway, M., Liang,
    J., 2017. 用于生物医学图像分析的卷积神经网络的微调：主动和增量的，在：IEEE计算机视觉与模式识别会议论文集, pp. 7340--7351。
- en: Zhou et al. [2021b] Zhou, Z., Shin, J.Y., Gurudu, S.R., Gotway, M.B., Liang,
    J., 2021b. Active, continual fine tuning of convolutional neural networks for
    reducing annotation efforts. Medical Image Analysis 71, 101997. doi:[10.1016/j.media.2021.101997](http://dx.doi.org/10.1016/j.media.2021.101997).
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人 [2021b] Zhou, Z., Shin, J.Y., Gurudu, S.R., Gotway, M.B., Liang, J.,
    2021b. 主动、持续地微调卷积神经网络以减少标注工作量。医学图像分析 71, 101997. doi:[10.1016/j.media.2021.101997](http://dx.doi.org/10.1016/j.media.2021.101997)。
- en: Zhu and Bento [2017] Zhu, J.J., Bento, J., 2017. Generative adversarial active
    learning. arXiv preprint arXiv:1702.07956 .
  id: totrans-686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 和 Bento [2017] Zhu, J.J., Bento, J., 2017. 生成对抗主动学习。arXiv 预印本 arXiv:1702.07956。
