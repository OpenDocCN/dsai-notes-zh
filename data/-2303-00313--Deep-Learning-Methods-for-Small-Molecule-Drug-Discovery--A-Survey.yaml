- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:41:09'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:41:09
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2303.00313] Deep Learning Methods for Small Molecule Drug Discovery: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2303.00313] 小分子药物发现的深度学习方法：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2303.00313](https://ar5iv.labs.arxiv.org/html/2303.00313)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2303.00313](https://ar5iv.labs.arxiv.org/html/2303.00313)
- en: 'Deep Learning Methods for Small Molecule Drug Discovery: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小分子药物发现的深度学习方法：综述
- en: 'Wenhao Hu^∗    Yingying Liu^∗    Xuanyu Chen    Wenhao Chai    Hangyue Chen
       Hongwei Wang^†    \IEEEmembershipMember, IEEE and Gaoang Wang^†    \IEEEmembershipMember, IEEE
    ^∗ Equal contribution.^† Corresponding author: Hongwei Wang, and Gaoang Wang.Wenhao
    Hu, Yingying Liu, Xuanyu Chen, and Wenhao Chai are with the Zhejiang University-University
    of Illinois at Urbana-Champaign Institute, Zhejiang University, China (e-mail:
    wenhao.21@intl.zju.edu.cn, yingying.19@intl.zju.edu.cn, xuanyu.19@intl.zju.edu.cn,
    wenhaochai.19@intl.zju.edu.cn).Hongwei Wang, and Gaoang Wang are with the Zhejiang
    University-University of Illinois at Urbana-Champaign Institute, and College of
    Computer Science and Technology, Zhejiang University, China (e-mail: hongweiwang@intl.zju.edu.cn,
    gaoangwang@intl.zju.edu.cn).Hangyue Chen is with the Hangzhou Dianzi University,
    China (e-mail: chy@hdu.edu.cn).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 伍文浩^∗    刘颖颖^∗    陈轩宇    柴文浩    陈航跃    王宏伟^†    \IEEEmembershipMember, IEEE
    和 王高昂^†    \IEEEmembershipMember, IEEE ^∗ 等贡献.^† 通讯作者：王宏伟和王高昂。伍文浩、刘颖颖、陈轩宇和柴文浩均为浙江大学-伊利诺伊大学厄本那-香槟分校研究所成员，浙江大学，中国（电子邮件：wenhao.21@intl.zju.edu.cn,
    yingying.19@intl.zju.edu.cn, xuanyu.19@intl.zju.edu.cn, wenhaochai.19@intl.zju.edu.cn）。王宏伟和王高昂为浙江大学-伊利诺伊大学厄本那-香槟分校研究所及计算机科学与技术学院成员，浙江大学，中国（电子邮件：hongweiwang@intl.zju.edu.cn,
    gaoangwang@intl.zju.edu.cn）。陈航跃为杭州电子科技大学成员，中国（电子邮件：chy@hdu.edu.cn）。
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: With the development of computer-assisted techniques, research communities including
    biochemistry and deep learning have been devoted into the drug discovery field
    for over a decade. Various applications of deep learning have drawn great attention
    in drug discovery, such as molecule generation, molecular property prediction,
    retrosynthesis prediction, and reaction prediction. While most existing surveys
    only focus on one of the applications, limiting the view of researchers in the
    community. In this paper, we present a comprehensive review on the aforementioned
    four aspects, and discuss the relationships among different applications. The
    latest literature and classical benchmarks are presented for better understanding
    the development of variety of approaches.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着计算机辅助技术的发展，包括生物化学和深度学习在内的研究社区已经投入了超过十年的药物发现领域。深度学习的各种应用在药物发现中引起了广泛关注，如分子生成、分子属性预测、逆合成预测和反应预测。尽管大多数现有综述仅关注其中一个应用，这限制了研究人员的视野。在本文中，我们全面回顾了上述四个方面，并讨论了不同应用之间的关系。最新文献和经典基准被呈现，以便更好地理解各种方法的发展。
- en: We commence by summarizing the molecule representation format in these works,
    followed by an introduction of recent proposed approaches for each of the four
    tasks. Furthermore, we review a variety of commonly used datasets and evaluation
    metrics and compare the performance of deep learning-based models. Finally, we
    conclude by identifying remaining challenges and discussing the future trend for
    deep learning methods in drug discovery.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先总结了这些研究中的分子表示格式，然后介绍了每个任务的近期提出的方法。此外，我们回顾了各种常用的数据集和评估指标，并比较了基于深度学习的模型的性能。最后，我们通过识别剩余的挑战并讨论药物发现中深度学习方法的未来趋势来做出总结。
- en: '{IEEEImpStatement}'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '{IEEEImpStatement}'
- en: As artificial intelligence continues to evolve, an increasing number of deep
    learning algorithms are proposed to utilize extensive experimental data to accelerate
    the time-consuming and costly procedure for drug discovery. Unlike previous surveys
    that tend to focus on a single aspect of drug discovery, we offer a more comprehensive
    survey that encompasses four areas of drug discovery utilizing deep learning techniques,
    including molecule generation, molecular property prediction, retrosynthesis,
    and reaction prediction. Before introducing the main methods, we start with molecular
    data representation, which is also crucial for deep learning algorithms. Moreover,
    we present the recent benchmarks for deep learning-based drug discovery, which
    cover 9 widely used databases.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人工智能的不断进步，越来越多的深度学习算法被提出，以利用大量实验数据来加快耗时且昂贵的药物发现过程。与以往那些专注于药物发现单一方面的调查不同，我们提供了一个更全面的调查，涵盖了利用深度学习技术的药物发现四个领域，包括分子生成、分子性质预测、逆合成以及反应预测。在介绍主要方法之前，我们从分子数据表示开始，这对深度学习算法也至关重要。此外，我们展示了针对深度学习基础的药物发现的最新基准测试，涵盖了9个广泛使用的数据库。
- en: '{IEEEkeywords}'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '{IEEEkeywords}'
- en: deep learning, drug discovery.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习，药物发现。
- en: '![Refer to caption](img/178371c3a75109202d1712882bce7b2d.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/178371c3a75109202d1712882bce7b2d.png)'
- en: 'Figure 1: Framework of deep learning methods for drug discovery.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：药物发现的深度学习方法框架。
- en: 1 Introduction
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: \IEEEPARstart
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: \IEEEPARstart
- en: 'Drug discovery is a very long process that involves extensive experiments and
    different stages. It may take more than ten years and cost around 2.6 billion
    dollars to discover a new drug [[1](#bib.bib1)]. The number of the existing molecules
    has reached more than 130 million, which leads to the fact that the searching
    space for effective drug molecules is pretty significant [[2](#bib.bib2)]. With
    the advent of artificial intelligence, more and more algorithms and methods are
    proposed to utilize the extensive experimental data from chemical labs to accelerate
    the time-consuming and costly procedure for drug discovery. Deep Learning can
    be applied to drug discovery in different stages. Among them, there are several
    vital aspects where the applications hugely help improve performance. In this
    survey, we focus on the following applications: 1) molecule generation, 2) molecular
    property prediction, 3) retrosynthesis, and 4) reaction prediction, as shown in
    Fig. [1](#S0.F1 "Figure 1 ‣ Deep Learning Methods for Small Molecule Drug Discovery:
    A Survey").'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 药物发现是一个非常漫长的过程，涉及广泛的实验和不同的阶段。发现一种新药可能需要十年以上的时间，并花费约26亿美元[[1](#bib.bib1)]。现有的分子数量已超过1.3亿，这导致有效药物分子的搜索空间相当巨大[[2](#bib.bib2)]。随着人工智能的出现，越来越多的算法和方法被提出，以利用化学实验室的广泛实验数据来加速耗时且昂贵的药物发现过程。深度学习可以应用于药物发现的不同阶段。其中，有几个关键方面的应用在提高性能方面非常有帮助。在本调查中，我们重点关注以下应用：1）分子生成，2）分子性质预测，3）逆合成，以及4）反应预测，如图[1](#S0.F1
    "图 1 ‣ 小分子药物发现的深度学习方法：综述")所示。
- en: Molecule generation is the basis of rational drug design and the starting point
    for obtaining new drug molecules. The core problem is to obtain candidate molecules
    that satisfy specific properties and druggability from the huge chemical space.
    Mathematically, molecule generation is usually defined as an optimization problem
    in which the desired molecular properties are predicted by oracle functions. First,
    molecular characteristics are learned from a large set of molecules. Then, novel
    candidates are obtained from the learned distribution with the restriction of
    predefined oracle functions. In the early stage of molecule generation, molecules
    with novel structures can be constructed by combining fragments of existing compounds
    [[3](#bib.bib3), [4](#bib.bib4)]. This requires assistance of chemical experiment
    which is relatively inefficient. Optimization algorithms such as genetic algorithms
    [[5](#bib.bib5)] are also considered for solving the molecule generation problem.
    Based on evolution principles, genetic algorithms obtain molecules with specific
    properties by changing parameters of a population. While the early approaches
    rely on stochastic steps that struggle to capture the constraints of chemical
    design [[6](#bib.bib6)]. Deep learning brings the ability to learn from vast amounts
    of data and the potential for drug design beyond chemical intuition, narrowing
    the $10^{60}$ size chemical space to dozens of valid candidate compounds.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 分子生成是理性药物设计的基础，是获取新药物分子的起点。核心问题是从庞大的化学空间中获得满足特定属性和药物可用性的候选分子。在数学上，分子生成通常被定义为优化问题，其中通过神谕函数预测所需的分子属性。首先，从大量的分子中学习分子特性。然后，从学习到的分布中获得新的候选分子，并以预定义的神谕函数作为限制。在分子生成的早期阶段，可以通过结合现有化合物的片段来构建具有新结构的分子[[3](#bib.bib3)、[4](#bib.bib4)]。这需要化学实验的辅助，效率相对较低。遗传算法[[5](#bib.bib5)]等优化算法也被考虑用于解决分子生成问题。基于进化原则，遗传算法通过改变种群的参数获得具有特定属性的分子。然而，早期的方法依赖于随机步骤，难以捕捉化学设计的约束[[6](#bib.bib6)]。深度学习带来了从大量数据中学习的能力，并为药物设计带来了超越化学直觉的潜力，将$10^{60}$大小的化学空间缩小到数十个有效的候选化合物。
- en: 'Molecular property prediction is a crucial part of drug development, and its
    primary purpose is to predict the drug activity, absorption, toxicity, and other
    properties of candidate compounds. Molecular property prediction has two main
    applications: quantitative structure-property relationship (QSPR) and virtual
    screening. QSPR models are usually defined as regression or classification models
    which predict property by establishing relationships between molecule structure
    and property. Early machine learning methods such as random forest [[7](#bib.bib7)],
    k nearest-neighbor [[8](#bib.bib8)], support vector machine [[9](#bib.bib9)] have
    been used for QSPR problems. These methods still perform better than modern deep
    learning methods for some specific problem instances [[10](#bib.bib10), [11](#bib.bib11),
    [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14)]. For example, algorithms
    using extremely randomized trees achieve better performance than deep learning
    methods on small datasets for organic molecular energy prediction problems [[15](#bib.bib15)].'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 分子属性预测是药物开发中的关键部分，其主要目的是预测候选化合物的药物活性、吸收、毒性和其他属性。分子属性预测有两个主要应用：定量构效关系（QSPR）和虚拟筛选。QSPR
    模型通常定义为回归或分类模型，通过建立分子结构与属性之间的关系来预测属性。早期的机器学习方法，如随机森林[[7](#bib.bib7)]、k 近邻[[8](#bib.bib8)]、支持向量机[[9](#bib.bib9)]，已被用于
    QSPR 问题。这些方法在一些特定问题实例中仍优于现代深度学习方法[[10](#bib.bib10)、[11](#bib.bib11)、[12](#bib.bib12)、[13](#bib.bib13)、[14](#bib.bib14)]。例如，使用极端随机树的算法在小数据集上进行有机分子能量预测时，比深度学习方法表现更好[[15](#bib.bib15)]。
- en: The purpose of virtual screening is to search the molecule library in order
    to identify those drug ligand structures which are most likely to bind to a target
    protein [[16](#bib.bib16), [17](#bib.bib17)]. Traditional virtual screening methods
    need to synthesize many compounds for biological experiments, and the whole process
    has a high cost, long cycle, and low success rate. The virtual screening of drugs
    through deep learning is expected to replace traditional activity screening methods,
    speed up intermediate steps, and significantly reduce costs. For instance, a particularly
    successful application is deep learning-based score function that can predict
    the affinities of protein-bound ligands with high accuracy [[18](#bib.bib18)].
    More specifically, AtomNet incorporates the 3D structural features of the protein–ligand
    complexes to the CNNs [[19](#bib.bib19)]. Feng et al. [[20](#bib.bib20)] combine
    the fringerprint and graph representations as ligand features. This model showes
    better performance on the Davis [[21](#bib.bib21)], Metz [[22](#bib.bib22)], and
    KIBA [[23](#bib.bib23)] benchmark datasets. Gao et al. [[24](#bib.bib24)] use
    the LSTM recurrent neural networks for the protein sequences and the GCN for ligand
    structures.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟筛选的目的是搜索分子库，以识别那些最有可能与靶蛋白结合的药物配体结构[[16](#bib.bib16), [17](#bib.bib17)]。传统的虚拟筛选方法需要合成大量化合物进行生物实验，整个过程成本高、周期长、成功率低。通过深度学习进行药物虚拟筛选有望取代传统的活性筛选方法，加快中间步骤并显著降低成本。例如，一个特别成功的应用是基于深度学习的评分函数，它可以高精度地预测蛋白结合配体的亲和力[[18](#bib.bib18)]。更具体地说，AtomNet
    将蛋白-配体复合物的 3D 结构特征纳入 CNNs [[19](#bib.bib19)]。Feng 等人[[20](#bib.bib20)] 将指纹图谱和图表示作为配体特征。这一模型在
    Davis [[21](#bib.bib21)]、Metz [[22](#bib.bib22)] 和 KIBA [[23](#bib.bib23)] 基准数据集上表现出更好的性能。Gao
    等人[[24](#bib.bib24)] 使用 LSTM 循环神经网络处理蛋白质序列，使用 GCN 处理配体结构。
- en: Retrosynthesis analysis and reaction prediction are the critical links in drug
    synthesis. Reaction prediction explores possible product molecules synthesized
    by given reactants [[25](#bib.bib25)]. Contrary to reaction prediction, retrosynthesis
    is a reverse extrapolation from the product molecule to accessible starting materials
    [[26](#bib.bib26)]. Early computer-aided synthesis planning primarily relied on
    human-encoded reaction rules, which can be only applied to specific reactions
    [[27](#bib.bib27)]. With neural networks, the reaction patterns of molecules and
    the breaking rules of chemical bonds are learned from the existing massive chemical
    reaction data. These rules are applied to the retrosynthesis analysis and reaction
    prediction of drug molecules, which can significantly speed up the synthesis of
    new drugs.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 逆合成分析和反应预测是药物合成中的关键环节。反应预测探索由给定反应物合成的可能产物分子[[25](#bib.bib25)]。与反应预测相对，逆合成是从产物分子反向推断出可获得的起始材料[[26](#bib.bib26)]。早期的计算机辅助合成规划主要依赖于人工编码的反应规则，这些规则只能应用于特定反应[[27](#bib.bib27)]。通过神经网络，可以从现有的大量化学反应数据中学习分子的反应模式和化学键的断裂规则。这些规则被应用于药物分子的逆合成分析和反应预测中，可以显著加快新药的合成速度。
- en: Many existing surveys focus on drug discovery in the AI era. Lavecchia [[28](#bib.bib28)]
    analyzes the application of machine learning techniques in ligand-based virtual
    screening. Gawehn et al. [[29](#bib.bib29)] use several classic deep neural networks
    as examples to introduce the potential application fields. Some present how machine
    learning takes advantage of big data to improve the traditional method and the
    applications in various stages of drug discovery [[30](#bib.bib30)]. While those
    works focus on general aspects of drug discovery, other surveys emphasize one
    specific task and analyze state-of-the-art (SOTA) models for the particular application.
    For property prediction, some papers review the main methods, introduce several
    fundamental machine learning techniques, and analyze the performance from the
    data side [[31](#bib.bib31), [32](#bib.bib32)]. For molecular design, Tong et
    al. [[33](#bib.bib33)] summarize generative models and list several tools which
    use those models, while Elton et al. [[34](#bib.bib34)] focus on the generation
    of lead molecules, classifying the models and comparing their performances. For
    the synthesis procedure, some surveys discuss the dataset, models, and tools for
    retrosynthesis and reaction prediction and point out the potential development
    directions [[26](#bib.bib26), [35](#bib.bib35)].
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 许多现有的调查研究集中于 AI 时代的药物发现。Lavecchia [[28](#bib.bib28)] 分析了机器学习技术在配体基础虚拟筛选中的应用。Gawehn
    等人 [[29](#bib.bib29)] 以几个经典深度神经网络为例，介绍了潜在的应用领域。一些研究展示了机器学习如何利用大数据来改进传统方法以及在药物发现各个阶段的应用
    [[30](#bib.bib30)]。虽然这些研究集中于药物发现的通用方面，但其他调查则强调特定任务，并分析了针对特定应用的最先进（SOTA）模型。对于属性预测，一些论文回顾了主要方法，介绍了几种基本的机器学习技术，并从数据角度分析了性能
    [[31](#bib.bib31), [32](#bib.bib32)]。对于分子设计，Tong 等人 [[33](#bib.bib33)] 总结了生成模型并列出了几种使用这些模型的工具，而
    Elton 等人 [[34](#bib.bib34)] 关注于先导分子的生成，对模型进行分类并比较其性能。对于合成过程，一些调查讨论了回溯合成和反应预测的数据集、模型和工具，并指出了潜在的发展方向
    [[26](#bib.bib26), [35](#bib.bib35)]。
- en: 'To the best of our knowledge, our survey first integrates the four applications
    mentioned above. The main contributions are summarized as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，我们的调查首次整合了上述四个应用。主要贡献总结如下：
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We summarize the latest literature and classical benchmarks in four applications
    and categorize them according to molecule representations.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们总结了四个应用领域的最新文献和经典基准，并根据分子表示对其进行分类。
- en: •
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We enumerate commonly used datasets and evaluation metrics and compare the results
    of existing models.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们列举了常用的数据集和评估指标，并比较了现有模型的结果。
- en: •
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose the problems of existing methods and analyze the future development
    direction.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了现有方法的问题，并分析了未来的发展方向。
- en: 'Following the three main components of deep learning: representation, model,
    and data [[36](#bib.bib36)], our organization for the paper will be as follows:
    we first briefly introduce the formats used in deep learning to represent the
    molecular structure in Section [2](#S2 "2 Molecule Representations ‣ Deep Learning
    Methods for Small Molecule Drug Discovery: A Survey"), including fingerprints,
    simplified molecular input line entry system (SMILES) and molecular graphs.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '根据深度学习的三个主要组成部分：表示、模型和数据 [[36](#bib.bib36)]，我们对论文的组织结构如下：我们首先简要介绍深度学习中用于表示分子结构的格式，在第
    [2](#S2 "2 Molecule Representations ‣ Deep Learning Methods for Small Molecule
    Drug Discovery: A Survey) 节中，包括指纹、简化分子输入线条系统（SMILES）和分子图。'
- en: 'After that, molecule generation, molecular property prediction, retrosynthesis
    and reaction prediction are introduced in Section [3](#S3 "3 Molecule Generation
    ‣ Deep Learning Methods for Small Molecule Drug Discovery: A Survey"), Section [4](#S4
    "4 Molecular Property Prediction ‣ Deep Learning Methods for Small Molecule Drug
    Discovery: A Survey"), Section [5](#S5 "5 Retrosynthesis ‣ Deep Learning Methods
    for Small Molecule Drug Discovery: A Survey"), and Section [6](#S6 "6 Reaction
    Prediction ‣ Deep Learning Methods for Small Molecule Drug Discovery: A Survey"),
    respectively. We also provide standard datasets, existing benchmark platforms,
    and usual evaluation metrics for all four tasks in Section [7](#S7 "7 Datasets
    and Benchmarks ‣ Deep Learning Methods for Small Molecule Drug Discovery: A Survey").
    Finally, we discuss the challenges and possible development directions in Section [8](#S8
    "8 Challenges and Future trend ‣ Deep Learning Methods for Small Molecule Drug
    Discovery: A Survey").'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '之后，第[3](#S3 "3 Molecule Generation ‣ Deep Learning Methods for Small Molecule
    Drug Discovery: A Survey)节、第[4](#S4 "4 Molecular Property Prediction ‣ Deep Learning
    Methods for Small Molecule Drug Discovery: A Survey)节、第[5](#S5 "5 Retrosynthesis
    ‣ Deep Learning Methods for Small Molecule Drug Discovery: A Survey)节和第[6](#S6
    "6 Reaction Prediction ‣ Deep Learning Methods for Small Molecule Drug Discovery:
    A Survey)节分别介绍了分子生成、分子性质预测、逆合成和反应预测。此外，第[7](#S7 "7 Datasets and Benchmarks ‣ Deep
    Learning Methods for Small Molecule Drug Discovery: A Survey)节提供了四项任务的标准数据集、现有基准平台和常用评价指标。最后，第[8](#S8
    "8 Challenges and Future trend ‣ Deep Learning Methods for Small Molecule Drug
    Discovery: A Survey)节讨论了挑战和可能的发展方向。'
- en: 2 Molecule Representations
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 分子表示
- en: '![Refer to caption](img/f3da122ae03f638779493ef2a478ee93.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f3da122ae03f638779493ef2a478ee93.png)'
- en: 'Figure 2: Taxonomy for deep neural network methods for drug discovery.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：用于药物发现的深度神经网络方法的分类。
- en: 'In order to convert the molecular structure to computer-readable information,
    there are several ways to represent the molecules. This section focuses on three
    common representations: fingerprints, SMILES string, and molecular graphs. After
    the introduction of the data representations, we show the taxonomy of the deep
    learning methods for drug discovery according to different representations in
    Fig. [2](#S2.F2 "Figure 2 ‣ 2 Molecule Representations ‣ Deep Learning Methods
    for Small Molecule Drug Discovery: A Survey").'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '为了将分子结构转换为计算机可读的信息，有几种方法可以表示分子。本节重点介绍三种常见的表示方法：指纹、SMILES字符串和分子图。在介绍数据表示后，我们在图[2](#S2.F2
    "Figure 2 ‣ 2 Molecule Representations ‣ Deep Learning Methods for Small Molecule
    Drug Discovery: A Survey)中展示了根据不同表示方法的药物发现深度学习方法的分类。'
- en: 2.1 Fingerprints
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 指纹
- en: Molecular fingerprint is a bit string that encodes the structural information
    of a molecule. Two types of fingerprints are widely used for molecule representation,
    i.e., key-based fingerprints and hash fingerprints.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 分子指纹是一种位字符串，编码了分子的结构信息。两种广泛用于分子表示的指纹类型是基于关键的指纹和哈希指纹。
- en: Key-based fingerprints, including molecular ACCess system (MACCS) [[37](#bib.bib37)],
    and PubChem fingerprint [[38](#bib.bib38)], have a predefined fragment library
    so that each molecule can be encoded into a binary bit stream according to its
    substructure. The MACCS contains 166 predefined fragments and the fragment keys
    are implemented in many cheminformatics software packages, including RDKit [[39](#bib.bib39)],
    OpenBabel [[40](#bib.bib40)], CDK [[41](#bib.bib41)]. The PubChem fingerprint
    has 881 bits representing element count, type of ring system, atom pairing, nearest
    neighbors, etc.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 基于关键的指纹，包括分子ACCess系统（MACCS）[[37](#bib.bib37)]和PubChem指纹[[38](#bib.bib38)]，具有预定义的片段库，使每个分子可以根据其子结构编码成二进制位流。MACCS包含166个预定义片段，这些片段键在许多化学信息学软件包中实现，包括RDKit[[39](#bib.bib39)]、OpenBabel[[40](#bib.bib40)]和CDK[[41](#bib.bib41)]。PubChem指纹具有881位，表示元素计数、环系统类型、原子配对、最近邻等信息。
- en: Hash fingerprints, such as Morgan fingerprints and functional-class fingerprints,
    do not have predefined substructures. Instead, they extract fragments from the
    given dataset and convert them into numeric values.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希指纹，如Morgan指纹和功能类指纹，没有预定义的子结构。相反，它们从给定的数据集中提取片段并将其转换为数值。
- en: Due to extraction of molecular substructures and matching process, obtaining
    molecular fingerprints is quite complicated. Meanwhile, the representation ability
    of binary molecular fingerprints is limited. Though molecular fingerprints are
    still used in SMILES [[42](#bib.bib42)] and molecular graphs [[43](#bib.bib43)],
    there are less works that take molecular fingerprints as the representation approach
    in recent progress.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于分子亚结构的提取和匹配过程，获得分子指纹相当复杂。同时，二进制分子指纹的表示能力有限。尽管分子指纹仍在SMILES[[42](#bib.bib42)]和分子图[[43](#bib.bib43)]中使用，但近年来以分子指纹作为表示方法的工作较少。
- en: 2.2 SMILES
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 SMILES
- en: Simplified molecular input line entry system (SMILES) [[44](#bib.bib44)] is
    the method that uses strings to represent the molecular structure. Complex molecular
    configurations are transformed into sequences in vector form, which is easy to
    obtain. Meanwhile, with the development of natural language processing techniques,
    SMILES string can be regarded as a sentence for molecule representations [[45](#bib.bib45),
    [46](#bib.bib46), [47](#bib.bib47)]. However, the SMILES representation also has
    certain limitations. The SMILES representation length varies with the molecule
    size, which poses significant challenges in devising generic models. Also, the
    property of sentences makes it challenging to represent three-dimensional information
    about molecules.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 简化分子输入行系统（SMILES）[[44](#bib.bib44)]是使用字符串表示分子结构的方法。复杂的分子配置被转换为向量形式的序列，这很容易获得。与此同时，随着自然语言处理技术的发展，SMILES字符串可以被视为分子表示的句子[[45](#bib.bib45),
    [46](#bib.bib46), [47](#bib.bib47)]。然而，SMILES表示也有一定的局限性。SMILES表示的长度随分子大小变化，这对设计通用模型提出了重大挑战。此外，句子的性质使得表示分子的三维信息具有挑战性。
- en: 2.3 Molecular Graph
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 分子图
- en: Graphs are realistic representations of molecules, preserving the rigorous details
    of the topology and geometry structures. The nodes in the graph can represent
    the attribute, and valence state of atoms, while the edges in the graph contain
    information such as the type and length of chemical bonds. Deep learning methods
    for graphs, especially for graph neural networks (GNNs), have promising performance
    in many tasks, such as property prediction and reaction prediction.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图形是分子的现实表示，保留了拓扑和几何结构的严谨细节。图中的节点可以表示原子的属性和价态，而图中的边包含化学键的类型和长度等信息。图的深度学习方法，特别是图神经网络（GNNs），在许多任务中，如属性预测和反应预测，具有良好的前景。
- en: Compared to SMILES and manually designed fingerprints in sequence, the graph-formed
    representation alleviates the order ambiguity represented in sequence form. It
    preserves rich structural information, such as the distances between atoms and
    the angles between bonds. Chen et al. [[48](#bib.bib48)] emphasize the great importance
    of edge features, inspiring more to be explored by preserving atom and bond information
    via the propagation of GNNs.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 与序列中的SMILES和手动设计的指纹相比，图形表示形式减轻了序列形式中存在的顺序模糊性。它保留了丰富的结构信息，如原子之间的距离和键之间的角度。陈等人[[48](#bib.bib48)]强调了边缘特征的重要性，激发了通过GNN的传播来保留原子和键信息的更多探索。
- en: 3 Molecule Generation
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 分子生成
- en: '![Refer to caption](img/254a4d83bebd59c753560b4236954518.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/254a4d83bebd59c753560b4236954518.png)'
- en: 'Figure 3: Illustrations of (A) Recurrent Neural Networks, (B) Variational Autoencoders
    and (C) Graph Neural Networks in molecule generation.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 分子生成中 (A) 递归神经网络、(B) 变分自编码器和 (C) 图神经网络的示意图。'
- en: 3.1 String-based
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 基于字符串
- en: Based on this molecular representation method, some standard deep learning models
    for processing sequence information, such as recurrent neural networks (RNNs),
    variational auto-encoders (VAEs), and genetic algorithm, are applied to the molecular
    generation model. These methods have been shown to perform well for many domains
    in deep learning.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这种分子表示方法，一些处理序列信息的标准深度学习模型，如递归神经网络（RNNs）、变分自编码器（VAEs）和遗传算法，被应用于分子生成模型。这些方法在深度学习的许多领域中表现良好。
- en: 'Recurrent Neural Networks (RNN). RNNs generate output symbols based on input
    from previous steps, then these symbols are gathered to form generated molecule
    (Fig. [3](#S3.F3 "Figure 3 ‣ 3 Molecule Generation ‣ Deep Learning Methods for
    Small Molecule Drug Discovery: A Survey")A). Olivecrona et al. [[49](#bib.bib49)]
    develop a policy based RL approach to fine-tune a pre-trained RNN network. Segler
    et al. [[50](#bib.bib50)] generate large sets of diverse molecules for virtual
    screening campaigns and then generate smaller, focused libraries enriched with
    possibly active molecules for a specific target. Stacked RNN layers are used to
    generate new molecular SMILES representations. This work demonstrates the robustness
    and transferability of RNNs in molecular generative models. Gupta et al. [[51](#bib.bib51)]
    also follow the idea of pre-training on large-scale molecular datasets and fine-tuning
    on small-scale datasets to generate molecules of specific properties. This work
    also highlights the potential of RNN-based generative models to complete molecules
    with particular properties from molecular fragments. Grisoni et al. [[52](#bib.bib52)]
    propose a method for generative and data augmentation from both directions of
    the sequence. Since molecular sequences are not as directional as NLP-like sequences,
    this attempt has been shown to perform better than unidirectional RNNs in experiments.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '循环神经网络（RNN）。RNN根据前一步的输入生成输出符号，然后将这些符号汇总形成生成的分子（图 [3](#S3.F3 "Figure 3 ‣ 3 Molecule
    Generation ‣ Deep Learning Methods for Small Molecule Drug Discovery: A Survey")A）。Olivecrona等人[[49](#bib.bib49)]
    开发了一种基于策略的RL方法，以微调预训练的RNN网络。Segler等人[[50](#bib.bib50)] 为虚拟筛选活动生成大规模的多样化分子集合，然后生成较小的、专注的库，丰富可能具有活性的分子以用于特定目标。堆叠RNN层用于生成新的分子SMILES表示。这项工作展示了RNN在分子生成模型中的鲁棒性和迁移性。Gupta等人[[51](#bib.bib51)]
    也遵循了在大规模分子数据集上预训练和在小规模数据集上微调以生成特定属性的分子的思路。这项工作还突显了基于RNN的生成模型在从分子片段完成具有特定属性的分子方面的潜力。Grisoni等人[[52](#bib.bib52)]
    提出了一个从序列的两个方向进行生成和数据增强的方法。由于分子序列不像NLP序列那样具有方向性，这种尝试在实验中表现优于单向RNN。'
- en: Many works also employ long-short term memory (LSTM) networks. Bjerrum et al.
    [[53](#bib.bib53)] train LSTM-based molecular generative models on two datasets
    consisting of fragment-like and drug-like molecules. Ertl et al. [[54](#bib.bib54)]
    use an LSTM-based molecule generation model to generate a large number of new
    molecules in a short period, of which structural features and functional groups
    remain closed within the drug-like space defined by the bioactive molecules from
    ChEMBL.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 许多工作还使用长短期记忆（LSTM）网络。Bjerrum等人[[53](#bib.bib53)] 在两个数据集上训练基于LSTM的分子生成模型，这些数据集包括片段状和药物状分子。Ertl等人[[54](#bib.bib54)]
    使用基于LSTM的分子生成模型，在短时间内生成大量新分子，这些分子的结构特征和功能基团仍然保持在由ChEMBL的生物活性分子定义的药物状空间内。
- en: 'Variational Auto-Encoders (VAE). VAEs encode high-dimensional, discrete chemical
    space into a low-dimensional, continuous latent space, which can be used to sample
    molecules with given property (Fig. [3](#S3.F3 "Figure 3 ‣ 3 Molecule Generation
    ‣ Deep Learning Methods for Small Molecule Drug Discovery: A Survey")B). Schiff
    et al. [[55](#bib.bib55)] only use SMILES representations instead of graph-based
    molecular representations. The method is well-performed by incorporating 3D geometric
    information into the VAE. Alperstein et al. [[56](#bib.bib56)] consider the non-uniqueness
    of molecular SMILES expression and propose encoding multiple SMILES strings of
    a single molecule. VAE effectively learns the hidden information between different
    SMILES representations and performs well in molecule generation and optimization
    in fully supervised and semi-supervised situations.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '变分自编码器（VAE）。VAE将高维、离散的化学空间编码到低维、连续的潜在空间中，可以用于采样具有给定属性的分子（图 [3](#S3.F3 "Figure
    3 ‣ 3 Molecule Generation ‣ Deep Learning Methods for Small Molecule Drug Discovery:
    A Survey")B）。Schiff等人[[55](#bib.bib55)] 仅使用SMILES表示，而不是基于图的分子表示。这种方法通过将3D几何信息融入VAE中表现良好。Alperstein等人[[56](#bib.bib56)]
    考虑到分子SMILES表达的非唯一性，并提出对单一分子的多个SMILES字符串进行编码。VAE有效地学习不同SMILES表示之间的隐藏信息，并在完全监督和半监督的情况下在分子生成和优化中表现良好。'
- en: In addition to the commonly used RNN and VAE models, Nigam et al. [[57](#bib.bib57)]
    combine the traditional genetic algorithm with deep neural network. The DNN-based
    discriminator improves the diversity of generated molecules and increases the
    interpretability of genetic algorithm. Moss et al. [[58](#bib.bib58)] first use
    string kernels and genetic algorithms in bayesian optimization loops. Most bayesian
    optimization approaches need to convert the original string inputs to fixed-size
    vectors, while this architecture can directly work on raw strings.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 除了常用的 RNN 和 VAE 模型外，Nigam 等人 [[57](#bib.bib57)] 将传统的遗传算法与深度神经网络结合起来。基于 DNN 的鉴别器提高了生成分子的多样性，并增加了遗传算法的可解释性。Moss
    等人 [[58](#bib.bib58)] 首次在贝叶斯优化循环中使用了字符串核和遗传算法。大多数贝叶斯优化方法需要将原始字符串输入转换为固定大小的向量，而这种架构可以直接处理原始字符串。
- en: In conclusion, string-based molecule generation considers the input and target
    molecules as the sequence data. Deep learning models like RNN, VAE, and genetic
    algorithm achieve great success in the generation task. However, there is still
    a limitation for the string-based method since it may lose the complex geometry
    information of molecules. Thus, most current works focus on the graph-based model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，基于字符串的分子生成将输入和目标分子视为序列数据。像 RNN、VAE 和遗传算法这样的深度学习模型在生成任务中取得了很大的成功。然而，基于字符串的方法仍然存在局限性，因为它可能会丢失分子的复杂几何信息。因此，目前大多数研究工作都集中在基于图的方法上。
- en: 3.2 Graph-based
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 基于图的方法
- en: 'Motif, also referred to as scaffold or rationale, is defined as the molecule
    fragment. Motif corresponds to the concept of functional groups in chemistry,
    closely related to the molecule’s chemical properties. Thus, motif can provide
    more prior knowledge when generating molecules with given properties. Meanwhile,
    motif already has a specific valid structure. With the involvement of motif, generating
    invalid molecules can be avoided to some extent. Motif-based molecular generation
    treats molecules as a collection of fragments. Substructures are then spliced
    to generate new molecules. Non-motif molecular generation generates molecules
    atom by atom (Fig. [3](#S3.F3 "Figure 3 ‣ 3 Molecule Generation ‣ Deep Learning
    Methods for Small Molecule Drug Discovery: A Survey")C).'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 'Motif，也称为骨架或合理性，是指分子片段。Motif 对应于化学中的官能团概念，与分子的化学性质密切相关。因此，在生成具有特定属性的分子时，motif
    可以提供更多的先验知识。同时，motif 已经具有特定的有效结构。通过涉及 motif，可以在一定程度上避免生成无效分子。基于 motif 的分子生成将分子视为片段的集合。然后，将子结构拼接以生成新分子。非
    motif 分子生成是逐个原子生成分子（见图 [3](#S3.F3 "Figure 3 ‣ 3 Molecule Generation ‣ Deep Learning
    Methods for Small Molecule Drug Discovery: A Survey")C）。'
- en: Motif-based Molecular Generation. Jin et al. [[43](#bib.bib43)] generate molecular
    graphs using a variational auto-encoder. They first extract valid chemical substructures
    from the training set to generate a tree-structured scaffold, then use the subgraphs
    as building blocks and combine them to form a molecular graph. Compared with the
    node-by-node approach, this structure-by-structure approach maintains chemical
    validity at each step. Jin et al. [[59](#bib.bib59)] further combine variational
    auto-encoder with an adversarial training method to obtain various and valid output
    distributions. An adversarial regularization is included to align the distribution
    of generated graphs with the distribution of valid targets. Jin et al. [[60](#bib.bib60)]
    propose a hierarchical graph encoder-decoder that can generate large molecules
    such as polymers. Each molecule has a fine-to-coarse representation from atom
    level to motif level. Similar to [[43](#bib.bib43)], Maziarz et al. [[61](#bib.bib61)]
    use extracted motif to generate molecules. Meanwhile, they integrate this method
    with atom-by-atom generation. You et al. [[62](#bib.bib62)] develop a graph convolutional
    network through reinforcement learning. The generation procedure is regarded as
    Markov Decision Process, and domain-specific rewards are incorporated into the
    model. Yang et al. [[63](#bib.bib63)] also propose a reinforcement learning framework
    that generates pharmacochemically acceptable molecules with significant docking
    scores. This method chooses a chemically realistic and pharmacochemically acceptable
    fragment based on the given state of the molecule. To generate molecules with
    multiple property constraints, Jin et al. [[64](#bib.bib64)] extract rationales
    for each property and combine them as multi-property rationales. A graph completion
    model is then implemented to generate complete molecules from rationales. Based
    on [[64](#bib.bib64)], Chen et al. [[65](#bib.bib65)] propose an Expectation-Maximization
    like algorithm. In the E-step, an explainable model extracts rationales from candidate
    molecules. While in the M-step, rationales are completed to generate molecules
    with a higher property score. Xie et al. [[66](#bib.bib66)] employ the annealed
    Markov chain Monte Carlo sampling method [[67](#bib.bib67)] to search the vase
    chemical space. They further train a graph neural network based on the sampling
    result to choose proper candidate edits. Fu et al. [[68](#bib.bib68)] propose
    differentiable scaffolding tree which is a gradient-based optimization method.
    Graph convolutional network transforms the discrete chemical space into a locally
    differentiable space. Further, the molecule is optimized by gradient back-propagation
    from the target.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 基于基序的分子生成。Jin 等人 [[43](#bib.bib43)] 使用变分自编码器生成分子图。他们首先从训练集中提取有效的化学子结构以生成树状支架，然后使用这些子图作为构建块并将其组合形成分子图。与逐节点方法相比，这种结构-结构的方法在每一步都保持了化学有效性。Jin
    等人 [[59](#bib.bib59)] 进一步将变分自编码器与对抗训练方法结合，以获得多样且有效的输出分布。包含对抗正则化，以使生成的图的分布与有效目标的分布对齐。Jin
    等人 [[60](#bib.bib60)] 提出了一个层次图编码-解码器，可以生成如聚合物等大型分子。每个分子从原子级到基序级都有精细到粗略的表示。与 [[43](#bib.bib43)]
    类似，Maziarz 等人 [[61](#bib.bib61)] 使用提取的基序生成分子。同时，他们将此方法与逐原子生成结合起来。You 等人 [[62](#bib.bib62)]
    通过强化学习开发了图卷积网络。生成过程被视为马尔可夫决策过程，并将领域特定的奖励纳入模型。Yang 等人 [[63](#bib.bib63)] 还提出了一种强化学习框架，该框架生成具有显著对接分数的药物化学可接受分子。该方法基于给定的分子状态选择化学上现实且药物化学上可接受的片段。为了生成具有多个属性约束的分子，Jin
    等人 [[64](#bib.bib64)] 提取每个属性的理由并将其结合为多属性理由。然后实现图完成模型，以从理由中生成完整的分子。基于 [[64](#bib.bib64)]，Chen
    等人 [[65](#bib.bib65)] 提出了类似于期望最大化的算法。在 E 步骤中，一个可解释模型从候选分子中提取理由。而在 M 步骤中，理由被完成以生成具有更高属性分数的分子。Xie
    等人 [[66](#bib.bib66)] 采用退火马尔可夫链蒙特卡洛采样方法 [[67](#bib.bib67)] 来搜索化学空间。他们进一步基于采样结果训练图神经网络，以选择合适的候选编辑。Fu
    等人 [[68](#bib.bib68)] 提出了可微分的支架树，这是一种基于梯度的优化方法。图卷积网络将离散的化学空间转换为局部可微分空间。此外，通过从目标处的梯度反向传播来优化分子。
- en: Non-motif Molecular Generation. Zhou et al. [[69](#bib.bib69)] generate molecule
    atom by atom with the help of the double Q-learning technique. This method does
    not require pre-training, so that the training set does not limit exploration
    capability. Combining autoregressive and flow-based methods, Shi et al. [[70](#bib.bib70)]
    develop a flow-based autoregressive graph generation model, allowing parallel
    computation in the training process. The model generates edges and nodes concerning
    the current graph. In each generation step, chemical knowledge like the valence
    rule could be utilized to check the molecular validity. For molecule optimization
    problem, Korovina et al. [[71](#bib.bib71)] develop a bayesian optimization model
    that focuses on small organic molecules. Chen et al. [[72](#bib.bib72)] propose
    a cost-effective evolution strategy in latent space. An evolutionary algorithm
    is introduced into the latent space to search for the desired molecules. Wu et
    al. [[73](#bib.bib73)] propose distilled graph attention policy network, which
    is aimed to optimize molecule structure based on user-defined objectives. A spatial
    graph attention mechanism is introduced, considering self-attention over the node
    and edge attributes.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 非模式分子生成。周等人[[69](#bib.bib69)]利用双重Q学习技术逐个原子生成分子。这种方法不需要预训练，因此训练集不会限制探索能力。结合自回归和基于流的方法，施等人[[70](#bib.bib70)]开发了一种基于流的自回归图生成模型，允许在训练过程中进行并行计算。该模型生成与当前图相关的边和节点。在每个生成步骤中，可以利用诸如价键规则等化学知识来检查分子的有效性。对于分子优化问题，科罗维娜等人[[71](#bib.bib71)]开发了一种专注于小型有机分子的贝叶斯优化模型。陈等人[[72](#bib.bib72)]提出了一种在潜在空间中具有成本效益的进化策略。将进化算法引入潜在空间中以搜索所需的分子。吴等人[[73](#bib.bib73)]提出了精炼图注意力策略网络，旨在基于用户定义的目标优化分子结构。引入了一种空间图注意力机制，考虑了节点和边属性的自注意力。
- en: In addition to exploring 2D molecule generation, many works have been done on
    3D molecule generation tasks. Simm et al. [[74](#bib.bib74)] combine a conditional
    variational autoencoder with a euclidean distance geometry algorithm. This method
    uses a set of pairwise distances between atoms to describe molecule conformation
    instead of cartesian coordinates. Following [[74](#bib.bib74)], Xu et al. [[75](#bib.bib75)]
    first propose an end-to-end conditional variational autoencoder framework for
    molecular conformation prediction. In this work, the distance prediction problem
    and the distance geometry problem are simultaneously optimized via bilevel programming.
    Shi et al. [[76](#bib.bib76)] directly estimate the gradient fields of the log
    density of atomic coordinates. The estimated gradient fields can generate conformations
    directly via Langevin dynamics, thus reducing the computation error. Zhu et al.
    [[77](#bib.bib77)] design a loss function invariant to the roto-translation of
    coordinates of conformations and permutation of symmetric atoms in molecules.
    Xu et al. [[78](#bib.bib78)] analogize conformation generation to diffusion process
    in thermodynamics. Atoms are first stabilized in specific conformations and then
    diffuse into a noise distribution. The reverse process is regarded as Markov chain
    solving for conformation generation problems. Luo et al. [[79](#bib.bib79)] propose
    an autoregressive flow model which can generate 3D molecules. This method directly
    generates distances, angles, and torsion angles of atoms rather than 3D coordinates.
    Once a molecule is generated, the relative distances and angles between atoms
    are determined, thus ensuring invariance and equivariance. Mansimov et al. [[80](#bib.bib80)]
    propose a conditional deep generative graph neural network to learn the energy
    function of molecule conformations. Compared with conventional molecular force
    field methods, this model can directly generate energy-supported molecular conformations
    without requiring multiple iterations. Guan et al. [[81](#bib.bib81)] also propose
    an energy-inspired neural optimization formulation. The molecule conformation
    is optimized by gradient descent for 3D coordinates through the energy surface.
    Xu et al. [[82](#bib.bib82)] propose a method that combines flow-based and energy-based
    models. Flow-based model is used to generate a distance matrix from a Gaussian
    prior. Then the energy-based model searches and optimizes the 3D coordinates of
    the molecule.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 除了探索二维分子生成，许多工作也集中在三维分子生成任务上。Simm 等人 [[74](#bib.bib74)] 将条件变分自编码器与欧几里得距离几何算法结合。这种方法使用原子之间的一组成对距离来描述分子构象，而不是笛卡尔坐标。继[[74](#bib.bib74)]之后，Xu
    等人 [[75](#bib.bib75)] 首次提出了一种用于分子构象预测的端到端条件变分自编码器框架。在这项工作中，通过双层规划同时优化距离预测问题和距离几何问题。Shi
    等人 [[76](#bib.bib76)] 直接估计原子坐标的对数密度梯度场。估计的梯度场可以通过朗之万动力学直接生成构象，从而减少计算误差。Zhu 等人
    [[77](#bib.bib77)] 设计了一种对构象坐标的旋转-平移以及分子中对称原子的排列不变的损失函数。Xu 等人 [[78](#bib.bib78)]
    将构象生成类比为热力学中的扩散过程。原子首先在特定构象中稳定，然后扩散到噪声分布中。反向过程被视为马尔可夫链，用于解决构象生成问题。Luo 等人 [[79](#bib.bib79)]
    提出了一个自回归流模型，该模型可以生成三维分子。这种方法直接生成原子的距离、角度和扭转角，而不是三维坐标。一旦生成了分子，原子之间的相对距离和角度就会被确定，从而确保了不变性和等变性。Mansimov
    等人 [[80](#bib.bib80)] 提出了一个条件深度生成图神经网络，用于学习分子构象的能量函数。与传统的分子力场方法相比，该模型可以直接生成支持能量的分子构象，而无需多次迭代。Guan
    等人 [[81](#bib.bib81)] 还提出了一种受能量启发的神经优化公式。通过能量表面，分子构象通过梯度下降优化三维坐标。Xu 等人 [[82](#bib.bib82)]
    提出了一种结合流基模型和能量基模型的方法。流基模型用于从高斯先验生成距离矩阵。然后，能量基模型搜索并优化分子的三维坐标。
- en: 4 Molecular Property Prediction
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 分子性质预测
- en: '![Refer to caption](img/12ea22a42fd64546adb4d74a8c909a5c.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/12ea22a42fd64546adb4d74a8c909a5c.png)'
- en: 'Figure 4: Illustrations of (A) Recurrent Neural Networks, (B) Transformer and
    (C) Graph Neural Networks in molecular property prediction.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：分子性质预测中(A)递归神经网络、(B)变换器和(C)图神经网络的插图。
- en: 4.1 SMILES-based
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 基于SMILES
- en: The SMILES-based methods utilize various architectures, such as RNN, VAE, and
    transformers, which are demonstrated as follows.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 基于SMILES的方法利用各种架构，如RNN、VAE和变换器，具体如下所示。
- en: 'Recurrent Neural Networks (RNN). RNNs are shown to be effective designs for
    sequential input such as text data. Thus, RNN and its two variants, LSTMs [[83](#bib.bib83)]
    and GRUs [[84](#bib.bib84)], are applied to learn chemical properties from SMILES
    (Fig. [4](#S4.F4 "Figure 4 ‣ 4 Molecular Property Prediction ‣ Deep Learning Methods
    for Small Molecule Drug Discovery: A Survey")A).'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '循环神经网络（RNN）。RNN被证明是对顺序输入如文本数据的有效设计。因此，RNN及其两个变体，LSTM [[83](#bib.bib83)]和GRU
    [[84](#bib.bib84)]，被应用于从SMILES中学习化学属性（见图[4](#S4.F4 "Figure 4 ‣ 4 Molecular Property
    Prediction ‣ Deep Learning Methods for Small Molecule Drug Discovery: A Survey")A）。'
- en: Mayr et al. [[85](#bib.bib85)] employe long short-term memory networks to construct
    the SmilesLSTM architecture, which utilizes SMILES strings as inputs. Inspired
    by the success of RNNs in sequence-to-sequence language translation, Goh et al.
    propose a sequence-to-vector model SMILES2vec [[86](#bib.bib86)], where the sequence
    is SMILES, and the vector is measured property. Instead of explicitly encoding
    the molecular information from element compositions in SMILES, they explore four
    CNN-based and RNNs-based architectures to learn the desired features directly.
    Meanwhile, an explanation mask is developed to localize the most important characters,
    improving the model’s interpretability.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Mayr等人[[85](#bib.bib85)]使用长短期记忆网络构建SmilesLSTM架构，该架构利用SMILES字符串作为输入。受到RNN在序列到序列语言翻译中成功的启发，Goh等人提出了一种序列到向量模型SMILES2vec
    [[86](#bib.bib86)]，其中序列是SMILES，向量是测量属性。他们没有显式地从SMILES中的元素组成中编码分子信息，而是探索了四种基于CNN和RNN的架构以直接学习所需的特征。同时，开发了一个解释掩码以定位最重要的字符，从而提高了模型的可解释性。
- en: While Goh et al. [[86](#bib.bib86)] stick to the commonly-used canonical SMILES,
    which preserves a one-to-one mapping from molecule to string, Li et al. [[87](#bib.bib87)]
    make use of multiple SMILES strings of a single molecule as data augmentations,
    which helps to learn better grammatical features. The proposed model generates
    the molecular representation from multiple SMILES sequences that first convert
    to a one-hot vector and then follow the message-passing process in the stacked
    CNN and RNN architecture.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Goh等人[[86](#bib.bib86)]坚持使用常用的规范SMILES，这保持了分子到字符串的一对一映射，但Li等人[[87](#bib.bib87)]利用单个分子的多个SMILES字符串作为数据增强，这有助于学习更好的语法特征。所提出的模型从多个SMILES序列生成分子表示，首先将其转换为一热向量，然后遵循堆叠CNN和RNN架构中的消息传递过程。
- en: Considering that chemical information is able to canonicalize SMILES strings,
    Peng et al. [[88](#bib.bib88)] exploit a framework called TOP, combining the usage
    of SMILES and predefined properties, including root atom positions and isomeric
    features. A bidirectional gated recurrent unit-based RNN (BiGRU) is employed for
    the SMILES strings to capture local and global context information. At the same
    time, a fully connected neural network (FCN) is used to process the physicochemical
    feature vector. When performing on balanced datasets, TOP significantly outperforms
    other methods, including SMILES2vec [[86](#bib.bib86)], CheMixNet [[89](#bib.bib89)],
    and Chemception [[90](#bib.bib90)], which uses only the images of 2D molecular
    drawings decoded from SMILES.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到化学信息能够规范化SMILES字符串，Peng等人[[88](#bib.bib88)]利用了一个叫做TOP的框架，结合了SMILES和预定义属性的使用，包括根原子位置和异构特征。采用基于双向门控递归单元的RNN（BiGRU）处理SMILES字符串，以捕捉局部和全局上下文信息。同时，使用全连接神经网络（FCN）处理理化特征向量。在平衡数据集上执行时，TOP显著优于其他方法，包括SMILES2vec
    [[86](#bib.bib86)]、CheMixNet [[89](#bib.bib89)]和Chemception [[90](#bib.bib90)]，后者仅使用从SMILES解码的2D分子图像。
- en: Variational Auto-Encoder (VAE). VAE models share a similar structure to the
    encoder-decoder structure mentioned in the RNN-based architecture. However, it
    is different in formulating the assumption that the embedded space follows Gaussian
    distributions. Among the existing architectures, VAEs focus more on molecular-based
    latent representations instead of specifying prediction tasks. Adapting the SSVAE
    devised in [[91](#bib.bib91)], Kang and Cho feed SMILES as the input variables
    and its continuous-valued property vectors as outputs. The encoder and decoder
    networks perform the recovery task of SMILES with the learned latent molecular
    representation as an intermediate between the two stages. Once the SSVAE is trained,
    the remaining RNN acts as the predictor network. ALL SMILES VAE [[56](#bib.bib56)]
    ensures the learned latent molecular representation to capture the molecular feature
    instead of its SMILES realization by using multiple SMILES and implicitly performing
    message passing among spanning trees of the molecular graph via recurrent structures.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 变分自编码器（VAE）。VAE模型与RNN基础架构中提到的编码器-解码器结构具有类似的结构。然而，它在假设嵌入空间遵循高斯分布上有所不同。在现有架构中，VAEs更关注基于分子的潜在表示，而不是指定预测任务。采用在
    [[91](#bib.bib91)] 中设计的SSVAE，Kang和Cho将SMILES作为输入变量，其连续值属性向量作为输出。编码器和解码器网络执行SMILES的恢复任务，将学习到的潜在分子表示作为两个阶段之间的中介。一旦SSVAE被训练，剩余的RNN则充当预测网络。ALL
    SMILES VAE [[56](#bib.bib56)] 通过使用多个SMILES并通过递归结构在分子图的跨越树之间隐式执行消息传递，确保学到的潜在分子表示能够捕捉到分子特征，而不是其SMILES实现。
- en: 'Transformer. Transformer architecture follows a similar encoder-decoder process,
    but it does not employ recurrent connections like RNNs and is thus prone to be
    more stable to converge and superior to RNNs in featurization on longer and larger
    corpus (Fig. [4](#S4.F4 "Figure 4 ‣ 4 Molecular Property Prediction ‣ Deep Learning
    Methods for Small Molecule Drug Discovery: A Survey")B) [[45](#bib.bib45), [46](#bib.bib46)].
    To guarantee the learned molecular representations are able to successfully transfer
    in numerous downstream tasks, pre-training strategies on a large SMILES corpus
    stand out. SMILES-GPT [[46](#bib.bib46)], prolonging the pre-training approach,
    applies a lightweight adapter network after each attention block on the design
    of GPT-2 [[47](#bib.bib47)] to learn specific task patterns. In this way, it alleviates
    the loss of domain knowledge when transferring the pre-trained model to the separate
    downstream task.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer。Transformer架构遵循类似的编码器-解码器过程，但不像RNNs那样使用递归连接，因此在长文本和大规模语料库上趋于更稳定的收敛，并且在特征化方面优于RNNs
    (图[4](#S4.F4 "图 4 ‣ 4 分子属性预测 ‣ 小分子药物发现的深度学习方法：综述")B) [[45](#bib.bib45), [46](#bib.bib46)]。为了确保学到的分子表示能够成功转移到众多下游任务中，大规模SMILES语料库上的预训练策略脱颖而出。SMILES-GPT
    [[46](#bib.bib46)] 延续了预训练方法，在每个注意力块之后应用了轻量级适配器网络，在GPT-2 [[47](#bib.bib47)] 设计上学习特定的任务模式。这样，它缓解了将预训练模型转移到单独下游任务时的领域知识损失。
- en: The language representation model BERT [[92](#bib.bib92)] introduces masked
    language model (MLM) pre-training techniques that alleviate the constraints of
    incorporating context from uni-direction. Benefiting from the similarities between
    MLM and atom masking in molecules, the BERT-style architecture has emerged as
    a robust technique in molecular representation learning. The efficacy of BERT-liked
    architectures, such as RoBERTa [[93](#bib.bib93)], is proved to achieve comparatively
    high classification accuracy when training through an extensive database [[94](#bib.bib94)].
    With a careful exploration of pre-training dataset size, tokenizer, and string
    representation, ChemBERTa [[95](#bib.bib95)] adapted from RoBERTa [[93](#bib.bib93)]
    again emphasizes the efficiency of large-scale pre-training in molecular property
    prediction.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 语言表示模型BERT [[92](#bib.bib92)] 引入了掩码语言模型（MLM）预训练技术，这些技术缓解了来自单向上下文的约束。由于MLM与分子中原子掩码的相似性，BERT风格的架构已经成为分子表示学习中的一种强大技术。BERT类似架构，如RoBERTa
    [[93](#bib.bib93)]，经过广泛数据库训练后被证明能够实现相对较高的分类准确性 [[94](#bib.bib94)]。通过仔细探索预训练数据集规模、分词器和字符串表示，来自RoBERTa
    [[93](#bib.bib93)] 的ChemBERTa [[95](#bib.bib95)] 再次强调了大规模预训练在分子属性预测中的效率。
- en: 4.2 Fingerprint-based
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 基于指纹的
- en: Fingerprints, as another class of molecular representations, also benefits molecular
    predictive tasks. Unterthiner et al. [[96](#bib.bib96)] employ multi-task learning
    in molecular property prediction, leveraging the power of deep neural networks
    to generate hierarchical representations of compounds. Meanwhile, Mayr et al. [[97](#bib.bib97)]
    introduce the DeepTox pipeline. DeepTox employs normalization techniques to generate
    standardized chemical representations of compounds, and subsequently computes
    an extensive array of chemical descriptors that serve as input to machine learning
    algorithms. Traditionally hand-crafted fingerprints are also introduced as the
    complement of SMILES strings for molecular feature information. In this way, the
    model performance no longer fluctuates with the length of SMILES strings drastically.
    Paul et al. [[89](#bib.bib89)] harness two successful architectures for property
    prediction, including SMILES2vec and MLP, into a multi-input-single-output (MISO)
    architecture CheMixNet. The model takes both SMILES strings and MACCS fingerprints
    as inputs. Leveraging both types of molecular structural representations as parallel
    inputs increase generalizability. Schimunek et al. [[98](#bib.bib98)] present
    a novel few-shot method that enhances the representation of a molecule by incorporating
    information from known context or reference molecules.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 指纹作为另一类分子表示方法，也有利于分子预测任务。Unterthiner 等人 [[96](#bib.bib96)] 在分子性质预测中使用了多任务学习，利用深度神经网络的力量生成化合物的层次表示。与此同时，Mayr
    等人 [[97](#bib.bib97)] 引入了 DeepTox 流水线。DeepTox 采用归一化技术生成标准化的化学表示，并随后计算大量化学描述符，这些描述符作为机器学习算法的输入。传统的手工制作指纹也作为
    SMILES 字符串的补充来提供分子特征信息。这样，模型的性能不再因 SMILES 字符串的长度剧烈波动。Paul 等人 [[89](#bib.bib89)]
    将两种成功的属性预测架构，包括 SMILES2vec 和 MLP，融合成一个多输入单输出 (MISO) 架构 CheMixNet。该模型同时接受 SMILES
    字符串和 MACCS 指纹作为输入。利用这两种分子结构表示作为并行输入，提高了模型的泛化能力。Schimunek 等人 [[98](#bib.bib98)]
    提出了一种新颖的少量样本方法，通过结合已知上下文或参考分子的 信息来增强分子的表示。
- en: However, the performance of traditional fingerprints is not good enough in prediction
    tasks due to the restrictions of the manually designed methods. For example, the
    hash-based fingerprint brings limited task-specific information due to its irreversibility.
    With the advancement of deep-learning techniques, novel methods have been invented
    to generate deep-learning-based fingerprints for property prediction.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于手工设计方法的限制，传统指纹在预测任务中的表现并不理想。例如，基于哈希的指纹由于其不可逆性，带来了有限的任务特定信息。随着深度学习技术的发展，已经发明了生成基于深度学习的指纹以进行属性预测的新方法。
- en: Recurrent Neural Networks (RNN). RNNs-based unsupervised fingerprint methods
    are proposed to tackle the problem of scarce labeled data. Deep neural networks
    are applied to utilize a large pool of unlabeled data. Motivated by the breakthrough
    success of the model applied in seq-to-seq language translations, encoder-decoder
    structured neural networks have been popular in generating fingerprints based
    on sequence-like SMILES strings. Xu et al. [[42](#bib.bib42)] extract the intermediate
    fixed-size molecular feature vectors as seq2seq fingerprints during the process
    of mapping a SMILES string to the desired vector and then translating back to
    the original string. The extracted fingerprints, combined with SMILES labels,
    are trained for prediction tasks in supervised methods with classifiers or regressors,
    such as multi-layer perceptron. Based on the design, Zhang et al. [[99](#bib.bib99)]
    modify it to the first end-to-end framework coupling recovery and inference tasks
    in a model named seq3seq fingerprint.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 循环神经网络 (RNN)。基于 RNN 的无监督指纹方法被提出以解决标签数据稀缺的问题。深度神经网络被应用于利用大量未标记的数据。受到在 seq-to-seq
    语言翻译中应用模型取得突破性成功的启发，编码器-解码器结构的神经网络在基于序列型 SMILES 字符串生成指纹方面变得流行。Xu 等人 [[42](#bib.bib42)]
    在将 SMILES 字符串映射到期望向量并将其翻译回原始字符串的过程中，提取了固定大小的分子特征向量作为 seq2seq 指纹。提取的指纹与 SMILES
    标签结合后，经过分类器或回归器等监督方法进行预测任务的训练，例如多层感知机。基于设计，Zhang 等人 [[99](#bib.bib99)] 将其修改为第一个端到端框架，将恢复和推理任务耦合在名为
    seq3seq 指纹的模型中。
- en: Transformer. Inspired by the excellent performance of the self-attention mechanism
    in language tasks, Transformer is believed to have a good performance on abundant
    unlabeled molecular data. By adopting the pre-training approach that shows promising
    results in the NLP field, SMILES transformer [[45](#bib.bib45)] is presented to
    learn molecular fingerprints through large-scaled pre-training on canonical SMILES.
    The data-driven extracted fingerprints work well with a simple multi-layer perceptron,
    which shows the great potential of exploiting unsupervised pre-training in property
    prediction.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer。受到自注意力机制在语言任务中优异表现的启发，Transformer 被认为在丰富的无标注分子数据上也能有良好的表现。通过采用在
    NLP 领域显示出良好结果的预训练方法，SMILES transformer [[45](#bib.bib45)] 被提出通过在标准 SMILES 上的大规模预训练来学习分子指纹。数据驱动提取的指纹与简单的多层感知器效果良好，这显示了在属性预测中利用无监督预训练的巨大潜力。
- en: BERT, similar to the encoder of the Transformer, is also a promising structure.
    SMILES-BERT [[100](#bib.bib100)], following the BERT approach, randomly masks
    selected tokens in an input SMILE to the mask token, any other token in the dictionary,
    or unchanged according to an 85/10/5 split ratio. The fingerprints generated from
    the MLM strategy are experimentally proved to have higher predictive accuracy
    on a rather large dataset than some representative fingerprints, including circular
    fingerprint [[101](#bib.bib101)], neural fingerprint [[102](#bib.bib102)] and
    seq2seq fingerprint [[42](#bib.bib42)].
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: BERT，与 Transformer 的编码器类似，也是一个有前途的结构。SMILES-BERT [[100](#bib.bib100)] 采用了 BERT
    方法，将输入 SMILE 中随机选择的标记遮盖为遮盖标记、词典中的任何其他标记，或按照 85/10/5 的比例保持不变。实验表明，从 MLM 策略生成的指纹在一个相当大的数据集上具有比一些代表性指纹更高的预测准确性，这些指纹包括圆形指纹
    [[101](#bib.bib101)]、神经指纹 [[102](#bib.bib102)] 和 seq2seq 指纹 [[42](#bib.bib42)]。
- en: 4.3 Graph-based
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 基于图的方法
- en: 'Graph Convolutional Network (GCN). Graph convolutional networks (GCN) [[103](#bib.bib103)]
    are always considered a common baseline choice for applications. The model focuses
    on learning node states and aggregates the neighboring messages (Fig. [4](#S4.F4
    "Figure 4 ‣ 4 Molecular Property Prediction ‣ Deep Learning Methods for Small
    Molecule Drug Discovery: A Survey")C). A wide range of applications in molecule
    representation learning is based on GCNs due to its lightweight calculation and
    scalability to large graphs.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '图卷积网络 (GCN)。图卷积网络 (GCN) [[103](#bib.bib103)] 总是被视为应用中的常见基线选择。该模型专注于学习节点状态并聚合邻居消息（图
    [4](#S4.F4 "Figure 4 ‣ 4 Molecular Property Prediction ‣ Deep Learning Methods
    for Small Molecule Drug Discovery: A Survey")C）。由于其轻量级计算和对大图的可扩展性，GCNs 在分子表示学习中的应用广泛。'
- en: Labeled datasets, for instance, the QM9 dataset [[104](#bib.bib104)] is composed
    of molecular properties approximated by costly methods such as density functional
    theory. The neighborhood aggregation scheme of GCNs is thus frequently used to
    exploit an overall high-order representation learning for molecules. A multilevel
    graph convolutional neural network proposed in [[105](#bib.bib105)] learns the
    node representations by preserving the conformation information with hierarchical
    modeling (atom-wise, pair-wise, etc), and its spatial information by introducing
    a radial basis function layer for robust distance tensors. The interaction layers
    that effectively combine self features with collected messages from neighbors
    are applied for high-order atom representations.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 标记数据集，例如 QM9 数据集 [[104](#bib.bib104)] 由通过昂贵的方法如密度泛函理论来近似的分子性质组成。因此，GCNs 的邻域聚合方案经常被用来利用整体高阶表示学习来处理分子。[[105](#bib.bib105)]
    提出的多层次图卷积神经网络通过保留构象信息（原子级、对级等）和引入径向基函数层来学习节点表示，以获得稳健的距离张量。有效结合自我特征与来自邻居的收集消息的交互层被应用于高阶原子表示。
- en: It is often challenging that annotated labels are so expensive that datasets
    are commonly seen to be partially labeled in real-world applications. Training
    on such limited labeled data easily leads to over-fitting and poor performance
    of dissimilar molecules from the training data. To address the problem of scarce
    task-specific labels and out-of-distribution predictions, researchers have made
    great efforts in pre-training to leverage the unlabeled data and improve the generalization
    power of GNNs. The key to pre-training is finding a suitable and effective task
    to leverage many unlabeled structures [[106](#bib.bib106)], yet choosing effective
    pre-training strategies is challenging since the selected properties must be aligned
    with the interests of specific downstream tasks. Otherwise, as mentioned above,
    the “negative transfer” effect can seriously harm the generalization when transferring
    the pre-learned knowledge to a new downstream task [[107](#bib.bib107)].
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 由于注释标签成本高昂，现实世界应用中的数据集常常是部分标注的，这常常带来挑战。基于有限标注数据的训练容易导致过拟合，并使得与训练数据不同的分子性能较差。为了应对任务特定标签稀缺和分布外预测的问题，研究人员在预训练方面做出了巨大努力，以利用未标注数据并提升GNN的泛化能力。预训练的关键在于找到一个合适且有效的任务来利用许多未标注的结构
    [[106](#bib.bib106)]，然而选择有效的预训练策略具有挑战性，因为所选属性必须与特定下游任务的兴趣对齐。否则，如上所述，“负迁移”效应可能会严重影响将预先学习的知识转移到新下游任务的泛化能力
    [[107](#bib.bib107)]。
- en: Pre-training is a common and effective strategy for CNNs, ImageMol[[108](#bib.bib108)]
    though the robust scheme has not been explored for GNNs until recent years. Hu
    et al. [[107](#bib.bib107)] conduct the first systematic large-scale investigation
    of pre-training strategies for GNNs. They propose self-supervised context prediction
    and attribute masking methods at the node level and supervised task predictions
    for domain-specific information decoding. Along with the foremost introduction
    of pre-training strategies for property prediction models, Hu et al. [[107](#bib.bib107)]
    apply context prediction and attribute masking with various GNN structures pre-trained
    on eight datasets from MoluculeNet, proving the efficacy of node-level strategies,.
    These methods open new ways for GNN pre-training schemes yet are far from satisfactory.
    Rong et al. [[109](#bib.bib109)] argue that the graph-level tasks are impeded
    with limited labels and introduce more risks of negative transfer in downstream
    tasks. Also, isolating the context and node type predictions as labels makes it
    hard to preserve local structure knowledge or address highly frequent atoms. To
    achieve better generalizability, some have made great efforts to investigate pre-training
    with data augmentation. The proposed model GraphCL [[110](#bib.bib110)] performs
    pre-training through maximizing MI between two augmented representations in the
    latent space generated by different data augmentation methods.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练是卷积神经网络（CNN）常见且有效的策略，尽管这种强大的方案在图神经网络（GNN）上直到最近几年才被探索。胡等人 [[107](#bib.bib107)]
    进行了首次系统的大规模GNN预训练策略调查。他们在节点级别提出了自监督上下文预测和属性掩蔽方法，并针对领域特定信息解码提出了监督任务预测。除了对属性预测模型的预训练策略的首要介绍外，胡等人
    [[107](#bib.bib107)] 还在来自MoluculeNet的八个数据集上应用了上下文预测和属性掩蔽，验证了节点级策略的有效性。这些方法为GNN预训练方案开辟了新的途径，但仍远未令人满意。荣等人
    [[109](#bib.bib109)] 认为图级任务受限于标签的数量，并引入了下游任务的负迁移风险。此外，将上下文和节点类型预测作为标签使得难以保留局部结构知识或处理高频原子。为了实现更好的泛化性，一些研究者在数据增强方面做出了巨大努力。提出的模型GraphCL
    [[110](#bib.bib110)] 通过最大化不同数据增强方法生成的潜在空间中的两个增强表示之间的互信息来进行预训练。
- en: Inspired by these generalized techniques, Wang et al. [[111](#bib.bib111)] introduce
    the specific molecular-designed model MolCLR that addresses GNNs pre-training
    with graph augmentations by contrastive learning. It follows a similar manner
    as GraphCL [[110](#bib.bib110)] by maximizing distance between two latent augmented
    vectors resulting from two stochastic augmentations. However, augmentation methods
    are more carefully designed and more specified for molecules. Despite atom masking
    and subgraph removal, the model utilizes bond deletions instead of random perturbations
    that can mimic the reactions of chemical bonds to learn more valuable features.
    However, researchers are still doubting the effectiveness of data augmentation
    in pre-training. Li et al. [[112](#bib.bib112)] argue that random modification
    of atoms and edges can harmfully destroy the natural structure. Liu et al. [[113](#bib.bib113)]
    propose the N-gram graph, which is a unsupervised representation for molecules.
    The approach commences by embedding the vertices in the molecule graph. It then
    creates a concise representation for the graph by assembling the vertex embeddings
    in short walks within the graph. Altae et al. [[114](#bib.bib114)] develop a architecture
    that combines iterative refinement long short-term memory with graph convolutional
    neural networks. This one-shot learning approach allows for significant reductions
    in the amount of data needed to make accurate predictions.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 受这些通用技术的启发，王等人[[111](#bib.bib111)]介绍了特定的分子设计模型MolCLR，该模型通过对比学习处理图增强的GNN预训练。它以类似于GraphCL[[110](#bib.bib110)]的方式，通过最大化来自两个随机增强的潜在增强向量之间的距离。然而，增强方法设计得更为细致，并且针对分子进行了更具体的优化。尽管存在原子遮蔽和子图移除，该模型利用键删除而非随机扰动来模拟化学键的反应，以学习更有价值的特征。然而，研究人员仍对数据增强在预训练中的有效性表示怀疑。李等人[[112](#bib.bib112)]认为，原子和边缘的随机修改可能会破坏自然结构。刘等人[[113](#bib.bib113)]提出了N-gram图，这是一种用于分子的无监督表示方法。该方法首先将分子图中的顶点嵌入，然后通过在图内的短步行中汇总顶点嵌入，创建图的简洁表示。Altae等人[[114](#bib.bib114)]开发了一种将迭代优化的长短期记忆与图卷积神经网络相结合的架构。这种一次性学习方法可以显著减少进行准确预测所需的数据量。
- en: Messsage Passing Neural Network (MPNN). When inferring molecular properties,
    the impact of bond types and distances of atoms can not be neglected. GCNs, though
    considering neighborhood aggregation, are not able to distinguish different edge
    types. To better handle edge features, Gilmer et al. [[115](#bib.bib115)] formally
    propose a message passing neural network (MPNN) to learn a graph level embedding
    with node features as well as the weighted edge messages. The framework involves
    two phases, a message-passing phase and a readout phase. By modeling atoms as
    nodes and bonds as edges, feature vectors of nodes and edges are input to the
    model as initialization. Further, message are aggregated from neighboring nodes
    through multiple layers of message passing. The readout phase then summarizes
    the feature vectors of the whole graph to target the downstream molecular property
    prediction task. Variations based on MPNN [[115](#bib.bib115)] have made great
    progress, such as message passing with attention mechanism in [[109](#bib.bib109)],
    spherical message passing for 3D molecular graphs [[116](#bib.bib116)] and so
    on. Despite the focus on node states, preservation of important bond (edge) information
    is also taken into account for better performance [[48](#bib.bib48)].
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 消息传递神经网络（MPNN）。在推断分子性质时，键类型和原子距离的影响不容忽视。尽管GCNs考虑了邻域聚合，但不能区分不同的边类型。为更好地处理边特征，Gilmer等人[[115](#bib.bib115)]正式提出了一种消息传递神经网络（MPNN），用于学习具有节点特征和加权边信息的图级嵌入。该框架包括两个阶段，一个是消息传递阶段，另一个是读取阶段。通过将原子建模为节点，键建模为边，节点和边的特征向量作为初始化输入到模型中。进一步地，消息通过多层消息传递从邻近节点聚合。读取阶段则总结整个图的特征向量，以针对下游的分子性质预测任务。基于MPNN[[115](#bib.bib115)]的变体取得了显著进展，例如在[[109](#bib.bib109)]中使用注意机制的消息传递、用于3D分子图的球面消息传递[[116](#bib.bib116)]等。尽管专注于节点状态，重要的键（边）信息的保留也被考虑在内，以提高性能[[48](#bib.bib48)]。
- en: The message passing scheme has shown its superior performance in molecular property
    prediction. Hao et al. [[117](#bib.bib117)] make the first attempt to employ the
    powerful framework for molecular property prediction in a semi-supervised manner.
    The novel strategy, by finding the most diversified subset in the unlabeled set
    and continuously adding them to the labeled dataset for training, alleviates the
    over-fitting and imbalance between labeled and unlabeled molecules.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 消息传递方案在分子属性预测中表现出了优越的性能。郝等人[[117](#bib.bib117)]首次尝试以半监督的方式使用这一强大的框架进行分子属性预测。这一新颖的策略通过在未标记集中过滤出最具多样性的子集，并持续将其添加到标记数据集中进行训练，缓解了过拟合以及标记和未标记分子之间的不平衡问题。
- en: Under the assumption of message passing neural networks, two atoms in the same
    neighborhood should have similar representations, neglecting that their positions
    in the molecule are distinct. Therefore, MPNNs are usually armed with positional
    encoding to alleviate the limitations. Instead of applying higher-order representations,
    Dwivedi et al. [[118](#bib.bib118)] introduce positional encoding (PE) for nodes
    and leverage the information as input information to learn both positional and
    structural feature representations at the same time. Combining PE with MPNNs contributes
    to more robust node embedding since it fills the gap in the canonical positioning
    of nodes.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在消息传递神经网络的假设下，同一邻域中的两个原子应该具有类似的表示，而忽略了它们在分子中的位置是不同的。因此，MPNNs通常配备位置编码来缓解这些限制。Dwivedi等人[[118](#bib.bib118)]引入了节点的位置编码（PE），并利用这些信息作为输入信息，以同时学习位置和结构特征表示。将PE与MPNNs结合有助于更稳健的节点嵌入，因为它填补了节点的标准定位中的空白。
- en: While 2D molecule graph provides rich information on topology, 3D geometric
    views also play a vital role in predicting molecular characteristics. Based upon
    the original message passing network [[115](#bib.bib115)], Liu et al. [[116](#bib.bib116)]
    propose the spherical message passing and SphereNet for 3D molecular learning.
    The model performs message passing in the spherical coordinate system and uses
    the relative 3D information and torsion computation to generalize invariant predictions
    of rotation and translation. Furthermore, it is shown that 3D geometric views
    significantly contribute to robust representation learning. In GeomGCL [[112](#bib.bib112)],
    the efficiency of 3D geometry is illustrated to be superior to other methods that
    confine to topology structures. Li et al. [[112](#bib.bib112)] devise a method
    to leverage 2D and 3D pair information to improve generalization ability. The
    dual-channel geometric message passing architecture allows collaborative supervision
    of 2D and 3D views between each other. To further leverage the local spatial correlations,
    a regularizer on angle domains is applied for generalization on similar property
    prediction. These strategies help achieve the goal of capturing both chemical
    semantic information and geometric information.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然二维分子图提供了丰富的拓扑信息，但三维几何视角在预测分子特性中也发挥着重要作用。基于原始的消息传递网络[[115](#bib.bib115)]，刘等人[[116](#bib.bib116)]提出了球面消息传递和SphereNet用于三维分子学习。该模型在球面坐标系统中执行消息传递，并使用相对的三维信息和扭转计算来推广旋转和位移的不变预测。此外，研究表明三维几何视角显著有助于稳健的表示学习。在GeomGCL
    [[112](#bib.bib112)]中，三维几何的效率被证明优于其他限制于拓扑结构的方法。李等人[[112](#bib.bib112)]设计了一种方法，通过利用二维和三维配对信息来提高泛化能力。双通道几何消息传递架构允许二维和三维视角之间的协同监督。为了进一步利用局部空间相关性，应用了一个角度域的正则化器，以便在类似属性预测上进行泛化。这些策略有助于实现捕捉化学语义信息和几何信息的目标。
- en: Graph Isomorphism Network (GIN). Capturing statistical dependencies is essential
    in molecular presentation, and the contrastive method is among the most effective
    approaches to obtaining the features [[119](#bib.bib119)]. Borrowed the idea of
    mutual information neural estimator (MINE) from mutual information (MI), deep
    InfoMax (DIM) [[120](#bib.bib120)] is introduced to maximize information content
    between input and output. Inspired by DIM, deep graph InfoMax (DGI) [[119](#bib.bib119)]
    trains a contrastive node encoder that uses GCN to maximize local mutual information
    to capture global information. However, the GCN convolutional encoding fails to
    distinguish some graph structures. Instead of mean and max aggregation, a more
    careful design of neighbor aggregation is needed for more substantial discriminative
    power for graph representations.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图同构网络（GIN）。捕捉统计依赖性在分子表示中至关重要，而对比方法是获取特征的最有效方法之一[[119](#bib.bib119)]。借鉴了互信息神经估计器（MINE）的思想，深度信息最大化（DIM）[[120](#bib.bib120)]
    被引入以最大化输入和输出之间的信息内容。受到 DIM 的启发，深度图信息最大化（DGI）[[119](#bib.bib119)] 训练一个对比节点编码器，使用
    GCN 最大化局部互信息以捕捉全局信息。然而，GCN 卷积编码未能区分一些图结构。需要更加精细的邻居聚合设计，以便为图表示提供更强的区分能力，而不是简单的均值和最大值聚合。
- en: Graph isomorphism network (GIN) [[121](#bib.bib121)] is then proposed and shown
    to be as powerful as Weisfeiler-Lehman graph isomorphism test that determines
    whether two graphs are topologically identical. The structure using sum aggregation
    has better performance in discriminating graph instances. Sun et al. [[122](#bib.bib122)]
    replace the graph convolution encoders with GIN and expands the mutual information
    idea in semi-supervised learning scheme using a ”student-teacher” model to train
    the whole graph level embedding.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图同构网络（GIN）[[121](#bib.bib121)] 随后被提出，并且展示了其与 Weisfeiler-Lehman 图同构测试具有同等的强大能力，该测试用于确定两个图是否在拓扑上相同。使用求和聚合的结构在区分图实例方面具有更好的性能。Sun
    等人[[122](#bib.bib122)] 用 GIN 替换了图卷积编码器，并在半监督学习方案中扩展了互信息的思想，使用“学生-教师”模型来训练整个图级嵌入。
- en: GINs are frequently used for backbone models in recent 2D GNN designs for molecular
    applications. Liu et al. [[106](#bib.bib106)] consider 3D geometric views for
    pre-training with message passing, aiming to train the 2D molecular GIN encoder
    to recover its 3D counterparts to some extent. By maximizing MI between 2D topological
    structure and 3D spatial and geometric information, the pre-trained model can
    benefit from implicit 3D geometric prior information, even if no 3D structure
    is provided in the downstream task. Meanwhile, a comparisons on two pre-training
    models of GraphCL [[110](#bib.bib110)] and GraphMVP are also illustrated in [[106](#bib.bib106)],
    showing that incorporate both 2D topology and 3D geometry is more competitive.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: GINs 最近在用于分子应用的 2D GNN 设计中频繁用作骨干模型。Liu 等人[[106](#bib.bib106)] 考虑了 3D 几何视图用于预训练，并通过消息传递，旨在训练
    2D 分子 GIN 编码器以在一定程度上恢复其 3D 对应物。通过最大化 2D 拓扑结构与 3D 空间和几何信息之间的互信息，预训练模型可以从隐式的 3D
    几何先验信息中受益，即使下游任务中没有提供 3D 结构。同时，在 [[106](#bib.bib106)] 中还对 GraphCL [[110](#bib.bib110)]
    和 GraphMVP 两个预训练模型进行了比较，显示结合 2D 拓扑和 3D 几何信息更具竞争力。
- en: Recurrent Graph Neural Networks. Recurrent neural networks, such as RNNs, GRUs,
    and LSTMs, are powerful tools for processing vary-sized sequences. Converting
    graphs to sequences is a potential solution to get rid of the fixed-size matrix
    problem for molecule graphs. Popular recurrent units, GRUs and LSTMs, have been
    widely used in molecule generation. Furthermore, recurrent units play a significant
    role in message aggregation and conformation preserving.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 循环图神经网络。循环神经网络，如 RNNs、GRUs 和 LSTMs，是处理不同大小序列的强大工具。将图转换为序列是解决分子图固定大小矩阵问题的一个潜在解决方案。流行的循环单元，GRUs
    和 LSTMs，在分子生成中得到了广泛应用。此外，循环单元在消息聚合和构象保持中发挥着重要作用。
- en: The gated recurrent units are responsible for updating hidden representations
    of nodes in message passing. While the edge network aggregates messages from 1-hop
    neighbors of the nodes, the GRU updates the node states with the most recent node
    state resulting from aggregated message based on the previous states [[115](#bib.bib115)],
    therefore, allowing information to travel through connected bonds. The architecture
    also allows preserving information from long ago. Li et al. [[123](#bib.bib123)]
    propose a conformation-aware architecture with GRUs, namely HamNet. With modifications
    in message calculations, the HamNet incorporates relative positions and momentum
    in atom representations generated from GRU.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 门控递归单元负责更新消息传递中节点的隐藏表示。当边缘网络从节点的1-hop邻居中汇聚消息时，GRU使用基于先前状态的汇聚消息结果来更新节点状态，从而允许信息通过连接的键传播。该架构还允许保留久远的信息。Li等人[[123](#bib.bib123)]提出了一种与构象相关的架构，称为HamNet。在消息计算中进行修改后，HamNet结合了GRU生成的原子表示中的相对位置和动量。
- en: The message passing scheme of the GCNs follows that adjacent atoms are in an
    identical chemical environment, i.e., neighborhood should have similar representation.
    Although the deep neural network can capture the local and global structures,
    it may fail to distinguish atoms performing different roles yet having the same
    neighborhoods. Therefore, the topological order usually needs to be introduced
    to the design by leveraging positional encoding techniques [[118](#bib.bib118)],
    or ordered SMILES representation. With an LSTM conducted over the GCN outputs,
    the unique positions for atoms can be determined by controlling the order of atoms
    in the LSTM that coincides with the canonical SMILES [[123](#bib.bib123), [124](#bib.bib124)].
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: GCN的消息传递方案遵循相邻原子处于相同化学环境的原则，即邻域应该具有相似的表示。虽然深度神经网络可以捕捉局部和全局结构，但它可能无法区分在具有相同邻域的情况下执行不同角色的原子。因此，通常需要通过利用位置编码技术[[118](#bib.bib118)]或有序SMILES表示来引入拓扑顺序。通过对GCN输出进行LSTM处理，可以通过控制LSTM中与规范SMILES[[123](#bib.bib123)、[124](#bib.bib124)]一致的原子顺序来确定原子的唯一位置。
- en: Transformer. Multiple prior works have applied transformer-style architecture
    in molecular applications. The expressive power of transformer trained on sequence
    representations, SMILES, and fingerprints has significantly been explored [[45](#bib.bib45),
    [93](#bib.bib93), [95](#bib.bib95)], and the architecture is also adapted to molecular
    graph structures to enhance the representational power. Maziarka et al. [[125](#bib.bib125)]
    introduce a novel pre-trained molecule attention transformer that learns domain-knowledge
    from the pre-text task and then utilizes the knowledge to augment self-attention.
    The key innovation of the proposed model is the replacement of the molecular multi-head
    self-attention layers that integrate the molecule graph and inter-atomic distances
    with the self-attention. Both sources of information extracted from graph structures
    further improve the performance. Rong et al. [[109](#bib.bib109)] follow a similar
    pre-train idea and pay more attention to bi-level information extraction from
    molecule graphs to better preserve the domain knowledge and avoid a negative transfer.
    Dynamic message passing networks are applied to extract local subgraph information
    from node embedding, while transformer modules are introduced respectively for
    nodes and edges to extract global relations of nodes. Transformer-style architecture
    with a dynamic message passing mechanism has an excellent performance in capturing
    structural information and enhances the expressive power of GNN. Future work may
    explore better pre-training tasks for the transformer-style architecture to help
    with various downstream molecular tasks.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer。多个先前的研究在分子应用中应用了transformer风格的架构。训练于序列表示、SMILES和指纹上的transformer的表现力已经得到了显著探索[[45](#bib.bib45),
    [93](#bib.bib93), [95](#bib.bib95)]，该架构也被适配于分子图结构，以增强表征能力。Maziarka等人[[125](#bib.bib125)]提出了一种新颖的预训练分子注意力transformer，该模型从预文本任务中学习领域知识，然后利用这些知识来增强自注意力。该模型的关键创新在于将整合分子图和原子间距的分子多头自注意力层替换为自注意力层。从图结构中提取的两种信息进一步提高了性能。Rong等人[[109](#bib.bib109)]遵循了类似的预训练思路，并更加关注从分子图中提取的双层信息，以更好地保留领域知识并避免负迁移。动态消息传递网络被应用于从节点嵌入中提取局部子图信息，同时分别为节点和边引入transformer模块，以提取节点的全局关系。带有动态消息传递机制的transformer风格架构在捕捉结构信息方面表现出色，并增强了GNN的表现力。未来的工作可能会探索更好的预训练任务，以帮助transformer风格架构在各种下游分子任务中表现更佳。
- en: 5 Retrosynthesis
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 逆合成
- en: '![Refer to caption](img/4fa4e57e3591e7d0bd513e46c805816a.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4fa4e57e3591e7d0bd513e46c805816a.png)'
- en: 'Figure 5: Illustrations of (A) Template-based and (B) Template-free Methods
    in Retrosynthesis and Reaction Prediction.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '图5: （A）基于模板的方法和（B）无模板方法在逆合成和反应预测中的示意图。'
- en: The goal of retrosynthesis is to decompose a complicated target product to find
    a set of reactant molecules with relatively simple structures. It is a fundamental
    task in synthesis planning and drug manufacturing. For example, a common prescription
    drug—aspirin, can be chopped up into two synthons, easily obtained from a nucleophilic
    addition-elimination reaction. However, the enormous potential searching space
    for all possible combinations results in the high cost of computational complexity.
    With the significant development of artificial intelligence, scientists have devoted
    themselves to finding efficient and effective computer-aid methods in retrosynthesis
    analysis.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 逆合成的目标是将一个复杂的目标产品分解，以找到一组具有相对简单结构的反应物分子。这是合成规划和药物制造中的一个基本任务。例如，一种常见的处方药——阿司匹林，可以被分解为两个合成子，这两个合成子可以通过亲核加成-消除反应轻松获得。然而，对于所有可能组合的巨大潜在搜索空间导致了计算复杂度的高成本。随着人工智能的显著发展，科学家们致力于寻找高效有效的计算机辅助逆合成分析方法。
- en: This section analyzes works that apply machine learning methods to solve the
    retrosynthesis prediction. We will introduce some early methods based on reaction
    templates and then analyze the template-free models for each task.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 本节分析了应用机器学习方法解决逆合成预测的问题。我们将介绍一些基于反应模板的早期方法，然后分析每个任务的无模板模型。
- en: 5.1 Template-based
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 基于模板的
- en: 'Template-based methods rely on encoding reaction templates or rules, which
    are generated either manually or automatically from the currently existing databases.
    Those templates are used to derive the retrosynthetic precursors. As there are
    different possible reaction templates for one target molecule, people developed
    various algorithms which consider chemical context, possible trade-offs, and reactivity
    to decide the most appropriate rule (Fig. [5](#S5.F5 "Figure 5 ‣ 5 Retrosynthesis
    ‣ Deep Learning Methods for Small Molecule Drug Discovery: A Survey")A).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 基于模板的方法依赖于编码反应模板或规则，这些模板是从当前存在的数据库中手动或自动生成的。这些模板用于推导逆合成前体。由于一个目标分子可能有不同的反应模板，人们开发了各种算法，这些算法考虑了化学背景、可能的权衡和反应性，以决定最合适的规则（图[5](#S5.F5
    "图 5 ‣ 5 逆合成 ‣ 小分子药物发现的深度学习方法：综述")A）。
- en: String-based. String-based methods convert molecules to fingerprints or SMILES
    and then put them into the network. Segler and Waller [[126](#bib.bib126)] propose
    a neural symbolic model which uses a deep neural network to predict the possible
    reaction template. As the encoding reaction templates are finite, they view retrosynthesis
    analysis as a multi-class classification task. They represent the input target
    molecule as Morgan fingerprint, and the output transformation will be applied
    to the target molecule to get the retrosynthetic precursors. Because similar molecules
    may have similar reactions, Coley et al. [[127](#bib.bib127)] introduce a similarity-based
    approach. This method uses similarity as the metric to determine the precedent
    reactions, which are used to find the appropriate reaction site for the target
    molecule. It then applies the corresponding templates to yield candidate precursors,
    which convert to reaction molecules by further applying similarity calculation.
    Baylon et al. [[128](#bib.bib128)] present a multi-scale approach with a deep
    highway network, which groups reaction rules based on chemical similarities without
    supervision. The model determines the reaction rule in two stages. It first decides
    which group the target molecule belongs to and then predicts the specified transformation
    rules. Segler et al. [[129](#bib.bib129)] view retrosynthesis as a Markov decision
    process. They combine Monte Carlo tree search with different neural networks,
    which guide the search and select the proper retrosynthesis direction. Seidl et
    al. [[130](#bib.bib130)] present a novel approach to single-step retrosynthesis
    modeling using Modern Hopfield Networks. Their template-based model utilizes encoded
    representations of both molecules and reaction templates to accurately predict
    the relevance of templates for a given molecule.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 基于字符串的方法。基于字符串的方法将分子转换为指纹或SMILES，然后将它们输入到网络中。Segler 和 Waller [[126](#bib.bib126)]
    提出了一个神经符号模型，该模型使用深度神经网络来预测可能的反应模板。由于编码的反应模板是有限的，他们将逆合成分析视为一个多类分类任务。他们将输入目标分子表示为Morgan指纹，输出的转换将应用于目标分子，以获得逆合成前体。由于相似的分子可能具有相似的反应，Coley
    等人 [[127](#bib.bib127)] 引入了一种基于相似性的的方法。这种方法使用相似性作为度量来确定先前的反应，这些反应用于寻找目标分子的合适反应位点。然后，它应用相应的模板以生成候选前体，并通过进一步应用相似性计算将其转换为反应分子。Baylon
    等人 [[128](#bib.bib128)] 提出了一个多尺度方法，结合深度高速公路网络，该方法根据化学相似性对反应规则进行分组，而无需监督。该模型在两个阶段确定反应规则。首先，它决定目标分子属于哪个组，然后预测指定的转化规则。Segler
    等人 [[129](#bib.bib129)] 将逆合成视为一个马尔可夫决策过程。他们将蒙特卡洛树搜索与不同的神经网络结合起来，这些网络指导搜索并选择合适的逆合成方向。Seidl
    等人 [[130](#bib.bib130)] 提出了一种使用现代Hopfield网络的单步逆合成建模的新方法。他们的基于模板的模型利用了分子和反应模板的编码表示，以准确预测模板与给定分子的相关性。
- en: Graph-based. Graphical models utilize the expressiveness and scalability of
    neural networks to extract useful information. Dai et al. [[131](#bib.bib131)]
    apply conditional graph logic network, which views chemical templates as logical
    rules. In logical rules, graphical structures of molecules and subgraphs are considered
    as logical variables. The predicted outcome is then formulated as the joint probability
    of the reactants and the rules. Instead of predicting reactants globally, Chen
    et al. [[132](#bib.bib132)] propose LocalRetro, which focuses on local reaction
    templates. Each atom and bond uses a message passing neural network to learn the
    local reactivity and applies several particular layers to learn the remote chemical
    knowledge. Based on the predicted atoms and bonds, local reaction templates are
    then applied to get the final reactants.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的方法。图形模型利用神经网络的表现力和可扩展性来提取有用的信息。戴等人 [[131](#bib.bib131)] 应用了条件图逻辑网络，将化学模板视为逻辑规则。在逻辑规则中，分子和子图的图形结构被视为逻辑变量。然后，将预测结果公式化为反应物和规则的联合概率。陈等人
    [[132](#bib.bib132)] 提出了LocalRetro，而不是全球预测反应物，LocalRetro专注于局部反应模板。每个原子和键使用消息传递神经网络来学习局部反应性，并应用几个特定的层来学习远程化学知识。根据预测的原子和键，然后应用局部反应模板以获得最终的反应物。
- en: 5.2 Template-free
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 无模板
- en: 'As deep learning has developed significantly in recent years, some template-free
    methods based on deep learning strategies have become increasingly popular. Template-free
    methods transform chemical structures from one to others without any reaction
    rules (Fig. [5](#S5.F5 "Figure 5 ‣ 5 Retrosynthesis ‣ Deep Learning Methods for
    Small Molecule Drug Discovery: A Survey")B).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '随着深度学习在近年来的显著发展，一些基于深度学习策略的无模板方法变得越来越受欢迎。无模板方法将化学结构从一种转换为另一种，而不依赖任何反应规则（图 [5](#S5.F5
    "Figure 5 ‣ 5 Retrosynthesis ‣ Deep Learning Methods for Small Molecule Drug Discovery:
    A Survey")B）。'
- en: String-based. As machine translation and retrosynthesis transform the source
    to target languages or molecules, researchers propose various models based on
    such an analogy. Those models utilize SMILES notation to represent molecules as
    strings. Liu et al. [[133](#bib.bib133)] build a LSTM-based sequence-to-sequence
    model, where the inputs are the target molecule and the specific reaction type,
    and the output is the most probable corresponding reactants. The advent of the
    transformer offers exciting opportunities for studying its various applications.
    Karpov et al. [[134](#bib.bib134)] utilize the transformer model and applies weights
    averaging and snapshot learning to complete the task. In order to make the prediction
    more general and diverse, Chen et al. [[135](#bib.bib135)] propose several pre-training
    approaches which generate new examples by randomly disconnecting the bonds or
    following the templates. They also use a mixture model with many latent variables
    to increase the diversity of the possible outcome reactants. Ishiguro et al. [[136](#bib.bib136)]
    further improve seq2seq models by applying the idea of data transfer to retrosynthesis.
    They consider different methods, including joint training, self-training, pre-training,
    and fine-tuning, and evaluate their performance using augmented datasets. Zheng
    et al. [[137](#bib.bib137)] develop a self-corrected retrosynthesis predictor
    which applies the reaction predictor to get raw candidate reactants. It uses another
    transformer that mimics the grammar corrector to fix molecular syntax errors.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 基于字符串的方法。由于机器翻译和逆合成将源语言或分子转换为目标语言或分子，研究人员提出了各种基于这种类比的模型。这些模型利用SMILES符号表示分子为字符串。刘等人
    [[133](#bib.bib133)] 构建了一个基于LSTM的序列到序列模型，其中输入为目标分子和特定的反应类型，输出为最可能的对应反应物。变压器的出现为研究其各种应用提供了激动人心的机会。卡尔波夫等人
    [[134](#bib.bib134)] 利用变压器模型，并应用权重平均和快照学习来完成任务。为了使预测更具通用性和多样性，陈等人 [[135](#bib.bib135)]
    提出了一些预训练方法，这些方法通过随机断开键或遵循模板来生成新示例。他们还使用了一个具有许多潜在变量的混合模型，以增加可能结果反应物的多样性。石黑等人 [[136](#bib.bib136)]
    通过将数据传输的思想应用于逆合成进一步改进了seq2seq模型。他们考虑了不同的方法，包括联合训练、自我训练、预训练和微调，并使用增强数据集评估其性能。郑等人
    [[137](#bib.bib137)] 开发了一种自我修正的逆合成预测器，该预测器应用反应预测器来获取原始候选反应物。它使用另一个模拟语法纠错器的变压器来修正分子语法错误。
- en: Zhao et al. [[138](#bib.bib138)] utilize reaction-aware substructures–which
    will not change during the chemical interactions to predict retrosynthesis transformation.
    Similar to previous works, they utilize a dual transformer encoder structure to
    get a product to candidate reactants mapping. They further isolate the unchanged
    substructure from those candidate reactants based on their fingerprints and use
    a sequence-to-sequence model to predict the output.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Zhao 等人[[138](#bib.bib138)]利用了在化学反应过程中不会改变的反应感知子结构来预测回溯合成转化。与之前的工作类似，他们利用双重变换器编码器结构来获取产品与候选反应物的映射。他们进一步根据指纹从这些候选反应物中隔离出不变的子结构，并使用序列到序列模型来预测输出。
- en: Graph-based. Besides the popularity of sequence models, various graphical models
    are proposed with their unique advantages in the expressiveness of subgraph structures
    and the rapid development of graph neural networks. Sacha et al. [[139](#bib.bib139)]
    present Molecule Edit Graph Attention Network, which views the retrosynthesis
    as a sequence of the graph editing process. The encoder-decoder structure model
    outputs a set of graph actions, including editing and adding atoms, bonds, or
    rings. Those actions are then applied to the target molecule to generate the desired
    reactants. Instead of performing retrosynthesis as a single-step task, G2Gs, proposed
    by Shi et al. [[140](#bib.bib140)], dissembles it into two parts. Their model
    first finds the reaction center by ranking the reactivity scores of atom pairs
    and then chops up the input target molecular graph into several sub-graphs. By
    applying a series of variation graph translations with a latent space for increasing
    diversity, it generates reactant graphs from those synthons. GraphRetro, built
    by Somnath et al. [[141](#bib.bib141)], also utilizes the two-step framework.
    Instead of scoring the atom pairs, GraphRetro ranks both bonds and atoms by a
    message passing network to predict the possible synthons. Unlike G2Gs that directly
    translates graphs to graphs, this model views the process of producing reactants
    from synthons as a classification problem and selects leaving groups from precomputed
    semi-templates to complete synthons. Another model, Semi-Retro [[142](#bib.bib142)],
    further adds local structures of synthons into semi-templates and proposes a directed
    relational graph attention layer for identifying the reaction center.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的。除了序列模型的流行外，还提出了各种图形模型，这些模型在子图结构的表达能力和图神经网络的快速发展方面具有独特的优势。Sacha 等人[[139](#bib.bib139)]提出了分子编辑图注意力网络，该网络将回溯合成视为图编辑过程的序列。编码器-解码器结构模型输出一组图操作，包括编辑和添加原子、键或环。这些操作随后应用于目标分子，以生成所需的反应物。与将回溯合成作为单步任务执行不同，Shi
    等人[[140](#bib.bib140)]提出的G2Gs将其拆分为两部分。他们的模型首先通过对原子对的反应性评分进行排名来找到反应中心，然后将输入的目标分子图切割成多个子图。通过应用一系列变换图翻译以及用于增加多样性的潜在空间，它从这些合成体生成反应物图。Somnath
    等人[[141](#bib.bib141)]构建的GraphRetro也利用了两步框架。与评分原子对不同，GraphRetro通过消息传递网络对键和原子进行排名，以预测可能的合成体。与直接将图转换为图的G2Gs不同，该模型将从合成体生成反应物的过程视为分类问题，并从预计算的半模板中选择离去基团以完成合成体。另一个模型Semi-Retro[[142](#bib.bib142)]进一步将合成体的局部结构添加到半模板中，并提出了一个定向关系图注意力层以识别反应中心。
- en: Combination of Graph and String. In order to incorporate the knowledge from
    both graph representation and sequence representation, some researchers propose
    methods that balance both properties. Like G2Gs, Yan et al. [[143](#bib.bib143)]
    propose RetroXpert, which splits retrosynthesis into two stages. RetroXpert uses
    Edge-enhanced Graph Attention Network to find the reaction centers among bonds,
    and it has an auxiliary task to predict the number of disconnects. In the second
    stage, it converts synthon graph into SMILE notation to apply the sequence model
    to generate the final reactants. Sun et al. [[144](#bib.bib144)] propose an energy-based
    framework for both graphical and sequence models by designing different energy
    functions. Based on the duality of forwarding reaction and retrosynthesis, they
    also develop a dual EBM variant model. By researching the intrinsic connection
    between graph neural network and transformer, Graph Truncated Attention, proposed
    by Seo et al. [[145](#bib.bib145)], adds molecular graph information to the attention
    layers of the transformer, which combines two representations smoothly without
    introducing additional parameters. Alternatively, Retroformer, presented by Wan
    et al. [[146](#bib.bib146)], uses a local attention head, which integrates graphical
    and sequence information, to learn local reactivity and global context simultaneously.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图形和字符串的结合。为了融合图形表示和序列表示的知识，一些研究人员提出了平衡这两种属性的方法。比如G2Gs，Yan等人[[143](#bib.bib143)]提出了RetroXpert，它将逆合成分为两个阶段。RetroXpert使用增强边图注意力网络来找到反应中心，并且具有预测断裂数量的辅助任务。在第二阶段，它将合成图转换为SMILE符号表示，以应用序列模型生成最终的反应物。Sun等人[[144](#bib.bib144)]提出了一种基于能量的框架，用于图形和序列模型，通过设计不同的能量函数。基于正向反应和逆合成的对偶性，他们还开发了一个对偶EBM变体模型。Seo等人[[145](#bib.bib145)]提出的图形截断注意力通过将分子图信息添加到变换器的注意力层，平滑地结合了两种表示，而不引入额外的参数。另一种选择是Wan等人[[146](#bib.bib146)]提出的Retroformer，它使用局部注意力头，整合图形和序列信息，以同时学习局部反应性和全局上下文。
- en: 6 Reaction Prediction
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 反应预测
- en: While the inverse processes of reaction generate massive convenience for the
    chemical industry, the forward synthesis of the organic reaction also raises tremendous
    interest. As another fundamental task in synthesis planning, reaction prediction
    is a task to predict the possible compounds for a given set of reactants, reagents,
    and solvents. Reaction prediction not only assists the evaluation for retrosynthesis
    but also helps with expensive and time-consuming experiments, especially those
    potentially harmful to laboratory technicians.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管反应的逆过程为化学工业带来了极大的便利，化学反应的正向合成也引起了巨大的兴趣。作为合成规划中的另一项基础任务，反应预测旨在预测给定反应物、试剂和溶剂的可能化合物。反应预测不仅有助于逆合成的评估，还能帮助减少昂贵且耗时的实验，尤其是那些对实验室技术人员可能有害的实验。
- en: 6.1 Template-based
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 基于模板
- en: Like retrosynthesis analysis, template-based models for reaction prediction
    are built on reaction templates. As the search spaces for the given reactants
    to generate compounds are pretty big, with substantial computational costs, reaction
    templates can solve this problem by restricting the space. Prediction models use
    different ways to match the appropriate templates and various procedures to decide
    the outcome molecules.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于逆合成分析，基于模板的反应预测模型建立在反应模板之上。由于给定反应物生成化合物的搜索空间非常大，计算成本也很高，反应模板通过限制空间来解决这个问题。预测模型采用不同的方法来匹配适当的模板，并通过各种程序来决定最终的产物分子。
- en: String-based. Some template-based models represent molecules as strings and
    then use string-based models to predict results. Using fingerprints representation
    of reactants and reagents as input, Wei et al. [[147](#bib.bib147)] present a
    model that first explores the application of machine learning in this task. The
    model predicts the possible reaction type as output, but only 16 kinds of reactions
    are considered in their work. By obtaining larger sets of reaction templates,
    more works are proposed. As described in the previous section, the model presented
    by Segler and Waller [[126](#bib.bib126)] can apply to both retrosynthesis analysis
    and reaction prediction. Specifically, their model utilizes neural network to
    process the Morgan fingerprint and uses probability as the criterion to decide
    the most probable reaction rules to apply to the input molecules. Coley et al.
    [[148](#bib.bib148)] also present a synthesis framework that applies all possible
    reaction templates to reactants, in order to generate all possible candidate reactions
    and use softmax layer to score and rank all the candidates.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 基于字符串。一些基于模板的模型将分子表示为字符串，然后使用基于字符串的模型预测结果。以反应物和试剂的指纹表示作为输入，Wei等人[[147](#bib.bib147)]提出了一个模型，该模型首次探索了机器学习在这项任务中的应用。该模型预测可能的反应类型作为输出，但在他们的工作中只考虑了16种反应。通过获取更大范围的反应模板，提出了更多的研究。如前一节所述，Segler和Waller[[126](#bib.bib126)]提出的模型可以应用于逆合成分析和反应预测。具体而言，他们的模型利用神经网络处理Morgan指纹，并使用概率作为标准来决定最可能的反应规则应用于输入分子。Coley等人[[148](#bib.bib148)]还提出了一个合成框架，该框架将所有可能的反应模板应用于反应物，以生成所有可能的候选反应，并使用softmax层对所有候选进行评分和排序。
- en: Graph-based. Unlike Segler and Waller [[126](#bib.bib126)] who use fingerprints
    to constitute the reaction template, Coley et al. [[148](#bib.bib148)] focus on
    the reaction cores as the representation. By formalizing reaction prediction as
    finding missing links between reactant molecules, reaction prediction can also
    be interpreted as predicting the missing nodes and edges for a given chemical
    knowledge graph. Based on such understanding, Segler and Waller [[149](#bib.bib149)]
    build a knowledge graph using millions of existing reactions and molecules from
    the database. Instead of simply constructing molecules as nodes and reactions
    as edges, they construct both molecules and reactions as nodes and assign different
    roles to the edges. The corresponding graph matching algorithms can perform product
    prediction and conditional prediction.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的。与Segler和Waller[[126](#bib.bib126)]使用指纹来构建反应模板不同，Coley等人[[148](#bib.bib148)]关注反应核心作为表示。通过将反应预测形式化为找到反应物分子之间的缺失链接，反应预测也可以解释为预测给定化学知识图谱中的缺失节点和边。在这种理解的基础上，Segler和Waller[[149](#bib.bib149)]使用数据库中的数百万个现有反应和分子构建了一个知识图谱。他们不仅将分子构建为节点，反应构建为边，还将分子和反应都构建为节点，并为边分配不同的角色。相应的图匹配算法可以执行产品预测和条件预测。
- en: 6.2 Template-free
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 无模板
- en: On the other hand, the models without using reaction templates also become prevalent
    in recent years. When researchers perform the task of reaction prediction, they
    often first find the reactivity site and then make the comparison to get the final
    products. Some template-free models mimic this process.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，近年来不使用反应模板的模型也变得越来越普遍。当研究人员执行反应预测任务时，他们通常首先找到反应性位点，然后进行比较以获得最终产品。一些无模板模型模仿了这个过程。
- en: Graph-based Jin et al. [[150](#bib.bib150)] propose a model based on Weisfeiler-Lehman
    Network. It takes a two-step strategy similar to the experts with two separate
    models. The first model is used to find the reaction center by predicting the
    reactivity scores of pairwise atoms. Based on chemical constraints, the bonds
    will be generated for those pairs of atoms, possibly the reaction site. Finally,
    the second model will be applied to rank those candidate products. Later, they
    improve their work [[151](#bib.bib151)] by replacing Weisfeiler-Lehman Network
    with a graph convolution network, then combing reaction center prediction and
    scoring candidate production as one single task. Qian et al. [[152](#bib.bib152)]
    also propose a two-stage model with a graph convolution network but consider things
    like hydrogen counts and formal charges when identifying the reaction site. Specifically,
    they utilize a message passing neural network to get the molecular embedding in
    each atom and use a convolution-based co-estimation network to predict the reaction
    site. Finally, they use integer linear programming to search the production space.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的 Jin 等人[[150](#bib.bib150)] 提出了一个基于 Weisfeiler-Lehman 网络的模型。它采用类似于专家的两步策略，使用两个独立的模型。第一个模型用于通过预测配对原子的反应性得分来找到反应中心。基于化学约束，将为那些可能是反应位点的原子对生成键。最后，第二个模型将应用于对这些候选产物进行排序。后来，他们通过用图卷积网络替换
    Weisfeiler-Lehman 网络来改进他们的工作[[151](#bib.bib151)]，然后将反应中心预测和候选产物评分结合为一个单一任务。Qian
    等人[[152](#bib.bib152)] 也提出了一个两阶段模型，使用图卷积网络，但在识别反应位点时考虑了氢计数和正式电荷等因素。他们具体利用消息传递神经网络获取每个原子的分子嵌入，并使用基于卷积的共同估计网络预测反应位点。最后，他们使用整数线性规划来搜索产物空间。
- en: 'While the above models design in a “human manner” with multi-step, there are
    also end-to-end models. A graph convolution network architecture proposed by Sacha
    et al. [[139](#bib.bib139)] for both reaction prediction and retrosynthesis generates
    the reaction by a sequence of graph edit, which is already discussed in the previous
    section. Focusing on predicting reaction mechanisms instead of the reaction products
    directly, Bradshaw et al. [[153](#bib.bib153)] propose an end-to-end generative
    model called ELECTRO. The reaction with the linear electron flow mechanism is
    then represented as the sequence of electron steps. Combining reinforcement learning
    with graphical models, Do et al. [[154](#bib.bib154)] propose a graph transformation
    policy network, which devotes to tackling the problem using less chemical knowledge.
    There are three parts in this model: a graph neural network used to represent
    the input molecules, including reactants and reagents, a node pair prediction
    network used to output the reaction triples, and a policy network used to generate
    the intermediate molecules. Bi et al.[[155](#bib.bib155)] proposed Non-autoregressive
    Electron Redistribution Framework, which views the change of edge as flowing electrons
    in molecules. Like others, they use graph neural networks to represent the molecule,
    but instead of predicting the generation or breaking of the molecular bonds, they
    predict the flow of electrons.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然上述模型以“人类方式”设计，具有多步骤的特点，但也存在端到端模型。Sacha 等人[[139](#bib.bib139)] 提出的图卷积网络架构用于反应预测和逆合成，通过一系列图编辑生成反应，这在前面的部分已经讨论过。Bradshaw
    等人[[153](#bib.bib153)] 提出了一个名为 ELECTRO 的端到端生成模型，专注于预测反应机制而不是直接预测反应产物。具有线性电子流机制的反应被表示为电子步骤的序列。Do
    等人[[154](#bib.bib154)] 将强化学习与图形模型相结合，提出了一个图变换策略网络，致力于使用更少的化学知识来解决问题。该模型有三个部分：一个图神经网络用于表示输入分子，包括反应物和试剂，一个节点对预测网络用于输出反应三元组，以及一个策略网络用于生成中间分子。Bi
    等人[[155](#bib.bib155)] 提出了非自回归电子重分配框架，该框架将边的变化视为分子中的流动电子。像其他方法一样，他们使用图神经网络来表示分子，但他们预测的是电子的流动，而不是分子键的生成或断裂。
- en: String-based. Besides the various graphical models, those entirely data-driven
    sequence-based models are also well-proposed. Schwaller et al. [[156](#bib.bib156)]
    present a model which views reaction prediction as a translation problem and thus
    applies neural machine translation models. The model consists of two recurrent
    neural networks. The first is used to encode the sequence representation of the
    molecule, and the second is a decoder used to produce the outcome products and
    the corresponding probability. Later, after the advent of the transformer, they
    further developed a multi-head attention molecular transformer model [[2](#bib.bib2)],
    which takes advantage of the attention mechanism.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 基于字符串的方法。除了各种图形模型外，完全数据驱动的基于序列的模型也得到了很好的提出。Schwaller等人[[156](#bib.bib156)]提出了一种将反应预测视为翻译问题的模型，从而应用神经机器翻译模型。该模型由两个递归神经网络组成。第一个用于编码分子的序列表示，第二个是解码器，用于生成产物及其对应的概率。后来，在变换器出现之后，他们进一步开发了一种多头注意力分子变换器模型[[2](#bib.bib2)]，该模型利用了注意力机制。
- en: Template-based methods have their own unique advantages. The process of finding
    possible existing reaction rules is similar to the way chemists complete this
    task. These methods inherently enhance the interpretability of models. The most
    important parts of template-based models are the generation of templates because
    the quality and numbers of reaction templates directly influence the model performance.
    The template generation leads to some problems. Firstly, because those models
    cannot apply the reaction rules or transformations not covered in the template
    library in the test stage, the generalization becomes a huge problem. Secondly,
    some hand-encoding rules and transforms have bias because they are generated from
    a small part of chemists [[147](#bib.bib147)] and thus not that accurate. Besides,
    some early models which use fingerprints as inputs [[126](#bib.bib126), [127](#bib.bib127),
    [128](#bib.bib128), [129](#bib.bib129)] have limitation from the data side. Fingerprints
    do not include much information, especially on the substructures, connectivity
    [[132](#bib.bib132)], and local contexts. In the later stage, the fully data-driven
    template generating algorithms tackle the second problem, but the computational
    source limitation problem still exists. It leads to the restriction on the amounts
    of templates, which further negatively influences the model’s coverage, scalability,
    and diversity. As Schwaller et al. [[2](#bib.bib2)] point out in their article,
    those auto-generating algorithms have flaws logically. Those template extracting
    algorithms are based on atom mapping, which comes from a template library. This
    creates a logical ring and is thus not that credible and accurate.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 基于模板的方法具有其独特的优势。寻找可能存在的反应规则的过程类似于化学家完成这一任务的方式。这些方法本质上增强了模型的可解释性。基于模板模型中最重要的部分是模板的生成，因为反应模板的质量和数量直接影响模型的表现。模板生成会带来一些问题。首先，由于这些模型在测试阶段无法应用模板库中未覆盖的反应规则或转换，一般化成为一个巨大问题。其次，一些手工编码的规则和转换存在偏差，因为它们是从少量化学家[[147](#bib.bib147)]那里生成的，因此不够准确。此外，一些早期使用指纹作为输入的模型[[126](#bib.bib126),
    [127](#bib.bib127), [128](#bib.bib128), [129](#bib.bib129)]存在数据方面的局限性。指纹不包含太多信息，特别是在子结构、连接性[[132](#bib.bib132)]和局部背景上。在后期，完全数据驱动的模板生成算法解决了第二个问题，但计算资源限制问题仍然存在。这导致了模板数量的限制，进一步对模型的覆盖范围、可扩展性和多样性产生负面影响。正如Schwaller等人[[2](#bib.bib2)]在他们的文章中指出的，那些自动生成算法在逻辑上存在缺陷。这些模板提取算法基于原子映射，源自模板库。这创造了一个逻辑上的环，因此不够可靠和准确。
- en: On the other hand, template-free models overcome the drawbacks mentioned above.
    Graphical models use graph representation, and it has excellent advantages in
    interpretability. As the atoms and bonds can be directly converted to nodes and
    edges, those graphs and subgraphs are explainable chemically. By using graph neural
    network, the local information can be aggregated to each node and edge. As graph
    neural network learns task-specific embeddings, for both retrosynthesis and reaction
    prediction, many graph-based models take two-stage strategies. By modifying the
    layers and focusing on latent spaces, some models like Chen et al. [[136](#bib.bib136)]
    also enhance the diversity of the models. Although graphical models have promising
    outcomes, wonderful interpretability, and scalability, they require atom-mapped
    datasets in the training stage [[147](#bib.bib147)]. Similar to the problems for
    template-based models, they implicitly use pre-defined reaction templates and
    thus maybe not be as credible as ground truth. Sequence-based models utilize the
    advantages of transformer and perform well on those tasks; however, it lacks interpretability
    because the string can hardly expose the local information for the three-dimensional
    structured molecules. The integration of sequence-based models containing graphical
    structures as input information [[141](#bib.bib141), [142](#bib.bib142), [143](#bib.bib143),
    [144](#bib.bib144)] take advantage of both sides, but it still can not bypass
    the drawbacks of atom-mapped datasets.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，无模板模型克服了上述提到的缺陷。图形模型使用图形表示，它在可解释性方面具有出色的优势。由于原子和化学键可以直接转换为节点和边，这些图形和子图在化学上是可以解释的。通过使用图神经网络，局部信息可以聚合到每个节点和边上。由于图神经网络学习任务特定的嵌入，对于反合成和反应预测，许多基于图形的模型采用了两阶段策略。通过修改层级并专注于潜在空间，一些模型如陈等人[[136](#bib.bib136)]也增强了模型的多样性。尽管图形模型具有良好的结果、出色的可解释性和可扩展性，但它们在训练阶段需要原子映射的数据集[[147](#bib.bib147)]。与基于模板的模型的问题类似，它们隐式使用预定义的反应模板，因此可能不如真实数据可靠。基于序列的模型利用了变换器的优势，并在这些任务上表现良好；然而，它缺乏可解释性，因为字符串难以揭示三维结构分子的局部信息。将包含图形结构的序列模型作为输入信息[[141](#bib.bib141),
    [142](#bib.bib142), [143](#bib.bib143), [144](#bib.bib144)]结合了双方的优点，但仍然无法绕过原子映射数据集的缺点。
- en: 7 Datasets and Benchmarks
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 数据集和基准
- en: 7.1 Datasets
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 数据集
- en: PubChem. PubChem [[157](#bib.bib157)] is an open chemistry database at the National
    Institutes of Health (NIH). Most samples in the database are small molecules,
    but large molecules such as nucleotides, carbohydrates, lipids, peptides, and
    chemically-modified macromolecules also exist. The information and annotations
    of molecules include chemical structures, identifiers, chemical and physical properties,
    biological activities, patents, health, safety, toxicity data, and many others.
    PubChem contains 93.9 million entries for compounds (54 million in September 2014),
    including pure and characterized compounds; 236 million entries for molecules
    (163 million in September 2014), and also mixtures, extracts, complexes, and uncharacterized
    substances.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: PubChem。PubChem [[157](#bib.bib157)] 是国家卫生研究院（NIH）提供的一个开放化学数据库。数据库中的大多数样本是小分子，但也存在核苷酸、碳水化合物、脂质、肽和化学修饰的大分子。分子的相关信息和注释包括化学结构、标识符、化学和物理性质、生物活性、专利、健康、安全、毒性数据等。PubChem包含93.9百万条化合物条目（2014年9月为54百万），包括纯化合物和已表征化合物；236百万条分子条目（2014年9月为163百万），以及混合物、提取物、复合物和未表征物质。
- en: ChEMBL. ChEMBL [[158](#bib.bib158)] is a manually curated database of bioactive
    molecules with drug-like properties. It brings together chemical, bioactivity
    and genomic data to aid the translation of genomic information into effective
    new drugs. It contains 14,885 targets and 2,157,379 distinct compounds by February
    2022\. The annotation of ChEMBL mainly includes the positive and negative effects
    of the compounds on the corresponding targets.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ChEMBL。ChEMBL [[158](#bib.bib158)] 是一个手动整理的具有药物性质的生物活性分子数据库。它汇集了化学、生物活性和基因组数据，以帮助将基因组信息转化为有效的新药。截至2022年2月，它包含14,885个靶点和2,157,379种不同的化合物。ChEMBL的注释主要包括化合物对相应靶点的正面和负面效果。
- en: ZINC. ZINC [[159](#bib.bib159)] is a free database of commercially-available
    compounds for virtual screening. ZINC contains over 230 million purchasable compounds
    in ready-to-dock, 3D formats and over 750 million purchasable compounds.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ZINC。ZINC [[159](#bib.bib159)] 是一个用于虚拟筛选的免费商业化合物数据库。ZINC 包含超过 2.3 亿种可购买的化合物，格式为准备对接的
    3D 形式，以及超过 7.5 亿种可购买的化合物。
- en: GDB. GDB [[160](#bib.bib160)] is the largest publicly available small organic
    molecule database. GDB dataset is a collection of SMILES strings, GDB-11 [[161](#bib.bib161)]
    has 100 million molecules, GDB-13 [[162](#bib.bib162)] has 1 billion molecules,
    and GDB-17 [[163](#bib.bib163)] has 160 billion molecules. The number in the postscript
    indicates the maximum number of atoms in the molecule in the dataset.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: GDB。GDB [[160](#bib.bib160)] 是最大公开可用的小有机分子数据库。GDB 数据集是 SMILES 字符串的集合，GDB-11
    [[161](#bib.bib161)] 有 1 亿个分子，GDB-13 [[162](#bib.bib162)] 有 10 亿个分子，GDB-17 [[163](#bib.bib163)]
    有 1600 亿个分子。后缀中的数字表示数据集中分子的最大原子数。
- en: 'QM9. QM9 [[104](#bib.bib104)] is a benchmark dataset that contains 134K stable
    organic molecules. QM9 records geometric, energetic, electronic, and thermodynamic
    properties. GEOM-QM9 is a subset of QM9, including 3D geometry structures with
    small molecular mass and few rotatable bonds. All molecules are modeled based
    on DFT methods, and same for the calculated quantum mechanical properties. Descriptions
    of recorded properties are described in TABLE [1](#S7.T1 "Table 1 ‣ 7.1 Datasets
    ‣ 7 Datasets and Benchmarks ‣ Deep Learning Methods for Small Molecule Drug Discovery:
    A Survey").'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 'QM9。QM9 [[104](#bib.bib104)] 是一个基准数据集，包含 134K 稳定的有机分子。QM9 记录了几何、能量、电子和热力学性质。GEOM-QM9
    是 QM9 的一个子集，包括具有小分子质量和少量可旋转键的 3D 几何结构。所有分子均基于 DFT 方法建模，计算的量子力学性质也相同。记录的性质描述见表
    TABLE [1](#S7.T1 "Table 1 ‣ 7.1 Datasets ‣ 7 Datasets and Benchmarks ‣ Deep Learning
    Methods for Small Molecule Drug Discovery: A Survey")。'
- en: 'Table 1: Description of properties in QM9 dataset'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：QM9 数据集中的性质描述
- en: '| Properties | Description |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| Properties | 描述 |'
- en: '| $U_{0}$ | Internal energy at 0K |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| $U_{0}$ | 0K 时的内能 |'
- en: '| $U$ | Internal energy at 298.15K |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| $U$ | 298.15K 时的内能 |'
- en: '| $G$ | Free energy at 298.15K |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| $G$ | 298.15K 时的自由能 |'
- en: '| $H$ | Enthalpy at 298.15K |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| $H$ | 298.15K 时的焓 |'
- en: '| $C_{v}$ | Heat capacity at 298.15K |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| $C_{v}$ | 298.15K 时的热容量 |'
- en: '| $\epsilon_{HOMO}(HOMO)$ | Energy of HOMO |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| $\epsilon_{HOMO}(HOMO)$ | HOMO 的能量 |'
- en: '| $\epsilon_{LUMO}(LUMO)$ | Energy of LUMO |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| $\epsilon_{LUMO}(LUMO)$ | LUMO 的能量 |'
- en: '| $\epsilon_{gap}(gap)$ | Gap ($\epsilon_{LUMO}-\epsilon_{HOMO}$) |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| $\epsilon_{gap}(gap)$ | Gap ($\epsilon_{LUMO}-\epsilon_{HOMO}$) |'
- en: '| ZPVE | Zero point vibrational energy |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| ZPVE | 零点振动能量 |'
- en: '| $<R^{2}>$ | Electronic spatial extent |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| $<R^{2}>$ | 电子空间范围 |'
- en: '| $\mu$ | Dipole moment |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| $\mu$ | 偶极矩 |'
- en: '| $\alpha$ | Isotropic polarizability |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| $\alpha$ | 各向同性极化率 |'
- en: GEOM-Drugs. GEOM-Drugs [[164](#bib.bib164)] is a dataset that provides 3D molecular
    geometries for larger drug molecules, up to a maximum of 181 atoms (91 heavy atoms).
    It also contains multiple conformations for each molecule, with a larger structure
    variance.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: GEOM-Drugs。GEOM-Drugs [[164](#bib.bib164)] 是一个提供较大药物分子 3D 分子几何结构的数据集，最多可达 181
    个原子（91 个重原子）。它还包含每个分子的多个构象，具有较大的结构变化。
- en: USPTO. USPTO [[165](#bib.bib165)] is an open-source chemical reaction database
    and contains about 3.7 million reactions. The most popular datasets for reaction
    and retrosynthesis prediction are from USPTO. The frequently used dataset includes
    USPTO-50K (contains 50k reactions), USPTO-MIT, USPTO-15k (contains 50k reactions),
    and USPTO-FULL (contains 1M reactions). Among all of these datasets, the most
    commonly used one is USPTO-50K. It randomly picks 50000 reactions from US patents,
    and all reactions are assigned to a specific reaction type. For single-step retrosynthesis,
    USPTO-50K often serves as a benchmark. However, the distribution of the reaction
    classes is not that uniform, and some patented syntheses are not validated by
    experiments and thus may have flaws.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: USPTO。USPTO [[165](#bib.bib165)] 是一个开源化学反应数据库，包含约 370 万个反应。最受欢迎的反应和逆合成预测数据集来自
    USPTO。常用的数据集包括 USPTO-50K（包含 50k 个反应）、USPTO-MIT、USPTO-15k（包含 50k 个反应）和 USPTO-FULL（包含
    1M 个反应）。在这些数据集中，最常用的是 USPTO-50K。它从美国专利中随机选取 50000 个反应，并且所有反应都被分配到特定的反应类型。对于单步逆合成，USPTO-50K
    通常作为基准。然而，反应类别的分布并不均匀，一些专利合成未通过实验验证，因此可能存在缺陷。
- en: Reaxys. Reaxys [[165](#bib.bib165)] is a database used by scholars who focus
    on reaction prediction. It has the world’s largest physical and chemical properties,
    factual reaction database and pharmaceutical chemistry database. This database
    has 253M substances, 58M reactions, 96M documents, 32M patents, and 42M bioactivities.
    Despite the rich contents, large scale, and long history of Reaxys, in order to
    extract useful information from the database and then apply it to the models,
    researchers need additional efforts in pre-processing (filter) the data.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Reaxys。Reaxys [[165](#bib.bib165)] 是一个供专注于反应预测的学者使用的数据库。它拥有全球最大的物理和化学性质、实际反应数据库以及药物化学数据库。该数据库包含253M种物质、58M个反应、96M份文献、32M项专利和42M项生物活性。尽管Reaxys内容丰富、规模庞大且历史悠久，但为了从数据库中提取有用信息并应用于模型，研究人员在数据预处理（筛选）上需要额外的努力。
- en: MoleculeNet. MoleculeNet [[166](#bib.bib166)] is a data collection specifically
    designed for evaluating molecular prediction models. The dataset collection includes
    over 700,000 compounds of various properties, mainly in four categories, quantum
    mechanics, physical chemistry, biophysics, and physiology. The first two collections
    are used to test as regression tasks, while the latter two are for classification
    ones. Quantum mechanics are information on electronic properties determined by
    DFT-based methods. ESOL, FreeSolv, and Lipophilicity in the physical chemistry
    category respectively include data of solubility, hydration free energy, and distribution
    coefficient in water. Physiology collection, including drug-related and toxicology
    data, with Biophysics collection composed of data of biological properties such
    as binding affinities and measured biological activities, are the most frequently
    used datasets for model evaluation in property prediction in the articles above.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: MoleculeNet。MoleculeNet [[166](#bib.bib166)] 是一个专门用于评估分子预测模型的数据集合。数据集包括超过700,000种具有各种属性的化合物，主要分为四类：量子力学、物理化学、生物物理学和生理学。前两类用于回归任务测试，而后两类则用于分类任务。量子力学类是通过DFT方法确定的电子性质信息。物理化学类中的ESOL、FreeSolv和Lipophilicity分别包含溶解度、溶剂化自由能和水中分布系数的数据。生理学集合包括与药物相关和毒理学的数据，而生物物理学集合则由如结合亲和力和测量生物活性等生物属性数据组成，是上述文章中用于属性预测模型评估的最常用数据集。
- en: ExcapeDB. ExcapeDB [[167](#bib.bib167)] is a comprehensive dataset that integrates
    active and inactive compounds from PubChem and ChEMBL. It serves as a data hub,
    providing researchers worldwide with convenient access to a standardized chemogenomics
    dataset, with the data and accompanying software available under open licenses.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ExcapeDB。ExcapeDB [[167](#bib.bib167)] 是一个综合数据集，整合了来自PubChem和ChEMBL的活性和非活性化合物。它作为数据中心，为全球研究人员提供标准化化学基因组数据集的便捷访问，数据和附带的软件都可以在开放许可证下获取。
- en: LSC. LSC [[85](#bib.bib85)] is a large benchmark dataset assembled from the
    ChEMBL database, enabling accurate evaluation of machine learning methods for
    compound target prediction. With over 500,000 compounds and more than 1,000 assays,
    the dataset represents a diverse array of target classes, including enzymes, ion
    channels, and receptors.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: LSC。LSC [[85](#bib.bib85)] 是一个从ChEMBL数据库汇编的大型基准数据集，能够准确评估用于化合物靶点预测的机器学习方法。该数据集包含超过500,000种化合物和1000多个测定，代表了各种靶点类别，包括酶、离子通道和受体。
- en: 7.2 Evaluation Metrics
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 评估指标
- en: There are multiple evaluation metrics for molecule generation. Novelty illustrates
    the percentage of generated molecules dissimilar to molecules in the training
    set [[168](#bib.bib168)]. Diversity is calculated based on pairwise Tanimoto similarity,
    which measures the diversity of generated molecules. Property score is the average
    score of the top 100 molecules. The success rate is the percentage of generated
    molecules that satisfy all objective functions [[49](#bib.bib49)]. For the 3D
    molecule generation problem, generated and reference molecule sets are used for
    evaluation. Coverage (COV) score [[82](#bib.bib82)] measures the percentage of
    molecule conformations in one set covered by another. Matching (MAT) score measures
    the distance of the closest neighbor between two sets. “-P” and “-R” means precision
    metric and recall metric, respectively.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 评估分子生成的指标有多个。新颖性表示生成的分子与训练集中分子的不同百分比[[168](#bib.bib168)]。多样性是基于对分子对的Tanimoto相似性计算的，衡量生成分子的多样性。属性分数是前100个分子的平均分数。成功率是生成的分子中满足所有目标函数的百分比[[49](#bib.bib49)]。对于3D分子生成问题，使用生成的分子和参考分子集进行评估。覆盖度（COV）分数[[82](#bib.bib82)]测量一个集合中由另一个集合覆盖的分子构象的百分比。匹配（MAT）分数测量两个集合之间最近邻的距离。“-P”和“-R”分别表示精确度指标和召回率指标。
- en: Mean-absolute error (MAE), root-mean-square error (RMSE), and ROC-AUC scores
    are the most commonly used evaluation metrics for molecular property prediction.
    Performance is measured on either classification or regression tasks, in which
    QM datasets and datasets from MoleculeNet [[166](#bib.bib166)] are commonly used
    for evaluation. If property prediction is regarded as a classification task, which
    is often the case, models are evaluated on a set of given labels after training.
    Regression tasks for molecular property prediction are more demanding than the
    classification ones, requiring a competitive model to predict the exact numeric
    values of molecular properties [[111](#bib.bib111)]. Supervised models are commonly
    introduced in the evaluation process as baselines.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 平均绝对误差（MAE）、均方根误差（RMSE）和ROC-AUC分数是分子属性预测中最常用的评估指标。性能可以在分类或回归任务中进行测量，其中QM数据集和来自MoleculeNet的数据集[[166](#bib.bib166)]常用于评估。如果将属性预测视为分类任务（这通常是情况），则在训练后在一组给定标签上评估模型。对于分子属性预测，回归任务比分类任务更具挑战性，需要一个具有竞争力的模型来预测分子属性的精确数值[[111](#bib.bib111)]。监督模型通常在评估过程中作为基准引入。
- en: 'Table 2: Datasets and Evaluation Metrics for Selected Models'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：选定模型的数据集和评估指标
- en: '| Task and Dataset | Model | Year | Evaluation Metrics |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 任务和数据集 | 模型 | 年份 | 评估指标 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 2D Molecule Generation |  |  | Diversity ↑ | Property Score ↑ | Success Rate
    ↑ |  |  |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 2D分子生成 |  |  | 多样性 ↑ | 属性分数 ↑ | 成功率 ↑ |  |  |'
- en: '| ZINC | GCPN [[62](#bib.bib62)] | 2018 | 0.596 | 0.450 | - |  |  |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| ZINC | GCPN [[62](#bib.bib62)] | 2018 | 0.596 | 0.450 | - |  |  |'
- en: '|  | MolDQN [[69](#bib.bib69)] | 2019 | 0.597 | 0.365 | - |  |  |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|  | MolDQN [[69](#bib.bib69)] | 2019 | 0.597 | 0.365 | - |  |  |'
- en: '|  | LSTM [[50](#bib.bib50)] | 2019 | 0.706 | 0.672 | - |  |  |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '|  | LSTM [[50](#bib.bib50)] | 2019 | 0.706 | 0.672 | - |  |  |'
- en: '|  | BOSS [[58](#bib.bib58)] | 2020 | 0.561 | 0.504 | - |  |  |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '|  | BOSS [[58](#bib.bib58)] | 2020 | 0.561 | 0.504 | - |  |  |'
- en: '|  | ChemBO [[71](#bib.bib71)] | 2020 | 0.701 | 0.648 | - |  |  |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|  | ChemBO [[71](#bib.bib71)] | 2020 | 0.701 | 0.648 | - |  |  |'
- en: '|  | DST [[68](#bib.bib68)] | 2022 | 0.755 | 0.752 | - |  |  |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '|  | DST [[68](#bib.bib68)] | 2022 | 0.755 | 0.752 | - |  |  |'
- en: '| ChEMBL | REINVENT [[49](#bib.bib49)] | 2017 | 0.666 | - | 46.6% |  |  |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| ChEMBL | REINVENT [[49](#bib.bib49)] | 2017 | 0.666 | - | 46.6% |  |  |'
- en: '|  | JT-VAE [[43](#bib.bib43)] | 2018 | 0.277 | - | 5.4% |  |  |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '|  | JT-VAE [[43](#bib.bib43)] | 2018 | 0.277 | - | 5.4% |  |  |'
- en: '|  | GA+D [[57](#bib.bib57)] | 2019 | 0.363 | - | 85.7% |  |  |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '|  | GA+D [[57](#bib.bib57)] | 2019 | 0.363 | - | 85.7% |  |  |'
- en: '|  | RationaleRL [[64](#bib.bib64)] | 2020 | 0.706 | - | 75.0% |  |  |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '|  | RationaleRL [[64](#bib.bib64)] | 2020 | 0.706 | - | 75.0% |  |  |'
- en: '|  | MARS [[66](#bib.bib66)] | 2021 | 0.719 | - | 92.3% |  |  |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '|  | MARS [[66](#bib.bib66)] | 2021 | 0.719 | - | 92.3% |  |  |'
- en: '|  | MolEvol [[65](#bib.bib65)] | 2021 | 0.681 | - | 93.0% |  |  |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '|  | MolEvol [[65](#bib.bib65)] | 2021 | 0.681 | - | 93.0% |  |  |'
- en: '| 3D Molecule Generation |  |  | COV-R (%) ↑ | MAT-R (Å) ↓ | COV-P (%) ↑ |
    MAT-P (%) ↓ |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 3D分子生成 |  |  | COV-R (%) ↑ | MAT-R (Å) ↓ | COV-P (%) ↑ | MAT-P (%) ↓ |'
- en: '|  |  | Mean | Median | Mean | Median | Mean | Median | Mean | Median |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 平均 | 中位数 | 平均 | 中位数 | 平均 | 中位数 | 平均 | 中位数 |'
- en: '| GEOM-Drugs | CVGAE [[80](#bib.bib80)] | 2019 | 0.00 | 0.00 | 3.0702 | 2.9937
    | - | - | - | - |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| GEOM-Drugs | CVGAE [[80](#bib.bib80)] | 2019 | 0.00 | 0.00 | 3.0702 | 2.9937
    | - | - | - | - |'
- en: '|  | GRAPHDG [[74](#bib.bib74)] | 2020 | 8.27 | 0.00 | 1.9722 | 1.9845 | 2.08
    | 0.00 | 2.4340 | 2.4100 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '|  | GRAPHDG [[74](#bib.bib74)] | 2020 | 8.27 | 0.00 | 1.9722 | 1.9845 | 2.08
    | 0.00 | 2.4340 | 2.4100 |'
- en: '|  | CGCF [[82](#bib.bib82)] | 2021 | 53.96 | 57.06 | 1.2487 | 1.2247 | 21.68
    | 13.72 | 1.8571 | 1.8066 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '|  | CGCF [[82](#bib.bib82)] | 2021 | 53.96 | 57.06 | 1.2487 | 1.2247 | 21.68
    | 13.72 | 1.8571 | 1.8066 |'
- en: '|  | CONFVAE [[75](#bib.bib75)] | 2021 | 55.20 | 59.43 | 1.2380 | 1.1417 |
    22.96 | 14.05 | 1.8287 | 1.8159 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '|  | CONFVAE [[75](#bib.bib75)] | 2021 | 55.20 | 59.43 | 1.2380 | 1.1417 |
    22.96 | 14.05 | 1.8287 | 1.8159 |'
- en: '|  | CONFGF [[76](#bib.bib76)] | 2021 | 62.15 | 70.93 | 1.1629 | 1.1596 | 23.42
    | 15.52 | 1.7219 | 1.6863 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '|  | CONFGF [[76](#bib.bib76)] | 2021 | 62.15 | 70.93 | 1.1629 | 1.1596 | 23.42
    | 15.52 | 1.7219 | 1.6863 |'
- en: '|  | GEOMOL [[77](#bib.bib77)] | 2022 | 67.16 | 71.71 | 1.0875 | 1.0586 | -
    | - | - | - |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '|  | GEOMOL [[77](#bib.bib77)] | 2022 | 67.16 | 71.71 | 1.0875 | 1.0586 | -
    | - | - | - |'
- en: '|  | GEODIFF [[78](#bib.bib78)] | 2022 | 89.13 | 97.88 | 0.8629 | 0.8529 |
    61.47 | 64.55 | 1.1712 | 1.1232 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|  | GEODIFF [[78](#bib.bib78)] | 2022 | 89.13 | 97.88 | 0.8629 | 0.8529 |
    61.47 | 64.55 | 1.1712 | 1.1232 |'
- en: '| GEOM-QM9 | CVGAE [[80](#bib.bib80)] | 2019 | 0.09 | 0.00 | 1.6713 | 1.6088
    | - | - | - | - |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| GEOM-QM9 | CVGAE [[80](#bib.bib80)] | 2019 | 0.09 | 0.00 | 1.6713 | 1.6088
    | - | - | - | - |'
- en: '|  | GRAPHDG [[74](#bib.bib74)] | 2020 | 3.33 | 84.21 | 0.4245 | 0.3973 | 43.90
    | 35.33 | 0.5809 | 0.5823 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|  | GRAPHDG [[74](#bib.bib74)] | 2020 | 3.33 | 84.21 | 0.4245 | 0.3973 | 43.90
    | 35.33 | 0.5809 | 0.5823 |'
- en: '|  | CGCF [[82](#bib.bib82)] | 2021 | 78.05 | 82.48 | 0.4219 | 0.3900 | 36.49
    | 33.57 | 0.6615 | 0.6427 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '|  | CGCF [[82](#bib.bib82)] | 2021 | 78.05 | 82.48 | 0.4219 | 0.3900 | 36.49
    | 33.57 | 0.6615 | 0.6427 |'
- en: '|  | CONFVAE [[75](#bib.bib75)] | 2021 | 77.84 | 88.20 | 0.4154 | 0.3739 |
    38.02 | 34.67 | 0.6215 | 0.6091 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '|  | CONFVAE [[75](#bib.bib75)] | 2021 | 77.84 | 88.20 | 0.4154 | 0.3739 |
    38.02 | 34.67 | 0.6215 | 0.6091 |'
- en: '|  | GEOMOL [[77](#bib.bib77)] | 2022 | 71.26 | 72.00 | 0.3731 | 0.3731 | -
    | - | - | - |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '|  | GEOMOL [[77](#bib.bib77)] | 2022 | 71.26 | 72.00 | 0.3731 | 0.3731 | -
    | - | - | - |'
- en: '|  | CONFGF [[76](#bib.bib76)] | 2021 | 88.49 | 94.31 | 0.2673 | 0.2685 | 46.43
    | 43.41 | 0.5224 | 0.5124 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '|  | CONFGF [[76](#bib.bib76)] | 2021 | 88.49 | 94.31 | 0.2673 | 0.2685 | 46.43
    | 43.41 | 0.5224 | 0.5124 |'
- en: '|  | GEODIFF [[78](#bib.bib78)] | 2022 | 90.07 | 93.39 | 0.2090 | 0.1988 |
    52.79 | 50.29 | 0.4448 | 0.4267 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '|  | GEODIFF [[78](#bib.bib78)] | 2022 | 90.07 | 93.39 | 0.2090 | 0.1988 |
    52.79 | 50.29 | 0.4448 | 0.4267 |'
- en: '| Retrosynthesis Prediction |  |  | Accuracies (%) ↑ |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| Retrosynthesis Prediction |  |  | 准确率 (%) ↑ |'
- en: '|  |  | Top-1 | Top-3 | Top-5 | Top-10 |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '|  |  | Top-1 | Top-3 | Top-5 | Top-10 |'
- en: '| USPTO-50k | SCROP [[137](#bib.bib137)] | 2019 | 59.0 | 74.8 | 78.1 | 81.1
    |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| USPTO-50k | SCROP [[137](#bib.bib137)] | 2019 | 59.0 | 74.8 | 78.1 | 81.1
    |'
- en: '|  | GLN [[131](#bib.bib131)] | 2019 | 63.2 | 77.5 | 83.4 | 89.1 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '|  | GLN [[131](#bib.bib131)] | 2019 | 63.2 | 77.5 | 83.4 | 89.1 |'
- en: '|  | G2Gs [[140](#bib.bib140)] | 2020 | 61.0 | 81.3 | 86.0 | 88.7 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '|  | G2Gs [[140](#bib.bib140)] | 2020 | 61.0 | 81.3 | 86.0 | 88.7 |'
- en: '|  | RetroXpert [[143](#bib.bib143)] | 2020 | 70.4 | 83.4 | 85.3 | 86.8 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '|  | RetroXpert [[143](#bib.bib143)] | 2020 | 70.4 | 83.4 | 85.3 | 86.8 |'
- en: '|  | Dual [[144](#bib.bib144)] | 2020 | 65.7 | 81.9 | 84.7 | 85.9 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '|  | Dual [[144](#bib.bib144)] | 2020 | 65.7 | 81.9 | 84.7 | 85.9 |'
- en: '|  | MEGAN [[139](#bib.bib139)] | 2021 | 60.7 | 82.0 | 87.5 | 91.6 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '|  | MEGAN [[139](#bib.bib139)] | 2021 | 60.7 | 82.0 | 87.5 | 91.6 |'
- en: '|  | GraphRetro [[141](#bib.bib141)] | 2021 | 63.9 | 81.5 | 85.2 | 88.1 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '|  | GraphRetro [[141](#bib.bib141)] | 2021 | 63.9 | 81.5 | 85.2 | 88.1 |'
- en: '|  | LocalRetro [[132](#bib.bib132)] | 2021 | 63.9 | 86.8 | 92.4 | 96.3 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  | LocalRetro [[132](#bib.bib132)] | 2021 | 63.9 | 86.8 | 92.4 | 96.3 |'
- en: '|  | Retroformer [[146](#bib.bib146)] | 2022 | 64.0 | 82.5 | 86.7 | 90.2 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '|  | Retroformer [[146](#bib.bib146)] | 2022 | 64.0 | 82.5 | 86.7 | 90.2 |'
- en: '| USPTO-full | RetroSim [[127](#bib.bib127)] | 2017 | 32.8 | - | - | 56.1 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| USPTO-full | RetroSim [[127](#bib.bib127)] | 2017 | 32.8 | - | - | 56.1 |'
- en: '|  | MEGAN [[139](#bib.bib139)] | 2021 | 33.6 | - | - | 63.9 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '|  | MEGAN [[139](#bib.bib139)] | 2021 | 33.6 | - | - | 63.9 |'
- en: '|  | GLN [[131](#bib.bib131)] | 2019 | 39.3 | - | - | 63.7 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '|  | GLN [[131](#bib.bib131)] | 2019 | 39.3 | - | - | 63.7 |'
- en: '|  | GTA [[145](#bib.bib145)] | 2021 | 46.6 | - | - | 70.4 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '|  | GTA [[145](#bib.bib145)] | 2021 | 46.6 | - | - | 70.4 |'
- en: '|  | Reaction-Aware [[138](#bib.bib138)] | 2022 | 51.6 | - | - | 70.7 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '|  | Reaction-Aware [[138](#bib.bib138)] | 2022 | 51.6 | - | - | 70.7 |'
- en: '| Reaction Prediction |  |  | Coverages (%) ↑ |  | Accuracies (%) ↑ |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| Reaction Prediction |  |  | 覆盖率 (%) ↑ |  | 准确率 (%) ↑ |'
- en: '|  |  | C@6 | C@8 | C@10 |  | Top-1 | Top-2 | Top-3 | Top-5 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '|  |  | C@6 | C@8 | C@10 |  | Top-1 | Top-2 | Top-3 | Top-5 |'
- en: '| USPTO-15k | WLDN [[150](#bib.bib150)] | 2017 | 81.6 | 86.1 | 89.1 |  | -
    | - | - | - |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| USPTO-15k | WLDN [[150](#bib.bib150)] | 2017 | 81.6 | 86.1 | 89.1 |  | -
    | - | - | - |'
- en: '|  | GTPN [[154](#bib.bib154)] | 2019 | 88.9 | 92.0 | 93.6 |  | - | - | - |
    - |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '|  | GTPN [[154](#bib.bib154)] | 2019 | 88.9 | 92.0 | 93.6 |  | - | - | - |
    - |'
- en: '| USPTO-MIT | WLDN [[150](#bib.bib150)] | 2017 | - | - | - |  | 79.6 | - |
    87.7 | 89.2 |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| USPTO-MIT | WLDN [[150](#bib.bib150)] | 2017 | - | - | - |  | 79.6 | - |
    87.7 | 89.2 |'
- en: '|  | GTPN [[154](#bib.bib154)] | 2019 | - | - | - |  | 83.2 | - | 86.0 | 86.5
    |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '|  | GTPN [[154](#bib.bib154)] | 2019 | - | - | - |  | 83.2 | - | 86.0 | 86.5
    |'
- en: '|  | Molecular Transformer[[2](#bib.bib2)] | 2019 | - | - | - |  | 90.4 | 93.7
    | 94.6 | 95.3 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '|  | Molecular Transformer [[2](#bib.bib2)] | 2019 | - | - | - |  | 90.4 |
    93.7 | 94.6 | 95.3 |'
- en: '|  | MEGAN [[139](#bib.bib139)] | 2021 | - | - | - |  | 89.3 | 92.7 | 94.4
    | 95.6 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|  | MEGAN [[139](#bib.bib139)] | 2021 | - | - | - |  | 89.3 | 92.7 | 94.4
    | 95.6 |'
- en: '|  | NERF [[155](#bib.bib155)] | 2021 | - | - | - |  | 90.7 | 92.3 | 93.3 |
    93.7 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '|  | NERF [[155](#bib.bib155)] | 2021 | - | - | - |  | 90.7 | 92.3 | 93.3 |
    93.7 |'
- en: 'Table 3: Datasets and Evaluation Metrics for Selected Models'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：所选模型的数据集和评估指标
- en: '| Task and Dataset | Model | Year | Evaluation Metrics |  |  |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 任务和数据集 | 模型 | 年份 | 评估指标 |  |  |'
- en: '| Property Prediction |  |  | MAE ↓ |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 属性预测 |  |  | MAE ↓ |'
- en: '|  |  | $U_{0}$(eV) | $U$(eV) | $G$(eV) | $H$(eV) | $C_{v}$($\frac{cal}{molK}$)
    | $HOMO$(eV) |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $U_{0}$(eV) | $U$(eV) | $G$(eV) | $H$(eV) | $C_{v}$($\frac{cal}{molK}$)
    | $HOMO$(eV) |'
- en: '| QM9 | InfoGraph [[122](#bib.bib122)] | 2019 | 0.1410 | 0.1702 | 0.1592 |
    0.1552 | 0.1965 | 0.1605 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| QM9 | InfoGraph [[122](#bib.bib122)] | 2019 | 0.1410 | 0.1702 | 0.1592 |
    0.1552 | 0.1965 | 0.1605 |'
- en: '|  | MGCN [[105](#bib.bib105)] | 2019 | 0.0129 | 0.0144 | 0.0146 | 0.0162 |
    0.0380 | 0.0421 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '|  | MGCN [[105](#bib.bib105)] | 2019 | 0.0129 | 0.0144 | 0.0146 | 0.0162 |
    0.0380 | 0.0421 |'
- en: '|  | ASGN [[117](#bib.bib117)] | 2020 | 0.0562 | 0.0594 | 0.0560 | 0.0583 |
    0.0984 | 0.1190 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '|  | ASGN [[117](#bib.bib117)] | 2020 | 0.0562 | 0.0594 | 0.0560 | 0.0583 |
    0.0984 | 0.1190 |'
- en: '|  | SphereNet [[116](#bib.bib116)] | 2021 | 0.0062 | 0.0064 | 0.0078 | 0.0063
    | 0.0215 | 0.0228 |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '|  | SphereNet [[116](#bib.bib116)] | 2021 | 0.0062 | 0.0064 | 0.0078 | 0.0063
    | 0.0215 | 0.0228 |'
- en: '|  |  |  | MAE ↓ |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | MAE ↓ |'
- en: '|  |  | $LUMO$(eV) | $gap$(eV) | $ZPVE$(eV) | $R^{2}$ ($a_{0}^{2}$) | $\mu$(D)
    | $\alpha$ ($a_{0}^{3}$) |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $LUMO$(eV) | $gap$(eV) | $ZPVE$(eV) | $R^{2}$ ($a_{0}^{2}$) | $\mu$(D)
    | $\alpha$ ($a_{0}^{3}$) |'
- en: '| QM9 | InfoGraph [[122](#bib.bib122)] | 2019 | 0.1659 | 0.2421 | 0.00036 |
    4.92 | 0.3168 | 0.5444 |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| QM9 | InfoGraph [[122](#bib.bib122)] | 2019 | 0.1659 | 0.2421 | 0.00036 |
    4.92 | 0.3168 | 0.5444 |'
- en: '|  | MGCN [[105](#bib.bib105)] | 2019 | 0.0574 | 0.0642 | 0.00112 | 0.11 |
    0.0560 | 0.0300 |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '|  | MGCN [[105](#bib.bib105)] | 2019 | 0.0574 | 0.0642 | 0.00112 | 0.11 |
    0.0560 | 0.0300 |'
- en: '|  | ASGN [[117](#bib.bib117)] | 2020 | 0.1061 | 0.2012 | 0.00017 | 1.38 |
    0.1947 | 0.2818 |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '|  | ASGN [[117](#bib.bib117)] | 2020 | 0.1061 | 0.2012 | 0.00017 | 1.38 |
    0.1947 | 0.2818 |'
- en: '|  | SphereNet [[116](#bib.bib116)] | 2021 | 0.0189 | 0.0311 | 0.00110 | 0.27
    | 0.0245 | 0.0449 |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '|  | SphereNet [[116](#bib.bib116)] | 2021 | 0.0189 | 0.0311 | 0.00110 | 0.27
    | 0.0245 | 0.0449 |'
- en: '|  |  |  | MAE ↓ |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | MAE ↓ |'
- en: '|  |  | FreeSolv | ESOL | Lipo | QM7 | QM8 |  |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '|  |  | FreeSolv | ESOL | Lipo | QM7 | QM8 |  |'
- en: '| MoleculeNet | MPNN [[115](#bib.bib115)] | 2017 | 2.185 | 1.167 | 0.672 |
    113.0 | 0.0150 |  |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| MoleculeNet | MPNN [[115](#bib.bib115)] | 2017 | 2.185 | 1.167 | 0.672 |
    113.0 | 0.0150 |  |'
- en: '|  | MGCN [[105](#bib.bib105)] | 2019 | 3.349 | 1.266 | 1.113 | 77.6 | 0.0220
    |  |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '|  | MGCN [[105](#bib.bib105)] | 2019 | 3.349 | 1.266 | 1.113 | 77.6 | 0.0220
    |  |'
- en: '|  | GROVER [[109](#bib.bib109)] | 2020 | 1.544 | 0.831 | 0.560 | 72.6 | 0.0125
    |  |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '|  | GROVER [[109](#bib.bib109)] | 2020 | 1.544 | 0.831 | 0.560 | 72.6 | 0.0125
    |  |'
- en: '|  | multiple SMILES[[87](#bib.bib87)] | 2022 | 0.786 | 0.445 | 0.548 | - |
    - |  |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '|  | multiple SMILES[[87](#bib.bib87)] | 2022 | 0.786 | 0.445 | 0.548 | - |
    - |  |'
- en: '|  | ChemNet [[124](#bib.bib124)] | 2021 | - | - | - | 60.1 | 0.0100 |  |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '|  | ChemNet [[124](#bib.bib124)] | 2021 | - | - | - | 60.1 | 0.0100 |  |'
- en: '|  | PhysChem [[124](#bib.bib124)] | 2021 | - | - | - | 59.6 | 0.0101 |  |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '|  | PhysChem [[124](#bib.bib124)] | 2021 | - | - | - | 59.6 | 0.0101 |  |'
- en: '|  |  |  | RMSE ↓ |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | RMSE ↓ |'
- en: '|  |  | FreeSolv | ESOL | Lipo |  |  |  |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '|  |  | FreeSolv | ESOL | Lipo |  |  |  |'
- en: '| MoleculeNet | N-Gram [[113](#bib.bib113)] | 2019 | 2.51 | 1.10 | 0.88 |  |  |  |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| MoleculeNet | N-Gram [[113](#bib.bib113)] | 2019 | 2.51 | 1.10 | 0.88 |  |  |  |'
- en: '|  | GROVER [[109](#bib.bib109)] | 2020 | 2.48 | 0.99 | 0.66 |  |  |  |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '|  | GROVER [[109](#bib.bib109)] | 2020 | 2.48 | 0.99 | 0.66 |  |  |  |'
- en: '|  | MolCLR [[111](#bib.bib111)] | 2022 | 2.20 | 1.11 | 0.65 |  |  |  |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '|  | MolCLR [[111](#bib.bib111)] | 2022 | 2.20 | 1.11 | 0.65 |  |  |  |'
- en: '|  |  |  | ROC-AUC ↑ |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | ROC-AUC ↑ |'
- en: '|  |  | BBBP | SIDER | ClinTox | BACE | Tox21 | ToxCast |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '|  |  | BBBP | SIDER | ClinTox | BACE | Tox21 | ToxCast |'
- en: '| MoleculeNet | AttrMasking [[107](#bib.bib107)] | 2019 | 0.702 | 0.604 | 0.686
    | 0.772 | 0.742 | 0.625 |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| MoleculeNet | AttrMasking [[107](#bib.bib107)] | 2019 | 0.702 | 0.604 | 0.686
    | 0.772 | 0.742 | 0.625 |'
- en: '|  | ContextPred [[107](#bib.bib107)] | 2019 | 0.712 | 0.593 | 0.737 | 0.786
    | 0.733 | 0.628 |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '|  | ContextPred [[107](#bib.bib107)] | 2019 | 0.712 | 0.593 | 0.737 | 0.786
    | 0.733 | 0.628 |'
- en: '|  | InfoGraph [[122](#bib.bib122)] | 2019 | 0.692 | 0.592 | 0.751 | 0.739
    | 0.730 | 0.620 |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '|  | InfoGraph [[122](#bib.bib122)] | 2019 | 0.692 | 0.592 | 0.751 | 0.739
    | 0.730 | 0.620 |'
- en: '|  | GraphCL [[110](#bib.bib110)] | 2020 | 0.675 | 0.601 | 0.789 | 0.687 |
    0.750 | 0.628 |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '|  | GraphCL [[110](#bib.bib110)] | 2020 | 0.675 | 0.601 | 0.789 | 0.687 |
    0.750 | 0.628 |'
- en: '|  | GROVER [[109](#bib.bib109)] | 2020 | 0.718 | 0.637 | 0.843 | 0.822 | 0.765
    | 0.635 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '|  | GROVER [[109](#bib.bib109)] | 2020 | 0.718 | 0.637 | 0.843 | 0.822 | 0.765
    | 0.635 |'
- en: '|  | ChemBERTa [[46](#bib.bib46)] | 2021 | 0.643 | - | 0.733 | - | 0.728 |
    - |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '|  | ChemBERTa [[46](#bib.bib46)] | 2021 | 0.643 | - | 0.733 | - | 0.728 |
    - |'
- en: '|  | GraphMVP [[106](#bib.bib106)] | 2021 | 0.724 | 0.639 | 0.791 | 0.812 |
    0.759 | 0.631 |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '|  | GraphMVP [[106](#bib.bib106)] | 2021 | 0.724 | 0.639 | 0.791 | 0.812 |
    0.759 | 0.631 |'
- en: '|  |  |  | AUC ↑ |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | AUC ↑ |'
- en: '|  |  | ClinTox | Tox21 |  |  |  |  |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '|  |  | ClinTox | Tox21 |  |  |  |  |'
- en: '| MoleculeNet | Chemception [[90](#bib.bib90)] | 2017 | 0.745 | 0.766 |  |  |  |  |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| MoleculeNet | Chemception [[90](#bib.bib90)] | 2017 | 0.745 | 0.766 |  |  |  |  |'
- en: '|  | SMILES2vec [[86](#bib.bib86)] | 2017 | 0.693 | 0.810 |  |  |  |  |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '|  | SMILES2vec [[86](#bib.bib86)] | 2017 | 0.693 | 0.810 |  |  |  |  |'
- en: '|  | CheMixNet [[89](#bib.bib89)] | 2018 | 0.944 | 0.920 |  |  |  |  |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '|  | CheMixNet [[89](#bib.bib89)] | 2018 | 0.944 | 0.920 |  |  |  |  |'
- en: '|  | TOP [[88](#bib.bib88)] | 2019 | 0.946 | - |  |  |  |  |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '|  | TOP [[88](#bib.bib88)] | 2019 | 0.946 | - |  |  |  |  |'
- en: The standard evaluation metric for retrosynthesis and reaction prediction is
    the top-k accuracy, a concept from probability. This metric will compute the percentage
    of times the correct answer is in the highest k ranking scores. Referring to the
    application in retrosynthesis prediction and reaction prediction, the match of
    the ground-truth reactants (or products) with the predicted one will be computed.
    Based on such an exact match, they will then apply top-k accuracy. The choice
    of k varies from 1 to 50, depending on different works. Another evaluation metric
    used in reaction prediction is Coverage@k, which is the proportion of reactions
    in all the actual atom pairs founded in the set of the predicted atom pairs.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 回溯合成和反应预测的标准评估指标是top-k准确率，这是一个源自概率的概念。该指标将计算正确答案出现在最高k排名分数中的百分比。参考在回溯合成预测和反应预测中的应用，将计算真实反应物（或产品）与预测结果的匹配程度。基于这种精确匹配，然后应用top-k准确率。k的选择从1到50不等，取决于不同的工作。另一个在反应预测中使用的评估指标是Coverage@k，它是所有实际原子对在预测原子对集合中的比例。
- en: 7.3 Benchmark Analysis
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 基准分析
- en: 'According to evaluation data of 2D molecule generation models in table [2](#S7.T2
    "Table 2 ‣ 7.2 Evaluation Metrics ‣ 7 Datasets and Benchmarks ‣ Deep Learning
    Methods for Small Molecule Drug Discovery: A Survey"), we could conclude that
    graph models like DST [[68](#bib.bib68)], MARS [[66](#bib.bib66)] and MolEvol
    [[65](#bib.bib65)] have better performance than SMILES models like GA+D [[57](#bib.bib57)]
    and LSTM [[169](#bib.bib169)]. This may be because SMILES strings fail to represent
    distances between atoms. For example, atoms close in the SMILES string may be
    far apart in the actual structure. Meanwhile, models using the notion of motif
    like MolEvol [[65](#bib.bib65)], MARS [[66](#bib.bib66)] and RationaleRL [[64](#bib.bib64)]
    have shown better success rate than atom by atom generation models. However, novelty
    of these models is limited since the motifs are extracted from the training set.
    For 3D molecule generation, variational auto-encoder and flow are two commonly
    used techniques in previous works. GEODIFF [[78](#bib.bib78)] combines the diffusion
    model with the molecular generation task and achieves the state-of-the-art result.
    Thus, finding models that better match 3D molecular invariant features is challenging
    for the 3D molecule generation task.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '根据表格[2](#S7.T2 "Table 2 ‣ 7.2 Evaluation Metrics ‣ 7 Datasets and Benchmarks
    ‣ Deep Learning Methods for Small Molecule Drug Discovery: A Survey")中的2D分子生成模型评估数据，我们可以得出结论，像DST
    [[68](#bib.bib68)]、MARS [[66](#bib.bib66)]和MolEvol [[65](#bib.bib65)]这样的图模型比SMILES模型如GA+D
    [[57](#bib.bib57)]和LSTM [[169](#bib.bib169)]表现更好。这可能是因为SMILES字符串无法表示原子之间的距离。例如，在SMILES字符串中接近的原子在实际结构中可能相距很远。同时，使用像MolEvol
    [[65](#bib.bib65)]、MARS [[66](#bib.bib66)]和RationaleRL [[64](#bib.bib64)]这样的模式概念的模型显示出比逐原子生成模型更高的成功率。然而，这些模型的创新性有限，因为模式是从训练集中提取的。对于3D分子生成，变分自编码器和流是之前工作中常用的两种技术。GEODIFF
    [[78](#bib.bib78)]将扩散模型与分子生成任务结合，达到了最先进的结果。因此，寻找更好地匹配3D分子不变特征的模型对3D分子生成任务来说是一个挑战。'
- en: Comparing the model performances on the QM9 datasets, we find out that utilizing
    unlabeled data appears to be an effective solution for predicting a large number
    of molecules [[117](#bib.bib117), [105](#bib.bib105)]. ASGN improves the transferability
    by weight transfer, while MGCN transfers the knowledge of small molecules to large
    ones to resolve the structural shortage of the dataset. These robust models achieve
    a more than 50$\%$ reduction on properties, such as, $U_{0}$, $C_{v}$, $\alpha$
    compared with baselines that rely on limited labeled data, showing a great necessity
    to improve generalizability and transferability. Incorporating multilevel information,
    especially the spatial position [[105](#bib.bib105), [116](#bib.bib116)], are
    proved to contribute to better performance. Instead of simply putting 3D information,
    such as angle, into use, spherical message passing (SMP) [[116](#bib.bib116)]
    produces accurate, complete, and physically meaningful data representations on
    3D graphs. The advancement has shown a significant improvement in almost all properties.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 比较 QM9 数据集上的模型表现，我们发现利用未标记数据似乎是预测大量分子的有效解决方案[[117](#bib.bib117), [105](#bib.bib105)]。ASGN
    通过权重转移提高了迁移性，而 MGCN 将小分子的知识转移到大分子上以解决数据集的结构短缺。这些稳健的模型在属性上实现了超过 50$\%$ 的减少，如 $U_{0}$、$C_{v}$、$\alpha$，相比依赖有限标记数据的基线，显示出提高通用性和迁移性的巨大需求。结合多层次信息，特别是空间位置
    [[105](#bib.bib105), [116](#bib.bib116)]，被证明有助于更好的性能。与其简单地使用 3D 信息，如角度，不如使用球面消息传递
    (SMP) [[116](#bib.bib116)] 生成准确、完整且物理上有意义的数据表示在 3D 图中。这一进展在几乎所有属性上都显示出显著的改进。
- en: As discovered in the molecule generation task, the overall performances on the
    MoleculeNet dataset reveal the overwhelming advantages of graph models over the
    string ones, especially for those involving multilevel structural details [[109](#bib.bib109)].
    The superb performance of TOP [[88](#bib.bib88)] on the ClinTox dataset demonstrates
    the strengths of incorporating multiple kinds of fingerprints compared to SMILES2vec
    [[86](#bib.bib86)]. The specially-designed mixed representation with SMILES strings
    and physiochemical properties demonstrate its superior capability for toxicity
    prediction on the ClinTox dataset. The innovation of combining properties with
    learned structural features provides insights to overcome shortcomings of existing
    explorations.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 如在分子生成任务中发现的那样，MoleculeNet 数据集的整体表现揭示了图模型相较于字符串模型的压倒性优势，特别是对于涉及多层次结构细节的任务[[109](#bib.bib109)]。TOP
    [[88](#bib.bib88)] 在 ClinTox 数据集上的卓越表现展示了与 SMILES2vec [[86](#bib.bib86)] 相比，结合多种指纹的优势。特别设计的混合表示结合了
    SMILES 字符串和物理化学性质，展示了其在 ClinTox 数据集上的优越毒性预测能力。将属性与学习到的结构特征结合的创新为克服现有探索的不足提供了见解。
- en: The overall model performance on the MoleculeNet dataset also indicates that
    self-supervised pre-training tasks result in a performance boost. While supervised
    pre-training tasks introduce the risk of negative transfer [[107](#bib.bib107)],
    well-designed self-supervised pre-trained models show rival performance in learning
    implicit domain knowledge [[109](#bib.bib109), [110](#bib.bib110), [111](#bib.bib111)].
    However, some tasks that involve alteration of the molecule structure, such as
    subgraph removal [[111](#bib.bib111)], result in poor performance in datasets
    sensitive to topology changes, such as the BBBP dataset. Moreover, the composition
    of different augmentation strategies is not bound to perform better since removing
    various substructures might easily lead to the loss of important structural information.
    Furthermore, models involving 3D information have superior performance on datasets
    of quantum mechanical properties. MGCN [[105](#bib.bib105)], though not showing
    distinct advantages on other datasets, shows a competitive result as those pre-training
    techniques on QM7 and QM8 datasets.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: MoleculeNet 数据集上的整体模型表现还表明，自监督预训练任务会带来性能提升。虽然监督预训练任务引入了负迁移的风险 [[107](#bib.bib107)]，但精心设计的自监督预训练模型在学习隐含领域知识方面展示了竞争力的表现
    [[109](#bib.bib109), [110](#bib.bib110), [111](#bib.bib111)]。然而，一些涉及分子结构改变的任务，如子图移除
    [[111](#bib.bib111)]，在对拓扑变化敏感的数据集（如 BBBP 数据集）上表现不佳。此外，不同增强策略的组合未必表现更好，因为移除各种子结构可能容易导致重要结构信息的丢失。此外，涉及
    3D 信息的模型在量子力学性质的数据集上表现优越。尽管 MGCN [[105](#bib.bib105)] 在其他数据集上未显示出明显优势，但在 QM7 和
    QM8 数据集上的结果与那些预训练技术相比仍具有竞争力。
- en: For retrosynthesis prediction, RetroXpert [[143](#bib.bib143)] and Reaction-Aware
    [[138](#bib.bib138)] combine the information from both graph representation and
    sequence representation and perform well. Generally speaking, template-free models
    have better performance. However, LocalRetro [[132](#bib.bib132)], a template-based
    model, outperforms others. This may be due to the model design, which not only
    strictly constrains the templates but also considers global structure. For reaction
    prediction, models such as GTPN [[154](#bib.bib154)], Molecular Transformer [[2](#bib.bib2)]
    and NERF [[155](#bib.bib155)] which utilize the state-of-art models in other applications
    of machine learning also get good results in this task.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 对于逆合成预测，RetroXpert [[143](#bib.bib143)] 和 Reaction-Aware [[138](#bib.bib138)]
    结合了图形表示和序列表示的信息，并表现良好。一般来说，无模板模型的表现更好。然而，基于模板的模型 LocalRetro [[132](#bib.bib132)]
    超越了其他模型。这可能是由于模型设计不仅严格约束模板，还考虑了全局结构。对于反应预测，GTPN [[154](#bib.bib154)]、Molecular
    Transformer [[2](#bib.bib2)] 和 NERF [[155](#bib.bib155)] 等利用其他应用中最先进的模型的模型在这一任务中也取得了良好结果。
- en: 8 Challenges and Future trend
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 个挑战和未来趋势
- en: 8.1 Challenges
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1 挑战
- en: Data. Despite all the machine learning models discussed above, it should be
    emphasized that data is the limiting factor in drug discovery. Data must be of
    sufficient quantity and high quality to make the model useful and practical. Although
    existing databases contain a large number of molecules, the number of data for
    a certain task can be very sparse [[170](#bib.bib170), [114](#bib.bib114), [171](#bib.bib171)].
    For instance, the training data is particularly limited for generating polymers
    with given properties [[172](#bib.bib172)]. Meanwhile, the quality of datasets
    still needs to be improved. The USPTO datasets are the most popular datasets for
    retrosynthesis due to their integrity and accessibility. However, the USPTO dataset
    still suffers from atom-mapping inaccuracy, and noisy stereochemical data [[173](#bib.bib173)].
    Data inconsistency is also a crucial problem in drug design [[174](#bib.bib174)].
    For example, data inconsistencies from different centres lead to substantial inconsistencies
    in drug responses in large pharmacogenomic studies [[175](#bib.bib175)].
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 数据。尽管讨论了上述所有机器学习模型，但必须强调数据是药物发现中的限制因素。数据必须具有足够的数量和高质量，才能使模型有用且实用。虽然现有数据库包含大量分子，但某些任务的数据量可能非常稀疏[[170](#bib.bib170),
    [114](#bib.bib114), [171](#bib.bib171)]。例如，生成具有特定属性的聚合物的训练数据特别有限[[172](#bib.bib172)]。与此同时，数据集的质量仍需改进。USPTO
    数据集因其完整性和可访问性而成为逆合成中最受欢迎的数据集。然而，USPTO 数据集仍然存在原子映射不准确和嘈杂的立体化学数据问题[[173](#bib.bib173)]。数据不一致也是药物设计中的一个关键问题[[174](#bib.bib174)]。例如，来自不同中心的数据不一致导致大规模药物基因组研究中药物反应存在重大差异[[175](#bib.bib175)]。
- en: Evaluation Metrics. The currently used evaluation metrics need to be improved.
    Renz et al. [[176](#bib.bib176)] have shown that it is easy to maximize “validity”
    by inserting a carbon atom into the training SMILES string. Current evaluation
    metrics for retrosynthesis also have misleading meanings [[177](#bib.bib177),
    [178](#bib.bib178), [179](#bib.bib179)]. Therefore, although a large number of
    evaluation metrics have been provided, these metrics are simplified due to computational
    complexity and differ from the real definition to some extent. How to balance
    computational complexity with real definitions is still an unsolved problem, which
    requires continuous efforts to refine the evaluation methods better.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 评价指标。目前使用的评价指标需要改进。Renz 等人[[176](#bib.bib176)]已显示，通过在训练 SMILES 字符串中插入一个碳原子可以轻松最大化“有效性”。目前的逆合成评价指标也具有误导性含义[[177](#bib.bib177),
    [178](#bib.bib178), [179](#bib.bib179)]。因此，尽管提供了大量评价指标，但由于计算复杂性，这些指标被简化，并在某种程度上与实际定义有所不同。如何平衡计算复杂性与实际定义仍然是一个未解决的问题，需要不断努力改进评价方法。
- en: 'Interpretability. Interpretability issue is another challenge in drug discovery.
    Although existing models perform well, the reasons behind them are still unclear.
    For instance, retrosynthesis can predict the initial products. However, if the
    mechanism behind retrosynthesis could also be provided, it would be helpful for
    the research of chemical reactions. More specifically, there are four aspects
    to cover [[180](#bib.bib180)]: 1) Transparency, which is knowing how the system
    reaches a particular answer; 2) Justification, which is elucidating why the answer
    provided by the model is acceptable; 3) Informativeness, which is providing new
    information to human decision-makers; and 4) Uncertainty estimation, which is
    quantifying how reliable a prediction is. An interpretable model has many advantages.
    It can help the expert to analyze the causes when the performance of model is
    poor and provide directions for further improvement. When the interpretation of
    the model is consistent with the prior knowledge, the confidence of the model
    can be improved [[181](#bib.bib181)]. Although there are some explorations to
    the interpretability via case studies [[68](#bib.bib68), [182](#bib.bib182), [183](#bib.bib183)],
    how to quantitatively evaluate interpretability remains a challenge [[184](#bib.bib184)].'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性。可解释性问题是药物发现中的另一个挑战。尽管现有模型表现良好，但其背后的原因仍不清楚。例如，逆合成可以预测初始产物。然而，如果能提供逆合成背后的机制，这将有助于化学反应的研究。更具体地说，有四个方面需要涵盖[[180](#bib.bib180)]：1)
    透明度，即了解系统如何得出特定答案；2) 解释，即阐明模型提供的答案为何是可接受的；3) 信息量，即向人类决策者提供新信息；4) 不确定性估计，即量化预测的可靠性。一个可解释的模型有很多优势。它可以帮助专家分析模型表现不佳时的原因，并提供进一步改进的方向。当模型的解释与先验知识一致时，可以提高模型的信心[[181](#bib.bib181)]。尽管通过案例研究[[68](#bib.bib68),
    [182](#bib.bib182), [183](#bib.bib183)]对可解释性进行了探索，但如何定量评估可解释性仍然是一个挑战[[184](#bib.bib184)]。
- en: Uncertainty Quantification. Most work has focused on improving model accuracy,
    while quantifying uncertainty requires more attention [[185](#bib.bib185)]. Model
    accuracy can only represent the reliability of the entire model. However, uncertainty
    quantification predicts the property interval of a given molecule at a certain
    confidence level, estimating reliability at the instance level [[186](#bib.bib186)].
    By combining the prediction results of the model with the quantification of uncertainty,
    it is possible to screen for reliable molecules with good properties, thus improving
    the efficiency of drug design. In addition, the algorithm using uncertainty quantization
    is robust when exploring the domain outside the distribution of training data,
    which is important for the model to explore in the huge and diverse chemical space [[187](#bib.bib187)].
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定性量化。大多数工作集中在提高模型准确性上，而不确定性量化则需要更多关注[[185](#bib.bib185)]。模型准确性只能代表整个模型的可靠性。然而，不确定性量化在一定置信水平下预测给定分子的性质区间，估计实例级别的可靠性[[186](#bib.bib186)]。通过将模型的预测结果与不确定性量化结合，可以筛选出具有良好性质的可靠分子，从而提高药物设计的效率。此外，使用不确定性量化的算法在探索训练数据分布之外的领域时具有鲁棒性，这对模型在巨大而多样的化学空间中进行探索至关重要[[187](#bib.bib187)]。
- en: 8.2 Future Trend
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2 未来趋势
- en: For molecule generation tasks, the molecular representation framework has gradually
    shifted from SMILES sequences to graph neural networks. Compared with SMILES sequences,
    graph neural networks can better represent molecular structures, especially cyclic
    ones. However, graph neural networks can only assign atom relationships to nodes
    and edges on the graph. Combining the constraints between atoms with neural networks
    remains to be explored. Meanwhile, this survey focuses on structured small molecule
    generation. Other compounds such as protein, gene and crystal with more complex
    data structures may also benefit from the methods discussed here.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分子生成任务，分子表示框架逐渐从SMILES序列转向图神经网络。与SMILES序列相比，图神经网络能更好地表示分子结构，特别是环状结构。然而，图神经网络只能将原子关系分配给图上的节点和边。将原子之间的约束与神经网络结合仍需探索。同时，本调查关注于结构化小分子的生成。其他如蛋白质、基因和晶体等具有更复杂数据结构的化合物也可能从这里讨论的方法中受益。
- en: For molecular property prediction tasks, the current trend of leveraging 2D
    topology and 3D geometry will be sustained. It appears that mutual information
    maximization and the MPNN framework will be continued to act as the basic theme.
    While most architectures focus on molecular representations, transferability to
    downstream tasks requires more attention to avoid the “negative transfer” effect
    since molecular property prediction is often viewed as a downstream task. Novel
    pre-training strategies will continue to be a powerful trend since these strategies
    address the limited labeled data and out-of-distribution prediction problems to
    some extent. Novel strategies for combining molecular properties, such as chemical
    reactions and molecular dynamics, will be explored with a specific focus on multi-dimensional
    structures.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分子属性预测任务，目前利用二维拓扑和三维几何的趋势将会持续。互信息最大化和MPNN框架似乎将继续作为基本主题。虽然大多数架构侧重于分子表示，但由于分子属性预测通常被视为下游任务，转移到下游任务需要更多关注以避免“负迁移”效应。新颖的预训练策略将继续成为一个强有力的趋势，因为这些策略在一定程度上解决了标签数据有限和分布外预测问题。将分子属性（例如化学反应和分子动力学）结合的新策略将会被探索，特别关注多维结构。
- en: For retrosynthesis and reaction prediction tasks, the methods for both tasks
    can be classified into two categories, i.e., template-based and template-free.
    The development space is limited for the multi-step template-based models due
    to the weak generalization ability. Meanwhile, more and more template-free models
    are proposed because of their excellent coverage, scalability, and diversity.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回溯合成和反应预测任务，这两类任务的方法可以分为基于模板和无模板两类。由于多步模板模型的泛化能力较弱，因此发展空间有限。同时，由于无模板模型具有出色的覆盖性、可扩展性和多样性，越来越多的无模板模型被提出。
- en: However, most of the proposed methods lack information about conditions, such
    as reagents, catalysts, solvents, temperature. Although recent developed algorithms
    have made a preliminary attempt on this aspect [[177](#bib.bib177), [188](#bib.bib188),
    [189](#bib.bib189)], the conversion of algorithms to experimental procedures should
    receive more attention in the future [[188](#bib.bib188)].
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大多数提出的方法缺乏关于条件的信息，例如试剂、催化剂、溶剂、温度。虽然最近开发的算法在这方面进行了初步尝试[[177](#bib.bib177),
    [188](#bib.bib188), [189](#bib.bib189)]，但未来应更多关注算法向实验程序的转化[[188](#bib.bib188)]。
- en: Although models and algorithms are proposed separately for different tasks,
    those tasks have intrinsic relationships. For example, after a molecule is produced
    by generation models, experts need to know some basic properties of this molecule
    (e.g., whether it is toxic, whether it can be absorbed by human body) as well
    as how to synthesize this molecule. This is where the property prediction and
    retrosynthesis algorithms come into play. Thus, making connections between different
    tasks and integrating them might be a trend in the future. Furthermore, most of
    the existing models are based on theory and lack experimental verification. The
    results of the model have a guiding effect on the experiment, and the data obtained
    from the experiment can also be fed back to improve the model. The potential for
    closing the loop for theoretical model and practical experiments is quite profound
    [[190](#bib.bib190)].
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管针对不同任务分别提出了模型和算法，但这些任务之间具有内在关系。例如，在生成模型产生分子后，专家需要了解该分子的一些基本性质（例如，是否有毒，是否能被人体吸收）以及如何合成该分子。这就是属性预测和回溯合成算法发挥作用的地方。因此，将不同任务联系起来并整合它们可能是未来的趋势。此外，大多数现有模型基于理论，缺乏实验验证。模型的结果对实验具有指导作用，实验获得的数据也可以反馈以改进模型。理论模型与实际实验闭环的潜力是相当深远的[[190](#bib.bib190)]。
- en: 9 Conclusion
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 结论
- en: In this survey, we comprehensively review molecule generation, molecular property
    prediction, retrosynthesis, and reaction prediction tasks under the setting of
    deep learning. We categorize the existing models based on the molecule representation
    they employ. Additionally, we delve into the datasets and evaluation metrics and
    analyze benchmark models in terms of performance. Finally, we highlight the challenges
    and outline the future trend of drug discovery utilizing deep learning methods.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在本综述中，我们全面回顾了在深度学习设置下的分子生成、分子属性预测、逆合成和反应预测任务。我们根据现有模型所使用的分子表示方法进行分类。此外，我们深入探讨了数据集和评价指标，并分析了基准模型的性能。最后，我们突出了挑战，并概述了利用深度学习方法进行药物发现的未来趋势。
- en: Acknowledgments
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work is supported by National Natural Science Foundation of China (62106219)
    and Natural Science Foundation of Zhejiang Province (QY19E050003).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了中国国家自然科学基金（62106219）和浙江省自然科学基金（QY19E050003）的支持。
- en: References
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] J. Deng, Z. Yang, I. Ojima, D. Samaras, and F. Wang, “Artificial intelligence
    in drug discovery: applications and techniques,” *Briefings in Bioinformatics*,
    vol. 23, no. 1, p. bbab430, 2022.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] J. Deng, Z. Yang, I. Ojima, D. Samaras, 和 F. Wang, “药物发现中的人工智能：应用与技术，”
    *生物信息学简报*，第23卷，第1期，第bbab430页，2022年。'
- en: '[2] P. Schwaller, T. Laino, T. Gaudin, P. Bolgar, C. A. Hunter, C. Bekas, and
    A. A. Lee, “Molecular transformer: a model for uncertainty-calibrated chemical
    reaction prediction,” *ACS central science*, vol. 5, no. 9, pp. 1572–1583, 2019.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] P. Schwaller, T. Laino, T. Gaudin, P. Bolgar, C. A. Hunter, C. Bekas, 和
    A. A. Lee, “分子变换器：不确定性校准化学反应预测模型，” *ACS中央科学*，第5卷，第9期，第1572–1583页，2019年。'
- en: '[3] A. Kumar, A. Voet, and K. Zhang, “Fragment based drug design: from experimental
    to computational approaches,” *Current medicinal chemistry*, vol. 19, no. 30,
    pp. 5128–5147, 2012.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] A. Kumar, A. Voet, 和 K. Zhang, “基于片段的药物设计：从实验到计算方法，” *当前药物化学*，第19卷，第30期，第5128–5147页，2012年。'
- en: '[4] C. Sheng and W. Zhang, “Fragment informatics and computational fragment-based
    drug design: an overview and update,” *Medicinal Research Reviews*, vol. 33, no. 3,
    pp. 554–598, 2013.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] C. Sheng 和 W. Zhang, “片段信息学和基于片段的药物设计：概述与更新，” *药物研究评论*，第33卷，第3期，第554–598页，2013年。'
- en: '[5] R. P. Sheridan and S. K. Kearsley, “Using a genetic algorithm to suggest
    combinatorial libraries,” *Journal of Chemical Information and Computer Sciences*,
    vol. 35, no. 2, pp. 310–320, 1995.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] R. P. Sheridan 和 S. K. Kearsley, “利用遗传算法建议组合库，” *化学信息与计算科学期刊*，第35卷，第2期，第310–320页，1995年。'
- en: '[6] D. Schwalbe-Koda and R. Gómez-Bombarelli, “Generative models for automatic
    chemical design,” in *Machine Learning Meets Quantum Physics*.   Springer, 2020,
    pp. 445–467.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] D. Schwalbe-Koda 和 R. Gómez-Bombarelli, “自动化化学设计的生成模型，” 见于 *机器学习遇见量子物理*。Springer，2020年，第445–467页。'
- en: '[7] V. Svetnik, A. Liaw, C. Tong, J. C. Culberson, R. P. Sheridan, and B. P.
    Feuston, “Random forest: a classification and regression tool for compound classification
    and qsar modeling,” *Journal of chemical information and computer sciences*, vol. 43,
    no. 6, pp. 1947–1958, 2003.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] V. Svetnik, A. Liaw, C. Tong, J. C. Culberson, R. P. Sheridan, 和 B. P.
    Feuston, “随机森林：用于化合物分类和QSAR建模的分类和回归工具，” *化学信息与计算科学期刊*，第43卷，第6期，第1947–1958页，2003年。'
- en: '[8] L. Zhang, H. Zhu, T. I. Oprea, A. Golbraikh, and A. Tropsha, “Qsar modeling
    of the blood–brain barrier permeability for diverse organic compounds,” *Pharmaceutical
    research*, vol. 25, no. 8, pp. 1902–1914, 2008.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] L. Zhang, H. Zhu, T. I. Oprea, A. Golbraikh, 和 A. Tropsha, “不同有机化合物的血脑屏障通透性QSAR建模，”
    *药物研究*，第25卷，第8期，第1902–1914页，2008年。'
- en: '[9] H. Fröhlich, J. K. Wegner, F. Sieker, and A. Zell, “Kernel functions for
    attributed molecular graphs–a new similarity-based approach to adme prediction
    in classification and regression,” *QSAR & Combinatorial Science*, vol. 25, no. 4,
    pp. 317–326, 2006.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] H. Fröhlich, J. K. Wegner, F. Sieker, 和 A. Zell, “属性分子图的核函数——一种基于相似性的ADME预测新方法，”
    *QSAR与组合科学*，第25卷，第4期，第317–326页，2006年。'
- en: '[10] D. Chen, S. Liu, P. Kingsbury, S. Sohn, C. B. Storlie, E. B. Habermann,
    J. M. Naessens, D. W. Larson, and H. Liu, “Deep learning and alternative learning
    strategies for retrospective real-world clinical data,” *NPJ digital medicine*,
    vol. 2, no. 1, pp. 1–5, 2019.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] D. Chen, S. Liu, P. Kingsbury, S. Sohn, C. B. Storlie, E. B. Habermann,
    J. M. Naessens, D. W. Larson, 和 H. Liu, “深度学习和替代学习策略在回顾性真实世界临床数据中的应用，” *NPJ数字医学*，第2卷，第1期，第1–5页，2019年。'
- en: '[11] V. Borisov, T. Leemann, K. Seßler, J. Haug, M. Pawelczyk, and G. Kasneci,
    “Deep neural networks and tabular data: A survey,” *arXiv preprint arXiv:2110.01889*,
    2021.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] V. Borisov, T. Leemann, K. Seßler, J. Haug, M. Pawelczyk, 和 G. Kasneci，“深度神经网络与表格数据：一项调查，”
    *arXiv预印本 arXiv:2110.01889*，2021年。'
- en: '[12] H. Li, K.-H. Sze, G. Lu, and P. J. Ballester, “Machine-learning scoring
    functions for structure-based virtual screening,” *Wiley Interdisciplinary Reviews:
    Computational Molecular Science*, vol. 11, no. 1, p. e1478, 2021.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] H. Li, K.-H. Sze, G. Lu, 和 P. J. Ballester，“基于结构的虚拟筛选的机器学习评分函数，” *Wiley跨学科评论：计算分子科学*，第11卷，第1期，第e1478页，2021年。'
- en: '[13] A. Bomane, A. Gonçalves, and P. J. Ballester, “Paclitaxel response can
    be predicted with interpretable multi-variate classifiers exploiting dna-methylation
    and mirna data,” *Frontiers in genetics*, vol. 10, p. 1041, 2019.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] A. Bomane, A. Gonçalves, 和 P. J. Ballester，“利用DNA甲基化和miRNA数据的可解释多变量分类器预测紫杉醇反应，”
    *遗传学前沿*，第10卷，第1041页，2019年。'
- en: '[14] L. Grinsztajn, E. Oyallon, and G. Varoquaux, “Why do tree-based models
    still outperform deep learning on tabular data?” *arXiv preprint arXiv:2207.08815*,
    2022.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] L. Grinsztajn, E. Oyallon, 和 G. Varoquaux，“为何基于树的模型仍然在表格数据上优于深度学习？” *arXiv预印本
    arXiv:2207.08815*，2022年。'
- en: '[15] A. Paul, A. Furmanchuk, W.-k. Liao, A. Choudhary, and A. Agrawal, “Property
    prediction of organic donor molecules for photovoltaic applications using extremely
    randomized trees,” *Molecular informatics*, vol. 38, no. 11-12, p. 1900038, 2019.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] A. Paul, A. Furmanchuk, W.-k. Liao, A. Choudhary, 和 A. Agrawal，“使用极端随机树进行光伏应用的有机供体分子性质预测，”
    *分子信息学*，第38卷，第11-12期，第1900038页，2019年。'
- en: '[16] U. Rester, “From virtuality to reality-virtual screening in lead discovery
    and lead optimization: a medicinal chemistry perspective.” *Current opinion in
    drug discovery & development*, vol. 11, no. 4, pp. 559–568, 2008.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] U. Rester，“从虚拟到现实——在先导发现和先导优化中的虚拟筛选：一种药物化学视角。” *药物发现与开发的当前观点*，第11卷，第4期，第559–568页，2008年。'
- en: '[17] J. M. Rollinger, H. Stuppner, and T. Langer, “Virtual screening for the
    discovery of bioactive natural products,” *Natural compounds as drugs Volume I*,
    pp. 211–249, 2008.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] J. M. Rollinger, H. Stuppner, 和 T. Langer，“用于发现生物活性天然产物的虚拟筛选，” *天然化合物作为药物
    第I卷*，第211–249页，2008年。'
- en: '[18] G. Ghislat, T. Rahman, and P. J. Ballester, “Recent progress on the prospective
    application of machine learning to structure-based virtual screening,” *Current
    opinion in chemical biology*, vol. 65, pp. 28–34, 2021.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] G. Ghislat, T. Rahman, 和 P. J. Ballester，“机器学习在基于结构的虚拟筛选中的前景应用的最新进展，”
    *化学生物学的当前观点*，第65卷，第28–34页，2021年。'
- en: '[19] I. Wallach, M. Dzamba, and A. Heifets, “Atomnet: a deep convolutional
    neural network for bioactivity prediction in structure-based drug discovery,”
    *arXiv preprint arXiv:1510.02855*, 2015.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] I. Wallach, M. Dzamba, 和 A. Heifets，“Atomnet：用于基于结构药物发现中的生物活性预测的深度卷积神经网络，”
    *arXiv预印本 arXiv:1510.02855*，2015年。'
- en: '[20] Q. Feng, E. Dueva, A. Cherkasov, and M. Ester, “Padme: A deep learning-based
    framework for drug-target interaction prediction,” *arXiv preprint arXiv:1807.09741*,
    2018.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Q. Feng, E. Dueva, A. Cherkasov, 和 M. Ester，“Padme：一个基于深度学习的药物-靶点相互作用预测框架，”
    *arXiv预印本 arXiv:1807.09741*，2018年。'
- en: '[21] M. I. Davis, J. P. Hunt, S. Herrgard, P. Ciceri, L. M. Wodicka, G. Pallares,
    M. Hocker, D. K. Treiber, and P. P. Zarrinkar, “Comprehensive analysis of kinase
    inhibitor selectivity,” *Nature biotechnology*, vol. 29, no. 11, pp. 1046–1051,
    2011.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] M. I. Davis, J. P. Hunt, S. Herrgard, P. Ciceri, L. M. Wodicka, G. Pallares,
    M. Hocker, D. K. Treiber, 和 P. P. Zarrinkar，“激酶抑制剂选择性的综合分析，” *自然生物技术*，第29卷，第11期，第1046–1051页，2011年。'
- en: '[22] J. T. Metz, E. F. Johnson, N. B. Soni, P. J. Merta, L. Kifle, and P. J.
    Hajduk, “Navigating the kinome,” *Nature chemical biology*, vol. 7, no. 4, pp.
    200–202, 2011.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] J. T. Metz, E. F. Johnson, N. B. Soni, P. J. Merta, L. Kifle, 和 P. J.
    Hajduk，“导航kinome，” *自然化学生物学*，第7卷，第4期，第200–202页，2011年。'
- en: '[23] J. Tang, A. Szwajda, S. Shakyawar, T. Xu, P. Hintsanen, K. Wennerberg,
    and T. Aittokallio, “Making sense of large-scale kinase inhibitor bioactivity
    data sets: a comparative and integrative analysis,” *Journal of Chemical Information
    and Modeling*, vol. 54, no. 3, pp. 735–743, 2014.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] J. Tang, A. Szwajda, S. Shakyawar, T. Xu, P. Hintsanen, K. Wennerberg,
    和 T. Aittokallio，“理解大规模激酶抑制剂生物活性数据集：比较与综合分析，” *化学信息与建模期刊*，第54卷，第3期，第735–743页，2014年。'
- en: '[24] K. Y. Gao, A. Fokoue, H. Luo, A. Iyengar, S. Dey, P. Zhang *et al.*, “Interpretable
    drug target prediction using deep neural representation.” in *IJCAI*, vol. 2018,
    2018, pp. 3371–3377.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] K. Y. Gao, A. Fokoue, H. Luo, A. Iyengar, S. Dey, P. Zhang *等*，“使用深度神经表示进行可解释的药物靶点预测。”
    收录于 *IJCAI*，2018年第2018卷，第3371–3377页。'
- en: '[25] Q. Yang, V. Sresht, P. Bolgar, X. Hou, J. L. Klug-McLeod, C. R. Butler
    *et al.*, “Molecular transformer unifies reaction prediction and retrosynthesis
    across pharma chemical space,” *Chemical communications*, vol. 55, no. 81, pp.
    12 152–12 155, 2019.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Q. Yang, V. Sresht, P. Bolgar, X. Hou, J. L. Klug-McLeod, C. R. Butler
    *等*，“分子变换器统一了药物化学空间中的反应预测和逆合成，” *化学通讯*，第55卷，第81期，第12 152–12 155页，2019年。'
- en: '[26] J. Dong, M. Zhao, Y. Liu, Y. Su, and X. Zeng, “Deep learning in retrosynthesis
    planning: datasets, models and tools,” *Briefings in Bioinformatics*, vol. 23,
    no. 1, p. bbab391, 2022.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] J. Dong, M. Zhao, Y. Liu, Y. Su, 和 X. Zeng，“逆合成规划中的深度学习：数据集、模型和工具，” *生物信息学简报*，第23卷，第1期，第bbab391页，2022年。'
- en: '[27] A. Cook, A. P. Johnson, J. Law, M. Mirzazadeh, O. Ravitz, and A. Simon,
    “Computer-aided synthesis design: 40 years on,” *Wiley Interdisciplinary Reviews:
    Computational Molecular Science*, vol. 2, no. 1, pp. 79–107, 2012.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] A. Cook, A. P. Johnson, J. Law, M. Mirzazadeh, O. Ravitz, 和 A. Simon，“计算机辅助合成设计：40
    年来，” *威利跨学科评论：计算分子科学*，第2卷，第1期，第79–107页，2012年。'
- en: '[28] A. Lavecchia, “Machine-learning approaches in drug discovery: methods
    and applications,” *Drug discovery today*, vol. 20, no. 3, pp. 318–331, 2015.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] A. Lavecchia，“药物发现中的机器学习方法：方法与应用，” *药物发现今日*，第20卷，第3期，第318–331页，2015年。'
- en: '[29] E. Gawehn, J. A. Hiss, and G. Schneider, “Deep learning in drug discovery,”
    *Molecular informatics*, vol. 35, no. 1, pp. 3–14, 2016.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] E. Gawehn, J. A. Hiss, 和 G. Schneider，“药物发现中的深度学习，” *分子信息学*，第35卷，第1期，第3–14页，2016年。'
- en: '[30] R. Gupta, D. Srivastava, M. Sahu, S. Tiwari, R. K. Ambasta, and P. Kumar,
    “Artificial intelligence to deep learning: machine intelligence approach for drug
    discovery,” *Molecular Diversity*, vol. 25, no. 3, pp. 1315–1360, 2021.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] R. Gupta, D. Srivastava, M. Sahu, S. Tiwari, R. K. Ambasta, 和 P. Kumar，“从人工智能到深度学习：药物发现的机器智能方法，”
    *分子多样性*，第25卷，第3期，第1315–1360页，2021年。'
- en: '[31] A. Nigam, R. Pollice, M. F. Hurley, R. J. Hickman, M. Aldeghi, N. Yoshikawa,
    S. Chithrananda, V. A. Voelz, and A. Aspuru-Guzik, “Assigning confidence to molecular
    property prediction,” *Expert opinion on drug discovery*, vol. 16, no. 9, pp.
    1009–1023, 2021.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] A. Nigam, R. Pollice, M. F. Hurley, R. J. Hickman, M. Aldeghi, N. Yoshikawa,
    S. Chithrananda, V. A. Voelz, 和 A. Aspuru-Guzik，“为分子属性预测赋予信心，” *药物发现专家意见*，第16卷，第9期，第1009–1023页，2021年。'
- en: '[32] O. Wieder, S. Kohlbacher, M. Kuenemann, A. Garon, P. Ducrot, T. Seidel,
    and T. Langer, “A compact review of molecular property prediction with graph neural
    networks,” *Drug Discovery Today: Technologies*, vol. 37, pp. 1–12, 2020.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] O. Wieder, S. Kohlbacher, M. Kuenemann, A. Garon, P. Ducrot, T. Seidel,
    和 T. Langer，“基于图神经网络的分子属性预测紧凑综述，” *药物发现今日：技术*，第37卷，第1–12页，2020年。'
- en: '[33] X. Tong, X. Liu, X. Tan, X. Li, J. Jiang, Z. Xiong, T. Xu, H. Jiang, N. Qiao,
    and M. Zheng, “Generative models for de novo drug design,” *Journal of Medicinal
    Chemistry*, vol. 64, no. 19, pp. 14 011–14 027, 2021.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] X. Tong, X. Liu, X. Tan, X. Li, J. Jiang, Z. Xiong, T. Xu, H. Jiang, N.
    Qiao, 和 M. Zheng，“用于 de novo 药物设计的生成模型，” *药物化学期刊*，第64卷，第19期，第14 011–14 027页，2021年。'
- en: '[34] D. C. Elton, Z. Boukouvalas, M. D. Fuge, and P. W. Chung, “Deep learning
    for molecular design—a review of the state of the art,” *Molecular Systems Design
    & Engineering*, vol. 4, no. 4, pp. 828–849, 2019.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] D. C. Elton, Z. Boukouvalas, M. D. Fuge, 和 P. W. Chung，“分子设计中的深度学习——前沿综述，”
    *分子系统设计与工程*，第4卷，第4期，第828–849页，2019年。'
- en: '[35] T. J. Struble, J. C. Alvarez, S. P. Brown, M. Chytil, J. Cisar, R. L.
    DesJarlais, O. Engkvist, S. A. Frank, D. R. Greve, D. J. Griffin *et al.*, “Current
    and future roles of artificial intelligence in medicinal chemistry synthesis,”
    *Journal of medicinal chemistry*, vol. 63, no. 16, pp. 8667–8682, 2020.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] T. J. Struble, J. C. Alvarez, S. P. Brown, M. Chytil, J. Cisar, R. L.
    DesJarlais, O. Engkvist, S. A. Frank, D. R. Greve, D. J. Griffin *等*，“人工智能在药物化学合成中的当前和未来角色，”
    *药物化学期刊*，第63卷，第16期，第8667–8682页，2020年。'
- en: '[36] M. R. Dobbelaere, P. P. Plehiers, R. Van de Vijver, C. V. Stevens, and
    K. M. Van Geem, “Machine learning in chemical engineering: strengths, weaknesses,
    opportunities, and threats,” *Engineering*, vol. 7, no. 9, pp. 1201–1211, 2021.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] M. R. Dobbelaere, P. P. Plehiers, R. Van de Vijver, C. V. Stevens, 和 K.
    M. Van Geem，“化学工程中的机器学习：优势、劣势、机会与威胁，” *工程学*，第7卷，第9期，第1201–1211页，2021年。'
- en: '[37] J. L. Durant, B. A. Leland, D. R. Henry, and J. G. Nourse, “Reoptimization
    of mdl keys for use in drug discovery,” *Journal of chemical information and computer
    sciences*, vol. 42, no. 6, pp. 1273–1280, 2002.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] J. L. Durant, B. A. Leland, D. R. Henry, 和 J. G. Nourse，“MDL 键的重新优化用于药物发现，”
    *化学信息与计算科学期刊*，第42卷，第6期，第1273–1280页，2002年。'
- en: '[38] “Pubchem substructure fingerprint,” [https://ftp.ncbi.nlm.nih.gov/pubchem/specifications/pubchem_fingerprints.pdf](https://ftp.ncbi.nlm.nih.gov/pubchem/specifications/pubchem_fingerprints.pdf),
    accessed September 2022.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] “Pubchem 子结构指纹”，[https://ftp.ncbi.nlm.nih.gov/pubchem/specifications/pubchem_fingerprints.pdf](https://ftp.ncbi.nlm.nih.gov/pubchem/specifications/pubchem_fingerprints.pdf)，访问日期：2022
    年 9 月。'
- en: '[39] “Rdkit,” [https://www.rdkit.org/](https://www.rdkit.org/), accessed September
    2022.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] “Rdkit”，[https://www.rdkit.org/](https://www.rdkit.org/)，访问日期：2022 年 9
    月。'
- en: '[40] N. M. O’Boyle, M. Banck, C. A. James, C. Morley, T. Vandermeersch, and
    G. R. Hutchison, “Open babel: An open chemical toolbox,” *Journal of cheminformatics*,
    vol. 3, no. 1, pp. 1–14, 2011.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] N. M. O’Boyle, M. Banck, C. A. James, C. Morley, T. Vandermeersch, 和 G.
    R. Hutchison，“Open Babel：一个开放的化学工具箱”，*化学信息学期刊*，第 3 卷，第 1 期，第 1–14 页，2011 年。'
- en: '[41] “Chemistry development kit (cdk),” [https://cdk.github.io/](https://cdk.github.io/),
    accessed September 2022.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] “化学开发工具包 (cdk)”，[https://cdk.github.io/](https://cdk.github.io/)，访问日期：2022
    年 9 月。'
- en: '[42] Z. Xu, S. Wang, F. Zhu, and J. Huang, “Seq2seq fingerprint: An unsupervised
    deep molecular embedding for drug discovery,” in *Proceedings of the 8th ACM international
    conference on bioinformatics, computational biology, and health informatics*,
    2017, pp. 285–294.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Z. Xu, S. Wang, F. Zhu, 和 J. Huang，“Seq2seq 指纹：一种用于药物发现的无监督深度分子嵌入”，发表于
    *第八届 ACM 国际生物信息学、计算生物学和健康信息学会议论文集*，2017 年，第 285–294 页。'
- en: '[43] W. Jin, R. Barzilay, and T. Jaakkola, “Junction tree variational autoencoder
    for molecular graph generation,” in *ICML*.   PMLR, 2018, pp. 2323–2332.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] W. Jin, R. Barzilay, 和 T. Jaakkola，“用于分子图生成的连接树变分自编码器”，发表于 *ICML*。   PMLR，2018
    年，第 2323–2332 页。'
- en: '[44] D. Weininger, “Smiles, a chemical language and information system. 1.
    introduction to methodology and encoding rules,” *Journal of chemical information
    and computer sciences*, vol. 28, no. 1, pp. 31–36, 1988.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] D. Weininger，“Smiles，一种化学语言和信息系统。1. 方法论和编码规则简介”，*化学信息与计算科学期刊*，第 28 卷，第
    1 期，第 31–36 页，1988 年。'
- en: '[45] S. Honda, S. Shi, and H. R. Ueda, “Smiles transformer: Pre-trained molecular
    fingerprint for low data drug discovery,” *arXiv preprint arXiv:1911.04738*, 2019.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] S. Honda, S. Shi, 和 H. R. Ueda，“Smiles 转换器：用于数据稀缺药物发现的预训练分子指纹”，*arXiv
    预印本 arXiv:1911.04738*，2019 年。'
- en: '[46] S. Adilov, “Generative pre-training from molecules,” 2021.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] S. Adilov，“分子生成预训练”，2021 年。'
- en: '[47] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever *et al.*,
    “Language models are unsupervised multitask learners,” *OpenAI blog*, vol. 1,
    no. 8, p. 9, 2019.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever *等*，“语言模型是无监督的多任务学习者”，*OpenAI
    博客*，第 1 卷，第 8 期，第 9 页，2019 年。'
- en: '[48] P. Chen, W. Liu, C.-Y. Hsieh, G. Chen, and S. Zhang, “Utilizing edge features
    in graph neural networks via variational information maximization,” *arXiv preprint
    arXiv:1906.05488*, 2019.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] P. Chen, W. Liu, C.-Y. Hsieh, G. Chen, 和 S. Zhang，“通过变分信息最大化在图神经网络中利用边缘特征”，*arXiv
    预印本 arXiv:1906.05488*，2019 年。'
- en: '[49] M. Olivecrona, T. Blaschke, O. Engkvist, and H. Chen, “Molecular de-novo
    design through deep reinforcement learning,” *Journal of cheminformatics*, vol. 9,
    no. 1, pp. 1–14, 2017.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] M. Olivecrona, T. Blaschke, O. Engkvist, 和 H. Chen，“通过深度强化学习进行分子新设计”，*化学信息学期刊*，第
    9 卷，第 1 期，第 1–14 页，2017 年。'
- en: '[50] M. H. Segler, T. Kogej, C. Tyrchan, and M. P. Waller, “Generating focused
    molecule libraries for drug discovery with recurrent neural networks,” *ACS central
    science*, vol. 4, no. 1, pp. 120–131, 2018.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] M. H. Segler, T. Kogej, C. Tyrchan, 和 M. P. Waller，“通过递归神经网络生成针对药物发现的聚焦分子库”，*ACS
    中央科学*，第 4 卷，第 1 期，第 120–131 页，2018 年。'
- en: '[51] A. Gupta, A. T. Müller, B. J. Huisman, J. A. Fuchs, P. Schneider, and
    G. Schneider, “Generative recurrent networks for de novo drug design,” *Molecular
    informatics*, vol. 37, no. 1-2, p. 1700111, 2018.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] A. Gupta, A. T. Müller, B. J. Huisman, J. A. Fuchs, P. Schneider, 和 G.
    Schneider，“用于新药设计的生成递归网络”，*分子信息学*，第 37 卷，第 1-2 期，第 1700111 页，2018 年。'
- en: '[52] F. Grisoni, M. Moret, R. Lingwood, and G. Schneider, “Bidirectional molecule
    generation with recurrent neural networks,” *Journal of chemical information and
    modeling*, vol. 60, no. 3, pp. 1175–1183, 2020.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] F. Grisoni, M. Moret, R. Lingwood, 和 G. Schneider，“使用递归神经网络的双向分子生成”，*化学信息与建模期刊*，第
    60 卷，第 3 期，第 1175–1183 页，2020 年。'
- en: '[53] E. J. Bjerrum and R. Threlfall, “Molecular generation with recurrent neural
    networks (rnns),” *arXiv preprint arXiv:1705.04612*, 2017.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] E. J. Bjerrum 和 R. Threlfall，“使用递归神经网络 (rnns) 的分子生成”，*arXiv 预印本 arXiv:1705.04612*，2017
    年。'
- en: '[54] P. Ertl, R. Lewis, E. Martin, and V. Polyakov, “In silico generation of
    novel, drug-like chemical matter using the lstm neural network,” *arXiv preprint
    arXiv:1712.07449*, 2017.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] P. Ertl, R. Lewis, E. Martin, 和 V. Polyakov，“使用 LSTM 神经网络进行计算机生成的新型药物化学物质”，*arXiv
    预印本 arXiv:1712.07449*，2017 年。'
- en: '[55] Y. Schiff, V. Chenthamarakshan, S. C. Hoffman, K. N. Ramamurthy, and P. Das,
    “Augmenting molecular deep generative models with topological data analysis representations,”
    in *ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal
    Processing (ICASSP)*.   IEEE, 2022, pp. 3783–3787.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Y. Schiff, V. Chenthamarakshan, S. C. Hoffman, K. N. Ramamurthy, 和 P.
    Das, “通过拓扑数据分析表示增强分子深度生成模型，” 见 *ICASSP 2022-2022 IEEE 国际声学、语音与信号处理会议 (ICASSP)*。IEEE，2022年，第3783–3787页。'
- en: '[56] Z. Alperstein, A. Cherkasov, and J. T. Rolfe, “All smiles variational
    autoencoder,” *arXiv preprint arXiv:1905.13343*, 2019.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Z. Alperstein, A. Cherkasov, 和 J. T. Rolfe, “所有 smiles 变分自编码器，” *arXiv
    预印本 arXiv:1905.13343*，2019年。'
- en: '[57] A. Nigam, P. Friederich, M. Krenn, and A. Aspuru-Guzik, “Augmenting genetic
    algorithms with deep neural networks for exploring the chemical space,” *arXiv
    preprint arXiv:1909.11655*, 2019.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] A. Nigam, P. Friederich, M. Krenn, 和 A. Aspuru-Guzik, “通过深度神经网络增强遗传算法以探索化学空间，”
    *arXiv 预印本 arXiv:1909.11655*，2019年。'
- en: '[58] H. Moss, D. Leslie, D. Beck, J. Gonzalez, and P. Rayson, “Boss: Bayesian
    optimization over string spaces,” *Advances in neural information processing systems*,
    vol. 33, pp. 15 476–15 486, 2020.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] H. Moss, D. Leslie, D. Beck, J. Gonzalez, 和 P. Rayson, “Boss: 在字符串空间上的贝叶斯优化，”
    *神经信息处理系统进展*，第33卷，第15,476–15,486页，2020年。'
- en: '[59] W. Jin, K. Yang, R. Barzilay, and T. Jaakkola, “Learning multimodal graph-to-graph
    translation for molecular optimization,” *arXiv preprint arXiv:1812.01070*, 2018.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] W. Jin, K. Yang, R. Barzilay, 和 T. Jaakkola, “学习用于分子优化的多模态图对图翻译，” *arXiv
    预印本 arXiv:1812.01070*，2018年。'
- en: '[60] W. Jin, R. Barzilay, and T. Jaakkola, “Hierarchical generation of molecular
    graphs using structural motifs,” in *ICML*.   PMLR, 2020, pp. 4839–4848.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] W. Jin, R. Barzilay, 和 T. Jaakkola, “使用结构模体的分子图层次生成，” 见 *ICML*。PMLR，2020年，第4839–4848页。'
- en: '[61] K. Maziarz, H. Jackson-Flux, P. Cameron, F. Sirockin, N. Schneider, N. Stiefl,
    M. Segler, and M. Brockschmidt, “Learning to extend molecular scaffolds with structural
    motifs,” *arXiv preprint arXiv:2103.03864*, 2021.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] K. Maziarz, H. Jackson-Flux, P. Cameron, F. Sirockin, N. Schneider, N.
    Stiefl, M. Segler, 和 M. Brockschmidt, “学习扩展分子骨架与结构模体，” *arXiv 预印本 arXiv:2103.03864*，2021年。'
- en: '[62] J. You, B. Liu, Z. Ying, V. Pande, and J. Leskovec, “Graph convolutional
    policy network for goal-directed molecular graph generation,” *Advances in neural
    information processing systems*, vol. 31, 2018.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] J. You, B. Liu, Z. Ying, V. Pande, 和 J. Leskovec, “用于目标导向分子图生成的图卷积策略网络，”
    *神经信息处理系统进展*，第31卷，2018年。'
- en: '[63] S. Yang, D. Hwang, S. Lee, S. Ryu, and S. J. Hwang, “Hit and lead discovery
    with explorative rl and fragment-based molecule generation,” *Advances in Neural
    Information Processing Systems*, vol. 34, 2021.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] S. Yang, D. Hwang, S. Lee, S. Ryu, 和 S. J. Hwang, “通过探索性 RL 和基于片段的分子生成发现命中和先导化合物，”
    *神经信息处理系统进展*，第34卷，2021年。'
- en: '[64] W. Jin, R. Barzilay, and T. Jaakkola, “Multi-objective molecule generation
    using interpretable substructures,” in *ICML*.   PMLR, 2020, pp. 4849–4859.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] W. Jin, R. Barzilay, 和 T. Jaakkola, “使用可解释子结构的多目标分子生成，” 见 *ICML*。PMLR，2020年，第4849–4859页。'
- en: '[65] B. Chen, T. Wang, C. Li, H. Dai, and L. Song, “Molecule optimization by
    explainable evolution,” in *ICLR*, 2021.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] B. Chen, T. Wang, C. Li, H. Dai, 和 L. Song, “通过可解释进化进行分子优化，” 见 *ICLR*，2021年。'
- en: '[66] Y. Xie, C. Shi, H. Zhou, Y. Yang, W. Zhang, Y. Yu, and L. Li, “Mars: Markov
    molecular sampling for multi-objective drug discovery,” *arXiv preprint arXiv:2103.10432*,
    2021.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] Y. Xie, C. Shi, H. Zhou, Y. Yang, W. Zhang, Y. Yu, 和 L. Li, “Mars: 用于多目标药物发现的马尔可夫分子采样，”
    *arXiv 预印本 arXiv:2103.10432*，2021年。'
- en: '[67] C. Andrieu, N. De Freitas, A. Doucet, and M. I. Jordan, “An introduction
    to mcmc for machine learning,” *Machine learning*, vol. 50, no. 1, pp. 5–43, 2003.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] C. Andrieu, N. De Freitas, A. Doucet, 和 M. I. Jordan, “机器学习中的 MCMC 入门，”
    *机器学习*，第50卷，第1期，第5–43页，2003年。'
- en: '[68] T. Fu, W. Gao, C. Xiao, J. Yasonik, C. W. Coley, and J. Sun, “Differentiable
    scaffolding tree for molecular optimization,” *arXiv preprint arXiv:2109.10469*,
    2021.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] T. Fu, W. Gao, C. Xiao, J. Yasonik, C. W. Coley, 和 J. Sun, “用于分子优化的可微分骨架树，”
    *arXiv 预印本 arXiv:2109.10469*，2021年。'
- en: '[69] Z. Zhou, S. Kearnes, L. Li, R. N. Zare, and P. Riley, “Optimization of
    molecules via deep reinforcement learning,” *Scientific reports*, vol. 9, no. 1,
    pp. 1–10, 2019.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] Z. Zhou, S. Kearnes, L. Li, R. N. Zare, 和 P. Riley, “通过深度强化学习优化分子，” *科学报告*，第9卷，第1期，第1–10页，2019年。'
- en: '[70] C. Shi, M. Xu, Z. Zhu, W. Zhang, M. Zhang, and J. Tang, “Graphaf: a flow-based
    autoregressive model for molecular graph generation,” *arXiv preprint arXiv:2001.09382*,
    2020.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] C. Shi, M. Xu, Z. Zhu, W. Zhang, M. Zhang, 和 J. Tang, “Graphaf: 用于分子图生成的基于流的自回归模型，”
    *arXiv 预印本 arXiv:2001.09382*，2020年。'
- en: '[71] K. Korovina, S. Xu, K. Kandasamy, W. Neiswanger, B. Poczos, J. Schneider,
    and E. Xing, “Chembo: Bayesian optimization of small organic molecules with synthesizable
    recommendations,” in *International Conference on Artificial Intelligence and
    Statistics*.   PMLR, 2020, pp. 3393–3403.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] K. Korovina, S. Xu, K. Kandasamy, W. Neiswanger, B. Poczos, J. Schneider,
    和 E. Xing, “Chembo: 小型有机分子的贝叶斯优化与可合成推荐，” 见 *International Conference on Artificial
    Intelligence and Statistics*。PMLR，2020 年，第 3393–3403 页。'
- en: '[72] Z. Chen, X. Fang, F. Wang, X. Fan, H. Wu, and H. Wang, “Cells: Cost-effective
    evolution in latent space for goal-directed molecular generation,” *arXiv preprint
    arXiv:2112.00905*, 2021.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] Z. Chen, X. Fang, F. Wang, X. Fan, H. Wu, 和 H. Wang, “Cells: 成本效益的潜在空间进化用于目标导向的分子生成，”
    *arXiv preprint arXiv:2112.00905*，2021 年。'
- en: '[73] Y. Wu, N. Choma, A. Chen, M. Cashman, É. T. Prates, M. Shah, V. G. M.
    Vergara, A. Clyde, T. S. Brettin, W. A. de Jong *et al.*, “Spatial graph attention
    and curiosity-driven policy for antiviral drug discovery,” *arXiv preprint arXiv:2106.02190*,
    2021.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] Y. Wu, N. Choma, A. Chen, M. Cashman, É. T. Prates, M. Shah, V. G. M.
    Vergara, A. Clyde, T. S. Brettin, W. A. de Jong *等*，“用于抗病毒药物发现的空间图注意力和好奇心驱动策略，”
    *arXiv preprint arXiv:2106.02190*，2021 年。'
- en: '[74] G. N. Simm and J. M. Hernández-Lobato, “A generative model for molecular
    distance geometry,” *arXiv preprint arXiv:1909.11459*, 2019.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] G. N. Simm 和 J. M. Hernández-Lobato, “用于分子距离几何的生成模型，” *arXiv preprint
    arXiv:1909.11459*，2019 年。'
- en: '[75] M. Xu, W. Wang, S. Luo, C. Shi, Y. Bengio, R. Gomez-Bombarelli, and J. Tang,
    “An end-to-end framework for molecular conformation generation via bilevel programming,”
    in *ICML*.   PMLR, 2021, pp. 11 537–11 547.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] M. Xu, W. Wang, S. Luo, C. Shi, Y. Bengio, R. Gomez-Bombarelli, 和 J. Tang,
    “通过双层编程生成分子构象的端到端框架，” 见 *ICML*。PMLR，2021 年，第 11 537–11 547 页。'
- en: '[76] C. Shi, S. Luo, M. Xu, and J. Tang, “Learning gradient fields for molecular
    conformation generation,” in *ICML*.   PMLR, 2021, pp. 9558–9568.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] C. Shi, S. Luo, M. Xu, 和 J. Tang, “学习梯度场用于分子构象生成，” 见 *ICML*。PMLR，2021
    年，第 9558–9568 页。'
- en: '[77] J. Zhu, Y. Xia, C. Liu, L. Wu, S. Xie, T. Wang, Y. Wang, W. Zhou, T. Qin,
    H. Li *et al.*, “Direct molecular conformation generation,” *arXiv preprint arXiv:2202.01356*,
    2022.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] J. Zhu, Y. Xia, C. Liu, L. Wu, S. Xie, T. Wang, Y. Wang, W. Zhou, T. Qin,
    H. Li *等*，“直接分子构象生成，” *arXiv preprint arXiv:2202.01356*，2022 年。'
- en: '[78] M. Xu, L. Yu, Y. Song, C. Shi, S. Ermon, and J. Tang, “Geodiff: A geometric
    diffusion model for molecular conformation generation,” *arXiv preprint arXiv:2203.02923*,
    2022.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] M. Xu, L. Yu, Y. Song, C. Shi, S. Ermon, 和 J. Tang, “Geodiff: 一种几何扩散模型用于分子构象生成，”
    *arXiv preprint arXiv:2203.02923*，2022 年。'
- en: '[79] Y. Luo and S. Ji, “An autoregressive flow model for 3d molecular geometry
    generation from scratch,” in *ICLR*, 2021.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] Y. Luo 和 S. Ji, “从头开始的 3D 分子几何生成的自回归流模型，” 见 *ICLR*，2021 年。'
- en: '[80] E. Mansimov, O. Mahmood, S. Kang, and K. Cho, “Molecular geometry prediction
    using a deep generative graph neural network,” *Scientific reports*, vol. 9, no. 1,
    pp. 1–13, 2019.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] E. Mansimov, O. Mahmood, S. Kang, 和 K. Cho, “使用深度生成图神经网络进行分子几何预测，” *Scientific
    reports*，第 9 卷，第 1 期，第 1–13 页，2019 年。'
- en: '[81] J. Guan, W. W. Qian, W.-Y. Ma, J. Ma, J. Peng *et al.*, “Energy-inspired
    molecular conformation optimization,” in *ICLR*, 2021.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] J. Guan, W. W. Qian, W.-Y. Ma, J. Ma, J. Peng *等*，“受能量启发的分子构象优化，” 见 *ICLR*，2021
    年。'
- en: '[82] M. Xu, S. Luo, Y. Bengio, J. Peng, and J. Tang, “Learning neural generative
    dynamics for molecular conformation generation,” *arXiv preprint arXiv:2102.10240*,
    2021.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] M. Xu, S. Luo, Y. Bengio, J. Peng, 和 J. Tang, “学习神经生成动态以进行分子构象生成，” *arXiv
    preprint arXiv:2102.10240*，2021 年。'
- en: '[83] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” *Neural computation*,
    vol. 9, no. 8, pp. 1735–1780, 1997.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] S. Hochreiter 和 J. Schmidhuber, “长短期记忆，” *Neural computation*，第 9 卷，第
    8 期，第 1735–1780 页，1997 年。'
- en: '[84] K. Cho, B. Van Merriënboer, D. Bahdanau, and Y. Bengio, “On the properties
    of neural machine translation: Encoder-decoder approaches,” *arXiv preprint arXiv:1409.1259*,
    2014.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] K. Cho, B. Van Merriënboer, D. Bahdanau, 和 Y. Bengio, “神经机器翻译的属性：编码器-解码器方法，”
    *arXiv preprint arXiv:1409.1259*，2014 年。'
- en: '[85] A. Mayr, G. Klambauer, T. Unterthiner, M. Steijaert, J. K. Wegner, H. Ceulemans,
    D.-A. Clevert, and S. Hochreiter, “Large-scale comparison of machine learning
    methods for drug target prediction on chembl,” *Chemical science*, vol. 9, no. 24,
    pp. 5441–5451, 2018.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] A. Mayr, G. Klambauer, T. Unterthiner, M. Steijaert, J. K. Wegner, H.
    Ceulemans, D.-A. Clevert, 和 S. Hochreiter, “针对 Chembl 上药物靶点预测的大规模机器学习方法比较，” *Chemical
    science*，第 9 卷，第 24 期，第 5441–5451 页，2018 年。'
- en: '[86] G. B. Goh, N. O. Hodas, C. Siegel, and A. Vishnu, “Smiles2vec: An interpretable
    general-purpose deep neural network for predicting chemical properties,” *arXiv
    preprint arXiv:1712.02034*, 2017.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] G. B. Goh, N. O. Hodas, C. Siegel, 和 A. Vishnu, “Smiles2vec: 一种可解释的通用深度神经网络用于预测化学性质，”
    *arXiv preprint arXiv:1712.02034*，2017 年。'
- en: '[87] C. Li, J. Feng, S. Liu, and J. Yao, “A novel molecular representation
    learning for molecular property prediction with a multiple smiles-based augmentation,”
    *Computational Intelligence and Neuroscience*, vol. 2022, 2022.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] C. Li, J. Feng, S. Liu, 和 J. Yao，"一种新型分子表征学习用于基于多重 smiles 的分子属性预测"，*计算智能与神经科学*，第
    2022 卷，2022 年。'
- en: '[88] Y. Peng, Z. Zhang, Q. Jiang, J. Guan, and S. Zhou, “Top: Towards better
    toxicity prediction by deep molecular representation learning,” in *2019 IEEE
    International Conference on Bioinformatics and Biomedicine*.   IEEE, 2019, pp.
    318–325.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] Y. Peng, Z. Zhang, Q. Jiang, J. Guan, 和 S. Zhou，"Top：通过深度分子表征学习实现更好的毒性预测"，在
    *2019 年 IEEE 国际生物信息学与生物医学会议*。IEEE，2019 年，第 318–325 页。'
- en: '[89] A. Paul, D. Jha, R. Al-Bahrani, W.-k. Liao, A. Choudhary, and A. Agrawal,
    “Chemixnet: Mixed dnn architectures for predicting chemical properties using multiple
    molecular representations,” *arXiv preprint arXiv:1811.08283*, 2018.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] A. Paul, D. Jha, R. Al-Bahrani, W.-k. Liao, A. Choudhary, 和 A. Agrawal，"Chemixnet：使用多重分子表征的混合
    DNN 架构预测化学属性"，*arXiv 预印本 arXiv:1811.08283*，2018 年。'
- en: '[90] G. B. Goh, C. Siegel, A. Vishnu, N. O. Hodas, and N. Baker, “Chemception:
    a deep neural network with minimal chemistry knowledge matches the performance
    of expert-developed qsar/qspr models,” *arXiv preprint arXiv:1706.06689*, 2017.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] G. B. Goh, C. Siegel, A. Vishnu, N. O. Hodas, 和 N. Baker，"Chemception：一个具备最少化学知识的深度神经网络与专家开发的
    QSAR/QSPR 模型的表现相匹配"，*arXiv 预印本 arXiv:1706.06689*，2017 年。'
- en: '[91] D. P. Kingma, S. Mohamed, D. Jimenez Rezende, and M. Welling, “Semi-supervised
    learning with deep generative models,” *Advances in neural information processing
    systems*, vol. 27, 2014.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] D. P. Kingma, S. Mohamed, D. Jimenez Rezende, 和 M. Welling，"使用深度生成模型的半监督学习"，*神经信息处理系统进展*，第
    27 卷，2014 年。'
- en: '[92] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
    of deep bidirectional transformers for language understanding,” *arXiv preprint
    arXiv:1810.04805*, 2018.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] J. Devlin, M.-W. Chang, K. Lee, 和 K. Toutanova，"Bert：用于语言理解的深度双向变换器预训练"，*arXiv
    预印本 arXiv:1810.04805*，2018 年。'
- en: '[93] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,
    L. Zettlemoyer, and V. Stoyanov, “Roberta: A robustly optimized bert pretraining
    approach,” *arXiv preprint arXiv:1907.11692*, 2019.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,
    L. Zettlemoyer, 和 V. Stoyanov，"Roberta：一种强优化的 BERT 预训练方法"，*arXiv 预印本 arXiv:1907.11692*，2019
    年。'
- en: '[94] D. R. Rahimovich, S. R. Abdiqayum o’g, A. S. Qaxramon o’g’li *et al.*,
    “Predicting the activity and properties of chemicals based on roberta,” in *2021
    International Conference on Information Science and Communications Technologies
    (ICISCT)*.   IEEE, 2021, pp. 1–4.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] D. R. Rahimovich, S. R. Abdiqayum o’g, A. S. Qaxramon o’g’li *等*，"基于 roberta
    的化学品活性和属性预测"，在 *2021 年信息科学与通信技术国际会议（ICISCT）*。IEEE，2021 年，第 1–4 页。'
- en: '[95] S. Chithrananda, G. Grand, and B. Ramsundar, “Chemberta: large-scale self-supervised
    pretraining for molecular property prediction,” *arXiv preprint arXiv:2010.09885*,
    2020.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] S. Chithrananda, G. Grand, 和 B. Ramsundar，"Chemberta：用于分子属性预测的大规模自监督预训练"，*arXiv
    预印本 arXiv:2010.09885*，2020 年。'
- en: '[96] T. Unterthiner, A. Mayr, G. Klambauer, M. Steijaert, J. K. Wegner, H. Ceulemans,
    and S. Hochreiter, “Deep learning as an opportunity in virtual screening,” in
    *Proceedings of the deep learning workshop at NIPS*, vol. 27, 2014, pp. 1–9.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] T. Unterthiner, A. Mayr, G. Klambauer, M. Steijaert, J. K. Wegner, H.
    Ceulemans, 和 S. Hochreiter，"深度学习在虚拟筛选中的机遇"，在 *NIPS 深度学习研讨会论文集*，第 27 卷，2014 年，第
    1–9 页。'
- en: '[97] A. Mayr, G. Klambauer, T. Unterthiner, and S. Hochreiter, “Deeptox: toxicity
    prediction using deep learning,” *Frontiers in Environmental Science*, vol. 3,
    p. 80, 2016.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] A. Mayr, G. Klambauer, T. Unterthiner, 和 S. Hochreiter，"Deeptox：使用深度学习进行毒性预测"，*环境科学前沿*，第
    3 卷，第 80 页，2016 年。'
- en: '[98] J. Schimunek, P. Seidl, L. Friedrich, D. Kuhn, F. Rippmann, S. Hochreiter,
    and G. Klambauer, “Context-enriched molecule representations improve few-shot
    drug discovery,” 2022.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] J. Schimunek, P. Seidl, L. Friedrich, D. Kuhn, F. Rippmann, S. Hochreiter,
    和 G. Klambauer，"上下文增强的分子表征改善了少量样本药物发现"，2022 年。'
- en: '[99] X. Zhang, S. Wang, F. Zhu, Z. Xu, Y. Wang, and J. Huang, “Seq3seq fingerprint:
    towards end-to-end semi-supervised deep drug discovery,” in *Proceedings of the
    2018 ACM International Conference on Bioinformatics, Computational Biology, and
    Health Informatics*, 2018, pp. 404–413.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] X. Zhang, S. Wang, F. Zhu, Z. Xu, Y. Wang, 和 J. Huang，"Seq3seq 指纹：朝着端到端的半监督深度药物发现"，在
    *2018 年 ACM 国际生物信息学、计算生物学与健康信息学会议论文集*，2018 年，第 404–413 页。'
- en: '[100] S. Wang, Y. Guo, Y. Wang, H. Sun, and J. Huang, “Smiles-bert: large scale
    unsupervised pre-training for molecular property prediction,” in *Proceedings
    of the 10th ACM international conference on bioinformatics, computational biology
    and health informatics*, 2019, pp. 429–436.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] S. Wang, Y. Guo, Y. Wang, H. Sun 和 J. Huang，“Smiles-bert：大规模无监督预训练用于分子属性预测，”
    在 *第10届ACM国际生物信息学、计算生物学和健康信息学会议论文集*，2019年，第429–436页。'
- en: '[101] R. C. Glen, A. Bender, C. H. Arnby, L. Carlsson, S. Boyer, and J. Smith,
    “Circular fingerprints: flexible molecular descriptors with applications from
    physical chemistry to adme,” *IDrugs*, vol. 9, no. 3, p. 199, 2006.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] R. C. Glen, A. Bender, C. H. Arnby, L. Carlsson, S. Boyer 和 J. Smith，“循环指纹：灵活的分子描述符，从物理化学到ADME的应用，”
    *IDrugs*，第9卷，第3期，第199页，2006年。'
- en: '[102] D. Bahdanau, K. Cho, and Y. Bengio, “Neural machine translation by jointly
    learning to align and translate,” *arXiv preprint arXiv:1409.0473*, 2014.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] D. Bahdanau, K. Cho 和 Y. Bengio，“通过联合学习对齐和翻译的神经机器翻译，” *arXiv 预印本 arXiv:1409.0473*，2014年。'
- en: '[103] T. N. Kipf and M. Welling, “Semi-supervised classification with graph
    convolutional networks,” *arXiv preprint arXiv:1609.02907*, 2016.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] T. N. Kipf 和 M. Welling，“基于图卷积网络的半监督分类，” *arXiv 预印本 arXiv:1609.02907*，2016年。'
- en: '[104] R. Ramakrishnan, P. O. Dral, M. Rupp, and O. A. Von Lilienfeld, “Quantum
    chemistry structures and properties of 134 kilo molecules,” *Scientific data*,
    vol. 1, no. 1, pp. 1–7, 2014.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] R. Ramakrishnan, P. O. Dral, M. Rupp 和 O. A. Von Lilienfeld，“134千分子量的量子化学结构和性质，”
    *科学数据*，第1卷，第1期，第1–7页，2014年。'
- en: '[105] C. Lu, Q. Liu, C. Wang, Z. Huang, P. Lin, and L. He, “Molecular property
    prediction: A multilevel quantum interactions modeling perspective,” in *Proceedings
    of the AAAI Conference on Artificial Intelligence*, vol. 33, no. 01, 2019, pp.
    1052–1060.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] C. Lu, Q. Liu, C. Wang, Z. Huang, P. Lin 和 L. He，“分子属性预测：一种多层次量子交互建模视角，”
    在 *AAAI人工智能会议论文集*，第33卷，第01期，2019年，第1052–1060页。'
- en: '[106] S. Liu, H. Wang, W. Liu, J. Lasenby, H. Guo, and J. Tang, “Pre-training
    molecular graph representation with 3d geometry,” *arXiv preprint arXiv:2110.07728*,
    2021.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] S. Liu, H. Wang, W. Liu, J. Lasenby, H. Guo 和 J. Tang，“使用3D几何进行分子图表示的预训练，”
    *arXiv 预印本 arXiv:2110.07728*，2021年。'
- en: '[107] W. Hu, B. Liu, J. Gomes, M. Zitnik, P. Liang, V. Pande, and J. Leskovec,
    “Strategies for pre-training graph neural networks,” *arXiv preprint arXiv:1905.12265*,
    2019.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] W. Hu, B. Liu, J. Gomes, M. Zitnik, P. Liang, V. Pande 和 J. Leskovec，“图神经网络预训练策略，”
    *arXiv 预印本 arXiv:1905.12265*，2019年。'
- en: '[108] X. Zeng, H. Xiang, L. Yu, J. Wang, K. Li, R. Nussinov, and F. Cheng,
    “Accurate prediction of molecular properties and drug targets using a self-supervised
    image representation learning framework,” *Nature Machine Intelligence*, pp. 1–13,
    2022.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] X. Zeng, H. Xiang, L. Yu, J. Wang, K. Li, R. Nussinov 和 F. Cheng，“使用自监督图像表示学习框架对分子属性和药物靶点进行准确预测，”
    *自然机器智能*，第1–13页，2022年。'
- en: '[109] Y. Rong, Y. Bian, T. Xu, W. Xie, Y. Wei, W. Huang, and J. Huang, “Self-supervised
    graph transformer on large-scale molecular data,” *Advances in Neural Information
    Processing Systems*, vol. 33, pp. 12 559–12 571, 2020.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] Y. Rong, Y. Bian, T. Xu, W. Xie, Y. Wei, W. Huang 和 J. Huang，“大规模分子数据上的自监督图变换器，”
    *神经信息处理系统进展*，第33卷，第12 559–12 571页，2020年。'
- en: '[110] Y. You, T. Chen, Y. Sui, T. Chen, Z. Wang, and Y. Shen, “Graph contrastive
    learning with augmentations,” *Advances in Neural Information Processing Systems*,
    vol. 33, pp. 5812–5823, 2020.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] Y. You, T. Chen, Y. Sui, T. Chen, Z. Wang 和 Y. Shen，“带增强的图对比学习，” *神经信息处理系统进展*，第33卷，第5812–5823页，2020年。'
- en: '[111] Y. Wang, J. Wang, Z. Cao, and A. Barati Farimani, “Molecular contrastive
    learning of representations via graph neural networks,” *Nature Machine Intelligence*,
    vol. 4, no. 3, pp. 279–287, 2022.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] Y. Wang, J. Wang, Z. Cao 和 A. Barati Farimani，“通过图神经网络的分子对比学习表示，” *自然机器智能*，第4卷，第3期，第279–287页，2022年。'
- en: '[112] S. Li, J. Zhou, T. Xu, D. Dou, and H. Xiong, “Geomgcl: Geometric graph
    contrastive learning for molecular property prediction,” *arXiv preprint arXiv:2109.11730*,
    2021.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] S. Li, J. Zhou, T. Xu, D. Dou 和 H. Xiong，“Geomgcl：用于分子属性预测的几何图对比学习，”
    *arXiv 预印本 arXiv:2109.11730*，2021年。'
- en: '[113] S. Liu, M. F. Demirel, and Y. Liang, “N-gram graph: Simple unsupervised
    representation for graphs, with applications to molecules,” *Advances in neural
    information processing systems*, vol. 32, 2019.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] S. Liu, M. F. Demirel 和 Y. Liang，“N-gram图：图的简单无监督表示，及其在分子中的应用，” *神经信息处理系统进展*，第32卷，2019年。'
- en: '[114] H. Altae-Tran, B. Ramsundar, A. S. Pappu, and V. Pande, “Low data drug
    discovery with one-shot learning,” *ACS central science*, vol. 3, no. 4, pp. 283–293,
    2017.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] H. Altae-Tran, B. Ramsundar, A. S. Pappu, 和 V. Pande，“通过单次学习进行低数据药物发现，”
    *ACS 中央科学*，第 3 卷，第 4 期，第 283–293 页，2017 年。'
- en: '[115] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl,
    “Neural message passing for quantum chemistry,” in *ICML*.   PMLR, 2017, pp. 1263–1272.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, 和 G. E. Dahl，“用于量子化学的神经消息传递，”发表于
    *ICML*。PMLR，2017 年，第 1263–1272 页。'
- en: '[116] Y. Liu, L. Wang, M. Liu, Y. Lin, X. Zhang, B. Oztekin, and S. Ji, “Spherical
    message passing for 3d molecular graphs,” in *ICLR*, 2021.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] Y. Liu, L. Wang, M. Liu, Y. Lin, X. Zhang, B. Oztekin, 和 S. Ji，“用于三维分子图的球面消息传递，”发表于
    *ICLR*，2021 年。'
- en: '[117] Z. Hao, C. Lu, Z. Huang, H. Wang, Z. Hu, Q. Liu, E. Chen, and C. Lee,
    “Asgn: An active semi-supervised graph neural network for molecular property prediction,”
    in *Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery
    & Data Mining*, 2020, pp. 731–752.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] Z. Hao, C. Lu, Z. Huang, H. Wang, Z. Hu, Q. Liu, E. Chen, 和 C. Lee，“Asgn:
    一种用于分子属性预测的主动半监督图神经网络，”发表于 *第 26 届 ACM SIGKDD 国际知识发现与数据挖掘会议论文集*，2020 年，第 731–752
    页。'
- en: '[118] V. P. Dwivedi, A. T. Luu, T. Laurent, Y. Bengio, and X. Bresson, “Graph
    neural networks with learnable structural and positional representations,” *arXiv
    preprint arXiv:2110.07875*, 2021.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] V. P. Dwivedi, A. T. Luu, T. Laurent, Y. Bengio, 和 X. Bresson，“具有可学习结构和位置表示的图神经网络，”
    *arXiv 预印本 arXiv:2110.07875*，2021 年。'
- en: '[119] P. Velickovic, W. Fedus, W. L. Hamilton, P. Liò, Y. Bengio, and R. D.
    Hjelm, “Deep graph infomax.” *ICLR (Poster)*, vol. 2, no. 3, p. 4, 2019.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] P. Velickovic, W. Fedus, W. L. Hamilton, P. Liò, Y. Bengio, 和 R. D. Hjelm，“深度图信息最大化。”
    *ICLR（海报）*，第 2 卷，第 3 期，第 4 页，2019 年。'
- en: '[120] R. D. Hjelm, A. Fedorov, S. Lavoie-Marchildon, K. Grewal, P. Bachman,
    A. Trischler, and Y. Bengio, “Learning deep representations by mutual information
    estimation and maximization,” *arXiv preprint arXiv:1808.06670*, 2018.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] R. D. Hjelm, A. Fedorov, S. Lavoie-Marchildon, K. Grewal, P. Bachman,
    A. Trischler, 和 Y. Bengio，“通过互信息估计和最大化学习深度表示，” *arXiv 预印本 arXiv:1808.06670*，2018
    年。'
- en: '[121] K. Xu, W. Hu, J. Leskovec, and S. Jegelka, “How powerful are graph neural
    networks?” *arXiv preprint arXiv:1810.00826*, 2018.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] K. Xu, W. Hu, J. Leskovec, 和 S. Jegelka，“图神经网络有多强大？” *arXiv 预印本 arXiv:1810.00826*，2018
    年。'
- en: '[122] F.-Y. Sun, J. Hoffmann, V. Verma, and J. Tang, “Infograph: Unsupervised
    and semi-supervised graph-level representation learning via mutual information
    maximization,” *arXiv preprint arXiv:1908.01000*, 2019.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] F.-Y. Sun, J. Hoffmann, V. Verma, 和 J. Tang，“Infograph：通过互信息最大化进行无监督和半监督图级表示学习，”
    *arXiv 预印本 arXiv:1908.01000*，2019 年。'
- en: '[123] Z. Li, S. Yang, G. Song, and L. Cai, “Conformation-guided molecular representation
    with hamiltonian neural networks,” in *ICLR*, 2020.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] Z. Li, S. Yang, G. Song, 和 L. Cai，“基于哈密顿神经网络的构象引导分子表示，”发表于 *ICLR*，2020
    年。'
- en: '[124] S. Yang, Z. Li, G. Song, and L. Cai, “Deep molecular representation learning
    via fusing physical and chemical information,” *Advances in Neural Information
    Processing Systems*, vol. 34, 2021.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] S. Yang, Z. Li, G. Song, 和 L. Cai，“通过融合物理和化学信息进行深度分子表示学习，” *神经信息处理系统进展*，第
    34 卷，2021 年。'
- en: '[125] Ł. Maziarka, T. Danel, S. Mucha, K. Rataj, J. Tabor, and S. Jastrzębski,
    “Molecule attention transformer,” *arXiv preprint arXiv:2002.08264*, 2020.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] Ł. Maziarka, T. Danel, S. Mucha, K. Rataj, J. Tabor, 和 S. Jastrzębski，“分子注意力变换器，”
    *arXiv 预印本 arXiv:2002.08264*，2020 年。'
- en: '[126] M. H. Segler and M. P. Waller, “Neural-symbolic machine learning for
    retrosynthesis and reaction prediction,” *Chemistry–A European Journal*, vol. 23,
    no. 25, pp. 5966–5971, 2017.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] M. H. Segler 和 M. P. Waller，“用于逆合成和反应预测的神经符号机器学习，” *化学–欧洲杂志*，第 23 卷，第
    25 期，第 5966–5971 页，2017 年。'
- en: '[127] C. W. Coley, L. Rogers, W. H. Green, and K. F. Jensen, “Computer-assisted
    retrosynthesis based on molecular similarity,” *ACS central science*, vol. 3,
    no. 12, pp. 1237–1245, 2017.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] C. W. Coley, L. Rogers, W. H. Green, 和 K. F. Jensen，“基于分子相似性的计算机辅助逆合成，”
    *ACS 中央科学*，第 3 卷，第 12 期，第 1237–1245 页，2017 年。'
- en: '[128] J. L. Baylon, N. A. Cilfone, J. R. Gulcher, and T. W. Chittenden, “Enhancing
    retrosynthetic reaction prediction with deep learning using multiscale reaction
    classification,” *Journal of chemical information and modeling*, vol. 59, no. 2,
    pp. 673–688, 2019.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] J. L. Baylon, N. A. Cilfone, J. R. Gulcher, 和 T. W. Chittenden，“利用多尺度反应分类增强逆合成反应预测的深度学习，”
    *化学信息与建模杂志*，第 59 卷，第 2 期，第 673–688 页，2019 年。'
- en: '[129] M. H. Segler, M. Preuss, and M. P. Waller, “Planning chemical syntheses
    with deep neural networks and symbolic ai,” *Nature*, vol. 555, no. 7698, pp.
    604–610, 2018.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] M. H. Segler, M. Preuss, 和 M. P. Waller，“使用深度神经网络和符号人工智能规划化学合成，” *自然*，第
    555 卷，第 7698 期，第 604–610 页，2018 年。'
- en: '[130] P. Seidl, P. Renz, N. Dyubankova, P. Neves, J. Verhoeven, J. K. Wegner,
    M. Segler, S. Hochreiter, and G. Klambauer, “Improving few-and zero-shot reaction
    template prediction using modern hopfield networks,” *Journal of chemical information
    and modeling*, vol. 62, no. 9, pp. 2111–2120, 2022.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] P. Seidl, P. Renz, N. Dyubankova, P. Neves, J. Verhoeven, J. K. Wegner,
    M. Segler, S. Hochreiter, 和 G. Klambauer, “使用现代霍普菲尔德网络改进少样本和零样本反应模板预测,” *化学信息与建模期刊*,
    vol. 62, no. 9, pp. 2111–2120, 2022。'
- en: '[131] H. Dai, C. Li, C. Coley, B. Dai, and L. Song, “Retrosynthesis prediction
    with conditional graph logic network,” *Advances in Neural Information Processing
    Systems*, vol. 32, 2019.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] H. Dai, C. Li, C. Coley, B. Dai, 和 L. Song, “使用条件图逻辑网络进行回溯合成预测,” *神经信息处理系统进展*,
    vol. 32, 2019。'
- en: '[132] S. Chen and Y. Jung, “Deep retrosynthetic reaction prediction using local
    reactivity and global attention,” *JACS Au*, vol. 1, no. 10, pp. 1612–1620, 2021.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] S. Chen 和 Y. Jung, “使用局部反应性和全局注意力的深度回溯合成反应预测,” *JACS Au*, vol. 1, no.
    10, pp. 1612–1620, 2021。'
- en: '[133] B. Liu, B. Ramsundar, P. Kawthekar, J. Shi, J. Gomes, Q. Luu Nguyen,
    S. Ho, J. Sloane, P. Wender, and V. Pande, “Retrosynthetic reaction prediction
    using neural sequence-to-sequence models,” *ACS central science*, vol. 3, no. 10,
    pp. 1103–1113, 2017.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] B. Liu, B. Ramsundar, P. Kawthekar, J. Shi, J. Gomes, Q. Luu Nguyen,
    S. Ho, J. Sloane, P. Wender, 和 V. Pande, “使用神经序列到序列模型进行回溯合成反应预测,” *ACS central
    science*, vol. 3, no. 10, pp. 1103–1113, 2017。'
- en: '[134] P. Karpov, G. Godin, and I. V. Tetko, “A transformer model for retrosynthesis,”
    in *International Conference on Artificial Neural Networks*.   Springer, 2019,
    pp. 817–830.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] P. Karpov, G. Godin, 和 I. V. Tetko, “用于回溯合成的变换器模型,” 在 *国际人工神经网络会议*. Springer,
    2019, pp. 817–830。'
- en: '[135] B. Chen, T. Shen, T. S. Jaakkola, and R. Barzilay, “Learning to make
    generalizable and diverse predictions for retrosynthesis,” *arXiv preprint arXiv:1910.09688*,
    2019.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] B. Chen, T. Shen, T. S. Jaakkola, 和 R. Barzilay, “学习生成可推广和多样化的回溯合成预测,”
    *arXiv 预印本 arXiv:1910.09688*, 2019。'
- en: '[136] K. Ishiguro, K. Ujihara, R. Sawada, H. Akita, and M. Kotera, “Data transfer
    approaches to improve seq-to-seq retrosynthesis,” *arXiv preprint arXiv:2010.00792*,
    2020.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] K. Ishiguro, K. Ujihara, R. Sawada, H. Akita, 和 M. Kotera, “数据迁移方法以改进
    seq-to-seq 回溯合成,” *arXiv 预印本 arXiv:2010.00792*, 2020。'
- en: '[137] S. Zheng, J. Rao, Z. Zhang, J. Xu, and Y. Yang, “Predicting retrosynthetic
    reactions using self-corrected transformer neural networks,” *Journal of chemical
    information and modeling*, vol. 60, no. 1, pp. 47–55, 2019.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] S. Zheng, J. Rao, Z. Zhang, J. Xu, 和 Y. Yang, “使用自我纠正变换器神经网络预测回溯合成反应,”
    *化学信息与建模期刊*, vol. 60, no. 1, pp. 47–55, 2019。'
- en: '[138] M. Zhao, L. Fang, L. Tan, J.-G. Lou, and Y. Lepage, “Leveraging reaction-aware
    substructures for retrosynthesis and reaction prediction,” *arXiv preprint arXiv:2204.05919*,
    2022.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] M. Zhao, L. Fang, L. Tan, J.-G. Lou, 和 Y. Lepage, “利用反应感知子结构进行回溯合成和反应预测,”
    *arXiv 预印本 arXiv:2204.05919*, 2022。'
- en: '[139] M. Sacha, M. Błaz, P. Byrski, P. Dabrowski-Tumanski, M. Chrominski, R. Loska,
    P. Włodarczyk-Pruszynski, and S. Jastrzebski, “Molecule edit graph attention network:
    modeling chemical reactions as sequences of graph edits,” *Journal of Chemical
    Information and Modeling*, vol. 61, no. 7, pp. 3273–3284, 2021.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] M. Sacha, M. Błaz, P. Byrski, P. Dabrowski-Tumanski, M. Chrominski, R.
    Loska, P. Włodarczyk-Pruszynski, 和 S. Jastrzebski, “分子编辑图注意网络: 将化学反应建模为图编辑序列,”
    *化学信息与建模期刊*, vol. 61, no. 7, pp. 3273–3284, 2021。'
- en: '[140] C. Shi, M. Xu, H. Guo, M. Zhang, and J. Tang, “A graph to graphs framework
    for retrosynthesis prediction,” in *ICML*.   PMLR, 2020, pp. 8818–8827.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] C. Shi, M. Xu, H. Guo, M. Zhang, 和 J. Tang, “用于回溯合成预测的图到图框架,” 在 *ICML*.
    PMLR, 2020, pp. 8818–8827。'
- en: '[141] V. R. Somnath, C. Bunne, C. Coley, A. Krause, and R. Barzilay, “Learning
    graph models for retrosynthesis prediction,” *Advances in Neural Information Processing
    Systems*, vol. 34, 2021.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] V. R. Somnath, C. Bunne, C. Coley, A. Krause, 和 R. Barzilay, “学习图模型进行回溯合成预测,”
    *神经信息处理系统进展*, vol. 34, 2021。'
- en: '[142] Z. Gao, C. Tan, L. Wu, and S. Z. Li, “Semiretro: Semi-template framework
    boosts deep retrosynthesis prediction,” *arXiv preprint arXiv:2202.08205*, 2022.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] Z. Gao, C. Tan, L. Wu, 和 S. Z. Li, “Semiretro: 半模板框架提升深度回溯合成预测,” *arXiv
    预印本 arXiv:2202.08205*, 2022。'
- en: '[143] C. Yan, Q. Ding, P. Zhao, S. Zheng, J. Yang, Y. Yu, and J. Huang, “Retroxpert:
    Decompose retrosynthesis prediction like a chemist,” *Advances in Neural Information
    Processing Systems*, vol. 33, pp. 11 248–11 258, 2020.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] C. Yan, Q. Ding, P. Zhao, S. Zheng, J. Yang, Y. Yu, 和 J. Huang, “Retroxpert:
    像化学家一样分解回溯合成预测,” *神经信息处理系统进展*, vol. 33, pp. 11 248–11 258, 2020。'
- en: '[144] R. Sun, H. Dai, L. Li, S. Kearnes, and B. Dai, “Energy-based view of
    retrosynthesis,” *arXiv preprint arXiv:2007.13437*, 2020.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] R. Sun, H. Dai, L. Li, S. Kearnes, 和 B. Dai，“基于能量的回溯合成视角，” *arXiv预印本arXiv:2007.13437*，2020年。'
- en: '[145] S.-W. Seo, Y. Y. Song, J. Y. Yang, S. Bae, H. Lee, J. Shin, S. J. Hwang,
    and E. Yang, “Gta: Graph truncated attention for retrosynthesis,” in *Proceedings
    of the AAAI Conference on Artificial Intelligence*, vol. 35, no. 1, 2021, pp.
    531–539.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] S.-W. Seo, Y. Y. Song, J. Y. Yang, S. Bae, H. Lee, J. Shin, S. J. Hwang,
    和 E. Yang，“GTA：用于回溯合成的图截断注意力，” 在 *AAAI人工智能会议论文集*，第35卷，第1期，2021年，页码531–539。'
- en: '[146] Y. Wan, B. Liao, C.-Y. Hsieh, and S. Zhang, “Retroformer: Pushing the
    limits of interpretable end-to-end retrosynthesis transformer,” *arXiv preprint
    arXiv:2201.12475*, 2022.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] Y. Wan, B. Liao, C.-Y. Hsieh, 和 S. Zhang，“Retroformer：推动可解释的端到端回溯合成变换器的极限，”
    *arXiv预印本arXiv:2201.12475*，2022年。'
- en: '[147] J. N. Wei, D. Duvenaud, and A. Aspuru-Guzik, “Neural networks for the
    prediction of organic chemistry reactions,” *ACS central science*, vol. 2, no. 10,
    pp. 725–732, 2016.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] J. N. Wei, D. Duvenaud, 和 A. Aspuru-Guzik，“用于预测有机化学反应的神经网络，” *ACS Central
    Science*，第2卷，第10期，页码725–732，2016年。'
- en: '[148] C. W. Coley, R. Barzilay, T. S. Jaakkola, W. H. Green, and K. F. Jensen,
    “Prediction of organic reaction outcomes using machine learning,” *ACS central
    science*, vol. 3, no. 5, pp. 434–443, 2017.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] C. W. Coley, R. Barzilay, T. S. Jaakkola, W. H. Green, 和 K. F. Jensen，“使用机器学习预测有机反应结果，”
    *ACS Central Science*，第3卷，第5期，页码434–443，2017年。'
- en: '[149] M. H. Segler and M. P. Waller, “Modelling chemical reasoning to predict
    and invent reactions,” *Chemistry–A European Journal*, vol. 23, no. 25, pp. 6118–6128,
    2017.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] M. H. Segler 和 M. P. Waller，“建模化学推理以预测和发明反应，” *化学–欧洲杂志*，第23卷，第25期，页码6118–6128，2017年。'
- en: '[150] W. Jin, C. Coley, R. Barzilay, and T. Jaakkola, “Predicting organic reaction
    outcomes with weisfeiler-lehman network,” *Advances in neural information processing
    systems*, vol. 30, 2017.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] W. Jin, C. Coley, R. Barzilay, 和 T. Jaakkola，“使用Weisfeiler-Lehman网络预测有机反应结果，”
    *神经信息处理系统进展*，第30卷，2017年。'
- en: '[151] C. W. Coley, W. Jin, L. Rogers, T. F. Jamison, T. S. Jaakkola, W. H.
    Green, R. Barzilay, and K. F. Jensen, “A graph-convolutional neural network model
    for the prediction of chemical reactivity,” *Chemical science*, vol. 10, no. 2,
    pp. 370–377, 2019.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] C. W. Coley, W. Jin, L. Rogers, T. F. Jamison, T. S. Jaakkola, W. H.
    Green, R. Barzilay, 和 K. F. Jensen，“用于化学反应预测的图卷积神经网络模型，” *Chemical Science*，第10卷，第2期，页码370–377，2019年。'
- en: '[152] W. W. Qian, N. T. Russell, C. L. Simons, Y. Luo, M. D. Burke, and J. Peng,
    “Integrating deep neural networks and symbolic inference for organic reactivity
    prediction,” 2020.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] W. W. Qian, N. T. Russell, C. L. Simons, Y. Luo, M. D. Burke, 和 J. Peng，“将深度神经网络与符号推理结合用于有机反应性预测，”
    2020年。'
- en: '[153] J. Bradshaw, M. J. Kusner, B. Paige, M. H. Segler, and J. M. Hernández-Lobato,
    “A generative model for electron paths,” *arXiv preprint arXiv:1805.10970*, 2018.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] J. Bradshaw, M. J. Kusner, B. Paige, M. H. Segler, 和 J. M. Hernández-Lobato，“电子路径生成模型，”
    *arXiv预印本arXiv:1805.10970*，2018年。'
- en: '[154] K. Do, T. Tran, and S. Venkatesh, “Graph transformation policy network
    for chemical reaction prediction,” in *Proceedings of the 25th ACM SIGKDD International
    Conference on Knowledge Discovery & Data Mining*, 2019, pp. 750–760.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] K. Do, T. Tran, 和 S. Venkatesh，“用于化学反应预测的图变换策略网络，” 在 *第25届ACM SIGKDD国际知识发现与数据挖掘会议论文集*，2019年，页码750–760。'
- en: '[155] H. Bi, H. Wang, C. Shi, C. Coley, J. Tang, and H. Guo, “Non-autoregressive
    electron redistribution modeling for reaction prediction,” in *ICML*.   PMLR,
    2021, pp. 904–913.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] H. Bi, H. Wang, C. Shi, C. Coley, J. Tang, 和 H. Guo，“用于反应预测的非自回归电子重分配建模，”
    在 *ICML*。 PMLR，2021年，页码904–913。'
- en: '[156] P. Schwaller, T. Gaudin, D. Lanyi, C. Bekas, and T. Laino, ““found in
    translation”: predicting outcomes of complex organic chemistry reactions using
    neural sequence-to-sequence models,” *Chemical science*, vol. 9, no. 28, pp. 6091–6098,
    2018.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] P. Schwaller, T. Gaudin, D. Lanyi, C. Bekas, 和 T. Laino，“‘翻译中的发现’：使用神经序列到序列模型预测复杂有机化学反应的结果，”
    *Chemical Science*，第9卷，第28期，页码6091–6098，2018年。'
- en: '[157] S. Kim, J. Chen, T. Cheng, A. Gindulyte, J. He, S. He, Q. Li, B. A. Shoemaker,
    P. A. Thiessen, B. Yu *et al.*, “Pubchem in 2021: new data content and improved
    web interfaces,” *Nucleic acids research*, vol. 49, no. D1, pp. D1388–D1395, 2021.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] S. Kim, J. Chen, T. Cheng, A. Gindulyte, J. He, S. He, Q. Li, B. A. Shoemaker,
    P. A. Thiessen, B. Yu *等*，“2021年的Pubchem：新数据内容和改进的网络界面，” *Nucleic Acids Research*，第49卷，第D1期，页码D1388–D1395，2021年。'
- en: '[158] A. Gaulton, L. J. Bellis, A. P. Bento, J. Chambers, M. Davies, A. Hersey,
    Y. Light, S. McGlinchey, D. Michalovich, B. Al-Lazikani *et al.*, “Chembl: a large-scale
    bioactivity database for drug discovery,” *Nucleic acids research*, vol. 40, no. D1,
    pp. D1100–D1107, 2012.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] A. Gaulton, L. J. Bellis, A. P. Bento, J. Chambers, M. Davies, A. Hersey,
    Y. Light, S. McGlinchey, D. Michalovich, B. Al-Lazikani *等*，“Chembl：一个用于药物发现的大规模生物活性数据库，”
    *核酸研究*，第40卷，第D1期，页D1100–D1107，2012年。'
- en: '[159] T. Sterling and J. J. Irwin, “Zinc 15–ligand discovery for everyone,”
    *Journal of chemical information and modeling*, vol. 55, no. 11, pp. 2324–2337,
    2015.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[159] T. Sterling 和 J. J. Irwin，“锌 15–配体发现，适用于所有人，” *化学信息与建模期刊*，第55卷，第11期，页2324–2337，2015年。'
- en: '[160] T. Fink, H. Bruggesser, and J.-L. Reymond, “Virtual exploration of the
    small-molecule chemical universe below 160 daltons,” *Angewandte Chemie International
    Edition*, vol. 44, no. 10, pp. 1504–1508, 2005.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[160] T. Fink, H. Bruggesser 和 J.-L. Reymond，“160 daltons 以下的小分子化学宇宙的虚拟探索，”
    *应用化学国际版*，第44卷，第10期，页1504–1508，2005年。'
- en: '[161] T. Fink and J.-L. Reymond, “Virtual exploration of the chemical universe
    up to 11 atoms of c, n, o, f: assembly of 26.4 million structures (110.9 million
    stereoisomers) and analysis for new ring systems, stereochemistry, physicochemical
    properties, compound classes, and drug discovery,” *Journal of chemical information
    and modeling*, vol. 47, no. 2, pp. 342–353, 2007.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[161] T. Fink 和 J.-L. Reymond，“对包含 11 个 C、N、O、F 原子的化学宇宙的虚拟探索：组装 2640万个结构（110.9百万立体异构体）并分析新环系统、立体化学、物理化学性质、化合物类别及药物发现，”
    *化学信息与建模期刊*，第47卷，第2期，页342–353，2007年。'
- en: '[162] L. C. Blum and J.-L. Reymond, “970 million druglike small molecules for
    virtual screening in the chemical universe database gdb-13,” *Journal of the American
    Chemical Society*, vol. 131, no. 25, pp. 8732–8733, 2009.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[162] L. C. Blum 和 J.-L. Reymond，“970百万个药物样小分子用于化学宇宙数据库 gdb-13 的虚拟筛选，” *美国化学学会期刊*，第131卷，第25期，页8732–8733，2009年。'
- en: '[163] L. Ruddigkeit, R. Van Deursen, L. C. Blum, and J.-L. Reymond, “Enumeration
    of 166 billion organic small molecules in the chemical universe database gdb-17,”
    *Journal of chemical information and modeling*, vol. 52, no. 11, pp. 2864–2875,
    2012.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[163] L. Ruddigkeit, R. Van Deursen, L. C. Blum 和 J.-L. Reymond，“化学宇宙数据库 gdb-17
    中的1660亿有机小分子的枚举，” *化学信息与建模期刊*，第52卷，第11期，页2864–2875，2012年。'
- en: '[164] S. Axelrod and R. Gomez-Bombarelli, “Geom, energy-annotated molecular
    conformations for property prediction and molecular generation,” *Scientific Data*,
    vol. 9, no. 1, pp. 1–14, 2022.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[164] S. Axelrod 和 R. Gomez-Bombarelli，“Geom，具有能量注释的分子构象用于性质预测和分子生成，” *科学数据*，第9卷，第1期，页1–14，2022年。'
- en: '[165] N. Schneider, N. Stiefl, and G. A. Landrum, “What’s what: The (nearly)
    definitive guide to reaction role assignment,” *Journal of chemical information
    and modeling*, vol. 56, no. 12, pp. 2336–2346, 2016.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[165] N. Schneider, N. Stiefl 和 G. A. Landrum，“什么是什么：关于反应角色分配的（几乎）权威指南，” *化学信息与建模期刊*，第56卷，第12期，页2336–2346，2016年。'
- en: '[166] Z. Wu, B. Ramsundar, E. N. Feinberg, J. Gomes, C. Geniesse, A. S. Pappu,
    K. Leswing, and V. Pande, “Moleculenet: a benchmark for molecular machine learning,”
    *Chemical science*, vol. 9, no. 2, pp. 513–530, 2018.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[166] Z. Wu, B. Ramsundar, E. N. Feinberg, J. Gomes, C. Geniesse, A. S. Pappu,
    K. Leswing 和 V. Pande，“Moleculenet：分子机器学习的基准测试，” *化学科学*，第9卷，第2期，页513–530，2018年。'
- en: '[167] J. Sun, N. Jeliazkova, V. Chupakhin, J.-F. Golib-Dzib, O. Engkvist, L. Carlsson,
    J. Wegner, H. Ceulemans, I. Georgiev, V. Jeliazkov *et al.*, “Excape-db: an integrated
    large scale dataset facilitating big data analysis in chemogenomics,” *Journal
    of cheminformatics*, vol. 9, pp. 1–9, 2017.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[167] J. Sun, N. Jeliazkova, V. Chupakhin, J.-F. Golib-Dzib, O. Engkvist, L.
    Carlsson, J. Wegner, H. Ceulemans, I. Georgiev, V. Jeliazkov *等*，“Excape-db：一个集成的大规模数据集，促进化学基因组学中的大数据分析，”
    *化学信息学期刊*，第9卷，页1–9，2017年。'
- en: '[168] W. P. Walters and M. Murcko, “Assessing the impact of generative ai on
    medicinal chemistry,” *Nature biotechnology*, vol. 38, no. 2, pp. 143–145, 2020.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[168] W. P. Walters 和 M. Murcko，“评估生成性 AI 对药物化学的影响，” *自然生物技术*，第38卷，第2期，页143–145，2020年。'
- en: '[169] N. Brown, M. Fiscato, M. H. Segler, and A. C. Vaucher, “Guacamol: benchmarking
    models for de novo molecular design,” *Journal of chemical information and modeling*,
    vol. 59, no. 3, pp. 1096–1108, 2019.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[169] N. Brown, M. Fiscato, M. H. Segler 和 A. C. Vaucher，“Guacamol：新分子设计模型的基准测试，”
    *化学信息与建模期刊*，第59卷，第3期，页1096–1108，2019年。'
- en: '[170] M. Stanley, J. F. Bronskill, K. Maziarz, H. Misztela, J. Lanini, M. Segler,
    N. Schneider, and M. Brockschmidt, “Fs-mol: A few-shot learning dataset of molecules,”
    in *Thirty-fifth Conference on Neural Information Processing Systems Datasets
    and Benchmarks Track (Round 2)*, 2021.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[170] M. Stanley, J. F. Bronskill, K. Maziarz, H. Misztela, J. Lanini, M. Segler,
    N. Schneider, 和 M. Brockschmidt, “Fs-mol: 一种少量学习的分子数据集，” 见 *第三十五届神经信息处理系统会议 数据集和基准跟踪（第2轮）*，2021年。'
- en: '[171] G. Subramanian, B. Ramsundar, V. Pande, and R. A. Denny, “Computational
    modeling of $\beta$-secretase 1 (bace-1) inhibitors using ligand based approaches,”
    *Journal of chemical information and modeling*, vol. 56, no. 10, pp. 1936–1949,
    2016.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[171] G. Subramanian, B. Ramsundar, V. Pande, 和 R. A. Denny, “使用基于配体的方法计算建模$\beta$-secretase
    1 (bace-1) 抑制剂，” *Journal of chemical information and modeling*, 第56卷，第10期，页码1936–1949，2016年。'
- en: '[172] M. Guo, V. Thost, B. Li, P. Das, J. Chen, and W. Matusik, “Data-efficient
    graph grammar learning for molecular generation,” *arXiv preprint arXiv:2203.08031*,
    2022.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[172] M. Guo, V. Thost, B. Li, P. Das, J. Chen, 和 W. Matusik, “数据高效的图语法学习用于分子生成，”
    *arXiv 预印本 arXiv:2203.08031*，2022年。'
- en: '[173] B. Chen, C. Li, H. Dai, and L. Song, “Retro*: learning retrosynthetic
    planning with neural guided a* search,” in *ICML*.   PMLR, 2020, pp. 1608–1616.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[173] B. Chen, C. Li, H. Dai, 和 L. Song, “Retro*: 使用神经引导的a*搜索进行逆合成规划学习，” 见
    *ICML*. PMLR, 2020年，页码1608–1616。'
- en: '[174] P. Sidorov, S. Naulaerts, J. Ariey-Bonnet, E. Pasquier, and P. J. Ballester,
    “Predicting synergism of cancer drug combinations using nci-almanac data,” *Frontiers
    in chemistry*, vol. 7, p. 509, 2019.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[174] P. Sidorov, S. Naulaerts, J. Ariey-Bonnet, E. Pasquier, 和 P. J. Ballester,
    “使用 nci-almanac 数据预测癌症药物组合的协同作用，” *Frontiers in chemistry*, 第7卷，页码509，2019年。'
- en: '[175] Z. Safikhani, P. Smirnov, M. Freeman, N. El-Hachem, A. She, Q. Rene,
    A. Goldenberg, N. J. Birkbak, C. Hatzis, L. Shi *et al.*, “Revisiting inconsistency
    in large pharmacogenomic studies,” *F1000Research*, vol. 5, 2016.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[175] Z. Safikhani, P. Smirnov, M. Freeman, N. El-Hachem, A. She, Q. Rene,
    A. Goldenberg, N. J. Birkbak, C. Hatzis, L. Shi *等*，“重审大型药理基因组研究中的不一致性，” *F1000Research*,
    第5卷，2016年。'
- en: '[176] P. Renz, D. Van Rompaey, J. K. Wegner, S. Hochreiter, and G. Klambauer,
    “On failure modes in molecule generation and optimization,” *Drug Discovery Today:
    Technologies*, vol. 32, pp. 55–63, 2019.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[176] P. Renz, D. Van Rompaey, J. K. Wegner, S. Hochreiter, 和 G. Klambauer,
    “分子生成和优化中的失败模式，” *Drug Discovery Today: Technologies*, 第32卷，页码55–63，2019年。'
- en: '[177] P. Schwaller, R. Petraglia, V. Zullo, V. H. Nair, R. A. Haeuselmann,
    R. Pisoni, C. Bekas, A. Iuliano, and T. Laino, “Predicting retrosynthetic pathways
    using transformer-based models and a hyper-graph exploration strategy,” *Chemical
    science*, vol. 11, no. 12, pp. 3316–3325, 2020.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[177] P. Schwaller, R. Petraglia, V. Zullo, V. H. Nair, R. A. Haeuselmann,
    R. Pisoni, C. Bekas, A. Iuliano, 和 T. Laino, “使用基于变换器的模型和超图探索策略预测逆合成路径，” *Chemical
    science*, 第11卷，第12期，页码3316–3325，2020年。'
- en: '[178] A. Thakkar, T. Kogej, J.-L. Reymond, O. Engkvist, and E. J. Bjerrum,
    “Datasets and their influence on the development of computer assisted synthesis
    planning tools in the pharmaceutical domain,” *Chemical science*, vol. 11, no. 1,
    pp. 154–168, 2020.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[178] A. Thakkar, T. Kogej, J.-L. Reymond, O. Engkvist, 和 E. J. Bjerrum, “数据集及其对药物领域计算机辅助合成规划工具发展的影响，”
    *Chemical science*, 第11卷，第1期，页码154–168，2020年。'
- en: '[179] M. E. Fortunato, C. W. Coley, B. C. Barnes, and K. F. Jensen, “Data augmentation
    and pretraining for template-based retrosynthetic prediction in computer-aided
    synthesis planning,” *Journal of chemical information and modeling*, vol. 60,
    no. 7, pp. 3398–3407, 2020.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[179] M. E. Fortunato, C. W. Coley, B. C. Barnes, 和 K. F. Jensen, “数据增强和预训练用于计算机辅助合成规划中的基于模板的逆合成预测，”
    *Journal of chemical information and modeling*, 第60卷，第7期，页码3398–3407，2020年。'
- en: '[180] J. Jiménez-Luna, F. Grisoni, and G. Schneider, “Drug discovery with explainable
    artificial intelligence,” *Nature Machine Intelligence*, vol. 2, no. 10, pp. 573–584,
    2020.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[180] J. Jiménez-Luna, F. Grisoni, 和 G. Schneider, “利用可解释的人工智能进行药物发现，” *Nature
    Machine Intelligence*, 第2卷，第10期，页码573–584，2020年。'
- en: '[181] J. Vamathevan, D. Clark, P. Czodrowski, I. Dunham, E. Ferran, G. Lee,
    B. Li, A. Madabhushi, P. Shah, M. Spitzer *et al.*, “Applications of machine learning
    in drug discovery and development,” *Nature reviews Drug discovery*, vol. 18,
    no. 6, pp. 463–477, 2019.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[181] J. Vamathevan, D. Clark, P. Czodrowski, I. Dunham, E. Ferran, G. Lee,
    B. Li, A. Madabhushi, P. Shah, M. Spitzer *等*，“机器学习在药物发现和开发中的应用，” *Nature reviews
    Drug discovery*, 第18卷，第6期，页码463–477，2019年。'
- en: '[182] K. Preuer, G. Klambauer, F. Rippmann, S. Hochreiter, and T. Unterthiner,
    “Interpretable deep learning in drug discovery,” *Explainable AI: interpreting,
    explaining and visualizing deep learning*, pp. 331–345, 2019.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[182] K. Preuer, G. Klambauer, F. Rippmann, S. Hochreiter, 和 T. Unterthiner,
    “药物发现中的可解释深度学习，” *Explainable AI: interpreting, explaining and visualizing deep
    learning*, 页码331–345，2019年。'
- en: '[183] Y. Du, X. Guo, A. Shehu, and L. Zhao, “Interpretable molecular graph
    generation via monotonic constraints,” in *Proceedings of the 2022 SIAM International
    Conference on Data Mining (SDM)*.   SIAM, 2022, pp. 73–81.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[183] Y. Du, X. Guo, A. Shehu, 和 L. Zhao, “通过单调约束的可解释分子图生成，” 见 *2022 SIAM 国际数据挖掘会议
    (SDM) 论文集*。 SIAM, 2022, 页码 73–81。'
- en: '[184] Y. Du, T. Fu, J. Sun, and S. Liu, “Molgensurvey: A systematic survey
    in machine learning models for molecule design,” *arXiv preprint arXiv:2203.14500*,
    2022.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[184] Y. Du, T. Fu, J. Sun, 和 S. Liu, “Molgensurvey: 机器学习模型在分子设计中的系统性调查，” *arXiv
    预印本 arXiv:2203.14500*, 2022。'
- en: '[185] L. H. Mervin, S. Johansson, E. Semenova, K. A. Giblin, and O. Engkvist,
    “Uncertainty quantification in drug design,” *Drug discovery today*, vol. 26,
    no. 2, pp. 474–489, 2021.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[185] L. H. Mervin, S. Johansson, E. Semenova, K. A. Giblin, 和 O. Engkvist,
    “药物设计中的不确定性量化，” *药物发现今日*，第 26 卷，第 2 期，页码 474–489, 2021。'
- en: '[186] S. Hernández-Hernández, S. Vishwakarma, and P. Ballester, “Conformal
    prediction of small-molecule drug resistance in cancer cell lines,” in *Conformal
    and Probabilistic Prediction with Applications*.   PMLR, 2022, pp. 92–108.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[186] S. Hernández-Hernández, S. Vishwakarma, 和 P. Ballester, “癌细胞系中小分子药物抗性的符合性预测，”
    见 *符合性和概率预测及其应用*。 PMLR, 2022, 页码 92–108。'
- en: '[187] B. Hie, B. D. Bryson, and B. Berger, “Leveraging uncertainty in machine
    learning accelerates biological discovery and design,” *Cell systems*, vol. 11,
    no. 5, pp. 461–477, 2020.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[187] B. Hie, B. D. Bryson, 和 B. Berger, “利用机器学习中的不确定性加速生物发现和设计，” *细胞系统*，第
    11 卷，第 5 期，页码 461–477, 2020。'
- en: '[188] A. C. Vaucher, P. Schwaller, J. Geluykens, V. H. Nair, A. Iuliano, and
    T. Laino, “Inferring experimental procedures from text-based representations of
    chemical reactions,” *Nature communications*, vol. 12, no. 1, pp. 1–11, 2021.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[188] A. C. Vaucher, P. Schwaller, J. Geluykens, V. H. Nair, A. Iuliano, 和
    T. Laino, “从基于文本的化学反应表示中推断实验程序，” *自然通讯*，第 12 卷，第 1 期，页码 1–11, 2021。'
- en: '[189] X. Wang, Y. Qian, H. Gao, C. W. Coley, Y. Mo, R. Barzilay, and K. F.
    Jensen, “Towards efficient discovery of green synthetic pathways with monte carlo
    tree search and reinforcement learning,” *Chemical science*, vol. 11, no. 40,
    pp. 10 959–10 972, 2020.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[189] X. Wang, Y. Qian, H. Gao, C. W. Coley, Y. Mo, R. Barzilay, 和 K. F. Jensen,
    “通过蒙特卡洛树搜索和强化学习实现绿色合成路径的高效发现，” *化学科学*，第 11 卷，第 40 期，页码 10 959–10 972, 2020。'
- en: '[190] A. B. Henson, P. S. Gromski, and L. Cronin, “Designing algorithms to
    aid discovery by chemical robots,” *ACS central science*, vol. 4, no. 7, pp. 793–804,
    2018.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[190] A. B. Henson, P. S. Gromski, 和 L. Cronin, “设计算法以辅助化学机器人发现，” *ACS 中央科学*，第
    4 卷，第 7 期，页码 793–804, 2018。'
