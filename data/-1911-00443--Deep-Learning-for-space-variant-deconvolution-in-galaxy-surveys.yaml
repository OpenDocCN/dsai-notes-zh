- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '分类: 未分类'
- en: 'date: 2024-09-06 20:04:17'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 20:04:17'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1911.00443] Deep Learning for space-variant deconvolution in galaxy surveys'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1911.00443] 深度学习在星系调查中的空间变异去卷积'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1911.00443](https://ar5iv.labs.arxiv.org/html/1911.00443)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1911.00443](https://ar5iv.labs.arxiv.org/html/1911.00443)
- en: '¹¹institutetext: Laboratoire AIM, CEA, CNRS, Université Paris-Saclay, Université
    Paris Diderot, Sorbonne Paris Cité, F-91191 Gif-sur-Yvette, France ²²institutetext:
    ONERA - The French Aerospace Lab, 6 chemin de la Vauve aux Granges, BP 80100,
    FR-91123 PALAISEAU cedex, France'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '¹¹institutetext: Laboratoire AIM, CEA, CNRS, 巴黎萨克雷大学, 巴黎第七大学, 巴黎索邦城市大学, F-91191
    Gif-sur-Yvette, 法国 ²²institutetext: ONERA - 法国航空航天实验室, 6 chemin de la Vauve aux
    Granges, BP 80100, FR-91123 PALAISEAU cedex, 法国'
- en: Deep Learning for space-variant deconvolution in galaxy surveys
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在星系调查中的空间变异去卷积
- en: F. Sureau 11    A. Lechat 1122    J.-L. Starck 11
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: F. Sureau 11    A. Lechat 1122    J.-L. Starck 11
- en: Deconvolution of large survey images with millions of galaxies requires to develop
    a new generation of methods which can take into account a space variant Point
    Spread Function (PSF) and have to be at the same time accurate and fast. We investigate
    in this paper how Deep Learning (DL) could be used to perform this task. We employ
    a U-Net Deep Neural Network (DNN) architecture to learn in a supervised setting
    parameters adapted for galaxy image processing and study two strategies for deconvolution.
    The first approach is a post-processing of a mere Tikhonov deconvolution with
    closed form solution and the second one is an iterative deconvolution framework
    based on the Alternating Direction Method of Multipliers (ADMM). Our numerical
    results based on GREAT3 simulations with realistic galaxy images and PSFs show
    that our two approaches outperforms standard techniques based on convex optimization,
    whether assessed in galaxy image reconstruction or shape recovery. The approach
    based on Tikhonov deconvolution leads to the most accurate results except for
    ellipticity errors at high signal to noise ratio where the ADMM approach performs
    slightly better, is also more computation-time efficient to process a large number
    of galaxies, and is therefore recommended in this scenario.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对包含数百万个星系的大型调查图像进行去卷积需要开发新一代方法，这些方法需要考虑空间变异的点扩散函数（PSF），并且必须同时具有准确性和速度。我们在本文中研究了深度学习（DL）如何用于执行这一任务。我们采用了U-Net深度神经网络（DNN）架构，在监督设置中学习适用于星系图像处理的参数，并研究了两种去卷积策略。第一种方法是对具有封闭形式解的简单Tikhonov去卷积进行后处理，第二种方法是基于交替方向乘子法（ADMM）的迭代去卷积框架。我们基于GREAT3模拟的现实星系图像和PSF的数值结果表明，我们的两种方法在星系图像重建或形状恢复方面都优于基于凸优化的标准技术。基于Tikhonov去卷积的方法在大多数情况下提供了最准确的结果，除了在高信噪比下的椭圆率误差，此时ADMM方法表现略好，处理大量星系的计算时间效率更高，因此在这种情况下推荐使用ADMM方法。
- en: 'Key Words.:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Methods:statistical, Methods:data analysis, Methods:numerical
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '方法: 统计方法, 方法: 数据分析, 方法: 数值方法'
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'Deconvolution of large galaxy survey images requires to take into account spatial-variation
    of the Point Spread Function (PSF) across the field of view. The PSF field is
    usually estimated beforehand, via parametric models and simulations as in Krist
    et al. ([2011](#bib.bib45)) or directly estimated from the (noisy) observations
    of stars in the field of view (Bertin [2011](#bib.bib7); Kuijken et al. [2015](#bib.bib46);
    Zuntz et al. [2018](#bib.bib94); Mboula et al. [2016](#bib.bib57); Schmitz et al.
    [2019](#bib.bib73)). Even with the ”perfect” knowledge of the PSF, this ill-posed
    deconvolution problem is challenging, in particular due to the size of the image
    to process. Starck et al. ([2000](#bib.bib77)) proposed an Object-Oriented Deconvolution,
    consisting in first detecting galaxies and then deconvolving each object independently
    taking into account the PSF at the position of the center of the galaxy (but not
    taking into account the variation of the PSF field at the galaxy scale). Following
    this idea, Farrens et al. ([2017](#bib.bib26)) introduced a space-variant deconvolution
    approach for galaxy images, based on two regularization strategies: using either
    a sparse prior in a transformed domain (Starck et al. [2015a](#bib.bib78)) or
    trying to learn unsupervisedly a low-dimensional subspace for galaxy representation
    using a low-rank prior on the recovered galaxy images. Provided a sufficient number
    of galaxies are jointly processed (more than 1000) they found that the low-rank
    approach provided significantly lower ellipticity errors than sparsity, which
    illustrates the importance of learning adequate representations for galaxies.
    To go one step further in learning, supervised deep learning techniques taking
    profit of databases of galaxy images could be employed to learn complex mappings
    that could regularize our deconvolution problem. Deep convolutional architectures
    have also proved to be computationally efficient to process large number of images
    once the model has been learned, and are therefore promising in the context of
    modern galaxy surveys.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大型银河系调查图像的去卷积需要考虑视野中点扩散函数（PSF）的空间变化。PSF场通常通过参数模型和模拟（如Krist et al. [2011](#bib.bib45)）预先估计，或直接从视野中的（噪声）星体观测中估计（Bertin
    [2011](#bib.bib7); Kuijken et al. [2015](#bib.bib46); Zuntz et al. [2018](#bib.bib94);
    Mboula et al. [2016](#bib.bib57); Schmitz et al. [2019](#bib.bib73)）。即使拥有“完美”的PSF知识，这个病态的去卷积问题依然具有挑战性，特别是由于图像处理的规模。Starck
    et al. ([2000](#bib.bib77)) 提出了一个面向对象的去卷积方法，首先检测银河系，然后独立地对每个对象进行去卷积，同时考虑银河系中心位置的PSF（但不考虑银河系尺度上的PSF场变化）。基于这一思路，Farrens
    et al. ([2017](#bib.bib26)) 引入了一种针对银河图像的空间变异去卷积方法，基于两种正则化策略：要么在变换域中使用稀疏先验（Starck
    et al. [2015a](#bib.bib78)），要么尝试无监督地学习低维子空间用于银河系表示，使用对恢复的银河系图像的低秩先验。若处理的银河系数量足够多（超过1000个），他们发现低秩方法比稀疏方法提供了显著更低的椭圆度误差，这说明了学习适当表示银河系的重要性。为了进一步提升学习效果，可以采用监督式深度学习技术，利用银河系图像数据库来学习复杂的映射，这些映射可以正则化我们的去卷积问题。深度卷积架构在模型学习后也被证明在处理大量图像时计算效率高，因此在现代银河系调查中具有前景。
- en: 'Deep Learning and Deconvolution: In the recent years, deep learning approaches
    have been proposed in a large number of inverse problems with high empirical success.
    Some potential explanations could lie on the expressivity of the deep architectures
    (e.g. the theoretical works for simple architecture in (Eldan & Shamir [2015](#bib.bib23);
    Safran & Shamir [2017](#bib.bib71); Petersen & Voigtlaender [2018](#bib.bib65)))
    as well as new architectures or new optimization strategies that increased the
    learning performance (for instance Kingma & Ba ([2014](#bib.bib43)); Ioffe & Szegedy
    ([2015](#bib.bib38)); He et al. ([2016](#bib.bib35)); Szegedy et al. ([2016](#bib.bib82))).
    Their success also depend on the huge datasets collected in the different applications
    for training the networks, as well as the increased computing power available
    to process them. With the progress made on simulating realistic galaxies (based
    for instance on real Hubble Space Telescope (HST) images as in Rowe et al. ([2015](#bib.bib70));
    Mandelbaum et al. ([2015](#bib.bib53))), deep learning techniques have therefore
    the potential to show the same success for deconvolution of galaxy images as in
    the other applications. Preliminary work have indeed shown that deep neural networks
    (DNN) can perform well for classical deconvolution of galaxy images (Flamary [2017](#bib.bib27);
    Schawinski et al. [2017](#bib.bib72)).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习与去卷积：近年来，深度学习方法在大量逆问题中取得了显著的经验成功。一些潜在的解释可能在于深度架构的表现力（例如，简单架构的理论研究见于（Eldan
    & Shamir [2015](#bib.bib23); Safran & Shamir [2017](#bib.bib71); Petersen & Voigtlaender
    [2018](#bib.bib65)))以及新架构或新优化策略的出现，提高了学习性能（例如 Kingma & Ba ([2014](#bib.bib43));
    Ioffe & Szegedy ([2015](#bib.bib38)); He et al. ([2016](#bib.bib35)); Szegedy
    et al. ([2016](#bib.bib82)))。它们的成功也依赖于用于训练网络的大型数据集以及处理这些数据集所需的计算能力。随着对现实银河系的模拟进展（例如基于真实的哈勃太空望远镜（HST）图像，如
    Rowe et al. ([2015](#bib.bib70)); Mandelbaum et al. ([2015](#bib.bib53)))，深度学习技术因此有潜力在银河图像去卷积中取得与其他应用相同的成功。初步工作确实显示深度神经网络（DNN）在经典的银河图像去卷积中表现良好（Flamary
    [2017](#bib.bib27); Schawinski et al. [2017](#bib.bib72)）。
- en: 'This paper: we investigates two different strategies to interface deep learning
    techniques with space variant deconvolution approaches inspired from convex optimization.
    In section [2](#S2 "2 Image Deconvolution in the Deep Learning Era ‣ Deep Learning
    for space-variant deconvolution in galaxy surveys"), we review deconvolution techniques
    based on convex optimization and deep learning schemes. The space variant deconvolution
    is presented in section [3](#S3 "3 Image Deconvolution with Space Variant PSF
    ‣ Deep Learning for space-variant deconvolution in galaxy surveys") where the
    two proposed methods are described, the first one using a deep neural network
    (DNN) for post-processing of a Tikhonov deconvolution and the second one including
    a DNN trained for denoising in an iterative algorithm derived from convex optimization.
    The neural network architecture proposed for deconvolution is also presented in
    this section. The experiment settings are described in section [4](#S4 "4 Experiments
    ‣ Deep Learning for space-variant deconvolution in galaxy surveys") and the results
    presented in section [5](#S5 "5 Results ‣ Deep Learning for space-variant deconvolution
    in galaxy surveys"). We conclude in section [6](#S6 "6 Conclusions ‣ Deep Learning
    for space-variant deconvolution in galaxy surveys").'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本文：我们探讨了两种不同的策略，将深度学习技术与受凸优化启发的空间变异去卷积方法结合起来。在第[2](#S2 "2 Image Deconvolution
    in the Deep Learning Era ‣ Deep Learning for space-variant deconvolution in galaxy
    surveys")节中，我们回顾了基于凸优化和深度学习方案的去卷积技术。空间变异去卷积在第[3](#S3 "3 Image Deconvolution with
    Space Variant PSF ‣ Deep Learning for space-variant deconvolution in galaxy surveys")节中介绍，其中描述了两种提出的方法，第一种使用深度神经网络（DNN）对Tikhonov去卷积进行后处理，第二种包括一个在从凸优化中派生的迭代算法中训练的DNN用于去噪。为去卷积提出的神经网络架构也在本节中介绍。实验设置在第[4](#S4
    "4 Experiments ‣ Deep Learning for space-variant deconvolution in galaxy surveys")节中描述，结果在第[5](#S5
    "5 Results ‣ Deep Learning for space-variant deconvolution in galaxy surveys")节中展示。我们在第[6](#S6
    "6 Conclusions ‣ Deep Learning for space-variant deconvolution in galaxy surveys")节中总结。
- en: 2 Image Deconvolution in the Deep Learning Era
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 深度学习时代的图像去卷积
- en: 2.1 Deconvolution before Deep Learning
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 深度学习之前的去卷积
- en: 'The standard deconvolution problem consists in solving the linear inverse problem
    $\mathbf{Y}=\mathbf{H}\mathbf{X}+\mathbf{N}$, where $\mathbf{Y}$ is the observed
    noisy data, $\mathbf{X}$ the unknown solution, $\mathbf{H}$ the matrix related
    to the PSF and $\mathbf{N}$ is the noise. Images $\mathbf{Y}$, $\mathbf{X}$ and
    $\mathbf{N}$ are represented by a column vector of $n_{p}$ pixels arranged in
    lexicographic order, with $n_{p}$ being the total number of pixels, and $\mathbf{H}$
    is a $n_{p}\times n_{p}$ matrix. State of the art deconvolution techniques typically
    solve this ill-posed inverse problem (i.e. with no unique and stable solution)
    through a modeling of the forward problem motivated from physics, and adding regularization
    penalty term $\mathcal{R}\left(\mathbf{X}\right)$ which can be interpreted as
    enforcing some constraints on the solution. It leads to minimize:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的去卷积问题包括解决线性逆问题 $\mathbf{Y}=\mathbf{H}\mathbf{X}+\mathbf{N}$，其中 $\mathbf{Y}$
    是观测到的带噪数据，$\mathbf{X}$ 是未知解，$\mathbf{H}$ 是与 PSF 相关的矩阵，$\mathbf{N}$ 是噪声。图像 $\mathbf{Y}$、$\mathbf{X}$
    和 $\mathbf{N}$ 由 $n_{p}$ 像素的列向量表示，按字典顺序排列，其中 $n_{p}$ 是像素的总数，$\mathbf{H}$ 是一个 $n_{p}\times
    n_{p}$ 的矩阵。最先进的去卷积技术通常通过对物理学驱动的前向问题建模，并添加正则化惩罚项 $\mathcal{R}\left(\mathbf{X}\right)$，来解决这个不适定的逆问题（即没有唯一且稳定的解）。这导致最小化：
- en: '|  | $\operatorname*{arg\,min}\limits_{\mathbf{X}}\frac{1}{2}&#124;&#124;\mathbf{Y}-\mathbf{H}\mathbf{X}&#124;&#124;^{2}_{F}+\mathcal{R}\left(\mathbf{X}\right),$
    |  | (1) |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '|  | $\operatorname*{arg\,min}\limits_{\mathbf{X}}\frac{1}{2}&#124;&#124;\mathbf{Y}-\mathbf{H}\mathbf{X}&#124;&#124;^{2}_{F}+\mathcal{R}\left(\mathbf{X}\right),$
    |  | (1) |'
- en: 'where $||\cdot||_{F}$ is the Frobenius norm. The most simple (and historic)
    regularization corresponding is the Tikhonov regularization (Tikhonov & Arsenin
    [1977](#bib.bib84); Hunt [1972](#bib.bib37); Twomey [1963](#bib.bib85)), where
    $\mathcal{R}\left(\mathbf{X}\right)$ is a quadratic term, $\mathcal{R}\left(\mathbf{X}\right)=\frac{\lambda}{2}||\mathbf{L}\mathbf{X}||^{2}_{F}$.
    The closed-form solution of this inverse problem is given by:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $||\cdot||_{F}$ 是 Frobenius 范数。最简单（也是历史悠久）的正则化方法是 Tikhonov 正则化（Tikhonov &
    Arsenin [1977](#bib.bib84); Hunt [1972](#bib.bib37); Twomey [1963](#bib.bib85)），其中
    $\mathcal{R}\left(\mathbf{X}\right)$ 是一个二次项，$\mathcal{R}\left(\mathbf{X}\right)=\frac{\lambda}{2}||\mathbf{L}\mathbf{X}||^{2}_{F}$。该逆问题的封闭形式解为：
- en: '|  | $\tilde{\mathbf{X}}=\left(\mathbf{H}^{T}\mathbf{H}+\lambda\mathbf{L}^{T}\mathbf{L}\right)^{-1}\mathbf{H}^{T}\mathbf{Y}$
    |  | (2) |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '|  | $\tilde{\mathbf{X}}=\left(\mathbf{H}^{T}\mathbf{H}+\lambda\mathbf{L}^{T}\mathbf{L}\right)^{-1}\mathbf{H}^{T}\mathbf{Y}$
    |  | (2) |'
- en: which involves the Tikhonov linear filter $\left(\mathbf{H}^{T}\mathbf{H}+\lambda\mathbf{L}^{T}\mathbf{L}\right)^{-1}\mathbf{H}^{T}$.
    The simplest version is when $\mathbf{L}=\boldsymbol{\operatorname*{Id}}$, which
    penalizes solutions with high energy. When the PSF is space invariant, the matrix
    $\mathbf{H}$ is block circulant and the inverse problem can then be written as
    a simple convolution product. It is also easy to see that the Wiener deconvolution
    corresponds to a specific case of the Tikhonov filter. See Bertero & Boccacci
    ([1998](#bib.bib6)) for more details.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 其中涉及到 Tikhonov 线性滤波器 $\left(\mathbf{H}^{T}\mathbf{H}+\lambda\mathbf{L}^{T}\mathbf{L}\right)^{-1}\mathbf{H}^{T}$。最简单的版本是当
    $\mathbf{L}=\boldsymbol{\operatorname*{Id}}$，这会惩罚高能量的解。当 PSF 是空间不变的，矩阵 $\mathbf{H}$
    是块循环矩阵，则逆问题可以写作简单的卷积积。同时也容易看出 Wiener 去卷积对应于 Tikhonov 滤波器的一个特例。有关更多细节，请参见 Bertero
    & Boccacci ([1998](#bib.bib6))。
- en: '![Refer to caption](img/e43af1f1786535a605d5fa9227df0f9f.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e43af1f1786535a605d5fa9227df0f9f.png)'
- en: 'Figure 1: Deconvolution with Tikhonov regularization.From left to right:galaxy
    image from HST used for the simulation, observed galaxy at $\mathrm{SNR}=20$ (see
    below for our definition of SNR), deconvolved image computed from Eq. [2](#S2.E2
    "In 2.1 Deconvolution before Deep Learning ‣ 2 Image Deconvolution in the Deep
    Learning Era ‣ Deep Learning for space-variant deconvolution in galaxy surveys").'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: 使用 Tikhonov 正则化的去卷积。从左到右：用于模拟的 HST 银河图像，$\mathrm{SNR}=20$ 时观测到的银河（见下文我们对
    SNR 的定义），从 Eq. [2](#S2.E2 "In 2.1 Deconvolution before Deep Learning ‣ 2 Image
    Deconvolution in the Deep Learning Era ‣ Deep Learning for space-variant deconvolution
    in galaxy surveys") 计算出的去卷积图像。'
- en: This rather crude deconvolution is illustrated in Fig. [1](#S2.F1 "Figure 1
    ‣ 2.1 Deconvolution before Deep Learning ‣ 2 Image Deconvolution in the Deep Learning
    Era ‣ Deep Learning for space-variant deconvolution in galaxy surveys") in a low
    signal to noise ratio (SNR) scenario, displaying both oversmoothing of the galaxy
    image, loss of energy in the recovered galaxy and the presence of coloured noise
    due to the inverse filter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这种相当粗糙的去卷积在图 [1](#S2.F1 "图 1 ‣ 2.1 深度学习之前的去卷积 ‣ 深度学习时代的图像去卷积 ‣ 空间变异去卷积中的深度学习")
    中展示了在低信噪比（SNR）场景下的结果，显示了星系图像的过度平滑、恢复的星系能量的丧失以及由于逆滤波器引起的彩色噪声的存在。
- en: 'Most advanced methods are non linear and generally involves iterative algorithms.
    There is a vast litterature in image processing on advanced regularization techniques
    applied to deconvolution: adding some prior information on $\mathbf{X}$ in a Bayesian
    paradigm (Bioucas-Dias [2006](#bib.bib10); Krishnan & Fergus [2009](#bib.bib44);
    Orieux et al. [2010](#bib.bib62)) or assuming $\mathbf{X}$ to belong to some classes
    of images to recover (e.g. using total variation regularization (Oliveira et al.
    [2009](#bib.bib61); Cai et al. [2010](#bib.bib14)), sparsity in fixed representations
    (Starck et al. [2003](#bib.bib80); Pesquet et al. [2009](#bib.bib64); Pustelnik
    et al. [2016](#bib.bib66)) or learnt via dictionary learning (Mairal et al. [2008](#bib.bib51);
    Lou et al. [2011](#bib.bib50); Jia & Evans [2011](#bib.bib39))), by constraining
    the solution to belong to some convex subsets (such as ensuring the final galaxy
    image to be positive).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数先进的方法是非线性的，并且通常涉及迭代算法。在图像处理领域，有大量关于应用于去卷积的高级正则化技术的文献：在贝叶斯范式中对$\mathbf{X}$添加一些先验信息（Bioucas-Dias
    [2006](#bib.bib10); Krishnan & Fergus [2009](#bib.bib44); Orieux et al. [2010](#bib.bib62)），或假设$\mathbf{X}$属于某些图像类别进行恢复（例如，使用全变差正则化（Oliveira
    et al. [2009](#bib.bib61); Cai et al. [2010](#bib.bib14)），在固定表示中稀疏（Starck et al.
    [2003](#bib.bib80); Pesquet et al. [2009](#bib.bib64); Pustelnik et al. [2016](#bib.bib66)）或通过字典学习进行学习（Mairal
    et al. [2008](#bib.bib51); Lou et al. [2011](#bib.bib50); Jia & Evans [2011](#bib.bib39)），通过约束解属于一些凸子集（例如，确保最终的星系图像为正）。
- en: 'For instance, a very efficient approach used for galaxy image deconvolution
    is based on sparse recovery which consists in minimizing:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，用于星系图像去卷积的一个非常有效的方法是基于稀疏恢复，该方法的核心是最小化：
- en: '|  |  | $\displaystyle\operatorname*{arg\,min}\limits_{\mathbf{X}}\frac{1}{2}\&#124;\mathbf{Y}-\mathbf{H}\mathbf{X}\&#124;_{2}^{2}+\lambda\&#124;\boldsymbol{\Phi}^{T}\mathbf{X}\&#124;_{1}$
    |  | (3) |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\operatorname*{arg\,min}\limits_{\mathbf{X}}\frac{1}{2}\|\mathbf{Y}-\mathbf{H}\mathbf{X}\|_{2}^{2}+\lambda\|\boldsymbol{\Phi}^{T}\mathbf{X}\|_{1}$
    |  | (3) |'
- en: where $\boldsymbol{\Phi}$ is a matrix related to a fixed transform (i.e. Fouriers,
    wavelet, curvelets, etc) or that can be learned from the data or a training data
    set (Starck et al. [2015b](#bib.bib79)). The $\ell_{1}$ norm in the regularisation
    term is known to reinforce the sparsity of the solution, see Starck et al. ([2015b](#bib.bib79))
    for a review on sparsity. Sparsity was found extremely efficient for different
    inverse problems in astrophysics such as Cosmic Microwave Background (CMB) estimation
    (Bobin et al. [2014](#bib.bib11)), compact sources estimation in CMB missions
    (Sureau et al. [2014](#bib.bib81)), weak lensing map recovery (Lanusse, F. et al.
    [2016](#bib.bib47)) or radio-interferomety image reconstruction (Garsden et al.
    [2015](#bib.bib28)). We will compare in this work our deconvolution techniques
    with such sparse deconvolution approach.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\boldsymbol{\Phi}$是与固定变换（即傅里叶变换、小波变换、曲线波变换等）相关的矩阵，或可以从数据或训练数据集（Starck et
    al. [2015b](#bib.bib79)）中学习得出。正则化项中的$\ell_{1}$范数已知能增强解的稀疏性，参见Starck et al.（[2015b](#bib.bib79)）关于稀疏性的综述。稀疏性在不同的天体物理逆问题中表现得非常有效，例如宇宙微波背景（CMB）估计（Bobin
    et al. [2014](#bib.bib11)）、CMB任务中的紧凑源估计（Sureau et al. [2014](#bib.bib81)）、弱透镜图的恢复（Lanusse,
    F. et al. [2016](#bib.bib47)）或无线电干涉成像重建（Garsden et al. [2015](#bib.bib28)）。在这项工作中，我们将比较我们的去卷积技术与这种稀疏去卷积方法。
- en: Iterative convex optimization techniques have been devised to solve Eq.[3](#S2.E3
    "In 2.1 Deconvolution before Deep Learning ‣ 2 Image Deconvolution in the Deep
    Learning Era ‣ Deep Learning for space-variant deconvolution in galaxy surveys")
    (see for instance Beck & Teboulle ([2009](#bib.bib5)); Zibulevsky & Elad ([2010](#bib.bib93));
    Combettes & Pesquet ([2011](#bib.bib18)); Chambolle & Pock ([2011](#bib.bib15));
    Afonso et al. ([2011](#bib.bib3)); Condat ([2013](#bib.bib20)); Combettes & Vu
    ([2014](#bib.bib19))), with well-studied convergence properties, but with a high
    computing cost when using adaptive representation for galaxies. This problem opens
    the way to a new generation of methods.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代凸优化技术已被开发用于解决 Eq.[3](#S2.E3 "在 2.1 深度学习前的反卷积 ‣ 2 深度学习时代的图像反卷积 ‣ 深度学习在星系调查中的空间变异反卷积")（例如
    Beck & Teboulle ([2009](#bib.bib5)); Zibulevsky & Elad ([2010](#bib.bib93)); Combettes
    & Pesquet ([2011](#bib.bib18)); Chambolle & Pock ([2011](#bib.bib15)); Afonso
    等人 ([2011](#bib.bib3)); Condat ([2013](#bib.bib20)); Combettes & Vu ([2014](#bib.bib19)))，这些方法具有良好的收敛性，但在使用自适应表示进行星系分析时计算成本较高。这一问题为新一代方法开辟了道路。
- en: 2.2 Toward Deep Learning
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 向深度学习迈进
- en: 'Recently deep learning techniques have been proposed to solve inverse problems
    by taking benefit of the dataset collected and/or the advances in simulations,
    including for deconvolving galaxy images. These approaches have proved to be able
    to learn complex mappings in the supervised setting, and to be computationally
    efficient once the model has been learned. We review here, without being exhaustive,
    some recent work on deconvolution using DNNs. We have identified three different
    strategies for using DNN in a deconvolution problem:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，深度学习技术被提出用于通过利用收集的数据集和/或模拟进展来解决逆问题，包括反卷积星系图像。这些方法已证明能够在有监督的环境中学习复杂的映射，并且在模型学习完成后具有计算效率。我们在这里回顾了一些使用
    DNN 进行反卷积的近期工作，但并不详尽。我们识别了三种不同的策略来在反卷积问题中使用 DNN：
- en: •
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Learning the inverse: the inverse convolution filter can be directly approximated
    using convolutional neural networks (Xu et al. [2014](#bib.bib89); Schuler et al.
    [2016](#bib.bib75)). In our application with space-variant deconvolution and known
    kernels, such complicated blind deconvolution is clearly not necessary and would
    require a large amount of data to try learning information already provided by
    the physics included in the forward model.'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学习逆问题：逆卷积滤波器可以直接通过卷积神经网络进行近似（Xu 等人 [2014](#bib.bib89); Schuler 等人 [2016](#bib.bib75)）。在我们处理空间变异反卷积和已知核的应用中，这种复杂的盲反卷积显然是不必要的，并且需要大量的数据来尝试学习前向模型中已包含的物理信息。
- en: •
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Post-processing of a regularized deconvolution: In the early years of using
    sparsity for deconvolution a two steps approach was proposed, consisting in first
    applying a simple linear deconvolution such as using the pseudo-inverse or the
    Tikhonov filter, letting noise entering in the solution, and then in the second
    step applying a sparse denoising (see the wavelet-vaguelette decomposition (Donoho
    [1995](#bib.bib22); Kalifa et al. [2003](#bib.bib42)), more general regularization
    (Guerrero-colon & Portilla [2006](#bib.bib31)), or the ForWaRD method (Neelamani
    et al. [2004](#bib.bib60))). Similarly, the second step have been replaced by
    denoising/removing artefacts using a multi-layer perceptron (Schuler et al. [2013](#bib.bib74)),
    or more recently using U-Nets (Jin et al. [2017](#bib.bib40)). CNNs are well adapted
    to this tasks, since the form of a CNN mimics unrolled iterative approaches when
    the forward model is a convolution. In another application, convolutional networks
    such as deep convolutional framelets have also been applied to remove artefacts
    from reconstructed CT images (Ye et al. [2018a](#bib.bib90)). One advantage of
    such decoupling approach is the ability to process quickly a large amount of data
    when the network has been learnt, if the deconvolution chosen has closed-form
    expression.'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 规则化去卷积的后处理：在早期使用稀疏性进行去卷积时，提出了一种两步法，首先应用简单的线性去卷积方法，如伪逆或Tikhonov滤波器，这样噪声会进入解中，然后在第二步中应用稀疏去噪（参见小波-模糊分解（Donoho
    [1995](#bib.bib22); Kalifa 等 [2003](#bib.bib42)），更一般的正则化（Guerrero-colon & Portilla
    [2006](#bib.bib31)），或ForWaRD方法（Neelamani 等 [2004](#bib.bib60)））。类似地，第二步已被使用多层感知机（Schuler
    等 [2013](#bib.bib74)）去噪/去除伪影替代，或更近期地使用U-Net（Jin 等 [2017](#bib.bib40)）。卷积神经网络（CNN）非常适合这些任务，因为CNN的形式模拟了展开的迭代方法，当前向模型是卷积时。在另一个应用中，卷积网络如深度卷积框架也已被应用于去除重建CT图像中的伪影（Ye
    等 [2018a](#bib.bib90)）。这种解耦方法的一个优势是，当网络已经训练好时，可以快速处理大量数据，如果选择的去卷积具有闭式表达。
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Iterative Deep Learning: the third strategy uses iterative approaches often
    derived from convex optimization coupled with deep learning networks. Several
    schemes have been devised to solve generic inverse problems. The first option,
    called unrolling or unfolding (see Monga et al. ([2019](#bib.bib59)) for a detailed
    review), is to mimic a few iterations of an iterative algorithm with DNNs so as
    to capture in the learning phase the impact of 1) the prior (Mardani et al. [2017](#bib.bib55)),
    2) the hyperparameters (Mardani et al. [2017](#bib.bib55); Adler & Öktem [2017](#bib.bib1),
    [2018](#bib.bib2); Bertocchi et al. [2018](#bib.bib8)), 3) the updating step of
    a gradient descent (Adler & Öktem [2017](#bib.bib1)) or 4) the whole update process
    (Gregor & LeCun [2010](#bib.bib30); Adler & Öktem [2018](#bib.bib2); Mardani et al.
    [2018](#bib.bib56)). Such approaches allow fast approximation of iterative algorithms
    (Gregor & LeCun [2010](#bib.bib30)), better hyperparameter selection (Bertocchi
    et al. [2018](#bib.bib8)) and/or provide in a supervised way new algorithms (Adler
    & Öktem [2017](#bib.bib1); Mardani et al. [2018](#bib.bib56); Adler & Öktem [2018](#bib.bib2))
    better adapted to process specific data set. This approach has noticeably been
    used recently for blind deconvolution (Li et al. [2019](#bib.bib49)). Finally,
    an alternative is to use iterative proximal algorithms from convex optimization
    (for instance in the framework of the alternating direction method of multiplier
    plug&play (ADMM PnP) (Venkatakrishnan et al. [2013](#bib.bib86); Sreehari et al.
    [2016](#bib.bib76); H. Chan et al. [2016](#bib.bib33)), or regularization by denoising
    (Romano et al. [2017](#bib.bib68); T. Reehorst & Schniter [2018](#bib.bib83))),
    where the proximity operator related to the prior is replaced by a DNN (Meinhardt
    et al. [2017](#bib.bib58); Bigdeli et al. [2017](#bib.bib9); Gupta et al. [2018](#bib.bib32))
    or a series of DNN trained in different denoising settings as in Zhang et al.
    ([2017](#bib.bib92)).'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 迭代深度学习：第三种策略使用通常源自凸优化的迭代方法与深度学习网络相结合。已经设计了几种方案来解决通用的逆问题。第一个选项，称为展开或展开（详见 Monga
    等人 ([2019](#bib.bib59))），是通过深度神经网络模拟迭代算法的几次迭代，以便在学习阶段捕捉 1) 先验 (Mardani 等人 [2017](#bib.bib55))、2)
    超参数 (Mardani 等人 [2017](#bib.bib55)；Adler & Öktem [2017](#bib.bib1)，[2018](#bib.bib2)；Bertocchi
    等人 [2018](#bib.bib8))、3) 梯度下降的更新步骤 (Adler & Öktem [2017](#bib.bib1)) 或 4) 整个更新过程
    (Gregor & LeCun [2010](#bib.bib30)；Adler & Öktem [2018](#bib.bib2)；Mardani 等人
    [2018](#bib.bib56)) 的影响。这些方法允许快速逼近迭代算法 (Gregor & LeCun [2010](#bib.bib30))、更好的超参数选择
    (Bertocchi 等人 [2018](#bib.bib8)) 和/或以监督方式提供新的算法 (Adler & Öktem [2017](#bib.bib1)；Mardani
    等人 [2018](#bib.bib56)；Adler & Öktem [2018](#bib.bib2))，这些算法更好地适应特定数据集的处理。最近，这种方法显著用于盲去卷积
    (Li 等人 [2019](#bib.bib49))。最后，一种替代方法是使用来自凸优化的迭代邻近算法（例如在交替方向乘子法插入式（ADMM PnP）(Venkatakrishnan
    等人 [2013](#bib.bib86)；Sreehari 等人 [2016](#bib.bib76)；H. Chan 等人 [2016](#bib.bib33)）框架中，或通过去噪正则化
    (Romano 等人 [2017](#bib.bib68)；T. Reehorst & Schniter [2018](#bib.bib83)），其中与先验相关的邻近算子被深度神经网络
    (Meinhardt 等人 [2017](#bib.bib58)；Bigdeli 等人 [2017](#bib.bib9)；Gupta 等人 [2018](#bib.bib32))
    或在不同去噪设置下训练的一系列深度神经网络 (如 Zhang 等人 ([2017](#bib.bib92))) 替代。
- en: The last two strategies are therefore more adapted to our targeted problem,
    and in the following we will investigate how they could be applied and how they
    perform compared to state-of-the art methods in space-variant deconvolution of
    galaxy images.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最后两种策略更适合我们的目标问题，接下来我们将研究它们如何应用以及它们与最先进的银河图像空间变去卷积方法相比的表现。
- en: 2.3 Discussion relative to Deep Deconvolution and Sparsity
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 与深度去卷积和稀疏性相关的讨论
- en: 'It is interesting to notice that connections exist between sparse recovery
    methodology and DNN:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，稀疏恢复方法与深度神经网络之间存在联系：
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Learning Invariants: the first features learnt in convolutive deep neural networks
    correspond typically to edges at particular orientation and location in the images
    (LeCun et al. [2015](#bib.bib48)), which is also what the wavelet transforms extract
    at different scales. Similar observations were noted for features learnt with
    a CNN in the context of cosmological parameter estimations from weak-lensing convergence
    maps (Ribli et al. [2019](#bib.bib67)). As well, understanding mathematically
    how the architecture of such networks captures progressively powerful invariants
    can be approached via wavelets and their use in the wavelet scattering transform
    (Mallat [2016](#bib.bib52)).'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学习不变性：在卷积深度神经网络中，首先学习到的特征通常对应于图像中某一特定方向和位置的边缘（LeCun 等人 [2015](#bib.bib48)），这也是小波变换在不同尺度上提取的特征。对于
    CNN 在弱透镜收敛图的宇宙学参数估计中的特征学习，观察到了类似的现象（Ribli 等人 [2019](#bib.bib67)）。此外，数学上理解此类网络架构如何逐渐捕捉强大的不变性，可以通过小波及其在小波散射变换中的使用来接近（Mallat
    [2016](#bib.bib52)）。
- en: •
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Learned proximal operator: Meinhardt et al. ([2017](#bib.bib58)) has shown
    that using a denoising neural network instead of a proximal operator (e.g. soft-thresholding
    in wavelet space in sparse recovery) during the minimisation iterations improves
    the deconvolution performance. They also claim that the noise level used to train
    the neural network behave like the regularisation parameter in sparse recovery.
    The convergence of the algorithm is not guaranteed anymore, but they observed
    experimentally that their algorithms stabilize and they expressed their fixed-points.'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学习的近端算子：Meinhardt 等人（[2017](#bib.bib58)）已经显示，使用去噪神经网络代替近端算子（例如在稀疏恢复中的小波空间软阈值）进行最小化迭代可以提高去卷积性能。他们还声称，训练神经网络所使用的噪声水平类似于稀疏恢复中的正则化参数。算法的收敛性不再得到保证，但他们通过实验观察到他们的算法稳定，并表达了其固定点。
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'expanding path and contracting path: the U-nets two parts are very similar
    to synthesis and analysis concepts in sparse representations. This has motivated
    the use of wavelets to implement in the U-net average pooling and unpooling in
    the expanding path (Ye et al. [2018b](#bib.bib91); Han & Ye [2018](#bib.bib34)).
    Some other connection can be made with soft-Autoencoder in Fan et al. ([2018](#bib.bib25))
    introducing a pair of ReLU units emulating soft-thresholding, accentuating the
    comparison with cascade wavelet shrinkage systems.'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 扩展路径和收缩路径：U-nets 的两个部分与稀疏表示中的合成和分析概念非常相似。这激发了在 U-net 中实现扩展路径的平均池化和反池化的使用小波（Ye
    等人 [2018b](#bib.bib91); Han & Ye [2018](#bib.bib34)）。还可以与 Fan 等人（[2018](#bib.bib25)）中的软自编码器建立一些其他联系，引入一对模拟软阈值的
    ReLU 单元，突出了与级联小波收缩系统的比较。
- en: Therefore, we observe exchanges between the two fields, in particular for U-Net
    architectures, with however significant differences such as the construction of
    a very rich dictionary in U-nets that is possible through the use of a large training
    data set, as well as non-linearities at every layer essential to capture invariants
    in the learning phase.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们观察到两个领域之间的交流，特别是对于 U-Net 架构，然而存在显著差异，例如在 U-nets 中构建一个非常丰富的字典，这可以通过使用大量的训练数据集实现，以及每一层的非线性，这对在学习阶段捕获不变性至关重要。
- en: 3 Image Deconvolution with Space Variant PSF
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 空间变异 PSF 的图像去卷积
- en: 3.1 Introduction
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 引言
- en: 'In the case of a space-variant deconvolution problem, we can write the same
    deconvolution equation as before, $\mathbf{Y}=\mathbf{H}\mathbf{X}+\mathbf{N}$,
    but $\mathbf{H}$ is not block circular anymore, and manipulating such a huge matrix
    is not possible in practice. As in Farrens et al. ([2017](#bib.bib26)), we consider
    instead an Object-Oriented Deconvolution, by first detecting $n_{g}$ galaxies
    with $n_{p}$ pixels each and then deconvolving independently each object using
    the PSF at the position of the center of the galaxy. We use the following definitions:
    the observations of $n_{g}$ galaxies with $n_{p}$ pixels are collected in $\mathbf{Y}\in\mathbb{R}^{n_{p}\times
    n_{g}}$ (as before, each galaxy being represented by a column vector arranged
    in lexicographic order), the galaxy images to recover are similarly collected
    $\mathbf{X}\in\mathbb{R}^{n_{p}\times n_{g}}=[\mathbf{x}_{\mathbf{i}}]_{i=1..n_{g}}$
    and the convolution operator with the different kernels is noted $\mathcal{H}$.
    It corresponds to applying in parallel a convolution matrix $\mathbf{H}_{\mathbf{i}}$
    to a galaxy $\mathbf{x}_{\mathbf{i}}$ ($\mathbf{H}_{\mathbf{i}}$ being typically
    a block circulant matrix with circulant block after zero padding which we perform
    on the images (Andrews & Hunt [1977](#bib.bib4))). Noise is noted $\mathbf{N}\in\mathbb{R}^{n_{p}\times
    n_{g}}$ as before and is assumed to be additive white gaussian noise. With these
    definitions, we now have'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在空间变异去卷积问题的情况下，我们可以写出与之前相同的去卷积方程，$\mathbf{Y}=\mathbf{H}\mathbf{X}+\mathbf{N}$，但此时$\mathbf{H}$不再是块循环矩阵，操作这样一个巨大的矩阵在实践中是不可能的。正如Farrens等人（[2017](#bib.bib26)）所述，我们考虑改为面向对象的去卷积方法，通过首先检测$n_{g}$个每个有$n_{p}$个像素的星系，然后使用星系中心位置的PSF独立地去卷积每个对象。我们使用以下定义：$n_{g}$个星系的观察值，每个星系有$n_{p}$个像素，收集在$\mathbf{Y}\in\mathbb{R}^{n_{p}\times
    n_{g}}$中（如前所述，每个星系由按字典序排列的列向量表示），需要恢复的星系图像类似地收集在$\mathbf{X}\in\mathbb{R}^{n_{p}\times
    n_{g}}=[\mathbf{x}_{\mathbf{i}}]_{i=1..n_{g}}$中，并且使用不同内核的卷积算子记为$\mathcal{H}$。这对应于并行地将卷积矩阵$\mathbf{H}_{\mathbf{i}}$应用于星系$\mathbf{x}_{\mathbf{i}}$（$\mathbf{H}_{\mathbf{i}}$通常是经过零填充后具有循环块的块循环矩阵，我们在图像上执行这种操作（Andrews
    & Hunt [1977](#bib.bib4)））。噪声记为$\mathbf{N}\in\mathbb{R}^{n_{p}\times n_{g}}$，如前所述，假设为加性白噪声。根据这些定义，我们现在有
- en: '|  | $\mathbf{Y}=\mathcal{H}(\mathbf{X})+\mathbf{N}$ |  | (4) |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{Y}=\mathcal{H}(\mathbf{X})+\mathbf{N}$ |  | (4) |'
- en: or more precisely
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 或更精确地说
- en: '|  | $\left\{\mathbf{y}_{\mathbf{i}}=\mathbf{H}_{\mathbf{i}}\mathbf{x}_{\mathbf{i}}+\mathbf{n}_{\mathbf{i}}\right\}_{i=1..n_{g}},$
    |  | (5) |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | $\left\{\mathbf{y}_{\mathbf{i}}=\mathbf{H}_{\mathbf{i}}\mathbf{x}_{\mathbf{i}}+\mathbf{n}_{\mathbf{i}}\right\}_{i=1..n_{g}},$
    |  | (5) |'
- en: 'for block circulant $\left\{\mathbf{H}_{\mathbf{i}}\right\}_{i=1..n_{g}}$,
    which illustrates that we consider multiple local space-invariant convolutions
    in our model (ignoring the very small variations of the PSF at the scale of the
    galaxy as done in practice (Kuijken et al. [2015](#bib.bib46); Mandelbaum et al.
    [2015](#bib.bib53); Zuntz et al. [2018](#bib.bib94))). The deconvolution problem
    of finding $\mathbf{X}$ knowing $\mathbf{Y}$ and $\mathcal{H}$ is therefore considered
    as a series of independent ill-posed inverse problems. To avoid having multiple
    solutions (due to a non trivial null space of $\left\{\mathbf{H}_{\mathbf{i}}\right\}_{i=1..n_{g}}$)
    or an unstable solution (bad conditioning of these matrices), we need to regularize
    the problem as in standard deconvolution approaches developed for space-invariant
    convolutions. This amounts to solve the following inverse problem:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于块循环$\left\{\mathbf{H}_{\mathbf{i}}\right\}_{i=1..n_{g}}$，这表明我们在模型中考虑了多个局部空间不变的卷积（忽略了星系尺度上PSF的非常小的变化，正如实践中所做的那样（Kuijken
    et al. [2015](#bib.bib46); Mandelbaum et al. [2015](#bib.bib53); Zuntz et al.
    [2018](#bib.bib94)））。因此，去卷积问题可以看作是一系列独立的病态逆问题。为了避免出现多个解（由于$\left\{\mathbf{H}_{\mathbf{i}}\right\}_{i=1..n_{g}}$的非平凡零空间）或不稳定解（这些矩阵的条件差），我们需要像在空间不变卷积的标准去卷积方法中那样对问题进行正则化。这等同于解决以下逆问题：
- en: '|  | $\operatorname*{arg\,min}\limits_{\mathbf{X}}\frac{1}{2}&#124;&#124;\mathbf{Y}-\mathcal{H}(\mathbf{X})&#124;&#124;^{2}_{F}+\mathcal{R}\left(\mathbf{X}\right)$
    |  | (6) |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|  | $\operatorname*{arg\,min}\limits_{\mathbf{X}}\frac{1}{2}&#124;&#124;\mathbf{Y}-\mathcal{H}(\mathbf{X})&#124;&#124;^{2}_{F}+\mathcal{R}\left(\mathbf{X}\right)$
    |  | (6) |'
- en: 'and in general we will choose separable regularizers so that we can handle
    in parallel the different deconvolution problems:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，我们会选择可分离的正则化项，以便能够并行处理不同的去卷积问题：
- en: '|  | $\left\{\operatorname*{arg\,min}\limits_{\mathbf{x}_{\mathbf{i}}}\frac{1}{2}&#124;&#124;\mathbf{y}_{\mathbf{i}}-\mathbf{H}_{\mathbf{i}}\mathbf{x}_{\mathbf{i}}&#124;&#124;^{2}_{2}+\mathcal{R}\left(\mathbf{x}_{\mathbf{i}}\right)\right\}_{i=1..n_{g}}$
    |  | (7) |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '|  | $\left\{\operatorname*{arg\,min}\limits_{\mathbf{x}_{\mathbf{i}}}\frac{1}{2}&#124;&#124;\mathbf{y}_{\mathbf{i}}-\mathbf{H}_{\mathbf{i}}\mathbf{x}_{\mathbf{i}}&#124;&#124;^{2}_{2}+\mathcal{R}\left(\mathbf{x}_{\mathbf{i}}\right)\right\}_{i=1..n_{g}}$
    |  | (7) |'
- en: 'Farrens et al. ([2017](#bib.bib26)) proposes two methods to perform this deconvolution:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Farrens 等人 ([2017](#bib.bib26)) 提出了两种方法来执行这一去卷积：
- en: •
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Sparse prior: each galaxy is supposed to be sparse in the wavelet domain, leading
    to minimize'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 稀疏先验：每个星系在小波域中被假定为稀疏，导致最小化
- en: '|  |  | $\displaystyle\underset{\mathbf{X}}{\text{argmin}}$ | $\displaystyle\frac{1}{2}\&#124;\mathbf{Y}-\mathcal{H}(\mathbf{X})\&#124;_{2}^{2}+\&#124;\mathbf{W}^{(k)}\odot\Phi(\mathbf{X})\&#124;_{1}$
    |  | s.t. |  | $\displaystyle\mathbf{X}\geq 0$ |  | (8) |'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\underset{\mathbf{X}}{\text{argmin}}$ | $\displaystyle\frac{1}{2}\&#124;\mathbf{Y}-\mathcal{H}(\mathbf{X})\&#124;_{2}^{2}+\&#124;\mathbf{W}^{(k)}\odot\Phi(\mathbf{X})\&#124;_{1}$
    |  | 满足 |  | $\displaystyle\mathbf{X}\geq 0$ |  | (8) |'
- en: with $\mathbf{W}^{(k)}$ a weighting matrix.
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中 $\mathbf{W}^{(k)}$ 是一个加权矩阵。
- en: •
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Low rank prior: In the above method, each galaxy is deconvolved independently
    from the others. As there are many similarities between galaxy images, Farrens
    et al. ([2017](#bib.bib26)) proposes a joint restoration process, where the matrix
    $\mathbf{X}$ has a low rank. This is enforced by adding a nuclear norm penalization
    instead of the sparse regularization, as follows:'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 低秩先验：在上述方法中，每个星系是独立去卷积的。由于星系图像之间有许多相似之处，Farrens 等人 ([2017](#bib.bib26)) 提出了一个联合恢复过程，其中矩阵
    $\mathbf{X}$ 具有低秩。这通过添加核范数惩罚代替稀疏正则化来强制实现，如下所示：
- en: '|  |  | $\displaystyle\underset{\mathbf{X}}{\text{argmin}}$ | $\displaystyle\frac{1}{2}\&#124;\mathbf{Y}-\mathcal{H}(\mathbf{X})\&#124;_{2}^{2}+\lambda\&#124;\mathbf{X}\&#124;_{*}$
    |  | s.t. |  | $\displaystyle\mathbf{X}\geq 0$ |  | (9) |'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\underset{\mathbf{X}}{\text{argmin}}$ | $\displaystyle\frac{1}{2}\&#124;\mathbf{Y}-\mathcal{H}(\mathbf{X})\&#124;_{2}^{2}+\lambda\&#124;\mathbf{X}\&#124;_{*}$
    |  | 满足 |  | $\displaystyle\mathbf{X}\geq 0$ |  | (9) |'
- en: where $\|\mathbf{X}\|_{*}=\sum_{k}\sigma_{k}(\mathbf{X})$, $\sigma_{k}(\mathbf{X})$
    denoting the $k^{\text{th}}$ largest singular value of $\mathbf{X}$.
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中 $\|\mathbf{X}\|_{*}=\sum_{k}\sigma_{k}(\mathbf{X})$，$\sigma_{k}(\mathbf{X})$
    表示 $\mathbf{X}$ 的第 $k^{\text{th}}$ 大奇异值。
- en: It was shown that the second approach outperforms sparsity techniques as soon
    as the number of galaxies in the field is larger than 1000 (Farrens et al. [2017](#bib.bib26)).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 研究表明，当场景中的星系数量大于 1000 时，第二种方法优于稀疏技术（Farrens 等人 [2017](#bib.bib26)）。
- en: 3.2 Neural Network architectures
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 神经网络架构
- en: 'DNN allows us to extend the previous low rank minimisation, by taking profit
    of existing databases and learning more features from the data in a supervised
    way, compared to what we could do with the simple SVD used for nuclear norm penalization.
    The choice of network architecture is crucial for performance. We have identified
    three different features we believe important for our application: 1) the forward
    model and the task implies that the network should be translation equivariant,
    2) the model should include some multi-scale processing based on the fact that
    we should be able to capture distant correlations, and 3) the model should minimize
    the number of trainable parameters for a given performance, so as to be efficient
    (lower GPU memory consumption) which is also important to ease the learning. Hopefully
    these objectives are not contradictory: the first consideration leads to the use
    of convolutional layers, while the second implies a structure such as the U-Net
    (Ronneberger et al. [2015](#bib.bib69)) already used to solve inverse problems
    (Jin et al. [2017](#bib.bib40)) or the deep convolutional framelets (Ye et al.
    [2018a](#bib.bib90)). But because such architectures allow to increase rapidly
    the receptive field in the layers along the network, they can compete with a smaller
    number of parameters against CNNs having a larger number of layers and therefore
    more parameters.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: DNN 使我们能够扩展先前的低秩最小化，通过利用现有数据库并以监督的方式从数据中学习更多特征，相比之下，我们所使用的简单 SVD 进行核范数惩罚的效果较差。网络架构的选择对于性能至关重要。我们确定了三种我们认为对应用程序重要的特征：1）前向模型和任务意味着网络应具备平移等变性，2）模型应包含一些多尺度处理，因为我们需要捕捉远程相关性，3）模型应在给定性能的情况下最小化可训练参数的数量，以提高效率（降低
    GPU 内存消耗），这对学习也很重要。希望这些目标并不矛盾：第一个考虑因素导致使用卷积层，而第二个考虑因素则需要类似 U-Net (Ronneberger
    et al. [2015](#bib.bib69)) 的结构来解决逆问题 (Jin et al. [2017](#bib.bib40)) 或深度卷积框架 (Ye
    et al. [2018a](#bib.bib90))。但由于这些架构允许在网络中迅速增加感受野，它们可以与参数较多的 CNNs 竞争，尽管这些 CNNs
    层数更多，参数更多。
- en: '![Refer to caption](img/a9a3b42ad6ee086a041d7a82f0f3802f.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a9a3b42ad6ee086a041d7a82f0f3802f.png)'
- en: 'Figure 2: DNN model used in this work. The global architecture is a U-Net,
    with small modifications for performance and to limit the number of model parameters.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：本文中使用的 DNN 模型。全球架构是 U-Net，进行了一些小修改以提高性能并限制模型参数的数量。
- en: 'We therefore have selected a global U-Net structure as in (Jin et al. [2017](#bib.bib40)),
    but including the following modifications:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们选择了如 (Jin et al. [2017](#bib.bib40)) 中所示的全球 U-Net 结构，但包括以下修改：
- en: •
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '2D separable convolutions: we replace 2D convolutions by 2D separable convolutions
    (Chollet [2016](#bib.bib16)). The separable convolutions allow to limit the number
    of parameters in the model by assuming that spatial correlations and correlations
    across feature maps can be independently captured. Their use have already lead
    to outperform architectures with non-separable convolution with a larger number
    of parameters (Chollet [2016](#bib.bib16)).'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2D 可分离卷积：我们用 2D 可分离卷积替代了 2D 卷积 (Chollet [2016](#bib.bib16))。可分离卷积通过假设空间相关性和特征图之间的相关性可以独立捕捉，从而限制了模型中的参数数量。其使用已导致在具有较多参数的非可分离卷积的架构中表现更好
    (Chollet [2016](#bib.bib16))。
- en: •
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dense blocks: we changed the convolutional layers at each ”scale” by using
    dense blocks (Huang et al. [2017](#bib.bib36)). Dense blocks also allow to reduce
    the number of parameters, by propagating through concatenation all prior feature
    maps to the input of the current layer. This was claimed to enable feature reuse,
    preservation of information, and to limit vanishing gradients in the learning.'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 稠密块：我们通过使用稠密块 (Huang et al. [2017](#bib.bib36)) 更改了每个“尺度”的卷积层。稠密块还可以通过将所有先前特征图通过连接传播到当前层的输入，来减少参数的数量。有人声称这可以实现特征重用、信息保存，并限制学习中的梯度消失问题。
- en: •
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Average-pooling: we change the pooling step: we have observed that max-pooling
    lead to over-segmentation of our final estimates, which is alleviated by the use
    of average pooling.'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平均池化：我们更改了池化步骤：我们观察到最大池化会导致最终估计的过度分割，通过使用平均池化可以缓解这一问题。
- en: •
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Skip connection: we removed the skip connection between the input and the output
    layers introduced by (Jin et al. [2017](#bib.bib40)) which proved to be detrimental
    to the performance of the network, especially at low SNR. Note that the dense
    blocks may have also better preserved the flow of relevant information and limited
    the interest of using residual learning.'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 跳过连接：我们移除了输入层和输出层之间由（Jin et al. [2017](#bib.bib40)）引入的跳过连接，这被证明对网络性能有害，尤其是在低SNR下。注意，密集块可能更好地保留了相关信息的流动，并限制了使用残差学习的兴趣。
- en: The two first modification limit significantly the number of parameters per
    ”scale” of the U-Net, and potentially allow for more scales to be used for a given
    budget of number of trainable parameters. Our network, we name ”XDense U-Net”,
    is displayed in Fig. [2](#S3.F2 "Figure 2 ‣ 3.2 Neural Network architectures ‣
    3 Image Deconvolution with Space Variant PSF ‣ Deep Learning for space-variant
    deconvolution in galaxy surveys"). The following describes how to use such networks
    in two different ways in order to perform the space variant deconvolution.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 前两项修改显著限制了U-Net每个“尺度”的参数数量，并可能允许在给定的可训练参数预算下使用更多的尺度。我们的网络，命名为“XDense U-Net”，如图
    [2](#S3.F2 "图2 ‣ 3.2 神经网络架构 ‣ 3 空间变异点扩散函数的图像解卷积 ‣ 深度学习在星系调查中的空间变异解卷积") 所示。以下描述了如何以两种不同的方式使用这些网络来执行空间变异解卷积。
- en: '3.3 Tikhonet: Tikhonov deconvolution post-processed by a Deep Neural Network'
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 Tikhonet：由深度神经网络后处理的Tikhonov解卷积
- en: 'The Tikhonov solution for the space variance variant PSF deconvolution is:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 空间变异点扩散函数解卷积的Tikhonov解为：
- en: '|  | $\operatorname*{arg\,min}\limits_{\mathbf{X}}\frac{1}{2}&#124;&#124;\mathbf{Y}-\mathcal{H}(\mathbf{X})&#124;&#124;^{2}_{F}+&#124;&#124;\mathcal{L}(\mathbf{X})&#124;&#124;^{2}_{F}$
    |  | (10) |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '|  | $\operatorname*{arg\,min}\limits_{\mathbf{X}}\frac{1}{2}&#124;&#124;\mathbf{Y}-\mathcal{H}(\mathbf{X})&#124;&#124;^{2}_{F}+&#124;&#124;\mathcal{L}(\mathbf{X})&#124;&#124;^{2}_{F}$
    |  | (10) |'
- en: 'where $\mathcal{L}$ is similarly built as $\mathcal{H}$. The closed-form solution
    of this linear inverse problem is given by:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{L}$ 以类似的方式构建为 $\mathcal{H}$。该线性逆问题的闭式解为：
- en: '|  | $\left\{\tilde{\mathbf{x}_{\mathbf{i}}}=\left(\mathbf{H}^{T}_{\mathbf{i}}\mathbf{H}_{\mathbf{i}}+\lambda_{i}\mathbf{L}^{T}_{\mathbf{i}}\mathbf{L}_{\mathbf{i}}\right)^{-1}\mathbf{H}_{\mathbf{i}}^{T}\mathbf{y}_{\mathbf{i}}\right\}_{i=1..n_{g}}$
    |  | (11) |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '|  | $\left\{\tilde{\mathbf{x}_{\mathbf{i}}}=\left(\mathbf{H}^{T}_{\mathbf{i}}\mathbf{H}_{\mathbf{i}}+\lambda_{i}\mathbf{L}^{T}_{\mathbf{i}}\mathbf{L}_{\mathbf{i}}\right)^{-1}\mathbf{H}_{\mathbf{i}}^{T}\mathbf{y}_{\mathbf{i}}\right\}_{i=1..n_{g}}$
    |  | (11) |'
- en: 'which involves for each galaxy a different Tikhonov filter $\left(\mathbf{H}^{T}_{\mathbf{i}}\mathbf{H}_{\mathbf{i}}+\lambda_{i}\mathbf{L}^{T}_{\mathbf{i}}\mathbf{L}_{\mathbf{i}}\right)^{-1}\mathbf{H}_{\mathbf{i}}^{T}$.
    In this work, we chose $\mathbf{L}_{\mathbf{i}}=\boldsymbol{\operatorname*{Id}}$
    and the regularization parameter $\lambda_{i}$ is different for each galaxy, depending
    on its SNR (see [3.5](#S3.SS5 "3.5 Implementation and choice of parameters for
    Network architecture ‣ 3 Image Deconvolution with Space Variant PSF ‣ Deep Learning
    for space-variant deconvolution in galaxy surveys") for more details). The final
    estimate is then only:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及到每个星系使用不同的Tikhonov滤波器 $\left(\mathbf{H}^{T}_{\mathbf{i}}\mathbf{H}_{\mathbf{i}}+\lambda_{i}\mathbf{L}^{T}_{\mathbf{i}}\mathbf{L}_{\mathbf{i}}\right)^{-1}\mathbf{H}_{\mathbf{i}}^{T}$。在这项工作中，我们选择了
    $\mathbf{L}_{\mathbf{i}}=\boldsymbol{\operatorname*{Id}}$，并且正则化参数 $\lambda_{i}$
    对每个星系都不同，取决于其SNR（有关更多细节，请参见 [3.5](#S3.SS5 "3.5 实现和网络架构参数选择 ‣ 3 空间变异点扩散函数的图像解卷积
    ‣ 深度学习在星系调查中的空间变异解卷积")）。最终的估计结果为：
- en: '|  | $\left\{\hat{\mathbf{x}_{\mathbf{i}}}=\mathcal{N}_{\boldsymbol{\theta}}(\tilde{\mathbf{x}_{\mathbf{i}}})\right\}_{i=1..n_{g}},$
    |  | (12) |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '|  | $\left\{\hat{\mathbf{x}_{\mathbf{i}}}=\mathcal{N}_{\boldsymbol{\theta}}(\tilde{\mathbf{x}_{\mathbf{i}}})\right\}_{i=1..n_{g}},$
    |  | (12) |'
- en: where the neural network predictions based on its parameters $\boldsymbol{\theta}$
    for some inputs $\mathbf{Y}$ are written as $\mathcal{N}_{\boldsymbol{\theta}}(\mathbf{Y})$.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 其中神经网络基于其参数 $\boldsymbol{\theta}$ 对某些输入 $\mathbf{Y}$ 的预测写作 $\mathcal{N}_{\boldsymbol{\theta}}(\mathbf{Y})$。
- en: 'The success of the first approach therefore lies on the supervised learning
    of the mapping between the Tikhonov deconvolution of Eq. ([11](#S3.E11 "In 3.3
    Tikhonet: Tikhonov deconvolution post-processed by a Deep Neural Network ‣ 3 Image
    Deconvolution with Space Variant PSF ‣ Deep Learning for space-variant deconvolution
    in galaxy surveys")) and the targeted galaxy.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，第一个方法的成功在于监督学习Tikhonov解卷积与目标星系之间的映射。
- en: 'We call this two-step approach ”Tikhonet” and the rather simple training process
    is described in Algorithm [1](#alg1 "Algorithm 1 ‣ 3.3 Tikhonet: Tikhonov deconvolution
    post-processed by a Deep Neural Network ‣ 3 Image Deconvolution with Space Variant
    PSF ‣ Deep Learning for space-variant deconvolution in galaxy surveys").'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们称这种两步方法为“**Tikhonet**”，其相对简单的训练过程如算法 [1](#alg1 "算法 1 ‣ 3.3 Tikhonet：Tikhonov
    去卷积后处理由深度神经网络 ‣ 3 带空间变换 PSF 的图像去卷积 ‣ 用于星系调查的空间变换去卷积的深度学习") 所述。
- en: Algorithm 1 DNN training in the Tikhonet approach
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 Tikhonet 方法中的 DNN 训练
- en: '1:  Initialization: Prepare noise-free training set, choose noise parameters
    (SNR range) and validation set. Choose architecture for network $\mathcal{N}$,
    learning parameters (optimizer and its parameters, batch size $B$ and number of
    batches $n_{batch}$, number of epochs $n_{epoch}$) and cost function to minimize
    (here mean squared error).2:  for $n=1$ to $n_{epoch}$ do {Loop over epochs}3:     for $b=1$
    to $n_{batch}$ do {Loop over batches}4:        for $i=1$ to $B$ do {Loop over
    galaxies in batch}5:           Add random noise to obtain a realization in the
    SNR range chosen6:           Compute the Tikhonov solution $\tilde{\mathbf{x}_{\mathbf{i}}}$
    using Eq. [2](#S2.E2 "In 2.1 Deconvolution before Deep Learning ‣ 2 Image Deconvolution
    in the Deep Learning Era ‣ Deep Learning for space-variant deconvolution in galaxy
    surveys")7:        end for8:        Predict $\hat{\mathbf{x}_{\mathbf{i}}}$ (Eq. [12](#S3.E12
    "In 3.3 Tikhonet: Tikhonov deconvolution post-processed by a Deep Neural Network
    ‣ 3 Image Deconvolution with Space Variant PSF ‣ Deep Learning for space-variant
    deconvolution in galaxy surveys")) and update network parameters $\boldsymbol{\theta}$
    according to the cost function.9:     end for10:  end for11:  return  $\mathcal{N}_{\boldsymbol{\theta}}$'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '1: 初始化：准备无噪声训练集，选择噪声参数（SNR 范围）和验证集。选择网络架构 $\mathcal{N}$、学习参数（优化器及其参数、批量大小 $B$
    和批次数 $n_{batch}$、轮数 $n_{epoch}$）和要最小化的成本函数（这里是均方误差）。2: 对于 $n=1$ 到 $n_{epoch}$
    执行 {遍历轮次} 3: 对于 $b=1$ 到 $n_{batch}$ 执行 {遍历批次} 4: 对于 $i=1$ 到 $B$ 执行 {遍历批次中的星系}
    5: 添加随机噪声以获得选择的 SNR 范围中的实现 6: 使用 Eq. [2](#S2.E2 "在 2.1 深度学习前的去卷积 ‣ 2 深度学习时代的图像去卷积
    ‣ 用于星系调查的空间变换去卷积的深度学习") 计算 Tikhonov 解 $\tilde{\mathbf{x}_{\mathbf{i}}}$ 7: 结束循环
    8: 预测 $\hat{\mathbf{x}_{\mathbf{i}}}$ (Eq. [12](#S3.E12 "在 3.3 Tikhonet：Tikhonov
    去卷积后处理由深度神经网络 ‣ 3 带空间变换 PSF 的图像去卷积 ‣ 用于星系调查的空间变换去卷积的深度学习")) 并根据成本函数更新网络参数 $\boldsymbol{\theta}$。9:
    结束循环 10: 结束轮次 11: 返回 $\mathcal{N}_{\boldsymbol{\theta}}$'
- en: '3.4 ADMMnet: Deep neural networks as constraint in ADMM plug-and-play'
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 ADMMnet：将深度神经网络作为 ADMM 插件中的约束
- en: The second approach we investigated is using the ADMM PnP framework with a DNN.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们调查的第二种方法是使用带有 DNN 的 ADMM PnP 框架。
- en: ADMM is an augmented lagrangian technique developed to solve convex problems
    under linear equality constraints (see for instance (Boyd et al. [2010](#bib.bib12))).
    It operates by decomposing the minimization problem into sub-problems solved sequentially.
    One iteration consists in first solving a minimization problem typically involving
    the data fidelity term, then solving a second minimization problem involving the
    regularization term, and finishing by an update of the dual variable.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ADMM 是一种增强拉格朗日技术，用于解决线性等式约束下的凸问题（参见（Boyd et al. [2010](#bib.bib12)））。它通过将最小化问题分解为顺序求解的子问题来运行。一轮迭代包括首先解决一个通常涉及数据保真度项的最小化问题，然后解决一个涉及正则化项的第二个最小化问题，最后更新对偶变量。
- en: It has previously been noted (Venkatakrishnan et al. [2013](#bib.bib86); Sreehari
    et al. [2016](#bib.bib76); H. Chan et al. [2016](#bib.bib33)) that the first two
    sub-steps can be interpreted as an inversion step followed by a denoising step
    coupled via the augmented lagrangian term and the dual variable. These authors
    suggested to use such ADMM structure with non-linear denoisers in the second step
    in an approach dubbed ADMM PnP, which recent work has proposed to implement via
    DNNs (Meinhardt et al. [2017](#bib.bib58)).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 之前已有文献（Venkatakrishnan et al. [2013](#bib.bib86); Sreehari et al. [2016](#bib.bib76);
    H. Chan et al. [2016](#bib.bib33)）指出，前两个子步骤可以被解释为一个反演步骤，随后是通过增强拉格朗日项和对偶变量耦合的去噪步骤。这些作者建议在第二步中使用非线性去噪器的
    ADMM 结构，称为 ADMM PnP，近期工作建议通过 DNN 实现（Meinhardt et al. [2017](#bib.bib58)）。
- en: In the following, we adopt such iterative approach based on the ADMM PnP because
    1) it separates the inversion step and the use of the DNN, offering flexibility
    to add extra convex constraints in the cost function that can be handled with
    convex optimization 2) it alleviates the cost of learning by focusing essentially
    on learning a denoiser or a projector - less networks, less parameters to learn
    jointly compared to unfolding approaches where each iteration corresponds to a
    different network 3) by iterating between the steps, the output of the network
    is propagated to the forward model to be compared with the observations, avoiding
    large discrepancies, contrary to the Tikhonet approach where the output of the
    network is not used in a likelihood.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面，我们采用基于 ADMM PnP 的这种迭代方法，因为 1）它将反演步骤与 DNN 的使用分开，提供了灵活性，以便在代价函数中添加额外的凸约束，这些约束可以通过凸优化来处理
    2）它通过主要关注学习去噪器或投影器来减轻学习成本 - 网络更少，相比于每次迭代对应不同网络的展开方法，学习的参数也更少 3）通过在各步骤之间迭代，网络的输出被传播到前向模型中，与观察结果进行比较，避免了大的差异，这与
    Tikhonet 方法相反，后者不在似然中使用网络的输出。
- en: 'The training of the network $\mathcal{N}_{\boldsymbol{\theta}}$ in this case
    is similar to Algorithm [1](#alg1 "Algorithm 1 ‣ 3.3 Tikhonet: Tikhonov deconvolution
    post-processed by a Deep Neural Network ‣ 3 Image Deconvolution with Space Variant
    PSF ‣ Deep Learning for space-variant deconvolution in galaxy surveys"), except
    that the noise-free training set is composed of noise-free target images instead
    of noise-free convolved images, and the noise added has constant standard deviation.
    Then the algorithm for deconvolving a galaxy is presented in Algo. [2](#alg2 "Algorithm
    2 ‣ 3.4 ADMMnet: Deep neural networks as constraint in ADMM plug-and-play ‣ 3
    Image Deconvolution with Space Variant PSF ‣ Deep Learning for space-variant deconvolution
    in galaxy surveys") and is derived from H. Chan et al. ([2016](#bib.bib33)). The
    application of the network is here illustrated in red. We call this approach ”ADMMnet”.
    The first step consists in solving the following regularized deconvolution problem
    at iteration $k$ using the accelerated iterative convex algorithm FISTA (Beck
    & Teboulle [2009](#bib.bib5)):'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '在这种情况下，网络 $\mathcal{N}_{\boldsymbol{\theta}}$ 的训练类似于算法 [1](#alg1 "算法 1 ‣ 3.3
    Tikhonet: 通过深度神经网络进行的 Tikhonov 反卷积 ‣ 3 空间变换 PSF 的图像反卷积 ‣ 深度学习在星系调查中的空间变换反卷积")，不同之处在于无噪声训练集由无噪声目标图像组成，而不是无噪声卷积图像，且添加的噪声具有常量标准差。然后，算法用于反卷积星系，如算法 [2](#alg2
    "算法 2 ‣ 3.4 ADMMnet: 作为 ADMM 插件的深度神经网络 ‣ 3 空间变换 PSF 的图像反卷积 ‣ 深度学习在星系调查中的空间变换反卷积")
    中所示，来源于 H. Chan 等人（[2016](#bib.bib33)）。这里以红色标出网络的应用。我们称这种方法为“ADMMnet”。第一步是在第 $k$
    次迭代中使用加速的迭代凸算法 FISTA（Beck & Teboulle [2009](#bib.bib5)）求解以下正则化反卷积问题。'
- en: '|  | $\left\{\operatorname*{arg\,min}\limits_{\mathbf{x}_{\mathbf{i}}}\frac{1}{2\sigma^{2}}&#124;&#124;\mathbf{y}_{\mathbf{i}}-\mathbf{H}_{\mathbf{i}}\mathbf{x}_{\mathbf{i}}&#124;&#124;^{2}_{2}+\iota_{\mathcal{C}}(\mathbf{x}_{\mathbf{i}})+\frac{\rho}{2}&#124;&#124;\mathbf{x}_{\mathbf{i}}-\mathbf{z}^{(k)}_{\mathbf{i}}+\boldsymbol{\mu}^{(k)}&#124;&#124;^{2}_{2}\right\}_{i=1..n_{g}}$
    |  | (13) |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '|  | $\left\{\operatorname*{arg\,min}\limits_{\mathbf{x}_{\mathbf{i}}}\frac{1}{2\sigma^{2}}&#124;&#124;\mathbf{y}_{\mathbf{i}}-\mathbf{H}_{\mathbf{i}}\mathbf{x}_{\mathbf{i}}&#124;&#124;^{2}_{2}+\iota_{\mathcal{C}}(\mathbf{x}_{\mathbf{i}})+\frac{\rho}{2}&#124;&#124;\mathbf{x}_{\mathbf{i}}-\mathbf{z}^{(k)}_{\mathbf{i}}+\boldsymbol{\mu}^{(k)}&#124;&#124;^{2}_{2}\right\}_{i=1..n_{g}}$
    |  | (13) |'
- en: where $\iota_{\mathcal{C}}$ is the characteristic function of the non-negative
    orthant, to enforce the non-negativity of the solution. The DNN used in the second
    step is used as an analogy with a denoiser (or as a projector),as presented above.
    The last step controls the augmented lagrangian parameter, and ensure that this
    parameter is increased when the optimization parameters are not sufficiently changing.
    This continuation scheme is also important, as noted in H. Chan et al. ([2016](#bib.bib33)),
    as increasing progressively the influence of the augmented lagrangian parameter
    ensures stabilization of the algorithm.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\iota_{\mathcal{C}}$ 是非负正交象限的特征函数，以强制解的非负性。第二步中使用的 DNN 被类比为去噪器（或作为投影器），如上所述。最后一步控制增广拉格朗日参数，并确保当优化参数变化不充分时，该参数会增加。正如
    H. Chan 等人（[2016](#bib.bib33)）指出的那样，这种连续方案也很重要，因为逐渐增加增广拉格朗日参数的影响可以确保算法的稳定性。
- en: Note that of course there is no convergence guarantee of such scheme and that
    contrary to the convex case the augmented lagrangian parameter $\rho$ is expected
    to impact the solution.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这种方案当然没有收敛保证，并且与凸情况不同，扩展拉格朗日参数 $\rho$ 预计会影响结果。
- en: Finally, because the target galaxy is obtained after re-convolution with a target
    PSF to avoid aliasing (see section [4](#S4 "4 Experiments ‣ Deep Learning for
    space-variant deconvolution in galaxy surveys")), we also re-convolve the ADMMnet
    solution with this target PSF to obtain our final estimate.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于目标银河图像是在目标 PSF 的重新卷积后获得的，以避免混叠（参见第 [4](#S4 "4 实验 ‣ 用于银河调查的空间变异去卷积的深度学习")
    节），我们还将 ADMMnet 解与此目标 PSF 进行重新卷积，以获得最终估计。
- en: Algorithm 2 Proposed ADMM Deep Plug&Play for deconvolution of a galaxy image
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 2 提出的 ADMM 深度 Plug&Play 方法用于银河图像的去卷积
- en: '1:  Initialize:set $\rho_{0},\rho_{max},\eta\in[0,1),\gamma>1,\Delta_{0}=0$,$\mathbf{X}^{(0)}=\mathbf{0},\mathbf{Z}^{(0)}=\mathbf{0},\boldsymbol{\mu}^{(0)}=\mathbf{0},\epsilon$2:  for $k=0$
    to $N_{it}$ do {Main Loop}3:     Deconvolution Sub-Problem: $\mathbf{X}^{(k+1)}=FISTA(\textbf{Y},\mathbf{X}^{(k)},\mathbf{Z}^{(k)},\boldsymbol{\mu}^{(k)},\rho_{k})$4:     ”Denoising”
    Sub-Problem: $\mathbf{Z}^{(k+1)}={\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathcal{N}_{\boldsymbol{\theta}}}\left(\mathbf{X}^{(k+1)}+\boldsymbol{\mu}^{(k)}\right)$5:     Lagrange
    Multiplier Update: $\boldsymbol{\mu}^{(k+1)}=\boldsymbol{\mu}^{(k)}+\left(\mathbf{X}^{(k+1)}-\mathbf{Z}^{(k+1)}\right)$6:     $\Delta_{k+1}=\frac{1}{\sqrt{n}}\left(||\mathbf{X}^{(k+1)}-\mathbf{X}^{(k)}||_{2}+||\mathbf{Z}^{(k+1)}-\mathbf{Z}^{(k)}||_{2}+||\boldsymbol{\mu}^{(k+1)}-\boldsymbol{\mu}^{(k)}||_{2}\right)$7:     if $\Delta_{k+1}\geq\eta\Delta_{k}$
    and $\rho_{k+1}\leq\rho_{max}$ then8:        $\rho_{k+1}=\gamma\rho_{k}$9:     else10:        $\rho_{k+1}=\rho_{k}$11:     end if12:     if $\|\mathbf{Z}^{(k+1)}-\mathbf{X}^{(k+1)}\|_{2}<\epsilon$ then13:        stop14:     end if15:  end for16:  return
     $\left\{\mathbf{X}^{(k+1)}\right\}$'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '1:  初始化：设定 $\rho_{0},\rho_{max},\eta\in[0,1),\gamma>1,\Delta_{0}=0$，$\mathbf{X}^{(0)}=\mathbf{0},\mathbf{Z}^{(0)}=\mathbf{0},\boldsymbol{\mu}^{(0)}=\mathbf{0},\epsilon$
    2:  对于 $k=0$ 到 $N_{it}$ 执行 {主循环} 3:     去卷积子问题：$\mathbf{X}^{(k+1)}=FISTA(\textbf{Y},\mathbf{X}^{(k)},\mathbf{Z}^{(k)},\boldsymbol{\mu}^{(k)},\rho_{k})$
    4:     “去噪”子问题：$\mathbf{Z}^{(k+1)}={\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathcal{N}_{\boldsymbol{\theta}}}\left(\mathbf{X}^{(k+1)}+\boldsymbol{\mu}^{(k)}\right)$
    5:     拉格朗日乘子更新：$\boldsymbol{\mu}^{(k+1)}=\boldsymbol{\mu}^{(k)}+\left(\mathbf{X}^{(k+1)}-\mathbf{Z}^{(k+1)}\right)$
    6:     $\Delta_{k+1}=\frac{1}{\sqrt{n}}\left(||\mathbf{X}^{(k+1)}-\mathbf{X}^{(k)}||_{2}+||\mathbf{Z}^{(k+1)}-\mathbf{Z}^{(k)}||_{2}+||\boldsymbol{\mu}^{(k+1)}-\boldsymbol{\mu}^{(k)}||_{2}\right)$
    7:     如果 $\Delta_{k+1}\geq\eta\Delta_{k}$ 且 $\rho_{k+1}\leq\rho_{max}$，则 8:         $\rho_{k+1}=\gamma\rho_{k}$
    9:     否则 10:         $\rho_{k+1}=\rho_{k}$ 11:     结束 如果 12:     如果 $\|\mathbf{Z}^{(k+1)}-\mathbf{X}^{(k+1)}\|_{2}<\epsilon$，则
    13:         停止 14:     结束 如果 15:   结束 循环 16:   返回 $\left\{\mathbf{X}^{(k+1)}\right\}$'
- en: 3.5 Implementation and choice of parameters for Network architecture
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 网络架构的实现与参数选择
- en: 'We describe here our practical choices for the implementation of the algorithms.
    For the Tikhonet, the hyperparameter $\lambda_{i}$ that controls the balance in
    between the data fidelity term and the quadratic regularization in Eq. [11](#S3.E11
    "In 3.3 Tikhonet: Tikhonov deconvolution post-processed by a Deep Neural Network
    ‣ 3 Image Deconvolution with Space Variant PSF ‣ Deep Learning for space-variant
    deconvolution in galaxy surveys") needs to be set for each galaxy. This can be
    done either manually by selecting an optimal value as a function of an estimate
    of the SNR, or by using automated procedures such as generalized cross-validation
    (GCV) (Golub et al. [1979](#bib.bib29)), the L-curve methode (Christian Hansen
    & O’leary [1993](#bib.bib17)), the Morozov discrepancy principle (Werner Engl
    et al. [1996](#bib.bib88)), various Stein Unbiased Risk Estimate (SURE) minimization
    (C. Eldar [2009](#bib.bib13); Pesquet et al. [2009](#bib.bib64); Deledalle et al.
    [2014](#bib.bib21)), or using a hierarchical Bayesian framework (Orieux et al.
    [2010](#bib.bib62); Pereyra et al. [2015](#bib.bib63)). We compared these approach,
    and report the results obtained by the SURE prediction risk minimization which
    lead to the best results with the GCV approach.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里描述了算法实现的实际选择。对于Tikhonet，控制数据保真项和平衡二次正则化的超参数$\lambda_{i}$需要为每个星系设置。这可以通过选择一个基于SNR估计的最佳值手动完成，或者使用自动化程序如广义交叉验证（GCV）（Golub等人[1979](#bib.bib29)）、L曲线方法（Christian
    Hansen & O’leary [1993](#bib.bib17)）、Morozov不一致原理（Werner Engl等人[1996](#bib.bib88)）、各种Stein无偏风险估计（SURE）最小化（C.
    Eldar [2009](#bib.bib13)；Pesquet等人[2009](#bib.bib64)；Deledalle等人[2014](#bib.bib21)），或使用分层贝叶斯框架（Orieux等人[2010](#bib.bib62)；Pereyra等人[2015](#bib.bib63)）来完成。我们比较了这些方法，并报告了通过SURE预测风险最小化获得的结果，该方法在与GCV方法相比时取得了最佳结果。
- en: For the ADMM, the parameters $\rho_{0}$, $\rho_{max}$, $\eta$, $\epsilon$ and
    $\gamma$ have been selected manually, as a balance between stabilizing quickly
    the algorithm (in particular high $\rho$) and favouring the minimization of the
    data fidelity term in the first steps (low $\rho$). We investigated in particular
    the choice of $\rho_{0}$ which illustrate how the continuation scheme impacts
    the solution.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于ADMM，参数$\rho_{0}$、$\rho_{max}$、$\eta$、$\epsilon$和$\gamma$是手动选择的，以在快速稳定算法（特别是高$\rho$）与在前期步骤中有利于数据保真项最小化（低$\rho$）之间取得平衡。我们特别研究了$\rho_{0}$的选择，这说明了继续方案如何影响解决方案。
- en: The DNNs were coded in Keras¹¹1https://keras.io with Tensorflow ²²2https://www.tensorflow.org
    as backend. For the proposed XDense U-Net, 4 scales were selected with an increasing
    number of layers for each scale (to capture distant correlations). Each separable
    convolution was composed of $3\times 3$ spatial filters and a growth factor of
    12 was selected for the dense blocks. The total number of trainable parameters
    was 184301. We also implemented a ”classical” U-Net to test the efficiency of
    the proposed XDense U-Net architecture. For this U-Net, we choose 3 scales with
    2 layers per scale and 20 feature maps per layer in the first scale, to end up
    with 206381 trainable parameters ($12\%$ more than the XDense U-Net implementation).
    In both networks we used batch normalization and rectified linear units for the
    activation. We also tested for our proposed approach weighted sigmoid activations
    (or swish in Elfwing et al. ([2018](#bib.bib24))) which seems to slightly improve
    the results but at the cost of increasing the computational burden and therefore
    we did not use them in the following results.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: DNNs在Keras¹¹1https://keras.io上编码，使用Tensorflow ²²2https://www.tensorflow.org作为后端。对于所提议的XDense
    U-Net，选择了4个尺度，每个尺度有递增数量的层（以捕捉远程相关性）。每个可分离卷积由$3\times 3$空间滤波器组成，密集块的增长因子选择为12。总的可训练参数数量为184301。我们还实现了一个“经典”U-Net以测试提出的XDense
    U-Net架构的效率。对于这个U-Net，我们选择了3个尺度，每个尺度有2层，每层在第一个尺度中有20个特征图，最终得到206381个可训练参数（比XDense
    U-Net实现多$12\%$）。在这两个网络中，我们使用了批量归一化和修正线性单元作为激活函数。我们还测试了我们提出的方法的加权Sigmoid激活（或Elfwing等人（[2018](#bib.bib24)）中的swish），这似乎略微改善了结果，但增加了计算负担，因此在后续结果中没有使用。
- en: In the training phase, we use 20 epochs, a batch size of 32 and the Adam optimizer
    was selected (we keep the default parameters) to minimize the mean squared error
    (MSE) cost function. After each epoch, we save the network parameters only if
    they improve the MSE on the validation set.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练阶段，我们使用 20 个 epoch，批处理大小为 32，选择了 Adam 优化器（保持默认参数）来最小化均方误差 (MSE) 代价函数。每个 epoch
    后，仅当网络参数在验证集上提高 MSE 时，我们才保存这些参数。
- en: 4 Experiments
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: In this section, we describe how we generated the simulations used for learning
    networks and testing our deconvolution schemes, as well as the criteria we will
    use to compare the different deconvolution techniques.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了生成用于学习网络和测试去卷积方案的模拟数据的方法，以及我们将用于比较不同去卷积技术的标准。
- en: 4.1 Dataset generation
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 数据集生成
- en: We use GalSim³³3https://github.com/GalSim-developers/GalSim (Rowe et al. [2015](#bib.bib70))
    to generate realistic images of galaxies for training our networks and testing
    our deconvolution approaches. We essentially follow the approach used in GREAT3
    (Mandelbaum et al. [2014](#bib.bib54)) to generate the realistic space branch
    from high resolution HST images, but choosing the PSFs in a set of 600 Euclid-like
    PSFs (the same as in Farrens et al. ([2017](#bib.bib26))). The process is illustrated
    in Fig. [3](#S4.F3 "Figure 3 ‣ 4.1 Dataset generation ‣ 4 Experiments ‣ Deep Learning
    for space-variant deconvolution in galaxy surveys").
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 GalSim³³3https://github.com/GalSim-developers/GalSim (Rowe et al. [2015](#bib.bib70))
    来生成用于训练我们网络和测试我们的去卷积方法的真实星系图像。我们基本上遵循了 GREAT3 (Mandelbaum et al. [2014](#bib.bib54))
    中用于从高分辨率 HST 图像生成真实空间分支的方法，但选择了 600 个类似 Euclid 的 PSFs（与 Farrens et al. ([2017](#bib.bib26))
    中的相同）。这一过程如图 [3](#S4.F3 "图 3 ‣ 4.1 数据集生成 ‣ 4 实验 ‣ 用于星系调查中的空间变异去卷积的深度学习") 所示。
- en: 'A HST galaxy is randomly selected from the set of about 58000 galaxies used
    in the GREAT3 challenge, deconvolved with its PSF, and random shift (taken from
    a uniform distribution in $[-1,1]$ pixel), rotation and shear are applied. The
    same cut in SNR is performed as in GREAT3 (Mandelbaum et al. [2014](#bib.bib54))
    , so as to obtain a realistic set of galaxies that would be observed in a SNR
    range $[20,100]$ when the noise level is as in GREAT3\. In this work we use the
    same definition of SNR as in this challenge:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 从约 58000 个用于 GREAT3 挑战的星系集中随机选择一个 HST 星系，使用其 PSF 进行去卷积，并应用随机位移（从 $[-1,1]$ 像素的均匀分布中抽取）、旋转和剪切。进行与
    GREAT3 (Mandelbaum et al. [2014](#bib.bib54)) 中相同的 SNR 截取，以便获得一个现实的星系集合，这些星系在
    SNR 范围 $[20,100]$ 内被观察到，当噪声水平如 GREAT3 中所示。在这项工作中，我们使用与该挑战中相同的 SNR 定义：
- en: '|  | $\mathrm{SNR}\left(\mathbf{X}_{\mathbf{i}}\right)=\frac{&#124;&#124;\mathbf{X}_{\mathbf{i}}&#124;&#124;_{2}}{\sigma}$
    |  | (14) |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathrm{SNR}\left(\mathbf{X}_{\mathbf{i}}\right)=\frac{&#124;&#124;\mathbf{X}_{\mathbf{i}}&#124;&#124;_{2}}{\sigma}$
    |  | (14) |'
- en: where $\sigma$ is the standard deviation of the noise. This SNR corresponds
    to an optimistic SNR for detection when the galaxy profile $\mathbf{X}_{\mathbf{i}}$
    is known. In other (experimental) definitions, the minimal SNR is indeed closer
    to 10, similarly to what is usually considered in weak lensing studies (Mandelbaum
    et al. [2014](#bib.bib54)).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\sigma$ 是噪声的标准差。这一 SNR 对于当星系轮廓 $\mathbf{X}_{\mathbf{i}}$ 已知时的检测来说是一个乐观的
    SNR。在其他（实验性）定义中，最小 SNR 实际上更接近 10，这与通常在弱引力透镜研究中考虑的情况相似 (Mandelbaum et al. [2014](#bib.bib54))。
- en: If the cut in SNR is passed, to obtain the target image in a $96\times 96$ grid
    with pixel size $0.05^{\prime\prime}$, we first convolve the HST deconvolved galaxy
    image with a Gaussian PSF with $FWHM=0.07^{\prime\prime}$ to ensure no aliasing
    occurs after the subsampling. To simulate the observed galaxy without extra noise,
    we convolve the HST deconvolved image with a PSF randomly selected among about
    600 Euclid-like PSFs (the same set as used in Farrens et al. ([2017](#bib.bib26))).
    Note that the same galaxy rotated by $90\degree$ is also simulated as in GREAT3.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果通过了 SNR 截取，为了在 $96\times 96$ 网格中获得目标图像，像素大小为 $0.05^{\prime\prime}$，我们首先用 $FWHM=0.07^{\prime\prime}$
    的高斯 PSF 对 HST 去卷积星系图像进行卷积，以确保在下采样后没有别名效应。为了模拟没有额外噪声的观测星系，我们用从约 600 个类似 Euclid
    的 PSFs 中随机选择的 PSF 对 HST 去卷积图像进行卷积（与 Farrens et al. ([2017](#bib.bib26)) 中使用的相同集）。注意，与
    GREAT3 中一样，旋转 $90\degree$ 的相同星系也会被模拟。
- en: Because we use as inputs real HST galaxies, noise from HST images propagate
    to our target and observed images, and is coloured by the deconvolution/reconvolution
    process. We did not want to denoise the original galaxy images to avoid losing
    substructures in the target images (and making them less ”realistic”), and as
    this noise level is lower than the noise added in our simulations we expect it
    to change marginally our results - and not the ranking of methods.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用的是实际的 HST 星系作为输入，HST 图像中的噪声传播到我们的目标和观测图像中，并且被去卷积/重卷积过程着色。我们不希望去噪原始星系图像，以避免在目标图像中丢失子结构（并使其变得不那么“真实”），且由于这个噪声水平低于我们模拟中添加的噪声，我们预计它对我们的结果变化很小——并不会改变方法的排名。
- en: This process is repeated so that we end up with about 210000 simulated observed
    galaxies and their corresponding target. For the learning, 190000 galaxies are
    employed, and 10000 for the validation set. The extra 10000 are used for testing
    our approaches.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程会重复进行，最终得到大约 210000 个模拟观测星系及其对应的目标星系。在学习阶段，使用了 190000 个星系，10000 个用于验证集。额外的
    10000 个用于测试我们的方法。
- en: '![Refer to caption](img/be63f0be4354c391f9696f705358849d.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/be63f0be4354c391f9696f705358849d.png)'
- en: 'Figure 3: Set up for a GalSim simulated realistic galaxy. In the upper branch
    we obtain the targeted galaxy. In the lower branch, we simulate the corresponding
    Euclid-like observed galaxy. Note that in these figures, a log-scale was adopted
    for the PSFs to illustrate its complicated structure.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：GalSim 模拟真实星系的设置。在上支路中，我们获得了目标星系。在下支路中，我们模拟了对应的类似 Euclid 的观测星系。请注意，这些图中采用了对数刻度来展示点扩散函数的复杂结构。
- en: In the learning phase, additive white Gaussian noise is added to the galaxy
    batches with standard deviation chosen so as to obtain a galaxy in a prescribed
    SNR range. For the Tikhonet, we choose randomly for each galaxy in the batch a
    $\mathrm{SNR}$ in the range $[20,100]$, which corresponds to selecting galaxies
    from the limit of detection to galaxies with observable substructures, as illustrated
    in Fig [4](#S4.F4 "Figure 4 ‣ 4.1 Dataset generation ‣ 4 Experiments ‣ Deep Learning
    for space-variant deconvolution in galaxy surveys"). For the ADMMnet, we learn
    a denoising network for a constant noise standard deviation of $\sigma=0.04$ (same
    level as in GREAT3).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习阶段，向星系批次中添加了具有标准差的加性白噪声，以获得指定信噪比范围内的星系。对于 Tikhonet，我们为批次中的每个星系随机选择一个范围在 $[20,100]$
    的 $\mathrm{SNR}$，这对应于从探测极限到具有可观测子结构的星系，如图 [4](#S4.F4 "Figure 4 ‣ 4.1 Dataset generation
    ‣ 4 Experiments ‣ Deep Learning for space-variant deconvolution in galaxy surveys")所示。对于
    ADMMnet，我们为常数噪声标准差 $\sigma=0.04$（与 GREAT3 中的水平相同）学习去噪网络。
- en: 'We then test the relative performance of the different approaches in a test
    set for fixed values: $\mathrm{SNR}\in\{20,40,60,80,100\}$ to better characterize
    (and discriminate) them, and for a fixed standard deviation of $\sigma=0.04$ corresponding
    to what was simulated in GREAT3 for the real galaxy space branch to obtain results
    on a representative observed galaxy set. The corresponding distribution of SNR
    in the last scenario is represented in Fig. [5](#S4.F5 "Figure 5 ‣ 4.1 Dataset
    generation ‣ 4 Experiments ‣ Deep Learning for space-variant deconvolution in
    galaxy surveys"). All the techniques are compared on exactly the same test sets.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们在测试集中对不同方法的相对性能进行测试，固定值为：$\mathrm{SNR}\in\{20,40,60,80,100\}$，以更好地表征（和区分）它们，并且固定标准差为
    $\sigma=0.04$，这对应于在 GREAT3 中模拟的真实星系空间分支，以获得代表性的观测星系集的结果。在最后一种情况下的 SNR 分布如图 [5](#S4.F5
    "Figure 5 ‣ 4.1 Dataset generation ‣ 4 Experiments ‣ Deep Learning for space-variant
    deconvolution in galaxy surveys")所示。所有技术在完全相同的测试集上进行比较。
- en: For the ADMMnet approach when testing at different SNRs, we need to adjust the
    noise level in the galaxy images to the level of noise in the learning phase.
    We therefore rescale the galaxy images to reach this targeted noise level, based
    on noise level estimation in the images. This is performed via a robust standard
    procedure based on computing the median absolute deviation in the wavelet domain
    (using orthogonal daubechies wavelets with 3 vanishing moments).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 ADMMnet 方法，在不同 SNR 测试时，我们需要将星系图像中的噪声水平调整到学习阶段的噪声水平。因此，我们根据图像中的噪声水平估计，将星系图像重新缩放到目标噪声水平。这是通过计算小波域中的中位绝对偏差（使用具有
    3 个消失矩的正交 Daubechies 小波）来完成的。
- en: '![Refer to caption](img/3786ecb13b81367a90d6dcca977cb462.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/3786ecb13b81367a90d6dcca977cb462.png)'
- en: 'Figure 4: Range of SNR used for the training and for testing in the simulations.
    From left to right: targeted galaxy image, then observed convolved images at increasing
    SNR. In our definition, $\mathrm{SNR}=20$ is barely at the galaxy detection limit,
    while at $\mathrm{SNR}=100$ galaxy substructures can be visualized.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：用于训练和测试的SNR范围。从左到右：目标星系图像，然后是逐渐增加SNR的观测卷积图像。在我们的定义中，$\mathrm{SNR}=20$ 刚好在星系检测极限，而$\mathrm{SNR}=100$
    时星系子结构可以被可视化。
- en: '![Refer to caption](img/502acd8722f887d9a794ffdb1e5d598e.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/502acd8722f887d9a794ffdb1e5d598e.png)'
- en: 'Figure 5: Distribution of SNR of simulated galaxies for constant noise simulations
    ($\sigma=0.04$). The peak of the distribution is at about $\mathrm{SNR}=30$, and
    the mean SNR is $\mathrm{SNR}=54$.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：常噪声模拟下模拟星系的信噪比（SNR）分布（$\sigma=0.04$）。分布的峰值约为$\mathrm{SNR}=30$，均值SNR为$\mathrm{SNR}=54$。
- en: 4.2 Quality criteria
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 质量标准
- en: 'The performance of the deconvolution schemes is measured according to two different
    criteria, related to pixel error and shape measurement errors. For pixel error
    we select a robust estimator:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 去卷积方案的性能根据两种不同标准来衡量，涉及像素误差和形状测量误差。对于像素误差，我们选择一个稳健的估计器：
- en: '|  | $\mathrm{P_{err}}\left(\widehat{\mathbf{X}}\right)=\mathrm{MED}\left(\frac{\&#124;\widehat{\mathbf{x}_{\mathbf{i}}}-\mathbf{x}^{(t)}_{\mathbf{i}}\&#124;^{2}_{2}}{\&#124;\mathbf{x}^{(t)}_{\mathbf{i}}\&#124;_{2}^{2}}\right)_{i=1..n_{g}}$
    |  | (15) |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathrm{P_{err}}\left(\widehat{\mathbf{X}}\right)=\mathrm{MED}\left(\frac{\&#124;\widehat{\mathbf{x}_{\mathbf{i}}}-\mathbf{x}^{(t)}_{\mathbf{i}}\&#124;^{2}_{2}}{\&#124;\mathbf{x}^{(t)}_{\mathbf{i}}\&#124;_{2}^{2}}\right)_{i=1..n_{g}}$
    |  | (15) |'
- en: where $\mathbf{x}^{(t)}_{\mathbf{i}}$ is the targeted value, and with $\mathrm{MED}$
    the median over the relative mean squared error computed for each galaxy $\mathbf{x}_{\mathbf{i}}$
    in the test set, in a central window of $41\times 41$ pixels common to all approaches.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathbf{x}^{(t)}_{\mathbf{i}}$是目标值，$\mathrm{MED}$是对测试集中每个星系$\mathbf{x}_{\mathbf{i}}$计算的相对均方误差的中位数，在所有方法共有的$41\times
    41$像素的中央窗口中。
- en: For shape measurement errors, we compute the ellipticity using a KSB approach
    implemented in shapelens⁴⁴4https://github.com/pmelchior/shapelens (Kaiser et al.
    [1995](#bib.bib41); Viola et al. [2011](#bib.bib87)), that additionally computes
    an adapted circular weight function from the data.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于形状测量误差，我们使用KSB方法计算椭圆度，该方法在shapelens中实现⁴⁴4https://github.com/pmelchior/shapelens（Kaiser等[1995](#bib.bib41)；Viola等[2011](#bib.bib87)），并从数据中计算适应的圆形加权函数。
- en: We first apply this KSB method to the targets, taking as well into account the
    target isotropic gaussian PSF, to obtain reference complex ellipticities $\epsilon_{i}$
    and windows. We then compute the complex ellipticity $\widehat{\epsilon_{i}}$
    of the deconvolved galaxies using the same circular weight functions as their
    target counterpart. Finally, we compute
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将此KSB方法应用于目标，同时考虑目标各向同性高斯PSF，以获得参考的复合椭圆度$\epsilon_{i}$和窗口。然后，我们使用与目标对应的相同圆形加权函数计算去卷积星系的复合椭圆度$\widehat{\epsilon_{i}}$。最后，我们计算
- en: '|  | $\mathrm{\epsilon_{err}}\left(\widehat{\mathbf{X}}\right)=\mathrm{MED}\left(\&#124;\epsilon_{i}^{(t)}-\widehat{\epsilon_{i}}\&#124;_{2}\right)_{i=1..n_{g}}$
    |  | (16) |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathrm{\epsilon_{err}}\left(\widehat{\mathbf{X}}\right)=\mathrm{MED}\left(\&#124;\epsilon_{i}^{(t)}-\widehat{\epsilon_{i}}\&#124;_{2}\right)_{i=1..n_{g}}$
    |  | (16) |'
- en: to obtain a robust estimate of the ellipticity error in the windows set up by
    the target images, again in a central window of $41\times 41$ pixels common to
    all approaches..
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得目标图像设置窗口中的椭圆度误差的稳健估计，再次在所有方法共有的$41\times 41$像素的中央窗口中进行。
- en: We also report the distribution of pixel and ellipticity errors prior to applying
    the median when finer assessments need to be made.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还报告了应用中位数之前的像素和椭圆度误差的分布，以便在需要更精细评估时使用。
- en: 5 Results
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结果
- en: 5.1 Setting the Tikhonet architecture and hyperparameters
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 设置Tikhonet架构和超参数
- en: 'For the Tikhonet, the key parameters to set are the hyperparameters $\lambda_{i}$
    in Eq. [11](#S3.E11 "In 3.3 Tikhonet: Tikhonov deconvolution post-processed by
    a Deep Neural Network ‣ 3 Image Deconvolution with Space Variant PSF ‣ Deep Learning
    for space-variant deconvolution in galaxy surveys"). In Fig. [6](#S5.F6 "Figure
    6 ‣ 5.1 Setting the Tikhonet architecture and hyperparameters ‣ 5 Results ‣ Deep
    Learning for space-variant deconvolution in galaxy surveys"), these hyperparameters
    are set to the parameters minimizing the SURE multiplied by factors ranging from
    10 to 0.01 at $\mathrm{SNR}=20$, for the proposed X-Dense architecture (similar
    visual results are obtained for the ”classical” U-Net). It appears that for the
    lowest factor, corresponding to the smallest regularization of deconvolution (i.e.
    more noise added in the deconvolved image), the Tikhonet is not able to perform
    as well as for intermediate values, in particular for exactly the SURE minimizer.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Tikhonet，关键参数是方程[11](#S3.E11 "在 3.3 Tikhonet：通过深度神经网络处理的 Tikhonov 解卷积 ‣ 3
    图像解卷积与空间变换 PSF ‣ 深度学习在银河系调查中的空间变换解卷积")中的超参数 $\lambda_{i}$。在图[6](#S5.F6 "图 6 ‣
    5.1 设置 Tikhonet 架构和超参数 ‣ 5 结果 ‣ 深度学习在银河系调查中的空间变换解卷积")中，这些超参数被设置为 SURE 最小化的参数，并在
    $\mathrm{SNR}=20$ 时乘以从 10 到 0.01 的因子，适用于所提出的 X-Dense 架构（“经典” U-Net 的视觉结果类似）。对于最低因子，即对应于解卷积的最小正则化（即在解卷积图像中添加更多噪声），Tikhonet
    的表现不如在中间值时，特别是在确切的 SURE 最小化器时。
- en: '![Refer to caption](img/7ce26d73938d8f0e95fa3a7171561847.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7ce26d73938d8f0e95fa3a7171561847.png)'
- en: 'Figure 6: Visual impact of the hyperparameter choice for the Tikhonet approach
    at SNR20\. Top: target and observations, followed by SURE estimates with different
    multiplicative factor. Bottom: residuals associated to the top row.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：SNR20 下 Tikhonet 方法超参数选择的视觉影响。上图：目标和观察，接着是不同乘法因子的 SURE 估计。下图：与上图相关的残差。
- en: This is confirmed in Fig. [7](#S5.F7 "Figure 7 ‣ 5.1 Setting the Tikhonet architecture
    and hyperparameters ‣ 5 Results ‣ Deep Learning for space-variant deconvolution
    in galaxy surveys") reporting the pixel errors for both proposed X-Dense and ”classical”
    architecture, and Fig. [8](#S5.F8 "Figure 8 ‣ 5.1 Setting the Tikhonet architecture
    and hyperparameters ‣ 5 Results ‣ Deep Learning for space-variant deconvolution
    in galaxy surveys") for the ellipticity errors.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这在图[7](#S5.F7 "图 7 ‣ 5.1 设置 Tikhonet 架构和超参数 ‣ 5 结果 ‣ 深度学习在银河系调查中的空间变换解卷积")中得到了确认，该图报告了所提出的
    X-Dense 和“经典”架构的像素误差，以及图[8](#S5.F8 "图 8 ‣ 5.1 设置 Tikhonet 架构和超参数 ‣ 5 结果 ‣ 深度学习在银河系调查中的空间变换解卷积")中的椭圆度误差。
- en: '![Refer to caption](img/7dd940528437174c246d74441295d767.png)![Refer to caption](img/8ff5a64e5219222ffd4626b2f70ad28f.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7dd940528437174c246d74441295d767.png)![参考说明](img/8ff5a64e5219222ffd4626b2f70ad28f.png)'
- en: 'Figure 7: Impact of of the hyperparameter multiplicative factor value for the
    Tikhonet using the proposed XDense U-Net architecture (left) and ”classical” U-Net
    architecture (right), in terms of pixel errors.The box indicate quartiles, while
    the vertical bars encompass $90\%$ of the data. Outliers are displayed with circles.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：使用所提出的 XDense U-Net 架构（左）和“经典” U-Net 架构（右）时，Tikhonet 超参数乘法因子值对像素误差的影响。箱体表示四分位数，而垂直条表示数据的
    $90\%$。异常值用圆圈表示。
- en: '![Refer to caption](img/a305dc55bf50717d970612d316668127.png)![Refer to caption](img/e3b258bb54ea42e80547527d743de14e.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a305dc55bf50717d970612d316668127.png)![参考说明](img/e3b258bb54ea42e80547527d743de14e.png)'
- en: 'Figure 8: Impact of the hyperparameter multiplicative factor value for the
    Tikhonet using the proposed XDense U-Net architecture (left) and ”classical” U-Net
    architecture (right), in terms of ellipticity errors.The box indicate quartiles,
    while the vertical bars encompass $90\%$ of the data. Outliers are displayed with
    circles.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：使用所提出的 XDense U-Net 架构（左）和“经典” U-Net 架构（右）时，Tikhonet 超参数乘法因子值对椭圆度误差的影响。箱体表示四分位数，而垂直条表示数据的
    $90\%$。异常值用圆圈表示。
- en: For both architectures, best results in terms of pixel or ellipticity errors
    are consistently obtained across all SNR tested for values of the multiplicative
    factor between 0.1 and 1\. Higher multiplicative factors also lead to larger extreme
    errors in particular at low SNR. In the following, we therefore set this parameter
    to the SURE minimizer.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这两种架构，像素或椭圆度误差的最佳结果在所有测试的 SNR 中均稳定地获得，乘法因子值在 0.1 到 1 之间。较高的乘法因子也会导致较大的极端误差，特别是在低
    SNR 时。因此，我们在后续中将该参数设置为 SURE 最小化器。
- en: Concerning the choice of architecture, Fig. [7](#S5.F7 "Figure 7 ‣ 5.1 Setting
    the Tikhonet architecture and hyperparameters ‣ 5 Results ‣ Deep Learning for
    space-variant deconvolution in galaxy surveys") illustrates that the XDense U-Net
    provides across SNR less extreme outliers in pixel errors for a multiplicative
    factor of 10, which is however far from providing the best results. Looking more
    closely at the median error values in Table [1](#S5.T1 "Table 1 ‣ 5.1 Setting
    the Tikhonet architecture and hyperparameters ‣ 5 Results ‣ Deep Learning for
    space-variant deconvolution in galaxy surveys") for the SURE minimizers, we see
    that slightly better results are consistently obtained for the proposed XDense
    U-Net architecture. In this experiment, the XDense obtains 4% (resp. 3%) less
    pixel errors at $\mathrm{SNR}=20$ (resp. $\mathrm{SNR}=100$), and the most significant
    difference is an about 8% improvement in ellipticity measurement at $\mathrm{SNR}=100$.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 关于架构的选择，图[7](#S5.F7 "Figure 7 ‣ 5.1 Setting the Tikhonet architecture and hyperparameters
    ‣ 5 Results ‣ Deep Learning for space-variant deconvolution in galaxy surveys")说明XDense
    U-Net在SNR范围内提供的像素误差中极端离群值较少，乘法因子为10，但这距离提供最佳结果还有很大差距。更仔细地查看表[1](#S5.T1 "Table
    1 ‣ 5.1 Setting the Tikhonet architecture and hyperparameters ‣ 5 Results ‣ Deep
    Learning for space-variant deconvolution in galaxy surveys")中SURE最小化器的中位数误差值，我们看到提出的XDense
    U-Net架构一致地获得了稍微更好的结果。在这项实验中，XDense在$\mathrm{SNR}=20$（分别在$\mathrm{SNR}=100$时）获得了4%（分别为3%）较少的像素误差，最显著的差异是$\mathrm{SNR}=100$时椭圆度测量约8%的改进。
- en: 'Table 1: Comparison of U-Net architectures for the SURE selected hyperparameter.
    The first number is obtained with the XDense U-Net architecture, the second in
    parentheses with the ”classical” U-Net architecture.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：对于SURE选择的超参数，U-Net架构的比较。第一个数字是使用XDense U-Net架构获得的，第二个数字（括号内）是使用“经典”U-Net架构获得的。
- en: $\mathrm{SNR}=20$ $\mathrm{SNR}=40$ $\mathrm{SNR}=60$ $\mathrm{SNR}=80$ $\mathrm{SNR}=100$
    Median Pixel Error 0.157 (0.163) 0.117 (0.121) 0.105 (0.106) 0.097 (0.097) 0.090
    (0.093) Median Ellipticity Error 0.109 (0.110) 0.063 (0.064) 0.045 (0.046) 0.035
    (0.038) 0.030 (0.033)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: $\mathrm{SNR}=20$ $\mathrm{SNR}=40$ $\mathrm{SNR}=60$ $\mathrm{SNR}=80$ $\mathrm{SNR}=100$
    中位数像素误差 0.157 (0.163) 0.117 (0.121) 0.105 (0.106) 0.097 (0.097) 0.090 (0.093)
    中位数椭圆度误差 0.109 (0.110) 0.063 (0.064) 0.045 (0.046) 0.035 (0.038) 0.030 (0.033)
- en: 5.2 Setting the ADMMnet architecture and hyperparameters
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 设置ADMMnet架构和超参数
- en: For the ADMMnet, we set manually the hyperparameters $\rho_{max}=200$, $\epsilon=0.01$
    to lead to ultimate stabilization of the algorithm, $\eta=0.5$ and $\gamma=1.4$
    to explore intermediate $\rho$ values, and we investigate the choice of parameter
    $\rho_{0}$ to illustrate the impact of the continuation scheme on the solution.
    This is illustrated in Fig. [9](#S5.F9 "Figure 9 ‣ 5.2 Setting the ADMMnet architecture
    and hyperparameters ‣ 5 Results ‣ Deep Learning for space-variant deconvolution
    in galaxy surveys") at high SNR, and Fig. [10](#S5.F10 "Figure 10 ‣ 5.2 Setting
    the ADMMnet architecture and hyperparameters ‣ 5 Results ‣ Deep Learning for space-variant
    deconvolution in galaxy surveys") at low SNR for the proposed XDense U-Net architecture.
    When $\rho_{0}$ is small, higher frequencies are recovered in the solution as
    illustrated in galaxy substructures in Fig. [9](#S5.F9 "Figure 9 ‣ 5.2 Setting
    the ADMMnet architecture and hyperparameters ‣ 5 Results ‣ Deep Learning for space-variant
    deconvolution in galaxy surveys"), but this could lead to artefacts at low SNR
    as illustrated in Fig. [10](#S5.F10 "Figure 10 ‣ 5.2 Setting the ADMMnet architecture
    and hyperparameters ‣ 5 Results ‣ Deep Learning for space-variant deconvolution
    in galaxy surveys").
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 对于ADMMnet，我们手动设置了超参数$\rho_{max}=200$，$\epsilon=0.01$以实现算法的最终稳定性，$\eta=0.5$和$\gamma=1.4$用于探索中间的$\rho$值，并且我们调查了参数$\rho_{0}$的选择，以说明继续方案对解决方案的影响。这在高SNR下的图[9](#S5.F9
    "Figure 9 ‣ 5.2 Setting the ADMMnet architecture and hyperparameters ‣ 5 Results
    ‣ Deep Learning for space-variant deconvolution in galaxy surveys")和低SNR下的图[10](#S5.F10
    "Figure 10 ‣ 5.2 Setting the ADMMnet architecture and hyperparameters ‣ 5 Results
    ‣ Deep Learning for space-variant deconvolution in galaxy surveys")中进行了说明，涉及提出的XDense
    U-Net架构。当$\rho_{0}$较小时，如图[9](#S5.F9 "Figure 9 ‣ 5.2 Setting the ADMMnet architecture
    and hyperparameters ‣ 5 Results ‣ Deep Learning for space-variant deconvolution
    in galaxy surveys")中的银河子结构所示，解决方案中恢复了更高的频率，但这可能会在低SNR下导致伪影，如图[10](#S5.F10 "Figure
    10 ‣ 5.2 Setting the ADMMnet architecture and hyperparameters ‣ 5 Results ‣ Deep
    Learning for space-variant deconvolution in galaxy surveys")所示。
- en: '![Refer to caption](img/2bb42520a74f18e54f65a06efbd08997.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/2bb42520a74f18e54f65a06efbd08997.png)'
- en: 'Figure 9: Visual impact of the initialization of $\rho$ for the ADMMnet for
    $\mathrm{SNR}=100$. Top: target and observations, followed by ADMM estimates with
    different augmented lagrangian parameter $\rho_{0}$. Bottom: residuals associated
    to the top row.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：$\mathrm{SNR}=100$ 时 ADMMnet 对 $\rho$ 初始化的视觉影响。顶部：目标和观测，接着是不同增广拉格朗日参数 $\rho_{0}$
    的 ADMM 估计。底部：与顶行相关的残差。
- en: '![Refer to caption](img/8e53efa807499d1d28c72e17c2858fd3.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8e53efa807499d1d28c72e17c2858fd3.png)'
- en: 'Figure 10: Visual impact of the initialization of $\rho$ for the ADMMnet for
    $\mathrm{SNR}=20$. Top: target and observations, followed by SURE estimates with
    different augmented lagrangian parameter $\rho_{0}$. Bottom: residuals associated
    to the top row.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：$\mathrm{SNR}=20$ 时 ADMMnet 对 $\rho$ 初始化的视觉影响。顶部：目标和观测，接着是不同增广拉格朗日参数 $\rho_{0}$
    的 SURE 估计。底部：与顶行相关的残差。
- en: Quantitative results concerning the two architectures are presented in Fig. [11](#S5.F11
    "Figure 11 ‣ 5.2 Setting the ADMMnet architecture and hyperparameters ‣ 5 Results
    ‣ Deep Learning for space-variant deconvolution in galaxy surveys") for pixel
    errors and Fig. [12](#S5.F12 "Figure 12 ‣ 5.2 Setting the ADMMnet architecture
    and hyperparameters ‣ 5 Results ‣ Deep Learning for space-variant deconvolution
    in galaxy surveys") for ellipticity errors. The distribution of errors is very
    stable with respect to the hyperparameter $\rho_{0}$ value, and similar for both
    architectures.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这两种架构的定量结果见图 [11](#S5.F11 "图 11 ‣ 5.2 设置 ADMMnet 架构和超参数 ‣ 5 结果 ‣ 深度学习在星系调查中的空间变换去卷积")
    的像素误差和图 [12](#S5.F12 "图 12 ‣ 5.2 设置 ADMMnet 架构和超参数 ‣ 5 结果 ‣ 深度学习在星系调查中的空间变换去卷积")
    的椭圆度误差。误差分布对超参数 $\rho_{0}$ 的值非常稳定，两种架构的情况相似。
- en: '![Refer to caption](img/05680c17b1f9b4944c062db037dc0c49.png)![Refer to caption](img/d7e8e6affe17ab16a6cf38cb3eefacc3.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/05680c17b1f9b4944c062db037dc0c49.png)![参考说明](img/d7e8e6affe17ab16a6cf38cb3eefacc3.png)'
- en: 'Figure 11: Impact of the hyperparameter $\rho_{0}$ value for the ADMMnet, in
    terms of pixel error, for the proposed XDense U-Net (left) and ”classical” U-Net
    (right).The box indicate quartiles, while the vertical bars encompass $90\%$ of
    the data. Outliers are displayed with circles.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：ADMMnet 超参数 $\rho_{0}$ 对像素误差的影响，针对提出的 XDense U-Net（左）和“经典”U-Net（右）。箱体表示四分位数，垂直条包含
    $90\%$ 的数据。异常值用圆圈表示。
- en: When looking at pixel error at high SNR and low SNR for both architecture, the
    lowest pixel errors in terms of median are obtained at low SNR for larger $\rho_{0}$,
    while at high SNR $\rho_{0}=1$ is the best. In terms of ellipticity errors, $\rho_{0}=1$
    allows to obtain consistently the best results at low and high SNR.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在高 SNR 和低 SNR 下观察两种架构的像素误差时，较大的 $\rho_{0}$ 在低 SNR 下获得的中位数像素误差最低，而在高 SNR 下 $\rho_{0}=1$
    是最佳的。在椭圆度误差方面，$\rho_{0}=1$ 在低 SNR 和高 SNR 下均能始终获得最佳结果。
- en: '![Refer to caption](img/a8a59b01c6a07653149ffaf843dd368c.png)![Refer to caption](img/dd72e40008ebb54fcb4025e8216a2b26.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a8a59b01c6a07653149ffaf843dd368c.png)![参考说明](img/dd72e40008ebb54fcb4025e8216a2b26.png)'
- en: 'Figure 12: Impact of the hyperparameter choice $\rho_{0}$ for the ADMMnet,
    in terms of ellipticity error, for the proposed XDense- U-Net (left) and ”classical”
    U-Net (right).The box indicate quartiles, while the vertical bars encompass $90\%$
    of the data. Outliers are displayed with circles.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：ADMMnet 超参数选择 $\rho_{0}$ 对椭圆度误差的影响，针对提出的 XDense-U-Net（左）和“经典”U-Net（右）。箱体表示四分位数，垂直条包含
    $90\%$ 的数据。异常值用圆圈表示。
- en: To better compare the differences between the two architectures, the median
    errors are reported in Table [2](#S5.T2 "Table 2 ‣ 5.2 Setting the ADMMnet architecture
    and hyperparameters ‣ 5 Results ‣ Deep Learning for space-variant deconvolution
    in galaxy surveys"). At low SNR the ”classical” U-Net performance varies more
    than that of the XDense and at $\mathrm{SNR}=20$, best results are obtained for
    the ”classical” U-Net approach ($4\%$ improvement over X-Dense). At high SNR however,
    best results are consistently obtained across $\rho_{0}$ values with the proposed
    XDense U-Net (but only $1\%$ improvement over the U-Net for the best $\rho_{0}=1$).
    Finally, concerning ellipticity median errors, best results are obtained for the
    smallest value $\rho_{0}=1$ for both architectures and the proposed XDense U-Net
    performs slightly better than the ”classical” U-Net (about $1\%$ better both at
    low and high SNR).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地比较这两种架构之间的差异，中位误差见表[2](#S5.T2 "Table 2 ‣ 5.2 Setting the ADMMnet architecture
    and hyperparameters ‣ 5 Results ‣ Deep Learning for space-variant deconvolution
    in galaxy surveys")。在低SNR下，“经典”U-Net的表现波动大于XDense，而在$\mathrm{SNR}=20$时，最佳结果由“经典”U-Net方法获得（比X-Dense提升了$4\%$）。然而，在高SNR下，提出的XDense
    U-Net在所有$\rho_{0}$值下均能 consistently 获得最佳结果（但相对于U-Net，最佳$\rho_{0}=1$仅提升了$1\%$）。最后，关于椭圆率中位误差，最佳结果出现在最小的$\rho_{0}=1$，两种架构中提出的XDense
    U-Net表现稍优于“经典”U-Net（在低SNR和高SNR下均优约$1\%$）。
- en: 'Table 2: Comparison of U-Net architectures for median errors. The first number
    is obtained with the proposed XDense U-Net architecture, the second in parentheses
    with the ”classical” U-Net architecture.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：U-Net架构在中位误差方面的比较。第一个数字是采用提出的XDense U-Net架构获得的，第二个数字在括号中是“经典”U-Net架构获得的。
- en: $\mathrm{SNR}=20$ $\rho_{0}=1$ $\rho_{0}=20$ $\rho_{0}=50$ $\rho_{0}=100$ $\rho_{0}=200$
    Median Pixel Error 0.186 (0.184) 0.185 (0.186) 0.182 (0.176) 0.183 (0.175) 0.182
    (0.175) Median Ellipticity Error 0.114 (0.116) 0.114 (0.116) 0.118 (0.115) 0.119
    (0.115) 0.119 (0.115) $\mathrm{SNR}=100$ $\rho_{0}=1$ $\rho_{0}=20$ $\rho_{0}=50$
    $\rho_{0}=100$ $\rho_{0}=200$ Median Pixel Error 0.095 (0.096) 0.096 (0.097) 0.098
    (0.099) 0.099 (0.099) 0.097 (0.098) Median Ellipticity Error 0.028 (0.028) 0.028
    (0.028) 0.029 (0.029) 0.029 (0.029) 0.029 (0.028)
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: $\mathrm{SNR}=20$ $\rho_{0}=1$ $\rho_{0}=20$ $\rho_{0}=50$ $\rho_{0}=100$ $\rho_{0}=200$
    中位像素误差 0.186 (0.184) 0.185 (0.186) 0.182 (0.176) 0.183 (0.175) 0.182 (0.175) 中位椭圆率误差
    0.114 (0.116) 0.114 (0.116) 0.118 (0.115) 0.119 (0.115) 0.119 (0.115) $\mathrm{SNR}=100$
    $\rho_{0}=1$ $\rho_{0}=20$ $\rho_{0}=50$ $\rho_{0}=100$ $\rho_{0}=200$ 中位像素误差
    0.095 (0.096) 0.096 (0.097) 0.098 (0.099) 0.099 (0.099) 0.097 (0.098) 中位椭圆率误差
    0.028 (0.028) 0.028 (0.028) 0.029 (0.029) 0.029 (0.029) 0.029 (0.028)
- en: Overall, this illustrates that the continuation scheme has a small impact in
    particular on the ellipticity errors, and that best results are obtained for different
    $\rho_{0}$ and network architectures if pixel or ellipticity errors are considered,
    depending on the SNR. The ”classical” U-Net allows smaller pixel errors than the
    proposed XDense at low SNR, but also leads to slightly higher pixel errors at
    higher SNR and ellipticity errors at both low and high SNR. In practice we keep
    in the following for the proposed XDense U-Net approach $\rho_{0}=1$ for further
    comparison with other deconvolution approaches as the pixel error is varying slowly
    with this architecture as a function of $\rho_{0}$.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来看，这表明继续方案对椭圆率误差的影响较小，并且对于不同的$\rho_{0}$和网络架构，考虑像素误差或椭圆率误差的最佳结果取决于SNR。在低SNR下，“经典”U-Net的像素误差比提出的XDense要小，但在高SNR下却会导致略高的像素误差以及在低SNR和高SNR下的椭圆率误差。在实际应用中，我们将提出的XDense
    U-Net方法中的$\rho_{0}=1$用于与其他反卷积方法的进一步比较，因为这种架构下像素误差随$\rho_{0}$的变化较慢。
- en: 5.3 DNN versus sparsity and low-rank
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 DNN与稀疏性和低秩
- en: We compare our two deep learning schemes with the XDense U-Net architecture
    and the hyperparameters set as described in the previous sections with the sparse
    and the low rank approaches of Farrens et al. ([2017](#bib.bib26)), implemented
    in sf_deconvolve ⁵⁵5https://github.com/sfarrens/sf_deconvolve. For the two methods,
    we used all parameters selected by default, reconvolved the recovered galaxy images
    with the target PSF and selected the central $41\times 41$ pixels of the observed
    galaxies to be processed in particular to speed up the computation of the singular
    value decomposition used in the low rank constraint (and therefore of the whole
    algorithm) as in Farrens et al. ([2017](#bib.bib26)). All comparisons are made
    in this central region of the galaxy images.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将两种深度学习方案与 XDense U-Net 架构进行比较，并使用了前述部分描述的超参数设置，与 Farrens 等人（[2017](#bib.bib26)）的稀疏和低秩方法进行比较，后者实现于
    sf_deconvolve ⁵⁵5https://github.com/sfarrens/sf_deconvolve。对于这两种方法，我们使用了默认选择的所有参数，重新卷积了恢复的星系图像与目标
    PSF，并选择了观察星系的中央 $41\times 41$ 像素进行处理，特别是为了加速低秩约束中使用的奇异值分解（以及整个算法）的计算，方法如 Farrens
    等人（[2017](#bib.bib26)）所述。所有比较都在星系图像的中央区域进行。
- en: We now illustrate the results for a variety of galaxies recovered at different
    SNR for the sparse, low-rank deconvolution approaches and the Tikhonet and ADMMnet.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在展示了在不同信噪比（SNR）下，通过稀疏、低秩去卷积方法以及 Tikhonet 和 ADMMnet 恢复的各种星系的结果。
- en: 'We first display several results at low SNR ($\mathrm{SNR}=20$) in Fig. [13](#S5.F13
    "Figure 13 ‣ 5.3 DNN versus sparsity and low-rank ‣ 5 Results ‣ Deep Learning
    for space-variant deconvolution in galaxy surveys") to illustrate the robustness
    of the various deconvolution approaches. Important artefacts appear in the sparse
    approach, illustrating the difficulty of recovering the galaxy images in this
    high noise scenario: retained noise in the deconvolved images lead to these point-like
    artefacts.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先在图 [13](#S5.F13 "图 13 ‣ 5.3 DNN 与稀疏和低秩 ‣ 5 结果 ‣ 深度学习在星系调查中的空间变化去卷积")中展示了在低信噪比（$\mathrm{SNR}=20$）下的几个结果，以说明各种去卷积方法的鲁棒性。在稀疏方法中出现了重要的伪影，突显了在高噪声场景下恢复星系图像的难度：去卷积图像中的噪声残留导致了这些点状伪影。
- en: For the low rank approach, low frequencies seems to be partially well recovered,
    but artefacts appears for elongated galaxies in the direction of the minor axis.
    Finally, both Tikhonet and ADMMnet seem to recover better the low frequency information,
    but the galaxy substructures are essentially lost. The ADMMnet seems to recover
    in this situation sharper images but with more propagated noise/artefacts than
    the Tikhonet, with similar features as for the sparse approach but with less point-like
    artefacts.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 对于低秩方法，低频信息似乎部分恢复良好，但在次轴方向上，延伸的星系出现了伪影。最后，Tikhonet 和 ADMMnet 似乎能更好地恢复低频信息，但星系的子结构基本丢失。在这种情况下，ADMMnet
    似乎能恢复出更清晰的图像，但噪声/伪影传播较多，与稀疏方法类似，但点状伪影较少。
- en: '![Refer to caption](img/ab031a864d4bcb6e882ff216f2c18641.png)![Refer to caption](img/583c84b11783173746187f21980e5cf2.png)![Refer
    to caption](img/742ef684e21dac83cb14107b72bdce61.png)![Refer to caption](img/2f507796aeea8c0e4fdb55f5b5b2f10f.png)![Refer
    to caption](img/76f5b977d95d04a818980e2d5794fd7f.png)![Refer to caption](img/09430644f2507f391492f5a8ecef4153.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/ab031a864d4bcb6e882ff216f2c18641.png)![参见标题](img/583c84b11783173746187f21980e5cf2.png)![参见标题](img/742ef684e21dac83cb14107b72bdce61.png)![参见标题](img/2f507796aeea8c0e4fdb55f5b5b2f10f.png)![参见标题](img/76f5b977d95d04a818980e2d5794fd7f.png)![参见标题](img/09430644f2507f391492f5a8ecef4153.png)'
- en: 'Figure 13: Deconvolved images with the various approaches for $\mathrm{SNR}=20$.
    Each row corresponds to a different processed galaxy. From left to right: image
    to recover, observation with a noise realization, sparse and low rank approaches,
    and finally Tikhonet and ADMMnet results.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13：不同方法去卷积的图像，$\mathrm{SNR}=20$。每行对应不同处理的星系。从左到右：恢复图像、噪声实现的观测图像、稀疏和低秩方法的结果，最后是
    Tikhonet 和 ADMMnet 的结果。
- en: We also display these galaxies at a much higher SNR ($\mathrm{SNR}=100$) in
    Fig. [14](#S5.F14 "Figure 14 ‣ 5.3 DNN versus sparsity and low-rank ‣ 5 Results
    ‣ Deep Learning for space-variant deconvolution in galaxy surveys") to assess
    the ability of the various deconvolution schemes to recover galaxy substructures
    in a low noise scenario.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在图 [14](#S5.F14 "图 14 ‣ 5.3 DNN 与稀疏和低秩 ‣ 5 结果 ‣ 深度学习在星系调查中的空间变化去卷积")中以更高的信噪比（$\mathrm{SNR}=100$）展示了这些星系，以评估各种去卷积方案在低噪声场景下恢复星系子结构的能力。
- en: '![Refer to caption](img/8c712210cda972bbba07af02c47371a9.png)![Refer to caption](img/e6d91188c60ef04c9c1e7fde07434f18.png)![Refer
    to caption](img/ca469e3e60c27dc96ca7482eddc1dd42.png)![Refer to caption](img/fe5a13eedb8bd06e4c8425094c5bde66.png)![Refer
    to caption](img/811f5e5a02705ca2f7a2fd30b1a4cf41.png)![Refer to caption](img/19b5bc5e61f2dfb0bb2bfae8fe0dda07.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/8c712210cda972bbba07af02c47371a9.png)![参考标题](img/e6d91188c60ef04c9c1e7fde07434f18.png)![参考标题](img/ca469e3e60c27dc96ca7482eddc1dd42.png)![参考标题](img/fe5a13eedb8bd06e4c8425094c5bde66.png)![参考标题](img/811f5e5a02705ca2f7a2fd30b1a4cf41.png)![参考标题](img/19b5bc5e61f2dfb0bb2bfae8fe0dda07.png)'
- en: 'Figure 14: Deconvolved images with the various approaches for $\mathrm{SNR}=100$.
    Each row corresponds to a different processed galaxy. From left to right: image
    to recover, observation with a noise realization, sparse and low rank approaches,
    and finally Tikhonet and ADMMnet results.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：在$\mathrm{SNR}=100$下，使用各种方法去卷积的图像。每一行对应不同处理的银河系。从左到右：待恢复的图像，带噪声实现的观察图像，稀疏和低秩方法，最后是Tikhonet和ADMMnet的结果。
- en: The low-rank approach displays less artefacts than at low SNR, but still does
    not seem to be able to adequately represent elongated galaxies or directional
    substructures in the galaxy. This is probably due to the fact that the low rankness
    approach does not adequately cope with translations, leading to over-smooth solutions.
    On the contrary, Tikhonet, ADMMnet and sparse recovery lead to recover substructures
    of the galaxies.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 低秩方法显示出的伪影较低，但仍然无法充分表示拉伸的银河系或银河系中的方向性子结构。这可能是由于低秩方法未能有效处理平移，导致过度平滑的解决方案。相反，Tikhonet、ADMMnet和稀疏恢复能够恢复银河系的子结构。
- en: Overall the two proposed deconvolution approaches using DNNs lead to the best
    visual results across SNR.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，使用DNN的两种提议的去卷积方法在SNR下提供了最佳的视觉结果。
- en: The quantitative deconvolution criteria are presented in Fig. [15](#S5.F15 "Figure
    15 ‣ 5.3 DNN versus sparsity and low-rank ‣ 5 Results ‣ Deep Learning for space-variant
    deconvolution in galaxy surveys"). Concerning median pixel error, this figure
    illustrates that both Tikhonet and ADMMnet perform better than the sparse and
    low-rank approach to recover the galaxy intensity values, whatever the SNR. In
    these noise settings the low-rank approach performed consistently worst than using
    sparsity. In terms of pixel errors, the sparse approach median errors are $27\%$
    (resp. $15\%$) larger at $\mathrm{SNR}=20$ (resp. $\mathrm{SNR}=100$) compared
    to the Tikhonet results. The Tikhonet seems to perform slightly better than the
    ADMMnet with this criterion as well.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 量化去卷积标准见图[15](#S5.F15 "Figure 15 ‣ 5.3 DNN versus sparsity and low-rank ‣ 5
    Results ‣ Deep Learning for space-variant deconvolution in galaxy surveys")。关于中位像素误差，这张图说明无论SNR如何，Tikhonet和ADMMnet的表现均优于稀疏和低秩方法以恢复银河系强度值。在这些噪声设置下，低秩方法的表现一贯不如稀疏方法。在像素误差方面，稀疏方法的中位误差在$\mathrm{SNR}=20$（相应$\mathrm{SNR}=100$）下比Tikhonet结果大$27\%$（$15\%$）。Tikhonet在这一标准下似乎也比ADMMnet表现稍好。
- en: '![Refer to caption](img/e9cca004ae47f0ae5de7182bf4e35ca5.png)![Refer to caption](img/6aee5a644eb78c9712d53747a895c2c1.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/e9cca004ae47f0ae5de7182bf4e35ca5.png)![参考标题](img/6aee5a644eb78c9712d53747a895c2c1.png)'
- en: 'Figure 15: Deconvolution quality criteria for the different deconvolution schemes.
    Left: median pixel error, Right: median ellipticity error.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图15：不同去卷积方案的去卷积质量标准。左侧：中位像素误差，右侧：中位椭圆度误差。
- en: For shape measurement errors, the best results are obtained with the Tikhonet
    approach at low SNR (up to $\mathrm{SNR}=40$), and then the ADMMnet outperforms
    the others at higher SNR. In terms of ellipticity errors, the sparse approach
    median errors are $14\%$ (resp. $5\%$) larger at $\mathrm{SNR}=20$ (resp. $\mathrm{SNR}=100$)
    compared to the Tikhonet results. Finally the low-rank performs the worst whatever
    the SNR. To summarize, these results clearly favour the choice of the DNN approaches
    resulting in lower errors consistently across SNR.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 对于形状测量误差，低SNR下（高达$\mathrm{SNR}=40$）的最佳结果由Tikhonet方法获得，而在更高SNR下，ADMMnet表现优于其他方法。在椭圆度误差方面，稀疏方法的中位误差在$\mathrm{SNR}=20$（相应$\mathrm{SNR}=100$）下比Tikhonet结果大$14\%$（$5\%$）。最后，无论SNR如何，低秩方法的表现最差。总的来说，这些结果显然偏向于选择DNN方法，这些方法在SNR范围内始终能提供较低的误差。
- en: 'This is confirmed when looking at a realistic distribution of galaxy SNR, as
    shown in Table [3](#S5.T3 "Table 3 ‣ 5.3 DNN versus sparsity and low-rank ‣ 5
    Results ‣ Deep Learning for space-variant deconvolution in galaxy surveys"). In
    terms of both median pixel and ellipticity errors, the proposed deep learning
    approaches perform similarly, and outperforms both sparse and low-rank approaches:
    median pixel error is reduced by almost $14\%$ (resp. $9\%$) for the Tikhonet
    (resp. ADMMnet) approach compared to sparse recovery, and ellipticity errors by
    about $13\%$ for both approaches. Higher differences are observed for the low-rank
    approach.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 当查看星系SNR的实际分布时，这一点得到了确认，如表 [3](#S5.T3 "表 3 ‣ 5.3 DNN与稀疏和低秩 ‣ 5 结果 ‣ 用于星系调查的空间变换反卷积的深度学习")所示。在中位像素和椭圆度误差方面，所提出的深度学习方法表现相似，并且优于稀疏和低秩方法：与稀疏恢复相比，Tikhonet（分别是ADMMnet）方法的中位像素误差降低了近$14\%$（$9\%$），两种方法的椭圆度误差降低了约$13\%$。低秩方法观察到的差异更大。
- en: 'Table 3: Criteria for constant noise simulations ($\sigma=0.04$). Best results
    are indicated in bold.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：恒定噪声模拟的标准（$\sigma=0.04$）。最佳结果以**粗体**标出。
- en: Sparse Low-Rank Tikhonet ADMMnet Median Pixel Error 0.130 0.169 0.112 0.119
    Median Ellipticity Error 0.061 0.072 0.053 0.054
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏低秩Tikhonet ADMMnet中位像素误差 0.130 0.169 0.112 0.119 中位椭圆度误差 0.061 0.072 0.053
    0.054
- en: 5.4 Computing Time
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 计算时间
- en: Finally, we also report in Table [4](#S5.T4 "Table 4 ‣ 5.4 Computing Time ‣
    5 Results ‣ Deep Learning for space-variant deconvolution in galaxy surveys")
    the time necessary to learn the networks and process the set of $10000$ galaxies
    on the same GPU/CPUs, as this is a crucial aspect when potentially processing
    a large number of galaxies such as in modern surveys. Among DNNs, learning the
    parameters of the denoising network for the ADMMnet is faster than those of the
    post-processing network in the Tikhonet since the latter requires each batch to
    be deconvolved. However once the network parameters have been learnt, the Tikhonet
    based on a closed-form deconvolution is the fastest to process a large number
    of galaxies (about 0.05s per galaxy). On the other hand, learning and restoring
    10000 galaxies is quite fast for the low-rank approach, while iterative algorithms
    such as ADMMnet or the primal-dual algorithm for sparse recovery are similar in
    terms of computing time (about 7 to 10s per galaxy). All these computing times
    could however be reduced if the restoration of different galaxy images is performed
    in parallel, which has not been implemented.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还在表 [4](#S5.T4 "表 4 ‣ 5.4 计算时间 ‣ 5 结果 ‣ 用于星系调查的空间变换反卷积的深度学习")中报告了在同一GPU/CPU上学习网络并处理$10000$个星系所需的时间，因为这是处理现代调查中大量星系时的一个关键方面。在DNN中，ADMMnet的去噪网络参数学习速度比Tikhonet的后处理网络快，因为后者需要对每个批次进行反卷积。然而，一旦网络参数学习完毕，基于闭式反卷积的Tikhonet处理大量星系的速度最快（每个星系约0.05秒）。另一方面，对于低秩方法，学习和恢复10000个星系的速度相当快，而ADMMnet或稀疏恢复的原始对偶算法等迭代算法在计算时间上相似（每个星系约7到10秒）。然而，如果不同星系图像的恢复可以并行进行，那么所有这些计算时间都可以减少，但目前尚未实现这一点。
- en: 'Table 4: Computing time for the various approaches (in hours).'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：各种方法的计算时间（单位：小时）。
- en: '| Method | Learning | Processing 10000 galaxies |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 学习 | 处理10000个星系 |'
- en: '| Sparse | / | 24.7 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 稀疏 | / | 24.7 |'
- en: '| Low-rank | 5.2 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 低秩 | 5.2 |'
- en: '| Tikhonet | 21.5 | 0.1 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| Tikhonet | 21.5 | 0.1 |'
- en: '| ADMMnet | 16.2 | 20.3 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| ADMMnet | 16.2 | 20.3 |'
- en: 6 Conclusions
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: 'We have proposed two new space-variant deconvolution strategies for galaxy
    images based on deep neural networks, while keeping all knowledge of the PSF in
    the forward model: the Tikhonet, a post-processing approach of a simple Tikhonov
    deconvolution with a DNN, and the ADMMnet based on regularization by a DNN denoiser
    inside an iterative ADMM PnP algorithm for deconvolution. We proposed to use for
    galaxy processing a DNN architecture based on the U-Net particularly adapted to
    deconvolution problems, with small modifications implemented (dense Blocks of
    separable convolutions, and no skip connection) to lower the number of parameters
    to learn compared to a ”classical” U-Net implementation. We finally evaluated
    these approaches compared to the deconvolution techniques in Farrens et al. ([2017](#bib.bib26))
    in simulations of realistic galaxy images derived from HST observations, with
    realistic sampled sparse-variant PSFs and noise, processed with the GalSim simulation
    code. We investigated in particular how to set the hyperparameters in both approach:
    the Tikhonov hyperparameter for the Tikhonet and the continuation parameters for
    the ADMMnet and compared our proposed XDense U-Net architecture with a ”classical”
    U-Net implementation. Our main findings are as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了两种基于深度神经网络的空间变异去卷积策略，同时保留了前向模型中的PSF所有知识：Tikhonet，这是一种简单的Tikhonov去卷积后处理方法，与DNN结合使用，以及基于DNN去噪器的ADMMnet，结合了迭代ADMM
    PnP算法的正则化方法。我们建议使用特别适合去卷积问题的U-Net DNN架构，进行了小幅修改（可分离卷积的密集块，无跳跃连接），以减少相比于“经典”U-Net实现的学习参数数量。我们最终在与Farrens等人（[2017](#bib.bib26)）的去卷积技术对比中，评估了这些方法，模拟了来自HST观测的真实星系图像，使用真实采样的稀疏变异PSF和噪声，通过GalSim模拟代码处理。我们特别研究了如何设置这两种方法的超参数：Tikhonet的Tikhonov超参数和ADMMnet的延续参数，并比较了我们提出的XDense
    U-Net架构与“经典”U-Net实现。我们的主要发现如下：
- en: •
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'for both Tikhonet and ADMMnet, the hyperparameters impact the performance of
    the approaches, but the results are quite stable in a range of values for these
    hyperparameters. In particular for the Tikhonet, the SURE minimizer is within
    this range. For the ADMMnet, more hyperparameters needs to be set, and the initialization
    of the augmented lagrangian parameter impacts the performance: small parameters
    lead to higher frequencies in the images, while larger parameters lead to over-smooth
    galaxies recovered.'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于Tikhonet和ADMMnet，超参数会影响方法的性能，但这些超参数在一定范围内结果较为稳定。特别是对于Tikhonet，SURE最小化器在这个范围内。对于ADMMnet，需要设置更多超参数，增广拉格朗日参数的初始化会影响性能：较小的参数导致图像中出现较高频率，而较大的参数则导致恢复的星系过于平滑。
- en: •
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: compared to the ”classical” implementation, the XDense U-Net leads to consistently
    improved criteria for the Tikhonet approach; the situation is more balanced for
    the ADMMnet, where lower pixel errors can be achieved at low SNR with the ”classical”
    architecture (with high hyperparamer value), but the XDense U-Net provides the
    best results for pixel errors at high SNR and ellipticity errors both at high
    and low SNR (with low hyperparameter value); however selecting one or the other
    architecture with their best hyperparameter value would not change the ranking
    among methods
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与“经典”实现相比，XDense U-Net在Tikhonet方法上始终带来改进的标准；对于ADMMnet，情况则更为平衡，在低SNR条件下使用“经典”架构（具有高超参数值）可以实现较低的像素误差，但XDense
    U-Net在高SNR和低SNR条件下的像素误差及椭圆率误差方面都提供了最佳结果（具有低超参数值）；然而，选择任一架构及其最佳超参数值并不会改变方法之间的排名。
- en: •
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: visually both methods outperform the sparse recovery and low-rank techniques,
    which displays artefacts at the low SNR probed (and for high SNR as well in the
    low-rank approach)
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在视觉上，这两种方法都优于稀疏恢复和低秩技术，这些技术在低SNR探测下显示了伪影（在高SNR下低秩方法也如此）。
- en: •
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: this is also confirmed in all SNR ranges and for a realistic distribution of
    SNR; in the latter about $14\%$ improvement is achieved in terms of median pixel
    error and about $13\%$ improvement for median shape measurement errors for the
    Tikhonet compared to sparse recovery.
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这一点在所有SNR范围内以及真实SNR分布下均得到了确认；在后者中，Tikhonet在中位像素误差方面提高了约$14\%$，在中位形状测量误差方面提高了约$13\%$，相比于稀疏恢复。
- en: •
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: among DNN approaches, Tikhonet outperforms ADMMnet in terms of median pixel
    errors whatever the SNR, and median ellipticity errors for low SNR ($\mathrm{SNR}<40$).
    At higher SNR, the ADMMnet leads to slightly lower ellipticity errors.
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在DNN方法中，Tikhonet在中位数像素误差方面优于ADMMnet，无论SNR如何，以及在低SNR（$\mathrm{SNR}<40$）下的中位数椭圆度误差。在较高SNR下，ADMMnet的椭圆度误差略低。
- en: •
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: the Tikhonet is the fastest approach once the network parameters have been learnt,
    with about 0.05s needed to process a galaxy, to be compared with sparse and ADMMnet
    iterative deconvolution approaches which takes about 7 to 10s per galaxy.
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦网络参数已被学习，Tikhonet是最快的方法，处理一个星系大约需要0.05秒，而与稀疏和ADMMnet迭代去卷积方法相比，每个星系需要大约7到10秒。
- en: If the ADMMnet approach is still promising, as extra constraints could be added
    easily to the framework (while the success of the Tikhonet approach also lies
    on the ability to compute a closed-form solution for the deconvolution step),
    these results illustrate that the Tikhonet is overall the best approach in this
    scenario to process both with high accuracy and fastly a large number of galaxies.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 如果ADMMnet方法仍然有前景，因为可以很容易地在框架中添加额外的约束（而Tikhonet方法的成功也在于其计算去卷积步骤的闭式解的能力），这些结果表明，Tikhonet在此场景中总体上是最佳方法，能够以高精度和快速处理大量星系。
- en: Reproducible Research
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可重复研究
- en: In the spirit of reproducible research, the codes will be made freely available
    on the CosmoStat website. The testing datasets will also be provided to repeat
    the experiments performed in this paper.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 本着可重复研究的精神，这些代码将在CosmoStat网站上免费提供。测试数据集也将提供以重复本文中的实验。
- en: Acknowledgements.
  id: totrans-214
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 致谢。
- en: The authors thank the Galsim developers/GREAT3 collaboration for publicly providing
    simulation codes and galaxy databases, and the developers of sf_deconvolve and
    shapelens as well for their code publicly available.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 作者感谢Galsim开发者/GREAT3合作伙伴公开提供的模拟代码和星系数据库，以及sf_deconvolve和shapelens的开发者公开的代码。
- en: References
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Adler & Öktem (2017) Adler, J. & Öktem, O. 2017, Inverse Problems, 33, 124007
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adler & Öktem (2017) Adler, J. & Öktem, O. 2017，《逆问题》，33，124007
- en: Adler & Öktem (2018) Adler, J. & Öktem, O. 2018, IEEE Transactions on Medical
    Imaging, 37, 1322
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adler & Öktem (2018) Adler, J. & Öktem, O. 2018，《IEEE医学成像汇刊》，37，1322
- en: Afonso et al. (2011) Afonso, M., Bioucas-Dias, J., & Figueiredo, M. 2011, IEEE
    transactions on image processing, 20, 681
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Afonso et al. (2011) Afonso, M., Bioucas-Dias, J., & Figueiredo, M. 2011，《IEEE图像处理汇刊》，20，681
- en: 'Andrews & Hunt (1977) Andrews, H. C. & Hunt, B. R. 1977, Digital Image Restoration
    (Englewood Cliffs, NJ: Prentice-Hall)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Andrews & Hunt (1977) Andrews, H. C. & Hunt, B. R. 1977，《数字图像恢复》（Englewood
    Cliffs, NJ: Prentice-Hall）'
- en: Beck & Teboulle (2009) Beck, A. & Teboulle, M. 2009, SIAM Journal on Imaging
    Sciences, 2, 183
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beck & Teboulle (2009) Beck, A. & Teboulle, M. 2009，《SIAM成像科学杂志》，2，183
- en: Bertero & Boccacci (1998) Bertero, M. & Boccacci, P. 1998, Introduction to Inverse
    Problems in Imaging (Institute of Physics)
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bertero & Boccacci (1998) Bertero, M. & Boccacci, P. 1998，《成像中的逆问题简介》（物理学研究所）
- en: Bertin (2011) Bertin, E. 2011, in Astronomical Society of the Pacific Conference
    Series, Vol. 442, Astronomical Data Analysis Software and Systems XX, ed. I. N.
    Evans, A. Accomazzi, D. J. Mink, & A. H. Rots, 435
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bertin (2011) Bertin, E. 2011，《太平洋天文学会会议系列》，第442卷，《天文数据分析软件和系统 XX》，编者 I. N.
    Evans, A. Accomazzi, D. J. Mink, & A. H. Rots，435
- en: Bertocchi et al. (2018) Bertocchi, C., Chouzenoux, E., Corbineau, M.-C., Pesquet,
    J.-C., & Prato, M. 2018, arXiv e-prints, arXiv:1812.04276
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bertocchi et al. (2018) Bertocchi, C., Chouzenoux, E., Corbineau, M.-C., Pesquet,
    J.-C., & Prato, M. 2018，《arXiv 电子预印本》，arXiv:1812.04276
- en: 'Bigdeli et al. (2017) Bigdeli, S. A., Jin, M., Favaro, P., & Zwicker, M. 2017,
    in Proceedings of the 31st International Conference on Neural Information Processing
    Systems, NIPS’17 (USA: Curran Associates Inc.), 763–772'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bigdeli et al. (2017) Bigdeli, S. A., Jin, M., Favaro, P., & Zwicker, M. 2017，《第31届国际神经信息处理系统会议论文集》，NIPS’17（美国：Curran
    Associates Inc.），763–772
- en: Bioucas-Dias (2006) Bioucas-Dias, J. 2006, Image Processing, IEEE Transactions
    on, 15, 937
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bioucas-Dias (2006) Bioucas-Dias, J. 2006，《图像处理》，IEEE汇刊，15，937
- en: Bobin et al. (2014) Bobin, J., Sureau, F., Starck, J.-L., Rassat, A., & Paykari,
    P. 2014, A&A, 563, A105
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bobin et al. (2014) Bobin, J., Sureau, F., Starck, J.-L., Rassat, A., & Paykari,
    P. 2014，《A&A》，563，A105
- en: Boyd et al. (2010) Boyd, S., Parikh, N., Chu, E., Peleato, B., & Eckstein, J.
    2010, Machine Learning, 3, 1
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boyd et al. (2010) Boyd, S., Parikh, N., Chu, E., Peleato, B., & Eckstein, J.
    2010，《机器学习》，3，1
- en: C. Eldar (2009) C. Eldar, Y. 2009, Signal Processing, IEEE Transactions on,
    57, 471
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C. Eldar (2009) C. Eldar, Y. 2009，《信号处理》，IEEE汇刊，57，471
- en: Cai et al. (2010) Cai, J., Osher, S., & Shen, Z. 2010, Multiscale Modeling &
    Simulation, 8, 337
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cai et al. (2010) Cai, J., Osher, S., & Shen, Z. 2010, Multiscale Modeling &
    Simulation, 8, 337
- en: Chambolle & Pock (2011) Chambolle, A. & Pock, T. 2011, Journal of Mathematical
    Imaging and Vision, 40, 120
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chambolle & Pock (2011) Chambolle, A. & Pock, T. 2011, Journal of Mathematical
    Imaging and Vision, 40, 120
- en: Chollet (2016) Chollet, F. 2016, 2017 IEEE Conference on Computer Vision and
    Pattern Recognition (CVPR), 1800
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chollet (2016) Chollet, F. 2016, 2017 IEEE Conference on Computer Vision and
    Pattern Recognition (CVPR), 1800
- en: Christian Hansen & O’leary (1993) Christian Hansen, P. & O’leary, D. 1993, SIAM
    J. Sci. Comput., 14, 1487
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Christian Hansen & O’leary (1993) Christian Hansen, P. & O’leary, D. 1993, SIAM
    J. Sci. Comput., 14, 1487
- en: Combettes & Pesquet (2011) Combettes, P. L. & Pesquet, J.-C. 2011, in Fixed-Point
    Algorithms for Inverse Problems in Science and Engineering, ed. Bauschke, H. Burachik,
    R. Combettes, P. Elser, V. Luke, D. Wolkowicz, & H. (Eds.) (Springer), 185–212
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Combettes & Pesquet (2011) Combettes, P. L. & Pesquet, J.-C. 2011, in Fixed-Point
    Algorithms for Inverse Problems in Science and Engineering, ed. Bauschke, H. Burachik,
    R. Combettes, P. Elser, V. Luke, D. Wolkowicz, & H. (Eds.) (Springer), 185–212
- en: Combettes & Vu (2014) Combettes, P. L. & Vu, B. C. 2014, Optimization, 63, 1289
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Combettes & Vu (2014) Combettes, P. L. & Vu, B. C. 2014, Optimization, 63, 1289
- en: Condat (2013) Condat, L. 2013, Journal of Optimization Theory and Applications,
    158, 460
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Condat (2013) Condat, L. 2013, Journal of Optimization Theory and Applications,
    158, 460
- en: Deledalle et al. (2014) Deledalle, C., Vaiter, S., Fadili, J., & Peyré, G. 2014,
    SIAM Journal on Imaging Sciences, 7, 2448
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deledalle et al. (2014) Deledalle, C., Vaiter, S., Fadili, J., & Peyré, G. 2014,
    SIAM Journal on Imaging Sciences, 7, 2448
- en: Donoho (1995) Donoho, D. L. 1995, Applied and Computational Harmonic Analysis,
    2, 101
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Donoho (1995) Donoho, D. L. 1995, Applied and Computational Harmonic Analysis,
    2, 101
- en: Eldan & Shamir (2015) Eldan, R. & Shamir, O. 2015, Conference on Learning Theory
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eldan & Shamir (2015) Eldan, R. & Shamir, O. 2015, Conference on Learning Theory
- en: Elfwing et al. (2018) Elfwing, S., Uchibe, E., & Doya, K. 2018, Neural Networks,
    107, 3 , special issue on deep reinforcement learning
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elfwing et al. (2018) Elfwing, S., Uchibe, E., & Doya, K. 2018, Neural Networks,
    107, 3 , special issue on deep reinforcement learning
- en: Fan et al. (2018) Fan, F., Li, M., Teng, Y., & Wang, G. 2018, arXiv preprint
    arXiv:1812.11675
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan et al. (2018) Fan, F., Li, M., Teng, Y., & Wang, G. 2018, arXiv preprint
    arXiv:1812.11675
- en: Farrens et al. (2017) Farrens, S., Starck, J.-L., & Mboula, F. 2017, Astronomy
    & Astrophysics, 601
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Farrens et al. (2017) Farrens, S., Starck, J.-L., & Mboula, F. 2017, Astronomy
    & Astrophysics, 601
- en: Flamary (2017) Flamary, R. 2017, 2017 25th European Signal Processing Conference
    (EUSIPCO), 2468
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flamary (2017) Flamary, R. 2017, 2017 25th European Signal Processing Conference
    (EUSIPCO), 2468
- en: Garsden et al. (2015) Garsden, H., Girard, J. N., & Starck, J.-L., e. a. 2015,
    å, 575, A90
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Garsden et al. (2015) Garsden, H., Girard, J. N., & Starck, J.-L., e. a. 2015,
    å, 575, A90
- en: Golub et al. (1979) Golub, G. H., Heath, M., & Wahba, G. 1979, Technometrics,
    21, 215
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Golub et al. (1979) Golub, G. H., Heath, M., & Wahba, G. 1979, Technometrics,
    21, 215
- en: 'Gregor & LeCun (2010) Gregor, K. & LeCun, Y. 2010, in Proceedings of the 27th
    International Conference on International Conference on Machine Learning, ICML’10
    (USA: Omnipress), 399–406'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gregor & LeCun (2010) Gregor, K. & LeCun, Y. 2010, in Proceedings of the 27th
    International Conference on International Conference on Machine Learning, ICML’10
    (USA: Omnipress), 399–406'
- en: Guerrero-colon & Portilla (2006) Guerrero-colon, J. A. & Portilla, J. 2006,
    in 2006 International Conference on Image Processing, 625–628
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guerrero-colon & Portilla (2006) Guerrero-colon, J. A. & Portilla, J. 2006,
    in 2006 International Conference on Image Processing, 625–628
- en: Gupta et al. (2018) Gupta, H., Jin, K. H., Nguyen, H. Q., McCann, M. T., & Unser,
    M. 2018, IEEE Transactions on Medical Imaging, 37, 1440
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gupta et al. (2018) Gupta, H., Jin, K. H., Nguyen, H. Q., McCann, M. T., & Unser,
    M. 2018, IEEE Transactions on Medical Imaging, 37, 1440
- en: H. Chan et al. (2016) H. Chan, S., Wang, X., & A. Elgendy, O. 2016, IEEE Transactions
    on Computational Imaging, PP
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H. Chan et al. (2016) H. Chan, S., Wang, X., & A. Elgendy, O. 2016, IEEE Transactions
    on Computational Imaging, PP
- en: Han & Ye (2018) Han, Y. & Ye, J. C. 2018, IEEE transactions on medical imaging,
    37, 1418
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han & Ye (2018) Han, Y. & Ye, J. C. 2018, IEEE Transactions on Medical Imaging,
    37, 1418
- en: He et al. (2016) He, K., Zhang, X., Ren, S., & Sun, J. 2016, in 2016 IEEE Conference
    on Computer Vision and Pattern Recognition (CVPR), 770–778
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. (2016) He, K., Zhang, X., Ren, S., & Sun, J. 2016, in 2016 IEEE Conference
    on Computer Vision and Pattern Recognition (CVPR), 770–778
- en: Huang et al. (2017) Huang, G., Liu, Z., v. d. Maaten, L., & Weinberger, K. Q.
    2017, in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
    2261–2269
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. (2017) Huang, G., Liu, Z., v. d. Maaten, L., & Weinberger, K. Q.
    2017, in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
    2261–2269
- en: Hunt (1972) Hunt, B. R. 1972, IEEE Transactions on Automatic and Control, AC-17,
    703
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hunt (1972) Hunt, B. R. 1972, IEEE Transactions on Automatic and Control, AC-17,
    703
- en: Ioffe & Szegedy (2015) Ioffe, S. & Szegedy, C. 2015, in Proceedings of the 32Nd
    International Conference on International Conference on Machine Learning - Volume
    37, ICML’15 (JMLR.org), 448–456
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ioffe & Szegedy (2015) Ioffe, S. & Szegedy, C. 2015, in Proceedings of the 32Nd
    International Conference on International Conference on Machine Learning - Volume
    37, ICML’15 (JMLR.org), 448–456
- en: Jia & Evans (2011) Jia, C. & Evans, B. L. 2011, in 2011 18th IEEE International
    Conference on Image Processing, 681–684
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jia & Evans（2011）Jia, C. & Evans, B. L. 2011, 发表在 2011年第18届IEEE图像处理国际会议上, 681–684
- en: Jin et al. (2017) Jin, K. H., McCann, M. T., Froustey, E., & Unser, M. 2017,
    IEEE Transactions on Image Processing, 26, 4509
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin 等人（2017）Jin, K. H., McCann, M. T., Froustey, E., & Unser, M. 2017, 发表在《IEEE
    图像处理汇刊》, 26, 4509
- en: Kaiser et al. (1995) Kaiser, N., Squires, G., & Broadhurst, T. 1995, ApJ, 449,
    460
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaiser 等人（1995）Kaiser, N., Squires, G., & Broadhurst, T. 1995, 发表在《天体物理学杂志》,
    449, 460
- en: Kalifa et al. (2003) Kalifa, J., Mallat, S., & Rouge, B. 2003, IEEE Transactions
    on Image Processing, 12, 446
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kalifa 等人（2003）Kalifa, J., Mallat, S., & Rouge, B. 2003, 发表在《IEEE 图像处理汇刊》, 12,
    446
- en: Kingma & Ba (2014) Kingma, D. & Ba, J. 2014, International Conference on Learning
    Representations
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma & Ba（2014）Kingma, D. & Ba, J. 2014, 国际学习表征会议
- en: Krishnan & Fergus (2009) Krishnan, D. & Fergus, R. 2009, in Advances in Neural
    Information Processing Systems 22, ed. Y. Bengio, D. Schuurmans, J. D. Lafferty,
    C. K. I. Williams, & A. Culotta (Curran Associates, Inc.), 1033–1041
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krishnan & Fergus（2009）Krishnan, D. & Fergus, R. 2009, 发表在《神经信息处理系统进展第22卷》，编辑
    Y. Bengio, D. Schuurmans, J. D. Lafferty, C. K. I. Williams, & A. Culotta（Curran
    Associates, Inc.），1033–1041
- en: Krist et al. (2011) Krist, J. E., Hook, R. N., & Stoehr, F. 2011, in Proc. SPIE,
    Vol. 8127, Optical Modeling and Performance Predictions V, 81270J
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krist 等人（2011）Krist, J. E., Hook, R. N., & Stoehr, F. 2011, 发表在 Proc. SPIE,
    第8127卷, 光学建模与性能预测 V, 81270J
- en: Kuijken et al. (2015) Kuijken, K., Heymans, C., Hildebrandt, H., et al. 2015,
    MNRAS, 454, 3500
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuijken 等人（2015）Kuijken, K., Heymans, C., Hildebrandt, H., 等. 2015, 发表在《皇家天文学会月刊》,
    454, 3500
- en: Lanusse, F. et al. (2016) Lanusse, F., Starck, J.-L., Leonard, A., & Pires,
    S. 2016, A&A, 591, A2
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lanusse 等人（2016）Lanusse, F., Starck, J.-L., Leonard, A., & Pires, S. 2016, 发表在《天文学与天体物理学》,
    591, A2
- en: LeCun et al. (2015) LeCun, Y., Bengio, Y., & Hinton, G. 2015, Nature, 521, 436
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun 等人（2015）LeCun, Y., Bengio, Y., & Hinton, G. 2015, 发表在《自然》, 521, 436
- en: Li et al. (2019) Li, Y., Tofighi, M., Monga, V., & Eldar, Y. C. 2019, in ICASSP
    2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing
    (ICASSP), 7675–7679
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人（2019）Li, Y., Tofighi, M., Monga, V., & Eldar, Y. C. 2019, 发表在 ICASSP 2019
    - 2019 IEEE 国际声学、语音与信号处理会议（ICASSP）上, 7675–7679
- en: Lou et al. (2011) Lou, Y., Bertozzi, A. L., & Soatto, S. 2011, Journal of Mathematical
    Imaging and Vision, 39, 1
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lou 等人（2011）Lou, Y., Bertozzi, A. L., & Soatto, S. 2011, 发表在《数学成像与视觉期刊》, 39,
    1
- en: Mairal et al. (2008) Mairal, J., Sapiro, G., & Elad, M. 2008, Multiscale Modeling
    & Simulation, 7, 214
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mairal 等人（2008）Mairal, J., Sapiro, G., & Elad, M. 2008, 发表在《多尺度建模与仿真》, 7, 214
- en: 'Mallat (2016) Mallat, S. 2016, Philosophical Transactions of the Royal Society
    A: Mathematical, Physical and Engineering Sciences, 374, 20150203'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mallat（2016）Mallat, S. 2016, 发表在《皇家学会哲学汇刊 A: 数学、物理与工程科学》, 374, 20150203'
- en: Mandelbaum et al. (2015) Mandelbaum, R., Rowe, B., Armstrong, R., et al. 2015,
    MNRAS, 450, 2963
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mandelbaum 等人（2015）Mandelbaum, R., Rowe, B., Armstrong, R., 等. 2015, 发表在《皇家天文学会月刊》,
    450, 2963
- en: Mandelbaum et al. (2014) Mandelbaum, R., Rowe, B., Bosch, J., et al. 2014, The
    Astrophysical Journal Supplement Series, 212, 5
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mandelbaum 等人（2014）Mandelbaum, R., Rowe, B., Bosch, J., 等. 2014, 发表在《天体物理学杂志补充系列》,
    212, 5
- en: Mardani et al. (2017) Mardani, M., Gong, E., Cheng, J. Y., Pauly, J. M., & Xing,
    L. 2017, in 2017 IEEE 7th International Workshop on Computational Advances in
    Multi-Sensor Adaptive Processing, CAMSAP 2017, Curaçao, The Netherlands, December
    10-13, 2017, 1–5
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mardani 等人（2017）Mardani, M., Gong, E., Cheng, J. Y., Pauly, J. M., & Xing, L.
    2017, 发表在 2017 IEEE 第七届多传感器自适应处理计算进展国际研讨会（CAMSAP 2017）上，库拉索，荷兰，2017年12月10-13日,
    1–5
- en: 'Mardani et al. (2018) Mardani, M., Sun, Q., Vasawanala, S., et al. 2018, in
    Proceedings of the 32Nd International Conference on Neural Information Processing
    Systems, NIPS’18 (USA: Curran Associates Inc.), 9596–9606'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mardani 等人（2018）Mardani, M., Sun, Q., Vasawanala, S., 等. 2018, 发表在第32届国际神经信息处理系统会议（NIPS’18）上（美国：Curran
    Associates Inc.），9596–9606
- en: Mboula et al. (2016) Mboula, F., Starck, J.-L., Okumura, K., Amiaux, J., & Hudelot,
    P. 2016, Inverse Problems, 32
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mboula 等人（2016）Mboula, F., Starck, J.-L., Okumura, K., Amiaux, J., & Hudelot,
    P. 2016, 发表在《反问题》, 32
- en: Meinhardt et al. (2017) Meinhardt, T., Moller, M., Hazirbas, C., & Cremers,
    D. 2017, in Proceedings of the IEEE International Conference on Computer Vision,
    1781–1790
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meinhardt 等人（2017）Meinhardt, T., Moller, M., Hazirbas, C., & Cremers, D. 2017,
    发表在 IEEE 国际计算机视觉会议论文集上, 1781–1790
- en: 'Monga et al. (2019) Monga, V., Li, Y., & Eldar, Y. C. 2019, Algorithm Unrolling:
    Interpretable, Efficient Deep Learning for Signal and Image Processing'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Monga 等人（2019）Monga, V., Li, Y., & Eldar, Y. C. 2019, 《算法展开：可解释的高效深度学习用于信号和图像处理》
- en: Neelamani et al. (2004) Neelamani, R., Hyeokho Choi, & Baraniuk, R. 2004, IEEE
    Transactions on Signal Processing, 52, 418
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neelamani 等人（2004）Neelamani, R., Hyeokho Choi, & Baraniuk, R. 2004, 发表在《IEEE
    信号处理汇刊》, 52, 418
- en: Oliveira et al. (2009) Oliveira, J. P., Bioucas-Dias, J. M., & Figueiredo, M. A.
    2009, Signal Processing, 89, 1683
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oliveira等（2009）Oliveira, J. P., Bioucas-Dias, J. M., & Figueiredo, M. A. 2009，《信号处理》，89,
    1683
- en: Orieux et al. (2010) Orieux, F., Giovannelli, J., & Rodet, T. 2010, in 2010
    IEEE International Conference on Acoustics, Speech and Signal Processing, 1350–1353
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Orieux等（2010）Orieux, F., Giovannelli, J., & Rodet, T. 2010，发表于2010 IEEE国际声学、语音和信号处理会议，1350–1353
- en: Pereyra et al. (2015) Pereyra, M., Bioucas-Dias, J. M., & Figueiredo, M. A. T.
    2015, in 2015 23rd European Signal Processing Conference (EUSIPCO), 230–234
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pereyra等（2015）Pereyra, M., Bioucas-Dias, J. M., & Figueiredo, M. A. T. 2015，发表于2015年第23届欧洲信号处理会议（EUSIPCO），230–234
- en: Pesquet et al. (2009) Pesquet, J., Benazza-Benyahia, A., & Chaux, C. 2009, IEEE
    Transactions on Signal Processing, 57, 4616
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pesquet等（2009）Pesquet, J., Benazza-Benyahia, A., & Chaux, C. 2009，《IEEE信号处理汇刊》，57,
    4616
- en: Petersen & Voigtlaender (2018) Petersen, P. & Voigtlaender, F. 2018, Neural
    Networks, 108, 296
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Petersen & Voigtlaender（2018）Petersen, P. & Voigtlaender, F. 2018，《神经网络》，108,
    296
- en: Pustelnik et al. (2016) Pustelnik, N., Benazza-Benhayia, A., Zheng, Y., & Pesquet,
    J.-C. 2016, Wiley Encyclopedia of Electrical and Electronics Engineering
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pustelnik等（2016）Pustelnik, N., Benazza-Benhayia, A., Zheng, Y., & Pesquet, J.-C.
    2016，《Wiley电气与电子工程百科全书》
- en: Ribli et al. (2019) Ribli, D., Pataki, B. Á., & Csabai, I. 2019, Nature Astronomy,
    3, 93
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ribli等（2019）Ribli, D., Pataki, B. Á., & Csabai, I. 2019，《自然天文学》，3, 93
- en: Romano et al. (2017) Romano, Y., Elad, M., & Milanfar, P. 2017, SIAM Journal
    on Imaging Sciences, 10, 1804
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Romano等（2017）Romano, Y., Elad, M., & Milanfar, P. 2017，《SIAM图像科学杂志》，10, 1804
- en: 'Ronneberger et al. (2015) Ronneberger, O., Fischer, P., & Brox, T. 2015, in
    Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015, ed.
    N. Navab, J. Hornegger, W. M. Wells, & A. F. Frangi (Cham: Springer International
    Publishing), 234–241'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ronneberger等（2015）Ronneberger, O., Fischer, P., & Brox, T. 2015，发表于《医学图像计算与计算机辅助干预
    – MICCAI 2015》，编辑 N. Navab, J. Hornegger, W. M. Wells, & A. F. Frangi（Cham: 施普林格国际出版社），234–241'
- en: Rowe et al. (2015) Rowe, B., Jarvis, M., Mandelbaum, R., et al. 2015, Astronomy
    and Computing, 10, 121
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rowe等（2015）Rowe, B., Jarvis, M., Mandelbaum, R., 等 2015，《天文学与计算》，10, 121
- en: Safran & Shamir (2017) Safran, I. & Shamir, O. 2017, in Proceedings of the 34th
    International Conference on Machine Learning - Volume 70, ICML’17 (JMLR.org),
    2979–2987
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Safran & Shamir（2017）Safran, I. & Shamir, O. 2017，发表于第34届国际机器学习会议论文集 - 第70卷，ICML’17（JMLR.org），2979–2987
- en: 'Schawinski et al. (2017) Schawinski, K., Zhang, C., Zhang, H., Fowler, L.,
    & Santhanam, G. K. 2017, Monthly Notices of the Royal Astronomical Society: Letters,
    467, slx008'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schawinski等（2017）Schawinski, K., Zhang, C., Zhang, H., Fowler, L., & Santhanam,
    G. K. 2017，《皇家天文学会月刊：信件》，467, slx008
- en: Schmitz et al. (2019) Schmitz, M. A., Starck, J. L., Ngole Mboula, F., et al.
    2019, arXiv e-prints, arXiv:1906.07676
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schmitz等（2019）Schmitz, M. A., Starck, J. L., Ngole Mboula, F., 等 2019，arXiv电子预印本，arXiv:1906.07676
- en: Schuler et al. (2013) Schuler, C. J., Burger, H. C., Harmeling, S., & Schölkopf,
    B. 2013, in 2013 IEEE Conference on Computer Vision and Pattern Recognition, 1067–1074
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schuler等（2013）Schuler, C. J., Burger, H. C., Harmeling, S., & Schölkopf, B.
    2013，发表于2013 IEEE计算机视觉与模式识别会议，1067–1074
- en: Schuler et al. (2016) Schuler, C. J., Hirsch, M., Harmeling, S., & Schölkopf,
    B. 2016, IEEE Transactions on Pattern Analysis and Machine Intelligence, 38, 1439
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schuler等（2016）Schuler, C. J., Hirsch, M., Harmeling, S., & Schölkopf, B. 2016，《IEEE模式分析与机器智能汇刊》，38,
    1439
- en: Sreehari et al. (2016) Sreehari, S., Venkatakrishnan, S., Wohlberg, B., et al.
    2016, IEEE Transactions on Computational Imaging, 2, 408
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sreehari等（2016）Sreehari, S., Venkatakrishnan, S., Wohlberg, B., 等 2016，《IEEE计算成像汇刊》，2,
    408
- en: Starck et al. (2000) Starck, J.-L., Bijaoui, A., Valtchanov, I., & Murtagh,
    F. 2000, Astronomy and Astrophysics, Supplement Series, 147, 139–149
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Starck等（2000）Starck, J.-L., Bijaoui, A., Valtchanov, I., & Murtagh, F. 2000，《天文学与天体物理学》，补充系列，147,
    139–149
- en: 'Starck et al. (2015a) Starck, J.-L., Murtagh, F., & Bertero, M. 2015a, Starlet
    Transform in Astronomical Data Processing (New York, NY: Springer New York), 2053–2098'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Starck等（2015a）Starck, J.-L., Murtagh, F., & Bertero, M. 2015a，《天文数据处理中的Starlet变换》（纽约：施普林格纽约），2053–2098
- en: 'Starck et al. (2015b) Starck, J.-L., Murtagh, F., & Fadili, J. 2015b, Sparse
    Image and Signal Processing: Wavelets and Related Geometric Multiscale Analysis
    (Cambridge University Press)'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Starck等（2015b）Starck, J.-L., Murtagh, F., & Fadili, J. 2015b，《稀疏图像与信号处理：小波及相关几何多尺度分析》（剑桥大学出版社）
- en: Starck et al. (2003) Starck, J.-L., Nguyen, M., & Murtagh, F. 2003, Signal Processing,
    83, 2279
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Starck等（2003）Starck, J.-L., Nguyen, M., & Murtagh, F. 2003，《信号处理》，83, 2279
- en: Sureau et al. (2014) Sureau, F. C., Starck, J.-L., Bobin, J., Paykari, P., &
    Rassat, A. 2014, Astronomy and Astrophysics - A&A, 566, A100
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sureau 等 (2014) Sureau, F. C., Starck, J.-L., Bobin, J., Paykari, P., & Rassat,
    A. 2014，《天文学与天体物理学 - A&A》，566，A100
- en: Szegedy et al. (2016) Szegedy, C., Ioffe, S., & Vanhoucke, V. 2016, AAAI Conference
    on Artificial Intelligence
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等 (2016) Szegedy, C., Ioffe, S., & Vanhoucke, V. 2016，《AAAI 人工智能会议》
- en: T. Reehorst & Schniter (2018) T. Reehorst, E. & Schniter, P. 2018, IEEE Transactions
    on Computational Imaging, PP, 1
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: T. Reehorst & Schniter (2018) T. Reehorst, E. & Schniter, P. 2018，《IEEE 计算成像汇刊》，PP，1
- en: Tikhonov & Arsenin (1977) Tikhonov, A. N. & Arsenin, V. Y. 1977, Solutions of
    Ill-posed problems (W.H. Winston)
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tikhonov & Arsenin (1977) Tikhonov, A. N. & Arsenin, V. Y. 1977，《不适定问题的解》（W.H.
    Winston）
- en: Twomey (1963) Twomey, S. 1963, J. ACM, 10, 97
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Twomey (1963) Twomey, S. 1963，《J. ACM》，10，97
- en: Venkatakrishnan et al. (2013) Venkatakrishnan, S. V., Bouman, C. A., & Wohlberg,
    B. 2013, 2013 IEEE Global Conference on Signal and Information Processing, 945
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Venkatakrishnan 等 (2013) Venkatakrishnan, S. V., Bouman, C. A., & Wohlberg,
    B. 2013，《2013 IEEE 全球信号与信息处理会议》，945
- en: Viola et al. (2011) Viola, M., Melchior, P., & Bartelmann, M. 2011, MNRAS, 410,
    2156
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Viola 等 (2011) Viola, M., Melchior, P., & Bartelmann, M. 2011，《MNRAS》，410，2156
- en: Werner Engl et al. (1996) Werner Engl, H., Hanke, M., & Neubauer, A. 1996, Regularization
    of inverse problems (Dordrecht:Kluwer)
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Werner Engl 等 (1996) Werner Engl, H., Hanke, M., & Neubauer, A. 1996，《逆问题的正则化》（Dordrecht:
    Kluwer）'
- en: Xu et al. (2014) Xu, L., Ren, J., Liu, C., & Jia, J. 2014, Advances in Neural
    Information Processing Systems, 2, 1790
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等 (2014) Xu, L., Ren, J., Liu, C., & Jia, J. 2014，《神经信息处理系统进展》，2，1790
- en: Ye et al. (2018a) Ye, J., Han, Y., & Cha, E. 2018a, SIAM Journal on Imaging
    Sciences, 11, 991
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ye 等 (2018a) Ye, J., Han, Y., & Cha, E. 2018a，《SIAM 图像科学杂志》，11，991
- en: Ye et al. (2018b) Ye, J. C., Han, Y., & Cha, E. 2018b, SIAM Journal on Imaging
    Sciences, 11, 991
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ye 等 (2018b) Ye, J. C., Han, Y., & Cha, E. 2018b，《SIAM 图像科学杂志》，11，991
- en: Zhang et al. (2017) Zhang, K., Zuo, W., Gu, S., & Zhang, L. 2017, in 2017 IEEE
    Conference on Computer Vision and Pattern Recognition (CVPR), 2808–2817
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等 (2017) Zhang, K., Zuo, W., Gu, S., & Zhang, L. 2017，《2017 IEEE 计算机视觉与模式识别会议
    (CVPR)》，2808–2817
- en: Zibulevsky & Elad (2010) Zibulevsky, M. & Elad, M. 2010, IEEE Signal Processing
    Magazine, 27, 76
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zibulevsky & Elad (2010) Zibulevsky, M. & Elad, M. 2010，《IEEE 信号处理杂志》，27，76
- en: Zuntz et al. (2018) Zuntz, J., Sheldon, E., Samuroff, S., et al. 2018, Monthly
    Notices of the Royal Astronomical Society, 481, 1149
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zuntz 等 (2018) Zuntz, J., Sheldon, E., Samuroff, S., 等 2018，《皇家天文学会月刊》，481，1149
