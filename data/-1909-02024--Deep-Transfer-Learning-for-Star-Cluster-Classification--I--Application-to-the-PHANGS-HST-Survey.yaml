- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:05:13'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:05:13
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1909.02024] Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1909.02024] 深度迁移学习用于星团分类：I. 对PHANGS-HST调查的应用'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1909.02024](https://ar5iv.labs.arxiv.org/html/1909.02024)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1909.02024](https://ar5iv.labs.arxiv.org/html/1909.02024)
- en: 'Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度迁移学习用于星团分类：I. 对PHANGS-HST调查的应用
- en: Wei Wei,^(1,2) E. A. Huerta,^(1,3) Bradley C. Whitmore,⁴ Janice C. Lee,⁵ Stephen
    Hannon,⁶ Rupali Chandar,⁷ Daniel A. Dale,⁸ Kirsten L. Larson,⁵ David A. Thilker,⁹
    Leonardo Ubeda,⁴ Médéric Boquien,^(10) Mélanie Chevance,^(11) J. M. Diederik Kruijssen,^(11)
    Andreas Schruba^(12), Guillermo Blanc^(13,14,15), Enrico Congiu^(16,13)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 韦伟^(1,2)、E. A. 胡尔塔^(1,3)、布拉德利·C·惠特莫尔⁴、贾尼斯·C·李⁵、斯蒂芬·汉农⁶、鲁帕利·昌达⁷、丹尼尔·A·戴尔⁸、克尔斯滕·L·拉尔森⁵、戴维·A·希尔克⁹、莱昂纳多·乌贝达⁴、梅德里克·博基安^(10)、梅拉尼·谢旺斯^(11)、J.
    M. 迪德里克·克鲁伊森^(11)、安德烈亚斯·施鲁巴^(12)、吉列尔莫·布兰克^(13,14,15)、恩里科·孔久^(16,13)
- en: ¹NCSA, University of Illinois at Urbana-Champaign, Urbana, Illinois 61801, USA
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹NCSA，伊利诺伊大学厄尔巴纳-香槟分校，厄尔巴纳，伊利诺伊州 61801，美国
- en: ²Department of Physics, University of Illinois at Urbana-Champaign, Urbana,
    Illinois 61801, USA
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ²物理系，伊利诺伊大学厄尔巴纳-香槟分校，厄尔巴纳，伊利诺伊州 61801，美国
- en: ³Department of Astronomy, University of Illinois at Urbana-Champaign, Urbana,
    Illinois 61801, USA
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ³天文学系，伊利诺伊大学厄尔巴纳-香槟分校，厄尔巴纳，伊利诺伊州 61801，美国
- en: ⁴Space Telescope Science Institute, 3700 San Martin Drive, Baltimore, MD, USA
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴空间望远镜科学研究所，3700 圣马丁大道，巴尔的摩，MD，美国
- en: ⁵Caltech/IPAC, California Institute of Technology, Pasadena, CA, USA
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ⁵加州理工学院/IPAC，加州理工学院，帕萨迪纳，CA，美国
- en: ⁶Department of Physics and Astronomy, University of California, Riverside, CA,
    USA
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ⁶物理与天文学系，加州大学河滨分校，河滨，CA，美国
- en: ⁷Department of Physics and Astronomy, University of Toledo, Toledo, OH USA
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ⁷物理与天文学系，托莱多大学，托莱多，OH，美国
- en: ⁸Department of Physics and Astronomy, University of Wyoming, Laramie, WY, USA
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ⁸物理与天文学系，怀俄明大学，拉勒米，WY，美国
- en: ⁹Department of Physics and Astronomy, The Johns Hopkins University, Baltimore,
    MD, USA
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ⁹物理与天文学系，约翰斯·霍普金斯大学，巴尔的摩，MD，美国
- en: ^(10)Unidad de Astronomía, Universidad de Antofagasta, Antofagasta, Chile
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ^(10)安托法加斯塔大学天文学单位，安托法加斯塔，智利
- en: ^(11)Astronomisches Rechen-Institut, Zentrum für Astronomie der Universität
    Heidelberg, Heidelberg, Germany
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ^(11)天文学计算研究所，海德堡大学天文学中心，海德堡，德国
- en: ^(12)Max-Planck-Institut für extraterrestrische Physik, Garching, Germany
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ^(12)马克斯·普朗克外星物理研究所，加兴，德国
- en: ^(13)Observatories of the Carnegie Institution for Science, Pasadena, CA, USA
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ^(13)卡内基科学研究所天文台，帕萨迪纳，CA，美国
- en: ^(14)Departamento de Astronomía, Universidad de Chile, Las Condes, Santiago,
    Chile
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ^(14)智利大学天文学系，拉斯孔德斯，圣地亚哥，智利
- en: ^(15)Centro de Astrofísica y Tecnologías Afines (CATA), Las Condes, Santiago,
    Chile
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ^(15)天体物理与相关技术中心（CATA），拉斯孔德斯，圣地亚哥，智利
- en: '^(16)Las Campanas Observatory, La Serena, Chile Contact e-mail: [weiw2@illinois.edu](mailto:weiw2@illinois.edu)(Accepted
    XXX. Received YYY; in original form ZZZ)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '^(16)拉斯坎帕纳斯天文台，拉塞雷纳，智利 联系邮箱: [weiw2@illinois.edu](mailto:weiw2@illinois.edu)(接受日期XXX。收到日期YYY；原始形式ZZZ)'
- en: Abstract
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'We present the results of a proof-of-concept experiment which demonstrates
    that deep learning can successfully be used for production-scale classification
    of compact star clusters detected in HST UV-optical imaging of nearby spiral galaxies
    ($D\lesssim 20\,\textrm{Mpc}$) in the PHANGS-HST survey. Given the relatively
    small nature of existing, human-labelled star cluster samples, we transfer the
    knowledge of state-of-the-art neural network models for real-object recognition
    to classify star clusters candidates into four morphological classes. We perform
    a series of experiments to determine the dependence of classification performance
    on: neural network architecture (ResNet18 and VGG19-BN); training data sets curated
    by either a single expert or three astronomers; and the size of the images used
    for training. We find that the overall classification accuracies are not significantly
    affected by these choices. The networks are used to classify star cluster candidates
    in the PHANGS-HST galaxy NGC 1559, which was not included in the training samples.
    The resulting prediction accuracies are 70%, 40%, 40-50%, 50-70% for class 1,
    2, 3 star clusters, and class 4 non-clusters respectively. This performance is
    competitive with consistency achieved in previously published human and automated
    quantitative classification of star cluster candidate samples (70-80%, 40-50%,
    40-50%, and 60-70%). The methods introduced herein lay the foundations to automate
    classification for star clusters at scale, and exhibit the need to prepare a standardized
    dataset of human-labelled star cluster classifications, agreed upon by a full
    range of experts in the field, to further improve the performance of the networks
    introduced in this study.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了一个概念验证实验的结果，该实验表明深度学习可以成功地用于大规模生产分类，分类对象为在PHANGS-HST调查中通过HST UV-光学成像检测到的紧凑型恒星簇（$D\lesssim
    20\,\textrm{Mpc}$）。鉴于现有的人工标注恒星簇样本相对较少，我们将最先进的神经网络模型在真实对象识别中的知识迁移到分类恒星簇候选者为四个形态类别。我们进行了一系列实验，以确定分类性能对以下因素的依赖性：神经网络架构（ResNet18和VGG19-BN）；由单个专家或三位天文学家策划的训练数据集；以及用于训练的图像大小。我们发现这些选择对总体分类准确性没有显著影响。网络被用于分类PHANGS-HST星系NGC
    1559中的恒星簇候选者，该星系未包含在训练样本中。得到的预测准确率分别为类别1、2、3和类别4非簇的70%、40%、40-50%、50-70%。这一性能与之前发布的人类和自动化定量分类恒星簇候选样本（70-80%、40-50%、40-50%和60-70%）的一致性相当。本文介绍的方法为大规模自动化恒星簇分类奠定了基础，并展示了需要准备一个标准化的人类标注恒星簇分类数据集，该数据集需得到该领域所有专家的认可，以进一步提升本文研究中介绍的网络性能。
- en: 'keywords:'
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: 'galaxies : star clusters : general^†^†pubyear: 2019^†^†pagerange: Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey–[C](#A3
    "Appendix C Batch normalization ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '星系 : 恒星簇 : 一般^†^†出版年份: 2019^†^†页码范围: 深度迁移学习用于恒星簇分类：I. 应用于PHANGS-HST调查–[C](#A3
    "附录C 批量归一化 ‣ 深度迁移学习用于恒星簇分类：I. 应用于PHANGS-HST调查")'
- en: 1 Introduction
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Human visual classification of electromagnetic signals from astronomical sources
    is a core task in observational research with a long established history (Cannon
    & Pickering, [1912](#bib.bib14), [1918](#bib.bib15); Hubble, [1926](#bib.bib34),
    [1936](#bib.bib35); de Vaucouleurs, [1963](#bib.bib67)). It has been an essential
    means by which progress has been made in understanding the formation and evolution
    of structures from stars to galaxies. However, in the modern era of “Big Data"
    in Astronomy, with unprecedented growth in electromagnetic survey area, field
    of view, sensitivity, resolution, wavelength coverage, cadence, and transient
    alert production, it has become apparent that human classification is no longer
    scalable (Abbott et al., [2016](#bib.bib1); LSST Science Collaboration et al.,
    [2009](#bib.bib43)). This realization has motivated the use of machine learning
    techniques to automate image classification (Ball et al., [2008](#bib.bib5); Banerji
    et al., [2010](#bib.bib6); Carrasco Kind & Brunner, [2013](#bib.bib16); Ishak,
    [2017](#bib.bib36); Kamdar et al., [2016](#bib.bib37); Kim & Brunner, [2017](#bib.bib39)).
    Some of these machine learning algorithms have been integrated into widely-used
    methods for image processing, such as the neural networks trained for star/galaxy
    separation in the automated source detection and photometry software SEXTRACTOR (Bertin
    & Arnouts, [1996a](#bib.bib10)). Other applications of machine learning for image
    classification include the use of so-called decision trees (Weir et al., [1995](#bib.bib62);
    Suchkov et al., [2005](#bib.bib59); Ball et al., [2006](#bib.bib4); Vasconcellos
    et al., [2011](#bib.bib61); Sevilla-Noarbe & Etayo-Sotos, [2015](#bib.bib54))
    and support vector machines (Fadely et al., [2012](#bib.bib25); Solarz et al.,
    [2017](#bib.bib58); Małek & et al, [2013](#bib.bib46)).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 人类对天文源的电磁信号进行视觉分类是观测研究中的核心任务，拥有悠久的历史（Cannon & Pickering, [1912](#bib.bib14),
    [1918](#bib.bib15); Hubble, [1926](#bib.bib34), [1936](#bib.bib35); de Vaucouleurs,
    [1963](#bib.bib67)）。这是了解从恒星到银河系结构的形成和演变的重要手段。然而，在现代“Big Data”天文学时代，电磁勘测领域、视场、灵敏度、分辨率、波长覆盖、观测频率和瞬态警报生成的前所未有的增长使得人类分类已不再具有扩展性（Abbott
    et al., [2016](#bib.bib1); LSST Science Collaboration et al., [2009](#bib.bib43)）。这一认识促使了机器学习技术的应用，以自动化图像分类（Ball
    et al., [2008](#bib.bib5); Banerji et al., [2010](#bib.bib6); Carrasco Kind &
    Brunner, [2013](#bib.bib16); Ishak, [2017](#bib.bib36); Kamdar et al., [2016](#bib.bib37);
    Kim & Brunner, [2017](#bib.bib39)）。这些机器学习算法中的一些已被集成到广泛使用的图像处理方法中，例如用于在自动源检测和光度测量软件SEXTRACTOR中进行星系分离的神经网络（Bertin
    & Arnouts, [1996a](#bib.bib10)）。机器学习在图像分类中的其他应用包括使用所谓的决策树（Weir et al., [1995](#bib.bib62);
    Suchkov et al., [2005](#bib.bib59); Ball et al., [2006](#bib.bib4); Vasconcellos
    et al., [2011](#bib.bib61); Sevilla-Noarbe & Etayo-Sotos, [2015](#bib.bib54)）和支持向量机（Fadely
    et al., [2012](#bib.bib25); Solarz et al., [2017](#bib.bib58); Małek & et al.,
    [2013](#bib.bib46)）。
- en: Visual object recognition has also been a core research activity in the computer
    science community. For instance, the PASCAL VOC challenge was initiated to develop
    software to accurately classify about 20,000 images divided into twenty object
    classes (Everingham et al., [2015](#bib.bib24)). Over the last decade deep learning
    algorithms have rapidly evolved to become the state-of-the-art signal-processing
    tools for computer vision, to the point of surpassing human performance. The success
    of deep learning algorithms for image classification can be broadly attributed
    to the combination of increasing processing speed and the availability of very
    large datasets for training; i.e., Graphics Processing Units (GPUs) to train,
    validate and test neural network models; and curation of high-quality, human-labeled
    datasets, such as the ImageNet dataset (Deng et al., [2009](#bib.bib21)), which
    has over 14 million images divided into more than 1000 object categories.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉对象识别也一直是计算机科学社区的核心研究活动。例如，PASCAL VOC挑战赛旨在开发能够准确分类大约20,000张分为二十个对象类别的图像的软件（Everingham
    et al., [2015](#bib.bib24)）。在过去十年中，深度学习算法迅速发展，成为计算机视觉领域的最先进信号处理工具，甚至超越了人类性能。深度学习算法在图像分类中的成功可以广泛归因于处理速度的提升和用于训练的非常大的数据集的可用性；即用于训练、验证和测试神经网络模型的图形处理单元（GPUs）；以及高质量、人工标注的数据集的策划，如ImageNet数据集（Deng
    et al., [2009](#bib.bib21)），该数据集包含超过1400万张图像，分为1000多个对象类别。
- en: The ImageNet Large Scale Visual Recognition Challenge (Russakovsky et al., [2015](#bib.bib50))
    has driven the development of deep learning models that have achieved breakthroughs
    for image classification. In 2012, the network architecture AlexNet (Krizhevsky
    et al., [2012](#bib.bib41)) achieved a $\sim 50\%$ reduction in error rate in
    the ImageNet challenge—a remarkable feat at that time that relied on the use of
    GPUs for the training of the model, data augmentation (image translations, horizontal
    reflections and mean subtraction), as well as other novel algorithm improvements
    that are at the core of state-of-the-art neural network models today, e.g., using
    successive convolution and pooling layers followed by fully-connected layers at
    the end of the neural network architecture.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ImageNet 大规模视觉识别挑战（Russakovsky 等，[2015](#bib.bib50)）推动了深度学习模型的发展，并在图像分类方面取得了突破。2012
    年，网络架构 AlexNet（Krizhevsky 等，[2012](#bib.bib41)）在 ImageNet 挑战中实现了 $\sim 50\%$ 的错误率减少——当时这是一个显著的成就，依赖于使用
    GPU 进行模型训练、数据增强（图像平移、水平翻转和均值减法）以及其他新颖的算法改进，这些改进是当今最先进的神经网络模型的核心，例如，使用连续的卷积层和池化层，最后跟随全连接层的神经网络架构。
- en: Within the next two years, the architectures VGGNet (Simonyan & Zisserman, [2014b](#bib.bib57))
    and GoogLeNet (Szegedy et al., [2014](#bib.bib60)) continued to improve the discriminative
    power of deep learning algorithms for image classification using deeper and wider
    neural network models, and innovating data augmentation techniques such as scale
    jittering. Furthermore, GoogLeNet provided the means to further improve image
    classification analysis by introducing multi-scale processing, i.e., allowing
    the neural network model to recover local features through smaller convolutions,
    and abstract features with larger convolutions. In 2015, the ResNet (He et al.,
    [2015](#bib.bib31)) model was the first architecture to surpass human performance
    on the ImageNet challenge. In addition to this milestone in computer vision, ResNet
    was also used to demonstrate that a naive stacking of layers does not guarantee
    enhanced performance in ultra deep neural network models, and may actually lead
    to sub-optimal performance for image classification.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的两年中，架构 VGGNet（Simonyan & Zisserman，[2014b](#bib.bib57)）和 GoogLeNet（Szegedy
    等，[2014](#bib.bib60)）继续通过更深更宽的神经网络模型提升深度学习算法在图像分类方面的辨别能力，并创新了如尺度抖动等数据增强技术。此外，GoogLeNet
    通过引入多尺度处理，即通过较小的卷积恢复局部特征，以及通过较大的卷积抽象特征，提供了进一步改进图像分类分析的方法。2015 年，ResNet（He 等，[2015](#bib.bib31)）模型成为第一个在
    ImageNet 挑战中超越人类表现的架构。除了这一计算机视觉的里程碑，ResNet 还被用来证明，简单地堆叠层并不能保证在超深神经网络模型中提升性能，实际上可能导致图像分类的次优性能。
- en: 'In view of the aforementioned accomplishments, research in deep learning for
    image classification has become a booming enterprise in science and technology.
    This vigorous program has led to innovative ways to leverage state-of-the-art
    neural network models to classify disparate datasets. This approach is required
    because most applications of deep learning for image classification rely on supervised
    learning. That is, neural network models are trained using large datasets of labelled
    data, such as the ImageNet dataset. In astronomical research, to enable the morphological
    classification of galaxies, the deep neural network model developed by (Dieleman
    et al., [2015](#bib.bib22)) was trained on $\sim$55,000 galaxy images, each with
    40-50 human classifications from the Galaxy Zoo 2 (Willett et al., [2013](#bib.bib66))
    online crowdsourcing project. This model was developed for the Galaxy Challenge
    competition in 2013-14 on the Kaggle platform, and took first place out of 326
    entries. \colorblack Given that datasets of that nature are challenging to obtain,
    deep “transfer” learning has provided the means to classify entirely new datasets
    by fine-tuning a pre-trained neural network model with the ImageNet dataset.¹¹1A
    brief overview of transfer learning is presented in Appendix [B](#A2 "Appendix
    B Deep transfer learning ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey").'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '鉴于上述成就，深度学习在图像分类领域的研究已成为科学技术中的蓬勃事业。这个充满活力的计划带来了利用最先进的神经网络模型对不同数据集进行分类的创新方法。这种方法是必要的，因为大多数深度学习图像分类应用依赖于监督学习。也就是说，神经网络模型是通过大量标注数据集进行训练的，例如ImageNet数据集。在天文学研究中，为了实现对星系的形态分类，（Dieleman等，[2015](#bib.bib22)）开发的深度神经网络模型是在约55,000张星系图像上训练的，每张图像都有来自Galaxy
    Zoo 2（Willett等，[2013](#bib.bib66)）在线众包项目的40-50个人工分类。该模型是为2013-14年Kaggle平台上的Galaxy
    Challenge竞赛开发的，并在326个参赛作品中获得第一名。由于这类数据集难以获得，深度“迁移”学习提供了通过用ImageNet数据集对预训练神经网络模型进行微调来分类全新数据集的手段。¹¹1迁移学习的简要概述见附录[B](#A2
    "Appendix B Deep transfer learning ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")。'
- en: While deep transfer learning was initially explored to classify datasets that
    were of similar nature to those used to train state-of-the-art neural network
    models, the first application of deep transfer learning of a pre-trained ImageNet
    neural network model to classify small datasets of entirely different nature was
    presented in George et al. ([2018](#bib.bib27), [2017](#bib.bib26)), where a variety
    of neural network models were used to report state-of-the-art image classification
    accuracy of noise anomalies in gravitational wave data. That study triggered a
    variety of applications of pre-trained ImageNet deep learning algorithms to classify
    images of galactic mergers (Ackermann et al., [2018](#bib.bib2)), and galaxies (Khan
    et al., [2019](#bib.bib38); Barchi et al., [2019](#bib.bib7); Domínguez Sánchez
    et al., [2018](#bib.bib23)), to mention a few examples.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然深度迁移学习最初是为了分类与训练最先进神经网络模型的数据集性质相似的数据集，但首次将预训练的ImageNet神经网络模型应用于完全不同性质的小数据集的深度迁移学习应用是由George等人（[2018](#bib.bib27),
    [2017](#bib.bib26)）提出的，其中使用了多种神经网络模型来报告在引力波数据中噪声异常的最先进图像分类准确性。这项研究引发了各种预训练ImageNet深度学习算法的应用，以分类星系合并（Ackermann等，[2018](#bib.bib2)）和星系（Khan等，[2019](#bib.bib38)；Barchi等，[2019](#bib.bib7)；Domínguez
    Sánchez等，[2018](#bib.bib23)）图像，仅举几个例子。
- en: 'Building upon these recent successful applications of deep transfer learning
    for image classification in physics and astronomy, in this paper we demonstrate
    that deep transfer learning provides the means to classify images of compact star
    clusters in nearby galaxies obtained with the Hubble Space Telescope (HST). We
    show that this approach yields classification accuracies on par with work performed
    by humans, and has the potential to \colorblack outperform humans and traditional
    machine learning. A major motivation of this work is to determine whether these
    deep transfer learning techniques can be used to automate production-scale classification
    of candidate star clusters in data from the Cycle 26 HST-PHANGS (Physics at High
    Angular Resolution in Nearby GalaxieS²²2[www.phangs.org](www.phangs.org)) Survey
    (PI: J.C. Lee, GO-15654) for which observations commenced in April 2019\. HST-PHANGS
    is anticipated to yield several tens of thousands of star cluster candidates for
    classification, only about a half of which will be true clusters. Encoding classification
    systems in neural networks will also improve the consistency of the classifications,
    and reduce the implicit impacts of subjectivity and subtle differences in classification
    systems adopted by different individuals (i.e., it can reduce both random and
    systematic errors in the classifcations).\colorblack'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基于近期在物理学和天文学图像分类中成功应用深度迁移学习的经验，本文展示了深度迁移学习可以用于对通过哈勃太空望远镜（HST）获得的相邻星系中紧凑星团的图像进行分类。我们表明，这种方法的分类准确性与人工工作相当，并且有潜力**超越**人类和传统机器学习。该工作的主要动机是确定这些深度迁移学习技术是否可以用于自动化生产规模的星团候选体分类，数据来自第26周期HST-PHANGS（**高角分辨率相邻星系物理学**²²2[www.phangs.org](www.phangs.org)）调查（首席研究员：J.C.
    Lee，GO-15654），观察始于2019年4月。预计HST-PHANGS将产生数万候选星团进行分类，其中仅约一半为真实的星团。在神经网络中编码分类系统还将提高分类的一致性，减少主观性和不同个体采用的分类系统之间的微妙差异所带来的隐含影响（即，它可以减少分类中的随机和系统性误差）。
- en: 'This paper is organized as follows. In Section [2](#S2 "2 Classification of
    Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey"), we summarize the objectives
    of star cluster classification, and describe the current classification system,
    which we employ in this paper. A review of the consistency between human classifications
    across prior studies is provided to establish the accuracy level to be achieved
    or surpassed by deep learning in this initial proof-of-concept experiment. In
    Section [3](#S3 "3 Data and Methods ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey"), we describe the imaging
    data and classifications used to train our neural network (NN) models, and then
    provide an overview of the NN models employed in this work. We report our results
    in Section [4](#S4 "4 Results ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey"). We conclude in Section [5](#S5 "5 Discussion
    & Conclusions ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey") with a summary of the results and next steps for future
    work.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '本文的组织结构如下。在第[2](#S2 "2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey")节中，我们总结了星团分类的目标，并描述了我们在本文中使用的当前分类系统。我们提供了先前研究中人类分类之间一致性的回顾，以建立深度学习在这次初步概念验证实验中需达到或超越的准确性水平。在第[3](#S3
    "3 Data and Methods ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")节中，我们描述了用于训练神经网络（NN）模型的成像数据和分类方法，并概述了在这项工作中采用的NN模型。在第[4](#S4
    "4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey")节中，我们报告了我们的结果。最后，在第[5](#S5 "5 Discussion & Conclusions
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey")节中，我们总结了结果并讨论了未来工作的下一步。'
- en: 2 Classification of Compact Star Clusters in Nearby Galaxies
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相邻星系中紧凑星团的分类
- en: 'The objects of interest in this study are compact star clusters and stellar
    associations in galaxies at distances between 4 Mpc to 20 Mpc. The physical sizes
    of compact clusters are characterized by effective radii between 0.5pc to about
    10pc (Portegies Zwart et al., [2010](#bib.bib49); Ryon et al., [2017](#bib.bib52)).
    Ryon et al. ([2014](#bib.bib51)) report that the distribution of effective radii
    of young ($\lesssim$10 Myr), massive compact star clusters peaks between 2-3 pc
    based on HST LEGUS observations of NGC1313 (D$\sim$4 Mpc) and NGC628 (D$\sim$10
    Mpc). Hence, only with the resolution of HST³³3The WFC3/UVIS point source function
    FWHM is 0$\aas@@fstack{\prime\prime}$067 at 5000Å. can such objects be distinguished
    from individual stars and separated from other star clusters in galaxies beyond
    the Local Group. ⁴⁴4We note that for a high signal-to-noise cluster it is possible
    to measure the broadening of the image (and hence the size of the source) to a
    fraction of the FWHM of the PSF of a star. The FWHM of a star using WFC3 is about
    1.8 pix (1.3 pc at D=4 Mpc, and 6.4 pc at 20 Mpc). A significant amount of testing
    has been done on ACS and WFC3 images using software like ISHAPE (Larson1999),
    and much published work (including Chandar et al. 2017, Ryon et al. 2017) has
    confirmed that this broadening can be measured down to about 0.2 pixels, corresponding
    to size limits of $\sim$0.3 pc, $\sim$0.6 pc at distances of 5 Mpc, 10 Mpc. Extending
    to 15 and 20 Mpc, the upper end of distance range covered by the PHANGS survey,
    the cluster size limits are 0.8 and 1.1 pc. Per the ISHAPE manual, at 5 Mpc, this
    is calculated as: 0.2 pix * 0.04 (arcsec/pix)* 24 pc/arcsec * 1.48 = 0.28 pc (where
    1.48 is a conversion factor given in the ISHAPE manual when assuming a King profile
    specifically). Hence, if the peak sizes for clusters are in the 2-3 pc range,
    the vast majority of cluster will be resolved for most of the galaxies in PHANGS-HST.
    The sizes of stellar associations, which dominate the young stellar population,
    span a wider range with sizes from a few pc to $\sim$100 pc  (Portegies Zwart
    et al., [2010](#bib.bib49); Gouliermis, [2018](#bib.bib29)).\colorblack'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究关注的对象是距离4 Mpc到20 Mpc的星系中的紧凑星团和星际联会。紧凑星团的物理尺寸由有效半径0.5 pc到约10 pc（Portegies
    Zwart等，[2010](#bib.bib49)；Ryon等，[2017](#bib.bib52)）特征化。Ryon等（[2014](#bib.bib51)）报告称，基于HST
    LEGUS对NGC1313（D$\sim$4 Mpc）和NGC628（D$\sim$10 Mpc）的观测，年轻（$\lesssim$10 Myr）、大质量紧凑星团的有效半径分布在2-3
    pc之间达到峰值。因此，只有在HST的分辨率下，这些对象才能从个别恒星中区分开，并从局部星系中的其他星团中分离出来。⁴⁴我们注意到，对于高信噪比的星团，可以将图像的扩展（因此源的大小）测量到星的PSF的FWHM的一个分数。使用WFC3的星的FWHM约为1.8像素（在D=4
    Mpc时为1.3 pc，在20 Mpc时为6.4 pc）。在使用像ISHAPE（Larson1999）这样的软件对ACS和WFC3图像进行大量测试后，许多已发布的工作（包括Chandar等人2017年，Ryon等人2017年）确认这一扩展可以测量到约0.2像素，对应于$\sim$0.3
    pc、5 Mpc和10 Mpc距离下的$\sim$0.6 pc的尺寸限制。扩展到15和20 Mpc，即PHANGS调查覆盖的距离范围的上限，星团的尺寸限制为0.8和1.1
    pc。根据ISHAPE手册，在5 Mpc下，这计算为：0.2像素 * 0.04（弧秒/像素）* 24 pc/弧秒 * 1.48 = 0.28 pc（其中1.48是ISHAPE手册中在假设King轮廓时给出的转换因子）。因此，如果星团的峰值尺寸在2-3
    pc范围内，大多数星团将在PHANGS-HST中的大多数星系中被分辨出来。主导年轻恒星群体的星际联会的尺寸跨度更广，从几pc到$\sim$100 pc（Portegies
    Zwart等，[2010](#bib.bib49)；Gouliermis，[2018](#bib.bib29)）。
- en: Early attempts at classifying clusters in external galaxies with HST imaging
    focused mainly on old globular clusters, for example, the swarm of thousands of
    globular clusters around the central elliptical galaxy in the Virgo Cluster, M87
     (Whitmore et al., [1995](#bib.bib63)). This was a fairly straightforward process
    since the background was smooth and the clusters were well separated. With the
    discovery of super star clusters in merging galaxies (e.g, Holtzman et al., [1992](#bib.bib33)),
    the enterprise of the identification and study of clusters in star-forming galaxies
    using HST began, despite the fact that crowding and variable backgrounds in such
    galaxies make the process far more challenging. Studies of normal spiral galaxies
    pushed the limits to fainter and more common clusters (e.g, Larsen, [2002](#bib.bib44);
    Chandar et al., [2010](#bib.bib17)). In all these early studies, the primary objective
    was to distinguish true clusters from individual stars and image artifacts, and
    there were essentially no attempts to further segregate the clusters into different
    classes.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 早期对外星系中星团的分类尝试主要集中在老的球状星团，例如，处于处女座星系团中心椭圆星系周围的成千上万的球状星团（Whitmore 等人，[1995](#bib.bib63)）。这是一个相当直接的过程，因为背景平滑且星团分离良好。随着在合并星系中发现超级星团（例如，Holtzman
    等人，[1992](#bib.bib33)），尽管拥挤和变化的背景使得这个过程更加具有挑战性，但使用 HST 进行星形成星系中星团的识别和研究的事业开始了。对正常螺旋星系的研究将极限推向了更暗和更常见的星团（例如，Larsen，[2002](#bib.bib44)；Chandar
    等人，[2010](#bib.bib17)）。在所有这些早期研究中，主要目标是将真实星团与单个星星和图像伪影区分开来，并且几乎没有进一步将星团分为不同类别的尝试。
- en: 'An exception, and one of the first attempts at a more detailed classification,
    was performed by Schweizer et al. ([1996](#bib.bib53)), who defined 9 object types
    and then grouped them into two classes: candidate globular clusters and extended
    stellar associations. More recently, Bastian et al. ([2012](#bib.bib8)), who studied
    clusters using HST imaging of the M83 galaxy, classified star clusters as either
    symmetric or asymmetric. Their analysis retained only symmetric clusters, which
    they posited were more likely to be gravitationally bound. Following this work,
    many studies in the field, most notably the Legacy ExtraGalactic UV Survey (LEGUS) (Calzetti
    et al., [2015a](#bib.bib12)) began differentiating clusters into two or three
    different categories, so that they could be studied separately or together depending
    on the goals of the project (see also the review by Krumholz et al., [2018](#bib.bib42),
    and their discussion of “exclusive" versus “inclusive" cluster catalogs).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例外，并且是更详细分类的最早尝试之一，由 Schweizer 等人（[1996](#bib.bib53)）进行，他们定义了 9 种对象类型，然后将它们分为两个类别：候选球状星团和扩展星关联。更近期，Bastian
    等人（[2012](#bib.bib8)）通过 HST 成像 M83 星系对星团进行了分类，将星团分为对称或非对称两类。他们的分析保留了仅对称的星团，认为这些星团更可能被引力束缚。在这项工作之后，该领域的许多研究，特别是遗产外银河紫外线调查（LEGUS）（Calzetti
    等，[2015a](#bib.bib12)）开始将星团区分为两类或三类，以便根据项目目标单独或一起研究（另见 Krumholz 等人，[2018](#bib.bib42)
    的综述以及他们对“独占”与“包容”星团目录的讨论）。
- en: The LEGUS project also employed machine learning techniques for some of their
    cluster classification work Messa et al. ([2018](#bib.bib47)); Grasha et al. ([2019](#bib.bib30)).
    This pioneering work will be discussed in Section 5.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: LEGUS 项目还采用了机器学习技术进行部分星团分类工作 Messa 等人（[2018](#bib.bib47)）；Grasha 等人（[2019](#bib.bib30)）。这项开创性工作将在第
    5 节讨论。
- en: 'In LEGUS, cluster candidates are sorted into four classes as follows (Adamo
    et al., [2017](#bib.bib3); Cook et al., [2019](#bib.bib20)):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LEGUS 中，星团候选对象被分为以下四类（Adamo 等，[2017](#bib.bib3)；Cook 等，[2019](#bib.bib20)）：
- en: •
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Class 1: compact, symmetric, single central peak, radial profile more extended
    relative to point source'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 类别 1：紧凑，对称，单一中央峰，相对点源的径向轮廓更扩展
- en: •
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Class 2: compact, asymmetric or non-circular (e.g., elongated), single central
    peak'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 类别 2：紧凑，非对称或非圆形（例如，拉长），单一中央峰
- en: •
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Class 3: asymmetric, multiple peaks, sometimes superimposed on diffuse extended
    source'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 类别 3：非对称，多峰，有时叠加在扩展的模糊源上
- en: •
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Class 4: not a star cluster (image artifacts, background galaxies, pairs and
    multiple stars in crowded regions, stars)'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 类别 4：非星团（图像伪影、背景星系、拥挤区域中的双星和多星、星星）
- en: 'We adopt the same classification system for this paper. In general, we refer
    to class 1, 2, and 3 as “compact symmetric cluster," “compact asymmetric cluster,"
    and “compact association" respectively. Examples of objects in each of these classes
    are shown in Figure [1](#S2.F1 "Figure 1 ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey").'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为本文采用相同的分类系统。一般来说，我们将第1、2和3类分别称为“紧凑对称星团”、“紧凑不对称星团”和“紧凑联会”。每个类别的对象示例如图[1](#S2.F1
    "图1 ‣ 近邻星系中紧凑星团的分类 ‣ 星团分类的深度迁移学习：I. 对PHANGS-HST调查的应用")所示。
- en: '![Refer to caption](img/c853e41278f0c98a7008015b82f50075.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c853e41278f0c98a7008015b82f50075.png)'
- en: 'Figure 1: Examples of each of the four cluster classifications illustrated
    with HST/WFC3 imaging. The top four rows show star clusters from NGC 4656, which
    are part of the training set, while the bottom four rows show clusters from recent
    PHANGS-HST observations of the spiral galaxy NGC 1559, which form our proof-of-concept
    test sample, and are not used for training. The first two columns show false-color
    RGB images for context: the first column displays a 299p x 299p RGB image (R =
    F814W, G = F438W + F555W, B = F275W + F336W) and the second column shows only
    the center 50p x 50p of the RGB image (184pc x 184pc for NGC1559, for example).
    The center 50p x 50p of individual NUV-U-B-V-I HST images, which are used as input
    to the pre-trained neural network models for further training (tuning) and evaluation,
    are shown in grayscale in the last 5 columns (from left to right, 50p x 50p images
    taken with filters F275W, F336W, F438W, F555W, and F814W). We also experiment
    with 25p x 25p and 100p x 100p images, as discussed in Sections 3 and 4.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：使用HST/WFC3成像展示的四种星团分类示例。顶部四行展示来自NGC 4656的星团，这些星团是训练集的一部分，而底部四行展示了来自最近PHANGS-HST观测的螺旋星系NGC
    1559的星团，这些星团构成了我们的概念验证测试样本，不用于训练。前两列显示了虚假彩色RGB图像以供参考：第一列显示了299p x 299p的RGB图像（R
    = F814W，G = F438W + F555W，B = F275W + F336W），第二列仅显示RGB图像的中心50p x 50p（例如NGC1559的184pc
    x 184pc）。最后5列（从左到右，50p x 50p图像采用滤镜F275W、F336W、F438W、F555W和F814W）显示了个别NUV-U-B-V-I
    HST图像的中心50p x 50p，这些图像作为预训练神经网络模型进一步训练（调整）和评估的输入。我们还实验了25p x 25p和100p x 100p的图像，具体见第3节和第4节。
- en: 2.1 Consistency among Classifications
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 分类一致性
- en: \color
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: \color
- en: black The stated goal of the current work is to provide cluster classifications
    via deep transfer learning models that achieve accuracy levels at least
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: black 当前工作的既定目标是通过深度迁移学习模型提供星团分类，以达到至少
- en: as good as other star cluster classifications in the literature, both by human
    visual inspection and by application of quantitative selection criteria. \colorblack
    In this section we establish this “accuracy" level, which we define as the consistency
    between different classifications for the same cluster populations as reported
    in the literature, as well as relative to classifications homogeneously performed
    by one of us (Bradley C. Whitmore, hereafter BCW.).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 与文献中的其他星团分类一样，无论是通过人工视觉检查还是应用定量选择标准，效果都很不错。 \colorblack 在这一部分，我们确定了这个“准确性”水平，我们将其定义为文献中对同一星团群体的不同分类之间的一致性，以及相对于我们中的一位（Bradley
    C. Whitmore，以下简称BCW.）进行的均匀分类。
- en: A first look at the overall consistency between the clusters cataloged by different
    studies, but based on the same data and same limiting magnitude, is provided by
    the work on M83 by Bastian et al. ([2012](#bib.bib8)); Whitmore et al. ([2014](#bib.bib64));
    Chandar et al. ([2014](#bib.bib18)). Comparisons reported in those papers show
    that about $\sim$70% of the clusters are in common between the studies. Later,
    Adamo et al. ([2017](#bib.bib3)) performed a similar comparison for the spiral
    galaxy NGC 628 for the catalogs from LEGUS and Whitmore et al. ([2014](#bib.bib64)),
    and finds an overlap
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对基于相同数据和相同限制幅度的不同研究分类星团的一致性进行初步观察的是Bastian等人对M83的研究（[2012](#bib.bib8)）；Whitmore等人（[2014](#bib.bib64)）；Chandar等人（[2014](#bib.bib18)）。这些论文中的比较显示大约70%的星团在这些研究之间是共同的。后来，Adamo等人（[2017](#bib.bib3)）对LEGUS和Whitmore等人（[2014](#bib.bib64)）的目录进行了类似的比较，发现重叠
- en: of $\sim$75%. Finally, the LEGUS study of M51 by Messa et al. ([2018](#bib.bib47))
    find
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 大约为75%。最后，Messa等人对M51的LEGUS研究（[2018](#bib.bib47)）发现
- en: an overlap of 73% in common with a study by Chandar et al. ([2016](#bib.bib19)).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 与Chandar等人（[2016](#bib.bib19)）的研究有73%的重叠。
- en: These results are not based only upon detailed analysis of human-vs-human cluster
    classifications for individual objects; they are statistical measures of overlap
    between samples where a mix of human classification/identification, and automated
    star/cluster separation based on the concentration index (i.e., the difference
    in magnitude in a 1 pixel vs. 3 pixel radius) were used across the studies.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果不仅基于对个别对象的人类与人类星团分类的详细分析；它们是样本之间重叠的统计测量，其中使用了人类分类/识别和基于浓度指数（即1像素与3像素半径的亮度差异）的自动星团分离。
- en: '![Refer to caption](img/94c84b11f318d8c2e0c1760799ec058f.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/94c84b11f318d8c2e0c1760799ec058f.png)'
- en: 'Figure 2: Comparisons between star cluster candidate classifications made by
    BCW and the mode of classifications made by three other LEGUS team members (trained
    by BCW, A. Adamo, and H. Kim) provided in the LEGUS public star cluster catalog
    for NGC 4656\. Each panel shows the distribution of classifications given in the
    LEGUS catalog for BCW labelled class 1 (top, symmetric compact clusters), class
    2 (upper middle, asymmetric compact clusters), class 3 (lower middle, compact
    associations) and class 4 (bottom, non-clusters) objects.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：BCW 和其他三名 LEGUS 团队成员（由 BCW、A. Adamo 和 H. Kim 培训）在 LEGUS 公共星团目录中提供的 NGC 4656
    星团候选分类的比较。每个面板展示了 BCW 标记的类别 1（顶部，对称紧凑星团）、类别 2（上中，对称紧凑星团）、类别 3（下中，紧凑星协）和类别 4（底部，非星团）物体的分类分布。
- en: 'To more directly evaluate human-vs-human cluster classifications alone we start
    with a comparison of the NGC 3351 cluster catalog from the LEGUS sample (performed
    by BCW and team member Sean Linden, who was trained by BCW) with a new version
    of the NGC3351 cluster catalog independently constructed by PHANGS-HST⁵⁵5PHANGS-HST
    has expanded imaging coverage of NGC3351 to produce greater overlap with PHANGS-ALMA
    CO observations of the galaxy, and is developing new star cluster catalogs for
    the fields. See Section [3.1](#S3.SS1 "3.1 Star Cluster Catalogs ‣ 3 Data and
    Methods ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey") for an overview of the catalog construction. (performed
    by BCW alone). This might be viewed as a test of the consistency that might be
    expected if the same (or very similar) classifiers return to the same data set
    after a passage of several years. We find a 80 % agreement between category 1
    objects, 53 % for category 2, 56 % for category 3\. If we combine category 1 and
    2 objects (which is what many authors do for their analysis), the agreement is
    88 %.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '为了更直接地评估人类与人类之间的星团分类，我们首先比较 LEGUS 样本中的 NGC 3351 星团目录（由 BCW 和团队成员 Sean Linden（由
    BCW 培训）完成）与 PHANGS-HST 独立构建的 NGC3351 星团目录的新版本。PHANGS-HST 扩展了 NGC3351 的成像覆盖范围，以产生与
    PHANGS-ALMA CO 观测的更大重叠，并正在开发新的星团目录。有关目录构建的概述，请参见第[3.1](#S3.SS1 "3.1 Star Cluster
    Catalogs ‣ 3 Data and Methods ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")节。这可以被视为如果相同（或非常相似）的分类器在几年后返回到相同数据集时，可能期望的一致性测试。我们发现类别
    1 对象的一致性为 80%，类别 2 为 53%，类别 3 为 56%。如果我们将类别 1 和 2 对象合并（这也是许多作者分析时采用的方法），则一致性为
    88%。'
- en: 'We next compare classifications assigned by BCW for NGC 4656 to those provided
    in the LEGUS public cluster catalog, which provides the mode of classifications
    made by three other LEGUS team members (trained by BCW, A. Adamo, and H. Kim).
    Results are shown in Figure [2](#S2.F2 "Figure 2 ‣ 2.1 Consistency among Classifications
    ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey").'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '接下来，我们将 BCW 为 NGC 4656 分配的分类与 LEGUS 公共星团目录中的分类进行比较，该目录提供了其他三名 LEGUS 团队成员（由
    BCW、A. Adamo 和 H. Kim 培训）进行的分类模式。结果如图[2](#S2.F2 "Figure 2 ‣ 2.1 Consistency among
    Classifications ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey")所示。'
- en: If we combine only the class $1+2$ clusters (to exclude compact associations
    which has a higher rate of confusion with class 4 non-clusters), the total match
    fraction is 67%. For the individual classes, the consistency of the assignments
    vary from 66%, 37%, 40%, 61% for class 1, 2, 3, and 4, respectively. Hence, the
    agreement for the BCW classifications versus the mode of classifications from
    three LEGUS team members for NGC 4656 are slightly lower than the comparisons
    between BCW and BCW (and Linden) for NGC 3351. Other galaxies where a similar
    comparison has been made between the BCW classifications and LEGUS 3-person (“consensus”)
    classifications (i.e., NGC 4242, NGC 4395N, and M51) result in similar numbers.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仅结合类别$1+2$的聚类（以排除与类别4非聚类混淆率较高的紧凑关联），总的匹配率为67%。对于各个类别，分配的一致性分别为66%、37%、40%和61%。因此，BCW分类与三名LEGUS团队成员的分类模式相比，对于NGC
    4656的匹配度略低于BCW与BCW（和Linden）在NGC 3351的比较。其他类似比较的星系，如BCW分类与LEGUS三人（“共识”）分类（即NGC
    4242、NGC 4395N和M51），结果相似。
- en: In summary, comparing between a wide range of different cluster classification
    methods, but for the same data sets, we find typical agreements in the range 40
    % (e.g., when comparing class 2 or class 3 objects alone) to 90 % (e.g. when combining
    class 1 + 2 for repeat classifications of
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，比较不同的聚类分类方法时，但对于相同的数据集，我们发现典型的一致性范围在40%（例如，仅比较类别2或类别3的对象）到90%（例如，将类别1和2结合进行重复分类）之间。
- en: cluster catalogs by the same, or very similar, classifiers). For the individual
    classes, the “accuracy" levels that we adopt to be achieved or surpassed for our
    deep learning studies proof-of-concept demonstration are 70-80%, 40-50%, 40-50%,
    and 60-70% for class 1, 2, 3, 4 objects respectively.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的，或非常相似的分类器的聚类目录）。对于各个类别，我们采用的“准确率”水平，以用于我们深度学习研究的概念验证展示，分别为70-80%、40-50%、40-50%和60-70%。
- en: \color
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: \color
- en: black
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 黑色
- en: '| Field | D (Mpc) | Class 1 | Class 2 | Class 3 | Class 4 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 场 | D (Mpc) | 类别1 | 类别2 | 类别3 | 类别4 |'
- en: '| NGC3351¹ | 10.0 | 118 | 80 | 95 | 325 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| NGC3351¹ | 10.0 | 118 | 80 | 95 | 325 |'
- en: '| NGC3627 | 10.1 | 403 | 175 | 164 | 837 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| NGC3627 | 10.1 | 403 | 175 | 164 | 837 |'
- en: '| NGC4242¹ | 5.8 | 117 | 60 | 14 | 42 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| NGC4242¹ | 5.8 | 117 | 60 | 14 | 42 |'
- en: '| NGC4395N² | 4.3 | 8 | 19 | 21 | 20 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| NGC4395N² | 4.3 | 8 | 19 | 21 | 20 |'
- en: '| NGC4449 | 4.31 | 120 | 261 | 213 | 0 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| NGC4449 | 4.31 | 120 | 261 | 213 | 0 |'
- en: '| NGC45¹ | 6.61 | 45 | 52 | 20 | 43 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| NGC45¹ | 6.61 | 45 | 52 | 20 | 43 |'
- en: '| NGC4656² | 5.5 | 83 | 125 | 47 | 173 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| NGC4656² | 5.5 | 83 | 125 | 47 | 173 |'
- en: '| NGC5457C | 6.7 | 287 | 108 | 81 | 436 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| NGC5457C | 6.7 | 287 | 108 | 81 | 436 |'
- en: '| NGC5474¹ | 6.8 | 48 | 95 | 34 | 144 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| NGC5474¹ | 6.8 | 48 | 95 | 34 | 144 |'
- en: '| NGC6744N | 7.1 | 164 | 143 | 58 | 210 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| NGC6744N | 7.1 | 164 | 143 | 58 | 210 |'
- en: '| Total |  | 1393 | 1118 | 747 | 2230 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 总计 |  | 1393 | 1118 | 747 | 2230 |'
- en: '| N $\geq$ 4 |  | 1271 | 1013 | 738 | 2125 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| N $\geq$ 4 |  | 1271 | 1013 | 738 | 2125 |'
- en: 'Table 1: Number of sources in each of the ten HST LEGUS fields which have been
    primarily classified by BCW. The number in each of morphological classes described
    in Section [2](#S2 "2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey") is given. The total number of clusters with detection in at
    least four filters (a requirement for inclusion in the training and testing) are
    given in the last row of the table. 80% of the latter (randomly selected) are
    used for training, and the remaining 20% are reserved for validation testing.
    Distances compiled by (Calzetti et al., [2015a](#bib.bib12)) are listed.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '表1：由BCW主要分类的每个HST LEGUS场中的源数。每个形态类别的数量如第[2](#S2 "2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")节所述。至少在四个滤镜中检测到的聚类总数（包含在训练和测试中的要求）在表格的最后一行给出。其中80%（随机选择）用于训练，其余20%用于验证测试。由(Calzetti
    et al., [2015a](#bib.bib12))编制的距离列出。'
- en: ¹ Classification primarily determined by BCW are available in the public release
    of the LEGUS cluster catalogs.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 由BCW主要确定的分类在LEGUS聚类目录的公开版本中可用。
- en: '² Independent classifications determined by BCW for fields for which LEGUS
    consensus classifications are available through the LEGUS public archive (Table [2](#S2.T2
    "Table 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '² 独立分类由 BCW 确定，适用于 LEGUS 共识分类可通过 LEGUS 公共档案获得的领域（表 [2](#S2.T2 "Table 2 ‣ 2.1
    Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey")）。'
- en: '| Field | D (Mpc) | Class 1 | Class 2 | Class 3 | Class 4 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 领域 | D (Mpc) | 类别 1 | 类别 2 | 类别 3 | 类别 4 |'
- en: '| NGC1313E | 4.39 | 42 | 95 | 122 | 386 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| NGC1313E | 4.39 | 42 | 95 | 122 | 386 |'
- en: '| NGC1313W | 4.39 | 85 | 191 | 210 | 373 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| NGC1313W | 4.39 | 85 | 191 | 210 | 373 |'
- en: '| NGC1433 | 8.3 | 51 | 61 | 56 | 138 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| NGC1433 | 8.3 | 51 | 61 | 56 | 138 |'
- en: '| NGC1566 | 18.0 | 258 | 214 | 261 | 328 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| NGC1566 | 18.0 | 258 | 214 | 261 | 328 |'
- en: '| NGC1705 | 5.1 | 16 | 13 | 13 | 54 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| NGC1705 | 5.1 | 16 | 13 | 13 | 54 |'
- en: '| NGC3344 | 7.0 | 119 | 118 | 159 | 161 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| NGC3344 | 7.0 | 119 | 118 | 159 | 161 |'
- en: '| NGC3738 | 4.9 | 49 | 93 | 86 | 214 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| NGC3738 | 4.9 | 49 | 93 | 86 | 214 |'
- en: '| NGC4656 | 5.5 | 93 | 91 | 78 | 169 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| NGC4656 | 5.5 | 93 | 91 | 78 | 169 |'
- en: '| M51 | 7.66 | 363 | 502 | 365 | 1261 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| M51 | 7.66 | 363 | 502 | 365 | 1261 |'
- en: '| NGC5253 | 3.15 | 20 | 37 | 23 | 154 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| NGC5253 | 3.15 | 20 | 37 | 23 | 154 |'
- en: '| NGC628C | 9.9 | 334 | 357 | 326 | 542 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| NGC628C | 9.9 | 334 | 357 | 326 | 542 |'
- en: '| NGC628E | 9.9 | 92 | 80 | 87 | 122 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| NGC628E | 9.9 | 92 | 80 | 87 | 122 |'
- en: '| NGC6503 | 5.27 | 71 | 96 | 131 | 172 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| NGC6503 | 5.27 | 71 | 96 | 131 | 172 |'
- en: '| NGC7793E | 3.44 | 32 | 76 | 83 | 62 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| NGC7793E | 3.44 | 32 | 76 | 83 | 62 |'
- en: '| NGC7793W | 3.44 | 51 | 84 | 86 | 78 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| NGC7793W | 3.44 | 51 | 84 | 86 | 78 |'
- en: '| IC4247 | 5.1 | 1 | 4 | 3 | 37 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| IC4247 | 5.1 | 1 | 4 | 3 | 37 |'
- en: '| IC559 | 5.3 | 9 | 12 | 4 | 18 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| IC559 | 5.3 | 9 | 12 | 4 | 18 |'
- en: '| NGC4395N | 4.3 | 8 | 12 | 19 | 19 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| NGC4395N | 4.3 | 8 | 12 | 19 | 19 |'
- en: '| NGC4395S | 4.3 | 31 | 64 | 42 | 31 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| NGC4395S | 4.3 | 31 | 64 | 42 | 31 |'
- en: '| NGC5238 | 4.51 | 4 | 4 | 1 | 9 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| NGC5238 | 4.51 | 4 | 4 | 1 | 9 |'
- en: '| NGC5477 | 6.4 | 5 | 9 | 9 | 49 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| NGC5477 | 6.4 | 5 | 9 | 9 | 49 |'
- en: '| UGC1249 | 6.9 | 13 | 35 | 40 | 133 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| UGC1249 | 6.9 | 13 | 35 | 40 | 133 |'
- en: '| UGC4305 | 3.05 | 16 | 29 | 40 | 147 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| UGC4305 | 3.05 | 16 | 29 | 40 | 147 |'
- en: '| UGC4459 | 3.66 | 2 | 5 | 3 | 20 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| UGC4459 | 3.66 | 2 | 5 | 3 | 20 |'
- en: '| UGC5139 | 3.98 | 2 | 7 | 7 | 23 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| UGC5139 | 3.98 | 2 | 7 | 7 | 23 |'
- en: '| UGC685 | 4.83 | 7 | 4 | 3 | 6 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| UGC685 | 4.83 | 7 | 4 | 3 | 6 |'
- en: '| UGC695 | 10.9 | 4 | 7 | 6 | 94 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| UGC695 | 10.9 | 4 | 7 | 6 | 94 |'
- en: '| UGC7408 | 6.7 | 19 | 16 | 11 | 32 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| UGC7408 | 6.7 | 19 | 16 | 11 | 32 |'
- en: '| UGCA281 | 5.9 | 2 | 9 | 4 | 34 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| UGCA281 | 5.9 | 2 | 9 | 4 | 34 |'
- en: '| Total |  | 1799 | 2325 | 2278 | 4866 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 总计 |  | 1799 | 2325 | 2278 | 4866 |'
- en: '| N $\geq$ 4 |  | 1795 | 2315 | 2265 | 4841 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| N $\geq$ 4 |  | 1795 | 2315 | 2265 | 4841 |'
- en: 'Table 2: Same as Table [1](#S2.T1 "Table 1 ‣ 2.1 Consistency among Classifications
    ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey"),
    but for the 29 HST LEGUS fields which have been classified by three people, and
    have star cluster catalogs available through the LEGUS public archive. The number
    in each of the morphological classes, as determined by the mode of these three
    people’s classifications, is given.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2：与表 [1](#S2.T1 "Table 1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification
    of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey") 相同，但适用于由三个人分类的
    29 个 HST LEGUS 领域，并且有星团目录可通过 LEGUS 公共档案获得。由这三个人分类的模式决定的每个形态类别中的数量，如上所述。'
- en: '| Field | D (Mpc) | Class 1 | Class 2 | Class 3 | Class 4 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 领域 | D (Mpc) | 类别 1 | 类别 2 | 类别 3 | 类别 4 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| NGC1559 | 19.0 | 302 | 252 | 162 | 710 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| NGC1559 | 19.0 | 302 | 252 | 162 | 710 |'
- en: 'Table 3: Number of sources in the PHANGS-HST observation of NGC 1559 which
    have been classified by BCW. This cluster sample is used to test the neural networks
    trained as described in Section [4.1](#S4.SS1 "4.1 Does prediction accuracy depend
    on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for
    Star Cluster Classification: I. Application to the PHANGS-HST Survey") as a proof-of-concept
    demonstration for production scale classification of PHANGS-HST compact clusters
    and associations.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3：PHANGS-HST 对 NGC 1559 的观测中已由 BCW 分类的源数量。此集群样本用于测试如第 [4.1](#S4.SS1 "4.1
    Does prediction accuracy depend on the origin of the classifications? ‣ 4 Results
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey") 节所述的神经网络，作为生产规模分类 PHANGS-HST 紧凑集群和关联的概念验证演示。'
- en: 3 Data and Methods
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 数据与方法
- en: In this section we describe the data sets used to train, validate and test our
    deep learning algorithms, and give an overview of the neural network models used.
    We approach this initial work as a proof of concept demonstration, with the intention
    of performing further optimization and more detailed tests in future work.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了用于训练、验证和测试我们深度学习算法的数据集，并概述了使用的神经网络模型。我们将这项初步工作视为概念验证演示，意在未来的工作中进行进一步的优化和更详细的测试。
- en: 3.1 Star Cluster Catalogs
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 星团目录
- en: A key point is that the training and testing of the neural networks presented
    here are based on a pre-selected sample of cluster candidates where a large fraction
    of unresolved (point) sources have been first discarded. In past work, such candidate
    samples have served as the starting point for visual classification by humans
    to remove remaining interlopers, and to characterize the morphologies of verified
    clusters as described above. The construction and selection methodolgy for cluster
    candidate samples used here follow most of the procedures adopted for the LEGUS
    project (Calzetti et al., [2015b](#bib.bib13)) as described in Adamo et al. ([2017](#bib.bib3)).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键点是，这里展示的神经网络的训练和测试基于预选的星团候选样本，其中已先行剔除了大量未解析的（点）源。在过去的工作中，这些候选样本作为人工视觉分类的起点，以去除剩余的伪影，并对验证的星团进行形态特征描述。这里使用的星团候选样本的构建和选择方法遵循了LEGUS项目（Calzetti等，[2015b](#bib.bib13)）采用的大部分程序，如Adamo等（[2017](#bib.bib3)）所述。
- en: To briefly review, the procedure includes detection using the SExtractor program (Bertin
    & Arnouts, [1996b](#bib.bib11)) on a white light image; filtering out most stars
    by requiring the concentration index⁶⁶6(CI = difference in magnitude between an
    aperture with 1 or 3 pixels) to be greater than a value determined based on training
    set of isolated point sources and clusters for each galaxy; requiring detections
    with photometric errors less than 0.3 mag in at least 4 filters; and selecting
    objects brighter than -6 mag in F555W (total Vega magnitude). Again, this results
    in a cluster candidate list which is then examined visually to remove artifacts
    (e.g., close pairs of stars, saturated stars and diffraction spikes, background
    galaxies, etc.). The primary tool used for the visual classification is the IMEXAMINE
    task in IRAF. See Figure 3 in Adamo et al. ([2017](#bib.bib3)) for a graphic description
    of the use of IMEXAMINE and the classification into four categories.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 简要回顾一下，这一过程包括使用SExtractor程序（Bertin & Arnouts，[1996b](#bib.bib11)）在白光图像上进行检测；通过要求浓度指数⁶⁶6（CI
    = 1或3像素的光圈之间的亮度差异）大于基于孤立点源和每个星系的星团的训练集确定的值来过滤大多数星星；要求在至少4个滤镜中光度误差小于0.3 mag；以及选择F555W中亮度大于-6
    mag的物体（总的Vega亮度）。这再次生成一个星团候选列表，然后进行视觉检查以去除伪影（例如，接近的双星、饱和星和衍射条纹、背景星系等）。主要用于视觉分类的工具是IRAF中的IMEXAMINE任务。有关IMEXAMINE的使用及其四类分类的图示描述，请参见Adamo等（[2017](#bib.bib3)）中的图3。
- en: 'For most of the LEGUS star cluster catalogs which have been publicly released
    through the MAST archive, ⁷⁷7[https://archive.stsci.edu/prepds/legus/dataproducts-public.html](https://archive.stsci.edu/prepds/legus/dataproducts-public.html)
    classifications are performed by three different team members and the mode is
    recorded as the final consensus value (i.e., the 29 fields in Table [2](#S2.T2
    "Table 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")). The LEGUS classifiers, were trained
    by BCW, A. Adamo, and H. Kim. For an additional 8 fields, classifications were
    performed primarily by a single team member, i.e., coauthor BCW.⁸⁸8S. Linden who
    was trained by BCW, assisted in classifications for sources in NGC 3351, NGC 3627,
    and NGC 5457) As of July 2019, classifications for 4 of the 8 HST fields primarily
    inspected by BCW are available from the LEGUS public archive (Table [1](#S2.T1
    "Table 1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")). BCW also independently classified
    two fields with LEGUS consensus classifications to enable consistency checks (e.g.,
    Figure [2](#S2.F2 "Figure 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification
    of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey")), bringing the
    total to 10 galaxies in the sample with BCW classifications.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '对于通过MAST档案馆公开发布的大多数LEGUS星团目录，⁷⁷7[https://archive.stsci.edu/prepds/legus/dataproducts-public.html](https://archive.stsci.edu/prepds/legus/dataproducts-public.html)
    分类是由三个不同的团队成员进行的，模式被记录为最终共识值（即表[2](#S2.T2 "Table 2 ‣ 2.1 Consistency among Classifications
    ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey")中的29个字段）。LEGUS分类器由BCW、A.
    Adamo和H. Kim培训。对于另外8个字段，分类主要由单个团队成员，即共同作者BCW进行。⁸⁸8S. Linden在BCW的培训下，协助对NGC 3351、NGC
    3627和NGC 5457中的源进行分类。截止到2019年7月，BCW主要检查的8个HST字段中的4个分类可以从LEGUS公开档案馆获取（表[1](#S2.T1
    "Table 1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")）。BCW还独立对两个具有LEGUS共识分类的字段进行了分类，以便进行一致性检查（例如，图[2](#S2.F2
    "Figure 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")），使BCW分类的样本总数达到10个星系。'
- en: The construction of a preliminary cluster catalog for the first galaxy observed
    in the PHANGS-HST program NGC 1559 generally follow the methods used for LEGUS.
    The primary differences are that a F555W image was used instead of a white light
    image (which is more prone to small differences in alignment of different filters
    and the presence of very close pairs of stars with different colors),
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 对PHANGS-HST计划中首次观测到的星系NGC 1559的初步星团目录的构建一般遵循LEGUS使用的方法。主要的区别在于使用了F555W图像，而不是白光图像（白光图像对不同滤镜的对准小差异和具有不同颜色的非常接近的星对更敏感）。
- en: 'and a false-color image from the Hubble Legacy Archive (Whitmore et al., [2016](#bib.bib65))
    was simultaneously examined to help classify the clusters. A magnitude limit of
    -7.5 in the V band was used for NGC 1559, reflecting its larger distance (19 Mpc:
    A. Reiss, private communication) relative to the average distance of the LEGUS
    galaxies. A detailed presentation of the PHANGS-HST star cluster and association
    candidate selection methods will be provided in the PHANGS-HST survey paper (Lee
    et al. 2020) and catalog papers (e.g., Whitmore et al. 2020, Thilker et al. 2020,
    Larson et al. 2020).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 从哈勃遗产档案馆（Whitmore et al., [2016](#bib.bib65)）获取的伪彩色图像被同时检查以帮助分类这些星团。对NGC 1559使用了V波段的-7.5的星等限制，反映了其相对平均LEGUS星系更大的距离（19
    Mpc：A. Reiss，私人通讯）。PHANGS-HST星团和关联体候选选择方法的详细介绍将会在PHANGS-HST调查论文（Lee et al. 2020）和目录论文（例如，Whitmore
    et al. 2020，Thilker et al. 2020，Larson et al. 2020）中提供。
- en: \color
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: \color
- en: black
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 黑色
- en: 3.2 Image data & curation
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 图像数据与整理
- en: 'As input for the neural network training, we use postage stamps extracted from
    HST imaging taken in five broadband filters. Sample postage stamps are presented
    in the last five columns of Figure [1](#S2.F1 "Figure 1 ‣ 2 Classification of
    Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey").'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '作为神经网络训练的输入，我们使用从HST成像中提取的五个宽波段滤镜的邮票样本。样本邮票显示在图 [1](#S2.F1 "Figure 1 ‣ 2 Classification
    of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey")的最后五列中。'
- en: LEGUS obtained HST observations with WFC3 in 2013-2014 (GO-13364; PI Calzetti),
    and combined those data with ACS data taken in previous cycles by other programs
    to provide NUV-U-B-V-I coverage for a sample of 50 galaxies with 63 fields.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: LEGUS在2013-2014年获得了使用WFC3的HST观测数据（GO-13364；首席研究员Calzetti），并将这些数据与之前周期其他项目获取的ACS数据结合，以提供NUV-U-B-V-I覆盖，样本包含50个星系和63个观测场。
- en: PHANGS-HST (GO-15654; PI Lee) began observations on April 6, 2019 and is also
    obtaining observations with similar exposure times in the NUV-U-B-V-I filters.
    The first galaxy to be observed is NGC 1559.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: PHANGS-HST（GO-15654；首席研究员Lee）于2019年4月6日开始观测，并且也在使用NUV-U-B-V-I滤镜获得具有类似曝光时间的观测。第一个观测的星系是NGC
    1559。
- en: Bearing in mind that the neural network models used in this study (i.e., VGG19-BN
    and ResNet18; see next section) were pre-trained with the ImageNet dataset, in
    which images are resized to $299\times 299\times 3$, we follow best coding practices
    of neural network training, and curate our datasets so that star cluster images
    have size $299\times 299$ pixels.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到本研究中使用的神经网络模型（即VGG19-BN和ResNet18；见下一节）是在ImageNet数据集上预训练的，其中图像的尺寸为$299\times
    299\times 3$，我们遵循神经网络训练的最佳编码实践，并整理数据集，以便星团图像的大小为$299\times 299$像素。
- en: 'However, given that star clusters subtend only about several to a dozen HST
    WFC3 pixels, we focus the training on a small area (see Figure [1](#S2.F1 "Figure
    1 ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey")).'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '然而，由于星团仅占用约几个到十几个HST WFC3像素，我们将训练集中于小区域（见图 [1](#S2.F1 "Figure 1 ‣ 2 Classification
    of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey")）。'
- en: We first extract regions of 50 x 50 HST/WFC3 pixels centered on the star cluster
    candidate, which are then resized to fit in an 299 x 299 pixel area for the training.
    With WFC3’s pixel size of 0.04 arcseconds, each region corresponds to a physical
    width between $\sim$40-100pc for our sample of galaxies. To test whether the size
    of the cropped HST image influences the accuracy, we also extract regions which
    are half and twice as large as 50 HST/WFC3 pixels across.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先提取以星团候选区域为中心的50 x 50 HST/WFC3像素区域，然后将其调整为适合299 x 299像素区域的大小用于训练。由于WFC3的像素尺寸为0.04角秒，每个区域对应于我们样本中星系的物理宽度约为$\sim$40-100pc。为了测试裁剪的HST图像的大小是否影响准确性，我们还提取了宽度为50
    HST/WFC3像素的一半和两倍大小的区域。
- en: Procedurally, from the HST mosaics, a .fits image “postage stamp" centered on
    each target cluster is cropped from each of the NUV-U-B-V-I bands.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 从HST拼接图像中，我们从每个NUV-U-B-V-I波段中裁剪出一个以目标星团为中心的.fits图像“邮票”。
- en: The five resultant stamps for each cluster candidate are then stored in individual
    header data units (HDUs) within a single MEF file. We note that if there was no
    observation of the cluster in one of the filters, all pixel values for that particular
    filter’s postage stamp were set to zero. If there was no observation in more than
    one filter, the cluster was removed from our sample, consistent with the candidate
    selection criteria.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 每个星团候选者的五个结果邮票然后存储在一个MEF文件中的单独头数据单元（HDUs）中。我们注意到，如果在某一个滤镜下没有对星团进行观测，则该滤镜的邮票的所有像素值被设置为零。如果在多个滤镜下没有观测，则该星团从我们的样本中移除，以符合候选选择标准。
- en: 3.3 Neural network models
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 神经网络模型
- en: 'The available star cluster data sets are small compared to the datasets used
    to successfully train state-of-the-art neural network models for image classification.
    Thus, we use two neural network models, VGG19 (Simonyan & Zisserman, [2014a](#bib.bib56))
    with batch normalization (VGG19-BN) and ResNet18 (He et al., [2016](#bib.bib32)),
    pre-trained with the ImageNet dataset (see Section [1](#S1 "1 Introduction ‣ Deep
    Transfer Learning for Star Cluster Classification: I. Application to the PHANGS-HST
    Survey")), and then use deep transfer learning⁹⁹9A brief overview of transfer
    learning is presented in Appendix [B](#A2 "Appendix B Deep transfer learning ‣
    Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey"). to leverage the knowledge of these models to classify real-object
    images to our task at hand, namely, the morphological classification of star clusters.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '可用的星团数据集与用于成功训练最先进图像分类神经网络模型的数据集相比较小。因此，我们使用了两种神经网络模型，VGG19（Simonyan & Zisserman,
    [2014a](#bib.bib56)）带批量归一化（VGG19-BN）和 ResNet18（He et al., [2016](#bib.bib32)），这些模型经过
    ImageNet 数据集的预训练（见第 [1](#S1 "1 Introduction ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey") 节），然后使用深度迁移学习⁹⁹9A
    brief overview of transfer learning is presented in Appendix [B](#A2 "Appendix
    B Deep transfer learning ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey") 来利用这些模型的知识对实际对象图像进行分类，具体来说，就是星团的形态分类。'
- en: 'Regarding batch normalization for VGG19: the weights of each layer in a neural
    network model change throughout the training phase, which implies that the activations
    of each layer will also change. Given that the activations of any given layer
    are the inputs to the subsequent layer, this means that the input distribution
    changes at every step. This is far from ideal because it forces each intermediate
    layer to continuously adapt to changing inputs. Batch normalization is used to
    ameliorate this problem by normalizing the activations of each layer. In practice
    this is accomplished by adding two trainable parameters to each layer, so the
    normalized output is multiplied by a standard deviation parameter, and then shifted
    by a mean parameter. With this approach only two parameters are changed for each
    activation, as opposed to losing the stability of the network by changing all
    the weights. It is expected that through this method each layer will learn on
    a more stable distribution of inputs, which may accelerate the training stage.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 VGG19 的批量归一化：神经网络模型中每一层的权重在训练阶段会发生变化，这意味着每一层的激活也会变化。由于任何给定层的激活是后续层的输入，这意味着每一步的输入分布都会变化。这远非理想，因为这迫使每个中间层不断适应变化的输入。批量归一化用于改善这个问题，通过对每层的激活进行归一化来实现。实际上，这通过向每层添加两个可训练的参数来完成，因此归一化后的输出会乘以一个标准差参数，然后由一个均值参数进行平移。通过这种方法，每个激活只有两个参数被更改，而不是通过更改所有权重来失去网络的稳定性。预计通过这种方法，每一层将在更稳定的输入分布上进行学习，这可能会加速训练阶段。
- en: Both neural network architectures, VGG19-BN and ResNet18 have 3 input channels.
    However, since the star cluster candidates have images taken in 5 broadband filters,
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 两种神经网络架构，VGG19-BN 和 ResNet18 都有 3 个输入通道。然而，由于星团候选者的图像是在 5 个宽带滤镜下拍摄的，
- en: 'we concatenate two copies of the same neural network architecture. The merged
    neural networks have 6 input channels in total, so we set the input to the last
    channel to be constant zeros. We also apply one more matrix multiplication and
    an element-wise softmax function (see Appendix [A](#A1 "Appendix A Statistical
    foundations of Deep Learning Classifiers ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey")) (Goodfellow et al.,
    [2016](#bib.bib28)) to make sure that for each'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将两个相同的神经网络架构进行拼接。合并后的神经网络总共有 6 个输入通道，因此我们将最后一个通道的输入设置为常数零。我们还应用了一个额外的矩阵乘法和逐元素
    softmax 函数（见附录 [A](#A1 "Appendix A Statistical foundations of Deep Learning Classifiers
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey")）(Goodfellow et al., [2016](#bib.bib28))，以确保每个'
- en: candidate cluster the output is a vector of size 4, representing the probability
    distribution over the 4 classes under consideration. We choose this particular
    combination given its simplicity and its expected performance for image classification.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 候选星团的输出是一个大小为 4 的向量，表示在考虑的 4 个类别上的概率分布。我们选择这种特定组合是因为它的简单性和预期的图像分类性能。
- en: We use the pre-trained weights, except those for the last layers, of VGG19-BN
    and ResNet18 provided by PyTorch (Paszke et al., [2017](#bib.bib48)) as the initial
    values for the weights in our models. The weights for the last layers in VGG19-BN
    and ResNet18 and the last fully connected layers are randomly initialized. We
    use cross-entropy as the loss function^(10)^(10)10A loss function is used to evaluate
    and diagnose model optimization during training. The penalty for errors in the
    cross-entropy loss function is logarithmic, i.e., large errors are more strongly
    penalized. and Adam (Kingma & Ba, [2014](#bib.bib40)) for optimization. The learning
    rate is set to $10^{-4}$. The batch size for ResNet18 is 32, and for VGG19-BN
    is 16.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了 PyTorch 提供的 VGG19-BN 和 ResNet18 的预训练权重（除了最后几层的权重），作为我们模型中权重的初始值。VGG19-BN
    和 ResNet18 的最后几层的权重以及最后的全连接层的权重都是随机初始化的。我们使用交叉熵作为损失函数^(10)^(10)10损失函数用于评估和诊断训练过程中的模型优化。交叉熵损失函数中的错误惩罚是对数的，即较大的错误会受到更强的惩罚。并使用
    Adam (Kingma & Ba, [2014](#bib.bib40)) 进行优化。学习率设置为 $10^{-4}$。ResNet18 的批量大小为 32，VGG19-BN
    的批量大小为 16。
- en: 'Batch size and batch normalization refer to two distinct concepts. One epoch
    corresponds to all the training examples being passed both forward and backward
    through the neural network only once, while the batch size is the number of training
    examples in one forward/backward pass. For instance, we may divide a training
    data set of 100 images into 4 batches, so that the batch size is 25 sample images,
    and 4 iterations will complete one epoch. On the other hand, batch normalization
    is a technique used to improve the stability of the learning algorithms. The details
    are described in Appendix [C](#A3 "Appendix C Batch normalization ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey").'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 批量大小和批量归一化是两个不同的概念。一个 epoch 对应于所有训练样本仅通过神经网络正向和反向传播一次，而批量大小是一次正向/反向传播中的训练样本数量。例如，我们可以将
    100 张图像的训练数据集分成 4 个批次，这样批量大小为 25 张样本图像，4 次迭代将完成一个 epoch。另一方面，批量归一化是一种用于提高学习算法稳定性的技术。详细信息请参见附录
    [C](#A3 "附录 C 批量归一化 ‣ 星团分类的深度迁移学习：I. 应用于 PHANGS-HST 调查")。
- en: Finally, following deep learning best practices, we quantify the variance in
    classification performance of our models by training them ten times independently
    and then presenting the mean accuracies and the corresponding standard deviations.
    We also compute the Shannon entropy  Shannon ([1948](#bib.bib55)) of the output
    distribution over the four star cluster classes to quantify the uncertainty in
    each individual neural network model’s prediction.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，按照深度学习的最佳实践，我们通过独立训练模型十次来量化模型在分类性能上的方差，然后展示平均准确率和相应的标准差。我们还计算了输出分布在四个星团类别上的
    Shannon 熵 Shannon ([1948](#bib.bib55))，以量化每个单独神经网络模型预测的不确定性。
- en: 3.4 Training Experiments
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 训练实验
- en: 'We perform a series of experiments to test how the accuracy of the neural network
    model for predicting the morphological classification of candidate star clusters
    depends on the following characteristics of the training sample:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一系列实验，以测试神经网络模型在预测候选星团的形态分类时对以下训练样本特征的准确性依赖情况：
- en: '1.'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'origin of classifications: primarily classified by BCW (Table [1](#S2.T1 "Table
    1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey")) or the mode of 3 LEGUS classifiers (Table [2](#S2.T2
    "Table 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey"))'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分类来源：主要由 BCW (表 [1](#S2.T1 "表 1 ‣ 2.1 分类的一致性 ‣ 2 邻近星系中紧凑星团的分类 ‣ 星团分类的深度迁移学习：I.
    应用于 PHANGS-HST 调查")) 或 3 个 LEGUS 分类器的模式 (表 [2](#S2.T2 "表 2 ‣ 2.1 分类的一致性 ‣ 2 邻近星系中紧凑星团的分类
    ‣ 星团分类的深度迁移学习：I. 应用于 PHANGS-HST 调查")) 进行分类
- en: '2.'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'size of images used for training: 25p x 25p, 50p x 50p, 100p x 100p'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用于训练的图像大小：25p x 25p、50p x 50p、100p x 100p
- en: '3.'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'imaging filters: NUV, U, B, V, I'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 成像滤波器：NUV、U、B、V、I
- en: 'Transfer learning is used to train the neural network models using a random
    selection of 80% of the samples described in Table [1](#S2.T1 "Table 1 ‣ 2.1 Consistency
    among Classifications ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey") and Table [2](#S2.T2 "Table 2 ‣ 2.1 Consistency among Classifications
    ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey")
    separately, and the remaining 20% are reserved for validation. In total, this
    results in training samples of about 1000, 800, 600, and 1700 class 1, 2, 3, 4
    objects primarily classified by BCW, and about 1400, 1800, 1800, 3900 objects
    with LEGUS consensus classifications.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '使用迁移学习训练神经网络模型，样本随机选择了表格 [1](#S2.T1 "Table 1 ‣ 2.1 Consistency among Classifications
    ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey")
    和表格 [2](#S2.T2 "Table 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification
    of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey") 中描述的80%的样本，剩余20%用于验证。总的来说，这导致了大约1000、800、600和1700个类别1、2、3、4的对象的训练样本，这些对象主要由BCW分类，还有大约1400、1800、1800、3900个对象根据LEGUS共识分类。'
- en: \color
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: \color
- en: black
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 黑色
- en: Absolute values of pixels are rescaled to be in the range [0, 1], to avoid the
    brightness of the sources from becoming a parameter in the classification. During
    training we use several standard data augmentation strategies, such as random
    flips, and random rotations in the range [$0,\,2\pi$] to make sure that the trained
    neural networks are robust against those transformations. Taking into account
    the batch size mentioned above for ResNet18 and VGG19-BN, and bearing in mind
    that we trained the models using about 10,000 batches, this means that the nets
    were exposed to 320,000 and 160,000 images, respectively. Note, however, that
    the data augmentation techniques used during the training stage may produce very
    similar images to the actual star cluster images curated for this analysis.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 像素的绝对值被重新缩放到[0, 1]的范围内，以避免源的亮度成为分类中的一个参数。在训练过程中，我们使用了几种标准的数据增强策略，如随机翻转和范围为[$0,\,2\pi$]的随机旋转，以确保训练的神经网络对这些变换具有鲁棒性。考虑到上述ResNet18和VGG19-BN的批量大小，并且我们训练了约10,000批次，这意味着网络分别暴露于320,000和160,000张图像。然而，请注意，在训练阶段使用的数据增强技术可能会产生与实际星团图像非常相似的图像，这些图像是为此分析而精心整理的。
- en: 'To investigate whether networks trained in this manner can be used to automate
    classification of star clusters in the PHANGS-HST dataset in the future, we test
    the networks on the first observations obtained by PHANGS-HST of the spiral galaxy
    NGC 1559. The PHANGS-HST NGC1559 observations provide 302, 252, 162, and 710 class
    1, 2, 3, 4 objects, as classified by BCW (Table [1](#S2.T1 "Table 1 ‣ 2.1 Consistency
    among Classifications ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey")).'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '为了研究以这种方式训练的网络是否可以用于未来自动化分类PHANGS-HST数据集中星团的任务，我们在PHANGS-HST首次观测到的螺旋星系NGC 1559上测试这些网络。PHANGS-HST
    NGC1559观测提供了302、252、162和710个类别1、2、3、4的对象，由BCW分类（表格 [1](#S2.T1 "Table 1 ‣ 2.1 Consistency
    among Classifications ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey")）。'
- en: 4 Results
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结果
- en: We present four sets of results in this section.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中我们展示了四组结果。
- en: 'In Section [4.1](#S4.SS1 "4.1 Does prediction accuracy depend on the origin
    of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey"), we present the classification
    accuracy for the four categories of star clusters candidates relative to classifications
    primarily determined by BCW and those based on the mode of classifications performed
    by three LEGUS team members. We also present the uncertainty quantification analysis
    of those models (i.e., due to random weight initialization).'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '在第 [4.1](#S4.SS1 "4.1 Does prediction accuracy depend on the origin of the
    classifications? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")节中，我们展示了四类星团候选对象的分类准确性，相对于主要由BCW确定的分类和基于三名LEGUS团队成员进行的分类模式的分类。我们还展示了这些模型的不确定性量化分析（即，由于随机权重初始化）。'
- en: 'In Section [4.2](#S4.SS2 "4.2 How accurately can the models predict classifications
    for clusters in galaxies not included in the training sample? ‣ 4 Results ‣ Deep
    Transfer Learning for Star Cluster Classification: I. Application to the PHANGS-HST
    Survey"), we quantify the robustness of our neural network models to generalize
    to star cluster images in different galaxies, choosing the PHANGS-HST observations
    of NGC 1559 as the driver of this exercise as discussed above.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[4.2节](#S4.SS2 "4.2 模型在多大程度上能够准确预测未包含在训练样本中的星系中的星团的分类？ ‣ 4 结果 ‣ 星团分类的深度迁移学习：I.
    应用于PHANGS-HST调查")中，我们量化了我们的神经网络模型在将星团图像推广到不同星系中的鲁棒性，选择NGC 1559的PHANGS-HST观测作为此练习的驱动因素，如上文所讨论。
- en: 'In Section [4.3](#S4.SS3 "4.3 How does classification accuracy depend on size
    of training images? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey"), we report on whether the classification
    accuracy depends on the size of the images used for network training.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[4.3节](#S4.SS3 "4.3 分类准确性如何依赖于训练图像的大小？ ‣ 4 结果 ‣ 星团分类的深度迁移学习：I. 应用于PHANGS-HST调查")中，我们报告了分类准确性是否依赖于用于网络训练的图像大小。
- en: 'In Section [4.4](#S4.SS4 "4.4 Classification accuracy as a function of imaging
    filter ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey"), we report on relative importance of different
    filters for image classification in our resulting deep learning models.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[4.4节](#S4.SS4 "4.4 分类准确度与成像滤镜的函数 ‣ 4 结果 ‣ 星团分类的深度迁移学习：I. 应用于PHANGS-HST调查")中，我们报告了不同滤镜在我们结果深度学习模型中的图像分类的相对重要性。
- en: 4.1 Does prediction accuracy depend on the origin of the classifications?
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 预测准确性是否依赖于分类的来源？
- en: It is often useful to approach a problem using multiple methods to check how
    sensitive the results are to the chosen method. For example, the use of both ResNet18
    and VGG19-BN architectures in this paper allows us to see which one provides better
    results, but as we will show below, the results are quite robust no matter which
    is used. We use a similar strategy in this section by examining the results from
    training using two different classification samples, namely the BCW sample (see
    Table 1) and the LEGUS-consensus (3 classifiers) sample (see Table 2). While the
    BCW sample might be expected to have greater internal self-consistency since it
    was performed by a single experienced classifier, averaging the results of three
    less-experienced classifiers might be expected to reduce the random noise. Hence
    it is not obvious which approach might give better results in this pilot project.
    In the long run, the development of a much larger standardized database using
    a full range of experienced classifiers, as discussed in Section 5, may be required
    to make significant improvements.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，使用多种方法来检查结果对所选方法的敏感性是有用的。例如，本文中同时使用ResNet18和VGG19-BN架构，使我们能够查看哪种架构提供了更好的结果，但正如我们将下面展示的，无论使用哪种架构，结果都是相当稳健的。在本节中，我们采用类似的策略，通过检查使用两种不同分类样本（即BCW样本（见表1）和LEGUS-consensus（三个分类器）样本（见表2））的训练结果来进行分析。虽然BCW样本可能由于由单个经验丰富的分类器执行而具有更大的内部自洽性，但平均三名经验较少的分类器的结果可能会减少随机噪声。因此，在这个试点项目中，哪种方法可能会提供更好的结果并不明显。从长远来看，可能需要开发一个使用全范围经验分类器的大型标准化数据库，如第5节讨论的那样，以实现显著改进。
- en: 'First, we quantify the performance of our models for classification accuracy
    when we fine-tune the models to determine whether the transfer learning was effective
    at learning the morphological features that tell apart the four classes of star
    clusters, and to assess the robustness of the optimization procedure for image
    classification. As described above, to fine-tune the models pre-trained with the
    ImageNet dataset, the weights of the last layers and the last fully connected
    layers of the VGG19-BN and ResNet18 models are randomly initialized. The process
    is performed separately for the datasets described in Tables [1](#S2.T1 "Table
    1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey") and  [2](#S2.T2 "Table 2 ‣ 2.1 Consistency
    among Classifications ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey") to examine the dependence of the results on the origin of
    the classifications. \colorblack'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们量化了模型在分类准确性方面的表现，以确定在微调模型时迁移学习是否有效地学习了区分四类星团的形态特征，并评估优化过程在图像分类中的稳健性。如上所述，为了微调用ImageNet数据集预训练的模型，VGG19-BN和ResNet18模型的最后几层和最后的全连接层的权重被随机初始化。该过程分别对表[1](#S2.T1
    "表 1 ‣ 2.1 分类一致性 ‣ 2 邻近星系中的紧致星团分类 ‣ 星团分类的深度迁移学习：I. 应用于PHANGS-HST调查")和表[2](#S2.T2
    "表 2 ‣ 2.1 分类一致性 ‣ 2 邻近星系中的紧致星团分类 ‣ 星团分类的深度迁移学习：I. 应用于PHANGS-HST调查")中描述的数据集进行，以检查结果对分类来源的依赖性。\colorblack
- en: 'The results based on training with classifications primarily determined by
    BCW are presented in the top row of confusion matrices in Figure [3](#S4.F3 "Figure
    3 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey"), for both the ResNet18 and VGG19-BN models, with mean
    classification accuracy taken as the average over ten individual trainings from
    scratch. As a reminder, the reported accuracies are based on classification of
    a random set of 20% of the overall sample that was not included in the training
    (the "validation" sample). Likewise, the results based on training with the mode
    of classifications performed by three LEGUS team members are presented in the
    bottom row in Figure [3](#S4.F3 "Figure 3 ‣ 4.1 Does prediction accuracy depend
    on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for
    Star Cluster Classification: I. Application to the PHANGS-HST Survey").\colorblack'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 基于以BCW确定的分类进行训练的结果呈现在图[3](#S4.F3 "图 3 ‣ 4.1 预测准确性是否依赖于分类来源？ ‣ 4 结果 ‣ 星团分类的深度迁移学习：I.
    应用于PHANGS-HST调查")中混淆矩阵的顶部行，适用于ResNet18和VGG19-BN模型，平均分类准确率是基于十次从头开始训练的平均值。需要提醒的是，报告的准确率基于未包含在训练中的总体样本的20%随机集合（即“验证”样本）。同样，基于三名LEGUS团队成员进行分类模式的训练结果呈现在图[3](#S4.F3
    "图 3 ‣ 4.1 预测准确性是否依赖于分类来源？ ‣ 4 结果 ‣ 星团分类的深度迁移学习：I. 应用于PHANGS-HST调查")的底部行。\colorblack
- en: 'The main result is that the classification accuracies for the validation samples
    are comparable for both ResNet18 and VGG19-BN networks, as well as for both training
    samples. Reading along the diagonal of the confusion matrices presented in Figure [3](#S4.F3
    "Figure 3 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey"), for the models trained on the objects primarily classified
    by BCW, the accuracies for ResNet18 are 76%, 58%, 60%, 71% for class 1, 2 ,3,
    and 4 objects respectively, and 71%, 64%, 60%, 69% for VGG19-BN. Similarly, for
    the networks trained on the mode of classifications performed by three LEGUS members
    the accuracies are 78%, 54%, 58%, 66% for ResNet18 and 76%, 54%, 57%, 69% for
    VGG19-BN. This provides evidence that our proof-of-concept neural network models
    are resilient to the choice of data used for training and validation despite the
    fact that the two samples were (i) labelled by different classifiers; and (ii)
    include different parent galaxies at a wide range of distances (4-10 Mpc for the
    objects primarily classified by BCW, and 4-18 Mpc for the sample with LEGUS consensus
    classifications.) Our findings indicate that notwithstanding these seemingly important
    differences, the prediction accuracies using these two independent datasets are
    fairly consistent. \colorblack'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '主要结果是验证样本的分类准确率对于ResNet18和VGG19-BN网络以及训练样本都具有可比性。参见图中的混淆矩阵对角线[3](#S4.F3 "Figure
    3 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey")，对于主要由BCW分类的对象训练的模型，ResNet18在1、2、3和4类对象上的准确率分别为76%、58%、60%、71%，而VGG19-BN则为71%、64%、60%、69%。类似地，对于由三名LEGUS成员执行的分类模式训练的网络，ResNet18的准确率为78%、54%、58%、66%，VGG19-BN为76%、54%、57%、69%。这表明我们的概念验证神经网络模型在训练和验证所用数据的选择上具有鲁棒性，尽管这两个样本（i）由不同的分类器标记；（ii）包括在不同距离范围（主要由BCW分类的对象为4-10
    Mpc，LEGUS共识分类样本为4-18 Mpc）内的不同母星系。我们的研究结果表明，尽管这些看似重要的差异，使用这两个独立数据集的预测准确率仍然相当一致。
    \colorblack'
- en: 'The variance in the ten independent classification measurements provide measure
    of the robustness of the models. The variances for our neural network models trained
    on the classifications primarily determined by BCW are given in Tables [4](#S4.T4
    "Table 4 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey") and [5](#S4.T5 "Table 5 ‣ 4.1 Does prediction accuracy
    depend on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning
    for Star Cluster Classification: I. Application to the PHANGS-HST Survey"). In
    all cases, the variances are between 4-8%. The variances for LEGUS classifications
    are comparable.\colorblack'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '十次独立分类测量中的方差提供了模型鲁棒性的度量。我们基于BCW主要确定的分类训练的神经网络模型的方差见表[4](#S4.T4 "Table 4 ‣ 4.1
    Does prediction accuracy depend on the origin of the classifications? ‣ 4 Results
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey")和[5](#S4.T5 "Table 5 ‣ 4.1 Does prediction accuracy depend
    on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for
    Star Cluster Classification: I. Application to the PHANGS-HST Survey")。在所有情况下，方差均在4-8%之间。LEGUS分类的方差也具有可比性。
    \colorblack'
- en: '![Refer to caption](img/4567db5f268c49e76d55f8f3546a4bcd.png) ![Refer to caption](img/caea1fb11003ed8e590943ffdbc42bae.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4567db5f268c49e76d55f8f3546a4bcd.png) ![参见说明](img/caea1fb11003ed8e590943ffdbc42bae.png)'
- en: '![Refer to caption](img/52df57ef2c562900a2ce06c66f22c50b.png) ![Refer to caption](img/b9768b5c417d5332624be7df6a18ee36.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/52df57ef2c562900a2ce06c66f22c50b.png) ![参见说明](img/b9768b5c417d5332624be7df6a18ee36.png)'
- en: 'Figure 3: Top panels: Prediction, averaged over 10 models, of ResNet18 (left)
    and VGG19-BN (right) trained on 80% of the data described in Table [1](#S2.T1
    "Table 1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey") and then tested on 20% of the data reserved
    for validation testing and not used for training. Note that in these confusion
    matrices each column corresponds to a predicted class, whereas each row corresponds
    to an actual class. Correct classification results are given along the diagonal
    from the top left to bottom-right of the matrices. The color bar indicates the
    number of evaluation images used. Bottom panels: Same as top panels, but for data
    in Table [2](#S2.T2 "Table 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification
    of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey").'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：上部面板：对 ResNet18（左）和 VGG19-BN（右）的预测，平均了 10 个模型，使用了表 [1](#S2.T1 "表 1 ‣ 2.1
    分类的一致性 ‣ 2 对近邻星系中紧凑型恒星团的分类 ‣ 恒星团分类的深度迁移学习：I. 应用于 PHANGS-HST 调查") 中描述的 80% 数据，然后在
    20% 数据上进行验证测试，这些数据未用于训练。请注意，在这些混淆矩阵中，每一列对应一个预测类别，而每一行对应一个实际类别。正确分类的结果沿着矩阵从左上角到右下角的对角线给出。颜色条表示使用的评估图像数量。下部面板：与上部面板相同，但数据来源于表 [2](#S2.T2
    "表 2 ‣ 2.1 分类的一致性 ‣ 2 对近邻星系中紧凑型恒星团的分类 ‣ 恒星团分类的深度迁移学习：I. 应用于 PHANGS-HST 调查")。
- en: '![Refer to caption](img/994a383b574e29ecc085681f023f9650.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/994a383b574e29ecc085681f023f9650.png)'
- en: '![Refer to caption](img/e724f62daf93f6c6d5cef9e77312dc96.png) ![Refer to caption](img/9e670a0de98e8afffd1cf471310d6623.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e724f62daf93f6c6d5cef9e77312dc96.png) ![参见说明](img/9e670a0de98e8afffd1cf471310d6623.png)'
- en: '![Refer to caption](img/07cd97af1a900a867b6cb1d3a45cd335.png) ![Refer to caption](img/e015af6d693f9c230bc8c34589ff8bdb.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/07cd97af1a900a867b6cb1d3a45cd335.png) ![参见说明](img/e015af6d693f9c230bc8c34589ff8bdb.png)'
- en: 'Figure 4: Top panels: Same as Figure [3](#S4.F3 "Figure 3 ‣ 4.1 Does prediction
    accuracy depend on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey"),
    but now the models trained on the classifications primarily determined by BCW
    (Table [1](#S2.T1 "Table 1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification
    of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey")) are applied
    to predict classifications for candidates in PHANGS-HST observations of NGC 1559,
    a galaxy which was not included in the training samples. As before, results were
    obtained after averaging over 10 models. Bottom panels: Same as top row, but for
    models trained on the mode of classifications performed by three LEGUS team members
    (Table [2](#S2.T2 "Table 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification
    of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey")).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：上部面板：与图 [3](#S4.F3 "图 3 ‣ 4.1 预测准确性是否取决于分类的来源？ ‣ 4 结果 ‣ 恒星团分类的深度迁移学习：I.
    应用于 PHANGS-HST 调查") 相同，但现在训练模型主要由 BCW 确定的分类（表 [1](#S2.T1 "表 1 ‣ 2.1 分类的一致性 ‣ 2
    对近邻星系中紧凑型恒星团的分类 ‣ 恒星团分类的深度迁移学习：I. 应用于 PHANGS-HST 调查")）用于预测 PHANGS-HST 观察中的 NGC
    1559 候选者的分类，该星系未包括在训练样本中。与之前一样，结果是在 10 个模型上进行平均后获得的。下部面板：与上部面板相同，但针对由三名 LEGUS
    团队成员执行的分类模式训练的模型（表 [2](#S2.T2 "表 2 ‣ 2.1 分类的一致性 ‣ 2 对近邻星系中紧凑型恒星团的分类 ‣ 恒星团分类的深度迁移学习：I.
    应用于 PHANGS-HST 调查")）。
- en: '|  | Class 1 [%] | Class 2 [%] | Class 3 [%] | Class 4 [%] | Total |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '|  | 类别 1 [%] | 类别 2 [%] | 类别 3 [%] | 类别 4 [%] | 总计 |'
- en: '| BCW Class 1 | 76.0$\pm$ 4.2 | 17.9$\pm$ 4.4 | 1.7$\pm$0.7 | 4.4$\pm$1.4 |
    254 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 1 | 76.0$\pm$ 4.2 | 17.9$\pm$ 4.4 | 1.7$\pm$0.7 | 4.4$\pm$1.4 | 254
    |'
- en: '| BCW Class 2 | 19.4 $\pm$3.5 | 58.2$\pm$5.3 | 7.9$\pm$3.5 | 14.6$\pm$3.0 |
    202 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 2 | 19.4 $\pm$3.5 | 58.2$\pm$5.3 | 7.9$\pm$3.5 | 14.6$\pm$3.0 | 202
    |'
- en: '| BCW Class 3 | 0.3 $\pm$0.5 | 16.3$\pm$5.4 | 59.9$\pm$6.8 | 23.4$\pm$5.6 |
    147 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 3 | 0.3 $\pm$0.5 | 16.3$\pm$5.4 | 59.9$\pm$6.8 | 23.4$\pm$5.6 | 147
    |'
- en: '| BCW Class 4 | 7.0$\pm$2.1 | 6.9$\pm$2.9 | 15.2$\pm$3.1 | 70.9$\pm$4.8 | 425
    |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 4 | 7.0$\pm$2.1 | 6.9$\pm$2.9 | 15.2$\pm$3.1 | 70.9$\pm$4.8 | 425
    |'
- en: 'Table 4: Prediction of ResNet18 on 20% of the data in Table [1](#S2.T1 "Table
    1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey") reserved for validation testing and not
    included in the training, averaged over 10 models. The averaged predictions from
    Figure [3](#S4.F3 "Figure 3 ‣ 4.1 Does prediction accuracy depend on the origin
    of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey") are repeated, but now
    the standard deviations are also shown. The number of validation images for each
    class are listed in the final column. \colorblack'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：ResNet18在表 [1](#S2.T1 "表 1 ‣ 2.1 分类一致性 ‣ 2 临近星系中紧凑星团的分类 ‣ 深度迁移学习用于星团分类：I.
    应用于PHANGS-HST调查")中20%的数据上的预测结果，这些数据保留用于验证测试，未包含在训练中，数据来源于10个模型的平均值。图 [3](#S4.F3
    "图 3 ‣ 4.1 预测准确性是否依赖于分类的来源？ ‣ 4 结果 ‣ 深度迁移学习用于星团分类：I. 应用于PHANGS-HST调查")中的平均预测结果已重复，但现在也显示了标准偏差。每个类别的验证图像数量列在最后一列中。
    \colorblack
- en: '|  | Class 1 [%] | Class 2 [%] | Class 3 [%] | Class 4 [%] | Total |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '|  | 类别 1 [%] | 类别 2 [%] | 类别 3 [%] | 类别 4 [%] | 总计 |'
- en: '| BCW Class 1 | 70.9$\pm$6.2 | 23.0$\pm$4.8 | 1.1$\pm$0.7 | 5.0$\pm$1.9 | 254
    |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 1 | 70.9$\pm$6.2 | 23.0$\pm$4.8 | 1.1$\pm$0.7 | 5.0$\pm$1.9 | 254
    |'
- en: '| BCW Class 2 | 13.3$\pm$4.3 | 63.8$\pm$4.8 | 9.4$\pm$2.9 | 13.6$\pm$3.6 |
    202 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 2 | 13.3$\pm$4.3 | 63.8$\pm$4.8 | 9.4$\pm$2.9 | 13.6$\pm$3.6 | 202
    |'
- en: '| BCW Class 3 | 0.5$\pm$0.7 | 14.0$\pm$6.3 | 59.8$\pm$7.5 | 25.6$\pm$7.4 |
    147 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 3 | 0.5$\pm$0.7 | 14.0$\pm$6.3 | 59.8$\pm$7.5 | 25.6$\pm$7.4 | 147
    |'
- en: '| BCW Class 4 | 6.5$\pm$2.4 | 8.1$\pm$2.6 | 16.3$\pm$3.8 | 69.1$\pm$6.8 | 425
    |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 4 | 6.5$\pm$2.4 | 8.1$\pm$2.6 | 16.3$\pm$3.8 | 69.1$\pm$6.8 | 425
    |'
- en: 'Table 5: As Table [4](#S4.T4 "Table 4 ‣ 4.1 Does prediction accuracy depend
    on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for
    Star Cluster Classification: I. Application to the PHANGS-HST Survey"), but now
    using VGG19-BN.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：与表 [4](#S4.T4 "表 4 ‣ 4.1 预测准确性是否依赖于分类的来源？ ‣ 4 结果 ‣ 深度迁移学习用于星团分类：I. 应用于PHANGS-HST调查")类似，但现在使用的是VGG19-BN。
- en: '|  | Class 1 [%] | Class 2 [%] | Class 3 [%] | Class 4 [%] | Total |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '|  | 类别 1 [%] | 类别 2 [%] | 类别 3 [%] | 类别 4 [%] | 总计 |'
- en: '| BCW Class 1 | 72.8$\pm$ 7.6 | 11.2$\pm$ 3.8 | 1.4$\pm$0.6 | 14.6$\pm 5.1$
    | 302 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 1 | 72.8$\pm$ 7.6 | 11.2$\pm$ 3.8 | 1.4$\pm$0.6 | 14.6$\pm 5.1$ |
    302 |'
- en: '| BCW Class 2 | 23.8$\pm$4.3 | 38.1$\pm$5.9 | 9.0$\pm$4.0 | 29.2$\pm$4.7 |
    252 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 2 | 23.8$\pm$4.3 | 38.1$\pm$5.9 | 9.0$\pm$4.0 | 29.2$\pm$4.7 | 252
    |'
- en: '| BCW Class 3 | 1.0$\pm$0.5 | 9.8$\pm$4.2 | 40.1$\pm$7.1 | 49.1$\pm$6.1 | 162
    |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 3 | 1.0$\pm$0.5 | 9.8$\pm$4.2 | 40.1$\pm$7.1 | 49.1$\pm$6.1 | 162
    |'
- en: '| BCW Class 4 | 4.6$\pm$1.4 | 6.5$\pm$1.8 | 14.1$\pm$3.1 | 74.8$\pm$3.5 | 710
    |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 4 | 4.6$\pm$1.4 | 6.5$\pm$1.8 | 14.1$\pm$3.1 | 74.8$\pm$3.5 | 710
    |'
- en: 'Table 6: Prediction of ResNet18 trained on star clusters primarily classified
    by BCW (Table [1](#S2.T1 "Table 1 ‣ 2.1 Consistency among Classifications ‣ 2
    Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning
    for Star Cluster Classification: I. Application to the PHANGS-HST Survey")) for
    candidates in spiral galaxy NGC 1559 from the PHANGS-HST program, averaged over
    10 models. Each row shows the averaged predictions (same as shown in top left
    panel of Figure [4](#S4.F4 "Figure 4 ‣ 4.1 Does prediction accuracy depend on
    the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey")), but now together
    with the standard deviations from the 10 models. The numbers of objects classified
    are given in the last column. This experiment was performed to test the ability
    of this neural network model to generalize to images from galaxies not included
    in the training sample. It is notable that NGC 1559 is roughly twice as far away
    as any of galaxies in the BCW training sample.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：ResNet18在主要由BCW分类的星团（表 [1](#S2.T1 "表 1 ‣ 2.1 分类一致性 ‣ 2 临近星系中紧凑星团的分类 ‣ 深度迁移学习用于星团分类：I.
    应用于PHANGS-HST调查")）上对PHANGS-HST项目中的螺旋星系NGC 1559的候选对象进行的预测，数据来源于10个模型的平均值。每行显示了平均预测结果（与图 [4](#S4.F4
    "图 4 ‣ 4.1 预测准确性是否依赖于分类的来源？ ‣ 4 结果 ‣ 深度迁移学习用于星团分类：I. 应用于PHANGS-HST调查")左上面板中的结果相同），但现在也包含了10个模型的标准偏差。分类的对象数量列在最后一列中。此实验旨在测试该神经网络模型对未包含在训练样本中的星系图像的泛化能力。值得注意的是，NGC
    1559的距离大约是BCW训练样本中任何星系的两倍。
- en: '|  | Class 1 [%] | Class 2 [%] | Class 3 [%] | Class 4 [%] | Total |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '|  | 类别 1 [%] | 类别 2 [%] | 类别 3 [%] | 类别 4 [%] | 总计 |'
- en: '| BCW Class 1 | 73.8$\pm$4.8 | 10.4$\pm$3.5 | 3.1$\pm$1.3 | 12.7$\pm$4.4 |
    302 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 1 | 73.8$\pm$4.8 | 10.4$\pm$3.5 | 3.1$\pm$1.3 | 12.7$\pm$4.4 | 302
    |'
- en: '| BCW Class 2 | 20.9$\pm$6.4 | 42.3$\pm$7.9 | 13.3$\pm$2.6 | 23.5$\pm$8.0 |
    252 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 2 | 20.9$\pm$6.4 | 42.3$\pm$7.9 | 13.3$\pm$2.6 | 23.5$\pm$8.0 | 252
    |'
- en: '| BCW Class 3 | 0.7$\pm$0.6 | 8.3$\pm$3.3 | 52.2$\pm$5.9 | 38.9$\pm$7.5 | 162
    |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 3 | 0.7$\pm$0.6 | 8.3$\pm$3.3 | 52.2$\pm$5.9 | 38.9$\pm$7.5 | 162
    |'
- en: '| BCW Class 4 | 6.1$\pm$2.4 | 8.3$\pm$3.3 | 18.3$\pm$3.0 | 67.3$\pm$6.8 | 710
    |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| BCW 类别 4 | 6.1$\pm$2.4 | 8.3$\pm$3.3 | 18.3$\pm$3.0 | 67.3$\pm$6.8 | 710
    |'
- en: 'Table 7: As Table [6](#S4.T6 "Table 6 ‣ 4.1 Does prediction accuracy depend
    on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for
    Star Cluster Classification: I. Application to the PHANGS-HST Survey"), but now
    using VGG19-BN.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 表7：如表[6](#S4.T6 "表 6 ‣ 4.1 预测准确性是否依赖于分类来源？ ‣ 4 结果 ‣ 深度迁移学习应用于星团分类：I. 应用到PHANGS-HST调查")所示，但现在使用VGG19-BN。
- en: 4.2 How accurately can the models predict classifications for clusters in galaxies
    not included in the training sample?
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 模型对训练样本中未包含的星系中的星团分类预测的准确性如何？
- en: 'To further assess the robustness and resilience of our neural network models,
    we use them to classify images from a galaxy not included in the original training
    dataset, namely the PHANGS-HST target NGC 1559\. This galaxy is about two to four
    times further away than the galaxies in either of the training samples, with the
    notable exception of NGC1566, which is at a comparable distance to NGC 1559 (18
    Mpc vs. 19 Mpc), and included the sample with consensus classifications from three
    LEGUS team members (Table [2](#S2.T2 "Table 2 ‣ 2.1 Consistency among Classifications
    ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey")).
    Results are presented in Figure [4](#S4.F4 "Figure 4 ‣ 4.1 Does prediction accuracy
    depend on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning
    for Star Cluster Classification: I. Application to the PHANGS-HST Survey") and
    Tables [6](#S4.T6 "Table 6 ‣ 4.1 Does prediction accuracy depend on the origin
    of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey") and [7](#S4.T7 "Table
    7 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey").'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步评估我们神经网络模型的鲁棒性和弹性，我们将它们用于对一个不包含在原始训练数据集中的星系图像进行分类，即PHANGS-HST目标NGC 1559。这个星系距离我们约为训练样本中星系的两到四倍远，特别是NGC1566，其距离与NGC
    1559相当（18 Mpc对比19 Mpc），并包含来自三位LEGUS团队成员的一致分类样本（表[2](#S2.T2 "表 2 ‣ 2.1 分类一致性 ‣
    2 临近星系中的紧凑星团分类 ‣ 深度迁移学习应用于星团分类：I. 应用到PHANGS-HST调查")）。结果展示在图[4](#S4.F4 "图 4 ‣ 4.1
    预测准确性是否依赖于分类来源？ ‣ 4 结果 ‣ 深度迁移学习应用于星团分类：I. 应用到PHANGS-HST调查")和表[6](#S4.T6 "表 6 ‣
    4.1 预测准确性是否依赖于分类来源？ ‣ 4 结果 ‣ 深度迁移学习应用于星团分类：I. 应用到PHANGS-HST调查")及[7](#S4.T7 "表
    7 ‣ 4.1 预测准确性是否依赖于分类来源？ ‣ 4 结果 ‣ 深度迁移学习应用于星团分类：I. 应用到PHANGS-HST调查")中。
- en: 'Notwithstanding these differences, we again notice that all models produce
    comparable results. Reading along the diagonal of the confusion matrices presented
    in Figure [4](#S4.F4 "Figure 4 ‣ 4.1 Does prediction accuracy depend on the origin
    of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey"), for the models trained
    on the objects primarily classified by BCW, the accuracies for ResNet18 are 73%,
    38%, 40%, 75% for class 1, 2 ,3, and 4 objects respectively, and 74%, 42%, 52%,
    67% for VGG19-BN. Likewise, for the networks trained on the mode of classifications
    performed by three LEGUS members the accuracies are 70%, 41%, 48%, 62% for ResNet18
    and 70%, 45%, 52%, 52% for VGG19-BN.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些差异，我们再次注意到所有模型产生的结果相似。阅读图[4](#S4.F4 "图 4 ‣ 4.1 预测准确性是否依赖于分类来源？ ‣ 4 结果
    ‣ 深度迁移学习应用于星团分类：I. 应用到PHANGS-HST调查")中展示的混淆矩阵对角线，对于主要由BCW分类的对象训练的模型，ResNet18在类别1、2、3和4的准确率分别为73%、38%、40%、75%，VGG19-BN的准确率分别为74%、42%、52%、67%。同样，对于由三位LEGUS成员进行分类模式训练的网络，ResNet18的准确率为70%、41%、48%、62%，而VGG19-BN的准确率为70%、45%、52%、52%。
- en: 'For all models, the performance for NGC1559 class 1 star clusters is at or
    above the 70% level. The classification accuracy of the BCW-based models is similar
    to their performance on the validation samples (i.e., Figure [3](#S4.F3 "Figure
    3 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey")). Meanwhile for NGC1559 class 1 star clusters the performance
    of the models trained on the LEGUS consensus classifications are 6-8% lower relative
    to the classification of the validation samples. On the other hand for class 2
    star clusters, the accuracies hover around the 40% level, and are the lowest of
    the four classes. The accuracies for the models trained on the objects primarily
    classified by BCW drop by $\sim$20%: from 58% (test subset sample) to 38% (NGC
    1559) for ResNet18, and from 64% to 42% for VGG19-BN. Similarly, those trained
    on the LEGUS consensus classifications drop, although by only $\sim$10%: from
    54% to 41% for ResNet18, and from 54% to 45% for VGG19-BN. The accuracies for
    the NGC 1559 class 3 star clusters are at the 40-50% level, a $\sim$10% drop for
    all models relative to the performance on the test subsets. Finally, for the class
    4 non-clusters, the models trained on the objects primarily classified by BCW
    perform comparably, i.e., at the 70% level, while those trained on the LEGUS consensus
    classifications drop to the 50-60% level.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '对于所有模型，NGC1559类1星团的表现都在70%水平或更高。基于BCW的模型的分类准确度与其在验证样本上的表现相似（即，[图 3](#S4.F3
    "Figure 3 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey")）。与此同时，对于NGC1559类1星团，基于LEGUS共识分类训练的模型的表现比验证样本的分类低6-8%。另一方面，对于类2星团，准确度在40%水平左右，是四类中最低的。基于BCW分类的对象训练的模型的准确度下降了约20%：ResNet18从58%（测试子集样本）下降到38%（NGC
    1559），VGG19-BN从64%下降到42%。类似地，基于LEGUS共识分类训练的模型准确度下降了约10%：ResNet18从54%下降到41%，VGG19-BN从54%下降到45%。NGC
    1559类3星团的准确度在40-50%水平，相对于测试子集的表现，所有模型的准确度下降了约10%。最后，对于类4非星团，基于BCW分类的对象训练的模型表现相当，即70%水平，而基于LEGUS共识分类的模型下降到50-60%水平。'
- en: \color
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: \color
- en: black
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: black
- en: 4.2.1 Uncertainty calculations through entropy analysis
  id: totrans-214
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1 通过熵分析进行的不确定性计算
- en: 'Another method to investigate the uncertainty in the models’ predictions is
    through the computation of entropy by using the probability distributions for
    each of the cluster classes we are trying to classify, which is an output of the
    models. Intuitively, the more pronounced the peak is in the probability distribution,
    the more confident the neural network is about its prediction, and in this case,
    the entropy calculated from the prediction probability distribution will be lower.
    For example, if the probability distribution is only concentrated on one class,
    the network network in this case is $100\%$ certain about its prediction and the
    entropy would be zero, i.e., there is no uncertainty. On the other hand, if the
    prediction assigned the same probability for all the 4 classes under consideration
    equally, we would have maximum uncertainty in this case, since for the given input
    image, all the 4 classes are equally possible to be the predicted classes, and
    in this case, the maximum entropy is $\ln(4)\approx 1.39$. Figure [5](#S4.F5 "Figure
    5 ‣ 4.2.1 Uncertainty calculations through entropy analysis ‣ 4.2 How accurately
    can the models predict classifications for clusters in galaxies not included in
    the training sample? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey") shows the distribution of the entropies
    for the predictions of VGG19-BN when tested on NGC 1559 images.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '另一种研究模型预测不确定性的方法是通过使用我们试图分类的每个星团类别的概率分布来计算熵，这些概率分布是模型的输出。直观地说，概率分布中的峰值越明显，神经网络对其预测的信心就越强，在这种情况下，从预测概率分布计算出的熵将会更低。例如，如果概率分布仅集中在一个类别上，网络在这种情况下对其预测有$100\%$的把握，熵将为零，即没有不确定性。另一方面，如果预测为所有4个类别分配相同的概率，我们将面临最大的不确定性，因为对于给定的输入图像，所有4个类别都有可能被预测，最大熵为$\ln(4)\approx
    1.39$。图[5](#S4.F5 "Figure 5 ‣ 4.2.1 Uncertainty calculations through entropy analysis
    ‣ 4.2 How accurately can the models predict classifications for clusters in galaxies
    not included in the training sample? ‣ 4 Results ‣ Deep Transfer Learning for
    Star Cluster Classification: I. Application to the PHANGS-HST Survey")显示了VGG19-BN在NGC
    1559图像上测试时预测熵的分布。'
- en: '![Refer to caption](img/873c50c72771e20d8ca75674048a0f8c.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/873c50c72771e20d8ca75674048a0f8c.png)'
- en: 'Figure 5: The uncertainty in the neural network’s prediction is quantified
    by the entropy of the predicted probability distribution over the 4 star cluster
    image classes considered in this analysis. For a random guess over the 4 classes,
    the entropy is $\ln(4)\approx 1.39$. The lower the entropy, the higher the confidence
    the neural network has about its prediction. The panel shows the predicted entropy
    value for each NGC1559 image with which we classified with our VGG19-BN model,
    trained on the objects primarily classified by BCW given in Table [1](#S2.T1 "Table
    1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey"). The x-axis shows the binned values of
    the entropy values, whose frequency of occurrence is indicated on the y-axis.
    To make clear that the area of each histogram is normalized to one, the y-axis
    label is explicitly labeled “Normalized distribution."'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '图5：神经网络预测的不确定性通过对4星团图像类别预测概率分布的熵进行量化。在4个类别的随机猜测中，熵为$\ln(4)\approx 1.39$。熵越低，神经网络对其预测的信心越高。面板显示了我们使用VGG19-BN模型对NGC1559图像进行分类的预测熵值，该模型在主要由BCW分类的对象上进行了训练，如表[1](#S2.T1
    "Table 1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")所示。x轴显示了熵值的分箱值，其出现频率在y轴上表示。为了明确每个直方图的面积标准化为1，y轴标签明确标记为“标准化分布”。'
- en: 4.3 How does classification accuracy depend on size of training images?
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 分类准确性如何依赖于训练图像的大小？
- en: 'To quantify the importance of image size for star cluster classification, we
    train our neural network models again, but with two additional cropping sizes:
    $25\times 25$ pixels and $100\times 100$ pixels. In Figure [6](#S4.F6 "Figure
    6 ‣ 4.3 How does classification accuracy depend on size of training images? ‣
    4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey"), we present results from training on the sample with
    LEGUS consensus classifications (again, where 80% of the sample is used for training
    and 20% for testing), where the results presented earlier from our fiducial experiments
    with $50\times 50$ pixels postage stamps are repeated to facilitate comparison.
    We present results based on the LEGUS consensus classifications as the range of
    distances of the galaxies (from 3.1 Mpc to 18 Mpc; Table [2](#S2.T2 "Table 2 ‣
    2.1 Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey")) is inclusive of the range spanned by the
    sample primarily classified by BCW (Table [1](#S2.T1 "Table 1 ‣ 2.1 Consistency
    among Classifications ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey")). Hence, the physical scales subtended by the cropped images
    span from 16 pc (for $25\times 25$ pixel images at 3.1 Mpc) to 360 pc (for $100\times
    100$ pixel images at 18 Mpc).'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '为了量化图像尺寸对星团分类的重要性，我们再次训练了神经网络模型，但使用了两个额外的裁剪尺寸：$25\times 25$像素和$100\times 100$像素。在图[6](#S4.F6
    "Figure 6 ‣ 4.3 How does classification accuracy depend on size of training images?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey")中，我们展示了使用LEGUS共识分类进行训练的样本的结果（同样，其中80%的样本用于训练，20%用于测试），这里重复了之前我们在$50\times
    50$像素邮票上的基准实验结果以便于比较。我们基于LEGUS共识分类的结果，因为这些银河的距离范围（从3.1 Mpc到18 Mpc；表[2](#S2.T2
    "Table 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")）包含了由BCW主要分类的样本跨度的范围（表[1](#S2.T1 "Table
    1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey")）。因此，裁剪图像的物理尺度从16 pc（对于3.1 Mpc下的$25\times
    25$像素图像）到360 pc（对于18 Mpc下的$100\times 100$像素图像）不等。'
- en: 'There are no significant differences between the results for the different
    cropping sizes. These results indicate that our neural network models are resilient
    to this particular data curation choice. We see variations at the level of $\sim
    5\%$, which is within the expected variation in the performance of the neural
    network models due to random weight initialization, as indicated in Tables [4](#S4.T4
    "Table 4 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey") and [5](#S4.T5 "Table 5 ‣ 4.1 Does prediction accuracy
    depend on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning
    for Star Cluster Classification: I. Application to the PHANGS-HST Survey"). Results
    for the models trained with objects primarily classified by BCW are consistent.
    The results also do not change if the neural network models are trained with postage
    stamps using random cropping sizes ranging from $25\times 25$ pixels to $100\times
    100$ pixels (i.e., a random cropping size is chosen for each object in the training
    and testing sample). \colorblack'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '对于不同裁剪尺寸的结果没有显著差异。这些结果表明我们的神经网络模型对这种特定的数据策划选择具有弹性。我们看到大约$\sim 5\%$的变化，这在神经网络模型由于随机权重初始化引起的性能预期变化范围内，如表[4](#S4.T4
    "Table 4 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey")和[5](#S4.T5 "Table 5 ‣ 4.1 Does prediction accuracy
    depend on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning
    for Star Cluster Classification: I. Application to the PHANGS-HST Survey")所示。使用BCW主要分类的对象训练的模型结果是一致的。如果使用随机裁剪尺寸（从$25\times
    25$像素到$100\times 100$像素）对邮票进行训练，结果也不会改变（即，每个训练和测试样本中的对象都选择一个随机裁剪尺寸）。\colorblack'
- en: '![Refer to caption](img/0f18d266dc234084f25231b6c865a674.png) ![Refer to caption](img/966dbc019b69e5408e72cad34a923152.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0f18d266dc234084f25231b6c865a674.png) ![参见说明](img/966dbc019b69e5408e72cad34a923152.png)'
- en: '![Refer to caption](img/939cd8d188af28dc728e52aebf5dbb41.png) ![Refer to caption](img/6118cbd4af29068569ce039eef4e8014.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/939cd8d188af28dc728e52aebf5dbb41.png) ![参见说明](img/6118cbd4af29068569ce039eef4e8014.png)'
- en: '![Refer to caption](img/c0e7355a71780e7f23fe90eb449fd76e.png) ![Refer to caption](img/d839ac299766c0e7797c63d205e6475d.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c0e7355a71780e7f23fe90eb449fd76e.png) ![参见说明](img/d839ac299766c0e7797c63d205e6475d.png)'
- en: 'Figure 6: Left column: VGG19-BN model classification results for cropping size
    $25\times 25$, $50\times 50$ and $100\times 100$. Right column: as before, but
    now for ResNet.\colorblack'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：左列：VGG19-BN模型在裁剪大小为$25\times 25$、$50\times 50$和$100\times 100$下的分类结果。右列：同样，但现在为ResNet。\colorblack
- en: 4.4 Classification accuracy as a function of imaging filter
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 分类准确率与成像滤镜的关系
- en: 'We have also quantified what filter has the leading contribution for classification
    accuracy. To do so, we perform the following experiment: using NGC 1559 images
    as testing dataset, we produced five different testing datasets in which one filter
    was set to zero. We then fed these 5 different testing datasets, one at a time,
    to our neural network models trained with objects primarily classified by BCW
    and quantified which missing filter leads to the most significant drop in classification
    accuracy. As shown in Figure [7](#S4.F7 "Figure 7 ‣ 4.4 Classification accuracy
    as a function of imaging filter ‣ 4 Results ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey"), the key filter
    is F555W.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '我们还量化了哪种滤镜对分类准确率的贡献最大。为此，我们进行了以下实验：使用NGC 1559图像作为测试数据集，我们生成了五个不同的测试数据集，其中一个滤镜被设为零。然后，我们将这5个不同的测试数据集逐一输入到我们的神经网络模型中，这些模型主要由BCW分类的对象进行训练，并量化哪个缺失的滤镜导致分类准确率的显著下降。如图 [7](#S4.F7
    "Figure 7 ‣ 4.4 Classification accuracy as a function of imaging filter ‣ 4 Results
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey")所示，关键滤镜是F555W。'
- en: This finding is expected, since the human classifications primarily rely on
    the F555W image (e.g., using DS9 and imexamine), with color images (F814, F555,
    F336W) generated by the Hubble Legacy Archive providing supporting morphological
    information. Therefore, our neural network models seem to use insights similar
    to human vision to classify star cluster images.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这一发现是预期中的，因为人类分类主要依赖于F555W图像（例如，使用DS9和imexamine），而由哈勃遗产档案提供的彩色图像（F814, F555,
    F336W）则提供了支持的形态信息。因此，我们的神经网络模型似乎使用了类似于人类视觉的洞察力来分类星团图像。
- en: '![Refer to caption](img/53812323f9d3f129d6f60271378e7676.png) ![Refer to caption](img/fec5c09d4b903d86740bbe3a8353db90.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/53812323f9d3f129d6f60271378e7676.png) ![参见说明](img/fec5c09d4b903d86740bbe3a8353db90.png)'
- en: '![Refer to caption](img/9e7ac5c384ea9008628c7ef6f6a17f5a.png) ![Refer to caption](img/590cf61fa2785c9a68ef68fcbc941965.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9e7ac5c384ea9008628c7ef6f6a17f5a.png) ![参见说明](img/590cf61fa2785c9a68ef68fcbc941965.png)'
- en: '![Refer to caption](img/cfa2d9e6d99291a656b6601bbd16c677.png) ![Refer to caption](img/c05a0135d0ec7b5406b671c1e0e49ff5.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/cfa2d9e6d99291a656b6601bbd16c677.png) ![参见说明](img/c05a0135d0ec7b5406b671c1e0e49ff5.png)'
- en: '![Refer to caption](img/e0b0b0d34793a8e81f48af5eba866894.png) ![Refer to caption](img/5c4a724cabf6dad2bae6a23d3720f294.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e0b0b0d34793a8e81f48af5eba866894.png) ![参见说明](img/5c4a724cabf6dad2bae6a23d3720f294.png)'
- en: '![Refer to caption](img/e7b5ee4fb8873ae8cd02bedd648d14a8.png) ![Refer to caption](img/a6574c8fb4caa47492e7eb0ff7c29687.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e7b5ee4fb8873ae8cd02bedd648d14a8.png) ![参见说明](img/a6574c8fb4caa47492e7eb0ff7c29687.png)'
- en: 'Figure 7: Left column: ResNet model classification results when the indicated
    filter is removed from the composite image. Right column: as before, but now for
    VGG19-BN. The greatest drop in the accuracies occurs when the V-band filter is
    removed.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：左列：当指示的滤镜从复合图像中移除时ResNet模型的分类结果。右列：同样，但现在为VGG19-BN。准确率的最大下降发生在V带滤镜被移除时。
- en: 5 Discussion & Conclusions
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 讨论与结论
- en: Using homogeneous datasets of human-labeled star cluster images from the Hubble
    Space Telescope, we have leveraged a new generation of neural network models and
    deep transfer learning techniques for morphological classification of compact
    star clusters in nearby galaxies to distances of $\sim$ 20 Mpc. These results
    are very promising.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 利用来自哈勃太空望远镜的同质化人类标记星团图像数据集，我们利用新一代神经网络模型和深度迁移学习技术对附近星系中紧凑星团的形态进行分类，距离达到约20 Mpc。这些结果非常有希望。
- en: '1.'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Through all of the experiments presented here with multiple training sweeps
    for each neural network model, we see that the classification accuracy is similar
    for both architectures studied: i.e., ResNet18 and VGG19-BN pre-trained with the
    ImageNet dataset where the weights of the last layers and the last fully connected
    layers are randomly initialized.'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过这里展示的所有实验，对于每个神经网络模型的多次训练循环，我们看到两种研究的架构：即ResNet18和VGG19-BN的分类准确率相似，这些模型在ImageNet数据集上进行了预训练，并且最后几层和最后的全连接层的权重是随机初始化的。
- en: '2.'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Somewhat surprisingly, the performance of the models is relatively robust to
    the origin of the human classifications used, the particular galaxies included
    in the training sample, and the cropping size of the training images (spanning
    physical sizes of 16pc to 360pc). Irrespective of whether the models are trained
    on a sample primarily classified by one expert (BCW) with galaxies at distances
    2-4 times closer than the star cluster candidates to be evaluated in PHANGS-HST
    galaxy NGC 1559; or trained on the mode of classifications from three individuals
    where the sample does includes a galaxy at a distance similar to NGC 1559; the
    results are comparable. The prediction accuracies for NGC 1559, which was not
    included in the training samples, are at the level of 70%:40%40-50% for the class
    1, 2, and 3 star clusters. However, the BCW-trained networks have a higher performance
    in classification of the class 4 non-clusters in NGC 1559 (70% vs. 50-60%). This
    might be expected since the classifications for NGC 1559 were also performed by
    BCW, and may be due to a higher level of self-consistency in the training and
    testing classification datasets.
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有些出乎意料的是，模型的性能对所使用的人类分类的来源、训练样本中包含的特定星系以及训练图像的裁剪大小（涵盖物理大小为16pc到360pc）相对稳健。无论模型是基于主要由一位专家（BCW）进行分类的样本进行训练（这些星系距离比待评估的PHANGS-HST星系NGC
    1559的距离近2-4倍），还是基于来自三位个体的分类模式进行训练，其中样本中包括了一个与NGC 1559距离相似的星系，结果都是可以比较的。NGC 1559的预测准确率，虽然未包含在训练样本中，达到了70%：40%40-50%的准确度，适用于第1、2和3类星团。然而，BCW训练的网络在NGC
    1559的第4类非星团分类中表现出更高的性能（70%对50-60%）。这可能是因为NGC 1559的分类也由BCW进行，可能由于训练和测试分类数据集中较高的自一致性。
- en: '3.'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Most importantly, despite training with relatively small datasets, the performance
    of the networks presented here is competitive with the consistency achieved in
    previous human and quantitative automated classification of the same star cluster
    candidate samples (Section [2.1](#S2.SS1 "2.1 Consistency among Classifications
    ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey")).
    Thus, this work provides a proof-of-concept demonstration that deep transfer learning
    can be successfully used to automate morphological classification of star cluster
    candidate samples using HST UV-optical imaging being obtained by PHANGS-HST.'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '最重要的是，尽管训练使用了相对较小的数据集，这里展示的网络性能与之前在相同星团候选样本的人类和定量自动分类中取得的一致性具有竞争力（第[2.1节](#S2.SS1
    "2.1 Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey")）。因此，这项工作提供了一个概念验证的展示，证明深度迁移学习可以成功用于自动化星团候选样本的形态分类，使用的是由PHANGS-HST获得的HST
    UV-光学成像。'
- en: \color
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: \color
- en: black
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 黑色
- en: This work represents a milestone in the use of deep transfer learning for this
    area of research, and represents progress from initial machine learning experiments
    described in Grasha et al. ([2019](#bib.bib30)) and also discussed in Messa et al.
    ([2018](#bib.bib47)). Grasha et al. ([2019](#bib.bib30)) experimented with the
    use of an ML algorithm for classifying the approximately eleven thousand clusters
    in the spiral galaxy M51, based on a human classified training set with $\sim$2500
    clusters from the LEGUS sample. While the recovery of class 1 and 2 clusters is
    fairly good (in the range 60 - 75 % in the Grasha and Messa studies, and comparable
    to the prediction accuracies presented here \colorblack) recovery of class 3 clusters
    is poor, with an apparently significant anti-correlation.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作代表了深度迁移学习在这一研究领域的一个里程碑，并且是从Grasha等（[2019](#bib.bib30)）描述的初始机器学习实验中取得的进展，也在Messa等（[2018](#bib.bib47)）中讨论过。Grasha等（[2019](#bib.bib30)）尝试使用一种ML算法对螺旋星系M51中的约一万一千个星团进行分类，基于一个由LEGUS样本中约2500个星团构成的人类标记训练集。尽管类别1和2的恢复效果相当好（在Grasha和Messa研究中在60%
    - 75%范围内，与此处展示的预测准确率相当），类别3的恢复效果较差，且似乎存在显著的反相关。
- en: To attempt to further improve upon the models presented here, future work will
    include training with the largest star cluster candidate sample possible (i.e.,
    combining all samples used for this proof-of-concept demonstration plus classifications
    for objects in several galaxies in PHANGS-HST). \colorblack Improvement in classification
    accuracy also requires the development of a standarized dataset of human-labelled
    star cluster classifications, with classifications agreed upon by a full range
    of experts in the field, to be used as the basis for future network training.
    This effort would benefit from a classification challenge, where experts can come
    to detailed agreement on the morphological features that constitute the criteria
    for classification (e.g., to establish full decision trees, such as those used
    for Galaxy Zoo by citizen scientists), \colorblack and explicitly describe where
    they disagree and why. A review of differences in star cluster definitions between
    research groups, and their possible impact on conclusions about star cluster formation
    and evolution, can be found in Krumholz et al. ([2018](#bib.bib42)). The ultimate
    goal is to use deep learning techniques to not only rapidly produce reliable classifications
    and speed the time to science, but to significantly advance the field of star
    cluster evolution. Given the discussion in Krumholz et al. ([2018](#bib.bib42)),
    this requires that deep learning networks are trained on such standardized datasets,
    broadly adopted by workers in the field.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步改进这里提出的模型，未来的工作将包括使用尽可能大的星团候选样本进行训练（即，结合所有用于此概念验证演示的样本以及PHANGS-HST中几个星系的对象分类）。**改进分类准确性**还需要开发一个标准化的人类标记星团分类数据集，该数据集应由该领域的全体专家达成一致，以作为未来网络训练的基础。这项工作将受益于分类挑战，在分类挑战中，专家们可以详细达成一致，明确分类标准（例如，建立完整的决策树，如公民科学家为银河动物园所用的），并明确描述他们的分歧及原因。关于研究小组之间星团定义差异及其对星团形成和演化结论可能影响的回顾，可以在Krumholz等（[2018](#bib.bib42)）中找到。**终极目标**是利用深度学习技术不仅快速产生可靠的分类结果并加速科学进程，还要显著推进星团演化领域。根据Krumholz等（[2018](#bib.bib42)）的讨论，这要求深度学习网络在这些标准化数据集上进行训练，并广泛被该领域的工作者采纳。
- en: With this study we open a new chapter to explore in earnest the use of deep
    transfer learning for the classification of very large datasets of star cluster
    galaxies in ongoing and future electromagnetic surveys, and application to the
    new PHANGS-HST data being obtained now.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这项研究，我们开启了一个新的篇章，认真探索深度迁移学习在对非常大规模星团星系数据集的分类中的应用，尤其是在进行中的和未来的电磁调查中，并应用于现在正在获得的新PHANGS-HST数据。
- en: Acknowledgements
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We thank the referee for feedback which significantly improved the paper, and
    in particular, motivated the expansion of our experiments to investigate potential
    differences in outcome when training with classifications by a single individual
    (BCW) versus using LEGUS consensus classifications from multiple individuals.
    Initially, our experiments were based solely on the classifications of BCW.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢评审的反馈，这些反馈显著提高了论文的质量，特别是激励了我们扩展实验，以调查在使用单一个体（BCW）与多个人员的 LEGUS 共识分类进行训练时，结果是否存在潜在差异。最初，我们的实验仅基于
    BCW 的分类。
- en: We also thank the LEGUS team, and in particular Daniela Calzetti and Kathryn
    Grasha, for their pioneering efforts in the field of classifying star clusters
    using machine learning techniques, and for making results available via the LEGUS
    public website. We thank Sean Linden for assisting BCW in classifications for
    star cluster candidates in NGC 3351, NGC 3627, and NGC 5457.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还感谢 LEGUS 团队，特别是 Daniela Calzetti 和 Kathryn Grasha，在使用机器学习技术对星团进行分类方面的开创性工作，并且感谢他们通过
    LEGUS 公众网站提供的结果。我们感谢 Sean Linden 协助 BCW 对 NGC 3351、NGC 3627 和 NGC 5457 的星团候选体进行分类。
- en: Based on observations made with the NASA/ESA Hubble Space Telescope, obtained
    from the data archive at the Space Telescope Science Institute. STScI is operated
    by the Association of Universities for Research in Astronomy, Inc. under NASA
    contract NAS 5-26555\. Support for Program number 15654 was provided through a
    grant from the STScI under NASA contract NAS5- 26555.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 基于使用 NASA/ESA 哈勃太空望远镜进行的观察，这些数据来自空间望远镜科学研究所的数据档案。STScI 由天文学研究大学协会运营，合同号 NAS
    5-26555。程序编号 15654 的支持来自于 STScI 的资助，合同号 NAS5-26555。
- en: This research has made use of the NASA/IPAC Extragalactic Database (NED) which
    is operated by the Jet Propulsion Laboratory, California Institute of Technology,
    under contract with NASA.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究使用了 NASA/IPAC 外星系数据库（NED），该数据库由加州理工学院喷气推进实验室运营，合同由 NASA 负责。
- en: EAH and WW gratefully acknowledge National Science Foundation (NSF) awards OAC-1931561
    and OAC-1934757.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: EAH 和 WW 感谢国家科学基金会（NSF）颁发的奖项 OAC-1931561 和 OAC-1934757。
- en: This research is part of the Blue Waters sustained-petascale computing project,
    which is supported by NSF awards OCI-0725070 and ACI-1238993, and the State of
    Illinois. Blue Waters is a joint effort of the University of Illinois at Urbana-Champaign
    and its National Center for Supercomputing Applications.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究是 Blue Waters 持续的超大规模计算项目的一部分，该项目由 NSF 奖项 OCI-0725070 和 ACI-1238993 以及伊利诺伊州政府支持。Blue
    Waters 是伊利诺伊大学厄本那-香槟分校及其国家超级计算应用中心的联合努力。
- en: This work utilized resources supported by the NSF’s Major Research Instrumentation
    program, grant OAC-1725729, as well as the University of Illinois at Urbana-Champaign.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作利用了由 NSF 主要研究仪器项目（资助号 OAC-1725729）以及伊利诺伊大学厄本那-香槟分校提供的资源。
- en: We are grateful to NVIDIA for donating several Tesla P100 and V100 GPUs that
    we used for our analysis, and the NSF grants NSF-1550514, NSF-1659702 and TG-PHY160053.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢 NVIDIA 赠送的几台 Tesla P100 和 V100 GPU，这些设备用于我们的分析，并感谢 NSF 的资助（NSF-1550514、NSF-1659702
    和 TG-PHY160053）。
- en: This research used resources of the Argonne Leadership Computing Facility, which
    is a DOE Office of Science User Facility supported under Contract DE-AC02-06CH11357\.
    We thank the [NCSA Gravity Group](http://gravity.ncsa.illinois.edu) for useful
    feedback.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究使用了阿贡领导计算设施的资源，这是由美国能源部科学办公室支持的用户设施，合同号 DE-AC02-06CH11357。我们感谢[NCSA 重力组](http://gravity.ncsa.illinois.edu)提供的有用反馈。
- en: MC and JMDK gratefully acknowledge funding from the Deutsche Forschungsgemeinschaft
    (DFG) through an Emmy Noether Research Group (grant number KR4801/1-1) and the
    DFG Sachbeihilfe (grant number KR4801/2-1). JMDK gratefully acknowledges funding
    from the European Research Council (ERC) under the European Union’s Horizon 2020
    research and innovation programme via the ERC Starting Grant MUSTANG (grant agreement
    number 714907).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: MC 和 JMDK 感谢德国研究基金会（DFG）通过 Emmy Noether 研究组（资助号 KR4801/1-1）以及 DFG Sachbeihilfe（资助号
    KR4801/2-1）提供的资助。JMDK 感谢欧洲研究委员会（ERC）在欧盟的地平线 2020 研究与创新计划下提供的资助，通过 ERC 启动资助 MUSTANG（资助协议号
    714907）。
- en: References
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Abbott et al. (2016) Abbott T., et al., 2016, [Mon. Not. Roy. Astron. Soc.](http://dx.doi.org/10.1093/mnras/stw641),
    460, 1270
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abbott 等 (2016) Abbott T., 等, 2016, [Mon. Not. Roy. Astron. Soc.](http://dx.doi.org/10.1093/mnras/stw641),
    460, 1270
- en: Ackermann et al. (2018) Ackermann S., Schawinski K., Zhang C., Weigel A. K.,
    Turp M. D., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/sty1398), 479, 415
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ackermann 等（2018）Ackermann S., Schawinski K., Zhang C., Weigel A. K., Turp M.
    D., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/sty1398), 479, 415
- en: Adamo et al. (2017) Adamo A., et al., 2017, [ApJ](http://dx.doi.org/10.3847/1538-4357/aa7132),
    [841, 131](http://adsabs.harvard.edu/abs/2017ApJ...841..131A)
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adamo 等（2017）Adamo A., 等, 2017, [ApJ](http://dx.doi.org/10.3847/1538-4357/aa7132),
    [841, 131](http://adsabs.harvard.edu/abs/2017ApJ...841..131A)
- en: Ball et al. (2006) Ball N. M., Brunner R. J., Myers A. D., Tcheng D., 2006,
    [ApJ](http://dx.doi.org/10.1086/507440), 650, 497
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ball 等（2006）Ball N. M., Brunner R. J., Myers A. D., Tcheng D., 2006, [ApJ](http://dx.doi.org/10.1086/507440),
    650, 497
- en: Ball et al. (2008) Ball N. M., Brunner R. J., Myers A. D., Strand N. E., Alberts
    S. L., Tcheng D., 2008, [ApJ](http://dx.doi.org/10.1086/589646), 683, 12
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ball 等（2008）Ball N. M., Brunner R. J., Myers A. D., Strand N. E., Alberts S.
    L., Tcheng D., 2008, [ApJ](http://dx.doi.org/10.1086/589646), 683, 12
- en: Banerji et al. (2010) Banerji M., et al., 2010, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2010.16713.x),
    406, 342
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Banerji 等（2010）Banerji M., 等, 2010, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2010.16713.x),
    406, 342
- en: Barchi et al. (2019) Barchi P. H., de Carvalho R. R., Rosa R. R., Sautter R.,
    Soares-Santos M., Marques B. A. D., Clua E., 2019, arXiv e-prints, p. arXiv:1901.07047
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barchi 等（2019）Barchi P. H., de Carvalho R. R., Rosa R. R., Sautter R., Soares-Santos
    M., Marques B. A. D., Clua E., 2019, arXiv 电子印刷本, 页. arXiv:1901.07047
- en: Bastian et al. (2012) Bastian N., et al., 2012, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2011.19909.x),
    [419, 2606](http://adsabs.harvard.edu/abs/2012MNRAS.419.2606B)
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bastian 等（2012）Bastian N., 等, 2012, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2011.19909.x),
    [419, 2606](http://adsabs.harvard.edu/abs/2012MNRAS.419.2606B)
- en: Bengio (2011) Bengio Y., 2011, in Proceedings of the 2011 International Conference
    on Unsupervised and Transfer Learning workshop-Volume 27\. pp 17–37
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengio（2011）Bengio Y., 2011, 发表在《2011年国际无监督与迁移学习研讨会论文集》第27卷，页17–37
- en: Bertin & Arnouts (1996a) Bertin E., Arnouts S., 1996a, [A&AS](http://dx.doi.org/10.1051/aas:1996164),
    [117, 393](https://ui.adsabs.harvard.edu/abs/1996A%26AS..117..393B)
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bertin & Arnouts（1996a）Bertin E., Arnouts S., 1996a, [A&AS](http://dx.doi.org/10.1051/aas:1996164),
    [117, 393](https://ui.adsabs.harvard.edu/abs/1996A%26AS..117..393B)
- en: Bertin & Arnouts (1996b) Bertin E., Arnouts S., 1996b, A&AS, [117, 393](http://adsabs.harvard.edu/abs/1996A%26AS..117..393B)
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bertin & Arnouts（1996b）Bertin E., Arnouts S., 1996b, A&AS, [117, 393](http://adsabs.harvard.edu/abs/1996A%26AS..117..393B)
- en: Calzetti et al. (2015a) Calzetti D., et al., 2015a, [AJ](http://dx.doi.org/10.1088/0004-6256/149/2/51),
    [149, 51](http://adsabs.harvard.edu/abs/2015AJ....149...51C)
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calzetti 等（2015a）Calzetti D., 等, 2015a, [AJ](http://dx.doi.org/10.1088/0004-6256/149/2/51),
    [149, 51](http://adsabs.harvard.edu/abs/2015AJ....149...51C)
- en: Calzetti et al. (2015b) Calzetti D., et al., 2015b, [ApJ](http://dx.doi.org/10.1088/0004-637X/811/2/75),
    [811, 75](http://adsabs.harvard.edu/abs/2015ApJ...811...75C)
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calzetti 等（2015b）Calzetti D., 等, 2015b, [ApJ](http://dx.doi.org/10.1088/0004-637X/811/2/75),
    [811, 75](http://adsabs.harvard.edu/abs/2015ApJ...811...75C)
- en: Cannon & Pickering (1912) Cannon A. J., Pickering E. C., 1912, Annals of Harvard
    College Observatory, [56, 65](https://ui.adsabs.harvard.edu/abs/1912AnHar..56...65C)
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cannon & Pickering（1912）Cannon A. J., Pickering E. C., 1912, 哈佛大学天文台年刊, [56,
    65](https://ui.adsabs.harvard.edu/abs/1912AnHar..56...65C)
- en: Cannon & Pickering (1918) Cannon A. J., Pickering E. C., 1918, Annals of Harvard
    College Observatory, [91, 1](https://ui.adsabs.harvard.edu/abs/1918AnHar..91....1C)
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cannon & Pickering（1918）Cannon A. J., Pickering E. C., 1918, 哈佛大学天文台年刊, [91,
    1](https://ui.adsabs.harvard.edu/abs/1918AnHar..91....1C)
- en: Carrasco Kind & Brunner (2013) Carrasco Kind M., Brunner R. J., 2013, [MNRAS](http://dx.doi.org/10.1093/mnras/stt574),
    432, 1483
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carrasco Kind & Brunner（2013）Carrasco Kind M., Brunner R. J., 2013, [MNRAS](http://dx.doi.org/10.1093/mnras/stt574),
    432, 1483
- en: Chandar et al. (2010) Chandar R., et al., 2010, [ApJ](http://dx.doi.org/10.1088/0004-637X/719/1/966),
    [719, 966](http://adsabs.harvard.edu/abs/2010ApJ...719..966C)
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chandar 等（2010）Chandar R., 等, 2010, [ApJ](http://dx.doi.org/10.1088/0004-637X/719/1/966),
    [719, 966](http://adsabs.harvard.edu/abs/2010ApJ...719..966C)
- en: Chandar et al. (2014) Chandar R., Whitmore B. C., Calzetti D., O’Connell R.,
    2014, [ApJ](http://dx.doi.org/10.1088/0004-637X/787/1/17), [787, 17](https://ui.adsabs.harvard.edu/abs/2014ApJ...787...17C)
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chandar 等（2014）Chandar R., Whitmore B. C., Calzetti D., O’Connell R., 2014,
    [ApJ](http://dx.doi.org/10.1088/0004-637X/787/1/17), [787, 17](https://ui.adsabs.harvard.edu/abs/2014ApJ...787...17C)
- en: Chandar et al. (2016) Chandar R., Whitmore B. C., Dinino D., Kennicutt R. C.,
    Chien L. H., Schinnerer E., Meidt S., 2016, [ApJ](http://dx.doi.org/10.3847/0004-637X/824/2/71),
    [824, 71](https://ui.adsabs.harvard.edu/abs/2016ApJ...824...71C)
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chandar 等（2016）Chandar R., Whitmore B. C., Dinino D., Kennicutt R. C., Chien
    L. H., Schinnerer E., Meidt S., 2016, [ApJ](http://dx.doi.org/10.3847/0004-637X/824/2/71),
    [824, 71](https://ui.adsabs.harvard.edu/abs/2016ApJ...824...71C)
- en: Cook et al. (2019) Cook D. O., et al., 2019, [MNRAS](http://dx.doi.org/10.1093/mnras/stz331),
    [484, 4897](http://adsabs.harvard.edu/abs/2019MNRAS.484.4897C)
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cook et al. (2019) Cook D. O., et al., 2019, [MNRAS](http://dx.doi.org/10.1093/mnras/stz331),
    [484, 4897](http://adsabs.harvard.edu/abs/2019MNRAS.484.4897C)
- en: Deng et al. (2009) Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L.,
    2009, in CVPR09\. [http://www.image-net.org/](http://www.image-net.org/)
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng et al. (2009) Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L.,
    2009, 在 CVPR09\. [http://www.image-net.org/](http://www.image-net.org/)
- en: Dieleman et al. (2015) Dieleman S., Willett K. W., Dambre J., 2015, [MNRAS](http://dx.doi.org/10.1093/mnras/stv632),
    [450, 1441](https://ui.adsabs.harvard.edu/abs/2015MNRAS.450.1441D)
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dieleman et al. (2015) Dieleman S., Willett K. W., Dambre J., 2015, [MNRAS](http://dx.doi.org/10.1093/mnras/stv632),
    [450, 1441](https://ui.adsabs.harvard.edu/abs/2015MNRAS.450.1441D)
- en: Domínguez Sánchez et al. (2018) Domínguez Sánchez H., Huertas-Company et al.,
    2018, preprint, p. arXiv:1807.00807 ([arXiv:1807.00807](http://arxiv.org/abs/1807.00807))
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Domínguez Sánchez et al. (2018) Domínguez Sánchez H., Huertas-Company et al.,
    2018, 预印本, p. arXiv:1807.00807 ([arXiv:1807.00807](http://arxiv.org/abs/1807.00807))
- en: Everingham et al. (2015) Everingham M., Eslami S. M. A., Van Gool L., Williams
    C. K. I., Winn J., Zisserman A., 2015, International Journal of Computer Vision,
    111, 98
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Everingham et al. (2015) Everingham M., Eslami S. M. A., Van Gool L., Williams
    C. K. I., Winn J., Zisserman A., 2015, 国际计算机视觉杂志, 111, 98
- en: Fadely et al. (2012) Fadely R., Hogg D. W., Willman B., 2012, [ApJ](http://dx.doi.org/10.1088/0004-637X/760/1/15),
    760, 15
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fadely et al. (2012) Fadely R., Hogg D. W., Willman B., 2012, [ApJ](http://dx.doi.org/10.1088/0004-637X/760/1/15),
    760, 15
- en: George et al. (2017) George D., Shen H., Huerta E. A., 2017, arXiv e-prints,
    p. arXiv:1711.07468
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: George et al. (2017) George D., Shen H., Huerta E. A., 2017, arXiv e-prints,
    p. arXiv:1711.07468
- en: George et al. (2018) George D., Shen H., Huerta E. A., 2018, [Phys. Rev. D](http://dx.doi.org/10.1103/PhysRevD.97.101501),
    97, 101501
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: George et al. (2018) George D., Shen H., Huerta E. A., 2018, [物理评论D](http://dx.doi.org/10.1103/PhysRevD.97.101501),
    97, 101501
- en: Goodfellow et al. (2016) Goodfellow I., Bengio Y., Courville A., 2016, Deep
    Learning. MIT Press
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow et al. (2016) Goodfellow I., Bengio Y., Courville A., 2016, 《深度学习》。麻省理工学院出版社
- en: Gouliermis (2018) Gouliermis D. A., 2018, [PASP](http://dx.doi.org/10.1088/1538-3873/aac1fd),
    [130, 072001](https://ui.adsabs.harvard.edu/abs/2018PASP..130g2001G)
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gouliermis (2018) Gouliermis D. A., 2018, [PASP](http://dx.doi.org/10.1088/1538-3873/aac1fd),
    [130, 072001](https://ui.adsabs.harvard.edu/abs/2018PASP..130g2001G)
- en: Grasha et al. (2019) Grasha K., et al., 2019, [MNRAS](http://dx.doi.org/10.1093/mnras/sty3424),
    [483, 4707](https://ui.adsabs.harvard.edu/abs/2019MNRAS.483.4707G)
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grasha et al. (2019) Grasha K., et al., 2019, [MNRAS](http://dx.doi.org/10.1093/mnras/sty3424),
    [483, 4707](https://ui.adsabs.harvard.edu/abs/2019MNRAS.483.4707G)
- en: He et al. (2015) He K., Zhang X., Ren S., Sun J., 2015, arXiv e-prints, [p.
    arXiv:1512.03385](https://ui.adsabs.harvard.edu/abs/2015arXiv151203385H)
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. (2015) He K., Zhang X., Ren S., Sun J., 2015, arXiv e-prints, [p.
    arXiv:1512.03385](https://ui.adsabs.harvard.edu/abs/2015arXiv151203385H)
- en: He et al. (2016) He K., Zhang X., Ren S., Sun J., 2016, in Proceedings of the
    IEEE conference on computer vision and pattern recognition. pp 770–778, [https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. (2016) He K., Zhang X., Ren S., Sun J., 2016, 在 IEEE 计算机视觉与模式识别会议论文集中.
    第 770–778 页, [https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)
- en: Holtzman et al. (1992) Holtzman J. A., et al., 1992, [AJ](http://dx.doi.org/10.1086/116094),
    [103, 691](https://ui.adsabs.harvard.edu/abs/1992AJ....103..691H)
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Holtzman et al. (1992) Holtzman J. A., et al., 1992, [AJ](http://dx.doi.org/10.1086/116094),
    [103, 691](https://ui.adsabs.harvard.edu/abs/1992AJ....103..691H)
- en: Hubble (1926) Hubble E. P., 1926, [ApJ](http://dx.doi.org/10.1086/143018), 64,
    321
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hubble (1926) Hubble E. P., 1926, [ApJ](http://dx.doi.org/10.1086/143018), 64,
    321
- en: Hubble (1936) Hubble E. P., 1936, Realm of the Nebulae
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hubble (1936) Hubble E. P., 1936, 《星云的领域》
- en: Ishak (2017) Ishak B., 2017, [Contemporary Physics](http://dx.doi.org/10.1080/00107514.2016.1246478),
    58, 99
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ishak (2017) Ishak B., 2017, [当代物理学](http://dx.doi.org/10.1080/00107514.2016.1246478),
    58, 99
- en: Kamdar et al. (2016) Kamdar H., Turk M., Brunner R., 2016, [Monthly Notices
    of the Royal Astronomical Society](http://dx.doi.org/10.1093/mnras/stv2310), 455,
    642
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kamdar et al. (2016) Kamdar H., Turk M., Brunner R., 2016, [皇家天文学会月刊](http://dx.doi.org/10.1093/mnras/stv2310),
    455, 642
- en: Khan et al. (2019) Khan A., Huerta E. A., Wang S., Gruendl R., Jennings E.,
    Zheng H., 2019, Phys. Lett., B795, 248
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan et al. (2019) Khan A., Huerta E. A., Wang S., Gruendl R., Jennings E.,
    Zheng H., 2019, 物理快报, B795, 248
- en: Kim & Brunner (2017) Kim E. J., Brunner R. J., 2017, [MNRAS](http://dx.doi.org/10.1093/mnras/stw2672),
    464, 4463
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim & Brunner (2017) Kim E. J., Brunner R. J., 2017, [MNRAS](http://dx.doi.org/10.1093/mnras/stw2672),
    464, 4463
- en: 'Kingma & Ba (2014) Kingma D. P., Ba J., 2014, Adam: A Method for Stochastic
    Optimization ([arXiv:1412.6980](http://arxiv.org/abs/1412.6980))'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kingma & Ba (2014) Kingma D. P., Ba J., 2014, Adam: 一种随机优化方法 ([arXiv:1412.6980](http://arxiv.org/abs/1412.6980))'
- en: Krizhevsky et al. (2012) Krizhevsky A., Sutskever I., Hinton G. E., 2012, in
    Proceedings of the 25th International Conference on Neural Information Processing
    Systems - Volume 1. NIPS’12. Curran Associates Inc., USA, pp 1097–1105, [http://dl.acm.org/citation.cfm?id=2999134.2999257](http://dl.acm.org/citation.cfm?id=2999134.2999257)
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky et al. (2012) Krizhevsky A., Sutskever I., Hinton G. E., 2012, 在第25届国际神经信息处理系统会议论文集
    - 第1卷. NIPS’12. Curran Associates Inc., USA, pp 1097–1105, [http://dl.acm.org/citation.cfm?id=2999134.2999257](http://dl.acm.org/citation.cfm?id=2999134.2999257)
- en: Krumholz et al. (2018) Krumholz M. R., McKee C. F., Bland -Hawthorn J., 2018,
    arXiv e-prints, [p. arXiv:1812.01615](https://ui.adsabs.harvard.edu/abs/2018arXiv181201615K)
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krumholz et al. (2018) Krumholz M. R., McKee C. F., Bland -Hawthorn J., 2018,
    arXiv 预印本, [p. arXiv:1812.01615](https://ui.adsabs.harvard.edu/abs/2018arXiv181201615K)
- en: LSST Science Collaboration et al. (2009) LSST Science Collaboration et al.,
    2009, preprint ([arXiv:0912.0201](http://arxiv.org/abs/0912.0201))
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LSST Science Collaboration et al. (2009) LSST Science Collaboration et al.,
    2009, 预印本 ([arXiv:0912.0201](http://arxiv.org/abs/0912.0201))
- en: Larsen (2002) Larsen S. S., 2002, [AJ](http://dx.doi.org/10.1086/342381), [124,
    1393](http://adsabs.harvard.edu/abs/2002AJ....124.1393L)
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Larsen (2002) Larsen S. S., 2002, [AJ](http://dx.doi.org/10.1086/342381), [124,
    1393](http://adsabs.harvard.edu/abs/2002AJ....124.1393L)
- en: LeCun et al. (2015) LeCun Y., Bengio Y., Hinton G., 2015, nature, 521, 436
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun et al. (2015) LeCun Y., Bengio Y., Hinton G., 2015, nature, 521, 436
- en: Małek & et al (2013) Małek K., et al 2013, [A&A](http://dx.doi.org/10.1051/0004-6361/201321447),
    557, A16
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Małek & et al (2013) Małek K., et al 2013, [A&A](http://dx.doi.org/10.1051/0004-6361/201321447),
    557, A16
- en: Messa et al. (2018) Messa M., et al., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/stx2403),
    [473, 996](https://ui.adsabs.harvard.edu/abs/2018MNRAS.473..996M)
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Messa et al. (2018) Messa M., et al., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/stx2403),
    [473, 996](https://ui.adsabs.harvard.edu/abs/2018MNRAS.473..996M)
- en: Paszke et al. (2017) Paszke A., et al., 2017, in NIPS-W.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Paszke et al. (2017) Paszke A., et al., 2017, 在 NIPS-W.
- en: Portegies Zwart et al. (2010) Portegies Zwart S. F., McMillan S. L. W., Gieles
    M., 2010, [ARA&A](http://dx.doi.org/10.1146/annurev-astro-081309-130834), [48,
    431](https://ui.adsabs.harvard.edu/abs/2010ARA&A..48..431P)
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Portegies Zwart et al. (2010) Portegies Zwart S. F., McMillan S. L. W., Gieles
    M., 2010, [ARA&A](http://dx.doi.org/10.1146/annurev-astro-081309-130834), [48,
    431](https://ui.adsabs.harvard.edu/abs/2010ARA&A..48..431P)
- en: Russakovsky et al. (2015) Russakovsky O., et al., 2015, [International Journal
    of Computer Vision (IJCV)](http://dx.doi.org/10.1007/s11263-015-0816-y), 115,
    211
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russakovsky et al. (2015) Russakovsky O., et al., 2015, [International Journal
    of Computer Vision (IJCV)](http://dx.doi.org/10.1007/s11263-015-0816-y), 115,
    211
- en: Ryon et al. (2014) Ryon J. E., et al., 2014, [AJ](http://dx.doi.org/10.1088/0004-6256/148/2/33),
    [148, 33](http://adsabs.harvard.edu/abs/2014AJ....148...33R)
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ryon et al. (2014) Ryon J. E., et al., 2014, [AJ](http://dx.doi.org/10.1088/0004-6256/148/2/33),
    [148, 33](http://adsabs.harvard.edu/abs/2014AJ....148...33R)
- en: Ryon et al. (2017) Ryon J. E., et al., 2017, [The Astrophysical Journal](http://dx.doi.org/10.3847/1538-4357/aa719e),
    841, 92
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ryon et al. (2017) Ryon J. E., et al., 2017, [The Astrophysical Journal](http://dx.doi.org/10.3847/1538-4357/aa719e),
    841, 92
- en: Schweizer et al. (1996) Schweizer F., Miller B. W., Whitmore B. C., Fall S. M.,
    1996, [AJ](http://dx.doi.org/10.1086/118146), [112, 1839](https://ui.adsabs.harvard.edu/abs/1996AJ....112.1839S)
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schweizer et al. (1996) Schweizer F., Miller B. W., Whitmore B. C., Fall S.
    M., 1996, [AJ](http://dx.doi.org/10.1086/118146), [112, 1839](https://ui.adsabs.harvard.edu/abs/1996AJ....112.1839S)
- en: Sevilla-Noarbe & Etayo-Sotos (2015) Sevilla-Noarbe I., Etayo-Sotos P., 2015,
    [Astronomy and Computing](http://dx.doi.org/10.1016/j.ascom.2015.03.010), 11,
    64
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sevilla-Noarbe & Etayo-Sotos (2015) Sevilla-Noarbe I., Etayo-Sotos P., 2015,
    [Astronomy and Computing](http://dx.doi.org/10.1016/j.ascom.2015.03.010), 11,
    64
- en: Shannon (1948) Shannon C. E., 1948, Bell system technical journal, 27, 379
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shannon (1948) Shannon C. E., 1948, Bell system technical journal, 27, 379
- en: Simonyan & Zisserman (2014a) Simonyan K., Zisserman A., 2014a, arXiv preprint
    arXiv:1409.1556
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simonyan & Zisserman (2014a) Simonyan K., Zisserman A., 2014a, arXiv 预印本 arXiv:1409.1556
- en: Simonyan & Zisserman (2014b) Simonyan K., Zisserman A., 2014b, arXiv e-prints,
    [p. arXiv:1409.1556](https://ui.adsabs.harvard.edu/abs/2014arXiv1409.1556S)
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simonyan & Zisserman (2014b) Simonyan K., Zisserman A., 2014b, arXiv 预印本, [p.
    arXiv:1409.1556](https://ui.adsabs.harvard.edu/abs/2014arXiv1409.1556S)
- en: Solarz et al. (2017) Solarz A., Bilicki M., Gromadzki M., Pollo A., Durkalec
    A., Wypych M., 2017, [A&A](http://dx.doi.org/10.1051/0004-6361/201730968), 606,
    A39
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Solarz et al. (2017) Solarz A., Bilicki M., Gromadzki M., Pollo A., Durkalec
    A., Wypych M., 2017, [A&A](http://dx.doi.org/10.1051/0004-6361/201730968), 606,
    A39
- en: Suchkov et al. (2005) Suchkov A. A., Hanisch R. J., Margon B., 2005, [AJ](http://dx.doi.org/10.1086/497363),
    130, 2439
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suchkov et al. (2005) Suchkov A. A., Hanisch R. J., Margon B., 2005, [AJ](http://dx.doi.org/10.1086/497363),
    130, 2439
- en: Szegedy et al. (2014) Szegedy C., et al., 2014, arXiv e-prints, [p. arXiv:1409.4842](https://ui.adsabs.harvard.edu/abs/2014arXiv1409.4842S)
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy et al. (2014) Szegedy C., et al., 2014, arXiv e-prints, [p. arXiv:1409.4842](https://ui.adsabs.harvard.edu/abs/2014arXiv1409.4842S)
- en: Vasconcellos et al. (2011) Vasconcellos E. C., de Carvalho R. R., Gal R. R.,
    LaBarbera F. L., Capelato H. V., Frago Campos Velho H., Trevisan M., Ruiz R. S. R.,
    2011, [AJ](http://dx.doi.org/10.1088/0004-6256/141/6/189), 141, 189
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vasconcellos et al. (2011) Vasconcellos E. C., de Carvalho R. R., Gal R. R.,
    LaBarbera F. L., Capelato H. V., Frago Campos Velho H., Trevisan M., Ruiz R. S.
    R., 2011, [AJ](http://dx.doi.org/10.1088/0004-6256/141/6/189), 141, 189
- en: Weir et al. (1995) Weir N., Fayyad U. M., Djorgovski S., 1995, [AJ](http://dx.doi.org/10.1086/117459),
    109, 2401
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weir et al. (1995) Weir N., Fayyad U. M., Djorgovski S., 1995, [AJ](http://dx.doi.org/10.1086/117459),
    109, 2401
- en: Whitmore et al. (1995) Whitmore B. C., Sparks W. B., Lucas R. A., Macchetto
    F. D., Biretta J. A., 1995, [ApJ](http://dx.doi.org/10.1086/309788), [454, L73](https://ui.adsabs.harvard.edu/abs/1995ApJ...454L..73W)
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Whitmore et al. (1995) Whitmore B. C., Sparks W. B., Lucas R. A., Macchetto
    F. D., Biretta J. A., 1995, [ApJ](http://dx.doi.org/10.1086/309788), [454, L73](https://ui.adsabs.harvard.edu/abs/1995ApJ...454L..73W)
- en: Whitmore et al. (2014) Whitmore B. C., et al., 2014, [ApJ](http://dx.doi.org/10.1088/0004-637X/795/2/156),
    [795, 156](http://adsabs.harvard.edu/abs/2014ApJ...795..156W)
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Whitmore et al. (2014) Whitmore B. C., et al., 2014, [ApJ](http://dx.doi.org/10.1088/0004-637X/795/2/156),
    [795, 156](http://adsabs.harvard.edu/abs/2014ApJ...795..156W)
- en: Whitmore et al. (2016) Whitmore B. C., et al., 2016, [AJ](http://dx.doi.org/10.3847/0004-6256/151/6/134),
    [151, 134](https://ui.adsabs.harvard.edu/abs/2016AJ....151..134W)
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Whitmore et al. (2016) Whitmore B. C., et al., 2016, [AJ](http://dx.doi.org/10.3847/0004-6256/151/6/134),
    [151, 134](https://ui.adsabs.harvard.edu/abs/2016AJ....151..134W)
- en: Willett et al. (2013) Willett K. W., et al., 2013, [MNRAS](http://dx.doi.org/10.1093/mnras/stt1458),
    [435, 2835](https://ui.adsabs.harvard.edu/abs/2013MNRAS.435.2835W)
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Willett et al. (2013) Willett K. W., et al., 2013, [MNRAS](http://dx.doi.org/10.1093/mnras/stt1458),
    [435, 2835](https://ui.adsabs.harvard.edu/abs/2013MNRAS.435.2835W)
- en: de Vaucouleurs (1963) de Vaucouleurs G., 1963, [ApJS](http://dx.doi.org/10.1086/190084),
    [8, 31](https://ui.adsabs.harvard.edu/abs/1963ApJS....8...31D)
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de Vaucouleurs (1963) de Vaucouleurs G., 1963, [ApJS](http://dx.doi.org/10.1086/190084),
    [8, 31](https://ui.adsabs.harvard.edu/abs/1963ApJS....8...31D)
- en: Appendix A Statistical foundations of Deep Learning Classifiers
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 深度学习分类器的统计基础
- en: Within the framework of statistical learning, an image $X$ can be modeled as
    a random matrix that takes value in set $\mathcal{X}$, and the corresponding class
    can be treated as a random variable $Y$ that takes value in set $\mathcal{Y}$.
    Since we use $299\times 299$ images with 5 channels, we treat a cluster image
    as random matrix of size $299\times 299\times 5$. Similarly, as we are trying
    to classify the images into 4 classes, $Y$ is a discrete random variable that
    takes values in $\mathcal{Y}$ with cardinality $|\mathcal{Y}|=4$.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学习框架下，图像 $X$ 可以被建模为一个在集合 $\mathcal{X}$ 中取值的随机矩阵，相应的类别可以被视为一个在集合 $\mathcal{Y}$
    中取值的随机变量 $Y$。由于我们使用的是 $299\times 299$ 的图像，具有 5 个通道，我们将一个集群图像视为大小为 $299\times 299\times
    5$ 的随机矩阵。类似地，因为我们尝试将图像分类到 4 个类别中，所以 $Y$ 是一个离散的随机变量，它在 $\mathcal{Y}$ 中取值，且 $|\mathcal{Y}|=4$。
- en: We assume that the star images and the corresponding class labels follow some
    unknown but fixed joint probability distribution, with the probability density
    function (pdf) $f_{XY}(x,y)$. We also use $\Delta_{\mathcal{Y}}$ to denote set
    of all possible distribution over $\mathcal{Y}$. Since in our case, $|\mathcal{Y}|=4$,
    we have $\Delta_{\mathcal{Y}}=\{\pi=(\pi_{1},\pi_{2},\pi_{3},\pi_{4}):\sum_{i=1}^{4}\pi_{i}=1,\pi_{i}\geq
    0,\forall i\in[4]\}$
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设星图像和相应的类别标签遵循某种未知但固定的联合概率分布，其概率密度函数（pdf）为 $f_{XY}(x,y)$。我们还用 $\Delta_{\mathcal{Y}}$
    表示 $\mathcal{Y}$ 上所有可能的分布的集合。由于在我们的案例中，$|\mathcal{Y}|=4$，因此我们有 $\Delta_{\mathcal{Y}}=\{\pi=(\pi_{1},\pi_{2},\pi_{3},\pi_{4}):\sum_{i=1}^{4}\pi_{i}=1,\pi_{i}\geq
    0,\forall i\in[4]\}$
- en: Under these conventions, the goal of classification is to find a classifier
    or function $h:X\rightarrow\Delta_{\mathcal{Y}}$ that minimizes the expectation
    of the cross entropy between the predicted and the ground truth probability mass
    distribution (pmf) over the classes given the input image $X$, namely,
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些约定下，分类的目标是找到一个分类器或函数 $h:X\rightarrow\Delta_{\mathcal{Y}}$，以最小化预测的类别与真实类别的概率质量分布（pmf）之间的交叉熵的期望值，给定输入图像
    $X$，即，
- en: '|  | $\displaystyle L(h)$ | $\displaystyle=\mathbf{E}[H(h(X),f_{Y&#124;X}(\cdot&#124;X))]$
    |  | (1) |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle L(h)$ | $\displaystyle=\mathbf{E}[H(h(X),f_{Y|X}(\cdot|X))]$
    |  | (1) |'
- en: '|  |  | $\displaystyle=\int H(h(X),f_{Y&#124;X}(\cdot&#124;x))f_{X}(x)dx\,,$
    |  | (2) |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\int H(h(X),f_{Y|X}(\cdot|x))f_{X}(x)dx\,,$ |  | (2)
    |'
- en: where $f_{X}(x)$ is the marginal distribution of $X$ over $\mathcal{X}$, and
    $H$ is the cross entropy between the predicted and the ground truth pmf over classes,
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $f_{X}(x)$ 是 $X$ 在 $\mathcal{X}$ 上的边际分布，$H$ 是预测的和真实的类别概率质量函数之间的交叉熵，
- en: '|  | $\displaystyle H(h(x),f_{Y&#124;Y}(\cdot&#124;x))=-\sum_{i=1}^{4}f_{Y&#124;X}(Y=i&#124;x)\log([h(x)]_{i}),$
    |  | (3) |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle H(h(x),f_{Y\mid Y}(\cdot\mid x))=-\sum_{i=1}^{4}f_{Y\mid
    X}(Y=i\mid x)\log([h(x)]_{i}),$ |  | (3) |'
- en: and the $f_{Y|X}(y|x)$ is the conditional distribution of $Y$ given $X$.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 和 $f_{Y|X}(y|x)$ 是在给定 $X$ 的情况下 $Y$ 的条件分布。
- en: In most cases, we only know the empirical distribution $\hat{f}_{XY}(x,y)$ of
    $(X,Y)$ and $\hat{f}_{Y|X}(y|x)$ of $Y$, which are determined by the empirical
    data. So the quantity we can directly minimize is
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，我们只知道 $(X,Y)$ 的经验分布 $\hat{f}_{XY}(x,y)$ 和 $Y$ 的经验分布 $\hat{f}_{Y|X}(y|x)$，这些分布是由经验数据决定的。因此，我们可以直接最小化的量是
- en: '|  | $\displaystyle\hat{L}(h)$ | $\displaystyle=\hat{\mathbf{E}}[H(h_{X}(\cdot),\hat{f}_{Y&#124;X}(\cdot&#124;X))]$
    |  | (4) |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\hat{L}(h)$ | $\displaystyle=\hat{\mathbf{E}}[H(h_{X}(\cdot),\hat{f}_{Y\mid
    X}(\cdot\mid X))]$ |  | (4) |'
- en: '|  |  | $\displaystyle=\int H(h_{x}(\cdot),\hat{f}_{Y&#124;X}(\cdot&#124;x))\hat{f}_{X}(x)dx\,,$
    |  | (5) |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\int H(h_{x}(\cdot),\hat{f}_{Y\mid X}(\cdot\mid x))\hat{f}_{X}(x)dx\,,$
    |  | (5) |'
- en: In practice, if the choice of $h(\cdot)$ is arbitrary, then finding an optimal
    solution is computationally unfeasible. Therefore, we often restrict the searching
    space to a class of parameterized functions, $h_{\mathbf{w}}(\cdot)$, where $\mathbf{w}$
    is a vector of parameters. In this case, the optimization problem can be posed
    as
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，如果 $h(\cdot)$ 的选择是任意的，那么找到一个最佳解在计算上是不可行的。因此，我们通常将搜索空间限制在一类参数化函数 $h_{\mathbf{w}}(\cdot)$
    中，其中 $\mathbf{w}$ 是参数向量。在这种情况下，优化问题可以表示为
- en: '|  | $\displaystyle\mathbf{w}^{*}=\operatorname*{arg\,min}_{\mathbf{w}}\hat{L}(h_{\mathbf{w}})\,.$
    |  | (6) |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathbf{w}^{*}=\operatorname*{arg\,min}_{\mathbf{w}}\hat{L}(h_{\mathbf{w}})\,.$
    |  | (6) |'
- en: The choice of the parameterized function class is critical to the success of
    any statistical learning algorithm. In recent years, a deep-layered structure
    of functions has received much attention  (LeCun et al., [2015](#bib.bib45); Goodfellow
    et al., [2016](#bib.bib28)),
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 参数化函数类的选择对于任何统计学习算法的成功至关重要。近年来，深层函数结构受到了广泛关注（LeCun et al., [2015](#bib.bib45);
    Goodfellow et al., [2016](#bib.bib28)），
- en: '|  | $\displaystyle{}h_{\mathbf{w}}(\mathbf{x})=h_{\mathbf{w}_{n}}(h_{\mathbf{w}_{n-1}}(\cdots
    h_{\mathbf{w}_{1}}(\mathbf{x}))),$ |  | (7) |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle{}h_{\mathbf{w}}(\mathbf{x})=h_{\mathbf{w}_{n}}(h_{\mathbf{w}_{n-1}}(\cdots
    h_{\mathbf{w}_{1}}(\mathbf{x}))),$ |  | (7) |'
- en: where $n$ is the number of layers or the depth. Usually, we choose, $h_{\mathbf{w}_{i}}(\mathbf{x})=g(\mathbf{w}_{i}\mathbf{x})$,
    where $\mathbf{w}_{i}$ is a matrix, $\mathbf{x}$ is an input vector, and $g(\cdot)$
    is a fixed non-linear function, e.g., $\max\{\cdot,0\}$ (also known as ReLU),
    $\tanh(\cdot)$, etc, that is applied element-wise. For the classification problems,
    we usually apply the so-called softmax function after the last linear transformation.
    The softmax function on a vector $\mathbf{x}$ is a normalization after an element-wise
    exponentiation,
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $n$ 是层数或深度。通常，我们选择 $h_{\mathbf{w}_{i}}(\mathbf{x})=g(\mathbf{w}_{i}\mathbf{x})$，其中
    $\mathbf{w}_{i}$ 是一个矩阵，$\mathbf{x}$ 是输入向量，$g(\cdot)$ 是一个固定的非线性函数，例如 $\max\{\cdot,0\}$（也称为
    ReLU），$\tanh(\cdot)$ 等，按元素逐一应用。对于分类问题，我们通常在最后一次线性变换后应用所谓的 softmax 函数。softmax 函数在向量
    $\mathbf{x}$ 上是一种元素逐一指数化后的归一化，
- en: '|  | $\displaystyle\text{softmax}(\mathbf{x})_{i}=\frac{\exp(x_{i})}{\sum_{i=1}^{n}{\exp(x_{i})}},\
    \ \ \ \forall i=1,...,n,$ |  | (8) |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{softmax}(\mathbf{x})_{i}=\frac{\exp(x_{i})}{\sum_{i=1}^{n}{\exp(x_{i})}},\
    \ \ \ \forall i=1,...,n,$ |  | (8) |'
- en: where $n$ is the length of $\mathbf{x}$.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $n$ 是 $\mathbf{x}$ 的长度。
- en: This function class and its extensions, also dubbed neural networks, combined
    with simple first-order optimization algorithms such as stochastic gradient descent
    (SGD), and improved computing hardware, has lead to disruptive applications of
    deep learning (LeCun et al., [2015](#bib.bib45); Goodfellow et al., [2016](#bib.bib28)).
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 这种函数类及其扩展，也称为神经网络，结合简单的一阶优化算法如随机梯度下降（SGD），以及改进的计算硬件，导致了深度学习的突破性应用（LeCun et al.,
    [2015](#bib.bib45); Goodfellow et al., [2016](#bib.bib28)）。
- en: Appendix B Deep transfer learning
  id: totrans-346
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 深度迁移学习
- en: 'In practice, Eq. [6](#A1.E6 "In Appendix A Statistical foundations of Deep
    Learning Classifiers ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey") is usually iteratively solved by using
    variants of SGD. Thus, the choice of initial value for weights $\mathbf{w}$ is
    critical to the success of the training algorithm. If we have some prior knowledge
    about what initial wights $\mathbf{w}_{0}$ works better, then it is highly possible
    that the numerical iteration can converge faster and return better weights $\mathbf{w}$.
    This is the idea behind deep transfer learning (Bengio, [2011](#bib.bib9); Goodfellow
    et al., [2016](#bib.bib28)).'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际操作中，方程式 [6](#A1.E6 "在附录A 深度学习分类器的统计基础 ‣ 对星团分类的深度迁移学习：I. 应用到PHANGS-HST调查")
    通常通过使用SGD的变种进行迭代求解。因此，权重 $\mathbf{w}$ 的初始值选择对训练算法的成功至关重要。如果我们对初始权重 $\mathbf{w}_{0}$
    有一些先验知识，知道哪种初始权重效果更好，那么数值迭代可能会更快收敛，并返回更好的权重 $\mathbf{w}$。这就是深度迁移学习的思想 （Bengio，[2011](#bib.bib9)；Goodfellow
    等，[2016](#bib.bib28)）。
- en: 'For a deep learning neural network, such as the one defined by Eq. [7](#A1.E7
    "In Appendix A Statistical foundations of Deep Learning Classifiers ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey"),
    the layered structure can be intuitively interpreted as different levels of abstraction
    for the learned features. In other words, layers that are close to the input learn
    lower-level features, such as different shapes and curves in the image, and layers
    that are close to the final output layer learn higher-level features, such as
    the type of the input image. Suppose we have a trained model that works well in
    one setting, with probability distribution $f^{(1)}_{XY}$, and now we would like
    to train another model in a different setting, with with probability distribution
    $f^{(2)}_{XY}$. If the images drawn from the distributions $f^{(1)}_{XY}$ and
    $f^{(2)}_{XY}$ share some features, then it is possible to transfer weights from
    the model trained on images sampled from $f^{(1)}_{XY}$, to the model that we
    would like to train, using images sampled from $f^{(2)}_{XY}$, with the assumption
    that the weights from the model trained on images sampled from $f^{(1)}_{XY}$,
    can also be useful in extracting features from images drawn from the distribution
    $f^{(2)}_{XY}$. So, instead of training the second model from scratch, we can
    initialize the weights of the second model to those of the first model that we
    trained in a different setting (e.g., distribution $f^{(1)}_{XY}$), and utilize
    the common features we have already learned in the previous setting.'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 对于深度学习神经网络，例如方程式 [7](#A1.E7 "在附录A 深度学习分类器的统计基础 ‣ 对星团分类的深度迁移学习：I. 应用到PHANGS-HST调查")
    定义的网络，分层结构可以直观地解释为对学习特征的不同抽象级别。换句话说，靠近输入的层学习较低级别的特征，例如图像中的不同形状和曲线，而靠近最终输出层的层学习较高级别的特征，例如输入图像的类型。假设我们有一个在某个设置下表现良好的训练模型，其概率分布为
    $f^{(1)}_{XY}$，现在我们希望在另一个设置下训练另一个模型，其概率分布为 $f^{(2)}_{XY}$。如果从分布 $f^{(1)}_{XY}$
    和 $f^{(2)}_{XY}$ 中提取的图像共享一些特征，那么可以将从 $f^{(1)}_{XY}$ 中抽取图像训练的模型的权重转移到我们希望训练的模型中，使用从
    $f^{(2)}_{XY}$ 中抽取的图像，假设从 $f^{(1)}_{XY}$ 中抽取图像训练的模型的权重也可以在从分布 $f^{(2)}_{XY}$ 中抽取的图像中提取特征。因此，我们可以在第二个模型的训练中，从头开始训练，而是将第二个模型的权重初始化为我们在不同设置（例如，分布
    $f^{(1)}_{XY}$）中训练的第一个模型的权重，并利用我们在之前的设置中已经学到的共同特征。
- en: Appendix C Batch normalization
  id: totrans-349
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 批量归一化
- en: The weights of each layer in a neural network model change throughout the training
    phase, which implies that the activations of each layer will also change. Given
    that the activations of any given layer are the inputs to the subsequent layer,
    this means that the input distribution changes at every step. This is far from
    ideal because it forces each intermediate layer to continuously adapt to its changing
    inputs.Batch normalization is used to ameliorate this problem by normalizing the
    activations of each layer.In practice this is accomplished by adding two trainable
    parameters to each layer, so the normalized output is multiplied by a standard
    deviation parameter, and then shifted by a mean parameter. With this approach
    only two parameters are changed for each activation, as opposed to losing the
    stability of the network by changing all the weights. It is expected that through
    this method each layer will learn on a more stable distribution of inputs, which
    may accelerate the training stage.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络模型中每一层的权重在训练阶段会不断变化，这意味着每一层的激活值也会发生变化。鉴于任何给定层的激活值都是后续层的输入，这意味着每一步的输入分布都会变化。这远非理想，因为这迫使每个中间层不断适应其变化的输入。批量归一化（Batch
    normalization）用于改善这个问题，通过对每一层的激活值进行归一化来实现。在实际操作中，这通过向每一层添加两个可训练的参数来完成，因此归一化后的输出会乘以一个标准差参数，然后再加上一个均值参数。通过这种方法，每个激活值只改变两个参数，而不是通过改变所有权重来失去网络的稳定性。预计通过这种方法，每一层将会在一个更稳定的输入分布上进行学习，这可能加速训练阶段。
