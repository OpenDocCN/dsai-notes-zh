- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 20:00:21'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:00:21
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2007.08199] Learning from Noisy Labels with Deep Neural Networks: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2007.08199] 从嘈杂标签中学习的深度神经网络：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2007.08199](https://ar5iv.labs.arxiv.org/html/2007.08199)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2007.08199](https://ar5iv.labs.arxiv.org/html/2007.08199)
- en: \DeclareNewFootnote
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \DeclareNewFootnote
- en: '[para]A'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[para]A'
- en: 'Learning from Noisy Labels with Deep Neural Networks: A Survey'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从嘈杂标签中学习的深度神经网络：综述
- en: 'Hwanjun Song, Minseok Kim, Dongmin Park, Yooju Shin, Jae-Gil Lee H. Song is
    with NAVER AI Lab, Seongnam 13561, Republic of Korea (e-mail: hwanjun.song@navercorp.com);
    M. Kim, D, Park, Y, Shin, and J.-G., Lee are with the Graduate School of Knowledge
    Service Engineering, Korea Advanced Institute of Science and Technology, Daejeon
    34141, Republic of Korea (e-mail: minseokkim@kaist.ac.kr; dongminpark@kaist.ac.kr;
    yooju24@kaist.ac.kr; jaegil@kaist.ac.kr). This work has been submitted to the
    IEEE for possible publication. Copyright may be transferred without notice, after
    which this version may no longer be accessible.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Hwanjun Song、Minseok Kim、Dongmin Park、Yooju Shin、Jae-Gil Lee H. Song 现为 NAVER
    AI Lab 的研究员，地址为韩国城南市 13561（电子邮件：hwanjun.song@navercorp.com）；M. Kim、D. Park、Y.
    Shin 和 J.-G. Lee 均为韩国科学技术院知识服务工程研究生院的成员，地址为韩国大田市 34141（电子邮件：minseokkim@kaist.ac.kr；dongminpark@kaist.ac.kr；yooju24@kaist.ac.kr；jaegil@kaist.ac.kr）。该工作已提交至
    IEEE 进行可能的出版。版权可能会在未通知的情况下转让，届时该版本可能不再可用。
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep learning has achieved remarkable success in numerous domains with help
    from large amounts of big data. However, the quality of data labels is a concern
    because of the lack of high-quality labels in many real-world scenarios. As noisy
    labels severely degrade the generalization performance of deep neural networks,
    learning from noisy labels (robust training) is becoming an important task in
    modern deep learning applications. In this survey, we first describe the problem
    of learning with label noise from a supervised learning perspective. Next, we
    provide a comprehensive review of 62 state-of-the-art robust training methods,
    all of which are categorized into five groups according to their methodological
    difference, followed by a systematic comparison of six properties used to evaluate
    their superiority. Subsequently, we perform an in-depth analysis of noise rate
    estimation and summarize the typically used evaluation methodology, including
    public noisy datasets and evaluation metrics. Finally, we present several promising
    research directions that can serve as a guideline for future studies. All the
    contents will be available at [https://github.com/songhwanjun/Awesome-Noisy-Labels](https://github.com/songhwanjun/Awesome-Noisy-Labels).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在许多领域取得了显著成功，得益于大量的大数据。然而，由于许多现实场景中缺乏高质量标签，数据标签的质量成为了一个关注点。由于嘈杂标签严重影响深度神经网络的泛化性能，从嘈杂标签中学习（鲁棒训练）正成为现代深度学习应用中的一个重要任务。在本综述中，我们首先从监督学习的角度描述标签噪声学习的问题。接着，我们全面回顾了
    62 种最先进的鲁棒训练方法，这些方法根据其方法学差异被分类为五组，并系统比较了用于评估其优越性的六种特性。随后，我们对噪声率估计进行了深入分析，并总结了常用的评估方法，包括公共嘈杂数据集和评估指标。最后，我们提出了几条有前景的研究方向，作为未来研究的指导。所有内容将在
    [https://github.com/songhwanjun/Awesome-Noisy-Labels](https://github.com/songhwanjun/Awesome-Noisy-Labels)
    上提供。
- en: 'Index Terms:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: deep learning, noisy label, label noise, robust optimization, robust deep learning,
    classification, survey
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习，嘈杂标签，标签噪声，鲁棒优化，鲁棒深度学习，分类，综述
- en: I Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: With the recent emergence of large-scale datasets, deep neural networks (DNNs)
    have exhibited impressive performance in numerous machine learning tasks, such
    as computer vision [[1](#bib.bib1), [2](#bib.bib2)], information retrieval [[3](#bib.bib3),
    [4](#bib.bib4), [5](#bib.bib5)], and language processing [[6](#bib.bib6), [7](#bib.bib7),
    [8](#bib.bib8)]. Their success is dependent on the availability of massive but
    carefully labeled data, which are expensive and time-consuming to obtain. Some
    non-expert sources, such as Amazon’s Mechanical Turk and the surrounding text
    of collected data, have been widely used to mitigate the high labeling cost; however,
    the use of these source often results in unreliable labels [[9](#bib.bib9), [10](#bib.bib10),
    [11](#bib.bib11), [12](#bib.bib12)]. In addition, data labels can be extremely
    complex even for experienced domain experts [[13](#bib.bib13), [14](#bib.bib14)];
    they can also be adversarially manipulated by a label-flipping attack [[15](#bib.bib15)].
    Such unreliable labels are called *noisy labels* because they may be *corrupted*
    from ground-truth labels. The ratio of corrupted labels in real-world datasets
    is reported to range from $8.0\%$ to $38.5\%$ [[16](#bib.bib16), [17](#bib.bib17),
    [18](#bib.bib18), [19](#bib.bib19)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大规模数据集的出现，深度神经网络（DNNs）在众多机器学习任务中表现出令人印象深刻的性能，如计算机视觉 [[1](#bib.bib1), [2](#bib.bib2)]、信息检索
    [[3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5)] 和语言处理 [[6](#bib.bib6), [7](#bib.bib7),
    [8](#bib.bib8)]。它们的成功依赖于海量但经过精心标注的数据，这些数据的获取既昂贵又耗时。一些非专家来源，如亚马逊的Mechanical Turk和收集数据的周边文本，被广泛用来缓解高标注成本的问题；然而，这些来源的使用通常会导致标签不可靠
    [[9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12)]。此外，即使对于经验丰富的领域专家，数据标签也可能非常复杂
    [[13](#bib.bib13), [14](#bib.bib14)]；它们还可能受到标签翻转攻击 [[15](#bib.bib15)] 的对抗性操控。这些不可靠的标签被称为*噪声标签*，因为它们可能*与真实标签*相悖。报告指出，现实世界数据集中被污染标签的比例从$8.0\%$到$38.5\%$不等
    [[16](#bib.bib16), [17](#bib.bib17), [18](#bib.bib18), [19](#bib.bib19)]。
- en: 'In the presence of noisy labels, training DNNs is known to be susceptible to
    noisy labels because of the significant number of model parameters that render
    DNNs overfit to even corrupted labels with the capability of learning any complex
    function [[20](#bib.bib20), [21](#bib.bib21)]. Zhang et al. [[22](#bib.bib22)]
    demonstrated that DNNs can easily fit an entire training dataset with any ratio
    of corrupted labels, which eventually resulted in poor generalizability on a test
    dataset. Unfortunately, popular regularization techniques, such as data augmentation
    [[23](#bib.bib23)], weight decay [[24](#bib.bib24)], dropout [[25](#bib.bib25)],
    and batch normalization [[26](#bib.bib26)] have been applied extensively, but
    they do *not* completely overcome the overfitting issue by themselves. As shown
    in Figure [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Learning from Noisy Labels with
    Deep Neural Networks: A Survey"), the gap in test accuracy between models trained
    on clean and noisy data remains significant even though all of the aforementioned
    regularization techniques are activated. Additionally, the accuracy drop with
    label noise is considered to be more harmful than with other noises, such as input
    noise [[27](#bib.bib27)]. Hence, achieving a good generalization capability in
    the presence of noisy labels is a key challenge.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '在存在噪声标签的情况下，训练DNNs被认为容易受到噪声标签的影响，因为模型参数众多使得DNNs对即使是被污染的标签也容易过拟合，具备学习任何复杂函数的能力
    [[20](#bib.bib20), [21](#bib.bib21)]。张等 [[22](#bib.bib22)] 证明了DNNs可以轻松拟合任何比例的被污染标签的整个训练数据集，这最终导致在测试数据集上的泛化能力差。不幸的是，虽然数据增强
    [[23](#bib.bib23)]、权重衰减 [[24](#bib.bib24)]、dropout [[25](#bib.bib25)] 和批量归一化 [[26](#bib.bib26)]
    等流行的正则化技术已被广泛应用，但它们*不能*单独完全克服过拟合问题。如图 [1](#S1.F1 "Figure 1 ‣ I Introduction ‣
    Learning from Noisy Labels with Deep Neural Networks: A Survey") 所示，即使激活了所有上述正则化技术，模型在干净数据和噪声数据上训练的测试准确率差距依然显著。此外，标签噪声造成的准确率下降被认为比其他噪声，如输入噪声
    [[27](#bib.bib27)]，更具危害。因此，在噪声标签存在的情况下实现良好的泛化能力是一个关键挑战。'
- en: '![Refer to caption](img/9652535680cd27cfc7f591f0cdba6866.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9652535680cd27cfc7f591f0cdba6866.png)'
- en: 'Figure 1: Convergence curves of training and test accuracy when training WideResNet-16-8
    using a standard training method on the CIFAR-100 dataset with the symmetric noise
    of $40\%$: “Noisy w/o. Reg.” and “Noisy w. Reg.” are the models trained on noisy
    data without and with regularization, respectively, and “Clean w. Reg.” is the
    model trained on clean data with regularization.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：使用标准训练方法在CIFAR-100数据集上训练WideResNet-16-8时的训练和测试精度收敛曲线，其中对称噪声为$40\%$：“Noisy
    w/o. Reg.”和“Noisy w. Reg.”分别是训练于有噪声数据的无正则化和有正则化模型，“Clean w. Reg.”是训练于干净数据的有正则化模型。
- en: 'Several studies have been conducted to investigate supervised learning under
    noisy labels. Beyond conventional machine learning techniques [[13](#bib.bib13),
    [28](#bib.bib28)], deep learning techniques have recently gained significant attention
    in the machine learning community. In this survey, we present the advances in
    recent deep learning techniques for overcoming noisy labels. We surveyed recent
    studies by recursively tracking relevant bibliographies in papers published at
    premier research conferences, such as CVPR, ICCV, NeurIPS, ICML, and ICLR. Although
    we attempted to comprehensively include all recent studies at the time of submission,
    some of them may not be included because of the quadratic increase in deep learning
    papers. The studies included were grouped into *five* categories, as shown in
    Figure [2](#S1.F2 "Figure 2 ‣ I Introduction ‣ Learning from Noisy Labels with
    Deep Neural Networks: A Survey") (see Section [III](#S3 "III Deep Learning Approaches
    ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey") for details).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了研究在噪声标签下的监督学习，已经进行了多项研究。除了传统的机器学习技术 [[13](#bib.bib13), [28](#bib.bib28)]，深度学习技术最近在机器学习社区中获得了显著关注。在这项调查中，我们呈现了克服噪声标签的最新深度学习技术进展。我们通过递归追踪在主要研究会议上发布的论文中的相关参考文献，如CVPR、ICCV、NeurIPS、ICML和ICLR，来调查近期的研究。尽管我们试图全面纳入提交时所有近期研究，但由于深度学习论文的数量呈平方增长，可能有些未被包括。所包括的研究被分为*五*个类别，如图[2](#S1.F2
    "图2 ‣ I 介绍 ‣ 通过深度神经网络从噪声标签中学习：一项调查")所示（详情见第[III](#S3 "III 深度学习方法 ‣ 通过深度神经网络从噪声标签中学习：一项调查")节）。
- en: '![Refer to caption](img/8aed60e5d07d2f16cc4c2312ee8812a0.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8aed60e5d07d2f16cc4c2312ee8812a0.png)'
- en: 'Figure 2: Categorization of recent deep learning methods for overcomming noisy
    labels.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：克服噪声标签的最新深度学习方法的分类。
- en: I-A Related Surveys
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-A 相关调查
- en: 'Frénay and Verleysen [[13](#bib.bib13)] discussed the potential negative consequence
    of learning from noisy labels and provided a comprehensive survey on noise-robust
    classification methods, focusing on conventional supervised approaches such as
    naïve Bayes and support vector machines. Furthermore, their survey included the
    definitions and sources of label noise as well as the taxonomy of label noise.
    Zhang et al. [[28](#bib.bib28)] discussed another aspect of label noise in crowdsourced
    data annotated by non-experts and provided a thorough review of expectation-maximization
    (EM) algorithms that were proposed to improve the quality of crowdsourced labels.
    Meanwhile, Nigam et al. [[29](#bib.bib29)] provided a brief introduction to deep
    learning algorithms that were proposed to manage noisy labels; however, the scope
    of these algorithms was limited to only two categories, i.e., the loss function
    and sample selection in Figure [2](#S1.F2 "Figure 2 ‣ I Introduction ‣ Learning
    from Noisy Labels with Deep Neural Networks: A Survey"). Recently, Han et al.
    [[30](#bib.bib30)] summarized the essential components of robust learning with
    noisy labels, but their categorization is totally different from ours in philosophy;
    we mainly focus on systematic methodological difference, whereas they rather focused
    on more general views, such as input data, objective functions, and optimization
    policies. Furthermore, this survey is the first to present a comprehensive methodological
    comparison of existing robust training approaches (see Tables [II](#S3.T2 "Table
    II ‣ III-E3 Hybrid Approach ‣ III-E Sample Selection ‣ III Deep Learning Approaches
    ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey") and [III](#S3.T3
    "Table III ‣ III-E3 Hybrid Approach ‣ III-E Sample Selection ‣ III Deep Learning
    Approaches ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey")).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 'Frénay 和 Verleysen [[13](#bib.bib13)] 讨论了从噪声标签中学习的潜在负面影响，并提供了关于噪声鲁棒分类方法的综合综述，重点关注传统的监督方法，如朴素贝叶斯和支持向量机。此外，他们的综述包括了标签噪声的定义和来源以及标签噪声的分类。张等人
    [[28](#bib.bib28)] 讨论了另一个方面的标签噪声，即由非专家注释的众包数据，并对期望最大化（EM）算法进行了详细回顾，这些算法旨在提高众包标签的质量。与此同时，Nigam
    等人 [[29](#bib.bib29)] 对于处理噪声标签的深度学习算法进行了简要介绍；然而，这些算法的范围仅限于两类，即损失函数和样本选择（见图 [2](#S1.F2
    "Figure 2 ‣ I Introduction ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")）。最近，Han 等人 [[30](#bib.bib30)] 总结了处理噪声标签的鲁棒学习的核心组件，但他们的分类在理念上与我们完全不同；我们主要关注系统方法的差异，而他们则关注更一般的观点，如输入数据、目标函数和优化策略。此外，本综述首次提供了现有鲁棒训练方法的全面方法学比较（见表
    [II](#S3.T2 "Table II ‣ III-E3 Hybrid Approach ‣ III-E Sample Selection ‣ III
    Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey") 和 [III](#S3.T3 "Table III ‣ III-E3 Hybrid Approach ‣ III-E Sample Selection
    ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")）。'
- en: I-B Survey Scope
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-B 综述范围
- en: Robust training with DNNs becomes critical to guarantee the reliability of machine
    learning algorithms. In addition to label noise, two types of flawed training
    data have been actively studied by different communities [[31](#bib.bib31), [32](#bib.bib32)].
    *Adversarial learning* is designed for small, worst-case perturbations of the
    inputs, so-called adversarial examples, which are maliciously constructed to deceive
    an already trained model into making errors [[33](#bib.bib33), [34](#bib.bib34),
    [35](#bib.bib35), [36](#bib.bib36)]. Meanwhile, *data imputation* primarily deals
    with missing inputs in training data, where missing values are estimated from
    the observed ones [[37](#bib.bib37), [32](#bib.bib32)]. Adversarial learning and
    data imputation are closely related to robust learning, but handling *feature*
    noise is beyond the scope of this survey—i.e., learning from noisy *labels*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用深度神经网络（DNNs）进行鲁棒训练变得至关重要，以保证机器学习算法的可靠性。除了标签噪声，两个类型的有缺陷训练数据已经被不同社区积极研究[[31](#bib.bib31),
    [32](#bib.bib32)]。*对抗学习*旨在处理输入的小范围、最坏情况扰动，即对抗样本，这些样本是恶意构造的，目的是欺骗已经训练好的模型，使其出现错误[[33](#bib.bib33),
    [34](#bib.bib34), [35](#bib.bib35), [36](#bib.bib36)]。与此同时，*数据填补*主要处理训练数据中的缺失输入，其中缺失值是从观察到的值中估算得出的[[37](#bib.bib37),
    [32](#bib.bib32)]。对抗学习和数据填补与鲁棒学习密切相关，但处理*特征*噪声超出了本综述的范围——即，学习来自噪声*标签*。
- en: II Preliminaries
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 初步准备
- en: 'In this section, the problem statement for supervised learning with noisy labels
    is provided along with the taxonomy of label noise. Managing noisy labels is a
    long-standing issue; therefore, we review the basic conventional approaches and
    theoretical foundations underlying robust deep learning. Table [I](#S2.T1 "Table
    I ‣ II Preliminaries ‣ Learning from Noisy Labels with Deep Neural Networks: A
    Survey") summarizes the notation frequently used in this study.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了带噪标签的监督学习问题陈述以及标签噪声的分类。管理噪声标签是一个长期存在的问题，因此我们回顾了基本的传统方法和支撑鲁棒深度学习的理论基础。表
    [I](#S2.T1 "表 I ‣ II 前言 ‣ 从带噪标签的深度神经网络中学习：综述") 总结了本研究中频繁使用的符号。
- en: 'Table I: Summary of the notation.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：符号说明汇总。
- en: '| ​​Notation |                      Description |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 符号 | 描述 |'
- en: '| $\mathcal{X}$ | the data feature space |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{X}$ | 数据特征空间 |'
- en: '| $\mathcal{Y}$, $\tilde{\mathcal{Y}}$ | the true and noisy label space |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{Y}$, $\tilde{\mathcal{Y}}$ | 真实和噪声标签空间 |'
- en: '| $\mathcal{D}$, $\tilde{\mathcal{D}}$ | the clean and noisy training data
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{D}$, $\tilde{\mathcal{D}}$ | 清洁和噪声训练数据 |'
- en: '| $P_{\mathcal{D}}$, $P_{\tilde{\mathcal{D}}}$ | the joint distributions of
    clean and noisy data |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| $P_{\mathcal{D}}$, $P_{\tilde{\mathcal{D}}}$ | 清洁数据和噪声数据的联合分布 |'
- en: '| $\mathcal{B}_{t}$ | a set of mini-batch examples at time $t$ |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{B}_{t}$ | 时间 $t$ 的小批量样本集合 |'
- en: '| $\Theta_{t}$ | the parameter of a deep neural network at time $t$ |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| $\Theta_{t}$ | 时间 $t$ 的深度神经网络参数 |'
- en: '| $f(\,\cdot\,;\Theta_{t})$ | a deep neural network parameterized by $\Theta_{t}$
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| $f(\,\cdot\,;\Theta_{t})$ | 由 $\Theta_{t}$ 参数化的深度神经网络 |'
- en: '| $\ell$ | a specific loss function |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| $\ell$ | 特定的损失函数 |'
- en: '| $\mathcal{R}$ | an empirical risk |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{R}$ | 经验风险 |'
- en: '| $\mathbb{E}_{\mathcal{D}}$ | an expectation over $\mathcal{D}$ |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbb{E}_{\mathcal{D}}$ | 对 $\mathcal{D}$ 的期望 |'
- en: '| $x$, $x_{i}$ | a data example of $\mathcal{X}$ |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| $x$, $x_{i}$ | $\mathcal{X}$ 的数据样本 |'
- en: '| $y$, $y_{i}$ | a true label of $\mathcal{Y}$ |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| $y$, $y_{i}$ | $\mathcal{Y}$ 的真实标签 |'
- en: '| $\tilde{y}$, $\tilde{y}_{i}$ | a noisy label of $\tilde{\mathcal{Y}}$ |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| $\tilde{y}$, $\tilde{y}_{i}$ | $\tilde{\mathcal{Y}}$ 的噪声标签 |'
- en: '| $\eta$ | a specific learning rate |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| $\eta$ | 特定的学习率 |'
- en: '| $\tau$ | a true noise rate |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| $\tau$ | 真实噪声率 |'
- en: '| $b$ | the number of mini-batch examples in $\mathcal{B}_{t}$ |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| $b$ | $\mathcal{B}_{t}$ 中的小批量样本数量 |'
- en: '| $c$ | the number of classes |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| $c$ | 类别数 |'
- en: '| T, $\hat{\text{T}}$ | the true and estimated noise transition matrix |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| T, $\hat{\text{T}}$ | 真实和估计的噪声转换矩阵 |'
- en: '![Refer to caption](img/aba79f256c3c8d1377c0b52c41755fad.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/aba79f256c3c8d1377c0b52c41755fad.png)'
- en: 'Figure 3: A high level research overview of robust deep learning for noisy
    labels. The research directions that are actively contributed by the machine learning
    community are categorized into five groups in blue italic.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：针对噪声标签的鲁棒深度学习的高层次研究概览。由机器学习社区积极贡献的研究方向被分类为五组，使用蓝色斜体表示。
- en: II-A Supervised Learning with Noisy Labels
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 带噪标签的监督学习
- en: '*Classification* is a representative supervised learning task for learning
    a function that maps an input feature to a label [[38](#bib.bib38)]. In this paper,
    we consider a $c$-class classification problem using a DNN with a softmax output
    layer. Let $\mathcal{X}\subset\mathbb{R}^{d}$ be the feature space and $\mathcal{Y}=\{0,1\}^{c}$
    be the ground-truth label space in a *one-hot* manner. In a typical classification
    problem, we are provided with a training dataset $\mathcal{D}=\{(x_{i},y_{i})\}_{i=1}^{N}$
    obtained from an unknown joint distribution $P_{\mathcal{D}}$ over $\mathcal{X}\times\mathcal{Y}$,
    where each $(x_{i},y_{i})$ is *independent and identically distributed*. The goal
    of the task is to learn the mapping function $f(\,\cdot\,;\Theta):\mathcal{X}\rightarrow[0,1]^{c}$
    of the DNN parameterized by $\Theta$ such that the parameter $\Theta$ minimizes
    the empirical risk $\mathcal{R}_{\mathcal{D}}(f)$,'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*分类* 是一种典型的监督学习任务，旨在学习一个将输入特征映射到标签的函数 [[38](#bib.bib38)]。本文考虑使用具有 softmax 输出层的
    DNN 进行 $c$ 类分类问题。设 $\mathcal{X}\subset\mathbb{R}^{d}$ 为特征空间，$\mathcal{Y}=\{0,1\}^{c}$
    为以 *one-hot* 方式表示的真实标签空间。在典型的分类问题中，我们获得了从未知联合分布 $P_{\mathcal{D}}$ 上的 $\mathcal{X}\times\mathcal{Y}$
    得到的训练数据集 $\mathcal{D}=\{(x_{i},y_{i})\}_{i=1}^{N}$，其中每个 $(x_{i},y_{i})$ 是 *独立同分布*
    的。任务的目标是学习 DNN 的映射函数 $f(\,\cdot\,;\Theta):\mathcal{X}\rightarrow[0,1]^{c}$，使得参数
    $\Theta$ 最小化经验风险 $\mathcal{R}_{\mathcal{D}}(f)$，'
- en: '|  | $\!\!\mathcal{R}_{\mathcal{D}}(f)=\mathbb{E}_{\mathcal{D}}[\ell\big{(}f(x;\Theta),y\big{)}]=\frac{1}{&#124;\mathcal{D}&#124;}\!\sum_{(x,y)\in\mathcal{D}}\!\!\!\!\ell\big{(}f(x;\Theta),y\big{)},$
    |  | (1) |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | $\!\!\mathcal{R}_{\mathcal{D}}(f)=\mathbb{E}_{\mathcal{D}}[\ell\big{(}f(x;\Theta),y\big{)}]=\frac{1}{\vert\mathcal{D}\vert}\!\sum_{(x,y)\in\mathcal{D}}\!\!\!\!\ell\big{(}f(x;\Theta),y\big{)},$
    |  | (1) |'
- en: where $\ell$ is a certain loss function.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\ell$ 是某个损失函数。
- en: As data labels are corrupted in various real-world scenarios, we aim to train
    the DNN from noisy labels. Specifically, we are provided with a noisy training
    dataset $\tilde{\mathcal{D}}=\{(x_{i},\tilde{y}_{i})\}_{i=1}^{N}$ obtained from
    a noisy joint distribution $P_{\tilde{\mathcal{D}}}$ over $\mathcal{X}\times\tilde{\mathcal{Y}}$,
    where $\tilde{y}$ is a *noisy* label which may not be true. Hence, following the
    standard training procedure, a mini-batch $\mathcal{B}_{t}=\{(x_{i},\tilde{y}_{i})\}_{i=1}^{b}$
    comprising $b$ examples is obtained randomly from the noisy training dataset $\tilde{\mathcal{D}}$
    at time $t$. Subsequently, the DNN parameter $\Theta_{t}$ at time $t$ is updated
    along the descent direction of the empirical risk on mini-batch $\mathcal{B}_{t}$,
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据标签在各种现实世界场景中被破坏，我们的目标是从噪声标签中训练 DNN。具体来说，我们获得了从噪声联合分布 $P_{\tilde{\mathcal{D}}}$
    上得到的噪声训练数据集 $\tilde{\mathcal{D}}=\{(x_{i},\tilde{y}_{i})\}_{i=1}^{N}$，其中 $\tilde{y}$
    是可能不真实的*噪声*标签。因此，按照标准训练程序，时间 $t$ 时从噪声训练数据集 $\tilde{\mathcal{D}}$ 随机获得一个包含 $b$
    个示例的迷你批次 $\mathcal{B}_{t}=\{(x_{i},\tilde{y}_{i})\}_{i=1}^{b}$。随后，时间 $t$ 时的 DNN
    参数 $\Theta_{t}$ 沿着迷你批次 $\mathcal{B}_{t}$ 上经验风险的下降方向进行更新，
- en: '|  | $\Theta_{t+1}=\Theta_{t}-\eta\nabla\Big{(}\frac{1}{&#124;\mathcal{B}_{t}&#124;}\!\sum_{(x,\tilde{y})\in\mathcal{B}_{t}}\!\!\!\!\ell\big{(}f(x;\Theta_{t}),\tilde{y}\big{)}\Big{)},$
    |  | (2) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  | $\Theta_{t+1}=\Theta_{t}-\eta\nabla\Big{(}\frac{1}{\vert\mathcal{B}_{t}\vert}\!\sum_{(x,\tilde{y})\in\mathcal{B}_{t}}\!\!\!\!\ell\big{(}f(x;\Theta_{t}),\tilde{y}\big{)}\Big{)},$
    |  | (2) |'
- en: where $\eta$ is a learning rate specified.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\eta$ 是指定的学习率。
- en: Here, the risk minimization process is no longer *noise-tolerant* because of
    the loss computed by the noisy labels. DNNs can easily memorize corrupted labels
    and correspondingly degenerate their generalizations on unseen data [[13](#bib.bib13),
    [28](#bib.bib28), [29](#bib.bib29)]. Hence, mitigating the adverse effects of
    noisy labels is essential to enable noise-tolerant training for deep learning.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，由于噪声标签计算的损失，风险最小化过程不再*耐噪声*。深度神经网络（DNNs）可以轻易地记住被破坏的标签，从而使其对未见数据的泛化能力退化 [[13](#bib.bib13),
    [28](#bib.bib28), [29](#bib.bib29)]。因此，减轻标签噪声的不利影响对于实现深度学习的噪声容忍训练至关重要。
- en: II-B Taxonomy of Label Noise
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 标签噪声分类
- en: This section presents the types of label noise that have been adopted to design
    robust training algorithms. Even if data labels are corrupted from ground-truth
    labels without *any* prior assumption, in essence, the corruption probability
    is affected by the dependency between *data features* or *class labels*. A detailed
    analysis of the taxonomy of label noise was provided by Frénay and Verleysen [[13](#bib.bib13)].
    Most existing algorithms dealt with instance-independent noise, but instance-dependent
    noise has not yet been extensively investigated owing to its complex modeling.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了为设计稳健训练算法而采用的标签噪声类型。即使数据标签被从真实标签中*任意*地破坏，从本质上讲，破坏概率受*数据特征*或*类别标签*之间依赖关系的影响。Frénay
    和 Verleysen 提供了标签噪声分类的详细分析 [[13](#bib.bib13)]。大多数现有算法处理的是实例无关噪声，但由于其复杂的建模，实例依赖噪声尚未得到广泛研究。
- en: II-B1 Instance-independent Label Noise
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B1 实例无关标签噪声
- en: A typical approach for modeling label noise assumes that the corruption process
    is conditionally *independent* of data features when the true label is given [[39](#bib.bib39),
    [22](#bib.bib22)]. That is, the true label is corrupted by a *noise transition
    matrix* $\text{T}\in[0,1]^{c\times c}$, where $\text{T}_{ij}\coloneqq p(\tilde{y}=j|y=i)$
    is the probability of the true label $i$ being flipped into a corrupted label
    $j$. In this approach, the noise is called a *symmetric* (or *uniform*) noise
    with a noise rate $\tau\in[0,1]$ if $\forall_{i=j}\text{T}_{ij}\!=\!1-\tau\wedge\forall_{i\neq
    j}\text{T}_{ij}=\frac{\tau}{c-1}$, where a true label is flipped into other labels
    with equal probability. In contrast to symmetric noise, the noise is called an
    *asymmetric* (or *label-dependent*) noise if $\forall_{i=j}\text{T}_{ij}\!=\!1-\tau\wedge\exists_{i\neq
    j,i\neq k,j\neq k}\text{T}_{ij}>\text{T}_{ik}$, where a true label is more likely
    to be mislabeled into a particular label. For example, a “dog” is more likely
    to be confused with a “cat” than with a “fish.” In a stricter case when $\forall_{i=j}\text{T}_{ij}\!=\!1-\tau\wedge\exists_{i\neq
    j}\text{T}_{ij}=\tau$, the noise is called a *pair noise*, where a true label
    is flipped into only a certain label.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一种典型的标签噪声建模方法假设，当给定真实标签时，腐蚀过程在条件上与数据特征*独立*[[39](#bib.bib39), [22](#bib.bib22)]。也就是说，真实标签通过*噪声转移矩阵*
    $\text{T}\in[0,1]^{c\times c}$ 被腐蚀，其中 $\text{T}_{ij}\coloneqq p(\tilde{y}=j|y=i)$
    是真实标签 $i$ 被翻转为腐蚀标签 $j$ 的概率。在这种方法中，如果 $\forall_{i=j}\text{T}_{ij}\!=\!1-\tau\wedge\forall_{i\neq
    j}\text{T}_{ij}=\frac{\tau}{c-1}$，噪声被称为*对称*（或*均匀*）噪声，噪声率为 $\tau\in[0,1]$，即真实标签以相等的概率被翻转为其他标签。与对称噪声相反，如果
    $\forall_{i=j}\text{T}_{ij}\!=\!1-\tau\wedge\exists_{i\neq j,i\neq k,j\neq k}\text{T}_{ij}>\text{T}_{ik}$，则噪声称为*不对称*（或*标签相关*）噪声，其中真实标签更有可能被错误标记为特定标签。例如，“狗”更可能与“猫”混淆，而不是与“鱼”混淆。在更严格的情况下，当
    $\forall_{i=j}\text{T}_{ij}\!=\!1-\tau\wedge\exists_{i\neq j}\text{T}_{ij}=\tau$
    时，噪声被称为*配对噪声*，其中真实标签仅被翻转为某个特定标签。
- en: II-B2 Instance-dependent Label Noise
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B2 实例依赖标签噪声
- en: For more realistic noise modeling, the corruption probability is assumed to
    be *dependent* on both the data features and class labels [[16](#bib.bib16), [40](#bib.bib40)].
    Accordingly, the corruption probability is defined as $\rho_{ij}(x)\!=\!p(\tilde{y}\!=\!j|y\!=\!i,x)$.
    Unlike the aforementioned noises, the data feature of an example $x$ also affects
    the chance of $x$ being mislabeled.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更现实的噪声建模，假设腐蚀概率*依赖*于数据特征和类别标签[[16](#bib.bib16), [40](#bib.bib40)]。因此，腐蚀概率定义为
    $\rho_{ij}(x)\!=\!p(\tilde{y}\!=\!j|y\!=\!i,x)$。与上述噪声不同，示例 $x$ 的数据特征也会影响 $x$ 被错误标记的机会。
- en: II-C Non-deep Learning Approaches
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 非深度学习方法
- en: 'For decades, numerous methods have been proposed to manage noisy labels using
    conventional machine learning techniques. These methods can be categorized into
    *four* groups [[13](#bib.bib13), [41](#bib.bib41), [29](#bib.bib29)], as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，许多方法被提出用来管理噪声标签，这些方法使用传统的机器学习技术。这些方法可以被分为*四*组[[13](#bib.bib13), [41](#bib.bib41),
    [29](#bib.bib29)]，如下：
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Data Cleaning: Training data are cleaned by excluding examples whose labels
    are likely to be corrupted. Bagging and boosting are used to filter out false-labeled
    examples to remove examples with higher weights because false-labeled examples
    tend to exhibit much higher weights than true-labeled examples [[42](#bib.bib42),
    [43](#bib.bib43)]. In addition, various methods, such as $k$-nearest neighbor,
    outlier detection, and anomaly detection, have been widely exploited to exclude
    false-labeled examples from noisy training data [[44](#bib.bib44), [45](#bib.bib45),
    [46](#bib.bib46)]. Nevertheless, this family of methods suffers from over-cleaning
    issue that overly removes even the true-labeled examples.'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据清洗：通过排除标签可能被腐蚀的示例来清洗训练数据。使用自助法和提升法来筛选错误标记的示例，以移除权重较高的示例，因为错误标记的示例往往具有比真实标记的示例更高的权重[[42](#bib.bib42),
    [43](#bib.bib43)]。此外，各种方法，如 $k$-近邻、异常值检测和异常检测，已广泛应用于从噪声训练数据中排除错误标记的示例[[44](#bib.bib44),
    [45](#bib.bib45), [46](#bib.bib46)]。尽管如此，这类方法存在过度清洗的问题，可能过度删除甚至真实标记的示例。
- en: •
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Surrogate Loss: Motivated by the noise-tolerance of the 0-1 loss function [[39](#bib.bib39)],
    many researchers have attempted to resolve its inherent limitations, such as computational
    hardness and non-convexity that render gradient methods unusable. Hence, several
    convex surrogate loss functions, which approximate the 0-1 loss function, have
    been proposed to train a specified classifier under the binary classification
    setting [[47](#bib.bib47), [48](#bib.bib48), [49](#bib.bib49), [50](#bib.bib50),
    [51](#bib.bib51)]. However, these loss functions cannot support the multi-class
    classification task.'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 替代损失：受到 0-1 损失函数的噪声容忍性的启发 [[39](#bib.bib39)]，许多研究者尝试解决其固有的局限性，如计算困难和非凸性，这使得梯度方法无法使用。因此，已经提出了几种凸替代损失函数，这些函数近似于
    0-1 损失函数，用于在二分类设置下训练指定的分类器 [[47](#bib.bib47), [48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50), [51](#bib.bib51)]。然而，这些损失函数不能支持多分类任务。
- en: •
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Probabilistic Method: Under the assumption that the distribution of features
    is helpful in solving the problem of learning from noisy labels [[52](#bib.bib52)],
    the confidence of each label is estimated by clustering and then used for a weighted
    training scheme [[53](#bib.bib53)]. This confidence is also used to convert hard
    labels into soft labels to reflect the uncertainty of labels [[54](#bib.bib54)].
    In addition to these clustering approaches, several Bayesian methods have been
    proposed for graphical models such that they can benefit from using any type of
    prior information in the learning process [[55](#bib.bib55)]. However, this family
    of methods may exacerbate the overfitting issue owing to the increased number
    of model parameters.'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 概率方法：在特征分布有助于解决带噪声标签的学习问题的假设下 [[52](#bib.bib52)]，通过聚类估计每个标签的置信度，然后用于加权训练方案 [[53](#bib.bib53)]。这种置信度也用于将硬标签转换为软标签，以反映标签的不确定性
    [[54](#bib.bib54)]。除了这些聚类方法外，还提出了几种贝叶斯方法用于图模型，使其能够在学习过程中利用任何类型的先验信息 [[55](#bib.bib55)]。然而，这一类方法可能由于模型参数数量增加而加剧过拟合问题。
- en: •
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model-based Method: As conventional models, such as the SVM and decision tree,
    are not robust to noisy labels, significant effort has been expended to improve
    the robustness of them. To develop a robust SVM model, misclassified examples
    during learning are penalized in the objective [[56](#bib.bib56), [57](#bib.bib57)].
    In addition, several decision tree models are extended using new split criteria
    to solve the overfitting issue when the training data are not fully reliable [[58](#bib.bib58),
    [59](#bib.bib59)]. However, it is infeasible to apply their design principles
    to deep learning.'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于模型的方法：由于传统模型，如 SVM 和决策树，对噪声标签不够鲁棒，已经投入了大量的精力来提高其鲁棒性。为了开发一个鲁棒的 SVM 模型，学习过程中的错误分类示例在目标函数中受到惩罚
    [[56](#bib.bib56), [57](#bib.bib57)]。此外，多个决策树模型通过新的分裂标准得以扩展，以解决当训练数据不完全可靠时的过拟合问题
    [[58](#bib.bib58), [59](#bib.bib59)]。然而，将这些设计原则应用于深度学习是不切实际的。
- en: Meanwhile, deep learning is more susceptible to label noises than traditional
    machine learning owing to its high expressive power, as proven by many researchers
    [[21](#bib.bib21), [60](#bib.bib60), [61](#bib.bib61)]. There has been significant
    effort to understand why noisy labels negatively affect the performance of DNNs
    [[62](#bib.bib62), [22](#bib.bib22), [61](#bib.bib61), [63](#bib.bib63)]. This
    theoretical understanding has led to the algorithmic design which achieves higher
    robustness than non-deep learning methods. A detailed analysis of theoretical
    understanding for robust deep learning was provided by Han et al. [[30](#bib.bib30)].
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，由于深度学习的高表达能力，它比传统机器学习更容易受到标签噪声的影响，这一点已被许多研究者证明 [[21](#bib.bib21), [60](#bib.bib60),
    [61](#bib.bib61)]。已经投入了大量的精力来理解噪声标签为什么会对 DNN 的性能产生负面影响 [[62](#bib.bib62), [22](#bib.bib22),
    [61](#bib.bib61), [63](#bib.bib63)]。这种理论理解已经导致了算法设计，能够比非深度学习方法实现更高的鲁棒性。Han 等人提供了对鲁棒深度学习理论理解的详细分析
    [[30](#bib.bib30)]。
- en: II-D Regression with Noisy Labels
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-D 带噪声标签的回归
- en: In addition to classification, regression is another main topic of supervised
    machine learning, which aims to model the relationship between a number of features
    and a continuous target variable. Unlike the classification task with a *discrete*
    label space, the regression task considers the continuous variable as its target
    label [[64](#bib.bib64)], and thus it learns the mapping function $f(\leavevmode\nobreak\
    \cdot\leavevmode\nobreak\ ;\Theta):\mathcal{X}\rightarrow\mathcal{Y}$, where $\mathcal{Y}\in\mathbb{R}$
    is a *continuous* label space. Given the input feature $x$ and its ground-truth
    label $y$, two types of label noise are considered in the regression task. An
    *additive noise* [[65](#bib.bib65)] is formulated by $\tilde{y}:=y+\epsilon$ where
    $\epsilon$ is drawn from a random distribution independent from the input feature;
    an *instance-dependent noise* [[66](#bib.bib66)] is formulated by $\tilde{y}:=\rho(x)$
    where $\rho:\mathcal{X}\rightarrow\mathcal{Y}$ is a noise function dependent on
    the input feature.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 除了分类，回归是监督机器学习的另一个主要主题，旨在建模多个特征与连续目标变量之间的关系。与具有*离散*标签空间的分类任务不同，回归任务将连续变量视为其目标标签
    [[64](#bib.bib64)]，因此它学习映射函数 $f(\leavevmode\nobreak\ \cdot\leavevmode\nobreak\
    ;\Theta):\mathcal{X}\rightarrow\mathcal{Y}$，其中 $\mathcal{Y}\in\mathbb{R}$ 是一个*连续*标签空间。给定输入特征
    $x$ 和其真实标签 $y$，回归任务中考虑了两种类型的标签噪声。一种是*加性噪声* [[65](#bib.bib65)]，通过 $\tilde{y}:=y+\epsilon$
    表示，其中 $\epsilon$ 从与输入特征无关的随机分布中抽取；另一种是*实例相关噪声* [[66](#bib.bib66)]，通过 $\tilde{y}:=\rho(x)$
    表示，其中 $\rho:\mathcal{X}\rightarrow\mathcal{Y}$ 是一个依赖于输入特征的噪声函数。
- en: Although regression predicts continuous values, regression and classification
    share the same concept of learning the mapping function from the input feature
    $x$ to the output label $y$. Thus, many robust approaches for classification are
    easily extended to the regression problem with simple modification [[67](#bib.bib67)].
    Thus, in this survey, we focus on the classification setting for which most robust
    methods are defined.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管回归预测连续值，但回归和分类共享从输入特征 $x$ 到输出标签 $y$ 的映射函数的学习概念。因此，许多针对分类的鲁棒方法可以通过简单修改轻松扩展到回归问题
    [[67](#bib.bib67)]。因此，在本综述中，我们专注于定义了大多数鲁棒方法的分类设置。
- en: III Deep Learning Approaches
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 深度学习方法
- en: 'According to our comprehensive survey, the robustness of deep learning can
    be enhanced in numerous approaches [[68](#bib.bib68), [16](#bib.bib16), [25](#bib.bib25),
    [69](#bib.bib69), [70](#bib.bib70), [71](#bib.bib71), [72](#bib.bib72), [73](#bib.bib73),
    [74](#bib.bib74)]. Figure [3](#S2.F3 "Figure 3 ‣ II Preliminaries ‣ Learning from
    Noisy Labels with Deep Neural Networks: A Survey") shows an overview of recent
    research directions conducted by the machine learning community. All of them (i.e.,
    §[III-A](#S3.SS1 "III-A Robust Architecture ‣ III Deep Learning Approaches ‣ Learning
    from Noisy Labels with Deep Neural Networks: A Survey") – §[III-E](#S3.SS5 "III-E
    Sample Selection ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels with
    Deep Neural Networks: A Survey")) focused on making a supervised learning process
    more robust to label noise:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的全面调查，深度学习的鲁棒性可以通过多种方法得到增强 [[68](#bib.bib68), [16](#bib.bib16), [25](#bib.bib25),
    [69](#bib.bib69), [70](#bib.bib70), [71](#bib.bib71), [72](#bib.bib72), [73](#bib.bib73),
    [74](#bib.bib74)]。图 [3](#S2.F3 "图 3 ‣ II 前提 ‣ 从带噪标签中学习的深度神经网络：综述") 展示了机器学习社区进行的最新研究方向概述。所有这些方法（即，§[III-A](#S3.SS1
    "III-A 鲁棒架构 ‣ III 深度学习方法 ‣ 从带噪标签中学习的深度神经网络：综述") – §[III-E](#S3.SS5 "III-E 样本选择
    ‣ III 深度学习方法 ‣ 从带噪标签中学习的深度神经网络：综述")）都集中在使监督学习过程对标签噪声更具鲁棒性：
- en: •
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '(§[III-A](#S3.SS1 "III-A Robust Architecture ‣ III Deep Learning Approaches
    ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey")) Robust architecture:
    adding a noise adaptation layer at the top of an underlying DNN to learn label
    transition process or developing a dedicated architecture to reliably support
    more diverse types of label noise;'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (§[III-A](#S3.SS1 "III-A 鲁棒架构 ‣ III 深度学习方法 ‣ 从带噪标签中学习的深度神经网络：综述")) 鲁棒架构：在基础
    DNN 顶部添加一个噪声适应层，以学习标签过渡过程，或开发专用架构以可靠地支持更多类型的标签噪声；
- en: •
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '(§[III-B](#S3.SS2 "III-B Robust Regularization ‣ III Deep Learning Approaches
    ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey")) Robust regularization:
    enforcing a DNN to overfit less to false-labeled examples explicitly or implicitly;'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (§[III-B](#S3.SS2 "III-B 鲁棒正则化 ‣ III 深度学习方法 ‣ 从带噪标签中学习的深度神经网络：综述")) 鲁棒正则化：明确或隐含地强制
    DNN 对错误标记的样本过拟合较少；
- en: •
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '(§[III-C](#S3.SS3 "III-C Robust Loss Function ‣ III Deep Learning Approaches
    ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey")) Robust loss
    function: improving the loss function;'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (§[III-C](#S3.SS3 "III-C 强健损失函数 ‣ III 深度学习方法 ‣ 从噪声标签中学习：综述")) 强健损失函数：改进损失函数；
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '(§[III-D](#S3.SS4 "III-D Loss Adjustment ‣ III Deep Learning Approaches ‣ Learning
    from Noisy Labels with Deep Neural Networks: A Survey")) Loss adjustment: adjusting
    the loss value according to the confidence of a given loss (or label) by loss
    correction, loss reweighting, or label refurbishment;'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (§[III-D](#S3.SS4 "III-D 损失调整 ‣ III 深度学习方法 ‣ 从噪声标签中学习：综述")) 损失调整：通过损失校正、损失重标定或标签修正，根据给定损失（或标签）的置信度调整损失值；
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '(§[III-E](#S3.SS5 "III-E Sample Selection ‣ III Deep Learning Approaches ‣
    Learning from Noisy Labels with Deep Neural Networks: A Survey")) Sample selection:
    identifying true-labeled examples from noisy training data via multi-network or
    multi-round learning.'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (§[III-E](#S3.SS5 "III-E 样本选择 ‣ III 深度学习方法 ‣ 从噪声标签中学习：综述")) 样本选择：通过多网络或多轮学习从噪声训练数据中识别真实标签的示例。
- en: 'Overall, we categorize all recent deep learning methods into *five* groups
    corresponding to popular research directions, as shown in Figure [3](#S2.F3 "Figure
    3 ‣ II Preliminaries ‣ Learning from Noisy Labels with Deep Neural Networks: A
    Survey"). In §[III-D](#S3.SS4 "III-D Loss Adjustment ‣ III Deep Learning Approaches
    ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey"), meta learning
    is also discussed because it finds the optimal hyperparameters for loss reweighting.
    In §[III-E](#S3.SS5 "III-E Sample Selection ‣ III Deep Learning Approaches ‣ Learning
    from Noisy Labels with Deep Neural Networks: A Survey"), we discuss the recent
    efforts for combining sample selection with other orthogonal directions or semi-supervised
    learning toward the state-of-the-art performance.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们将所有最新的深度学习方法归类为 *五* 组，对应于流行的研究方向，如图 [3](#S2.F3 "图 3 ‣ II 初步知识 ‣ 从噪声标签中学习：综述")
    所示。在 §[III-D](#S3.SS4 "III-D 损失调整 ‣ III 深度学习方法 ‣ 从噪声标签中学习：综述") 中，也讨论了元学习，因为它找到了损失重标定的最佳超参数。在
    §[III-E](#S3.SS5 "III-E 样本选择 ‣ III 深度学习方法 ‣ 从噪声标签中学习：综述") 中，我们讨论了将样本选择与其他正交方向或半监督学习相结合的最新努力，以实现最先进的性能。
- en: 'Figure [2](#S1.F2 "Figure 2 ‣ I Introduction ‣ Learning from Noisy Labels with
    Deep Neural Networks: A Survey") illustrates the categorization of robust training
    methods using these five groups.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [2](#S1.F2 "图 2 ‣ I 介绍 ‣ 从噪声标签中学习：综述") 说明了使用这五组方法对强健训练方法的分类。
- en: III-A Robust Architecture
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 强健架构
- en: In numerous studies, architectural changes have been made to model the noise
    transition matrix of a noisy dataset [[75](#bib.bib75), [76](#bib.bib76), [77](#bib.bib77),
    [78](#bib.bib78), [79](#bib.bib79), [16](#bib.bib16), [80](#bib.bib80), [81](#bib.bib81),
    [82](#bib.bib82)]. These changes include adding a noise adaptation layer at the
    top of the softmax layer and designing a new dedicated architecture. The resulting
    architectures yield improved generalization through the modification of the DNN
    output based on the estimated label transition probability.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多研究中，已经对模型进行了架构上的更改，以建模噪声数据集的噪声转移矩阵 [[75](#bib.bib75), [76](#bib.bib76), [77](#bib.bib77),
    [78](#bib.bib78), [79](#bib.bib79), [16](#bib.bib16), [80](#bib.bib80), [81](#bib.bib81),
    [82](#bib.bib82)]。这些更改包括在 softmax 层顶部添加噪声适应层和设计新的专用架构。结果的架构通过根据估计的标签转移概率修改 DNN
    输出，从而实现了更好的泛化。
- en: III-A1 Noise Adaptation Layer
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A1 噪声适应层
- en: From the view of training data, the noise process is modeled by discovering
    the underlying label transition pattern (i.e., the noise transition matrix T).
    Given an example $x$, the noisy class posterior probability for an example $x$
    is expressed by
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练数据的角度来看，噪声过程是通过发现潜在的标签转移模式（即噪声转移矩阵 T）来建模的。给定示例 $x$，示例 $x$ 的噪声类别后验概率表示为
- en: '|  | $\begin{gathered}\!\!\!\!\!p(\tilde{y}=j&#124;x)\!=\!\sum_{i=1}^{c}p(\tilde{y}=j,y=i&#124;x)\!=\!\sum_{i=1}^{c}\text{T}_{ij}p(y=i&#124;x),\\
    \text{where}\leavevmode\nobreak\ \leavevmode\nobreak\ \text{T}_{ij}=p(\tilde{y}=j&#124;y=i,x).\end{gathered}$
    |  | (3) |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{gathered}\!\!\!\!\!p(\tilde{y}=j&#124;x)\!=\!\sum_{i=1}^{c}p(\tilde{y}=j,y=i&#124;x)\!=\!\sum_{i=1}^{c}\text{T}_{ij}p(y=i&#124;x),\\
    \text{where}\leavevmode\nobreak\ \leavevmode\nobreak\ \text{T}_{ij}=p(\tilde{y}=j&#124;y=i,x).\end{gathered}$
    |  | (3) |'
- en: 'In light of this, the noise adaptation layer is intended to mimic the label
    transition behavior in learning a DNN. Let $p(y|x;\Theta)$ be the output of the
    base DNN with a softmax output layer. Then, following Eq. ([3](#S3.E3 "In III-A1
    Noise Adaptation Layer ‣ III-A Robust Architecture ‣ III Deep Learning Approaches
    ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey")), the probability
    of an example $x$ being predicted as its noisy label $\tilde{y}$ is parameterized
    by'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于此，噪声适配层旨在模拟DNN学习中的标签转移行为。设$p(y|x;\Theta)$为基础DNN的输出，具有softmax输出层。然后，按照Eq. ([3](#S3.E3
    "在III-A1 噪声适配层 ‣ III-A 稳健架构 ‣ III 深度学习方法 ‣ 从噪声标签中学习：综述"))，示例$x$被预测为其噪声标签$\tilde{y}$的概率由以下公式参数化：
- en: '|  | $\begin{split}\!\!\!p(\tilde{y}=j&#124;x;\Theta,\mathcal{W})&amp;=\sum_{i=1}^{c}p(\tilde{y}=j,y\!=\!i&#124;x;\Theta,\mathcal{W})\\
    &amp;=\sum_{i=1}^{c}\underbrace{p(\tilde{y}=j&#124;y\!=\!i;\mathcal{W})}_{\text{Noise
    Adaptation Layer}}\underbrace{p(y\!=\!i&#124;x;\Theta)}_{\text{Base Model}}.\end{split}$
    |  | (4) |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\!\!\!p(\tilde{y}=j&#124;x;\Theta,\mathcal{W})&amp;=\sum_{i=1}^{c}p(\tilde{y}=j,y\!=\!i&#124;x;\Theta,\mathcal{W})\\
    &amp;=\sum_{i=1}^{c}\underbrace{p(\tilde{y}=j&#124;y\!=\!i;\mathcal{W})}_{\text{噪声适配层}}\underbrace{p(y\!=\!i&#124;x;\Theta)}_{\text{基础模型}}.\end{split}$
    |  | (4) |'
- en: 'Here, the noisy label $\tilde{y}$ is assumed to be *conditionally independent*
    of the input $x$ in general. Accordingly, as shown in Figure [4](#S3.F4 "Figure
    4 ‣ III-A1 Noise Adaptation Layer ‣ III-A Robust Architecture ‣ III Deep Learning
    Approaches ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey"),
    the noisy adaptation layer is added at the top of the base DNN to model the noise
    transition matrix parameterized by $\mathcal{W}$. This layer should be removed
    when test data is to be predicted.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，假设噪声标签$\tilde{y}$通常在条件上与输入$x$*条件独立*。因此，如图[4](#S3.F4 "图4 ‣ III-A1 噪声适配层 ‣
    III-A 稳健架构 ‣ III 深度学习方法 ‣ 从噪声标签中学习：综述")所示，噪声适配层被添加在基础DNN的顶部，以建模由$\mathcal{W}$参数化的噪声转移矩阵。当要预测测试数据时，这一层应被移除。
- en: '![Refer to caption](img/04619274794b7f5746f06408ce97be92.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/04619274794b7f5746f06408ce97be92.png)'
- en: 'Figure 4: Noise modeling process using the noise adaptation layer.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：使用噪声适配层的噪声建模过程。
- en: 'Technical Detail: *Webly learning* [[75](#bib.bib75)] first trains the base
    DNN only for easy examples retrieved by search engines; subsequently, the confusion
    matrix for all training examples is used as the initial weight $\mathcal{W}$ of
    the noise adaptation layer. It fine-tunes the entire model in an end-to-end manner
    for hard training examples. In contrast, the *noise model* [[77](#bib.bib77)]
    initializes $\mathcal{W}$ to an identity matrix and adds a regularizer to force
    $\mathcal{W}$ to diffuse during DNN training. The *dropout noise model* [[25](#bib.bib25)]
    applies dropout regularization to the adaptation layer, whose output is normalized
    by the softmax function to implicitly diffuse $\mathcal{W}$. The *s-model* [[79](#bib.bib79)]
    is similar to the *dropout noise model* but dropout is not applied. The *c-model*
    [[79](#bib.bib79)] is an extension of the s-model that models the instance-dependent
    noise, which is more realistic than the symmetric and asymmetric noises. Meanwhile,
    *NLNN* [[76](#bib.bib76)] adopts the EM algorithm to iterate the E-step to estimate
    the noise transition matrix and the M-step to back-propagate the DNN.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 技术细节：*Webly学习* [[75](#bib.bib75)] 首先仅对由搜索引擎检索的简单示例训练基础DNN；随后，将所有训练示例的混淆矩阵用作噪声适配层的初始权重$\mathcal{W}$。它以端到端的方式对整个模型进行微调，以处理困难的训练示例。相比之下，*噪声模型*
    [[77](#bib.bib77)] 将$\mathcal{W}$初始化为单位矩阵，并添加正则化项以强制$\mathcal{W}$在DNN训练过程中扩散。*Dropout噪声模型*
    [[25](#bib.bib25)] 对适配层应用dropout正则化，其输出由softmax函数归一化，以隐式地扩散$\mathcal{W}$。*s模型*
    [[79](#bib.bib79)] 类似于*dropout噪声模型*，但不应用dropout。*c模型* [[79](#bib.bib79)] 是s模型的扩展，它建模实例依赖的噪声，比对称噪声和不对称噪声更现实。同时，*NLNN*
    [[76](#bib.bib76)] 采用EM算法迭代E步以估计噪声转移矩阵，并进行M步以反向传播DNN。
- en: 'Remark: A common drawback of this family is their inability to identify false-labeled
    examples, treating all the examples equally. Thus, the estimation error for the
    transition matrix is generally large when only noisy training data is used or
    when the noise rate is high [[83](#bib.bib83)]. Meanwhile, for the EM-based method,
    becoming stuck in local optima is inevitable, and high computational costs are
    incurred [[79](#bib.bib79)].'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：这一类方法的一个常见缺点是无法识别虚假标记的示例，将所有示例视为相同。因此，当仅使用噪声训练数据或噪声率较高时，转换矩阵的估计误差通常较大[[83](#bib.bib83)]。与此同时，对于基于EM的方法，陷入局部最优解是不可避免的，并且会产生高计算成本[[79](#bib.bib79)]。
- en: III-A2 Dedicated Architecture
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A2 专用架构
- en: Beyond the label-dependent label noise, several studies have been conducted
    to support more complex noise, leading to the design of dedicated architectures
    [[16](#bib.bib16), [80](#bib.bib80), [81](#bib.bib81)]. They typically aimed at
    increasing the reliability of estimating the label transition probability to handle
    more complex and realistic label noise.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 除了依赖标签的标签噪声外，已经进行了一些研究以支持更复杂的噪声，这导致了专用架构的设计[[16](#bib.bib16), [80](#bib.bib80),
    [81](#bib.bib81)]。它们通常旨在提高估计标签转换概率的可靠性，以处理更复杂和更现实的标签噪声。
- en: 'Technical Detail: *Probabilistic noise modeling* [[16](#bib.bib16)] manages
    two independent networks, each of which is specialized to predict the noise type
    and label transition probability. Because an EM-based approach with random initialization
    is impractical for training the entire network, both networks are trained with
    massive noisy labeled data after the pre-training step with a small amount of
    clean data. Meanwhile, *masking* [[80](#bib.bib80)] is a human-assisted approach
    to convey the human cognition of invalid label transitions. Considering that noisy
    labels are mainly from the interaction between humans and tasks, the invalid transition
    investigated by humans was leveraged to constrain the noise modeling process.
    Owing to the difficulty in specifying the explicit constraint, a variant of generative
    adversarial networks (GANs) [[84](#bib.bib84)] was employed in this study. Recently,
    the *contrastive-additive noise network* [[81](#bib.bib81)] was proposed to adjust
    incorrectly estimated label transition probabilities by introducing a new concept
    of quality embedding, which models the trustworthiness of noisy labels. *RoG*
    [[85](#bib.bib85)] builds a simple yet robust generative classifier on top of
    any discriminative DNN pre-trained on noisy data.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 技术细节：*概率噪声建模*[[16](#bib.bib16)]管理两个独立的网络，每个网络专门用于预测噪声类型和标签转换概率。由于基于EM的方法在随机初始化下对整个网络的训练不切实际，因此在经过少量干净数据的预训练步骤后，两个网络使用大量噪声标记数据进行训练。同时，*遮罩*[[80](#bib.bib80)]是一种人工辅助的方法，用于传达无效标签转换的人类认知。考虑到噪声标签主要来自人类与任务之间的交互，人工调查的无效转换被利用来约束噪声建模过程。由于难以指定明确的约束，本研究采用了生成对抗网络（GANs）的变体[[84](#bib.bib84)]。最近，提出了*对比加性噪声网络*[[81](#bib.bib81)]，通过引入质量嵌入的新概念来调整错误估计的标签转换概率，该概念对噪声标签的可信度进行建模。*RoG*[[85](#bib.bib85)]在任何经过噪声数据预训练的判别性DNN基础上构建了一个简单而强健的生成分类器。
- en: 'Remark: Compared with the noise adaptation layer, this family of methods significantly
    improves the robustness to more diverse types of label noise, but it cannot be
    easily extended to other architectures in general.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：与噪声适应层相比，这类方法显著提高了对更各种标签噪声类型的鲁棒性，但通常无法轻松扩展到其他架构。
- en: III-B Robust Regularization
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 强健正则化
- en: Regularization methods have been widely studied to improve the generalizability
    of a learned model in the machine learning community [[26](#bib.bib26), [24](#bib.bib24),
    [25](#bib.bib25), [23](#bib.bib23)]. By avoiding overfitting in model training,
    the robustness to label noise improves with widely-used regularization techniques
    such as *data augmentation* [[23](#bib.bib23)], *weight decay* [[24](#bib.bib24)],
    *dropout* [[25](#bib.bib25)], and *batch normalization* [[26](#bib.bib26)]. These
    canonical regularization methods operate well on moderately noisy data, but they
    alone do *not sufficiently* improve the test accuracy; poor generalization could
    be obtained when the noise is heavy [[86](#bib.bib86)]. Thus, more advanced regularization
    techniques have been recently proposed, which further improved robustness to label
    noise when used along with the canonical methods. The main advantage of this family
    is its *flexibility* in collaborating with other directions because it only requires
    simple modifications.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化方法在机器学习领域被广泛研究，以提高学习模型的泛化能力 [[26](#bib.bib26), [24](#bib.bib24), [25](#bib.bib25),
    [23](#bib.bib23)]。通过避免模型训练中的过拟合，使用广泛应用的正则化技术，如*数据增强* [[23](#bib.bib23)]、*权重衰减*
    [[24](#bib.bib24)]、*dropout* [[25](#bib.bib25)]和*批量归一化* [[26](#bib.bib26)]，对标签噪声的鲁棒性得以提高。这些经典的正则化方法在适度噪声的数据上表现良好，但它们单独*不能充分*提高测试准确性；当噪声较重时，可能会获得较差的泛化效果
    [[86](#bib.bib86)]。因此，最近提出了更多先进的正则化技术，这些技术在与经典方法结合使用时进一步提高了对标签噪声的鲁棒性。这类方法的主要优势在于其与其他方向协作的*灵活性*，因为它只需要简单的修改。
- en: III-B1 Explicit Regularization
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B1 显式正则化
- en: The regularization can be an explicit form that modifies the expected training
    loss, e.g., weight decay and dropout.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化可以是显式形式，修改期望的训练损失，例如权重衰减和 dropout。
- en: 'Technical Detail: *Bilevel learning* [[87](#bib.bib87)] uses a clean validation
    dataset to regularize the overfitting of a model by introducing a bilevel optimization
    approach, which differs from the conventional one in that its regularization constraint
    is also an optimization problem. Overfitting is controlled by adjusting the weights
    on each mini-batch and selecting their values such that they minimize the error
    on the validation dataset. Meanwhile, *annotator confusion* [[86](#bib.bib86)]
    assumes the existence of multiple annotators and introduces a regularized EM-based
    approach to model the label transition probability; its regularizer enables the
    estimated transition probability to converge to the true confusion matrix of the
    annotators. In contrast, *pre-training* [[88](#bib.bib88)] empirically proves
    that fine-tuning on a pre-trained model provides a significant improvement in
    robustness compared with models trained from scratch; the universal representations
    of pre-training prevent the model parameters from being updated in the wrong direction
    by noisy labels. *PHuber* [[89](#bib.bib89)] proposes a composite loss-based gradient
    clipping, which is a variation of standard gradient clipping for label noise robustness.
    *Robust early-learning* [[90](#bib.bib90)] classifies critical parameters and
    non-critical parameters for fitting clean and noise labels, respectively. Then,
    it penalizes only the non-critical ones with a different update rule. *ODLN* [[91](#bib.bib91)]
    leverages open-set auxiliary data and prevents the overfitting to noisy labels
    by assigning random labels to the open-set examples, which are uniformly sampled
    from the label set.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 技术细节：*双层学习* [[87](#bib.bib87)] 使用干净的验证数据集，通过引入双层优化方法来正则化模型的过拟合，这种方法与传统方法的不同之处在于其正则化约束也是一个优化问题。通过调整每个小批量上的权重并选择其值，使其最小化验证数据集上的误差，从而控制过拟合。与此同时，*标注者混淆*
    [[86](#bib.bib86)] 假设存在多个标注者，并引入基于正则化的 EM 方法来建模标签转移概率；其正则化器使得估计的转移概率收敛于标注者的真实混淆矩阵。相比之下，*预训练*
    [[88](#bib.bib88)] 实证证明，相比于从头训练的模型，微调预训练模型显著提高了鲁棒性；预训练的通用表示防止了模型参数因噪声标签而被错误更新。*PHuber*
    [[89](#bib.bib89)] 提出了基于复合损失的梯度裁剪，这是一种针对标签噪声鲁棒性的标准梯度裁剪的变体。*鲁棒的早期学习* [[90](#bib.bib90)]
    将关键参数和非关键参数分别分类用于拟合干净和噪声标签，然后仅对非关键参数施加不同的更新规则。*ODLN* [[91](#bib.bib91)] 利用开放集辅助数据，通过将随机标签分配给从标签集中均匀采样的开放集示例，来防止对噪声标签的过拟合。
- en: 'Remark: The explicit regularization often introduces sensitive model-dependent
    hyperparameters or requires deeper architectures to compensate for the reduced
    capacity, yet it can lead to significant performance gain if they are optimally
    tuned.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：显式正则化通常引入敏感的模型依赖超参数或需要更深的架构来弥补容量的减少，但如果这些超参数得到最佳调整，它可以带来显著的性能提升。
- en: III-B2 Implicit Regularization
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B2 隐式正则化
- en: The regularization can also be an implicit form that gives the effect of stochasticity,
    e.g., data augmentation and mini-batch stochastic gradient descent.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化还可以是一种隐式形式，这种形式能产生随机性的效果，例如数据增强和小批量随机梯度下降。
- en: 'Technical Detail: *Adversarial training* [[92](#bib.bib92)] enhances the noise
    tolerance by encouraging the DNN to correctly classify both original inputs and
    hostilely perturbed ones. *Label smoothing* [[93](#bib.bib93), [94](#bib.bib94)]
    estimates the marginalized effect of label noise during training, thereby reducing
    overfitting by preventing the DNN from assigning a full probability to noisy training
    examples. Instead of the one-hot label, the noisy label is mixed with a uniform
    mixture over all possible labels,'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 技术细节：*对抗训练* [[92](#bib.bib92)] 通过鼓励深度神经网络（DNN）正确分类原始输入和敌对扰动输入来提高噪声容忍度。*标签平滑*
    [[93](#bib.bib93), [94](#bib.bib94)] 估计训练过程中标签噪声的边际效应，从而通过防止DNN将全部概率分配给噪声训练样本来减少过拟合。噪声标签被混合在所有可能标签上，而不是使用独热标签，
- en: '|  | $\begin{gathered}\bar{y}=\big{\langle}\bar{y}(1),\bar{y}(2),\dots,\bar{y}(c)\big{\rangle},\\
    \text{where}\leavevmode\nobreak\ \bar{y}(i)=(1-\alpha)\cdot[\tilde{y}=i]+\alpha/c\leavevmode\nobreak\
    \text{and}\leavevmode\nobreak\ \alpha\in[0,1].\end{gathered}$ |  | (5) |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{gathered}\bar{y}=\big{\langle}\bar{y}(1),\bar{y}(2),\dots,\bar{y}(c)\big{\rangle},\\
    \text{其中}\leavevmode\nobreak\ \bar{y}(i)=(1-\alpha)\cdot[\tilde{y}=i]+\alpha/c\leavevmode\nobreak\
    \text{和}\leavevmode\nobreak\ \alpha\in[0,1].\end{gathered}$ |  | (5) |'
- en: Here, $[\cdot]$ is the Iverson bracket and $\alpha$ is the smoothing degree.
    In contrast, *mixup* [[95](#bib.bib95)] regularizes the DNN to favor simple linear
    behaviors in between training examples. First, the mini-batch is constructed using
    virtual training examples, each of which is formed by the linear interpolation
    of two noisy training examples $(x_{i},\tilde{y}_{i})$ and $(x_{j},\tilde{y}_{j})$
    obtained at random from noisy training data $\tilde{\mathcal{D}}$,
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，$[\cdot]$ 是 Iverson 括号，$\alpha$ 是平滑度。相反，*mixup* [[95](#bib.bib95)] 对 DNN
    进行正则化，以在训练样本之间偏向简单的线性行为。首先，使用虚拟训练样本构建小批量，每个样本是通过对两个从噪声训练数据 $\tilde{\mathcal{D}}$
    随机获得的噪声训练样本 $(x_{i},\tilde{y}_{i})$ 和 $(x_{j},\tilde{y}_{j})$ 进行线性插值而形成的，
- en: '|  | ${x}_{mix}=\lambda x_{i}+(1-\lambda)x_{j}\leavevmode\nobreak\ \leavevmode\nobreak\
    \text{and}\leavevmode\nobreak\ \leavevmode\nobreak\ {y}_{mix}=\lambda\tilde{y}_{i}+(1-\lambda)\tilde{y}_{j},$
    |  | (6) |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | ${x}_{mix}=\lambda x_{i}+(1-\lambda)x_{j}\leavevmode\nobreak\ \leavevmode\nobreak\
    \text{和}\leavevmode\nobreak\ \leavevmode\nobreak\ {y}_{mix}=\lambda\tilde{y}_{i}+(1-\lambda)\tilde{y}_{j},$
    |  | (6) |'
- en: where $\lambda\in[0,1]$ is the balance parameter between two examples. Thus,
    *mixup* extends the training distribution by updating the DNN for the constructed
    mini-batch.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\lambda\in[0,1]$ 是两个样本之间的平衡参数。因此，*mixup* 通过更新 DNN 来扩展训练分布，以适应构建的小批量。
- en: 'Remark: The implicit regularization improves the generalization capability
    of the DNN without reducing the representational capacity. It also does not introduce
    sensitive model-dependent hyperparameters because it is applied to the training
    data. However, the extended feature or label space slows down the convergence
    of training.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：隐式正则化提高了DNN的泛化能力，而不会降低其表征能力。它也不会引入敏感的模型依赖超参数，因为它应用于训练数据。然而，扩展的特征或标签空间会减慢训练的收敛速度。
- en: III-C Robust Loss Function
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 稳健损失函数
- en: It was proven that a learned DNN with a *suitably modified* loss function $\ell^{\prime}$
    for noisy data $\tilde{\mathcal{D}}$ can approach the Bayes optimal classifier
    $f^{*}$, which achieves the optimal Bayes risk $\mathcal{R}^{*}=\mathcal{R}_{\mathcal{D}}(f^{*})$
    for clean data $\mathcal{D}$. Let $\hat{f}=\text{argmin}_{f\in\mathcal{F}}\hat{\mathcal{R}}_{\ell^{\prime},\tilde{\mathcal{D}}}(f)$
    be the learned classifier with the modified loss $\ell^{\prime}$ for the noisy
    data, where $\hat{\mathcal{R}}_{\ell^{\prime},\tilde{\mathcal{D}}}(f)=\mathbb{E}_{\tilde{\mathcal{D}}}[\ell(f(x;\Theta),\tilde{y})]$.
    If $\ell$ is $L$-Lipschitz and classification-calibrated [[50](#bib.bib50)], with
    probability at least $1\!-\!\delta$, there exists a non-decreasing function $\zeta_{\ell}$
    with $\zeta_{\ell}(0)=0$ [[39](#bib.bib39)] such that
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 已证明，具有*适当修改*的损失函数$\ell^{\prime}$的深度神经网络（DNN）可以接近贝叶斯最优分类器$f^{*}$，该分类器在干净数据$\mathcal{D}$上实现了最优贝叶斯风险$\mathcal{R}^{*}=\mathcal{R}_{\mathcal{D}}(f^{*})$。令$\hat{f}=\text{argmin}_{f\in\mathcal{F}}\hat{\mathcal{R}}_{\ell^{\prime},\tilde{\mathcal{D}}}(f)$为对噪声数据的修改损失$\ell^{\prime}$的学习分类器，其中$\hat{\mathcal{R}}_{\ell^{\prime},\tilde{\mathcal{D}}}(f)=\mathbb{E}_{\tilde{\mathcal{D}}}[\ell(f(x;\Theta),\tilde{y})]$。如果$\ell$是$L$-Lipschitz且分类校准的[[50](#bib.bib50)]，则以至少$1\!-\!\delta$的概率，存在一个非递减函数$\zeta_{\ell}$，使得$\zeta_{\ell}(0)=0$[[39](#bib.bib39)]，使得
- en: '|  | $\begin{split}\mathcal{R}_{\mathcal{D}}(\hat{f})-\mathcal{R}^{*}\leq&amp;\leavevmode\nobreak\
    \overbrace{\zeta_{\ell}\Big{(}\text{min}_{f\in\mathcal{F}}\mathcal{R}_{\ell,\mathcal{D}}(f)-\text{min}_{f}\mathcal{R}_{\ell,\mathcal{D}}(f)}^{\text{Approximation
    and Estimation Errors}}\\ &amp;\leavevmode\nobreak\ \leavevmode\nobreak\ +4L_{p}\text{RC}(\mathcal{F})+2\sqrt{{\text{log}(1/\delta)}\big{/}{2&#124;\mathcal{D}&#124;}}\Big{)},\!\!\!\!\!\end{split}$
    |  | (7) |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\mathcal{R}_{\mathcal{D}}(\hat{f})-\mathcal{R}^{*}\leq&\leavevmode\nobreak\
    \overbrace{\zeta_{\ell}\Big{(}\text{min}_{f\in\mathcal{F}}\mathcal{R}_{\ell,\mathcal{D}}(f)-\text{min}_{f}\mathcal{R}_{\ell,\mathcal{D}}(f)}^{\text{近似和估计误差}}\\
    &\leavevmode\nobreak\ \leavevmode\nobreak\ +4L_{p}\text{RC}(\mathcal{F})+2\sqrt{{\text{log}(1/\delta)}\big{/}{2\mid\mathcal{D}\mid}}\Big{)},\!\!\!\!\!\end{split}$
    |  | (7) |'
- en: $L_{p}$ is the Lipschitz constant of $\ell^{\prime}$ and RC is the Rademacher
    complexity of the hypothesis class $\mathcal{F}$. Then, by the universal approximation
    theorem [[96](#bib.bib96)], the Bayes optimal classifier $f^{*}$ is guaranteed
    to be in the hypothesis class $\mathcal{F}$ with DNNs.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: $L_{p}$是$\ell^{\prime}$的Lipschitz常数，RC是假设类$\mathcal{F}$的Rademacher复杂度。然后，根据通用逼近定理[[96](#bib.bib96)]，贝叶斯最优分类器$f^{*}$在深度神经网络（DNNs）中保证存在于假设类$\mathcal{F}$中。
- en: Based on this theoretical foundation, researchers have attempted to design robust
    loss functions such that they achieve a small risk for unseen clean data even
    when noisy labels exist in the training data [[68](#bib.bib68), [97](#bib.bib97),
    [98](#bib.bib98), [99](#bib.bib99), [100](#bib.bib100), [101](#bib.bib101)].
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这一理论基础，研究人员尝试设计稳健的损失函数，以便即使在训练数据中存在噪声标签时，它们也能在未见过的干净数据上实现较小的风险[[68](#bib.bib68),
    [97](#bib.bib97), [98](#bib.bib98), [99](#bib.bib99), [100](#bib.bib100), [101](#bib.bib101)]。
- en: 'Technical Detail: Initially, Manwani and Sastry [[48](#bib.bib48)] theoretically
    proved a sufficient condition for the loss function such that risk minimization
    with that function becomes noise-tolerant for binary classification. Subsequently,
    the sufficient condition was extended for multi-class classification using deep
    learning [[68](#bib.bib68)]. Specifically, a loss function is defined to be *noise-tolerant*
    for a $c$-class classification under *symmetric* noise if the function satisfies
    the noise rate $\tau<\frac{c-1}{c}$ and'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 技术细节：最初，Manwani和Sastry [[48](#bib.bib48)] 理论上证明了一个足够条件，以使得使用该损失函数的风险最小化对二分类变得噪声容忍。随后，这一足够条件被扩展到多类分类，使用深度学习[[68](#bib.bib68)]。具体而言，损失函数被定义为*噪声容忍*，对于$
    c $-类分类在*对称*噪声下，如果函数满足噪声率$\tau<\frac{c-1}{c}$且
- en: '|  | $\sum_{j=1}^{c}\ell\big{(}f(x;\Theta),y=j\big{)}=C,\leavevmode\nobreak\
    \forall x\in\mathcal{X},\leavevmode\nobreak\ \forall f,$ |  | (8) |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '|  | $\sum_{j=1}^{c}\ell\big{(}f(x;\Theta),y=j\big{)}=C,\leavevmode\nobreak\
    \forall x\in\mathcal{X},\leavevmode\nobreak\ \forall f,$ |  | (8) |'
- en: where $C$ is a constant. This condition guarantees that the classifier trained
    on noisy data has the same misclassification probability as that trained on noise-free
    data under the specified assumption. An extension for *multi-label* classification
    was provided by Kumar et al. [[102](#bib.bib102)]. Moreover, if $\mathcal{R}_{\mathcal{D}}(f^{*})=0$,
    then the function is also noise-tolerant under an *asymmetric* noise, where $f^{*}$
    is a global risk minimizer of $\mathcal{R}_{\mathcal{D}}$.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $C$ 是一个常数。该条件保证了在指定假设下，在噪声数据上训练的分类器具有与在无噪声数据上训练的分类器相同的误分类概率。Kumar 等人 [[102](#bib.bib102)]
    提供了*多标签* 分类的扩展。此外，如果 $\mathcal{R}_{\mathcal{D}}(f^{*})=0$，则该函数在*非对称* 噪声下也是噪声容忍的，其中
    $f^{*}$ 是 $\mathcal{R}_{\mathcal{D}}$ 的全局风险最小化器。
- en: For the classification task, the categorical cross entropy (CCE) loss is the
    most widely used loss function owing to its fast convergence and high generalization
    capability. However, in the presence of noisy labels, the *robust MAE* [[68](#bib.bib68)]
    showed that the mean absolute error (MAE) loss achieves better generalization
    than the CCE loss because only the MAE loss satisfies the aforementioned condition.
    A limitation of the MAE loss is that its generalization performance degrades significantly
    when complicated data are involved. Hence, the *generalized cross entropy* (GCE)
    [[97](#bib.bib97)] was proposed to achieve the advantages of both MAE and CCE
    losses; the GCE loss is a more general class of noise-robust loss that encompasses
    both of them. Amid et al. [[103](#bib.bib103)] extended the GCE loss by introducing
    two temperatures based on the Tsallis divergence. *Bi-tempered loss* [[104](#bib.bib104)]
    introduces a proper unbiased generalization of the CE loss based on the Bregman
    divergence. In addition, inspired by the symmetricity of the Kullback-Leibler
    divergence, the symmetric cross entropy (SCE) [[98](#bib.bib98)] was proposed
    by combining a noise tolerance term, namely reverse cross entropy loss, with the
    standard CCE loss.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类任务，类别交叉熵（CCE）损失是最广泛使用的损失函数，因为它具有快速收敛和高泛化能力。然而，在存在噪声标签的情况下，*稳健的 MAE* [[68](#bib.bib68)]
    研究表明，平均绝对误差（MAE）损失在泛化方面优于 CCE 损失，因为只有 MAE 损失满足上述条件。MAE 损失的一个限制是，当涉及复杂数据时，其泛化性能显著下降。因此，提出了*广义交叉熵*（GCE）
    [[97](#bib.bib97)] 来实现 MAE 和 CCE 损失的优势；GCE 损失是一种更通用的噪声鲁棒损失，包括了它们俩。Amid 等人 [[103](#bib.bib103)]
    通过基于 Tsallis 散度引入两个温度来扩展 GCE 损失。*双温损失* [[104](#bib.bib104)] 基于 Bregman 散度引入了 CE
    损失的适当无偏广义化。此外，受到 Kullback-Leibler 散度对称性的启发，*对称交叉熵*（SCE） [[98](#bib.bib98)] 通过将一个噪声容忍项，即反向交叉熵损失，与标准
    CCE 损失结合提出。
- en: Meanwhile, the *curriculum loss* (CL) [[99](#bib.bib99)] is a surrogate loss
    of the 0-1 loss function; it provides a tight upper bound and can easily be extended
    to multi-class classification. The *active passive loss* (APL) [[105](#bib.bib105)]
    is a combination of two types of robust loss functions, an active loss that maximizes
    the probability of belonging to the given class and a passive loss that minimizes
    the probability of belonging to other classes.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，*课程损失*（CL） [[99](#bib.bib99)] 是 0-1 损失函数的一个替代损失；它提供了一个紧的上界，并且可以很容易地扩展到多类别分类。*主动被动损失*（APL）
    [[105](#bib.bib105)] 是两种鲁棒损失函数的组合，其中主动损失最大化属于给定类别的概率，被动损失则最小化属于其他类别的概率。
- en: 'Remark: The robustness of these methods is theoretically supported well. However,
    they perform well only in simple cases, when learning is easy or the number of
    classes is small [[106](#bib.bib106)]. Moreover, the modification of the loss
    function increases the training time for convergence [[97](#bib.bib97)].'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：这些方法的鲁棒性在理论上得到了很好的支持。然而，它们仅在简单情况下表现良好，例如学习容易或类别数量较少 [[106](#bib.bib106)]。此外，损失函数的修改增加了收敛的训练时间
    [[97](#bib.bib97)]。
- en: III-D Loss Adjustment
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-D 损失调整
- en: 'Loss adjustment is effective for reducing the negative impact of noisy labels
    by adjusting the loss of all training examples before updating the DNN [[62](#bib.bib62),
    [107](#bib.bib107), [108](#bib.bib108), [109](#bib.bib109), [69](#bib.bib69),
    [110](#bib.bib110), [111](#bib.bib111), [19](#bib.bib19)]. The methods associated
    with it can be categorized into three groups depending on their adjustment philosophy:
    *1)* *loss correction* that estimates the noise transition matrix to correct the
    forward or backward loss, *2)* *loss reweighting* that imposes different importance
    to each example for a weighted training scheme, *3)* *label refurbishment* that
    adjusts the loss using the refurbished label obtained from a convex combination
    of noisy and predicted labels, and *4)* *meta learning* that automatically infers
    the optimal rule for loss adjustment. Unlike the robust loss function newly designed
    for robustness, this family of methods aims to make the traditional optimization
    process robust to label noise. Hence, in the middle of training, the update rule
    is adjusted such that the negative impact of label noise is minimized.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 损失调整通过在更新深度神经网络（DNN）之前调整所有训练示例的损失，有效减少噪声标签的负面影响 [[62](#bib.bib62), [107](#bib.bib107),
    [108](#bib.bib108), [109](#bib.bib109), [69](#bib.bib69), [110](#bib.bib110),
    [111](#bib.bib111), [19](#bib.bib19)]。与之相关的方法可以根据其调整哲学分为三类：*1)* *损失修正* 通过估计噪声转移矩阵来修正前向或后向损失，*2)*
    *损失重标定* 通过为每个示例施加不同的重要性以进行加权训练，*3)* *标签修复* 使用从噪声标签和预测标签的凸组合中获得的修复标签调整损失，以及 *4)*
    *元学习* 自动推断损失调整的最佳规则。与新设计的稳健损失函数不同，这些方法旨在使传统优化过程对标签噪声具有稳健性。因此，在训练过程中，更新规则会被调整，以最小化标签噪声的负面影响。
- en: In general, loss adjustment allows for a *full exploration* of the training
    data by adjusting the loss of every example. However, the error incurred by *false*
    correction is accumulated, especially when the number of classes or the number
    of mislabeled examples is large [[112](#bib.bib112)].
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，损失调整允许对训练数据进行*全面探索*，通过调整每个示例的损失。然而，由于*错误*修正带来的误差会累积，尤其是当类别数或标签错误示例数量较大时
    [[112](#bib.bib112)]。
- en: III-D1 Loss Correction
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-D1 损失修正
- en: 'Similar to the noise adaptation layer presented in Section [III-A](#S3.SS1
    "III-A Robust Architecture ‣ III Deep Learning Approaches ‣ Learning from Noisy
    Labels with Deep Neural Networks: A Survey"), this approach modifies the loss
    of each example by multiplying the estimated label transition probability by the
    output of a specified DNN. The main difference is that the learning of the transition
    probability is decoupled from that of the model.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '与第 [III-A](#S3.SS1 "III-A Robust Architecture ‣ III Deep Learning Approaches
    ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey") 节中介绍的噪声适应层类似，这种方法通过将估计的标签转移概率乘以指定
    DNN 的输出来修改每个示例的损失。主要区别在于转移概率的学习与模型的学习是解耦的。'
- en: 'Technical Detail: *Backward correction* [[62](#bib.bib62)] initially approximates
    the noise transition matrix using the softmax output of the DNN trained without
    loss correction. Subsequently, it retrains the DNN while correcting the original
    loss based on the estimated matrix. The corrected loss of a example $(x,\tilde{y})$
    is computed by a linear combination of its loss values for observable labels,
    whose coefficient is the inverse transition matrix $\text{T}^{-1}$ to the observable
    label $y\in\{1,\dots,c\}$, given its target label $\tilde{y}$. Therefore, the
    backward correction $\textstyle\vec{}\mkern 4.0mu$ $\textstyle\ell$ is performed
    by multiplying the inverse transition matrix to the prediction for all the observable
    labels,'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 技术细节：*反向修正* [[62](#bib.bib62)] 最初使用未经过损失修正的 DNN 的 softmax 输出来近似噪声转移矩阵。随后，它在基于估计矩阵修正原始损失的同时重新训练
    DNN。示例 $(x,\tilde{y})$ 的修正损失通过其可观测标签的损失值的线性组合来计算，其系数是对可观测标签 $y\in\{1,\dots,c\}$
    的逆转移矩阵 $\text{T}^{-1}$，给定其目标标签 $\tilde{y}$。因此，反向修正 $\textstyle\vec{}\mkern 4.0mu$
    $\textstyle\ell$ 是通过将逆转移矩阵乘以所有可观测标签的预测来进行的，
- en: '|  |  $\small\begin{split}{\mathchoice{\vbox{\offinterlineskip\halign{#\cr\reflectbox{$\displaystyle\vec{}\mkern
    4.0mu$}\cr\kern-3.87498pt\cr$\displaystyle\ell$\cr}}}{\vbox{\offinterlineskip\halign{#\cr\reflectbox{$\textstyle\vec{}\mkern
    4.0mu$}\cr\kern-3.87498pt\cr$\textstyle\ell$\cr}}}{\vbox{\offinterlineskip\halign{#\cr\reflectbox{$\scriptstyle\vec{}\mkern
    4.0mu$}\cr\kern-2.7125pt\cr$\scriptstyle\ell$\cr}}}{\vbox{\offinterlineskip\halign{#\cr\reflectbox{$\scriptscriptstyle\vec{}\mkern
    4.0mu$}\cr\kern-1.93748pt\cr$\scriptscriptstyle\ell$\cr}}}}\big{(}f(x;&amp;\Theta),\tilde{y}\big{)}=\hat{\text{T}}^{-1}\Big{\langle}\ell\big{(}f(x;\Theta),1\big{)},\dots,\ell\big{(}f(x;\Theta),c\big{)}\Big{\rangle}^{\!\top}\!\!,\end{split}$
    |  | (9) |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '|  |  $\small\begin{split}{\mathchoice{\vbox{\offinterlineskip\halign{#\cr\reflectbox{$\displaystyle\vec{}\mkern
    4.0mu$}\cr\kern-3.87498pt\cr$\displaystyle\ell$\cr}}}{\vbox{\offinterlineskip\halign{#\cr\reflectbox{$\textstyle\vec{}\mkern
    4.0mu$}\cr\kern-3.87498pt\cr$\textstyle\ell$\cr}}}{\vbox{\offinterlineskip\halign{#\cr\reflectbox{$\scriptstyle\vec{}\mkern
    4.0mu$}\cr\kern-2.7125pt\cr$\scriptstyle\ell$\cr}}}{\vbox{\offinterlineskip\halign{#\cr\reflectbox{$\scriptscriptstyle\vec{}\mkern
    4.0mu$}\cr\kern-1.93748pt\cr$\scriptscriptstyle\ell$\cr}}}}\big{(}f(x;&amp;\Theta),\tilde{y}\big{)}=\hat{\text{T}}^{-1}\Big{\langle}\ell\big{(}f(x;\Theta),1\big{)},\dots,\ell\big{(}f(x;\Theta),c\big{)}\Big{\rangle}^{\!\top}\!\!,\end{split}$
    |  | (9) |'
- en: where $\hat{\text{T}}$ is the estimated noise transition matrix.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\hat{\text{T}}$是估计的噪声转换矩阵。
- en: Conversely, *forward correction* [[62](#bib.bib62)] uses a linear combination
    of a DNN’s softmax outputs before applying the loss function. Hence, the forward
    correction $\vec{\ell}$ is performed by multiplying the estimated transition probability
    with the softmax outputs during the forward propagation step,
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，*前向修正* [[62](#bib.bib62)] 使用DNN的softmax输出的线性组合来应用损失函数。因此，前向修正$\vec{\ell}$通过在前向传播步骤中将估计的转换概率与softmax输出相乘来进行，
- en: '|  | $\small\begin{split}\vec{\ell}\big{(}f(x;\Theta),\tilde{y}\big{)}&amp;=\ell\Big{(}\Big{\langle}\hat{p}(\tilde{y}&#124;1),\dots,\hat{p}(\tilde{y}&#124;c)\Big{\rangle}f(x;\Theta)^{\top},\tilde{y}\Big{)}\\
    &amp;=\ell\big{(}\hat{\text{T}}^{\top}f(x;\Theta)^{\top},\tilde{y}\big{)}.\end{split}$
    |  | (10) |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|  | $\small\begin{split}\vec{\ell}\big{(}f(x;\Theta),\tilde{y}\big{)}&amp;=\ell\Big{(}\Big{\langle}\hat{p}(\tilde{y}&#124;1),\dots,\hat{p}(\tilde{y}&#124;c)\Big{\rangle}f(x;\Theta)^{\top},\tilde{y}\Big{)}\\
    &amp;=\ell\big{(}\hat{\text{T}}^{\top}f(x;\Theta)^{\top},\tilde{y}\big{)}.\end{split}$
    |  | (10) |'
- en: Furthermore, *gold loss correction* [[107](#bib.bib107)] assumes the availability
    of clean validation data or anchor points for loss correction. Thus, a more accurate
    transition matrix is obtained by using them as additional information, which further
    improves the robustness of the loss correction. Recently, *T-Revision* [[113](#bib.bib113)]
    provides a solution that can infer the transition matrix without anchor points,
    and *Dual T* [[114](#bib.bib114)] factorizes the matrix into the product of two
    easy-to-estimate matrices to avoid directly estimating the noisy class posterior.
    Beyond the instance-independent noise assumption, Zhang et al. [[115](#bib.bib115)]
    introduced the instance-confidence embedding to model instance-dependent noise
    in estimating the transition matrix. On the other hand, Yang et al. [[116](#bib.bib116)]
    proposed to use the Bayes optimal transition matrix estimated from the distilled
    examples for the instance-dependent noise transition matrix.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，*金标准损失修正* [[107](#bib.bib107)] 假设有可用的干净验证数据或锚点用于损失修正。因此，通过将它们作为额外信息来获得更准确的转换矩阵，从而进一步提高了损失修正的鲁棒性。最近，*T-Revision*
    [[113](#bib.bib113)] 提供了一种在没有锚点的情况下推断转换矩阵的解决方案，而*Dual T* [[114](#bib.bib114)]
    将矩阵分解为两个易于估计的矩阵的乘积，以避免直接估计噪声类别后验。超越实例独立噪声假设，Zhang等人 [[115](#bib.bib115)] 引入了实例置信度嵌入来建模实例相关噪声，以估计转换矩阵。另一方面，Yang等人
    [[116](#bib.bib116)] 提出了使用从蒸馏样本中估计的贝叶斯最优转换矩阵来处理实例相关噪声转换矩阵。
- en: 'Remark: The robustness of these approaches is highly dependent on how precisely
    the transition matrix is estimated. To acquire such a transition matrix, they
    require prior knowledge in general, such as anchor points or clean validation
    data.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 注：这些方法的鲁棒性高度依赖于转换矩阵的准确估计。为了获得这样的转换矩阵，它们通常需要先验知识，例如锚点或干净的验证数据。
- en: III-D2 Loss Reweighting
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-D2 损失重加权
- en: Inspired by the concept of importance reweighting [[117](#bib.bib117)], loss
    reweighting aims to assign smaller weights to the examples with false labels and
    greater weights to those with true labels. Accordingly, the reweighted loss on
    the mini-batch $\mathcal{B}_{t}$ is used to update the DNN,
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 受到重要性重加权 [[117](#bib.bib117)] 概念的启发，损失重加权旨在为带有错误标签的示例分配较小的权重，而为带有正确标签的示例分配较大的权重。因此，使用重加权的损失在小批量$\mathcal{B}_{t}$上更新DNN，
- en: '|  | $\Theta_{t+1}=\Theta_{t}-\eta\nabla\Big{(}\frac{1}{&#124;\mathcal{B}_{t}&#124;}\!\sum_{(x,\tilde{y})\in\mathcal{B}_{t}}\!\!\!\!\overbrace{w(x,\tilde{y})\ell\big{(}f(x;\Theta_{t}),\tilde{y}\big{)}}^{\text{Reweighted
    Loss}}\Big{)},$ |  | (11) |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '|  | $\Theta_{t+1}=\Theta_{t}-\eta\nabla\Big{(}\frac{1}{&#124;\mathcal{B}_{t}&#124;}\!\sum_{(x,\tilde{y})\in\mathcal{B}_{t}}\!\!\!\!\overbrace{w(x,\tilde{y})\ell\big{(}f(x;\Theta_{t}),\tilde{y}\big{)}}^{\text{重新加权的损失}}\Big{)},$
    |  | (11) |'
- en: where $w(x,\tilde{y})$ is the weight of an example $x$ with its noisy label
    $\tilde{y}$. Hence, the examples with smaller weights do not significantly affect
    the DNN learning.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$w(x,\tilde{y})$是样本$x$及其噪声标签$\tilde{y}$的权重。因此，权重较小的样本对DNN学习的影响不大。
- en: 'Technical Detail: In *importance reweighting* [[108](#bib.bib108)], the ratio
    of two joint data distributions $w(x,\tilde{y})=P_{\mathcal{D}}(x,\tilde{y})/P_{\tilde{\mathcal{D}}}(x,\tilde{y})$
    determines the contribution of the loss of each noisy example. An approximate
    solution to estimate the ratio was developed because the two distributions are
    difficult to determine from noisy data. Meanwhile, *active bias* [[109](#bib.bib109)]
    emphasizes uncertain examples with inconsistent label predictions by assigning
    their prediction variances as the weights for training. *DualGraph* [[118](#bib.bib118)]
    employs graph neural networks and reweights the examples according to the structural
    relations among labels, eliminating the abnormal noise examples.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 技术细节：在*重要性重新加权* [[108](#bib.bib108)]中，两组数据分布的比率$w(x,\tilde{y})=P_{\mathcal{D}}(x,\tilde{y})/P_{\tilde{\mathcal{D}}}(x,\tilde{y})$决定了每个噪声样本的损失贡献。由于从噪声数据中很难确定这两个分布，因此开发了一种估计比率的近似解决方案。同时，*主动偏差*
    [[109](#bib.bib109)]通过将预测方差作为训练权重，强调了标签预测不一致的不确定样本。*DualGraph* [[118](#bib.bib118)]使用图神经网络，根据标签之间的结构关系对样本进行重新加权，从而消除了异常噪声样本。
- en: 'Remark: These approaches need to manually pre-specify the weighting function
    as well as there additional hyper-parameters, which is fairly hard to be applied
    in practice due to the significant variation of appropriate weighting schemes
    that rely on the noise type and training data.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：这些方法需要手动预先指定加权函数以及其他超参数，由于适当加权方案的显著变化取决于噪声类型和训练数据，这在实践中很难应用。
- en: III-D3 Label Refurbishment
  id: totrans-151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-D3 标签修正
- en: Refurbishing a noisy label $\tilde{y}$ effectively prevents overfitting to false
    labels. Let $\hat{y}$ be the current prediction of the DNN $f(x;\Theta)$. Therefore,
    the refurbished label $y^{refurb}$ can be obtained by a convex combination of
    the noisy label $\tilde{y}$ and the DNN prediction $\hat{y}$,
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对噪声标签$\tilde{y}$进行修正可以有效防止过拟合到错误标签。设$\hat{y}$为当前DNN$f(x;\Theta)$的预测值。因此，经过修正的标签$y^{refurb}$可以通过噪声标签$\tilde{y}$和DNN预测值$\hat{y}$的凸组合来获得，
- en: '|  | $y^{refurb}=\alpha\tilde{y}+(1-\alpha)\hat{y},$ |  | (12) |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '|  | $y^{refurb}=\alpha\tilde{y}+(1-\alpha)\hat{y},$ |  | (12) |'
- en: where $\alpha\in[0,1]$ is the label confidence of $\tilde{y}$. To mitigate the
    damage of incorrect labeling, this approach backpropagates the loss for the refurbished
    label instead of the noisy one, thereby yielding substantial robustness to noisy
    labels.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\alpha\in[0,1]$是$\tilde{y}$的标签置信度。为了减轻错误标注的影响，这种方法反向传播修正标签的损失，而不是噪声标签的损失，从而显著增强对噪声标签的鲁棒性。
- en: 'Technical Detail: *Bootstrapping* [[69](#bib.bib69)] is the first method that
    proposes the concept of label refurbishment to update the target label of training
    examples. It develops a more coherent network that improves its ability to evaluate
    the consistency of noisy labels, with the label confidence $\alpha$ obtained via
    cross-validation. *Dynamic bootstrapping* [[110](#bib.bib110)] dynamically adjusts
    the confidence $\alpha$ of individual training examples. The confidence $\alpha$
    is obtained by fitting a two-component and one-dimensional beta mixture model
    to the loss distribution of all training examples. *Self-adaptive training* [[119](#bib.bib119)]
    applies the exponential moving average to alleviate the instability issue of using
    instantaneous prediction of the current DNN,'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 技术细节：*自助法* [[69](#bib.bib69)]是第一个提出标签修正概念以更新训练样本目标标签的方法。它开发了一个更连贯的网络，提高了其评估噪声标签一致性的能力，标签置信度$\alpha$通过交叉验证获得。*动态自助法*
    [[110](#bib.bib110)]动态调整个体训练样本的置信度$\alpha$。置信度$\alpha$是通过将一个二维和一维的贝塔混合模型拟合到所有训练样本的损失分布上获得的。*自适应训练*
    [[119](#bib.bib119)]应用指数移动平均来减轻使用当前DNN瞬时预测的稳定性问题，
- en: '|  | $\!\!y_{t+1}^{refurb}=\alpha y_{t}^{refurb}+(1-\alpha)\hat{y},\leavevmode\nobreak\
    \text{where}\leavevmode\nobreak\ y_{0}^{refurb}=\tilde{y}\!\!$ |  | (13) |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|  | $\!\!y_{t+1}^{refurb}=\alpha y_{t}^{refurb}+(1-\alpha)\hat{y},\leavevmode\nobreak\
    \text{其中}\leavevmode\nobreak\ y_{0}^{refurb}=\tilde{y}\!\!$ |  | (13) |'
- en: '*D2L* [[111](#bib.bib111)] trains a DNN using a dimensionality-driven learning
    strategy to avoid overfitting to false labels. A simple measure called *local
    intrinsic dimensionality* [[120](#bib.bib120)] is adopted to evaluate the confidence
    $\alpha$ in considering that the overfitting is exacerbated by dimensional expansion.
    Hence, refurbished labels are generated to prevent the dimensionality of the representation
    subspace from expanding at a later stage of training. Recently, *SELFIE* [[19](#bib.bib19)]
    introduces a novel concept of *refurbishable examples* that can be corrected with
    high precision. The key idea is to consider the example with consistent label
    predictions as refurbishable because such consistent predictions correspond to
    its true label with a high probability owing to the learner’s perceptual consistency.
    Accordingly, the labels of only refurbishable examples are corrected to minimize
    the number of falsely corrected cases. Similarly, *AdaCorr* [[121](#bib.bib121)]
    selectively refurbishes the label of noisy examples, but a theoretical error-bound
    is provided. Alternatively, *SEAL* [[122](#bib.bib122)] averages the softmax output
    of a DNN on each example over the whole training process, then re-trains the DNN
    using the averaged soft labels.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '*D2L* [[111](#bib.bib111)] 使用一种基于维度的学习策略训练 DNN，以避免对错误标签的过拟合。采用一种叫做 *局部内在维度*
    [[120](#bib.bib120)] 的简单度量来评估信心 $\alpha$，认为维度扩展加剧了过拟合。因此，生成了刷新标签，以防止表示子空间的维度在训练的后期阶段扩展。最近，*SELFIE*
    [[19](#bib.bib19)] 引入了一种新的概念——*可刷新样本*，这些样本可以高精度地进行修正。关键思想是将具有一致标签预测的样本视为可刷新样本，因为这些一致的预测对应于其真实标签的概率很高，得益于学习者的感知一致性。因此，只有可刷新样本的标签会被修正，以最小化错误修正的案例数量。类似地，*AdaCorr*
    [[121](#bib.bib121)] 选择性地刷新噪声样本的标签，但提供了理论误差界。或者，*SEAL* [[122](#bib.bib122)] 在整个训练过程中对每个样本的
    DNN 的 softmax 输出进行平均，然后使用平均 soft 标签重新训练 DNN。'
- en: 'Remark: Differently from loss correction and reweighting, all the noisy labels
    are explicitly replaced with other expected clean labels (or their combination).
    If there are not many confusing classes in data, these methods work well by refurbishing
    the noisy labels with high precision. In the opposite case, the DNN could overfit
    to wrongly refurbished labels.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：与损失修正和重标定不同，所有噪声标签都被显式地替换为其他预期的干净标签（或它们的组合）。如果数据中混淆类不多，这些方法通过高精度地刷新噪声标签效果良好。相反的情况下，DNN
    可能会对错误刷新标签过拟合。
- en: III-D4 Meta Learning
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-D4 元学习
- en: In recent years, meta learning becomes an important topic in the machine learning
    community and is applied to improve noise robustness [[123](#bib.bib123), [124](#bib.bib124),
    [125](#bib.bib125)]. The key concept is *learning to learn* that performs learning
    at a level higher than conventional learning, thus achieving data-agnostic and
    noise type-agnostic rules for better practical use. It is similar to loss reweighting
    and label refurbishment, but the adjustment is automated in a meta learning manner.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，元学习成为机器学习社区的重要话题，并被应用于提高噪声鲁棒性 [[123](#bib.bib123), [124](#bib.bib124), [125](#bib.bib125)]。关键概念是
    *学习如何学习*，这在比传统学习更高的层次上进行学习，从而实现数据无关和噪声类型无关的规则，以更好地应用于实际。它类似于损失重标定和标签刷新，但调整是以元学习的方式自动进行的。
- en: 'Technical Detail: For the loss reweighting in Eq. ([11](#S3.E11 "In III-D2
    Loss Reweighting ‣ III-D Loss Adjustment ‣ III Deep Learning Approaches ‣ Learning
    from Noisy Labels with Deep Neural Networks: A Survey")), the goal is to learn
    the weight function $w(x,\tilde{y})$. Specifically, *L2LWS* [[126](#bib.bib126)]
    and *CWS* [[127](#bib.bib127)] are unified neural architectures composed of a
    target DNN and a meta-DNN. The meta-DNN is trained on a small clean validation
    dataset; it then provides guidance to evaluate the weight score for the target
    DNN. Here, part of the two DNNs are shared and jointly trained to benefit from
    each other. *Automatic reweighting* [[106](#bib.bib106)] is a meta learning algorithm
    that learns the weights of training examples based on their gradient directions.
    It includes a small clean validation dataset into the training dataset and reweights
    the backward loss of the mini-batch examples such that the updated gradient minimizes
    the loss of this validation dataset. *Meta-weight-net* [[124](#bib.bib124)] parameterizes
    the weighting function as a multi-layer perceptron network with only one hidden
    layer. A meta-objective is defined to update its parameters such that they minimize
    the empirical risk of a small clean dataset. At each iteration, the parameter
    of the target network is guided by the weight function updated via the meta-objective.
    Likewise, *data coefficients* (i.e., exemplar weights and true labels) [[128](#bib.bib128)]
    are estimated by meta-optimization with a small clean set, which is only $0.2$%
    of the entire training set, while refurbishing the examples probably mislabeled.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 技术细节：对于方程式中的损失重加权（[11](#S3.E11 "在 III-D2 损失重加权 ‣ III-D 损失调整 ‣ III 深度学习方法 ‣ 从带噪声标签中学习：综述")），目标是学习权重函数
    $w(x,\tilde{y})$。具体来说，*L2LWS* [[126](#bib.bib126)] 和 *CWS* [[127](#bib.bib127)]
    是由目标 DNN 和元 DNN 组成的统一神经网络架构。元 DNN 在一个小型干净验证数据集上训练，然后提供指导来评估目标 DNN 的权重分数。这里，两个
    DNN 部分共享并共同训练以互相受益。*自动重加权* [[106](#bib.bib106)] 是一种元学习算法，它基于训练样本的梯度方向学习权重。它将一个小型干净验证数据集纳入训练数据集中，并重新加权小批量样本的反向损失，使得更新后的梯度最小化该验证数据集的损失。*Meta-weight-net*
    [[124](#bib.bib124)] 将加权函数参数化为一个只有一层隐藏层的多层感知器网络。定义了一个元目标来更新其参数，以最小化小型干净数据集的经验风险。在每次迭代中，目标网络的参数由通过元目标更新的权重函数指导。同样，*数据系数*（即示例权重和真实标签）
    [[128](#bib.bib128)] 通过元优化估计，使用仅为整个训练集 $0.2$% 的小型干净集，同时修正可能标记错误的示例。
- en: 'For the label refurbishment in Eq. ([12](#S3.E12 "In III-D3 Label Refurbishment
    ‣ III-D Loss Adjustment ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels
    with Deep Neural Networks: A Survey")), *knowledge distillation* [[129](#bib.bib129)]
    adopts the technique of transferring knowledge from one expert model to a target
    model. The prediction from the expert DNN trained on small clean validation data
    is used instead of the prediction $\hat{y}$ from the target DNN. *MLC* [[130](#bib.bib130)]
    updates the target model with corrected labels provided by a meta model trained
    on clean validation data. The two models are trained concurrently via a bi-level
    optimization.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 对于方程式中的标签修正（[12](#S3.E12 "在 III-D3 标签修正 ‣ III-D 损失调整 ‣ III 深度学习方法 ‣ 从带噪声标签中学习：综述")），*知识蒸馏*
    [[129](#bib.bib129)] 采用将知识从一个专家模型转移到目标模型的技术。使用在小型干净验证数据上训练的专家 DNN 的预测，而不是目标 DNN
    的预测 $\hat{y}$。*MLC* [[130](#bib.bib130)] 使用由在干净验证数据上训练的元模型提供的修正标签更新目标模型。这两个模型通过双层优化并行训练。
- en: 'Remark: By learning the update rule via meta learning, the trained network
    easily adapts to various types of data and label noise. Nevertheless, unbiased
    clean validation data is essential to minimize the auxiliary objective, although
    it may not be available in real-world data.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：通过元学习学习更新规则，训练好的网络能够轻松适应各种类型的数据和标签噪声。然而，尽管在现实数据中可能无法获得，但无偏的干净验证数据对于最小化辅助目标至关重要。
- en: III-E Sample Selection
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-E 样本选择
- en: 'To avoid any false corrections, many recent studies [[70](#bib.bib70), [131](#bib.bib131),
    [112](#bib.bib112), [132](#bib.bib132), [133](#bib.bib133), [134](#bib.bib134),
    [135](#bib.bib135), [19](#bib.bib19), [136](#bib.bib136), [99](#bib.bib99), [137](#bib.bib137)]
    have adopted sample selection that involves selecting true-labeled examples from
    a noisy training dataset. In this case, the update equation in Eq. ([2](#S2.E2
    "In II-A Supervised Learning with Noisy Labels ‣ II Preliminaries ‣ Learning from
    Noisy Labels with Deep Neural Networks: A Survey")) is modified to render a DNN
    more robust for noisy labels. Let $\mathcal{C}_{t}\subseteq\mathcal{B}_{t}$ be
    the identified *clean* examples at time $t$. Then, the DNN is updated only for
    the selected clean examples $\mathcal{C}_{t}$,'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '为了避免任何错误修正，许多最近的研究 [[70](#bib.bib70), [131](#bib.bib131), [112](#bib.bib112),
    [132](#bib.bib132), [133](#bib.bib133), [134](#bib.bib134), [135](#bib.bib135),
    [19](#bib.bib19), [136](#bib.bib136), [99](#bib.bib99), [137](#bib.bib137)] 采用了样本选择方法，从噪声训练数据集中选择真实标记的样本。在这种情况下，方程
    [2](#S2.E2 "In II-A Supervised Learning with Noisy Labels ‣ II Preliminaries ‣
    Learning from Noisy Labels with Deep Neural Networks: A Survey") 中的更新方程被修改，以使
    DNN 对噪声标签更加稳健。设 $\mathcal{C}_{t}\subseteq\mathcal{B}_{t}$ 为时间 $t$ 识别出的*干净*样本。然后，DNN
    仅对选定的干净样本 $\mathcal{C}_{t}$ 进行更新，'
- en: '|  | $\Theta_{t+1}=\Theta_{t}-\eta\nabla\Big{(}\frac{1}{&#124;\mathcal{C}_{t}&#124;}\!\sum_{(x,\tilde{y})\in\mathcal{C}_{t}}\!\!\!\!\ell\big{(}f(x;\Theta_{t}),\tilde{y}\big{)}\Big{)},$
    |  | (14) |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '|  | $\Theta_{t+1}=\Theta_{t}-\eta\nabla\Big{(}\frac{1}{&#124;\mathcal{C}_{t}&#124;}\!\sum_{(x,\tilde{y})\in\mathcal{C}_{t}}\!\!\!\!\ell\big{(}f(x;\Theta_{t}),\tilde{y}\big{)}\Big{)},$
    |  | (14) |'
- en: where the rest mini-batch examples, which are likely to be false-labeled, are
    excluded to pursue robust learning.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 其中排除了可能被错误标记的其余小批量样本，以追求稳健学习。
- en: The memorization nature of DNNs has been explored theoretically and empirically
    to identify clean examples from noisy training data [[138](#bib.bib138), [139](#bib.bib139),
    [140](#bib.bib140)]. Specifically, assuming clusterable data where the clusters
    are located on the unit Euclidean ball, Li et al. [[61](#bib.bib61)] proved the
    distance from the initial weight ${W}_{0}$ to the weight ${W}_{t}$ after $t$ iterations,
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: DNN 的记忆特性已通过理论和实证研究来探索，以从噪声训练数据中识别干净的例子 [[138](#bib.bib138), [139](#bib.bib139),
    [140](#bib.bib140)]。具体来说，假设数据是可聚类的，并且聚类位于单位欧几里得球上，Li 等人 [[61](#bib.bib61)] 证明了从初始权重
    ${W}_{0}$ 到 $t$ 次迭代后的权重 ${W}_{t}$ 的距离，
- en: '|  | $\left\lVert{W}_{t}-{W}_{0}\right\rVert_{F}\lesssim\big{(}\sqrt{K}+(K^{2}\epsilon_{0}/\left\lVert{C}\right\rVert^{2})t\big{)},$
    |  | (15) |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '|  | $\left\lVert{W}_{t}-{W}_{0}\right\rVert_{F}\lesssim\big{(}\sqrt{K}+(K^{2}\epsilon_{0}/\left\lVert{C}\right\rVert^{2})t\big{)},$
    |  | (15) |'
- en: 'where $\left\lVert\cdot\right\rVert_{F}$ is the Frobenius norm, $K$ is the
    number of clusters, and ${C}$ is the set of cluster centers reaching all input
    examples within their $\epsilon_{0}$ neighborhood. Eq. ([15](#S3.E15 "In III-E
    Sample Selection ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels with
    Deep Neural Networks: A Survey")) demonstrates that the weights of DNNs start
    to stray far from the initial weights when overfitting to corrupted labels, while
    they are still in the vicinity of the initial weights at an early stage of training
    [[61](#bib.bib61), [30](#bib.bib30)]. In the empirical studies [[21](#bib.bib21),
    [141](#bib.bib141)], the *memorization effect* is also observed since DNNs tend
    to first learn simple and generalized patterns and then gradually overfit to all
    noisy patterns. As such, favoring small-loss training examples as the clean ones
    are commonly employed to design robust training methods [[112](#bib.bib112), [131](#bib.bib131),
    [135](#bib.bib135), [134](#bib.bib134), [142](#bib.bib142)].'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $\left\lVert\cdot\right\rVert_{F}$ 是 Frobenius 范数，$K$ 是聚类的数量，而 ${C}$ 是包含所有输入例子在其
    $\epsilon_{0}$ 邻域内的聚类中心集合。方程 ([15](#S3.E15 "In III-E Sample Selection ‣ III Deep
    Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks: A
    Survey")) 说明，当过拟合到损坏的标签时，DNN 的权重开始远离初始权重，而在训练的早期阶段，它们仍然接近初始权重 [[61](#bib.bib61),
    [30](#bib.bib30)]。在实证研究 [[21](#bib.bib21), [141](#bib.bib141)] 中，也观察到了*记忆效应*，因为
    DNN 往往首先学习简单的、泛化的模式，然后逐渐过拟合所有的噪声模式。因此，倾向于将小损失训练样本作为干净样本被广泛采用来设计稳健的训练方法 [[112](#bib.bib112),
    [131](#bib.bib131), [135](#bib.bib135), [134](#bib.bib134), [142](#bib.bib142)]。'
- en: Learning with sample selection is well motivated and works well in general,
    but this approach suffers from accumulated error caused by incorrect selection,
    especially when there are many ambiguous classes in training data. Hence, recent
    approaches often leverage multiple DNNs to cooperate with one another [[112](#bib.bib112)]
    or run multiple training rounds [[133](#bib.bib133)]. Moreover, to benefit from
    even false-labeled examples, loss correction or semi-supervised learning have
    been recently combined with the sample selection strategy [[19](#bib.bib19), [142](#bib.bib142)].
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 带有样本选择的学习有充分的动机，并且一般效果很好，但这种方法存在由于选择不准确而累积的错误，特别是在训练数据中有许多模糊类别时。因此，最近的方法通常利用多个DNN互相合作[[112](#bib.bib112)]或进行多次训练轮次[[133](#bib.bib133)]。此外，为了从虚假标记的样本中受益，最近将损失修正或半监督学习与样本选择策略相结合[[19](#bib.bib19),
    [142](#bib.bib142)]。
- en: '![Refer to caption](img/f2f552e7d0e2fde51781ca94a26d484a.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f2f552e7d0e2fde51781ca94a26d484a.png)'
- en: (a) Symmetric Noise $40\%$.       (b) Asymmetric Noise $40\%$.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 对称噪声 $40\%$。       (b) 非对称噪声 $40\%$。
- en: 'Figure 5: Loss distribution of training examples at the training accuracy of
    $50\%$ on noisy CIFAR-100\. (This figure is adapted from Song et al. [[141](#bib.bib141)].)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：在噪声CIFAR-100上训练准确率为$50\%$时，训练样本的损失分布。（此图改编自Song等人[[141](#bib.bib141)]。）
- en: III-E1 Multi-network Learning
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-E1 多网络学习
- en: Collaborative learning and co-training are widely used for the multi-network
    training. Consequently, the sample selection process is guided by the mentor network
    in the case of collaborative learning or the peer network in the case of co-training.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 协作学习和协同训练在多网络训练中广泛使用。因此，在协作学习的情况下，样本选择过程由导师网络指导；在协同训练的情况下，由同行网络指导。
- en: 'Technical Detail: Initially, *Decouple* [[70](#bib.bib70)] proposes the decoupling
    of when to update from how to update. Hence, two DNNs are maintained simultaneously
    and updated only the examples selected based on a disagreement between the two
    DNNs. Next, due to the memorization effect of DNNs, many researchers have adopted
    another selection criterion, called a *small-loss* trick, which treats a certain
    number of small-loss training examples as true-labeled examples; many true-labeled
    examples tend to exhibit smaller losses than false-labeled examples, as illustrated
    in Figure [5](#S3.F5 "Figure 5 ‣ III-E Sample Selection ‣ III Deep Learning Approaches
    ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey")(a). In *MentorNet*
    [[131](#bib.bib131)], a pre-trained mentor network guides the training of a student
    network in a collaborative learning manner. Based on the small-loss trick, the
    mentor network provides the student network with examples whose labels are likely
    to be correct. *Co-teaching* [[112](#bib.bib112)] and *Co-teaching+* [[132](#bib.bib132)]
    also maintain two DNNs, but each DNN selects a certain number of small-loss examples
    and feeds them to its peer DNN for further training. *Co-teaching+* further employs
    the disagreement strategy of *Decouple* compared with *Co-teaching*. In contrast,
    *JoCoR* [[143](#bib.bib143)] reduces the diversity of two networks via co-regularization,
    making predictions of the two networks closer.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 技术细节：最初，*Decouple* [[70](#bib.bib70)] 提出了将更新的时机与更新的方法分开。因此，两个DNN同时维护，仅更新基于两个DNN之间不一致选择的样本。接下来，由于DNN的记忆效应，许多研究者采用了另一种选择标准，称为*small-loss*技巧，它将一定数量的小损失训练样本视为真实标记样本；许多真实标记样本的损失通常比虚假标记样本小，如图[5](#S3.F5
    "图5 ‣ III-E 样本选择 ‣ III 深度学习方法 ‣ 从噪声标签中学习：深度神经网络的调查")(a)所示。在*MentorNet* [[131](#bib.bib131)]中，一个预训练的导师网络以协作学习的方式指导学生网络的训练。基于*small-loss*技巧，导师网络为学生网络提供标签可能正确的样本。*Co-teaching*
    [[112](#bib.bib112)]和*Co-teaching+* [[132](#bib.bib132)]也维护两个DNN，但每个DNN选择一定数量的小损失样本，并将其提供给其同行DNN进行进一步训练。与*Co-teaching*相比，*Co-teaching+*进一步采用了*Decouple*的分歧策略。相比之下，*JoCoR*
    [[143](#bib.bib143)]通过共同正则化减少两个网络的多样性，使两个网络的预测更接近。
- en: 'Remark: The co-training methods help reduce the confirmation bias [[112](#bib.bib112)],
    which is a hazard of favoring the examples selected at the beginning of training,
    while the increase in the number of learnable parameters makes their learning
    pipeline inefficient. In addition, the small-loss trick does not work well when
    the loss distribution of true-labeled and false-labeled examples largely overlap,
    as in the asymmetric noise in Figure [5](#S3.F5 "Figure 5 ‣ III-E Sample Selection
    ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")(b).'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：协同训练方法有助于减少确认偏差 [[112](#bib.bib112)]，这是一个偏向于训练开始时选择的样本的风险，而可学习参数的增加使得它们的学习管道效率低下。此外，当真实标记样本和虚假标记样本的损失分布大体重叠时，例如图
    [5](#S3.F5 "图 5 ‣ III-E 样本选择 ‣ III 深度学习方法 ‣ 从带噪声标签中学习：综述") (b) 中的不对称噪声，使用小损失技巧效果不好。
- en: III-E2 Multi-round Learning
  id: totrans-179
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-E2 多轮学习
- en: Without maintaining additional DNNs, multi-round learning iteratively refines
    the selected set of clean examples by repeating the training round. Thus, the
    selected set keeps improved as the number of rounds increases.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在不维护额外 DNN 的情况下，多轮学习通过重复训练轮次迭代地优化所选的干净样本集合。因此，随着轮次的增加，所选集合会不断改善。
- en: 'Technical Detail: *ITLM* [[134](#bib.bib134)] iteratively minimizes the trimmed
    loss by alternating between selecting true-labeled examples at the current moment
    and retraining the DNN using them. At each training round, only a fraction of
    small-loss examples obtained in the current round are used to retrain the DNN
    in the next round. *INCV* [[135](#bib.bib135)] randomly divides noisy training
    data and then employs cross-validation to classify true-labeled examples while
    removing large-loss examples at each training round. Here, *Co-teaching* is adopted
    to train the DNN on the identified examples in the final round of training. Similarly,
    *O2U-Net* [[144](#bib.bib144)] repeats the whole training process with the cyclical
    learning rate until enough loss statistics of every examples are gathered. Next,
    the DNN is re-trained from scratch only for the clean data where false-labeled
    examples have been detected and removed based on statistics.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 技术细节：*ITLM* [[134](#bib.bib134)] 通过在当前时刻选择真实标记的样本并使用这些样本重新训练 DNN 的方式，迭代地最小化修剪损失。在每轮训练中，仅使用当前轮次获得的小损失样本的一部分来在下一轮中重新训练
    DNN。*INCV* [[135](#bib.bib135)] 随机划分噪声训练数据，然后通过交叉验证对真实标记的样本进行分类，同时在每轮训练中移除大损失样本。在这里，*Co-teaching*
    被采用在最终的训练轮次中对识别出的样本进行 DNN 的训练。类似地，*O2U-Net* [[144](#bib.bib144)] 使用周期性学习率重复整个训练过程，直到收集到每个样本足够的损失统计数据。接下来，DNN
    从头开始仅对已根据统计数据检测并移除的虚假标记样本进行重新训练。
- en: A number of variations have been proposed to achieve high performance using
    iterative refinement only in a single training round. Beyond the small-loss trick,
    *iterative detection* [[133](#bib.bib133)] detects false-labeled examples by employing
    the local outlier factor algorithm [[145](#bib.bib145)]. With a Siamese network,
    it gradually pulls away false-labeled examples from true-labeled samples in the
    deep feature space. *MORPH* [[137](#bib.bib137)] introduces the concept of memorized
    examples which is used to iteratively expand an initial safe set into a maximal
    safe set via self-transitional learning. *TopoFilter* [[146](#bib.bib146)] utilizes
    the spatial topological pattern of learned representations to detect true-labeled
    examples, not relying on the prediction of the noisy classifier. *NGC* [[147](#bib.bib147)]
    iteratively constructs the nearest neighbor graph using latent representations
    and performs geometry-based sample selection by aggregating information from neighborhoods.
    Soft pesudo-labels are assigned to the examples not selected.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 已提出多种变体，以便在单轮训练中仅通过迭代优化实现高性能。除了小损失技巧，*iterative detection* [[133](#bib.bib133)]
    通过使用局部离群因子算法 [[145](#bib.bib145)] 检测虚假标记的样本。通过 Siamese 网络，它逐渐将虚假标记样本从真实标记样本中拉开，在深层特征空间中。*MORPH*
    [[137](#bib.bib137)] 引入了记忆样本的概念，用于通过自我转换学习将初始安全集合迭代扩展为最大安全集合。*TopoFilter* [[146](#bib.bib146)]
    利用学习表示的空间拓扑模式来检测真实标记样本，而不依赖于噪声分类器的预测。*NGC* [[147](#bib.bib147)] 迭代地构建使用潜在表示的最近邻图，并通过汇聚邻域中的信息执行基于几何的样本选择。对未被选择的样本分配软伪标签。
- en: 'Remark: The selected clean set keeps expanded and purified with iterative refinement,
    mainly through multi-round learning. As a side effect, the computational cost
    for training increases linearly for the number of training rounds.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：选择的干净集通过多轮学习不断扩展和净化。副作用是，训练的计算成本随着训练轮次的增加而线性增长。
- en: III-E3 Hybrid Approach
  id: totrans-184
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-E3 混合方法
- en: An inherent limitation of sample selection is to discard all the *unselected*
    training examples, thus resulting in a *partial* exploration of training data.
    To exploit all the noisy examples, researchers have attempted to combine sample
    selection with other orthogonal ideas.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 样本选择的一个固有限制是丢弃所有的*未选择*训练示例，从而导致*部分*数据探索。为了利用所有嘈杂的示例，研究人员尝试将样本选择与其他正交思想结合起来。
- en: '![Refer to caption](img/3c914bc4958eff9c7257c6ebcb6e6eec.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/3c914bc4958eff9c7257c6ebcb6e6eec.png)'
- en: (a) Noisy Data.      (b) Transformed Data.          (c) SSL.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 嘈杂数据。 (b) 转换数据。 (c) SSL。
- en: 'Figure 6: Procedures for semi-supervised learning under label noise.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：在标签噪声下的半监督学习过程。
- en: 'Technical Detail: The most prominent method in this direction is combining
    a specific sample selection strategy with a specific semi-supervised learning
    model. As illustrated in Figure [6](#S3.F6 "Figure 6 ‣ III-E3 Hybrid Approach
    ‣ III-E Sample Selection ‣ III Deep Learning Approaches ‣ Learning from Noisy
    Labels with Deep Neural Networks: A Survey"), selected examples are treated as
    labeled clean data, whereas the remaining examples are treated as unlabeled. Subsequently,
    semi-supervised learning is performed using the transformed data. *SELF* [[136](#bib.bib136)]
    is combined with a semi-supervised learning approach to progressively filter out
    false-labeled examples from noisy data. By maintaining the running average model
    called the mean-teacher [[148](#bib.bib148)] as the backbone, it obtains the self-ensemble
    predictions of all training examples and then progressively removes examples whose
    ensemble predictions do not agree with their annotated labels. This method further
    leverages unsupervised loss from the examples not included in the selected clean
    set. *DivideMix* [[142](#bib.bib142)] uses two-component and one-dimensional Gaussian
    mixture models to transform noisy data into labeled (clean) and unlabeled (noisy)
    sets. Then, it applies a semi-supervised technique *MixMatch* [[149](#bib.bib149)].
    Recently, *RoCL* [[150](#bib.bib150)] employs two-phase learning strategies: supervised
    training on selected clean examples and then semi-supervised learning on relabeled
    noisy examples with self-supervision. For selection and relabeling, it computes
    the exponential moving average of the loss over training iterations.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '技术细节：这个方向中最显著的方法是将特定的样本选择策略与特定的半监督学习模型结合起来。如图 [6](#S3.F6 "Figure 6 ‣ III-E3
    Hybrid Approach ‣ III-E Sample Selection ‣ III Deep Learning Approaches ‣ Learning
    from Noisy Labels with Deep Neural Networks: A Survey") 所示，选择的示例被视为标记的干净数据，而其余的示例被视为未标记的数据。随后，使用转换后的数据进行半监督学习。*SELF*
    [[136](#bib.bib136)] 与半监督学习方法结合，逐步从嘈杂的数据中筛选出错误标记的示例。通过保持被称为 mean-teacher [[148](#bib.bib148)]
    的运行平均模型作为骨干，它获得所有训练示例的自我集成预测，然后逐步移除那些集成预测与其注释标签不一致的示例。这种方法进一步利用未包含在选择的干净集中的示例的无监督损失。*DivideMix*
    [[142](#bib.bib142)] 使用两个组件和一维高斯混合模型将嘈杂数据转化为标记（干净）和未标记（嘈杂）集合。然后，应用半监督技术 *MixMatch*
    [[149](#bib.bib149)]。最近，*RoCL* [[150](#bib.bib150)] 采用两阶段学习策略：在选择的干净示例上进行监督训练，然后在重新标记的嘈杂示例上进行半监督学习，并进行自我监督。在选择和重新标记时，它计算训练迭代中的损失的指数移动平均。'
- en: 'Table II: Comparison of proposed robust deep learning methods with respect
    to the following six properties: (P1) Flexibility, (P2) No Pre-training, (P3) Full
    Exploration, (P4) No Supervision, (P5) Heavy Noise, and (P6) Complex Noise.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：提出的鲁棒深度学习方法在以下六个属性上的比较：(P1) 灵活性，(P2) 无需预训练，(P3) 完全探索，(P4) 无需监督，(P5) 重噪声，和
    (P6) 复杂噪声。
- en: '| Category | Method | P1 | P2 | P3 | P4 | P5 | P6 | Implementation​​ |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 方法 | P1 | P2 | P3 | P4 | P5 | P6 | 实现​​ |'
- en: '|  ​​​​​​ Robust Architecture         (§[III-A](#S3.SS1 "III-A Robust Architecture
    ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")) ​​​​​ | Noisy Adaptation         Layer | *Webly Learning*[[75](#bib.bib75)]
    | $\bigtriangleup$ | ✕ | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ | Official (Caffe)¹¹1[https://github.com/endernewton/webly-supervised](https://github.com/endernewton/webly-supervised)
    |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '|  ​​​​​​ 鲁棒架构         (§[III-A](#S3.SS1 "III-A 鲁棒架构 ‣ III 深度学习方法 ‣ 从带噪标签的深度神经网络中学习：综述"))
    ​​​​​ | 噪声适应层         | *Webly学习*[[75](#bib.bib75)] | $\bigtriangleup$ | ✕ | $\bigcirc$
    | $\bigcirc$ | ✕ | ✕ | 官方 (Caffe)¹¹1[https://github.com/endernewton/webly-supervised](https://github.com/endernewton/webly-supervised)
    |'
- en: '|  |  | *Noise Model*[[77](#bib.bib77)] | $\bigtriangleup$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | ✕ | Unofficial (Keras)²²2[https://github.com/delchiaro/training-cnn-noisy-labels-keras](https://github.com/delchiaro/training-cnn-noisy-labels-keras)
    |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *噪声模型*[[77](#bib.bib77)] | $\bigtriangleup$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | ✕ | 非官方 (Keras)²²2[https://github.com/delchiaro/training-cnn-noisy-labels-keras](https://github.com/delchiaro/training-cnn-noisy-labels-keras)
    |'
- en: '|  |  | *Dropout Noise Model*[[78](#bib.bib78)] | $\bigtriangleup$ | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ | Official (MATLAB)³³3[https://github.com/ijindal/Noisy_Dropout_regularization](https://github.com/ijindal/Noisy_Dropout_regularization)
    |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *Dropout噪声模型*[[78](#bib.bib78)] | $\bigtriangleup$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | ✕ | 官方 (MATLAB)³³3[https://github.com/ijindal/Noisy_Dropout_regularization](https://github.com/ijindal/Noisy_Dropout_regularization)
    |'
- en: '|  |  | *S-model*[[79](#bib.bib79)] | $\bigtriangleup$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | ✕ | Official (Keras)⁴⁴4[https://github.com/udibr/noisy_labels](https://github.com/udibr/noisy_labels)
    |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *S-model*[[79](#bib.bib79)] | $\bigtriangleup$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | ✕ | 官方 (Keras)⁴⁴4[https://github.com/udibr/noisy_labels](https://github.com/udibr/noisy_labels)
    |'
- en: '|  |  | *C-model*[[79](#bib.bib79)] | $\bigtriangleup$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | $\bigcirc$ | Official (Keras)⁴⁴4[https://github.com/udibr/noisy_labels](https://github.com/udibr/noisy_labels)
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *C-model*[[79](#bib.bib79)] | $\bigtriangleup$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | $\bigcirc$ | 官方 (Keras)⁴⁴4[https://github.com/udibr/noisy_labels](https://github.com/udibr/noisy_labels)
    |'
- en: '|  |  | *NLNN*[[76](#bib.bib76)] | $\bigtriangleup$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | ✕ | Unofficial (Chainer)⁵⁵5[https://github.com/Ryo-Ito/Noisy-Labels-Neural-Network](https://github.com/Ryo-Ito/Noisy-Labels-Neural-Network)
    |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *NLNN*[[76](#bib.bib76)] | $\bigtriangleup$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | ✕ | 非官方 (Chainer)⁵⁵5[https://github.com/Ryo-Ito/Noisy-Labels-Neural-Network](https://github.com/Ryo-Ito/Noisy-Labels-Neural-Network)
    |'
- en: '|  | Dedicated Architecture | *Probablistic Noise Model*[[16](#bib.bib16)]
    | ✕ | ✕ | $\bigcirc$ | ✕ | $\pagecolor{gray!10}\bigtriangleup$ | $\bigcirc$ |
    Official (Caffe)⁶⁶6[https://github.com/Cysu/noisy_label](https://github.com/Cysu/noisy_label)
    |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '|  | 专用架构 | *概率噪声模型*[[16](#bib.bib16)] | ✕ | ✕ | $\bigcirc$ | ✕ | $\pagecolor{gray!10}\bigtriangleup$
    | $\bigcirc$ | 官方 (Caffe)⁶⁶6[https://github.com/Cysu/noisy_label](https://github.com/Cysu/noisy_label)
    |'
- en: '|  |  | *Masking*[[80](#bib.bib80)] | ✕ | $\bigcirc$ | $\bigcirc$ | ✕ | $\pagecolor{gray!10}\bigtriangleup$
    | $\bigcirc$ | Official (TensorFlow)⁷⁷7[https://github.com/bhanML/Masking](https://github.com/bhanML/Masking)
    |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *遮罩*[[80](#bib.bib80)] | ✕ | $\bigcirc$ | $\bigcirc$ | ✕ | $\pagecolor{gray!10}\bigtriangleup$
    | $\bigcirc$ | 官方 (TensorFlow)⁷⁷7[https://github.com/bhanML/Masking](https://github.com/bhanML/Masking)
    |'
- en: '|  |  | *Contrastive-Additive Noise Network*[[81](#bib.bib81)] | ✕ | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | $\pagecolor{gray!10}\bigtriangleup$ | $\bigcirc$ |
    N/A |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *对比加性噪声网络*[[81](#bib.bib81)] | ✕ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\pagecolor{gray!10}\bigtriangleup$ | $\bigcirc$ | 不适用 |'
- en: '|  |  | *RoG*[[85](#bib.bib85)] | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\pagecolor{gray!10}\bigtriangleup$ | Official (PyTorch)⁸⁸8[https://github.com/pokaxpoka/RoGNoisyLabel](https://github.com/pokaxpoka/RoGNoisyLabel)
    |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *RoG*[[85](#bib.bib85)] | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\pagecolor{gray!10}\bigtriangleup$ | 官方 (PyTorch)⁸⁸8[https://github.com/pokaxpoka/RoGNoisyLabel](https://github.com/pokaxpoka/RoGNoisyLabel)
    |'
- en: '|  ​​​​​​ Robust Regularization          (§[III-B](#S3.SS2 "III-B Robust Regularization
    ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")) ​​​​​ |      Explicit Regularization | *Bilevel Learning*[[87](#bib.bib87)]
    | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigtriangleup$ | $\bigtriangleup$
    | Official (TensorFlow)⁹⁹9[https://github.com/sjenni/DeepBilevel](https://github.com/sjenni/DeepBilevel)
    |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '|  ​​​​​​ 鲁棒正则化          (§[III-B](#S3.SS2 "III-B 鲁棒正则化 ‣ III 深度学习方法 ‣ 从带噪标签的深度神经网络中学习：综述"))
    ​​​​​ |      显式正则化 | *双层学习*[[87](#bib.bib87)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | ✕ | $\bigtriangleup$ | $\bigtriangleup$ | 官方 (TensorFlow)⁹⁹9[https://github.com/sjenni/DeepBilevel](https://github.com/sjenni/DeepBilevel)
    |'
- en: '|  |  | *Annotator Confusion*[[86](#bib.bib86)] | $\bigcirc$ | ✕ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | $\bigtriangleup$ | Official (TensorFlow)^(10)^(10)10[https://rt416.github.io/pdf/trace_codes.pdf](https://rt416.github.io/pdf/trace_codes.pdf)
    |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *标注者混淆*[[86](#bib.bib86)] | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | $\bigtriangleup$ | $\bigtriangleup$ | 官方 (TensorFlow)^(10)^(10)10[https://rt416.github.io/pdf/trace_codes.pdf](https://rt416.github.io/pdf/trace_codes.pdf)
    |'
- en: '|  |  | *Pre-training*[[88](#bib.bib88)] | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | $\bigtriangleup$ | $\bigtriangleup$ | Official (PyTorch)^(11)^(11)11[github.com/hendrycks/pre-training](github.com/hendrycks/pre-training)
    |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *预训练*[[88](#bib.bib88)] | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | $\bigtriangleup$ | $\bigtriangleup$ | 官方 (PyTorch)^(11)^(11)11[github.com/hendrycks/pre-training](github.com/hendrycks/pre-training)
    |'
- en: '|  |  | *PHuber*[[89](#bib.bib89)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | $\bigtriangleup$ | $\bigtriangleup$ | Unofficial (PyTorch)^(12)^(12)12[https://github.com/dmizr/phuber](https://github.com/dmizr/phuber)
    |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *PHuber*[[89](#bib.bib89)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | $\bigtriangleup$ | $\bigtriangleup$ | 非官方 (PyTorch)^(12)^(12)12[https://github.com/dmizr/phuber](https://github.com/dmizr/phuber)
    |'
- en: '|  |  | *Robust Early-learning*[[90](#bib.bib90)] | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | $\bigtriangleup$ | Official (PyTorch)^(13)^(13)13[https://github.com/xiaoboxia/CDR](https://github.com/xiaoboxia/CDR)
    |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *稳健早期学习*[[90](#bib.bib90)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | $\bigtriangleup$ | $\bigtriangleup$ | 官方 (PyTorch)^(13)^(13)13[https://github.com/xiaoboxia/CDR](https://github.com/xiaoboxia/CDR)
    |'
- en: '|  |  | *ODLN*[[91](#bib.bib91)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigtriangleup$ | $\bigtriangleup$ | Official (PyTorch)^(14)^(14)14[https://github.com/hongxin001/ODNL?ref=pythonrepo.com](https://github.com/hongxin001/ODNL?ref=pythonrepo.com)
    |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *ODLN*[[91](#bib.bib91)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigtriangleup$ | $\bigtriangleup$ | 官方 (PyTorch)^(14)^(14)14[https://github.com/hongxin001/ODNL?ref=pythonrepo.com](https://github.com/hongxin001/ODNL?ref=pythonrepo.com)
    |'
- en: '|  |      Implicit Regularization | *Adversarial Training*[[92](#bib.bib92)]
    | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigtriangleup$ | Unofficial (PyTorch)^(15)^(15)15[https://https://github.com/sarathknv/adversarial-examples-pytorch](https://https://github.com/sarathknv/adversarial-examples-pytorch)
    |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '|  |      隐式正则化 | *对抗训练*[[92](#bib.bib92)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | $\bigtriangleup$ | 非官方 (PyTorch)^(15)^(15)15[https://https://github.com/sarathknv/adversarial-examples-pytorch](https://https://github.com/sarathknv/adversarial-examples-pytorch)
    |'
- en: '|  |  | *Label Smoothing*[[93](#bib.bib93)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | $\bigtriangleup$ | Unofficial (PyTorch)^(16)^(16)16[https://github.com/CoinCheung/pytorch-loss](https://github.com/CoinCheung/pytorch-loss)
    |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *标签平滑*[[93](#bib.bib93)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | ✕ | $\bigtriangleup$ | 非官方 (PyTorch)^(16)^(16)16[https://github.com/CoinCheung/pytorch-loss](https://github.com/CoinCheung/pytorch-loss)
    |'
- en: '|  |  | *Mixup*[[95](#bib.bib95)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | ✕ | $\bigtriangleup$ | Official (PyTorch)^(17)^(17)17[https://github.com/facebookresearch/mixup-cifar10](https://github.com/facebookresearch/mixup-cifar10)
    |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *Mixup*[[95](#bib.bib95)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | ✕ | $\bigtriangleup$ | 官方 (PyTorch)^(17)^(17)17[https://github.com/facebookresearch/mixup-cifar10](https://github.com/facebookresearch/mixup-cifar10)
    |'
- en: '| Robust Loss Function          (§[III-C](#S3.SS3 "III-C Robust Loss Function
    ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")) | *Robust MAE*[[68](#bib.bib68)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | ✕ | N/A |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 稳健损失函数          (§[III-C](#S3.SS3 "III-C Robust Loss Function ‣ III Deep
    Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks: A
    Survey")) | *稳健MAE*[[68](#bib.bib68)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | ✕ | ✕ | 不适用 |'
- en: '| *Generalized Cross Entropy*[[97](#bib.bib97)] | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | $\bigcirc$ | ✕ | ✕ | Unofficial (PyTorch)^(18)^(18)18[https://github.com/AlanChou/Truncated-Loss](https://github.com/AlanChou/Truncated-Loss)
    |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| *广义交叉熵*[[97](#bib.bib97)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | ✕ | ✕ | 非官方 (PyTorch)^(18)^(18)18[https://github.com/AlanChou/Truncated-Loss](https://github.com/AlanChou/Truncated-Loss)
    |'
- en: '| *Symmetric Cross Entropy*[[98](#bib.bib98)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | ✕ | Official (Keras)^(19)^(19)19[https://github.com/YisenWang/symmetric_cross_entropy](https://github.com/YisenWang/symmetric_cross_entropy_for_noisy_label)
    |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| *对称交叉熵*[[98](#bib.bib98)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | ✕ | ✕ | 官方 (Keras)^(19)^(19)19[https://github.com/YisenWang/symmetric_cross_entropy](https://github.com/YisenWang/symmetric_cross_entropy_for_noisy_label)
    |'
- en: '| *Bi-tempered Loss*[[104](#bib.bib104)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | $\bigtriangleup$ | Official (TensorFlow)^(20)^(20)20[https://github.com/google/bi-tempered-loss](https://github.com/google/bi-tempered-loss)
    |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| *双温损失*[[104](#bib.bib104)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigtriangleup$ | $\bigtriangleup$ | 官方 (TensorFlow)^(20)^(20)20[https://github.com/google/bi-tempered-loss](https://github.com/google/bi-tempered-loss)
    |'
- en: '| *Curriculum Learning*[[99](#bib.bib99)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | ✕ | $\bigcirc$ | $\bigtriangleup$ | N/A |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| *课程学习*[[99](#bib.bib99)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigcirc$
    | $\bigtriangleup$ | 不适用 |'
- en: '| *Active Passive Loss*[[105](#bib.bib105)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | Official (PyTorch)^(21)^(21)21[https://github.com/HanxunH/Active-Passive-Losses](https://github.com/HanxunH/Active-Passive-Losses)
    |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| *主动被动损失*[[105](#bib.bib105)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | 官方 (PyTorch)^(21)^(21)21[https://github.com/HanxunH/Active-Passive-Losses](https://github.com/HanxunH/Active-Passive-Losses)
    |'
- en: '|  ​​​​​​ Loss Adjustment        (§[III-D](#S3.SS4 "III-D Loss Adjustment ‣
    III Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")) ​​​​​ | Loss Correction | *Backward Correction*[[62](#bib.bib62)]
    | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ | ✕ | Official (Keras)^(22)^(22)22[https://github.com/giorgiop/loss-correction](https://github.com/giorgiop/loss-correction)
    |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '|  ​​​​​​ 损失调整        (§[III-D](#S3.SS4 "III-D 损失调整 ‣ III 深度学习方法 ‣ 从带噪声标签的深度神经网络中学习：综述"))
    ​​​​​ | 损失修正 | *反向修正*[[62](#bib.bib62)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | ✕ | ✕ | ✕ | 官方 (Keras)^(22)^(22)22[https://github.com/giorgiop/loss-correction](https://github.com/giorgiop/loss-correction)
    |'
- en: '|  |  | *Forward Correction*[[62](#bib.bib62)] | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | ✕ | ✕ | ✕ | Official (Keras)^(22)^(22)22[https://github.com/giorgiop/loss-correction](https://github.com/giorgiop/loss-correction)
    |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *前向修正*[[62](#bib.bib62)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕
    | ✕ | ✕ | 官方 (Keras)^(22)^(22)22[https://github.com/giorgiop/loss-correction](https://github.com/giorgiop/loss-correction)
    |'
- en: '|  |  | *Gold Loss Correction*[[107](#bib.bib107)] | $\bigcirc$ | ✕ | $\bigcirc$
    | ✕ | ✕ | ✕ | Official (PyTorch)^(23)^(23)23[https://github.com/mmazeika/glc](https://github.com/mmazeika/glc)
    |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *黄金损失修正*[[107](#bib.bib107)] | $\bigcirc$ | ✕ | $\bigcirc$ | ✕ | ✕
    | ✕ | 官方 (PyTorch)^(23)^(23)23[https://github.com/mmazeika/glc](https://github.com/mmazeika/glc)
    |'
- en: '|  |  | *T-revision*[[113](#bib.bib113)] | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | ✕ | ✕ | Official (PyTorch)^(24)^(24)24[https://github.com/xiaoboxia/T-Revision](https://github.com/xiaoboxia/T-Revision)
    |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *T修正*[[113](#bib.bib113)] | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | ✕ | ✕ | 官方 (PyTorch)^(24)^(24)24[https://github.com/xiaoboxia/T-Revision](https://github.com/xiaoboxia/T-Revision)
    |'
- en: '|  |  | *Dual T*[[114](#bib.bib114)] | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | $\bigtriangleup$ | ✕ | N/A |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *双T*[[114](#bib.bib114)] | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | $\bigtriangleup$ | ✕ | 不适用 |'
- en: '|  | Loss Reweigting | *Importance Reweighting*[[108](#bib.bib108)] | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigtriangleup$ | Unofficial (PyTorch)^(25)^(25)25[https://github.com/xiaoboxia/Classification-with-noisy-labels](https://github.com/xiaoboxia/Classification-with-noisy-labels-by-importance-reweighting)
    |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '|  | 损失重标定 | *重要性重标定*[[108](#bib.bib108)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | $\bigtriangleup$ | 非官方 (PyTorch)^(25)^(25)25[https://github.com/xiaoboxia/Classification-with-noisy-labels](https://github.com/xiaoboxia/Classification-with-noisy-labels-by-importance-reweighting)
    |'
- en: '|  |  | *Active Bias*[[109](#bib.bib109)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | $\bigtriangleup$ | Unofficial (TensorFlow)^(26)^(26)26[https://github.com/songhwanjun/ActiveBias](https://github.com/songhwanjun/ActiveBias)​​
    |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *主动偏差*[[109](#bib.bib109)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | ✕ | $\bigtriangleup$ | 非官方 (TensorFlow)^(26)^(26)26[https://github.com/songhwanjun/ActiveBias](https://github.com/songhwanjun/ActiveBias)​​
    |'
- en: '|  |  | *DualGraph*[[118](#bib.bib118)] | ✕ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | N/A |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *双图*[[118](#bib.bib118)] | ✕ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | 不适用 |'
- en: '|  | Label Refurbishment | *Bootstrapping*[[69](#bib.bib69)] | $\bigcirc$ |
    $\bigcirc$ | $\bigcirc$ | ✕ | ✕ | $\bigtriangleup$ | Unofficial (Keras)^(27)^(27)27[https://github.com/dr-darryl-wright/Noisy-Labels-with-Bootstrapping](https://github.com/dr-darryl-wright/Noisy-Labels-with-Bootstrapping)
    |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '|  | 标签修复 | *自举法*[[69](#bib.bib69)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | ✕ | ✕ | $\bigtriangleup$ | 非官方 (Keras)^(27)^(27)27[https://github.com/dr-darryl-wright/Noisy-Labels-with-Bootstrapping](https://github.com/dr-darryl-wright/Noisy-Labels-with-Bootstrapping)
    |'
- en: '|  |  | *Dynamic Bootstrapping*[[110](#bib.bib110)] | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigtriangleup$ | Official (PyTorch)^(28)^(28)28[https://github.com/PaulAlbert31/LabelNoiseCorrection](https://github.com/PaulAlbert31/LabelNoiseCorrection)
    |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *动态自举*[[110](#bib.bib110)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | ✕ | $\bigtriangleup$ | 官方 (PyTorch)^(28)^(28)28[https://github.com/PaulAlbert31/LabelNoiseCorrection](https://github.com/PaulAlbert31/LabelNoiseCorrection)
    |'
- en: '|  |  | *Self-adaptive Training*[[119](#bib.bib119)] | $\bigcirc$ | ✕ | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | Official (PyTorch)^(29)^(29)29[https://github.com/LayneH/self-adaptive-training](https://github.com/LayneH/self-adaptive-training)
    |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *自适应训练*[[119](#bib.bib119)] | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | 官方 (PyTorch)^(29)^(29)29[https://github.com/LayneH/self-adaptive-training](https://github.com/LayneH/self-adaptive-training)
    |'
- en: '|  |  | *D2L*[[111](#bib.bib111)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | ✕ | $\bigtriangleup$ | Official (Keras)^(30)^(30)30[https://github.com/xingjunm/dimensionality-driven-learning](https://github.com/xingjunm/dimensionality-driven-learning)
    |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *D2L*[[111](#bib.bib111)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | ✕ | $\bigtriangleup$ | 官方 (Keras)^(30)^(30)30[https://github.com/xingjunm/dimensionality-driven-learning](https://github.com/xingjunm/dimensionality-driven-learning)
    |'
- en: '|  |  | *AdaCorr*[[121](#bib.bib121)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | Official (PyTorch)^(31)^(31)31[https://github.com/pingqingsheng/LRT](https://github.com/pingqingsheng/LRT)
    |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *AdaCorr*[[121](#bib.bib121)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | 官方 (PyTorch)^(31)^(31)31[https://github.com/pingqingsheng/LRT](https://github.com/pingqingsheng/LRT)
    |'
- en: '|  |  | *SEAL*[[122](#bib.bib122)] | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | Official (PyTorch)^(32)^(32)32[https://github.com/chenpf1025/IDN](https://github.com/chenpf1025/IDN)
    |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *SEAL*[[122](#bib.bib122)] | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | 官方 (PyTorch)^(32)^(32)32[https://github.com/chenpf1025/IDN](https://github.com/chenpf1025/IDN)
    |'
- en: '|  | Meta Learning | *L2LWS*[[126](#bib.bib126)] | ✕ | $\bigcirc$ | $\bigcirc$
    | ✕ | $\bigtriangleup$ | $\bigtriangleup$ | Unofficial (TensorFlow)^(33)^(33)33[https://github.com/krayush07/learn-by-weak-supervision](https://github.com/krayush07/learn-by-weak-supervision)​​
    |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '|  | 元学习 | *L2LWS*[[126](#bib.bib126)] | ✕ | $\bigcirc$ | $\bigcirc$ | ✕ |
    $\bigtriangleup$ | $\bigtriangleup$ | 非官方 (TensorFlow)^(33)^(33)33[https://github.com/krayush07/learn-by-weak-supervision](https://github.com/krayush07/learn-by-weak-supervision)​​
    |'
- en: '|  |  | *CWS*[[127](#bib.bib127)] | ✕ | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigtriangleup$
    | $\bigtriangleup$ | N/A |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *CWS*[[127](#bib.bib127)] | ✕ | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigtriangleup$
    | $\bigtriangleup$ | 不适用 |'
- en: '|  |  | *Automatic Reweighting*[[106](#bib.bib106)] | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | $\bigtriangleup$ | $\bigtriangleup$ | Official (TensorFlow)^(34)^(34)34[https://github.com/uber-research/learning-to-reweight-examples](https://github.com/uber-research/learning-to-reweight-examples)
    |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *自动重标定*[[106](#bib.bib106)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | ✕ | $\bigtriangleup$ | $\bigtriangleup$ | 官方 (TensorFlow)^(34)^(34)34[https://github.com/uber-research/learning-to-reweight-examples](https://github.com/uber-research/learning-to-reweight-examples)
    |'
- en: '|  |  | *Meta-weight-net*[[124](#bib.bib124)] | $\bigtriangleup$ | $\bigcirc$
    | $\bigcirc$ | ✕ | $\bigtriangleup$ | $\bigtriangleup$ | Official (PyTorch)^(35)^(35)35[https://github.com/xjtushujun/meta-weight-net](https://github.com/xjtushujun/meta-weight-net)
    |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *Meta-weight-net*[[124](#bib.bib124)] | $\bigtriangleup$ | $\bigcirc$
    | $\bigcirc$ | ✕ | $\bigtriangleup$ | $\bigtriangleup$ | 官方 (PyTorch)^(35)^(35)35[https://github.com/xjtushujun/meta-weight-net](https://github.com/xjtushujun/meta-weight-net)
    |'
- en: '|  |  | *Data Coefficients*[[128](#bib.bib128)] | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | ✕ | $\bigtriangleup$ | $\bigtriangleup$ | Official (TensorFlow)^(36)^(36)36[https://github.com/google-research/google-research/tree/master/ieg](https://github.com/google-research/google-research/tree/master/ieg)
    |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *数据系数*[[128](#bib.bib128)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    ✕ | $\bigtriangleup$ | $\bigtriangleup$ | 官方 (TensorFlow)^(36)^(36)36[https://github.com/google-research/google-research/tree/master/ieg](https://github.com/google-research/google-research/tree/master/ieg)
    |'
- en: '|  |  | *Knowledge Distillation*[[129](#bib.bib129)] | $\bigcirc$ | ✕ | $\bigcirc$
    | ✕ | $\bigtriangleup$ | $\bigtriangleup$ | N/A |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *知识蒸馏*[[129](#bib.bib129)] | $\bigcirc$ | ✕ | $\bigcirc$ | ✕ | $\bigtriangleup$
    | $\bigtriangleup$ | 不适用 |'
- en: '|  |  | *MLC*[[130](#bib.bib130)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    ✕ | $\bigtriangleup$ | $\bigcirc$ | Official (PyTorch)^(37)^(37)37[https://aka.ms/MLC](https://aka.ms/MLC)
    |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *MLC*[[130](#bib.bib130)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    ✕ | $\bigtriangleup$ | $\bigcirc$ | 官方 (PyTorch)^(37)^(37)37[https://aka.ms/MLC](https://aka.ms/MLC)
    |'
- en: '|  ​​​​​​ Sample Selection        (§[III-E](#S3.SS5 "III-E Sample Selection
    ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")) ​​​​​ | Multi-Network      Learning | *Decouple*[[70](#bib.bib70)]
    | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigcirc$ | ✕ | $\bigtriangleup$ | Official (TensorFlow)^(38)^(38)38[https://github.com/emalach/UpdateByDisagreement](https://github.com/emalach/UpdateByDisagreement)
    |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '|  ​​​​​​ 样本选择        (§[III-E](#S3.SS5 "III-E 样本选择 ‣ III 深度学习方法 ‣ 从噪声标签中学习：综述"))
    ​​​​​ | 多网络      学习 | *Decouple*[[70](#bib.bib70)] | $\bigcirc$ | $\bigcirc$ |
    ✕ | $\bigcirc$ | ✕ | $\bigtriangleup$ | 官方 (TensorFlow)^(38)^(38)38[https://github.com/emalach/UpdateByDisagreement](https://github.com/emalach/UpdateByDisagreement)
    |'
- en: '|  |  | *MentorNet*[[131](#bib.bib131)] | ✕ | ✕ | ✕ | ✕ | $\bigcirc$ | $\bigtriangleup$
    | Official (TensorFlow)^(39)^(39)39[https://github.com/google/mentornet](https://github.com/google/mentornet)
    |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *MentorNet*[[131](#bib.bib131)] | ✕ | ✕ | ✕ | ✕ | $\bigcirc$ | $\bigtriangleup$
    | 官方 (TensorFlow)^(39)^(39)39[https://github.com/google/mentornet](https://github.com/google/mentornet)
    |'
- en: '|  |  | *Co-teaching*[[112](#bib.bib112)] | $\bigcirc$ | $\bigcirc$ | ✕ | ✕
    | $\bigcirc$ | $\bigtriangleup$ | Official (PyTorch)^(40)^(40)40[https://github.com/bhanML/Co-teaching](https://github.com/bhanML/Co-teaching)
    |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *Co-teaching*[[112](#bib.bib112)] | $\bigcirc$ | $\bigcirc$ | ✕ | ✕
    | $\bigcirc$ | $\bigtriangleup$ | 官方 (PyTorch)^(40)^(40)40[https://github.com/bhanML/Co-teaching](https://github.com/bhanML/Co-teaching)
    |'
- en: '|  |  | *Co-teaching+*[[132](#bib.bib132)] | $\bigcirc$ | $\bigcirc$ | ✕ |
    ✕ | $\bigcirc$ | $\bigtriangleup$ | Official (PyTorch)^(41)^(41)41[https://github.com/bhanML/coteaching_plus](https://github.com/bhanML/coteaching_plus)
    |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *Co-teaching+*[[132](#bib.bib132)] | $\bigcirc$ | $\bigcirc$ | ✕ |
    ✕ | $\bigcirc$ | $\bigtriangleup$ | 官方 (PyTorch)^(41)^(41)41[https://github.com/bhanML/coteaching_plus](https://github.com/bhanML/coteaching_plus)
    |'
- en: '|  |  | *JoCoR*[[143](#bib.bib143)] | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ | $\bigcirc$
    | $\bigtriangleup$ | Official (PyTorch)^(42)^(42)42[https://github.com/hongxin001/JoCoR](https://github.com/hongxin001/JoCoR)
    |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *JoCoR*[[143](#bib.bib143)] | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ | $\bigcirc$
    | $\bigtriangleup$ | 官方 (PyTorch)^(42)^(42)42[https://github.com/hongxin001/JoCoR](https://github.com/hongxin001/JoCoR)
    |'
- en: '|  | Multi-Round Learning | *ITLM*[[134](#bib.bib134)] | $\bigcirc$ | $\bigcirc$
    | ✕ | ✕ | $\bigcirc$ | $\bigtriangleup$ | Official (GluonCV)^(43)^(43)43[https://github.com/yanyao-shen/ITLM-simplecode](https://github.com/yanyao-shen/ITLM-simplecode)
    |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '|  | 多轮学习 | *ITLM*[[134](#bib.bib134)] | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ |
    $\bigcirc$ | $\bigtriangleup$ | 官方 (GluonCV)^(43)^(43)43[https://github.com/yanyao-shen/ITLM-simplecode](https://github.com/yanyao-shen/ITLM-simplecode)
    |'
- en: '|  |  | *INCV*[[135](#bib.bib135)] | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | Official (Keras)^(44)^(44)44[https://github.com/chenpf1025/noisy_label_understanding_utilizing](https://github.com/chenpf1025/noisy_label_understanding_utilizing)
    |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *INCV*[[135](#bib.bib135)] | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | 官方 (Keras)^(44)^(44)44[https://github.com/chenpf1025/noisy_label_understanding_utilizing](https://github.com/chenpf1025/noisy_label_understanding_utilizing)
    |'
- en: '|  |  | *O2U-Net*[[144](#bib.bib144)] | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ | $\bigcirc$
    | $\bigtriangleup$ | Unofficial (PyTorch)^(45)^(45)45[https://github.com/hjimce/O2U-Net](https://github.com/hjimce/O2U-Net)
    |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *O2U-Net*[[144](#bib.bib144)] | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ | $\bigcirc$
    | $\bigtriangleup$ | 非官方 (PyTorch)^(45)^(45)45[https://github.com/hjimce/O2U-Net](https://github.com/hjimce/O2U-Net)
    |'
- en: '|  |  | *Iterative Detection*[[133](#bib.bib133)] | $\bigcirc$ | $\bigcirc$
    | ✕ | $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | Official (Keras)^(46)^(46)46[https://github.com/YisenWang/Iterative_learning](https://github.com/YisenWang/Iterative_learning)
    |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *Iterative Detection*[[133](#bib.bib133)] | $\bigcirc$ | $\bigcirc$
    | ✕ | $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | 官方 (Keras)^(46)^(46)46[https://github.com/YisenWang/Iterative_learning](https://github.com/YisenWang/Iterative_learning)
    |'
- en: '|  |  | *MORPH*[[137](#bib.bib137)] | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | N/A |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *MORPH*[[137](#bib.bib137)] | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | 无 |'
- en: '|  |  | *TopoFilter*[[146](#bib.bib146)] | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | Official (PyTorch)^(47)^(47)47[https://github.com/pxiangwu/TopoFilter](https://github.com/pxiangwu/TopoFilter)
    |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *TopoFilter*[[146](#bib.bib146)] | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | 官方 (PyTorch)^(47)^(47)47[https://github.com/pxiangwu/TopoFilter](https://github.com/pxiangwu/TopoFilter)
    |'
- en: '|  |  | *NGC*[[147](#bib.bib147)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | N/A |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *NGC*[[147](#bib.bib147)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | 无 |'
- en: '|  | Hybrid Approach | *SELFIE*[[19](#bib.bib19)] | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigtriangleup$ | Official (TensorFlow)^(48)^(48)48[https://github.com/kaist-dmlab/SELFIE](https://github.com/kaist-dmlab/SELFIE)
    |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '|  | 混合方法 | *SELFIE*[[19](#bib.bib19)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | ✕ | $\bigcirc$ | $\bigtriangleup$ | 官方 (TensorFlow)^(48)^(48)48[https://github.com/kaist-dmlab/SELFIE](https://github.com/kaist-dmlab/SELFIE)
    |'
- en: '|  |  | *SELF*[[136](#bib.bib136)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | N/A |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *SELF*[[136](#bib.bib136)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | 不适用 |'
- en: '|  |  | *DivideMix*[[142](#bib.bib142)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | Official (PyTorch)^(49)^(49)49[https://github.com/LiJunnan1992/DivideMix](https://github.com/LiJunnan1992/DivideMix)
    |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *DivideMix*[[142](#bib.bib142)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | 官方 (PyTorch)^(49)^(49)49[https://github.com/LiJunnan1992/DivideMix](https://github.com/LiJunnan1992/DivideMix)
    |'
- en: '|  |  | *RoCL*[[150](#bib.bib150)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | N/A |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *RoCL*[[150](#bib.bib150)] | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ |
    $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$ | 不适用 |'
- en: 'Table III: Comparison of robust deep learning categories for overcoming noisy
    labels.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '表 III: 克服噪声标签的鲁棒深度学习类别比较。'
- en: '| Category | P1 | P2 | P3 | P4 | P5 | P6 |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | P1 | P2 | P3 | P4 | P5 | P6 |'
- en: '| ​​​Flexibility​​​ | ​​​No Pre-train​​​ | ​​​Full Exploration​​​ | ​​​No Supervision​​​
    | ​​​Heavy Noise​​​ | ​​​Complex Noise​​​ |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| ​​​灵活性​​​ | ​​​无需预训练​​​ | ​​​全面探索​​​ | ​​​无需监督​​​ | ​​​重噪声​​​ | ​​​复杂噪声​​​
    |'
- en: '| Robust Architecture​​​        (§[III-A](#S3.SS1 "III-A Robust Architecture
    ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")) | ​​Noise Adaptation Layer | $\bigtriangleup$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | ✕ | ✕ |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 鲁棒架构​​​        (§[III-A](#S3.SS1 "III-A 鲁棒架构 ‣ III 深度学习方法 ‣ 从带噪声标签中学习的深度神经网络：综述"))
    | ​​噪声适应层 | $\bigtriangleup$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ |'
- en: '|  | ​​Dedicated Architecture | ✕ | $\bigtriangleup$ | $\bigcirc$ | $\bigtriangleup$
    | $\bigtriangleup$ | $\bigcirc$ |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '|  | ​​专用架构 | ✕ | $\bigtriangleup$ | $\bigcirc$ | $\bigtriangleup$ | $\bigtriangleup$
    | $\bigcirc$ |'
- en: '| Robust Regularization​​​​​​        (§[III-B](#S3.SS2 "III-B Robust Regularization
    ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")) | ​​Implicit Regularization | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ | $\bigtriangleup$ |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 鲁棒正则化​​​​​​        (§[III-B](#S3.SS2 "III-B 鲁棒正则化 ‣ III 深度学习方法 ‣ 从带噪声标签中学习的深度神经网络：综述"))
    | ​​隐式正则化 | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$
    | $\bigtriangleup$ |'
- en: '|  | ​​Explicit Regularization | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | ✕ | $\bigtriangleup$ |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '|  | ​​显式正则化 | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigtriangleup$
    |'
- en: '| Robust Loss Function (§[III-C](#S3.SS3 "III-C Robust Loss Function ‣ III
    Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")) | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 鲁棒损失函数 (§[III-C](#S3.SS3 "III-C 鲁棒损失函数 ‣ III 深度学习方法 ‣ 从带噪声标签中学习的深度神经网络：综述"))
    | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ |'
- en: '| ​ Loss Adjustment        (§[III-D](#S3.SS4 "III-D Loss Adjustment ‣ III Deep
    Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks: A
    Survey")) | ​​Loss Correction | $\bigcirc$ | ✕ | $\bigcirc$ | ✕ | ✕ | ✕ |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| ​ 损失调整        (§[III-D](#S3.SS4 "III-D 损失调整 ‣ III 深度学习方法 ‣ 从带噪声标签中学习的深度神经网络：综述"))
    | ​​损失修正 | $\bigcirc$ | ✕ | $\bigcirc$ | ✕ | ✕ | ✕ |'
- en: '|  | ​​Loss Reweighting | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | ✕ | $\bigtriangleup$ |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '|  | ​​损失重标定 | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigtriangleup$
    |'
- en: '|  | ​​Label Refurbishment | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigtriangleup$ | $\bigtriangleup$ |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '|  | ​​标签修整 | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$
    | $\bigtriangleup$ |'
- en: '|  | ​​Meta Learning | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigtriangleup$
    | $\bigtriangleup$ |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '|  | ​​元学习 | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigtriangleup$ |
    $\bigtriangleup$ |'
- en: '| Sample Selection        (§[III-E](#S3.SS5 "III-E Sample Selection ‣ III Deep
    Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks: A
    Survey")) | ​​Multi-Network Learning | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ | $\bigcirc$
    | $\bigtriangleup$ |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 样本选择        (§[III-E](#S3.SS5 "III-E 样本选择 ‣ III 深度学习方法 ‣ 从带噪声标签中学习的深度神经网络：综述"))
    | ​​多网络学习 | $\bigcirc$ | $\bigcirc$ | ✕ | ✕ | $\bigcirc$ | $\bigtriangleup$ |'
- en: '|  | ​​Multi-Round Learning | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$
    | $\bigtriangleup$ |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '|  | ​​多轮学习 | $\bigcirc$ | $\bigcirc$ | ✕ | $\bigcirc$ | $\bigcirc$ | $\bigtriangleup$
    |'
- en: '|  | ​​Hybrid Approach | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigcirc$ | $\bigtriangleup$ |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '|  | ​​混合方法 | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$ | $\bigcirc$
    | $\bigtriangleup$ |'
- en: Meanwhile, *SELFIE* [[19](#bib.bib19)] is a hybrid approach of sample selection
    and loss correction. The loss of refurbishable examples is corrected (i.e., loss
    correction) and then used together with that of small-loss examples (i.e., sample
    selection). Consequently, more training examples are considered for updating the
    DNN. The *curriculum loss (CL)* [[99](#bib.bib99)] is combined with the robust
    loss function approach and used to extract the true-labeled examples from noisy
    data.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，*SELFIE* [[19](#bib.bib19)] 是一种样本选择和损失修正的混合方法。对可修复示例的损失进行修正（即，损失修正），然后与小损失示例的损失一起使用（即，样本选择）。因此，更多的训练示例被考虑用于更新深度神经网络。*课程损失（CL）*
    [[99](#bib.bib99)] 与鲁棒损失函数方法结合使用，用于从噪声数据中提取真实标签的示例。
- en: 'Remark: Noise robustness is significantly improved by combining with other
    techniques. However, the hyperparameters introduced by these techniques render
    a DNN more susceptible to changes in data and noise types, and an increase in
    computational cost is inevitable'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 注：通过与其他技术结合可以显著提高噪声鲁棒性。然而，这些技术引入的超参数使得深度神经网络对数据和噪声类型的变化更加敏感，计算成本的增加也是不可避免的。
- en: IV Methodological Comparison
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 方法比较
- en: 'In this section, we compare the $62$ deep learning methods for overcoming noisy
    labels introduced in Section [III](#S3 "III Deep Learning Approaches ‣ Learning
    from Noisy Labels with Deep Neural Networks: A Survey") with respect to the following
    *six* properties. When selecting the properties, we refer to the properties that
    are typically used to compare the performance of robust deep learning methods
    [[112](#bib.bib112), [19](#bib.bib19)]. To the best of our knowledge, this survey
    is the first to provide a systematic comparison of robust training methods. This
    comprehensive comparison will provide useful insights that can enlighten new future
    directions.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将第[III](#S3 "III 深度学习方法 ‣ 从噪声标签中学习：综述")节中介绍的$62$种深度学习方法用于克服噪声标签的比较，涉及以下*六*个属性。在选择这些属性时，我们参考了通常用于比较鲁棒深度学习方法性能的属性[[112](#bib.bib112),
    [19](#bib.bib19)]。据我们所知，这项综述是首个提供系统比较鲁棒训练方法的研究。这一全面比较将提供有用的见解，为未来的研究方向提供启发。
- en: •
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '(P1) Flexibility: With the rapid evolution of deep learning research, a number
    of new network architectures are constantly emerging and becoming available. Hence,
    the ability to support any type of architecture is important. “Flexibility” ensures
    that the proposed method can quickly adapt to the state-of-the-art architecture.'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (P1) 灵活性：随着深度学习研究的迅速发展，各种新网络架构不断出现并变得可用。因此，支持任何类型架构的能力很重要。“灵活性”确保所提出的方法能够迅速适应最先进的架构。
- en: •
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '(P2) No Pre-training: A typical approach to improve noise robustness is to
    use a pre-trained network; however, this incurs an additional computational cost
    to the learning process. “No Pre-training” ensures that the proposed method can
    be trained from scratch without any pre-training.'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (P2) 无预训练：提高噪声鲁棒性的典型方法是使用预训练网络；然而，这会给学习过程带来额外的计算成本。“无预训练”确保所提出的方法可以从头开始进行训练，而不需要任何预训练。
- en: •
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '(P3) Full Exploration: Excluding unreliable examples from the update is an
    effective method for robust deep learning; however, it eliminates hard but useful
    training examples as well. “Full Exploration” ensures that the proposed methods
    can use *all* training examples without severe overfitting to false-labeled examples
    by adjusting their training losses or applying semi-supervised learning.'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (P3) 全面探索：排除不可靠示例的更新是提高深度学习鲁棒性的一种有效方法；然而，它也会排除那些困难但有用的训练示例。“全面探索”确保所提出的方法可以使用*所有*训练示例，而不会因为调整训练损失或应用半监督学习而严重过拟合于错误标记的示例。
- en: •
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '(P4) No Supervision: Learning with supervision, such as a clean validation
    set or a known noise rate, is often impractical because they are difficult to
    obtain. Hence, such supervision had better be avoided to increase practicality
    in real-world scenarios. “No Supervision” ensures that the proposed methods can
    be trained without any supervision.'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (P4) 无需监督：有监督的学习，如干净的验证集或已知的噪声率，通常不切实际，因为这些数据难以获得。因此，最好避免这种监督，以提高实际应用中的实用性。“无需监督”确保所提出的方法可以在没有任何监督的情况下进行训练。
- en: •
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '(P5) Heavy Noise: In real-world noisy data, the noise rate can vary from light
    to heavy. Hence, learning methods should achieve consistent noise robustness with
    respect to the noise rate. “Heavy Noise” ensures that the proposed methods can
    combat even the heavy noise.'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (P5) 重噪声：在实际噪声数据中，噪声率可能从轻微到严重不等。因此，学习方法应在噪声率方面实现一致的噪声鲁棒性。“重噪声”确保所提出的方法可以应对甚至是严重的噪声。
- en: •
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '(P6) Complex Noise: The type of label noise significantly affects the performance
    of a learning method. To manage real-world noisy data, diverse types of label
    noise should be considered when designing a robust training method. “Complex Noise”
    ensures that the proposed method can combat even the complex label noise.'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (P6) 复杂噪声：标签噪声的类型显著影响学习方法的性能。为了处理现实世界中的噪声数据，在设计鲁棒训练方法时应考虑多种类型的标签噪声。“复杂噪声”确保所提出的方法能够应对复杂的标签噪声。
- en: 'Table [II](#S3.T2 "Table II ‣ III-E3 Hybrid Approach ‣ III-E Sample Selection
    ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey") shows a comparison of all robust deep learning methods, which are grouped
    according to the most appropriate category. In the first row, the aforementioned
    six properties are labeled as P1–P6, and the availability of open-source implementation
    is added in the last column. For each property, we assign “$\bigcirc$” if it is
    completely supported, “✕” if it is not supported, and “$\bigtriangleup$” if it
    is supported but not completely. More specifically, “$\bigtriangleup$” is assigned
    to P1 if the method can be flexible but requires additional effort, to P5 if the
    method can combat only moderate label noise, and to P6 if the method does not
    make a strict assumption about the noise type but without explicitly modeling
    instance-dependent noise. Thus, for P6, the method marked with “✕” only deals
    with the instance-independent noise, while the method marked with “$\bigcirc$”
    deals with both instance-independent and -dependent noises. The remaining properties (i.e.,
    P2, P3, and P4) are only assigned “$\bigcirc$” or “✕”. Regarding the implementation,
    we assign “N/A” if a publicly available source code is not available.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [II](#S3.T2 "Table II ‣ III-E3 Hybrid Approach ‣ III-E Sample Selection ‣
    III Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey") 显示了所有鲁棒深度学习方法的比较，这些方法根据最合适的类别进行了分组。在第一行中，前述的六个属性被标记为 P1–P6，并且最后一列添加了开源实现的可用性。对于每个属性，我们赋予“$\bigcirc$”如果它被完全支持，“✕”如果不被支持，以及“$\bigtriangleup$”如果被支持但不完全支持。更具体地说，如果方法可以灵活应对但需要额外努力，则
    P1 标记为“$\bigtriangleup$”；如果方法只能应对中等标签噪声，则 P5 标记为“$\bigtriangleup$”；如果方法没有对噪声类型做严格假设但没有明确建模实例依赖噪声，则
    P6 标记为“$\bigtriangleup$”。因此，对于 P6，标记为“✕” 的方法仅处理实例无关噪声，而标记为“$\bigcirc$” 的方法处理实例无关和依赖噪声。其余属性（即
    P2、P3 和 P4）仅标记为“$\bigcirc$”或“✕”。关于实现，我们在没有公开源代码的情况下标记为“N/A”。'
- en: 'No existing method supports all the properties. Each method achieves noise
    robustness by supporting a different combination of the properties. The supported
    properties are similar among the methods of the same (sub-)category because those
    methods share the same methodological philosophy; however, they differ significantly
    depending on the (sub-)category. Therefore, we investigate the properties generally
    supported in each (sub-)category and summarize them in Table [III](#S3.T3 "Table
    III ‣ III-E3 Hybrid Approach ‣ III-E Sample Selection ‣ III Deep Learning Approaches
    ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey"). Here, the
    property of a (sub-)category is marked as the majority of the belonging methods.
    If no clear trend is observed among those methods, then the property is marked
    “$\bigtriangleup$”.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '目前没有现有的方法支持所有属性。每种方法通过支持不同的属性组合来实现噪声鲁棒性。由于这些方法共享相同的方法论理念，因此在相同（子）类别的方法之间，支持的属性是相似的；然而，根据（子）类别的不同，它们之间的差异是显著的。因此，我们调查了每个（子）类别中普遍支持的属性，并在表
    [III](#S3.T3 "Table III ‣ III-E3 Hybrid Approach ‣ III-E Sample Selection ‣ III
    Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey") 中总结了这些属性。在这里，（子）类别的属性标记为大多数所属方法。如果在这些方法中没有观察到明确的趋势，则该属性标记为“$\bigtriangleup$”。'
- en: V Noise Rate Estimation
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 噪声率估计
- en: The estimation of a noise rate is an imperative part of utilizing robust methods
    for better practical use, especially with the approaches belonging to the loss
    adjustment and sample selection. The estimated noise rate is widely used to reweight
    examples for a robust classifier [[97](#bib.bib97), [114](#bib.bib114), [117](#bib.bib117)]
    or to determine how many examples should be selected as clean ones [[112](#bib.bib112),
    [19](#bib.bib19), [135](#bib.bib135)]. However, detailed analysis has yet to be
    performed properly, though many robust approaches highly rely on the accuracy
    of noise rate estimation. The noise rate can be estimated by exploiting the inferred
    noise transition matrix [[113](#bib.bib113), [114](#bib.bib114), [151](#bib.bib151)],
    the Gaussian mixture model [[110](#bib.bib110), [152](#bib.bib152), [137](#bib.bib137)],
    or the cross-validation [[135](#bib.bib135), [19](#bib.bib19)].
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声率的估计是利用稳健方法进行更好实际应用的关键部分，尤其是在属于损失调整和样本选择的方法中。估计的噪声率被广泛用于重新加权样本以用于稳健分类器 [[97](#bib.bib97),
    [114](#bib.bib114), [117](#bib.bib117)]，或确定应选择多少样本作为干净样本 [[112](#bib.bib112),
    [19](#bib.bib19), [135](#bib.bib135)]。然而，尽管许多稳健方法高度依赖于噪声率估计的准确性，但详细分析尚未得到妥善进行。噪声率可以通过利用推断的噪声转移矩阵
    [[113](#bib.bib113), [114](#bib.bib114), [151](#bib.bib151)]、高斯混合模型 [[110](#bib.bib110),
    [152](#bib.bib152), [137](#bib.bib137)] 或交叉验证 [[135](#bib.bib135), [19](#bib.bib19)]
    来估计。
- en: V-A Noise Transition Matrix
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-A 噪声转移矩阵
- en: 'The noise transition matrix has been used to build a statistically consistent
    robust classifier because it represents the class posterior probabilities for
    noisy and clean data, as in Eq. ([3](#S3.E3 "In III-A1 Noise Adaptation Layer
    ‣ III-A Robust Architecture ‣ III Deep Learning Approaches ‣ Learning from Noisy
    Labels with Deep Neural Networks: A Survey")). The first method to estimate the
    noise rate is exploiting this noise transition matrix, which can be inferred or
    trained accurately by using perfectly clean examples, i.e., *anchor points* [[117](#bib.bib117),
    [153](#bib.bib153)]; an example $x$ with its label $i$ is defined as an anchor
    point if $p(y=i|x)=1$ and $p(y=k|x)=0$ for $k\neq i$. Thus, let $\mathcal{A}_{i}$
    be the set of anchor points with label $i$, then the element of the noise transition
    matrix $T_{ij}$ is estimated by'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '噪声转移矩阵已被用于构建统计一致的稳健分类器，因为它表示了噪声和干净数据的类后验概率，如方程 ([3](#S3.E3 "In III-A1 Noise
    Adaptation Layer ‣ III-A Robust Architecture ‣ III Deep Learning Approaches ‣
    Learning from Noisy Labels with Deep Neural Networks: A Survey"))。估计噪声率的第一种方法是利用这个噪声转移矩阵，它可以通过使用完全干净的样本，即*锚点*
    [[117](#bib.bib117), [153](#bib.bib153)]，准确推断或训练；如果一个样本 $x$ 的标签 $i$ 被定义为锚点，则 $p(y=i|x)=1$
    且 $p(y=k|x)=0$ 对于 $k\neq i$。因此，设 $\mathcal{A}_{i}$ 为标签为 $i$ 的锚点集合，则噪声转移矩阵 $T_{ij}$
    的元素的估计值为'
- en: '|  | $\begin{split}\hat{T}_{ij}&amp;=\frac{1}{&#124;\mathcal{A}_{i}&#124;}\sum_{x\in\mathcal{A}_{i}}\sum_{k=1}^{c}p(\tilde{y}=j&#124;y=k)p(y=k&#124;x)\\
    &amp;=\frac{1}{&#124;\mathcal{A}_{i}&#124;}\sum_{x\in\mathcal{A}_{i}}p(\tilde{y}=j&#124;x;\Theta),\end{split}$
    |  | (16) |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\hat{T}_{ij}&amp;=\frac{1}{&#124;\mathcal{A}_{i}&#124;}\sum_{x\in\mathcal{A}_{i}}\sum_{k=1}^{c}p(\tilde{y}=j&#124;y=k)p(y=k&#124;x)\\
    &amp;=\frac{1}{&#124;\mathcal{A}_{i}&#124;}\sum_{x\in\mathcal{A}_{i}}p(\tilde{y}=j&#124;x;\Theta),\end{split}$
    |  | (16) |'
- en: where $p(\tilde{y}=j|x;\Theta)$ is the noisy class posterior probability of
    the classifier trained on noisy training data for the anchor point $x$ (see the
    detailed proof in [[113](#bib.bib113), [107](#bib.bib107), [114](#bib.bib114)]).
    Next, based on the inferred noise transition matrix, the noise rate of a balanced
    training data is obtained by averaging the label transition probabilities between
    classes,
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p(\tilde{y}=j|x;\Theta)$ 是在噪声训练数据上训练的分类器对于锚点 $x$ 的噪声类后验概率（详细证明见 [[113](#bib.bib113),
    [107](#bib.bib107), [114](#bib.bib114)]）。接下来，基于推断的噪声转移矩阵，平衡训练数据的噪声率通过平均类间标签转移概率获得，
- en: '|  | $\hat{\tau}=\frac{1}{c}\sum_{i=1}^{c}\sum_{j\neq i}^{c}p(\tilde{y}=j&#124;{y}=i)=\frac{1}{c}\sum_{i=1}^{c}\sum_{j\neq
    i}^{c}\hat{T}_{ij}.$ |  | (17) |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\tau}=\frac{1}{c}\sum_{i=1}^{c}\sum_{j\neq i}^{c}p(\tilde{y}=j&#124;{y}=i)=\frac{1}{c}\sum_{i=1}^{c}\sum_{j\neq
    i}^{c}\hat{T}_{ij}.$ |  | (17) |'
- en: However, since the anchor points are typically unknown in real-world data, they
    are identified from noisy training data by either theoretical derivations [[117](#bib.bib117)]
    or heuristics [[62](#bib.bib62)]. In addition, there have been recent efforts
    to learn the noise transition matrix without anchor points. *T-Revision* [[113](#bib.bib113)]
    initializes a transition matrix by exploiting the examples with high noisy class
    posterior probabilities and then refines the matrix by adding a slack variable.
    *Dual-T* [[114](#bib.bib114)] introduces an intermediate class that factorizes
    the transition matrix into two easy-to-estimate matrices for better accuracy.
    *VolMinNet* [[151](#bib.bib151)] realizes an end-to-end framework and relaxes
    the need for anchor points under the sufficiently scattered assumption.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于锚点在现实数据中通常未知，它们是通过理论推导 [[117](#bib.bib117)] 或启发式方法 [[62](#bib.bib62)] 从噪声训练数据中识别出的。此外，最近也有努力在没有锚点的情况下学习噪声转移矩阵。
    *T-Revision* [[113](#bib.bib113)] 通过利用具有高噪声类别后验概率的示例初始化转移矩阵，然后通过添加松弛变量来精炼该矩阵。
    *Dual-T* [[114](#bib.bib114)] 引入了一个中间类别，将转移矩阵分解为两个易于估计的矩阵，以提高准确性。 *VolMinNet*
    [[151](#bib.bib151)] 实现了一个端到端的框架，并在充分分散的假设下放松了对锚点的需求。
- en: 'Table IV: Summary of publicly available datasets used for studying label noise.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '表 IV: 用于研究标签噪声的公开数据集汇总。'
- en: '| Dataset | # Training | # Validation | # Testing | # Classes | Noise Rate (%)
    |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 训练数量 | 验证数量 | 测试数量 | 类别数量 | 噪声率 (%) |'
- en: '|   ​​​​​​ Clean Data ​​​​​ | MNIST [[154](#bib.bib154)]^(50)^(50)50 | 60K
    | N/A | 10K | $10$ | $\approx 0.0$ |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '|   ​​​​​​ 清洗数据 ​​​​​ | MNIST [[154](#bib.bib154)]^(50)^(50)50 | 60K | N/A
    | 10K | $10$ | $\approx 0.0$ |'
- en: '|  | Fashion-MNIST [[155](#bib.bib155)]^(51)^(51)51​​​​​ | 60K | N/A | 10K
    | $10$ | $\approx 0.0$ |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '|  | Fashion-MNIST [[155](#bib.bib155)]^(51)^(51)51​​​​​ | 60K | N/A | 10K
    | $10$ | $\approx 0.0$ |'
- en: '|  | CIFAR-10 [[156](#bib.bib156)]^(52)^(52)52 | 50K | N/A | 10K | $10$ | $\approx
    0.0$ |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '|  | CIFAR-10 [[156](#bib.bib156)]^(52)^(52)52 | 50K | N/A | 10K | $10$ | $\approx
    0.0$ |'
- en: '|  | CIFAR-100 [[156](#bib.bib156)]^(52)^(52)52 | 50K | N/A | 10K | $100$ |
    $\approx 0.0$ |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '|  | CIFAR-100 [[156](#bib.bib156)]^(52)^(52)52 | 50K | N/A | 10K | $100$ |
    $\approx 0.0$ |'
- en: '|  | SVHN [[157](#bib.bib157)]^(53)^(53)53 | 73K | N/A | 26K | $10$ | $\approx
    0.0$ |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '|  | SVHN [[157](#bib.bib157)]^(53)^(53)53 | 73K | N/A | 26K | $10$ | $\approx
    0.0$ |'
- en: '|  | Tiny-ImageNet [[158](#bib.bib158)]^(55)^(55)55 | 100K | 10K | 10K | $200$
    | $\approx 0.0$ |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '|  | Tiny-ImageNet [[158](#bib.bib158)]^(55)^(55)55 | 100K | 10K | 10K | $200$
    | $\approx 0.0$ |'
- en: '|  | ImageNet [[1](#bib.bib1)]^(54)^(54)54 | 1.3M | 50K | 50K | $1000$ | $\approx
    0.0$ |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '|  | ImageNet [[1](#bib.bib1)]^(54)^(54)54 | 1.3M | 50K | 50K | $1000$ | $\approx
    0.0$ |'
- en: '|   ​​​​​​ Real-world Noisy Data ​​​​​ | ANIMAL-10N [[19](#bib.bib19)]^(56)^(56)56
    | 50K | N/A | 5K | $10$ | $\approx 8.0$ |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '|   ​​​​​​ 真实世界噪声数据 ​​​​​ | ANIMAL-10N [[19](#bib.bib19)]^(56)^(56)56 | 50K
    | N/A | 5K | $10$ | $\approx 8.0$ |'
- en: '|  | CIFAR-10N [[159](#bib.bib159)]^(57)^(57)57 | 50K | N/A | 10K | $10$ |
    $\approx 9.0/18.0/40.2$​​​​​​​ |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '|  | CIFAR-10N [[159](#bib.bib159)]^(57)^(57)57 | 50K | N/A | 10K | $10$ |
    $\approx 9.0/18.0/40.2$​​​​​​​ |'
- en: '|  | CIFAR-100N [[159](#bib.bib159)]^(57)^(57)57 | 50K | N/A | 10K | $100$
    | $\approx 25.6/40.2$ |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '|  | CIFAR-100N [[159](#bib.bib159)]^(57)^(57)57 | 50K | N/A | 10K | $100$
    | $\approx 25.6/40.2$ |'
- en: '|  | Food-101N [[18](#bib.bib18)]^(58)^(58)58 | 310K | 5K | 25K | $101$ | $\approx
    18.4$ |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '|  | Food-101N [[18](#bib.bib18)]^(58)^(58)58 | 310K | 5K | 25K | $101$ | $\approx
    18.4$ |'
- en: '|  | Clothing1M [[16](#bib.bib16)]^(59)^(59)59 | 1M | 14K | 10K | $14$ | $\approx
    38.5$ |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '|  | Clothing1M [[16](#bib.bib16)]^(59)^(59)59 | 1M | 14K | 10K | $14$ | $\approx
    38.5$ |'
- en: '|  | WebVision [[17](#bib.bib17)]^(60)^(60)60 | 2.4M | 50K | 50K | $1000$ |
    $\approx 20.0$ |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '|  | WebVision [[17](#bib.bib17)]^(60)^(60)60 | 2.4M | 50K | 50K | $1000$ |
    $\approx 20.0$ |'
- en: V-B Gaussian Mixture Model (GMM)
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-B 高斯混合模型（GMM）
- en: '![Refer to caption](img/da46fd9da6bb31d043617457d6e5a089.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/da46fd9da6bb31d043617457d6e5a089.png)'
- en: (a) Symmetric Noise.              (b) Asymmetric Noise.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 对称噪声。              (b) 非对称噪声。
- en: 'Figure 7: Training loss distributions of true-labeled and false-labeled examples
    using the ground-truth label and the GMM on CIFAR-100 data with two synthetic
    noises of $40\%$.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7: 使用地面真实标签和 GMM 在 CIFAR-100 数据上进行的真实标记和错误标记示例的训练损失分布，包含 $40\%$ 的两种合成噪声。'
- en: 'The second method is exploiting a one-dimensional and two-component GMM to
    model the loss distribution of true-labeled and false-labeled examples [[110](#bib.bib110),
    [152](#bib.bib152)]. As shown in Figure [7](#S5.F7 "Figure 7 ‣ V-B Gaussian Mixture
    Model (GMM) ‣ V Noise Rate Estimation ‣ Learning from Noisy Labels with Deep Neural
    Networks: A Survey"), since the loss distribution tends to be *bi-modal*, the
    two Gaussian components are fitted to the training loss by using the EM algorithm;
    the probability of an example being a false-labeled one is obtained through its
    posterior probability. Hence, the noise rate is estimated at each epoch $t$ by
    computing the expectation of the posterior probability for all training examples,'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '第二种方法是利用一维和两个分量的高斯混合模型（GMM）来建模真实标签和虚假标签示例的损失分布 [[110](#bib.bib110), [152](#bib.bib152)]。如图
    [7](#S5.F7 "Figure 7 ‣ V-B Gaussian Mixture Model (GMM) ‣ V Noise Rate Estimation
    ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey") 所示，由于损失分布趋向于*双峰*，通过使用
    EM 算法将两个高斯分量拟合到训练损失上；通过其后验概率获得示例为虚假标签的概率。因此，噪声率在每个轮次 $t$ 通过计算所有训练示例的后验概率的期望来估计，'
- en: '|  | $\begin{gathered}\hat{\tau}=\mathbb{E}_{(x,\tilde{y})\in\tilde{\mathcal{D}}}\Big{[}\,p\big{(}g\,&#124;\,\ell\big{(}f(x;\Theta_{t}),\tilde{y}\big{)}\big{)}\,\Big{]},\\
    \end{gathered}$ |  | (18) |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{gathered}\hat{\tau}=\mathbb{E}_{(x,\tilde{y})\in\tilde{\mathcal{D}}}\Big{[}\,p\big{(}g\,\mid\,\ell\big{(}f(x;\Theta_{t}),\tilde{y}\big{)}\big{)}\,\Big{]},\\
    \end{gathered}$ |  | (18) |'
- en: where $g$ is the Gaussian component with a larger loss. However, Pleiss et al.
    [[152](#bib.bib152)] recently pointed out that the training loss becomes less
    separable by the GMM as the training progresses, and thus proposed the *area under
    the loss* (AUL) curve, which is the sum of the example’s training losses obtained
    from all previous training epochs. Even after the loss signal decays in later
    epochs, the distributions remain separable. Therefore, the noise rate is finally
    estimated by
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $g$ 是具有较大损失的高斯分量。然而，Pleiss 等人 [[152](#bib.bib152)] 最近指出，随着训练的进行，训练损失变得不那么可分，因此提出了*损失曲线下面积*（AUL），即从所有先前训练轮次中获得的示例训练损失之和。即使在后期轮次中损失信号减弱，分布仍然可分。因此，噪声率最终通过
- en: '|  | $\begin{gathered}\hat{\tau}=\mathbb{E}_{(x,\tilde{y})\in\tilde{\mathcal{D}}}\Big{[}\,p\big{(}g\,&#124;\,{\rm
    AUL}_{t}(x,\tilde{y})\big{)}\,\Big{]},\\ \text{where}\leavevmode\nobreak\ \text{AUL}_{t}(x,\tilde{y})=\sum_{i=1}^{t}\ell\big{(}f(x;\Theta_{t}),\tilde{y}\big{)}.\end{gathered}$
    |  | (19) |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{gathered}\hat{\tau}=\mathbb{E}_{(x,\tilde{y})\in\tilde{\mathcal{D}}}\Big{[}\,p\big{(}g\,\mid\,{\rm
    AUL}_{t}(x,\tilde{y})\big{)}\,\Big{]},\\ \text{where}\leavevmode\nobreak\ \text{AUL}_{t}(x,\tilde{y})=\sum_{i=1}^{t}\ell\big{(}f(x;\Theta_{t}),\tilde{y}\big{)}.\end{gathered}$
    |  | (19) |'
- en: V-C Cross Validation
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-C 交叉验证
- en: The third method is estimating the noise rate by applying cross validation,
    which typically requires clean validation data [[19](#bib.bib19), [112](#bib.bib112),
    [132](#bib.bib132)]. However, such clean validation data is hard to acquire in
    real-world applications. Thus, Chen et al. [[135](#bib.bib135)] leveraged two
    randomly divided noisy training datasets for cross validation. Under the assumption
    that the two datasets share exactly the same noise transition matrix, the noise
    rate quantifies the test accuracy of DNNs that are respectively trained and tested
    on the two divided sets,
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种方法是通过应用交叉验证来估计噪声率，这通常需要干净的验证数据 [[19](#bib.bib19), [112](#bib.bib112), [132](#bib.bib132)]。然而，在实际应用中，这种干净的验证数据难以获得。因此，陈等人
    [[135](#bib.bib135)] 利用两个随机划分的噪声训练数据集进行交叉验证。在假设这两个数据集具有完全相同的噪声转移矩阵的前提下，噪声率量化了分别在这两个划分集上训练和测试的深度神经网络（DNN）的测试准确率，
- en: '|  | $\!\!\!{\rm Test\,Accuracy}\!=\!\!\!\ \begin{cases}(1-\hat{\tau})^{2}+\hat{\tau}^{2}/(c-1)\!\!&amp;\!\!\text{if
    symmetric}\!\!\!\!\\ (1-\hat{\tau})^{2}+\hat{\tau}^{2}\!\!&amp;\!\!\text{if asymmetric}.\!\!\!\!\end{cases}$
    |  | (20) |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '|  | $\!\!\!{\rm Test\,Accuracy}\!=\!\!\!\ \begin{cases}(1-\hat{\tau})^{2}+\hat{\tau}^{2}/(c-1)\!\!&\!\!\text{如果对称}\!\!\!\!\\
    (1-\hat{\tau})^{2}+\hat{\tau}^{2}\!\!&\!\!\text{如果不对称}.\!\!\!\!\end{cases}$ |  |
    (20) |'
- en: Therefore, the noise rate is estimated from the test accuracy obtained by cross
    validation.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，噪声率是根据交叉验证获得的测试准确率来估计的。
- en: VI Experimental Design
  id: totrans-322
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 实验设计
- en: This section describes the typically used experimental design for comparing
    robust training methods in the presence of label noise. We introduce publicly
    available image datasets and then describe widely-used evaluation metrics.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了在标签噪声存在的情况下，通常用于比较鲁棒训练方法的实验设计。我们介绍了公开可用的图像数据集，并描述了广泛使用的评估指标。
- en: VI-A Publicly Available Datasets
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-A 公开可用的数据集
- en: 'To validate the robustness of the proposed algorithms, an image classification
    task was widely conducted on numerous image benchmark datasets. Table [IV](#S5.T4
    "Table IV ‣ V-A Noise Transition Matrix ‣ V Noise Rate Estimation ‣ Learning from
    Noisy Labels with Deep Neural Networks: A Survey") summarizes popularly-used public
    benchmark datasets, which are classified into two categories: *1)* a “clean dataset”
    that consists of mostly true-labeled examples annotated by human experts and *2)*
    a “real-world noisy dataset” that comprises real-world noisy examples with varying
    numbers of false labels.'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '为了验证所提出算法的鲁棒性，对多个图像基准数据集进行了广泛的图像分类任务。表[IV](#S5.T4 "Table IV ‣ V-A Noise Transition
    Matrix ‣ V Noise Rate Estimation ‣ Learning from Noisy Labels with Deep Neural
    Networks: A Survey")总结了常用的公共基准数据集，这些数据集被分为两类：*1)* “干净数据集”，主要由人类专家标注的真实标签示例组成；*2)*
    “现实世界噪声数据集”，包含带有不同数量错误标签的真实世界噪声示例。'
- en: VI-A1 Clean Datasets
  id: totrans-326
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-A1 干净数据集
- en: 'According to the literature [[133](#bib.bib133), [19](#bib.bib19), [142](#bib.bib142)],
    *seven* clean datasets are widely used: MNIST^(50)^(50)50[http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist),
    classification of handwritten digits [[154](#bib.bib154)]; Fashion-MNIST^(51)^(51)51[https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist),
    classification of various clothing [[155](#bib.bib155)]; CIFAR-10^(52)^(52)52[https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)
    and CIFAR-100^(52)^(52)footnotemark: 52, classification of a subset of $80$ million
    categorical images [[156](#bib.bib156)]; SVHN^(53)^(53)53[http://ufldl.stanford.edu/housenumbers](http://ufldl.stanford.edu/housenumbers),
    classification of house numbers in Google Street view images [[157](#bib.bib157)];
    ImageNet^(54)^(54)54[http://www.image-net.org](http://www.image-net.org) and Tiny-ImageNet^(55)^(55)55[https://www.kaggle.com/c/tiny-imagenet](https://www.kaggle.com/c/tiny-imagenet),
    image database organized according to the WordNet hierarchy and its small subset
    [[1](#bib.bib1), [158](#bib.bib158)]. Because the labels in these datasets are
    almost all true-labeled, their labels in the training data should be artificially
    corrupted for the evaluation of synthetic noises, namely *symmetric* noise and
    *asymmetric* noise.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '根据文献[[133](#bib.bib133), [19](#bib.bib19), [142](#bib.bib142)]，*七个*干净数据集被广泛使用：MNIST^(50)^(50)50[http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist)，手写数字分类[[154](#bib.bib154)];
    Fashion-MNIST^(51)^(51)51[https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist)，各种服装分类[[155](#bib.bib155)];
    CIFAR-10^(52)^(52)52[https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)
    和 CIFAR-100^(52)^(52)footnotemark: 52，$80$百万类别图像的子集分类[[156](#bib.bib156)]; SVHN^(53)^(53)53[http://ufldl.stanford.edu/housenumbers](http://ufldl.stanford.edu/housenumbers)，Google街景图像中的房屋号码分类[[157](#bib.bib157)];
    ImageNet^(54)^(54)54[http://www.image-net.org](http://www.image-net.org) 和 Tiny-ImageNet^(55)^(55)55[https://www.kaggle.com/c/tiny-imagenet](https://www.kaggle.com/c/tiny-imagenet)，按WordNet层级组织的图像数据库及其小子集[[1](#bib.bib1),
    [158](#bib.bib158)]。由于这些数据集中的标签几乎都是正确标注的，因此它们的训练数据标签应当人为地损坏，以便评估合成噪声，即*symmetric*噪声和*asymmetric*噪声。'
- en: VI-A2 Real-world Noisy Datasets
  id: totrans-328
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-A2 现实世界噪声数据集
- en: 'Unlike the clean datasets, real-world noisy datasets inherently contain many
    mislabeled examples annotated by non-experts. According to the literature [[17](#bib.bib17),
    [19](#bib.bib19), [18](#bib.bib18), [16](#bib.bib16)], *six* real-world noisy
    datasets are widely used: ANIMAL-10N^(56)^(56)56[https://dm.kaist.ac.kr/datasets/animal-10n](https://dm.kaist.ac.kr/datasets/animal-10n),
    real-world noisy data of human-labeled online images for 10 confusing animals
    [[19](#bib.bib19)]; CIFAR-10N^(57)^(57)57[http://noisylabels.com/](http://noisylabels.com/)
    and CIFAR-100N^(57)^(57)footnotemark: 57, variations of CIFAR-10 and CIFAR-100
    with human-annotated real-world noisy labels collected from Amazon’s Mechanical
    Turk [[159](#bib.bib159)]. They provide human labels with different noise rates,
    as shown in Table [IV](#S5.T4 "Table IV ‣ V-A Noise Transition Matrix ‣ V Noise
    Rate Estimation ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey");
    Food-101N^(58)^(58)58[https://kuanghuei.github.io/Food-101N](https://kuanghuei.github.io/Food-101N),
    real-world noisy data of crawled food images annotated by their search keywords
    in the Food-101 taxonomy [[160](#bib.bib160), [18](#bib.bib18)]; Clothing1M^(59)^(59)59[https://www.floydhub.com/lukasmyth/datasets/clothing1m](https://www.floydhub.com/lukasmyth/datasets/clothing1m),
    real-world noisy data of large-scale crawled clothing images from several online
    shopping websites [[16](#bib.bib16)]; WebVision^(60)^(60)60[https://data.vision.ee.ethz.ch/cvl/webvision/download.html](https://data.vision.ee.ethz.ch/cvl/webvision/download.html),
    real-world noisy data of large-scale web images crawled from Flickr and Google
    Images search [[17](#bib.bib17)]. To support sophisticated evaluation, most real-world
    noisy datasets contain their own clean validation set and provide the estimated
    noise rate of their training set.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '与干净的数据集不同，现实世界中的噪声数据集本质上包含许多由非专家标注的错误标记样本。根据文献[[17](#bib.bib17), [19](#bib.bib19),
    [18](#bib.bib18), [16](#bib.bib16)]，*六个* 现实世界的噪声数据集被广泛使用：ANIMAL-10N^(56)^(56)56[https://dm.kaist.ac.kr/datasets/animal-10n](https://dm.kaist.ac.kr/datasets/animal-10n)，用于
    10 种混淆动物的人工标注在线图像的现实世界噪声数据[[19](#bib.bib19)]；CIFAR-10N^(57)^(57)57[http://noisylabels.com/](http://noisylabels.com/)
    和 CIFAR-100N^(57)^(57)footnotemark: 57，是 CIFAR-10 和 CIFAR-100 的变体，包含从亚马逊 Mechanical
    Turk 收集的带有人工标注现实世界噪声标签的数据[[159](#bib.bib159)]。它们提供了具有不同噪声率的人类标签，如表 [IV](#S5.T4
    "Table IV ‣ V-A Noise Transition Matrix ‣ V Noise Rate Estimation ‣ Learning from
    Noisy Labels with Deep Neural Networks: A Survey") 所示；Food-101N^(58)^(58)58[https://kuanghuei.github.io/Food-101N](https://kuanghuei.github.io/Food-101N)，包含从
    Food-101 分类中的搜索关键字标注的爬取食品图像的现实世界噪声数据[[160](#bib.bib160), [18](#bib.bib18)]；Clothing1M^(59)^(59)59[https://www.floydhub.com/lukasmyth/datasets/clothing1m](https://www.floydhub.com/lukasmyth/datasets/clothing1m)，包含来自多个在线购物网站的大规模爬取服装图像的现实世界噪声数据[[16](#bib.bib16)]；WebVision^(60)^(60)60[https://data.vision.ee.ethz.ch/cvl/webvision/download.html](https://data.vision.ee.ethz.ch/cvl/webvision/download.html)，包含从
    Flickr 和 Google Images 搜索中爬取的大规模 web 图像的现实世界噪声数据[[17](#bib.bib17)]。为了支持复杂的评估，大多数现实世界噪声数据集包含自己的干净验证集，并提供其训练集的估计噪声率。'
- en: VI-B Evaluation Metrics
  id: totrans-330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-B 评估指标
- en: A typical metric to assess the robustness of a particular method is the prediction
    accuracy for unbiased and clean examples that are not used in training. The prediction
    accuracy degrades significantly if the DNN overfits to false-labeled examples
    [[22](#bib.bib22)]. Hence, *test accuracy* has generally been adopted for evaluation
    [[13](#bib.bib13)]. For a test set $\mathcal{T}=\{(x_{i},y_{i})\}_{i=1}^{|\mathcal{T}|}$,
    let $\hat{y}_{i}$ be the predicted label of the $i$-th example in $\mathcal{T}$.
    Subsequently, the test accuracy is formalized by
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 评估某一方法鲁棒性的典型指标是对未参与训练的无偏干净样本的预测准确率。如果深度神经网络（DNN）对错误标记的样本过拟合，则预测准确率会显著下降[[22](#bib.bib22)]。因此，*测试准确率*通常被用于评估[[13](#bib.bib13)]。对于测试集
    $\mathcal{T}=\{(x_{i},y_{i})\}_{i=1}^{|\mathcal{T}|}$，设 $\hat{y}_{i}$ 为第 $i$ 个样本在
    $\mathcal{T}$ 中的预测标签。随后，测试准确率被公式化为
- en: '|  | $\text{Test Accuracy}=\frac{&#124;\{(x_{i},y_{i})\in\mathcal{T}:\hat{y}_{i}=y_{i}\}&#124;}{&#124;\mathcal{T}&#124;}.$
    |  | (21) |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '|  | $\text{Test Accuracy}=\frac{&#124;\{(x_{i},y_{i})\in\mathcal{T}:\hat{y}_{i}=y_{i}\}&#124;}{&#124;\mathcal{T}&#124;}.$
    |  | (21) |'
- en: 'If the test data are not available, *validation accuracy* can be used by replacing
    $\mathcal{T}$ in Eq. ([21](#S6.E21 "In VI-B Evaluation Metrics ‣ VI Experimental
    Design ‣ Learning from Noisy Labels with Deep Neural Networks: A Survey")) with
    validation data $\mathcal{V}=\{(x_{i},y_{i})\}_{i=1}^{|\mathcal{V}|}$ as an alternative,'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '如果测试数据不可用，可以通过用验证数据 $\mathcal{V}=\{(x_{i},y_{i})\}_{i=1}^{|\mathcal{V}|}$ 替换
    Eq. ([21](#S6.E21 "In VI-B Evaluation Metrics ‣ VI Experimental Design ‣ Learning
    from Noisy Labels with Deep Neural Networks: A Survey")) 中的 $\mathcal{T}$ 来使用
    *验证准确率* 作为替代，'
- en: '|  | $\text{Validation Accuracy}=\frac{&#124;\{(x_{i},y_{i})\in\mathcal{V}:\hat{y}_{i}=y_{i}\}&#124;}{&#124;\mathcal{V}&#124;}.$
    |  | (22) |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '|  | $\text{验证准确率}=\frac{&#124;\{(x_{i},y_{i})\in\mathcal{V}:\hat{y}_{i}=y_{i}\}&#124;}{&#124;\mathcal{V}&#124;}.$
    |  | (22) |'
- en: Furthermore, if the specified method belongs to the “sample selection” category,
    *label precision* and *label recall* [[112](#bib.bib112), [135](#bib.bib135)]
    can be used as the metrics,
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果指定的方法属于“样本选择”类别，则可以使用*标签精度*和*标签召回率* [[112](#bib.bib112), [135](#bib.bib135)]
    作为度量标准，
- en: '|  | $\begin{gathered}\text{Label Precision}=\frac{&#124;\{(x_{i},\tilde{y}_{i})\in\mathcal{S}_{t}:\tilde{y}_{i}=y_{i}\}&#124;}{&#124;\mathcal{S}_{t}&#124;},\\
    \text{Label Recall}=\frac{&#124;\{(x_{i},\tilde{y}_{i})\in\mathcal{S}_{t}:\tilde{y}_{i}=y_{i}\}&#124;}{&#124;\{(x_{i},\tilde{y}_{i})\in\mathcal{B}_{t}:\tilde{y}_{i}=y_{i}\}&#124;},\end{gathered}$
    |  | (23) |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{gathered}\text{标签精度}=\frac{&#124;\{(x_{i},\tilde{y}_{i})\in\mathcal{S}_{t}:\tilde{y}_{i}=y_{i}\}&#124;}{&#124;\mathcal{S}_{t}&#124;},\\
    \text{标签召回率}=\frac{&#124;\{(x_{i},\tilde{y}_{i})\in\mathcal{S}_{t}:\tilde{y}_{i}=y_{i}\}&#124;}{&#124;\{(x_{i},\tilde{y}_{i})\in\mathcal{B}_{t}:\tilde{y}_{i}=y_{i}\}&#124;},\end{gathered}$
    |  | (23) |'
- en: where $\mathcal{S}_{t}$ is the set of selected clean examples in a mini-batch
    $\mathcal{B}_{t}$. The two metrics are performance indicators for the examples
    selected from the mini-batch as true-labeled ones [[112](#bib.bib112)].
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{S}_{t}$ 是在小批量 $\mathcal{B}_{t}$ 中选择的干净样本的集合。这两个度量是从小批量中选出的真实标签样本的性能指标
    [[112](#bib.bib112)]。
- en: Meanwhile, if the specified method belongs to the “label refurbishment” category,
    *correction error* [[19](#bib.bib19)] can be used as an indicator of how many
    examples are incorrectly refurbished,
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，如果指定的方法属于“标签修正”类别，则可以使用*修正误差* [[19](#bib.bib19)] 作为指示器，以衡量有多少例子被错误修正，
- en: '|  | $\!\text{Correction Error}=\frac{&#124;\{x_{i}\!\in\!\mathcal{R}:\text{argmax}(y_{i}^{refurb})\neq
    y_{i}\}&#124;}{&#124;\mathcal{R}&#124;},$ |  | (24) |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '|  | $\!\text{修正误差}=\frac{&#124;\{x_{i}\!\in\!\mathcal{R}:\text{argmax}(y_{i}^{refurb})\neq
    y_{i}\}&#124;}{&#124;\mathcal{R}&#124;},$ |  | (24) |'
- en: 'where $\mathcal{R}$ is the set of examples whose labels are refurbished by
    Eq. ([12](#S3.E12 "In III-D3 Label Refurbishment ‣ III-D Loss Adjustment ‣ III
    Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")) and $y_{i}^{refurb}$ is the refurbished label of the $i$-th examples
    in $\mathcal{R}$.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{R}$ 是由 Eq. ([12](#S3.E12 "在 III-D3 标签修正 ‣ III-D 损失调整 ‣ III 深度学习方法
    ‣ 从有噪声标签中学习：综述")) 修正标签的样本集合，$y_{i}^{refurb}$ 是 $\mathcal{R}$ 中第 $i$ 个样本的修正标签。
- en: VII Future Research Directions
  id: totrans-341
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VII 未来研究方向
- en: With recent efforts in the machine learning community, the robustness of DNNs
    becomes evolving in several directions. Thus, the existing approaches covered
    in our survey face a variety of future challenges. This section provides discussion
    for future research that can facilitate and envision the development of deep learning
    in the label noise area.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器学习领域的最新努力，深度神经网络的鲁棒性在多个方向上不断发展。因此，我们调研中涵盖的现有方法面临各种未来挑战。本节讨论了能够促进和展望深度学习在标签噪声领域发展的未来研究方向。
- en: VII-A Instance-dependent Label Noise
  id: totrans-343
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-A 实例相关标签噪声
- en: Existing theoretical and empirical studies for *robust loss function* and *loss
    correction* are largely built upon the instance-independent noise assumption that
    the label noise is independent of input features [[77](#bib.bib77), [76](#bib.bib76),
    [113](#bib.bib113), [114](#bib.bib114)]. However, this assumption may not be a
    good approximation of the real-world label noise. In particular, Chen et al. [[122](#bib.bib122)]
    conducted a theoretical hypothesis testing^(61)^(61)61In Clothing1M, the result
    showed that the instance-independent noise happens with probability lower than
    $10^{-21250}$, which is statistically impossible. using a popular real-world dataset,
    Clothing1M, and proved that its label noise is statistically different from the
    instance-independent noise. This testing confirms that the label noise should
    depend on the instance.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的理论和实证研究对于*鲁棒损失函数*和*损失修正* 大多建立在标签噪声与输入特征独立的假设基础上 [[77](#bib.bib77), [76](#bib.bib76),
    [113](#bib.bib113), [114](#bib.bib114)]。然而，这一假设可能并不适用于现实世界中的标签噪声。特别是，陈等 [[122](#bib.bib122)]
    使用一个流行的现实世界数据集 Clothing1M 进行了理论假设检验，并证明其标签噪声在统计上不同于实例无关噪声。这一检验确认了标签噪声应当依赖于实例。
- en: 'Conversely, most methods for the other direction (especially, *sample selection*)
    work well even under the instance-dependent label noise in general since they
    do not rely on the assumption. Nevertheless, Song et al. [[141](#bib.bib141)]
    pointed out that their performance could considerably worsen in the instance-dependent (or
    real-world) noise compared to symmetric noise due to the confusion between true-labeled
    and false-labeled examples. The loss distribution of true-labeled examples heavily
    overlaps that of false-labeled samples in the asymmetric noise, which is similar
    to the real-world noise, in Figure [5](#S3.F5 "Figure 5 ‣ III-E Sample Selection
    ‣ III Deep Learning Approaches ‣ Learning from Noisy Labels with Deep Neural Networks:
    A Survey")(b). Thus, identifying clean examples becomes more challenging when
    dealing with the instance-dependent label noise.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '相反，大多数针对另一方向的方法（尤其是*样本选择*）即使在实例相关的标签噪声下通常也能很好地工作，因为它们不依赖于假设。然而，Song等人[[141](#bib.bib141)]指出，由于真实标签和虚假标签样本之间的混淆，他们的性能可能在实例相关（或现实世界）噪声下显著恶化。图[5](#S3.F5
    "Figure 5 ‣ III-E Sample Selection ‣ III Deep Learning Approaches ‣ Learning from
    Noisy Labels with Deep Neural Networks: A Survey")(b)显示了真实标签样本的损失分布在不对称噪声下（类似于现实世界噪声）与虚假标签样本的损失分布严重重叠。因此，在处理实例相关标签噪声时，识别干净的样本变得更加具有挑战性。'
- en: Beyond the instance-independent label noise, there have been a few recent studies
    for the instance-dependent label noise. Mostly, they only focus on a binary classification
    task [[66](#bib.bib66), [161](#bib.bib161)] or a restricted small-scale machine
    learning model such as logistic regression [[63](#bib.bib63)]. Therefore, learning
    with the instance-dependent label noise is an important topic that deserves more
    research attention.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 超越实例无关标签噪声，最近有一些关于实例相关标签噪声的研究。大多数研究仅关注于二分类任务[[66](#bib.bib66), [161](#bib.bib161)]或受限的小规模机器学习模型，如逻辑回归[[63](#bib.bib63)]。因此，带有实例相关标签噪声的学习是一个值得更多研究关注的重要课题。
- en: VII-B Multi-label Data with Label Noise
  id: totrans-347
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-B 带标签噪声的多标签数据
- en: Most of the existing methods are applicable only for a *single-label* multi-class
    classification problem, where each data example is assumed to have only one true
    label. However, in the case of *multi-label* learning, each data example can be
    associated with a set of multiple true class labels. In music categorization,
    each music can belong to multiple categories [[162](#bib.bib162)]. In semantic
    scene classification, each scene may belong to multiple scene classes [[163](#bib.bib163)].
    Thus, contrary to the single-label setup, the multi-label classifier aims to predict
    a set of target objects simultaneously. In this setup, a multi-label dataset of
    millions of examples are reported to contain over $26.6\%$ false-positive labels
    as well as a significant number of omitted labels [[164](#bib.bib164)].
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现有方法仅适用于*单标签*多类分类问题，其中每个数据样本被假设只有一个真实标签。然而，在*多标签*学习的情况下，每个数据样本可以关联多个真实类别标签。在音乐分类中，每首音乐可以属于多个类别[[162](#bib.bib162)]。在语义场景分类中，每个场景可能属于多个场景类别[[163](#bib.bib163)]。因此，与单标签设置相反，多标签分类器旨在同时预测一组目标对象。在这种设置下，报告称一个包含数百万个样本的多标签数据集中，超过$26.6\%$的标签是虚假正例，并且遗漏标签的数量也很大[[164](#bib.bib164)]。
- en: Even worse, the difference in occurrence between classes makes this problem
    more challenging; some minor class labels occur less in training data than other
    major class labels. Considering such aspects that can arise in multi-label classification,
    the simple extension of existing methods may not learn the proper correlations
    among multiple labels. Therefore, learning from noisy labels with multi-label
    data is another important topic for future research. We refer the readers to a
    recent study [[165](#bib.bib165)] that discusses the evaluation of multi-label
    classifiers trained with noisy labels.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 更糟糕的是，各类之间的出现差异使得这个问题更加具有挑战性；一些次要类标签在训练数据中的出现频率低于其他主要类标签。考虑到多标签分类中可能出现的这些方面，现有方法的简单扩展可能无法学习到多个标签之间的适当关联。因此，从带噪声的标签中学习多标签数据是未来研究的另一个重要课题。我们建议读者参考最近的研究[[165](#bib.bib165)]，该研究讨论了带噪声标签训练的多标签分类器的评估。
- en: VII-C Class Imbalance Data with Label Noise
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-C 类别不平衡数据与标签噪声
- en: The *class imbalance* in training data is commonly observed, where a few classes
    account for most of the data. Especially when working with large data in many
    real-world applications, this problem becomes more severe and is often associated
    with the problem of noisy labels [[166](#bib.bib166)]. Nevertheless, to ease the
    label noise problem, it is commonly assumed that training examples are equally
    distributed over all class labels in the training data. This assumption is quite
    strong when collecting large-scale data, and thus we need to consider a more realistic
    scenario in which the two problems coexist.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据中的*类别不平衡*是常见的现象，其中少数类别占据了大部分数据。特别是在处理许多真实世界应用中的大规模数据时，这个问题变得更加严重，并且通常与标签噪声问题相关[[166](#bib.bib166)]。然而，为了缓解标签噪声问题，通常假设训练示例在所有类别标签上均匀分布。这种假设在收集大规模数据时相当强，因此我们需要考虑一种更现实的情景，其中这两个问题共存。
- en: Most of the existing robust methods may not work well with the class imbalance,
    especially when they rely on the learning dynamics of DNNs, e.g., the small-loss
    trick or memorization effect. Under the existence of the class imbalance, the
    training model converges to major classes faster than minor classes such that
    most examples in the major class exhibit small losses (i.e., early memorization).
    That is, there is a risk of discarding most examples in the minor class. Furthermore,
    in terms of example importance, high-loss examples are commonly favored for the
    class imbalance problem [[124](#bib.bib124)], while small-loss examples are favored
    for the label noise problem. This conceptual contradiction hinders the applicability
    of the existing methods that neglect the class imbalance. Therefore, these two
    problems should be considered simultaneously to deal with more general situations.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现有的稳健方法可能在处理类别不平衡时效果不佳，尤其是当它们依赖于深度神经网络（DNN）的学习动态时，例如小损失技巧或记忆效应。在类别不平衡的情况下，训练模型对主要类别的收敛速度比对次要类别的收敛速度快，从而使主要类别的大多数示例表现出小损失（即早期记忆）。也就是说，存在丢弃次要类别大多数示例的风险。此外，在示例重要性方面，高损失示例通常被偏爱用于类别不平衡问题[[124](#bib.bib124)]，而小损失示例则被偏爱用于标签噪声问题。这种概念上的矛盾阻碍了忽视类别不平衡的现有方法的适用性。因此，这两个问题应同时考虑，以应对更一般的情况。
- en: VII-D Robust and Fair Training
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-D 稳健与公平训练
- en: Machine learning classifiers can perpetuate and amplify the existing systemic
    injustices in society [[167](#bib.bib167)]. Hence, fairness is becoming another
    important topic. Traditionally, robust training and fair training have been studied
    by separate communities; robust training with noisy labels has mostly focused
    on combating label noise without regarding data bias [[13](#bib.bib13), [30](#bib.bib30)],
    whereas fair training has focused on dealing with data bias, not necessarily noise
    [[167](#bib.bib167), [168](#bib.bib168)]. However, noisy labels and data bias,
    in fact, coexist in real-world data. Satisfying both robustness and fairness is
    more realistic but challenging because the bias in data is pertinent to label
    noise.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习分类器可能会延续并放大社会中现有的系统性不公[[167](#bib.bib167)]。因此，公平性正成为另一个重要话题。传统上，稳健训练和公平训练是由不同的社区研究的；稳健训练通常专注于应对标签噪声，而不考虑数据偏差[[13](#bib.bib13),
    [30](#bib.bib30)]，而公平训练则关注处理数据偏差，而不一定涉及噪声[[167](#bib.bib167), [168](#bib.bib168)]。然而，噪声标签和数据偏差实际上在真实世界数据中是共存的。实现稳健性和公平性既现实又具有挑战性，因为数据中的偏差与标签噪声相关。
- en: In general, many fairness criteria are group-based, where a target metric is
    equalized or enforced over subpopulations in the data, also known as *protected
    groups* such as race or gender [[167](#bib.bib167)]. Accordingly, the goal of
    fair training is building a model that satisfies such fairness criteria for the
    *true* protected groups. However, if the *noisy* protection group is involved,
    such fairness criteria cannot be directly applied. Recently, mostly after 2020,
    a few pioneering studies have emerged to consider both robustness and fairness
    objectives at the same time under the binary classification setting [[169](#bib.bib169),
    [170](#bib.bib170)]. Therefore, more research attention is needed for the convergence
    of robust training and fair training.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，许多公平性标准是基于群体的，其中目标指标在数据的子群体中被平等化或强制执行，这些子群体也称为*受保护群体*，如种族或性别 [[167](#bib.bib167)]。因此，公平训练的目标是建立一个满足这些公平性标准的模型，针对*真实*受保护群体。然而，如果涉及到*噪声*保护群体，这些公平性标准就不能直接应用。最近，尤其是2020年以后，出现了一些开创性的研究，考虑在二分类设置下同时实现鲁棒性和公平性目标
    [[169](#bib.bib169), [170](#bib.bib170)]。因此，需要更多的研究关注鲁棒训练和公平训练的收敛性。
- en: VII-E Connection with Input Perturbation
  id: totrans-356
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-E 与输入扰动的联系
- en: There has been a lot of research on the robustness of deep learning under input
    perturbation, mainly in the field of adversarial training where the input feature
    is maliciously perturbed to distort the output of the DNN [[34](#bib.bib34), [36](#bib.bib36)].
    Although learning with noisy labels and learning with noisy inputs have been regarded
    as separate research fields, their goals are similar in that they learn noise-robust
    representations from noisy data. Based on this common point of view, a few recent
    studies have investigated the interaction of adversarial training with noisy labels
    [[171](#bib.bib171), [172](#bib.bib172), [173](#bib.bib173)].
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 关于输入扰动下深度学习的鲁棒性，已经有大量研究，主要集中在对抗训练领域，其中输入特征被恶意扰动以扭曲 DNN 的输出 [[34](#bib.bib34),
    [36](#bib.bib36)]。虽然带有噪声标签的学习和带有噪声输入的学习被视为独立的研究领域，但它们的目标相似，都是从噪声数据中学习到鲁棒的表示。基于这一共同观点，最近的一些研究调查了对抗训练与噪声标签之间的相互作用
    [[171](#bib.bib171), [172](#bib.bib172), [173](#bib.bib173)]。
- en: Interestingly, it was turned out that adversarial training makes DNNs robust
    to label noise [[171](#bib.bib171)]. Based on this finding, Damodaran et al. [[172](#bib.bib172)]
    proposed a new regularization term, called Wasserstein adversarial regularization,
    to address the problem of learning with noisy labels. Zhu et al. [[173](#bib.bib173)]
    proposed to use the number of projected gradient descent steps as a new criterion
    for sample selection such that clean examples are filtered out from noisy data.
    These approaches are regarded as a new perspective on label noise compared to
    traditional work. Therefore, understanding the connection between input perturbation
    and label noise could be another future topic for better representation learning
    toward robustness.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，研究发现对抗训练使深度神经网络（DNN）对标签噪声具有鲁棒性 [[171](#bib.bib171)]。基于这一发现，Damodaran 等人
    [[172](#bib.bib172)] 提出了一个新的正则化项，称为 Wasserstein 对抗正则化，用于解决带有噪声标签的学习问题。Zhu 等人 [[173](#bib.bib173)]
    提议使用投影梯度下降步骤的数量作为样本选择的新标准，以便从噪声数据中筛选出干净的样本。这些方法相较于传统的研究，被视为对标签噪声的新视角。因此，理解输入扰动与标签噪声之间的联系可能是未来更好地进行鲁棒性表示学习的另一个主题。
- en: VII-F Efficient Learning Pipeline
  id: totrans-359
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-F 高效学习流程
- en: The efficiency of the learning pipeline is another important aspect to design
    deep learning approaches. However, for robust deep learning, most studies have
    neglected the efficiency of the algorithm because their main goal is to improve
    the robustness to label noise. For example, maintaining multiple DNNs or training
    a DNN in multiple rounds is frequently used, but these approaches significantly
    degrade the efficiency of the learning pipeline. On ther other hand, the need
    for more efficient algorithms is increasing owing to the rapid increase in the
    amount of available data [[174](#bib.bib174)].
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 学习流程的效率是设计深度学习方法的另一个重要方面。然而，对于鲁棒深度学习，大多数研究忽略了算法的效率，因为它们的主要目标是提高对标签噪声的鲁棒性。例如，维护多个
    DNN 或在多轮中训练 DNN 是常用的方法，但这些方法显著降低了学习流程的效率。另一方面，由于可用数据量的快速增加，对更高效算法的需求也在上升 [[174](#bib.bib174)]。
- en: According to our literature survey, most work did not even report the efficiency (or
    time complexity) of their approaches. However, it is evident that saving the training
    time is helpful under the restricted budget for computation. Therefore, enhancing
    the efficiency will significantly increase the usability of robust deep learning
    in the big data era.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的文献调查，大多数工作甚至没有报告其方法的效率（或时间复杂度）。然而，显而易见的是，在计算预算受限的情况下，节省训练时间是有帮助的。因此，提高效率将显著增加在大数据时代中强健深度学习的实用性。
- en: VIII Conclusion
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VIII 结论
- en: DNNs easily overfit to false labels owing to their high capacity in totally
    memorizing all noisy training samples. This overfitting issue still remains even
    with various conventional regularization techniques, such as dropout and batch
    normalization, thereby significantly decreasing their generalization performance.
    Even worse, in real-world applications, the difficulty in labeling renders the
    overfitting issue more severe. Therefore, learning from noisy labels has recently
    become one of the most active research topics.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 由于深度神经网络具有完全记住所有噪声训练样本的高能力，它们很容易对错误标签进行过拟合。即使采用各种传统正则化技术，如dropout和批量归一化，这一过拟合问题仍然存在，从而显著降低了它们的泛化性能。更糟糕的是，在实际应用中，标注的困难使过拟合问题更加严重。因此，从噪声标签中学习最近已成为最活跃的研究主题之一。
- en: In this survey, we presented a comprehensive understanding of modern deep learning
    methods to address the negative consequences of learning from noisy labels. All
    the methods were grouped into five categories according to their underlying strategies
    and described along with their methodological weaknesses. Furthermore, a systematic
    comparison was conducted using six popular properties used for evaluation in the
    recent literature. According to the comparison results, there is no ideal method
    that supports all the required properties; the supported properties varied depending
    on the category to which each method belonged. Several experimental guidelines
    were also discussed, including noise rate estimation, publicly available datasets,
    and evaluation metrics. Finally, we provided insights and directions for future
    research in this domain.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次调查中，我们提供了对现代深度学习方法的全面理解，以解决从噪声标签中学习的负面影响。所有方法根据其基本策略分为五类，并描述了它们的方法论缺陷。此外，使用最近文献中的六个流行属性进行了系统比较。根据比较结果，没有一种理想的方法支持所有所需的属性；支持的属性因每种方法所属的类别而异。还讨论了几个实验指南，包括噪声率估计、公开数据集和评估指标。最后，我们提供了对该领域未来研究的见解和方向。
- en: References
  id: totrans-365
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet classification
    with deep convolutional neural networks,” in *Proc. NeurIPS*, 2012, pp. 1097–1105.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] A. Krizhevsky, I. Sutskever, 和 G. E. Hinton，“使用深度卷积神经网络进行ImageNet分类，”发表于*Proc.
    NeurIPS*，2012年，页码1097–1105。'
- en: '[2] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only look once:
    Unified, real-time object detection,” in *Proc. CVPR*, 2016, pp. 779–788.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] J. Redmon, S. Divvala, R. Girshick, 和 A. Farhadi，“你只需看一次：统一的实时物体检测，”发表于*Proc.
    CVPR*，2016年，页码779–788。'
- en: '[3] W. Zhang, T. Du, and J. Wang, “Deep learning over multi-field categorical
    data,” in *Proc. ECIR*, 2016, pp. 45–57.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] W. Zhang, T. Du, 和 J. Wang，“多字段分类数据上的深度学习，”发表于*Proc. ECIR*，2016年，页码45–57。'
- en: '[4] L. Pang, Y. Lan, J. Guo, J. Xu, J. Xu, and X. Cheng, “Deeprank: A new deep
    architecture for relevance ranking in information retrieval,” in *Proc. CIKM*,
    2017, pp. 257–266.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] L. Pang, Y. Lan, J. Guo, J. Xu, J. Xu, 和 X. Cheng，“Deeprank：信息检索中相关性排名的新深度架构，”发表于*Proc.
    CIKM*，2017年，页码257–266。'
- en: '[5] K. D. Onal, Y. Zhang, I. S. Altingovde, M. M. Rahman, P. Karagoz, A. Braylan,
    B. Dang, H.-L. Chang, H. Kim, Q. McNamara *et al.*, “Neural information retrieval:
    At the end of the early years,” *Information Retrieval Journal*, vol. 21, no.
    2-3, pp. 111–182, 2018.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] K. D. Onal, Y. Zhang, I. S. Altingovde, M. M. Rahman, P. Karagoz, A. Braylan,
    B. Dang, H.-L. Chang, H. Kim, Q. McNamara *等*，“神经信息检索：早期阶段的终结，”*Information Retrieval
    Journal*，第21卷，第2-3期，页码111–182，2018年。'
- en: '[6] J. Howard and S. Ruder, “Universal language model fine-tuning for text
    classification,” in *Proc. ACL*, 2018, pp. 328–339.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] J. Howard 和 S. Ruder，“用于文本分类的通用语言模型微调，”发表于*Proc. ACL*，2018年，页码328–339。'
- en: '[7] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training of
    deep bidirectional transformers for language understanding,” in *Proc. ACL*, 2019,
    pp. 4171–4186.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] J. Devlin, M.-W. Chang, K. Lee, 和 K. Toutanova，“BERT：用于语言理解的深度双向变换器的预训练，”发表于*Proc.
    ACL*，2019年，页码4171–4186。'
- en: '[8] A. Severyn and A. Moschitti, “Twitter sentiment analysis with deep convolutional
    neural networks,” in *Proc. ACL*, 2015, pp. 959–962.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] A. Severyn 和 A. Moschitti，"使用深度卷积神经网络进行推特情感分析"，在 *ACL 会议论文集*，2015 年，页码
    959–962。'
- en: '[9] G. Paolacci, J. Chandler, and P. G. Ipeirotis, “Running experiments on
    amazon mechanical turk,” *Judgment and Decision Making*, vol. 5, no. 5, pp. 411–419,
    2010.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] G. Paolacci，J. Chandler 和 P. G. Ipeirotis，"在亚马逊 Mechanical Turk 上进行实验"，*判断与决策*，第
    5 卷，第 5 期，页码 411–419，2010 年。'
- en: '[10] V. Cothey, “Web-crawling reliability,” *Journal of the American Society
    for Information Science and Technology*, vol. 55, no. 14, pp. 1228–1238, 2004.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] V. Cothey，"网页爬虫的可靠性"，*美国信息科学与技术学会期刊*，第 55 卷，第 14 期，页码 1228–1238，2004 年。'
- en: '[11] W. Mason and S. Suri, “Conducting behavioral research on amazon’s mechanical
    turk,” *Behavior Research Methods*, vol. 44, no. 1, pp. 1–23, 2012.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] W. Mason 和 S. Suri，"在亚马逊 Mechanical Turk 上进行行为研究"，*行为研究方法*，第 44 卷，第 1
    期，页码 1–23，2012 年。'
- en: '[12] C. Scott, G. Blanchard, and G. Handy, “Classification with asymmetric
    label noise: Consistency and maximal denoising,” in *Proc. COLT*, 2013, pp. 489–511.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] C. Scott，G. Blanchard 和 G. Handy，"在不对称标签噪声下的分类：一致性和最大去噪"，在 *COLT 会议论文集*，2013
    年，页码 489–511。'
- en: '[13] B. Frénay and M. Verleysen, “Classification in the presence of label noise:
    A survey,” *IEEE Transaction on Neural Networks and Learning Systems*, vol. 25,
    no. 5, pp. 845–869, 2013.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] B. Frénay 和 M. Verleysen，"在标签噪声存在下的分类：综述"，*IEEE 神经网络与学习系统学报*，第 25 卷，第
    5 期，页码 845–869，2013 年。'
- en: '[14] R. V. Lloyd, L. A. Erickson, M. B. Casey, K. Y. Lam, C. M. Lohse, S. L.
    Asa, J. K. Chan, R. A. DeLellis, H. R. Harach, K. Kakudo *et al.*, “Observer variation
    in the diagnosis of follicular variant of papillary thyroid carcinoma,” *The American
    Journal of Surgical Pathology*, vol. 28, no. 10, pp. 1336–1340, 2004.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] R. V. Lloyd，L. A. Erickson，M. B. Casey，K. Y. Lam，C. M. Lohse，S. L. Asa，J.
    K. Chan，R. A. DeLellis，H. R. Harach 和 K. Kakudo *等*，"甲状腺乳头状癌滤泡变异型诊断中的观察者差异"，*美国外科病理学杂志*，第
    28 卷，第 10 期，页码 1336–1340，2004 年。'
- en: '[15] H. Xiao, H. Xiao, and C. Eckert, “Adversarial label flips attack on support
    vector machines.” in *Proc. ECAI*, 2012, pp. 870–875.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] H. Xiao，H. Xiao 和 C. Eckert，"对支持向量机的对抗标签翻转攻击"，在 *ECAI 会议论文集*，2012 年，页码
    870–875。'
- en: '[16] T. Xiao, T. Xia, Y. Yang, C. Huang, and X. Wang, “Learning from massive
    noisy labeled data for image classification,” in *Proc. CVPR*, 2015, pp. 2691–2699.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] T. Xiao，T. Xia，Y. Yang，C. Huang 和 X. Wang，"从大规模噪声标签数据中学习进行图像分类"，在 *CVPR
    会议论文集*，2015 年，页码 2691–2699。'
- en: '[17] W. Li, L. Wang, W. Li, E. Agustsson, and L. Van Gool, “Webvision database:
    Visual learning and understanding from web data,” *arXiv preprint arXiv:1708.02862*,
    2017.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] W. Li，L. Wang，W. Li，E. Agustsson 和 L. Van Gool，"Webvision 数据库：从网络数据中进行视觉学习和理解"，*arXiv
    预印本 arXiv:1708.02862*，2017 年。'
- en: '[18] K.-H. Lee, X. He, L. Zhang, and L. Yang, “CleanNet: Transfer learning
    for scalable image classifier training with label noise,” in *Proc. CVPR*, 2018,
    pp. 5447–5456.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] K.-H. Lee，X. He，L. Zhang 和 L. Yang，"CleanNet：用于标签噪声的可扩展图像分类器训练的迁移学习"，在
    *CVPR 会议论文集*，2018 年，页码 5447–5456。'
- en: '[19] H. Song, M. Kim, and J.-G. Lee, “SELFIE: Refurbishing unclean samples
    for robust deep learning,” in *Proc. ICML*, 2019, pp. 5907–5915.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] H. Song，M. Kim 和 J.-G. Lee，"SELFIE：为鲁棒深度学习翻新不洁样本"，在 *ICML 会议论文集*，2019
    年，页码 5907–5915。'
- en: '[20] J. Krause, B. Sapp, A. Howard, H. Zhou, A. Toshev, T. Duerig, J. Philbin,
    and L. Fei-Fei, “The unreasonable effectiveness of noisy data for fine-grained
    recognition,” in *Proc. ECCV*, 2016, pp. 301–320.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] J. Krause，B. Sapp，A. Howard，H. Zhou，A. Toshev，T. Duerig，J. Philbin 和 L.
    Fei-Fei，"噪声数据在细粒度识别中的不合理有效性"，在 *ECCV 会议论文集*，2016 年，页码 301–320。'
- en: '[21] D. Arpit, S. Jastrzebski, N. Ballas, D. Krueger, E. Bengio, M. S. Kanwal,
    T. Maharaj, A. Fischer, A. Courville, Y. Bengio *et al.*, “A closer look at memorization
    in deep networks,” in *Proc. ICML*, 2017, pp. 233–242.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] D. Arpit，S. Jastrzebski，N. Ballas，D. Krueger，E. Bengio，M. S. Kanwal，T.
    Maharaj，A. Fischer，A. Courville，Y. Bengio *等*，"深入了解深度网络中的记忆"，在 *ICML 会议论文集*，2017
    年，页码 233–242。'
- en: '[22] C. Zhang, S. Bengio, M. Hardt, B. Recht, and O. Vinyals, “Understanding
    deep learning requires rethinking generalization,” in *Proc. ICLR*, 2017.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] C. Zhang，S. Bengio，M. Hardt，B. Recht 和 O. Vinyals，"理解深度学习需要重新思考泛化"，在 *ICLR
    会议论文集*，2017 年。'
- en: '[23] C. Shorten and T. M. Khoshgoftaar, “A survey on image data augmentation
    for deep learning,” *Journal of Big Data*, vol. 6, no. 1, p. 60, 2019.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] C. Shorten 和 T. M. Khoshgoftaar，"深度学习中的图像数据增强综述"，*大数据杂志*，第 6 卷，第 1 期，页码
    60，2019 年。'
- en: '[24] A. Krogh and J. A. Hertz, “A simple weight decay can improve generalization,”
    in *Proc, NeurIPS*, 1992, pp. 950–957.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] A. Krogh 和 J. A. Hertz，"简单的权重衰减可以改善泛化"，在 *NeurIPS 会议论文集*，1992 年，页码 950–957。'
- en: '[25] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov,
    “Dropout: A simple way to prevent neural networks from overfitting,” *The Journal
    of Machine Learning Research*, vol. 15, no. 1, pp. 1929–1958, 2014.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, 和 R. Salakhutdinov,
    “Dropout：一种防止神经网络过拟合的简单方法”，*机器学习研究杂志*，第15卷，第1期，第1929–1958页，2014年。'
- en: '[26] S. Ioffe and C. Szegedy, “Batch normalization: Accelerating deep network
    training by reducing internal covariate shift,” in *Proc. ICML*, 2015, pp. 448–456.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] S. Ioffe 和 C. Szegedy, “批量归一化：通过减少内部协变量偏移来加速深度网络训练”，见于*ICML会议论文集*，2015年，第448–456页。'
- en: '[27] X. Zhu and X. Wu, “Class noise vs. attribute noise: A quantitative study,”
    *Artificial Intelligence Review*, vol. 22, no. 3, pp. 177–210, 2004.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] X. Zhu 和 X. Wu, “类别噪声与属性噪声：一项定量研究”，*人工智能评论*，第22卷，第3期，第177–210页，2004年。'
- en: '[28] J. Zhang, X. Wu, and V. S. Sheng, “Learning from crowdsourced labeled
    data: A survey,” *Artificial Intelligence Review*, vol. 46, no. 4, pp. 543–576,
    2016.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] J. Zhang, X. Wu, 和 V. S. Sheng, “从众包标注数据中学习：一项调查”，*人工智能评论*，第46卷，第4期，第543–576页，2016年。'
- en: '[29] N. Nigam, T. Dutta, and H. P. Gupta, “Impact of noisy labels in learning
    techniques: A survey,” in *Proc. ICDIS*, 2020, pp. 403–411.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] N. Nigam, T. Dutta, 和 H. P. Gupta, “噪声标签对学习技术的影响：一项调查”，见于*ICDIS会议论文集*，2020年，第403–411页。'
- en: '[30] B. Han, Q. Yao, T. Liu, G. Niu, I. W. Tsang, J. T. Kwok, and M. Sugiyama,
    “A survey of label-noise representation learning: Past, present and future,” *arXiv
    preprint arXiv:2011.04406*, 2020.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] B. Han, Q. Yao, T. Liu, G. Niu, I. W. Tsang, J. T. Kwok, 和 M. Sugiyama,
    “标签噪声表示学习的调查：过去、现在和未来”，*arXiv预印本arXiv:2011.04406*，2020年。'
- en: '[31] N. Akhtar and A. Mian, “Threat of adversarial attacks on deep learning
    in computer vision: A survey,” *Access*, vol. 6, pp. 14 410–14 430, 2018.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] N. Akhtar 和 A. Mian, “对深度学习在计算机视觉中的对抗攻击的威胁：一项调查”，*Access*，第6卷，第14 410–14 430页，2018年。'
- en: '[32] J. Yoon, J. Jordon, and M. Schaar, “Gain: Missing data imputation using
    generative adversarial nets,” in *Proc. ICML*, 2018, pp. 5689–5698.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] J. Yoon, J. Jordon, 和 M. Schaar, “Gain：使用生成对抗网络进行缺失数据插补”，见于*ICML会议论文集*，2018年，第5689–5698页。'
- en: '[33] A. Fawzi, S.-M. Moosavi-Dezfooli, and P. Frossard, “Robustness of classifiers:
    from adversarial to random noise,” in *Proc. NeurIPS*, 2016, pp. 1632–1640.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] A. Fawzi, S.-M. Moosavi-Dezfooli, 和 P. Frossard, “分类器的鲁棒性：从对抗噪声到随机噪声”，见于*NeurIPS会议论文集*，2016年，第1632–1640页。'
- en: '[34] E. Dohmatob, “Limitations of adversarial robustness: strong no free lunch
    theorem,” in *Proc. ICML*, 2019.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] E. Dohmatob, “对抗鲁棒性的局限性：强无免费午餐定理”，见于*ICML会议论文集*，2019年。'
- en: '[35] J. Gilmer, N. Ford, N. Carlini, and E. Cubuk, “Adversarial examples are
    a natural consequence of test error in noise,” in *Proc. ICML*, 2019, pp. 2280–2289.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] J. Gilmer, N. Ford, N. Carlini, 和 E. Cubuk, “对抗样本是噪声中测试误差的自然结果”，见于*ICML会议论文集*，2019年，第2280–2289页。'
- en: '[36] S. Mahloujifar, D. I. Diochnos, and M. Mahmoody, “The curse of concentration
    in robust learning: Evasion and poisoning attacks from concentration of measure,”
    in *Proc. AAAI*, vol. 33, no. 01, 2019, pp. 4536–4543.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] S. Mahloujifar, D. I. Diochnos, 和 M. Mahmoody, “鲁棒学习中的集中诅咒：来自测量集中度的规避和中毒攻击”，见于*AAAI会议论文集*，第33卷，第01期，2019年，第4536–4543页。'
- en: '[37] D. B. Rubin, “Inference and missing data,” *Biometrika*, vol. 63, no. 3,
    pp. 581–592, 1976.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] D. B. Rubin, “推断与缺失数据”，*生物统计学*，第63卷，第3期，第581–592页，1976年。'
- en: '[38] C. M. Bishop, *Pattern recognition and machine learning*.   Springer,
    2006.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] C. M. Bishop, *模式识别与机器学习*。Springer，2006年。'
- en: '[39] N. Natarajan, I. S. Dhillon, P. K. Ravikumar, and A. Tewari, “Learning
    with noisy labels,” in *Proc. NeurIPS*, 2013, pp. 1196–1204.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] N. Natarajan, I. S. Dhillon, P. K. Ravikumar, 和 A. Tewari, “处理噪声标签的学习”，见于*NeurIPS会议论文集*，2013年，第1196–1204页。'
- en: '[40] J. Goldberger and E. Ben-Reuven, “Training deep neural-networks using
    a noise adaptation layer,” in *Proc. ICLR*, 2017.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] J. Goldberger 和 E. Ben-Reuven, “使用噪声适应层训练深度神经网络”，见于*ICLR会议论文集*，2017年。'
- en: '[41] P. Sastry and N. Manwani, “Robust learning of classifiers in the presence
    of label noise,” in *Pattern Recognition and Big Data*, 2017, pp. 167–197.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] P. Sastry 和 N. Manwani, “在标签噪声存在下的分类器鲁棒学习”，见于*模式识别与大数据*，2017年，第167–197页。'
- en: '[42] V. Wheway, “Using boosting to detect noisy data,” in *Proc. PRICAI*, 2000,
    pp. 123–130.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] V. Wheway, “利用提升检测噪声数据”，见于*PRICAI会议论文集*，2000年，第123–130页。'
- en: '[43] B. Sluban, D. Gamberger, and N. Lavrač, “Ensemble-based noise detection:
    Noise ranking and visual performance evaluation,” *Data Mining and Knowledge Discovery*,
    vol. 28, no. 2, pp. 265–303, 2014.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] B. Sluban, D. Gamberger, 和 N. Lavrač, “基于集成的噪声检测：噪声排序和视觉性能评估”，*数据挖掘与知识发现*，第28卷，第2期，第265–303页，2014年。'
- en: '[44] S. J. Delany, N. Segata, and B. Mac Namee, “Profiling instances in noise
    reduction,” *Knowledge-Based Systems*, vol. 31, pp. 28–40, 2012.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] S. J. Delany, N. Segata 和 B. Mac Namee，“噪声减少中的实例剖析”，*Knowledge-Based Systems*，第31卷，第28–40页，2012年。'
- en: '[45] D. Gamberger, N. Lavrac, and S. Dzeroski, “Noise detection and elimination
    in data preprocessing: Experiments in medical domains,” *Applied Artificial Intelligence*,
    vol. 14, no. 2, pp. 205–223, 2000.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] D. Gamberger, N. Lavrac 和 S. Dzeroski，“数据预处理中的噪声检测与消除：医疗领域的实验”，*Applied
    Artificial Intelligence*，第14卷，第2期，第205–223页，2000年。'
- en: '[46] J. Thongkam, G. Xu, Y. Zhang, and F. Huang, “Support vector machine for
    outlier detection in breast cancer survivability prediction,” in *Proc. APWeb*,
    2008, pp. 99–109.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] J. Thongkam, G. Xu, Y. Zhang 和 F. Huang，“用于乳腺癌生存预测的异常值检测支持向量机”，发表于*Proc.
    APWeb*，2008年，第99–109页。'
- en: '[47] V. Mnih and G. E. Hinton, “Learning to label aerial images from noisy
    data,” in *Proc. ICML*, 2012, pp. 567–574.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] V. Mnih 和 G. E. Hinton，“从噪声数据中学习标注航空图像”，发表于*Proc. ICML*，2012年，第567–574页。'
- en: '[48] N. Manwani and P. Sastry, “Noise tolerance under risk minimization,” *IEEE
    Transactions on Cybernetics*, vol. 43, no. 3, pp. 1146–1151, 2013.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] N. Manwani 和 P. Sastry，“在风险最小化下的噪声容忍度”，*IEEE Transactions on Cybernetics*，第43卷，第3期，第1146–1151页，2013年。'
- en: '[49] A. Ghosh, N. Manwani, and P. Sastry, “Making risk minimization tolerant
    to label noise,” *Neurocomputing*, vol. 160, pp. 93–107, 2015.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] A. Ghosh, N. Manwani 和 P. Sastry，“使风险最小化容忍标签噪声”，*Neurocomputing*，第160卷，第93–107页，2015年。'
- en: '[50] B. Van Rooyen, A. Menon, and R. C. Williamson, “Learning with symmetric
    label noise: The importance of being unhinged,” in *Proc. NeurIPS*, 2015, pp.
    10–18.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] B. Van Rooyen, A. Menon 和 R. C. Williamson，“具有对称标签噪声的学习：保持理智的重要性”，发表于*Proc.
    NeurIPS*，2015年，第10–18页。'
- en: '[51] G. Patrini, F. Nielsen, R. Nock, and M. Carioni, “Loss factorization,
    weakly supervised learning and label noise robustness,” in *Proc. ICML*, 2016,
    pp. 708–717.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] G. Patrini, F. Nielsen, R. Nock 和 M. Carioni，“损失分解、弱监督学习和标签噪声的鲁棒性”，发表于*Proc.
    ICML*，2016年，第708–717页。'
- en: '[52] R. Xu and D. Wunsch, “Survey of clustering algorithms,” *IEEE Transactions
    on Neural Networks*, vol. 16, no. 3, pp. 645–678, 2005.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] R. Xu 和 D. Wunsch，“聚类算法综述”，*IEEE Transactions on Neural Networks*，第16卷，第3期，第645–678页，2005年。'
- en: '[53] U. Rebbapragada and C. E. Brodley, “Class noise mitigation through instance
    weighting,” in *Proc. ECML*, 2007, pp. 708–715.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] U. Rebbapragada 和 C. E. Brodley，“通过实例加权减轻类噪声”，发表于*Proc. ECML*，2007年，第708–715页。'
- en: '[54] T. Liu, K. Wang, B. Chang, and Z. Sui, “A soft-label method for noise-tolerant
    distantly supervised relation extraction,” in *Proc. EMNLP*, 2017, pp. 1790–1795.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] T. Liu, K. Wang, B. Chang 和 Z. Sui，“一种用于噪声容忍的远程监督关系抽取的软标签方法”，发表于*Proc.
    EMNLP*，2017年，第1790–1795页。'
- en: '[55] F. O. Kaster, B. H. Menze, M.-A. Weber, and F. A. Hamprecht, “Comparative
    validation of graphical models for learning tumor segmentations from noisy manual
    annotations,” in *Proc. MICCAI*, 2010, pp. 74–85.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] F. O. Kaster, B. H. Menze, M.-A. Weber 和 F. A. Hamprecht，“图形模型在学习肿瘤分割中的比较验证：从噪声手动标注中学习”，发表于*Proc.
    MICCAI*，2010年，第74–85页。'
- en: '[56] A. Ganapathiraju and J. Picone, “Support vector machines for automatic
    data cleanup,” in *Proc. ICSLP*, 2000.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] A. Ganapathiraju 和 J. Picone，“用于自动数据清理的支持向量机”，发表于*Proc. ICSLP*，2000年。'
- en: '[57] B. Biggio, B. Nelson, and P. Laskov, “Support vector machines under adversarial
    label noise,” in *Proc. ACML*, 2011, pp. 97–112.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] B. Biggio, B. Nelson 和 P. Laskov，“在对抗性标签噪声下的支持向量机”，发表于*Proc. ACML*，2011年，第97–112页。'
- en: '[58] C. J. Mantas and J. Abellán, “Credal-C4\. 5: Decision tree based on imprecise
    probabilities to classify noisy data,” *Expert Systems with Applications*, vol. 41,
    no. 10, pp. 4625–4637, 2014.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] C. J. Mantas 和 J. Abellán，“Credal-C4.5：基于不精确概率的决策树以分类噪声数据”，*Expert Systems
    with Applications*，第41卷，第10期，第4625–4637页，2014年。'
- en: '[59] A. Ghosh, N. Manwani, and P. Sastry, “On the robustness of decision tree
    learning under label noise,” in *Proc. PAKDD*, 2017, pp. 685–697.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] A. Ghosh, N. Manwani 和 P. Sastry，“决策树学习在标签噪声下的鲁棒性”，发表于*Proc. PAKDD*，2017年，第685–697页。'
- en: '[60] S. Liu, J. Niles-Weed, N. Razavian, and C. Fernandez-Granda, “Early-learning
    regularization prevents memorization of noisy labels,” in *Proc. NeurIPS*, vol. 33,
    2020.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] S. Liu, J. Niles-Weed, N. Razavian 和 C. Fernandez-Granda，“早期学习正则化防止噪声标签的记忆”，发表于*Proc.
    NeurIPS*，第33卷，2020年。'
- en: '[61] M. Li, M. Soltanolkotabi, and S. Oymak, “Gradient descent with early stopping
    is provably robust to label noise for overparameterized neural networks,” in *Proc.
    AISTATS*, 2020, pp. 4313–4324.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] M. Li, M. Soltanolkotabi 和 S. Oymak，“梯度下降与早期停止在过参数化神经网络中对标签噪声的可证明鲁棒性”，发表于*Proc.
    AISTATS*，2020年，第4313–4324页。'
- en: '[62] G. Patrini, A. Rozza, A. Krishna Menon, R. Nock, and L. Qu, “Making deep
    neural networks robust to label noise: A loss correction approach,” in *Proc.
    CVPR*, 2017, pp. 1944–1952.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] G. Patrini, A. Rozza, A. Krishna Menon, R. Nock, 和 L. Qu, “使深度神经网络对标签噪声具有鲁棒性：一种损失修正方法，”发表于
    *Proc. CVPR*, 2017, 页码 1944–1952。'
- en: '[63] J. Cheng, T. Liu, K. Ramamohanarao, and D. Tao, “Learning with bounded
    instance and label-dependent label noise,” in *Proc. ICML*, 2020, pp. 1789–1799.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] J. Cheng, T. Liu, K. Ramamohanarao, 和 D. Tao, “学习有界实例和标签依赖标签噪声，”发表于 *Proc.
    ICML*, 2020, 页码 1789–1799。'
- en: '[64] B. Garg and N. Manwani, “Robust deep ordinal regression under label noise,”
    in *Proc. ACML*, 2020, pp. 782–796.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] B. Garg 和 N. Manwani, “在标签噪声下的鲁棒深度序数回归，”发表于 *Proc. ACML*, 2020, 页码 782–796。'
- en: '[65] W. Hu, Z. Li, and D. Yu, “Simple and effective regularization methods
    for training on noisily labeled data with generalization guarantee,” in *Proc.
    ICLR*, 2020.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] W. Hu, Z. Li, 和 D. Yu, “用于噪声标签数据的简单有效的正则化方法，具有泛化保证，”发表于 *Proc. ICLR*,
    2020。'
- en: '[66] A. K. Menon, B. Van Rooyen, and N. Natarajan, “Learning from binary labels
    with instance-dependent noise,” *Machine Learning*, vol. 107, no. 8, pp. 1561–1595,
    2018.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] A. K. Menon, B. Van Rooyen, 和 N. Natarajan, “从具有实例依赖噪声的二元标签中学习，” *Machine
    Learning*, vol. 107, no. 8, 页码 1561–1595, 2018。'
- en: '[67] L. Torgo and J. Gama, “Regression using classification algorithms,” *Intelligent
    Data Analysis*, vol. 1, no. 4, pp. 275–292, 1997.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] L. Torgo 和 J. Gama, “使用分类算法的回归，” *Intelligent Data Analysis*, vol. 1,
    no. 4, 页码 275–292, 1997。'
- en: '[68] A. Ghosh, H. Kumar, and P. Sastry, “Robust loss functions under label
    noise for deep neural networks,” in *Proc. AAAI*, 2017.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] A. Ghosh, H. Kumar, 和 P. Sastry, “针对深度神经网络的标签噪声的鲁棒损失函数，”发表于 *Proc. AAAI*,
    2017。'
- en: '[69] S. Reed, H. Lee, D. Anguelov, C. Szegedy, D. Erhan, and A. Rabinovich,
    “Training deep neural networks on noisy labels with bootstrapping,” in *Proc.
    ICLR*, 2015.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] S. Reed, H. Lee, D. Anguelov, C. Szegedy, D. Erhan, 和 A. Rabinovich, “在噪声标签上使用自助法训练深度神经网络，”发表于
    *Proc. ICLR*, 2015。'
- en: '[70] E. Malach and S. Shalev-Shwartz, “Decoupling” when to update” from” how
    to update”,” in *Proc. NeurIPS*, 2017, pp. 960–970.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] E. Malach 和 S. Shalev-Shwartz, “将‘何时更新’与‘如何更新’解耦，”发表于 *Proc. NeurIPS*,
    2017, 页码 960–970。'
- en: '[71] L. P. Garcia, A. C. de Carvalho, and A. C. Lorena, “Noise detection in
    the meta-learning level,” *Neurocomputing*, vol. 176, pp. 14–25, 2016.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] L. P. Garcia, A. C. de Carvalho, 和 A. C. Lorena, “元学习层中的噪声检测，” *Neurocomputing*,
    vol. 176, 页码 14–25, 2016。'
- en: '[72] Y. Yan, Z. Xu, I. W. Tsang, G. Long, and Y. Yang, “Robust semi-supervised
    learning through label aggregation,” in *Proc. AAAI*, 2016.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] Y. Yan, Z. Xu, I. W. Tsang, G. Long, 和 Y. Yang, “通过标签聚合实现鲁棒的半监督学习，”发表于
    *Proc. AAAI*, 2016。'
- en: '[73] H. Harutyunyan, K. Reing, G. Ver Steeg, and A. Galstyan, “Improving generalization
    by controlling label-noise information in neural network weights,” in *Proc. ICML*,
    2020, pp. 4071–4081.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] H. Harutyunyan, K. Reing, G. Ver Steeg, 和 A. Galstyan, “通过控制神经网络权重中的标签噪声信息来改善泛化，”发表于
    *Proc. ICML*, 2020, 页码 4071–4081。'
- en: '[74] P. Chen, G. Chen, J. Ye, jingwei zhao, and P.-A. Heng, “Noise against
    noise: stochastic label noise helps combat inherent label noise,” in *Proc. ICLR*,
    2021.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] P. Chen, G. Chen, J. Ye, jingwei zhao, 和 P.-A. Heng, “噪声对抗噪声：随机标签噪声有助于对抗固有标签噪声，”发表于
    *Proc. ICLR*, 2021。'
- en: '[75] X. Chen and A. Gupta, “Webly supervised learning of convolutional networks,”
    in *Proc. ICCV*, 2015, pp. 1431–1439.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] X. Chen 和 A. Gupta, “卷积网络的Webly监督学习，”发表于 *Proc. ICCV*, 2015, 页码 1431–1439。'
- en: '[76] A. J. Bekker and J. Goldberger, “Training deep neural-networks based on
    unreliable labels,” in *Proc. ICASSP*, 2016, pp. 2682–2686.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] A. J. Bekker 和 J. Goldberger, “基于不可靠标签训练深度神经网络，”发表于 *Proc. ICASSP*, 2016,
    页码 2682–2686。'
- en: '[77] S. Sukhbaatar, J. Bruna, M. Paluri, L. Bourdev, and R. Fergus, “Training
    convolutional networks with noisy labels,” in *Proc. ICLRW*, 2015.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] S. Sukhbaatar, J. Bruna, M. Paluri, L. Bourdev, 和 R. Fergus, “用噪声标签训练卷积网络，”发表于
    *Proc. ICLRW*, 2015。'
- en: '[78] I. Jindal, M. Nokleby, and X. Chen, “Learning deep networks from noisy
    labels with dropout regularization,” in *Proc. ICDM*, 2016, pp. 967–972.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] I. Jindal, M. Nokleby, 和 X. Chen, “通过 dropout 正则化从噪声标签中学习深度网络，”发表于 *Proc.
    ICDM*, 2016, 页码 967–972。'
- en: '[79] J. Goldberger and E. Ben-Reuven, “Training deep neural-networks using
    a noise adaptation layer,” in *Proc. ICLR*, 2017.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] J. Goldberger 和 E. Ben-Reuven, “使用噪声适应层训练深度神经网络，”发表于 *Proc. ICLR*, 2017。'
- en: '[80] B. Han, J. Yao, G. Niu, M. Zhou, I. Tsang, Y. Zhang, and M. Sugiyama,
    “Masking: A new perspective of noisy supervision,” in *Proc. NeurIPS*, 2018, pp.
    5836–5846.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] B. Han, J. Yao, G. Niu, M. Zhou, I. Tsang, Y. Zhang, 和 M. Sugiyama, “Masking：一种新的噪声监督视角，”发表于
    *Proc. NeurIPS*, 2018, 页码 5836–5846。'
- en: '[81] J. Yao, J. Wang, I. W. Tsang, Y. Zhang, J. Sun, C. Zhang, and R. Zhang,
    “Deep learning from noisy image labels with quality embedding,” *IEEE Transactions
    on Image Processing*, vol. 28, no. 4, pp. 1909–1922, 2018.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] J. Yao, J. Wang, I. W. Tsang, Y. Zhang, J. Sun, C. Zhang, 和 R. Zhang,
    “利用质量嵌入从噪声图像标签中进行深度学习”，*IEEE 图像处理汇刊*，第28卷，第4期，第1909–1922页，2018年。'
- en: '[82] L. Cheng, X. Zhou, L. Zhao, D. Li, H. Shang, Y. Zheng, P. Pan, and Y. Xu,
    “Weakly supervised learning with side information for noisy labeled images,” in
    *Proc. ECCV*, 2020, pp. 306–321.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] L. Cheng, X. Zhou, L. Zhao, D. Li, H. Shang, Y. Zheng, P. Pan, 和 Y. Xu,
    “利用附加信息进行弱监督学习以处理带噪标签的图像”，发表于 *Proc. ECCV*，2020年，第306–321页。'
- en: '[83] X. Xia, T. Liu, B. Han, N. Wang, J. Deng, J. Li, and Y. Mao, “Extended
    T: Learning with mixed closed-set and open-set noisy labels,” *arXiv preprint
    arXiv:2012.00932*, 2020.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] X. Xia, T. Liu, B. Han, N. Wang, J. Deng, J. Li, 和 Y. Mao, “扩展 T：在混合封闭集和开放集噪声标签下进行学习”，*arXiv
    预印本 arXiv:2012.00932*，2020年。'
- en: '[84] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, and Y. Bengio, “Generative adversarial nets,” in *Proc. NeurIPS*,
    2014, pp. 2672–2680.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S.
    Ozair, A. Courville, 和 Y. Bengio, “生成对抗网络”，发表于 *Proc. NeurIPS*，2014年，第2672–2680页。'
- en: '[85] K. Lee, S. Yun, K. Lee, H. Lee, B. Li, and J. Shin, “Robust inference
    via generative classifiers for handling noisy labels,” in *Proc. ICML*, 2019,
    pp. 3763–3772.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] K. Lee, S. Yun, K. Lee, H. Lee, B. Li, 和 J. Shin, “通过生成分类器进行鲁棒推断以处理噪声标签”，发表于
    *Proc. ICML*，2019年，第3763–3772页。'
- en: '[86] R. Tanno, A. Saeedi, S. Sankaranarayanan, D. C. Alexander, and N. Silberman,
    “Learning from noisy labels by regularized estimation of annotator confusion,”
    in *Proc. CVPR*, 2019, pp. 11 244–11 253.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] R. Tanno, A. Saeedi, S. Sankaranarayanan, D. C. Alexander, 和 N. Silberman,
    “通过正则化估计标注者混淆来学习噪声标签”，发表于 *Proc. CVPR*，2019年，第11 244–11 253页。'
- en: '[87] S. Jenni and P. Favaro, “Deep bilevel learning,” in *Proc. ECCV*, 2018,
    pp. 618–633.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] S. Jenni 和 P. Favaro, “深度双层学习”，发表于 *Proc. ECCV*，2018年，第618–633页。'
- en: '[88] D. Hendrycks, K. Lee, and M. Mazeika, “Using pre-training can improve
    model robustness and uncertainty,” in *Proc. ICML*, 2019.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] D. Hendrycks, K. Lee, 和 M. Mazeika, “使用预训练可以提高模型的鲁棒性和不确定性”，发表于 *Proc.
    ICML*，2019年。'
- en: '[89] A. K. Menon, A. S. Rawat, S. J. Reddi, and S. Kumar, “Can gradient clipping
    mitigate label noise?” in *Proc. ICLR*, 2020.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] A. K. Menon, A. S. Rawat, S. J. Reddi, 和 S. Kumar, “梯度裁剪能否缓解标签噪声？”，发表于
    *Proc. ICLR*，2020年。'
- en: '[90] X. Xia, T. Liu, B. Han, C. Gong, N. Wang, Z. Ge, and Y. Chang, “Robust
    early-learning: Hindering the memorization of noisy labels,” in *Proc. ICLR*,
    2021.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] X. Xia, T. Liu, B. Han, C. Gong, N. Wang, Z. Ge, 和 Y. Chang, “鲁棒的早期学习：阻碍噪声标签的记忆化”，发表于
    *Proc. ICLR*，2021年。'
- en: '[91] H. Wei, L. Tao, R. Xie, and B. An, “Open-set label noise can improve robustness
    against inherent label noise,” in *Proc. NeurIPS*, 2021.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] H. Wei, L. Tao, R. Xie, 和 B. An, “开放集标签噪声可以提高对固有标签噪声的鲁棒性”，发表于 *Proc. NeurIPS*，2021年。'
- en: '[92] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing
    adversarial examples,” in *Proc. ICLR*, 2014.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] I. J. Goodfellow, J. Shlens, 和 C. Szegedy, “解释和利用对抗样本”，发表于 *Proc. ICLR*，2014年。'
- en: '[93] G. Pereyra, G. Tucker, J. Chorowski, Ł. Kaiser, and G. Hinton, “Regularizing
    neural networks by penalizing confident output distributions,” in *Proc. ICLRW*,
    2017.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] G. Pereyra, G. Tucker, J. Chorowski, Ł. Kaiser, 和 G. Hinton, “通过惩罚自信的输出分布来正则化神经网络”，发表于
    *Proc. ICLRW*，2017年。'
- en: '[94] M. Lukasik, S. Bhojanapalli, A. Menon, and S. Kumar, “Does label smoothing
    mitigate label noise?” in *Proc. ICLR*, 2020, pp. 6448–6458.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] M. Lukasik, S. Bhojanapalli, A. Menon, 和 S. Kumar, “标签平滑是否能缓解标签噪声？”，发表于
    *Proc. ICLR*，2020年，第6448–6458页。'
- en: '[95] H. Zhang, M. Cisse, Y. N. Dauphin, and D. Lopez-Paz, “Mixup: Beyond empirical
    risk minimization,” in *Proc. ICLR*, 2018.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] H. Zhang, M. Cisse, Y. N. Dauphin, 和 D. Lopez-Paz, “Mixup：超越经验风险最小化”，发表于
    *Proc. ICLR*，2018年。'
- en: '[96] B. C. Csáji *et al.*, “Approximation with artificial neural networks,”
    *Faculty of Sciences, Etvs Lornd University, Hungary*, vol. 24, no. 48, p. 7,
    2001.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] B. C. Csáji *等*，“使用人工神经网络的近似”，*匈牙利厄尔特大学科学学院*，第24卷，第48期，第7页，2001年。'
- en: '[97] Z. Zhang and M. Sabuncu, “Generalized cross entropy loss for training
    deep neural networks with noisy labels,” in *Proc. NeurIPS*, 2018, pp. 8778–8788.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] Z. Zhang 和 M. Sabuncu, “用于训练深度神经网络的广义交叉熵损失”，发表于 *Proc. NeurIPS*，2018年，第8778–8788页。'
- en: '[98] Y. Wang, X. Ma, Z. Chen, Y. Luo, J. Yi, and J. Bailey, “Symmetric cross
    entropy for robust learning with noisy labels,” in *Proc. ICCV*, 2019, pp. 322–330.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] Y. Wang, X. Ma, Z. Chen, Y. Luo, J. Yi, 和 J. Bailey, “用于鲁棒学习的对称交叉熵与噪声标签”，发表于
    *Proc. ICCV*，2019年，第322–330页。'
- en: '[99] Y. Lyu and I. W. Tsang, “Curriculum loss: Robust learning and generalization
    against label corruption,” in *Proc. ICLR*, 2020.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] Y. Lyu 和 I. W. Tsang, “课程损失：对标签污染的鲁棒学习和泛化”，发表于 *Proc. ICLR*，2020年。'
- en: '[100] L. Feng, S. Shu, Z. Lin, F. Lv, L. Li, and B. An, “Can cross entropy
    loss be robust to label noise,” in *Proc. IJCAI*, 2020, pp. 2206–2212.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] L. 冯，S. 舒，Z. 林，F. 吕，L. 李和B. 安，“交叉熵损失能对抗标签噪声吗”，*IJCAI会议论文集*，2020年，pp.
    2206-2212。'
- en: '[101] Y. Liu and H. Guo, “Peer loss functions: Learning from noisy labels without
    knowing noise rates,” in *Proc. ICML*, 2020, pp. 6226–6236.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] Y. 刘和H. 郭，“对等损失函数：在不了解噪声率的情况下从嘈杂标签中学习”，*ICML会议论文集*，2020年，pp. 6226-6236。'
- en: '[102] H. Kumar, N. Manwani, and P. Sastry, “Robust learning of multi-label
    classifiers under label noise,” in *Proc. CODS-COMAD*, 2020, pp. 90–97.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] H. 库马尔，N. 曼瓦尼和P. 萨斯特里，“标签噪声下多标签分类器的鲁棒学习”，*CODS-COMAD会议论文集*，2020年，pp.
    90-97。'
- en: '[103] E. Amid, M. K. Warmuth, and S. Srinivasan, “Two-temperature logistic
    regression based on the tsallis divergence,” in *Proc. AISTATS*, 2019, pp. 2388–2396.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] E. Amid，M. K. 沃默斯和S. 斯里尼瓦桑，“基于Tsallis散度的双温度逻辑回归”，*AISTATS会议论文集*，2019年，pp.
    2388-2396。'
- en: '[104] E. Amid, M. K. Warmuth, R. Anil, and T. Koren, “Robust bi-tempered logistic
    loss based on bregman divergences,” in *Proc. NeurIPS*, 2019, pp. 14 987–14 996.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] E. Amid，M. K. 沃默斯，R. 阿尼尔和T. 科伦，“基于Bregman散度的鲁棒双温度逻辑损失”，*NeurIPS会议论文集*，2019年，pp.
    14 987-14 996。'
- en: '[105] X. Ma, H. Huang, Y. Wang, S. Romano, S. Erfani, and J. Bailey, “Normalized
    loss functions for deep learning with noisy labels,” in *Proc. ICML*, 2020, pp.
    6543–6553.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] X. 马，H. 黄，Y. 王，S. 罗曼诺，S. 埃尔法尼和J. 贝利，“深度学习带有嘈杂标签的归一化损失函数”，*ICML会议论文集*，2020年，pp.
    6543-6553。'
- en: '[106] M. Ren, W. Zeng, B. Yang, and R. Urtasun, “Learning to reweight examples
    for robust deep learning,” in *Proc. ICML*, 2018.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] M. 任，W. 曾，B. 杨和R. 乌尔塔松，“学习重新加权示例以实现鲁棒的深度学习”，*ICML会议论文集*，2018年。'
- en: '[107] D. Hendrycks, M. Mazeika, D. Wilson, and K. Gimpel, “Using trusted data
    to train deep networks on labels corrupted by severe noise,” in *Proc. NeurIPS*,
    2018, pp. 10 456–10 465.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] D. 亨德里克斯，M. 马泽卡，D. 威尔逊和K. 吉姆佩尔，“利用受信任的数据在标签严重污损的情况下训练深度网络”，*NeurIPS会议论文集*，2018年，pp.
    10 456-10 465。'
- en: '[108] R. Wang, T. Liu, and D. Tao, “Multiclass learning with partially corrupted
    labels,” *IEEE Transactions on Neural Networks and Learning Systems*, vol. 29,
    no. 6, pp. 2568–2580, 2017.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] 王瑞，T. 刘和D. 陶，“带部分错误标签的多类学习”，《IEEE神经网络与学习系统交易》，第29卷，第6期，2017年，pp. 2568-2580。'
- en: '[109] H.-S. Chang, E. Learned-Miller, and A. McCallum, “Active Bias: Training
    more accurate neural networks by emphasizing high variance samples,” in *Proc.
    NeurIPS*, 2017, pp. 1002–1012.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] H.-S. 张，E. Learned-Miller和A. 麦卡勒姆，“主动偏差：通过强调高方差样本训练更准确的神经网络”，*NeurIPS会议论文集*，2017年，pp.
    1002-1012。'
- en: '[110] E. Arazo, D. Ortego, P. Albert, N. E. O’Connor, and K. McGuinness, “Unsupervised
    label noise modeling and loss correction,” in *Proc. ICML*, 2019.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] E. 阿拉佐，D. 奥尔特戈，P. 阿尔伯特，N. E. 奥康纳和K. 麦吉尼斯，“无监督标签噪声建模和损失修正”，*ICML会议论文集*，2019年。'
- en: '[111] X. Ma, Y. Wang, M. E. Houle, S. Zhou, S. M. Erfani, S.-T. Xia, S. Wijewickrema,
    and J. Bailey, “Dimensionality-driven learning with noisy labels,” in *Proc. ICML*,
    2018.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] X. 马，Y. 王，M. E. 侯勒，S. 周，S. M. 埃尔法尼，S.-T. 夏和S. Wijewickrema，“受维度驱动的嘈杂标签学习”，*ICML会议论文集*，2018年。'
- en: '[112] B. Han, Q. Yao, X. Yu, G. Niu, M. Xu, W. Hu, I. Tsang, and M. Sugiyama,
    “Co-teaching: Robust training of deep neural networks with extremely noisy labels,”
    in *Proc. NeurIPS*, 2018, pp. 8527–8537.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] B. 韩，Q. 姚，X. 余，G. 牛，M. 徐，W. 胡，I. 曾和M. 杉山，“共同教学：极端嘈杂标签下深度神经网络的稳健训练”，*NeurIPS会议论文集*，2018年，pp.
    8527-8537。'
- en: '[113] X. Xia, T. Liu, N. Wang, B. Han, C. Gong, G. Niu, and M. Sugiyama, “Are
    anchor points really indispensable in label-noise learning?” in *Proc. NeurIPS*,
    2019.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] X. 夏，T. 刘，N. 王，B. 韩，C. 龚，G. 牛和M. 杉山，“锚点在标签噪声学习中真的是不可或缺的吗？” *NeurIPS会议论文集*，2019年。'
- en: '[114] Y. Yao, T. Liu, B. Han, M. Gong, J. Deng, G. Niu, and M. Sugiyama, “Dual
    T: Reducing estimation error for transition matrix in label-noise learning,” in
    *Proc. NeurIPS*, 2020.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] Y. 姚，T. 刘，B. 韩，M. 龚，J. 邓，G. 牛和M. 杉山，“双T：减小标签噪声学习中转移矩阵估计误差”，*NeurIPS会议论文集*，2020年。'
- en: '[115] Y. Zhang and M. Sugiyama, “Approximating instance-dependent noise via
    instance-confidence embedding,” *arXiv preprint arXiv:2103.13569*, 2021.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] Y. 张和M. 杉山，“通过实例置信度嵌入近似实例相关噪声”，*arXiv预印本 arXiv:2103.13569*，2021年。'
- en: '[116] S. Yang, E. Yang, B. Han, Y. Liu, M. Xu, G. Niu, and T. Liu, “Estimating
    instance-dependent label-noise transition matrix using dnns,” *arXiv preprint
    arXiv:2105.13001*, 2021.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] S. 杨，E. 杨，B. 韩，Y. 刘，M. 徐，G. 牛和T. 刘，“使用DNNs估计实例相关标签噪声转换矩阵”，*arXiv预印本 arXiv:2105.13001*，2021年。'
- en: '[117] T. Liu and D. Tao, “Classification with noisy labels by importance reweighting,”
    *IEEE Transactions on Pattern Analysis and Machine Intelligence*, vol. 38, no. 3,
    pp. 447–461, 2015.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] T. Liu 和 D. Tao，“通过重要性重加权处理噪声标签的分类，” *IEEE Transactions on Pattern Analysis
    and Machine Intelligence*，第38卷，第3期，第447–461页，2015年。'
- en: '[118] H. Zhang, X. Xing, and L. Liu, “DualGraph: A graph-based method for reasoning
    about label noise,” in *Proc. CVPR*, 2021, pp. 9654–9663.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] H. Zhang, X. Xing, 和 L. Liu，“DualGraph: 一种用于推理标签噪声的基于图的方法，”见于 *Proc.
    CVPR*，2021年，第9654–9663页。'
- en: '[119] L. Huang, C. Zhang, and H. Zhang, “Self-adaptive training: beyond empirical
    risk minimization,” in *Proc. NeurIPS*, 2020.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] L. Huang, C. Zhang, 和 H. Zhang，“自适应训练：超越经验风险最小化，”见于 *Proc. NeurIPS*，2020年。'
- en: '[120] M. E. Houle, “Local intrinsic dimensionality I: An extreme-value-theoretic
    foundation for similarity applications,” in *Proc. SISAP*, 2017, pp. 64–79.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] M. E. Houle，“局部内在维度 I: 相似性应用的极值理论基础，”见于 *Proc. SISAP*，2017年，第64–79页。'
- en: '[121] S. Zheng, P. Wu, A. Goswami, M. Goswami, D. Metaxas, and C. Chen, “Error-bounded
    correction of noisy labels,” in *Proc. ICML*, 2020, pp. 11 447–11 457.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] S. Zheng, P. Wu, A. Goswami, M. Goswami, D. Metaxas, 和 C. Chen，“带误差界限的噪声标签修正，”见于
    *Proc. ICML*，2020年，第11 447–11 457页。'
- en: '[122] P. Chen, J. Ye, G. Chen, J. Zhao, and P.-A. Heng, “Beyond class-conditional
    assumption: A primary attempt to combat instance-dependent label noise,” in *Proc.
    AAAI*, 2021.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] P. Chen, J. Ye, G. Chen, J. Zhao, 和 P.-A. Heng，“超越类别条件假设：初步尝试对抗实例依赖的标签噪声，”见于
    *Proc. AAAI*，2021年。'
- en: '[123] C. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning for
    fast adaptation of deep networks,” in *Proc. ICML*, 2017, pp. 1126–1135.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] C. Finn, P. Abbeel, 和 S. Levine，“模型无关的元学习以快速适应深度网络，”见于 *Proc. ICML*，2017年，第1126–1135页。'
- en: '[124] J. Shu, Q. Xie, L. Yi, Q. Zhao, S. Zhou, Z. Xu, and D. Meng, “Meta-Weight-Net:
    Learning an explicit mapping for sample weighting,” in *Proc. NeurIPS*, 2019,
    pp. 1917–1928.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] J. Shu, Q. Xie, L. Yi, Q. Zhao, S. Zhou, Z. Xu, 和 D. Meng，“Meta-Weight-Net:
    学习样本加权的显式映射，”见于 *Proc. NeurIPS*，2019年，第1917–1928页。'
- en: '[125] Z. Wang, G. Hu, and Q. Hu, “Training noise-robust deep neural networks
    via meta-learning,” in *Proc. CVPR*, 2020, pp. 4524–4533.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] Z. Wang, G. Hu, 和 Q. Hu，“通过元学习训练抗噪声的深度神经网络，”见于 *Proc. CVPR*，2020年，第4524–4533页。'
- en: '[126] M. Dehghani, A. Severyn, S. Rothe, and J. Kamps, “Learning to learn from
    weak supervision by full supervision,” in *Proc. NeurIPSW*, 2017.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] M. Dehghani, A. Severyn, S. Rothe, 和 J. Kamps，“通过完全监督学习如何从弱监督中学习，”见于
    *Proc. NeurIPSW*，2017年。'
- en: '[127] ——, “Avoiding your teacher’s mistakes: Training neural networks with
    controlled weak supervision,” *arXiv preprint arXiv:1711.00313*, 2017.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] ——，“避免你老师的错误：用受控的弱监督训练神经网络，” *arXiv 预印本 arXiv:1711.00313*，2017年。'
- en: '[128] Z. Zhang, H. Zhang, S. O. Arik, H. Lee, and T. Pfister, “Distilling effective
    supervision from severe label noise,” in *Proc. CVPR*, 2020, pp. 9294–9303.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] Z. Zhang, H. Zhang, S. O. Arik, H. Lee, 和 T. Pfister，“从严重标签噪声中提炼有效监督，”见于
    *Proc. CVPR*，2020年，第9294–9303页。'
- en: '[129] Y. Li, J. Yang, Y. Song, L. Cao, J. Luo, and L.-J. Li, “Learning from
    noisy labels with distillation,” in *Proc. ICCV*, 2017, pp. 1910–1918.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] Y. Li, J. Yang, Y. Song, L. Cao, J. Luo, 和 L.-J. Li，“通过蒸馏从噪声标签中学习，”见于
    *Proc. ICCV*，2017年，第1910–1918页。'
- en: '[130] G. Zheng, A. H. Awadallah, and S. Dumais, “Meta label correction for
    noisy label learning,” in *Proc. AAAI*, 2021.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] G. Zheng, A. H. Awadallah, 和 S. Dumais，“用于噪声标签学习的元标签修正，”见于 *Proc. AAAI*，2021年。'
- en: '[131] L. Jiang, Z. Zhou, T. Leung, L.-J. Li, and L. Fei-Fei, “MentorNet: Learning
    data-driven curriculum for very deep neural networks on corrupted labels,” in
    *Proc. ICML*, 2018.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] L. Jiang, Z. Zhou, T. Leung, L.-J. Li, 和 L. Fei-Fei，“MentorNet: 针对损坏标签的非常深层神经网络学习数据驱动的课程，”见于
    *Proc. ICML*，2018年。'
- en: '[132] X. Yu, B. Han, J. Yao, G. Niu, I. W. Tsang, and M. Sugiyama, “How does
    disagreement help generalization against label corruption?” in *Proc. ICML*, 2019.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] X. Yu, B. Han, J. Yao, G. Niu, I. W. Tsang, 和 M. Sugiyama，“分歧如何帮助对抗标签腐败的泛化？”见于
    *Proc. ICML*，2019年。'
- en: '[133] Y. Wang, W. Liu, X. Ma, J. Bailey, H. Zha, L. Song, and S.-T. Xia, “Iterative
    learning with open-set noisy labels,” in *Proc. CVPR*, 2018, pp. 8688–8696.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] Y. Wang, W. Liu, X. Ma, J. Bailey, H. Zha, L. Song, 和 S.-T. Xia，“带开放集噪声标签的迭代学习，”见于
    *Proc. CVPR*，2018年，第8688–8696页。'
- en: '[134] Y. Shen and S. Sanghavi, “Learning with bad training data via iterative
    trimmed loss minimization,” in *Proc. ICML*, 2019.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] Y. Shen 和 S. Sanghavi，“通过迭代修剪损失最小化学习不良训练数据，”见于 *Proc. ICML*，2019年。'
- en: '[135] P. Chen, B. Liao, G. Chen, and S. Zhang, “Understanding and utilizing
    deep neural networks trained with noisy labels,” in *Proc. ICML*, 2019.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] P. Chen, B. Liao, G. Chen, 和 S. Zhang，“理解和利用用噪声标签训练的深度神经网络，”见于 *Proc.
    ICML*，2019年。'
- en: '[136] D. T. Nguyen, C. K. Mummadi, T. P. N. Ngo, T. H. P. Nguyen, L. Beggel,
    and T. Brox, “SELF: Learning to filter noisy labels with self-ensembling,” in
    *Proc. ICLR*, 2020.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] D. T. Nguyen, C. K. Mummadi, T. P. N. Ngo, T. H. P. Nguyen, L. Beggel,
    和 T. Brox，“SELF: 学习过滤噪声标签的自我集成，”发表于 *Proc. ICLR*，2020年。'
- en: '[137] H. Song, M. Kim, D. Park, Y. Shin, and J.-G. Lee, “Robust learning by
    self-transition for handling noisy labels,” in *KDD*, 2021.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] H. Song, M. Kim, D. Park, Y. Shin, 和 J.-G. Lee，“通过自我转换处理噪声标签的鲁棒学习，”发表于
    *KDD*，2021年。'
- en: '[138] D. Krueger, N. Ballas, S. Jastrzebski, D. Arpit, M. S. Kanwal, T. Maharaj,
    E. Bengio, A. Fischer, and A. Courville, “Deep nets don’t learn via memorization,”
    in *Proc. ICLRW*, 2017.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] D. Krueger, N. Ballas, S. Jastrzebski, D. Arpit, M. S. Kanwal, T. Maharaj,
    E. Bengio, A. Fischer, 和 A. Courville，“深度网络不会通过记忆来学习，”发表于 *Proc. ICLRW*，2017年。'
- en: '[139] C. Zhang, S. Bengio, M. Hardt, M. C. Mozer, and Y. Singer, “Identity
    Crisis: Memorization and generalization under extreme overparameterization,” in
    *Proc. ICLR*, 2020.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] C. Zhang, S. Bengio, M. Hardt, M. C. Mozer, 和 Y. Singer，“身份危机：极端过参数化下的记忆与泛化，”发表于
    *Proc. ICLR*，2020年。'
- en: '[140] Q. Yao, H. Yang, B. Han, G. Niu, and J. T.-Y. Kwok, “Searching to exploit
    memorization effect in learning with noisy labels,” in *Proc. ICML*, 2020, pp.
    10 789–10 798.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] Q. Yao, H. Yang, B. Han, G. Niu, 和 J. T.-Y. Kwok，“搜索利用记忆效应在噪声标签学习中的应用，”发表于
    *Proc. ICML*，2020年，第10 789–10 798页。'
- en: '[141] H. Song, M. Kim, D. Park, and J.-G. Lee, “How does early stopping help
    generalization against label noise?” *arXiv preprint arXiv:1911.08059*, 2019.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] H. Song, M. Kim, D. Park, 和 J.-G. Lee，“早期停止如何帮助对抗标签噪声的泛化？” *arXiv 预印本
    arXiv:1911.08059*，2019年。'
- en: '[142] J. Li, R. Socher, and S. C. Hoi, “DivideMix: Learning with noisy labels
    as semi-supervised learning,” in *Proc. ICLR*, 2020.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] J. Li, R. Socher, 和 S. C. Hoi，“DivideMix: 作为半监督学习的噪声标签学习，”发表于 *Proc.
    ICLR*，2020年。'
- en: '[143] H. Wei, L. Feng, X. Chen, and B. An, “Combating noisy labels by agreement:
    A joint training method with co-regularization,” in *Proc. CVPR*, 2020, pp. 13 726–13 735.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] H. Wei, L. Feng, X. Chen, 和 B. An，“通过一致性对抗噪声标签：一种具有协同正则化的联合训练方法，”发表于
    *Proc. CVPR*，2020年，第13 726–13 735页。'
- en: '[144] J. Huang, L. Qu, R. Jia, and B. Zhao, “O2U-Net: A simple noisy label
    detection approach for deep neural networks,” in *Proc. ICCV*, 2019, pp. 3326–3334.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] J. Huang, L. Qu, R. Jia, 和 B. Zhao，“O2U-Net: 一种用于深度神经网络的简单噪声标签检测方法，”发表于
    *Proc. ICCV*，2019年，第3326–3334页。'
- en: '[145] M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander, “LOF: Identifying
    density-based local outliers,” *ACM SIGMOD Record*, vol. 29, no. 2, pp. 93–104,
    2000.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] M. M. Breunig, H.-P. Kriegel, R. T. Ng, 和 J. Sander，“LOF: 识别基于密度的局部异常点，”
    *ACM SIGMOD Record*，第29卷，第2期，第93–104页，2000年。'
- en: '[146] P. Wu, S. Zheng, M. Goswami, D. Metaxas, and C. Chen, “A topological
    filter for learning with label noise,” in *Proc. NeurIPS*, 2020.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] P. Wu, S. Zheng, M. Goswami, D. Metaxas, 和 C. Chen，“用于学习标签噪声的拓扑过滤器，”发表于
    *Proc. NeurIPS*，2020年。'
- en: '[147] Z.-F. Wu, T. Wei, J. Jiang, C. Mao, M. Tang, and Y.-F. Li, “NGC: A unified
    framework for learning with open-world noisy data,” in *Proc. ICCV*, 2021, pp.
    62–71.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] Z.-F. Wu, T. Wei, J. Jiang, C. Mao, M. Tang, 和 Y.-F. Li，“NGC: 一个统一的开放世界噪声数据学习框架，”发表于
    *Proc. ICCV*，2021年，第62–71页。'
- en: '[148] A. Tarvainen and H. Valpola, “Mean teachers are better role models: Weight-averaged
    consistency targets improve semi-supervised deep learning results,” in *Proc.
    NeurIPS*, 2017, pp. 1195–1204.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] A. Tarvainen 和 H. Valpola，“均值教师更好的角色模型：加权平均一致性目标改善半监督深度学习结果，”发表于 *Proc.
    NeurIPS*，2017年，第1195–1204页。'
- en: '[149] D. Berthelot, N. Carlini, I. Goodfellow, N. Papernot, A. Oliver, and
    C. A. Raffel, “MixMatch: A holistic approach to semi-supervised learning,” in
    *Proc. NeurIPS*, 2019, pp. 5050–5060.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] D. Berthelot, N. Carlini, I. Goodfellow, N. Papernot, A. Oliver, 和 C.
    A. Raffel，“MixMatch: 一种全面的半监督学习方法，”发表于 *Proc. NeurIPS*，2019年，第5050–5060页。'
- en: '[150] T. Zhou, S. Wang, and J. Bilmes, “Robust curriculum learning: from clean
    label detection to noisy label self-correction,” in *Proc. ICLR*, 2021.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] T. Zhou, S. Wang, 和 J. Bilmes，“鲁棒的课程学习：从干净标签检测到噪声标签自我校正，”发表于 *Proc. ICLR*，2021年。'
- en: '[151] X. Li, T. Liu, B. Han, G. Niu, and M. Sugiyama, “Provably end-to-end
    label-noise learning without anchor points,” in *Proc. ICML*, 2021, pp. 6403–6413.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] X. Li, T. Liu, B. Han, G. Niu, 和 M. Sugiyama，“可证明的端到端标签噪声学习无需锚点，”发表于
    *Proc. ICML*，2021年，第6403–6413页。'
- en: '[152] G. Pleiss, T. Zhang, E. R. Elenberg, and K. Q. Weinberger, “Detecting
    noisy training data with loss curves,” 2020\. [Online]. Available: [https://openreview.net/forum?id=HyenUkrtDB](https://openreview.net/forum?id=HyenUkrtDB)'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] G. Pleiss, T. Zhang, E. R. Elenberg, 和 K. Q. Weinberger，“通过损失曲线检测噪声训练数据，”2020年。[在线]。可用：[https://openreview.net/forum?id=HyenUkrtDB](https://openreview.net/forum?id=HyenUkrtDB)'
- en: '[153] C. Scott, “A rate of convergence for mixture proportion estimation, with
    application to learning from noisy labels,” in *AISTATS*, 2015, pp. 838–846.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] C. Scott，“混合比例估计的收敛速度，及其在从噪声标签中学习的应用，”见于*AISTATS*，2015年，第838–846页。'
- en: '[154] Y. LeCun, C. Cortes, and C. J. Burges, “The MNIST database of handwritten
    digits, 1998,” *URL http://yann. lecun. com/exdb/mnist*, vol. 10, p. 34, 1998.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] Y. LeCun, C. Cortes, 和 C. J. Burges，“MNIST 手写数字数据库，1998年，”*URL http://yann.lecun.com/exdb/mnist*，第10卷，第34页，1998年。'
- en: '[155] H. Xiao, K. Rasul, and R. Vollgraf, “Fashion-MNIST: A novel image dataset
    for benchmarking machine learning algorithms,” *arXiv preprint arXiv:1708.07747*,
    2017.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] H. Xiao, K. Rasul, 和 R. Vollgraf，“Fashion-MNIST：一个用于基准测试机器学习算法的新型图像数据集，”*arXiv
    预印本 arXiv:1708.07747*，2017年。'
- en: '[156] A. Krizhevsky, V. Nair, and G. Hinton, “CIFAR-10 and CIFAR-100 datasets,”
    2014, [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html).'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] A. Krizhevsky, V. Nair, 和 G. Hinton，“CIFAR-10 和 CIFAR-100 数据集，”2014年，[https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)。'
- en: '[157] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng, “Reading
    digits in natural images with unsupervised feature learning,” in *Proc. NeurIPSW*,
    2011.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, 和 A. Y. Ng，“通过无监督特征学习在自然图像中读取数字，”见于*Proc.
    NeurIPSW*，2011。'
- en: '[158] A. Karpathy *et al.*, “Cs231n convolutional neural networks for visual
    recognition,” *Neural Networks*, vol. 1, p. 1, 2016.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] A. Karpathy *等*，“Cs231n 卷积神经网络用于视觉识别，”*神经网络*，第1卷，第1页，2016年。'
- en: '[159] J. Wei, Z. Zhu, H. Cheng, T. Liu, G. Niu, and Y. Liu, “Learning with
    noisy labels revisited: A study using real-world human annotations,” *arXiv preprint
    arXiv:2110.12088*, 2021.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[159] J. Wei, Z. Zhu, H. Cheng, T. Liu, G. Niu, 和 Y. Liu，“带噪声标签的学习重新审视：使用真实世界人类注释的研究，”*arXiv
    预印本 arXiv:2110.12088*，2021年。'
- en: '[160] L. Bossard, M. Guillaumin, and L. Van Gool, “Food-101–mining discriminative
    components with random forests,” in *Proc. ECCV*, 2014, pp. 446–461.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[160] L. Bossard, M. Guillaumin, 和 L. Van Gool，“Food-101–使用随机森林挖掘区分组件，”见于*Proc.
    ECCV*，2014年，第446–461页。'
- en: '[161] J. Bootkrajang and J. Chaijaruwanich, “Towards instance-dependent label
    noise-tolerant classification: a probabilistic approach,” *Pattern Analysis and
    Applications*, vol. 23, no. 1, pp. 95–111, 2020.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[161] J. Bootkrajang 和 J. Chaijaruwanich，“面向实例依赖标签噪声容忍分类：一种概率方法，”*模式分析与应用*，第23卷，第1期，第95–111页，2020年。'
- en: '[162] G. Tsoumakas and I. Katakis, “Multi-label classification: An overview,”
    *International Journal of Data Warehousing and Mining*, vol. 3, no. 3, pp. 1–13,
    2007.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[162] G. Tsoumakas 和 I. Katakis，“多标签分类：概述，”*国际数据仓库与挖掘杂志*，第3卷，第3期，第1–13页，2007年。'
- en: '[163] M. R. Boutell, J. Luo, X. Shen, and C. M. Brown, “Learning multi-label
    scene classification,” *Pattern Recognition*, vol. 37, no. 9, pp. 1757–1771, 2004.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[163] M. R. Boutell, J. Luo, X. Shen, 和 C. M. Brown，“学习多标签场景分类，”*模式识别*，第37卷，第9期，第1757–1771页，2004年。'
- en: '[164] I. Krasin, T. Duerig, N. Alldrin, V. Ferrari, S. Abu-El-Haija, A. Kuznetsova,
    H. Rom, J. Uijlings, S. Popov, A. Veit *et al.*, “OpenImages: A public dataset
    for large-scale multi-label and multi-class image classification,” *Dataset available
    from https://github. com/openimages*, vol. 2, no. 3, p. 18, 2017.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[164] I. Krasin, T. Duerig, N. Alldrin, V. Ferrari, S. Abu-El-Haija, A. Kuznetsova,
    H. Rom, J. Uijlings, S. Popov, A. Veit *等*，“OpenImages：一个用于大规模多标签和多类别图像分类的公共数据集，”*数据集可从
    https://github.com/openimages 获取*，第2卷，第3期，第18页，2017年。'
- en: '[165] W. Zhao and C. Gomes, “Evaluating multi-label classifiers with noisy
    labels,” *arXiv preprint arXiv:2102.08427*, 2021.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[165] W. Zhao 和 C. Gomes，“评估带噪声标签的多标签分类器，”*arXiv 预印本 arXiv:2102.08427*，2021年。'
- en: '[166] J. M. Johnson and T. M. Khoshgoftaar, “Survey on deep learning with class
    imbalance,” *Journal of Big Data*, vol. 6, no. 1, pp. 1–54, 2019.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[166] J. M. Johnson 和 T. M. Khoshgoftaar，“关于类不平衡的深度学习调查，”*大数据杂志*，第6卷，第1期，第1–54页，2019年。'
- en: '[167] M. Hardt, E. Price, and N. Srebro, “Equality of opportunity in supervised
    learning,” in *Proc. NeurIPS*, 2016.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[167] M. Hardt, E. Price, 和 N. Srebro，“监督学习中的机会平等，”见于*Proc. NeurIPS*，2016年。'
- en: '[168] H. Jiang and O. Nachum, “Identifying and correcting label bias in machine
    learning,” in *Proc. AISTATS*, 2020, pp. 702–712.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[168] H. Jiang 和 O. Nachum，“识别和纠正机器学习中的标签偏差，”见于*Proc. AISTATS*，2020年，第702–712页。'
- en: '[169] S. Wang, W. Guo, H. Narasimhan, A. Cotter, M. Gupta, and M. I. Jordan,
    “Robust optimization for fairness with noisy protected groups,” in *Proc. NeurIPS*,
    2020.'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[169] S. Wang, W. Guo, H. Narasimhan, A. Cotter, M. Gupta, 和 M. I. Jordan，“针对噪声保护组的公平性鲁棒优化，”见于*Proc.
    NeurIPS*，2020年。'
- en: '[170] J. Wang, Y. Liu, and C. Levy, “Fair classification with group-dependent
    label noise,” in *Proc. FAccT*, 2021, pp. 526–536.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[170] J. Wang, Y. Liu, 和 C. Levy，“带组依赖标签噪声的公平分类，”见于*Proc. FAccT*，2021年，第526–536页。'
- en: '[171] J. Uesato, J.-B. Alayrac, P.-S. Huang, R. Stanforth, A. Fawzi, and P. Kohli,
    “Are labels required for improving adversarial robustness?” in *Proc. NeurIPS*,
    2019, pp. 12 192–12 202.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[171] J. Uesato, J.-B. Alayrac, P.-S. Huang, R. Stanforth, A. Fawzi, 和 P. Kohli,
    “改善对抗性鲁棒性是否需要标签？”发表于*NeurIPS会议录*，2019年，第12 192–12 202页。'
- en: '[172] B. B. Damodaran, K. Fatras, S. Lobry, R. Flamary, D. Tuia, and N. Courty,
    “Wasserstein adversarial regularization (WAR) on label noise,” in *Proc. ICLR*,
    2020.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[172] B. B. Damodaran, K. Fatras, S. Lobry, R. Flamary, D. Tuia, 和 N. Courty,
    “标签噪声上的Wasserstein对抗正则化（WAR）”，发表于*ICLR会议录*，2020年。'
- en: '[173] J. Zhu, J. Zhang, B. Han, T. Liu, G. Niu, H. Yang, M. Kankanhalli, and
    M. Sugiyama, “Understanding the interaction of adversarial training with noisy
    labels,” *arXiv preprint arXiv:2102.03482*, 2021.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[173] J. Zhu, J. Zhang, B. Han, T. Liu, G. Niu, H. Yang, M. Kankanhalli, 和
    M. Sugiyama, “理解对抗训练与噪声标签的交互”，*arXiv预印本arXiv:2102.03482*，2021年。'
- en: '[174] G. Nguyen, S. Dlugolinsky, M. Bobák, V. Tran, Á. L. García, I. Heredia,
    P. Malík, and L. Hluchỳ, “Machine learning and deep learning frameworks and libraries
    for large-scale data mining: a survey,” *Artificial Intelligence Review*, vol. 52,
    no. 1, pp. 77–124, 2019.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[174] G. Nguyen, S. Dlugolinsky, M. Bobák, V. Tran, Á. L. García, I. Heredia,
    P. Malík, 和 L. Hluchỳ, “大规模数据挖掘的机器学习和深度学习框架及库：综述”，*人工智能评论*，第52卷，第1期，第77–124页，2019年。'
- en: Acknowledgements
  id: totrans-540
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: 'This work was supported by Institute of Information & Communications Technology
    Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No.
    2020-0-00862, DB4DL: High-Usability and Performance In-Memory Distributed DBMS
    for Deep Learning).'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了由韩国政府（MSIT）资助的[信息与通信技术规划与评估院（IITP）](https://example.org)资助（编号：2020-0-00862，DB4DL：用于深度学习的高可用性和性能的内存分布式DBMS）。
