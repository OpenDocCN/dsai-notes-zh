- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:52:03'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:52:03
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2108.08876] Deep Learning-based Spacecraft Relative Navigation Methods: A
    Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2108.08876] 基于深度学习的航天器相对导航方法：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2108.08876](https://ar5iv.labs.arxiv.org/html/2108.08876)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2108.08876](https://ar5iv.labs.arxiv.org/html/2108.08876)
- en: 'Deep Learning-based Spacecraft Relative Navigation Methods: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于深度学习的航天器相对导航方法：综述
- en: Jianing Song¹¹1Equal contribution²²2Postdoctoral Research Fellow, Department
    of Electrical and Electronic Engineering [jianing.song@city.ac.uk](mailto:jianing.song@city.ac.uk)
    Duarte Rondao³³3Equal contribution⁴⁴4Postdoctoral Research Fellow, Department
    of Electrical and Electronic Engineering [duarte.rondao@city.ac.uk](mailto:duarte.rondao@city.ac.uk)
    Nabil Aouf⁵⁵5Professor of Robotics and Autonomous Systems, Department of Electrical
    and Electronic Engineering [nabil.aouf@city.ac.uk](mailto:nabil.aouf@city.ac.uk)
    City, University of London, ECV1 0HB London, United Kingdom
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**蒋宁**¹¹1等贡献²²2电子与电气工程系博士后研究员 [jianing.song@city.ac.uk](mailto:jianing.song@city.ac.uk)
    **杜阿特·朗道**³³3等贡献⁴⁴4电子与电气工程系博士后研究员 [duarte.rondao@city.ac.uk](mailto:duarte.rondao@city.ac.uk)
    **纳比尔·奥夫**⁵⁵5机器人与自主系统教授，电子与电气工程系 [nabil.aouf@city.ac.uk](mailto:nabil.aouf@city.ac.uk)
    伦敦城市大学，ECV1 0HB 伦敦，英国'
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Autonomous spacecraft relative navigation technology has been planned for and
    applied to many famous space missions. The development of on-board electronics
    systems has enabled the use of vision-based and LiDAR-based methods to achieve
    better performances. Meanwhile, deep learning has reached great success in different
    areas, especially in computer vision, which has also attracted the attention of
    space researchers. However, spacecraft navigation differs from ground tasks due
    to high reliability requirements but lack of large datasets. This survey aims
    to systematically investigate the current deep learning-based autonomous spacecraft
    relative navigation methods, focusing on concrete orbital applications such as
    spacecraft rendezvous and landing on small bodies or the Moon. The fundamental
    characteristics, primary motivations, and contributions of deep learning-based
    relative navigation algorithms are first summarised from three perspectives of
    spacecraft rendezvous, asteroid exploration, and terrain navigation. Furthermore,
    popular visual tracking benchmarks and their respective properties are compared
    and summarised. Finally, potential applications are discussed, along with expected
    impediments.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 自主航天器相对导航技术已被计划并应用于许多著名的太空任务。机载电子系统的发展使得基于视觉和激光雷达的方法能够实现更好的性能。同时，深度学习在不同领域取得了巨大成功，特别是在计算机视觉领域，这也引起了空间研究人员的关注。然而，航天器导航与地面任务不同，由于对高可靠性的要求而缺乏大规模数据集。这项综述旨在系统地调查当前基于深度学习的自主航天器相对导航方法，重点关注具体的轨道应用，如航天器对接和在小天体或月球上的着陆。首先，从航天器对接、小行星探索和地形导航三个角度总结了基于深度学习的相对导航算法的基本特征、主要动机和贡献。此外，还比较和总结了流行的视觉跟踪基准及其各自的特性。最后，讨论了潜在的应用和预期的障碍。
- en: 'keywords:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: 'Deep learning , Space relative navigation , Terrain navigation , Asteroid exploration^†^†journal:
    Acta Astronautica\setabbreviationstyle'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习，空间相对导航，地形导航，小行星探索^†^†期刊：Acta Astronautica\setabbreviationstyle
- en: '[acronym]long-postshort-user \glssetcategoryattributeacronymnohyperfirsttrue
    \DTMusemodulebritishen-GB'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[acronym]long-postshort-user \glssetcategoryattributeacronymnohyperfirsttrue
    \DTMusemodulebritishen-GB'
- en: Glossary
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 术语表
- en: 2D
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 2D
- en: two-dimensional
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 二维
- en: 3D
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 3D
- en: three-dimensional
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 三维
- en: AI
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: AI
- en: Artificial Intelligence
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能
- en: ALHAT
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ALHAT
- en: Autonomous Landing Hazard Avoidance Technology
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 自主着陆危险规避技术
- en: ANN
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ANN
- en: Artificial Neural Network
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络
- en: BCE
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: BCE
- en: Binary Cross-Entropy
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制交叉熵
- en: CD
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: CD
- en: Crater Detection
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 陨石坑检测
- en: CI
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: CI
- en: Crater Identification
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 陨石坑识别
- en: CL
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: CL
- en: Convolutional Layer
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层
- en: CNN
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: CNN
- en: Convolutional Neural Network
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: COCO
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: COCO
- en: Common Objects in Context
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文中的常见物体
- en: CRO
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: CRO
- en: Candidate for a Regional Object
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 区域物体候选
- en: DEM
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: DEM
- en: Digital Elevation Map
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数字高程图
- en: DL
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: DL
- en: Deep Learning
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习
- en: DNN
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: DNN
- en: Deep Neural Network
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络
- en: DoF
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: DoF
- en: Degree-of-Freedom
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 自由度
- en: DRCNN
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: DRCNN
- en: Deep Recurrent Convolutional Neural Network
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 深度递归卷积神经网络
- en: EKF
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: EKF
- en: Extended Kalman Filter
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展卡尔曼滤波器
- en: ESA
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ESA
- en: European Space Agency
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 欧洲航天局
- en: FCL
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: FCL
- en: Fully Connected Layer
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 全连接层
- en: FPGA
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: FPGA
- en: Field-Programmable Gate Array
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 可编程逻辑阵列
- en: GPOPS II
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: GPOPS II
- en: General Purpose Optimal Control Software
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通用最优控制软件
- en: HDA
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: HDA
- en: Hazard Detection and Avoidance
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 危险检测与避免
- en: HRNet
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: HRNet
- en: High-Resolution Net
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 高分辨率网络
- en: ICP
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ICP
- en: Iterative Closest Point
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代最近点
- en: KPEC
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: KPEC
- en: Kelvins Pose Estimation Challenge
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Kelvin姿态估计挑战
- en: KRN
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: KRN
- en: Keypoint Regression Network
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点回归网络
- en: LCLF
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: LCLF
- en: Lunar-Centred, Lunar-Fixed Coordinates
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以月球为中心、固定月球坐标
- en: LoG
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: LoG
- en: Laplacian of Gaussian
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯拉普拉斯
- en: LRO
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: LRO
- en: Lunar Reconnaissance Orbiter
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 月球 reconnaissance 卫星
- en: LSTM
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM
- en: Long Short-Term Memory
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 长短期记忆
- en: LVLH
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: LVLH
- en: Local-Vertical, Local-Horizontal
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 本地垂直、本地水平
- en: ML
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ML
- en: Machine Learning
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习
- en: MLP
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: MLP
- en: Multilayer Perceptron
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 多层感知器
- en: MSE
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 均方误差
- en: Mean Square Error
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 均方误差
- en: NASA
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: NASA
- en: National Aeronautics and Space Administration
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 美国国家航空航天局
- en: NEA
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: NEA
- en: Near-Earth Asteroid
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 近地小行星
- en: NN
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: NN
- en: Neural Network
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络
- en: ODN
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ODN
- en: Object Detection Network
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 目标检测网络
- en: PDS
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: PDS
- en: Planetary Data System
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 行星数据系统
- en: P$n$P
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: P$n$P
- en: Perspective-n-Point
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 透视-n-点
- en: PyCDA
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: PyCDA
- en: Python Crater Detection Algorithm
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Python 陨石坑检测算法
- en: RANSAC
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: RANSAC
- en: Random Sample Consensus
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 随机样本一致性
- en: R-CNN
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: R-CNN
- en: Region-based Convolutional Neural Network
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 基于区域的卷积神经网络
- en: RGB
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: RGB
- en: Red-Green-Blue
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 红绿蓝
- en: RMSE
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 均方根误差
- en: Root Mean Square Error
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 均方根误差
- en: RNN
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: RNN
- en: Recurrent Neural Network
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: RoI
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: RoI
- en: Region of Interest
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 关注区域
- en: RPN
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: RPN
- en: Region Proposal Network
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 区域建议网络
- en: S/C
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: S/C
- en: spacecraft
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 航天器
- en: SoC
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: SoC
- en: System-on-a-Chip
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 芯片系统
- en: SPEED
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: SPEED
- en: Spacecraft Pose Estimation Dataset
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 航天器姿态估计数据集
- en: SPN
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: SPN
- en: Spacecraft Pose Network
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 航天器姿态网络
- en: TRN
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: TRN
- en: Terrain Relative Navigation
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 地形相对导航
- en: URSO
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: URSO
- en: Unreal Rendered Spacecraft On-Orbit
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 虚幻渲染的在轨航天器
- en: VO
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: VO
- en: Visual Odometry
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉里程计
- en: WAC
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: WAC
- en: Wide Angle Camera
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 广角相机
- en: 1 Introduction
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'In recent years, there has been a growing interest in [Artificial Intelligence
    (AI)](#glo.main.ai), [Machine Learning (ML)](#glo.main.ml), and [Deep Learning
    (DL)](#glo.main.dl), especially amongst science, technology, engineering, and
    mathematics disciplines. There have been several approaches to define [AI](#glo.main.ai)
    historically; the most common refers to techniques enabling machines to mimic
    human intelligence. Then, [ML](#glo.main.ml) is the key component responsible
    for automatically processing data inside an [AI](#glo.main.ai). A [Neural Network
    (NN)](#glo.main.nn) is a specific [ML](#glo.main.ml) model aiming to approximate
    a certain function $f^{\ast}$ relating training examples ${\bm{x}}$ to labels
    $y$ by defining a mapping $y=f({\bm{x}},{\bm{\theta}})$ and learning the ${\bm{\theta}}^{\ast}$
    parameters that result in the best approximation. [NNs](#glo.main.nn) work by
    stacking many different functions, called layers, and the number of layers defines
    the depth of the [NN](#glo.main.nn). The term [DL](#glo.main.dl) derives from
    this wording, typically signifying a [NN](#glo.main.nn) with large depth [[1](#bib.bib1)].
    A rough relationship among these three concepts is summarised and illustrated
    in Fig. [7](#footnote7 "footnote 7 ‣ Figure 1 ‣ 1 Introduction ‣ Deep Learning-based
    Spacecraft Relative Navigation Methods: A Survey").'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '近年来，[人工智能（AI）](#glo.main.ai)、[机器学习（ML）](#glo.main.ml)和[深度学习（DL）](#glo.main.dl)在科学、技术、工程和数学学科中引起了越来越多的关注。历史上对[AI](#glo.main.ai)的定义有多种方法；最常见的定义是指能够使机器模拟人类智能的技术。接着，[ML](#glo.main.ml)是负责在[AI](#glo.main.ai)内部自动处理数据的关键组件。[神经网络（NN）](#glo.main.nn)是一个特定的[ML](#glo.main.ml)模型，旨在通过定义映射$y=f({\bm{x}},{\bm{\theta}})$并学习${\bm{\theta}}^{\ast}$参数来近似某个函数$f^{\ast}$，将训练示例${\bm{x}}$与标签$y$相关联。[NNs](#glo.main.nn)通过堆叠多个不同的函数（称为层）来工作，层的数量定义了[NN](#glo.main.nn)的深度。[DL](#glo.main.dl)一词源于此，通常表示具有大深度的[NN](#glo.main.nn)
    [[1](#bib.bib1)]。这三个概念之间的粗略关系在图[7](#footnote7 "footnote 7 ‣ Figure 1 ‣ 1 Introduction
    ‣ Deep Learning-based Spacecraft Relative Navigation Methods: A Survey")中总结并说明。'
- en: 'In the field of space exploration, autonomous vision-based [spacecraft (S/C)](#glo.main.sc)
    navigation is one key area with the potential of greatly benefiting from \glsxtrshortdnn-based
    (\glsxtrlong*dnn) estimation methods. Cameras are rapidly becoming the preferred
    sensor for autonomous rendezvous thanks to the introduction of compact and lightweight
    passive optical sensors as feasible onboard instruments [[2](#bib.bib2)]. Additionally,
    vision-based techniques have been used in-flight for deep space navigation tasks
    [[3](#bib.bib3)]. Potential future applications of domains include: 1) non-cooperative
    rendezvous with a spacecraft; 2) terrain navigation for descent and landing; and
    3) asteroid explorations and asteroid patch pinpoint localisation.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在空间探索领域，基于视觉的[航天器（S/C）](#glo.main.sc)自主导航是一个关键领域，具有从 \glsxtrshortdnn（\glsxtrlong*dnn）估计方法中极大受益的潜力。由于紧凑且轻便的被动光学传感器作为可行的机载仪器的引入，摄像头正在迅速成为自主交会的首选传感器[[2](#bib.bib2)]。此外，视觉技术已经在飞行中用于深空导航任务[[3](#bib.bib3)]。未来潜在的应用领域包括：1)
    与航天器的非合作交会；2) 降落和着陆的地形导航；以及 3) 小行星探测和小行星补丁定位。
- en: '![Refer to caption](img/b9501a22acbe0b2f5860b723973f5069.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b9501a22acbe0b2f5860b723973f5069.png)'
- en: 'Figure 1: Relationship between [AI](#glo.main.ai), [ML](#glo.main.ml) and [DL](#glo.main.dl)
    (reproduced from Mathworks.⁷⁷7[https://explore.mathworks.com/machine-learning-vs-deep-learning/chapter-1-129M-833I7.html](https://explore.mathworks.com/machine-learning-vs-deep-learning/chapter-1-129M-833I7.html).)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: [AI](#glo.main.ai)、[ML](#glo.main.ml) 和 [DL](#glo.main.dl) 之间的关系（转载自 Mathworks.⁷⁷7[https://explore.mathworks.com/machine-learning-vs-deep-learning/chapter-1-129M-833I7.html](https://explore.mathworks.com/machine-learning-vs-deep-learning/chapter-1-129M-833I7.html)）。'
- en: 'All of these scenarios involve the estimation of a chaser or lander spacecraft’s
    relative state, typically through the six [Degree-of-Freedom (DoF)](#glo.main.dof)
    pose ${\bm{T}}_{ct}$ of the target object frame $\underaccent{\vec{}}{\bm{\mathcal{F}}}_{t}$
    relative to the chaser frame $\underaccent{\vec{}}{\bm{\mathcal{F}}}_{c}$, composed
    of a rotation ${\bm{R}}_{ct}$, and a translation $\prescript{c}{}{{\bm{t}}}_{ct}$
    (see Fig. [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Deep Learning-based Spacecraft
    Relative Navigation Methods: A Survey")). Pose estimation methods have traditionally
    worked by relating features of the target (expressed in $\underaccent{\vec{}}{\bm{\mathcal{F}}}_{t}$),
    typically obtained from a model, to their images captured by the onboard camera
    (expressed in $\underaccent{\vec{}}{\bm{\mathcal{F}}}_{c}$), whereas using [DNN](#glo.main.dnn)
    models would adequately capture the intrinsic nonlinearities between the input
    sensor data and the state estimates, especially for images or [Digital Elevation
    Maps (DEMs)](#glo.main.dem).'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '所有这些场景都涉及对追踪器或着陆器航天器的相对状态进行估计，通常通过目标物体框架$\underaccent{\vec{}}{\bm{\mathcal{F}}}_{t}$相对于追踪器框架$\underaccent{\vec{}}{\bm{\mathcal{F}}}_{c}$的六个[自由度（DoF）](#glo.main.dof)位姿${\bm{T}}_{ct}$来进行，其中包括旋转${\bm{R}}_{ct}$和平移$\prescript{c}{}{{\bm{t}}}_{ct}$（见图 [2](#S1.F2
    "Figure 2 ‣ 1 Introduction ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey")）。传统的位姿估计方法通过将目标（在$\underaccent{\vec{}}{\bm{\mathcal{F}}}_{t}$中表达）特征与由机载摄像头捕获的图像（在$\underaccent{\vec{}}{\bm{\mathcal{F}}}_{c}$中表达）进行关联来工作，而使用[DNN](#glo.main.dnn)模型可以充分捕捉输入传感器数据与状态估计之间的内在非线性，尤其适用于图像或[数字高程图（DEMs）](#glo.main.dem)。'
- en: '![Refer to caption](img/6c619fa8453a8933de24dbfaa5e5bc7a.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6c619fa8453a8933de24dbfaa5e5bc7a.png)'
- en: (a) Rendezvous with non-cooperative spacecraft
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 与非合作航天器的交会
- en: '![Refer to caption](img/fffcc6314257398bd341bfe04f501ced.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/fffcc6314257398bd341bfe04f501ced.png)'
- en: (b) Asteroid pinpointing via patch classification
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 通过补丁分类进行的小行星定位
- en: '![Refer to caption](img/2e4a253d6fe1a6510ea04c60a8a65c0a.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2e4a253d6fe1a6510ea04c60a8a65c0a.png)'
- en: (c) Terrain navigation
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 地形导航
- en: 'Figure 2: Identification of potential relative navigation scenarios for the
    application of \Glsxtrshortpldnn.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: 应用 \Glsxtrshortpldnn 的潜在相对导航场景识别。'
- en: Previous studies have approached the topic of [DL](#glo.main.dl)-based navigation
    for space. Kothari et al. [[4](#bib.bib4)] collated various applications of [DL](#glo.main.dl)
    for space, briefly discussing the achieved and prospective goals of onboard systems
    for spacecraft positioning during docking and landing. Aiming at non-cooperative
    spacecraft rendezvous specifically, Cassinis et al. [[5](#bib.bib5)] first provided
    a review of \glsxtrshortcnn-based (\glsxtrlong*cnn) schemes in the context of
    monocular pose estimation systems discussing in detail several works (e.g.  [[6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8)]).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以往的研究探讨了基于[DL](#glo.main.dl)的太空导航主题。Kothari等人[[4](#bib.bib4)]整理了基于[DL](#glo.main.dl)在太空中的各种应用，简要讨论了航天器对接和着陆过程中实现的和预期的目标。专门针对非合作航天器会合，Cassinis等人[[5](#bib.bib5)]首先提供了\glsxtrshortcnn-based（\glsxtrlong*cnn）方案在单目姿态估计系统中的综述，详细讨论了几项工作（例如[[6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8)]）。
- en: '![Refer to caption](img/8a53f953f610c5234c599fddedc54a2e.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/8a53f953f610c5234c599fddedc54a2e.png)'
- en: 'Figure 3: The tree diagram of [DL](#glo.main.dl)-based [S/C](#glo.main.sc)
    relative navigation approaches reviewed in this paper. The boxes in yellow, blue,
    and white represent applications, methods, and candidate references, respectively.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 本文回顾的基于[DL](#glo.main.dl)的[S/C](#glo.main.sc)相对导航方法的树状图。黄色、蓝色和白色的框分别表示应用、方法和候选参考文献。'
- en: 'However, there is a shortage of comparative analysis of [DL](#glo.main.dl)
    methods for general relative navigation in space. With this survey, we thus intend
    to bridge this gap and provide a comprehensive reference for researchers and engineers
    aspiring to leverage deep learning for this subject, specifically for the three
    main applications identified in Fig. [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Deep
    Learning-based Spacecraft Relative Navigation Methods: A Survey"). Fig. [3](#S1.F3
    "Figure 3 ‣ 1 Introduction ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey") shows the set of research methods and application domains
    covered by our survey. In Fig. [3](#S1.F3 "Figure 3 ‣ 1 Introduction ‣ Deep Learning-based
    Spacecraft Relative Navigation Methods: A Survey"), direct [DNN](#glo.main.dnn)
    methods are end-to-end methods using [DNNs](#glo.main.dnn), which constitute a
    direct, uninterrupted pipeline from inputs $x$ to the desired quantity to estimate
    $y$. In contrast, indirect [DNN](#glo.main.dnn) methods are those in which the
    [DNN](#glo.main.dnn) is exclusively tasked with performing the image processing
    functions on the input, while the actual quantity to be estimated is achieved
    by combining this output with other methods, such as classical ML, geometry-based
    optimisation, and Kalman filtering.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '然而，针对一般太空相对导航的[DL](#glo.main.dl)方法的比较分析仍然不足。通过本次调查，我们旨在弥补这一差距，并为希望利用深度学习进行这一研究的研究人员和工程师提供全面参考，特别是针对图[2](#S1.F2
    "图 2 ‣ 1 引言 ‣ 基于深度学习的航天器相对导航方法: 综述")中识别的三种主要应用。图[3](#S1.F3 "图 3 ‣ 1 引言 ‣ 基于深度学习的航天器相对导航方法:
    综述")展示了我们调查涵盖的研究方法和应用领域。在图[3](#S1.F3 "图 3 ‣ 1 引言 ‣ 基于深度学习的航天器相对导航方法: 综述")中，直接[DNN](#glo.main.dnn)方法是使用[DNNs](#glo.main.dnn)的端到端方法，它们构成了从输入$x$到期望量$y$的直接、不间断的管道。相比之下，间接[DNN](#glo.main.dnn)方法是指[DNN](#glo.main.dnn)专门负责对输入进行图像处理，而实际要估计的量则通过将此输出与其他方法（如经典ML、基于几何的优化和卡尔曼滤波）结合来实现。'
- en: 'This paper is organized as follows. Section [2](#S2 "2 \glsfmtshortdl-based
    Pose Estimation for Spacecraft Relative Navigation ‣ Deep Learning-based Spacecraft
    Relative Navigation Methods: A Survey") presents a review of [DL](#glo.main.dl)-based
    pose estimation algorithms for spacecraft rendezvous. Section [3](#S3 "3 Crater
    and Hazard Detection for Terrain Navigation Using \glsfmtshortdl ‣ Deep Learning-based
    Spacecraft Relative Navigation Methods: A Survey") contains a detailed review
    of crater and hazard detection of [Terrain Relative Navigation (TRN)](#glo.main.trn)
    using [DNNs](#glo.main.dnn). Section [4](#S4 "4 \glsfmtshortdl-based Relative
    Navigation for Asteroid Research ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey") provides a review of [DL](#glo.main.dl) techniques with a
    focus on asteroid exploration. Finally, Section [5](#S5 "5 Summary and Conclusion
    ‣ Deep Learning-based Spacecraft Relative Navigation Methods: A Survey") lists
    the main conclusions and discussions.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '本文组织结构如下。第 [2](#S2 "2 \glsfmtshortdl-based Pose Estimation for Spacecraft Relative
    Navigation ‣ Deep Learning-based Spacecraft Relative Navigation Methods: A Survey")
    节回顾了 [DL](#glo.main.dl) 基于的航天器交会姿态估计算法。第 [3](#S3 "3 Crater and Hazard Detection
    for Terrain Navigation Using \glsfmtshortdl ‣ Deep Learning-based Spacecraft Relative
    Navigation Methods: A Survey") 节包含了使用 [DNNs](#glo.main.dnn) 的 [Terrain Relative
    Navigation (TRN)](#glo.main.trn) 的陨石坑和危险检测的详细回顾。第 [4](#S4 "4 \glsfmtshortdl-based
    Relative Navigation for Asteroid Research ‣ Deep Learning-based Spacecraft Relative
    Navigation Methods: A Survey") 节提供了针对小行星探测的 [DL](#glo.main.dl) 技术的回顾。最后，第 [5](#S5
    "5 Summary and Conclusion ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey") 节列出了主要的结论和讨论。'
- en: 2 \glsfmtshortdl-based Pose Estimation for Spacecraft Relative Navigation
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 \glsfmtshortdl 基于的航天器相对导航姿态估计
- en: 2.1 Related Works on Terrestrial Pose Estimation
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 地面姿态估计的相关工作
- en: With the successful application of deep learning approaches in various research
    areas, \glsxtrshortdl-based camera-relative pose determination techniques for
    terrestrial scenarios have been attracting a considerable amount of interest.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习方法在各个研究领域的成功应用，基于 \glsxtrshortdl 的相机相对姿态确定技术在地面场景中引起了相当大的关注。
- en: Kendall et al. [[9](#bib.bib9)] proposed the PoseNet architecture for 6-[DoF](#glo.main.dof)
    motion estimation in an end-to-end manner. To develop the pose regression network,
    they used a modified pre-trained GoogLeNet [[10](#bib.bib10)] by replacing all
    softmax classifiers with affine regressor. A weighted sum of the $L^{2}$ error
    norms of the position vector and the attitude quaternion is selected as the loss
    function for better training of the location and orientation simultaneously. Their
    results demonstrate a $2\text{\,}\mathrm{m}$ and $3\text{\,}\mathrm{d}\mathrm{e}\mathrm{g}$
    accuracy for large scale outdoor scenes and $0.5\text{\,}\mathrm{m}$ and $5\text{\,}\mathrm{d}\mathrm{e}\mathrm{g}$
    accuracy indoors.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Kendall 等人 [[9](#bib.bib9)] 提出了 PoseNet 架构用于 6-[DoF](#glo.main.dof) 运动估计，采用端到端的方法。为了开发姿态回归网络，他们使用了经过修改的预训练
    GoogLeNet [[10](#bib.bib10)]，将所有 softmax 分类器替换为仿射回归器。选择位置向量和姿态四元数的 $L^{2}$ 误差范数的加权和作为损失函数，以更好地同时训练位置和方向。他们的结果表明，对于大规模户外场景，精度为
    $2\text{\,}\mathrm{m}$ 和 $3\text{\,}\mathrm{d}\mathrm{e}\mathrm{g}$，对于室内环境，精度为
    $0.5\text{\,}\mathrm{m}$ 和 $5\text{\,}\mathrm{d}\mathrm{e}\mathrm{g}$。
- en: Rather than self-localising with respect to a known world model, Wang et al.
    [[11](#bib.bib11)] presented the DeepVO architecture to obtain a vehicle’s egomotion
    from frame to frame based on monocular [Visual Odometry (VO)](#glo.main.vo). The
    pipeline follows the architecture of a [Deep Recurrent Convolutional Neural Network
    (DRCNN)](#glo.main.drcnn) [[12](#bib.bib12)], in which a pre-trained FlowNet [[13](#bib.bib13)]
    first learns features from sequences of [Red-Green-Blue (RGB)](#glo.main.rgb)
    images, which are then processed by [Long Short-Term Memory (LSTM)](#glo.main.lstm)
    cells to estimate poses. The end-to-end [DRCNN](#glo.main.drcnn) framework achieves
    an average [Root Mean Square Error (RMSE)](#glo.main.rmse) drift of $5.96\text{\,}\mathrm{\char
    37\relax}$ and $6.12\text{\,}\mathrm{d}\mathrm{e}\mathrm{g}$ per trajectory for
    position and attitude, respectively, on lengths of $100\text{\,}\mathrm{m}800\text{\,}\mathrm{m}$,
    showing a competitive performance relative to Monocular VISO2 [[14](#bib.bib14)].
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于已知世界模型进行自我定位不同，Wang等人[[11](#bib.bib11)]提出了DeepVO架构，该架构基于单目[视觉里程计（VO）](#glo.main.vo)从帧到帧获取车辆的自我运动。该流程遵循[深度递归卷积神经网络（DRCNN）](#glo.main.drcnn)的架构[[12](#bib.bib12)]，其中一个预训练的FlowNet
    [[13](#bib.bib13)]首先从一系列[红绿蓝（RGB）](#glo.main.rgb)图像中学习特征，然后由[长短期记忆（LSTM）](#glo.main.lstm)单元处理这些特征以估计姿态。端到端的[DRCNN](#glo.main.drcnn)框架在长度为$100\text{\,}\mathrm{m}$到$800\text{\,}\mathrm{m}$的轨迹上，对位置和姿态的平均[均方根误差（RMSE）](#glo.main.rmse)漂移分别为$5.96\text{\,}\mathrm{\char
    37\relax}$和$6.12\text{\,}\mathrm{d}\mathrm{e}\mathrm{g}$，显示出相对于单目VISO2 [[14](#bib.bib14)]的竞争力表现。
- en: Differing from the above end-to-end, or direct, methods, some works opt instead
    by following indirect methods, for which the [DNN](#glo.main.dnn) is exclusively
    tasked with performing the image processing functions on the input, while the
    actual quantity to be estimated is achieved by combing this output with other
    methods, such as classical [ML](#glo.main.ml) or Kalman filtering. For instance,
    Rad and Lepetit [[15](#bib.bib15)] developed the BB8 algorithm for object pose
    estimation by combining a [CNN](#glo.main.cnn) to regress the [two-dimensional
    (2D)](#glo.main.2d) locations of the eight [three-dimensional (3D)](#glo.main.3d)
    points defining their bounding box with a [Perspective-n-Point (P$n$P)](#glo.main.pnp)
    algorithm [[16](#bib.bib16)] to retrieve the pose based on those correspondences.
    The VGG architecture [[17](#bib.bib17)] was chosen as the basis for their work,
    and the classical reprojection (or geometric) error was used as the corresponding
    loss function [[18](#bib.bib18)].
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述端到端或直接方法不同，一些工作选择采用间接方法，其中[DNN](#glo.main.dnn)专门负责对输入进行图像处理，而实际需要估计的量则通过将该输出与其他方法（如经典的[ML](#glo.main.ml)或卡尔曼滤波）结合来实现。例如，Rad和Lepetit
    [[15](#bib.bib15)]开发了BB8算法，通过结合一个[CNN](#glo.main.cnn)来回归定义其边界框的八个[三维（3D）](#glo.main.3d)点的[二维（2D）](#glo.main.2d)位置，以及一个[透视-n-点（P$n$P）](#glo.main.pnp)算法[[16](#bib.bib16)]，基于这些对应关系恢复姿态。他们选择了VGG架构[[17](#bib.bib17)]作为工作的基础，并使用经典的重投影（或几何）误差作为对应的损失函数[[18](#bib.bib18)]。
- en: '![Refer to caption](img/c106dc173fd75732405326547fafaff7.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c106dc173fd75732405326547fafaff7.png)'
- en: 'Figure 4: Direct versus indirect methods for \Glsxtrshortdl-based pose estimation.
    The former use a \Glsxtrshortdnn to directly estimate the pose from the input,
    whereas the latter use it exclusively to identify features, or landmarks, on the
    target, which are then input to a \Glsxtrshortml algorithm.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：基于\Glsxtrshortdl的姿态估计中的直接方法与间接方法。前者使用\Glsxtrshortdnn直接从输入中估计姿态，而后者则专门用于识别目标上的特征或标记点，然后将这些特征输入到\Glsxtrshortml算法中。
- en: 'Figure [4](#S2.F4 "Figure 4 ‣ 2.1 Related Works on Terrestrial Pose Estimation
    ‣ 2 \glsfmtshortdl-based Pose Estimation for Spacecraft Relative Navigation ‣
    Deep Learning-based Spacecraft Relative Navigation Methods: A Survey") illustrates
    the difference between direct and indirect methods, which are explored further
    in this section.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [4](#S2.F4 "图 4 ‣ 2.1 地面姿态估计相关工作 ‣ 2 \glsfmtshortdl 基于空间飞行器相对导航的姿态估计 ‣ 基于深度学习的空间飞行器相对导航方法综述")
    说明了直接方法和间接方法之间的区别，本节将进一步探讨这些方法。
- en: 2.2 Challenges and Motivations
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 挑战与动机
- en: Recent advancements in [DL](#glo.main.dl) exhibit promising alternatives with
    respect to classical approaches, and related terrestrial frameworks also inspire
    the idea of \glsxtrshortdl-based spacecraft relative navigation. However, there
    still exists a gap between the two domains of application.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[DL](#glo.main.dl)的最新进展在经典方法方面展示了有前景的替代方案，相关的地面框架也激发了基于\glsxtrshortdl的航天器相对导航的想法。然而，这两个应用领域之间仍然存在差距。'
- en: 'Relative pose estimation of objects in space is a different problem from pose
    determination of objects on Earth due to the vast differences in environment.
    Additionally, real labelled on-orbit images required for training [DL](#glo.main.dl)
    algorithms are expensive and hard to obtain, which leads to a lack of space imagery
    datasets. Challenges in space missions for applying vision-based [DL](#glo.main.dl)
    methods can be summarised from previous research [[7](#bib.bib7), [19](#bib.bib19),
    [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22), [23](#bib.bib23), [24](#bib.bib24),
    [25](#bib.bib25), [26](#bib.bib26)] as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 空间中物体的相对姿态估计与地球上物体的姿态确定由于环境的巨大差异而是一个不同的问题。此外，用于训练[DL](#glo.main.dl)算法的实际标注轨道图像昂贵且难以获得，这导致了空间图像数据集的缺乏。针对在空间任务中应用基于视觉的[DL](#glo.main.dl)方法的挑战，可以从之前的研究[[7](#bib.bib7),
    [19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22), [23](#bib.bib23),
    [24](#bib.bib24), [25](#bib.bib25), [26](#bib.bib26)]总结如下：
- en: $\bullet$
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Planets and stars acting as background distractors for the navigation system;
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 行星和恒星作为导航系统的背景干扰物；
- en: $\bullet$
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Challenging visual conditions due to lack of atmosphere and light diffusion;
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于缺乏大气层和光线散射，视觉条件具有挑战性；
- en: $\bullet$
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Much stronger shadows and varied illumination conditions resulting in extreme
    image contrast and low signal-to-noise ratio;
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更强的阴影和多变的照明条件导致极端的图像对比度和低信噪比；
- en: $\bullet$
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Limited properties of space hardware in power consumption and computational
    resources (e.g., low sensor resolution);
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 空间硬件在功耗和计算资源方面的有限属性（例如，低传感器分辨率）；
- en: $\bullet$
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Training datasets for non-cooperative navigation of spaceborne objects are scarce;
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用于非合作导航的空间物体的训练数据集稀缺；
- en: $\bullet$
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Concerns over the reliability of [DL](#glo.main.dl) technique preventing their
    practice in the space industry.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对[DL](#glo.main.dl)技术可靠性的担忧阻碍了其在航天工业中的应用。
- en: The characteristics of space images also challenge conventional vision-based
    navigation algorithms for spacecraft, while the [DL](#glo.main.dl) technique provides
    promising solutions and performance that can alleviate these issues. In terms
    of dynamic lighting, \glsxtrshortdnn-based schemes show increased robustness in
    attitude initialisation [[22](#bib.bib22), [27](#bib.bib27)]. With the deployment
    of high-performance devices, \glsxtrshortcnn-based methods can not only provide
    a lower computational complexity in pose acquisition process, but also reduce
    the need for complicated dynamics models [[28](#bib.bib28)]. Additionally, [DNN](#glo.main.dnn)
    pipelines are able to output various information and be combined with navigation
    filters or other processes [[25](#bib.bib25)].
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 空间图像的特征也对传统的基于视觉的航天器导航算法构成挑战，而[DL](#glo.main.dl)技术提供了有前景的解决方案和性能，能够缓解这些问题。在动态照明方面，基于\glsxtrshortdnn的方案显示出在姿态初始化方面的增强鲁棒性[[22](#bib.bib22),
    [27](#bib.bib27)]。随着高性能设备的部署，基于\glsxtrshortcnn的方法不仅可以在姿态获取过程中提供较低的计算复杂性，还可以减少对复杂动态模型的需求[[28](#bib.bib28)]。此外，[DNN](#glo.main.dnn)管道能够输出各种信息，并与导航滤波器或其他过程结合[[25](#bib.bib25)]。
- en: Motivated by the attractiveness described above, and to overcome current limitations
    in spacecraft relative pose estimation, [European Space Agency (ESA)](#glo.main.esa)
    launched the [Kelvins Pose Estimation Challenge (KPEC)](#glo.main.kpec) ⁸⁸8[https://kelvins.esa.int/satellite-pose-estimation-challenge](https://kelvins.esa.int/satellite-pose-estimation-challenge).
    in 2019, inviting the community to propose and validate new approaches directly
    from greyscale images acquired by an on-board camera. The data for training and
    testing in this challenge consisted of Stanford’s [Spacecraft Pose Estimation
    Dataset (SPEED)](#glo.main.speed), which contains labelled synthetic images of
    the Tango satellite, and a smaller, real set of images acquired in laboratory
    using a replica of the target.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 受以上描述的吸引力所激发，并为克服当前空间航行器相对姿态估计的局限性， [欧洲空间局（ESA）](#glo.main.esa) 在2019年启动了 [Kelvins
    Pose Estimation Challenge (KPEC)](#glo.main.kpec) ⁸⁸8[https://kelvins.esa.int/satellite-pose-estimation-challenge](https://kelvins.esa.int/satellite-pose-estimation-challenge)。，邀请社区以灰度图像直接提出和验证新的方法。此次挑战的训练和测试数据来自斯坦福的
    [Spacecraft Pose Estimation Dataset (SPEED)](#glo.main.speed)，其中包含标记的Tango卫星合成图像，以及在实验室中使用目标复制品获取的小型真实图像集。
- en: 2.3 Direct Frameworks for Spacecraft Relative Pose Estimation
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 直接航天器相对姿态估计框架
- en: 'In this survey, direct \glsxtrshortdl-based frameworks are defined as those
    in which the estimation of the desired quantity is entirely relayed to the [DNN](#glo.main.dnn),
    thus forming a continuous, uninterrupted pipeline from input to output. For spacecraft
    relative navigation, the problem is posited as estimating the 6-[DoF](#glo.main.dof)
    pose of a target, $\underaccent{\vec{}}{\bm{\mathcal{F}}}_{t}$, in the frame of
    reference of a chaser, $\underaccent{\vec{}}{\bm{\mathcal{F}}}_{c}$ (as shown
    in Fig. [2(a)](#S1.F2.sf1 "In Figure 2 ‣ 1 Introduction ‣ Deep Learning-based
    Spacecraft Relative Navigation Methods: A Survey")). The target may be non-cooperative,
    in which case it will not relay any explicit information to the chaser’s onboard
    navigation system, and the relative pose is estimated from acquired images of
    the target only.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '在本调查中，直接\glsxtrshortdl为基础的框架被定义为那些完全依靠于[DNN](#glo.main.dnn)来估计期望的量，从而形成从输入到输出的连续、不间断的流水线。对于航天器相对导航，问题被提出为在追逐者的参考系$\underaccent{\vec{}}{\bm{\mathcal{F}}}_{c}$中估计目标$\underaccent{\vec{}}{\bm{\mathcal{F}}}_{t}$的6-[DoF](#glo.main.dof)姿态（如图[2(a)](#S1.F2.sf1
    "在Figure 2 ‣ 1 Introduction ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey"中显示")）。目标可能是非合作的，这种情况下它将不会向追逐者的机载导航系统中传递任何明确的信息，相对姿态仅从目标获取的图像中估计。'
- en: By partitioning the relative pose space into discrete hypotheses, a classification
    framework may be established if the target spacecraft has a known model. Sharma
    et al. [[7](#bib.bib7)] have proposed a deep [CNN](#glo.main.cnn) for relative
    pose classification of non-cooperative spacecraft. Taking advantage of transfer
    learning, AlexNet model [[29](#bib.bib29)] pre-trained on the large ImageNet dataset
    [[30](#bib.bib30)] is modified by replacing the last few layers to adapt to the
    space imagery of the Tango spacecraft flown in the Prisma mission [[31](#bib.bib31)].
    Ten datasets with different added noises are created from synthetic images. The
    proposed approach demonstrated greater accuracy than a baseline method using classical
    pose estimation techniques from [2D](#glo.main.2d)-[3D](#glo.main.3d) feature
    matching but is deemed not fine enough for any application other than a coarse
    initialisation.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将相对姿态空间划分为离散的假设，如果目标航天器有已知模型，就可以建立分类框架。Sharma等人[[7](#bib.bib7)]已提出了一个深度[CNN](#glo.main.cnn)用于非合作航天器的相对姿态分类。利用迁移学习，基于大型ImageNet数据集[[30](#bib.bib30)]预训练的AlexNet模型[[29](#bib.bib29)]被修改，以适应Prisma任务[[31](#bib.bib31)]中Tango航天器的太空图像。从合成图像中创建了十个具有不同噪声的数据集。该方法显示出比使用经典姿态估计技术从[2D](#glo.main.2d)-[3D](#glo.main.3d)特征匹配的基线方法更准确，但被认为除了粗略初始化外，不适用于任何应用。
- en: 'Sharma and D’Amico [[8](#bib.bib8)] later on improve their original work with
    the creation of the [Spacecraft Pose Network (SPN)](#glo.main.spn). The [SPN](#glo.main.spn)
    (Fig. [5](#S2.F5 "Figure 5 ‣ 2.3 Direct Frameworks for Spacecraft Relative Pose
    Estimation ‣ 2 \glsfmtshortdl-based Pose Estimation for Spacecraft Relative Navigation
    ‣ Deep Learning-based Spacecraft Relative Navigation Methods: A Survey")) uses
    a five-layer [CNN](#glo.main.cnn) backbone of which the activations are connected
    to three different branches. The first branch uses the Faster [Region-based Convolutional
    Neural Network (R-CNN)](#glo.main.rcnn) architecture [[32](#bib.bib32)] to detect
    the [2D](#glo.main.2d) bounding box of the target in the input image. To be robust
    towards intrusive background elements (i.e., presence of Earth), specific features
    output by the final activation map of the first branch are extracted using [R-CNN](#glo.main.rcnn)’s
    [Region of Interest (RoI)](#glo.main.roi) pooling technique, and then fed to the
    other two branches of the [CNN](#glo.main.cnn) containing three fully connected
    layers.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 'Sharma 和 D’Amico [[8](#bib.bib8)] 随后通过创建 [航天器姿态网络 (SPN)](#glo.main.spn) 改进了他们的原始工作。
    [SPN](#glo.main.spn)（图 [5](#S2.F5 "Figure 5 ‣ 2.3 Direct Frameworks for Spacecraft
    Relative Pose Estimation ‣ 2 \glsfmtshortdl-based Pose Estimation for Spacecraft
    Relative Navigation ‣ Deep Learning-based Spacecraft Relative Navigation Methods:
    A Survey")）使用了一个五层的 [CNN](#glo.main.cnn) 主干网络，其中的激活连接到三个不同的分支。第一个分支使用 Faster [基于区域的卷积神经网络
    (R-CNN)](#glo.main.rcnn) 架构 [[32](#bib.bib32)] 来检测输入图像中目标的 [2D](#glo.main.2d)
    边界框。为了对抗干扰背景元素（即地球的存在），通过第一个分支的最终激活图输出的特定特征通过 [R-CNN](#glo.main.rcnn) 的 [感兴趣区域
    (RoI)](#glo.main.roi) 池化技术提取，然后输入到包含三个全连接层的 [CNN](#glo.main.cnn) 的其他两个分支中。'
- en: The second branch classifies the target attitude in terms of a probability distribution
    of discrete classes. It minimises a standard cross-entropy loss for the $N$ closest
    attitude labels in the viewsphere. Lastly, the third branch takes the $N$ candidates
    obtained from the previous branch and minimises another cross-entropy loss to
    yield the relative weighting of each. The final refined attitude is obtained via
    quaternion averaging with resort to the computed weights, which can be seen as
    a soft classification method.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个分支根据离散类别的概率分布对目标姿态进行分类。它对视球中 $N$ 个最接近的姿态标签最小化标准交叉熵损失。最后，第三个分支利用从前一个分支获得的
    $N$ 个候选者，并最小化另一种交叉熵损失，以产生每个候选者的相对权重。最终的精细化姿态通过四元数平均法结合计算的权重得到，这可以被视为一种软分类方法。
- en: '![Refer to caption](img/ee137b520d4c2072fa16f2fc9150e89d.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/ee137b520d4c2072fa16f2fc9150e89d.png)'
- en: 'Figure 5: The \glsxtrlong*spn (\glsxtrshortspn) architecture. Reproduced from
    Sharma and D’Amico [[33](#bib.bib33)].'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：\glsxtrlong*spn (\glsxtrshortspn) 架构。转载自 Sharma 和 D’Amico [[33](#bib.bib33)]。
- en: Mathematically, the [SPN](#glo.main.spn) utilises a Gauss-Newton algorithm to
    solve a minimisation problem for the estimate of relative position, for which
    the required initial guess is obtained from the bounding box (analogously to Kehl
    et al. [[34](#bib.bib34)]). The network is initially trained on the ImageNet dataset,
    and then the branch layers are further trained with an $80\text{\,}\mathrm{\char
    37\relax}20\text{\,}\mathrm{\char 37\relax}$ train-validation split on the [SPEED](#glo.main.speed)
    dataset. As they report, the [SPN](#glo.main.spn) method performs at degree-level
    and centimetre-level on relative attitude and position error, respectively.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，[SPN](#glo.main.spn) 利用高斯-牛顿算法来解决相对位置的最小化问题，为此所需的初始猜测是通过边界框获得的（类似于 Kehl
    等人 [[34](#bib.bib34)]）。网络首先在 ImageNet 数据集上进行训练，然后使用 [SPEED](#glo.main.speed) 数据集进行
    $80\text{\,}\mathrm{\char 37\relax}20\text{\,}\mathrm{\char 37\relax}$ 的训练-验证划分进一步训练分支层。正如他们报告的那样，[SPN](#glo.main.spn)
    方法在相对姿态和位置误差上分别达到了度级和厘米级的表现。
- en: In Ref. [[33](#bib.bib33)], Sharma and D’Amico expand their conference paper
    [[8](#bib.bib8)] by discussing two features of the [SPN](#glo.main.spn), target-in-target
    pose estimation and uncertainty quantification. The capability of estimating the
    uncertainty associated with the estimated pose of the [SPN](#glo.main.spn) emphasises
    that [SPN](#glo.main.spn) can be integrated with conventional navigation filters.
    Additionally, the authors detail the proposed [SPEED](#glo.main.speed) dataset,
    considering the solar illumination of the synthetic images and the ground truth
    calibration of the relative pose by the real images. The [SPN](#glo.main.spn)
    is also trained in three versions by using different datasets, including [SPEED](#glo.main.speed),
    ”Apogee Motor”, ”Imitation-25”, and ”PRISMA-25”. Experiments are also carried
    out to demonstrate two key features of [SPN](#glo.main.spn) method and compare
    it with their previous work, namely \glsxtrshortcnn-based [[7](#bib.bib7)] and
    image processing-based feature detection and correspondence [[35](#bib.bib35)]
    methods.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在参考文献[[33](#bib.bib33)]中，Sharma和D’Amico通过讨论[SPN](#glo.main.spn)的两个特性来扩展他们的会议论文[[8](#bib.bib8)]，即目标内目标姿态估计和不确定性量化。估计与[SPN](#glo.main.spn)估计姿态相关的不确定性的能力强调了[SPN](#glo.main.spn)可以与传统导航滤波器集成。此外，作者详细介绍了提出的[SPEED](#glo.main.speed)数据集，考虑了合成图像的太阳照射和通过真实图像的相对姿态的真实标定。[SPN](#glo.main.spn)还通过使用不同的数据集进行三种版本的训练，包括[SPEED](#glo.main.speed)、”Apogee
    Motor”、”Imitation-25”和”PRISMA-25”。还进行了实验以展示[SPN](#glo.main.spn)方法的两个关键特性，并将其与他们之前的工作进行比较，即\glsxtrshortcnn-based
    [[7](#bib.bib7)]和基于图像处理的特征检测和匹配[[35](#bib.bib35)]方法。
- en: Instead of employing a bounding box feature detection, Proença and Gao [[36](#bib.bib36)]
    modify a pre-trained ResNet architecture [[37](#bib.bib37)] with initial weights
    trained on the [Common Objects in Context (COCO)](#glo.main.coco) dataset to keep
    spatial feature resolution. Similarly to Ref. [[8](#bib.bib8)], two branches are
    designed to estimate [3D](#glo.main.3d) location and orientation, respectively.
    The position estimation consists of a simple regression branch with two fully
    connected layers and the relative error is minimised for better generalisation
    in terms of loss weight magnitudes. The continuous attitude estimation is then
    realised via a soft classification method [[38](#bib.bib38)]. Additionally, the
    authors present their own synthetic [Unreal Rendered Spacecraft On-Orbit (URSO)](#glo.main.urso)
    dataset for training featuring Soyuz. Experiments on renders of [URSO](#glo.main.urso)
    and [SPEED](#glo.main.speed) datasets are conducted to evaluate the proposed framework,
    with which their model achieved a third and a second place on the synthetic and
    real test set categories of [SPEED](#glo.main.speed) in [KPEC](#glo.main.kpec),
    respectively. Moreover, the experimental results show that estimating the orientation
    by soft classification performs better than direct regression methods.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: Proença和Gao[[36](#bib.bib36)]修改了一个经过预训练的ResNet架构[[37](#bib.bib37)]，使用在[COCO](#glo.main.coco)数据集上训练的初始权重，以保持空间特征分辨率，而不是采用边界框特征检测。与参考文献[[8](#bib.bib8)]类似，设计了两个分支来分别估计[3D](#glo.main.3d)位置和方向。位置估计包括一个简单的回归分支，具有两个全连接层，并且为了更好的泛化，最小化了相对误差的损失权重幅度。然后，通过软分类方法[[38](#bib.bib38)]实现连续的姿态估计。此外，作者提出了他们自己的合成[虚幻渲染航天器在轨（URSO）](#glo.main.urso)数据集，用于训练包含Soyuz。对[URSO](#glo.main.urso)和[SPEED](#glo.main.speed)数据集的渲染图像进行了实验，以评估所提出的框架，使用该框架，他们的模型在[KPEC](#glo.main.kpec)的[SPEED](#glo.main.speed)合成测试集和真实测试集类别中分别获得了第三名和第二名。此外，实验结果表明，通过软分类估计方向比直接回归方法表现更好。
- en: '![Refer to caption](img/05b53d1699b53beb85fbb4032d3fdd44.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/05b53d1699b53beb85fbb4032d3fdd44.png)'
- en: (a) Simplified architecture model
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 简化的架构模型
- en: '![Refer to caption](img/ada0fc472a650429a8980446f94a4460.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/ada0fc472a650429a8980446f94a4460.png)'
- en: (b) ResNet block
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: (b) ResNet模块
- en: 'Figure 6: The [CNN](#glo.main.cnn) pipeline in Ref. [[36](#bib.bib36)]. The
    [CNN](#glo.main.cnn) front-end is based on ResNet, of which the elementary blocks
    implement skip connections that help mitigate the vanishing gradient problem in
    very deep networks.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '图6: 参考文献[[36](#bib.bib36)]中的[卷积神经网络（CNN）](#glo.main.cnn)流程图。[CNN](#glo.main.cnn)的前端基于ResNet，其基本模块实现了跳跃连接，有助于缓解在非常深的网络中出现的梯度消失问题。'
- en: Hirano et al. [[24](#bib.bib24)] present a [3D](#glo.main.3d) keypoint estimator
    by using an AlexNet-based [CNN](#glo.main.cnn) architecture to regress spacecraft
    pose information directly, rather than retrieving [3D](#glo.main.3d) objects from
    the location of [2D](#glo.main.2d) keypoints. The parameters of AlexNet are changed
    for the purpose of the pose estimation task, and batch normalisation layers [[39](#bib.bib39)]
    are utilised in all [Convolutional Layer (CL)](#glo.main.cl) and [Fully Connected
    Layer (FCL)](#glo.main.fl) for convergence in training. Synthesised images of
    a [3D](#glo.main.3d) model with the [3D](#glo.main.3d) keypoint position labels
    are generated on the Gazebo simulator [[40](#bib.bib40)] and used to train the
    [CNN](#glo.main.cnn). Real images taken by hardware simulators are imported to
    evaluate the trained [CNN](#glo.main.cnn). Images in both training and test dataset
    include the effects of lighting, shadows, and random noise, which leads the proposed
    framework to a potential application in practical space missions.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Hirano 等人 [[24](#bib.bib24)] 提出了一种基于 AlexNet 的 [CNN](#glo.main.cnn) 架构的 [3D](#glo.main.3d)
    关键点估计器，该方法直接回归航天器姿态信息，而不是从 [2D](#glo.main.2d) 关键点的位置检索 [3D](#glo.main.3d) 对象。AlexNet
    的参数为了姿态估计任务而进行了调整，并在所有的 [Convolutional Layer (CL)](#glo.main.cl) 和 [Fully Connected
    Layer (FCL)](#glo.main.fl) 中使用了批量归一化层 [[39](#bib.bib39)] 以实现训练过程中的收敛。通过 Gazebo
    仿真器 [[40](#bib.bib40)] 生成的带有 [3D](#glo.main.3d) 关键点位置标签的 [3D](#glo.main.3d) 模型的合成图像被用来训练
    [CNN](#glo.main.cnn)。通过硬件模拟器拍摄的真实图像被导入以评估训练后的 [CNN](#glo.main.cnn)。训练和测试数据集中包括了光照、阴影和随机噪声的影响，这使得所提出的框架在实际空间任务中具有潜在应用。
- en: Arakawa et al. [[41](#bib.bib41)] also treat the attitude estimation as a \glsxtrshortcnn-based
    regression problem to obtain spacecraft attitude quaternion from the constructed
    images, in which the output of the proposed [CNN](#glo.main.cnn) is four independent
    real numbers corresponding to four quaternion elements. A [3D](#glo.main.3d) model
    of the JCSAT-3 satellite is built in the Blender software to generate a training
    image dataset. A point spread function is applied to the renders for simulating
    atmospheric fluctuations and optical effects. Compared with conventional image
    matching approaches, their results clarify an improved performance on the accuracy,
    robustness, and computational cost.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Arakawa 等人 [[41](#bib.bib41)] 也将姿态估计视为基于 \glsxtrshortcnn 的回归问题，以从构建的图像中获取航天器姿态四元数，其中所提出的
    [CNN](#glo.main.cnn) 的输出是四个独立的实数，分别对应四个四元数元素。在 Blender 软件中建立了 JCSAT-3 卫星的 [3D](#glo.main.3d)
    模型，用于生成训练图像数据集。渲染图像应用了点扩散函数，以模拟大气波动和光学效应。与传统的图像匹配方法相比，他们的结果在准确性、鲁棒性和计算成本上都有所改进。
- en: 'Considering that natural feature-based methods for spacecraft pose estimation
    are not always sufficient, Sonawani et al. [[19](#bib.bib19)] develop a modified
    model to assist a cooperative object tracker in space assembly tasks. The proposed
    [CNN](#glo.main.cnn) architecture is similar to Ref. [[7](#bib.bib7)], but uses
    VGG-19 as a backbone and replace the last layer with a 7-node one instead of an
    activation function. Two different models, namely a branch-based model and a parallel-based
    model, are developed to estimate relative poses. The frameworks of the two models
    are illustrated in Fig. [7](#S2.F7 "Figure 7 ‣ 2.3 Direct Frameworks for Spacecraft
    Relative Pose Estimation ‣ 2 \glsfmtshortdl-based Pose Estimation for Spacecraft
    Relative Navigation ‣ Deep Learning-based Spacecraft Relative Navigation Methods:
    A Survey"), in which the parallel model contains two parallel streams for position
    prediction and attitude estimation, respectively. Synthetic images are generated
    in Gazebo, including truss-shaped objects labelled with the pose. The Euclidean
    distance error between the predicted poses and actual ones is defined as the loss
    function. Simulation results show their models are comparable to the current feature-selection
    methods and are robust to other types of spacecraft.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '考虑到基于自然特征的方法在航天器姿态估计中并不总是足够的，Sonawani 等人 [[19](#bib.bib19)] 发展了一种改进模型，以协助空间组装任务中的合作目标跟踪器。所提出的
    [CNN](#glo.main.cnn) 架构类似于文献 [[7](#bib.bib7)]，但使用 VGG-19 作为骨干，并将最后一层替换为一个 7 节点的层而不是激活函数。开发了两种不同的模型，即基于分支的模型和基于并行的模型，用于估计相对姿态。这两种模型的框架在图
    [7](#S2.F7 "Figure 7 ‣ 2.3 Direct Frameworks for Spacecraft Relative Pose Estimation
    ‣ 2 \glsfmtshortdl-based Pose Estimation for Spacecraft Relative Navigation ‣
    Deep Learning-based Spacecraft Relative Navigation Methods: A Survey") 中说明，其中并行模型包含两个并行流，用于位置预测和姿态估计。合成图像在
    Gazebo 中生成，包括标记了姿态的桁架状物体。预测姿态与实际姿态之间的欧几里得距离误差定义为损失函数。仿真结果表明，他们的模型与当前特征选择方法相当，并且对其他类型的航天器具有鲁棒性。'
- en: '![Refer to caption](img/52368456eeebf5ab463229998af35f0a.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/52368456eeebf5ab463229998af35f0a.png)'
- en: (a) Branch model
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 分支模型
- en: '![Refer to caption](img/d635e484e226970fd1efcfb96b4e8439.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d635e484e226970fd1efcfb96b4e8439.png)'
- en: (b) Parallel model
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 并行模型
- en: 'Figure 7: The VGG-19-based architecture of Sonawani et al. [[19](#bib.bib19)].
    The branch is used to preserve feature-position information discarded by the later
    pooling layers.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：Sonawani 等人基于 VGG-19 的架构 [[19](#bib.bib19)]。该分支用于保留后续池化层丢弃的特征位置信息。
- en: Aiming at vision-based uncooperative docking operations, Phisannupawong et al.
    [[42](#bib.bib42)] construct a spacecraft pose estimation model by proposing an
    advanced GoogLeNet pre-trained on [URSO](#glo.main.urso). The original GoogLeNet
    framework is modified by using 23 layers of [CNN](#glo.main.cnn) presented in
    Ref. [[9](#bib.bib9)], and the output for spacecraft pose is a seven-element vector.
    Experiments are carried out with an exponential loss function and a weighted Euclidean
    loss function, separately. The simulating results suggest that the weighted Euclidean-based
    pose estimation model successfully achieves moderately high prediction accuracy,
    but the exponential-based model results in poor orientation estimation accuracy.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 针对基于视觉的非合作对接操作，Phisannupawong 等人 [[42](#bib.bib42)] 通过提出一个先进的在 [URSO](#glo.main.urso)
    上预训练的 GoogLeNet 来构建航天器姿态估计模型。原始的 GoogLeNet 框架通过使用文献 [[9](#bib.bib9)] 中提出的 23 层
    [CNN](#glo.main.cnn) 进行了修改，航天器姿态的输出为一个七元素向量。实验分别使用了指数损失函数和加权欧几里得损失函数。模拟结果表明，加权欧几里得基的姿态估计模型成功实现了中等偏高的预测精度，但指数基的模型导致了较差的方向估计精度。
- en: 'Instead of estimating poses at individual timesteps, Kechagias-Stamatis et al.
    [[43](#bib.bib43)] propose a [DRCNN](#glo.main.drcnn) to regress the relative
    pose of spacecraft from frame to frame. For a relative spacecraft navigation system,
    these chained poses serve as continuous outputs, of which the continuity is vital
    to autonomous missions such as rendezvous and formation flyover. Specifically,
    the [DRCNN](#glo.main.drcnn) consists of a [CNN](#glo.main.cnn) module and followed
    a [LSTM](#glo.main.lstm) module to extract features of the input images and automatically
    modelling the relative dynamics, respectively (see Fig. [8](#S2.F8 "Figure 8 ‣
    2.3 Direct Frameworks for Spacecraft Relative Pose Estimation ‣ 2 \glsfmtshortdl-based
    Pose Estimation for Spacecraft Relative Navigation ‣ Deep Learning-based Spacecraft
    Relative Navigation Methods: A Survey")). [3D](#glo.main.3d) lidar data is projected
    onto the image plane, yielding three different [2D](#glo.main.2d) depth images
    to be processed by a regular [CNN](#glo.main.cnn). As in Ref. [[11](#bib.bib11)],
    the loss minimises the pose [Mean Square Error (MSE)](#glo.main.mse), but the
    attitude is represented via a direction cosine matrix. Trials are conducted on
    both synthetic and real data. For the former, the Elite target satellite platform
    is used to create a self-occluded point cloud. The real dataset is acquired with
    a scaled mock-up of Envisat. Their results on both simulated and real lidar data
    scenarios demonstrate that the [DRCNN](#glo.main.drcnn) achieves better odometry
    accuracy at lower computational requirements than current algorithms such as [Iterative
    Closest Point (ICP)](#glo.main.icp) [[44](#bib.bib44)] and descriptor matching
    with $H_{\infty}$ filtering.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Kechagias-Stamatis 等人 [[43](#bib.bib43)] 提出了一个 [DRCNN](#glo.main.drcnn) 模型，用于从帧到帧回归航天器的相对姿态，而不是在单个时间步估计姿态。对于相对航天器导航系统，这些链式姿态作为连续输出，其中连续性对自主任务（如对接和编队飞行）至关重要。具体而言，[DRCNN](#glo.main.drcnn)
    包括一个 [CNN](#glo.main.cnn) 模块和一个 [LSTM](#glo.main.lstm) 模块，分别用于提取输入图像的特征和自动建模相对动态（见图
    [8](#S2.F8 "图 8 ‣ 2.3 航天器相对姿态估计的直接框架 ‣ 2 \glsfmtshortdl-based 航天器相对导航 ‣ 基于深度学习的航天器相对导航方法综述")）。[3D](#glo.main.3d)
    激光雷达数据被投影到图像平面上，生成三个不同的 [2D](#glo.main.2d) 深度图像，然后由普通 [CNN](#glo.main.cnn) 处理。如参考文献
    [[11](#bib.bib11)] 所示，损失函数最小化姿态 [均方误差 (MSE)](#glo.main.mse)，但姿态通过方向余弦矩阵表示。实验在合成数据和真实数据上进行。对于前者，使用
    Elite 目标卫星平台创建自遮挡点云。真实数据集通过 Envisat 的缩放模型获取。他们在模拟和真实激光雷达数据场景中的结果表明，[DRCNN](#glo.main.drcnn)
    在较低的计算需求下实现了比当前算法（如 [迭代最近点 (ICP)](#glo.main.icp) [[44](#bib.bib44)] 和 $H_{\infty}$
    滤波的描述符匹配）更好的里程计精度。
- en: '![Refer to caption](img/be6a8fee6c13f798dbf2ddd7c3bddce9.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/be6a8fee6c13f798dbf2ddd7c3bddce9.png)'
- en: 'Figure 8: The [DRCNN](#glo.main.drcnn) architecture of Kechagias-Stamatis et al.
    [[43](#bib.bib43)]. A shallow [CNN](#glo.main.cnn) architecture is utilised to
    extract low-level features for projected images, which are then modelled with
    [LSTMs](#glo.main.lstm).'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8: Kechagias-Stamatis 等人 [[43](#bib.bib43)] 的 [DRCNN](#glo.main.drcnn) 架构。采用浅层
    [CNN](#glo.main.cnn) 架构提取投影图像的低级特征，然后使用 [LSTMs](#glo.main.lstm) 对其进行建模。'
- en: 'Oestreich et al. [[22](#bib.bib22)] study on-orbit relative pose initialisation
    by employing AlexNet-based transfer learning and a post-classification attitude
    refinement algorithm, which provides a foundation for future work in \glsxtrshortcnn-based
    spacecraft pose initialisation. Their research puts focus on answering several
    questions on the applicability of [DL](#glo.main.dl) to this domain, including
    the necessary amount of training imagery, attitude label discretisation, and the
    effects of lighting and image background on [CNN](#glo.main.cnn) performance.
    Thus, AlexNet, used as the backbone of the proposed framework, only changes the
    final [FCL](#glo.main.fl) to yield attitude labels. The output attitude, obtained
    from a single branch unlike Ref. [[8](#bib.bib8)], is then refined using the eight
    most likely labels via direction cosine matrix averaging. Synthetic images of
    the SpaceX Dragon capsule are rendered using Blender at a fixed range of $20\text{\,}\mathrm{m}$.
    Four different synthetic image sets are created to study the performance of the
    presented scheme and answer the proposed questions, namely considering a black
    and empty background, Sun angle variation, Earth background variation, and sensor
    noise. Based on their experimental results, it is indicated that: 1) both classification
    accuracy and attitude error exhibit an asymptotic trend; 2) the [CNN](#glo.main.cnn)
    performs well in more challenging light conditions of the Sun variation dataset
    but poorly for the Earth background and sensor noise datasets; and 3) using the
    confidence rejection threshold in the refinement step can improve estimation accuracy
    slightly.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: Oestreich 等人 [[22](#bib.bib22)] 研究了通过采用基于 AlexNet 的迁移学习和后分类姿态精化算法进行轨道相对姿态初始化，为未来的基于
    \glsxtrshortcnn 的航天器姿态初始化工作奠定了基础。他们的研究重点回答了几个关于 [DL](#glo.main.dl) 在该领域适用性的问题，包括所需的训练图像量、姿态标签离散化以及光照和图像背景对
    [CNN](#glo.main.cnn) 性能的影响。因此，AlexNet 作为所提框架的骨干，仅改变了最终的 [FCL](#glo.main.fl) 以生成姿态标签。得到的姿态，与
    Ref. [[8](#bib.bib8)] 的单分支不同，通过方向余弦矩阵平均使用八个最可能的标签进行精化。使用 Blender 在固定范围 $20\text{\,}\mathrm{m}$
    渲染 SpaceX Dragon 胶囊的合成图像。创建了四个不同的合成图像集，以研究所提出方案的性能并回答提出的问题，即考虑黑色和空白背景、太阳角度变化、地球背景变化和传感器噪声。根据他们的实验结果，指出：1)
    分类准确率和姿态误差都表现出渐近趋势；2) [CNN](#glo.main.cnn) 在太阳变化数据集的较为苛刻光照条件下表现良好，但在地球背景和传感器噪声数据集中的表现较差；3)
    在精化步骤中使用置信度拒绝阈值可以稍微提高估计精度。
- en: Recently, Cosmas and Kenichi [[23](#bib.bib23)] first investigated the feasibility
    of \glsxtrshortcnn-based spacecraft pose estimation by assessing the onboard inference
    capabilities of the model. Accounting for power consumption and cost-effectiveness,
    the Xilinx Zynq Ultrascale+ multiprocessor [System-on-a-Chip (SoC)](#glo.main.soc)
    hybrid [Field-Programmable Gate Array (FPGA)](#glo.main.fpga) is proposed as a
    suitable solution. Two typical approaches and one presented framework are trained
    in Google Colab using the [SPEED](#glo.main.speed) dataset, showing that a U-Net-based
    detection network performs better than the ResNet-50 based direct regression scheme,
    albeit poorer than the developed ResNet34-U-Net model. Later, the ResNet34-U-Net
    pipeline is implemented on the proposed hardware, starting with a YOLOv3 for [RoI](#glo.main.roi)
    detection, followed by a landmark localisation network to predict keypoints. Inference
    experiments, including an evaluation of the performance, compared to a desktop-based
    implementation, [DL](#glo.main.dl) processing unit resource utilisation, and power
    consumption are analysed with results of satisfactory accuracy and low on-chip
    power consumption of $3.5\text{\,}\mathrm{W}$.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Cosmas 和 Kenichi [[23](#bib.bib23)] 首次研究了基于 \glsxtrshortcnn 的航天器姿态估计的可行性，评估了模型的板载推理能力。考虑到功耗和成本效益，建议使用
    Xilinx Zynq Ultrascale+ 多处理器 [片上系统 (SoC)](#glo.main.soc) 混合 [现场可编程门阵列 (FPGA)](#glo.main.fpga)
    作为合适的解决方案。两种典型的方法和一个提出的框架在 Google Colab 上使用 [SPEED](#glo.main.speed) 数据集进行训练，结果表明，基于
    U-Net 的检测网络表现优于基于 ResNet-50 的直接回归方案，但仍不如开发的 ResNet34-U-Net 模型。随后，ResNet34-U-Net
    流水线在提议的硬件上实现，首先使用 YOLOv3 进行 [RoI](#glo.main.roi) 检测，然后使用地标定位网络预测关键点。推理实验，包括性能评估、与桌面实现的比较、[DL](#glo.main.dl)
    处理单元资源利用率和功耗分析，结果显示精度令人满意，芯片功耗低至 $3.5\text{\,}\mathrm{W}$。
- en: 'To make a clear comparison between the aforementioned approaches, Table [1](#S2.T1
    "Table 1 ‣ 2.3 Direct Frameworks for Spacecraft Relative Pose Estimation ‣ 2 \glsfmtshortdl-based
    Pose Estimation for Spacecraft Relative Navigation ‣ Deep Learning-based Spacecraft
    Relative Navigation Methods: A Survey") summarises the surveyed \glsxtrshortdl-based
    direct frameworks for relative pose estimation. As shown, over half of the solutions
    employ transfer learning, which traditionally has also been considered by the
    most successful applications of [DNNs](#glo.main.dnn) to terrain navigation problems.
    In terms of framework types, most are seen to adopt an estimation by regression
    or soft classifier. Open datasets of real images are limited; only PRISMA-25 and
    [SPEED](#glo.main.speed) are available. On the other hand, synthetic imagery can
    be simulated by different software or platforms, such as OpenGL, Gazebo, Unreal
    Engine 4, and Blender, leading to datasets such as [URSO](#glo.main.urso). Moreover,
    the recent research output volume demonstrates there is an increasing interest
    in \glsxtrshortdl-based spacecraft pose estimation, including even a first report
    on onboard implementations with [FPGAs](#glo.main.fpga).'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对上述方法进行清晰的比较，表格[1](#S2.T1 "表 1 ‣ 2.3 空间飞行器相对姿态估计的直接框架 ‣ 2 \glsfmtshortdl-基础姿态估计用于空间飞行器相对导航
    ‣ 基于深度学习的空间飞行器相对导航方法：调查") 总结了调查过的基于\glsxtrshortdl的相对姿态估计的直接框架。正如所示，超过一半的解决方案采用了迁移学习，这在传统上也被认为是最成功的[DNNs](#glo.main.dnn)在地形导航问题上的应用之一。在框架类型方面，大多数采用回归或软分类器进行估计。真实图像的开放数据集有限；仅有
    PRISMA-25 和[SPEED](#glo.main.speed)可用。另一方面，合成图像可以通过不同的软件或平台进行模拟，例如 OpenGL、Gazebo、Unreal
    Engine 4 和 Blender，从而生成如[URSO](#glo.main.urso)等数据集。此外，近期的研究输出量表明，对基于\glsxtrshortdl的空间飞行器姿态估计的兴趣正在增加，甚至包括对[FPGAs](#glo.main.fpga)的首次报告。
- en: 'Table 1: Summary of \glsxtrshortdl-based direct pose estimation methods for
    spacecraft relative navigation.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 基于\glsxtrshortdl的空间飞行器相对导航的直接姿态估计方法总结。'
- en: '| Ref. | Backbone | Transfer | Type | Dataset | Comments |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 主干 | 迁移 | 类型 | 数据集 | 评论 |'
- en: '|  |  | learning |  |  |  |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 学习 |  |  |  |'
- en: '| [[7](#bib.bib7)] | AlexNet | ImageNet | Classifier | PRISMA, synthetic |
    Coarse initialisation |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| [[7](#bib.bib7)] | AlexNet | ImageNet | 分类器 | PRISMA，合成 | 粗略初始化 |'
- en: '| [[8](#bib.bib8)] | Faster [R-CNN](#glo.main.rcnn) | ImageNet | Soft classifier
    | [SPEED](#glo.main.speed), synthetic | Introduction of [SPN](#glo.main.spn) |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| [[8](#bib.bib8)] | Faster[R-CNN](#glo.main.rcnn) | ImageNet | 软分类器 | [SPEED](#glo.main.speed)，合成
    | [SPN](#glo.main.spn)的介绍 |'
- en: '| [[33](#bib.bib33)] | [SPN](#glo.main.spn) | ImageNet | Soft classifier |
    [SPEED](#glo.main.speed), PRISMA, synthetic (OpenGL) | Outperforms Ref. [[7](#bib.bib7)]
    |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| [[33](#bib.bib33)] | [SPN](#glo.main.spn) | ImageNet | 软分类器 | [SPEED](#glo.main.speed)，PRISMA，合成（OpenGL）
    | 优于参考文献[[7](#bib.bib7)] |'
- en: '| [[36](#bib.bib36)] | ResNet-50 | [COCO](#glo.main.coco) | Soft classifier
    | [URSO](#glo.main.urso) (Soyuz [S/C](#glo.main.sc)) | Soft classifier outperforms
    regressor in attitude |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| [[36](#bib.bib36)] | ResNet-50 | [COCO](#glo.main.coco) | 软分类器 | [URSO](#glo.main.urso)
    (Soyuz [S/C](#glo.main.sc)) | 软分类器在姿态估计中优于回归器 |'
- en: '| [[24](#bib.bib24)] | AlexNet | ✗ | Regressor | Synthetic (Gazebo), real |
    Direct [3D](#glo.main.3d) keypoint regression |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| [[24](#bib.bib24)] | AlexNet | ✗ | 回归器 | 合成（Gazebo），真实 | 直接[3D](#glo.main.3d)关键点回归
    |'
- en: '| [[41](#bib.bib41)] | 2-layer [CNN](#glo.main.cnn) | ✗ | Regressor | Synthetic
    (Blender, JCSAT-3 [S/C](#glo.main.sc)) | Evaluates robustness to noise, outputs
    quaternions |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| [[41](#bib.bib41)] | 2层[CNN](#glo.main.cnn) | ✗ | 回归器 | 合成（Blender，JCSAT-3
    [S/C](#glo.main.sc)） | 评估对噪声的鲁棒性，输出四元数 |'
- en: '| [[19](#bib.bib19)] | VGG-19 | ImageNet | Regressor | Synthetic (Gazebo) |
    Cooperative object tracker |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| [[19](#bib.bib19)] | VGG-19 | ImageNet | 回归器 | 合成（Gazebo） | 协作对象跟踪器 |'
- en: '| [[42](#bib.bib42)] | GoogLeNet | PoseNet | Regressor | Synthetic (Unreal
    Engine 4, Soyuz [S/C](#glo.main.sc)) | Comparison of two loss functions |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| [[42](#bib.bib42)] | GoogLeNet | PoseNet | 回归器 | 合成（Unreal Engine 4，Soyuz
    [S/C](#glo.main.sc)） | 两种损失函数的比较 |'
- en: '| [[43](#bib.bib43)] | Shallow [CNN](#glo.main.cnn) + [LSTM](#glo.main.lstm)
    | ✗ | Regressor | Synthetic (Elite [S/C](#glo.main.sc)), real (Envisat [S/C](#glo.main.sc))
    | Frame to frame motion estimator |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| [[43](#bib.bib43)] | 浅层[CNN](#glo.main.cnn) + [LSTM](#glo.main.lstm) | ✗
    | 回归器 | 合成（Elite [S/C](#glo.main.sc)），真实（Envisat [S/C](#glo.main.sc)） | 帧到帧的运动估计器
    |'
- en: '| [[23](#bib.bib23)] | U-Net, ResNet, YOLOv3 | ✗ | Regressor | [SPEED](#glo.main.speed)
    | Onboard [FPGA](#glo.main.fpga) implementation |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| [[23](#bib.bib23)] | U-Net, ResNet, YOLOv3 | ✗ | 回归器 | [SPEED](#glo.main.speed)
    | 机载[FPGAs](#glo.main.fpga)实现 |'
- en: '| [[22](#bib.bib22)] | AlexNet | ImageNet | Classifier | Synthetic (Dragon
    [S/C](#glo.main.sc)) | Analysis of Sun angles, Earth presence, noise |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| [[22](#bib.bib22)] | AlexNet | ImageNet | 分类器 | 合成 (Dragon [S/C](#glo.main.sc))
    | 太阳角度分析、地球存在、噪声 |'
- en: 2.4 Indirect Frameworks for Spacecraft Relative Pose Estimation
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 航天器相对姿态估计的间接框架
- en: Estimating the pose from images using end-to-end \glsxtrshortdl-based methods
    has been argued to yield inadequate feature representation and limited explainability,
    either of which has so far achieved subpar performances as opposed to geometry-based
    methods. Sattler et al. [[45](#bib.bib45)] discuss the limitations of end-to-end
    \glsxtrshortcnn-based terrain pose regression and suggest that there is a gap
    for practical applications. Moreover, the [DNN](#glo.main.dnn) model has a risk
    of overfitting, which results in unpredictable drops in performance between the
    training images and test images due to memorising, rather than learning, properties
    of the former set that do not function well on the latter [[1](#bib.bib1)]. Therefore,
    some research avenues have recently refocused on the indirect methods, which aim
    to combine [DL](#glo.main.dl) and conventional geometry-based techniques to refine
    the estimation of the pose.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 使用端到端的\glsxtrshortdl方法从图像中估计姿态被认为提供了不足的特征表示和有限的解释性，这些方法的表现与基于几何的方法相比一直不尽如人意。Sattler等人[[45](#bib.bib45)]讨论了端到端的\glsxtrshortcnn基于地形姿态回归的局限性，并建议在实际应用中存在差距。此外，[DNN](#glo.main.dnn)模型有过拟合的风险，这会导致训练图像和测试图像之间的性能不可预测地下降，因为它记住了前者的属性，而不是学习，这些属性在后者上效果不好[[1](#bib.bib1)]。因此，一些研究方向最近重新聚焦于间接方法，旨在结合[DL](#glo.main.dl)和传统几何方法来改进姿态估计。
- en: 'To promote the practical use of \glsxtrshortdl-based pose estimation in space
    missions, Park et al. [[46](#bib.bib46)] take the [SPN](#glo.main.spn) framework
    [[8](#bib.bib8)] and modify it by employing both a novel [CNN](#glo.main.cnn)
    for target detection and [Random Sample Consensus (RANSAC)](#glo.main.ransac)
    algorithms for solving the [P$n$P](#glo.main.pnp) problem. The proposed [CNN](#glo.main.cnn)
    is decoupled into the detection and pose estimation networks to determine the
    [2D](#glo.main.2d) bounding box of the [RoI](#glo.main.roi) and to regress the
    [2D](#glo.main.2d) locataion of keypoints, respectively. As demonstrated in Fig. [9(a)](#S2.F9.sf1
    "In Figure 9 ‣ 2.4 Indirect Frameworks for Spacecraft Relative Pose Estimation
    ‣ 2 \glsfmtshortdl-based Pose Estimation for Spacecraft Relative Navigation ‣
    Deep Learning-based Spacecraft Relative Navigation Methods: A Survey"), the [Object
    Detection Network (ODN)](#glo.main.odn) and the [Keypoint Regression Network (KRN)](#glo.main.krn)
    closely follow the pipeline of YOLOv2/YOLOv3 [[47](#bib.bib47)], but use MobileNetv2
    [[48](#bib.bib48)] and MobileNet [[49](#bib.bib49)], respectively. To drastically
    reduce the number of network parameters, traditional convolution operations of
    the network are replaced with depth-wise convolutions followed by point-wise convolutions
    (see Fig. [9(b)](#S2.F9.sf2 "In Figure 9 ‣ 2.4 Indirect Frameworks for Spacecraft
    Relative Pose Estimation ‣ 2 \glsfmtshortdl-based Pose Estimation for Spacecraft
    Relative Navigation ‣ Deep Learning-based Spacecraft Relative Navigation Methods:
    A Survey")).'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 为了促进\glsxtrshortdl基于的姿态估计在空间任务中的实际应用，Park等人[[46](#bib.bib46)]采用了[SPN](#glo.main.spn)框架[[8](#bib.bib8)]，并通过采用新型的[CNN](#glo.main.cnn)进行目标检测和[随机样本一致性（RANSAC）](#glo.main.ransac)算法来解决[P$n$P](#glo.main.pnp)问题来对其进行修改。提出的[CNN](#glo.main.cnn)被解耦为检测和姿态估计网络，以分别确定[2D](#glo.main.2d)边界框的[RoI](#glo.main.roi)和回归[2D](#glo.main.2d)关键点的位置。如图[9(a)](#S2.F9.sf1
    "在图9中 ‣ 2.4 航天器相对姿态估计的间接框架 ‣ 2 \glsfmtshortdl基于的姿态估计用于航天器相对导航 ‣ 基于深度学习的航天器相对导航方法：综述")所示，[对象检测网络（ODN）](#glo.main.odn)和[关键点回归网络（KRN）](#glo.main.krn)紧随YOLOv2/YOLOv3[[47](#bib.bib47)]的流程，但分别使用MobileNetv2[[48](#bib.bib48)]和MobileNet[[49](#bib.bib49)]。为了大幅减少网络参数数量，网络的传统卷积操作被深度卷积和点卷积所替代（见图[9(b)](#S2.F9.sf2
    "在图9中 ‣ 2.4 航天器相对姿态估计的间接框架 ‣ 2 \glsfmtshortdl基于的姿态估计用于航天器相对导航 ‣ 基于深度学习的航天器相对导航方法：综述")）。
- en: Considering the lack of real space-based datasets with representative texture
    and surface illumination properties, Park et al. [[46](#bib.bib46)] also contribute
    with a new training procedure to improve the robustness of [CNNs](#glo.main.cnn)
    to spaceborne imagery when trained solely on synthetic data. Inspired by Ref. [[50](#bib.bib50)],
    they generate a new dataset by applying neural style transfer techniques [[51](#bib.bib51)]
    to a custom synthetic dataset with the same pose distribution as [SPEED](#glo.main.speed).
    After training with the new texture-randomised dataset, the proposed network performs
    better on spaceborne images and scores 4th place in [KPEC](#glo.main.kpec).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到缺乏具有代表性纹理和表面照明特性的实际空间数据集，Park等人[[46](#bib.bib46)]还通过一种新的训练程序来提高[ CNNs](#glo.main.cnn)对仅在合成数据上训练的空间影像的鲁棒性。受参考文献[[50](#bib.bib50)]的启发，他们通过将神经风格迁移技术[[51](#bib.bib51)]应用于具有与[SPEED](#glo.main.speed)相同姿态分布的自定义合成数据集，生成了一个新的数据集。在用新的纹理随机化数据集训练之后，提出的网络在空间影像上的表现更好，并在[KPEC](#glo.main.kpec)中获得了第4名。
- en: '![Refer to caption](img/66716a84c8d0e46152c0015a2ef30f86.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/66716a84c8d0e46152c0015a2ef30f86.png)'
- en: (a) Pose estimation network
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 姿态估计网络
- en: '![Refer to caption](img/b8cba0744ac12e7639bad0d4cd231ae9.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/b8cba0744ac12e7639bad0d4cd231ae9.png)'
- en: (b) Different convolution operations
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 不同的卷积操作
- en: 'Figure 9: Proposed [DNN](#glo.main.dnn) framework in Ref. [[46](#bib.bib46)]
    and comparison of three convolution operations.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '图 9: 参考文献[[46](#bib.bib46)]中提出的[DNN](#glo.main.dnn)框架以及三种卷积操作的比较。'
- en: The 1st place [KPEC](#glo.main.kpec) solution is also an indirect \glsxtrshortdl-based
    scheme proposed by Chen et al. [[20](#bib.bib20)], where [DL](#glo.main.dl) and
    geometric optimisation are combined to present a \glsxtrshortcnn-based pipeline
    for pose estimation from a single image. Firstly, [3D](#glo.main.3d) landmarks
    of the satellite are computed from the training set via multiview triangulation.
    A [High-Resolution Net (HRNet)](#glo.main.hrnet) [[52](#bib.bib52)] is then trained
    to regress the location of projected [2D](#glo.main.2d) corner point landmarks
    on the spacecraft from the input greyscale image. Finally, the optimal poses are
    obtained by the proposed geometric optimisation algorithm based on simulated annealing,
    where the initial pose is estimated from a [P$n$P](#glo.main.pnp) solver. More
    specifically, the proposed [DNN](#glo.main.dnn) framework contains two modules.
    The first uses an [HRNet](#glo.main.hrnet) front-end/Faster [R-CNN](#glo.main.rcnn)
    combination to detect the [2D](#glo.main.2d) bounding box of the target in the
    input image. The [RoI](#glo.main.roi) is then cropped and resized for use in the
    second model, which consists of a pure [HRNet](#glo.main.hrnet) and is trained
    on an [MSE](#glo.main.mse) loss between the predicted and ground truth heatmaps
    of the visible landmarks in each image.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 第一名的[KPEC](#glo.main.kpec)解决方案也是陈等人提出的基于\glsxtrshortdl的间接方案[[20](#bib.bib20)]，其中[DL](#glo.main.dl)和几何优化相结合，呈现出一个基于\glsxtrshortcnn的管道，用于从单幅图像中进行姿态估计。首先，通过多视角三角测量从训练集中计算卫星的[3D](#glo.main.3d)标志点。然后，训练一个[高分辨率网络
    (HRNet)](#glo.main.hrnet) [[52](#bib.bib52)]来回归从输入灰度图像中投影的[2D](#glo.main.2d)角点标志物的位置。最后，通过基于模拟退火的几何优化算法获得最佳姿态，其中初始姿态是通过[P$n$P](#glo.main.pnp)求解器估计的。更具体地说，提出的[DNN](#glo.main.dnn)框架包含两个模块。第一个模块使用[HRNet](#glo.main.hrnet)前端和Faster
    [R-CNN](#glo.main.rcnn)组合来检测输入图像中目标的[2D](#glo.main.2d)边界框。然后对[RoI](#glo.main.roi)进行裁剪和调整大小，以便在第二个模型中使用，第二个模型由纯[HRNet](#glo.main.hrnet)构成，并在每张图像中预测的可见标志点的热图与实际热图之间的[MSE](#glo.main.mse)损失上进行训练。
- en: 'To achieve a fast and accurate estimate of the pose, Huo et al. [[53](#bib.bib53)]
    developed a novel [DLs](#glo.main.dl)-based approach combining [P$n$P](#glo.main.pnp)
    and geometric optimisation. A new and lightweight tiny-YOLOv3 based framework
    is designed to predict the [2D](#glo.main.2d) locations of the projected keypoints
    of the constructed [3D](#glo.main.3d) model. Fig. [10](#S2.F10 "Figure 10 ‣ 2.4
    Indirect Frameworks for Spacecraft Relative Pose Estimation ‣ 2 \glsfmtshortdl-based
    Pose Estimation for Spacecraft Relative Navigation ‣ Deep Learning-based Spacecraft
    Relative Navigation Methods: A Survey") shows the corresponding regression network,
    in which the output of tiny-YOLOv3 is modified to establish a box reliability
    judgement mode for detecting the [S/C](#glo.main.sc) and predicting the [2D](#glo.main.2d)
    [RoI](#glo.main.roi). Next, the regression of [S/C](#glo.main.sc) keypoints is
    achieved by replacing the [FCLs](#glo.main.fl) with [CLs](#glo.main.cl) to yield
    heatmaps. Finally, [P$n$P](#glo.main.pnp) and bundle adjustment are utilised to
    generate the initial pose and optimise it, respectively, which improves the accuracy
    and robustness of the proposed approach. Their method is evaluated on the [SPEED](#glo.main.speed)
    dataset and achieves competitive performance in spacecraft pose estimation with
    a lighter computational footprint.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '为了实现快速准确的姿态估计，Huo 等人 [[53](#bib.bib53)] 开发了一种基于**DLs**的创新方法，该方法结合了[P$n$P](#glo.main.pnp)和几何优化。设计了一个新的轻量级
    tiny-YOLOv3 框架，用于预测构建的[3D](#glo.main.3d)模型的投影关键点的[2D](#glo.main.2d)位置。图[10](#S2.F10
    "Figure 10 ‣ 2.4 Indirect Frameworks for Spacecraft Relative Pose Estimation ‣
    2 \glsfmtshortdl-based Pose Estimation for Spacecraft Relative Navigation ‣ Deep
    Learning-based Spacecraft Relative Navigation Methods: A Survey")显示了相应的回归网络，其中tiny-YOLOv3的输出被修改，以建立一个用于检测[S/C](#glo.main.sc)并预测[2D](#glo.main.2d)[RoI](#glo.main.roi)的框可靠性判断模式。接下来，通过用[CLs](#glo.main.cl)替换[FCLs](#glo.main.fl)来生成热图，实现了[S/C](#glo.main.sc)关键点的回归。最后，利用[P$n$P](#glo.main.pnp)和束调整生成初始姿态并分别进行优化，从而提高了所提方法的准确性和鲁棒性。他们的方法在[SPEED](#glo.main.speed)数据集上进行了评估，在航天器姿态估计方面表现出色，并且计算负担更轻。'
- en: '![Refer to caption](img/e1c9c38ee9bb692e3d832bd46c2dc697.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e1c9c38ee9bb692e3d832bd46c2dc697.png)'
- en: 'Figure 10: The overall structure of the network designed by Huo et al. [[53](#bib.bib53)].'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：Huo 等人 [[53](#bib.bib53)] 设计的网络总体结构。
- en: Another indirect [DLs](#glo.main.dl)-based scheme combines a \glsxtrshortcnn-based
    feature detector with a [P$n$P](#glo.main.pnp) solver and an [Extended Kalman
    Filter (EKF)](#glo.main.ekf) to guarantee a robust pose estimation [[27](#bib.bib27)].
    The authors build an hourglass-shaped [CNN](#glo.main.cnn) composed of a six-block
    encoder and a six-block decoder to estimate the heatmaps of $16$ predefined corners
    on the Envisat spacecraft. A target detection module is not incorporated since
    the presence of Earth in the background is not considered. Using the weights from
    the heatmaps, an associated landmark covariance is calculated. Two testing campaigns
    are then performed. The first one uses a dataset composed of singular images and
    computes the relative pose by incorporating the covariance of the regressed landmarks
    into the [P$n$P](#glo.main.pnp) procedure [[54](#bib.bib54)]. The second campaign
    considers a sequential dataset simulating a V-bar approach with Envisat at a fixed
    relative distance, where the target performs a roll rotation with respect to the
    [Local-Vertical, Local-Horizontal (LVLH)](#glo.main.lvlh) frame of reference.
    The relative pose is estimated by a tightly coupled [EKF](#glo.main.ekf) based
    on a Clohessy-Wiltshire dynamical model. Sensor measurements input of the filter,
    the landmark locations and covariances, come from the [CNN](#glo.main.cnn). The
    filter achieves steady-state position errors inferior to $0.2\text{\,}\mathrm{m}$
    for all axes, and the attitude errors are under $2\text{\,}\mathrm{deg}$.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种间接的[DLs](#glo.main.dl)基础方案将一个基于\glsxtrshortcnn的特征检测器与一个[P$n$P](#glo.main.pnp)求解器和一个[扩展卡尔曼滤波器
    (EKF)](#glo.main.ekf)结合，以确保稳健的姿态估计[[27](#bib.bib27)]。作者构建了一个沙漏形状的[CNN](#glo.main.cnn)，由一个六块编码器和一个六块解码器组成，用于估计Envisat航天器上$16$个预定义角点的热图。由于背景中地球的存在未被考虑，目标检测模块未被纳入。利用热图中的权重，计算了相关地标协方差。然后进行了两个测试阶段。第一个阶段使用由单张图像组成的数据集，并通过将回归地标的协方差纳入[P$n$P](#glo.main.pnp)程序中来计算相对姿态[[54](#bib.bib54)]。第二个阶段考虑了一个模拟V-bar接近的序列数据集，其中Envisat在固定相对距离下进行滚转，与[局部垂直-局部水平
    (LVLH)](#glo.main.lvlh)参考系相关。相对姿态通过基于Clohessy-Wiltshire动力学模型的紧耦合[EKF](#glo.main.ekf)进行估计。滤波器的传感器测量输入包括地标位置和协方差，来自[CNN](#glo.main.cnn)。该滤波器在所有轴上达到低于$0.2\text{\,}\mathrm{m}$的稳态位置误差，姿态误差低于$2\text{\,}\mathrm{deg}$。
- en: 'A pipeline similar to Ref. [[53](#bib.bib53)] is investigated by Huan et al.
    [[21](#bib.bib21)], achieving results nearly an order of magnitude better in the
    precision and accuracy of position and attitude estimation relative to the [SPN](#glo.main.spn)
    framework. The training methodology consists of four steps: 1) manual selection
    of images from the training dataset to be used for the reconstruction of the target
    [3D](#glo.main.3d) model, 2) detection of the [2D](#glo.main.2d) bounding box
    by an [ODN](#glo.main.odn), 3) estimation of the [2D](#glo.main.2d) image location
    of keypoints from a [KRN](#glo.main.krn), and 4) projection of the [3D](#glo.main.3d)
    groundtruth keypoints onto the image plane and solving the [P$n$P](#glo.main.pnp)
    problem from the correspondences with the estimated keypoints. Differing from
    Ref. [[53](#bib.bib53)], the proposed target detection network and [KRN](#glo.main.krn)
    in Ref. [[21](#bib.bib21)] apply the state-of-the-art [HRNet](#glo.main.hrnet)
    as backbone. The 6-[DoF](#glo.main.dof) pose is finally predicted by non-linear
    minimisation of a Huber reprojection loss. The training dataset is constructed
    of synthesised greyscale images, and the test set images are captured in real-time
    using a monocular camera.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Huan等人[[21](#bib.bib21)]研究了一种类似于Ref. [[53](#bib.bib53)]的流程，在位置和姿态估计的精度和准确度方面，相对于[SPN](#glo.main.spn)框架取得了近一个数量级的改进。训练方法包括四个步骤：1)
    从训练数据集中手动选择用于重建目标[3D](#glo.main.3d)模型的图像，2) 通过[ODN](#glo.main.odn)检测[2D](#glo.main.2d)边界框，3)
    从[KRN](#glo.main.krn)中估计关键点的[2D](#glo.main.2d)图像位置，4) 将[3D](#glo.main.3d)真实关键点投影到图像平面上，并从与估计关键点的对应关系中解决[P$n$P](#glo.main.pnp)问题。与Ref.
    [[53](#bib.bib53)]不同的是，Ref. [[21](#bib.bib21)]中的目标检测网络和[KRN](#glo.main.krn)采用了最先进的[HRNet](#glo.main.hrnet)作为骨干网络。最终通过Huber重投影损失的非线性最小化来预测6-[DoF](#glo.main.dof)姿态。训练数据集由合成的灰度图像构成，测试集图像则使用单目相机实时捕获。
- en: Shi et al. [[6](#bib.bib6)] transfer the state-of-the-art [CNN](#glo.main.cnn)
    techniques to target CubeSat detection, but with no further discussion on pose
    estimation. Inception-ResNet-V2 [[55](#bib.bib55)] and ResNet-101 [[37](#bib.bib37)]
    are combined and trained to estimate the bounding box of the target [S/C](#glo.main.sc)
    with a laboratory test platform. The final [FCL](#glo.main.fl) of ResNet-101 is
    reduced to two classes to differentiate between the "1U_CubeSat" and "3U_CubeSat"
    labels. The pre-trained weights of the [CNN](#glo.main.cnn) are obtained from
    the [COCO](#glo.main.coco) dataset [[56](#bib.bib56)] and further trained on a
    mixture of real and synthetic CubeSat images. Their simulation results indicate
    that the Inception-ResNet-V2 framework achieves a slightly higher accuracy and
    precision for [S/C](#glo.main.sc) detection, whereas the ResNet-101 network is
    less computationally heavy. To tackle a similar problem, Ming [[57](#bib.bib57)]
    constructs a feature extraction network and [Region Proposal Network (RPN)](#glo.main.rpn)
    structure framework based on Faster [R-CNN](#glo.main.rcnn) [[32](#bib.bib32)]
    on the [CNN](#glo.main.cnn) Caffe [[58](#bib.bib58)] open platform. The proposed
    network performs intelligent identification of a spacecraft module in the image
    sequence and filters out the certain components of interest.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: Shi 等人 [[6](#bib.bib6)] 将最先进的 [CNN](#glo.main.cnn) 技术应用于目标 CubeSat 检测，但未进一步讨论姿态估计。Inception-ResNet-V2
    [[55](#bib.bib55)] 和 ResNet-101 [[37](#bib.bib37)] 被结合并训练，以估计目标 [S/C](#glo.main.sc)
    的边界框，使用实验室测试平台。ResNet-101 的最终 [FCL](#glo.main.fl) 被减少为两个类别，以区分“1U_CubeSat”和“3U_CubeSat”标签。预训练的
    [CNN](#glo.main.cnn) 权重来自 [COCO](#glo.main.coco) 数据集 [[56](#bib.bib56)]，并在实际和合成的
    CubeSat 图像混合数据上进一步训练。他们的模拟结果表明，Inception-ResNet-V2 框架在 [S/C](#glo.main.sc) 检测中实现了略高的准确性和精确度，而
    ResNet-101 网络则计算负担较轻。为解决类似问题，Ming [[57](#bib.bib57)] 基于 Faster [R-CNN](#glo.main.rcnn)
    [[32](#bib.bib32)] 在 [CNN](#glo.main.cnn) Caffe [[58](#bib.bib58)] 开放平台上构建了一个特征提取网络和
    [区域提议网络 (RPN)](#glo.main.rpn) 结构框架。所提网络在图像序列中智能识别航天器模块，并过滤出特定感兴趣的组件。
- en: For other space missions beyond rendezvous, Yi [[59](#bib.bib59)] studies the
    relative position estimation problem of a docking mission (below $10\text{\,}\mathrm{m}$).
    Assuming relative attitude has been adjusted, the method utilises a modified VGG-16
    to regress the relative position between docking rings. Further position smoothing
    and relative speed estimation are achieved by Kalman filtering. Additionally,
    a satellite positioning error compensation technique based on [DL](#glo.main.dl)
    is discussed by Jiaming [[60](#bib.bib60)]. Large amounts of data are collected
    to generate a robust model; a [CNN](#glo.main.cnn), a depth belief network, and
    a [Recurrent Neural Network (RNN)](#glo.main.rnn) are trained on satellite location
    data are collected by the Institute of Technology of the Chinese Academy of Sciences,
    which aims to generate a robust model. A [CNN](#glo.main.cnn), a depth belief
    network, and a [RNN](#glo.main.rnn) are trained on the collected data, of which
    the [CNN](#glo.main.cnn) performs the best compensation result.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他超越会合的太空任务，Yi [[59](#bib.bib59)] 研究了对接任务的相对位置估计问题（低于 $10\text{\,}\mathrm{m}$）。假设相对姿态已经调整，该方法利用修改后的
    VGG-16 来回归对接环之间的相对位置。进一步的位置平滑和相对速度估计通过卡尔曼滤波实现。此外，Jiaming [[60](#bib.bib60)] 讨论了一种基于
    [DL](#glo.main.dl) 的卫星定位误差补偿技术。大量数据被收集以生成一个鲁棒的模型；一个 [CNN](#glo.main.cnn)、一个深度置信网络和一个
    [递归神经网络 (RNN)](#glo.main.rnn) 在由中国科学院技术研究所收集的卫星位置数据上进行训练，目的是生成一个鲁棒的模型。一个 [CNN](#glo.main.cnn)、一个深度置信网络和一个
    [RNN](#glo.main.rnn) 在收集的数据上进行训练，其中 [CNN](#glo.main.cnn) 产生了最佳的补偿结果。
- en: 'Table 2: Summary of \glsxtrshortdl-based indirect pose estimation methods for
    spacecraft relative navigation.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 基于 \glsxtrshortdl 的航天器相对导航间接姿态估计方法汇总。'
- en: '[b] Ref. Backbone Transfer Type Dataset Pose estimation by learning [[46](#bib.bib46)]
    YOLO, MobileNet ✗ Keypoint regressor Synthetic (\glsxtrshortnst¹ ), [SPEED](#glo.main.speed)
    [P$n$P](#glo.main.pnp) [[20](#bib.bib20)] [HRNet](#glo.main.hrnet) + Faster [R-CNN](#glo.main.rcnn)
    ✗ Keypoint regressor [SPEED](#glo.main.speed) [P$n$P](#glo.main.pnp) [[53](#bib.bib53)]
    tiny-YOLOv3 [COCO](#glo.main.coco) Keypoint regressor [SPEED](#glo.main.speed)
    [P$n$P](#glo.main.pnp) [[27](#bib.bib27)] Hourglass network ✗ Keypoint regressor
    Synthetic (Cinema 4D, Envisat [S/C](#glo.main.sc)) [P$n$P](#glo.main.pnp) + [EKF](#glo.main.ekf)
    [[21](#bib.bib21)] 2-layer [CNN](#glo.main.cnn) ✗ Keypoint regressor Synthetic,
    real (lab) [P$n$P](#glo.main.pnp) [[59](#bib.bib59)] VGG-16 ✗ Position regressor
    Synthetic (Blender) [EKF](#glo.main.ekf) [[6](#bib.bib6)] ResNet [COCO](#glo.main.coco)
    Classifier Synthetic, real CubeSat detection [[57](#bib.bib57)] Faster [R-CNN](#glo.main.rcnn)
    ✗ Regressor Synthetic Object detection [[60](#bib.bib60)] [LSTM](#glo.main.lstm)
    ✗ Regressor Real Position error compensation'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[b] 参考文献 主干 转移类型 数据集 学习中姿态估计 [[46](#bib.bib46)] YOLO, MobileNet ✗ 关键点回归器 合成
    (\glsxtrshortnst¹ ), [SPEED](#glo.main.speed) [P$n$P](#glo.main.pnp) [[20](#bib.bib20)]
    [HRNet](#glo.main.hrnet) + Faster [R-CNN](#glo.main.rcnn) ✗ 关键点回归器 [SPEED](#glo.main.speed)
    [P$n$P](#glo.main.pnp) [[53](#bib.bib53)] tiny-YOLOv3 [COCO](#glo.main.coco) 关键点回归器
    [SPEED](#glo.main.speed) [P$n$P](#glo.main.pnp) [[27](#bib.bib27)] Hourglass 网络
    ✗ 关键点回归器 合成 (Cinema 4D, Envisat [S/C](#glo.main.sc)) [P$n$P](#glo.main.pnp) +
    [EKF](#glo.main.ekf) [[21](#bib.bib21)] 2层 [CNN](#glo.main.cnn) ✗ 关键点回归器 合成, 实验室
    (实际) [P$n$P](#glo.main.pnp) [[59](#bib.bib59)] VGG-16 ✗ 位置回归器 合成 (Blender) [EKF](#glo.main.ekf)
    [[6](#bib.bib6)] ResNet [COCO](#glo.main.coco) 分类器 合成, 实际 CubeSat 检测 [[57](#bib.bib57)]
    Faster [R-CNN](#glo.main.rcnn) ✗ 回归器 合成 物体检测 [[60](#bib.bib60)] [LSTM](#glo.main.lstm)
    ✗ 回归器 实际 位置误差补偿'
- en: 1\glsxtrlong
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1\glsxtrlong
- en: '*nst; applied to randomise the texture of the spacecraft.'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*nst; 应用于随机化飞行器的纹理。'
- en: 'Table [2](#S2.T2 "Table 2 ‣ 2.4 Indirect Frameworks for Spacecraft Relative
    Pose Estimation ‣ 2 \glsfmtshortdl-based Pose Estimation for Spacecraft Relative
    Navigation ‣ Deep Learning-based Spacecraft Relative Navigation Methods: A Survey")
    contains a brief summary of indirect \glsxtrshortdl-based  algorithms for spacecraft
    pose estimation and related applications. As illustrated, the earlier studies
    (last four referenced) are more focused on parts of pose estimation missions,
    such as detection and position estimation. [P$n$P](#glo.main.pnp) and [EKF](#glo.main.ekf)
    are commonly combined to refine poses output by [DNNs](#glo.main.dnn). Moreover,
    transfer learning and very deep networks are rarely utilised when [DL](#glo.main.dl)
    methods are combined with optimisers. This could potentially be due to the fact
    that the pipelines rely heavily on these optimisation steps at the end, which
    are able to guarantee a decent estimate of the pose. In this way, shallow networks
    can reduce the computational cost, which is beneficial for practical use and potential
    onboard implementations.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 [2](#S2.T2 "Table 2 ‣ 2.4 Indirect Frameworks for Spacecraft Relative Pose
    Estimation ‣ 2 \glsfmtshortdl-based Pose Estimation for Spacecraft Relative Navigation
    ‣ Deep Learning-based Spacecraft Relative Navigation Methods: A Survey") 包含了间接
    \glsxtrshortdl-based 飞行器姿态估计和相关应用的简要总结。如图所示，早期的研究（最后四篇引用的）更侧重于姿态估计任务的部分，例如检测和位置估计。[P$n$P](#glo.main.pnp)
    和 [EKF](#glo.main.ekf) 通常结合使用来优化 [DNNs](#glo.main.dnn) 输出的姿态。此外，当 [DL](#glo.main.dl)
    方法与优化器结合使用时，迁移学习和非常深的网络很少被利用。这可能是因为这些管道在最后阶段高度依赖于这些优化步骤，这些步骤能够保证姿态的合理估计。这样，浅层网络可以降低计算成本，这对实际使用和潜在的机载实施是有利的。'
- en: 3 Crater and Hazard Detection for Terrain Navigation Using \glsfmtshortdl
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 火山口和危险检测用于地形导航，使用 \glsfmtshortdl
- en: 'Exploring and landing on the lunar surface has long been a challenge of great
    interest within space technology and science. Recent developments in [DL](#glo.main.dl)
    have led to a renewed interest in learning-based [TRN](#glo.main.trn). Craters
    are ideal landmarks for relative navigation on or around the Moon and asteroids
    [[61](#bib.bib61), [62](#bib.bib62)]. Additionally, hazards should be avoided
    for a successful landing mission. This section, therefore, reviews the field of
    \glsxtrshortdl-based terrain navigation in three aspects: crater detection, hazard
    detection, and [TRN](#glo.main.trn) methods, all using [DNNs](#glo.main.dnn).
    Figure [11](#S3.F11 "Figure 11 ‣ 3 Crater and Hazard Detection for Terrain Navigation
    Using \glsfmtshortdl ‣ Deep Learning-based Spacecraft Relative Navigation Methods:
    A Survey") shows schematic diagram and difference between the three aspects.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 探索和登陆月球表面长期以来一直是空间技术和科学中备受关注的挑战。最近在[深度学习](#glo.main.dl)领域的进展重新激发了对基于学习的[地形相对导航](#glo.main.trn)的兴趣。陨石坑是月球和小行星表面相对导航的理想标志物[[61](#bib.bib61),
    [62](#bib.bib62)]。此外，为了成功着陆，必须避免危险。因此，本节从三个方面回顾了基于\glsxtrshortdl的地形导航领域：陨石坑检测、危险检测和[地形相对导航](#glo.main.trn)方法，均使用[DNNs](#glo.main.dnn)。图[11](#S3.F11
    "图 11 ‣ 基于\glsfmtshortdl的深度学习月球相对导航方法的陨石坑和危险检测 ‣ 调查")展示了这三个方面的示意图和区别。
- en: '![Refer to caption](img/75897c183cc696dc39ae6de7b5b96275.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/75897c183cc696dc39ae6de7b5b96275.png)'
- en: 'Figure 11: Scenarios of crater detection, hazard detection for safe landing
    area, and terrain navigation.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：陨石坑检测、危险检测以确保安全着陆区域及地形导航的场景。
- en: 3.1 Crater detection
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 陨石坑检测
- en: With advances in computer vision and successful applications of [CNNs](#glo.main.cnn)
    in the object detection area, CNN-based crater detection algorithms are also emerging.
    However, most of the earlier methods only utilise a [CNN](#glo.main.cnn) as a
    classifier to validate selected features, such as in Refs. [[63](#bib.bib63),
    [64](#bib.bib64), [65](#bib.bib65)]. The shapes of natural craters vary in morphology,
    including peak rings, central pits, and wall terraces [[66](#bib.bib66)]. Some
    craters may also overlap with others. Considering the illumination conditions
    and different poses of on-board cameras, the imaged craters can be diverse in
    terms of dimensions and appearance [[61](#bib.bib61)]. Conversely, robust crater
    detection algorithms have been developed by applying [DNNs](#glo.main.dnn) to
    fully process raw crater images, exhibiting promising results which have attracted
    a lot of interest.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 随着计算机视觉的进步和[CNNs](#glo.main.cnn)在目标检测领域的成功应用，基于 CNN 的陨石坑检测算法也开始出现。然而，大多数早期方法仅将[CNN](#glo.main.cnn)用作分类器来验证选定特征，如参考文献[[63](#bib.bib63),
    [64](#bib.bib64), [65](#bib.bib65)]。自然陨石坑的形状在形态上各不相同，包括峰环、中央凹坑和壁阶[[66](#bib.bib66)]。一些陨石坑可能还会重叠。考虑到照明条件和机载相机的不同姿态，成像的陨石坑在尺寸和外观上可能会有所不同[[61](#bib.bib61)]。相反，已通过应用[DNNs](#glo.main.dnn)对原始陨石坑图像进行全面处理，开发出稳健的陨石坑检测算法，显示出有前景的结果，吸引了大量兴趣。
- en: The [Python Crater Detection Algorithm (PyCDA)](#glo.main.pycda) [[67](#bib.bib67)]
    is an open-source crater detection library composed of a detector, extractor,
    and classifier, which focuses on detecting new craters that have never been catalogued.
    [PyCDA](#glo.main.pycda) uses a downsized U-Net architecture to compute the per-pixel
    likelihoods of a crater rim from inputs of greyscale intensity images. The pixel
    prediction map is then fed to the extractor to generate a list of crater candidates.
    A classifier [CNN](#glo.main.cnn) is finally applied to determine true craters.
    Thanks to [PyCDA](#glo.main.pycda), a considerable amount of craters have been
    detected and categorised, thus helping to generate new labelled datasets for training
    and testing of [DL](#glo.main.dl) algorithms.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '[Python 陨石坑检测算法 (PyCDA)](#glo.main.pycda) [[67](#bib.bib67)] 是一个开源的陨石坑检测库，包括检测器、提取器和分类器，专注于检测从未被编目过的新陨石坑。[PyCDA](#glo.main.pycda)
    使用缩小版的 U-Net 架构，从灰度强度图像输入中计算每个像素的陨石坑边缘可能性。然后将像素预测图传递给提取器，以生成陨石坑候选列表。最后，应用分类器[CNN](#glo.main.cnn)来确定真正的陨石坑。得益于[PyCDA](#glo.main.pycda)，大量陨石坑已被检测和分类，从而帮助生成新的标记数据集，以便训练和测试[深度学习](#glo.main.dl)算法。'
- en: '![Refer to caption](img/48e5a04cb00d63f76365458d61f28abe.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/48e5a04cb00d63f76365458d61f28abe.png)'
- en: 'Figure 12: Framework of CraterIDNet reproduced from Wang et al. [[61](#bib.bib61)].'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：Wang 等人复现的 CraterIDNet 框架 [[61](#bib.bib61)]。
- en: 'Wang et al. [[61](#bib.bib61)] proposed an end-to-end fully [CNN](#glo.main.cnn),
    CrateIDNet, for simultaneous crater detection and identification. CraterIDNet
    takes remote sensing images in various sizes and outputs detected crater positions,
    apparent diameters, and indices of the identified craters. Instead of using large
    off-the-shelf [DNN](#glo.main.dnn) models, a small [CNN](#glo.main.cnn) architecture
    pre-trained on Martian crater samples [[68](#bib.bib68)] is first developed to
    extract feature maps. Next, two pipelines, namely [Crater Detection (CD)](#glo.main.cd)
    and [Crater Identification (CI)](#glo.main.ci) are proposed for simultaneous detecting
    and identifying craters. The [CD](#glo.main.cd) process involves detecting the
    presence of craters and locating them within the image if they exist. The output
    of [CD](#glo.main.cd) is then fed to the [CI](#glo.main.ci) process to match the
    detected craters to surface landmarks in a known database, and matches of [CI](#glo.main.ci)
    will provide position estimation. Fig. [12](#S3.F12 "Figure 12 ‣ 3.1 Crater detection
    ‣ 3 Crater and Hazard Detection for Terrain Navigation Using \glsfmtshortdl ‣
    Deep Learning-based Spacecraft Relative Navigation Methods: A Survey") shows the
    whole framework of CraterIDNet. The [CD](#glo.main.cd) modifies the [RPN](#glo.main.rpn)
    architecture [[32](#bib.bib32)] as the backbone, regressing objectness scores
    and crater diameters from feature maps. Due to different craters sizes, two [CD](#glo.main.cd)
    pipelines are designed by sharing same [CLs](#glo.main.cl) but with different
    parameters. Later, craters are identified by [CI](#glo.main.ci) that combines
    a proposed grid pattern layer and [CNN](#glo.main.cnn) framework. For the training
    and testing dataset, $1600$ craters are manually catalogued and enlarged to a
    final sample set of $16\,000$ instances through data augmentation. Experiments
    reveal that the light CraterIDNet with a size of $4\text{\,}\mathrm{MB}$ performs
    better than previous algorithms [[64](#bib.bib64)].'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 'Wang等人[[61](#bib.bib61)] 提出了一个端到端的完全[卷积神经网络](#glo.main.cnn)，CraterIDNet，用于同时检测和识别火山口。CraterIDNet接收各种尺寸的遥感图像，并输出检测到的火山口位置、明显直径以及识别到的火山口索引。与使用大型现成[深度神经网络](#glo.main.dnn)模型不同，首先开发了一个小型的[卷积神经网络](#glo.main.cnn)架构，该架构在火星火山口样本[[68](#bib.bib68)]上进行了预训练，以提取特征图。接下来，提出了两个流程，即[火山口检测（CD）](#glo.main.cd)和[火山口识别（CI）](#glo.main.ci)，用于同时检测和识别火山口。[CD](#glo.main.cd)过程涉及检测图像中是否存在火山口以及定位这些火山口。然后将[CD](#glo.main.cd)的输出馈送给[CI](#glo.main.ci)过程，将检测到的火山口与已知数据库中的地表标志匹配，且[CI](#glo.main.ci)的匹配结果将提供位置估计。图[12](#S3.F12
    "Figure 12 ‣ 3.1 Crater detection ‣ 3 Crater and Hazard Detection for Terrain
    Navigation Using \glsfmtshortdl ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey")显示了CraterIDNet的整体框架。[CD](#glo.main.cd)修改了[RPN](#glo.main.rpn)架构[[32](#bib.bib32)]作为骨干网络，从特征图中回归物体性分数和火山口直径。由于火山口大小不同，设计了两个[CD](#glo.main.cd)流程，通过共享相同的[CLs](#glo.main.cl)但使用不同的参数。随后，通过结合提出的网格模式层和[卷积神经网络](#glo.main.cnn)框架来进行[CI](#glo.main.ci)火山口识别。对于训练和测试数据集，$1600$个火山口被手动编目并通过数据增强扩大到最终的$16\,000$个实例。实验结果表明，体积为$4\text{\,}\mathrm{MB}$的轻量级CraterIDNet表现优于以前的算法[[64](#bib.bib64)]。'
- en: 'Silburt et al. [[69](#bib.bib69)] employ a [CNN](#glo.main.cnn) architecture
    for robust crater detection on the lunar surface using [DEMs](#glo.main.dem).
    The method relies on the developed DeepMoon network to identify the craters in
    terms of their centroid and radius, and outputs pixel-wise confidence maps of
    crater rims on the surface of a rocky body. DeepMoon modifies U-Net [[70](#bib.bib70)]
    by changing the input image size, the number of filters in each convolution layer,
    and the use of dropout [[71](#bib.bib71)] in the expansive path for memory limitations
    and regularisation respectively. Fig. [13](#S3.F13 "Figure 13 ‣ 3.1 Crater detection
    ‣ 3 Crater and Hazard Detection for Terrain Navigation Using \glsfmtshortdl ‣
    Deep Learning-based Spacecraft Relative Navigation Methods: A Survey") presents
    the DeepMoon architecture.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 'Silburt等人[[69](#bib.bib69)]使用[卷积神经网络](#glo.main.cnn)架构进行月球表面的稳健火山口检测，利用[数字高程模型](#glo.main.dem)。该方法依赖于开发的DeepMoon网络来识别火山口的质心和半径，并输出火山口边缘的像素级置信度图。DeepMoon通过更改输入图像尺寸、每个卷积层中的滤波器数量以及在扩展路径中使用dropout[[71](#bib.bib71)]以应对内存限制和正则化，来修改U-Net
    [[70](#bib.bib70)]。图[13](#S3.F13 "Figure 13 ‣ 3.1 Crater detection ‣ 3 Crater
    and Hazard Detection for Terrain Navigation Using \glsfmtshortdl ‣ Deep Learning-based
    Spacecraft Relative Navigation Methods: A Survey")展示了DeepMoon架构。'
- en: '![Refer to caption](img/169cec966705f58b7a07924a3dc257ee.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/169cec966705f58b7a07924a3dc257ee.png)'
- en: 'Figure 13: Architecture of DeepMoon network [[69](#bib.bib69)]'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13：DeepMoon 网络架构 [[69](#bib.bib69)]
- en: For training, the data used in DeepMoon is generated by merging two human-generated
    crater catalogues, which are the [Lunar Reconnaissance Orbiter (LRO)](#glo.main.lro)
    [Wide Angle Camera (WAC)](#glo.main.wac) Global Lunar [DEM](#glo.main.dem) [[72](#bib.bib72)]
    and the [LRO](#glo.main.lro) Lunar Orbiter Laser Altimeter [DEM](#glo.main.dem)
    [[73](#bib.bib73)]. The dataset is split into equal train-validation-test parts,
    yielding $30\,000$ [DEM](#glo.main.dem) images per part. The minimised loss function
    is chosen as the pixel-wise [Binary Cross-Entropy (BCE)](#glo.main.bce). DeepMoon
    produces a crater rim prediction mask, which is then fed to a low-level image
    process and a template matching procedure to determine the actual craters. The
    median fractional longitude, latitude and radius errors are $11\text{\,}\mathrm{\char
    37\relax}$ or less, representing good agreement with the human-generated datasets.
    Additionally, transfer learning from training on lunar maps to testing on maps
    of Mercury is qualitatively demonstrated successfully.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 对于训练，DeepMoon 使用的数据是通过合并两个人工生成的陨石坑目录生成的，这些目录分别是[Lunar Reconnaissance Orbiter
    (LRO)](#glo.main.lro) [Wide Angle Camera (WAC)](#glo.main.wac) 全球月球 [DEM](#glo.main.dem)
    [[72](#bib.bib72)] 和 [LRO](#glo.main.lro) 月球轨道激光高度计 [DEM](#glo.main.dem) [[73](#bib.bib73)]。数据集被分割成相等的训练-验证-测试部分，每部分生成
    $30\,000$ 张 [DEM](#glo.main.dem) 图像。选择的最小化损失函数是按像素计算的 [Binary Cross-Entropy (BCE)](#glo.main.bce)。DeepMoon
    生成一个陨石坑边缘预测掩模，然后将其输入低级图像处理和模板匹配过程，以确定实际的陨石坑。中位数经度、纬度和半径误差为 $11\text{\,}\mathrm{\char
    37\relax}$ 或更少，表示与人工生成的数据集的良好一致性。此外，从月球地图训练到水星地图测试的迁移学习也得到了成功的定性展示。
- en: 'Downes et al. [[25](#bib.bib25)] propose the LunaNet framework to detect craters
    for lunar [TRN](#glo.main.trn), which is quite similar to DeepMoon with the exception
    that it takes greyscale images as inputs. Thus, the method is more suitable for
    implementation aboard a spacecraft equipped with an optical camera without the
    need for a depth sensor. The output of the [CNN](#glo.main.cnn) is, like DeepMoon,
    a crater rim prediction mask. However, the craters are extracted through a different
    method and, Fig. [14](#S3.F14 "Figure 14 ‣ 3.1 Crater detection ‣ 3 Crater and
    Hazard Detection for Terrain Navigation Using \glsfmtshortdl ‣ Deep Learning-based
    Spacecraft Relative Navigation Methods: A Survey") shows each feature extraction
    step of the LunaNet, including prediction mask, eroded and thresholded prediction,
    contour detection, and ellipse fitting. The data preparation is also akin to the
    process followed by DeepMoon, with the [LRO](#glo.main.lro) [WAC](#glo.main.wac)
    Global Lunar [DEM](#glo.main.dem) dataset [[72](#bib.bib72)], followed by a histogram
    rescaling of the input greyscale images to match the intensity distribution of
    a [DEM](#glo.main.dem) image. Based on the pre-trained DeepMoon weights, LunaNet
    reduces the training effort and final detection results. Experimental results
    indicate that LunaNet’s performance surpasses DeepMoon and [PyCDA](#glo.main.pycda)
    in terms of robustness to noisy images, location accuracy, and average crater
    detection time.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 'Downes 等人 [[25](#bib.bib25)] 提出了 LunaNet 框架来检测月球 [TRN](#glo.main.trn) 的陨石坑，该框架与
    DeepMoon 非常相似，不同之处在于它接受灰度图像作为输入。因此，该方法更适合用于配备光学相机的航天器上，而无需深度传感器。与 DeepMoon 一样，[CNN](#glo.main.cnn)
    的输出是一个陨石坑边缘预测掩模。然而，陨石坑是通过不同的方法提取的，图 [14](#S3.F14 "Figure 14 ‣ 3.1 Crater detection
    ‣ 3 Crater and Hazard Detection for Terrain Navigation Using \glsfmtshortdl ‣
    Deep Learning-based Spacecraft Relative Navigation Methods: A Survey") 展示了 LunaNet
    的每个特征提取步骤，包括预测掩模、腐蚀和阈值预测、轮廓检测和椭圆拟合。数据准备过程也类似于 DeepMoon 的过程，包括[LRO](#glo.main.lro)
    [WAC](#glo.main.wac) 全球月球 [DEM](#glo.main.dem) 数据集 [[72](#bib.bib72)]，随后对输入的灰度图像进行直方图重标定，以匹配
    [DEM](#glo.main.dem) 图像的强度分布。基于预训练的 DeepMoon 权重，LunaNet 减少了训练工作量并提高了最终检测结果。实验结果表明，LunaNet
    在对噪声图像的鲁棒性、位置精度和平均陨石坑检测时间方面超越了 DeepMoon 和 [PyCDA](#glo.main.pycda)。'
- en: '![Refer to caption](img/739d448e5b654c1100639e7e56542209.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/739d448e5b654c1100639e7e56542209.png)'
- en: 'Figure 14: Feature extraction steps of LunaNet [[25](#bib.bib25)]'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14：LunaNet 的特征提取步骤 [[25](#bib.bib25)]
- en: 'It has been observed that areas with low solar angles, where there is heavy
    shadowing, result in reduced crater detection reliability. Lee et al. [[74](#bib.bib74)]
    employ a \glsxtrshortcnn-based object detector to distinguish likely landmark
    candidates and predict detection probabilities along various lighting geometric
    flight paths, aiming to identify high-value landmarks by using optical navigation
    systems. A massive dataset based on real lunar-surface data is collected. A [Candidate
    for a Regional Object (CRO)](#glo.main.cro) is defined as an image object with
    specific latitudes and longitudes. The LunarNet architecture (Fig. [15](#S3.F15
    "Figure 15 ‣ 3.1 Crater detection ‣ 3 Crater and Hazard Detection for Terrain
    Navigation Using \glsfmtshortdl ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey"); see also the process of LunarNet-based landmark selection
    in Ref. [[74](#bib.bib74)]) is then used and trained to identify [CROs](#glo.main.cro)
    by maximising the discrimination between local areas of the Moon. Finally, the
    [CRO](#glo.main.cro) performance map is formed based on the scored [CROs](#glo.main.cro)
    arranged by considering the azimuth and elevation angles of the Sun during the
    year. Numerical experimental results demonstrate that the proposed landmark detection
    pipeline can provide usable navigation information even at Sun angle elevations
    of less than $1.8\text{\,}\mathrm{deg}$ in highland areas, which indicates a successful
    application for the worst dark highlands near the South Pole.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '观察发现，在太阳角度较低且阴影严重的区域，陨石坑检测的可靠性降低。Lee 等人 [[74](#bib.bib74)] 使用 \glsxtrshortcnn
    基于的目标检测器来区分可能的地标候选，并预测沿不同光照几何飞行路径的检测概率，旨在通过光学导航系统识别高价值的地标。收集了一个基于真实月球表面数据的大型数据集。定义
    [区域对象候选 (CRO)](#glo.main.cro) 为具有特定纬度和经度的图像对象。然后使用 LunarNet 架构 (图 [15](#S3.F15
    "Figure 15 ‣ 3.1 Crater detection ‣ 3 Crater and Hazard Detection for Terrain
    Navigation Using \glsfmtshortdl ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey")；另见 Ref. [[74](#bib.bib74)] 中基于 LunarNet 的地标选择过程) 进行训练，以通过最大化月球局部区域之间的辨别度来识别
    [CROs](#glo.main.cro)。最后，基于考虑到太阳在一年中的方位角和高度角的得分 [CROs](#glo.main.cro) 形成 [CRO](#glo.main.cro)
    性能图。数值实验结果表明，即使在太阳角度小于 $1.8\text{\,}\mathrm{deg}$ 的高地区域，该地标检测管道也能提供可用的导航信息，这表明在南极附近最黑暗的高地应用成功。'
- en: '![Refer to caption](img/1bdd0b7aab2e0a87de612524ba2915a9.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/1bdd0b7aab2e0a87de612524ba2915a9.png)'
- en: 'Figure 15: \glsxtrshortcnn-based [CRO](#glo.main.cro) discriminator (LunarNet)
    [[74](#bib.bib74)]'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '图 15: \glsxtrshortcnn 基于 [CRO](#glo.main.cro) 鉴别器 (LunarNet) [[74](#bib.bib74)]'
- en: 3.2 Hazard detection
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 危险检测
- en: Hazard detection is considered the vital research field of space [TRN](#glo.main.trn)
    to avoid failures during landing. In 1974, Apollo program officials introduced
    manual hazard and target selection for lunar descent guidance [[75](#bib.bib75)].
    In the past decade, many algorithms have been developed which benefit from the
    increasing computational power of processor devices. Since 2006, promoted by the
    [Autonomous Landing Hazard Avoidance Technology (ALHAT)](#glo.main.alhat) project
    [[76](#bib.bib76)] conducted by the [National Aeronautics and Space Administration
    (NASA)](#glo.main.nasa), there has been growing interest in hazard estimation
    based on [DEMs](#glo.main.dem). In 2012, Furfaro et al. [[77](#bib.bib77)] implemented
    an [AI](#glo.main.ai) system to autonomously select a soft landing site in a region
    with safe terrains for Venus and Titan. In 2015, Maturana and Scherer [[78](#bib.bib78)]
    used what they called a [3D](#glo.main.3d)-[CNN](#glo.main.cnn) to create a safety
    map for autonomous landing zone detection for helicopters.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 危险检测被认为是空间 [TRN](#glo.main.trn) 的重要研究领域，以避免着陆过程中发生故障。1974 年，阿波罗计划官员引入了月球下降引导的手动危险和目标选择
    [[75](#bib.bib75)]。在过去十年中，许多算法得益于处理器设备计算能力的提高。自 2006 年以来，由 [国家航空航天局 (NASA)](#glo.main.nasa)
    进行的 [自主着陆危险规避技术 (ALHAT)](#glo.main.alhat) 项目 [[76](#bib.bib76)] 推动了对基于 [DEMs](#glo.main.dem)
    的危险估计的兴趣。2012 年，Furfaro 等人 [[77](#bib.bib77)] 实施了一个 [AI](#glo.main.ai) 系统，以在具有安全地形的区域内自主选择软着陆点。2015
    年，Maturana 和 Scherer [[78](#bib.bib78)] 使用他们称之为 [3D](#glo.main.3d)-[CNN](#glo.main.cnn)
    的技术为直升机的自主着陆区检测创建了一个安全地图。
- en: 'Earlier research in \glsxtrshortnn-based [Hazard Detection and Avoidance (HDA)](#glo.main.hda)
    for lunar landing is studied by Lunghi and Lavagna [[79](#bib.bib79)] and Lunghi
    et al. [[80](#bib.bib80)], who demonstrate the ability and attractive properties
    of [Artificial Neural Networks (ANNs)](#glo.main.ann) for real-time applications.
    The ground truth is calculated from the corresponding [DEM](#glo.main.dem) by
    thresholding pixel-wise figures. Input images of the terrain are manually processed
    at a resolution of $1024\text{\times}1024\text{\,}\mathrm{p}\mathrm{x}$ to extract
    a $13$-dimensional vector per pixel comprising the image intensity mean, standard
    deviation, gradient and the [Laplacian of Gaussian (LoG)](#glo.main.log) at three
    different scales, and the Sun’s inclination angle. Following this, the crafted
    features are fed to a neural network, outputting a $256\text{\times}256\text{\,}\mathrm{p}\mathrm{x}$
    hazard map with each pixel value denoting a confidence value. From the output
    hazard map, candidate landing sites are obtained via pixel thresholding and scored
    global landing potential by analysing minimum radial dimension requirements, distance
    to an a priori nominal landing site, and the [NN](#glo.main.nn) scores of pixels
    inside the candidate radius. The target landing site is selected as the one that
    maximises the global score. Two different pipelines are developed: one based on
    a [Multilayer Perceptron (MLP)](#glo.main.mlp) with $15$ nodes, and the other
    based on a cascading [NN](#glo.main.nn) with successive layers of hidden information
    added during training. A test set of $8$ images including four landscapes in two
    Sun inclination angles are utilised to evaluate two proposed pipelines. The predicted
    hazard maps during training have a negligible difference, with $0.0194$ for the
    [MLP](#glo.main.mlp) and $0.020\,39$ for the cascade of pixel-wise [MSE](#glo.main.mse).
    However, the former proved better at determining safe landing sites. In addition,
    qualitative results have been presented for asteroid images acquired by the Rosetta
    probe.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 早期在 \glsxtrshortnn 基于 [危险检测与规避 (HDA)](#glo.main.hda) 的研究由 Lunghi 和 Lavagna [[79](#bib.bib79)]
    以及 Lunghi 等人 [[80](#bib.bib80)] 进行，他们展示了 [人工神经网络 (ANNs)](#glo.main.ann) 在实时应用中的能力和吸引人的特性。地面实况通过阈值化像素级数据从相应的
    [数字高程模型 (DEM)](#glo.main.dem) 中计算得出。地形的输入图像以 $1024\text{\times}1024\text{\,}\mathrm{p}\mathrm{x}$
    的分辨率手动处理，以提取每个像素的 $13$ 维向量，包括图像强度均值、标准差、梯度和三种不同尺度下的 [拉普拉斯高斯 (LoG)](#glo.main.log)，以及太阳的倾斜角度。接下来，将提取的特征输入到神经网络中，输出一个
    $256\text{\times}256\text{\,}\mathrm{p}\mathrm{x}$ 的危险图，每个像素值表示置信度值。从输出的危险图中，通过像素阈值化获取候选着陆点，并通过分析最小径向尺寸要求、到先验名义着陆点的距离以及候选半径内像素的
    [NN](#glo.main.nn) 分数来评分全球着陆潜力。目标着陆点被选为最大化全球得分的点。开发了两种不同的管道：一种基于具有 $15$ 个节点的 [多层感知器
    (MLP)](#glo.main.mlp)，另一种基于具有逐层添加隐藏信息的级联 [NN](#glo.main.nn)。利用包括四种地形在两种太阳倾斜角度下的
    $8$ 张图像的测试集来评估这两种管道。训练期间预测的危险图之间的差异可以忽略不计，[MLP](#glo.main.mlp) 为 $0.0194$，而像素级
    [MSE](#glo.main.mse) 的级联为 $0.020\,39$。然而，前者在确定安全着陆点方面表现更好。此外，还展示了由 Rosetta 探测器获取的小行星图像的定性结果。
- en: 'Recently, Moghe and Zanetti [[81](#bib.bib81)] presented a more modern approach
    towards tackling the same problem. Aiming at the hazard detection of the [ALHAT](#glo.main.alhat)
    project, the authors implement an hourglass-like [CNN](#glo.main.cnn) architecture
    with copy and crop connections based on U-Net [[70](#bib.bib70)]. The framework
    processes [DEMs](#glo.main.dem) directly and classifies safe and hazardous landing
    spots with the output map. Through data augmentation and transforming existing
    datasets, they create a new dataset from the [LRO](#glo.main.lro) dataset [[63](#bib.bib63)].
    The output, similarly to Ref. [[80](#bib.bib80)], is a confidence map followed
    by a threshold to yield a binary landing/non-landing score, despite not provide
    a specific landing site. Results on a set of $100$ testing images demonstrate
    an average hazard mapping Dice accuracy score of $83\text{\,}\mathrm{\char 37\relax}$
    and indicate the potential of real-time processing in future missions. Later,
    Moghe and Zanetti [[81](#bib.bib81)] expand and modify their work in Ref. [[82](#bib.bib82)],
    using the same network architecture but featuring improved layers covering the
    input size, output size, and layer width. The topology of the modified network
    is illustrated in Fig. [16](#S3.F16 "Figure 16 ‣ 3.2 Hazard detection ‣ 3 Crater
    and Hazard Detection for Terrain Navigation Using \glsfmtshortdl ‣ Deep Learning-based
    Spacecraft Relative Navigation Methods: A Survey"). Similarly, the Albumentations
    data augmentation suite [[83](#bib.bib83)] is used to prepare data. The modified
    \glsxtrshortcnn-based network outputs a mean pixel accuracy of $\sim 92\text{\,}\mathrm{\char
    37\relax}$ on the same testing dataset of Ref. [[81](#bib.bib81)].'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Moghe 和 Zanetti [[81](#bib.bib81)] 提出了一个更现代的方法来解决相同的问题。针对 [ALHAT](#glo.main.alhat)
    项目的危险检测，作者实现了一个类似沙漏的 [CNN](#glo.main.cnn) 结构，该结构基于 U-Net [[70](#bib.bib70)] 并具有复制和裁剪连接。该框架直接处理
    [DEM](#glo.main.dem) 数据，并通过输出图对安全和危险的着陆点进行分类。通过数据增强和转换现有数据集，他们从 [LRO](#glo.main.lro)
    数据集 [[63](#bib.bib63)] 创建了一个新数据集。输出结果类似于 Ref. [[80](#bib.bib80)]，是一个置信度图，随后应用阈值生成二元着陆/非着陆评分，尽管未提供具体的着陆点。在
    100 张测试图像的结果表明，平均危险映射 Dice 精度分数为 $83\text{\,}\mathrm{\char 37\relax}$，并表明未来任务中实时处理的潜力。随后，Moghe
    和 Zanetti [[81](#bib.bib81)] 在 Ref. [[82](#bib.bib82)] 中扩展和修改了他们的工作，使用相同的网络结构，但改进了涵盖输入大小、输出大小和层宽度的层。修改后的网络的拓扑结构如图
    [16](#S3.F16 "图 16 ‣ 3.2 危险检测 ‣ 3 使用 \glsfmtshortdl 的陨石坑和危险检测 ‣ 基于深度学习的航天器相对导航方法：综述")
    所示。同样地，Albumentations 数据增强套件 [[83](#bib.bib83)] 被用来准备数据。修改后的 \glsxtrshortcnn 基于的网络在
    Ref. [[81](#bib.bib81)] 的相同测试数据集上输出了约 $\sim 92\text{\,}\mathrm{\char 37\relax}$
    的像素平均准确率。
- en: '![Refer to caption](img/a996c183ebb625f1485424dbc8ca3fd6.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/a996c183ebb625f1485424dbc8ca3fd6.png)'
- en: 'Figure 16: The topology of the network in [[82](#bib.bib82)]'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16：网络的拓扑结构见 [[82](#bib.bib82)]
- en: 3.3 Terrain navigation
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 地形导航
- en: In the field of image-based planetary [TRN](#glo.main.trn), Campbell et al.
    [[28](#bib.bib28)] first utilise a [CNN](#glo.main.cnn) architecture trained on
    a series of images rendered from a [DEM](#glo.main.dem) simulating the Apollo
    16 landing site to output the position of a spacecraft relative to the ground
    along one direction. The problem is posed by taking a centre $128\text{\,}\mathrm{p}\mathrm{x}$
    wide strip from the original $1024\text{\times}1024\text{\,}\mathrm{p}\mathrm{x}$
    nadir base image, considering each pixel location along the on-track dimension
    as its own class. $128\text{\times}128\text{\,}\mathrm{p}\mathrm{x}$ training
    images are generated by sampling every $8\text{\,}\mathrm{p}\mathrm{x}$ horizontally
    across the strip and rendering it $11$ times at different Sun illumination angles.
    The $1024$-dimensional one-hot vector, which labels the position along the track
    line, is then applied to each image. The [CNN](#glo.main.cnn) is composed of three
    [CLs](#glo.main.cl) and each followed by a max pooling layer. Thirty images are
    rendered at unseen Sun angles to make up a test dataset. Six of these are classified
    correctly, while in general, the maximum error observed is equal to $5\text{\,}\mathrm{p}\mathrm{x}$.
    For a ground sample distance of $0.5\text{\,}\mathrm{m}$, this means that achieved
    position errors are bounded at $2.5\text{\,}\mathrm{m}$. The testing is repeated
    for training images resampled at $4\text{\,}\mathrm{p}\mathrm{x}$, and the errors
    dropped to a maximum of $3\text{\,}\mathrm{p}\mathrm{x}$ (or $1.5\text{\,}\mathrm{m}$).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于图像的行星[TRN](#glo.main.trn)领域，Campbell等人[[28](#bib.bib28)]首次利用训练于从[DEM](#glo.main.dem)渲染的一系列图像的[CNN](#glo.main.cnn)架构，输出航天器相对于地面的一个方向的位置。问题通过从原始$1024\text{\times}1024\text{\,}\mathrm{p}\mathrm{x}$的天顶基图像中取出一个宽$128\text{\,}\mathrm{p}\mathrm{x}$的中心条带提出，考虑条带上每个像素位置作为其自己的类别。$128\text{\times}128\text{\,}\mathrm{p}\mathrm{x}$的训练图像通过在条带上每$8\text{\,}\mathrm{p}\mathrm{x}$水平采样并在不同的太阳照射角度下渲染$11$次生成。$1024$维的独热向量用于标记沿轨迹线的位置，并应用于每个图像。该[CNN](#glo.main.cnn)由三个[CLs](#glo.main.cl)组成，每个[CL](#glo.main.cl)后面跟着一个最大池化层。渲染了30张在未见过的太阳角度下的图像，以组成测试数据集。六张图像被正确分类，而通常观察到的最大误差为$5\text{\,}\mathrm{p}\mathrm{x}$。对于$0.5\text{\,}\mathrm{m}$的地面采样距离，这意味着实现的位置误差被限制在$2.5\text{\,}\mathrm{m}$。对以$4\text{\,}\mathrm{p}\mathrm{x}$重新采样的训练图像重复测试，误差降至最大$3\text{\,}\mathrm{p}\mathrm{x}$（或$1.5\text{\,}\mathrm{m}$）。
- en: In 2020, Downes et al. [[26](#bib.bib26)] explored how their LunaNet could be
    applied to the [TRN](#glo.main.trn) problem and reported a system for the robust
    estimation of relative position and velocity information. Thus, LunaNet is utilised
    to detect and match craters to known lunar landmarks from frame to frame across
    a trajectory. The matched craters are treated as features feeding to a feature-based
    [EKF](#glo.main.ekf), where the state of the filter is the position and velocity
    of the camera in [Lunar-Centred, Lunar-Fixed Coordinates (LCLF)](#glo.main.lclf),
    as well as the location of detected features in this same reference frame. Compared
    to an image processing-based crater detection method [[84](#bib.bib84)], the LunaNet
    + [EKF](#glo.main.ekf) combination produces considerable improvements on the accuracy
    of the [TRN](#glo.main.trn), with reliable performance in variable lighting conditions.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 2020年，Downes等人[[26](#bib.bib26)]探讨了如何将他们的LunaNet应用于[TRN](#glo.main.trn)问题，并报告了一个用于稳健估计相对位置和速度信息的系统。因此，LunaNet被用来检测和匹配从一个轨迹帧到另一个帧的已知月球地标的陨石坑。匹配的陨石坑被视为特征，输入到基于特征的[EKF](#glo.main.ekf)中，其中滤波器的状态是[Lunar-Centred,
    Lunar-Fixed Coordinates (LCLF)](#glo.main.lclf)下的相机位置和速度，以及在相同参考框架中检测到的特征的位置。与基于图像处理的陨石坑检测方法[[84](#bib.bib84)]相比，LunaNet
    + [EKF](#glo.main.ekf)组合在[TRN](#glo.main.trn)的准确性上有显著提升，并在变光条件下表现可靠。
- en: '![Refer to caption](img/728b3509b5018e25d5fb478916c8646a.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/728b3509b5018e25d5fb478916c8646a.png)'
- en: (a) \glsxtrshortnn-based classification flow
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: (a) \glsxtrshortnn-based classification flow
- en: '![Refer to caption](img/95aa2b8c920dd0d92b31a698b47dc7fd.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/95aa2b8c920dd0d92b31a698b47dc7fd.png)'
- en: (b) The structure of \glsxtrshortdmlp[NN](#glo.main.nn)
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: (b) \glsxtrshortdmlp[NN](#glo.main.nn)的结构
- en: 'Figure 17: \glsxtrshortdmlp[NN](#glo.main.nn) classification flow and proposed
    architecture of Bai et al. [[85](#bib.bib85)].'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '图17: \glsxtrshortdmlp[NN](#glo.main.nn)分类流程和Bai等人[[85](#bib.bib85)]提出的架构。'
- en: 'Accurately identifying the detected terrain environment helps to achieve successful
    missions relying on planetary rovers. However, vision-based [TRN](#glo.main.trn)
    systems are difficult to effectively perceive the material and mechanical characteristics
    of the terrain environment. Thus, Bai et al. [[85](#bib.bib85)] and Chengchao
    [[86](#bib.bib86)] investigate several terrain classification and recognition
    methods from vibration using [DNNs](#glo.main.dnn). The experimental and [NN](#glo.main.nn)
    classification flows are illustrated in Fig. [17(a)](#S3.F17.sf1 "In Figure 17
    ‣ 3.3 Terrain navigation ‣ 3 Crater and Hazard Detection for Terrain Navigation
    Using \glsfmtshortdl ‣ Deep Learning-based Spacecraft Relative Navigation Methods:
    A Survey"). The authors compare three different learning-based approaches towards
    terrain material perception and classification: an improved [NN](#glo.main.nn)
    algorithm, a \glsxtrshortdmlp[NN](#glo.main.nn) algorithm, and [CNN](#glo.main.cnn)-[LSTM](#glo.main.lstm)
    based algorithm. Among these three schemes, the \glsxtrshortdmlp[NN](#glo.main.nn)
    achieves the best performance [[85](#bib.bib85)]. To classify textures, \glsxtrshortdmlp[NN](#glo.main.nn)
    (shown in Fig. [17(b)](#S3.F17.sf2 "In Figure 17 ‣ 3.3 Terrain navigation ‣ 3
    Crater and Hazard Detection for Terrain Navigation Using \glsfmtshortdl ‣ Deep
    Learning-based Spacecraft Relative Navigation Methods: A Survey")) adopts a five-[FCL](#glo.main.fl)
    architecture, in which the activation functions are ReLU and softmax for the first
    four and last layers, respectively. For the dataset and training, three-dimensional
    raw vibration data collected by sensors is first segmented to a vector with a
    fixed duration. Using the fast Fourier transform, the vector is then transferred
    to the frequency domain, in which the eigenvectors are obtained for network training.
    Five different textures, including brick, sand, flat, cement, soil, are trained
    and recognised by \glsxtrshortdmlp[NN](#glo.main.nn) with high overall classification
    accuracy.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 准确识别探测到的地形环境有助于实现依靠行星探测车的成功任务。然而，基于视觉的[TRN](#glo.main.trn)系统难以有效感知地形环境的材料和机械特性。因此，Bai等人[[85](#bib.bib85)]和Chengchao[[86](#bib.bib86)]研究了几种基于振动的地形分类和识别方法，使用[DNNs](#glo.main.dnn)。实验和[NN](#glo.main.nn)分类流程如图[17(a)](#S3.F17.sf1
    "在图17中 ‣ 3.3 地形导航 ‣ 3 利用\glsfmtshortdl进行陨石坑和危险检测 ‣ 基于深度学习的航天器相对导航方法综述")所示。作者比较了三种不同的基于学习的方法来进行地形材料感知和分类：改进的[NN](#glo.main.nn)算法、\glsxtrshortdmlp[NN](#glo.main.nn)算法和基于[CNN](#glo.main.cnn)-[LSTM](#glo.main.lstm)的算法。在这三种方案中，\glsxtrshortdmlp[NN](#glo.main.nn)表现最佳[[85](#bib.bib85)]。为了分类纹理，\glsxtrshortdmlp[NN](#glo.main.nn)（见图[17(b)](#S3.F17.sf2
    "在图17中 ‣ 3.3 地形导航 ‣ 3 利用\glsfmtshortdl进行陨石坑和危险检测 ‣ 基于深度学习的航天器相对导航方法综述")）采用了五层[FCL](#glo.main.fl)架构，其中前四层和最后一层的激活函数分别为ReLU和softmax。对于数据集和训练，首先将传感器收集的三维原始振动数据分割为固定时长的向量。利用快速傅里叶变换，将向量转移到频域，从中获得特征向量用于网络训练。五种不同的纹理，包括砖块、沙子、平整、混凝土和土壤，由\glsxtrshortdmlp[NN](#glo.main.nn)进行高整体分类准确率的训练和识别。
- en: 'For an autonomous lunar landing scenario, Furfaro et al. [[87](#bib.bib87)]
    propose a [DNN](#glo.main.dnn) architecture that predicts the fuel-optimal control
    actions only using raw greyscale images taken by an on-board lander camera (Fig. [18](#S3.F18
    "Figure 18 ‣ 3.3 Terrain navigation ‣ 3 Crater and Hazard Detection for Terrain
    Navigation Using \glsfmtshortdl ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey")). The architecture is a five-layer [CNN](#glo.main.cnn) with
    three sequential images as input for each timestep. The [DNN](#glo.main.dnn) is
    modified with an [LSTM](#glo.main.lstm) back-end connected to two further branches:
    one for regression and one for classification. For training the network, a set
    of optimal trajectories is computed numerically via Gauss pseudo-spectral sampling
    methods using the [General Purpose Optimal Control Software (GPOPS II)](#glo.main.gpops)
    [[88](#bib.bib88)], producing a set of initial and final relative positions and
    velocities. Each state of the optimum trajectory is simulated by raytracing a
    [DEM](#glo.main.dem) of a patch on the Lunar surface, resulting in $562$ images
    with $256\text{\,}\mathrm{p}\mathrm{x}$ $\times$ $256\text{\,}\mathrm{p}\mathrm{x}$
    of resolution. For better performance, the model is retrained explicitly with
    subsets of data that do not produce satisfactory results on the first try [[89](#bib.bib89)].'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '对于自主月球着陆场景，Furfaro等人[[87](#bib.bib87)]提出了一种[DNN](#glo.main.dnn)架构，该架构仅使用由机载着陆相机拍摄的原始灰度图像来预测燃料最优控制动作（见图[18](#S3.F18
    "Figure 18 ‣ 3.3 Terrain navigation ‣ 3 Crater and Hazard Detection for Terrain
    Navigation Using \glsfmtshortdl ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey")）。该架构是一个五层的[CNN](#glo.main.cnn)，每个时间步使用三幅连续图像作为输入。[DNN](#glo.main.dnn)经过修改，配备了一个[LSTM](#glo.main.lstm)后端，连接到两个进一步的分支：一个用于回归，一个用于分类。为了训练网络，通过使用[通用最优控制软件（GPOPS
    II）](#glo.main.gpops) [[88](#bib.bib88)]的高斯伪谱采样方法，数值计算了一组最优轨迹，生成了一组初始和最终的相对位置和速度。最优轨迹的每个状态通过射线追踪月球表面的一块[DEM](#glo.main.dem)来模拟，产生了$562$幅$256\text{\,}\mathrm{p}\mathrm{x}$
    $\times$ $256\text{\,}\mathrm{p}\mathrm{x}$分辨率的图像。为了获得更好的性能，模型会明确地用在第一次尝试中结果不佳的数据子集重新训练[[89](#bib.bib89)]。'
- en: '![Refer to caption](img/4586c8113e426047c5276b9338e427cf.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题说明](img/4586c8113e426047c5276b9338e427cf.png)'
- en: 'Figure 18: The architecture proposed by Furfaro et al. [[87](#bib.bib87)]'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 图18：Furfaro等人提出的架构 [[87](#bib.bib87)]
- en: 3.4 Brief summary
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 简要总结
- en: The use of [DNNs](#glo.main.dnn) in crater and hazard detection has not been
    widely investigated due to the lack of labelled databases. Datasets containing
    crater images which are open to the public do exist, e.g. the Lunar Crater Database⁹⁹9[https://astrogeology.usgs.gov/search/map/Moon/Research/Craters/lunar_crater_database_robbins_2018](https://astrogeology.usgs.gov/search/map/Moon/Research/Craters/lunar_crater_database_robbins_2018).
    [[63](#bib.bib63)] or the Robbins Mars Crater Database [[68](#bib.bib68)]. Yet,
    manually catalogued craters are required for applying supervised [DL](#glo.main.dl)
    methods as presented in [[61](#bib.bib61), [90](#bib.bib90), [25](#bib.bib25),
    [72](#bib.bib72), [73](#bib.bib73)]. There exists still a gap towards the automatic
    generation of [DL](#glo.main.dl) crater datasets, and in the past two years there
    have been increasing studies of [DNNs](#glo.main.dnn) with promising performance
    for [TRN](#glo.main.trn) tasks.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 由于缺乏标注数据库，使用[DNNs](#glo.main.dnn)进行陨石坑和危险检测的研究并不广泛。确实存在一些公开的包含陨石坑图像的数据集，例如月球陨石坑数据库⁹⁹9[https://astrogeology.usgs.gov/search/map/Moon/Research/Craters/lunar_crater_database_robbins_2018](https://astrogeology.usgs.gov/search/map/Moon/Research/Craters/lunar_crater_database_robbins_2018)。[[63](#bib.bib63)]
    或 Robbins火星陨石坑数据库 [[68](#bib.bib68)]。然而，对于应用监督式[DL](#glo.main.dl)方法，如[[61](#bib.bib61),
    [90](#bib.bib90), [25](#bib.bib25), [72](#bib.bib72), [73](#bib.bib73)]所示，仍然需要手动编目的陨石坑。自动生成[DL](#glo.main.dl)陨石坑数据集仍存在差距，在过去两年中，关于[DNNs](#glo.main.dnn)的研究增加了，并且在[TRN](#glo.main.trn)任务中表现出良好的前景。
- en: 4 \glsfmtshortdl-based Relative Navigation for Asteroid Research
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于\glsfmtshortdl的相对导航用于小行星研究
- en: 4.1 Challenges and Motivations for \glsxtrshortdl-based Asteroid Exploration
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: \glsxtrshortdl为小行星探测带来的挑战和动机
- en: Recent trends in small planetary exploration have led to a proliferation of
    studies that include asteroids and comets, pushed by scientific, planetary defence,
    and resource exploitation motivations [[91](#bib.bib91), [92](#bib.bib92)]. Autonomous
    navigation is demanded due to the long communication delay and complicated dynamic
    environment in the vicinity of asteroids [[93](#bib.bib93)]. Thus, it becomes
    necessary to develop new autonomous navigation algorithms for future asteroid
    sample and return missions, for which [DL](#glo.main.dl) techniques may provide
    a potential alternative.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 小型行星探测的近期趋势导致了包括小行星和彗星在内的研究激增，推动力来自科学、行星防御和资源开采动机[[91](#bib.bib91), [92](#bib.bib92)]。由于小行星附近的长通信延迟和复杂动态环境，需要自主导航[[93](#bib.bib93)]。因此，开发新的自主导航算法以用于未来的小行星采样和返回任务变得必要，其中[DL](#glo.main.dl)技术可能提供了一个潜在的替代方案。
- en: 'The aforementioned studies demonstrate the potential of [DNNs](#glo.main.dnn)
    for image patch classification invariant under illumination changes applied to
    terrain navigation. The same principle could be used for other relative navigation
    applications, such as asteroid location pinpointing, illustrated in Fig. [2(b)](#S1.F2.sf2
    "In Figure 2 ‣ 1 Introduction ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey"). [Near-Earth Asteroid (NEA)](#glo.main.nea) missions, however,
    are more challenging than lunar missions; this is because one has limited information
    on the gravitation and environment of asteroids. If the celestial body and its
    orbit environment are in great uncertainty, all plans elaborated on-ground may
    dramatically fail when implemented in space [[94](#bib.bib94)]. Additionally,
    the lack of labelled ground truth data for asteroids challenges the application
    and development of [DL](#glo.main.dl) techniques in asteroid detection and landing
    [[95](#bib.bib95)].'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 前述研究展示了[DNNs](#glo.main.dnn)在处理地形导航中光照变化不变的图像块分类的潜力。相同的原则也可以用于其他相关导航应用，例如小行星定位，如图[2(b)](#S1.F2.sf2
    "在图2 ‣ 1 引言 ‣ 基于深度学习的航天器相对导航方法：综述")所示。然而，[近地小行星 (NEA)](#glo.main.nea)任务比月球任务更具挑战性；这是因为对于小行星的引力和环境信息有限。如果天体及其轨道环境存在很大不确定性，那么所有在地面上制定的计划在空间实施时可能会极其失败[[94](#bib.bib94)]。此外，小行星缺乏标注的真实数据，这也挑战了[DL](#glo.main.dl)技术在小行星探测和着陆中的应用和发展[[95](#bib.bib95)]。
- en: 4.2 Previous Works Contributing to the Field
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 之前对该领域的贡献工作
- en: For asteroid missions, earlier researchers have made various contributions towards
    \glsxtrshortnn-based orbit and dynamics uncertainty estimation. Harl et al. [[96](#bib.bib96)]
    develop a \glsxtrshortnn-based state observer to estimate gravitational uncertainties
    that spacecraft experience in an asteroid orbiting scenario. The [NN](#glo.main.nn)
    of the proposed state observer outputs the uncertainty as a function of the states
    instead of discrete values of an [EKF](#glo.main.ekf). Guffanti [[94](#bib.bib94)]
    trains a neural network as an autonomous motion planning unit to compute the optimal
    spacecraft orbital configuration, which takes the uncertain [NEA](#glo.main.nea)
    dynamics parameters created by navigation filters and the selected trade-off.
    Song et al. [[97](#bib.bib97)] also employ a six-hidden-layer [DNN](#glo.main.dnn)
    to quickly estimate the gravity and gradient of irregular asteroids and further
    apply the [DNN](#glo.main.dnn)-based gravitational model in orbital dynamic analysis.
    Instead of focusing on-orbit estimation, Kalita et al. [[98](#bib.bib98)] introduce
    an [NN](#glo.main.nn) to the formulation of asteroid missions in terms of the
    planning and design phases, while Feruglio et al. [[99](#bib.bib99)] utilise a
    feed-forward [NN](#glo.main.nn) to autonomously identify a [S/C](#glo.main.sc)
    impact event. Viavattene and Ceriotti [[100](#bib.bib100)] take advantage of a
    [NN](#glo.main.nn) to map the transfer time and cost for [NEA](#glo.main.nea)
    rendezvous trajectory.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 对于小行星任务，早期的研究人员在\glsxtrshortnn基础上的轨道和动力学不确定性估计方面做出了各种贡献。Harl等人[[96](#bib.bib96)]开发了一种基于\glsxtrshortnn的状态观测器，以估计航天器在小行星轨道场景中经历的引力不确定性。所提议的状态观测器的[NN](#glo.main.nn)输出作为状态函数的不确定性，而不是[EKF](#glo.main.ekf)的离散值。Guffanti[[94](#bib.bib94)]训练了一个神经网络作为自主运动规划单元，以计算最佳的航天器轨道配置，考虑了由导航滤波器创建的不确定[NEA](#glo.main.nea)动态参数和选择的权衡。Song等人[[97](#bib.bib97)]还使用了一个六层隐藏的[
    DNN](#glo.main.dnn)来快速估计不规则小行星的引力和梯度，并进一步在轨道动力学分析中应用基于[DNN](#glo.main.dnn)的引力模型。Kalita等人[[98](#bib.bib98)]则引入了一个[NN](#glo.main.nn)到小行星任务的规划和设计阶段，而Feruglio等人[[99](#bib.bib99)]利用前馈[NN](#glo.main.nn)来自主识别[S/C](#glo.main.sc)碰撞事件。Viavattene和Ceriotti[[100](#bib.bib100)]利用[NN](#glo.main.nn)来映射[NEA](#glo.main.nea)接近轨迹的转移时间和成本。
- en: \glsxtrshort
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: \glsxtrshort
- en: 'dnn-based optical navigation is an increasingly important area in asteroid
    exploration missions, which can manage challenges of previous schemes, including
    traditional high-cost and high-risk spacecraft systems, irregular and illuminated
    asteroids, and conventional image processing techniques. In such a scenario (Fig. [2(b)](#S1.F2.sf2
    "In Figure 2 ‣ 1 Introduction ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey")), the chaser may be commanded to inspect a particular patch
    on the surface of the asteroid it has rendezvoused with (observed on frame $\underaccent{\vec{}}{\bm{\mathcal{F}}}_{c}$),
    which is intrinsically a localisation task requiring the estimation of ${\bm{T}}_{ct}$.
    If the asteroid has been previously mapped, and there exists a codebook with annotated
    landmarks (on frame $\underaccent{\vec{}}{\bm{\mathcal{F}}}_{t}$) for comparison,
    there are two possible approaches. The first follows the same direct classification
    procedure as Ref. [[28](#bib.bib28)], where a [DNN](#glo.main.dnn) is used to
    match the observed patch with the corresponding patch in the codebook, which is
    annotated with the relative pose, but with the dataset of Lunar surface. The alternative
    approach is to have a single class per patch on the database and train the [DNN](#glo.main.dnn)
    to be robust to viewpoint distortion, and then rely on classical image processing
    techniques to infer the pose based on the different observed features between
    the observations and matched patches.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 DNN 的光学导航在小行星探测任务中越来越重要，这可以解决之前方案的挑战，包括传统的高成本和高风险航天器系统、不规则和被照亮的小行星以及传统图像处理技术。在这种情况下（见图
    [2(b)](#S1.F2.sf2 "在图 2 ‣ 1 介绍 ‣ 基于深度学习的航天器相对导航方法：综述")），追踪器可能会被指令检查它已经会合的小行星表面的特定区域（在帧
    $\underaccent{\vec{}}{\bm{\mathcal{F}}}_{c}$ 上观察到），这本质上是一个定位任务，需要估计 ${\bm{T}}_{ct}$。如果小行星已经被事先绘制了地图，并且存在一个带有标注地标的代码本（在帧
    $\underaccent{\vec{}}{\bm{\mathcal{F}}}_{t}$ 上）用于比较，有两种可能的方法。第一种方法遵循与参考文献 [28](#bib.bib28)
    相同的直接分类程序，其中使用 [DNN](#glo.main.dnn) 将观察到的区域与代码本中对应的区域进行匹配，该代码本带有相对姿态，但数据集为月球表面。另一种方法是对数据库中的每个区域使用单一类别，并训练
    [DNN](#glo.main.dnn) 以对视角失真具有鲁棒性，然后依赖经典图像处理技术根据观察到的特征与匹配区域之间的差异来推断姿态。
- en: 'Pugliatti and Topputo [[101](#bib.bib101)] first present \glsxtrshortcnn-based
    methods for on-board small-body shape classification since shape information can
    enhance the image processing and autonomy of self-task planning. A set of $8$
    well-known models from the [Planetary Data System (PDS)](#glo.main.pds) node^(10)^(10)10[https://sbn.psi.edu/pds/shape-models](https://sbn.psi.edu/pds/shape-models).
    is selected to represent the most important features of small asteroids at a global
    scale. Fig. [19](#S4.F19 "Figure 19 ‣ 4.2 Previous Works Contributing to the Field
    ‣ 4 \glsfmtshortdl-based Relative Navigation for Asteroid Research ‣ Deep Learning-based
    Spacecraft Relative Navigation Methods: A Survey") presents a sketch of the steps
    for building the database and the proposed [CNN](#glo.main.cnn) framework for
    classifying asteroids. The database is generated in Blender with an assumed camera
    pointing and illumination, and further augmented in TensorFlow [[102](#bib.bib102)]
    with random rotations, translations, and scaling. The database composed of $20\,988$
    images is divided into training, validation and test sets according to a $80\text{\,}\mathrm{\char
    37\relax}$-$10\text{\,}\mathrm{\char 37\relax}$-$10\text{\,}\mathrm{\char 37\relax}$
    split. Their [CNN](#glo.main.cnn) architecture has five [CLs](#glo.main.cl) in
    sequence, with each followed by a pooling layer, a reshape operation, and three
    [FCLs](#glo.main.fl) to classify. A hyperparameter search is used to obtain network
    parameters. Three traditional approaches, such as Hu invariant moments, Fourier
    descriptors, and polar outlines, are compared, in which the proposed \glsxtrshortcnn-based
    scheme performs best.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: Pugliatti 和 Topputo [[101](#bib.bib101)] 首次提出了基于 \glsxtrshortcnn 的方法用于车载小型天体形状分类，因为形状信息可以增强图像处理和自我任务规划的自主性。选取了来自[行星数据系统
    (PDS)](#glo.main.pds)节点的 $8$ 个著名模型^(10)^(10)10[https://sbn.psi.edu/pds/shape-models](https://sbn.psi.edu/pds/shape-models)以代表小型小行星的最重要特征。图
    [19](#S4.F19 "图 19 ‣ 4.2 贡献领域的先前工作 ‣ 4 \glsfmtshortdl 基于小行星研究的相对导航 ‣ 基于深度学习的航天器相对导航方法：综述")
    展示了构建数据库的步骤草图以及用于分类小行星的[卷积神经网络 (CNN)](#glo.main.cnn)框架。数据库在 Blender 中生成，假设了相机指向和照明，并在
    TensorFlow [[102](#bib.bib102)] 中进一步通过随机旋转、平移和缩放进行增强。包含 $20\,988$ 张图像的数据库根据 $80\text{\,}\mathrm{\char
    37\relax}$-$10\text{\,}\mathrm{\char 37\relax}$-$10\text{\,}\mathrm{\char 37\relax}$
    的比例被划分为训练、验证和测试集。他们的[卷积神经网络 (CNN)](#glo.main.cnn)架构有五个[卷积层 (CL)](#glo.main.cl)，每个卷积层后跟一个池化层、一个重塑操作和三个[全连接层
    (FCL)](#glo.main.fl)进行分类。使用超参数搜索以获得网络参数。比较了三种传统方法，如 Hu 不变矩、傅里叶描述符和极坐标轮廓，其中提出的
    \glsxtrshortcnn 基于方案表现最佳。
- en: '![Refer to caption](img/ba072dd4834518d16ef93a6a6f371e47.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/ba072dd4834518d16ef93a6a6f371e47.png)'
- en: (a) Step flows for database generation
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 数据库生成的步骤流程
- en: '![Refer to caption](img/20905c786d96f64a478d981548c85886.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/20905c786d96f64a478d981548c85886.png)'
- en: (b) Schematic representation of the proposed [CNN](#glo.main.cnn)
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 提出的 [CNN](#glo.main.cnn) 的示意图
- en: 'Figure 19: Database generation flow and proposed [CNN](#glo.main.cnn) architecture
    of Pugliatti and Topputo [[101](#bib.bib101)].'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19：Pugliatti 和 Topputo 提出的数据库生成流程及[卷积神经网络 (CNN)](#glo.main.cnn)架构[[101](#bib.bib101)]。
- en: Later, Pugliatti and Topputo [[91](#bib.bib91)] proposed on-board autonomous
    navigation using segmentation maps and a [CNN](#glo.main.cnn) to estimate spacecraft
    position concerning an asteroid fixed reference frame. The [CNN](#glo.main.cnn)
    transferred from the MobileNetV2 network [[48](#bib.bib48)] classifies the segmentation
    maps to generate a rough estimate of the position information from the input.
    The relative position is finally obtained by refining the output of the [CNN](#glo.main.cnn)
    using an advanced normalised cross-correlation method. Didymos and Hartley are
    selected as representatives of regular and irregular small-bodies to create the
    dataset, which includes $49\,716$ samples of synthetic maps for five different
    scenarios. Experimental results indicate the capability of [CNN](#glo.main.cnn)
    in predicting the correct class and achieve a relative position error below $5\text{\,}\mathrm{\char
    37\relax}8\text{\,}\mathrm{\char 37\relax}$ of the range from the asteroid.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 后来，Pugliatti 和 Topputo [[91](#bib.bib91)] 提出了使用分割图和 [CNN](#glo.main.cnn) 在航天器相对于小行星固定参考系的定位。来自
    MobileNetV2 网络 [[48](#bib.bib48)] 的 [CNN](#glo.main.cnn) 将分割图分类，以从输入中生成位置信息的粗略估计。通过使用高级归一化互相关方法对
    [CNN](#glo.main.cnn) 的输出进行精细化处理，最终获得相对位置。Didymos 和 Hartley 被选为常规和不规则小天体的代表来创建数据集，其中包括
    $49\,716$ 个五种不同场景的合成图像样本。实验结果表明， [CNN](#glo.main.cnn) 在预测正确类别方面具有能力，并且相对位置误差低于
    $5\text{\,}\mathrm{\char 37\relax}8\text{\,}\mathrm{\char 37\relax}$。
- en: In 2021, Ravani et al. [[95](#bib.bib95)] developed a novel Mask-Region [CNN](#glo.main.cnn)
    to detect landing sites for autonomous soft-landing on asteroids. Since there
    is no open public dataset of potential landing sites labelled with ground truth,
    the authors first gather image mosaics of the asteroid Vesta from the [PDS](#glo.main.pds)
    of [NASA](#glo.main.nasa) ^(11)^(11)11[https://pds.nasa.gov](https://pds.nasa.gov).
    and then fragment the large images into smaller ones with a fixed size. Next,
    the training dataset is labelled manually. For the Mask‑Region [CNN](#glo.main.cnn)
    pipeline, it follows a backbone network of ResNet-50-C4 for initialisation; an
    [RPN](#glo.main.rpn) for extracting feature maps; Faster [R-CNN](#glo.main.rcnn)
    for [RoI](#glo.main.roi) alignment; the network head is structured using [FCLs](#glo.main.fl)
    for computing the bounding box; and the mask head of a [FCL](#glo.main.fl) network
    [[103](#bib.bib103)] is used for calculating the pixel-level mask. Comparing with
    conventional image processing methods, the proposed network on their dataset results
    in an accuracy of $94\text{\,}\mathrm{\char 37\relax}$ with lower computational
    time cost in the implementation phase.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2021 年，Ravani 等人 [[95](#bib.bib95)] 开发了一种新型的 Mask-Region [CNN](#glo.main.cnn)
    用于检测小行星的自动软着陆地点。由于没有公开标注有真实数据的潜在着陆点数据集，作者首先从 [NASA](#glo.main.nasa) 的 [PDS](#glo.main.pds)
    ^(11)^(11)11[https://pds.nasa.gov](https://pds.nasa.gov) 收集了小行星 Vesta 的图像拼接，并将大图像分割成固定大小的小图像。接着，训练数据集进行了人工标注。对于
    Mask-Region [CNN](#glo.main.cnn) 流水线，它采用 ResNet-50-C4 作为初始化的骨干网络；使用 [RPN](#glo.main.rpn)
    提取特征图；使用 Faster [R-CNN](#glo.main.rcnn) 进行 [RoI](#glo.main.roi) 对齐；网络头部使用 [FCLs](#glo.main.fl)
    计算边界框；[FCL](#glo.main.fl) 网络 [[103](#bib.bib103)] 的掩膜头用于计算像素级掩膜。与传统图像处理方法相比，该网络在其数据集上的准确率达到
    $94\text{\,}\mathrm{\char 37\relax}$，且在实施阶段的计算时间成本较低。
- en: 5 Summary and Conclusion
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 总结与结论
- en: This work surveyed recent trends in deep learning techniques for 6-[DoF](#glo.main.dof)
    relative pose estimation in spaceborne applications. Contributions in the field
    of computer vision were presented, followed by concrete applications from the
    literature to autonomous spacecraft navigation, including spaceborne pose estimation,
    crater and hazard detection of terrain relative navigation, and [DL](#glo.main.dl)-based
    asteroid navigation. This survey is motivated by the applicability of [DL](#glo.main.dl)
    techniques in relative spacecraft navigation for future space missions, i.e. rendezvous,
    docking, formation flying, descent and landing on the lunar surface, orbiting
    and inspecting asteroids. The general [DNN](#glo.main.dnn) framework for the applications
    in this research area was reviewed in terms of network structure, type of network,
    training method, dataset topology and generation, and attained performance.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 本文调查了深度学习技术在空间应用中的6-[自由度](#glo.main.dof)相对姿态估计的最新趋势。介绍了计算机视觉领域的贡献，并展示了来自文献的具体应用，如自主航天器导航，包括空间姿态估计、地形相对导航的坑洞和危险检测，以及基于[深度学习](#glo.main.dl)的
    asteroid 导航。此次调查受到[深度学习](#glo.main.dl)技术在未来空间任务中相对航天器导航应用的启发，即对接、对接、编队飞行、月球表面下降和着陆、绕行和检查小行星。综述了本研究领域中应用的一般[DNN](#glo.main.dnn)框架，包括网络结构、网络类型、训练方法、数据集拓扑和生成，以及所达到的性能。
- en: 'First, a review of [DNN](#glo.main.dnn)-based [S/C](#glo.main.sc) relative
    pose estimation techniques was given, in which a top level distinction between
    supervised and unsupervised methods was made, whereby contributions in the space
    domain were found to belong exclusively to the former. Context in terms of preceding
    ground-based applications was established. Further lower level categorisations
    were made; in particular, it was found that many techniques favoured a direct
    approach (so called “end-to-end”), where a [DNN](#glo.main.dnn) pipeline is trained
    directly on images to yield the relative state. Indeed, this is a very appealing
    property of deep learning, as not only is the feature extraction task relayed
    to a [CNN](#glo.main.cnn), but so is the modelling task, eliminating the ”middleman”
    and allowing the user to focus mainly on the architecture design and optimisation
    of learnable parameters. However, it was seen that more accurate solutions were
    obtained by combining them with classical methods. For these indirect methods,
    a [CNN](#glo.main.cnn) was tasked with regressing the locations of [2D](#glo.main.2d)
    keypoints on the target and estimating the relative pose from geometrical correspondences
    with their [3D](#glo.main.3d) counterparts, using techniques such as [P$n$P](#glo.main.pnp)
    or nonlinear optimisation. Furthermore, such solutions are easily incorporated
    into navigation filters to further refine the estimate with continuous, smooth
    consistency (also beyond pose estimation). The role of [RNNs](#glo.main.rnn),
    particularly [LSTMs](#glo.main.lstm), is highlighted in the processing of a continuous
    stream of images. Tables [1](#S2.T1 "Table 1 ‣ 2.3 Direct Frameworks for Spacecraft
    Relative Pose Estimation ‣ 2 \glsfmtshortdl-based Pose Estimation for Spacecraft
    Relative Navigation ‣ Deep Learning-based Spacecraft Relative Navigation Methods:
    A Survey") and [2](#S2.T2 "Table 2 ‣ 2.4 Indirect Frameworks for Spacecraft Relative
    Pose Estimation ‣ 2 \glsfmtshortdl-based Pose Estimation for Spacecraft Relative
    Navigation ‣ Deep Learning-based Spacecraft Relative Navigation Methods: A Survey")
    summarises these findings in terms of relative pose estimation error for spacecraft
    rendezvous [DL](#glo.main.dl) applications.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，对基于[DNN](#glo.main.dnn)的[S/C](#glo.main.sc)相对姿态估计技术进行了回顾，其中对监督和无监督方法进行了高级别的区分，在空间领域的贡献被发现完全属于前者。建立了之前地面应用的背景。进一步进行了较低级别的分类；特别是发现许多技术倾向于直接方法（所谓的“端到端”），其中[DNN](#glo.main.dnn)管道直接在图像上进行训练以产生相对状态。的确，这是深度学习非常吸引人的特性，因为不仅特征提取任务被转交给了[CNN](#glo.main.cnn)，而且建模任务也是如此，消除了“中介”，允许用户主要关注架构设计和可学习参数的优化。然而，发现通过将它们与经典方法结合，可以获得更准确的解决方案。对于这些间接方法，[CNN](#glo.main.cnn)负责回归目标上的[2D](#glo.main.2d)关键点的位置，并通过几何对应关系与它们的[3D](#glo.main.3d)对应点来估计相对姿态，使用如[P$n$P](#glo.main.pnp)或非线性优化等技术。此外，这些解决方案可以轻松地纳入导航滤波器，以进一步通过连续的平滑一致性（甚至超出姿态估计）来细化估计。[RNNs](#glo.main.rnn)的角色，特别是[LSTMs](#glo.main.lstm)，在处理连续图像流方面得到了强调。表[1](#S2.T1
    "Table 1 ‣ 2.3 Direct Frameworks for Spacecraft Relative Pose Estimation ‣ 2 \glsfmtshortdl-based
    Pose Estimation for Spacecraft Relative Navigation ‣ Deep Learning-based Spacecraft
    Relative Navigation Methods: A Survey")和[2](#S2.T2 "Table 2 ‣ 2.4 Indirect Frameworks
    for Spacecraft Relative Pose Estimation ‣ 2 \glsfmtshortdl-based Pose Estimation
    for Spacecraft Relative Navigation ‣ Deep Learning-based Spacecraft Relative Navigation
    Methods: A Survey")总结了这些关于航天器会合[DL](#glo.main.dl)应用的相对姿态估计误差的发现。'
- en: Second, the applications of [DNNs](#glo.main.dnn) to [TRN](#glo.main.trn) were
    divided into three aspects for surveying, in which the [DNN](#glo.main.dnn)-based
    crater and hazard detection methods were recognised as contributors towards building
    a terrain navigation system. It was pointed out that public open data for training
    and testing of [DNN](#glo.main.dnn)-based [TRN](#glo.main.trn) frameworks is limited.
    Furthermore, [DL](#glo.main.dl)-based relative navigation methods focusing on
    asteroid missions were provided. The challenges and motivations were discussed
    before a detailed review of this field.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，对[DNNs](#glo.main.dnn)在[TRN](#glo.main.trn)中的应用进行了三个方面的调查，其中基于[DNN](#glo.main.dnn)的陨石坑和危险检测方法被认为是构建地形导航系统的重要贡献者。指出了用于训练和测试基于[DNN](#glo.main.dnn)的[TRN](#glo.main.trn)框架的公共开放数据有限。此外，还提供了关注小行星任务的[DL](#glo.main.dl)基于相对导航的方法。在详细回顾这一领域之前，讨论了挑战和动机。
- en: Lastly, regarding unsupervised learning methods (i.e. concerning cases in which
    the desired output for each input is not given during training), far too little
    attention has been paid to this kind of technique for space navigation. However,
    unsupervised techniques such as [CNN](#glo.main.cnn)-\glsxtrshortslam (\glsxtrlong*slam)
    or unsupervised [VO](#glo.main.vo) are underlined as a potential novel approach
    for the space domain and may be investigated in future. Additionally, most publications
    study the application of [DL](#glo.main.dl) in space in a theoretical way without
    being concerned with computational performance; indeed, only a few publications
    [[19](#bib.bib19), [22](#bib.bib22), [81](#bib.bib81)] focus on actual deployments
    on hardware, considering things like execution time, and size of the training
    dataset. Therefore, it can be concluded that these studies towards the actual
    engineering practice have been little discussed and require further development.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，关于无监督学习方法（即在训练期间每个输入的期望输出未给出），对这种空间导航技术的关注远远不足。然而，无监督技术如 [CNN](#glo.main.cnn)-\glsxtrshortslam
    (\glsxtrlong*slam*) 或无监督 [VO](#glo.main.vo) 被认为是空间领域潜在的新方法，并可能在未来进行研究。此外，大多数出版物以理论方式研究
    [DL](#glo.main.dl) 在空间中的应用，而不关注计算性能；事实上，只有少数出版物 [[19](#bib.bib19), [22](#bib.bib22),
    [81](#bib.bib81)] 专注于硬件上的实际部署，考虑了执行时间和训练数据集的大小。因此，可以得出结论，这些关于实际工程实践的研究讨论甚少，需要进一步发展。
- en: References
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Goodfellow et al. [2016] Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
    *Deep learning*. MIT press, 2016.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow et al. [2016] Ian Goodfellow, Yoshua Bengio, 和 Aaron Courville. *深度学习*。麻省理工学院出版社，2016年。
- en: Wie et al. [2014] Bong Wie, Vaios Lappas, and Jesús Gil-Fernández. Attitude
    and orbit control systems. In Malcolm Macdonald and Viorel Badescu, editors, *The
    International Handbook of Space Technology*, chapter 12, page 362\. Springer Praxis
    Books, 2014. doi:[10.1007/978-3-642-41101-4](https://doi.org/10.1007/978-3-642-41101-4).
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wie et al. [2014] Bong Wie, Vaios Lappas, 和 Jesús Gil-Fernández. 姿态和轨道控制系统。见
    Malcolm Macdonald 和 Viorel Badescu 编，*国际空间技术手册*，第12章，第362页。Springer Praxis 图书，2014年。doi:[10.1007/978-3-642-41101-4](https://doi.org/10.1007/978-3-642-41101-4)。
- en: Bhaskaran et al. [1998] Shyam Bhaskaran, S Desai, P Dumont, B Kennedy, G Null,
    W Owen Jr, J Riedel, S Synnott, and R Werner. Orbit determination performance
    evaluation of the deep space 1 autonomous navigation system. In *AAS/AIAA Space
    Flight Mechanics Meeting*, 1998. URL [https://trs.jpl.nasa.gov/bitstream/handle/2014/19040/98-0222.pdf?sequence=1](https://trs.jpl.nasa.gov/bitstream/handle/2014/19040/98-0222.pdf?sequence=1).
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bhaskaran et al. [1998] Shyam Bhaskaran, S Desai, P Dumont, B Kennedy, G Null,
    W Owen Jr, J Riedel, S Synnott, 和 R Werner. 深空1号自主导航系统的轨道确定性能评估。见 *AAS/AIAA 太空飞行力学会议*，1998年。网址
    [https://trs.jpl.nasa.gov/bitstream/handle/2014/19040/98-0222.pdf?sequence=1](https://trs.jpl.nasa.gov/bitstream/handle/2014/19040/98-0222.pdf?sequence=1)。
- en: 'Kothari et al. [2020] Vivek Kothari, Edgar Liberis, and Nicholas D. Lane. The
    final frontier: Deep learning in space. In *Proceedings of the 21st International
    Workshop on Mobile Computing Systems and Applications*, HotMobile ’20, page 45–49,
    New York, NY, USA, 2020\. Association for Computing Machinery. ISBN 9781450371162.
    doi:[10.1145/3376897.3377864](https://doi.org/10.1145/3376897.3377864).'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kothari et al. [2020] Vivek Kothari, Edgar Liberis, 和 Nicholas D. Lane. 最终边界：空间中的深度学习。见
    *第21届国际移动计算系统与应用研讨会论文集*，HotMobile ’20，第45–49页，美国纽约，2020年。计算机协会。ISBN 9781450371162。doi:[10.1145/3376897.3377864](https://doi.org/10.1145/3376897.3377864)。
- en: Cassinis et al. [2019] Lorenzo Pasqualetto Cassinis, Robert Fonod, and Eberhard
    Gill. Review of the robustness and applicability of monocular pose estimation
    systems for relative navigation with an uncooperative spacecraft. *Progress in
    Aerospace Sciences*, 110:100548, 2019. ISSN 0376-0421. doi:[https://doi.org/10.1016/j.paerosci.2019.05.008](https://doi.org/https://doi.org/10.1016/j.paerosci.2019.05.008).
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cassinis et al. [2019] Lorenzo Pasqualetto Cassinis, Robert Fonod, 和 Eberhard
    Gill. 单目姿态估计系统在与非合作航天器的相对导航中的鲁棒性和适用性的综述。*航空航天科学进展*，110:100548，2019年。ISSN 0376-0421。doi:[https://doi.org/10.1016/j.paerosci.2019.05.008](https://doi.org/10.1016/j.paerosci.2019.05.008)。
- en: Shi et al. [2018] Jian Feng Shi, Steve Ulrich, and Stéphane Ruel. Cubesat simulation
    and detection using monocular camera images and convolutional neural networks.
    In *2018 AIAA Guidance, Navigation, and Control Conference*, page 1604, 2018.
    doi:[10.2514/6.2018-1604](https://doi.org/10.2514/6.2018-1604).
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi et al. [2018] Jian Feng Shi, Steve Ulrich, 和 Stéphane Ruel. 使用单目相机图像和卷积神经网络进行立方体卫星模拟和检测。见
    *2018 AIAA 导航、控制会议*，第1604页，2018年。doi:[10.2514/6.2018-1604](https://doi.org/10.2514/6.2018-1604)。
- en: Sharma et al. [2018a] Sumant Sharma, Connor Beierle, and Simone D'Amico. Pose
    estimation for non-cooperative spacecraft rendezvous using convolutional neural
    networks. In *2018 IEEE Aerospace Conference*. IEEE, March 2018a. doi:[10.1109/aero.2018.8396425](https://doi.org/10.1109/aero.2018.8396425).
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sharma 等 [2018a] Sumant Sharma, Connor Beierle 和 Simone D'Amico。利用卷积神经网络进行非合作性航天器对接的姿态估计。见于
    *2018 IEEE 航空航天会议*。IEEE，2018年3月。doi：[10.1109/aero.2018.8396425](https://doi.org/10.1109/aero.2018.8396425)。
- en: 'Sharma and D’Amico [2019] Sumant Sharma and Simone D’Amico. Pose estimation
    for non-cooperative spacecraft rendezvous using neural networks. In *Proceedings
    of the AIAA/AAS Space Flight Mechanics Meeting*, 2019. URL [https://arxiv.org/abs/1906.09868v1](https://arxiv.org/abs/1906.09868v1).
    report number: AAS 19-350.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sharma 和 D’Amico [2019] Sumant Sharma 和 Simone D’Amico。利用神经网络进行非合作性航天器对接的姿态估计。见于
    *AIAA/AAS 航天飞行力学会议论文集*，2019。网址 [https://arxiv.org/abs/1906.09868v1](https://arxiv.org/abs/1906.09868v1)。报告编号：AAS
    19-350。
- en: 'Kendall et al. [2015] Alex Kendall, Matthew Grimes, and Roberto Cipolla. PoseNet:
    A convolutional network for real-time 6-DOF camera relocalization. In *2015 IEEE
    International Conference on Computer Vision (ICCV)*, pages 2938–2946, Santiago,
    Chile, October 2015\. IEEE. doi:[10.1109/iccv.2015.336](https://doi.org/10.1109/iccv.2015.336).'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kendall 等 [2015] Alex Kendall, Matthew Grimes 和 Roberto Cipolla。PoseNet：一种用于实时6-DOF相机重定位的卷积网络。见于
    *2015 IEEE 国际计算机视觉会议 (ICCV)*，第2938–2946页，智利圣地亚哥，2015年10月。IEEE。doi：[10.1109/iccv.2015.336](https://doi.org/10.1109/iccv.2015.336)。
- en: Szegedy et al. [2015] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet,
    Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
    Going deeper with convolutions. In *2015 IEEE Conference on Computer Vision and
    Pattern Recognition (CVPR)*. IEEE, June 2015. doi:[10.1109/cvpr.2015.7298594](https://doi.org/10.1109/cvpr.2015.7298594).
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等 [2015] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet,
    Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke 和 Andrew Rabinovich。更深层次的卷积网络。见于
    *2015 IEEE 计算机视觉与模式识别会议 (CVPR)*。IEEE，2015年6月。doi：[10.1109/cvpr.2015.7298594](https://doi.org/10.1109/cvpr.2015.7298594)。
- en: 'Wang et al. [2017] Sen Wang, Ronald Clark, Hongkai Wen, and Niki Trigoni. DeepVO:
    Towards end-to-end visual odometry with deep recurrent convolutional neural networks.
    In *2017 IEEE International Conference on Robotics and Automation (ICRA)*. IEEE,
    May 2017. doi:[10.1109/icra.2017.7989236](https://doi.org/10.1109/icra.2017.7989236).'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 [2017] Sen Wang, Ronald Clark, Hongkai Wen 和 Niki Trigoni。DeepVO：基于深度递归卷积神经网络的端到端视觉里程计。见于
    *2017 IEEE 国际机器人与自动化会议 (ICRA)*。IEEE，2017年5月。doi：[10.1109/icra.2017.7989236](https://doi.org/10.1109/icra.2017.7989236)。
- en: Donahue et al. [2015] Jeff Donahue, Lisa Anne Hendricks, Sergio Guadarrama,
    Marcus Rohrbach, Subhashini Venugopalan, Trevor Darrell, and Kate Saenko. Long-term
    recurrent convolutional networks for visual recognition and description. In *2015
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*. IEEE, June
    2015. doi:[10.1109/cvpr.2015.7298878](https://doi.org/10.1109/cvpr.2015.7298878).
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Donahue 等 [2015] Jeff Donahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus
    Rohrbach, Subhashini Venugopalan, Trevor Darrell 和 Kate Saenko。用于视觉识别和描述的长期递归卷积网络。见于
    *2015 IEEE 计算机视觉与模式识别会议 (CVPR)*。IEEE，2015年6月。doi：[10.1109/cvpr.2015.7298878](https://doi.org/10.1109/cvpr.2015.7298878)。
- en: 'Dosovitskiy et al. [2015] Alexey Dosovitskiy, Philipp Fischer, Eddy Ilg, Philip
    Hausser, Caner Hazirbas, Vladimir Golkov, Patrick van der Smagt, Daniel Cremers,
    and Thomas Brox. FlowNet: Learning optical flow with convolutional networks. In
    *2015 IEEE International Conference on Computer Vision (ICCV)*. IEEE, October
    2015. doi:[10.1109/iccv.2015.316](https://doi.org/10.1109/iccv.2015.316).'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dosovitskiy 等 [2015] Alexey Dosovitskiy, Philipp Fischer, Eddy Ilg, Philip Hausser,
    Caner Hazirbas, Vladimir Golkov, Patrick van der Smagt, Daniel Cremers 和 Thomas
    Brox。FlowNet：使用卷积网络学习光流。见于 *2015 IEEE 国际计算机视觉会议 (ICCV)*。IEEE，2015年10月。doi：[10.1109/iccv.2015.316](https://doi.org/10.1109/iccv.2015.316)。
- en: 'Geiger et al. [2011] Andreas Geiger, Julius Ziegler, and Christoph Stiller.
    StereoScan: Dense 3D reconstruction in real-time. In *2011 IEEE Intelligent Vehicles
    Symposium (IV)*. IEEE, June 2011. doi:[10.1109/ivs.2011.5940405](https://doi.org/10.1109/ivs.2011.5940405).'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Geiger 等 [2011] Andreas Geiger, Julius Ziegler 和 Christoph Stiller。StereoScan：实时稠密3D重建。见于
    *2011 IEEE 智能车辆研讨会 (IV)*。IEEE，2011年6月。doi：[10.1109/ivs.2011.5940405](https://doi.org/10.1109/ivs.2011.5940405)。
- en: 'Rad and Lepetit [2017] Mahdi Rad and Vincent Lepetit. BB8: A scalable, accurate,
    robust to partial occlusion method for predicting the 3D poses of challenging
    objects without using depth. In *2017 IEEE International Conference on Computer
    Vision (ICCV)*, October 2017. doi:[10.1109/iccv.2017.413](https://doi.org/10.1109/iccv.2017.413).'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rad 和 Lepetit [2017] Mahdi Rad 和 Vincent Lepetit. BB8：一种可扩展、准确、对部分遮挡具有鲁棒性的方法，用于预测具有挑战性的物体的
    3D 姿态而不使用深度信息。发表于*2017 IEEE 国际计算机视觉大会 (ICCV)*，2017年10月。doi:[10.1109/iccv.2017.413](https://doi.org/10.1109/iccv.2017.413)。
- en: 'Szeliski [2010] Richard Szeliski. *Computer Vision: Algorithms and Applications*.
    Springer Science & Business Media, 2010. doi:[10.1007/978-1-84882-935-0](https://doi.org/10.1007/978-1-84882-935-0).'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szeliski [2010] Richard Szeliski. *计算机视觉：算法与应用*。Springer 科学与商业媒体，2010年。doi:[10.1007/978-1-84882-935-0](https://doi.org/10.1007/978-1-84882-935-0)。
- en: Simonyan and Zisserman [2014] Karen Simonyan and Andrew Zisserman. Very deep
    convolutional networks for large-scale image recognition, 2014. URL [https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556).
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simonyan 和 Zisserman [2014] Karen Simonyan 和 Andrew Zisserman. 用于大规模图像识别的非常深的卷积网络，2014。网址
    [https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)。
- en: Hartley and Zisserman [2004] Richard Hartley and Andrew Zisserman. *Multiple
    View Geometry in Computer Vision*. Cambridge University Press, 2nd edition, 2004.
    doi:[10.1017/CBO9780511811685](https://doi.org/10.1017/CBO9780511811685).
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hartley 和 Zisserman [2004] Richard Hartley 和 Andrew Zisserman. *计算机视觉中的多视图几何*。剑桥大学出版社，第2版，2004年。doi:[10.1017/CBO9780511811685](https://doi.org/10.1017/CBO9780511811685)。
- en: Sonawani et al. [2020] Shubham Sonawani, Ryan Alimo, Renaud Detry, Daniel Jeong,
    Andrew Hess, and Heni Ben Amor. Assistive relative pose estimation for on-orbit
    assembly using convolutional neural networks. In *AIAA Scitech 2020 Forum*. American
    Institute of Aeronautics and Astronautics, January 2020. doi:[10.2514/6.2020-2096](https://doi.org/10.2514/6.2020-2096).
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sonawani 等 [2020] Shubham Sonawani, Ryan Alimo, Renaud Detry, Daniel Jeong,
    Andrew Hess 和 Heni Ben Amor. 使用卷积神经网络进行轨道组装的辅助相对姿态估计。发表于*AIAA Scitech 2020 论坛*。美国航空航天学会，2020年1月。doi:[10.2514/6.2020-2096](https://doi.org/10.2514/6.2020-2096)。
- en: Chen et al. [2019] Bo Chen, Jiewei Cao, Alvaro Parra, and Tat-Jun Chin. Satellite
    pose estimation with deep landmark regression and nonlinear pose refinement. In
    *2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)*.
    IEEE, October 2019. doi:[10.1109/iccvw.2019.00343](https://doi.org/10.1109/iccvw.2019.00343).
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 [2019] Bo Chen, Jiewei Cao, Alvaro Parra 和 Tat-Jun Chin. 基于深度标志回归和非线性姿态优化的卫星姿态估计。发表于*2019
    IEEE/CVF 国际计算机视觉大会研讨会 (ICCVW)*。IEEE，2019年10月。doi:[10.1109/iccvw.2019.00343](https://doi.org/10.1109/iccvw.2019.00343)。
- en: Huan et al. [2020] Wenxiu Huan, Mingmin Liu, and Qinglei Hu. Pose estimation
    for non-cooperative spacecraft based on deep learning. In *2020 39th Chinese Control
    Conference (CCC)*, pages 3339–3343, 2020. doi:[10.23919/CCC50068.2020.9189253](https://doi.org/10.23919/CCC50068.2020.9189253).
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huan 等 [2020] Wenxiu Huan, Mingmin Liu 和 Qinglei Hu. 基于深度学习的非合作航天器姿态估计。发表于*2020年第39届中国控制会议
    (CCC)*，页3339–3343，2020年。doi:[10.23919/CCC50068.2020.9189253](https://doi.org/10.23919/CCC50068.2020.9189253)。
- en: Oestreich et al. [2020] Charles Oestreich, Tae W. Lim, and Randy Broussard.
    On-orbit relative pose initialization via convolutional neural networks. In *AIAA
    Scitech 2020 Forum*. American Institute of Aeronautics and Astronautics, January
    2020. doi:[10.2514/6.2020-0457](https://doi.org/10.2514/6.2020-0457).
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oestreich 等 [2020] Charles Oestreich, Tae W. Lim 和 Randy Broussard. 通过卷积神经网络进行轨道上相对姿态初始化。发表于*AIAA
    Scitech 2020 论坛*。美国航空航天学会，2020年1月。doi:[10.2514/6.2020-0457](https://doi.org/10.2514/6.2020-0457)。
- en: Cosmas and Kenichi [2020] Kiruki Cosmas and Asami Kenichi. Utilization of FPGA
    for onboard inference of landmark localization in CNN-based spacecraft pose estimation.
    *Aerospace*, 7(11), 2020. ISSN 2226-4310. doi:[10.3390/aerospace7110159](https://doi.org/10.3390/aerospace7110159).
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cosmas 和 Kenichi [2020] Kiruki Cosmas 和 Asami Kenichi. 在基于 CNN 的航天器姿态估计中利用 FPGA
    进行地标定位的机载推理。*航空航天*，7(11)，2020年。ISSN 2226-4310。doi:[10.3390/aerospace7110159](https://doi.org/10.3390/aerospace7110159)。
- en: Hirano et al. [2018] Daichi Hirano, Hiroki Kato, and Tatsuhiko Saito. Deep learning
    based pose estimation in space. In *Proceedings of the International Symposium
    on Artificial Intelligence, Robotics and Automation in Space (i-SAIRAS)*, 2018.
    URL [https://robotics.estec.esa.int/i-SAIRAS/isairas2018/Papers/Session%203c/4_isairas2018_deep_ver1-39-77-Hirano-Daichi.pdf](https://robotics.estec.esa.int/i-SAIRAS/isairas2018/Papers/Session%203c/4_isairas2018_deep_ver1-39-77-Hirano-Daichi.pdf).
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hirano et al. [2018] Daichi Hirano, Hiroki Kato, 和 Tatsuhiko Saito. 基于深度学习的空间姿态估计。发表于
    *国际人工智能、机器人技术和空间自动化研讨会 (i-SAIRAS) 论文集*，2018年。网址 [https://robotics.estec.esa.int/i-SAIRAS/isairas2018/Papers/Session%203c/4_isairas2018_deep_ver1-39-77-Hirano-Daichi.pdf](https://robotics.estec.esa.int/i-SAIRAS/isairas2018/Papers/Session%203c/4_isairas2018_deep_ver1-39-77-Hirano-Daichi.pdf)。
- en: Downes et al. [2020a] Lena Downes, Ted J. Steiner, and Jonathan P. How. Deep
    learning crater detection for lunar terrain relative navigation. In *AIAA Scitech
    2020 Forum*. American Institute of Aeronautics and Astronautics, January 2020a.
    doi:[10.2514/6.2020-1838](https://doi.org/10.2514/6.2020-1838).
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Downes et al. [2020a] Lena Downes, Ted J. Steiner, 和 Jonathan P. How. 基于深度学习的月球地形相对导航陨石坑检测。发表于
    *AIAA Scitech 2020论坛*。美国航空航天学会，2020年1月。doi: [10.2514/6.2020-1838](https://doi.org/10.2514/6.2020-1838)。'
- en: Downes et al. [2020b] Lena M. Downes, Ted J. Steiner, and Jonathan P. How. Lunar
    terrain relative navigation using a convolutional neural network for visual crater
    detection. In *2020 American Control Conference (ACC)*, pages 4448–4453, 2020b.
    doi:[10.23919/ACC45564.2020.9147595](https://doi.org/10.23919/ACC45564.2020.9147595).
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Downes et al. [2020b] Lena M. Downes, Ted J. Steiner, 和 Jonathan P. How. 使用卷积神经网络进行月球地形相对导航以进行视觉陨石坑检测。发表于
    *2020年美国控制会议 (ACC)*，第4448–4453页，2020年。doi: [10.23919/ACC45564.2020.9147595](https://doi.org/10.23919/ACC45564.2020.9147595)。'
- en: Cassinis et al. [2020] Lorenzo Pasqualetto Cassinis, Robert Fonod, Eberhard
    Gill, Ingo Ahrns, and Jesus Gil Fernandez. CNN-based pose estimation system for
    close-proximity operations around uncooperative spacecraft. In *AIAA Scitech 2020
    Forum*. American Institute of Aeronautics and Astronautics, January 2020. doi:[10.2514/6.2020-1457](https://doi.org/10.2514/6.2020-1457).
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cassinis et al. [2020] Lorenzo Pasqualetto Cassinis, Robert Fonod, Eberhard
    Gill, Ingo Ahrns, 和 Jesus Gil Fernandez. 基于CNN的姿态估计系统用于与不合作航天器的近距离操作。发表于 *AIAA
    Scitech 2020论坛*。美国航空航天学会，2020年1月。doi: [10.2514/6.2020-1457](https://doi.org/10.2514/6.2020-1457)。'
- en: Campbell et al. [2017] Tanner Campbell, Roberto Furfaro, Richard Linares, and
    David Gaylor. A deep learning approach for optical autonomous planetary relative
    terrain navigation. In *27th AAS/AIAA Space Flight Mechanics Meeting, 2017*, pages
    3293–3302\. Univelt Inc., 2017. URL [http://arclab.mit.edu/wp-content/uploads/2018/10/2017_06.pdf](http://arclab.mit.edu/wp-content/uploads/2018/10/2017_06.pdf).
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Campbell et al. [2017] Tanner Campbell, Roberto Furfaro, Richard Linares, 和
    David Gaylor. 一种用于光学自主行星相对地形导航的深度学习方法。发表于 *第27届AAS/AIAA航天飞行力学会议, 2017*，第3293–3302页。Univelt
    Inc.，2017年。网址 [http://arclab.mit.edu/wp-content/uploads/2018/10/2017_06.pdf](http://arclab.mit.edu/wp-content/uploads/2018/10/2017_06.pdf)。
- en: Krizhevsky et al. [2012] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
    Imagenet classification with deep convolutional neural networks. In F. Pereira,
    C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, *Advances in Neural
    Information Processing Systems*, volume 25. Curran Associates, Inc., 2012. URL
    [https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf).
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky et al. [2012] Alex Krizhevsky, Ilya Sutskever, 和 Geoffrey E Hinton.
    基于深度卷积神经网络的Imagenet分类。由 F. Pereira, C. J. C. Burges, L. Bottou, 和 K. Q. Weinberger
    编辑，*神经信息处理系统进展*，第25卷。Curran Associates, Inc.，2012年。网址 [https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)。
- en: 'Deng et al. [2009] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and
    Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In *2009 IEEE
    Conference on Computer Vision and Pattern Recognition*, pages 248–255, 2009. doi:[10.1109/CVPR.2009.5206848](https://doi.org/10.1109/CVPR.2009.5206848).'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Deng et al. [2009] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, 和
    Li Fei-Fei. Imagenet: 一个大规模的层次化图像数据库。发表于 *2009 IEEE计算机视觉与模式识别会议*，第248–255页，2009年。doi:
    [10.1109/CVPR.2009.5206848](https://doi.org/10.1109/CVPR.2009.5206848)。'
- en: Persson et al. [2006] Staffan Persson, Per Bodin, Eberhard Gill, Jon Harr, and
    John Jörgensen. PRISMA - An autonomous formation flying mission. In *Small Satellite
    Systems and Services - The 4S Symposium*, 2006. URL [https://elib.dlr.de/46839/](https://elib.dlr.de/46839/).
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Persson et al. [2006] Staffan Persson, Per Bodin, Eberhard Gill, Jon Harr, 和
    John Jörgensen. PRISMA - 一项自主编队飞行任务。发表于 *小型卫星系统与服务 - 4S研讨会*，2006年。网址 [https://elib.dlr.de/46839/](https://elib.dlr.de/46839/)。
- en: 'Ren et al. [2017] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster
    R-CNN: Towards real-time object detection with region proposal networks. *IEEE
    Transactions on Pattern Analysis and Machine Intelligence*, 39(6):1137–1149, June
    2017. doi:[10.1109/tpami.2016.2577031](https://doi.org/10.1109/tpami.2016.2577031).'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ren 等人 [2017] Shaoqing Ren, Kaiming He, Ross Girshick, 和 Jian Sun. Faster R-CNN:
    面向实时目标检测的区域提议网络。*IEEE模式分析与机器智能汇刊*，39(6):1137–1149，2017年6月。doi:[10.1109/tpami.2016.2577031](https://doi.org/10.1109/tpami.2016.2577031)。'
- en: Sharma and D’Amico [2020] Sumant Sharma and Simone D’Amico. Neural network-based
    pose estimation for noncooperative spacecraft rendezvous. *IEEE Transactions on
    Aerospace and Electronic Systems*, 56(6):4638–4658, 2020. doi:[10.1109/TAES.2020.2999148](https://doi.org/10.1109/TAES.2020.2999148).
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sharma 和 D’Amico [2020] Sumant Sharma 和 Simone D’Amico. 基于神经网络的姿态估计用于非合作航天器对接。*IEEE航天与电子系统汇刊*，56(6):4638–4658，2020年。doi:[10.1109/TAES.2020.2999148](https://doi.org/10.1109/TAES.2020.2999148)。
- en: 'Kehl et al. [2017] Wadim Kehl, Fabian Manhardt, Federico Tombari, Slobodan
    Ilic, and Nassir Navab. SSD-6D: Making RGB-based 3D detection and 6D pose estimation
    great again. In *2017 IEEE International Conference on Computer Vision (ICCV)*.
    IEEE, October 2017. doi:[10.1109/iccv.2017.169](https://doi.org/10.1109/iccv.2017.169).'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kehl 等人 [2017] Wadim Kehl, Fabian Manhardt, Federico Tombari, Slobodan Ilic,
    和 Nassir Navab. SSD-6D: 使基于RGB的3D检测和6D姿态估计重焕辉煌。在*2017 IEEE国际计算机视觉会议（ICCV）*。IEEE，2017年10月。doi:[10.1109/iccv.2017.169](https://doi.org/10.1109/iccv.2017.169)。'
- en: Sharma et al. [2018b] Sumant Sharma, Jacopo Ventura, and Simone D’Amico. Robust
    model-based monocular pose initialization for noncooperative spacecraft rendezvous.
    *Journal of Spacecraft and Rockets*, 55(6):1414–1429, nov 2018b. doi:[10.2514/1.a34124](https://doi.org/10.2514/1.a34124).
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sharma 等人 [2018b] Sumant Sharma, Jacopo Ventura, 和 Simone D’Amico. 稳健的基于模型的单目姿态初始化用于非合作航天器对接。*航天器与火箭期刊*，55(6):1414–1429，2018年11月。doi:[10.2514/1.a34124](https://doi.org/10.2514/1.a34124)。
- en: Proença and Gao [2020] P. F. Proença and Y. Gao. Deep learning for spacecraft
    pose estimation from photorealistic rendering. In *2020 IEEE International Conference
    on Robotics and Automation (ICRA)*, pages 6007–6013, Paris, France, 2020. doi:[10.1109/ICRA40945.2020.9197244](https://doi.org/10.1109/ICRA40945.2020.9197244).
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Proença 和 Gao [2020] P. F. Proença 和 Y. Gao. 基于深度学习的航天器姿态估计来自逼真的渲染。在*2020 IEEE国际机器人与自动化会议（ICRA）*，第6007–6013页，法国巴黎，2020年。doi:[10.1109/ICRA40945.2020.9197244](https://doi.org/10.1109/ICRA40945.2020.9197244)。
- en: He et al. [2016] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep
    residual learning for image recognition. In *Proceedings of the IEEE conference
    on computer vision and pattern recognition (CVPR)*, pages 770–778, 2016. doi:[10.1109/cvpr.2016.90](https://doi.org/10.1109/cvpr.2016.90).
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等人 [2016] Kaiming He, Xiangyu Zhang, Shaoqing Ren, 和 Jian Sun. 深度残差学习用于图像识别。在*IEEE计算机视觉与模式识别会议（CVPR）*，第770–778页，2016年。doi:[10.1109/cvpr.2016.90](https://doi.org/10.1109/cvpr.2016.90)。
- en: Liu et al. [2011] Lingqiao Liu, Lei Wang, and Xinwang Liu. In defense of soft-assignment
    coding. In *2011 International Conference on Computer Vision*, pages 2486–2493,
    2011. doi:[10.1109/iccv.2011.6126534](https://doi.org/10.1109/iccv.2011.6126534).
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2011] Lingqiao Liu, Lei Wang, 和 Xinwang Liu. 为软分配编码辩护。在*2011国际计算机视觉大会*，第2486–2493页，2011年。doi:[10.1109/iccv.2011.6126534](https://doi.org/10.1109/iccv.2011.6126534)。
- en: 'Ioffe and Szegedy [2015] Sergey Ioffe and Christian Szegedy. Batch normalization:
    Accelerating deep network training by reducing internal covariate shift. In *International
    conference on machine learning*, pages 448–456\. PMLR, 2015. URL [http://proceedings.mlr.press/v37/ioffe15.html](http://proceedings.mlr.press/v37/ioffe15.html).'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ioffe 和 Szegedy [2015] Sergey Ioffe 和 Christian Szegedy. 批量归一化：通过减少内部协变量偏移加速深度网络训练。在*国际机器学习会议*，第448–456页。PMLR，2015年。URL
    [http://proceedings.mlr.press/v37/ioffe15.html](http://proceedings.mlr.press/v37/ioffe15.html)。
- en: Koenig and Howard [2004] Nathan Koenig and Andrew Howard. Design and use paradigms
    for gazebo, an open-source multi-robot simulator. In *2004 IEEE/RSJ International
    Conference on Intelligent Robots and Systems (IROS)(IEEE Cat. No. 04CH37566)*,
    volume 3, pages 2149–2154, 2004. doi:[10.1109/iros.2004.1389727](https://doi.org/10.1109/iros.2004.1389727).
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koenig 和 Howard [2004] Nathan Koenig 和 Andrew Howard. Gazebo的设计和使用范式，一个开源多机器人模拟器。在*2004
    IEEE/RSJ国际智能机器人与系统会议（IROS）（IEEE Cat. No. 04CH37566）*，第3卷，第2149–2154页，2004年。doi:[10.1109/iros.2004.1389727](https://doi.org/10.1109/iros.2004.1389727)。
- en: Arakawa et al. [2019] Ryohei Arakawa, Yuri Matsushita, Toshiya Hanada, Yasuhiro
    Yoshimura, and Shuji Nagasaki. Attitude estimation of space objects using imaging
    observations and deep learning. In *Advanced Maui Optical and Space Surveillance
    Technologies Conference*, page 21, 2019. URL [https://amostech.com/TechnicalPapers/2019/Non-Resolved-Object-Characterization/Arakawa.pdf](https://amostech.com/TechnicalPapers/2019/Non-Resolved-Object-Characterization/Arakawa.pdf).
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arakawa et al. [2019] Ryohei Arakawa、Yuri Matsushita、Toshiya Hanada、Yasuhiro
    Yoshimura 和 Shuji Nagasaki。利用成像观测和深度学习进行空间物体的姿态估计。在*高级毛伊光学和空间监视技术会议*，第21页，2019年。URL
    [https://amostech.com/TechnicalPapers/2019/Non-Resolved-Object-Characterization/Arakawa.pdf](https://amostech.com/TechnicalPapers/2019/Non-Resolved-Object-Characterization/Arakawa.pdf)。
- en: Phisannupawong et al. [2020] Thaweerath Phisannupawong, Patcharin Kamsing, Peerapong
    Torteeka, Sittiporn Channumsin, Utane Sawangwit, Warunyu Hematulin, Tanatthep
    Jarawan, Thanaporn Somjit, Soemsak Yooyen, Daniel Delahaye, and Pisit Boonsrimuang.
    Vision-based spacecraft pose estimation via a deep convolutional neural network
    for noncooperative docking operations. *Aerospace*, 7(9):126, 2020. doi:[10.3390/aerospace7090126](https://doi.org/10.3390/aerospace7090126).
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Phisannupawong et al. [2020] Thaweerath Phisannupawong、Patcharin Kamsing、Peerapong
    Torteeka、Sittiporn Channumsin、Utane Sawangwit、Warunyu Hematulin、Tanatthep Jarawan、Thanaporn
    Somjit、Soemsak Yooyen、Daniel Delahaye 和 Pisit Boonsrimuang。基于视觉的航天器姿态估计通过深度卷积神经网络用于非合作对接操作。*Aerospace*，7(9)：126，2020年。doi：[10.3390/aerospace7090126](https://doi.org/10.3390/aerospace7090126)。
- en: 'Kechagias-Stamatis et al. [2020] Odysseas Kechagias-Stamatis, Nabil Aouf, Vincent
    Dubanchet, and Mark A Richardson. DeepLO: Multi-projection deep LIDAR odometry
    for space orbital robotics rendezvous relative navigation. *Acta Astronautica*,
    177:270–285, 2020. doi:[10.1016/j.actaastro.2020.07.034](https://doi.org/10.1016/j.actaastro.2020.07.034).'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kechagias-Stamatis et al. [2020] Odysseas Kechagias-Stamatis、Nabil Aouf、Vincent
    Dubanchet 和 Mark A Richardson。DeepLO：用于空间轨道机器人会合相对导航的多投影深度LIDAR里程计。*Acta Astronautica*，177：270–285，2020年。doi：[10.1016/j.actaastro.2020.07.034](https://doi.org/10.1016/j.actaastro.2020.07.034)。
- en: Besl and McKay [1992] P.J. Besl and Neil D. McKay. A method for registration
    of 3-D shapes. *IEEE Transactions on Pattern Analysis and Machine Intelligence*,
    14(2):239–256, February 1992. doi:[10.1109/34.121791](https://doi.org/10.1109/34.121791).
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Besl and McKay [1992] P.J. Besl 和 Neil D. McKay。一种3-D形状配准的方法。*IEEE 计算机学会模式分析与机器智能汇刊*，14(2)：239–256，1992年2月。doi：[10.1109/34.121791](https://doi.org/10.1109/34.121791)。
- en: Sattler et al. [2019] Torsten Sattler, Qunjie Zhou, Marc Pollefeys, and Laura
    Leal-Taixe. Understanding the limitations of CNN-based absolute camera pose regression.
    In *2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*,
    pages 3302–3312, 2019. doi:[10.1109/cvpr.2019.00342](https://doi.org/10.1109/cvpr.2019.00342).
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sattler et al. [2019] Torsten Sattler、Qunjie Zhou、Marc Pollefeys 和 Laura Leal-Taixe。理解基于CNN的绝对相机姿态回归的局限性。在*2019
    IEEE/CVF 计算机视觉与模式识别会议（CVPR）*，页3302–3312，2019年。doi：[10.1109/cvpr.2019.00342](https://doi.org/10.1109/cvpr.2019.00342)。
- en: Park et al. [2019] Tae Ha Park, Sumant Sharma, and Simone D’Amico. Towards robust
    learning-based pose estimation of noncooperative spacecraft. 2019. URL [http://arxiv.org/abs/1909.00392](http://arxiv.org/abs/1909.00392).
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park et al. [2019] Tae Ha Park、Sumant Sharma 和 Simone D’Amico。朝向稳健的基于学习的非合作航天器姿态估计。2019年。URL
    [http://arxiv.org/abs/1909.00392](http://arxiv.org/abs/1909.00392)。
- en: 'Redmon and Farhadi [2018] Joseph Redmon and Ali Farhadi. Yolov3: An incremental
    improvement. 2018. URL [http://arxiv.org/abs/1804.02767](http://arxiv.org/abs/1804.02767).'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redmon and Farhadi [2018] Joseph Redmon 和 Ali Farhadi。Yolov3：一种增量改进。2018年。URL
    [http://arxiv.org/abs/1804.02767](http://arxiv.org/abs/1804.02767)。
- en: 'Sandler et al. [2018] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov,
    and Liang-Chieh Chen. MobileNetV2: Inverted residuals and linear bottlenecks.
    In *2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition*. IEEE,
    jun 2018. doi:[10.1109/cvpr.2018.00474](https://doi.org/10.1109/cvpr.2018.00474).'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sandler et al. [2018] Mark Sandler、Andrew Howard、Menglong Zhu、Andrey Zhmoginov
    和 Liang-Chieh Chen。MobileNetV2：倒置残差和线性瓶颈。在*2018 IEEE/CVF 计算机视觉与模式识别会议*。IEEE，2018年6月。doi：[10.1109/cvpr.2018.00474](https://doi.org/10.1109/cvpr.2018.00474)。
- en: 'Howard et al. [2017] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko,
    Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. MobileNets: Efficient
    convolutional neural networks for mobile vision applications. 2017. URL [http://arxiv.org/abs/1704.04861](http://arxiv.org/abs/1704.04861).'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Howard et al. [2017] Andrew G Howard、Menglong Zhu、Bo Chen、Dmitry Kalenichenko、Weijun
    Wang、Tobias Weyand、Marco Andreetto 和 Hartwig Adam。MobileNets：用于移动视觉应用的高效卷积神经网络。2017年。URL
    [http://arxiv.org/abs/1704.04861](http://arxiv.org/abs/1704.04861)。
- en: Geirhos et al. [2018] Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias
    Bethge, Felix A Wichmann, and Wieland Brendel. ImageNet-trained CNNs are biased
    towards texture; increasing shape bias improves accuracy and robustness. 2018.
    URL [http://arxiv.org/abs/1811.12231](http://arxiv.org/abs/1811.12231).
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Geirhos等人 [2018] Robert Geirhos、Patricia Rubisch、Claudio Michaelis、Matthias
    Bethge、Felix A Wichmann 和 Wieland Brendel。ImageNet训练的CNN对纹理有偏见；增加形状偏见可提高准确性和鲁棒性。2018年。网址
    [http://arxiv.org/abs/1811.12231](http://arxiv.org/abs/1811.12231)。
- en: Huang and Belongie [2017] Xun Huang and Serge Belongie. Arbitrary style transfer
    in real-time with adaptive instance normalization. In *2017 IEEE International
    Conference on Computer Vision (ICCV)*, pages 1501–1510, 2017. doi:[10.1109/iccv.2017.167](https://doi.org/10.1109/iccv.2017.167).
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 和 Belongie [2017] Xun Huang 和 Serge Belongie。实时任意风格迁移与自适应实例归一化。发表于*2017
    IEEE International Conference on Computer Vision (ICCV)*，第1501–1510页，2017年。doi:[10.1109/iccv.2017.167](https://doi.org/10.1109/iccv.2017.167)。
- en: Sun et al. [2019] Ke Sun, Bin Xiao, Dong Liu, and Jingdong Wang. Deep high-resolution
    representation learning for human pose estimation. In *2019 IEEE/CVF Conference
    on Computer Vision and Pattern Recognition (CVPR)*. IEEE, June 2019. doi:[10.1109/cvpr.2019.00584](https://doi.org/10.1109/cvpr.2019.00584).
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun等人 [2019] Ke Sun、Bin Xiao、Dong Liu 和 Jingdong Wang。用于人体姿态估计的深度高分辨率表示学习。发表于*2019
    IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*。IEEE，2019年6月。doi:[10.1109/cvpr.2019.00584](https://doi.org/10.1109/cvpr.2019.00584)。
- en: Huo et al. [2020] Yurong Huo, Zhi Li, and Feng Zhang. Fast and accurate spacecraft
    pose estimation from single shot space imagery using box reliability and keypoints
    existence judgments. *IEEE Access*, 8:216283–216297, 2020. doi:[10.1109/ACCESS.2020.3041415](https://doi.org/10.1109/ACCESS.2020.3041415).
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huo等人 [2020] Yurong Huo、Zhi Li 和 Feng Zhang。基于盒子可靠性和关键点存在判断的单幅空间图像快速准确航天器姿态估计。*IEEE
    Access*，8:216283–216297，2020年。doi:[10.1109/ACCESS.2020.3041415](https://doi.org/10.1109/ACCESS.2020.3041415)。
- en: Ferraz et al. [2014] Luis Ferraz, Xavier Binefa, and Francesc Moreno-Noguer.
    Leveraging feature uncertainty in the PnP problem. In *Proceedings of the British
    Machine Vision Conference 2014*. British Machine Vision Association, 2014. doi:[10.5244/c.28.83](https://doi.org/10.5244/c.28.83).
    URL [https://doi.org/10.5244%2Fc.28.83](https://doi.org/10.5244%2Fc.28.83).
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ferraz等人 [2014] Luis Ferraz、Xavier Binefa 和 Francesc Moreno-Noguer。在PnP问题中利用特征不确定性。发表于*Proceedings
    of the British Machine Vision Conference 2014*。英国机器视觉协会，2014年。doi:[10.5244/c.28.83](https://doi.org/10.5244/c.28.83)。网址
    [https://doi.org/10.5244%2Fc.28.83](https://doi.org/10.5244%2Fc.28.83)。
- en: Szegedy et al. [2017] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and
    Alexander Alemi. Inception-v4, Inception-ResNet and the impact of residual connections
    on learning. In *Proceedings of the AAAI Conference on Artificial Intelligence*,
    2017. URL [http://arxiv.org/abs/1602.07261](http://arxiv.org/abs/1602.07261).
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy等人 [2017] Christian Szegedy、Sergey Ioffe、Vincent Vanhoucke 和 Alexander
    Alemi。Inception-v4、Inception-ResNet 及残差连接对学习的影响。发表于*Proceedings of the AAAI Conference
    on Artificial Intelligence*，2017年。网址 [http://arxiv.org/abs/1602.07261](http://arxiv.org/abs/1602.07261)。
- en: 'Lin et al. [2014] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
    Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. Microsoft COCO:
    Common objects in context. In *Computer Vision – ECCV 2014*, pages 740–755, 2014.
    doi:[10.1007/978-3-319-10602-1_48](https://doi.org/10.1007/978-3-319-10602-1_48).'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin等人 [2014] Tsung-Yi Lin、Michael Maire、Serge Belongie、James Hays、Pietro Perona、Deva
    Ramanan、Piotr Dollár 和 C Lawrence Zitnick。微软COCO：上下文中的常见物体。发表于*Computer Vision
    – ECCV 2014*，第740–755页，2014年。doi:[10.1007/978-3-319-10602-1_48](https://doi.org/10.1007/978-3-319-10602-1_48)。
- en: Ming [2018] Yang Ming. Multi-pattern 3d intelligent reconstruction method for
    non-cooperative space targets based on deep learning. Master’s thesis, Harbin
    Institute of Technology, Harbin, 2018.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ming [2018] Yang Ming。基于深度学习的非合作空间目标多模式三维智能重建方法。硕士学位论文，哈尔滨工业大学，哈尔滨，2018年。
- en: 'Jia et al. [2014] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev,
    Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. Caffe: Convolutional
    architecture for fast feature embedding. In *Proceedings of the 22nd ACM international
    conference on Multimedia*, pages 675–678, 2014. doi:[10.1145/2647868.2654889](https://doi.org/10.1145/2647868.2654889).'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jia等人 [2014] Yangqing Jia、Evan Shelhamer、Jeff Donahue、Sergey Karayev、Jonathan
    Long、Ross Girshick、Sergio Guadarrama 和 Trevor Darrell。Caffe：用于快速特征嵌入的卷积架构。发表于*Proceedings
    of the 22nd ACM international conference on Multimedia*，第675–678页，2014年。doi:[10.1145/2647868.2654889](https://doi.org/10.1145/2647868.2654889)。
- en: Yi [2020] Lin Yi. Research on method of docking ring spatial position intelligent
    perception. Master’s thesis, Harbin Institute of Technology, Harbin, 2020. URL
    [https://cdmd.cnki.com.cn/Article/CDMD-10213-1020396416.htm](https://cdmd.cnki.com.cn/Article/CDMD-10213-1020396416.htm).
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yi [2020] 林毅。对接环空间位置智能感知方法的研究。硕士论文，哈尔滨工业大学，哈尔滨，2020。URL [https://cdmd.cnki.com.cn/Article/CDMD-10213-1020396416.htm](https://cdmd.cnki.com.cn/Article/CDMD-10213-1020396416.htm)。
- en: Jiaming [2018] Chen Jiaming. Research and simulation of satellite positioning
    error compensation technology based on convolution neural network. Master’s thesis,
    Beijing University of Posts and Telecommunications, Beijing, 2018.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiaming [2018] 陈佳明。基于卷积神经网络的卫星定位误差补偿技术研究与模拟。硕士论文，北京邮电大学，北京，2018。
- en: 'Wang et al. [2018] Hao Wang, Jie Jiang, and Guangjun Zhang. CraterIDNet: An
    end-to-end fully convolutional neural network for crater detection and identification
    in remotely sensed planetary images. *Remote sensing*, 10(7):1067, 2018. doi:[10.3390/rs10071067](https://doi.org/10.3390/rs10071067).'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 [2018] Hao Wang、Jie Jiang 和 Guangjun Zhang。CraterIDNet：一个端到端的全卷积神经网络，用于遥感行星图像中的撞击坑检测和识别。*遥感*，10(7):1067，2018。doi:[10.3390/rs10071067](https://doi.org/10.3390/rs10071067)。
- en: Vaniman et al. [1991] David Vaniman, Robert Reedy, Grant Heiken, Gary Olhoeft,
    and Wendell Mendell. The lunar environment. *The lunar Sourcebook*, pages 27–60,
    1991. URL [https://ci.nii.ac.jp/naid/10003734174/en/](https://ci.nii.ac.jp/naid/10003734174/en/).
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaniman 等 [1991] David Vaniman、Robert Reedy、Grant Heiken、Gary Olhoeft 和 Wendell
    Mendell。月球环境。*月球参考书*，第27–60页，1991。URL [https://ci.nii.ac.jp/naid/10003734174/en/](https://ci.nii.ac.jp/naid/10003734174/en/)。
- en: Emami et al. [2015] Ebrahim Emami, George Bebis, Ara Nefian, and Terry Fong.
    Automatic crater detection using convex grouping and convolutional neural networks.
    In *International symposium on visual computing*, pages 213–224, 2015. doi:[10.1007/978-3-319-27863-6_20](https://doi.org/10.1007/978-3-319-27863-6_20).
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Emami 等 [2015] Ebrahim Emami、George Bebis、Ara Nefian 和 Terry Fong。使用凸分组和卷积神经网络进行自动化撞击坑检测。*国际视觉计算研讨会论文集*，第213–224页，2015。doi:[10.1007/978-3-319-27863-6_20](https://doi.org/10.1007/978-3-319-27863-6_20)。
- en: Cohen et al. [2016] Joseph Paul Cohen, Henry Z Lo, Tingting Lu, and Wei Ding.
    Crater detection via convolutional neural networks. 2016. URL [http://arxiv.org/abs/1601.00978](http://arxiv.org/abs/1601.00978).
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cohen 等 [2016] Joseph Paul Cohen、Henry Z Lo、Tingting Lu 和 Wei Ding。通过卷积神经网络进行撞击坑检测。2016。URL
    [http://arxiv.org/abs/1601.00978](http://arxiv.org/abs/1601.00978)。
- en: Palafox et al. [2017] Leon F Palafox, Christopher W Hamilton, Stephen P Scheidt,
    and Alexander M Alvarez. Automated detection of geological landforms on Mars using
    convolutional neural networks. *Computers & Geosciences*, 101:48–56, 2017. doi:[10.1016/j.cageo.2016.12.015](https://doi.org/10.1016/j.cageo.2016.12.015).
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Palafox 等 [2017] Leon F Palafox、Christopher W Hamilton、Stephen P Scheidt 和 Alexander
    M Alvarez。使用卷积神经网络自动检测火星上的地质地貌。*计算机与地球科学*，101:48–56，2017。doi:[10.1016/j.cageo.2016.12.015](https://doi.org/10.1016/j.cageo.2016.12.015)。
- en: 'O’Keefe and Ahrens [1999] J. D. O’Keefe and T. J. Ahrens. Complex craters:
    Relationship of stratigraphy and rings to impact conditions. *Journal of Geophysical
    Research Planets*, 104:27091–27104, 1999. doi:[10.1029/1998je000596](https://doi.org/10.1029/1998je000596).'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: O’Keefe 和 Ahrens [1999] J. D. O’Keefe 和 T. J. Ahrens. 复杂撞击坑：地层学和环形结构与撞击条件的关系。*地球物理研究行星学报*，104:27091–27104，1999。doi:[10.1029/1998je000596](https://doi.org/10.1029/1998je000596)。
- en: 'Klear [2018] Michael R Klear. Pycda: An open-source library for automated crater
    detection. *Proceedings of the 9th Planetary Crater Consort, Boulder, CO*, 2018.
    URL [http://planetarycraterconsortium.nau.edu/KlearPCC9.pdf](http://planetarycraterconsortium.nau.edu/KlearPCC9.pdf).'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Klear [2018] Michael R Klear. Pycda: 一个用于自动化撞击坑检测的开源库。*第九届行星撞击坑协会年会论文集，科罗拉多州博尔德*，2018。URL
    [http://planetarycraterconsortium.nau.edu/KlearPCC9.pdf](http://planetarycraterconsortium.nau.edu/KlearPCC9.pdf)。'
- en: 'Robbins and Hynek [2012] Stuart J. Robbins and Brian M. Hynek. A new global
    database of mars impact craters $\geq$1 km: 2\. global crater properties and regional
    variations of the simple-to-complex transition diameter. *Journal of Geophysical
    Research: Planets*, 117(E6), June 2012. doi:[10.1029/2011je003967](https://doi.org/10.1029/2011je003967).'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Robbins 和 Hynek [2012] Stuart J. Robbins 和 Brian M. Hynek. 一个新的火星撞击坑全球数据库 $\geq$1
    km: 2. 全球撞击坑属性及简单-复杂过渡直径的区域变化。*地球物理研究：行星学报*，117(E6)，2012年6月。doi:[10.1029/2011je003967](https://doi.org/10.1029/2011je003967)。'
- en: Silburt et al. [2019] Ari Silburt, Mohamad Ali-Dib, Chenchong Zhu, Alan Jackson,
    Diana Valencia, Yevgeni Kissin, Daniel Tamayo, and Kristen Menou. Lunar crater
    identification via deep learning. *Icarus*, 317:27–38, 2019. doi:[10.1016/j.icarus.2018.06.022](https://doi.org/10.1016/j.icarus.2018.06.022).
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Silburt et al. [2019] Ari Silburt, Mohamad Ali-Dib, Chenchong Zhu, Alan Jackson,
    Diana Valencia, Yevgeni Kissin, Daniel Tamayo, 和 Kristen Menou. 通过深度学习识别月球陨石坑。*Icarus*,
    317:27–38, 2019. doi:[10.1016/j.icarus.2018.06.022](https://doi.org/10.1016/j.icarus.2018.06.022).
- en: 'Ronneberger et al. [2015] Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
    U-net: Convolutional networks for biomedical image segmentation. In *Lecture Notes
    in Computer Science*, pages 234–241\. Springer International Publishing, 2015.
    doi:[10.1007/978-3-319-24574-4_28](https://doi.org/10.1007/978-3-319-24574-4_28).'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ronneberger et al. [2015] Olaf Ronneberger, Philipp Fischer, 和 Thomas Brox.
    U-net: 用于生物医学图像分割的卷积网络. 见 *Lecture Notes in Computer Science*, 第234–241页。Springer
    International Publishing, 2015. doi:[10.1007/978-3-319-24574-4_28](https://doi.org/10.1007/978-3-319-24574-4_28).'
- en: 'Srivastava et al. [2014] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
    Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural
    networks from overfitting. *Journal of Machine Learning Research*, 15(1):1929–1958,
    2014. URL [http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf).'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Srivastava et al. [2014] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
    Ilya Sutskever, 和 Ruslan Salakhutdinov. Dropout: 一种防止神经网络过拟合的简单方法。*Journal of
    Machine Learning Research*, 15(1):1929–1958, 2014. URL [http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf).'
- en: 'Povilaitis et al. [2018] RZ Povilaitis, MS Robinson, CH Van der Bogert, Harald
    Hiesinger, HM Meyer, and LR Ostrach. Crater density differences: Exploring regional
    resurfacing, secondary crater populations, and crater saturation equilibrium on
    the moon. *Planetary and Space Science*, 162:41–51, 2018. doi:[10.1016/j.pss.2017.05.006](https://doi.org/10.1016/j.pss.2017.05.006).'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Povilaitis et al. [2018] RZ Povilaitis, MS Robinson, CH Van der Bogert, Harald
    Hiesinger, HM Meyer, 和 LR Ostrach. 陨石坑密度差异：探索月球的区域再造、二次陨石坑群体和陨石坑饱和平衡。*Planetary
    and Space Science*, 162:41–51, 2018. doi:[10.1016/j.pss.2017.05.006](https://doi.org/10.1016/j.pss.2017.05.006).
- en: 'Head et al. [2010] James W Head, Caleb I Fassett, Seth J Kadish, David E Smith,
    Maria T Zuber, Gregory A Neumann, and Erwan Mazarico. Global distribution of large
    lunar craters: Implications for resurfacing and impactor populations. *science*,
    329(5998):1504–1507, 2010. doi:[10.1126/science.1195050](https://doi.org/10.1126/science.1195050).'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Head et al. [2010] James W Head, Caleb I Fassett, Seth J Kadish, David E Smith,
    Maria T Zuber, Gregory A Neumann, 和 Erwan Mazarico. 大型月球陨石坑的全球分布：对再造和撞击体群体的影响。*science*,
    329(5998):1504–1507, 2010. doi:[10.1126/science.1195050](https://doi.org/10.1126/science.1195050).
- en: Lee et al. [2020] Hoonhee Lee, Han-Lim Choi, Dawoon Jung, and Sujin Choi. Deep
    neural network-based landmark selection method for optical navigation on lunar
    highlands. *IEEE Access*, 8:99010–99023, 2020. doi:[10.1109/ACCESS.2020.2996403](https://doi.org/10.1109/ACCESS.2020.2996403).
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee et al. [2020] Hoonhee Lee, Han-Lim Choi, Dawoon Jung, 和 Sujin Choi. 基于深度神经网络的月球高地光学导航地标选择方法。*IEEE
    Access*, 8:99010–99023, 2020. doi:[10.1109/ACCESS.2020.2996403](https://doi.org/10.1109/ACCESS.2020.2996403).
- en: Klumpp [1974] Allan R Klumpp. Apollo lunar descent guidance. *Automatica*, 10(2):133–146,
    1974. doi:[10.1016/0005-1098(74)90019-3](https://doi.org/10.1016/0005-1098(74)90019-3).
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Klumpp [1974] Allan R Klumpp. 阿波罗月球下降引导. *Automatica*, 10(2):133–146, 1974.
    doi:[10.1016/0005-1098(74)90019-3](https://doi.org/10.1016/0005-1098(74)90019-3).
- en: Epp et al. [2008] Chirold D Epp, Edward A Robertson, and Tye Brady. Autonomous
    landing and hazard avoidance technology (ALHAT). In *2008 IEEE Aerospace Conference*,
    pages 1–7, 2008. doi:[10.1109/aero.2008.4526297](https://doi.org/10.1109/aero.2008.4526297).
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Epp et al. [2008] Chirold D Epp, Edward A Robertson, 和 Tye Brady. 自动着陆与危险规避技术（ALHAT）。见
    *2008 IEEE Aerospace Conference*, 第1–7页, 2008. doi:[10.1109/aero.2008.4526297](https://doi.org/10.1109/aero.2008.4526297).
- en: Furfaro et al. [2012] Roberto Furfaro, Wolfgang Fink, and Jeffrey S Kargel.
    Autonomous real-time landing site selection for Venus and Titan using evolutionary
    fuzzy cognitive maps. *Applied Soft Computing*, 12(12):3825–3839, 2012. doi:[10.1016/j.asoc.2012.01.014](https://doi.org/10.1016/j.asoc.2012.01.014).
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Furfaro et al. [2012] Roberto Furfaro, Wolfgang Fink, 和 Jeffrey S Kargel. 使用进化模糊认知图进行金星和泰坦的自主实时着陆点选择。*Applied
    Soft Computing*, 12(12):3825–3839, 2012. doi:[10.1016/j.asoc.2012.01.014](https://doi.org/10.1016/j.asoc.2012.01.014).
- en: Maturana and Scherer [2015] Daniel Maturana and Sebastian Scherer. 3D convolutional
    neural networks for landing zone detection from LiDAR. In *2015 IEEE International
    Conference on Robotics and Automation (ICRA)*, pages 3471–3478, 2015. doi:[10.1109/icra.2015.7139679](https://doi.org/10.1109/icra.2015.7139679).
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maturana 和 Scherer [2015] Daniel Maturana 和 Sebastian Scherer。用于从 LiDAR 中检测着陆区的
    3D 卷积神经网络。见于 *2015 IEEE 国际机器人与自动化会议 (ICRA)*，页码 3471–3478，2015年。doi:[10.1109/icra.2015.7139679](https://doi.org/10.1109/icra.2015.7139679)。
- en: Lunghi and Lavagna [2014] Paolo Lunghi and Michèle Lavagna. Autonomous vision-based
    hazard map generator for planetary landing phases. In *65th International Astronautical
    Congress (IAC)*, pages 5103–5114, 2014. URL [http://hdl.handle.net/11311/861150](http://hdl.handle.net/11311/861150).
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lunghi 和 Lavagna [2014] Paolo Lunghi 和 Michèle Lavagna。用于行星着陆阶段的自主视觉基础危险地图生成器。见于
    *第65届国际宇航大会 (IAC)*，页码 5103–5114，2014年。URL [http://hdl.handle.net/11311/861150](http://hdl.handle.net/11311/861150)。
- en: Lunghi et al. [2016] Paolo Lunghi, Marco Ciarambino, and Michèle Lavagna. A
    multilayer perceptron hazard detector for vision-based autonomous planetary landing.
    *Advances in Space Research*, 58(1):131–144, July 2016. doi:[10.1016/j.asr.2016.04.012](https://doi.org/10.1016/j.asr.2016.04.012).
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lunghi 等 [2016] Paolo Lunghi、Marco Ciarambino 和 Michèle Lavagna。用于基于视觉的自主行星着陆的多层感知机危险检测器。*太空研究进展*，58(1)：131–144，2016年7月。doi:[10.1016/j.asr.2016.04.012](https://doi.org/10.1016/j.asr.2016.04.012)。
- en: Moghe and Zanetti [2020a] Rahul Moghe and Renato Zanetti. On-line hazard detection
    algorithm for precision lunar landing using semantic segmentation. In *AIAA Scitech
    2020 Forum*. American Institute of Aeronautics and Astronautics, January 2020a.
    doi:[10.2514/6.2020-0462](https://doi.org/10.2514/6.2020-0462).
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moghe 和 Zanetti [2020a] Rahul Moghe 和 Renato Zanetti。用于精确月球着陆的在线危险检测算法，采用语义分割技术。见于
    *AIAA Scitech 2020 论坛*。美国航空航天学会，2020年1月。doi:[10.2514/6.2020-0462](https://doi.org/10.2514/6.2020-0462)。
- en: Moghe and Zanetti [2020b] Rahul Moghe and Renato Zanetti. A deep learning approach
    to hazard detection for autonomous lunar landing. *The Journal of the Astronautical
    Sciences*, 67(4):1811–1830, 2020b. doi:[10.1007/s40295-020-00239-8](https://doi.org/10.1007/s40295-020-00239-8).
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moghe 和 Zanetti [2020b] Rahul Moghe 和 Renato Zanetti。用于自主月球着陆的深度学习危险检测方法。*宇航科学杂志*，67(4)：1811–1830，2020年。doi:[10.1007/s40295-020-00239-8](https://doi.org/10.1007/s40295-020-00239-8)。
- en: 'Buslaev et al. [2020] Alexander Buslaev, Vladimir I Iglovikov, Eugene Khvedchenya,
    Alex Parinov, Mikhail Druzhinin, and Alexandr A Kalinin. Albumentations: Fast
    and flexible image augmentations. *Information*, 11(2):125, 2020. doi:[10.3390/info11020125](https://doi.org/10.3390/info11020125).'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Buslaev 等 [2020] Alexander Buslaev、Vladimir I Iglovikov、Eugene Khvedchenya、Alex
    Parinov、Mikhail Druzhinin 和 Alexandr A Kalinin。Albumentations：快速且灵活的图像增强技术。*信息*，11(2)：125，2020年。doi:[10.3390/info11020125](https://doi.org/10.3390/info11020125)。
- en: 'Singh and Lim [2008] Leena Singh and Sungyung Lim. On lunar on-orbit vision-based
    navigation: Terrain mapping, feature tracking driven EKF. In *AIAA Guidance, Navigation
    and Control Conference and Exhibit*, page 6834, 2008. doi:[10.2514/6.2008-6834](https://doi.org/10.2514/6.2008-6834).'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singh 和 Lim [2008] Leena Singh 和 Sungyung Lim。关于月球轨道视觉导航：基于地形映射和特征跟踪的扩展卡尔曼滤波。见于
    *AIAA 指导、导航与控制会议及展览*，页码 6834，2008年。doi:[10.2514/6.2008-6834](https://doi.org/10.2514/6.2008-6834)。
- en: Bai et al. [2019] Chengchao Bai, Jifeng Guo, Linli Guo, and Junlin Song. Deep
    multi-layer perception based terrain classification for planetary exploration
    rovers. *Sensors*, 19(14):3102, 2019. doi:[10.3390/s19143102](https://doi.org/10.3390/s19143102).
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai 等 [2019] Chengchao Bai、Jifeng Guo、Linli Guo 和 Junlin Song。基于深度多层感知的行星探测车地形分类。*传感器*，19(14)：3102，2019年。doi:[10.3390/s19143102](https://doi.org/10.3390/s19143102)。
- en: Chengchao [2019] Bai Chengchao. *Research on vision/vibration based Terrain
    perception for rovers*. PhD thesis, Harbin Institute of Technology, Harbin, 2019.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chengchao [2019] Bai Chengchao。*基于视觉/振动的探测车地形感知研究*。博士学位论文，哈尔滨工业大学，哈尔滨，2019年。
- en: Furfaro et al. [2018] Roberto Furfaro, Ilaria Bloise, Marcello Orlandelli, Pierluigi
    Di Lizia, Francesco Topputo, Richard Linares, et al. Deep learning for autonomous
    lunar landing. In *2018 AAS/AIAA Astrodynamics Specialist Conference*, pages 3285–3306,
    2018. URL [http://hdl.handle.net/11311/1063150](http://hdl.handle.net/11311/1063150).
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Furfaro 等 [2018] Roberto Furfaro、Ilaria Bloise、Marcello Orlandelli、Pierluigi
    Di Lizia、Francesco Topputo、Richard Linares 等。深度学习用于自主月球着陆。见于 *2018 AAS/AIAA 天体动力学专业会议*，页码
    3285–3306，2018年。URL [http://hdl.handle.net/11311/1063150](http://hdl.handle.net/11311/1063150)。
- en: 'Patterson and Rao [2014] Michael A. Patterson and Anil V. Rao. GPOPS-II: A
    MATLAB software for solving multiple-phase optimal control problems using hp-adaptive
    gaussian quadrature collocation methods and sparse nonlinear programming. *ACM
    Transactions on Mathematical Software*, 41(1):1–37, October 2014. doi:[10.1145/2558904](https://doi.org/10.1145/2558904).'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Patterson and Rao [2014] Michael A. Patterson 和 Anil V. Rao. GPOPS-II: 一个MATLAB软件，用于解决多阶段最优控制问题，采用hp-adaptive高斯积分配置方法和稀疏非线性规划。*ACM
    Transactions on Mathematical Software*，41(1):1–37，2014年10月。doi:[10.1145/2558904](https://doi.org/10.1145/2558904)。'
- en: Furfaro and Law [2016] Roberto Furfaro and Andrew M. Law. Relative optical navigation
    around small bodies via extreme learning machines. In *2015 AAS/AIAA Astrodynamics
    Specialist Conference*, volume 156, pages 1959–1978, 2016. URL [http://www.scopus.com/inward/record.url?scp=85007336458&partnerID=8YFLogxK](http://www.scopus.com/inward/record.url?scp=85007336458&partnerID=8YFLogxK).
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Furfaro and Law [2016] Roberto Furfaro 和 Andrew M. Law. 通过极端学习机实现对小天体的相对光学导航。发表于*2015
    AAS/AIAA Astrodynamics Specialist Conference*，第156卷，第1959–1978页，2016年。网址 [http://www.scopus.com/inward/record.url?scp=85007336458&partnerID=8YFLogxK](http://www.scopus.com/inward/record.url?scp=85007336458&partnerID=8YFLogxK)。
- en: 'Silburt et al. [2018] Ari Silburt, Chenchong Zhu, Mohamad Ali-Dib, Kristen
    Menou, and Alan Jackson. DeepMoon: Convolutional neural network trainer to identify
    Moon craters. *Astrophysics Source Code Library*, 2018. URL [https://ui.adsabs.harvard.edu/abs/2018ascl.soft05029S](https://ui.adsabs.harvard.edu/abs/2018ascl.soft05029S).'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Silburt et al. [2018] Ari Silburt, Chenchong Zhu, Mohamad Ali-Dib, Kristen
    Menou 和 Alan Jackson. DeepMoon: 卷积神经网络训练器，用于识别月球陨石坑。*Astrophysics Source Code
    Library*，2018年。网址 [https://ui.adsabs.harvard.edu/abs/2018ascl.soft05029S](https://ui.adsabs.harvard.edu/abs/2018ascl.soft05029S)。'
- en: Pugliatti and Topputo [2021] Mattia Pugliatti and Francesco Topputo. Navigation
    about irregular bodies through segmentation maps. In *31st Space Flight Mechanics
    Meeting*, pages AAS21–383, 2021. URL [http://hdl.handle.net/11311/1163932](http://hdl.handle.net/11311/1163932).
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pugliatti and Topputo [2021] Mattia Pugliatti 和 Francesco Topputo. 通过分割图实现对不规则天体的导航。发表于*31st
    Space Flight Mechanics Meeting*，第AAS21–383页，2021年。网址 [http://hdl.handle.net/11311/1163932](http://hdl.handle.net/11311/1163932)。
- en: Beauchamp et al. [2017] P. M. Beauchamp, J. A. Cutts, C. Mercer, and L. A. Dudzinski.
    Technology Planning for NASA’s Future Planetary Science Missions. In *Planetary
    Science Vision 2050 Workshop*, volume 1989, page 8051, February 2017. URL [https://ui.adsabs.harvard.edu/abs/2017LPICo1989.8051B](https://ui.adsabs.harvard.edu/abs/2017LPICo1989.8051B).
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beauchamp et al. [2017] P. M. Beauchamp, J. A. Cutts, C. Mercer 和 L. A. Dudzinski.
    为NASA未来的行星科学任务进行技术规划。发表于*Planetary Science Vision 2050 Workshop*，第1989卷，第8051页，2017年2月。网址
    [https://ui.adsabs.harvard.edu/abs/2017LPICo1989.8051B](https://ui.adsabs.harvard.edu/abs/2017LPICo1989.8051B)。
- en: Shuang and Pingyuan [2008] Li Shuang and Cui Pingyuan. Landmark tracking based
    autonomous navigation schemes for landing spacecraft on asteroids. *Acta Astronautica*,
    62(6-7):391–403, 2008. doi:[10.1016/j.actaastro.2007.11.009](https://doi.org/10.1016/j.actaastro.2007.11.009).
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shuang and Pingyuan [2008] 李爽 和 崔平原。基于地标跟踪的自动导航方案，用于在小行星上着陆。*Acta Astronautica*，62(6-7):391–403，2008年。doi:[10.1016/j.actaastro.2007.11.009](https://doi.org/10.1016/j.actaastro.2007.11.009)。
- en: 'Guffanti [2018] Tommaso Guffanti. Multi-objective autonomous spacecraft motion
    planning around near-earth asteroids using machine learning. Technical Report
    1-6, 2018. URL [http://cs229.stanford.edu/proj2018/report/223.pdf](http://cs229.stanford.edu/proj2018/report/223.pdf).
    CS 229: Final Project.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guffanti [2018] Tommaso Guffanti. 多目标自主航天器在近地小行星附近的运动规划，采用机器学习方法。技术报告 1-6，2018年。网址
    [http://cs229.stanford.edu/proj2018/report/223.pdf](http://cs229.stanford.edu/proj2018/report/223.pdf)。CS
    229: 期末项目。'
- en: Ravani et al. [2021] Khilan Ravani, S. Mathavaraj, and Radhakant Padhi. Site
    detection for autonomous soft-landing on asteroids using deep learning. *Transactions
    of the Indian National Academy of Engineering*, 6(2):365–375, 2021. doi:[10.1007/s41403-021-00207-0](https://doi.org/10.1007/s41403-021-00207-0).
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ravani et al. [2021] Khilan Ravani, S. Mathavaraj 和 Radhakant Padhi. 使用深度学习进行小行星上自动软着陆的站点检测。*Transactions
    of the Indian National Academy of Engineering*，6(2):365–375，2021年。doi:[10.1007/s41403-021-00207-0](https://doi.org/10.1007/s41403-021-00207-0)。
- en: Harl et al. [2013] Nathan Harl, Karthikeyan Rajagopal, and SN Balakrishnan.
    Neural network based modified state observer for orbit uncertainty estimation.
    *Journal of Guidance, Control, and Dynamics*, 36(4):1194–1209, 2013. doi:[10.2514/1.55711](https://doi.org/10.2514/1.55711).
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Harl et al. [2013] Nathan Harl, Karthikeyan Rajagopal 和 SN Balakrishnan. 基于神经网络的改进状态观测器用于轨道不确定性估计。*Journal
    of Guidance, Control, and Dynamics*，36(4):1194–1209，2013年。doi:[10.2514/1.55711](https://doi.org/10.2514/1.55711)。
- en: Song et al. [2019] Yu Song, Lin Cheng, and Shengping Gong. Fast estimation of
    gravitational field of irregular asteroids based on deep neural network and its
    application. In *Advances in the Astronautical Sciences AAS/AIAA Spaceflight Mechanics*,
    volume 168, pages AAS 19–397, 2019. URL [https://www.researchgate.net/profile/Yu-Song-45/publication/331523846_FAST_ESTIMATION_OF_GRAVITATIONAL_FIELD_OF_IRREGULAR_ASTEROIDS_BASED_ON_DEEP_NEURAL_NETWORK_AND_ITS_APPLICATION/links/5c7e5d9c458515831f8421a7/FAST-ESTIMATION-OF-GRAVITATIONAL-FIELD-OF-IRREGULAR-ASTEROIDS-BASED-ON-DEEP-NEURAL-NETWORK-AND-ITS-APPLICATION.pdf](https://www.researchgate.net/profile/Yu-Song-45/publication/331523846_FAST_ESTIMATION_OF_GRAVITATIONAL_FIELD_OF_IRREGULAR_ASTEROIDS_BASED_ON_DEEP_NEURAL_NETWORK_AND_ITS_APPLICATION/links/5c7e5d9c458515831f8421a7/FAST-ESTIMATION-OF-GRAVITATIONAL-FIELD-OF-IRREGULAR-ASTEROIDS-BASED-ON-DEEP-NEURAL-NETWORK-AND-ITS-APPLICATION.pdf).
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song 等 [2019] Yu Song、Lin Cheng 和 Shengping Gong. 基于深度神经网络的非规则小行星引力场的快速估计及其应用。在*《航天科学进展
    AAS/AIAA 空间飞行力学》*，第 168 卷，第 AAS 19–397 页，2019年。网址 [https://www.researchgate.net/profile/Yu-Song-45/publication/331523846_FAST_ESTIMATION_OF_GRAVITATIONAL_FIELD_OF_IRREGULAR_ASTEROIDS_BASED_ON_DEEP_NEURAL_NETWORK_AND_ITS_APPLICATION/links/5c7e5d9c458515831f8421a7/FAST-ESTIMATION-OF-GRAVITATIONAL-FIELD-OF-IRREGULAR-ASTEROIDS-BASED-ON-DEEP-NEURAL-NETWORK-AND-ITS-APPLICATION.pdf](https://www.researchgate.net/profile/Yu-Song-45/publication/331523846_FAST_ESTIMATION_OF_GRAVITATIONAL_FIELD_OF_IRREGULAR_ASTEROIDS_BASED_ON_DEEP_NEURAL_NETWORK_AND_ITS_APPLICATION/links/5c7e5d9c458515831f8421a7/FAST-ESTIMATION-OF-GRAVITATIONAL-FIELD-OF-IRREGULAR-ASTEROIDS-BASED-ON-DEEP-NEURAL-NETWORK-AND-ITS-APPLICATION.pdf)。
- en: Kalita et al. [2017] Himangshu Kalita, Erik Asphaug, Stephen Schwartz, and Jekanthan
    Thangavelautham. Network of nano-landers for in-situ characterization of asteroid
    impact studies. In *68th International Astronautical Congress (IAC)*, Adelaide,
    Australia, 2017. URL [http://arxiv.org/abs/1709.02885](http://arxiv.org/abs/1709.02885).
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kalita 等 [2017] Himangshu Kalita、Erik Asphaug、Stephen Schwartz 和 Jekanthan Thangavelautham.
    用于小行星撞击研究的纳米着陆器网络。在*第68届国际宇航大会（IAC）*，澳大利亚阿德莱德，2017年。网址 [http://arxiv.org/abs/1709.02885](http://arxiv.org/abs/1709.02885)。
- en: 'Feruglio et al. [2016] Lorenzo Feruglio, Sabrina Corpino, and Daniele Calvi.
    Neural networks for event detection: an interplanetary CubeSat asteroid mission
    case study. In *AIAA SPACE 2016*. American Institute of Aeronautics and Astronautics,
    sep 2016. doi:[10.2514/6.2016-5615](https://doi.org/10.2514/6.2016-5615).'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feruglio 等 [2016] Lorenzo Feruglio、Sabrina Corpino 和 Daniele Calvi. 用于事件检测的神经网络：一次星际立方卫星小行星任务案例研究。在*AIAA
    SPACE 2016*。美国航空航天学会，2016年9月。doi:[10.2514/6.2016-5615](https://doi.org/10.2514/6.2016-5615)。
- en: Viavattene and Ceriotti [2019] Giulia Viavattene and Matteo Ceriotti. Artificial
    neural network for preliminary multiple nea rendezvous mission using low thrust.
    In *70th International Astronautical Congress (IAC), Washington, DC, USA*, 2019.
    URL [http://eprints.gla.ac.uk/202035/1/202035.pdf](http://eprints.gla.ac.uk/202035/1/202035.pdf).
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Viavattene 和 Ceriotti [2019] Giulia Viavattene 和 Matteo Ceriotti. 用于初步多个近地天体会合任务的人工神经网络，采用低推力。在*第70届国际宇航大会（IAC），美国华盛顿特区*，2019年。网址
    [http://eprints.gla.ac.uk/202035/1/202035.pdf](http://eprints.gla.ac.uk/202035/1/202035.pdf)。
- en: Pugliatti and Topputo [2020] Mattia Pugliatti and Francesco Topputo. Small-body
    shape recognition with convolutional neural network and comparison with explicit
    features based method. In *2020 AAS/AIAA Astrodynamics Specialist Conference*,
    pages 1–20, 2020. URL [https://re.public.polimi.it/retrieve/handle/11311/1145538/537728/PUGLM01-20.pdf](https://re.public.polimi.it/retrieve/handle/11311/1145538/537728/PUGLM01-20.pdf).
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pugliatti 和 Topputo [2020] Mattia Pugliatti 和 Francesco Topputo. 使用卷积神经网络进行小天体形状识别并与显式特征方法进行比较。在*2020
    AAS/AIAA 天体动力学专家会议*，第 1–20 页，2020年。网址 [https://re.public.polimi.it/retrieve/handle/11311/1145538/537728/PUGLM01-20.pdf](https://re.public.polimi.it/retrieve/handle/11311/1145538/537728/PUGLM01-20.pdf)。
- en: 'Abadi et al. [2016] Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo,
    Zhifeng Chen, Craig Citro, Greg S Corrado, Andy Davis, Jeffrey Dean, Matthieu
    Devin, et al. Tensorflow: Large-scale machine learning on heterogeneous distributed
    systems. 2016. URL [http://arxiv.org/abs/1603.04467](http://arxiv.org/abs/1603.04467).'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abadi 等 [2016] Martín Abadi、Ashish Agarwal、Paul Barham、Eugene Brevdo、Zhifeng
    Chen、Craig Citro、Greg S Corrado、Andy Davis、Jeffrey Dean、Matthieu Devin 等。Tensorflow：在异构分布式系统上的大规模机器学习。2016年。网址
    [http://arxiv.org/abs/1603.04467](http://arxiv.org/abs/1603.04467)。
- en: Long et al. [2015] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully
    convolutional networks for semantic segmentation. In *Proceedings of the IEEE
    conference on computer vision and pattern recognition*, pages 3431–3440, 2015.
    URL [https://openaccess.thecvf.com/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf](https://openaccess.thecvf.com/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf).
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Long 等人 [2015] Jonathan Long、Evan Shelhamer 和 Trevor Darrell。用于语义分割的全卷积网络。发表于
    *IEEE 计算机视觉与模式识别会议论文集*，第 3431–3440 页，2015 年。网址 [https://openaccess.thecvf.com/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf](https://openaccess.thecvf.com/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)。
