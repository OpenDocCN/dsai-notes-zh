- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-06 19:39:52'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 19:39:52'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2305.06611] Hyperbolic Deep Learning in Computer Vision: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2305.06611] 超曲率深度学习在计算机视觉中的应用：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2305.06611](https://ar5iv.labs.arxiv.org/html/2305.06611)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2305.06611](https://ar5iv.labs.arxiv.org/html/2305.06611)
- en: ∎
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ∎
- en: '¹¹institutetext: Pascal Mettes ²²institutetext: University of Amsterdam, the
    Netherlands'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '¹¹institutetext: Pascal Mettes ²²institutetext: 阿姆斯特丹大学，荷兰'
- en: '²²email: p.s.m.mettes@uva.nl ³³institutetext: Mina Ghadimi Atigh ⁴⁴institutetext:
    University of Amsterdam, the Netherlands'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '²²电子邮件: p.s.m.mettes@uva.nl ³³institutetext: Mina Ghadimi Atigh ⁴⁴institutetext:
    阿姆斯特丹大学，荷兰'
- en: '⁴⁴email: m.ghadimiatigh@uva.nl ⁵⁵institutetext: Martin Keller-Ressel ⁶⁶institutetext:
    TU Dresden, Germany'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '⁴⁴电子邮件: m.ghadimiatigh@uva.nl ⁵⁵institutetext: Martin Keller-Ressel ⁶⁶institutetext:
    德累斯顿工业大学，德国'
- en: '⁶⁶email: martin.keller-ressel@tu-dresden.de ⁷⁷institutetext: Jeffrey Gu ⁸⁸institutetext:
    Stanford University, USA'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '⁶⁶电子邮件: martin.keller-ressel@tu-dresden.de ⁷⁷institutetext: Jeffrey Gu ⁸⁸institutetext:
    斯坦福大学，美国'
- en: '⁸⁸email: jeffgu@stanford.edu ⁹⁹institutetext: Serena Yeung ^(10)^(10)institutetext:
    Stanford University, USA'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '⁸⁸电子邮件: jeffgu@stanford.edu ⁹⁹institutetext: Serena Yeung ^(10)^(10)institutetext:
    斯坦福大学，美国'
- en: '^(10)^(10)email: syyeung@stanford.edu'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '^(10)^(10)电子邮件: syyeung@stanford.edu'
- en: 'Hyperbolic Deep Learning in Computer Vision: A Survey'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超曲率深度学习在计算机视觉中的应用：综述
- en: 'Pascal Mettes    Mina Ghadimi Atigh    Martin Keller-Ressel    Jeffrey Gu   
    Serena Yeung(Received: date / Accepted: date)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 'Pascal Mettes    Mina Ghadimi Atigh    Martin Keller-Ressel    Jeffrey Gu   
    Serena Yeung（收到: 日期 / 接受: 日期）'
- en: Abstract
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep representation learning is a ubiquitous part of modern computer vision.
    While Euclidean space has been the de facto standard manifold for learning visual
    representations, hyperbolic space has recently gained rapid traction for learning
    in computer vision. Specifically, hyperbolic learning has shown a strong potential
    to embed hierarchical structures, learn from limited samples, quantify uncertainty,
    add robustness, limit error severity, and more. In this paper, we provide a categorization
    and in-depth overview of current literature on hyperbolic learning for computer
    vision. We research both supervised and unsupervised literature and identify three
    main research themes in each direction. We outline how hyperbolic learning is
    performed in all themes and discuss the main research problems that benefit from
    current advances in hyperbolic learning for computer vision. Moreover, we provide
    a high-level intuition behind hyperbolic geometry and outline open research questions
    to further advance research in this direction.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 深度表示学习是现代计算机视觉的一个普遍组成部分。虽然欧几里得空间一直是学习视觉表示的事实标准流形，但超曲率空间最近在计算机视觉学习中迅速获得了关注。具体而言，超曲率学习在嵌入层次结构、从有限样本中学习、量化不确定性、增加鲁棒性、限制错误严重性等方面表现出强大的潜力。在这篇论文中，我们对当前关于计算机视觉的超曲率学习文献进行了分类和深入概述。我们研究了有监督和无监督的文献，并在每个方向上确定了三个主要的研究主题。我们概述了超曲率学习在所有主题中的实施方法，并讨论了从当前超曲率学习进展中受益的主要研究问题。此外，我们提供了超曲率几何的高层次直觉，并概述了进一步推进该方向研究的开放研究问题。
- en: '^†^†journal: International Journal of Computer Vision'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '^†^†期刊: 国际计算机视觉杂志'
- en: 1 Introduction
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: From image segmentation to future frame prediction and from video grounding
    to generating images, deep representation learning is the central component that
    drives modern computer vision problems (LeCun et al, [2015](#bib.bib75)). In short
    succession, many differentiable layers and network architectures have been proposed
    to tackle visual research problems (Gu et al, [2018](#bib.bib49); Bommasani et al,
    [2021](#bib.bib11); Khan et al, [2022](#bib.bib66)). While different in structure,
    scope, and inductive biases, all are based on Euclidean operators and therefore
    - implicitly or explicitly - assume that data is best represented on regular grids.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 从图像分割到未来帧预测，从视频定位到生成图像，深度表示学习是推动现代计算机视觉问题的核心组成部分（LeCun et al, [2015](#bib.bib75)）。在短时间内，提出了许多可微分的层和网络架构来解决视觉研究问题（Gu
    et al, [2018](#bib.bib49); Bommasani et al, [2021](#bib.bib11); Khan et al, [2022](#bib.bib66)）。尽管结构、范围和归纳偏差不同，但所有这些方法都基于欧几里得运算符，因此
    - 无论是隐式还是显式 - 都假设数据在规则网格上表示最佳。
- en: Euclidean space forms an intuitive and grounded underlying manifold, but its
    inherent properties are not a best match for all types of data. Consider for example
    hierarchical structures such as trees, ontologies, and taxonomies. Hierarchies
    are foundational building blocks across all scientific disciplines to formalize
    our knowledge (Noy and Hafner, [1997](#bib.bib95)). In hierarchies, the number
    of nodes grows exponentially with depth, from few coarse-grained to many fine-grained
    nodes. The volume of a ball in Euclidean space however, grows only polynomially
    with its diameter. An alternative geometry is needed to match the nature of hierarchies.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 欧几里得空间形成了一个直观且基础的流形，但其固有属性并不适用于所有类型的数据。例如，考虑像树状结构、范畴和分类法这样的层次结构。层次结构是所有科学学科中用于形式化我们知识的基础构件（Noy
    和 Hafner，[1997](#bib.bib95)）。在层次结构中，节点数量随着深度呈指数增长，从少量粗略节点到许多细粒度节点。然而，在欧几里得空间中，球体的体积仅随着直径多项式增长。需要一种替代几何来匹配层次结构的性质。
- en: 'In the quest for a more appropriate geometry of hierarchies, hyperbolic geometry
    provides a direct fit (Bridson and Haefliger, [2013](#bib.bib13)). In essence,
    hyperbolic and Euclidean geometry are different in only one aspect: the parallel
    postulate. In Euclidean space, there is exactly one parallel line that goes through
    a point not on the other line. In hyperbolic space, there are at least two such
    parallel lines. This change comes with many consequences and as a result, hyperbolic
    geometry can be seen as a geometry of constant negative curvature. In the context
    of deep learning this geometry has many attractive properties, such as its hierarchical
    structure and exponential expansion.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在寻找更合适的层次几何形态的过程中，双曲几何提供了直接的适配（Bridson 和 Haefliger，[2013](#bib.bib13)）。本质上，双曲几何和欧几里得几何在唯一一个方面不同：平行公设。在欧几里得空间中，通过一个不在另一条直线上的点有且只有一条平行直线。在双曲空间中，至少有两条这样的平行直线。这一变化带来了许多后果，因此双曲几何可以被视为一种具有恒定负曲率的几何。在深度学习的背景下，这种几何具有许多吸引人的特性，如其层次结构和指数扩展。
- en: Empowered by these geometric properties, hierarchical embeddings have in recent
    years been performed in hyperbolic space with great success (Nickel and Kiela,
    [2017](#bib.bib93)), leading to unparalleled abilities to embed deep and complex
    trees with minimal distortion (Ganea et al, [2018a](#bib.bib40); Sala et al, [2018](#bib.bib102)).
    This has led to rapid advances in hyperbolic deep learning across many disciplines
    and research areas, including but not limited to graph networks (Chami et al,
    [2019](#bib.bib16); Liu et al, [2019](#bib.bib80); Dai et al, [2021](#bib.bib29)),
    text embeddings (Tifrea et al, [2019](#bib.bib110); Zhu et al, [2020](#bib.bib134)),
    molecular representation learning (Klimovskaia et al, [2020](#bib.bib72); Yu et al,
    [2020](#bib.bib126); Wu et al, [2021](#bib.bib121)), and recommender systems (Mirvakhabova
    et al, [2020](#bib.bib88); Wang et al, [2021](#bib.bib118); Yang et al, [2022](#bib.bib125)).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 受到这些几何特性的启发，近年来层次嵌入在双曲空间中取得了巨大的成功（Nickel 和 Kiela，[2017](#bib.bib93)），使得嵌入深度复杂树结构的能力达到了前所未有的水平，*失真最小*（Ganea
    等，[2018a](#bib.bib40)；Sala 等，[2018](#bib.bib102)）。这推动了许多学科和研究领域中双曲深度学习的快速进展，包括但不限于图网络（Chami
    等，[2019](#bib.bib16)；Liu 等，[2019](#bib.bib80)；Dai 等，[2021](#bib.bib29)），文本嵌入（Tifrea
    等，[2019](#bib.bib110)；Zhu 等，[2020](#bib.bib134)），分子表示学习（Klimovskaia 等，[2020](#bib.bib72)；Yu
    等，[2020](#bib.bib126)；Wu 等，[2021](#bib.bib121)），以及推荐系统（Mirvakhabova 等，[2020](#bib.bib88)；Wang
    等，[2021](#bib.bib118)；Yang 等，[2022](#bib.bib125)）。
- en: In the wake of other disciplines, computer vision has in recent years also benefited
    from research into deep learning in hyperbolic space. A quickly growing body of
    literature has shown that hyperbolic embeddings benefit few-shot learning, zero-shot
    recognition, out-of-distribution generalization, uncertainty quantification, generative
    learning, and hierarchical representation learning amongst others. These works
    show evidence that hyperbolic geometry has a lot of potential for learning in
    computer vision.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 紧随其他学科，计算机视觉近年来也从对双曲空间深度学习的研究中受益。大量文献显示，双曲嵌入有助于*少样本学习*、*零样本识别*、*分布外泛化*、*不确定性量化*、*生成学习*以及*层次表示学习*等。这些工作表明双曲几何在计算机视觉学习中具有巨大的潜力。
- en: This survey provides an in-depth overview and categorization of the recent boom
    in hyperbolic computer vision literature. These works have investigated hyperbolic
    learning across many visual research problems with different solutions. As a result,
    it is unclear how current literature is connected, what is common and new in each
    work, and in which direction the field is heading. This survey seeks to fill this
    void. We investigate both supervised and unsupervised papers. For supervised learning,
    we identify three shared themes amongst current papers, where samples are matched
    to either gyroplanes, prototypes, or other samples in hyperbolic space. For unsupervised
    papers, we dive into the three main axes explored in current papers, namely generative
    learning, clustering, and self-supervised learning. Peng et al ([2021](#bib.bib96))
    have recently written a general survey on hyperbolic neural networks but their
    scope did not include the computer vision literature on hyperbolic learning. This
    survey fills this void.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本综述提供了对双曲计算机视觉文献近期繁荣的深入概述和分类。这些研究探讨了在许多视觉研究问题上应用双曲学习的不同解决方案。因此，目前的文献如何连接、每项工作中的共同点和新颖点以及该领域的发展方向尚不清楚。本综述旨在填补这一空白。我们调查了有监督和无监督的论文。对于有监督学习，我们识别了当前论文中的三个共同主题，即样本与双曲空间中的陀螺体、原型或其他样本匹配。对于无监督论文，我们深入探讨了当前论文中探索的三个主要轴，即生成学习、聚类和自监督学习。Peng等人（[2021](#bib.bib96)）最近撰写了一份关于双曲神经网络的一般综述，但他们的范围没有包括双曲学习的计算机视觉文献。本综述填补了这一空白。
- en: 'The rest of the paper is organised as follows. In Section [2](#S2 "2 Background
    on hyperbolic geometry ‣ Hyperbolic Deep Learning in Computer Vision: A Survey")
    we provide the background on hyperbolic geometry and foundational papers on hyperbolic
    embeddings and hyperbolic neural networks. Sections [3](#S3 "3 Supervised hyperbolic
    visual learning ‣ Hyperbolic Deep Learning in Computer Vision: A Survey") and
    [4](#S4 "4 Unsupervised hyperbolic visual learning ‣ Hyperbolic Deep Learning
    in Computer Vision: A Survey") provide an overview of supervised and unsupervised
    hyperbolic visual learning literature. Lastly in Section [5](#S5 "5 Conclusions
    and future outlook ‣ Hyperbolic Deep Learning in Computer Vision: A Survey") we
    outline advantages and improvements reported in current papers, as well as open
    challenges for the field.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的其余部分组织如下。在第[2](#S2 "2 关于双曲几何的背景 ‣ 计算机视觉中的双曲深度学习：综述")节中，我们提供了双曲几何的背景及双曲嵌入和双曲神经网络的基础论文。第[3](#S3
    "3 有监督的双曲视觉学习 ‣ 计算机视觉中的双曲深度学习：综述")节和第[4](#S4 "4 无监督的双曲视觉学习 ‣ 计算机视觉中的双曲深度学习：综述")节概述了有监督和无监督双曲视觉学习的文献。最后，在第[5](#S5
    "5 结论与未来展望 ‣ 计算机视觉中的双曲深度学习：综述")节中，我们概述了当前论文中报告的优点和改进，以及该领域的开放挑战。
- en: 2 Background on hyperbolic geometry
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 关于双曲几何的背景
- en: 2.1 What is hyperbolic geometry?
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 什么是双曲几何？
- en: Hyperbolic geometry was initially developed in the 19th century by Gauss, Lobachevsky,
    Bolyai and others as a concrete example of a non-Euclidean geometry. Soon after
    it found important applications in physics, as the mathematical basis of Einstein’s
    special theory of relativity. It can be characterized as the geometry of *constant
    negative curvature*, differentiating it from the flat geometry of Euclidean space
    and the positively curved geometry of spheres and hyperspheres. From the point
    of view of representation learning, its attractive properties are its exponential
    expansion and its hierarchical, tree-like structure. Exponential expansion means
    that the volume of a ball in hyperbolic space growths exponentially with its diameter,
    in contrast to Euclidean space, where the rate of growth is polynomial. The ‘tree-likeness’
    of a metric space can be quantified by Gromov’s hyperbolicity (Bridson and Haefliger,
    [2013](#bib.bib13)), which is zero for tree graphs, finite (but non-zero) for
    hyperbolic space, and infinite for Euclidean space.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 双曲几何最初由高斯、罗巴切夫斯基、博利亚伊等人在19世纪发展起来，作为非欧几里得几何的具体例子。它很快在物理学中找到了重要的应用，作为爱因斯坦狭义相对论的数学基础。它可以被描述为*常数负曲率*的几何，区别于欧几里得空间的平坦几何和球体及超球体的正曲率几何。从表示学习的角度来看，它的吸引力特性在于其指数扩展和层级、树状结构。指数扩展意味着双曲空间中一个球的体积随着直径的增加而指数增长，与欧几里得空间中的多项式增长速率形成对比。度量空间的‘树状特性’可以通过Gromov的双曲性（Bridson
    和 Haefliger，[2013](#bib.bib13)）来量化，对于树图而言为零，对于双曲空间为有限（但非零），对于欧几里得空间为无限。
- en: 2.2 Models of hyperbolic geometry
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 双曲几何模型
- en: Several different, but eventually equivalent, models of hyperbolic geometry
    exist (Cannon et al, [1997](#bib.bib14)). They differ in their coordinate representations
    of points and in their expressions for distances, geodesics, and other quantities.
    Although they can be converted into each other, certain models may be preferred
    for a given task, for reasons of numerical efficiency, ease of visualization,
    or simplified calculations. The most commonly used models are the Poincaré model,
    the hyperboloid (or ‘Lorentz’) model, the Klein model, and the upper half-space
    model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 存在几种不同但最终等价的双曲几何模型（Cannon 等，[1997](#bib.bib14)）。它们在点的坐标表示和距离、测地线及其他量的表达上有所不同。尽管它们可以互相转换，但由于数值效率、可视化的便利性或简化计算的原因，某些模型可能在特定任务中更为优选。最常用的模型有庞加莱模型、超曲面（或‘洛伦兹’）模型、克莱因模型和上半空间模型。
- en: $\bullet$
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: The Poincaré model represents $d$-dimensional hyperbolic space by the unit ball
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 庞加莱模型通过单位球表示 $d$ 维双曲空间
- en: '|  | $\mathbb{D}_{d}=\{p\in\mathbb{R}^{d}:p_{1}^{2}+\dotsm+p_{d}^{2}<1\}$ |  |'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\mathbb{D}_{d}=\{p\in\mathbb{R}^{d}:p_{1}^{2}+\dotsm+p_{d}^{2}<1\}$ |  |'
- en: 'which, in the frequently considered case $d=2$ becomes the unit disc. Geodesics
    (‘shortest paths’) are arcs of Euclidean circles (or lines), meeting the boundary
    of $\mathbb{D}_{d}$ at a right angle. While distances, area and volume are distorted
    in comparison to their Euclidean counterparts, the model is *conformal*, i.e.,
    hyperbolic angles are measured as in Euclidean geometry. In its two-dimensional
    form as Poincaré disc, the model is popular for visualizations; it is also the
    geometric basis of the art works Circle Limits I-IV of M. C. Escher; see Figure [1](#S2.F1
    "Figure 1 ‣ item ∙ ‣ 2.2 Models of hyperbolic geometry ‣ 2 Background on hyperbolic
    geometry ‣ Hyperbolic Deep Learning in Computer Vision: A Survey").'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '在常考虑的情况 $d=2$ 下变为单位圆盘。测地线（‘最短路径’）是欧几里得圆（或直线）的弧，与 $\mathbb{D}_{d}$ 的边界垂直相交。虽然与欧几里得对应物相比，距离、面积和体积都发生了扭曲，但该模型是
    *保角* 的，即双曲角度与欧几里得几何中的角度测量方式相同。作为庞加莱圆盘的二维形式，该模型在可视化方面很受欢迎；它也是 M. C. Escher 的艺术作品
    Circle Limits I-IV 的几何基础；见图 [1](#S2.F1 "Figure 1 ‣ item ∙ ‣ 2.2 Models of hyperbolic
    geometry ‣ 2 Background on hyperbolic geometry ‣ Hyperbolic Deep Learning in Computer
    Vision: A Survey")。'
- en: '![Refer to caption](img/7e73eb56312655d95652e8b1a1c9db38.png)'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![参见说明](img/7e73eb56312655d95652e8b1a1c9db38.png)'
- en: 'Figure 1: Circle Limit I (1958). This artwork by M. C. Escher is based on the
    Poincaré disc model of hyperbolic geometry.'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1：Circle Limit I（1958）。M. C. Escher 创作的这幅艺术作品基于庞加莱圆盘模型的双曲几何。
- en: $\bullet$
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: The hyperboloid model uses the single-sheet hyperboloid
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 超曲面模型使用单片超曲面
- en: '|  | $\mathbb{H}_{d}=\{x\in\mathbb{R}^{d+1}:x_{0}^{2}-\left(x_{1}^{2}+\dotsm+x_{d}^{2}\right)=1,x_{0}>0\}$
    |  |'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\mathbb{H}_{d}=\{x\in\mathbb{R}^{d+1}:x_{0}^{2}-\left(x_{1}^{2}+\dotsm+x_{d}^{2}\right)=1,x_{0}>0\}$
    |  |'
- en: as a model of $d$-dimensional hyperbolic geometry. Contrary to the other models,
    its ambient space $\mathbb{R}^{d+1}$ adds one dimension to the modeled space.
    Many formulas involving the hyperboloid model can be written in concise form by
    introducing the *Lorentz product* $x\circ y=x_{0}y_{0}-(x_{1}y_{1}+\dotsm+x_{d}y_{d})$.
    An advantage of the hyperboloid model is that it retains some linear structure;
    translations and other isometries, for example, can be represented by linear maps.
    Expressions for distances and geodesics are simpler compared to other models.
    Notably, the Poincaré model can be derived as a projection (‘stereographic projection’)
    of the hyperboloid model to the unit ball (Cannon et al, [1997](#bib.bib14); Ratcliffe,
    [1994](#bib.bib99)).
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作为 $d$ 维双曲几何的模型。与其他模型相反，它的环境空间 $\mathbb{R}^{d+1}$ 为建模空间增加了一维。通过引入 *洛伦兹积* $x\circ
    y=x_{0}y_{0}-(x_{1}y_{1}+\dotsm+x_{d}y_{d})$，许多涉及超曲面模型的公式可以用简洁的形式表示。超曲面模型的一个优点是它保留了一些线性结构；例如，平移和其他等距变换可以通过线性映射表示。与其他模型相比，距离和测地线的表达更简单。值得注意的是，庞加莱模型可以作为超曲面模型到单位球的投影（‘立体投影’）导出（Cannon
    等，[1997](#bib.bib14)；Ratcliffe，[1994](#bib.bib99)）。
- en: $\bullet$
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: The Klein model $\mathbb{K}_{d}$ also uses the unit ball to represent hyperbolic
    space. In contrast to the Poincaré model, it is not conformal; its geodesics,
    however, are Euclidean (‘straight’) lines, which can be beneficial from a computational
    point of view, *e.g.,* when computing barycenters.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 克莱因模型 $\mathbb{K}_{d}$ 也使用单位球来表示双曲空间。与庞加莱模型不同，它不是保角的；然而，它的测地线是欧几里得的（‘直线’），这从计算的角度来看可能是有利的，*例如*，在计算重心时。
- en: $\bullet$
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Lastly, the upper half space model represents $d$-dimensional hyperbolic space
    by the set $\mathbb{U}_{d}=\{x\in\mathbb{R}^{d}:x_{d}>0\}$. It is a conformal
    model and shares many properties with the Poincaré model; geodesics, for example,
    are also arcs of Euclidean circles (or lines), meeting the boundary of $\mathbb{U}_{d}$
    at a right angle.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，上半空间模型通过集合 $\mathbb{U}_{d}=\{x\in\mathbb{R}^{d}:x_{d}>0\}$ 来表示 $d$ 维双曲空间。它是一个保角模型，并且与庞加莱模型共享许多性质；例如，测地线也是欧几里得圆（或直线）的弧，且与
    $\mathbb{U}_{d}$ 的边界成直角相交。
- en: 2.3 Five core hyperbolic operations
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 五个核心双曲操作
- en: 'Within the context of deep learning and computer vision, we find that five
    core operations form the basic building blocks of the vast majority of algorithms.
    The ability to work with these five operations will cover most of existing literature:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习和计算机视觉的背景下，我们发现五个核心操作构成了绝大多数算法的基本构建块。掌握这五种操作将覆盖大多数现有文献：
- en: '1.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Measuring the distance of two points $x$ and $y$;
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测量两点 $x$ 和 $y$ 之间的距离；
- en: '2.'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Finding the geodesic arc (the distance-minimizing curve) from $x$ to $y$;
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从 $x$ 到 $y$ 寻找测地线弧（最短距离曲线）；
- en: '3.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Forming a geodesic, by extending a geodesic arc as far as possible;
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 形成一个测地线，通过尽可能扩展测地线弧；
- en: '4.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Using the exponential map, to determine the result of following a geodesic in
    direction $u$, at speed $r$, starting at a point $x$;
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用指数映射，确定在点 $x$ 开始，沿方向 $u$ 以速度 $r$ 追踪测地线的结果；
- en: '5.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: Moving a cloud of points, while preserving all their pairwise hyperbolic distances,
    by applying a hyperbolic translation.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过应用双曲平移，移动一组点云，同时保持它们所有成对的双曲距离不变。
- en: The distance of two points is given, in the Poincaré and the hyperboloid model
    respectively, by
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在庞加莱模型和双曲面模型中，两点之间的距离分别由以下公式给出
- en: '|  | $\displaystyle d_{\mathbb{D}}(p,q)$ | $\displaystyle=\frac{1}{\sqrt{\kappa}}\operatorname*{arcosh}\left(1+\frac{2&#124;p-q&#124;^{2}}{(1-&#124;p&#124;^{2})(1-&#124;q&#124;^{2})}\right),$
    |  | (1) |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle d_{\mathbb{D}}(p,q)$ | $\displaystyle=\frac{1}{\sqrt{\kappa}}\operatorname*{arcosh}\left(1+\frac{2\vert
    p-q\vert^{2}}{(1-\vert p\vert^{2})(1-\vert q\vert^{2})}\right),$ |  | (1) |'
- en: '|  | $\displaystyle d_{\mathbb{H}}(x,y)$ | $\displaystyle=\frac{1}{\sqrt{\kappa}}\operatorname*{arcosh}\left(x\circ
    y\right).$ |  | (2) |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle d_{\mathbb{H}}(x,y)$ | $\displaystyle=\frac{1}{\sqrt{\kappa}}\operatorname*{arcosh}\left(x\circ
    y\right).$ |  | (2) |'
- en: In the less frequently used Klein and the upper half space model, distances
    are given by
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在不太常用的克莱因模型和上半空间模型中，距离的计算方法如下
- en: '|  | $\displaystyle d_{\mathbb{K}}(p,q)$ | $\displaystyle=\frac{1}{\sqrt{\kappa}}\operatorname*{arcosh}\left(\frac{1-p^{\top}q}{\sqrt{1-&#124;p&#124;^{2}}\sqrt{1-&#124;q&#124;^{2}}}\right),$
    |  | (3) |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle d_{\mathbb{K}}(p,q)$ | $\displaystyle=\frac{1}{\sqrt{\kappa}}\operatorname*{arcosh}\left(\frac{1-p^{\top}q}{\sqrt{1-\vert
    p\vert^{2}}\sqrt{1-\vert q\vert^{2}}}\right),$ |  | (3) |'
- en: '|  | $\displaystyle d_{\mathbb{U}}(x,y)$ | $\displaystyle=\frac{1}{\sqrt{\kappa}}\operatorname*{arcosh}\left(1+\frac{&#124;x-y&#124;^{2}}{2x_{d}y_{d}}\right),$
    |  | (4) |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle d_{\mathbb{U}}(x,y)$ | $\displaystyle=\frac{1}{\sqrt{\kappa}}\operatorname*{arcosh}\left(1+\frac{\vert
    x-y\vert^{2}}{2x_{d}y_{d}}\right),$ |  | (4) |'
- en: see (Ratcliffe, [1994](#bib.bib99), §6.1). The scaling factor of distances is
    controlled by the *curvature parameter* $\kappa\in(0,\infty)$, which is often
    standardized to $\kappa=1$. The sectional curvature (in the sense of differential
    geometry) of hyperbolic space is constant, negative and equal to $-\kappa$. Given
    the distance function, it makes sense to speak of geodesics and geodesic arcs,
    that is (locally) distance-minimizing curves, either extending infinitely or connecting
    two points. In the hyperboloid model for example, each geodesic is the intersection
    of $\mathbb{H}_{d}$ with a Euclidean hyperplane in the ambient space $\mathbb{R}^{d+1}$.
    The geodesic at a point $x\in\mathbb{H}_{d}$ in direction $v$ can be written as
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 参见（Ratcliffe，[1994](#bib.bib99)，§6.1）。距离的缩放因子由*曲率参数* $\kappa\in(0,\infty)$ 控制，通常标准化为
    $\kappa=1$。双曲空间的断面曲率（在微分几何的意义上）是常数，负值且等于 $-\kappa$。给定距离函数，谈论测地线和测地线弧，即（局部）最短距离曲线是有意义的，这些曲线可以是无限延伸的或连接两点的。在双曲面模型中，每条测地线是
    $\mathbb{H}_{d}$ 与环境空间 $\mathbb{R}^{d+1}$ 中的欧几里得超平面的交集。点 $x\in\mathbb{H}_{d}$
    处沿方向 $v$ 的测地线可以写成
- en: '|  | $\lambda_{\mathbb{H}}(t)=\cosh(t\sqrt{\kappa})x+\sinh(t\sqrt{\kappa})u,\quad
    t\in\mathbb{R}.$ |  | (5) |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '|  | $\lambda_{\mathbb{H}}(t)=\cosh(t\sqrt{\kappa})x+\sinh(t\sqrt{\kappa})u,\quad
    t\in\mathbb{R}.$ |  | (5) |'
- en: 'where $u$ is an element of the *tangent space* $T_{x}=\{u\in\mathbb{R}^{d+1}:x\circ
    u=0\}$, normalized to $u\circ u=-1$. In the Poincaré model, the geodesics are
    precisely the segments of Euclidean circles and lines that meet the boundary of
    $\mathbb{D}_{d}$ at a right angle. A convenient formula for the geodesic arc between
    two points $p,q\in\mathbb{D}_{d}$ can be given in terms of gyrovectorspace calculus,
    see ([8](#S2.E8 "In 2.4 Gyrovectorspace calculus ‣ 2 Background on hyperbolic
    geometry ‣ Hyperbolic Deep Learning in Computer Vision: A Survey")).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $u$ 是 *切空间* $T_{x}=\{u\in\mathbb{R}^{d+1}:x\circ u=0\}$ 的一个元素，归一化为 $u\circ
    u=-1$。在庞加莱模型中，测地线恰好是与 $\mathbb{D}_{d}$ 边界垂直相交的欧几里得圆和直线的线段。两点 $p,q\in\mathbb{D}_{d}$
    之间的测地弧的方便公式可以用gyrovectorspace微积分给出，见([8](#S2.E8 "2.4 Gyrovectorspace 微积分 ‣ 2 背景知识
    ‣ 计算机视觉中的双曲深度学习：综述"))。
- en: 'The value of the exponential map $\exp_{x}(tu)$ is the result of following
    a geodesic in a normalized direction $u$ at a speed $t>0$, after starting at a
    given point $x$ in hyperbolic space. Identifying $\mathbb{R}^{d}$ with the tangent
    space $T_{x}$ at $x$, the exponential mapping provides a convenient way to embed
    $\mathbb{R}^{d}$ into hyperbolic space with origin at $x$. The exponential map
    is the most often used function in hyperbolic learning for computer vision, as
    it allows us to map visual representations from Euclidean to hyperbolic space.
    In the hyperboloid model, the exponential mapping coincides with the expression
    of the geodesic given in ([5](#S2.E5 "In 2.3 Five core hyperbolic operations ‣
    2 Background on hyperbolic geometry ‣ Hyperbolic Deep Learning in Computer Vision:
    A Survey")). In the Poincaré model the exponential map can be conveniently written
    in terms of gyrovectorspace addition and is given in ([9](#S2.E9 "In 2.4 Gyrovectorspace
    calculus ‣ 2 Background on hyperbolic geometry ‣ Hyperbolic Deep Learning in Computer
    Vision: A Survey")).'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 指数映射 $\exp_{x}(tu)$ 的值是沿着归一化方向 $u$ 以速度 $t>0$ 追随测地线的结果，从给定点 $x$ 开始，在双曲空间中。将 $\mathbb{R}^{d}$
    与 $x$ 处的切空间 $T_{x}$ 进行同一化，指数映射提供了一种方便的方式将 $\mathbb{R}^{d}$ 嵌入到以 $x$ 为原点的双曲空间中。指数映射是计算机视觉中双曲学习中最常用的函数，因为它允许我们将视觉表示从欧几里得空间映射到双曲空间。在双曲面模型中，指数映射与在([5](#S2.E5
    "2.3 五个核心双曲操作 ‣ 2 背景知识 ‣ 计算机视觉中的双曲深度学习：综述"))中给出的测地线表达式一致。在庞加莱模型中，指数映射可以方便地用gyrovectorspace加法表示，见([9](#S2.E9
    "2.4 Gyrovectorspace 微积分 ‣ 2 背景知识 ‣ 计算机视觉中的双曲深度学习：综述"))。
- en: Finally, the hyperbolic translation $\tau_{x}$, also called Lorentz boost, Möbius
    transformation, or gyrovectorspace addition, is the unique distance-preserving
    transformation of hyperbolic space, which moves $0$ to a given point $x$. In the
    hyperboloid model, it can be represented by the linear map
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，双曲线变换 $\tau_{x}$，也称为洛伦兹提升、莫比乌斯变换或gyrovectorspace加法，是双曲空间中唯一的距离保持变换，它将 $0$
    移动到给定点 $x$。在双曲面模型中，它可以由线性映射表示
- en: '|  | $\displaystyle\tau_{x}(y)$ | $\displaystyle=L_{x}\cdot y,\quad\text{where}$
    |  | (6) |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\tau_{x}(y)$ | $\displaystyle=L_{x}\cdot y,\quad\text{其中}$
    |  | (6) |'
- en: '|  | $\displaystyle L_{x}$ | $\displaystyle=\begin{pmatrix}x_{0}&amp;\bar{x}^{\top}\\
    \bar{x}&amp;\sqrt{I_{d}+\bar{x}\bar{x}^{\top}}\end{pmatrix}\text{ with }\bar{x}=(x_{0},\dotsc,x_{d}).$
    |  | (7) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle L_{x}$ | $\displaystyle=\begin{pmatrix}x_{0}&amp;\bar{x}^{\top}\\
    \bar{x}&amp;\sqrt{I_{d}+\bar{x}\bar{x}^{\top}}\end{pmatrix}\text{，其中 }\bar{x}=(x_{0},\dotsc,x_{d}).$
    |  | (7) |'
- en: In the Poincaré model hyperbolic translations are also known as gyrovectorspace
    addition and form the basic operation of gyrovectorspace calculus.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在庞加莱模型中，双曲线变换也被称为gyrovectorspace加法，并构成了gyrovectorspace微积分的基本操作。
- en: 2.4 Gyrovectorspace calculus
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 Gyrovectorspace 微积分
- en: Gyrovectorspace calculus, as introduced by Ungar ([2005](#bib.bib113), [2012](#bib.bib115)),
    provides a convenient and rapidly adopted framework for calculations in the Poincaré
    ball model. Its first basic operation is the (non-commutative) gyrovectorspace
    addition
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Gyrovectorspace 微积分，由Ungar ([2005](#bib.bib113), [2012](#bib.bib115)) 提出，提供了一种方便且被迅速采用的框架用于庞加莱球模型中的计算。其第一个基本操作是（非交换的）gyrovectorspace加法
- en: '|  | $p\oplus q=\frac{(1-&#124;p&#124;^{2})q+(1+2p^{\top}q+&#124;q&#124;^{2})p}{1+2p^{\top}q+&#124;p&#124;^{2}&#124;q&#124;^{2}}.$
    |  |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  | $p\oplus q=\frac{(1-&#124;p&#124;^{2})q+(1+2p^{\top}q+&#124;q&#124;^{2})p}{1+2p^{\top}q+&#124;p&#124;^{2}&#124;q&#124;^{2}}.$
    |  |'
- en: As a secondary operation, the (commutative) gyrovectorspace scalar product
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 作为次要操作，（交换的）gyrovectorspace标量积
- en: '|  | $t\otimes p=p\otimes t=\tanh\big{(}t\operatorname*{artanh}(&#124;p&#124;)\big{)}\frac{p}{&#124;p&#124;}$
    |  |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '|  | $t\otimes p=p\otimes t=\tanh\big{(}t\operatorname*{artanh}(&#124;p&#124;)\big{)}\frac{p}{&#124;p&#124;}$
    |  |'
- en: with a scalar $t\in\mathbb{R}$ is introduced. Hyperbolic translations are directly
    given by $\tau_{p}(q)=p\oplus q$ and the geodesic arc connecting $p$ and $q$ is
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 引入了一个标量$t\in\mathbb{R}$。双曲平移由$\tau_{p}(q)=p\oplus q$直接给出，连接$p$和$q$的测地弧是
- en: '|  | $\lambda_{\mathbb{D}}(t)=p\oplus\Big{(}\big{(}(-p)\oplus q\big{)}\otimes
    t\Big{)},\quad t\in[0,1].$ |  | (8) |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '|  | $\lambda_{\mathbb{D}}(t)=p\oplus\Big{(}\big{(}(-p)\oplus q\big{)}\otimes
    t\Big{)},\quad t\in[0,1].$ |  | (8) |'
- en: Letting $t$ range through all of $\mathbb{R}$ a full geodesic line is obtained.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让$t$在整个$\mathbb{R}$中变化，可以得到一条完整的测地线。
- en: In the context of gyrovector space calculus, the Poincaré ball is often rescaled
    with the square root of curvature, setting
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在陀螺矢量空间微积分的背景下，庞加莱球通常会用曲率的平方根进行缩放，设置为
- en: '|  | $\mathbb{D}^{d}_{\kappa}=\{p\in\mathbb{R}^{d}:p_{1}^{2}+\dotsm+p_{d}^{2}<1/\kappa\}.$
    |  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{D}^{d}_{\kappa}=\{p\in\mathbb{R}^{d}:p_{1}^{2}+\dotsm+p_{d}^{2}<1/\kappa\}.$
    |  |'
- en: The advantage of this rescaling is that Euclidean space is obtained as a continuous
    limit as $\kappa\to 0$. In the rescaled model, gyrovectorspace addition and scalar
    product become
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这种缩放的优势在于，随着$\kappa\to 0$，欧几里得空间作为一个连续极限被得到。在缩放模型中，陀螺矢量空间加法和标量积变为
- en: '|  | $p\oplus_{\kappa}q=\tfrac{1}{\sqrt{\kappa}}\left((\sqrt{\kappa}p)\oplus(\sqrt{\kappa}q)\right)$
    |  |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  | $p\oplus_{\kappa}q=\tfrac{1}{\sqrt{\kappa}}\left((\sqrt{\kappa}p)\oplus(\sqrt{\kappa}q)\right)$
    |  |'
- en: and
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '|  | $t\otimes_{\kappa}p=\tfrac{1}{\sqrt{\kappa}}(t\otimes(\sqrt{\kappa}p))$
    |  |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '|  | $t\otimes_{\kappa}p=\tfrac{1}{\sqrt{\kappa}}(t\otimes(\sqrt{\kappa}p))$
    |  |'
- en: for $p,q\in\mathbb{D}^{d}_{\kappa}$. The exponential map in direction of a tangent
    vector $v\in T_{p}$ can then be written as
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于$p,q\in\mathbb{D}^{d}_{\kappa}$。在切向量$v\in T_{p}$的方向上的指数映射可以写成
- en: '|  | $\exp_{x}^{\kappa}(v)=x\oplus_{\kappa}\left(\tanh\left(\frac{\sqrt{\kappa}&#124;v&#124;}{1-\kappa&#124;x&#124;^{2}}\right)\frac{v}{\sqrt{\kappa}&#124;v&#124;}\right)$
    |  | (9) |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|  | $\exp_{x}^{\kappa}(v)=x\oplus_{\kappa}\left(\tanh\left(\frac{\sqrt{\kappa}\lvert
    v \rvert}{1-\kappa \lvert x \rvert^{2}}\right)\frac{v}{\sqrt{\kappa}\lvert v \rvert}\right)$
    |  | (9) |'
- en: for $p\in\mathbb{D}^{d}_{\kappa}$, see Ganea et al ([2018b](#bib.bib41)).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于$p\in\mathbb{D}^{d}_{\kappa}$，见 Ganea et al ([2018b](#bib.bib41))。
- en: 2.5 Non-visual hyperbolic learning
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5 非视觉双曲学习
- en: The traction of hyperbolic learning in computer vision is built upon advances
    in embedding hierarchical structures, designing hyperbolic network layers, and
    hyperbolic learning on other data types such as graphs, text, and more. Below,
    we discuss these works and their relevance for hyperbolic visual learning literature.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 双曲学习在计算机视觉中的吸引力建立在嵌入层次结构、设计双曲网络层以及在其他数据类型（如图、文本等）上进行双曲学习的进展之上。下面，我们讨论这些工作及其对双曲视觉学习文献的相关性。
- en: Hyperbolic embedding of hierarchies.
  id: totrans-90
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 双曲层次结构的嵌入。
- en: 'Embedding hierarchical structures like trees and taxonomies in Euclidean space
    suffers from large distortion (Bachmann et al, [2020](#bib.bib6)), and polynomial
    volume expansion, limiting its capacity to capture the exponential complexity
    of hierarchies. However, hyperbolic space can be thought of as a continuous version
    of trees (Nickel and Kiela, [2017](#bib.bib93)) and has tree-like properties (Hamann,
    [2018](#bib.bib56); Ungar, [2008](#bib.bib114)), like the exponential growth of
    distances when moving from the origin towards the boundary. Encouraged by this, Nickel
    and Kiela ([2017](#bib.bib93)) propose to embed hierarchical structures on the
    Poincaré model. The goal is to learn hyperbolic representations for the nodes
    of a hierarchy, such that the distance in the embedding space has an inverse relation
    with semantic similarity. Let $\mathcal{D}=\{(u,v)\}$ denote the set of the nodes
    connected in a given hierarchy. To embed the nodes in the Poincaré model,  Nickel
    and Kiela ([2017](#bib.bib93)) minimize the following loss function:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 将像树和分类学这样的层次结构嵌入欧几里得空间会受到严重的失真（Bachmann et al, [2020](#bib.bib6)），以及多项式体积扩展，这限制了它捕捉层次结构的指数复杂性的能力。然而，双曲空间可以被视为树的连续版本（Nickel
    and Kiela, [2017](#bib.bib93)），并具有树状属性（Hamann, [2018](#bib.bib56); Ungar, [2008](#bib.bib114)），例如，从原点向边界移动时距离的指数增长。受到这一点的鼓舞，Nickel
    和 Kiela（[2017](#bib.bib93)）提出将层次结构嵌入到庞加莱模型中。其目标是学习层次结构节点的双曲表示，使嵌入空间中的距离与语义相似度成反比。设$\mathcal{D}=\{(u,v)\}$表示在给定层次结构中连接的节点集合。为了在庞加莱模型中嵌入节点，Nickel
    和 Kiela（[2017](#bib.bib93)）最小化以下损失函数：
- en: '|  | $\mathcal{L}(\Theta)=\sum_{(u,v)\in\mathcal{D}}\log\frac{e^{-d(u,v)}}{\sum_{v^{{}^{\prime}}\in\mathcal{N}(u)}e^{-d(u,v^{{}^{\prime}})}},$
    |  | (10) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}(\Theta)=\sum_{(u,v)\in\mathcal{D}}\log\frac{e^{-d(u,v)}}{\sum_{v^{{}^{\prime}}\in\mathcal{N}(u)}e^{-d(u,v^{{}^{\prime}})}},$
    |  | (10) |'
- en: 'where $\mathcal{N}(u)=\{v^{{}^{\prime}}|(u,v^{{}^{\prime}})\notin\mathcal{D}\}\cup\{v\}$
    denotes the set of the nodes not related to $u$, including $v$, as negative examples.
    The loss function pushes unrelated nodes farther apart than the related ones.
    To evaluate the embedded hierarchy, the distances between pairs of connected nodes
    $(u,v)$ are calculated and ranked among the negative pairs of nodes (*i.e.,* the
    nodes not in $\mathcal{D}$), and the mean average precision (MAP) is calculated
    based on the ranking. Later, Sala et al ([2018](#bib.bib102)) propose a combinatorial
    construction to embed the trees in hyperbolic space without optimization and with
    low distortion, relieving the optimization problems in existing works.  Ganea
    et al ([2018a](#bib.bib40)) address drawbacks of (Nickel and Kiela, [2017](#bib.bib93))
    including the collapse of the points on the boundary of the space as a result
    of the loss function and incapability of encoding asymmetric relations. They introduce
    entailment cones to embed hierarchies, using a max-margin loss function:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{N}(u)=\{v^{{}^{\prime}}|(u,v^{{}^{\prime}})\notin\mathcal{D}\}\cup\{v\}$
    表示与 $u$ 无关的节点集合，包括 $v$，作为负样本。损失函数使无关的节点彼此远离，而相关节点更靠近。为了评估嵌入的层次结构，计算并排序连接节点对 $(u,v)$
    之间的距离，并在负样本节点对中（*即，* 不在 $\mathcal{D}$ 的节点）计算平均准确率（MAP）。随后，Sala 等人 ([2018](#bib.bib102))
    提出了一个组合构造方法，在没有优化且失真较低的情况下将树嵌入到双曲空间中，从而缓解了现有工作中的优化问题。Ganea 等人 ([2018a](#bib.bib40))
    解决了 (Nickel 和 Kiela, [2017](#bib.bib93)) 的不足，包括损失函数导致空间边界点的坍缩和编码非对称关系的能力不足。他们引入了蕴含锥来嵌入层次结构，使用最大边际损失函数：
- en: '|  | $\mathcal{L}=\sum_{(u,v)\in\mathcal{P}}E(u,v)+\sum_{(u^{{}^{\prime}},v^{{}^{\prime}})\in\mathcal{N}}\max(0,\gamma-E(u^{{}^{\prime}},v^{{}^{\prime}})),$
    |  | (11) |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}=\sum_{(u,v)\in\mathcal{P}}E(u,v)+\sum_{(u^{{}^{\prime}},v^{{}^{\prime}})\in\mathcal{N}}\max(0,\gamma-E(u^{{}^{\prime}},v^{{}^{\prime}})),$
    |  | (11) |'
- en: where $\gamma$, $\mathcal{P}$, and $\mathcal{N}$ indicate margin, the positive
    and negative edges, respectively. $E(u,v)$ is a penalty term that forces child
    nodes to fall under the cone of the parent node. Amongst others, hyperbolic embeddings
    have been proposed for multi-relational graphs (Balazevic et al, [2019](#bib.bib9)),
    low-dimensional knowledge graphs (Chami et al, [2020b](#bib.bib18)), and learning
    continuous hierarchies in Lorentz model (Nickel and Kiela, [2018](#bib.bib94)).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\gamma$、$\mathcal{P}$ 和 $\mathcal{N}$ 分别表示边际、正边和负边。$E(u,v)$ 是一个惩罚项，迫使子节点落在父节点的锥体下。除了其他应用外，双曲嵌入已被提出用于多关系图（Balazevic
    等人，[2019](#bib.bib9)）、低维知识图（Chami 等人，[2020b](#bib.bib18)）以及在洛伦兹模型中学习连续层次结构（Nickel
    和 Kiela，[2018](#bib.bib94)）。
- en: Hyperbolic neural networks.
  id: totrans-96
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 双曲神经网络。
- en: Foundational in the transition of deep learning towards hyperbolic space is
    the development of hyperbolic network layers and their optimization. We consider
    two pivotal papers here that provide a such theoretical foundation, namely Hyperbolic
    Neural Networks by Ganea et al ([2018b](#bib.bib41)) and Hyperbolic Neural Networks++
    by Shimizu et al ([2021](#bib.bib105)).  Ganea et al ([2018b](#bib.bib41)) propose
    multinomial logistic regression in the Poincaré ball. Given $k\in\{1,...,K\}$
    classes, $p_{k}\in\mathbb{D}^{n}_{c}$, and $a_{k}\in\mathbb{D}^{n}_{c}\setminus\{0\}$,
    hyperbolic logistic regression is performed using
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习向双曲空间过渡的基础中，双曲网络层及其优化的发展是关键。我们在这里考虑了两个提供这种理论基础的重要论文，即 Ganea 等人 ([2018b](#bib.bib41))
    的《双曲神经网络》和 Shimizu 等人 ([2021](#bib.bib105)) 的《双曲神经网络++》。Ganea 等人 ([2018b](#bib.bib41))
    提出了在庞加莱球中进行的多项逻辑回归。给定 $k\in\{1,...,K\}$ 类别，$p_{k}\in\mathbb{D}^{n}_{c}$ 和 $a_{k}\in\mathbb{D}^{n}_{c}\setminus\{0\}$，使用双曲逻辑回归进行分类。
- en: '|  | $\begin{split}p(y=k&#124;x)\propto&amp;\exp(\frac{\lambda^{c}_{pk}\lVert
    a_{k}\rVert}{\sqrt{c}}\\ &amp;\sinh^{-1}(\frac{2\sqrt{c}\langle-p_{k}\oplus_{c}x,a_{k}\rangle}{(1-c\lVert-p_{k}\oplus_{c}x\rVert^{2})\lVert
    a_{k}\rVert})).\end{split}$ |  | (12) |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}p(y=k&#124;x)\propto&amp;\exp(\frac{\lambda^{c}_{pk}\lVert
    a_{k}\rVert}{\sqrt{c}}\\ &amp;\sinh^{-1}(\frac{2\sqrt{c}\langle-p_{k}\oplus_{c}x,a_{k}\rangle}{(1-c\lVert-p_{k}\oplus_{c}x\rVert^{2})\lVert
    a_{k}\rVert})).\end{split}$ |  | (12) |'
- en: 'As an extension, a hyperbolic version of linear layer $f$ is given as $f:\mathbb{R}^{n}\rightarrow\mathbb{R}^{m}$,
    a Möbius version of $f$ where the map from $\mathbb{D}^{n}\rightarrow\mathbb{D}^{m}$
    is defined as:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 作为扩展，线性层 $f$ 的双曲版本定义为 $f:\mathbb{R}^{n}\rightarrow\mathbb{R}^{m}$，其中 $f$ 的 Möbius
    版本从 $\mathbb{D}^{n}\rightarrow\mathbb{D}^{m}$ 的映射定义为：
- en: '|  | $f^{\otimes_{c}}\coloneqq\exp^{c}_{0}(f(\log^{c}_{0}(x))),$ |  | (13)
    |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '|  | $f^{\otimes_{c}}\coloneqq\exp^{c}_{0}(f(\log^{c}_{0}(x))),$ |  | (13)
    |'
- en: with $\exp^{c}_{0}:T_{0_{m}}\mathbb{D}^{m}_{c}\rightarrow\mathbb{D}^{m}_{c}$
    and $\log^{c}_{0}:\mathbb{D}^{n}_{c}\rightarrow T_{0_{n}}\mathbb{D}^{n}_{c}$.
    They furthermore outline how to create recurrent network layers.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 $\exp^{c}_{0}:T_{0_{m}}\mathbb{D}^{m}_{c}\rightarrow\mathbb{D}^{m}_{c}$ 和
    $\log^{c}_{0}:\mathbb{D}^{n}_{c}\rightarrow T_{0_{n}}\mathbb{D}^{n}_{c}$。他们进一步概述了如何创建递归网络层。
- en: Shimizu et al ([2021](#bib.bib105)) reformulate the hyperbolic logistic regression
    of (Ganea et al, [2018b](#bib.bib41)) to reduce the number of parameters to the
    same level as the Euclidean logistic regression. The new formulation is $p(y=k|x)\propto\exp(v_{k}(x))$,
    where
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Shimizu 等人 ([2021](#bib.bib105)) 重新制定了 (Ganea 等人, [2018b](#bib.bib41)) 的双曲线逻辑回归，以将参数数量减少到与欧几里得逻辑回归相同的水平。新的公式是
    $p(y=k|x)\propto\exp(v_{k}(x))$，其中
- en: '|  | $\begin{split}v_{k}(x)=&amp;\ 2c^{-\frac{1}{2}}\lVert z_{k}\rVert\sinh^{-1}(\lambda^{c}_{x}\langle\sqrt{c}x,[z_{k}]\rangle\cosh(2\sqrt{c}r_{k})\\
    &amp;-(\lambda^{c}_{x}-1)\sinh(2\sqrt{c}r_{k}))\end{split}$ |  | (14) |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}v_{k}(x)=&amp;\ 2c^{-\frac{1}{2}}\lVert z_{k}\rVert\sinh^{-1}(\lambda^{c}_{x}\langle\sqrt{c}x,[z_{k}]\rangle\cosh(2\sqrt{c}r_{k})\\
    &amp;-(\lambda^{c}_{x}-1)\sinh(2\sqrt{c}r_{k}))\end{split}$ |  | (14) |'
- en: where $r_{k}\in\mathbb{R}$ and $z_{k}\in T_{0}\mathbb{B}^{n}_{c}=\mathbb{R}^{n}$
    are the parameters for each class. In turn, their linear layer is given as
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $r_{k}\in\mathbb{R}$ 和 $z_{k}\in T_{0}\mathbb{B}^{n}_{c}=\mathbb{R}^{n}$
    是每个类别的参数。然后，他们的线性层表示为
- en: '|  | $y=\mathcal{F}^{c}(x;Z,r)\coloneqq w(1+\sqrt{{1+c\lVert w\rVert^{2}}})^{-1}$
    |  | (15) |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '|  | $y=\mathcal{F}^{c}(x;Z,r)\coloneqq w(1+\sqrt{{1+c\lVert w\rVert^{2}}})^{-1}$
    |  | (15) |'
- en: where $Z=\{z_{k}\in T_{0}\mathbb{B}^{n}_{c}=\mathbb{R}^{n}\}^{m}_{k=1}$, $r=\{r_{k}\in\mathbb{R}\}^{m}_{k=1}$,
    and $w\coloneqq(c^{-\frac{1}{2}}\sinh(\sqrt{c}v_{k}(x)))^{m}_{k=1}$. More importantly
    for computer vision, they show how to formulate convolutional layers using Poincaré
    fully connected layer and $\beta$-concatenation. To do so, they show how to generalize
    the hyperbolic linear layer to image patches through $\beta$-splits, and $\beta$-concatenation,
    leading in principle to arbitrary-dimensional convolutional layers. Moreover,
    Poincaré multi-head attention is possible through the same operators.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $Z=\{z_{k}\in T_{0}\mathbb{B}^{n}_{c}=\mathbb{R}^{n}\}^{m}_{k=1}$, $r=\{r_{k}\in\mathbb{R}\}^{m}_{k=1}$,
    和 $w\coloneqq(c^{-\frac{1}{2}}\sinh(\sqrt{c}v_{k}(x)))^{m}_{k=1}$。对于计算机视觉更重要的是，他们展示了如何使用
    Poincaré 全连接层和 $\beta$-连接来构造卷积层。为此，他们展示了如何通过 $\beta$-分裂和 $\beta$-连接将双曲线线性层推广到图像补丁，从而原理上实现任意维度的卷积层。此外，通过相同的算子也可以实现
    Poincaré 多头注意力。
- en: '![Refer to caption](img/e296a280c07a1d5450d9c3584d572258.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/e296a280c07a1d5450d9c3584d572258.png)'
- en: 'Figure 2: The three core strategies for supervised hyperbolic learning in computer
    vision. Current literature performs hyperbolic learning of visual embeddings by
    learning to match training samples (i) to hyperbolic class hyperplanes, *i.e.,*
    gyroplanes, (ii) to hyperbolic class prototypes, or (iii) by contrasting to other
    samples.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：计算机视觉中监督式双曲线学习的三种核心策略。当前文献通过学习匹配训练样本 (i) 到双曲线类别超平面，即，陀螺面，(ii) 到双曲线类别原型，或
    (iii) 通过与其他样本对比，来实现视觉嵌入的双曲线学习。
- en: .
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: Hyperbolic learning of graphs, text, and more.
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 双曲线学习图形、文本及其他。
- en: The advances in hyperbolic embeddings of hierarchies and the introduction of
    hyperbolic network layers have spurred research in several other research directions
    as well. As a logical extension of hierarchical embeddings, graph networks have
    been extended to hyperbolic space. Liu et al ([2019](#bib.bib80)) and Chami et al
    ([2019](#bib.bib16)) propose a tangent-based view to hyperbolic graph networks.
    Both approaches model a graph layer by first mapping node embeddings to the tangent
    space, then performing the transformation and aggregation in the tangent space,
    after which the updated node embeddings are projected back to the hyperbolic manifold
    at hand. Since tangent operations only provide an approximation of the graph operations
    on the manifold, several works have proposed graph networks that better abide
    the underlying hyperbolic geometry, such as constant curvature $\kappa$-GCNs (Bachmann
    et al, [2020](#bib.bib6)), hyperbolic-to-hyperbolic GCNs (Dai et al, [2021](#bib.bib29)),
    Lorentzian GCNs (Zhang et al, [2021c](#bib.bib133)), and attention-based hyperbolic
    graph networks (Gulcehre et al, [2019](#bib.bib50); Zhang et al, [2021b](#bib.bib132)).
    Hyperbolic graph networks have shown to improve node, link, and graph classification
    compared to Euclidean variants, especially when graphs have latent hierarchical
    structures.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 双曲嵌入层级结构的进展和双曲网络层的引入也激发了其他研究方向的研究。作为层级嵌入的逻辑扩展，图网络已被扩展到双曲空间。Liu et al ([2019](#bib.bib80))
    和 Chami et al ([2019](#bib.bib16)) 提出了基于切线的双曲图网络视图。这两种方法通过先将节点嵌入映射到切线空间，再在切线空间中进行变换和聚合，最后将更新后的节点嵌入投影回双曲流形。由于切线操作仅提供了对流形上图操作的近似，一些工作提出了更好地遵循基础双曲几何的图网络，如常曲率
    $\kappa$-GCNs（Bachmann et al, [2020](#bib.bib6)），双曲到双曲 GCNs（Dai et al, [2021](#bib.bib29)），洛伦兹
    GCNs（Zhang et al, [2021c](#bib.bib133)），以及基于注意力的双曲图网络（Gulcehre et al, [2019](#bib.bib50);
    Zhang et al, [2021b](#bib.bib132)）。与欧几里得变体相比，双曲图网络在节点、链接和图分类中表现出改进，特别是在图具有潜在层级结构时。
- en: Hyperbolic embeddings have also been investigated for text. Tifrea et al ([2019](#bib.bib110)),
    Dhingra et al ([2018](#bib.bib34)), and Leimeister and Wilson ([2018](#bib.bib76))
    propose hyperbolic alternatives for word embeddings. Zhu et al ([2020](#bib.bib134))
    introduce HyperText to endow FastText with hyperbolic geometry. Embedding text
    in hyperbolic space has the potential to improve similarity, analogy, and hypernymy
    detection, most notably with few embedding dimensions.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 双曲嵌入也已被用于文本。Tifrea et al ([2019](#bib.bib110))，Dhingra et al ([2018](#bib.bib34))
    和 Leimeister 和 Wilson ([2018](#bib.bib76)) 提出了用于词嵌入的双曲替代方案。Zhu et al ([2020](#bib.bib134))
    引入了 HyperText，将双曲几何赋予 FastText。在双曲空间中嵌入文本有可能提高相似性、类比和上位词检测，尤其是在嵌入维度较少的情况下。
- en: Beyond text and graphs, hyperbolic learning has shown to be beneficial for several
    other research directions, including but not limited to learning representations
    for molecular/cellular structures (Klimovskaia et al, [2020](#bib.bib72); Yu et al,
    [2020](#bib.bib126); Wu et al, [2021](#bib.bib121)), recommender systems (Mirvakhabova
    et al, [2020](#bib.bib88); Wang et al, [2021](#bib.bib118); Yang et al, [2022](#bib.bib125)),
    skeletal action recognition (Franco et al, [2023](#bib.bib39)), LiDAR data (Tong
    et al, [2022](#bib.bib111); Wang et al, [2023](#bib.bib119)), point clouds (Montanaro
    et al, [2022](#bib.bib91); Anvekar and Bazazian, [2023](#bib.bib3)), and 3D shapes
    (Chen et al, [2020b](#bib.bib21)). In summary, hyperbolic geometry has impacted
    a wide range of research fields. This survey focuses specifically on the impact
    and potential in the visual domain.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 除了文本和图形，双曲学习还在多个其他研究方向中显示出了益处，包括但不限于分子/细胞结构的学习表示（Klimovskaia et al, [2020](#bib.bib72);
    Yu et al, [2020](#bib.bib126); Wu et al, [2021](#bib.bib121)），推荐系统（Mirvakhabova
    et al, [2020](#bib.bib88); Wang et al, [2021](#bib.bib118); Yang et al, [2022](#bib.bib125)），骨骼动作识别（Franco
    et al, [2023](#bib.bib39)），LiDAR 数据（Tong et al, [2022](#bib.bib111); Wang et al,
    [2023](#bib.bib119)），点云（Montanaro et al, [2022](#bib.bib91); Anvekar and Bazazian,
    [2023](#bib.bib3)），以及 3D 形状（Chen et al, [2020b](#bib.bib21)）。总之，双曲几何已经对广泛的研究领域产生了影响。本调查特别关注于视觉领域的影响和潜力。
- en: 3 Supervised hyperbolic visual learning
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 **监督式**双曲视觉学习
- en: 'In Figure [2](#S2.F2 "Figure 2 ‣ Hyperbolic neural networks. ‣ 2.5 Non-visual
    hyperbolic learning ‣ 2 Background on hyperbolic geometry ‣ Hyperbolic Deep Learning
    in Computer Vision: A Survey"), we provide an overview of literature on supervised
    learning with hyperbolic geometry in computer vision. In current vision works,
    hyperbolic learning is mostly performed at the embedding- or classifier-level.
    In other words, current works rely on standard networks for feature learning and
    transform the output embeddings to hyperbolic space for the final learning stage.
    For supervised learning in hyperbolic space, we have identified three main optimization
    strategies:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '在图 [2](#S2.F2 "Figure 2 ‣ Hyperbolic neural networks. ‣ 2.5 Non-visual hyperbolic
    learning ‣ 2 Background on hyperbolic geometry ‣ Hyperbolic Deep Learning in Computer
    Vision: A Survey")中，我们提供了关于计算机视觉中使用双曲几何的监督学习文献的概述。在当前的视觉工作中，双曲学习主要是在嵌入层或分类器层进行的。换句话说，目前的工作依赖于标准网络进行特征学习，并将输出嵌入转换到双曲空间进行最终学习阶段。对于双曲空间中的监督学习，我们已识别出三种主要的优化策略：'
- en: '1.'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Sample-to-gyroplane learning denotes the setting where classes are represented
    by hyperbolic hyperplanes, *i.e.,* gyroplanes, with networks optimized based on
    confidence logit scores between samples and gyroplanes.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 样本到陀螺面学习指的是将类别表示为双曲超平面，即陀螺面，并基于样本与陀螺面之间的置信度逻辑得分来优化网络的设置。
- en: '2.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Sample-to-prototype learning denotes the setting where class semantics are represented
    as points in hyperbolic space, and networks are optimized to minimize hyperbolic
    distances between samples and prototypes.
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 样本到原型的学习指的是将类别语义表示为双曲空间中的点，并通过优化网络以最小化样本与原型之间的双曲距离来实现的设置。
- en: '3.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Sample-to-sample learning denotes the setting where networks are optimized by
    learning metrics or contrastive objectives between samples in a batch.
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 样本到样本的学习指的是通过在一个批次中的样本之间学习度量或对比目标来优化网络的设置。
- en: For all strategies, let $(x,y)$ denote the visual input $x$, which can be an
    image or a video, and the corresponding label $y\in\mathcal{Y}$. Let $f_{\theta}(x)\in\mathbb{R}^{D}$
    denote its Euclidean embedding after going through a network. This representation
    is mapped to hyperbolic space using the exponential map, denoted as $g(x)=\exp_{0}(f_{\theta}(x))$.
    In many hyperbolic works, additional information about hierarchical relations
    between classes is assumed. Let $\mathcal{H}=(\mathcal{Y},\mathcal{P},\mathcal{R})$,
    with $\mathcal{Y}$ the class labels denoting the leaf nodes of the hierarchy,
    $\mathcal{P}$ the internal nodes, and $\mathcal{R}$ the set of hypernym-hyponym
    relations of the hierarchy. Below, we discuss how current literature tackles each
    strategy in detail sequentially.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有策略，设$(x,y)$为视觉输入$x$，可以是图像或视频，以及相应的标签$y\in\mathcal{Y}$。设$f_{\theta}(x)\in\mathbb{R}^{D}$为经过网络处理后的欧几里得嵌入。该表示通过指数映射映射到双曲空间，记作$g(x)=\exp_{0}(f_{\theta}(x))$。在许多双曲工作中，假定存在关于类别之间的层次关系的附加信息。设$\mathcal{H}=(\mathcal{Y},\mathcal{P},\mathcal{R})$，其中$\mathcal{Y}$为表示层次结构的叶节点的类别标签，$\mathcal{P}$为内部节点，$\mathcal{R}$为层次结构的上位词-下位词关系集合。下面，我们将依次详细讨论当前文献如何处理每种策略。
- en: 3.1 Sample-to-gyroplane learning
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 样本到陀螺面学习
- en: The most direct way to induce hyperbolic geometry in the classification space
    is by replacing the classification layer by a hyperbolic alternative. This can
    be done either by means of a hyperbolic logistic regression or through hyperbolic
    kernel machines.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类空间中引入双曲几何的最直接方法是用双曲替代品替换分类层。这可以通过双曲逻辑回归或双曲核机器来实现。
- en: Hyperbolic logistic regression.
  id: totrans-125
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 双曲逻辑回归。
- en: Khrulkov et al ([2020](#bib.bib68)) incorporate a hyperbolic classifier by taking
    a standard convolutional network and mapping the outputs of the last hidden layer
    to hyperbolic space using an exponential map. Afterwards, the hyperbolic multinomial
    logistic regression as described by Ganea et al ([2018b](#bib.bib41)) is used
    to obtain class logits which can be optimized with cross-entropy. They find that
    training a hyperbolic classifier on top of a convolutional network allows us to
    obtain uncertainty information based on the distance to the origin of the hyperbolic
    embeddings of images. Out-of-distribution samples on average have a smaller norm,
    making it possible by differentiating in- to out-of-distribution samples by sorting
    them by the distance to the origin.  Hong et al ([2022](#bib.bib60)) show that
    hyperbolic classification is beneficial for visual anomaly recognition tasks,
    such as out-of-distribution detection in image classification and segmentation
    tasks. Araño et al ([2021](#bib.bib4)) use hyperbolic layers to perform multi-modal
    sentiment analysis based on the audio, video, and text modalities. Ahmad and Lecue
    ([2022](#bib.bib1)) also show the effect of hyperbolic space to perform object
    recognition with ultra-wide field-of-view lenses.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Khrulkov等人 ([2020](#bib.bib68)) 通过将标准卷积网络的最后一个隐藏层的输出映射到双曲空间来引入双曲分类器，使用指数映射。之后，使用Ganea等人
    ([2018b](#bib.bib41)) 描述的双曲多项式逻辑回归来获得类对数值，这些对数值可以通过交叉熵进行优化。他们发现，在卷积网络顶部训练双曲分类器可以基于图像的双曲嵌入到原点的距离来获得不确定性信息。分布外样本的平均范数较小，这使得可以通过按距离原点排序来区分分布内和分布外样本。
    Hong等人 ([2022](#bib.bib60)) 证明了双曲分类在视觉异常识别任务中的好处，如图像分类和分割任务中的分布外检测。Araño等人 ([2021](#bib.bib4))
    使用双曲层来进行基于音频、视频和文本模态的多模态情感分析。Ahmad和Lecue ([2022](#bib.bib1)) 还展示了双曲空间在使用超宽视场镜头进行物体识别中的效果。
- en: 'Guo et al ([2022](#bib.bib54)) address a limitation when training classifiers
    in hyperbolic space, namely a vanishing gradient problem due to the hybrid architecture
    of current hyperbolic approaches in computer vision, where Euclidean features
    are connected to a hyperbolic classifier. Equation [12](#S2.E12 "In Hyperbolic
    neural networks. ‣ 2.5 Non-visual hyperbolic learning ‣ 2 Background on hyperbolic
    geometry ‣ Hyperbolic Deep Learning in Computer Vision: A Survey") highlights
    that to maximize the likelihood of correct predictions, the distance to hyperbolic
    gyroplanes needs to be maximized. In practice, embeddings of samples are pushed
    to the boundary of the Poincaré ball. As a result, the inverse of the Riemannian
    tensor metric approaches zero, resulting in small gradients. This finding is in
    line with several other works on vanishing gradients in hyperbolic representation
    learning (Nickel and Kiela, [2018](#bib.bib94); Liu et al, [2019](#bib.bib80)).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Guo等人 ([2022](#bib.bib54)) 解决了训练双曲空间分类器时的一个局限性，即由于当前计算机视觉中双曲方法的混合架构导致的梯度消失问题，其中欧几里得特征连接到双曲分类器。方程
    [12](#S2.E12 "在双曲神经网络中。 ‣ 2.5 非视觉双曲学习 ‣ 2 双曲几何背景 ‣ 计算机视觉中的双曲深度学习：综述") 强调了为了最大化正确预测的可能性，需要最大化到双曲陀螺面的距离。在实际操作中，样本的嵌入被推到庞加莱球的边界。因此，黎曼张量度量的逆接近于零，导致梯度很小。这个发现与一些关于双曲表示学习中的梯度消失的其他研究结果一致（Nickel和Kiela,
    [2018](#bib.bib94); Liu等人, [2019](#bib.bib80)）。
- en: 'To combat the vanishing gradient problem, Guo et al ([2022](#bib.bib54)) propose
    to clip the Euclidean embeddings of samples before the exponential mapping, *i.e.,*:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对梯度消失问题，Guo等人 ([2022](#bib.bib54)) 提出在指数映射之前剪切样本的欧几里得嵌入，*即*：
- en: '|  | $f^{\text{clipped}}_{\theta}(x)=\min\big{\{}1,\frac{r}{&#124;&#124;f_{\theta}(x)&#124;&#124;}\big{\}}\cdot
    f_{\theta}(x),$ |  | (16) |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '|  | $f^{\text{clipped}}_{\theta}(x)=\min\big{\{}1,\frac{r}{\|f_{\theta}(x)\|}\big{\}}\cdot
    f_{\theta}(x),$ |  | (16) |'
- en: with $r$ as a hyperparameter. This trick improves learning with hyperbolic multinomial
    logistic regression, especially when dealing with many classes such as on ImageNet.
    Furthermore, training with clipped hyperbolic classifiers improves out-of-distribution
    detection over training with Euclidean classifiers, while also being more robust
    to adversarial attacks.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以$r$作为超参数。这个技巧通过双曲多项式逻辑回归提高了学习效果，尤其是在处理如ImageNet这样的多类别问题时。此外，使用剪切的双曲分类器进行训练，相比于使用欧几里得分类器进行训练，能更好地检测分布外样本，同时对对抗攻击也更具鲁棒性。
- en: 'Next to global classification, a few recent works have investigated hyperbolic
    logistic regression for structured prediction tasks such as object detection and
    image segmentation. Valada ([2022](#bib.bib116)) extend object detection with
    hyperbolic geometry, amongst others by replacing the classifier head of a two-stage
    detection like Sparse R-CNN (Sun et al, [2021](#bib.bib108)) with a hyperbolic
    logistic regression, improving object detection performance in standard and zero-shot
    settings. Ghadimi Atigh et al ([2022](#bib.bib47)) introduce Hyperbolic Image
    Segmentation, where the final per-pixel classification was performed in hyperbolic
    space. Starting from the geometric interpretation of hyperbolic gyroplanes of
    Ganea et al ([2018b](#bib.bib41)), they find that simultaneously computing class
    logits over all pixels of all images in a batch, as is customary in Euclidean
    networks, is not directly applicable in hyperbolic space. This is because the
    explicit computation of the Möbius addition requires evaluating a tensor in $\mathbb{R}^{W\times
    H\times|\mathcal{Y}|\times d}$ for an images of size $(W\times H)$ with $d$ embedding
    dimensions. Instead, they rewrite the Möbius addition as:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 除了全球分类之外，最近一些研究探讨了用于结构化预测任务的超曲率逻辑回归，例如目标检测和图像分割。Valada ([2022](#bib.bib116))
    将目标检测扩展到超曲率几何中，其中包括通过将类似 Sparse R-CNN (Sun et al, [2021](#bib.bib108)) 的二阶段检测的分类头替换为超曲率逻辑回归，提升了标准和零样本设置下的目标检测性能。Ghadimi
    Atigh 等人 ([2022](#bib.bib47)) 引入了超曲率图像分割，其中最终的每像素分类是在超曲率空间中进行的。从 Ganea 等人 ([2018b](#bib.bib41))
    对超曲率陀螺面的几何解释出发，他们发现同时计算批次中所有图像的所有像素的类对数，与欧几里得网络中惯用的做法不同，在超曲率空间中并不直接适用。这是因为显式计算
    Möbius 加法需要评估一个尺寸为 $(W\times H)$，具有 $d$ 嵌入维度的图像的 $\mathbb{R}^{W\times H\times|\mathcal{Y}|\times
    d}$ 张量。相反，他们将 Möbius 加法重写为：
- en: '|  | <math   alttext="\begin{split}f_{1}\oplus_{c}f_{2}=&amp;\alpha f_{1}+\beta
    f_{2},\\ \alpha=&amp;\frac{1+2c\langle f_{1},f_{2}\rangle+c&#124;&#124;f_{2}&#124;&#124;^{2}}{1+2c\langle
    f_{1},f_{2}\rangle+c^{2}&#124;&#124;f_{1}&#124;&#124;^{2}&#124;&#124;f_{2}&#124;&#124;^{2}},\\'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}f_{1}\oplus_{c}f_{2}=&amp;\alpha f_{1}+\beta
    f_{2},\\ \alpha=&amp;\frac{1+2c\langle f_{1},f_{2}\rangle+c&#124;&#124;f_{2}&#124;&#124;^{2}}{1+2c\langle
    f_{1},f_{2}\rangle+c^{2}&#124;&#124;f_{1}&#124;&#124;^{2}&#124;&#124;f_{2}&#124;&#124;^{2}},\\'
- en: \beta=&amp;\frac{1+c&#124;&#124;f_{1}&#124;&#124;^{2}}{1+2c\langle f_{1},f_{2}\rangle+c^{2}&#124;&#124;f_{1}&#124;&#124;^{2}&#124;&#124;f_{2}&#124;&#124;^{2}}.\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"
    ><mtr ><mtd columnalign="right" ><mrow ><mrow ><msub ><mi >f</mi><mn  >1</mn></msub><msub
    ><mo  >⊕</mo><mi >c</mi></msub><msub ><mi  >f</mi><mn >2</mn></msub></mrow><mo
    >=</mo></mrow></mtd><mtd columnalign="left" ><mrow ><mrow ><mrow ><mi >α</mi><mo
    lspace="0em" rspace="0em" >​</mo><msub ><mi >f</mi><mn >1</mn></msub></mrow><mo
    >+</mo><mrow ><mi >β</mi><mo lspace="0em" rspace="0em" >​</mo><msub ><mi >f</mi><mn
    >2</mn></msub></mrow></mrow><mo >,</mo></mrow></mtd></mtr><mtr ><mtd columnalign="right"
    ><mrow ><mi >α</mi><mo >=</mo></mrow></mtd><mtd columnalign="left" ><mrow ><mfrac
    ><mrow ><mn  >1</mn><mo >+</mo><mrow ><mn >2</mn><mo lspace="0em" rspace="0em"  >​</mo><mi
    >c</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"  >⟨</mo><msub
    ><mi >f</mi><mn >1</mn></msub><mo >,</mo><msub ><mi >f</mi><mn >2</mn></msub><mo
    stretchy="false"  >⟩</mo></mrow></mrow><mo >+</mo><mrow ><mi >c</mi><mo lspace="0em"
    rspace="0em"  >​</mo><msup ><mrow ><mo stretchy="false"  >‖</mo><msub ><mi >f</mi><mn
    >2</mn></msub><mo stretchy="false"  >‖</mo></mrow><mn >2</mn></msup></mrow></mrow><mrow
    ><mn >1</mn><mo >+</mo><mrow ><mn >2</mn><mo lspace="0em" rspace="0em" >​</mo><mi
    >c</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"  >⟨</mo><msub
    ><mi >f</mi><mn >1</mn></msub><mo >,</mo><msub ><mi >f</mi><mn >2</mn></msub><mo
    stretchy="false"  >⟩</mo></mrow></mrow><mo >+</mo><mrow ><msup ><mi >c</mi><mn
    >2</mn></msup><mo lspace="0em" rspace="0em"  >​</mo><msup ><mrow ><mo stretchy="false"  >‖</mo><msub
    ><mi >f</mi><mn >1</mn></msub><mo stretchy="false"  >‖</mo></mrow><mn >2</mn></msup><mo
    lspace="0em" rspace="0em"  >​</mo><msup ><mrow ><mo stretchy="false"  >‖</mo><msub
    ><mi >f</mi><mn >2</mn></msub><mo stretchy="false"  >‖</mo></mrow><mn >2</mn></msup></mrow></mrow></mfrac><mo
    >,</mo></mrow></mtd></mtr><mtr ><mtd columnalign="right" ><mrow ><mi >β</mi><mo
    >=</mo></mrow></mtd><mtd columnalign="left" ><mrow ><mfrac ><mrow ><mn  >1</mn><mo
    >+</mo><mrow ><mi >c</mi><mo lspace="0em" rspace="0em"  >​</mo><msup ><mrow ><mo
    stretchy="false"  >‖</mo><msub ><mi >f</mi><mn >1</mn></msub><mo stretchy="false"  >‖</mo></mrow><mn
    >2</mn></msup></mrow></mrow><mrow ><mn >1</mn><mo >+</mo><mrow ><mn >2</mn><mo
    lspace="0em" rspace="0em" >​</mo><mi >c</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false"  >⟨</mo><msub ><mi >f</mi><mn >1</mn></msub><mo >,</mo><msub
    ><mi >f</mi><mn >2</mn></msub><mo stretchy="false"  >⟩</mo></mrow></mrow><mo >+</mo><mrow
    ><msup ><mi >c</mi><mn >2</mn></msup><mo lspace="0em" rspace="0em"  >​</mo><msup
    ><mrow ><mo stretchy="false"  >‖</mo><msub ><mi >f</mi><mn >1</mn></msub><mo stretchy="false"  >‖</mo></mrow><mn
    >2</mn></msup><mo lspace="0em" rspace="0em"  >​</mo><msup ><mrow ><mo stretchy="false"  >‖</mo><msub
    ><mi >f</mi><mn >2</mn></msub><mo stretchy="false"  >‖</mo></mrow><mn >2</mn></msup></mrow></mrow></mfrac><mo
    lspace="0em" >.</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content"
    ><apply ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply ><apply ><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><csymbol cd="latexml"  >direct-sum</csymbol><ci
    >𝑐</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑓</ci><cn
    type="integer" >1</cn></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑓</ci><cn type="integer" >2</cn></apply></apply><apply ><apply ><ci >𝛼</ci><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑓</ci><cn type="integer" >1</cn></apply></apply><apply
    ><ci >𝛽</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑓</ci><cn
    type="integer"  >2</cn></apply></apply></apply></apply><apply ><csymbol cd="ambiguous"
    >formulae-sequence</csymbol><apply ><ci >𝛼</ci><apply ><apply  ><cn type="integer"  >1</cn><apply
    ><cn type="integer"  >2</cn><ci >𝑐</ci><list ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><cn type="integer"  >1</cn></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><cn type="integer"  >2</cn></apply></list></apply><apply ><ci >𝑐</ci><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><apply ><csymbol cd="latexml"  >norm</csymbol><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑓</ci><cn type="integer"  >2</cn></apply></apply><cn
    type="integer"  >2</cn></apply></apply></apply><apply ><cn type="integer" >1</cn><apply
    ><cn type="integer"  >2</cn><ci >𝑐</ci><list ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><cn type="integer"  >1</cn></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><cn type="integer"  >2</cn></apply></list></apply><apply ><apply ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci >𝑐</ci><cn type="integer"  >2</cn></apply><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><apply ><csymbol cd="latexml"  >norm</csymbol><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑓</ci><cn type="integer"  >1</cn></apply></apply><cn
    type="integer"  >2</cn></apply><apply ><csymbol cd="ambiguous"  >superscript</csymbol><apply
    ><csymbol cd="latexml"  >norm</csymbol><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><cn type="integer"  >2</cn></apply></apply><cn type="integer"  >2</cn></apply></apply></apply></apply></apply><apply
    ><ci >𝛽</ci><apply ><apply  ><cn type="integer"  >1</cn><apply ><ci >𝑐</ci><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><apply ><csymbol cd="latexml"  >norm</csymbol><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑓</ci><cn type="integer"  >1</cn></apply></apply><cn
    type="integer"  >2</cn></apply></apply></apply><apply ><cn type="integer" >1</cn><apply
    ><cn type="integer"  >2</cn><ci >𝑐</ci><list ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><cn type="integer"  >1</cn></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><cn type="integer"  >2</cn></apply></list></apply><apply ><apply ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci >𝑐</ci><cn type="integer"  >2</cn></apply><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><apply ><csymbol cd="latexml"  >norm</csymbol><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑓</ci><cn type="integer"  >1</cn></apply></apply><cn
    type="integer"  >2</cn></apply><apply ><csymbol cd="ambiguous"  >superscript</csymbol><apply
    ><csymbol cd="latexml"  >norm</csymbol><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><cn type="integer"  >2</cn></apply></apply><cn type="integer"  >2</cn></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}f_{1}\oplus_{c}f_{2}=&\alpha f_{1}+\beta
    f_{2},\\ \alpha=&\frac{1+2c\langle f_{1},f_{2}\rangle+c&#124;&#124;f_{2}&#124;&#124;^{2}}{1+2c\langle
    f_{1},f_{2}\rangle+c^{2}&#124;&#124;f_{1}&#124;&#124;^{2}&#124;&#124;f_{2}&#124;&#124;^{2}},\\
    \beta=&\frac{1+c&#124;&#124;f_{1}&#124;&#124;^{2}}{1+2c\langle f_{1},f_{2}\rangle+c^{2}&#124;&#124;f_{1}&#124;&#124;^{2}&#124;&#124;f_{2}&#124;&#124;^{2}}.\end{split}</annotation></semantics></math>
    |  | (17) |
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: \beta=&amp;\frac{1+c&#124;&#124;f_{1}&#124;&#124;^{2}}{1+2c\langle f_{1},f_{2}\rangle+c^{2}&#124;&#124;f_{1}&#124;&#124;^{2}&#124;&#124;f_{2}&#124;&#124;^{2}}.\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"
    ><mtr ><mtd columnalign="right" ><mrow ><mrow ><msub ><mi >f</mi><mn  >1</mn></msub><msub
    ><mo  >⊕</mo><mi >c</mi></msub><msub ><mi  >f</mi><mn >2</mn></msub></mrow><mo
    >=</mo></mrow></mtd><mtd columnalign="left" ><mrow ><mrow ><mrow ><mi >α</mi><mo
    lspace="0em" rspace="0em" >​</mo><msub ><mi >f</mi><mn >1</mn></msub></mrow><mo
    >+</mo><mrow ><mi >β</mi><mo lspace="0em" rspace="0em" >​</mo><msub ><mi >f</mi><mn
    >2</mn></msub></mrow></mrow><mo >,</mo></mrow></mtd></mtr><mtr ><mtd columnalign="right"
    ><mrow ><mi >α</mi><mo >=</mo></mrow></mtd><mtd columnalign="left" ><mrow ><mfrac
    ><mrow ><mn  >1</mn><mo >+</mo><mrow ><mn >2</mn><mo lspace="0em" rspace="0em"  >​</mo><mi
    >c</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"  >⟨</mo><msub
    ><mi >f</mi><mn >1</mn></msub><mo >,</mo><msub ><mi >f</mi><mn >2</mn></msub><mo
    stretchy="false"  >⟩</mo></mrow></mrow><mo >+</mo><mrow ><mi >c</mi><mo lspace="0em"
    rspace="0em"  >​</mo><msup ><mrow ><mo stretchy="false"  >‖</mo><msub ><mi >f</mi><mn
    >2</mn></msub><mo stretchy="false"  >‖</mo></mrow><mn >2</mn></msup></mrow></mrow><mrow
    ><mn >1</mn><mo >+</mo><mrow ><mn >2</mn><mo lspace="0em" rspace="0em" >​</mo><mi
    >c</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"  >⟨</mo><msub
    ><mi >f</mi><mn >1</mn></msub><mo >,</mo><msub ><mi >f</mi><mn >2</mn></msub><mo
    stretchy="false"  >⟩</mo></mrow></mrow><mo >+</mo><mrow ><msup ><mi >c</mi><mn
    >2</mn></msup><mo lspace="0em" rspace="0em"  >​</mo><msup ><mrow ><mo stretchy="false"  >‖</mo><msub
    ><mi >f</mi><mn >1</mn></msub><mo stretchy="false"  >‖</mo></mrow><mn >2</mn></msup><mo
    lspace="0em" rspace="0em"  >​</mo><msup ><mrow ><mo stretchy="false"  >‖</mo><msub
    ><mi >f</mi><mn >2</mn></msub><mo stretchy="false"  >‖</mo></mrow><mn >2</mn></msup></mrow></mrow></mfrac><mo
    >,</mo></mrow></mtd></mtr><mtr ><mtd columnalign="right" ><mrow ><mi >β</mi><mo
    >=</mo></mrow></mtd><mtd columnalign="left" ><mrow ><mfrac ><mrow ><mn  >1</mn><mo
    >+</mo><mrow ><mi >c</mi><mo lspace="0em" rspace="0em"  >​</mo><msup ><mrow ><mo
    stretchy="false"  >‖</mo><msub ><mi >f</mi><mn >1</mn></msub><mo stretchy="false"  >‖</mo></mrow><mn
    >2</mn></msup></mrow></mrow><mrow ><mn >1</mn><mo >+</mo><mrow ><mn >2</mn><mo
    lspace="0em" rspace="0em" >​</mo><mi >c</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false"  >⟨</mo><msub ><mi >f</mi><mn >1</mn></msub><mo >,</mo><msub
    ><mi >f</mi><mn >2</mn></msub><mo stretchy="false"  >⟩</mo></mrow></mrow><mo >+</mo><mrow
    ><msup ><mi >c</mi><mn >2</mn></msup><mo lspace="0em" rspace="0em"  >​</mo><msup
    ><mrow ><mo stretchy="false"  >‖</mo><msub ><mi >f</mi><mn >1</mn></msub><mo stretchy="false"  >‖</mo></mrow><mn
    >2</mn></msup><mo lspace="0em" rspace="0em"  >​</mo><msup ><mrow ><mo stretchy="false"  >‖</mo><msub
    ><mi >f</mi><mn >2</mn></msub><mo stretchy="false"  >‖</mo></mrow><mn >2</mn></msup></mrow></mrow></mfrac><mo
    lspace="0em" >.</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content"
    ><apply ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply ><apply ><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><csymbol cd="latexml"  >direct-sum</csymbol><ci
    >𝑐</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑓</ci><cn
    type="integer" >1</cn></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑓</ci><cn type="integer" >2</cn></apply></apply><apply ><apply ><ci >𝛼</ci><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑓</ci><cn type="integer" >1</cn></apply></apply><apply
    ><ci >𝛽</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑓</ci><cn
    type="integer"  >2</cn></apply></apply></apply></apply><apply ><csymbol cd="ambiguous"
    >formulae-sequence</csymbol><apply ><ci >𝛼</ci><apply ><apply  ><cn type="integer"  >1</cn><apply
    ><cn type="integer"  >2</cn><ci >𝑐</ci><list ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><cn type="integer"  >1</cn></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><cn type="integer"  >2</cn></apply></list></apply><apply ><ci >𝑐</ci><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><apply ><csymbol cd="latexml"  >norm</csymbol><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑓</ci><cn type="integer"  >2</cn></apply></apply><cn
    type="integer"  >2</cn></apply></apply></apply><apply ><cn type="integer" >1</cn><apply
    ><cn type="integer"  >2</cn><ci >𝑐</ci><list ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><
- en: 'This rewrite reduces the addition to adding two tensors in $\mathbb{R}^{W\times
    H\times|\mathcal{Y}|}$, allowing for per-pixel evaluation on image batches. For
    training, Ghadimi Atigh et al ([2022](#bib.bib47)) incorporate hierarchical information
    by replacing the one-hot softmax with a hierarchical softmax:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 此重写将添加操作简化为在$\mathbb{R}^{W\times H\times|\mathcal{Y}|}$中添加两个张量，从而允许对图像批次进行逐像素评估。在训练过程中，Ghadimi
    Atigh等人 ([2022](#bib.bib47)) 通过将单热编码softmax替换为层级softmax来融入层级信息：
- en: '|  | $p(\hat{y}=y&#124;g(x)_{ij})=\prod_{h\in\mathcal{H}_{y}}\frac{\exp(\xi_{h}(g(x)_{ij}))}{\sum_{s}\in
    S_{h}\exp(\xi_{s}(g(x)_{ij}))},$ |  | (18) |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '|  | $p(\hat{y}=y&#124;g(x)_{ij})=\prod_{h\in\mathcal{H}_{y}}\frac{\exp(\xi_{h}(g(x)_{ij}))}{\sum_{s}\in
    S_{h}\exp(\xi_{s}(g(x)_{ij}))},$ |  | (18) |'
- en: 'with $\mathcal{H}_{y}=\{y\}\cap\mathcal{A}_{y}$ the set containing $y$ and
    its ancestors and $S_{h}$ the set of siblings of class $h$. Performing per-pixel
    classification with hyperbolic hierarchical logistic regression opens up multiple
    new doors for image segmentation. First, the notion of uncertainty as given by
    the hyperbolic norm of output embeddings generalizes naturally to the pixel level.
    As shown in Figure [3](#S3.F3 "Figure 3 ‣ Hyperbolic logistic regression. ‣ 3.1
    Sample-to-gyroplane learning ‣ 3 Supervised hyperbolic visual learning ‣ Hyperbolic
    Deep Learning in Computer Vision: A Survey"), the norm of pixel embeddings correlates
    with semantic ambiguity; the closer the pixel is to a semantic boundary the lower
    the pixel norm. Chen et al ([2022](#bib.bib19)) have already used this insight
    to improve image segmentation. They outline a hyperbolic uncertainty loss, where
    the cross-entropy loss of a pixel is weighted as follows for pixel $x_{ij}$:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '设$\mathcal{H}_{y}=\{y\}\cap\mathcal{A}_{y}$为包含$y$及其祖先的集合，$S_{h}$为类$h$的兄弟集合。使用双曲层级逻辑回归进行逐像素分类，为图像分割开启了多个新方向。首先，由双曲嵌入输出的双曲范数表示的不确定性概念自然地推广到像素级别。如图[3](#S3.F3
    "Figure 3 ‣ Hyperbolic logistic regression. ‣ 3.1 Sample-to-gyroplane learning
    ‣ 3 Supervised hyperbolic visual learning ‣ Hyperbolic Deep Learning in Computer
    Vision: A Survey")所示，像素嵌入的范数与语义模糊性相关；像素越接近语义边界，其像素范数越低。Chen等人 ([2022](#bib.bib19))
    已经利用这一见解来改善图像分割。他们提出了一种双曲不确定性损失，其中像素$x_{ij}$的交叉熵损失加权如下：'
- en: '|  | $\text{uw}(x_{ij})=1+\frac{1}{\log(t+\frac{d_{h}(g(x)_{ij},0)}{d_{h}(g(s),0)})},$
    |  | (19) |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '|  | $\text{uw}(x_{ij})=1+\frac{1}{\log(t+\frac{d_{h}(g(x)_{ij},0)}{d_{h}(g(s),0)})},$
    |  | (19) |'
- en: with $s$ the most confident pixel and $t$ a hyperparameter set to 1.02 in order
    to have a wide weight variation while avoiding division by zero. Adding this weight
    to the cross-entropy pixel loss consistently improves segmentation results for
    well-known segmentation networks. Other benefits of hyperbolic image segmentation
    include better zero-label generalization and higher effectiveness with few embedding
    dimensions compared to Euclidean pixel embeddings.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$s$是最自信的像素，$t$是设置为1.02的超参数，以便具有宽泛的权重变化，同时避免除零。将此权重添加到交叉熵像素损失中，一致地改善了知名分割网络的分割结果。双曲图像分割的其他好处包括更好的零标签泛化能力和在嵌入维度较少的情况下相比于欧几里得像素嵌入更高的效果。
- en: '![Refer to caption](img/761973d6fbcc87b744e7d48ff190429a.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/761973d6fbcc87b744e7d48ff190429a.png)'
- en: 'Figure 3: Hyperbolic image segmentation naturally provides us per-pixel uncertainty
    information. Pixels with low hyperbolic norm constitute pixels with high uncertainty
    and are strongly correlated with closeness to semantic boundaries. Image courtesy
    of Ghadimi Atigh et al ([2022](#bib.bib47)).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：双曲图像分割自然提供逐像素的不确定性信息。具有低双曲范数的像素构成高不确定性像素，并且与接近语义边界的关系密切。图片由Ghadimi Atigh等人
    ([2022](#bib.bib47)) 提供。
- en: '![Refer to caption](img/d640193a743fdabfb954d455c90095cf.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d640193a743fdabfb954d455c90095cf.png)'
- en: 'Figure 4: Hierarchical knowledge amongst classes provides a structure for hyperbolic
    embeddings in computer vision approaches, where classes are represented as points
    or prototypes in hyperbolic space according to their hypernym-hyponym relations.
    For example, Dhall et al ([2020](#bib.bib33)) exploit hierarchical relations from
    entomological collections (left), while Yu et al ([2022](#bib.bib127)) utilize
    taxonomies of skin lesion diseases (middle) and Long et al ([2020](#bib.bib82))
    do the same for action hierarchies (right). Images courtesy of the respective
    publications.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：类之间的层级知识为计算机视觉方法中的双曲嵌入提供了结构，其中类根据其上位词-下位词关系在双曲空间中表示为点或原型。例如，Dhall等人 ([2020](#bib.bib33))
    利用昆虫分类收藏中的层级关系（左），Yu等人 ([2022](#bib.bib127)) 使用皮肤病变的分类（中），Long等人 ([2020](#bib.bib82))
    则对动作层级（右）做了相同处理。图片由相关出版物提供。
- en: Hyperbolic kernel machines.
  id: totrans-143
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 双曲核机器。
- en: Next to logistic regression, Cho et al ([2019](#bib.bib24)) provide a general
    formulation for kernel methods in hyperbolic space with large-margin classifiers.
    Fang et al ([2021](#bib.bib38)) introduce positive definite kernel functions in
    hyperbolic space and show its potential for computer vision. Specifically, they
    propose hyperbolic instantiations of tangent kernels, radial basis function kernels,
    (generalized) Laplace kernels, and binomial kernels. The kernels can be plugged
    on top of convolutional networks and trained with cross-entropy to benefit from
    both the representation learning of the convolutional layers and the hyperbolic
    kernel dynamics in the classifier. Deep learning with hyperbolic kernel methods
    improves few-shot learning, person re-identification, and knowledge distillation.
    Zero-shot learning is even enabled through kernel distances between visual embeddings
    and semantic class representations.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 除了逻辑回归之外，Cho 等人（[2019](#bib.bib24)）提供了一个用于大边际分类器的双曲空间中核方法的一般公式。Fang 等人（[2021](#bib.bib38)）引入了双曲空间中的正定核函数，并展示了其在计算机视觉中的潜力。具体来说，他们提出了切向核、径向基函数核、（广义）拉普拉斯核和二项核的双曲实例。这些核函数可以添加到卷积网络上，并与交叉熵一起训练，以同时受益于卷积层的表示学习和分类器中的双曲核动态。使用双曲核方法的深度学习可以提高少样本学习、行人再识别和知识蒸馏。甚至可以通过视觉嵌入与语义类别表示之间的核距离实现零样本学习。
- en: 3.2 Sample-to-prototype learning
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 从样本到原型的学习
- en: 'The most popular strategy in hyperbolic learning is to represent classes as
    prototypes, *i.e.,* as points in hyperbolic space. In this research direction,
    there are two solutions: embedding classes based on their sample mean, in the
    spirit of Prototypical Networks (ProtoNet) (Snell et al, [2017](#bib.bib106)),
    or embeddings classes based on a given hierarchy over all classes.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在双曲学习中，最流行的策略是将类别表示为原型，即在双曲空间中的点。在这一研究方向中，有两种解决方案：基于样本均值嵌入类别，类似于原型网络（ProtoNet）（Snell
    等人，[2017](#bib.bib106)），或者基于所有类别的给定层级嵌入类别。
- en: Hyperbolic ProtoNet.
  id: totrans-147
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 双曲 ProtoNet。
- en: 'In Prototypical Networks (Snell et al, [2017](#bib.bib106)), the prototype
    of a class $k$ is determined as the mean vector of the samples belonging to that
    class:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在原型网络（Snell 等人，[2017](#bib.bib106)）中，类别 $k$ 的原型被确定为属于该类别的样本的均值向量：
- en: '|  | $P_{\mathbb{R}}(k)=\frac{1}{&#124;S_{k}&#124;}\sum_{y_{s}\in S_{k}}f_{\theta}(x_{s}),$
    |  | (20) |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '|  | $P_{\mathbb{R}}(k)=\frac{1}{&#124;S_{k}&#124;}\sum_{y_{s}\in S_{k}}f_{\theta}(x_{s}),$
    |  | (20) |'
- en: 'with $S_{k}$ the set of samples belonging to class $k$. Inference can in turn
    be performed by assigning the label of the nearest prototype for a test sample.
    Khrulkov et al ([2020](#bib.bib68)) generalize this formulation to Hyperbolic
    Prototypical Networks. Since computing averages in the Poincaré ball model requires
    expensive Fréchet mean calculations, they perform averaging using the Einstein
    midpoint, given in Klein coordinates as:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $S_{k}$ 是属于类别 $k$ 的样本集合。推理可以通过将测试样本的标签分配给最近的原型来进行。Khrulkov 等人（[2020](#bib.bib68)）将这一公式推广到双曲原型网络。由于在庞加莱球模型中计算均值需要昂贵的
    Fréchet 均值计算，他们使用爱因斯坦中点来执行均值计算，在 Klein 坐标下表示为：
- en: '|  | $P_{\mathbb{K}}(k)=\sum_{i=1}^{&#124;S_{k}&#124;}\gamma_{i}g_{\mathbb{K}}(x_{i})/\sum_{i=1}^{&#124;S_{k}&#124;}\gamma_{i},$
    |  | (21) |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '|  | $P_{\mathbb{K}}(k)=\sum_{i=1}^{&#124;S_{k}&#124;}\gamma_{i}g_{\mathbb{K}}(x_{i})/\sum_{i=1}^{&#124;S_{k}&#124;}\gamma_{i},$
    |  | (21) |'
- en: 'with $\gamma_{i}$ the Lorentz factors:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\gamma_{i}$ 是洛伦兹因子：
- en: '|  | $\gamma_{i}=\frac{1}{\sqrt{1-c&#124;&#124;g(x_{i})&#124;&#124;^{2}}}.$
    |  | (22) |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '|  | $\gamma_{i}=\frac{1}{\sqrt{1-c&#124;&#124;g(x_{i})&#124;&#124;^{2}}}.$
    |  | (22) |'
- en: 'Since Khrulkov et al ([2020](#bib.bib68)) operate in the Poincaré ball model,
    this averaging operation requires transforming embeddings to and from the Klein
    model:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Khrulkov 等人（[2020](#bib.bib68)）在庞加莱球模型中进行操作，这一均值计算操作需要将嵌入转化为并从 Klein 模型中转化：
- en: '|  | $\begin{split}g_{\mathbb{K}}(x_{i})=&amp;\frac{2g_{\mathbb{D}}(x_{i})}{1+c&#124;&#124;g_{\mathbb{D}}(x_{i})&#124;&#124;^{2}},\\
    g_{\mathbb{D}}(x_{i})=&amp;\frac{g_{\mathbb{K}}(x_{i})}{1+\sqrt{1-c&#124;&#124;g_{\mathbb{K}}(x_{i})&#124;&#124;^{2}}},\end{split}$
    |  | (23) |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}g_{\mathbb{K}}(x_{i})=&amp;\frac{2g_{\mathbb{D}}(x_{i})}{1+c&#124;&#124;g_{\mathbb{D}}(x_{i})&#124;&#124;^{2}},\\
    g_{\mathbb{D}}(x_{i})=&amp;\frac{g_{\mathbb{K}}(x_{i})}{1+\sqrt{1-c&#124;&#124;g_{\mathbb{K}}(x_{i})&#124;&#124;^{2}}},\end{split}$
    |  | (23) |'
- en: with $g_{\mathbb{D}}(x_{i})$ and $g_{\mathbb{K}}(x_{i})$ the embeddings of input
    $x_{i}$ in respectively the Poincaré ball model and the Klein model. Akin to its
    Euclidean counterpart, Hyperbolic ProtoNet is used to address few-shot learning,
    where the sample mean prototype serves as the class representation. Khrulkov et al
    ([2020](#bib.bib68)) show that performing prototypical few-shot learning in hyperbolic
    space is competitive to Euclidean prototypical learning, even resulting in better
    accuracy scores when relying on a 4-layer ConvNet as the backbone.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$g_{\mathbb{D}}(x_{i})$和$g_{\mathbb{K}}(x_{i})$分别是输入$x_{i}$在庞加莱球模型和克莱因模型中的嵌入。类似于其欧几里得对应物，双曲ProtoNet用于处理少样本学习，其中样本均值原型作为类别表示。Khrulkov等人（[2020](#bib.bib68)）展示了在双曲空间中进行原型少样本学习与欧几里得原型学习具有竞争力，甚至在依赖4层ConvNet作为骨干网时获得了更好的准确度分数。
- en: As a follow-up work, Gao et al ([2021](#bib.bib42)) show that different tasks
    and even individual classes in few-shot learning favor different curvatures. They
    propose to generate a per-class curvature based on the second-order statistics
    of its in-class and out-of-class sample representations. Using the second-order
    statistics, a multi-layer perceptron with sigmoid activation is learned to fix
    the range of the curvature to $[0,1]$. Given class-specific curvatures, prototypes
    are obtained by constructing an intra-class distance matrix on top of which an
    MLP is trained. The MLP serves as weights for each in-class sample. The procedure
    is repeated for the closest samples in the out-of-class set, after which the per-class
    prototype is given as the weighted hyperbolic average over the in-class and closest
    out-of-class samples. The curvature generation and weighted hyperbolic averaging
    improve few-shot learning in both inductive and transductive settings.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 作为后续工作，高等人（[2021](#bib.bib42)）展示了不同任务甚至单个类别在少样本学习中偏好不同的曲率。他们提出基于类别内和类别外样本表示的二阶统计量生成每类曲率。利用二阶统计量，通过学习具有sigmoid激活的多层感知机来将曲率范围固定在$[0,1]$。给定类别特定的曲率，通过在类别内距离矩阵上训练一个MLP来获得原型。MLP作为每个类别内样本的权重。该过程对类别外集合中的最接近样本重复进行，之后按类别加权双曲平均得到每类原型。曲率生成和加权双曲平均在归纳和传导设置中都改善了少样本学习。
- en: The hyperbolic clipping of Guo et al ([2022](#bib.bib54)) is also effective
    for few-shot learning, consistently outperforming the standard ProtoNet and Hyperbolic
    ProtoNet on the CUB Birds and miniImageNet few-shot benchmarks. A few other works
    have extended Hyperbolic ProtoNet for few-shot learning with set- and grouplet-based
    learning and will be discussed in the sample-to-sample learning section.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Guo等人（[2022](#bib.bib54)）的双曲剪裁方法在少样本学习中也有效，一致优于标准ProtoNet和Hyperbolic ProtoNet在CUB
    Birds和miniImageNet少样本基准测试中的表现。一些其他工作扩展了Hyperbolic ProtoNet用于少样本学习，采用了集合和组别学习方法，将在样本到样本学习部分讨论。
- en: Recently, Gao et al ([2022](#bib.bib43)) investigate feature augmentation in
    hyperbolic space to solve the overfitting problem when dealing with limited data.
    On top, they introduce a scheme to estimate the feature distribution using neural-ODE.
    These elements are then plugged into few-shot approaches such as the hyperbolic
    prototypical networks of Khrulkov et al ([2020](#bib.bib68)), improving performance.
     Choudhary and Reddy ([2022](#bib.bib27)) improve hyperbolic few-shot learning
    by reformulating hyperbolic neural networks through Taylor series expansions of
    hyperbolic trigonometric functions and show that it improves the scalability and
    compatibility, and outperforms Hyperbolic ProtoNet.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，高等人（[2022](#bib.bib43)）研究了在双曲空间中进行特征增强，以解决处理有限数据时的过拟合问题。除此之外，他们还引入了一种使用神经ODE估计特征分布的方案。这些元素随后被应用到少样本方法中，如Khrulkov等人（[2020](#bib.bib68)）的双曲原型网络，从而提高了性能。Choudhary和Reddy（[2022](#bib.bib27)）通过对双曲神经网络进行双曲三角函数的泰勒级数展开，改进了双曲少样本学习，展示了其在可扩展性和兼容性上的优势，并且优于Hyperbolic
    ProtoNet。
- en: Hierarchical embedding of prototypes.
  id: totrans-160
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 原型的层次嵌入。
- en: 'Where Hyperbolic ProtoNets are effective in few-shot settings, a number of
    works have also investigated prototype-based solutions for the general classification.
    As starting point, these works commonly assume that the classes in a dataset are
    organized in a hierarchy, see Figure [4](#S3.F4 "Figure 4 ‣ Hyperbolic logistic
    regression. ‣ 3.1 Sample-to-gyroplane learning ‣ 3 Supervised hyperbolic visual
    learning ‣ Hyperbolic Deep Learning in Computer Vision: A Survey"). Long et al
    ([2020](#bib.bib82)) embed action class hierarchy $\mathcal{H}$ in hyperbolic
    space using hyperbolic entailment cones (Ganea et al, [2018a](#bib.bib40)), with
    an additional loss to increase the angular separation between leaf nodes to avoid
    inter-label confusion amongst class labels $\mathcal{Y}$. With $\mathcal{L}_{H}(\mathcal{H})$
    as the hyperbolic embedding loss for hierarchy $\mathcal{H}$, let $\mathcal{P}$
    denote the leave nodes of the hierarchy. Then the separation-based loss is given
    over the leaf nodes as:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在少量样本设置中，双曲原型网络（Hyperbolic ProtoNets）表现出色，许多研究也探讨了基于原型的通用分类解决方案。作为起点，这些研究通常假设数据集中的类别是按层次结构组织的，参见图[4](#S3.F4
    "图 4 ‣ 双曲逻辑回归 ‣ 3.1 样本到陀螺平面学习 ‣ 3 监督式双曲视觉学习 ‣ 双曲深度学习在计算机视觉中的应用调查")。Long 等人 ([2020](#bib.bib82))
    使用双曲蕴涵锥（Ganea 等， [2018a](#bib.bib40)）将动作类别层次结构 $\mathcal{H}$ 嵌入到双曲空间中，并加入额外的损失函数，以增加叶节点之间的角度分离，避免类别标签
    $\mathcal{Y}$ 之间的混淆。设 $\mathcal{L}_{H}(\mathcal{H})$ 为层次结构 $\mathcal{H}$ 的双曲嵌入损失，令
    $\mathcal{P}$ 表示层次结构的叶节点。则基于分离的损失在叶节点上给出为：
- en: '|  | $\mathcal{L}_{S}(\mathcal{P})=\mathbf{1}^{T}(\hat{P}\hat{P}^{T}-I)\mathbf{1},$
    |  | (24) |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}_{S}(\mathcal{P})=\mathbf{1}^{T}(\hat{P}\hat{P}^{T}-I)\mathbf{1},$
    |  | (24) |'
- en: with $\hat{P}$ the $\ell_{2}$-normalized representations of the leaf nodes.
    By combining the hierarchical and separation based losses, the hierarchy is embedded
    to balance both hierarchical constraints and discriminative abilities. The embedding
    is learned *a priori*, after which video embeddings are projected to the same
    hyperbolic space and optimized to their correct class embedding. This approach
    improves action recognition, zero-shot action classification, and hierarchical
    action search. In a similar spirit, Dhall et al ([2020](#bib.bib33)) show that
    using hyperbolic entailment cones for image classification is empirically better
    than using Euclidean entailment cones. Rather than separating hierarchical and
    visual embedding learning, Yu et al ([2022](#bib.bib127)) propose to simultaneously
    learn hierarchical and visual representations for skin lesion recognition in images.
    Image embeddings are optimized towards their correct class prototype, while the
    classes are optimized to abide by their hyperbolic entailment cones with an extra
    distortion loss to obtain better hierarchical embeddings. Gulshad et al ([2023](#bib.bib52))
    propose Hierarchical Prototype Explainer, a reasoning model in hyperbolic space
    to provide explainability in video action recognition. Their approach learns hierarchical
    prototypes at different levels of granularity *e.g.,* parent and grandparent levels,
    to explain the recognized action in the video. By learning the hierarchical prototypes,
    they can provide explanations on different levels of granularity, including interpretation
    of the prediction of a specific class label and providing information on the spatiotemporal
    parts that contribute to the final prediction.  Li et al ([2023](#bib.bib78))
    investigate the semantic space of action recognition datasets and bridge the gap
    between different labeling systems. To achieve a unified action learning, actions
    are connected into a hierarchy using VerbNet (Schuler, [2005](#bib.bib104)) and
    embedded as prototypes in hyperbolic space.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 以$\hat{P}$为叶节点的$\ell_{2}$-标准化表示。通过结合基于层次和分离的损失，层次结构被嵌入以平衡层次约束和判别能力。该嵌入是*事先*学习的，然后视频嵌入被投影到相同的双曲空间，并优化到其正确的类别嵌入。这种方法改善了动作识别、零样本动作分类和层次动作搜索。本着类似的精神，Dhall等人（[2020](#bib.bib33)）展示了使用双曲推断锥进行图像分类在经验上优于使用欧几里得推断锥。Yu等人（[2022](#bib.bib127)）提出同时学习层次和视觉表示用于皮肤病变图像识别，而不是将层次和视觉嵌入学习分开。图像嵌入被优化到其正确的类别原型，而类别则被优化以遵守其双曲推断锥，并加入额外的畸变损失以获得更好的层次嵌入。Gulshad等人（[2023](#bib.bib52)）提出了层次原型解释器，一个在双曲空间中的推理模型，用于提供视频动作识别的可解释性。他们的方法在不同的粒度级别*例如*父级和祖父级别上学习层次原型，以解释视频中识别的动作。通过学习层次原型，他们可以在不同的粒度级别提供解释，包括对特定类别标签预测的解释和提供关于贡献最终预测的时空部分的信息。Li等人（[2023](#bib.bib78)）研究了动作识别数据集的语义空间，并弥合了不同标注系统之间的差距。为了实现统一的动作学习，使用VerbNet（Schuler，[2005](#bib.bib104)）将动作连接成层次结构，并嵌入为双曲空间中的原型。
- en: Hierarchical prototype embeddings have also been successfully employed in the
    zero-shot domain. Liu et al ([2020](#bib.bib81)) show how to perform zero-shot
    learning with hyperbolic embeddings. Classes are embedded by taking their WordNet-based
    Poincaré Embeddings (Nickel and Kiela, [2017](#bib.bib93)) and text-based Poincaré
    GloVe embeddings (Tifrea et al, [2019](#bib.bib110)). Both are concatenated to
    obtain class prototypes. By optimizing seen training images to their prototypes,
    it becomes possible to generalize to unseen classes during testing through a nearest
    neighbor search in the concatenated hyperbolic space. Xu et al ([2022](#bib.bib122))
    also perform hyperbolic zero-shot learning by training hyperbolic graph layers
    (Chami et al, [2019](#bib.bib16)) on top of hyperbolic word embeddings. Dengxiong
    and Kong ([2023](#bib.bib31)) show the potential of hyperbolic space in generalized
    open set recognition, which classifies unknown samples based on side information.
    A side information (taxonomy) learning framework is introduced to embed the information
    in hyperbolic space with low distortion and identify the unknown samples. Moreover,
    an ancestor search algorithm is outlined to find the most similar ancestor in
    the taxonomy of the known classes.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 层次原型嵌入也成功应用于零样本领域。Liu等人（[2020](#bib.bib81)）展示了如何使用双曲嵌入进行零样本学习。通过采用基于WordNet的Poincaré嵌入（Nickel和Kiela，[2017](#bib.bib93)）和基于文本的Poincaré
    GloVe嵌入（Tifrea等人，[2019](#bib.bib110)）对类别进行嵌入。这两者被连接以获得类别原型。通过优化已见训练图像到其原型，可以在测试期间通过在连接的双曲空间中进行最近邻搜索来推广到未见类别。Xu等人（[2022](#bib.bib122)）也通过在双曲词嵌入上训练双曲图层（Chami等人，[2019](#bib.bib16)）来执行双曲零样本学习。Dengxiong和Kong（[2023](#bib.bib31)）展示了双曲空间在广义开放集识别中的潜力，该方法基于附加信息对未知样本进行分类。引入了一种附加信息（分类）学习框架，将信息嵌入到双曲空间中，具有低失真度，并识别未知样本。此外，还概述了一种祖先搜索算法，用于在已知类别的分类中找到最相似的祖先。
- en: 'For standard classification, Ghadimi Atigh et al ([2021](#bib.bib46)) show
    how to integrate uniformity amongst prototypes in hyperbolic space by embedding
    classes with maximum separation on the boundary of the Poincaré ball given by
    (Mettes et al, [2019](#bib.bib87); Kasarla et al, [2022](#bib.bib65)). With prototypes
    now at the boundary of the ball, standard distance functions no longer apply since
    they are at the infinite distance to any point within the ball. To that end, they
    propose to use the Busemann distance, which is given for hyperbolic image embedding
    $g(x)$ and prototype $p$ as:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于标准分类，Ghadimi Atigh等人（[2021](#bib.bib46)）展示了如何通过在Poincaré球体边界上嵌入具有最大分离度的类别来整合双曲空间中的原型均匀性（由Mettes等人，[2019](#bib.bib87)；Kasarla等人，[2022](#bib.bib65)）。由于原型现在位于球体边界上，标准距离函数不再适用，因为它们与球体内的任何点之间的距离是无限的。为此，他们建议使用Busemann距离，给定双曲图像嵌入$g(x)$和原型$p$的Busemann距离为：
- en: '|  | $b_{p}(g(x))=\log(\frac{&#124;&#124;p-g(x)&#124;&#124;^{2}}{1-&#124;&#124;g(x)&#124;&#124;^{2}}).$
    |  | (25) |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '|  | $b_{p}(g(x))=\log(\frac{&#124;&#124;p-g(x)&#124;&#124;^{2}}{1-&#124;&#124;g(x)&#124;&#124;^{2}}).$
    |  | (25) |'
- en: By fixing prototypes with maximum separation *a priori* and minimizing this
    distance function with an extra regularization towards the origin, it becomes
    possible to perform hyperbolic prototypical learning with prototypes at the ideal
    boundary. Ghadimi Atigh et al ([2021](#bib.bib46)) show that such an approach
    has direct links with conventional logistic regression in the binary case, highlighting
    its inherent properties. Moreover, maximally separated prototypes can also be
    replaced by prototypes from word embeddings or hierarchical knowledge, depending
    on the available knowledge and task at hand. In addition to standard classification,
    hierarchical hyperbolic embeddings have demonstrated effectiveness in continual
    learning (Gao et al, [2023](#bib.bib44)). To learn the new data, Gao et al ([2023](#bib.bib44))
    propose a dynamically expanding geometry through a mixed-curvature space, enabling
    learning of complex hierarchies in a data stream. To prevent forgetting, angle-regularization
    and neighbor-robustness losses are used to preserve the geometry of the old data.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 通过固定最大分离的原型*事先*，并通过额外的正则化最小化该距离函数，可以在理想边界处执行双曲原型学习。Ghadimi Atigh 等人 ([2021](#bib.bib46))
    表明这种方法在二分类情况下与传统的逻辑回归有直接联系，突出了其固有属性。此外，根据可用知识和手头的任务，最大分离的原型还可以由词嵌入或层次知识中的原型替代。除了标准分类，层次双曲嵌入在持续学习中也表现出有效性
    (Gao 等人, [2023](#bib.bib44))。为了学习新数据，Gao 等人 ([2023](#bib.bib44)) 提出了通过混合曲率空间动态扩展几何体的方法，使得在数据流中能够学习复杂的层次结构。为了防止遗忘，使用了角度正则化和邻域鲁棒性损失来保持旧数据的几何结构。
- en: Few-shot learning has also been investigated with hierarchical knowledge. Zhang
    et al ([2022](#bib.bib129)) perform such few-shot learning by first training a
    network on a joint classification and hierarchical consistency objective. The
    classification is given as a softmax over the class probabilities, as well as
    the softmax over the superclasses. In the few-shot inference stage, class prototypes
    are obtained through hyperbolic graph propagation to deal with the limited sample
    setting, improving few-shot learning as a result.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本学习也已通过层次知识进行研究。张等人 ([2022](#bib.bib129)) 首先通过在联合分类和层次一致性目标上训练网络来进行这种少样本学习。分类结果作为类别概率的
    softmax 以及超类别的 softmax 进行给出。在少样本推理阶段，通过双曲图传播获得类别原型，以应对有限样本设置，从而提高了少样本学习的效果。
- en: '![Refer to caption](img/e4b8c7cd41ea5372c79ed977400e6e79.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e4b8c7cd41ea5372c79ed977400e6e79.png)'
- en: 'Figure 5: Embeddings of hyperbolic vision transformers cluster samples based
    on their label towards the boundary of the Poincaré ball, while simultaneously
    exhibiting latent hierarchical relations. Image courtesy of Ermolov et al ([2022](#bib.bib37)).'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：双曲视觉变换器的嵌入根据样本标签将样本聚类到 Poincaré 球体的边界附近，同时展现潜在的层次关系。图片由 Ermolov 等人 ([2022](#bib.bib37))
    提供。
- en: 3.3 Sample-to-sample learning
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 样本到样本的学习
- en: Lastly, a number of recent works have investigated hyperbolic learning by contrasting
    between samples.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一些最近的研究通过对比样本来研究双曲学习。
- en: Hyperbolic metric learning.
  id: totrans-173
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 双曲度量学习。
- en: 'Ermolov et al ([2022](#bib.bib37)) investigate the potential of hyperbolic
    embedding for metric learning. In metric learning, the de facto solution is to
    match representations of sample pairs based on embeddings given by a pre-trained
    encoder. Rather than relying on Euclidean distances and contrastive learning for
    optimization, they propose a hyperbolic pairwise cross-entropy loss. Given a dataset
    with $|\mathcal{Y}|$ classes, each batch samples two samples from each category,
    *i.e.,* $K=2\cdot|\mathcal{Y}|$. Then the loss function for a positive pair with
    the same class label is given as:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Ermolov 等人 ([2022](#bib.bib37)) 研究了双曲嵌入在度量学习中的潜力。在度量学习中，实际解决方案是基于预训练编码器给出的嵌入匹配样本对的表示。他们提出了一种双曲对交叉熵损失，而不是依赖欧几里得距离和对比学习进行优化。给定一个包含
    $|\mathcal{Y}|$ 类的数据集，每个批次从每个类别中抽取两个样本，即 $K=2\cdot|\mathcal{Y}|$。然后，同类标签的正样本对的损失函数给出为：
- en: '|  | $\ell_{ij}=-\log\frac{\exp(-D(g(x_{i}),g(x_{j}))/\tau)}{\sum_{k=1}^{K}\exp(-D(g(x_{i}),g(x_{k}))/\tau)},$
    |  | (26) |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '|  | $\ell_{ij}=-\log\frac{\exp(-D(g(x_{i}),g(x_{j}))/\tau)}{\sum_{k=1}^{K}\exp(-D(g(x_{i}),g(x_{k}))/\tau)},$
    |  | (26) |'
- en: 'where $D(\cdot,\cdot)$ can be either a hyperbolic or a cosine distance and
    $\tau$ denotes a temperature hyperparameter. This loss is computed over all positive
    pairs $(i,j)$ and $(j,i)$ in a batch. Using supervised (Dosovitskiy et al, [2021](#bib.bib36))
    and self-supervised (Caron et al, [2021](#bib.bib15)) vision transformers as encoders,
    hyperbolic metric learning consistently outperforms Euclidean alternatives and
    sets state-of-the-art on fine-grained datasets. Figure [5](#S3.F5 "Figure 5 ‣
    Hierarchical embedding of prototypes. ‣ 3.2 Sample-to-prototype learning ‣ 3 Supervised
    hyperbolic visual learning ‣ Hyperbolic Deep Learning in Computer Vision: A Survey")
    shows a 2D projection of the embeddings learned with hyperbolic metric learning
    on vision transformers, where classes are grouped towards the boundary and latent
    hierarchical neighborhood relations emerge.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $D(\cdot,\cdot)$ 可以是超曲面距离或余弦距离，而 $\tau$ 表示一个温度超参数。这个损失是在一个批次中所有正样本对 $(i,j)$
    和 $(j,i)$ 上计算的。使用监督 (Dosovitskiy et al, [2021](#bib.bib36)) 和自监督 (Caron et al,
    [2021](#bib.bib15)) 视觉变换器作为编码器，超曲面度量学习始终优于欧几里得替代方法，并在细粒度数据集上设立了最先进的水平。图 [5](#S3.F5
    "Figure 5 ‣ Hierarchical embedding of prototypes. ‣ 3.2 Sample-to-prototype learning
    ‣ 3 Supervised hyperbolic visual learning ‣ Hyperbolic Deep Learning in Computer
    Vision: A Survey") 显示了使用超曲面度量学习在视觉变换器上学习的嵌入的 2D 投影，其中类别被分组到边界附近，潜在的层次邻域关系显现出来。'
- en: Hyperbolic metric learning has shown to be effective to overcome overfitting
    and catastrophic forgetting in few-shot class-incremental learning tasks, explored
    by  Cui et al ([2022](#bib.bib28)). This is done by adding a metric learning loss
    as a part of the distillation in continual learning. They also propose a hyperbolic
    version of Reciprocal Point Learning (Chen et al, [2020a](#bib.bib20)) to provide
    extra-class space for known categories in the few-shot learning stage. Yan et al
    ([2023](#bib.bib124)) also explore hyperbolic metric learning, incorporating noise-insensitive
    and adaptive hierarchical similarity to handle noisy labels and multi-level relations.
    Kim et al ([2022](#bib.bib70)) add a hierarchical regularization term on top of
    the metric learning approaches, with the goal of learning hierarchical ancestors
    in hyperbolic space without any annotation. Hyperbolic metric learning is furthermore
    effective in semantic hashing (Amin et al, [2022](#bib.bib2)), face recognition
    via large-margin nearest-neighbor learning (Trpin and Boshkoska, [2022](#bib.bib112)),
    and multi-modal alignment given videos and knowledge graph (Guo et al, [2021](#bib.bib53)).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 超曲面度量学习在少样本类增量学习任务中有效克服了过拟合和灾难性遗忘，这一点由 Cui 等人 ([2022](#bib.bib28)) 探索了。这是通过将度量学习损失作为持续学习中的一个蒸馏部分来实现的。他们还提出了一个超曲面版本的互惠点学习
    (Chen et al, [2020a](#bib.bib20))，以在少样本学习阶段为已知类别提供额外的类间空间。Yan 等人 ([2023](#bib.bib124))
    还探索了超曲面度量学习，结合了噪声不敏感和自适应层次相似性，以处理噪声标签和多层次关系。Kim 等人 ([2022](#bib.bib70)) 在度量学习方法上添加了层次正则化项，旨在无任何注释的情况下学习超曲面空间中的层次祖先。超曲面度量学习在语义哈希
    (Amin et al, [2022](#bib.bib2))、通过大间距最近邻学习的人脸识别 (Trpin 和 Boshkoska, [2022](#bib.bib112))
    以及给定视频和知识图谱的多模态对齐 (Guo et al, [2021](#bib.bib53)) 中也表现出色。
- en: Following the progress of large language models and the success of vision-language
    models (*e.g.,* CLIP (Radford et al, [2021](#bib.bib98))) in multimodal representation
    learning, Desai et al ([2023](#bib.bib32)) propose a hyperbolic image-text representation.
    The proposed method first processes the input image and text using two separate
    encoders. Then, the generated embedding is projected into the hyperbolic space,
    and training is performed using a contrastive and entailment loss. The paper shows
    that the proposed approach outperforms the Euclidean CLIP as it is capable of
    capturing hierarchical multimodal relations in hyperbolic space.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 跟随大型语言模型的发展以及视觉-语言模型（*例如*，CLIP (Radford et al, [2021](#bib.bib98))) 在多模态表示学习中的成功，Desai
    等人 ([2023](#bib.bib32)) 提出了一个超曲面图像-文本表示方法。该方法首先使用两个独立的编码器处理输入的图像和文本。然后，将生成的嵌入投影到超曲面空间中，并使用对比损失和蕴含损失进行训练。论文表明，该方法在超曲面空间中能够捕捉层次化的多模态关系，表现优于欧几里得
    CLIP。
- en: Hyperbolic set-based learning.
  id: totrans-179
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 超曲面集合学习。
- en: Where sample-to-prototype and sample-to-sample approaches compare samples to
    individual elements, some works have shown that set-based and group-based distances
    are more effective and robust. Ma et al ([2022](#bib.bib84)) introduce an adaptive
    sample-to-set distance function in the context of few-shot learning. Rather than
    aggregating support samples to a single prototype, an adaptive sample-to-set approach
    is proposed to increase the robustness to the outliers. The sample-to-set function
    is a weighted average of the distance from the query to all support samples, where
    the distance is calculated with a small network over the feature maps of the query
    and support samples. This approach benefits few-shot learning, especially when
    dealing with outliers.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 与样本到原型和样本到样本的方法对比样本的单个元素相比，一些研究表明基于集合和基于组的距离更为有效和稳健。Ma 等（[2022](#bib.bib84)）在小样本学习的背景下引入了一种自适应样本到集合距离函数。与将支持样本聚合到单个原型不同，自适应样本到集合的方法旨在提高对异常值的鲁棒性。样本到集合函数是查询到所有支持样本的距离的加权平均，其中距离通过一个小型网络在查询和支持样本的特征图上计算。这种方法对小样本学习有利，尤其是在处理异常值时。
- en: In the context of metric learning, Zhang et al ([2021a](#bib.bib131)) argue
    that sample-to-sample learning is computationally expensive, while sample-to-prototype
    learning is less accurate. They propose a hybrid strategy based on grouplets.
    Each grouplet is a random subset of samples and the set of grouplets is matched
    with prototypes through a differentiable optimal transport. Akin to Ermolov et al
    ([2022](#bib.bib37)), they show that using hyperbolic embedding spaces improved
    metric learning on fine-grained datasets. Moreover, they provide empirical evidence
    that other metric-based losses benefit from hyperbolic embeddings, highlighting
    the general utility of hyperbolic space for metric learning.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在度量学习的背景下，Zhang 等（[2021a](#bib.bib131)）认为样本到样本的学习计算成本高，而样本到原型的学习则准确性较低。他们提出了一种基于组的小策略，每个组是样本的随机子集，组的集合通过可微分的最优传输与原型匹配。类似于
    Ermolov 等（[2022](#bib.bib37)），他们展示了使用双曲嵌入空间可以改善对精细数据集的度量学习。此外，他们提供了实证证据表明，其他基于度量的损失也受益于双曲嵌入，突显了双曲空间在度量学习中的普遍实用性。
- en: '![Refer to caption](img/0280a39b6a7b361173303daf245bda95.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/0280a39b6a7b361173303daf245bda95.png)'
- en: 'Figure 6: The three major methods for unsupervised hyperbolic learning in computer
    vision. Current literature performs unsupervised learning in hyperbolic space
    using (i) generative models, (ii) clustering, (iii) self-supervised learning.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：计算机视觉中无监督双曲学习的三种主要方法。目前的文献使用 (i) 生成模型、(ii) 聚类、(iii) 自监督学习 在双曲空间中进行无监督学习。
- en: .
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: 4 Unsupervised hyperbolic visual learning
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 无监督双曲视觉学习
- en: 'Hyperbolic learning has been actively researched in the unsupervised domain
    of computer vision. We identify three dominant research directions in which hyperbolic
    deep learning has found success: generative learning, clustering, and self-supervised
    learning. Below, each is discussed separately.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 双曲学习在计算机视觉的无监督领域中已被积极研究。我们确定了双曲深度学习取得成功的三种主要研究方向：生成学习、聚类和自监督学习。以下将分别讨论每个方向。
- en: 4.1 Generative approaches
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 生成方法
- en: 4.1.1 Hyperbolic VAEs
  id: totrans-188
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 双曲VAE
- en: 'Variational autoencoders (VAEs) (Kingma and Welling, [2013](#bib.bib71); Rezende
    et al, [2014](#bib.bib100)) with hyperbolic latent space have been used to learn
    representations of images. Nagano et al ([2019](#bib.bib92)) propose the hyperbolic
    wrapped normal distribution and derive algorithms for both reparametrizable sampling
    and computing the probability density function. They then derive a hyperbolic
    $\beta$-VAE (Higgins et al, [2017](#bib.bib59)) using the wrapped normal function
    as the prior and posterior, replacing the usual (Euclidean) Gaussian distribution.
    The wrapped normal distribution in a manifold $\mathcal{M}$ is the pushforward
    measure under the exponential map $\exp_{\mathcal{M}}$. Thus, a sample $z$ can
    be obtained as (Mathieu et al, [2019](#bib.bib85)):'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 双曲潜在空间的变分自编码器 (VAE)（Kingma 和 Welling，[2013](#bib.bib71)；Rezende 等，[2014](#bib.bib100)）已被用于学习图像的表示。Nagano
    等（[2019](#bib.bib92)）提出了双曲包装正态分布，并推导了可重参数化采样和计算概率密度函数的算法。他们随后推导了一个双曲 $\beta$-VAE（Higgins
    等，[2017](#bib.bib59)），使用包装正态函数作为先验和后验，替代了通常的（欧几里得）高斯分布。流形 $\mathcal{M}$ 中的包装正态分布是通过指数映射
    $\exp_{\mathcal{M}}$ 得到的推前测度。因此，样本 $z$ 可以表示为（Mathieu 等，[2019](#bib.bib85)）：
- en: '|  | $\displaystyle z=\exp_{\mu}^{\mathcal{M}}\left(G(\mu)^{-1/2}v\right),v\sim\mathcal{N}(\cdot&#124;0,\Sigma)$
    |  | (27) |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle z=\exp_{\mu}^{\mathcal{M}}\left(G(\mu)^{-1/2}v\right),v\sim\mathcal{N}(\cdot\mid0,\Sigma)$
    |  | (27) |'
- en: where $\exp_{\mu}^{\mathcal{M}}$ is the exponential map of $\mathcal{M}$ at
    $\mu$ and $G$ is the matrix representation of the metric of $\mathcal{M}$. To
    accommodate the geometry of the latent space, exponential and logarithmic maps
    were added at the end of the VAE encoder and before the start of the VAE decoder,
    respectively. In order to train their hyperbolic VAE with the typical evidence
    lower bound, Nagano et al ([2019](#bib.bib92)) compute the density of the wrapped
    normal distribution using the change-of-variables formula. Since their sampling
    algorithm required the exponential and parallel transport maps, Nagano et al ([2019](#bib.bib92))
    compute the log-determinants and inverses of these maps in order to apply the
    change-of-variables formula. Nagano et al ([2019](#bib.bib92)) then use their
    VAE to learn representations of MNIST and Atari 2600 Breakout screens. On MNIST,
    Hyperbolic representations outperform Euclidean representations at low latent
    dimensions but were overtaken starting at dimension 10.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\exp_{\mu}^{\mathcal{M}}$ 是 $\mathcal{M}$ 在 $\mu$ 点的指数映射，$G$ 是 $\mathcal{M}$
    度量的矩阵表示。为了适应潜在空间的几何结构，指数映射和对数映射分别在 VAE 编码器的末尾和 VAE 解码器的开始之前添加。为了用典型的证据下界训练他们的超bolic
    VAE，Nagano 等人 ([2019](#bib.bib92)) 使用变换变量公式计算包裹正态分布的密度。由于他们的采样算法需要指数映射和并行传输映射，Nagano
    等人 ([2019](#bib.bib92)) 计算了这些映射的对数行列式和逆，以应用变换变量公式。Nagano 等人 ([2019](#bib.bib92))
    然后使用他们的 VAE 学习 MNIST 和 Atari 2600 Breakout 屏幕的表示。在 MNIST 上，超bolic 表示在低潜在维度下优于欧几里得表示，但从维度
    10 开始被超越。
- en: 'Mathieu et al ([2019](#bib.bib85)) extend the work of Nagano et al ([2019](#bib.bib92))
    by introducing the Riemannian normal distribution and deriving reparametrizable
    sampling schemes for both the Riemannian normal and wrapped normal using hyperbolic
    polar coordinates. The Riemannian normal views the Euclidean normal distribution
    as the distribution minimizing the entropy for a given mean and standard deviation
    and defines a new normal distribution on hyperbolic space with this property:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Mathieu 等人 ([2019](#bib.bib85)) 通过引入黎曼正态分布并推导出使用超bolic 极坐标的黎曼正态和包裹正态的重新参数化采样方案，从而扩展了
    Nagano 等人 ([2019](#bib.bib92)) 的工作。黎曼正态将欧几里得正态分布视为在给定均值和标准差的情况下最小化熵的分布，并在超bolic
    空间上定义了具有此性质的新正态分布：
- en: '|  | $\displaystyle\mathcal{N}_{\mathcal{M}}^{R}(z&#124;\mu,\sigma^{2})=\frac{1}{Z^{R}}\exp\left(-\frac{d_{\mathcal{M}}(\mu,z)^{2}}{2\sigma^{2}}\right)$
    |  | (28) |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{N}_{\mathcal{M}}^{R}(z\mid\mu,\sigma^{2})=\frac{1}{Z^{R}}\exp\left(-\frac{d_{\mathcal{M}}(\mu,z)^{2}}{2\sigma^{2}}\right)$
    |  | (28) |'
- en: where $Z^{R}$ is a normalizing constant. Mathieu et al ([2019](#bib.bib85))
    additionally introduce the use of a gyroplane layer as the first layer of the
    decoder, following Ganea et al ([2018b](#bib.bib41)). Noting that an Euclidean
    affine transform can be written as
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $Z^{R}$ 是归一化常数。Mathieu 等人 ([2019](#bib.bib85)) 进一步引入了将陀螺层作为解码器第一层的使用，继 Ganea
    等人 ([2018b](#bib.bib41)) 之后。注意到欧几里得仿射变换可以写作
- en: '|  | $f_{a,p}(z)=\text{sign}(\langle a,z-p\rangle)&#124;&#124;a&#124;&#124;d_{E}(z,H_{a,p})$
    |  |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '|  | $f_{a,p}(z)=\text{sign}(\langle a,z-p\rangle)\|\|\ a\|\|\ d_{E}(z,H_{a,p})$
    |  |'
- en: where $H_{a,p}=\{z\in\mathbb{R}^{n}|\langle a,z-p\rangle=0\}$ is the decision
    hyperplane, they replace each piece of the formula with its hyperbolic counterpart
    to obtain
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $H_{a,p}=\{z\in\mathbb{R}^{n}|\langle a,z-p\rangle=0\}$ 是决策超平面，他们用其超bolic
    对应物替换了公式中的每一部分，以得到
- en: '|  | $\displaystyle f_{a,p}^{c}(z)=\text{sign}(\langle a,\log_{p}^{c}(z)\rangle_{p})&#124;&#124;a&#124;&#124;_{p}d_{p}^{c}(z,H_{a,p}^{c})$
    |  | (29) |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f_{a,p}^{c}(z)=\text{sign}(\langle a,\log_{p}^{c}(z)\rangle_{p})\|\|\
    a\|\|\_{p}d_{p}^{c}(z,H_{a,p}^{c})$ |  | (29) |'
- en: where all $H_{a,p}^{c}=\{z\in\mathbb{H}|\langle a,\log_{p}^{c}(z)\rangle=0\}$.
    The closed-form formula for the distance term in the Poincaré ball is
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $H_{a,p}^{c}=\{z\in\mathbb{H}|\langle a,\log_{p}^{c}(z)\rangle=0\}$。Poincaré
    球面上的距离项的封闭式公式是
- en: '|  | $\displaystyle d_{p}^{c}(z,H_{a,p}^{c})=\frac{1}{\sqrt{c}}\sinh^{-1}\left(\frac{2\sqrt{c}&#124;\langle-p\oplus_{c}z,a\rangle&#124;}{(1-c&#124;&#124;-p\oplus_{c}z&#124;&#124;^{2})&#124;&#124;a&#124;&#124;}\right)$
    |  | (30) |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle d_{p}^{c}(z,H_{a,p}^{c})=\frac{1}{\sqrt{c}}\sinh^{-1}\left(\frac{2\sqrt{c}\|\langle-p\oplus_{c}z,a\rangle\|}{(1-c\|\|-p\oplus_{c}z\|\|^{2})\|\|a\|\|}\right)$
    |  | (30) |'
- en: Mathieu et al ([2019](#bib.bib85)) also use their hyperbolic VAE to learn representations
    of MNIST and find that using both the Riemannian normal and the gyroplane layer
    improve test log-likelihoods, especially at low latent dimensions.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: Mathieu 等人 ([2019](#bib.bib85)) 还使用他们的双曲 VAE 学习 MNIST 的表示，发现使用 Riemannian 正态分布和
    gyroplane 层都能提高测试对数似然，尤其是在低潜在维度下。
- en: '![Refer to caption](img/9bd7b4a97d0126c214a8aa8ed210346a.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/9bd7b4a97d0126c214a8aa8ed210346a.png)'
- en: 'Figure 7: The standard hyperbolic wrapped normal (top) and rotated hyperbolic
    wrapped normal (bottom). In (a), the principal axes of the normal distribution
    are illustrated. In (b), the principal axes of the transported normal distribution
    are visualized. The density of the two distributions are visualized in (c). Image
    courtesy of Cho et al ([2022](#bib.bib25)).'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：标准双曲线包裹正态分布（上）和旋转双曲线包裹正态分布（下）。在 (a) 中，正态分布的主轴被描绘出来。在 (b) 中，运输正态分布的主轴被可视化。在
    (c) 中，两个分布的密度被可视化。图片由 Cho 等人 ([2022](#bib.bib25)) 提供。
- en: 'Cho et al ([2022](#bib.bib25)) extend the previous two works by proposing a
    new version of the hyperbolic wrapped normal distribution (HWN). Their primary
    observation is that for the wrapped normal distribution, the principal axes of
    the distributions are not aligned with the local standard axes, see Figure [7](#S4.F7
    "Figure 7 ‣ 4.1.1 Hyperbolic VAEs ‣ 4.1 Generative approaches ‣ 4 Unsupervised
    hyperbolic visual learning ‣ Hyperbolic Deep Learning in Computer Vision: A Survey").
    They propose a new sampling process that fixes the alignment of the principal
    axes, resulting in a new distribution which they call the rotated hyperbolic wrapped
    normal (RoWN). Given a mean $\mu$ in the Lorentz model of hyperbolic geometry
    and a diagonal covariance matrix $\Sigma$, samples from the RoWN distribution
    are sampled as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 'Cho 等人 ([2022](#bib.bib25)) 通过提出一种新的双曲线包裹正态分布（HWN）版本，扩展了之前的两个工作。他们的主要观察是，对于包裹正态分布，分布的主轴与局部标准轴不对齐，见图
    [7](#S4.F7 "Figure 7 ‣ 4.1.1 Hyperbolic VAEs ‣ 4.1 Generative approaches ‣ 4 Unsupervised
    hyperbolic visual learning ‣ Hyperbolic Deep Learning in Computer Vision: A Survey")。他们提出了一种新的采样过程，修正了主轴的对齐，得到一种他们称之为旋转双曲线包裹正态分布（RoWN）的新分布。给定双曲线几何学的洛伦兹模型中的均值
    $\mu$ 和对角协方差矩阵 $\Sigma$，从 RoWN 分布中采样的步骤如下：'
- en: '1.'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Find the rotation matrix $R$ that rotates the $x$-axis $x=\left([\pm 1,\ldots,0]\right)$
    to $y=\mu_{1:}$. We can compute $R$ as
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 找到将 $x$-轴 $x=\left([\pm 1,\ldots,0]\right)$ 旋转到 $y=\mu_{1:}$ 的旋转矩阵 $R$。我们可以计算
    $R$ 为
- en: '|  | $\displaystyle R=I+(y^{T}x-x^{T}y)+\frac{(y^{T}x-x^{T}y)^{2}}{1+\langle
    x,y\rangle}$ |  | (31) |'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\displaystyle R=I+(y^{T}x-x^{T}y)+\frac{(y^{T}x-x^{T}y)^{2}}{1+\langle
    x,y\rangle}$ |  | (31) |'
- en: '2.'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Rotate $\Sigma$ by $R$: $\hat{\Sigma}=R\Sigma R^{T}$'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用 $R$ 旋转 $\Sigma$：$\hat{\Sigma}=R\Sigma R^{T}$
- en: '3.'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Now sample as in the usual hyperbolic wrapped normal: sample $v\sim\mathcal{N}(\mathbf{0},\hat{\Sigma})$
    and then map it to hyperbolic space as follows: $\exp_{\mu}(\text{PT}_{\mathbf{0}\to\mu}([0,v]))$'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在按通常的双曲线包裹正态分布进行采样：采样 $v\sim\mathcal{N}(\mathbf{0},\hat{\Sigma})$，然后将其映射到双曲空间：$\exp_{\mu}(\text{PT}_{\mathbf{0}\to\mu}([0,v]))$
- en: Cho et al ([2022](#bib.bib25)) find that RoWN outperforms HWN in a variety of
    settings, such as the Atari 2600 Breakout image generation experiment first examined
    in Nagano et al ([2019](#bib.bib92)).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Cho 等人 ([2022](#bib.bib25)) 发现 RoWN 在多种设置中优于 HWN，例如在 Nagano 等人 ([2019](#bib.bib92))
    首次研究的 Atari 2600 Breakout 图像生成实验中。
- en: 4.1.2 Hyperbolic GANs
  id: totrans-212
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2 双曲线 GANs
- en: Using the intuition that images are organized hierarchically, several works
    have proposed hyperbolic generative adversarial networks (GANs). Lazcano et al
    ([2021](#bib.bib74)) propose a hyperbolic GAN which replaces some of the Euclidean
    layers in both the generator and discriminator with hyperbolic layers (Ganea et al,
    [2018a](#bib.bib40)) with learnable curvature. Lazcano et al ([2021](#bib.bib74))
    propose hyperbolic variants of the original GAN (Goodfellow et al, [2020](#bib.bib48)),
    the Wasserstein GAN WGAN-GP (Gulrajani et al, [2017](#bib.bib51)) and conditional
    GAN CGAN (Mirza and Osindero, [2014](#bib.bib89)). The paper finds that their
    best configurations of Euclidean and hyperbolic layers generally improved the
    Inception Score (Salimans et al, [2016](#bib.bib103)) and Frechet Inception Distance
    (Heusel et al, [2017](#bib.bib58)) on MNIST image generation, with the best improvements
    in the GAN architecture. The best learned curvatures are close to zero. Unlike
    other hyperbolic generative models (VAEs and normalizing flows), good results
    are observed at large latent dimensions.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 利用图像层次组织的直觉，一些研究提出了双曲生成对抗网络（GANs）。Lazcano 等人（[2021](#bib.bib74)）提出了一种双曲GAN，该网络在生成器和判别器中用双曲层（Ganea
    等人，[2018a](#bib.bib40)）替代了一些欧几里得层，且具有可学习的曲率。Lazcano 等人（[2021](#bib.bib74)）还提出了原始GAN（Goodfellow
    等人，[2020](#bib.bib48)）、Wasserstein GAN WGAN-GP（Gulrajani 等人，[2017](#bib.bib51)）和条件GAN
    CGAN（Mirza 和 Osindero，[2014](#bib.bib89)）的双曲变体。论文发现，其最佳的欧几里得和双曲层配置通常能提高MNIST图像生成的Inception
    Score（Salimans 等人，[2016](#bib.bib103)）和Frechet Inception Distance（Heusel 等人，[2017](#bib.bib58)），GAN架构的改进效果最佳。学习到的最佳曲率接近零。与其他双曲生成模型（VAEs和标准化流）不同的是，在较大的潜在维度下观察到了良好的结果。
- en: 'Qu and Zou ([2022](#bib.bib97)) propose HAEGAN, a hyperbolic autoencoder and
    GAN framework in the Lorentz model $\mathbb{L}$ (also known as the hyperboloid
    model), of hyperbolic geometry. The GAN is based on the structure of WGAN-GP (Arjovsky
    et al, [2017](#bib.bib5); Gulrajani et al, [2017](#bib.bib51)). The structure
    of HAEGAN consists of an encoder, which takes in real data and generates real
    representations, and a generator, which takes in noise and generates fake representations.
    A critic is trained to distinguish between the two representations, and a decoder
    takes the fake representations and produces the final generated object. Qu and
    Zou ([2022](#bib.bib97)) generalize WGAN-GP to hyperbolic space using three operations:
    the first is the hyperbolic linear layer is $\texttt{HLinear}_{n,m}:\mathbb{L}_{K}^{n}\to\mathbb{L}_{K}^{m}$
    of Chen et al ([2021](#bib.bib23)) , the second the hyperbolic centroid distance
    layer $\texttt{HCDist}_{n,m}(x):\mathbb{L}_{K}^{n}\to\mathbb{R}^{m}$ of Liu et al
    ([2019](#bib.bib80)), and the third a a new Lorentz concatenation layer:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: Qu 和 Zou（[2022](#bib.bib97)）提出了HAEGAN，这是一个在Lorentz模型$\mathbb{L}$（也称为双曲面模型）中的双曲自编码器和GAN框架。该GAN基于WGAN-GP（Arjovsky
    等人，[2017](#bib.bib5); Gulrajani 等人，[2017](#bib.bib51)）的结构。HAEGAN的结构包括一个编码器，它接收真实数据并生成真实表示；一个生成器，它接收噪声并生成虚假表示；一个批评者被训练来区分这两种表示；一个解码器接收虚假表示并生成最终的生成物。Qu
    和 Zou（[2022](#bib.bib97)）通过三个操作将WGAN-GP推广到双曲空间：第一个是Chen 等人（[2021](#bib.bib23)）的双曲线性层$\texttt{HLinear}_{n,m}:\mathbb{L}_{K}^{n}\to\mathbb{L}_{K}^{m}$，第二个是Liu
    等人（[2019](#bib.bib80)）的双曲质心距离层$\texttt{HCDist}_{n,m}(x):\mathbb{L}_{K}^{n}\to\mathbb{R}^{m}$，第三个是新的Lorentz连接层：
- en: '|  | $\displaystyle\texttt{HCat}(\{x_{i}\}_{i=1}^{N})=\left[\sqrt{\sum_{i=1}^{N}x_{i_{t}}^{2}+(N-1)/K},x_{1_{s}}^{\top},\ldots,x_{1_{s}}^{\top}\right]^{\top}$
    |  | (32) |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\texttt{HCat}(\{x_{i}\}_{i=1}^{N})=\left[\sqrt{\sum_{i=1}^{N}x_{i_{t}}^{2}+(N-1)/K},x_{1_{s}}^{\top},\ldots,x_{1_{s}}^{\top}\right]^{\top}$
    |  | (32) |'
- en: Compared to previous work Shimizu et al ([2021](#bib.bib105)), the HCat layer
    has the advantage of always having bounded gradients. (Shimizu et al, [2021](#bib.bib105)).
    Compared to Lazcano et al ([2021](#bib.bib74)), HAEGAN shows improved results
    on MNIST image generation.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的研究Shimizu 等人（[2021](#bib.bib105)）相比，HCat层具有始终有界梯度的优势。（Shimizu 等人，[2021](#bib.bib105)）。与Lazcano
    等人（[2021](#bib.bib74)）相比，HAEGAN在MNIST图像生成中显示出了改进的结果。
- en: '![Refer to caption](img/eadc8b024e5f621fe30751441ae83c89.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/eadc8b024e5f621fe30751441ae83c89.png)'
- en: 'Figure 8: Hierarchical attribute editing in hyperbolic space is possible due
    to hyperbolic space’s ability to encode semantic hierarchical structure within
    image data. Changing the high-level, category-relevant details (closest to the
    origin) changes the category, while changing low-level (farthest from the origin),
    category-irrelevant attributes varies images within categories. Image courtesy
    of Li et al ([2022](#bib.bib77)).'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：由于超曲面空间能够在图像数据中编码语义层次结构，因此在超曲面空间中进行分层属性编辑成为可能。改变高层次的类别相关细节（最接近原点）会改变类别，而改变低层次的（最远离原点）类别无关的属性则会在类别内变化图像。图像由Li等人
    ([2022](#bib.bib77)) 提供。
- en: 'Li et al ([2022](#bib.bib77)) propose a hyperbolic method for few-shot image
    generation. The main idea is that hyperbolic space encodes a semantic hierarchy,
    where the root of the hierarchy (*i.e.,* at the center of hyperbolic space) is
    a category, *e.g.,* dog. At lower levels, we have more fine-grained separations,
    such as subcategories, *e.g.,* Shih-Tzu and Ridgeback dogs. Finally, at the lowest
    level, there are category-irrelevant features, *e.g.,* the hair color or pose
    of the dog (see Figure [8](#S4.F8 "Figure 8 ‣ 4.1.2 Hyperbolic GANs ‣ 4.1 Generative
    approaches ‣ 4 Unsupervised hyperbolic visual learning ‣ Hyperbolic Deep Learning
    in Computer Vision: A Survey")). This method builds on the Euclidean pSp method
    (Richardson et al, [2021](#bib.bib101)) for image-to-image translation. The pSp
    method uses a feature pyramid to extract feature maps and uses a set of projection
    heads on these feature maps to produce each of the style vectors required by StyleGAN
    (Karras et al, [2019](#bib.bib63), [2020](#bib.bib64)), which is commonly denoted
    the $\mathcal{W}^{+}$-space. Image-to-image translation can then be done by editing
    or replacing style vectors. Li et al ([2022](#bib.bib77)) generalize to hyperbolic
    space by mapping the output of a frozen, pre-trained pSp encoder to hyperbolic
    space and then back to the $\mathcal{W}^{+}$-space of style vectors, and then
    feeding the style vectors into a frozen, pre-trained StyleGAN. Projection to hyperbolic
    space is done using the Mobius layer $f^{\otimes c}$ of Ganea et al ([2018b](#bib.bib41)),
    with the full projection layer having the form'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 'Li等人 ([2022](#bib.bib77)) 提出了一个用于少样本图像生成的超曲面方法。主要思想是超曲面空间编码了一个语义层次结构，其中层次的根（*即*超曲面空间的中心）是一个类别，例如，狗。在较低层次，我们有更多的细分，如子类别，例如，狮子狗和罗威纳犬。最后，在最低层次，有类别无关的特征，例如，狗的毛色或姿势（见图
    [8](#S4.F8 "Figure 8 ‣ 4.1.2 Hyperbolic GANs ‣ 4.1 Generative approaches ‣ 4 Unsupervised
    hyperbolic visual learning ‣ Hyperbolic Deep Learning in Computer Vision: A Survey")）。该方法建立在Euclidean
    pSp方法（Richardson等人，[2021](#bib.bib101)）的图像到图像转换基础上。pSp方法使用特征金字塔提取特征图，并在这些特征图上使用一组投影头生成StyleGAN
    (Karras等人，[2019](#bib.bib63)，[2020](#bib.bib64))所需的每个样式向量，通常表示为$\mathcal{W}^{+}$空间。然后可以通过编辑或替换样式向量来完成图像到图像的转换。Li等人
    ([2022](#bib.bib77)) 通过将冻结的预训练pSp编码器的输出映射到超曲面空间，再映射回$\mathcal{W}^{+}$样式向量空间，并将样式向量输入到冻结的预训练StyleGAN中，来推广到超曲面空间。投影到超曲面空间是使用Ganea等人
    ([2018b](#bib.bib41)) 的Mobius层$f^{\otimes c}$完成的，完整的投影层具有以下形式：'
- en: '|  | $\displaystyle z_{\mathbb{D}i}=f^{\otimes c}(\exp_{0}^{c}(\texttt{MLP}_{E}(\mathbf{w}_{i})))$
    |  | (33) |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle z_{\mathbb{D}i}=f^{\otimes c}(\exp_{0}^{c}(\texttt{MLP}_{E}(\mathbf{w}_{i})))$
    |  | (33) |'
- en: with mapping back to the $\mathcal{W}^{+}$-space achieved by a logarithmic map
    plus an MLP. Li et al ([2022](#bib.bib77)) supervise the hyperbolic latent space
    with a hyperbolic classification loss based on the multinomial logistic regression
    formulation of Ganea et al ([2018b](#bib.bib41)). After calculating the probabilities,
    the loss function is just negative log-likelihood as
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对$\mathcal{W}^{+}$空间进行对数映射加上MLP的方式来实现映射回去。Li等人 ([2022](#bib.bib77)) 使用基于Ganea等人
    ([2018b](#bib.bib41))的多项式逻辑回归公式的超曲面分类损失来监督超曲面潜在空间。计算概率后，损失函数就是负对数似然，如下所示：
- en: '|  | $\displaystyle\mathcal{L}_{\mathrm{hyper}}=-\frac{1}{N}\sum_{i=1}^{N}\log(p_{n})$
    |  | (34) |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\mathrm{hyper}}=-\frac{1}{N}\sum_{i=1}^{N}\log(p_{n})$
    |  | (34) |'
- en: 'The full loss function is the pSp loss function plus this term, excluding a
    specific facial reconstruction loss used by the pSp method, since Li et al ([2022](#bib.bib77))
    do not focus on face generation. Li et al ([2022](#bib.bib77)) perform image generation
    as follows: given an image $x_{i}$, the image is embedded in hyperbolic space
    with representation $g_{\mathbb{D}}(x_{i})$ and is rescaled to the desired radius
    (*i.e.,* fine-grained-ness) $r$. A random vector is then sampled from the seen
    categories and a point is taken on the geodesic between the two points. Li et al
    ([2022](#bib.bib77)) find that their method is competitive with state-of-the-art
    methods and show promise for image-to-image transfer.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的损失函数是 pSp 损失函数加上这个项，排除了 pSp 方法使用的特定面部重建损失，因为 Li 等 ([2022](#bib.bib77)) 并不关注面部生成。Li
    等 ([2022](#bib.bib77)) 的图像生成方法如下：给定图像 $x_{i}$，该图像在双曲空间中嵌入为表示 $g_{\mathbb{D}}(x_{i})$
    并调整到所需的半径 (*即，* 细致程度) $r$。然后从已知类别中随机采样一个向量，并在两个点之间的测地线上的一点取样。Li 等 ([2022](#bib.bib77))
    发现他们的方法与最先进的方法具有竞争力，并且在图像到图像的转换中表现出良好的前景。
- en: 4.1.3 Hyperbolic Normalizing Flows
  id: totrans-224
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.3 双曲正则化流
- en: '![Refer to caption](img/b5a00363eeb1c6dda399e772a22823a9.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/b5a00363eeb1c6dda399e772a22823a9.png)'
- en: 'Figure 9: The left figure shows the partitioning step of wrapped hyperbolic
    coupling, and the right figure shows how the vector is transformed, transported,
    and projected back to hyperbolic space. Image courtesy of Bose et al ([2020](#bib.bib12)).'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：左侧图展示了包裹双曲耦合的分割步骤，右侧图展示了向量如何被转换、传输并投影回双曲空间。图片由 Bose 等 ([2020](#bib.bib12))
    提供。
- en: 'Bose et al ([2020](#bib.bib12)) propose a hyperbolic normalizing flow that
    generalizes the Euclidean normalizing flow RealNVP (Dinh et al, [2016](#bib.bib35))
    to hyperbolic space. They propose two types of hyperbolic normalizing flows: the
    first, which they call tangent coupling, which carries out the coupling layer
    of RealNVP in the tangent space at the hyperbolic origin $o$:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: Bose 等 ([2020](#bib.bib12)) 提出了一个双曲正则化流，将欧几里得正则化流 RealNVP (Dinh 等, [2016](#bib.bib35))
    推广到双曲空间。他们提出了两种类型的双曲正则化流：第一种被称为切向耦合，在双曲原点 $o$ 的切向空间中执行 RealNVP 的耦合层：
- en: '|  | $\displaystyle\tilde{f}^{\mathcal{T}C}(\tilde{x})=\begin{cases}\tilde{z}_{1}=\tilde{x}_{1}\\
    \tilde{z}_{2}=\tilde{x}_{2}\odot\sigma(s(\tilde{x}_{1}))+t(\tilde{x}_{1})\end{cases}$
    |  | (35) |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\tilde{f}^{\mathcal{T}C}(\tilde{x})=\begin{cases}\tilde{z}_{1}=\tilde{x}_{1}\\
    \tilde{z}_{2}=\tilde{x}_{2}\odot\sigma(s(\tilde{x}_{1}))+t(\tilde{x}_{1})\end{cases}$
    |  | (35) |'
- en: '|  | $\displaystyle f^{\mathcal{T}C}(x)=\exp_{o}^{K}(\tilde{f}^{\mathcal{T}C}(\log_{o}^{K}(x)))$
    |  | (36) |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f^{\mathcal{T}C}(x)=\exp_{o}^{K}(\tilde{f}^{\mathcal{T}C}(\log_{o}^{K}(x)))$
    |  | (36) |'
- en: where $s,t$ are neural networks and $\sigma$ is a pointwise non-linearity.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $s,t$ 是神经网络，$\sigma$ 是逐点非线性函数。
- en: 'The wrapped hyperboloid extends tangent coupling by using parallel transport
    to map intermediate vectors from the tangent space of the origin to the tangent
    space of another point in hyperbolic space (see Figure [9](#S4.F9 "Figure 9 ‣
    4.1.3 Hyperbolic Normalizing Flows ‣ 4.1 Generative approaches ‣ 4 Unsupervised
    hyperbolic visual learning ‣ Hyperbolic Deep Learning in Computer Vision: A Survey")):'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 包裹双曲面通过使用平行传输将中间向量从原点的切向空间映射到双曲空间中另一个点的切向空间，从而扩展了切向耦合（见图 [9](#S4.F9 "图 9 ‣ 4.1.3
    双曲正则化流 ‣ 4.1 生成方法 ‣ 4 无监督双曲视觉学习 ‣ 计算机视觉中的双曲深度学习：综述")）：
- en: '|  | $\displaystyle\tilde{f}^{\mathcal{W}\mathbb{H}C}(\tilde{x})$ | $\displaystyle=\begin{cases}\tilde{z}_{1}=\tilde{x}_{1}\\
    \tilde{z}_{2}=\log_{o}^{K}\left(\exp_{t(\tilde{x}_{1})}^{K}\left(\mathrm{PT}_{o\to
    t(\tilde{x}_{1})}(v)\right)\right)\end{cases}$ |  | (37) |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\tilde{f}^{\mathcal{W}\mathbb{H}C}(\tilde{x})$ | $\displaystyle=\begin{cases}\tilde{z}_{1}=\tilde{x}_{1}\\
    \tilde{z}_{2}=\log_{o}^{K}\left(\exp_{t(\tilde{x}_{1})}^{K}\left(\mathrm{PT}_{o\to
    t(\tilde{x}_{1})}(v)\right)\right)\end{cases}$ |  | (37) |'
- en: '|  | $\displaystyle v$ | $\displaystyle=\tilde{x}_{2}\odot\sigma(s(\tilde{x}_{1}))$
    |  | (38) |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle v$ | $\displaystyle=\tilde{x}_{2}\odot\sigma(s(\tilde{x}_{1}))$
    |  | (38) |'
- en: '|  | $\displaystyle f^{\mathcal{W}\mathbb{H}C}(x)$ | $\displaystyle=\exp_{o}^{K}(\tilde{f}^{\mathcal{W}\mathbb{H}C}(\log_{o}^{K}(x)))$
    |  | (39) |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f^{\mathcal{W}\mathbb{H}C}(x)$ | $\displaystyle=\exp_{o}^{K}(\tilde{f}^{\mathcal{W}\mathbb{H}C}(\log_{o}^{K}(x)))$
    |  | (39) |'
- en: 'Compared to tangent coupling, wrapped hyperbolic coupling allows the flow to
    leverage different parts of the manifold instead of just the origin. The paper
    also derives the inverse and Jacobian determinants of the two flows. As is the
    case for hyperbolic VAEs, Bose et al ([2020](#bib.bib12)) also benchmark on MNIST,
    and find a similar trend as Nagano et al ([2019](#bib.bib92)): the performance
    of hyperbolic models exceed that of the equivalent Euclidean model at low dimension,
    but as early as latent dimension 6 Euclidean models overtake hyperbolic models
    in performance. Bose et al ([2020](#bib.bib12)) find that hyperbolic normalizing
    flows outperform hyperbolic VAEs at these low latent dimensions.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 与切线耦合相比，包裹超曲率耦合允许流量利用流形的不同部分，而不仅仅是原点。论文还推导了这两种流的逆矩阵和雅可比行列式。与超曲率VAE的情况一样，Bose等人
    ([2020](#bib.bib12)) 也在MNIST上进行基准测试，发现与Nagano等人 ([2019](#bib.bib92)) 的趋势类似：超曲率模型在低维度下优于等效的欧几里得模型，但在潜在维度达到6时，欧几里得模型的性能超越了超曲率模型。Bose等人
    ([2020](#bib.bib12)) 发现，在这些低潜在维度下，超曲率标准化流优于超曲率VAE。
- en: 4.2 Clustering
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 聚类
- en: Due to the close relationship between hyperbolic space, hierarchies, and trees,
    several works have explored hierarchical clustering using hyperbolic space. Monath
    et al ([2019](#bib.bib90)) propose to perform hierarchical clustering using hyperbolic
    representations. Given a dataset $\mathcal{D}=\{x_{i}\}_{i=1}^{N}$, Monath et al
    ([2019](#bib.bib90)) require a hyperbolic representation at the edge of the Poincaré
    disk $\mathbb{D}^{d}$ for each data point $x_{i}\in\mathcal{D}$, which becomes
    the leaves of the hierarchical clustering. The method of Monath et al ([2019](#bib.bib90))
    creates a hierarchical clustering by optimizing the hyperbolic representations
    for a fixed number of internal nodes. Parent-children dissimilarity between a
    child representation $z_{c}$ and a parent representation $z_{p}$ is measured by
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 由于超曲率空间、层次结构和树之间的密切关系，已有多个工作探讨了使用超曲率空间的层次聚类。Monath等人 ([2019](#bib.bib90)) 提出使用超曲率表示来执行层次聚类。给定一个数据集$\mathcal{D}=\{x_{i}\}_{i=1}^{N}$，Monath等人
    ([2019](#bib.bib90)) 要求每个数据点$x_{i}\in\mathcal{D}$在Poincaré圆盘$\mathbb{D}^{d}$的边缘有一个超曲率表示，这些表示成为层次聚类的叶子节点。Monath等人
    ([2019](#bib.bib90)) 的方法通过优化超曲率表示来创建层次聚类，固定内部节点的数量。子表示$z_{c}$和父表示$z_{p}$之间的父子异质性通过以下公式测量
- en: '|  | $\displaystyle d_{cp}(z_{c},z_{p})=d_{\mathbb{D}}(z_{c},z_{p})(1+\max\{&#124;&#124;z_{p}&#124;&#124;_{\mathbb{D}}-&#124;&#124;z_{c}&#124;&#124;_{\mathbb{D}},0\})$
    |  | (40) |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle d_{cp}(z_{c},z_{p})=d_{\mathbb{D}}(z_{c},z_{p})(1+\max\{&#124;&#124;z_{p}&#124;&#124;_{\mathbb{D}}-&#124;&#124;z_{c}&#124;&#124;_{\mathbb{D}},0\})$
    |  | (40) |'
- en: 'which encourages children to have larger norms than their parents. A discrete
    tree can then be extracted as follows:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这鼓励子节点的范数大于其父节点。然后可以提取出离散树，如下所示：
- en: '|  | $\displaystyle\texttt{Parent}(z_{c})=\operatorname*{arg\,min}_{&#124;&#124;z_{p}&#124;&#124;<&#124;&#124;z_{c}&#124;&#124;}d_{cp}(z_{c},z_{p})$
    |  | (41) |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\texttt{Parent}(z_{c})=\operatorname*{arg\,min}_{&#124;&#124;z_{p}&#124;&#124;<&#124;&#124;z_{c}&#124;&#124;}d_{cp}(z_{c},z_{p})$
    |  | (41) |'
- en: 'The internal node observations are supervised by two losses: first, a hierarchical
    clustering loss based on Dasgupta’s cost (Dasgupta, [2016](#bib.bib30)) and a
    continuous extension due to Wang and Wang ([2018](#bib.bib117)) that reformulates
    the loss in terms of last common ancestors (LCAs), and second, a parent-child
    margin objective that encourages parent nodes to have smaller norm than their
    children.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 内部节点的观测通过两种损失进行监督：首先是基于Dasgupta成本的层次聚类损失（Dasgupta，[2016](#bib.bib30)）和Wang和Wang
    ([2018](#bib.bib117)) 提出的一个连续扩展，该扩展将损失重新表述为最近公共祖先（LCAs）；其次是一个父子边距目标，鼓励父节点的范数小于其子节点。
- en: Suppose $\mathcal{D}$ has pairwise similarities $\{w_{ij}\}_{i,j\in[N]}$. A
    hierarchical clustering of $\mathcal{D}$ is a rooted tree $T$ such that each leaf
    is a data point. For leaves $i,j\in T$, denote their LCA by $i\vee j$, the subtree
    rooted at $i\vee j$ by $T[i\vee j]$, and the leaves of $T[i\vee j]$ by $\texttt{leaves}(T[i\vee
    j])$. Finally, let relation $\{i,j|k\}$ holds if $i\vee j$ is a descendant of
    $i\vee j\vee k$. Then Dasgupta’s cost can be formulated as
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 假设$\mathcal{D}$有成对的相似度$\{w_{ij}\}_{i,j\in[N]}$。$\mathcal{D}$的层次聚类是一个根树$T$，其中每个叶子节点都是一个数据点。对于叶子节点$i,j\in
    T$，记它们的最近公共祖先为$i\vee j$，以$i\vee j$为根的子树为$T[i\vee j]$，$T[i\vee j]$的叶子节点为$\texttt{leaves}(T[i\vee
    j])$。最后，当$i\vee j$是$i\vee j\vee k$的后代时，关系$\{i,j|k\}$成立。然后Dasgupta的成本可以被表述为
- en: '|  | $\displaystyle C_{\mathrm{Dasgupta}}(T;w)=\sum_{ij}w_{ij}&#124;\texttt{leaves}(T[i\vee
    j])&#124;$ |  | (42) |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle C_{\mathrm{Dasgupta}}(T;w)=\sum_{ij}w_{ij}&#124;\texttt{leaves}(T[i\vee
    j])&#124;$ |  | (42) |'
- en: Wang and Wang ([2018](#bib.bib117)) show that
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: Wang 和 Wang ([2018](#bib.bib117)) 表明
- en: '|  | $\displaystyle C_{\mathrm{Dasgupta}}(T;w)$ | $\displaystyle=\sum_{ijk}[w_{ij}+w_{ik}+w_{jk}-w_{ijk}(T;w)]$
    |  | (43) |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle C_{\mathrm{Dasgupta}}(T;w)$ | $\displaystyle=\sum_{ijk}[w_{ij}+w_{ik}+w_{jk}-w_{ijk}(T;w)]$
    |  | (43) |'
- en: '|  |  | $\displaystyle+2\sum_{ij}w_{ij}$ |  | (44) |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle+2\sum_{ij}w_{ij}$ |  | (44) |'
- en: where
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '|  | $\displaystyle w_{ijk}(T;w)=w_{ij}\mathbbm{1}[\{i,j&#124;k\}]+w_{ik}\mathbbm{1}[\{i,k&#124;j\}]+w_{jk}\mathbbm{1}[\{j,k&#124;i\}]$
    |  | (45) |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle w_{ijk}(T;w)=w_{ij}\mathbbm{1}[\{i,j&#124;k\}]+w_{ik}\mathbbm{1}[\{i,k&#124;j\}]+w_{jk}\mathbbm{1}[\{j,k&#124;i\}]$
    |  | (45) |'
- en: The margin parent-child dissimilarity is given as
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 边际父子不相似度定义为
- en: '|  | $\displaystyle d_{cp}(z_{c},z_{p};\gamma)=d_{\mathbb{D}}(z_{c},z_{p})(1+\max\{&#124;&#124;z_{p}&#124;&#124;_{\mathbb{D}}-&#124;&#124;z_{c}&#124;&#124;_{\mathbb{D}}+\gamma,0\})$
    |  | (46) |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle d_{cp}(z_{c},z_{p};\gamma)=d_{\mathbb{D}}(z_{c},z_{p})(1+\max\{&#124;&#124;z_{p}&#124;&#124;_{\mathbb{D}}-&#124;&#124;z_{c}&#124;&#124;_{\mathbb{D}}+\gamma,0\})$
    |  | (46) |'
- en: and the total margin objective is
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 总边际目标为
- en: '|  | $\displaystyle\mathcal{L}_{cp}=\sum_{z_{c}}d_{cp}(z_{c},\texttt{Parent}(z_{c});\gamma)$
    |  | (47) |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{cp}=\sum_{z_{c}}d_{cp}(z_{c},\texttt{Parent}(z_{c});\gamma)$
    |  | (47) |'
- en: The embedding is alternately optimized between the clustering objective and
    the parent-child objective. Optimization of the hyperbolic parameters is done
    via the method of Nickel and Kiela ([2017](#bib.bib93)). Using this method, Monath
    et al ([2019](#bib.bib90)) are able to embed ImageNet using representations taken
    from the last layer of a pre-trained Inception neural network.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入在聚类目标和父子目标之间交替优化。超曲率参数的优化通过 Nickel 和 Kiela ([2017](#bib.bib93)) 的方法进行。利用这种方法，Monath
    等人 ([2019](#bib.bib90)) 能够使用从预训练的 Inception 神经网络的最后一层提取的表示来嵌入 ImageNet。
- en: 'Similar to Monath et al ([2019](#bib.bib90)), Chami et al ([2020a](#bib.bib17))
    base their method on Dasgupta’s cost (Equation [42](#S4.E42 "In 4.2 Clustering
    ‣ 4 Unsupervised hyperbolic visual learning ‣ Hyperbolic Deep Learning in Computer
    Vision: A Survey")) and Wang and Wang’s (Equation [43](#S4.E43 "In 4.2 Clustering
    ‣ 4 Unsupervised hyperbolic visual learning ‣ Hyperbolic Deep Learning in Computer
    Vision: A Survey")) reformulation in terms of LCAs. Chami et al ([2020a](#bib.bib17))
    define the LCA of two points in hyperbolic space to be the point on the geodesic
    connecting the two points that are closest to the hyperbolic origin, and provide
    a formula to calculate this point in the Poincaré disk $\mathbb{D}$. This formula
    allows Equation [43](#S4.E43 "In 4.2 Clustering ‣ 4 Unsupervised hyperbolic visual
    learning ‣ Hyperbolic Deep Learning in Computer Vision: A Survey") to be directly
    optimized by replacing the $w_{ijk}(T;w)$ terms with its continuous counterpart.
    A hierarchical clustering tree can then be produced by iteratively merging the
    most similar pairs, where similarity is measured by their hyperbolic LCA distance
    from the origin. Unlike the method of Monath et al ([2019](#bib.bib90)), Chami
    et al ([2020a](#bib.bib17)) do not require hyperbolic embeddings to be available,
    and optimize the hyperbolic embeddings of the whole tree, not just the leaves.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 Monath 等人 ([2019](#bib.bib90))，Chami 等人 ([2020a](#bib.bib17)) 基于 Dasgupta
    的成本 (方程 [42](#S4.E42 "在 4.2 聚类 ‣ 4 无监督超曲率视觉学习 ‣ 超曲率深度学习在计算机视觉中的应用综述")) 和 Wang
    和 Wang (方程 [43](#S4.E43 "在 4.2 聚类 ‣ 4 无监督超曲率视觉学习 ‣ 超曲率深度学习在计算机视觉中的应用综述")) 的重新表述。Chami
    等人 ([2020a](#bib.bib17)) 将超曲率空间中两点的 LCA 定义为连接两点的测地线上的点，该点距离超曲率原点最近，并提供了一个公式来计算
    Poincaré 磁盘 $\mathbb{D}$ 中的该点。这个公式允许方程 [43](#S4.E43 "在 4.2 聚类 ‣ 4 无监督超曲率视觉学习 ‣
    超曲率深度学习在计算机视觉中的应用综述") 通过用其连续对应项替换 $w_{ijk}(T;w)$ 项来直接优化。然后，可以通过迭代合并最相似的对来生成一个层次聚类树，其中相似度通过它们与原点的超曲率
    LCA 距离来衡量。与 Monath 等人 ([2019](#bib.bib90)) 的方法不同，Chami 等人 ([2020a](#bib.bib17))
    不需要超曲率嵌入可用，而是优化整个树的超曲率嵌入，而不仅仅是叶子。
- en: 'Lin et al ([2022](#bib.bib79)) propose a neural-network based framework for
    the hierarchical clustering of multi-view data. The framework consists of two
    steps: first, improving representation quality via reconstruction loss, contrastive
    learning between different views, and a weighted triplet loss between positive
    examples and mined hard negative examples, and second, applying the hyperbolic
    hierarchical clustering framework of Chami et al ([2020a](#bib.bib17)).'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Lin 等人 ([2022](#bib.bib79)) 提出了一个基于神经网络的框架，用于多视图数据的层次聚类。该框架包括两个步骤：首先，通过重构损失、不同视图之间的对比学习以及正例与挖掘到的困难负例之间的加权三元组损失来提高表示质量，其次，应用
    Chami 等人 ([2020a](#bib.bib17)) 的超曲率层次聚类框架。
- en: The contrastive loss in Lin et al ([2022](#bib.bib79)) is the usual contrastive
    loss (see following section) where positive examples are views from the same object
    and negative examples are views from different objects. The weighted triplet loss
    is
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: Lin等人([2022](#bib.bib79))中的对比损失是通常的对比损失（见下节），其中正样本是来自同一对象的视图，负样本是来自不同对象的视图。加权三元组损失为
- en: '|  | $\displaystyle\mathcal{L}_{m}=\frac{1}{N}\sum_{i=1}^{N}w^{m}(a_{i},p_{i})[m+&#124;&#124;a_{i}-p_{i}&#124;&#124;^{2}_{2}-&#124;&#124;a_{i}-n_{i}&#124;&#124;^{2}_{2}]_{+}$
    |  | (48) |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{m}=\frac{1}{N}\sum_{i=1}^{N}w^{m}(a_{i},p_{i})[m+&#124;&#124;a_{i}-p_{i}&#124;&#124;^{2}_{2}-&#124;&#124;a_{i}-n_{i}&#124;&#124;^{2}_{2}]_{+}$
    |  | (48) |'
- en: where $a_{i}$ refer to the anchor points, $p_{i}$ are the positive examples,
    and $n_{i}$ are the negative examples. Positive and negatives examples are mined
    based on the method of Iscen et al ([2017](#bib.bib62)), which measures the similarity
    of a pair of points based on estimating the data manifold using $k$-nearest neighbors
    graphs. Lin et al ([2022](#bib.bib79)) apply their method to perform multi-view
    clustering for a variety of multi-view image datasets.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $a_{i}$ 代表锚点，$p_{i}$ 是正样本，而 $n_{i}$ 是负样本。正样本和负样本是基于Iscen等人([2017](#bib.bib62))的方法挖掘的，该方法通过使用
    $k$-最近邻图来估计数据流形，从而测量一对点的相似性。Lin等人([2022](#bib.bib79))将他们的方法应用于各种多视角图像数据集的多视角聚类。
- en: 4.3 Self-supervised learning
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 自监督学习
- en: 'In Section [4.3.1](#S4.SS3.SSS1 "4.3.1 Hyperbolic self-supervision ‣ 4.3 Self-supervised
    learning ‣ 4 Unsupervised hyperbolic visual learning ‣ Hyperbolic Deep Learning
    in Computer Vision: A Survey"), we describe methods for hyperbolic self-supervision
    which are primarily based on triplet losses, and in Section [4.3.2](#S4.SS3.SSS2
    "4.3.2 Hyperbolic contrastive learning ‣ 4.3 Self-supervised learning ‣ 4 Unsupervised
    hyperbolic visual learning ‣ Hyperbolic Deep Learning in Computer Vision: A Survey")
    we discuss methods for hyperbolic self-supervision which are primarily based on
    contrastive losses.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[4.3.1节](#S4.SS3.SSS1 "4.3.1 超曲面自监督 ‣ 4.3 自监督学习 ‣ 4 无监督超曲面视觉学习 ‣ 计算机视觉中的超曲面深度学习：综述")中，我们描述了主要基于三元组损失的超曲面自监督方法，而在第[4.3.2节](#S4.SS3.SSS2
    "4.3.2 超曲面对比学习 ‣ 4.3 自监督学习 ‣ 4 无监督超曲面视觉学习 ‣ 计算机视觉中的超曲面深度学习：综述")中，我们讨论了主要基于对比损失的超曲面自监督方法。
- en: 4.3.1 Hyperbolic self-supervision
  id: totrans-261
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1 超曲面自监督
- en: 'Based on the idea that biomedical images are inherently hierarchical, Hsu et al
    ([2021](#bib.bib61)) propose to learn patch-level representations of 3D biomedical
    images using a 3D hyperbolic VAE and to perform 3D unsupervised segmentation by
    clustering the representations. Hsu et al ([2021](#bib.bib61)) extend the hyperbolic
    VAE architecture of Mathieu et al ([2019](#bib.bib85)) using a 3D convolutional
    encoder and decoder as well as gyroplane convolutional layer that generalizes
    the Euclidean convolution with the gyroplane layer of Ganea et al ([2018b](#bib.bib41))
    (See Equations [29](#S4.E29 "In 4.1.1 Hyperbolic VAEs ‣ 4.1 Generative approaches
    ‣ 4 Unsupervised hyperbolic visual learning ‣ Hyperbolic Deep Learning in Computer
    Vision: A Survey") and [30](#S4.E30 "In 4.1.1 Hyperbolic VAEs ‣ 4.1 Generative
    approaches ‣ 4 Unsupervised hyperbolic visual learning ‣ Hyperbolic Deep Learning
    in Computer Vision: A Survey")). In order to learn good representations, the paper
    proposes to use a hierarchical self-supervised loss that captures the implicit
    hierarchical structure of 3D biomedical images.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 基于生物医学图像本质上是层次化的观点，Hsu等人([2021](#bib.bib61))提出使用3D超曲面VAE学习3D生物医学图像的补丁级表示，并通过对表示进行聚类来执行3D无监督分割。Hsu等人([2021](#bib.bib61))扩展了Mathieu等人([2019](#bib.bib85))的超曲面VAE架构，使用3D卷积编码器和解码器以及陀螺面卷积层，这一层将欧几里得卷积与Ganea等人([2018b](#bib.bib41))的陀螺面层进行了推广（见方程[29](#S4.E29
    "在4.1.1 超曲面VAE ‣ 4.1 生成方法 ‣ 4 无监督超曲面视觉学习 ‣ 计算机视觉中的超曲面深度学习：综述")和[30](#S4.E30 "在4.1.1
    超曲面VAE ‣ 4.1 生成方法 ‣ 4 无监督超曲面视觉学习 ‣ 计算机视觉中的超曲面深度学习：综述")）。为了学习良好的表示，本文提出使用一种层次化自监督损失来捕捉3D生物医学图像的隐含层次结构。
- en: 'To capture the hierarchical structure of 3D biomedical images, Hsu et al ([2021](#bib.bib61))
    propose that given a parent patch $\mu_{p}$, to sample a child patch $\mu_{c}$
    which is a subpatch of the parent patch, and a negative patch $\mu_{n}$ that does
    not overlap with the parent patch. Then the hierarchical self-supervised loss
    is defined as a margin triplet loss as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 为了捕捉 3D 生物医学图像的层次结构，Hsu 等人（[2021](#bib.bib61)）提出，给定一个父补丁 $\mu_{p}$，可以采样一个子补丁
    $\mu_{c}$，它是父补丁的子补丁，以及一个与父补丁不重叠的负补丁 $\mu_{n}$。然后，层次自监督损失定义为如下的边际三元组损失：
- en: '|  | $\displaystyle\mathcal{L}_{\mathrm{hierarchical}}=\max(0,d_{\mathbb{D}}(\mu_{p},\mu_{c})-d_{\mathbb{D}}(\mu_{p},\mu_{n})+\gamma)$
    |  | (49) |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\mathrm{hierarchical}}=\max(0,d_{\mathbb{D}}(\mu_{p},\mu_{c})-d_{\mathbb{D}}(\mu_{p},\mu_{n})+\gamma)$
    |  | (49) |'
- en: This encourages the representations of subpatches to be children or descendants
    of the representation of the main patch, and faraway patches (which likely contain
    different structures) to be on other branches of the learned hierarchical representation.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这鼓励子补丁的表示成为主补丁表示的子代或后代，而远离的补丁（可能包含不同结构）则位于学习到的层次表示的其他分支上。
- en: 'To perform unsupervised segmentation, the learned latent representations are
    extracted and clustered using a hyperbolic k-means algorithm, where the traditional
    Euclidean mean is replaced with the Frechet mean. For a manifold $\mathcal{M}$
    with metric $d_{\mathcal{M}}$, the Frechet mean of a set of points $\{z_{i}\}_{i=1}^{k},z_{i}\in\mathcal{M}$
    is defined as the point $\mu$ that minimizes the squared distance to all points
    $z_{i}$:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行无监督分割，提取和聚类学习到的潜在表示，使用超曲率 k-means 算法，其中传统的欧几里得均值被弗雷歇均值替代。对于一个带有度量 $d_{\mathcal{M}}$
    的流形 $\mathcal{M}$，一组点 $\{z_{i}\}_{i=1}^{k},z_{i}\in\mathcal{M}$ 的弗雷歇均值定义为点 $\mu$，使得到所有点
    $z_{i}$ 的平方距离最小：
- en: '|  | $\displaystyle\mu_{\mathrm{Fr}}=\operatorname*{arg\,min}_{\mu\in\mathcal{M}}\frac{1}{k}\sum_{i=1}^{k}d_{\mathcal{M}}(z_{i},\mu)^{2}$
    |  | (50) |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mu_{\mathrm{Fr}}=\operatorname*{arg\,min}_{\mu\in\mathcal{M}}\frac{1}{k}\sum_{i=1}^{k}d_{\mathcal{M}}(z_{i},\mu)^{2}$
    |  | (50) |'
- en: and is one way to generalize the concept of a mean to manifolds. Unfortunately,
    the Frechet mean on the Poincaré ball does not admit a closed-form solution, so
    Hsu et al ([2021](#bib.bib61)) compute the Frechet mean with the iterative algorithm
    of Lou et al ([2020](#bib.bib83)). The paper finds that this strategy is effective
    for the unsupervised segmentation of both synthetic biological data and 3D brain
    tumor MRI scans (Menze et al, [2014](#bib.bib86); Bakas et al, [2017](#bib.bib7),
    [2018](#bib.bib8)).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种将均值的概念推广到流形上的方法。不幸的是，Poincaré 球上的弗雷歇均值没有封闭形式解，因此 Hsu 等人（[2021](#bib.bib61)）使用
    Lou 等人（[2020](#bib.bib83)）的迭代算法计算弗雷歇均值。论文发现这一策略对于合成生物数据和 3D 脑肿瘤 MRI 扫描的无监督分割都很有效（Menze
    等人，[2014](#bib.bib86)；Bakas 等人，[2017](#bib.bib7)，[2018](#bib.bib8)）。
- en: 'Weng et al ([2021](#bib.bib120)) propose to leverage the hierarchical structure
    of objects within images to perform weakly-supervised long-tail instance segmentation.
    To capture this hierarchical structure, Weng et al ([2021](#bib.bib120)) learn
    hyperbolic representations which are supervised with several hyperbolic self-supervised
    losses. Instance segmentation is done in three stages: first, mask proposals are
    generated using a pre-trained mask proposal network. Mask proposals consists of
    bounding boxes $\{\mathcal{B}_{i}\}_{i=1}^{k}$ and masks $\{\mathcal{M}_{i}\}_{i=1}^{k}$.
    Define $x_{i}^{\mathrm{full}}$ to be the original image cropped to bounding box
    $\mathcal{B}_{i}$, $x_{i}^{\mathrm{bg}}$ to be the cropped image with the object
    masked out using mask $1-\mathcal{M}_{i}$, and $x_{i}^{\mathrm{fg}}$ to be the
    same cropped image with the background masked out using mask $\mathcal{M}_{i}$.
    We will refer to these as the full object image, object background, and object,
    respectively.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: Weng 等人（[2021](#bib.bib120)）提出利用图像中物体的层次结构来执行弱监督长尾实例分割。为了捕捉这一层次结构，Weng 等人（[2021](#bib.bib120)）学习了超曲率表示，并使用几个超曲率自监督损失对其进行监督。实例分割分为三个阶段：首先，使用预训练的掩码提议网络生成掩码提议。掩码提议包括边界框
    $\{\mathcal{B}_{i}\}_{i=1}^{k}$ 和掩码 $\{\mathcal{M}_{i}\}_{i=1}^{k}$。定义 $x_{i}^{\mathrm{full}}$
    为裁剪到边界框 $\mathcal{B}_{i}$ 的原始图像，$x_{i}^{\mathrm{bg}}$ 为使用掩码 $1-\mathcal{M}_{i}$
    遮蔽对象的裁剪图像，$x_{i}^{\mathrm{fg}}$ 为使用掩码 $\mathcal{M}_{i}$ 遮蔽背景的相同裁剪图像。我们将这些称为完整对象图像、对象背景和对象。
- en: 'Second, hyperbolic representations of $z_{i}^{\mathrm{bg}}=g(x_{i}^{\mathrm{bg}})$,
    and $z_{i}^{\mathrm{fg}}=g(x_{i}^{\mathrm{fg}})$ are learned by a pre-trained
    feature extractor and supervised by a combination of three self-supervised losses.
    The representations are fixed to have latent dimension 2\. The first self-supervised
    loss encourages representation of the object to be similar to that of the full
    object image and farther away from the representation of the object background:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，$z_{i}^{\mathrm{bg}}=g(x_{i}^{\mathrm{bg}})$和$z_{i}^{\mathrm{fg}}=g(x_{i}^{\mathrm{fg}})$的超曲率表示通过预训练的特征提取器学习，并通过三种自监督损失的组合进行监督。表示被固定为潜在维度2。第一种自监督损失鼓励物体的表示与完整物体图像的表示相似，并远离物体背景的表示：
- en: '|  | $\displaystyle\mathcal{L}_{\mathrm{mask}}=\sum_{i=1}^{k}\max(0,\gamma-d(z_{i}^{\mathrm{full}},z^{\mathrm{fg}})+d(z_{i}^{\mathrm{full}},z_{i}^{\mathrm{bg}}))$
    |  | (51) |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\mathrm{mask}}=\sum_{i=1}^{k}\max(0,\gamma-d(z_{i}^{\mathrm{full}},z^{\mathrm{fg}})+d(z_{i}^{\mathrm{full}},z_{i}^{\mathrm{bg}}))$
    |  | (51) |'
- en: The second loss is a triplet loss that requires the sampling of positive and
    negative examples.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种损失是一种三元组损失，需要对正样本和负样本进行采样。
- en: '|  | $\displaystyle\mathcal{L}_{\mathrm{object}}=\sum_{i=1}^{k}\max(0,\gamma-d(z_{i}^{\mathrm{fg}},\hat{z}^{\mathrm{fg}})+d(z_{i}^{\mathrm{fg}},\overline{z}_{i}^{\mathrm{fg}}))$
    |  | (52) |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\mathrm{object}}=\sum_{i=1}^{k}\max(0,\gamma-d(z_{i}^{\mathrm{fg}},\hat{z}^{\mathrm{fg}})+d(z_{i}^{\mathrm{fg}},\overline{z}_{i}^{\mathrm{fg}}))$
    |  | (52) |'
- en: 'The third loss is similar to the hierarchical triplet loss of Hsu et al ([2021](#bib.bib61))
    described above, except with the origin taking the place of negative samples:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种损失与上述Hsu等人 ([2021](#bib.bib61)) 描述的层次三元组损失类似，只不过原点取代了负样本：
- en: '|  | $\displaystyle\mathcal{L}_{\mathrm{hierarchical}}=\sum_{i=1}^{k}\max(0,\gamma-d(z_{i}^{\mathrm{child}},o)-d(z_{i}^{\mathrm{fg}},o))$
    |  | (53) |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\mathrm{hierarchical}}=\sum_{i=1}^{k}\max(0,\gamma-d(z_{i}^{\mathrm{child}},o)-d(z_{i}^{\mathrm{fg}},o))$
    |  | (53) |'
- en: 'Finally, the representations are clustered using hyperbolic k-means clustering.
    Unlike Hsu et al ([2021](#bib.bib61)), to compute the mean they map the representations
    from the Poincare disk to the hyperboloid model $\mathcal{L}$ and compute the
    (weighted) hyperboloid midpoint proposed by Law et al ([2019](#bib.bib73)):'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用超曲率k-means聚类对表示进行聚类。与Hsu等人 ([2021](#bib.bib61)) 不同，他们将表示从Poincare圆盘映射到超曲率模型$\mathcal{L}$，并计算Law等人
    ([2019](#bib.bib73)) 提出的（加权）超曲率中点。
- en: '|  | $\displaystyle\mu=\frac{\sum_{i=1}^{k}\nu_{i}x_{i}}{\left&#124;&#124;&#124;\sum_{i=1}^{k}\nu_{i}x_{i}&#124;&#124;_{\mathcal{L}}\right&#124;}$
    |  | (54) |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mu=\frac{\sum_{i=1}^{k}\nu_{i}x_{i}}{\left&#124;&#124;&#124;\sum_{i=1}^{k}\nu_{i}x_{i}&#124;&#124;_{\mathcal{L}}\right&#124;}$
    |  | (54) |'
- en: Compared to the Frechet mean, this mean has the advantage of having a closed-form
    formula, making it more computationally efficient. Weng et al ([2021](#bib.bib120))
    find that their method improves other partially-supervised methods on the LVIS
    long-tail segmentation dataset (Gupta et al, [2019](#bib.bib55)).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 与Frechet均值相比，这种均值的优点在于具有封闭形式的公式，使其计算效率更高。Weng等人 ([2021](#bib.bib120)) 发现他们的方法在LVIS长尾分割数据集上（Gupta等人，[2019](#bib.bib55)）改进了其他部分监督方法。
- en: 4.3.2 Hyperbolic contrastive learning
  id: totrans-279
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.2 超曲率对比学习
- en: '![Refer to caption](img/91d8eb92f2c844fbdcad2c5b3adc91d5.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/91d8eb92f2c844fbdcad2c5b3adc91d5.png)'
- en: 'Figure 10: Surís et al ([2021](#bib.bib109)) model uncertainty with hyperbolic
    representations. If the model is uncertain, it can predict an abstraction of all
    possible actions (red square), and if it is certain it can predict a more specific
    action (blue square). The pink circle shows how computing the mean of two representations
    (pink squares) increases the generality. Image courtesy of Surís et al ([2021](#bib.bib109)).'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：Surís等人 ([2021](#bib.bib109)) 使用超曲率表示模型不确定性。如果模型不确定，它可以预测所有可能行动的抽象（红色方框），如果确定，它可以预测更具体的行动（蓝色方框）。粉红色圆圈显示计算两个表示的均值（粉红色方框）如何增加一般性。图片由Surís等人
    ([2021](#bib.bib109)) 提供。
- en: 'Hyperbolic contrastive learning methods have also been proposed. Surís et al
    ([2021](#bib.bib109)) propose to learn hyperbolic representations for video action
    prediction because of their ability to combine representing hierarchy and giving
    a measure of uncertainty (See Figure [10](#S4.F10 "Figure 10 ‣ 4.3.2 Hyperbolic
    contrastive learning ‣ 4.3 Self-supervised learning ‣ 4 Unsupervised hyperbolic
    visual learning ‣ Hyperbolic Deep Learning in Computer Vision: A Survey")). Surís
    et al ([2021](#bib.bib109)) learn an action hierarchy where more abstract actions
    are near the origin of the Poincaré disk and more fine-grained actions are near
    the edge. If the preceding video frames are ambiguous, this hierarchical representation
    allows the ability to predict a more general parent category of action (*e.g.,*
    greeting) instead of having to predict more fine-grained child categories of action
    (*e.g.,* handshake or high-five). The parent of two actions is computed as the
    hyperbolic mean of their hyperbolic representations, which Surís et al ([2021](#bib.bib109))
    compute as the midpoint of the geodesic connecting the two representations. Surís
    et al ([2021](#bib.bib109)) propose a two-stage framework for video action prediction
    which consists first of contrastive pre-training hyperbolic representations, then
    freezing the representations and training a linear classifier for action prediction.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 超曲率对比学习方法也已被提出。Surís 等人 ([2021](#bib.bib109)) 提出学习超曲率表示用于视频动作预测，因为这种表示能够结合表示层次结构并提供不确定性度量（见图
    [10](#S4.F10 "图 10 ‣ 4.3.2 超曲率对比学习 ‣ 4.3 自监督学习 ‣ 4 无监督超曲率视觉学习 ‣ 超曲率深度学习在计算机视觉中的应用")）。Surís
    等人 ([2021](#bib.bib109)) 学习了一个动作层次结构，其中较抽象的动作靠近庞加莱圆盘的原点，而更细粒度的动作则靠近边缘。如果前面的画面模糊，这种层次表示可以预测一个更一般的动作类别（*例如，*问候），而不必预测更细粒度的子类别动作（*例如，*握手或击掌）。两个动作的父类别是通过计算它们的超曲率表示的超曲率均值来得到的，Surís
    等人 ([2021](#bib.bib109)) 计算这一均值为连接这两个表示的测地线的中点。Surís 等人 ([2021](#bib.bib109))
    提出了一种两阶段的视频动作预测框架，首先进行对比预训练超曲率表示，然后冻结这些表示，并训练线性分类器进行动作预测。
- en: 'Self-supervised pre-training proceeds as follows: let $x_{t}$ be a frame of
    the video, and a representation $z_{t}=f(x_{t})$ is produced by an encoder $f$.
    The pretext task is to predict the representation $z_{t+\delta}$ of a clip $\delta$
    frames into the future. The model produces an estimate $\hat{z}_{t+\delta}=\phi(c_{t},\delta)$,
    where $c_{t}=g(z_{1},\ldots,z_{t})$ is an encoding of all past video frames. All
    function $f,g,\phi$ are parameterized by a neural network. The training is supervised
    by a contrastive loss:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督预训练过程如下：设 $x_{t}$ 为视频的一帧，表示 $z_{t}=f(x_{t})$ 由编码器 $f$ 生成。预训练任务是预测未来 $\delta$
    帧的表示 $z_{t+\delta}$。模型生成一个估计值 $\hat{z}_{t+\delta}=\phi(c_{t},\delta)$，其中 $c_{t}=g(z_{1},\ldots,z_{t})$
    是所有过去视频帧的编码。所有函数 $f,g,\phi$ 都由神经网络参数化。训练由对比损失进行监督：
- en: '|  | $\displaystyle\mathcal{L}=-\sum_{i}\left[\log\frac{\exp(-d_{\mathbb{D}}^{2}(\hat{z}_{i},z_{i}))}{\sum_{j}\exp(-d_{\mathbb{D}}^{2}(\hat{z}_{i},z_{j}))}\right]$
    |  | (55) |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}=-\sum_{i}\left[\log\frac{\exp(-d_{\mathbb{D}}^{2}(\hat{z}_{i},z_{i}))}{\sum_{j}\exp(-d_{\mathbb{D}}^{2}(\hat{z}_{i},z_{j}))}\right]$
    |  | (55) |'
- en: which encourages the positive pairs $\hat{z}_{i},z_{i}$ to have similar representations
    while pushing $\hat{z}_{i}$ from the representations of all negative examples
    $z_{j}$. One key feature of this loss is that under the presence of uncertainty,
    say when actions $a,b$ are probable, $\mathcal{L}$ is minimized by predicting
    the midpoint on the geodesic connecting $a,b$, which is equivalent to moving one
    level up the hierarchy to the parent of $a,b$.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这促使正对 $\hat{z}_{i},z_{i}$ 具有相似的表示，同时将 $\hat{z}_{i}$ 从所有负例 $z_{j}$ 的表示中推开。这种损失的一个关键特性是，在存在不确定性的情况下，比如当动作
    $a,b$ 可能发生时，$\mathcal{L}$ 通过预测连接 $a,b$ 的测地线上的中点来最小化，这等同于将层次上升一级到 $a,b$ 的父类别。
- en: '![Refer to caption](img/7949e32f6e0a3941f3d89333572c5e80.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7949e32f6e0a3941f3d89333572c5e80.png)'
- en: 'Figure 11: The learned hierarchy of Ge et al ([2022](#bib.bib45)) has objects
    near the origin of the Poincaré disk and scenes near the edge of hyperbolic space.
    Image courtesy of Ge et al ([2022](#bib.bib45)).'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：Ge 等人 ([2022](#bib.bib45)) 学到的层次结构中，物体靠近庞加莱圆盘的原点，场景靠近超曲率空间的边缘。图片由 Ge 等人
    ([2022](#bib.bib45)) 提供。
- en: 'Ge et al ([2022](#bib.bib45)) propose to improve contrastive learning by incorporating
    the hierarchical structure of images with a scene-object hierarchy (see Figure
    [11](#S4.F11 "Figure 11 ‣ 4.3.2 Hyperbolic contrastive learning ‣ 4.3 Self-supervised
    learning ‣ 4 Unsupervised hyperbolic visual learning ‣ Hyperbolic Deep Learning
    in Computer Vision: A Survey")). Ge et al ([2022](#bib.bib45)) use a hyperbolic
    version of the MoCo architecture (He et al, [2020](#bib.bib57)), which the authors
    call HCL. Ge et al ([2022](#bib.bib45)) extend the MoCo architectures in several
    ways: first, unlike previous works for visual contrastive learning, HCL requires
    that object regions be extracted from the input image. Secondly, a hyperbolic
    backbone along with a corresponding momentum encoder is added to MoCo’s Euclidean
    backbone and its momentum encoder. The Euclidean backbone and momentum encoder
    are trained the same way as in He et al ([2020](#bib.bib57)), but the inputs are
    not images but the extracted object regions. The hyperbolic branch takes as input
    a scene region $u$ and an object region $v$ that is a subregion of the scene $u$,
    and negative objects $\mathcal{N}_{u}=\{n_{1},\ldots,n_{k}\}$ that are not subregions
    of the scene $u$. Let the representations of $u,v,n_{j}$ be $z_{u},z_{v},z_{j}$,
    respectively. The hyperbolic branch is then trained with a contrastive loss with
    hyperbolic distance as the similarity measure:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 'Ge 等人 ([2022](#bib.bib45)) 提出了通过结合具有场景-对象层次结构的图像的层次结构来改进对比学习（见图 [11](#S4.F11
    "Figure 11 ‣ 4.3.2 Hyperbolic contrastive learning ‣ 4.3 Self-supervised learning
    ‣ 4 Unsupervised hyperbolic visual learning ‣ Hyperbolic Deep Learning in Computer
    Vision: A Survey")）。Ge 等人 ([2022](#bib.bib45)) 使用了 MoCo 架构的双曲版本（He 等人，[2020](#bib.bib57)），作者称之为
    HCL。Ge 等人 ([2022](#bib.bib45)) 以几种方式扩展了 MoCo 架构：首先，与之前的视觉对比学习工作不同，HCL 要求从输入图像中提取对象区域。其次，向
    MoCo 的欧几里得骨干网及其动量编码器中添加了一个双曲骨干网及相应的动量编码器。欧几里得骨干网和动量编码器的训练方式与 He 等人 ([2020](#bib.bib57))
    相同，但输入不是图像，而是提取的对象区域。双曲分支将场景区域 $u$ 和对象区域 $v$（它是场景 $u$ 的子区域）以及不属于场景 $u$ 的负对象 $\mathcal{N}_{u}=\{n_{1},\ldots,n_{k}\}$
    作为输入。令 $u,v,n_{j}$ 的表示分别为 $z_{u},z_{v},z_{j}$。然后使用双曲距离作为相似性度量，通过对比损失训练双曲分支：'
- en: '|  | $\displaystyle\mathcal{L}_{\mathrm{hyp}}=-\log\frac{\exp\left(-d_{\mathbb{D}}(z_{u},z_{v})/\tau\right)}{\exp\left(-d_{\mathbb{D}}(z_{u},z_{v})/\tau\right)+\sum_{j}\exp\left(-d_{\mathbb{D}}(z_{u},z_{j})/\tau\right)}$
    |  | (56) |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\mathrm{hyp}}=-\log\frac{\exp\left(-d_{\mathbb{D}}(z_{u},z_{v})/\tau\right)}{\exp\left(-d_{\mathbb{D}}(z_{u},z_{v})/\tau\right)+\sum_{j}\exp\left(-d_{\mathbb{D}}(z_{u},z_{j})/\tau\right)}$
    |  | (56) |'
- en: where $\tau$ is a temperature parameter. This loss encourages representations
    to form a scene-object hierarchy where scenes have the highest norm (i.e., are
    at the edge of the Poincaré ball $\mathbb{D}$) and objects have the smallest norm
    (i.e., are at the center of $\mathbb{D}$). The paper finds that their method achieves
    small gains over the original MoCo and MoCo augmented with bounding box information.
    They also examine the representations of out-of-context objects using their method,
    and find that they generally have higher distance to the scene images.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\tau$ 是一个温度参数。该损失函数鼓励表示形成场景-对象层次结构，其中场景具有最高的范数（即位于 Poincaré 球 $\mathbb{D}$
    的边缘），而对象具有最小的范数（即位于 $\mathbb{D}$ 的中心）。论文发现他们的方法在原始 MoCo 和增添了边界框信息的 MoCo 上取得了小幅提升。他们还使用该方法检查了上下文之外对象的表示，并发现它们通常与场景图像之间的距离较大。
- en: 'Yue et al ([2023](#bib.bib128)) propose a different method for hyperbolic contrastive
    learning that is based on SimCLR (Chen et al, [2020c](#bib.bib22)). Like Ge et al
    ([2022](#bib.bib45)), Yue et al ([2023](#bib.bib128)) replace the dot-product
    similarity of the contrastive loss with the hyperbolic distance:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: Yue 等人 ([2023](#bib.bib128)) 提出了另一种基于 SimCLR (Chen 等人，[2020c](#bib.bib22)) 的双曲对比学习方法。与
    Ge 等人 ([2022](#bib.bib45)) 类似，Yue 等人 ([2023](#bib.bib128)) 将对比损失的点积相似度替换为双曲距离：
- en: '|  | $\displaystyle\mathcal{L}_{hyp}^{self}=-\sum_{i\in I}\log\frac{\exp(-d_{\mathbb{D}}(z_{i},z_{j(i)})/\tau)}{\sum_{a\in
    A(i)}\exp(-d_{\mathbb{D}}(z_{i},z_{a})/\tau)}$ |  | (57) |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{hyp}^{self}=-\sum_{i\in I}\log\frac{\exp(-d_{\mathbb{D}}(z_{i},z_{j(i)})/\tau)}{\sum_{a\in
    A(i)}\exp(-d_{\mathbb{D}}(z_{i},z_{a})/\tau)}$ |  | (57) |'
- en: 'but unlike Ge et al ([2022](#bib.bib45)), they only have a hyperbolic branch
    and do not retain an Euclidean branch. Yue et al ([2023](#bib.bib128)) also propose
    to extend the supervised contrastive learning method SupCon (Khosla et al, [2020](#bib.bib67))
    in the same way. Yue et al ([2023](#bib.bib128)) also propose to train an adversarially
    robust contrastive learner that extends the Robust Contrastive Learning (RoCL)
    (Kim et al, [2020](#bib.bib69)) method to hyperbolic space by replacing the Euclidean
    contrastive losses in RoCL’s adversarial training loss with their hyperbolic contrastive
    loss:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 但不同于 Ge 等人 ([2022](#bib.bib45))，他们只有一个超曲分支，不保留欧几里得分支。Yue 等人 ([2023](#bib.bib128))
    也提出以相同方式扩展有监督对比学习方法 SupCon (Khosla 等人, [2020](#bib.bib67))。Yue 等人 ([2023](#bib.bib128))
    还提出训练一个对抗鲁棒的对比学习者，该学习者通过用超曲对比损失替代 RoCL 方法中的欧几里得对比损失，将鲁棒对比学习 (RoCL) (Kim 等人, [2020](#bib.bib69))
    方法扩展到超曲空间中：
- en: '|  | $\displaystyle\mathcal{L}_{hyp}^{self}(\tilde{x},\{\tilde{x}^{+},\tilde{x}^{adv},\{\tilde{x}^{-}\}\})+\lambda\mathcal{L}_{hyp}^{self}(\tilde{x}^{adv},\tilde{x}^{+},\{\tilde{x}^{-}\})$
    |  | (58) |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{hyp}^{self}(\tilde{x},\{\tilde{x}^{+},\tilde{x}^{adv},\{\tilde{x}^{-}\}\})+\lambda\mathcal{L}_{hyp}^{self}(\tilde{x}^{adv},\tilde{x}^{+},\{\tilde{x}^{-}\})$
    |  | (58) |'
- en: where $\tilde{x}$ is a given image, $\tilde{x}^{+}$ is a positive example, $\tilde{x}^{-}$
    is a negative example, and $\tilde{x}^{adv}$ is an adversarial example that is
    within $\delta$ of $\tilde{x}$. As in Ge et al ([2022](#bib.bib45)), Yan et al
    ([2021](#bib.bib123)) find that hyperbolic contrastive learning generally achieves
    small gains over its Euclidean counterparts.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\tilde{x}$ 是给定的图像，$\tilde{x}^{+}$ 是正例，$\tilde{x}^{-}$ 是负例，$\tilde{x}^{adv}$
    是在 $\delta$ 内的对抗示例。正如 Ge 等人 ([2022](#bib.bib45)) 所示，Yan 等人 ([2021](#bib.bib123))
    发现超曲对比学习通常比其欧几里得对手获得小幅提升。
- en: 5 Conclusions and future outlook
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论与未来展望
- en: This survey provides an overview of the current state of affairs in hyperbolic
    deep learning for computer vision. Based on the organization of supervised and
    unsupervised literature, we conclude the survey by discussing which types of problems
    currently benefit most from hyperbolic learning and discussing open problems for
    future research.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查概述了计算机视觉领域超曲深度学习的现状。根据有监督和无监督文献的组织，我们通过讨论当前哪些类型的问题最能从超曲学习中受益以及未来研究的开放问题来结束调查。
- en: 5.1 When is hyperbolic learning most effective?
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 何时超曲学习最有效？
- en: 'From current works, we identify four main axes of improvement that have come
    with the recent shift towards learning in hyperbolic space for computer vision:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 从当前的工作中，我们确定了随着向计算机视觉中的超曲空间学习的转变而带来的四个主要改进方向：
- en: $\bullet$
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Hierarchical learning. The inherent links between hierarchical data and hyperbolic
    embeddings are well known. It is therefore not all too surprising to see that
    a wide range of works have used hyperbolic learning to improve hierarchical objectives
    in computer vision. The ability to incorporate hierarchical knowledge, for example
    through hyperbolic embeddings or hierarchical hyperbolic logistic regression,
    has been utilized for several problems. Hierarchical learning in hyperbolic space
    can among others reduce error severity, resulting in smaller mistakes and more
    consistent retrieval. This is a key property for example in medical domains, where
    large mistakes need to be avoided at all costs.
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分层学习。分层数据与超曲嵌入之间的固有联系已广为人知。因此，看到大量工作利用超曲学习来改善计算机视觉中的分层目标也就不足为奇了。例如，通过超曲嵌入或分层超曲逻辑回归来融入分层知识的能力已被用于多个问题。超曲空间中的分层学习可以减少错误的严重性，从而减少错误和提高检索的一致性。这在医学领域尤其重要，在这些领域中需要避免大错误。
- en: Hierarchical learning has also shown to enable zero-shot generalization. By
    embedding class hierarchies in hyperbolic space and mapping examples of seen classes
    to their corresponding embedding, it becomes possible to generalize to examples
    of unseen classes. In general, hierarchical information between classes helps
    to structure the semantics of the task at hand, and embedding such knowledge in
    hyperbolic space is preferred over Euclidean space.
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分层学习也显示出能够实现零样本泛化。通过将类别层次嵌入超曲空间，并将已见类别的示例映射到相应的嵌入中，可以实现对未见类别示例的泛化。通常，类别之间的分层信息有助于构建任务的语义，将这种知识嵌入超曲空间比嵌入欧几里得空间更为优越。
- en: $\bullet$
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Few-sample learning. Few-shot learning is popular in hyperbolic deep learning
    for computer vision. Many works have shown that consistent improvements can be
    made by performing this task with hyperbolic embeddings and prototypes, both with
    and without hierarchical knowledge. In few-shot learning, samples are scarce when
    it comes to generalization, and working in hyperbolic space consistently improves
    accuracy. These results indicate that hyperbolic space can generalize from fewer
    examples, with potential in domains where examples are scarce. This is already
    visible in the unsupervised domain, where generative learning is better in hyperbolic
    space when working with constrained data sources.
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 少样本学习。少样本学习在计算机视觉中的双曲深度学习中很受欢迎。许多研究表明，通过使用双曲嵌入和原型，无论是否有层次知识，都可以显著提高效果。在少样本学习中，样本在泛化时很稀缺，而在双曲空间中进行学习可以持续提高准确性。这些结果表明，双曲空间可以从更少的示例中进行泛化，在示例稀缺的领域具有潜力。这一点在无监督领域已经显现出来，当处理受限的数据源时，生成学习在双曲空间中表现更好。
- en: $\bullet$
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Robust learning. Across several axes, hyperbolic learning has shown to be more
    robust. For example, hyperbolic embeddings improve out-of-distribution detection,
    provide a natural way to quantify uncertainty about samples, pinpoint unsupervised
    out-of-context samples, and can improve robustness to adversarial attacks. Robustness
    and uncertainty are key challenges in deep learning in general, hyperbolic deep
    learning can provide a natural solution to robustify networks.
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 鲁棒学习。在多个方面，双曲学习表现出更强的鲁棒性。例如，双曲嵌入改善了分布外检测，提供了一种自然的方式来量化样本的不确定性，识别无监督的背景外样本，并且可以提高对抗攻击的鲁棒性。鲁棒性和不确定性是深度学习中的关键挑战，双曲深度学习可以为网络的鲁棒性提供自然的解决方案。
- en: $\bullet$
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Low-dimensional learning. For a lot of applications, networks, and embedding
    spaces need to be constrained, for example when learning on embedded devices or
    when visualizing data. In the unsupervised domain, hyperbolic learning consistently
    improves over Euclidean learning when working with smaller embedding spaces. Similarly,
    the embedding space in supervised problems can be substantially reduced while
    maintaining downstream performance in hyperbolic space. As such, hyperbolic learning
    has the potential to enable learning in compressed and embedded domains.
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 低维学习。对于许多应用，网络和嵌入空间需要被限制，例如在嵌入式设备上进行学习或数据可视化时。在无监督领域中，双曲学习在处理较小的嵌入空间时，一致性地优于欧几里得学习。同样，在有监督问题中，嵌入空间可以显著缩减，同时在双曲空间中保持下游性能。因此，双曲学习有潜力在压缩和嵌入领域实现学习。
- en: 5.2 Open research questions
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 公开研究问题
- en: 'Hyperbolic learning has made an impact on computer vision with many promising
    avenues ahead. The field is however still in the early stages with many challenges
    and opportunities ahead. Three directions stand out:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 双曲学习在计算机视觉中产生了影响，并且有许多有前景的方向。然而，该领域仍处于早期阶段，面临许多挑战和机遇。有三个方向尤为突出：
- en: $\bullet$
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: 'Fully hyperbolic learning. Hyperbolic learning papers in computer vision commonly
    share one perspective: hyperbolic learning should be done in the embedding space.
    For the most part, the representation learning of earlier layers is done in Euclidean
    space, resulting in hybrid networks. Works from neuroscience indicate that for
    the earlier layers in neural networks, hyperbolic space can also play a prominent
    role (Chossat, [2020](#bib.bib26)). Recently, Zhang et al ([2023](#bib.bib130))
    have shown that spatial relations in the hippocampus are more hyperbolic than
    Euclidean.'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 完全双曲学习。计算机视觉中的双曲学习论文通常共享一个观点：双曲学习应该在嵌入空间中进行。在大多数情况下，早期层的表征学习是在欧几里得空间中完成的，导致了混合网络。神经科学的研究表明，对于神经网络中的早期层，双曲空间也可以发挥重要作用（Chossat,
    [2020](#bib.bib26)）。最近，Zhang 等人 ([2023](#bib.bib130)) 表明，海马体中的空间关系比欧几里得的更加双曲。
- en: Learning deep networks fully in hyperbolic space requires rethinking all layers,
    from convolutions to self-attention and normalization. At the time of writing
    the survey, two works have made steps in this direction. Bdeir et al ([2023](#bib.bib10))
    introduce a hyperbolic convolutional network in the Lorentz model of hyperbolic
    space. They outline how to perform convolutions, batch normalization, and residual
    connections. Simultaneously, van Spengler et al ([2023](#bib.bib107)) introduce
    Poincaré ResNet, with convolutions, residuals, batch normalization, and better
    network initialization in the Poincaré ball model. The works provide a foundation
    towards fully hyperbolic learning, but many open questions remain. Which model
    is most suitable for fully hyperbolic learning? Or do different layers work best
    in different models? And how can fully hyperbolic learning scale to ImageNet and
    beyond? Should each stage of the network have the same curvature? And how effective
    can hyperbolic networks become across all possible tasks compared to Euclidean
    networks? A lot more research is needed to answer these questions.
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在超曲率空间中完全学习深度网络需要重新思考所有层，从卷积到自注意力和归一化。在撰写调查时，已有两项工作在这方面取得了进展。Bdeir 等人 ([2023](#bib.bib10))
    在超曲率空间的洛伦兹模型中介绍了一个超曲率卷积网络。他们概述了如何执行卷积、批量归一化和残差连接。与此同时，van Spengler 等人 ([2023](#bib.bib107))
    在庞加莱球模型中介绍了 Poincaré ResNet，具有卷积、残差、批量归一化和更好的网络初始化。这些工作为完全超曲率学习奠定了基础，但仍然存在许多未解之谜。哪种模型最适合完全的超曲率学习？不同的层在不同的模型中效果最佳吗？完全超曲率学习如何扩展到
    ImageNet 及更广泛的应用？网络的每个阶段是否应具有相同的曲率？与欧几里得网络相比，超曲率网络在所有可能的任务中可以变得多么有效？这些问题仍需大量研究以得到答案。
- en: $\bullet$
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Computational challenges. Performing gradient-based learning in hyperbolic space
    changes how networks are optimized and how parameters behave. Compared to their
    Euclidean counterpart however, hyperbolic networks and embeddings can be numerically
    more unstable, with issues at the boundary of the ball, vanishing gradients, and
    more. Moreover, hyperbolic operations can be more involved and computationally
    heavy depending on the used model, leading to less efficient networks. Such computational
    challenges are relevant for all domains of hyperbolic learning and a broader topic
    that is receiving attention.
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 计算挑战。在超曲率空间中进行基于梯度的学习改变了网络的优化方式和参数的行为。然而，与欧几里得网络相比，超曲率网络和嵌入可能在数值上更不稳定，存在球体边界问题、梯度消失等问题。此外，根据使用的模型，超曲率操作可能更加复杂和计算密集，导致网络效率较低。这些计算挑战与超曲率学习的所有领域相关，并且是一个受到关注的更广泛话题。
- en: $\bullet$
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Open source community. Modern deep learning libraries are centered around Euclidean
    geometry. Any new researcher in hyperbolic learning, therefore, does not have
    the opportunity to quickly implement networks and layers to get an intuition into
    its workings. Moreover, any new advances have to be either implemented from scratch
    or imported from code repositories of other papers. What is missing is an open-source
    community and a shared repository that houses advances in hyperbolic learning
    for computer vision. Such a community and code base is vital to get further traction
    and attract a wide audience, including practitioners. Whether it be part of existing
    libraries or as a separate library, continued development of open-source hyperbolic
    learning code is key for the future of the field.
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 开源社区。现代深度学习库以欧几里得几何为中心。因此，任何新的超曲率学习研究人员都没有机会快速实现网络和层，以便直观地了解其工作原理。此外，任何新的进展都必须从头开始实现或从其他论文的代码库中导入。缺失的是一个开源社区和一个共享的代码库，专门收录计算机视觉中的超曲率学习进展。这样的社区和代码库对于进一步的推动和吸引广泛受众（包括从业者）至关重要。无论是作为现有库的一部分还是作为一个独立库，继续开发开源超曲率学习代码对于该领域的未来至关重要。
- en: $\bullet$
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Large and multimodal learning. In computer vision, and Artificial Intelligence
    in general, there is a strong trend towards learning at large scale and learning
    with multiple modalities, *e.g.,* image-text or video-audio models. It is therefore
    a natural desire for the field to arrive at hyperbolic foundation models. While
    early work has shown that large-scale and/or multimodal learning is viable with
    hyperbolic embeddings (Desai et al, [2023](#bib.bib32)), hyperbolic foundation
    models form a longer-term commitment as they require solutions to all open problems
    mentioned above, from stable, fully hyperbolic learning to continued open source
    development.
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大规模和多模态学习。在计算机视觉和人工智能领域，存在强烈的趋势，即大规模学习和多模态学习，*例如*，图像-文本或视频-音频模型。因此，领域中自然会希望出现双曲基础模型。尽管早期工作表明，大规模和/或多模态学习通过双曲嵌入是可行的
    (Desai 等, [2023](#bib.bib32))，但双曲基础模型形成了一个长期承诺，因为它们需要解决上述所有未解决的问题，从稳定的完全双曲学习到持续的开源开发。
- en: References
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Ahmad and Lecue (2022) Ahmad O, Lecue F (2022) Fisheyehdk: Hyperbolic deformable
    kernel learning for ultra-wide field-of-view image recognition. In: AAAI Conference
    on Artificial Intelligence'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ahmad 和 Lecue (2022) Ahmad O, Lecue F (2022) Fisheyehdk: 超广视场图像识别的双曲变形核学习。见：AAAI
    人工智能会议'
- en: 'Amin et al (2022) Amin F, Mondal A, Mathew J (2022) Deep semantic hashing with
    structure-semantic disagreement correction via hyperbolic metric learning. In:
    International Workshop on Multimedia Signal Processing'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amin 等 (2022) Amin F, Mondal A, Mathew J (2022) 通过双曲度量学习进行结构-语义不一致纠正的深度语义哈希。见：国际多媒体信号处理研讨会
- en: 'Anvekar and Bazazian (2023) Anvekar T, Bazazian D (2023) Gpr-net: Geometric
    prototypical network for point cloud few-shot learning. arXiv'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Anvekar 和 Bazazian (2023) Anvekar T, Bazazian D (2023) Gpr-net: 用于点云小样本学习的几何原型网络。arXiv'
- en: Araño et al (2021) Araño KA, Orsenigo C, Soto M, Vercellis C (2021) Multimodal
    sentiment and emotion recognition in hyperbolic space. Expert Systems with Applications
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Araño 等 (2021) Araño KA, Orsenigo C, Soto M, Vercellis C (2021) 双曲空间中的多模态情感与情绪识别。应用专家系统
- en: 'Arjovsky et al (2017) Arjovsky M, Chintala S, Bottou L (2017) Wasserstein generative
    adversarial networks. In: International Conference on Machine Learning'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arjovsky 等 (2017) Arjovsky M, Chintala S, Bottou L (2017) Wasserstein 生成对抗网络。见：国际机器学习会议
- en: 'Bachmann et al (2020) Bachmann G, Bécigneul G, Ganea O (2020) Constant curvature
    graph convolutional networks. In: International Conference on Machine Learning'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bachmann 等 (2020) Bachmann G, Bécigneul G, Ganea O (2020) 恒定曲率图卷积网络。见：国际机器学习会议
- en: Bakas et al (2017) Bakas S, Akbari H, Sotiras A, Bilello M, Rozycki M, Kirby
    JS, Freymann JB, Farahani K, Davatzikos C (2017) Advancing the cancer genome atlas
    glioma mri collections with expert segmentation labels and radiomic features.
    Scientific data
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bakas 等 (2017) Bakas S, Akbari H, Sotiras A, Bilello M, Rozycki M, Kirby JS,
    Freymann JB, Farahani K, Davatzikos C (2017) 通过专家分割标签和放射组学特征推动癌症基因组图谱的胶质瘤 MRI
    集合。科学数据
- en: Bakas et al (2018) Bakas S, Reyes M, Jakab A, Bauer S, Rempfler M, Crimi A,
    Shinohara RT, Berger C, Ha SM, Rozycki M, et al (2018) Identifying the best machine
    learning algorithms for brain tumor segmentation, progression assessment, and
    overall survival prediction in the brats challenge. arXiv
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bakas 等 (2018) Bakas S, Reyes M, Jakab A, Bauer S, Rempfler M, Crimi A, Shinohara
    RT, Berger C, Ha SM, Rozycki M, 等 (2018) 在 BRATS 挑战中识别最佳机器学习算法用于脑肿瘤分割、进展评估和整体生存预测。arXiv
- en: 'Balazevic et al (2019) Balazevic I, Allen C, Hospedales T (2019) Multi-relational
    poincaré graph embeddings. In: Advances in Neural Information Processing Systems'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Balazevic 等 (2019) Balazevic I, Allen C, Hospedales T (2019) 多关系庞加莱图嵌入。见：神经信息处理系统进展
- en: 'Bdeir et al (2023) Bdeir A, Schwethelm K, Landwehr N (2023) Hyperbolic geometry
    in computer vision: A novel framework for convolutional neural networks. arXiv'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bdeir 等 (2023) Bdeir A, Schwethelm K, Landwehr N (2023) 计算机视觉中的双曲几何：用于卷积神经网络的新框架。arXiv
- en: Bommasani et al (2021) Bommasani R, Hudson DA, Adeli E, Altman R, Arora S, von
    Arx S, Bernstein MS, Bohg J, Bosselut A, Brunskill E, et al (2021) On the opportunities
    and risks of foundation models. arXiv
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bommasani 等 (2021) Bommasani R, Hudson DA, Adeli E, Altman R, Arora S, von Arx
    S, Bernstein MS, Bohg J, Bosselut A, Brunskill E, 等 (2021) 关于基础模型的机会和风险。arXiv
- en: 'Bose et al (2020) Bose J, Smofsky A, Liao R, Panangaden P, Hamilton W (2020)
    Latent variable modelling with hyperbolic normalizing flows. In: International
    Conference on Machine Learning'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bose 等 (2020) Bose J, Smofsky A, Liao R, Panangaden P, Hamilton W (2020) 使用双曲归一化流的潜变量建模。见：国际机器学习会议
- en: Bridson and Haefliger (2013) Bridson MR, Haefliger A (2013) Metric spaces of
    non-positive curvature, vol 319\. Springer Science & Business Media
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bridson和Haefliger（2013）Bridson MR, Haefliger A（2013）《非正曲率度量空间，第319卷》。Springer
    Science & Business Media
- en: Cannon et al (1997) Cannon JW, Floyd WJ, Kenyon R, Parry WR, et al (1997) Hyperbolic
    geometry. Flavors of geometry 31(59-115):2
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cannon等人（1997）Cannon JW, Floyd WJ, Kenyon R, Parry WR, 等（1997）《双曲几何》。几何风味 31（59-115）：2
- en: 'Caron et al (2021) Caron M, Touvron H, Misra I, Jégou H, Mairal J, Bojanowski
    P, Joulin A (2021) Emerging properties in self-supervised vision transformers.
    In: International Conference on Computer Vision'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caron等人（2021）Caron M, Touvron H, Misra I, Jégou H, Mairal J, Bojanowski P, Joulin
    A（2021）《自监督视觉变换器中的新兴特性》。发表于：国际计算机视觉会议
- en: 'Chami et al (2019) Chami I, Ying Z, Ré C, Leskovec J (2019) Hyperbolic graph
    convolutional neural networks. In: Advances in Neural Information Processing Systems'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chami等人（2019）Chami I, Ying Z, Ré C, Leskovec J（2019）《双曲图卷积神经网络》。发表于：神经信息处理系统进展
- en: 'Chami et al (2020a) Chami I, Gu A, Chatziafratis V, Ré C (2020a) From trees
    to continuous embeddings and back: Hyperbolic hierarchical clustering. In: Advances
    in Neural Information Processing Systems'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chami等人（2020a）Chami I, Gu A, Chatziafratis V, Ré C（2020a）《从树到连续嵌入及其回归：双曲层次聚类》。发表于：神经信息处理系统进展
- en: Chami et al (2020b) Chami I, Wolf A, Juan DC, Sala F, Ravi S, Ré C (2020b) Low-dimensional
    hyperbolic knowledge graph embeddings. arXiv
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chami等人（2020b）Chami I, Wolf A, Juan DC, Sala F, Ravi S, Ré C（2020b）《低维双曲知识图谱嵌入》。arXiv
- en: Chen et al (2022) Chen B, Peng W, Cao X, Röning J (2022) Hyperbolic uncertainty
    aware semantic segmentation. Transactions on Intelligent Transportation Systems
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人（2022）Chen B, Peng W, Cao X, Röning J（2022）《双曲不确定性感知语义分割》。智能交通系统交易
- en: 'Chen et al (2020a) Chen G, Qiao L, Shi Y, Peng P, Li J, Huang T, Pu S, Tian
    Y (2020a) Learning open set network with discriminative reciprocal points. In:
    European Conference on Computer Vision'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人（2020a）Chen G, Qiao L, Shi Y, Peng P, Li J, Huang T, Pu S, Tian Y（2020a）《学习开放集网络与区分性倒数点》。发表于：欧洲计算机视觉会议
- en: 'Chen et al (2020b) Chen J, Qin J, Shen Y, Liu L, Zhu F, Shao L (2020b) Learning
    attentive and hierarchical representations for 3d shape recognition. In: European
    Conference on Computer Vision'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人（2020b）Chen J, Qin J, Shen Y, Liu L, Zhu F, Shao L（2020b）《学习注意力和层次表示以进行3D形状识别》。发表于：欧洲计算机视觉会议
- en: 'Chen et al (2020c) Chen T, Kornblith S, Norouzi M, Hinton G (2020c) A simple
    framework for contrastive learning of visual representations. In: International
    conference on machine learning'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人（2020c）Chen T, Kornblith S, Norouzi M, Hinton G（2020c）《用于视觉表示对比学习的简单框架》。发表于：机器学习国际会议
- en: Chen et al (2021) Chen W, Han X, Lin Y, Zhao H, Liu Z, Li P, Sun M, Zhou J (2021)
    Fully hyperbolic neural networks. arXiv
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人（2021）Chen W, Han X, Lin Y, Zhao H, Liu Z, Li P, Sun M, Zhou J（2021）《完全双曲神经网络》。arXiv
- en: 'Cho et al (2019) Cho H, DeMeo B, Peng J, Berger B (2019) Large-margin classification
    in hyperbolic space. In: International Conference on Artificial Intelligence and
    Statistics'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cho等人（2019）Cho H, DeMeo B, Peng J, Berger B（2019）《双曲空间中的大间隔分类》。发表于：人工智能与统计学国际会议
- en: Cho et al (2022) Cho S, Lee J, Park J, Kim D (2022) A rotated hyperbolic wrapped
    normal distribution for hierarchical representation learning. arXiv
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cho等人（2022）Cho S, Lee J, Park J, Kim D（2022）《用于层次表示学习的旋转双曲包裹正态分布》。arXiv
- en: Chossat (2020) Chossat P (2020) The hyperbolic model for edge and texture detection
    in the primary visual cortex. The Journal of Mathematical Neuroscience
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chossat（2020）Chossat P（2020）《用于初级视觉皮层边缘和纹理检测的双曲模型》。《数学神经科学杂志》
- en: Choudhary and Reddy (2022) Choudhary N, Reddy CK (2022) Towards scalable hyperbolic
    neural networks using taylor series approximations. arXiv
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Choudhary和Reddy（2022）Choudhary N, Reddy CK（2022）《使用泰勒级数近似的可扩展双曲神经网络》。arXiv
- en: Cui et al (2022) Cui Y, Yu Z, Peng W, Liu L (2022) Rethinking few-shot class-incremental
    learning with open-set hypothesis in hyperbolic geometry. arXiv
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cui等人（2022）Cui Y, Yu Z, Peng W, Liu L（2022）《重新思考具有开放集假设的少样本类增量学习在双曲几何中的应用》。arXiv
- en: 'Dai et al (2021) Dai J, Wu Y, Gao Z, Jia Y (2021) A hyperbolic-to-hyperbolic
    graph convolutional network. In: Computer Vision and Pattern Recognition'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dai等人（2021）Dai J, Wu Y, Gao Z, Jia Y（2021）《双曲到双曲图卷积网络》。发表于：计算机视觉与模式识别
- en: 'Dasgupta (2016) Dasgupta S (2016) A cost function for similarity-based hierarchical
    clustering. In: ACM symposium on Theory of Computing'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dasgupta（2016）Dasgupta S（2016）《基于相似性的层次聚类成本函数》。发表于：ACM计算理论研讨会
- en: 'Dengxiong and Kong (2023) Dengxiong X, Kong Y (2023) Ancestor search: Generalized
    open set recognition via hyperbolic side information learning. In: Winter Conference
    on Applications of Computer Vision'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dengxiong和Kong（2023）Dengxiong X, Kong Y（2023）**祖先搜索**：通过超曲率侧信息学习的广义开放集识别。发表于《冬季计算机视觉应用会议》
- en: Desai et al (2023) Desai K, Nickel M, Rajpurohit T, Johnson J, Vedantam R (2023)
    Hyperbolic image-text representations. arXiv
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Desai等（2023）Desai K, Nickel M, Rajpurohit T, Johnson J, Vedantam R（2023）**超曲率图像-文本表示**。arXiv
- en: 'Dhall et al (2020) Dhall A, Makarova A, Ganea O, Pavllo D, Greeff M, Krause
    A (2020) Hierarchical image classification using entailment cone embeddings. In:
    Computer Vision and Pattern Recognition Workshops'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dhall等（2020）Dhall A, Makarova A, Ganea O, Pavllo D, Greeff M, Krause A（2020）**利用蕴含锥嵌入的层次图像分类**。发表于《计算机视觉与模式识别研讨会》
- en: 'Dhingra et al (2018) Dhingra B, Shallue CJ, Norouzi M, Dai AM, Dahl GE (2018)
    Embedding text in hyperbolic spaces. In: Workshop on Graph-Based Methods for Natural
    Language Processing'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dhingra等（2018）Dhingra B, Shallue CJ, Norouzi M, Dai AM, Dahl GE（2018）**在超曲率空间中嵌入文本**。发表于《基于图的方法自然语言处理研讨会》
- en: Dinh et al (2016) Dinh L, Sohl-Dickstein J, Bengio S (2016) Density estimation
    using real nvp. arXiv
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dinh等（2016）Dinh L, Sohl-Dickstein J, Bengio S（2016）**利用真实NVP的密度估计**。arXiv
- en: 'Dosovitskiy et al (2021) Dosovitskiy A, Beyer L, Kolesnikov A, Weissenborn
    D, Zhai X, Unterthiner T, Dehghani M, Minderer M, Heigold G, Gelly S, et al (2021)
    An image is worth 16x16 words: Transformers for image recognition at scale. In:
    International Conference on Learning Representations'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dosovitskiy等（2021）Dosovitskiy A, Beyer L, Kolesnikov A, Weissenborn D, Zhai
    X, Unterthiner T, Dehghani M, Minderer M, Heigold G, Gelly S等（2021）**一张图像胜过16x16个词**：用于大规模图像识别的变换器。发表于《学习表征国际会议》
- en: 'Ermolov et al (2022) Ermolov A, Mirvakhabova L, Khrulkov V, Sebe N, Oseledets
    I (2022) Hyperbolic vision transformers: Combining improvements in metric learning.
    In: Computer Vision and Pattern Recognition'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ermolov等（2022）Ermolov A, Mirvakhabova L, Khrulkov V, Sebe N, Oseledets I（2022）**超曲率视觉变换器**：结合度量学习的改进。发表于《计算机视觉与模式识别》
- en: 'Fang et al (2021) Fang P, Harandi M, Petersson L (2021) Kernel methods in hyperbolic
    spaces. In: International Conference on Computer Vision'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fang等（2021）Fang P, Harandi M, Petersson L（2021）**超曲率空间中的核方法**。发表于《国际计算机视觉会议》
- en: 'Franco et al (2023) Franco L, Mandica P, Munjal B, Galasso F (2023) Hyperbolic
    self-paced learning for self-supervised skeleton-based action representations.
    In: International Conference on Learning Representations'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Franco等（2023）Franco L, Mandica P, Munjal B, Galasso F（2023）**超曲率自定步学习**用于自监督骨架基础的动作表示。发表于《学习表征国际会议》
- en: 'Ganea et al (2018a) Ganea O, Bécigneul G, Hofmann T (2018a) Hyperbolic entailment
    cones for learning hierarchical embeddings. In: International Conference on Machine
    Learning'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ganea等（2018a）Ganea O, Bécigneul G, Hofmann T（2018a）**用于学习层次嵌入的超曲率蕴含锥**。发表于《国际机器学习会议》
- en: Ganea et al (2018b) Ganea O, Bécigneul G, Hofmann T (2018b) Hyperbolic neural
    networks. Advances in Neural Information Processing Systems
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ganea等（2018b）Ganea O, Bécigneul G, Hofmann T（2018b）**超曲率神经网络**。发表于《神经信息处理系统进展》
- en: 'Gao et al (2021) Gao Z, Wu Y, Jia Y, Harandi M (2021) Curvature generation
    in curved spaces for few-shot learning. In: International Conference on Computer
    Vision'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao等（2021）Gao Z, Wu Y, Jia Y, Harandi M（2021）**在曲面空间中的曲率生成**用于少量样本学习。发表于《国际计算机视觉会议》
- en: 'Gao et al (2022) Gao Z, Wu Y, Jia Y, Harandi M (2022) Hyperbolic feature augmentation
    via distribution estimation and infinite sampling on manifolds. In: Advances in
    Neural Information Processing Systems'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao等（2022）Gao Z, Wu Y, Jia Y, Harandi M（2022）**通过分布估计和流形上的无限采样的超曲率特征增强**。发表于《神经信息处理系统进展》
- en: Gao et al (2023) Gao Z, Xu C, Li F, Jia Y, Harandi M, Wu Y (2023) Exploring
    data geometry for continual learning. arXiv
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao等（2023）Gao Z, Xu C, Li F, Jia Y, Harandi M, Wu Y（2023）**探索数据几何学**以实现持续学习。arXiv
- en: Ge et al (2022) Ge S, Mishra S, Kornblith S, Li CL, Jacobs D (2022) Hyperbolic
    contrastive learning for visual representations beyond objects. arXiv
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ge等（2022）Ge S, Mishra S, Kornblith S, Li CL, Jacobs D（2022）**超曲率对比学习**用于超越物体的视觉表示。arXiv
- en: 'Ghadimi Atigh et al (2021) Ghadimi Atigh M, Keller-Ressel M, Mettes P (2021)
    Hyperbolic busemann learning with ideal prototypes. In: Advances in Neural Information
    Processing Systems'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ghadimi Atigh等（2021）Ghadimi Atigh M, Keller-Ressel M, Mettes P（2021）**超曲率Busemann学习**与理想原型。发表于《神经信息处理系统进展》
- en: 'Ghadimi Atigh et al (2022) Ghadimi Atigh M, Schoep J, Acar E, van Noord N,
    Mettes P (2022) Hyperbolic image segmentation. In: Computer Vision and Pattern
    Recognition'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ghadimi Atigh等（2022）Ghadimi Atigh M, Schoep J, Acar E, van Noord N, Mettes P（2022）**超曲率图像分割**。发表于《计算机视觉与模式识别》
- en: Goodfellow et al (2020) Goodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley
    D, Ozair S, Courville A, Bengio Y (2020) Generative adversarial networks. Communications
    of the ACM
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等人 (2020) Goodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley
    D, Ozair S, Courville A, Bengio Y (2020) 生成对抗网络。ACM 通讯
- en: Gu et al (2018) Gu J, Wang Z, Kuen J, Ma L, Shahroudy A, Shuai B, Liu T, Wang
    X, Wang G, Cai J, et al (2018) Recent advances in convolutional neural networks.
    Pattern recognition
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu 等人 (2018) Gu J, Wang Z, Kuen J, Ma L, Shahroudy A, Shuai B, Liu T, Wang X,
    Wang G, Cai J 等 (2018) 卷积神经网络的最新进展。模式识别
- en: 'Gulcehre et al (2019) Gulcehre C, Denil M, Malinowski M, Razavi A, Pascanu
    R, Hermann KM, Battaglia P, Bapst V, Raposo D, Santoro A, et al (2019) Hyperbolic
    attention networks. In: International Conference on Learning Representations'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gulcehre 等人 (2019) Gulcehre C, Denil M, Malinowski M, Razavi A, Pascanu R,
    Hermann KM, Battaglia P, Bapst V, Raposo D, Santoro A 等 (2019) 双曲注意力网络。发表于: 国际学习表征会议'
- en: 'Gulrajani et al (2017) Gulrajani I, Ahmed F, Arjovsky M, Dumoulin V, Courville
    AC (2017) Improved training of wasserstein gans. In: Advances in Neural Information
    Processing Systems'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gulrajani 等人 (2017) Gulrajani I, Ahmed F, Arjovsky M, Dumoulin V, Courville
    AC (2017) 改进的 Wasserstein GAN 训练。发表于: 神经信息处理系统进展'
- en: Gulshad et al (2023) Gulshad S, Long T, van Noord N (2023) Hierarchical explanations
    for video action recognition. arXiv
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gulshad 等人 (2023) Gulshad S, Long T, van Noord N (2023) 视频动作识别的层次解释。arXiv
- en: Guo et al (2021) Guo H, Tang J, Zeng W, Zhao X, Liu L (2021) Multi-modal entity
    alignment in hyperbolic space. Neurocomputing
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等人 (2021) Guo H, Tang J, Zeng W, Zhao X, Liu L (2021) 双曲空间中的多模态实体对齐。神经计算
- en: 'Guo et al (2022) Guo Y, Wang X, Chen Y, Yu SX (2022) Clipped hyperbolic classifiers
    are super-hyperbolic classifiers. In: Computer Vision and Pattern Recognition'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guo 等人 (2022) Guo Y, Wang X, Chen Y, Yu SX (2022) 裁剪双曲分类器是超级双曲分类器。发表于: 计算机视觉与模式识别'
- en: 'Gupta et al (2019) Gupta A, Dollar P, Girshick R (2019) Lvis: A dataset for
    large vocabulary instance segmentation. In: Computer Vision and Pattern Recognition'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gupta 等人 (2019) Gupta A, Dollar P, Girshick R (2019) Lvis: 大词汇量实例分割数据集。发表于:
    计算机视觉与模式识别'
- en: 'Hamann (2018) Hamann M (2018) On the tree-likeness of hyperbolic spaces. In:
    Mathematical proceedings of the cambridge philosophical society, Cambridge University
    Press, vol 164, pp 345–361'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hamann (2018) Hamann M (2018) 关于双曲空间的树状特征。发表于: 剑桥哲学学会数学论文集, 剑桥大学出版社, 第164卷,
    页345–361'
- en: 'He et al (2020) He K, Fan H, Wu Y, Xie S, Girshick R (2020) Momentum contrast
    for unsupervised visual representation learning. In: Computer Vision and Pattern
    Recognition'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'He 等人 (2020) He K, Fan H, Wu Y, Xie S, Girshick R (2020) 用于无监督视觉表征学习的动量对比。发表于:
    计算机视觉与模式识别'
- en: 'Heusel et al (2017) Heusel M, Ramsauer H, Unterthiner T, Nessler B, Hochreiter
    S (2017) Gans trained by a two time-scale update rule converge to a local nash
    equilibrium. In: Advances in Neural Information Processing Systems'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Heusel 等人 (2017) Heusel M, Ramsauer H, Unterthiner T, Nessler B, Hochreiter
    S (2017) 通过双时间尺度更新规则训练的 GAN 收敛到局部纳什均衡。发表于: 神经信息处理系统进展'
- en: 'Higgins et al (2017) Higgins I, Matthey L, Pal A, Burgess C, Glorot X, Botvinick
    M, Mohamed S, Lerchner A (2017) beta-vae: Learning basic visual concepts with
    a constrained variational framework. In: International Conference on Learning
    Representations'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Higgins 等人 (2017) Higgins I, Matthey L, Pal A, Burgess C, Glorot X, Botvinick
    M, Mohamed S, Lerchner A (2017) beta-vae: 使用受限变分框架学习基本视觉概念。发表于: 国际学习表征会议'
- en: Hong et al (2022) Hong J, Fang P, Li W, Han J, Petersson L, Harandi M (2022)
    Curved geometric networks for visual anomaly recognition. arXiv
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong 等人 (2022) Hong J, Fang P, Li W, Han J, Petersson L, Harandi M (2022) 用于视觉异常识别的曲线几何网络。arXiv
- en: 'Hsu et al (2021) Hsu J, Gu J, Wu G, Chiu W, Yeung S (2021) Capturing implicit
    hierarchical structure in 3d biomedical images with self-supervised hyperbolic
    representations. In: Advances in Neural Information Processing Systems'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hsu 等人 (2021) Hsu J, Gu J, Wu G, Chiu W, Yeung S (2021) 通过自监督双曲表征捕捉 3D 生物医学图像中的隐含层次结构。发表于:
    神经信息处理系统进展'
- en: 'Iscen et al (2017) Iscen A, Tolias G, Avrithis Y, Furon T, Chum O (2017) Efficient
    diffusion on region manifolds: Recovering small objects with compact cnn representations.
    In: Computer Vision and Pattern Recognition'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Iscen 等人 (2017) Iscen A, Tolias G, Avrithis Y, Furon T, Chum O (2017) 区域流形上的高效扩散：用紧凑的
    CNN 表示恢复小物体。发表于: 计算机视觉与模式识别'
- en: 'Karras et al (2019) Karras T, Laine S, Aila T (2019) A style-based generator
    architecture for generative adversarial networks. In: Computer Vision and Pattern
    Recognition'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Karras 等人 (2019) Karras T, Laine S, Aila T (2019) 基于风格的生成对抗网络生成器架构。发表于: 计算机视觉与模式识别'
- en: 'Karras et al (2020) Karras T, Laine S, Aittala M, Hellsten J, Lehtinen J, Aila
    T (2020) Analyzing and improving the image quality of stylegan. In: Computer Vision
    and Pattern Recognition'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karras 等人 (2020) Karras T, Laine S, Aittala M, Hellsten J, Lehtinen J, Aila
    T (2020) 分析和改进 StyleGAN 的图像质量。收录于《计算机视觉与模式识别》
- en: 'Kasarla et al (2022) Kasarla T, Burghouts G, van Spengler M, van der Pol E,
    Cucchiara R, Mettes P (2022) Maximum class separation as inductive bias in one
    matrix. In: Advances in Neural Information Processing Systems'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kasarla 等人 (2022) Kasarla T, Burghouts G, van Spengler M, van der Pol E, Cucchiara
    R, Mettes P (2022) 作为归纳偏置的最大类别分离。在一个矩阵中。收录于《神经信息处理系统进展》
- en: 'Khan et al (2022) Khan S, Naseer M, Hayat M, Zamir SW, Khan FS, Shah M (2022)
    Transformers in vision: A survey. ACM Computing Surveys'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan 等人 (2022) Khan S, Naseer M, Hayat M, Zamir SW, Khan FS, Shah M (2022) 视觉中的
    Transformers：一项综述。ACM 计算调查
- en: 'Khosla et al (2020) Khosla P, Teterwak P, Wang C, Sarna A, Tian Y, Isola P,
    Maschinot A, Liu C, Krishnan D (2020) Supervised contrastive learning. In: Advances
    in Neural Information Processing Systems'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khosla 等人 (2020) Khosla P, Teterwak P, Wang C, Sarna A, Tian Y, Isola P, Maschinot
    A, Liu C, Krishnan D (2020) 监督对比学习。收录于《神经信息处理系统进展》
- en: 'Khrulkov et al (2020) Khrulkov V, Mirvakhabova L, Ustinova E, Oseledets I,
    Lempitsky V (2020) Hyperbolic image embeddings. In: Computer Vision and Pattern
    Recognition'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khrulkov 等人 (2020) Khrulkov V, Mirvakhabova L, Ustinova E, Oseledets I, Lempitsky
    V (2020) 双曲图像嵌入。收录于《计算机视觉与模式识别》
- en: 'Kim et al (2020) Kim M, Tack J, Hwang SJ (2020) Adversarial self-supervised
    contrastive learning. In: Advances in Neural Information Processing Systems'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 等人 (2020) Kim M, Tack J, Hwang SJ (2020) 对抗性自监督对比学习。收录于《神经信息处理系统进展》
- en: 'Kim et al (2022) Kim S, Jung B, Kwak S (2022) Hier: Metric learning beyond
    class labels via hierarchical regularization. arXiv'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kim 等人 (2022) Kim S, Jung B, Kwak S (2022) Hier: 通过层次正则化进行超越类别标签的度量学习。arXiv'
- en: Kingma and Welling (2013) Kingma DP, Welling M (2013) Auto-encoding variational
    bayes. arXiv
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma 和 Welling (2013) Kingma DP, Welling M (2013) 自编码变分贝叶斯。arXiv
- en: Klimovskaia et al (2020) Klimovskaia A, Lopez-Paz D, Bottou L, Nickel M (2020)
    Poincaré maps for analyzing complex hierarchies in single-cell data. Nature communications
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Klimovskaia 等人 (2020) Klimovskaia A, Lopez-Paz D, Bottou L, Nickel M (2020)
    用于分析单细胞数据复杂层次结构的庞加莱映射。自然通讯
- en: 'Law et al (2019) Law M, Liao R, Snell J, Zemel R (2019) Lorentzian distance
    learning for hyperbolic representations. In: International Conference on Machine
    Learning'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Law 等人 (2019) Law M, Liao R, Snell J, Zemel R (2019) 用于双曲表示的洛伦兹距离学习。收录于《国际机器学习会议》
- en: 'Lazcano et al (2021) Lazcano D, Franco NF, Creixell W (2021) Hgan: Hyperbolic
    generative adversarial network. IEEE Access'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lazcano 等人 (2021) Lazcano D, Franco NF, Creixell W (2021) Hgan: 双曲生成对抗网络。IEEE
    访问'
- en: LeCun et al (2015) LeCun Y, Bengio Y, Hinton G (2015) Deep learning. Nature
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun 等人 (2015) LeCun Y, Bengio Y, Hinton G (2015) 深度学习。自然
- en: Leimeister and Wilson (2018) Leimeister M, Wilson BJ (2018) Skip-gram word embeddings
    in hyperbolic space. arXiv
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Leimeister 和 Wilson (2018) Leimeister M, Wilson BJ (2018) 双曲空间中的 Skip-gram 词嵌入。arXiv
- en: 'Li et al (2022) Li L, Zhang Y, Wang S (2022) The euclidean space is evil: Hyperbolic
    attribute editing for few-shot image generation. arXiv'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 (2022) Li L, Zhang Y, Wang S (2022) 欧几里得空间是邪恶的：双曲属性编辑用于小样本图像生成。arXiv
- en: 'Li et al (2023) Li YL, Wu X, Liu X, Dou Y, Ji Y, Zhang J, Li Y, Tan J, Lu X,
    Lu C (2023) From isolated islands to pangea: Unifying semantic space for human
    action understanding. arXiv'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 (2023) Li YL, Wu X, Liu X, Dou Y, Ji Y, Zhang J, Li Y, Tan J, Lu X, Lu
    C (2023) 从孤立岛屿到泛大陆：统一的人类动作理解语义空间。arXiv
- en: Lin et al (2022) Lin F, Bai B, Bai K, Ren Y, Zhao P, Xu Z (2022) Contrastive
    multi-view hyperbolic hierarchical clustering. arXiv
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等人 (2022) Lin F, Bai B, Bai K, Ren Y, Zhao P, Xu Z (2022) 对比多视角双曲层次聚类。arXiv
- en: 'Liu et al (2019) Liu Q, Nickel M, Kiela D (2019) Hyperbolic graph neural networks.
    In: Advances in Neural Information Processing Systems'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2019) Liu Q, Nickel M, Kiela D (2019) 双曲图神经网络。收录于《神经信息处理系统进展》
- en: 'Liu et al (2020) Liu S, Chen J, Pan L, Ngo CW, Chua TS, Jiang YG (2020) Hyperbolic
    visual embedding learning for zero-shot recognition. In: Computer Vision and Pattern
    Recognition'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2020) Liu S, Chen J, Pan L, Ngo CW, Chua TS, Jiang YG (2020) 双曲视觉嵌入学习用于零样本识别。收录于《计算机视觉与模式识别》
- en: 'Long et al (2020) Long T, Mettes P, Shen HT, Snoek CGM (2020) Searching for
    actions on the hyperbole. In: Computer Vision and Pattern Recognition'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Long 等人 (2020) Long T, Mettes P, Shen HT, Snoek CGM (2020) 在双曲线上搜索动作。收录于《计算机视觉与模式识别》
- en: 'Lou et al (2020) Lou A, Katsman I, Jiang Q, Belongie S, Lim SN, De Sa C (2020)
    Differentiating through the fréchet mean. In: International Conference on Machine
    Learning'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lou 等 (2020) Lou A, Katsman I, Jiang Q, Belongie S, Lim SN, De Sa C (2020) 通过弗雷歇均值进行区分。见于：国际机器学习大会
- en: 'Ma et al (2022) Ma R, Fang P, Drummond T, Harandi M (2022) Adaptive poincaré
    point to set distance for few-shot classification. In: AAAI Conference on Artificial
    Intelligence'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma 等 (2022) Ma R, Fang P, Drummond T, Harandi M (2022) 自适应庞加莱点到集合距离用于少样本分类。见于：AAAI
    人工智能会议
- en: 'Mathieu et al (2019) Mathieu E, Le Lan C, Maddison CJ, Tomioka R, Teh YW (2019)
    Continuous hierarchical representations with poincaré variational auto-encoders.
    In: Advances in Neural Information Processing Systems, vol 32'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mathieu 等 (2019) Mathieu E, Le Lan C, Maddison CJ, Tomioka R, Teh YW (2019)
    使用庞加莱变分自编码器的连续层次表示。见于：神经信息处理系统进展，第32卷
- en: Menze et al (2014) Menze BH, Jakab A, Bauer S, Kalpathy-Cramer J, Farahani K,
    Kirby J, Burren Y, Porz N, Slotboom J, Wiest R, et al (2014) The multimodal brain
    tumor image segmentation benchmark (brats). IEEE Transactions on Medical Imaging
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Menze 等 (2014) Menze BH, Jakab A, Bauer S, Kalpathy-Cramer J, Farahani K, Kirby
    J, Burren Y, Porz N, Slotboom J, Wiest R, 等 (2014) 多模态脑肿瘤图像分割基准 (BRATS)。IEEE 医学影像学汇刊
- en: 'Mettes et al (2019) Mettes P, Van der Pol E, Snoek C (2019) Hyperspherical
    prototype networks. In: Advances in Neural Information Processing Systems'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mettes 等 (2019) Mettes P, Van der Pol E, Snoek C (2019) 双曲球面原型网络。见于：神经信息处理系统进展
- en: 'Mirvakhabova et al (2020) Mirvakhabova L, Frolov E, Khrulkov V, Oseledets I,
    Tuzhilin A (2020) Performance of hyperbolic geometry models on top-n recommendation
    tasks. In: ACM Conference on Recommender Systems'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mirvakhabova 等 (2020) Mirvakhabova L, Frolov E, Khrulkov V, Oseledets I, Tuzhilin
    A (2020) 双曲几何模型在 Top-N 推荐任务中的表现。见于：ACM 推荐系统会议
- en: Mirza and Osindero (2014) Mirza M, Osindero S (2014) Conditional generative
    adversarial nets. arXiv
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mirza 和 Osindero (2014) Mirza M, Osindero S (2014) 条件生成对抗网络。arXiv
- en: 'Monath et al (2019) Monath N, Zaheer M, Silva D, McCallum A, Ahmed A (2019)
    Gradient-based hierarchical clustering using continuous representations of trees
    in hyperbolic space. In: International Conference on Knowledge Discovery & Data
    Mining'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Monath 等 (2019) Monath N, Zaheer M, Silva D, McCallum A, Ahmed A (2019) 使用双曲空间中树的连续表示的梯度基础层次聚类。见于：国际知识发现与数据挖掘大会
- en: Montanaro et al (2022) Montanaro A, Valsesia D, Magli E (2022) Rethinking the
    compositionality of point clouds through regularization in the hyperbolic space.
    arXiv
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Montanaro 等 (2022) Montanaro A, Valsesia D, Magli E (2022) 通过双曲空间中的正则化重新思考点云的组合性。arXiv
- en: 'Nagano et al (2019) Nagano Y, Yamaguchi S, Fujita Y, Koyama M (2019) A wrapped
    normal distribution on hyperbolic space for gradient-based learning. In: International
    Conference on Machine Learning'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nagano 等 (2019) Nagano Y, Yamaguchi S, Fujita Y, Koyama M (2019) 用于梯度基础学习的双曲空间上的包裹正态分布。见于：国际机器学习大会
- en: 'Nickel and Kiela (2017) Nickel M, Kiela D (2017) Poincaré embeddings for learning
    hierarchical representations. In: Advances in Neural Information Processing Systems,
    vol 30'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nickel 和 Kiela (2017) Nickel M, Kiela D (2017) 学习层次表示的庞加莱嵌入。见于：神经信息处理系统进展，第30卷
- en: 'Nickel and Kiela (2018) Nickel M, Kiela D (2018) Learning continuous hierarchies
    in the lorentz model of hyperbolic geometry. In: International Conference on Machine
    Learning'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nickel 和 Kiela (2018) Nickel M, Kiela D (2018) 在洛伦兹模型的双曲几何中学习连续层次结构。见于：国际机器学习大会
- en: 'Noy and Hafner (1997) Noy NF, Hafner CD (1997) The state of the art in ontology
    design: A survey and comparative review. AI magazine'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Noy 和 Hafner (1997) Noy NF, Hafner CD (1997) 本体设计的现状：综述与比较评审。AI 杂志
- en: 'Peng et al (2021) Peng W, Varanka T, Mostafa A, Shi H, Zhao G (2021) Hyperbolic
    deep neural networks: A survey. IEEE Transactions on Pattern Analysis and Machine
    Intelligence'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng 等 (2021) Peng W, Varanka T, Mostafa A, Shi H, Zhao G (2021) 双曲深度神经网络：综述。IEEE
    模式分析与机器智能汇刊
- en: Qu and Zou (2022) Qu E, Zou D (2022) Autoencoding hyperbolic representation
    for adversarial generation. arXiv
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qu 和 Zou (2022) Qu E, Zou D (2022) 用于对抗生成的自编码双曲表示。arXiv
- en: 'Radford et al (2021) Radford A, Kim JW, Hallacy C, Ramesh A, Goh G, Agarwal
    S, Sastry G, Askell A, Mishkin P, Clark J, et al (2021) Learning transferable
    visual models from natural language supervision. In: International Conference
    on Machine Learning'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford 等 (2021) Radford A, Kim JW, Hallacy C, Ramesh A, Goh G, Agarwal S, Sastry
    G, Askell A, Mishkin P, Clark J, 等 (2021) 从自然语言监督中学习可转移的视觉模型。见于：国际机器学习大会
- en: Ratcliffe (1994) Ratcliffe JG (1994) Foundations of hyperbolic manifolds, vol
    149\. Springer
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ratcliffe (1994) Ratcliffe JG (1994) 双曲流形基础，第149卷。Springer
- en: 'Rezende et al (2014) Rezende DJ, Mohamed S, Wierstra D (2014) Stochastic backpropagation
    and approximate inference in deep generative models. In: International Conference
    on Machine Learning'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rezende等（2014）Rezende DJ, Mohamed S, Wierstra D（2014）《深度生成模型中的随机反向传播和近似推断》。发表于《国际机器学习会议》
- en: 'Richardson et al (2021) Richardson E, Alaluf Y, Patashnik O, Nitzan Y, Azar
    Y, Shapiro S, Cohen-Or D (2021) Encoding in style: a stylegan encoder for image-to-image
    translation. In: Computer Vision and Pattern Recognition'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Richardson等（2021）Richardson E, Alaluf Y, Patashnik O, Nitzan Y, Azar Y, Shapiro
    S, Cohen-Or D（2021）《风格编码：用于图像到图像转换的StyleGAN编码器》。发表于《计算机视觉与模式识别》
- en: 'Sala et al (2018) Sala F, De Sa C, Gu A, Ré C (2018) Representation tradeoffs
    for hyperbolic embeddings. In: International Conference on Machine Learning'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sala等（2018）Sala F, De Sa C, Gu A, Ré C（2018）《超曲面嵌入的表示权衡》。发表于《国际机器学习会议》
- en: 'Salimans et al (2016) Salimans T, Goodfellow I, Zaremba W, Cheung V, Radford
    A, Chen X (2016) Improved techniques for training gans. In: Advances in Neural
    Information Processing Systems'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salimans等（2016）Salimans T, Goodfellow I, Zaremba W, Cheung V, Radford A, Chen
    X（2016）《训练生成对抗网络的改进技术》。发表于《神经信息处理系统进展》
- en: 'Schuler (2005) Schuler KK (2005) VerbNet: A broad-coverage, comprehensive verb
    lexicon. University of Pennsylvania'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schuler（2005）Schuler KK（2005）《VerbNet：一个广覆盖的全面动词词典》。宾夕法尼亚大学
- en: 'Shimizu et al (2021) Shimizu R, Mukuta Y, Harada T (2021) Hyperbolic neural
    networks++. In: International Conference on Learning Representations'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shimizu等（2021）Shimizu R, Mukuta Y, Harada T（2021）《超曲面神经网络++》。发表于《学习表征国际会议》
- en: 'Snell et al (2017) Snell J, Swersky K, Zemel R (2017) Prototypical networks
    for few-shot learning. In: Advances in Neural Information Processing Systems'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Snell等（2017）Snell J, Swersky K, Zemel R（2017）《少样本学习的原型网络》。发表于《神经信息处理系统进展》
- en: van Spengler et al (2023) van Spengler M, Berkhout E, Mettes P (2023) Poincar$\backslash$’e
    resnet. arXiv
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: van Spengler等（2023）van Spengler M, Berkhout E, Mettes P（2023）《Poincar$\backslash$’e
    resnet》。arXiv
- en: 'Sun et al (2021) Sun P, Zhang R, Jiang Y, Kong T, Xu C, Zhan W, Tomizuka M,
    Li L, Yuan Z, Wang C, et al (2021) Sparse r-cnn: End-to-end object detection with
    learnable proposals. In: Computer Vision and Pattern Recognition'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun等（2021）Sun P, Zhang R, Jiang Y, Kong T, Xu C, Zhan W, Tomizuka M, Li L, Yuan
    Z, Wang C, 等（2021）《稀疏R-CNN：端到端可学习提议的目标检测》。发表于《计算机视觉与模式识别》
- en: 'Surís et al (2021) Surís D, Liu R, Vondrick C (2021) Learning the predictability
    of the future. In: Computer Vision and Pattern Recognition'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Surís等（2021）Surís D, Liu R, Vondrick C（2021）《未来的可预测性学习》。发表于《计算机视觉与模式识别》
- en: 'Tifrea et al (2019) Tifrea A, Bécigneul G, Ganea OE (2019) Poincar$\backslash$’e
    glove: Hyperbolicp word embeddings. In: International Conference on Learning Representations'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tifrea等（2019）Tifrea A, Bécigneul G, Ganea OE（2019）《Poincar$\backslash$’e glove：超曲面词嵌入》。发表于《学习表征国际会议》
- en: Tong et al (2022) Tong J, Yang F, Yang S, Dong E, Du S, Wang X, Yi X (2022)
    Hyperbolic cosine transformer for lidar 3d object detection. arXiv
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tong等（2022）Tong J, Yang F, Yang S, Dong E, Du S, Wang X, Yi X（2022）《用于激光雷达3D目标检测的超曲面余弦变换器》。arXiv
- en: 'Trpin and Boshkoska (2022) Trpin A, Boshkoska B (2022) Face recognition with
    a hyperbolic metric classification model. In: International Convention on Information,
    Communication and Electronic Technology'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trpin和Boshkoska（2022）Trpin A, Boshkoska B（2022）《基于超曲面度量分类模型的人脸识别》。发表于《信息、通信与电子技术国际大会》
- en: Ungar (2005) Ungar AA (2005) Gyrovector spaces and their differential geometry.
    Nonlinear Funct Anal Appl 10(5):791–834
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ungar（2005）Ungar AA（2005）《陀螺向量空间及其微分几何》。非线性函数分析应用 10(5):791–834
- en: Ungar (2008) Ungar AA (2008) A gyrovector space approach to hyperbolic geometry.
    Synthesis Lectures on Mathematics and Statistics 1(1):1–194
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ungar（2008）Ungar AA（2008）《一种陀螺向量空间方法来研究超曲面几何》。合成数学与统计讲座 1(1):1–194
- en: 'Ungar (2012) Ungar AA (2012) Beyond the Einstein addition law and its gyroscopic
    Thomas precession: The theory of gyrogroups and gyrovector spaces, vol 117\. Springer
    Science & Business Media'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ungar（2012）Ungar AA（2012）《超越爱因斯坦加法法则及其陀螺型托马斯进动：陀螺群和陀螺向量空间理论，第117卷》。Springer
    Science & Business Media
- en: 'Valada (2022) Valada A (2022) On hyperbolic embeddings in object detection.
    In: German Conference on Pattern Recognition'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Valada（2022）Valada A（2022）《对象检测中的超曲面嵌入》。发表于《德国模式识别会议》
- en: Wang and Wang (2018) Wang D, Wang Y (2018) An improved cost function for hierarchical
    cluster trees. arXiv
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang和Wang（2018）Wang D, Wang Y（2018）《层次聚类树的改进成本函数》。arXiv
- en: 'Wang et al (2021) Wang L, Hu F, Wu S, Wang L (2021) Fully hyperbolic graph
    convolution network for recommendation. In: Proceedings of the 30th ACM International
    Conference on Information & Knowledge Management'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2021) Wang L, Hu F, Wu S, Wang L (2021) 完全双曲图卷积网络用于推荐。发表于：第30届ACM国际信息与知识管理大会论文集
- en: 'Wang et al (2023) Wang S, Kang Q, She R, Wang W, Zhao K, Song Y, Tay WP (2023)
    Hypliloc: Towards effective lidar pose regression with hyperbolic fusion. arXiv'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等人 (2023) Wang S, Kang Q, She R, Wang W, Zhao K, Song Y, Tay WP (2023)
    Hypliloc: 向有效的激光雷达姿态回归迈进，使用双曲融合。arXiv'
- en: 'Weng et al (2021) Weng Z, Ogut MG, Limonchik S, Yeung S (2021) Unsupervised
    discovery of the long-tail in instance segmentation using hierarchical self-supervision.
    In: Computer Vision and Pattern Recognition, pp 2603–2612'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weng 等人 (2021) Weng Z, Ogut MG, Limonchik S, Yeung S (2021) 使用层次自监督无监督发现实例分割中的长尾。发表于：计算机视觉与模式识别会议，pp
    2603–2612
- en: 'Wu et al (2021) Wu Z, Jiang D, Hsieh CY, Chen G, Liao B, Cao D, Hou T (2021)
    Hyperbolic relational graph convolution networks plus: a simple but highly efficient
    qsar-modeling method. Briefings in Bioinformatics'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人 (2021) Wu Z, Jiang D, Hsieh CY, Chen G, Liao B, Cao D, Hou T (2021) 双曲关系图卷积网络加：一种简单而高效的
    QSAR 建模方法。生物信息学简报
- en: Xu et al (2022) Xu Y, Mu L, Ji Z, Liu X, Han J (2022) Meta hyperbolic networks
    for zero-shot learning. Neurocomputing
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人 (2022) Xu Y, Mu L, Ji Z, Liu X, Han J (2022) 用于零样本学习的元双曲网络。神经计算
- en: 'Yan et al (2021) Yan J, Luo L, Deng C, Huang H (2021) Unsupervised hyperbolic
    metric learning. In: Computer Vision and Pattern Recognition'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yan 等人 (2021) Yan J, Luo L, Deng C, Huang H (2021) 无监督双曲度量学习。发表于：计算机视觉与模式识别会议
- en: Yan et al (2023) Yan J, Luo L, Deng C, Huang H (2023) Adaptive hierarchical
    similarity metric learning with noisy labels. IEEE Transactions on Image Processing
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yan 等人 (2023) Yan J, Luo L, Deng C, Huang H (2023) 带噪声标签的自适应层次相似性度量学习。IEEE 图像处理学报
- en: 'Yang et al (2022) Yang M, Zhou M, Liu J, Lian D, King I (2022) Hrcf: Enhancing
    collaborative filtering via hyperbolic geometric regularization. In: Proceedings
    of the ACM Web Conference'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang 等人 (2022) Yang M, Zhou M, Liu J, Lian D, King I (2022) Hrcf: 通过双曲几何正则化增强协同过滤。发表于：ACM
    Web 会议论文集'
- en: Yu et al (2020) Yu K, Visweswaran S, Batmanghelich K (2020) Semi-supervised
    hierarchical drug embedding in hyperbolic space. Journal of chemical information
    and modeling
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等人 (2020) Yu K, Visweswaran S, Batmanghelich K (2020) 在双曲空间中的半监督层次药物嵌入。化学信息与建模学报
- en: 'Yu et al (2022) Yu Z, Nguyen T, Gal Y, Ju L, Chandra SS, Zhang L, Bonnington
    P, Mar V, Wang Z, Ge Z (2022) Skin lesion recognition with class-hierarchy regularized
    hyperbolic embeddings. In: International Conference on Medical Image Computing
    and Computer-Assisted Intervention'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等人 (2022) Yu Z, Nguyen T, Gal Y, Ju L, Chandra SS, Zhang L, Bonnington P,
    Mar V, Wang Z, Ge Z (2022) 使用类层次正则化的双曲嵌入进行皮肤病变识别。发表于：国际医学图像计算与计算机辅助干预会议
- en: Yue et al (2023) Yue Y, Lin F, Yamada KD, Zhang Z (2023) Hyperbolic contrastive
    learning. arXiv
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yue 等人 (2023) Yue Y, Lin F, Yamada KD, Zhang Z (2023) 双曲对比学习。arXiv
- en: 'Zhang et al (2022) Zhang B, Jiang H, Feng S, Li X, Ye Y, Ye R (2022) Hyperbolic
    knowledge transfer with class hierarchy for few-shot learning. In: International
    Joint Conference on Artificial Intelligence'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 (2022) Zhang B, Jiang H, Feng S, Li X, Ye Y, Ye R (2022) 带类层次的双曲知识转移用于少样本学习。发表于：国际人工智能联合会议
- en: Zhang et al (2023) Zhang H, Rich PD, Lee AK, Sharpee TO (2023) Hippocampal spatial
    representations exhibit a hyperbolic geometry that expands with experience. Nature
    Neuroscience
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 (2023) Zhang H, Rich PD, Lee AK, Sharpee TO (2023) 海马体空间表征展示了一种随经验扩展的双曲几何。自然神经科学
- en: 'Zhang et al (2021a) Zhang Y, Luo L, Xian W, Huang H (2021a) Learning better
    visual data similarities via new grouplet non-euclidean embedding. In: International
    Conference on Computer Vision'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 (2021a) Zhang Y, Luo L, Xian W, Huang H (2021a) 通过新的组非欧几里得嵌入学习更好的视觉数据相似性。发表于：国际计算机视觉会议
- en: Zhang et al (2021b) Zhang Y, Wang X, Shi C, Jiang X, Ye Y (2021b) Hyperbolic
    graph attention network. IEEE Transactions on Big Data
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 (2021b) Zhang Y, Wang X, Shi C, Jiang X, Ye Y (2021b) 双曲图注意网络。IEEE
    大数据学报
- en: 'Zhang et al (2021c) Zhang Y, Wang X, Shi C, Liu N, Song G (2021c) Lorentzian
    graph convolutional networks. In: Proceedings of the Web Conference'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 (2021c) Zhang Y, Wang X, Shi C, Liu N, Song G (2021c) 洛伦兹图卷积网络。发表于：网络会议论文集
- en: 'Zhu et al (2020) Zhu Y, Zhou D, Xiao J, Jiang X, Chen X, Liu Q (2020) Hypertext:
    Endowing fasttext with hyperbolic geometry. In: Empirical Methods in Natural Language
    Processing'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu 等人 (2020) Zhu Y, Zhou D, Xiao J, Jiang X, Chen X, Liu Q (2020) Hypertext:
    为 fasttext 提供双曲几何。发表于：自然语言处理经验方法会议'
