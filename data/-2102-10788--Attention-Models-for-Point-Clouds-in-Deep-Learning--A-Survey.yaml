- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 19:56:47'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:56:47
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2102.10788] Attention Models for Point Clouds in Deep Learning: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2102.10788] 深度学习中的点云注意力模型：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2102.10788](https://ar5iv.labs.arxiv.org/html/2102.10788)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2102.10788](https://ar5iv.labs.arxiv.org/html/2102.10788)
- en: 'Attention Models for Point Clouds in Deep Learning: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习中的点云注意力模型：综述
- en: Xu Wang¹    Yi Jin¹    Yigang Cen¹    Tao Wang¹&Yidong Li¹ ¹Beijing Jiaotong
    University
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Xu Wang¹    Yi Jin¹    Yigang Cen¹    Tao Wang¹&Yidong Li¹ ¹北京交通大学
- en: '{xu.wang, yjin, ygcen, twang, ydli}@bjtu.edu.cn'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '{xu.wang, yjin, ygcen, twang, ydli}@bjtu.edu.cn'
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Recently, the advancement of 3D point clouds in deep learning has attracted
    intensive research in different application domains such as computer vision and
    robotic tasks. However, creating feature representation of robust, discriminative
    from unordered and irregular point clouds is challenging. In this paper, our ultimate
    goal is to provide a comprehensive overview of the point clouds feature representation
    which uses attention models. More than 75+ key contributions in the recent three
    years are summarized in this survey, including the 3D objective detection, 3D
    semantic segmentation, 3D pose estimation, point clouds completion etc. We provide
    a detailed characterization (1) the role of attention mechanisms, (2) the usability
    of attention models into different tasks, (3) the development trend of key technology.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，3D点云在深度学习中的进展吸引了不同应用领域的广泛研究，如计算机视觉和机器人任务。然而，从无序和不规则的点云中创建强健且具有辨别力的特征表示具有挑战性。本文的*最终目标*是提供使用注意力模型的点云特征表示的全面概述。我们在本综述中总结了最近三年中超过75项关键贡献，包括3D目标检测、3D语义分割、3D姿态估计、点云补全等。我们提供了详细的描述：（1）注意力机制的作用，（2）注意力模型在不同任务中的可用性，（3）关键技术的发展趋势。
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Point clouds representation is an important data format that can preserve the
    original geometric information in 3D space without any discretization. Meanwhile,
    deep learning have widely and successfully applied to various tasks nowadays.
    Therefore, it is natural that more and more research currently aims at the adaption
    of deep learning to 3D point clouds, such as computer vision Wang et al. ([2019](#bib.bib50))
    and robotics Behl et al. ([2019](#bib.bib2)). However, unordered and irregular
    3D point clouds structure are still a significant challenge for deep learning.
    The traditional point cloud representation methods include BEV Yang et al. ([2018](#bib.bib62)),
    multi-view Yang and Wang ([2019](#bib.bib61)), and 3D voxels Maturana and Scherer
    ([2015](#bib.bib34)). The main problem of these methods is the fast growth of
    point sets size Hu et al. ([2020](#bib.bib12)) and geometric information loss
    Qin et al. ([2019](#bib.bib40)). To alleviate these problems, attention mechanism
    is introduced to make neural networks to focus on the important parts of input
    data, helping to simplified point clouds and capture sufficient feature representations
    Chaudhari et al. ([2019](#bib.bib4)). Thus, in this paper, we aim to provide a
    brief, yet comprehensive survey on attention models for point clouds in deep learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 点云表示是一种重要的数据格式，它能够在3D空间中保留原始的几何信息而无需任何离散化。同时，深度学习目前已被广泛且成功地应用于各种任务。因此，越来越多的研究现在着眼于将深度学习应用于3D点云，如计算机视觉
    Wang 等人 ([2019](#bib.bib50)) 和机器人技术 Behl 等人 ([2019](#bib.bib2))。然而，无序且不规则的3D点云结构仍然是深度学习面临的重大挑战。这些方法的主要问题包括点集规模的快速增长
    Hu 等人 ([2020](#bib.bib12)) 和几何信息的丢失 Qin 等人 ([2019](#bib.bib40))。为了解决这些问题，引入了注意力机制，使神经网络能够关注输入数据的重要部分，帮助简化点云并捕捉足够的特征表示
    Chaudhari 等人 ([2019](#bib.bib4))。因此，本文旨在提供关于深度学习中点云的注意力模型的简要但全面的综述。
- en: 'There have been a few domain-specific surveys published Nguyen et al. ([2018](#bib.bib36));
    Lee et al. ([2019a](#bib.bib15)); Chaudhari et al. ([2019](#bib.bib4)); Wu et
    al. ([2020](#bib.bib58)); Liu et al. ([2019a](#bib.bib23)). Compared with existing
    surveys, the contributions of our work can be summarized as:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 已经有一些特定领域的综述文章发布 Nguyen 等人 ([2018](#bib.bib36)); Lee 等人 ([2019a](#bib.bib15));
    Chaudhari 等人 ([2019](#bib.bib4)); Wu 等人 ([2020](#bib.bib58)); Liu 等人 ([2019a](#bib.bib23))。与现有综述相比，我们工作的贡献可以总结为：
- en: '1.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: To the best of our knowledge, this is the first survey fully focus on attention
    models for point clouds tasks in deep learning, including computer vision, robotics
    and miscellaneous applications.
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 据我们所知，这是首个完全关注点云任务的注意力模型的调查，包括计算机视觉、机器人技术和其他应用领域。
- en: '2.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: This paper comprehensively covers recent and advanced progresses of attention
    models for point clouds. Therefore, it allows readers to learn about the state-of-the-art
    attention mechanisms from different perspectives.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本文全面涵盖了点云注意力模型的最新进展。因此，它允许读者从不同的角度了解最先进的注意力机制。
- en: The structure of this paper is as follows. We start by introducing short overview
    of attention mechanisms in section 2\. Then we provide and discuss the attention
    mechanisms in different tasks in section3 to 5, respectively. In section 6, we
    present the development trend for future technology. Finally, we conclude the
    paper in section 7.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的结构如下。我们首先在第2节介绍注意力机制的简要概述。然后，我们分别在第3至第5节提供和讨论不同任务中的注意力机制。在第6节中，我们展示了未来技术的发展趋势。最后，我们在第7节总结了本文内容。
- en: 2 Overview
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 概述
- en: Human brain system can focus on just a salient regions with limited data, instead
    of an entire scene Marblestone et al. ([2016](#bib.bib33)). An attention-based
    feature extraction is used in the salient regions to acquire the high-level feature
    representation for improving brain efficiently learns. In spired by this prior
    knowledge, attention mechanism was first introduced in deep learning to help to
    researchers choose important data for their tasks Bahdanau et al. ([2015](#bib.bib1)).
    With the continuous research, attention mechanisms have achieved great success
    in Natural Language Processing Galassi et al. ([2020](#bib.bib10)), Computer Vision
    Wang and Tax ([2016](#bib.bib49)), and robotics Ferreira and Dias ([2014](#bib.bib8)).
    Next, we will describe two main attetion mechanism types used in citation papers.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 人脑系统可以仅关注显著区域，使用有限的数据，而不是整个场景（Marblestone et al. ([2016](#bib.bib33))）。在显著区域使用基于注意力的特征提取，以获得高层次的特征表示，从而提高大脑的学习效率。受到这一先验知识的启发，注意力机制首次被引入深度学习中，以帮助研究人员为他们的任务选择重要数据（Bahdanau
    et al. ([2015](#bib.bib1))）。随着持续的研究，注意力机制在自然语言处理（Galassi et al. ([2020](#bib.bib10))）、计算机视觉（Wang
    and Tax ([2016](#bib.bib49))）和机器人技术（Ferreira and Dias ([2014](#bib.bib8))）中取得了巨大的成功。接下来，我们将描述引用文献中使用的两种主要注意力机制类型。
- en: 2.1 Sequence
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 序列
- en: Self-attention means that learning relevant tokens in a single input sequence
    for every token in the same input sequence Chaudhari et al. ([2019](#bib.bib4)).
    Obviously self-attention is sometimes called inner-attention. Example of self-attention
    is Yang et al. ([2019](#bib.bib63)).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 自注意力（Self-attention）指的是在单个输入序列中为每个标记学习相关标记（Chaudhari et al. ([2019](#bib.bib4))）。显然，自注意力有时被称为内在注意力。自注意力的一个例子是Yang
    et al. ([2019](#bib.bib63))。
- en: Co-attention, on the other hand, means that multiple input sequences are processed
    simultaneously and jointly learn their attentive feature weights to capture interactions
    between these inputs Chaudhari et al. ([2019](#bib.bib4)). Example of co-attention
    is You et al. ([2018](#bib.bib66)).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 共注意力（Co-attention）指的是多个输入序列同时处理，并共同学习其注意力特征权重，以捕捉这些输入之间的交互作用（Chaudhari et al.
    ([2019](#bib.bib4))）。共注意力的一个例子是You et al. ([2018](#bib.bib66))。
- en: 2.2 Positions
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 位置
- en: Soft-attentionis a differentiable deterministic process so that it can be trained
    with a backpropagation algorithm Kingkan et al. ([2019](#bib.bib14)). The global-attention
    model is similar to the soft attention model Luong et al. ([2015](#bib.bib32)).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 软注意力（Soft-attention）是一个可微分的确定性过程，因此可以使用反向传播算法进行训练（Kingkan et al. ([2019](#bib.bib14))）。全局注意力模型类似于软注意力模型（Luong
    et al. ([2015](#bib.bib32))）。
- en: Hard-attention, on the other hand, is a non-differentiable stochastic process
    and relies on a sampling-based method for training Kingkan et al. ([2019](#bib.bib14)).
    local-attention model is an intermediate between soft-attention and hard-attention
    Luong et al. ([2015](#bib.bib32)).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 硬注意力（Hard-attention）是一个不可微分的随机过程，依赖于基于采样的方法进行训练（Kingkan et al. ([2019](#bib.bib14))）。局部注意力模型介于软注意力和硬注意力之间（Luong
    et al. ([2015](#bib.bib32))）。
- en: 3 3D Computer Vision Applications
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 3D计算机视觉应用
- en: In this section, we review existing attention models for computer vision. We
    group the applications to different subcategories, namely, 3D recognition and
    retrieval, 3D detection, 3D segmentation, 3D classification and 3D registration.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们回顾了现有的计算机视觉注意力模型。我们将应用程序分组为不同的子类别，即3D识别与检索、3D检测、3D分割、3D分类和3D注册。
- en: 3.1 3D Recognition and Retrieval
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 3D 识别与检索
- en: 3.1.1 3D Recognition
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 3D 识别
- en: 3D object recognition is one of the most fundamental and intriguing problems
    in computer vision, spanning broad applications from environment understanding
    to self-driving. Attention model is used to make the neural network focus on informative
    features to obtain a stronger representation. To gesture recognition, Kingkan
    et al. ([2019](#bib.bib14)) design an automatic feature extraction network by
    using soft-attention module. This work is based on the intuition that, only particular
    points of body movement in an input point clouds are required for the network
    to classify the gestures. Li et al. ([2019b](#bib.bib19)) propose a graph attention
    module to specify different weights for different nodes by calculating relational
    degree in the local feature space. In their model, attention module is applied
    four times in different layers to aggregate feature and dynamically update the
    state of node. Finally, they can obtain more plentiful node feature representation.
    Similarly, Xia et al. ([2020](#bib.bib59)) apply self-attention unit to better
    capture feature dependencies among long-range context. Sun et al. ([2020](#bib.bib45))
    introduce a dual attention module (point-wise and channel-wise) to weigh importance
    of points and features for enhancing the feature representation ability.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 3D 对象识别是计算机视觉中最基础且最引人入胜的问题之一，涉及从环境理解到自动驾驶等广泛应用。注意力模型用于使神经网络集中于信息丰富的特征，以获得更强的表示能力。针对手势识别，Kingkan
    等人 ([2019](#bib.bib14)) 设计了一个通过使用软注意力模块的自动特征提取网络。这项工作基于这样的直觉：输入点云中仅特定的身体运动点是网络分类手势所必需的。Li
    等人 ([2019b](#bib.bib19)) 提出了一个图注意力模块，通过在局部特征空间计算关系度，为不同节点指定不同的权重。在他们的模型中，注意力模块在不同层中应用了四次，以聚合特征并动态更新节点状态。最终，他们能够获得更丰富的节点特征表示。类似地，Xia
    等人 ([2020](#bib.bib59)) 应用自注意力单元来更好地捕捉长范围上下文中的特征依赖性。Sun 等人 ([2020](#bib.bib45))
    引入了一个双重注意力模块（点级和通道级），以权衡点和特征的重要性，从而增强特征表示能力。
- en: Similar to the human visual system, attention mechanism can be used to multimodal
    feature fusion. You et al. ([2018](#bib.bib66)) propose a point-view feature fusion
    method based on soft-attention mask. Lu et al. ([2020b](#bib.bib30)) use global
    channel attention and spatial attention VLAD Jégou et al. ([2010](#bib.bib13))
    to fuse the feature of point cloud and image. Zhao et al. ([2020a](#bib.bib73))
    present a MANet framework for high-precision 3D object recognition that is able
    to fuse point-view data. Luo et al. ([2020](#bib.bib31)) introduce an embedding
    attention point-slice fusion strategy for new shape representation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于人类视觉系统，注意力机制可以用于多模态特征融合。You 等人 ([2018](#bib.bib66)) 提出了基于软注意力掩码的点视图特征融合方法。Lu
    等人 ([2020b](#bib.bib30)) 使用全球通道注意力和空间注意力 VLAD Jégou 等人 ([2010](#bib.bib13)) 来融合点云和图像的特征。Zhao
    等人 ([2020a](#bib.bib73)) 提出了一个 MANet 框架用于高精度 3D 对象识别，该框架能够融合点视图数据。Luo 等人 ([2020](#bib.bib31))
    引入了一种嵌入注意力点切片融合策略用于新的形状表示。
- en: 3.1.2 3D Retrieval
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 3D 检索
- en: In order to manage large scale point cloud datasets, exploring effective 3D
    shape retrieval algorithms is necessary. Li et al. ([2020b](#bib.bib21)) propose
    a multi-part attention network for 3D model retrieval, and applies a novel self-attention
    module to explore the spatial relevance of local features. Zhang and Xiao ([2019](#bib.bib69))
    apply a Point Contextual Attention network to discriminate the local feature which
    positively contribute to the final global feature representations. Lei et al.
    ([2019](#bib.bib17)) report that view differences of feature have no direct impact
    on retrieval performance. Their Representative-View Selection algorithm only trend
    to choose views which can contribute to better performance. In other works, Liu
    et al. ([2019b](#bib.bib24)) develop a hierarchical self-attention to highlight
    informative elements in point, scale and region levels. Dovrat et al. ([2019](#bib.bib6))
    extend visual attention, focusing the subsequent task network on significant points.
    Experiments on various benchmark datasets show that these methods can effectively
    remove the redundancy and results in an enhanced feature representation.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了管理大规模点云数据集，探索有效的3D形状检索算法是必要的。Li等人（[2020b](#bib.bib21)）提出了一种多部分注意力网络用于3D模型检索，并应用了一种新型的自注意力模块来探索局部特征的空间相关性。Zhang和Xiao（[2019](#bib.bib69)）应用了一个点上下文注意力网络来区分对最终全局特征表示有正面贡献的局部特征。Lei等人（[2019](#bib.bib17)）报告了特征视图差异对检索性能没有直接影响。他们的代表性视图选择算法只倾向于选择能够提升性能的视图。在其他工作中，Liu等人（[2019b](#bib.bib24)）开发了一种分层自注意力机制，以突出点、尺度和区域级别的信息元素。Dovrat等人（[2019](#bib.bib6)）扩展了视觉注意力，将后续任务网络专注于重要点。各种基准数据集上的实验表明，这些方法能够有效去除冗余，增强特征表示。
- en: 3.2 3D Detection
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 3D检测
- en: 3D object detection is an important aspect in computer vision. However, point
    clouds are usually unordered, sparse and unevenly distributed, which heavily affects
    feature extraction and accurate object localization. Paigwar et al. ([2019](#bib.bib37))
    extend visual attention mechanism for multiple object detection. The attention
    module makes the network focus on smaller region containing the objects of interest.
    Wu and Ogai ([2020](#bib.bib56)) exploit self-attention mechanism to boost useful
    features and suppress useless features. Xie et al. ([2020](#bib.bib60)) design
    two attention modules and a feature fusion module for 3D object detection that
    are able to exploit contextual information at patch, object and global scene levels.
    Similarly, Liu et al. ([2020b](#bib.bib27)) propose a Triple Attention module
    that considering the channel-wise, point-wise and voxel-wise attention jointly.
    Li et al. ([2020a](#bib.bib20)) present an end-to-end geometric relation network
    architecture inspired by the self-attention mechanism. To solve boundary problem,
    Wang et al. ([2020c](#bib.bib53)) introduce an auxiliary corner attention module.
    Its key contribution is to enforce network focus on object boundaries.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 3D物体检测是计算机视觉中的一个重要方面。然而，点云通常是无序的、稀疏的且分布不均，这严重影响了特征提取和准确的物体定位。Paigwar等人（[2019](#bib.bib37)）扩展了视觉注意力机制用于多物体检测。注意力模块使网络专注于包含感兴趣物体的较小区域。Wu和Ogai（[2020](#bib.bib56)）利用自注意力机制来提升有用特征并抑制无用特征。Xie等人（[2020](#bib.bib60)）设计了两个注意力模块和一个特征融合模块用于3D物体检测，能够在补丁、物体和全局场景级别上利用上下文信息。类似地，Liu等人（[2020b](#bib.bib27)）提出了一种三重注意力模块，联合考虑了通道级、点级和体素级注意力。Li等人（[2020a](#bib.bib20)）提出了一种受自注意力机制启发的端到端几何关系网络架构。为了解决边界问题，Wang等人（[2020c](#bib.bib53)）引入了一个辅助角点注意力模块。其关键贡献在于强制网络关注物体边界。
- en: 3.3 3D Segmentation
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 3D分割
- en: 3D semantic instance segmentation is a popular topic in computer vision. However,
    there are still many challenges for 3D point clouds segmentation, such as large
    scene and heterogeneous anisotropic distribution. Qingyong et al. ([2019](#bib.bib41))
    combine Local Spatial Encoding and Attentive Pooling modules to automatically
    learn important local feature. Zhang et al. ([2020a](#bib.bib70)) propose an Attention
    Adversarial Network based on adversarial learning. In the learning phase, network
    can pay more attention to different regional informative features. Tu et al. ([2020](#bib.bib46))
    present an online attention-base spatial and temporal feature fusion method for
    high-precision and real-time semantic segmentation. 4D point clouds (3D point
    cloud videos) segmentation is a more challenging task, which needs to capture
    both spatial and temporal information. To solve above problems, Shi et al. ([2020](#bib.bib43))
    design a cross-frame global attention module. Instance segmentation aims to understand
    geometric information of point clouds on both semantic level and instance level.
    To instance segmentation, Liang et al. ([2019](#bib.bib22)) introduce a graph
    neural network based on attention mechanism which can aggregate geometric and
    embedding information from neighbours. Wen et al. ([2020a](#bib.bib54)) model
    the relationships between neighbor and central points by learnable attention mechanism.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 3D 语义实例分割是计算机视觉中的一个热门话题。然而，3D 点云分割仍然面临许多挑战，如大场景和异质各向异性分布。Qingyong 等人 ([2019](#bib.bib41))
    结合了局部空间编码和注意力池化模块，以自动学习重要的局部特征。Zhang 等人 ([2020a](#bib.bib70)) 提出了一个基于对抗学习的注意力对抗网络。在学习阶段，网络可以更关注不同区域的信息特征。Tu
    等人 ([2020](#bib.bib46)) 提出了一个在线注意力基础的空间和时间特征融合方法，用于高精度和实时语义分割。4D 点云（3D 点云视频）分割是一个更具挑战性的任务，需要同时捕捉空间和时间信息。为了解决上述问题，Shi
    等人 ([2020](#bib.bib43)) 设计了一个跨帧全局注意力模块。实例分割旨在理解点云在语义层次和实例层次的几何信息。对于实例分割，Liang
    等人 ([2019](#bib.bib22)) 引入了一种基于注意力机制的图神经网络，能够从邻居处聚合几何和嵌入信息。Wen 等人 ([2020a](#bib.bib54))
    通过可学习的注意力机制建模邻点和中心点之间的关系。
- en: 3.4 3D Classification
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 3D 分类
- en: 3D classification is a critical task in computer vision, which is widely utilized
    in autonomous vehicle and robotics. In recent years, weak representation ability
    of low-dimensional feature and noisy points are still challenging. Fuchs et al.
    ([2020](#bib.bib9)) introduce a robust SE(3)-Transformer, a variant of the self-attention
    module for data translation and rotation. Lee et al. ([2019b](#bib.bib16)) present
    an attention-base network, Set Transformer, to model interactions among elements
    in point clouds. Yang et al. ([2019](#bib.bib63)) propose to use attention layers
    to capture the relations between point. They also design a parameter-efficient
    Group Shuffle Attention to decrease voluminous computing consumption of Multi-Head
    Attention. Airborne Laser Scanning (ALS) classification is a critical application
    for point clouds. Shajahan et al. ([2019](#bib.bib42)) design a view-based approach
    for roof classification, based on adding a self-attention network. Bhattacharyya
    et al. ([2021](#bib.bib3)) propose an elevation-attention module, urging network
    take per-point elevation information into account for better ALS classification.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 3D 分类是计算机视觉中的一项关键任务，广泛应用于自动驾驶和机器人技术。近年来，低维特征的弱表示能力和噪声点仍然具有挑战性。Fuchs 等人 ([2020](#bib.bib9))
    引入了一种强健的 SE(3)-Transformer，这是一种自注意力模块的变体，用于数据的平移和旋转。Lee 等人 ([2019b](#bib.bib16))
    提出了一个基于注意力的网络，Set Transformer，用于建模点云中元素之间的交互。Yang 等人 ([2019](#bib.bib63)) 提出了使用注意力层来捕捉点之间的关系。他们还设计了一种参数高效的
    Group Shuffle Attention，以减少多头注意力的计算消耗。机载激光扫描 (ALS) 分类是点云的一项关键应用。Shajahan 等人 ([2019](#bib.bib42))
    设计了一种基于视图的方法用于屋顶分类，基于增加一个自注意力网络。Bhattacharyya 等人 ([2021](#bib.bib3)) 提出了一个升高注意力模块，促使网络考虑每个点的升高信息，以改善
    ALS 分类。
- en: 3.5 3D Registration
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 3D 配准
- en: Point clouds registration is a key problem for computer vision, which aims to
    estimate the optimal rigid transformation between two or more different point
    sets. However, point clouds have innumerable unique aspects that can increase
    the complexity of this problem, such as local sparsity and noisy points. Yew and
    Lee ([2018](#bib.bib65)) add an attention layer into their network architecture
    that better identify 3D local keypoints and descriptors for matching. Inspired
    by this work, Lu et al. ([2019](#bib.bib28)) develop a novel point weighting layer
    to learning the saliency of each point in an end-to-end framework. Wang and Solomon
    ([2019](#bib.bib48)) combine attention-base module and pointer generation layer
    to approximate combinatorial matching. Lu et al. ([2020a](#bib.bib29)) present
    an Attentive Point Aggregation module that can be used in keypoints generation
    by aggregating positions and features of neighbor points. Also, this module outputs
    an attentive feature map help to estimate saliency uncertainly of each keypoint.
    [Qiao et al.](#bib.bib39) use self-attention and cross attention to enhance structure
    information and corresponding information for feature aggregation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 点云配准是计算机视觉中的一个关键问题，其目标是估计两个或多个不同点集之间的最佳刚性变换。然而，点云具有无数独特的方面，这可能增加问题的复杂性，例如局部稀疏性和噪声点。叶和李
    ([2018](#bib.bib65)) 在他们的网络架构中添加了一个注意力层，以更好地识别 3D 局部关键点和描述符进行匹配。受到这项工作的启发，陆等人
    ([2019](#bib.bib28)) 开发了一种新颖的点加权层，以在端到端框架中学习每个点的显著性。王和所罗门 ([2019](#bib.bib48))
    结合了基于注意力的模块和指针生成层，以近似组合匹配。陆等人 ([2020a](#bib.bib29)) 提出了一个注意力点聚合模块，该模块通过聚合邻域点的位置和特征来生成关键点。此外，该模块输出一个注意力特征图，帮助估计每个关键点的显著性不确定性。
    [乔等人](#bib.bib39) 使用自注意力和交叉注意力来增强结构信息和对应信息，以进行特征聚合。
- en: 4 Robotic Applications
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 机器人应用
- en: In this section, we review a variety of attention mechanisms that can applied
    to robotic tasks. We group the applications as 3D completion,3D pose estimation
    and scene flow.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们回顾了各种可以应用于机器人任务的注意力机制。我们将应用分为 3D 完成、3D 姿态估计和场景流。
- en: 4.1 3D Completion
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 3D 完成
- en: Point cloud completion is a challenging problem in robotic and computer vision.
    Incomplete point cloud shapes cannot be directly used in practical application
    due to the limited view angles or occlusion. Zhang et al. ([2020c](#bib.bib72))
    use attention module to reconstruct and refine the input point clouds, the generated
    points are more uniformly distributed with fewer outliers and noises. Wen et al.
    ([2020b](#bib.bib55)) propose a Skip-Attention Network for point cloud completion.
    Their proposed model can extract geometric information from local regions of incomplete
    point clouds to encode complete shape representation at different resolutions.
    Han et al. ([2020](#bib.bib11)) design a Non-local Attention module that combines
    multi-resolution shape details and contributive local features for shape completion.
    Zhang et al. ([2020b](#bib.bib71)) add an Attention Unit in their multi-stage
    network. This unit allocates higher weights for the important points which provide
    more valuable information for point clouds reconstruction.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 点云完成是机器人和计算机视觉中的一个具有挑战性的问题。由于视角有限或遮挡，无法直接在实际应用中使用不完整的点云形状。张等人 ([2020c](#bib.bib72))
    使用注意力模块来重建和优化输入点云，生成的点分布更均匀，异常值和噪声更少。温等人 ([2020b](#bib.bib55)) 提出了一个用于点云完成的跳跃注意力网络。他们提出的模型可以从不完整点云的局部区域中提取几何信息，以在不同分辨率下编码完整的形状表示。韩等人
    ([2020](#bib.bib11)) 设计了一个非局部注意力模块，该模块结合了多分辨率形状细节和有贡献的局部特征进行形状完成。张等人 ([2020b](#bib.bib71))
    在他们的多阶段网络中增加了一个注意力单元。这个单元为重要点分配更高的权重，这些点提供了更多有价值的信息用于点云重建。
- en: 4.2 3D Pose Estimation
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 3D 姿态估计
- en: 3D pose estimation is widely applied in robotic tasks, such as manipulation,
    grasping and navigation. The key challenge is to estimate pose by extracting enough
    features of point clouds to find pose in any environment Yuan et al. ([2020](#bib.bib68)).
    Yang et al. ([2020](#bib.bib64)) present a 3D Spatial Attention Region Ensemble
    Network for real-time 3D hand pose estimation. With the help of spatial attention
    mechanism, they extract enough local structure features of hand joints. 6D pose
    estimation is another important branch of pose estimation, including 3D rotation
    and 3D translation. Song et al. ([2020](#bib.bib44)) propose a Point Attention
    module to extract powerful feature from point clouds, with geometric attention
    path and channel attention path. This module makes neural network focus on efficient
    geometric and channel information to create better feature representations. Du
    et al. ([2020](#bib.bib7)) introduce an attention predictor that effectively utilize
    multi-level geometric information and channel-wise relations to generate global
    descriptor. Unlike above single input approaches, multimodal inputs can provide
    additional feature information. Yuan and Veltkamp ([2020](#bib.bib67)) apply a
    graph attention network to effectively fuse the color and depth features. Similarly,
    Cheng et al. ([2019](#bib.bib5)) use attention mechanism to learn discriminative
    multimodal features from image and point clouds. The difference between two works
    mentioned above is that they use different network architectures.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 3D 姿态估计广泛应用于机器人任务中，如操控、抓取和导航。关键挑战是通过提取足够的点云特征来估计姿态，以在任何环境中找到姿态 Yuan 等人 ([2020](#bib.bib68))。Yang
    等人 ([2020](#bib.bib64)) 提出了一个用于实时 3D 手部姿态估计的 3D 空间注意力区域集成网络。在空间注意力机制的帮助下，他们提取了足够的手部关节局部结构特征。6D
    姿态估计是姿态估计的另一个重要分支，包括 3D 旋转和 3D 平移。Song 等人 ([2020](#bib.bib44)) 提出了一个点注意力模块，从点云中提取强大的特征，具有几何注意力路径和通道注意力路径。该模块使神经网络专注于有效的几何和通道信息，以创建更好的特征表示。Du
    等人 ([2020](#bib.bib7)) 引入了一种注意力预测器，能够有效利用多层次的几何信息和通道间关系来生成全局描述符。与上述单输入方法不同，多模态输入可以提供额外的特征信息。Yuan
    和 Veltkamp ([2020](#bib.bib67)) 应用图注意力网络有效地融合了颜色和深度特征。类似地，Cheng 等人 ([2019](#bib.bib5))
    使用注意力机制从图像和点云中学习区分性的多模态特征。上述两个工作的区别在于它们使用了不同的网络架构。
- en: 4.3 Scene Flow
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 场景流
- en: Scene flow is the 3D displacement vector between each surface point in two consecutive
    frames Wu et al. ([2019](#bib.bib57)). Estimating scene flow is an important fundamental
    basis for numerous higher-level challenges such as robotics. It is noteworthy
    that each point in the point clouds has only one direction flowing to the second
    frame, not all feature information has the same importance. Wang et al. ([2020a](#bib.bib51))
    propose a hierarchical attention learning network model for scene flow estimation.
    This model includes two different attention modules, first attentive embedding
    and second attentive embedding, which can better focus on matched regions and
    features to find the right flowing direction. Inspired by above work, Wang et
    al. ([2020b](#bib.bib52)) present an attention cost volume structure to associate
    two point clouds and extract the embedding motion information. Puy et al. ([2020](#bib.bib38))
    propose FloT attention module for scene flow estimation by optimal transport tools.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 场景流是两个连续帧中每个表面点的 3D 位移向量 Wu 等人 ([2019](#bib.bib57))。估计场景流是许多高级挑战的一个重要基础，如机器人技术。值得注意的是，点云中的每个点只有一个方向流向第二帧，并不是所有特征信息都具有相同的重要性。Wang
    等人 ([2020a](#bib.bib51)) 提出了一个用于场景流估计的层次注意力学习网络模型。该模型包括两个不同的注意力模块，第一个注意力嵌入和第二个注意力嵌入，可以更好地专注于匹配区域和特征，以找到正确的流动方向。受到上述工作的启发，Wang
    等人 ([2020b](#bib.bib52)) 提出了一个注意力代价体积结构，用于关联两个点云并提取嵌入运动信息。Puy 等人 ([2020](#bib.bib38))
    提出了 FloT 注意力模块，通过最优传输工具进行场景流估计。
- en: 5 Miscellaneous Applications
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 杂项应用
- en: In this section, we review the attention model unclassified in preceding two
    categories, namely, 3D upsampling and 3D normal estimation.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们回顾了前两类中未分类的注意力模型，即 3D 上采样和 3D 法线估计。
- en: 5.1 3D Upsampling
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 3D 上采样
- en: Point clouds provide a flexible and scalable geometric representation suitable
    for a variety of applications, but its unordered and irregular structure also
    needs to be noticed. To alleviate above challenge, upsampling is proposed to acquire
    dense and uniform point set from raw point clouds. Li et al. ([2019a](#bib.bib18))
    propose a point cloud upsampling network, namely PU-GAN, to upsample points over
    patches on object surfaces. PU-GAN uses adversarial network architecture to train
    a generator module, which can produce a rich and robust point distributions from
    the latent space. Avoiding the network tend to poor convergence, they introduce
    a self-attention unit to enhance the feature integration quality. Liu et al. ([2019b](#bib.bib24))
    present an unsupervised upsampling method , named L2G-AE, with deep recurrent
    neural network. They leverage hierarchical self-attention mechanism to help feature
    aggregation at three levels of point, scale and region. Conversely, Liu et al.
    ([2020a](#bib.bib26)) propose a self-supervised point cloud upsampling model,
    named SPU-Net, with graph convolution model. They combine the above two models
    to simultaneously capture context feature information inside and among local regions.
    Zhao et al. ([2020b](#bib.bib74)) develop a upsampling and completing network
    called PUI-Net. Noticeable, they apply channel attention mechanism to extract
    discriminative feature from point clouds.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 点云提供了一种灵活且可扩展的几何表示，适用于各种应用，但其无序和不规则的结构也需要注意。为了缓解上述挑战，提出了上采样方法，以从原始点云中获得密集而均匀的点集。Li
    et al. ([2019a](#bib.bib18)) 提出了一个点云上采样网络，即PU-GAN，用于在对象表面上采样点。PU-GAN使用对抗网络架构来训练生成器模块，从潜在空间中生成丰富且强健的点分布。为了避免网络趋向于较差的收敛性，他们引入了自注意力单元来增强特征集成质量。Liu
    et al. ([2019b](#bib.bib24)) 提出了一个无监督的上采样方法，名为L2G-AE，结合深度递归神经网络。他们利用层次自注意力机制，帮助在点、尺度和区域三个层次上进行特征聚合。相反，Liu
    et al. ([2020a](#bib.bib26)) 提出了一个自监督点云上采样模型，名为SPU-Net，结合图卷积模型。他们结合上述两种模型，同时捕捉局部区域内及区域之间的上下文特征信息。Zhao
    et al. ([2020b](#bib.bib74)) 开发了一个上采样和补全网络，称为PUI-Net。值得注意的是，他们应用了通道注意力机制，从点云中提取判别特征。
- en: 5.2 3D Normal Estimation
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 3D法线估计
- en: 3D normal estimation is a fundament task for many high-level applications, including
    3d reconstruction, tracking, and rendering Liu et al. ([2019c](#bib.bib25)). In
    previous research, traditional normal estimation method, such as Principal Components
    Analysis, requires manually tuning hyper-parameters. Recent methods based on deep
    learning mainly focus on high-quality 3D normal estimation without manually tuning
    parameters. Wang and Prisacariu ([2020](#bib.bib47)) propose a temperature adjusted
    multi-head self-attention module, namely TMHSA, which combined with deep neural
    network. The TMHSA softly fuses per-point weighted feature from different aspects
    and outputs high-quality feature representations. Matveev et al. ([2020](#bib.bib35))
    present an attention-based neural network model that can improve neighborhood
    selection of point clouds and effectively incorporate geometric relations between
    the points. The use of geometric attention module as a means of extracting global
    feature representation is motivated by the fact that different quantities are
    defined locally.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 3D法线估计是许多高级应用的基础任务，包括3D重建、跟踪和渲染Liu et al. ([2019c](#bib.bib25))。在以往的研究中，传统的法线估计方法，如主成分分析，需要手动调节超参数。基于深度学习的近期方法主要关注于高质量的3D法线估计，而无需手动调节参数。Wang和Prisacariu
    ([2020](#bib.bib47)) 提出了一个温度调整的多头自注意力模块，即TMHSA，它与深度神经网络结合。TMHSA软融合了来自不同方面的每点加权特征，并输出高质量的特征表示。Matveev
    et al. ([2020](#bib.bib35)) 提出了一个基于注意力的神经网络模型，可以改进点云的邻域选择，并有效地结合点之间的几何关系。使用几何注意力模块作为提取全局特征表示的一种手段，是由于不同的量在局部定义的事实。
- en: 6 Discussions
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 讨论
- en: In this section, we discuss additional issues and highlight important challenges
    in future investigation.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了额外的问题并强调了未来研究中的重要挑战。
- en: '1.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: New applications. With the rapid development of 3D sensors and point clouds
    technologies, new application domains are constantly and gradually emerging, including
    autonomous driving, virtual reality and smart wear. It would be necessary to explore
    other attention mechanisms suit for different applications. Indeed, attention
    mechanism can be used in many applications not limited to the aforementioned domains.
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 新应用。随着 3D 传感器和点云技术的快速发展，新的应用领域不断逐渐出现，包括自动驾驶、虚拟现实和智能穿戴。探索适合不同应用的其他注意力机制是必要的。实际上，注意力机制可以应用于许多应用场景，而不仅限于上述领域。
- en: '2.'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Powerful attention model. Over the past several years, a large number of different
    neural network architectures have been proposed, such as generative adversarial
    network, graph neural network and transformer. These architectures are important
    as they allow deep learning to handle many real-world cases. Moreover, with the
    rapid increase of network architecture complexity, it is difficult to extract
    enough feature representation without introducing more computational cost. Therefore,
    a light-weight attention model with powerful and meaningful feature representation
    for different network architecture would be an interesting direction for future
    investigation.
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 强大的注意力模型。在过去几年中，提出了大量不同的神经网络架构，例如生成对抗网络、图神经网络和变换器。这些架构非常重要，因为它们使深度学习能够处理许多现实世界的案例。此外，随着网络架构复杂性的快速增加，在不引入更多计算成本的情况下提取足够的特征表示变得困难。因此，具有强大且有意义特征表示的轻量级注意力模型对于不同网络架构将是一个有趣的未来研究方向。
- en: '3.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Multimodal feature fusion. Modern application domains, such as autonomous driving,
    are commonly equipped with multiple sensors e.g., RGB cameras, thermal, starlight,
    LiDAR and RADAR to provide a more comprehensive understanding of real-world environment.
    It is important to effectively capture all task-relevant information from multimodal
    data especially if there are complex structure involved. Therefore, including
    but not limited to aforementioned point-view feature fuse methods, an interesting
    direction for future study is looking at attention-based technologies that can
    be used to effective and simplified multimodal feature extract and fuse.
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多模态特征融合。现代应用领域，如自动驾驶，通常配备了多种传感器，例如 RGB 摄像头、热成像、星光、激光雷达和雷达，以提供对现实世界环境的更全面理解。有效捕捉所有与任务相关的多模态数据中的信息尤为重要，特别是当涉及复杂结构时。因此，除了前述的点云特征融合方法，一个有趣的未来研究方向是关注基于注意力的技术，这些技术可以有效且简化地提取和融合多模态特征。
- en: '4.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Energy-efficient balance. In recent years, capturing 3D point clouds is getting
    easier, so that the scale of point cloud datasets increases gradually. The majority
    of methods that calculate an attention-based work may have trouble in scaling
    effectively to larger point sets. Furthermore, an emerging trend of deep learning
    is applied to handheld devices. Power consumption, computational cost and memory
    footprint will be the most significant obstacle. Therefore, it would be useful
    to explore other ways of applying attention mechanism not simply to boost model
    accuracy but to balance the model energy-efficient.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 节能平衡。近年来，捕捉 3D 点云变得越来越容易，从而点云数据集的规模逐渐增加。大多数计算基于注意力的工作方法可能在有效扩展到更大的点集时遇到困难。此外，深度学习应用于手持设备是一个新兴趋势。功耗、计算成本和内存占用将是最重要的障碍。因此，探索应用注意力机制的其他方式，不仅仅是为了提高模型准确性，还要平衡模型的节能效果，将是有益的。
- en: 7 Conclusion
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: 'In this paper, we have provided a systematic review of state-of-the-art attention
    models for point clouds in deep learning. To the best of our knowledge, this is
    the first work of this kind. We group existing work to three intuitive taxonomies:
    computer vision, robotics and Miscellaneous applications. We also list several
    challenges and opportunities for future investigation in the field of 3D point
    clouds based on attention mechanism.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提供了对深度学习中点云的最先进注意力模型的系统评述。据我们所知，这是此类工作的首个成果。我们将现有工作分为三种直观的分类：计算机视觉、机器人技术和其他应用。我们还列出了一些基于注意力机制的
    3D 点云领域未来研究的挑战和机遇。
- en: References
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Bahdanau et al. [2015] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural
    machine translation by jointly learning to align and translate. In 3rd International
    Conference on Learning Representations, ICLR 2015, 2015.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bahdanau et al. [2015] 德米特里·巴赫达瑙，金贤俊，约书亚·本吉奥。通过联合学习对齐和翻译的神经机器翻译。发表于第 3 届国际学习表征会议，ICLR
    2015，2015 年。
- en: 'Behl et al. [2019] Aseem Behl, Despoina Paschalidou, Simon Donné, and Andreas
    Geiger. Pointflownet: Learning representations for rigid motion estimation from
    point clouds. In Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition, pages 7962–7971, 2019.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Behl et al. [2019] 阿西姆·贝尔，德斯波伊娜·帕斯卡利杜，西蒙·多内，安德烈亚斯·盖格尔。Pointflownet：从点云中学习刚体运动估计的表示。发表于
    IEEE 计算机视觉与模式识别会议论文集，第 7962–7971 页，2019 年。
- en: Bhattacharyya et al. [2021] Prarthana Bhattacharyya, Chengjie Huang, and Krzysztof
    Czarnecki. Self-attention based context-aware 3d object detection. arXiv preprint
    arXiv:2101.02672, 2021.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bhattacharyya et al. [2021] 普拉斯塔纳·巴塔查尔亚，成杰·黄，克日什托夫·察尔涅基。基于自注意力的上下文感知 3d 目标检测。arXiv
    预印本 arXiv:2101.02672，2021 年。
- en: Chaudhari et al. [2019] Sneha Chaudhari, Gungor Polatkan, Rohan Ramanath, and
    Varun Mithal. An attentive survey of attention models. arXiv preprint arXiv:1904.02874,
    2019.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chaudhari et al. [2019] 斯内哈·查乌达里，贡戈尔·波拉特坎，罗汉·拉马纳斯，瓦伦·米塔尔。关于注意力模型的关注性调查。arXiv
    预印本 arXiv:1904.02874，2019 年。
- en: Cheng et al. [2019] Yi Cheng, Hongyuan Zhu, Cihan Acar, Wei Jing, Yan Wu, Liyuan
    Li, Cheston Tan, and Joo-Hwee Lim. 6d pose estimation with correlation fusion.
    arXiv preprint arXiv:1909.12936, 2019.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng et al. [2019] 易·程，洪远·朱，席汉·阿卡尔，魏·井，燕·吴，李元·李，切斯顿·谭，林珠辉。基于相关性融合的 6d 姿态估计。arXiv
    预印本 arXiv:1909.12936，2019 年。
- en: Dovrat et al. [2019] Oren Dovrat, Itai Lang, and Shai Avidan. Learning to sample.
    CVPR, 2019.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dovrat et al. [2019] 奥伦·多夫拉特，伊泰·朗，沙伊·阿维丹。学习采样。CVPR，2019 年。
- en: 'Du et al. [2020] Juan Du, Rui Wang, and Daniel Cremers. Dh3d: Deep hierarchical
    3d descriptors for robust large-scale 6dof relocalization. In European Conference
    on Computer Vision, pages 744–762. Springer, 2020.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du et al. [2020] 胡安·杜，瑞·王，丹尼尔·克雷默斯。Dh3d：用于鲁棒大规模 6dof 重新定位的深度层次 3d 描述符。发表于欧洲计算机视觉会议论文集，第
    744–762 页。施普林格，2020 年。
- en: Ferreira and Dias [2014] J. F. Ferreira and J. Dias. Attentional mechanisms
    for socially interactive robots–a survey. IEEE Transactions on Autonomous Mental
    Development, 6(2):110–125, 2014.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ferreira and Dias [2014] J. F. 费雷拉，J. 迪亚斯。社会互动机器人中的注意机制——综述。IEEE 自主心理发展杂志，6(2)：110–125，2014
    年。
- en: 'Fuchs et al. [2020] B. Fabian Fuchs, E. Daniel Worrall, Volker Fischer, and
    Max Welling. Se(3)-transformers: 3d roto-translation equivariant attention networks.
    NeurIPS, 2020.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fuchs et al. [2020] B. 法比安·福克斯，E. 丹尼尔·沃勒尔，福尔克·费舍尔，马克斯·威灵。Se(3)-变换器：3d 旋转-平移等变注意力网络。NeurIPS，2020
    年。
- en: Galassi et al. [2020] A. Galassi, M. Lippi, and P. Torroni. Attention in natural
    language processing. IEEE Transactions on Neural Networks and Learning Systems,
    pages 1–18, 2020.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Galassi et al. [2020] A. 加拉西，M. 利皮，P. 托罗尼。自然语言处理中的注意力。IEEE 神经网络与学习系统汇刊，第 1–18
    页，2020 年。
- en: Han et al. [2020] Zhizhong Han, Baorui Ma, Yu-Shen Liu, and Matthias Zwicker.
    Reconstructing 3d shapes from multiple sketches using direct shape optimization.
    IEEE Transactions on Image Processing, 29:8721–8734, 2020.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han et al. [2020] 志中·韩，宝瑞·马，玉申·刘，马蒂亚斯·兹维克。通过直接形状优化从多个草图重建 3d 形状。IEEE 图像处理汇刊，29：8721–8734，2020
    年。
- en: 'Hu et al. [2020] Qingyong Hu, Bo Yang, Linhai Xie, Stefano Rosa, Yulan Guo,
    Zhihua Wang, Niki Trigoni, and Andrew Markham. Randla-net: Efficient semantic
    segmentation of large-scale point clouds. In Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pages 11108–11117, 2020.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. [2020] 青永·胡，博·杨，林海·谢，斯特凡诺·罗莎，玉兰·郭，智华·王，尼基·特里戈尼，安德鲁·马克汉姆。Randla-net：大规模点云的高效语义分割。发表于
    IEEE/CVF 计算机视觉与模式识别会议论文集，第 11108–11117 页，2020 年。
- en: Jégou et al. [2010] Hervé Jégou, Matthijs Douze, Cordelia Schmid, and Patrick
    Pérez. Aggregating local descriptors into a compact image representation. In 2010
    IEEE computer society conference on computer vision and pattern recognition, pages
    3304–3311\. IEEE, 2010.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jégou et al. [2010] 埃尔维·热戈，马蒂耶斯·杜兹，科迪利亚·施密德，帕特里克·佩雷斯。将局部描述符聚合成紧凑的图像表示。发表于 2010
    年 IEEE 计算机学会计算机视觉与模式识别会议论文集，第 3304–3311 页。IEEE，2010 年。
- en: Kingkan et al. [2019] Cherdsak Kingkan, Joshua Owoyemi, and Koichi Hashimoto.
    Point attention network for gesture recognition using point cloud data. In 29th
    British Machine Vision Conference, BMVC 2018, 2019.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingkan et al. [2019] 切尔萨克·金坎，乔舒亚·欧沃耶米，桥本光一。用于手势识别的点注意力网络，使用点云数据。发表于第 29 届英国机器视觉会议，BMVC
    2018，2019 年。
- en: 'Lee et al. [2019a] John Boaz Lee, Ryan A Rossi, Sungchul Kim, Nesreen K Ahmed,
    and Eunyee Koh. Attention models in graphs: A survey. ACM Transactions on Knowledge
    Discovery from Data (TKDD), 13(6):1–25, 2019.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee et al. [2019a] 约翰·博阿兹·李、瑞安·A·罗西、金成哲、内斯琳·K·艾哈迈德和高恩熙。图中的注意力模型：综述。《ACM数据知识发现交易》（TKDD），13(6):1–25，2019年。
- en: 'Lee et al. [2019b] Juho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin
    Choi, and Yee Whye Teh. Set transformer: A framework for attention-based permutation-invariant
    neural networks. In International Conference on Machine Learning, pages 3744–3753\.
    PMLR, 2019.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee et al. [2019b] 李洙浩、李允浩、金正泰、亚当·科西奥雷克、崔胜真和叶惠哲。集合变换器：一种基于注意力的排列不变神经网络框架。载于国际机器学习会议，页3744–3753。PMLR，2019年。
- en: Lei et al. [2019] Yinjie Lei, Ziqin Zhou, Pingping Zhang, Yulan Guo, Zijun Ma,
    and Lingqiao Liu. Deep point-to-subspace metric learning for sketch-based 3d shape
    retrieval. Pattern Recognition, 96:106981, 2019.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lei et al. [2019] 李银杰、周自钦、张平平、郭玉兰、马子俊和刘凌乔。用于草图基础的 3D 形状检索的深度点到子空间度量学习。《模式识别》，96:106981，2019年。
- en: 'Li et al. [2019a] Ruihui Li, Xianzhi Li, Chi-Wing Fu, Daniel Cohen-Or, and
    Pheng-Ann Heng. Pu-gan: a point cloud upsampling adversarial network. In Proceedings
    of the IEEE International Conference on Computer Vision, pages 7203–7212, 2019.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2019a] 李瑞辉、李显智、傅志伟、丹尼尔·科恩-奥尔和冯安恒。Pu-gan：点云上采样对抗网络。载于IEEE国际计算机视觉会议论文集，页7203–7212，2019年。
- en: Li et al. [2019b] Zongmin Li, Jun Zhang, Guanlin Li, Yujie Liu, and Siyuan Li.
    Graph attention neural networks for point cloud recognition. In 2019 IEEE International
    Conference on Multimedia and Expo (ICME), pages 387–392\. IEEE, 2019.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2019b] 李宗敏、张军、李冠林、刘宇杰和李思远。用于点云识别的图注意力神经网络。载于2019年IEEE国际多媒体与博览会（ICME），页387–392。IEEE，2019年。
- en: 'Li et al. [2020a] Ying Li, Lingfei Ma, Weikai Tan, Chen Sun, Dongpu Cao, and
    Jonathan Li. Grnet: Geometric relation network for 3d object detection from point
    clouds. ISPRS Journal of Photogrammetry and Remote Sensing, 165:43–53, 2020.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2020a] 李颖、马凌飞、谭伟凯、陈孙、曹东浦和李乔纳森。Grnet：用于从点云中检测3D物体的几何关系网络。《ISPRS摄影测量与遥感杂志》，165:43–53，2020年。
- en: 'Li et al. [2020b] Zirui Li, Junyu Xu, Yue Zhao, Wenhui Li, and Weizhi Nie.
    Mpan: Multi-part attention network for point cloud based 3d shape retrieval. IEEE
    Access, 8:157322–157332, 2020.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2020b] 李自瑞、徐俊宇、赵悦、李文辉和聂维志。Mpan：用于基于点云的3D形状检索的多部分注意力网络。《IEEE访问》，8:157322–157332，2020年。
- en: 'Liang et al. [2019] Zhidong Liang, Ming Yang, and Chunxiang Wang. 3d graph
    embedding learning with a structure-aware loss function for point cloud semantic
    instance segmentation. arXiv: Computer Vision and Pattern Recognition, 2019.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang et al. [2019] 梁志东、杨铭和王春祥。具有结构感知损失函数的3D图嵌入学习，用于点云语义实例分割。arXiv：计算机视觉与模式识别，2019年。
- en: 'Liu et al. [2019a] Weiping Liu, Jia Sun, Wanyi Li, Ting Hu, and Peng Wang.
    Deep learning on point clouds and its application: A survey. Sensors, 19(19):4188,
    2019.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. [2019a] 刘伟平、孙佳、李万怡、胡婷和王鹏。点云上的深度学习及其应用：综述。《传感器》，19(19):4188，2019年。
- en: 'Liu et al. [2019b] Xinhai Liu, Zhizhong Han, Xin Wen, Yu-Shen Liu, and Matthias
    Zwicker. L2g auto-encoder: Understanding point clouds by local-to-global reconstruction
    with hierarchical self-attention. In Proceedings of the 27th ACM International
    Conference on Multimedia, pages 989–997, 2019.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. [2019b] 刘新海、韩志忠、温鑫、刘宇申和马蒂亚斯·茨维克。L2g 自编码器：通过具有层次自注意力的局部到全局重建来理解点云。载于第27届ACM国际多媒体会议论文集，页989–997，2019年。
- en: 'Liu et al. [2019c] Yongcheng Liu, Bin Fan, Gaofeng Meng, Jiwen Lu, Shiming
    Xiang, and Chunhong Pan. Densepoint: Learning densely contextual representation
    for efficient point cloud processing. In Proceedings of the IEEE International
    Conference on Computer Vision, pages 5239–5248, 2019.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. [2019c] 刘永成、范彬、孟高峰、陆纪文、项世铭和潘春红。Densepoint：学习密集上下文表示以提高点云处理效率。载于IEEE国际计算机视觉会议论文集，页5239–5248，2019年。
- en: 'Liu et al. [2020a] Xinhai Liu, Xinchen Liu, Zhizhong Han, and Yu-Shen Liu.
    Spu-net: Self-supervised point cloud upsampling by coarse-to-fine reconstruction
    with self-projection optimization. arXiv preprint arXiv:2012.04439, 2020.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. [2020a] 刘新海、刘新臣、韩志忠和刘宇申。Spu-net：通过粗到细的重建和自投影优化进行自监督点云上采样。arXiv预印本arXiv:2012.04439，2020年。
- en: 'Liu et al. [2020b] Zhe Liu, Xin Zhao, Tengteng Huang, hu ruolan, Yu Zhou, and
    Xiang Bai. Tanet: Robust 3d object detection from point clouds with triple attention.
    AAAI, pages 11677–11684, 2020.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. [2020b] 刘哲、赵鑫、黄腾腾、胡若兰、周宇和白翔。Tanet：通过三重注意力从点云中进行鲁棒的3D物体检测。AAAI，页11677–11684，2020年。
- en: 'Lu et al. [2019] Weixin Lu, Guowei Wan, Yao Zhou, Xiangyu Fu, Pengfei Yuan,
    and Shiyu Song. Deepvcp: An end-to-end deep neural network for point cloud registration.
    In Proceedings of the IEEE International Conference on Computer Vision, pages
    12–21, 2019.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lu et al. [2019] Weixin Lu, Guowei Wan, Yao Zhou, Xiangyu Fu, Pengfei Yuan,
    和 Shiyu Song. Deepvcp: 一种端到端的深度神经网络用于点云配准。发表于 IEEE 国际计算机视觉会议论文集, 页码 12–21, 2019。'
- en: 'Lu et al. [2020a] Fan Lu, Guang Chen, Yinlong Liu, Zhongnan Qu, and Alois Knoll.
    Rskdd-net: Random sample-based keypoint detector and descriptor. arXiv preprint
    arXiv:2010.12394, 2020.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lu et al. [2020a] Fan Lu, Guang Chen, Yinlong Liu, Zhongnan Qu, 和 Alois Knoll.
    Rskdd-net: 基于随机样本的关键点检测器和描述符。arXiv 预印本 arXiv:2010.12394, 2020。'
- en: 'Lu et al. [2020b] Yuheng Lu, Fan Yang, Fangping Chen, and Don Xie. Pic-net:
    Point cloud and image collaboration network for large-scale place recognition.
    arXiv preprint arXiv:2008.00658, 2020.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lu et al. [2020b] Yuheng Lu, Fan Yang, Fangping Chen, 和 Don Xie. Pic-net: 点云和图像协作网络用于大规模地点识别。arXiv
    预印本 arXiv:2008.00658, 2020。'
- en: Luo et al. [2020] Zhipeng Luo, Di Liu, Jonathan Li, Yiping Chen, Zhenlong Xiao,
    José Marcato Junior, Wesley Nunes Gonçalves, and Cheng Wang. Learning sequential
    slice representation with an attention-embedding network for 3d shape recognition
    and retrieval in mls point clouds. ISPRS Journal of Photogrammetry and Remote
    Sensing, 161:147–163, 2020.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luo et al. [2020] Zhipeng Luo, Di Liu, Jonathan Li, Yiping Chen, Zhenlong Xiao,
    José Marcato Junior, Wesley Nunes Gonçalves, 和 Cheng Wang. 使用注意力嵌入网络学习序列切片表示，以进行
    MLS 点云中的 3D 形状识别和检索。ISPRS 摄影测量与遥感杂志, 161:147–163, 2020。
- en: Luong et al. [2015] Minh-Thang Luong, Hieu Pham, and Christopher D Manning.
    Effective approaches to attention-based neural machine translation. arXiv preprint
    arXiv:1508.04025, 2015.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luong et al. [2015] Minh-Thang Luong, Hieu Pham, 和 Christopher D Manning. 基于注意力的神经机器翻译的有效方法。arXiv
    预印本 arXiv:1508.04025, 2015。
- en: Marblestone et al. [2016] Adam H Marblestone, Greg Wayne, and Konrad P Kording.
    Toward an integration of deep learning and neuroscience. Frontiers in computational
    neuroscience, 10:94, 2016.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marblestone et al. [2016] Adam H Marblestone, Greg Wayne, 和 Konrad P Kording.
    朝着深度学习与神经科学的融合。计算神经科学前沿, 10:94, 2016。
- en: 'Maturana and Scherer [2015] Daniel Maturana and Sebastian Scherer. Voxnet:
    A 3d convolutional neural network for real-time object recognition. In 2015 IEEE/RSJ
    International Conference on Intelligent Robots and Systems (IROS), pages 922–928\.
    IEEE, 2015.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Maturana and Scherer [2015] Daniel Maturana 和 Sebastian Scherer. Voxnet: 一种用于实时物体识别的
    3D 卷积神经网络。发表于 2015 IEEE/RSJ 国际智能机器人与系统会议 (IROS), 页码 922–928. IEEE, 2015。'
- en: Matveev et al. [2020] Albert Matveev, Alexey Artemov, Denis Zorin, and Evgeny
    Burnaev. Geometric attention for prediction of differential properties in 3d point
    clouds. In IAPR Workshop on Artificial Neural Networks in Pattern Recognition,
    pages 113–124\. Springer, 2020.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matveev et al. [2020] Albert Matveev, Alexey Artemov, Denis Zorin, 和 Evgeny
    Burnaev. 预测 3D 点云中微分属性的几何注意力。发表于 IAPR 人工神经网络模式识别研讨会论文集, 页码 113–124. Springer,
    2020。
- en: 'Nguyen et al. [2018] Tam V Nguyen, Qi Zhao, and Shuicheng Yan. Attentive systems:
    A survey. International Journal of Computer Vision, 126(1):86–110, 2018.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nguyen et al. [2018] Tam V Nguyen, Qi Zhao, 和 Shuicheng Yan. 注意力系统：一项综述。计算机视觉国际杂志,
    126(1):86–110, 2018。
- en: Paigwar et al. [2019] Anshul Paigwar, Ozgur Erkent, Christian Wolf, and Christian
    Laugier. Attentional pointnet for 3d-object detection in point clouds. In Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages
    0–0, 2019.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Paigwar et al. [2019] Anshul Paigwar, Ozgur Erkent, Christian Wolf, 和 Christian
    Laugier. 用于点云中的 3D 物体检测的注意力 PointNet。发表于 IEEE 计算机视觉与模式识别会议论文集, 页码 0–0, 2019。
- en: 'Puy et al. [2020] Gilles Puy, Alexandre Boulch, and Renaud Marlet. Flot: Scene
    flow on point clouds guided by optimal transport. arXiv preprint arXiv:2007.11142,
    2020.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Puy et al. [2020] Gilles Puy, Alexandre Boulch, 和 Renaud Marlet. Flot: 通过最优传输引导的点云场景流。arXiv
    预印本 arXiv:2007.11142, 2020。'
- en: '[39] Zhijian Qiao, Zhe Liu, Chuanzhe Suo, Huanshu Wei, Zhuowen Shen, and Hesheng
    Wang. End-to-end 3d point cloud learning for registration task using virtual correspondences.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Zhijian Qiao, Zhe Liu, Chuanzhe Suo, Huanshu Wei, Zhuowen Shen, 和 Hesheng
    Wang. 用虚拟对应物进行端到端 3D 点云学习以完成配准任务。'
- en: 'Qin et al. [2019] Can Qin, Haoxuan You, Lichen Wang, C-C Jay Kuo, and Yun Fu.
    Pointdan: A multi-scale 3d domain adaption network for point cloud representation.
    In Advances in Neural Information Processing Systems, pages 7192–7203, 2019.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qin et al. [2019] Can Qin, Haoxuan You, Lichen Wang, C-C Jay Kuo, 和 Yun Fu.
    Pointdan: 一种多尺度 3D 领域适应网络用于点云表示。发表于神经信息处理系统进展, 页码 7192–7203, 2019。'
- en: 'Qingyong et al. [2019] Hu Qingyong, Yang Bo, Xie Linhai, Rosa Stefano, Guo
    Yulan, Wang Zhihua, Trigoni Niki, and Markham Andrew. Randla-net: Efficient semantic
    segmentation of large-scale point clouds. CVPR, pages 11105–11114, 2019.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 青勇等人 [2019] 胡青勇、杨博、谢林海、罗莎·斯特凡诺、郭玉兰、王志华、特里戈尼·妮基和马克汉·安德鲁。Randla-net：大规模点云的高效语义分割。CVPR，第11105–11114页，2019年。
- en: Shajahan et al. [2019] Dimple A Shajahan, Vaibhav Nayel, and Ramanathan Muthuganapathy.
    Roof classification from 3-d lidar point clouds using multiview cnn with self-attention.
    IEEE Geoscience and Remote Sensing Letters, 2019.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 沙贾汉等人 [2019] 丁普尔·A·沙贾汉、维巴夫·纳耶尔和拉马纳坦·穆图甘纳帕提。基于多视角CNN和自注意力的3D激光雷达点云屋顶分类。IEEE地球科学与遥感快报，2019年。
- en: 'Shi et al. [2020] Hanyu Shi, Guosheng Lin, Hao Wang, Tzu-Yi Hung, and Zhenhua
    Wang. Spsequencenet: Semantic segmentation network on 4d point clouds. In Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4574–4583,
    2020.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 石等人 [2020] 石汉宇、林国生、王浩、洪子怡和王振华。Spsequencenet：4D点云上的语义分割网络。载于《IEEE/CVF计算机视觉与模式识别会议论文集》，第4574–4583页，2020年。
- en: 'Song et al. [2020] Myoungha Song, Jeongho Lee, and Donghwan Kim. Pam: Point-wise
    attention module for 6d object pose estimation. arXiv preprint arXiv:2008.05242,
    2020.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 宋等人 [2020] 宋明夏、李正浩和金东焕。PAM：用于6D物体姿态估计的点级注意力模块。arXiv预印本arXiv:2008.05242，2020年。
- en: 'Sun et al. [2020] Qi Sun, Hongyan Liu, Jun He, Zhaoxin Fan, and Xiaoyong Du.
    Dagc: Employing dual attention and graph convolution for point cloud based place
    recognition. In Proceedings of the 2020 International Conference on Multimedia
    Retrieval, pages 224–232, 2020.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 孙等人 [2020] 孙琪、刘洪燕、何军、范兆鑫和杜晓勇。DAGC：采用双重注意力和图卷积进行基于点云的地点识别。载于《2020年国际多媒体检索会议论文集》，第224–232页，2020年。
- en: Tu et al. [2020] Xinyuan Tu, Jian Zhang, Runhao Luo, Kai Wang, Qingji Zeng,
    Yu Zhou, Yao Yu, and Sidan Du. Reconstruction of high-precision semantic map.
    Sensors, 20(21):6264, 2020.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 屠等人 [2020] 屠欣源、张建、罗润浩、王凯、曾庆纪、周宇、尤尧和杜思丹。高精度语义地图的重建。传感器，20(21)：6264，2020年。
- en: Wang and Prisacariu [2020] Zirui Wang and Victor Adrian Prisacariu. Neighbourhood-insensitive
    point cloud normal estimation network. arXiv preprint arXiv:2008.09965, 2020.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王和普里萨卡留 [2020] 王子睿和维克托·阿德里安·普里萨卡留。邻域不敏感的点云法线估计网络。arXiv预印本arXiv:2008.09965，2020年。
- en: 'Wang and Solomon [2019] Yue Wang and Justin M Solomon. Deep closest point:
    Learning representations for point cloud registration. In Proceedings of the IEEE
    International Conference on Computer Vision, pages 3523–3532, 2019.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王和所罗门 [2019] 王跃和贾斯廷·M·所罗门。深度最近点：点云配准的表示学习。载于《IEEE国际计算机视觉会议论文集》，第3523–3532页，2019年。
- en: Wang and Tax [2016] Feng Wang and David MJ Tax. Survey on the attention based
    rnn model and its applications in computer vision. arXiv preprint arXiv:1601.06823,
    2016.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王和Tax [2016] 王锋和大卫·MJ·塔克。基于注意力的RNN模型及其在计算机视觉中的应用综述。arXiv预印本arXiv:1601.06823，2016年。
- en: Wang et al. [2019] Kaiqi Wang, Ke Chen, and Kui Jia. Deep cascade generation
    on point sets. In IJCAI, volume 2019, page 4, 2019.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等人 [2019] 王开琪、陈珂和贾奎。点集上的深度级联生成。载于IJCAI，2019年，卷号2019，第4页。
- en: Wang et al. [2020a] Guangming Wang, Xinrui Wu, Zhe Liu, and Hesheng Wang. Hierarchical
    attention learning of scene flow in 3d point clouds. arXiv preprint arXiv:2010.05762,
    2020.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等人 [2020a] 王光明、吴欣锐、刘哲和王和生。3D点云场景流的分层注意力学习。arXiv预印本arXiv:2010.05762，2020年。
- en: 'Wang et al. [2020b] Guangming Wang, Xinrui Wu, Zhe Liu, and Hesheng Wang. Pwclo-net:
    Deep lidar odometry in 3d point clouds using hierarchical embedding mask optimization.
    arXiv preprint arXiv:2012.00972, 2020.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等人 [2020b] 王光明、吴欣锐、刘哲和王和生。PWCLo-net：使用分层嵌入掩码优化的3D点云深度激光雷达里程计。arXiv预印本arXiv:2012.00972，2020年。
- en: 'Wang et al. [2020c] Guojun Wang, Bin Tian, Yunfeng Ai, Tong Xu, Long Chen,
    and Dongpu Cao. Centernet3d: An anchor free object detector for autonomous driving.
    arXiv preprint arXiv:2007.07214, 2020.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等人 [2020c] 王国俊、田斌、艾云峰、徐彤、陈龙和曹东普。CenterNet3D：一种用于自动驾驶的无锚物体检测器。arXiv预印本arXiv:2007.07214，2020年。
- en: 'Wen et al. [2020a] Xin Wen, Zhizhong Han, Geunhyuk Youk, and Yu-Shen Liu. Cf-sis:
    Semantic-instance segmentation of 3d point clouds by context fusion with self-attention.
    In Proceedings of the 28th ACM International Conference on Multimedia, pages 1661–1669,
    2020.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 温等人 [2020a] 温欣、韩志中、郁根赫和刘宇申。Cf-sis：通过上下文融合与自注意力实现3D点云的语义实例分割。载于《第28届ACM国际多媒体会议论文集》，第1661–1669页，2020年。
- en: Wen et al. [2020b] Xin Wen, Tianyang Li, Zhizhong Han, and Yu-Shen Liu. Point
    cloud completion by skip-attention network with hierarchical folding. In Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1939–1948,
    2020.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 温等人 [2020b] Xin Wen、Tianyang Li、Zhizhong Han 和 Yu-Shen Liu。通过跳跃注意力网络和层次折叠进行点云补全。发表于
    IEEE/CVF 计算机视觉与模式识别会议论文集，页码 1939–1948，2020年。
- en: Wu and Ogai [2020] Yutian Wu and Harutoshi Ogai. Realtime single-shot refinement
    neural network for 3d obejct detection from lidar point cloud. In 2020 59th Annual
    Conference of the Society of Instrument and Control Engineers of Japan (SICE),
    pages 332–337\. IEEE, 2020.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吴和 Ogai [2020] Yutian Wu 和 Harutoshi Ogai。用于从激光雷达点云中进行 3D 物体检测的实时单次精化神经网络。发表于
    2020年第59届日本仪器与控制工程师学会年会 (SICE)，页码 332–337。IEEE，2020年。
- en: 'Wu et al. [2019] Wenxuan Wu, Zhiyuan Wang, Zhuwen Li, Wei Liu, and Li Fuxin.
    Pointpwc-net: A coarse-to-fine network for supervised and self-supervised scene
    flow estimation on 3d point clouds. arXiv preprint arXiv:1911.12408, 2019.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吴等人 [2019] Wenxuan Wu、Zhiyuan Wang、Zhuwen Li、Wei Liu 和 Li Fuxin。Pointpwc-net：用于监督和自监督场景流估计的粗到细网络。arXiv
    预印本 arXiv:1911.12408，2019年。
- en: 'Wu et al. [2020] Yutian Wu, Yueyu Wang, Shuwei Zhang, and Harutoshi Ogai. Deep
    3d object detection networks using lidar data: A review. IEEE Sensors Journal,
    21(2):1152–1171, 2020.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吴等人 [2020] Yutian Wu、Yueyu Wang、Shuwei Zhang 和 Harutoshi Ogai。利用激光雷达数据的深度 3D
    物体检测网络：综述。IEEE 传感器期刊，21(2)：1152–1171，2020年。
- en: 'Xia et al. [2020] Yan Xia, Yusheng Xu, Shuang Li, Rui Wang, Juan Du, Daniel
    Cremers, and Uwe Stilla. Soe-net: A self-attention and orientation encoding network
    for point cloud based place recognition. arXiv preprint arXiv:2011.12430, 2020.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 夏等人 [2020] Yan Xia、Yusheng Xu、Shuang Li、Rui Wang、Juan Du、Daniel Cremers 和 Uwe
    Stilla。Soe-net：用于点云基础场所识别的自注意力和方向编码网络。arXiv 预印本 arXiv:2011.12430，2020年。
- en: 'Xie et al. [2020] Qian Xie, Yu-Kun Lai, Jing Wu, Zhoutao Wang, Yiming Zhang,
    Kai Xu, and Jun Wang. Mlcvnet: Multi-level context votenet for 3d object detection.
    In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    pages 10447–10456, 2020.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谢等人 [2020] Qian Xie、Yu-Kun Lai、Jing Wu、Zhoutao Wang、Yiming Zhang、Kai Xu 和 Jun
    Wang。Mlcvnet：用于 3D 物体检测的多级上下文 votenet。发表于 IEEE/CVF 计算机视觉与模式识别会议论文集，页码 10447–10456，2020年。
- en: Yang and Wang [2019] Ze Yang and Liwei Wang. Learning relationships for multi-view
    3d object recognition. In Proceedings of the IEEE International Conference on
    Computer Vision, pages 7505–7514, 2019.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杨和王 [2019] Ze Yang 和 Liwei Wang。学习多视角 3D 物体识别的关系。发表于 IEEE 国际计算机视觉会议论文集，页码 7505–7514，2019年。
- en: 'Yang et al. [2018] Bin Yang, Wenjie Luo, and Raquel Urtasun. Pixor: Real-time
    3d object detection from point clouds. In Proceedings of the IEEE conference on
    Computer Vision and Pattern Recognition, pages 7652–7660, 2018.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杨等人 [2018] Bin Yang、Wenjie Luo 和 Raquel Urtasun。Pixor：来自点云的实时 3D 物体检测。发表于 IEEE
    计算机视觉与模式识别会议论文集，页码 7652–7660，2018年。
- en: Yang et al. [2019] Jiancheng Yang, Qiang Zhang, Bingbing Ni, Linguo Li, Jinxian
    Liu, Mengdie Zhou, and Qi Tian. Modeling point clouds with self-attention and
    gumbel subset sampling. In Proceedings of the IEEE Conference on Computer Vision
    and Pattern Recognition, pages 3323–3332, 2019.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杨等人 [2019] Jiancheng Yang、Qiang Zhang、Bingbing Ni、Linguo Li、Jinxian Liu、Mengdie
    Zhou 和 Qi Tian。使用自注意力和 Gumbel 子集抽样建模点云。发表于 IEEE 计算机视觉与模式识别会议论文集，页码 3323–3332，2019年。
- en: 'Yang et al. [2020] Jian Yang, Xu Jiang, and Xiaohong Ma. 3dsenet: 3d spatial
    attention region ensemble network for real-time 3d hand pose estimation. In 2020
    10th International Conference on Information Science and Technology (ICIST), pages
    96–104\. IEEE, 2020.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杨等人 [2020] Jian Yang、Xu Jiang 和 Xiaohong Ma。3dsenet：用于实时 3D 手势姿态估计的 3D 空间注意力区域集成网络。发表于
    2020年第十届信息科学与技术国际会议 (ICIST)，页码 96–104。IEEE，2020年。
- en: 'Yew and Lee [2018] Zi Jian Yew and Gim Hee Lee. 3dfeat-net: Weakly supervised
    local 3d features for point cloud registration. In European Conference on Computer
    Vision, pages 630–646. Springer, 2018.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yew 和 Lee [2018] Zi Jian Yew 和 Gim Hee Lee。3dfeat-net：用于点云配准的弱监督局部 3D 特征。发表于欧洲计算机视觉会议，页码
    630–646。Springer，2018年。
- en: 'You et al. [2018] Haoxuan You, Yifan Feng, Rongrong Ji, and Yue Gao. Pvnet:
    A joint convolutional network of point cloud and multi-view for 3d shape recognition.
    In Proceedings of the 26th ACM international conference on Multimedia, pages 1310–1318,
    2018.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 游等人 [2018] Haoxuan You、Yifan Feng、Rongrong Ji 和 Yue Gao。Pvnet：一个点云和多视角的联合卷积网络用于
    3D 形状识别。发表于第26届 ACM 国际多媒体会议论文集，页码 1310–1318，2018年。
- en: Yuan and Veltkamp [2020] Honglin Yuan and Remco C Veltkamp. 6d object pose estimation
    with color/geometry attention fusion. In 2020 16th International Conference on
    Control, Automation, Robotics and Vision (ICARCV), pages 529–535\. IEEE, 2020.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan 和 Veltkamp [2020] 袁洪林 和 Remco C Veltkamp。通过颜色/几何注意力融合进行 6D 对象姿态估计。在2020年第16届国际控制、自动化、机器人和视觉会议（ICARCV）上，页码529–535。IEEE，2020年。
- en: 'Yuan et al. [2020] Honglin Yuan, Remco C Veltkamp, Georgios Albanis, Nikolaos
    Zioulis, Dimitrios Zarpalas, and Petros Daras. Shrec 2020 track: 6d object pose
    estimation. arXiv preprint arXiv:2010.09355, 2020.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan 等人 [2020] 袁洪林、Remco C Veltkamp、Georgios Albanis、Nikolaos Zioulis、Dimitrios
    Zarpalas 和 Petros Daras。Shrec 2020 赛道：6D 对象姿态估计。arXiv 预印本 arXiv:2010.09355，2020年。
- en: 'Zhang and Xiao [2019] Wenxiao Zhang and Chunxia Xiao. Pcan: 3d attention map
    learning using contextual information for point cloud based retrieval. In Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition, pages 12436–12445,
    2019.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang 和 Xiao [2019] 张文瀟 和 萧春霞。PCAN: 使用上下文信息进行点云检索的 3D 注意力图学习。在IEEE计算机视觉与模式识别大会会议录中，页码12436–12445，2019年。'
- en: 'Zhang et al. [2020a] Gege Zhang, Qinghua Ma, Licheng Jiao, Fang Liu, and Qigong
    Sun. Attan: Attention adversarial networks for 3d point cloud semantic segmentation.
    IJCAI, pages 789–796, 2020.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang 等人 [2020a] 张戈戈、马清华、焦丽程、刘芳 和 孙琦功。ATTAN: 用于 3D 点云语义分割的注意力对抗网络。IJCAI，页码789–796，2020年。'
- en: Zhang et al. [2020b] Wenxiao Zhang, Chengjiang Long, Qingan Yan, Alix LH Chow,
    and Chunxia Xiao. Multi-stage point completion network with critical set supervision.
    Computer Aided Geometric Design, 82:101925, 2020.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 [2020b] 张文瀟、龙成江、闫青安、Alix LH Chow 和 萧春霞。具有关键集监督的多阶段点补全网络。计算机辅助几何设计，82:101925，2020年。
- en: Zhang et al. [2020c] Wenxiao Zhang, Qingan Yan, and Chunxia Xiao. Detail preserved
    point cloud completion via separated feature aggregation. european conference
    on computer vision, pages 512–528, 2020.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 [2020c] 张文瀟、闫青安 和 萧春霞。通过分离特征聚合的细节保留点云补全。欧洲计算机视觉会议，页码512–528，2020年。
- en: 'Zhao et al. [2020a] Yaxin Zhao, Jichao Jiao, and Tangkun Zhang. Manet: Multimodal
    attention network based point-view fusion for 3d shape recognition. arXiv preprint
    arXiv:2002.12573, 2020.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao 等人 [2020a] 赵亚欣、焦继超 和 张唐坤。Manet: 基于多模态注意力网络的点视图融合用于 3D 形状识别。arXiv 预印本 arXiv:2002.12573，2020年。'
- en: 'Zhao et al. [2020b] Yifan Zhao, Jin Xie, Jianjun Qian, and Jian Yang. Pui-net:
    A point cloud upsampling and inpainting network. In Chinese Conference on Pattern
    Recognition and Computer Vision (PRCV), pages 328–340\. Springer, 2020.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao 等人 [2020b] 赵一凡、谢进、钱建军 和 杨建。Pui-net: 一个点云上采样和修补网络。在中国模式识别与计算机视觉大会（PRCV）上，页码328–340。Springer，2020年。'
