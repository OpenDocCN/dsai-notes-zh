- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:03:11'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:03:11
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2001.01293] Towards Automatic Threat Detection: A Survey of Advances of Deep
    Learning within X-ray Security Imaging'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2001.01293] 迈向自动威胁检测：深度学习在 X 射线安全成像中的进展综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2001.01293](https://ar5iv.labs.arxiv.org/html/2001.01293)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2001.01293](https://ar5iv.labs.arxiv.org/html/2001.01293)
- en: 'Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迈向自动威胁检测：深度学习在 X 射线安全成像中的进展综述
- en: Samet Akcay Toby Breckon Intel R&D, UK Department of Computer Science, Durham
    University, Durham, UK
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Samet Akcay Toby Breckon Intel R&D, UK Department of Computer Science, Durham
    University, Durham, UK
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: X-ray security screening is widely used to maintain aviation/transport security,
    and its significance poses a particular interest in automated screening systems.
    This paper aims to review computerised X-ray security imaging algorithms by taxonomising
    the field into conventional machine learning and contemporary deep learning applications.
    The first part briefly discusses the classical machine learning approaches utilised
    within X-ray security imaging, while the latter part thoroughly investigates the
    use of modern deep learning algorithms. The proposed taxonomy sub-categorises
    the use of deep learning approaches into supervised and unsupervised learning,
    with a particular focus on object classification, detection, segmentation and
    anomaly detection tasks. The paper further explores well-established X-ray datasets
    and provides a performance benchmark. Based on the current and future trends in
    deep learning, the paper finally presents a discussion and future directions for
    X-ray security imagery.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: X 射线安全筛查被广泛用于维护航空/交通安全，其重要性引起了对自动化筛查系统的特别关注。本文旨在通过将计算机化 X 射线安全成像算法分类为传统的机器学习和现代深度学习应用，来回顾这一领域。第一部分简要讨论了
    X 射线安全成像中使用的经典机器学习方法，而后半部分则深入研究了现代深度学习算法的使用。提出的分类法将深度学习方法细分为监督学习和无监督学习，特别关注对象分类、检测、分割和异常检测任务。本文进一步探讨了已建立的
    X 射线数据集，并提供了性能基准。根据当前和未来深度学习的趋势，本文最后讨论了 X 射线安全成像的未来方向。
- en: 'keywords:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: 'Review , Survey , X-ray Security Imaging , Deep Learning^†^†journal: Pattern
    Recognition\newunicodechar'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 综述，调查，X 射线安全成像，深度学习^†^†期刊：模式识别\newunicodechar
- en: fifi \newunicodecharffff
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: fifi \newunicodecharffff
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: X-ray security screening is one of the most widely used security measures for
    maintaining airport and transport security, whereby manual screening by human
    operators plays the vital role. Although experience and knowledge are the key
    factors for confident detection, external variables such as emotional exhaustion
    and job satisfaction adversely impact the manual screening [[1](#bib.bib1)].
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: X 射线安全筛查是维护机场和交通安全的最广泛使用的安全措施之一，其中人工筛查发挥着至关重要的作用。虽然经验和知识是自信检测的关键因素，但外部变量如情绪疲劳和工作满意度会对人工筛查产生不利影响
    [[1](#bib.bib1)]。
- en: Cluttered nature of X-ray bags also negatively affects the decision time and
    detection performance of the human operators [[2](#bib.bib2), [3](#bib.bib3)].
    For instance, the threat detection performance of human screeners significantly
    reduces when laptops are left inside the bags. This is due to the compact structure
    of laptops, limiting detection capability of the screeners [[4](#bib.bib4)]. All
    these issues necessitate the use of automated object detection algorithms within
    X-ray security imaging, which would maintain the alertness and improve detection
    and response time of human operators [[5](#bib.bib5)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: X 射线行李的混杂性质也对人工操作员的决策时间和检测性能产生负面影响 [[2](#bib.bib2), [3](#bib.bib3)]。例如，当笔记本电脑留在包内时，人为筛查员的威胁检测性能显著降低。这是由于笔记本电脑的紧凑结构限制了筛查员的检测能力
    [[4](#bib.bib4)]。所有这些问题都需要在 X 射线安全成像中使用自动化目标检测算法，这将保持操作员的警觉性并提高检测和响应时间 [[5](#bib.bib5)]。
- en: '![Refer to caption](img/8a32bfa1b8a0ef265a1ecc4d59eefbf2.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8a32bfa1b8a0ef265a1ecc4d59eefbf2.png)'
- en: 'Figure 1: Statistics for the recent papers published in X-ray security imaging.
    (a) Distribution of machine learning vs. deep learning papers over the years.
    (b) Distribution of the papers based on the task'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：最近在 X 射线安全成像领域发表的论文统计数据。(a) 多年来机器学习与深度学习论文的分布。(b) 根据任务对论文的分布
- en: Despite the surge of interest in X-ray screening [[6](#bib.bib6), [7](#bib.bib7),
    [8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)], automated computer-aided screening
    is understudied, particularly due to the lack of data, and the need for advanced
    learning algorithms. Previous work in the field have focused more on conventional
    image analysis [[11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13)] and machine
    learning methods, spanning classification [[14](#bib.bib14), [15](#bib.bib15),
    [16](#bib.bib16)], detection [[17](#bib.bib17), [18](#bib.bib18)] and segmentation
    [[19](#bib.bib19), [20](#bib.bib20)] tasks. Notable surveys within the field [[21](#bib.bib21),
    [22](#bib.bib22)] thoroughly review these approaches and categorize the existing
    literature within image processing and understanding.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管对X射线筛查[[6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)]的兴趣激增，自动化计算机辅助筛查仍然研究不足，特别是由于数据的缺乏和对先进学习算法的需求。该领域的前期工作更多集中于传统图像分析[[11](#bib.bib11),
    [12](#bib.bib12), [13](#bib.bib13)]和机器学习方法，涉及分类[[14](#bib.bib14), [15](#bib.bib15),
    [16](#bib.bib16)]、检测[[17](#bib.bib17), [18](#bib.bib18)]和分割[[19](#bib.bib19),
    [20](#bib.bib20)]任务。该领域的著名调查[[21](#bib.bib21), [22](#bib.bib22)]详细回顾了这些方法，并对图像处理和理解中的现有文献进行了分类。
- en: More recently, on the other hand, deep-learning-based algorithms have been adopted
    in X-ray security imaging [[23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25)],
    especially after convolutional neural networks (CNN) significantly outperform
    the conventional machine learning methods. To this end, as of 2017, the use of
    deep learning algorithms is in the official US Government technology road-map
    for use across the US; and as of 2019/20, several early commercial systems have
    emerged from the academic research [[26](#bib.bib26)].
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，另一方面，基于深度学习的算法已被应用于X射线安全成像[[23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25)]，尤其是在卷积神经网络（CNN）显著超越传统机器学习方法之后。为此，截至2017年，深度学习算法的使用已纳入美国政府的技术路线图；到2019/20年，几种早期商业系统已从学术研究中出现[[26](#bib.bib26)]。
- en: <svg   height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><foreignobject
    width="-15.37" height="0" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">\Tree[27](#bib.bib27),
    [11](#bib.bib11), [28](#bib.bib28), [29](#bib.bib29), [30](#bib.bib30), [31](#bib.bib31)[32](#bib.bib32),
    [33](#bib.bib33), [34](#bib.bib34)[35](#bib.bib35), [36](#bib.bib36), [37](#bib.bib37),
    [38](#bib.bib38), [39](#bib.bib39), [40](#bib.bib40), [41](#bib.bib41), [42](#bib.bib42),
    [43](#bib.bib43), [44](#bib.bib44), [42](#bib.bib42), [43](#bib.bib43), [18](#bib.bib18),
    [14](#bib.bib14), [45](#bib.bib45), [46](#bib.bib46), [14](#bib.bib14), [15](#bib.bib15),
    [16](#bib.bib16)[47](#bib.bib47), [41](#bib.bib41), [48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50), [51](#bib.bib51), [52](#bib.bib52), [53](#bib.bib53), [54](#bib.bib54),
    [55](#bib.bib55), [24](#bib.bib24), [56](#bib.bib56)[57](#bib.bib57), [18](#bib.bib18)[17](#bib.bib17),
    [18](#bib.bib18)[58](#bib.bib58), [59](#bib.bib59), [60](#bib.bib60), [61](#bib.bib61),
    [13](#bib.bib13), [19](#bib.bib19), [20](#bib.bib20)[23](#bib.bib23), [62](#bib.bib62),
    [25](#bib.bib25), [63](#bib.bib63), [64](#bib.bib64), [65](#bib.bib65), [66](#bib.bib66),
    [67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69), [70](#bib.bib70), [71](#bib.bib71)[72](#bib.bib72),
    [73](#bib.bib73), [74](#bib.bib74)[73](#bib.bib73), [75](#bib.bib75), [70](#bib.bib70),
    [76](#bib.bib76), [74](#bib.bib74), [77](#bib.bib77), [78](#bib.bib78)[79](#bib.bib79),
    [80](#bib.bib80), [81](#bib.bib81)[82](#bib.bib82), [83](#bib.bib83), [84](#bib.bib84)[85](#bib.bib85),
    [86](#bib.bib86), [87](#bib.bib87), [88](#bib.bib88), [89](#bib.bib89), [90](#bib.bib90),
    [91](#bib.bib91)</foreignobject></g></svg>
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: <svg   height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><foreignobject
    width="-15.37" height="0" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">\Tree[27](#bib.bib27),
    [11](#bib.bib11), [28](#bib.bib28), [29](#bib.bib29), [30](#bib.bib30), [31](#bib.bib31)[32](#bib.bib32),
    [33](#bib.bib33), [34](#bib.bib34)[35](#bib.bib35), [36](#bib.bib36), [37](#bib.bib37),
    [38](#bib.bib38), [39](#bib.bib39), [40](#bib.bib40), [41](#bib.bib41), [42](#bib.bib42),
    [43](#bib.bib43), [44](#bib.bib44), [42](#bib.bib42), [43](#bib.bib43), [18](#bib.bib18),
    [14](#bib.bib14), [45](#bib.bib45), [46](#bib.bib46), [14](#bib.bib14), [15](#bib.bib15),
    [16](#bib.bib16)[47](#bib.bib47), [41](#bib.bib41), [48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50), [51](#bib.bib51), [52](#bib.bib52), [53](#bib.bib53), [54](#bib.bib54),
    [55](#bib.bib55), [24](#bib.bib24), [56](#bib.bib56)[57](#bib.bib57), [18](#bib.bib18)[17](#bib.bib17),
    [18](#bib.bib18)[58](#bib.bib58), [59](#bib.bib59), [60](#bib.bib60), [61](#bib.bib61),
    [13](#bib.bib13), [19](#bib.bib19), [20](#bib.bib20)[23](#bib.bib23), [62](#bib.bib62),
    [25](#bib.bib25), [63](#bib.bib63), [64](#bib.bib64), [65](#bib.bib65), [66](#bib.bib66),
    [67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69), [70](#bib.bib70), [71](#bib.bib71)[72](#bib.bib72),
    [73](#bib.bib73), [74](#bib.bib74)[73](#bib.bib73), [75](#bib.bib75), [70](#bib.bib70),
    [76](#bib.bib76), [74](#bib.bib74), [77](#bib.bib77), [78](#bib.bib78)[79](#bib.bib79),
    [80](#bib.bib80), [81](#bib.bib81)[82](#bib.bib82), [83](#bib.bib83), [84](#bib.bib84)[85](#bib.bib85),
    [86](#bib.bib86), [87](#bib.bib87), [88](#bib.bib88), [89](#bib.bib89), [90](#bib.bib90),
    [91](#bib.bib91)</foreignobject></g></svg>
- en: 'Figure 2: A Taxonomy of the X-ray security imaging papers.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：X射线安全成像文献的分类法。
- en: 'Following this trend change, this literature survey reviews the published work
    within various computer vision tasks (Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging")B) in X-ray security screening, with a particular focus
    on the deep learning applications. We use the following keywords and operators
    in Google Scholar search to search the relevant papers: ‘((x-ray security) OR
    (x-ray baggage) OR (x-ray luggage)) AND ((detection) OR classification OR segmentation)’.
    We also conduct a backward search based on the citations and related papers, and
    overall identify approximately 213 relevant articles, of which 36 employ deep-learning-based
    algorithms (Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")A).
    Based on the scope of the work, we finally reduce the number of relevant papers
    to 130\. The main contributions of this work, therefore, are as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 随着这一趋势的变化，本文献综述回顾了在各种计算机视觉任务中已发表的工作（图 [1](#S1.F1 "图 1 ‣ 1 引言 ‣ 向自动威胁检测迈进：X射线安全成像中深度学习进展的综述")B），特别关注深度学习应用。我们在
    Google Scholar 搜索中使用以下关键词和运算符来搜索相关论文：‘((x-ray security) OR (x-ray baggage) OR
    (x-ray luggage)) AND ((detection) OR classification OR segmentation)’. 我们还基于引用和相关论文进行了逆向搜索，最终识别出大约
    213 篇相关文章，其中 36 篇采用了基于深度学习的算法（图 [1](#S1.F1 "图 1 ‣ 1 引言 ‣ 向自动威胁检测迈进：X射线安全成像中深度学习进展的综述")A）。根据工作的范围，我们最终将相关论文的数量减少到
    130 篇。因此，本工作的主要贡献如下：
- en: '1.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1.'
- en: '*taxonomy* — an extensive overview of classical machine learning and contemporary
    deep learning within X-ray security imaging (Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction
    ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging")).'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*分类法* — 经典机器学习和现代深度学习在 X 射线安全成像中的广泛概述（见图 [2](#S1.F2 "图 2 ‣ 1 引言 ‣ 朝向自动威胁检测：X
    射线安全成像中深度学习的进展调查")）。'
- en: '2.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2.'
- en: '*datasets* — an overview of the large datasets used to train deep learning
    approaches within the field.'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*数据集* — 用于训练深度学习方法的大型数据集概述。'
- en: '3.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '3.'
- en: '*open problems* — discussion of the open problems, current challenges, and
    future directions based on the current trends within computer vision.'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*开放问题* — 基于计算机视觉当前趋势的开放问题、当前挑战和未来方向的讨论。'
- en: 'The rest of the paper is as follows: Section [2](#S2 "2 Background: X-ray Imaging
    ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging") provides a brief background regarding the principle of
    X-ray imaging. Sections [3](#S3 "3 Datasets ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging") and [4](#S4
    "4 Evaluation Criteria ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging") introduce datasets and evaluation
    criterion used to measure the performance of the methods. Sections [5](#S5 "5
    Conventional Image Analysis ‣ Towards Automatic Threat Detection: A Survey of
    Advances of Deep Learning within X-ray Security Imaging") and [6](#S6 "6 Machine
    Learning Approaches in X-ray Security Imaging ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging") explore
    conventional image analysis and machine learning algorithms. Section [7](#S7 "7
    Deep Learning in X-ray Security Imaging ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging") reviews
    the applications of the deep learning algorithms within X-ray security imaging.
    Section [8](#S8 "8 Discussion and Future Directions ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")
    discusses the open problems, current challenges and Section [9](#S9 "9 Conclusion
    ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging") finally concludes the paper.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的其余部分如下：第 [2](#S2 "2 背景：X 射线成像 ‣ 朝向自动威胁检测：X 射线安全成像中深度学习的进展调查") 节提供了关于 X 射线成像原理的简要背景。第
    [3](#S3 "3 数据集 ‣ 朝向自动威胁检测：X 射线安全成像中深度学习的进展调查") 和第 [4](#S4 "4 评估标准 ‣ 朝向自动威胁检测：X
    射线安全成像中深度学习的进展调查") 节介绍了用于评估方法性能的数据集和评估标准。第 [5](#S5 "5 传统图像分析 ‣ 朝向自动威胁检测：X 射线安全成像中深度学习的进展调查")
    和第 [6](#S6 "6 X 射线安全成像中的机器学习方法 ‣ 朝向自动威胁检测：X 射线安全成像中深度学习的进展调查") 节探讨了传统图像分析和机器学习算法。第
    [7](#S7 "7 X 射线安全成像中的深度学习 ‣ 朝向自动威胁检测：X 射线安全成像中深度学习的进展调查") 节回顾了深度学习算法在 X 射线安全成像中的应用。第
    [8](#S8 "8 讨论与未来方向 ‣ 朝向自动威胁检测：X 射线安全成像中深度学习的进展调查") 节讨论了当前趋势下的开放问题、当前挑战，而第 [9](#S9
    "9 结论 ‣ 朝向自动威胁检测：X 射线安全成像中深度学习的进展调查") 节最终总结了论文。
- en: '2 Background: X-ray Imaging'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景：X 射线成像
- en: '![Refer to caption](img/5e6db09bc682a6def379ef36fe07f668.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/5e6db09bc682a6def379ef36fe07f668.png)'
- en: 'Figure 3: High-level overview of X-ray imaging. RGB and X-ray images are from
    COMPASS-XP dataset [[92](#bib.bib92)].'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：X 射线成像的高级概述。RGB 和 X 射线图像来自 COMPASS-XP 数据集 [[92](#bib.bib92)]。
- en: 'As depicted in Figure [3](#S2.F3 "Figure 3 ‣ 2 Background: X-ray Imaging ‣
    Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging")A, the main principle of X-ray imaging is that an X-ray
    tube generates beams that penetrate the scanned object. Depending on its material
    density, the object attenuates the X-ray signal. This attenuation is formulated
    as $I_{x}=I_{0}e^{\mu x}$, where $I_{x}$ is the intensity at $x$ cm, $I_{0}$ is
    the initial intensity, and $\mu$ is the linear attenuation coefficient based on
    the thickness of the material. This formulation shows that material density and
    measured intensity are inversely proportional —for instance, a high-density material
    yields high attenuation and low measured intensity.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '如图 [3](#S2.F3 "Figure 3 ‣ 2 Background: X-ray Imaging ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")A
    所示，X 射线成像的主要原理是 X 射线管发射穿透被扫描物体的射线。根据物体的材料密度，物体会衰减 X 射线信号。这种衰减公式为 $I_{x}=I_{0}e^{\mu
    x}$，其中 $I_{x}$ 是 $x$ cm 处的强度，$I_{0}$ 是初始强度，$\mu$ 是基于材料厚度的线性衰减系数。这个公式显示了材料密度和测量强度之间的反比例关系——例如，高密度材料会导致高衰减和低测量强度。'
- en: 'Modern X-ray machines are equipped with multiple ($m$)-energy that produces
    $m$ X-ray images via different energies (Figure [3](#S2.F3 "Figure 3 ‣ 2 Background:
    X-ray Imaging ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep
    Learning within X-ray Security Imaging")B), identifying the objects’ density and
    effective atomic number ($Z_{eff}$). The estimated intensity and $Z_{eff}$ values
    are converted to pseudo-colored images via a look-up table [[29](#bib.bib29)].
    In addition to multiple energy levels, the state-of-the art machines generates
    X-ray scans from multiple view-points to view the objects of interest from various
    angles (Figure [3](#S2.F3 "Figure 3 ‣ 2 Background: X-ray Imaging ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging")C). For more details regarding the X-ray image generation process, the
    reader is referred to [[93](#bib.bib93)].'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '现代 X 射线机器配备了多个 ($m$) 能量，能够通过不同能量产生 $m$ 张 X 射线图像（图 [3](#S2.F3 "Figure 3 ‣ 2
    Background: X-ray Imaging ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging")B），以识别物体的密度和有效原子序数 ($Z_{eff}$)。估计的强度和
    $Z_{eff}$ 值通过查找表转换为伪彩色图像 [[29](#bib.bib29)]。除了多个能量级别，最先进的机器还从多个视角生成 X 射线扫描，以从不同角度查看感兴趣的物体（图
    [3](#S2.F3 "Figure 3 ‣ 2 Background: X-ray Imaging ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")C）。有关
    X 射线图像生成过程的更多细节，请参阅 [[93](#bib.bib93)]。'
- en: 3 Datasets
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 数据集
- en: This section explores X-ray security imaging datasets that are widely used in
    the literature.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了在文献中广泛使用的 X 射线安全成像数据集。
- en: 3.1 Durham Baggage (DB) Patch/Full Image Dataset
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 Durham Baggage (DB) Patch/Full Image Dataset
- en: 'This dataset comprises $15,449$ X-ray samples with associated false color materials
    mapping from dual-energy four-view Smiths 6040i machine. Originally, samples have
    the following class distributions: $494$ camera, $1,596$ ceramic knife, $3,208$
    knife, $3,192$ firearms, $1,203$ firearm parts, $2,390$ laptop and $3,366$ benign
    images. Several variants of this dataset is constructed for classification (DBP2
    and DBP6) [[23](#bib.bib23), [15](#bib.bib15), [73](#bib.bib73)] and detection
    (DBF2 and DBF6) [[72](#bib.bib72), [73](#bib.bib73)]. The dataset is well-balanced
    with wide variety of threat objects. However, being a private dataset, it’s usage
    is limited within the literature.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集包含 $15,449$ 个 X 射线样本，配有来自双能四视角 Smiths 6040i 机器的伪彩色材料映射。最初，样本具有以下类别分布：$494$
    个相机，$1,596$ 个陶瓷刀，$3,208$ 个刀具，$3,192$ 个火器，$1,203$ 个火器部件，$2,390$ 个笔记本电脑和 $3,366$
    个良性图像。这个数据集的多个变体被构建用于分类（DBP2 和 DBP6）[[23](#bib.bib23), [15](#bib.bib15), [73](#bib.bib73)]
    和检测（DBF2 和 DBF6）[[72](#bib.bib72), [73](#bib.bib73)]。数据集均衡地涵盖了各种威胁对象。然而，由于这是一个私有数据集，它的使用仅限于文献中。
- en: 3.2 GDXray
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 GDXray
- en: Grima X-ray Dataset ($\mathbb{GDX}$RAY) [[94](#bib.bib94)] comprises $19,407$
    X-ray samples from five various subsets including castings ($2,727$), welds ($88$),
    baggage ($8,150$), natural images ($8,290$), and settings ($152$). The baggage
    subset is mainly used for security applications and comprises images from multiple-views.
    The limitation of this dataset is its non-complex content, which is non-ideal
    to train for real-time deployment.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Grima X射线数据集（$\mathbb{GDX}$RAY）[[94](#bib.bib94)]包含$19,407$个X射线样本，来自五个不同的子集，包括铸件（$2,727$）、焊接（$88$）、行李（$8,150$）、自然图像（$8,290$）和设置（$152$）。行李子集主要用于安全应用，包含多个视角的图像。该数据集的限制是内容不复杂，不适合用于实时部署的训练。
- en: 3.3 UCL TIP
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 UCL TIP
- en: 'This dataset comprises $120,000$ benign images, scanned with Rapiscan^® R60\.
    Each sample is 16-bit grayscale with sizes varying between $1920\times 850$ and
    $2570\times 850$. The train and test split of the dataset is $110000$ : $10000$,
    where the training images are $256\times 256$ patches randomly sub-sampled from
    $110,000$ images and the test set comprises $5000$ benign and $5000$ threat images.
    The threat images are synthetically generated via the TIP algorithm proposed in
    [[33](#bib.bib33)], where, depending on the application, small metallic threats
    (SMT) or car images are projected into the benign samples. With several variants,
    this dataset is used in several studies such as [[87](#bib.bib87), [88](#bib.bib88),
    [63](#bib.bib63), [65](#bib.bib65), [25](#bib.bib25), [64](#bib.bib64), [66](#bib.bib66)].'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '该数据集包含$120,000$个良性图像，使用Rapiscan^® R60扫描。每个样本为16位灰度图像，大小在$1920\times 850$和$2570\times
    850$之间变化。数据集的训练和测试分割为$110000$ : $10000$，其中训练图像为$256\times 256$的补丁，随机从$110,000$张图像中抽样，而测试集包含$5000$张良性图像和$5000$张威胁图像。威胁图像通过[[33](#bib.bib33)]中提出的TIP算法合成生成，根据应用需求，将小型金属威胁（SMT）或汽车图像投影到良性样本中。该数据集有多种变体，用于多个研究，如[[87](#bib.bib87),
    [88](#bib.bib88), [63](#bib.bib63), [65](#bib.bib65), [25](#bib.bib25), [64](#bib.bib64),
    [66](#bib.bib66)]。'
- en: 3.4 SIXray
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 SIXray
- en: 'With unknown machine specification, this dataset is acquired from subway stations
    and released by [[71](#bib.bib71)], SIXray dataset comprises $1,059,231$ X-ray
    images, $8929$ of which are manually annotated for $6$ different classes: gun,
    knife, wrench, pliers, scissors, hammer, and background. The dataset consists
    of objects with a wide variety in scale, viewpoint and mostly overlapping, making
    it a suitable dataset for real-time classification, detection and segmentation
    applications.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器规格未知的情况下，该数据集来自地铁站，由[[71](#bib.bib71)]发布。SIXray数据集包含$1,059,231$张X射线图像，其中$8929$张经过手动标注，分为$6$个不同的类别：枪支、刀具、扳手、钳子、剪刀、锤子和背景。该数据集包含尺度、视点广泛且大多重叠的物体，使其成为实时分类、检测和分割应用的合适数据集。
- en: 3.5 Durham Baggage Anomaly Dataset –DBA
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 达勒姆行李异常数据集–DBA
- en: This in-house dataset comprises $230,275$ dual energy X-ray security image patches
    extracted via a $64\times 64$ overlapping sliding window approach. The dataset
    contains 3 abnormal sub-classes —knife ($63,496$), gun ($45,855$) and gun component
    ($13,452$). Normal class comprises $107,472$ benign X-ray patches, split via $80:20$
    train-test ratio. DBA dataset is used in [[89](#bib.bib89)] and [[90](#bib.bib90)]
    for unsupervised anomaly detection. Similar to DB dataset varians, this dataset
    is not publicly available, limiting its use in the literature.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这个内部数据集包含$230,275$个双能量X射线安全图像补丁，使用$64\times 64$的重叠滑动窗口方法提取。数据集包含3个异常子类——刀具（$63,496$）、枪支（$45,855$）和枪支组件（$13,452$）。正常类包含$107,472$个良性X射线补丁，按照$80:20$的训练-测试比例分割。DBA数据集在[[89](#bib.bib89)]和[[90](#bib.bib90)]中用于无监督异常检测。与DB数据集变体类似，该数据集不公开，限制了其在文献中的使用。
- en: 3.6 Full firearm vs Operational Benign –FFOB
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.6 完整火器与操作性良性–FFOB
- en: As presented in [[73](#bib.bib73), [89](#bib.bib89), [90](#bib.bib90), [91](#bib.bib91)],
    this dataset contains samples from the UK government evaluation dataset [[95](#bib.bib95)],
    comprising both expertly concealed firearm (threat) items and operational benign
    (non-threat) imagery from commercial X-ray security screening operations (baggage/parcels).
    Denoted as FFOB, this dataset comprises $4,680$ firearm full-weapons as full abnormal
    and $67,672$ operational benign as full normal images, respectively. The main
    drawback of this dataset is its restricted access.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如[[73](#bib.bib73), [89](#bib.bib89), [90](#bib.bib90), [91](#bib.bib91)]中所示，该数据集包含来自英国政府评估数据集[[95](#bib.bib95)]的样本，包括专家隐蔽的火器（威胁）物品和来自商业X射线安全筛查操作（行李/包裹）的操作性良性（非威胁）图像。该数据集标记为FFOB，包括$4,680$个完整火器作为完整异常和$67,672$个操作性良性作为完整正常图像。该数据集的主要缺点是访问受限。
- en: 3.7 Compass - XP Dataset
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.7 Compass - XP 数据集
- en: This dataset [[92](#bib.bib92)] is collected using $501$ objects from $369$
    object classes that are a subset of ImageNet classes. The dataset includes $1901$
    image pairs such that each pair has an X-ray image scanned with Gilardoni FEP
    ME 536 and its photographic version is taken with a Sony DSC-W800 digital camera.
    Besides, each X-ray image has its low-energy, high-energy, material density, grey-scale
    (the combination of low and high energy) and pseudo-coloured RGB versions. This
    dataset is well-suited to X-ray imaging research; however, its non-cluttered nature
    limits its use for real-time applications.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集 [[92](#bib.bib92)] 使用 $501$ 个物体从 $369$ 个对象类别中收集，这些类别是 ImageNet 类别的子集。数据集包括
    $1901$ 对图像，每对图像包含用 Gilardoni FEP ME 536 扫描的 X 光图像及其用 Sony DSC-W800 数码相机拍摄的照片版本。此外，每张
    X 光图像都有其低能量、高能量、材料密度、灰度（低能量和高能量的组合）和伪彩色 RGB 版本。该数据集非常适合 X 光成像研究，但其非混杂特性限制了其在实时应用中的使用。
- en: 3.8 OPIXray Dataset
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8 OPIXray 数据集
- en: OPIXray dataset [[96](#bib.bib96)] is an airport inspection dataset manually
    annotated by the security personnel. The dataset comprises 8885 X-ray images (7019
    training, 1776 testing) from five sharp objects, including folding knife (1,993),
    straight knife (1,044), scissor (1,863), utility knife (1,978) and multi-tool
    knife (2,042).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: OPIXray 数据集 [[96](#bib.bib96)] 是由安检人员手动标注的机场检查数据集。该数据集包含来自五种锐利物体的8885张X光图像（7019张训练图像，1776张测试图像），包括折叠刀（1,993）、直刀（1,044）、剪刀（1,863）、多功能刀（1,978）和多工具刀（2,042）。
- en: '| Dataset | Domain | Task | # Samples | Classes | Performance | Reference |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 领域 | 任务 | 样本数量 | 类别 | 性能 | 参考文献 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| DBP2 | Baggage | Classification | 19,938 | firearm, background | ACC: 0.994
    | [[23](#bib.bib23), [73](#bib.bib73)] |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| DBP2 | 行李 | 分类 | 19,938 | 枪支、背景 | ACC: 0.994 | [[23](#bib.bib23), [73](#bib.bib73)]
    |'
- en: '| DBP6 | Baggage | Classification | 10,137 | firearm, firearm parts, camera,
    | ACC: 0.937 | [[23](#bib.bib23), [73](#bib.bib73)] |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| DBP6 | 行李 | 分类 | 10,137 | 枪支、枪支部件、相机 | ACC: 0.937 | [[23](#bib.bib23), [73](#bib.bib73)]
    |'
- en: '|  |  |  |  | knife, ceramic knife, laptop |  |  |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | 刀、陶瓷刀、笔记本电脑 |  |  |'
- en: '| UCL TIP | Cargo | Classification | 120,000 | small metallic threat (SMT),
    car | ACC: 0.970 | [[65](#bib.bib65), [87](#bib.bib87), [67](#bib.bib67), [66](#bib.bib66),
    [88](#bib.bib88), [64](#bib.bib64)] |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| UCL TIP | 货物 | 分类 | 120,000 | 小型金属威胁（SMT）、汽车 | ACC: 0.970 | [[65](#bib.bib65),
    [87](#bib.bib87), [67](#bib.bib67), [66](#bib.bib66), [88](#bib.bib88), [64](#bib.bib64)]
    |'
- en: '|  |  | Detection |  |  |  |  |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 检测 |  |  |  |  |'
- en: '|  |  | Anomaly Detection |  |  |  |  |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 异常检测 |  |  |  |  |'
- en: '| GDXRay | Baggage | Classification | 19,407 | gun, shuriken, razor blade |
    ACC: 0.963 | [[24](#bib.bib24), [97](#bib.bib97), [70](#bib.bib70), [98](#bib.bib98)]
    |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| GDXRay | 行李 | 分类 | 19,407 | 枪支、飞镖、剃刀片 | ACC: 0.963 | [[24](#bib.bib24), [97](#bib.bib97),
    [70](#bib.bib70), [98](#bib.bib98)] |'
- en: '|  |  | Detection |  |  |  |  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 检测 |  |  |  |  |'
- en: '| DBF2 | Baggage | Detection | 15,449 | firearm, background | mAP: 0.974 |
    [[72](#bib.bib72), [73](#bib.bib73)] |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| DBF2 | 行李 | 检测 | 15,449 | 枪支、背景 | mAP: 0.974 | [[72](#bib.bib72), [73](#bib.bib73)]
    |'
- en: '| DBF6 | Baggage | Detection | 15,449 | firearm, firearm parts, camera, | mAP:
    0.885 | [[72](#bib.bib72), [73](#bib.bib73)] |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| DBF6 | 行李 | 检测 | 15,449 | 枪支、枪支部件、相机 | mAP: 0.885 | [[72](#bib.bib72), [73](#bib.bib73)]
    |'
- en: '|  |  |  |  | knife, ceramic knife, laptop |  |  |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | 刀、陶瓷刀、笔记本电脑 |  |  |'
- en: '| PBOD | Baggage | Classification | 9,520 | Explosives | AUC: 0.950 | [[99](#bib.bib99)]
    |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| PBOD | 行李 | 分类 | 9,520 | 爆炸物 | AUC: 0.950 | [[99](#bib.bib99)] |'
- en: '| MV-Xray | Baggage | Detection | 16,724 | Glass Bottle, TIP Weapon, Real Weapon
    | mAP: 0.956 | [[79](#bib.bib79)] |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| MV-Xray | 行李 | 检测 | 16,724 | 玻璃瓶、TIP 武器、真实武器 | mAP: 0.956 | [[79](#bib.bib79)]
    |'
- en: '| SASC | Baggage | Detection | 3,250 | Scissors, Aerosols | mAP: 0.945 | [[75](#bib.bib75)]
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| SASC | 行李 | 检测 | 3,250 | 剪刀、气雾剂 | mAP: 0.945 | [[75](#bib.bib75)] |'
- en: '| Zhao *et al.* | Baggage | Classification | 1,600 | wrench, pliers, blade,
    lighter, | ACC: 0.992 | [[69](#bib.bib69)] |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| Zhao *et al.* | 行李 | 分类 | 1,600 | 扳手、钳子、刀片、打火机 | ACC: 0.992 | [[69](#bib.bib69)]
    |'
- en: '|  |  |  |  | knife, screwdriver, hammer |  |  |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | 刀、螺丝刀、锤子 |  |  |'
- en: '| Smiths-Duke | Baggage | Detection | 16,312 | gun, pocket knife, mixed sharp
    | mAP: 0.938 | [[100](#bib.bib100)] |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| Smiths-Duke | 行李 | 检测 | 16,312 | 枪支、折叠刀、混合锐利物体 | mAP: 0.938 | [[100](#bib.bib100)]
    |'
- en: '| SIXray | Baggage | Detection | 1,059,231 | gun, knife, wrench, pliers, |
    mAP: 0.439 | [[71](#bib.bib71)] |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| SIXray | 行李 | 检测 | 1,059,231 | 枪支、刀、扳手、钳子 | mAP: 0.439 | [[71](#bib.bib71)]
    |'
- en: '|  |  |  |  | scissors, hammer, background |  |  |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | 剪刀、锤子、背景 |  |  |'
- en: '| UBA | Baggage | Anomaly Detection | 230,275 | gun, gun part, knife | AUC:
    0.940 | [[89](#bib.bib89), [90](#bib.bib90)] |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| UBA | 行李 | 异常检测 | 230,275 | 枪支、枪支部件、刀具 | AUC: 0.940 | [[89](#bib.bib89),
    [90](#bib.bib90)] |'
- en: '| FFOB | Baggage | Anomaly Detection | 72,352 | full-weapon, benign | ACC:
    0.998 | [[89](#bib.bib89), [90](#bib.bib90)] |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| FFOB | 行李 | 异常检测 | 72,352 | 全武器、良性 | ACC: 0.998 | [[89](#bib.bib89), [90](#bib.bib90)]
    |'
- en: '| Yang *et al.* | Baggage | Classification | 2,000 | wrench, fork, handgun,
    power bank, | ACC: 0.991 | [[101](#bib.bib101)] |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| Yang *et al.* | 行李 | 分类 | 2,000 | 扳手、叉子、手枪、移动电源 | ACC: 0.991 | [[101](#bib.bib101)]
    |'
- en: '|  |  |  |  | lighter, pliers, knife, liquid, umbrella, screwdriver |  |  |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | 打火机、钳子、刀具、液体、伞、螺丝刀 |  |  |'
- en: '| OPIXray | Baggage | Detection | 8,885 | Folding Knife, Straight Knife, |
    mAP: 0.753 | [[96](#bib.bib96)] |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| OPIXray | 行李 | 检测 | 8,885 | 折叠刀、直刀 | mAP: 0.753 | [[96](#bib.bib96)] |'
- en: '|  |  |  |  | lighter, Scissor, Utility Knife, Multi-tool Knife |  |  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | 打火机、剪刀、多功能刀 |  |  |'
- en: 'Table 1: Datasets used in deep learning applications within X-ray security
    imaging'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：用于深度学习应用的 X 射线安全成像数据集
- en: 4 Evaluation Criteria
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 评估标准
- en: Before reviewing the papers, it is essential to introduce the various performance
    metrics used in the field. All of the metrics shown here are computed based on
    true positives ($TP$), false positives ($FP$), true negatives ($TN$) and false
    negatives ($FN$).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在审阅论文之前，介绍领域内使用的各种性能指标是必要的。这里展示的所有指标都是基于真实阳性 ($TP$)、假阳性 ($FP$)、真实阴性 ($TN$) 和假阴性
    ($FN$) 计算的。
- en: Accuracy
  id: totrans-83
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 准确率
- en: (ACC) is defined as the number of correctly predicted samples over the the total
    number of predictions, which is mathematically shown as $ACC=(TP+TN)/(TP+TN+FP+FN)$.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: (ACC) 被定义为正确预测样本的数量与总预测数量的比值，数学表达为 $ACC=(TP+TN)/(TP+TN+FP+FN)$。
- en: True Positive Rate
  id: totrans-85
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 真实阳性率
- en: '(TPR) is the proportion of correctly predicted positive samples: $TPR=TP/(TP+FN)$'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: (TPR) 是正确预测的正样本比例： $TPR=TP/(TP+FN)$
- en: False Positive Rate
  id: totrans-87
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 假阳性率
- en: '(FPR) is calculated as the ratio of the negative samples predicted as positive:
    $FPR=FP/(FP+TN)$.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: (FPR) 被计算为预测为正样本的负样本比例： $FPR=FP/(FP+TN)$。
- en: Mean Average Precision
  id: totrans-89
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 平均平均精度
- en: (mAP) is defined as the mean of the average precision, a metric evaluated by
    the area under the precision and recall curve, where precision is $TP/(TP+FP)$,
    and recall is $TP/(FN+TP)$.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: (mAP) 被定义为平均精度的均值，这是通过精度和召回曲线下的面积来评估的指标，其中精度是 $TP/(TP+FP)$，召回率是 $TP/(FN+TP)$。
- en: Area Under the Curve
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 曲线下面积
- en: (AUC) is the area under the curve of the receiver operating characteristics
    (ROC), plotted by the true positive rates and false positives rates.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: (AUC) 是接收器操作特性（ROC）曲线下的面积，由真实阳性率和假阳性率绘制。
- en: 'Table [1](#S3.T1 "Table 1 ‣ 3.8 OPIXray Dataset ‣ 3 Datasets ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging") shows the benchmark statistics based on the datasets and evaluation
    criteria discussed in Sections [3](#S3 "3 Datasets ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")
    and [4](#S4 "4 Evaluation Criteria ‣ Towards Automatic Threat Detection: A Survey
    of Advances of Deep Learning within X-ray Security Imaging"). The best performing
    models will be explained in the following sections.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [1](#S3.T1 "表 1 ‣ 3.8 OPIXray 数据集 ‣ 3 数据集 ‣ 自动威胁检测：X射线安全成像中深度学习的进展调研") 显示了基于第
    [3](#S3 "3 数据集 ‣ 自动威胁检测：X射线安全成像中深度学习的进展调研") 和 [4](#S4 "4 评估标准 ‣ 自动威胁检测：X射线安全成像中深度学习的进展调研")
    节中讨论的数据集和评估标准的基准统计数据。表现最佳的模型将在接下来的部分中详细说明。
- en: 5 Conventional Image Analysis
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 传统图像分析
- en: This section explores the conventional image analysis techniques that perform
    image enhancement and threat image projection.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了执行图像增强和威胁图像投影的传统图像分析技术。
- en: 5.1 Image Enhancement
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 图像增强
- en: Preprocessing the input data plays a substantial role to yield higher-quality
    images that increase the readability by both screener and computer. Common approach
    in literature is to [[11](#bib.bib11)] fuse low and high energy X-ray images and
    apply background subtraction for noise reduction, followed by either manual [[27](#bib.bib27)]
    or adaptive [[28](#bib.bib28)] threshold selection. Pseudo-colouring [[11](#bib.bib11),
    [29](#bib.bib29), [102](#bib.bib102)] is another enhancement technique that colours
    grey scale X-ray images, improving the detection performance and alertness level
    of the operators.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对输入数据的预处理在生成更高质量的图像方面起着重要作用，从而提高了筛查者和计算机的可读性。文献中常见的方法是[[11](#bib.bib11)]融合低能量和高能量的X射线图像，并应用背景减法来减少噪声，然后进行手动[[27](#bib.bib27)]或自适应[[28](#bib.bib28)]阈值选择。伪彩色处理[[11](#bib.bib11),
    [29](#bib.bib29), [102](#bib.bib102)]是另一种增强技术，它为灰度X射线图像上色，提高了检测性能和操作员的警觉性。
- en: 5.2 Threat Image Projection
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 威胁图像投影
- en: Threat image projection (TIP) [[32](#bib.bib32)] is another method that could
    be categorised within conventional image analysis. TIP is used to generate a synthetic
    dataset to either train human screeners [[103](#bib.bib103)] or machine/deep learning
    models. A common TIP approach is to project a binary threat mask onto a benign
    input X-ray image via multiplication, yielding an output X-ray image with the
    threat item. Application of affine [[33](#bib.bib33)] or logarithmic [[34](#bib.bib34)]
    transformations adds various threat projections onto the benign image. Empirical
    studies show that the use of TIP improves the overall detection performance of
    models [[33](#bib.bib33), [34](#bib.bib34), [104](#bib.bib104)].
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 威胁图像投影（TIP）[[32](#bib.bib32)]是另一种可以归类于传统图像分析的方法。TIP用于生成合成数据集，以训练人工筛查员[[103](#bib.bib103)]或机器/深度学习模型。常见的TIP方法是通过乘法将二进制威胁掩模投影到良性输入X射线图像上，从而生成包含威胁项目的输出X射线图像。应用仿射[[33](#bib.bib33)]或对数[[34](#bib.bib34)]变换会在良性图像上添加各种威胁投影。实证研究表明，使用TIP可以提高模型的整体检测性能[[33](#bib.bib33),
    [34](#bib.bib34), [104](#bib.bib104)]。
- en: 6 Machine Learning Approaches in X-ray Security Imaging
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 X射线安全成像中的机器学习方法
- en: 'This section explores the applications of conventional machine learning approaches
    in X-ray security imaging. The literature is reviewed based on three tasks: classification,
    detection, and segmentation. For an alternative perspective for this section,
    the reader could refer to the related reviews of Mery [[93](#bib.bib93)] and Rogers
    *et al.*[[22](#bib.bib22)].'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了传统机器学习方法在X射线安全成像中的应用。根据分类、检测和分割三个任务来回顾文献。对于本节的另一种视角，读者可以参考Mery[[93](#bib.bib93)]和Rogers
    *et al.*[[22](#bib.bib22)]的相关综述。
- en: 6.1 Object Classification
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 对象分类
- en: Prior to the dominance of the deep learning within the field, the bag of visual
    words (BoVW) approach was prevalent. A common approach is to (i) perform feature
    extraction via detector/descriptors, (ii) cluster the features via k-means [[105](#bib.bib105),
    [38](#bib.bib38)] and (iii) classify RF[[106](#bib.bib106)], SVM [[107](#bib.bib107)]
    or sparse-representation [[38](#bib.bib38), [49](#bib.bib49), [39](#bib.bib39),
    [43](#bib.bib43), [42](#bib.bib42), [45](#bib.bib45), [46](#bib.bib46), [16](#bib.bib16),
    [15](#bib.bib15)].
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习主导该领域之前，视觉词袋（BoVW）方法曾经很流行。常见的方法是（i）通过检测器/描述符进行特征提取，（ii）通过k-means[[105](#bib.bib105),
    [38](#bib.bib38)]对特征进行聚类，（iii）对RF[[106](#bib.bib106)]、SVM[[107](#bib.bib107)]或稀疏表示[[38](#bib.bib38),
    [49](#bib.bib49), [39](#bib.bib39), [43](#bib.bib43), [42](#bib.bib42), [45](#bib.bib45),
    [46](#bib.bib46), [16](#bib.bib16), [15](#bib.bib15)]进行分类。
- en: 'Despite the BoVW dominance, other computer vision/machine learning techniques
    have also been studied for X-ray object classification task. Mery *et al.*[[49](#bib.bib49)]
    utilize structure estimation and segmentation together with a general tracking
    algorithm to detect X-ray objects. Similar works [[41](#bib.bib41), [54](#bib.bib54),
    [55](#bib.bib55), [62](#bib.bib62), [24](#bib.bib24), [108](#bib.bib108)] exhaustively
    evaluate various computer vision techniques, with a specific focus on k-NN based
    sparse representation, achieving comparable accuracy to deep models on [GDXray](#S3.SS2
    "3.2 GDXray ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging") ($94.7\%$ vs. $96.3\%$).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管BoVW主导了领域，其他计算机视觉/机器学习技术也被研究用于X射线目标分类任务。Mery *et al.*[[49](#bib.bib49)]结合结构估计和分割以及通用跟踪算法来检测X射线目标。类似的工作[[41](#bib.bib41)、[54](#bib.bib54)、[55](#bib.bib55)、[62](#bib.bib62)、[24](#bib.bib24)、[108](#bib.bib108)]详尽评估了各种计算机视觉技术，特别关注基于k-NN的稀疏表示，在[GDXray](#S3.SS2
    "3.2 GDXray ‣ 3 数据集 ‣ 自动威胁检测：X射线安全成像中深度学习的进展")上实现了与深度模型相当的准确度（$94.7\%$ 对比 $96.3\%$）。
- en: 6.2 Object Detection
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 目标检测
- en: This section reviews the conventional X-ray object detection models presented
    in the literature. Being a challenging task, where the bounding box coordinates
    and class labels are to be predicted simultaneously, conventional object detection
    algorithms in the literature is relatively limited in the field.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 本节回顾了文献中提出的传统X射线目标检测模型。由于是一个具有挑战性的任务，需要同时预测边界框坐标和类别标签，因此文献中的传统目标检测算法在这一领域相对有限。
- en: 'Similar to classification methods explored in Section [6.1](#S6.SS1 "6.1 Object
    Classification ‣ 6 Machine Learning Approaches in X-ray Security Imaging ‣ Towards
    Automatic Threat Detection: A Survey of Advances of Deep Learning within X-ray
    Security Imaging"), conventional detection algorithms also primarily employ BoVW
    approach. Evaluation works of [[57](#bib.bib57), [40](#bib.bib40), [18](#bib.bib18)]
    exhaustively investigate the use of BoVW for the X-ray object detection. Evaluating
    various feature descriptors with SVM classifier [[107](#bib.bib107)] shows that
    (i) sparse intensity domain image descriptor (SPIN) [[109](#bib.bib109)] achieves
    the highest detection performance (mAP: $46.1\%$).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '与第[6.1](#S6.SS1 "6.1 目标分类 ‣ 6 X射线安全成像中的机器学习方法 ‣ 自动威胁检测：X射线安全成像中深度学习的进展")节中探讨的分类方法类似，传统检测算法也主要采用BoVW方法。[[57](#bib.bib57)、[40](#bib.bib40)、[18](#bib.bib18)]的评估工作详尽地研究了BoVW在X射线目标检测中的应用。用SVM分类器[[107](#bib.bib107)]评估各种特征描述符显示，（i）稀疏强度域图像描述符（SPIN）[[109](#bib.bib109)]实现了最高的检测性能（mAP:
    $46.1\%$）。'
- en: Unlike classification, here the models also utilise multiple-view imagery, which
    generally improves the performance when rotation and superimposition hinder the
    viewability of the objects from one view [[110](#bib.bib110)]. Despite its computational
    complexity, multi-view imaging help human operators and machines to improve the
    detection performance [[111](#bib.bib111), [17](#bib.bib17), [18](#bib.bib18)].
    A general multi-staged approach proposed in the works of [[112](#bib.bib112),
    [50](#bib.bib50), [52](#bib.bib52), [48](#bib.bib48)] initially performs feature
    extraction via feature descriptors and k-NN classifier [[113](#bib.bib113)]. Features
    matched from different views are classified by the k-NN classifier [[113](#bib.bib113)]
    ($95.7\%$ precision).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 与分类不同，这里模型还利用了多视角图像，这通常能在旋转和叠加阻碍从一个视角看到目标时提高性能[[110](#bib.bib110)]。尽管其计算复杂性较高，多视角成像帮助人工操作员和机器提高检测性能[[111](#bib.bib111)、[17](#bib.bib17)、[18](#bib.bib18)]。[[112](#bib.bib112)、[50](#bib.bib50)、[52](#bib.bib52)、[48](#bib.bib48)]提出的一种通用多阶段方法首先通过特征描述符和k-NN分类器[[113](#bib.bib113)]进行特征提取。来自不同视角的匹配特征由k-NN分类器[[113](#bib.bib113)]进行分类（$95.7\%$精度）。
- en: 6.3 Object Segmentation
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 目标分割
- en: This section explores various segmentation techniques presented in the literature.
    Early work in the field [[58](#bib.bib58), [59](#bib.bib59)] investigates simplistic
    pixel-based segmentation with a fixed absolute threshold and region grouping.
    Subsequent work, on the other hand, focuses more on pre-segmentation via nearest
    neighbour, overlapping background removal and final classification [[60](#bib.bib60),
    [61](#bib.bib61), [13](#bib.bib13), [19](#bib.bib19), [20](#bib.bib20)].
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了文献中提出的各种分割技术。该领域的早期工作 [[58](#bib.bib58), [59](#bib.bib59)] 研究了基于像素的简单分割方法，使用固定的绝对阈值和区域分组。随后，更多的工作则专注于通过最近邻预分割、背景去除和最终分类
    [[60](#bib.bib60), [61](#bib.bib61), [13](#bib.bib13), [19](#bib.bib19), [20](#bib.bib20)]。
- en: Another approach is to utilize graph-based algorithms for the segmentation.
    Early work concentrates on fuzzy similarity distance between attribute relational
    graphs [[114](#bib.bib114), [61](#bib.bib61)], while more recent investigates
    spectral clustering and variational image segmentation [[115](#bib.bib115)].
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是利用基于图的算法进行分割。早期的工作集中在属性关系图之间的模糊相似度距离 [[114](#bib.bib114), [61](#bib.bib61)]，而最近的研究则探讨了光谱聚类和变分图像分割
    [[115](#bib.bib115)]。
- en: Despite the promising detection performance reported, these techniques are generally
    experimented on a small datasets, limiting their scalability for real-time applications.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管报告了有希望的检测性能，这些技术通常在小型数据集上进行实验，限制了它们在实时应用中的可扩展性。
- en: 7 Deep Learning in X-ray Security Imaging
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 X 射线安全成像中的深度学习
- en: 'This section reviews the X-ray security applications utilising deep learning
    algorithms. As shown in Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Towards
    Automatic Threat Detection: A Survey of Advances of Deep Learning within X-ray
    Security Imaging") and Table [2](#S7.T2 "Table 2 ‣ 7.2 Unsupervised Approaches
    ‣ 7 Deep Learning in X-ray Security Imaging ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging"), we categorise
    the algorithms as supervised (classification, detection and segmentation) and
    unsupervised (anomaly detection) approaches.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '本节回顾了利用深度学习算法的 X 射线安全应用。如图 [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Towards
    Automatic Threat Detection: A Survey of Advances of Deep Learning within X-ray
    Security Imaging") 和表 [2](#S7.T2 "Table 2 ‣ 7.2 Unsupervised Approaches ‣ 7 Deep
    Learning in X-ray Security Imaging ‣ Towards Automatic Threat Detection: A Survey
    of Advances of Deep Learning within X-ray Security Imaging") 所示，我们将算法分为监督（分类、检测和分割）和无监督（异常检测）方法。'
- en: 7.1 Supervised Approaches
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 监督学习方法
- en: Supervised approaches are grouped within classification, detection and segmentation
    tasks, where the models utilise the ground-truth global, bounding-box and pixel-wise
    labels, respectively.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习方法分为分类、检测和分割任务，其中模型分别使用地面真值全局、边界框和像素级标签。
- en: '![Refer to caption](img/1f6326cbbd18179ac52dd47cece3b7d1.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1f6326cbbd18179ac52dd47cece3b7d1.png)'
- en: 'Figure 4: An input X-ray image, and the outputs depending on the deep learning
    task, (a) classification via ResNet-50 [[116](#bib.bib116)], (b) detection with
    YOLOv3 [[117](#bib.bib117)] and segmentation via Mask RCNN [[118](#bib.bib118)]'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：一个输入的 X 射线图像，以及根据深度学习任务的输出，（a）通过 ResNet-50 进行分类 [[116](#bib.bib116)]，（b）使用
    YOLOv3 进行检测 [[117](#bib.bib117)] 和通过 Mask RCNN 进行分割 [[118](#bib.bib118)]。
- en: 7.1.1 Classification
  id: totrans-119
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.1 分类
- en: 'The study of [[23](#bib.bib23)] is one of the first research applying CNN to
    X-ray security imagery as a classification task, where the model predicts the
    global image label (Figure [4](#S7.F4 "Figure 4 ‣ 7.1 Supervised Approaches ‣
    7 Deep Learning in X-ray Security Imaging ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging")B). The authors
    examine the use of CNN via transfer learning to evaluate to what extent transfer
    learning helps classify X-ray objects within the problem domain, where the availability
    of the datasets is somewhat limited. Freezing AlexNet weights layer by layer on
    a two-class (gun vs. no-gun) X-ray classification problem shows that CNN significantly
    outperforms the BoVW approach (SIFT+SURF), trained with SVM or RF, even when the
    layers of the network are all frozen. Another set of experimentation analyses
    the use of CNN within a challenging 6-class classification problem, whose results
    show a great promise of the use of CNN in the field.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '研究[[23](#bib.bib23)]是首次将CNN应用于X射线安全图像分类任务的研究之一，其中模型预测全局图像标签（图 [4](#S7.F4 "Figure
    4 ‣ 7.1 Supervised Approaches ‣ 7 Deep Learning in X-ray Security Imaging ‣ Towards
    Automatic Threat Detection: A Survey of Advances of Deep Learning within X-ray
    Security Imaging")B）。作者检查了通过迁移学习使用CNN，以评估迁移学习在有限数据集情况下对X射线对象分类的帮助程度。在一个二分类（枪与非枪）X射线分类问题上逐层冻结AlexNet权重的实验表明，即使网络的所有层都被冻结，CNN也显著优于BoVW方法（SIFT+SURF），即使是训练有SVM或RF。另一组实验分析了CNN在具有挑战性的6类分类问题中的应用，其结果显示了CNN在该领域的巨大潜力。'
- en: 'A similar work [[25](#bib.bib25)] compares the use of deep learning against
    the conventional machine learning to classify non-empty cargo containers with
    cars or SMT. A multi-stage approach first classifies cargo containers as empty
    vs. non-empty. The second stage is the classification of cars from the containers
    classified as non-empty, achieved via oBIF + RF. By using [UCL TIP](#S3.SS3 "3.3
    UCL TIP ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging") dataset, the authors evaluate
    the performance of 9 and 19-layer networks [[63](#bib.bib63)] that are similar
    to [[119](#bib.bib119)] and [[120](#bib.bib120)], and show that even the worst-performing
    CNN outperforms the conventional machine learning approach (oBIF + RF).'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '一项类似的研究[[25](#bib.bib25)]对比了深度学习与传统机器学习在对装有汽车或SMT的非空货柜进行分类中的应用。该多阶段方法首先将货柜分类为空的和非空的。第二阶段是对被分类为非空的货柜中的汽车进行分类，采用了oBIF
    + RF方法。通过使用[UCL TIP](#S3.SS3 "3.3 UCL TIP ‣ 3 Datasets ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")数据集，作者评估了9层和19层网络[[63](#bib.bib63)]的性能，这些网络类似于[[119](#bib.bib119)]和[[120](#bib.bib120)]，并且显示出即使是性能最差的CNN也优于传统的机器学习方法（oBIF
    + RF）。'
- en: 'A follow-up work [[64](#bib.bib64)] further investigates the detection of cars
    from X-ray cargo images. A sliding window splits [UCL TIP](#S3.SS3 "3.3 UCL TIP
    ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep
    Learning within X-ray Security Imaging") images into patches. Authors then explore
    various features including intensity, oBIF [[121](#bib.bib121)], Pyramid of Histogram
    of Visual Words (PHOW) [[122](#bib.bib122)] and CNN features. Training these features
    on SVM [[107](#bib.bib107)], RF [[106](#bib.bib106)], and soft-max (CNN) shows
    that a RF classifier trained on the VGG-18 [[120](#bib.bib120)] features extracted
    from log-transform images achieves the highest performance (FPR: $0.22$%).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '后续研究[[64](#bib.bib64)]进一步探讨了从X射线货物图像中检测汽车的问题。一个滑动窗口将[UCL TIP](#S3.SS3 "3.3
    UCL TIP ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging")图像分割成多个块。作者随后探索了包括强度、oBIF [[121](#bib.bib121)]、视觉词直方图金字塔（PHOW）[[122](#bib.bib122)]以及CNN特征在内的各种特征。在SVM
    [[107](#bib.bib107)]、RF [[106](#bib.bib106)]和soft-max（CNN）上训练这些特征表明，基于VGG-18 [[120](#bib.bib120)]的RF分类器在从对数变换图像中提取的特征上训练，达到了最高的性能（FPR:
    $0.22$%）。'
- en: 'Additional work by Jaccard *et al.*[[65](#bib.bib65)] evaluate the impact of
    input types on CNN performance by training single-channel raw image and dual-channel
    data that contains the raw image and its log-transformed image on VGG [[120](#bib.bib120)]
    variants. The quantitive analysis demonstrates that VGG-19 model trained from
    scratch by using dual-channel raw and log-transformed images outperforms the other
    variants (AUC: $97\%$, FPR: $6\%$).'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 'Jaccard *等*[[65](#bib.bib65)] 的额外工作评估了输入类型对 CNN 性能的影响，通过在 VGG [[120](#bib.bib120)]
    变体上训练单通道原始图像和包含原始图像及其对数变换图像的双通道数据。定量分析表明，使用双通道原始图像和对数变换图像从头开始训练的 VGG-19 模型优于其他变体（AUC:
    $97\%$, FPR: $6\%$）。'
- en: 'Rogers *et al.*[[66](#bib.bib66)] explore the use of dual-energy X-ray images
    for automated threat detection. Authors investigate varying transformations applied
    to high-energy ($H$) and low-energy($L$) X-ray images captured via the dual-energy
    X-ray machine. Using [UCL TIP](#S3.SS3 "3.3 UCL TIP ‣ 3 Datasets ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging") dataset, 640,000 image patches are generated via a $256\times 256$ sliding-window.
    Training this dataset with a fixed VGG-19 network [[120](#bib.bib120)] with varying
    input channels, including single-channel ($H$), dual-channel($\{H,-\log{H}\}$,
    $\{-\log{H},-\log{L}\}$) and four-channels $(\{-\log{L},L,H,\allowbreak-\log{H}\})$
    shows that dual and four-channels always achieves superior detection performance
    compared to their single-channel variants (ACC: $95\%$–dual vs $90\%$–single).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 'Rogers *等*[[66](#bib.bib66)] 探讨了使用双能量 X 射线图像进行自动威胁检测。作者研究了应用于通过双能量 X 射线机拍摄的高能
    ($H$) 和低能 ($L$) X 射线图像的各种变换。使用 [UCL TIP](#S3.SS3 "3.3 UCL TIP ‣ 3 Datasets ‣ Towards
    Automatic Threat Detection: A Survey of Advances of Deep Learning within X-ray
    Security Imaging") 数据集，通过 $256\times 256$ 滑动窗口生成 640,000 个图像补丁。使用固定的 VGG-19 网络
    [[120](#bib.bib120)] 训练此数据集，输入通道包括单通道 ($H$)、双通道 ($\{H,-\log{H}\}$, $\{-\log{H},-\log{L}\}$)
    和四通道 $(\{-\log{L},L,H,\allowbreak-\log{H}\})$，结果显示双通道和四通道相比于单通道变体总是能实现更优的检测性能（ACC:
    $95\%$–双通道 vs $90\%$–单通道）。'
- en: Inspired by the limited availability of X-ray datasets, a three-stage algorithm
    by Zhao *et al.*[[69](#bib.bib69)] initially classifies and labels the input X-ray
    dataset via the angle information of the foreground objects extracted from the
    input image. The second stage generates new X-ray objects via an adversarial network
    similar to [[123](#bib.bib123)]. Additional use of [[124](#bib.bib124)] improves
    the quality of the generated images. Finally, a small classification network confirms
    whether the generated image belongs to the correct class. In a follow-up study,
    Yang *et al.*[[101](#bib.bib101)] further investigate the ways to improve the
    GAN training to produce better X-ray images. The quantitative evaluation shows
    that the proposed GAN approach in the paper generates visually superior prohibited
    items.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 受到 X 射线数据集有限可用性的启发，Zhao *等*[[69](#bib.bib69)] 提出了一个三阶段算法，该算法最初通过从输入图像中提取的前景物体的角度信息对输入
    X 射线数据集进行分类和标记。第二阶段通过类似于 [[123](#bib.bib123)] 的对抗网络生成新的 X 射线物体。额外使用 [[124](#bib.bib124)]
    可以提高生成图像的质量。最后，一个小型分类网络确认生成的图像是否属于正确的类别。在后续研究中，Yang *等*[[101](#bib.bib101)] 进一步探讨了改进
    GAN 训练以生成更好 X 射线图像的方法。定量评估显示，本文提出的 GAN 方法生成了视觉上优于的禁止物品。
- en: 'Miao *et al.*[[71](#bib.bib71)] introduce a model (CHR) to classify/detect
    X-ray images from [SIXray](#S3.SS4 "3.4 SIXray ‣ 3 Datasets ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging"). The model copes with class imbalance and clutter issue by extracting
    image features from three consecutive layers, where subsequent layers are upsampled
    and concatenated with the previous layers. A refinement function $g()$ removes
    the redundant information from the concatenated feature map. The objective of
    the work is to minimize the loss of the weighted sum of the classification of
    the refined mid-level features from the three consecutive layers ($\{h(\tilde{x}_{n}^{(l-1)}),\allowbreak
    h(\tilde{x}_{n}^{(l)}),h(\tilde{x}_{n}^{(l+1)})\}$). Training the model with the
    proposed loss yields $2.13\%$ mAP improvement when used with ResNet-101 on [SIXray](#S3.SS4
    "3.4 SIXray ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging") ($36.01$ vs. $38.14$). A similar
    approach [[96](#bib.bib96)] introduces a plug and play module that utilises edge
    and material information to localise objects via attention mechanism.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '缪 *等人*[[71](#bib.bib71)] 介绍了一种模型（CHR）用于分类/检测来自[SIXray](#S3.SS4 "3.4 SIXray
    ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep
    Learning within X-ray Security Imaging")的 X 射线图像。该模型通过从三个连续层中提取图像特征来处理类别不平衡和杂乱问题，其中后续层被上采样并与前一层连接。一个细化函数
    $g()$ 从连接的特征图中去除冗余信息。该工作的目标是最小化从三个连续层中细化的中级特征分类的加权总和的损失（$\{h(\tilde{x}_{n}^{(l-1)}),\allowbreak
    h(\tilde{x}_{n}^{(l)}),h(\tilde{x}_{n}^{(l+1)})\}$）。使用建议的损失训练模型时，在 [SIXray](#S3.SS4
    "3.4 SIXray ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging") 上与 ResNet-101 一起使用时，mAP 提升了 $2.13\%$
    （$36.01$ 对比 $38.14$）。类似的方法 [[96](#bib.bib96)] 介绍了一种即插即用的模块，利用边缘和材料信息通过注意机制来定位对象。'
- en: An evaluation work [[99](#bib.bib99)] investigates the use of CNN for the task
    of explosive detection. An initial stage process the input data by fixing the
    image size, cropping the irrelevant background object where $Z_{eff}=0$ and applying
    data augmentation transformations. Evaluation of random initialization vs. pre-training
    on VGG19[[120](#bib.bib120)], Xception [[125](#bib.bib125)], and InceptionV3 [[126](#bib.bib126)]
    networks shows that randomly initialized models achieves superior accuracy for
    binary classification task. To study the impact of intensity and Z-eff values
    on the performance, the authors train three VGG-19 networks on both intensity
    and Z-effective, the intensity only and Z-effective only. Training the model with
    only Z-eff is shown to yield the highest accuracy. The final set of experiments
    investigates localization via heatmaps and shows that pre-trained networks achieves
    superior performance since randomly initialized networks tend to overfit on small
    datasets.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 一项评估工作 [[99](#bib.bib99)] 调查了 CNN 在爆炸物检测任务中的应用。初始阶段通过固定图像大小、裁剪 $Z_{eff}=0$ 的不相关背景对象以及应用数据增强变换来处理输入数据。对随机初始化与在
    VGG19[[120](#bib.bib120)]、Xception [[125](#bib.bib125)] 和 InceptionV3 [[126](#bib.bib126)]
    网络上的预训练进行评估，结果表明随机初始化的模型在二分类任务中取得了更好的准确率。为了研究强度和 Z-eff 值对性能的影响，作者对强度和 Z-effective、仅强度和仅
    Z-effective 三个 VGG-19 网络进行了训练。结果表明，仅使用 Z-eff 训练的模型精度最高。最后一组实验通过热图调查定位，并表明预训练网络表现优越，因为随机初始化的网络往往在小数据集上过拟合。
- en: Caldwell *et al.*[[67](#bib.bib67)] study the generalisation capability of models
    trained with different datasets from various scanners. The authors create training
    and test splits from both single or multiple domains to investigate the impact
    of transferring between other modalities. Quantitative analysis reveals that transferring
    information is challenging due to unknown parameters of the scanners and generalisability
    of CNN to the unseen target dataset.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 卡德威尔 *等人*[[67](#bib.bib67)] 研究了在不同扫描仪的不同数据集上训练的模型的泛化能力。作者从单个或多个领域创建训练和测试拆分，以研究在其他模态之间转移的影响。定量分析揭示了由于扫描仪的未知参数和
    CNN 对未见目标数据集的泛化能力，信息转移是具有挑战性的。
- en: 7.1.2 Detection
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.2 检测
- en: This section explores CNN-based object detection algorithms by a categorisation
    of single and multi-view object detection.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 本节通过对单视图和多视图目标检测的分类来探讨基于 CNN 的目标检测算法。
- en: Single-View Detection
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 单视图检测
- en: 'After the success of CNN for classification, the work of [[72](#bib.bib72)]
    trains sliding-window based CNN, Faster RCNN [[127](#bib.bib127)] and R-FCN [[128](#bib.bib128)]
    models on [DBF2/6](#S3.SS1 "3.1 Durham Baggage (DB) Patch/Full Image Dataset ‣
    3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep
    Learning within X-ray Security Imaging") datasets for firearm and multi-class
    detection problems. Experiments demonstrate that Faster RCNN [[127](#bib.bib127)]
    with VGG16 [[120](#bib.bib120)] yield $88.3\%$ mAP on 6-class [DBF6](#S3.SS1 "3.1
    Durham Baggage (DB) Patch/Full Image Dataset ‣ 3 Datasets ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging") dataset, while R-FCN with ResNet-101 achieves the highest performance
    ($96.3$ mAP) on 2-class (gun vs no-gun) on [DBF2](#S3.SS1 "3.1 Durham Baggage
    (DB) Patch/Full Image Dataset ‣ 3 Datasets ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging") dataset.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '在CNN分类成功之后，[[72](#bib.bib72)] 的研究训练了基于滑动窗口的CNN、Faster RCNN [[127](#bib.bib127)]
    和 R-FCN [[128](#bib.bib128)] 模型，用于[DBF2/6](#S3.SS1 "3.1 Durham Baggage (DB) Patch/Full
    Image Dataset ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging")数据集上的火器和多类检测问题。实验表明，Faster RCNN
    [[127](#bib.bib127)] 与 VGG16 [[120](#bib.bib120)] 在 6 类 [DBF6](#S3.SS1 "3.1 Durham
    Baggage (DB) Patch/Full Image Dataset ‣ 3 Datasets ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")
    数据集上获得 $88.3\%$ 的 mAP，而 R-FCN 与 ResNet-101 在 2 类（枪 vs 无枪） [DBF2](#S3.SS1 "3.1
    Durham Baggage (DB) Patch/Full Image Dataset ‣ 3 Datasets ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging") 数据集上取得了最高的性能 ($96.3$ mAP)。'
- en: Sigman *et al.*[[129](#bib.bib129)] utilise an adversarial domain adaptation
    technique to match the distribution of the background of a sizeable unlabelled
    stream of commerce (SoC) dataset. By doing so helps to detect the objects in the
    SoC dataset by training a Faster RCNN [[127](#bib.bib127)] on a small labelled
    dataset.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Sigman *et al.*[[129](#bib.bib129)] 使用了对抗领域自适应技术，以匹配大量未标记的商业（SoC）数据集的背景分布。通过这种方式，帮助在小型标记数据集上训练
    Faster RCNN [[127](#bib.bib127)] 从而检测 SoC 数据集中的对象。
- en: Subramani *et al.*[[77](#bib.bib77)] investigate the use of SSD [[130](#bib.bib130)]
    and RetinaNet [[131](#bib.bib131)] trained on SIXray10 dataset, achieving $60.5\%$
    and $60.9\%$, respectively.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Subramani *et al.*[[77](#bib.bib77)] 研究了在 SIXray10 数据集上训练的 SSD [[130](#bib.bib130)]
    和 RetinaNet [[131](#bib.bib131)]，分别达到了 $60.5\%$ 和 $60.9\%$ 的性能。
- en: Liu *et al.*[[75](#bib.bib75)] also performs object detection via YOLOv2 [[117](#bib.bib117)]
    to detect scissors and aeorosols on SASC dataset. Training YOLO v2 for 6000 iterations
    yield $94.5\%$ average precision and $92.6\%$ recall rates with $68$ FPS run-time
    speed.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Liu *et al.*[[75](#bib.bib75)] 还通过 YOLOv2 [[117](#bib.bib117)] 进行目标检测，以检测 SASC
    数据集上的剪刀和气溶胶。训练 YOLO v2 经过 6000 次迭代获得了 $94.5\%$ 的平均精度和 $92.6\%$ 的召回率，并具有 $68$ FPS
    的运行速度。
- en: Cui and Oztan [[76](#bib.bib76)] argue that RetinaNet [[131](#bib.bib131)] achieves
    comparable detection performance, while being considerably faster than traditional
    sliding window classification when trained with 30,000 images synthetically generated
    via TIP with $5000$ X-ray cargo containers and $544$ firearms.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Cui 和 Oztan [[76](#bib.bib76)] 认为，RetinaNet [[131](#bib.bib131)] 在训练时可以获得与传统滑动窗口分类相媲美的检测性能，同时速度明显更快，训练所用的图像数量为
    30,000 张，这些图像是通过 TIP 合成生成的，涉及 $5000$ 个 X 光货物容器和 $544$ 个火器。
- en: 'Hassan *et al.*[[74](#bib.bib74)] proposes an object detection algorithm, whereby
    the RoI is generated via cascaded multi-scale structure tensors that extracts
    based on the variations of the orientations of the object. The extracted RoI is
    then passed into a CNN, which quantitatively and computationally outperforms RetinaNet,
    YOLOv2 and F-RCNN on [GDXray](#S3.SS2 "3.2 GDXray ‣ 3 Datasets ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging") and [SIXray](#S3.SS4 "3.4 SIXray ‣ 3 Datasets ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")
    datasets. A similar approach in [[78](#bib.bib78), [132](#bib.bib132)] produces
    contour-based object proposals, which are subsequently forward-passed into a CNN,
    achieving $96\%$ mAP on SIXray10 dataset.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 'Hassan *等* [[74](#bib.bib74)] 提出了一个目标检测算法，其中 RoI 通过级联的多尺度结构张量生成，这些张量基于对象方向的变化进行提取。提取的
    RoI 然后输入到 CNN 中，该 CNN 在 [GDXray](#S3.SS2 "3.2 GDXray ‣ 3 Datasets ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging") 和 [SIXray](#S3.SS4 "3.4 SIXray ‣ 3 Datasets ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")
    数据集上在定量和计算上超越了 RetinaNet、YOLOv2 和 F-RCNN。类似的方法在 [[78](#bib.bib78), [132](#bib.bib132)]
    中生成基于轮廓的对象提案，随后输入到 CNN 中，在 SIXray10 数据集上实现了 $96\%$ mAP。'
- en: 'Motivated by the lack of annotated X-ray datasets, Xu *et al.*[[70](#bib.bib70)],
    make use of attention mechanisms for the localization of threat materials. The
    first stage forward-passes an input and finds the corresponding class probability.
    The back-propagation step identifies the interconnected neurons activated during
    the decision of the output class. Activations from the first convolutional layer
    generate a heatmap. The final stage refines the activation map by normalizing
    the layers with the activations of the previous layer. Comparison against the
    traditional deconvolution method (mAP: $34.3\%$) shows that the proposed method
    achieves superior detection ($56.6\%$) without requiring bounding box information.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '受到缺乏注释 X 射线数据集的启发，徐 *等* [[70](#bib.bib70)] 利用注意力机制进行威胁材料的定位。第一阶段前向传播输入，找到相应的类别概率。反向传播步骤识别在输出类别决策过程中激活的相互连接的神经元。第一卷积层的激活生成热图。最终阶段通过将激活图层的前一层的激活进行归一化来细化激活图。与传统反卷积方法（mAP:
    $34.3\%$）相比，所提方法在不需要边界框信息的情况下实现了优越的检测（$56.6\%$）。'
- en: Similar to [[67](#bib.bib67)], generalisation capability of CNN is studied by
    Gaus *et al.*[[82](#bib.bib82)] by training/validating CNN on different datasets
    (DBF3 ($88\%$ mAP) $\rightarrow$ SIXray ($85\%$ mAP)).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 [[67](#bib.bib67)]，Gaus *等* [[82](#bib.bib82)] 通过在不同数据集上训练/验证 CNN 来研究 CNN
    的泛化能力（DBF3 ($88\%$ mAP) $\rightarrow$ SIXray ($85\%$ mAP)）。
- en: Multi-View Detection
  id: totrans-140
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 多视角检测
- en: There are number of papers utilising the multi-view X-ray imagery to improve
    the detection performance of their models. An evaluation work [[100](#bib.bib100)]
    explores the performance of F-RCNN, R-FCN [[128](#bib.bib128)] and SSD [[130](#bib.bib130)]
    within single/multi-view X-ray imagery. Utilizing OR-gate detection by merging
    object detection outputs from individual views shows that multi-view outperforms
    that of single-view ($0.938$ vs. $0.798$ when trained with R-FCN and ResNet-101).
    A two-stage approach by Liu *et al.*[[133](#bib.bib133)] first extracts foreground
    objects and subsequently utilises F-RCNN to detect $32,253$ subway X-ray images,
    with an mAP of $77\%$ for 6 object classes.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多论文利用多视角 X 射线图像来提高模型的检测性能。一项评估工作 [[100](#bib.bib100)] 探讨了 F-RCNN、R-FCN [[128](#bib.bib128)]
    和 SSD [[130](#bib.bib130)] 在单视角/多视角 X 射线图像中的表现。通过合并来自各个视角的目标检测输出来利用 OR 门检测，显示多视角的表现优于单视角（$0.938$
    对比 $0.798$，当使用 R-FCN 和 ResNet-101 进行训练时）。刘 *等* [[133](#bib.bib133)] 提出的一种两阶段方法首先提取前景对象，然后利用
    F-RCNN 检测 $32,253$ 张地铁 X 射线图像，对 6 类对象的 mAP 达到 $77\%$。
- en: A similar study [[80](#bib.bib80)] explores SSD and F-RCNN by training on a
    dataset containing 4 threat classes, each of which comprises approximately $3,400$
    images. F-RCNN with Inception ResNet v2 backbone yields the highest mAP ($92.2$
    and $97.7$ on single and multi-view images, respectively). Another work [[79](#bib.bib79)]
    utilize multi-view by modifying F-RCNN. A multi-view pooling layer constructs
    3D feature 2D extracted from the convolutional layers. 3D region proposal network
    generates the RoI. Classification and bounding box prediction is performed after
    3D RoI pooling layer. Experiments show that multi-view yields an improvement compared
    to single-view imagery ($95.56\%$ vs. $91.23\%$).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 一项类似的研究 [[80](#bib.bib80)] 通过在包含 4 个威胁类别的数据集上训练 SSD 和 F-RCNN，每个类别大约包含 $3,400$
    张图像。以 Inception ResNet v2 为骨干网络的 F-RCNN 在单视角和多视角图像上的 mAP 分别达到了 $92.2$ 和 $97.7$。另一项研究
    [[79](#bib.bib79)] 通过修改 F-RCNN 利用多视角。多视角池化层构建了从卷积层提取的 3D 特征 2D。3D 区域提议网络生成 RoI。在
    3D RoI 池化层之后进行分类和边界框预测。实验表明，与单视角图像相比，多视角图像带来了改进（$95.56\%$ 对比 $91.23\%$）。
- en: 'Isaac-Medina *et al.*[[81](#bib.bib81)] train a YOLOv3 [[117](#bib.bib117)]
    detector by utilising epipolar constraints of multiple-views of X-ray images,
    which outperforms the single-view by 2.2% (Figure [4](#S7.F4 "Figure 4 ‣ 7.1 Supervised
    Approaches ‣ 7 Deep Learning in X-ray Security Imaging ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")C).'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 'Isaac-Medina *等人*[[81](#bib.bib81)] 利用 X 射线图像的多视角极点约束训练了一个 YOLOv3 [[117](#bib.bib117)]
    检测器，其性能比单视角高出 2.2%（图 [4](#S7.F4 "Figure 4 ‣ 7.1 Supervised Approaches ‣ 7 Deep
    Learning in X-ray Security Imaging ‣ Towards Automatic Threat Detection: A Survey
    of Advances of Deep Learning within X-ray Security Imaging")C）。'
- en: Overall, these results suggest that the use of multiple-view imagery aids improving
    the detection performance of the deep learning models.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这些结果表明，使用多视角图像有助于提高深度学习模型的检测性能。
- en: 7.1.3 Segmentation
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.3 分割
- en: 'Due to the scarcity of datasets with pixel-level annotation, the task of segmentation
    is understudied within the field. One of the published work [[83](#bib.bib83)]
    addresses segmentation and anomaly detection tasks together, whereby a dual-CNN
    pipeline initially segments RoI via Mask RCNN [[118](#bib.bib118)] and classifies
    the regions as benign/abnormal via ResNet-18 [[116](#bib.bib116)], achieving $97.6\%$
    segmentation mAP and $66.0\%$ anomaly detection accuracy (Figure [4](#S7.F4 "Figure
    4 ‣ 7.1 Supervised Approaches ‣ 7 Deep Learning in X-ray Security Imaging ‣ Towards
    Automatic Threat Detection: A Survey of Advances of Deep Learning within X-ray
    Security Imaging")D). Another work [[134](#bib.bib134)] proposes three-stage approach,
    whereby (i) object-level segmentation is achieved by the use of Mask RCNN [[118](#bib.bib118)],
    (ii) sub-component regions are segmented via super-pixel segmentation and (iii)
    final object classification is performed via fine-grained CNN classification,
    which overall yields $97.91\%$ anomaly detection accuracy on $7,878$ electronic
    items. An *et al.*[[135](#bib.bib135)] propose a segmentation model that utilises
    dual attention mechanism within an encoder-decoder segmentation network. The former
    attention module classifies the RoI, while the latter localises the object. Experiments
    on PASCAL alike structured X-ray dataset containing $7,532$ augmented images from
    7-classes yield $99.3$ accuracy and $68.3$ mean intersection over union (mIoU).'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '由于缺乏像素级标注的数据集，分割任务在该领域中研究较少。发布的一个研究 [[83](#bib.bib83)] 将分割和异常检测任务结合起来，其中双 CNN
    流水线首先通过 Mask RCNN [[118](#bib.bib118)] 对 RoI 进行分割，然后通过 ResNet-18 [[116](#bib.bib116)]
    将这些区域分类为良性/异常，达到了 $97.6\%$ 的分割 mAP 和 $66.0\%$ 的异常检测准确率（图 [4](#S7.F4 "Figure 4
    ‣ 7.1 Supervised Approaches ‣ 7 Deep Learning in X-ray Security Imaging ‣ Towards
    Automatic Threat Detection: A Survey of Advances of Deep Learning within X-ray
    Security Imaging")D）。另一项工作 [[134](#bib.bib134)] 提出了三阶段方法，其中 (i) 通过使用 Mask RCNN
    [[118](#bib.bib118)] 实现对象级分割，(ii) 通过超像素分割分割子组件区域，(iii) 通过细粒度 CNN 分类进行最终对象分类，总体上在
    $7,878$ 个电子物品上实现了 $97.91\%$ 的异常检测准确率。*等人*[[135](#bib.bib135)] 提出了一个利用编码-解码分割网络中双重注意力机制的分割模型。前一个注意力模块对
    RoI 进行分类，而后一个则对对象进行定位。在 PASCAL 类似结构的 X 射线数据集上进行实验，该数据集包含来自 7 个类别的 $7,532$ 张增强图像，取得了
    $99.3$ 的准确率和 $68.3$ 的平均交集比例（mIoU）。'
- en: Hassan *et al.*[[84](#bib.bib84)] propose a single-stage instance segmentation
    algorithm. The method initially extracts transitional patterns via trainable structure
    tensors, which are subsequently passed to an encoder-decoder to construct the
    binary segmentation masks. mAP evaluation on GDXray ($96.7$), SIXray ($96.16$),
    OPIXray($75.32$) and COMPASS XP ($58.4$) datasets show that the model achieves
    the state-of-the-art instance segmentation performance on benchmarks.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**Hassan et al.**[[84](#bib.bib84)]提出了一种单阶段实例分割算法。该方法首先通过可训练的结构张量提取过渡模式，然后将其传递给编码器-解码器以构建二进制分割掩码。在GDXray（$96.7$）、SIXray（$96.16$）、OPIXray（$75.32$）和COMPASS
    XP（$58.4$）数据集上的mAP评估显示，该模型在基准测试中达到了最先进的实例分割性能。'
- en: 7.2 Unsupervised Approaches
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 无监督方法
- en: This section explores unsupervised deep learning models, where the proposed
    algorithms mainly investigate the anomaly detection task. Human operators tend
    to perform better detection when focusing on benign objects rather than threat
    items. Besides, the knowledge of every-day benign objects leads to a much better
    detection performance [[136](#bib.bib136)]. The same concept is applied in anomaly
    detection, where the model is only trained with normal samples, and tested on
    normal/abnormal examples.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了无监督深度学习模型，其中提出的算法主要研究异常检测任务。当人类操作员专注于正常物体而非威胁项目时，检测表现往往更好。此外，对日常正常物体的了解也会导致更好的检测性能[[136](#bib.bib136)]。相同的概念应用于异常检测，其中模型仅用正常样本进行训练，并在正常/异常示例上进行测试。
- en: An anomaly detection approach [[86](#bib.bib86)] employs sparse feed-forward
    autoencoders in an unsupervised manner to learn the feature encoding of normal
    and abnormal data. An SVM [[107](#bib.bib107)] then classifies the images either
    anomalous or benign. Validation on MNIST [[137](#bib.bib137)] and freight container
    dataset (empty vs non-empty) shows that hidden layer representation extracted
    from the autoencoder, is significant for the detection of abnormalities in the
    images. When fused with the raw-input and residual error, features encoding from
    the hidden layers yield even better detection performance.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 一种异常检测方法[[86](#bib.bib86)]采用稀疏前馈自编码器以无监督方式学习正常和异常数据的特征编码。然后，使用SVM[[107](#bib.bib107)]对图像进行分类，将其分为异常或正常。对MNIST[[137](#bib.bib137)]和货物集装箱数据集（空的与非空的）进行的验证表明，从自编码器中提取的隐藏层表示对于图像中异常的检测具有重要意义。当与原始输入和残差误差融合时，来自隐藏层的特征编码能提供更好的检测性能。
- en: 'A follow-up work utilizes intensity, log-intensity and VGG-19 [[120](#bib.bib120)]
    features extracted from patches from [UCL TIP](#S3.SS3 "3.3 UCL TIP ‣ 3 Datasets
    ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging") dataset and train normal images via forest of random
    split trees anomaly detector [[138](#bib.bib138)]. Testing the model on normal
    + abnormal data yields $64$% AUC.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '后续工作利用从[UCL TIP](#S3.SS3 "3.3 UCL TIP ‣ 3 Datasets ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")数据集中提取的强度、对数强度和VGG-19[[120](#bib.bib120)]特征，通过随机分裂树森林异常检测器[[138](#bib.bib138)]对正常图像进行训练。在正常+异常数据上测试该模型，得到$64$%的AUC。'
- en: 'A similar study [[89](#bib.bib89)], in which image and latent vector spaces
    are optimized for anomaly detection, utilizes an adversarial network such that
    the generator comprises encoder-decoder-encoder sub-networks. The objective of
    the model is to minimize the distance between both real/generated images and their
    latent representations jointly, which overall outperforms the previous state-of-the-art
    both statistically and computationally ([UBA](#S3.SS5 "3.5 Durham Baggage Anomaly
    Dataset –DBA ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging"): $64.3\%$, [FFOB](#S3.SS6 "3.6
    Full firearm vs Operational Benign –FFOB ‣ 3 Datasets ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging"):
    $88.2\%$ – AUC). A follow-up work [[90](#bib.bib90)] improves the performance
    of [[89](#bib.bib89)] further by (i) utilizing skip-connections in the generator
    network to cope with higher resolution images, and (ii) learning the latent representations
    within the discriminator network ([UBA](#S3.SS5 "3.5 Durham Baggage Anomaly Dataset
    –DBA ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances of
    Deep Learning within X-ray Security Imaging"): $94.0\%$, [FFOB](#S3.SS6 "3.6 Full
    firearm vs Operational Benign –FFOB ‣ 3 Datasets ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging"): $90.3\%$
    – AUC).'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '一项类似的研究[[89](#bib.bib89)]，在其中图像和潜在向量空间被优化用于异常检测，利用了对抗网络，使得生成器包含编码器-解码器-编码器子网络。该模型的目标是联合最小化真实/生成图像与其潜在表示之间的距离，整体上在统计和计算上都优于之前的最新技术（[UBA](#S3.SS5
    "3.5 Durham Baggage Anomaly Dataset –DBA ‣ 3 Datasets ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging"):
    $64.3\%$, [FFOB](#S3.SS6 "3.6 Full firearm vs Operational Benign –FFOB ‣ 3 Datasets
    ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging"): $88.2\%$ – AUC）。后续工作[[90](#bib.bib90)]进一步提高了[[89](#bib.bib89)]的性能，通过（i）在生成器网络中使用跳跃连接以应对更高分辨率的图像，以及（ii）在鉴别器网络中学习潜在表示（[UBA](#S3.SS5
    "3.5 Durham Baggage Anomaly Dataset –DBA ‣ 3 Datasets ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging"):
    $94.0\%$, [FFOB](#S3.SS6 "3.6 Full firearm vs Operational Benign –FFOB ‣ 3 Datasets
    ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging"): $90.3\%$ – AUC）。'
- en: '| Reference | Domain | Problem | Method |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 领域 | 问题 | 方法 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Akçay *et al.*[[23](#bib.bib23)] | Baggage | Object Classification | CNN
    with transfer learning |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| Akçay *等*[[23](#bib.bib23)] | 行李 | 物体分类 | 使用迁移学习的CNN |'
- en: '| Svec [[62](#bib.bib62)] | Baggage | Object Classification | CNN with transfer
    learning |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| Svec [[62](#bib.bib62)] | 行李 | 物体分类 | 使用迁移学习的CNN |'
- en: '| Andrews *et al.*[[88](#bib.bib88)] | Cargo | Anomaly Detection | Train CNN
    features with Random Split Trees |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| Andrews *等*[[88](#bib.bib88)] | 货物 | 异常检测 | 用随机分裂树训练CNN特征 |'
- en: '| Jaccard *et al.*[[25](#bib.bib25)] | Cargo | Object Classification | oBIF+RF
    for non-empty cargo detection, followed by CNN for car detection |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| Jaccard *等*[[25](#bib.bib25)] | 货物 | 物体分类 | 使用oBIF+RF进行非空货物检测，然后用CNN进行汽车检测
    |'
- en: '| Jaccard *et al.*[[63](#bib.bib63)] | Cargo | Object Classification | CNN
    from scratch outperforms RF |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| Jaccard *等*[[63](#bib.bib63)] | 货物 | 物体分类 | 从头开始的CNN优于RF |'
- en: '| Rogers *et al.*[[66](#bib.bib66)] | Cargo | Object Classification | Evaluation
    of high and low energy x-ray imagery |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| Rogers *等*[[66](#bib.bib66)] | 货物 | 物体分类 | 高低能量X射线图像的评估 |'
- en: '| Caldwell *et al.*[[67](#bib.bib67)] | Cargo, Baggage | Object Classification
    | Transferability between domains |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Caldwell *等*[[67](#bib.bib67)] | 货物，行李 | 物体分类 | 领域间的可迁移性 |'
- en: '| Yuan and Gui [[68](#bib.bib68)] | Tera Hertz | Object Classification | Two-stage.
    Classify from RGB, then Tera-Hertz images. |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| Yuan 和 Gui [[68](#bib.bib68)] | 太赫兹 | 物体分类 | 两阶段。首先对RGB图像进行分类，然后对太赫兹图像进行分类。
    |'
- en: '| Zhao *et al.*[[69](#bib.bib69)] | Baggage | Image Generation, | Generate
    X-ray objects via GAN, and classify with CNN |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| Zhao *等*[[69](#bib.bib69)] | 行李 | 图像生成 | 通过GAN生成X射线物体，并使用CNN进行分类 |'
- en: '|  |  | Object Classification |  |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 物体分类 |  |'
- en: '| Yang *et al.*[[101](#bib.bib101)] | Baggage | Image Generation | Generate
    X-ray objects via GAN, and classify with CNN |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| Yang *等*[[101](#bib.bib101)] | 行李 | 图像生成 | 通过GAN生成X射线物体，并使用CNN进行分类 |'
- en: '|  |  | Object Classification |  |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 物体分类 |  |'
- en: '| Miao *et al.*[[71](#bib.bib71)] | Baggage | Object Classification | with
    class-balanced hierarchical refinement |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| Miao *等*[[71](#bib.bib71)] | 行李 | 物体分类 | 使用类别平衡的层次细化 |'
- en: '| Morris *et al.*[[99](#bib.bib99)] | Baggage | Object Classification | Region-based
    detection with Z-effective |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| Morris *等人*[[99](#bib.bib99)] | 行李 | 目标分类 | 基于区域的检测与 Z-effective |'
- en: '| Akçay and Breckon [[72](#bib.bib72)] | Baggage | Object Detection | Object
    Detection, Faster-RCNN is the best. |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| Akçay 和 Breckon [[72](#bib.bib72)] | 行李 | 目标检测 | 目标检测，Faster-RCNN 最佳。 |'
- en: '| Liang *et al.*[[100](#bib.bib100)] | Baggage | Object Detection | RFCN is
    the best. Multi-view outperforms single view. |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| Liang *等人*[[100](#bib.bib100)] | 行李 | 目标检测 | RFCN 最佳。多视角优于单视角。 |'
- en: '| Liang *et al.*[[80](#bib.bib80)] | Baggage | Object Detection | Explores
    various detection algorithms, F-RCNN with Inception ResNet v2 achieves the highest
    performance |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| Liang *等人*[[80](#bib.bib80)] | 行李 | 目标检测 | 探索各种检测算法，F-RCNN 与 Inception ResNet
    v2 实现了最佳性能 |'
- en: '| Steitz *et al.*[[79](#bib.bib79)] | Baggage | Object Detection | F-RCNN with
    multi view pooling is superior to single view only. |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| Steitz *等人*[[79](#bib.bib79)] | 行李 | 目标检测 | 具有多视角池化的 F-RCNN 优于单视角。 |'
- en: '| Liu *et al.*[[75](#bib.bib75)] | Baggage | Object Detection | YOLOv2 achieves
    real time performance. |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| Liu *等人*[[75](#bib.bib75)] | 行李 | 目标检测 | YOLOv2 实现了实时性能。 |'
- en: '| Xu *et al.*[[70](#bib.bib70)] | Baggage | Object Detection | Localizes the
    threat material from the X-ray images via attention mechanisms |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| Xu *等人*[[70](#bib.bib70)] | 行李 | 目标检测 | 通过注意力机制从 X 射线图像中定位威胁材料 |'
- en: '| Islam *et al.*[[139](#bib.bib139)] | Baggage | Object Detection | track passengers
    and their belongings in airports while passing X-ray security checkpoints |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| Islam *等人*[[139](#bib.bib139)] | 行李 | 目标检测 | 跟踪机场的乘客及其行李，经过 X 射线安检点时进行检测
    |'
- en: '| Liu *et al.*[[133](#bib.bib133)] | Baggage | Object Detection | Foreground
    object segmentation via material info, followed by a F-RCNN |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| Liu *等人*[[133](#bib.bib133)] | 行李 | 目标检测 | 通过材料信息进行前景对象分割，然后使用 F-RCNN |'
- en: '| Gauss *et al.*[[82](#bib.bib82)] | Baggage | Object Detection | F-RCNN to
    investigate the tranferrability between various X-ray scanners. |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| Gauss *等人*[[82](#bib.bib82)] | 行李 | 目标检测 | F-RCNN 调查各种 X 射线扫描仪之间的可迁移性。 |'
- en: '| Cui and Oztan [[76](#bib.bib76)] | Baggage | Object Detection | RetinaNet
    trained on a TIP dataset achieves considerable faster detection than sliding window
    CNN. |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| Cui 和 Oztan [[76](#bib.bib76)] | 行李 | 目标检测 | 在 TIP 数据集上训练的 RetinaNet 比滑动窗口
    CNN 检测速度更快。 |'
- en: '| Hassan *et al.*[[74](#bib.bib74)] | Baggage | Object Detection | RoI are
    extracted via cascaded multiscale structure tensors, which are then classified
    via a CNN |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Hassan *等人*[[74](#bib.bib74)] | 行李 | 目标检测 | 通过级联多尺度结构张量提取 RoI，然后通过 CNN 进行分类
    |'
- en: '| Bhowmik *et al.*[[104](#bib.bib104)] | Baggage | Object Detection | Explores
    the generalisation capability of the models trained on TIP datasets. |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| Bhowmik *等人*[[104](#bib.bib104)] | 行李 | 目标检测 | 探索在 TIP 数据集上训练的模型的泛化能力。'
- en: '| Andrews *et al.*[[86](#bib.bib86)] | Cargo | Anomaly Detection | Fusion of
    the raw-input and residual error with feature encoding from the hidden layers.
    |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| Andrews *等人*[[86](#bib.bib86)] | 货物 | 异常检测 | 原始输入与隐藏层特征编码的残差误差融合。 |'
- en: '| Akçay *et al.*[[89](#bib.bib89)] | Baggage | Anomaly Detection | encoder-
    decoder-encoder sub-networks. Minimize latent vector and image space. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| Akçay *等人*[[89](#bib.bib89)] | 行李 | 异常检测 | 编码器-解码器-编码器子网络。最小化潜在向量和图像空间。 |'
- en: '| Akçay *et al.*[[90](#bib.bib90)] | Baggage | Anomaly Detection | Use of skip
    connections. Minimize latent vector in the discriminator network. |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| Akçay *等人*[[90](#bib.bib90)] | 行李 | 异常检测 | 使用跳跃连接。最小化鉴别网络中的潜在向量。 |'
- en: '| Griffin *et al.*[[91](#bib.bib91)] | Baggage | Anomaly Detection | Feature
    Extraction with CNN, then train with Gaussian model. |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| Griffin *等人*[[91](#bib.bib91)] | 行李 | 异常检测 | 使用 CNN 提取特征，然后用高斯模型进行训练。 |'
- en: '| Gauss *et al.*[[83](#bib.bib83)] | Baggage | Object Segmentation | Mask-RCNN
    to segment RoI, and CNN classification for anomaly detection |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| Gauss *等人*[[83](#bib.bib83)] | 行李 | 目标分割 | 使用 Mask-RCNN 分割 RoI，并用 CNN 分类进行异常检测
    |'
- en: '| Bhowmik *et al.*[[134](#bib.bib134)] | Baggage | Object Segmentation | Mask-RCNN
    to segment RoI, superpixel for sub-component level analysis, fine-grained CNN
    for classification |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| Bhowmik *等人*[[134](#bib.bib134)] | 行李 | 目标分割 | 使用 Mask-RCNN 分割 RoI，超像素用于子组件级分析，细粒度
    CNN 进行分类 |'
- en: '| An *et al.*[[140](#bib.bib140)] | Baggage | Object Segmentation | Dual attention
    mechanism within an encoder decoder segmentation network. |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| An *等人*[[140](#bib.bib140)] | 行李 | 目标分割 | 在编码器-解码器分割网络中使用双重注意力机制。 |'
- en: 'Table 2: Overview of deep learning approaches applied within X-ray security
    imaging.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：X 射线安检图像中应用的深度学习方法概述。
- en: 'Another anomaly detection algorithm [[91](#bib.bib91)] (i) first extract the
    feature of the normal images from Inception v3 [[141](#bib.bib141)] alike network,
    (ii) subsequently trains a multivariate Gaussian model to capture the normal distribution
    of [CAST](#S3.SS6 "3.6 Full firearm vs Operational Benign –FFOB ‣ 3 Datasets ‣
    Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging") dataset. Anomaly score of a test sample is based on its
    likelihood that is relative to the model, which overall yields $92.5\%$ AUC.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '另一种异常检测算法 [[91](#bib.bib91)] (i) 首先从类似Inception v3 [[141](#bib.bib141)] 的网络中提取正常图像的特征，(ii)
    随后训练一个多变量高斯模型来捕捉[CAST](#S3.SS6 "3.6 Full firearm vs Operational Benign –FFOB ‣
    3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep
    Learning within X-ray Security Imaging") 数据集的正常分布。测试样本的异常得分基于其相对于模型的可能性，总体上得到$92.5\%$
    AUC。'
- en: 8 Discussion and Future Directions
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 讨论与未来方向
- en: Despite the promising performance of the proposed approaches, there are still
    some identifiable limitations. This section discusses the challenges and future
    directions based on the weaknesses and strengths of the current approaches presented
    in this paper and the broader literature including concurrent work to that presented
    here.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管提出的方法表现出色，但仍存在一些可识别的限制。本节讨论了基于当前方法的优缺点以及相关文献（包括与本文相关的并行工作）的挑战和未来方向。
- en: Dataset
  id: totrans-192
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据集
- en: 'Although the use of transfer learning improves the performance of small X-ray
    datasets, the lack of large datasets limits contemporary deep model training.
    Relatively large datasets in the field such as [SIXray](#S3.SS4 "3.4 SIXray ‣
    3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep
    Learning within X-ray Security Imaging"), [FFOB](#S3.SS6 "3.6 Full firearm vs
    Operational Benign –FFOB ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A
    Survey of Advances of Deep Learning within X-ray Security Imaging") are highly
    biased towards certain classes, limiting to train reliable supervised methods.
    Hence, it is essential to build large, homogeneous, realistic and publicly available
    datasets, collected either by (i) manually scanning numerous bags with different
    objects and orientations in a lab environment or (ii) generating synthetic datasets
    via contemporary algorithms.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管迁移学习提高了小型X射线数据集的性能，但缺乏大型数据集限制了当代深度模型的训练。领域内相对较大的数据集如[SIXray](#S3.SS4 "3.4
    SIXray ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging")、[FFOB](#S3.SS6 "3.6 Full firearm
    vs Operational Benign –FFOB ‣ 3 Datasets ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging") 在某些类别上高度偏倚，限制了训练可靠的监督方法。因此，必须建立大型的、同质的、现实的且公开可用的数据集，这些数据集可以通过
    (i) 在实验室环境中手动扫描不同物体和方向的多个包，或 (ii) 通过现代算法生成合成数据集来收集。'
- en: There are advantages and disadvantages of both methods. Although manual data
    collection enables to gather realistic samples with the flexibility to produce
    any combination, it is rather expensive, requiring tremendous human effort and
    time.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 两种方法各有优缺点。尽管手动数据收集可以获取现实样本并具有灵活性以生成任意组合，但它相当昂贵，需要大量的人力和时间。
- en: Synthetic dataset generation, on that hand, is another method, currently achieved
    by TIP [[33](#bib.bib33), [34](#bib.bib34)] or GAN [[69](#bib.bib69), [101](#bib.bib101)].
    A recent study [[104](#bib.bib104)] empirically demonstrates that using a TIP
    dataset for a detection task adversely impacts the detection performance on real
    examples. In future work, therefore, more advanced algorithms such as image translation
    or domain adaptation [[124](#bib.bib124), [142](#bib.bib142)] could be considered
    such that the model would learn to translate between benign and threat domains,
    which overall would yield superior projection/translation to TIP.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据集生成则是另一种方法，目前由TIP [[33](#bib.bib33), [34](#bib.bib34)] 或GAN [[69](#bib.bib69),
    [101](#bib.bib101)] 实现。近期的研究 [[104](#bib.bib104)] 实证表明，使用TIP数据集进行检测任务会对真实样本的检测性能产生负面影响。因此，未来的工作中可以考虑更先进的算法，如图像翻译或领域适应
    [[124](#bib.bib124), [142](#bib.bib142)]，使得模型能够学习在良性和威胁领域之间进行翻译，从而整体上比TIP更具优越的投影/翻译效果。
- en: The literature has also seen another type of synthetic datasets generated by
    GAN algorithms. The limitation of current GAN datasets [[69](#bib.bib69), [101](#bib.bib101)],
    however, is that the models are currently incapable of producing full X-ray images.
    Moreover, the quality of the generated images is far from being realistic. Further
    studies, taking these issues into account, will need to be undertaken. It might
    be feasible to create more realistic X-ray images by using contemporary GAN algorithms
    [[143](#bib.bib143)].
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 文献中还出现了由 GAN 算法生成的另一种合成数据集。然而，目前 GAN 数据集[[69](#bib.bib69)、[101](#bib.bib101)]的局限性在于模型目前无法生成完整的
    X 射线图像。此外，生成图像的质量远未达到真实水平。需要进一步研究，考虑到这些问题，可能有望通过使用现代 GAN 算法[[143](#bib.bib143)]来创建更逼真的
    X 射线图像。
- en: Exploiting Multiple-View Information
  id: totrans-197
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 利用多视角信息
- en: Existing research recognizes the critical role played by multiple-view imagery,
    especially when the detection of an object from a particular viewpoint is challenging
    [[110](#bib.bib110), [79](#bib.bib79), [100](#bib.bib100)].
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现有研究认识到多视角图像的关键作用，特别是当从特定视角检测物体具有挑战性时[[110](#bib.bib110)、[79](#bib.bib79)、[100](#bib.bib100)]。
- en: Few studies [[100](#bib.bib100), [79](#bib.bib79), [81](#bib.bib81)] investigate
    utilizing multiple-view integration inside/outside a CNN. Despite the incremental
    performance improvement reported, further work is required to investigate other
    possible ways to utilise multiple-view imagery better.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究[[100](#bib.bib100)、[79](#bib.bib79)、[81](#bib.bib81)]探讨了在 CNN 内部/外部利用多视角整合。尽管报告中指出了性能的逐步改善，但仍需进一步研究以探索更好的利用多视角图像的方法。
- en: Domain Adaptation between X-ray Scanners
  id: totrans-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: X 射线扫描仪之间的领域适应
- en: As pointed out in [[67](#bib.bib67), [82](#bib.bib82)], transferring models
    between different scanners could be challenging due to the unknown intrinsics
    of the scanners. Future work would utilize domain adaptation [[142](#bib.bib142)],
    where the source domain contains images from one scanner, and the target domain
    would be of another X-ray scanner. Training with even unbalanced datasets would
    learn the intrinsic, and map from one to the other.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 正如[[67](#bib.bib67)、[82](#bib.bib82)]中指出的，将模型在不同扫描仪之间转移可能会遇到挑战，因为扫描仪的内部参数未知。未来的工作将利用领域适应[[142](#bib.bib142)]，其中源领域包含来自一种扫描仪的图像，而目标领域则是另一种
    X 射线扫描仪的图像。即使在数据集不平衡的情况下进行训练，也能学习到内部特征，并将一种图像映射到另一种图像。
- en: Improving Unsupervised Anomaly Detection Approaches
  id: totrans-202
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 改进无监督异常检测方法
- en: 'The performance of the current anomaly detection algorithms presented in Section
    [7.2](#S7.SS2 "7.2 Unsupervised Approaches ‣ 7 Deep Learning in X-ray Security
    Imaging ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning
    within X-ray Security Imaging") is somewhat limited to be deployed for a real-world
    scenario. Therefore, more research on this topic needs to be undertaken to design
    better reconstruction techniques that thoroughly learn the characteristics of
    the normality from which the abnormality would be detected.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '本文第[7.2](#S7.SS2 "7.2 Unsupervised Approaches ‣ 7 Deep Learning in X-ray Security
    Imaging ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning
    within X-ray Security Imaging")节中提出的当前异常检测算法的性能在实际应用场景中有所限制。因此，需要更多的研究以设计更好的重建技术，深入学习正常性的特征，从而检测异常。'
- en: Use of the Material Information
  id: totrans-204
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 材料信息的使用
- en: In dual-energy X-ray systems attenuation between high and low energies yields
    a unique value for different materials, which could be utilized further for more
    accurate object classification/detection [[144](#bib.bib144), [145](#bib.bib145)].
    Even though recent research [[99](#bib.bib99), [66](#bib.bib66)] have examined
    the use of material information, the research outcome present inconsistent results.
    Hence, a further study thoroughly investigating the material information is suggested.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在双能 X 射线系统中，高能和低能之间的衰减为不同材料提供了唯一的值，这可以进一步用于更准确的物体分类/检测[[144](#bib.bib144)、[145](#bib.bib145)]。尽管近期研究[[99](#bib.bib99)、[66](#bib.bib66)]已考察了材料信息的使用，但研究结果存在不一致。因此，建议进一步研究以全面调查材料信息。
- en: 9 Conclusion
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 结论
- en: This paper taxonomises conventional machine and modern deep learning algorithms
    utilised within X-ray security imaging. Traditional approaches are sub-categorised
    based on computer vision tasks such as image enhancement, threat image projection,
    object segmentation, feature extraction, object classification, and detection.
    Review of the deep learning approaches includes classification, detection, segmentation
    and unsupervised anomaly detection algorithms applied within the field.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 本文对传统机器和现代深度学习算法在 X 射线安全成像中的应用进行了分类。传统方法根据计算机视觉任务如图像增强、威胁图像投影、对象分割、特征提取、对象分类和检测进行了子分类。深度学习方法的回顾包括分类、检测、分割和无监督异常检测算法在该领域的应用。
- en: Based on this review, several conclusion can be drawn for the future directions
    of the field. Despite the recently emerging datasets, the lack of large, well-balanced
    datasets limits the design of deep learning algorithms that are generalisable
    enough to be deployed in a real-time environment. Besides, since the public datasets
    are mostly from various machines with different intrinsic, the use of domain adaptation
    techniques could improve the generalisation capability of the algorithms.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这项回顾，可以为该领域的未来方向得出几个结论。尽管最近出现了一些数据集，但缺乏大规模且平衡良好的数据集限制了足够通用的深度学习算法的设计，使其难以在实时环境中应用。此外，由于公开数据集大多来自不同机器，具有不同的内在特性，使用领域适应技术可以提高算法的泛化能力。
- en: Unlike the abundance of studies in conventional machine learning, most of the
    recent approaches do not fully utilise X-ray imaging such as multiple-view geometry
    and high-low energy. Despite the existence of a few studies, there is room for
    further research. Moreover, further research in unsupervised learning could further
    utilise the existing X-ray datasets that are not labelled and not in use.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统机器学习领域的研究丰富不同，大多数最近的方法未充分利用 X 射线成像技术，如多视角几何和高低能量。尽管存在少量研究，但仍有进一步研究的空间。此外，在无监督学习领域的进一步研究可能会更好地利用现有的未标记和未使用的
    X 射线数据集。
- en: Overall, this paper reviews the strengths and weaknesses of the current techniques,
    and provides a thorough discussion for open challenges and envisions the future
    directions of the field.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，本文回顾了当前技术的优缺点，并对开放挑战进行了全面讨论，同时展望了该领域的未来方向。
- en: References
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Chavaillaz et al. [2019] A. Chavaillaz, A. Schwaninger, S. Michel, J. Sauer,
    Expertise, Automation and Trust in X-Ray Screening of Cabin Baggage, Frontiers
    in Psychology 10 (2019).
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chavaillaz 等人 [2019] A. Chavaillaz, A. Schwaninger, S. Michel, J. Sauer, 《X
    射线行李筛查中的专业知识、自动化和信任》，《心理学前沿》 10 (2019)。
- en: 'Schwaninger et al. [2008] A. Schwaninger, A. Bolfing, T. Halbherr, S. Helman,
    A. Belyavin, L. Hay, The Impact of Image Based Factors and Training on Threat
    Detection Performance in X-ray Screening, in: International Conference on Research
    in Air Transportation, p. 8.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schwaninger 等人 [2008] A. Schwaninger, A. Bolfing, T. Halbherr, S. Helman, A.
    Belyavin, L. Hay, 《基于图像的因素和训练对 X 射线筛查威胁检测性能的影响》，发表于：国际航空运输研究会议，页码 8。
- en: 'Wales et al. [2009] A. Wales, T. Halbherr, A. Schwaninger, Using speed measures
    to predict performance in x-ray luggage screening tasks, in: International Carnahan
    Conference on Security Technology, IEEE, 2009, pp. 212–215.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wales 等人 [2009] A. Wales, T. Halbherr, A. Schwaninger, 《利用速度测量预测 X 射线行李筛查任务中的表现》，发表于：国际卡纳汉安全技术会议，IEEE，2009，页码
    212–215。
- en: Mendes et al. [2013] M. Mendes, A. Schwaninger, S. Michel, Can Laptops Be Left
    Inside Passenger Bags If Motion Imaging Is Used in X-ray Security Screening?,
    Frontiers in Human Neuroscience 7 (2013).
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mendes 等人 [2013] M. Mendes, A. Schwaninger, S. Michel, 《如果 X 射线安全筛查中使用运动成像，笔记本电脑可以留在乘客行李中吗？》，《人类神经科学前沿》
    7 (2013)。
- en: 'Chavaillaz et al. [2018] A. Chavaillaz, A. Schwaninger, S. Michel, J. Sauer,
    Automation in Visual Inspection Tasks: X-ray Luggage Screening Supported by A
    System Of Direct, Indirect or Adaptable Cueing with Low and High System Reliability,
    Ergonomics 61 (2018) 1395–1408.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chavaillaz 等人 [2018] A. Chavaillaz, A. Schwaninger, S. Michel, J. Sauer, 《视觉检查任务中的自动化：由低高系统可靠性支持的直接、间接或可适应提示的
    X 射线行李筛查》，《人体工程学》 61 (2018) 1395–1408。
- en: 'Murray and Riordan [1995] N. C. Murray, K. Riordan, Evaluation of Automatic
    Explosive Detection Systems, in: International Carnahan Conference on Security
    Technology, IEEE, 1995, pp. 175–179.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Murray 和 Riordan [1995] N. C. Murray, K. Riordan, 《自动爆炸物检测系统的评估》，发表于：国际卡纳汉安全技术会议，IEEE，1995，页码
    175–179。
- en: 'Zentai [2008] G. Zentai, X-ray Imaging for Homeland Security, in: International
    Workshop on Imaging Systems and Techniques, IEEE, 2008, pp. 1–6.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zentai[2008] G. Zentai, X射线成像在国土安全中的应用，见：成像系统与技术国际研讨会，IEEE，2008年，第1–6页。
- en: Wells and Bradley [2012] K. Wells, D. Bradley, A Review of X-ray Explosives
    Detection Techniques for Checked Baggage, Applied Radiation and Isotopes 70 (2012)
    1729–1746.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wells和Bradley[2012] K. Wells, D. Bradley, 行李X射线爆炸物检测技术综述，应用辐射与同位素70（2012）1729–1746。
- en: Caygill et al. [2012] J. S. Caygill, F. Davis, S. P. J. Higson, Current Trends
    in Explosive Detection Techniques, Talanta 88 (2012) 14–29.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caygill等人[2012] J. S. Caygill, F. Davis, S. P. J. Higson, 当前爆炸物检测技术的趋势，Talanta
    88（2012）14–29。
- en: Singh and Singh [2003] S. Singh, M. Singh, Explosives Detection Systems (EDS)
    for Aviation Security, Signal Processing 83 (2003) 31–55.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singh和Singh[2003] S. Singh, M. Singh, 航空安全爆炸物检测系统（EDS），信号处理83（2003）31–55。
- en: 'Abidi et al. [2005] B. R. Abidi, D. L. Page, M. A. Abidi, A Combinational Approach
    to the Fusion, De-noising and Enhancement of Dual-Energy X-Ray Luggage Images,
    in: Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, volume 3,
    IEEE, 2005, p. 2.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abidi等人[2005] B. R. Abidi, D. L. Page, M. A. Abidi, 组合方法用于双能X射线行李图像的融合、去噪和增强，见：计算机视觉与模式识别会议（CVPR）研讨会，卷3，IEEE，2005年，第2页。
- en: 'Abidi et al. [2006] B. R. Abidi, Y. Zheng, A. V. Gribok, M. A. Abidi, Improving
    Weapon Detection In Single Energy X-ray Images Through Pseudocoloring, IEEE Transactions
    on Systems, Man and Cybernetics Part C: Applications and Reviews 36 (2006) 784–796.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abidi等人[2006] B. R. Abidi, Y. Zheng, A. V. Gribok, M. A. Abidi, 通过伪彩色提高单能X射线图像中的武器检测，IEEE系统、人类与控制论学报C部分：应用与评审36（2006）784–796。
- en: Lu and Conners [2006] Q. Lu, R. Conners, Using Image Processing Methods to Improve
    the Explosive Detection Accuracy, IEEE Transactions on Systems, Man and Cybernetics,
    Part C (Applications and Reviews) 36 (2006) 750–760.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu和Conners[2006] Q. Lu, R. Conners, 使用图像处理方法提高爆炸物检测精度，IEEE系统、人类与控制论学报，C部分（应用与评审）36（2006）750–760。
- en: 'Morton et al. [2015] E. Morton, T. Rogers, L. Griffin, N. Jaccard, Detection
    Of Cargo Container Loads From X-ray Images, in: International Conference on Intelligent
    Signal Processing 2015 (ISP), IET, 2015, pp. 6 .–6 .'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Morton等人[2015] E. Morton, T. Rogers, L. Griffin, N. Jaccard, 从X射线图像中检测货物集装箱负载，见：2015年智能信号处理国际会议（ISP），IET，2015年，第6页–第6页。
- en: 'Kundegorski et al. [2016] M. Kundegorski, S. Akçay, M. Devereux, A. Mouton,
    T. Breckon, On using Feature Descriptors as Visual Words for Object Detection
    within X-ray Baggage Security Screening, in: International Conference on Imaging
    for Crime Detection and Prevention (ICDP), IET, 2016, pp. 12 (6 .)–12 (6 .).'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kundegorski等人[2016] M. Kundegorski, S. Akçay, M. Devereux, A. Mouton, T. Breckon,
    在X射线行李安检中使用特征描述符作为视觉词进行物体检测，见：犯罪检测与预防成像国际会议（ICDP），IET，2016年，第12（6 .）页–第12（6 .）页。
- en: 'Mery et al. [2016] D. Mery, E. Svec, M. Arias, Object Recognition in Baggage
    Inspection Using Adaptive Sparse Representations of X-ray Images, in: Pacific-Rim
    Symposium on Image and Video Technology (PSIVT), Springer, Cham, 2016, pp. 709–720.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery等人[2016] D. Mery, E. Svec, M. Arias, 使用适应性稀疏表示进行行李检查中的物体识别，见：太平洋地区图像与视频技术研讨会（PSIVT），Springer，Cham，2016年，第709–720页。
- en: 'Franzel et al. [2012] T. Franzel, U. Schmidt, S. Roth, Object Detection in
    Multi-view X-Ray Images, in: Pattern Recognition: Joint DAGM and OAGM Symposium,
    Springer Berlin Heidelberg, 2012, pp. 144–154.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Franzel等人[2012] T. Franzel, U. Schmidt, S. Roth, 多视角X射线图像中的物体检测，见：模式识别：联合DAGM和OAGM研讨会，Springer
    Berlin Heidelberg，2012年，第144–154页。
- en: Bastan [2015] M. Bastan, Multi-view Object Detection In Dual-energy X-ray Images,
    Machine Vision and Applications 26 (2015) 1045–1060.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bastan[2015] M. Bastan, 双能X射线图像中的多视角物体检测，机器视觉与应用26（2015）1045–1060。
- en: 'Heitz and Chechik [2010] G. Heitz, G. Chechik, Object Separation in X-ray Image
    Sets, in: Conference on Computer Vision and Pattern Recognition (CVPR), IEEE,
    2010, pp. 2093–2100.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heitz和Chechik[2010] G. Heitz, G. Chechik, X射线图像集中的物体分离，见：计算机视觉与模式识别会议（CVPR），IEEE，2010年，第2093–2100页。
- en: 'Kechagias-Stamatis et al. [2017] O. Kechagias-Stamatis, N. Aouf, C. Belloni,
    D. Nam, Automatic X-ray Image Segmentation And Clustering For Threat Detection,
    in: Target and Background Signatures III, SPIE, 2017, p. 24.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kechagias-Stamatis等人[2017] O. Kechagias-Stamatis, N. Aouf, C. Belloni, D. Nam,
    自动X射线图像分割与聚类用于威胁检测，见：目标与背景签名III，SPIE，2017年，第24页。
- en: Mouton and Breckon [2015] A. Mouton, T. P. Breckon, A Review of Automated Image
    Understanding within 3D Baggage Computed Tomography Security Screening, Journal
    of X-Ray Science and Technology 23 (2015) 531–555.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mouton 和 Breckon [2015] A. Mouton, T. P. Breckon, 关于 3D 行李计算机断层扫描安全筛查中的自动化图像理解的综述,
    《X 射线科学与技术杂志》 23 (2015) 531–555。
- en: 'Rogers et al. [2017] T. W. Rogers, N. Jaccard, E. J. Morton, L. D. Griffin,
    Automated X-ray Image Analysis for Cargo Security: Critical Review and Future
    Promise, Journal of X-Ray Science and Technology 25 (2017) 33–56.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rogers 等人 [2017] T. W. Rogers, N. Jaccard, E. J. Morton, L. D. Griffin, 自动化
    X 射线图像分析用于货物安全: 关键评估与未来前景, 《X 射线科学与技术杂志》 25 (2017) 33–56。'
- en: 'Akçay et al. [2016] S. Akçay, M. E. Kundegorski, M. Devereux, T. P. Breckon,
    Transfer Learning Using Convolutional Neural Networks for Object Classification
    within X-ray Baggage Security Imagery, in: International Conference on Image Processing
    (ICIP), IEEE, 2016, pp. 1057–1061.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Akçay 等人 [2016] S. Akçay, M. E. Kundegorski, M. Devereux, T. P. Breckon, 使用卷积神经网络的迁移学习进行
    X 射线行李安全影像中的物体分类, 在: 国际图像处理会议 (ICIP), IEEE, 2016, 第 1057–1061 页。'
- en: 'Mery et al. [2017] D. Mery, E. Svec, M. Arias, V. Riffo, J. M. Saavedra, S. Banerjee,
    Modern Computer Vision Techniques for X-Ray Testing in Baggage Inspection, IEEE
    Transactions on Systems, Man, and Cybernetics: Systems 47 (2017) 682–692.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery 等人 [2017] D. Mery, E. Svec, M. Arias, V. Riffo, J. M. Saavedra, S. Banerjee,
    现代计算机视觉技术用于行李检查中的 X 射线检测, 《IEEE 系统、人类与控制系统学报》 47 (2017) 682–692。
- en: 'Jaccard et al. [2016] N. Jaccard, T. W. Rogers, E. J. Morton, L. D. Griffin,
    Tackling The X-ray Cargo Inspection Challenge Using Machine Learning, in: A. Ashok,
    M. A. Neifeld, M. E. Gehm (Eds.), Anomaly Detection and Imaging with X-Rays, volume
    9847, SPIE, 2016, p. 98470N.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jaccard 等人 [2016] N. Jaccard, T. W. Rogers, E. J. Morton, L. D. Griffin, 利用机器学习应对
    X 射线货物检查挑战, 在: A. Ashok, M. A. Neifeld, M. E. Gehm (编), 《X 射线异常检测与成像》，第 9847 卷,
    SPIE, 2016, 第 98470N 页。'
- en: Departmenf of Homeland Security [2018] Departmenf of Homeland Security, Advanced
    Integrated Passenger and Baggage Screening Technologies, 2018.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 美国国土安全部 [2018] 美国国土安全部, 先进的综合乘客与行李筛查技术, 2018。
- en: Abidi et al. [2004] B. R. Abidi, J. Liang, M. Mitckes, M. A. Abidi, Improving
    The Detection Of Low-density Weapons In X-ray Luggage Scans Using Image Enhancement
    And Novel Scene-decluttering Techniques, Journal of Electronic Imaging 13 (2004)
    523–539.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abidi 等人 [2004] B. R. Abidi, J. Liang, M. Mitckes, M. A. Abidi, 使用图像增强和新颖的场景去杂乱技术提高
    X 射线行李扫描中低密度武器的检测, 《电子成像杂志》 13 (2004) 523–539。
- en: 'Singh and Singh [2005] M. Singh, S. Singh, Optimizing Image Enhancement For
    Screening Luggage At Airports, in: International Conference on Computational Intelligence
    for Homeland Security and Personal Safety (CIHSPS), IEEE, 2005, pp. 131–136.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Singh 和 Singh [2005] M. Singh, S. Singh, 优化机场行李筛查的图像增强, 在: 国际计算智能国家安全与个人安全会议
    (CIHSPS), IEEE, 2005, 第 131–136 页。'
- en: 'Abidi et al. [2005] B. Abidi, Y. Zheng, A. Gribok, M. Abidi, Screener Evaluation
    of Pseudo-Colored Single Energy X-ray Luggage Images, in: Conference on Computer
    Vision and Pattern Recognition (CVPR) - Workshops, volume 3, IEEE, 2005, pp. 35–35.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Abidi 等人 [2005] B. Abidi, Y. Zheng, A. Gribok, M. Abidi, 对伪彩色单能量 X 射线行李图像的筛查评估,
    在: 计算机视觉与模式识别会议 (CVPR) - 研讨会, 第 3 卷, IEEE, 2005, 第 35–35 页。'
- en: 'Rogers et al. [2014] T. W. Rogers, J. Ollier, E. J. Morton, L. D. Griffin,
    Reduction Of Wobble Artefacts In Images From Mobile Transmission X-ray Vehicle
    Scanners, in: International Conference on Imaging Systems and Techniques (IST),
    IEEE, 2014, pp. 356–360.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rogers 等人 [2014] T. W. Rogers, J. Ollier, E. J. Morton, L. D. Griffin, 减少移动传输
    X 射线车辆扫描仪图像中的抖动伪影, 在: 国际成像系统与技术会议 (IST), IEEE, 2014, 第 356–360 页。'
- en: Rogers et al. [2017] T. W. Rogers, J. Ollier, E. J. Morton, L. D. Griffin, Measuring
    And Correcting Wobble In Large-scale Transmission Radiography, Journal of X-ray
    Science and Technology 25 (2017) 57–77.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rogers 等人 [2017] T. W. Rogers, J. Ollier, E. J. Morton, L. D. Griffin, 大规模传输放射摄影中的抖动测量与修正,
    《X 射线科学与技术杂志》 25 (2017) 57–77。
- en: Mitckes [2003] M. Mitckes, Threat Image Projection – An Overview, Technical
    Report, 2003.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mitckes [2003] M. Mitckes, 威胁图像投影 – 概述, 技术报告, 2003。
- en: 'Rogers et al. [2016] T. W. Rogers, N. Jaccard, E. D. Protonotarios, J. Ollier,
    E. J. Morton, L. D. Griffin, Threat Image Projection (TIP) into X-ray Images of
    Cargo Containers for Training Humans and Machines, in: International Carnahan
    Conference on Security Technology (ICCST), IEEE, 2016, pp. 1–7.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rogers 等人 [2016] T. W. Rogers, N. Jaccard, E. D. Protonotarios, J. Ollier,
    E. J. Morton, L. D. Griffin, 在 X 射线货物集装箱图像中进行威胁图像投影 (TIP) 以培训人类和机器, 在: 国际卡纳汉安全技术会议
    (ICCST), IEEE, 2016, 第 1–7 页。'
- en: 'Mery and Katsaggelos [2017] D. Mery, A. K. Katsaggelos, A Logarithmic X-Ray
    Imaging Model for Baggage Inspection: Simulation and Object Detection, in: Conference
    on Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE, 2017, pp.
    251–259.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery和Katsaggelos [2017] D. Mery, A. K. Katsaggelos, 行李检查的对数X射线成像模型：仿真与目标检测，发表于：计算机视觉与模式识别研讨会（CVPRW），IEEE，2017，第251–259页。
- en: 'Oertel and Bock [2006] C. Oertel, P. Bock, Identification of Objects-of-Interest
    in X-Ray Images, in: Applied Imagery and Pattern Recognition Workshop (AIPR),
    IEEE, 2006, pp. 17–17.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oertel和Bock [2006] C. Oertel, P. Bock, X射线图像中的兴趣对象识别，发表于：应用图像与模式识别研讨会（AIPR），IEEE，2006，第17–17页。
- en: 'Gesick et al. [2009] R. Gesick, C. Saritac, C.-C. Hung, Automatic image analysis
    process for the detection of concealed weapons, in: Annual Workshop on Cyber Security
    and Information Intelligence Research Cyber Security and Information Intelligence
    Challenges and Strategies (CSIIRW), ACM Press, 2009, p. 1.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gesick等人 [2009] R. Gesick, C. Saritac, C.-C. Hung, 隐藏武器检测的自动图像分析过程，发表于：年度网络安全与信息智能研究研讨会网络安全与信息智能挑战与策略（CSIIRW），ACM
    Press，2009，第1页。
- en: 'Fu et al. [2009] K. Fu, C. Guest, P. Das, Segmentation of suspicious objects
    in an x-ray image using automated region filling approach, in: Signal and Data
    Processing of Small Targets 2009, volume 7445, International Society for Optics
    and Photonics, 2009, p. 744510.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu等人 [2009] K. Fu, C. Guest, P. Das, 使用自动区域填充方法对X射线图像中的可疑物体进行分割，发表于：小目标信号与数据处理2009，卷7445，国际光学与光子学学会，2009，第744510页。
- en: 'Baştan et al. [2011] M. Baştan, M. R. Yousefi, T. M. Breuel, Visual Words on
    Baggage X-Ray Images, in: International Conference on Computer Analysis of Images
    and Patterns, Lecture Notes in Computer Science, Springer Berlin Heidelberg, 2011,
    pp. 360–368.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baştan等人 [2011] M. Baştan, M. R. Yousefi, T. M. Breuel, 行李X射线图像上的视觉词，发表于：国际计算机图像与模式分析会议，计算机科学讲义，Springer
    Berlin Heidelberg，2011，第360–368页。
- en: 'Turcsany et al. [2013] D. Turcsany, A. Mouton, T. P. Breckon, Improving feature-based
    object recognition for X-ray baggage security screening using primed visualwords,
    in: International Conference on Industrial Technology (ICIT), IEEE, 2013, pp.
    1140–1145.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Turcsany等人 [2013] D. Turcsany, A. Mouton, T. P. Breckon, 使用优化视觉词改善基于特征的X射线行李安全筛查中的对象识别，发表于：国际工业技术会议（ICIT），IEEE，2013，第1140–1145页。
- en: Bastan et al. [2013] M. Bastan, W. Byeon, T. M. Breuel, Object Recognition in
    Multi-View Dual Energy X-ray Images – Executive summary, British Machine Vision
    Conference (BMVC) (2013) 1–11.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bastan等人 [2013] M. Bastan, W. Byeon, T. M. Breuel, 多视图双能X射线图像中的对象识别 – 执行摘要，英国机器视觉会议（BMVC）（2013）1–11。
- en: 'Zheng and Elmaghraby [2013] Y. Zheng, A. Elmaghraby, A Vehicle Threat Detection
    System Using Correlation Analysis And Synthesized X-ray Images, in: Detection
    and Sensing of Mines, Explosive Objects, and Obscured Targets XVIII, volume 8709,
    International Society for Optics and Photonics, 2013, p. 87090V.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng和Elmaghraby [2013] Y. Zheng, A. Elmaghraby, 使用相关分析和合成X射线图像的车辆威胁检测系统，发表于：第十八届矿物、爆炸物体与遮挡目标检测与传感会议，卷8709，国际光学与光子学学会，2013，第87090V页。
- en: 'Zhang et al. [2014] J. Zhang, L. Zhang, Z. Zhao, Y. Liu, J. Gu, Q. Li, D. Zhang,
    Joint Shape and Texture Based X-Ray Cargo Image Classification, in: Conference
    on Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE, 2014, pp.
    266–273.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等人 [2014] J. Zhang, L. Zhang, Z. Zhao, Y. Liu, J. Gu, Q. Li, D. Zhang,
    基于联合形状和纹理的X射线货物图像分类，发表于：计算机视觉与模式识别研讨会（CVPRW），IEEE，2014，第266–273页。
- en: 'Jaccard et al. [2014] N. Jaccard, T. W. Rogers, L. D. Griffin, Automated Detection
    Of Cars In Transmission X-ray Images Of Freight Containers, in: International
    Conference on Advanced Video and Signal Based Surveillance (AVSS), IEEE, 2014,
    pp. 387–392.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaccard等人 [2014] N. Jaccard, T. W. Rogers, L. D. Griffin, 货运集装箱传输X射线图像中的汽车自动检测，发表于：国际先进视频与信号监控会议（AVSS），IEEE，2014，第387–392页。
- en: 'Kolkoori et al. [2014] S. Kolkoori, N. Wrobel, A. Deresch, B. Redmer, U. Ewert,
    Dual High-energy X-ray Digital Radiography For Material Discrimination In Cargo
    Containers, in: European Conference on Non-Destructive Testing (ECNDT), pp. 6–10.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kolkoori等人 [2014] S. Kolkoori, N. Wrobel, A. Deresch, B. Redmer, U. Ewert, 货物集装箱中材料区分的双高能X射线数字放射摄影，发表于：欧洲无损检测会议（ECNDT），第6–10页。
- en: Zhang and Zhu [2015] N. Zhang, J. Zhu, A Study Of X-ray Machine Image Local
    Semantic Features Extraction Model Based On Bag-ofwords For Airport Security,
    International Journal on Smart Sensing and Intelligent Systems 8 (2015) 45–64.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang和Zhu [2015] N. Zhang, J. Zhu, 基于词袋模型的机场安全X射线机器图像局部语义特征提取研究，国际智能传感与智能系统期刊8（2015）45–64。
- en: Zhang [2015] N. Zhang, A Study On Optimization Methods Of X-ray Machine Recognition
    For Aviation Security System, International Journal on Smart Sensing and Intelligent
    Systems 8 (2015) 1313–1332.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang [2015] N. Zhang, 关于优化航空安全系统X射线机器识别的方法研究，《智能传感与智能系统国际杂志》8（2015）1313–1332。
- en: 'Abusaeeda et al. [2011] O. Abusaeeda, J. Evans, D. Downes, J. Chan, View Synthesis
    Of KDEX Imagery For 3d Security X-ray Imaging, in: International Conference on
    Imaging for Crime Detection and Prevention (ICDP), IET, 2011, pp. P40–P40.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abusaeeda et al. [2011] O. Abusaeeda, J. Evans, D. Downes, J. Chan, KDEX图像的视图合成用于3D安全X射线成像，载于：犯罪检测与预防成像国际会议（ICDP），IET，2011年，页码
    P40–P40。
- en: 'Mery [2011] D. Mery, Automated Detection In Complex Objects Using A Tracking
    Algorithm In Multiple X-ray Views, in: Conference on Computer Vision and Pattern
    Recognition Workshops (CVPRW), IEEE, 2011, pp. 41–48.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery [2011] D. Mery, 使用多视角X射线图像中的跟踪算法进行复杂物体的自动检测，载于：计算机视觉与模式识别会议工作坊（CVPRW），IEEE，2011年，页码
    41–48。
- en: Mery et al. [2013a] D. Mery, G. Mondragon, V. Riffo, I. Zuccar, Detection Of
    Regular Objects In Baggage Using Multiple X-ray Views, Insight - Non-Destructive
    Testing and Condition Monitoring 55 (2013a) 16–20.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery et al. [2013a] D. Mery, G. Mondragon, V. Riffo, I. Zuccar, 使用多视角X射线图像检测行李中的常规物体，《洞察》
    - 无损检测与状态监测 55（2013a）16–20。
- en: 'Mery et al. [2013b] D. Mery, V. Riffo, I. Zuccar, C. Pieringer, Automated X-Ray
    Object Recognition Using an Efficient Search Algorithm in Multiple Views, in:
    Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE,
    2013b, pp. 368–374.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery et al. [2013b] D. Mery, V. Riffo, I. Zuccar, C. Pieringer, 使用高效搜索算法在多视角中自动识别X射线物体，载于：计算机视觉与模式识别会议工作坊（CVPRW），IEEE，2013b，页码
    368–374。
- en: Mery and Riffo [2013] D. Mery, V. Riffo, Automated Object Recognition In Baggage
    Screening Using Multiple X-ray Views, Annual Conference of the British Institute
    of Non-Destructive Testing (NDT) 4860 (2013) 1–12.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery and Riffo [2013] D. Mery, V. Riffo, 使用多视角X射线图像进行行李中物体的自动识别，英国无损检测研究所（NDT）年会
    4860（2013）1–12。
- en: Mery et al. [2013] D. Mery, G. Mondragon, V. Riffo, I. Zuccar, Detection of
    regular objects in baggage using multiple X-ray views, Insight - Non-Destructive
    Testing and Condition Monitoring 55 (2013) 16–20.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery et al. [2013] D. Mery, G. Mondragon, V. Riffo, I. Zuccar, 使用多视角X射线图像检测行李中的常规物体，《洞察》
    - 无损检测与状态监测 55（2013）16–20。
- en: Mery [2015] D. Mery, Inspection of Complex Objects Using Multiple-X-Ray Views,
    IEEE/ASME Transactions on Mechatronics 20 (2015) 338–347.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery [2015] D. Mery, 使用多视角X射线图像检查复杂物体，《IEEE/ASME机电一体化学报》20（2015）338–347。
- en: Mery et al. [2016] D. Mery, E. Svec, M. Arias, Object Recognition in X-ray Testing
    Using Adaptive Sparse Representations, Journal of Nondestructive Evaluation 35
    (2016) 45.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery et al. [2016] D. Mery, E. Svec, M. Arias, 使用自适应稀疏表示进行X射线检测中的物体识别，《无损检测杂志》35（2016）45。
- en: 'Riffo and Mery [2016] V. Riffo, D. Mery, Automated Detection of Threat Objects
    Using Adapted Implicit Shape Model, IEEE Transactions on Systems, Man, and Cybernetics:
    Systems 46 (2016) 472–482.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Riffo and Mery [2016] V. Riffo, D. Mery, 使用改进的隐式形状模型自动检测威胁物体，《IEEE系统、人类与控制论学报：系统》46（2016）472–482。
- en: 'Cañizares et al. [2018] P. C. Cañizares, M. G. Merayo, A. Núñez, FORTIFIER:
    a FORmal disTrIbuted Framework to Improve the dEtection of thReatening objects
    in baggage, Journal of Information and Telecommunication 2 (2018) 2–18.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cañizares et al. [2018] P. C. Cañizares, M. G. Merayo, A. Núñez, FORTIFIER：一种用于提高行李中威胁物体检测的正式分布式框架，《信息与电信学杂志》2（2018）2–18。
- en: 'Schmidt-Hackenberg et al. [2012] L. Schmidt-Hackenberg, M. R. Yousefi, T. M.
    Breuel, Visual Cortex Inspired Features For Object Detection In X-ray Images,
    in: International Conference on Pattern Recognition (ICPR), IEEE, Tsukuba, Japan,
    2012, pp. 2573–2576.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schmidt-Hackenberg et al. [2012] L. Schmidt-Hackenberg, M. R. Yousefi, T. M.
    Breuel, 受视觉皮层启发的物体检测特征应用于X射线图像，载于：模式识别国际会议（ICPR），IEEE，筑波，日本，2012年，页码 2573–2576。
- en: 'Paranjape et al. [1998] R. Paranjape, M. Sluser, E. Runtz, Segmentation of
    handguns in dual energy X-ray imagery of passenger carry-on baggage, in: Canadian
    Conference on Electrical and Computer Engineering, volume 1, IEEE, 1998, pp. 377–380.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Paranjape et al. [1998] R. Paranjape, M. Sluser, E. Runtz, 在乘客随身行李的双能X射线图像中对手枪的分割，载于：加拿大电气与计算机工程会议，第1卷，IEEE，1998年，页码
    377–380。
- en: 'Sluser and Paranjape [1999] M. Sluser, R. Paranjape, Model-based Probabilistic
    Relaxation Segmentation Applied To Threat Detection In Airport X-ray Imagery,
    in: Canadian Conference on Electrical and Computer Engineering, volume 2, IEEE,
    1999, pp. 720–726.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sluser 和 Paranjape [1999] M. Sluser, R. Paranjape, 基于模型的概率松弛分割在机场 X 射线图像威胁检测中的应用，见：加拿大电气与计算机工程会议，第
    2 卷，IEEE，1999年，第 720–726 页。
- en: 'Singh and Singh [2004] M. Singh, S. Singh, Image Segmentation Optimisation
    For X-ray Images Of Airline Luggage, in: International Conference on Computational
    Intelligence for Homeland Security and Personal Safety (CIHSPS), IEEE, 2004, pp.
    10–17.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singh 和 Singh [2004] M. Singh, S. Singh, 针对航空行李 X 射线图像的图像分割优化，见：国际计算智能与国土安全及个人安全会议（CIHSPS），IEEE，2004年，第
    10–17 页。
- en: 'Ding et al. [2006] J. Ding, Y. Li, X. Xu, L. Wang, X-ray Image Segmentation
    by Attribute Relational Graph Matching, in: International Conference on Signal
    Processing, IEEE, 2006.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding 等人 [2006] J. Ding, Y. Li, X. Xu, L. Wang, 基于属性关系图匹配的 X 射线图像分割，见：国际信号处理会议，IEEE，2006年。
- en: Svec P. [2016] E. Svec P., Sparse KNN - A Method For Object Recognition Over
    X-ray Images Using Knn Based In Sparse Reconstruction, Ph.D. thesis, Pontificia
    Universidad Catolica De Chile, 2016.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Svec P. [2016] E. Svec P., 稀疏 KNN - 一种基于稀疏重建的 KNN 对 X 射线图像进行物体识别的方法，博士学位论文，智利天主教大学，2016年。
- en: 'Jaccard et al. [2016] N. Jaccard, T. W. Rogers, E. J. Morton, L. D. Griffin,
    Using Deep Learning On X-ray Images To Detect Threats, in: Defence and Security
    Doctoral Symposium Paper, Cranfield University, 2016, pp. 1–12.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaccard 等人 [2016] N. Jaccard, T. W. Rogers, E. J. Morton, L. D. Griffin, 在 X
    射线图像中使用深度学习检测威胁，见：国防与安全博士生研讨会论文，克兰菲尔德大学，2016年，第 1–12 页。
- en: Jaccard et al. [2017] N. Jaccard, T. W. Rogers, E. J. Morton, Detection Of Concealed
    Cars In Complex Cargo X-ray Imagery Using Deep Learning, Journal of X-Ray Science
    and Technology 25 (2017) 323–339.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaccard 等人 [2017] N. Jaccard, T. W. Rogers, E. J. Morton, 使用深度学习检测复杂货物 X 射线图像中的隐蔽车辆，《X
    射线科学与技术杂志》25（2017）323–339。
- en: 'Jaccard et al. [2016] N. Jaccard, T. Rogers, E. Morton, L. Griffin, Automated
    Detection Of Smuggled High-risk Security Threats Using Deep Learning, in: International
    Conference on Imaging for Crime Detection and Prevention (ICDP), IET, 2016, pp.
    11 (4 .)–11 (4 .).'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaccard 等人 [2016] N. Jaccard, T. Rogers, E. Morton, L. Griffin, 使用深度学习自动检测走私高风险安全威胁，见：国际犯罪检测与预防成像会议（ICDP），IET，2016年，第
    11 (4 .)–11 (4 .) 页。
- en: 'Rogers et al. [2017] T. W. Rogers, N. Jaccard, L. D. Griffin, A Deep Learning
    Framework For The Automated Inspection Of Complex Dual-energy X-ray Cargo Imagery,
    in: Conference on Anomaly Detection and Imaging with X-Rays (ADIX) II, SPIE, 2017.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rogers 等人 [2017] T. W. Rogers, N. Jaccard, L. D. Griffin, 一种用于复杂双能 X 射线货物图像自动检测的深度学习框架，见：
    X 射线异常检测与成像会议 (ADIX) II，SPIE，2017年。
- en: 'Caldwell et al. [2017] M. Caldwell, M. Ransley, T. W. Rogers, L. D. Griffin,
    Transferring X-ray Based Automated Threat Detection Between Scanners With Different
    Energies And Resolution, in: Counterterrorism, Crime Fighting, Forensics, and
    Surveillance Technologies, SPIE, 2017, p. 15.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caldwell 等人 [2017] M. Caldwell, M. Ransley, T. W. Rogers, L. D. Griffin, 在不同能量和分辨率的扫描仪之间转移基于
    X 射线的自动威胁检测，见：反恐、打击犯罪、法医与监控技术会议，SPIE，2017年，第 15 页。
- en: 'Yuan and Guo [2018] J. Yuan, C. Guo, A Deep Learning Method for Detection of
    Dangerous Equipment, in: International Conference on Information Science and Technology
    (ICIST), IEEE, 2018, pp. 159–164.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan 和 Guo [2018] J. Yuan, C. Guo, 一种用于危险设备检测的深度学习方法，见：国际信息科学与技术会议（ICIST），IEEE，2018年，第
    159–164 页。
- en: 'Zhao et al. [2018] Z. Zhao, H. Zhang, J. Yang, A GAN-Based Image Generation
    Method for X-Ray Security Prohibited Items, in: Chinese Conference on Pattern
    Recognition and Computer Vision (PRCV), Lecture Notes in Computer Science, Springer
    International Publishing, 2018, pp. 420–430.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人 [2018] Z. Zhao, H. Zhang, J. Yang, 基于 GAN 的 X 射线安全禁品图像生成方法，见：中文模式识别与计算机视觉会议（PRCV），计算机科学讲义，Springer
    国际出版社，2018年，第 420–430 页。
- en: 'Xu et al. [2018] M. Xu, H. Zhang, J. Yang, Prohibited Item Detection in Airport
    X-Ray Security Images via Attention Mechanism Based CNN, in: Chinese Conference
    on Pattern Recognition and Computer Vision (PRCV), Lecture Notes in Computer Science,
    Springer International Publishing, 2018, pp. 429–439.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人 [2018] M. Xu, H. Zhang, J. Yang, 基于注意力机制的 CNN 在机场 X 射线安检图像中的禁品检测，见：中文模式识别与计算机视觉会议（PRCV），计算机科学讲义，Springer
    国际出版社，2018年，第 429–439 页。
- en: 'Miao et al. [2019] C. Miao, L. Xie, F. Wan, C. Su, H. Liu, J. Jiao, Q. Ye,
    SIXray : A Large-scale Security Inspection X-ray Benchmark for Prohibited Item
    Discovery in Overlapping Images, in: Conference on Computer Vision and Pattern
    Recognition (CVPR), IEEE, 2019.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miao 等 [2019] C. Miao, L. Xie, F. Wan, C. Su, H. Liu, J. Jiao, Q. Ye, SIXray：用于重叠图像中禁止物品发现的大规模安全检查
    X 射线基准，见：计算机视觉与模式识别会议（CVPR），IEEE，2019年。
- en: 'Akçay and Breckon [2017] S. Akçay, T. P. Breckon, An Evaluation Of Region-Based
    Object Detection Strategies Within X-ray Baggage Security Imagery, in: IEEE International
    Conference on Image Processing (ICIP), IEEE, 2017, pp. 1337–1341.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Akçay 和 Breckon [2017] S. Akçay, T. P. Breckon, 在 X 射线行李安全影像中对基于区域的目标检测策略的评估，见：IEEE
    国际图像处理会议（ICIP），IEEE，2017年，第 1337–1341 页。
- en: Akçay et al. [2018] S. Akçay, M. E. Kundegorski, C. G. Willcocks, T. P. Breckon,
    Using Deep Convolutional Neural Network Architectures for Object Classification
    and Detection within X-ray Baggage Security Imagery, IEEE Transactions on Information
    Forensics and Security (2018).
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Akçay 等 [2018] S. Akçay, M. E. Kundegorski, C. G. Willcocks, T. P. Breckon,
    使用深度卷积神经网络架构进行 X 射线行李安全成像中的目标分类和检测，《IEEE 信息取证与安全事务》 (2018)。
- en: Hassan et al. [2019] T. Hassan, S. H. Khan, S. Akcay, M. Bennamoun, N. Werghi,
    Deep CMST Framework for the Autonomous Recognition of Heavily Occluded and Cluttered
    Baggage Items from Multivendor Security Radiographs, CoRR (2019).
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hassan 等 [2019] T. Hassan, S. H. Khan, S. Akcay, M. Bennamoun, N. Werghi, 用于自主识别严重遮挡和杂乱行李物品的深度
    CMST 框架，计算机科学技术预印本（2019）。
- en: 'Liu et al. [2018] Z. Liu, J. Li, Y. Shu, D. Zhang, Detection and Recognition
    of Security Detection Object Based on Yolo9000, in: International Conference on
    Systems and Informatics (ICSAI), IEEE, 2018, pp. 278–282.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 [2018] Z. Liu, J. Li, Y. Shu, D. Zhang, 基于 Yolo9000 的安全检测对象的检测与识别，见：国际系统与信息学会议（ICSAI），IEEE，2018年，第
    278–282 页。
- en: 'Cui and Oztan [2019] Y. Cui, B. Oztan, Automated firearms detection in cargo
    x-ray images using RetinaNet, in: A. Ashok, M. E. Gehm, J. A. Greenberg (Eds.),
    Anomaly Detection and Imaging with X-Rays (ADIX) IV, SPIE, 2019, p. 24.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cui 和 Oztan [2019] Y. Cui, B. Oztan, 使用 RetinaNet 在货物 X 射线图像中自动检测火器，见：A. Ashok,
    M. E. Gehm, J. A. Greenberg (编)，X 射线异常检测与成像（ADIX）IV，SPIE，2019年，第 24 页。
- en: Subramani et al. [2020] M. Subramani, K. Rajaduari, S. D. Choudhury, A. Topkar,
    V. Ponnusamy, Evaluating One Stage Detector Architecture of Convolutional Neural
    Network for Threat Object Detection Using X-Ray Baggage Security Imaging, Revue
    d’Intelligence Artificielle 34 (2020) 495–500.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Subramani 等 [2020] M. Subramani, K. Rajaduari, S. D. Choudhury, A. Topkar, V.
    Ponnusamy, 评估用于 X 射线行李安全成像的卷积神经网络单阶段检测器架构的威胁目标检测，《人工智能评论》34 (2020) 495–500。
- en: 'Hassan et al. [2020] T. Hassan, M. Bettayeb, S. Akcay, S. Khan, M. Bennamoun,
    N. Werghi, Detecting Prohibited Items in X-Ray Images: a Contour Proposal Learning
    Approach, in: 2020 IEEE International Conference on Image Processing (ICIP), IEEE,
    2020, pp. 2016–2020.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hassan 等 [2020] T. Hassan, M. Bettayeb, S. Akcay, S. Khan, M. Bennamoun, N.
    Werghi, 在 X 射线图像中检测禁止物品：一种轮廓提议学习方法，见：2020 IEEE 国际图像处理会议（ICIP），IEEE，2020年，第 2016–2020
    页。
- en: 'Steitz et al. [2019] J.-M. O. Steitz, F. Saeedan, S. Roth, Multi-view X-Ray
    R-CNN, in: German Conference on Pattern Recognition (GCPR), 2019, pp. 153–168.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Steitz 等 [2019] J.-M. O. Steitz, F. Saeedan, S. Roth, 多视角 X 射线 R-CNN，见：德国模式识别会议（GCPR），2019年，第
    153–168 页。
- en: Liang et al. [2019] K. J. Liang, J. B. Sigman, G. P. Spell, D. Strellis, W. Chang,
    F. Liu, T. Mehta, L. Carin, Toward Automatic Threat Recognition for Airport X-ray
    Baggage Screening with Deep Convolutional Object Detection, CoRR (2019).
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang 等 [2019] K. J. Liang, J. B. Sigman, G. P. Spell, D. Strellis, W. Chang,
    F. Liu, T. Mehta, L. Carin, 致力于机场 X 射线行李筛查的自动威胁识别，深度卷积目标检测，《计算机科学技术预印本》（2019）。
- en: 'Isaac-Medina et al. [2020] B. Isaac-Medina, C. Willcocks, T. Breckon, Multi-view
    Object Detection Using Epipolar Constraints within Cluttered X-ray Security Imagery,
    in: Proceedings of the International Conference on Pattern Recognition (ICPR),
    IEEE, 2020.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Isaac-Medina 等 [2020] B. Isaac-Medina, C. Willcocks, T. Breckon, 使用视极约束在杂乱的
    X 射线安全影像中进行多视角目标检测，见：国际模式识别会议论文集（ICPR），IEEE，2020年。
- en: 'Gaus et al. [2019a] Y. Gaus, N. Bhowmik, S. Akcay, T. Breckon, Evaluating the
    Transferability and Adversarial Discrimination of Convolutional Neural Networks
    for Threat Object Detection and Classification within X-Ray Security Imagery,
    in: Procedings of the International Conference on Machine Learning Applications
    (ICMLA), IEEE, 2019a.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gaus 等 [2019a] Y. Gaus, N. Bhowmik, S. Akcay, T. Breckon, 评估卷积神经网络在 X 射线安全影像中的威胁目标检测和分类的迁移性和对抗性区分能力，见：国际机器学习应用会议论文集（ICMLA），IEEE，2019a。
- en: 'Gaus et al. [2019b] Y. F. A. Gaus, N. Bhowmik, S. Akçay, P. M. Guillen-Garcia,
    J. W. Barker, T. P. Breckon, Evaluation of a Dual Convolutional Neural Network
    Architecture for Object-wise Anomaly Detection in Cluttered X-ray Security Imagery,
    in: International Joint Conference on Neural Networks (IJCNN), IEEE, 2019b.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gaus 等 [2019b] Y. F. A. Gaus, N. Bhowmik, S. Akçay, P. M. Guillen-Garcia, J.
    W. Barker, T. P. Breckon, 对混乱 X 射线安全图像中的对象级异常检测的双卷积神经网络架构评估，见：国际联合神经网络会议 (IJCNN)，IEEE，2019b。
- en: 'Hassan et al. [2020] T. Hassan, S. Akcay, M. Bennamoun, S. Khan, N. Werghi,
    Trainable Structure Tensors for Autonomous Baggage Threat Detection Under Extreme
    Occlusion, in: Asian Conference on Computer Vision - ACCV, Springer, 2020.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hassan 等 [2020] T. Hassan, S. Akcay, M. Bennamoun, S. Khan, N. Werghi, 用于极端遮挡下自主行李威胁检测的可训练结构张量，见：亚洲计算机视觉会议
    - ACCV，Springer，2020 年。
- en: Tuszynski et al. [2013] J. Tuszynski, J. T. Briggs, J. Kaufhold, A Method For
    Automatic Manifest Verification Of Container Cargo Using Radiography Images, Journal
    of Transportation Security 6 (2013) 339–356.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tuszynski 等 [2013] J. Tuszynski, J. T. Briggs, J. Kaufhold, 一种自动验证集装箱货物的放射影像方法，运输安全杂志
    6 (2013) 339–356。
- en: Andrews et al. [2016a] J. T. A. Andrews, E. J. Morton, L. D. Griffin, Detecting
    Anomalous Data Using Auto-encoders, International Journal of Machine Learning
    and Computing 6 (2016a) 21.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Andrews 等 [2016a] J. T. A. Andrews, E. J. Morton, L. D. Griffin, 使用自编码器检测异常数据，国际机器学习与计算杂志
    6 (2016a) 21。
- en: 'Andrews et al. [2016b] J. T. A. Andrews, N. Jaccard, T. W. Rogers, T. Tanay,
    L. D. Griffin, Anomaly Detection for Security Imaging, in: Defence and Security
    Doctoral Symposium, Cranfield University, 2016b.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Andrews 等 [2016b] J. T. A. Andrews, N. Jaccard, T. W. Rogers, T. Tanay, L. D.
    Griffin, 安全成像的异常检测，见：国防与安全博士生研讨会，克兰菲尔德大学，2016b。
- en: 'Andrews et al. [2017] J. T. A. Andrews, N. Jaccard, T. W. Rogers, L. D. Griffin,
    Representation-learning For Anomaly Detection In Complex X-ray Cargo Imagery,
    in: Anomaly Detection and Imaging with X-Rays (ADIX) II, SPIE, 2017.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Andrews 等 [2017] J. T. A. Andrews, N. Jaccard, T. W. Rogers, L. D. Griffin,
    复杂 X 射线货物图像中的异常检测表示学习，见：异常检测与 X 射线成像 (ADIX) II，SPIE，2017 年。
- en: 'Akcay et al. [2019a] S. Akcay, A. Atapour-Abarghouei, T. P. Breckon, GANomaly:
    Semi-supervised Anomaly Detection via Adversarial Training, in: Asian Conference
    on Computer Vision - ACCV, Springer, 2019a, pp. 622–637.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Akcay 等 [2019a] S. Akcay, A. Atapour-Abarghouei, T. P. Breckon, GANomaly: 通过对抗训练的半监督异常检测，见：亚洲计算机视觉会议
    - ACCV，Springer，2019a，第 622–637 页。'
- en: 'Akcay et al. [2019b] S. Akcay, A. Atapour-Abarghouei, T. P. Breckon, Skip-GANomaly:
    Skip Connected and Adversarially Trained Encoder-Decoder Anomaly Detection, in:
    International Joint Conference on Neural Networks (IJCNN), IEEE, 2019b, pp. 1–8.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Akcay 等 [2019b] S. Akcay, A. Atapour-Abarghouei, T. P. Breckon, Skip-GANomaly:
    跳过连接和对抗训练的编码器-解码器异常检测，见：国际联合神经网络会议 (IJCNN)，IEEE，2019b，第 1–8 页。'
- en: 'Griffin et al. [2019] L. D. Griffin, M. Caldwell, J. T. A. Andrews, H. Bohler,
    “Unexpected Item in the Bagging Area”: Anomaly Detection in X-Ray Security Images,
    IEEE Transactions on Information Forensics and Security 14 (2019) 1539–1553.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Griffin 等 [2019] L. D. Griffin, M. Caldwell, J. T. A. Andrews, H. Bohler, “袋区意外物品”：X
    射线安全图像中的异常检测，IEEE 信息取证与安全交易 14 (2019) 1539–1553。
- en: Caldwell and Griffin [2019] M. Caldwell, L. D. Griffin, Limits on transfer learning
    from photographic image data to X-ray threat detection, Journal of X-Ray Science
    and Technology (2019) 1–14.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caldwell 和 Griffin [2019] M. Caldwell, L. D. Griffin, 从摄影图像数据到 X 射线威胁检测的迁移学习限制，X
    射线科学与技术杂志 (2019) 1–14。
- en: Mery [2015] D. Mery, Computer Vision for X-Ray Testing, Springer International
    Publishing, Cham, 2015.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery [2015] D. Mery, X 射线检测中的计算机视觉，Springer 国际出版，Cham，2015 年。
- en: 'Mery et al. [2015] D. Mery, V. Riffo, U. Zscherpel, G. Mondragón, I. Lillo,
    I. Zuccar, H. Lobel, M. Carrasco, GDXray: The Database of X-ray Images for Nondestructive
    Testing, Journal of Nondestructive Evaluation 34 (2015) 42.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mery 等 [2015] D. Mery, V. Riffo, U. Zscherpel, G. Mondragón, I. Lillo, I. Zuccar,
    H. Lobel, M. Carrasco, GDXray: 用于无损检测的 X 射线图像数据库，非破坏性评估杂志 34 (2015) 42。'
- en: Centre for Applied Scienceand Technology (2016) [CAST] Centre for Applied Scienceand
    Technology (CAST), OSCT Borders X-ray Image Library, Technical Report, UK Home
    Office, 2016.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用科学与技术中心 (2016) [CAST] 应用科学与技术中心 (CAST)，OSCT 边境 X 射线图像库，技术报告，英国内政部，2016 年。
- en: 'Wei et al. [2020] Y. Wei, R. Tao, Z. Wu, Y. Ma, L. Zhang, X. Liu, Occluded
    Prohibited Items Detection: An X-ray Security Inspection Benchmark and De-occlusion
    Attention Module, in: Proceedings of the 28th ACM International Conference on
    Multimedia, ACM, New York, NY, USA, 2020, pp. 138–146.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei等人[2020] Y. Wei, R. Tao, Z. Wu, Y. Ma, L. Zhang, X. Liu, 《遮挡禁忌物品检测：一个X射线安全检查基准和去遮挡注意力模块》，见：第28届ACM国际多媒体会议论文集，ACM，纽约，NY，USA，2020，第138–146页。
- en: 'Mery and Arteta [2017] D. Mery, C. Arteta, Automatic Defect Recognition in
    X-Ray Testing Using Computer Vision, in: Winter Conference on Applications of
    Computer Vision (WACV), IEEE, 2017, pp. 1026–1035.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery和Arteta[2017] D. Mery, C. Arteta, 《使用计算机视觉的X射线检测中的自动缺陷识别》，见：冬季计算机视觉应用会议（WACV），IEEE，2017，第1026–1035页。
- en: Dhiraj and Jain [2019] Dhiraj, D. K. Jain, An Evaluation Of Deep Learning-Based
    Object Detection Strategies For Threat Object Detection In Baggage Security Imagery,
    Pattern Recognition Letters 120 (2019) 112–119.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dhiraj和Jain[2019] Dhiraj, D. K. Jain, 《基于深度学习的目标检测策略在行李安全影像中的威胁对象检测评估》，模式识别快报
    120 (2019) 112–119。
- en: 'Morris et al. [2018] T. Morris, T. Chien, E. Goodman, Convolutional Neural
    Networks for Automatic Threat Detection in Security X-Ray Images, in: International
    Conference on Machine Learning and Applications (ICMLA), IEEE, 2018, pp. 285–292.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Morris等人[2018] T. Morris, T. Chien, E. Goodman, 《用于安全X射线图像自动威胁检测的卷积神经网络》，见：国际机器学习与应用会议（ICMLA），IEEE，2018，第285–292页。
- en: 'Liang et al. [2018] K. Liang, C. Gregory, S. O. Diallo, K. Roe, G. Heilmann,
    L. Carin, D. Carlson, G. Spell, J. Sigman, Automatic Threat Recognition Of Prohibited
    Items At Aviation Checkpoint With X-ray Imaging: A Deep Learning Approach, in:
    A. Ashok, M. A. Neifeld, M. E. Gehm, J. A. Greenberg (Eds.), Anomaly Detection
    and Imaging with X-Rays (ADIX) III, SPIE, 2018, p. 2.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang等人[2018] K. Liang, C. Gregory, S. O. Diallo, K. Roe, G. Heilmann, L. Carin,
    D. Carlson, G. Spell, J. Sigman, 《利用X射线成像在航空检查点自动识别禁忌物品：一种深度学习方法》，见：A. Ashok,
    M. A. Neifeld, M. E. Gehm, J. A. Greenberg (编)，《异常检测与X射线成像（ADIX）III》，SPIE，2018，第2页。
- en: Yang et al. [2019] J. Yang, Z. Zhao, H. Zhang, Y. Shi, Data Augmentation for
    X-Ray Prohibited Item Images Using Generative Adversarial Networks, IEEE Access
    (2019) 1–1.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang等人[2019] J. Yang, Z. Zhao, H. Zhang, Y. Shi, 《利用生成对抗网络进行X射线禁忌物品图像的数据增强》，IEEE
    Access (2019) 1–1。
- en: 'Chan et al. [2010] J. Chan, P. Evans, X. Wang, Enhanced Color Coding Scheme
    For Kinetic Depth Effect X-ray (KDEX) Imaging, in: International Carnahan Conference
    on Security Technology, IEEE, 2010, pp. 155–160.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chan等人[2010] J. Chan, P. Evans, X. Wang, 《用于动力深度效应X射线（KDEX）成像的增强色彩编码方案》，见：国际卡纳汉安全技术会议，IEEE，2010，第155–160页。
- en: 'Cutler and Paddock [2009] V. Cutler, S. Paddock, Use Of Threat Image Projection
    (TIP) To Enhance Security Performance, in: International Carnahan Conference on
    Security Technology, IEEE, 2009, pp. 46–51.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cutler和Paddock[2009] V. Cutler, S. Paddock, 《利用威胁图像投影（TIP）提升安全性能》，见：国际卡纳汉安全技术会议，IEEE，2009，第46–51页。
- en: 'Bhowmik et al. [2019] N. Bhowmik, Q. Wang, Y. F. A. Gaus, M. Szarek, T. P.
    Breckon, The Good, the Bad and the Ugly: Evaluating Convolutional Neural Networks
    for Prohibited Item Detection Using Real and Synthetically Composited X-ray Imagery,
    in: British Machine Vision Conference (BMVC) Workshops.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bhowmik等人[2019] N. Bhowmik, Q. Wang, Y. F. A. Gaus, M. Szarek, T. P. Breckon,
    《好、坏与丑：评估用于禁忌物品检测的卷积神经网络，使用真实与合成X射线图像》，见：英国机器视觉会议（BMVC）研讨会。
- en: 'Hartigan and Wong [1979] J. A. Hartigan, M. A. Wong, Algorithm AS 136: A K-Means
    Clustering Algorithm, Applied Statistics 28 (1979) 100.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hartigan和Wong[1979] J. A. Hartigan, M. A. Wong, 《算法AS 136：K均值聚类算法》，应用统计 28 (1979)
    100。
- en: Breiman [2001] L. Breiman, Random Forests, Machine Learning 45 (2001) 5–32.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Breiman[2001] L. Breiman, 《随机森林》，机器学习 45 (2001) 5–32。
- en: Hearst et al. [1998] M. Hearst, S. Dumais, E. Osuna, J. Platt, B. Scholkopf,
    Support Vector Machines, IEEE Intelligent Systems and their Applications 13 (1998)
    18–28.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hearst等人[1998] M. Hearst, S. Dumais, E. Osuna, J. Platt, B. Scholkopf, 《支持向量机》，IEEE智能系统及其应用
    13 (1998) 18–28。
- en: 'Xu et al. [2019] Z. Xu, S. Lyu, W. Jin, Y. Lu, Modified Adaptive Implicit Shape
    Model for Object Detection, in: Communications in Computer and Information Science,
    Springer, 2019, pp. 144–151.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu等人[2019] Z. Xu, S. Lyu, W. Jin, Y. Lu, 《用于目标检测的改进自适应隐式形状模型》，见：计算机与信息科学通讯，Springer，2019，第144–151页。
- en: Lazebnik et al. [2005] S. Lazebnik, C. Schmid, J. Ponce, A sparse texture representation
    using local affine regions, IEEE Transactions on Pattern Analysis and Machine
    Intelligence 27 (2005) 1265–1278.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lazebnik等人[2005] S. Lazebnik, C. Schmid, J. Ponce, 《一种使用局部仿射区域的稀疏纹理表示》，IEEE模式分析与机器智能学报
    27 (2005) 1265–1278。
- en: 'Michel and Schwaninger [2009] S. Michel, A. Schwaninger, Human-machine Interaction
    In X-ray Screening, in: International Carnahan Conference on Security Technology,
    IEEE, 2009, pp. 13–19.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Michel和Schwaninger [2009] S. Michel, A. Schwaninger, X射线筛查中的人机交互，发表于：国际卡纳汉安全技术会议，IEEE，2009年，第13–19页。
- en: Bastian et al. [2008] C. C. V. Bastian, A. Schwaninger, S. Michel, Do Multi-view
    X-ray Systems Improve X-ray Image In- Terpretation In Airport Security Screening
    ?, Zeitschrift für Arbeitswissenschaft 3 (2008) 166–173.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bastian等人 [2008] C. C. V. Bastian, A. Schwaninger, S. Michel, 多视角X射线系统是否改善了机场安检中的X射线图像解读？，《工作科学期刊》3（2008）166–173。
- en: Mery et al. [2017] D. Mery, V. Riffo, I. Zuccar, C. Pieringer, Object Recognition
    In X-ray Testing Using An Efficient Search Algorithm In Multiple Views, Insight
    - Non-Destructive Testing and Condition Monitoring 59 (2017) 85–92.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mery等人 [2017] D. Mery, V. Riffo, I. Zuccar, C. Pieringer, 使用高效搜索算法在多视角中进行X射线测试中的物体识别，《Insight
    - 无损检测与状态监测》59（2017）85–92。
- en: Cover and Hart [1967] T. Cover, P. Hart, Nearest Neighbor Pattern Classification,
    IEEE Transactions on Information Theory 13 (1967) 21–27.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cover和Hart [1967] T. Cover, P. Hart, 最近邻模式分类，《IEEE信息理论汇刊》13（1967）21–27。
- en: 'Wang et al. [2005] L. Wang, Y. Li, J. Ding, K. Li, Structural X-ray Image Segmentation
    for Threat Detection by Attribute Relational Graph Matching, in: 2005 International
    Conference on Neural Networks and Brain, IEEE, 2005, pp. 1206–1211.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人 [2005] L. Wang, Y. Li, J. Ding, K. Li, 用于威胁检测的结构化X射线图像分割，通过属性关系图匹配，发表于：2005年国际神经网络与大脑会议，IEEE，2005年，第1206–1211页。
- en: Mallia-Parfitt and Giasemidis [2019] N. Mallia-Parfitt, G. Giasemidis, Graph
    clustering and variational image segmentation for automated firearm detection
    in X-ray images, IET Image Processing 13 (2019) 1105–1114.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mallia-Parfitt和Giasemidis [2019] N. Mallia-Parfitt, G. Giasemidis, 图形聚类与变分图像分割用于X射线图像中自动化枪支检测，《IET图像处理》13（2019）1105–1114。
- en: 'He et al. [2016] K. He, X. Zhang, S. Ren, J. Sun, Deep Residual Learning for
    Image Recognition, in: Conference on Computer Vision and Pattern Recognition (CVPR),
    volume 7, IEEE, 2016, pp. 770–778.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He等人 [2016] K. He, X. Zhang, S. Ren, J. Sun, 用于图像识别的深度残差学习，发表于：计算机视觉与模式识别会议（CVPR），第7卷，IEEE，2016年，第770–778页。
- en: 'Redmon and Farhadi [2018] J. Redmon, A. Farhadi, YOLOv3: An Incremental Improvement,
    Technical Report, 2018.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redmon和Farhadi [2018] J. Redmon, A. Farhadi, YOLOv3：增量改进，技术报告，2018年。
- en: 'He et al. [2017] K. He, G. Gkioxari, P. Dollar, R. Girshick, Mask R-CNN, in:
    International Conference on Computer Vision (ICCV), IEEE, 2017, pp. 2961–2969.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He等人 [2017] K. He, G. Gkioxari, P. Dollar, R. Girshick, Mask R-CNN，发表于：国际计算机视觉会议（ICCV），IEEE，2017年，第2961–2969页。
- en: 'Krizhevsky et al. [2012] A. Krizhevsky, I. Sutskever, G. E. Hinton, ImageNet
    Classification with Deep Convolutional Neural Networks, in: Conference on Neural
    Information Processing Systems (NeurIPS), Curran Associates, Inc., 2012, pp. 1097–1105.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky等人 [2012] A. Krizhevsky, I. Sutskever, G. E. Hinton, 使用深度卷积神经网络进行ImageNet分类，发表于：神经信息处理系统会议（NeurIPS），Curran
    Associates, Inc.，2012年，第1097–1105页。
- en: 'Simonyan and Zisserman [2015] K. Simonyan, A. Zisserman, Very Deep Convolutional
    Networks for Large-Scale Image Recognition, in: International Conference on Learning
    Representations (ICLR).'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simonyan和Zisserman [2015] K. Simonyan, A. Zisserman, 用于大规模图像识别的非常深层卷积网络，发表于：国际学习表征会议（ICLR）。
- en: Griffin et al. [2009] L. D. Griffin, M. Lillholm, M. Crosier, J. van Sande,
    Basic Image Features (BIFs) Arising from Approximate Symmetry Type, Springer,
    Berlin, Heidelberg, 2009, pp. 343–355.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Griffin等人 [2009] L. D. Griffin, M. Lillholm, M. Crosier, J. van Sande, 从近似对称类型中产生的基本图像特征（BIFs），Springer，柏林，海德堡，2009年，第343–355页。
- en: 'Bosch et al. [2007] A. Bosch, A. Zisserman, X. Munoz, Representing Shape With
    A Spatial Pyramid Kernel, in: International Conference On Image And Video Retrieval
    (CIVR), ACM Press, 2007, pp. 401–408.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bosch等人 [2007] A. Bosch, A. Zisserman, X. Munoz, 使用空间金字塔核表示形状，发表于：国际图像与视频检索会议（CIVR），ACM出版社，2007年，第401–408页。
- en: 'Arjovsky et al. [2017] M. Arjovsky, S. Chintala, L. Bottou, Wasserstein GAN,
    in: International Conference on Machine Learning (ICML), PMLR, 2017, pp. 214–223.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arjovsky等人 [2017] M. Arjovsky, S. Chintala, L. Bottou, Wasserstein GAN，发表于：国际机器学习会议（ICML），PMLR，2017年，第214–223页。
- en: 'Isola et al. [2017] P. Isola, J.-Y. Zhu, T. Zhou, A. A. Efros, Image-to-Image
    Translation with Conditional Adversarial Networks, in: Conference on Computer
    Vision and Pattern Recognition (CVPR), IEEE, 2017, pp. 5967–5976.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Isola等人 [2017] P. Isola, J.-Y. Zhu, T. Zhou, A. A. Efros, 条件对抗网络的图像到图像翻译，发表于：计算机视觉与模式识别会议（CVPR），IEEE，2017年，第5967–5976页。
- en: 'Chollet [2017] F. Chollet, Xception: Deep Learning with Depthwise Separable
    Convolutions, in: Conference on Computer Vision and Pattern Recognition (CVPR),
    IEEE, 2017, pp. 1800–1807.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chollet [2017] F. Chollet, Xception: 深度学习中的深度可分离卷积，见：计算机视觉与模式识别会议（CVPR），IEEE，2017，第
    1800–1807 页。'
- en: 'Szegedy et al. [2016] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna,
    Rethinking the Inception Architecture for Computer Vision, in: Conference on Computer
    Vision and Pattern Recognition (CVPR), IEEE, 2016, pp. 2818–2826.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等 [2016] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna, 重新思考计算机视觉中的
    Inception 架构，见：计算机视觉与模式识别会议（CVPR），IEEE，2016，第 2818–2826 页。
- en: 'Ren et al. [2017] S. Ren, K. He, R. Girshick, J. Sun, Faster R-CNN: Towards
    Real-Time Object Detection with Region Proposal Networks, IEEE Transactions on
    Pattern Analysis and Machine Intelligence (PAMI) 39 (2017) 1137–1149.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ren 等 [2017] S. Ren, K. He, R. Girshick, J. Sun, Faster R-CNN: 通过区域提议网络实现实时物体检测，IEEE
    模式分析与机器智能（PAMI）39（2017）1137–1149。'
- en: 'Dai et al. [2016] J. Dai, Y. Li, K. He, J. Sun, R-FCN: Object Detection via
    Region-based Fully Convolutional Networks, in: International Conference on Neural
    Information Processing Systems (NeurIPS), pp. 379–387.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dai 等 [2016] J. Dai, Y. Li, K. He, J. Sun, R-FCN: 通过基于区域的全卷积网络进行物体检测，见：神经信息处理系统会议（NeurIPS），第
    379–387 页。'
- en: 'Sigman et al. [2020] J. B. Sigman, G. P. Spell, K. J. Liang, L. Carin, Background
    adaptive faster R-CNN for semi-supervised convolutional object detection of threats
    in x-ray images, in: A. Ashok, M. E. Gehm, J. A. Greenberg (Eds.), Anomaly Detection
    and Imaging with X-Rays (ADIX) V, SPIE, 2020, p. 5.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sigman 等 [2020] J. B. Sigman, G. P. Spell, K. J. Liang, L. Carin, 背景自适应 Faster
    R-CNN 用于 X 射线图像中威胁的半监督卷积物体检测，见：A. Ashok, M. E. Gehm, J. A. Greenberg（编），X 射线异常检测与成像（ADIX）V，SPIE，2020，第
    5 页。
- en: 'Liu et al. [2016] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y.
    Fu, A. C. Berg, SSD: Single Shot MultiBox Detector, in: European Conference on
    Computer Vision (ECCV), Springer, Cham, 2016, pp. 21–37.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等 [2016] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu,
    A. C. Berg, SSD: 单次多框检测器，见：欧洲计算机视觉会议（ECCV），Springer，Cham，2016，第 21–37 页。'
- en: Lin et al. [2018] T. Y. Lin, P. Goyal, R. Girshick, K. He, P. Dollar, Focal
    loss for dense object detection, IEEE Transactions on Pattern Analysis and Machine
    Intelligence (2018).
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等 [2018] T. Y. Lin, P. Goyal, R. Girshick, K. He, P. Dollar, 用于密集物体检测的焦点损失，IEEE
    模式分析与机器智能（2018）。
- en: Hassan et al. [2020] T. Hassan, S. Akcay, M. Bennamoun, S. Khan, N. Werghi,
    Cascaded Structure Tensor Framework for Robust Identification of Heavily Occluded
    Baggage Items from X-ray Scans, arXiv (2020).
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hassan 等 [2020] T. Hassan, S. Akcay, M. Bennamoun, S. Khan, N. Werghi, 用于从 X
    射线扫描中稳健识别严重遮挡行李物品的级联结构张量框架，arXiv（2020）。
- en: 'Jinyi et al. [2019] L. Jinyi, J. Leng, Y. Liu, Deep Convolutional Neural Network
    Based Object Detector for X-Ray Baggage Security Imagery, in: Proceedings of the
    International Conference on Tools with Artificial Intelligence (ICTAI), IEEE,
    2019.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jinyi 等 [2019] L. Jinyi, J. Leng, Y. Liu, 基于深度卷积神经网络的 X 射线行李安检图像物体检测器，见：国际人工智能工具会议（ICTAI）论文集，IEEE，2019。
- en: 'Bhowmik et al. [2019] N. Bhowmik, Y. F. A. Gaus, S. Akcay, J. W. Barker, T. P.
    Breckon, On the Impact of Object and Sub-component Level Segmentation Strategies
    for Supervised Anomaly Detection within X-ray Security Imagery, in: Procedings
    of the International Conference on Machine Learning Applications (ICMLA), IEEE,
    2019.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bhowmik 等 [2019] N. Bhowmik, Y. F. A. Gaus, S. Akcay, J. W. Barker, T. P. Breckon,
    物体及子组件级分割策略对 X 射线安全图像中监督异常检测的影响，见：国际机器学习应用会议（ICMLA）论文集，IEEE，2019。
- en: 'An et al. [2019] J. An, H. Zhang, Y. Zhu, J. Yang, Semantic Segmentation for
    Prohibited Items in Baggage Inspection, in: Lecture Notes in Computer Science,
    Springer, 2019, pp. 495–505.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: An 等 [2019] J. An, H. Zhang, Y. Zhu, J. Yang, 行李检查中禁止物品的语义分割，见：计算机科学讲义，Springer，2019，第
    495–505 页。
- en: 'Sterchi et al. [2017] Y. Sterchi, N. Hättenschwiler, S. Michel, A. Schwaninger,
    Relevance of visual inspection strategy and knowledge about everyday objects for
    X-ray baggage screening, in: International Carnahan Conference on Security Technology
    (ICCST), IEEE, 2017, pp. 1–6.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sterchi 等 [2017] Y. Sterchi, N. Hättenschwiler, S. Michel, A. Schwaninger, 视觉检查策略及对日常物品的知识在
    X 射线行李筛查中的相关性，见：国际卡纳汉安全技术会议（ICCST），IEEE，2017，第 1–6 页。
- en: Lecun et al. [1998] Y. Lecun, L. Bottou, Y. Bengio, P. Haffner, Gradient-based
    Learning Applied To Document Recognition, Proceedings of the IEEE 86 (1998) 2278–2324.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lecun 等 [1998] Y. Lecun, L. Bottou, Y. Bengio, P. Haffner, 基于梯度的学习应用于文档识别，IEEE
    论文集 86（1998）2278–2324。
- en: Liu et al. [2012] F. T. Liu, K. M. Ting, Z.-H. Zhou, Isolation-Based Anomaly
    Detection, ACM Transactions on Knowledge Discovery from Data 6 (2012) 1–39.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2012] F. T. Liu, K. M. Ting, Z.-H. Zhou, 基于孤立的异常检测, ACM 数据知识发现交易 6 (2012)
    1–39。
- en: 'Islam et al. [2018] A. Islam, Y. Zhang, D. Yin, O. Camps, R. J. Radke, Correlating
    Belongings with Passengers in a Simulated Airport Security Checkpoint, in: International
    Conference on Distributed Smart Cameras (ICDSC), ACM Press, 2018, pp. 1–7.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Islam 等人 [2018] A. Islam, Y. Zhang, D. Yin, O. Camps, R. J. Radke, 在模拟机场安全检查点中将物品与乘客相关联,
    见: 分布式智能摄像机国际会议 (ICDSC), ACM Press, 2018, pp. 1–7。'
- en: 'An et al. [2019] J. An, H. Zhang, Y. Zhu, J. Yang, Semantic Segmentation for
    Prohibited Items in Baggage Inspection, in: Lecture Notes in Computer Science,
    Springer, 2019, pp. 495–505.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'An 等人 [2019] J. An, H. Zhang, Y. Zhu, J. Yang, 行李检查中的禁止物品语义分割, 见: 计算机科学讲义笔记,
    Springer, 2019, pp. 495–505。'
- en: 'Szegedy et al. [2017] C. Szegedy, S. Ioffe, V. Vanhoucke, A. Alemi, Inception-v4,
    Inception-ResNet and the Impact of Residual Connections on Learning, in: AAAI
    Conference on Artificial Intelligence.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Szegedy 等人 [2017] C. Szegedy, S. Ioffe, V. Vanhoucke, A. Alemi, Inception-v4,
    Inception-ResNet 及残差连接对学习的影响, 见: AAAI 人工智能会议。'
- en: 'Zhu et al. [2017] J.-Y. Zhu, T. Park, P. Isola, A. A. Efros, Unpaired Image-to-Image
    Translation, in: International Conference on Computer Vision (ICCV), IEEE, 2017,
    pp. 2223–2232.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu 等人 [2017] J.-Y. Zhu, T. Park, P. Isola, A. A. Efros, 无配对的图像到图像翻译, 见: 计算机视觉国际会议
    (ICCV), IEEE, 2017, pp. 2223–2232。'
- en: Karras et al. [2019] T. Karras, S. Laine, M. Aittala, J. Hellsten, J. Lehtinen,
    T. Aila, Analyzing and Improving the Image Quality of StyleGAN, CoRR (2019).
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karras 等人 [2019] T. Karras, S. Laine, M. Aittala, J. Hellsten, J. Lehtinen,
    T. Aila, 分析和改进 StyleGAN 的图像质量, CoRR (2019)。
- en: Chen et al. [2007] G. Chen, G. Bennett, D. Perticone, Dual-energy X-ray Radiography
    For Automatic High- Z Material Detection, Nuclear Instruments and Methods in Physics
    Research B 261 (2007) 356–359.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 [2007] G. Chen, G. Bennett, D. Perticone, 用于自动高 Z 材料检测的双能 X 射线摄影, 核科学与技术研究
    B 261 (2007) 356–359。
- en: 'Fu et al. [2010] K. Fu, D. Ranta, P. Das, C. Guest, Layer Separation For Material
    Discrimination Cargo Imaging System, in: Image Processing: Machine Vision Applications
    III, volume 7538, SPIE, 2010, p. 75380Y.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fu 等人 [2010] K. Fu, D. Ranta, P. Das, C. Guest, 材料鉴别货物成像系统的层分离, 见: 图像处理：机器视觉应用
    III, 第 7538 卷, SPIE, 2010, p. 75380Y。'
