- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:02:01'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:02:01
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2003.06979] Anomalous Instance Detection in Deep Learning: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2003.06979] 深度学习中的异常实例检测：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2003.06979](https://ar5iv.labs.arxiv.org/html/2003.06979)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2003.06979](https://ar5iv.labs.arxiv.org/html/2003.06979)
- en: 'Anomalous Instance Detection in Deep Learning: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习中的异常实例检测：综述
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep Learning (DL) is vulnerable to out-of-distribution and adversarial examples
    resulting in incorrect outputs. To make DL more robust, several posthoc anomaly
    detection techniques to detect (and discard) these anomalous samples have been
    proposed in the recent past. This survey tries to provide a structured and comprehensive
    overview of the research on anomaly detection for DL based applications. We provide
    a taxonomy for existing techniques based on their underlying assumptions and adopted
    approaches. We discuss various techniques in each of the categories and provide
    the relative strengths and weaknesses of the approaches. Our goal in this survey
    is to provide an easier yet better understanding of the techniques belonging to
    different categories in which research has been done on this topic. Finally, we
    highlight the unsolved research challenges while applying anomaly detection techniques
    in DL systems and present some high-impact future research directions.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）对分布外和对抗样本比较脆弱，这会导致不正确的输出。为了增强深度学习的鲁棒性，近年来提出了几种后处理异常检测技术，以检测（并丢弃）这些异常样本。本综述试图提供一个结构化和全面的深度学习应用中异常检测研究的概述。我们根据现有技术的基本假设和采用的方法提供了一个分类法。我们讨论了各类别中的各种技术，并提供了这些方法的相对优缺点。我们在本综述中的目标是提供对属于不同类别的技术的更简单但更好的理解，这些类别中都进行了相关的研究。最后，我们突出指出了在深度学习系统中应用异常检测技术时尚未解决的研究挑战，并提出了一些高影响力的未来研究方向。
- en: 1 Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Deep Learning (DL) techniques provide incredible opportunities to answer some
    of the most important and difficult questions in a wide range of applications
    in science and engineering. Therefore, scientists and engineers are increasingly
    adopting the use of DL for making potentially important decisions in the context
    of applications of interest, such as bioinformatics, healthcare, cyber-security,
    and fully autonomous vehicles. Several of these applications are often high-regret
    (i.e., incurring significant costs) in nature. In such applications, incorrect
    decisions or predictions have significant costs either in terms of experimental
    resources when testing drugs, lost opportunities to observe rare phenomena, or
    in health and safety when certifying parts. Most DL methods implicitly assume
    ideal conditions and rely on the assumption that test data comes from the “same
    distribution” as the training data. However, this assumption is not satisfied
    in many real-world applications and virtually all problems require various levels
    of transformation of the DL output as test data is typically different from the
    training data either due to noise, adversarial corruptions, or other changes in
    distribution possibly due to temporal and spatial effects. These deviant (or out-of-distribution)
    data samples are often referred to as anomalies, outliers, novelties in different
    domains. It is well known that DL models are highly sensitive to such anomalies,
    which often leads to unintended and potentially harmful consequences due to incorrect
    results generated by DL. Hence, it is critical to determine whether the incoming
    test data is so different from the training dataset that the output of the model
    cannot be trusted (referred to as the anomaly detection problem).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）技术在科学和工程的广泛应用中提供了回答一些最重要和困难问题的极好机会。因此，科学家和工程师越来越多地采用DL来在感兴趣的应用领域中做出潜在重要的决策，例如生物信息学、医疗保健、网络安全以及完全自主车辆。这些应用中的几个往往具有高度后悔性（即，产生重大成本）。在这些应用中，不正确的决策或预测会带来显著的成本，无论是在测试药物时的实验资源、观察稀有现象的丧失机会，还是在认证零部件时的健康和安全。大多数DL方法隐含地假设理想条件，并依赖于测试数据来自与训练数据“相同分布”的假设。然而，这一假设在许多实际应用中并未得到满足，几乎所有问题都需要对DL输出进行各种级别的转换，因为测试数据通常与训练数据不同，可能由于噪声、对抗性破坏或其他由于时间和空间效应引起的分布变化。这些偏离（或分布外）数据样本在不同领域中通常被称为异常、离群点、新奇点。众所周知，DL模型对这些异常数据非常敏感，这常常导致由于DL生成的不正确结果而产生意外和潜在的有害后果。因此，确定输入的测试数据是否与训练数据集差异如此之大，以至于模型的输出无法被信任（称为异常检测问题）是至关重要的。
- en: Due to its practical importance, anomaly detection has received a lot of attention
    from statistics, signal processing and machine learning communities. Recently,
    there has been a surge of interest in devising anomaly detection methods for DL
    applications. This survey aims to provide a structured overview of recent studies
    and approaches to anomaly detection in DL based high-regret applications. To the
    best of our knowledge, there has not been any comprehensive review of anomaly
    detection approaches in DL systems. Although a number of surveys have appeared
    for conventional machine learning applications, none of these are specifically
    for DL applications. This has motivated this survey paper especially in light
    of recent research results in DL. We expect that this review will facilitate a
    better understanding of the different directions in which research has been carried
    out on this topic and potential high-impact future directions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其实际重要性，异常检测受到了统计学、信号处理和机器学习社区的广泛关注。最近，对于DL应用中的异常检测方法的兴趣激增。本调查旨在提供一个结构化的概述，涵盖了DL基础上的高后悔应用中的异常检测的最新研究和方法。据我们所知，尚未有任何关于DL系统中异常检测方法的全面综述。尽管出现了许多针对传统机器学习应用的综述，但没有专门针对DL应用的综述。这激发了这篇综述论文的写作，特别是考虑到最近DL研究结果。我们期望这项评审将有助于更好地理解在这一主题上的研究方向及潜在的高影响未来方向。
- en: 1.1 What are Anomalies?
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 什么是异常？
- en: 'The problem setup for anomaly detection in deep neural networks (DNNs) is as
    follows: the DNN is trained on in-distribution data and is asked to perform predictions
    on both in-distribution as well as out-of-distribution (OOD) test samples. In-distribution
    test samples are from the same distribution as the training data and the trained
    DNN is expected to perform reliably on them. On the other hand, anomalous test
    samples are samples which do not conform to the distribution of the training data.
    Therefore, predictions of DNNs based on these anomalous samples should not be
    trusted. The goal of the anomaly detection problem is to design post-hoc detectors
    to detect these nonconforming test samples (see Fig. [1](#S1.F1 "Figure 1 ‣ 1.1
    What are Anomalies? ‣ 1 Introduction ‣ Anomalous Instance Detection in Deep Learning:
    A Survey")).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '异常检测在深度神经网络（DNNs）中的问题设置如下：DNN在内部分布数据上进行训练，并要求对内部分布和外部分布（OOD）测试样本进行预测。内部分布测试样本来自与训练数据相同的分布，训练后的DNN预计能对其做出可靠的预测。另一方面，异常测试样本是指那些不符合训练数据分布的样本。因此，基于这些异常样本的DNN预测不应被信任。异常检测问题的目标是设计事后检测器来检测这些不符合分布的测试样本（参见图
    [1](#S1.F1 "Figure 1 ‣ 1.1 What are Anomalies? ‣ 1 Introduction ‣ Anomalous Instance
    Detection in Deep Learning: A Survey")）。'
- en: '![Refer to caption](img/4dee0d0c37d30243faf42cf4eb4d30d7.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4dee0d0c37d30243faf42cf4eb4d30d7.png)'
- en: 'Fig. 1: Schematic of anomaly detection in DL.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：深度学习中的异常检测示意图。
- en: 'Next we discuss the types of anomalies, and present their respective differences.
    We classify anomalies into (a) unintentional and (b) intentional (see Fig. [2](#S1.F2
    "Figure 2 ‣ 1.1.2 Intentional: Adversarial Examples ‣ 1.1 What are Anomalies?
    ‣ 1 Introduction ‣ Anomalous Instance Detection in Deep Learning: A Survey"))
    types. Unintentional anomalies are independent of the DNN model, as opposed to,
    intentional anomalies which are intentionally designed by an attacker to force
    the DNN model to yield incorrect results, and are model dependent.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '接下来，我们讨论异常的类型，并展示它们各自的差异。我们将异常分为（a）非故意的和（b）故意的（参见图 [2](#S1.F2 "Figure 2 ‣ 1.1.2
    Intentional: Adversarial Examples ‣ 1.1 What are Anomalies? ‣ 1 Introduction ‣
    Anomalous Instance Detection in Deep Learning: A Survey")）。非故意的异常与DNN模型无关，而故意的异常是攻击者故意设计的，以迫使DNN模型产生不正确的结果，并且依赖于模型。'
- en: '1.1.1 Unintentional: Novel and out-of-distribution examples'
  id: totrans-17
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.1.1 非故意的：新颖和超出分布的示例
- en: 'The unintentional anomalies are further classified into novel and OOD examples¹¹1Note
    that we refer to samples as examples.. Novelty detection is the identification
    of new or unknown in-distribution data that a machine learning system is not aware
    of during training. However, the OOD example comes from a distribution other than
    that of the training data. The distinction between novelties and OOD data is that
    the novel data samples are typically incorporated into the normal model after
    being detected, however, OOD samples are usually discarded. In Fig. [2](#S1.F2
    "Figure 2 ‣ 1.1.2 Intentional: Adversarial Examples ‣ 1.1 What are Anomalies?
    ‣ 1 Introduction ‣ Anomalous Instance Detection in Deep Learning: A Survey"),
    the blue circles outside class boundaries are OOD examples. The OOD examples do
    not belong to any of the classes. In other words, the classifier is either unaware
    or does not recognize the OOD examples.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '非故意的异常进一步分为新颖和OOD示例¹¹注意我们将样本称为示例。新颖性检测是识别机器学习系统在训练期间未见过的新或未知的内部分布数据。然而，OOD示例来自与训练数据不同的分布。新颖数据和OOD数据的区别在于，新颖数据样本通常在检测后被纳入正常模型，而OOD样本通常被丢弃。在图
    [2](#S1.F2 "Figure 2 ‣ 1.1.2 Intentional: Adversarial Examples ‣ 1.1 What are
    Anomalies? ‣ 1 Introduction ‣ Anomalous Instance Detection in Deep Learning: A
    Survey")中，蓝色圆圈位于类别边界之外的是OOD示例。这些OOD示例不属于任何类别。换句话说，分类器要么无法识别，要么不认识这些OOD示例。'
- en: A related problem arises in Domain adaptation (DA) and transfer learning [[1](#bib.bib1)]
    which deal with scenarios where a model trained on a source distribution is used
    in the context of a different (but related) target distribution. The difference
    between the DA and OOD problems is that DA techniques assume that the test/target
    distribution is related to the task (or distribution) of interest (thus, utilized
    during training). On the other hand, OOD techniques are designed to detect if
    incoming data is so different (and unrelated) from the training data that the
    model cannot be trusted.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一个相关的问题出现在领域适应（DA）和迁移学习 [[1](#bib.bib1)] 中，这些方法处理的是一个在源分布上训练的模型在不同（但相关）目标分布的上下文中使用的情况。DA
    和 OOD 问题的区别在于，DA 技术假设测试/目标分布与感兴趣的任务（或分布）相关（因此，在训练过程中被利用）。另一方面，OOD 技术旨在检测输入数据是否与训练数据如此不同（且不相关），以至于模型无法被信任。
- en: '1.1.2 Intentional: Adversarial Examples'
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.1.2 有意：对抗样本
- en: 'The intentional anomalies (also known as the adversarial examples) are the
    test inputs that are intentionally designed by an attacker to coerce the model
    to make a mistake. For example, an attacker can modify the input image to fool
    the DNN classifier which could lead to unforeseen consequences, such as, accidents
    of autonomous cars or possible bank frauds. In Fig. [2](#S1.F2 "Figure 2 ‣ 1.1.2
    Intentional: Adversarial Examples ‣ 1.1 What are Anomalies? ‣ 1 Introduction ‣
    Anomalous Instance Detection in Deep Learning: A Survey"), the examples in red
    are adversarial in nature. Via small perturbation at the input, these examples
    have been moved to other class regions leading to misclassification. The classifier
    may or may not have access to some of the labels of these examples leading to
    different techniques in the literature.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有意异常（也称为对抗样本）是攻击者故意设计的测试输入，目的是迫使模型出错。例如，攻击者可以修改输入图像，以欺骗 DNN 分类器，这可能导致不可预见的后果，如自动驾驶汽车事故或可能的银行欺诈。在图
    Fig. [2](#S1.F2 "图 2 ‣ 1.1.2 有意：对抗样本 ‣ 1.1 什么是异常？ ‣ 1 引言 ‣ 深度学习中的异常实例检测：综述")中，红色的例子本质上是对抗样本。通过对输入进行小幅扰动，这些例子被移动到其他类别区域，导致错误分类。分类器可能会有或没有这些例子的一些标签，这导致文献中有不同的技术。
- en: '![Refer to caption](img/66cebd062954ce749b07916b994a6efa.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/66cebd062954ce749b07916b994a6efa.png)'
- en: 'Fig. 2: (a) A simple example of anomalies in a 2-dimensional data set. (b)
    Different variants of anomalous examples for the Panda vs. Gibbon classification
    problem. Captions indicate the true label and the color indicates whether the
    prediction is correct or wrong (blue for correct and red for wrong).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: (a) 二维数据集中异常的简单示例。 (b) Panda 和 Gibbon 分类问题的异常样本的不同变体。图注表示真实标签，颜色表示预测是否正确（蓝色为正确，红色为错误）。'
- en: 1.2 Challenges
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2 挑战
- en: 'As mentioned above, anomalies are data samples that do not comply with the
    expected normal behavior. Hence, a naive approach for detecting anomalies is to
    define a region in the data space that represents normal behavior and declare
    an example as anomaly if it does not lie in this region. However, there are several
    factors that make this seemingly simple method ineffective:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，异常是指不符合预期正常行为的数据样本。因此，检测异常的一个简单方法是定义一个代表正常行为的数据空间区域，如果一个样本不在该区域内，则将其声明为异常。然而，有几个因素使得这种看似简单的方法效果不佳：
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The boundary between the normal and anomalous regions is very difficult to define,
    especially, in complex DNN feature spaces.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在复杂的 DNN 特征空间中，正常和异常区域的边界非常难以定义。
- en: •
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Based on the type of applications, the definition of an anomaly changes. For
    certain applications, a small deviation in the classification result from that
    of the normal input data may have far reaching consequences and thus may be declared
    as anomaly. In other applications, the deviation needs to be large for the input
    to be declared as an anomaly.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据应用类型，异常的定义会有所不同。在某些应用中，分类结果与正常输入数据的轻微偏差可能会产生深远的后果，因此可能被声明为异常。在其他应用中，输入要被声明为异常，需要有较大的偏差。
- en: •
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The success of some anomaly detection techniques in the literature depends on
    the availability of the labels for the training and/or testing data.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 文献中一些异常检测技术的成功取决于训练和/或测试数据标签的可用性。
- en: •
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Anomaly detection is particularly difficult when the adversarial examples tend
    to disguise themselves as normal data.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当对抗样本趋向于伪装成正常数据时，异常检测尤其困难。
- en: The aforementioned difficulties make the anomaly detection problem difficult
    to solve in general. Therefore, most of the techniques in the literature tend
    to solve a specific instance of the general problem based on the type of application,
    type of input data and model, availability of labels for the training and/or testing
    data, and type of anomalies.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 上述困难使得异常检测问题一般很难解决。因此，大多数文献中的技术倾向于根据应用类型、输入数据和模型的类型、训练和/或测试数据标签的可用性以及异常的类型来解决一般问题的特定实例。
- en: 1.3 Related Work
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3 相关工作
- en: Anomaly detection is the subject of various surveys, review articles, and books.
    In [[2](#bib.bib2)], a comprehensive survey of various categories of anomaly detection
    techniques for conventional machine learning as well as statistical models is
    presented. For each category of detection, various techniques and their respective
    assumptions along with the advantages and disadvantages are discussed. The computational
    complexity of each technique is also mentioned. A comprehensive survey of the
    novelty detection techniques is presented in [[3](#bib.bib3)]. Various techniques
    are classified based on the statistical models used and the complexity of methods.
    Recently, an elaborate survey is presented in [[4](#bib.bib4)] where DL based
    anomaly detection techniques are discussed. Here, two more categories of anomaly
    detection, namely, hybrid models as well as one-class DNN techniques are also
    included. Note that our survey paper is different from [[4](#bib.bib4)] as our
    focus is on discussing unintentional and intentional anomalies specifically in
    the context of DNNs whereas [[4](#bib.bib4)] discusses approaches which use DNN
    based detectors applied to conventional ML problems. In some sense, our survey
    paper is much broader in the context of DL applications. In [[5](#bib.bib5)],
    a survey of the data mining techniques used for anomaly detection are discussed.
    The techniques discussed are clustering, regression, and rule learning. Furthermore,
    in [[6](#bib.bib6)], the authors discuss the models that are adaptive to account
    for the data coming from the dynamically changing characteristics of the environment
    and detect anomalies from the evolving data. Here, the techniques account for
    the change in the underlying data distribution and the corresponding unsupervised
    techniques are reviewed. In [[7](#bib.bib7)], the anomaly detection techniques
    are classified based on the type of data namely, metric data, evolving data, and
    multi-structured data. The metric data anomaly detection techniques consider the
    use of metrics like distance, correlation, and distribution. The evolving data
    include discrete sequences and time series. In [[8](#bib.bib8)], various statistical
    techniques, data mining based techniques, and machine learning based techniques
    for anomaly detection are discussed. In [[9](#bib.bib9), [10](#bib.bib10)], the
    existing techniques for anomaly detection which include statistical, neural network
    based, and other machine learning based techniques are discussed. Various books [[11](#bib.bib11),
    [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14)] also discussed the techniques
    for anomaly detection.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测是各种调查、综述文章和书籍的主题。在[[2](#bib.bib2)]中，提供了对传统机器学习及统计模型中各种异常检测技术类别的全面调查。每个检测类别中，讨论了各种技术及其各自的假设，以及优缺点。还提到了每种技术的计算复杂性。在[[3](#bib.bib3)]中，提供了对新颖性检测技术的全面调查。各种技术根据使用的统计模型和方法的复杂性进行分类。最近，在[[4](#bib.bib4)]中，提出了一项详细的调查，讨论了基于DL的异常检测技术。这里还包括了两个额外的异常检测类别，即混合模型以及单类DNN技术。请注意，我们的调查论文与[[4](#bib.bib4)]不同，因为我们的重点是讨论DNN中无意和有意的异常，而[[4](#bib.bib4)]讨论的是将DNN检测器应用于传统ML问题的方法。从某种意义上讲，我们的调查论文在DL应用的背景下要广泛得多。在[[5](#bib.bib5)]中，讨论了用于异常检测的数据挖掘技术。这些技术包括聚类、回归和规则学习。此外，在[[6](#bib.bib6)]中，作者讨论了适应性模型，这些模型考虑了来自环境动态变化特征的数据，并从不断变化的数据中检测异常。这里的技术考虑了基础数据分布的变化，并回顾了相应的无监督技术。在[[7](#bib.bib7)]中，异常检测技术根据数据类型分类，即度量数据、演变数据和多结构数据。度量数据异常检测技术考虑了距离、相关性和分布等度量的使用。演变数据包括离散序列和时间序列。在[[8](#bib.bib8)]中，讨论了各种统计技术、数据挖掘技术和机器学习技术用于异常检测。在[[9](#bib.bib9),
    [10](#bib.bib10)]中，讨论了现有的异常检测技术，包括统计、神经网络基础和其他机器学习技术。各种书籍[[11](#bib.bib11), [12](#bib.bib12),
    [13](#bib.bib13), [14](#bib.bib14)]也讨论了异常检测技术。
- en: 1.4 Our Contributions
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4 我们的贡献
- en: To the best of our knowledge, this survey is the first attempt to provide a
    structured and a broad overview of extensive research on detection techniques
    spanning both unintentional and intentional anomalies in the context of DNNs.
    Most of the existing surveys on anomaly detection focus on (i) anomaly detection
    techniques for conventional machine learning algorithms and statistical models,
    (ii) novelty detection techniques for statistical models, (iii) DL based anomaly
    detection techniques. In contrast, we provide a focused survey on post-hoc anomaly
    detection techniques for DL. We classify these techniques based on the availability
    of labels for the training data corresponding to anomalies, namely, supervised,
    semi-supervised, and unsupervised techniques. We discuss various techniques in
    each of the categories and provide the relative strengths and weaknesses of the
    approaches. We also briefly discuss anomaly detection techniques that do not fall
    in the post-hoc category, e.g.,training-based, architecture design, etc.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，本调查是首次尝试提供一个结构化且广泛的综述，涵盖了在深度神经网络（DNN）背景下无意和故意异常检测技术的广泛研究。现有的大多数异常检测综述集中于（i）传统机器学习算法和统计模型的异常检测技术，（ii）统计模型的异常检测技术，（iii）基于深度学习的异常检测技术。相比之下，我们提供了一个专注于深度学习事后异常检测技术的综述。我们根据训练数据中异常的标签可用性对这些技术进行分类，即监督、半监督和无监督技术。我们讨论了每个类别中的各种技术，并提供了这些方法的相对优缺点。我们还简要讨论了不属于事后类别的异常检测技术，例如基于训练的、架构设计等。
- en: '![Refer to caption](img/36cf3714a6c6228170eb5e32610c7896.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/36cf3714a6c6228170eb5e32610c7896.png)'
- en: 'Fig. 3: Schematic representation of different types of anomaly detection techniques
    discussed in this survey.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：本调查中讨论的不同类型异常检测技术的示意图。
- en: 1.5 Organization
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5 组织结构
- en: 'This survey is organized mainly in three parts: detection of unintentional
    anomalies, detection of intentional anomalies, and applications. For both unintentional
    and intentional anomalies, we will discuss different types of approaches (as illustrated
    in Fig. [3](#S1.F3 "Figure 3 ‣ 1.4 Our Contributions ‣ 1 Introduction ‣ Anomalous
    Instance Detection in Deep Learning: A Survey")). In Sec. 2, we present various
    post-hoc anomaly detection techniques which are used to detect unintentional anomalies.
    These techniques are classified based on the availability of labels. In Sec. 3,
    we present various post-hoc anomaly detection techniques which are used to detect
    intentional anomalies (or adversarial examples). The techniques are again classified
    based on the availability of labels. In Sec. 4, we discuss strengths and weaknesses
    of different categories of methods. In Sec. 5, we describe various application
    domains where anomaly detection is applied. Finally, we conclude and present open
    questions in this area in Sec. 6.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '本调查主要分为三部分：无意异常检测、故意异常检测和应用。对于无意和故意异常，我们将讨论不同类型的方法（如图[3](#S1.F3 "Figure 3 ‣
    1.4 Our Contributions ‣ 1 Introduction ‣ Anomalous Instance Detection in Deep
    Learning: A Survey")所示）。在第2节中，我们介绍了各种用于检测无意异常的事后异常检测技术。这些技术根据标签的可用性进行分类。在第3节中，我们介绍了各种用于检测故意异常（或对抗样本）的事后异常检测技术。这些技术同样根据标签的可用性进行分类。在第4节中，我们讨论了不同类别方法的优缺点。在第5节中，我们描述了异常检测应用的各种领域。最后，我们在第6节中总结并提出该领域的开放问题。'
- en: 2 Unintentional Anomaly Detection
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 无意异常检测
- en: In this section, we discuss the detection techniques which detect the OOD examples
    given a pre-trained neural network. Most DL approaches assume that the test examples
    belong to the same distribution as the training examples. Consequently, the neural
    networks are vulnerable to test examples which are OOD. Hence, we need techniques
    to improve the reliability of the predictions or determine whether the test example
    is different in distribution from that of the training dataset. Here, we concentrate
    on the techniques that determine whether the test example is different in distribution
    from that of the training dataset, using the pre-trained DNN followed by a detector.
    We refer to this architecture as post-hoc anomaly detection. A topic related to
    OOD example detection is novelty detection [[15](#bib.bib15), [16](#bib.bib16),
    [17](#bib.bib17)] which aims at detecting previously unobserved (emergent, novel)
    patterns in the data. It should be noted that solutions for novelty detection
    related problems are often used for OOD detection and vice-versa, and hence we
    use these terms interchangeably in this survey. Based on the availability of labels
    for OOD data, techniques are classified as supervised, semi-supervised, and unsupervised
    which are discussed next and summarized in Table LABEL:tab:oodtable.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了在给定预训练神经网络的情况下检测 OOD 示例的技术。大多数深度学习方法假设测试示例与训练示例属于相同的分布。因此，神经网络对 OOD
    测试示例非常敏感。因此，我们需要技术来提高预测的可靠性或确定测试示例是否与训练数据集的分布不同。在这里，我们集中讨论那些利用预训练 DNN 及后续检测器来确定测试示例是否与训练数据集分布不同的技术。我们称这种架构为事后异常检测。与
    OOD 示例检测相关的一个主题是新颖性检测[[15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17)]，其目标是检测数据中之前未观察到的（新兴、创新）模式。需要注意的是，新颖性检测相关问题的解决方案通常也用于
    OOD 检测，反之亦然，因此在本调查中我们将这些术语交替使用。根据 OOD 数据标签的可用性，技术被分为监督、半监督和无监督，接下来将讨论并总结在表格 LABEL:tab:oodtable
    中。
- en: 'Table 1: OOD detection related papers.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 1: OOD 检测相关论文。'
- en: Classification Type Reference Contributions Supervised [[18](#bib.bib18)] Uncertainty
    measure based on the gradient of the negative log-likelihood is used as a measure
    of confidence Supervised [[19](#bib.bib19)] Confidence scores based on Mahalanobis
    distance from different layers is combined using weighted averaging Supervised
    [[20](#bib.bib20)] Invariance of classifier’s softmax under various transformations
    to input image is used as a measure of confidence Supervised [[21](#bib.bib21)]
    Ratio of Hausdorff distances between test sample to the nearest non-predicted
    and the predicted classes is used as the trust score Semi-supervised [[22](#bib.bib22)]
    Probably Approximately Correct (PAC) algorithm is proposed to guarantee a user-specified
    anomaly detection rate Semi-supervised [[23](#bib.bib23)] Likelihood ratio-based
    method is used to differentiate between in-distribution and OOD examples Semi-supervised
    [[24](#bib.bib24)] A two-head CNN consisting of a common feature extractor and
    two classifiers with different decision boundaries is trained to detect OOD examples
    Unsupervised [[25](#bib.bib25)] Predicted softmax probability is used to detect
    OOD examples Unsupervised [[26](#bib.bib26)] Temperature scaling and by adding
    small perturbations to the input is used to better separate the softmax score
    for OOD detection Unsupervised [[27](#bib.bib27)] GAN based architecture is used
    to compare the bottleneck features of the generated image with that of the test
    image Unsupervised [[28](#bib.bib28)] Degenerated prior network with concentration
    perturbation algorithm is used to get better uncertainty measure Unsupervised
    [[29](#bib.bib29)] Learning to discriminate between geometric transformations
    is used for learning unique features that are useful in OOD detection Unsupervised
    [[30](#bib.bib30)] Mahalanobis distance is applied in the latent space of the
    autoencoder to detect OOD examples Unsupervised [[31](#bib.bib31)] Resampling
    uncertainty estimation approach is proposed as an approximation to the bootstrap
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 分类类型 参考 贡献 监督 [[18](#bib.bib18)] 基于负对数似然梯度的**不确定性度量**被用作置信度的衡量 监督 [[19](#bib.bib19)]
    基于不同层的马氏距离的置信度得分通过加权平均进行组合 监督 [[20](#bib.bib20)] 分类器的softmax在各种输入图像变换下的不变性被用作置信度的度量
    监督 [[21](#bib.bib21)] 测试样本与最近的未预测类和预测类之间的Hausdorff距离的比例被用作信任分数 半监督 [[22](#bib.bib22)]
    提出了**大致正确**（PAC）算法以保证用户指定的异常检测率 半监督 [[23](#bib.bib23)] 基于似然比的方法被用来区分在分布内和**OOD**样本
    半监督 [[24](#bib.bib24)] 由一个公共特征提取器和两个具有不同决策边界的分类器组成的双头CNN被训练以检测**OOD**样本 无监督 [[25](#bib.bib25)]
    预测的softmax概率被用来检测**OOD**样本 无监督 [[26](#bib.bib26)] 通过温度缩放和对输入添加小扰动来更好地区分softmax分数用于**OOD**检测
    无监督 [[27](#bib.bib27)] 基于**GAN**的架构用于比较生成图像与测试图像的瓶颈特征 无监督 [[28](#bib.bib28)] 退化先验网络与浓度扰动算法被用来获得更好的**不确定性度量**
    无监督 [[29](#bib.bib29)] 学习区分几何变换用于学习在**OOD**检测中有用的独特特征 无监督 [[30](#bib.bib30)] 在自编码器的潜在空间中应用马氏距离来检测**OOD**样本
    无监督 [[31](#bib.bib31)] 提出了重采样不确定性估计方法作为自助法的近似
- en: 2.1 Supervised Approaches
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 监督学习方法
- en: In this section, we review the anomaly detection approaches when the labels
    of both the in-distribution and the OOD examples are available to enable differentiation
    between them as the supervised anomaly detection problem. Any unseen test data
    sample is compared with the detector to determine which class (in-distribution
    vs. OOD) it belongs to.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们回顾了当在分布内和**OOD**样本的标签都可用时的异常检测方法，以便将其作为监督异常检测问题进行区分。任何未见过的测试数据样本都与检测器进行比较，以确定其属于哪个类别（在分布内与**OOD**）。
- en: In [[18](#bib.bib18)], an approach to measure uncertainty of a neural network
    based on gradient information of the negative log-likelihood at the predicted
    class label is presented. The gradient metrics are computed from all the layers
    in this method and scalarized using norm or min/max operations. A large value
    of the gradient metrics indicates incorrect classification or OOD example. A convolutional
    neural network (CNN) is used as the classifier trained on Extended MNIST digits [[32](#bib.bib32)].
    EMNIST letters, CIFAR10 [[33](#bib.bib33)] images as well as different types of
    noise are used as OOD data. The authors found that such an unsupervised scheme
    does not work well on all types of OOD data. Therefore, a supervised variant of
    this scheme where one allows an anomaly detector to be trained on uncertainty
    metrics of some OOD samples is proposed. It was shown that the performance is
    improved considerably by utilizing the labeled OOD data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[18](#bib.bib18)]中，提出了一种基于预测类别标签的负对数似然梯度信息来测量神经网络不确定性的方法。该方法计算所有层的梯度指标，并使用范数或最小/最大操作进行标量化。梯度指标的大值表明分类错误或
    OOD 示例。使用卷积神经网络（CNN）作为分类器，训练于扩展 MNIST 数字[[32](#bib.bib32)]。EMNIST 字母、CIFAR10[[33](#bib.bib33)]
    图像以及不同类型的噪声被用作 OOD 数据。作者发现这种无监督方案在所有类型的 OOD 数据上效果并不好。因此，提出了一种该方案的监督变体，允许在一些 OOD
    样本的不确定性指标上训练一个异常检测器。结果表明，通过利用标记的 OOD 数据，性能得到了显著提升。
- en: In [[19](#bib.bib19)], the high-level idea is to measure the probability density
    of test sample on DNN feature spaces. Specifically, the authors fit class-conditional
    Gaussian distributions to pre-trained features. This is possible since the posterior
    distribution can be shown to be equivalent to the softmax classifier under Gaussian
    discriminant analysis. Next, a confidence score using the Mahalanobis distance
    with respect to the closest class conditional distribution is defined. Its parameters
    are chosen to be empirical class means and tied empirical covariance of training
    samples. To further improve the performance, confidence scores from different
    layers of DNN is combined using weighted averaging. Weight of each layer is learned
    by training a logistic regression detector using labeled validation samples comprising
    of both in-distribution and OOD data. The method is shown to be robust to OOD
    examples.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[19](#bib.bib19)]中，高级想法是测量测试样本在 DNN 特征空间上的概率密度。具体来说，作者将类条件的高斯分布拟合到预训练特征上。这是可能的，因为后验分布可以被证明等同于高斯判别分析下的
    softmax 分类器。接下来，定义了一个使用马氏距离相对于最近的类条件分布的信心分数。其参数选择为经验类均值和训练样本的经验协方差。为了进一步提高性能，将来自
    DNN 不同层的信心分数使用加权平均进行组合。每一层的权重通过使用包含分布内数据和 OOD 数据的标记验证样本来训练一个逻辑回归检测器进行学习。该方法被证明对
    OOD 示例具有鲁棒性。
- en: In [[20](#bib.bib20)], a detector was trained on representations derived from
    a set of classifier responses generated from applying different natural transformation
    to a given image. Analyzing the invariance of classifier’s decision under various
    transformations establishes a measure of confidence in its decision. In other
    words, the softmax values of the OOD input should fluctuate across transformed
    versions, while those of the in-distribution image should be relatively stable.
    The authors trained a binary OOD detector on confidence scores under various transformations
    for in-distribution vs. OOD training data. ResNet based architecture is used as
    the classifier and the Self-Taught Learning (STL-10) dataset [[34](#bib.bib34)]
    is used as the in-distribution data and the Street View House Numbers (SVHN) dataset [[35](#bib.bib35)]
    is used as the OOD data. The approach is shown to outperform other baselines.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[20](#bib.bib20)]中，一个检测器被训练以从应用不同自然变换到给定图像生成的一组分类器响应中提取的表示进行训练。分析分类器在各种变换下的决策不变性可以建立对其决策的信心度。换句话说，OOD
    输入的 softmax 值应该在变换版本中波动，而在分布内图像的值应该相对稳定。作者在各种变换下对分布内与 OOD 训练数据的信心分数进行了二分类 OOD
    检测器的训练。使用基于 ResNet 的架构作为分类器，Self-Taught Learning (STL-10) 数据集[[34](#bib.bib34)]用作分布内数据，Street
    View House Numbers (SVHN) 数据集[[35](#bib.bib35)]用作 OOD 数据。该方法被证明优于其他基准方法。
- en: In [[21](#bib.bib21)], a trust score is proposed to know whether the prediction
    of a test example by a classifier can be trusted. This score is defined as the
    ratio of the Hausdorff distances between the distance from the testing sample
    to the nearest class different from the predicted class (e.g., OOD class) and
    the distance to the predicted class. To compute the trust score, the training
    data is pre-processed to find a high density set of each class to filter outliers.
    The trust score is estimated based on this high density set. The idea behind the
    approach is that if the classifier predicts a label that is considerably farther
    than the closest label, then it may be an OOD or unreliable example. For the task
    of identifying correctly/incorrectly classified examples, it was shown that the
    trust score performs well in low to medium dimensions. However, it performs similar
    to classifiers’ own reported confidence (i.e., probabilities from the softmax
    layer) in high dimensions.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[21](#bib.bib21)]中，提出了一种信任评分来判断分类器对测试样本的预测是否可靠。该评分定义为测试样本到与预测类别不同的最近类别（例如，OOD类别）的距离与到预测类别的距离之间的Hausdorff距离的比率。为了计算信任评分，训练数据被预处理，以找到每个类别的高密度集合，从而过滤掉异常值。信任评分是基于这个高密度集合来估算的。这个方法的核心思想是，如果分类器预测的标签与最近的标签相差较远，那么它可能是一个OOD或不可靠的样本。在识别正确/错误分类样本的任务中，研究表明信任评分在低到中等维度下表现良好。然而，在高维度下，其表现类似于分类器自己报告的置信度（即，softmax层的概率）。
- en: 2.2 Semi-supervised Approaches
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 半监督方法
- en: We refer to the anomaly detection techniques as semi-supervised if they utilize
    unlabeled contaminated data (or information) in addition to labeled instances
    of in-distribution class. Since, these techniques do not require to know whether
    unlabeled instance is in-distribution or OOD, they are more widely applicable
    than supervised techniques.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将利用未标记的污染数据（或信息）以及标记的在分布类别实例的异常检测技术称为半监督技术。由于这些技术不需要知道未标记实例是否在分布中或是OOD，因此它们比监督技术具有更广泛的适用性。
- en: In [[22](#bib.bib22)], the algorithm uses the knowledge of the upper bound on
    the number of anomaly examples in the training dataset to provide Probably Approximately
    Correct (PAC) guarantees for achieving a desired anomaly detection rate. The algorithm
    uses cumulative distribution functions (CDFs) over anomaly scores for the clean
    and contaminated training datasets to derive an anomaly threshold. An anomaly
    detector assigns score for all the test examples and orders them according to
    how anomalous the examples are with respect to the in-distribution data. This
    ordered score vector is then compared to the threshold to detect the OOD examples.
    The threshold is computed such that it guarantees a specific anomaly detection
    rate. Empirical results on synthetic and standard datasets show that the algorithm
    achieves guaranteed performance on OOD detection task given enough data.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[22](#bib.bib22)]中，该算法利用训练数据集中异常样本数量的上界知识来为实现期望的异常检测率提供“可能近似正确”（PAC）保证。该算法使用异常分数的累计分布函数（CDFs）对干净和污染的训练数据集进行处理，以推导异常阈值。异常检测器为所有测试样本分配分数，并根据样本相对于在分布数据的异常程度对其进行排序。然后将这个排序的分数向量与阈值进行比较，以检测OOD样本。阈值的计算方式是保证特定的异常检测率。对合成数据集和标准数据集的实证结果表明，给定足够的数据，该算法在OOD检测任务上实现了保证性能。
- en: In [[23](#bib.bib23)], a likelihood ratio-based method using deep generative
    models is presented to differentiate between in-distribution and OOD examples.
    The authors assumed that the in-distribution data is comprised of both semantic
    and background parts. The authors found that the likelihood can be confounded
    by the background (e.g. OOD input with the same background but different semantic
    component). Using this information about OOD data, they propose to use a background
    model to correct for the background statistics and enhance the in-distribution
    specific features for OOD detection. Specifically, background model is trained
    by adding the right amount of perturbations to inputs to corrupt the semantic
    structure in the data. Hence, the model trained on perturbed inputs captures only
    the population level background statistics. This likelihood ratio is computed
    from the in-distribution data and the background statistics. If the likelihood
    ratio is larger than a pre-specified threshold, it is highly likely that the test
    example is OOD. The National Center for Biotechnology Information microbial genome
    dataset is utilized in [[23](#bib.bib23)] in the following manner. Various bacteria
    are grouped into classes which were discovered over the years. Specifically, the
    classes discovered before a given cutoff year are considered as in-distribution
    classes and those discovered after the cutoff year are considered OOD classes.
    The proposed test improves the accuracy of OOD detection compared to the accuracy
    of the state-of-the-art detection results.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[23](#bib.bib23)]中，提出了一种基于似然比的深度生成模型方法，用于区分在分布内样本和OOD样本。作者假设在分布内数据包含语义部分和背景部分。作者发现，背景（例如，具有相同背景但不同语义成分的OOD输入）可能会混淆似然。利用关于OOD数据的信息，他们建议使用背景模型来纠正背景统计数据，并增强在分布内的特征以进行OOD检测。具体来说，通过对输入添加适量的扰动来破坏数据中的语义结构，从而训练背景模型。因此，在扰动输入上训练的模型仅捕获人群级别的背景统计信息。这个似然比是从在分布内数据和背景统计数据中计算得出的。如果似然比大于预设的阈值，则测试样本很可能是OOD。在[[23](#bib.bib23)]中，国家生物技术信息中心微生物基因组数据集以如下方式使用：将各种细菌分组到多年来发现的类别中。具体来说，在给定截止年份之前发现的类别被视为在分布内类别，而截止年份之后发现的类别被视为OOD类别。与最先进的检测结果的准确性相比，所提出的测试方法提高了OOD检测的准确性。
- en: In [[24](#bib.bib24)], a semi-supervised OOD detection technique based on two-head
    CNN was proposed. The idea is to train a two-head CNN consisting of one common
    feature extractor and two classifiers which have different decision boundaries
    but can classify in-distribution samples correctly. Further, unlabeled contaminated
    data is used to maximize the discrepancy between two classifiers to push OOD samples
    outside in-distribution manifold. This enables the detection of OOD samples that
    are far from the support of the in-distribution samples.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[24](#bib.bib24)]中，提出了一种基于双头CNN的半监督OOD检测技术。其思想是训练一个由一个共同特征提取器和两个具有不同决策边界的分类器组成的双头CNN，这两个分类器可以正确地分类在分布内样本。此外，使用未标记的污染数据来最大化两个分类器之间的差异，以将OOD样本推向在分布内流形之外。这使得检测远离在分布内样本支持的OOD样本成为可能。
- en: 2.3 Unsupervised Approaches
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 无监督方法
- en: We refer to the detection techniques as unsupervised if they only utilize in-distribution
    data for OOD detection.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果检测技术仅利用在分布内数据进行OOD检测，则称之为无监督方法。
- en: In [[25](#bib.bib25)], as the statistics derived from the softmax distributions
    are helpful, a baseline method based on softmax to determine whether or not a
    test example is OOD is proposed. The idea is that a well trained network tends
    to assign higher predicted probability to in-distribution examples than to OOD
    examples. Hence, the OOD example can be detected by comparing the predicted softmax
    class probabilities of the examples to a threshold. Specifically, the authors
    generated the training data by separating correctly and incorrectly classified
    test set examples and, for each example, computing the softmax probability of
    the predicted class which was used to compute the threshold. The performance of
    this approach was evaluated on computer vision, natural language processing and
    speech recognition tasks. The technique fails if the classifier does not separate
    the maximum values of the predictive distribution well enough with respect to
    in-distribution and OOD examples. Therefore, the authors in [[26](#bib.bib26)]
    proposed a method based on the observation that using temperature scaling and
    adding small perturbations to the input can better separate the softmax score
    distributions between in- and out-of-distribution images. Wide ResNet [[36](#bib.bib36)]
    and DenseNet [[37](#bib.bib37)] architectures were used and trained using the
    CIFAR-10 and CIFAR-100 [[33](#bib.bib33)] as in-distribution datasets. The OOD
    detector was tested on several different natural image datasets and synthetic
    noise datasets. It was shown that the approach significantly improves the detection
    performance and outperforms the baseline in [[25](#bib.bib25)].
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[25](#bib.bib25)]中，由于来自softmax分布的统计数据很有帮助，提出了一种基于softmax的基准方法来确定测试示例是否为分布外数据。其思想是，训练良好的网络倾向于将概率预测较高的分配给分布内示例，而不是分布外示例。因此，通过将示例的预测softmax类概率与阈值进行比较，可以检测出分布外示例。具体而言，作者通过分离分类正确和分类错误的测试集示例来生成训练数据，并计算用于计算阈值的预测类的softmax概率。该方法在计算机视觉、自然语言处理和语音识别任务上进行了评估。该技术在分类器无法将预测分布的最大值与分布内和分布外示例相对较好地分离的情况下失效。因此，在[[26](#bib.bib26)]中，作者提出了一种基于温度尺度和对输入添加小扰动的方法，可以更好地区分分布内和分布外图像之间的softmax得分分布。使用Wide
    ResNet [[36](#bib.bib36)]和DenseNet [[37](#bib.bib37)]架构，并使用CIFAR-10和CIFAR-100
    [[33](#bib.bib33)]作为分布内数据集进行训练。该分布外数据检测器在多个不同的自然图像数据集和合成噪声数据集上进行了测试。结果表明，该方法显著提高了检测性能，并优于[[25](#bib.bib25)]中的基准方法。
- en: In [[27](#bib.bib27)], a generative adversarial network (GAN) [[38](#bib.bib38)]
    based architecture is used in reconstruction error based OOD detection method.
    The motivation is that the GAN will perform better when generating images from
    previously seen objects (i.e., in-distribution data) than it will when generating
    images of objects it has never seen before (i.e., OOD data). In this approach,
    the test image is first passed through the generator of the GAN, which produces
    bottleneck features and a reconstructed image. Next, the reconstructed image is
    passed through the encoder producing another set of bottleneck features. The Euclidean
    distance between these two feature sets represents a measure of how much the generated
    image deviates from the original image and is used as an anomaly score.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[27](#bib.bib27)]中，使用基于生成对抗网络（GAN）[[38](#bib.bib38)]的架构来进行重构误差的异常检测方法。其动机是，当GAN生成以前见过的对象的图像（即分布内数据）时，其性能会更好，而生成以前未见过的对象的图像（即分布外数据）时，性能会较差。在这种方法中，测试图像首先经过GAN的生成器，产生瓶颈特征和重构图像。接下来，重构图像经过编码器生成另一组瓶颈特征。这两组特征之间的欧氏距离表示生成图像与原始图像之间的差异程度，并用作异常分数。
- en: In [[28](#bib.bib28)], the authors propose a degenerated prior network architecture,
    which can efficiently separate model-level uncertainty from data-level uncertainty
    via prior entropy. To better separate in-distribution and OOD images, they propose
    a concentration perturbation algorithm, which adaptively adds noise to concentration
    parameters of prior network. Through comprehensive experiments, it was shown that
    this method achieves state-of-the-art performance especially on the large-scale
    dataset. However, this method is found to be sensitive to different neural network
    architectures, which could sometimes lead to inferior performance.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[28](#bib.bib28)]中，作者提出了一种退化的先验网络架构，该架构可以通过先验熵有效地将模型级不确定性与数据级不确定性分开。为了更好地分离分布内和OOD图像，他们提出了一种浓度扰动算法，该算法自适应地向先验网络的浓度参数添加噪声。通过综合实验，显示该方法在大规模数据集上特别取得了最先进的性能。然而，该方法对不同的神经网络架构敏感，有时可能导致性能较差。
- en: In [[29](#bib.bib29)], the intuition is that learning to discriminate between
    geometric transformations applied to images help in learning of unique features
    of each class that are useful in anomaly detection. The authors train a multi-class
    classifier over a self-labeled dataset created by applying various geometric transformations
    to in-distribution images. At test time, transformed images are passed through
    this classifier, and an anomaly score derived from the distribution of softmax
    values of the in-distribution training images is used for detecting OOD data.
    The classifier used is the Wide Residual Network model [[36](#bib.bib36)] trained
    on CIFAR dataset. The CatsvsDogs dataset [[39](#bib.bib39)], that contains 12,500
    images of cats and dogs each, is treated as the OOD data. The method performs
    better compared to the baseline approaches in [[25](#bib.bib25)] for the larger-sized
    images and is robust to the OOD examples. The method is able to distinguish between
    the normal and OOD examples with a significant margin compared to the baseline
    methods.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[29](#bib.bib29)]中，直觉是学习区分应用于图像的几何变换有助于学习每个类别的独特特征，这些特征在异常检测中很有用。作者在一个自标记的数据集上训练多类别分类器，该数据集通过对分布内图像应用各种几何变换来创建。在测试时，将变换后的图像传递给该分类器，并使用从分布内训练图像的softmax值分布中得出的异常分数来检测OOD数据。使用的分类器是训练于CIFAR数据集的Wide
    Residual Network模型[[36](#bib.bib36)]。CatsvsDogs数据集[[39](#bib.bib39)]，其中包含12,500张猫和狗的图像，被视为OOD数据。该方法在较大图像上的表现优于[[25](#bib.bib25)]中的基线方法，并且对OOD样本具有较强的鲁棒性。与基线方法相比，该方法能够以显著的优势区分正常样本和OOD样本。
- en: The approach in [[30](#bib.bib30)] (and references therein) consider the problem
    of detecting OOD samples based on the reconstruction error. These methods assume
    that OOD data is composed of different factors than in-distribution data. Therefore,
    it is difficult to compress and reconstruct OOD data based on a reconstruction
    scheme optimized for in-distribution data. Specifically, [[30](#bib.bib30)] proposes
    to incorporate the Mahalanobis distance in latent space to better capture these
    OOD samples. They combined the Mahalanobis distance between the encoded test sample
    and the mean vector of the encoded training set with the reconstruction loss of
    the test sample to construct an anomaly score. Single digit class from MNIST [[40](#bib.bib40)]
    is used as in-distribution and the other classes of MNIST are treated as OOD samples.
    The authors illustrate that by including the latent distance helps in improving
    the detection of in-distribution and OOD examples.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[[30](#bib.bib30)]（及其参考文献）中提出的方法考虑了基于重建误差检测OOD样本的问题。这些方法假设OOD数据由不同于分布内数据的因素组成。因此，基于优化的重建方案很难压缩和重建OOD数据。具体来说，[[30](#bib.bib30)]提出在潜在空间中引入马氏距离，以更好地捕捉这些OOD样本。他们将编码测试样本与编码训练集均值向量之间的马氏距离与测试样本的重建损失结合，以构建异常分数。使用MNIST数据集中单数字类别[[40](#bib.bib40)]作为分布内数据，其他类别的MNIST被视为OOD样本。作者指出，通过包括潜在距离可以改善对分布内和OOD样本的检测。'
- en: In [[31](#bib.bib31)], the predictions of a pre-trained DNN are audited to determine
    their reliability. Resampling uncertainty estimation (RUE) approach is proposed
    as an approximation to the bootstrap procedure. Intuitively, RUE estimates the
    amount that a prediction would change if different training data was used from
    the same distribution. It quantifies uncertainty using the gradients and Hessian
    of the model’s loss on training data and bootstrap samples to produce an ensemble
    of predictions for a test input. This uncertainty score is compared to a threshold
    for detecting correct and incorrect predictions. A single hidden layer feedforward
    neural network architecture is trained using eight common benchmark regression
    datasets [[41](#bib.bib41)] from the UCI dataset repository. The authors show
    that the uncertainty score detects inaccurate predictions for auditing reliability
    compared to existing techniques more effectively. This approach can also be used
    to detect OOD samples.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[31](#bib.bib31)]中，审计了预训练DNN的预测，以确定其可靠性。提出了重采样不确定性估计（RUE）方法，作为对引导程序的近似。直观地说，RUE估计了如果使用来自相同分布的不同训练数据，预测会发生多少变化。它使用模型在训练数据和引导样本上的损失的梯度和Hessian量化不确定性，以生成测试输入的预测集成。该不确定性分数与阈值进行比较，以检测正确和不正确的预测。使用来自UCI数据集库的八个常见基准回归数据集[[41](#bib.bib41)]训练了一个单隐藏层前馈神经网络架构。作者表明，与现有技术相比，不确定性分数在审计可靠性时更有效地检测不准确的预测。该方法还可以用于检测OOD样本。
- en: Note that the unsupervised methods discussed above require comparing proposed
    anomaly scores with a threshold. Although thresholds are computed solely based
    on in-distribution data, one can further improve the performance by optimally
    choosing thresholds based on OOD validation samples (if available).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，上述讨论的无监督方法需要将提出的异常分数与阈值进行比较。虽然阈值完全基于分布内数据计算，但通过根据OOD验证样本（如果有的话）优化选择阈值，可以进一步提高性能。
- en: 2.4 Other Miscellaneous Techniques
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 其他杂项技术
- en: In this section, we discuss various approaches that are different from the post-hoc
    anomaly detection techniques, e.g., training-based, architecture design, etc.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了不同于事后异常检测技术的方法，例如基于训练的、架构设计的等。
- en: In [[42](#bib.bib42)], a new form of support vector machine (SVM) is presented
    that combines multi-class classification and OOD detection into a single step.
    Specifically, the authors augmented original SVM with an auxiliary zeroth class
    as the anomaly class for labeling OOD examples. The UCI datasets are used as the
    training examples. The authors demonstrate the trade-off between the ability to
    detect anomalies and the incorrect labeling of normal examples as anomalies.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[42](#bib.bib42)]中，提出了一种新的支持向量机（SVM）形式，将多类分类和OOD检测合并为一个步骤。具体而言，作者通过将原始SVM扩展为一个辅助的零类作为异常类，用于标记OOD示例。使用UCI数据集作为训练示例。作者展示了检测异常能力与将正常示例错误标记为异常之间的权衡。
- en: A hybrid model for fake news detection in [[43](#bib.bib43)] consists of three
    steps which capture the temporal pattern of user activity on a given article using
    a recurrent neural network (RNN), checking the credibility of the media source,
    and classifying the article as fake or not. In [[44](#bib.bib44)], an RNN network
    is used to detect anomalous data where the Numenta Anomaly Benchmark metric is
    used for early detection of anomalies.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[43](#bib.bib43)]中，针对假新闻检测的混合模型包含三个步骤：使用递归神经网络（RNN）捕捉用户对给定文章的时间模式，检查媒体来源的可信度，以及将文章分类为假新闻或非假新闻。在[[44](#bib.bib44)]中，使用RNN网络检测异常数据，其中Numenta异常基准指标用于早期检测异常。
- en: The method presented in [[45](#bib.bib45)] proposed to modify the output layer
    of DNNs. Specifically, instead of using logit scores for computing class probabilities,
    the cosine of the angle between the weights of a class and the features of the
    class are used. In other words, the class probabilities are obtained using the
    softmax of scaled cosine similarity. The detection of OOD samples is done by comparing
    the maximum of cosine values across classes to a threshold. The method is hyperparameter-free
    and has high OOD detection performance. However, the trade-off is the degradation
    of the classification accuracy. The Wide Residual Network [[36](#bib.bib36)] is
    used as the classifier trained using the CIFAR dataset, and tiny ImageNet and
    SVHN datasets are considered OOD data. The approach achieves competitive detection
    performance even without the tuning of the hyperparameters and the method requires
    only a single forward pass without the need for backpropagation for each input.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[45](#bib.bib45)]中提出了一种修改DNN输出层的方法。具体而言，不使用logit分数计算类别概率，而是使用类别权重与类别特征之间的余弦角度。换句话说，类别概率是通过缩放余弦相似度的softmax获得的。OOD样本的检测是通过将所有类别的余弦值最大值与阈值进行比较来完成的。该方法无需超参数，并且具有较高的OOD检测性能。然而，其权衡是分类准确性的下降。使用Wide
    Residual Network[[36](#bib.bib36)]作为分类器，该网络使用CIFAR数据集进行训练，tiny ImageNet和SVHN数据集被视为OOD数据。即使在没有调整超参数的情况下，该方法也能实现有竞争力的检测性能，并且该方法仅需要单次前向传递，无需对每个输入进行反向传播。
- en: In [[46](#bib.bib46)], a deep autoencoder is combined with CNN to perform supervised
    OOD detection. Autoencoder is used as a pre-training method for supervised CNN
    training. The idea is to reconstruct high-dimensional features using the deep
    autoencoder and detect anomalies using CNNs. It was shown that this combination
    can improve the accuracy and efficiency of large-scale Android malware detection.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[46](#bib.bib46)]中，将深度自编码器与CNN结合用于执行监督的OOD检测。自编码器作为监督CNN训练的预训练方法。其思路是使用深度自编码器重建高维特征，并通过CNN检测异常。研究表明，这种组合可以提高大规模Android恶意软件检测的准确性和效率。
- en: A novel training method is presented in [[47](#bib.bib47)] where two additional
    terms are added in the cross entropy loss that minimize the Kullback-Leibler (KL)
    distance between the predictive distribution on OOD examples and the uniform distribution
    to assign less confident predictions to the OOD examples. Then, in-distribution
    and OOD samples are expected to be more separable. However, the loss function
    for optimization requires OOD examples for training which are generated by using
    a GAN architecture. Hence, the training involves minimizing the classifier’s loss
    and the GAN loss alternately.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[47](#bib.bib47)]中提出了一种新的训练方法，其中在交叉熵损失中添加了两个额外项，以最小化OOD样本预测分布与均匀分布之间的Kullback-Leibler
    (KL)距离，从而将不确定的预测分配给OOD样本。这样，分布内样本和OOD样本应该变得更加可分。然而，优化的损失函数需要用于训练的OOD样本，这些样本是通过使用GAN架构生成的。因此，训练涉及交替最小化分类器的损失和GAN的损失。
- en: In [[48](#bib.bib48)], the algorithm comprises of an ensemble of leave-out-classifiers.
    Each classifier is trained using in-distribution examples as well as OOD examples.
    Here, the OOD examples are obtained by designating a random subset from the training
    dataset as OOD and the rest are in-distribution. A novel margin-based loss function
    is presented that maintains a margin $m$ between the average entropy of the OOD
    and in-distribution samples. Hence, the loss function is the cross-entropy loss
    along with the margin-based loss. The loss function is minimized to train the
    ensemble of classifiers. The OOD detection score is obtained by combining the
    softmax prediction score and the entropy with temperature scaling. The score is
    shown to be high for in-distribution examples and low for OOD examples.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[48](#bib.bib48)]中，该算法由一组留出分类器组成。每个分类器使用分布内样本和OOD样本进行训练。这里，OOD样本通过将训练数据集中的随机子集指定为OOD，其余样本为分布内样本来获得。提出了一种新的基于边际的损失函数，该损失函数保持OOD样本和分布内样本的平均熵之间的边际$m$。因此，损失函数是交叉熵损失与基于边际的损失的组合。通过最小化损失函数来训练分类器集成。OOD检测评分是通过结合softmax预测分数和带温度缩放的熵来获得的。结果表明，该评分对分布内样本较高，对OOD样本较低。
- en: Furthermore, [[49](#bib.bib49)] proposes leveraging alternative data sources
    to improve OOD detection by training anomaly detectors against an auxiliary dataset
    of outliers, an approach they call Outlier Exposure. The motivation is that while
    it is difficult to model every variant of anomaly distribution, one can learn
    effective heuristics for detecting OOD samples by exposing the model to diverse
    OOD datasets. Thus, learning a more conservative concept of the in-distribution
    and enabling anomaly detectors to generalize and detect unseen anomalies.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，[[49](#bib.bib49)] 提出了利用替代数据源来改善OOD检测，通过对抗一个异常值的辅助数据集训练异常检测器，这种方法被称为异常值暴露。其动机在于，虽然很难建模每种变异的异常分布，但通过将模型暴露于不同的OOD数据集，可以学习到有效的启发式方法来检测OOD样本。因此，学习一个更保守的在分布概念，使得异常检测器能够泛化并检测未见过的异常。
- en: The key idea in [[50](#bib.bib50)] is that the likelihood models assign higher
    density values to the OOD examples than the in-distribution examples. The authors
    propose generative ensembles to detect OOD examples by combining a density evaluation
    model with predictive uncertainty estimation on the density model via ensemble
    variance. Specifically, they use uncertainty estimation on randomly sampled GAN
    discriminators to de-correlate the OOD classification errors made by a single
    discriminator.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[[50](#bib.bib50)] 的关键思想是，似然模型对OOD样本分配的密度值高于在分布样本。作者提出了生成性集成方法，通过将密度评估模型与通过集成方差对密度模型进行的预测不确定性估计相结合，来检测OOD样本。具体来说，他们使用对随机采样的GAN判别器的不确定性估计来去相关化单个判别器产生的OOD分类错误。'
- en: The authors in [[51](#bib.bib51)] proposed a permutation test statistics to
    detect OOD samples using deep generative models trained with batch normalization.
    They show that the training objective of generative models with batch normalization
    can be interpreted as maximum pseudo-likelihood over a different joint distribution.
    Over this joint distribution, the estimated likelihood of a batch of OOD samples
    is shown to be much lower than that of in-distribution samples.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[[51](#bib.bib51)] 中的作者提出了一种排列检验统计量来检测使用批量归一化训练的深度生成模型中的OOD样本。他们展示了带有批量归一化的生成模型的训练目标可以被解释为对不同联合分布的最大伪似然。在这个联合分布上，OOD样本的批量估计似然被显示为远低于在分布样本的。'
- en: In [[52](#bib.bib52)], benchmarking of some of the existing posthoc calibration
    based OOD detection techniques is performed. The effect of OOD examples on the
    accuracy and calibration for the classification tasks is investigated. The authors
    evaluate uncertainty not only for in-distribution examples but also for OOD examples.
    They utilize metrics such as negative log-likelihood and Brier scores to evaluate
    the model uncertainty or accuracy of computed predicted probabilities. Using large-scale
    experiments, the authors show that the calibration error increases with increasing
    distribution shift and post-hoc calibration does indeed fall short in detecting
    OOD examples.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[52](#bib.bib52)]中，对一些现有的基于后校准的OOD检测技术进行了基准测试。研究了OOD样本对分类任务的准确性和校准的影响。作者不仅评估了在分布样本的不确定性，还评估了OOD样本的不确定性。他们使用如负对数似然和Brier分数等指标来评估模型的不确定性或计算预测概率的准确性。通过大规模实验，作者展示了随着分布偏移的增加，校准误差也在增加，后校准确实在检测OOD样本时有所不足。
- en: 3 Intentional Anomaly Detection
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 故意异常检测
- en: In this section, we discuss the detection techniques for detecting intentionally
    designed adversarial test examples given a pre-trained neural network. It is well
    known that DNNs are highly susceptible to test time adversarial examples – human-imperceptible
    perturbations that, when added to any image, causes it to be misclassified with
    high probability [[53](#bib.bib53), [54](#bib.bib54)]. The imperceptibility constraint
    ensures that the test example belongs to the data manifold yet gets misclassified.
    Hence, we need techniques to improve the reliability of the predictions or determine
    whether the test example is adversarial or normal. Here, we focus on the latter
    with the availability of a pre-trained DNN followed by a detector. Based on the
    availability of labels, the techniques are classified as supervised, semi-supervised,
    and unsupervised which are elaborated as follows and summarized in Table LABEL:tab:adversarialtable.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了针对给定预训练神经网络检测故意设计的对抗测试样本的检测技术。众所周知，深度神经网络（DNN）对测试时的对抗样本非常敏感——这些人为难以察觉的扰动，当添加到任何图像中时，会以高概率导致误分类[[53](#bib.bib53),
    [54](#bib.bib54)]。不可察觉性约束确保测试样本属于数据流形，但却被误分类。因此，我们需要技术来提高预测的可靠性或确定测试样本是对抗性还是正常的。在这里，我们专注于后者，即利用预训练DNN及其后续检测器。在标签可用性方面，这些技术被分类为监督、半监督和无监督，具体说明如下，并总结在表
    LABEL:tab:adversarialtable 中。
- en: 'Table 2: Adversarial example detection related papers.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：与对抗样本检测相关的论文。
- en: 'Classification Type Reference Contributions Supervised [[55](#bib.bib55)] Binary
    detector trained on intermediate feature representations is proposed to detect
    adversarial examples Supervised [[56](#bib.bib56)] Logistic regression based detector
    trained with two features: the uncertainty and the density estimate is used Supervised
    [[57](#bib.bib57)] LSTM based binary detector is trained to analyze the sequence
    of deep features embedded in a distance space Supervised [[58](#bib.bib58)] Local
    Intrinsic Dimensionality is used to characterize the dimensional properties of
    the regions where the adversarial examples lie Supervised [[59](#bib.bib59)] Three
    layer regression NN used as the detector to predict confidence score Unsupervised
    [[60](#bib.bib60)] Rank based statistics with generative models is used for detecting
    adversarial examples Unsupervised [[61](#bib.bib61)] KL distance based metric
    is applied on the posterior distributions to detect the adversarial examples Unsupervised
    [[62](#bib.bib62)] Nearest neighbor classification score based on deep features
    is used as to detect adversarial examples Unsupervised [[63](#bib.bib63)] Adversarial
    examples are detected by modeling output distribution of hidden layers of the
    DNN given normal examples Unsupervised [[64](#bib.bib64)] Provenance and activation
    invariance is used to detect adversarial examples Unsupervised [[65](#bib.bib65)]
    Mutual Information is used to detect adversarial examples by minimizing uncertainty
    over sampling probabilities Unsupervised [[66](#bib.bib66)] Detection by nearest
    neighbor search based projections of adversarial examples onto in-distribution
    image manifold is used Unsupervised [[67](#bib.bib67)] Detection by gradient search
    based projections of adversarial examples onto in-distribution image manifold
    is used'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 分类类型 参考 贡献 监督 [[55](#bib.bib55)] 提出了基于中间特征表示训练的二分类检测器来检测对抗样本 监督 [[56](#bib.bib56)]
    基于逻辑回归的检测器使用两个特征：不确定性和密度估计 监督 [[57](#bib.bib57)] 基于LSTM的二分类检测器训练来分析深度特征嵌入距离空间的序列
    监督 [[58](#bib.bib58)] 使用局部内在维度来表征对抗样本所在区域的维度特性 监督 [[59](#bib.bib59)] 三层回归NN用作检测器以预测置信度分数
    无监督 [[60](#bib.bib60)] 基于生成模型的排序统计用于检测对抗样本 无监督 [[61](#bib.bib61)] 基于KL距离的度量应用于后验分布以检测对抗样本
    无监督 [[62](#bib.bib62)] 基于深度特征的最近邻分类分数用于检测对抗样本 无监督 [[63](#bib.bib63)] 通过建模DNN隐藏层的输出分布来检测对抗样本，给定正常样本
    无监督 [[64](#bib.bib64)] 使用源流和激活不变性来检测对抗样本 无监督 [[65](#bib.bib65)] 通过最小化采样概率的不确定性来检测对抗样本的互信息
    无监督 [[66](#bib.bib66)] 基于对抗样本在数据流形上的最近邻搜索投影的检测 无监督 [[67](#bib.bib67)] 基于梯度搜索的对抗样本在数据流形上的投影检测
- en: 3.1 Supervised Approaches
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 监督方法
- en: In this section, we discuss the detection techniques that require the labels
    of both in-distribution and adversarial examples and referred to them as supervised
    anomaly detection techniques. The test examples are compared against the detector
    to determine whether they are normal or adversarial.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们讨论了需要标签的检测技术，包括分布内样本和对抗样本，并将其称为监督异常检测技术。测试样本与检测器进行比较，以确定它们是正常的还是对抗的。
- en: In [[55](#bib.bib55)], a binary adversarial example detector is proposed. The
    detector is trained on intermediate feature representations of a pre-trained classifier
    on the original data set and adversarial examples. Although it may seem very difficult
    to train such a detector, their results on CIFAR10 and a 10-class subset of ImageNet
    datasets show that training such a detector is indeed possible. In fact, the detector
    achieves high accuracy in the detection of adversarial examples. Moreover, while
    the detector is trained on adversarial examples generated using a specific attack
    method, it is found that the detector generalizes to similar and weaker attack
    methods. Similar strategy was employed in [[68](#bib.bib68)] where ML model was
    augmented with an additional class in which the model is trained to classify all
    adversarial inputs using labeled data.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[55](#bib.bib55)]中，提出了一种二元对抗样本检测器。该检测器在原始数据集和对抗样本的预训练分类器的中间特征表示上进行训练。尽管训练这样的检测器可能看起来非常困难，但他们在CIFAR10和ImageNet数据集的10类子集上的结果表明，训练这样的检测器确实是可能的。实际上，该检测器在对抗样本检测中达到了高精度。此外，虽然检测器是基于特定攻击方法生成的对抗样本进行训练的，但发现该检测器能够对类似和较弱的攻击方法具有泛化能力。在[[68](#bib.bib68)]中采用了类似的策略，其中ML模型通过额外的类别来扩展，模型被训练以使用标记数据对所有对抗输入进行分类。
- en: 'The authors in [[56](#bib.bib56)] proposed three methods to detect adversarial
    examples. First, method which is based on the density estimation uses estimates
    from the kernel density estimation of the training set in the feature space of
    the last hidden layer to detect adversarial examples. This method is meant to
    detect points that lie far from the data manifold. However, this strategy may
    not work well when adversarial example is very near the benign submanifold. Therefore,
    the authors proposed second approach which uses Bayesian uncertainty estimates
    from the dropout neural networks when points lie in low-confidence regions of
    the input space. They show that dropout based method can detect adversarial samples
    in situations where density estimates cannot. Finally, they also build a combined
    detector which is a simple logistic regression classifier with two features as
    input: the uncertainty and the density estimate. The combined detector is trained
    on a labeled training set which comprises of uncertainty values and density estimates
    for both benign and adversarial examples generated using different adversarial
    attack methods. The authors report that the performance of the combined detector
    (detection accuracy of 85-93%) is better than detectors trained either on uncertainty
    or on density values, demonstrating that each feature is able to detect different
    qualities of adversarial features.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[56](#bib.bib56)]中，作者提出了三种检测对抗样本的方法。首先，基于密度估计的方法使用来自训练集的最后隐藏层特征空间的核密度估计来检测对抗样本。该方法旨在检测那些远离数据流形的点。然而，当对抗样本非常接近良性子流形时，这种策略可能效果不好。因此，作者提出了第二种方法，即使用来自丢弃神经网络的贝叶斯不确定性估计，当点位于输入空间的低置信度区域时，他们展示了基于丢弃的方法可以在密度估计无法检测到的情况下检测对抗样本。最后，他们还建立了一个组合检测器，该检测器是一个简单的逻辑回归分类器，输入特征包括：不确定性和密度估计。组合检测器在标记训练集上进行训练，该训练集包括使用不同对抗攻击方法生成的良性和对抗样本的不确定性值和密度估计。作者报告称，组合检测器的性能（检测准确率为85-93%）优于仅在不确定性或密度值上训练的检测器，表明每个特征能够检测对抗特征的不同特性。
- en: In [[57](#bib.bib57)], the idea is that the trajectory of the internal representations
    in the forward pass for the adversarial examples are different from that of the
    in-distribution examples. The internal representations of an input is embedded
    into the feature distance spaces which capture the relative positions of an example
    with respect to a given in-distribution example in the feature space. The embedding
    enables compact encoding of the evolution of the activations through the forward
    pass of the network. Hence, facilitating the search for differences between the
    trajectories of in-distribution and adversarial inputs. An LSTM based binary detector
    is trained to analyze the sequence of deep features embedded in a distance space
    and detect adversarial examples. The experimental results show that the detection
    scheme is able to detect a variety of adversarial examples targeting the ResNet-50
    classifier pre-trained on the ImageNet dataset.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[57](#bib.bib57)]中，观点是对抗样本在前向传播中的内部表示轨迹与在分布内样本的轨迹不同。输入的内部表示被嵌入到特征距离空间中，该空间捕捉了相对于特定在分布内样本的示例的相对位置。这种嵌入使得网络前向传播中激活的演变可以紧凑地编码。因此，促进了在分布内和对抗输入的轨迹之间差异的搜索。一个基于LSTM的二分类检测器被训练来分析嵌入在距离空间中的深度特征序列，并检测对抗样本。实验结果表明，该检测方案能够检测各种针对ResNet-50分类器的对抗样本，ResNet-50是预训练于ImageNet数据集上的。
- en: In [[58](#bib.bib58)], an expansion-based measure of intrinsic dimensionality
    is used as an alternative to density measure to detect adversarial example. The
    expansion model of dimensionality assesses the local dimensional structure of
    the data and characterizes the intrinsic dimensionality as a property of the datasets.
    The Local Intrinsic Dimensionality (LID) generalizes this concept to the local
    distance distribution from a reference point to its neighbors – the dimensionality
    of the local data submanifold in the vicinity of the reference point is revealed
    by the growth characteristics of the cumulative distribution function. The authors
    use LID to characterize the intrinsic dimensionality of regions where adversarial
    examples lie, and use estimates of LID to detect adversarial examples. Note that
    LID is a function of the nearest neighbor distances and it found to be significantly
    higher for the adversarial examples than the benign examples. A binary adversarial
    example detector is trained by using the training data to construct features for
    each sample, based on its LID across different layers, where the class label is
    assigned positive for adversarial examples and assigned negative for in-distribution
    examples. Experiments on several attack strategies show that LID based detector
    outperforms several state-of-the-art detection measures by large margins.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[58](#bib.bib58)]中，使用基于扩展的内在维度测量作为检测对抗样本的替代密度测量方法。内在维度的扩展模型评估数据的局部维度结构，并将内在维度特性作为数据集的属性。局部内在维度（LID）将这一概念推广到从参考点到其邻居的局部距离分布——通过累计分布函数的增长特性揭示了参考点附近局部数据子流形的维度。作者使用LID来描述对抗样本所在区域的内在维度，并使用LID估计值来检测对抗样本。注意，LID是最近邻距离的函数，发现对抗样本的LID显著高于良性样本。通过使用训练数据基于其在不同层的LID构建每个样本的特征来训练一个二分类对抗样本检测器，其中对抗样本的类别标签被赋予正值，分布内样本的标签被赋予负值。在多个攻击策略上的实验表明，基于LID的检测器在检测精度上大幅超越了多个最先进的检测措施。
- en: In [[59](#bib.bib59)], a three layer regression NN is used as a detector that
    takes logits of in-distribution and adversarial examples from a pre-trained DNN
    as the input and predicts the confidence value, i.e., whether the classification
    is normal or adversarial. The classifier used is a pre-trained CNN trained using
    in-distribution datasets (MNIST and CIFAR) and the detector is trained on logits
    of both in-distribution and adversarial examples generated using different methods.
    This work show that logits of a pre-trained network provide relevant information
    to detect adversarial examples.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[59](#bib.bib59)]中，使用了一个三层回归神经网络作为检测器，该检测器将来自预训练深度神经网络的在分布内和对抗样本的logits作为输入，并预测置信度值，即分类是正常还是对抗。使用的分类器是一个基于在分布内数据集（MNIST和CIFAR）训练的预训练CNN，检测器则在使用不同方法生成的在分布内和对抗样本的logits上进行训练。这项工作表明，预训练网络的logits提供了检测对抗样本的相关信息。
- en: 3.2 Semi-supervised Approaches
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 半监督方法
- en: Semi-supervised anomaly detection techniques utilize unlabeled contaminated
    data (or information) in addition to labeled instances of in-distribution class.
    Since, these techniques do not require to know whether unlabeled instance is in-distribution
    or adversarial examples, they are more widely applicable than supervised techniques.
    However, we could not find any existing semi-supervised adversarial example detection
    approach in the literature. Note that this may be a worthwhile direction to pursue
    in future research.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督异常检测技术除了利用标记的分布内类别实例外，还利用未标记的受污染数据（或信息）。由于这些技术不需要知道未标记的实例是否在分布内或为对抗样本，它们比监督技术更广泛适用。然而，我们在文献中找不到现有的半监督对抗样本检测方法。请注意，这可能是未来研究中的一个值得追求的方向。
- en: 3.3 Unsupervised Approaches
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 无监督方法
- en: We refer to the detection techniques as unsupervised if they only utilize in-distribution
    data for adversarial detection.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将检测技术称为无监督的，如果它们仅利用分布内数据进行对抗检测。
- en: In [[60](#bib.bib60)], the probabilities of all the training images under the
    generative model (such as, PixelCNN) is computed. Then, for a test example, the
    probability density at the input is computed and its rank among the density values
    of all the training examples is evaluated. This rank can be used as a test statistic
    which gives a $p$-value for whether the example is normal or adversarial. The
    method improves resilience of the state-of-the-art methods against attacks and
    increases the detection accuracy by a significant margin. Further, the authors
    suggest purifying adversarial examples by searching for more probable images within
    a small distance of the original training ones. By utilizing $L^{\infty}$ distance,
    the true labels of the purified images remains unchanged. The resulting purified
    images have higher probability under in-distribution so that the classifier trained
    on normal images will have more reliable predictions on these purified images.
    This intuition is used to build a more effective defense against adversarial attacks.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[60](#bib.bib60)]中，所有训练图像在生成模型（如PixelCNN）下的概率被计算出来。然后，对于测试样本，计算输入处的概率密度，并评估其在所有训练样本的密度值中的排名。这个排名可以作为测试统计量，用来给出一个$p$-值，判断样本是正常的还是对抗性的。该方法提高了最先进方法对攻击的韧性，并显著提高了检测准确率。此外，作者建议通过在原始训练样本的较小距离内搜索更可能的图像来净化对抗样本。通过利用$L^{\infty}$距离，净化图像的真实标签保持不变。结果是净化后的图像在分布内的概率更高，从而使在正常图像上训练的分类器对这些净化图像的预测更加可靠。这种直觉用于建立更有效的对抗攻击防御。
- en: The motivation for the method in [[61](#bib.bib61)] is that adversarial examples
    should be both (a) “too atypical” (i.e., have atypically low likelihood) under
    the density model for the DNN-predicted class, and (b) “too typical” (i.e., have
    too high a likelihood) under some class other than the DNN-predicted class. While
    it may seem that one requires to use two detection thresholds, they instead propose
    a single decision statistic that captures both requirements. Specifically, they
    define (a) a two-class posterior evaluated with respect to the (density-based)
    null model, and (b) corresponding two-class posterior evaluated via the DNN. Both
    deviations (“too atypical” and “too typical”) are captured by the Kullback-Leibler
    divergence decision statistic. A sample is declared adversarial if this statistic
    exceeds a preset threshold value.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[61](#bib.bib61)]中的方法动机是，对抗样本应该在DNN预测的类别下（a）“过于不典型”（即，具有不典型的低概率），以及在DNN预测类别之外的某些类别下（b）“过于典型”（即，具有过高的概率）。虽然看起来可能需要使用两个检测阈值，但他们提出了一个单一的决策统计量来捕捉这两个要求。具体来说，他们定义了（a）相对于（基于密度的）零模型评估的两个类别后验，以及（b）通过DNN评估的相应两个类别后验。这两种偏差（“过于不典型”和“过于典型”）由Kullback-Leibler散度决策统计量捕获。如果该统计量超过预设的阈值，则样本被声明为对抗性的。
- en: The approach in [[62](#bib.bib62)] performs a kNN similarity search among the
    deep features obtained from the training images to a given test image classified
    by the DNN. They then use the score assigned by a kNN classifier to the class
    predicted by the DNN as a measure of confidence of the classification. Note that
    this approach does not rely on the classification produced by the kNN classifier,
    but only use the score assigned to the DNN prediction as a measure of confidence.
    The intuition behind this approach is that while it is unlikely that a class correctly
    predicted by the DNN has the highest kNN score among the scores of all the classes,
    it is implausible that a correct classification has a very low score. Results
    on the ImageNet dataset show that hidden layers activations can be used to detect
    misclassifications caused by various attacks.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[62](#bib.bib62)]中，所采用的方法是在通过DNN分类的测试图像与训练图像中获得的深度特征之间执行kNN相似性搜索。然后，他们使用kNN分类器分配给DNN预测类别的分数作为分类置信度的度量。需要注意的是，这种方法并不依赖于kNN分类器产生的分类结果，而只是将分配给DNN预测的分数作为置信度的度量。这种方法的直觉是，虽然DNN正确预测的类别在所有类别的kNN分数中不一定具有最高分数，但正确分类具有非常低分数的可能性是不切实际的。对ImageNet数据集的结果表明，隐藏层激活可以用于检测各种攻击造成的误分类。
- en: In [[63](#bib.bib63)], intrinsic properties of the pre-trained DNN, i.e., output
    distributions of the hidden neurons, are used to detect adversarial examples.
    Their motivation is that when the DNN incorrectly assigns an adversarial example
    to a specific class label, the distribution of its hidden states are very different
    as compared to those obtained by the normal data of the same class. They use Gaussian
    Mixture Model (GMM) to approximate the hidden state distribution of each class
    using benign training data. Likelihoods are then compared to the respective class
    thresholds to detect whether an example is adversarial or not. Experimental results
    on standard datasets (MNIST, F-MNIST, CIFAR-10) against several attack methods
    show that this approach can achieve state-of-the-art robustness in defending black-box
    and gray-box attacks.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[63](#bib.bib63)]中，利用预训练DNN的内在属性，即隐藏神经元的输出分布，来检测对抗样本。他们的动机是，当DNN将对抗样本错误地分配到特定类别标签时，其隐藏状态的分布与正常数据的相同类别相比非常不同。他们使用高斯混合模型（GMM）来近似每个类别的隐藏状态分布，使用的是良性训练数据。然后将似然性与各自的类别阈值进行比较，以检测样本是否为对抗样本。在标准数据集（MNIST、F-MNIST、CIFAR-10）上的实验结果表明，这种方法在防御黑箱和灰箱攻击方面能够实现最先进的鲁棒性。
- en: 'The authors in [[64](#bib.bib64)] found that adversarial examples mainly exploit
    two attack channels: the provenance channel and the activation value distribution
    channel. The provenance channel imply instability of DNN output to small changes
    in activation values, which eventually leads to misclassification. On the other
    hand, the activation channel imply that while the provenance changes slightly,
    the activation values of a layer may be substantially different from those in
    the presence of benign inputs. Exploiting these observations they propose a method
    that extracts two kinds of invariants (or probability distributions denoted by
    models), the value invariants to guard the value channel and the provenance invariants
    to guard the provenance channel. This is achieved by training a set of models
    for individual layers to describe the activation and provenance distributions
    only using in-distribution inputs. In other words, invariant models are trained
    as a One-Class Classification (OCC) problem where all training samples are positive
    (i.e., in-distribution inputs in this context). At test time, an input is passed
    through all the invariant models which provide independent predictions about whether
    the input induces states that violate the invariant distributions. The final result
    is a joint decision based on all these predictions. Extensive experiments on various
    attacks, datasets and models suggest that this method can achieve consistently
    high detection accuracy on all different types of attacks, while the performance
    of baseline detectors is not consistent.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[64](#bib.bib64)]中，作者发现对抗样本主要利用两种攻击通道：来源通道和激活值分布通道。来源通道表明DNN输出对激活值的小变化不稳定，最终导致分类错误。另一方面，激活通道表明，虽然来源略有变化，但一层的激活值可能与存在良性输入时大相径庭。利用这些观察，他们提出了一种提取两种不变性的（或由模型表示的概率分布）方法，即值不变性以保护值通道，来源不变性以保护来源通道。这是通过训练一组模型来描述激活和来源分布，仅使用分布内输入来实现的。换句话说，不变模型被训练为单类分类（OCC）问题，其中所有训练样本都是正样本（即此上下文中的分布内输入）。在测试时，一个输入会通过所有不变模型，这些模型提供关于输入是否引发违反不变分布的状态的独立预测。最终结果是基于所有这些预测的联合决策。对各种攻击、数据集和模型的广泛实验表明，该方法可以在所有不同类型的攻击中实现持续高的检测准确率，而基线检测器的性能则不稳定。
- en: In [[65](#bib.bib65)], the idea is that inherent distance of adversarial perturbation
    from the training data manifold will cause the overall network uncertainty to
    exceed that of the normal example. To this end, random sampling of hidden units
    of each layer of a pre-trained network is used to introduce randomness and the
    overall uncertainty of a test image is quantified in terms of the hidden layer
    components. A mutual information based thresholding test is used to detect adversarial
    examples. The performance is further improved by optimizing over the sampling
    probabilities to minimize uncertainty. Experiments on the CIFAR10 and the cats-and-dogs
    datasets on deep state-of-the-art CNNs demonstrated the importance sampling parameter
    optimization, which readily translate to improved attack detection.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[65](#bib.bib65)]中，理念是对抗扰动与训练数据流形的固有距离会导致整体网络不确定性超过正常示例。为此，使用预训练网络每层的隐藏单元的随机抽样来引入随机性，并通过隐藏层组件来量化测试图像的整体不确定性。利用基于互信息的阈值测试来检测对抗样本。通过优化采样概率以最小化不确定性，进一步提高了性能。在深度最先进的CNN上对CIFAR10和猫狗数据集的实验展示了重要的采样参数优化，这可直接转化为改进的攻击检测。
- en: Approaches such as [[66](#bib.bib66)] and [[67](#bib.bib67)] rely on projecting
    the test image to benign dataset manifold to detect adversarial examples. The
    underlying assumption in these approaches is that adversarial perturbations move
    the test image away from the benign image manifold and the effect of adversary
    can be nullified by projecting the images back onto the benign manifold before
    classifying them. As the true image manifold is unknown, various estimation techniques
    are used. For example, [[66](#bib.bib66)] use a sample approximation comprising
    a database of billions of natural images. On the other hand, [[67](#bib.bib67)]
    use a generative model trained on benign images to estimate the manifold. Given
    the estimated benign manifold, the projection is done by nearest neighbor search
    in [[66](#bib.bib66)] and gradient-based search in [[67](#bib.bib67)]. These methods
    are founds to be robust against gray-box and black-box attacks where the adversary
    is unaware of the defense strategy.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 像[[66](#bib.bib66)]和[[67](#bib.bib67)]这样的 approaches 依赖于将测试图像投影到 benign 数据集流形中以检测对抗样本。这些方法的基本假设是对抗扰动将测试图像从
    benign 图像流形上移开，而通过将图像在分类之前投影回 benign 流形，可以抵消对抗者的影响。由于真实的图像流形是未知的，因此使用了各种估计技术。例如，[[66](#bib.bib66)]使用一个包含数十亿自然图像的数据库进行样本近似。另一方面，[[67](#bib.bib67)]使用在
    benign 图像上训练的生成模型来估计流形。根据估计的 benign 流形，[[66](#bib.bib66)]通过最近邻搜索进行投影，而[[67](#bib.bib67)]则通过基于梯度的搜索进行投影。这些方法在对抗者不了解防御策略的灰盒和黑盒攻击中表现出较强的鲁棒性。
- en: 3.4 Other Miscellaneous Techniques
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 其他杂项技术
- en: Here we discuss some other techniques that are used for adversarial example
    detection which do not fall in the aforementioned categorizations of the post-hoc
    processing.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们讨论一些其他用于对抗样本检测的技术，这些技术不属于上述的后处理分类。
- en: In [[69](#bib.bib69)], various uncertainty measures, e.g., entropy, mutual information,
    softmax variance, for adversarial example detection are examined. Each of these
    measures capture distinct types of uncertainty and are analyzed from the perspective
    of adversarial example detection. The authors showed that only the mutual information
    gets useful detection performance on adversarial examples. In fact, most other
    measures of uncertainty seem to be worse than random guessing on MNIST and Kaggle
    dogs vs. cats classification datasets.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[69](#bib.bib69)]中，检查了用于对抗样本检测的各种不确定性度量，例如熵、互信息、softmax 方差。这些度量捕捉了不同类型的不确定性，并从对抗样本检测的角度进行了分析。作者展示了只有互信息在对抗样本上具有有效的检测性能。实际上，大多数其他不确定性度量在
    MNIST 和 Kaggle dogs vs. cats 分类数据集上似乎比随机猜测更差。
- en: The approach in [[70](#bib.bib70)] is motivated by the observation that the
    DNN feature spaces are often unnecessarily large, and this provides extensive
    degrees of freedom for an attacker to construct adversarial examples. The authors
    propose to reduce the degrees of freedom for constructing adversarial examples
    by “squeezing” out unnecessary input features. Specifically, they compare the
    model’s prediction of the original test example with its prediction of the test
    example after squeezing, i.e., reducing the color depth of images, and using smoothing
    to reduce the variation among pixels. If the original and the squeezed inputs
    produce substantially different predictions then the example is declared adversarial.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[[70](#bib.bib70)]中的方法受到以下观察的启发：DNN 特征空间通常过大，这为攻击者构造对抗样本提供了广泛的自由度。作者建议通过“挤出”不必要的输入特征来减少构造对抗样本的自由度。具体而言，他们比较了模型对原始测试样本的预测与在挤压后，即减少图像的颜色深度和使用平滑减少像素间变异的测试样本的预测。如果原始输入和挤压后的输入产生了实质性不同的预测，则该样本被宣布为对抗样本。'
- en: In [[71](#bib.bib71)] SafetyNet is proposed which consists of the original classifier,
    and an adversary detector which looks at the internal state of the later layers
    in the original classifier. Here, the output from the ReLU is quantized to generate
    a discrete code based on some set of thresholds. They claimed that different code
    patterns appear for natural examples and adversarial examples. An adversarial
    example detector (i.e., RBF-SVM) is used that compares a code produced at test
    time with a collection of examples, i.e., an attacker must make the network produce
    a code that is acceptable to the detector which is shown to be hard.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[71](#bib.bib71)]中，提出了SafetyNet，它由原始分类器和一个对抗检测器组成，该检测器查看原始分类器后层的内部状态。在这里，ReLU的输出被量化以生成基于某些阈值的离散代码。他们声称，自然样本和对抗样本会出现不同的代码模式。使用对抗样本检测器（即RBF-SVM），将测试时产生的代码与一组样本进行比较，即攻击者必须使网络生成一个检测器可接受的代码，这被证明是困难的。
- en: In [[72](#bib.bib72)], the method improves the naive Bayes used in many generative
    classifiers by combining it with variational auto-encoder. They propose three
    adversarial example detection methods. The first two use the learned generative
    model as a proxy of the data manifold, and reject inputs that are far away from
    it. The third computes statistics for the classifier’s output probability vector,
    and rejects inputs that lead to under-confident predictions. Experimental results
    suggest that deep Bayes classifiers are more robust than deep discriminative classifiers,
    and that the detection methods based on deep Bayes are effective against various
    attacks.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[72](#bib.bib72)]中，该方法通过将朴素贝叶斯与变分自编码器结合，改进了许多生成分类器中使用的朴素贝叶斯。它们提出了三种对抗样本检测方法。前两种方法使用学习到的生成模型作为数据流形的代理，拒绝远离该流形的输入。第三种方法计算分类器输出概率向量的统计量，并拒绝导致不自信预测的输入。实验结果表明，深度贝叶斯分类器比深度判别分类器更具鲁棒性，基于深度贝叶斯的检测方法对各种攻击都有效。
- en: In [[73](#bib.bib73)], the authors propose to model the outputs of the various
    layers (deep features) with parametric probability distributions (Gaussian and
    Gaussian Mixture Models). At test time, the log-likelihood scores of the features
    of a test sample are calculated with respect to these distributions and used as
    anomaly score to discriminate in-distribution samples (which should have high
    likelihood) from adversarial examples (which should have low likelihood).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[73](#bib.bib73)]中，作者建议用参数概率分布（高斯和高斯混合模型）来建模各层（深度特征）的输出。在测试时，计算测试样本特征相对于这些分布的对数似然分数，并用作异常分数，以区分分布内样本（应该有高似然）和对抗样本（应该有低似然）。
- en: The main idea in [[74](#bib.bib74)] is to combine kNN based distance measure [[75](#bib.bib75)]
    with influence function which is a measure of how much a test sample classification
    is affected by each training sample. The motivation behind this approach is that
    for an in-distribution input, its kNN training samples (nearest neighbors in the
    embedding space) and the most helpful training samples (found using the influence
    function) should correlate. However, this correlation is much weaker for adversarial
    examples, and serves as an indication of the attack.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[[74](#bib.bib74)]中的主要思想是将基于kNN的距离度量[[75](#bib.bib75)]与影响函数结合，影响函数是一种度量测试样本分类受到每个训练样本影响的程度的方法。这种方法的动机是，对于分布内输入，其kNN训练样本（嵌入空间中的最近邻）和最有帮助的训练样本（通过影响函数找到）应该相关。然而，对于对抗样本，这种相关性要弱得多，这表明了攻击的存在。'
- en: The motivation in [[76](#bib.bib76)] is the observation that different neural
    networks presented with the same adversarial example will make different mistakes.
    The authors propose to use such mistake patterns for adversarial example detection.
    Experiments on the MNIST and CIFAR10 datasets show that such detection approach
    generalizes well across different adversarial example generation methods.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[[76](#bib.bib76)]中的动机是观察到不同的神经网络在面对相同的对抗样本时会犯不同的错误。作者建议利用这些错误模式进行对抗样本检测。对MNIST和CIFAR10数据集的实验表明，这种检测方法在不同对抗样本生成方法中具有良好的泛化能力。'
- en: In [[77](#bib.bib77)] robust feature alignment is used to detect adversarial
    examples. By using an object detector, the authors first extract higher-level
    robust features contained in images. Next, the approach quantifies the similarity
    between the image’s extracted features with the expected features of its predicted
    class. A similarity threshold is finally used to classify a test sample as benign
    or adversarial.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[77](#bib.bib77)]中，使用了鲁棒特征对齐来检测对抗性示例。通过使用对象检测器，作者首先提取图像中包含的高级鲁棒特征。接下来，该方法量化图像提取的特征与预测类别的预期特征之间的相似性。最后，使用相似性阈值将测试样本分类为良性或对抗性。
- en: In [[78](#bib.bib78)], anomaly detection is performed by introducing random
    feature nullification in both training and testing phases that ensures the non-deterministic
    nature of the DNN. Here, the randomization introduced at the test time ensures
    that the model’s processing of the input decreases the effectiveness of the adversarial
    examples even if the attacker learns critical features.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[78](#bib.bib78)]中，通过引入训练和测试阶段的随机特征无效化来执行异常检测，从而确保DNN的非确定性特性。在测试时引入的随机化确保模型处理输入时，即使攻击者学习了关键特征，对抗性示例的效果也会降低。
- en: In [[79](#bib.bib79)], three strategies are presented. First, regularized feature
    vectors are used to retrain the last layer of the CNN. This can be used to detect
    whether the input is adversarial. Second, histograms are created from the absolute
    values of the hidden layer outputs and are combined to form a vector which is
    used by the SVM to classify. Third, the input is perturbed to reinforce the parts
    of the input example that are ignored by the DNN which can then be used for adversarial
    example detection. Finally, the authors combine the best aspects of these methods
    to develop a more robust approach.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[79](#bib.bib79)]中，提出了三种策略。首先，使用正则化特征向量重新训练CNN的最后一层。这可以用来检测输入是否具有对抗性。其次，从隐藏层输出的绝对值中创建直方图，并将其合并成一个向量，由SVM进行分类。第三，对输入进行扰动，以强化被DNN忽视的输入示例部分，然后可以用来进行对抗示例检测。最后，作者结合了这些方法的最佳方面，开发了一种更强大的方法。
- en: In [[80](#bib.bib80)], a framework is presented for enhancing the robustness
    of DNN against adversarial examples. The idea is to use locality-preserving hash
    functions to transform examples to enhance the robustness. The hash representations
    of the examples are reconstructed by using a denoising auto-encoder (DAE) that
    enables the DNN classifier to attain the locality information in the latent space.
    Moreover, the DAE can detect the adversarial examples that are far from the support
    of the underlying training distribution.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[80](#bib.bib80)]中，提出了一种增强DNN对抗性示例鲁棒性的框架。其思想是使用局部保持哈希函数来转换示例，以增强鲁棒性。示例的哈希表示通过使用去噪自编码器（DAE）进行重建，使DNN分类器能够在潜在空间中获得局部信息。此外，DAE可以检测与基础训练分布的支持距离较远的对抗示例。
- en: 4 Relative Strengths and Weakness
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 相对优势与劣势
- en: The supervised techniques usually have higher performance compared to other
    methods as they use the labeled examples from both normal and anomaly classes.
    They are able to learn the boundary from the labeled training examples and then
    more easily classify the unseen test examples into normal or anomaly classes.
    However, when training data for anomalies (the known unknowns) may not represent
    the full spectrum of anomalies, supervised approaches may overfit and perform
    poorly on unseen anomalous data (the unknown unknowns). Furthermore, due to the
    lack of availability of labeled anomalous examples, supervised techniques are
    not as popular as the semi-supervised or unsupervised techniques.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他方法相比，监督技术通常具有更高的性能，因为它们使用了来自正常和异常类别的标记示例。它们能够从标记的训练示例中学习边界，然后更容易将未见过的测试示例分类为正常或异常。然而，当异常的训练数据（已知的未知数）可能不能代表异常的全部范围时，监督方法可能会过拟合，并在未见过的异常数据（未知的未知数）上表现不佳。此外，由于缺乏标记异常示例，监督技术不如半监督或无监督技术受欢迎。
- en: Unsupervised techniques are quite flexible and broadly applicable as they do
    not rely on the availability of the anomalous data and corresponding labels. The
    techniques learn inherent characteristics or unique features solely from in-distribution
    data that are useful in separating normal from anomalous examples. Unfortunately,
    this flexibility comes at the cost of robustness – the unsupervised techniques
    are very sensitive to noise, and data corruptions and are often less accurate
    than supervised or semi-supervised techniques.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督技术非常灵活且广泛适用，因为它们不依赖于异常数据及其对应标签的可用性。这些技术仅从分布内数据中学习固有特征或独特的特征，这些特征有助于将正常样本与异常样本分开。不幸的是，这种灵活性以稳健性为代价——无监督技术对噪声和数据损坏非常敏感，通常不如监督或半监督技术准确。
- en: Semi-supervised techniques exploit unlabeled data in addition to labeled in-distribution
    data to improve the performance of unsupervised techniques. Though, whether unlabeled
    data is in-distribution or anomaly is not known, it is observed that unlabeled
    data is helpful in improving the performance of anomaly detection. Note that unlabeled
    data can be obtained easily in real-world applications making semi-supervised
    techniques amenable in practice. These methods also suffer from the overfitting
    problem on unseen anomalies.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督技术利用未标记的数据和标记的分布内数据来提升无监督技术的性能。虽然未标记数据是否属于分布内或异常数据未知，但观察到未标记数据有助于提高异常检测的性能。请注意，在现实世界应用中，未标记的数据容易获得，使得半监督技术在实践中更具可行性。这些方法也存在对未见异常的过拟合问题。
- en: Distance-based methods, e.g., kNN approaches, require appropriate distance measure
    to be defined a priori. Most distance measures are not effective in high-dimension.
    Further, such methods are typically heuristic and require manual selection of
    parameters. Projection-based methods, e.g., GAN approaches, are very flexible
    and address the high-dimensionality challenge. However, their performance is heavily
    dependent on the quality of the image manifold estimate. In certain applications,
    it may not be easy to estimate the image manifold with sample approximation or
    generative modeling. Probabilistic methods, e.g., density estimation approaches,
    make use of the distribution of the training data or features to determine the
    location of the anomaly boundary. The performance of such methods is very poor
    in the small data regime as reliable estimates cannot be obtained. Uncertainty-based
    methods, e.g., entropy approaches, require a metric that is sensitive enough to
    detect the effects of anomalies in the dataset. Although these methods are easy
    to implement in practice, the performance of such methods is highly dependent
    on the the quality of uncertainties. Uncertainty quantification in DL is an ongoing
    research topic and high quality uncertainty estimates will surely improve the
    performance of uncertainty-based methods.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 基于距离的方法，例如 kNN 方法，需要事先定义合适的距离度量。大多数距离度量在高维空间中效果不佳。此外，这些方法通常是启发式的，需要手动选择参数。基于投影的方法，例如
    GAN 方法，非常灵活，可以解决高维挑战。然而，它们的性能严重依赖于图像流形估计的质量。在某些应用中，使用样本近似或生成建模来估计图像流形可能并不容易。概率方法，例如密度估计方法，利用训练数据或特征的分布来确定异常边界的位置。这些方法在小数据环境下表现非常差，因为无法获得可靠的估计。基于不确定性的方法，例如熵方法，需要一个足够敏感的度量来检测数据集中异常的影响。虽然这些方法在实践中容易实现，但其性能高度依赖于不确定性的质量。深度学习中的不确定性量化是一个正在研究的课题，高质量的不确定性估计必将改善基于不确定性的方法的性能。
- en: The computational complexity of these methods is another important aspect to
    consider. In general, probabilistic and uncertainty-based methods have computationally
    expensive training phases, however efficient testing. On the other hand, distance-based
    and projection-based methods, in general, are computationally expensive in the
    test phase. Depending on the application requirements, a user should choose the
    most appropriate anomaly detection method.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法的计算复杂性是另一个重要的考虑因素。一般来说，概率方法和基于不确定性的方法在训练阶段计算开销较大，但测试阶段效率较高。另一方面，基于距离和基于投影的方法通常在测试阶段计算开销较大。根据应用需求，用户应选择最合适的异常检测方法。
- en: 5 Application Domains
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 应用领域
- en: In this section, we briefly discuss several applications of OOD and adversarial
    example detection. We also suggest future research that is needed for these application
    domains.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们简要讨论了OOD和对抗性样本检测的几种应用。我们还建议了这些应用领域未来所需的研究方向。
- en: Intrusion Detection - An Intrusion Detection System is a system that monitors
    network traffic for suspicious activity and issues alerts when such activity is
    discovered. A key challenge for intrusion detection is the huge volume of data
    and sophisticated malicious patterns. Therefore, DL techniques are quite promising
    in the intrusion detection application.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 入侵检测 - 入侵检测系统是一种监控网络流量以发现可疑活动并在发现此类活动时发出警报的系统。入侵检测的一个关键挑战是数据量庞大和恶意模式复杂。因此，深度学习技术在入侵检测应用中相当有前景。
- en: In [[81](#bib.bib81)], a neural network based intrusion detector is trained
    to identify intruders. In [[82](#bib.bib82)], a deep hierarchical model is proposed
    for intrusion detection. The model is a combination of a restricted Boltzmann
    machine (RBM) for unsupervised feature learning and a supervised learning network
    called as Backpropagation network. In [[83](#bib.bib83)], a network intrusion
    model is proposed where feature learning is performed by stacking dilated convolutional
    autoencoders. These feature are then used to train a softmax classifier to perform
    supervised intrusion detection. In [[84](#bib.bib84)], an autoencoder based model
    in combination with a stochastic anomaly threshold determination method is proposed
    for intrusion detection. The algorithm computes the threshold using the empirical
    mean and standard deviation which are found from training set via the trained
    autoencoder.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[81](#bib.bib81)]中，基于神经网络的入侵检测器被训练以识别入侵者。在[[82](#bib.bib82)]中，提出了一种用于入侵检测的深层次模型。该模型结合了用于无监督特征学习的限制玻尔兹曼机（RBM）和一种称为反向传播网络的监督学习网络。在[[83](#bib.bib83)]中，提出了一种网络入侵模型，其中通过堆叠扩张卷积自编码器进行特征学习。这些特征随后用于训练一个softmax分类器以执行监督入侵检测。在[[84](#bib.bib84)]中，提出了一种结合了随机异常阈值确定方法的基于自编码器的模型用于入侵检测。该算法使用从训练集通过训练的自编码器获得的经验均值和标准差来计算阈值。
- en: As mentioned earlier, these DL based systems are equally susceptible to both
    OOD and adversarial examples [[85](#bib.bib85), [86](#bib.bib86), [87](#bib.bib87)].
    In [[85](#bib.bib85)], the authors analyze the performances of the state-of-the-art
    attack algorithms against DL-based intrusion detection. The susceptibility of
    DNNs used in the intrusion detection system is validated by experiments and the
    role of individual features is also explored. The authors in [[86](#bib.bib86)]
    demonstrated that an adversary can generate effective adversarial examples against
    DL based intrusion detection systems even when the internal information of the
    target model is not available to the adversary. Note that in intrusion detection
    applications, a large amount of labeled data corresponding to normal behavior
    is usually available, while labels for intrusions are not. Therefore, semi-supervised
    and unsupervised OOD and adversarial example detection techniques discussed in
    the previous sections are worthwhile directions to pursue.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这些基于深度学习的系统同样易受到OOD和对抗性样本的影响[[85](#bib.bib85), [86](#bib.bib86), [87](#bib.bib87)]。在[[85](#bib.bib85)]中，作者分析了最先进攻击算法对基于深度学习的入侵检测系统的表现。通过实验验证了入侵检测系统中使用的深度神经网络的易受攻击性，并探索了各个特征的作用。[[86](#bib.bib86)]中的作者证明了即使在攻击者无法获得目标模型的内部信息的情况下，攻击者仍然可以生成有效的对抗性样本来对抗基于深度学习的入侵检测系统。请注意，在入侵检测应用中，通常可以获得大量对应正常行为的标注数据，而入侵的标注数据则较少。因此，前面章节中讨论的半监督和无监督的OOD及对抗性样本检测技术是值得追求的方向。
- en: Fraud Detection - Fraud detection refers to detection of fraudulent activities
    occurring in many e-commerce domains, such as, banking, insurance, law enforcement,
    etc. A good fraud detection system should be able to identify the fraudulent transactions
    accurately and should make the detection possible in real-time. There is an increase
    in interest in applying DL techniques in fraud detection systems. In [[88](#bib.bib88)],
    fraud detection is modeled as a sequence classification task. An LSTM is used
    to generate transaction sequences and incorporate aggregation functions like mean,
    absolute value to aggregate the learned features for fraud detection. Furthermore,
    in [[89](#bib.bib89)], feature sequencing is performed using CNNs for detecting
    transaction fraud. Recently, the authors in [[90](#bib.bib90)] analyzed the vulnerability
    of deep fraud detector to adversarial examples, i.e., slight perturbations in
    input transactions designed to fool the fraud detector. They show that the deployed
    deep fraud detector is highly vulnerable to attacks as the average precision is
    decreased from 90% to as low as 20%.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 欺诈检测 - 欺诈检测是指检测许多电子商务领域中发生的欺诈活动，例如银行、保险、执法等。一个好的欺诈检测系统应该能够准确识别欺诈交易，并应能实现实时检测。对在欺诈检测系统中应用深度学习技术的兴趣日益增加。在[[88](#bib.bib88)]中，欺诈检测被建模为序列分类任务。使用LSTM生成交易序列，并结合均值、绝对值等聚合函数来汇总学习到的特征以进行欺诈检测。此外，在[[89](#bib.bib89)]中，使用CNN进行特征序列化以检测交易欺诈。最近，[[90](#bib.bib90)]中的作者分析了深度欺诈检测器对对抗性样本的脆弱性，即对欺诈检测器进行欺骗的输入交易中的微小扰动。他们展示了部署的深度欺诈检测器对攻击高度脆弱，因为平均精度从90%降至低至20%。
- en: This motivates the study of the effect of unintentional and intentional anomalies
    in deep fraud detection systems. Techniques discussed in the previous sections
    will be applicable for such a problem and are potential viable solutions for designing
    robust deep fraud detection systems.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这激发了对深度欺诈检测系统中无意和故意异常效应研究的兴趣。前面讨论的技术将适用于这样的问题，并且是设计强健的深度欺诈检测系统的潜在可行解决方案。
- en: Anomaly Detection in Healthcare and Industrial Domains - Anomaly detection in
    the healthcare domain try to detect abnormal patient conditions or instrumentation
    errors. Anomaly detection is a very critical problem in this domain and requires
    high degree of accuracy. Similarly, in industrial systems like wind turbines,
    power plants, and storage devices which are exposed to large amounts of stress
    on a daily basis, it is critical to detect any damages as quickly as possible.
    The medical abnormalities and industrial damage are rare events and detecting
    them can be modeled as an anomaly detection problem. Therefore, there is a surge
    of interest in applying DL in both medical [[91](#bib.bib91)] and industrial application
    domains [[92](#bib.bib92)].
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗保健和工业领域的异常检测 - 医疗保健领域的异常检测试图检测异常的患者状况或仪器错误。在该领域，异常检测是一个非常关键的问题，需要高精度。同样，在风力涡轮机、发电厂和储存设备等工业系统中，这些系统每天承受大量压力，检测任何损坏尽可能快地是至关重要的。医疗异常和工业损伤是稀有事件，检测它们可以建模为异常检测问题。因此，对深度学习在医疗[[91](#bib.bib91)]和工业应用领域[[92](#bib.bib92)]中的应用兴趣激增。
- en: 'Unfortunately, similar to other DL applications, these systems are equally
    susceptible to OOD and adversarial examples. For example, the authors in [[93](#bib.bib93)]
    demonstrated that adversarial examples are capable of manipulating DL systems
    across three clinical domains: diabetic retinopathy from retinal fundoscopy, pneumothorax
    from chest-Xray, and melanoma from dermoscopic photographs.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，与其他深度学习应用类似，这些系统同样容易受到OOD和对抗性样本的影响。例如，[[93](#bib.bib93)]中的作者展示了对抗性样本能够操控深度学习系统，跨越三个临床领域：视网膜眼底检查中的糖尿病视网膜病变、胸部X光中的气胸，以及皮肤镜照片中的黑色素瘤。
- en: This motivates the study of the effect of anomalies in DL based healthcare and
    industrial systems. Techniques discussed in the previous sections can be used
    for designing robust healthcare and damage detection systems.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这激发了对深度学习（DL）在医疗保健和工业系统中异常效应研究的兴趣。前面讨论的技术可以用于设计强健的医疗保健和损伤检测系统。
- en: Malware Detection - Malware detection focuses on detecting malware software
    by monitoring the activity of the computer systems and classifying it as normal
    or anomalous. The velocity, volume, and the complexity of malware are posing new
    challenges to the anti-malware community. Current state-of-the-art research shows
    that recently, researchers started applying machine learning and DL methods for
    malware analysis and detection [[94](#bib.bib94)]. In [[78](#bib.bib78)], malware
    detection is performed by introducing random feature nullification in both training
    and testing phases that ensures the non-deterministic nature of the DNNs. Intuitively,
    the non-deterministic nature ensures that the model’s processing of the input
    decreases the effectiveness of the adversarial examples even if the attacker learns
    critical features. Furthermore, in [[95](#bib.bib95)], a stacked autoencoders
    model is used for malware detection. The model employs a greedy layerwise training
    operation for unsupervised feature learning and supervised parameter tuning. Furthermore,
    in [[96](#bib.bib96)], fake malware is generated and is learned to distinguish
    from the real data using a novel GAN architecture.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 恶意软件检测 - 恶意软件检测侧重于通过监控计算机系统的活动来检测恶意软件，并将其分类为正常或异常。恶意软件的速度、体积和复杂性对反恶意软件社区带来了新的挑战。目前的前沿研究表明，最近研究人员开始应用机器学习和深度学习方法进行恶意软件分析和检测[[94](#bib.bib94)]。在[[78](#bib.bib78)]中，通过在训练和测试阶段引入随机特征失效来进行恶意软件检测，以确保DNN的非确定性特性。直观地，非确定性特性确保模型对输入的处理减少了对抗样本的有效性，即使攻击者了解了关键特征。此外，在[[95](#bib.bib95)]中，使用了堆叠自编码器模型进行恶意软件检测。该模型采用贪婪的分层训练操作进行无监督特征学习和监督参数调整。此外，在[[96](#bib.bib96)]中，生成了伪恶意软件，并使用一种新颖的GAN架构来区分真实数据。
- en: Authors in [[97](#bib.bib97), [98](#bib.bib98)] expanded on existing adversarial
    example crafting algorithms to construct a highly-effective attack against malware
    detection models. Using the augmented adversarial crafting algorithm, authors
    managed to mislead the malware detection classifier for 63% of all malware samples.
    In [[80](#bib.bib80)], the authors analyzed the effect of several attacks on the
    Android malware classification task.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[[97](#bib.bib97), [98](#bib.bib98)]的作者扩展了现有的对抗样本构造算法，构造了对恶意软件检测模型的高度有效攻击。利用增强的对抗构造算法，作者成功误导了63%的所有恶意软件样本的检测分类器。在[[80](#bib.bib80)]中，作者分析了几种攻击对Android恶意软件分类任务的影响。'
- en: Given the susceptibility of the state-of-the-art malware detection classifiers
    to adversarial examples, it will be useful to utilize OOD and adversarial example
    detection techniques in deep malware detection systems.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于最先进的恶意软件检测分类器对对抗样本的易感性，将OOD和对抗样本检测技术应用于深度恶意软件检测系统将是有用的。
- en: Time Series and Video Surveillance Anomaly Detection - The task of detecting
    anomalies in multivariate time series data is quite challenging. Hence, efficient
    detection of multivariate time series anomalies is critical for fault diagnostics.
    RNN and LSTM based methods perform well in detecting anomalies in multivariate
    time series data. In [[99](#bib.bib99)], a generic framework based on DL for detecting
    anomalies in multivariate time series data is presented. Deep attention based
    models are used in [[100](#bib.bib100)] for anomaly detection for effective detection
    of anomalies. Many works have applied the deep learning models for video surveillance
    anomaly detection in [[101](#bib.bib101), [102](#bib.bib102), [103](#bib.bib103)].
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列和视频监控异常检测 - 在多变量时间序列数据中检测异常的任务相当具有挑战性。因此，多变量时间序列异常的有效检测对故障诊断至关重要。基于RNN和LSTM的方法在检测多变量时间序列数据中的异常方面表现良好。在[[99](#bib.bib99)]中，提出了一种基于深度学习的通用框架来检测多变量时间序列数据中的异常。深度注意力模型在[[100](#bib.bib100)]中用于异常检测，以实现有效的异常检测。许多研究在[[101](#bib.bib101),
    [102](#bib.bib102), [103](#bib.bib103)]中应用了深度学习模型进行视频监控异常检测。
- en: Unfortunately, some recent papers [[104](#bib.bib104), [105](#bib.bib105)] have
    shown that one can design adversarial examples on time-series classifiers as well.
    Thus, in our opinion, future researchers should incorporate OOD and adversarial
    example detectors in their time series classification systems to improve the resilience
    and consider model robustness as an evaluative metric.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，一些近期的论文[[104](#bib.bib104), [105](#bib.bib105)]表明，也可以在时间序列分类器上设计对抗样本。因此，在我们看来，未来的研究者应在时间序列分类系统中加入OOD和对抗样本检测器，以提高系统的抗干扰能力，并将模型的鲁棒性作为评估指标。
- en: 6 Conclusion and Open Questions
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论与开放问题
- en: In this survey, we discussed various techniques for detecting OOD and adversarial
    examples given a pre-trained DNN. For each category of anomaly detection techniques,
    we discussed the strengths and weaknesses of these techniques. Finally, we discussed
    various application domains where the post-hoc processing, as well as, training
    based anomaly detection techniques are applicable.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次调查中，我们讨论了在给定预训练DNN的情况下，检测OOD和对抗样本的各种技术。对于每种异常检测技术类别，我们讨论了这些技术的优缺点。最后，我们讨论了后处理以及基于训练的异常检测技术适用的各种应用领域。
- en: There are several open issues and worthwhile future directions for further research.
    Several of these are identified by analyzing and comparing existing literature
    and the research considered in this survey.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 目前存在几个开放问题和有价值的未来研究方向。这些问题通过分析和比较现有文献以及本调查中考虑的研究被识别出来。
- en: 'Methods: We classified anomaly detection algorithms based on the availability
    of the labels of anomalous examples and the type of metrics used. Based on the
    availability of the labels, the techniques are classified as supervised, semi-supervised,
    and unsupervised. Based on the type of metric, the techniques are classified as
    probability-based, distance-based, projection-based, and uncertainty-based. Each
    category of methods have their own strengths and weaknesses, and faces different
    challenges as discussed in Section [4](#S4 "4 Relative Strengths and Weakness
    ‣ Anomalous Instance Detection in Deep Learning: A Survey"). We conjecture that
    exploration of ensemble detection approaches can be a worthwhile future direction.
    The ensemble approach combines outputs of multiple detectors offering complementary
    strengths into a single one, thus yielding better performance compared to using
    individual detectors.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '方法：我们根据异常样本标签的可用性和使用的度量类型对异常检测算法进行了分类。根据标签的可用性，技术被分类为有监督、半监督和无监督。根据度量类型，技术被分类为基于概率、基于距离、基于投影和基于不确定性。每种方法类别都有其自身的优缺点，并面临不同的挑战，详细讨论见第[4](#S4
    "4 Relative Strengths and Weakness ‣ Anomalous Instance Detection in Deep Learning:
    A Survey")节。我们推测，探索集成检测方法可能是一个值得的未来方向。集成方法将多个检测器的输出结合在一起，提供互补的优点，从而比使用单独检测器获得更好的性能。'
- en: 'Defining Anomalies: Majority of the research on detecting OOD and adversarial
    examples in DL focuses on detecting independent anomalies (e.g., adversarial examples
    generated independently from one another). However, anomalous behaviors can be
    much more complex requiring more sophisticated detection approaches than currently
    available. An example of this is discussed in [[106](#bib.bib106)] where a simple
    correlated anomaly generation approach was discussed. It was shown that current
    defenses are not capable of defending against this simple scheme. Further, defining
    collective and contextual anomalies [[107](#bib.bib107)] in the context of OOD
    and adversarial examples in DL can be very interesting and detecting them will
    certainly require the development of a new class of detectors. Also, we want to
    emphasize that it is important for future research on anomaly detection to be
    cognizant of the fact that anomalies may not adhere to our definitions and assumptions
    and can have extremely complex unknown behavior. This is similar to the concept
    of unknown-unknowns [[108](#bib.bib108)]. We believe that the research on domain
    generalization [[109](#bib.bib109)] and meta learning [[110](#bib.bib110)] can
    be used to solve some of these issues.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 定义异常：大多数关于在深度学习中检测OOD（Out-of-Distribution）和对抗样本的研究集中在检测独立异常（例如，彼此独立生成的对抗样本）。然而，异常行为可能更加复杂，需要比当前可用的检测方法更复杂的检测方式。一个例子在[[106](#bib.bib106)]中讨论了简单的相关异常生成方法。研究表明，当前的防御措施无法防御这种简单的方案。此外，在深度学习中定义集体和情境异常[[107](#bib.bib107)]可能非常有趣，检测它们无疑需要开发新类别的检测器。同时，我们要强调，未来异常检测研究中必须认识到，异常可能不符合我们的定义和假设，可能具有极其复杂的未知行为。这类似于未知未知的概念[[108](#bib.bib108)]。我们相信，领域泛化[[109](#bib.bib109)]和元学习[[110](#bib.bib110)]的研究可以用于解决这些问题。
- en: 'Going beyond image classification: Most of the papers discussed in this survey
    (and in the literature) focus on the detection of anomalous examples in DNN based
    image classification problems. However, in recent years there has been a surge
    of interest in applying DL on other data types, e.g. text, graphs, trees, manifolds
    etc. These data types are ubiquitous in several high-impact applications including
    bioinformatics, neuroscience, social sciences, and molecular chemistry. Unfortunately,
    DL approaches in these data types also suffer from the existence of OOD and adversarial
    examples [[111](#bib.bib111)]. Post-hoc detection of such anomalies has not received
    much attention. Furthermore, going beyond classification problems and exploring
    the design and the detection of anomalies in DL based object detection, control,
    and planning problems can be a high-impact future research direction.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 超越图像分类：本调查（及文献中）讨论的大多数论文都集中在基于DNN的图像分类问题中的异常样本检测上。然而，近年来，应用深度学习（DL）于其他数据类型（如文本、图形、树、流形等）引起了广泛关注。这些数据类型在多个高影响力应用领域中普遍存在，包括生物信息学、神经科学、社会科学和分子化学。不幸的是，这些数据类型中的DL方法也遭遇了OOD和对抗样本的问题[[111](#bib.bib111)]。对这些异常的事后检测尚未受到足够关注。此外，超越分类问题，探索DL基础上的对象检测、控制和规划问题中的异常设计和检测，可以成为一个高影响力的未来研究方向。
- en: 'Performance Evaluation: Reliably evaluating the performance of OOD and adversarial
    example detection methods has proven to be extremely difficult. Previous evaluation
    methods are found to be ineffective and performing incorrect or incomplete evaluations [[112](#bib.bib112),
    [113](#bib.bib113)]. Absence of a standard definition for anomalies makes this
    problem very challenging. Furthermore, as anomalies become more sophisticated,
    it may become even harder to reliably evaluate the detection performance. Majority
    of current approaches evaluate the performance of anomaly detectors on OOD and
    adversarial examples. Assuming that training data may not represent the full spectrum
    of anomalies, this evaluation approach raises the risk of overfitting. Ideally,
    one should adopt an evaluation method that can assess the detection performance
    on adaptive and unseen anomalies (the unknown unknowns) over methods that only
    can assess the detection performance on previously seen anomalies (the known unknowns).
    Due to these reasons, there is an immediate need for designing principled benchmarks
    to reliably evaluate the anomaly detection performance [[113](#bib.bib113), [114](#bib.bib114)].'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 性能评估：可靠地评估OOD（Out-of-Distribution）和对抗样本检测方法的性能已被证明是极其困难的。以往的评估方法被发现无效，且进行的评估可能是不正确或不完整的[[112](#bib.bib112),
    [113](#bib.bib113)]。由于缺乏对异常的标准定义，这个问题变得非常具有挑战性。此外，随着异常变得越来越复杂，可靠评估检测性能可能变得更加困难。目前大多数方法在OOD和对抗样本上评估异常检测器的性能。假设训练数据可能无法代表所有异常的全谱，这种评估方法增加了过拟合的风险。理想情况下，应该采用能够评估对适应性和未见过的异常（未知的未知）的检测性能的方法，而不是仅能评估已见过的异常（已知的未知）的检测性能的方法。基于这些原因，迫切需要设计有原则的基准来可靠地评估异常检测性能[[113](#bib.bib113),
    [114](#bib.bib114)]。
- en: 'Theoretical analysis and Fundamental Limits: Finally, we need to make efforts
    on the theoretical front to understand the nature of the anomaly detection problem
    in DL-based systems. In the recent past, a pattern has emerged in which the majority
    of heuristics based defenses (both posthoc detection and training based) are easily
    broken by new attacks [[115](#bib.bib115), [112](#bib.bib112)]. Therefore, the
    development of a coherent theory and methodology that guides practical design
    for anomaly detection in DL-based systems [[116](#bib.bib116)], and fundamental
    characterizations of the existence of adversarial examples [[117](#bib.bib117)]
    is of utmost importance. How to leverage special learning properties such as the
    spatial and temporal consistencies to identify OOD examples [[118](#bib.bib118),
    [119](#bib.bib119)] also worth further exploration.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 理论分析和基本限制：最后，我们需要在理论层面上努力，以理解DL系统中异常检测问题的本质。近年来，出现了一种模式，即大多数基于启发式的防御（包括事后检测和基于训练的防御）都容易被新攻击打破[[115](#bib.bib115),
    [112](#bib.bib112)]。因此，发展一个连贯的理论和方法来指导DL系统中的异常检测实践设计[[116](#bib.bib116)]，以及对对抗样本存在的基本特征[[117](#bib.bib117)]进行研究是至关重要的。如何利用空间和时间一致性等特殊学习属性来识别OOD样本[[118](#bib.bib118),
    [119](#bib.bib119)]也值得进一步探索。
- en: To summarize, OOD and adversarial example detection in DL-based systems is an
    open problem. We highlighted several aspects of the problem to be understood on
    both theoretical and algorithmic front to improve the effectiveness and feasibility
    of anomaly detection. We hope that this survey will provide a comprehensive understanding
    of the different approaches, show the bigger picture of the problem, and suggest
    few promising directions for researchers to pursue in further investigations on
    the anomaly detection in DL-based systems.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，基于深度学习的系统中的OOD和对抗样本检测仍是一个开放问题。我们强调了需要在理论和算法层面理解问题的若干方面，以提高异常检测的有效性和可行性。我们希望这项综述能够提供对不同方法的全面理解，展示问题的整体视角，并为研究人员在进一步研究深度学习系统中的异常检测方面提供一些有前景的方向。
- en: Acknowledgement
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work was performed under the auspices of the U.S. Department of Energy
    by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作是在美国能源部的资助下，由劳伦斯利弗莫尔国家实验室根据合同DE-AC52-07NA27344进行的。
- en: References
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] L. Zhang, “Transfer adaptation learning: A decade survey,” *arXiv preprint
    arXiv:1903.04687*, 2019.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] L. Zhang, “迁移适应学习：十年综述，” *arXiv预印本 arXiv:1903.04687*, 2019年。'
- en: '[2] V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A survey,”
    *ACM Comput. Surv.*, vol. 41, no. 3, pp. 15:1–15:58, Jul. 2009.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] V. Chandola, A. Banerjee, 和 V. Kumar, “异常检测：综述，” *ACM计算机调查*, 第41卷, 第3期,
    页15:1–15:58, 2009年7月。'
- en: '[3] M. A. F. Pimentel, D. A. Clifton, L. Clifton, and L. Tarassenko, “Review:
    A review of novelty detection,” *Signal Process.*, vol. 99, pp. 215–249, Jun.
    2014.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] M. A. F. Pimentel, D. A. Clifton, L. Clifton, 和 L. Tarassenko, “综述：新颖性检测的回顾，”
    *信号处理*, 第99卷, 页215–249, 2014年6月。'
- en: '[4] R. Chalapathy and S. Chawla, “Deep learning for anomaly detection: A survey,”
    *CoRR*, vol. abs/1901.03407, 2019.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] R. Chalapathy 和 S. Chawla, “深度学习在异常检测中的应用：综述，” *CoRR*, 第abs/1901.03407卷,
    2019年。'
- en: '[5] S. Agrawal and J. Agrawal, “Survey on anomaly detection using data mining
    techniques,” *Procedia Computer Science*, vol. 60, pp. 708–713, 2015.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] S. Agrawal 和 J. Agrawal, “基于数据挖掘技术的异常检测调查，” *计算机科学学报*, 第60卷, 页708–713,
    2015年。'
- en: '[6] M. Salehi and L. Rashidi, “A survey on anomaly detection in evolving data:
    [with application to forest fire risk prediction],” *SIGKDD Explor. Newsl.*, vol. 20,
    no. 1, pp. 13–23, May 2018.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] M. Salehi 和 L. Rashidi, “演变数据中的异常检测调查：[应用于森林火灾风险预测]，” *SIGKDD探索新通讯*, 第20卷,
    第1期, 页13–23, 2018年5月。'
- en: '[7] L. Kalinichenko, I. Shanin, and I. Taraban, “Methods for anomaly detection:
    A survey,” in *CEUR Workshop Proceedings*, 2014.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] L. Kalinichenko, I. Shanin, 和 I. Taraban, “异常检测方法：综述，” 见 *CEUR工作坊论文集*,
    2014年。'
- en: '[8] A. Patcha and J.-M. Park, “An overview of anomaly detection techniques:
    Existing solutions and latest technological trends,” *Computer networks*, vol. 51,
    no. 12, pp. 3448–3470, 2007.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] A. Patcha 和 J.-M. Park, “异常检测技术概述：现有解决方案和最新技术趋势，” *计算机网络*, 第51卷, 第12期,
    页3448–3470, 2007年。'
- en: '[9] V. Hodge and J. Austin, “A survey of outlier detection methodologies,”
    *Artificial intelligence review*, vol. 22, no. 2, pp. 85–126, 2004.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] V. Hodge 和 J. Austin, “异常值检测方法综述，” *人工智能评论*, 第22卷, 第2期, 页85–126, 2004年。'
- en: '[10] G. Muruti, F. A. Rahim, and Z. bin Ibrahim, “A survey on anomalies detection
    techniques and measurement methods,” in *2018 IEEE Conference on Application,
    Information and Network Security (AINS)*, Nov 2018, pp. 81–86.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] G. Muruti, F. A. Rahim, 和 Z. bin Ibrahim, “异常检测技术与测量方法的调查，” 见 *2018年IEEE应用、信息和网络安全会议（AINS）*,
    2018年11月, 页81–86。'
- en: '[11] T. Dunning and E. Friedman, *Practical Machine Learning: A New Look at
    Anomaly Detection*.   O’Reilly Media, 2014.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] T. Dunning 和 E. Friedman, *实用机器学习：异常检测的新视角*。O''Reilly Media, 2014年。'
- en: '[12] K. Mehrotra, C. Mohan, and H. Huang, *Anomaly Detection Principles and
    Algorithms*.   Springer International Publishing, 2017.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] K. Mehrotra, C. Mohan, 和 H. Huang, *异常检测原理与算法*。Springer International
    Publishing, 2017年。'
- en: '[13] C. Aggarwal, *Outlier Analysis*.   Springer International Publishing,
    2016.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] C. Aggarwal, *异常值分析*。Springer International Publishing, 2016年。'
- en: '[14] M. Bhuyan, D. Bhattacharyya, and J. Kalita, *Network Traffic Anomaly Detection
    and Prevention: Concepts, Techniques, and Tools*.   Springer International Publishing,
    2017.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] M. Bhuyan, D. Bhattacharyya, 和 J. Kalita, *网络流量异常检测与防御：概念、技术与工具*。Springer
    International Publishing, 2017年。'
- en: '[15] R. Domingues, P. Michiardi, J. Barlet, and M. Filippone, “A comparative
    evaluation of novelty detection algorithms for discrete sequences,” *arXiv preprint
    arXiv:1902.10940*, 2019.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] R. Domingues, P. Michiardi, J. Barlet, 和 M. Filippone, “离散序列新颖性检测算法的比较评估，”
    *arXiv预印本 arXiv:1902.10940*, 2019年。'
- en: '[16] S. Marsland, “Novelty detection in learning systems,” *Neural Comp. Surveys*,
    2003.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] S. Marsland, “学习系统中的新颖性检测，” *Neural Comp. Surveys*, 2003。'
- en: '[17] M.-R. Bouguelia, S. Nowaczyk, and A. H. Payberah, “An adaptive algorithm
    for anomaly and novelty detection in evolving data streams,” *Data mining and
    knowledge discovery*, vol. 32, no. 6, pp. 1597–1633, 2018.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] M.-R. Bouguelia, S. Nowaczyk 和 A. H. Payberah, “一种用于不断变化的数据流中的异常和新颖性检测的自适应算法，”
    *Data mining and knowledge discovery*, vol. 32, no. 6, pp. 1597–1633, 2018。'
- en: '[18] P. Oberdiek, M. Rottmann, and H. Gottschalk, “Classification uncertainty
    of deep neural networks based on gradient information,” *CoRR*, vol. abs/1805.08440,
    2018.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] P. Oberdiek, M. Rottmann 和 H. Gottschalk, “基于梯度信息的深度神经网络分类不确定性，” *CoRR*,
    vol. abs/1805.08440, 2018。'
- en: '[19] K. Lee, K. Lee, H. Lee, and J. Shin, “A simple unified framework for detecting
    out-of-distribution samples and adversarial attacks,” in *Advances in Neural Information
    Processing Systems 31*, 2018, pp. 7167–7177.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] K. Lee, K. Lee, H. Lee 和 J. Shin, “用于检测分布外样本和对抗攻击的简单统一框架，” 收录于 *Advances
    in Neural Information Processing Systems 31*, 2018, pp. 7167–7177。'
- en: '[20] Y. Bahat and G. Shakhnarovich, “Confidence from invariance to image transformations,”
    *ArXiv*, vol. abs/1804.00657, 2018.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Y. Bahat 和 G. Shakhnarovich, “基于不变性的信心评估图像变换，” *ArXiv*, vol. abs/1804.00657,
    2018。'
- en: '[21] H. Jiang, B. Kim, M. Guan, and M. Gupta, “To trust or not to trust a classifier,”
    in *Advances in Neural Information Processing Systems 31*, 2018, pp. 5541–5552.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] H. Jiang, B. Kim, M. Guan 和 M. Gupta, “信任分类器还是不信任分类器，” 收录于 *Advances in
    Neural Information Processing Systems 31*, 2018, pp. 5541–5552。'
- en: '[22] S. Liu, R. Garrepalli, T. G. Dietterich, A. Fern, and D. Hendrycks, “Open
    category detection with PAC guarantees,” *CoRR*, vol. abs/1808.00529, 2018.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] S. Liu, R. Garrepalli, T. G. Dietterich, A. Fern 和 D. Hendrycks, “具有PAC保证的开放类别检测，”
    *CoRR*, vol. abs/1808.00529, 2018。'
- en: '[23] J. Ren, P. J. Liu, E. Fertig, J. Snoek, R. Poplin, M. A. DePristo, J. V.
    Dillon, and B. Lakshminarayanan, “Likelihood ratios for out-of-distribution detection,”
    *ArXiv*, vol. abs/1906.02845, 2019.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] J. Ren, P. J. Liu, E. Fertig, J. Snoek, R. Poplin, M. A. DePristo, J.
    V. Dillon 和 B. Lakshminarayanan, “分布外检测的似然比，” *ArXiv*, vol. abs/1906.02845, 2019。'
- en: '[24] Q. Yu and K. Aizawa, “Unsupervised out-of-distribution detection by maximum
    classifier discrepancy,” in *Proceedings of the IEEE International Conference
    on Computer Vision*, 2019, pp. 9518–9526.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Q. Yu 和 K. Aizawa, “通过最大分类器差异进行无监督的分布外检测，” 收录于 *Proceedings of the IEEE
    International Conference on Computer Vision*, 2019, pp. 9518–9526。'
- en: '[25] D. Hendrycks and K. Gimpel, “A baseline for detecting misclassified and
    out-of-distribution examples in neural networks,” *CoRR*, vol. abs/1610.02136,
    2016.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] D. Hendrycks 和 K. Gimpel, “用于检测神经网络中的误分类和分布外示例的基线，” *CoRR*, vol. abs/1610.02136,
    2016。'
- en: '[26] S. Liang, Y. Li, and R. Srikant, “Enhancing the reliability of out-of-distribution
    image detection in neural networks,” in *International Conference on Learning
    Representations*, 2018.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] S. Liang, Y. Li 和 R. Srikant, “提高神经网络中分布外图像检测的可靠性，” 收录于 *International
    Conference on Learning Representations*, 2018。'
- en: '[27] W. Lawson, E. Bekele, and K. Sullivan, “Finding anomalies with generative
    adversarial networks for a patrolbot,” in *2017 IEEE Conference on Computer Vision
    and Pattern Recognition Workshops (CVPRW)*, July 2017, pp. 484–485.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] W. Lawson, E. Bekele 和 K. Sullivan, “利用生成对抗网络寻找巡逻机器人中的异常，” 收录于 *2017 IEEE
    Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)*, 2017年7月,
    pp. 484–485。'
- en: '[28] X. W. Wenhu Chen, Yilin Shen and W. Wang, “Enhancing the robustness of
    prior network in out-of-distribution detection,” *CoRR*, vol. abs/1811.07308,
    2018.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] X. W. Wenhu Chen, Yilin Shen 和 W. Wang, “在分布外检测中增强先验网络的鲁棒性，” *CoRR*, vol.
    abs/1811.07308, 2018。'
- en: '[29] I. Golan and R. El-Yaniv, “Deep anomaly detection using geometric transformations,”
    in *Advances in Neural Information Processing Systems*, 2018, pp. 9758–9769.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] I. Golan 和 R. El-Yaniv, “利用几何变换进行深度异常检测，” 收录于 *Advances in Neural Information
    Processing Systems*, 2018, pp. 9758–9769。'
- en: '[30] T. Denouden, R. Salay, K. Czarnecki, V. Abdelzad, B. Phan, and S. Vernekar,
    “Improving reconstruction autoencoder out-of-distribution detection with mahalanobis
    distance,” *ArXiv*, vol. abs/1812.02765, 2018.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] T. Denouden, R. Salay, K. Czarnecki, V. Abdelzad, B. Phan 和 S. Vernekar,
    “通过马氏距离改进重建自编码器的分布外检测，” *ArXiv*, vol. abs/1812.02765, 2018。'
- en: '[31] P. Schulam and S. Saria, “Can you trust this prediction? auditing pointwise
    reliability after learning,” in *Proceedings of Machine Learning Research*, ser.
    Proceedings of Machine Learning Research, vol. 89.   PMLR, 16–18 Apr 2019, pp.
    1022–1031.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] P. Schulam 和 S. Saria, “你能信任这个预测吗？学习后的点对点可靠性审核，” 收录于 *Proceedings of Machine
    Learning Research*, ser. Proceedings of Machine Learning Research, vol. 89. PMLR,
    2019年4月16-18日, pp. 1022–1031。'
- en: '[32] G. Cohen, S. Afshar, J. Tapson, and A. van Schaik, “Emnist: an extension
    of mnist to handwritten letters,” *arXiv preprint arXiv:1702.05373*, 2017.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] G. Cohen、S. Afshar、J. Tapson 和 A. van Schaik，“EMNIST：MNIST 到手写字母的扩展”，*arXiv
    预印本 arXiv:1702.05373*，2017年。'
- en: '[33] A. Krizhevsky *et al.*, “Learning multiple layers of features from tiny
    images,” Citeseer, Tech. Rep., 2009.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] A. Krizhevsky *等*，“从微小图像中学习多个特征层”，Citeseer，技术报告，2009年。'
- en: '[34] A. Coates, A. Ng, and H. Lee, “An analysis of single-layer networks in
    unsupervised feature learning,” in *Proceedings of the fourteenth international
    conference on artificial intelligence and statistics*, 2011, pp. 215–223.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] A. Coates、A. Ng 和 H. Lee，“对单层网络在无监督特征学习中的分析”，见于*第十四届人工智能与统计国际会议论文集*，2011年，第215–223页。'
- en: '[35] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng, “Reading
    digits in natural images with unsupervised feature learning,” 2011.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Y. Netzer、T. Wang、A. Coates、A. Bissacco、B. Wu 和 A. Y. Ng，“在自然图像中阅读数字的无监督特征学习”，2011年。'
- en: '[36] S. Zagoruyko and N. Komodakis, “Wide residual networks,” *arXiv preprint
    arXiv:1605.07146*, 2016.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] S. Zagoruyko 和 N. Komodakis，“宽残差网络”，*arXiv 预印本 arXiv:1605.07146*，2016年。'
- en: '[37] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, “Densely connected
    convolutional networks,” in *Proceedings of the IEEE conference on computer vision
    and pattern recognition*, 2017, pp. 4700–4708.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] G. Huang、Z. Liu、L. Van Der Maaten 和 K. Q. Weinberger，“密集连接卷积网络”，见于*IEEE
    计算机视觉与模式识别会议论文集*，2017年，第4700–4708页。'
- en: '[38] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, and Y. Bengio, “Generative adversarial nets,” in *Advances in neural
    information processing systems*, 2014, pp. 2672–2680.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] I. Goodfellow、J. Pouget-Abadie、M. Mirza、B. Xu、D. Warde-Farley、S. Ozair、A.
    Courville 和 Y. Bengio，“生成对抗网络”，见于*神经信息处理系统进展*，2014年，第2672–2680页。'
- en: '[39] J. Elson, J. J. Douceur, J. Howell, and J. Saul, “Asirra: a captcha that
    exploits interest-aligned manual image categorization,” 2007.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] J. Elson、J. J. Douceur、J. Howell 和 J. Saul，“ASIRRA：一种利用兴趣对齐的手动图像分类的验证码”，2007年。'
- en: '[40] Y. LeCun and C. Cortes, “MNIST handwritten digit database,” 2010.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Y. LeCun 和 C. Cortes，“MNIST 手写数字数据库”，2010年。'
- en: '[41] J. M. Hernández-Lobato and R. Adams, “Probabilistic backpropagation for
    scalable learning of bayesian neural networks,” in *International Conference on
    Machine Learning*, 2015, pp. 1861–1869.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] J. M. Hernández-Lobato 和 R. Adams，“用于可扩展学习贝叶斯神经网络的概率反向传播”，见于*国际机器学习会议*，2015年，第1861–1869页。'
- en: '[42] A. Shilton, S. Rajasegarar, and M. Palaniswami, “Combined multiclass classification
    and anomaly detection for large-scale wireless sensor networks,” in *2013 IEEE
    Eighth International Conference on Intelligent Sensors, Sensor Networks and Information
    Processing*, April 2013, pp. 491–496.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] A. Shilton、S. Rajasegarar 和 M. Palaniswami，“大规模无线传感器网络的多类别分类与异常检测相结合”，见于*2013
    IEEE 第八届智能传感器、传感器网络与信息处理国际会议*，2013年4月，第491–496页。'
- en: '[43] N. Ruchansky, S. Seo, and Y. Liu, “Csi: A hybrid deep model for fake news
    detection,” in *Proceedings of the 2017 ACM on Conference on Information and Knowledge
    Management*.   ACM, 2017, pp. 797–806.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] N. Ruchansky、S. Seo 和 Y. Liu，“CSI：一种用于虚假新闻检测的混合深度模型”，见于*2017年ACM信息与知识管理会议论文集*，ACM，2017年，第797–806页。'
- en: '[44] P. Filonov, F. Kitashov, and A. Lavrentyev, “Rnn-based early cyber-attack
    detection for the tennessee eastman process,” *arXiv preprint arXiv:1709.02232*,
    2017.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] P. Filonov、F. Kitashov 和 A. Lavrentyev，“基于 RNN 的早期网络攻击检测用于田纳西东曼过程”，*arXiv
    预印本 arXiv:1709.02232*，2017年。'
- en: '[45] E. Techapanurak and T. Okatani, “Hyperparameter-free out-of-distribution
    detection using softmax of scaled cosine similarity,” *CoRR*, vol. abs/1905.10628,
    2019.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] E. Techapanurak 和 T. Okatani，“使用缩放余弦相似度的 Softmax 进行无超参数分布外检测”，*CoRR*，卷
    abs/1905.10628，2019年。'
- en: '[46] W. Wang, M. Zhao, and J. Wang, “Effective android malware detection with
    a hybrid model based on deep autoencoder and convolutional neural network,” *Journal
    of Ambient Intelligence and Humanized Computing*, vol. 10, no. 8, pp. 3035–3043,
    2019.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] W. Wang、M. Zhao 和 J. Wang，“基于深度自编码器和卷积神经网络的混合模型的有效安卓恶意软件检测”，*环境智能与人性化计算杂志*，第10卷，第8期，第3035–3043页，2019年。'
- en: '[47] K. Lee, H. Lee, K. Lee, and J. Shin, “Training confidence-calibrated classifiers
    for detecting out-of-distribution samples,” in *International Conference on Learning
    Representations*, 2018.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] K. Lee、H. Lee、K. Lee 和 J. Shin，“训练置信度校准分类器以检测分布外样本”，见于*国际学习表示会议*，2018年。'
- en: '[48] A. Vyas, N. Jammalamadaka, X. Zhu, D. Das, B. Kaul, and T. L. Willke,
    “Out-of-distribution detection using an ensemble of self supervised leave-out
    classifiers,” *CoRR*, vol. abs/1809.03576, 2018.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] A. Vyas, N. Jammalamadaka, X. Zhu, D. Das, B. Kaul, 和 T. L. Willke, “使用自监督留出分类器集进行分布外检测”，*CoRR*，卷abs/1809.03576，2018年。'
- en: '[49] D. Hendrycks, M. Mazeika, and T. G. Dietterich, “Deep anomaly detection
    with outlier exposure,” *CoRR*, vol. abs/1812.04606, 2018.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] D. Hendrycks, M. Mazeika, 和 T. G. Dietterich, “通过异常值暴露进行深度异常检测”，*CoRR*，卷abs/1812.04606，2018年。'
- en: '[50] H. Choi, E. Jang, and A. A. Alemi, “Waic, but why? generative ensembles
    for robust anomaly detection,” *arXiv preprint arXiv:1810.01392*, 2018.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] H. Choi, E. Jang, 和 A. A. Alemi, “Waic，但为什么？用于鲁棒异常检测的生成集成”，*arXiv预印本 arXiv:1810.01392*，2018年。'
- en: '[51] J. Song, Y. Song, and S. Ermon, “Unsupervised out-of-distribution detection
    with batch normalization,” *arXiv preprint arXiv:1910.09115*, 2019.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] J. Song, Y. Song, 和 S. Ermon, “通过批量归一化进行无监督的分布外检测”，*arXiv预印本 arXiv:1910.09115*，2019年。'
- en: '[52] J. Snoek, Y. Ovadia, E. Fertig, B. Lakshminarayanan, S. Nowozin, D. Sculley,
    J. Dillon, J. Ren, and Z. Nado, “Can you trust your model’s uncertainty? evaluating
    predictive uncertainty under dataset shift,” in *Advances in Neural Information
    Processing Systems*, 2019, pp. 13 969–13 980.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] J. Snoek, Y. Ovadia, E. Fertig, B. Lakshminarayanan, S. Nowozin, D. Sculley,
    J. Dillon, J. Ren, 和 Z. Nado, “你能信任模型的不确定性吗？在数据集转移下评估预测不确定性”，发表于*神经信息处理系统进展*，2019年，第13,969–13,980页。'
- en: '[53] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow,
    and R. Fergus, “Intriguing properties of neural networks,” *arXiv preprint arXiv:1312.6199*,
    2013.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow,
    和 R. Fergus, “神经网络的有趣属性”，*arXiv预印本 arXiv:1312.6199*，2013年。'
- en: '[54] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing
    adversarial examples,” *arXiv preprint arXiv:1412.6572*, 2014.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] I. J. Goodfellow, J. Shlens, 和 C. Szegedy, “解释和利用对抗样本”，*arXiv预印本 arXiv:1412.6572*，2014年。'
- en: '[55] J. H. Metzen, T. Genewein, V. Fischer, and B. Bischoff, “On detecting
    adversarial perturbations,” *arXiv preprint arXiv:1702.04267*, 2017.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] J. H. Metzen, T. Genewein, V. Fischer, 和 B. Bischoff, “检测对抗扰动”，*arXiv预印本
    arXiv:1702.04267*，2017年。'
- en: '[56] R. Feinman, R. R. Curtin, S. Shintre, and A. B. Gardner, “Detecting adversarial
    samples from artifacts,” *ArXiv*, vol. abs/1703.00410, 2017.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] R. Feinman, R. R. Curtin, S. Shintre, 和 A. B. Gardner, “从伪影中检测对抗样本”，*ArXiv*，卷abs/1703.00410，2017年。'
- en: '[57] F. Carrara, R. Becarelli, R. Caldelli, F. Falchi, and G. Amato, “Adversarial
    examples detection in features distance spaces,” in *Proceedings of the European
    Conference on Computer Vision (ECCV)*, 2018.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] F. Carrara, R. Becarelli, R. Caldelli, F. Falchi, 和 G. Amato, “特征距离空间中的对抗样本检测”，发表于*欧洲计算机视觉会议（ECCV）论文集*，2018年。'
- en: '[58] X. Ma, B. Li, Y. Wang, S. M. Erfani, S. Wijewickrema, G. Schoenebeck,
    D. Song, M. E. Houle, and J. Bailey, “Characterizing adversarial subspaces using
    local intrinsic dimensionality,” *arXiv preprint arXiv:1801.02613*, 2018.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] X. Ma, B. Li, Y. Wang, S. M. Erfani, S. Wijewickrema, G. Schoenebeck,
    D. Song, M. E. Houle, 和 J. Bailey, “使用局部内在维度表征对抗子空间”，*arXiv预印本 arXiv:1801.02613*，2018年。'
- en: '[59] J. Aigrain and M. Detyniecki, “Detecting adversarial examples and other
    misclassifications in neural networks by introspection,” *CoRR*, vol. abs/1905.09186,
    2019.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] J. Aigrain 和 M. Detyniecki, “通过自我反思检测神经网络中的对抗样本和其他误分类”，*CoRR*，卷abs/1905.09186，2019年。'
- en: '[60] Y. Song, T. Kim, S. Nowozin, S. Ermon, and N. Kushman, “Pixeldefend: Leveraging
    generative models to understand and defend against adversarial examples,” *CoRR*,
    vol. abs/1710.10766, 2017.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Y. Song, T. Kim, S. Nowozin, S. Ermon, 和 N. Kushman, “Pixeldefend：利用生成模型理解和防御对抗样本”，*CoRR*，卷abs/1710.10766，2017年。'
- en: '[61] D. Miller, Y. Wang, and G. Kesidis, “When not to classify: Anomaly detection
    of attacks (ADA) on DNN classifiers at test time,” *Neural Computation*, 12 2017.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] D. Miller, Y. Wang, 和 G. Kesidis, “何时不分类：测试时对DNN分类器进行攻击的异常检测（ADA）”，*神经计算*，2017年12月。'
- en: '[62] F. Carrara, F. Falchi, R. Caldelli, G. Amato, R. Fumarola, and R. Becarelli,
    “Detecting adversarial example attacks to deep neural networks,” in *Proceedings
    of the 15th International Workshop on Content-Based Multimedia Indexing*.   ACM,
    2017, p. 38.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] F. Carrara, F. Falchi, R. Caldelli, G. Amato, R. Fumarola, 和 R. Becarelli,
    “检测深度神经网络的对抗样本攻击”，发表于*第15届基于内容的多媒体索引国际研讨会论文集*，ACM，2017年，第38页。'
- en: '[63] Z. Zheng and P. Hong, “Robust detection of adversarial attacks by modeling
    the intrinsic properties of deep neural networks,” in *Advances in Neural Information
    Processing Systems 31*, 2018, pp. 7913–7922.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] Z. Zheng 和 P. Hong, “通过建模深度神经网络的内在属性来鲁棒地检测对抗攻击”，发表于*神经信息处理系统进展 31*，2018年，第7913–7922页。'
- en: '[64] S. Ma, Y. Liu, G. Tao, W.-C. Lee, and X. Zhang, “Nic: Detecting adversarial
    samples with neural network invariant checking,” in *NDSS*, 2019.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] S. Ma, Y. Liu, G. Tao, W.-C. Lee, 和 X. Zhang, “Nic：通过神经网络不变量检查检测对抗样本，”
    见于 *NDSS*, 2019。'
- en: '[65] F. Sheikholeslami, S. Jain, and G. B. Giannakis, “Minimum uncertainty
    based detection of adversaries in deep neural networks,” *ArXiv*, vol. abs/1904.02841,
    2019.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] F. Sheikholeslami, S. Jain, 和 G. B. Giannakis, “基于最小不确定性的深度神经网络对抗者检测，”
    *ArXiv*, vol. abs/1904.02841, 2019。'
- en: '[66] A. Dubey, L. v. d. Maaten, Z. Yalniz, Y. Li, and D. Mahajan, “Defense
    against adversarial images using web-scale nearest-neighbor search,” in *Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition*, 2019, pp.
    8767–8776.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] A. Dubey, L. v. d. Maaten, Z. Yalniz, Y. Li, 和 D. Mahajan, “利用网络规模最近邻搜索对抗图像的防御，”
    见于 *IEEE计算机视觉与模式识别会议论文集*, 2019, 第 8767–8776 页。'
- en: '[67] R. Anirudh, J. J. Thiagarajan, B. Kailkhura, and T. Bremer, “Mimicgan:
    Robust projection onto image manifolds with corruption mimicking,” *arXiv preprint
    arXiv:1912.07748*, 2019.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] R. Anirudh, J. J. Thiagarajan, B. Kailkhura, 和 T. Bremer, “Mimicgan：通过腐蚀模拟进行图像流形的鲁棒投影，”
    *arXiv 预印本 arXiv:1912.07748*, 2019。'
- en: '[68] K. Grosse, P. Manoharan, N. Papernot, M. Backes, and P. McDaniel, “On
    the (statistical) detection of adversarial examples,” *arXiv preprint arXiv:1702.06280*,
    2017.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] K. Grosse, P. Manoharan, N. Papernot, M. Backes, 和 P. McDaniel, “关于（统计）对抗样本的检测，”
    *arXiv 预印本 arXiv:1702.06280*, 2017。'
- en: '[69] L. Smith and Y. Gal, “Understanding measures of uncertainty for adversarial
    example detection,” *arXiv preprint arXiv:1803.08533*, 2018.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] L. Smith 和 Y. Gal, “理解对抗样本检测的不确定性度量，” *arXiv 预印本 arXiv:1803.08533*, 2018。'
- en: '[70] W. Xu, D. Evans, and Y. Qi, “Feature squeezing: Detecting adversarial
    examples in deep neural networks,” *CoRR*, vol. abs/1704.01155, 2017.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] W. Xu, D. Evans, 和 Y. Qi, “特征挤压：在深度神经网络中检测对抗样本，” *CoRR*, vol. abs/1704.01155,
    2017。'
- en: '[71] J. Lu, T. Issaranon, and D. A. Forsyth, “Safetynet: Detecting and rejecting
    adversarial examples robustly,” *2017 IEEE International Conference on Computer
    Vision (ICCV)*, pp. 446–454, 2017.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] J. Lu, T. Issaranon, 和 D. A. Forsyth, “Safetynet：鲁棒地检测和拒绝对抗样本，” *2017年IEEE计算机视觉国际会议（ICCV）*，第
    446–454 页，2017。'
- en: '[72] Y. Li, J. Bradshaw, and Y. Sharma, “Are generative classifiers more robust
    to adversarial attacks?” *arXiv preprint arXiv:1802.06552*, 2018.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] Y. Li, J. Bradshaw, 和 Y. Sharma, “生成分类器是否对对抗攻击更具鲁棒性？” *arXiv 预印本 arXiv:1802.06552*,
    2018。'
- en: '[73] N. A. Ahuja, I. Ndiour, T. Kalyanpur, and O. Tickoo, “Probabilistic modeling
    of deep features for out-of-distribution and adversarial detection,” *arXiv preprint
    arXiv:1909.11786*, 2019.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] N. A. Ahuja, I. Ndiour, T. Kalyanpur, 和 O. Tickoo, “深度特征的概率建模用于分布外和对抗检测，”
    *arXiv 预印本 arXiv:1909.11786*, 2019。'
- en: '[74] G. Cohen, G. Sapiro, and R. Giryes, “Detecting adversarial samples using
    influence functions and nearest neighbors,” *arXiv preprint arXiv:1909.06872*,
    2019.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] G. Cohen, G. Sapiro, 和 R. Giryes, “使用影响函数和最近邻检测对抗样本，” *arXiv 预印本 arXiv:1909.06872*,
    2019。'
- en: '[75] C. Sitawarin and D. Wagner, “Defending against adversarial examples with
    k-nearest neighbor,” *arXiv preprint arXiv:1906.09525*, 2019.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] C. Sitawarin 和 D. Wagner, “使用 k-最近邻防御对抗样本，” *arXiv 预印本 arXiv:1906.09525*,
    2019。'
- en: '[76] J. Monteiro, I. Albuquerque, Z. Akhtar, and T. H. Falk, “Generalizable
    adversarial examples detection based on bi-model decision mismatch,” in *2019
    IEEE International Conference on Systems, Man and Cybernetics (SMC)*.   IEEE,
    2019, pp. 2839–2844.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] J. Monteiro, I. Albuquerque, Z. Akhtar, 和 T. H. Falk, “基于双模态决策不匹配的可泛化对抗样本检测，”
    见于 *2019 IEEE 系统、人类和控制论国际会议（SMC）*。IEEE，2019，第 2839–2844 页。'
- en: '[77] S. Freitas, S.-T. Chen, Z. Wang, and D. H. Chau, “Unmask: Adversarial
    detection and defense through robust feature alignment,” *arXiv preprint arXiv:2002.09576*,
    2020.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] S. Freitas, S.-T. Chen, Z. Wang, 和 D. H. Chau, “Unmask：通过鲁棒特征对齐进行对抗检测和防御，”
    *arXiv 预印本 arXiv:2002.09576*, 2020。'
- en: '[78] Q. Wang, W. Guo, K. Zhang, X. Xing, C. L. Giles, and X. Liu, “Random feature
    nullification for adversary resistant deep architecture,” *CoRR*, vol. abs/1610.01239,
    2016.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] Q. Wang, W. Guo, K. Zhang, X. Xing, C. L. Giles, 和 X. Liu, “用于对抗性抗深度架构的随机特征置空，”
    *CoRR*, vol. abs/1610.01239, 2016。'
- en: '[79] S. Pertigkiozoglou and P. Maragos, “Detecting adversarial examples in
    convolutional neural networks,” *CoRR*, vol. abs/1812.03303, 2018.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] S. Pertigkiozoglou 和 P. Maragos, “在卷积神经网络中检测对抗样本，” *CoRR*, vol. abs/1812.03303,
    2018。'
- en: '[80] D. Li, R. Baral, T. Li, H. Wang, Q. Li, and S. Xu, “Hashtran-dnn: A framework
    for enhancing robustness of deep neural networks against adversarial malware samples,”
    *CoRR*, vol. abs/1809.06498, 2018.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] D. Li, R. Baral, T. Li, H. Wang, Q. Li, 和 S. Xu, “Hashtran-dnn：增强深度神经网络对抗恶意软件样本的鲁棒性的框架，”
    *CoRR*, vol. abs/1809.06498, 2018。'
- en: '[81] J. Ryan, M.-J. Lin, and R. Miikkulainen, “Intrusion detection with neural
    networks,” in *Proceedings of the 1997 Conference on Advances in Neural Information
    Processing Systems 10*, ser. NIPS ’97, 1998, pp. 943–949.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] J. Ryan, M.-J. Lin 和 R. Miikkulainen，“利用神经网络进行入侵检测，” 收录于 *第 10 届神经信息处理系统会议论文集*，系列
    NIPS ’97，1998 年，页码 943–949。'
- en: '[82] N. Gao, L. Gao, Q. Gao, and H. Wang, “An intrusion detection model based
    on deep belief networks,” in *2014 Second International Conference on Advanced
    Cloud and Big Data*, Nov 2014, pp. 247–252.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] N. Gao, L. Gao, Q. Gao 和 H. Wang，“基于深度置信网络的入侵检测模型，” 收录于 *2014 第二届国际先进云计算与大数据会议*，2014
    年 11 月，页码 247–252。'
- en: '[83] Y. Yu, J. Long, and Z. Cai, “Network intrusion detection through stacking
    dilated convolutional autoencoders,” *Security and Communication Networks*, vol.
    2017, 2017.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] Y. Yu, J. Long 和 Z. Cai，“通过堆叠膨胀卷积自编码器进行网络入侵检测，” *安全与通信网络*，第 2017 卷，2017
    年。'
- en: '[84] R. C. Aygun and A. G. Yavuz, “Network anomaly detection with stochastically
    improved autoencoder based models,” in *2017 IEEE 4th International Conference
    on Cyber Security and Cloud Computing (CSCloud)*, June 2017, pp. 193–198.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] R. C. Aygun 和 A. G. Yavuz，“使用随机改进自编码器模型的网络异常检测，” 收录于 *2017 IEEE 第四届国际网络安全与云计算会议
    (CSCloud)*，2017 年 6 月，页码 193–198。'
- en: '[85] Z. Wang, “Deep learning-based intrusion detection with adversaries,” *IEEE
    Access*, vol. 6, 2018.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] Z. Wang，“基于深度学习的入侵检测与对抗者，” *IEEE Access*，第 6 卷，2018 年。'
- en: '[86] K. Yang, J. Liu, C. Zhang, and Y. Fang, “Adversarial examples against
    the deep learning based network intrusion detection systems,” in *MILCOM 2018-2018
    IEEE Military Communications Conference (MILCOM)*.   IEEE, 2018, pp. 559–564.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] K. Yang, J. Liu, C. Zhang 和 Y. Fang，“针对基于深度学习的网络入侵检测系统的对抗性样本，” 收录于 *MILCOM
    2018-2018 IEEE 军事通信会议 (MILCOM)*。   IEEE，2018 年，页码 559–564。'
- en: '[87] O. Ibitoye, O. Shafiq, and A. Matrawy, “Analyzing adversarial attacks
    against deep learning for intrusion detection in iot networks,” *arXiv preprint
    arXiv:1905.05137*, 2019.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] O. Ibitoye, O. Shafiq 和 A. Matrawy，“分析针对物联网网络入侵检测的深度学习对抗性攻击，” *arXiv 预印本
    arXiv:1905.05137*，2019 年。'
- en: '[88] J. Jurgovsky, M. Granitzer, K. Ziegler, S. Calabretto, P.-E. Portier,
    L. He-Guelton, and O. Caelen, “Sequence classification for credit-card fraud detection,”
    *Expert Syst. Appl.*, vol. 100, pp. 234–245, 2018.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] J. Jurgovsky, M. Granitzer, K. Ziegler, S. Calabretto, P.-E. Portier,
    L. He-Guelton 和 O. Caelen，“用于信用卡欺诈检测的序列分类，” *专家系统应用*，第 100 卷，页码 234–245，2018 年。'
- en: '[89] Z. Zhang, X. Zhou, X. Zhang, L. Wang, and P. Wang, “A model based on convolutional
    neural network for online transaction fraud detection,” *Security and Communication
    Networks*, vol. 2018, pp. 5 680 264:1–5 680 264:9, 2018.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] Z. Zhang, X. Zhou, X. Zhang, L. Wang 和 P. Wang，“基于卷积神经网络的在线交易欺诈检测模型，”
    *安全与通信网络*，第 2018 卷，页码 5,680,264:1–5,680,264:9，2018 年。'
- en: '[90] Q. Guo, Z. Li, B. An, P. Hui, J. Huang, L. Zhang, and M. Zhao, “Securing
    the deep fraud detector in large-scale e-commerce platform via adversarial machine
    learning approach,” in *The World Wide Web Conference*.   ACM, 2019, pp. 616–626.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] Q. Guo, Z. Li, B. An, P. Hui, J. Huang, L. Zhang 和 M. Zhao，“通过对抗性机器学习方法保障大规模电子商务平台中的深度欺诈检测器，”
    收录于 *世界万维网会议*。   ACM，2019 年，页码 616–626。'
- en: '[91] A. Esteva, A. Robicquet, B. Ramsundar, V. Kuleshov, M. DePristo, K. Chou,
    C. Cui, G. Corrado, S. Thrun, and J. Dean, “A guide to deep learning in healthcare,”
    *Nature medicine*, vol. 25, no. 1, pp. 24–29, 2019.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] A. Esteva, A. Robicquet, B. Ramsundar, V. Kuleshov, M. DePristo, K. Chou,
    C. Cui, G. Corrado, S. Thrun 和 J. Dean，“医疗保健中的深度学习指南，” *自然医学*，第 25 卷，第 1 期，页码
    24–29，2019 年。'
- en: '[92] W. Nash, T. Drummond, and N. Birbilis, “A review of deep learning in the
    study of materials degradation,” *npj Materials Degradation*, vol. 2, no. 1, pp.
    1–12, 2018.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] W. Nash, T. Drummond 和 N. Birbilis， “关于深度学习在材料退化研究中的综述，” *npj材料退化*，第 2
    卷，第 1 期，页码 1–12，2018 年。'
- en: '[93] S. G. Finlayson, H. W. Chung, I. S. Kohane, and A. L. Beam, “Adversarial
    attacks against medical deep learning systems,” *arXiv preprint arXiv:1804.05296*,
    2018.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] S. G. Finlayson, H. W. Chung, I. S. Kohane 和 A. L. Beam，“对医疗深度学习系统的对抗性攻击，”
    *arXiv 预印本 arXiv:1804.05296*，2018 年。'
- en: '[94] H. Rathore, S. Agarwal, S. K. Sahay, and M. Sewak, “Malware detection
    using machine learning and deep learning,” in *International Conference on Big
    Data Analytics*.   Springer, 2018, pp. 402–411.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] H. Rathore, S. Agarwal, S. K. Sahay 和 M. Sewak，“利用机器学习和深度学习进行恶意软件检测，”
    收录于 *国际大数据分析会议*。   Springer，2018 年，页码 402–411。'
- en: '[95] W. Hardy, L. Chen, S. Hou, Y. Ye, and X. Li, “Dl4md: A deep learning framework
    for intelligent malware detection,” in *Proceedings of the International Conference
    on Data Mining (DMIN)*.   The Steering Committee of The World Congress in Computer
    Science, Computer, 2016, p. 61.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] W. Hardy, L. Chen, S. Hou, Y. Ye, 和 X. Li，“Dl4md: 用于智能恶意软件检测的深度学习框架，”
    见 *Proceedings of the International Conference on Data Mining (DMIN)*。 The Steering
    Committee of The World Congress in Computer Science, Computer, 2016年，第61页。'
- en: '[96] J.-Y. Kim, S.-J. Bu, and S.-H. Cho, “Zero-day malware detection using
    transferred generative adversarial networks based on deep autoencoders,” *Inf.
    Sci.*, vol. 460-461, pp. 83–102, 2018.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] J.-Y. Kim, S.-J. Bu, 和 S.-H. Cho，“基于深度自编码器的转移生成对抗网络的零日恶意软件检测，” *Inf. Sci.*,
    第460-461卷，第83–102页，2018年。'
- en: '[97] K. Grosse, N. Papernot, P. Manoharan, M. Backes, and P. McDaniel, “Adversarial
    examples for malware detection,” in *European Symposium on Research in Computer
    Security*.   Springer, 2017, pp. 62–79.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] K. Grosse, N. Papernot, P. Manoharan, M. Backes, 和 P. McDaniel，“用于恶意软件检测的对抗样本，”
    见 *European Symposium on Research in Computer Security*。 Springer, 2017年，第62–79页。'
- en: '[98] O. Suciu, S. E. Coull, and J. Johns, “Exploring adversarial examples in
    malware detection,” in *2019 IEEE Security and Privacy Workshops (SPW)*.   IEEE,
    2019, pp. 8–14.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] O. Suciu, S. E. Coull, 和 J. Johns，“探索恶意软件检测中的对抗样本，” 见 *2019 IEEE Security
    and Privacy Workshops (SPW)*。 IEEE, 2019年，第8–14页。'
- en: '[99] T. S. Buda, B. Caglayan, and H. Assem, “Deepad: A generic framework based
    on deep learning for time series anomaly detection,” in *Advances in Knowledge
    Discovery and Data Mining*, D. Phung, V. S. Tseng, G. I. Webb, B. Ho, M. Ganji,
    and L. Rashidi, Eds., 2018, pp. 577–588.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] T. S. Buda, B. Caglayan, 和 H. Assem，“Deepad: 基于深度学习的通用框架用于时间序列异常检测，” 见
    *Advances in Knowledge Discovery and Data Mining*, D. Phung, V. S. Tseng, G. I.
    Webb, B. Ho, M. Ganji, 和 L. Rashidi, 编辑，2018年，第577–588页。'
- en: '[100] Y. Yuan, G. Xun, F. Ma, Y. Wang, N. Du, K. Jia, L. Su, and A. Zhang,
    “Muvan: A multi-view attention network for multivariate temporal data,” in *2018
    IEEE International Conference on Data Mining (ICDM)*, Nov 2018, pp. 717–726.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] Y. Yuan, G. Xun, F. Ma, Y. Wang, N. Du, K. Jia, L. Su, 和 A. Zhang，“Muvan:
    多视图注意网络用于多变量时间数据，” 见 *2018 IEEE International Conference on Data Mining (ICDM)*,
    2018年11月，第717–726页。'
- en: '[101] M. Gutoski, N. M. R. Aquino, M. Ribeiro, A. Lazzaretti, and H. S. Lopes,
    “Detection of video anomalies using convolutional autoencoders and one-class support
    vector machines,” 2017.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] M. Gutoski, N. M. R. Aquino, M. Ribeiro, A. Lazzaretti, 和 H. S. Lopes，“利用卷积自编码器和一类支持向量机检测视频异常，”
    2017年。'
- en: '[102] I. Ben-Ari and R. Shwartz-Ziv, “Attentioned convolutional LSTM inpaintingnetwork
    for anomaly detection in videos,” *CoRR*, vol. abs/1811.10228, 2018.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] I. Ben-Ari 和 R. Shwartz-Ziv，“带注意力的卷积LSTM修复网络用于视频异常检测，” *CoRR*, 第abs/1811.10228卷，2018年。'
- en: '[103] G. Tripathi, K. Singh, and D. K. Vishwakarma, “Convolutional neural networks
    for crowd behaviour analysis: a survey,” *The Visual Computer*, vol. 35, no. 5,
    pp. 753–776, May 2019.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] G. Tripathi, K. Singh, 和 D. K. Vishwakarma，“用于人群行为分析的卷积神经网络：综述，” *The
    Visual Computer*, 第35卷，第5期，第753–776页，2019年5月。'
- en: '[104] H. I. Fawaz, G. Forestier, J. Weber, L. Idoumghar, and P. Muller, “Adversarial
    attacks on deep neural networks for time series classification,” *arXiv preprint
    arXiv:1903.07054*, 2019.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] H. I. Fawaz, G. Forestier, J. Weber, L. Idoumghar, 和 P. Muller，“对深度神经网络的对抗攻击用于时间序列分类，”
    *arXiv预印本 arXiv:1903.07054*, 2019年。'
- en: '[105] F. Karim, S. Majumdar, and H. Darabi, “Adversarial attacks on time series,”
    *CoRR*, vol. abs/1902.10755, 2019\. [Online]. Available: http://arxiv.org/abs/1902.10755'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] F. Karim, S. Majumdar, 和 H. Darabi，“时间序列上的对抗攻击，” *CoRR*, 第abs/1902.10755卷，2019年。[在线]
    可用: http://arxiv.org/abs/1902.10755'
- en: '[106] I. Goodfellow, “A research agenda: Dynamic models to defend against correlated
    attacks,” *arXiv preprint arXiv:1903.06293*, 2019.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] I. Goodfellow，“研究议程：动态模型防御相关攻击，” *arXiv预印本 arXiv:1903.06293*, 2019年。'
- en: '[107] H. Zhang, K. Nian, T. F. Coleman, and Y. Li, “Spectral ranking and unsupervised
    feature selection for point, collective, and contextual anomaly detection,” *International
    Journal of Data Science and Analytics*, pp. 1–19, 2018.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] H. Zhang, K. Nian, T. F. Coleman, 和 Y. Li，“用于点、集合和上下文异常检测的光谱排序和无监督特征选择，”
    *International Journal of Data Science and Analytics*, 第1–19页，2018年。'
- en: '[108] H. Lakkaraju, E. Kamar, R. Caruana, and E. Horvitz, “Identifying unknown
    unknowns in the open world: Representations and policies for guided exploration,”
    in *Thirty-First AAAI Conference on Artificial Intelligence*, 2017.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] H. Lakkaraju, E. Kamar, R. Caruana, 和 E. Horvitz，“在开放世界中识别未知的未知：引导探索的表示和策略，”
    见 *第31届AAAI人工智能会议*, 2017年。'
- en: '[109] K. Muandet, D. Balduzzi, and B. Schölkopf, “Domain generalization via
    invariant feature representation,” in *International Conference on Machine Learning*,
    2013, pp. 10–18.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] K. Muandet, D. Balduzzi, 和 B. Schölkopf，“通过不变特征表示进行领域泛化”，在*国际机器学习大会*，2013年，第10–18页。'
- en: '[110] R. Vilalta and Y. Drissi, “A perspective view and survey of meta-learning,”
    *Artificial intelligence review*, vol. 18, no. 2, pp. 77–95, 2002.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] R. Vilalta 和 Y. Drissi，“元学习的视角和综述”，*人工智能评论*，第18卷，第2期，第77–95页，2002年。'
- en: '[111] H. Xu, Y. Ma, H. Liu, D. Deb, H. Liu, J. Tang, and A. Jain, “Adversarial
    attacks and defenses in images, graphs and text: A review,” *arXiv preprint arXiv:1909.08072*,
    2019.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] H. Xu, Y. Ma, H. Liu, D. Deb, H. Liu, J. Tang, 和 A. Jain，“图像、图形和文本中的对抗攻击与防御：综述”，*arXiv
    预印本 arXiv:1909.08072*，2019年。'
- en: '[112] N. Carlini and D. Wagner, “Adversarial examples are not easily detected:
    Bypassing ten detection methods,” in *Proceedings of the 10th ACM Workshop on
    Artificial Intelligence and Security*, 2017, pp. 3–14.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] N. Carlini 和 D. Wagner，“对抗样本不易被检测：绕过十种检测方法”，在*第十届 ACM 人工智能与安全研讨会论文集*，2017年，第3–14页。'
- en: '[113] A. Shafaei, M. Schmidt, and J. J. Little, “A less biased evaluation of
    out-of-distribution sample detectors,” *arXiv preprint arXiv:1809.04729*, 2018.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] A. Shafaei, M. Schmidt, 和 J. J. Little，“对分布外样本检测器的偏差较小的评估”，*arXiv 预印本
    arXiv:1809.04729*，2018年。'
- en: '[114] N. Carlini, A. Athalye, N. Papernot, W. Brendel, J. Rauber, D. Tsipras,
    I. Goodfellow, A. Madry, and A. Kurakin, “On evaluating adversarial robustness,”
    *arXiv preprint arXiv:1902.06705*, 2019.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] N. Carlini, A. Athalye, N. Papernot, W. Brendel, J. Rauber, D. Tsipras,
    I. Goodfellow, A. Madry, 和 A. Kurakin，“关于评估对抗性鲁棒性”，*arXiv 预印本 arXiv:1902.06705*，2019年。'
- en: '[115] A. Athalye, N. Carlini, and D. Wagner, “Obfuscated gradients give a false
    sense of security: Circumventing defenses to adversarial examples,” *arXiv preprint
    arXiv:1802.00420*, 2018.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] A. Athalye, N. Carlini, 和 D. Wagner，“混淆梯度带来虚假的安全感：绕过对抗样本的防御”，*arXiv 预印本
    arXiv:1802.00420*，2018年。'
- en: '[116] S. Vernekar, A. Gaurav, T. Denouden, B. Phan, V. Abdelzad, R. Salay,
    and K. Czarnecki, “Analysis of confident-classifiers for out-of-distribution detection,”
    *arXiv preprint arXiv:1904.12220*, 2019.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] S. Vernekar, A. Gaurav, T. Denouden, B. Phan, V. Abdelzad, R. Salay,
    和 K. Czarnecki，“对自信分类器在分布外检测中的分析”，*arXiv 预印本 arXiv:1904.12220*，2019年。'
- en: '[117] A. Shafahi, W. R. Huang, C. Studer, S. Feizi, and T. Goldstein, “Are
    adversarial examples inevitable?” *arXiv preprint arXiv:1809.02104*, 2018.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] A. Shafahi, W. R. Huang, C. Studer, S. Feizi, 和 T. Goldstein，“对抗样本是不可避免的吗？”
    *arXiv 预印本 arXiv:1809.02104*，2018年。'
- en: '[118] C. Xiao, R. Deng, B. Li, F. Yu, M. Liu, and D. Song, “Characterizing
    adversarial examples based on spatial consistency information for semantic segmentation,”
    in *Proceedings of the European Conference on Computer Vision (ECCV)*, 2018, pp.
    217–234.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] C. Xiao, R. Deng, B. Li, F. Yu, M. Liu, 和 D. Song，“基于空间一致性信息对语义分割的对抗样本特征化”，在*欧洲计算机视觉大会（ECCV）论文集*，2018年，第217–234页。'
- en: '[119] Z. Yang, B. Li, P.-Y. Chen, and D. Song, “Characterizing audio adversarial
    examples using temporal dependency,” *arXiv preprint arXiv:1809.10875*, 2018.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] Z. Yang, B. Li, P.-Y. Chen, 和 D. Song，“使用时间依赖性表征音频对抗样本”，*arXiv 预印本 arXiv:1809.10875*，2018年。'
