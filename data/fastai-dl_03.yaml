- en: 'Deep Learning 2: Part 1 Lesson 3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习2：第1部分第3课
- en: 原文：[https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56](https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56](https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56)'
- en: '*My personal notes from* [*fast.ai course*](http://www.fast.ai/)*. These notes
    will continue to be updated and improved as I continue to review the course to
    “really” understand it. Much appreciation to* [*Jeremy*](https://twitter.com/jeremyphoward)
    *and* [*Rachel*](https://twitter.com/math_rachel) *who gave me this opportunity
    to learn.*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*来自* [*fast.ai课程*](http://www.fast.ai/)*的个人笔记。随着我继续复习课程以“真正”理解它，这些笔记将继续更新和改进。非常感谢*
    [*Jeremy*](https://twitter.com/jeremyphoward) *和* [*Rachel*](https://twitter.com/math_rachel)
    *给了我这个学习机会。*'
- en: '[Lesson 3](http://forums.fast.ai/t/wiki-lesson-3/9401/1)'
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[第3课](http://forums.fast.ai/t/wiki-lesson-3/9401/1)'
- en: 'Helpful materials created by students:'
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学生们制作的有用材料：
- en: '[AWS how-to](https://github.com/reshamas/fastai_deeplearn_part1/blob/master/tools/aws_ami_gpu_setup.md)'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AWS如何操作](https://github.com/reshamas/fastai_deeplearn_part1/blob/master/tools/aws_ami_gpu_setup.md)'
- en: '[Tmux](https://github.com/reshamas/fastai_deeplearn_part1/blob/master/tools/tmux.md)'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Tmux](https://github.com/reshamas/fastai_deeplearn_part1/blob/master/tools/tmux.md)'
- en: '[Lesson 2 summary](/@apiltamang/case-study-a-world-class-image-classifier-for-dogs-and-cats-err-anything-9cf39ee4690e)'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第2课总结](/@apiltamang/case-study-a-world-class-image-classifier-for-dogs-and-cats-err-anything-9cf39ee4690e)'
- en: '[Learning rate finder](https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习率查找器](https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0)'
- en: '[PyTorch](https://towardsdatascience.com/a-practitioners-guide-to-pytorch-1d0f6a238040)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch](https://towardsdatascience.com/a-practitioners-guide-to-pytorch-1d0f6a238040)'
- en: '[Learning rate vs. Batch size](https://miguel-data-sc.github.io/2017-11-05-first/)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习率与批量大小](https://miguel-data-sc.github.io/2017-11-05-first/)'
- en: '[Smoother area of the error surface vs. generalization](/@radekosmulski/do-smoother-areas-of-the-error-surface-lead-to-better-generalization-b5f93b9edf5b)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[错误表面的平滑区域与泛化](/@radekosmulski/do-smoother-areas-of-the-error-surface-lead-to-better-generalization-b5f93b9edf5b)'
- en: '[Convolutional Neural Network in 5 minutes](/@init_27/convolutional-neural-network-in-5-minutes-8f867eb9ca39)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5分钟内的卷积神经网络](/@init_27/convolutional-neural-network-in-5-minutes-8f867eb9ca39)'
- en: '[Decoding ResNet Architecture](http://teleported.in/posts/decoding-resnet-architecture/)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解码ResNet架构](http://teleported.in/posts/decoding-resnet-architecture/)'
- en: '[Yet Another ResNet Tutorial](/@apiltamang)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[又一个ResNet教程](/@apiltamang)'
- en: 'Where we go from here:'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们接下来要做什么：
- en: 'Review [[08:24](https://youtu.be/9C06ZPF8Uuc?t=8m24s)]:'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾[[08:24](https://youtu.be/9C06ZPF8Uuc?t=8m24s)]：
- en: 'Kaggle CLI : How to download data 1:'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kaggle CLI：如何下载数据1：
- en: '[Kaggle CLI](https://github.com/floydwch/kaggle-cli) is a good tool to use
    when you are downloading from Kaggle. Because it is downloading data from Kaggle
    website (through screen scraping), it breaks when the website changes. When that
    happens, run `pip install kaggle-cli --upgrade`.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kaggle CLI](https://github.com/floydwch/kaggle-cli)是从Kaggle下载时使用的好工具。因为它是通过屏幕抓取从Kaggle网站下载数据，当网站更改时会中断。当发生这种情况时，运行`pip
    install kaggle-cli --upgrade`。'
- en: 'Then you can run:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然后您可以运行：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Replace `<username>`, `<password>` with your credential and `<competition>`
    is what follows `/c/` in the URL. For example, if you are trying to download dog
    breed data from `https://www.kaggle.com**/c/**dog-breed-identification` the command
    would look like:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 用您的凭据替换`<username>`，`<password>`，`<competition>`是URL中`/c/`后面的内容。例如，如果您想从`https://www.kaggle.com**/c/**dog-breed-identification`下载狗品种数据，命令将如下所示：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Make sure you had clicked on the `Download` button from your computer once
    and accepted the rules:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您已经从计算机上点击了`下载`按钮并接受了规则：
- en: 'CurWget (Chrome extension): How to download data 2:'
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CurWget（Chrome扩展程序）：如何下载数据2：
- en: '[](https://chrome.google.com/webstore/detail/curlwget/jmocjfidanebdlinpbcdkcmgdifblncg)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://chrome.google.com/webstore/detail/curlwget/jmocjfidanebdlinpbcdkcmgdifblncg)'
- en: Quick Dogs vs. Cats [[13:39](https://youtu.be/9C06ZPF8Uuc?t=13m39s)]
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速狗与猫[[13:39](https://youtu.be/9C06ZPF8Uuc?t=13m39s)]
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Often the notebook assumes that your data is in `data` folder. But maybe you
    want to put them somewhere else. In that case, you can use symbolic link (symlink
    for short):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 通常笔记本假设您的数据在`data`文件夹中。但也许您想把它们放在其他地方。在这种情况下，您可以使用符号链接（简称symlink）：
- en: 'Here is an end to end process to get a state of the art result for dogs vs.
    cats:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个端到端的过程，用于获得狗与猫的最新结果：
- en: Quick Dogs v Cats
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 快速狗与猫
- en: 'A little further analysis:'
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稍微进一步的分析：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`from_paths` : Indicates that subfolder names are the labels. If your `train`
    folder or `valid` folder has a different name, you can send `trn_name` and `val_name`
    argument.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_paths`：表示子文件夹名称是标签。如果您的`train`文件夹或`valid`文件夹有不同的名称，您可以发送`trn_name`和`val_name`参数。'
- en: '`test_name` : If you want to submit to Kaggle competition, you will need to
    fill in the name of the folder where the test set is.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test_name`：如果您想提交到Kaggle竞赛，您需要填写测试集所在文件夹的名称。'
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Notice that we did not set `pre_compue=True`. It is just a shortcut which caches
    some of the intermediate steps that do not have to be recalculated each time.
    If you are at all confused about it, you can just leave it off.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请注意，我们没有设置`pre_compue=True`。这只是一个快捷方式，可以缓存一些中间步骤，这些步骤不必每次重新计算。如果您对此感到困惑，可以将其留空。
- en: Remember, when `pre_compute=True` , data augmentation does not work.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请记住，当`pre_compute=True`时，数据增强不起作用。
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`bn_freeze` : If you are using a bigger deeper model like ResNet50 or ResNext101
    (anything with number bigger than 34) on a dataset that is very similar to ImageNet
    (i.e. side-on photos of standard object whose size is similar to ImageNet between
    200–500 pixels), you should add this line. We will learn more in the second half
    of the course, but it is causing the batch normalization moving averages to not
    be updated.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bn_freeze`：如果您正在使用更大更深的模型，如ResNet50或ResNext101（任何数字大于34的模型），在一个与ImageNet非常相似的数据集上（即侧面拍摄的标准物体的照片，其大小与ImageNet在200-500像素之间），您应该添加这一行。我们将在课程的后半部分学到更多，但这会导致批量归一化移动平均值不会被更新。'
- en: '[How to use other libraries — Keras](https://github.com/fastai/fastai/blob/master/courses/dl1/keras_lesson1.ipynb)
    [[20:02](https://youtu.be/9C06ZPF8Uuc?t=20m2s)]'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[如何使用其他库 — Keras](https://github.com/fastai/fastai/blob/master/courses/dl1/keras_lesson1.ipynb)
    [[20:02](https://youtu.be/9C06ZPF8Uuc?t=20m2s)]'
- en: It is important to understand how to use libraries other than Fast.ai. Keras
    is a good example to look at because just like Fast.ai sits on top of PyTorch,
    it sits on top of varieties of libraries such as TensorFlow, MXNet, CNTK, etc.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 了解如何使用Fast.ai以外的库是很重要的。Keras是一个很好的例子，因为就像Fast.ai建立在PyTorch之上一样，它也建立在各种库之上，如TensorFlow、MXNet、CNTK等。
- en: If you want to run [the notebook](https://github.com/fastai/fastai/blob/master/courses/dl1/keras_lesson1.ipynb),
    run `pip install tensorflow-gpu keras`
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想运行[笔记本](https://github.com/fastai/fastai/blob/master/courses/dl1/keras_lesson1.ipynb)，运行`pip
    install tensorflow-gpu keras`
- en: '**Define data generators**'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**定义数据生成器**'
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The idea of train folder and validation folder with subfolders with the label
    names is commonly done, and Keras also does it.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练文件夹和验证文件夹的子文件夹与标签名称的想法是常见的，Keras也这样做。
- en: Keras requires much more code and many more parameters to be set.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras需要更多的代码和更多的参数来设置。
- en: Rather than creating a single data object, in Keras you define `DataGenerator`
    and specify what kind of data augmentation we want it to do and also what kind
    of normalization to do. In other words, in Fast.ai, we can just say “whatever
    ResNet50 requires, just do that for me please” but in Keras, you need to know
    what is expected. There is no standard set of augmentations.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与创建单个数据对象不同，在Keras中，您定义`DataGenerator`并指定要进行的数据增强类型，还要指定要进行的规范化类型。换句话说，在Fast.ai中，我们可以说“ResNet50需要什么，就请为我做”，但在Keras中，您需要知道期望的是什么。没有标准的增强集。
- en: You have to then create a validation data generator in which you are responsible
    to create a generator that does not have data augmentation. And you also have
    to tell it not to shuffle the dataset for validation because otherwise you cannot
    keep track of how well you are doing.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后您必须创建一个验证数据生成器，您负责创建一个没有数据增强的生成器。您还必须告诉它不要对验证数据集进行洗牌，否则您无法跟踪您的表现如何。
- en: '**2\. Create a model**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 创建模型**'
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The reason Jeremy used ResNet50 for Quick Dogs and Cats was because Keras does
    not have ResNet34\. We want to compare apple to apple.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jeremy在Quick Dogs and Cats中使用ResNet50的原因是因为Keras没有ResNet34。我们想要进行苹果对苹果的比较。
- en: You cannot ask it to construct a model that is suitable for a particular dataset,
    so you have to do it by hand.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您不能要求它构建适合特定数据集的模型，因此您必须手动完成。
- en: First you create a base model, then you construct layers you want to add on
    top of it.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先创建一个基本模型，然后构建您想要添加到其顶部的层。
- en: '**3\. Freeze layers and compile**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 冻结层并编译**'
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Loop through layers and freeze them manually by calling `layer.trainable=False`
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过循环层并手动调用`layer.trainable=False`来冻结它们
- en: You need to compile a model
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要编译一个模型
- en: Pass the type of optimizer, loss, and metrics
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传递优化器、损失和指标的类型
- en: '**4\. Fit**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. 拟合**'
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Keras expects to know how many batches there are per epoch.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras希望知道每个epoch有多少批次。
- en: '`workers` : how many processors to use'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`workers`：要使用的处理器数量'
- en: '**5\. Fine-tune: Unfreeze some layers, compile, then fit again**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**5\. 微调：解冻一些层，编译，然后再次拟合**'
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**Pytorch** — If you want to deploy to mobile devices, PyTorch is still very
    early.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pytorch** — 如果您想要部署到移动设备，PyTorch仍处于早期阶段。'
- en: '**Tensorflow** — If you want to convert things you learned in this class, do
    more work with Keras, but it would take a bit more work and is hard to get the
    same level of results. Maybe there will be TensorFlow compatible version of Fast.ai
    in future. We will see.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**Tensorflow** — 如果您想将在本课程中学到的内容转换为更多的Keras工作，但这需要更多的工作，很难获得相同水平的结果。也许将来会有TensorFlow兼容版本的Fast.ai。我们将看到。'
- en: Create Submission file for Kaggle [[32:45](https://youtu.be/9C06ZPF8Uuc?t=32m45s)]
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为Kaggle创建提交文件[[32:45](https://youtu.be/9C06ZPF8Uuc?t=32m45s)]
- en: 'To create the submission files, we need two pieces of information:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建提交文件，我们需要两个信息：
- en: '`data.classes` : contains all the different classes'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data.classes`：包含所有不同的类'
- en: '`data.test_ds.fnames` : test file names'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data.test_ds.fnames`：测试文件名'
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: It is always good idea to use `TTA:`
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 始终使用`TTA`是一个好主意：
- en: '`is_test=True` : it will give you predictions on the test set rather than the
    validation set'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_test=True`：它将为您提供测试集的预测，而不是验证集'
- en: By default, PyTorch models will give you back the log of the predictions, so
    you need to do `np.exp(log_preds)` to get the probability.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下，PyTorch模型将返回预测的对数，因此您需要执行`np.exp(log_preds)`以获得概率。
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Create Pandas `DataFrame`
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建Pandas `DataFrame`
- en: Set the column name as `data.classes`
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将列名设置为`data.classes`
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Insert a new column at position zero named `id`. Remove first 5 and last 4 letters
    since we just need IDs (a file name looks like `test/0042d6bf3e5f3700865886db32689436.jpg`)
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在位置零插入一个名为`id`的新列。删除前5个和最后4个字母，因为我们只需要ID（文件名看起来像`test/0042d6bf3e5f3700865886db32689436.jpg`）
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now you can call `ds.to_csv` to create a CSV file and `compression='gzip'` will
    zip it up on the server.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在您可以调用`ds.to_csv`创建一个CSV文件，`compression='gzip'`将在服务器上对其进行压缩。
- en: '[PRE16]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: You can use Kaggle CLI to submit from the server directly, or you can use `FileLink`
    which will give you a link to download the file from the server to your computer.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用Kaggle CLI直接从服务器提交，或者您可以使用`FileLink`，它将为您提供一个链接，从服务器下载文件到您的计算机。
- en: Individual prediction [[39:32](https://youtu.be/9C06ZPF8Uuc?t=39m32s)]
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单个预测[[39:32](https://youtu.be/9C06ZPF8Uuc?t=39m32s)]
- en: What if we want to run a single image through a model to get a prediction?
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想通过模型运行单个图像以获得预测，会怎样？
- en: '[PRE17]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We will pick a first file from the validation set.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将从验证集中选择第一个文件。
- en: 'This is the shortest way to get a prediction:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这是获得预测的最简单方法：
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Image must be transformed. `tfms_from_model` returns training transforms and
    validation transforms. In this case, we will use validation transform.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像必须被转换。`tfms_from_model`返回训练转换和验证转换。在这种情况下，我们将使用验证转换。
- en: Everything that gets passed to or returned from a model is generally assumed
    to be in a mini-batch. Here we only have one image, but we have to turn that into
    a mini-batch of a single image. In other words, we need to create a tensor that
    is not just `[rows, columns, channels]` , but `[number of images, rows, columns,
    channels]`.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传递给模型或从模型返回的所有内容通常被假定为在一个小批次中。这里我们只有一张图片，但我们必须将其转换为一批包含一张图片的小批次。换句话说，我们需要创建一个张量，不仅是`[行，列，通道]`，而是`[图片数量，行，列，通道]`。
- en: '`im[None]` : Numpy trick to add additional unit axis to the start.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`im[None]`：Numpy技巧，将额外的单位轴添加到开头。'
- en: 'Theory: What is actually going on behind the scenes with convolutional neural
    network [[42:17](https://youtu.be/9C06ZPF8Uuc?t=42m17s)]'
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理论：卷积神经网络背后实际发生了什么[[42:17](https://youtu.be/9C06ZPF8Uuc?t=42m17s)]
- en: We saw a little bit of theory in Lesson 1 — [http://setosa.io/ev/image-kernels/](http://setosa.io/ev/image-kernels/)
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在第1课中看到了一点理论 — [http://setosa.io/ev/image-kernels/](http://setosa.io/ev/image-kernels/)
- en: Convolution is something where we have a little matrix (nearly always 3x3 in
    deep learning) and multiply every element of that matrix by every element of 3x3
    section of an image and add them all together to get the result of that convolution
    at one point.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积是一种操作，其中我们有一个小矩阵（在深度学习中几乎总是3x3），将该矩阵的每个元素与图像的3x3部分的每个元素相乘，然后将它们全部加在一起，以获得在一个点上的卷积结果。
- en: '**Otavio’s fantastic visualization (he created Word Lens):**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**Otavio的出色可视化（他创建了Word Lens）：**'
- en: '**Jeremy’s visualization:** [**Spreadsheet**](https://github.com/fastai/fastai/blob/master/courses/dl1/excel/conv-example.xlsx)
    **[**[**49:51**](https://youtu.be/9C06ZPF8Uuc?t=49m51s)**]**'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**Jeremy的可视化：** [**电子表格**](https://github.com/fastai/fastai/blob/master/courses/dl1/excel/conv-example.xlsx)
    **[**[**49:51**](https://youtu.be/9C06ZPF8Uuc?t=49m51s)**]**'
- en: I used [https://office.live.com/start/Excel.aspx](https://office.live.com/start/Excel.aspx?ui=en-US&rs=US)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用[https://office.live.com/start/Excel.aspx](https://office.live.com/start/Excel.aspx?ui=en-US&rs=US)
- en: This data is from MNIST
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些数据来自MNIST
- en: '**Activation**: A number that is calculated by applying some kind of linear
    operation to some numbers in the input.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**激活：** 通过对输入中的一些数字应用某种线性操作来计算的数字。'
- en: '**Rectified Linear Unit (ReLU)**: Throw away negative — i.e. MAX(0, x)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修正线性单元（ReLU）**：丢弃负数 — 即MAX(0, x)'
- en: '**Filter/Kernel:** A 3x3 slice of a 3D tensor you used for convolution'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**滤波器/卷积核：** 用于卷积的3D张量的3x3切片'
- en: '**Tensor:** Multidimensional array or matrix Hidden Layer A layer that is neither
    input nor output'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**张量：** 多维数组或矩阵 隐藏层 既不是输入也不是输出的层'
- en: '**Max pooling:** A (2,2) max pooling will halve the resolution in both height
    and width — think of it as a summary'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大池化：** (2,2)最大池化将在高度和宽度上减半 — 将其视为一个摘要'
- en: '**Fully connected layer:** Give a weight to each and every single activation
    and calculate the sum product. Weight matrix is as big as the entire input.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层：** 为每个激活赋予权重并计算总乘积。权重矩阵与整个输入一样大。'
- en: 'Note: There are many things you can do after the max pooling layer. One of
    them is to do another max pool across the entire size. In older architectures
    or structured data, we do fully connected layer. Architecture that make heavy
    use of fully connected layers are prone to overfitting and are slower. ResNet
    and ResNext do not use very large fully connected layers.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意：在最大池化层之后可以做许多事情。其中之一是在整个大小上再做一次最大池化。在旧的架构或结构化数据中，我们会做全连接层。大量使用全连接层的架构容易过拟合且速度较慢。ResNet和ResNext不使用非常大的全连接层。
- en: '**Question**: What happens if the input had 3 channels? [[1:05:30](https://youtu.be/9C06ZPF8Uuc?t=1h5m30s)]
    It will look something similar to the Conv1 layer which has 2 channels — therefore,
    filters have 2 channels per filter. Pre-trained ImageNet models use 3 channels.
    Some of the techniques you can use when you do when you do have less than 3 channel
    is to either duplicate one of the channels to make it 3, or if you have 2, then
    get an average and consider that as the third channel. If you have 4 channels,
    you could add extra level to the convolutional kernel with all zeros.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：如果输入有3个通道会发生什么？[[1:05:30](https://youtu.be/9C06ZPF8Uuc?t=1h5m30s)] 它将看起来类似于具有2个通道的Conv1层
    — 因此，滤波器每个滤波器有2个通道。预训练的ImageNet模型使用3个通道。当你的通道少于3个时，你可以使用一些技术，例如复制一个通道使其变为3个，或者如果你有2个通道，那么取平均值并将其视为第三个通道。如果你有4个通道，你可以向卷积核添加额外的级别，所有值都为零。'
- en: What happens next? [[1:08:47](https://youtu.be/9C06ZPF8Uuc?t=1h8m47s)]
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 接下来会发生什么？[[1:08:47](https://youtu.be/9C06ZPF8Uuc?t=1h8m47s)]
- en: We have gotten as far as fully connected layer (it does classic matrix product).
    In the excel sheet, there is one activation. If we want to look at which one of
    ten digit the input is, we actually want to calculate 10 numbers.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经走到了全连接层（它执行经典的矩阵乘积）。在Excel表中，有一个激活。如果我们想要查看输入是哪一个十位数，我们实际上想要计算10个数字。
- en: 'Let’s look at an example where we are trying to predict whether a picture is
    a cat, a dog, or a plane, or fish, or a building. Our goal is:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个例子，我们试图预测一张图片是猫、狗、飞机、鱼还是建筑物。我们的目标是：
- en: Take output from the fully connected layer (no ReLU so there may be negatives)
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从全连接层获取输出（没有ReLU，因此可能有负数）
- en: Calculate 5 numbers where each of them is between 0 and 1 and they add up to
    1.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算5个数字，每个数字都在0和1之间，它们加起来等于1。
- en: To do this, we need a different kind of activation function (a function applied
    to an activation).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要一种不同类型的激活函数（应用于激活的函数）。
- en: Why do we need non-lineality? If you stack multiple linear layers, it is still
    just a linear layer. By adding non-linear layers, we can fit arbitrarily complex
    shapes. The non-linear activation function we used was ReLU.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们需要非线性？如果堆叠多个线性层，它仍然只是一个线性层。通过添加非线性层，我们可以拟合任意复杂的形状。我们使用的非线性激活函数是ReLU。
- en: Softmax [[01:14:08](https://youtu.be/9C06ZPF8Uuc?t=1h14m8s)]
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Softmax [[01:14:08](https://youtu.be/9C06ZPF8Uuc?t=1h14m8s)]
- en: Softmax only ever occurs in the final layer. It outputs numbers between 0 and
    1, and they add up to 1\. In theory, this is not strictly necessary — we could
    ask out neural net to learn a set of kernels which give probabilities that line
    up as closely as possible with what we want. In general with deep learning, if
    you can construct your architecture so that the desired characteristics are as
    easy to express as possible, you will end up with better models (learn more quickly
    and with less parameters).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Softmax只会出现在最后一层。它输出介于0和1之间的数字，它们加起来为1。理论上，这并不是绝对必要的 - 我们可以要求我们的神经网络学习一组核，这些核给出的概率尽可能接近我们想要的。一般来说，在深度学习中，如果你可以构建你的架构，使得所需的特征尽可能容易表达，你将得到更好的模型（学习更快，参数更少）。
- en: 'Get rid of negatives by `e^x` because we cannot have negative probabilities.
    It also accentuates the value difference (2.85 : 4.08 → 17.25 : 59.03)'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过`e^x`去除负数，因为我们不能有负概率。它也突出了值的差异（2.85：4.08 → 17.25：59.03）
- en: 'All the math that you need to be familiar with to do deep learning:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 所有你需要熟悉的数学来进行深度学习：
- en: 2\. We then add up the `exp` column (182.75), and divide the `e^x` by the sum.
    The result will always be positive since we divided positive by positive. Each
    number will be between 0 and 1, and the total will be 1.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 然后我们将`exp`列（182.75）相加，然后将`e^x`除以总和。结果总是正的，因为我们将正数除以正数。每个数字将在0和1之间，总和为1。
- en: '**Question**: What kind of activation function do we use if we want to classify
    the picture as cat and dog? [[1:20:27](https://youtu.be/9C06ZPF8Uuc?t=1h20m27s)]
    It so happens that we are going to do that right now. One reason we might want
    to do that is to do multi-label classification.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：如果我们想要将图片分类为猫和狗，我们应该使用什么样的激活函数？这正好是我们现在要做的事情。我们可能想这样做的一个原因是进行多标签分类。
- en: Planet Competition [[01:20:54](https://youtu.be/9C06ZPF8Uuc?t=1h20m54s)]
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 星球竞赛[01:20:54]
- en: '[Notebook](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson2-image_models.ipynb)
    / [Kaggle page](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[笔记本](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson2-image_models.ipynb)
    / [Kaggle页面](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space)'
- en: I would definitely recommend anthropomorphizing your activation functions. They
    have personalities. [[1:22:21](https://youtu.be/9C06ZPF8Uuc?t=1h22m21s)]
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我绝对建议你拟人化你的激活函数。它们有个性。[1:22:21]
- en: Softmax does not like to predicting multiple things. It wants to pick one thing.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Softmax不喜欢预测多个事物。它想要选择一个事物。
- en: 'Fast.ai library will automatically switch into multi-label mode if there is
    more than one label. So you do not have to do anything. But here is what happens
    behind the scene:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Fast.ai库会在有多个标签时自动切换到多标签模式。所以你不需要做任何事情。但是这是幕后发生的事情：
- en: '[PRE19]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Multi-label classification cannot be done with Keras style approach where subfolder
    is the name of the label. So we use `from_csv`
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Keras风格的方法无法进行多标签分类，其中子文件夹是标签的名称。所以我们使用`from_csv`
- en: '`transform_top_down` : it does more than just a vertical flip. There are 8
    possible symmetries for a square — it can be rotated through 0, 90, 180, 270 degrees
    and for each of those, it can be flipped (**dihedral** group of eight)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transform_top_down`：它不仅仅是垂直翻转。对于一个正方形，有8种可能的对称性 - 它可以通过0、90、180、270度旋转，对于每一个，它可以被翻转（八面体群）。'
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We had seen `data.val_ds` , `test_ds`, `train_ds`(`ds`: dataset) for which
    you can get an individual image by `data.train_ds[0]`, for example.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已经看到了`data.val_ds`，`test_ds`，`train_ds`（`ds`：数据集），你可以通过`data.train_ds[0]`来获取单个图像，例如。
- en: '`dl` is a data loader which will give you a mini-batch, specifically *transformed*
    mini-batch. With a data loader, you cannot ask for a particular mini-batch; you
    can only get back the `next` mini-batch. In Python, it is called “generator” or
    “iterator”. PyTorch really leverages modern Python methodologies.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dl`是一个数据加载器，它会给你一个小批量，特别是*转换后*的小批量。使用数据加载器，你不能要求一个特定的小批量；你只能得到`next`小批量。在Python中，它被称为“生成器”或“迭代器”。PyTorch真正利用了现代Python方法。'
- en: '[If you know Python well, PyTorch comes very naturally. If you don’t know Python
    well, PyTorch is a good reason to learn Python well.](https://youtu.be/9C06ZPF8Uuc?t=1h27m45s)'
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[如果你很了解Python，PyTorch会非常自然。如果你不太了解Python，PyTorch是学习Python的一个很好的理由。](https://youtu.be/9C06ZPF8Uuc?t=1h27m45s)'
- en: '`x` : a mini-batch of images, `y` : a mini-batch of labels.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：一批图像，`y`：一批标签。'
- en: If you are never sure what arguments a function takes, hit `shift+tab` .
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不确定一个函数需要什么参数，按下`shift+tab`。
- en: '[PRE21]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Behind the scenes, PyTorch and fast.ai are turning our labels into one-hot-encoded
    labels. If the actual label is dog, it will look like:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，PyTorch和fast.ai将我们的标签转换为独热编码标签。如果实际标签是狗，它看起来像：
- en: We take the difference between `actuals` and `softmax` , add them up to say
    how much error there is (i.e. loss function) [[1:31:02](https://youtu.be/9C06ZPF8Uuc?t=1h31m2s)].
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们取`actuals`和`softmax`之间的差异，将它们相加以表示有多少错误（即损失函数）[1:31:02]。
- en: One-hot-encoding is terribly inefficient for storing, so we will store an index
    value (single integer) rather than 0’s and 1’s for the target value (`y`) [[1:31:21](https://youtu.be/9C06ZPF8Uuc?t=1h31m21s)].
    If you look at the `y` values for the dog breeds competition, you won’t actually
    see a big lists of 1’s and 0's, but you will wee a single integer. And internally,
    PyTorch is converting the index to one-hot-encoded vector (even though you will
    literally never see it). PyTorch has different loss functions for ones that are
    one hot encoded and others that are not — but these details are hidden by the
    fast.ai library so you do not have to worry about it. But the cool thing to realize
    is that we are doing exactly the same thing for both single label classification
    and multi label classification.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 独热编码对于存储来说非常低效，所以我们将存储一个索引值（单个整数）而不是目标值（`y`）的0和1。如果您查看狗品种竞赛的`y`值，您实际上不会看到一个大的1和0的列表，而是会看到一个单个整数。在内部，PyTorch将索引转换为独热编码向量（即使您永远不会看到它）。PyTorch有不同的损失函数，适用于独热编码和其他不是独热编码的情况，但这些细节被fast.ai库隐藏，因此您不必担心。但要意识到的很酷的事情是，我们对单标签分类和多标签分类都做了完全相同的事情。
- en: '**Question**: Does it make sense to change the base of log for softmax?[[01:32:55](https://youtu.be/9C06ZPF8Uuc?t=1h32m55s)]
    No, changing the base is just a linear scaling which neural net can learn easily:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：改变softmax的对数基数有意义吗？[[01:32:55](https://youtu.be/9C06ZPF8Uuc?t=1h32m55s)]
    不，改变基数只是一个线性缩放，神经网络可以轻松学习：'
- en: '[PRE22]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '`*1.4` : The image was washed out, so making it more visible (“brightening
    it up a bit”). Images are just matrices of numbers, so we can do things like this.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`*1.4`：图像被冲洗了，所以让它更明显（“稍微提亮”）。图像只是数字矩阵，所以我们可以做这样的事情。'
- en: It is good to experiment images like this because these images are not at all
    like ImageNet. The vast majority of things you do involving convolutional neural
    net will not actually be anything like ImageNet (medical imaging, classifying
    different kinds of steel tube, satellite images, etc)
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试这样的图像是很好的，因为这些图像根本不像ImageNet。你所做的绝大多数涉及卷积神经网络的事情实际上都不像ImageNet（医学成像，分类不同种类的钢管，卫星图像等）
- en: '[PRE23]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We will not use `sz=64` for cats and dogs competition because we started with
    pre-trained ImageNet network which starts off nearly perfect. If we re-trained
    the whole set with 64 by 64 images, we would destroy the weights that are already
    very good. Remember, most of ImageNet models are trained with 224 by 224 or 299
    by 299 images.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不会在猫狗竞赛中使用`sz=64`，因为我们从预训练的ImageNet网络开始，它几乎完美。如果我们用64x64的图像重新训练整个集合，我们会破坏已经非常好的权重。请记住，大多数ImageNet模型是用224x224或299x299的图像训练的。
- en: There is no images in ImageNet that looks like the one above. And only the first
    couple layers are useful to us. So starting out with smaller images works well
    in this case.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ImageNet中没有像上面那样的图像。而且只有前几层对我们有用。所以从较小的图像开始在这种情况下效果很好。
- en: '[PRE24]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '`[lr/9, lr/3, lr]` — this is because the images are unlike ImageNet image and
    earlier layers are probably not as close to what they need to be.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[lr/9, lr/3, lr]` — 这是因为这些图像不像ImageNet图像，而且较早的层可能与它们需要的不太接近。'
- en: '[PRE26]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'A couple of questions people have asked what this does [[01:38:46](https://youtu.be/9C06ZPF8Uuc?t=1h38m46s)]:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个人问了这个问题[[01:38:46](https://youtu.be/9C06ZPF8Uuc?t=1h38m46s)]：
- en: '[PRE28]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'When we specify what transforms to apply, we send a size:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们指定要应用的转换时，我们发送一个大小：
- en: '[PRE29]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: One of the things the data loader does is to resize the images on-demand. This
    has nothing to do with `data.resize` . If the initial image is 1000 by 1000, reading
    that JPEG and resizing it to 64 by 64 take more time than training the convolutional
    net. `data.resize` tells it that we will not use images bigger than `sz*1.3` so
    go through once and create new JPEGs of this size. Since images are rectangular,
    so new JPEGs whose smallest edge is `sz*1.3` (center-cropped). It will save you
    a lot of time.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 数据加载器的一项工作是按需调整图像的大小。这与`data.resize`无关。如果初始图像是1000x1000，读取该JPEG并将其调整为64x64比训练卷积网络需要更多时间。`data.resize`告诉它我们不会使用大于`sz*1.3`的图像，因此请通过一次并创建新的这个大小的JPEG。由于图像是矩形的，因此最小边为`sz*1.3`的新JPEG（中心裁剪）。这将节省您大量时间。
- en: '[PRE30]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Instead of `accuacy`, we used [F-beta](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html)
    for this notebook — it is a way of weighing false negatives and false positives.
    The reason we are using it is because this particular Kaggle competition wants
    to use it. Take a look at [planet.py](https://github.com/fastai/fastai/blob/master/courses/dl1/planet.py)
    to see how you can create your own metrics function. This is what gets printed
    out at the end `[ 0\. 0.08932 0.08218 **0.9324** ]`
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这个笔记本中使用[F-beta](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html)而不是`accuacy`，这是一种权衡假阴性和假阳性的方法。我们使用它的原因是因为这个特定的Kaggle竞赛想要使用它。查看[planet.py](https://github.com/fastai/fastai/blob/master/courses/dl1/planet.py)看看如何创建自己的指标函数。这是最后打印出来的内容`[
    0\. 0.08932 0.08218 **0.9324** ]`
- en: Activation function for multi-label classification [[01:44:25](https://youtu.be/9C06ZPF8Uuc?t=1h44m25s)]
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多标签分类的激活函数[[01:44:25](https://youtu.be/9C06ZPF8Uuc?t=1h44m25s)]
- en: Activation function for multi-label classification is called **sigmoid.**
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 多标签分类的激活函数称为**sigmoid**。
- en: '**Question**: Why don’t we start training with differential learning rate rather
    than training the last layers alone? [[01:50:30](https://youtu.be/9C06ZPF8Uuc?t=1h50m30s)]'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：为什么我们不从不同的学习率开始训练，而是只训练最后的层？[[01:50:30](https://youtu.be/9C06ZPF8Uuc?t=1h50m30s)]'
- en: You can skip training just the last layer and go straight to differential learning
    rates, but you probably do not want to. Convolutional layers all contain pre-trained
    weights, so they are not random — for things that are close to ImageNet, they
    are really good; for things that are not close to ImageNet, they are better than
    nothing. All of our fully connected layers, however, are totally random. Therefore,
    you would always want to make the fully connected weights better than random by
    training them a bit first. Otherwise if you go straight to unfreeze, then you
    are actually going to be fiddling around with those early layer weights when the
    later ones are still random — which is probably not what you want.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以跳过训练最后一层，直接进行不同的学习率，但您可能不想这样做。卷积层都包含预训练权重，因此它们不是随机的 — 对于接近ImageNet的东西，它们非常好；对于不接近ImageNet的东西，它们比没有好。然而，我们所有的全连接层都是完全随机的。因此，您始终希望通过先训练它们使全连接权重比随机更好一些。否则，如果直接解冻，那么您实际上将在后续层仍然是随机的情况下摆弄那些早期层的权重
    — 这可能不是您想要的。
- en: 'Question: When you use the differential learning rates, do those three learning
    rates spread evenly across the layers? [[01:55:35](https://youtu.be/9C06ZPF8Uuc?t=1h55m35s)]
    We will talk more about this later in the course but the fast.ai library, there
    is a concept of “layer groups”. In something like ResNet50, there are hundreds
    of layers and you probably do not want to write hundreds of learning rates, so
    the library decided for you how to split them and the last one always refers to
    just the fully connected layers that we have randomly initialized and added.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：当您使用不同的学习率时，这三个学习率是否均匀分布在各层之间？[[01:55:35](https://youtu.be/9C06ZPF8Uuc?t=1h55m35s)]我们将在课程后面更多地讨论这个问题，但是在fast.ai库中，有一个“层组”的概念。在像ResNet50这样的模型中，有数百个层，您可能不想编写数百个学习率，因此库为您决定如何分割它们，最后一个始终指的是我们随机初始化并添加的全连接层。
- en: Visualizing the layers [[01:56:42](https://youtu.be/9C06ZPF8Uuc?t=1h56m42s)]
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化层[[01:56:42](https://youtu.be/9C06ZPF8Uuc?t=1h56m42s)]
- en: '[PRE31]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '`‘input_shape’, [-1, **3, 64, 64**]` — PyTorch lists channel before the image
    size. Some of the GPU computations run faster when it is in that order. This is
    done behind scene by the transformation step.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`‘input_shape’, [-1, **3, 64, 64**]` — PyTorch在图像尺寸之前列出通道。当按照这个顺序进行GPU计算时，一些计算会更快。这是通过转换步骤在幕后完成的。'
- en: '`-1` : indicates however big the batch size is. Keras uses `None` .'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-1`：表示批量大小有多大。Keras使用`None`。'
- en: '`‘output_shape’, [-1, 64, 32, 32]` — 64 is the number of kernels'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`‘output_shape’, [-1, 64, 32, 32]` — 64是卷积核的数量'
- en: '**Question**: Learning rate finder for a very small dataset returned strange
    number and the plot was empty [[01:58:57](https://youtu.be/9C06ZPF8Uuc?t=1h58m57s)]
    — The learning rate finder will go through a mini-batch at a time. If you have
    a tiny dataset, there is just not enough mini-batches. So the trick is to make
    your batch size very small like 4 or 8.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：对于一个非常小的数据集，学习率查找器返回了奇怪的数字，绘图为空[[01:58:57](https://youtu.be/9C06ZPF8Uuc?t=1h58m57s)]
    — 学习率查找器将逐个小批量进行。如果您有一个微小的数据集，那么就没有足够的小批量。因此，诀窍是将批量大小设置得非常小，如4或8。'
- en: Structured Data [[01:59:48](https://youtu.be/9C06ZPF8Uuc?t=1h59m48s)]
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构化数据[[01:59:48](https://youtu.be/9C06ZPF8Uuc?t=1h59m48s)]
- en: 'There are two types of dataset we use in machine learning:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中我们使用两种类型的数据集：
- en: '**Unstructured** — Audio, images, natural language text where all of the things
    inside an object are all the same kind of things — pixels, amplitude of waveform,
    or words.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非结构化** — 音频、图像、自然语言文本，其中对象内的所有内容都是同一种类型的东西 — 像素、波形振幅或单词。'
- en: '**Structured** — Profit and loss statement, information about a Facebook user
    where each column is structurally quite different. “Structured” refers to columnar
    data as you might find in a database or a spreadsheet where different columns
    represent different kinds of things, and each row represents an observation.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结构化** — 损益表，关于Facebook用户的信息，其中每列在结构上都非常不同。 “结构化”指的是列式数据，就像您在数据库或电子表格中找到的那样，不同的列代表不同类型的事物，每行代表一个观察。 '
- en: 'Structured data is often ignored in academics because it is pretty hard to
    get published in fancy conference proceedings if you have a better logistics model.
    But it is the thing that makes the world goes round, makes everybody money and
    efficiency. We will not ignore it because we are doing practical deep learning,
    and Kaggle does not either because people put prize money up on Kaggle to solve
    real-world problems:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化数据在学术界经常被忽视，因为如果您有更好的物流模型，很难在高端会议论文中发表。但这是让世界运转的东西，让每个人都赚钱和提高效率。我们不会忽视它，因为我们正在进行实际的深度学习，Kaggle也不会，因为人们在Kaggle上提供奖金来解决现实世界的问题：
- en: '[Corporación Favorita Grocery Sales Forecasting](https://www.kaggle.com/c/favorita-grocery-sales-forecasting)
    — which is currently running'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Corporación Favorita Grocery Sales Forecasting](https://www.kaggle.com/c/favorita-grocery-sales-forecasting)
    — 目前正在进行中'
- en: '[Rossmann Store Sales](https://www.kaggle.com/c/rossmann-store-sales) — almost
    identical to above but completed competition.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Rossmann Store Sales](https://www.kaggle.com/c/rossmann-store-sales) — 几乎与上述相同，但是已经完成的比赛。'
- en: Rossmann Store Sale [[02:02:42](https://youtu.be/9C06ZPF8Uuc?t=2h2m42s)]
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Rossmann Store Sale [[02:02:42](https://youtu.be/9C06ZPF8Uuc?t=2h2m42s)]
- en: '[Notebook](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson3-rossman.ipynb)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[笔记本](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson3-rossman.ipynb)'
- en: '[PRE32]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '`fastai.structured` — not PyTorch specific and also used in machine learning
    course doing random forests with no PyTorch at all. It can used on its own without
    any of the other parts of Fast.ai library.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fastai.structured` — 不是特定于PyTorch的，也在机器学习课程中使用，使用随机森林而没有PyTorch。它可以独立使用，而无需使用Fast.ai库的其他部分。'
- en: '`fastai.column_data` — allows us to do Fast.ai and PyTorch stuff with columnar
    structured data.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fastai.column_data` — 允许我们使用列式结构化数据进行Fast.ai和PyTorch操作。'
- en: For structured data need to use **Pandas** a lot. Pandas is an attempt to replicate
    R’s data frames in Python (If you are not familiar with Pandas, here is a good
    book — [Python for Data Analysis, 2nd Edition](http://shop.oreilly.com/product/0636920050896.do))
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于结构化数据，需要大量使用 **Pandas**。Pandas 是在 Python 中尝试复制 R 的数据框架（如果您对 Pandas 不熟悉，这里有一本好书
    — [Python 数据分析，第二版](http://shop.oreilly.com/product/0636920050896.do)）
- en: There are a lot of data pre-processing This notebook contains the entire pipeline
    from the third place winner ([Entity Embeddings of Categorical Variables](https://arxiv.org/abs/1604.06737)).
    Data processing is not covered in this course, but is covered in machine learning
    course in some detail because feature engineering is very important.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多数据预处理。这个笔记本包含了第三名获奖者的整个流程（[分类变量的实体嵌入](https://arxiv.org/abs/1604.06737)）。数据处理在本课程中没有涉及，但在一些机器学习课程中有详细介绍，因为特征工程非常重要。
- en: Looking at CSV files
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看 CSV 文件
- en: '[PRE33]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '`StoreType` — you often get datasets where some columns contain “code”. It
    really does not matter what the code means. Stay away from learning too much about
    it and see what the data says first.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`StoreType` — 您经常会得到一些列包含“代码”的数据集。实际上，这个代码的含义并不重要。不要过多地了解它，先看看数据说了什么。'
- en: Joining tables
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接表
- en: 'This is a relational dataset, and you have join quite a few tables together
    — which is easy to do with Pandas’ `merge`:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个关系型数据集，您需要将许多表连接在一起 — 这在 Pandas 的 `merge` 中很容易实现：
- en: '[PRE34]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'From Fast.ai library:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 Fast.ai 库：
- en: '[PRE35]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Take a date and pull out a bunch of columns such as “day of week”, “start of
    a quarter”, “month of year” and so on and add them all to the dataset.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 取一个日期并提取出一堆列，比如“星期几”，“季度开始”，“年份的月份”等等，并将它们全部添加到数据集中。
- en: Duration section will calculate things like how long until the next holiday,
    how long it has been since the last holiday, etc.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续时间部分将计算诸如距下一个假期还有多长时间，距上一个假期已经过去多长时间等等。
- en: '[PRE36]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '`to_feather` : Saves a Pandas’ data frame into a “feather” format which takes
    it as it sits in RAM and dumps it to the disk. So it is really really fast. Ecuadorian
    grocery competition has 350 million records, so you will care about how long it
    takes to save.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`to_feather`：将 Pandas 的数据框保存为“feather”格式，该格式将数据框原封不动地转储到磁盘上。因此速度非常快。厄瓜多尔杂货店竞赛有
    3.5 亿条记录，因此您会关心保存需要多长时间。'
- en: Next week
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下周
- en: 'split columns into two types: categorical and continuous. Categorical column
    will be represented as one hot encoding, and continuous column gets fed into fully
    connected layer as is.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将列分为两种类型：分类和连续。分类列将被表示为独热编码，而连续列将被直接输入到全连接层中。
- en: 'categorical: store #1 and store #2 are not numerically related to each other.
    Similarly, day of week Monday (day 0) and Tuesday (day 1).'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '分类：商店 #1 和商店 #2 之间没有数值关联。同样，星期几的星期一（第 0 天）和星期二（第 1 天）也没有数值关联。'
- en: 'continuous: Things like distance in kilometers to the nearest competitor is
    a number we treat numerically.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续：像到最近竞争对手的公里数这样的距离是我们以数字方式处理的一个数字。
- en: '`ColumnarModelData`'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ColumnarModelData`'
