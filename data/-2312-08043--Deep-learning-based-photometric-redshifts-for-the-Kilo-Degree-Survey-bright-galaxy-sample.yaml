- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-06 19:35:37'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-06 19:35:37'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2312.08043] Deep learning based photometric redshifts for the Kilo-Degree
    Survey bright galaxy sample'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2312.08043] 基于深度学习的 Kilo-Degree Survey 明亮星系样本的光度红移'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2312.08043](https://ar5iv.labs.arxiv.org/html/2312.08043)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2312.08043](https://ar5iv.labs.arxiv.org/html/2312.08043)
- en: '[cft] [cft] [cft] [cft] cft]Center For Theoretical Physics, Aleja Lotników
    32/46, 02-668 Warsaw, Poland \headtitleDeep-learning photometric redshifts for
    KiDS DR4 bright galaxies'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[cft] [cft] [cft] [cft] cft]理论物理中心，Aleja Lotników 32/46，02-668 华沙，波兰 \headtitle深度学习光度红移用于
    KiDS DR4 明亮星系'
- en: Deep learning based photometric redshifts for the Kilo-Degree Survey bright
    galaxy sample
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于深度学习的 Kilo-Degree Survey 明亮星系样本的光度红移
- en: Anjitha John William    Priyanka Jalan    Maciej Bilicki    Wojciech A. Hellwing
    [
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Anjitha John William    Priyanka Jalan    Maciej Bilicki    Wojciech A. Hellwing
    [
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: In cosmological analyses, precise redshift determination remains pivotal for
    understanding cosmic evolution. However, with only a fraction of galaxies having
    spectroscopic redshifts (spec-$z$s), the challenge lies in estimating redshifts
    for a larger number. To address this, photometry-based redshift (photo-$z$) estimation,
    employing machine learning algorithms, is a viable solution. Identifying the limitations
    of previous methods, this study focuses on implementing deep learning (DL) techniques
    within the Kilo-Degree Survey (KiDS) Bright Sample for more accurate photo-$z$
    estimations. Comparing our new DL-based model against prior ‘shallow’ neural networks,
    we showcase improvements in redshift accuracy. Our model gives mean photo-$z$
    bias $\langle\Delta z\rangle=10^{-3}$ and scatter $\mathrm{SMAD}(\Delta z)=0.016$,
    where $\Delta z=(z_{\mathrm{phot}}-z_{\mathrm{spec}})/(1+z_{\mathrm{spec}})$.
    This research highlights the promising role of DL in revolutionizing photo-$z$
    estimation.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在宇宙学分析中，精确的红移测定对于理解宇宙演化仍然至关重要。然而，由于只有一小部分星系具有光谱红移（spec-$z$s），因此挑战在于为更多星系估计红移。为解决这一问题，基于光度的红移（photo-$z$）估计，使用机器学习算法，是一种可行的解决方案。识别了以往方法的局限性后，本研究重点在于在
    Kilo-Degree Survey (KiDS) 明亮样本中实施深度学习 (DL) 技术，以实现更准确的 photo-$z$ 估计。通过将我们新的基于 DL
    的模型与以前的‘浅层’神经网络进行比较，我们展示了红移准确度的改进。我们的模型给出了平均 photo-$z$ 偏差 $\langle\Delta z\rangle=10^{-3}$
    和散布 $\mathrm{SMAD}(\Delta z)=0.016$，其中 $\Delta z=(z_{\mathrm{phot}}-z_{\mathrm{spec}})/(1+z_{\mathrm{spec}})$。这项研究突显了
    DL 在革命性 photo-$z$ 估计中的有前景的角色。
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: Redshift is a basic quantity in cosmological analyses, serving as one of the
    indicators of galaxy distances. Its precise determination enables the mapping
    of the three-dimensional large-scale structure of the Universe and facilitates
    our comprehension of cosmic evolution. Achieving sub-percent accuracy in redshift
    measurements is exclusively feasible through spectroscopy. In obtaining spectroscopic
    redshifts (spec-zs), we initially capture the spectrum of a celestial source and
    subsequently identify the shift in spectral lines relative to their rest frame.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 红移是宇宙学分析中的基本量之一，用于指示星系距离。其精确测定使得可以绘制宇宙的三维大尺度结构，并促进我们对宇宙演化的理解。实现红移测量的亚百分比准确度仅通过光谱学才能实现。在获得光谱红移（spec-zs）时，我们首先捕捉天体的光谱，然后识别相对于其静止参考系的光谱线偏移。
- en: Due to expensive telescope time needed, spec-$z$s are only attainable for a
    fraction of galaxies. However, a viable alternative is the estimation of redshifts
    through photometric measurements. Such photometric redshifts (photo-$z$s) may
    not provide the same level of redshift accuracy and precision as spec-$z$s; however,
    they have proven indispensable in the era of massive imaging surveys. Such redshift
    estimates rely on the correlation between observed galaxy photometry and the true
    redshift (e.g. Baum, [1957](#bib.bib2)). This proceeding focuses on estimating
    this correlation using machine learning (ML) algorithms.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 由于需要昂贵的望远镜时间，spec-$z$s 仅能在少数星系中获得。然而，一种可行的替代方法是通过光度测量来估计红移。这些光度红移（photo-$z$s）可能无法提供与
    spec-$z$s 相同水平的红移准确性和精度；然而，在大规模成像调查时代，它们已经被证明是不可或缺的。这些红移估计依赖于观测星系光度与真实红移之间的相关性（例如，Baum，[1957](#bib.bib2)）。该过程聚焦于使用机器学习
    (ML) 算法来估计这种相关性。
- en: Machine learning-based techniques for photo-z estimation include supervised
    learning (Wadadekar, [2005](#bib.bib26); Collister & Lahav, [2004](#bib.bib6);
    Oyaizu et al., [2008](#bib.bib22)), unsupervised learning (Way & Klose, [2012](#bib.bib27)),
    k-nearest neighbors (Graham et al., [2018](#bib.bib13)), ensemble learning and
    Gaussian processes (Way & Srivastava, [2006](#bib.bib28); Bonfield et al., [2010](#bib.bib4)),
    mixed density networks (Ansari et al., [2021](#bib.bib1)) and finally, deep neural
    networks (Hoyle et al., [2015](#bib.bib15); D’Isanto & Polsterer, [2018](#bib.bib9)).
    In supervised ML techniques, the algorithm establishes an empirical relationship
    between observed quantities and corresponding labels through training on appropriately
    labeled data. The main challenge and limitation of these methods lie in extrapolating
    results beyond the representative training set.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 基于机器学习的光度-$z$估计技术包括监督学习（Wadadekar，[2005](#bib.bib26)；Collister & Lahav，[2004](#bib.bib6)；Oyaizu等，[2008](#bib.bib22)），无监督学习（Way
    & Klose，[2012](#bib.bib27)），k-最近邻（Graham等，[2018](#bib.bib13)），集成学习和高斯过程（Way &
    Srivastava，[2006](#bib.bib28)；Bonfield等，[2010](#bib.bib4)），混合密度网络（Ansari等，[2021](#bib.bib1)）以及最终的深度神经网络（Hoyle等，[2015](#bib.bib15)；D’Isanto
    & Polsterer，[2018](#bib.bib9)）。在监督机器学习技术中，算法通过对适当标记的数据进行训练，建立观察量与相应标签之间的经验关系。这些方法的主要挑战和限制在于将结果外推到代表性训练集之外。
- en: Deep learning (DL) based photo-$z$ derivation is a promising technique among
    other supervised ML techniques (e.g. Menou, [2019](#bib.bib21); Dey et al., [2022](#bib.bib8);
    Li et al., [2022](#bib.bib19); Treyer et al., [2024](#bib.bib25)). In such frameworks,
    the term ‘deep’ signifies that the models typically employ intricate, multi-layer
    architectures. Deep learning methods, specifically convolutional neural networks
    (CNNs), are selected for predicting photo-zs due to their exceptional ability
    to discern patterns in data, particularly images.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 基于深度学习（DL）的光度-$z$推导在其他监督机器学习技术中是一种有前景的技术（例如Menou，[2019](#bib.bib21)；Dey等，[2022](#bib.bib8)；Li等，[2022](#bib.bib19)；Treyer等，[2024](#bib.bib25)）。在这些框架中，“深度”一词意味着模型通常采用复杂的多层架构。深度学习方法，特别是卷积神经网络（CNNs），由于其在数据（尤其是图像）中识别模式的卓越能力，被选择用于预测光度-$z$。
- en: In this work, we present a deep learning model for photometric redshift estimation
    of bright galaxies in the Kilo-Degree Survey (KiDS, de Jong et al., [2013](#bib.bib7)),
    a multiband imaging survey covering about 1350 deg² of the sky. Following up on
    earlier KiDS work by Li et al. ([2022](#bib.bib19)), we applied the DL models
    for photo-z estimation within the flux-limited ‘KiDS Bright Sample’, encompassing
    all galaxies from KiDS with $r<20$ mag (Bilicki et al., [2021](#bib.bib3)). We
    compare our derivations with the previously released KiDS bright sample photo-zs
    obtained with ‘shallow’ neural networks from the public package ANNz2 (Sadeh et al.,
    [2016](#bib.bib23)). Our new model improves over those previous results and gives
    great perspectives for the final KiDS data release.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们提出了一种用于Kilo-Degree Survey（KiDS，de Jong等，[2013](#bib.bib7)）中明亮星系的光度红移估计的深度学习模型，该调查涵盖了大约1350平方度的天空。继Li等（[2022](#bib.bib19)）对早期KiDS工作的跟进，我们在流量限制的‘KiDS
    Bright Sample’中应用了DL模型进行光度-$z$估计，该样本涵盖了所有$r<20$ mag的KiDS星系（Bilicki等，[2021](#bib.bib3)）。我们将我们的推导与之前使用公共包ANNz2（Sadeh等，[2016](#bib.bib23)）中的‘浅层’神经网络获得的KiDS明亮样本光度-$z$进行比较。我们的新模型在这些先前结果上有所改进，并为最终的KiDS数据发布提供了良好的前景。
- en: 2 Input Data
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 输入数据
- en: This section details the datasets used in this study. The training sample required
    for the neural network is KiDS-DR4 four-band (u, g, r, and i) optical galaxy images
    and their 9-band magnitudes, with their corresponding labels of true (spectroscopic)
    redshifts from the Galaxy And Mass Assembly (GAMA, Driver et al., [2011](#bib.bib10))
    survey.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本节详细介绍了本研究中使用的数据集。神经网络所需的训练样本为KiDS-DR4四波段（u、g、r和i）光学星系图像及其9波段的光度，与来自银河系及质量组装（GAMA，Driver等，
    [2011](#bib.bib10)）调查的真实（光谱）红移标签相对应。
- en: 2.1 Images and Photometry
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 图像与光度测量
- en: KiDS is an extensive optical survey conducted by the European Southern Observatory
    (ESO) at the VLT Survey Telescope (VST, Capaccioli & Schipani, [2011](#bib.bib5)),
    which utilizes the OmegaCAM CCD mosaic camera, boasting an impressive 268 million-pixel
    focal plane. It is positioned at the ESO Paranal Observatory in Chile. The VST
    is an alt-azimuth mounted telescope based on a modified Ritchey-Chrétien design.
    KiDS captured images in four distinct broad bands ($ugri$) and encompasses an
    area of 1350 square degrees within the extragalactic sky.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: KiDS是由欧洲南方天文台（ESO）在VLT巡天望远镜（VST, Capaccioli & Schipani, [2011](#bib.bib5)）上进行的大型光学调查，使用了OmegaCAM
    CCD镶嵌相机，具有268百万像素的焦平面。它位于智利的ESO帕拉纳尔天文台。VST是一台基于改进型Ritchey-Chrétien设计的高架望远镜。KiDS在四个不同的宽带（$ugri$）中捕捉了图像，覆盖了1350平方度的外银河天空区域。
- en: We have used KiDS Data Release 4 (DR4, Kuijken et al., [2019](#bib.bib17))¹¹1[https://kids.strw.leidenuniv.nl/DR4](https://kids.strw.leidenuniv.nl/DR4)
    co-added images that had been calibrated for both astrometry and photometry, ensuring
    a consistent pixel scale of 0.2 arcseconds. We have also incorporated the nine-band
    magnitudes of galaxies. These latter join original KiDS $ugri$ measurements with
    those from the VIKING (Edge et al., [2013](#bib.bib12)) survey, encompassing five
    near-IR bands ($ZYJHK_{s}$).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了经过天体测量和光度校准的KiDS数据发布4（DR4, Kuijken等， [2019](#bib.bib17)）¹¹1[https://kids.strw.leidenuniv.nl/DR4](https://kids.strw.leidenuniv.nl/DR4)合成图像，确保了0.2角秒的一致像素尺度。我们还纳入了星系的九带幅度数据。这些数据将原始KiDS的$ugri$测量与VIKING（Edge等，
    [2013](#bib.bib12)）调查的五个近红外带（$ZYJHK_{s}$）数据相结合。
- en: 2.2 GAMA Spectroscopic Data
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 GAMA光谱数据
- en: The true (spectroscopic) redshifts used for training and testing are obtained
    from the GAMA dataset. This survey, conducted across five fields, of which four
    are fully within the KiDS footprint, covers a total area of approx. 286 square
    degrees. The data were obtained using the AAOmega fiber-fed spectrograph facility
    mounted on the 3.9-meter Anglo-Australian Telescope (Driver et al., [2011](#bib.bib10)).
    GAMA gives spectra, redshifts, their quality, and other ancillary information.
    KiDS-DR4 fully overlaps with the G09, G12, G15 and G23 fields. In this work, we
    have used the GAMA-II spectroscopic redshift catalog of galaxies from the GAMA
    DR4 (Driver et al., [2022](#bib.bib11))²²2[http://www.gama-survey.org/dr4](http://www.gama-survey.org/dr4).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 用于训练和测试的真实（光谱）红移数据来源于GAMA数据集。该调查覆盖了五个领域，其中四个完全位于KiDS的观测范围内，总面积约为286平方度。这些数据是通过安装在3.9米的英-澳望远镜上的AAOmega光纤光谱仪设施获得的（Driver等，
    [2011](#bib.bib10)）。GAMA提供了光谱、红移、质量及其他附加信息。KiDS-DR4与G09、G12、G15和G23领域完全重叠。在本研究中，我们使用了来自GAMA
    DR4的GAMA-II光谱红移星系目录（Driver等， [2022](#bib.bib11)）²²2[http://www.gama-survey.org/dr4](http://www.gama-survey.org/dr4)。
- en: We have identified galaxies within KiDS tiles that overlap between the GAMA
    and KiDS-bright sample based on their sky coordinates. Subsequently, we created
    cutouts for these galaxies, positioning each at the center of the cutout with
    dimensions of $7.2^{\prime\prime}\times 7.2^{\prime\prime}$. The final cutout
    catalog comprises $\sim 136$k galaxies in the equatorial field, with $\sim 95$k
    utilized for model training. Model testing was conducted on $\sim 20$k galaxies
    present in both the equatorial field and KiDS bright sample.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们识别出了在KiDS图块中与GAMA和KiDS-bright样本重叠的星系，基于它们的天空坐标。随后，我们为这些星系创建了切图，每个切图的中心位置为$7.2^{\prime\prime}\times
    7.2^{\prime\prime}$。最终的切图目录包含了约136,000个赤道场星系，其中约95,000个用于模型训练。模型测试是在同时存在于赤道场和KiDS亮星样本中的约20,000个星系上进行的。
- en: 2.3 KiDS-DR4 Bright Galaxy Sample
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 KiDS-DR4亮星系样本
- en: The KiDS-bright galaxy sample (Bilicki et al., [2021](#bib.bib3)) is a collection
    of KiDS galaxies selected based on their flux and free from artifacts etc. Specifically,
    it includes galaxies with a magnitude limit of $r_{\mathrm{auto}}<20$ mag, where
    ‘auto’ stands for SExtractor-derived estimate of the total flux via automatic
    aperture photometry.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: KiDS-bright星系样本（Bilicki等， [2021](#bib.bib3)）是一个基于流量选择的KiDS星系集合，且没有伪影等问题。具体来说，它包括了$r_{\mathrm{auto}}<20$
    mag的星系，其中‘auto’指的是通过自动孔径光度法得到的SExtractor总流量估计值。
- en: 3 Methodology
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法论
- en: Convolutional Neural Networks (CNNs), a subtype of Artificial Neural Networks
    (ANNs), excel in addressing computer vision challenges like image detection and
    classification. The operational principles of CNNs draw inspiration from the human
    neural system, mirroring the functionality of neurons (McCulloch, [1943](#bib.bib20)).
    Similar to biological neurons that receive input and transmit electrochemical
    signals, CNNs employ artificial neurons to process information. The importance
    of CNNs becomes apparent through their widespread application in image recognition
    tasks, as highlighted by e.g. LeCun et al. ([1998](#bib.bib18)). The adaptability
    and efficacy of CNNs make them a key technology in the field of computer vision,
    contributing significantly to advancements in image-based tasks. Our model includes
    a special CNN architecture called Inception (Szegedy et al., [2015](#bib.bib24)).
    Our approach employs CNNs to forecast the photo-zs for the KiDS-bright sample,
    treating it as a regression problem. To label the training set, we used the spectroscopic
    GAMA data detailed earlier.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNNs），作为人工神经网络（ANNs）的一个子类型，在解决计算机视觉问题如图像检测和分类方面表现出色。CNNs的操作原理从人类神经系统中汲取灵感，模仿神经元的功能（McCulloch,
    [1943](#bib.bib20)）。类似于接收输入并传递电化学信号的生物神经元，CNNs使用人工神经元来处理信息。CNNs的重要性通过其在图像识别任务中的广泛应用变得显而易见，例如LeCun等人所强调的（[1998](#bib.bib18)）。CNNs的适应性和效能使其成为计算机视觉领域的关键技术，为图像相关任务的发展做出了重要贡献。我们的模型包括一个特殊的CNN架构，称为Inception（Szegedy等人，[2015](#bib.bib24)）。我们的方法利用CNNs来预测KiDS-bright样本的photo-z，将其视为回归问题。为了标记训练集，我们使用了之前详细描述的光谱GAMA数据。
- en: 'Our ML model for photo-zs is a combined, multi-input one. Inspired by Henghes
    et al. ([2022](#bib.bib14)); Li et al. ([2022](#bib.bib19)), we use both 4-band
    KiDS images and the corresponding 9-band KiDS+VIKING magnitudes. We combined two
    different ML schemes: ordinary neural networks (ONN) and CNN (Inception). The
    architecture of our model is shown in Fig. [3](#S3 "3 Methodology ‣ Deep learning
    based photometric redshifts for the Kilo-Degree Survey bright galaxy sample").'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的photo-z ML模型是一个综合的多输入模型。受到Henghes等人（[2022](#bib.bib14)）；Li等人（[2022](#bib.bib19)）的启发，我们使用了4波段的KiDS图像和对应的9波段KiDS+VIKING光度。我们结合了两种不同的ML方案：普通神经网络（ONN）和CNN（Inception）。我们的模型架构如图Fig. [3](#S3
    "3 Methodology ‣ Deep learning based photometric redshifts for the Kilo-Degree
    Survey bright galaxy sample")所示。
- en: 'When tuning the model and assessing its performance, we primarily employed
    three metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared
    error ($R^{2}$):'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在调整模型和评估其性能时，我们主要使用了三种指标：均方误差（MSE）、平均绝对误差（MAE）和R平方误差（$R^{2}$）：
- en: '|  | $R^{2}=1-\frac{\sum_{i=1}^{n}(z_{i}-\hat{z}_{i})^{2}}{\sum_{i=1}^{n}(z_{i}-\bar{z})^{2}}\;,$
    |  | (1) |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '|  | $R^{2}=1-\frac{\sum_{i=1}^{n}(z_{i}-\hat{z}_{i})^{2}}{\sum_{i=1}^{n}(z_{i}-\bar{z})^{2}}\;,$
    |  | (1) |'
- en: where $n$ is the number of samples used, $z_{i}$ is the predicted value, $\hat{z}_{i}$
    is the true value, and $\bar{z}$ is the mean of true redshift values. $R^{2}$
    is a statistical measure indicating how well a model predicts outcomes in a regression
    analysis. It represents the proportion of variance explained by the model relative
    to the total variance. In an ideal scenario, its value is unity, and our combined
    model has demonstrated the capability to achieve an $R^{2}$ value exceeding $0.92$.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$n$是使用的样本数量，$z_{i}$是预测值，$\hat{z}_{i}$是真实值，$\bar{z}$是真实红移值的平均值。$R^{2}$是一个统计度量，表示模型在回归分析中预测结果的能力。它表示模型解释的方差占总方差的比例。在理想情况下，它的值为1，我们的综合模型已经显示出能够实现超过$0.92$的$R^{2}$值。
- en: 'MSE is effective for learning outliers, while MAE is advantageous for disregarding
    them. In our approach, we employed the Huber ([1964](#bib.bib16)) loss function
    that combines the characteristics of both MSE and MAE, providing a balanced approach
    to handling outliers during the training of the model:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: MSE对于学习异常值有效，而MAE则有利于忽略它们。在我们的方法中，我们采用了Huber（[1964](#bib.bib16)）损失函数，它结合了MSE和MAE的特点，提供了一种平衡的处理异常值的方式，用于模型训练：
- en: '|  | $H(z,\hat{z})=\begin{cases}\frac{1}{2}(z-\hat{z})^{2},&amp;\text{if }&#124;z-\hat{z}&#124;\leq\delta,\\
    \delta(&#124;z-\hat{z}&#124;-\frac{\delta}{2}),&amp;\text{otherwise}.\end{cases}$
    |  | (2) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '|  | $H(z,\hat{z})=\begin{cases}\frac{1}{2}(z-\hat{z})^{2},&amp;\text{如果 }&#124;z-\hat{z}&#124;\leq\delta,\\
    \delta(&#124;z-\hat{z}&#124;-\frac{\delta}{2}),&amp;\text{否则}.\end{cases}$ |  |
    (2) |'
- en: The value of $\delta$ we use is 0.0001 by trial and error.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的$\delta$值是通过反复试验得到的，为0.0001。
- en: '![Refer to caption](img/f0f63db3234abb2951beaebdee1ad7a3.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f0f63db3234abb2951beaebdee1ad7a3.png)'
- en: (a) Architecture of the Combined model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 组合模型的架构。
- en: '![Refer to caption](img/ea7dd52eb342b18ea04391901c7084a7.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ea7dd52eb342b18ea04391901c7084a7.png)'
- en: (b) Comparison of spectroscopic and the predicted photometric redshifts for
    the test sample. The thick red solid line represents the running median, while
    the thinner red lines enclose the scatter, quantified by the SMAD.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 比较光谱和预测的光度红移在测试样本中的表现。粗红色实线表示运行中位数，而细红线包围了由SMAD量化的散布。
- en: '![Refer to caption](img/f69f7274ce63975cba4597045df6213a.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f69f7274ce63975cba4597045df6213a.png)'
- en: (c) Normalised bias as a function of photo-$z$, with red lines encoding the
    running median and SMAD as in the upper panel.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 光度-$z$作为函数的标准化偏差，红线表示运行中位数和SMAD，如上图所示。
- en: 4 Results
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结果
- en: 'The photo-z performance is evaluated using the following statistics:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 光度-$z$性能通过以下统计量进行评估：
- en: •
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'bias:'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 偏差：
- en: '|  | $\delta z=z_{\mathrm{phot}}-z_{\mathrm{spec}}\,,$ |  | (3) |'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\delta z=z_{\mathrm{phot}}-z_{\mathrm{spec}}\,,$ |  | (3) |'
- en: •
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'normalized bias:'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 标准化偏差：
- en: '|  | $\Delta z=\frac{\delta z}{1+z_{\mathrm{spec}}}\,,$ |  | (4) |'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\Delta z=\frac{\delta z}{1+z_{\mathrm{spec}}}\,,$ |  | (4) |'
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: the standard deviation of $\Delta z$,
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\Delta z$的标准偏差，
- en: •
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: scaled median absolute deviation (SMAD) of $\Delta z$, where
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\Delta z$的标准化中位绝对偏差（SMAD），其中
- en: '|  | $\text{SMAD}(x)=1.4826\times\text{median}\left(\lvert x-\text{median}(x)\rvert\right)\,.$
    |  | (5) |'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\text{SMAD}(x)=1.4826\times\text{median}\left(\lvert x-\text{median}(x)\rvert\right)\,.$
    |  | (5) |'
- en: These statistics for the overall test sample (based on GAMA equatorial data)
    are provided in Table [1](#S4.T1 "Table 1 ‣ 4 Results ‣ Deep learning based photometric
    redshifts for the Kilo-Degree Survey bright galaxy sample"), where they are directly
    compared with previous results from Bilicki et al. ([2021](#bib.bib3)), derived
    with the ANNz2 software employing 9-band KiDS+VIKING magnitudes. There is visible
    improvement in terms of scatter, both in the standard deviation and SMAD, from
    the earlier ANNz2 results to our new DL model. This shows that our combined model
    gives promise for improved photo-$z$s for the KiDS Bright Galaxy Sample. We additionally
    visualize our DL photo-$z$ performance in Figs. [3](#S3 "3 Methodology ‣ Deep
    learning based photometric redshifts for the Kilo-Degree Survey bright galaxy
    sample") & [3](#S3 "3 Methodology ‣ Deep learning based photometric redshifts
    for the Kilo-Degree Survey bright galaxy sample"), which show generally unbiased
    and stable photo-$z$s as a function of the photometric redshift itself.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这些针对整体测试样本（基于GAMA赤道数据）的统计数据见表[1](#S4.T1 "表1 ‣ 4结果 ‣ 基于深度学习的Kilo-Degree Survey亮星系样本的光度红移")，其中直接与Bilicki等人的先前结果进行比较（[2021](#bib.bib3)），这些结果是通过使用9波段KiDS+VIKING光度的ANNz2软件得出的。从早期的ANNz2结果到我们的新深度学习模型，在标准偏差和SMAD方面都有明显的改进。这表明我们的组合模型对KiDS亮星系样本提供了改进的光度-$z$。我们还在图[3](#S3
    "3方法 ‣ 基于深度学习的Kilo-Degree Survey亮星系样本的光度红移") & [3](#S3 "3方法 ‣ 基于深度学习的Kilo-Degree
    Survey亮星系样本的光度红移")中可视化了我们的深度学习光度-$z$表现，显示出光度红移本身作为函数的一般无偏和稳定的光度-$z$。
- en: 'Table 1: Statistics of photometric redshift performance obtained for KiDS-GAMA
    equatorial spectroscopic sample.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：KiDS-GAMA赤道光谱样本的光度红移性能统计。
- en: '| Method | $\langle\delta z\rangle$ | $\langle\Delta z\rangle$ | $\sigma(\Delta
    z)$ | SMAD$(\Delta z)$ |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | $\langle\delta z\rangle$ | $\langle\Delta z\rangle$ | $\sigma(\Delta
    z)$ | SMAD$(\Delta z)$ |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| ANNz2 (Bilicki et al., [2021](#bib.bib3)) | $0.0005$ | $0.0009$ | $0.024$
    | $0.018$ |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| ANNz2（Bilicki等人，[2021](#bib.bib3)） | $0.0005$ | $0.0009$ | $0.024$ | $0.018$
    |'
- en: '| Combined model (this work) | $0.001$ | $0.001$ | $0.021$ | $0.016$ |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 组合模型（本研究） | $0.001$ | $0.001$ | $0.021$ | $0.016$ |'
- en: 5 Conclusion and Future Prospects
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论与未来展望
- en: In these proceedings, we described a new deep-learning model for photometric
    redshift derivation in the KiDS bright sample that joins Inception-based CNN using
    4-band KiDS images, with an ANN employing 9-band magnitudes. We see improvement
    over previous work by Bilicki et al. ([2021](#bib.bib3)), where ANNs with magnitudes
    only were used. In the forthcoming paper, we will present more details and apply
    our model to the entire KiDS DR4 Bright Galaxy Sample, which will give new, improved
    photo-$z$s for that dataset.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些程序中，我们描述了一种新的深度学习模型，用于KiDS亮样本的光度红移推导，该模型结合了使用4波段KiDS图像的Inception基础CNN和使用9波段光度的ANN。我们看到比Bilicki等人（[2021](#bib.bib3)）的先前工作有所改进，其中仅使用了光度的ANN。在即将发表的论文中，我们将介绍更多细节，并将我们的模型应用于整个KiDS
    DR4亮星系样本，这将为该数据集提供新的、改进的光度-$z$。
- en: In the near future, we plan to build a deep-learning model which will use the
    9-band imaging from both KiDS and VIKING (unlike KiDS $ugri$ only as presently).
    That model will be subsequently used to derive photo-$z$s for the Bright Galaxy
    Sample in the final KiDS Data Release 5 (Wright et al., in press; Wright, [2023](#bib.bib29)).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在不久的将来，我们计划建立一个深度学习模型，该模型将使用来自 KiDS 和 VIKING 的 9 帧成像（与目前仅使用 KiDS $ugri$ 的情况不同）。该模型随后将用于推导最终
    KiDS 数据发布 5 中的亮星系样本的照片-$z$s（Wright 等，待发表；Wright, [2023](#bib.bib29)）。
- en: 6 Acknowledgement
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 致谢
- en: This work is funded via the research project ‘Precision and Accuracy for Cosmological
    Imaging Surveys (PACIS)’ from the Polish National Science Centre through a Sonata-Bis
    grant no. 2020/38/E/ST9/00395\. We thank Rui Li and Nicola Napolitano for their
    assistance and feedback.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究由波兰国家科学中心通过 Sonata-Bis 资助项目“宇宙学成像调查的精度与准确性（PACIS）”资助，资助号为 2020/38/E/ST9/00395。我们感谢
    Rui Li 和 Nicola Napolitano 的帮助和反馈。
- en: References
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Ansari et al. (2021) Ansari, Z., Agnello, A., Gall, C., *A&A* 650, A90 (2021)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ansari 等（2021）Ansari, Z., Agnello, A., Gall, C., *A&A* 650, A90 (2021)
- en: Baum (1957) Baum, W. A., *AJ* 62, 6 (1957)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baum（1957）Baum, W. A., *AJ* 62, 6 (1957)
- en: Bilicki et al. (2021) Bilicki, M., et al., *A&A* 653, A82 (2021)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bilicki 等（2021）Bilicki, M., 等, *A&A* 653, A82 (2021)
- en: Bonfield et al. (2010) Bonfield, D. G., et al., *MNRAS* 405, 2, 987 (2010)
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bonfield 等（2010）Bonfield, D. G., 等, *MNRAS* 405, 2, 987 (2010)
- en: Capaccioli & Schipani (2011) Capaccioli, M., Schipani, P., *The Messenger* 146,
    2 (2011)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Capaccioli & Schipani（2011）Capaccioli, M., Schipani, P., *The Messenger* 146,
    2 (2011)
- en: Collister & Lahav (2004) Collister, A. A., Lahav, O., *PASP* 116, 818, 345 (2004)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Collister & Lahav（2004）Collister, A. A., Lahav, O., *PASP* 116, 818, 345 (2004)
- en: de Jong et al. (2013) de Jong, J. T. A., Verdoes Kleijn, G. A., Kuijken, K. H.,
    Valentijn, E. A., *Experimental Astronomy* 35, 1-2, 25 (2013)
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de Jong 等（2013）de Jong, J. T. A., Verdoes Kleijn, G. A., Kuijken, K. H., Valentijn,
    E. A., *Experimental Astronomy* 35, 1-2, 25 (2013)
- en: Dey et al. (2022) Dey, B., et al., *MNRAS* 515, 4, 5285 (2022)
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dey 等（2022）Dey, B., 等, *MNRAS* 515, 4, 5285 (2022)
- en: D’Isanto & Polsterer (2018) D’Isanto, A., Polsterer, K. L., *A&A* 609, A111
    (2018)
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: D’Isanto & Polsterer（2018）D’Isanto, A., Polsterer, K. L., *A&A* 609, A111 (2018)
- en: Driver et al. (2011) Driver, S. P., et al., *MNRAS* 413, 2, 971 (2011)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Driver 等（2011）Driver, S. P., 等, *MNRAS* 413, 2, 971 (2011)
- en: Driver et al. (2022) Driver, S. P., et al., *MNRAS* 513, 1, 439 (2022)
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Driver 等（2022）Driver, S. P., 等, *MNRAS* 513, 1, 439 (2022)
- en: Edge et al. (2013) Edge, A., et al., *The Messenger* 154, 32 (2013)
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Edge 等（2013）Edge, A., 等, *The Messenger* 154, 32 (2013)
- en: Graham et al. (2018) Graham, M. L., et al., *AJ* 155, 1, 1 (2018)
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Graham 等（2018）Graham, M. L., 等, *AJ* 155, 1, 1 (2018)
- en: Henghes et al. (2022) Henghes, B., et al., *MNRAS* 512, 2, 1696 (2022)
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Henghes 等（2022）Henghes, B., 等, *MNRAS* 512, 2, 1696 (2022)
- en: Hoyle et al. (2015) Hoyle, B., et al., *MNRAS* 449, 2, 1275 (2015)
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hoyle 等（2015）Hoyle, B., 等, *MNRAS* 449, 2, 1275 (2015)
- en: Huber (1964) Huber, P. J., *Annals of Mathematical Statistics* 35, 492 (1964),
    URL [https://api.semanticscholar.org/CorpusID:121252793](https://api.semanticscholar.org/CorpusID:121252793)
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huber（1964）Huber, P. J., *Annals of Mathematical Statistics* 35, 492 (1964),
    网址 [https://api.semanticscholar.org/CorpusID:121252793](https://api.semanticscholar.org/CorpusID:121252793)
- en: Kuijken et al. (2019) Kuijken, K., et al., *A&A* 625, A2 (2019)
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuijken 等（2019）Kuijken, K., 等, *A&A* 625, A2 (2019)
- en: LeCun et al. (1998) LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., *Proc. IEEE*
    86, 2278 (1998), URL [https://api.semanticscholar.org/CorpusID:14542261](https://api.semanticscholar.org/CorpusID:14542261)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun 等（1998）LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., *Proc. IEEE* 86,
    2278 (1998), 网址 [https://api.semanticscholar.org/CorpusID:14542261](https://api.semanticscholar.org/CorpusID:14542261)
- en: Li et al. (2022) Li, R., et al., *A&A* 666, A85 (2022)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2022）Li, R., 等, *A&A* 666, A85 (2022)
- en: McCulloch (1943) McCulloch, *The bulletin of mathematical biophysics* (1943),
    URL [https://doi.org/10.1007/BF02478259](https://doi.org/10.1007/BF02478259)
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McCulloch（1943）McCulloch, *The bulletin of mathematical biophysics* (1943),
    网址 [https://doi.org/10.1007/BF02478259](https://doi.org/10.1007/BF02478259)
- en: Menou (2019) Menou, K., *MNRAS* 489, 4, 4802 (2019)
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Menou（2019）Menou, K., *MNRAS* 489, 4, 4802 (2019)
- en: Oyaizu et al. (2008) Oyaizu, H., et al., *ApJ* 689, 2, 709 (2008)
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oyaizu 等（2008）Oyaizu, H., 等, *ApJ* 689, 2, 709 (2008)
- en: Sadeh et al. (2016) Sadeh, I., Abdalla, F. B., Lahav, O., *PASP* 128, 968, 104502
    (2016)
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sadeh 等（2016）Sadeh, I., Abdalla, F. B., Lahav, O., *PASP* 128, 968, 104502 (2016)
- en: Szegedy et al. (2015) Szegedy, C., et al., in 2015 IEEE Conference on Computer
    Vision and Pattern Recognition (CVPR), 1–9 (2015)
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等（2015）Szegedy, C., 等, 2015 IEEE 计算机视觉与模式识别会议（CVPR）, 1–9 (2015)
- en: Treyer et al. (2024) Treyer, M., et al., *MNRAS* 527, 1, 651 (2024)
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Treyer 等（2024）Treyer, M., 等, *MNRAS* 527, 1, 651 (2024)
- en: Wadadekar (2005) Wadadekar, Y., *PASP* 117, 827, 79 (2005)
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wadadekar（2005）Wadadekar, Y., *PASP* 117, 827, 79 (2005)
- en: Way & Klose (2012) Way, M. J., Klose, C. D., *PASP* 124, 913, 274 (2012)
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Way & Klose（2012）Way, M. J., Klose, C. D., *PASP* 124, 913, 274 (2012)
- en: Way & Srivastava (2006) Way, M. J., Srivastava, A. N., *ApJ* 647, 1, 102 (2006)
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Way & Srivastava (2006) Way, M. J., Srivastava, A. N., *ApJ* 647, 1, 102 (2006)
- en: Wright (2023) Wright, A., in A Decade of ESO Wide-field Imaging Surveys (surveys2023,
    5 (2023)
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wright (2023) Wright, A., 在《欧洲南方天文台广视场成像调查十年回顾》（surveys2023, 5 (2023)）
