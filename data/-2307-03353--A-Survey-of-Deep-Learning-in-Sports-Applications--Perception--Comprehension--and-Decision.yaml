- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:38:19'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:38:19
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2307.03353] A Survey of Deep Learning in Sports Applications: Perception,
    Comprehension, and Decision'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2307.03353] 深度学习在体育应用中的调研：感知、理解与决策'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2307.03353](https://ar5iv.labs.arxiv.org/html/2307.03353)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2307.03353](https://ar5iv.labs.arxiv.org/html/2307.03353)
- en: 'A Survey of Deep Learning in Sports Applications: Perception, Comprehension,
    and Decision'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在体育应用中的调研：感知、理解与决策
- en: Zhonghan Zhao^∗, Wenhao Chai^∗, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong
    Cao,
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Zhonghan Zhao^∗, Wenhao Chai^∗, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong
    Cao,
- en: 'Mingli Song,  Jenq-Neng Hwang,  Gaoang Wang^† ^∗ Equal contribution.^† Corresponding
    author: Gaoang Wang.Zhonghan Zhao, Shengyu Hao, Wenhao Hu, Guanhong Wang, Mingli
    Song are with College of Computer Science and Technology, Zhejiang University.Shidong
    Cao is with the Zhejiang University-University of Illinois Urbana-Champaign Institute,
    Zhejiang University.Gaoang Wang is with the Zhejiang University-University of
    Illinois Urbana-Champaign Institute, and College of Computer Science and Technology,
    Zhejiang University.Wenhao Chai and Jenq-Neng Hwang are with the University of
    Washington.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Mingli Song, Jenq-Neng Hwang, Gaoang Wang^† ^∗ 共同贡献。^† 通讯作者：Gaoang Wang。Zhonghan
    Zhao、Shengyu Hao、Wenhao Hu、Guanhong Wang、Mingli Song 隶属于浙江大学计算机科学与技术学院。Shidong
    Cao 隶属于浙江大学-伊利诺伊大学香槟分校研究所，浙江大学。Gaoang Wang 隶属于浙江大学-伊利诺伊大学香槟分校研究所和浙江大学计算机科学与技术学院。Wenhao
    Chai 和 Jenq-Neng Hwang 隶属于华盛顿大学。
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Deep learning has the potential to revolutionize sports performance, with applications
    ranging from perception and comprehension to decision. This paper presents a comprehensive
    survey of deep learning in sports performance, focusing on three main aspects:
    algorithms, datasets and virtual environments, and challenges. Firstly, we discuss
    the hierarchical structure of deep learning algorithms in sports performance which
    includes perception, comprehension and decision while comparing their strengths
    and weaknesses. Secondly, we list widely used existing datasets in sports and
    highlight their characteristics and limitations. Finally, we summarize current
    challenges and point out future trends of deep learning in sports. Our survey
    provides valuable reference material for researchers interested in deep learning
    in sports applications.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习有可能彻底改变体育表现，其应用范围从感知和理解到决策。本文呈现了深度学习在体育表现中的全面调研，重点关注三个主要方面：算法、数据集和虚拟环境，以及挑战。首先，我们讨论了体育表现中深度学习算法的层级结构，包括感知、理解和决策，并比较了它们的优缺点。其次，我们列出了体育领域广泛使用的现有数据集，并突出其特性和局限性。最后，我们总结了当前挑战，并指出深度学习在体育领域的未来趋势。我们的调研为对深度学习在体育应用中感兴趣的研究人员提供了宝贵的参考资料。
- en: 'Index Terms:'
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 索引词：
- en: Sports Performance, Internet of Things, Computer Vision, Deep Learning, Survey
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 体育表现、物联网、计算机视觉、深度学习、调研
- en: I Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Artificial Intelligence (AI) has found wide-ranging applications and holds a
    bright future in the world of sports. Its ever-growing involvement is set to revolutionize
    the industry in myriad ways, enabling new heights of efficiency and precision.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）在体育领域得到了广泛应用，并且未来充满光明。它日益增长的参与将以各种方式彻底改变这一行业，实现效率和精度的新高度。
- en: A prominent application of AI in sports is the use of deep learning techniques.
    Specifically, these advanced algorithms are utilized in areas like player performance
    analysis, injury prediction, and game strategy formulation [[1](#bib.bib1)]. Through
    capturing and processing large amounts of data, deep learning models can predict
    outcomes, uncover patterns, and formulate strategies that might not be evident
    to the human eye. This seamless integration of deep learning and the sports industry [[2](#bib.bib2),
    [3](#bib.bib3)] exemplifies how technology is enhancing our ability to optimize
    sporting performance and decision-making.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）在体育中的一个重要应用是深度学习技术的使用。具体而言，这些先进的算法被应用于球员表现分析、伤害预测和比赛策略制定等领域[[1](#bib.bib1)]。通过捕获和处理大量数据，深度学习模型能够预测结果、发现模式，并制定可能对人眼不明显的策略。这种深度学习与体育产业的无缝整合[[2](#bib.bib2),
    [3](#bib.bib3)]展示了技术如何提升我们优化运动表现和决策的能力。
- en: '![Refer to caption](img/e53f20952ba8add5a3ca047dd84ead0f.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e53f20952ba8add5a3ca047dd84ead0f.png)'
- en: 'Figure 1: The examples of the applications in sports performance in perception,
    comprehension, and decision.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：在感知、理解和决策中的运动表现应用实例。
- en: Although predicting and optimizing athletic performance has numerous advantages,
    it remains a complex problem. Traditionally, sports experts like coaches, managers,
    scouts, and sports health professionals have relied on conventional analytical
    methods to tackle these challenges. However, gathering statistical data and analyzing
    decisions manually is a demanding and time-consuming endeavor [[4](#bib.bib4)].
    Consequently, an automated system powered by machine learning emerges as a promising
    solution that can revolutionize the sports industry by automating the processing
    of large-scale data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管预测和优化运动表现具有诸多优点，但这仍然是一个复杂的问题。传统上，教练、经理、 scouts和运动健康专业人士等运动专家依赖于传统的分析方法来解决这些挑战。然而，收集统计数据和手动分析决策是一项费力且耗时的工作[[4](#bib.bib4)]。因此，由机器学习驱动的自动化系统作为一种有前景的解决方案，可以通过自动化处理大规模数据来彻底改变体育行业。
- en: In recent years, there has been a notable increase in comprehensive surveys
    exploring the applications of machine learning and deep learning in sports performance.
    These surveys cover a wide range of topics, including the recognition of sports-specific
    movements [[5](#bib.bib5)], mining sports data [[6](#bib.bib6)], and employing
    AI techniques in team sports [[7](#bib.bib7)]. While some surveys focus on specific
    sports like soccer [[7](#bib.bib7)] and badminton [[8](#bib.bib8)], others concentrate
    on particular tasks within computer vision, such as video action recognition [[9](#bib.bib9)],
    video action quality assessment [[10](#bib.bib10)], and ball tracking [[11](#bib.bib11)].
    Furthermore, several studies explore the usage of wearable technology [[12](#bib.bib12),
    [13](#bib.bib13)] and motion capture systems [[14](#bib.bib14)] in sports, with
    a particular emphasis on the Internet of Things (IoT).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，关于机器学习和深度学习在运动表现中的应用的综合调查显著增加。这些调查涵盖了广泛的话题，包括运动特定动作的识别[[5](#bib.bib5)]、运动数据挖掘[[6](#bib.bib6)]，以及在团队运动中应用AI技术[[7](#bib.bib7)]。一些调查专注于特定运动，如足球[[7](#bib.bib7)]和羽毛球[[8](#bib.bib8)]，而其他则集中于计算机视觉中的特定任务，如视频动作识别[[9](#bib.bib9)]、视频动作质量评估[[10](#bib.bib10)]和球类跟踪[[11](#bib.bib11)]。此外，一些研究探讨了可穿戴技术[[12](#bib.bib12),
    [13](#bib.bib13)]和运动捕捉系统[[14](#bib.bib14)]在运动中的使用，特别是物联网（IoT）的重点。
- en: 'Previous studies [[15](#bib.bib15), [16](#bib.bib16)] have employed a hierarchical
    approach to analyze sports performance, starting from lower-level aspects and
    progressing to higher-level components, while also providing training recommendations.
    In order to comprehend the utilization of deep learning in sports, we have segmented
    it into three levels: Perception, Comprehension, and Decision. Additionally, we
    have categorized diverse datasets according to specific sports disciplines and
    outlined the primary challenges associated with deep learning methodologies and
    datasets. Furthermore, we have highlighted the future directions of deep learning
    in motion, based on the current work built upon foundational models.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 先前的研究[[15](#bib.bib15), [16](#bib.bib16)]采用了分层方法来分析运动表现，从低层次的方面开始，逐步过渡到高层次的组件，同时提供了训练建议。为了理解深度学习在运动中的应用，我们将其分为三个层级：感知、理解和决策。此外，我们还根据特定的运动学科对不同的数据集进行了分类，并概述了深度学习方法和数据集的主要挑战。进一步地，我们基于目前在基础模型上建立的工作，突出了深度学习在运动中的未来方向。
- en: The contributions of this comprehensive survey of deep learning in sports performance
    can be summarized in three key aspects.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这项关于深度学习在运动表现中的综合调查的贡献可以总结为三个关键方面。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'We propose a hierarchical structure that systematically divides deep learning
    tasks into three categories: Perception, Comprehension, and Decision, covering
    low-level to high-level tasks.'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种分层结构，将深度学习任务系统地分为三个类别：感知、理解和决策，涵盖了从低层次到高层次的任务。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We provide a summary of sports datasets and virtual environments. Meanwhile,
    this paper covers dozens of sports scenarios, processing both visual information
    and IoT sensor data.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提供了运动数据集和虚拟环境的总结。同时，本文涵盖了几十种运动场景，处理了视觉信息和物联网传感器数据。
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We summarize the current challenges and future feasible research directions
    for deep learning in various sports fields.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们总结了当前深度学习在各个运动领域面临的挑战和未来可行的研究方向。
- en: 'The paper is organized as follows: Section [II](#S2 "II Perception ‣ A Survey
    of Deep Learning in Sports Applications: Perception, Comprehension, and Decision"),
    [III](#S3 "III Comprehension ‣ A Survey of Deep Learning in Sports Applications:
    Perception, Comprehension, and Decision"), and [IV](#S4 "IV Decision ‣ A Survey
    of Deep Learning in Sports Applications: Perception, Comprehension, and Decision")
    introduce different tasks with methods for perception, comprehension, and decision
    tasks in sports. Section [V](#S5 "V Datasets and Benchmarks ‣ A Survey of Deep
    Learning in Sports Applications: Perception, Comprehension, and Decision") and
    [VI](#S6 "VI Virtual Environments ‣ A Survey of Deep Learning in Sports Applications:
    Perception, Comprehension, and Decision") discuss the sports-related datasets
    and virtual environments. In Section [VII](#S7 "VII Challenges ‣ A Survey of Deep
    Learning in Sports Applications: Perception, Comprehension, and Decision") and
    [VIII](#S8 "VIII Future trend ‣ A Survey of Deep Learning in Sports Applications:
    Perception, Comprehension, and Decision"), we highlight the current challenges
    and future trends of deep learning in sports. Lastly, we conclude the paper in
    Section [IX](#S9 "IX Conclusion ‣ A Survey of Deep Learning in Sports Applications:
    Perception, Comprehension, and Decision").'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '本文结构如下：第[II](#S2 "II Perception ‣ A Survey of Deep Learning in Sports Applications:
    Perception, Comprehension, and Decision")、[III](#S3 "III Comprehension ‣ A Survey
    of Deep Learning in Sports Applications: Perception, Comprehension, and Decision")和[IV](#S4
    "IV Decision ‣ A Survey of Deep Learning in Sports Applications: Perception, Comprehension,
    and Decision")部分介绍了不同的感知、理解和决策任务的方法。第[V](#S5 "V Datasets and Benchmarks ‣ A Survey
    of Deep Learning in Sports Applications: Perception, Comprehension, and Decision")和[VI](#S6
    "VI Virtual Environments ‣ A Survey of Deep Learning in Sports Applications: Perception,
    Comprehension, and Decision")部分讨论了与体育相关的数据集和虚拟环境。在第[VII](#S7 "VII Challenges ‣
    A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and
    Decision")和[VIII](#S8 "VIII Future trend ‣ A Survey of Deep Learning in Sports
    Applications: Perception, Comprehension, and Decision")部分，我们强调了深度学习在体育领域中的当前挑战和未来趋势。最后，在第[IX](#S9
    "IX Conclusion ‣ A Survey of Deep Learning in Sports Applications: Perception,
    Comprehension, and Decision")部分我们总结了论文。'
- en: '![Refer to caption](img/9be9fa4c39d50ed84bf65283534b6bcc.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9be9fa4c39d50ed84bf65283534b6bcc.png)'
- en: 'Figure 2: Taxonomy. A hierarchical structure that contains three categories
    of tasks: Perception, Comprehension, and Decision, as well as Benchmark.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：分类。一个包含感知、理解和决策三个类别任务以及基准的层次结构。
- en: II Perception
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 感知
- en: '![Refer to caption](img/b349107968a7e12593a0896ffc3f05c0.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b349107968a7e12593a0896ffc3f05c0.png)'
- en: 'Figure 3: Taxonomy and description of perception tasks.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：感知任务的分类和描述。
- en: 'Perception involves the fundamental interpretation of acquired data. This section
    presents different deep-learning methodologies tailored to specific sports tasks
    at the perception level as shown in Figure [3](#S2.F3 "Figure 3 ‣ II Perception
    ‣ A Survey of Deep Learning in Sports Applications: Perception, Comprehension,
    and Decision"). The subsequent perception segment will encompass tasks such as
    player tracking, player pose recognition, player instance segmentation, ball localization,
    camera calibration etc..'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '感知涉及对获取数据的基本解释。本节介绍了针对特定体育任务的不同深度学习方法，如图[3](#S2.F3 "Figure 3 ‣ II Perception
    ‣ A Survey of Deep Learning in Sports Applications: Perception, Comprehension,
    and Decision")所示。随后的感知部分将包括如球员追踪、球员姿态识别、球员实例分割、球定位、相机标定等任务。'
- en: II-A Player and Ball Localization
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 球员和球的定位
- en: Player and ball localization aims at identifying and determining the spatial
    location of players and balls, which is an essential undertaking in sports video
    analysis. Precisely identifying these entities can provide valuable insights into
    team performance, enabling coaches to make well-informed decisions using data.
    In recent years, numerous deep learning-based techniques have emerged, specifically
    designed for accurately localizing players and balls in a variety of sports, such
    as soccer, basketball, and cricket.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 球员和球的定位旨在识别和确定球员和球的空间位置，这是体育视频分析中的一项重要任务。精确识别这些实体可以提供关于团队表现的宝贵洞察，帮助教练利用数据做出明智的决策。近年来，许多基于深度学习的技术相继出现，专门设计用于在各种体育项目中准确定位球员和球，如足球、篮球和板球。
- en: II-A1 Player Localization
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A1 球员定位
- en: Player localization or detection [[17](#bib.bib17), [18](#bib.bib18), [19](#bib.bib19)]
    serves as a foundation for various downstream applications within the field of
    sports analysis. These applications include identifying player jersey numbers [[20](#bib.bib20),
    [21](#bib.bib21), [22](#bib.bib22)] and teams [[23](#bib.bib23), [24](#bib.bib24)],
    predicting movements and intentions [[25](#bib.bib25), [26](#bib.bib26), [27](#bib.bib27)].
    Some works [[28](#bib.bib28)] leverage advancements in generic object detection
    to enhance the understanding of soccer broadcasts. Others [[24](#bib.bib24)] focus
    on unsupervised methods to differentiate player teams and employ multi-modal and
    multi-view distillation approaches for player detection in amateur sports [[29](#bib.bib29)].
    Vandeghen et al. [[30](#bib.bib30)] introduces a distillation method for semi-supervised
    learning, which significantly reduces the reliance on labeled data. Moreover,
    certain studies [[31](#bib.bib31), [32](#bib.bib32)] utilize player localization
    for action recognition and spotting. Object tracking [[33](#bib.bib33)] is also
    crucial for the temporal localization of players.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 球员定位或检测[[17](#bib.bib17), [18](#bib.bib18), [19](#bib.bib19)]为体育分析领域中的各种下游应用奠定了基础。这些应用包括识别球员的球衣号码[[20](#bib.bib20),
    [21](#bib.bib21), [22](#bib.bib22)]和球队[[23](#bib.bib23), [24](#bib.bib24)]，预测动作和意图[[25](#bib.bib25),
    [26](#bib.bib26), [27](#bib.bib27)]。一些研究[[28](#bib.bib28)]利用通用物体检测的进展来增强对足球广播的理解。其他研究[[24](#bib.bib24)]则专注于无监督方法来区分球队，并采用多模态和多视角蒸馏方法进行业余体育中的球员检测[[29](#bib.bib29)]。Vandeghen等人[[30](#bib.bib30)]引入了一种半监督学习的蒸馏方法，显著减少了对标注数据的依赖。此外，一些研究[[31](#bib.bib31),
    [32](#bib.bib32)]利用球员定位进行动作识别和检测。物体跟踪[[33](#bib.bib33)]对于球员的时间定位也至关重要。
- en: II-A2 Ball Localization
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A2 球的定位
- en: Ball localization provides crucial 3D positional information about the ball,
    which offers comprehensive insights into its movement state [[11](#bib.bib11)].
    This task involves estimating the ball’s diameter in pixels within an image patch
    centered on the ball, and it finds applications in various aspects of game analytics [[34](#bib.bib34)].
    These applications include automated offside detection in soccer [[35](#bib.bib35)],
    release point localization in basketball [[36](#bib.bib36)], and event spotting
    in table tennis [[37](#bib.bib37)].
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 球的定位提供了关于球的关键3D位置信息，这为其运动状态提供了全面的见解[[11](#bib.bib11)]。该任务涉及估计图像块中心的球直径（以像素为单位），并在游戏分析的各个方面有应用[[34](#bib.bib34)]。这些应用包括足球中的自动越位检测[[35](#bib.bib35)]，篮球中的发球点定位[[36](#bib.bib36)]，以及乒乓球中的事件检测[[37](#bib.bib37)]。
- en: Existing solutions often rely on multi-view points [[38](#bib.bib38), [39](#bib.bib39),
    [40](#bib.bib40)] to triangulate the 2D positions of the ball detected in individual
    frames, providing robustness against occlusions that are prevalent in team sports
    such as basketball or American football.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的解决方案通常依赖于多视角[[38](#bib.bib38), [39](#bib.bib39), [40](#bib.bib40)]来三角定位在单个帧中检测到的球的2D位置，提供了对篮球或美式足球等团队运动中常见遮挡的鲁棒性。
- en: However, in single-view ball 3D localization, occlusion becomes a significant
    challenge. Most approaches resort to fitting 3D ballistic trajectories based on
    the 2D detections [[41](#bib.bib41), [40](#bib.bib40)], limiting their effectiveness
    in detecting the ball during free fall when it follows ballistic paths. Nonetheless,
    in many game situations, the ball may be partially visible or fully occluded during
    free fall. Van et al. [[36](#bib.bib36), [42](#bib.bib42)] address these limitations
    by deviating from assumptions of ballistic trajectory, time consistency, and clear
    visibility. They propose an image-based method that detects the ball’s center
    and estimates its size within the image space, bridging the gap between trajectory
    predictions offered by ballistic approaches. Additionally, there are also works
    on reconstructing 3D shuttle trajectories in badminton [[43](#bib.bib43)].
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在单视角球的3D定位中，遮挡成为了一个重要的挑战。大多数方法通过基于2D检测拟合3D弹道轨迹[[41](#bib.bib41), [40](#bib.bib40)]，在球自由落体时跟踪球的效果有限，尤其是在弹道路径上。然而，在许多游戏情况下，球在自由落体过程中可能部分可见或完全被遮挡。Van等人[[36](#bib.bib36),
    [42](#bib.bib42)]通过偏离弹道轨迹、时间一致性和清晰可见性的假设来解决这些限制。他们提出了一种基于图像的方法，检测球的中心并估计其在图像空间中的大小，弥补了弹道方法提供的轨迹预测之间的差距。此外，还有一些关于羽毛球中3D羽毛球轨迹重建的研究[[43](#bib.bib43)]。
- en: II-B Player and Ball Tracking
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 球员和球的跟踪
- en: Player and ball tracking is the process of consistently following and identifying
    the location and motion of objects across consecutive frames. This tracking operation
    is integral to facilitating an automated understanding of sports activities.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 玩家和球的追踪是一个在连续帧之间持续跟踪和识别物体位置与运动的过程。这一追踪操作对于实现对体育活动的自动化理解至关重要。
- en: II-B1 Player Tracking
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B1 玩家追踪
- en: Tracking players in the temporal dimension is immensely valuable for gathering
    player-specific statistics. Recent works [[44](#bib.bib44), [45](#bib.bib45)]
    utilize the SORT algorithm [[46](#bib.bib46)], which combines Kalman filtering
    with the Hungarian algorithm to associate overlapping bounding boxes. Additionally,
    Hurault et al. [[47](#bib.bib47)] employ a self-supervised approach, fine-tuning
    an object detection model trained on generic objects specifically for soccer player
    detection and tracking.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间维度上追踪玩家对于收集特定玩家的统计数据极为宝贵。最近的工作[[44](#bib.bib44), [45](#bib.bib45)] 利用SORT算法[[46](#bib.bib46)]，该算法将卡尔曼滤波与匈牙利算法结合，以关联重叠的边界框。此外，Hurault
    等人[[47](#bib.bib47)]采用自监督方法，对在通用物体上训练的物体检测模型进行微调，专门用于足球玩家的检测和追踪。
- en: In player tracking, a common challenge arises from similar appearances that
    make it difficult to associate detections and maintain identity consistency. Intuitively,
    integrating information from other tasks can assist in tracking. Some works [[48](#bib.bib48)]
    explore patterns in jersey numbers, team classification, and pose-guided partial
    features to handle player identity switches and correlate player IDs using the
    K-shortest path algorithm. In dance scenarios, incorporating skeleton features
    from human pose estimation significantly improves tracking performance in challenging
    scenes with uniform costumes and diverse movements [[49](#bib.bib49)].
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在玩家追踪中，一个常见的挑战是相似的外观使得关联检测和保持身份一致变得困难。从直观上讲，整合其他任务的信息可以帮助追踪。一些工作[[48](#bib.bib48)]
    探索了球衣号码、团队分类和姿态引导的局部特征，以处理玩家身份切换并使用K最短路径算法关联玩家ID。在舞蹈场景中，结合来自人体姿态估计的骨架特征显著提升了在统一服装和多样动作的挑战性场景中的追踪性能[[49](#bib.bib49)]。
- en: To address identity mismatches during occlusions, Naik et al. [[44](#bib.bib44)]
    utilize the difference in jersey color between teams and referees in soccer. They
    update color masks in the tracker module from frame to frame, assigning tracker
    IDs based on jersey color. Additionally, other works [[45](#bib.bib45), [50](#bib.bib50)]
    tackle occlusion issues using DeepSort [[51](#bib.bib51)].
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为解决遮挡期间的身份不匹配，Naik 等人[[44](#bib.bib44)] 利用足球比赛中队伍和裁判的球衣颜色差异。他们在追踪器模块中逐帧更新颜色掩码，根据球衣颜色分配追踪器ID。此外，其他工作[[45](#bib.bib45),
    [50](#bib.bib50)] 使用DeepSort[[51](#bib.bib51)] 处理遮挡问题。
- en: II-B2 Ball Tracking
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B2 球追踪
- en: Accurately recognizing and tracking a high-speed, small ball from raw video
    poses significant challenges. Huang et al. [[52](#bib.bib52)] propose a heatmap-based
    deep learning network [[53](#bib.bib53), [54](#bib.bib54)] to identify the ball
    image in a single frame and learn its flight patterns across consecutive frames.
    Furthermore, precise ball tracking is essential for assisting other tasks, such
    as recognizing spin actions in table tennis [[55](#bib.bib55)] by combining ball
    tracking information.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 准确识别和追踪高速的小球从原始视频中面临重大挑战。Huang 等人[[52](#bib.bib52)] 提出了一种基于热图的深度学习网络[[53](#bib.bib53),
    [54](#bib.bib54)]，用于在单帧中识别球的图像，并学习其在连续帧中的飞行模式。此外，精确的球追踪对于辅助其他任务至关重要，比如通过结合球追踪信息识别乒乓球的旋转动作[[55](#bib.bib55)]。
- en: II-C Player Re-identification
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 玩家再识别
- en: Player re-identification (ReID) is a task of matching and recognizing individuals
    across time and different views. In technical terms, this involves comparing an
    image of a person, referred to as the query, against a collection of other images
    within a large database, known as the gallery, taken from various camera viewpoints.
    In sports, the ReID task aims to re-identify players, coaches, and referees across
    images captured successively from moving cameras [[36](#bib.bib36), [56](#bib.bib56)].
    Challenges such as similar appearances and occlusions and the low resolution of
    player details in broadcast videos make player re-identification a challenging
    task.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 球员重新识别（ReID）是一个在不同时间和视角下匹配和识别个体的任务。在技术术语中，这涉及将一个人的图像（称为查询）与大数据库中的其他图像（称为库）进行比较，这些图像来自不同的摄像头视角。在体育中，ReID任务旨在在从移动摄像头连续捕捉的图像中重新识别球员、教练和裁判。相似的外观、遮挡和广播视频中球员细节的低分辨率等挑战使得球员重新识别成为一项具有挑战性的任务。
- en: Addressing these challenges, many approaches have focused on recognizing jersey
    numbers as a means of identifying players [[22](#bib.bib22), [57](#bib.bib57)],
    or have employed part-based classification techniques [[58](#bib.bib58)]. Recently,
    Teket et al. [[59](#bib.bib59)] proposed a real-time capable pipeline for player
    detection and identification using a Siamese network with a triplet loss to distinguish
    players from each other, without relying on fixed classes or jersey numbers. An et
    al. [[60](#bib.bib60)] introduced a multi-granularity network with an attention
    mechanism for player ReID, while Habel et al. [[61](#bib.bib61)] utilized CLIP
    with InfoNCE loss as an objective, focusing on class-agnostic approaches.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这些挑战，许多方法集中在识别球衣号码以识别球员[[22](#bib.bib22), [57](#bib.bib57)]，或采用基于部件的分类技术[[58](#bib.bib58)]。最近，Teket等人[[59](#bib.bib59)]提出了一种实时能力的管道，使用Siamese网络和三元组损失来区分球员，而无需依赖固定类别或球衣号码。An等人[[60](#bib.bib60)]引入了一种具有注意机制的多粒度网络用于球员ReID，而Habel等人[[61](#bib.bib61)]利用CLIP和InfoNCE损失作为目标，专注于与类别无关的方法。
- en: To address the issue of low-resolution player details in multi-view soccer match
    broadcast videos, Comandur et al. [[56](#bib.bib56)] proposed a model that re-identifies
    players by ranking replay frames based on their distance to a given action frame,
    incorporating a centroid loss, triplet loss, and cross-entropy loss to increase
    the margin between clusters.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决多视角足球比赛广播视频中球员细节低分辨率的问题，Comandur等人[[56](#bib.bib56)]提出了一种模型，通过基于与给定动作帧的距离对回放帧进行排序来重新识别球员，结合了质心损失、三元组损失和交叉熵损失，以增加聚类之间的间距。
- en: In addition, some researchers have explored semi-supervised or weakly supervised
    methods. Maglo et al. [[62](#bib.bib62)] developed a semi-interactive system using
    a transformer-based architecture for player ReID. Similarly, in hockey, Vats et
    al. [[63](#bib.bib63)] employed a weakly-supervised training approach with cross-entropy
    loss to predict jersey numbers as a form of classification.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些研究者探索了半监督或弱监督方法。Maglo等人[[62](#bib.bib62)]开发了一种基于变换器架构的半互动系统，用于球员重新识别（ReID）。类似地，在冰球中，Vats等人[[63](#bib.bib63)]采用了弱监督训练方法，使用交叉熵损失来预测球衣号码，作为分类的一种形式。
- en: II-D Player Instance Segmentation
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-D 球员实例分割
- en: Player instance segmentation aims at assigning pixel-level labels to each player.
    In player instance segmentation, occlusion is the key problem, especially in crowded
    regions, like basketball [[36](#bib.bib36)]. Some works [[64](#bib.bib64), [65](#bib.bib65)]
    utilize online specific copy-paste method [[66](#bib.bib66)] to address the occlusion
    issue.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 球员实例分割的目标是为每个球员分配像素级标签。在球员实例分割中，遮挡是关键问题，尤其是在拥挤的区域，如篮球场[[36](#bib.bib36)]。一些研究[[64](#bib.bib64),
    [65](#bib.bib65)]利用在线特定的复制粘贴方法[[66](#bib.bib66)]来解决遮挡问题。
- en: Moreover, instance segmentation features can be used to distinguish different
    players in team sports with different actions [[24](#bib.bib24), [67](#bib.bib67)].
    In hockey, Koshkina et al. [[24](#bib.bib24)] use Mask R-CNN [[68](#bib.bib68)]
    to detect and segment each person on the playing surface. Zhang et al. [[67](#bib.bib67)]
    utilize the segmentation task to enhance throw action recognition [[67](#bib.bib67)]
    and event spotting [[37](#bib.bib37)].
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，实例分割特征可以用于区分团队运动中不同动作的不同球员[[24](#bib.bib24), [67](#bib.bib67)]。在冰球中，Koshkina等人[[24](#bib.bib24)]使用Mask
    R-CNN[[68](#bib.bib68)]检测并分割场地上的每个人。Zhang等人[[67](#bib.bib67)]利用分割任务来增强投掷动作识别[[67](#bib.bib67)]和事件检测[[37](#bib.bib37)]。
- en: II-E Player Pose Estimation
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 二-E 球员姿势估计
- en: Player pose estimation contributes to predicting the body joint locations and
    their spatial relationships. It often serves as a foundational component for various
    tasks [[69](#bib.bib69)], but there are limited works that specifically address
    the unique characteristics of sports scenes, such as their long processing times,
    reliance on appearance models, and sensitivity to calibration errors and noisy
    detections.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 球员姿势估计有助于预测身体关节位置及其空间关系。它通常作为各种任务的基础组件[[69](#bib.bib69)]，但目前对体育场景的独特特点，如长时间处理、依赖外观模型以及对校准误差和噪声检测的敏感性，还没有特别研究的工作。
- en: Recent approaches have employed OpenPose [[70](#bib.bib70)] for action detection
    or positional predictions of different elements in sports practice [[71](#bib.bib71),
    [72](#bib.bib72), [73](#bib.bib73)]. For sports with rapidly changing player movements,
    such as table tennis, some works [[74](#bib.bib74)] utilize a long short-term
    pose prediction network [[75](#bib.bib75)] to ensure real-time performance. In
    specific actions analysis of sports videos, certain works [[76](#bib.bib76)] use
    pose estimation techniques. Furthermore, Thilakarathne et al. [[77](#bib.bib77)]
    utilize tracked poses as input to enhance group activity recognition in volleyball.
    In more spatial heavy sports where less action or movement is present but more
    complexity lies in the poses, researchers focus on providing practitioners with
    tools to verify the correctness of their poses for more efficient learning, such
    as in Taichi [[78](#bib.bib78)] and Yoga [[79](#bib.bib79)].
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 近期的研究采用了OpenPose [[70](#bib.bib70)]进行动作检测或不同元素在体育实践中的位置预测[[71](#bib.bib71),
    [72](#bib.bib72), [73](#bib.bib73)]。对于像乒乓球这样球员运动迅速变化的体育项目，一些工作[[74](#bib.bib74)]利用了长短期姿势预测网络[[75](#bib.bib75)]以确保实时性能。在对体育视频的具体动作分析中，某些工作[[76](#bib.bib76)]使用了姿势估计技术。此外，Thilakarathne等人[[77](#bib.bib77)]使用跟踪到的姿势作为输入来提高排球中的群体活动识别。在动作较少或运动不频繁而姿势复杂度较高的体育项目中，研究人员致力于为从业者提供验证其姿势正确性的工具，以实现更有效的学习，如太极[[78](#bib.bib78)]和瑜伽[[79](#bib.bib79)]。
- en: II-F Camera Calibration
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 二-F 相机校准
- en: Camera calibration in sports, also known as field registration, aims at estimating
    the intrinsic and extrinsic parameters of cameras. Homography provides a mapping
    between a planar field and the corresponding visible area within an image. Field
    calibration plays a crucial role in tasks that benefit from position information
    within the stadium, such as 3D player tracking on the field. Various approaches
    have been employed to solve sport-field registrations in different sports domains,
    including tennis, volleyball, and soccer [[80](#bib.bib80), [81](#bib.bib81)],
    often relying on keypoint retrieval methods.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 体育镜头校准，也被称为场地注册，旨在估计相机的内外参数。单应性提供了平面场地与图像中相应可见区域之间的映射关系。场地校准在那些受益于体育场馆内球员位置信息的任务中起着至关重要的作用，例如场上的3D球员跟踪。不同的方法已经被用于解决不同体育领域的体育场地注册问题，包括网球、排球和足球[[80](#bib.bib80),
    [81](#bib.bib81)]，通常依靠关键点检索方法。
- en: With the emergence of deep learning, recent approaches focus on learning a representation
    of the visible sports field through various forms of semantic segmentation [[82](#bib.bib82),
    [83](#bib.bib83), [84](#bib.bib84), [32](#bib.bib32)]. These approaches either
    directly predict or regress an initial homography matrix [[85](#bib.bib85), [86](#bib.bib86),
    [87](#bib.bib87)], or search for the best matching homography in a reference database [[84](#bib.bib84),
    [88](#bib.bib88)] that contains synthetic images with known homography matrices
    or camera parameters. In other cases [[83](#bib.bib83), [84](#bib.bib84)], a dictionary
    of camera views is utilized, connecting an image projection of a synthetic reference
    field model to a homography. The segmentation is then linked to the closest synthetic
    view in the dictionary, providing an approximate camera parameter estimate, which
    is further refined for the final prediction.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习的出现，最近的方法聚焦于通过各种形式的语义分割学习可见体育场地的表示[[82](#bib.bib82), [83](#bib.bib83),
    [84](#bib.bib84), [32](#bib.bib32)]。这些方法要么直接预测或回归一个初始单应性矩阵[[85](#bib.bib85), [86](#bib.bib86),
    [87](#bib.bib87)]，要么在参考数据库[[84](#bib.bib84), [88](#bib.bib88)]中搜索最佳匹配的单应性矩阵，该数据库包含具有已知单应性矩阵或相机参数的合成图像。在其他情况下[[83](#bib.bib83),
    [84](#bib.bib84)]，利用一个相机视图字典，将合成参考场地模型的图像投影与单应性联系起来。然后将分割结果与字典中最接近的合成视图关联起来，提供一个近似的相机参数估计，进一步进行最终预测的精炼。
- en: III Comprehension
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 三 理解
- en: '![Refer to caption](img/f2eb22d9757e14fa469762209ce09710.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f2eb22d9757e14fa469762209ce09710.png)'
- en: 'Figure 4: Taxonomy and description of comprehension tasks.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：理解任务的分类和描述。
- en: 'Comprehension can be defined as the process of understanding and analyzing
    data. It involves higher-level tasks compared to the perception stage discussed
    in Section [II](#S2 "II Perception ‣ A Survey of Deep Learning in Sports Applications:
    Perception, Comprehension, and Decision"). In order to achieve a comprehensive
    understanding of sports, the implementation can utilize raw data and directly
    or indirectly incorporate the tasks from the perception layer. Namely, it can
    utilize the outputs obtained from the perception network, such as human skeletons,
    depth images etc.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 理解可以定义为理解和分析数据的过程。它涉及比感知阶段更高级的任务，这在第[II](#S2 "II 感知 ‣ 深度学习在体育应用中的调查：感知、理解和决策")节中有讨论。为了全面理解体育，实施可以利用原始数据，并直接或间接地纳入感知层的任务。也就是说，它可以利用从感知网络获得的输出，例如人体骨架、深度图像等。
- en: 'In this section, we delve into specific tasks related to understanding and
    analyzing sports as shown in Figure [4](#S3.F4 "Figure 4 ‣ III Comprehension ‣
    A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and
    Decision"). These tasks include individual and group action recognition, action
    quality assessment, action spotting, sports video summarization, and captioning.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们深入探讨了与理解和分析体育相关的具体任务，如图[4](#S3.F4 "图 4 ‣ III 理解 ‣ 深度学习在体育应用中的调查：感知、理解和决策")所示。这些任务包括个体和群体动作识别、动作质量评估、动作检测、体育视频总结和字幕生成。
- en: 'TABLE I: Deep learning models for Sports comprehension. “IAR”, “GAR”, “AQA”
    stand for Individual Action Recognition, Group Action Recognition, Action Quality
    Assessment.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：体育理解的深度学习模型。 “IAR”、“GAR”、“AQA”分别代表个体动作识别、群体动作识别和动作质量评估。
- en: '| Task | Method | Venue | Benchmark | Link |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 方法 | 会议 | 基准 | 链接 |'
- en: '| IAR | TSM [[89](#bib.bib89)] | ICCV-2019 | FineGym, P²A | [$\usym{2713}$](https://github.com/mit-han-lab/temporal-shift-module)
    |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| IAR | TSM [[89](#bib.bib89)] | ICCV-2019 | FineGym, P²A | [$\usym{2713}$](https://github.com/mit-han-lab/temporal-shift-module)
    |'
- en: '| CSN [[90](#bib.bib90)] | ICCV-2019 | Sports 1M | [$\usym{2713}$](https://github.com/facebookresearch/VMZ)
    |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| CSN [[90](#bib.bib90)] | ICCV-2019 | Sports 1M | [$\usym{2713}$](https://github.com/facebookresearch/VMZ)
    |'
- en: '| SlowFast [[91](#bib.bib91)] | ICCV-2019 | P²A, Diving48 | [$\usym{2713}$](https://github.com/facebookresearch/SlowFast)
    |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| SlowFast [[91](#bib.bib91)] | ICCV-2019 | P²A, Diving48 | [$\usym{2713}$](https://github.com/facebookresearch/SlowFast)
    |'
- en: '| G-Blend [[92](#bib.bib92)] | CVPR-2020 | Sports 1M | [$\usym{2713}$](https://github.com/facebookresearch/VMZ)
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| G-Blend [[92](#bib.bib92)] | CVPR-2020 | Sports 1M | [$\usym{2713}$](https://github.com/facebookresearch/VMZ)
    |'
- en: '| AGCN [[93](#bib.bib93)] | TIP-2020 | FSD-10 | [$\usym{2713}$](https://github.com/lshiwjx/2s-AGCN)
    |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| AGCN [[93](#bib.bib93)] | TIP-2020 | FSD-10 | [$\usym{2713}$](https://github.com/lshiwjx/2s-AGCN)
    |'
- en: '| ResGCN [[94](#bib.bib94)] | MM-2020 | FSD-10 | [$\usym{2713}$](https://github.com/Thomas-yx/ResGCNv1)
    |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| ResGCN [[94](#bib.bib94)] | MM-2020 | FSD-10 | [$\usym{2713}$](https://github.com/Thomas-yx/ResGCNv1)
    |'
- en: '| MoViNet [[95](#bib.bib95)] | CVPR-2021 | P²A | [$\usym{2713}$](https://github.com/Atze00/MoViNet-pytorch)
    |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| MoViNet [[95](#bib.bib95)] | CVPR-2021 | P²A | [$\usym{2713}$](https://github.com/Atze00/MoViNet-pytorch)
    |'
- en: '| TimeSformer [[96](#bib.bib96)] | ICML-2021 | P²A, Diving48 | [$\usym{2713}$](https://github.com/facebookresearch/TimeSformer)
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| TimeSformer [[96](#bib.bib96)] | ICML-2021 | P²A, Diving48 | [$\usym{2713}$](https://github.com/facebookresearch/TimeSformer)
    |'
- en: '| ViSwin [[97](#bib.bib97)] | arXiv-2021 | P²A | [$\usym{2713}$](https://github.com/SwinTransformer/Video-Swin-Transformer)
    |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| ViSwin [[97](#bib.bib97)] | arXiv-2021 | P²A | [$\usym{2713}$](https://github.com/SwinTransformer/Video-Swin-Transformer)
    |'
- en: '| ORViT [[98](#bib.bib98)] | arXiv-2021 | Diving48 | [$\usym{2713}$](https://github.com/eladb3/ORViT)
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| ORViT [[98](#bib.bib98)] | arXiv-2021 | Diving48 | [$\usym{2713}$](https://github.com/eladb3/ORViT)
    |'
- en: '| BEVT [[99](#bib.bib99)] | arXiv-2021 | Diving48 | [$\usym{2713}$](https://github.com/xyzforever/BEVT)
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| BEVT [[99](#bib.bib99)] | arXiv-2021 | Diving48 | [$\usym{2713}$](https://github.com/xyzforever/BEVT)
    |'
- en: '| VIMPAC [[100](#bib.bib100)] | arXiv-2021 | Diving48 | [$\usym{2713}$](https://github.com/airsplay/vimpac)
    |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| VIMPAC [[100](#bib.bib100)] | arXiv-2021 | Diving48 | [$\usym{2713}$](https://github.com/airsplay/vimpac)
    |'
- en: '| CTR-GCN [[101](#bib.bib101)] | ICCV-2021 | FSD-10 | [$\usym{2713}$](https://github.com/Uason-Chen/CTR-GCN)
    |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| CTR-GCN [[101](#bib.bib101)] | ICCV-2021 | FSD-10 | [$\usym{2713}$](https://github.com/Uason-Chen/CTR-GCN)
    |'
- en: '| GAR | DIN [[102](#bib.bib102)] | ICCV-2021 | Diving48, HierVolleyball-v2
    | [$\usym{2713}$](https://github.com/JacobYuan7/DIN-Group-Activity-Recognition-Benchmark)
    |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| GAR | DIN [[102](#bib.bib102)] | ICCV-2021 | Diving48, HierVolleyball-v2
    | [$\usym{2713}$](https://github.com/JacobYuan7/DIN-Group-Activity-Recognition-Benchmark)
    |'
- en: '| PoseC3D [[103](#bib.bib103)] | CVPR-2022 | FineGym, FSD-10, HierVolleyball-v2
    | [$\usym{2713}$](https://github.com/kennymckormick/pyskl) |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| PoseC3D [[103](#bib.bib103)] | CVPR-2022 | FineGym, FSD-10, HierVolleyball-v2
    | [$\usym{2713}$](https://github.com/kennymckormick/pyskl) |'
- en: '| AQA | S3D [[104](#bib.bib104)] | ICIP-2018 | AQA-7 | [$\usym{2713}$](https://github.com/YeTianJHU/diving-score)
    |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| AQA | S3D [[104](#bib.bib104)] | ICIP-2018 | AQA-7 | [$\usym{2713}$](https://github.com/YeTianJHU/diving-score)
    |'
- en: '| C3D-LSTM [[105](#bib.bib105)] | WACV-2019 | AQA-7 | [$\usym{2713}$](http://rtis.oit.unlv.edu/datasets.html)
    |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| C3D-LSTM [[105](#bib.bib105)] | WACV-2019 | AQA-7 | [$\usym{2713}$](http://rtis.oit.unlv.edu/datasets.html)
    |'
- en: '| C3D-AVG-MTL  [[106](#bib.bib106)] | CVPR-2019 | MTL-AQA | [$\usym{2713}$](https://github.com/ParitoshParmar/MTL-AQA)
    |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| C3D-AVG-MTL [[106](#bib.bib106)] | CVPR-2019 | MTL-AQA | [$\usym{2713}$](https://github.com/ParitoshParmar/MTL-AQA)
    |'
- en: '| C3D-MSLSTM [[107](#bib.bib107)] | TCSVT-2020 | FisV, MIT-Skate | [$\usym{2713}$](https://github.com/loadder/MS_LSTM.git)
    |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| C3D-MSLSTM [[107](#bib.bib107)] | TCSVT-2020 | FisV, MIT-Skate | [$\usym{2713}$](https://github.com/loadder/MS_LSTM.git)
    |'
- en: '| I3D-USDL [[108](#bib.bib108)] | CVPR-2020 | AQA-7, MTL-AQA | [$\usym{2713}$](https://github.com/nzl-thu/MUSDL)
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| I3D-USDL [[108](#bib.bib108)] | CVPR-2020 | AQA-7, MTL-AQA | [$\usym{2713}$](https://github.com/nzl-thu/MUSDL)
    |'
- en: '| TSA [[109](#bib.bib109)] | ACM MM 2021 | FR-FS, AQA-7, MTL-AQA | [$\usym{2713}$](https://github.com/Shunli-Wang/TSA-Net)
    |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| TSA [[109](#bib.bib109)] | ACM MM 2021 | FR-FS, AQA-7, MTL-AQA | [$\usym{2713}$](https://github.com/Shunli-Wang/TSA-Net)
    |'
- en: III-A Individual Action Recognition
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 个人动作识别
- en: Player action recognition targets classifying and detecting specific human action.
    Individual action recognition is commonly used for automated statistical analysis
    of individual sports, such as counting the occurrences of specific actions. Moreover,
    it plays a crucial role in analyzing tactics, identifying key moments in matches,
    and tracking player activity, including metrics like running distance and performance.
    This analysis can assist players and coaches in identifying the essential technical
    factors required for achieving better results. In team sports, coaches need to
    monitor all players on the field and their respective actions, particularly how
    they execute them. Therefore, an automated system capable of tracking all these
    elements could greatly contribute to the players’ success. However, this casts
    a significant challenge for computers due to the simultaneous occurrence of different
    actions by multiple players on the sports field, leading to issues such as occlusion
    and confusing scenes.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 玩家动作识别旨在对特定的人类动作进行分类和检测。个人动作识别常用于自动统计分析个别运动，例如计数特定动作的发生次数。此外，它在分析战术、识别比赛中的关键时刻以及跟踪玩家活动（包括跑动距离和表现等指标）中发挥了重要作用。这种分析可以帮助玩家和教练识别实现更好结果所需的关键技术因素。在团队运动中，教练需要监控场上所有球员及其各自的动作，特别是他们如何执行这些动作。因此，一个能够跟踪所有这些元素的自动化系统可能对球员的成功有很大贡献。然而，这对计算机提出了重大挑战，因为多个球员在运动场上同时进行不同的动作，导致遮挡和混乱场景等问题。
- en: While end-to-end models [[96](#bib.bib96), [97](#bib.bib97), [110](#bib.bib110)]
    are commonly employed in the literature on video action recognition, they are
    often better suited for coarse-grained classification tasks [[111](#bib.bib111),
    [112](#bib.bib112), [113](#bib.bib113)], which focus on broader categories like
    punches or kicks. In contrast, most sports require more fine-grained methods capable
    of distinguishing between specific techniques within these broader categories [[114](#bib.bib114),
    [115](#bib.bib115)].
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在视频动作识别的文献中，端到端模型 [[96](#bib.bib96), [97](#bib.bib97), [110](#bib.bib110)]
    常被采用，但它们通常更适合于粗粒度分类任务 [[111](#bib.bib111), [112](#bib.bib112), [113](#bib.bib113)]，这些任务关注如拳击或踢腿等更广泛的类别。相比之下，大多数运动需要更细粒度的方法，能够区分这些更广泛类别中的具体技术
    [[114](#bib.bib114), [115](#bib.bib115)]。
- en: Fine-grained action recognition within a single sport can help mitigate contextual
    biases present in coarse-grained tasks, making it an increasingly important research
    area [[114](#bib.bib114), [116](#bib.bib116), [117](#bib.bib117)]. Skeleton-based
    methods [[118](#bib.bib118), [119](#bib.bib119), [120](#bib.bib120)] have gained
    popularity for fine-grained action recognition in body-centric sports. These approaches
    utilize 2D or 3D human pose as input for recognizing human actions. By representing
    the human skeleton as a graph with joint positions as nodes and modeling the movement
    as changes in these graph coordinates over time, both the spatial and temporal
    aspects of the action can be captured. Additionally, some works [[121](#bib.bib121),
    [122](#bib.bib122), [123](#bib.bib123)] focus on fine-grained action recognition
    in sports that do not involve body-centric actions.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 单一运动中的细粒度动作识别有助于减轻粗粒度任务中存在的上下文偏差，使其成为一个越来越重要的研究领域[[114](#bib.bib114), [116](#bib.bib116),
    [117](#bib.bib117)]。基于骨架的方法[[118](#bib.bib118), [119](#bib.bib119), [120](#bib.bib120)]在以身体为中心的运动中获得了广泛的关注。这些方法利用2D或3D人体姿态作为输入来识别人体动作。通过将人体骨架表示为一个图，关节位置作为节点，并将运动建模为这些图坐标随时间变化，可以捕捉动作的空间和时间方面。此外，一些研究[[121](#bib.bib121),
    [122](#bib.bib122), [123](#bib.bib123)]专注于不涉及身体中心动作的运动中的细粒度动作识别。
- en: III-B Group Action Recognition
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 群体动作识别
- en: Group activity recognition involves recognizing activities performed by multiple
    individuals or objects. It plays a significant role in automated human behavior
    analysis in various fields, including sports, healthcare, and surveillance. Unlike
    multi-player activity recognition, group / team action recognition focuses on
    identifying a single group action that arises from the collective actions and
    interactions of each player within the group. This poses greater challenges compared
    to individual action recognition and requires the integration of multiple computer
    vision techniques.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 群体活动识别涉及识别由多个个体或物体执行的活动。在运动、医疗保健和监控等多个领域中，它在自动化人类行为分析中扮演着重要角色。与多玩家活动识别不同，群体/团队动作识别专注于识别从群体内每个玩家的集体动作和交互中产生的单一群体动作。这比个体动作识别面临更大的挑战，需要整合多种计算机视觉技术。
- en: Due to the involvement of multiple players, modeling player interaction relations
    becomes essential in group action analysis. In general, actor interaction relations
    can be modeled using graph convolutional networks (GCN) or Transformers in various
    methods. Transformer-based methods [[124](#bib.bib124), [125](#bib.bib125), [126](#bib.bib126),
    [127](#bib.bib127), [128](#bib.bib128), [129](#bib.bib129)] often explicitly represent
    spatiotemporal relations and employ attention-based techniques to model individual
    relations for inferring group activity. GCN-based methods [[130](#bib.bib130),
    [102](#bib.bib102)] construct relational graphs of the actors and simultaneously
    explore spatial and temporal actor interactions using graph convolution networks.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 由于涉及多个参与者，建模参与者交互关系在群体行为分析中变得至关重要。一般而言，演员交互关系可以使用图卷积网络（GCN）或变换器进行建模。基于变换器的方法[[124](#bib.bib124),
    [125](#bib.bib125), [126](#bib.bib126), [127](#bib.bib127), [128](#bib.bib128),
    [129](#bib.bib129)]通常明确表示时空关系，并采用基于注意力的技术来建模个体关系以推断群体活动。基于GCN的方法[[130](#bib.bib130),
    [102](#bib.bib102)]构建演员的关系图，并同时使用图卷积网络探索空间和时间的演员交互。
- en: Among them, Yan et al. [[126](#bib.bib126)] construct separate spatial and temporal
    relation graphs to model actor relations. Gavrilyuk et al. [[124](#bib.bib124)]
    encode temporal information using I3D [[111](#bib.bib111)] and establish spatial
    relations among actors using a vanilla transformer. Li et al. [[129](#bib.bib129)]
    introduces a cluster attention mechanism. Dual-AI [[131](#bib.bib131)] proposes
    a dual-path role interaction framework for group behavior recognition, incorporating
    temporal encoding of the actor into the transformer architecture. Moreover, the
    use of simple multi-layer perceptrons (MLP) for feature extraction in group activity
    analysis [[132](#bib.bib132)] is an emerging approach with great potential.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，Yan等人[[126](#bib.bib126)]构建了独立的空间和时间关系图来建模演员关系。Gavrilyuk等人[[124](#bib.bib124)]使用I3D
    [[111](#bib.bib111)]对时间信息进行编码，并使用普通变换器建立演员之间的空间关系。Li等人[[129](#bib.bib129)]引入了一个集群注意机制。Dual-AI
    [[131](#bib.bib131)]提出了一种双路径角色交互框架用于群体行为识别，将演员的时间编码纳入变换器架构。此外，在群体活动分析中使用简单的多层感知器（MLP）进行特征提取[[132](#bib.bib132)]是一种具有巨大潜力的新兴方法。
- en: Moreover, some other works focus more on specific action recognition through
    temporal localization rather than classification. Several automated methods have
    been proposed to identify important actions in a game by analyzing camera shots
    or semantic information. Studies [[133](#bib.bib133), [134](#bib.bib134), [135](#bib.bib135)]
    have explored human activity localization in sports videos, salient game action
    identification [[136](#bib.bib136), [137](#bib.bib137)], and automatic identification
    and summarization of game highlights [[138](#bib.bib138), [139](#bib.bib139),
    [140](#bib.bib140)]. Recent methods are more on soccer. For instance, Giancola et
    al. [[141](#bib.bib141)] introduce the concept of accurately identifying and localizing
    specific actions within uncut soccer broadcast videos. More recently, innovative
    methodologies have emerged in this field, aiming to automate the process. Cioppa et
    al. [[142](#bib.bib142)] propose the application of a context-aware loss function
    to enhance model performance. They later demonstrated how integrating camera calibration
    and player localization features can improve spotting capabilities [[32](#bib.bib32)].
    Hong et al. [[143](#bib.bib143)] propose an efficient end-to-end training approach,
    while Darwish et al. [[144](#bib.bib144)] utilize spatiotemporal encoders. Alternative
    strategies, such as graph-based techniques [[145](#bib.bib145)] and transformer-based
    methods [[146](#bib.bib146)], offer fresh perspectives, particularly in handling
    relational data and addressing long-range dependencies. Lastly, Soares et al. [[147](#bib.bib147),
    [148](#bib.bib148)] have highlighted the potential of anchor-based methods in
    precise action localization and categorization.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，其他一些工作更关注通过时间定位进行特定动作识别，而非分类。已经提出了几种自动化方法，通过分析摄像机镜头或语义信息来识别游戏中的重要动作。研究[[133](#bib.bib133),
    [134](#bib.bib134), [135](#bib.bib135)]探索了体育视频中的人类活动定位，显著游戏动作识别[[136](#bib.bib136),
    [137](#bib.bib137)]，以及游戏亮点的自动识别和总结[[138](#bib.bib138), [139](#bib.bib139), [140](#bib.bib140)]。近期的方法更多集中在足球上。例如，Giancola等[[141](#bib.bib141)]引入了在未剪辑的足球广播视频中准确识别和定位特定动作的概念。最近，该领域出现了创新的方法，旨在自动化该过程。Cioppa等[[142](#bib.bib142)]提出应用上下文感知损失函数以增强模型性能。他们后来展示了如何通过整合摄像机校准和球员定位特征来提高发现能力[[32](#bib.bib32)]。Hong等[[143](#bib.bib143)]提出了一种高效的端到端训练方法，而Darwish等[[144](#bib.bib144)]利用了时空编码器。图形基技术[[145](#bib.bib145)]和基于变换器的方法[[146](#bib.bib146)]等替代策略提供了新视角，特别是在处理关系数据和解决长程依赖性方面。最后，Soares等[[147](#bib.bib147),
    [148](#bib.bib148)]强调了基于锚点的方法在精确动作定位和分类中的潜力。
- en: III-C Action Quality Assessment
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 行动质量评估
- en: 'Action quality assessment (AQA) is a method used to evaluate and quantify the
    overall performance or proficiency of human actions based on the analysis of video
    or motion data. AQA takes into account criteria such as technique, speed, and
    control to assess the movement and assign a score, which can be used to guide
    training and rehabilitation programs. AQA has proven to be reliable and valid
    for assessing movement quality across various sports. Research in this field primarily
    focuses on analyzing the actions of athletes in the Olympic Games, such as diving,
    gymnastics, and other sports mentioned in Section [V](#S5 "V Datasets and Benchmarks
    ‣ A Survey of Deep Learning in Sports Applications: Perception, Comprehension,
    and Decision"). Existing methods typically approach AQA as a regression task using
    various video representations supervised by scores.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '行动质量评估（AQA）是一种用于评估和量化基于视频或运动数据分析的人类动作总体表现或熟练度的方法。AQA考虑了技术、速度和控制等标准来评估动作并赋予分数，这些分数可用于指导训练和康复计划。AQA已被证明在评估各种体育运动的动作质量方面可靠有效。该领域的研究主要集中在分析奥运会运动员的动作，如跳水、体操以及第[V](#S5
    "V Datasets and Benchmarks ‣ A Survey of Deep Learning in Sports Applications:
    Perception, Comprehension, and Decision")节提到的其他运动。现有的方法通常将AQA视为回归任务，使用各种视频表示通过分数进行监督。'
- en: Some studies concentrate on enhancing network structures to extract more distinct
    features. For instance, Xu et al. [[107](#bib.bib107)] propose self-attentive
    LSTM and multi-scale convolutional skip LSTM models to predict Total Element Score (TES)
    and Total Program Component Score (PCS) in figure skating by capturing local and
    global sequential information in long-term videos. Xiang et al. [[104](#bib.bib104)]
    divide the diving process into four stages and employ four independent P3D models
    for feature extraction. Pan et al.[[149](#bib.bib149)] develop a graph-based joint
    relation model that analyzes human node motion using the joint commonality module
    and the joint difference module. Parisi et al. [[150](#bib.bib150)] propose a
    recurrent neural network with a growing self-organizing structure to learn body
    motion sequences and facilitate matching. Kim et al. [[151](#bib.bib151)] model
    the action as a structured process and encode action units using an LSTM network.
    Wang et al. [[109](#bib.bib109)] introduce a tube self-attention module for feature
    aggregation, enabling efficient generation of spatial-temporal contextual information
    through sparse feature interactions. Yu et al. [[152](#bib.bib152)] construct
    a contrastive regression framework based on video-level features to rank videos
    and predict accurate scores.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究集中于增强网络结构以提取更明显的特征。例如，Xu 等人[[107](#bib.bib107)] 提出了自注意力 LSTM 和多尺度卷积跳跃 LSTM
    模型，通过捕捉长期视频中的局部和全局序列信息来预测花样滑冰中的总元素得分 (TES) 和总程序组件得分 (PCS)。Xiang 等人[[104](#bib.bib104)]
    将跳水过程分为四个阶段，并采用四个独立的 P3D 模型进行特征提取。Pan 等人[[149](#bib.bib149)] 开发了一种基于图的联合关系模型，该模型通过关节共性模块和关节差异模块分析人体关节运动。Parisi
    等人[[150](#bib.bib150)] 提出了一个具有自组织结构的递归神经网络，以学习身体运动序列并促进匹配。Kim 等人[[151](#bib.bib151)]
    将动作建模为一个结构化过程，并使用 LSTM 网络编码动作单元。Wang 等人[[109](#bib.bib109)] 引入了一个管道自注意力模块用于特征聚合，通过稀疏特征交互高效生成时空上下文信息。Yu
    等人[[152](#bib.bib152)] 构建了一个基于视频级特征的对比回归框架，以对视频进行排序并预测准确的得分。
- en: 'Other studies focus on improving the performance of action quality assessment
    by designing network loss functions. Li et al. [[153](#bib.bib153)] propose an
    end-to-end framework that employs C3D as a feature extractor and integrates a
    ranking loss with the mean squared error (MSE) loss. Parmar et al. [[106](#bib.bib106)]
    explore the AQA model in a multi-task learning scenario by introducing three parallel
    prediction tasks: action recognition, comment generation, and AQA score regression.
    Tang et al. [[108](#bib.bib108)] propose an uncertainty-aware score distribution
    learning approach that takes into account difficulty levels during the modeling
    process, resulting in a more realistic simulation of the scoring process.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 其他研究则专注于通过设计网络损失函数来提高动作质量评估的性能。Li 等人[[153](#bib.bib153)] 提出了一个端到端的框架，该框架采用 C3D
    作为特征提取器，并将排名损失与均方误差 (MSE) 损失相结合。Parmar 等人[[106](#bib.bib106)] 通过引入三个并行预测任务：动作识别、评论生成和
    AQA 得分回归，探索了多任务学习场景下的 AQA 模型。Tang 等人[[108](#bib.bib108)] 提出了一种不确定性感知得分分布学习方法，该方法在建模过程中考虑了难度水平，从而更真实地模拟了评分过程。
- en: Furthermore, some studies focus on comparing the quality of paired actions.
    Bertasius et al. [[154](#bib.bib154)] propose a model for basketball games based
    on first-person perspective videos, utilizing a convolutional-LSTM network to
    detect events and evaluate the quality of any two movements.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些研究集中于比较配对动作的质量。Bertasius 等人[[154](#bib.bib154)] 提出了一个基于第一人称视角视频的篮球比赛模型，利用卷积-LSTM
    网络检测事件并评估任意两个动作的质量。
- en: III-D Sports Video Summarization
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-D 体育视频摘要
- en: Sports video summarization aims at generating concise and coherent summaries
    that capture the key information. It often prioritizes the recognition of player
    actions [[155](#bib.bib155)]. This research field aims to generate highlights
    of broadcasted sports videos, as these videos are often too lengthy for audiences
    to watch in their entirety. Given that many sports matches can have durations
    of 90-180 minutes, it becomes a challenging task to create a summary that includes
    only the most interesting and exciting events.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 体育视频摘要的目的是生成简明而连贯的总结，以捕捉关键信息。它通常优先识别球员动作[[155](#bib.bib155)]。这一研究领域旨在生成广播体育视频的亮点，因为这些视频通常过于冗长，观众无法完整观看。考虑到许多体育比赛的持续时间可能为
    90-180 分钟，创建一个仅包含最有趣和令人兴奋事件的摘要成为一项具有挑战性的任务。
- en: Agyeman et al. [[155](#bib.bib155)] employ a 3D ResNet CNN and LSTM-based deep
    model to detect five different soccer sports action classes. Rafiq et al. [[156](#bib.bib156)]
    propose a transfer learning-based classification framework for categorizing cricket
    match clips [[157](#bib.bib157)] into five classes, utilizing a pre-trained AlexNet
    CNN and data augmentation. Shingrakhia et al. [[158](#bib.bib158)] present a multimodal
    hybrid approach for classifying sports video segments, utilizing the hybrid rotation
    forest deep belief network and a stacked RNN with deep attention for the identification
    of key events. Li et al. [[159](#bib.bib159)] propose a supervised action proposal
    guided Q-learning based hierarchical refinement approach for structure-adaptive
    summarization of soccer videos. While current research in sports video summarization
    focuses on specific sports, further efforts are needed to develop a generic framework
    that can support different types of sports videos.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Agyeman等人[[155](#bib.bib155)]采用了3D ResNet CNN和基于LSTM的深度模型来检测五种不同的足球运动动作类别。Rafiq等人[[156](#bib.bib156)]提出了一种基于迁移学习的分类框架，用于将板球比赛片段[[157](#bib.bib157)]分类为五个类别，利用预训练的AlexNet
    CNN和数据增强。Shingrakhia等人[[158](#bib.bib158)]提出了一种多模态混合方法来分类体育视频片段，利用混合旋转森林深度置信网络和带有深度注意力的堆叠RNN来识别关键事件。Li等人[[159](#bib.bib159)]提出了一种监督性动作提议指导的Q学习基于层次细化的方法，用于足球视频的结构自适应摘要。尽管当前体育视频摘要研究关注于特定运动，但仍需要进一步努力开发可以支持不同类型体育视频的通用框架。
- en: III-E Captioning
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-E 字幕生成
- en: Sports video captioning involves generating descriptive and coherent textual
    descriptions. Sports video captioning models are designed to generate sentences
    that provide specific details related to a particular sport, which is a multimodal [[160](#bib.bib160)]
    task. For instance, in basketball, Yu et al. [[161](#bib.bib161)] propose a structure
    that consists of a CNN model for categorizing pixels into classes such as the
    ball, teams, and background, a model that captures player movements using optical
    flow features, and a component that models player relationships. These components
    are combined in a hierarchical structure to generate captions for NBA basketball
    videos. Similarly, attention mechanisms and hierarchical recurrent neural networks
    have been employed for captioning volleyball videos [[162](#bib.bib162)].
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 体育视频字幕生成涉及生成描述性和连贯的文本描述。体育视频字幕生成模型旨在生成提供与特定运动相关的详细信息的句子，这是一项多模态[[160](#bib.bib160)]任务。例如，在篮球中，Yu等人[[161](#bib.bib161)]提出了一种结构，该结构包含一个用于将像素分类为球、球队和背景等类别的CNN模型，一个利用光流特征捕捉球员动作的模型，以及一个建模球员关系的组件。这些组件在层次结构中结合，以生成NBA篮球视频的字幕。同样，注意力机制和层次递归神经网络已被用于生成排球视频的字幕[[162](#bib.bib162)]。
- en: Furthermore, the utilization of multiple modalities can be extended to explore
    the creation of detailed captions or narratives for sports videos. Qi et al. [[163](#bib.bib163)]
    and Yu et al. [[164](#bib.bib164)] have successfully generated fine-grained textual
    descriptions for sports videos by incorporating attention mechanisms that consider
    motion modeling and contextual information related to groups and relationships.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，利用多种模态可以扩展到探索创建体育视频的详细字幕或叙述。Qi等人[[163](#bib.bib163)]和Yu等人[[164](#bib.bib164)]通过结合考虑运动建模和与群体及关系相关的上下文信息的注意力机制，成功生成了体育视频的细粒度文本描述。
- en: IV Decision
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 决策
- en: '![Refer to caption](img/84e6c901ff4ba028c6ed59cbb58f74a3.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/84e6c901ff4ba028c6ed59cbb58f74a3.png)'
- en: 'Figure 5: Taxonomy and description of decision tasks.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：决策任务的分类和描述。
- en: 'The decision or decision-making process in sports involves the highest level
    of tasks, where the deployment or implicit perception and understanding of sports
    are essential before generating more abstract decisions. This section encompasses
    various tasks such as match evaluation, play forecasting, game simulation, player
    motion generation, and match generation as shown in Figure [5](#S4.F5 "Figure
    5 ‣ IV Decision ‣ A Survey of Deep Learning in Sports Applications: Perception,
    Comprehension, and Decision").'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '体育中的决策或决策过程涉及到最高级别的任务，其中在生成更抽象的决策之前，体育的部署或隐含感知与理解至关重要。本节包括各种任务，如比赛评估、比赛预测、游戏模拟、球员动作生成和比赛生成，如图[5](#S4.F5
    "Figure 5 ‣ IV Decision ‣ A Survey of Deep Learning in Sports Applications: Perception,
    Comprehension, and Decision")所示。'
- en: IV-A Match Evaluation
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 比赛评估
- en: Match evaluation involves analyzing and assessing various aspects of a sport
    match, such as player performance, team strategies, and game dynamics. This task
    requires match modeling, often employing deep reinforcement learning methods.
    For instance, Wang et al. [[165](#bib.bib165)] develop a deep reinforcement learning
    model to study NBA games with the goal of minimizing offensive scores. Luo et
    al. [[166](#bib.bib166)] combine Q-function learning and inverse reinforcement
    learning to devise a unique ranking method and an alternating learning framework
    for a multi-agent ice hockey Markov game. Liu et al. [[167](#bib.bib167)] value
    player actions under different game contexts using Q-function learning and introduce
    a new player evaluation metric called the Game Impact Metric. Yanai et al. [[168](#bib.bib168)]
    model basketball games by extending the DDPG [[169](#bib.bib169)] architecture
    to evaluate the performance of players and teams.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 比赛评估涉及分析和评估体育比赛的各个方面，例如球员表现、团队策略和比赛动态。这个任务需要比赛建模，通常采用深度强化学习方法。例如，王等人[[165](#bib.bib165)]开发了一个深度强化学习模型来研究NBA比赛，目的是最小化进攻得分。罗等人[[166](#bib.bib166)]结合了Q-函数学习和逆向强化学习，设计了一种独特的排名方法和一个用于多智能体冰球马尔可夫游戏的交替学习框架。刘等人[[167](#bib.bib167)]在不同的游戏背景下使用Q-函数学习来评估球员行为，并引入了一种新的球员评估指标，称为游戏影响指标。矢内等人[[168](#bib.bib168)]通过扩展DDPG[[169](#bib.bib169)]架构来建模篮球比赛，以评估球员和球队的表现。
- en: IV-B Play Forecasting
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 比赛预测
- en: Play Forecasting aims at predicting the future actions, strategies, or outcomes
    of a game or play, leveraging machine learning models to anticipate player movements,
    team tactics, and potential game changing events. The availability of accurate
    player and ball tracking data in professional sports venues has generated interest
    in assisting coaches and analysts with data-driven predictive models of player
    or team behavior [[170](#bib.bib170), [171](#bib.bib171)]. Several studies have
    utilized multiple years of match data to predict various aspects, such as predicting
    the ball placement in tennis [[172](#bib.bib172), [173](#bib.bib173)] and the
    likelihood of winning a point [[174](#bib.bib174)]. Le et al. [[175](#bib.bib175)]
    focus on predicting how NBA defenses will react to different offensive plays,
    while Power et al. [[176](#bib.bib176)] analyze the risk-reward of passes in soccer.
    In a more recent work, Wang et al. [[177](#bib.bib177)] delve into the analysis
    of where and what strokes to return in badminton.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 比赛预测旨在预测游戏或比赛的未来动作、策略或结果，利用机器学习模型来预判球员动作、团队战术和潜在的游戏变化事件。在职业体育场馆中准确的球员和球的追踪数据的可用性引起了对利用数据驱动的预测模型来帮助教练和分析师的兴趣[[170](#bib.bib170),
    [171](#bib.bib171)]。一些研究利用了多年的比赛数据来预测各种方面，如预测网球中的球位置[[172](#bib.bib172), [173](#bib.bib173)]和赢得一个分数的可能性[[174](#bib.bib174)]。乐等人[[175](#bib.bib175)]专注于预测NBA防守如何应对不同的进攻战术，而Power等人[[176](#bib.bib176)]分析了足球中传球的风险与回报。在最近的一项工作中，王等人[[177](#bib.bib177)]深入分析了羽毛球中应该返回的位置和击球类型。
- en: IV-C Game Simulators
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 游戏模拟器
- en: 'Game simulators typically aim at creating virtual environments that mimic real
    sports games, allowing for realistic simulations and the generation of training
    data [[178](#bib.bib178), [179](#bib.bib179), [180](#bib.bib180), [181](#bib.bib181)].
    These virtual environments, which are discussed in detail in Section [VI](#S6
    "VI Virtual Environments ‣ A Survey of Deep Learning in Sports Applications: Perception,
    Comprehension, and Decision"), allow agents to move freely based on specific algorithms,
    simulating real-world sports scenarios. Within such environments, deep reinforcement
    learning (DRL) algorithms have shown remarkable performance in sport-related tasks.
    Zhao et al. [[182](#bib.bib182)] propose a hierarchical learning approach within
    a multi-agent reinforcement framework to emulate human performance in sports games.
    Jia et al. [[183](#bib.bib183)] address the challenges of asynchronous real-time
    scenarios in a basketball sports environment, supporting both single-agent and
    multi-agent training.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏模拟器通常旨在创建模拟真实体育比赛的虚拟环境，以便进行逼真的模拟和生成训练数据 [[178](#bib.bib178), [179](#bib.bib179),
    [180](#bib.bib180), [181](#bib.bib181)]。这些虚拟环境在[第 VI 部分](#S6 "VI 虚拟环境 ‣ 深度学习在体育应用中的调查：感知、理解和决策")中有详细讨论，允许代理根据特定算法自由移动，从而模拟现实世界的体育场景。在这种环境中，深度强化学习（DRL）算法在与体育相关的任务中表现出色。赵等人 [[182](#bib.bib182)]
    在多代理强化框架中提出了一种分层学习方法，以模拟体育比赛中的人类表现。贾等人 [[183](#bib.bib183)] 解决了篮球体育环境中异步实时场景的挑战，支持单代理和多代理训练。
- en: The soccer virtual environment GFootball has gained significant attention in
    recent years [[181](#bib.bib181)]. In the 2020 Google Research Football Competition,
    the winning team, WeKick [[184](#bib.bib184)], developed a powerful agent using
    imitation learning and distributed league training. However, WeKick is specifically
    designed for single-agent AI and cannot be extended to multi-agent control. To
    address this limitation, Huang et al. [[185](#bib.bib185)] propose TiKick, an
    offline multi-agent algorithm that completes full games in GFootball using replay
    data generated by WeKick [[185](#bib.bib185)]. Another approach, Tizero [[186](#bib.bib186)],
    trains agents from scratch without pre-collected data and employs a self-improvement
    process to develop high-quality AI for multi-agent control [[186](#bib.bib186)].
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 足球虚拟环境 GFootball 近年来受到广泛关注 [[181](#bib.bib181)]。在2020年谷歌研究足球竞赛中，获胜团队 WeKick [[184](#bib.bib184)]
    开发了一种强大的代理，使用了模仿学习和分布式联赛训练。然而，WeKick 专门设计用于单代理 AI，无法扩展到多代理控制。为了解决这一限制，黄等人 [[185](#bib.bib185)]
    提出了 TiKick，一种离线多代理算法，利用 WeKick 生成的重播数据完成 GFootball 中的完整比赛 [[185](#bib.bib185)]。另一种方法，Tizero [[186](#bib.bib186)]，从零开始训练代理，未使用预先收集的数据，并采用自我改进过程开发高质量的多代理控制
    AI [[186](#bib.bib186)]。
- en: Although DRL systems have made significant progress, they continue to encounter
    challenges in several areas, including multi-agent coordination, long-term planning,
    and non-transitivity [[187](#bib.bib187), [188](#bib.bib188), [189](#bib.bib189)].
    These challenges highlight the complexity of developing AI systems that can effectively
    coordinate with multiple agents, make strategic decisions over extended periods,
    and account for non-transitive relationships in dynamic environments. Further
    research and advancements in these areas are crucial for enhancing the capabilities
    of DRL systems.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 DRL 系统取得了显著进展，但在多个领域仍面临挑战，包括多代理协调、长期规划和非传递性 [[187](#bib.bib187), [188](#bib.bib188),
    [189](#bib.bib189)]。这些挑战突显了开发能够有效协调多个代理、在较长时间内做出战略决策并考虑动态环境中的非传递性关系的 AI 系统的复杂性。进一步的研究和进展对于提升
    DRL 系统的能力至关重要。
- en: IV-D Player Motion Synthesizing
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-D 玩家运动合成
- en: Utilizing video-based sequences to capture and analyze player movements represents
    a powerful approach to enhancing data diversity in sports. This innovative initiative
    has the potential to make a positive impact on the development of sports disciplines.
    Through detailed analysis and reproduction of player movements, we can gain valuable
    insights that have the potential to improve techniques, elevate athletic performance,
    and drive progress in the world of sports. This pioneering endeavor holds great
    promise for advancing the field and benefiting athletes and sports enthusiasts
    alike.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 利用基于视频的序列来捕捉和分析运动员的动作，代表了一种增强体育数据多样性的强大方法。这一创新举措有潜力对体育学科的发展产生积极影响。通过对运动员动作的详细分析和重现，我们可以获得有价值的见解，这些见解有可能改善技术、提升运动表现，并推动体育领域的进步。这一开创性工作对推进该领域并造福运动员和体育爱好者都具有巨大潜力。
- en: IV-D1 Auto Choreographer
  id: totrans-127
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-D1 自动编舞师
- en: Creating choreography involves the creative design of dance movements. However,
    automating the choreography process computationally is a challenging task. It
    requires generating continuous and complex motion that captures the intricate
    relationship with accompanying music.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 创建编舞涉及到舞蹈动作的创意设计。然而，自动化编舞过程是一个具有挑战性的任务。它需要生成连续且复杂的动作，以捕捉与伴随音乐的微妙关系。
- en: Music-to-dance motion generation can be approached from both 2D and 3D perspectives.
    2D approaches [[190](#bib.bib190), [191](#bib.bib191), [192](#bib.bib192)] rely
    on accurate 2D pose detectors [[193](#bib.bib193)] but have limitations in terms
    of expressiveness and downstream applications. On the other hand, 3D dance generation
    methods utilize techniques such as LSTMs [[194](#bib.bib194), [195](#bib.bib195),
    [196](#bib.bib196), [197](#bib.bib197), [198](#bib.bib198)], GANs [[199](#bib.bib199),
    [200](#bib.bib200)], transformer encoders with the RNN decoder [[201](#bib.bib201)]
    or transformer decoder [[202](#bib.bib202)], and convolutional sequence-to-sequence
    models [[203](#bib.bib203), [204](#bib.bib204)] to generate motion from audio.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 音乐到舞蹈动作生成可以从2D和3D两个角度来探讨。2D方法 [[190](#bib.bib190), [191](#bib.bib191), [192](#bib.bib192)]
    依赖于准确的2D姿态检测器 [[193](#bib.bib193)]，但在表现力和后续应用方面存在限制。另一方面，3D舞蹈生成方法利用LSTMs [[194](#bib.bib194),
    [195](#bib.bib195), [196](#bib.bib196), [197](#bib.bib197), [198](#bib.bib198)],
    GANs [[199](#bib.bib199), [200](#bib.bib200)], 带有RNN解码器的transformer编码器 [[201](#bib.bib201)]
    或transformer解码器 [[202](#bib.bib202)]，以及卷积序列到序列模型 [[203](#bib.bib203), [204](#bib.bib204)]
    来从音频生成动作。
- en: Early works [[191](#bib.bib191), [198](#bib.bib198), [204](#bib.bib204)] in
    this field could predict future motion deterministically from audio but struggled
    when the same audio had multiple corresponding motions. However, recent advancements,
    such as the work by Li et al. [[202](#bib.bib202)], have addressed this limitation
    by formulating the problem with seed motion. This enables the generation of multiple
    motions from the same audio, even with a deterministic model. Li et al. [[202](#bib.bib202)]
    propose a novel cross-modal transformer-based model that better preserves the
    correlation between music and 3D motion. This approach results in more realistic
    and globally translated long human motion.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 早期工作 [[191](#bib.bib191), [198](#bib.bib198), [204](#bib.bib204)] 可能从音频中确定性地预测未来动作，但当相同音频对应多个动作时会遇到困难。然而，近期的进展，如Li等人的工作 [[202](#bib.bib202)]，通过将问题公式化为种子动作，解决了这一限制。这使得即使在确定性模型下，也能从相同音频生成多个动作。Li等人 [[202](#bib.bib202)]
    提出了一个新颖的基于跨模态transformer的模型，该模型更好地保留了音乐与3D动作之间的关联。这种方法产生了更现实且全球翻译的长人类动作。
- en: IV-E Sport Video Synthesizing
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-E 体育视频合成
- en: The goal of artificially synthesizing sports videos is to generate realistic
    and immersive content, such as player movements or game scenarios. Early works
    in this field train models using annotated videos where each time step is labeled
    with the corresponding action. However, these approaches use a discrete representation
    of actions, which make it challenging to define prior knowledge for real-world
    environments. Additionally, devising a suitable continuous action representation
    for an environment is also complex. To address the complexity of action representation
    in tennis, Menapace et al. [[205](#bib.bib205)] propose a discrete action representation.
    Building upon this idea, Huang et al. [[206](#bib.bib206)] model actions as a
    learned set of geometric transformations. Davtyan et al. [[207](#bib.bib207)]
    take a different approach by separating actions into a global shift component
    and a local discrete action component. More recent works in tennis have utilized
    a NeRF-based renderer [[208](#bib.bib208)], which allows for the representation
    of complex 3D scenes. Among these works, Menapace et al. [[209](#bib.bib209)]
    employ a text-based action representation that provides precise details about
    the specific ball-hitting action being performed and the destination of the ball.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 人工合成体育视频的目标是生成逼真和沉浸的内容，如球员动作或比赛场景。早期的研究使用标注视频训练模型，其中每个时间步骤都标记了对应的动作。然而，这些方法使用离散的动作表示，使得在实际环境中定义先验知识变得困难。此外，为环境设计适当的连续动作表示也是复杂的。为了应对网球中动作表示的复杂性，Menapace 等人[[205](#bib.bib205)]提出了离散动作表示。在此基础上，Huang 等人[[206](#bib.bib206)]将动作建模为一组学习得到的几何变换。Davtyan 等人[[207](#bib.bib207)]通过将动作分为全局位移组件和局部离散动作组件采取了不同的方法。网球中的最新研究利用了基于NeRF的渲染器[[208](#bib.bib208)]，允许表示复杂的3D场景。在这些研究中，Menapace 等人[[209](#bib.bib209)]采用了基于文本的动作表示，提供了关于执行的具体击球动作和球的目标的详细信息。
- en: V Datasets and Benchmarks
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 数据集与基准
- en: 'In the era of deep learning, having access to effective data is crucial for
    training and evaluating models. In order to facilitate this, we have compiled
    a list of commonly used public sports datasets, along with their corresponding
    details, as shown in Table [II](#S5.T2 "TABLE II ‣ V Datasets and Benchmarks ‣
    A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and
    Decision"). Below, we provide a more detailed description of each dataset.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '在深度学习时代，有效的数据对于训练和评估模型至关重要。为了便利这一点，我们整理了一份常用的公共体育数据集列表及其对应的详细信息，如表格[II](#S5.T2
    "TABLE II ‣ V Datasets and Benchmarks ‣ A Survey of Deep Learning in Sports Applications:
    Perception, Comprehension, and Decision")所示。下面，我们提供了每个数据集的更详细描述。'
- en: 'TABLE II: A list of video-based sports-related datasets used in the published
    papers. Note that some of them are not publicly available and “multiple” means
    that the dataset contains various sports instead of only one specific type of
    sports. “det.”, “cls.”, “tra.”, “ass.”, “seg.”, “loc.”,“cal.”, “cap.” stand for
    player/ball detection, action classification, player/ball tracking, action quality
    assessment, object segmentation, temporal action localization, camera calibration,
    and captioning respectively.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：在已发表的论文中使用的视频基础体育相关数据集列表。注意其中一些数据集并未公开，且“multiple”表示数据集中包含多种体育项目，而不仅仅是一种特定的体育类型。“det.”、“cls.”、“tra.”、“ass.”、“seg.”、“loc.”、“cal.”、“cap.”
    分别代表球员/球检测、动作分类、球员/球追踪、动作质量评估、物体分割、时间动作定位、相机标定和字幕生成。
- en: '| Sport | Dataset | Year | Task | # Videos | Avg. length | Link |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| Sport | 数据集 | 年份 | 任务 | 视频数量 | 平均时长 | 链接 |'
- en: '| Soccer | SoccerNet [[141](#bib.bib141)] | 2018 | loc.& cls. | 500 | 5,400
    | [$\usym{2713}$](https://silviogiancola.github.io/SoccerNet/) |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| Soccer | SoccerNet [[141](#bib.bib141)] | 2018 | loc.& cls. | 500 | 5,400
    | [$\usym{2713}$](https://silviogiancola.github.io/SoccerNet/) |'
- en: '| SSET [[210](#bib.bib210)] | 2020 | det.&tra. | 350 | 0.8h | [$\usym{2713}$](http://media.hust.edu.cn/dataset.htm)
    |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| SSET [[210](#bib.bib210)] | 2020 | det.&tra. | 350 | 0.8h | [$\usym{2713}$](http://media.hust.edu.cn/dataset.htm)
    |'
- en: '| SoccerDB [[211](#bib.bib211)] | 2020 | cls.& loc. | 346 | 1.5h | [$\usym{2713}$](https://github.com/newsdata/SoccerDB)
    |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| SoccerDB [[211](#bib.bib211)] | 2020 | cls.& loc. | 346 | 1.5h | [$\usym{2713}$](https://github.com/newsdata/SoccerDB)
    |'
- en: '| SoccerNet-v2 [[212](#bib.bib212)] | 2021 | cls.&loc. | 500 | 1.5h1.5h | [$\usym{2713}$](https://www.soccer-net.org/data)
    |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| SoccerNet-v2 [[212](#bib.bib212)] | 2021 | cls.&loc. | 500 | 1.5h1.5h | [$\usym{2713}$](https://www.soccer-net.org/data)
    |'
- en: '| SoccerKicks [[213](#bib.bib213)] | 2021 | pos. | 38 | - | [$\usym{2713}$](https://github.com/larocs/SoccerKicks)
    |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| SoccerKicks [[213](#bib.bib213)] | 2021 | pos. | 38 | - | [$\usym{2713}$](https://github.com/larocs/SoccerKicks)
    |'
- en: '| SoccerNet-v3 [[34](#bib.bib34)] | 2022 | cls.&tra. | 346 | 1.5h | [$\usym{2713}$](https://www.soccer-net.org/data)
    |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| SoccerNet-v3 [[34](#bib.bib34)] | 2022 | cls.&tra. | 346 | 1.5h | [$\usym{2713}$](https://www.soccer-net.org/data)
    |'
- en: '| SoccerNet-Tracking [[33](#bib.bib33)] | 2022 | cls.&tra. | 21 | 45.5m | [$\usym{2713}$](https://www.soccer-net.org/data)
    |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| SoccerNet-Tracking [[33](#bib.bib33)] | 2022 | cls.&tra. | 21 | 45.5m | [$\usym{2713}$](https://www.soccer-net.org/data)
    |'
- en: '| SoccerTrack [[214](#bib.bib214)] | 2022 | tra.&loc. | 20 | 30s | [$\usym{2713}$](https://github.com/AtomScott/SoccerTrack)
    |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 足球轨迹 [[214](#bib.bib214)] | 2022 | tra.&loc. | 20 | 30s | [$\usym{2713}$](https://github.com/AtomScott/SoccerTrack)
    |'
- en: '| Basketball | BPAD [[215](#bib.bib215)] | 2017 | ass. | 48 | 13m | [$\usym{2713}$](https://www.kaggle.com/datasets/gabrielvanzandycke/spiroudome-dataset)
    |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 篮球 | BPAD [[215](#bib.bib215)] | 2017 | ass. | 48 | 13m | [$\usym{2713}$](https://www.kaggle.com/datasets/gabrielvanzandycke/spiroudome-dataset)
    |'
- en: '| NBA [[126](#bib.bib126)] | 2020 | cls. | 181 | - | [$\usym{2713}$](https://ruiyan1995.github.io/SAM.html)
    |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| NBA [[126](#bib.bib126)] | 2020 | cls. | 181 | - | [$\usym{2713}$](https://ruiyan1995.github.io/SAM.html)
    |'
- en: '| NPUBasketball [[216](#bib.bib216)] | 2021 | cls. | 2,169 | - | [$\usym{2713}$](https://github.com/Medjed46/NPU-RGBD-Basketball-Dataset)
    |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| NPUBasketball [[216](#bib.bib216)] | 2021 | cls. | 2,169 | - | [$\usym{2713}$](https://github.com/Medjed46/NPU-RGBD-Basketball-Dataset)
    |'
- en: '| DeepSportradar-v1 [[36](#bib.bib36)] | 2022 | seq.&cal. | - | - | [$\usym{2713}$](https://github.com/DeepSportRadar)
    |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| DeepSportradar-v1 [[36](#bib.bib36)] | 2022 | seq.&cal. | - | - | [$\usym{2713}$](https://github.com/DeepSportRadar)
    |'
- en: '| NSVA [[217](#bib.bib217)] | 2022 | cls.&cap. | 32,019 | 9.5s | [$\usym{2713}$](https://github.com/jackwu502/NSVA)
    |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| NSVA [[217](#bib.bib217)] | 2022 | cls.&cap. | 32,019 | 9.5s | [$\usym{2713}$](https://github.com/jackwu502/NSVA)
    |'
- en: '| Tennis | PE-Tennis [[218](#bib.bib218)] | 2022 | det.&cal. | 14,053 | 3s
    | [$\usym{2713}$](https://github.com/willi-menapace/PlayableEnvironments) |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 网球 | PE-Tennis [[218](#bib.bib218)] | 2022 | det.&cal. | 14,053 | 3s | [$\usym{2713}$](https://github.com/willi-menapace/PlayableEnvironments)
    |'
- en: '| LGEs-Tennis [[209](#bib.bib209)] | 2023 | cal.&tra.&cap. | 7,112 | 7.8s |
    [$\usym{2713}$](https://learnable-game-engines.github.io/lge-website/) |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| LGEs-Tennis [[209](#bib.bib209)] | 2023 | cal.&tra.&cap. | 7,112 | 7.8s |
    [$\usym{2713}$](https://learnable-game-engines.github.io/lge-website/) |'
- en: '| Figure Skating | FisV-5 [[219](#bib.bib219)] | 2020 | ass.& cls. | 500 |
    2m50s | [$\usym{2713}$](https://github.com/loadder/MS_LSTM) |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 花样滑冰 | FisV-5 [[219](#bib.bib219)] | 2020 | ass.& cls. | 500 | 2m50s | [$\usym{2713}$](https://github.com/loadder/MS_LSTM)
    |'
- en: '| FR-FS [[220](#bib.bib220)] | 2021 | ass.& cls. | 417 | - | [$\usym{2713}$](https://github.com/Shunli-Wang/TSA-Net)
    |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| FR-FS [[220](#bib.bib220)] | 2021 | ass.& cls. | 417 | - | [$\usym{2713}$](https://github.com/Shunli-Wang/TSA-Net)
    |'
- en: '| Diving | MTL-AQA [[221](#bib.bib221)] | 2019 | ass. | 1,412 | - | [$\usym{2713}$](http://rtis.oit.unlv.edu/datasets.html)
    |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 跳水 | MTL-AQA [[221](#bib.bib221)] | 2019 | ass. | 1,412 | - | [$\usym{2713}$](http://rtis.oit.unlv.edu/datasets.html)
    |'
- en: '| FineDiving [[222](#bib.bib222)] | 2022 | ass.& cls. | 3,000 | 52s | [$\usym{2713}$](https://github.com/xujinglin/FineDiving)
    |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| FineDiving [[222](#bib.bib222)] | 2022 | ass.& cls. | 3,000 | 52s | [$\usym{2713}$](https://github.com/xujinglin/FineDiving)
    |'
- en: '| Dance | GrooveNet [[194](#bib.bib194)] | 2017 | pos. | 2 | 11.5m | [$\usym{2713}$](https://omid.al/groovenet-material-ml4c/)
    |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 舞蹈 | GrooveNet [[194](#bib.bib194)] | 2017 | pos. | 2 | 11.5m | [$\usym{2713}$](https://omid.al/groovenet-material-ml4c/)
    |'
- en: '| Dance with Melody [[195](#bib.bib195)] | 2018 | pos. | 61 | 92s | [$\usym{2713}$](https://github.com/Music-to-dance-motion-synthesis/dataset)
    |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 与旋律共舞 [[195](#bib.bib195)] | 2018 | pos. | 61 | 92s | [$\usym{2713}$](https://github.com/Music-to-dance-motion-synthesis/dataset)
    |'
- en: '| EA-MUD [[200](#bib.bib200)] | 2020 | pos. | 17 | 74s | [$\usym{2713}$](https://github.com/computer-animation-perception-group/DeepDance)
    |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| EA-MUD [[200](#bib.bib200)] | 2020 | pos. | 17 | 74s | [$\usym{2713}$](https://github.com/computer-animation-perception-group/DeepDance)
    |'
- en: '| AIST++ [[202](#bib.bib202)] | 2021 | det&pos. | 1,408 | 13s | [$\usym{2713}$](https://google.github.io/aistplusplus_dataset/factsfigures.html)
    |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| AIST++ [[202](#bib.bib202)] | 2021 | det&pos. | 1,408 | 13s | [$\usym{2713}$](https://google.github.io/aistplusplus_dataset/factsfigures.html)
    |'
- en: '| DanceTrack [[49](#bib.bib49)] | 2022 | tra. | 100 | 52.9s | [$\usym{2713}$](https://github.com/DanceTrack/DanceTrack)
    |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| DanceTrack [[49](#bib.bib49)] | 2022 | tra. | 100 | 52.9s | [$\usym{2713}$](https://github.com/DanceTrack/DanceTrack)
    |'
- en: '| Golf | GolfDB [[223](#bib.bib223)] | 2019 | cls. | 1,400 | - | [$\usym{2713}$](https://github.com/wmcnally/GolfDB)
    |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 高尔夫 | GolfDB [[223](#bib.bib223)] | 2019 | cls. | 1,400 | - | [$\usym{2713}$](https://github.com/wmcnally/GolfDB)
    |'
- en: '| Gymnastics | FineGym [[114](#bib.bib114)] | 2020 | cls.& loc. | - | - | [$\usym{2713}$](https://sdolivia.github.io/FineGym/)
    |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 体操 | FineGym [[114](#bib.bib114)] | 2020 | cls.& loc. | - | - | [$\usym{2713}$](https://sdolivia.github.io/FineGym/)
    |'
- en: '| Rugby | Rugby sevens [[119](#bib.bib119)] | 2022 | tra. | 346 | 40s | [$\usym{2713}$](https://kalisteo.cea.fr/index.php/free-resources/)
    |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 橄榄球 | Rugby sevens [[119](#bib.bib119)] | 2022 | tra. | 346 | 40s | [$\usym{2713}$](https://kalisteo.cea.fr/index.php/free-resources/)
    |'
- en: '| Baseball | MLB-YouTube[[224](#bib.bib224)] | 2018 | cls. | 5,111 | - | [$\usym{2713}$](https://github.com/piergiaj/mlb-youtube/)
    |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| Baseball | MLB-YouTube[[224](#bib.bib224)] | 2018 | cls. | 5,111 | - | [$\usym{2713}$](https://github.com/piergiaj/mlb-youtube/)
    |'
- en: '| General | Sports 1M [[225](#bib.bib225)] | 2014 | cls. | 1M | 36s | [$\usym{2713}$](https://code.google.com/archive/p/sports-1m-dataset/)
    |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| General | Sports 1M [[225](#bib.bib225)] | 2014 | cls. | 1M | 36s | [$\usym{2713}$](https://code.google.com/archive/p/sports-1m-dataset/)
    |'
- en: '| OlympicSports [[226](#bib.bib226)] | 2014 | ass. | 309 | - | [$\usym{2713}$](https://redirect.cs.umbc.edu/~hpirsiav/quality.html)
    |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| OlympicSports [[226](#bib.bib226)] | 2014 | ass. | 309 | - | [$\usym{2713}$](https://redirect.cs.umbc.edu/~hpirsiav/quality.html)
    |'
- en: '| SVW [[227](#bib.bib227)] | 2015 | det.& cls. | 4,100 | 11.6s | [$\usym{2713}$](http://cvlab.cse.msu.edu/project-svw.html)
    |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| SVW [[227](#bib.bib227)] | 2015 | det.& cls. | 4,100 | 11.6s | [$\usym{2713}$](http://cvlab.cse.msu.edu/project-svw.html)
    |'
- en: '| OlympicScoring [[228](#bib.bib228)] | 2017 | ass. | 716 | - | [$\usym{2713}$](http://rtis.oit.unlv.edu/datasets.html)
    |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| OlympicScoring [[228](#bib.bib228)] | 2017 | ass. | 716 | - | [$\usym{2713}$](http://rtis.oit.unlv.edu/datasets.html)
    |'
- en: '| MADS [[229](#bib.bib229)] | 2017 | ass. | 30 | - | [$\usym{2713}$](http://visal.cs.cityu.edu.hk/research/mads/)
    |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| MADS [[229](#bib.bib229)] | 2017 | ass. | 30 | - | [$\usym{2713}$](http://visal.cs.cityu.edu.hk/research/mads/)
    |'
- en: '| MultiTHUMOS [[230](#bib.bib230)] | 2017 | cls. | 400 | 4.5m | [$\usym{2713}$](http://ai.stanford.edu/~syyeung/everymoment.html)
    |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| MultiTHUMOS [[230](#bib.bib230)] | 2017 | cls. | 400 | 4.5m | [$\usym{2713}$](http://ai.stanford.edu/~syyeung/everymoment.html)
    |'
- en: '| AQA-7 [[231](#bib.bib231)] | 2019 | ass. | 1,189 | - | [$\usym{2713}$](http://rtis.oit.unlv.edu/datasets.html)
    |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| AQA-7 [[231](#bib.bib231)] | 2019 | ass. | 1,189 | - | [$\usym{2713}$](http://rtis.oit.unlv.edu/datasets.html)
    |'
- en: '| C-Sports [[232](#bib.bib232)] | 2020 | cls.&loc. | 2,187 | - | [$\usym{2713}$](https://cemilzalluhoglu.github.io/csports)
    |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| C-Sports [[232](#bib.bib232)] | 2020 | cls.&loc. | 2,187 | - | [$\usym{2713}$](https://cemilzalluhoglu.github.io/csports)
    |'
- en: '| MultiSports [[233](#bib.bib233)] | 2021 | cls.&loc. | 3,200 | 20.9s | [$\usym{2713}$](https://github.com/MCG-NJU/MultiSports/)
    |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| MultiSports [[233](#bib.bib233)] | 2021 | cls.&loc. | 3,200 | 20.9s | [$\usym{2713}$](https://github.com/MCG-NJU/MultiSports/)
    |'
- en: '| ASPset-510 [[234](#bib.bib234)] | 2021 | pos. | 510 | - | [$\usym{2713}$](https://github.com/anibali/aspset-510)
    |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| ASPset-510 [[234](#bib.bib234)] | 2021 | pos. | 510 | - | [$\usym{2713}$](https://github.com/anibali/aspset-510)
    |'
- en: '| HAA-500 [[235](#bib.bib235)] | 2021 | cls. | 10,000 | 2.12s | [$\usym{2713}$](https://www.cse.ust.hk/haa/)
    |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| HAA-500 [[235](#bib.bib235)] | 2021 | cls. | 10,000 | 2.12s | [$\usym{2713}$](https://www.cse.ust.hk/haa/)
    |'
- en: '| SMART [[236](#bib.bib236)] | 2021 | cls. | 5,000 | - | [$\usym{2713}$](https://chenxin.tech/files/Paper/IJCV2020_Sport/project_page_SportsCap/index.htm)
    |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| SMART [[236](#bib.bib236)] | 2021 | cls. | 5,000 | - | [$\usym{2713}$](https://chenxin.tech/files/Paper/IJCV2020_Sport/project_page_SportsCap/index.htm)
    |'
- en: '| Win-Fail [[237](#bib.bib237)] | 2022 | cls. | 817 | 3.3s | [$\usym{2713}$](https://github.com/ParitoshParmar/Win-Fail-Action-Recognition)
    |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| Win-Fail [[237](#bib.bib237)] | 2022 | cls. | 817 | 3.3s | [$\usym{2713}$](https://github.com/ParitoshParmar/Win-Fail-Action-Recognition)
    |'
- en: '| SportsPose [[238](#bib.bib238)] | 2023 | pos. | 25 | 11m | [$\usym{2713}$](https://github.com/ChristianIngwersen/SportsPose)
    |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| SportsPose [[238](#bib.bib238)] | 2023 | pos. | 25 | 11m | [$\usym{2713}$](https://github.com/ChristianIngwersen/SportsPose)
    |'
- en: '|  | SportsMOT [[239](#bib.bib239)] | 2023 | tra. | 240 | 25s | [$\usym{2713}$](https://deeperaction.github.io/datasets/sportsmot.html)
    |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '|  | SportsMOT [[239](#bib.bib239)] | 2023 | tra. | 240 | 25s | [$\usym{2713}$](https://deeperaction.github.io/datasets/sportsmot.html)
    |'
- en: V-A Soccer
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-A 足球
- en: In soccer, most video-based datasets benefit from active tasks like player tracking
    and action recognition, while some datasets focus on field localization and registration
    or player depth maps and meshes.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在足球领域，大多数基于视频的数据集受益于球员跟踪和动作识别等主动任务，而一些数据集则关注场地定位和注册或球员深度图和网格。
- en: Some datasets focus more on player detection and tracking. Soccer-ISSIA [[240](#bib.bib240)]
    is an early work and a relatively small dataset with player bounding box annotations.
    SVPP [[241](#bib.bib241)] provides a multi-sensor dataset that includes body sensor
    data and video data. Soccer Player [[242](#bib.bib242)] is specifically designed
    for player detection and tracking, while SoccerTrack [[214](#bib.bib214)] is a
    novel dataset with multi-view and super high definition.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据集更专注于球员检测和跟踪。Soccer-ISSIA [[240](#bib.bib240)] 是一项早期工作，数据集相对较小，并提供球员边界框注释。SVPP [[241](#bib.bib241)]
    提供了包括身体传感器数据和视频数据的多传感器数据集。Soccer Player [[242](#bib.bib242)] 专门用于球员检测和跟踪，而 SoccerTrack [[214](#bib.bib214)]
    是一个具有多视角和超高分辨率的新数据集。
- en: Other datasets like Football Action [[137](#bib.bib137)] and SoccerDB [[211](#bib.bib211)]
    benefit action recognition, and ComprehensiveSoccer [[243](#bib.bib243)] and SSET [[210](#bib.bib210)]
    can be used for various video analysis tasks, such as action classification, localization,
    and player detection. SoccerKicks [[212](#bib.bib212)] provides player pose estimation.
    GOAL [[244](#bib.bib244)] supports knowledge-grounded video captioning.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 像 Football Action [[137](#bib.bib137)] 和 SoccerDB [[211](#bib.bib211)] 这样的数据集对动作识别有帮助，而
    ComprehensiveSoccer [[243](#bib.bib243)] 和 SSET [[210](#bib.bib210)] 可用于各种视频分析任务，如动作分类、定位和球员检测。SoccerKicks
    [[212](#bib.bib212)] 提供球员姿态估计。GOAL [[244](#bib.bib244)] 支持知识驱动的视频字幕生成。
- en: The SoccerNet series [[141](#bib.bib141), [212](#bib.bib212), [34](#bib.bib34),
    [33](#bib.bib33)] is the largest one including annotations for a variety of spatial
    annotations and cross-view correspondences. It covers multiple vision-based tasks
    including player understanding like player tracking, re-identification, broadcast
    video understanding like action spotting, video captioning, and field understanding
    like camera calibration.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: SoccerNet 系列 [[141](#bib.bib141), [212](#bib.bib212), [34](#bib.bib34), [33](#bib.bib33)]
    是最大的数据集之一，包含各种空间注释和跨视角对应关系的注释。它涵盖了多种基于视觉的任务，包括球员理解（如球员跟踪、重新识别）、广播视频理解（如动作检测、视频字幕生成）和场地理解（如相机校准）。
- en: In recent years, the combination of large-scale datasets and deep learning models
    has become increasingly popular in the field of soccer tasks, raising the popularity
    of the SoccerNet series datasets [[141](#bib.bib141), [212](#bib.bib212), [34](#bib.bib34)].
    Meanwhile, SoccerDB [[211](#bib.bib211)], SSET [[210](#bib.bib210)], and ComprehensiveSoccer [[243](#bib.bib243)]
    are more suitable for tasks that require player detection. However, there are
    few datasets like SoccerKick [[213](#bib.bib213)] for soccer player pose estimation.
    It is hoped that more attention can be paid to the recognition and understanding
    of player skeletal movements in the future.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 最近几年，大规模数据集和深度学习模型的结合在足球任务领域越来越受欢迎，这提高了 SoccerNet 系列数据集 [[141](#bib.bib141),
    [212](#bib.bib212), [34](#bib.bib34)] 的受欢迎程度。同时，SoccerDB [[211](#bib.bib211)],
    SSET [[210](#bib.bib210)] 和 ComprehensiveSoccer [[243](#bib.bib243)] 更适合需要球员检测的任务。然而，像
    SoccerKick [[213](#bib.bib213)] 这样用于足球球员姿态估计的数据集较少。希望未来能更多关注球员骨骼运动的识别和理解。
- en: V-B Basketball
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-B 篮球
- en: Basketball datasets have been developed for various tasks such as player and
    ball detection, action recognition, and pose estimation. APIDIS [[245](#bib.bib245),
    [40](#bib.bib40)] is a challenging dataset with annotations for player and ball
    positions, and clock and non-clock actions. Basket-1,2 [[38](#bib.bib38)] consists
    of two frame sequences for action recognition and ball detection. NCAA [[246](#bib.bib246)]
    is a large dataset with action categories and bounding boxes for player detection.
    SPIROUDOME [[215](#bib.bib215)] focuses on player detection and localization.
    BPAD [[154](#bib.bib154)] is a first-person perspective dataset with labeled basketball
    events. SpaceJam [[247](#bib.bib247)] is for action recognition with estimated
    player poses. FineBasketball [[248](#bib.bib248)] is a fine-grained dataset with
    3 broad and 26 fine-grained categories. NBA [[126](#bib.bib126)] is a dataset
    for group activity recognition, where each clip belongs to one of the nine group
    activities, and no individual annotations are provided, such as separate action
    labels and bounding boxes. NPUBasketball [[216](#bib.bib216)] contains RGB frames,
    depth maps, and skeleton information for various types of action recognition models.
    DeepSportradar-v1 [[36](#bib.bib36)] is a multi-label dataset for 3D localization,
    calibration, and instance segmentation tasks. In Captioning task, NSVA [[217](#bib.bib217)]
    is the largest open-source dataset in the basketball domain. Compared to SVN [[249](#bib.bib249)]
    and SVCDV [[162](#bib.bib162)], NSVA is publicly accessible and has the most sentences
    among the three datasets, with five times more videos than both SVN and SVCDV.
    Additionally, there are some special datasets that focus on reconstructing the
    player. NBA2K dataset [[250](#bib.bib250)] includes body meshes and texture data
    of several NBA players.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 篮球数据集已经被开发用于各种任务，例如球员和球的检测、动作识别和姿态估计。APIDIS [[245](#bib.bib245), [40](#bib.bib40)]
    是一个具有球员和球位置注释的挑战性数据集，并且标注了时钟和非时钟动作。Basket-1,2 [[38](#bib.bib38)] 包含了用于动作识别和球检测的两个帧序列。NCAA [[246](#bib.bib246)]
    是一个大型数据集，具有动作类别和球员检测的边界框。SPIROUDOME [[215](#bib.bib215)] 关注于球员检测和定位。BPAD [[154](#bib.bib154)]
    是一个第一人称视角的数据集，标注了篮球事件。SpaceJam [[247](#bib.bib247)] 用于动作识别，并估计了球员的姿态。FineBasketball [[248](#bib.bib248)]
    是一个细粒度的数据集，具有3个广泛类别和26个细粒度类别。NBA [[126](#bib.bib126)] 是一个用于群体活动识别的数据集，其中每个片段属于九种群体活动之一，没有提供单独的注释，例如分开的动作标签和边界框。NPUBasketball [[216](#bib.bib216)]
    包含了RGB帧、深度图和骨架信息，适用于各种类型的动作识别模型。DeepSportradar-v1 [[36](#bib.bib36)] 是一个多标签数据集，用于3D定位、校准和实例分割任务。在图像描述任务中，NSVA [[217](#bib.bib217)]
    是篮球领域最大的开源数据集。与SVN [[249](#bib.bib249)] 和SVCDV [[162](#bib.bib162)] 相比，NSVA是公开可访问的，并且在三个数据集中拥有最多的句子，其视频数量是SVN和SVCDV的五倍。此外，还有一些特殊的数据集专注于重建球员。NBA2K数据集 [[250](#bib.bib250)]
    包含了几位NBA球员的身体网格和纹理数据。
- en: V-C Volleyball
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-C 排球
- en: Despite being a popular sport, there are only a few volleyball datasets available,
    most of which are on small scales. Volleyball-1,2 [[38](#bib.bib38)] contains
    two sequences with manually annotated ball positions. HierVolleyball [[251](#bib.bib251)]
    and its extension HierVolleyball-v2 [[252](#bib.bib252)] are developed for team
    activity recognition, with annotated player actions and positions. Sports Video
    Captioning Dataset-Volleyball (SVCDV) [[162](#bib.bib162)] is a dataset for captioning
    tasks, with 55 videos from YouTube, each containing an average of 9.2 sentences.
    However, this dataset is not available for download.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管排球是一项受欢迎的运动，但现有的排球数据集数量不多，大多数数据集规模较小。Volleyball-1,2 [[38](#bib.bib38)] 包含了两个具有人工标注球位置的序列。HierVolleyball [[251](#bib.bib251)]
    及其扩展版本HierVolleyball-v2 [[252](#bib.bib252)] 是为团队活动识别开发的，具有标注的球员动作和位置。Sports Video
    Captioning Dataset-Volleyball (SVCDV) [[162](#bib.bib162)] 是一个用于图像描述任务的数据集，包含55个来自YouTube的视频，每个视频平均包含9.2个句子。然而，这个数据集不可供下载。
- en: V-D Hockey
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-D 冰球
- en: The Hockey Fight dataset [[253](#bib.bib253)] contains 1,000 video clips from
    National Hockey League (NHL) games for binary classification of fight and non-fight.
    The Player Tracklet dataset [[254](#bib.bib254)] consists of 84 video clips from
    NHL games with annotated bounding boxes and identity labels for players and referees
    and is suitable for player tracking and identification.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 冰球打斗数据集 [[253](#bib.bib253)] 包含了来自国家冰球联盟（NHL）比赛的1,000个视频片段，用于打斗与非打斗的二分类。Player
    Tracklet数据集 [[254](#bib.bib254)] 包含了84个来自NHL比赛的视频片段，具有标注的边界框和球员及裁判的身份标签，适用于球员追踪和识别。
- en: V-E Tennis
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-E 网球
- en: Various datasets have been constructed for tennis video analysis. ACASVA [[255](#bib.bib255)]
    is designed for tennis action recognition and consists of six broadcast videos
    of tennis games with labeled player positions and time boundaries of actions.
    THETIS [[256](#bib.bib256)] includes 1,980 self-recorded videos of 12 tennis actions
    with RGB, depth, 2D skeleton, and 3D skeleton videos, which can be used for multiple
    types of action recognition models. TenniSet [[257](#bib.bib257)] contains five
    Olympic tennis match videos with six labeled event categories and textural descriptions,
    making it suitable for both recognition, localization, and action retrieval tasks.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 各种数据集已被构建用于网球视频分析。ACASVA [[255](#bib.bib255)]旨在进行网球动作识别，由六个广播网球比赛视频组成，标注了玩家位置和动作的时间边界。THETIS [[256](#bib.bib256)]包括1,980个自录制的视频，涵盖12种网球动作，带有RGB、深度、2D骨架和3D骨架视频，可用于多种类型的动作识别模型。TenniSet [[257](#bib.bib257)]包含五个奥运网球比赛视频，具有六个标注的事件类别和纹理描述，适用于识别、定位和动作检索任务。
- en: It should be noted that some recent works focus more on generative tasks, like
    PVG [[258](#bib.bib258)], which obtained a tennis dataset through YouTube videos.
    PE-Tennis [[218](#bib.bib218)] built upon PVG and introduces camera calibration
    resulting from reconstruction, making it possible to edit the viewpoint. LGEs-Tennis [[209](#bib.bib209)]
    enables generation from text editing on player movement, shot type, and location.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 应当注意的是，一些近期的工作更多关注生成任务，如PVG [[258](#bib.bib258)]，它通过YouTube视频获得了一个网球数据集。PE-Tennis [[218](#bib.bib218)]在PVG的基础上进行了扩展，引入了重建后的相机标定，使得编辑视角成为可能。LGEs-Tennis [[209](#bib.bib209)]使得从文本编辑生成玩家动作、击球类型和位置成为可能。
- en: V-F Table Tennis
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-F 乒乓球
- en: Various datasets have been developed for table tennis stroke recognition, such
    as TTStroke-21 [[259](#bib.bib259)], which comprises 129 self-recorded videos
    of 21 categories, and SPIN [[55](#bib.bib55)], which includes 53 hours of self-recorded
    videos with annotations of ball position and player joints. OpenTTGames [[37](#bib.bib37)]
    consists of 12 HD videos of table tennis games, labeled with ball coordinates
    and events. Stroke Recognition [[260](#bib.bib260)] is similar to TTStroke-21,
    but much larger, and P²A [[261](#bib.bib261)] is one of the largest datasets for
    table tennis analysis, with annotations of each stroke in 2,721 broadcasting videos.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 各种数据集已被开发用于乒乓球击球动作识别，如TTStroke-21 [[259](#bib.bib259)]，它包含129个自录制的21类视频，以及SPIN [[55](#bib.bib55)]，它包括53小时的自录制视频，带有球的位置和玩家关节的注释。OpenTTGames [[37](#bib.bib37)]由12个高清乒乓球比赛视频组成，标注了球的坐标和事件。Stroke
    Recognition [[260](#bib.bib260)]类似于TTStroke-21，但规模更大，而P²A [[261](#bib.bib261)]是最大的乒乓球分析数据集之一，包含2,721个广播视频中每个击球的注释。
- en: V-G Gymnastics
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-G 体操
- en: The FineGym [[114](#bib.bib114)] is a recent work developed for gymnastic action
    recognition and localization. It contains 303 videos with around 708-hour length
    and is annotated hierarchically, making it suitable for fine-grained action recognition
    and localization. On the other hand, AFG-Olympics [[262](#bib.bib262)] provides
    challenging scenarios with extensive background, viewpoint, and scale variations
    over an extended sample duration of up to 2 minutes. Additionally, a discriminative
    attention module is proposed to embed long-range spatial and temporal correlation
    semantics.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: FineGym [[114](#bib.bib114)]是最近开发的用于体操动作识别和定位的工作。它包含303个视频，总时长约708小时，并且具有分层注释，使其适用于细粒度动作识别和定位。另一方面，AFG-Olympics [[262](#bib.bib262)]提供了具有挑战性的场景，背景、视角和尺度变化广泛，样本持续时间最长可达2分钟。此外，还提出了一种判别性注意模块，以嵌入长距离空间和时间相关语义。
- en: V-H Badminton
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-H 羽毛球
- en: The Badminton Olympic [[263](#bib.bib263)] provides annotations for player detection,
    point localization, action recognition, and localization tasks. It comprises 10
    YouTube videos of singles badminton matches, each approximately an hour long.
    The dataset includes annotations for player positions, temporal locations of point
    wins, and time boundaries and labels of strokes. Meanwhile, Stroke Forecasting [[177](#bib.bib177)]
    contains 43,191 trimmed video clips of badminton strokes categorized into 10 types,
    which can be used for both action recognition and stroke forecasting.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: Badminton Olympic [[263](#bib.bib263)]提供了用于玩家检测、点位定位、动作识别和定位任务的注释。它包含10个YouTube羽毛球单打比赛视频，每个视频大约一个小时。数据集包括玩家位置、点赢得的时间位置，以及击球的时间边界和标签的注释。与此同时，Stroke
    Forecasting [[177](#bib.bib177)]包含43,191个修剪过的羽毛球击球视频片段，分类为10种类型，可用于动作识别和击球预测。
- en: V-I Figure skating
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-I 花样滑冰
- en: There are 5 datasets proposed for figure skating action recognition in recent
    years. FineSkating [[264](#bib.bib264)] is a hierarchical-labeled dataset of 46
    videos of figure skating competitions for action recognition and action quality
    assessment. FSD-10 [[265](#bib.bib265)] comprises ten categories of figure skating
    actions and provides scores for action quality assessment. FisV-5 [[107](#bib.bib107)]
    is a dataset of 500 figure skating competition videos labeled with scores by 9
    professional judges. FR-FS [[109](#bib.bib109)] is designed to recognize figure
    skating falls, with 417 videos containing the movements of take-off, rotation,
    and landing. MCFS [[266](#bib.bib266)] has three-level annotations of figure skating
    actions and their time boundaries, allowing for action recognition and localization.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，提出了5个用于花样滑冰动作识别的数据集。FineSkating [[264](#bib.bib264)] 是一个分层标注的数据集，包含46个花样滑冰比赛视频，用于动作识别和动作质量评估。FSD-10 [[265](#bib.bib265)]
    包含十类花样滑冰动作，并提供动作质量评估的分数。FisV-5 [[107](#bib.bib107)] 是一个包含500个花样滑冰比赛视频的数据集，由9位专业评委打分。FR-FS [[109](#bib.bib109)]
    旨在识别花样滑冰中的跌倒动作，包含417个视频，涵盖起跳、旋转和落地动作。MCFS [[266](#bib.bib266)] 提供了花样滑冰动作的三层级注释及其时间边界，支持动作识别和定位。
- en: V-J Diving
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-J 潜水
- en: There are three diving datasets available for action recognition and action
    quality assessment. Diving48 [[267](#bib.bib267)] contains 18,404 video segments
    covering 48 fine-grained categories of diving actions, making it a relatively
    low-bias dataset suitable for model evaluation. In contrast, MTL-AQA [[221](#bib.bib221)]
    consists of 1,412 samples annotated with action quality scores, class labels,
    and textural commentary, making it suitable for multiple tasks. In addition, FineDiving [[222](#bib.bib222)]
    is a recent dataset consisting of 3,000 video samples covering 52 types of actions,
    29 sub-action types, and 23 difficulty levels, providing fine-grained annotations
    including action types, sub-action types, coarse and fine time boundaries, and
    action scores. It is the first fine-grained motion video dataset for the AQA task,
    filling the gap in fine-grained annotations in AQA and suitable for designing
    competition strategies and better showcasing athletes’ strengths.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个潜水数据集可用于动作识别和动作质量评估。Diving48 [[267](#bib.bib267)] 包含18,404个视频片段，涵盖48个细粒度的潜水动作类别，是一个相对低偏倚的数据集，适合模型评估。相比之下，MTL-AQA [[221](#bib.bib221)]
    由1,412个样本组成，这些样本标注了动作质量评分、类别标签和文本评论，适用于多任务处理。此外，FineDiving [[222](#bib.bib222)]
    是一个最新的数据集，包含3,000个视频样本，涵盖52种动作、29种子动作类型和23个难度级别，提供细粒度的注释，包括动作类型、子动作类型、粗略和精确的时间边界，以及动作评分。它是AQA任务中第一个细粒度动作视频数据集，填补了AQA中细粒度注释的空白，适合用于设计竞赛策略和更好地展示运动员的优势。
- en: V-K Dance
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-K 舞蹈
- en: The field of deep learning has several research tasks for dance, including music-oriented
    choreography, dance motion synthesis, and multiple object tracking. Researchers
    propose several datasets to promote research in this field. GrooveNet [[194](#bib.bib194)]
    consists of approximately 23 minutes of motion capture data recorded at 60 frames
    per second and four performances by a dancer. Dance with Melody [[195](#bib.bib195)]
    includes 40 complete dance choreographies for four types of dance, totaling 907,200
    frames collected with optical motion capture equipment. EA-MUD [[200](#bib.bib200)]
    includes 104 video sequences of 12 dancing genres, while AIST++ [[202](#bib.bib202)]
    is a large-scale 3D human dance motion dataset with frame-level annotations including
    9 views of camera intrinsic and extrinsic parameters, 17 COCO-format human joint
    locations in both 2D and 3D, and 24 SMPL pose parameters. These datasets can be
    used for tasks such as dance motion recognition, tracking, and quality assessment.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习领域有多个舞蹈研究任务，包括音乐导向的编舞、舞蹈动作合成和多物体跟踪。研究人员提出了几个数据集以推动该领域的研究。GrooveNet [[194](#bib.bib194)]
    包含约23分钟的动作捕捉数据，记录了60帧每秒的四场舞蹈表演。Dance with Melody [[195](#bib.bib195)] 包括四种舞蹈类型的40个完整舞蹈编排，总计907,200帧，通过光学动作捕捉设备收集。EA-MUD [[200](#bib.bib200)]
    包含104个视频序列，涵盖12种舞蹈风格，而AIST++ [[202](#bib.bib202)] 是一个大规模的3D人体舞蹈动作数据集，具有帧级注释，包括9种相机内外参数视角、17个COCO格式的人体关节位置（2D和3D），以及24个SMPL姿态参数。这些数据集可用于舞蹈动作识别、跟踪和质量评估。
- en: V-L Sport Related Datasets for General Purpose
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-L 一般目的的运动相关数据集
- en: There are several datasets for sports action recognition and assessment tasks,
    including UCF sports [[268](#bib.bib268)], MSR Action3D [[269](#bib.bib269)],
    Olympic [[270](#bib.bib270)], Sports 1M[[225](#bib.bib225)], SVW [[227](#bib.bib227)],
    MultiSports [[233](#bib.bib233)], OlympicSports [[226](#bib.bib226)], OlympicScoring [[228](#bib.bib228)],
    and AQA [[231](#bib.bib231)]. These datasets cover different sports, including
    team sports and individual sports, and provide various annotations, such as action
    labels, quality scores, and bounding boxes.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个数据集用于体育动作识别和评估任务，包括 UCF sports [[268](#bib.bib268)]、MSR Action3D [[269](#bib.bib269)]、Olympic
    [[270](#bib.bib270)]、Sports 1M [[225](#bib.bib225)]、SVW [[227](#bib.bib227)]、MultiSports
    [[233](#bib.bib233)]、OlympicSports [[226](#bib.bib226)]、OlympicScoring [[228](#bib.bib228)]
    和 AQA [[231](#bib.bib231)]。这些数据集覆盖了不同的体育项目，包括团队运动和个人运动，并提供了各种注释，如动作标签、质量评分和边界框。
- en: Additionally, Win-Fail [[237](#bib.bib237)] is a dataset specifically designed
    for recognizing the outcome of actions, while SportsPose [[238](#bib.bib238)]
    is the largest markerless dataset for 3D human pose estimation in sports, containing
    5 short sports-related activities recorded from 7 cameras, totaling 1.5 million
    frames. SportsMOT [[239](#bib.bib239)] is a large-scale and high-quality multi-object
    tracking dataset comprising detailed annotations for each player present on the
    field in diverse sports scenarios. These datasets provide valuable resources for
    researchers to develop and evaluate algorithms for various sports-related tasks.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Win-Fail [[237](#bib.bib237)] 是一个专门设计用于识别动作结果的数据集，而 SportsPose [[238](#bib.bib238)]
    是最大规模的无标记数据集，用于体育中的 3D 人体姿态估计，包含 7 台摄像机记录的 5 个短体育相关活动，总计 150 万帧。SportsMOT [[239](#bib.bib239)]
    是一个大规模且高质量的多目标跟踪数据集，包含不同体育场景中每个球员的详细注释。这些数据集为研究人员开发和评估各种体育相关任务的算法提供了宝贵资源。
- en: V-M Others
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-M 其他
- en: CVBASE Handball [[271](#bib.bib271)] and CVBASE Squash [[271](#bib.bib271)]
    are developed for handball and squash action recognition, respectively, with annotated
    trajectories of players and action categories. GolfDB [[223](#bib.bib223)] facilitates
    the analysis of golf swings, providing 1,400 high-quality golf swing video segments,
    action labels, and bounding boxes of players. Lastly, FenceNet [[119](#bib.bib119)]
    consists of 652 videos of expert-level fencers performing six categories of actions,
    with RGB frames, 3D skeleton data, and depth data provided. Rugby sevens [[62](#bib.bib62)]
    is a public sports tracking dataset with tracking ground truth and the generated
    tracks. MLB-YouTube[[224](#bib.bib224)] is introduced for fine-grained action
    recognition in baseball videos.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: CVBASE Handball [[271](#bib.bib271)] 和 CVBASE Squash [[271](#bib.bib271)] 分别用于手球和壁球动作识别，附有球员的注释轨迹和动作类别。GolfDB
    [[223](#bib.bib223)] 促进了高尔夫挥杆的分析，提供了 1,400 个高质量的高尔夫挥杆视频片段、动作标签和球员的边界框。最后，FenceNet
    [[119](#bib.bib119)] 包含 652 个专家级击剑运动员执行六类动作的视频，提供 RGB 帧、3D 骨架数据和深度数据。Rugby sevens
    [[62](#bib.bib62)] 是一个公共体育跟踪数据集，包含跟踪真实情况和生成的轨迹。MLB-YouTube [[224](#bib.bib224)]
    用于细粒度的棒球视频动作识别。
- en: VI Virtual Environments
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 虚拟环境
- en: Researchers can utilize virtual environments for simulation. In a virtual environment
    that provides agents with simulated motion tasks, multiple data information can
    be continuously generated and retained in the simulation. For example, Fever Basketball [[183](#bib.bib183)]
    is an asynchronous environment, which supports multiple characters, multiple positions,
    and both the single-agent and multi-agent player control modes.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员可以利用虚拟环境进行模拟。在一个为代理提供模拟运动任务的虚拟环境中，可以不断生成和保留多种数据。例如，Fever Basketball [[183](#bib.bib183)]
    是一个异步环境，支持多角色、多位置，以及单代理和多代理控制模式。
- en: There are many virtual soccer games, such as rSoccer [[178](#bib.bib178)], RoboCup
    Soccer Simulator [[272](#bib.bib272)], the DeepMind MuJoCo Multi-Agent Soccer
    Environment [[179](#bib.bib179), [180](#bib.bib180)] and JiDi Olympics Football [[273](#bib.bib273)].
    rSoccer [[178](#bib.bib178)] and JiDi Olympics Football [[273](#bib.bib273)] are
    two toy football games in which plays are just rigid bodies and can just move
    and push the ball. However, players in GFootball [[181](#bib.bib181)] have more
    complex actions, such as dribbling, sliding, and sprinting. Besides, environments
    like RoboCup Soccer Simulator [[272](#bib.bib272)] and DeepMind MuJoCo Multi-Agent
    Soccer Environment [[179](#bib.bib179), [180](#bib.bib180)] focus more on low-level
    control of a physics simulation of robots, while GFootball focuses more on developing
    high-level tactics. To improve the flexibility and control over environment dynamics,
    SCENIC [[274](#bib.bib274)] is proposed to model and generate diverse scenarios
    in a real-time strategy environment programmatically.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 目前有许多虚拟足球游戏，例如 rSoccer [[178](#bib.bib178)]、RoboCup 足球模拟器 [[272](#bib.bib272)]、DeepMind
    MuJoCo 多智能体足球环境 [[179](#bib.bib179), [180](#bib.bib180)] 和 JiDi 奥林匹克足球 [[273](#bib.bib273)]。rSoccer [[178](#bib.bib178)]
    和 JiDi 奥林匹克足球 [[273](#bib.bib273)] 是两款玩具足球游戏，其中球员仅仅是刚体，能够移动和推球。然而，GFootball [[181](#bib.bib181)]
    中的球员具有更复杂的动作，例如带球、滑行和冲刺。此外，像 RoboCup 足球模拟器 [[272](#bib.bib272)] 和 DeepMind MuJoCo
    多智能体足球环境 [[179](#bib.bib179), [180](#bib.bib180)] 更注重机器人的物理仿真中的低级控制，而 GFootball
    更侧重于开发高级战术。为了提高对环境动态的灵活性和控制，提出了 SCENIC [[274](#bib.bib274)]，旨在通过编程的方式建模和生成实时策略环境中的多样化场景。
- en: VII Challenges
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VII 挑战
- en: In recent years, deep learning has emerged as a powerful tool in the analysis
    and enhancement of sports performance. The application of these advanced techniques
    has revolutionized the way athletes, coaches, and teams approach training, strategy,
    and decision-making. By leveraging the vast amounts of data generated in sports,
    deep learning models have the potential to uncover hidden patterns, optimize performance,
    and provide valuable insights that can inform decision-making processes. However,
    despite its promising potential, the implementation of deep learning in sports
    performance faces several challenges that need to be addressed to fully realize
    its benefits.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度学习已成为分析和提升运动表现的强大工具。这些先进技术的应用彻底改变了运动员、教练和团队在训练、战略和决策制定方面的方式。通过利用体育中生成的大量数据，深度学习模型有潜力揭示隐藏的模式、优化表现，并提供有价值的见解，从而为决策过程提供信息。然而，尽管其潜力很有希望，但深度学习在运动表现中的实施面临着几个挑战，需要解决这些挑战以充分发挥其优势。
- en: Task Challenge
  id: totrans-217
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 任务挑战
- en: The complex and dynamic nature of sports activities presents unique challenges
    for computer vision tasks in tracking and recognizing athletes and their movements.
    Issues such as identity mismatch due to similar appearances [[49](#bib.bib49),
    [48](#bib.bib48)], blurring [[52](#bib.bib52)] caused by rapid motion, and occlusion [[44](#bib.bib44),
    [45](#bib.bib45)] from other players or objects in the scene can lead to inaccuracies
    and inconsistencies in tracking and analysis. Developing robust and adaptable
    algorithms that can effectively handle these challenges is essential to improve
    the performance and reliability of deep learning models in sports applications.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 体育活动的复杂性和动态特性为计算机视觉任务中追踪和识别运动员及其动作带来了独特的挑战。诸如由于相似外观造成的身份不匹配 [[49](#bib.bib49),
    [48](#bib.bib48)]、快速运动引起的模糊 [[52](#bib.bib52)] 和来自其他球员或场景中的物体造成的遮挡 [[44](#bib.bib44),
    [45](#bib.bib45)] 等问题可能导致追踪和分析中的不准确性和不一致性。开发能够有效应对这些挑战的强大且适应性强的算法对于提高深度学习模型在体育应用中的性能和可靠性至关重要。
- en: Datasets Standardization
  id: totrans-219
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据集标准化
- en: Standardizing datasets for various sports is a daunting task, as each sport
    has unique technical aspects and rules that make it difficult to create a unified
    benchmark for specific tasks. For example, taking action recognition tasks as
    an example, in diving [[222](#bib.bib222)], only the movement of the athlete needs
    to be focused on, and attention should be paid to the details of role actions.
    However, in team sports such as volleyball [[251](#bib.bib251)], more attention
    is needed to distinguish and identify targets and cluster the same actions after
    identification. Given the varying emphases of tasks, there are substantial differences
    in the dataset requirements. To go further, action recognition of the same sport
    type, involves nuanced differences in label classification, making it challenging
    to develop a one-size-fits-all solution or benchmark. The creation of standardized,
    user-friendly, open-source, high-quality, and large-scale datasets is crucial
    for advancing research and enabling fair comparisons between different models
    and approaches in sports performance analysis.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 对各种运动标准化数据集是一项艰巨的任务，因为每项运动都有其独特的技术方面和规则，使得为特定任务创建统一基准变得困难。例如，以动作识别任务为例，在跳水中[[222](#bib.bib222)]，只需关注运动员的动作，关注角色动作的细节。然而，在排球等团队运动中[[251](#bib.bib251)]，需要更多关注目标的区分和识别，并在识别后对相同动作进行聚类。鉴于任务的不同侧重点，数据集需求存在显著差异。进一步来说，同一运动类型的动作识别涉及标签分类的细微差别，使得开发一个通用解决方案或基准变得具有挑战性。创建标准化、用户友好、开源、高质量和大规模的数据集对于推动研究进展并在体育表现分析中实现不同模型和方法之间的公平比较至关重要。
- en: Data Utilization
  id: totrans-221
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据利用
- en: The sports domain generates vast amounts of fine-grained data through sensors
    and IoT devices. However, current data processing methods primarily focus on computer
    vision and do not fully exploit the potential of end-to-end deep learning approaches.
    To fully harness the power of these rich data sources, researchers must develop
    methods that combine fine-grained sensor data with visual information. This fusion
    of diverse data streams can enable more comprehensive and insightful analysis,
    leading to significant advancements in the field of sports performance. Some studies
    have shown that introducing multi-modal data can benefit the analysis of athletic
    performance. For example, in table tennis, visual and IOT signals can be simultaneously
    used to analyze athlete performance [[275](#bib.bib275)]. In dance, visual and
    audio signals are both important [[202](#bib.bib202)]. More attention is needed
    on how to utilize diverse data, so as to achieve better fusion. Meanwhile, multi-modal
    algorithms and datasets [[202](#bib.bib202)] are both necessary.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 体育领域通过传感器和物联网设备生成大量细粒度数据。然而，目前的数据处理方法主要集中于计算机视觉，并没有充分利用端到端深度学习方法的潜力。为了充分发挥这些丰富数据源的作用，研究人员必须开发将细粒度传感器数据与视觉信息结合的方法。这种多样化数据流的融合可以实现更全面和深入的分析，推动体育表现领域的显著进展。一些研究表明，引入多模态数据可以有利于运动表现分析。例如，在乒乓球中，视觉和物联网信号可以同时用于分析运动员的表现[[275](#bib.bib275)]。在舞蹈中，视觉和音频信号都很重要[[202](#bib.bib202)]。需要更多关注如何利用多样化数据，以实现更好的融合。同时，多模态算法和数据集[[202](#bib.bib202)]都是必要的。
- en: VIII Future trend
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VIII 未来趋势
- en: The integration of deep learning methodologies into sports analytics can empower
    athletes, coaches, and teams with unprecedented insights into performance, decision-making,
    and injury prevention. This future work aims to explore the transformative impact
    of deep learning techniques in sports performance, focusing on data generation
    methods, multi-modality and multi-task models, foundation models, applications,
    and practicability.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习方法在体育分析中的整合可以为运动员、教练和团队提供前所未有的洞察力，提升表现、决策和伤害预防。这项未来的工作旨在探索深度学习技术在体育表现中的变革性影响，重点关注数据生成方法、多模态与多任务模型、基础模型、应用和可行性。
- en: Multi-modality and Multi-task
  id: totrans-225
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 多模态性与多任务
- en: By harnessing the power of multi-modal data and multi-task learning, robust
    and versatile models capable of handling diverse and complex sports-related challenges
    can be fulfilled. Furthermore, we will investigate the potential of large-scale
    models in enhancing predictive and analytical capabilities. It consists of practical
    applications and real-world implementations that can improve athlete performance
    and overall team dynamics. Ultimately, this work seeks to contribute to the growing
    body of research on deep learning in sports performance, paving the way for novel
    strategies and technologies that can revolutionize the world of sports analytics.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用多模态数据和多任务学习的力量，可以实现处理多样且复杂的体育相关挑战的强大而多功能的模型。此外，我们将探讨大型模型在提升预测和分析能力方面的潜力。它包括能够改善运动员表现和整体团队动态的实际应用和现实世界实施。*最终*，这项工作旨在为深度学习在体育表现研究中做出贡献，为创新的策略和技术铺平道路，从而彻底改变体育分析领域。
- en: Foundation Model
  id: totrans-227
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基础模型
- en: The popularity of ChatGPT has demonstrated the power of large language models [[276](#bib.bib276)],
    while the recent segment-anything project showcases the impressive performance
    of large models in visual tasks [[277](#bib.bib277)]. The prompt-based paradigm
    is highly capable and flexible in natural language processing and even image segmentation,
    offering unprecedented rich functionality. For example, some recent work has leveraged
    segment-anything in medical image [[278](#bib.bib278), [279](#bib.bib279), [280](#bib.bib280)],
    achieving promising results by providing point or bounding box prompts for preliminary
    zero-shot capability assessment, demonstrating that segment anything model (SAM)
    has good generalization performance in medical imaging. Therefore, the development
    of large models in the sports domain should consider how to combine existing large
    models to explore applications, and how to create large models specifically for
    the sports domain.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT的普及展示了大型语言模型的强大[[276](#bib.bib276)]，而最近的segment-anything项目展示了大型模型在视觉任务中的出色表现[[277](#bib.bib277)]。基于提示的范式在自然语言处理甚至图像分割中都具有极高的能力和灵活性，提供了前所未有的丰富功能。例如，一些近期工作利用segment-anything在医学图像中[[278](#bib.bib278),
    [279](#bib.bib279), [280](#bib.bib280)]，通过提供点或边界框提示进行初步的零样本能力评估，取得了有前景的结果，展示了segment
    anything模型（SAM）在医学成像中的良好泛化性能。因此，体育领域的大型模型开发应考虑如何结合现有的大型模型以探索应用，以及如何为体育领域专门创建大型模型。
- en: 'Combining large models requires considering the adaptability of the task. Compared
    to the medical field, sports involve a high level of human participation, inherently
    accommodating different levels and modalities of methods and data. We believe
    that both large language models in natural language processing and large image
    segmentation models in computer vision should have strong compatibility in sports.
    In short, we believe there is potential for exploring downstream tasks, such as
    using ChatGPT for performance evaluation and feedback: employ ChatGPT to generate
    natural language summaries of player or team performance, as well as provide personalized
    feedback and recommendations for improvement.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 结合大型模型需要考虑任务的适应性。与医学领域相比，体育涉及高度的人类参与，自然适应不同水平和方法的数据。我们相信，在体育领域，自然语言处理的大型语言模型和计算机视觉的大型图像分割模型应该具有强大的兼容性。简而言之，我们认为可以探索下游任务，例如使用ChatGPT进行表现评估和反馈：利用ChatGPT生成关于球员或团队表现的自然语言总结，并提供个性化反馈和改进建议。
- en: Foundation models directly related to the sports domain require a vast amount
    of data corresponding to the specific tasks. For visual tasks, for example, it
    is essential to ensure good scalability, adopt a prompt-based paradigm, and maintain
    powerful capabilities while being flexible and offering richer functionality.
    It is important to note that large models do not necessarily imply a large number
    of parameters, but rather a strong ability to solve tasks. Recent work on segment-anything
    has proven that even relatively simple models can achieve excellent performance
    when the data volume is sufficiently large. Therefore, creating large-scale, high-quality
    datasets in the sports domain remains a crucial task.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 与运动领域直接相关的基础模型需要大量与特定任务对应的数据。例如，对于视觉任务，确保良好的可扩展性、采用基于提示的范式，并在保持强大能力的同时具有灵活性和丰富功能至关重要。需要注意的是，大型模型不一定意味着参数数量多，而是解决任务的强大能力。近期关于segment-anything的研究证明，即使是相对简单的模型，当数据量足够大时也能实现优异的性能。因此，在运动领域创建大规模、高质量的数据集仍然是一个关键任务。
- en: Data Generation
  id: totrans-231
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据生成
- en: 'High-quality generated data can significantly reduce manual labor costs while
    demonstrating the diversity that generative models can bring. Many studies [[202](#bib.bib202),
    [281](#bib.bib281)] have focused on generating sports videos, offering easily
    editable, high-quality generation methods, which are elaborated upon in the relevant
    Section [IV-D](#S4.SS4 "IV-D Player Motion Synthesizing ‣ IV Decision ‣ A Survey
    of Deep Learning in Sports Applications: Perception, Comprehension, and Decision")
    and [IV-E](#S4.SS5 "IV-E Sport Video Synthesizing ‣ IV Decision ‣ A Survey of
    Deep Learning in Sports Applications: Perception, Comprehension, and Decision").
    Meanwhile, by combining large models, additional annotation work can be performed
    at this stage, and if possible, new usable data can be generated.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '高质量生成的数据可以显著降低人工劳动成本，同时展示生成模型所带来的多样性。许多研究[[202](#bib.bib202), [281](#bib.bib281)]集中于生成运动视频，提供了易于编辑的高质量生成方法，这些方法在相关章节[IV-D](#S4.SS4
    "IV-D Player Motion Synthesizing ‣ IV Decision ‣ A Survey of Deep Learning in
    Sports Applications: Perception, Comprehension, and Decision")和[IV-E](#S4.SS5
    "IV-E Sport Video Synthesizing ‣ IV Decision ‣ A Survey of Deep Learning in Sports
    Applications: Perception, Comprehension, and Decision")中有详细阐述。同时，通过结合大型模型，可以在此阶段进行额外的注释工作，并在可能的情况下生成新的可用数据。'
- en: Applications
  id: totrans-233
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 应用
- en: Though there are many excellent automatic algorithms for different tasks in
    the field of sports, they are still insufficient when it comes to deployment for
    specific tasks. In the daily exercise of ordinary people, who generally lack professional
    guidance, there should be more applications that make good use of these deep learning
    algorithms, and use more user-friendly and intelligent methods to promote sports
    for everyone. There are already some works [[282](#bib.bib282), [283](#bib.bib283),
    [284](#bib.bib284)] focusing on sports performance analysis, data recording visualization,
    energy expenditure estimation, and many other aspects. At the same time, in professional
    sports, there are also some works [[275](#bib.bib275), [16](#bib.bib16)] that
    focus on combining various data and methods to help improve athletic performance.
    Broadly speaking, in both daily life and professional fields, there is a need
    for more applications relating to health and fitness assessments.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在运动领域有许多优秀的自动算法用于不同任务，但在特定任务的部署上仍显不足。在普通人的日常锻炼中，通常缺乏专业指导，应该有更多的应用利用这些深度学习算法，并使用更友好和智能的方法来推广全民运动。已经有一些研究[[282](#bib.bib282),
    [283](#bib.bib283), [284](#bib.bib284)]集中于运动表现分析、数据记录可视化、能量消耗估计等多个方面。同时，在职业体育中，也有一些研究[[275](#bib.bib275),
    [16](#bib.bib16)]关注于结合各种数据和方法来帮助提高运动表现。广泛来说，无论是日常生活还是专业领域，都需要更多与健康和健身评估相关的应用。
- en: Practicability
  id: totrans-235
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 实用性
- en: In more challenging, high-level tasks with real-world applications, practicality
    becomes increasingly important. Many practical challenges remain unexplored or
    under-explored in applying deep learning to sports performance. In decision-making,
    for example, current solutions often rely on simulation-based approaches. However,
    multi-agent decision-making techniques hold great potential for enhancing real-world
    sports decision-making. Tasks such as ad-hoc teamwork [[285](#bib.bib285)] in
    multi-agent systems and zero-shot human-machine interaction are crucial for enabling
    effective and practical real-world applications. Further research is needed to
    bridge the gap between theoretical advancements and their practical implications
    in sports performance analysis and decision-making. For example, RoboCup [[272](#bib.bib272)]
    aims to defeat human players in the World Cup by 2050\. This complex task requires
    robots to perceive their environment, gather information, understand it, and execute
    specific actions. Such agents must exhibit sufficient generalization, engage in
    extensive human-machine interaction, and quickly respond to performance and environmental
    changes in real-time.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在更具挑战性的高层次任务中，实际应用的可行性变得越来越重要。许多实际挑战在将深度学习应用于体育表现中仍未被探索或尚未充分探索。例如，在决策制定中，目前的解决方案通常依赖于基于模拟的方法。然而，多智能体决策技术在提升现实世界体育决策中具有巨大的潜力。任务如多智能体系统中的临时团队合作[[285](#bib.bib285)]和零样本人机交互对实现有效且实际的现实世界应用至关重要。需要进一步研究以弥合理论进展与体育表现分析和决策制定实际影响之间的差距。例如，RoboCup[[272](#bib.bib272)]旨在到2050年战胜世界杯上的人类选手。这一复杂任务要求机器人感知其环境、收集信息、理解信息，并执行特定的动作。这些代理必须展示足够的泛化能力，进行广泛的人机交互，并实时响应表现和环境变化。
- en: IX Conclusion
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IX 结论
- en: 'In this paper, we present a comprehensive survey of deep learning in sports,
    focusing on four main aspects: algorithms, datasets, challenges, and future works.
    We innovatively summarize the taxonomy and divide methods into perception, comprehension,
    and decision from low-level to high-level tasks. In the challenges and future
    works, we provide cutting-edge methods and give insights into the future trends
    and challenges of deep learning in sports.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们对体育领域的深度学习进行了全面调查，重点关注四个主要方面：算法、数据集、挑战和未来工作。我们创新性地总结了分类法，并将方法从低级任务到高级任务分为感知、理解和决策。在挑战和未来工作部分，我们提供了前沿方法，并对深度学习在体育中的未来趋势和挑战进行了洞察。
- en: Acknowledgments
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work is supported by National Key R&D Program of China under Grant No.2022ZD0162000,
    and National Natural Science Foundation of China No.62106219.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作得到中国国家重点研发计划（资助编号2022ZD0162000）和国家自然科学基金（编号62106219）的支持。
- en: References
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] N. Chmait and H. Westerbeek, “Artificial intelligence and machine learning
    in sport research: An introduction for non-data scientists,” *Frontiers in Sports
    and Active Living*, p. 363, 2021.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] N. Chmait 和 H. Westerbeek，“体育研究中的人工智能和机器学习：非数据科学家的介绍，” *体育与活跃生活前沿*，363页，2021年。'
- en: '[2] “Smt,” [https://www.smt.com/](https://www.smt.com/).'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] “Smt，” [https://www.smt.com/](https://www.smt.com/)。'
- en: '[3] “vizrt,” [https://www.vizrt.com/](https://www.vizrt.com/).'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] “vizrt，” [https://www.vizrt.com/](https://www.vizrt.com/)。'
- en: '[4] A. Duarte, C. Micael, S. Ludovic, S. Hugo, and D. Keith, *Artificial Intelligence
    in Sport Performance Analysis*, 2021.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] A. Duarte, C. Micael, S. Ludovic, S. Hugo, 和 D. Keith, *体育表现分析中的人工智能*，2021年。'
- en: '[5] E. E. Cust, A. J. Sweeting, K. Ball, and S. Robertson, “Machine and deep
    learning for sport-specific movement recognition: a systematic review of model
    development and performance,” *Journal of sports sciences*, vol. 37, no. 5, pp.
    568–600, 2019.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] E. E. Cust, A. J. Sweeting, K. Ball, 和 S. Robertson，“针对特定运动的机器学习和深度学习：模型发展与性能的系统评述，”
    *运动科学期刊*，第37卷，第5期，568–600页，2019年。'
- en: '[6] R. P. Bonidia, L. A. Rodrigues, A. P. Avila-Santos, D. S. Sanches, J. D.
    Brancher *et al.*, “Computational intelligence in sports: A systematic literature
    review,” *Advances in Human-Computer Interaction*, vol. 2018, 2018.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] R. P. Bonidia, L. A. Rodrigues, A. P. Avila-Santos, D. S. Sanches, J. D.
    Brancher *等*，“体育中的计算智能：系统文献综述，” *人机交互进展*，第2018卷，2018年。'
- en: '[7] R. Beal, T. J. Norman, and S. D. Ramchurn, “Artificial intelligence for
    team sports: a survey,” *The Knowledge Engineering Review*, vol. 34, p. e28, 2019.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] R. Beal, T. J. Norman, 和 S. D. Ramchurn，“团队运动中的人工智能：调查，” *知识工程评论*，第34卷，e28页，2019年。'
- en: '[8] D. Tan, H. Ting, and S. Lau, “A review on badminton motion analysis,” in
    *2016 International Conference on Robotics, Automation and Sciences (ICORAS)*.   IEEE,
    2016, pp. 1–4.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] D. Tan, H. Ting, 和 S. Lau，“羽毛球运动分析综述”，在 *2016 年国际机器人、自动化与科学会议（ICORAS）*
    中。IEEE, 2016, pp. 1–4.'
- en: '[9] F. Wu, Q. Wang, J. Bian, N. Ding, F. Lu, J. Cheng, D. Dou, and H. Xiong,
    “A survey on video action recognition in sports: Datasets, methods and applications,”
    *IEEE Transactions on Multimedia*, 2022.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] F. Wu, Q. Wang, J. Bian, N. Ding, F. Lu, J. Cheng, D. Dou, 和 H. Xiong，“关于体育视频动作识别的调查：数据集、方法与应用”，*IEEE
    多媒体汇刊*，2022.'
- en: '[10] S. Wang, D. Yang, P. Zhai, Q. Yu, T. Suo, Z. Sun, K. Li, and L. Zhang,
    “A survey of video-based action quality assessment,” in *2021 International Conference
    on Networking Systems of AI (INSAI)*.   IEEE, 2021, pp. 1–9.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] S. Wang, D. Yang, P. Zhai, Q. Yu, T. Suo, Z. Sun, K. Li, 和 L. Zhang，“基于视频的动作质量评估综述”，在
    *2021 年国际人工智能网络系统会议（INSAI）* 中。IEEE, 2021, pp. 1–9.'
- en: '[11] P. R. Kamble, A. G. Keskar, and K. M. Bhurchandi, “Ball tracking in sports:
    a survey,” *Artificial Intelligence Review*, vol. 52, no. 3, pp. 1655–1705, 2019.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] P. R. Kamble, A. G. Keskar, 和 K. M. Bhurchandi，“体育中的球跟踪：综述”，*人工智能评论*，第
    52 卷，第 3 期，pp. 1655–1705, 2019.'
- en: '[12] Y. Adesida, E. Papi, and A. H. McGregor, “Exploring the role of wearable
    technology in sport kinematics and kinetics: A systematic review,” *Sensors*,
    vol. 19, no. 7, p. 1597, 2019.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Y. Adesida, E. Papi, 和 A. H. McGregor，“探索可穿戴技术在运动运动学和动力学中的作用：系统综述”，*传感器*，第
    19 卷，第 7 期，p. 1597, 2019.'
- en: '[13] M. Rana and V. Mittal, “Wearable sensors for real-time kinematics analysis
    in sports: a review,” *IEEE Sensors Journal*, vol. 21, no. 2, pp. 1187–1207, 2020.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] M. Rana 和 V. Mittal，“用于实时运动学分析的可穿戴传感器：综述”，*IEEE 传感器期刊*，第 21 卷，第 2 期，pp.
    1187–1207, 2020.'
- en: '[14] E. Van der Kruk and M. M. Reijne, “Accuracy of human motion capture systems
    for sport applications; state-of-the-art review,” *European journal of sport science*,
    vol. 18, no. 6, pp. 806–819, 2018.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] E. Van der Kruk 和 M. M. Reijne，“运动应用中的人类运动捕捉系统的准确性；最前沿综述”，*欧洲运动科学杂志*，第
    18 卷，第 6 期，pp. 806–819, 2018.'
- en: '[15] A. M. Turing, *Computing machinery and intelligence*.   Springer, 2009.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] A. M. Turing, *计算机械与智能*。Springer, 2009.'
- en: '[16] J. Wang, K. Qiu, H. Peng, J. Fu, and J. Zhu, “Ai coach: Deep human pose
    estimation and analysis for personalized athletic training assistance,” in *Proceedings
    of the 27th ACM international conference on multimedia*, 2019, pp. 374–382.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. Wang, K. Qiu, H. Peng, J. Fu, 和 J. Zhu，“AI 教练：深度人体姿态估计与分析用于个性化运动训练辅助”，在
    *第 27 届 ACM 国际多媒体会议论文集* 中，2019, pp. 374–382.'
- en: '[17] U. Rao and U. C. Pati, “A novel algorithm for detection of soccer ball
    and player,” in *2015 International Conference on Communications and Signal Processing
    (ICCSP)*.   IEEE, 2015, pp. 0344–0348.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] U. Rao 和 U. C. Pati，“一种新颖的足球和运动员检测算法”，在 *2015 年国际通信与信号处理会议（ICCSP）* 中。IEEE,
    2015, pp. 0344–0348.'
- en: '[18] Y. Yang, M. Xu, W. Wu, R. Zhang, and Y. Peng, “3d multiview basketball
    players detection and localization based on probabilistic occupancy,” in *2018
    Digital Image Computing: Techniques and Applications (DICTA)*.   IEEE, 2018, pp.
    1–8.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Y. Yang, M. Xu, W. Wu, R. Zhang, 和 Y. Peng，“基于概率占用的 3D 多视角篮球运动员检测与定位”，在
    *2018 年数字图像计算：技术与应用（DICTA）* 中。IEEE, 2018, pp. 1–8.'
- en: '[19] M. Şah and C. Direkoğlu, “Evaluation of image representations for player
    detection in field sports using convolutional neural networks,” in *13th International
    Conference on Theory and Application of Fuzzy Systems and Soft Computing—ICAFS-2018
    13*.   Springer, 2019, pp. 107–115.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] M. Şah 和 C. Direkoğlu，“使用卷积神经网络对场地运动中球员检测的图像表示进行评估”，在 *第 13 届模糊系统与软计算理论与应用国际会议——ICAFS-2018
    13* 中。Springer, 2019, pp. 107–115.'
- en: '[20] S. Gerke, A. Linnemann, and K. Müller, “Soccer player recognition using
    spatial constellation features and jersey number recognition,” *Computer Vision
    and Image Understanding*, vol. 159, pp. 105–115, 2017.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] S. Gerke, A. Linnemann, 和 K. Müller，“利用空间星座特征和球衣号码识别的足球运动员识别”，*计算机视觉与图像理解*，第
    159 卷，pp. 105–115, 2017.'
- en: '[21] G. Li, S. Xu, X. Liu, L. Li, and C. Wang, “Jersey number recognition with
    semi-supervised spatial transformer network,” in *Proceedings of the IEEE conference
    on computer vision and pattern recognition workshops*, 2018, pp. 1783–1790.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] G. Li, S. Xu, X. Liu, L. Li, 和 C. Wang，“基于半监督空间变换网络的球衣号码识别”，在 *IEEE 计算机视觉与模式识别会议论文集*
    中，2018, pp. 1783–1790.'
- en: '[22] H. Liu and B. Bhanu, “Pose-guided r-cnn for jersey number recognition
    in sports,” in *Proceedings of the IEEE/CVF Conference on Computer Vision and
    Pattern Recognition Workshops*, 2019, pp. 0–0.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] H. Liu 和 B. Bhanu，“基于姿态的r-cnn用于体育中的球衣号码识别”，在*IEEE/CVF计算机视觉与模式识别会议研讨会*，2019年，第0–0页。'
- en: '[23] M. Istasse, J. Moreau, and C. De Vleeschouwer, “Associative embedding
    for team discrimination,” in *Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition Workshops*, 2019, pp. 0–0.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] M. Istasse, J. Moreau, 和 C. De Vleeschouwer，“用于团队区分的关联嵌入”，在*IEEE/CVF计算机视觉与模式识别会议研讨会*，2019年，第0–0页。'
- en: '[24] M. Koshkina, H. Pidaparthy, and J. H. Elder, “Contrastive learning for
    sports video: Unsupervised player classification,” in *Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition*, 2021, pp. 4528–4536.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] M. Koshkina, H. Pidaparthy, 和 J. H. Elder，“用于体育视频的对比学习：无监督球员分类”，在*IEEE/CVF计算机视觉与模式识别会议论文集*，2021年，第4528–4536页。'
- en: '[25] M. Manafifard, H. Ebadi, and H. A. Moghaddam, “A survey on player tracking
    in soccer videos,” *Computer Vision and Image Understanding*, vol. 159, pp. 19–46,
    2017.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] M. Manafifard, H. Ebadi, 和 H. A. Moghaddam，“关于足球视频中球员追踪的调查”，*计算机视觉与图像理解*，第159卷，第19–46页，2017年。'
- en: '[26] R. Theagarajan, F. Pala, X. Zhang, and B. Bhanu, “Soccer: Who has the
    ball? generating visual analytics and player statistics,” in *Proceedings of the
    IEEE Conference on Computer Vision and Pattern Recognition Workshops*, 2018, pp.
    1749–1757.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] R. Theagarajan, F. Pala, X. Zhang, 和 B. Bhanu，“足球：谁在控球？生成视觉分析和球员统计”，在*IEEE计算机视觉与模式识别会议研讨会*，2018年，第1749–1757页。'
- en: '[27] A. Arbues-Sanguesa, A. Martín, J. Fernández, C. Ballester, and G. Haro,
    “Using player’s body-orientation to model pass feasibility in soccer,” in *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops*,
    2020, pp. 886–887.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] A. Arbues-Sanguesa, A. Martín, J. Fernández, C. Ballester, 和 G. Haro，“使用球员身体方向建模足球传球可行性”，在*IEEE/CVF计算机视觉与模式识别会议研讨会*，2020年，第886–887页。'
- en: '[28] S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards real-time
    object detection with region proposal networks,” in *Advances in Neural Information
    Processing Systems (NeurIPS)*, vol. 28, 2015, pp. 91–99.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] S. Ren, K. He, R. Girshick, 和 J. Sun，“Faster r-cnn：通过区域提议网络实现实时物体检测”，在*神经信息处理系统进展（NeurIPS）*，第28卷，2015年，第91–99页。'
- en: '[29] A. Cioppa, A. Deliege, M. Istasse, C. De Vleeschouwer, and M. Van Droogenbroeck,
    “Arthus: Adaptive real-time human segmentation in sports through online distillation,”
    in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
    Workshops*, 2019, pp. 0–0.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] A. Cioppa, A. Deliege, M. Istasse, C. De Vleeschouwer, 和 M. Van Droogenbroeck，“Arthus：通过在线蒸馏在体育中实现自适应实时人体分割”，在*IEEE/CVF计算机视觉与模式识别会议研讨会*，2019年，第0–0页。'
- en: '[30] R. Vandeghen, A. Cioppa, and M. Van Droogenbroeck, “Semi-supervised training
    to improve player and ball detection in soccer,” in *Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition*, 2022, pp. 3481–3490.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] R. Vandeghen, A. Cioppa, 和 M. Van Droogenbroeck，“半监督训练以提高足球中球员和球的检测”，在*IEEE/CVF计算机视觉与模式识别会议论文集*，2022年，第3481–3490页。'
- en: '[31] R. Sanford, S. Gorji, L. G. Hafemann, B. Pourbabaee, and M. Javan, “Group
    activity detection from trajectory and video data in soccer,” in *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops*,
    2020, pp. 898–899.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] R. Sanford, S. Gorji, L. G. Hafemann, B. Pourbabaee, 和 M. Javan，“基于轨迹和视频数据的群体活动检测”，在*IEEE/CVF计算机视觉与模式识别会议研讨会*，2020年，第898–899页。'
- en: '[32] A. Cioppa, A. Deliege, F. Magera, S. Giancola, O. Barnich, B. Ghanem,
    and M. Van Droogenbroeck, “Camera calibration and player localization in soccernet-v2
    and investigation of their representations for action spotting,” in *Proceedings
    of the IEEE/CVF Conference on CVPR*, 2021, pp. 4537–4546.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] A. Cioppa, A. Deliege, F. Magera, S. Giancola, O. Barnich, B. Ghanem,
    和 M. Van Droogenbroeck，“Soccernet-v2中的相机标定与球员定位及其在动作检测中的表示调查”，在*IEEE/CVF计算机视觉与模式识别会议论文集*，2021年，第4537–4546页。'
- en: '[33] A. Cioppa, S. Giancola, A. Deliege, L. Kang, X. Zhou, Z. Cheng, B. Ghanem,
    and M. Van Droogenbroeck, “Soccernet-tracking: Multiple object tracking dataset
    and benchmark in soccer videos,” in *Proceedings of the IEEE/CVF Conference on
    Computer Vision and Pattern Recognition*, 2022, pp. 3491–3502.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] A. Cioppa, S. Giancola, A. Deliege, L. Kang, X. Zhou, Z. Cheng, B. Ghanem,
    和 M. Van Droogenbroeck，“Soccernet-tracking：足球视频中的多目标追踪数据集和基准”，在*IEEE/CVF计算机视觉与模式识别会议论文集*，2022年，第3491–3502页。'
- en: '[34] A. Cioppa, A. Deliège, S. Giancola, B. Ghanem, and M. Van Droogenbroeck,
    “Scaling up soccernet with multi-view spatial localization and re-identification,”
    *Scientific Data*, vol. 9, no. 1, p. 355, 2022.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] A. Cioppa、A. Deliège、S. Giancola、B. Ghanem 和 M. Van Droogenbroeck，"多视图空间定位和重新识别扩展
    Soccernet"，《科学数据》，第 9 卷，第 1 期，2022 年，页码 355。'
- en: '[35] I. Uchida, A. Scott, H. Shishido, and Y. Kameda, “Automated offside detection
    by spatio-temporal analysis of football videos,” in *Proceedings of the 4th International
    Workshop on Multimedia Content Analysis in Sports*, 2021, pp. 17–24.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] I. Uchida、A. Scott、H. Shishido 和 Y. Kameda，"通过对足球视频的时空分析实现自动越位检测"，第 4
    届国际多媒体内容分析工作坊录稿集，2021 年，页码 17-24。'
- en: '[36] G. Van Zandycke, V. Somers, M. Istasse, C. D. Don, and D. Zambrano, “Deepsportradar-v1:
    Computer vision dataset for sports understanding with high quality annotations,”
    in *Proceedings of the 5th International ACM Workshop on Multimedia Content Analysis
    in Sports*, 2022, pp. 1–8.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] G. Van Zandycke、V. Somers、M. Istasse、C. D. Don 和 D. Zambrano，"Deepsportradar-v1:
    计算机视觉数据集，用于高质量注释的体育理解"，第 5 届国际 ACM 多媒体内容分析工作坊论文集，2022 年，页码 1-8。'
- en: '[37] R. Voeikov, N. Falaleev, and R. Baikulov, “Ttnet: Real-time temporal and
    spatial video analysis of table tennis,” in *Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition Workshops*, 2020, pp. 884–885.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] R. Voeikov、N. Falaleev 和 R. Baikulov，"Ttnet：实时且时空的乒乓球视频分析"，《IEEE/CVF 计算机视觉与模式识别会议录稿集》，2020
    年，页码 884-885。'
- en: '[38] A. Maksai, X. Wang, and P. Fua, “What players do with the ball: A physically
    constrained interaction modeling,” in *Proceedings of the IEEE conference on computer
    vision and pattern recognition*, 2016, pp. 972–981.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] A. Maksai、X. Wang 和 P. Fua，"球员如何使用球：物理约束交互建模"，《IEEE 计算机视觉和模式识别会议录稿集》，2016
    年，页码 972-981。'
- en: '[39] X. Cheng, N. Ikoma, M. Honda, and T. Ikenaga, “Simultaneous physical and
    conceptual ball state estimation in volleyball game analysis,” in *2017 IEEE Visual
    Communications and Image Processing (VCIP)*.   IEEE, 2017, pp. 1–4.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] X. Cheng、N. Ikoma、M. Honda 和 T. Ikenaga，"排球比赛分析中的物理和概念球状态同时估计"，2017 年
    IEEE 视觉通信和图像处理大会（VCIP）论文集，IEEE，2017 年，页码 1-4。'
- en: '[40] P. Parisot and C. De Vleeschouwer, “Consensus-based trajectory estimation
    for ball detection in calibrated cameras systems,” *Journal of Real-Time Image
    Processing*, vol. 16, no. 5, pp. 1335–1350, 2019.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] P. Parisot 和 C. De Vleeschouwer，"Consensus-based trajectory estimation
    for ball detection in calibrated cameras systems"，《实时图像处理杂志》，第 16 卷，第 5 期，2019
    年，页码 1335-1350。'
- en: '[41] J. Sköld, “Estimating 3d-trajectories from monocular video sequences,”
    2015.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] J. Sköld，"从单目视频序列中估计三维轨迹"，2015 年。'
- en: '[42] G. Van Zandycke and C. De Vleeschouwer, “3d ball localization from a single
    calibrated image,” in *Proceedings of the IEEE/CVF Conference on CVPR*, 2022,
    pp. 3472–3480.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] G. Van Zandycke 和 C. De Vleeschouwer，"从单个校准图像定位 3D 球"，《IEEE/CVF 计算机视觉与模式识别会议录稿集》，2022
    年，页码 3472-3480。'
- en: '[43] P. Liu and J.-H. Wang, “Monotrack: Shuttle trajectory reconstruction from
    monocular badminton video,” in *Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition*, 2022, pp. 3513–3522.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] P. Liu 和 J.-H. Wang，"Monotrack：单目羽毛球视频中航天飞机轨迹重建"，《IEEE/CVF 计算机视觉与模式识别会议录稿集》，2022
    年，页码 3513-3522。'
- en: '[44] B. T. Naik, M. F. Hashmi, Z. W. Geem, and N. D. Bokde, “Deepplayer-track:
    player and referee tracking with jersey color recognition in soccer,” *IEEE Access*,
    vol. 10, pp. 32 494–32 509, 2022.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] B. T. Naik、M. F. Hashmi、Z. W. Geem 和 N. D. Bokde，"Deepplayer-track：具有球衣颜色识别的足球运动员和裁判跟踪"，《IEEE
    Access》，第 10 卷，页码 32 494-32 509，2022 年。'
- en: '[45] B. T. Naik and M. F. Hashmi, “Yolov3-sort: detection and tracking player/ball
    in soccer sport,” *Journal of Electronic Imaging*, vol. 32, no. 1, pp. 011 003–011 003,
    2023.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] B. T. Naik 和 M. F. Hashmi，"Yolov3-sort：检测和跟踪足球运动中的球员/球"，《电子成像杂志》，第 32
    卷，第 1 期，页码 011 003-011 003，2023 年。'
- en: '[46] A. Bewley, Z. Ge, L. Ott, F. Ramos, and B. Upcroft, “Simple online and
    realtime tracking,” in *2016 IEEE international conference on image processing
    (ICIP)*.   IEEE, 2016, pp. 3464–3468.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] A. Bewley、Z. Ge、L. Ott、F. Ramos 和 B. Upcroft，"Simple online and realtime
    tracking"，《2016 IEEE 国际图像处理会议（ICIP）论文集》，IEEE，2016 年，页码 3464-3468。'
- en: '[47] S. Hurault, C. Ballester, and G. Haro, “Self-supervised small soccer player
    detection and tracking,” in *Proceedings of the 3rd international workshop on
    multimedia content analysis in sports*, 2020, pp. 9–18.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] S. Hurault、C. Ballester 和 G. Haro，"自我监督的小型足球运动员检测和跟踪"，第 3 届国际多媒体内容分析工作坊录稿集，2020
    年，页码 9-18。'
- en: '[48] R. Zhang, L. Wu, Y. Yang, W. Wu, Y. Chen, and M. Xu, “Multi-camera multi-player
    tracking with deep player identification in sports video,” *Pattern Recognition*,
    vol. 102, p. 107260, 2020.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] R. Zhang, L. Wu, Y. Yang, W. Wu, Y. Chen 和 M. Xu，“多摄像头多运动员跟踪与深度运动员识别在体育视频中的应用，”
    *模式识别*，第102卷，第107260页，2020。'
- en: '[49] P. Sun, J. Cao, Y. Jiang, Z. Yuan, S. Bai, K. Kitani, and P. Luo, “Dancetrack:
    Multi-object tracking in uniform appearance and diverse motion,” *arXiv preprint
    arXiv:2111.14690*, 2021.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] P. Sun, J. Cao, Y. Jiang, Z. Yuan, S. Bai, K. Kitani 和 P. Luo，“Dancetrack：均匀外观和多样运动中的多目标跟踪，”
    *arXiv 预印本 arXiv:2111.14690*，2021。'
- en: '[50] M. Buric, M. Ivasic-Kos, and M. Pobar, “Player tracking in sports videos,”
    in *2019 IEEE International Conference on Cloud Computing Technology and Science
    (CloudCom)*, 2019, pp. 334–340.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] M. Buric, M. Ivasic-Kos 和 M. Pobar，“运动视频中的运动员跟踪，” 在 *2019年IEEE国际云计算技术与科学会议
    (CloudCom)* 中，2019，pp. 334–340。'
- en: '[51] N. Wojke, A. Bewley, and D. Paulus, “Simple online and realtime tracking
    with a deep association metric,” in *2017 IEEE international conference on image
    processing (ICIP)*.   IEEE, 2017, pp. 3645–3649.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] N. Wojke, A. Bewley 和 D. Paulus，“基于深度关联度量的简单在线和实时跟踪，” 在 *2017年IEEE国际图像处理会议
    (ICIP)* 中。IEEE，2017，pp. 3645–3649。'
- en: '[52] Y.-C. Huang, I.-N. Liao, C.-H. Chen, T.-U. İk, and W.-C. Peng, “Tracknet:
    A deep learning network for tracking high-speed and tiny objects in sports applications,”
    in *2019 16th IEEE International Conference on Advanced Video and Signal Based
    Surveillance (AVSS)*, 2019, pp. 1–8.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] Y.-C. Huang, I.-N. Liao, C.-H. Chen, T.-U. İk 和 W.-C. Peng，“Tracknet：用于体育应用中跟踪高速和微小物体的深度学习网络，”
    在 *2019年第16届IEEE国际高级视频与信号基监测会议 (AVSS)* 中，2019，pp. 1–8。'
- en: '[53] V. Belagiannis and A. Zisserman, “Recurrent human pose estimation,” in
    *2017 12th IEEE International Conference on Automatic Face & Gesture Recognition
    (FG 2017)*.   IEEE, 2017, pp. 468–475.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] V. Belagiannis 和 A. Zisserman，“递归人体姿态估计，” 在 *2017年第12届IEEE国际面部与手势识别会议
    (FG 2017)* 中。IEEE，2017，pp. 468–475。'
- en: '[54] T. Pfister, J. Charles, and A. Zisserman, “Flowing convnets for human
    pose estimation in videos,” in *Proceedings of the IEEE international conference
    on computer vision*, 2015, pp. 1913–1921.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] T. Pfister, J. Charles 和 A. Zisserman，“流动卷积网络在视频中的人体姿态估计，” 在 *IEEE国际计算机视觉会议论文集*
    中，2015，pp. 1913–1921。'
- en: '[55] S. Schwarcz, P. Xu, D. D’Ambrosio, J. Kangaspunta, A. Angelova, H. Phan,
    and N. Jaitly, “Spin: A high speed, high resolution vision dataset for tracking
    and action recognition in ping pong,” *arXiv preprint arXiv:1912.06640*, 2019.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] S. Schwarcz, P. Xu, D. D’Ambrosio, J. Kangaspunta, A. Angelova, H. Phan
    和 N. Jaitly，“Spin：用于乒乓球跟踪和动作识别的高速、高分辨率视觉数据集，” *arXiv 预印本 arXiv:1912.06640*，2019。'
- en: '[56] B. Comandur, “Sports re-id: Improving re-identification of players in
    broadcast videos of team sports,” *arXiv preprint arXiv:2206.02373*, 2022.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] B. Comandur，“运动员重新识别：改进团队运动广播视频中运动员的重新识别，” *arXiv 预印本 arXiv:2206.02373*，2022。'
- en: '[57] A. Nady and E. E. Hemayed, “Player identification in different sports,”
    in *VISIGRAPP*, 2021.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] A. Nady 和 E. E. Hemayed，“不同运动中的运动员识别，” 在 *VISIGRAPP* 中，2021。'
- en: '[58] A. Senocak, T.-H. Oh, J. Kim, and I. S. Kweon, “Part-based player identification
    using deep convolutional representation and multi-scale pooling,” in *2018 IEEE/CVF
    Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)*, 2018,
    pp. 1813–18 137.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] A. Senocak, T.-H. Oh, J. Kim 和 I. S. Kweon，“基于部件的运动员识别，使用深度卷积表示和多尺度池化，”
    在 *2018 IEEE/CVF计算机视觉与模式识别研讨会 (CVPRW)* 中，2018，pp. 1813–18 137。'
- en: '[59] O. M. Teket and I. S. Yetik, “A fast deep learning based approach for
    basketball video analysis,” in *Proceedings of the 2020 4th International Conference
    on Vision, Image and Signal Processing*, ser. ICVISP 2020.   New York, NY, USA:
    Association for Computing Machinery, 2020\. [Online]. Available: [https://doi.org/10.1145/3448823.3448882](https://doi.org/10.1145/3448823.3448882)'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] O. M. Teket 和 I. S. Yetik，“一种快速的基于深度学习的篮球视频分析方法，” 在 *2020年第四届国际视觉、图像和信号处理会议论文集*
    中，ICVISP 2020。纽约，NY，美国：计算机协会，2020年。[在线]. 可用：[https://doi.org/10.1145/3448823.3448882](https://doi.org/10.1145/3448823.3448882)'
- en: '[60] Q. An, K. Cui, R. Liu, C. Wang, M. Qi, and H. Ma, “Attention-aware multiple
    granularities network for player re-identification,” in *Proceedings of the 5th
    International ACM Workshop on Multimedia Content Analysis in Sports*, 2022, pp.
    137–144.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Q. An, K. Cui, R. Liu, C. Wang, M. Qi 和 H. Ma，“关注感知的多粒度网络用于运动员重新识别，” 在
    *第5届国际ACM运动多媒体内容分析研讨会论文集* 中，2022，pp. 137–144。'
- en: '[61] K. Habel, F. Deuser, and N. Oswald, “Clip-reident: Contrastive training
    for player re-identification,” in *Proceedings of the 5th International ACM Workshop
    on Multimedia Content Analysis in Sports*, 2022, pp. 129–135.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] K. Habel，F.Deuser和N.Oswald，“Clip-reident：针对运动员重新识别的对比式训练”，收录于《第五届国际多媒体内容分析工作坊论文集》，2022年，第129-135页。'
- en: '[62] A. Maglo, A. Orcesi, and Q.-C. Pham, “Efficient tracking of team sport
    players with few game-specific annotations,” in *Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition*, 2022, pp. 3461–3471.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] A.Maglo，A.Orcesi和Q.-C.Pham，“用少量特定于游戏的注释高效跟踪团队体育运动员”，收录于《IEEE/CVF计算机视觉与模式识别会议论文集》，2022年，第3461-3471页。'
- en: '[63] K. Vats, W. McNally, P. Walters, D. A. Clausi, and J. S. Zelek, “Ice hockey
    player identification via transformers,” *arXiv preprint arXiv:2111.11535*, 2021.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] K.Vats，W.McNally，P.Walters，D.A.Clausi和J.S.Zelek，“通过变压器进行冰球球员识别”，《arXiv预印本arXiv:2111.11535》，2021年。'
- en: '[64] B. Yan, Y. Li, X. Zhao, and H. Wang, “Dual data augmentation method for
    data-deficient and occluded instance segmentation,” in *Proceedings of the 5th
    International ACM Workshop on Multimedia Content Analysis in Sports*, 2022, pp.
    117–120.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] B.Yan，Y.Li，X.Zhao和H.Wang，“双重数据增强方法用于数据不足和遮挡的实例分割”，收录于《第五届国际多媒体内容分析工作坊论文集》，2022年，第117-120页。'
- en: '[65] B. Yan, F. Qi, Z. Li, Y. Li, and H. Wang, “Strong instance segmentation
    pipeline for mmsports challenge,” *arXiv preprint arXiv:2209.13899*, 2022.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] B.Yan，F.Qi，Z.Li，Y.Li和H.Wang，“Mmsports挑战的强大实例分割管道”，《arXiv预印本arXiv:2209.13899》，2022年。'
- en: '[66] G. Ghiasi, Y. Cui, A. Srinivas, R. Qian, T.-Y. Lin, E. D. Cubuk, Q. V.
    Le, and B. Zoph, “Simple copy-paste is a strong data augmentation method for instance
    segmentation,” in *Proceedings of the IEEE/CVF conference on computer vision and
    pattern recognition*, 2021, pp. 2918–2928.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] G.Ghiasi，Y.Cui，A.Srinivas，R.Qian，T.-Y.Lin，E.D.Cubuk，Q.V.Le和B.Zoph，“简单的复制粘贴是一种强大的实例分割数据增强方法”，收录于《计算机视觉和模式识别的IEEE/CVF会议论文集》，2021年，第2918-2928页。'
- en: '[67] C. Zhang, M. Wang, and L. Zhou, “Recognition method of basketball players’
    throwing action based on image segmentation,” *International Journal of Biometrics*,
    vol. 15, no. 2, pp. 121–133, 2023.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] C. Zhang，M.Wang和L.Zhou，“基于图像分割的篮球运动员投篮动作识别方法”，《国际生物识别学杂志》，第15卷，第2期，第121-133页，2023年。'
- en: '[68] K. He, G. Gkioxari, P. Dollár, and R. Girshick, “Mask r-cnn,” in *2017
    IEEE International Conference on Computer Vision (ICCV)*, 2017, pp. 2980–2988.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] K.He，G.Gkioxari，P.Dollár和R.Girshick，“Mask r-cnn”，收录于《2017年IEEE计算机视觉国际会议（ICCV）》
    ，2017年，第2980-2988页。'
- en: '[69] W. Chai, Z. Jiang, J.-N. Hwang, and G. Wang, “Global adaptation meets
    local generalization: Unsupervised domain adaptation for 3d human pose estimation,”
    *arXiv preprint arXiv:2303.16456*, 2023.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] W. Chai，Z.Jiang，J.-N.Hwang和G.Wang，“全局适应性遇到局部概括：针对3D人体姿势估计的无监督领域适应”，《arXiv预印本arXiv:2303.16456》，2023年。'
- en: '[70] Z. Cao, G. Hidalgo, T. Simon, S.-E. Wei, and Y. Sheikh, “Openpose: realtime
    multi-person 2d pose estimation using part affinity fields,” *IEEE transactions
    on pattern analysis and machine intelligence*, vol. 43, no. 1, pp. 172–186, 2021.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] Z. Cao，G. Hidalgo，T. Simon，S.-E.Wei和Y.Sheikh，“Openpose：基于部分亲和场的实时多人二维姿势估计”，《IEEE模式分析与机器智能交易》，第43卷，第1期，第172-186页，2021年。'
- en: '[71] N. Promrit and S. Waijanya, “Model for practice badminton basic skills
    by using motion posture detection from video posture embedding and one-shot learning
    technique,” in *Proceedings of the 2019 2nd artificial intelligence and cloud
    computing conference*, 2019, pp. 117–124.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] N. Promrit和S.Waijanya，“基于视频姿态嵌入和单次学习技术的羽毛球基本技能训练模型”，收录于《2019年第二届人工智能与云计算会议论文集》，2019年，第117-124页。'
- en: '[72] S. Suda, Y. Makino, and H. Shinoda, “Prediction of volleyball trajectory
    using skeletal motions of setter player,” in *Proceedings of the 10th Augmented
    Human International Conference 2019*, 2019, pp. 1–8.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] S. Suda，Y.Makino和H.Shinoda，“利用接球人员骨骼动作预测排球轨迹”，收录于《第十届增强人类国际会议2019论文集》，2019年，第1-8页。'
- en: '[73] T. Shimizu, R. Hachiuma, H. Saito, T. Yoshikawa, and C. Lee, “Prediction
    of future shot direction using pose and position of tennis player,” in *Proceedings
    Proceedings of the 2nd International Workshop on Multimedia Content Analysis in
    Sports*, 2019, pp. 59–66.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] T. Shimizu，R.Hachiuma，H.Saito，T.Yoshikawa和C.Lee，“利用网球运动员的姿势和位置预测未来的投篮方向”，收录于《第二届国际多媒体内容分析工作坊论文集》，2019年，第59-66页。'
- en: '[74] E. Wu and H. Koike, “Futurepong: Real-time table tennis trajectory forecasting
    using pose prediction network,” in *Extended Abstracts of the 2020 CHI Conference
    on Human Factors in Computing Systems*, 2020, pp. 1–8.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] E. Wu 和 H. Koike，“Futurepong：使用姿态预测网络的实时乒乓球轨迹预测”，发表于*2020年CHI计算机系统人因会议扩展摘要*，2020年，第1–8页。'
- en: '[75] H. Sak, A. W. Senior, and F. Beaufays, “Long short-term memory recurrent
    neural network architectures for large scale acoustic modeling,” 2014.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] H. Sak, A. W. Senior, 和 F. Beaufays，“大规模声学建模的长短期记忆递归神经网络架构”，2014年。'
- en: '[76] M. Einfalt, C. Dampeyrou, D. Zecha, and R. Lienhart, “Frame-level event
    detection in athletics videos with pose-based convolutional sequence networks,”
    in *Proceedings Proceedings of the 2nd International Workshop on Multimedia Content
    Analysis in Sports*, 2019, pp. 42–50.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] M. Einfalt, C. Dampeyrou, D. Zecha, 和 R. Lienhart，“基于姿态的卷积序列网络在田径视频中的帧级事件检测”，发表于*第二届国际运动内容分析研讨会论文集*，2019年，第42–50页。'
- en: '[77] H. Thilakarathne, A. Nibali, Z. He, and S. Morgan, “Pose is all you need:
    The pose only group activity recognition system (pogars),” *Machine Vision and
    Applications*, vol. 33, no. 6, p. 95, 2022.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] H. Thilakarathne, A. Nibali, Z. He, 和 S. Morgan，“姿态就是你所需要的：仅基于姿态的群体活动识别系统（pogars）”，*机器视觉与应用*，第33卷，第6期，第95页，2022年。'
- en: '[78] A. Tharatipyakul, K. T. Choo, and S. T. Perrault, “Pose estimation for
    facilitating movement learning from online videos,” in *Proceedings of the International
    Conference on Advanced Visual Interfaces*, 2020, pp. 1–5.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] A. Tharatipyakul, K. T. Choo, 和 S. T. Perrault，“通过在线视频促进运动学习的姿态估计”，发表于*国际先进视觉接口会议论文集*，2020年，第1–5页。'
- en: '[79] E. W. Trejo and P. Yuan, “Recognition of yoga poses through an interactive
    system with kinect based on confidence value,” in *2018 3rd international conference
    on advanced robotics and mechatronics (ICARM)*.   IEEE, 2018, pp. 606–611.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] E. W. Trejo 和 P. Yuan，“通过基于置信度的Kinect交互系统识别瑜伽姿势”，发表于*2018年第3届国际先进机器人与机电一体化会议（ICARM）*。IEEE，2018年，第606–611页。'
- en: '[80] D. Farin, S. Krabbe, W. Effelsberg *et al.*, “Robust camera calibration
    for sport videos using court models,” in *Storage and Retrieval Methods and Applications
    for Multimedia 2004*, vol. 5307.   SPIE, 2003, pp. 80–91.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] D. Farin, S. Krabbe, W. Effelsberg *等*，“使用场地模型的运动视频稳健相机标定”，发表于*多媒体存储与检索方法与应用*，第5307卷。SPIE，2003年，第80–91页。'
- en: '[81] Q. Yao, A. Kubota, K. Kawakita, K. Nonaka, H. Sankoh, and S. Naito, “Fast
    camera self-calibration for synthesizing free viewpoint soccer video,” in *2017
    IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*.   IEEE,
    2017, pp. 1612–1616.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] Q. Yao, A. Kubota, K. Kawakita, K. Nonaka, H. Sankoh, 和 S. Naito，“用于合成自由视角足球视频的快速相机自标定”，发表于*2017年IEEE国际声学、语音与信号处理会议（ICASSP）*。IEEE，2017年，第1612–1616页。'
- en: '[82] N. Homayounfar, S. Fidler, and R. Urtasun, “Sports field localization
    via deep structured models,” in *Proceedings of the IEEE Conference on CVPR*,
    2017, pp. 5212–5220.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] N. Homayounfar, S. Fidler, 和 R. Urtasun，“通过深度结构模型进行运动场定位”，发表于*IEEE CVPR会议论文集*，2017年，第5212–5220页。'
- en: '[83] J. Chen and J. J. Little, “Sports camera calibration via synthetic data,”
    in *Proceedings of the IEEE/CVF conference on CVPR workshops*, 2019, pp. 0–0.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] J. Chen 和 J. J. Little，“通过合成数据进行运动相机标定”，发表于*IEEE/CVF CVPR会议论文集*，2019年，第0–0页。'
- en: '[84] L. Sha, J. Hobbs, P. Felsen, X. Wei, P. Lucey, and S. Ganguly, “End-to-end
    camera calibration for broadcast videos,” in *Proceedings of the IEEE/CVF conference
    on CVPR*, 2020, pp. 13 627–13 636.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] L. Sha, J. Hobbs, P. Felsen, X. Wei, P. Lucey, 和 S. Ganguly，“面向广播视频的端到端相机标定”，发表于*IEEE/CVF
    CVPR会议论文集*，2020年，第13,627–13,636页。'
- en: '[85] X. Nie, S. Chen, and R. Hamid, “A robust and efficient framework for sports-field
    registration,” in *Winter Conference on Applications of Computer Vision, WACV*.   IEEE,
    2021, pp. 1935–1943\. [Online]. Available: [https://doi.org/10.1109/WACV48630.2021.00198](https://doi.org/10.1109/WACV48630.2021.00198)'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] X. Nie, S. Chen, 和 R. Hamid，“用于运动场登记的稳健高效框架”，发表于*冬季计算机视觉应用会议（WACV）*。IEEE，2021年，第1935–1943页。[在线]。可用:
    [https://doi.org/10.1109/WACV48630.2021.00198](https://doi.org/10.1109/WACV48630.2021.00198)'
- en: '[86] F. Shi, P. Marchwica, J. C. G. Higuera, M. Jamieson, M. Javan, and P. Siva,
    “Self-supervised shape alignment for sports field registration,” in *Winter Conference
    on Applications of Computer Vision, WACV*.   IEEE, 2022, pp. 3768–3777\. [Online].
    Available: [https://doi.org/10.1109/WACV51458.2022.00382](https://doi.org/10.1109/WACV51458.2022.00382)'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] F. Shi, P. Marchwica, J. C. G. Higuera, M. Jamieson, M. Javan, 和 P. Siva，“用于运动场地注册的自监督形状对齐，”
    *冬季计算机视觉应用会议，WACV*。IEEE，2022年，第3768–3777页。[在线]。可用: [https://doi.org/10.1109/WACV51458.2022.00382](https://doi.org/10.1109/WACV51458.2022.00382)'
- en: '[87] Y.-J. Chu, J.-W. Su, K.-W. Hsiao, C.-Y. Lien, S.-H. Fan, M.-C. Hu, R.-R.
    Lee, C.-Y. Yao, and H.-K. Chu, “Sports field registration via keypoints-aware
    label condition,” in *Conference on Computer Vision and Pattern Recognition Workshops,
    CVPRW*.   IEEE/CVF, 2022, pp. 3523–3530\. [Online]. Available: [https://doi.org/10.1109/CVPRW56347.2022.00396](https://doi.org/10.1109/CVPRW56347.2022.00396)'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] Y.-J. Chu, J.-W. Su, K.-W. Hsiao, C.-Y. Lien, S.-H. Fan, M.-C. Hu, R.-R.
    Lee, C.-Y. Yao, 和 H.-K. Chu，“通过关键点感知标签条件进行运动场地注册，” *计算机视觉与模式识别研讨会，CVPRW*。IEEE/CVF，2022年，第3523–3530页。[在线]。可用:
    [https://doi.org/10.1109/CVPRW56347.2022.00396](https://doi.org/10.1109/CVPRW56347.2022.00396)'
- en: '[88] N. Zhang and E. Izquierdo, “A high accuracy camera calibration method
    for sport videos,” in *International Conference on Visual Communications and Image
    Processing, VCIP*.   IEEE, 2021, pp. 1–5\. [Online]. Available: [https://doi.org/10.1109/VCIP53242.2021.9675379](https://doi.org/10.1109/VCIP53242.2021.9675379)'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] N. Zhang 和 E. Izquierdo，“用于运动视频的高精度相机标定方法，” *国际视觉通信与图像处理会议，VCIP*。IEEE，2021年，第1–5页。[在线]。可用:
    [https://doi.org/10.1109/VCIP53242.2021.9675379](https://doi.org/10.1109/VCIP53242.2021.9675379)'
- en: '[89] J. Lin, C. Gan, and S. Han, “Tsm: Temporal shift module for efficient
    video understanding,” in *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*, 2019, pp. 7083–7093.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] J. Lin, C. Gan, 和 S. Han，“TSM：高效视频理解的时间移位模块，” *IEEE/CVF 国际计算机视觉会议论文集*，2019年，第7083–7093页。'
- en: '[90] D. Tran, H. Wang, L. Torresani, and M. Feiszli, “Video classification
    with channel-separated convolutional networks,” in *Proceedings of the IEEE/CVF
    International Conference on Computer Vision*, 2019, pp. 5552–5561.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] D. Tran, H. Wang, L. Torresani, 和 M. Feiszli，“使用通道分离卷积网络进行视频分类，” *IEEE/CVF
    国际计算机视觉会议论文集*，2019年，第5552–5561页。'
- en: '[91] C. Feichtenhofer, H. Fan, J. Malik, and K. He, “Slowfast networks for
    video recognition,” in *Proceedings of the IEEE/CVF international conference on
    computer vision*, 2019, pp. 6202–6211.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] C. Feichtenhofer, H. Fan, J. Malik, 和 K. He，“用于视频识别的 Slowfast 网络，” *IEEE/CVF
    国际计算机视觉会议论文集*，2019年，第6202–6211页。'
- en: '[92] W. Wang, D. Tran, and M. Feiszli, “What makes training multi-modal classification
    networks hard?” in *Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition*, 2020, pp. 12 695–12 705.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] W. Wang, D. Tran, 和 M. Feiszli，“是什么使得训练多模态分类网络变得困难？” *IEEE/CVF 计算机视觉与模式识别会议论文集*，2020年，第12 695–12 705页。'
- en: '[93] L. Shi, Y. Zhang, J. Cheng, and H. Lu, “Skeleton-based action recognition
    with multi-stream adaptive graph convolutional networks,” *IEEE Transactions on
    Image Processing*, vol. 29, pp. 9532–9545, 2020.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] L. Shi, Y. Zhang, J. Cheng, 和 H. Lu，“基于骨架的动作识别与多流自适应图卷积网络，” *IEEE 图像处理学报*，第29卷，第9532–9545页，2020年。'
- en: '[94] Y.-F. Song, Z. Zhang, C. Shan, and L. Wang, “Stronger, faster and more
    explainable: A graph convolutional baseline for skeleton-based action recognition,”
    in *proceedings of the 28th ACM international conference on multimedia*, 2020,
    pp. 1625–1633.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] Y.-F. Song, Z. Zhang, C. Shan, 和 L. Wang，“更强、更快且更具解释性的：一种用于骨架基础动作识别的图卷积基线，”
    *第28届 ACM 国际多媒体会议论文集*，2020年，第1625–1633页。'
- en: '[95] D. Kondratyuk, L. Yuan, Y. Li, L. Zhang, M. Tan, M. Brown, and B. Gong,
    “Movinets: Mobile video networks for efficient video recognition,” in *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2021,
    pp. 16 020–16 030.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] D. Kondratyuk, L. Yuan, Y. Li, L. Zhang, M. Tan, M. Brown, 和 B. Gong，“Movinets：高效视频识别的移动视频网络，”
    *IEEE/CVF 计算机视觉与模式识别会议论文集*，2021年，第16 020–16 030页。'
- en: '[96] G. Bertasius, H. Wang, and L. Torresani, “Is space-time attention all
    you need for video understanding,” *arXiv preprint arXiv:2102.05095*, vol. 2,
    no. 3, p. 4, 2021.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] G. Bertasius, H. Wang, 和 L. Torresani，“空间时间注意力是否足够进行视频理解，” *arXiv 预印本
    arXiv:2102.05095*，第2卷，第3期，第4页，2021年。'
- en: '[97] Z. Liu, J. Ning, Y. Cao, Y. Wei, Z. Zhang, S. Lin, and H. Hu, “Video swin
    transformer,” *arXiv preprint arXiv:2106.13230*, 2021.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] Z. Liu, J. Ning, Y. Cao, Y. Wei, Z. Zhang, S. Lin, 和 H. Hu，“视频 swin transformer，”
    *arXiv 预印本 arXiv:2106.13230*，2021年。'
- en: '[98] R. Herzig, E. Ben-Avraham, K. Mangalam, A. Bar, G. Chechik, A. Rohrbach,
    T. Darrell, and A. Globerson, “Object-region video transformers,” *arXiv preprint
    arXiv:2110.06915*, 2021.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] R. Herzig, E. Ben-Avraham, K. Mangalam, A. Bar, G. Chechik, A. Rohrbach,
    T. Darrell, 和 A. Globerson，“对象区域视频变换器”，*arXiv预印本 arXiv:2110.06915*，2021年。'
- en: '[99] R. Wang, D. Chen, Z. Wu, Y. Chen, X. Dai, M. Liu, Y.-G. Jiang, L. Zhou,
    and L. Yuan, “Bevt: Bert pretraining of video transformers,” *arXiv preprint arXiv:2112.01529*,
    2021.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] R. Wang, D. Chen, Z. Wu, Y. Chen, X. Dai, M. Liu, Y.-G. Jiang, L. Zhou,
    和 L. Yuan，“Bevt: 视频变换器的Bert预训练”，*arXiv预印本 arXiv:2112.01529*，2021年。'
- en: '[100] H. Tan, J. Lei, T. Wolf, and M. Bansal, “Vimpac: Video pre-training via
    masked token prediction and contrastive learning,” *arXiv preprint arXiv:2106.11250*,
    2021.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] H. Tan, J. Lei, T. Wolf, 和 M. Bansal，“Vimpac: 通过掩码令牌预测和对比学习进行视频预训练”，*arXiv预印本
    arXiv:2106.11250*，2021年。'
- en: '[101] Y. Chen, Z. Zhang, C. Yuan, B. Li, Y. Deng, and W. Hu, “Channel-wise
    topology refinement graph convolution for skeleton-based action recognition,”
    in *Proceedings of the IEEE/CVF International Conference on Computer Vision*,
    2021, pp. 13 359–13 368.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] Y. Chen, Z. Zhang, C. Yuan, B. Li, Y. Deng, 和 W. Hu，“用于基于骨架的动作识别的通道级拓扑优化图卷积”，发表于
    *IEEE/CVF国际计算机视觉会议论文集*，2021年，第13 359–13 368页。'
- en: '[102] H. Yuan, D. Ni, and M. Wang, “Spatio-temporal dynamic inference network
    for group activity recognition,” in *Proceedings of the IEEE/CVF International
    Conference on Computer Vision*, 2021, pp. 7476–7485.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] H. Yuan, D. Ni, 和 M. Wang，“用于群体活动识别的时空动态推理网络”，发表于 *IEEE/CVF国际计算机视觉会议论文集*，2021年，第7476–7485页。'
- en: '[103] H. Duan, Y. Zhao, K. Chen, D. Shao, D. Lin, and B. Dai, “Revisiting skeleton-based
    action recognition,” *arXiv preprint arXiv:2104.13586*, 2021.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] H. Duan, Y. Zhao, K. Chen, D. Shao, D. Lin, 和 B. Dai，“重新审视基于骨架的动作识别”，*arXiv预印本
    arXiv:2104.13586*，2021年。'
- en: '[104] X. Xiang, Y. Tian, A. Reiter, G. D. Hager, and T. D. Tran, “S3d: Stacking
    segmental p3d for action quality assessment,” in *ICIP*, 2018, pp. 928–932.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] X. Xiang, Y. Tian, A. Reiter, G. D. Hager, 和 T. D. Tran，“S3d: 堆叠分段 p3d
    用于动作质量评估”，发表于 *ICIP*，2018年，第928–932页。'
- en: '[105] P. Parmar and B. T. Morris, “Action quality assessment across multiple
    actions,” in *WACV*, 2018.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] P. Parmar 和 B. T. Morris，“跨多动作的动作质量评估”，发表于 *WACV*，2018年。'
- en: '[106] ——, “What and how well you performed? a multitask learning approach to
    action quality assessment,” in *CVPR*, 2019.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] ——，“你表现得如何？一种多任务学习方法用于动作质量评估”，发表于 *CVPR*，2019年。'
- en: '[107] C. Xu, Y. Fu, B. Zhang, Z. Chen, and X. Xue, “Learning to score figure
    skating sport videos,” *IEEE Transactions on Circuits and Systems for Video Technology
    (TCSVT)*, vol. PP, no. 99, pp. 1–1, 2019.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] C. Xu, Y. Fu, B. Zhang, Z. Chen, 和 X. Xue，“学习对花样滑冰运动视频进行评分”，*IEEE电路与系统视频技术汇刊
    (TCSVT)*，第PP卷，第99期，第1–1页，2019年。'
- en: '[108] Y. Tang, Z. Ni, J. Zhou, D. Zhang, and J. Zhou, “Uncertainty-aware score
    distribution learning for action quality assessment,” in *CVPR*, 2020.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] Y. Tang, Z. Ni, J. Zhou, D. Zhang, 和 J. Zhou，“面向动作质量评估的关注不确定性评分分布学习”，发表于
    *CVPR*，2020年。'
- en: '[109] S. Wang, Y. D., Z. P., C. C., and Z. L., “Tsa-net: Tube self-attention
    network for action quality assessment,” in *ACM MM*, 2021.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] S. Wang, Y. D., Z. P., C. C., 和 Z. L.，“Tsa-net: 管状自注意网络用于动作质量评估”，发表于
    *ACM MM*，2021年。'
- en: '[110] Z. Qi, R. Zhu, Z. Fu, W. Chai, and V. Kindratenko, “Weakly supervised
    two-stage training scheme for deep video fight detection model,” *arXiv preprint
    arXiv:2209.11477*, 2022.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] Z. Qi, R. Zhu, Z. Fu, W. Chai, 和 V. Kindratenko，“针对深度视频战斗检测模型的弱监督两阶段训练方案”，*arXiv预印本
    arXiv:2209.11477*，2022年。'
- en: '[111] J. Carreira and A. Zisserman, “Quo vadis, action recognition? a new model
    and the kinetics dataset,” in *proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition*, 2017, pp. 6299–6308.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] J. Carreira 和 A. Zisserman，“动作识别的未来？一种新模型及其动力学数据集”，发表于 *IEEE计算机视觉与模式识别会议论文集*，2017年，第6299–6308页。'
- en: '[112] M. Monfort, A. Andonian, B. Zhou, K. Ramakrishnan, S. A. Bargal, T. Yan,
    L. Brown, Q. Fan, D. Gutfreund, C. Vondrick *et al.*, “Moments in time dataset:
    one million videos for event understanding,” *IEEE transactions on pattern analysis
    and machine intelligence*, vol. 42, no. 2, pp. 502–508, 2019.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] M. Monfort, A. Andonian, B. Zhou, K. Ramakrishnan, S. A. Bargal, T. Yan,
    L. Brown, Q. Fan, D. Gutfreund, C. Vondrick *等*，“Moments in Time 数据集：用于事件理解的一百万个视频”，*IEEE模式分析与机器智能汇刊*，第42卷，第2期，第502–508页，2019年。'
- en: '[113] G. Wang, K. Lu, Y. Zhou, Z. He, and G. Wang, “Human-centered prior-guided
    and task-dependent multi-task representation learning for action recognition pre-training,”
    in *2022 IEEE International Conference on Multimedia and Expo (ICME)*.   IEEE,
    2022, pp. 1–6.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] G. Wang, K. Lu, Y. Zhou, Z. He, 和 G. Wang，“以人为中心的先验引导和任务依赖的多任务表示学习用于动作识别预训练”，发表于
    *2022 IEEE国际多媒体与博览会（ICME）*。IEEE，2022年，第1–6页。'
- en: '[114] D. Shao, Y. Zhao, B. Dai, and D. Lin, “Finegym: A hierarchical video
    dataset for fine-grained action understanding,” in *Proceedings of the IEEE/CVF
    conference on computer vision and pattern recognition*, 2020, pp. 2616–2625.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] D. Shao, Y. Zhao, B. Dai, 和 D. Lin, “Finegym：用于细粒度动作理解的层次视频数据集，”发表于*IEEE/CVF计算机视觉与模式识别会议论文集*，2020年，页码2616–2625。'
- en: '[115] S. Sun, F. Wang, Q. Liang, and L. He, “Taichi: A fine-grained action
    recognition dataset,” in *Proceedings of the 2017 ACM on International Conference
    on Multimedia Retrieval*, 2017, pp. 429–433.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] S. Sun, F. Wang, Q. Liang, 和 L. He, “Taichi：一个细粒度动作识别数据集，”发表于*2017 ACM国际多媒体检索会议论文集*，2017年，页码429–433。'
- en: '[116] J. Choi, C. Gao, J. C. Messou, and J.-B. Huang, “Why can’t i dance in
    the mall? learning to mitigate scene bias in action recognition,” *Advances in
    Neural Information Processing Systems*, vol. 32, 2019.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] J. Choi, C. Gao, J. C. Messou, 和 J.-B. Huang, “为什么我不能在商场里跳舞？学习减轻动作识别中的场景偏差，”*神经信息处理系统进展*，第32卷，2019年。'
- en: '[117] P. Weinzaepfel and G. Rogez, “Mimetics: Towards understanding human actions
    out of context,” *International Journal of Computer Vision*, vol. 129, no. 5,
    pp. 1675–1690, 2021.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] P. Weinzaepfel 和 G. Rogez, “Mimetics：致力于理解脱离背景的人类动作，”*国际计算机视觉期刊*，第129卷，第5期，页码1675–1690，2021年。'
- en: '[118] Z. Liu, H. Zhang, Z. Chen, Z. Wang, and W. Ouyang, “Disentangling and
    unifying graph convolutions for skeleton-based action recognition,” in *Proceedings
    of the IEEE/CVF conference on computer vision and pattern recognition*, 2020,
    pp. 143–152.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] Z. Liu, H. Zhang, Z. Chen, Z. Wang, 和 W. Ouyang, “解开和统一图卷积用于骨架动作识别，”发表于*IEEE/CVF计算机视觉与模式识别会议论文集*，2020年，页码143–152。'
- en: '[119] K. Zhu, A. Wong, and J. McPhee, “Fencenet: Fine-grained footwork recognition
    in fencing,” in *Proceedings of the IEEE/CVF Conference on Computer Vision and
    Pattern Recognition*, 2022, pp. 3589–3598.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] K. Zhu, A. Wong, 和 J. McPhee, “Fencenet：击剑中的细粒度脚法识别，”发表于*IEEE/CVF计算机视觉与模式识别会议论文集*，2022年，页码3589–3598。'
- en: '[120] J. Hong, M. Fisher, M. Gharbi, and K. Fatahalian, “Video pose distillation
    for few-shot, fine-grained sports action recognition,” in *Proceedings of the
    IEEE/CVF International Conference on Computer Vision*, 2021, pp. 9254–9263.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] J. Hong, M. Fisher, M. Gharbi, 和 K. Fatahalian, “视频姿态蒸馏用于少样本、细粒度的运动动作识别，”发表于*IEEE/CVF国际计算机视觉会议论文集*，2021年，页码9254–9263。'
- en: '[121] Y. Ben-Shabat, X. Yu, F. Saleh, D. Campbell, C. Rodriguez-Opazo, H. Li,
    and S. Gould, “The ikea asm dataset: Understanding people assembling furniture
    through actions, objects and pose,” in *Proceedings of the IEEE/CVF Winter Conference
    on Applications of Computer Vision*, 2021, pp. 847–859.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] Y. Ben-Shabat, X. Yu, F. Saleh, D. Campbell, C. Rodriguez-Opazo, H. Li,
    和 S. Gould, “IKEA ASM数据集：通过动作、物体和姿态理解人们组装家具的过程，”发表于*IEEE/CVF计算机视觉应用冬季会议论文集*，2021年，页码847–859。'
- en: '[122] D. Damen, H. Doughty, G. M. Farinella, S. Fidler, A. Furnari, E. Kazakos,
    D. Moltisanti, J. Munro, T. Perrett, W. Price *et al.*, “Scaling egocentric vision:
    The epic-kitchens dataset,” in *Proceedings of the European Conference on Computer
    Vision (ECCV)*, 2018, pp. 720–736.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] D. Damen, H. Doughty, G. M. Farinella, S. Fidler, A. Furnari, E. Kazakos,
    D. Moltisanti, J. Munro, T. Perrett, W. Price *等*，“扩展自我中心视觉：EPIC-KITCHENS数据集，”发表于*欧洲计算机视觉会议（ECCV）论文集*，2018年，页码720–736。'
- en: '[123] R. Goyal, S. Ebrahimi Kahou, V. Michalski, J. Materzynska, S. Westphal,
    H. Kim, V. Haenel, I. Fruend, P. Yianilos, M. Mueller-Freitag *et al.*, “The"
    something something" video database for learning and evaluating visual common
    sense,” in *Proceedings of the IEEE international conference on computer vision*,
    2017, pp. 5842–5850.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] R. Goyal, S. Ebrahimi Kahou, V. Michalski, J. Materzynska, S. Westphal,
    H. Kim, V. Haenel, I. Fruend, P. Yianilos, M. Mueller-Freitag *等*，“用于学习和评估视觉常识的‘某某’视频数据库，”发表于*IEEE国际计算机视觉会议论文集*，2017年，页码5842–5850。'
- en: '[124] K. Gavrilyuk, R. Sanford, M. Javan, and C. G. Snoek, “Actor-transformers
    for group activity recognition,” in *CVPR*, 2020, pp. 839–848.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] K. Gavrilyuk, R. Sanford, M. Javan, 和 C. G. Snoek, “用于群体活动识别的演员-变换器，”发表于*CVPR*，2020年，页码839–848。'
- en: '[125] G. Hu, B. Cui, Y. He, and S. Yu, “Progressive relation learning for group
    activity recognition,” in *CVPR*, 2020, pp. 980–989.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] G. Hu, B. Cui, Y. He, 和 S. Yu, “渐进关系学习用于群体活动识别，”发表于*CVPR*，2020年，页码980–989。'
- en: '[126] R. Yan, L. Xie, J. Tang, X. Shu, and Q. Tian, “Social adaptive module
    for weakly-supervised group activity recognition,” in *Computer Vision–ECCV 2020:
    16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part VIII
    16*.   Springer, 2020, pp. 208–224.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] R. Yan, L. Xie, J. Tang, X. Shu, 和 Q. Tian, “用于弱监督群体活动识别的社交自适应模块，”发表于*计算机视觉–ECCV
    2020：第16届欧洲会议，英国格拉斯哥，2020年8月23–28日，论文集，第VIII卷第16篇*，Springer，2020年，页码208–224。'
- en: '[127] M. Ehsanpour, A. Abedin, F. Saleh, J. Shi, I. Reid, and H. Rezatofighi,
    “Joint learning of social groups, individuals action and sub-group activities
    in videos,” in *ECCV*.   Springer, 2020, pp. 177–195.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] M. Ehsanpour, A. Abedin, F. Saleh, J. Shi, I. Reid, 和 H. Rezatofighi，“视频中社交群体、个体动作和子群体活动的联合学习”，载于*ECCV*。Springer，2020，第177–195页。'
- en: '[128] R. R. A. Pramono, Y. T. Chen, and W. H. Fang, “Empowering relational
    network by self-attention augmented conditional random fields for group activity
    recognition,” in *ECCV*.   Springer, 2020, pp. 71–90.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] R. R. A. Pramono, Y. T. Chen, 和 W. H. Fang，“通过自注意力增强的条件随机场提升关系网络用于群体活动识别”，载于*ECCV*。Springer，2020，第71–90页。'
- en: '[129] S. Li, Q. Cao, L. Liu, K. Yang, S. Liu, J. Hou, and S. Yi, “Groupformer:
    Group activity recognition with clustered spatial-temporal transformer,” *ICCV*,
    2021.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] S. Li, Q. Cao, L. Liu, K. Yang, S. Liu, J. Hou, 和 S. Yi，“Groupformer：使用聚类空间-时间变换器的群体活动识别”，*ICCV*，2021。'
- en: '[130] J. Wu, L. Wang, L. Wang, J. Guo, and G. Wu, “Learning actor relation
    graphs for group activity recognition,” in *CVPR*, 2019, pp. 9964–9974.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] J. Wu, L. Wang, L. Wang, J. Guo, 和 G. Wu，“学习演员关系图用于群体活动识别”，载于*CVPR*，2019，第9964–9974页。'
- en: '[131] M. Han, D. J. Zhang, Y. Wang, R. Yan, L. Yao, X. Chang, and Y. Qiao,
    “Dual-ai: dual-path actor interaction learning for group activity recognition,”
    in *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition*,
    2022, pp. 2990–2999.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] M. Han, D. J. Zhang, Y. Wang, R. Yan, L. Yao, X. Chang, 和 Y. Qiao，“Dual-ai：双路径演员交互学习用于群体活动识别”，载于*IEEE/CVF计算机视觉与模式识别会议论文集*，2022，第2990–2999页。'
- en: '[132] G. Xu and J. Yin, “Mlp-air: An efficient mlp-based method for actor interaction
    relation learning in group activity recognition,” *arXiv preprint arXiv:2304.08803*,
    2023.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] G. Xu 和 J. Yin，“Mlp-air：一种高效的基于MLP的方法用于群体活动识别中的演员交互关系学习”，*arXiv预印本arXiv:2304.08803*，2023。'
- en: '[133] V. Bettadapura, C. Pantofaru, and I. Essa, “Leveraging contextual cues
    for generating basketball highlights,” in *Proceedings of the 24th ACM international
    conference on Multimedia*, 2016, pp. 908–917.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] V. Bettadapura, C. Pantofaru, 和 I. Essa，“利用上下文线索生成篮球精彩片段”，载于*第24届ACM国际多媒体会议论文集*，2016，第908–917页。'
- en: '[134] F. C. Heilbron, W. Barrios, V. Escorcia, and B. Ghanem, “Scc: Semantic
    context cascade for efficient action detection,” in *2017 IEEE Conference on Computer
    Vision and Pattern Recognition (CVPR)*.   IEEE, 2017, pp. 3175–3184.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] F. C. Heilbron, W. Barrios, V. Escorcia, 和 B. Ghanem，“SCC：用于高效动作检测的语义上下文级联”，载于*2017年IEEE计算机视觉与模式识别会议（CVPR）*。IEEE，2017，第3175–3184页。'
- en: '[135] P. Felsen, P. Agrawal, and J. Malik, “What will happen next? forecasting
    player moves in sports videos,” in *Proceedings of the IEEE international conference
    on computer vision*, 2017, pp. 3342–3351.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] P. Felsen, P. Agrawal, 和 J. Malik，“接下来会发生什么？预测体育视频中的玩家动作”，载于*IEEE国际计算机视觉会议论文集*，2017，第3342–3351页。'
- en: '[136] A. Cioppa, A. Deliege, and M. Van Droogenbroeck, “A bottom-up approach
    based on semantics for the interpretation of the main camera stream in soccer
    games,” in *Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition Workshops*, 2018, pp. 1765–1774.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] A. Cioppa, A. Deliege, 和 M. Van Droogenbroeck，“基于语义的自下而上方法用于足球比赛主摄像头流的解释”，载于*IEEE计算机视觉与模式识别会议研讨会论文集*，2018，第1765–1774页。'
- en: '[137] T. Tsunoda, Y. Komori, M. Matsugu, and T. Harada, “Football action recognition
    using hierarchical lstm,” in *Proceedings of the IEEE conference on computer vision
    and pattern recognition workshops*, 2017, pp. 99–107.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] T. Tsunoda, Y. Komori, M. Matsugu, 和 T. Harada，“使用分层LSTM的足球动作识别”，载于*IEEE计算机视觉与模式识别会议研讨会论文集*，2017，第99–107页。'
- en: '[138] Z. Cai, H. Neher, K. Vats, D. A. Clausi, and J. Zelek, “Temporal hockey
    action recognition via pose and optical flows,” in *Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition Workshops*, 2019, pp. 0–0.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] Z. Cai, H. Neher, K. Vats, D. A. Clausi, 和 J. Zelek，“通过姿态和光流的时间性冰球动作识别”，载于*IEEE计算机视觉与模式识别会议研讨会论文集*，2019，第0–0页。'
- en: '[139] M. Sanabria, F. Precioso, and T. Menguy, “A deep architecture for multimodal
    summarization of soccer games,” in *Proceedings Proceedings of the 2nd International
    Workshop on Multimedia Content Analysis in Sports*, 2019, pp. 16–24.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] M. Sanabria, F. Precioso, 和 T. Menguy，“一种用于足球比赛多模态总结的深度架构”，载于*第2届国际体育多媒体内容分析研讨会论文集*，2019，第16–24页。'
- en: '[140] F. Turchini, L. Seidenari, L. Galteri, A. Ferracani, G. Becchi, and A. Del Bimbo,
    “Flexible automatic football filming and summarization,” in *Proceedings Proceedings
    of the 2nd International Workshop on Multimedia Content Analysis in Sports*, 2019,
    pp. 108–114.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] F. Turchini, L. Seidenari, L. Galteri, A. Ferracani, G. Becchi, 和 A.
    Del Bimbo, “灵活的自动足球拍摄和总结，” 发表在*第2届国际运动多媒体内容分析研讨会论文集*，2019，第108–114页。'
- en: '[141] S. Giancola, M. Amine, T. Dghaily, and B. Ghanem, “Soccernet: A scalable
    dataset for action spotting in soccer videos,” in *Proceedings of the IEEE conference
    on computer vision and pattern recognition workshops*, 2018, pp. 1711–1721.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] S. Giancola, M. Amine, T. Dghaily, 和 B. Ghanem, “Soccernet: 一个可扩展的数据集用于足球视频中的动作检测，”
    发表在*IEEE计算机视觉与模式识别研讨会论文集*，2018，第1711–1721页。'
- en: '[142] A. Cioppa, A. Deliege, S. Giancola, B. Ghanem, M. V. Droogenbroeck, R. Gade,
    and T. B. Moeslund, “A context-aware loss function for action spotting in soccer
    videos,” in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition*, 2020, pp. 13 126–13 136.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] A. Cioppa, A. Deliege, S. Giancola, B. Ghanem, M. V. Droogenbroeck, R.
    Gade, 和 T. B. Moeslund, “一种用于足球视频动作检测的上下文感知损失函数，” 发表在*IEEE/CVF计算机视觉与模式识别大会论文集*，2020，第13 126–13 136页。'
- en: '[143] J. Hong, H. Zhang, M. Gharbi, M. Fisher, and K. Fatahalian, “Spotting
    temporally precise, fine-grained events in video,” in *Computer Vision–ECCV 2022:
    17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings,
    Part XXXV*.   Springer, 2022, pp. 33–51.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] J. Hong, H. Zhang, M. Gharbi, M. Fisher, 和 K. Fatahalian, “在视频中检测时间精确的细粒度事件，”
    发表在*计算机视觉–ECCV 2022: 第17届欧洲会议，特拉维夫，以色列，2022年10月23-27日，论文集，第三十五部分*。Springer, 2022，第33–51页。'
- en: '[144] A. Darwish and T. El-Shabrway, “Ste: Spatio-temporal encoder for action
    spotting in soccer videos,” in *Proceedings of the 5th International ACM Workshop
    on Multimedia Content Analysis in Sports*, 2022, pp. 87–92.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] A. Darwish 和 T. El-Shabrway, “Ste: 用于足球视频动作检测的时空编码器，” 发表在*第5届国际ACM运动多媒体内容分析研讨会论文集*，2022，第87–92页。'
- en: '[145] A. Cartas, C. Ballester, and G. Haro, “A graph-based method for soccer
    action spotting using unsupervised player classification,” in *Proceedings of
    the 5th International ACM Workshop on Multimedia Content Analysis in Sports*,
    2022, pp. 93–102.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] A. Cartas, C. Ballester, 和 G. Haro, “一种基于图的方法用于足球动作检测，采用无监督球员分类，” 发表在*第5届国际ACM运动多媒体内容分析研讨会论文集*，2022，第93–102页。'
- en: '[146] H. Zhu, J. Liang, C. Lin, J. Zhang, and J. Hu, “A transformer-based system
    for action spotting in soccer videos,” in *Proceedings of the 5th International
    ACM Workshop on Multimedia Content Analysis in Sports*, 2022, pp. 103–109.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] H. Zhu, J. Liang, C. Lin, J. Zhang, 和 J. Hu, “基于Transformer的足球视频动作检测系统，”
    发表在*第5届国际ACM运动多媒体内容分析研讨会论文集*，2022，第103–109页。'
- en: '[147] J. V. Soares and A. Shah, “Action spotting using dense detection anchors
    revisited: Submission to the soccernet challenge 2022,” *arXiv preprint arXiv:2206.07846*,
    2022.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] J. V. Soares 和 A. Shah, “重新审视使用密集检测锚点进行动作检测：提交至Soccernet挑战赛2022，” *arXiv预印本arXiv:2206.07846*，2022。'
- en: '[148] J. V. Soares, A. Shah, and T. Biswas, “Temporally precise action spotting
    in soccer videos using dense detection anchors,” in *2022 IEEE International Conference
    on Image Processing (ICIP)*.   IEEE, 2022, pp. 2796–2800.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] J. V. Soares, A. Shah, 和 T. Biswas, “在足球视频中使用密集检测锚点进行时间精确的动作检测，” 发表在*2022
    IEEE国际图像处理会议（ICIP）*。IEEE, 2022, 第2796–2800页。'
- en: '[149] J. H. Pan, J. Gao, and W. S. Zheng, “Action assessment by joint relation
    graphs,” in *ICCV*, 2019.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] J. H. Pan, J. Gao, 和 W. S. Zheng, “通过联合关系图进行动作评估，” 发表在*ICCV*，2019。'
- en: '[150] G. I. Parisi, S. Magg, and S. Wermter, “Human motion assessment in real
    time using recurrent self-organization,” in *IEEE International Symposium on Robot
    and Human Interactive Communication (RO-MAN)*, 2016.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] G. I. Parisi, S. Magg, 和 S. Wermter, “使用递归自组织进行实时人体运动评估，” 发表在*IEEE国际机器人与人机交互会议（RO-MAN）*，2016。'
- en: '[151] S. T. Kim and M. R. Yong, “Evaluationnet: Can human skill be evaluated
    by deep networks?” *arXiv:1705.11077*, 2017.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] S. T. Kim 和 M. R. Yong, “Evaluationnet: 人类技能能否通过深度网络评估？” *arXiv:1705.11077*，2017。'
- en: '[152] X. Yu, Y. Rao, W. Zhao, J. Lu, and J. Zhou, “Group-aware contrastive
    regression for action quality assessment,” in *Proceedings of the IEEE/CVF International
    Conference on Computer Vision*, 2021, pp. 7919–7928.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] X. Yu, Y. Rao, W. Zhao, J. Lu, 和 J. Zhou, “面向群体的对比回归用于动作质量评估，” 发表在*IEEE/CVF国际计算机视觉大会论文集*，2021，第7919–7928页。'
- en: '[153] Y. Li, X. Chai, and X. Chen, “End-to-end learning for action quality
    assessment,” in *Advances in Multimedia Information Processing – PCM*, 2018.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] Y. Li, X. Chai, 和 X. Chen, “端到端学习用于动作质量评估，” 发表在*多媒体信息处理进展 – PCM*，2018。'
- en: '[154] G. Bertasius, H. S. Park, S. X. Yu, and J. Shi, “Am i a baller? basketball
    performance assessment from first-person videos,” in *ICCV*, 2019.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] G. Bertasius, H. S. Park, S. X. Yu, 和 J. Shi，“我算不算球员？从第一人称视频评估篮球表现，”
    在 *ICCV*，2019年。'
- en: '[155] R. Agyeman, R. Muhammad, and G. S. Choi, “Soccer video summarization
    using deep learning,” in *2019 IEEE Conference on Multimedia Information Processing
    and Retrieval (MIPR)*, 2019, pp. 270–273.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] R. Agyeman, R. Muhammad, 和 G. S. Choi，“利用深度学习进行足球视频总结，” 在 *2019 IEEE
    多媒体信息处理与检索会议 (MIPR)*，2019年，第270–273页。'
- en: '[156] M. Rafiq, G. Rafiq, R. Agyeman, G. S. Choi, and S.-I. Jin, “Scene classification
    for sports video summarization using transfer learning,” *Sensors*, vol. 20, no. 6,
    p. 1702, Mar 2020\. [Online]. Available: [http://dx.doi.org/10.3390/s20061702](http://dx.doi.org/10.3390/s20061702)'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] M. Rafiq, G. Rafiq, R. Agyeman, G. S. Choi, 和 S.-I. Jin，“利用迁移学习进行体育视频场景分类，”
    *传感器*，第20卷，第6期，第1702页，2020年3月。[在线]. 可用：[http://dx.doi.org/10.3390/s20061702](http://dx.doi.org/10.3390/s20061702)'
- en: '[157] A. A. Khan, J. Shao, W. Ali, and S. Tumrani, “Content-aware summarization
    of broadcast sports videos: An audio–visual feature extraction approach,” *Neural
    Processing Letters*, pp. 1–24, 2020.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] A. A. Khan, J. Shao, W. Ali, 和 S. Tumrani，“面向内容的广播体育视频总结：一种音频-视觉特征提取方法，”
    *神经处理信函*，第1–24页，2020年。'
- en: '[158] H. Shingrakhia and H. Patel, “Sgrnn-am and hrf-dbn: A hybrid machine
    learning model for cricket video summarization,” *Vis. Comput.*, vol. 38, no. 7,
    p. 2285–2301, jul 2022\. [Online]. Available: [https://doi.org/10.1007/s00371-021-02111-8](https://doi.org/10.1007/s00371-021-02111-8)'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] H. Shingrakhia 和 H. Patel，“Sgrnn-am 和 hrf-dbn：一种用于板球视频总结的混合机器学习模型，” *视觉计算*，第38卷，第7期，第2285–2301页，2022年7月。[在线].
    可用：[https://doi.org/10.1007/s00371-021-02111-8](https://doi.org/10.1007/s00371-021-02111-8)'
- en: '[159] W. Li, G. Pan, C. Wang, Z. Xing, and Z. Han, “From coarse to fine: Hierarchical
    structure-aware video summarization,” *ACM Trans. Multimedia Comput. Commun. Appl.*,
    vol. 18, no. 1s, jan 2022\. [Online]. Available: [https://doi.org/10.1145/3485472](https://doi.org/10.1145/3485472)'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[159] W. Li, G. Pan, C. Wang, Z. Xing, 和 Z. Han，“从粗到细：层次结构感知的视频总结，” *ACM 多媒体计算、通信与应用汇刊*，第18卷，第1s期，2022年1月。[在线].
    可用：[https://doi.org/10.1145/3485472](https://doi.org/10.1145/3485472)'
- en: '[160] W. Chai and G. Wang, “Deep vision multimodal learning: Methodology, benchmark,
    and trend,” *Applied Sciences*, vol. 12, no. 13, p. 6588, 2022.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[160] W. Chai 和 G. Wang，“深度视觉多模态学习：方法论、基准和趋势，” *应用科学*，第12卷，第13期，第6588页，2022年。'
- en: '[161] H. Yu, S. Cheng, B. Ni, M. Wang, J. Zhang, and X. Yang, “Fine-grained
    video captioning for sports narrative,” in *Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition*, 2018, pp. 6006–6015.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[161] H. Yu, S. Cheng, B. Ni, M. Wang, J. Zhang, 和 X. Yang，“体育叙事的细粒度视频字幕生成，”
    在 *IEEE 计算机视觉与模式识别会议论文集*，2018年，第6006–6015页。'
- en: '[162] M. Qi, Y. Wang, A. Li, and J. Luo, “Sports video captioning via attentive
    motion representation and group relationship modeling,” *IEEE Transactions on
    Circuits and Systems for Video Technology*, vol. 30, no. 8, pp. 2617–2633, 2019.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[162] M. Qi, Y. Wang, A. Li, 和 J. Luo，“通过注意力运动表示和群体关系建模进行体育视频字幕生成，” *IEEE 视频技术电路与系统汇刊*，第30卷，第8期，第2617–2633页，2019年。'
- en: '[163] ——, “Sports video captioning via attentive motion representation and
    group relationship modeling,” *IEEE Transactions on Circuits and Systems for Video
    Technology*, vol. 30, no. 8, pp. 2617–2633, 2020.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[163] ——，“通过注意力运动表示和群体关系建模进行体育视频字幕生成，” *IEEE 视频技术电路与系统汇刊*，第30卷，第8期，第2617–2633页，2020年。'
- en: '[164] H. Yu, S. Cheng, B. Ni, M. Wang, J. Zhang, and X. Yang, “Fine-grained
    video captioning for sports narrative,” in *2018 IEEE/CVF Conference on Computer
    Vision and Pattern Recognition*, 2018, pp. 6006–6015.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[164] H. Yu, S. Cheng, B. Ni, M. Wang, J. Zhang, 和 X. Yang，“体育叙事的细粒度视频字幕生成，”
    在 *2018 IEEE/CVF 计算机视觉与模式识别会议*，2018年，第6006–6015页。'
- en: '[165] J. Wang, I. Fox, J. Skaza, N. Linck, S. Singh, and J. Wiens, “The advantage
    of doubling: a deep reinforcement learning approach to studying the double team
    in the nba,” *arXiv preprint arXiv:1803.02940*, 2018.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[165] J. Wang, I. Fox, J. Skaza, N. Linck, S. Singh, 和 J. Wiens，“双倍的优势：一种深度强化学习方法来研究NBA中的双人防守，”
    *arXiv 预印本 arXiv:1803.02940*，2018年。'
- en: '[166] Y. Luo, “Inverse reinforcement learning for team sports: Valuing actions
    and players,” 2020.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[166] Y. Luo，“团队运动中的逆向强化学习：评估动作和球员，” 2020年。'
- en: '[167] G. Liu and O. Schulte, “Deep reinforcement learning in ice hockey for
    context-aware player evaluation,” *arXiv preprint arXiv:1805.11088*, 2018.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[167] G. Liu 和 O. Schulte，“冰球中的深度强化学习用于情境感知的球员评估，” *arXiv 预印本 arXiv:1805.11088*，2018年。'
- en: '[168] C. Yanai, A. Solomon, G. Katz, B. Shapira, and L. Rokach, “Q-ball: Modeling
    basketball games using deep reinforcement learning,” in *Proceedings of the AAAI
    Conference on Artificial Intelligence*, vol. 36, no. 8, 2022, pp. 8806–8813.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[168] C. Yanai, A. Solomon, G. Katz, B. Shapira, 和 L. Rokach, “Q-ball: 利用深度强化学习建模篮球比赛，”
    *人工智能学会会议录*，第36卷，第8期，2022年，页码8806–8813。'
- en: '[169] T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa,
    D. Silver, and D. Wierstra, “Continuous control with deep reinforcement learning,”
    *arXiv preprint arXiv:1509.02971*, 2015.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[169] T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa,
    D. Silver, 和 D. Wierstra, “通过深度强化学习进行连续控制，” *arXiv 预印本 arXiv:1509.02971*，2015年。'
- en: '[170] “statsperform-optical-tracking,” [https://www.statsperform.com/team-performance/football/optical-tracking](https://www.statsperform.com/team-performance/football/optical-tracking).'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[170] “statsperform-optical-tracking，” [https://www.statsperform.com/team-performance/football/optical-tracking](https://www.statsperform.com/team-performance/football/optical-tracking)。'
- en: '[171] “secondspectrum,” [https://www.secondspectrum.com](https://www.secondspectrum.com).'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[171] “secondspectrum，” [https://www.secondspectrum.com](https://www.secondspectrum.com)。'
- en: '[172] X. Wei, P. Lucey, S. Morgan, and S. Sridharan, “Forecasting the next
    shot location in tennis using fine-grained spatiotemporal tracking data,” *IEEE
    Transactions on Knowledge and Data Engineering*, vol. 28, no. 11, pp. 2988–2997,
    2016.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[172] X. Wei, P. Lucey, S. Morgan, 和 S. Sridharan, “利用细粒度时空跟踪数据预测网球下一个击球位置，”
    *IEEE 知识与数据工程汇刊*，第28卷，第11期，页码2988–2997，2016年。'
- en: '[173] T. Fernando, S. Denman, S. Sridharan, and C. Fookes, “Memory augmented
    deep generative models for forecasting the next shot location in tennis,” *IEEE
    Transactions on Knowledge and Data Engineering*, vol. 32, no. 9, pp. 1785–1797,
    2019.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[173] T. Fernando, S. Denman, S. Sridharan, 和 C. Fookes, “用于预测网球下一个击球位置的记忆增强深度生成模型，”
    *IEEE 知识与数据工程汇刊*，第32卷，第9期，页码1785–1797，2019年。'
- en: '[174] X. Wei, P. Lucey, S. Morgan, M. Reid, and S. Sridharan, “The thin edge
    of the wedge: Accurately predicting shot outcomes in tennis using style and context
    priors,” in *Proceedings of the 10th Annu MIT Sloan Sport Anal Conf, Boston, MA,
    USA*, 2016, pp. 1–11.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[174] X. Wei, P. Lucey, S. Morgan, M. Reid, 和 S. Sridharan, “薄薄的切入点：利用风格和背景先验准确预测网球击球结果，”
    *第10届麻省理工学院斯隆体育分析年会录*，波士顿，马萨诸塞州，美国，2016年，页码1–11。'
- en: '[175] H. M. Le, P. Carr, Y. Yue, and P. Lucey, “Data-driven ghosting using
    deep imitation learning,” 2017.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[175] H. M. Le, P. Carr, Y. Yue, 和 P. Lucey, “利用深度模仿学习进行数据驱动的虚拟演练，” 2017年。'
- en: '[176] P. Power, H. Ruiz, X. Wei, and P. Lucey, “Not all passes are created
    equal: Objectively measuring the risk and reward of passes in soccer from tracking
    data,” in *Proceedings of the 23rd ACM SIGKDD international conference on knowledge
    discovery and data mining*, 2017, pp. 1605–1613.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[176] P. Power, H. Ruiz, X. Wei, 和 P. Lucey, “并非所有传球都是相同的：从跟踪数据中客观衡量足球传球的风险和回报，”
    *第23届ACM SIGKDD国际知识发现与数据挖掘会议录*，2017年，页码1605–1613。'
- en: '[177] W.-Y. Wang, H.-H. Shuai, K.-S. Chang, and W.-C. Peng, “Shuttlenet: Position-aware
    fusion of rally progress and player styles for stroke forecasting in badminton,”
    in *Proceedings of the AAAI Conference on Artificial Intelligence*, 2022.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[177] W.-Y. Wang, H.-H. Shuai, K.-S. Chang, 和 W.-C. Peng, “Shuttlenet: 基于位置的羽毛球比赛进展和球员风格融合以预测击球，”
    *人工智能学会会议录*，2022年。'
- en: '[178] F. B. Martins, M. G. Machado, H. F. Bassani, P. H. M. Braga, and E. S.
    Barros, “rsoccer: A framework for studying reinforcement learning in small and
    very small size robot soccer,” 2021.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[178] F. B. Martins, M. G. Machado, H. F. Bassani, P. H. M. Braga, 和 E. S.
    Barros, “rsoccer: 一个用于研究小型和非常小型机器人足球中的强化学习的框架，” 2021年。'
- en: '[179] S. Liu, G. Lever, J. Merel, S. Tunyasuvunakool, N. Heess, and T. Graepel,
    “Emergent coordination through competition,” *arXiv preprint arXiv:1902.07151*,
    2019.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[179] S. Liu, G. Lever, J. Merel, S. Tunyasuvunakool, N. Heess, 和 T. Graepel,
    “通过竞争实现自发协调，” *arXiv 预印本 arXiv:1902.07151*，2019年。'
- en: '[180] S. Liu, G. Lever, Z. Wang, J. Merel, S. Eslami, D. Hennes, W. M. Czarnecki,
    Y. Tassa, S. Omidshafiei, A. Abdolmaleki *et al.*, “From motor control to team
    play in simulated humanoid football,” *arXiv preprint arXiv:2105.12196*, 2021.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[180] S. Liu, G. Lever, Z. Wang, J. Merel, S. Eslami, D. Hennes, W. M. Czarnecki,
    Y. Tassa, S. Omidshafiei, A. Abdolmaleki *等*，“从运动控制到模拟人形足球中的团队配合，” *arXiv 预印本
    arXiv:2105.12196*，2021年。'
- en: '[181] K. Kurach, A. Raichuk, P. Stańczyk, M. Zając, O. Bachem, L. Espeholt,
    C. Riquelme, D. Vincent, M. Michalski, O. Bousquet *et al.*, “Google research
    football: A novel reinforcement learning environment,” in *Proceedings of the
    AAAI Conference on Artificial Intelligence*, vol. 34, no. 04, 2020, pp. 4501–4510.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[181] K. Kurach, A. Raichuk, P. Stańczyk, M. Zając, O. Bachem, L. Espeholt,
    C. Riquelme, D. Vincent, M. Michalski, O. Bousquet *等*，“Google research football：一种新型的强化学习环境，”
    收录于 *AAAI 人工智能会议论文集*，第34卷，第04期，2020年，第4501–4510页。'
- en: '[182] Y. Zhao, I. Borovikov, J. Rupert, C. Somers, and A. Beirami, “On multi-agent
    learning in team sports games,” *arXiv preprint arXiv:1906.10124*, 2019.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[182] Y. Zhao, I. Borovikov, J. Rupert, C. Somers, 和 A. Beirami，“关于团队体育游戏中的多智能体学习，”
    *arXiv 预印本 arXiv:1906.10124*，2019。'
- en: '[183] H. Jia, Y. Hu, Y. Chen, C. Ren, T. Lv, C. Fan, and C. Zhang, “Fever basketball:
    A complex, flexible, and asynchronized sports game environment for multi-agent
    reinforcement learning,” *arXiv preprint arXiv:2012.03204*, 2020.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[183] H. Jia, Y. Hu, Y. Chen, C. Ren, T. Lv, C. Fan, 和 C. Zhang，“Fever篮球：一个复杂、灵活且不同步的多智能体强化学习体育游戏环境，”
    *arXiv 预印本 arXiv:2012.03204*，2020。'
- en: '[184] F. Z. Ziyang Li, Kaiwen Zhu, “Wekick,” [https://www.kaggle.com/c/google-football/discussion/202232](https://www.kaggle.com/c/google-football/discussion/202232),
    2020.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[184] F. Z. Ziyang Li, Kaiwen Zhu，“Wekick，” [https://www.kaggle.com/c/google-football/discussion/202232](https://www.kaggle.com/c/google-football/discussion/202232)，2020。'
- en: '[185] S. Huang, W. Chen, L. Zhang, Z. Li, F. Zhu, D. Ye, T. Chen, and J. Zhu,
    “Tikick: Towards playing multi-agent football full games from single-agent demonstrations,”
    *arXiv preprint arXiv:2110.04507*, 2021.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[185] S. Huang, W. Chen, L. Zhang, Z. Li, F. Zhu, D. Ye, T. Chen, 和 J. Zhu，“Tikick：从单智能体演示中进行多智能体足球完整游戏的探索，”
    *arXiv 预印本 arXiv:2110.04507*，2021。'
- en: '[186] F. Lin, S. Huang, T. Pearce, W. Chen, and W.-W. Tu, “Tizero: Mastering
    multi-agent football with curriculum learning and self-play,” *arXiv preprint
    arXiv:2302.07515*, 2023.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[186] F. Lin, S. Huang, T. Pearce, W. Chen, 和 W.-W. Tu，“Tizero：通过课程学习和自我博弈掌握多智能体足球，”
    *arXiv 预印本 arXiv:2302.07515*，2023。'
- en: '[187] C. Yu, A. Velu, E. Vinitsky, Y. Wang, A. Bayen, and Y. Wu, “The surprising
    effectiveness of mappo in cooperative, multi-agent games,” *arXiv preprint arXiv:2103.01955*,
    2021.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[187] C. Yu, A. Velu, E. Vinitsky, Y. Wang, A. Bayen, 和 Y. Wu，“mappo 在合作型多智能体游戏中的惊人有效性，”
    *arXiv 预印本 arXiv:2103.01955*，2021。'
- en: '[188] M. Wen, J. G. Kuba, R. Lin, W. Zhang, Y. Wen, J. Wang, and Y. Yang, “Multi-agent
    reinforcement learning is a sequence modeling problem,” *arXiv preprint arXiv:2205.14953*,
    2022.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[188] M. Wen, J. G. Kuba, R. Lin, W. Zhang, Y. Wen, J. Wang, 和 Y. Yang，“多智能体强化学习是一种序列建模问题，”
    *arXiv 预印本 arXiv:2205.14953*，2022。'
- en: '[189] A. Ecoffet, J. Huizinga, J. Lehman, K. O. Stanley, and J. Clune, “First
    return, then explore,” *Nature*, vol. 590, no. 7847, pp. 580–586, 2021.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[189] A. Ecoffet, J. Huizinga, J. Lehman, K. O. Stanley, 和 J. Clune，“先返回，再探索，”
    *Nature*，第590卷，第7847期，第580–586页，2021。'
- en: '[190] P. Tendulkar, A. Das, A. Kembhavi, and D. Parikh, “Feel the music: Automatically
    generating a dance for an input song,” *arXiv preprint arXiv:2006.11905*, 2020.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[190] P. Tendulkar, A. Das, A. Kembhavi, 和 D. Parikh，“感受音乐：为输入歌曲自动生成舞蹈，” *arXiv
    预印本 arXiv:2006.11905*，2020。'
- en: '[191] X. Ren, H. Li, Z. Huang, and Q. Chen, “Self-supervised dance video synthesis
    conditioned on music,” in *Proceedings of the 28th ACM International Conference
    on Multimedia*, 2020, pp. 46–54.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[191] X. Ren, H. Li, Z. Huang, 和 Q. Chen，“基于音乐的自监督舞蹈视频合成，” 收录于 *第28届ACM国际多媒体会议论文集*，2020年，第46–54页。'
- en: '[192] J. P. Ferreira, T. M. Coutinho, T. L. Gomes, J. F. Neto, R. Azevedo,
    R. Martins, and E. R. Nascimento, “Learning to dance: A graph convolutional adversarial
    network to generate realistic dance motions from audio,” *Computers & Graphics*,
    vol. 94, pp. 11–21, 2021.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[192] J. P. Ferreira, T. M. Coutinho, T. L. Gomes, J. F. Neto, R. Azevedo,
    R. Martins, 和 E. R. Nascimento，“学习跳舞：一种图卷积对抗网络从音频生成逼真的舞蹈动作，” *Computers & Graphics*，第94卷，第11–21页，2021。'
- en: '[193] Z. Cao, T. Simon, S.-E. Wei, and Y. Sheikh, “Realtime multi-person 2d
    pose estimation using part affinity fields,” in *Proceedings of the IEEE conference
    on computer vision and pattern recognition*, 2017, pp. 7291–7299.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[193] Z. Cao, T. Simon, S.-E. Wei, 和 Y. Sheikh，“使用部件亲和场的实时多人2D姿态估计，” 收录于 *IEEE计算机视觉与模式识别会议论文集*，2017年，第7291–7299页。'
- en: '[194] O. Alemi, J. Françoise, and P. Pasquier, “Groovenet: Real-time music-driven
    dance movement generation using artificial neural networks,” *networks*, vol. 8,
    no. 17, p. 26, 2017.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[194] O. Alemi, J. Françoise, 和 P. Pasquier，“Groovenet：使用人工神经网络进行实时音乐驱动的舞蹈动作生成，”
    *networks*，第8卷，第17期，第26页，2017。'
- en: '[195] T. Tang, J. Jia, and H. Mao, “Dance with melody: An lstm-autoencoder
    approach to music-oriented dance synthesis,” in *Proceedings of the 26th ACM international
    conference on Multimedia*, 2018, pp. 1598–1606.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[195] T. Tang, J. Jia, 和 H. Mao, “伴旋律舞蹈：一种基于LSTM自编码器的音乐导向舞蹈合成方法，” 收录于 *第26届ACM国际多媒体会议论文集*，2018年，第1598–1606页。'
- en: '[196] N. Yalta, S. Watanabe, K. Nakadai, and T. Ogata, “Weakly-supervised deep
    recurrent neural networks for basic dance step generation,” in *2019 International
    Joint Conference on Neural Networks (IJCNN)*.   IEEE, 2019, pp. 1–8.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[196] N. Yalta, S. Watanabe, K. Nakadai, 和 T. Ogata, “用于基础舞步生成的弱监督深度递归神经网络，”
    收录于 *2019年国际神经网络联合会议（IJCNN）*，IEEE，2019年，第1–8页。'
- en: '[197] W. Zhuang, Y. Wang, J. Robinson, C. Wang, M. Shao, Y. Fu, and S. Xia,
    “Towards 3d dance motion synthesis and control,” *arXiv preprint arXiv:2006.05743*,
    2020.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[197] W. Zhuang, Y. Wang, J. Robinson, C. Wang, M. Shao, Y. Fu, 和 S. Xia, “面向3D舞蹈动作合成与控制，”
    *arXiv预印本 arXiv:2006.05743*，2020年。'
- en: '[198] H.-K. Kao and L. Su, “Temporally guided music-to-body-movement generation,”
    in *Proceedings of the 28th ACM International Conference on Multimedia*, 2020,
    pp. 147–155.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[198] H.-K. Kao 和 L. Su, “时间指导的音乐到身体运动生成，” 收录于 *第28届ACM国际多媒体会议论文集*，2020年，第147–155页。'
- en: '[199] H.-Y. Lee, X. Yang, M.-Y. Liu, T.-C. Wang, Y.-D. Lu, M.-H. Yang, and
    J. Kautz, “Dancing to music,” *Advances in neural information processing systems*,
    vol. 32, 2019.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[199] H.-Y. Lee, X. Yang, M.-Y. Liu, T.-C. Wang, Y.-D. Lu, M.-H. Yang, 和 J. Kautz,
    “随音乐舞蹈，” *神经信息处理系统进展*，第32卷，2019年。'
- en: '[200] G. Sun, Y. Wong, Z. Cheng, M. S. Kankanhalli, W. Geng, and X. Li, “Deepdance:
    music-to-dance motion choreography with adversarial learning,” *IEEE Transactions
    on Multimedia*, vol. 23, pp. 497–509, 2020.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[200] G. Sun, Y. Wong, Z. Cheng, M. S. Kankanhalli, W. Geng, 和 X. Li, “Deepdance:
    基于对抗学习的音乐到舞蹈动作编排，” *IEEE多媒体汇刊*，第23卷，第497–509页，2020年。'
- en: '[201] R. Huang, H. Hu, W. Wu, K. Sawada, M. Zhang, and D. Jiang, “Dance revolution:
    Long-term dance generation with music via curriculum learning,” *arXiv preprint
    arXiv:2006.06119*, 2020.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[201] R. Huang, H. Hu, W. Wu, K. Sawada, M. Zhang, 和 D. Jiang, “舞蹈革命：通过课程学习的长期舞蹈生成与音乐结合，”
    *arXiv预印本 arXiv:2006.06119*，2020年。'
- en: '[202] R. Li, S. Yang, D. A. Ross, and A. Kanazawa, “Ai choreographer: Music
    conditioned 3d dance generation with aist++,” 2021.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[202] R. Li, S. Yang, D. A. Ross, 和 A. Kanazawa, “AI编舞师：基于AIST++的音乐条件3D舞蹈生成，”
    2021年。'
- en: '[203] H. Ahn, J. Kim, K. Kim, and S. Oh, “Generative autoregressive networks
    for 3d dancing move synthesis from music,” *IEEE Robotics and Automation Letters*,
    vol. 5, no. 2, pp. 3501–3508, 2020.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[203] H. Ahn, J. Kim, K. Kim, 和 S. Oh, “用于从音乐生成3D舞蹈动作的生成自回归网络，” *IEEE机器人与自动化快报*，第5卷，第2期，第3501–3508页，2020年。'
- en: '[204] Z. Ye, H. Wu, J. Jia, Y. Bu, W. Chen, F. Meng, and Y. Wang, “Choreonet:
    Towards music to dance synthesis with choreographic action unit,” in *Proceedings
    of the 28th ACM International Conference on Multimedia*, 2020, pp. 744–752.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[204] Z. Ye, H. Wu, J. Jia, Y. Bu, W. Chen, F. Meng, 和 Y. Wang, “Choreonet：面向音乐到舞蹈合成的编排动作单元，”
    收录于 *第28届ACM国际多媒体会议论文集*，2020年，第744–752页。'
- en: '[205] W. Menapace, S. Lathuiliere, S. Tulyakov, A. Siarohin, and E. Ricci,
    “Playable video generation,” in *Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition (CVPR)*, 2021, pp. 10 061–10 070.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[205] W. Menapace, S. Lathuiliere, S. Tulyakov, A. Siarohin, 和 E. Ricci, “可播放的视频生成，”
    收录于 *IEEE计算机视觉与模式识别会议（CVPR）论文集*，2021年，第10,061–10,070页。'
- en: '[206] J. Huang, Y. Jin, K. M. Yi, and L. Sigal, “Layered controllable video
    generation,” in *"Proceedings of the European Conference of Computer Vision (ECCV)"*,
    S. Avidan, G. Brostow, M. Cissé, G. M. Farinella, and T. Hassner, Eds., 2022.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[206] J. Huang, Y. Jin, K. M. Yi, 和 L. Sigal, “可控的分层视频生成，” 收录于 *“欧洲计算机视觉会议（ECCV）论文集”*，由
    S. Avidan, G. Brostow, M. Cissé, G. M. Farinella 和 T. Hassner 主编，2022年。'
- en: '[207] A. Davtyan and P. Favaro, “Controllable video generation through global
    and local motion dynamics,” in *Proceedings of the European Conference of Computer
    Vision (ECCV)*, 2022.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[207] A. Davtyan 和 P. Favaro, “通过全局和局部运动动态的可控视频生成，” 收录于 *欧洲计算机视觉会议（ECCV）论文集*，2022年。'
- en: '[208] B. Mildenhall, P. P. Srinivasan, M. Tancik, J. T. Barron, R. Ramamoorthi,
    and R. Ng, “Nerf: Representing scenes as neural radiance fields for view synthesis,”
    in *Proceedings of the European Conference of Computer Vision (ECCV)*, 2020.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[208] B. Mildenhall, P. P. Srinivasan, M. Tancik, J. T. Barron, R. Ramamoorthi,
    和 R. Ng, “Nerf：将场景表示为神经辐射场用于视图合成，” 收录于 *欧洲计算机视觉会议（ECCV）论文集*，2020年。'
- en: '[209] W. Menapace, A. Siarohin, S. Lathuilière, P. Achlioptas, V. Golyanik,
    E. Ricci, and S. Tulyakov, “Plotting behind the scenes: Towards learnable game
    engines,” *arXiv preprint arXiv:2303.13472*, 2023.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[209] W. Menapace, A. Siarohin, S. Lathuilière, P. Achlioptas, V. Golyanik,
    E. Ricci, 和 S. Tulyakov，“幕后绘图：朝向可学习的游戏引擎”，*arXiv 预印本 arXiv:2303.13472*，2023年。'
- en: '[210] N. Feng, Z. Song, J. Yu, Y.-P. P. Chen, Y. Zhao, Y. He, and T. Guan,
    “Sset: a dataset for shot segmentation, event detection, player tracking in soccer
    videos,” *Multimedia Tools and Applications*, vol. 79, pp. 28 971–28 992, 2020.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[210] N. Feng, Z. Song, J. Yu, Y.-P. P. Chen, Y. Zhao, Y. He, 和 T. Guan，“Sset：一个用于足球视频的镜头分割、事件检测和球员跟踪的数据集”，*多媒体工具与应用*，第79卷，第28,971–28,992页，2020年。'
- en: '[211] Y. Jiang, K. Cui, L. Chen, C. Wang, and C. Xu, “Soccerdb: A large-scale
    database for comprehensive video understanding,” in *Proceedings of the 3rd International
    Workshop on Multimedia Content Analysis in Sports*, 2020, pp. 1–8.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[211] Y. Jiang, K. Cui, L. Chen, C. Wang, 和 C. Xu，“Soccerdb：用于全面视频理解的大规模数据库”，在*第3届国际体育多媒体内容分析研讨会论文集*，2020年，第1–8页。'
- en: '[212] A. Deliege, A. Cioppa, S. Giancola, M. J. Seikavandi, J. V. Dueholm,
    K. Nasrollahi, B. Ghanem, T. B. Moeslund, and M. Van Droogenbroeck, “Soccernet-v2:
    A dataset and benchmarks for holistic understanding of broadcast soccer videos,”
    in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    2021, pp. 4508–4519.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[212] A. Deliege, A. Cioppa, S. Giancola, M. J. Seikavandi, J. V. Dueholm,
    K. Nasrollahi, B. Ghanem, T. B. Moeslund, 和 M. Van Droogenbroeck，“Soccernet-v2：用于全面理解广播足球视频的数据集和基准”，在*IEEE/CVF
    计算机视觉与模式识别会议论文集*，2021年，第4508–4519页。'
- en: '[213] N. M. Lessa, E. L. Colombini, and A. D. S. Simões, “Soccerkicks: a dataset
    of 3d dead ball kicks reference movements for humanoid robots,” in *2021 IEEE
    International Conference on Systems, Man, and Cybernetics (SMC)*.   IEEE, 2021,
    pp. 3472–3478.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[213] N. M. Lessa, E. L. Colombini, 和 A. D. S. Simões，“Soccerkicks：用于类人机器人
    3D 死球踢击参考动作的数据集”，在*2021 IEEE 国际系统、人类与控制会议 (SMC)*，IEEE，2021年，第3472–3478页。'
- en: '[214] A. Scott, I. Uchida, M. Onishi, Y. Kameda, K. Fukui, and K. Fujii, “Soccertrack:
    A dataset and tracking algorithm for soccer with fish-eye and drone videos,” in
    *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    2022, pp. 3569–3579.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[214] A. Scott, I. Uchida, M. Onishi, Y. Kameda, K. Fukui, 和 K. Fujii，“Soccertrack：用于足球的鱼眼和无人机视频数据集及跟踪算法”，在*IEEE/CVF
    计算机视觉与模式识别会议论文集*，2022年，第3569–3579页。'
- en: '[215] P. Parisot and C. De Vleeschouwer, “Scene-specific classifier for effective
    and efficient team sport players detection from a single calibrated camera,” *Computer
    Vision and Image Understanding*, vol. 159, pp. 74–88, 2017.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[215] P. Parisot 和 C. De Vleeschouwer，“针对有效和高效的团队运动员检测的场景特定分类器，基于单台校准相机”，*计算机视觉与图像理解*，第159卷，第74–88页，2017年。'
- en: '[216] C. Ma, J. Fan, J. Yao, and T. Zhang, “Npu rgb+ d dataset and a feature-enhanced
    lstm-dgcn method for action recognition of basketball players,” *Applied Sciences*,
    vol. 11, no. 10, p. 4426, 2021.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[216] C. Ma, J. Fan, J. Yao, 和 T. Zhang，“Npu rgb+ d 数据集和一种特征增强的 lstm-dgcn 方法用于篮球运动员的动作识别”，*应用科学*，第11卷，第10期，第4426页，2021年。'
- en: '[217] D. Wu, H. Zhao, X. Bao, and R. P. Wildes, “Sports video analysis on large-scale
    data,” in *ECCV*, Oct. 2022.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[217] D. Wu, H. Zhao, X. Bao, 和 R. P. Wildes，“大规模数据上的体育视频分析”，在*ECCV*，2022年10月。'
- en: '[218] W. Menapace, S. Lathuiliere, A. Siarohin, C. Theobalt, S. Tulyakov, V. Golyanik,
    and E. Ricci, “Playable environments: Video manipulation in space and time,” in
    *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    2022, pp. 3584–3593.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[218] W. Menapace, S. Lathuiliere, A. Siarohin, C. Theobalt, S. Tulyakov, V.
    Golyanik, 和 E. Ricci，“可玩环境：时空视频操控”，在*IEEE/CVF 计算机视觉与模式识别会议论文集*，2022年，第3584–3593页。'
- en: '[219] C. Xu, Y. Fu, B. Zhang, Z. Chen, Y.-G. Jiang, and X. Xue, “Learning to
    score figure skating sport videos,” *IEEE transactions on circuits and systems
    for video technology*, vol. 30, no. 12, pp. 4578–4590, 2019.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[219] C. Xu, Y. Fu, B. Zhang, Z. Chen, Y.-G. Jiang, 和 X. Xue，“学习评分花样滑冰运动视频”，*IEEE
    电路与系统视频技术学报*，第30卷，第12期，第4578–4590页，2019年。'
- en: '[220] S. Wang, D. Yang, P. Zhai, C. Chen, and L. Zhang, “Tsa-net: Tube self-attention
    network for action quality assessment,” in *Proceedings of the 29th ACM International
    Conference on Multimedia*, 2021, pp. 4902–4910.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[220] S. Wang, D. Yang, P. Zhai, C. Chen, 和 L. Zhang，“Tsa-net：用于动作质量评估的管道自注意力网络”，在*第29届
    ACM 国际多媒体会议论文集*，2021年，第4902–4910页。'
- en: '[221] P. Parmar and B. T. Morris, “What and how well you performed? a multitask
    learning approach to action quality assessment,” in *Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition*, 2019, pp. 304–313.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[221] P. Parmar 和 B. T. Morris，“你表现如何？一种多任务学习方法用于动作质量评估”，发表于 *IEEE/CVF计算机视觉与模式识别会议论文集*，2019年，第304–313页。'
- en: '[222] J. Xu, Y. Rao, X. Yu, G. Chen, J. Zhou, and J. Lu, “Finediving: A fine-grained
    dataset for procedure-aware action quality assessment,” in *Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2022, pp. 2949–2958.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[222] J. Xu, Y. Rao, X. Yu, G. Chen, J. Zhou 和 J. Lu，“Finediving：一个用于过程感知动作质量评估的细粒度数据集”，发表于
    *IEEE/CVF计算机视觉与模式识别会议论文集*，2022年，第2949–2958页。'
- en: '[223] W. McNally, K. Vats, T. Pinto, C. Dulhanty, J. McPhee, and A. Wong, “Golfdb:
    A video database for golf swing sequencing,” in *Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition Workshops*, 2019, pp. 0–0.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[223] W. McNally, K. Vats, T. Pinto, C. Dulhanty, J. McPhee 和 A. Wong，“Golfdb：用于高尔夫挥杆序列的视频数据库”，发表于
    *IEEE/CVF计算机视觉与模式识别会议论文集（研讨会）*，2019年，第0–0页。'
- en: '[224] A. Piergiovanni and M. S. Ryoo, “Fine-grained activity recognition in
    baseball videos,” in *Proceedings of the ieee conference on computer vision and
    pattern recognition workshops*, 2018, pp. 1740–1748.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[224] A. Piergiovanni 和 M. S. Ryoo，“棒球视频中的细粒度活动识别”，发表于 *IEEE计算机视觉与模式识别会议论文集（研讨会）*，2018年，第1740–1748页。'
- en: '[225] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, and L. Fei-Fei,
    “Large-scale video classification with convolutional neural networks,” in *Proceedings
    of the IEEE conference on Computer Vision and Pattern Recognition*, 2014, pp.
    1725–1732.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[225] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar 和 L. Fei-Fei，“大规模视频分类与卷积神经网络”，发表于
    *IEEE计算机视觉与模式识别会议论文集*，2014年，第1725–1732页。'
- en: '[226] H. Pirsiavash, C. Vondrick, and A. Torralba, “Assessing the quality of
    actions,” in *Computer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland,
    September 6-12, 2014, Proceedings, Part VI 13*.   Springer, 2014, pp. 556–571.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[226] H. Pirsiavash, C. Vondrick 和 A. Torralba，“评估动作质量”，发表于 *计算机视觉–ECCV 2014：第13届欧洲会议，瑞士苏黎世，2014年9月6-12日，论文集，第VI部分*。Springer，2014年，第556–571页。'
- en: '[227] S. M. Safdarnejad, X. Liu, L. Udpa, B. Andrus, J. Wood, and D. Craven,
    “Sports videos in the wild (svw): A video dataset for sports analysis,” in *2015
    11th IEEE International Conference and Workshops on Automatic Face and Gesture
    Recognition (FG)*, vol. 1.   IEEE, 2015, pp. 1–7.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[227] S. M. Safdarnejad, X. Liu, L. Udpa, B. Andrus, J. Wood 和 D. Craven，“野外运动视频（svw）：用于运动分析的视频数据集”，发表于
    *2015年第11届IEEE国际自动面部与姿态识别会议（FG）*，第1卷。IEEE，2015年，第1–7页。'
- en: '[228] P. Parmar and B. Tran Morris, “Learning to score olympic events,” in
    *Proceedings of the IEEE conference on computer vision and pattern recognition
    workshops*, 2017, pp. 20–28.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[228] P. Parmar 和 B. Tran Morris，“学习评分奥运项目”，发表于 *IEEE计算机视觉与模式识别会议论文集（研讨会）*，2017年，第20–28页。'
- en: '[229] W. Zhang, Z. Liu, L. Zhou, H. Leung, and A. B. Chan, “Martial arts, dancing
    and sports dataset: A challenging stereo and multi-view dataset for 3d human pose
    estimation,” *Image and Vision Computing*, vol. 61, pp. 22–39, 2017.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[229] W. Zhang, Z. Liu, L. Zhou, H. Leung 和 A. B. Chan，“武术、舞蹈与运动数据集：一个具有挑战性的立体和多视角数据集，用于3D人体姿势估计”，*图像与视觉计算*，第61卷，第22–39页，2017年。'
- en: '[230] S. Yeung, O. Russakovsky, N. Jin, M. Andriluka, G. Mori, and L. Fei-Fei,
    “Every moment counts: Dense detailed labeling of actions in complex videos,” *International
    Journal of Computer Vision*, vol. 126, pp. 375–389, 2018.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[230] S. Yeung, O. Russakovsky, N. Jin, M. Andriluka, G. Mori 和 L. Fei-Fei，“每一刻都很重要：复杂视频中的详细动作密集标注”，*国际计算机视觉期刊*，第126卷，第375–389页，2018年。'
- en: '[231] P. Parmar and B. Morris, “Action quality assessment across multiple actions,”
    in *2019 IEEE winter conference on applications of computer vision (WACV)*.   IEEE,
    2019, pp. 1468–1476.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[231] P. Parmar 和 B. Morris，“多动作的动作质量评估”，发表于 *2019年IEEE冬季计算机视觉应用会议（WACV）*。IEEE，2019年，第1468–1476页。'
- en: '[232] C. Zalluhoglu and N. Ikizler-Cinbis, “Collective sports: A multi-task
    dataset for collective activity recognition,” *Image and Vision Computing*, vol. 94,
    p. 103870, 2020.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[232] C. Zalluhoglu 和 N. Ikizler-Cinbis，“集体运动：一个用于集体活动识别的多任务数据集”，*图像与视觉计算*，第94卷，第103870页，2020年。'
- en: '[233] Y. Li, L. Chen, R. He, Z. Wang, G. Wu, and L. Wang, “Multisports: A multi-person
    video dataset of spatio-temporally localized sports actions,” in *Proceedings
    of the IEEE/CVF International Conference on Computer Vision*, 2021, pp. 13 536–13 545.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[233] Y. Li, L. Chen, R. He, Z. Wang, G. Wu 和 L. Wang，“Multisports：一个多人物视频数据集，用于时空定位的运动动作”，发表于
    *IEEE/CVF国际计算机视觉会议论文集*，2021年，第13 536–13 545页。'
- en: '[234] A. Nibali, J. Millward, Z. He, and S. Morgan, “Aspset: An outdoor sports
    pose video dataset with 3d keypoint annotations,” *Image and Vision Computing*,
    vol. 111, p. 104196, 2021.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[234] A. Nibali, J. Millward, Z. He 和 S. Morgan，“Aspset: 一个户外体育姿势视频数据集，具有3D关键点注释，”*图像与视觉计算*，第111卷，页码104196，2021年。'
- en: '[235] J. Chung, C.-h. Wuu, H.-r. Yang, Y.-W. Tai, and C.-K. Tang, “Haa500:
    Human-centric atomic action dataset with curated videos,” in *Proceedings of the
    IEEE/CVF International Conference on Computer Vision*, 2021, pp. 13 465–13 474.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[235] J. Chung, C.-h. Wuu, H.-r. Yang, Y.-W. Tai 和 C.-K. Tang，“Haa500: 以人为本的原子动作数据集及其策划视频，”在
    *IEEE/CVF 国际计算机视觉会议论文集*，2021年，页码13 465–13 474。'
- en: '[236] X. Chen, A. Pang, W. Yang, Y. Ma, L. Xu, and J. Yu, “Sportscap: Monocular
    3d human motion capture and fine-grained understanding in challenging sports videos,”
    *International Journal of Computer Vision*, Aug 2021. [Online]. Available: [https://doi.org/10.1007/s11263-021-01486-4](https://doi.org/10.1007/s11263-021-01486-4)'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[236] X. Chen, A. Pang, W. Yang, Y. Ma, L. Xu 和 J. Yu，“Sportscap: 单目3D人体运动捕捉和在挑战性体育视频中的细粒度理解，”*计算机视觉国际期刊*，2021年8月。[在线]
    可用: [https://doi.org/10.1007/s11263-021-01486-4](https://doi.org/10.1007/s11263-021-01486-4)'
- en: '[237] P. Parmar and B. Morris, “Win-fail action recognition,” in *Proceedings
    of the IEEE/CVF Winter Conference on Applications of Computer Vision*, 2022, pp.
    161–171.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[237] P. Parmar 和 B. Morris，“胜负动作识别，”在 *IEEE/CVF冬季计算机视觉应用会议论文集*，2022年，页码161–171。'
- en: '[238] C. K. Ingwersen, C. Mikkelstrup, J. N. Jensen, M. R. Hannemose, and A. B.
    Dahl, “Sportspose: A dynamic 3d sports pose dataset,” in *Proceedings of the IEEE/CVF
    International Workshop on Computer Vision in Sports*, 2023.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[238] C. K. Ingwersen, C. Mikkelstrup, J. N. Jensen, M. R. Hannemose 和 A. B.
    Dahl，“Sportspose: 一个动态3D体育姿势数据集，”在 *IEEE/CVF国际体育计算机视觉研讨会论文集*，2023年。'
- en: '[239] Y. Cui, C. Zeng, X. Zhao, Y. Yang, G. Wu, and L. Wang, “Sportsmot: A
    large multi-object tracking dataset in multiple sports scenes,” *arXiv preprint
    arXiv:2304.05170*, 2023.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[239] Y. Cui, C. Zeng, X. Zhao, Y. Yang, G. Wu 和 L. Wang，“Sportsmot: 一个大型多目标跟踪数据集，涵盖多种运动场景，”*arXiv
    预印本 arXiv:2304.05170*，2023年。'
- en: '[240] T. D’Orazio, M. Leo, N. Mosca, P. Spagnolo, and P. L. Mazzeo, “A semi-automatic
    system for ground truth generation of soccer video sequences,” in *2009 Sixth
    IEEE International Conference on Advanced Video and Signal Based Surveillance*.   IEEE,
    2009, pp. 559–564.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[240] T. D’Orazio, M. Leo, N. Mosca, P. Spagnolo 和 P. L. Mazzeo，“用于足球视频序列地面真实生成的半自动系统，”在
    *2009年第六届IEEE国际先进视频和信号基监控会议*。IEEE，2009年，页码559–564。'
- en: '[241] S. A. Pettersen, D. Johansen, H. Johansen, V. Berg-Johansen, V. R. Gaddam,
    A. Mortensen, R. Langseth, C. Griwodz, H. K. Stensland, and P. Halvorsen, “Soccer
    video and player position dataset,” in *Proceedings of the 5th ACM Multimedia
    Systems Conference*, 2014, pp. 18–23.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[241] S. A. Pettersen, D. Johansen, H. Johansen, V. Berg-Johansen, V. R. Gaddam,
    A. Mortensen, R. Langseth, C. Griwodz, H. K. Stensland 和 P. Halvorsen，“足球视频和球员位置数据集，”在
    *第5届ACM多媒体系统会议论文集*，2014年，页码18–23。'
- en: '[242] K. Lu, J. Chen, J. J. Little, and H. He, “Light cascaded convolutional
    neural networks for accurate player detection,” *arXiv preprint arXiv:1709.10230*,
    2017.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[242] K. Lu, J. Chen, J. J. Little 和 H. He，“用于准确玩家检测的轻量级级联卷积神经网络，”*arXiv 预印本
    arXiv:1709.10230*，2017年。'
- en: '[243] J. Yu, A. Lei, Z. Song, T. Wang, H. Cai, and N. Feng, “Comprehensive
    dataset of broadcast soccer videos,” in *2018 IEEE Conference on Multimedia Information
    Processing and Retrieval (MIPR)*.   IEEE, 2018, pp. 418–423.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[243] J. Yu, A. Lei, Z. Song, T. Wang, H. Cai 和 N. Feng，“广播足球视频的综合数据集，”在 *2018
    IEEE多媒体信息处理与检索会议（MIPR）*。IEEE，2018年，页码418–423。'
- en: '[244] J. Qi, J. Yu, T. Tu, K. Gao, Y. Xu, X. Guan, X. Wang, Y. Dong, B. Xu,
    L. Hou *et al.*, “Goal: A challenging knowledge-grounded video captioning benchmark
    for real-time soccer commentary generation,” *arXiv preprint arXiv:2303.14655*,
    2023.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[244] J. Qi, J. Yu, T. Tu, K. Gao, Y. Xu, X. Guan, X. Wang, Y. Dong, B. Xu,
    L. Hou *等*，“Goal: 一个具有挑战性的基于知识的视频字幕基准，用于实时足球评论生成，”*arXiv 预印本 arXiv:2303.14655*，2023年。'
- en: '[245] C. De Vleeschouwer, F. Chen, D. Delannay, C. Parisot, C. Chaudy, E. Martrou,
    A. Cavallaro *et al.*, “Distributed video acquisition and annotation for sport-event
    summarization,” *NEM summit*, vol. 8, no. 10.1016, 2008.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[245] C. De Vleeschouwer, F. Chen, D. Delannay, C. Parisot, C. Chaudy, E. Martrou,
    A. Cavallaro *等*，“运动事件总结的分布式视频采集和标注，”*NEM峰会*，第8卷，第10.1016号，2008年。'
- en: '[246] V. Ramanathan, J. Huang, S. Abu-El-Haija, A. Gorban, K. Murphy, and L. Fei-Fei,
    “Detecting events and key actors in multi-person videos,” in *Proceedings of the
    IEEE conference on computer vision and pattern recognition*, 2016, pp. 3043–3053.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[246] V. Ramanathan, J. Huang, S. Abu-El-Haija, A. Gorban, K. Murphy 和 L. Fei-Fei，“在多人视频中检测事件和关键参与者，”在
    *IEEE计算机视觉与模式识别会议论文集*，2016年，页码3043–3053。'
- en: '[247] S. Francia, S. Calderara, and D. F. Lanzi, “Classificazione di azioni
    cestistiche mediante tecniche di deep learning,” *URL: https://www. researchgate.
    net/publication/330534530_Classificazione_di_Azioni_ Cestistiche_mediante_Tecniche_di_Deep_Learning*,
    2018.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[247] S. Francia, S. Calderara 和 D. F. Lanzi, “通过深度学习技术进行篮球动作分类，” *网址: https://www.
    researchgate. net/publication/330534530_Classificazione_di_Azioni_ Cestistiche_mediante_Tecniche_di_Deep_Learning*，2018年。'
- en: '[248] X. Gu, X. Xue, and F. Wang, “Fine-grained action recognition on a novel
    basketball dataset,” in *ICASSP 2020-2020 IEEE International Conference on Acoustics,
    Speech and Signal Processing (ICASSP)*.   IEEE, 2020, pp. 2563–2567.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[248] X. Gu, X. Xue 和 F. Wang, “在一个新型篮球数据集上进行细粒度动作识别，” 见 *ICASSP 2020-2020
    IEEE国际声学、语音与信号处理会议（ICASSP）*。IEEE，2020年，第2563–2567页。'
- en: '[249] Y. Yan, N. Zhuang, B. Ni, J. Zhang, M. Xu, Q. Zhang, Z. Zhang, S. Cheng,
    Q. Tian, Y. Xu *et al.*, “Fine-grained video captioning via graph-based multi-granularity
    interaction learning,” *IEEE transactions on pattern analysis and machine intelligence*,
    vol. 44, no. 2, pp. 666–683, 2019.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[249] Y. Yan, N. Zhuang, B. Ni, J. Zhang, M. Xu, Q. Zhang, Z. Zhang, S. Cheng,
    Q. Tian, Y. Xu *等*，“通过基于图的多粒度交互学习进行细粒度视频字幕生成，” *IEEE模式分析与机器智能学报*，第44卷，第2期，第666–683页，2019年。'
- en: '[250] L. Zhu, K. Rematas, B. Curless, S. Seitz, and I. Kemelmacher-Shlizerman,
    “Reconstructing nba players,” in *Proceedings of the European Conference on Computer
    Vision (ECCV)*, August 2020.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[250] L. Zhu, K. Rematas, B. Curless, S. Seitz 和 I. Kemelmacher-Shlizerman,
    “重建NBA球员，” 见 *欧洲计算机视觉会议（ECCV）论文集*，2020年8月。'
- en: '[251] M. S. Ibrahim, S. Muralidharan, Z. Deng, A. Vahdat, and G. Mori, “A hierarchical
    deep temporal model for group activity recognition,” in *Proceedings of the IEEE
    conference on computer vision and pattern recognition*, 2016, pp. 1971–1980.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[251] M. S. Ibrahim, S. Muralidharan, Z. Deng, A. Vahdat 和 G. Mori, “用于群体活动识别的层次深度时间模型，”
    见 *IEEE计算机视觉与模式识别会议论文集*，2016年，第1971–1980页。'
- en: '[252] Ibrahim, Mostafa S and Muralidharan, Srikanth and Deng, Zhiwei and Vahdat,
    Arash and Mori, Greg, “Hierarchical deep temporal models for group activity recognition,”
    *CoRR*, vol. abs/1607.02643, 2016\. [Online]. Available: [http://arxiv.org/abs/1607.02643](http://arxiv.org/abs/1607.02643)'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[252] Ibrahim, Mostafa S 和 Muralidharan, Srikanth 和 Deng, Zhiwei 和 Vahdat,
    Arash 和 Mori, Greg, “用于群体活动识别的层次深度时间模型，” *CoRR*，第abs/1607.02643卷，2016年。[在线]. 可用:
    [http://arxiv.org/abs/1607.02643](http://arxiv.org/abs/1607.02643)'
- en: '[253] E. Bermejo Nievas, O. Deniz Suarez, G. Bueno García, and R. Sukthankar,
    “Violence detection in video using computer vision techniques,” in *Computer Analysis
    of Images and Patterns: 14th International Conference, CAIP 2011, Seville, Spain,
    August 29-31, 2011, Proceedings, Part II 14*.   Springer, 2011, pp. 332–339.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[253] E. Bermejo Nievas, O. Deniz Suarez, G. Bueno García 和 R. Sukthankar,
    “使用计算机视觉技术检测视频中的暴力行为，” 见 *计算机图像与模式分析: 第14届国际会议，CAIP 2011，西班牙塞维利亚，2011年8月29-31日，论文集，第II部分*。Springer，2011年，第332–339页。'
- en: '[254] K. Vats, P. Walters, M. Fani, D. A. Clausi, and J. Zelek, “Player tracking
    and identification in ice hockey,” *arXiv preprint arXiv:2110.03090*, 2021.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[254] K. Vats, P. Walters, M. Fani, D. A. Clausi 和 J. Zelek, “冰球中的球员跟踪与识别，”
    *arXiv预印本 arXiv:2110.03090*，2021年。'
- en: '[255] T. De Campos, M. Barnard, K. Mikolajczyk, J. Kittler, F. Yan, W. Christmas,
    and D. Windridge, “An evaluation of bags-of-words and spatio-temporal shapes for
    action recognition,” in *2011 IEEE Workshop on Applications of Computer Vision
    (WACV)*.   IEEE, 2011, pp. 344–351.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[255] T. De Campos, M. Barnard, K. Mikolajczyk, J. Kittler, F. Yan, W. Christmas
    和 D. Windridge, “对动作识别中的词袋模型和时空形状进行评估，” 见 *2011 IEEE计算机视觉应用研讨会（WACV）*。IEEE，2011年，第344–351页。'
- en: '[256] S. Gourgari, G. Goudelis, K. Karpouzis, and S. Kollias, “Thetis: Three
    dimensional tennis shots a human action dataset,” in *Proceedings of the IEEE
    Conference on Computer Vision and Pattern Recognition Workshops*, 2013, pp. 676–681.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[256] S. Gourgari, G. Goudelis, K. Karpouzis 和 S. Kollias, “Thetis: 三维网球击球动作数据集，”
    见 *IEEE计算机视觉与模式识别研讨会论文集*，2013年，第676–681页。'
- en: '[257] H. Faulkner and A. Dick, “Tenniset: a dataset for dense fine-grained
    event recognition, localisation and description,” in *2017 International Conference
    on Digital Image Computing: Techniques and Applications (DICTA)*.   IEEE, 2017,
    pp. 1–8.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[257] H. Faulkner 和 A. Dick, “Tenniset: 一个用于密集细粒度事件识别、定位和描述的数据集，” 见 *2017国际数字图像计算会议（DICTA）*。IEEE，2017年，第1–8页。'
- en: '[258] W. Menapace, S. Lathuiliere, S. Tulyakov, A. Siarohin, and E. Ricci,
    “Playable video generation,” in *Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition*, 2021, pp. 10 061–10 070.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[258] W. Menapace, S. Lathuiliere, S. Tulyakov, A. Siarohin 和 E. Ricci, “可播放视频生成，”
    见 *IEEE/CVF计算机视觉与模式识别会议论文集*，2021年，第10 061–10 070页。'
- en: '[259] P.-E. Martin, J. Benois-Pineau, R. Péteri, and J. Morlier, “Sport action
    recognition with siamese spatio-temporal cnns: Application to table tennis,” in
    *2018 International Conference on Content-Based Multimedia Indexing (CBMI)*.   IEEE,
    2018, pp. 1–6.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[259] P.-E. Martin, J. Benois-Pineau, R. Péteri, 和 J. Morlier, “使用孪生时空CNN进行体育动作识别：应用于乒乓球，”
    *2018国际基于内容的多媒体索引会议（CBMI）*。 IEEE，2018，第1–6页。'
- en: '[260] K. M. Kulkarni and S. Shenoy, “Table tennis stroke recognition using
    two-dimensional human pose estimation,” in *Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition*, 2021, pp. 4576–4584.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[260] K. M. Kulkarni 和 S. Shenoy, “使用二维人体姿态估计进行乒乓球击球动作识别，” *IEEE/CVF计算机视觉与模式识别会议论文集*，2021年，第4576–4584页。'
- en: '[261] J. Bian, Q. Wang, H. Xiong, J. Huang, C. Liu, X. Li, J. Cheng, J. Zhao,
    F. Lu, and D. Dou, “P2a: A dataset and benchmark for dense action detection from
    table tennis match broadcasting videos,” *arXiv preprint arXiv:2207.12730*, 2022.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[261] J. Bian, Q. Wang, H. Xiong, J. Huang, C. Liu, X. Li, J. Cheng, J. Zhao,
    F. Lu, 和 D. Dou, “P2a：一个用于从乒乓球比赛广播视频中进行密集动作检测的数据集和基准，” *arXiv预印本 arXiv:2207.12730*，2022年。'
- en: '[262] S. Zahan, G. M. Hassan, and A. Mian, “Learning sparse temporal video
    mapping for action quality assessment in floor gymnastics,” *arXiv preprint arXiv:2301.06103*,
    2023.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[262] S. Zahan, G. M. Hassan, 和 A. Mian, “学习稀疏时间视频映射以评估地面体操中的动作质量，” *arXiv预印本
    arXiv:2301.06103*，2023年。'
- en: '[263] A. Ghosh, S. Singh, and C. Jawahar, “Towards structured analysis of broadcast
    badminton videos,” in *2018 IEEE Winter Conference on Applications of Computer
    Vision (WACV)*.   IEEE, 2018, pp. 296–304.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[263] A. Ghosh, S. Singh, 和 C. Jawahar, “迈向广播羽毛球视频的结构化分析，” *2018 IEEE冬季计算机视觉应用会议（WACV）*。
    IEEE，2018，第296–304页。'
- en: '[264] Z. T. L. Shan, “Fineskating: A high-quality figure skating dataset and
    multi-task approach for sport action,” *Peng Cheng Laboratory Commumications*,
    vol. 1, no. 3, p. 107, 2020.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[264] Z. T. L. Shan, “Fineskating：一个高质量花样滑冰数据集和多任务运动方法，” *彭城实验室通讯*，第1卷，第3期，第107页，2020年。'
- en: '[265] S. Liu, X. Liu, G. Huang, L. Feng, L. Hu, D. Jiang, A. Zhang, Y. Liu,
    and H. Qiao, “Fsd-10: a dataset for competitive sports content analysis,” *arXiv
    preprint arXiv:2002.03312*, 2020.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[265] S. Liu, X. Liu, G. Huang, L. Feng, L. Hu, D. Jiang, A. Zhang, Y. Liu,
    和 H. Qiao, “Fsd-10：一个用于竞技体育内容分析的数据集，” *arXiv预印本 arXiv:2002.03312*，2020年。'
- en: '[266] S. Liu, A. Zhang, Y. Li, J. Zhou, L. Xu, Z. Dong, and R. Zhang, “Temporal
    segmentation of fine-gained semantic action: A motion-centered figure skating
    dataset,” in *Proceedings of the AAAI conference on artificial intelligence*,
    vol. 35, no. 3, 2021, pp. 2163–2171.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[266] S. Liu, A. Zhang, Y. Li, J. Zhou, L. Xu, Z. Dong, 和 R. Zhang, “细粒度语义动作的时间分割：一个以动作为中心的花样滑冰数据集，”
    *AAAI人工智能会议论文集*，第35卷，第3期，2021年，第2163–2171页。'
- en: '[267] Y. Li, Y. Li, and N. Vasconcelos, “Resound: Towards action recognition
    without representation bias,” in *Proceedings of the European Conference on Computer
    Vision (ECCV)*, 2018, pp. 513–528.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[267] Y. Li, Y. Li, 和 N. Vasconcelos, “Resound：迈向无表示偏差的动作识别，” *欧洲计算机视觉会议（ECCV）论文集*，2018年，第513–528页。'
- en: '[268] M. D. Rodriguez, J. Ahmed, and M. Shah, “Action mach a spatio-temporal
    maximum average correlation height filter for action recognition,” in *2008 IEEE
    conference on computer vision and pattern recognition*.   IEEE, 2008, pp. 1–8.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[268] M. D. Rodriguez, J. Ahmed, 和 M. Shah, “Action mach：一种用于动作识别的时空最大平均相关高度滤波器，”
    *2008 IEEE计算机视觉与模式识别会议*。 IEEE，2008，第1–8页。'
- en: '[269] W. Li, Z. Zhang, and Z. Liu, “Action recognition based on a bag of 3d
    points,” in *2010 IEEE computer society conference on computer vision and pattern
    recognition-workshops*.   IEEE, 2010, pp. 9–14.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[269] W. Li, Z. Zhang, 和 Z. Liu, “基于3D点袋的动作识别，” *2010 IEEE计算机协会计算机视觉与模式识别会议-研讨会*。
    IEEE，2010，第9–14页。'
- en: '[270] J. C. Niebles, C.-W. Chen, and L. Fei-Fei, “Modeling temporal structure
    of decomposable motion segments for activity classification,” in *Computer Vision–ECCV
    2010: 11th European Conference on Computer Vision, Heraklion, Crete, Greece, September
    5-11, 2010, Proceedings, Part II 11*.   Springer, 2010, pp. 392–405.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[270] J. C. Niebles, C.-W. Chen, 和 L. Fei-Fei, “用于活动分类的可分解运动片段的时间结构建模，” *计算机视觉–ECCV
    2010：第11届欧洲计算机视觉会议，希腊克里特岛赫拉克利翁，2010年9月5-11日，会议录，第II部分 11*。 Springer，2010，第392–405页。'
- en: '[271] J. Pers, “Cvbase 06 dataset: a dataset for development and testing of
    computer vision based methods in sport environments,” *SN, Ljubljana*, 2005.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[271] J. Pers, “Cvbase 06数据集：用于运动环境中基于计算机视觉的方法开发和测试的数据集，” *SN，卢布尔雅那*，2005年。'
- en: '[272] H. Kitano, M. Asada, Y. Kuniyoshi, I. Noda, and E. Osawa, “Robocup: The
    robot world cup initiative,” in *Proceedings of the first international conference
    on Autonomous agents*, 1997, pp. 340–347.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[272] H. Kitano, M. Asada, Y. Kuniyoshi, I. Noda, 和 E. Osawa， “机器人世界杯倡议（Robocup），”
    收录于 *第一届国际自主代理人会议论文集*，1997年，第340–347页。'
- en: '[273] JiDi, “Jidi olympics football,” [https://github.com/jidiai/ai_lib/blob/master/env/olympics_football.py](https://github.com/jidiai/ai_lib/blob/master/env/olympics_football.py),
    2022.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[273] JiDi， “Jidi 奥林匹克足球，” [https://github.com/jidiai/ai_lib/blob/master/env/olympics_football.py](https://github.com/jidiai/ai_lib/blob/master/env/olympics_football.py)，2022年。'
- en: '[274] A. S. Azad, E. Kim, Q. Wu, K. Lee, I. Stoica, P. Abbeel, A. Sangiovanni-Vincentelli,
    and S. A. Seshia, “Programmatic modeling and generation of real-time strategic
    soccer environments for reinforcement learning,” in *Proceedings of the AAAI Conference
    on Artificial Intelligence*, vol. 36, no. 6, 2022, pp. 6028–6036.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[274] A. S. Azad, E. Kim, Q. Wu, K. Lee, I. Stoica, P. Abbeel, A. Sangiovanni-Vincentelli,
    和 S. A. Seshia， “实时战略足球环境的程序化建模与生成，用于强化学习，” 收录于 *AAAI 人工智能会议论文集*，第36卷，第6期，2022年，第6028–6036页。'
- en: '[275] J. Wang, J. Ma, K. Hu, Z. Zhou, H. Zhang, X. Xie, and Y. Wu, “Tac-trainer:
    A visual analytics system for iot-based racket sports training,” *IEEE Transactions
    on Visualization and Computer Graphics*, vol. 29, no. 1, pp. 951–961, 2022.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[275] J. Wang, J. Ma, K. Hu, Z. Zhou, H. Zhang, X. Xie, 和 Y. Wu， “Tac-trainer：用于基于物联网的球拍运动训练的可视分析系统，”
    *IEEE 可视化与计算机图形学学报*，第29卷，第1期，第951–961页，2022年。'
- en: '[276] Y. Liu, T. Han, S. Ma, J. Zhang, Y. Yang, J. Tian, H. He, A. Li, M. He,
    Z. Liu, Z. Wu, D. Zhu, X. Li, N. Qiang, D. Shen, T. Liu, and B. Ge, “Summary of
    chatgpt/gpt-4 research and perspective towards the future of large language models,”
    2023.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[276] Y. Liu, T. Han, S. Ma, J. Zhang, Y. Yang, J. Tian, H. He, A. Li, M. He,
    Z. Liu, Z. Wu, D. Zhu, X. Li, N. Qiang, D. Shen, T. Liu, 和 B. Ge， “ChatGPT/GPT-4
    研究总结及对大型语言模型未来的展望，” 2023年。'
- en: '[277] A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao,
    S. Whitehead, A. C. Berg, W.-Y. Lo *et al.*, “Segment anything,” *arXiv preprint
    arXiv:2304.02643*, 2023.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[277] A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T.
    Xiao, S. Whitehead, A. C. Berg, W.-Y. Lo *等*， “段落模型，” *arXiv 预印本 arXiv:2304.02643*，2023年。'
- en: '[278] R. Deng, C. Cui, Q. Liu, T. Yao, L. W. Remedios, S. Bao, B. A. Landman,
    L. E. Wheless, L. A. Coburn, K. T. Wilson *et al.*, “Segment anything model (sam)
    for digital pathology: Assess zero-shot segmentation on whole slide imaging,”
    *arXiv preprint arXiv:2304.04155*, 2023.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[278] R. Deng, C. Cui, Q. Liu, T. Yao, L. W. Remedios, S. Bao, B. A. Landman,
    L. E. Wheless, L. A. Coburn, K. T. Wilson *等*， “数字病理学的段落模型（sam）：评估全幻灯片成像的零样本分割，”
    *arXiv 预印本 arXiv:2304.04155*，2023年。'
- en: '[279] S. Roy, T. Wald, G. Koehler, M. R. Rokuss, N. Disch, J. Holzschuh, D. Zimmerer,
    and K. H. Maier-Hein, “Sam.md: Zero-shot medical image segmentation capabilities
    of the segment anything model,” 2023.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[279] S. Roy, T. Wald, G. Koehler, M. R. Rokuss, N. Disch, J. Holzschuh, D.
    Zimmerer, 和 K. H. Maier-Hein， “Sam.md：段落模型的零样本医学图像分割能力，” 2023年。'
- en: '[280] Y. Liu, J. Zhang, Z. She, A. Kheradmand, and M. Armand, “Samm (segment
    any medical model): A 3d slicer integration to sam,” 2023.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[280] Y. Liu, J. Zhang, Z. She, A. Kheradmand, 和 M. Armand， “Samm（段落任何医学模型）：与
    sam 的 3D slicer 集成，” 2023年。'
- en: '[281] J. Z. Wu, Y. Ge, X. Wang, W. Lei, Y. Gu, W. Hsu, Y. Shan, X. Qie, and
    M. Z. Shou, “Tune-a-video: One-shot tuning of image diffusion models for text-to-video
    generation,” *arXiv preprint arXiv:2212.11565*, 2022.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[281] J. Z. Wu, Y. Ge, X. Wang, W. Lei, Y. Gu, W. Hsu, Y. Shan, X. Qie, 和 M.
    Z. Shou， “Tune-a-video：用于文本到视频生成的图像扩散模型的单次调整，” *arXiv 预印本 arXiv:2212.11565*，2022年。'
- en: '[282] J. Liu, N. Saquib, Z. Chen, R. H. Kazi, L.-Y. Wei, H. Fu, and C.-L. Tai,
    “Posecoach: A customizable analysis and visualization system for video-based running
    coaching,” *IEEE Transactions on Visualization and Computer Graphics*, 2022.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[282] J. Liu, N. Saquib, Z. Chen, R. H. Kazi, L.-Y. Wei, H. Fu, 和 C.-L. Tai，
    “Posecoach：一个可定制的视频跑步教练分析与可视化系统，” *IEEE 可视化与计算机图形学学报*，2022年。'
- en: '[283] Z. Zhao, S. Lan, and S. Zhang, “Human pose estimation based speed detection
    system for running on treadmill,” in *2020 International Conference on Culture-oriented
    Science & Technology (ICCST)*.   IEEE, 2020, pp. 524–528.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[283] Z. Zhao, S. Lan, 和 S. Zhang， “基于人体姿态估计的跑步速度检测系统，” 收录于 *2020 年国际文化导向科学与技术大会（ICCST）*，IEEE，2020年，第524–528页。'
- en: '[284] T. Perrett, A. Masullo, D. Damen, T. Burghardt, I. Craddock, M. Mirmehdi
    *et al.*, “Personalized energy expenditure estimation: Visual sensing approach
    with deep learning,” *JMIR Formative Research*, vol. 6, no. 9, p. e33606, 2022.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[284] T. Perrett, A. Masullo, D. Damen, T. Burghardt, I. Craddock, M. Mirmehdi
    *等*， “个性化能量消耗估计：基于深度学习的视觉传感方法，” *JMIR 形成研究*，第6卷，第9期，第e33606页，2022年。'
- en: '[285] D. Radke and A. Orchard, “Presenting multiagent challenges in team sports
    analytics,” *arXiv preprint arXiv:2303.13660*, 2023.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[285] D. Radke 和 A. Orchard, “在团队运动分析中展示多智能体挑战，” *arXiv预印本 arXiv:2303.13660*,
    2023.'
- en: '| ![[Uncaptioned image]](img/e3e35a4dc251244cb834c132cc3d44c3.png) | Zhonghan
    Zhao received the BE degree from Communication University of China. He is currently
    working toward the PhD degree with Zhejiang University - University of Illinois
    Urbana-Champaign Institute, Zhejiang University. His research interests include
    machine learning, reinforcement learning and computer vision. |'
  id: totrans-527
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/e3e35a4dc251244cb834c132cc3d44c3.png) | Zhonghan Zhao获得了中国传媒大学的工程学学士学位。他目前在浙江大学
    - 伊利诺伊大学厄本那-香槟分校研究所攻读博士学位。他的研究兴趣包括机器学习、强化学习和计算机视觉。 |'
- en: '| ![[Uncaptioned image]](img/a8962ea6e37107d6452d0a4eeb074573.png) | Wenhao
    Chai received the BE degree from Zhejiang University, China. He is currently working
    toward the Master degree with University of Washington. His research interests
    include 3D human pose estimation, generative models, and multi-modality learning.
    |'
  id: totrans-528
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/a8962ea6e37107d6452d0a4eeb074573.png) | Wenhao Chai获得了中国浙江大学的工程学学士学位。他目前在华盛顿大学攻读硕士学位。他的研究兴趣包括3D人体姿态估计、生成模型和多模态学习。
    |'
- en: '| ![[Uncaptioned image]](img/1e030cae72b5aa1134fc41705d7cc71d.png) | Shengyu
    Hao received the MS degree from Beijing University of Posts and Telecommunications,
    China. He is currently working toward the PhD degree with Zhejiang University
    - University of Illinois Urbana-Champaign Institute, Zhejiang University. His
    research interests include machine learning and computer vision. |'
  id: totrans-529
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/1e030cae72b5aa1134fc41705d7cc71d.png) | Shengyu Hao获得了中国北京邮电大学的硕士学位。他目前在浙江大学
    - 伊利诺伊大学厄本那-香槟分校研究所攻读博士学位。他的研究兴趣包括机器学习和计算机视觉。 |'
- en: '| ![[Uncaptioned image]](img/af15d2a48b892b899b4ca4d7ace2733d.png) | Wenhao
    Hu received the BS degree from Zhejiang University, China. He is currently working
    toward the PhD degree with Zhejiang University - University of Illinois Urbana-Champaign
    Institute, Zhejiang University. His research interests include generative models
    and 3D reconstruction. |'
  id: totrans-530
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/af15d2a48b892b899b4ca4d7ace2733d.png) | Wenhao Hu获得了中国浙江大学的学士学位。他目前在浙江大学
    - 伊利诺伊大学厄本那-香槟分校研究所攻读博士学位。他的研究兴趣包括生成模型和3D重建。 |'
- en: '| ![[Uncaptioned image]](img/e726629c3d345296e8f25fba6b8e280e.png) | Guanhong
    Wang received the MS degree from Huaqiao University, China. He is currently working
    toward the PhD degree with Zhejiang University - University of Illinois Urbana-Champaign
    Institute, Zhejiang University. His research interests include deep learning and
    computer vision. |'
  id: totrans-531
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/e726629c3d345296e8f25fba6b8e280e.png) | Guanhong Wang获得了中国华侨大学的硕士学位。他目前在浙江大学
    - 伊利诺伊大学厄本那-香槟分校研究所攻读博士学位。他的研究兴趣包括深度学习和计算机视觉。 |'
- en: '| ![[Uncaptioned image]](img/c1fd100fca92a70ef43352d191aeb8ca.png) | Shidong
    Cao received the BE degree from Beijing University of Posts and Telecommunications,
    China. He is currently working toward the MS degree with Zhejiang University -
    University of Illinois Urbana-Champaign Institute, Zhejiang University. His research
    interests include machine learning and computer vision. |'
  id: totrans-532
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/c1fd100fca92a70ef43352d191aeb8ca.png) | Shidong Cao获得了中国北京邮电大学的工程学学士学位。他目前在浙江大学
    - 伊利诺伊大学厄本那-香槟分校研究所攻读硕士学位。他的研究兴趣包括机器学习和计算机视觉。 |'
- en: '| ![[Uncaptioned image]](img/a2bc393c22001d189efb41dfc9216792.png) | Dr. Mingli
    Song received the Ph.D. degree in computer science from Zhejiang University, China,
    in 2006\. He is currently a Professor with the Microsoft Visual Perception Laboratory,
    Zhejiang University. His research interests include face modeling and facial expression
    analysis. He received the Microsoft Research Fellowship in 2004. |'
  id: totrans-533
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/a2bc393c22001d189efb41dfc9216792.png) | Dr. Mingli Song获得了2006年浙江大学计算机科学博士学位。他目前是浙江大学微软视觉感知实验室的教授。他的研究兴趣包括面部建模和面部表情分析。他于2004年获得了微软研究院奖学金。
    |'
- en: '| ![[Uncaptioned image]](img/92bf0a7ae7ba6d334e70570b31bf8cbe.png) | Dr. Jenq-Neng
    Hwang received the BS and MS degrees, both in electrical engineering from the
    National Taiwan University, Taipei, Taiwan, in 1981 and 1983 separately. He then
    received his Ph.D. degree from the University of Southern California. In the summer
    of 1989, Dr. Hwang joined the Department of Electrical and Computer Engineering
    (ECE) of the University of Washington in Seattle, where he has been promoted to
    Full Professor since 1999\. He is the Director of the Information Processing Lab.
    (IPL), which has won several AI City Challenges and BMTT Tracking awards in the
    past years. Dr. Hwang served as associate editors for IEEE T-SP, T-NN and T-CSVT,
    T-IP and Signal Processing Magazine (SPM). He was the General Co-Chair of 2021
    IEEE World AI IoT Congress, as well as the program Co-Chairs of IEEE ICME 2016,
    ICASSP 1998 and ISCAS 2009\. Dr. Hwang is a fellow of IEEE since 2001. |'
  id: totrans-534
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图像]](img/92bf0a7ae7ba6d334e70570b31bf8cbe.png) | **黄正能**于1981年和1983年分别获得国立台湾大学电机工程学士和硕士学位。随后，他在南加州大学获得博士学位。1989年夏季，**黄正能**加入了华盛顿大学西雅图分校电气与计算机工程系（ECE），自1999年起被晋升为正教授。他是信息处理实验室（IPL）的主任，该实验室在过去几年中赢得了多个AI城市挑战和BMTT跟踪奖。**黄正能**曾担任IEEE
    T-SP、T-NN和T-CSVT、T-IP及信号处理杂志（SPM）的副主编。他曾担任2021 IEEE世界人工智能物联网大会的总主席，以及IEEE ICME
    2016、ICASSP 1998和ISCAS 2009的程序主席。**黄正能**自2001年起成为IEEE会士。'
- en: '| ![[Uncaptioned image]](img/41ee22a3181a375e14cf1fe7a3b16c84.png) | Dr. Gaoang
    Wang joined the international campus of Zhejiang University as an Assistant Professor
    in September 2020\. He is also an Adjunct Assistant Professor at UIUC. Gaoang
    Wang received a B.S. degree at Fudan University in 2013, a M.S. degree at the
    University of Wisconsin-Madison in 2015, and a Ph.D. degree from the Information
    Processing Laboratory of the Electrical and Computer Engineering department at
    the University of Washington in 2019\. After that, he joined Megvii US office
    in July 2019 as a research scientist working on multi-frame fusion. He then joined
    Wyze Labs in November 2019 working on deep neural network design for edge-cloud
    collaboration. His research interests are computer vision, machine learning, artificial
    intelligence, including multi-object tracking, representation learning, and active
    learning. Gaoang Wang published papers in many renowned journals and conferences,
    including IEEE T-IP, IEEE T-MM, IEEE T-CSVT, IEEE T-VT, CVPR, ICCV, ECCV, ACM
    MM, IJCAI. |'
  id: totrans-535
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图像]](img/41ee22a3181a375e14cf1fe7a3b16c84.png) | **高昂·王**于2020年9月加入浙江大学国际校区担任助理教授。他也是UIUC的兼职助理教授。**高昂·王**于2013年在复旦大学获得学士学位，2015年在威斯康星大学麦迪逊分校获得硕士学位，2019年在华盛顿大学电气与计算机工程系的信息处理实验室获得博士学位。之后，他于2019年7月加入Megvii美国办公室，担任研究科学家，主要研究多帧融合技术。随后，他于2019年11月加入Wyze
    Labs，致力于边缘云协作的深度神经网络设计。他的研究兴趣包括计算机视觉、机器学习和人工智能，涉及多目标跟踪、表征学习和主动学习等领域。**高昂·王**在许多著名期刊和会议上发表了论文，包括IEEE
    T-IP、IEEE T-MM、IEEE T-CSVT、IEEE T-VT、CVPR、ICCV、ECCV、ACM MM、IJCAI。 |'
