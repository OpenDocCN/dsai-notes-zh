- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '分类: 未分类'
- en: 'date: 2024-09-06 20:02:14'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 20:02:14'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2002.12478] Time Series Data Augmentation for Deep Learning: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2002.12478] 时间序列数据增强用于深度学习：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2002.12478](https://ar5iv.labs.arxiv.org/html/2002.12478)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2002.12478](https://ar5iv.labs.arxiv.org/html/2002.12478)
- en: 'Time Series Data Augmentation for Deep Learning: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列数据增强用于深度学习：综述
- en: Qingsong Wen¹, Liang Sun¹, Fan Yang², Xiaomin Song¹, Jingkun Gao³¹¹1The work
    was done when Jingkun Gao was at Alibaba Group., Xue Wang¹, Huan Xu² ¹DAMO Academy,
    Alibaba Group, Bellevue, WA, USA
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Qingsong Wen¹, Liang Sun¹, Fan Yang², Xiaomin Song¹, Jingkun Gao³¹¹1此项工作是在 Jingkun
    Gao 在阿里巴巴集团期间完成的。, Xue Wang¹, Huan Xu² ¹DAMO 学院，阿里巴巴集团，美国华盛顿州贝尔维尤
- en: ²Alibaba Group, Hangzhou, China
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ²阿里巴巴集团，中国杭州
- en: ³Twitter, Seattle, WA, USA {qingsong.wen, liang.sun, fanyang.yf, xiaomin.song,
    xue.w, huan.xu}@alibaba-inc.com, jingkung@twitter.com
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ³Twitter，美国华盛顿州西雅图 {qingsong.wen, liang.sun, fanyang.yf, xiaomin.song, xue.w,
    huan.xu}@alibaba-inc.com, jingkung@twitter.com
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep learning performs remarkably well on many time series analysis tasks recently.
    The superior performance of deep neural networks relies heavily on a large number
    of training data to avoid overfitting. However, the labeled data of many real-world
    time series applications may be limited such as classification in medical time
    series and anomaly detection in AIOps. As an effective way to enhance the size
    and quality of the training data, data augmentation is crucial to the successful
    application of deep learning models on time series data. In this paper, we systematically
    review different data augmentation methods for time series. We propose a taxonomy
    for the reviewed methods, and then provide a structured review for these methods
    by highlighting their strengths and limitations. We also empirically compare different
    data augmentation methods for different tasks including time series classification,
    anomaly detection, and forecasting. Finally, we discuss and highlight five future
    directions to provide useful research guidance.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在许多时间序列分析任务中表现出色。深度神经网络的卓越性能在很大程度上依赖于大量的训练数据以避免过拟合。然而，许多现实世界的时间序列应用的标记数据可能有限，例如医学时间序列中的分类和
    AIOps 中的异常检测。作为增强训练数据大小和质量的有效方式，数据增强对深度学习模型在时间序列数据上的成功应用至关重要。在本文中，我们系统地回顾了不同的时间序列数据增强方法。我们提出了一种对所评审方法的分类法，然后通过突出其优点和局限性来提供结构化的回顾。我们还对不同任务（包括时间序列分类、异常检测和预测）中的不同数据增强方法进行了实证比较。最后，我们讨论并强调了五个未来方向，以提供有用的研究指导。
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Deep learning has achieved remarkable success in many fields, including computer
    vision (CV), natural language processing (NLP), and speech processing, etc. Recently,
    it is increasingly embraced for solving time series related tasks, including time
    series classification Fawaz et al. ([2019](#bib.bib16)), time series forecasting Han
    et al. ([2019](#bib.bib23)), and time series anomaly detection Gamboa ([2017](#bib.bib20)).
    The success of deep learning relies heavily on a large number of training data
    to avoid overfitting. Unfortunately, many time series tasks do not have enough
    labeled data. As an effective tool to enhance the size and quality of the training
    data, data augmentation is crucial to the successful application of deep learning
    models. The basic idea of data augmentation is to generate synthetic dataset covering
    unexplored input space while maintaining correct labels. Data augmentation has
    shown its effectiveness in many applications, such as AlexNet Krizhevsky et al.
    ([2012](#bib.bib32)) for ImageNet classification.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在许多领域取得了显著成功，包括计算机视觉 (CV)、自然语言处理 (NLP) 和语音处理等。最近，它越来越被用于解决与时间序列相关的任务，包括时间序列分类
    Fawaz 等人 ([2019](#bib.bib16))、时间序列预测 Han 等人 ([2019](#bib.bib23)) 和时间序列异常检测 Gamboa
    ([2017](#bib.bib20))。深度学习的成功在很大程度上依赖于大量的训练数据，以避免过拟合。不幸的是，许多时间序列任务没有足够的标记数据。作为一种有效的工具来增强训练数据的大小和质量，数据增强对深度学习模型的成功应用至关重要。数据增强的基本思想是生成涵盖未探索输入空间的合成数据集，同时保持正确的标签。数据增强在许多应用中显示了其有效性，例如用于
    ImageNet 分类的 AlexNet Krizhevsky 等人 ([2012](#bib.bib32))。
- en: However, less attention has been paid to find better data augmentation methods
    specifically for time series data. Here we highlight some challenges arising from
    data augmentation methods for time series data. Firstly, the intrinsic properties
    of time series data are not fully utilized in current data augmentation methods.
    One unique property of time series data is the so-called temporal dependency.
    Unlike image data, the time series data can be transformed into the frequency
    and time-frequency domains and effective data augmentation methods can be designed
    and implemented in the transformed domain. This becomes more complicated when
    we model multivariate time series where we need to consider the potentially complex
    dynamics of these variables across time. Thus, simply applying those data augmentation
    methods from image and speech processing may not result in valid synthetic data.
    Secondly, the data augmentation methods are also task dependent. For example,
    the data augmentation methods applicable for time series classification may not
    be valid for time series anomaly detection. In addition, data augmentation becomes
    more crucial in many time series classification problems where class imbalance
    is often observed. In this case, how to effective generate a large number of synthetic
    data with labels with less samples remains a challenge.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于针对时间序列数据的更好的数据增强方法的研究还得到较少关注。我们在这里强调了一些由于时间序列数据的数据增强方法而产生的挑战。首先，目前的数据增强方法没有充分利用时间序列数据的内在特性。时间序列数据的一个独特属性是所谓的时间依赖性。与图像数据不同，时间序列数据可以转换为频率和时频域，并且可以在转换域中设计和实施有效的数据增强方法。当我们对多变量时间序列建模时，这变得更加复杂，我们需要考虑这些变量在时间上的潜在复杂动态。因此，仅仅应用图像和语音处理中的那些数据增强方法可能无法生成有效的合成数据。其次，数据增强方法还取决于具体任务。例如，适用于时间序列分类的数据增强方法可能不适用于时间序列异常检测。此外，在许多时间序列分类问题中，数据增强变得更加重要，因为通常观察到类别不平衡的情况。在这种情况下，如何有效地生成具有较少样本标签的大量合成数据仍然是一个挑战。
- en: Unlike data augmentation for CV Shorten and Khoshgoftaar ([2019](#bib.bib48))
    or speech Cui et al. ([2015](#bib.bib9)), data augmentation for time series has
    not yet been comprehensively and systematically reviewed to the best of our knowledge.
    One work closely related to ours is Iwana and Uchida ([2020](#bib.bib27)) which
    presents a survey of existing data augmentation methods for time series classification.
    However, it does not review the data augmentation methods for other common tasks
    like time series forecasting Bandara et al. ([2020](#bib.bib2)); Hu et al. ([2020](#bib.bib26));
    Lee and Kim ([2020](#bib.bib35)) and anomaly detection Lim et al. ([2018](#bib.bib37));
    Zhou et al. ([2019](#bib.bib61)); Gao et al. ([2020](#bib.bib21)). Furthermore,
    the potential avenues for future research opportunities of time series data augmentations
    are also missing.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，与我们最了解的情况相比，目前还没有全面系统地对时间序列的数据增强进行综述。与我们紧密相关的一项工作是Iwana和Uchida（[2020](#bib.bib27)），该工作对现有的时间序列分类数据增强方法进行了调查。然而，它没有回顾其他常见任务的数据增强方法，比如时间序列预测Bandara等人（[2020](#bib.bib2)）；胡等人（[2020](#bib.bib26)）；李和金（[2020](#bib.bib35)）和异常检测Lim等人（[2018](#bib.bib37)）；周等人（[2019](#bib.bib61)）；高等人（[2020](#bib.bib21)）。此外，关于时间序列数据增强的未来研究机会的潜在途径也没有被提及。
- en: 'In this paper, we aim to fill the aforementioned gaps by summarizing existing
    time series data augmentation methods in common tasks, including time series forecasting,
    anomaly detection, classification, as well as providing insightful future directions.
    To this end, we propose a taxonomy of data augmentation methods for time series,
    as illustrated in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Time Series Data
    Augmentation for Deep Learning: A Survey"). Based on the taxonomy, we review these
    data augmentation methods systematically. We start the discussion from the simple
    transformations in time domain first. And then we discuss more transformations
    on time series in the transformed frequency and time-frequency domains. Besides
    the transformations in different domains for time series, we also summarize more
    advanced methods, including decomposition-based methods, model-based methods,
    and learning-based methods. For learning-based methods, we further divide them
    into embedding space, deep generative models (DGMs), and automated data augmentation
    methods. To demonstrate effectiveness of data augmentation, we conduct preliminary
    evaluation of augmentation methods in three typical time series tasks, including
    time series classification, anomaly detection, and forecasting. Finally, we discuss
    and highlight five future directions: augmentation in time-frequency domain, augmentation
    for imbalanced class, augmentation selection and combination, augmentation with
    Gaussian processes, and augmentation with deep generative models.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在通过总结现有的时间序列数据增强方法，填补上述空白，包括时间序列预测、异常检测、分类等常见任务，并提供有价值的未来方向。为此，我们提出了时间序列数据增强方法的分类，如图[1](#S1.F1
    "图 1 ‣ 1 引言 ‣ 深度学习中的时间序列数据增强：综述")所示。基于这一分类，我们系统地回顾了这些数据增强方法。我们首先讨论时间域中的简单变换。然后我们讨论在变换后的频率域和时间-频率域中对时间序列的更多变换。除了不同领域中的时间序列变换，我们还总结了更先进的方法，包括基于分解的方法、基于模型的方法和基于学习的方法。对于基于学习的方法，我们进一步将其划分为嵌入空间、深度生成模型（DGMs）和自动数据增强方法。为了展示数据增强的有效性，我们对三种典型时间序列任务中的增强方法进行了初步评估，包括时间序列分类、异常检测和预测。最后，我们讨论并突出五个未来方向：时间-频率域中的增强、不平衡类别的增强、增强选择与组合、基于高斯过程的增强，以及基于深度生成模型的增强。
- en: '![Refer to caption](img/4042f0e5fd2fda5151e9266e0142e481.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题说明](img/4042f0e5fd2fda5151e9266e0142e481.png)'
- en: 'Figure 1: A taxonomy of time series data augmentation techniques.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：时间序列数据增强技术的分类。
- en: 2 Basic Data Augmentation Methods
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 基本数据增强方法
- en: 2.1 Time Domain
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 时间域
- en: The transforms in the time domain are the most straightforward data augmentation
    methods for time series data. Most of them manipulate the original input time
    series directly, like injecting Gaussian noise or more complicated noise patterns
    such as spike, step-like trend, and slope-like trend. Besides this straightforward
    methods, we will also discuss a particular data augmentation method for time series
    anomaly detection, i.e., label expansion in the time domain.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 时间域中的变换是时间序列数据最直接的数据增强方法。它们大多数直接操作原始输入时间序列，例如注入高斯噪声或更复杂的噪声模式，如脉冲、阶跃式趋势和斜坡式趋势。除了这些直接的方法，我们还将讨论一种用于时间序列异常检测的特定数据增强方法，即时间域中的标签扩展。
- en: Window cropping or slicing has been mentioned in  Le Guennec et al. ([2016](#bib.bib34)).
    Introduced in  Cui et al. ([2016](#bib.bib10)), window cropping is similar to
    cropping in CV area. It is a sub-sample method to randomly extract continuous
    slices from the original time series. The length of the slice is a tunable parameter.
    For classification problem, the labels of sliced samples are the same as the original
    time series. During test time, each slice from a test time series is classified
    using majority voting. For anomaly detection problem, the anomaly label will be
    sliced along with value series.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口裁剪或切片在 Le Guennec 等人（[2016](#bib.bib34)）的研究中已有提及。Cui 等人（[2016](#bib.bib10)）引入了窗口裁剪，这与计算机视觉领域的裁剪类似。这是一种子样本方法，通过从原始时间序列中随机提取连续片段来实现。片段的长度是一个可调参数。对于分类问题，切片样本的标签与原始时间序列相同。在测试时，每个测试时间序列的切片通过多数投票进行分类。对于异常检测问题，异常标签将与值序列一起被切片。
- en: Window warping is a unique augmentation method for time series. Similar to dynamic
    time warping (DTW), this method selects a random time range, then compresses (down
    sample) or extends (up sample) it, while keeps other time range unchanged. Window
    warping would change the total length of the original time series, so it should
    be conducted along with window cropping for deep learning models. This method
    contains the normal down sampling which takes down sample through the whole length
    of the original time series.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口扭曲是一种独特的时间序列数据增强方法。类似于动态时间规整（DTW），该方法选择一个随机时间范围，然后对其进行压缩（下采样）或扩展（上采样），同时保持其他时间范围不变。窗口扭曲会改变原始时间序列的总长度，因此应该与窗口裁剪一起进行，以便用于深度学习模型。该方法包含了正常的下采样，通过原始时间序列的整个长度进行下采样。
- en: Flipping is another method that generates the new sequence $x^{{}^{\prime}}_{1},\cdots,x^{{}^{\prime}}_{N}$
    by flipping the sign of original time series $x_{1},\cdots,x_{N}$, where $x^{{}^{\prime}}_{t}=-x_{t}$.
    The labels are still the same, for both anomaly detection and classification,
    assuming that we have symmetry between up and down directions.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 翻转是另一种方法，通过翻转原始时间序列 $x_{1},\cdots,x_{N}$ 的符号来生成新的序列 $x^{{}^{\prime}}_{1},\cdots,x^{{}^{\prime}}_{N}$，其中
    $x^{{}^{\prime}}_{t}=-x_{t}$。标签仍然保持不变，对于异常检测和分类都适用，假设上下方向之间存在对称性。
- en: Another interesting perturbation and also ensemble based method is introduced
    in  Fawaz et al. ([2018](#bib.bib15)). This method generates new time series with
    DTW and then ensembles them by a weighted version of the Barycentric Averaging
    (DBA) algorithm. It shows improvement of classification in some of the UCR datasets.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Fawaz 等人 ([2018](#bib.bib15)) 引入了另一种有趣的扰动和集成方法。该方法通过动态时间规整（DTW）生成新的时间序列，然后使用加权版本的重心平均（DBA）算法对它们进行集成。这在一些
    UCR 数据集中显示了分类性能的提升。
- en: Noise injection is a method by injecting small amount of noise/outlier into
    time series without changing the corresponding labels. This includes injecting
    Gaussian noise, spike, step-like trend, and slope-like trend, etc. For spike,
    we can randomly pick index and direction, randomly assign magnitude but bounded
    by multiples of standard deviation of the original time series. For step-like
    trend, it is the cumulative summation of the spikes from left index to right index.
    The slope-like trend is adding a linear trend into the original time series. These
    schemes are mostly mentioned in Wen and Keyes ([2019](#bib.bib54))
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声注入是一种通过将少量噪声/异常值注入时间序列而不改变对应标签的方法。这包括注入高斯噪声、尖峰、阶跃趋势和斜率趋势等。对于尖峰，我们可以随机选择索引和方向，随机分配幅度，但幅度以原始时间序列标准差的倍数为界。对于阶跃趋势，它是从左索引到右索引的尖峰的累积和。斜率趋势是将线性趋势添加到原始时间序列中。这些方案大多在
    Wen 和 Keyes ([2019](#bib.bib54)) 中提到。
- en: In time series anomaly detection, the anomalies generally last long enough during
    a continuous span so that the start and end points are sometimes “blurry”. As
    a result, a data point close to a labeled anomaly in terms of both time distance
    and value distance is very likely to be an anomaly. In this case, the label expansion
    method is proposed to change those data points and their labels as anomalies (by
    assign it an anomaly score or switch its label), which brings performance improvement
    for time series anomaly detection as shown in Gao et al. ([2020](#bib.bib21)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列异常检测中，异常通常在连续区间内持续较长时间，因此起始点和结束点有时会“模糊”。因此，靠近标记异常的数据点，无论是在时间距离还是数值距离上，都很可能是异常。在这种情况下，提出了标签扩展方法，以将这些数据点及其标签更改为异常（通过分配异常分数或切换其标签），这提高了时间序列异常检测的性能，如
    Gao 等人 ([2020](#bib.bib21)) 所示。
- en: 2.2 Frequency Domain
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 频域
- en: While most of the existing data augmentation methods focus on time domain, only
    a few studies investigate data augmentation from frequency domain perspective
    for time series.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然大多数现有的数据增强方法集中于时间域，但只有少数研究从频域角度探讨了时间序列的数据增强。
- en: 'A recent work in Gao et al. ([2020](#bib.bib21)) proposes to utilize perturbations
    in both amplitude spectrum and phase spectrum in frequency domain for data augmentation
    in time series anomaly detection by convolutional neural network. Specifically,
    for the input time series $x_{1},\cdots,x_{N}$, its frequency spectrum $F(\omega_{k})$
    through Fourier transform is calculated as:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Gao 等人 ([2020](#bib.bib21)) 的最新工作建议在频域中利用幅度谱和相位谱的扰动来进行时间序列异常检测的数据增强，使用卷积神经网络。具体来说，对于输入时间序列
    $x_{1},\cdots,x_{N}$，其通过傅里叶变换得到的频谱 $F(\omega_{k})$ 被计算如下：
- en: '|  | $\displaystyle F(\omega_{k})\!=\!\frac{1}{{N}}\!\!\sum_{t=0}^{N-1}\!x_{t}e^{-j\omega_{k}t}\
    =A(\omega_{k})\exp[j\theta(\omega_{k})]$ |  | (1) |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle F(\omega_{k})\!=\!\frac{1}{{N}}\!\!\sum_{t=0}^{N-1}\!x_{t}e^{-j\omega_{k}t}\
    =A(\omega_{k})\exp[j\theta(\omega_{k})]$ |  | (1) |'
- en: where $\omega_{k}=\frac{2\pi k}{N}$ is the angular frequency, $A(\omega_{k})$
    is the amplitude spectrum, and $\theta(\omega_{k})$ is the phase spectrum. For
    perturbations in amplitude spectrum $A(\omega_{k})$, the amplitude values of randomly
    selected segments are replaced with Gaussian noise by considering the original
    mean and variance in the amplitude spectrum. While for perturbations in phase
    spectrum $\theta(\omega_{k})$, the phase values of randomly selected segments
    are added by an extra zero-mean Gaussian noise in the phase spectrum. The amplitude
    and phase perturbations (APP) based data augmentation combined with aforementioned
    time-domain augmentation methods bring significant time series anomaly detection
    improvements as shown in the experiments of Gao et al. ([2020](#bib.bib21)).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\omega_{k}=\frac{2\pi k}{N}$是角频率，$A(\omega_{k})$是幅度谱，$\theta(\omega_{k})$是相位谱。对于幅度谱$A(\omega_{k})$的扰动，通过考虑幅度谱中的原始均值和方差，将随机选择段的幅度值替换为高斯噪声。而对于相位谱$\theta(\omega_{k})$的扰动，则在相位谱中向随机选择段的相位值添加额外的零均值高斯噪声。幅度和相位扰动（APP）结合前述的时域增强方法在时间序列异常检测中带来了显著的改进，如Gao等人（[2020](#bib.bib21)）的实验所示。
- en: 'Another recent work in Lee et al. ([2019](#bib.bib36)) proposes to utilize
    the surrogate data to improve the classification performance of rehabilitative
    time series in deep neural network. Two conventional types of surrogate time series
    are adopted in the work: the amplitude adjusted Fourier transform (AAFT) and the
    iterated AAFT (IAAFT) Schreiber and Schmitz ([2000](#bib.bib47)). The main idea
    is to perform random phase shuffle in phase spectrum after Fourier transform and
    then perform rank-ordering of time series after inverse Fourier transform. The
    generated time series from AAFT and IAAFT can approximately preserve the temporal
    correlation, power spectra, and the amplitude distribution of the original time
    series. In the experiments of Lee et al. ([2019](#bib.bib36)), the authors conducted
    two types of data augmentation by extending the data by 10 then 100 times through
    AAFT and IAAFT methods, and demonstrated promising classification accuracy improvements
    compared to the original time series without data augmentation.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一项近期的工作由Lee等人（[2019](#bib.bib36)）提出，利用替代数据来提高深度神经网络中康复时间序列的分类性能。工作中采用了两种常见的替代时间序列类型：幅度调整傅里叶变换（AAFT）和迭代AAFT（IAAFT）Schreiber和Schmitz（[2000](#bib.bib47)）。其主要思想是在傅里叶变换后对相位谱进行随机相位洗牌，然后在逆傅里叶变换后对时间序列进行排名。由AAFT和IAAFT生成的时间序列可以大致保持原始时间序列的时间相关性、功率谱和幅度分布。在Lee等人（[2019](#bib.bib36)）的实验中，作者通过AAFT和IAAFT方法将数据扩展10倍和100倍，并展示了相比于未增强的数据原始时间序列的分类准确性改进。
- en: 2.3 Time-Frequency Domain
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 时间-频率域
- en: Time-frequency analysis is a widely applied technique for time series analysis,
    which can be utilized as an appropriate input features in deep neural networks.
    However, similar to data augmentation in frequency domain, only a few studies
    considered data augmentation from time-frequency domain for time series.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 时间-频率分析是一种广泛应用于时间序列分析的技术，可以作为深度神经网络中的合适输入特征。然而，类似于频率域的数据增强，只有少数研究考虑了时间-频率域的数据增强。
- en: The authors in Steven Eyobu and Han ([2018](#bib.bib50)) adopt short Fourier
    transform (STFT) to generate time-frequency features for sensor time series, and
    conduct data augmentation on the time-frequency features for human activity classification
    by a deep LSTM neural network. Specifically, two augmentation techniques are proposed.
    One is the local averaging based on a defined criteria with the generated features
    appended at the tail end of the feature set. Another is the shuffling of feature
    vectors to create variation in the data. Similarly, in speech time series, recently
    SpecAugment Park et al. ([2019](#bib.bib39)) is proposed to make data augmentation
    in Mel-Frequency (a time-frequency representation based on STFT for speech time
    series), where the augmentation scheme consists of warping the features, masking
    blocks of frequency channels, and masking blocks of time steps. They demonstrate
    that SpecAugment can greatly improve the performance of speech recognition neural
    networks and obtain state-of-the-art results.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Steven Eyobu和Han（[2018](#bib.bib50)）采用短时傅里叶变换（STFT）生成传感器时间序列的时间-频率特征，并对这些特征进行数据增强，以便通过深度LSTM神经网络进行人体活动分类。具体而言，提出了两种增强技术。一种是基于定义标准的局部平均，生成的特征附加在特征集的尾部。另一种是特征向量的洗牌，以在数据中创建变化。类似地，在语音时间序列中，最近提出的SpecAugment
    Park等（[2019](#bib.bib39)）用于在Mel-Frequency（基于STFT的语音时间序列时间-频率表示）中进行数据增强，其中增强方案包括特征扭曲、屏蔽频率通道的块以及屏蔽时间步长的块。他们展示了SpecAugment可以显著提高语音识别神经网络的性能，并获得了最先进的结果。
- en: 'For illustration, we summarize several typical time series data augmentation
    methods in time, frequency, and time-frequency domains in Fig. [2](#S2.F2 "Figure
    2 ‣ 2.3 Time-Frequency Domain ‣ 2 Basic Data Augmentation Methods ‣ Time Series
    Data Augmentation for Deep Learning: A Survey").'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '为了说明，我们总结了图[2](#S2.F2 "Figure 2 ‣ 2.3 Time-Frequency Domain ‣ 2 Basic Data
    Augmentation Methods ‣ Time Series Data Augmentation for Deep Learning: A Survey")中时间、频率和时间-频率域中几种典型的时间序列数据增强方法。'
- en: '![Refer to caption](img/b5109805a7194b1647331e6d4d73de64.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b5109805a7194b1647331e6d4d73de64.png)'
- en: (a) time domain
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 时间域
- en: '![Refer to caption](img/2a303c0c8038e87a71c71f8f5c7a4b6d.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2a303c0c8038e87a71c71f8f5c7a4b6d.png)'
- en: (b) (time-)frequency domain
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: (b) （时间-）频率域
- en: 'Figure 2: Illustration of several typical time series data augmentations in
    time, frequency, and time-frequency domains.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：时间、频率和时间-频率域中几种典型时间序列数据增强的说明。
- en: 3 Advanced Data Augmentation Methods
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 高级数据增强方法
- en: 3.1 Decomposition-based Methods
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 基于分解的方法
- en: Decomposition-based time series augmentation has also been adopted and shown
    success in many time series related tasks, such as forecasting and anomaly detection.
    Common decomposition method like STL Cleveland et al. ([1990](#bib.bib6)) or RobustSTL Wen
    et al. ([2019b](#bib.bib56)) decomposes time series $x_{t}$ as
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 基于分解的时间序列增强方法也已被采用，并在许多与时间序列相关的任务中取得了成功，如预测和异常检测。常见的分解方法如STL Cleveland等（[1990](#bib.bib6)）或RobustSTL
    Wen等（[2019b](#bib.bib56)）将时间序列$x_{t}$分解为
- en: '|  | $x_{t}=\tau_{t}+s_{t}+r_{t},\quad t=1,2,...N$ |  | (2) |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '|  | $x_{t}=\tau_{t}+s_{t}+r_{t},\quad t=1,2,...N$ |  | (2) |'
- en: where $\tau_{t}$ is the trend signal, $s_{t}$ is the seasonal/periodic signal,
    and the $r_{t}$ denotes the remainder signal.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\tau_{t}$是趋势信号，$s_{t}$是季节性/周期性信号，$r_{t}$表示剩余信号。
- en: In Kegel et al. ([2018](#bib.bib29)), authors discussed the decomposition method
    to generate new time series. After STL, it recombines new time series with a deterministic
    component and a stochastic component. The deterministic part is reconstructed
    by adjusting weights for base, trend, and seasonality. The stochastic part is
    generated by building a composite statistical model based on residual, such as
    an auto-regressive model. The summed generated time series is validated by examining
    whether a feature-based distance to its original signal is within certain range.
    Meanwhile, authors in Bergmeir et al. ([2016](#bib.bib3)) proposed to apply bootstrapping
    on the STL decomposed residuals to generate augmented signals, which are then
    added back with trend and seasonality to assemble a new time series. An ensemble
    of the forecasting models on the augmented time series has outperformed the original
    forecasting model consistently, demonstrating the effectiveness of decomposition-based
    time series augmentation approaches.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kegel等人（[2018](#bib.bib29)）的研究中，作者讨论了生成新时间序列的分解方法。经过STL处理后，它将新的时间序列与确定性组件和随机组件重新组合。确定性部分通过调整基础、趋势和季节性的权重进行重建。随机部分则通过基于残差建立的复合统计模型生成，例如自回归模型。生成的时间序列通过检查与原始信号的特征基础距离是否在一定范围内进行验证。同时，Bergmeir等人（[2016](#bib.bib3)）提出对STL分解残差应用自助法以生成增广信号，然后将其与趋势和季节性重新组合以组装新的时间序列。在增广时间序列上的预测模型集成相比于原始预测模型表现更好，展示了基于分解的时间序列增广方法的有效性。
- en: Recently, in Gao et al. ([2020](#bib.bib21)), authors showed that applying time-domain
    and frequency-domain augmentation on the decomposed residual that is generated
    using robust decomposition Wen et al. ([2020](#bib.bib57), [2019a](#bib.bib55))
    can help increase the performance of anomaly detection significantly, compared
    with the same method without augmentation.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，在Gao等人（[2020](#bib.bib21)）的研究中，作者展示了将时间域和频率域增广应用于通过稳健分解方法生成的分解残差，可以显著提高异常检测的性能，相比于没有增广的相同方法。
- en: 3.2 Statistical Generative Models
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 统计生成模型
- en: Time series augmentation approaches based on statistical generative models typically
    involve modelling the dynamics of the time series with statistical models. In Cao
    et al. ([2014](#bib.bib4)), authors proposed a parsimonious statistical model,
    known as mixture of Gaussian trees, for modeling multi-modal minority class time
    series data to solve the problem of imbalanced classification, which shows advantages
    compared with existing oversampling approaches that do not exploit time series
    correlations between neighboring points. Authors in Smyl and Kuber ([2016](#bib.bib49))
    use samples of parameters and forecast paths calculated by a statistical algorithm
    called LGT (Local and Global Trend). More recently, in Kang et al. ([2020](#bib.bib28))
    researchers use mixture autoregressive (MAR) models to simulate sets of time series
    and investigate the diversity and coverage of the generated time series in a time
    series feature space.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 基于统计生成模型的时间序列增广方法通常涉及使用统计模型对时间序列的动态进行建模。在Cao等人（[2014](#bib.bib4)）的研究中，作者提出了一种简洁的统计模型，称为高斯树混合模型，用于建模多模态少数类时间序列数据，以解决不平衡分类问题，相比于不利用邻近点之间时间序列相关性的现有过采样方法显示出优势。Smyl和Kuber（[2016](#bib.bib49)）的作者使用由名为LGT（局部和全局趋势）的统计算法计算的参数样本和预测路径。最近，在Kang等人（[2020](#bib.bib28)）的研究中，研究人员使用混合自回归（MAR）模型模拟时间序列集合，并调查生成时间序列在时间序列特征空间中的多样性和覆盖范围。
- en: Essentially, these models describe the conditional distribution of time series
    by assuming the value at time $t$ depends on previous points. Once the initial
    value is perturbed, a new time series sequence could be generated following the
    conditional distribution.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，这些模型通过假设时间$t$的值依赖于先前的点来描述时间序列的条件分布。一旦初始值被扰动，就可以生成一个新的时间序列，遵循条件分布。
- en: 3.3 Learning-based Methods
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 基于学习的方法
- en: Time series data augmentation methods should be capable of not only generating
    diverse samples, but also mimicking the characteristics of real data. In this
    section, we summarize some recent learning based schemes that have such potentials.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据增广方法不仅应能够生成多样化的样本，还应能够模拟真实数据的特征。在本节中，我们总结了一些具有这种潜力的最新学习方法。
- en: 3.3.1 Embedding Space
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1 嵌入空间
- en: In DeVries and Taylor ([2017](#bib.bib13)), the data augmentation is proposed
    to perform in the learned embedding space (aka., latent space). It assumes that
    simple transforms applied to encoded inputs rather than the raw inputs would produce
    more plausible synthetic data due to the manifold unfolding in feature space.
    Note that the selection of the representation model in this framework is open
    and depends on the specific task and data type. When the time series data is addressed,
    a sequence autoencoder is selected in DeVries and Taylor ([2017](#bib.bib13)).
    Specifically, the interpolation and extrapolation are applied to generate new
    samples. The first $k$ nearest labels in the transformed space with the same label
    are identified. Then for each pair of neighboring samples, a new sample is generated
    which is the linear combination of them. The difference of interpolation and extrapolation
    lies in the weight selection in sample generation. This technique is particular
    useful for time series classification as demonstrated in DeVries and Taylor ([2017](#bib.bib13)).
    Recently, another data augmentation method in the embedding space named MODALS
    (Modality-agnostic Automated Data Augmentation in the Latent Space) is proposed
    in  Cheung and Yeung ([2021](#bib.bib5)). Instead of training an autoencoder to
    learn the latent space and generate additional synthetic data for training, the
    MODALS method train a classification model jointly with different compositions
    of latent space augmentations, which demonstrates superior performance for time
    series classification problems.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在DeVries和Taylor（[2017](#bib.bib13)）中，提出了在学习的嵌入空间（即潜在空间）中进行数据增强。它假设对编码后的输入应用简单变换，而不是原始输入，会由于特征空间中的流形展开而生成更具可信度的合成数据。注意，在这个框架中表示模型的选择是开放的，取决于具体任务和数据类型。当处理时间序列数据时，DeVries和Taylor（[2017](#bib.bib13)）选择了序列自编码器。具体而言，插值和外推被应用于生成新样本。在变换空间中，首先识别出具有相同标签的前$k$个最近标签。然后，对于每一对相邻样本，生成一个新的样本，该样本是它们的线性组合。插值和外推的区别在于样本生成中的权重选择。正如DeVries和Taylor（[2017](#bib.bib13)）中所展示的，这种技术对时间序列分类特别有用。最近，Cheung和Yeung（[2021](#bib.bib5)）提出了另一种嵌入空间中的数据增强方法，称为MODALS（模态无关自动数据增强在潜在空间中）。该方法不是训练自编码器来学习潜在空间并生成额外的合成数据，而是联合训练分类模型和不同组成的潜在空间增强，这在时间序列分类问题上表现出优越的性能。
- en: 3.3.2 Deep Generative Models
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2 深度生成模型
- en: Deep generative models (DGMs) have recently been shown to be able to generate
    near-realistic high-dimensional data objects such as images and sequences. DGMs
    developed for sequential data, such as audio and text, often can be extended to
    model time series data. Among DGMs, generative adversarial networks (GANs) are
    popular methods to generate synthetic samples and increase the training set effectively.
    Although the GAN frameworks have received significant attention in many fields,
    how to generate effective time series data still remains a challenging problem.
    In this subsection, we briefly review several recent works on GANs for time series
    data augmentation.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 深度生成模型（DGMs）最近被证明能够生成接近真实的高维数据对象，如图像和序列。针对顺序数据（如音频和文本）开发的DGMs通常可以扩展到建模时间序列数据。在DGMs中，生成对抗网络（GANs）是生成合成样本和有效增加训练集的流行方法。尽管GAN框架在许多领域受到了广泛关注，但如何生成有效的时间序列数据仍然是一个具有挑战性的问题。在本小节中，我们简要回顾了几个关于时间序列数据增强的GAN的近期工作。
- en: In Esteban et al. ([2017](#bib.bib14)), a Recurrent GAN (RGAN) and Recurrent
    Conditional GAN (RCGAN) are proposed to produce realistic real-valued multi-dimensional
    time series data. The RGAN adopts RNN in the generator and discriminator, while
    the RCGAN adopts both RNNs conditioned on auxiliary information. Besides desirable
    performance of RGAN and RCGAN for time series data augmentation, differential
    privacy can be used in training the RCGAN for stricter privacy guarantees like
    medicine or other sensitive domains. Recently, Yoon et al. ([2019](#bib.bib59))
    proposed TimeGAN, a natural framework for generating realistic time series data
    in various domains. TimeGAN is a generative time series model, trained adversarially
    and jointly via a learned embedding space with both supervised and unsupervised
    losses. Specifically, a stepwise supervised loss is introduced to learn the stepwise
    conditional distributions in data. It also introduces an embedding network to
    provide a reversible mapping between features and latent representations to reduce
    the high-dimensionality of the adversarial learning space. Note that the supervised
    loss is minimized by jointly training both the embedding and generator networks.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Esteban 等人 ([2017](#bib.bib14)) 的研究中，提出了 Recurrent GAN（RGAN）和 Recurrent Conditional
    GAN（RCGAN）以生成逼真的真实值多维时间序列数据。RGAN 在生成器和判别器中采用 RNN，而 RCGAN 则在条件辅助信息的条件下采用两个 RNN。除了
    RGAN 和 RCGAN 在时间序列数据增强中的良好表现外，差分隐私还可以用于训练 RCGAN 以在医学或其他敏感领域提供更严格的隐私保障。最近，Yoon
    等人 ([2019](#bib.bib59)) 提出了 TimeGAN，这是一种在各种领域生成逼真的时间序列数据的自然框架。TimeGAN 是一个生成时间序列模型，通过学习的嵌入空间以对抗方式和联合方式进行训练，同时采用监督和无监督损失。具体而言，引入了逐步监督损失以学习数据中的逐步条件分布。它还引入了一个嵌入网络，以在特征和潜在表示之间提供可逆的映射，从而减少对抗学习空间的高维度。值得注意的是，监督损失通过联合训练嵌入和生成器网络来最小化。
- en: 3.3.3 Automated Data Augmentation
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.3 自动数据增强
- en: The idea of automated data augmentation is to automatically search for optimal
    data augmentation policies through reinforcement learning, meta learning, or evolutionary
    search  Ratner et al. ([2017](#bib.bib43)); Cubuk et al. ([2019](#bib.bib7));
    Zhang et al. ([2020](#bib.bib60)); Cheung and Yeung ([2021](#bib.bib5)). The TANDA
    (Transformation Adversarial Networks for Data Augmentations) scheme in Ratner
    et al. ([2017](#bib.bib43)) is designed to train a generative sequence model over
    specified transformation functions using reinforcement learning in a GAN-like
    framework to generate realistic transformed data points, which yields strong gains
    over common heuristic data augmentation methods for a range of applications including
    image recognition and natural language understanding tasks.  Cubuk et al. ([2019](#bib.bib7))
    proposes a procedure called AutoAugment to automatically search for improved data
    augmentation policies in a reinforcement learning framework. It adopts a controller
    RNN network to predicts an augmentation policy from the search space and another
    network is trained to achieve convergence accuracy. Then, the accuracy is used
    as reward to update the RNN controller for better policies in the next iteration.
    The experimental results show that AutoAugment improves the accuracy of modern
    image classifiers significantly in a wide range of datasets.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 自动数据增强的思想是通过强化学习、元学习或进化搜索自动寻找最佳的数据增强策略  Ratner 等人 ([2017](#bib.bib43))；Cubuk
    等人 ([2019](#bib.bib7))；Zhang 等人 ([2020](#bib.bib60))；Cheung 和 Yeung ([2021](#bib.bib5))。Ratner
    等人 ([2017](#bib.bib43)) 中的 TANDA（用于数据增强的转换对抗网络）方案旨在通过在类似 GAN 的框架中使用强化学习来训练一个生成序列模型，利用指定的转换函数生成逼真的变换数据点，这在图像识别和自然语言理解等各种应用中，相较于常见的启发式数据增强方法，取得了显著的效果。Cubuk
    等人 ([2019](#bib.bib7)) 提出了一个名为 AutoAugment 的程序，用于在强化学习框架中自动搜索改进的数据增强策略。它采用一个控制器
    RNN 网络从搜索空间中预测一个增强策略，并训练另一个网络以实现收敛精度。然后，使用准确度作为奖励来更新 RNN 控制器，以在下一次迭代中获得更好的策略。实验结果表明，AutoAugment
    在广泛的数据集上显著提高了现代图像分类器的准确性。
- en: 'For time series data augmentation, the MODALS Cheung and Yeung ([2021](#bib.bib5))
    is designed to find the optimal composition of latent space transformations for
    data augmentation using evolution search strategy based on population based augmentation
    (PBA) Ho et al. ([2019](#bib.bib24)), which demonstrates superior performance
    on classification problems in continuous and discrete time series data. Another
    recent work on automated data augmentation is proposed in  Fons et al. ([2021](#bib.bib18)),
    where two sample-adaptive automatic weighting schemes are designed specifically
    for time series data: one learns to weight the contribution of the augmented samples
    to the loss, and the other selects a subset of transformations based on the ranking
    of the predicted training loss. Both adaptive policies demonstrate improvement
    on classification problems in multiple time series datasets.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于时间序列数据增强，MODALS Cheung 和 Yeung ([2021](#bib.bib5)) 旨在利用基于种群的增强（PBA）Ho 等人 ([2019](#bib.bib24))
    的进化搜索策略，找到潜在空间变换的最佳组合来进行数据增强，这在连续和离散时间序列数据的分类问题上表现出优越的性能。另一项关于自动数据增强的最新研究由 Fons
    等人 ([2021](#bib.bib18)) 提出，其中为时间序列数据设计了两种样本自适应自动加权方案：一种学习加权增强样本对损失的贡献，另一种则根据预测训练损失的排名选择变换的子集。这两种自适应策略在多个时间序列数据集上的分类问题中都显示出了改进。
- en: 4 Preliminary Evaluation
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 初步评估
- en: In this section, we demonstrate preliminary evaluations in three common time
    series tasks to show the effectiveness of data augmentation for performance improvement.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了在三种常见时间序列任务中的初步评估，以展示数据增强对性能提升的有效性。
- en: 4.1 Time Series Classification
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 时间序列分类
- en: 'In this experiment, we compare the classification performance with and without
    data augmentation. Specifically, we collect $5000$ time series of one-week long
    and 5-min interval samples with binary class labels (seasonal or non-seasonal)
    from Alibaba Cloud monitoring system. The data is randomly splitted into training
    and test sets where training contains $80\%$ of total samples. We train a fully
    convolutional network Wang et al. ([2017](#bib.bib53)) to classify each time series
    in the training set. In our experiment, we inject different types of outliers,
    including spike, step, and slope, into the test set to evaluate the robustness
    of the trained classifier. The data augmentations methods applied include cropping,
    warping, and flipping. Table [1](#S4.T1 "Table 1 ‣ 4.1 Time Series Classification
    ‣ 4 Preliminary Evaluation ‣ Time Series Data Augmentation for Deep Learning:
    A Survey") summarizes the accuracies with and without data augmentation when different
    types of outliers are injected into the test set. It can be observed that data
    augmentation leads to $0.1\%\sim 1.9\%$ accuracy improvement.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '在本实验中，我们比较了有无数据增强的分类性能。具体来说，我们从阿里巴巴云监控系统中收集了 $5000$ 条为期一周、间隔为 5 分钟的二分类标签（季节性或非季节性）时间序列样本。数据被随机分为训练集和测试集，其中训练集包含
    $80\%$ 的总样本。我们训练了一个完全卷积网络 Wang 等人 ([2017](#bib.bib53)) 以对训练集中的每个时间序列进行分类。在我们的实验中，我们将不同类型的异常值，包括尖峰、阶跃和斜率，注入到测试集中，以评估训练分类器的鲁棒性。应用的数据增强方法包括裁剪、扭曲和翻转。表
    [1](#S4.T1 "Table 1 ‣ 4.1 Time Series Classification ‣ 4 Preliminary Evaluation
    ‣ Time Series Data Augmentation for Deep Learning: A Survey") 总结了在不同类型的异常值注入到测试集中时，有无数据增强的准确率。可以观察到，数据增强导致
    $0.1\%\sim 1.9\%$ 的准确率提升。'
- en: '| Outlier injection | w/o aug | w/ aug | Improvement |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 异常值注入 | 无增强 | 有增强 | 提升 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| spike | 96.26% | 96.37% | 0.11% |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 尖峰 | 96.26% | 96.37% | 0.11% |'
- en: '| step | 93.70% | 95.62% | 1.92% |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| step | 93.70% | 95.62% | 1.92% |'
- en: '| slope | 95.84% | 96.16% | 0.32% |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| slope | 95.84% | 96.16% | 0.32% |'
- en: 'Table 1: Accuracy improvement from data augmentation under outlier injection
    in time series classification.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：时间序列分类中异常值注入下的数据增强准确率提升。
- en: 4.2 Time Series Anomaly Detection
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 时间序列异常检测
- en: 'Given the challenges of both *data scarcity* and *data imbalance* in time series
    anomaly detection, it is beneficial by adopting data augmentation to generate
    more labeled data. We briefly summarize the results in Gao et al. ([2020](#bib.bib21)),
    where a U-Net based network is designed and evaluated on public Yahoo! dataset Laptev
    et al. ([2015](#bib.bib33)) for time series anomaly detection. The performance
    comparison under different settings are summarized in Table [2](#S4.T2 "Table
    2 ‣ 4.2 Time Series Anomaly Detection ‣ 4 Preliminary Evaluation ‣ Time Series
    Data Augmentation for Deep Learning: A Survey"), including applying the model
    on the raw data (U-Net-Raw), on the decomposed residuals (U-Net-DeW), and on the
    residuals with data augmentation (U-Net-DeWA). The applied data augmentation methods
    include flipping, cropping, label expansion, and APP based augmentation in frequency
    domain. It can be observed that the decomposition helps the increase of the F1
    score and the data augmentation further boosts the performance.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '鉴于时间序列异常检测中存在的*数据稀缺*和*数据不平衡*的挑战，采用数据增强来生成更多标记数据是有益的。我们简要总结了Gao等人（[2020](#bib.bib21)）的结果，其中设计并在公共Yahoo!数据集Laptev等人（[2015](#bib.bib33)）上评估了一个基于U-Net的网络，用于时间序列异常检测。不同设置下的性能比较总结在表[2](#S4.T2
    "Table 2 ‣ 4.2 Time Series Anomaly Detection ‣ 4 Preliminary Evaluation ‣ Time
    Series Data Augmentation for Deep Learning: A Survey")中，包括对原始数据（U-Net-Raw）、对分解后的残差（U-Net-DeW）和对增强后的残差（U-Net-DeWA）的应用。所采用的数据增强方法包括翻转、裁剪、标签扩展以及基于频域的APP增强。可以观察到，分解有助于提高
    F1 分数，而数据增强进一步提升了性能。'
- en: '| Algorithm | Precision | Recall | F1 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 算法 | 精确度 | 召回率 | F1 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| U-Net-Raw | 0.473 | 0.351 | 0.403 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| U-Net-Raw | 0.473 | 0.351 | 0.403 |'
- en: '| U-Net-DeW | 0.793 | 0.569 | 0.662 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| U-Net-DeW | 0.793 | 0.569 | 0.662 |'
- en: '| U-Net-DeWA (w/ aug) | 0.859 | 0.581 | 0.693 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| U-Net-DeWA（带增强） | 0.859 | 0.581 | 0.693 |'
- en: 'Table 2: Time series anomaly detection improvement from data augmentation based
    on precision, recall, and F1 score.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 基于精确度、召回率和 F1 分数的数据增强在时间序列异常检测中的改进。'
- en: 4.3 Time Series Forecasting
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 时间序列预测
- en: 'In this subsection we demonstrate the practical effectiveness of data augmentation
    in two popular deep models DeepAR Salinas et al. ([2019](#bib.bib46)) and Transformer
    Vaswani et al. ([2017](#bib.bib52)). In Table [3](#S4.T3 "Table 3 ‣ 4.3 Time Series
    Forecasting ‣ 4 Preliminary Evaluation ‣ Time Series Data Augmentation for Deep
    Learning: A Survey"), we report the performance improvement on mean absolute scaled
    error (MASE) on several public datasets: electricity and traffic from UCI Learning
    Repository²²2[http://archive.ics.uci.edu/ml/datasets.php](http://archive.ics.uci.edu/ml/datasets.php)
    and 3 datasets from the M4 competition³³3[https://github.com/Mcompetitions/M4-methods/tree/master/Dataset](https://github.com/Mcompetitions/M4-methods/tree/master/Dataset).
    We consider the basic augmentation methods including cropping, warping, flipping,
    and APP based augmentation in frequency domain. In Table [3](#S4.T3 "Table 3 ‣
    4.3 Time Series Forecasting ‣ 4 Preliminary Evaluation ‣ Time Series Data Augmentation
    for Deep Learning: A Survey"), we summarize average MASE without augmentation,
    with augmentation and average relative improvement (ARI) which is computed as
    the mean of $(\textrm{MASE}_{\textrm{w/o aug}}-\textrm{MASE}_{\textrm{w aug}})/\textrm{MASE}_{\textrm{w
    aug}}$. We observe that the data augmentation methods bring promising results
    for all models in average sense. However, the negative results can still be observed
    for specific data/model pairs. As a future work, it motivates us to search for
    advanced automated data augmentation policies that stabilize the influence of
    data augmentation specifically for time series forecasting.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们展示了数据增强在两个流行的深度模型中的实际效果：DeepAR Salinas 等人 ([2019](#bib.bib46)) 和 Transformer
    Vaswani 等人 ([2017](#bib.bib52))。在表[3](#S4.T3 "表 3 ‣ 4.3 时间序列预测 ‣ 4 初步评估 ‣ 针对深度学习的时间序列数据增强：综述")中，我们报告了在多个公共数据集上均值绝对缩放误差（MASE）的性能提升，包括来自
    UCI 学习库的电力和交通数据²²2[http://archive.ics.uci.edu/ml/datasets.php](http://archive.ics.uci.edu/ml/datasets.php)以及
    M4 竞赛的3个数据集³³3[https://github.com/Mcompetitions/M4-methods/tree/master/Dataset](https://github.com/Mcompetitions/M4-methods/tree/master/Dataset)。我们考虑了包括裁剪、扭曲、翻转和基于频率域的
    APP 增强在内的基本增强方法。在表[3](#S4.T3 "表 3 ‣ 4.3 时间序列预测 ‣ 4 初步评估 ‣ 针对深度学习的时间序列数据增强：综述")中，我们总结了没有增强和有增强的平均
    MASE 以及计算为 $(\textrm{MASE}_{\textrm{w/o aug}}-\textrm{MASE}_{\textrm{w aug}})/\textrm{MASE}_{\textrm{w
    aug}}$ 的平均相对提升（ARI）。我们观察到数据增强方法在所有模型中的平均效果都很有前景。然而，在特定的数据/模型对中仍然可以观察到负面结果。作为未来的工作，这促使我们寻找先进的自动化数据增强策略，以稳定数据增强对时间序列预测的影响。
- en: '| Dataset | DeepAR | Transformer |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | DeepAR | Transformer |'
- en: '| --- | --- | --- |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| w/o aug | w/ aug | ARI | w/o aug | w/ aug | ARI |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| w/o aug | w/ aug | ARI | w/o aug | w/ aug | ARI |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| electricity | $0.87$ | $0.97$ | $1.92\%$ | $1.04$ | $1.11$ | $-2\%$ |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| electricity | $0.87$ | $0.97$ | $1.92\%$ | $1.04$ | $1.11$ | $-2\%$ |'
- en: '| traffic | $0.66$ | $0.80$ | $-12\%$ | $0.70$ | $0.91$ | $-16\%$ |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| traffic | $0.66$ | $0.80$ | $-12\%$ | $0.70$ | $0.91$ | $-16\%$ |'
- en: '| m4-hourly | $6.33$ | $5.35$ | $56\%$ | $7.77$ | $7.87$ | $38\%$ |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| m4-hourly | $6.33$ | $5.35$ | $56\%$ | $7.77$ | $7.87$ | $38\%$ |'
- en: '| m4-daily | $4.88$ | $4.48$ | $10\%$ | $7.85$ | $7.38$ | $37\%$ |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| m4-daily | $4.88$ | $4.48$ | $10\%$ | $7.85$ | $7.38$ | $37\%$ |'
- en: '| m4-weekly | $12.00$ | $9.34$ | $76\%$ | $6.62$ | $7.09$ | $23\%$ |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| m4-weekly | $12.00$ | $9.34$ | $76\%$ | $6.62$ | $7.09$ | $23\%$ |'
- en: 'Table 3: Time seires forecasting improvement from data augmentation based on
    MASE.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：基于 MASE 的数据增强对时间序列预测的改进。
- en: 5 Discussion for Future Opportunities
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 未来机会讨论
- en: 5.1 Augmentation in Time-Frequency Domain
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 时间-频率域的增强
- en: 'As discussed in Section [2.3](#S2.SS3 "2.3 Time-Frequency Domain ‣ 2 Basic
    Data Augmentation Methods ‣ Time Series Data Augmentation for Deep Learning: A
    Survey"), so far there are only limited studies of time series data augmentation
    methods based on STFT in the time-frequency domain. Besides STFT, wavelet transform
    and its variants including continuous wavelet transform (CWT) and discrete wavelet
    transform (DWT), are another family of adaptive time–frequency domain analysis
    methods to characterize time-varying properties of time series. Compared to STFT,
    they can handle non-stationary time series and non-Gaussian noises more effectively
    and robustly. Among many wavelet transform variants, maximum overlap discrete
    wavelet transform (MODWT) is especially attractive for time series analysis Percival
    and Walden ([2000](#bib.bib40)); Wen et al. ([2021](#bib.bib58)) due to the following
    advantages: 1) more computationally efficiency compared to CWT; 2) ability to
    handle any time series length; 3) increased resolution at coarser scales compared
    with DWT. MODWT based surrogate time series have been proposed in Keylock ([2006](#bib.bib30)),
    where wavelet iterative amplitude adjusted Fourier transform (WIAAFT) is designed
    by combining the iterative amplitude adjusted Fourier transform (IAAFT) scheme
    to each level of MODWT coefficients. In contrast to IAAFT, WIAAFT does not assume
    sationarity and can roughly maintain the shape of the original data in terms of
    the temporal evolution. Besides WIAAFT, we can also consider the perturbation
    of both amplitude spectrum and phase spectrum as Gao et al. ([2020](#bib.bib21))
    at each level of MODWT coefficients as a data augmentation scheme.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '如第 [2.3](#S2.SS3 "2.3 Time-Frequency Domain ‣ 2 Basic Data Augmentation Methods
    ‣ Time Series Data Augmentation for Deep Learning: A Survey") 节所讨论的，目前基于STFT的时间序列数据增强方法的研究仍然较为有限。除了STFT外，小波变换及其变体，包括连续小波变换（CWT）和离散小波变换（DWT），是另一系列自适应的时频域分析方法，用于表征时间序列的时变性质。与STFT相比，它们能够更有效和更稳健地处理非平稳时间序列和非高斯噪声。在众多的小波变换变体中，最大重叠离散小波变换（MODWT）尤其吸引人，用于时间序列分析 Percival
    and Walden ([2000](#bib.bib40)); Wen et al. ([2021](#bib.bib58))，原因如下：1）与CWT相比更高的计算效率；2）能够处理任何时间序列长度；3）与DWT相比在粗略尺度上具有更高的分辨率。基于MODWT的替代时间序列在 Keylock
    ([2006](#bib.bib30))中被提出，其中将小波迭代幅度调整傅里叶变换（WIAAFT）方案设计为每个MODWT系数级别的组合。与IAAFT不同，WIAAFT不假设平稳性，并且在时间演化方面大致维持了原始数据的形状。除了WIAAFT，我们还可以考虑在每个MODWT系数级别上考虑幅度谱和相位谱的扰动，作为数据增强方案 Gao
    et al. ([2020](#bib.bib21))。'
- en: It would be an interesting future direction to investigate how to exploit different
    wavelet transforms (CWT, DWT, MODWT, etc.) for an effective time-frequency domain
    based time series data augmentation in deep neural networks.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 探究如何利用不同的小波变换（CWT、DWT、MODWT等）来有效利用深度神经网络中基于时频域的时间序列数据增强，将是一个有趣的未来方向。
- en: 5.2 Augmentation for Imbalanced Class
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 不平衡类别的增强
- en: In time series classification, class imbalance occurs very frequently. One classical
    approach addressing imbalanced classification problem is to oversample the minority
    class as the synthetic minority oversampling technique (SMOTE) Fernández et al.
    ([2018](#bib.bib17)) to artificially mitigate the imbalance. However, this oversampling
    strategy may change the distribution of raw data and cause overfitting. Another
    approach is to design cost-sensitive model by using adjust loss function Geng
    and Luo ([2018](#bib.bib22)). Furthermore, Gao et al. ([2020](#bib.bib21)) designed
    label-based weight and value-based weight in the loss function in convolution
    neural networks, which considers weight adjustment for class labels and the neighborhood
    of each sample. Thus, both class imbalance and temporal dependency are explicitly
    considered.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列分类中，类别不平衡经常发生。解决不平衡分类问题的一个经典方法是对少数类进行过采样，即合成少数类过采样技术（SMOTE） Fernández et
    al. ([2018](#bib.bib17)) ，以人工减轻不平衡现象。然而，这种过采样策略可能改变原始数据的分布并导致过拟合。另一种方法是通过使用调整损失函数设计成本敏感模型 Geng
    and Luo ([2018](#bib.bib22))。此外，Gao et al. ([2020](#bib.bib21))在卷积神经网络的损失函数中设计了基于标签的权重和基于数值的权重，考虑了类别标签和每个样本的邻域的权重调整。因此，这两个类别不平衡和时间依赖性都得到了明确考虑。
- en: Performing data augmentation and weighting for imbalanced class together would
    be an interesting and effective direction. A recent study investigates this topic
    in the area of CV and NLP Hu et al. ([2019](#bib.bib25)), which significantly
    improves text and image classification in low data regime and imbalanced class
    problems. In future, it is interesting to design deep network by jointly considering
    data augmentation and weighting for imbalanced class in time series data.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不平衡类别的数据进行数据增强和加权的结合将是一个有趣且有效的方向。最近的研究探讨了这一主题，涉及计算机视觉和自然语言处理领域Hu et al. ([2019](#bib.bib25))，这显著改善了低数据和不平衡类别问题下的文本和图像分类。未来，通过共同考虑时间序列数据中的数据增强和不平衡类别加权来设计深度网络将是一个有趣的方向。
- en: 5.3 Augmentation Selection and Combination
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 增强选择与组合
- en: 'Given different data augmentation methods summarized in Fig. [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Time Series Data Augmentation for Deep Learning: A Survey"),
    one key strategy is how to select and combine various augmentation methods together.
    The experiments in Um et al. ([2017](#bib.bib51)) show that the combination of
    three basic time-domain methods (permutation, rotation, and time warping) is better
    than that of a single method and achieves the best performance in time series
    classification. Also, the results in Rashid and Louis ([2019](#bib.bib41)) demonstrate
    substantial performance improvement for a time series classification task when
    using a deep neural network by combining four data augmentation methods (i.e,
    jittering, scaling, rotation and time-warping). However, considering various data
    augmentation methods, directly combining different augmentations may result in
    a huge amount of data, and may not be efficient and effective for performance
    improvement. Recently, RandAugment Cubuk et al. ([2020](#bib.bib8)) is proposed
    as a practical way for augmentation combination in image classification and object
    detection. For each random generated dataset, RandAugment is based on only two
    interpretable hyperparameters $N$ (number of augmentation methods to combine)
    and $M$ (magnitude for all augmentation methods), where each augmentation is randomly
    selected from $K$=14 available augmentation methods. Furthermore, this randomly
    combined augmentation with simple grid search can be used in the reinforcement
    learning based data augmentation as  Cubuk et al. ([2019](#bib.bib7)) for efficient
    space searching.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '根据图 [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Time Series Data Augmentation for
    Deep Learning: A Survey") 总结的不同数据增强方法，关键策略之一是如何选择和组合各种增强方法。Um et al. ([2017](#bib.bib51))
    的实验表明，三种基本时间域方法（置换、旋转和时间扭曲）的组合优于单一方法，并在时间序列分类中实现了最佳性能。此外，Rashid 和 Louis ([2019](#bib.bib41))
    的结果显示，通过将四种数据增强方法（即抖动、缩放、旋转和时间扭曲）结合使用深度神经网络，时间序列分类任务的性能显著提升。然而，考虑到各种数据增强方法，直接组合不同的增强可能会导致大量数据，并可能对性能提升效率和效果不佳。最近，RandAugment Cubuk
    et al. ([2020](#bib.bib8)) 被提出作为图像分类和目标检测中的增强组合的实际方法。对于每个随机生成的数据集，RandAugment
    仅基于两个可解释的超参数 $N$（组合的增强方法数量）和 $M$（所有增强方法的幅度），其中每种增强方法是从 $K$=14 种可用增强方法中随机选择的。此外，这种随机组合的增强与简单的网格搜索可以用于基于强化学习的数据增强，类似于Cubuk
    et al. ([2019](#bib.bib7)) 用于高效空间搜索。'
- en: An interesting future direction is how to design effective augmentation selection
    and/or combination strategies suitable for time series data in deep learning.
    Customized reinforcement learning and meta learning optimized for time series
    could be potential approaches. Furthermore, algorithm efficiency is another important
    consideration in practice.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的未来方向是如何设计适用于深度学习中时间序列数据的有效增强选择和/或组合策略。定制化的强化学习和优化的元学习可能是潜在的方法。此外，算法效率在实践中也是另一个重要的考虑因素。
- en: 5.4 Augmentation with Gaussian Processes
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 使用高斯过程的增强
- en: Gaussian Processes (GPs) Rasmussen and Williams ([2005](#bib.bib42)) are well-known
    Bayesian non-parametric models suitable for time series analysis Roberts et al.
    ([2013](#bib.bib44)). From the function-space view, GPs induce a distribution
    over functions, i.e., a stochastic process. Time series can be viewed as functions
    with time as input and observation as output, and thus can be modeled with GPs.
    A GP $f(t)\sim\mathcal{GP}(m(t),k(t,t^{\prime}))$ is characterized by a mean function
    $m(t)$ and a covariance kernel function $k(t,t^{\prime})$. The choice of the kernel
    allows to place assumptions on some general properties of the modeled functions,
    such as smoothness, scale, periodicity and noise level. Kernels can be composed
    through addition and multiplication, resulting in compositional function properties,
    such as pseudo-periodicity, additive decomposability, and change point. GPs are
    often applied to interpolation and extrapolation tasks, which correspond to imputation
    and forecasting in time series analysis. Furthermore, deep Gaussian processes(DGPs) Damianou
    and Lawrence ([2013](#bib.bib11)); Salimbeni and Deisenroth ([2017](#bib.bib45)),
    which are richer models with hierarchical composition of GPs and often exceed
    standard (single-layer) GPs significantly in many cases, have not been well studied
    for time series. We believe GPs and DGPs are future directions as they allow to
    sample time series with those properties mentioned above through the design of
    kernels, and to generate new data instances from existing ones by exploiting their
    interpolation/extrapolation abilities.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯过程（GPs）Rasmussen和Williams（[2005](#bib.bib42)）是广为人知的适合时间序列分析的贝叶斯非参数模型 Roberts等人（[2013](#bib.bib44)）。从函数空间的角度来看，高斯过程诱导了一个函数分布，即一个随机过程。时间序列可以视为以时间为输入、观察值为输出的函数，因此可以用GPs来建模。一个GP
    $f(t)\sim\mathcal{GP}(m(t),k(t,t^{\prime}))$由均值函数 $m(t)$ 和协方差核函数 $k(t,t^{\prime})$
    特征化。核的选择允许对建模函数的一些一般属性进行假设，如平滑性、尺度、周期性和噪声水平。核可以通过加法和乘法进行组合，从而产生组合函数属性，如伪周期性、加性分解性和变化点。GPs通常应用于插值和外推任务，这对应于时间序列分析中的填补和预测。此外，深度高斯过程（DGPs）Damianou和Lawrence（[2013](#bib.bib11)）；Salimbeni和Deisenroth（[2017](#bib.bib45)），这些模型具有层次化的GPs组合，并且在许多情况下常常显著超越标准（单层）GPs，但在时间序列方面尚未得到很好研究。我们认为GPs和DGPs是未来的方向，因为它们通过核的设计允许采样具有上述属性的时间序列，并利用其插值/外推能力从现有数据实例生成新的数据实例。
- en: 5.5 Augmentation with Deep Generative Models
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 使用深度生成模型的增强
- en: Current DGMs adopted for time series data augmentation are mainly GANs. However,
    other DGMs also have great potentials for time series modeling. For example, deep
    autoregressive networks (DARNs) exhibit a natural fit for time series because
    they generate data in a sequential manner, obeying the causal direction of physical
    time series data generating process. DARNs like Wavenet Oord et al. ([2016](#bib.bib38))
    and Transformer Vaswani et al. ([2017](#bib.bib52)) have demonstrated promising
    performance in time series forecasting tasks Alexandrov et al. ([2020](#bib.bib1)).
    Another example is normalizing flows (NFs) Kobyzev et al. ([2020](#bib.bib31)),
    which recently have shown success in modeling time series stochastic processes
    with excellent inter-/extrapolation performance given observed data Deng et al.
    ([2020](#bib.bib12)). Most recently, variational autoencoders (VAEs) based data
    augmentation Fu et al. ([2020](#bib.bib19)) are investigated for human activity
    recognition.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 目前用于时间序列数据增强的深度生成模型主要是GANs。然而，其他深度生成模型也在时间序列建模中具有巨大潜力。例如，深度自回归网络（DARNs）展示了与时间序列的自然契合，因为它们以顺序方式生成数据，遵循物理时间序列数据生成过程的因果方向。像Wavenet
    Oord等人（[2016](#bib.bib38)）和Transformer Vaswani等人（[2017](#bib.bib52)）这样的DARNs在时间序列预测任务中表现出了有希望的性能
    Alexandrov等人（[2020](#bib.bib1)）。另一个例子是归一化流（NFs） Kobyzev等人（[2020](#bib.bib31)），它们最近在建模时间序列随机过程方面取得了成功，表现出了出色的插值/外推性能，给定的观测数据
    Deng等人（[2020](#bib.bib12)）。最近，基于变分自编码器（VAEs）的数据增强 Fu等人（[2020](#bib.bib19)）被研究用于人类活动识别。
- en: In summary, besides the common GAN architectures, how to leverage other deep
    generative models like DARNs, NFs, and VAEs, which are less investigated for time
    series data augmentation, remain exciting future opportunities.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 总结而言，除了常见的GAN架构之外，如何利用其他深度生成模型如DARNs、NFs和VAEs，这些模型在时间序列数据增强中的研究较少，仍然是令人兴奋的未来机会。
- en: 6 Conclusion
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: As deep learning models are becoming more popular on time series data, the limited
    labeled data calls for effective data augmentation methods. In this paper, we
    give a comprehensive survey on time series data augmentation methods in various
    tasks. We organize the reviewed methods in a taxonomy consisting of basic and
    advanced approaches, summarize representative methods in each category, compare
    them empirically in typical tasks, and highlight future research directions.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习模型在时间序列数据上的流行，有限的标记数据要求有效的数据增强方法。在本文中，我们对各种任务中的时间序列数据增强方法进行了全面调查。我们将审查的方法组织在一个包括基础和高级方法的分类法中，总结了每个类别中的代表性方法，实证比较了它们在典型任务中的表现，并强调了未来的研究方向。
- en: References
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Alexandrov et al. [2020] Alexander Alexandrov, Konstantinos Benidis, Michael
    Bohlke-Schneider, Valentin Flunkert, Jan Gasthaus, Tim Januschowski, Danielle C
    Maddix, Syama Rangapuram, David Salinas, Jasper Schulz, et al. Gluonts: Probabilistic
    and neural time series modeling in python. Journal of Machine Learning Research,
    21(116):1–6, 2020.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Alexandrov 等人 [2020] Alexander Alexandrov、Konstantinos Benidis、Michael Bohlke-Schneider、Valentin
    Flunkert、Jan Gasthaus、Tim Januschowski、Danielle C Maddix、Syama Rangapuram、David
    Salinas、Jasper Schulz 等人。Gluonts: Python中的概率和神经时间序列建模。机器学习研究杂志, 21(116):1–6, 2020。'
- en: Bandara et al. [2020] Kasun Bandara, Hansika Hewamalage, Yuan-Hao Liu, Yanfei
    Kang, and Christoph Bergmeir. Improving the accuracy of global forecasting models
    using time series data augmentation. arXiv preprint arXiv:2008.02663, 2020.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bandara 等人 [2020] Kasun Bandara、Hansika Hewamalage、Yuan-Hao Liu、Yanfei Kang
    和 Christoph Bergmeir。通过时间序列数据增强提高全球预测模型的准确性。arXiv 预印本 arXiv:2008.02663, 2020。
- en: Bergmeir et al. [2016] Christoph Bergmeir, Rob J. Hyndman, and José M. Benítez.
    Bagging exponential smoothing methods using STL decomposition and Box–Cox transformation.
    International Journal of Forecasting, 32(2):303–312, 2016.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bergmeir 等人 [2016] Christoph Bergmeir、Rob J. Hyndman 和 José M. Benítez。使用 STL
    分解和 Box–Cox 变换的包外指数平滑方法。国际预测杂志, 32(2):303–312, 2016。
- en: Cao et al. [2014] Hong Cao, Vincent YF Tan, and John ZF Pang. A parsimonious
    mixture of gaussian trees model for oversampling in imbalanced and multimodal
    time-series classification. IEEE TNNLS, 25(12):2226–2239, 2014.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等人 [2014] Hong Cao、Vincent YF Tan 和 John ZF Pang。用于不平衡和多模态时间序列分类的简约高斯树混合模型。IEEE
    TNNLS, 25(12):2226–2239, 2014。
- en: 'Cheung and Yeung [2021] Tsz-Him Cheung and Dit-Yan Yeung. MODALS: Modality-agnostic
    automated data augmentation in the latent space. In International Conference on
    Learning Representations (ICLR), 2021.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cheung 和 Yeung [2021] Tsz-Him Cheung 和 Dit-Yan Yeung。MODALS: 潜在空间中的模态无关自动数据增强。在国际学习表征会议
    (ICLR), 2021。'
- en: 'Cleveland et al. [1990] Robert B Cleveland, William S Cleveland, Jean E McRae,
    and Irma Terpenning. STL: A seasonal-trend decomposition procedure based on loess.
    Journal of Official Statistics, 6(1):3–73, 1990.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cleveland 等人 [1990] Robert B Cleveland、William S Cleveland、Jean E McRae 和 Irma
    Terpenning。STL: 基于 loess 的季节性趋势分解程序。官方统计学杂志, 6(1):3–73, 1990。'
- en: 'Cubuk et al. [2019] Ekin D. Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan,
    and Quoc V. Le. AutoAugment: Learning augmentation strategies from data. In IEEE
    CVPR 2019, pages 113–123, June 2019.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cubuk 等人 [2019] Ekin D. Cubuk、Barret Zoph、Dandelion Mane、Vijay Vasudevan 和
    Quoc V. Le。AutoAugment: 从数据中学习增强策略。在 IEEE CVPR 2019, 第 113–123 页, 2019年6月。'
- en: 'Cubuk et al. [2020] Ekin D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V
    Le. RandAugment: Practical automated data augmentation with a reduced search space.
    In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops,
    pages 3008–3017, 2020.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cubuk 等人 [2020] Ekin D Cubuk、Barret Zoph、Jonathon Shlens 和 Quoc V Le。RandAugment:
    带有缩小搜索空间的实用自动数据增强。在 2020 IEEE/CVF 计算机视觉与模式识别会议研讨会, 第 3008–3017 页, 2020。'
- en: Cui et al. [2015] X Cui, V Goel, and B Kingsbury. Data augmentation for deep
    neural network acoustic modeling. IEEE/ACM TASLP, 23(9):1469–1477, 2015.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cui 等人 [2015] X Cui、V Goel 和 B Kingsbury。深度神经网络声学建模的数据增强。IEEE/ACM TASLP, 23(9):1469–1477,
    2015。
- en: Cui et al. [2016] Zhicheng Cui, Wenlin Chen, et al. Multi-scale convolutional
    neural networks for time series classification. arXiv preprint arXiv:1603.06995,
    2016.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cui 等人 [2016] Zhicheng Cui、Wenlin Chen 等人。用于时间序列分类的多尺度卷积神经网络。arXiv 预印本 arXiv:1603.06995,
    2016。
- en: Damianou and Lawrence [2013] Andreas Damianou and Neil D Lawrence. Deep gaussian
    processes. In Artificial intelligence and statistics, pages 207–215. PMLR, 2013.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Damianou 和 Lawrence [2013] Andreas Damianou 和 Neil D Lawrence。深度高斯过程。在人工智能与统计,
    第 207–215 页。PMLR, 2013。
- en: Deng et al. [2020] Ruizhi Deng, Bo Chang, Marcus A Brubaker, Greg Mori, and
    Andreas Lehrmann. Modeling continuous stochastic processes with dynamic normalizing
    flows. In NeurIPS 2020, Dec 2020.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng 等 [2020] Ruizhi Deng, Bo Chang, Marcus A Brubaker, Greg Mori 和 Andreas
    Lehrmann. 使用动态归一化流建模连续随机过程。在 NeurIPS 2020, 2020年12月。
- en: DeVries and Taylor [2017] Terrance DeVries and Graham W. Taylor. Dataset augmentation
    in feature space. In ICLR 2017, pages 1–12, Toulon, 2017.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeVries 和 Taylor [2017] Terrance DeVries 和 Graham W. Taylor. 特征空间的数据集增强。在 ICLR
    2017, 页码 1–12, Toulon, 2017。
- en: Esteban et al. [2017] Cristóbal Esteban, Stephanie L Hyland, and Gunnar Rätsch.
    Real-valued (medical) time series generation with recurrent conditional gans.
    arXiv preprint arXiv:1706.02633, 2017.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Esteban 等 [2017] Cristóbal Esteban, Stephanie L Hyland 和 Gunnar Rätsch. 使用递归条件生成对抗网络生成实值（医学）时间序列。arXiv
    预印本 arXiv:1706.02633, 2017。
- en: Fawaz et al. [2018] Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber,
    Lhassane Idoumghar, and Pierre-Alain Muller. Data augmentation using synthetic
    data for time series classification with deep residual networks. In ECML/PKDD
    Workshop on AALTD, 2018.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fawaz 等 [2018] Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane
    Idoumghar 和 Pierre-Alain Muller. 使用合成数据进行时间序列分类的数据增强与深度残差网络。在 ECML/PKDD AALTD
    研讨会, 2018。
- en: 'Fawaz et al. [2019] Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber,
    et al. Deep learning for time series classification: a review. Data Mining and
    Knowledge Discovery, 33(4):917–963, 2019.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fawaz 等 [2019] Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber 等. 时间序列分类的深度学习：综述。《数据挖掘与知识发现》，33(4):917–963,
    2019。
- en: 'Fernández et al. [2018] Alberto Fernández, Salvador Garcia, Francisco Herrera,
    and Nitesh V Chawla. SMOTE for learning from imbalanced data: progress and challenges,
    marking the 15-year anniversary. Journal of Artificial Intelligence Research,
    61:863–905, 2018.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fernández 等 [2018] Alberto Fernández, Salvador Garcia, Francisco Herrera 和 Nitesh
    V Chawla. 针对不平衡数据学习的 SMOTE：进展与挑战，庆祝15周年。《人工智能研究期刊》，61:863–905, 2018。
- en: Fons et al. [2021] Elizabeth Fons, Paula Dawson, Xiao-jun Zeng, John Keane,
    and Alexandros Iosifidis. Adaptive weighting scheme for automatic time-series
    data augmentation. arXiv preprint arXiv:2102.08310, 2021.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fons 等 [2021] Elizabeth Fons, Paula Dawson, Xiao-jun Zeng, John Keane 和 Alexandros
    Iosifidis. 自动时间序列数据增强的自适应加权方案。arXiv 预印本 arXiv:2102.08310, 2021。
- en: 'Fu et al. [2020] Biying Fu, Florian Kirchbuchner, and Arjan Kuijper. Data augmentation
    for time series: traditional vs generative models on capacitive proximity time
    series. In ACM PETRA, pages 1–10, 2020.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu 等 [2020] Biying Fu, Florian Kirchbuchner 和 Arjan Kuijper. 时间序列的数据增强：传统模型与生成模型在电容接近时间序列上的比较。在
    ACM PETRA, 页码 1–10, 2020。
- en: Gamboa [2017] John Cristian Borges Gamboa. Deep learning for time-series analysis.
    arXiv preprint arXiv:1701.01887, 2017.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gamboa [2017] John Cristian Borges Gamboa. 用于时间序列分析的深度学习。arXiv 预印本 arXiv:1701.01887,
    2017。
- en: 'Gao et al. [2020] Jingkun Gao, Xiaomin Song, Qingsong Wen, Pichao Wang, Liang
    Sun, and Huan Xu. Robusttad: Robust time series anomaly detection via decomposition
    and convolutional neural networks. MileTS’20: 6th KDD Workshop on Mining and Learning
    from Time Series, pages 1–6, 2020.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gao 等 [2020] Jingkun Gao, Xiaomin Song, Qingsong Wen, Pichao Wang, Liang Sun
    和 Huan Xu. Robusttad：通过分解和卷积神经网络进行稳健的时间序列异常检测。MileTS’20: 第六届 KDD 时间序列挖掘与学习研讨会,
    页码 1–6, 2020。'
- en: Geng and Luo [2018] Yue Geng and Xinyu Luo. Cost-sensitive convolution based
    neural networks for imbalanced time-series classification. arXiv preprint arXiv:1801.04396,
    2018.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Geng 和 Luo [2018] Yue Geng 和 Xinyu Luo. 面向不平衡时间序列分类的成本敏感卷积神经网络。arXiv 预印本 arXiv:1801.04396,
    2018。
- en: Han et al. [2019] Z Han, J Zhao, H Leung, K F Ma, and W Wang. A review of deep
    learning models for time series prediction. IEEE Sensors Journal, page 1, 2019.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等 [2019] Z Han, J Zhao, H Leung, K F Ma 和 W Wang. 深度学习模型在时间序列预测中的综述。《IEEE
    传感器期刊》，第1页, 2019。
- en: 'Ho et al. [2019] Daniel Ho, Eric Liang, Xi Chen, Ion Stoica, and Pieter Abbeel.
    Population based augmentation: Efficient learning of augmentation policy schedules.
    In International Conference on Machine Learning (ICML), pages 2731–2741, 2019.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ho 等 [2019] Daniel Ho, Eric Liang, Xi Chen, Ion Stoica 和 Pieter Abbeel. 基于人群的增强：高效学习增强策略调度。在国际机器学习大会（ICML）,
    页码 2731–2741, 2019。
- en: Hu et al. [2019] Zhiting Hu, Bowen Tan, Russ R Salakhutdinov, Tom M Mitchell,
    and Eric P Xing. Learning data manipulation for augmentation and weighting. In
    NeurIPS 2019, pages 15764–15775, 2019.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等 [2019] Zhiting Hu, Bowen Tan, Russ R Salakhutdinov, Tom M Mitchell 和 Eric
    P Xing. 学习数据操作以进行增强和加权。在 NeurIPS 2019, 页码 15764–15775, 2019。
- en: 'Hu et al. [2020] Hailin Hu, MingJian Tang, and Chengcheng Bai. Datsing: Data
    augmented time series forecasting with adversarial domain adaptation. In Proceedings
    of the 29th ACM International Conference on Information & Knowledge Management,
    pages 2061–2064, 2020.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hu et al. [2020] Hailin Hu, MingJian Tang 和 Chengcheng Bai. Datsing: 使用对抗性领域适应的数据增强时间序列预测。第29届ACM国际信息与知识管理会议论文集,
    页码 2061–2064, 2020。'
- en: Iwana and Uchida [2020] Brian Kenji Iwana and Seiichi Uchida. An empirical survey
    of data augmentation for time series classification with neural networks. arXiv
    preprint arXiv:2007.15951, 2020.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iwana and Uchida [2020] Brian Kenji Iwana 和 Seiichi Uchida. 基于神经网络的时间序列分类的数据增强实证调查。arXiv
    预印本 arXiv:2007.15951, 2020。
- en: 'Kang et al. [2020] Yanfei Kang, Rob J Hyndman, and Feng Li. GRATIS: Generating
    time series with diverse and controllable characteristics. Statistical Analysis
    and Data Mining: The ASA Data Science Journal, 13(4):354–376, 2020.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kang et al. [2020] Yanfei Kang, Rob J Hyndman 和 Feng Li. GRATIS: 生成具有多样和可控特征的时间序列。统计分析与数据挖掘:
    ASA 数据科学期刊, 13(4):354–376, 2020。'
- en: Kegel et al. [2018] Lars Kegel, Martin Hahmann, and Wolfgang Lehner. Feature-based
    comparison and generation of time series. In SSDBM 2018, 2018.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kegel et al. [2018] Lars Kegel, Martin Hahmann 和 Wolfgang Lehner. 基于特征的时间序列比较与生成。在
    SSDBM 2018 中, 2018。
- en: Keylock [2006] C J Keylock. Constrained surrogate time series with preservation
    of the mean and variance structure. Phys. Rev. E, 73(3):36707, Mar 2006.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keylock [2006] C J Keylock. 保持均值和方差结构的约束替代时间序列。物理评论 E, 73(3):36707, 2006年3月。
- en: 'Kobyzev et al. [2020] Ivan Kobyzev, Simon Prince, and Marcus Brubaker. Normalizing
    flows: An introduction and review of current methods. IEEE Transactions on Pattern
    Analysis and Machine Intelligence, pages 1–17, 2020.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kobyzev et al. [2020] Ivan Kobyzev, Simon Prince 和 Marcus Brubaker. 归一化流: 当前方法的介绍与回顾。IEEE
    模式分析与机器智能汇刊, 页码 1–17, 2020。'
- en: Krizhevsky et al. [2012] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
    Imagenet classification with deep convolutional neural networks. In NeurIPS 2012,
    pages 1097–1105, 2012.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky et al. [2012] Alex Krizhevsky, Ilya Sutskever 和 Geoffrey E Hinton.
    使用深度卷积神经网络的 Imagenet 分类。在 NeurIPS 2012 中, 页码 1097–1105, 2012。
- en: Laptev et al. [2015] Nikolay Laptev, Saeed Amizadeh, et al. Generic and scalable
    framework for automated time-series anomaly detection. KDD, pages 1939–1947, 2015.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Laptev et al. [2015] Nikolay Laptev, Saeed Amizadeh 等. 用于自动化时间序列异常检测的通用和可扩展框架。KDD,
    页码 1939–1947, 2015。
- en: Le Guennec et al. [2016] Arthur Le Guennec, Simon Malinowski, and Romain Tavenard.
    Data augmentation for time series classification using convolutional neural networks.
    In ECML/PKDD Workshop on AALTD, 2016.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Le Guennec et al. [2016] Arthur Le Guennec, Simon Malinowski 和 Romain Tavenard.
    使用卷积神经网络的时间序列分类数据增强。在 ECML/PKDD AALTD 研讨会中, 2016。
- en: Lee and Kim [2020] Si Woon Lee and Ha Young Kim. Stock market forecasting with
    super-high dimensional time-series data using convlstm, trend sampling, and specialized
    data augmentation. Expert Systems with Applications, 161:113704, 2020.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee and Kim [2020] Si Woon Lee 和 Ha Young Kim. 使用 convlstm、趋势采样和专门的数据增强进行超高维时间序列数据的股市预测。专家系统与应用,
    161:113704, 2020。
- en: Lee et al. [2019] Tracey Kah-Mein Lee, YL Kuah, Kee-Hao Leo, Saeid Sanei, Effie
    Chew, and Ling Zhao. Surrogate rehabilitative time series data for image-based
    deep learning. In EUSIPCO 2019, pages 1–5, 2019.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee et al. [2019] Tracey Kah-Mein Lee, YL Kuah, Kee-Hao Leo, Saeid Sanei, Effie
    Chew 和 Ling Zhao. 用于基于图像的深度学习的替代性康复时间序列数据。在 EUSIPCO 2019 中, 页码 1–5, 2019。
- en: 'Lim et al. [2018] Swee Kiat Lim, Yi Loo, Ngoc-Trung Tran, Ngai-Man Cheung,
    Gemma Roig, and Yuval Elovici. DOPING: Generative data augmentation for unsupervised
    anomaly detection with gan. In 2018 IEEE International Conference on Data Mining
    (ICDM), pages 1122–1127\. IEEE, 2018.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lim et al. [2018] Swee Kiat Lim, Yi Loo, Ngoc-Trung Tran, Ngai-Man Cheung,
    Gemma Roig 和 Yuval Elovici. DOPING: 用于无监督异常检测的生成数据增强与 gan。在 2018 年 IEEE 数据挖掘国际会议
    (ICDM) 中, 页码 1122–1127。IEEE, 2018。'
- en: 'Oord et al. [2016] Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan,
    Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.
    Wavenet: A generative model for raw audio. In International Conference on Learning
    Representations, 2016.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Oord et al. [2016] Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan,
    Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior 和 Koray Kavukcuoglu.
    Wavenet: 一种原始音频生成模型。国际学习表征会议, 2016。'
- en: 'Park et al. [2019] Daniel S Park, William Chan, Yu Zhang, Chung-Cheng Chiu,
    Barret Zoph, Ekin D Cubuk, et al. SpecAugment: A simple data augmentation method
    for automatic speech recognition. In INTERSPEECH 2019, pages 2613–2617, 2019.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Park et al. [2019] Daniel S Park, William Chan, Yu Zhang, Chung-Cheng Chiu,
    Barret Zoph, Ekin D Cubuk 等. SpecAugment: 一种用于自动语音识别的简单数据增强方法。在 INTERSPEECH 2019
    中, 页码 2613–2617, 2019。'
- en: Percival and Walden [2000] Donald B Percival and Andrew T Walden. Wavelet methods
    for time series analysis, volume 4. Cambridge university press, New York, 2000.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Percival 和 Walden [2000] Donald B Percival 和 Andrew T Walden. 时间序列分析的波动方法，第4卷.
    剑桥大学出版社, 纽约, 2000.
- en: Rashid and Louis [2019] Khandakar M Rashid and Joseph Louis. Times-series data
    augmentation and deep learning for construction equipment activity recognition.
    Advanced Engineering Informatics, 42:100944, 2019.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rashid 和 Louis [2019] Khandakar M Rashid 和 Joseph Louis. 时间序列数据增强和深度学习用于建筑设备活动识别.
    高级工程信息学, 42:100944, 2019.
- en: Rasmussen and Williams [2005] Carl Edward Rasmussen and Christopher KI Williams.
    Gaussian Processes for Machine Learning. The MIT Press, 2005.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rasmussen 和 Williams [2005] Carl Edward Rasmussen 和 Christopher KI Williams.
    高斯过程机器学习. 麻省理工学院出版社, 2005.
- en: Ratner et al. [2017] Alexander J Ratner, Henry R Ehrenberg, Zeshan Hussain,
    Jared Dunnmon, and Christopher Ré. Learning to compose domain-specific transformations
    for data augmentation. NeurIPS 2017, 30:3239, 2017.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ratner 等 [2017] Alexander J Ratner, Henry R Ehrenberg, Zeshan Hussain, Jared
    Dunnmon 和 Christopher Ré. 学习组合领域特定转换用于数据增强. NeurIPS 2017, 30:3239, 2017.
- en: 'Roberts et al. [2013] Stephen Roberts, Michael Osborne, Mark Ebden, Steven
    Reece, Neale Gibson, and Suzanne Aigrain. Gaussian processes for time-series modelling.
    Philosophical Transactions of the Royal Society A: Mathematical, Physical and
    Engineering Sciences, 371(1984):20110550, 2013.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Roberts 等 [2013] Stephen Roberts, Michael Osborne, Mark Ebden, Steven Reece,
    Neale Gibson 和 Suzanne Aigrain. 时间序列建模的高斯过程. 皇家学会A辑: 数学、物理与工程科学, 371(1984):20110550,
    2013.'
- en: Salimbeni and Deisenroth [2017] Hugh Salimbeni and Marc Peter Deisenroth. Doubly
    stochastic variational inference for deep gaussian processes. In NeurIPS 2017,
    pages 4591–4602, 2017.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salimbeni 和 Deisenroth [2017] Hugh Salimbeni 和 Marc Peter Deisenroth. 双重随机变分推断用于深度高斯过程.
    载于 NeurIPS 2017, 页 4591–4602, 2017.
- en: 'Salinas et al. [2019] David Salinas, Valentin Flunkert, Jan Gasthaus, and Tim
    Januschowski. DeepAR: Probabilistic forecasting with autoregressive recurrent
    networks. International Journal of Forecasting, 2019.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Salinas 等 [2019] David Salinas, Valentin Flunkert, Jan Gasthaus 和 Tim Januschowski.
    DeepAR: 使用自回归递归网络的概率预测. 国际预测期刊, 2019.'
- en: 'Schreiber and Schmitz [2000] Thomas Schreiber and Andreas Schmitz. Surrogate
    time series. Physica D: Nonlinear Phenomena, 142(3):346–382, 2000.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schreiber 和 Schmitz [2000] Thomas Schreiber 和 Andreas Schmitz. 替代时间序列. 物理学D:
    非线性现象, 142(3):346–382, 2000.'
- en: Shorten and Khoshgoftaar [2019] Connor Shorten and Taghi M Khoshgoftaar. A survey
    on image data augmentation for deep learning. Journal of Big Data, 6(1):60, 2019.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shorten 和 Khoshgoftaar [2019] Connor Shorten 和 Taghi M Khoshgoftaar. 深度学习图像数据增强的综述.
    大数据期刊, 6(1):60, 2019.
- en: Smyl and Kuber [2016] Slawek Smyl and Karthik Kuber. Data preprocessing and
    augmentation for multiple short time series forecasting with recurrent neural
    networks. In 36th International Symposium on Forecasting, June 2016.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Smyl 和 Kuber [2016] Slawek Smyl 和 Karthik Kuber. 数据预处理和增强用于多个短时间序列预测与递归神经网络.
    载于第36届国际预测研讨会, 2016年6月.
- en: Steven Eyobu and Han [2018] Odongo Steven Eyobu and Dong Seog Han. Feature representation
    and data augmentation for human activity classification based on wearable IMU
    sensor data using a deep LSTM neural network. Sensors, 18(9):2892, 2018.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Steven Eyobu 和 Han [2018] Odongo Steven Eyobu 和 Dong Seog Han. 基于可穿戴IMU传感器数据的深度LSTM神经网络的人类活动分类特征表示和数据增强.
    传感器, 18(9):2892, 2018.
- en: Um et al. [2017] Terry T Um, Franz M J Pfister, Daniel Pichler, Satoshi Endo,
    Muriel Lang, Sandra Hirche, Urban Fietzek, and Dana Kulić. Data augmentation of
    wearable sensor data for Parkinson’s disease monitoring using convolutional neural
    networks. In ACM ICMI 2017, pages 216–220, 2017.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Um 等 [2017] Terry T Um, Franz M J Pfister, Daniel Pichler, Satoshi Endo, Muriel
    Lang, Sandra Hirche, Urban Fietzek 和 Dana Kulić. 使用卷积神经网络的可穿戴传感器数据增强用于帕金森病监测.
    载于 ACM ICMI 2017, 页 216–220, 2017.
- en: Vaswani et al. [2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, et al. Attention is all you need. In NeurIPS 2017, pages 5998–6008,
    2017.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani 等 [2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones 等. 注意力机制就是你所需的一切. 载于 NeurIPS 2017, 页 5998–6008, 2017.
- en: 'Wang et al. [2017] Zhiguang Wang, Weizhong Yan, and Tim Oates. Time series
    classification from scratch with deep neural networks: A strong baseline. In IJCNN,
    pages 1578–1585, 2017.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等 [2017] Zhiguang Wang, Weizhong Yan 和 Tim Oates. 从头开始的时间序列分类与深度神经网络:
    一个强基线. 载于 IJCNN, 页 1578–1585, 2017.'
- en: Wen and Keyes [2019] Tailai Wen and Roy Keyes. Time series anomaly detection
    using convolutional neural networks and transfer learning. In IJCAI Workshop on
    AI4IoT, 2019.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wen 和 Keyes [2019] Tailai Wen 和 Roy Keyes. 使用卷积神经网络和迁移学习的时间序列异常检测. 载于 IJCAI
    AI4IoT 研讨会, 2019.
- en: 'Wen et al. [2019a] Qingsong Wen, Jingkun Gao, Xiaomin Song, Liang Sun, and
    Jian Tan. RobustTrend: A Huber loss with a combined first and second order difference
    regularization for time series trend filtering. In IJCAI, pages 3856–3862, 2019.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wen et al. [2019a] Qingsong Wen, Jingkun Gao, Xiaomin Song, Liang Sun, 和 Jian
    Tan。RobustTrend：一种结合了一阶和二阶差分正则化的Huber损失，用于时间序列趋势滤波。收录于 IJCAI，页码 3856–3862，2019年。
- en: 'Wen et al. [2019b] Qingsong Wen, Jingkun Gao, Xiaomin Song, Liang Sun, Huan
    Xu, and Shenghuo Zhu. RobustSTL: A robust seasonal-trend decomposition algorithm
    for long time series. In AAAI, volume 33, pages 5409–5416, 2019.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wen et al. [2019b] Qingsong Wen, Jingkun Gao, Xiaomin Song, Liang Sun, Huan
    Xu, 和 Shenghuo Zhu。RobustSTL：一种用于长时间序列的稳健季节-趋势分解算法。收录于 AAAI，第 33 卷，页码 5409–5416，2019年。
- en: 'Wen et al. [2020] Qingsong Wen, Zhe Zhang, Yan Li, and Liang Sun. Fast RobustSTL:
    Efficient and robust seasonal-trend decomposition for time series with complex
    patterns. In KDD, pages 2203–2213, 2020.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wen et al. [2020] Qingsong Wen, Zhe Zhang, Yan Li, 和 Liang Sun。Fast RobustSTL：一种高效且稳健的季节-趋势分解方法，适用于具有复杂模式的时间序列。收录于
    KDD，页码 2203–2213，2020年。
- en: 'Wen et al. [2021] Qingsong Wen, Kai He, Liang Sun, Yingying Zhang, Min Ke,
    and Huan Xu. RobustPeriod: Time-frequency mining for robust multiple periodicities
    detection. In International Conference on Management of Data (SIGMOD), 2021.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wen et al. [2021] Qingsong Wen, Kai He, Liang Sun, Yingying Zhang, Min Ke, 和
    Huan Xu。RobustPeriod：用于稳健多重周期检测的时间频率挖掘。收录于 数据管理国际会议 (SIGMOD)，2021年。
- en: Yoon et al. [2019] Jinsung Yoon, Daniel Jarrett, and Mihaela van der Schaar.
    Time-series generative adversarial networks. In NeurIPS 2019, pages 5508–5518,
    2019.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yoon et al. [2019] Jinsung Yoon, Daniel Jarrett, 和 Mihaela van der Schaar。时间序列生成对抗网络。收录于
    NeurIPS 2019，页码 5508–5518，2019年。
- en: Zhang et al. [2020] Xinyu Zhang, Qiang Wang, Jian Zhang, and Zhao Zhong. Adversarial
    autoaugment. In International Conference on Learning Representations (ICLR), 2020.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. [2020] Xinyu Zhang, Qiang Wang, Jian Zhang, 和 Zhao Zhong。对抗性自动增强。收录于
    国际学习表征会议 (ICLR)，2020年。
- en: 'Zhou et al. [2019] Bin Zhou, Shenghua Liu, Bryan Hooi, Xueqi Cheng, and Jing
    Ye. Beatgan: Anomalous rhythm detection using adversarially generated time series.
    In IJCAI, pages 4433–4439, 2019.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou et al. [2019] Bin Zhou, Shenghua Liu, Bryan Hooi, Xueqi Cheng, 和 Jing Ye。Beatgan：使用对抗生成时间序列进行异常节奏检测。收录于
    IJCAI，页码 4433–4439，2019年。
