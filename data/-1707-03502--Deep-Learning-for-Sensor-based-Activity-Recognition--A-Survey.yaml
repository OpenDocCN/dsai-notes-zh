- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 20:08:56'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:08:56
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1707.03502] Deep Learning for Sensor-based Activity Recognition: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1707.03502] 基于传感器的活动识别中的深度学习：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1707.03502](https://ar5iv.labs.arxiv.org/html/1707.03502)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1707.03502](https://ar5iv.labs.arxiv.org/html/1707.03502)
- en: 'Deep Learning for Sensor-based Activity Recognition: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于传感器的活动识别中的深度学习：综述
- en: Jindong Wang Yiqiang Chen [yqchen@ict.ac.cn](mailto:yqchen@ict.ac.cn) Shuji
    Hao Xiaohui Peng Lisha Hu Beijing Key Laboratory of Mobile Computing and Pervasive
    Device, Institute of Computing Technology, Chinese Academy of Sciences, Beijing,
    China University of Chinese Academy of Sciences, Beijing, China Institute of High
    Performance Computing, A*STAR, Singapore
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Jindong Wang Yiqiang Chen [yqchen@ict.ac.cn](mailto:yqchen@ict.ac.cn) Shuji
    Hao Xiaohui Peng Lisha Hu 北京市移动计算与普适设备重点实验室，计算技术研究所，中国科学院，北京，中国科学院大学，北京，新加坡A*STAR高性能计算研究所
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Sensor-based activity recognition seeks the profound high-level knowledge about
    human activities from multitudes of low-level sensor readings. Conventional pattern
    recognition approaches have made tremendous progress in the past years. However,
    those methods often heavily rely on heuristic hand-crafted feature extraction,
    which could hinder their generalization performance. Additionally, existing methods
    are undermined for unsupervised and incremental learning tasks. Recently, the
    recent advancement of deep learning makes it possible to perform automatic high-level
    feature extraction thus achieves promising performance in many areas. Since then,
    deep learning based methods have been widely adopted for the sensor-based activity
    recognition tasks. This paper surveys the recent advance of deep learning based
    sensor-based activity recognition. We summarize existing literature from three
    aspects: sensor modality, deep model, and application. We also present detailed
    insights on existing work and propose grand challenges for future research.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基于传感器的活动识别旨在从大量低级传感器读数中获取关于人类活动的深层次高级知识。传统的模式识别方法在过去几年取得了巨大进展。然而，这些方法往往严重依赖于启发式手工特征提取，这可能会妨碍它们的泛化性能。此外，现有方法在无监督和增量学习任务中效果不佳。近年来，深度学习的进展使得自动进行高级特征提取成为可能，从而在许多领域中取得了令人满意的性能。自那时起，基于深度学习的方法已被广泛应用于基于传感器的活动识别任务。本文综述了基于深度学习的传感器活动识别的最新进展。我们从传感器模态、深度模型和应用三个方面总结了现有文献。我们还对现有工作进行了详细的见解，并提出了未来研究的重大挑战。
- en: 'Keywords: Deep learning; activity recognition; pattern recognition; pervasive
    computing'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 关键词：深度学习；活动识别；模式识别；普适计算
- en: '^†^†journal: Pattern Recognition Letters'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ^†^†期刊：模式识别快报
- en: Research Highlights (Required)
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 研究亮点（必填）
- en: To create your highlights, please type the highlights against each `\item` command.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建您的亮点，请在每个`\item`命令下输入亮点。
- en: It should be short collection of bullet points that convey the core findings
    of the article. It should include 3 to 5 bullet points (maximum 85 characters,
    including spaces, per bullet point.) • We survey deep learning based HAR in sensor
    modality, deep model, and application. • We comprehensively discuss the insights
    of deep learning models for HAR tasks. • We extensively investigate why deep learning
    can improve the performance of HAR. • We also summarize the public HAR datasets
    frequently used for research purpose. • We present some grand challenges and feasible
    solutions for deep learning based HAR.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这应是一个简短的要点集合，传达文章的核心发现。应包括3到5个要点（每个要点最多85个字符，包括空格）。 • 我们调查了基于深度学习的传感器模态、深度模型和应用中的人体活动识别。
    • 我们全面讨论了深度学习模型在人体活动识别任务中的见解。 • 我们广泛研究了深度学习如何提升人体活动识别的性能。 • 我们还总结了用于研究目的的公共人体活动识别数据集。
    • 我们提出了一些重大挑战和可行的解决方案，以推动基于深度学习的身体活动识别。
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'Human activity recognition (HAR) plays an important role in people’s daily
    life for its competence in learning profound high-level knowledge about human
    activity from raw sensor inputs. Successful HAR applications include home behavior
    analysis (Vepakomma et al., [2015](#bib.bib61)), video surveillance (Qin et al.,
    [2016](#bib.bib50)), gait analysis (Hammerla et al., [2016](#bib.bib21)), and
    gesture recognition (Kim and Toomajian, [2016](#bib.bib31)). There are mainly
    two types of HAR: video-based HAR and sensor-based HAR (Cook et al., [2013](#bib.bib13)).
    Video-based HAR analyzes videos or images containing human motions from the camera,
    while sensor-based HAR focuses on the motion data from smart sensors such as an
    accelerometer, gyroscope, Bluetooth, sound sensors and so on. Due to the thriving
    development of sensor technology and pervasive computing, sensor-based HAR is
    becoming more popular and widely used with privacy well protected. Therefore,
    in this paper, our main focus is on sensor-based HAR.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 人类活动识别（HAR）在日常生活中发挥着重要作用，因为它能够从原始传感器输入中学习到深层次的关于人类活动的知识。成功的 HAR 应用包括家庭行为分析（Vepakomma
    et al., [2015](#bib.bib61)）、视频监控（Qin et al., [2016](#bib.bib50)）、步态分析（Hammerla
    et al., [2016](#bib.bib21)）和手势识别（Kim and Toomajian, [2016](#bib.bib31)）。HAR 主要有两种类型：基于视频的
    HAR 和基于传感器的 HAR（Cook et al., [2013](#bib.bib13)）。基于视频的 HAR 分析来自摄像机的视频或图像中的人类动作，而基于传感器的
    HAR 侧重于来自智能传感器（如加速度计、陀螺仪、蓝牙、声音传感器等）的运动数据。由于传感器技术和普遍计算的发展迅速，基于传感器的 HAR 正变得越来越流行，并且隐私得到了很好的保护。因此，在本文中，我们的主要关注点是基于传感器的
    HAR。
- en: HAR can be treated as a typical pattern recognition (PR) problem. Conventional
    PR approaches have made tremendous progress on HAR by adopting machine learning
    algorithms such as decision tree, support vector machine, naive Bayes, and hidden
    Markov models (Lara and Labrador, [2013](#bib.bib34)). It is no wonder that in
    some controlled environments where there are only a few labeled data or certain
    domain knowledge is required (e.g. some disease issues), conventional PR methods
    are fully capable of achieving satisfying results. However, in most daily HAR
    tasks, those methods may heavily rely on heuristic hand-crafted feature extraction,
    which is usually limited by human domain knowledge (Bengio, [2013](#bib.bib5)).
    Furthermore, only shallow features can be learned by those approaches (Yang et al.,
    [2015](#bib.bib66)), leading to undermined performance for unsupervised and incremental
    tasks. Due to those limitations, the performances of conventional PR methods are
    restricted regarding classification accuracy and model generalization.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: HAR 可以视为一种典型的模式识别（PR）问题。传统的 PR 方法通过采用机器学习算法（如决策树、支持向量机、朴素贝叶斯和隐马尔可夫模型）在 HAR 领域取得了巨大进展（Lara
    and Labrador, [2013](#bib.bib34)）。难怪在某些受控环境中，当标记数据稀少或需要特定领域知识（例如某些疾病问题）时，传统的 PR
    方法能够取得令人满意的结果。然而，在大多数日常 HAR 任务中，这些方法可能严重依赖启发式的人工特征提取，这通常受到人工领域知识的限制（Bengio, [2013](#bib.bib5)）。此外，这些方法只能学习浅层特征（Yang
    et al., [2015](#bib.bib66)），导致无监督和增量任务的性能受到影响。由于这些局限性，传统 PR 方法在分类准确性和模型泛化方面的表现受到限制。
- en: Recent years have witnessed the fast development and advancement of deep learning,
    which achieves unparalleled performance in many areas such as visual object recognition,
    natural language processing, and logic reasoning (LeCun et al., [2015](#bib.bib35)).
    Different from traditional PR methods, deep learning can largely relieve the effort
    on designing features and can learn much more high-level and meaningful features
    by training an end-to-end neural network. In addition, the deep network structure
    is more feasible to perform unsupervised and incremental learning. Therefore,
    deep learning is an ideal approach for HAR and has been widely explored in existing
    work (Lane et al., [2015](#bib.bib33); Alsheikh et al., [2016](#bib.bib3); Plötz
    et al., [2011](#bib.bib47)).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度学习的发展迅速，在视觉对象识别、自然语言处理和逻辑推理等多个领域取得了无与伦比的成果（LeCun et al., [2015](#bib.bib35)）。与传统的模式识别（PR）方法不同，深度学习在很大程度上减轻了特征设计的工作量，并且通过训练端到端的神经网络可以学习到更多高级和有意义的特征。此外，深层网络结构更适合进行无监督和增量学习。因此，深度学习是人类活动识别（HAR）的理想方法，并在现有的研究中得到了广泛的探索（Lane
    et al., [2015](#bib.bib33); Alsheikh et al., [2016](#bib.bib3); Plötz et al.,
    [2011](#bib.bib47)）。
- en: Although some surveys have been conducted in deep learning (LeCun et al., [2015](#bib.bib35);
    Schmidhuber, [2015](#bib.bib58); Bengio, [2013](#bib.bib5)) and HAR (Lara and
    Labrador, [2013](#bib.bib34); Bulling et al., [2014](#bib.bib7)), respectively,
    there has been no specific survey focusing on the intersections of these two areas.
    To our best knowledge, this is the first article to present the recent advance
    on deep learning based HAR. We hope this survey can provide a helpful summary
    of existing work, and present potential future research directions.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在深度学习（LeCun等，[2015](#bib.bib35)；Schmidhuber，[2015](#bib.bib58)；Bengio，[2013](#bib.bib5)）和HAR（Lara和Labrador，[2013](#bib.bib34)；Bulling等，[2014](#bib.bib7)）领域已有一些调查研究，但尚无专门关注这两个领域交集的调查。根据我们所知，这是第一篇介绍深度学习基础的HAR最新进展的文章。我们希望这份调查能提供现有工作的有益总结，并提出潜在的未来研究方向。
- en: 'The rest of this paper is organized as follows. In Section [2](#S2 "2 Background
    ‣ Deep Learning for Sensor-based Activity Recognition: A Survey"), we briefly
    introduce sensor-based activity recognition and explain why deep learning can
    improve its performance. In Section [3](#S3 "3 Sensor Modality ‣ Deep Learning
    for Sensor-based Activity Recognition: A Survey"), [4](#S4 "4 Deep Model ‣ Deep
    Learning for Sensor-based Activity Recognition: A Survey") and [5](#S5 "5 Applications
    ‣ Deep Learning for Sensor-based Activity Recognition: A Survey"), we review recent
    advance of deep learning based HAR from three aspects: sensor modality, deep model,
    and application, respectively. We also introduce several benchmark datasets. Section [6](#S6
    "6 Summary and Discussion ‣ Deep Learning for Sensor-based Activity Recognition:
    A Survey") presents summary and insights on existing work. In Section [7](#S7
    "7 Grand Challenges ‣ Deep Learning for Sensor-based Activity Recognition: A Survey"),
    we discuss some grand challenges and feasible solutions. Finally, this paper is
    concluded in Section [8](#S8 "8 Conclusion ‣ Deep Learning for Sensor-based Activity
    Recognition: A Survey").'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '本文的其余部分组织如下。在第[2](#S2 "2 Background ‣ Deep Learning for Sensor-based Activity
    Recognition: A Survey")节，我们简要介绍传感器基础活动识别，并解释为什么深度学习可以提高其性能。在第[3](#S3 "3 Sensor
    Modality ‣ Deep Learning for Sensor-based Activity Recognition: A Survey")、[4](#S4
    "4 Deep Model ‣ Deep Learning for Sensor-based Activity Recognition: A Survey")和[5](#S5
    "5 Applications ‣ Deep Learning for Sensor-based Activity Recognition: A Survey")节，我们从传感器模态、深度模型和应用三个方面回顾了深度学习基础的HAR的最新进展。我们还介绍了几个基准数据集。第[6](#S6
    "6 Summary and Discussion ‣ Deep Learning for Sensor-based Activity Recognition:
    A Survey")节总结并深入探讨了现有工作。在第[7](#S7 "7 Grand Challenges ‣ Deep Learning for Sensor-based
    Activity Recognition: A Survey")节，我们讨论了一些重大挑战和可行的解决方案。最后，本文在第[8](#S8 "8 Conclusion
    ‣ Deep Learning for Sensor-based Activity Recognition: A Survey")节总结。'
- en: '![Refer to caption](img/828577c9b458de53743769b6eb11f829.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/828577c9b458de53743769b6eb11f829.png)'
- en: 'Fig. 1: An illustration of sensor-based activity recognition using conventional
    pattern recognition approaches.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：使用传统模式识别方法的传感器基础活动识别的示意图。
- en: 2 Background
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景
- en: 2.1 Sensor-based Activity Recognition
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 传感器基础活动识别
- en: 'HAR aims to understand human behaviors which enable the computing systems to
    proactively assist users based on their requirement (Bulling et al., [2014](#bib.bib7)).
    Formally speaking, suppose a user is performing some kinds of activities belonging
    to a predefined activity set $A$:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: HAR旨在理解人类行为，从而使计算系统能够根据用户的需求主动提供帮助（Bulling等，[2014](#bib.bib7)）。形式上，假设一个用户正在执行一些属于预定义活动集$A$的活动：
- en: '|  | $A=\{A_{i}\}^{m}_{i=1}$ |  | (1) |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '|  | $A=\{A_{i}\}^{m}_{i=1}$ |  | (1) |'
- en: where $m$ denotes the number of activity types. There is a sequence of sensor
    reading that captures the activity information
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$m$表示活动类型的数量。存在一个传感器读数序列捕获活动信息
- en: '|  | $\mathbf{s}=\{\mathbf{d}_{1},\mathbf{d}_{2},\cdots,\mathbf{d}_{t},\cdots\mathbf{d}_{n}\}$
    |  | (2) |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{s}=\{\mathbf{d}_{1},\mathbf{d}_{2},\cdots,\mathbf{d}_{t},\cdots\mathbf{d}_{n}\}$
    |  | (2) |'
- en: where $\mathbf{d}_{t}$ denotes the sensor reading at time $t$.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathbf{d}_{t}$表示时间$t$的传感器读数。
- en: We need to build a model $\mathcal{F}$ to predict the activity sequence based
    on sensor reading s
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要建立一个模型$\mathcal{F}$来预测基于传感器读数$s$的活动序列
- en: '|  | $\hat{A}=\{\hat{A}_{j}\}^{n}_{j=1}=\mathcal{F}(\mathbf{s}),\quad\hat{A}_{j}\in
    A$ |  | (3) |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{A}=\{\hat{A}_{j}\}^{n}_{j=1}=\mathcal{F}(\mathbf{s}),\quad\hat{A}_{j}\in
    A$ |  | (3) |'
- en: while the true activity sequence (ground truth) is denoted as
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 而真实的活动序列（地面实况）表示为
- en: '|  | $A^{\ast}=\{A^{\ast}_{j}\}^{n}_{j=1},\quad A^{\ast}_{j}\in A$ |  | (4)
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '|  | $A^{\ast}=\{A^{\ast}_{j}\}^{n}_{j=1},\quad A^{\ast}_{j}\in A$ |  | (4)
    |'
- en: where $n$ denotes the length of sequence and $n\geq m$.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$n$表示序列的长度，且$n\geq m$。
- en: The goal of HAR is to learn the model $\mathcal{F}$ by minimizing the discrepancy
    between predicted activity $\hat{A}$ and the ground truth activity $A^{\ast}$.
    Typically, a positive loss function $\mathcal{L}(\mathcal{F}(\textbf{s}),A^{\ast})$
    is constructed to reflect their discrepancy. $\mathcal{F}$ usually does not directly
    take s as input, and it usually assumes that there is a projection function $\Phi$
    that projects the sensor reading data $\mathbf{d_{i}}\in\mathbf{s}$ to a $d$-dimensional
    feature vector $\Phi(\textbf{d}_{i})\in\mathbb{R}^{d}$. To that end, the goal
    turns into minimizing the loss function $\mathcal{L}(\mathcal{F}(\Phi(\textbf{d}_{i})),A^{\ast})$.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: HAR 的目标是通过最小化预测活动 $\hat{A}$ 和地面真实活动 $A^{\ast}$ 之间的差异来学习模型 $\mathcal{F}$。通常会构建一个正的损失函数
    $\mathcal{L}(\mathcal{F}(\textbf{s}),A^{\ast})$ 来反映它们的差异。$\mathcal{F}$ 通常不会直接以
    $\textbf{s}$ 作为输入，而是假设存在一个投影函数 $\Phi$，将传感器读数数据 $\mathbf{d_{i}}\in\mathbf{s}$ 投影到一个
    $d$ 维特征向量 $\Phi(\textbf{d}_{i})\in\mathbb{R}^{d}$。因此，目标变为最小化损失函数 $\mathcal{L}(\mathcal{F}(\Phi(\textbf{d}_{i})),A^{\ast})$。
- en: 'Fig. [1](#S1.F1 "Fig. 1 ‣ 1 Introduction ‣ Deep Learning for Sensor-based Activity
    Recognition: A Survey") presents a typical flowchart of HAR using conventional
    PR approaches. First, raw signal inputs are obtained from several types of sensors (smartphones,
    watches, Wi-Fi, Bluetooth, sound etc.). Second, features are manually extracted
    from those readings based on human knowledge (Bao and Intille, [2004](#bib.bib4)),
    such as the mean, variance, DC, and amplitude in traditional machine learning
    approaches (Hu et al., [2016](#bib.bib25)). Finally, those features serve as inputs
    to train a PR model to make activity inference in real HAR tasks.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [1](#S1.F1 "Fig. 1 ‣ 1 Introduction ‣ Deep Learning for Sensor-based Activity
    Recognition: A Survey") 展示了使用传统 PR 方法进行 HAR 的典型流程图。首先，从多种类型的传感器（智能手机、手表、Wi-Fi、蓝牙、声音等）获取原始信号输入。其次，基于人类知识（Bao
    和 Intille，[2004](#bib.bib4)）从这些读数中手动提取特征，例如传统机器学习方法中的均值、方差、DC 和幅度（Hu 等，[2016](#bib.bib25)）。最后，这些特征作为输入用于训练一个
    PR 模型，以在实际 HAR 任务中进行活动推断。'
- en: 2.2 Why Deep Learning?
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 为什么要使用深度学习？
- en: Conventional PR approaches have made tremendous progress in HAR (Bulling et al.,
    [2014](#bib.bib7)). However, there are several drawbacks to conventional PR methods.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 传统 PR 方法在 HAR 方面取得了巨大进展（Bulling 等，[2014](#bib.bib7)）。然而，传统 PR 方法存在几个缺点。
- en: Firstly, the features are always extracted via a heuristic and hand-crafted
    way, which heavily relies on human experience or domain knowledge. This human
    knowledge may help in certain task-specific settings, but for more general environments
    and tasks, this will result in a lower chance and longer time to build a successful
    activity recognition system.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，特征始终是通过启发式和手工制作的方式提取的，这在很大程度上依赖于人类经验或领域知识。这些人类知识可能在特定任务设置中有所帮助，但对于更一般的环境和任务，这将导致构建成功的活动识别系统的机会较低，时间较长。
- en: Secondly, only shallow features can be learned according to human expertise (Yang
    et al., [2015](#bib.bib66)). Those shallow features often refer to some statistical
    information including mean, variance, frequency and amplitude etc. They can only
    be used to recognize low-level activities like walking or running, and hard to
    infer high-level or context-aware activities (Yang, [2009](#bib.bib67)). For instance,
    having coffee is more complex and nearly impossible to be recognized by using
    only shallow features.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，根据人类专业知识，只能学习浅层特征（Yang 等，[2015](#bib.bib66)）。这些浅层特征通常指一些统计信息，包括均值、方差、频率和幅度等。它们只能用于识别低层次的活动，如行走或跑步，难以推断高层次或上下文感知的活动（Yang，[2009](#bib.bib67)）。例如，喝咖啡更为复杂，几乎不可能仅通过浅层特征来识别。
- en: Thirdly, conventional PR approaches often require a large amount of well-labeled
    data to train the model. However, most of the activity data are remaining unlabeled
    in real applications. Thus, these models’ performance is undermined in unsupervised
    learning tasks (Bengio, [2013](#bib.bib5)). In contrast, existing deep generative
    networks (Hinton et al., [2006](#bib.bib24)) are able to exploit the unlabeled
    samples for model training.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，传统 PR 方法通常需要大量的标记数据来训练模型。然而，在实际应用中，大多数活动数据仍然没有标记。因此，在无监督学习任务中，这些模型的性能受到影响（Bengio，[2013](#bib.bib5)）。相比之下，现有的深度生成网络能够利用未标记样本进行模型训练（Hinton
    等，[2006](#bib.bib24)）。
- en: Moreover, most existing PR models mainly focus on learning from static data;
    while activity data in real life are coming in stream, requiring robust online
    and incremental learning.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，大多数现有的PR模型主要集中在从静态数据中学习；而现实生活中的活动数据是连续流动的，需要强大的在线和增量学习。
- en: 'Deep learning tends to overcome those limitations. Fig. [2](#S2.F2 "Fig. 2
    ‣ 2.2 Why Deep Learning? ‣ 2 Background ‣ Deep Learning for Sensor-based Activity
    Recognition: A Survey") shows how deep learning works for HAR with different types
    of networks. Compared to Fig. [1](#S1.F1 "Fig. 1 ‣ 1 Introduction ‣ Deep Learning
    for Sensor-based Activity Recognition: A Survey"), the feature extraction and
    model building procedures are often performed simultaneously in the deep learning
    models. The features can be learned automatically through the network instead
    of being manually designed. Besides, the deep neural network can also extract
    high-level representation in deep layer, which makes it more suitable for complex
    activity recognition tasks. When faced with a large amount of unlabeled data,
    deep generative models (Hinton et al., [2006](#bib.bib24)) are able to exploit
    the unlabeled data for model training. What’s more, deep learning models trained
    on a large-scale labeled dataset can usually be transferred to new tasks where
    there are few or none labels.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '深度学习倾向于克服这些限制。图[2](#S2.F2 "Fig. 2 ‣ 2.2 Why Deep Learning? ‣ 2 Background ‣
    Deep Learning for Sensor-based Activity Recognition: A Survey")展示了深度学习如何通过不同类型的网络进行HAR。与图[1](#S1.F1
    "Fig. 1 ‣ 1 Introduction ‣ Deep Learning for Sensor-based Activity Recognition:
    A Survey")相比，深度学习模型中的特征提取和模型构建程序通常是同时进行的。特征可以通过网络自动学习，而不需要手动设计。此外，深度神经网络还可以在深层提取高级表示，这使其更适合复杂的活动识别任务。当面临大量未标记的数据时，深度生成模型（Hinton等，[2006](#bib.bib24)）能够利用未标记的数据进行模型训练。更重要的是，在大规模标记数据集上训练的深度学习模型通常可以迁移到新任务中，即使这些新任务中只有少量或没有标签。'
- en: '![Refer to caption](img/535a0c843008c622c191095cf8f7057f.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/535a0c843008c622c191095cf8f7057f.png)'
- en: 'Fig. 2: An illustration of sensor-based activity recognition using deep learning
    approaches.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：使用深度学习方法的传感器基础活动识别示意图。
- en: 'In the following sections, we mainly summarize the existing work based on the
    pipeline of HAR: (a) sensor modality, (b) deep model, and (c) application.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们主要总结了基于HAR流程的现有工作：（a）传感器模式，（b）深度模型，以及（c）应用。
- en: 3 Sensor Modality
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 传感器模式
- en: 'Although some HAR approaches can be generalized to all sensor modalities, most
    of them are only specific to certain types. According to (Chavarriaga et al.,
    [2013](#bib.bib8)), we mainly classify those modalities into three aspects: body-worn
    sensors, object sensors, and ambient sensors. Table [1](#S3.T1 "Table 1 ‣ 3.1
    Body-worn Sensor ‣ 3 Sensor Modality ‣ Deep Learning for Sensor-based Activity
    Recognition: A Survey") briefly outlines all the modalities.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '虽然一些HAR方法可以推广到所有传感器模式，但大多数方法仅适用于特定类型的传感器。根据(Chavarriaga等，[2013](#bib.bib8))，我们主要将这些模式分类为三类：穿戴式传感器、物体传感器和环境传感器。表[1](#S3.T1
    "Table 1 ‣ 3.1 Body-worn Sensor ‣ 3 Sensor Modality ‣ Deep Learning for Sensor-based
    Activity Recognition: A Survey")简要概述了所有这些模式。'
- en: 3.1 Body-worn Sensor
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 穿戴式传感器
- en: Body-worn sensors are one of the most common modalities in HAR. Those sensors
    are often worn by the users, such as an accelerometer, magnetometer, and gyroscope.
    The acceleration and angular velocity are changed according to human body movements;
    thus they can infer human activities. Those sensors can often be found on smart
    phones, watches, bands, glasses, and helmets.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 穿戴式传感器是人类活动识别（HAR）中最常见的模式之一。这些传感器通常由用户佩戴，例如加速度计、磁力计和陀螺仪。加速度和角速度会根据人体运动而变化，因此它们可以推测人类活动。这些传感器通常可以在智能手机、手表、手环、眼镜和头盔上找到。
- en: Body-worn sensors were widely used in deep learning based HAR (Chen and Xue,
    [2015](#bib.bib10); Plötz et al., [2011](#bib.bib47); Zeng et al., [2014](#bib.bib70);
    Jiang and Yin, [2015](#bib.bib27); Yang et al., [2015](#bib.bib66)). Among those
    work, the accelerometer is mostly adopted. Gyroscope and magnetometer are also
    frequently used together with the accelerometer. Those sensors are often exploited
    to recognize activities of daily living (ADL) and sports. Instead of extracting
    statistical and frequency features from the movement data, the original signal
    is directly used as inputs for the network.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 穿戴式传感器在基于深度学习的HAR研究中被广泛使用（Chen 和 Xue, [2015](#bib.bib10); Plötz 等, [2011](#bib.bib47);
    Zeng 等, [2014](#bib.bib70); Jiang 和 Yin, [2015](#bib.bib27); Yang 等, [2015](#bib.bib66)）。在这些研究中，加速度计被广泛采用。陀螺仪和磁力计也常常与加速度计一起使用。这些传感器通常用于识别日常活动（ADL）和运动。与从运动数据中提取统计特征和频率特征不同，原始信号直接作为网络的输入。
- en: 'Table 1: Sensor modalities for HAR tasks'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: HAR 任务的传感器模态'
- en: '| Modality | Description | Examples |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 模态 | 描述 | 示例 |'
- en: '| --- | --- | --- |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Body-worn | Worn by the user to describe the body movements | Smartphone,
    watch, or band’s accelerometer, gyroscope etc. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 穿戴式 | 由用户佩戴以描述身体运动 | 智能手机、手表或手环的加速度计、陀螺仪等 |'
- en: '| Object | Attached to objects to capture objects movements | RFID, accelerometer
    on cup etc. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 物体 | 附着在物体上以捕捉物体运动 | RFID、杯子上的加速度计等 |'
- en: '| Ambient | Applied in environment to reflect user interaction | Sound, door
    sensor, WiFi, Bluetooth etc. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 环境 | 应用于环境中以反映用户互动 | 声音、门传感器、WiFi、蓝牙等 |'
- en: '| Hybrid | Crossing sensor boundary | Combination of types, often deployed
    in smart environments |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 混合 | 跨越传感器边界 | 类型的组合，通常部署在智能环境中 |'
- en: 3.2 Object Sensor
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 物体传感器
- en: Object sensors are usually placed on objects to detect the movement of a specific
    object (Chavarriaga et al., [2013](#bib.bib8)). Different from body-worn sensors
    which capture human movements, object sensors are mainly used to detect the movement
    of certain objects in order to infer human activities. For instance, the accelerometer
    attached to a cup can be used to detect the drinking water activity. Radio frequency
    identifier (RFID) tags are typically used as object sensors and deployed in smart
    home environment (Vepakomma et al., [2015](#bib.bib61); Yang et al., [2015](#bib.bib66);
    Fang and Hu, [2014](#bib.bib15)) and medical activities (Li et al., [2016b](#bib.bib38);
    Wang et al., [2016a](#bib.bib63)). The RFID can provide more fine-grained information
    for more complex activity recognition.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 物体传感器通常放置在物体上以检测特定物体的运动（Chavarriaga 等, [2013](#bib.bib8)）。与捕捉人类运动的穿戴式传感器不同，物体传感器主要用于检测某些物体的运动，以推断人类活动。例如，附着在杯子上的加速度计可以用于检测饮水活动。射频识别（RFID）标签通常用作物体传感器，并部署在智能家居环境（Vepakomma
    等, [2015](#bib.bib61); Yang 等, [2015](#bib.bib66); Fang 和 Hu, [2014](#bib.bib15)）和医疗活动（Li
    等, [2016b](#bib.bib38); Wang 等, [2016a](#bib.bib63)）中。RFID可以提供更细粒度的信息以进行更复杂的活动识别。
- en: It should be noted that object sensors are less used than body-worn sensors
    due to the difficulty in its deployment. Besides, the combination of object sensors
    with other types is emerging in order to recognize more high-level activities (Yang,
    [2009](#bib.bib67)).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 应注意，由于部署困难，物体传感器的使用频率低于穿戴式传感器。此外，为了识别更多的高级活动，物体传感器与其他类型的组合正在兴起（Yang, [2009](#bib.bib67)）。
- en: 3.3 Ambient Sensor
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 环境传感器
- en: Ambient sensors are used to capture the interaction between humans and the environment.
    They are usually embedded in users’ smart environment. There are many kinds of
    ambient sensors such as radar, sound sensors, pressure sensors, and temperature
    sensors. Different from object sensors which measure the object movements, ambient
    sensors are used to capture the change of the environment.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 环境传感器用于捕捉人类与环境之间的互动。它们通常嵌入在用户的智能环境中。有许多种环境传感器，如雷达、声音传感器、压力传感器和温度传感器。与测量物体运动的物体传感器不同，环境传感器用于捕捉环境的变化。
- en: Several literature used ambient sensors to recognize daily activities and hand
    gesture (Lane et al., [2015](#bib.bib33); Wang et al., [2016a](#bib.bib63); Kim
    and Toomajian, [2016](#bib.bib31)). Most of the work was tested in the smart home
    environment. Same as object sensors, the deployment of ambient sensors is also
    difficult. In addition, ambient sensors are easily affected by the environment,
    and only certain types of activities can be robustly inferred.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一些文献使用环境传感器来识别日常活动和手势（Lane et al., [2015](#bib.bib33)；Wang et al., [2016a](#bib.bib63)；Kim
    and Toomajian, [2016](#bib.bib31)）。大多数工作在智能家居环境中进行了测试。与对象传感器一样，环境传感器的部署也很困难。此外，环境传感器容易受到环境的影响，只有某些类型的活动可以被可靠地推断。
- en: 3.4 Hybrid Sensor
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 混合传感器
- en: Some work combined different types of sensors for HAR. As shown in (Hayashi
    et al., [2015](#bib.bib23)), combining acceleration with acoustic information
    could improve the accuracy of HAR. Ambient sensors are also used together with
    object sensors; hence they can record both the object movements and environment
    state. (Vepakomma et al., [2015](#bib.bib61)) designed a smart home environment
    called A-Wristocracy, where a large number of fine-grained and complex activities
    of multiple occupants can be recognized through body-worn, object, and ambient
    sensors. It is obvious that the combination of sensors is capable of capturing
    rich information of human activities, which is also possible for a real smart
    home system in the future.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究结合了不同类型的传感器用于HAR。如（Hayashi et al., [2015](#bib.bib23)）所示，将加速度与声学信息结合可以提高HAR的准确性。环境传感器也与对象传感器一起使用，因此它们可以记录物体运动和环境状态。（Vepakomma
    et al., [2015](#bib.bib61)）设计了一个名为A-Wristocracy的智能家居环境，其中多个占用者的大量精细复杂的活动可以通过佩戴式、对象和环境传感器识别。显然，传感器的组合能够捕捉丰富的人类活动信息，这在未来的智能家居系统中也是可能的。
- en: 4 Deep Model
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 深度模型
- en: 'In this section, we investigate the deep learning models used in HAR tasks.
    Table [2](#S4.T2 "Table 2 ‣ 4.2 Convolutional Neural Network ‣ 4 Deep Model ‣
    Deep Learning for Sensor-based Activity Recognition: A Survey") lists all the
    models.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们调查了在HAR任务中使用的深度学习模型。表[2](#S4.T2 "表 2 ‣ 4.2 卷积神经网络 ‣ 4 深度模型 ‣ 基于传感器的活动识别的深度学习：综述")列出了所有模型。
- en: 4.1 Deep Neural Network
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 深度神经网络
- en: Deep neural network (DNN) is developed from artificial neural network (ANN).
    Traditional ANN often contains very few hidden layers (shallow) while DNN contains
    more (deep). With more layers, DNN is more capable of learning from large data.
    DNN usually serves as the dense layer of other deep models. For example, in a
    convolution neural network, several dense layers are often added after the convolution
    layers. In this part, we mainly focus on DNN as a single model, while in other
    sections we will discuss the dense layer.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络（DNN）是从人工神经网络（ANN）发展而来的。传统的ANN通常包含很少的隐藏层（浅层），而DNN包含更多的隐藏层（深层）。随着层数的增加，DNN能够从大量数据中学习更多。DNN通常作为其他深度模型的密集层。例如，在卷积神经网络中，卷积层后通常会添加几个密集层。在这一部分，我们主要关注DNN作为单一模型，而在其他部分我们将讨论密集层。
- en: (Vepakomma et al., [2015](#bib.bib61)) first extracted hand-engineered features
    from the sensors, then those features are fed into a DNN model. Similarly, (Walse
    et al., [2016](#bib.bib62)) performed PCA before using DNN. In those work, DNN
    only served as a classification model after hand-crafted feature extraction, hence
    they may not generalize well. And the network was rather shallow. (Hammerla et al.,
    [2016](#bib.bib21)) used a 5-hidden-layer DNN to perform automatic feature learning
    and classification with improved performance. Those work indicated that, when
    the HAR data is multi-dimensional and activities are more complex, more hidden
    layers can help the model train well since their representation capability is
    stronger (Bengio, [2013](#bib.bib5)). However, more details should be considered
    in certain situations to help the model fine-tune better.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: （Vepakomma et al., [2015](#bib.bib61)）首先从传感器中提取手工工程特征，然后将这些特征输入到DNN模型中。类似地，（Walse
    et al., [2016](#bib.bib62)）在使用DNN之前进行了PCA。在这些工作中，DNN仅作为手工特征提取后的分类模型，因此它们可能不能很好地泛化。而且网络相当浅。（Hammerla
    et al., [2016](#bib.bib21)）使用了一个5层隐藏层的DNN进行自动特征学习和分类，并取得了更好的性能。这些工作表明，当HAR数据是多维的且活动更复杂时，更多的隐藏层可以帮助模型更好地训练，因为它们的表示能力更强（Bengio,
    [2013](#bib.bib5)）。然而，在某些情况下，还需考虑更多细节以帮助模型更好地微调。
- en: 4.2 Convolutional Neural Network
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 卷积神经网络
- en: 'Convolutional Neural Network (ConvNets, or CNN) leverages three important ideas:
    sparse interactions, parameter sharing, and equivariant representations (LeCun
    et al., [2015](#bib.bib35)). After convolution, there are usually pooling and
    fully-connected layers, which perform classification or regression tasks.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（ConvNets或CNN）利用了三个重要的思想：稀疏交互、参数共享和等变表示（LeCun等，[2015](#bib.bib35)）。经过卷积后，通常会有池化和全连接层，这些层执行分类或回归任务。
- en: 'CNN is competent to extract features from signals and it has achieved promising
    results in image classification, speech recognition, and text analysis. When applied
    to time series classification like HAR, CNN has two advantages over other models:
    local dependency and scale invariance. Local dependency means the nearby signals
    in HAR are likely to be correlated, while scale invariance refers to the scale-invariant
    for different paces or frequencies. Due to the effectiveness of CNN, most of the
    surveyed work focused on this area.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: CNN擅长从信号中提取特征，并在图像分类、语音识别和文本分析中取得了良好效果。在应用于时间序列分类（如HAR）时，CNN相较于其他模型有两个优势：局部依赖性和尺度不变性。局部依赖性指的是HAR中的相邻信号可能相关，而尺度不变性指的是不同步伐或频率下的尺度不变。由于CNN的有效性，大多数调研工作集中在这一领域。
- en: 'When applying CNN to HAR, there are several aspects to be considered: input
    adaptation, pooling, and weight-sharing.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在将CNN应用于HAR时，需要考虑多个方面：输入适配、池化和权重共享。
- en: '1) Input adaptation. Unlike images, most HAR sensors produce time series readings
    such as acceleration signal, which is temporal multi-dimensional 1D readings.
    Input adaptation is necessary before applying CNN to those inputs. The main idea
    is to adapt the inputs in order to form a virtual image. There are mainly two
    types of adaptation: model-driven and data-driven.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 1) 输入适配。与图像不同，大多数HAR传感器产生的是时间序列读数，例如加速度信号，这是时间上的多维1D读数。在将CNN应用于这些输入之前，输入适配是必要的。主要思想是将输入适配成虚拟图像。适配主要有两种类型：模型驱动和数据驱动。
- en: •
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Data-driven approach treats each dimension as a channel, then performs 1D convolution
    on them. After convolution and pooling, the outputs of each channel are flattened
    to unified DNN layers. A very early work is (Zeng et al., [2014](#bib.bib70)),
    where each dimension of the accelerometer was treated as one channel like RGB
    of an image, then the convolution and pooling were performed separately. (Yang
    et al., [2015](#bib.bib66)) further proposed to unify and share weights in multi-sensor
    CNN by using 1D convolution in the same temporal window. Along with this line,
    (Chen and Xue, [2015](#bib.bib10)) resized the convolution kernel to obtain the
    best kernel for HAR data. Other similar work include (Hammerla et al., [2016](#bib.bib21);
    Sathyanarayana et al., [2016](#bib.bib57); Pourbabaee et al., [2017](#bib.bib48)).
    This data-driven approach treats the 1D sensor reading as a 1D image, which is
    simple and easy to implement. The disadvantage of this approach is the ignorance
    of dependencies between dimension and sensors, which may influence the performance.
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据驱动方法将每个维度视为一个通道，然后对它们进行1D卷积。经过卷积和池化后，每个通道的输出被展平为统一的DNN层。一项较早的工作是（Zeng等，[2014](#bib.bib70)），其中将加速度计的每个维度视为像图像的RGB一样的通道，然后分别进行卷积和池化。（Yang等，[2015](#bib.bib66)）进一步提出通过在相同时间窗口内使用1D卷积来统一和共享多传感器CNN中的权重。在这方面，（Chen和Xue，[2015](#bib.bib10)）调整了卷积核的大小，以获得最佳的HAR数据卷积核。其他类似的工作包括（Hammerla等，[2016](#bib.bib21)；Sathyanarayana等，[2016](#bib.bib57)；Pourbabaee等，[2017](#bib.bib48)）。这种数据驱动方法将1D传感器读数视为1D图像，简单易行。然而，这种方法的缺点是忽略了维度和传感器之间的依赖关系，这可能会影响性能。
- en: •
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Model-driven approach resizes the inputs to a virtual 2D image so as to adopt
    a 2D convolution. This approach usually pertains to non-trivial input tuning techniques.
    (Ha et al., [2015](#bib.bib19)) combined all dimensions to form an image, while
    (Jiang and Yin, [2015](#bib.bib27)) designed a more complex algorithm to transform
    the time series into an image. In (Singh et al., [2017](#bib.bib59)), pressure
    sensor data was transformed to the image via modality transformation. Other similar
    work include (Ravi et al., [2016](#bib.bib52); Li et al., [2016b](#bib.bib38)).
    This model-driven approach can make use of the temporal correlation of sensor.
    But the map of time series to image is non-trivial task and needs domain knowledge.
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型驱动方法将输入调整为虚拟的 2D 图像以采用 2D 卷积。这种方法通常涉及非平凡的输入调节技术。（Ha 等人，[2015](#bib.bib19)）将所有维度组合形成图像，而（Jiang
    和 Yin，[2015](#bib.bib27)）设计了一个更复杂的算法将时间序列转换为图像。在（Singh 等人，[2017](#bib.bib59)）中，通过模态转换将压力传感器数据转化为图像。其他类似的工作包括（Ravi
    等人，[2016](#bib.bib52)；Li 等人，[2016b](#bib.bib38)）。这种模型驱动方法可以利用传感器的时间相关性。但时间序列到图像的映射是一个非平凡的任务，需要领域知识。
- en: 2) Pooling. The convolution-pooling combination is common in CNN, and most approaches
    performed max or average pooling after convolution (Ha et al., [2015](#bib.bib19);
    Kim and Toomajian, [2016](#bib.bib31); Pourbabaee et al., [2017](#bib.bib48)).
    Apart from avoiding overfitting, pooling can also speed up the training process
    on large data (Bengio, [2013](#bib.bib5)).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 池化。卷积-池化组合在 CNN 中很常见，大多数方法在卷积后执行最大池化或平均池化（Ha 等人，[2015](#bib.bib19)；Kim 和
    Toomajian，[2016](#bib.bib31)；Pourbabaee 等人，[2017](#bib.bib48)）。除了避免过拟合，池化还可以加速大数据上的训练过程（Bengio，[2013](#bib.bib5)）。
- en: 3) Weight-sharing. Weight sharing (Zebin et al., [2016](#bib.bib69); Sathyanarayana
    et al., [2016](#bib.bib57)) is an efficient method to speed up the training process
    on a new task. (Zeng et al., [2014](#bib.bib70)) utilized a relaxed partial weight
    sharing technique since the signal appeared in different units may behave differently.
    (Ha and Choi, [2016](#bib.bib18)) adopted a CNN-pf and CNN-pff structure to investigate
    the performance of different weight-sharing techniques. It is shown in those literature
    that partial weight-sharing could improve the performance of CNN.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 3) 权重共享。权重共享（Zebin 等人，[2016](#bib.bib69)；Sathyanarayana 等人，[2016](#bib.bib57)）是一种高效的加速新任务训练过程的方法。（Zeng
    等人，[2014](#bib.bib70)）利用了一种放松的部分权重共享技术，因为在不同单元中出现的信号可能表现不同。（Ha 和 Choi，[2016](#bib.bib18)）采用了
    CNN-pf 和 CNN-pff 结构来研究不同权重共享技术的性能。文献表明，部分权重共享可以提高 CNN 的性能。
- en: 'Table 2: Deep learning models for HAR tasks'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 用于 HAR 任务的深度学习模型'
- en: '| Model | Description |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| Model | 描述 |'
- en: '| --- | --- |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| DNN | Deep fully-connected network, artificial neural network with deep layers
    |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| DNN | 深度全连接网络，具有深层的人工神经网络 |'
- en: '| CNN | Convolutional neural network, multiple convolution operations for feature
    extraction |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 卷积神经网络，通过多个卷积操作进行特征提取 |'
- en: '| RNN | Recurrent neural network, network with time correlations and LSTM |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| RNN | 循环神经网络，具有时间相关性和 LSTM 的网络 |'
- en: '| DBN / RBM | Deep belief network and restricted Boltzmann machine |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| DBN / RBM | 深度信念网络和限制玻尔兹曼机 |'
- en: '| SAE | Stacked autoencoder, feature learning by decoding-encoding autoencoder
    |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| SAE | 堆叠自编码器，通过解码-编码自编码器进行特征学习 |'
- en: '| Hybrid | combination of some deep models |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| Hybrid | 一些深度模型的组合 |'
- en: 4.3 Autoencoder
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 自编码器
- en: Autoencoder learns a latent representation of the input values through the hidden
    layers, which can be considered as an encoding-decoding procedure. The purpose
    of autoencoder is to learn more advanced feature representation via an unsupervised
    learning schema. Stacked autoencoder (SAE) is the stack of some autoencoders.
    SAE treats every layer as the basic model of autoencoder. After several rounds
    of training, the learned features are stacked with labels to form a classifier.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器通过隐藏层学习输入值的潜在表示，这可以被视为编码-解码过程。自编码器的目的是通过无监督学习方案学习更高级的特征表示。堆叠自编码器（SAE）是一些自编码器的堆叠。SAE
    将每一层视为自编码器的基本模型。经过几轮训练后，学习到的特征与标签堆叠形成一个分类器。
- en: (Almaslukh et al., [2017](#bib.bib2); Wang et al., [2016a](#bib.bib63)) used
    SAE for HAR, where they first adopted the greedy layer-wise pre-training (Hinton
    et al., [2006](#bib.bib24)), then performed fine-tuning. Compared to those works,
    (Li et al., [2014](#bib.bib39)) investigated the sparse autoencoder by adding
    KL divergence and noise to the cost function, which indicates that adding sparse
    constraints could improve the performance of HAR. The advantage of SAE is that
    it can perform unsupervised feature learning for HAR, which could be a powerful
    tool for feature extraction. But SAE depends too much on its layers and activation
    functions which may be hard to search the optimal solutions.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: （Almaslukh等人，[2017](#bib.bib2)；Wang等人，[2016a](#bib.bib63)）在HAR中使用SAE，他们首先采用了贪婪逐层预训练（Hinton等人，[2006](#bib.bib24)），然后进行了微调。与那些工作相比，（Li等人，[2014](#bib.bib39)）通过在成本函数中添加KL散度和噪声来研究稀疏自编码器，这表明添加稀疏约束可以改善HAR的性能。SAE的优势在于它可以进行无监督特征学习，这可能是特征提取的强大工具。但是SAE过于依赖其层和激活函数，可能很难找到最佳解决方案。
- en: 4.4 Restricted Boltzmann Machine
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 限制玻尔兹曼机
- en: Restricted Boltzmann machine (RBM) is a bipartite, fully-connected, undirected
    graph consisting of a visible layer and a hidden layer (Hinton et al., [2006](#bib.bib24)).
    The stacked RBM is called deep belief network (DBN) by treating every two consecutive
    layers as an RBM. DBN/RBM is often followed by fully-connected layers.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 限制玻尔兹曼机（RBM）是一个二部图，全连接的无向图，由一个可见层和一个隐藏层组成（Hinton等人，[2006](#bib.bib24)）。堆叠的RBM被称为深信网（DBN），将每两个连续的层视为一个RBM。DBN/RBM通常后面跟随全连接层。
- en: In pre-training, most work applied Gaussian RBM in the first layer while binary
    RBM for the rest layers (Plötz et al., [2011](#bib.bib47); Hammerla et al., [2015](#bib.bib20);
    Lane et al., [2015](#bib.bib33)). For multi-modal sensors, (Radu et al., [2016](#bib.bib51))
    designed a multi-modal RBM where an RBM is constructed for each sensor modality,
    then the output of all the modalities are unified. (Li et al., [2016a](#bib.bib37))
    added pooling after the fully-connected layers to extract the important features.
    (Fang and Hu, [2014](#bib.bib15)) used a contrastive gradient (CG) method to update
    the weight in fine-tuning, which helps the network to search and convergence quickly
    in all directions. (Zhang et al., [2015b](#bib.bib72)) further implemented RBM
    on a mobile phone for offline training, indicating RBM can be very light-weight.
    Similar to autoencoder, RBM/DBN can also perform unsupervised feature learning
    for HAR.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在预训练中，大多数工作在第一层应用高斯RBM，而在其余层应用二值RBM（Plötz等人，[2011](#bib.bib47)；Hammerla等人，[2015](#bib.bib20)；Lane等人，[2015](#bib.bib33)）。对于多模传感器，（Radu等人，[2016](#bib.bib51)）设计了多模态RBM，其中为每个传感器模态构建了一个RBM，然后统一所有模态的输出。（Li等人，[2016a](#bib.bib37)）在全连接层后添加了池化来提取重要特征。（Fang和胡，[2014](#bib.bib15)）使用对比梯度（CG）方法在微调中更新权重，这有助于网络在所有方向上快速搜索和收敛。（Zhang等人，[2015b](#bib.bib72)）进一步在手机上实现了离线训练的RBM，表明RBM可以非常轻量化。与自编码器类似，RBM/DBN也可以执行无监督特征学习用于HAR。
- en: 4.5 Recurrent Neural Network
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 循环神经网络
- en: Recurrent neural network (RNN) is widely used in speech recognition and natural
    language processing by utilizing the temporal correlations between neurons. LSTM
    (long-short term memory) cells are often combined with RNN where LSTM is serving
    as the memory units through gradient descent.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 循环神经网络（RNN）广泛用于利用神经元之间的时间相关性进行语音识别和自然语言处理。长短期记忆（LSTM）单元通常与RNN结合使用，其中LSTM作为内存单元通过梯度下降进行服务。
- en: Few work used RNN for the HAR tasks (Hammerla et al., [2016](#bib.bib21); Inoue
    et al., [2016](#bib.bib26); Edel and Köppe, [2016](#bib.bib14); Guan and Ploetz,
    [2017](#bib.bib17)), where the learning speed and resource consumption are the
    main concerns for HAR. (Inoue et al., [2016](#bib.bib26)) investigated several
    model parameters first and then proposed a relatively good model which can perform
    HAR with high throughput. (Edel and Köppe, [2016](#bib.bib14)) proposed a binarized-BLSTM-RNN
    model, in which the weight parameters, input, and output of all hidden layers
    are all binary values. The main line of RNN based HAR models is dealing with resource-constrained
    environments while still achieve good performance.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 少量作品使用RNN进行HAR任务（Hammerla et al., [2016](#bib.bib21); Inoue et al., [2016](#bib.bib26);
    Edel and Köppe, [2016](#bib.bib14); Guan and Ploetz, [2017](#bib.bib17))，其中学习速度和资源消耗是HAR的主要关注点。
    （Inoue et al., [2016](#bib.bib26)) 首先调查了几个模型参数，然后提出了一个相对良好的模型，可以以高吞吐量执行HAR。 （Edel
    and Köppe, [2016](#bib.bib14)) 提出了一个二进制化的BLSTM-RNN模型，其中所有隐藏层的权重参数、输入和输出都是二进制值。
    RNN基础的HAR模型的主线是处理资源受限环境，同时实现良好的性能。
- en: 'Table 3: Public HAR datasets (A=accelerometer, G=gyroscope, M=magnetometer,
    O=object sensor, AM=ambient sensor, ECG=electrocardiograph)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：公共HAR数据集（A=加速度计，G=陀螺仪，M=磁力计，O=物体传感器，AM=环境传感器，ECG=心电图）
- en: '| ID | Dataset | Type | #Subject | S. Rate | #Activity | #Sample | Sensor |
    Reference |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| ID | 数据集 | 类型 | #主体 | S. Rate | #活动 | #样本 | 传感器 | 参考文献 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| D01 | OPPORTUNITY | ADL | 4 | 32 Hz | 16 | 701,366 | A, G, M, O, AM | (Ordóñez
    and Roggen, [2016](#bib.bib44)) |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| D01 | OPPORTUNITY | ADL | 4 | 32 Hz | 16 | 701,366 | A, G, M, O, AM | (Ordóñez
    and Roggen, [2016](#bib.bib44)) |'
- en: '| D02 | Skoda Checkpoint | Factory | 1 | 96 Hz | 10 | 22,000 | A | (Plötz et al.,
    [2011](#bib.bib47)) |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| D02 | Skoda Checkpoint | Factory | 1 | 96 Hz | 10 | 22,000 | A | (Plötz et al.,
    [2011](#bib.bib47)) |'
- en: '| D03 | UCI Smartphone | ADL | 30 | 50 Hz | 6 | 10,299 | A, G | (Almaslukh
    et al., [2017](#bib.bib2)) |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| D03 | UCI Smartphone | ADL | 30 | 50 Hz | 6 | 10,299 | A, G | (Almaslukh
    et al., [2017](#bib.bib2)) |'
- en: '| D04 | PAMAP2 | ADL | 9 | 100 Hz | 18 | 2,844,868 | A, G, M | (Zheng et al.,
    [2014](#bib.bib76)) |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| D04 | PAMAP2 | ADL | 9 | 100 Hz | 18 | 2,844,868 | A, G, M | (Zheng et al.,
    [2014](#bib.bib76)) |'
- en: '| D05 | USC-HAD | ADL | 14 | 100 Hz | 12 | 2,520,000 | A, G | (Jiang and Yin,
    [2015](#bib.bib27)) |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| D05 | USC-HAD | ADL | 14 | 100 Hz | 12 | 2,520,000 | A, G | (Jiang and Yin,
    [2015](#bib.bib27)) |'
- en: '| D06 | WISDM | ADL | 29 | 20 Hz | 6 | 1,098,207 | A | (Alsheikh et al., [2016](#bib.bib3))
    |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| D06 | WISDM | ADL | 29 | 20 Hz | 6 | 1,098,207 | A | (Alsheikh et al., [2016](#bib.bib3))
    |'
- en: '| D07 | DSADS | ADL | 8 | 25 Hz | 19 | 1,140,000 | A, G, M | (Zhang et al.,
    [2015c](#bib.bib73)) |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| D07 | DSADS | ADL | 8 | 25 Hz | 19 | 1,140,000 | A, G, M | (Zhang et al.,
    [2015c](#bib.bib73)) |'
- en: '| D08 | Ambient kitchen | Food preparation | 20 | 40 Hz | 2 | 55,000 | O |
    (Plötz et al., [2011](#bib.bib47)) |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| D08 | Ambient kitchen | 食品准备 | 20 | 40 Hz | 2 | 55,000 | O | (Plötz et al.,
    [2011](#bib.bib47)) |'
- en: '| D09 | Darmstadt Daily Routines | ADL | 1 | 100 Hz | 35 | 24,000 | A | (Plötz
    et al., [2011](#bib.bib47)) |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| D09 | Darmstadt Daily Routines | ADL | 1 | 100 Hz | 35 | 24,000 | A | (Plötz
    et al., [2011](#bib.bib47)) |'
- en: '| D10 | Actitracker | ADL | 36 | 20 Hz | 6 | 2,980,765 | A | (Zeng et al.,
    [2014](#bib.bib70)) |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| D10 | Actitracker | ADL | 36 | 20 Hz | 6 | 2,980,765 | A | (Zeng et al.,
    [2014](#bib.bib70)) |'
- en: '| D11 | SHO | ADL | 10 | 50 Hz | 7 | 630,000 | A, G, M | (Jiang and Yin, [2015](#bib.bib27))
    |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| D11 | SHO | ADL | 10 | 50 Hz | 7 | 630,000 | A, G, M | (Jiang and Yin, [2015](#bib.bib27))
    |'
- en: '| D12 | BIDMC | Heart failure | 15 | 125 Hz | 2 | >20,000 | ECG | (Zheng et al.,
    [2014](#bib.bib76)) |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| D12 | BIDMC | 心力衰竭 | 15 | 125 Hz | 2 | >20,000 | ECG | (Zheng et al., [2014](#bib.bib76))
    |'
- en: '| D13 | MHEALTH | ADL | 10 | 50 Hz | 12 | 16,740 | A, C, G | (Ha and Choi,
    [2016](#bib.bib18)) |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| D13 | MHEALTH | ADL | 10 | 50 Hz | 12 | 16,740 | A, C, G | (Ha and Choi,
    [2016](#bib.bib18)) |'
- en: '| D14 | Daphnet Gait | Gait | 10 | 64 Hz | 2 | 1,917,887 | A | (Hammerla et al.,
    [2016](#bib.bib21)) |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| D14 | Daphnet Gait | 步态 | 10 | 64 Hz | 2 | 1,917,887 | A | (Hammerla et al.,
    [2016](#bib.bib21)) |'
- en: '| D15 | ActiveMiles | ADL | 10 | 50-200 Hz | 7 | 4,390,726 | A | (Ravì et al.,
    [2017](#bib.bib53)) |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| D15 | ActiveMiles | ADL | 10 | 50-200 Hz | 7 | 4,390,726 | A | (Ravì et al.,
    [2017](#bib.bib53)) |'
- en: '| D16 | HASC | ADL | 1 | 200 Hz | 13 | NA | A | (Hayashi et al., [2015](#bib.bib23))
    |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| D16 | HASC | ADL | 1 | 200 Hz | 13 | NA | A | (Hayashi et al., [2015](#bib.bib23))
    |'
- en: '| D17 | PAF | PAF | 48 | 128 Hz | 2 | 230,400 | EEG | (Pourbabaee et al., [2017](#bib.bib48))
    |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| D17 | PAF | PAF | 48 | 128 Hz | 2 | 230,400 | EEG | (Pourbabaee et al., [2017](#bib.bib48))
    |'
- en: '| D18 | ActRecTut | Gesture | 2 | 32 Hz | 12 | 102,613 | A, G | (Yang et al.,
    [2015](#bib.bib66)) |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| D18 | ActRecTut | 手势 | 2 | 32 Hz | 12 | 102,613 | A, G | (Yang et al., [2015](#bib.bib66))
    |'
- en: '| D19 | Heterogeneous | ADL | 9 | 100-200 Hz | 6 | 43,930,257 | A, G | (Yao
    et al., [2017](#bib.bib68)) |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| D19 | Heterogeneous | ADL | 9 | 100-200 Hz | 6 | 43,930,257 | A, G | (Yao
    et al., [2017](#bib.bib68)) |'
- en: 4.6 Hybrid Model
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 混合模型
- en: Hybrid model is the combination of some deep models.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 混合模型是一些深度模型的组合。
- en: One emerging hybrid model is the combination of CNN and RNN. (Ordóñez and Roggen,
    [2016](#bib.bib44); Yao et al., [2017](#bib.bib68)) provided good examples for
    how to combine CNN and RNN. It is shown in (Ordóñez and Roggen, [2016](#bib.bib44))
    that the performance of ‘CNN + recurrent dense layers’ is better than ‘CNN + dense
    layers’. Similar results are also shown in (Singh et al., [2017](#bib.bib59)).
    The reason is that CNN is able to capture the spatial relationship, while RNN
    can make use of the temporal relationship. Combining CNN and RNN could enhance
    the ability to recognize different activities that have varied time span and signal
    distributions. Other work combined CNN with models such as SAE (Zheng et al.,
    [2016](#bib.bib77)) and RBM (Liu et al., [2016](#bib.bib40)). In those work, CNN
    performs feature extraction, and the generative models can help in speeding up
    the training process. In the future, we expect there will be more research in
    this area.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一种新兴的混合模型是CNN与RNN的结合。（Ordóñez and Roggen, [2016](#bib.bib44); Yao et al., [2017](#bib.bib68)）提供了如何结合CNN和RNN的良好示例。研究表明（Ordóñez
    and Roggen, [2016](#bib.bib44)），‘CNN + recurrent dense layers’的表现优于‘CNN + dense
    layers’。类似的结果也在（Singh et al., [2017](#bib.bib59)）中显示。原因是CNN能够捕捉空间关系，而RNN可以利用时间关系。结合CNN和RNN可以增强识别具有不同时间跨度和信号分布的活动的能力。其他工作将CNN与SAE（Zheng
    et al., [2016](#bib.bib77)）和RBM（Liu et al., [2016](#bib.bib40)）等模型结合。在这些工作中，CNN执行特征提取，生成模型可以帮助加速训练过程。未来，我们期待在这一领域会有更多研究。
- en: 5 Applications
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 应用
- en: HAR is always not the final goal of an application, but it serves as an important
    step in many applications such as skill assessment and smart home assistant. In
    this section, we survey deep learning based HAR from the application perspective.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: HAR通常不是应用的终极目标，但它在许多应用中，如技能评估和智能家居助手，作为一个重要步骤。在本节中，我们从应用角度调查基于深度学习的HAR。
- en: 5.1 Featured Applications
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 特色应用
- en: Most of the surveyed work focused on recognizing activities of daily living
    (ADL) and sports (Zeng et al., [2014](#bib.bib70); Chen and Xue, [2015](#bib.bib10);
    Ronao and Cho, [2016](#bib.bib56); Ravì et al., [2017](#bib.bib53)). Those activities
    of simple movements are easily captured by body-worn sensors. Some research studied
    people’s lifestyle such as sleep (Sathyanarayana et al., [2016](#bib.bib57)) and
    respiration (Khan et al., [2017](#bib.bib29); Hannink et al., [2017](#bib.bib22)).
    The detection of such activities often requires some object and ambient sensors
    such as WiFi and sound, which are rather different from ADL.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 调查的工作大多数集中在识别日常生活活动（ADL）和运动（Zeng et al., [2014](#bib.bib70); Chen and Xue, [2015](#bib.bib10);
    Ronao and Cho, [2016](#bib.bib56); Ravì et al., [2017](#bib.bib53)）。这些简单动作的活动可以通过佩戴在身体上的传感器轻松捕捉。一些研究则探讨了人们的生活方式，如睡眠（Sathyanarayana
    et al., [2016](#bib.bib57)）和呼吸（Khan et al., [2017](#bib.bib29); Hannink et al.,
    [2017](#bib.bib22)）。这种活动的检测通常需要一些物体和环境传感器，如WiFi和声音，这些与ADL有所不同。
- en: It is a developing trend to apply HAR to health and disease issues. Some pioneering
    work has been done with regard to Parkinson’s disease (Hammerla et al., [2015](#bib.bib20)),
    trauma resuscitation (Li et al., [2016a](#bib.bib37), [b](#bib.bib38)) and paroxysmal
    atrial fibrillation (PAF) (Pourbabaee et al., [2017](#bib.bib48)). Disease issues
    are always related to the change of certain body movements or functions, so they
    can be detected using corresponding sensors.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 将HAR应用于健康和疾病问题是一种发展趋势。一些开创性的工作已经完成，如帕金森病（Hammerla et al., [2015](#bib.bib20)）、创伤复苏（Li
    et al., [2016a](#bib.bib37), [b](#bib.bib38)）和阵发性房颤（PAF）（Pourbabaee et al., [2017](#bib.bib48)）。疾病问题总是与某些身体动作或功能的变化有关，因此可以使用相应的传感器进行检测。
- en: Under those circumstances, the association between disease and activity should
    be given more consideration. It is important to use the appropriate sensors. For
    instance, Parkinson’s disease is often related to the frozen of gait, which can
    be reflected by some inertial sensors attached to shoes (Hammerla et al., [2015](#bib.bib20)).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，疾病与活动之间的关联应给予更多关注。使用适当的传感器非常重要。例如，帕金森病通常与步态僵硬有关，这可以通过附加在鞋子上的一些惯性传感器反映（Hammerla
    et al., [2015](#bib.bib20)）。
- en: Other than health and disease, the recognition of high-level activities is helpful
    to learn more resourceful information for HAR. The movement, behavior, environment,
    emotion, and thought are critical parts in recognizing high-level activities.
    However, most work only focused on body movements in smart homes (Vepakomma et al.,
    [2015](#bib.bib61); Fang and Hu, [2014](#bib.bib15)), which is not enough to recognize
    high-level activities. For instance, (Vepakomma et al., [2015](#bib.bib61)) combined
    activity and environment signal to recognize activities in a smart home, but the
    activities are constrained to body movements without more information on user
    emotion and state, which are also important. In the future, we expect there will
    be more research in this area.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 除了健康和疾病，高级活动的识别对于了解更多丰富的信息非常有帮助。运动、行为、环境、情绪和思维是识别高级活动的关键部分。然而，大多数工作只集中在智能家居中的身体运动（Vepakomma等人，[2015](#bib.bib61);
    方和胡，[2014](#bib.bib15)），这不足以识别高级活动。例如，（Vepakomma等人，[2015](#bib.bib61)）结合活动和环境信号在智能家居中识别活动，但这些活动仅限于身体运动，缺乏关于用户情绪和状态等更多信息，这些信息同样重要。未来，我们预计在这一领域将有更多的研究。
- en: 5.2 Benchmark Datasets
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 基准数据集
- en: 'We extensively explore the benchmark datasets for deep learning based HAR.
    Basically, there are two types of data acquisition schemes: self data collection
    and public datasets.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们广泛探讨了基于深度学习的HAR基准数据集。基本上，有两种数据采集方案：自我数据收集和公开数据集。
- en: •
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Self data collection: Some work performed their own data collection (e.g. (Chen
    and Xue, [2015](#bib.bib10); Zhang et al., [2015b](#bib.bib72); Bhattacharya and
    Lane, [2016](#bib.bib6); Zhang et al., [2015a](#bib.bib71))). Very detailed efforts
    are required for self data collection, and it is rather tedious to process the
    collected data.'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自我数据收集：一些工作进行了自己的数据收集（例如（陈和薛，[2015](#bib.bib10); 张等人，[2015b](#bib.bib72); Bhattacharya和Lane，[2016](#bib.bib6);
    张等人，[2015a](#bib.bib71)））。自我数据收集需要非常详细的努力，并且处理收集到的数据相当繁琐。
- en: •
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Public datasets: There are already many public HAR datasets that are adopted
    by most researchers (e.g. (Plötz et al., [2011](#bib.bib47); Ravi et al., [2016](#bib.bib52);
    Hammerla et al., [2016](#bib.bib21))). By summarizing existing literature, we
    present several widely used public datasets in Table [3](#S4.T3 "Table 3 ‣ 4.5
    Recurrent Neural Network ‣ 4 Deep Model ‣ Deep Learning for Sensor-based Activity
    Recognition: A Survey").'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 公开数据集：已有许多公开的HAR数据集被大多数研究人员采用（例如（Plötz等人，[2011](#bib.bib47); Ravi等人，[2016](#bib.bib52);
    Hammerla等人，[2016](#bib.bib21)））。通过总结现有文献，我们在表[3](#S4.T3 "表 3 ‣ 4.5 递归神经网络 ‣ 4
    深度模型 ‣ 基于传感器的活动识别深度学习调查")中列出了几个广泛使用的公开数据集。
- en: 'Table 4: Summation of existing works based on the three aspects: sensor modality,
    deep model and application (in literature order)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：基于三个方面的现有作品总结：传感器模态、深度模型和应用（按文献顺序）
- en: '| Literature | Sensor Modality | Deep Model | Application | Dataset |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 文献 | 传感器模态 | 深度模型 | 应用 | 数据集 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| (Almaslukh et al., [2017](#bib.bib2)) | Body-worn | SAE | ADL | D03 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| (Almaslukh等人，[2017](#bib.bib2)) | 身体佩戴 | SAE | ADL | D03 |'
- en: '| (Alsheikh et al., [2016](#bib.bib3)) | Body-worn | RBM | ADL, factory, Parkinson
    | D02, D06, D14 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| (Alsheikh等人，[2016](#bib.bib3)) | 身体佩戴 | RBM | ADL、工厂、帕金森 | D02、D06、D14 |'
- en: '| (Bhattacharya and Lane, [2016](#bib.bib6)) | Body-worn, ambiemt | RBM | Gesture,
    ADL, transportation | Self, D01 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| (Bhattacharya和Lane，[2016](#bib.bib6)) | 身体佩戴、环境 | RBM | 手势、ADL、交通 | 自我、D01
    |'
- en: '| (Chen and Xue, [2015](#bib.bib10)) | Body-worn | CNN | ADL | Self |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| (陈和薛，[2015](#bib.bib10)) | 身体佩戴 | CNN | ADL | 自我 |'
- en: '| (Chen et al., [2016b](#bib.bib11)) | Body-worn | CNN | ADL | D06 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| (陈等人，[2016b](#bib.bib11)) | 身体佩戴 | CNN | ADL | D06 |'
- en: '| (Cheng and Scotland, [2017](#bib.bib12)) | Body-worn | DNN | Parkinson |
    Self |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| (程和苏格兰，[2017](#bib.bib12)) | 身体佩戴 | DNN | 帕金森 | 自我 |'
- en: '| (Edel and Köppe, [2016](#bib.bib14)) | Body-worn | RNN | ADL | D01, D04,
    Self |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| (埃德尔和克珀，[2016](#bib.bib14)) | 身体佩戴 | RNN | ADL | D01、D04、自我 |'
- en: '| (Fang and Hu, [2014](#bib.bib15)) | Object, ambient | DBN | ADL | Self |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| (方和胡，[2014](#bib.bib15)) | 物体、环境 | DBN | ADL | 自我 |'
- en: '| (Gjoreski et al., [2016](#bib.bib16)) | Body-worn | CNN | ADL | Self, D01
    |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| (Gjoreski等人，[2016](#bib.bib16)) | 身体佩戴 | CNN | ADL | 自我、D01 |'
- en: '| (Guan and Ploetz, [2017](#bib.bib17)) | Body-worn, object, ambient | RNN
    | ADL, smart home | D01, D02, D04 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| (关和普莱茨, [2017](#bib.bib17)) | 身体佩戴、物体、环境 | RNN | ADL、智能家居 | D01、D02、D04 |'
- en: '| (Ha et al., [2015](#bib.bib19)) | Body-worn | CNN | Factory, health | D02,
    D13 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| (哈等人，[2015](#bib.bib19)) | 身体佩戴 | CNN | 工厂、健康 | D02、D13 |'
- en: '| (Ha and Choi, [2016](#bib.bib18)) | Body-worn | CNN | ADL, health | D13 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| (哈和崔，[2016](#bib.bib18)) | 身体佩戴 | CNN | ADL、健康 | D13 |'
- en: '| (Hammerla et al., [2015](#bib.bib20)) | Body-worn | RBM | Parkinson | Self
    |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| (Hammerla et al., [2015](#bib.bib20)) | 穿戴式 | RBM | 帕金森 | 自我 |'
- en: '| (Hammerla et al., [2016](#bib.bib21)) | Body-worn, object, ambient | DNN,
    CNN, RNN | ADL, smart home, gait | D01, D04, D14 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| (Hammerla et al., [2016](#bib.bib21)) | 穿戴式、物体、环境 | DNN、CNN、RNN | ADL、智能家居、步态
    | D01、D04、D14 |'
- en: '| (Hannink et al., [2017](#bib.bib22)) | Body-worn | CNN | Gait | Self |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| (Hannink et al., [2017](#bib.bib22)) | 穿戴式 | CNN | 步态 | 自我 |'
- en: '| (Hayashi et al., [2015](#bib.bib23)) | Body-worn, ambient | RBM | ADL, smart
    home | D16 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| (Hayashi et al., [2015](#bib.bib23)) | 穿戴式、环境 | RBM | ADL、智能家居 | D16 |'
- en: '| (Inoue et al., [2016](#bib.bib26)) | Body-worn | RNN | ADL | D16 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| (Inoue et al., [2016](#bib.bib26)) | 穿戴式 | RNN | ADL | D16 |'
- en: '| (Jiang and Yin, [2015](#bib.bib27)) | Body-worn | CNN | ADL | D03, D05, D11
    |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| (Jiang and Yin, [2015](#bib.bib27)) | 穿戴式 | CNN | ADL | D03、D05、D11 |'
- en: '| (Khan et al., [2017](#bib.bib29)) | Ambient | CNN | Respiration | Self |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| (Khan et al., [2017](#bib.bib29)) | 环境 | CNN | 呼吸 | 自我 |'
- en: '| (Kim and Toomajian, [2016](#bib.bib31)) | Ambient | CNN | Hand gesture |
    Self |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| (Kim and Toomajian, [2016](#bib.bib31)) | 环境 | CNN | 手势 | 自我 |'
- en: '| (Kim and Li, [2017](#bib.bib30)) | Body-worn | CNN | ADL | Self |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| (Kim and Li, [2017](#bib.bib30)) | 穿戴式 | CNN | ADL | 自我 |'
- en: '| (Lane and Georgiev, [2015](#bib.bib32)) | Body-worn, ambient | RBM | ADL,
    emotion | Self |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| (Lane and Georgiev, [2015](#bib.bib32)) | 穿戴式、环境 | RBM | ADL、情感 | 自我 |'
- en: '| (Lane et al., [2015](#bib.bib33)) | Ambient | RBM | ADL | Self |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| (Lane et al., [2015](#bib.bib33)) | 环境 | RBM | ADL | 自我 |'
- en: '| (Lee et al., [2017](#bib.bib36)) | Body-worn | CNN | ADL | Self |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| (Lee et al., [2017](#bib.bib36)) | 穿戴式 | CNN | ADL | 自我 |'
- en: '| (Li et al., [2016a](#bib.bib37)) | Object | RBM | Patient resuscitation |
    Self |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| (Li et al., [2016a](#bib.bib37)) | 物体 | RBM | 患者复苏 | 自我 |'
- en: '| (Li et al., [2016b](#bib.bib38)) | Object | CNN | Patient resuscitation |
    Self |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| (Li et al., [2016b](#bib.bib38)) | 物体 | CNN | 患者复苏 | 自我 |'
- en: '| (Li et al., [2014](#bib.bib39)) | Body-worn | SAE | ADL | D03 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| (Li et al., [2014](#bib.bib39)) | 穿戴式 | SAE | ADL | D03 |'
- en: '| (Liu et al., [2016](#bib.bib40)) | Body-worn | CNN, RBM | ADL | Self |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| (Liu et al., [2016](#bib.bib40)) | 穿戴式 | CNN、RBM | ADL | 自我 |'
- en: '| (Mohammed and Tashev, [2017](#bib.bib41)) | Body-worn | CNN | ADL, gesture
    | Self |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| (Mohammed and Tashev, [2017](#bib.bib41)) | 穿戴式 | CNN | ADL、手势 | 自我 |'
- en: '| (Morales and Roggen, [2016](#bib.bib42)) | Body-worn | CNN | ADL, smart home
    | D01, D02 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| (Morales and Roggen, [2016](#bib.bib42)) | 穿戴式 | CNN | ADL、智能家居 | D01、D02
    |'
- en: '| (Murad and Pyun, [2017](#bib.bib43)) | Body-worn | RNN | ADL, smart home
    | D01, D02, D05, D14 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| (Murad and Pyun, [2017](#bib.bib43)) | 穿戴式 | RNN | ADL、智能家居 | D01、D02、D05、D14
    |'
- en: '| (Ordóñez and Roggen, [2016](#bib.bib44)) | Body-worn | CNN, RNN | ADL, gesture,
    posture, factory | D01, D02 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| (Ordóñez and Roggen, [2016](#bib.bib44)) | 穿戴式 | CNN、RNN | ADL、手势、姿态、工厂 |
    D01、D02 |'
- en: '| (Panwar et al., [2017](#bib.bib46)) | Body-worn | CNN | ADL | Self |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| (Panwar et al., [2017](#bib.bib46)) | 穿戴式 | CNN | ADL | 自我 |'
- en: '| (Plötz et al., [2011](#bib.bib47)) | Body-worn, object | RBM | ADL, food
    preparation, factory | D01, D02, D08, D14 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| (Plötz et al., [2011](#bib.bib47)) | 穿戴式、物体 | RBM | ADL、食物准备、工厂 | D01、D02、D08、D14
    |'
- en: '| (Pourbabaee et al., [2017](#bib.bib48)) | Body-worn | CNN | PAF disease |
    D17 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| (Pourbabaee et al., [2017](#bib.bib48)) | 穿戴式 | CNN | PAF疾病 | D17 |'
- en: '| (Radu et al., [2016](#bib.bib51)) | Body-worn | RBM | ADL | D19 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| (Radu et al., [2016](#bib.bib51)) | 穿戴式 | RBM | ADL | D19 |'
- en: '| (Ravi et al., [2016](#bib.bib52)) | Body-worn | CNN | ADL, factory | D02,
    D06, D14, D15 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| (Ravi et al., [2016](#bib.bib52)) | 穿戴式 | CNN | ADL、工厂 | D02、D06、D14、D15
    |'
- en: '| (Ravì et al., [2017](#bib.bib53)) | Body-worn | CNN | ADL, factory, Parkinson
    | D02, D06, D14, D15 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| (Ravì et al., [2017](#bib.bib53)) | 穿戴式 | CNN | ADL、工厂、帕金森 | D02、D06、D14、D15
    |'
- en: '| (Ronao and Cho, [2015a](#bib.bib54), [b](#bib.bib55), [2016](#bib.bib56))
    | Body-worn | CNN | ADL | D03 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| (Ronao and Cho, [2015a](#bib.bib54), [b](#bib.bib55), [2016](#bib.bib56))
    | 穿戴式 | CNN | ADL | D03 |'
- en: '| (Sathyanarayana et al., [2016](#bib.bib57)) | Body-worn | CNN, RNN, DNN |
    ADL, sleep | Self |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| (Sathyanarayana et al., [2016](#bib.bib57)) | 穿戴式 | CNN、RNN、DNN | ADL、睡眠
    | 自我 |'
- en: '| (Singh et al., [2017](#bib.bib59)) | Ambient | CNN, RNN | Gait | NA |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| (Singh et al., [2017](#bib.bib59)) | 环境 | CNN、RNN | 步态 | NA |'
- en: '| (Vepakomma et al., [2015](#bib.bib61)) | Body-worn, object, ambient | DNN
    | ADL | Self |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| (Vepakomma et al., [2015](#bib.bib61)) | 穿戴式、物体、环境 | DNN | ADL | 自我 |'
- en: '| (Walse et al., [2016](#bib.bib62)) | Body-worn | DNN | ADL | D03 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| (Walse et al., [2016](#bib.bib62)) | 穿戴式 | DNN | ADL | D03 |'
- en: '| (Wang et al., [2016b](#bib.bib65)) | Body-worn, ambient | CNN | ADL, location
    | Self |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| (Wang et al., [2016b](#bib.bib65)) | 穿戴式、环境 | CNN | ADL、位置 | 自我 |'
- en: '| (Wang et al., [2016a](#bib.bib63)) | Object, ambient | SAE | ADL | NA |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| (Wang et al., [2016a](#bib.bib63)) | 物体、环境 | SAE | ADL | NA |'
- en: '| (Yang et al., [2015](#bib.bib66)) | Body-worn, object, ambient | CNN | ADL,
    smart home, gesture | D01, D18 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| (Yang et al., [2015](#bib.bib66)) | 穿戴式、物体、环境 | CNN | ADL、智能家居、手势 | D01、D18
    |'
- en: '| (Yao et al., [2017](#bib.bib68)) | Body-worn, object | CNN, RNN | Cartrack,
    ADL | Self, D19 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| (姚等人，[2017](#bib.bib68)) | 身体佩戴、物体 | CNN、RNN | 车辆追踪、ADL（日常活动） | 个人、D19 |'
- en: '| (Zebin et al., [2016](#bib.bib69)) | Body-worn | CNN | ADL | Self |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| (Zebin等人，[2016](#bib.bib69)) | 身体佩戴 | CNN | ADL（日常活动） | 个人 |'
- en: '| (Zeng et al., [2014](#bib.bib70)) | Body-worn, ambient, object | CNN | ADL,
    smart home, factory | D01, D02, D10 |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| (曾等人，[2014](#bib.bib70)) | 身体佩戴、环境、物体 | CNN | ADL（日常活动）、智能家居、工厂 | D01、D02、D10
    |'
- en: '| (Zhang et al., [2015a](#bib.bib71)) | Body-worn | DNN | ADL | Self |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| (张等人，[2015a](#bib.bib71)) | 身体佩戴 | DNN | ADL（日常活动） | 个人 |'
- en: '| (Zhang et al., [2015b](#bib.bib72)) | Body-worn | RBM | ADL | Self |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| (张等人，[2015b](#bib.bib72)) | 身体佩戴 | RBM | ADL（日常活动） | 个人 |'
- en: '| (Zhang et al., [2015c](#bib.bib73)) | Body-worn | DBN | ADL, smart home |
    D01, D05, D07 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| (张等人，[2015c](#bib.bib73)) | 身体佩戴 | DBN | ADL（日常活动）、智能家居 | D01、D05、D07 |'
- en: '| (Zhang et al., [2017b](#bib.bib75)) | Object | CNN | Medical | Self |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| (张等人，[2017b](#bib.bib75)) | 物体 | CNN | 医疗 | 个人 |'
- en: '| (Zhang et al., [2017a](#bib.bib74)) | Body-worn | DNN | ADL | Self |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| (张等人，[2017a](#bib.bib74)) | 身体佩戴 | DNN | ADL（日常活动） | 个人 |'
- en: '| (Zheng et al., [2016](#bib.bib77)) | Body-worn | CNN, SAE | ADL | D04 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| (郑等人，[2016](#bib.bib77)) | 身体佩戴 | CNN、SAE | ADL（日常活动） | D04 |'
- en: '| (Zheng et al., [2014](#bib.bib76)) | Body-worn | CNN | ADL, heart failure
    | D04, D14 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| (郑等人，[2014](#bib.bib76)) | 身体佩戴 | CNN | ADL（日常活动）、心力衰竭 | D04、D14 |'
- en: 6 Summary and Discussion
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 总结与讨论
- en: 'Table [4](#S5.T4 "Table 4 ‣ 5.2 Benchmark Datasets ‣ 5 Applications ‣ Deep
    Learning for Sensor-based Activity Recognition: A Survey") presents all the surveyed
    work in this article. We can make several observations based on the table.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [4](#S5.T4 "Table 4 ‣ 5.2 Benchmark Datasets ‣ 5 Applications ‣ Deep Learning
    for Sensor-based Activity Recognition: A Survey") 展示了本文中调查的所有工作。根据该表可以得出几个观察结果。'
- en: 1) Sensor deployment and preprocessing. Choosing the suitable sensors is critical
    for successful HAR. In surveyed literature, body-worn sensors serve as the most
    common modalities and accelerometer is mostly used. The reasons are two folds.
    Firstly, a lot of wearable devices such as smartphones or watches are equipped
    with an accelerometer, which is easy to access. Secondly, the accelerometer is
    competent to recognize many types of daily activities since most of them are simple
    body movements. Compared to body-worn sensors, object and ambient sensors are
    better at recognizing activities related to context and environment such as having
    coffee. Therefore, it is suggested to use body-worn sensors (mostly accelerometer+gyroscope)
    for ADL and sports activities. If the activities are pertaining to some semantic
    meaning but more than simple body movements, it is better to combine the object
    and ambient sensors. In addition, there are few public datasets for object and
    ambient sensors probably because of privacy issues and deployment difficulty of
    the data collecting system. We expect there will be more open datasets regarding
    those sensors.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '1) 传感器部署和预处理。选择合适的传感器对成功的人体活动识别（HAR）至关重要。在调查的文献中，身体佩戴传感器作为最常见的模式，加速度计被广泛使用。原因有两点。首先，许多可穿戴设备如智能手机或手表配备了加速度计，易于获取。其次，加速度计能够识别许多类型的日常活动，因为大多数都是简单的身体运动。与身体佩戴传感器相比，物体和环境传感器更擅长识别与上下文和环境相关的活动，如喝咖啡。因此，建议在ADL和运动活动中使用身体佩戴传感器（主要是加速度计+陀螺仪）。如果活动涉及某种语义含义而不仅仅是简单的身体运动，则最好结合物体和环境传感器。此外，关于物体和环境传感器的公开数据集较少，可能是由于隐私问题和数据收集系统的部署困难。我们预期将会有更多关于这些传感器的开放数据集。  '
- en: Sensor placement is also important. Most body-worn sensors are placed on the
    dominant wrist, waist, and the dominant hip pocket. This placement strategy can
    help to recognize most common daily activities. However, when it comes to object
    and ambient sensors, it is critical to deploy them in a non-invasive way. Those
    sensors are not usually interacting with users directly, so it is critical to
    collect the data naturally and non-invasively.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 传感器部署也很重要。大多数身体佩戴传感器放置在主导手腕、腰部和主导臀袋上。这种放置策略有助于识别大多数日常活动。然而，当涉及到物体和环境传感器时，非侵入性的部署方式至关重要。这些传感器通常不直接与用户交互，因此自然且非侵入地收集数据至关重要。
- en: Before using deep models, the raw sensor data need to be preprocessed accordingly.
    There are two important aspects. The first aspect is sliding window. The inputs
    should be cut into individual inputs according to the sampling rate. This procedure
    is similar to conventional PR approaches. The second one is channels. Different
    sensor modalities can be treated as separate channels, and each axis of a sensor
    can also be a channel. Using multi-channel could enhance the representation capability
    of the deep model since it can reflect the hidden knowledge of the sensor inputs.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用深度模型之前，需要对原始传感器数据进行相应的预处理。有两个重要方面。第一个方面是滑动窗口。输入数据应根据采样率切割成单独的输入。这一过程类似于传统的PR方法。第二个方面是通道。不同的传感器模态可以视作独立的通道，每个传感器的每个轴也可以作为一个通道。使用多通道可以增强深度模型的表示能力，因为它可以反映传感器输入的隐藏知识。
- en: '2) Model selection. There are several deep models surveyed in this article.
    Then, a natural question arises: which model is the best for HAR? (Hammerla et al.,
    [2016](#bib.bib21)) did an early work by investigating the performance of DNN,
    CNN and RNN through 4,000 experiments on some public HAR datasets. We combine
    their work and our explorations to draw some conclusions: RNN and LSTM are recommended
    to recognize short activities that have natural order while CNN is better at inferring
    long-term repetitive activities (Hammerla et al., [2016](#bib.bib21)). The reason
    is that RNN could make use of the time-order relationship between sensor readings,
    and CNN is more capable of learning deep features contained in recursive patterns.
    For multi-modal signals, it is better to use CNN since the features can be integrated
    through multi-channel convolutions (Zeng et al., [2014](#bib.bib70); Zheng et al.,
    [2014](#bib.bib76); Ha et al., [2015](#bib.bib19)). While adapting CNN, data-driven
    approaches are better than model-driven approaches as the inner properties of
    the activity signal can be exploited better when the input data are transformed
    into the virtual image. Multiple convolutions and poolings also help CNN perform
    better. RBM and autoencoders are usually pre-trained before being fine-tuned.
    Multi-layer RBM or SAE is preferred for more accurate recognition.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 模型选择。本文调查了几种深度模型。于是，提出了一个自然的问题：哪种模型最适合用于HAR？（Hammerla等，[2016](#bib.bib21)）通过在一些公共HAR数据集上进行4,000次实验，早期研究了DNN、CNN和RNN的性能。我们结合他们的研究成果和我们的探索得出了一些结论：RNN和LSTM推荐用于识别具有自然顺序的短期活动，而CNN更擅长推断长期重复活动（Hammerla等，[2016](#bib.bib21)）。原因是RNN能够利用传感器读数之间的时间顺序关系，而CNN更能学习递归模式中包含的深层特征。对于多模态信号，使用CNN更为合适，因为通过多通道卷积可以整合特征（Zeng等，[2014](#bib.bib70)；Zheng等，[2014](#bib.bib76)；Ha等，[2015](#bib.bib19)）。在调整CNN时，数据驱动的方法优于模型驱动的方法，因为当输入数据被转换为虚拟图像时，活动信号的内在特性可以被更好地利用。多个卷积和池化操作也有助于CNN的表现。RBM和自编码器通常会在微调之前进行预训练。为了更准确的识别，通常推荐使用多层RBM或SAE。
- en: 'Technically there is no model which outperforms all the others in all situations,
    so it is recommended to choose models based on the scenarios. To better illustrate
    the performance of some deep models, Table [5](#S6.T5 "Table 5 ‣ 6 Summary and
    Discussion ‣ Deep Learning for Sensor-based Activity Recognition: A Survey") offers
    some results comparison of existing work on public datasets in Table [3](#S4.T3
    "Table 3 ‣ 4.5 Recurrent Neural Network ‣ 4 Deep Model ‣ Deep Learning for Sensor-based
    Activity Recognition: A Survey") ¹¹1OPP 1, OPP 2, Skoda, and UCI smartphone follow
    the protocols in (Hammerla et al., [2016](#bib.bib21)), (Plötz et al., [2011](#bib.bib47)),
    (Zeng et al., [2014](#bib.bib70)), and (Ronao and Cho, [2016](#bib.bib56)), respectively.
    OPP 1 used weighted f1-score; OPP 2, Skoda, and UCI smartphone used accuracy..
    In Skoda and UCI Smartphone protocols, CNN achieves the best performance. In two
    OPPORTUNITY protocols, DBN and RNN outperform the others. This confirms that no
    models can achieve the best in all tasks. Moreover, the hybrid models tend to
    perform better than single models (DeepConvLSTM in OPPORTUNITY 1 and Skoda). For
    a single model, CNN with shifted inputs (Fourier transform) generates better results
    compared to shifted kernels.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '从技术上讲，没有任何模型能在所有情况下超越其他模型，因此建议根据场景选择模型。为了更好地说明一些深度模型的性能，表[5](#S6.T5 "Table
    5 ‣ 6 Summary and Discussion ‣ Deep Learning for Sensor-based Activity Recognition:
    A Survey") 提供了在公共数据集上的现有工作结果比较，如表[3](#S4.T3 "Table 3 ‣ 4.5 Recurrent Neural Network
    ‣ 4 Deep Model ‣ Deep Learning for Sensor-based Activity Recognition: A Survey")¹¹1所示。OPP
    1、OPP 2、Skoda 和 UCI 智能手机遵循了(Hammerla et al., [2016](#bib.bib21))、(Plötz et al.,
    [2011](#bib.bib47))、(Zeng et al., [2014](#bib.bib70))和(Ronao and Cho, [2016](#bib.bib56))中的协议。OPP
    1 使用了加权 f1-score；OPP 2、Skoda 和 UCI 智能手机使用了准确率。在 Skoda 和 UCI 智能手机协议中，CNN 达到了最佳性能。在两个
    OPPORTUNITY 协议中，DBN 和 RNN 超越了其他模型。这证实了没有模型能在所有任务中达到最佳。此外，混合模型往往比单一模型表现更好（例如 OPPORTUNITY
    1 和 Skoda 中的 DeepConvLSTM）。对于单一模型而言，使用移位输入（傅里叶变换）的 CNN 相较于使用移位卷积核的模型产生了更好的结果。'
- en: 'Table 5: Performance comparison of existing deep models'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：现有深度模型的性能比较
- en: '| Protocol | Model | Result | Reference |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| Protocol | Model | Result | Reference |'
- en: '| --- | --- | --- | --- |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| OPP 1 | b-LSTM-S | 92.70 | (Hammerla et al., [2016](#bib.bib21)) |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| OPP 1 | b-LSTM-S | 92.70 | (Hammerla et al., [2016](#bib.bib21)) |'
- en: '| CNN | 85.10 | (Yang et al., [2015](#bib.bib66)) |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 85.10 | (Yang et al., [2015](#bib.bib66)) |'
- en: '| CNN | 88.30 | (Ordóñez and Roggen, [2016](#bib.bib44)) |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 88.30 | (Ordóñez and Roggen, [2016](#bib.bib44)) |'
- en: '| DeepConvLSTM | 91.70 | (Ordóñez and Roggen, [2016](#bib.bib44)) |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| DeepConvLSTM | 91.70 | (Ordóñez and Roggen, [2016](#bib.bib44)) |'
- en: '| OPP 2 | DBN | 73.20 | (Plötz et al., [2011](#bib.bib47)) |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| OPP 2 | DBN | 73.20 | (Plötz et al., [2011](#bib.bib47)) |'
- en: '| CNN | 76.80 | (Zeng et al., [2014](#bib.bib70)) |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 76.80 | (Zeng et al., [2014](#bib.bib70)) |'
- en: '| DBN | 83.30 | (Zhang et al., [2015c](#bib.bib73)) |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| DBN | 83.30 | (Zhang et al., [2015c](#bib.bib73)) |'
- en: '| Skoda | CNN | 86.10 | (Zeng et al., [2014](#bib.bib70)) |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| Skoda | CNN | 86.10 | (Zeng et al., [2014](#bib.bib70)) |'
- en: '| CNN | 89.30 | (Alsheikh et al., [2016](#bib.bib3)) |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 89.30 | (Alsheikh et al., [2016](#bib.bib3)) |'
- en: '| DeepConvLSTM | 95.80 | (Ordóñez and Roggen, [2016](#bib.bib44)) |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| DeepConvLSTM | 95.80 | (Ordóñez and Roggen, [2016](#bib.bib44)) |'
- en: '| UCI smartphone | CNN | 94.61 | (Ronao and Cho, [2016](#bib.bib56)) |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| UCI smartphone | CNN | 94.61 | (Ronao and Cho, [2016](#bib.bib56)) |'
- en: '| CNN | 95.18 | (Jiang and Yin, [2015](#bib.bib27)) |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 95.18 | (Jiang and Yin, [2015](#bib.bib27)) |'
- en: '| CNN | 94.79 | (Ronao and Cho, [2015a](#bib.bib54)) |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 94.79 | (Ronao and Cho, [2015a](#bib.bib54)) |'
- en: '| CNN | 90.00 | (Ronao and Cho, [2015b](#bib.bib55)) |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 90.00 | (Ronao and Cho, [2015b](#bib.bib55)) |'
- en: 7 Grand Challenges
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 大挑战
- en: Despite the progress in previous work, there are still challenges for deep learning
    based HAR. In this section, we present those challenges and propose some feasible
    solutions.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在之前的工作中取得了进展，但基于深度学习的HAR（人类活动识别）仍面临挑战。在本节中，我们将介绍这些挑战，并提出一些可行的解决方案。
- en: 'A. Online and mobile deep activity recognition. Two critical issues are related
    to deep HAR: online deployment and mobile application. Although some existing
    work adopted deep HAR on smartphone (Lane et al., [2015](#bib.bib33)) and watch (Bhattacharya
    and Lane, [2016](#bib.bib6)), they are still far from online and mobile deployment.
    Because the model is often trained offline on some remote server and the mobile
    device only utilizes a trained model. This approach is neither real-time nor friendly
    to incremental learning. There are two approaches to tackle this problem: reducing
    the communication cost between mobile and server, and enhancing computing ability
    of the mobile devices.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: A. 在线和移动深度活动识别。深度活动识别面临两个关键问题：在线部署和移动应用。尽管一些现有工作在智能手机（Lane等人，[2015](#bib.bib33)）和手表（Bhattacharya和Lane，[2016](#bib.bib6)）上采用了深度活动识别技术，但它们仍然远未实现在线和移动部署。因为模型通常是在某些远程服务器上离线训练，移动设备只是利用一个训练好的模型。这种方法既不是实时的，也不利于增量学习。解决这个问题有两种方法：减少移动设备与服务器之间的通信成本，以及增强移动设备的计算能力。
- en: B. More accurate unsupervised activity recognition. The performance of deep
    learning still relies heavily on labeled samples. Acquiring sufficient activity
    labels is expensive and time-consuming. Thus, unsupervised activity recognition
    is urgent.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: B. 更准确的无监督活动识别。深度学习的性能仍然严重依赖于标记样本。获取足够的活动标签是昂贵且耗时的。因此，无监督活动识别显得尤为迫切。
- en: •
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Take advantage of the crowd. The latest research indicates that exploiting the
    knowledge from the crowd will facilitate the task (Prelec et al., [2017](#bib.bib49)).
    Crowd-sourcing takes advantage of the crowd to annotate the unlabeled activities.
    Other than acquiring labels passively, researchers could also develop more elaborate,
    privacy-concerned way to collect useful labels.
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 利用群体优势。最新的研究表明，利用群体的知识将有助于完成任务（Prelec等人，[2017](#bib.bib49)）。众包利用群体来注释未标记的活动。研究人员除了
    passively 获取标签外，还可以开发更精心的、注重隐私的方式来收集有用的标签。
- en: •
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Deep transfer learning. Transfer learning performs data annotation by leveraging
    labeled data from other auxiliary domains (Pan and Yang, [2010](#bib.bib45); Cook
    et al., [2013](#bib.bib13); Wang et al., [2017](#bib.bib64)). There are many factors
    related to human activity, which can be exploited as auxiliary information using
    deep transfer learning. Problems such as sharing weights between networks, exploiting
    knowledge between activity related domains, and how to find more relevant domains
    are to be resolved.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度迁移学习。迁移学习通过利用其他辅助领域的标记数据执行数据注释（Pan和Yang，[2010](#bib.bib45); Cook等人，[2013](#bib.bib13);
    Wang等人，[2017](#bib.bib64)）。人类活动相关的许多因素可以利用深度迁移学习作为辅助信息。需要解决的问题包括网络间权重共享、活动相关领域知识的利用以及如何找到更相关的领域。
- en: C. Flexible models to recognize high-level activities. More complex high-level
    activities need to be recognized other than only simple daily activities. It is
    difficult to determine the hierarchical structure of high-level activities because
    they contain more semantic and context information. Existing methods often ignore
    the correlation between signals, thus they cannot obtain good results.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: C. 灵活模型以识别高级活动。除了简单的日常活动外，还需要识别更复杂的高级活动。确定高级活动的层次结构很困难，因为它们包含更多语义和上下文信息。现有方法经常忽视信号之间的相关性，因此无法取得良好的结果。
- en: •
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Hybrid sensor. Elaborate information provided by the hybrid sensor is useful
    for recognizing fine-grained activities (Vepakomma et al., [2015](#bib.bib61)).
    Special attention should be paid to the recognition of fine-grained activities
    by exploiting the collaboration of hybrid sensors.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 混合传感器。混合传感器提供的详细信息对识别细粒度活动很有用（Vepakomma等人，[2015](#bib.bib61)）。需要特别关注通过利用混合传感器的协作来识别细粒度活动。
- en: •
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Exploit context information. Context is any information that can be used to
    characterize the situation of an entity (Abowd et al., [1999](#bib.bib1)). Context
    information such as Wi-Fi, Bluetooth, and GPS can be used to infer more environmental
    knowledge about the activity. The exploitation of resourceful context information
    will greatly help to recognize user state as well as more specific activities.
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 利用上下文信息。上下文是指用于描述实体情况的任何信息（Abowd等人，[1999](#bib.bib1)）。诸如Wi-Fi、蓝牙和GPS等上下文信息可以用来推断更多关于活动环境的知识。充分利用资源丰富的上下文信息将极大帮助识别用户状态及更具体的活动。
- en: D. Light-weight deep models. Deep models often require lots of computing resources,
    which is not available for wearable devices. In addition, the models are often
    trained off-line which cannot be executed in real-time. However, less complex
    models such as shallow NN and conventional PR methods could not achieve good performance.
    Therefore, it is necessary to develop light-weight deep models to perform HAR.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 轻量级深度模型。深度模型通常需要大量计算资源，这在可穿戴设备上并不具备。此外，这些模型通常在离线环境中训练，无法实时执行。然而，像浅层神经网络和传统模式识别方法等较简单的模型无法实现良好的性能。因此，有必要开发轻量级深度模型以进行HAR。
- en: •
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Combination of human-crafted and deep features. Recent work indicated that human-crafted
    and deep features together could achieve better performance (Plötz et al., [2011](#bib.bib47)).
    Some pre-knowledge about the activity will greatly contribute to more robust feature
    learning in deep models (Stewart and Ermon, [2017](#bib.bib60)). Researchers should
    consider the possibility of applying two kinds of features to HAR with human experience
    and machine intelligence.
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 人工特征和深度特征的结合。近期工作表明，人工特征和深度特征的结合可以实现更好的性能 (Plötz et al., [2011](#bib.bib47))。关于活动的一些先验知识将极大地有助于深度模型中的更强健的特征学习 (Stewart
    and Ermon, [2017](#bib.bib60))。研究人员应考虑将这两种特征应用于结合人类经验和机器智能的HAR。
- en: •
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Collaboration of deep and shallow models. Deep models have powerful learning
    abilities, while shallow models are more efficient. The collaboration of those
    two models has the potential to perform both accurate and light-weight HAR. Several
    issues such as how to share the parameters between deep and shallow models are
    to be addressed.
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度模型和浅层模型的协作。深度模型具有强大的学习能力，而浅层模型则更高效。这两种模型的协作有潜力在实现准确且轻量级的HAR方面发挥作用。需要解决一些问题，例如如何在深度和浅层模型之间共享参数。
- en: E. Non-invasive activity sensing. Traditional activity collection strategies
    need to be updated with more non-invasive approaches. Non-invasive approaches
    tend to collect information and infer activity without disturbing the subjects
    and requires more flexible computing resources.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 非侵入式活动感知。传统的活动采集策略需要更新为更多非侵入式的方法。非侵入式方法倾向于在不打扰受试者的情况下收集信息并推断活动，并且需要更灵活的计算资源。
- en: •
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Opportunistic activity sensing with deep learning. Opportunistic sensing could
    dynamically harness the non-continuous activity signal to accomplish activity
    inference (Chen et al., [2016a](#bib.bib9)). In this scenario, back propagation
    of deep models should be well-designed.
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 利用深度学习进行机会感知活动。机会感知可以动态利用非连续活动信号来完成活动推断 (Chen et al., [2016a](#bib.bib9))。在这种情况下，深度模型的反向传播应设计得很完善。
- en: 'F. Beyond activity recognition: assessment and assistant. Recognizing activities
    is often the initial step in many applications. For instance, some professional
    skill assessment is required in fitness exercises and smart home assistant plays
    an important role in healthcare services. There is some early work on climbing
    assessment (Khan et al., [2015](#bib.bib28)). With the advancement of deep learning,
    more applications should be developed to be beyond just recognition.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 超越活动识别：评估和辅助。活动识别通常是许多应用中的初步步骤。例如，某些专业技能评估在健身运动中是必需的，而智能家居助手在医疗服务中发挥着重要作用。早期已经有一些关于攀岩评估的研究 (Khan
    et al., [2015](#bib.bib28))。随着深度学习的发展，应该开发更多超越单纯识别的应用。
- en: 8 Conclusion
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: 'Human activity recognition is an important research topic in pattern recognition
    and pervasive computing. In this paper, we survey the recent advance in deep learning
    approaches for sensor-based activity recognition. Compared to traditional pattern
    recognition methods, deep learning reduces the dependency on human-crafted feature
    extraction and achieves better performance by automatically learning high-level
    representations of the sensor data. We highlight the recent progress in three
    important categories: sensor modality, deep model, and application. Subsequently,
    we summarize and discuss the surveyed research in detail. Finally, several grand
    challenges and feasible solutions are presented for future research.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 人体活动识别是模式识别和普适计算中的一个重要研究课题。在本文中，我们调查了基于传感器的活动识别中深度学习方法的最新进展。与传统模式识别方法相比，深度学习减少了对人工特征提取的依赖，并通过自动学习传感器数据的高级表示实现了更好的性能。我们重点介绍了三个重要类别的最新进展：传感器模式、深度模型和应用。随后，我们详细总结和讨论了调查的研究。最后，我们提出了未来研究的几个重大挑战和可行的解决方案。
- en: Acknowledgments
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work is supported in part by National Key R & D Program of China (No.2017YFB1002801),
    NSFC (No.61572471), and Science and Technology Planning Project of Guangdong Province (No.2015B010105001).
    Authors thank the reviewers for their valuable comments.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究部分得到中国国家重点研发计划 (No.2017YFB1002801)、NSFC (No.61572471) 和广东省科技计划项目 (No.2015B010105001)
    的支持。作者感谢审稿人提供的宝贵意见。
- en: References
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Abowd et al. (1999) Abowd, G.D., Dey, A.K., Brown, P.J., Davies, N., Smith,
    M., Steggles, P., 1999. Towards a better understanding of context and context-awareness,
    in: International Symposium on Handheld and Ubiquitous Computing, Springer. pp.
    304–307.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abowd 等 (1999) Abowd, G.D., Dey, A.K., Brown, P.J., Davies, N., Smith, M., Steggles,
    P., 1999. 朝着更好地理解上下文和上下文感知的方向，收录于：国际手持和普适计算研讨会，Springer出版社，第 304–307 页。
- en: Almaslukh et al. (2017) Almaslukh, B., AlMuhtadi, J., Artoli, A., 2017. An effective
    deep autoencoder approach for online smartphone-based human activity recognition.
    International Journal of Computer Science and Network Security 17, 160.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Almaslukh 等 (2017) Almaslukh, B., AlMuhtadi, J., Artoli, A., 2017. 一种有效的深度自编码器方法用于在线智能手机的人类活动识别。国际计算机科学与网络安全期刊
    17, 160。
- en: Alsheikh et al. (2016) Alsheikh, M.A., Selim, A., Niyato, D., Doyle, L., Lin,
    S., Tan, H.P., 2016. Deep activity recognition models with triaxial accelerometers.
    AAAI workshop .
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alsheikh 等 (2016) Alsheikh, M.A., Selim, A., Niyato, D., Doyle, L., Lin, S.,
    Tan, H.P., 2016. 使用三轴加速度计的深度活动识别模型。AAAI 研讨会。
- en: 'Bao and Intille (2004) Bao, L., Intille, S.S., 2004. Activity recognition from
    user-annotated acceleration data, in: International Conference on Pervasive Computing,
    Springer. pp. 1–17.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bao 和 Intille (2004) Bao, L., Intille, S.S., 2004. 基于用户标注的加速度数据的活动识别，收录于：国际普适计算会议，Springer出版社，第
    1–17 页。
- en: 'Bengio (2013) Bengio, Y., 2013. Deep learning of representations: Looking forward,
    in: International Conference on Statistical Language and Speech Processing, Springer.
    pp. 1–37.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengio (2013) Bengio, Y., 2013. 表示学习的深度学习：展望，收录于：国际统计语言与语音处理会议，Springer出版社，第
    1–37 页。
- en: 'Bhattacharya and Lane (2016) Bhattacharya, S., Lane, N.D., 2016. From smart
    to deep: Robust activity recognition on smartwatches using deep learning, in:
    2016 IEEE International Conference on Pervasive Computing and Communication Workshops
    (PerCom Workshops), IEEE. pp. 1–6.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bhattacharya 和 Lane (2016) Bhattacharya, S., Lane, N.D., 2016. 从智能到深度：利用深度学习在智能手表上进行稳健的活动识别，收录于：2016
    IEEE 国际普适计算与通信研讨会（PerCom Workshops），IEEE出版社，第 1–6 页。
- en: Bulling et al. (2014) Bulling, A., Blanke, U., Schiele, B., 2014. A tutorial
    on human activity recognition using body-worn inertial sensors. ACM Computing
    Surveys (CSUR) 46, 33.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bulling 等 (2014) Bulling, A., Blanke, U., Schiele, B., 2014. 使用体感惯性传感器进行人类活动识别的教程。ACM
    计算调查（CSUR）46, 33。
- en: 'Chavarriaga et al. (2013) Chavarriaga, R., Sagha, H., Calatroni, A., Digumarti,
    S.T., Tröster, G., Millán, J.d.R., Roggen, D., 2013. The opportunity challenge:
    A benchmark database for on-body sensor-based activity recognition. Pattern Recognition
    Letters 34, 2033–2042.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chavarriaga 等 (2013) Chavarriaga, R., Sagha, H., Calatroni, A., Digumarti, S.T.,
    Tröster, G., Millán, J.d.R., Roggen, D., 2013. 机会挑战：一个用于基于体感传感器活动识别的基准数据库。模式识别快报
    34, 2033–2042。
- en: 'Chen et al. (2016a) Chen, Y., Gu, Y., Jiang, X., Wang, J., 2016a. Ocean: a
    new opportunistic computing model for wearable activity recognition, in: UbiComp,
    ACM. pp. 33–36.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2016a) Chen, Y., Gu, Y., Jiang, X., Wang, J., 2016a. Ocean：一种用于可穿戴活动识别的新型机会计算模型，收录于：UbiComp，ACM出版社，第
    33–36 页。
- en: 'Chen and Xue (2015) Chen, Y., Xue, Y., 2015. A deep learning approach to human
    activity recognition based on single accelerometer, in: Systems, Man, and Cybernetics
    (SMC), 2015 IEEE International Conference on, IEEE. pp. 1488–1492.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 和 Xue (2015) Chen, Y., Xue, Y., 2015. 基于单个加速度计的人类活动识别的深度学习方法，收录于：系统、人工智能与控制（SMC），2015
    IEEE 国际会议，IEEE出版社，第 1488–1492 页。
- en: Chen et al. (2016b) Chen, Y., Zhong, K., Zhang, J., Sun, Q., Zhao, X., 2016b.
    Lstm networks for mobile human activity recognition .
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2016b) Chen, Y., Zhong, K., Zhang, J., Sun, Q., Zhao, X., 2016b. 用于移动人类活动识别的
    Lstm 网络。
- en: 'Cheng and Scotland (2017) Cheng, W.Y., Scotland, A.e.a., 2017. Human activity
    recognition from sensor-based large-scale continuous monitoring of parkinson’s
    disease patients, in: Connected Health: Applications, Systems and Engineering
    Technologies (CHASE), 2017 IEEE/ACM International Conference on, pp. 249–250.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 和 Scotland (2017) Cheng, W.Y., Scotland, A.e.a., 2017. 基于传感器的大规模连续监测帕金森病患者的人类活动识别，收录于：连接健康：应用、系统与工程技术（CHASE），2017
    IEEE/ACM 国际会议，第 249–250 页。
- en: 'Cook et al. (2013) Cook, D., Feuz, K.D., Krishnan, N.C., 2013. Transfer learning
    for activity recognition: A survey. Knowledge and information systems 36, 537–556.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cook等人（2013年）Cook, D., Feuz, K.D., Krishnan, N.C., 2013. 活动识别的迁移学习：一项调查。知识与信息系统
    36, 537–556。
- en: 'Edel and Köppe (2016) Edel, M., Köppe, E., 2016. Binarized-blstm-rnn based
    human activity recognition, in: Indoor Positioning and Indoor Navigation (IPIN),
    2016 International Conference on, IEEE. pp. 1–7.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Edel和Köppe（2016年）Edel, M., Köppe, E., 2016. 基于二值化BLSTM-RNN的人体活动识别，收录于：室内定位与室内导航（IPIN），2016年国际会议，IEEE。页码
    1–7。
- en: 'Fang and Hu (2014) Fang, H., Hu, C., 2014. Recognizing human activity in smart
    home using deep learning algorithm, in: Chinese Control Conference (CCC), pp.
    4716–4720.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fang和Hu（2014年）Fang, H., Hu, C., 2014. 利用深度学习算法在智能家居中识别人类活动，收录于：中国控制会议（CCC），页码
    4716–4720。
- en: 'Gjoreski et al. (2016) Gjoreski, H., Bizjak, J., Gjoreski, M., Gams, M., 2016.
    Comparing deep and classical machine learning methods for human activity recognition
    using wrist accelerometer, in: IJCAI-16 workshop on Deep Learning for Artificial
    Intelligence (DLAI).'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gjoreski等人（2016年）Gjoreski, H., Bizjak, J., Gjoreski, M., Gams, M., 2016. 比较手腕加速计进行人体活动识别的深度与经典机器学习方法，收录于：IJCAI-16深度学习与人工智能研讨会（DLAI）。
- en: Guan and Ploetz (2017) Guan, Y., Ploetz, T., 2017. Ensembles of deep lstm learners
    for activity recognition using wearables. arXiv preprint arXiv:1703.09370 .
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guan和Ploetz（2017年）Guan, Y., Ploetz, T., 2017. 使用可穿戴设备进行活动识别的深度LSTM学习器集成。arXiv预印本
    arXiv:1703.09370 。
- en: 'Ha and Choi (2016) Ha, S., Choi, S., 2016. Convolutional neural networks for
    human activity recognition using multiple accelerometer and gyroscope sensors,
    in: Neural Networks (IJCNN), 2016 International Joint Conference on, IEEE. pp.
    381–388.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ha和Choi（2016年）Ha, S., Choi, S., 2016. 利用多个加速度计和陀螺仪传感器进行人体活动识别的卷积神经网络，收录于：神经网络（IJCNN），2016年国际联合会议，IEEE。页码
    381–388。
- en: 'Ha et al. (2015) Ha, S., Yun, J.M., Choi, S., 2015. Multi-modal convolutional
    neural networks for activity recognition, in: Systems, Man, and Cybernetics (SMC),
    2015 IEEE International Conference on, IEEE. pp. 3017–3022.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ha等人（2015年）Ha, S., Yun, J.M., Choi, S., 2015. 多模态卷积神经网络用于活动识别，收录于：系统、人类与计算机联合（SMC），2015年IEEE国际会议，IEEE。页码
    3017–3022。
- en: 'Hammerla et al. (2015) Hammerla, N.Y., Fisher, J., Andras, P., Rochester, L.,
    Walker, R., Plötz, T., 2015. Pd disease state assessment in naturalistic environments
    using deep learning, in: Twenty-Ninth AAAI Conference on Artificial Intelligence.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hammerla等人（2015年）Hammerla, N.Y., Fisher, J., Andras, P., Rochester, L., Walker,
    R., Plötz, T., 2015. 使用深度学习在自然环境中进行帕金森病状态评估，收录于：第二十九届AAAI人工智能会议。
- en: 'Hammerla et al. (2016) Hammerla, N.Y., Halloran, S., Ploetz, T., 2016. Deep,
    convolutional, and recurrent models for human activity recognition using wearables,
    in: IJCAI.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hammerla等人（2016年）Hammerla, N.Y., Halloran, S., Ploetz, T., 2016. 使用可穿戴设备进行人体活动识别的深度、卷积和递归模型，收录于：IJCAI。
- en: Hannink et al. (2017) Hannink, J., Kautz, T., Pasluosta, C.F., Gaßmann, K.G.,
    et al., 2017. Sensor-based gait parameter extraction with deep convolutional neural
    networks. IEEE journal of biomedical and health informatics 21, 85–93.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hannink等人（2017年）Hannink, J., Kautz, T., Pasluosta, C.F., Gaßmann, K.G., 等，2017.
    基于传感器的步态参数提取与深度卷积神经网络。IEEE生物医学与健康信息学杂志 21, 85–93。
- en: 'Hayashi et al. (2015) Hayashi, T., Nishida, M., Kitaoka, N., Takeda, K., 2015.
    Daily activity recognition based on dnn using environmental sound and acceleration
    signals, in: Signal Processing Conference (EUSIPCO), 23rd European, pp. 2306–2310.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hayashi等人（2015年）Hayashi, T., Nishida, M., Kitaoka, N., Takeda, K., 2015. 基于环境声音和加速度信号的DNN的日常活动识别，收录于：信号处理会议（EUSIPCO），第23届欧洲，页码
    2306–2310。
- en: Hinton et al. (2006) Hinton, G.E., Osindero, S., Teh, Y.W., 2006. A fast learning
    algorithm for deep belief nets. Neural computation 18, 1527–1554.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton等人（2006年）Hinton, G.E., Osindero, S., Teh, Y.W., 2006. 深度信念网络的快速学习算法。神经计算
    18, 1527–1554。
- en: 'Hu et al. (2016) Hu, L., Chen, Y., Wang, S., Wang, J., Shen, J., Jiang, X.,
    Shen, Z., 2016. Less annotation on personalized activity recognition using context
    data, in: UIC, pp. 327–332.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu等人（2016年）Hu, L., Chen, Y., Wang, S., Wang, J., Shen, J., Jiang, X., Shen,
    Z., 2016. 使用上下文数据进行个性化活动识别的少标注方法，收录于：UIC，页码 327–332。
- en: Inoue et al. (2016) Inoue, M., Inoue, S., Nishida, T., 2016. Deep recurrent
    neural network for mobile human activity recognition with high throughput. arXiv
    preprint arXiv:1611.03607 .
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Inoue等人（2016年）Inoue, M., Inoue, S., Nishida, T., 2016. 高吞吐量移动人体活动识别的深度递归神经网络。arXiv预印本
    arXiv:1611.03607 。
- en: 'Jiang and Yin (2015) Jiang, W., Yin, Z., 2015. Human activity recognition using
    wearable sensors by deep convolutional neural networks, in: MM, ACM. pp. 1307–1310.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 和 Yin (2015) Jiang, W., Yin, Z., 2015. 使用深度卷积神经网络通过可穿戴传感器进行人类活动识别，发表于：MM，ACM。第
    1307–1310 页。
- en: 'Khan et al. (2015) Khan, A., Mellor, S., Berlin, E., Thompson, R., McNaney,
    R., Olivier, P., Plötz, T., 2015. Beyond activity recognition: skill assessment
    from accelerometer data, in: UbiComp, ACM. pp. 1155–1166.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan 等 (2015) Khan, A., Mellor, S., Berlin, E., Thompson, R., McNaney, R., Olivier,
    P., Plötz, T., 2015. 超越活动识别：基于加速度计数据的技能评估，发表于：UbiComp，ACM。第 1155–1166 页。
- en: Khan et al. (2017) Khan, U.M., Kabir, Z., Hassan, S.A., Ahmed, S.H., 2017. A
    deep learning framework using passive wifi sensing for respiration monitoring.
    arXiv preprint arXiv:1704.05708 .
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan 等 (2017) Khan, U.M., Kabir, Z., Hassan, S.A., Ahmed, S.H., 2017. 使用被动 WiFi
    感测的深度学习框架进行呼吸监测。arXiv 预印本 arXiv:1704.05708.
- en: Kim and Li (2017) Kim, Y., Li, Y., 2017. Human activity classification with
    transmission and reflection coefficients of on-body antennas through deep convolutional
    neural networks. IEEE Transactions on Antennas and Propagation 65, 2764–2768.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 和 Li (2017) Kim, Y., Li, Y., 2017. 通过深度卷积神经网络利用体内天线的传输和反射系数进行人类活动分类。IEEE
    Transactions on Antennas and Propagation 65, 2764–2768.
- en: Kim and Toomajian (2016) Kim, Y., Toomajian, B., 2016. Hand gesture recognition
    using micro-doppler signatures with convolutional neural network. IEEE Access
    .
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 和 Toomajian (2016) Kim, Y., Toomajian, B., 2016. 使用微多普勒签名和卷积神经网络的手势识别。IEEE
    Access.
- en: 'Lane and Georgiev (2015) Lane, N.D., Georgiev, P., 2015. Can deep learning
    revolutionize mobile sensing?, in: Proceedings of the 16th International Workshop
    on Mobile Computing Systems and Applications, ACM. pp. 117–122.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lane 和 Georgiev (2015) Lane, N.D., Georgiev, P., 2015. 深度学习能否革新移动感测？，发表于：第 16
    届国际移动计算系统与应用研讨会，ACM。第 117–122 页。
- en: 'Lane et al. (2015) Lane, N.D., Georgiev, P., Qendro, L., 2015. Deepear: robust
    smartphone audio sensing in unconstrained acoustic environments using deep learning,
    in: UbiComp, ACM. pp. 283–294.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lane 等 (2015) Lane, N.D., Georgiev, P., Qendro, L., 2015. Deepear: 使用深度学习在非约束声学环境中进行鲁棒的智能手机音频感测，发表于：UbiComp，ACM。第
    283–294 页。'
- en: Lara and Labrador (2013) Lara, O.D., Labrador, M.A., 2013. A survey on human
    activity recognition using wearable sensors. IEEE Communications Surveys & Tutorials
    15, 1192–1209.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lara 和 Labrador (2013) Lara, O.D., Labrador, M.A., 2013. 使用可穿戴传感器的人类活动识别调查。IEEE
    Communications Surveys & Tutorials 15, 1192–1209.
- en: LeCun et al. (2015) LeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning.
    Nature 521, 436–444.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun 等 (2015) LeCun, Y., Bengio, Y., Hinton, G., 2015. 深度学习。自然 521, 436–444.
- en: 'Lee et al. (2017) Lee, S.M., Yoon, S.M., Cho, H., 2017. Human activity recognition
    from accelerometer data using convolutional neural network, in: Big Data and Smart
    Computing (BigComp), IEEE International Conference on, pp. 131–134.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee 等 (2017) Lee, S.M., Yoon, S.M., Cho, H., 2017. 使用卷积神经网络从加速度计数据中进行人类活动识别，发表于：大数据与智能计算
    (BigComp)，IEEE 国际会议，第 131–134 页。
- en: 'Li et al. (2016a) Li, X., Zhang, Y., Li, M., Marsic, I., Yang, J., Burd, R.S.,
    2016a. Deep neural network for rfid based activity recognition, in: Wireless of
    the Students, by the Students, and for the Students (S3) Workshop with MobiCom.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2016a) Li, X., Zhang, Y., Li, M., Marsic, I., Yang, J., Burd, R.S., 2016a.
    基于 RFID 的活动识别的深度神经网络，发表于：学生主办的无线通信 (S3) 研讨会，MobiCom。
- en: 'Li et al. (2016b) Li, X., Zhang, Y., Marsic, I., Sarcevic, A., Burd, R.S.,
    2016b. Deep learning for rfid-based activity recognition, in: Proceedings of the
    14th ACM Conference on Embedded Network Sensor Systems CD-ROM, ACM. pp. 164–175.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2016b) Li, X., Zhang, Y., Marsic, I., Sarcevic, A., Burd, R.S., 2016b.
    基于 RFID 的活动识别的深度学习，发表于：第 14 届 ACM 嵌入式网络传感器系统会议 CD-ROM，ACM。第 164–175 页。
- en: 'Li et al. (2014) Li, Y., Shi, D., Ding, B., Liu, D., 2014. Unsupervised feature
    learning for human activity recognition using smartphone sensors, in: Mining Intelligence
    and Knowledge Exploration. Springer, pp. 99–107.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2014) Li, Y., Shi, D., Ding, B., Liu, D., 2014. 使用智能手机传感器进行人类活动识别的无监督特征学习，发表于：智能挖掘与知识探索。Springer，第
    99–107 页。
- en: 'Liu et al. (2016) Liu, C., Zhang, L., Liu, Z., Liu, K., Li, X., Liu, Y., 2016.
    Lasagna: towards deep hierarchical understanding and searching over mobile sensing
    data, in: Proceedings of the 22nd Annual International Conference on Mobile Computing
    and Networking, ACM. pp. 334–347.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等 (2016) Liu, C., Zhang, L., Liu, Z., Liu, K., Li, X., Liu, Y., 2016. Lasagna:
    实现对移动感测数据的深层次层次理解和搜索，发表于：第 22 届国际移动计算与网络会议，ACM。第 334–347 页。'
- en: 'Mohammed and Tashev (2017) Mohammed, S., Tashev, I., 2017. Unsupervised deep
    representation learning to remove motion artifacts in free-mode body sensor networks,
    in: Wearable and Implantable Body Sensor Networks (BSN), 2017 IEEE 14th International
    Conference on, IEEE. pp. 183–188.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mohammed 和 Tashev（2017）Mohammed, S., Tashev, I., 2017. 无监督深度表示学习以消除自由模式身体传感器网络中的运动伪影，于：可穿戴和植入式身体传感器网络（BSN），2017年IEEE第14届国际会议，IEEE。pp.
    183–188。
- en: 'Morales and Roggen (2016) Morales, F.J.O., Roggen, D., 2016. Deep convolutional
    feature transfer across mobile activity recognition domains, sensor modalities
    and locations, in: Proceedings of the 2016 ACM International Symposium on Wearable
    Computers, ACM. pp. 92–99.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Morales 和 Roggen（2016）Morales, F.J.O., Roggen, D., 2016. 深度卷积特征跨移动活动识别领域、传感器模态和位置传输，于：2016年ACM国际可穿戴计算机大会论文集，ACM。pp.
    92–99。
- en: Murad and Pyun (2017) Murad, A., Pyun, J.Y., 2017. Deep recurrent neural networks
    for human activity recognition. Sensors 17, 2556.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Murad 和 Pyun（2017）Murad, A., Pyun, J.Y., 2017. 用于人体活动识别的深度递归神经网络。传感器 17, 2556。
- en: Ordóñez and Roggen (2016) Ordóñez, F.J., Roggen, D., 2016. Deep convolutional
    and lstm recurrent neural networks for multimodal wearable activity recognition.
    Sensors 16, 115.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ordóñez 和 Roggen（2016）Ordóñez, F.J., Roggen, D., 2016. 深度卷积和lstm递归神经网络用于多模式可穿戴活动识别。传感器
    16, 115。
- en: Pan and Yang (2010) Pan, S.J., Yang, Q., 2010. A survey on transfer learning.
    Knowledge and Data Engineering, IEEE Transactions on 22, 1345–1359.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan 和 Yang（2010）Pan, S.J., Yang, Q., 2010. 关于迁移学习的调查。IEEE交易知识与数据工程 22, 1345–1359。
- en: 'Panwar et al. (2017) Panwar, M., Dyuthi, S.R., Prakash, K.C., Biswas, D., Acharyya,
    A., Maharatna, K., Gautam, A., Naik, G.R., 2017. Cnn based approach for activity
    recognition using a wrist-worn accelerometer, in: Engineering in Medicine and
    Biology Society (EMBC), 2017 39th Annual International Conference of the IEEE,
    IEEE. pp. 2438–2441.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Panwar 等人（2017）Panwar, M., Dyuthi, S.R., Prakash, K.C., Biswas, D., Acharyya,
    A., Maharatna, K., Gautam, A., Naik, G.R., 2017. 基于CNN的手腕佩戴加速度计活动识别方法，于：IEEE工程医学与生物学会议（EMBC），2017年第39届年会国际会议，IEEE。pp.
    2438–2441。
- en: 'Plötz et al. (2011) Plötz, T., Hammerla, N.Y., Olivier, P., 2011. Feature learning
    for activity recognition in ubiquitous computing, in: IJCAI, p. 1729.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Plötz 等人（2011）Plötz, T., Hammerla, N.Y., Olivier, P., 2011. 无处不在计算中活动识别的特征学习，于：IJCAI，p.
    1729。
- en: Pourbabaee et al. (2017) Pourbabaee, B., Roshtkhari, M.J., Khorasani, K., 2017.
    Deep convolution neural networks and learning ecg features for screening paroxysmal
    atrial fibrillatio patients. IEEE Trans. on Systems, Man, and Cybernetics .
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pourbabaee 等人（2017）Pourbabaee, B., Roshtkhari, M.J., Khorasani, K., 2017. 深度卷积神经网络和学习心电图特征用于筛查阵发性心房颤动患者。IEEE系统、人类和网络系统交易。
- en: Prelec et al. (2017) Prelec, D., Seung, H.S., McCoy, J., 2017. A solution to
    the single-question crowd wisdom problem. Nature 541, 532–535.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prelec 等人（2017）Prelec, D., Seung, H.S., McCoy, J., 2017. 单问题众智问题的解决方案。自然 541,
    532–535。
- en: Qin et al. (2016) Qin, J., Liu, L., Zhang, Z., Wang, Y., Shao, L., 2016. Compressive
    sequential learning for action similarity labeling. IEEE Transactions on Image
    Processing 25, 756–769.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin 等人（2016）Qin, J., Liu, L., Zhang, Z., Wang, Y., Shao, L., 2016. 用于动作相似性标记的压缩顺序学习。IEEE图像处理交易
    25, 756–769。
- en: 'Radu et al. (2016) Radu, V., Lane, N.D., Bhattacharya, S., Mascolo, C., Marina,
    M.K., Kawsar, F., 2016. Towards multimodal deep learning for activity recognition
    on mobile devices, in: UbiComp, ACM. pp. 185–188.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radu 等人（2016）Radu, V., Lane, N.D., Bhattacharya, S., Mascolo, C., Marina, M.K.,
    Kawsar, F., 2016. 用于移动设备活动识别的多模态深度学习，于：UbiComp，ACM。pp. 185–188。
- en: 'Ravi et al. (2016) Ravi, D., Wong, C., Lo, B., Yang, G.Z., 2016. Deep learning
    for human activity recognition: A resource efficient implementation on low-power
    devices, in: Wearable and Implantable Body Sensor Networks (BSN), 2016 IEEE 13th
    International Conference on, IEEE. pp. 71–76.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ravi 等人（2016）Ravi, D., Wong, C., Lo, B., Yang, G.Z., 2016. 人体活动识别的深度学习：低功耗设备上的资源高效实现，于：可穿戴和植入式身体传感器网络（BSN），2016年IEEE第13届国际会议，IEEE。pp.
    71–76。
- en: Ravì et al. (2017) Ravì, D., Wong, C., Lo, B., Yang, G.Z., 2017. A deep learning
    approach to on-node sensor data analytics for mobile or wearable devices. IEEE
    journal of biomedical and health informatics 21, 56–64.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ravì 等人（2017）Ravì, D., Wong, C., Lo, B., Yang, G.Z., 2017. 一种用于移动或可穿戴设备上节点传感器数据分析的深度学习方法。IEEE生物医学与健康信息学杂志
    21, 56–64。
- en: 'Ronao and Cho (2015a) Ronao, C.A., Cho, S.B., 2015a. Deep convolutional neural
    networks for human activity recognition with smartphone sensors, in: International
    Conference on Neural Information Processing, Springer. pp. 46–53.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ronao 和 Cho（2015年）Ronao, C.A., Cho, S.B., 2015a. 用于智能手机传感器的深度卷积神经网络进行人体活动识别，在：国际神经信息处理会议，Springer。pp.
    46–53。
- en: 'Ronao and Cho (2015b) Ronao, C.A., Cho, S.B., 2015b. Evaluation of deep convolutional
    neural network architectures for human activity recognition with smartphone sensors,
    in: Proc. of the KIISE Korea Computer Congress, pp. 858–860.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ronao 和 Cho（2015年）Ronao, C.A., Cho, S.B., 2015b. 评估用于智能手机传感器的人体活动识别的深度卷积神经网络架构，在：KIISE韩国计算机大会论文集，pp.
    858–860。
- en: Ronao and Cho (2016) Ronao, C.A., Cho, S.B., 2016. Human activity recognition
    with smartphone sensors using deep learning neural networks. Expert Systems with
    Applications 59, 235–244.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ronao 和 Cho（2016年）Ronao, C.A., Cho, S.B., 2016. 使用深度学习神经网络进行智能手机传感器的人体活动识别。Expert
    Systems with Applications 59, 235–244。
- en: 'Sathyanarayana et al. (2016) Sathyanarayana, A., Joty, S., Fernandez-Luque,
    L., Ofli, F., Srivastava, J., Elmagarmid, A., Taheri, S., Arora, T., 2016. Impact
    of physical activity on sleep: A deep learning based exploration. arXiv preprint:1607.07034
    .'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sathyanarayana 等人（2016年）Sathyanarayana, A., Joty, S., Fernandez-Luque, L., Ofli,
    F., Srivastava, J., Elmagarmid, A., Taheri, S., Arora, T., 2016. 身体活动对睡眠的影响：基于深度学习的探索。arXiv预印本:1607.07034
    。
- en: 'Schmidhuber (2015) Schmidhuber, J., 2015. Deep learning in neural networks:
    An overview. Neural Networks 61, 85–117.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schmidhuber（2015年）Schmidhuber, J., 2015. 神经网络中的深度学习：综述。神经网络 61, 85–117。
- en: Singh et al. (2017) Singh, M.S., Pondenkandath, V., Zhou, B., Lukowicz, P.,
    Liwicki, M., 2017. Transforming sensor data to the image domain for deep learning-an
    application to footstep detection. arXiv preprint arXiv:1701.01077 .
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singh 等人（2017年）Singh, M.S., Pondenkandath, V., Zhou, B., Lukowicz, P., Liwicki,
    M., 2017. 将传感器数据转换到图像领域进行深度学习——以步态检测为例。arXiv预印本 arXiv:1701.01077 。
- en: 'Stewart and Ermon (2017) Stewart, R., Ermon, S., 2017. Label-free supervision
    of neural networks with physics and domain knowledge., in: AAAI, pp. 2576–2582.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stewart 和 Ermon（2017年）Stewart, R., Ermon, S., 2017. 无标签监督神经网络与物理和领域知识。在：AAAI，pp.
    2576–2582。
- en: 'Vepakomma et al. (2015) Vepakomma, P., De, D., Das, S.K., Bhansali, S., 2015.
    A-wristocracy: Deep learning on wrist-worn sensing for recognition of user complex
    activities, in: 2015 IEEE 12th International Conference on Wearable and Implantable
    Body Sensor Networks (BSN), IEEE. pp. 1–6.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vepakomma 等人（2015年）Vepakomma, P., De, D., Das, S.K., Bhansali, S., 2015. A-wristocracy：手腕穿戴传感器的深度学习，第12届国际穿戴和植入身体传感器网络会议（BSN）论文集，IEEE。pp.
    1–6。
- en: 'Walse et al. (2016) Walse, K.H., Dharaskar, R.V., Thakare, V.M., 2016. Pca
    based optimal ann classifiers for human activity recognition using mobile sensors
    data, in: Proceedings of First International Conference on Information and Communication
    Technology for Intelligent Systems: Volume 1, Springer. pp. 429–436.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Walse 等人（2016年）Walse, K.H., Dharaskar, R.V., Thakare, V.M., 2016. 基于PCA的最优ANN分类器用于使用移动传感器数据的人体活动识别，第一届智能系统信息与通信技术国际会议论文集，Springer。pp.
    429–436。
- en: 'Wang et al. (2016a) Wang, A., Chen, G., Shang, C., Zhang, M., Liu, L., 2016a.
    Human activity recognition in a smart home environment with stacked denoising
    autoencoders, in: International Conference on Web-Age Information Management,
    Springer. pp. 29–40.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2016a年）Wang, A., Chen, G., Shang, C., Zhang, M., Liu, L., 2016a. 在智能家居环境中使用堆叠降噪自编码器进行人体活动识别，国际Web-Age信息管理会议，Springer。pp.
    29–40。
- en: 'Wang et al. (2017) Wang, J., Chen, Y., Hao, S., Feng, W., Shen, Z., 2017. Balanced
    distribution adaptation for transfer learning, in: The IEEE International conference
    on data mining (ICDM), pp. 1129–1134.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2017年）Wang, J., Chen, Y., Hao, S., Feng, W., Shen, Z., 2017. 平衡分布适应用于迁移学习，在：IEEE国际数据挖掘会议（ICDM），pp.
    1129–1134。
- en: 'Wang et al. (2016b) Wang, J., Zhang, X., Gao, Q., Yue, H., Wang, H., 2016b.
    Device-free wireless localization and activity recognition: A deep learning approach.
    IEEE Transactions on Vehicular Technology .'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2016b年）Wang, J., Zhang, X., Gao, Q., Yue, H., Wang, H., 2016b. 无设备无线定位和活动识别：一种深度学习方法。IEEE
    Transactions on Vehicular Technology 。
- en: 'Yang et al. (2015) Yang, J.B., Nguyen, M.N., San, P.P., Li, X.L., Krishnaswamy,
    S., 2015. Deep convolutional neural networks on multichannel time series for human
    activity recognition, in: IJCAI, Buenos Aires, Argentina, pp. 25–31.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2015年）Yang, J.B., Nguyen, M.N., San, P.P., Li, X.L., Krishnaswamy, S.,
    2015. 用于人体活动识别的多通道时间序列深度卷积神经网络，IJCAI，阿根廷布宜诺斯艾利斯，pp. 25–31。
- en: 'Yang (2009) Yang, Q., 2009. Activity recognition: Linking low-level sensors
    to high-level intelligence., in: IJCAI, pp. 20–25.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang (2009) Yang, Q., 2009. 活动识别：将低级传感器与高级智能链接，见：IJCAI，第20–25页。
- en: 'Yao et al. (2017) Yao, S., Hu, S., Zhao, Y., Zhang, A., Abdelzaher, T., 2017.
    Deepsense: A unified deep learning framework for time-series mobile sensing data
    processing, in: WWW, pp. 351–360.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2017) Yao, S., Hu, S., Zhao, Y., Zhang, A., Abdelzaher, T., 2017.
    Deepsense：一个统一的深度学习框架，用于时间序列移动传感数据处理，见：WWW，第351–360页。
- en: 'Zebin et al. (2016) Zebin, T., Scully, P.J., Ozanyan, K.B., 2016. Human activity
    recognition with inertial sensors using a deep learning approach, in: SENSORS,
    pp. 1–3.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zebin et al. (2016) Zebin, T., Scully, P.J., Ozanyan, K.B., 2016. 使用深度学习方法和惯性传感器进行人体活动识别，见：传感器，第1–3页。
- en: 'Zeng et al. (2014) Zeng, M., Nguyen, L.T., Yu, B., Mengshoel, O.J., Zhu, J.,
    Wu, P., Zhang, J., 2014. Convolutional neural networks for human activity recognition
    using mobile sensors, in: Mobile Computing, Applications and Services (MobiCASE),
    2014 6th International Conference on, IEEE. pp. 197–205.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeng et al. (2014) Zeng, M., Nguyen, L.T., Yu, B., Mengshoel, O.J., Zhu, J.,
    Wu, P., Zhang, J., 2014. 使用移动传感器的卷积神经网络进行人类活动识别，见：移动计算、应用与服务（MobiCASE），2014年第六届国际会议，IEEE。第197–205页。
- en: 'Zhang et al. (2015a) Zhang, L., Wu, X., Luo, D., 2015a. Human activity recognition
    with hmm-dnn model, in: Cognitive Informatics & Cognitive Computing (ICCI* CC),
    2015 IEEE 14th International Conference on, IEEE. pp. 192–197.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2015a) Zhang, L., Wu, X., Luo, D., 2015a. 使用HMM-DNN模型进行人体活动识别，见：认知信息学与认知计算（ICCI*
    CC），2015 IEEE第14届国际会议，IEEE。第192–197页。
- en: 'Zhang et al. (2015b) Zhang, L., Wu, X., Luo, D., 2015b. Real-time activity
    recognition on smartphones using deep neural networks, in: UIC, IEEE. pp. 1236–1242.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2015b) Zhang, L., Wu, X., Luo, D., 2015b. 使用深度神经网络进行智能手机上的实时活动识别，见：UIC，IEEE。第1236–1242页。
- en: 'Zhang et al. (2015c) Zhang, L., Wu, X., Luo, D., 2015c. Recognizing human activities
    from raw accelerometer data using deep neural networks, in: IEEE 14th International
    Conference on Machine Learning and Applications (ICMLA), pp. 865–870.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2015c) Zhang, L., Wu, X., Luo, D., 2015c. 使用深度神经网络从原始加速度计数据中识别人体活动，见：IEEE第14届国际机器学习与应用会议（ICMLA），第865–870页。
- en: 'Zhang et al. (2017a) Zhang, S., Ng, W.W., Zhang, J., Nugent, C.D., 2017a. Human
    activity recognition using radial basis function neural network trained via a
    minimization of localized generalization error, in: International Conference on
    Ubiquitous Computing and Ambient Intelligence, Springer. pp. 498–507.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2017a) Zhang, S., Ng, W.W., Zhang, J., Nugent, C.D., 2017a. 使用通过最小化局部化泛化误差训练的径向基函数神经网络进行人体活动识别，见：普适计算与环境智能国际会议，Springer。第498–507页。
- en: 'Zhang et al. (2017b) Zhang, Y., Li, X., Zhang, J., et al., 2017b. Car-a deep
    learning structure for concurrent activity recognition, in: IPSN, pp. 299–300.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2017b) Zhang, Y., Li, X., Zhang, J., 等，2017b. CAR：用于并发活动识别的深度学习结构，见：IPSN，第299–300页。
- en: 'Zheng et al. (2014) Zheng, Y., Liu, Q., Chen, E., Ge, Y., Zhao, J.L., 2014.
    Time series classification using multi-channels deep convolutional neural networks,
    in: International Conference on Web-Age Information Management, Springer. pp.
    298–310.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2014) Zheng, Y., Liu, Q., Chen, E., Ge, Y., Zhao, J.L., 2014.
    使用多通道深度卷积神经网络进行时间序列分类，见：网络时代信息管理国际会议，Springer。第298–310页。
- en: Zheng et al. (2016) Zheng, Y., Liu, Q., Chen, E., Ge, Y., Zhao, J.L., 2016.
    Exploiting multi-channels deep convolutional neural networks for multivariate
    time series classification. Frontiers of Computer Science 10, 96–112.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2016) Zheng, Y., Liu, Q., Chen, E., Ge, Y., Zhao, J.L., 2016.
    利用多通道深度卷积神经网络进行多变量时间序列分类。《计算机科学前沿》10, 第96–112页。
