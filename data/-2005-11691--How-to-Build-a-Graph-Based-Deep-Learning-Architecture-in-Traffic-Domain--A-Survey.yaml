- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-06 20:01:09'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 20:01:09'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2005.11691] How to Build a Graph-Based Deep Learning Architecture in Traffic
    Domain: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2005.11691] 如何在交通领域构建基于图的深度学习架构: 调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2005.11691](https://ar5iv.labs.arxiv.org/html/2005.11691)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2005.11691](https://ar5iv.labs.arxiv.org/html/2005.11691)
- en: 'How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A
    Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '如何在交通领域构建基于图的深度学习架构: 调查'
- en: 'Jiexia Ye, Juanjuan Zhao*, Kejiang Ye, IEEE Member,  Chengzhong Xu, IEEE Fellow
    *Corresponding author: Juanjuan Zhao Jiexia Ye, Juanjuan Zhao, Kejiang Ye are
    with Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences,
    China (E-mail: {jx.ye, jj.zhao, kj.ye}@siat.ac.cn). Chengzhong Xu is with State
    Key Lab of IOTSC, Department of Computer Science, University of Macau, Macau SAR,
    China (E-mail: czxu@um.edu.mo).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 'Jiexia Ye, Juanjuan Zhao*, Kejiang Ye, IEEE 会员, Chengzhong Xu, IEEE 研究员 *通讯作者:
    Juanjuan Zhao Jiexia Ye, Juanjuan Zhao, Kejiang Ye 在中国科学院深圳先进技术研究院工作（电子邮件: {jx.ye,
    jj.zhao, kj.ye}@siat.ac.cn）。Chengzhong Xu 在澳门大学计算机科学系物联网系统国家重点实验室工作（电子邮件: czxu@um.edu.mo）。'
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: In recent years, various deep learning architectures have been proposed to solve
    complex challenges (e.g. spatial dependency, temporal dependency) in traffic domain,
    which have achieved satisfactory performance. These architectures are composed
    of multiple deep learning techniques in order to tackle various challenges in
    traffic tasks. Traditionally, convolution neural networks (CNNs) are utilized
    to model spatial dependency by decomposing the traffic network as grids. However,
    many traffic networks are graph-structured in nature. In order to utilize such
    spatial information fully, it’s more appropriate to formulate traffic networks
    as graphs mathematically. Recently, various novel deep learning techniques have
    been developed to process graph data, called graph neural networks (GNNs). More
    and more works combine GNNs with other deep learning techniques to construct an
    architecture dealing with various challenges in a complex traffic task, where
    GNNs are responsible for extracting spatial correlations in traffic network. These
    graph-based architectures have achieved state-of-the-art performance. To provide
    a comprehensive and clear picture of such emerging trend, this survey carefully
    examines various graph-based deep learning architectures in many traffic applications.
    We first give guidelines to formulate a traffic problem based on graph and construct
    graphs from various kinds of traffic datasets. Then we decompose these graph-based
    architectures to discuss their shared deep learning techniques, clarifying the
    utilization of each technique in traffic tasks. What’s more, we summarize some
    common traffic challenges and the corresponding graph-based deep learning solutions
    to each challenge. Finally, we provide benchmark datasets, open source codes and
    future research directions in this rapidly growing field.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，已经提出了各种深度学习架构以解决交通领域中的复杂挑战（例如空间依赖性、时间依赖性），这些架构已取得令人满意的性能。这些架构由多个深度学习技术组成，以应对交通任务中的各种挑战。传统上，卷积神经网络（CNNs）用于通过将交通网络分解为网格来建模空间依赖性。然而，许多交通网络本质上是图结构的。为了充分利用这些空间信息，更合适的做法是将交通网络在数学上表述为图。最近，已经开发了各种新颖的深度学习技术来处理图数据，这些技术称为图神经网络（GNNs）。越来越多的工作将GNNs与其他深度学习技术结合，以构建一种架构来处理复杂交通任务中的各种挑战，其中GNNs负责提取交通网络中的空间关联。这些基于图的架构已实现了最先进的性能。为了全面清晰地呈现这一新兴趋势，本调查仔细检查了许多交通应用中的各种基于图的深度学习架构。我们首先提供了将交通问题基于图进行表述的指南，并从各种交通数据集中构建图。然后，我们对这些基于图的架构进行分解，讨论它们共享的深度学习技术，澄清每种技术在交通任务中的应用。此外，我们总结了一些常见的交通挑战及相应的基于图的深度学习解决方案。最后，我们提供了基准数据集、开源代码和该快速发展的领域的未来研究方向。
- en: 'Index Terms:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '索引词:'
- en: Graph Neural Networks, GNNs, Graph Convolution Network, GCN, Graph, Deep Learning,
    Traffic Forecasting, Traffic Domain, ITS
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图神经网络，GNNs，图卷积网络，GCN，图，深度学习，交通预测，交通领域，智能交通系统
- en: I Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Along with the acceleration of urbanization process, mass population is quickly
    gathering together towards cities. In many cities, especially cities in developing
    countries, the rapidly increasing number of private vehicles and growing demand
    of public transport services are putting great pressure on their current transportation
    systems. The traffic problems such as frequent traffic jams, serious traffic accidents
    and long commute have seriously decreased the operation efficiency of cities and
    degraded the travel experience of passengers. To address these challenges, many
    cities are committed to develop an Intelligent Transportation System (ITS) which
    can provide efficient traffic management, accurate traffic resources allocation
    and high-quality transportation service. Such a system can reduce traffic accidents,
    relieve traffic congestion and ensure public traffic safety.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着城市化进程的加速，大量人口迅速向城市聚集。在许多城市，尤其是发展中国家的城市，私人车辆数量的快速增长和对公共交通服务需求的增加对现有交通系统造成了巨大压力。交通问题如频繁的交通拥堵、严重的交通事故和长时间的通勤严重降低了城市的运行效率，并恶化了乘客的出行体验。为了应对这些挑战，许多城市致力于开发一个智能交通系统（ITS），以提供高效的交通管理、准确的交通资源分配和高质量的交通服务。这样的系统可以减少交通事故、缓解交通拥堵，并确保公共交通安全。
- en: To construct an Intelligent Transportation System which makes cities smart,
    there are mainly two indispensable components, i.e. intelligent infrastructures
    and advanced algorithms.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建一个使城市智能化的智能交通系统，主要有两个不可或缺的组件，即智能基础设施和先进算法。
- en: On one hand, with the increasing investment in transportation infrastructures,
    there are more and more traffic equipments and systems, including loop detectors,
    probes, cameras on road networks, GPS in taxis or buses, smart cards on subways
    and buses, automatic fare collection system and online ride-hailing system. These
    infrastructures produce traffic data around-the-clock, which are heterogeneous
    data, including numeric data (e.g. GPS trajectories, traffic measurements), image/video
    data (e.g. vehicle images) and textual data (e.g. incident reports). These transportation
    data are enormous in volume and complicated in structure, containing complex traffic
    patterns (e.g. spatiotemporal dependency, highly nonlinearity, complex dynamics).
    There is an urgent need to utilize more intelligent and powerful approaches to
    process such traffic data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一方面，随着对交通基础设施投资的增加，道路网络上出现了越来越多的交通设备和系统，包括环形探测器、探头、道路摄像头、出租车或公交车上的GPS、地铁和公交车上的智能卡、自动收费系统和在线打车系统。这些基础设施全天候产生交通数据，这些数据是异构的，包括数值数据（例如GPS轨迹、交通测量）、图像/视频数据（例如车辆图像）和文本数据（例如事件报告）。这些交通数据在体量上庞大，结构上复杂，包含复杂的交通模式（例如时空依赖性、高度非线性、复杂的动态性）。急需利用更智能、更强大的方法来处理这些交通数据。
- en: On the other hand, in transportation domain, researchers have witnessed the
    algorithms evolving from statistical methods, to machine learning models and recently
    to deep learning approaches. In the early stage, statistic methods including ARIMA
    and its variants [[1](#bib.bib1)],[[2](#bib.bib2)], VAR[[3](#bib.bib3)], Kalman
    filtering [[4](#bib.bib4)] were prevalent, as they have solid and widely accepted
    mathematical foundations. However, the linear and stationarity assumptions of
    these methods are violated by the highly non-linearity and dynamics in traffic
    data, resulting in poor performance in practice. Traditional machine learning
    approaches such as Support Vector Machine [[5](#bib.bib5)], K-Nearest Neighbors[[6](#bib.bib6)]
    can model non-linearity and extract more complex correlations in traffic data.
    However, the shallow architecture, manual feature selection and separated learning
    in these models are considered to be unsatisfactory in big data scenarios [[7](#bib.bib7)].
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在交通领域，研究人员目睹了算法从统计方法、到机器学习模型、最近到深度学习方法的演变。在早期阶段，统计方法包括ARIMA及其变体[[1](#bib.bib1)]、[[2](#bib.bib2)]，VAR[[3](#bib.bib3)]，Kalman滤波[[4](#bib.bib4)]曾经广泛使用，因为它们具有坚实且被广泛接受的数学基础。然而，这些方法的线性和稳定性假设被交通数据中的高度非线性和动态性所违背，导致实际表现不佳。传统的机器学习方法如支持向量机[[5](#bib.bib5)]、K-近邻[[6](#bib.bib6)]可以建模非线性，并提取交通数据中的更复杂的关联。然而，这些模型的浅层架构、手动特征选择和分离学习在大数据场景中被认为是不令人满意的[[7](#bib.bib7)]。
- en: The breakthrough of deep learning in many domains, including computer vision,
    natural language processing has attracted attention from transportation industry
    and research community. Deep learning techniques overcome the handcrafted feature
    engineering by providing an end-to-end learning from raw traffic data. The powerful
    capacities of deep learning techniques to approximate any complex functions in
    theory can model more complicated patterns in various traffic tasks. In recent
    years, due to the increasing computing power (e.g. GPU) and sufficient traffic
    data [[7](#bib.bib7)], deep learning based techniques have been widely employed
    and achieved state-of-the-art performance in various traffic applications. The
    Recurrent neural networks (RNNs) and Convolutional neural networks (CNNs) based
    architectures used to be popular in extracting spatiotemporal dependencies. In
    these architectures, RNN or its variants are employed to extract the temporal
    correlations in traffic data [[8](#bib.bib8)]. CNNs are used to capture the spatial
    correlations in grid-based traffic network [[9](#bib.bib9)]. However, many traffic
    networks are graph-structured in nature, e.g. road network [[10](#bib.bib10)]
    and subway network. The spatial features learned in CNN are not optimal for representing
    the graph-based traffic network. Although some previous works have analyzed traffic
    problems in a graph view [[11](#bib.bib11)],[[12](#bib.bib12)], these traditional
    approaches are not powerful enough to process big data and tackle complicated
    correlations in traffic network.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在许多领域的突破，包括计算机视觉和自然语言处理，已引起交通行业和研究界的关注。深度学习技术通过从原始交通数据中提供端到端学习，克服了手工特征工程的限制。深度学习技术理论上能够近似任何复杂函数，从而能够建模各种交通任务中的复杂模式。近年来，由于计算能力的提高（例如
    GPU）和足够的交通数据 [[7](#bib.bib7)]，基于深度学习的技术已被广泛应用，并在各种交通应用中取得了最先进的性能。基于递归神经网络（RNNs）和卷积神经网络（CNNs）的架构曾在提取时空依赖性方面非常流行。在这些架构中，RNN
    或其变体被用来提取交通数据中的时间相关性 [[8](#bib.bib8)]。CNNs 用于捕捉网格状交通网络中的空间相关性 [[9](#bib.bib9)]。然而，许多交通网络本质上是图结构的，例如道路网络
    [[10](#bib.bib10)] 和地铁网络。在 CNN 中学习到的空间特征并不适合表示基于图的交通网络。尽管一些先前的工作已经从图的角度分析了交通问题
    [[11](#bib.bib11)], [[12](#bib.bib12)]，这些传统方法在处理大数据和解决交通网络中的复杂相关性方面并不够强大。
- en: Recently, many researchers have extended deep learning approaches on graph data
    to exploit graph structure information [[13](#bib.bib13)] and proposed a new group
    of neural networks called graph neural networks (GNNs)[[14](#bib.bib14)],[[15](#bib.bib15)],[[16](#bib.bib16)],
    which aims to address graph-related applications. GNNs have become the state-of-the-art
    approaches in many domains, including computer vision [[17](#bib.bib17)], natural
    language processing [[18](#bib.bib18)], biology [[19](#bib.bib19)], recommendation
    system [[20](#bib.bib20)]. Since many traffic data are graph-structured, many
    existing works incorporate GNNs into a deep learning architecture to capture the
    spatial dependency. Recent works have shown that such GNNs-based architectures
    can achieve better performance than CNNs-based architectures, for that most traffic
    networks are graph-structured naturally and GNNs can extract the spatial dependency
    more accurately. In addition, some tasks inherently require researchers to conduct
    prediction based on a graph, e.g. prediction in traffic network with irregular
    shapes. Many related works have been produced during the last couple of years
    and more are on the road. Under this circumstance, a comprehensive literature
    review on these graph-based deep learning architectures in transportation domain
    would be very timely, which is exactly our work.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，许多研究者扩展了深度学习方法在图数据上的应用，以利用图结构信息 [[13](#bib.bib13)]，并提出了一组新的神经网络，称为图神经网络（GNNs）[[14](#bib.bib14)],
    [[15](#bib.bib15)], [[16](#bib.bib16)]，旨在解决图相关的应用。GNNs 已成为许多领域的最先进方法，包括计算机视觉 [[17](#bib.bib17)]、自然语言处理
    [[18](#bib.bib18)]、生物学 [[19](#bib.bib19)]、推荐系统 [[20](#bib.bib20)]。由于许多交通数据是图结构的，许多现有的工作将
    GNNs 融入深度学习架构中，以捕捉空间依赖性。近期的工作表明，这种基于 GNNs 的架构可以比基于 CNNs 的架构实现更好的性能，因为大多数交通网络自然是图结构的，GNNs
    能够更准确地提取空间依赖性。此外，一些任务本质上要求研究人员基于图进行预测，例如预测具有不规则形状的交通网络。近年来已经产生了许多相关工作，还有更多正在进行中。在这种情况下，对这些图基深度学习架构在交通领域的全面文献综述将非常及时，这正是我们的工作。
- en: To our best knowledge, we are the first to provide a comprehensive survey on
    graph-based deep learning works in traffic domain. Note that some works we review
    actually work on similar traffic problems with similar techniques. Our work can
    help the upcoming researchers avoid repetitive works and focus on new solutions.
    What’s more, the practical and clear guidance in this survey enables participators
    to apply these new emerging approaches in real-world traffic tasks quickly.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，我们是首个对交通领域中的基于图的深度学习工作的全面调查进行综述的研究。值得注意的是，我们评审的一些工作实际上解决了类似的交通问题，并使用了类似的技术。我们的工作可以帮助未来的研究者避免重复的工作，集中于新的解决方案。此外，本调查中的实际和清晰的指导使参与者能够迅速将这些新兴方法应用于现实世界的交通任务中。
- en: 'To sum up, the main contributions of this paper are as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本文的主要贡献如下：
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We systematically outline traffic problems, related research directions, challenges
    and techniques in traffic domain, which can help related researchers to locate
    or expand their researches.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们系统地概述了交通问题、相关研究方向、挑战和交通领域的技术，这可以帮助相关研究人员定位或扩展他们的研究。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We summarize a general formulation about various traffic problems and provide
    a specific guidance to construct graphs from several typical kinds of raw traffic
    datasets. Such thorough summarization is quite practical and can accelerate the
    applications of graph-based approaches in traffic domain.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们总结了关于各种交通问题的一般性公式，并提供了从几种典型的原始交通数据集中构建图的具体指导。这种彻底的总结非常实用，可以加速基于图的方法在交通领域的应用。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We provide a comprehensive review over typical deep learning techniques widely
    used in graph-based traffic works. We elaborate their theoretical aspects, advantages,
    limitations and variants in specific traffic tasks, hoping to inspire the followers
    to develop more novel models.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提供了对广泛应用于基于图的交通工作中的典型深度学习技术的全面回顾。我们详细阐述了它们的理论方面、优点、局限性和在特定交通任务中的变体，希望能够激发研究者开发更多创新模型。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We discuss some challenges shared by most graph-based traffic tasks. For each
    challenge, we conclude multiple deep learning-based solutions and make necessary
    comparison, providing useful suggestions for model selection in traffic tasks.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们讨论了大多数基于图的交通任务所面临的一些挑战。对于每个挑战，我们总结了多种基于深度学习的解决方案，并进行必要的比较，为交通任务中的模型选择提供有用的建议。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We collect benchmark datasets, open-source codes in related papers to facilitate
    baseline experiments in traffic domain. Finally, we propose some future research
    directions.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们收集了基准数据集和相关论文中的开源代码，以促进交通领域的基线实验。最后，我们提出了一些未来的研究方向。
- en: 'The rest of the paper is organized as follows. Section [II](#S2 "II Related
    Research Surveys ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic
    Domain: A Survey") presents some surveys in traffic domain and some reviews about
    graph neural networks. Section [III](#S3 "III Problems, Research Directions and
    Challenges ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic
    Domain: A Survey") briefly outlines several traffic problems and the corresponding
    research directions, challenges and solutions. Section [IV](#S4 "IV Problem Formulation
    and Graph Construction ‣ How to Build a Graph-Based Deep Learning Architecture
    in Traffic Domain: A Survey") summarizes a general formulation about traffic problems
    and the graph construction from traffic datasets. Section [V](#S5 "V Deep Learning
    Techniques Perspective ‣ How to Build a Graph-Based Deep Learning Architecture
    in Traffic Domain: A Survey") analyzes the functionality, advantages and defects
    of GNNs and other deep learning techniques, as well as examining the tricks to
    create novel variants of these techniques in specific traffic tasks. Section [VI](#S6
    "VI Challenges Perspective ‣ How to Build a Graph-Based Deep Learning Architecture
    in Traffic Domain: A Survey") discusses common challenges in traffic domain and
    the corresponding multiple solutions. Section [VII](#S7 "VII Public Datasets and
    Open Source Codes ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic
    Domain: A Survey") provides hyperlinks of datasets and open codes in papers we
    investigate. Section [VIII](#S8 "VIII Future Directions ‣ How to Build a Graph-Based
    Deep Learning Architecture in Traffic Domain: A Survey") presents future directions.
    Section [IX](#S9 "IX Conclusion ‣ How to Build a Graph-Based Deep Learning Architecture
    in Traffic Domain: A Survey") concludes the paper.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '论文的其余部分组织如下。第[II](#S2 "II Related Research Surveys ‣ How to Build a Graph-Based
    Deep Learning Architecture in Traffic Domain: A Survey")节介绍了交通领域的一些调查以及图神经网络的一些评论。第[III](#S3
    "III Problems, Research Directions and Challenges ‣ How to Build a Graph-Based
    Deep Learning Architecture in Traffic Domain: A Survey")节简要概述了几个交通问题以及相应的研究方向、挑战和解决方案。第[IV](#S4
    "IV Problem Formulation and Graph Construction ‣ How to Build a Graph-Based Deep
    Learning Architecture in Traffic Domain: A Survey")节总结了有关交通问题的一般性公式化以及从交通数据集中构建图的过程。第[V](#S5
    "V Deep Learning Techniques Perspective ‣ How to Build a Graph-Based Deep Learning
    Architecture in Traffic Domain: A Survey")节分析了GNNs和其他深度学习技术的功能、优点和缺陷，并探讨了在特定交通任务中创建这些技术的新变体的技巧。第[VI](#S6
    "VI Challenges Perspective ‣ How to Build a Graph-Based Deep Learning Architecture
    in Traffic Domain: A Survey")节讨论了交通领域的常见挑战以及相应的多种解决方案。第[VII](#S7 "VII Public Datasets
    and Open Source Codes ‣ How to Build a Graph-Based Deep Learning Architecture
    in Traffic Domain: A Survey")节提供了我们调查论文中的数据集和开源代码的超链接。第[VIII](#S8 "VIII Future
    Directions ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic
    Domain: A Survey")节介绍了未来的研究方向。第[IX](#S9 "IX Conclusion ‣ How to Build a Graph-Based
    Deep Learning Architecture in Traffic Domain: A Survey")节总结了论文内容。'
- en: II Related Research Surveys
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 相关研究调查
- en: There have been some surveys summarizing the development process of algorithms
    in traffic tasks from different perspectives. Karlaftis et al. [[21](#bib.bib21)]
    discussed differences and similarities between statistical methods and neural
    networks to promote the comprehension between these two communities. Vlahogianni
    et al. [[22](#bib.bib22)] reviewed ten challenges on short-term traffic forecasting,
    which stemmed from the changing needs of ITS applications. Xie et al. [[23](#bib.bib23)]
    conducted a comprehensive overview of approaches in urban flow forecasting. Liu
    et al. [[7](#bib.bib7)] classified deep learning based urban big data fusion methods
    into three categories, i.e. DL-output-based fusion, DL-input-based fusion and
    DL-double-stage-based fusion. Deep learning approaches for popular topics including
    traffic network representation, traffic flow forecasting, traffic signal control,
    automatic vehicle detection are discussed in [[24](#bib.bib24)], [[25](#bib.bib25)].
    Veres et al. [[26](#bib.bib26)] and Chen et al.[[27](#bib.bib27)] gave a similar
    but more elaborate analysis on new emerging deep learning models in various transportation
    topics. Wang et al. [[28](#bib.bib28)] provided a spatial-temporal perspective
    to summarize deep learning techniques in traffic domain and other domains. However,
    all these surveys do not take graph neural networks (GNNs) related literatures
    into consideration, except that Wang et al. [[28](#bib.bib28)] mentioned GNNs
    but in a very short subsection.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 已有一些综述从不同的角度总结了交通任务中算法的发展过程。Karlaftis 等人 [[21](#bib.bib21)] 讨论了统计方法和神经网络之间的异同，以促进这两个社区之间的理解。Vlahogianni
    等人 [[22](#bib.bib22)] 回顾了短期交通预测的十个挑战，这些挑战源于 ITS 应用需求的变化。Xie 等人 [[23](#bib.bib23)]
    对城市流量预测的方法进行了全面的概述。Liu 等人 [[7](#bib.bib7)] 将基于深度学习的城市大数据融合方法分为三类，即 DL 输出基融合、DL
    输入基融合和 DL 双阶段融合。有关交通网络表示、交通流预测、交通信号控制、自动车辆检测等热门话题的深度学习方法在 [[24](#bib.bib24)]、[[25](#bib.bib25)]
    中进行了讨论。Veres 等人 [[26](#bib.bib26)] 和 Chen 等人 [[27](#bib.bib27)] 对各种交通运输主题中新兴的深度学习模型进行了类似但更详细的分析。Wang
    等人 [[28](#bib.bib28)] 从时空角度总结了交通领域和其他领域的深度学习技术。然而，除了 Wang 等人 [[28](#bib.bib28)]
    在非常简短的子章节中提到 GNN 外，所有这些综述均未考虑图神经网络（GNN）相关的文献。
- en: On the other hand, in recent years, there are several reviews summarizing literatures
    about GNNs in different aspects. Bronstein et al. [[29](#bib.bib29)] is the first
    to overview deep learning techniques on processing data in non-Euclidean space
    (e.g. graph data). Zhou et al. [[30](#bib.bib30)] categorized GNNs into graph
    types, propagation types and training types. In addition, they divided related
    applications into structural scenarios, non-structural scenarios, and other scenarios.
    Zhang et al.[[31](#bib.bib31)] introduced GNNs on small graphs and giant graphs
    respectively. Quan et al. [[32](#bib.bib32)] and Zhang et al. [[33](#bib.bib33)]
    focused on reviewing works in a specific branch of GNNs, i.e. graph convolutional
    network (GCN). However, they seldom introduce GNNs works in traffic scenarios.
    Wu et.al proposed [[34](#bib.bib34)] the only survey spending a paragraph to describe
    GNNs in traffic domain, which is obviously not enough for anyone desiring to explore
    this field.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，近年来有几篇综述总结了关于 GNN 的不同方面的文献。Bronstein 等人 [[29](#bib.bib29)] 是首个概述处理非欧几里得空间（如图数据）中的深度学习技术的研究。Zhou
    等人 [[30](#bib.bib30)] 将 GNN 按图类型、传播类型和训练类型进行了分类。此外，他们还将相关应用分为结构场景、非结构场景和其他场景。Zhang
    等人 [[31](#bib.bib31)] 分别介绍了小图和大图中的 GNN。Quan 等人 [[32](#bib.bib32)] 和 Zhang 等人 [[33](#bib.bib33)]
    专注于回顾 GNN 的特定分支，即图卷积网络（GCN）的研究。然而，他们很少介绍 GNN 在交通场景中的工作。Wu 等人 [[34](#bib.bib34)]
    提出了唯一一个在交通领域描述 GNN 的综述，然而仅用一段话描述显然不足以满足任何希望深入探讨这一领域的人的需求。
- en: In summary, there still lacks a systematic and elaborated survey to explore
    the rapidly developed graph-based deep learning techniques in traffic domain recently.
    Our work aims to fill this gap and promote understanding of the new emerging techniques
    in transportation community.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，目前仍缺乏一个系统且详尽的综述，以探讨最近在交通领域快速发展的基于图的深度学习技术。我们的工作旨在填补这一空白，促进交通社区对新兴技术的理解。
- en: III Problems, Research Directions and Challenges
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 问题、研究方向和挑战
- en: '![Refer to caption](img/b4882e1dfd04f5f90bba98791b446b60.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/b4882e1dfd04f5f90bba98791b446b60.png)'
- en: 'Figure 1: Typical traffic problems and the corresponding research directions'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：典型交通问题及其对应的研究方向
- en: 'In this section, we introduce background knowledge in traffic domain briefly,
    including some important traffic problems and the corresponding research directions
    (as shown in Figure [1](#S3.F1 "Figure 1 ‣ III Problems, Research Directions and
    Challenges ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic
    Domain: A Survey")), as well as common challenges and techniques under these problems.
    On one hand, we believe that such a concise but systematic introduction can help
    readers understand this domain quickly. On the other hand, our survey shows that
    existing works related with graph-based deep learning techniques only cover some
    research directions, which inspires successors to transfer similar techniques
    to remaining directions.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们简要介绍交通领域的背景知识，包括一些重要的交通问题及其相应的研究方向（如图 [1](#S3.F1 "Figure 1 ‣ III Problems,
    Research Directions and Challenges ‣ How to Build a Graph-Based Deep Learning
    Architecture in Traffic Domain: A Survey") 所示），以及这些问题下的常见挑战和技术。一方面，我们相信这样简洁但系统的介绍可以帮助读者迅速理解这一领域。另一方面，我们的调查显示，现有与图基深度学习技术相关的工作仅涵盖了部分研究方向，这激励了后继者将类似技术转移到剩余方向。'
- en: III-A Traffic Problems
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 交通问题
- en: The goals the transportation community aims to achieve include relieving traffic
    congestion, satisfying travel demand, enhancing traffic management, ensuring transportation
    safety and realizing automatic driving. Each problem under the corresponding traffic
    goal can be partitioned into several research directions and each direction can
    serve more than one problem.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 交通社区的目标包括缓解交通拥堵、满足旅行需求、增强交通管理、确保交通安全和实现自动驾驶。每个与相应交通目标相关的问题可以细分为若干研究方向，每个方向可以服务于多个问题。
- en: III-A1 Traffic Congestion
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A1 交通拥堵
- en: Traffic congestion [[35](#bib.bib35)] is one of the most important and urgent
    problems in modern cities in terms of significant time loss, air pollution and
    energy waste. The congestion can be solved by increasing the traffic efficiency
    [[36](#bib.bib36)], [[37](#bib.bib37)], alleviating the traffic congestion on
    road network [[38](#bib.bib38)], [[39](#bib.bib39)], [[40](#bib.bib40)], controlling
    the road conditions by traffic state prediction[[41](#bib.bib41)],[[42](#bib.bib42)],
    optimizing vehicle flow by controlling traffic signals [[43](#bib.bib43)],[[44](#bib.bib44)],
    optimizing passenger flow by predicting passenger demand in public transportation
    systems [[45](#bib.bib45)].
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 交通拥堵[[35](#bib.bib35)]是现代城市中最重要和最紧迫的问题之一，涉及显著的时间损失、空气污染和能源浪费。可以通过提高交通效率[[36](#bib.bib36)]，[[37](#bib.bib37)]、缓解道路网络上的交通拥堵[[38](#bib.bib38)]，[[39](#bib.bib39)]，[[40](#bib.bib40)]、通过交通状态预测控制道路条件[[41](#bib.bib41)]，[[42](#bib.bib42)]、通过控制交通信号优化车辆流量[[43](#bib.bib43)]，[[44](#bib.bib44)]、通过预测公共交通系统中的乘客需求优化乘客流量[[45](#bib.bib45)]来解决拥堵问题。
- en: III-A2 Travel Demand
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A2 交通需求
- en: The travel demand prediction refers to the demand of traffic services, such
    as taxi, bike, metro and bus in a crowd perspective. With the emerging of online
    ride-hailing platforms (e.g. Uber, DiDi) and rapid development of public transportation
    systems (e.g. metro system and bus system), travel demand prediction has become
    more and more important for transport authorities, business sectors and individuals.
    For related authorities, it can help to better allocate resources, e.g. increase
    metro frequency at rush hours, add more buses to service hotspots. For business
    sector, it enables them to better manage taxi-hiring [[46](#bib.bib46)], carpooling
    [[47](#bib.bib47)], bike-sharing services [[48](#bib.bib48)],[[49](#bib.bib49)],
    and maximize their revenues. For individuals, it encourages users to consider
    various forms of transportation to decrease their commuting time and improve travel
    experience.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 旅行需求预测指的是从人群角度出发的交通服务需求，例如出租车、自行车、地铁和公交。随着在线打车平台（如Uber、滴滴）和公共交通系统（如地铁系统和公交系统）的快速发展，旅行需求预测对交通部门、商业部门和个人的重要性越来越高。对相关部门而言，这有助于更好地分配资源，例如在高峰时段增加地铁频次，增加热门区域的公交车数量。对商业部门而言，它使他们能够更好地管理出租车租赁[[46](#bib.bib46)]、拼车[[47](#bib.bib47)]、共享自行车服务[[48](#bib.bib48)],
    [[49](#bib.bib49)]，并最大化收入。对个人而言，它鼓励用户考虑各种交通方式，以减少通勤时间并改善旅行体验。
- en: III-A3 Transportation Safety
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A3 交通安全
- en: Transportation safety is an indispensable part of public safety. Traffic accidents
    can not only cause damage to victims, vehicles and road infrastructures, but also
    lead to traffic congestion and reduce efficiency of road network. Therefore, monitoring
    the traffic accidents is essential to avoid property loss and save life. Many
    researchers focus on directions such as detecting traffic incidents [[50](#bib.bib50)],
    predicting traffic accidents from social media data [[51](#bib.bib51)], predicting
    the injury severity of traffic accidents [[52](#bib.bib52)], [[53](#bib.bib53)],
    predicting prevention of accidents [[54](#bib.bib54)], [[55](#bib.bib55)], [[56](#bib.bib56)].
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 交通安全是公共安全不可或缺的一部分。交通事故不仅会对受害者、车辆和道路基础设施造成损害，还会导致交通拥堵，降低道路网络的效率。因此，监控交通事故对于避免财产损失和拯救生命至关重要。许多研究者关注的方向包括检测交通事件[[50](#bib.bib50)]、从社交媒体数据预测交通事故[[51](#bib.bib51)]、预测交通事故的伤害严重性[[52](#bib.bib52)],
    [[53](#bib.bib53)]、预测事故预防[[54](#bib.bib54)], [[55](#bib.bib55)], [[56](#bib.bib56)]。
- en: III-A4 Traffic Surveillance
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A4 交通监控
- en: Nowadays, surveillance cameras have been widely deployed in city roads, generating
    numerous images and videos [[27](#bib.bib27)]. Such development has enhanced traffic
    surveillance, which includes traffic law enforcement, automatic toll collection
    [[57](#bib.bib57)] and traffic monitoring systems. The research directions of
    traffic surveillance include license plate detection[[58](#bib.bib58)], automatic
    vehicle detection [[59](#bib.bib59)], pedestrian detection [[60](#bib.bib60)].
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，监控摄像头已经在城市道路上广泛部署，生成了大量的图像和视频[[27](#bib.bib27)]。这种发展增强了交通监控，包括交通执法、自动收费[[57](#bib.bib57)]以及交通监控系统。交通监控的研究方向包括车牌检测[[58](#bib.bib58)]、自动车辆检测[[59](#bib.bib59)]、行人检测[[60](#bib.bib60)]。
- en: III-A5 Autonomous Driving
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A5 自动驾驶
- en: Recently, automatic driving vehicle has become a hot spot of research in transportation
    domain. Many tasks are related with visual recognition. The research directions
    of autonomous driving include lane/vehicle detection [[61](#bib.bib61)], pedestrian
    detection [[62](#bib.bib62)], traffic sign detection [[63](#bib.bib63)] and human/vehicle
    trajectory prediction [[64](#bib.bib64)].
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，自动驾驶车辆已成为交通领域的研究热点。许多任务涉及视觉识别。自动驾驶的研究方向包括车道/车辆检测[[61](#bib.bib61)]、行人检测[[62](#bib.bib62)]、交通标志检测[[63](#bib.bib63)]以及人/车轨迹预测[[64](#bib.bib64)]。
- en: III-B Research Directions
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 研究方向
- en: Our survey of graph-based deep learning in traffic domain shows that existing
    works focus mainly on traffic state prediction, travel demand prediction, trajectory
    prediction. A few works focus on vehicle behavior classification [[65](#bib.bib65)],
    optimal dynamic electronic toll collection (DETC) scheme [[57](#bib.bib57)], path
    availability [[66](#bib.bib66)], traffic signal control [[67](#bib.bib67)]. To
    our best knowledge, traffic incident detection and vehicle detection have not
    been explored based in a graph view yet.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对交通领域基于图的深度学习的调查显示，现有的工作主要集中在交通状态预测、旅行需求预测和轨迹预测上。少数工作关注于车辆行为分类[[65](#bib.bib65)]、优化动态电子收费（DETC）方案[[57](#bib.bib57)]、路径可用性[[66](#bib.bib66)]、交通信号控制[[67](#bib.bib67)]。据我们了解，基于图视角的交通事件检测和车辆检测尚未得到探索。
- en: III-B1 Traffic State Prediction
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B1 交通状态预测
- en: Traffic state in literatures refers to traffic flow, traffic speed, travel time,
    traffic density and so on. Traffic Flow Prediction (TFP) [[68](#bib.bib68)],[[69](#bib.bib69)],
    Traffic Speed Prediction (TSP) [[70](#bib.bib70)], [[71](#bib.bib71)], Travel
    Time Prediction (TTP) [[72](#bib.bib72)],[[73](#bib.bib73)], [[74](#bib.bib74)]
    are hot branches of traffic state prediction and have attracted intensive studies.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 文献中的交通状态指的是交通流量、交通速度、旅行时间、交通密度等。交通流量预测（TFP）[[68](#bib.bib68)], [[69](#bib.bib69)]、交通速度预测（TSP）[[70](#bib.bib70)],
    [[71](#bib.bib71)]、旅行时间预测（TTP）[[72](#bib.bib72)], [[73](#bib.bib73)], [[74](#bib.bib74)]是交通状态预测的热点分支，并吸引了大量研究。
- en: III-B2 Travel Demand Prediction
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B2 旅行需求预测
- en: Travel demand prediction aims to estimate the future number of users who require
    traffic services. It can be categorized into two kinds, i.e. zone-level demand
    prediction and origin-destination travel demand prediction. The former one aims
    to predict the future travel demand in each region of a city, for example, to
    predict future taxi request in each area of a city [[75](#bib.bib75)],[[76](#bib.bib76)],
    or to predict the station-level passenger demand in subway system [[77](#bib.bib77)],
    [[78](#bib.bib78)], [[79](#bib.bib79)], [[45](#bib.bib45)] or to predict the bike
    hiring demand in each region of a city [[48](#bib.bib48)],[[49](#bib.bib49)].
    The latter one aims to predict the number of travel demand from one region to
    another, which can provide richer information than the zone-level demand prediction
    and is a more challenging issue worth exploration. Up to now, there are only a
    few studies [[80](#bib.bib80)], [[81](#bib.bib81)], [[82](#bib.bib82)] directed
    towards the origin-destination based travel demand prediction, which is a promising
    research direction.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 旅行需求预测旨在估计未来需要交通服务的用户数量。它可以分为两种类型，即区域级需求预测和出发地-目的地旅行需求预测。前者旨在预测城市每个区域的未来旅行需求，例如，预测城市各个区域的未来出租车请求
    [[75](#bib.bib75)],[[76](#bib.bib76)]，或预测地铁系统的车站级乘客需求 [[77](#bib.bib77)], [[78](#bib.bib78)],
    [[79](#bib.bib79)], [[45](#bib.bib45)]，或预测城市每个区域的自行车租赁需求 [[48](#bib.bib48)],[[49](#bib.bib49)]。后者旨在预测从一个区域到另一个区域的旅行需求，这比区域级需求预测提供了更丰富的信息，是一个值得深入探索的更具挑战性的问题。至今，仅有少数研究
    [[80](#bib.bib80)], [[81](#bib.bib81)], [[82](#bib.bib82)]] 关注基于出发地-目的地的旅行需求预测，这是一个有前景的研究方向。
- en: III-B3 Traffic Signal Control
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B3 交通信号控制
- en: The traffic signal control aims to properly control the traffic lights so as
    to reduce vehicle staying time at the road intersections in the long run [[25](#bib.bib25)].
    Traffic signal control [[67](#bib.bib67)] can optimize the traffic flow and reduce
    traffic congestion and vehicle emission.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 交通信号控制旨在适当控制交通灯，以减少车辆在交叉路口的停留时间，从而在长期内 [[25](#bib.bib25)]。交通信号控制 [[67](#bib.bib67)]
    可以优化交通流量，减少交通拥堵和车辆排放。
- en: III-B4 Traffic Incident Detection
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B4 交通事件检测
- en: Major incidents can cause fatal injuries to travelers and long delays on a road
    network. Therefore, understanding the main cause of incidents and the impact of
    incidents on a traffic network is crucial for a modern transportation management
    system [[50](#bib.bib50)],[[52](#bib.bib52)], [[53](#bib.bib53)].
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 重大事件可能导致旅客重伤和道路网络的长时间延误。因此，了解事件的主要原因以及事件对交通网络的影响对现代交通管理系统至关重要 [[50](#bib.bib50)],[[52](#bib.bib52)],
    [[53](#bib.bib53)]。
- en: III-B5 Human/Vehicle Trajectory Prediction
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B5 人员/车辆轨迹预测
- en: Trajectory Prediction [[64](#bib.bib64)], [[83](#bib.bib83)], [[84](#bib.bib84)]
    aims to forecast future positions of dynamic agents in a scene. Accurate human/vehicle
    trajectories prediction is of great importance for downstream tasks including
    autonomous driving and traffic surveillance [[85](#bib.bib85)]. For instance,
    an accurate pedestrian trajectory prediction can help controller to control the
    vehicle ahead in a dangerous environment [[86](#bib.bib86)]. It can also enable
    transportation surveillance system to identify suspicious activities [[87](#bib.bib87)].
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 轨迹预测 [[64](#bib.bib64)], [[83](#bib.bib83)], [[84](#bib.bib84)] 旨在预测场景中动态代理的未来位置。准确的人员/车辆轨迹预测对包括自动驾驶和交通监控在内的下游任务非常重要
    [[85](#bib.bib85)]。例如，准确的行人轨迹预测可以帮助控制器在危险环境中控制前方车辆 [[86](#bib.bib86)]。它还可以使交通监控系统识别可疑活动
    [[87](#bib.bib87)]。
- en: III-C Challenges and Techniques Overview
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 挑战与技术概述
- en: '![Refer to caption](img/0d68339e180bc804472ff4d6cf39b0e4.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0d68339e180bc804472ff4d6cf39b0e4.png)'
- en: 'Figure 2: Traffic challenges and the corresponding deep learning techniques.
    SGCN refers spectral graph convolution network, DGCN refers diffusion graph convolution
    network, GAT refers graph attention network, TCN refers temporal convolution network,
    RNN refers recurrent neural network, GRU refers gated recurrent unit, LSTM refers
    long short term memory network, MLP refers multi-layer perceptron, Seq2Seq refers
    sequence to sequence model, GAN refers generative adversarial network.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：交通挑战及相应的深度学习技术。SGCN 指谱图卷积网络，DGCN 指扩散图卷积网络，GAT 指图注意力网络，TCN 指时间卷积网络，RNN 指递归神经网络，GRU
    指门控递归单元，LSTM 指长短期记忆网络，MLP 指多层感知器，Seq2Seq 指序列到序列模型，GAN 指生成对抗网络。
- en: Although traffic problems and the related research directions are different,
    most of them share the same challenges, e.g. spatial dependency, temporal dependency,
    external factors.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管交通问题及相关研究方向有所不同，但大多数都面临相同的挑战，例如空间依赖性、时间依赖性、外部因素。
- en: III-C1 Spatiotemporal Dependency
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-C1 时空依赖性
- en: There are complex spatiotemporal dependency in traffic data which can affect
    the prediction in traffic tasks. For instance, to predict a traffic congestion
    in a region, its previous traffic conditions and the traffic conditions of its
    surrounding regions are important factors for prediction[[35](#bib.bib35)],[[38](#bib.bib38)],[[39](#bib.bib39)].
    In vehicle trajectory prediction, the stochastic behaviors of surrounding vehicles
    and the historical information of self-trajectory influence the prediction performance
    [[88](#bib.bib88)]. When it comes to predict the ride-hailing demand in a region,
    its previous orders as well as orders in other regions with similar functionality
    are critical for prediction[[89](#bib.bib89)]. To predict the traffic signal,
    the geometric features of multiple intersections are taken into consideration,
    as well as the previous traffic flow around [[67](#bib.bib67)].
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 交通数据中存在复杂的时空依赖性，这可能影响交通任务中的预测。例如，要预测某一地区的交通拥堵，其之前的交通状况及周围地区的交通状况是预测的重要因素[[35](#bib.bib35)],[[38](#bib.bib38)],[[39](#bib.bib39)]。在车辆轨迹预测中，周围车辆的随机行为和自身轨迹的历史信息会影响预测性能[[88](#bib.bib88)]。预测某一地区的网约车需求时，该地区的历史订单以及其他具有相似功能地区的订单对预测至关重要[[89](#bib.bib89)]。预测交通信号时，需要考虑多个交叉口的几何特征，以及周围的交通流量[[67](#bib.bib67)]。
- en: III-C2 External Factors
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-C2 外部因素
- en: Except the spatiotemporal data, some types of data play an important role in
    traffic tasks, referred as external factors, such as holidays, weather conditions
    (e.g. rainfall, temperature, air quality), extreme events [[90](#bib.bib90)] and
    traffic incidents (e.g. incident time, incident type) [[91](#bib.bib91)]. The
    influence of external factors on traffic conditions can be observed in daily life.
    A rainstorm is likely to affect the traffic volume. A large-scale concert or football
    match results in traffic congregation, affecting traffic conditions around.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 除了时空数据外，一些类型的数据在交通任务中扮演着重要角色，称为外部因素，例如假期、天气条件（如降雨、温度、空气质量）、极端事件[[90](#bib.bib90)]和交通事件（如事件时间、事件类型）[[91](#bib.bib91)]。外部因素对交通状况的影响在日常生活中是可以观察到的。暴风雨可能会影响交通量。大规模音乐会或足球比赛会导致交通拥堵，影响周围的交通状况。
- en: To tackle challenges above, various deep learning techniques have been proposed.
    In this paper, we focus on graph-based deep learning architectures in traffic
    domain. Among these graph-based deep learning frameworks, graph neural networks
    (GNNs) are usually employed to model the spatial dependency in traffic network.
    Recurrent neural networks (RNNs) and temporal convolution network (TCN) are generally
    adopted to model the temporal dependency in traffic data. RNNs and Multi-layer
    Perceptrons (MLPs) are typically employed to process external factors. Sequence
    to Sequence (Seq2Seq) model is usually utilized to make multi-step traffic prediction.
    These techniques along with other tricks (e.g. gated mechanism, attention mechanism)
    are combined organically to improve the prediction accuracy.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为应对上述挑战，提出了各种深度学习技术。本文聚焦于交通领域的图基深度学习架构。在这些图基深度学习框架中，图神经网络（GNNs）通常用于建模交通网络中的空间依赖性。递归神经网络（RNNs）和时间卷积网络（TCN）通常用于建模交通数据中的时间依赖性。RNNs和多层感知器（MLPs）通常用于处理外部因素。序列到序列（Seq2Seq）模型通常用于进行多步骤交通预测。这些技术与其他技巧（如门控机制、注意力机制）有机结合，以提高预测准确性。
- en: 'In this paper, we aim to provide readers guidance about how to build a graph-based
    deep learning architecture and we have investigated enormous existing traffic
    works adopting graph-based deep learning solutions. In the following sections,
    we first introduce a common way to formulate the traffic problem and give detailed
    guidelines to build traffic graphs from various kinds of traffic data. Then we
    clarify the correlations between challenges and techniques (as shown in Figure
    [2](#S3.F2 "Figure 2 ‣ III-C Challenges and Techniques Overview ‣ III Problems,
    Research Directions and Challenges ‣ How to Build a Graph-Based Deep Learning
    Architecture in Traffic Domain: A Survey")) in two perspectives, i.e. the techniques
    perspective and the challenges perspective. In the perspective of techniques,
    we introduce several common techniques and interpret the way they tackle challenges
    in traffic tasks. In the perspective of challenges, we elaborate each challenge
    and summarize the techniques which can tackle this challenge. In a word, we hope
    to provide insights into solving traffic challenges with various deep learning
    techniques based on a graph view.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '在本文中，我们旨在为读者提供如何构建基于图的深度学习架构的指导，并且我们调查了大量现有的采用图基深度学习解决方案的交通相关工作。在接下来的部分中，我们首先介绍一种常见的交通问题制定方式，并提供详细的指导以从各种交通数据中构建交通图。然后，我们从两个角度澄清挑战与技术之间的关联（如图
    [2](#S3.F2 "Figure 2 ‣ III-C Challenges and Techniques Overview ‣ III Problems,
    Research Directions and Challenges ‣ How to Build a Graph-Based Deep Learning
    Architecture in Traffic Domain: A Survey") 所示），即技术角度和挑战角度。在技术角度中，我们介绍几种常见技术，并解释它们如何应对交通任务中的挑战。在挑战角度中，我们详细阐述每个挑战，并总结可以解决这些挑战的技术。总之，我们希望提供基于图视角的各种深度学习技术解决交通挑战的见解。'
- en: IV Problem Formulation and Graph Construction
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 问题制定与图构建
- en: Among the graph-based deep learning traffic literatures we investigate, the
    majority of tasks (more than 80%) belong to spatiotemporal forecasting problems,
    especially traffic state prediction and travel demand prediction. In this section,
    we first list commonly used notations. Then we summarize a general formulation
    of graph-based spatiotemporal prediction in traffic domain. We provide details
    to construct graphs from various traffic datasets. We also discuss multiple definitions
    of adjacency matrix, which represents the topology of graph-based traffic network
    and is the key element of graph-based solution.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们调查的基于图的深度学习交通文献中，大多数任务（超过 80%）属于时空预测问题，特别是交通状态预测和出行需求预测。在本节中，我们首先列出常用的符号。然后我们总结了交通领域中基于图的时空预测的一般制定方式。我们提供了从各种交通数据集中构建图的详细信息。我们还讨论了邻接矩阵的多种定义，它代表了基于图的交通网络的拓扑结构，是图基解决方案的关键元素。
- en: 'TABLE I: Notations In This Paper'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：本文中的符号
- en: '| Graph related elements |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 图相关元素 |'
- en: '| --- |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| $\mathbf{G}$ | Graph |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{G}$ | 图 |'
- en: '| $\mathbf{E}$ | Edges of graph $\mathbf{G}$ |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{E}$ | 图 $\mathbf{G}$ 的边 |'
- en: '| $\mathbf{V}$ | Vertices of graph $\mathbf{G}$ |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{V}$ | 图 $\mathbf{G}$ 的顶点 |'
- en: '| $\mathbf{A}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | Adjacency matrix
    of graph $\mathbf{G}$ |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{A}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | 图 $\mathbf{G}$ 的邻接矩阵
    |'
- en: '| $\mathbf{A}^{T}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | The transpose
    matrix of $\mathbf{A}$ |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{A}^{T}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | $\mathbf{A}$
    的转置矩阵 |'
- en: '| $\mathbf{\tilde{A}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | Equal to
    $\mathbf{A}+\mathbf{I_{N}}$, a self-looped $\mathbf{A}$ |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{\tilde{A}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | 等于 $\mathbf{A}+\mathbf{I_{N}}$
    的自环矩阵 $\mathbf{A}$ |'
- en: '| $\mathbf{D}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | The degree matrix
    of adjacency matrix $\mathbf{A}$ |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{D}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | 邻接矩阵 $\mathbf{A}$
    的度矩阵 |'
- en: '| $\mathbf{D_{I}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | The in-degree
    matrix of adjacency matrix $\mathbf{A}$ |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{D_{I}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | 邻接矩阵 $\mathbf{A}$
    的入度矩阵 |'
- en: '| $\mathbf{D_{O}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | The out-degree
    matrix of adjacency matrix $\mathbf{A}$ |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{D_{O}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | 邻接矩阵 $\mathbf{A}$
    的出度矩阵 |'
- en: '| $\mathbf{L}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | Laplacian matrix
    of graph $\mathbf{G}$ |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{L}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | 图 $\mathbf{G}$ 的拉普拉斯矩阵
    |'
- en: '| $\mathbf{U}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | The eigenvectors
    matrix of $\mathbf{L}$ |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{U}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | $\mathbf{L}$ 的特征向量矩阵
    |'
- en: '| $\mathbf{\Lambda}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | The diagonal
    eigenvalues matrix of $\mathbf{L}$ |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{\Lambda}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | $\mathbf{L}$
    的对角特征值矩阵 |'
- en: '| $\boldsymbol{\lambda}_{max}$ | The max eigenvalue of $\mathbf{L}$ |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{\lambda}_{max}$ | $\mathbf{L}$ 的最大特征值 |'
- en: '| $\mathbf{I_{N}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | An identity
    matrix |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{I_{N}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ | 单位矩阵 |'
- en: '| Hyper parameters |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 超参数 |'
- en: '| $\mathbf{N}$ | The number of nodes in graph $\mathbf{G}$ |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{N}$ | 图 $\mathbf{G}$ 中的节点数量 |'
- en: '| $\mathbf{F_{I}}$ | The number of input features |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{F_{I}}$ | 输入特征的数量 |'
- en: '| $\mathbf{F_{H}}$ | The number of hidden features |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{F_{H}}$ | 隐藏特征的数量 |'
- en: '| $\mathbf{F_{O}}$ | The number of output features |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{F_{O}}$ | 输出特征的数量 |'
- en: '| $\mathbf{P}$ | The number of past time slices |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{P}$ | 过去时间切片的数量 |'
- en: '| $\mathbf{Q}$ | The number of future time slices |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{Q}$ | 未来时间切片的数量 |'
- en: '| $\mathbf{d}$ | The dilation rate |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{d}$ | 扩张率 |'
- en: '| Trainable parameters |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 可训练的参数 |'
- en: '| $W,b,\theta,\phi$ | The trainable parameters |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| $W,b,\theta,\phi$ | 可训练的参数 |'
- en: '| $\Theta$ | The kernel |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| $\Theta$ | 核 |'
- en: '| Activation functions |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 激活函数 |'
- en: '| $\boldsymbol{\rho}(\boldsymbol{\cdot})$ | The activation function, e.g. tanh,
    sigmoid, ReLU |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{\rho}(\boldsymbol{\cdot})$ | 激活函数，例如 tanh, sigmoid, ReLU |'
- en: '| $\boldsymbol{\sigma}(\boldsymbol{\cdot})\in[0,1]$ | The sigmoid function
    |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{\sigma}(\boldsymbol{\cdot})\in[0,1]$ | Sigmoid 函数 |'
- en: '| $\boldsymbol{tanh}(\boldsymbol{\cdot})\in[-1,1]$ | The hyperbolic tangent
    function |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{tanh}(\boldsymbol{\cdot})\in[-1,1]$ | 双曲正切函数 |'
- en: '| $\boldsymbol{ReLU}(\boldsymbol{\cdot})\in[0,x]$ | The ReLU function |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{ReLU}(\boldsymbol{\cdot})\in[0,x]$ | ReLU 函数 |'
- en: '| Operations |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 操作 |'
- en: '| $\boldsymbol{*_{\mathcal{G}}}$ | The convolution operator on graph |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{*_{\mathcal{G}}}$ | 图上的卷积运算符 |'
- en: '| $\boldsymbol{\odot}$ | Element-wise multiplication |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{\odot}$ | 元素级乘法 |'
- en: '| $\boldsymbol{\cdot}$ | Matrix multiplication |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{\cdot}$ | 矩阵乘法 |'
- en: '| Spatial variables |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 空间变量 |'
- en: '| $X\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{I}}}$ | An input graph composed
    of $\mathbf{N}$ nodes with $\mathbf{F_{I}}$ features |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| $X\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{I}}}$ | 由 $\mathbf{N}$ 个节点和 $\mathbf{F_{I}}$
    特征组成的输入图 |'
- en: '| $X_{j}\in\mathbb{R}^{\mathbf{N}}$ | The $j^{th}$ feature of an input graph
    |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| $X_{j}\in\mathbb{R}^{\mathbf{N}}$ | 输入图的第 $j^{th}$ 特征 |'
- en: '| $X^{i}\in\mathbb{R}^{\mathbf{F_{I}}}$ | Node $i$ in an input graph |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| $X^{i}\in\mathbb{R}^{\mathbf{F_{I}}}$ | 输入图中的节点 $i$ |'
- en: '| $x\in\mathbb{R}^{\mathbf{N}}$ | A simply input graph |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| $x\in\mathbb{R}^{\mathbf{N}}$ | 一个简单的输入图 |'
- en: '| $Y\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{O}}}$ | An output graph composed
    of $\mathbf{N}$ nodes with $\mathbf{\mathbf{F_{O}}}$ features |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| $Y\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{O}}}$ | 由 $\mathbf{N}$ 个节点和 $\mathbf{\mathbf{F_{O}}}$
    特征组成的输出图 |'
- en: '| $Y_{j}\in\mathbb{R}^{\mathbf{N}}$ | The $j^{th}$ feature of an output graph
    |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| $Y_{j}\in\mathbb{R}^{\mathbf{N}}$ | 输出图的第 $j^{th}$ 特征 |'
- en: '| $Y^{i}\in\mathbb{R}^{\mathbf{F_{O}}}$ | Node $i$ in an output graph |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| $Y^{i}\in\mathbb{R}^{\mathbf{F_{O}}}$ | 输出图中的节点 $i$ |'
- en: '| $y\in\mathbb{R}^{\mathbf{N}}$ | A simply output graph |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| $y\in\mathbb{R}^{\mathbf{N}}$ | 一个简单的输出图 |'
- en: '| Temporal variables |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 时间变量 |'
- en: '| $\mathbf{X}\in\mathbb{R}^{\mathbf{P}\times\mathbf{F_{I}}}$ | A sequential
    input with $\mathbf{F_{I}}$ features over $\mathbf{P}$ time slices |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{X}\in\mathbb{R}^{\mathbf{P}\times\mathbf{F_{I}}}$ | 在 $\mathbf{P}$
    时间切片上的 $\mathbf{F_{I}}$ 特征的序列输入 |'
- en: '| $\mathbf{X}_{t}\in\mathbb{R}^{\mathbf{F_{I}}}$ | The element of sequential
    input at time $t$ |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{X}_{t}\in\mathbb{R}^{\mathbf{F_{I}}}$ | 时间 $t$ 的序列输入的元素 |'
- en: '| $\mathbf{x}\in\mathbb{R}^{\mathbf{P}}$ | A simply sequential input over $\mathbf{P}$
    time slices |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{x}\in\mathbb{R}^{\mathbf{P}}$ | 在 $\mathbf{P}$ 时间切片上的简单序列输入 |'
- en: '| $\mathbf{x}_{t}\in\mathbb{R}$ | The element of simply sequential input at
    time $t$ |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{x}_{t}\in\mathbb{R}$ | 时间 $t$ 的简单序列输入的元素 |'
- en: '| $\mathbf{H}_{t}\in\mathbb{R}^{\mathbf{F_{H}}}$ | A hidden state with $\mathbf{\mathbf{F}_{H}}$
    features at time $t$ |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{H}_{t}\in\mathbb{R}^{\mathbf{F_{H}}}$ | 时间 $t$ 的隐藏状态，具有 $\mathbf{\mathbf{F}_{H}}$
    特征 |'
- en: '| $\mathbf{Y}\in\mathbb{R}^{\mathbf{P}\times\mathbf{F_{O}}}$ | A sequential
    output with $\mathbf{F_{O}}$ features over $\mathbf{P}$ time slices |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{Y}\in\mathbb{R}^{\mathbf{P}\times\mathbf{F_{O}}}$ | 在 $\mathbf{P}$
    时间切片上的 $\mathbf{F_{O}}$ 特征的序列输出 |'
- en: '| $\mathbf{Y}_{t}\in\mathbb{R}^{\mathbf{F_{O}}}$ | The element of sequential
    output at time $t$ |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{Y}_{t}\in\mathbb{R}^{\mathbf{F_{O}}}$ | 时间 $t$ 的序列输出的元素 |'
- en: '| $\mathbf{y}\in\mathbb{R}^{\mathbf{P}}$ | A simply sequential output over
    $\mathbf{P}$ time slices |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{y}\in\mathbb{R}^{\mathbf{P}}$ | 在 $\mathbf{P}$ 时间切片上简单的序列输出 |'
- en: '| $\mathbf{y}_{t}\in\mathbb{R}$ | The element of simply sequential output at
    time $t$ |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{y}_{t}\in\mathbb{R}$ | 时间$t$时简单顺序输出的元素 |'
- en: '| Spatiotemporal variables |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 空间-时间变量 |'
- en: '| $\mathcal{X}\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{I}}}$
    | A series of input graphs composed of $\mathbf{N}$ nodes with $\mathbf{F_{I}}$
    features over $\mathbf{P}$ time slices |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{X}\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{I}}}$
    | 一系列输入图，由$\mathbf{N}$个节点和$\mathbf{F_{I}}$特征组成，覆盖$\mathbf{P}$个时间片段 |'
- en: '| $\mathcal{X}_{t}\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{I}}}$ | An input
    graph at time $t$ |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{X}_{t}\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{I}}}$ | 时间$t$时的输入图
    |'
- en: '| $\mathcal{X}^{i}_{t}\in\mathbb{R}^{\mathbf{F_{I}}}$ | node $i$ in an input
    graph at time $t$ |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{X}^{i}_{t}\in\mathbb{R}^{\mathbf{F_{I}}}$ | 时间$t$时输入图中的节点$i$ |'
- en: '| $\mathcal{X}_{t,j}\in\mathbb{R}^{\mathbf{N}}$ | the $j^{th}$ feature of an
    input graph at time $t$ |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{X}_{t,j}\in\mathbb{R}^{\mathbf{N}}$ | 时间$t$时输入图的第$j^{th}$特征 |'
- en: '| $\mathcal{X}^{i}_{t,j}\in\mathbb{R}$ | the $j^{th}$ feature of node $i$ in
    an input graph at time $t$ |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{X}^{i}_{t,j}\in\mathbb{R}$ | 时间$t$时输入图中节点$i$的第$j^{th}$特征 |'
- en: '| $\mathcal{Y}\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{O}}}$
    | A series of output graphs composed of $\mathbf{N}$ nodes with $\mathbf{F_{O}}$
    features over $\mathbf{P}$ time slices |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{Y}\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{O}}}$
    | 一系列输出图，由$\mathbf{N}$个节点和$\mathbf{F_{O}}$特征组成，覆盖$\mathbf{P}$个时间片段 |'
- en: '| $\mathcal{Y}_{t}\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{O}}}$ | An output
    graph at time $t$ |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{Y}_{t}\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{O}}}$ | 时间$t$时的输出图
    |'
- en: '| $\mathcal{Y}^{i}_{t}\in\mathbb{R}^{\mathbf{F_{O}}}$ | node $i$ in an output
    graph at time $t$ |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{Y}^{i}_{t}\in\mathbb{R}^{\mathbf{F_{O}}}$ | 时间$t$时输出图中的节点$i$ |'
- en: '| $\mathcal{Y}_{t,j}\in\mathbb{R}^{\mathbf{N}}$ | the $j^{th}$ feature of an
    output graph at time $t$ |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{Y}_{t,j}\in\mathbb{R}^{\mathbf{N}}$ | 时间$t$时输出图的第$j^{th}$特征 |'
- en: '| $\mathcal{Y}^{i}_{t,j}\in\mathbb{R}$ | the $j^{th}$ feature of node $i$ in
    an output graph at time $t$ |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{Y}^{i}_{t,j}\in\mathbb{R}$ | 时间$t$时输出图中节点$i$的第$j^{th}$特征 |'
- en: IV-A Notations
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 符号
- en: In this section, we have denoted some commonly used notations, including graph
    related elements, variables, parameters (hyper or trainable), activation functions,
    and operations. The variables are comprised of input variables {$x$, $X$, $\mathbf{x}$,
    $\mathbf{X}$, $\mathcal{X}$} and output variables {$y$, $Y$, $\mathbf{y}$, $\mathbf{Y}$,
    $\mathcal{Y}$}. These variables can divided into spatial variables, temporal variables,
    spatiotemporal variables. The spatial variables are only related with spatial
    attributes and the temporal variables are only related with temporal attributes.
    The spatiotemporal variables are related with both spatial and temporal attributes.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们已标记一些常用符号，包括图相关元素、变量、参数（超参数或可训练的）、激活函数和操作。变量包括输入变量{$x$, $X$, $\mathbf{x}$,
    $\mathbf{X}$, $\mathcal{X}$}和输出变量{$y$, $Y$, $\mathbf{y}$, $\mathbf{Y}$, $\mathcal{Y}$}。这些变量可以分为空间变量、时间变量和空间-时间变量。空间变量仅与空间属性相关，时间变量仅与时间属性相关，而空间-时间变量与空间和时间属性都相关。
- en: IV-B Graph-based Spatio-Temporal Forecasting
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 基于图的空间-时间预测
- en: To our best knowledge, most existing graph-based deep learning traffic works
    can be categorized into spatial-temporal forecasting due to that most traffic
    datasets have both spatial attributes and temporal attributes. They formalize
    their prediction problems in a very similar way despite different mathematical
    notations and representations. We summarize their works to provide a general formulation
    for graph-based spatial-temporal problems in traffic domain.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们了解，大多数现有的基于图的深度学习交通工作可以归类为空间-时间预测，因为大多数交通数据集同时具有空间属性和时间属性。尽管数学符号和表示方式不同，它们以非常相似的方式形式化其预测问题。我们总结了它们的工作，以提供一种通用的图形空间-时间问题的公式化方法。
- en: The traffic network is represented as a graph $\mathbf{G}=(\mathbf{V},\mathbf{E},\mathbf{A})$,
    which can be weighted [[92](#bib.bib92)],[[72](#bib.bib72)],[[68](#bib.bib68)]
    or unweighted [[66](#bib.bib66)],[[93](#bib.bib93)],[[94](#bib.bib94)], directed
    [[66](#bib.bib66)],[[95](#bib.bib95)],[[96](#bib.bib96)] or undirected [[69](#bib.bib69)],[[97](#bib.bib97)],
    depending on specific tasks. $\mathbf{V}$ is a set of nodes and $|\mathbf{V}|=\mathbf{N}$
    refers $\mathbf{N}$ nodes in the graph. Each node represents a traffic object,
    which can be a sensor [[70](#bib.bib70)],[[69](#bib.bib69)],[[98](#bib.bib98)],
    a road segment [[92](#bib.bib92)],[[99](#bib.bib99)],[[100](#bib.bib100)], a road
    intersection [[72](#bib.bib72)],[[95](#bib.bib95)], [[68](#bib.bib68)]. $\mathbf{E}$
    is a set of edges referring the connectivity between nodes.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 交通网络表示为一个图 $\mathbf{G}=(\mathbf{V},\mathbf{E},\mathbf{A})$，可以是加权的 [[92](#bib.bib92)],
    [[72](#bib.bib72)], [[68](#bib.bib68)] 或非加权的 [[66](#bib.bib66)], [[93](#bib.bib93)],
    [[94](#bib.bib94)]，有向的 [[66](#bib.bib66)], [[95](#bib.bib95)], [[96](#bib.bib96)]
    或无向的 [[69](#bib.bib69)], [[97](#bib.bib97)]，这取决于具体任务。 $\mathbf{V}$ 是节点的集合，$|\mathbf{V}|=\mathbf{N}$
    表示图中的$\mathbf{N}$个节点。每个节点代表一个交通对象，可以是传感器 [[70](#bib.bib70)], [[69](#bib.bib69)],
    [[98](#bib.bib98)]，一个道路段 [[92](#bib.bib92)], [[99](#bib.bib99)], [[100](#bib.bib100)]，一个道路交叉口
    [[72](#bib.bib72)], [[95](#bib.bib95)], [[68](#bib.bib68)]。$\mathbf{E}$ 是表示节点之间连通性的边的集合。
- en: $\mathbf{A}=(\mathbf{a}_{ij})_{\mathbf{N}\times\mathbf{N}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$
    is the adjacency matrix containing the topology information of the traffic network,
    which is valuable for traffic prediction. The entry $\mathbf{a}_{ij}$ in matrix
    $\mathbf{A}$ represents the node proximity and is different in various applications.
    It can be a binary value $0$ or $1$ [[69](#bib.bib69)],[[93](#bib.bib93)],[[94](#bib.bib94)].
    Specifically, $0$ indicates no edge between node $i$ and node $j$ while $1$ indicates
    an edge between these two nodes. It can also be a float value representing some
    kind of relationship between nodes [[92](#bib.bib92)],[[101](#bib.bib101)], e.g.
    the road distance between two sensors [[70](#bib.bib70)],[[102](#bib.bib102)],[[96](#bib.bib96)].
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: $\mathbf{A}=(\mathbf{a}_{ij})_{\mathbf{N}\times\mathbf{N}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$
    是包含交通网络拓扑信息的邻接矩阵，这对交通预测非常有价值。矩阵$\mathbf{A}$中的条目$\mathbf{a}_{ij}$表示节点的接近度，在不同的应用中有所不同。它可以是二进制值$0$或$1$
    [[69](#bib.bib69)], [[93](#bib.bib93)], [[94](#bib.bib94)]。具体而言，$0$表示节点$i$和节点$j$之间没有边，而$1$表示这两个节点之间有边。它也可以是浮点值，表示节点之间某种关系
    [[92](#bib.bib92)], [[101](#bib.bib101)]，例如两个传感器之间的道路距离 [[70](#bib.bib70)], [[102](#bib.bib102)],
    [[96](#bib.bib96)]。
- en: $\mathcal{X}_{t}=[\mathcal{X}_{t}^{1},\cdots,\mathcal{X}_{t}^{i},\cdots,\mathcal{X}_{t}^{\mathbf{N}}]\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{I}}}$
    is a feature matrix of the whole graph at time $t$. $\mathcal{X}^{i}_{t}\in\mathbb{R}^{\mathbf{F_{I}}}$
    represents node $i$ with $\mathbf{F_{I}}$ features at time $t$. The features are
    usually traffic indicators, such as traffic flow [[97](#bib.bib97)],[[96](#bib.bib96)],
    traffic speed [[70](#bib.bib70)],[[99](#bib.bib99)],[[95](#bib.bib95)], or rail-hail
    orders [[89](#bib.bib89)],[[101](#bib.bib101)], passenger flow [[77](#bib.bib77)],[[78](#bib.bib78)].
    Usually, continuous indicators are normalized during data preprocessing phase.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: $\mathcal{X}_{t}=[\mathcal{X}_{t}^{1},\cdots,\mathcal{X}_{t}^{i},\cdots,\mathcal{X}_{t}^{\mathbf{N}}]\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{I}}}$
    是时间$t$时刻的整个图的特征矩阵。 $\mathcal{X}^{i}_{t}\in\mathbb{R}^{\mathbf{F_{I}}}$ 代表时间$t$时刻具有$\mathbf{F_{I}}$个特征的节点$i$。这些特征通常是交通指标，如交通流量
    [[97](#bib.bib97)], [[96](#bib.bib96)], 交通速度 [[70](#bib.bib70)], [[99](#bib.bib99)],
    [[95](#bib.bib95)], 或铁路运单 [[89](#bib.bib89)], [[101](#bib.bib101)], 乘客流量 [[77](#bib.bib77)],
    [[78](#bib.bib78)]。通常，连续指标在数据预处理阶段会进行归一化处理。
- en: 'Given historical indicators of the whole traffic network over past $\mathbf{P}$
    time slices, denoted as $\mathcal{X}=[\mathcal{X}_{1},\cdots,\mathcal{X}_{t},\cdots,\mathcal{X}_{\mathbf{P}}]\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{I}}}$,
    the spatial-temporal forecasting problem in traffic domain aims to predict the
    future traffic indicators over the next $\mathbf{Q}$ time slices, denoted as $\mathcal{Y}=[\mathcal{Y}_{1},\cdots,\mathcal{Y}_{t},\cdots,\mathcal{Y}_{\mathbf{Q}}]\in\mathbb{R}^{\mathbf{Q}\times\mathbf{N}\times\mathbf{F_{O}}}$,
    where $\mathcal{Y}_{t}\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{O}}}$ represents
    output graph with $\mathbf{F_{O}}$ features at time $t$. The problem (as shown
    in Figure [3](#S4.F3 "Figure 3 ‣ IV-B Graph-based Spatio-Temporal Forecasting
    ‣ IV Problem Formulation and Graph Construction ‣ How to Build a Graph-Based Deep
    Learning Architecture in Traffic Domain: A Survey")) can be formulated as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '给定过去 $\mathbf{P}$ 个时间切片的整个交通网络历史指标，记作 $\mathcal{X}=[\mathcal{X}_{1},\cdots,\mathcal{X}_{t},\cdots,\mathcal{X}_{\mathbf{P}}]\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{I}}}$，交通领域中的时空预测问题旨在预测未来
    $\mathbf{Q}$ 个时间切片的交通指标，记作 $\mathcal{Y}=[\mathcal{Y}_{1},\cdots,\mathcal{Y}_{t},\cdots,\mathcal{Y}_{\mathbf{Q}}]\in\mathbb{R}^{\mathbf{Q}\times\mathbf{N}\times\mathbf{F_{O}}}$，其中
    $\mathcal{Y}_{t}\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{O}}}$ 表示时间 $t$ 处具有 $\mathbf{F_{O}}$
    特征的输出图。该问题（如图 [3](#S4.F3 "Figure 3 ‣ IV-B Graph-based Spatio-Temporal Forecasting
    ‣ IV Problem Formulation and Graph Construction ‣ How to Build a Graph-Based Deep
    Learning Architecture in Traffic Domain: A Survey") 所示）可以表述如下：'
- en: '|  | $\mathcal{Y}=f(\mathcal{X};\mathbf{G})$ |  | (1) |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{Y}=f(\mathcal{X};\mathbf{G})$ |  | (1) |'
- en: '![Refer to caption](img/0af64006d3a74e004443f8d9429b10ed.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0af64006d3a74e004443f8d9429b10ed.png)'
- en: 'Figure 3: The graph-based spatial-temporal problem formulation in traffic domain'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：交通领域中的图基时空问题表述
- en: Some works predict multiple traffic indicators in the future (i.e. $\mathbf{F_{O}}>1$)
    while other works predict one traffic indicator (i.e. $\mathbf{F_{O}}=1$), such
    as traffic speed [[99](#bib.bib99)], [[95](#bib.bib95)], rail-hide orders [[89](#bib.bib89)],[[101](#bib.bib101)].
    Some works only consider one-step prediction [[103](#bib.bib103)],[[75](#bib.bib75)],[[57](#bib.bib57)],
    i.e. forecasting traffic conditions in the next time step and $\mathbf{Q}=1$.
    But models designed for one-step prediction can’t be directly applied to predict
    multiple steps, because they are optimized by reducing error during the training
    stage for the next-step instead of the subsequent time steps [[76](#bib.bib76)].
    Many works focus on multi-step forecasting (i.e. $\mathbf{Q}>1$) [[104](#bib.bib104)],[[42](#bib.bib42)],[[105](#bib.bib105)].
    According to our survey, there are mainly three kinds of techniques to generate
    a multi-step output, i.e. FC layer, Seq2Seq, dilation technique. Fully connected
    (FC) layer is the simplest technique as being the output layer to obtain a desired
    output shape [[70](#bib.bib70)], [[69](#bib.bib69)], [[106](#bib.bib106)], [[93](#bib.bib93)],
    [[91](#bib.bib91)], [[107](#bib.bib107)]. Some works adopt the Sequence to Sequence
    (Seq2Seq) architecture with a RNNs-based decoder to generate output recursively
    through multiple steps [[108](#bib.bib108)],[[98](#bib.bib98)],[[109](#bib.bib109)],[[104](#bib.bib104)],[[110](#bib.bib110)],[[96](#bib.bib96)].
    Dilation technique is adopted to get a desired output length [[102](#bib.bib102)],
    [[105](#bib.bib105)].
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究预测未来的多个交通指标（即 $\mathbf{F_{O}}>1$），而其他研究预测单一交通指标（即 $\mathbf{F_{O}}=1$），例如交通速度
    [[99](#bib.bib99)], [[95](#bib.bib95)], 铁路隐藏订单 [[89](#bib.bib89)], [[101](#bib.bib101)]。一些研究仅考虑一步预测
    [[103](#bib.bib103)], [[75](#bib.bib75)], [[57](#bib.bib57)]，即预测下一时间步的交通状况，并且
    $\mathbf{Q}=1$。但是，为一步预测设计的模型不能直接应用于多步预测，因为它们是在训练阶段通过减少下一步的误差来优化的，而不是随后的时间步 [[76](#bib.bib76)]。许多研究集中于多步预测（即
    $\mathbf{Q}>1$） [[104](#bib.bib104)], [[42](#bib.bib42)], [[105](#bib.bib105)]。根据我们的调查，生成多步输出的主要有三种技术，即全连接（FC）层、Seq2Seq
    和扩张技术。全连接（FC）层是最简单的技术，它作为输出层来获得所需的输出形状 [[70](#bib.bib70)], [[69](#bib.bib69)],
    [[106](#bib.bib106)], [[93](#bib.bib93)], [[91](#bib.bib91)], [[107](#bib.bib107)]。一些研究采用了基于
    RNN 的 Seq2Seq 架构，通过多个步骤递归生成输出 [[108](#bib.bib108)], [[98](#bib.bib98)], [[109](#bib.bib109)],
    [[104](#bib.bib104)], [[110](#bib.bib110)], [[96](#bib.bib96)]。扩张技术则被用来获得所需的输出长度
    [[102](#bib.bib102)], [[105](#bib.bib105)]。
- en: '![Refer to caption](img/b2b985f7fa0050c683c29a5f25dacf96.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b2b985f7fa0050c683c29a5f25dacf96.png)'
- en: 'Figure 4: Graph construction from various traffic datasets: a) In a sensor
    graph, sensor represents node and there is an edge between adjacent sensors on
    the same side of a road. b) In a road segment graph, road segment represents node
    and two connected segments have an edge. c) In a road intersection graph, road
    intersection represents node and there is an edge between two road intersections
    connected by a road segment. Most works consider the edge direction being the
    traffic flow direction[[70](#bib.bib70)],[[98](#bib.bib98)],[[66](#bib.bib66)],[[96](#bib.bib96)],[[68](#bib.bib68)],[[111](#bib.bib111)],
    while some works ignore the direction and construct an undirected graph [[69](#bib.bib69)],[[102](#bib.bib102)],[[94](#bib.bib94)][[100](#bib.bib100)],[[95](#bib.bib95)].'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：来自各种交通数据集的图构建：a) 在传感器图中，传感器表示节点，且在道路同侧的相邻传感器之间有一条边。b) 在道路段图中，道路段表示节点，相连的两个段之间有一条边。c)
    在道路交叉口图中，道路交叉口表示节点，且在由道路段连接的两个道路交叉口之间有一条边。大多数研究认为边的方向是交通流向[[70](#bib.bib70)],[[98](#bib.bib98)],[[66](#bib.bib66)],[[96](#bib.bib96)],[[68](#bib.bib68)],[[111](#bib.bib111)]，而有些研究忽略方向，构建无向图[[69](#bib.bib69)],[[102](#bib.bib102)],[[94](#bib.bib94)][[100](#bib.bib100)],[[95](#bib.bib95)]。
- en: 'In addition, some works not only consider traffic indicators, but also take
    external factors (e.g. time attributes, weather) [[70](#bib.bib70)],[[112](#bib.bib112)],[[91](#bib.bib91)],[[113](#bib.bib113)]
    into consideration. Therefore, the problem formulation becomes:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些研究不仅考虑交通指标，还考虑外部因素（例如时间属性、天气）[[70](#bib.bib70)],[[112](#bib.bib112)],[[91](#bib.bib91)],[[113](#bib.bib113)]。因此，问题的表述变为：
- en: '|  | $\mathcal{Y}=f(\mathcal{X},\mathcal{E};\mathbf{G})$ |  | (2) |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{Y}=f(\mathcal{X},\mathcal{E};\mathbf{G})$ |  | (2) |'
- en: where $\mathcal{E}$ is the external factors.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathcal{E}$是外部因素。
- en: IV-C Graph Construction from Traffic Datasets
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 来自交通数据集的图构建
- en: To model a traffic network as a graph is vital for any works that intend to
    utilize graph-based deep learning architectures to solve traffic problems. A traffic
    graph $\mathbf{G}$ for prediction is generally composed of four parts, i.e. nodes
    $\mathbf{V}$, node features (feature matrix $\mathcal{X}_{t}$), edges $\mathbf{E}$,
    edge weight $\mathbf{a}_{ij}$. Note that edges and edge weight can be represented
    by adjacency matrix $\mathbf{A}=(\mathbf{a}_{ij})_{\mathbf{N}\times\mathbf{N}}$.
    Nodes and node features can be constructed from traffic datasets. The construction
    of adjacency matrix not only depends on traffic datasets but also depends on the
    assumption of node relationship, which can be static or dynamic. We first introduce
    how to construct node and node features from various kinds of traffic datasets
    and then we give a systematic introduction to the popular adjacency matrices.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 将交通网络建模为图对于任何打算利用图基深度学习架构解决交通问题的研究来说都是至关重要的。用于预测的交通图$\mathbf{G}$通常由四部分组成，即节点$\mathbf{V}$、节点特征（特征矩阵$\mathcal{X}_{t}$）、边$\mathbf{E}$、边权重$\mathbf{a}_{ij}$。请注意，边和边权重可以通过邻接矩阵$\mathbf{A}=(\mathbf{a}_{ij})_{\mathbf{N}\times\mathbf{N}}$表示。节点和节点特征可以从交通数据集中构建。邻接矩阵的构建不仅依赖于交通数据集，还依赖于节点关系的假设，这可以是静态的或动态的。我们首先介绍如何从各种交通数据集中构建节点和节点特征，然后系统地介绍流行的邻接矩阵。
- en: IV-C1 Nodes and Node Features Construction
  id: totrans-162
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C1 节点和节点特征构建
- en: 'Many works are different in graph construction due to the different traffic
    datasets they collect. We divide these datasets into four categories according
    to the traffic infrastructures: data collected by the sensors deployed on road
    network [[70](#bib.bib70)],[[69](#bib.bib69)],[[71](#bib.bib71)], vehicle GPS
    trajectories [[68](#bib.bib68)],[[111](#bib.bib111)],[[95](#bib.bib95)], orders
    of rail-hailing system [[101](#bib.bib101)],[[76](#bib.bib76)],[[113](#bib.bib113)],
    transaction records of subway system [[77](#bib.bib77)],[[78](#bib.bib78)] or
    bus system [[111](#bib.bib111)]. For each category, we describe the datasets and
    explain the construction of nodes $\mathbf{V}$, feature matrix $\mathcal{X}_{t}$.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所收集的交通数据集不同，许多研究在图构建上有所不同。我们根据交通基础设施将这些数据集分为四类：由道路网络上部署的传感器收集的数据[[70](#bib.bib70)],[[69](#bib.bib69)],[[71](#bib.bib71)]，车辆GPS轨迹[[68](#bib.bib68)],[[111](#bib.bib111)],[[95](#bib.bib95)]，铁路叫车系统的订单[[101](#bib.bib101)],[[76](#bib.bib76)],[[113](#bib.bib113)]，地铁系统的交易记录[[77](#bib.bib77)],[[78](#bib.bib78)]或公交系统[[111](#bib.bib111)]。对于每一类，我们描述数据集并解释节点$\mathbf{V}$、特征矩阵$\mathcal{X}_{t}$的构建。
- en: Sensors Datasets Traffic measurements (e.g. traffic speed) are generally collected
    during a short time interval by the sensors (e.g. loop detectors, probes) on a
    road network in metropolises like Beijing [[92](#bib.bib92)], California [[71](#bib.bib71)],
    Los Angeles [[70](#bib.bib70)], New York [[99](#bib.bib99)], Philadelphia [[106](#bib.bib106)],
    Seattle [[94](#bib.bib94)], Xiamen [[98](#bib.bib98)], and Washington [[106](#bib.bib106)].
    Sensor datasets are the most prevalent datasets in existing works, especially
    PEMS dataset from California. Generally, a road network contains traffic objects
    such as sensors, road segments.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 传感器数据集 交通测量（例如交通速度）通常在大城市（如北京 [[92](#bib.bib92)]、加州 [[71](#bib.bib71)]、洛杉矶 [[70](#bib.bib70)]、纽约
    [[99](#bib.bib99)]、费城 [[106](#bib.bib106)]、西雅图 [[94](#bib.bib94)]、厦门 [[98](#bib.bib98)]
    和华盛顿 [[106](#bib.bib106)]）的道路网络上由传感器（例如环形探测器、探针）在短时间间隔内收集。传感器数据集是现有研究中最为普遍的数据集，特别是来自加州的
    PEMS 数据集。通常，道路网络包含交通对象，如传感器、路段。
- en: 'A sensor graph (as shown in Figure [4](#S4.F4 "Figure 4 ‣ IV-B Graph-based
    Spatio-Temporal Forecasting ‣ IV Problem Formulation and Graph Construction ‣
    How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey"))
    is constructed in [[70](#bib.bib70)],[[69](#bib.bib69)],[[96](#bib.bib96)] where
    a sensor represents a node and features of this node are traffic measurements
    collected by its corresponding sensor.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '传感器图（如图 [4](#S4.F4 "Figure 4 ‣ IV-B Graph-based Spatio-Temporal Forecasting
    ‣ IV Problem Formulation and Graph Construction ‣ How to Build a Graph-Based Deep
    Learning Architecture in Traffic Domain: A Survey") 所示）在 [[70](#bib.bib70)]，[[69](#bib.bib69)]，[[96](#bib.bib96)]
    中被构建，其中传感器表示一个节点，该节点的特征是其对应传感器收集的交通测量值。'
- en: 'A road segment graph (as shown in Figure [4](#S4.F4 "Figure 4 ‣ IV-B Graph-based
    Spatio-Temporal Forecasting ‣ IV Problem Formulation and Graph Construction ‣
    How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey"))
    is constructed in [[92](#bib.bib92)],[[99](#bib.bib99)],[[106](#bib.bib106)] where
    a road segment represents a node and features of this node are average traffic
    measurements (e.g. traffic speed) recorded by all the sensors on its corresponding
    road segment.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '路段图（如图 [4](#S4.F4 "Figure 4 ‣ IV-B Graph-based Spatio-Temporal Forecasting
    ‣ IV Problem Formulation and Graph Construction ‣ How to Build a Graph-Based Deep
    Learning Architecture in Traffic Domain: A Survey") 所示）在 [[92](#bib.bib92)]，[[99](#bib.bib99)]，[[106](#bib.bib106)]
    中被构建，其中路段表示一个节点，该节点的特征是其对应路段上所有传感器记录的平均交通测量值（例如交通速度）。'
- en: GPS Datasets GPS trajectories datasets are usually generated by numbers of taxis
    over some period of time in a city, e.g. Beijing [[68](#bib.bib68)], Chengdu [[68](#bib.bib68)],
    Shenzhen [[93](#bib.bib93)], Cologne [[95](#bib.bib95)], and Chicago [[100](#bib.bib100)].
    Each taxi produces substantial GPS records with time, location, speed information
    every day. Every GPS record is fitted to its nearest road on the city road map.
    All roads are divided into multiple road segments through road intersections.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: GPS 数据集 GPS 轨迹数据集通常由城市中大量出租车在一段时间内生成，例如北京 [[68](#bib.bib68)]、成都 [[68](#bib.bib68)]、深圳
    [[93](#bib.bib93)]、科隆 [[95](#bib.bib95)] 和芝加哥 [[100](#bib.bib100)]。每辆出租车每天生成大量的
    GPS 记录，包括时间、位置、速度信息。每条 GPS 记录都被拟合到城市道路地图上最近的道路上。所有道路通过道路交叉口被划分为多个路段。
- en: 'A road segment graph (as shown in Figure [4](#S4.F4 "Figure 4 ‣ IV-B Graph-based
    Spatio-Temporal Forecasting ‣ IV Problem Formulation and Graph Construction ‣
    How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey"))
    is constructed in [[100](#bib.bib100)], [[93](#bib.bib93)] where a road segment
    represents a node and features of this node are average traffic measurements recorded
    by all the GPS points on its corresponding road segment.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '路段图（如图 [4](#S4.F4 "Figure 4 ‣ IV-B Graph-based Spatio-Temporal Forecasting
    ‣ IV Problem Formulation and Graph Construction ‣ How to Build a Graph-Based Deep
    Learning Architecture in Traffic Domain: A Survey") 所示）在 [[100](#bib.bib100)]，[[93](#bib.bib93)]
    中被构建，其中路段表示一个节点，该节点的特征是其对应路段上所有 GPS 点记录的平均交通测量值。'
- en: 'A road intersection graph (as shown in Figure [4](#S4.F4 "Figure 4 ‣ IV-B Graph-based
    Spatio-Temporal Forecasting ‣ IV Problem Formulation and Graph Construction ‣
    How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey"))
    is constructed in [[72](#bib.bib72)],[[68](#bib.bib68)],[[95](#bib.bib95)] where
    a road intersection represents a node and features of this node are sum-up of
    the traffic measurements through it.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '道路交叉口图（如图 [4](#S4.F4 "Figure 4 ‣ IV-B Graph-based Spatio-Temporal Forecasting
    ‣ IV Problem Formulation and Graph Construction ‣ How to Build a Graph-Based Deep
    Learning Architecture in Traffic Domain: A Survey") 所示）在 [[72](#bib.bib72)]，[[68](#bib.bib68)]，[[95](#bib.bib95)]
    中被构建，其中道路交叉口表示一个节点，该节点的特征是通过它的交通测量值的总和。'
- en: 'Rail-hailing Datasets These datasets record car/taxi/bicycle demand orders
    over a period of time in cities like Beijing [[89](#bib.bib89)],[[101](#bib.bib101)],
    Chengdu [[101](#bib.bib101)], and Shanghai [[89](#bib.bib89)], Manhattan, New
    York [[99](#bib.bib99)]. The target city with an OpenStreetMap is divided into
    equal-size grid-based regions (as shown in Figure [5](#S4.F5 "Figure 5 ‣ IV-C1
    Nodes and Node Features Construction ‣ IV-C Graph Construction from Traffic Datasets
    ‣ IV Problem Formulation and Graph Construction ‣ How to Build a Graph-Based Deep
    Learning Architecture in Traffic Domain: A Survey")). Each region is defined as
    a node in a graph. The feature of each node is the number of orders in the corresponding
    region during a given interval.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 铁路召车数据集 这些数据集记录了在北京[[89](#bib.bib89)],[[101](#bib.bib101)], 成都[[101](#bib.bib101)]和上海[[89](#bib.bib89)],
    曼哈顿, 纽约[[99](#bib.bib99)]等城市的一段时间内的汽车/出租车/自行车需求订单。目标城市使用OpenStreetMap被划分为相等大小的网格区域（如图[5](#S4.F5
    "图 5 ‣ IV-C1 节点及节点特征构建 ‣ IV-C 图构建来自交通数据集 ‣ IV 问题表述和图构建 ‣ 如何在交通领域构建基于图的深度学习架构：综述")所示）。每个区域定义为图中的一个节点。每个节点的特征是在给定时间间隔内相应区域的订单数量。
- en: '![Refer to caption](img/0e06f62f993496e47efadcc8c998b317.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/0e06f62f993496e47efadcc8c998b317.png)'
- en: 'Figure 5: Multi-relationships: a) A spatial locality graph: This graph is based
    on spatial proximity and it constructs edges between a region and its 8 adjacent
    regions in a 3 x 3 grid. b) A functional similarity graph: This graph assumes
    that regions sharing similar functionality might have similar demand patterns.
    Edges are constructed between regions with similar surrounding POIs (Point of
    Interests). c) A transportation connectivity graph: This graph assumes that regions
    which are geographically distant from the target region but conveniently reachable
    by transportation (e.g. motorway, highway or subway) have strong correlations
    with the target region. There should be edges between them.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：多重关系：a) 空间局部性图：该图基于空间接近性，并在一个3 x 3网格中构建区域与其8个相邻区域之间的边。b) 功能相似性图：该图假设共享相似功能的区域可能具有类似的需求模式。边在具有类似周边兴趣点（POI）的区域之间构建。c)
    交通连接性图：该图假设地理上与目标区域距离较远但通过交通（如高速公路、高速公路或地铁）便捷到达的区域与目标区域具有较强的相关性。它们之间应存在边。
- en: Transactions Datasets These datasets are collected by automatic fare collection
    (AFC) system deployed in public transit network, such as subway network and bus
    network. A subway graph is constructed in [[77](#bib.bib77)],[[78](#bib.bib78)],[[111](#bib.bib111)].
    Each station in the subway system is treated as a node. The features of a station
    usually contain the number of passengers departing at the station and the number
    of passengers arriving at the station during a given time interval based on transaction
    records collected by subwayAFC systems, which log when each passenger enters and
    leaves a metro system.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 交易数据集 这些数据集由自动票务收集（AFC）系统在公共交通网络中收集，例如地铁网络和公交网络。在[[77](#bib.bib77)],[[78](#bib.bib78)],[[111](#bib.bib111)]中构建了地铁图。地铁系统中的每个车站被视为一个节点。车站的特征通常包括在给定时间间隔内从车站离开的乘客数量和到达车站的乘客数量，基于地铁AFC系统收集的交易记录，这些系统记录了每个乘客何时进入和离开地铁系统。
- en: A bus graph is constructed in [[111](#bib.bib111)]. Each bus stop is treated
    as a node. The features of a bus stop usually contain the number of departing
    passengers at the station during a given time interval, but not the number of
    arriving passengers, since most bus AFC systems only log the boarding record of
    each passenger.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[111](#bib.bib111)]中构建了公交图。每个公交站被视为一个节点。公交站的特征通常包括在给定时间间隔内离开车站的乘客数量，但不包括到达乘客的数量，因为大多数公交AFC系统仅记录每个乘客的登车记录。
- en: IV-C2 Adjacency Matrix Construction
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C2 邻接矩阵构建
- en: The adjacency matrix $\mathbf{A}=(\mathbf{a}_{ij})_{\mathbf{N}\times\mathbf{N}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$
    is the key to capture spatial dependency which is valuable for prediction. Element
    $\mathbf{a}_{ij}$ (unweighted or weighted) represents heterogeneous pairwise relationship
    between nodes. However, there are different assumptions of node relationships
    in different traffic scenarios, based on which the adjacency matrix can be designed
    differently, e.g. fixed matrix, dynamic matrix, evolving matrix.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 邻接矩阵 $\mathbf{A}=(\mathbf{a}_{ij})_{\mathbf{N}\times\mathbf{N}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$
    是捕捉空间依赖性的关键，这对预测非常有价值。元素 $\mathbf{a}_{ij}$（加权或未加权）表示节点之间的异质成对关系。然而，在不同的交通场景中，节点关系有不同的假设，基于这些假设，邻接矩阵的设计可以有所不同，例如固定矩阵、动态矩阵、演变矩阵。
- en: Fixed Matrix Many works assume that the correlations between nodes are fixed
    and do not change over time. Therefore, a fixed matrix is designed and unchanged
    during the whole experiment. Researchers have designed various fixed adjacency
    matrices to capture various kinds of pre-defined correlations between nodes in
    a traffic graph, like function similarity and transportation connectivity [[89](#bib.bib89)],
    semantic connection [[101](#bib.bib101)], temporal similarity [[71](#bib.bib71)].
    Here, we introduce several popular adjacency matrices.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 固定矩阵 许多研究假设节点之间的相关性是固定的，并且不会随时间变化。因此，设计了一个固定矩阵，并在整个实验过程中保持不变。研究人员设计了各种固定的邻接矩阵，以捕捉交通图中节点之间的各种预定义相关性，例如功能相似性和交通连接性
    [[89](#bib.bib89)]、语义连接 [[101](#bib.bib101)]、时间相似性 [[71](#bib.bib71)]。在这里，我们介绍几种流行的邻接矩阵。
- en: Connection matrix measures the connectivity between nodes. The entry value in
    the matrix is defined as $1$ (connection) or $0$ (disconnection) [[69](#bib.bib69)],[[106](#bib.bib106)],[[93](#bib.bib93)],[[94](#bib.bib94)].
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 连接矩阵衡量节点之间的连接性。矩阵中的条目值定义为 $1$（连接）或 $0$（断开连接） [[69](#bib.bib69)]、[[106](#bib.bib106)]、[[93](#bib.bib93)]、[[94](#bib.bib94)]。
- en: 'Distance matrix measures the closeness between nodes in terms of geometrical
    distance. The entry value is defined as a function of distance between nodes [[85](#bib.bib85)].
    For example, some works [[72](#bib.bib72)],[[68](#bib.bib68)],[[100](#bib.bib100)],[[97](#bib.bib97)],[[76](#bib.bib76)],[[95](#bib.bib95)]
    used threshold Gaussian Kernel to define $\mathbf{a}_{ij}$ as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 距离矩阵从几何距离的角度衡量节点之间的接近度。条目值定义为节点之间距离的函数 [[85](#bib.bib85)]。例如，一些研究 [[72](#bib.bib72)]、[[68](#bib.bib68)]、[[100](#bib.bib100)]、[[97](#bib.bib97)]、[[76](#bib.bib76)]、[[95](#bib.bib95)]
    使用阈值高斯核来定义 $\mathbf{a}_{ij}$ 如下：
- en: '|  | $\mathbf{a}_{ij}=\left\{\begin{array}[]{l}\exp\left(-\frac{\mathbf{d}_{ij}^{2}}{\sigma^{2}}\right),i\neq
    j\text{ and }\mathbf{d}_{ij}\geq\epsilon\\ 0\quad,i=j\text{ or }\mathbf{d}_{ij}<\epsilon\end{array}\right.$
    |  | (3) |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{a}_{ij}=\left\{\begin{array}[]{l}\exp\left(-\frac{\mathbf{d}_{ij}^{2}}{\sigma^{2}}\right),i\neq
    j\text{ 和 }\mathbf{d}_{ij}\geq\epsilon\\ 0\quad,i=j\text{ 或 }\mathbf{d}_{ij}<\epsilon\end{array}\right.$
    |  | (3) |'
- en: where $\mathbf{d}_{ij}$ is the distance between node $i$ and node $j$. Hyper
    parameters $\sigma^{2}$ and $\epsilon$ are thresholds to control the distribution
    and sparsity of matrix $\mathbf{A}$.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathbf{d}_{ij}$ 是节点 $i$ 和节点 $j$ 之间的距离。超参数 $\sigma^{2}$ 和 $\epsilon$ 是控制矩阵
    $\mathbf{A}$ 的分布和稀疏性的阈值。
- en: 'Functional similarity matrix measures whether two nodes are similar in terms
    of functionality (e.g. both of them are business zones). The corresponding functional
    similarity graph is shown in Figure [5](#S4.F5 "Figure 5 ‣ IV-C1 Nodes and Node
    Features Construction ‣ IV-C Graph Construction from Traffic Datasets ‣ IV Problem
    Formulation and Graph Construction ‣ How to Build a Graph-Based Deep Learning
    Architecture in Traffic Domain: A Survey"). It assumes that regions sharing similar
    functionality might have similar demand patterns [[89](#bib.bib89)]. Edges are
    constructed between regions with similar surrounding POIs (Point of Interests).'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 功能相似性矩阵衡量两个节点在功能性方面是否相似（例如，它们都是商业区）。对应的功能相似性图见图 [5](#S4.F5 "图 5 ‣ IV-C1 节点和节点特征构建
    ‣ IV-C 从交通数据集中构建图 ‣ IV 问题定义和图构建 ‣ 如何构建交通领域的图基深度学习架构：综述")。它假设功能相似的区域可能有类似的需求模式
    [[89](#bib.bib89)]。在具有相似周边兴趣点（POIs）的区域之间构建边。
- en: 'Transportation connectivity matrix measures the correlation between regions
    that are geographically distant but conveniently reachable by motorway, highway
    or subway. The corresponding transportation connectivity graph is shown in Figure
    [5](#S4.F5 "Figure 5 ‣ IV-C1 Nodes and Node Features Construction ‣ IV-C Graph
    Construction from Traffic Datasets ‣ IV Problem Formulation and Graph Construction
    ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey").
    There should be edges between them [[89](#bib.bib89)].'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 交通连通矩阵衡量的是地理上距离较远但通过高速公路、国道或地铁方便到达的区域之间的相关性。相应的交通连通图如图 [5](#S4.F5 "图 5 ‣ IV-C1
    节点及节点特征构建 ‣ IV-C 从交通数据集中构建图 ‣ IV 问题定义与图构建 ‣ 如何在交通领域建立基于图的深度学习架构：综述") 所示。它们之间应该存在边[[89](#bib.bib89)]。
- en: Dynamic Matrix Some works argue that the pre-defined matrix does not necessarily
    reflect the true dependency among nodes due to the defective prior knowledge or
    incomplete data [[72](#bib.bib72)]. A novel adaptive matrix is proposed and learned
    through data. Experiments in [[102](#bib.bib102)],[[72](#bib.bib72)],[[99](#bib.bib99)]
    have proven that adaptive matrix can precisely capture the hidden spatial dependency
    more precisely in some traffic tasks.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 动态矩阵 一些研究认为，预定义矩阵由于先验知识缺陷或数据不完整，未必能真实反映节点间的真实依赖关系[[72](#bib.bib72)]。因此，提出了一种通过数据学习得到的新型自适应矩阵。实验表明，在一些交通任务中，自适应矩阵能更准确地捕捉隐藏的空间依赖[[102](#bib.bib102)],[[72](#bib.bib72)],[[99](#bib.bib99)]。
- en: Evolving Matrix In some scenarios, the graph structure can evolve over time
    as some edges may become unavailable, like road congestion or closure, and become
    available again after alleviating congestion. An evolving topological structure
    [[66](#bib.bib66)], [[114](#bib.bib114)] is incorporated into the model to capture
    such dynamic spatial change.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 发展矩阵 在一些场景中，图结构可能会随时间演变，因为某些边可能变得不可用，比如道路拥堵或封闭，缓解拥堵后又恢复可用。一个演变的拓扑结构[[66](#bib.bib66)],
    [[114](#bib.bib114)]被纳入模型中以捕捉这种动态空间变化。
- en: V Deep Learning Techniques Perspective
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 深度学习技术视角
- en: 'TABLE II: The decomposition of graph-based deep learning architectures investigated
    in this paper'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '表 II: 本文研究的基于图的深度学习架构的分解'
- en: '| Reference | Year | Directions | Models | Modules |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 年份 | 方向 | 模型 | 模块 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| [[83](#bib.bib83)] | 2019 | Human/Vehicle Trajectory Prediction | SAGCN |
    SGCN, TCN, Attention |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| [[83](#bib.bib83)] | 2019 | 人车轨迹预测 | SAGCN | SGCN, TCN, 注意力 |'
- en: '| [[87](#bib.bib87)] | 2019 | Human/Vehicle Trajectory Prediction | Social-BiGAT
    | GAT, LSTM, GAN |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| [[87](#bib.bib87)] | 2019 | 人车轨迹预测 | Social-BiGAT | GAT, LSTM, GAN |'
- en: '| [[85](#bib.bib85)] | 2020 | Human/Vehicle Trajectory Prediction | Social-STGCNN
    | SGCN, TCN |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| [[85](#bib.bib85)] | 2020 | 人车轨迹预测 | Social-STGCNN | SGCN, TCN |'
- en: '| [[64](#bib.bib64)] | 2020 | Human/Vehicle Trajectory Prediction | Social-WaGDAT
    | GAT, Seq2Seq, MLP |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| [[64](#bib.bib64)] | 2020 | 人车轨迹预测 | Social-WaGDAT | GAT, Seq2Seq, MLP |'
- en: '| [[88](#bib.bib88)] | 2020 | Human/Vehicle Trajectory Prediction |  | SGCN,
    LSTM |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| [[88](#bib.bib88)] | 2020 | 人车轨迹预测 |  | SGCN, LSTM |'
- en: '| [[57](#bib.bib57)] | 2019 | Optimal DETC Scheme |  | SGCN |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| [[57](#bib.bib57)] | 2019 | 最优 DETC 方案 |  | SGCN |'
- en: '| [[65](#bib.bib65)] | 2020 | Vehicle Behaviour Classification | MR-GCN | SGCN,
    LSTM |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| [[65](#bib.bib65)] | 2020 | 车辆行为分类 | MR-GCN | SGCN, LSTM |'
- en: '| [[67](#bib.bib67)] | 2018 | Traffic Signal Control |  | SGCN, Reinforcement
    Learning |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| [[67](#bib.bib67)] | 2018 | 交通信号控制 |  | SGCN, 强化学习 |'
- en: '| [[66](#bib.bib66)] | 2019 | Path Availability | LRGCN-SAPE | SGCN, LSTM |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| [[66](#bib.bib66)] | 2019 | 路径可用性 | LRGCN-SAPE | SGCN, LSTM |'
- en: '| [[72](#bib.bib72)] | 2019 | Travel Time Prediction |  | SGCN |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| [[72](#bib.bib72)] | 2019 | 行程时间预测 |  | SGCN |'
- en: '| [[68](#bib.bib68)] | 2018 | Traffic Flow Prediction | KW-GCN | SGCN, LCN
    |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| [[68](#bib.bib68)] | 2018 | 交通流预测 | KW-GCN | SGCN, LCN |'
- en: '| [[97](#bib.bib97)] | 2018 | Traffic Flow Prediction | Graph-CNN | CNN, Graph
    Matrix |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| [[97](#bib.bib97)] | 2018 | 交通流预测 | Graph-CNN | CNN, 图矩阵 |'
- en: '| [[115](#bib.bib115)] | 2018 | Traffic Flow Prediction | DST-GCNN | SGCN |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| [[115](#bib.bib115)] | 2018 | 交通流预测 | DST-GCNN | SGCN |'
- en: '| [[69](#bib.bib69)] | 2019 | Traffic Flow Prediction |  | SGCN, CNN, Attention
    Mechanism |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| [[69](#bib.bib69)] | 2019 | 交通流预测 |  | SGCN, CNN, 注意机制 |'
- en: '| [[111](#bib.bib111)] | 2019 | Traffic Flow Prediction |  | SGCN, TCN, Residual
    |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| [[111](#bib.bib111)] | 2019 | 交通流预测 |  | SGCN, TCN, 残差 |'
- en: '| [[109](#bib.bib109)] | 2019 | Traffic Flow Prediction | GHCRNN | SGCN, GRU,
    Seq2Seq |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| [[109](#bib.bib109)] | 2019 | 交通流预测 | GHCRNN | SGCN, GRU, Seq2Seq |'
- en: '| [[104](#bib.bib104)] | 2019 | Traffic Flow Prediction | STGSA | GAT, GRU,
    Seq2Seq |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| [[104](#bib.bib104)] | 2019 | 交通流量预测 | STGSA | GAT, GRU, Seq2Seq |'
- en: '| [[96](#bib.bib96)] | 2019 | Traffic Flow Prediction | DCRNN-RIL | DGCN, GRU,
    Seq2Seq |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| [[96](#bib.bib96)] | 2019 | 交通流量预测 | DCRNN-RIL | DGCN, GRU, Seq2Seq |'
- en: '| [[116](#bib.bib116)] | 2019 | Traffic Flow Prediction | MVGCN | SGCN, FNN,
    Gate Mechanism, Residual |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| [[116](#bib.bib116)] | 2019 | 交通流量预测 | MVGCN | SGCN, FNN, Gate Mechanism,
    Residual |'
- en: '| [[117](#bib.bib117)] | 2019 | Traffic Flow Prediction | STGI- ResNet | SGCN,
    Residual |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| [[117](#bib.bib117)] | 2019 | 交通流量预测 | STGI- ResNet | SGCN, Residual |'
- en: '| [[118](#bib.bib118)] | 2020 | Traffic Flow Prediction | FlowConvGRU | DGCN,
    GRU |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| [[118](#bib.bib118)] | 2020 | 交通流量预测 | FlowConvGRU | DGCN, GRU |'
- en: '| [[45](#bib.bib45)] | 2020 | Traffic Flow Prediction | Multi-STGCnet | SGCN,
    LSTM |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| [[45](#bib.bib45)] | 2020 | 交通流量预测 | Multi-STGCnet | SGCN, LSTM |'
- en: '| [[119](#bib.bib119)] | 2018 | Traffic Speed Prediction |  | GAT, GRU, Gate
    Mechanism |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| [[119](#bib.bib119)] | 2018 | 交通速度预测 |  | GAT, GRU, Gate Mechanism |'
- en: '| [[70](#bib.bib70)] | 2019 | Traffic Speed Prediction | GTCN | SGCN, TCN,
    Residual |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| [[70](#bib.bib70)] | 2019 | 交通速度预测 | GTCN | SGCN, TCN, Residual |'
- en: '| [[71](#bib.bib71)] | 2019 | Traffic Speed Prediction | 3D-TGCN | SGCN, Gate
    Mechanism |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| [[71](#bib.bib71)] | 2019 | 交通速度预测 | 3D-TGCN | SGCN, Gate Mechanism |'
- en: '| [[91](#bib.bib91)] | 2019 | Traffic Speed Prediction | DIGC-Net | SGCN, LSTM
    |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| [[91](#bib.bib91)] | 2019 | 交通速度预测 | DIGC-Net | SGCN, LSTM |'
- en: '| [[120](#bib.bib120)] | 2019 | Traffic Speed Prediction | MW-TGC | SGCN, LSTM
    |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| [[120](#bib.bib120)] | 2019 | 交通速度预测 | MW-TGC | SGCN, LSTM |'
- en: '| [[110](#bib.bib110)] | 2019 | Traffic Speed Prediction | AGC-Seq2Seq | SGCN,
    GRU, Seq2Seq, Attention Mechanism |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| [[110](#bib.bib110)] | 2019 | 交通速度预测 | AGC-Seq2Seq | SGCN, GRU, Seq2Seq,
    Attention Mechanism |'
- en: '| [[95](#bib.bib95)] | 2019 | Traffic Speed Prediction | GCGA | SGCN, GAN |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| [[95](#bib.bib95)] | 2019 | 交通速度预测 | GCGA | SGCN, GAN |'
- en: '| [[107](#bib.bib107)] | 2019 | Traffic Speed Prediction | ST-GAT | GAT, LSTM
    |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| [[107](#bib.bib107)] | 2019 | 交通速度预测 | ST-GAT | GAT, LSTM |'
- en: '| [[92](#bib.bib92)] | 2018 | Traffic State Prediction | STGCN | SGCN, TCN,
    Gate Mechanism |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| [[92](#bib.bib92)] | 2018 | 交通状态预测 | STGCN | SGCN, TCN, Gate Mechanism |'
- en: '| [[108](#bib.bib108)] | 2018 | Traffic State Prediction | DCRNN | DGCN, GRU,
    Seq2Seq |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| [[108](#bib.bib108)] | 2018 | 交通状态预测 | DCRNN | DGCN, GRU, Seq2Seq |'
- en: '| [[99](#bib.bib99)] | 2019 | Traffic State Prediction |  | SGCN, CNN, Gate
    Mechanism |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| [[99](#bib.bib99)] | 2019 | 交通状态预测 |  | SGCN, CNN, Gate Mechanism |'
- en: '| [[112](#bib.bib112)] | 2019 | Traffic State Prediction | MRes-RGNN | DGCN,
    GRU, Residual, Gate Mechanism |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| [[112](#bib.bib112)] | 2019 | 交通状态预测 | MRes-RGNN | DGCN, GRU, Residual, Gate
    Mechanism |'
- en: '| [[100](#bib.bib100)] | 2019 | Traffic State Prediction | GCGAN | DGCN, LSTM,
    GAN, Seq2Seq, Attention Mechanism |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| [[100](#bib.bib100)] | 2019 | 交通状态预测 | GCGAN | DGCN, LSTM, GAN, Seq2Seq,
    Attention Mechanism |'
- en: '| [[102](#bib.bib102)] | 2019 | Traffic State Prediction | Graph WaveNet |
    DGCN, TCN, Residual, Gate Mechanism |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| [[102](#bib.bib102)] | 2019 | 交通状态预测 | Graph WaveNet | DGCN, TCN, Residual,
    Gate Mechanism |'
- en: '| [[93](#bib.bib93)] | 2019 | Traffic State Prediction | T-GCN | SGCN, GRU
    |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| [[93](#bib.bib93)] | 2019 | 交通状态预测 | T-GCN | SGCN, GRU |'
- en: '| [[94](#bib.bib94)] | 2019 | Traffic State Prediction | TGC-LSTM | SGCN, LSTM
    |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| [[94](#bib.bib94)] | 2019 | 交通状态预测 | TGC-LSTM | SGCN, LSTM |'
- en: '| [[41](#bib.bib41)] | 2019 | Traffic State Prediction | DualGraph | Seq2Seq,
    MLP, Graph Matirx |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| [[41](#bib.bib41)] | 2019 | 交通状态预测 | DualGraph | Seq2Seq, MLP, Graph Matrix
    |'
- en: '| [[105](#bib.bib105)] | 2019 | Traffic State Prediction | ST-UNet | SGCN,
    GRU |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| [[105](#bib.bib105)] | 2019 | 交通状态预测 | ST-UNet | SGCN, GRU |'
- en: '| [[98](#bib.bib98)] | 2020 | Traffic State Prediction | GMAN | GAT, Gate Mechanism,
    Seq2Seq, Attention Mechanism |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| [[98](#bib.bib98)] | 2020 | 交通状态预测 | GMAN | GAT, Gate Mechanism, Seq2Seq,
    Attention Mechanism |'
- en: '| [[106](#bib.bib106)] | 2020 | Traffic State Prediction | OGCRNN | SGCN, GRU,
    Attention Mechanism |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| [[106](#bib.bib106)] | 2020 | 交通状态预测 | OGCRNN | SGCN, GRU, Attention Mechanism
    |'
- en: '| [[42](#bib.bib42)] | 2020 | Traffic State Prediction | MRA-BGCN | SGCN, GRU,
    Seq2Seq, Attention Mechanism |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| [[42](#bib.bib42)] | 2020 | 交通状态预测 | MRA-BGCN | SGCN, GRU, Seq2Seq, Attention
    Mechanism |'
- en: '| [[48](#bib.bib48)] | 2018 | Travel Demand-Bike |  | SGCN, LSTM, Seq2Seq |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| [[48](#bib.bib48)] | 2018 | 旅行需求-自行车 |  | SGCN, LSTM, Seq2Seq |'
- en: '| [[49](#bib.bib49)] | 2018 | Travel Demand-Bike | GCNN-DDGF | SGCN, LSTM |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| [[49](#bib.bib49)] | 2018 | 旅行需求-自行车 | GCNN-DDGF | SGCN, LSTM |'
- en: '| [[77](#bib.bib77)] | 2020 | Travel Demand-Subway | PVCGN | SGCN, GRU, Seq2Seq,
    Attention Mechanism |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| [[77](#bib.bib77)] | 2020 | 旅行需求-地铁 | PVCGN | SGCN, GRU, Seq2Seq, Attention
    Mechanism |'
- en: '| [[78](#bib.bib78)] | 2019 | Travel Demand-Subway | WDGTC | Tensor Completion,
    Graph Matrix |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| [[78](#bib.bib78)] | 2019 | 旅行需求-地铁 | WDGTC | Tensor Completion, Graph Matrix
    |'
- en: '| [[89](#bib.bib89)] | 2019 | Travel Demand-Taxi | CGRNN | SGCN, RNN, Attention
    Mechanism, Gate Mechanism |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| [[89](#bib.bib89)] | 2019 | 旅行需求-出租车 | CGRNN | SGCN, RNN, Attention Mechanism,
    Gate Mechanism |'
- en: '| [[101](#bib.bib101)] | 2019 | Travel Demand-Taxi | GEML | SGCN, LSTM |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| [[101](#bib.bib101)] | 2019 | 旅行需求-出租车 | GEML | SGCN, LSTM |'
- en: '| [[75](#bib.bib75)] | 2019 | Travel Demand-Taxi | MGCN | SGCN |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| [[75](#bib.bib75)] | 2019 | 旅行需求-出租车 | MGCN | SGCN |'
- en: '| [[76](#bib.bib76)] | 2019 | Travel Demand-Taxi | STG2Seq | SGCN, Seq2Seq,
    Attention Mechanism, Gate Mechanism, Residual |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| [[76](#bib.bib76)] | 2019 | 旅行需求-出租车 | STG2Seq | SGCN, Seq2Seq, 注意力机制, 门控机制,
    残差 |'
- en: '| [[113](#bib.bib113)] | 2019 | Travel Demand-Taxi |  | SGCN, LSTM, Seq2Seq
    |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| [[113](#bib.bib113)] | 2019 | 旅行需求-出租车 |  | SGCN, LSTM, Seq2Seq |'
- en: '| [[103](#bib.bib103)] | 2019 | Travel Demand-Taxi | ST-ED-RMGC | SGCN, LSTM,
    Seq2Seq, Residual |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| [[103](#bib.bib103)] | 2019 | 旅行需求-出租车 | ST-ED-RMGC | SGCN, LSTM, Seq2Seq,
    残差 |'
- en: 'We summarize the graph-based deep learning architectures in existing traffic
    literatures and find that most of them are composed of graph neural networks (GNNs)
    and other modules, such as recurrent neural networks (RNNs), temporal convolution
    network (TCN), Sequence to Sequence (Seq2Seq) model, generative adversarial network
    (GAN) (as shown in Table [II](#S5.T2 "TABLE II ‣ V Deep Learning Techniques Perspective
    ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey")).
    It is the cooperation of GNNs and other deep learning techniques that achieves
    state-of-the-art performance in many traffic scenarios. This section aims to introduce
    the functionality, advantages, defects and variants of these techniques in traffic
    tasks, which can help participators understand how to utilize these deep learning
    techniques in traffic domain.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '我们总结了现有交通文献中的基于图的深度学习架构，发现其中大多数由图神经网络（GNNs）和其他模块组成，如递归神经网络（RNNs）、时间卷积网络（TCN）、序列到序列（Seq2Seq）模型、生成对抗网络（GAN）（如表格
    [II](#S5.T2 "TABLE II ‣ V Deep Learning Techniques Perspective ‣ How to Build
    a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey") 所示）。GNNs
    与其他深度学习技术的合作在许多交通场景中实现了最先进的性能。本节旨在介绍这些技术在交通任务中的功能、优点、缺陷和变体，这可以帮助参与者了解如何在交通领域利用这些深度学习技术。'
- en: V-A GNNs
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-A 图神经网络
- en: '![Refer to caption](img/ad1d77a3d24e51a148d2049a2244ed57.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ad1d77a3d24e51a148d2049a2244ed57.png)'
- en: 'Figure 6: The structure of Graph Neural Network is generally composed of two
    kind of layers: 1) Aggregation layer: In each feature dimension, the features
    of adjacent nodes are aggregated to the central node. Mathematically, the output
    of aggregation layer is the product of adjacency matrix and features matrix. 2)
    Non-linear transformation layer: All the aggregated features of each node are
    fed into the non-linear transformation layer to create higher level feature representation.
    All nodes share the same transformation kernel. $\{1,2,3,4\}$ are node indexes.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：图神经网络的结构通常由两种类型的层组成：1) 聚合层：在每个特征维度上，相邻节点的特征被聚合到中央节点上。从数学上讲，聚合层的输出是邻接矩阵和特征矩阵的乘积。2)
    非线性变换层：每个节点的所有聚合特征都输入到非线性变换层，以创建更高层次的特征表示。所有节点共享相同的变换核。$\{1,2,3,4\}$ 是节点索引。
- en: In the last couple of years, motivated by the huge success of deep learning
    approaches (e.g. CNNs, RNNs), there is an increasing interest in generalizing
    neural networks to arbitrarily structured graphs and such networks are classified
    as graph neural networks (GNNs). In the early stage, the studies about GNNs can
    be categorized into recurrent graph neural networks (RecGNNs) which are inspired
    by RNNs [[34](#bib.bib34)]. Subsequently, inspired by the huge success of CNNs,
    many works focus on extending the convolution of CNN on graph data and these works
    can be categorized into convolutional graph neural networks (ConvGNNs) [[34](#bib.bib34)].
    There are also other branches of GNNs developed in recent years, e.g. graph auto-encoders
    (GAEs) [[121](#bib.bib121)] and graph attention networks (GATs) [[122](#bib.bib122)].
    According to our investigation, most traffic works focus on ConvGNNs and there
    are only a few studies [[119](#bib.bib119)] employing other branches of GNNs up
    to now. Further, ConvGNNs can be divided into two main streams, i.e. the spectral-based
    approaches which develop graph convolutions based on the spectral theory and the
    spatial-based approaches which define graph convolutions based on spatial relations
    between nodes[[123](#bib.bib123)]. Recently, many novel spatial-based convolutions
    have emerged, among which diffusion convolution is a popular spatial-based graph
    convolution which regards graph convolution as a diffusion process.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，受到深度学习方法（如CNNs、RNNs）巨大成功的激励，越来越多的人关注将神经网络推广到任意结构的图上，这些网络被归类为图神经网络（GNNs）。在早期阶段，关于GNNs的研究可以分为受RNNs启发的递归图神经网络（RecGNNs）[[34](#bib.bib34)]。随后，受CNNs巨大成功的启发，许多工作集中于将CNN的卷积扩展到图数据上，这些工作可以归类为卷积图神经网络（ConvGNNs）[[34](#bib.bib34)]。近年来也出现了其他分支的GNNs，例如图自编码器（GAEs）[[121](#bib.bib121)]和图注意力网络（GATs）[[122](#bib.bib122)]。根据我们的调查，大多数交通研究工作集中在ConvGNNs上，目前只有少数研究[[119](#bib.bib119)]采用了GNNs的其他分支。此外，ConvGNNs可以分为两大主流，即基于谱的方法，它们基于谱理论开发图卷积，以及基于空间的方法，它们根据节点之间的空间关系定义图卷积[[123](#bib.bib123)]。近年来，许多新颖的基于空间的卷积方法涌现，其中扩散卷积是一种受欢迎的基于空间的图卷积，它将图卷积视为一个扩散过程。
- en: 'According to our survey, most existing traffic works utilize either spectral
    graph convolution or diffusion graph convolution. There are also other novel convolutions
    [[68](#bib.bib68)] but their applications in traffic domain are relatively few.
    Therefore, in this section, we focus on introducing spectral graph convolution
    (SGC) and diffusion graph convolution (DGC) in traffic domain. In this paper,
    we refer the graph neural network with spectral graph convolution as SGCN and
    that with diffusion graph convolution as DGCN. Note that SGC is for undirected
    graph while DGC can be applied in both directed graph and undirected graph. In
    addition, both SGC and DGC aim to generate new feature representations for each
    node in a graph through feature aggregation and non-linear transformation (as
    shown in Figure [6](#S5.F6 "Figure 6 ‣ V-A GNNs ‣ V Deep Learning Techniques Perspective
    ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey")).'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '根据我们的调查，大多数现有的交通研究工作采用了谱图卷积或扩散图卷积。还有其他一些新颖的卷积方法[[68](#bib.bib68)]，但在交通领域中的应用相对较少。因此，在本节中，我们重点介绍谱图卷积（SGC）和扩散图卷积（DGC）在交通领域中的应用。在本文中，我们将采用谱图卷积的图神经网络称为SGCN，而将扩散图卷积的图神经网络称为DGCN。需要注意的是，SGC适用于无向图，而DGC既可以应用于有向图，也可以应用于无向图。此外，SGC和DGC的目标都是通过特征聚合和非线性变换为图中的每个节点生成新的特征表示（如图[6](#S5.F6
    "Figure 6 ‣ V-A GNNs ‣ V Deep Learning Techniques Perspective ‣ How to Build a
    Graph-Based Deep Learning Architecture in Traffic Domain: A Survey")所示）。'
- en: V-A1 Spectral Graph Convolution
  id: totrans-249
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-A1 谱图卷积
- en: In the spectral theory, a graph is represented by its corresponding normalized
    Laplacian matrix $\mathbf{L}=\mathbf{I_{N}}-\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$.
    The real symmetric matrix $\mathbf{L}$ can be diagonalized via eigendecomposition
    as $\mathbf{L}=\mathbf{U}\mathbf{\Lambda}\mathbf{U}^{T}$ where $\mathbf{U}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$
    is the eigenvectors matrix and $\mathbf{\Lambda}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$
    is the diagonal eigenvalues matrix. Since $\mathbf{U}$ is also an orthogonal matrix,
    Shuman et al. [[124](#bib.bib124)] adopted it as a graph Fourier basis, defining
    graph Fourier transform of a graph signal $x\in\mathbb{R}^{\mathbf{N}}$ as $\hat{x}=\mathbf{U}^{T}x$,
    and its inverse as $x=\mathbf{U}\hat{x}$.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在谱理论中，图通过其对应的归一化拉普拉斯矩阵 $\mathbf{L}=\mathbf{I_{N}}-\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$
    表示。实对称矩阵 $\mathbf{L}$ 可以通过特征分解对角化为 $\mathbf{L}=\mathbf{U}\mathbf{\Lambda}\mathbf{U}^{T}$，其中
    $\mathbf{U}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$ 是特征向量矩阵，$\mathbf{\Lambda}\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$
    是对角特征值矩阵。由于 $\mathbf{U}$ 也是一个正交矩阵，Shuman 等人 [[124](#bib.bib124)] 将其作为图傅里叶基，定义图信号
    $x\in\mathbb{R}^{\mathbf{N}}$ 的图傅里叶变换为 $\hat{x}=\mathbf{U}^{T}x$，其逆变换为 $x=\mathbf{U}\hat{x}$。
- en: Bruna et al. [[125](#bib.bib125)] tried to build an analogue of CNN convolution
    in spectral domain and defined the spectral convolution as $y=\Theta\boldsymbol{*_{\mathcal{G}}}x=\mathbf{U}\Theta\mathbf{U}^{T}x$,
    i.e. transforming $x$ into spectral domain, adjusting its amplitude by a diagonal
    kernel $\Theta=\operatorname{diag}(\theta_{0},\ldots,\theta_{\mathbf{N}-1})\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$,
    and doing inverse Fourier transform to get the final result $y$ in spatial domain.
    Although such convolution is theoretically guaranteed, it is computationally expensive
    as multiplication with $\mathbf{U}$ is $\mathcal{O}(\mathbf{N}^{2})$ and the eigendecomposition
    of $\mathbf{L}$ is intolerable for large scale graphs. In addition, it considers
    all nodes by the kernel $\Theta$ with $\mathbf{N}$ parameters and can’t extract
    spatial localization.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Bruna 等人 [[125](#bib.bib125)] 尝试在谱域构建 CNN 卷积的类似物，并将谱卷积定义为 $y=\Theta\boldsymbol{*_{\mathcal{G}}}x=\mathbf{U}\Theta\mathbf{U}^{T}x$，即将
    $x$ 转换到谱域，通过对角核 $\Theta=\operatorname{diag}(\theta_{0},\ldots,\theta_{\mathbf{N}-1})\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$
    调整其幅度，并进行反傅里叶变换以获得最终结果 $y$ 在空间域中。虽然这种卷积在理论上是保证的，但由于与 $\mathbf{U}$ 的乘法是 $\mathcal{O}(\mathbf{N}^{2})$，且
    $\mathbf{L}$ 的特征分解对大规模图来说是不可接受的，因此计算开销很大。此外，它通过具有 $\mathbf{N}$ 个参数的核 $\Theta$
    考虑所有节点，无法提取空间定位。
- en: To avoid such limitations, Defferrard et al. [[126](#bib.bib126)] localized
    the convolution and reduced its parameters by restricting the kernel $\Theta$
    to be a polynomial of eigenvalues matrix $\mathbf{\Lambda}$ as $\Theta=\sum_{k=0}^{\mathbf{K}-1}\theta_{k}\mathbf{\Lambda}^{k}$
    and $\mathbf{K}$ determines the maximum radius of the convolution from a central
    node. Thus, the convolution can be rewritten as $\Theta\boldsymbol{*_{\mathcal{G}}}x=\sum_{k=0}^{\mathbf{K}-1}\theta_{k}\mathbf{U}\mathbf{\Lambda}^{k}\mathbf{U}^{T}x=\sum_{k=0}^{\mathbf{K}-1}\theta_{k}\mathbf{L}^{k}x$.
    Further more, Defferrard et al. [[126](#bib.bib126)] adopted the Chebyshev polynomials
    $T_{k}(x)$ to approximate $\mathbf{L}^{k}$, resulting in $\Theta\boldsymbol{*_{\mathcal{G}}}x\approx\sum_{k=0}^{\mathbf{K}-1}\theta_{k}T_{k}(\tilde{\mathbf{L}})x$
    with a rescaled $\tilde{\mathbf{L}}=\frac{2}{\boldsymbol{\lambda}_{\max}}\mathbf{L}-\mathbf{I_{N}}$
    where $\boldsymbol{\lambda}_{\max}$ is the largest eigenvalue of $\mathbf{L}$
    and $T_{k}(x)=2xT_{k-1}(x)-T_{k-2}(x)$, $T_{0}(x)=1$, $T_{1}(x)=x$ [[127](#bib.bib127)].
    By recursively computing $T_{k}(x)$, the complexity of this $\mathbf{K}$-localized
    convolution can be reduced to $\mathcal{O}(\mathbf{K}|\mathbf{E}|)$ with $|\mathbf{E}|$
    being the number of edges.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种限制，Defferrard 等人 [[126](#bib.bib126)] 将卷积局部化，并通过将核 $\Theta$ 限制为特征值矩阵 $\mathbf{\Lambda}$
    的多项式形式 $\Theta=\sum_{k=0}^{\mathbf{K}-1}\theta_{k}\mathbf{\Lambda}^{k}$ 来减少其参数，其中
    $\mathbf{K}$ 确定了从中心节点的卷积最大半径。因此，卷积可以重写为 $\Theta\boldsymbol{*_{\mathcal{G}}}x=\sum_{k=0}^{\mathbf{K}-1}\theta_{k}\mathbf{U}\mathbf{\Lambda}^{k}\mathbf{U}^{T}x=\sum_{k=0}^{\mathbf{K}-1}\theta_{k}\mathbf{L}^{k}x$。进一步地，Defferrard
    等人 [[126](#bib.bib126)] 采用了切比雪夫多项式 $T_{k}(x)$ 来逼近 $\mathbf{L}^{k}$，从而得到 $\Theta\boldsymbol{*_{\mathcal{G}}}x\approx\sum_{k=0}^{\mathbf{K}-1}\theta_{k}T_{k}(\tilde{\mathbf{L}})x$，其中
    $\tilde{\mathbf{L}}=\frac{2}{\boldsymbol{\lambda}_{\max}}\mathbf{L}-\mathbf{I_{N}}$，$\boldsymbol{\lambda}_{\max}$
    是 $\mathbf{L}$ 的最大特征值，$T_{k}(x)=2xT_{k-1}(x)-T_{k-2}(x)$，$T_{0}(x)=1$，$T_{1}(x)=x$
    [[127](#bib.bib127)]。通过递归计算 $T_{k}(x)$，这种 $\mathbf{K}$-局部化卷积的复杂度可以降低到 $\mathcal{O}(\mathbf{K}|\mathbf{E}|)$，其中
    $|\mathbf{E}|$ 是边的数量。
- en: 'Based on [[126](#bib.bib126)], Kipf et al. [[128](#bib.bib128)] simplified
    the spectral graph convolution by limiting $\mathbf{K}=2$ and with $T_{0}(\tilde{\mathbf{L}})=1$,
    $T_{1}(\tilde{\mathbf{L}})=\tilde{\mathbf{L}}$. They got $\Theta\boldsymbol{*_{\mathcal{G}}}x\approx\theta_{0}T_{0}(\tilde{\mathbf{L}})x+\theta_{1}T_{1}(\tilde{\mathbf{L}})x=\theta_{0}x+\theta_{1}\tilde{\mathbf{L}}x$.
    Noticing that $\tilde{\mathbf{L}}=\frac{2}{\lambda_{\max}}\mathbf{L}-\mathbf{I_{N}}$,
    they set $\boldsymbol{\lambda}_{\max}=2$, resulting in $\Theta\boldsymbol{*_{\mathcal{G}}}x\approx\theta_{0}x+\theta_{1}(\mathbf{L}-\mathbf{I_{N}})x$.
    For that $\mathbf{L}=\mathbf{I_{N}}-\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}}$
    and $\mathbf{L}-\mathbf{I_{N}}=-\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}}$,
    they got $\Theta\boldsymbol{*_{\mathcal{G}}}x\approx\theta_{0}x-\theta_{1}(\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}})x$.
    Further, they reduced the number of parameters by setting $\theta=\theta_{0}=-\theta_{1}$
    to address overfitting and got $\Theta\boldsymbol{*_{\mathcal{G}}}x\approx\theta(\mathbf{I_{N}}+\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}})x$.
    They defined $\tilde{\mathbf{A}}=\mathbf{A}+\mathbf{I_{N}}$ and adopted a renormalization
    trick to get $y=\Theta\boldsymbol{\boldsymbol{*_{\mathcal{G}}}}x\approx\theta\tilde{\mathbf{D}}^{-\frac{1}{2}}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-\frac{1}{2}}x$,
    where $\tilde{\mathbf{D}}$ is the degree matrix of $\tilde{\mathbf{A}}$. Finally,
    Kipf et al.[[128](#bib.bib128)] proposed a spectral graph convolution layer as
    follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 [[126](#bib.bib126)]，Kipf 等人 [[128](#bib.bib128)] 通过将 $\mathbf{K}=2$ 和 $T_{0}(\tilde{\mathbf{L}})=1$，$T_{1}(\tilde{\mathbf{L}})=\tilde{\mathbf{L}}$
    简化了谱图卷积。他们得到 $\Theta\boldsymbol{*_{\mathcal{G}}}x\approx\theta_{0}T_{0}(\tilde{\mathbf{L}})x+\theta_{1}T_{1}(\tilde{\mathbf{L}})x=\theta_{0}x+\theta_{1}\tilde{\mathbf{L}}x$。注意到
    $\tilde{\mathbf{L}}=\frac{2}{\lambda_{\max}}\mathbf{L}-\mathbf{I_{N}}$，他们设置 $\boldsymbol{\lambda}_{\max}=2$，结果得到
    $\Theta\boldsymbol{*_{\mathcal{G}}}x\approx\theta_{0}x+\theta_{1}(\mathbf{L}-\mathbf{I_{N}})x$。由于
    $\mathbf{L}=\mathbf{I_{N}}-\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}}$
    和 $\mathbf{L}-\mathbf{I_{N}}=-\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}}$，他们得到
    $\Theta\boldsymbol{*_{\mathcal{G}}}x\approx\theta_{0}x-\theta_{1}(\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}})x$。此外，他们通过设置
    $\theta=\theta_{0}=-\theta_{1}$ 来减少参数数量，以应对过拟合，并得到 $\Theta\boldsymbol{*_{\mathcal{G}}}x\approx\theta(\mathbf{I_{N}}+\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}})x$。他们定义了
    $\tilde{\mathbf{A}}=\mathbf{A}+\mathbf{I_{N}}$ 并采用了重新归一化技巧，得到 $y=\Theta\boldsymbol{\boldsymbol{*_{\mathcal{G}}}}x\approx\theta\tilde{\mathbf{D}}^{-\frac{1}{2}}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-\frac{1}{2}}x$，其中
    $\tilde{\mathbf{D}}$ 是 $\tilde{\mathbf{A}}$ 的度矩阵。最后，Kipf 等人 [[128](#bib.bib128)]
    提出了如下的谱图卷积层：
- en: '|  | $\begin{split}Y_{j}&amp;=\boldsymbol{\rho}(\Theta_{j}\boldsymbol{*_{\mathcal{G}}}X)=\boldsymbol{\rho}(\sum_{i=1}^{\mathbf{F_{I}}}\theta_{i,j}\tilde{\mathbf{D}}^{-\frac{1}{2}}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-\frac{1}{2}}X_{i}),1\leq
    j\leq\mathbf{F_{O}}\\ Y&amp;=\boldsymbol{\rho}(\tilde{\mathbf{D}}^{-\frac{1}{2}}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-\frac{1}{2}}XW)\end{split}$
    |  | (4) |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}Y_{j}&amp;=\boldsymbol{\rho}(\Theta_{j}\boldsymbol{*_{\mathcal{G}}}X)=\boldsymbol{\rho}(\sum_{i=1}^{\mathbf{F_{I}}}\theta_{i,j}\tilde{\mathbf{D}}^{-\frac{1}{2}}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-\frac{1}{2}}X_{i}),1\leq
    j\leq\mathbf{F_{O}}\\ Y&amp;=\boldsymbol{\rho}(\tilde{\mathbf{D}}^{-\frac{1}{2}}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-\frac{1}{2}}XW)\end{split}$
    |  | (4) |'
- en: here, $X\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{I}}}$ is the layer input with
    $\mathbf{F_{I}}$ features, $X_{i}\in\mathbb{R}^{\mathbf{N}}$ is its $i^{th}$ feature.
    $Y\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{O}}}$ is the layer output with $\mathbf{F_{O}}$
    features, $Y_{j}\in\mathbb{R}^{\mathbf{N}}$ is its $j^{th}$ feature. $W\in\mathbb{R}^{\mathbf{F_{I}}\times\mathbf{F_{O}}}$
    is a trainable parameter. $\boldsymbol{\rho}(\boldsymbol{\cdot})$ is the activation
    function. Such layer can aggregate information of 1-hop neighbors. The receptive
    field of neighborhood can be expanded by stacking multiple graph convolution layers
    [[42](#bib.bib42)].
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，$X\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{I}}}$ 是具有 $\mathbf{F_{I}}$ 特征的层输入，$X_{i}\in\mathbb{R}^{\mathbf{N}}$
    是其第 $i^{th}$ 特征。$Y\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{O}}}$ 是具有 $\mathbf{F_{O}}$
    特征的层输出，$Y_{j}\in\mathbb{R}^{\mathbf{N}}$ 是其第 $j^{th}$ 特征。$W\in\mathbb{R}^{\mathbf{F_{I}}\times\mathbf{F_{O}}}$
    是一个可训练参数。$\boldsymbol{\rho}(\boldsymbol{\cdot})$ 是激活函数。这样的层可以聚合 1-hop 邻居的信息。通过堆叠多个图卷积层，可以扩展邻域的感受野
    [[42](#bib.bib42)]。
- en: V-A2 Diffusion Graph Convolution
  id: totrans-256
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-A2 扩散图卷积
- en: 'Spectral graph convolution requires a symmetric Laplacian matrix to implement
    eigendecomposition. It becomes invalid for a directed graph with an asymmetric
    Laplacian matrix. Diffusion convolution origins from graph diffusion and has no
    constraint on graph. Graph diffusion [[129](#bib.bib129)], [[130](#bib.bib130)]
    can be represented as a transition matrix power series giving the probability
    of jumping from one node to another node at each step. After many steps, such
    Markov process converges to a stationary distribution $\mathcal{P}=\sum_{k=0}^{\infty}\alpha(1-\alpha)^{k}(\mathbf{D_{O}}^{-1}\mathbf{A})^{k}$,
    where $\mathbf{D_{O}}^{-1}\mathbf{A}$ is the transition matrix, $\alpha\in[0,1]$
    is the restart probability and $k$ is the diffusion step. In practice, a finite
    $\mathbf{K}$-step truncation of the diffusion process is adopted and each step
    is assigned a trainable weight $\theta$. Based on the $\mathbf{K}$-step diffusion
    process, Li et al. [[108](#bib.bib108)] defined diffusion graph convolution as:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 谱图卷积需要对称的拉普拉斯矩阵来实现特征分解。对于具有非对称拉普拉斯矩阵的定向图，这种方法无效。扩散卷积源自图扩散，对图没有约束。图扩散[[129](#bib.bib129)],
    [[130](#bib.bib130)]可以表示为过渡矩阵的幂级数，给出在每一步从一个节点跳到另一个节点的概率。经过许多步之后，这种马尔可夫过程会收敛到一个稳态分布
    $\mathcal{P}=\sum_{k=0}^{\infty}\alpha(1-\alpha)^{k}(\mathbf{D_{O}}^{-1}\mathbf{A})^{k}$，其中
    $\mathbf{D_{O}}^{-1}\mathbf{A}$ 是过渡矩阵，$\alpha\in[0,1]$ 是重启概率，$k$ 是扩散步骤。在实践中，采用有限的
    $\mathbf{K}$ 步截断扩散过程，并为每一步分配一个可训练的权重 $\theta$。基于 $\mathbf{K}$ 步扩散过程，Li 等人[[108](#bib.bib108)]
    定义了扩散图卷积：
- en: '|  | $y=\Theta\boldsymbol{*_{\mathcal{G}}}x=\sum_{k=0}^{\mathbf{K}-1}(\theta_{k,1}(\mathbf{D_{O}}^{-1}\mathbf{A})^{k}+\theta_{k,2}(\mathbf{D_{I}}^{-1}\mathbf{A}^{T})^{k})x$
    |  | (5) |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '|  | $y=\Theta\boldsymbol{*_{\mathcal{G}}}x=\sum_{k=0}^{\mathbf{K}-1}(\theta_{k,1}(\mathbf{D_{O}}^{-1}\mathbf{A})^{k}+\theta_{k,2}(\mathbf{D_{I}}^{-1}\mathbf{A}^{T})^{k})x$
    |  | (5) |'
- en: 'here, $\mathbf{D_{O}}^{-1}\mathbf{A}$ represents the transition matrix and
    $\mathbf{D_{I}}^{-1}\mathbf{A}^{T}$ is its transpose. Such bidirectional diffusion
    enables the operation to capture the spatial correlation on a directed graph[[108](#bib.bib108)].
    Similar to spectral graph convolution layer, a diffusion graph convolutional layer
    is built as follows:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，$\mathbf{D_{O}}^{-1}\mathbf{A}$ 代表过渡矩阵，$\mathbf{D_{I}}^{-1}\mathbf{A}^{T}$
    是其转置。这样的双向扩散使得操作能够捕捉定向图上的空间关联[[108](#bib.bib108)]。类似于谱图卷积层，扩散图卷积层的构建如下：
- en: '|  | $\begin{split}Y_{j}&amp;=\boldsymbol{\rho}(\sum_{k=0}^{\mathbf{K}-1}\sum_{i=1}^{\mathbf{F_{I}}}(\theta_{k,1,i,j}(\mathbf{D_{O}}^{-1}\mathbf{A})^{k}+\theta_{k,2,i,j}(\mathbf{D_{I}}^{-1}\mathbf{A}^{T})^{k})X_{i})\\
    Y&amp;=\boldsymbol{\rho}(\sum_{k=0}^{\mathbf{K}-1}(\mathbf{D_{O}}^{-1}\mathbf{A})^{k}XW_{k1}+(\mathbf{D_{I}}^{-1}\mathbf{A}^{T})^{k}XW_{k2})\end{split}$
    |  | (6) |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}Y_{j}&=\boldsymbol{\rho}(\sum_{k=0}^{\mathbf{K}-1}\sum_{i=1}^{\mathbf{F_{I}}}(\theta_{k,1,i,j}(\mathbf{D_{O}}^{-1}\mathbf{A})^{k}+\theta_{k,2,i,j}(\mathbf{D_{I}}^{-1}\mathbf{A}^{T})^{k})X_{i})\\
    Y&=\boldsymbol{\rho}(\sum_{k=0}^{\mathbf{K}-1}(\mathbf{D_{O}}^{-1}\mathbf{A})^{k}XW_{k1}+(\mathbf{D_{I}}^{-1}\mathbf{A}^{T})^{k}XW_{k2})\end{split}$
    |  | (6) |'
- en: where $1\leq j\leq\mathbf{F_{O}}$, parameters $W_{k1},W_{k2}\in\mathbb{R}^{\mathbf{F_{I}}\times\mathbf{F_{O}}}$
    are trainable.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $1\leq j\leq\mathbf{F_{O}}$，参数 $W_{k1},W_{k2}\in\mathbb{R}^{\mathbf{F_{I}}\times\mathbf{F_{O}}}$
    是可训练的。
- en: V-A3 GNNs in Traffic Domain
  id: totrans-262
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-A3 交通领域中的GNNs
- en: 'Many traffic works, such as subway network and road network, are graph structure
    naturally (See Section [IV](#S4 "IV Problem Formulation and Graph Construction
    ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey")).
    Compared with previous works modeling traffic network as grids [[131](#bib.bib131)],[[132](#bib.bib132)],
    the works modeling traffic network as graph can fully utilize spatial information.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '许多交通工程，如地铁网络和道路网络，自然地呈现图结构（参见第[IV](#S4 "IV Problem Formulation and Graph Construction
    ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey)节"）。与之前将交通网络建模为网格的工作[[131](#bib.bib131)],[[132](#bib.bib132)]相比，将交通网络建模为图的工作能够充分利用空间信息。'
- en: By now, many works employ convolution operation directly on traffic graph to
    capture the complex spatial dependency of traffic data. Most of them adopt spectral
    graph convolution (SGC) while some employ diffusion graph convolution (DGC) [[112](#bib.bib112)],
    [[108](#bib.bib108)], [[100](#bib.bib100)], [[102](#bib.bib102)], [[96](#bib.bib96)],[[118](#bib.bib118)].
    There are also some other graph based deep learning techniques such as graph attention
    network (GAT) [[119](#bib.bib119)], [[107](#bib.bib107)], [[98](#bib.bib98)],[[104](#bib.bib104)],
    tensor decomposition and completion on graph [[78](#bib.bib78)], but their related
    works are few, which might be a future research direction.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，许多研究直接在交通图上应用卷积操作，以捕捉交通数据的复杂空间依赖性。他们中的大多数采用了谱图卷积（SGC），而一些则使用了扩散图卷积（DGC）[[112](#bib.bib112)],
    [[108](#bib.bib108)], [[100](#bib.bib100)], [[102](#bib.bib102)], [[96](#bib.bib96)],
    [[118](#bib.bib118)]。还有一些其他基于图的深度学习技术，如图注意力网络（GAT）[[119](#bib.bib119)], [[107](#bib.bib107)],
    [[98](#bib.bib98)], [[104](#bib.bib104)]，图上的张量分解与完成[[78](#bib.bib78)]，但相关工作较少，可能是未来的研究方向。
- en: The key difference between SGC and DGC lies in their matrices which represent
    different assumptions on the spatial correlations in traffic network. The adjacency
    matrix in SGC infers that a central node in a graph has stronger correlation with
    its adjacent nodes than other distant ones [[89](#bib.bib89)],[[70](#bib.bib70)].
    The state transition matrix in DGC indicates that the spatial dependency is stochastic
    depending on the restart probability and dynamic instead of being fixed. The traffic
    flow is related to a diffusion process on a traffic graph to model its dynamic
    spatial correlations. In addition, the bidirectional diffusion in DGC offers the
    model more flexibility to capture the influence from both upstream and downstream
    traffic [[108](#bib.bib108)]. In a word, DGC is more complicated than SGC. DGC
    can be adopted in both symmetric or asymmetric traffic network graph while SGC
    can be only utilized to process symmetric traffic graph.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: SGC 和 DGC 之间的关键区别在于它们的矩阵，这些矩阵代表了对交通网络中空间关联的不同假设。SGC中的邻接矩阵推测图中的中心节点与其邻近节点的关联比其他远离节点的关联更强[[89](#bib.bib89)],
    [[70](#bib.bib70)]。DGC中的状态转移矩阵表明空间依赖性是随机的，取决于重启概率，并且是动态的而不是固定的。交通流与交通图上的扩散过程相关，以建模其动态空间关联。此外，DGC中的双向扩散为模型提供了更多的灵活性，以捕捉来自上游和下游交通的影响[[108](#bib.bib108)]。总之，DGC
    比 SGC 更复杂。DGC 可以在对称或非对称交通网络图中使用，而 SGC 只能用于处理对称交通图。
- en: Existing graph convolution theories are mainly applied on 2-D signal $X\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{I}}}$.
    However, the traffic data with both spatial and temporal attributes are usually
    3-D signal $\mathcal{X}\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{I}}}$.
    The convolution operations need to be further generalized to 3-D signal. Equal
    convolution operation (e.g. SGC, DGC) with the same kernel is imposed on each
    time step of 3-D signal $\mathcal{X}$ in parallel [[92](#bib.bib92)], [[70](#bib.bib70)],
    [[111](#bib.bib111)],[[115](#bib.bib115)].
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的图卷积理论主要应用于二维信号 $X\in\mathbb{R}^{\mathbf{N}\times\mathbf{F_{I}}}$。然而，具有空间和时间属性的交通数据通常是三维信号
    $\mathcal{X}\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{I}}}$。卷积操作需要进一步推广到三维信号。在每个时间步骤上并行施加相同核的卷积操作（例如
    SGC、DGC）[[92](#bib.bib92)], [[70](#bib.bib70)], [[111](#bib.bib111)], [[115](#bib.bib115)]。
- en: In order to enhance the performance of graph convolution in traffic tasks, many
    works develop various variants of SGC.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提升图卷积在交通任务中的性能，许多研究开发了SGC的各种变体。
- en: 'Guo et al. [[69](#bib.bib69)] redefined SGC with attention mechanism to adaptively
    capture the dynamic correlations in traffic network: $\Theta\boldsymbol{*_{\mathcal{G}}}x\approx\sum_{k=0}^{\mathbf{K}-1}\theta_{k}(T_{k}(\tilde{\mathbf{L}})\boldsymbol{\odot}\mathbf{S})x$
    , where $\mathbf{S}=W_{1}\boldsymbol{\odot}\boldsymbol{\rho}((XW_{2})W_{3}(W_{4}X)^{T}+b)\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$
    is the spatial attention.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: Guo 等人[[69](#bib.bib69)] 重新定义了带有注意力机制的SGC，以自适应地捕捉交通网络中的动态关联：$\Theta\boldsymbol{*_{\mathcal{G}}}x\approx\sum_{k=0}^{\mathbf{K}-1}\theta_{k}(T_{k}(\tilde{\mathbf{L}})\boldsymbol{\odot}\mathbf{S})x$，其中
    $\mathbf{S}=W_{1}\boldsymbol{\odot}\boldsymbol{\rho}((XW_{2})W_{3}(W_{4}X)^{T}+b)\in\mathbb{R}^{\mathbf{N}\times\mathbf{N}}$
    是空间注意力。
- en: 'Yu et al. [[71](#bib.bib71)] generalized SGC on both spatial and temporal dimensions
    by scanning $\mathbf{K}$ order neighbors on graph and $\mathbf{K}_{t}$ neighbors
    on time-axis without padding. The equation is as follows:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: Yu 等人[[71](#bib.bib71)] 通过扫描图上的 $\mathbf{K}$ 阶邻居和时间轴上的 $\mathbf{K}_{t}$ 邻居来将SGC推广到空间和时间维度，而无需填充。方程如下：
- en: '|  | $\mathcal{Y}_{t,j}=\boldsymbol{\rho}(\sum_{t^{\prime}=0}^{\mathbf{K}_{t}-1}\sum_{k=0}^{\mathbf{K}-1}\sum_{i=1}^{\mathbf{F_{I}}}\theta_{j,t^{\prime},k,i}\tilde{\mathbf{L}}^{k}\mathcal{X}_{t-t^{\prime},i})$
    |  | (7) |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{Y}_{t,j}=\boldsymbol{\rho}(\sum_{t^{\prime}=0}^{\mathbf{K}_{t}-1}\sum_{k=0}^{\mathbf{K}-1}\sum_{i=1}^{\mathbf{F_{I}}}\theta_{j,t^{\prime},k,i}\tilde{\mathbf{L}}^{k}\mathcal{X}_{t-t^{\prime},i})$
    |  | (7) |'
- en: where $\mathcal{X}_{t-t^{\prime},i}\in\mathbb{R}^{\mathbf{N}}$ is the $i^{th}$
    feature of input $\mathcal{X}$ at time $t-t^{\prime}$ , $\mathcal{Y}_{t,j}\in\mathbb{R}^{\mathbf{N}}$
    is the $j^{th}$ feature of output $\mathcal{Y}$ at time $t$.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathcal{X}_{t-t^{\prime},i}\in\mathbb{R}^{\mathbf{N}}$是时间$t-t^{\prime}$时输入$\mathcal{X}$的第$i$个特征，$\mathcal{Y}_{t,j}\in\mathbb{R}^{\mathbf{N}}$是时间$t$时输出$\mathcal{Y}$的第$j$个特征。
- en: Zhao et al. [[94](#bib.bib94)] changed SGC as $\Theta\boldsymbol{*_{\mathcal{G}}}x=(W\boldsymbol{\odot}\tilde{\mathbf{A}}^{\mathbf{K}}\boldsymbol{\odot}\mathcal{FFR})x$
    , where $\tilde{\mathbf{A}}^{\mathbf{K}}$ is the $\mathbf{K}$-hop neighborhood
    matrix and $\mathcal{FFR}$ is a matrix representing physical properties of road
    network. Some researchers [[120](#bib.bib120)],[[110](#bib.bib110)] followed this
    work and redefined $\Theta\boldsymbol{*_{\mathcal{G}}}x=(W\boldsymbol{\odot}Bi(\mathbf{A}^{\mathbf{K}}+\mathbf{I_{N}}))x$,
    where $Bi(.)$ is a function clipping each nonzero element in matrix to 1.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 赵等人[[94](#bib.bib94)] 将SGC修改为$\Theta\boldsymbol{*_{\mathcal{G}}}x=(W\boldsymbol{\odot}\tilde{\mathbf{A}}^{\mathbf{K}}\boldsymbol{\odot}\mathcal{FFR})x$，其中$\tilde{\mathbf{A}}^{\mathbf{K}}$是$\mathbf{K}$跳邻域矩阵，$\mathcal{FFR}$是表示道路网络物理属性的矩阵。一些研究人员[[120](#bib.bib120)],[[110](#bib.bib110)]
    继承了这项工作，并重新定义了$\Theta\boldsymbol{*_{\mathcal{G}}}x=(W\boldsymbol{\odot}Bi(\mathbf{A}^{\mathbf{K}}+\mathbf{I_{N}}))x$，其中$Bi(.)$是一个将矩阵中每个非零元素截断为1的函数。
- en: Sun et al. [[116](#bib.bib116)] modified adjacency matrix $\mathbf{A}$ in SGC
    as $\mathbf{S}=\mathbf{A}\boldsymbol{\odot}\omega$ to integrate the geospatial
    positions information into the model and $\omega$ is a matrix calculated via a
    thresholded Gaussian kernel weighting function. The layer is built as $Y=\boldsymbol{\rho}(\tilde{\mathbf{Q}}^{-\frac{1}{2}}\tilde{\mathbf{S}}\tilde{\mathbf{Q}}^{-\frac{1}{2}}XW)$,
    where $\tilde{\mathbf{Q}}$ is the degree matrix of $\tilde{\mathbf{S}}=\mathbf{S}+\mathbf{I_{N}}$.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 孙等人[[116](#bib.bib116)] 将SGC中的邻接矩阵$\mathbf{A}$修改为$\mathbf{S}=\mathbf{A}\boldsymbol{\odot}\omega$，以将地理空间位置信息整合到模型中，$\omega$是通过阈值高斯核加权函数计算的矩阵。该层构建为$Y=\boldsymbol{\rho}(\tilde{\mathbf{Q}}^{-\frac{1}{2}}\tilde{\mathbf{S}}\tilde{\mathbf{Q}}^{-\frac{1}{2}}XW)$，其中$\tilde{\mathbf{Q}}$是$\tilde{\mathbf{S}}=\mathbf{S}+\mathbf{I_{N}}$的度矩阵。
- en: Qiu et al. [[57](#bib.bib57)] designed a novel edge-based SGC on road network
    to extract the spatiotemporal correlations of the edge features. Both the feature
    matrix $X$ and adjacency matrix $\mathbf{A}$ are defined on edges instead of nodes.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 邱等人[[57](#bib.bib57)] 设计了一种新颖的基于边缘的SGC来提取边缘特征的时空相关性。特征矩阵$X$和邻接矩阵$\mathbf{A}$都定义在边缘而不是节点上。
- en: V-B RNNs
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-B RNNs
- en: Recurrent Neural Networks (RNNs) are a type of neural network architecture which
    is mainly used to detect patterns in sequential data [[133](#bib.bib133)]. The
    traffic data collected in many traffic tasks are time series data, thus RNNs are
    commonly utilized in these traffic tasks to capture the temporal dependency in
    traffic data. In this subsection, we introduce three classical models of RNNs
    (i.e. RNN, LSTM, GRU) and the correlations among them, providing theoretical evidence
    for participators to choose appropriate models for specific traffic problems.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 循环神经网络（RNNs）是一种主要用于检测序列数据中模式的神经网络架构[[133](#bib.bib133)]。许多交通任务中收集的交通数据是时间序列数据，因此RNNs通常用于这些交通任务中以捕捉交通数据中的时间依赖性。在这一小节中，我们介绍了三种经典的RNN模型（即RNN、LSTM、GRU）及其之间的关联，为参与者选择适合特定交通问题的模型提供理论依据。
- en: V-B1 RNN
  id: totrans-277
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-B1 RNN
- en: '![Refer to caption](img/b80c6a7ddf1fe5650466cb7173d16014.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![参见图例](img/b80c6a7ddf1fe5650466cb7173d16014.png)'
- en: 'Figure 7: The folded and unfolded structure of recurrent neural networks'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：循环神经网络的折叠与展开结构
- en: Similar to a classical Feedforward Neural Network (FNN), a simple recurrent
    neural network (RNN) [[134](#bib.bib134)] contains three layers, i.e. input layer,
    hidden layer, output layer [[135](#bib.bib135)]. What differentiates RNN from
    FNN is the hidden layer. It passes information forward to the output layer in
    FNN while in RNN, it also transmits information back into itself forming a cycle
    [[133](#bib.bib133)]. For this reason, the hidden layer in RNN is called recurrent
    hidden layer. Such cycling trick can retain historical information, enabling RNN
    to process time series data.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于经典的前馈神经网络（FNN），简单的递归神经网络（RNN）[[134](#bib.bib134)] 包含三层，即输入层、隐藏层和输出层 [[135](#bib.bib135)]。RNN
    与 FNN 的区别在于隐藏层。FNN 中的隐藏层将信息传递给输出层，而在 RNN 中，它还将信息传递回自身，形成一个循环 [[133](#bib.bib133)]。因此，RNN
    中的隐藏层被称为递归隐藏层。这种循环机制可以保留历史信息，使 RNN 能够处理时间序列数据。
- en: 'Suppose there are $\mathbf{F_{I}}$, $\mathbf{F_{H}}$, $\mathbf{F_{O}}$ units
    in the input, hidden, output layer of RNN respectively. The input layer takes
    time series data $\mathbf{X}=[\mathbf{X}_{1},\cdots,\mathbf{X}_{\mathbf{P}}]\in\mathbb{R}^{\mathbf{P}\times\mathbf{F_{I}}}$
    in. For each element $\mathbf{X}_{t}\in\mathbb{R}^{\mathbf{F_{I}}}$ at time $t$,
    the hidden layer transforms it to $\mathbf{H}_{t}\in\mathbb{R}^{\mathbf{F_{H}}}$
    and the output layer maps $\mathbf{H}_{t}$ to $\mathbf{Y}_{t}\in\mathbb{R}^{\mathbf{F_{O}}}$.
    Note that the hidden layer not only takes $\mathbf{X}_{t}$ as input but also takes
    $\mathbf{H}_{t-1}$ as input. Such cycling mechanism enables RNN to memorize the
    past information (as shown in Figure [7](#S5.F7 "Figure 7 ‣ V-B1 RNN ‣ V-B RNNs
    ‣ V Deep Learning Techniques Perspective ‣ How to Build a Graph-Based Deep Learning
    Architecture in Traffic Domain: A Survey")). The mathematical notations of hidden
    layer and output layer are as follows:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '假设 RNN 的输入层、隐藏层和输出层分别有 $\mathbf{F_{I}}$、$\mathbf{F_{H}}$ 和 $\mathbf{F_{O}}$
    个单元。输入层接收时间序列数据 $\mathbf{X}=[\mathbf{X}_{1},\cdots,\mathbf{X}_{\mathbf{P}}]\in\mathbb{R}^{\mathbf{P}\times\mathbf{F_{I}}}$。对于时间
    $t$ 的每个元素 $\mathbf{X}_{t}\in\mathbb{R}^{\mathbf{F_{I}}}$，隐藏层将其转换为 $\mathbf{H}_{t}\in\mathbb{R}^{\mathbf{F_{H}}}$，输出层将
    $\mathbf{H}_{t}$ 映射为 $\mathbf{Y}_{t}\in\mathbb{R}^{\mathbf{F_{O}}}$。请注意，隐藏层不仅以
    $\mathbf{X}_{t}$ 作为输入，还以 $\mathbf{H}_{t-1}$ 作为输入。这种循环机制使得 RNN 能够记住过去的信息（如图 [7](#S5.F7
    "Figure 7 ‣ V-B1 RNN ‣ V-B RNNs ‣ V Deep Learning Techniques Perspective ‣ How
    to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey")
    所示）。隐藏层和输出层的数学表示如下：'
- en: '|  | $\begin{split}\mathbf{H}_{t}&amp;=\boldsymbol{tanh}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{h}+b_{h})\\
    \mathbf{Y}_{t}&amp;=\boldsymbol{\rho}(\mathbf{H}_{t}\boldsymbol{\cdot}W_{y}+b_{y})\end{split}$
    |  | (8) |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\mathbf{H}_{t}&amp;=\boldsymbol{tanh}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{h}+b_{h})\\
    \mathbf{Y}_{t}&amp;=\boldsymbol{\rho}(\mathbf{H}_{t}\boldsymbol{\cdot}W_{y}+b_{y})\end{split}$
    |  | (8) |'
- en: where $W_{h}\in\mathbb{R}^{(\mathbf{F_{I}+\mathbf{F_{H}}})\times\mathbf{F_{H}}}$,
    $W_{y}\in\mathbb{R}^{\mathbf{F_{H}}\times\mathbf{F_{O}}}$, $b_{h}\in\mathbb{R}^{\mathbf{F_{H}}}$,
    $b_{y}\in\mathbb{R}^{\mathbf{F_{O}}}$ are trainable parameters. $t=1,\cdots,\mathbf{P}$
    and $\mathbf{P}$ is the input sequence length. $\mathbf{H}_{0}$ is initialized
    using small non-zero elements which can improve overall performance and stability
    of the network [[136](#bib.bib136)].
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $W_{h}\in\mathbb{R}^{(\mathbf{F_{I}+\mathbf{F_{H}}})\times\mathbf{F_{H}}}$，$W_{y}\in\mathbb{R}^{\mathbf{F_{H}}\times\mathbf{F_{O}}}$，$b_{h}\in\mathbb{R}^{\mathbf{F_{H}}}$，$b_{y}\in\mathbb{R}^{\mathbf{F_{O}}}$
    是可训练的参数。$t=1,\cdots,\mathbf{P}$，$\mathbf{P}$ 是输入序列的长度。$\mathbf{H}_{0}$ 使用小的非零元素初始化，这可以改善网络的整体性能和稳定性
    [[136](#bib.bib136)]。
- en: 'In a word, RNN takes sequential data as input and generates another sequence
    with the same length: $[\mathbf{X}_{1},\cdots,\mathbf{X}_{\mathbf{P}}]\stackrel{{\scriptstyle
    RNN}}{{\longrightarrow}}[\mathbf{Y}_{1},\cdots,\mathbf{Y}_{\mathbf{P}}]$. Note
    that we can deepen RNN through stacking multiple recurrent hidden layers.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 简言之，RNN 将序列数据作为输入，并生成另一长度相同的序列：$[\mathbf{X}_{1},\cdots,\mathbf{X}_{\mathbf{P}}]\stackrel{{\scriptstyle
    RNN}}{{\longrightarrow}}[\mathbf{Y}_{1},\cdots,\mathbf{Y}_{\mathbf{P}}]$。请注意，我们可以通过堆叠多个递归隐藏层来深化
    RNN。
- en: V-B2 LSTM
  id: totrans-285
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-B2 LSTM
- en: Although the hidden state enables RNN to memorize the input information over
    past time steps, it also introduces matrix multiplication over the (potentially
    very long) sequence. Small values in the matrix multiplication cause the gradients
    to decrease at each time step, resulting in final vanish phenomenon. Oppositely
    big values lead to exploding problem [[137](#bib.bib137)]. The vanishing or exploding
    gradients actually hinder the capacity of RNN to learn long-term sequential dependencies
    in data [[135](#bib.bib135)].
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管隐藏状态使得RNN能够记住过去时间步的输入信息，但它也引入了对（可能非常长的）序列的矩阵乘法。矩阵乘法中的小值导致梯度在每个时间步减少，从而导致最终的梯度消失现象。相反，大值则导致爆炸问题[[137](#bib.bib137)]。梯度消失或梯度爆炸实际上阻碍了RNN学习数据中长期序列依赖的能力[[135](#bib.bib135)]。
- en: 'To overcome this hurdle, Long Short-Term Memory (LSTM) neural networks[[138](#bib.bib138)]
    are proposed to capture long-term dependency in sequence learning. Compared with
    the hidden layer in RNN, LSTM hidden layer has extra four parts, i.e. a memory
    cell, input gate, forget gate, and output gate. These three gates ranging in [0,1]
    can control information flow into the memory cell and preserve the extracted features
    from previous time steps. These simple changes enable the memory cell to store
    and read as much long-term information as possible. The mathematical notations
    of LSTM hidden layer are as follows:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这个障碍，提出了长短期记忆（LSTM）神经网络[[138](#bib.bib138)]，以捕捉序列学习中的长期依赖性。与RNN中的隐藏层相比，LSTM隐藏层多了四个部分，即一个记忆单元、输入门、遗忘门和输出门。这三个范围在[0,1]之间的门控可以控制信息流入记忆单元，并保存来自前一个时间步的提取特征。这些简单的变化使得记忆单元能够存储和读取尽可能多的长期信息。LSTM隐藏层的数学表示如下：
- en: '|  | <math   alttext="\begin{split}i_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{i}+b_{i})\\
    o_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{o}+b_{o})\\'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}i_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{i}+b_{i})\\
    o_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{o}+b_{o})\\'
- en: f_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{f}+b_{f})\\
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: f_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{f}+b_{f})\\
- en: \mathbf{C}_{t}&amp;=f_{t}\boldsymbol{\odot}\mathbf{C}_{t-1}+i_{t}\boldsymbol{\odot}\boldsymbol{tanh}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{c}+b_{c})\\
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: \mathbf{C}_{t}&amp;=f_{t}\boldsymbol{\odot}\mathbf{C}_{t-1}+i_{t}\boldsymbol{\odot}\boldsymbol{tanh}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{c}+b_{c})\\
- en: \mathbf{H}_{t}&amp;=o_{t}\boldsymbol{\odot}\boldsymbol{tanh}(\mathbf{C}_{t})\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"  ><mtr
    ><mtd columnalign="right"  ><msub ><mi mathsize="80%" >i</mi><mi mathsize="80%"
    >t</mi></msub></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><mi mathsize="80%"  >𝝈</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mrow ><mrow ><mrow ><mo maxsize="80%" minsize="80%"  >[</mo><msub
    ><mi mathsize="80%"  >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%"
    >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo mathsize="80%"  >,</mo><msub
    ><mi mathsize="80%"  >𝐗</mi><mi mathsize="80%"  >t</mi></msub><mo maxsize="80%"
    minsize="80%" rspace="0.055em"  >]</mo></mrow><mo mathsize="80%" mathvariant="bold"
    rspace="0.222em" >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi mathsize="80%"  >i</mi></msub></mrow><mo
    mathsize="80%"  >+</mo><msub ><mi mathsize="80%"  >b</mi><mi mathsize="80%"  >i</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><msub ><mi mathsize="80%" >o</mi><mi mathsize="80%" >t</mi></msub></mtd><mtd
    columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%"
    >𝝈</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo maxsize="80%" minsize="80%"
    >(</mo><mrow ><mrow ><mrow ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi
    mathsize="80%" >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%" >−</mo><mn
    mathsize="80%" >1</mn></mrow></msub><mo mathsize="80%" >,</mo><msub ><mi mathsize="80%"
    >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo maxsize="80%" minsize="80%" rspace="0.055em"  >]</mo></mrow><mo
    mathsize="80%" mathvariant="bold" rspace="0.222em" >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi
    mathsize="80%"  >o</mi></msub></mrow><mo mathsize="80%"  >+</mo><msub ><mi mathsize="80%"  >b</mi><mi
    mathsize="80%"  >o</mi></msub></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msub ><mi mathsize="80%" >f</mi><mi mathsize="80%"
    >t</mi></msub></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><mi mathsize="80%" >𝝈</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo maxsize="80%"
    minsize="80%" >(</mo><mrow ><mrow ><mrow ><mo maxsize="80%" minsize="80%" >[</mo><msub
    ><mi mathsize="80%" >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%"
    >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo mathsize="80%" >,</mo><msub
    ><mi mathsize="80%" >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo maxsize="80%"
    minsize="80%" rspace="0.055em"  >]</mo></mrow><mo mathsize="80%" mathvariant="bold"
    rspace="0.222em" >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi mathsize="80%"  >f</mi></msub></mrow><mo
    mathsize="80%"  >+</mo><msub ><mi mathsize="80%"  >b</mi><mi mathsize="80%"  >f</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><msub ><mi mathsize="80%" >𝐂</mi><mi mathsize="80%" >t</mi></msub></mtd><mtd
    columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><mrow  ><msub ><mi
    mathsize="80%" >f</mi><mi mathsize="80%" >t</mi></msub><mo lspace="0.222em" mathsize="80%"
    mathvariant="bold" rspace="0.222em"  >⊙</mo><msub ><mi mathsize="80%" >𝐂</mi><mrow
    ><mi mathsize="80%" >t</mi><mo mathsize="80%" >−</mo><mn mathsize="80%" >1</mn></mrow></msub></mrow><mo
    mathsize="80%" >+</mo><mrow ><mrow ><msub ><mi mathsize="80%" >i</mi><mi mathsize="80%"
    >t</mi></msub><mo lspace="0.222em" mathsize="80%" mathvariant="bold" rspace="0.222em"
    >⊙</mo><mi mathsize="80%" >𝒕</mi></mrow><mo lspace="0em" rspace="0em" >​</mo><mi
    mathsize="80%"  >𝒂</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒏</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒉</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mrow ><mo maxsize="80%" minsize="80%"  >[</mo><msub ><mi mathsize="80%"  >𝐇</mi><mrow
    ><mi mathsize="80%"  >t</mi><mo mathsize="80%"  >−</mo><mn mathsize="80%"  >1</mn></mrow></msub><mo
    mathsize="80%"  >,</mo><msub ><mi mathsize="80%"  >𝐗</mi><mi mathsize="80%"  >t</mi></msub><mo
    maxsize="80%" minsize="80%" rspace="0.055em"  >]</mo></mrow><mo mathsize="80%"
    mathvariant="bold" rspace="0.222em" >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi
    mathsize="80%"  >c</mi></msub></mrow><mo mathsize="80%"  >+</mo><msub ><mi mathsize="80%"  >b</mi><mi
    mathsize="80%"  >c</mi></msub></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msub ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%"
    >t</mi></msub></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><mrow  ><msub ><mi mathsize="80%" >o</mi><mi mathsize="80%" >t</mi></msub><mo
    lspace="0.222em" mathsize="80%" mathvariant="bold" rspace="0.222em"  >⊙</mo><mi
    mathsize="80%"  >𝒕</mi></mrow><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒂</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒏</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >𝒉</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><msub ><mi mathsize="80%"  >𝐂</mi><mi
    mathsize="80%"  >t</mi></msub><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑖</ci><ci >𝑡</ci></apply><apply ><ci  >𝝈</ci><apply ><apply ><ci  >bold-⋅</ci><interval
    closure="closed"  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><apply
    ><ci  >𝑡</ci><cn type="integer"  >1</cn></apply></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝐗</ci><ci >𝑡</ci></apply></interval><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑊</ci><ci >𝑖</ci></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑏</ci><ci >𝑖</ci></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑜</ci><ci  >𝑡</ci></apply></apply></apply><apply ><apply ><ci  >𝝈</ci><apply
    ><apply ><ci  >bold-⋅</ci><interval closure="closed"  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝐇</ci><apply ><ci >𝑡</ci><cn type="integer" >1</cn></apply></apply><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝐗</ci><ci >𝑡</ci></apply></interval><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑊</ci><ci >𝑜</ci></apply></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑏</ci><ci >𝑜</ci></apply></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑓</ci><ci  >𝑡</ci></apply></apply></apply><apply
    ><apply ><ci  >𝝈</ci><apply ><apply ><ci  >bold-⋅</ci><interval closure="closed"  ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><apply ><ci >𝑡</ci><cn
    type="integer" >1</cn></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐗</ci><ci >𝑡</ci></apply></interval><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑊</ci><ci >𝑓</ci></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑏</ci><ci >𝑓</ci></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐂</ci><ci  >𝑡</ci></apply></apply></apply><apply ><apply ><apply  ><csymbol cd="latexml"  >direct-product</csymbol><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑓</ci><ci >𝑡</ci></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐂</ci><apply ><ci  >𝑡</ci><cn
    type="integer"  >1</cn></apply></apply></apply><apply ><apply ><csymbol cd="latexml"
    >direct-product</csymbol><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑖</ci><ci >𝑡</ci></apply><ci >𝒕</ci></apply><ci >𝒂</ci><ci >𝒏</ci><ci >𝒉</ci><apply
    ><apply  ><ci >bold-⋅</ci><interval closure="closed"  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝐇</ci><apply ><ci >𝑡</ci><cn type="integer"  >1</cn></apply></apply><apply ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci >𝐗</ci><ci >𝑡</ci></apply></interval><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑊</ci><ci >𝑐</ci></apply></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑏</ci><ci >𝑐</ci></apply></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐇</ci><ci >𝑡</ci></apply></apply></apply></apply><apply
    ><apply ><apply  ><csymbol cd="latexml"  >direct-product</csymbol><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝑜</ci><ci >𝑡</ci></apply><ci >𝒕</ci></apply><ci
    >𝒂</ci><ci  >𝒏</ci><ci >𝒉</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐂</ci><ci >𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}i_{t}&=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{i}+b_{i})\\
    o_{t}&=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{o}+b_{o})\\
    f_{t}&=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{f}+b_{f})\\
    \mathbf{C}_{t}&=f_{t}\boldsymbol{\odot}\mathbf{C}_{t-1}+i_{t}\boldsymbol{\odot}\boldsymbol{tanh}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{c}+b_{c})\\
    \mathbf{H}_{t}&=o_{t}\boldsymbol{\odot}\boldsymbol{tanh}(\mathbf{C}_{t})\end{split}</annotation></semantics></math>
    |  | (9) |
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: \mathbf{H}_{t}&amp;=o_{t}\boldsymbol{\odot}\boldsymbol{tanh}(\mathbf{C}_{t})\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"  ><mtr
    ><mtd columnalign="right"  ><msub ><mi mathsize="80%" >i</mi><mi mathsize="80%"
    >t</mi></msub></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><mi mathsize="80%"  >𝝈</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mrow ><mrow ><mrow ><mo maxsize="80%" minsize="80%"  >[</mo><msub
    ><mi mathsize="80%"  >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%"
    >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo mathsize="80%"  >,</mo><msub
    ><mi mathsize="80%"  >𝐗</mi><mi mathsize="80%"  >t</mi></msub><mo maxsize="80%"
    minsize="80%" rspace="0.055em"  >]</mo></mrow><mo mathsize="80%" mathvariant="bold"
    rspace="0.222em" >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi mathsize="80%"  >i</mi></msub></mrow><mo
    mathsize="80%"  >+</mo><msub ><mi mathsize="80%"  >b</mi><mi mathsize="80%"  >i</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><msub ><mi mathsize="80%" >o</mi><mi mathsize="80%" >t</mi></msub></mtd><mtd
    columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%"
    >𝝈</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo maxsize="80%" minsize="80%"
    >(</mo><mrow ><mrow ><mrow ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi
    mathsize="80%" >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%" >−</mo><mn
    mathsize="80%" >1</mn></mrow></msub><mo mathsize="80%" >,</mo><msub ><mi mathsize="80%"
    >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo maxsize="80%" minsize="80%" rspace="0.055em"  >]</mo></mrow><mo
    mathsize="80%" mathvariant="bold" rspace="0.222em" >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi
    mathsize="80%"  >o</mi></msub></mrow><mo mathsize="80%"  >+</mo><msub ><mi mathsize="80%"  >b</mi><mi
    mathsize="80%"  >o</mi></msub></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msub ><mi mathsize="80%" >f</mi><mi mathsize="80%"
    >t</mi></msub></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><mi mathsize="80%" >𝝈</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo maxsize="80%"
    minsize="80%" >(</mo><mrow ><mrow ><mrow ><mo maxsize="80%" minsize="80%" >[</mo><msub
    ><mi mathsize="80%" >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%"
    >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo mathsize="80%" >,</mo><msub
    ><mi mathsize="80%" >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo maxsize="80%"
    minsize="80%" rspace="0.055em"  >]</mo></mrow><mo mathsize="80%" mathvariant="bold"
    rspace="0.222em" >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi mathsize="80%"  >f</mi></msub></mrow><mo
    mathsize="80%"  >+</mo><msub ><mi mathsize="80%"  >b</mi><mi mathsize="80%"  >f</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><msub ><mi mathsize="80%" >𝐂</mi><mi mathsize="80%" >t</mi></msub></mtd><mtd
    columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><mrow  ><msub ><mi
    mathsize="80%" >f</mi><mi mathsize="80%" >t</mi></msub><mo lspace="0.222em" mathsize="80%"
    mathvariant="bold" rspace="0.222em"  >⊙</mo><msub ><mi mathsize="80%" >𝐂</mi><mrow
    ><mi mathsize="80%" >t</mi><mo mathsize="80%" >−</mo><mn mathsize="80%" >1</mn></mrow></msub></mrow><mo
    mathsize="80%" >+</mo><mrow ><mrow ><msub ><mi mathsize="80%" >i</mi><mi mathsize="80%"
    >t</mi></msub><mo lspace="0.222em" mathsize="80%" mathvariant="bold" rspace="0.222em"
    >⊙</mo><mi mathsize="80%" >𝒕</mi></mrow><mo lspace="0em" rspace="0em" >​</mo><mi
    mathsize="80%"  >𝒂</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒏</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒉</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mrow ><mo maxsize="80%" minsize="80%"  >[</mo><msub ><mi mathsize="80%"  >𝐇</mi><mrow
    ><mi mathsize="80%"  >t</mi><mo mathsize="80%"  >−</mo><mn mathsize="80%"  >1</mn></mrow></msub><mo
    mathsize="80%"  >,</mo><msub ><mi mathsize="80%"  >𝐗</mi><mi mathsize="80%"  >t</mi></msub><mo
    maxsize="80%" minsize="80%" rspace="0.055em"  >]</mo></mrow><mo mathsize="80%"
    mathvariant="bold" rspace="0.222em" >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi
    mathsize="80%"  >c</mi></msub></mrow><mo mathsize="80%"  >+</mo><msub ><mi mathsize="80%"  >b</mi><mi
    mathsize="80%"  >c</mi></msub></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msub ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%"
    >t</mi></msub></mtd><mtd columnalign="left"  ><mrow ><mo
- en: where $i_{t}$, $o_{t}$, $f_{t}$ are the input gate, output gate, forget gate
    at time $t$ respectively. $\mathbf{C}_{t}$ is the memory cell at time $t$.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $i_{t}$、$o_{t}$ 和 $f_{t}$ 分别是时间 $t$ 的输入门、输出门和遗忘门。$\mathbf{C}_{t}$ 是时间 $t$
    的记忆单元。
- en: V-B3 GRU
  id: totrans-293
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-B3 GRU
- en: 'While LSTM is a viable option for avoiding vanishing or exploding gradients,
    its complex structure leads to more memory requirement and longer training time.
    Chung et al. [[139](#bib.bib139)] proposed a simple yet powerful variant of LSTM,
    i.e. Gated Recurrent Unit (GRU). The LSTM cell has three gates, but the GRU cell
    only has two gates, resulting in fewer parameters thus shorter training time.
    However, GRU is equally effective as LSTM empirically [[139](#bib.bib139)] and
    is widely used in various tasks. The mathematical notations of GRU hidden layer
    are as follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 LSTM 是避免梯度消失或爆炸的可行选择，但其复杂的结构导致了更多的内存需求和更长的训练时间。Chung 等人[[139](#bib.bib139)]
    提出了 LSTM 的一种简单而强大的变体，即门控循环单元 (GRU)。LSTM 单元有三个门，但 GRU 单元只有两个门，从而减少了参数数量，缩短了训练时间。然而，GRU
    的实际效果与 LSTM 同样有效[[139](#bib.bib139)]，并且在各种任务中得到了广泛应用。GRU 隐藏层的数学符号如下：
- en: '|  | <math   alttext="\begin{split}r_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{r}+b_{r})\\
    u_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{u}+b_{u})\\'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}r_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{r}+b_{r})\\
    u_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{u}+b_{u})\\'
- en: \tilde{\mathbf{H}_{t}}&amp;=\boldsymbol{tanh}(r_{t}\boldsymbol{\odot}[\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{h}+b_{h})\\
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: \tilde{\mathbf{H}_{t}}&amp;=\boldsymbol{tanh}(r_{t}\boldsymbol{\odot}[\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{h}+b_{h})\\
- en: \mathbf{H}_{t}&amp;=u_{t}\boldsymbol{\odot}\mathbf{H}_{t-1}+(1-u_{t})\boldsymbol{\odot}\tilde{\mathbf{H}_{t}}\\
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: \mathbf{H}_{t}&amp;=u_{t}\boldsymbol{\odot}\mathbf{H}_{t-1}+(1-u_{t})\boldsymbol{\odot}\tilde{\mathbf{H}_{t}}\\
- en: \end{split}" display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt"  ><mtr ><mtd columnalign="right"  ><msub ><mi mathsize="80%"
    >r</mi><mi mathsize="80%" >t</mi></msub></mtd><mtd columnalign="left"  ><mrow
    ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%"  >𝝈</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mrow ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi mathsize="80%"  >𝐇</mi><mrow
    ><mi mathsize="80%" >t</mi><mo mathsize="80%"  >−</mo><mn mathsize="80%"  >1</mn></mrow></msub><mo
    mathsize="80%"  >,</mo><msub ><mi mathsize="80%"  >𝐗</mi><mi mathsize="80%"  >t</mi></msub><mo
    maxsize="80%" minsize="80%" rspace="0.055em" >]</mo></mrow><mo  mathsize="80%"
    mathvariant="bold" rspace="0.222em"  >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi
    mathsize="80%"  >r</mi></msub></mrow><mo mathsize="80%"  >+</mo><msub ><mi mathsize="80%"
    >b</mi><mi mathsize="80%"  >r</mi></msub></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msub ><mi mathsize="80%" >u</mi><mi mathsize="80%"
    >t</mi></msub></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><mi mathsize="80%" >𝝈</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mrow ><mrow ><mrow ><mo maxsize="80%" minsize="80%" >[</mo><msub
    ><mi mathsize="80%" >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%"
    >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo mathsize="80%" >,</mo><msub
    ><mi mathsize="80%" >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo maxsize="80%"
    minsize="80%" rspace="0.055em"  >]</mo></mrow><mo mathsize="80%" mathvariant="bold"
    rspace="0.222em" >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi mathsize="80%"  >u</mi></msub></mrow><mo
    mathsize="80%"  >+</mo><msub ><mi mathsize="80%" >b</mi><mi mathsize="80%"  >u</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><mover accent="true"  ><msub ><mi mathsize="80%" >𝐇</mi><mi
    mathsize="80%"  >t</mi></msub><mo mathsize="80%"  >~</mo></mover></mtd><mtd columnalign="left"  ><mrow
    ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%" >𝒕</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >𝒂</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒏</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒉</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mrow ><msub ><mi mathsize="80%" >r</mi><mi mathsize="80%" >t</mi></msub><mo
    lspace="0.222em" mathsize="80%" mathvariant="bold" rspace="0.222em" >⊙</mo><mrow
    ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi mathsize="80%" >𝐇</mi><mrow
    ><mi mathsize="80%" >t</mi><mo mathsize="80%" >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo
    mathsize="80%" >,</mo><msub ><mi mathsize="80%" >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo
    maxsize="80%" minsize="80%" rspace="0.055em"  >]</mo></mrow></mrow><mo mathsize="80%"
    mathvariant="bold" rspace="0.222em" >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi
    mathsize="80%"  >h</mi></msub></mrow><mo mathsize="80%"  >+</mo><msub ><mi mathsize="80%"
    >b</mi><mi mathsize="80%"  >h</mi></msub></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msub ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%"
    >t</mi></msub></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><mrow ><msub  ><mi mathsize="80%"  >u</mi><mi mathsize="80%"  >t</mi></msub><mo
    lspace="0.222em" mathsize="80%" mathvariant="bold" rspace="0.222em"  >⊙</mo><msub
    ><mi mathsize="80%" >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%"  >−</mo><mn
    mathsize="80%"  >1</mn></mrow></msub></mrow><mo mathsize="80%"  >+</mo><mrow ><mrow
    ><mo maxsize="80%" minsize="80%" >(</mo><mrow ><mn mathsize="80%" >1</mn><mo mathsize="80%"
    >−</mo><msub ><mi mathsize="80%" >u</mi><mi mathsize="80%" >t</mi></msub></mrow><mo
    maxsize="80%" minsize="80%" rspace="0.055em"  >)</mo></mrow><mo mathsize="80%"
    mathvariant="bold" rspace="0.222em" >⊙</mo><mover accent="true"  ><msub ><mi mathsize="80%"  >𝐇</mi><mi
    mathsize="80%"  >t</mi></msub><mo mathsize="80%"  >~</mo></mover></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑟</ci><ci >𝑡</ci></apply><apply ><ci  >𝝈</ci><apply ><apply ><ci  >bold-⋅</ci><interval
    closure="closed"  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><apply
    ><ci  >𝑡</ci><cn type="integer"  >1</cn></apply></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝐗</ci><ci >𝑡</ci></apply></interval><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑊</ci><ci >𝑟</ci></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑏</ci><ci >𝑟</ci></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑢</ci><ci >𝑡</ci></apply></apply></apply><apply ><apply  ><ci >𝝈</ci><apply ><apply
    ><ci  >bold-⋅</ci><interval closure="closed"  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝐇</ci><apply ><ci >𝑡</ci><cn type="integer" >1</cn></apply></apply><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝐗</ci><ci >𝑡</ci></apply></interval><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑊</ci><ci >𝑢</ci></apply></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑏</ci><ci >𝑢</ci></apply></apply><apply
    ><ci  >~</ci><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><ci
    >𝑡</ci></apply></apply></apply></apply><apply ><apply ><ci  >𝒕</ci><ci >𝒂</ci><ci
    >𝒏</ci><ci  >𝒉</ci><apply ><apply ><ci  >bold-⋅</ci><apply ><csymbol cd="latexml"
    >direct-product</csymbol><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑟</ci><ci >𝑡</ci></apply><interval closure="closed" ><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝐇</ci><apply ><ci >𝑡</ci><cn type="integer" >1</cn></apply></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐗</ci><ci >𝑡</ci></apply></interval></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑊</ci><ci >ℎ</ci></apply></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑏</ci><ci >ℎ</ci></apply></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐇</ci><ci >𝑡</ci></apply></apply></apply><apply
    ><apply  ><apply ><csymbol cd="latexml" >direct-product</csymbol><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝑢</ci><ci >𝑡</ci></apply><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝐇</ci><apply ><ci  >𝑡</ci><cn type="integer"  >1</cn></apply></apply></apply><apply
    ><csymbol cd="latexml" >direct-product</csymbol><apply ><cn type="integer" >1</cn><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑢</ci><ci >𝑡</ci></apply></apply><apply
    ><ci >~</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐇</ci><ci
    >𝑡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}r_{t}&=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{r}+b_{r})\\
    u_{t}&=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{u}+b_{u})\\
    \tilde{\mathbf{H}_{t}}&=\boldsymbol{tanh}(r_{t}\boldsymbol{\odot}[\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\cdot}W_{h}+b_{h})\\
    \mathbf{H}_{t}&=u_{t}\boldsymbol{\odot}\mathbf{H}_{t-1}+(1-u_{t})\boldsymbol{\odot}\tilde{\mathbf{H}_{t}}\\
    \end{split}</annotation></semantics></math> |  | (10) |
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: \end{split}" display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt"  ><mtr ><mtd columnalign="right"  ><msub ><mi mathsize="80%"
    >r</mi><mi mathsize="80%" >t</mi></msub></mtd><mtd columnalign="left"  ><mrow
    ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%"  >𝝈</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mrow ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi mathsize="80%"  >𝐇</mi><mrow
    ><mi mathsize="80%" >t</mi><mo mathsize="80%"  >−</mo><mn mathsize="80%"  >1</mn></mrow></msub><mo
    mathsize="80%"  >,</mo><msub ><mi mathsize="80%"  >𝐗</mi><mi mathsize="80%"  >t</mi></msub><mo
    maxsize="80%" minsize="80%" rspace="0.055em" >]</mo></mrow><mo  mathsize="80%"
    mathvariant="bold" rspace="0.222em"  >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi
    mathsize="80%"  >r</mi></msub></mrow><mo mathsize="80%"  >+</mo><msub ><mi mathsize="80%"
    >b</mi><mi mathsize="80%"  >r</mi></msub></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msub ><mi mathsize="80%" >u</mi><mi mathsize="80%"
    >t</mi></msub></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><mi mathsize="80%" >𝝈</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mrow ><mrow ><mrow ><mo maxsize="80%" minsize="80%" >[</mo><msub
    ><mi mathsize="80%" >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%"
    >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo mathsize="80%"  >,</mo><msub
    ><mi mathsize="80%" >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo maxsize="80%"
    minsize="80%" rspace="0.055em"  >]</mo></mrow><mo mathsize="80%" mathvariant="bold"
    rspace="0.222em" >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi mathsize="80%"  >u</mi></msub></mrow><mo
    mathsize="80%"  >+</mo><msub ><mi mathsize="80%" >b</mi><mi mathsize="80%"  >u</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><mover accent="true"  ><msub ><mi mathsize="80%" >𝐇</mi><mi
    mathsize="80%"  >t</mi></msub><mo mathsize="80%"  >~</mo></mover></mtd><mtd columnalign="left"  ><mrow
    ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%" >𝒕</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >𝒂</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒏</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒉</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mrow ><msub ><mi mathsize="80%" >r</mi><mi mathsize="80%" >t</mi></msub><mo
    lspace="0.222em" mathsize="80%" mathvariant="bold" rspace="0.222em" >⊙</mo><mrow
    ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi mathsize="80%" >𝐇</mi><mrow
    ><mi mathsize="80%" >t</mi><mo mathsize="80%" >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo
    mathsize="80%" >,</mo><msub ><mi mathsize="80%" >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo
    maxsize="80%" minsize="80%" rspace="0.055em"  >]</mo></mrow></mrow><mo mathsize="80%"
    mathvariant="bold" rspace="0.222em" >⋅</mo><msub ><mi mathsize="80%"  >W</mi><mi
    mathsize="80%"  >h</mi></msub></mrow><mo mathsize="80%"  >+</mo><msub ><mi mathsize="80%"
    >b</mi><mi mathsize="80%"  >h</mi></msub></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msub ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%"
    >t</mi></msub></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><mrow ><msub  ><mi mathsize="80%"  >u</mi><mi mathsize="80%"  >t</mi></msub><mo
    lspace="0.222em" mathsize="80%" mathvariant="bold" rspace="0.222em"  >⊙</mo><msub
    ><mi mathsize="80%" >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%"  >−</mo><mn
    mathsize="80%"  >1</mn></mrow></msub></mrow><mo mathsize="80%"  >+</mo><mrow ><mrow
    ><mo maxsize="80%" minsize="80%" >(</mo><mrow ><mn mathsize="80%" >1</mn><mo mathsize="80%"
    >−</mo><msub ><mi mathsize="80%" >u</mi><mi mathsize="80%" >t</mi></msub></mrow><mo
    maxsize="80%" minsize="80%" rspace="0.055em"  >)</mo></mrow><mo mathsize="80%"
    mathvariant="bold" rspace="0.222em" >⊙</mo><mover accent="true"  ><msub ><mi mathsize="80%"  >𝐇</mi><mi
    mathsize="80%"  >t</mi></msub><mo mathsize="80%"  >~</mo></mover></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑟</ci><ci >𝑡</ci></apply><apply ><ci  >𝝈</ci><apply ><apply ><ci  >bold-⋅</ci><interval
    closure="closed"  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><apply
    ><ci  >𝑡</ci><cn type="integer"  >1</cn></apply></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝐗</ci><ci >𝑡</ci></apply></interval><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑊</ci><ci >𝑟</ci></apply
- en: where $r_{t}$ is the reset gate, $u_{t}$ is the update gate.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $r_{t}$ 是重置门，$u_{t}$ 是更新门。
- en: V-B4 RNNs in Traffic Domain
  id: totrans-300
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-B4 交通领域中的RNN
- en: RNNs have shown impressive capability of processing time series data. Since
    traffic data has a distinct temporal dependency, RNNs are usually leveraged to
    capture temporal correlation in traffic data. Among the works we survey, only
    Geng et al. [[89](#bib.bib89)] utilized RNN to capture temporal dependency in
    traffic data while more than a half adopted GRU and some employed LSTM. This can
    be explained that RNN survives severe gradient disappearance or gradient explosion
    while LSTM and GRU handle this successfully and GRU can reduce the training time.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: RNNs（循环神经网络）在处理时间序列数据方面展现了令人印象深刻的能力。由于交通数据具有明显的时间依赖性，因此通常使用RNN来捕捉交通数据中的时间相关性。在我们调查的工作中，只有**Geng**等人[[89](#bib.bib89)]利用RNN来捕捉交通数据中的时间依赖性，而超过一半的研究采用了GRU，部分研究使用了LSTM。这可以解释为，RNN在面对严重的梯度消失或梯度爆炸时仍能存活，而LSTM和GRU能够成功应对这些问题，并且GRU可以缩短训练时间。
- en: In addition, there are many tricks to augment RNNs’ capacity to model the complex
    temporal dynamics in traffic domain, such as attention mechanism, gating mechanism
    and residual mechanism.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有许多技巧可以增强RNN在交通领域建模复杂时间动态的能力，例如注意力机制、门控机制和残差机制。
- en: 'For instance, Geng et al. [[89](#bib.bib89)] incorporated the contextual information,
    i.e. output of SGCN which contains information of related regions, into an attention
    operation to model the correlations between observations at different timestamps:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，**Geng**等人[[89](#bib.bib89)]将上下文信息，即包含相关区域信息的SGCN输出，纳入注意力操作中，以建模不同时间戳观测值之间的相关性：
- en: '|  | <math   alttext="\begin{split}z&amp;=F_{pool}(\mathbf{X}_{t},SGCN(\mathbf{X}_{t}))\\
    S&amp;=\boldsymbol{\sigma}(W_{1}\boldsymbol{ReLU}(W_{2}z))\\'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}z&amp;=F_{pool}(\mathbf{X}_{t},SGCN(\mathbf{X}_{t}))\\
    S&amp;=\boldsymbol{\sigma}(W_{1}\boldsymbol{ReLU}(W_{2}z))\\'
- en: \mathbf{H}_{t}&amp;=RNN([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\odot}S)\\
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: \mathbf{H}_{t}&amp;=RNN([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\odot}S)\\
- en: \end{split}" display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt"  ><mtr ><mtd columnalign="right"  ><mi mathsize="80%"  >z</mi></mtd><mtd
    columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><msub  ><mi mathsize="80%"  >F</mi><mrow
    ><mi mathsize="80%" >p</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >l</mi></mrow></msub><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><msub ><mi
    mathsize="80%" >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo mathsize="80%"  >,</mo><mrow
    ><mi mathsize="80%" >S</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >G</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >C</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >N</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><msub ><mi mathsize="80%"  >𝐗</mi><mi
    mathsize="80%"  >t</mi></msub><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><mi mathsize="80%"  >S</mi></mtd><mtd columnalign="left"  ><mrow
    ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%" >𝝈</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><msub ><mi mathsize="80%" >W</mi><mn
    mathsize="80%" >1</mn></msub><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"  >𝑹</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒆</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >𝑳</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >𝑼</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mrow ><msub ><mi mathsize="80%"  >W</mi><mn mathsize="80%"  >2</mn></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >z</mi></mrow><mo maxsize="80%"
    minsize="80%"  >)</mo></mrow></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msub ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%"
    >t</mi></msub></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><mi mathsize="80%" >R</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >N</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >N</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi mathsize="80%" >𝐇</mi><mrow
    ><mi mathsize="80%" >t</mi><mo mathsize="80%" >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo
    mathsize="80%" >,</mo><msub ><mi mathsize="80%" >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo
    maxsize="80%" minsize="80%" rspace="0.055em"  >]</mo></mrow><mo mathsize="80%"
    mathvariant="bold" rspace="0.222em" >⊙</mo><mi mathsize="80%"  >S</mi></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><ci >𝑧</ci><apply ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci >𝐹</ci><apply ><ci  >𝑝</ci><ci >𝑜</ci><ci
    >𝑜</ci><ci >𝑙</ci></apply></apply><interval closure="open"  ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝐗</ci><ci >𝑡</ci></apply><apply ><ci  >𝑆</ci><ci
    >𝐺</ci><ci >𝐶</ci><ci >𝑁</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐗</ci><ci >𝑡</ci></apply></apply></interval><ci >𝑆</ci></apply></apply><apply
    ><apply ><ci  >𝝈</ci><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑊</ci><cn type="integer" >1</cn></apply><ci >𝑹</ci><ci  >𝒆</ci><ci >𝑳</ci><ci
    >𝑼</ci><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑊</ci><cn
    type="integer"  >2</cn></apply><ci >𝑧</ci></apply></apply><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝐇</ci><ci >𝑡</ci></apply></apply></apply><apply ><apply  ><ci
    >𝑅</ci><ci >𝑁</ci><ci  >𝑁</ci><apply ><csymbol cd="latexml" >direct-product</csymbol><interval
    closure="closed"  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐇</ci><apply
    ><ci >𝑡</ci><cn type="integer" >1</cn></apply></apply><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝐗</ci><ci >𝑡</ci></apply></interval><ci >𝑆</ci></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}z&=F_{pool}(\mathbf{X}_{t},SGCN(\mathbf{X}_{t}))\\
    S&=\boldsymbol{\sigma}(W_{1}\boldsymbol{ReLU}(W_{2}z))\\ \mathbf{H}_{t}&=RNN([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\odot}S)\\
    \end{split}</annotation></semantics></math> |  | (11) |
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: \end{split}" display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt"  ><mtr ><mtd columnalign="right"  ><mi mathsize="80%"  >z</mi></mtd><mtd
    columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><msub  ><mi mathsize="80%"  >F</mi><mrow
    ><mi mathsize="80%" >p</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >l</mi></mrow></msub><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><msub ><mi
    mathsize="80%" >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo mathsize="80%"  >,</mo><mrow
    ><mi mathsize="80%" >S</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >G</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >C</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >N</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><msub ><mi mathsize="80%"  >𝐗</mi><mi
    mathsize="80%"  >t</mi></msub><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><mi mathsize="80%"  >S</mi></mtd><mtd columnalign="left"  ><mrow
    ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%" >𝝈</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><msub ><mi mathsize="80%" >W</mi><mn
    mathsize="80%" >1</mn></msub><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"  >𝑹</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒆</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >𝑳</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >𝑼</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mrow ><msub ><mi mathsize="80%"  >W</mi><mn mathsize="80%"  >2</mn></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >z</mi></mrow><mo maxsize="80%"
    minsize="80%"  >)</mo></mrow></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msub ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%"
    >t</mi></msub></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><mi mathsize="80%" >R</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >N</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >N</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi mathsize="80%" >𝐇</mi><mrow
    ><mi mathsize="80%" >t</mi><mo mathsize="80%" >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo
    mathsize="80%" >,</mo><msub ><mi mathsize="80%" >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo
    maxsize="80%" minsize="80%" rspace="0.055em"  >]</mo></mrow><mo mathsize="80%"
    mathvariant="bold" rspace="0.222em" >⊙</mo><mi mathsize="80%"  >S</mi></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><ci >𝑧</ci><apply ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci >𝐹</ci><apply ><ci  >𝑝</ci><ci >𝑜</ci><ci
    >𝑜</ci><ci >𝑙</ci></apply></apply><interval closure="open"  ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝐗</ci><ci >𝑡</ci></apply><apply ><ci  >𝑆</ci><ci
    >𝐺</ci><ci >𝐶</ci><ci >𝑁</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐗</ci><ci >𝑡</ci></apply></apply></interval><ci >𝑆</ci></apply></apply><apply
    ><apply ><ci  >𝝈</ci><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑊</ci><cn type="integer" >1</cn></apply><ci >𝑹</ci><ci  >𝒆</ci><ci >𝑳</ci><ci
    >𝑼</ci><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑊</ci><cn
    type="integer"  >2</cn></apply><ci >𝑧</ci></apply></apply><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝐇</ci><ci >𝑡</ci></apply></apply></apply><apply ><apply  ><ci
    >𝑅</ci><ci >𝑁</ci><ci  >𝑁</ci><apply ><csymbol cd="latexml" >direct-product</csymbol><interval
    closure="closed"  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐇</ci><apply
    ><ci >𝑡</ci><cn type="integer" >1</cn></apply></apply><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝐗</ci><ci >𝑡</ci></apply></interval><ci >𝑆</ci></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}z&=F_{pool}(\mathbf{X}_{t},SGCN(\mathbf{X}_{t}))\\
    S&=\boldsymbol{\sigma}(W_{1}\boldsymbol{ReLU}(W_{2}z))\\ \mathbf{H}_{t}&=RNN([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{\odot}S)\\
    \end{split}</annotation></semantics></math> |  | (11) |
- en: where $F_{pool}(\boldsymbol{\cdot})$ is a global average pooling layer, $RNN(\boldsymbol{\cdot})$
    denotes the RNN hidden layer.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $F_{pool}(\boldsymbol{\cdot})$ 是一个全局平均池化层，$RNN(\boldsymbol{\cdot})$ 表示 RNN
    隐藏层。
- en: 'Chen et al. [[112](#bib.bib112)] took external factors into consideration by
    embedding external attributes into the input. In addition, they added the previous
    hidden states to the next hidden states through a residual shortcut path, which
    they believed can make GRU more sensitive and robust to sudden changes in traffic
    historical observations. The new hidden state is formulated as: $\mathbf{H}_{t}=GRU([\mathbf{H}_{t-1},\mathbf{X}_{t}],\mathbf{E}_{t})+\mathbf{H}_{t-1}W$,
    where $\mathbf{E}_{t}$ is the external features at time $t$, $W$ is a linear trainable
    parameter, $\mathbf{H}_{t-1}W$ is the residual shortcut.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 陈等人 [[112](#bib.bib112)] 通过将外部属性嵌入输入中来考虑外部因素。此外，他们通过一个残差快捷路径将前一个隐藏状态添加到下一个隐藏状态中，他们认为这可以使
    GRU 对交通历史观测中的突发变化更加敏感和稳健。新的隐藏状态被表述为：$\mathbf{H}_{t}=GRU([\mathbf{H}_{t-1},\mathbf{X}_{t}],\mathbf{E}_{t})+\mathbf{H}_{t-1}W$，其中
    $\mathbf{E}_{t}$ 是时间 $t$ 的外部特征，$W$ 是一个线性可训练参数，$\mathbf{H}_{t-1}W$ 是残差快捷路径。
- en: Yu et al. [[105](#bib.bib105)] inserted a dilated skip connection into GRU by
    changing hidden state from $\mathbf{H}_{t}=GRU([\mathbf{H}_{t-1},\mathbf{X}_{t}])$
    to $\mathbf{H}_{t}=GRU(\mathbf{H}_{t-s},\mathbf{X}_{t})$, where $s$ refers to
    the skip length or dilation rate of each layer, $GRU(\boldsymbol{\cdot})$ denotes
    the GRU hidden layer. Such hierarchical design of dilation brings in multiple
    temporal scales for recurrent units at different layers which achieves multi-timescale
    modeling.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 于等人 [[105](#bib.bib105)] 通过将隐藏状态从 $\mathbf{H}_{t}=GRU([\mathbf{H}_{t-1},\mathbf{X}_{t}])$
    改为 $\mathbf{H}_{t}=GRU(\mathbf{H}_{t-s},\mathbf{X}_{t})$，在 GRU 中插入了一个扩张跳跃连接，其中
    $s$ 指每层的跳跃长度或扩张率，$GRU(\boldsymbol{\cdot})$ 表示 GRU 隐藏层。这种扩张的分层设计为不同层的递归单元引入了多个时间尺度，实现了多时间尺度建模。
- en: 'Despite the tricks above, some works replace the matrix multiplication in RNNs’
    hidden layer with spectral graph convolution (SGC) or diffusion graph convolution
    (DGC), to capture spatial-temporal correlations jointly. Take GRU as example:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有上述技巧，一些研究通过用谱图卷积（SGC）或扩散图卷积（DGC）替代 RNN 隐藏层中的矩阵乘法，以共同捕捉时空相关性。以 GRU 为例：
- en: '|  | <math   alttext="\begin{split}r_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{*_{\mathcal{G}}}W_{r}+b_{r})\\
    u_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{*_{\mathcal{G}}}W_{u}+b_{u})\\'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}r_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{*_{\mathcal{G}}}W_{r}+b_{r})\\
    u_{t}&amp;=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{*_{\mathcal{G}}}W_{u}+b_{u})\\'
- en: \tilde{\mathbf{H}_{t}}&amp;=\boldsymbol{tanh}(r_{t}\boldsymbol{\odot}[\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{*_{\mathcal{G}}}W_{h}+b_{h})\\
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: \tilde{\mathbf{H}_{t}}&amp;=\boldsymbol{tanh}(r_{t}\boldsymbol{\odot}[\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{*_{\mathcal{G}}}W_{h}+b_{h})\\
- en: \mathbf{H}_{t}&amp;=u_{t}\boldsymbol{\odot}\mathbf{H}_{t-1}+(1-u_{t})\boldsymbol{\odot}\tilde{\mathbf{H}_{t}}\\
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: \mathbf{H}_{t}&amp;=u_{t}\boldsymbol{\odot}\mathbf{H}_{t-1}+(1-u_{t})\boldsymbol{\odot}\tilde{\mathbf{H}_{t}}\\
- en: \end{split}" display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt"  ><mtr ><mtd columnalign="right"  ><msub ><mi mathsize="80%"
    >r</mi><mi mathsize="80%" >t</mi></msub></mtd><mtd columnalign="left"  ><mrow
    ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%"  >𝝈</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mrow ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi mathsize="80%"  >𝐇</mi><mrow
    ><mi mathsize="80%" >t</mi><mo mathsize="80%"  >−</mo><mn mathsize="80%"  >1</mn></mrow></msub><mo
    mathsize="80%"  >,</mo><msub ><mi mathsize="80%"  >𝐗</mi><mi mathsize="80%"  >t</mi></msub><mo
    maxsize="80%" minsize="80%" rspace="0.055em" >]</mo></mrow><msub ><mo  mathsize="80%"
    mathvariant="bold" rspace="0.222em"  >∗</mo><mi mathsize="80%" >𝓖</mi></msub><msub
    ><mi mathsize="80%" >W</mi><mi mathsize="80%" >r</mi></msub></mrow><mo mathsize="80%"
    >+</mo><msub ><mi mathsize="80%" >b</mi><mi mathsize="80%"  >r</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><msub ><mi mathsize="80%" >u</mi><mi mathsize="80%" >t</mi></msub></mtd><mtd
    columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%"
    >𝝈</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow
    ><mrow ><mrow ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi mathsize="80%"
    >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%" >−</mo><mn mathsize="80%"
    >1</mn></mrow></msub><mo mathsize="80%" >,</mo><msub ><mi mathsize="80%" >𝐗</mi><mi
    mathsize="80%" >t</mi></msub><mo maxsize="80%" minsize="80%" rspace="0.055em"  >]</mo></mrow><msub
    ><mo mathsize="80%" mathvariant="bold" rspace="0.222em" >∗</mo><mi mathsize="80%"
    >𝓖</mi></msub><msub ><mi mathsize="80%" >W</mi><mi mathsize="80%" >u</mi></msub></mrow><mo
    mathsize="80%" >+</mo><msub ><mi mathsize="80%" >b</mi><mi mathsize="80%"  >u</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><mover accent="true"  ><msub ><mi mathsize="80%" >𝐇</mi><mi
    mathsize="80%"  >t</mi></msub><mo mathsize="80%"  >~</mo></mover></mtd><mtd columnalign="left"  ><mrow
    ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%" >𝒕</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >𝒂</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒏</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒉</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mrow ><msub ><mi mathsize="80%" >r</mi><mi mathsize="80%" >t</mi></msub><mo
    lspace="0.222em" mathsize="80%" mathvariant="bold" rspace="0.222em" >⊙</mo><mrow
    ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi mathsize="80%" >𝐇</mi><mrow
    ><mi mathsize="80%" >t</mi><mo mathsize="80%" >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo
    mathsize="80%" >,</mo><msub ><mi mathsize="80%" >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo
    maxsize="80%" minsize="80%" rspace="0.055em"  >]</mo></mrow></mrow><msub ><mo
    mathsize="80%" mathvariant="bold" rspace="0.222em" >∗</mo><mi mathsize="80%" >𝓖</mi></msub><msub
    ><mi mathsize="80%" >W</mi><mi mathsize="80%" >h</mi></msub></mrow><mo mathsize="80%"
    >+</mo><msub ><mi mathsize="80%" >b</mi><mi mathsize="80%"  >h</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><msub ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%" >t</mi></msub></mtd><mtd
    columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><mrow ><msub  ><mi
    mathsize="80%"  >u</mi><mi mathsize="80%"  >t</mi></msub><mo lspace="0.222em"
    mathsize="80%" mathvariant="bold" rspace="0.222em"  >⊙</mo><msub ><mi mathsize="80%"
    >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%"  >−</mo><mn mathsize="80%"  >1</mn></mrow></msub></mrow><mo
    mathsize="80%"  >+</mo><mrow ><mrow ><mo maxsize="80%" minsize="80%" >(</mo><mrow
    ><mn mathsize="80%" >1</mn><mo mathsize="80%" >−</mo><msub ><mi mathsize="80%"
    >u</mi><mi mathsize="80%" >t</mi></msub></mrow><mo maxsize="80%" minsize="80%"
    rspace="0.055em"  >)</mo></mrow><mo mathsize="80%" mathvariant="bold" rspace="0.222em"
    >⊙</mo><mover accent="true"  ><msub ><mi mathsize="80%"  >𝐇</mi><mi mathsize="80%"  >t</mi></msub><mo
    mathsize="80%"  >~</mo></mover></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑟</ci><ci >𝑡</ci></apply><apply ><ci  >𝝈</ci><apply ><apply ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci >𝓖</ci></apply><interval closure="closed"  ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><apply ><ci  >𝑡</ci><cn
    type="integer"  >1</cn></apply></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝐗</ci><ci >𝑡</ci></apply></interval><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑊</ci><ci >𝑟</ci></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑏</ci><ci >𝑟</ci></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑢</ci><ci >𝑡</ci></apply></apply></apply><apply ><apply  ><ci >𝝈</ci><apply ><apply
    ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝓖</ci></apply><interval
    closure="closed"  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><apply
    ><ci >𝑡</ci><cn type="integer" >1</cn></apply></apply><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝐗</ci><ci >𝑡</ci></apply></interval><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝑊</ci><ci >𝑢</ci></apply></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑏</ci><ci >𝑢</ci></apply></apply><apply
    ><ci  >~</ci><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><ci
    >𝑡</ci></apply></apply></apply></apply><apply ><apply ><ci  >𝒕</ci><ci >𝒂</ci><ci
    >𝒏</ci><ci  >𝒉</ci><apply ><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝓖</ci></apply><apply ><csymbol cd="latexml" >direct-product</csymbol><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝑟</ci><ci >𝑡</ci></apply><interval closure="closed"
    ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐇</ci><apply ><ci >𝑡</ci><cn
    type="integer" >1</cn></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐗</ci><ci >𝑡</ci></apply></interval></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑊</ci><ci >ℎ</ci></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑏</ci><ci >ℎ</ci></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐇</ci><ci >𝑡</ci></apply></apply></apply><apply ><apply  ><apply ><csymbol cd="latexml"
    >direct-product</csymbol><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑢</ci><ci >𝑡</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐇</ci><apply ><ci  >𝑡</ci><cn type="integer"  >1</cn></apply></apply></apply><apply
    ><csymbol cd="latexml" >direct-product</csymbol><apply ><cn type="integer" >1</cn><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑢</ci><ci >𝑡</ci></apply></apply><apply
    ><ci >~</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐇</ci><ci
    >𝑡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}r_{t}&=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{*_{\mathcal{G}}}W_{r}+b_{r})\\
    u_{t}&=\boldsymbol{\sigma}([\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{*_{\mathcal{G}}}W_{u}+b_{u})\\
    \tilde{\mathbf{H}_{t}}&=\boldsymbol{tanh}(r_{t}\boldsymbol{\odot}[\mathbf{H}_{t-1},\mathbf{X}_{t}]\boldsymbol{*_{\mathcal{G}}}W_{h}+b_{h})\\
    \mathbf{H}_{t}&=u_{t}\boldsymbol{\odot}\mathbf{H}_{t-1}+(1-u_{t})\boldsymbol{\odot}\tilde{\mathbf{H}_{t}}\\
    \end{split}</annotation></semantics></math> |  | (12) |
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: \end{split}" display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt"  ><mtr ><mtd columnalign="right"  ><msub ><mi mathsize="80%"
    >r</mi><mi mathsize="80%" >t</mi></msub></mtd><mtd columnalign="left"  ><mrow
    ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%"  >𝝈</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mrow ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi mathsize="80%"  >𝐇</mi><mrow
    ><mi mathsize="80%" >t</mi><mo mathsize="80%"  >−</mo><mn mathsize="80%"  >1</mn></mrow></msub><mo
    mathsize="80%"  >,</mo><msub ><mi mathsize="80%"  >𝐗</mi><mi mathsize="80%"  >t</mi></msub><mo
    maxsize="80%" minsize="80%" rspace="0.055em" >]</mo></mrow><msub ><mo  mathsize="80%"
    mathvariant="bold" rspace="0.222em"  >∗</mo><mi mathsize="80%" >𝓖</mi></msub><msub
    ><mi mathsize="80%" >W</mi><mi mathsize="80%" >r</mi></msub></mrow><mo mathsize="80%"
    >+</mo><msub ><mi mathsize="80%" >b</mi><mi mathsize="80%"  >r</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><msub ><mi mathsize="80%" >u</mi><mi mathsize="80%" >t</mi></msub></mtd><mtd
    columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%"
    >𝝈</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow
    ><mrow ><mrow ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi mathsize="80%"
    >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%" >−</mo><mn mathsize="80%"
    >1</mn></mrow></msub><mo mathsize="80%" >,</mo><msub ><mi mathsize="80%" >𝐗</mi><mi
    mathsize="80%" >t</mi></msub><mo maxsize="80%" minsize="80%" rspace="0.055em"  >]</mo></mrow><msub
    ><mo mathsize="80%" mathvariant="bold" rspace="0.222em" >∗</mo><mi mathsize="80%"
    >𝓖</mi></msub><msub ><mi mathsize="80%" >W</mi><mi mathsize="80%" >u</mi></msub></mrow><mo
    mathsize="80%" >+</mo><msub ><mi mathsize="80%" >b</mi><mi mathsize="80%"  >u</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><mover accent="true"  ><msub ><mi mathsize="80%" >𝐇</mi><mi
    mathsize="80%"  >t</mi></msub><mo mathsize="80%"  >~</mo></mover></mtd><mtd columnalign="left"  ><mrow
    ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%" >𝒕</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >𝒂</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒏</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >𝒉</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mrow ><msub ><mi mathsize="80%" >r</mi><mi mathsize="80%" >t</mi></msub><mo
    lspace="0.222em" mathsize="80%" mathvariant="bold" rspace="0.222em" >⊙</mo><mrow
    ><mo maxsize="80%" minsize="80%" >[</mo><msub ><mi mathsize="80%" >𝐇</mi><mrow
    ><mi mathsize="80%" >t</mi><mo mathsize="80%" >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo
    mathsize="80%" >,</mo><msub ><mi mathsize="80%" >𝐗</mi><mi mathsize="80%" >t</mi></msub><mo
    maxsize="80%" minsize="80%" rspace="0.055em"  >]</mo></mrow></mrow><msub ><mo
    mathsize="80%" mathvariant="bold" rspace="0.222em" >∗</mo><mi mathsize="80%" >𝓖</mi></msub><msub
    ><mi mathsize="80%" >W</mi><mi mathsize="80%" >h</mi></msub></mrow><mo mathsize="80%"
    >+</mo><msub ><mi mathsize="80%" >b</mi><mi mathsize="80%"  >h</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="right"  ><msub ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%" >t</mi></msub></mtd><mtd
    columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><mrow ><msub  ><mi
    mathsize="80%"  >u</mi><mi mathsize="80%"  >t</mi></msub><mo lspace="0.222em"
    mathsize="80%" mathvariant="bold" rspace="0.222em"  >⊙</mo><msub ><mi mathsize="80%"
    >𝐇</mi><mrow ><mi mathsize="80%" >t</mi><mo mathsize="80%"  >−</mo><mn mathsize="80%"  >1</mn></mrow></msub></mrow><mo
    mathsize="80%"  >+</mo><mrow ><mrow ><mo maxsize="80%" minsize="80%" >(</mo><mrow
    ><mn mathsize="80%" >1</mn><mo mathsize="80%" >−</mo><msub ><mi mathsize="80%"
    >u</mi><mi mathsize="80%" >t</mi></msub></mrow><mo maxsize="80%" minsize="80%"
    rspace="0.055em"  >)</mo></mrow><mo mathsize="80%" mathvariant="bold" rspace="0.222em"
    >⊙</mo><mover accent="true"  ><msub ><mi mathsize="80%"  >𝐇</mi><mi mathsize="80%"  >t</mi></msub><mo
    mathsize="80%"  >~</mo></mover></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑟</ci><ci >𝑡</ci></apply><apply ><ci  >𝝈</ci><apply ><apply ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci >𝓖</ci></apply><interval closure="closed"  ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><apply ><ci  >𝑡</ci><cn
    type="integer"  >1</cn></apply></apply><apply ><csymbol
- en: The $\boldsymbol{*_{\mathcal{G}}}$ can represent SGC, DGC or other convolution
    operations. In the literatures we survey, most replacements happen in GRU and
    only one in LSTM [[66](#bib.bib66)]. Among GRU related traffic works, [[112](#bib.bib112)],
    [[108](#bib.bib108)], [[106](#bib.bib106)], [[96](#bib.bib96)],[[118](#bib.bib118)]
    replaced matrix multiplication with DGC, [[42](#bib.bib42)], [[105](#bib.bib105)],
    [[77](#bib.bib77)] with SGC, [[104](#bib.bib104)], [[119](#bib.bib119)] with GAT.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: $\boldsymbol{*_{\mathcal{G}}}$ 可以表示SGC、DGC或其他卷积操作。在我们调查的文献中，大多数替换发生在GRU中，只有一个发生在LSTM中[[66](#bib.bib66)]。在与GRU相关的交通工作中，[[112](#bib.bib112)]、[[108](#bib.bib108)]、[[106](#bib.bib106)]、[[96](#bib.bib96)]、[[118](#bib.bib118)]用DGC替代了矩阵乘法，[[42](#bib.bib42)]、[[105](#bib.bib105)]、[[77](#bib.bib77)]用SGC替代了矩阵乘法，[[104](#bib.bib104)]、[[119](#bib.bib119)]用GAT替代了矩阵乘法。
- en: Note that besides RNNs, other techniques (e.g. TCN in the next subsection) are
    also popular choices to extract the temporal dynamics in traffic tasks.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，除了RNN之外，其他技术（例如下一小节中的TCN）也是提取交通任务时间动态的热门选择。
- en: V-C TCN
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-C TCN
- en: Although RNN-based models become widespread in time-series analysis, RNNs for
    traffic prediction still suffer from time-consuming iteration, complex gate mechanism,
    and slow response to dynamic changes [[92](#bib.bib92)]. On the contrary, 1D-CNN
    has the superiority of fast training, simple structure, and no constraints to
    previous steps [[140](#bib.bib140)]. However, 1D-CNN is less common than RNNs
    in practice due to its lack of memory for a long sequence [[141](#bib.bib141)].
    In 2016, a novel convolution operation integrating causal convolution and dilated
    convolution [[142](#bib.bib142)] is proposed, which outperforms RNNs in text-to-speech
    tasks. The prediction of causal convolution depends on previous elements but not
    on future elements. Dilated convolution expands the receptive field of original
    filter by dilating it with zeros [[143](#bib.bib143)]. Bai et al. [[144](#bib.bib144)]
    simplified the causal dilated convolution [[142](#bib.bib142)] for sequence modeling
    problem and renamed it as temporal convolution network (TCN). Recently, more and
    more works employ TCN to process traffic data [[92](#bib.bib92)], [[70](#bib.bib70)],
    [[102](#bib.bib102)], [[111](#bib.bib111)].
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于RNN的模型在时间序列分析中变得广泛，但用于交通预测的RNN仍然面临着耗时的迭代、复杂的门控机制以及对动态变化响应缓慢的问题[[92](#bib.bib92)]。相反，1D-CNN具有快速训练、结构简单以及没有对前一步骤的约束等优点[[140](#bib.bib140)]。然而，由于缺乏对长序列的记忆，1D-CNN在实践中不如RNN常见[[141](#bib.bib141)]。2016年，提出了一种将因果卷积和膨胀卷积相结合的新型卷积操作[[142](#bib.bib142)]，在文本到语音任务中优于RNN。因果卷积的预测依赖于先前的元素，而不依赖于未来的元素。膨胀卷积通过用零扩展原始滤波器的感受野[[143](#bib.bib143)]。Bai等人[[144](#bib.bib144)]简化了因果膨胀卷积[[142](#bib.bib142)]以解决序列建模问题，并将其重新命名为时间卷积网络（TCN）。最近，越来越多的工作使用TCN处理交通数据[[92](#bib.bib92)]、[[70](#bib.bib70)]、[[102](#bib.bib102)]、[[111](#bib.bib111)]。
- en: V-C1 Sequence Modeling and 1-D TCN
  id: totrans-319
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-C1 序列建模与1-D TCN
- en: Given an input sequence with length $\mathbf{P}$ denoted as $\mathbf{x}=[\mathbf{x}_{1},\cdots,\mathbf{x}_{\mathbf{P}}]\in\mathbb{R}^{\mathbf{P}}$,
    sequence modeling aims to generate an output sequence with the same length, denoted
    as $\mathbf{y}=[\mathbf{y}_{1},\cdots,\mathbf{y}_{\mathbf{P}}]\in\mathbb{R}^{\mathbf{P}}$.
    The key assumption is that the output at current time $\mathbf{y}_{t}$ only depends
    on historical data $[\mathbf{x}_{1},\cdots,\mathbf{x}_{t}]$ but does not depend
    on any future inputs $[\mathbf{x}_{t+1},\cdots,\mathbf{x}_{\mathbf{P}}]$, i.e.
    $\mathbf{y}_{t}=f(\mathbf{x}_{1},\cdots,\mathbf{x}_{t})$, $f$ is the mapping function.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个长度为$\mathbf{P}$的输入序列，表示为$\mathbf{x}=[\mathbf{x}_{1},\cdots,\mathbf{x}_{\mathbf{P}}]\in\mathbb{R}^{\mathbf{P}}$，序列建模的目标是生成一个长度相同的输出序列，表示为$\mathbf{y}=[\mathbf{y}_{1},\cdots,\mathbf{y}_{\mathbf{P}}]\in\mathbb{R}^{\mathbf{P}}$。关键假设是当前时间的输出$\mathbf{y}_{t}$仅依赖于历史数据$[\mathbf{x}_{1},\cdots,\mathbf{x}_{t}]$，而不依赖于任何未来的输入$[\mathbf{x}_{t+1},\cdots,\mathbf{x}_{\mathbf{P}}]$，即$\mathbf{y}_{t}=f(\mathbf{x}_{1},\cdots,\mathbf{x}_{t})$，$f$是映射函数。
- en: 'Obviously, RNN, LSTM and GRU can be solutions to sequence modeling tasks. However,
    TCN can tackle sequence modeling problem more efficiently than RNNs for that it
    can capture long sequence properly in a non-recursive manner. The dilated causal
    convolution in TCN is formulated as follows:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，RNN、LSTM和GRU可以解决序列建模任务。然而，TCN可以比RNN更高效地处理序列建模问题，因为它可以以非递归的方式有效捕捉长序列。TCN中的膨胀因果卷积公式如下：
- en: '|  | $\mathbf{y}_{t}=\Theta*_{\mathcal{T}^{\mathbf{d}}}\mathbf{x}_{t}=\sum_{k=0}^{\mathbf{K}-1}w_{k}\mathbf{x}_{t-\mathbf{d}k}$
    |  | (13) |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{y}_{t}=\Theta*_{\mathcal{T}^{\mathbf{d}}}\mathbf{x}_{t}=\sum_{k=0}^{\mathbf{K}-1}w_{k}\mathbf{x}_{t-\mathbf{d}k}$
    |  | (13) |'
- en: 'where $*_{\mathcal{T}^{\mathbf{d}}}$ is the dilated causal operator with dilation
    rate $\mathbf{d}$ controlling the skipping distance, $\Theta=[w_{0},\cdots,w_{\mathbf{K-1}}]\in\mathbb{R}^{\mathbf{K}}$
    is the kernel. Zero padding strategy is utilized to keep the output length the
    same as the input length (as shown in Figure [8](#S5.F8 "Figure 8 ‣ V-C1 Sequence
    Modeling and 1-D TCN ‣ V-C TCN ‣ V Deep Learning Techniques Perspective ‣ How
    to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey")).
    Without padding, the output length is shortened by $(\mathbf{K}-1)\mathbf{d}$
    [[92](#bib.bib92)].'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $*_{\mathcal{T}^{\mathbf{d}}}$ 是膨胀因果算子，膨胀率 $\mathbf{d}$ 控制跳跃距离，$\Theta=[w_{0},\cdots,w_{\mathbf{K-1}}]\in\mathbb{R}^{\mathbf{K}}$
    是卷积核。利用零填充策略使得输出长度与输入长度相同（如图 [8](#S5.F8 "图 8 ‣ V-C1 序列建模和 1-D TCN ‣ V-C TCN ‣
    V 深度学习技术视角 ‣ 如何在交通领域构建基于图的深度学习架构：一项综述") 所示）。如果不进行填充，输出长度将缩短 $(\mathbf{K}-1)\mathbf{d}$
    [[92](#bib.bib92)]。
- en: '![Refer to caption](img/bedaffa3c763518bfcbf7854cc55384f.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/bedaffa3c763518bfcbf7854cc55384f.png)'
- en: 'Figure 8: Multiple dilated causal convolution layers in TCN: $[\mathbf{x}_{1},\mathbf{x}_{2},\mathbf{x}_{3}]$
    is the input sequence and $[\mathbf{y}_{1},\mathbf{y}_{2},\mathbf{y}_{3}]$ is
    the output sequence with the same length. The size of kernel is $2$ and the dilation
    rate sequence is $[1,2,4]$. Zero padding strategy is taken.'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：TCN 中的多个膨胀因果卷积层：$[\mathbf{x}_{1},\mathbf{x}_{2},\mathbf{x}_{3}]$ 是输入序列，$[\mathbf{y}_{1},\mathbf{y}_{2},\mathbf{y}_{3}]$
    是具有相同长度的输出序列。卷积核的大小为 $2$，膨胀率序列为 $[1,2,4]$。采用了零填充策略。
- en: 'To enlarge the receptive field, TCN stacks multiple dilated causal convolution
    layers with $\mathbf{d}=2^{l}$ as the dilation rate of $l^{th}$ layer (as shown
    in Figure [8](#S5.F8 "Figure 8 ‣ V-C1 Sequence Modeling and 1-D TCN ‣ V-C TCN
    ‣ V Deep Learning Techniques Perspective ‣ How to Build a Graph-Based Deep Learning
    Architecture in Traffic Domain: A Survey")). Therefore, the receptive field in
    the network grows exponentially without requiring many convolutional layers or
    larger filter, which can handle longer sequence with less layers and save computation
    resources [[102](#bib.bib102)].'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 为了扩大感受野，TCN 堆叠了多个膨胀的因果卷积层，其中第 $l^{th}$ 层的膨胀率为 $\mathbf{d}=2^{l}$（如图 [8](#S5.F8
    "图 8 ‣ V-C1 序列建模和 1-D TCN ‣ V-C TCN ‣ V 深度学习技术视角 ‣ 如何在交通领域构建基于图的深度学习架构：一项综述")
    所示）。因此，网络中的感受野呈指数增长，无需大量卷积层或更大的滤波器，这样可以用更少的层处理更长的序列，并节省计算资源 [[102](#bib.bib102)]。
- en: V-C2 TCN in Traffic Domain
  id: totrans-327
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-C2 TCN 在交通领域
- en: There are many traffic works related with sequence modeling, especially traffic
    spatial-temporal forecasting tasks. Compared with RNNs, the non-recursive calculation
    manner enables TCN to alleviate the gradient explosion problem and facilitate
    the training by parallel computation. Therefore, some works adopt TCN to capture
    the temporal dependency in traffic data.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多与序列建模相关的交通研究，特别是交通时空预测任务。与 RNNs 相比，无递归计算方式使得 TCN 能够缓解梯度爆炸问题，并通过并行计算促进训练。因此，一些研究采用
    TCN 来捕捉交通数据中的时间依赖性。
- en: 'Most graph-based traffic data is 3-D signal denoted as $\mathcal{X}\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{I}}}$,
    which requires the generalization of 1-D TCN to 3-D TCN. The dilated causal convolution
    can be adopted to produce the $j^{th}$ output feature of node $i$ at time $t$
    as follows [[70](#bib.bib70)]:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数基于图的交通数据是 3-D 信号，记作 $\mathcal{X}\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{I}}}$，这需要将
    1-D TCN 泛化到 3-D TCN。可以采用膨胀因果卷积来生成节点 $i$ 在时间 $t$ 的第 $j^{th}$ 输出特征，如下所示 [[70](#bib.bib70)]：
- en: '|  | $\begin{split}\mathcal{Y}_{t,j}^{i}&amp;=\boldsymbol{\rho}(\Theta_{j}*_{\mathcal{T}^{\mathbf{d}}}\mathcal{X}_{t}^{i})=\boldsymbol{\rho}(\sum_{m=1}^{\mathbf{F_{I}}}\sum_{k=0}^{\mathbf{K}-1}w_{j,m,k}\mathcal{X}_{t-\mathbf{d}k,m}^{i})\end{split}$
    |  | (14) |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\mathcal{Y}_{t,j}^{i}&amp;=\boldsymbol{\rho}(\Theta_{j}*_{\mathcal{T}^{\mathbf{d}}}\mathcal{X}_{t}^{i})=\boldsymbol{\rho}(\sum_{m=1}^{\mathbf{F_{I}}}\sum_{k=0}^{\mathbf{K}-1}w_{j,m,k}\mathcal{X}_{t-\mathbf{d}k,m}^{i})\end{split}$
    |  | (14) |'
- en: where $1\leq j\leq\mathbf{F_{O}}$, $\mathcal{Y}_{t,j}^{i}\in\mathbb{R}$ is the
    $j^{th}$ output feature of node $i$ at time $t$. $\mathcal{X}_{t-\mathbf{d}k,m}^{i}\in\mathbb{R}$
    is the $m^{th}$ input feature of node $i$ at time $t-\mathbf{d}k$. The kernel
    $\Theta_{j}\in\mathbb{R}^{\mathbf{K}\times\mathbf{F_{I}}}$ is trainable. $\mathbf{F_{O}}$
    is the number of output features.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $1\leq j\leq\mathbf{F_{O}}$，$\mathcal{Y}_{t,j}^{i}\in\mathbb{R}$ 是节点 $i$
    在时间 $t$ 的第 $j^{th}$ 输出特征。$\mathcal{X}_{t-\mathbf{d}k,m}^{i}\in\mathbb{R}$ 是节点
    $i$ 在时间 $t-\mathbf{d}k$ 的第 $m^{th}$ 输入特征。卷积核 $\Theta_{j}\in\mathbb{R}^{\mathbf{K}\times\mathbf{F_{I}}}$
    是可训练的。$\mathbf{F_{O}}$ 是输出特征的数量。
- en: 'The same convolution kernel is applied to all nodes in the traffic network
    and each node produces $\mathbf{F_{O}}$ new features. The mathematical formulation
    of each layer is as follows [[70](#bib.bib70)],[[111](#bib.bib111)]:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的卷积核应用于交通网络中的所有节点，每个节点生成 $\mathbf{F_{O}}$ 个新特征。每一层的数学公式如下 [[70](#bib.bib70)],[[111](#bib.bib111)]：
- en: '|  | $\mathcal{Y}=\boldsymbol{\rho}(\Theta*_{\mathcal{T}^{\mathbf{d}}}\mathcal{X})$
    |  | (15) |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{Y}=\boldsymbol{\rho}(\Theta*_{\mathcal{T}^{\mathbf{d}}}\mathcal{X})$
    |  | (15) |'
- en: where $\mathcal{X}\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{I}}}$
    represents the historical observations of the whole traffic network over past
    $\mathbf{P}$ time slices, $\Theta\in\mathbb{R}^{\mathbf{K}\times\mathbf{F_{I}}\times\mathbf{F_{O}}}$
    represents the related convolution kernel, $\mathcal{Y}\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{O}}}$
    is the output of TCN layer.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{X}\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{I}}}$
    表示过去 $\mathbf{P}$ 个时间片段中整个交通网络的历史观测，$\Theta\in\mathbb{R}^{\mathbf{K}\times\mathbf{F_{I}}\times\mathbf{F_{O}}}$
    表示相关的卷积核，$\mathcal{Y}\in\mathbb{R}^{\mathbf{P}\times\mathbf{N}\times\mathbf{F_{O}}}$
    是 TC 层的输出。
- en: 'There are some tricks to enhance the performance of TCN in specific traffic
    tasks. For instance, Fang et al. [[111](#bib.bib111)] stacked multiple TCN layers
    to extract the short-term neighboring dependency by bottom layer and long-term
    temporal dependency by higher layer:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些技巧可以提升 TC 在特定交通任务中的表现。例如，Fang 等人 [[111](#bib.bib111)] 堆叠了多个 TC 层，通过底层提取短期邻近依赖性，通过高层提取长期时间依赖性：
- en: '|  | $\mathcal{Y}^{(l+1)}=\boldsymbol{\sigma}(\Theta^{l}*_{\mathcal{T}^{\mathbf{d}}}\mathcal{Y}^{(l)})$
    |  | (16) |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{Y}^{(l+1)}=\boldsymbol{\sigma}(\Theta^{l}*_{\mathcal{T}^{\mathbf{d}}}\mathcal{Y}^{(l)})$
    |  | (16) |'
- en: where $\mathcal{Y}^{(l)}$ is the input of $l^{th}$ layer, $\mathcal{Y}^{(l+1)}$
    is the output and $\mathcal{Y}^{(0)}=\mathcal{X}$. $\mathbf{d}=2^{l}$ is the dilation
    rate of $l^{th}$ layer.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{Y}^{(l)}$ 是第 $l$ 层的输入，$\mathcal{Y}^{(l+1)}$ 是输出，$\mathcal{Y}^{(0)}=\mathcal{X}$。$\mathbf{d}=2^{l}$
    是第 $l$ 层的膨胀率。
- en: 'To reduce the complexity of model training, Ge et al. [[70](#bib.bib70)] constructed
    a residual block containing two TCN layers with the same dilation rate. The block
    input was added to last TCN layer to get the block output:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少模型训练的复杂性，Ge 等人 [[70](#bib.bib70)] 构建了一个包含两个具有相同膨胀率的 TC 层的残差块。将块输入加到最后一个
    TC 层以获得块输出：
- en: '|  | $\mathcal{Y}^{(l+1)}=\mathcal{Y}^{(l)}+\boldsymbol{ReLU}(\Theta_{1}^{l}*_{\mathcal{T}^{\mathbf{d}}}(\boldsymbol{ReLU}(\Theta_{0}^{l}*_{\mathcal{T}^{\mathbf{d}}}\mathcal{Y}^{(l)})))$
    |  | (17) |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{Y}^{(l+1)}=\mathcal{Y}^{(l)}+\boldsymbol{ReLU}(\Theta_{1}^{l}*_{\mathcal{T}^{\mathbf{d}}}(\boldsymbol{ReLU}(\Theta_{0}^{l}*_{\mathcal{T}^{\mathbf{d}}}\mathcal{Y}^{(l)})))$
    |  | (17) |'
- en: where $\Theta^{l}_{1},\Theta^{l}_{2}$ are the convolution kernels of the first
    layer and the second layer respectively. $\mathcal{Y}^{(l)}$ is the input of residual
    block and $\mathcal{Y}^{(l+1)}$ is its output.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\Theta^{l}_{1},\Theta^{l}_{2}$ 分别是第一层和第二层的卷积核。$\mathcal{Y}^{(l)}$ 是残差块的输入，$\mathcal{Y}^{(l+1)}$
    是其输出。
- en: 'Wu et al. [[102](#bib.bib102)] integrated gating mechanism[[141](#bib.bib141)]
    with TCN to learn complex temporal dependency in traffic data:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: Wu 等人[[102](#bib.bib102)] 将门控机制[[141](#bib.bib141)]与 TC 结合，学习交通数据中的复杂时间依赖性：
- en: '|  | $\mathcal{Y}=\boldsymbol{\rho}_{1}(\Theta_{1}*_{\mathcal{T}^{\mathbf{d}}}\mathcal{X}+b_{1})\boldsymbol{\odot}\boldsymbol{\rho}_{2}(\Theta_{2}*_{\mathcal{T}^{\mathbf{d}}}\mathcal{X}+b_{2})$
    |  | (18) |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{Y}=\boldsymbol{\rho}_{1}(\Theta_{1}*_{\mathcal{T}^{\mathbf{d}}}\mathcal{X}+b_{1})\boldsymbol{\odot}\boldsymbol{\rho}_{2}(\Theta_{2}*_{\mathcal{T}^{\mathbf{d}}}\mathcal{X}+b_{2})$
    |  | (18) |'
- en: where $\boldsymbol{\rho}_{2}(\boldsymbol{\cdot})\in[0,1]$ determines the ratio
    of information passed to the next layer.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\boldsymbol{\rho}_{2}(\boldsymbol{\cdot})\in[0,1]$ 确定传递到下一层的信息比例。
- en: Similarly, Yu et al. [[92](#bib.bib92)] used the Gated TCN and set the dilation
    rate $\mathbf{d}=1$ without zero padding to shorten the output length as $\mathcal{Y}=(\Theta_{1}*_{\mathcal{T}^{1}}\mathcal{X})\boldsymbol{\odot}\boldsymbol{\sigma}(\Theta_{2}*_{\mathcal{T}^{1}}\mathcal{X})$.
    They argued that this can discover variances in time series traffic data.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，Yu 等人[[92](#bib.bib92)] 使用了门控 TC 并将膨胀率设置为 $\mathbf{d}=1$，没有零填充，将输出长度缩短为 $\mathcal{Y}=(\Theta_{1}*_{\mathcal{T}^{1}}\mathcal{X})\boldsymbol{\odot}\boldsymbol{\sigma}(\Theta_{2}*_{\mathcal{T}^{1}}\mathcal{X})$。他们认为这可以发现时间序列流量数据中的变化。
- en: V-D Seq2Seq
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-D Seq2Seq
- en: V-D1 Seq2Seq
  id: totrans-346
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-D1 Seq2Seq
- en: '![Refer to caption](img/d31237e6367284e901b690e15b64ae89.png)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d31237e6367284e901b690e15b64ae89.png)'
- en: 'Figure 9: Sequence to Sequence Structure without attention mechanism'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：没有注意力机制的序列到序列结构
- en: 'Sequence to Sequence (Seq2Seq) model proposed in 2014 [[145](#bib.bib145)]
    has been widely used in sequence prediction such as machine translation [[146](#bib.bib146)].
    Seq2Seq architecture consists of two components, i.e. an encoder in charge of
    converting the input sequence $\mathbf{X}$ into a fixed latent vector $\mathbf{C}$,
    and a decoder responsible for converting $\mathbf{C}$ into an output sequence
    $\mathbf{Y}$ (as shown in Figure [9](#S5.F9 "Figure 9 ‣ V-D1 Seq2Seq ‣ V-D Seq2Seq
    ‣ V Deep Learning Techniques Perspective ‣ How to Build a Graph-Based Deep Learning
    Architecture in Traffic Domain: A Survey")). Note that $\mathbf{X}$ and $\mathbf{Y}$
    can have different lengths.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 2014年提出的序列到序列（Seq2Seq）模型 [[145](#bib.bib145)] 已被广泛应用于序列预测，如机器翻译 [[146](#bib.bib146)]。Seq2Seq
    架构包含两个组件，即一个负责将输入序列 $\mathbf{X}$ 转换为固定潜在向量 $\mathbf{C}$ 的编码器和一个负责将 $\mathbf{C}$
    转换为输出序列 $\mathbf{Y}$ 的解码器（如图 [9](#S5.F9 "图 9 ‣ V-D1 Seq2Seq ‣ V-D Seq2Seq ‣ V
    深度学习技术视角 ‣ 如何构建基于图的深度学习架构在交通领域：综述") 所示）。请注意，$\mathbf{X}$ 和 $\mathbf{Y}$ 可以具有不同的长度。
- en: '|  | $\mathbf{X}\!=\![\mathbf{X}_{1}\!,\cdots,\!\mathbf{X}_{i},\cdots,\mathbf{X}_{\mathbf{P}}]\stackrel{{\scriptstyle
    Seq2Seq}}{{\longrightarrow}}\mathbf{Y}=[\mathbf{Y}_{1},\cdots,\mathbf{Y}_{j},\cdots,\mathbf{Y}_{\mathbf{Q}}]$
    |  | (19) |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{X}\!=\![\mathbf{X}_{1}\!,\cdots,\!\mathbf{X}_{i},\cdots,\mathbf{X}_{\mathbf{P}}]\stackrel{{\scriptstyle
    Seq2Seq}}{{\longrightarrow}}\mathbf{Y}=[\mathbf{Y}_{1},\cdots,\mathbf{Y}_{j},\cdots,\mathbf{Y}_{\mathbf{Q}}]$
    |  | (19) |'
- en: where $\mathbf{P}$ is the input length and $\mathbf{Q}$ is the output length.
    $\mathbf{X}_{i}$ is the input at time step $i$. $\mathbf{Y}_{j}$ is the output
    at time step $j$.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathbf{P}$ 是输入长度，$\mathbf{Q}$ 是输出长度。 $\mathbf{X}_{i}$ 是第 $i$ 步的输入。 $\mathbf{Y}_{j}$
    是第 $j$ 步的输出。
- en: 'The specific calculation of $\mathbf{Y}_{j}$ is denoted as follows:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: $\mathbf{Y}_{j}$ 的具体计算表示如下：
- en: '|  | <math   alttext="\begin{split}\mathbf{H}_{i}&amp;=Encoder(\mathbf{X}_{i},\mathbf{H}_{i-1})\\
    \mathbf{C}&amp;=\mathbf{H}_{\mathbf{P}},\mathbf{S}_{0}=\mathbf{H}_{\mathbf{P}}\\'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math alttext="\begin{split}\mathbf{H}_{i}&amp;=Encoder(\mathbf{X}_{i},\mathbf{H}_{i-1})\\
    \mathbf{C}&amp;=\mathbf{H}_{\mathbf{P}},\mathbf{S}_{0}=\mathbf{H}_{\mathbf{P}}\\'
- en: \mathbf{S}_{j}&amp;=Decoder(\mathbf{C},\mathbf{Y}_{j-1},\mathbf{S}_{j-1})\\
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: \mathbf{S}_{j}&amp;=Decoder(\mathbf{C},\mathbf{Y}_{j-1},\mathbf{S}_{j-1})\\
- en: \mathbf{Y}_{j}&amp;=\mathbf{S}_{j}W\end{split}" display="block"><semantics ><mtable
    columnspacing="0pt" displaystyle="true" rowspacing="0pt" ><mtr ><mtd  columnalign="right"
    ><msub ><mi mathsize="80%"  >𝐇</mi><mi mathsize="80%"  >i</mi></msub></mtd><mtd
    columnalign="left" ><mrow ><mo mathsize="80%"  >=</mo><mrow ><mi mathsize="80%"
    >E</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%" >n</mi><mo lspace="0em"
    rspace="0em" >​</mo><mi mathsize="80%" >c</mi><mo lspace="0em" rspace="0em" >​</mo><mi
    mathsize="80%" >o</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"
    >d</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%" >e</mi><mo lspace="0em"
    rspace="0em" >​</mo><mi mathsize="80%" >r</mi><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><msub ><mi mathsize="80%" >𝐗</mi><mi
    mathsize="80%" >i</mi></msub><mo mathsize="80%" >,</mo><msub ><mi mathsize="80%"  >𝐇</mi><mrow
    ><mi mathsize="80%"  >i</mi><mo mathsize="80%"  >−</mo><mn mathsize="80%"  >1</mn></mrow></msub><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd  columnalign="right"
    ><mi mathsize="80%"  >𝐂</mi></mtd><mtd columnalign="left" ><mrow ><mrow ><mo mathsize="80%"
    >=</mo><msub ><mi mathsize="80%"  >𝐇</mi><mi mathsize="80%"  >𝐏</mi></msub></mrow><mo
    mathsize="80%"  >,</mo><mrow ><msub ><mi mathsize="80%"  >𝐒</mi><mn mathsize="80%"  >0</mn></msub><mo
    mathsize="80%"  >=</mo><msub ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%" >𝐏</mi></msub></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><msub ><mi mathsize="80%"  >𝐒</mi><mi mathsize="80%"  >j</mi></msub></mtd><mtd
    columnalign="left" ><mrow ><mo mathsize="80%"  >=</mo><mrow ><mi mathsize="80%"
    >D</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%" >e</mi><mo lspace="0em"
    rspace="0em" >​</mo><mi mathsize="80%" >c</mi><mo lspace="0em" rspace="0em" >​</mo><mi
    mathsize="80%" >o</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"
    >d</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%" >e</mi><mo lspace="0em"
    rspace="0em" >​</mo><mi mathsize="80%" >r</mi><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><mi mathsize="80%"  >𝐂</mi><mo mathsize="80%"  >,</mo><msub
    ><mi mathsize="80%" >𝐘</mi><mrow ><mi mathsize="80%" >j</mi><mo mathsize="80%"
    >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo mathsize="80%" >,</mo><msub
    ><mi mathsize="80%"  >𝐒</mi><mrow ><mi mathsize="80%"  >j</mi><mo mathsize="80%"  >−</mo><mn
    mathsize="80%"  >1</mn></mrow></msub><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><msub ><mi mathsize="80%"  >𝐘</mi><mi mathsize="80%"  >j</mi></msub></mtd><mtd
    columnalign="left" ><mrow ><mo mathsize="80%"  >=</mo><mrow ><msub ><mi mathsize="80%"
    >𝐒</mi><mi mathsize="80%" >j</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >W</mi></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content"
    ><apply ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply ><apply  ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><ci >𝑖</ci></apply><apply
    ><ci  >𝐸</ci><ci >𝑛</ci><ci >𝑐</ci><ci  >𝑜</ci><ci >𝑑</ci><ci >𝑒</ci><ci  >𝑟</ci><interval
    closure="open"  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐗</ci><ci
    >𝑖</ci></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><apply
    ><ci >𝑖</ci><cn type="integer"  >1</cn></apply></apply></interval><ci >𝐂</ci></apply></apply><apply
    ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐇</ci><ci >𝐏</ci></apply></apply></apply><apply
    ><apply  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐒</ci><cn
    type="integer" >0</cn></apply><apply ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝐇</ci><ci >𝐏</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐒</ci><ci >𝑗</ci></apply></apply></apply><apply ><apply ><ci  >𝐷</ci><ci >𝑒</ci><ci
    >𝑐</ci><ci  >𝑜</ci><ci >𝑑</ci><ci >𝑒</ci><ci >𝑟</ci><vector ><ci >𝐂</ci><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐘</ci><apply ><ci >𝑗</ci><cn
    type="integer" >1</cn></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐒</ci><apply ><ci >𝑗</ci><cn type="integer" >1</cn></apply></apply></vector><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐘</ci><ci >𝑗</ci></apply></apply></apply><apply
    ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐒</ci><ci >𝑗</ci></apply><ci
    >𝑊</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >\begin{split}\mathbf{H}_{i}&=Encoder(\mathbf{X}_{i},\mathbf{H}_{i-1})\\ \mathbf{C}&=\mathbf{H}_{\mathbf{P}},\mathbf{S}_{0}=\mathbf{H}_{\mathbf{P}}\\
    \mathbf{S}_{j}&=Decoder(\mathbf{C},\mathbf{Y}_{j-1},\mathbf{S}_{j-1})\\ \mathbf{Y}_{j}&=\mathbf{S}_{j}W\end{split}</annotation></semantics></math>
    |  | (20) |
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: \mathbf{H}_{i}&=编码器(\mathbf{X}_{i},\mathbf{H}_{i-1})\\ \mathbf{C}&=\mathbf{H}_{\mathbf{P}},\mathbf{S}_{0}=\mathbf{H}_{\mathbf{P}}\\
    \mathbf{S}_{j}&=解码器(\mathbf{C},\mathbf{Y}_{j-1},\mathbf{S}_{j-1})\\ \mathbf{Y}_{j}&=\mathbf{S}_{j}W\end{split}
- en: here, $\mathbf{H}_{i}$ is the hidden state of encoder. $\mathbf{H}_{0}$ is initialized
    using small non-zero elements. $\mathbf{S}_{j}$ is the decoder hidden state. $\mathbf{Y}_{0}$
    is the representation of beginning sign. Note that the encoder and decoder can
    be any model as long as it can accept sequence and produce sequence, such as RNN,
    LSTM, GRU or other novel models.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\mathbf{H}_{i}$ 是编码器的隐藏状态。$\mathbf{H}_{0}$ 使用小的非零元素进行初始化。$\mathbf{S}_{j}$
    是解码器的隐藏状态。$\mathbf{Y}_{0}$ 是开始符号的表示。注意，编码器和解码器可以是任何模型，只要它能接受序列并生成序列，如 RNN、LSTM、GRU
    或其他新型模型。
- en: A major limitation of Seq2Seq is that the latent vector $\mathbf{C}$ is fixed
    for each $\mathbf{Y}_{j}$ while $\mathbf{Y}_{j}$ might have stronger correlation
    with $\mathbf{X}_{j}$ than other elements. To address this issue, attention mechanism
    is integrated into Seq2Seq, allowing the decoder to focus on task-relevant parts
    of the input sequence, helping the decoder make better prediction.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: Seq2Seq 的一个主要限制是潜在向量 $\mathbf{C}$ 对每个 $\mathbf{Y}_{j}$ 是固定的，而 $\mathbf{Y}_{j}$
    可能与 $\mathbf{X}_{j}$ 的相关性比其他元素更强。为了解决这个问题，注意力机制被集成到 Seq2Seq 中，使解码器能够关注输入序列中的任务相关部分，帮助解码器做出更好的预测。
- en: '|  | <math   alttext="\begin{split}\mathbf{H}_{i}&amp;=Encoder(\mathbf{X}_{i},\mathbf{H}_{i-1})\\
    \mathbf{C}_{j}&amp;=\sum_{i=1}^{\mathbf{P}}(\theta_{ji}\mathbf{H}_{i}),\mathbf{S}_{0}=\mathbf{H}_{\mathbf{P}}\\'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}\mathbf{H}_{i}&amp;=Encoder(\mathbf{X}_{i},\mathbf{H}_{i-1})\\
    \mathbf{C}_{j}&amp;=\sum_{i=1}^{\mathbf{P}}(\theta_{ji}\mathbf{H}_{i}),\mathbf{S}_{0}=\mathbf{H}_{\mathbf{P}}\\'
- en: \mathbf{S}_{j}&amp;=Decoder(\mathbf{C}_{j},\mathbf{Y}_{j-1},\mathbf{S}_{j-1})\\
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: \mathbf{S}_{j}&amp;=Decoder(\mathbf{C}_{j},\mathbf{Y}_{j-1},\mathbf{S}_{j-1})\\
- en: \mathbf{Y}_{j}&amp;=\mathbf{S}_{j}W\\
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: \mathbf{Y}_{j}&amp;=\mathbf{S}_{j}W\\
- en: \end{split}" display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt" ><mtr ><mtd columnalign="right" ><msub ><mi mathsize="80%"  >𝐇</mi><mi
    mathsize="80%"  >i</mi></msub></mtd><mtd columnalign="left" ><mrow ><mo mathsize="80%"  >=</mo><mrow
    ><mi mathsize="80%" >E</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"
    >n</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%" >c</mi><mo lspace="0em"
    rspace="0em" >​</mo><mi mathsize="80%" >o</mi><mo lspace="0em" rspace="0em" >​</mo><mi
    mathsize="80%" >d</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"
    >e</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%" >r</mi><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><msub ><mi
    mathsize="80%" >𝐗</mi><mi mathsize="80%" >i</mi></msub><mo mathsize="80%" >,</mo><msub
    ><mi mathsize="80%"  >𝐇</mi><mrow ><mi mathsize="80%"  >i</mi><mo mathsize="80%"  >−</mo><mn
    mathsize="80%"  >1</mn></mrow></msub><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><msub ><mi mathsize="80%"  >𝐂</mi><mi mathsize="80%"  >j</mi></msub></mtd><mtd
    columnalign="left" ><mrow ><mrow ><mo mathsize="80%" rspace="0.111em" >=</mo><mrow
    ><munderover ><mo maxsize="80%" minsize="80%" movablelimits="false" rspace="0em"
    stretchy="true"  >∑</mo><mrow ><mi mathsize="80%" >i</mi><mo mathsize="80%"  >=</mo><mn
    mathsize="80%"  >1</mn></mrow><mi mathsize="80%"  >𝐏</mi></munderover><mrow ><mo
    maxsize="80%" minsize="80%" >(</mo><mrow ><msub ><mi mathsize="80%" >θ</mi><mrow
    ><mi mathsize="80%" >j</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"
    >i</mi></mrow></msub><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi mathsize="80%"
    >𝐇</mi><mi mathsize="80%" >i</mi></msub></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow><mo
    mathsize="80%"  >,</mo><mrow ><msub ><mi mathsize="80%"  >𝐒</mi><mn mathsize="80%"  >0</mn></msub><mo
    mathsize="80%"  >=</mo><msub ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%" >𝐏</mi></msub></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><msub ><mi mathsize="80%"  >𝐒</mi><mi mathsize="80%"  >j</mi></msub></mtd><mtd
    columnalign="left" ><mrow ><mo mathsize="80%"  >=</mo><mrow ><mi mathsize="80%"
    >D</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%" >e</mi><mo lspace="0em"
    rspace="0em" >​</mo><mi mathsize="80%" >c</mi><mo lspace="0em" rspace="0em" >​</mo><mi
    mathsize="80%" >o</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"
    >d</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%" >e</mi><mo lspace="0em"
    rspace="0em" >​</mo><mi mathsize="80%" >r</mi><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><msub ><mi mathsize="80%" >𝐂</mi><mi
    mathsize="80%" >j</mi></msub><mo mathsize="80%" >,</mo><msub ><mi mathsize="80%"  >𝐘</mi><mrow
    ><mi mathsize="80%"  >j</mi><mo mathsize="80%"  >−</mo><mn mathsize="80%"  >1</mn></mrow></msub><mo
    mathsize="80%"  >,</mo><msub ><mi mathsize="80%" >𝐒</mi><mrow ><mi mathsize="80%"
    >j</mi><mo mathsize="80%" >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo maxsize="80%"
    minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd  columnalign="right"
    ><msub ><mi mathsize="80%"  >𝐘</mi><mi mathsize="80%"  >j</mi></msub></mtd><mtd
    columnalign="left" ><mrow ><mo mathsize="80%"  >=</mo><mrow ><msub ><mi mathsize="80%"
    >𝐒</mi><mi mathsize="80%" >j</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >W</mi></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content"
    ><apply ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply ><apply  ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><ci >𝑖</ci></apply><apply
    ><ci  >𝐸</ci><ci >𝑛</ci><ci >𝑐</ci><ci  >𝑜</ci><ci >𝑑</ci><ci >𝑒</ci><ci  >𝑟</ci><interval
    closure="open"  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐗</ci><ci
    >𝑖</ci></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><apply
    ><ci >𝑖</ci><cn type="integer"  >1</cn></apply></apply></interval><apply ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci >𝐂</ci><ci >𝑗</ci></apply></apply></apply><apply
    ><apply ><apply ><csymbol cd="ambiguous" >superscript</csymbol><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><apply ><ci  >𝑖</ci><cn type="integer"  >1</cn></apply></apply><ci
    >𝐏</ci></apply><apply ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝜃</ci><apply ><ci >𝑗</ci><ci >𝑖</ci></apply></apply><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝐇</ci><ci >𝑖</ci></apply></apply></apply></apply></apply><apply
    ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐒</ci><cn type="integer"
    >0</cn></apply><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐇</ci><ci >𝐏</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐒</ci><ci >𝑗</ci></apply></apply></apply><apply ><apply ><ci  >𝐷</ci><ci >𝑒</ci><ci
    >𝑐</ci><ci  >𝑜</ci><ci >𝑑</ci><ci >𝑒</ci><ci >𝑟</ci><vector ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝐂</ci><ci >𝑗</ci></apply><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝐘</ci><apply ><ci >𝑗</ci><cn type="integer"
    >1</cn></apply></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐒</ci><apply ><ci >𝑗</ci><cn type="integer" >1</cn></apply></apply></vector><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐘</ci><ci >𝑗</ci></apply></apply></apply><apply
    ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐒</ci><ci >𝑗</ci></apply><ci
    >𝑊</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >\begin{split}\mathbf{H}_{i}&=Encoder(\mathbf{X}_{i},\mathbf{H}_{i-1})\\ \mathbf{C}_{j}&=\sum_{i=1}^{\mathbf{P}}(\theta_{ji}\mathbf{H}_{i}),\mathbf{S}_{0}=\mathbf{H}_{\mathbf{P}}\\
    \mathbf{S}_{j}&=Decoder(\mathbf{C}_{j},\mathbf{Y}_{j-1},\mathbf{S}_{j-1})\\ \mathbf{Y}_{j}&=\mathbf{S}_{j}W\\
    \end{split}</annotation></semantics></math> |  | (21) |
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: \end{split}" display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt" ><mtr ><mtd columnalign="right" ><msub ><mi mathsize="80%"  >𝐇</mi><mi
    mathsize="80%"  >i</mi></msub></mtd><mtd columnalign="left" ><mrow ><mo mathsize="80%"  >=</mo><mrow
    ><mi mathsize="80%" >E</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"
    >n</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%" >c</mi><mo lspace="0em"
    rspace="0em" >​</mo><mi mathsize="80%" >o</mi><mo lspace="0em" rspace="0em" >​</mo><mi
    mathsize="80%" >d</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"
    >e</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%" >r</mi><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><msub ><mi
    mathsize="80%" >𝐗</mi><mi mathsize="80%" >i</mi></msub><mo mathsize="80%" >,</mo><msub
    ><mi mathsize="80%"  >𝐇</mi><mrow ><mi mathsize="80%"  >i</mi><mo mathsize="80%"  >−</mo><mn
    mathsize="80%"  >1</mn></mrow></msub><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><msub ><mi mathsize="80%"  >𝐂</mi><mi mathsize="80%"  >j</mi></msub></mtd><mtd
    columnalign="left" ><mrow ><mrow ><mo mathsize="80%" rspace="0.111em" >=</mo><mrow
    ><munderover ><mo maxsize="80%" minsize="80%" movablelimits="false" rspace="0em"
    stretchy="true"  >∑</mo><mrow ><mi mathsize="80%" >i</mi><mo mathsize="80%"  >=</mo><mn
    mathsize="80%"  >1</mn></mrow><mi mathsize="80%"  >𝐏</mi></munderover><mrow ><mo
    maxsize="80%" minsize="80%" >(</mo><mrow ><msub ><mi mathsize="80%" >θ</mi><mrow
    ><mi mathsize="80%" >j</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"
    >i</mi></mrow></msub><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi mathsize="80%"
    >𝐇</mi><mi mathsize="80%" >i</mi></msub></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow><mo
    mathsize="80%"  >,</mo><mrow ><msub ><mi mathsize="80%"  >𝐒</mi><mn mathsize="80%"  >0</mn></msub><mo
    mathsize="80%"  >=</mo><msub ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%" >𝐏</mi></msub></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><msub ><mi mathsize="80%"  >𝐒</mi><mi mathsize="80%"  >j</mi></msub></mtd><mtd
    columnalign="left" ><mrow ><mo mathsize="80%"  >=</mo><mrow ><mi mathsize="80%"
    >D</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%" >e</mi><mo lspace="0em"
    rspace="0em" >​</mo><mi mathsize="80%" >c</mi><mo lspace="0em" rspace="0em" >​</mo><mi
    mathsize="80%" >o</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"
    >d</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%" >e</mi><mo lspace="0em"
    rspace="0em" >​</mo><mi mathsize="80%" >r</mi><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><msub ><mi mathsize="80%" >𝐂</mi><mi
    mathsize="80%" >j</mi></msub><mo mathsize="80%" >,</mo><msub ><mi mathsize="80%"  >𝐘</mi><mrow
    ><mi mathsize="80%"  >j</mi><mo mathsize="80%"  >−</mo><mn mathsize="80%"  >1</mn></mrow></msub><mo
    mathsize="80%"  >,</mo><msub ><mi mathsize="80%" >𝐒</mi><mrow ><mi mathsize="80%"
    >j</mi><mo mathsize="80%" >−</mo><mn mathsize="80%" >1</mn></mrow></msub><mo maxsize="80%"
    minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd  columnalign="right"
    ><msub ><mi mathsize="80%"  >𝐘</mi><mi mathsize="80%"  >j</mi></msub></mtd><mtd
    columnalign="left" ><mrow ><mo mathsize="80%"  >=</mo><mrow ><msub ><mi mathsize="80%"
    >𝐒</mi><mi mathsize="80%" >j</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >W</mi></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content"
    ><apply ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply ><apply  ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><ci >𝑖</ci></apply><apply
    ><ci  >𝐸</ci><ci >𝑛</ci><ci >𝑐</ci><ci  >𝑜</ci><ci >𝑑</ci><ci >𝑒</ci><ci  >𝑟</ci><interval
    closure="open"  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐗</ci><ci
    >𝑖</ci></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><apply
    ><ci >𝑖</ci><cn type="integer"  >1</cn></apply></apply></interval><apply ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci >𝐂</ci><ci >𝑗</ci></apply></apply></apply><apply
    ><apply ><apply ><csymbol cd="ambiguous" >superscript</csymbol><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><apply ><ci  >𝑖</ci><cn type="integer"  >1</cn></apply></apply><ci
    >𝐏</ci></apply><apply ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝜃</ci><apply ><ci >𝑗</ci><ci >𝑖</ci></apply></apply><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝐇</ci><ci >𝑖</ci></apply></apply></apply></apply></apply><apply
    ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐒</ci><cn type="integer"
    >0</cn></apply><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐇</ci><ci >𝐏</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐒</ci><ci
- en: where $\theta_{ji}=\frac{\exp(f_{ji})}{\sum_{k=1}^{\mathbf{P}}\exp(f_{jk})}$
    is the normalized attention score, and $f_{ji}=f(\mathbf{H}_{j},\mathbf{S}_{i-1})$
    [[146](#bib.bib146)] is a function to measure the correlation between $i^{th}$
    input and $j^{th}$ output, for instance, Luong et al. [[147](#bib.bib147)] proposed
    three kinds of attention score calculation.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\theta_{ji}=\frac{\exp(f_{ji})}{\sum_{k=1}^{\mathbf{P}}\exp(f_{jk})}$ 是归一化的注意力得分，$f_{ji}=f(\mathbf{H}_{j},\mathbf{S}_{i-1})$
    [[146](#bib.bib146)] 是一个用于测量第 $i^{th}$ 输入和第 $j^{th}$ 输出之间相关性的函数，例如，Luong 等人 [[147](#bib.bib147)]
    提出了三种注意力得分计算方法。
- en: '|  | <math   alttext="f_{ji}=\left\{\begin{array}[]{ll}\mathbf{H}_{j}^{T}\mathbf{S}_{i-1}&amp;\text{
    dot }\\ \mathbf{H}_{j}^{T}\boldsymbol{W}_{\boldsymbol{a}}\mathbf{S}_{i-1}&amp;\text{
    general }\\'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math alttext="f_{ji}=\left\{\begin{array}[]{ll}\mathbf{H}_{j}^{T}\mathbf{S}_{i-1}&amp;\text{
    点积 }\\ \mathbf{H}_{j}^{T}\boldsymbol{W}_{\boldsymbol{a}}\mathbf{S}_{i-1}&amp;\text{
    一般 }\\'
- en: \boldsymbol{v}_{a}^{T}\tanh\left(\boldsymbol{W}_{\boldsymbol{a}}\left[\mathbf{H}_{j},\mathbf{S}_{i-1}\right]\right)&amp;\text{
    concat }\end{array}\right." display="block"><semantics ><mrow ><msub  ><mi mathsize="80%"  >f</mi><mrow
    ><mi mathsize="80%" >j</mi><mo lspace="0em" rspace="0em" >​</mo><mi mathsize="80%"
    >i</mi></mrow></msub><mo mathsize="80%" >=</mo><mrow  ><mo >{</mo><mtable columnspacing="5pt"
    displaystyle="true" rowspacing="0pt"  ><mtr ><mtd  columnalign="left" ><mrow  ><msubsup
    ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%"  >j</mi><mi mathsize="80%"  >T</mi></msubsup><mo
    lspace="0em" rspace="0em"  >​</mo><msub ><mi mathsize="80%" >𝐒</mi><mrow ><mi
    mathsize="80%" >i</mi><mo mathsize="80%" >−</mo><mn mathsize="80%" >1</mn></mrow></msub></mrow></mtd><mtd
    columnalign="left"  ><mtext mathsize="80%" > dot </mtext></mtd></mtr><mtr ><mtd  columnalign="left"
    ><mrow  ><msubsup ><mi mathsize="80%" >𝐇</mi><mi mathsize="80%"  >j</mi><mi mathsize="80%"  >T</mi></msubsup><mo
    lspace="0em" rspace="0em"  >​</mo><msub ><mi mathsize="80%" >𝑾</mi><mi mathsize="80%"
    >𝒂</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi mathsize="80%"
    >𝐒</mi><mrow ><mi mathsize="80%" >i</mi><mo mathsize="80%" >−</mo><mn mathsize="80%"
    >1</mn></mrow></msub></mrow></mtd><mtd columnalign="left"  ><mtext mathsize="80%"
    > general </mtext></mtd></mtr><mtr ><mtd  columnalign="left" ><mrow  ><msubsup
    ><mi mathsize="80%" >𝒗</mi><mi mathsize="80%"  >a</mi><mi mathsize="80%"  >T</mi></msubsup><mo
    lspace="0.167em" rspace="0em"  >​</mo><mrow ><mi mathsize="80%" >tanh</mi><mo
    >⁡</mo><mrow ><mo  >(</mo><mrow ><msub ><mi mathsize="80%"  >𝑾</mi><mi mathsize="80%"  >𝒂</mi></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo >[</mo><msub ><mi mathsize="80%"  >𝐇</mi><mi
    mathsize="80%"  >j</mi></msub><mo mathsize="80%"  >,</mo><msub ><mi mathsize="80%"  >𝐒</mi><mrow
    ><mi mathsize="80%"  >i</mi><mo mathsize="80%"  >−</mo><mn mathsize="80%"  >1</mn></mrow></msub><mo
    >]</mo></mrow></mrow><mo >)</mo></mrow></mrow></mrow></mtd><mtd columnalign="left"  ><mtext
    mathsize="80%"  > concat </mtext></mtd></mtr></mtable></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci  >𝑓</ci><apply
    ><ci >𝑗</ci><ci  >𝑖</ci></apply></apply><apply ><csymbol cd="latexml" >cases</csymbol><matrix  ><matrixrow
    ><apply ><apply  ><csymbol cd="ambiguous"  >superscript</csymbol><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝐇</ci><ci >𝑗</ci></apply><ci >𝑇</ci></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐒</ci><apply ><ci >𝑖</ci><cn
    type="integer" >1</cn></apply></apply></apply><ci ><mtext mathsize="80%" > dot </mtext></ci></matrixrow><matrixrow
    ><apply  ><apply ><csymbol cd="ambiguous" >superscript</csymbol><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝐇</ci><ci >𝑗</ci></apply><ci >𝑇</ci></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑾</ci><ci >𝒂</ci></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐒</ci><apply ><ci  >𝑖</ci><cn
    type="integer"  >1</cn></apply></apply></apply><ci ><mtext mathsize="80%" > general </mtext></ci></matrixrow><matrixrow
    ><apply ><apply  ><csymbol cd="ambiguous"  >superscript</csymbol><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝒗</ci><ci >𝑎</ci></apply><ci >𝑇</ci></apply><apply
    ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑾</ci><ci >𝒂</ci></apply><interval
    closure="closed" ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐇</ci><ci
    >𝑗</ci></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐒</ci><apply
    ><ci >𝑖</ci><cn type="integer"  >1</cn></apply></apply></interval></apply></apply></apply><ci
    ><mtext mathsize="80%" > concat </mtext></ci></matrixrow></matrix></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >f_{ji}=\left\{\begin{array}[]{ll}\mathbf{H}_{j}^{T}\mathbf{S}_{i-1}&\text{
    dot }\\ \mathbf{H}_{j}^{T}\boldsymbol{W}_{\boldsymbol{a}}\mathbf{S}_{i-1}&\text{
    general }\\ \boldsymbol{v}_{a}^{T}\tanh\left(\boldsymbol{W}_{\boldsymbol{a}}\left[\mathbf{H}_{j},\mathbf{S}_{i-1}\right]\right)&\text{
    concat }\end{array}\right.</annotation></semantics></math> |  | (22) |
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '**f**_{ji}=\left\{\begin{array}[]{ll}\mathbf{H}_{j}^{T}\mathbf{S}_{i-1}&\text{
    点积 }\\ \mathbf{H}_{j}^{T}\boldsymbol{W}_{\boldsymbol{a}}\mathbf{S}_{i-1}&\text{
    一般形式 }\\ \boldsymbol{v}_{a}^{T}\tanh\left(\boldsymbol{W}_{\boldsymbol{a}}\left[\mathbf{H}_{j},\mathbf{S}_{i-1}\right]\right)&\text{
    连接形式 }\end{array}\right.'
- en: Another way to enhance Seq2Seq performance is the scheduled sampling technique
    [[148](#bib.bib148)]. The inputs of decoder during training and testing phases
    are different. Decoder during training phase is fed with true labels of training
    datasets while it is fed with predictions generated by itself during testing phase,
    which accumulates error at testing time and causes degraded performance. To mitigate
    this issue, scheduled sampling is integrated into the model. At $j^{th}$ iteration
    during the training process, the probability of feeding the decoder with true
    label is set as $\epsilon_{j}$ and the probability of feeding the decoder with
    prediction at the previous step is set as $1-\epsilon_{j}$. Probability $\epsilon_{j}$
    gradually decreases to 0, allowing the decoder to learn the testing distribution
    [[108](#bib.bib108)], keeping the training and testing as same as possible.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 提升 Seq2Seq 性能的另一种方法是计划采样技术[[148](#bib.bib148)]。训练和测试阶段的解码器输入不同。训练阶段的解码器输入真实标签，而测试阶段则输入自身生成的预测，这会在测试时积累误差并导致性能下降。为缓解这个问题，模型中集成了计划采样。在训练过程中第
    $j^{th}$ 次迭代时，输入解码器的真实标签的概率设置为 $\epsilon_{j}$，输入预测的概率设置为 $1-\epsilon_{j}$。概率 $\epsilon_{j}$
    会逐渐降低至 0，使解码器能够学习测试分布[[108](#bib.bib108)]，尽可能保持训练和测试的一致性。
- en: V-D2 Seq2Seq in Traffic Domain
  id: totrans-366
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-D2 Seq2Seq 在交通领域
- en: Since Seq2Seq can take in an input sequence and generate an output sequence
    with different length, it is applied on multi-step prediction in many traffic
    tasks. The encoder encodes the historical traffic data into a latent space vector.
    Then, the latent vector is fed into a decoder to generate the future traffic conditions.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Seq2Seq 可以接受不同长度的输入序列并生成不同长度的输出序列，它在许多交通任务中被应用于多步预测。编码器将历史交通数据编码成潜在空间向量，然后将潜在向量输入解码器，以生成未来的交通条件。
- en: Attention mechanism is usually incorporated into Seq2Seq to model the different
    influence on future prediction from previous traffic observations at different
    time slots [[100](#bib.bib100)],[[98](#bib.bib98)], [[110](#bib.bib110)],[[76](#bib.bib76)].
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制通常被整合进 Seq2Seq 中，以建模不同时间点的历史交通观测对未来预测的不同影响[[100](#bib.bib100)],[[98](#bib.bib98)],
    [[110](#bib.bib110)],[[76](#bib.bib76)]。
- en: 'The encoder and decoder in many traffic literatures are in charge of capturing
    spatial-temporal dependencies. For instance, Li et al. [[108](#bib.bib108)] proposed
    DCGRU to be the encoder and decoder, which can capture spatial and temporal dynamics
    jointly. The design of encoder and decoder is usually the core contribution and
    novel part of relative works. Note that the encoder and decoder are not necessarily
    the same and we have made a summarization of Seq2Seq structure in previous graph-based
    traffic works (as shown in Table [III](#S5.T3 "TABLE III ‣ V-D2 Seq2Seq in Traffic
    Domain ‣ V-D Seq2Seq ‣ V Deep Learning Techniques Perspective ‣ How to Build a
    Graph-Based Deep Learning Architecture in Traffic Domain: A Survey")).'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '在许多交通文献中，编码器和解码器负责捕捉时空依赖关系。例如，Li 等人[[108](#bib.bib108)] 提出了 DCGRU 作为编码器和解码器，它可以同时捕捉空间和时间动态。编码器和解码器的设计通常是相关工作的核心贡献和新颖部分。注意，编码器和解码器不一定相同，我们在之前的基于图的交通工作中对
    Seq2Seq 结构进行了总结（如表 [III](#S5.T3 "TABLE III ‣ V-D2 Seq2Seq in Traffic Domain ‣
    V-D Seq2Seq ‣ V Deep Learning Techniques Perspective ‣ How to Build a Graph-Based
    Deep Learning Architecture in Traffic Domain: A Survey")所示）。'
- en: 'TABLE III: The encoders and decoders of sequence to sequence architecture'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 表 III：序列到序列架构的编码器和解码器
- en: '| References | Encoder | Decoder |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 编码器 | 解码器 |'
- en: '| --- | --- | --- |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| [[108](#bib.bib108)] | GRU+DGCN | Same as encoder |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| [[108](#bib.bib108)] | GRU+DGCN | 与编码器相同 |'
- en: '| [[100](#bib.bib100)] | SGCN +LSTM | LSTM+SGCN |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| [[100](#bib.bib100)] | SGCN +LSTM | LSTM+SGCN |'
- en: '| [[98](#bib.bib98)] | STAtt Block | Same as encoder |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| [[98](#bib.bib98)] | STAtt Block | 与编码器相同 |'
- en: '| [[41](#bib.bib41)] | MLPs | An MLP |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| [[41](#bib.bib41)] | MLPs | 一个 MLP |'
- en: '| [[109](#bib.bib109)] | SGCN+Pooling+GRU | GCN+Upooling+GRU |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| [[109](#bib.bib109)] | SGCN+Pooling+GRU | GCN+Upooling+GRU |'
- en: '| [[104](#bib.bib104)] | GRU with graph self-attention | Same as encoder |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| [[104](#bib.bib104)] | 带图自注意力的 GRU | 与编码器相同 |'
- en: '| [[42](#bib.bib42)] | GRU+SGCN | Same as encoder |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| [[42](#bib.bib42)] | GRU+SGCN | 与编码器相同 |'
- en: '| [[110](#bib.bib110)] | SGCN+ bidirectional GRU | Same as encoder |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| [[110](#bib.bib110)] | SGCN+ 双向 GRU | 与编码器相同 |'
- en: '| [[76](#bib.bib76)] | Long-term encoder (Gated SGCN) | Short-term encoder
    |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| [[76](#bib.bib76)] | 长期编码器（门控 SGCN） | 短期编码器 |'
- en: '| [[113](#bib.bib113)] | SGCN+LSTM | LSTM |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| [[113](#bib.bib113)] | SGCN+LSTM | LSTM |'
- en: '| [[96](#bib.bib96)] | SGCN+GRU | Same as encoder |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| [[96](#bib.bib96)] | SGCN+GRU | 与编码器相同 |'
- en: '| [[77](#bib.bib77)] | CGRM (GRU, SGCN) | Same as encoder |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| [[77](#bib.bib77)] | CGRM (GRU, SGCN) | 与编码器相同 |'
- en: '| [[103](#bib.bib103)] | LSTM+RGC | RGC |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| [[103](#bib.bib103)] | LSTM+RGC | RGC |'
- en: '| [[48](#bib.bib48)] | LSTM | Same as encoder |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| [[48](#bib.bib48)] | LSTM | 与编码器相同 |'
- en: RNNs-based decoder has a severe error accumulation problem during testing inference
    due to that each previous predicted step is the input to produce the next step
    prediction. The scheduled sampling to alleviate this problem is adopted in [[108](#bib.bib108)],[[104](#bib.bib104)].
    RNNs-based decoder is replaced with a short-term and long-term decoder to take
    in last step prediction exclusively, thus easing error accumulation [[76](#bib.bib76)].
    The utilization of Seq2Seq technique in traffic domain is flexible. For instance,
    Seq2Seq is integrated into a bigger framework, being the generator and discriminator
    of GAN [[100](#bib.bib100)].
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 RNN 的解码器在测试推理过程中存在严重的误差积累问题，因为每个先前的预测步骤都是生成下一个步骤预测的输入。为缓解这个问题，[[108](#bib.bib108)]、[[104](#bib.bib104)]
    中采用了计划采样方法。基于 RNN 的解码器被替换为仅接收上一步预测的短期和长期解码器，从而减轻了误差积累 [[76](#bib.bib76)]。在交通领域中，Seq2Seq
    技术的应用是灵活的。例如，Seq2Seq 被集成到一个更大的框架中，作为 GAN 的生成器和判别器 [[100](#bib.bib100)]。
- en: V-E GAN
  id: totrans-388
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-E GAN
- en: V-E1 GAN
  id: totrans-389
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-E1 GAN
- en: '![Refer to caption](img/651837ea4ea84ac50ca890f443f44404.png)'
  id: totrans-390
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/651837ea4ea84ac50ca890f443f44404.png)'
- en: 'Figure 10: Generative Adversarial Network: Generator $G$ is in charge of producing
    a generated sample $x_{f}=G(z)$ from a random vector $z$, which is sampled from
    a prior distribution $p_{z}$. Discriminator $D$ is in charge of discriminating
    between the fake sample $x_{f}$ generated from $G$ and the real sample $x_{r}$
    from the training data.'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：生成对抗网络：生成器 $G$ 负责从随机向量 $z$ 中生成生成样本 $x_{f}=G(z)$，其中 $z$ 是从先验分布 $p_{z}$ 中采样得到的。判别器
    $D$ 负责区分从 $G$ 生成的伪造样本 $x_{f}$ 和来自训练数据的真实样本 $x_{r}$。
- en: 'Generative Adversarial Network (GAN) [[149](#bib.bib149)] is a powerful deep
    generative model aiming to generate artificial samples as indistinguishable as
    possible from their real counterparts. GAN, inspired by game theory, is composed
    of two players, a generative neural network called Generator $G$ and an adversarial
    network called Discriminator $D$ (as shown in Figure [10](#S5.F10 "Figure 10 ‣
    V-E1 GAN ‣ V-E GAN ‣ V Deep Learning Techniques Perspective ‣ How to Build a Graph-Based
    Deep Learning Architecture in Traffic Domain: A Survey")).'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '生成对抗网络（GAN） [[149](#bib.bib149)] 是一种强大的深度生成模型，旨在生成尽可能无法与真实样本区分的人工样本。GAN 受到博弈论的启发，由两个玩家组成，一个是称为生成器
    $G$ 的生成神经网络，另一个是称为判别器 $D$ 的对抗网络（如图 [10](#S5.F10 "Figure 10 ‣ V-E1 GAN ‣ V-E GAN
    ‣ V Deep Learning Techniques Perspective ‣ How to Build a Graph-Based Deep Learning
    Architecture in Traffic Domain: A Survey") 所示）。'
- en: Discriminator $D$ tries to determine whether the input samples belong to the
    generated data or the real data while Generator $G$ tries to cheat on Discriminator
    $D$ by producing samples as true as possible. The two mutually adversarial and
    optimized processes are alternately trained, which strengthens the performance
    of both $D$ and $G$. When the fake sample produced by $G$ is very close to the
    ground truth and $D$ is unable to distinguish them any more, it is considered
    that Generator $G$ has learned the true distribution of the real data and the
    model converges. At this time, we can consider this game to reach a Nash equilibrium
    [[150](#bib.bib150)].
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器 $D$ 尝试确定输入样本是属于生成的数据还是实际的数据，而生成器 $G$ 试图通过生成尽可能真实的样本来欺骗判别器 $D$。这两个相互对立且优化的过程交替训练，从而增强了
    $D$ 和 $G$ 的性能。当 $G$ 生成的伪造样本非常接近真实数据且 $D$ 无法再区分时，认为生成器 $G$ 已经学会了真实数据的真实分布，模型也就收敛了。这时，我们可以认为这个游戏达到了纳什均衡
    [[150](#bib.bib150)]。
- en: 'Mathematically, such process can be formulated to minimize their losses $Loss_{G}$
    and $Loss_{D}$. With the loss function being cross entropy denoted as $f$, we
    can have:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，这一过程可以被表述为最小化它们的损失 $Loss_{G}$ 和 $Loss_{D}$。损失函数为交叉熵，记作 $f$，可以表示为：
- en: '|  | <math   alttext="\begin{split}Loss_{G}&amp;=f(D(G(z)),1)=-\sum\log D(G(z))\\
    \phi^{*}&amp;=\underset{\phi}{\operatorname{argmin}}(Loss_{G})=\underset{\phi}{\operatorname{argmax}}(-Loss_{G})\\'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}Loss_{G}&amp;=f(D(G(z)),1)=-\sum\log D(G(z))\\
    \phi^{*}&amp;=\underset{\phi}{\operatorname{argmin}}(Loss_{G})=\underset{\phi}{\operatorname{argmax}}(-Loss_{G})\\'
- en: '&amp;=\underset{\phi}{\operatorname{argmax}}\mathbb{E}(\log D(G(z)))\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"  ><mtr
    ><mtd  columnalign="right" ><mrow ><mi mathsize="80%"  >L</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >s</mi><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi mathsize="80%"
    >s</mi><mi mathsize="80%" >G</mi></msub></mrow></mtd><mtd columnalign="left"  ><mrow
    ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%"  >f</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mi
    mathsize="80%" >D</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mrow ><mi mathsize="80%"  >G</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><mi mathsize="80%"  >z</mi><mo maxsize="80%"
    minsize="80%"  >)</mo></mrow></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo
    mathsize="80%"  >,</mo><mn mathsize="80%"  >1</mn><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo
    mathsize="80%"  >=</mo><mrow ><mo mathsize="80%" >−</mo><mrow ><mo maxsize="80%"
    minsize="80%" movablelimits="false" stretchy="true" >∑</mo><mrow ><mrow  ><mi
    mathsize="80%"  >log</mi><mo lspace="0.167em"  >⁡</mo><mi mathsize="80%"  >D</mi></mrow><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow
    ><mi mathsize="80%"  >G</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mi mathsize="80%"  >z</mi><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msup ><mi mathsize="80%" >ϕ</mi><mo mathsize="80%"
    >∗</mo></msup></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><munder accentunder="true" ><mi mathsize="80%" >argmin</mi><mo mathsize="80%"
    mathvariant="italic" >ϕ</mo></munder><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mi mathsize="80%" >L</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >s</mi><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi mathsize="80%" >s</mi><mi mathsize="80%" >G</mi></msub></mrow><mo maxsize="80%"
    minsize="80%"  >)</mo></mrow></mrow><mo mathsize="80%"  >=</mo><mrow ><munder
    accentunder="true" ><mi mathsize="80%" >argmax</mi><mo mathsize="80%" mathvariant="italic"
    >ϕ</mo></munder><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mrow ><mo mathsize="80%" >−</mo><mrow ><mi mathsize="80%"
    >L</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >s</mi><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi mathsize="80%"  >s</mi><mi mathsize="80%"  >G</mi></msub></mrow></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><munder accentunder="true"
    ><mi mathsize="80%" >argmax</mi><mo mathsize="80%" mathvariant="italic" >ϕ</mo></munder><mo
    lspace="0.167em" rspace="0em" >​</mo><mi mathsize="80%"  >𝔼</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mi mathsize="80%"  >log</mi><mo lspace="0.167em"  >⁡</mo><mi mathsize="80%"  >D</mi></mrow><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow
    ><mi mathsize="80%"  >G</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mi mathsize="80%"  >z</mi><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><ci >𝐿</ci><ci  >𝑜</ci><ci
    >𝑠</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑠</ci><ci  >𝐺</ci></apply></apply><apply
    ><ci >𝑓</ci><interval closure="open" ><apply  ><ci >𝐷</ci><apply ><ci  >𝐺</ci><ci
    >𝑧</ci></apply></apply><cn type="integer"  >1</cn></interval></apply></apply><apply
    ><apply ><apply  ><apply ><apply ><ci  >𝐷</ci></apply><apply ><ci >𝐺</ci><ci >𝑧</ci></apply><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >italic-ϕ</ci></apply></apply></apply></apply></apply><apply
    ><apply ><apply  ><ci >italic-ϕ</ci><ci >argmin</ci></apply><apply ><ci >𝐿</ci><ci  >𝑜</ci><ci
    >𝑠</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑠</ci><ci >𝐺</ci></apply></apply></apply></apply><apply
    ><apply ><apply  ><ci >italic-ϕ</ci><ci >argmax</ci></apply><apply ><apply ><ci  >𝐿</ci><ci
    >𝑜</ci><ci >𝑠</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑠</ci><ci
    >𝐺</ci></apply></apply></apply></apply></apply><apply ><apply ><apply  ><ci >italic-ϕ</ci><ci
    >argmax</ci></apply><ci >𝔼</ci><apply ><apply ><ci  >𝐷</ci></apply><apply ><ci
    >𝐺</ci><ci >𝑧</ci></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}Loss_{G}&=f(D(G(z)),1)=-\sum\log D(G(z))\\
    \phi^{*}&=\underset{\phi}{\operatorname{argmin}}(Loss_{G})=\underset{\phi}{\operatorname{argmax}}(-Loss_{G})\\
    &=\underset{\phi}{\operatorname{argmax}}\mathbb{E}(\log D(G(z)))\end{split}</annotation></semantics></math>
    |  | (23) |'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;=\underset{\phi}{\operatorname{argmax}}\mathbb{E}(\log D(G(z)))\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"  ><mtr
    ><mtd  columnalign="right" ><mrow ><mi mathsize="80%"  >L</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >s</mi><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi mathsize="80%"
    >s</mi><mi mathsize="80%" >G</mi></msub></mrow></mtd><mtd columnalign="left"  ><mrow
    ><mo mathsize="80%" >=</mo><mrow ><mi mathsize="80%"  >f</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mi
    mathsize="80%" >D</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mrow ><mi mathsize="80%"  >G</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><mi mathsize="80%"  >z</mi><mo maxsize="80%"
    minsize="80%"  >)</mo></mrow></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo
    mathsize="80%"  >,</mo><mn mathsize="80%"  >1</mn><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo
    mathsize="80%"  >=</mo><mrow ><mo mathsize="80%" >−</mo><mrow ><mo maxsize="80%"
    minsize="80%" movablelimits="false" stretchy="true" >∑</mo><mrow ><mrow  ><mi
    mathsize="80%"  >log</mi><mo lspace="0.167em"  >⁡</mo><mi mathsize="80%"  >D</mi></mrow><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow
    ><mi mathsize="80%"  >G</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mi mathsize="80%"  >z</mi><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msup ><mi mathsize="80%" >ϕ</mi><mo mathsize="80%"
    >∗</mo></msup></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><munder accentunder="true" ><mi mathsize="80%" >argmin</mi><mo mathsize="80%"
    mathvariant="italic" >ϕ</mo></munder><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mi mathsize="80%" >L</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >s</mi><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi mathsize="80%" >s</mi><mi mathsize="80%" >G</mi></msub></mrow><mo maxsize="80%"
    minsize="80%"  >)</mo></mrow></mrow><mo mathsize="80%"  >=</mo><mrow ><munder
    accentunder="true" ><mi mathsize="80%" >argmax</mi><mo mathsize="80%" mathvariant="italic"
    >ϕ</mo></munder><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mrow ><mo mathsize="80%" >−</mo><mrow ><mi mathsize="80%"
    >L</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >s</mi><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi mathsize="80%"  >s</mi><mi mathsize="80%"  >G</mi></msub></mrow></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr ><mtd
    columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><munder accentunder="true"
    ><mi mathsize="80%" >argmax</mi><mo mathsize="80%" mathvariant="italic" >ϕ</mo></munder><mo
    lspace="0.167em" rspace="0em" >​</mo><mi mathsize="80%"  >𝔼</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mrow
    ><mi mathsize="80%"  >log</mi><mo lspace="0.167em"  >⁡</mo><mi mathsize="80%"  >D</mi></mrow><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow
    ><mi mathsize="80%"  >G</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mi mathsize="80%"  >z</mi><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><ci >𝐿</ci><ci  >𝑜</ci><ci
    >𝑠</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑠</ci><ci  >𝐺</ci></apply></apply><apply
    ><ci >𝑓</ci><interval closure="open" ><apply  ><ci >𝐷</ci><apply ><ci  >𝐺</ci><ci
    >𝑧</ci></apply></apply><cn type="integer"  >1</cn></interval></apply></apply><apply
    ><apply ><apply  ><apply ><apply ><ci  >𝐷</ci></apply><apply ><ci >𝐺</ci><ci >𝑧</ci></apply><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >italic-ϕ</ci></apply></apply></apply></apply></apply><apply
    ><apply ><apply  ><ci >italic-ϕ</ci><ci >argmin</ci></apply><apply ><ci >𝐿</ci><ci  >𝑜</ci><ci
    >𝑠</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑠</ci><ci >𝐺</ci></apply></apply></apply></apply><apply
    ><apply ><apply  ><ci >italic-ϕ</ci><ci >argmax</ci></apply><apply ><apply ><ci  >𝐿</ci><ci
    >𝑜</ci><ci >𝑠</ci><apply ><csymbol'
- en: '|  | <math   alttext="\begin{split}Loss_{D}&amp;=f(D(x_{r}),1,D(x_{f}),0)\\
    &amp;=-\sum\log D(x_{r})-\sum\log(1-D(x_{f}))\\'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}Loss_{D}&amp;=f(D(x_{r}),1,D(x_{f}),0)\\
    &amp;=-\sum\log D(x_{r})-\sum\log(1-D(x_{f}))\\'
- en: \theta^{*}&amp;=\underset{\theta}{\operatorname{argmin}}(Loss_{D})=\underset{\theta}{\operatorname{argmax}}(-Loss_{D})\\
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: \theta^{*}&amp;=\underset{\theta}{\operatorname{argmin}}(Loss_{D})=\underset{\theta}{\operatorname{argmax}}(-Loss_{D})\\
- en: '&amp;=\underset{\theta}{\operatorname{argmax}}(\mathbb{E}(\log D(x_{r})+\log(1-D(x_{f}))))\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"  ><mtr
    ><mtd columnalign="right"  ><mrow ><mi mathsize="80%" >L</mi><mo lspace="0em"
    rspace="0em" >​</mo><mi mathsize="80%" >o</mi><mo lspace="0em" rspace="0em" >​</mo><mi
    mathsize="80%" >s</mi><mo lspace="0em" rspace="0em" >​</mo><msub  ><mi mathsize="80%"  >s</mi><mi
    mathsize="80%"  >D</mi></msub></mrow></mtd><mtd columnalign="left"  ><mrow ><mo
    mathsize="80%" >=</mo><mrow ><mi mathsize="80%"  >f</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mi mathsize="80%" >D</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><msub
    ><mi mathsize="80%"  >x</mi><mi mathsize="80%"  >r</mi></msub><mo maxsize="80%"
    minsize="80%"  >)</mo></mrow></mrow><mo mathsize="80%"  >,</mo><mn mathsize="80%"  >1</mn><mo
    mathsize="80%"  >,</mo><mrow ><mi mathsize="80%" >D</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><msub ><mi mathsize="80%"  >x</mi><mi
    mathsize="80%"  >f</mi></msub><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo
    mathsize="80%"  >,</mo><mn mathsize="80%"  >0</mn><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><mrow ><mo
    mathsize="80%" >−</mo><mrow ><mo maxsize="80%" minsize="80%" movablelimits="false"
    stretchy="true"  >∑</mo><mrow ><mrow ><mi mathsize="80%"  >log</mi><mo lspace="0.167em"  >⁡</mo><mi
    mathsize="80%"  >D</mi></mrow><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo
    maxsize="80%" minsize="80%"  >(</mo><msub ><mi mathsize="80%"  >x</mi><mi mathsize="80%"  >r</mi></msub><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mrow><mo mathsize="80%"
    rspace="0.055em"  >−</mo><mrow ><mo maxsize="80%" minsize="80%" movablelimits="false"
    stretchy="true" >∑</mo><mrow ><mi mathsize="80%" >log</mi><mo >⁡</mo><mrow ><mo
    maxsize="80%" minsize="80%" >(</mo><mrow ><mn mathsize="80%" >1</mn><mo mathsize="80%"
    >−</mo><mrow ><mi mathsize="80%" >D</mi><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo maxsize="80%" minsize="80%" >(</mo><msub ><mi mathsize="80%" >x</mi><mi mathsize="80%"
    >f</mi></msub><mo maxsize="80%" minsize="80%" >)</mo></mrow></mrow></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msup ><mi mathsize="80%" >θ</mi><mo mathsize="80%"
    >∗</mo></msup></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><munder accentunder="true" ><mi mathsize="80%" >argmin</mi><mo mathsize="80%"  >𝜃</mo></munder><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow
    ><mi mathsize="80%"  >L</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >s</mi><mo lspace="0em"
    rspace="0em"  >​</mo><msub ><mi mathsize="80%"  >s</mi><mi mathsize="80%"  >D</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo mathsize="80%"  >=</mo><mrow
    ><munder accentunder="true" ><mi mathsize="80%" >argmax</mi><mo mathsize="80%"  >𝜃</mo></munder><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow
    ><mo mathsize="80%"  >−</mo><mrow ><mi mathsize="80%"  >L</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >s</mi><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi mathsize="80%"  >s</mi><mi
    mathsize="80%"  >D</mi></msub></mrow></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><munder accentunder="true"
    ><mi mathsize="80%" >argmax</mi><mo mathsize="80%"  >𝜃</mo></munder><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mi
    mathsize="80%"  >𝔼</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mrow ><mrow ><mrow ><mi mathsize="80%"  >log</mi><mo lspace="0.167em"  >⁡</mo><mi
    mathsize="80%"  >D</mi></mrow><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo
    maxsize="80%" minsize="80%" >(</mo><msub ><mi mathsize="80%" >x</mi><mi mathsize="80%"
    >r</mi></msub><mo maxsize="80%" minsize="80%" >)</mo></mrow></mrow><mo mathsize="80%"  >+</mo><mrow
    ><mi mathsize="80%"  >log</mi><mo >⁡</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow
    ><mn mathsize="80%"  >1</mn><mo mathsize="80%"  >−</mo><mrow ><mi mathsize="80%"  >D</mi><mo
    lspace="0em" rspace="0em" >​</mo><mrow ><mo maxsize="80%" minsize="80%" >(</mo><msub
    ><mi mathsize="80%" >x</mi><mi mathsize="80%" >f</mi></msub><mo maxsize="80%"
    minsize="80%" >)</mo></mrow></mrow></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><ci >𝐿</ci><ci  >𝑜</ci><ci
    >𝑠</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑠</ci><ci  >𝐷</ci></apply></apply><apply
    ><ci >𝑓</ci><vector  ><apply ><ci >𝐷</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑥</ci><ci >𝑟</ci></apply></apply><cn type="integer" >1</cn><apply ><ci  >𝐷</ci><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑥</ci><ci >𝑓</ci></apply></apply><cn
    type="integer"  >0</cn></vector></apply></apply><apply ><apply ><apply  ><apply
    ><apply ><apply  ><ci >𝐷</ci></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑥</ci><ci >𝑟</ci></apply></apply></apply></apply><apply ><apply ><apply  ><apply
    ><cn type="integer" >1</cn><apply ><ci >𝐷</ci><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝑥</ci><ci >𝑓</ci></apply></apply></apply></apply><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝜃</ci></apply></apply></apply></apply></apply><apply
    ><apply ><apply  ><ci >𝜃</ci><ci >argmin</ci></apply><apply ><ci >𝐿</ci><ci  >𝑜</ci><ci
    >𝑠</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑠</ci><ci >𝐷</ci></apply></apply></apply></apply><apply
    ><apply ><apply  ><ci >𝜃</ci><ci >argmax</ci></apply><apply ><apply ><ci  >𝐿</ci><ci
    >𝑜</ci><ci >𝑠</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑠</ci><ci
    >𝐷</ci></apply></apply></apply></apply></apply><apply ><apply ><apply  ><ci >𝜃</ci><ci
    >argmax</ci></apply><apply ><ci >𝔼</ci><apply ><apply ><apply ><ci  >𝐷</ci></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑥</ci><ci >𝑟</ci></apply></apply><apply
    ><apply ><cn type="integer" >1</cn><apply ><ci  >𝐷</ci><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑥</ci><ci >𝑓</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}Loss_{D}&=f(D(x_{r}),1,D(x_{f}),0)\\
    &=-\sum\log D(x_{r})-\sum\log(1-D(x_{f}))\\ \theta^{*}&=\underset{\theta}{\operatorname{argmin}}(Loss_{D})=\underset{\theta}{\operatorname{argmax}}(-Loss_{D})\\
    &=\underset{\theta}{\operatorname{argmax}}(\mathbb{E}(\log D(x_{r})+\log(1-D(x_{f}))))\end{split}</annotation></semantics></math>
    |  | (24) |'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;=\underset{\theta}{\operatorname{argmax}}(\mathbb{E}(\log D(x_{r})+\log(1-D(x_{f}))))\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"  ><mtr
    ><mtd columnalign="right"  ><mrow ><mi mathsize="80%" >L</mi><mo lspace="0em"
    rspace="0em" >​</mo><mi mathsize="80%" >o</mi><mo lspace="0em" rspace="0em" >​</mo><mi
    mathsize="80%" >s</mi><mo lspace="0em" rspace="0em" >​</mo><msub  ><mi mathsize="80%"  >s</mi><mi
    mathsize="80%"  >D</mi></msub></mrow></mtd><mtd columnalign="left"  ><mrow ><mo
    mathsize="80%" >=</mo><mrow ><mi mathsize="80%"  >f</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mi mathsize="80%" >D</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><msub
    ><mi mathsize="80%"  >x</mi><mi mathsize="80%"  >r</mi></msub><mo maxsize="80%"
    minsize="80%"  >)</mo></mrow></mrow><mo mathsize="80%"  >,</mo><mn mathsize="80%"  >1</mn><mo
    mathsize="80%"  >,</mo><mrow ><mi mathsize="80%" >D</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo maxsize="80%" minsize="80%"  >(</mo><msub ><mi mathsize="80%"  >x</mi><mi
    mathsize="80%"  >f</mi></msub><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo
    mathsize="80%"  >,</mo><mn mathsize="80%"  >0</mn><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><mrow ><mo
    mathsize="80%" >−</mo><mrow ><mo maxsize="80%" minsize="80%" movablelimits="false"
    stretchy="true"  >∑</mo><mrow ><mrow ><mi mathsize="80%"  >log</mi><mo lspace="0.167em"  >⁡</mo><mi
    mathsize="80%"  >D</mi></mrow><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo
    maxsize="80%" minsize="80%"  >(</mo><msub ><mi mathsize="80%"  >x</mi><mi mathsize="80%"  >r</mi></msub><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mrow><mo mathsize="80%"
    rspace="0.055em"  >−</mo><mrow ><mo maxsize="80%" minsize="80%" movablelimits="false"
    stretchy="true" >∑</mo><mrow ><mi mathsize="80%" >log</mi><mo >⁡</mo><mrow ><mo
    maxsize="80%" minsize="80%" >(</mo><mrow ><mn mathsize="80%" >1</mn><mo mathsize="80%"  >−</mo><mrow
    ><mi mathsize="80%" >D</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo maxsize="80%"
    minsize="80%" >(</mo><msub ><mi mathsize="80%" >x</mi><mi mathsize="80%" >f</mi></msub><mo
    maxsize="80%" minsize="80%" >)</mo></mrow></mrow></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><msup ><mi mathsize="80%" >θ</mi><mo mathsize="80%"
    >∗</mo></msup></mtd><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow
    ><munder accentunder="true" ><mi mathsize="80%" >argmin</mi><mo mathsize="80%"  >𝜃</mo></munder><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow
    ><mi mathsize="80%"  >L</mi><mo lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi mathsize="80%"  >s</mi><mo lspace="0em"
    rspace="0em"  >​</mo><msub ><mi mathsize="80%"  >s</mi><mi mathsize="80%"  >D</mi></msub></mrow><mo
    maxsize="80%" minsize="80%"  >)</mo></mrow></mrow><mo mathsize="80%"  >=</mo><mrow
    ><munder accentunder="true" ><mi mathsize="80%" >argmax</mi><mo mathsize="80%"  >𝜃</mo></munder><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow
    ><mo mathsize="80%"  >−</mo><mrow ><mi mathsize="80%"  >L</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi mathsize="80%"  >o</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="80%"  >s</mi><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi mathsize="80%"  >s</mi><mi
    mathsize="80%"  >D</mi></msub></mrow></mrow><mo maxsize="80%" minsize="80%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="left"  ><mrow ><mo mathsize="80%" >=</mo><mrow ><munder accentunder="true"
    ><mi mathsize="80%" >argmax</mi><mo mathsize="80%"  >𝜃</mo></munder><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow ><mi
    mathsize="80%"  >𝔼</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo maxsize="80%"
    minsize="80%"  >(</mo><mrow ><mrow ><mrow ><mi mathsize="80%"  >log</mi><mo lspace="0.167em"  >⁡</mo><mi
    mathsize="80%"  >D</mi></mrow><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo
    maxsize="80%" minsize="80%" >(</mo><msub ><mi mathsize="80%" >x</mi><mi mathsize="80%"
    >r</mi></msub><mo maxsize="80%" minsize="80%" >)</mo></mrow></mrow><mo mathsize="80%"  >+</mo><mrow
    ><mi mathsize="80%"  >log</mi><mo >⁡</mo><mrow ><mo maxsize="80%" minsize="80%"  >(</mo><mrow
    ><mn mathsize="80%"  >1</mn><mo mathsize="80%"  >−</mo><mrow ><mi mathsize="80%"  >D</mi><mo
    lspace="0em" rspace="0em" >​</mo><mrow ><mo maxsize="80%" minsize="80%" >(</mo><msub
    ><'
- en: where $1$ is the label of true sample $x_{r}$. $0$ is the label of fake sample
    $x_{f}=G(z)$. $\phi$ and $\theta$ are the trainable parameters of $G$ and $D$
    respectively. Note that when $G$ is trained, $D$ is untrainable. Interested readers
    can refer to [[151](#bib.bib151)],[[152](#bib.bib152)] for surveys of GAN.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $1$ 是真实样本 $x_{r}$ 的标签。$0$ 是伪造样本 $x_{f}=G(z)$ 的标签。$\phi$ 和 $\theta$ 分别是 $G$
    和 $D$ 的可训练参数。注意，当 $G$ 进行训练时，$D$ 是不可训练的。有兴趣的读者可以参考 [[151](#bib.bib151)], [[152](#bib.bib152)]
    以了解 GAN 的综述。
- en: V-E2 GAN in Traffic Domain
  id: totrans-401
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-E2 交通领域中的 GAN
- en: When GAN is applied in traffic prediction tasks [[153](#bib.bib153)],[[154](#bib.bib154)],
    Generator $G$ is usually employed to generate future traffic observations based
    on the historical observations. Then the generated data and the future real data
    are fed into Discriminator $D$ to train it. After training, Generator $G$ can
    learn the distribution of the real traffic flow data through a large number of
    historical data and can be used to predict the future traffic states [[100](#bib.bib100)].
    GAN can be also utilized to solve the sparsity problem of traffic data for its
    efficacy in handling data generation [[95](#bib.bib95)].
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 当 GAN 应用于交通预测任务时 [[153](#bib.bib153)], [[154](#bib.bib154)]，生成器 $G$ 通常用于基于历史观察生成未来的交通观测。然后，将生成的数据和未来的真实数据输入判别器
    $D$ 进行训练。训练后，生成器 $G$ 可以通过大量历史数据学习真实交通流数据的分布，并用于预测未来的交通状态 [[100](#bib.bib100)]。GAN
    也可以用于解决交通数据的稀疏性问题，因为其在数据生成方面的有效性 [[95](#bib.bib95)]。
- en: In addition, the generator or discriminator of GAN can be any model, such as
    RNNs, Seq2Seq, depending on the specific traffic tasks.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，GAN 的生成器或判别器可以是任何模型，如 RNN、Seq2Seq，具体取决于任务的需求。
- en: VI Challenges Perspective
  id: totrans-404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 挑战视角
- en: Traffic tasks are very challenging due to the complicated spatial dependency,
    temporal dependency in traffic data. In addition, external factors such as holiday
    or event can also affect the traffic conditions. In this section, we introduce
    four common challenges in traffic domain. We carefully examine each challenge
    and its corresponding solutions, making necessary comparison.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 交通任务由于交通数据中的复杂空间依赖性、时间依赖性而非常具有挑战性。此外，假期或事件等外部因素也会影响交通状况。在本节中，我们介绍了交通领域中的四个常见挑战。我们仔细考察了每个挑战及其对应的解决方案，并进行了必要的比较。
- en: VI-A Spatial Dependency
  id: totrans-406
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-A 空间依赖性
- en: '![Refer to caption](img/a3dca06c8862d2f2e5dc10d162e1fd0d.png)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a3dca06c8862d2f2e5dc10d162e1fd0d.png)'
- en: 'Figure 11: The formulation of a bidirectional road: The traffic condition of
    road $R_{1}$ is only influenced by the same side road $R_{2}$ and has weak correlation
    with the opposite side road $R_{3}$. But if this region is modeled as grids, $R_{3}$
    has similar impact on $R_{1}$ as $R_{2}$, which is against the truth. If it is
    model as a graph, $R_{1}$ is connected with $R_{2}$ and disconnected with $R_{3}$,
    which can reflect the true relationship.'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：双向道路的表述：道路 $R_{1}$ 的交通状况仅受同侧道路 $R_{2}$ 的影响，与对侧道路 $R_{3}$ 的关联较弱。但如果将该区域建模为网格，$R_{3}$
    对 $R_{1}$ 的影响与 $R_{2}$ 类似，这与实际情况不符。如果将其建模为图，$R_{1}$ 与 $R_{2}$ 连接，而与 $R_{3}$ 断开，这可以反映真实的关系。
- en: 'As mentioned in previous section, some literatures[[131](#bib.bib131)],[[132](#bib.bib132)],[[155](#bib.bib155)]
    extract spatial features through decomposing the whole traffic network into grids
    and then employing CNNs to process the grid-based data. However, the grid-based
    assumption actually violates the nature topology of traffic network. Many traffic
    networks are physically organized as a graph and the graph topology information
    is obviously valuable for traffic prediction (as shown in Figure [11](#S6.F11
    "Figure 11 ‣ VI-A Spatial Dependency ‣ VI Challenges Perspective ‣ How to Build
    a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey")). According
    to our survey, graph neural networks can model spatial dependencies in graph-based
    traffic networks much better than grid-based approaches. In addition, the complicated
    spatial dependencies in traffic network can be categorized into three spatial
    attributes, i.e. spatial locality, multiple relationships and global connectivity.
    Different kinds of GNNs combining with other deep learning techniques are utilized
    to solve different kinds of spatial attributes.'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '如前一节所述，一些文献[[131](#bib.bib131)],[[132](#bib.bib132)],[[155](#bib.bib155)]通过将整个交通网络分解为网格，然后使用CNN处理基于网格的数据来提取空间特征。然而，这种基于网格的假设实际上违背了交通网络的自然拓扑。许多交通网络在物理上被组织成图，图的拓扑信息显然对交通预测具有价值（如图
    [11](#S6.F11 "Figure 11 ‣ VI-A Spatial Dependency ‣ VI Challenges Perspective
    ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey")所示）。根据我们的调查，图神经网络比基于网格的方法更好地建模图形化交通网络中的空间依赖。此外，交通网络中的复杂空间依赖可以分为三种空间属性，即空间局部性、多重关系和全局连接性。不同类型的GNN结合其他深度学习技术被用于解决不同的空间属性。'
- en: VI-A1 Spatial Locality
  id: totrans-410
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-A1 空间局部性
- en: Spatial locality refers that adjacent regions are usually highly relevant to
    each other. For example, the passenger flow of a station in a subway is obviously
    affected by its connected stations. $\mathbf{K}$-localized spectral graph convolution
    network (SGCN) is widely adopted to aggregate the information of $0$ to $\mathbf{K}-1$
    hop neighbors to the central region. In addition, some works make different assumptions
    about the spatial locality and utilize some novel tricks.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 空间局部性指的是相邻区域通常彼此高度相关。例如，地铁站的客流量显然受到其连接站点的影响。$\mathbf{K}$-局部化谱图卷积网络（SGCN）被广泛采用，以将从$0$到$\mathbf{K}-1$跳的邻居信息聚合到中央区域。此外，一些工作对空间局部性做出了不同的假设，并利用了一些新颖的技巧。
- en: The adjacency matrix representing the traffic topology is usually pre-defined
    while some works [[69](#bib.bib69)],[[42](#bib.bib42)] argued that neighboring
    locations are dynamically correlated with each other. They incorporated the attention
    mechanism into SGCN to adaptively capture the dynamic correlations among surrounding
    regions.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 代表交通拓扑的邻接矩阵通常是预定义的，而一些工作[[69](#bib.bib69)],[[42](#bib.bib42)]则认为相邻位置之间的相关性是动态的。他们将注意力机制融入SGCN，以适应地捕捉周围区域之间的动态相关性。
- en: SGCN requires all the regions to have the same local statistics and its convolution
    kernel is location-independent. However, Zhang et al. [[68](#bib.bib68)] clarified
    that the local statistics of traffic data changed from region to region and they
    designed location-dependent kernels for different regions automatically.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: SGCN要求所有区域具有相同的局部统计特征，其卷积核是位置无关的。然而，张等人[[68](#bib.bib68)]澄清了交通数据的局部统计特征在不同区域之间有所变化，他们为不同区域自动设计了位置相关的卷积核。
- en: VI-A2 Multiple Relationships
  id: totrans-414
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-A2 多重关系
- en: 'While locality attribute focuses on spatial proximity, the target region can
    be correlated with distant regions through various non-Euclidean relationships
    such as functional similarity, transportation connectivity (as shown in Figure
    [5](#S4.F5 "Figure 5 ‣ IV-C1 Nodes and Node Features Construction ‣ IV-C Graph
    Construction from Traffic Datasets ‣ IV Problem Formulation and Graph Construction
    ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey")),
    semantic neighbors. Functional similarity refers that distant region is similar
    to the target region in terms of functionality, which can be characterized by
    the surrounding POIs [[89](#bib.bib89)],[[70](#bib.bib70)]. Transportation connectivity
    suggests that those geographically distant but conveniently reachable can be correlated
    [[89](#bib.bib89)]. The reachable way can be motorway, highway, subway. Semantic
    neighbors are adopted to model the correlation between origins and destinations
    [[101](#bib.bib101)]. The correlation is measured by the passenger flow between
    them. To explicitly extract these correlation information, different types of
    correlations using multiple graphs are encoded [[89](#bib.bib89)] and multi-graph
    convolution is leveraged.'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然局部属性关注空间邻近性，但目标区域可以通过功能相似性、交通连通性（如图 [5](#S4.F5 "图 5 ‣ IV-C1 节点及节点特征构建 ‣ IV-C
    从交通数据集中构建图 ‣ IV 问题定义与图构建 ‣ 如何在交通领域建立基于图的深度学习架构：综述")）、语义邻居等各种非欧几里得关系与远处区域相关。功能相似性指的是远离区域在功能上与目标区域相似，这可以通过周围的POI来表征[[89](#bib.bib89)],
    [[70](#bib.bib70)]。交通连通性建议那些地理上远但方便到达的区域可以相关联[[89](#bib.bib89)]。到达方式可以是高速公路、高速路、地铁。语义邻居被用来建模起点和终点之间的相关性[[101](#bib.bib101)]。这种相关性通过它们之间的客流量来衡量。为了明确提取这些相关信息，使用多个图的不同类型的相关性被编码[[89](#bib.bib89)]，并且利用了多图卷积。
- en: VI-A3 Global Connectivity
  id: totrans-416
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-A3 全球连通性
- en: Both spatial proximity and multi-relationship focus on parts of the network
    while ignore the whole structure. Global connectivity refers that traffic conditions
    of different regions have influenced each other at a whole network scale. There
    are several strategies to exploit the global structure information of traffic
    network.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 空间邻近性和多重关系关注网络的部分区域，而忽视了整个结构。全球连通性指的是不同区域的交通状况在整个网络规模上相互影响。有几种策略可以利用交通网络的全球结构信息。
- en: A popular way to capture global connectivity is to model the changing traffic
    conditions in the traffic network as a diffusion process that happens at a network
    scale, which is presented by a power series of transition matrices. Then, diffusion
    graph convolution network (DGCN) is adopted to extract the spatial dependency
    globally [[112](#bib.bib112)], [[108](#bib.bib108)], [[100](#bib.bib100)], [[102](#bib.bib102)],
    [[96](#bib.bib96)],[[118](#bib.bib118)].
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 捕捉全球连通性的一个流行方法是将交通网络中变化的交通状况建模为在网络规模上发生的扩散过程，这通过转移矩阵的幂级数来表示。然后，采用扩散图卷积网络（DGCN）来全球提取空间依赖[[112](#bib.bib112)],
    [[108](#bib.bib108)], [[100](#bib.bib100)], [[102](#bib.bib102)], [[96](#bib.bib96)],
    [[118](#bib.bib118)]。
- en: A novel spatial graph pooling layer with path growing algorithm is designed
    to produce a coarser graph [[105](#bib.bib105)]. This pooling layer is stacked
    before SGC layer to get multi-granularity graph convolutions, which can extract
    spatial features at various scopes.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 设计了一个新颖的空间图池化层与路径增长算法，用于生成更粗略的图[[105](#bib.bib105)]。该池化层堆叠在SGC层之前，以获得多粒度的图卷积，这可以在不同范围内提取空间特征。
- en: A SGC layer with a self-adaptive adjacency matrix is proposed [[102](#bib.bib102)]
    to capture the hidden global spatial dependency in the data. This self-adaptive
    adjacency matrix is learned from the data through an end-to-end supervised training.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 提出了一个具有自适应邻接矩阵的SGC层[[102](#bib.bib102)]，用于捕捉数据中隐藏的全局空间依赖。这个自适应邻接矩阵通过端到端的监督训练从数据中学习得出。
- en: VI-B Temporal Dependency
  id: totrans-421
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-B 时间依赖性
- en: Temporal dependency refers that prediction of traffic conditions at a certain
    time is usually correlated with various historical observations [[92](#bib.bib92)].
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 时间依赖性指的是在某一时刻对交通状况的预测通常与各种历史观察相关联[[92](#bib.bib92)]。
- en: 'As stated in Section [V](#S5 "V Deep Learning Techniques Perspective ‣ How
    to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey"),
    many works extract the temporal dependency by RNNs-based approaches. However,
    RNNs-based approaches suffer from time-consuming iterations and confront gradient
    vanishing/explosion problem for capturing long sequence. Compared with RNNs-based
    approaches, TCN-based approaches have the superiority of simple structures, parallel
    computing and stable gradients. Therefore, some works [[92](#bib.bib92)],[[70](#bib.bib70)]
    adopt TCN-based approaches to capture the temporal pattern in traffic data. In
    addition, TCN is able to handle different temporal levels by stacking multiple
    layers. For instance, Fang et al. [[111](#bib.bib111)] and Wu et al. [[102](#bib.bib102)]
    stacked multiple TCN layers with the bottom layers extracting short-term neighboring
    dependencies and the higher layers learning long-term temporal patterns.'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 如第 [V](#S5 "V 深度学习技术视角 ‣ 如何在交通领域构建基于图的深度学习架构：综述") 节所述，许多研究通过基于 RNN 的方法提取时间依赖性。然而，基于
    RNN 的方法在捕捉长序列时会遭遇时间消耗大的迭代过程以及梯度消失/爆炸问题。与基于 RNN 的方法相比，基于 TCN 的方法具有结构简单、并行计算和梯度稳定的优点。因此，一些研究
    [[92](#bib.bib92)], [[70](#bib.bib70)] 采用基于 TCN 的方法来捕捉交通数据中的时间模式。此外，TCN 通过堆叠多个层能够处理不同的时间层次。例如，方等人
    [[111](#bib.bib111)] 和吴等人 [[102](#bib.bib102)] 堆叠了多个 TCN 层，其中底层提取短期邻近依赖性，高层学习长期时间模式。
- en: VI-B1 Multi-timescale
  id: totrans-424
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-B1 多时间尺度
- en: Some works extract the temporal dependency at a multi-timescale perspective
    [[69](#bib.bib69)],[[116](#bib.bib116)]. Temporal dependency is decomposed into
    recent, daily and weekly dependencies [[69](#bib.bib69)]. The recent dependency
    refers that the future traffic conditions are influenced by the traffic conditions
    recently. For instance, the traffic congestion at 9 am inevitably influences traffic
    flow at the following hours. Daily dependency describes that the repeated daily
    pattern in traffic data due to the regular daily routine of people, such as morning
    peak and evening peak. Weekly dependency considers the influence caused by the
    same week attributes. For instance, all Mondays share similar traffic pattern
    in a short-term. Guo et al. [[69](#bib.bib69)] set three parallel components with
    the same structure to model these three temporal attributes respectively.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究从多时间尺度的角度提取时间依赖性 [[69](#bib.bib69)], [[116](#bib.bib116)]。时间依赖性被分解为近期、每日和每周依赖性
    [[69](#bib.bib69)]。近期依赖性指未来的交通状况受最近的交通状况影响。例如，早上9点的交通拥堵不可避免地会影响接下来几个小时的交通流量。每日依赖性描述了由于人们的日常规律，交通数据中重复出现的每日模式，例如早高峰和晚高峰。每周依赖性考虑了相同周属性所造成的影响。例如，所有的星期一在短期内有类似的交通模式。郭等人
    [[69](#bib.bib69)] 设置了三个具有相同结构的并行组件，分别对这三种时间属性进行建模。
- en: VI-B2 Different Weights
  id: totrans-426
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-B2 不同的权重
- en: Some works argue that the correlations between historical and future observations
    are varying at different previous time slices. Guo et al. [[69](#bib.bib69)] adopted
    a temporal attention mechanism to adaptively attach different importance to historical
    data.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究认为历史观察和未来观察之间的相关性在不同的过去时间片段中是不同的。郭等人 [[69](#bib.bib69)] 采用了时间注意机制，以自适应地赋予历史数据不同的重要性。
- en: VI-C Spatiotemporal Dependency
  id: totrans-428
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-C 时空依赖性
- en: Many works capture the spatial and temporal dependency separately in a sequential
    manner [[110](#bib.bib110)], [[100](#bib.bib100)], [[94](#bib.bib94)], [[65](#bib.bib65)],[[91](#bib.bib91)],[[120](#bib.bib120)],[[88](#bib.bib88)]
    while the spatial and temporal dependencies are closely intertwined in traffic
    data. Guo et al. [[69](#bib.bib69)] argued that the historical observations in
    different locations at different times have varying impacts on central region
    in the future. Take an obvious example, a traffic accident in a critical road
    results in serious disruptions over related roads but at different time, due to
    the gradual formation and dispersion of traffic congestion.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究将空间和时间依赖性分别以顺序方式捕捉 [[110](#bib.bib110)], [[100](#bib.bib100)], [[94](#bib.bib94)],
    [[65](#bib.bib65)], [[91](#bib.bib91)], [[120](#bib.bib120)], [[88](#bib.bib88)]，而在交通数据中，空间和时间依赖性是紧密交织的。郭等人
    [[69](#bib.bib69)] 认为不同时间不同地点的历史观察对未来中心区域的影响各不相同。举一个明显的例子，关键道路上的交通事故会导致相关道路的严重拥堵，但在不同时间，由于交通拥堵的逐渐形成和扩散。
- en: 'A limitation of separately modeling is that the potential interactions between
    spatial features and temporal features are ignored, which may hurt the prediction
    performance. To overcome such limitation, a popular way is to incorporate the
    graph convolution operations (e.g. SGC, DGC) to RNNs (as stated in Section [VI](#S6
    "VI Challenges Perspective ‣ How to Build a Graph-Based Deep Learning Architecture
    in Traffic Domain: A Survey")) to capture spatial-temporal correlations jointly
    [[66](#bib.bib66)], [[112](#bib.bib112)], [[108](#bib.bib108)], [[106](#bib.bib106)],
    [[96](#bib.bib96)],[[118](#bib.bib118)],[[42](#bib.bib42)], [[105](#bib.bib105)],
    [[77](#bib.bib77)].'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '单独建模的一个局限性是忽略了空间特征与时间特征之间的潜在交互，这可能会影响预测性能。为克服这一局限性，一种流行的方法是将图卷积操作（例如SGC, DGC）结合到RNN中（如第[VI](#S6
    "VI Challenges Perspective ‣ How to Build a Graph-Based Deep Learning Architecture
    in Traffic Domain: A Survey")节所述），以联合捕捉时空相关性 [[66](#bib.bib66)], [[112](#bib.bib112)],
    [[108](#bib.bib108)], [[106](#bib.bib106)], [[96](#bib.bib96)],[[118](#bib.bib118)],[[42](#bib.bib42)],
    [[105](#bib.bib105)], [[77](#bib.bib77)]。'
- en: VI-D External Factors
  id: totrans-431
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-D 外部因素
- en: Factors such as holidays, time attributes (e.g. hour, day, week, month, season,
    year) [[70](#bib.bib70)],[[116](#bib.bib116)], weather (e.g. rainfall, temperature,
    air quality)[[116](#bib.bib116)], special events, POIs[[89](#bib.bib89)] and traffic
    incidents (e.g. incident time, incident type) [[91](#bib.bib91)] can influence
    the traffic prediction in some extent, which we refer as external factors or context
    factors. In addition, Zhang et al. [[110](#bib.bib110)] considered historical
    statistical speed information (e.g. average or standard deviation of traffic speed)
    as external factor.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 一些因素如节假日、时间属性（例如小时、日、周、月、季节、年）[[70](#bib.bib70)],[[116](#bib.bib116)]，天气（例如降雨量、温度、空气质量）[[116](#bib.bib116)]，特殊事件、POI[[89](#bib.bib89)]和交通事故（例如事故时间、事故类型）[[91](#bib.bib91)]可以在一定程度上影响交通预测，我们将其称为外部因素或上下文因素。此外，Zhang等人
    [[110](#bib.bib110)] 将历史统计速度信息（例如交通速度的平均值或标准差）视为外部因素。
- en: Some factors such as day attributes, holidays and weather conditions are encoded
    as discrete values and they are usually transformed into binary vectors by one-hot
    encoding. Other factors including temperature, wind speed are encoded as continual
    values and they are usually normalized by Min-Max normalization or Z-score normalization.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 一些因素如日期属性、节假日和天气条件被编码为离散值，通常通过独热编码转换为二进制向量。其他因素包括温度、风速被编码为连续值，通常通过最小-最大归一化或Z-score归一化来进行标准化。
- en: There are two approaches to handle external factors in the literatures we survey.
    The first approach is to concatenate the external factors with other features
    and feed them into model [[112](#bib.bib112)], [[70](#bib.bib70)]. The second
    approach is to design an external component in charge of processing external factors
    alone. The external component usually contains two fully connected layers, of
    which the first extracting important features and the second mapping low dimension
    features to high dimension features [[70](#bib.bib70)], [[91](#bib.bib91)],[[116](#bib.bib116)],[[48](#bib.bib48)].
    Bai et al. [[113](#bib.bib113)] employed multi-LSTM layers to extract representation
    of external factors. The output of external component is fused with other components
    to generate the final result.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们调查的文献中，有两种处理外部因素的方法。第一种方法是将外部因素与其他特征拼接在一起，并输入模型 [[112](#bib.bib112)], [[70](#bib.bib70)]。第二种方法是设计一个专门处理外部因素的外部组件。外部组件通常包含两个全连接层，第一个用于提取重要特征，第二个将低维特征映射到高维特征
    [[70](#bib.bib70)], [[91](#bib.bib91)],[[116](#bib.bib116)],[[48](#bib.bib48)]。Bai等人
    [[113](#bib.bib113)] 采用了多层LSTM来提取外部因素的表示。外部组件的输出与其他组件融合以生成最终结果。
- en: VII Public Datasets and Open Source Codes
  id: totrans-435
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VII 公共数据集和开源代码
- en: 'TABLE IV: Some open traffic datasets'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: '表 IV: 一些开放的交通数据集'
- en: '| Datasets | Links | References |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 链接 | 参考文献 |'
- en: '| NYC taxi | https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page
    | [[99](#bib.bib99)], [[116](#bib.bib116)],[[91](#bib.bib91)],[[103](#bib.bib103)]
    |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| 纽约市出租车 | https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page |
    [[99](#bib.bib99)], [[116](#bib.bib116)],[[91](#bib.bib91)],[[103](#bib.bib103)]
    |'
- en: '| NYC bike | https://www.citibikenyc.com/system-data | [[116](#bib.bib116)],
    [[48](#bib.bib48)], [[76](#bib.bib76)], [[113](#bib.bib113)] |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| 纽约市自行车 | https://www.citibikenyc.com/system-data | [[116](#bib.bib116)],
    [[48](#bib.bib48)], [[76](#bib.bib76)], [[113](#bib.bib113)] |'
- en: '| San Francisco taxi | https://crawdad.org/ crawdad/epfl/mobility/20090224/
    | [[91](#bib.bib91)] |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| 旧金山出租车 | https://crawdad.org/ crawdad/epfl/mobility/20090224/ | [[91](#bib.bib91)]
    |'
- en: '| Chicago bike | https://www.divvybikes.com/system-data | [[48](#bib.bib48)]
    |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| 芝加哥自行车 | https://www.divvybikes.com/system-data | [[48](#bib.bib48)] |'
- en: '| BikeDC (Bike Washington) | https://www.capitalbikeshare.com/system-data |
    [[116](#bib.bib116)] |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| BikeDC (华盛顿自行车) | https://www.capitalbikeshare.com/system-data | [[116](#bib.bib116)]
    |'
- en: '| California -PEMS | http://pems.dot.ca.gov/ | [[92](#bib.bib92)],[[70](#bib.bib70)],[[69](#bib.bib69)],[[99](#bib.bib99)],[[112](#bib.bib112)],[[71](#bib.bib71)],[[98](#bib.bib98)],[[102](#bib.bib102)],[[106](#bib.bib106)],[[66](#bib.bib66)],[[96](#bib.bib96)]
    |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| 加州 - PEMS | http://pems.dot.ca.gov/ | [[92](#bib.bib92)],[[70](#bib.bib70)],[[69](#bib.bib69)],[[99](#bib.bib99)],[[112](#bib.bib112)],[[71](#bib.bib71)],[[98](#bib.bib98)],[[102](#bib.bib102)],[[106](#bib.bib106)],[[66](#bib.bib66)],[[96](#bib.bib96)]
    |'
- en: VII-A Public Datasets
  id: totrans-444
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-A 公共数据集
- en: 'We summarize some public datasets (as shown in Table [IV](#S7.T4 "TABLE IV
    ‣ VII Public Datasets and Open Source Codes ‣ How to Build a Graph-Based Deep
    Learning Architecture in Traffic Domain: A Survey")) in the literatures we survey
    to help successors participate in this domain and produce more valuable works.'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '我们总结了一些公共数据集（如表 [IV](#S7.T4 "TABLE IV ‣ VII Public Datasets and Open Source
    Codes ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic Domain:
    A Survey") 所示），以帮助后继者参与该领域并产生更多有价值的工作。'
- en: VII-B Open Source Codes
  id: totrans-446
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-B 开源代码
- en: 'Open-source implementations are helpful for researchers to compare their approaches.
    We provide the hyperlinks of public source codes of the literatures reviewed in
    this paper (as shown in Table [V](#S7.T5 "TABLE V ‣ VII-B Open Source Codes ‣
    VII Public Datasets and Open Source Codes ‣ How to Build a Graph-Based Deep Learning
    Architecture in Traffic Domain: A Survey")) to facilitate the baseline experiments
    in traffic domain.'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '开源实现对研究人员比较他们的方法非常有帮助。我们提供了本文所述文献的公共源代码超链接（如表 [V](#S7.T5 "TABLE V ‣ VII-B Open
    Source Codes ‣ VII Public Datasets and Open Source Codes ‣ How to Build a Graph-Based
    Deep Learning Architecture in Traffic Domain: A Survey") 所示），以方便在交通领域的基线实验。'
- en: 'TABLE V: Some open source codes'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 表 V：一些开源代码
- en: '| Reference | Model | Year | Framework | Github |'
  id: totrans-449
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 模型 | 年份 | 框架 | Github |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| [[108](#bib.bib108)] | DCRNN | 2018 | Tensorflow | https://github.com/liyaguang/DCRNN
    |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| [[108](#bib.bib108)] | DCRNN | 2018 | Tensorflow | https://github.com/liyaguang/DCRNN
    |'
- en: '| [[97](#bib.bib97)] | GCNN | 2018 | Keras | https://github.com/RingBDStack/GCNN-In-Traffic
    |'
  id: totrans-452
  prefs: []
  type: TYPE_TB
  zh: '| [[97](#bib.bib97)] | GCNN | 2018 | Keras | https://github.com/RingBDStack/GCNN-In-Traffic
    |'
- en: '| [[93](#bib.bib93)] | T-GCN | 2019 | Tensorflow | https://github.com/lehaifeng/T-GCN
    |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
  zh: '| [[93](#bib.bib93)] | T-GCN | 2019 | Tensorflow | https://github.com/lehaifeng/T-GCN
    |'
- en: '| [[98](#bib.bib98)] | GMAN | 2019 | Tensorflow | https://github.com/zhengchuanpan/GMAN
    |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '| [[98](#bib.bib98)] | GMAN | 2019 | Tensorflow | https://github.com/zhengchuanpan/GMAN
    |'
- en: '| [[102](#bib.bib102)] | Graph-WaveNet | 2019 | Torch | https://github.com/nnzhan/Graph-WaveNet
    |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| [[102](#bib.bib102)] | Graph-WaveNet | 2019 | Torch | https://github.com/nnzhan/Graph-WaveNet
    |'
- en: VIII Future Directions
  id: totrans-456
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VIII 未来方向
- en: 'We have investigated the latest advances in graph-based traffic literatures
    and made a summary of these literatures in Table [II](#S5.T2 "TABLE II ‣ V Deep
    Learning Techniques Perspective ‣ How to Build a Graph-Based Deep Learning Architecture
    in Traffic Domain: A Survey"). Further, we suggest some directions for researchers
    to explore, which can be divided into three categories, i.e. application related,
    technique related, external factor related directions.'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: '我们调查了基于图的交通文献中的最新进展，并在表 [II](#S5.T2 "TABLE II ‣ V Deep Learning Techniques
    Perspective ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic
    Domain: A Survey") 中总结了这些文献。此外，我们建议研究人员探索一些方向，这些方向可以分为三类，即应用相关、技术相关和外部因素相关方向。'
- en: VIII-1 Application Related Directions
  id: totrans-458
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VIII-1 应用相关方向
- en: 'As shown in Table [II](#S5.T2 "TABLE II ‣ V Deep Learning Techniques Perspective
    ‣ How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey"),
    there are many works utilizing graph-based deep learning architectures to tackle
    traffic state prediction and traffic demand prediction, which have achieved state-of-the-art
    performance. However, there are only a handful of works analyzing traffic data
    in a graph perspective in other research directions, such as vehicle behavior
    classification [[65](#bib.bib65)], optimal dynamic electronic toll collection
    (DETC) scheme [[57](#bib.bib57)], path availability [[66](#bib.bib66)], traffic
    signal control [[67](#bib.bib67)]. When it comes to traffic incident detection,
    vehicle detection, origin-destination travel demand prediction and transfer learning
    from City to City, works adopting graph-based deep learning techniques are rare
    up to now. Therefore, the upcoming participators can explore these directions
    in a graph perspective and learn the successful experiences from existing works.'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '如表 [II](#S5.T2 "TABLE II ‣ V Deep Learning Techniques Perspective ‣ How to
    Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey") 所示，许多工作利用基于图的深度学习架构来处理交通状态预测和交通需求预测，已取得了最先进的性能。然而，只有少数工作在其他研究方向上从图的角度分析交通数据，例如车辆行为分类[[65](#bib.bib65)]，最优动态电子收费（DETC）方案[[57](#bib.bib57)]，路径可用性[[66](#bib.bib66)]，交通信号控制[[67](#bib.bib67)]。在交通事件检测、车辆检测、起点-终点旅行需求预测以及城市间的迁移学习方面，采用基于图的深度学习技术的工作仍然稀少。因此，未来的参与者可以从图的角度探索这些方向，并学习现有工作的成功经验。'
- en: VIII-2 Technique Related Directions
  id: totrans-460
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VIII-2 技术相关方向
- en: On one hand, most existing works have employed spectral graph convolution network
    (SGCN) and diffusion graph convolution network (DGCN), two popular kinds of GNNs,
    to analyze traffic tasks. There are only a handful of works utilizing Graph attention
    networks (GATs) in traffic domain [[122](#bib.bib122)], [[98](#bib.bib98)], [[104](#bib.bib104)],
    [[107](#bib.bib107)],[[119](#bib.bib119)]. Other kinds of GNNs, such as graph
    auto-encoders (GAEs) [[156](#bib.bib156)],[[157](#bib.bib157)], recurrent graph
    neural networks (RecGNNs) [[158](#bib.bib158)] have achieved state-of-the-art
    performance in other domains, but they are seldom explored in traffic domain up
    to now. Therefore, it is worth to extend these branches of GNNs to traffic domain.
    On the other hand, recent works have combined GNNs with other deep learning techniques
    such as RNNs, TCN, Seq2Seq, GAN to solve the challenges in traffic tasks. However,
    few traffic works consider transfer learning, continue learning and reinforcement
    learning together with GNNs, which might be a promising direction for researchers.
    In addition, most of the graph-based traffic works are regression tasks, while
    classification tasks are few [[66](#bib.bib66)],[[65](#bib.bib65)]. Researchers
    can explore the classification traffic tasks in a graph perspective.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 一方面，大多数现有的研究采用了光谱图卷积网络（SGCN）和扩散图卷积网络（DGCN）这两种流行的GNNs来分析交通任务。只有少数工作在交通领域利用了图注意力网络（GATs）[[122](#bib.bib122)],
    [[98](#bib.bib98)], [[104](#bib.bib104)], [[107](#bib.bib107)], [[119](#bib.bib119)]。其他类型的GNNs，如图自编码器（GAEs）[[156](#bib.bib156)],
    [[157](#bib.bib157)]，递归图神经网络（RecGNNs）[[158](#bib.bib158)]在其他领域已取得了最先进的性能，但迄今为止在交通领域鲜有探讨。因此，将这些GNN的分支扩展到交通领域是值得的。另一方面，近期的研究将GNNs与其他深度学习技术如RNNs、TCN、Seq2Seq、GAN结合，解决交通任务中的挑战。然而，很少有交通工作将迁移学习、持续学习和强化学习与GNNs结合，这可能是一个有前景的研究方向。此外，大多数基于图的交通研究是回归任务，而分类任务则较少[[66](#bib.bib66)],
    [[65](#bib.bib65)]。研究人员可以从图的角度探索分类交通任务。
- en: VIII-3 External Factors Related Directions
  id: totrans-462
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VIII-3 外部因素相关方向
- en: Finally, many existing traffic models do not take external factors into consideration,
    for that external factors are hard to collect and have various formats. The data
    sparsity of external factors is still a challenge confronted by the research community.
    In addition, the techniques to process external factors are rather naive, e.g.
    a simple fully connected layer. There should be more approaches to process external
    factors.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，许多现有的交通模型未考虑外部因素，因为外部因素难以收集且格式多样。外部因素的数据稀疏性仍然是研究界面临的挑战。此外，处理外部因素的技术相当幼稚，例如简单的全连接层。应该有更多的方法来处理外部因素。
- en: IX Conclusion
  id: totrans-464
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IX 结论
- en: In this survey, we conduct a comprehensive review of various graph-based deep
    learning architectures in recent traffic works. More specifically, we summarize
    a general graph-based formulation of traffic problem and graph construction from
    various traffic datasets. Further, we decompose all the investigated architectures
    and analyze the common modules they share, including graph neural networks (GNNs),
    recurrent neural networks (RNNs), temporal convolution network (TCN), Sequence
    to Sequence (Seq2Seq) model, generative adversarial network (GAN). We provide
    a thorough description of their variants in traffic tasks, hoping to provide upcoming
    researchers insights into how to design novel techniques for their own traffic
    tasks. We also summarize the common challenges in many traffic scenarios, such
    as spatial dependency, temporal dependency, external factors. More than that,
    we present multiple deep learning based solutions for each challenge. In addition,
    we provide some hyperlinks of public datasets and codes in related works to facilitate
    the upcoming researches. Finally, we suggest some future directions for participators
    interested in this domain.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次调查中，我们对近期交通领域中各种基于图的深度学习架构进行了全面回顾。更具体地说，我们总结了交通问题的一般图基模型及各种交通数据集中的图构建方法。此外，我们分解了所有研究过的架构，并分析了它们共享的共同模块，包括图神经网络（GNNs）、递归神经网络（RNNs）、时间卷积网络（TCN）、序列到序列（Seq2Seq）模型、生成对抗网络（GAN）。我们详细描述了它们在交通任务中的变体，希望为未来的研究者提供关于如何设计新技术的见解。我们还总结了许多交通场景中的常见挑战，如空间依赖、时间依赖、外部因素。更重要的是，我们为每个挑战提出了多种基于深度学习的解决方案。此外，我们提供了一些相关工作的公共数据集和代码的超链接，以方便未来的研究。最后，我们建议了一些对该领域感兴趣的参与者的未来研究方向。
- en: Acknowledgment
  id: totrans-466
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: The authors would like to thank anonymous reviewers for their valuable comments.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们感谢匿名评审人提供的宝贵意见。
- en: This work is supported by the National Key R&D Program of China (No.2019YFB2102100),
    National Natural Science Foundation of China (No.61802387), China’s Post-doctoral
    Science Fund (No.2019M663183), National Natural Science Foundation of Shenzhen
    (No.JCYJ20190812153212464), Shenzhen Engineering Research Center for Beidou Positioning
    Service Improvement Technology (No.XMHT20190101035), Science and Technology Development
    Fund of Macao S.A.R (FDCT) under number 0015/2019/AKP, Shenzhen Discipline Construction
    Project for Urban Computing and Data Intelligence.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作得到中国国家重点研发计划（No.2019YFB2102100）、中国国家自然科学基金（No.61802387）、中国博士后科学基金（No.2019M663183）、深圳市国家自然科学基金（No.JCYJ20190812153212464）、深圳市北斗定位服务技术提升工程研究中心（No.XMHT20190101035）、澳门特别行政区科技发展基金（FDCT）编号0015/2019/AKP、深圳市城市计算与数据智能学科建设项目的支持。
- en: References
  id: totrans-469
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] G. Yu and C. Zhang, “Switching ARIMA model based forecasting for traffic
    flow,” in *ICASSP*, 2004, pp. 429–432.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] G. Yu and C. Zhang, “基于ARIMA模型的交通流预测，” in *ICASSP*, 2004, pp. 429–432.'
- en: '[2] B. M. Williams and L. A. Hoel, “Modeling and forecasting vehicular traffic
    flow as a seasonal arima process: Theoretical basis and empirical results,” *Journal
    of Transportation Engineering*, vol. 129, no. 6, pp. 664–672, 2003.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] B. M. Williams and L. A. Hoel, “将车辆交通流建模和预测为季节性ARIMA过程：理论基础和实证结果，” *Journal
    of Transportation Engineering*, vol. 129, no. 6, pp. 664–672, 2003.'
- en: '[3] S. R. Chandra and H. Al-Deek, “Predictions of freeway traffic speeds and
    volumes using vector autoregressive models,” *IEEE Transactions on Intelligent
    Transportation Systems*, vol. 13, no. 2, pp. 53–72, 2009.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] S. R. Chandra and H. Al-Deek, “使用向量自回归模型预测高速公路交通速度和流量，” *IEEE Transactions
    on Intelligent Transportation Systems*, vol. 13, no. 2, pp. 53–72, 2009.'
- en: '[4] Y. Xie, Y. Zhang, and Z. Ye, “Short-term traffic volume forecasting using
    kalman filter with discrete wavelet decomposition,” *Computer-Aided Civil and
    Infrastructure Engineering*, vol. 22, no. 5, pp. 326–334, 2007.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Y. Xie, Y. Zhang, and Z. Ye, “使用卡尔曼滤波和离散小波分解进行短期交通流量预测，” *Computer-Aided
    Civil and Infrastructure Engineering*, vol. 22, no. 5, pp. 326–334, 2007.'
- en: '[5] H. Fu, H. Ma, Y. Liu, and D. Lu, “A vehicle classification system based
    on hierarchical multi-svms in crowded traffic scenes,” *Neurocomputing*, vol.
    211, pp. 182–190, 2016.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] H. Fu, H. Ma, Y. Liu, and D. Lu, “基于层次多支持向量机的拥挤交通场景中的车辆分类系统，” *Neurocomputing*,
    vol. 211, pp. 182–190, 2016.'
- en: '[6] M. May, D. Hecker, C. Körner, S. Scheider, and D. Schulz, “A vector-geometry
    based spatial knn-algorithm for traffic frequency predictions,” in *ICDM Workshops*,
    2008, pp. 442–447.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] M. May, D. Hecker, C. Körner, S. Scheider, and D. Schulz, “基于向量几何的空间k近邻算法用于交通频率预测，”
    in *ICDM Workshops*, 2008, pp. 442–447.'
- en: '[7] J. Liu, T. Li, P. Xie, S. Du, F. Teng, and X. Yang, “Urban big data fusion
    based on deep learning: An overview,” *Information Fusion*, vol. 53, pp. 123–133,
    2020.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] J. Liu, T. Li, P. Xie, S. Du, F. Teng, 和 X. Yang，“基于深度学习的城市大数据融合：概述，” *Information
    Fusion*，第53卷，第123–133页，2020年。'
- en: '[8] Z. Lv, J. Xu, K. Zheng, H. Yin, P. Zhao, and X. Zhou, “LC-RNN: A deep learning
    model for traffic speed prediction,” in *IJCAI*, 2018, pp. 3470–3476.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Z. Lv, J. Xu, K. Zheng, H. Yin, P. Zhao, 和 X. Zhou，“LC-RNN：用于交通速度预测的深度学习模型，”
    在 *IJCAI*，2018年，第3470–3476页。'
- en: '[9] X. Ma, Z. Dai, Z. He, J. Ma, Y. Wang, and Y. Wang, “Learning traffic as
    images: a deep convolutional neural network for large-scale transportation network
    speed prediction,” *Sensors*, vol. 17, no. 4, p. 818, 2017.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] X. Ma, Z. Dai, Z. He, J. Ma, Y. Wang, 和 Y. Wang，“将交通学习为图像：一种用于大规模交通网络速度预测的深度卷积神经网络，”
    *Sensors*，第17卷，第4期，第818页，2017年。'
- en: '[10] L. Yan, H. Shen, J. Zhao, C. Xu, F. Luo, and C. Qiu, “Catcharger: Deploying
    wireless charging lanes in a metropolitan road network through categorization
    and clustering of vehicle traffic,” in *INFOCOM*, 2017, pp. 1–9.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] L. Yan, H. Shen, J. Zhao, C. Xu, F. Luo, 和 C. Qiu，“Catcharger：通过车辆流量的分类和聚类在大都市道路网络中部署无线充电车道，”
    在 *INFOCOM*，2017年，第1–9页。'
- en: '[11] Y. Sun, X. Yu, R. Bie, and H. Song, “Discovering time-dependent shortest
    path on traffic graph for drivers towards green driving,” *Journal of Network
    and Computer Applications*, vol. 83, pp. 204–212, 2017.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Y. Sun, X. Yu, R. Bie, 和 H. Song，“在交通图上发现时间相关的最短路径以实现绿色驾驶，” *Journal of
    Network and Computer Applications*，第83卷，第204–212页，2017年。'
- en: '[12] H. Sun, J. Wu, D. Ma, and J. Long, “Spatial distribution complexities
    of traffic congestion and bottlenecks in different network topologies,” *Applied
    Mathematical Modelling*, vol. 38, no. 2, pp. 496–505, 2014.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] H. Sun, J. Wu, D. Ma, 和 J. Long，“不同网络拓扑中交通拥堵和瓶颈的空间分布复杂性，” *Applied Mathematical
    Modelling*，第38卷，第2期，第496–505页，2014年。'
- en: '[13] M. Gori, G. Monfardini, and F. Scarselli, “A new model for learning in
    graph domains,” in *IJCNN*, vol. 2, 2005, pp. 729–734.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] M. Gori, G. Monfardini, 和 F. Scarselli，“图域学习的新模型，” 在 *IJCNN*，第2卷，2005年，第729–734页。'
- en: '[14] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini,
    “The graph neural network model,” *IEEE Transactions on Neural Networks*, vol. 20,
    no. 1, pp. 61–80, 2008.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, 和 G. Monfardini，“图神经网络模型，”
    *IEEE Transactions on Neural Networks*，第20卷，第1期，第61–80页，2008年。'
- en: '[15] M. Henaff, J. Bruna, and Y. LeCun, “Deep convolutional networks on graph-structured
    data,” *arXiv:1506.05163*, 2015.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] M. Henaff, J. Bruna, 和 Y. LeCun，“图结构数据上的深度卷积网络，” *arXiv:1506.05163*，2015年。'
- en: '[16] Y. Li, O. Vinyals, C. Dyer, R. Pascanu, and P. Battaglia, “Learning deep
    generative models of graphs,” *arXiv:1803.03324*, 2018.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Y. Li, O. Vinyals, C. Dyer, R. Pascanu, 和 P. Battaglia，“学习图的深度生成模型，” *arXiv:1803.03324*，2018年。'
- en: '[17] Z.-M. Chen, X.-S. Wei, P. Wang, and Y. Guo, “Multi-label image recognition
    with graph convolutional networks,” in *CVPR*, 2019, pp. 5177–5186.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Z.-M. Chen, X.-S. Wei, P. Wang, 和 Y. Guo，“使用图卷积网络进行多标签图像识别，” 在 *CVPR*，2019年，第5177–5186页。'
- en: '[18] Z. Guo, Y. Zhang, and W. Lu, “Attention guided graph convolutional networks
    for relation extraction,” in *ACL*, 2019, pp. 241–251.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Z. Guo, Y. Zhang, 和 W. Lu，“用于关系提取的注意力引导图卷积网络，” 在 *ACL*，2019年，第241–251页。'
- en: '[19] D. K. Duvenaud, D. Maclaurin, J. Iparraguirre, and e. Bombarell, “Convolutional
    networks on graphs for learning molecular fingerprints,” in *NIPS*, 2015, pp.
    2224–2232.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] D. K. Duvenaud, D. Maclaurin, J. Iparraguirre, 和 e. Bombarell，“用于学习分子指纹的图卷积网络，”
    在 *NIPS*，2015年，第2224–2232页。'
- en: '[20] R. Ying, R. He, K. Chen, P. Eksombatchai, W. L. Hamilton, and J. Leskovec,
    “Graph convolutional neural networks for web-scale recommender systems,” in *KDD*,
    2018, pp. 974–983.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] R. Ying, R. He, K. Chen, P. Eksombatchai, W. L. Hamilton, 和 J. Leskovec，“用于网络规模推荐系统的图卷积神经网络，”
    在 *KDD*，2018年，第974–983页。'
- en: '[21] M. G. Karlaftis and E. I. Vlahogianni, “Statistical methods versus neural
    networks in transportation research: Differences, similarities and some insights,”
    *Transportation Research Part C: Emerging Technologies*, vol. 19, no. 3, pp. 387–399,
    2011.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] M. G. Karlaftis 和 E. I. Vlahogianni，“交通研究中的统计方法与神经网络：差异、相似性及一些见解，” *Transportation
    Research Part C: Emerging Technologies*，第19卷，第3期，第387–399页，2011年。'
- en: '[22] E. I. Vlahogianni, M. G. Karlaftis, and J. C. Golias, “Short-term traffic
    forecasting: Where we are and where we’re going,” *Transportation Research Part
    C: Emerging Technologies*, vol. 43, pp. 3–19, 2014.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] E. I. Vlahogianni, M. G. Karlaftis, 和 J. C. Golias，“短期交通预测：我们的位置与未来发展方向，”
    *Transportation Research Part C: Emerging Technologies*，第43卷，第3–19页，2014年。'
- en: '[23] P. Xie, T. Li, J. Liu, S. Du, X. Yang, and J. Zhang, “Urban flow prediction
    from spatiotemporal data using machine learning: A survey,” *Information Fusion*,
    2020.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] P. Xie, T. Li, J. Liu, S. Du, X. Yang, 和 J. Zhang，“基于时空数据的城市流动预测：综述”，*信息融合*，2020年。'
- en: '[24] H. Nguyen, L.-M. Kieu, T. Wen, and C. Cai, “Deep learning methods in transportation
    domain: a review,” *IET Intelligent Transport Systems*, vol. 12, no. 9, pp. 998–1004,
    2018.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] H. Nguyen, L.-M. Kieu, T. Wen, 和 C. Cai，“交通领域的深度学习方法：综述”，*IET 智能交通系统*，第12卷，第9期，页码
    998–1004，2018年。'
- en: '[25] Y. Wang, D. Zhang, Y. Liu, B. Dai, and L. H. Lee, “Enhancing transportation
    systems via deep learning: A survey,” *Transportation Research Part C: Emerging
    Technologies*, vol. 99, pp. 144–163, 2019.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Y. Wang, D. Zhang, Y. Liu, B. Dai, 和 L. H. Lee，“通过深度学习增强交通系统：综述”，*运输研究C部分：新兴技术*，第99卷，页码
    144–163，2019年。'
- en: '[26] M. Veres and M. Moussa, “Deep learning for intelligent transportation
    systems: A survey of emerging trends,” *IEEE Transactions on Intelligent Transportation
    Systems*, 2019.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] M. Veres 和 M. Moussa，“智能交通系统中的深度学习：新兴趋势综述”，*IEEE 智能交通系统杂志*，2019年。'
- en: '[27] Q. Chen, W. Wang, F. Wu, S. De, and e. Wang, “A survey on an emerging
    area: Deep learning for smart city data,” *IEEE Transactions on Emerging Topics
    in Computational Intelligence*, vol. 3, no. 5, pp. 392–410, 2019.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Q. Chen, W. Wang, F. Wu, S. De, 和 e. Wang，“新兴领域综述：智能城市数据的深度学习”，*IEEE 计算智能前沿话题杂志*，第3卷，第5期，页码
    392–410，2019年。'
- en: '[28] S. Wang, J. Cao, and P. S. Yu, “Deep learning for spatio-temporal data
    mining: A survey,” *arXiv:1906.04928*, 2019.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] S. Wang, J. Cao, 和 P. S. Yu，“时空数据挖掘中的深度学习：综述”，*arXiv:1906.04928*，2019年。'
- en: '[29] M. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, and P. Vandergheynst, “Geometric
    deep learning: going beyond euclidean data,” *IEEE Signal Processing Magazine*,
    vol. 34, no. 4, pp. 18–42, 2017.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] M. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, 和 P. Vandergheynst，“几何深度学习：超越欧几里得数据”，*IEEE
    信号处理杂志*，第34卷，第4期，页码 18–42，2017年。'
- en: '[30] J. Zhou, G. Cui, Z. Zhang, and e. Yang, “Graph neural networks: A review
    of methods and applications,” *arXiv:1812.08434*, 2018.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] J. Zhou, G. Cui, Z. Zhang, 和 e. Yang，“图神经网络：方法与应用综述”，*arXiv:1812.08434*，2018年。'
- en: '[31] J. Zhang, “Graph neural networks for small graph and giant network representation
    learning: An overview,” *arXiv:1908.00187*, 2019.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] J. Zhang，“小图和大规模网络表示学习的图神经网络：概述”，*arXiv:1908.00187*，2019年。'
- en: '[32] P. Quan, Y. Shi, M. Lei, J. Leng, T. Zhang, and L. Niu, “A brief review
    of receptive fields in graph convolutional networks,” in *IEEE/WIC/ACM International
    Conference on Web Intelligence-Companion Volume*, 2019, pp. 106–110.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] P. Quan, Y. Shi, M. Lei, J. Leng, T. Zhang, 和 L. Niu，“图卷积网络中的感受野简要综述”，在*IEEE/WIC/ACM
    国际网络智能会议-伴随卷*，2019年，页码 106–110。'
- en: '[33] S. Zhang, H. Tong, J. Xu, and R. Maciejewski, “Graph convolutional networks:
    a comprehensive review,” *Computational Social Networks*, vol. 6, no. 1, p. 11,
    2019.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] S. Zhang, H. Tong, J. Xu, 和 R. Maciejewski，“图卷积网络：全面综述”，*计算社会网络*，第6卷，第1期，页码
    11，2019年。'
- en: '[34] Z. Wu, S. Pan, F. Chen, G. Long, and e. Zhang, “A comprehensive survey
    on graph neural networks,” *IEEE Transactions on Neural Networks and Learning
    Systems*, 2020.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Z. Wu, S. Pan, F. Chen, G. Long, 和 e. Zhang，“图神经网络的全面综述”，*IEEE 神经网络与学习系统杂志*，2020年。'
- en: '[35] Y. Chen, Y. Lv, Z. Li, and F. Wang, “Long short-term memory model for
    traffic congestion prediction with online open data,” in *ITSC*, 2016, pp. 132–137.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Y. Chen, Y. Lv, Z. Li, 和 F. Wang，“基于在线开放数据的交通拥堵预测的长短期记忆模型”，在*ITSC*，2016年，页码
    132–137。'
- en: '[36] L. Yan and H. Shen, “TOP: optimizing vehicle driving speed with vehicle
    trajectories for travel time minimization and road congestion avoidance,” *ACM
    Trans. Cyber Phys. Syst.*, vol. 4, no. 2, pp. 17:1–17:25, 2020.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] L. Yan 和 H. Shen，“TOP：通过车辆轨迹优化车辆驾驶速度以最小化旅行时间和避免道路拥堵”，*ACM 网络与物理系统事务*，第4卷，第2期，页码
    17:1–17:25，2020年。'
- en: '[37] L. Yan, H. Shen, and K. Chen, “Mobit: Distributed and congestion-resilient
    trajectory-based routing for vehicular delay tolerant networks,” *IEEE/ACM Trans.
    Netw.*, vol. 26, no. 3, pp. 1078–1091, 2018.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] L. Yan, H. Shen, 和 K. Chen，“Mobit：一种分布式和抗拥堵的基于轨迹的车辆延迟容忍网络路由”，*IEEE/ACM
    网络事务*，第26卷，第3期，页码 1078–1091，2018年。'
- en: '[38] X. Ma, H. Yu, Y. Wang, and Y. Wang, “Large-scale transportation network
    congestion evolution prediction using deep learning theory,” *PloS one*, vol. 10,
    no. 3, 2015.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] X. Ma, H. Yu, Y. Wang, 和 Y. Wang，“基于深度学习理论的大规模交通网络拥堵演变预测”，*PloS one*，第10卷，第3期，2015年。'
- en: '[39] F. Sun, A. Dubey, and J. White, “Dxnat—deep neural networks for explaining
    non-recurring traffic congestion,” in *Big Data*, 2017.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] F. Sun, A. Dubey, 和 J. White，“Dxnat—解释非重复性交通拥堵的深度神经网络，” 在 *大数据*，2017 年。'
- en: '[40] L. Yan, H. Shen, and K. Chen, “Mobit: A distributed and congestion-resilient
    trajectory based routing algorithm for vehicular delay tolerant networks,” in
    *Proceedings of the Second International Conference on Internet-of-Things Design
    and Implementation, IoTDI 2017, Pittsburgh, PA, USA, April 18-21, 2017*, 2017,
    pp. 209–214.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] L. Yan, H. Shen, 和 K. Chen，“Mobit：一种分布式且抗拥堵的基于轨迹的路由算法，用于车辆延迟容忍网络，” 在 *第二届国际物联网设计与实施会议论文集，IoTDI
    2017，匹兹堡，PA，美国，2017 年 4 月 18-21 日*，2017 年，页码 209–214。'
- en: '[41] L. Wei, Z. Yu, Z. Jin, L. Xie, J. Huang, D. Cai, X. He, and X.-S. Hua,
    “Dual graph for traffic forecasting,” *IEEE Access*, 2019.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] L. Wei, Z. Yu, Z. Jin, L. Xie, J. Huang, D. Cai, X. He, 和 X.-S. Hua，“用于交通预测的双图模型，”
    *IEEE Access*，2019 年。'
- en: '[42] W. Chen, L. Chen, Y. Xie, W. Cao, Y. Gao, and X. Feng, “Multi-range attentive
    bicomponent graph convolutional network for traffic forecasting,” *AAAI*, 2020.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] W. Chen, L. Chen, Y. Xie, W. Cao, Y. Gao, 和 X. Feng，“用于交通预测的多范围注意双组件图卷积网络，”
    *AAAI*，2020 年。'
- en: '[43] Z. Cao, S. Jiang, J. Zhang, and H. Guo, “A unified framework for vehicle
    rerouting and traffic light control to reduce traffic congestion,” *IEEE Transactions
    on Intelligent Transportation Systems*, vol. 18, no. 7, pp. 1958–1973, 2017.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Z. Cao, S. Jiang, J. Zhang, 和 H. Guo，“一个统一的框架用于车辆重新规划和交通信号灯控制以减少交通拥堵，”
    *IEEE 智能交通系统学报*，第 18 卷，第 7 期，页码 1958–1973，2017 年。'
- en: '[44] L. Qi, M. Zhou, and W. Luan, “A two-level traffic light control strategy
    for preventing incident-based urban traffic congestion,” *IEEE Transactions on
    Intelligent Transportation Systems*, vol. 19, no. 1, pp. 13–24, 2018.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] L. Qi, M. Zhou, 和 W. Luan，“一种双层交通信号灯控制策略用于防止基于事件的城市交通拥堵，” *IEEE 智能交通系统学报*，第
    19 卷，第 1 期，页码 13–24，2018 年。'
- en: '[45] J. Ye, J. Zhao, K. Ye, and C. Xu, “Multi-stgcnet: A graph convolution
    based spatial-temporal framework for subway passenger flow forecasting,” in *2020
    International Joint Conference on Neural Networks (IJCNN)*, 2020, pp. 1–8.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] J. Ye, J. Zhao, K. Ye, 和 C. Xu，“Multi-stgcnet：一种基于图卷积的时空框架用于地铁客流预测，” 在
    *2020 国际神经网络联合会议 (IJCNN)*，2020 年，页码 1–8。'
- en: '[46] F. Rodrigues, I. Markou, and F. C. Pereira, “Combining time-series and
    textual data for taxi demand prediction in event areas: A deep learning approach,”
    *Information Fusion*, vol. 49, pp. 120–129, 2019.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] F. Rodrigues, I. Markou, 和 F. C. Pereira，“结合时间序列和文本数据进行事件区域出租车需求预测：一种深度学习方法，”
    *信息融合*，第 49 卷，页码 120–129，2019 年。'
- en: '[47] D. Wang, W. Cao, J. Li, and J. Ye, “Deepsd: Supply-demand prediction for
    online car-hailing services using deep neural networks,” in *ICDE*, 2017, pp.
    243–254.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] D. Wang, W. Cao, J. Li, 和 J. Ye，“Deepsd：使用深度神经网络进行在线打车服务的供需预测，” 在 *ICDE*，2017
    年，页码 243–254。'
- en: '[48] D. Chai, L. Wang, and Q. Yang, “Bike flow prediction with multi-graph
    convolutional networks,” in *SIGSPATIAL*, 2018.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] D. Chai, L. Wang, 和 Q. Yang，“使用多图卷积网络进行单车流量预测，” 在 *SIGSPATIAL*，2018 年。'
- en: '[49] L. Lin, Z. He, and S. Peeta, “Predicting station-level hourly demand in
    a large-scale bike-sharing network: A graph convolutional neural network approach,”
    *Transportation Research Part C: Emerging Technologies*, vol. 97, pp. 258–276,
    2018.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] L. Lin, Z. He, 和 S. Peeta，“在大规模共享单车网络中预测站点级每小时需求：一种图卷积神经网络方法，” *运输研究 C
    部分：新兴技术*，第 97 卷，页码 258–276，2018 年。'
- en: '[50] X. Han, T. Grubenmann, R. Cheng, S. C. Wong, X. Li, and W. Sun, “Traffic
    incident detection: A trajectory-based approach,” in *ICDE*, 2020, pp. 1866–1869.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] X. Han, T. Grubenmann, R. Cheng, S. C. Wong, X. Li, 和 W. Sun，“交通事件检测：一种基于轨迹的方法，”
    在 *ICDE*，2020 年，页码 1866–1869。'
- en: '[51] Z. Zhang, Q. He, J. Gao, and M. Ni, “A deep learning approach for detecting
    traffic accidents from social media data,” *Transportation Research Part C: Emerging
    Technologies*, vol. 86, pp. 580–596, 2018.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Z. Zhang, Q. He, J. Gao, 和 M. Ni，“一种深度学习方法用于从社交媒体数据中检测交通事故，” *运输研究 C 部分：新兴技术*，第
    86 卷，页码 580–596，2018 年。'
- en: '[52] M. I. Sameen and B. Pradhan, “Severity prediction of traffic accidents
    with recurrent neural networks,” *Applied Sciences*, 2017.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] M. I. Sameen 和 B. Pradhan，“使用递归神经网络进行交通事故严重性预测，” *应用科学*，2017 年。'
- en: '[53] S. Alkheder, M. Taamneh, and S. Taamneh, “Severity prediction of traffic
    accident using an artificial neural network,” *Journal of Forecasting*, vol. 36,
    no. 1, pp. 100–108, 2017.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] S. Alkheder, M. Taamneh, 和 S. Taamneh，“使用人工神经网络进行交通事故严重性预测，” *预测学报*，第
    36 卷，第 1 期，页码 100–108，2017 年。'
- en: '[54] A. M. Kashevnik, I. Lashkov, and A. V. Gurtov, “Methodology and mobile
    application for driver behavior analysis and accident prevention,” *IEEE Transactions
    on Intelligent Transportation Systems*, vol. 21, no. 6, pp. 2427–2436, 2020.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] A. M. Kashevnik, I. Lashkov, 和 A. V. Gurtov，“驾驶行为分析与事故预防的方法论与移动应用”，*IEEE
    Transactions on Intelligent Transportation Systems*，第21卷，第6期，第2427–2436页，2020年。'
- en: '[55] M. Hanninen, “Bayesian networks for maritime traffic accident prevention:
    benefits and challenges,” *Accident Analysis & Prevention*, vol. 73, pp. 305–312,
    2014.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] M. Hanninen，“用于海事交通事故预防的贝叶斯网络：益处与挑战”，*Accident Analysis & Prevention*，第73卷，第305–312页，2014年。'
- en: '[56] B. Jo, Y. Lee, R. M. A. Khan, J. Kim, and D. Kim, “Robust construction
    safety system (RCSS) for collision accidents prevention on construction sites,”
    *Sensors*, vol. 19, no. 4, p. 932, 2019.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] B. Jo, Y. Lee, R. M. A. Khan, J. Kim, 和 D. Kim，“用于施工现场碰撞事故预防的鲁棒建设安全系统（RCSS）”，*Sensors*，第19卷，第4期，第932页，2019年。'
- en: '[57] W. Qiu, H. Chen, and B. An, “Dynamic electronic toll collection via multi-agent
    deep reinforcement learning with edge-based graph convolutional networks,” in
    *IJCAI*, 2019, pp. 4568–4574.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] W. Qiu, H. Chen, 和 B. An，“通过边缘图卷积网络的多智能体深度强化学习进行动态电子收费”，发表于*IJCAI*，2019，第4568–4574页。'
- en: '[58] H. Li, P. Wang, and C. Shen, “Toward end-to-end car license plate detection
    and recognition with deep neural networks,” *IEEE Transactions on Intelligent
    Transportation Systems*, vol. 20, no. 3, pp. 1126–1136, 2019.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] H. Li, P. Wang, 和 C. Shen，“基于深度神经网络的端到端汽车车牌检测与识别”，*IEEE Transactions on
    Intelligent Transportation Systems*，第20卷，第3期，第1126–1136页，2019年。'
- en: '[59] X. Chen, S. Xiang, C.-L. Liu, and C.-H. Pan, “Vehicle detection in satellite
    images by hybrid deep convolutional neural networks,” *IEEE Geoscience and remote
    sensing letters*, 2014.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] X. Chen, S. Xiang, C.-L. Liu, 和 C.-H. Pan，“通过混合深度卷积神经网络在卫星图像中进行车辆检测”，*IEEE
    Geoscience and remote sensing letters*，2014年。'
- en: '[60] S. Zhang, J. Yang, and B. Schiele, “Occluded pedestrian detection through
    guided attention in cnns,” in *CVPR*, 2018, pp. 6995–7003.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] S. Zhang, J. Yang, 和 B. Schiele，“通过CNN中的引导注意力进行遮挡行人检测”，发表于*CVPR*，2018，第6995–7003页。'
- en: '[61] H. Tayara, K. G. Soo, and K. T. Chong, “Vehicle detection and counting
    in high-resolution aerial images using convolutional regression neural network,”
    *IEEE Access*, vol. 6, pp. 2220–2230, 2017.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] H. Tayara, K. G. Soo, 和 K. T. Chong，“使用卷积回归神经网络在高分辨率航空图像中进行车辆检测与计数”，*IEEE
    Access*，第6卷，第2220–2230页，2017年。'
- en: '[62] J. Li, X. Liang, S. Shen, T. Xu, J. Feng, and S. Yan, “Scale-aware fast
    r-cnn for pedestrian detection,” *IEEE transactions on Multimedia*, vol. 20, no. 4,
    pp. 985–996, 2017.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] J. Li, X. Liang, S. Shen, T. Xu, J. Feng, 和 S. Yan，“尺度感知快速R-CNN用于行人检测”，*IEEE
    transactions on Multimedia*，第20卷，第4期，第985–996页，2017年。'
- en: '[63] M. A. S. Kamal, T. Hayakawa, and J. Imura, “Development and evaluation
    of an adaptive traffic signal control scheme under a mixed-automated traffic scenario,”
    *IEEE Transactions on Intelligent Transportation Systems*, vol. 21, no. 2, pp.
    590–602, 2020.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] M. A. S. Kamal, T. Hayakawa, 和 J. Imura，“在混合自动化交通场景下的自适应交通信号控制方案的开发与评估”，*IEEE
    Transactions on Intelligent Transportation Systems*，第21卷，第2期，第590–602页，2020年。'
- en: '[64] J. Li, H. Ma, Z. Zhang, and M. Tomizuka, “Social-wagdat: Interaction-aware
    trajectory prediction via wasserstein graph double-attention network,” *arxiv:2002.06241*,
    2020.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] J. Li, H. Ma, Z. Zhang, 和 M. Tomizuka，“Social-wagdat：通过Wasserstein图双重注意力网络进行互动感知的轨迹预测”，*arxiv:2002.06241*，2020年。'
- en: '[65] S. Mylavarapu, M. Sandhu, P. Vijayan, K. M. Krishna, B. Ravindran, and
    A. Namboodiri, “Towards accurate vehicle behaviour classification with multi-relational
    graph convolutional networks,” *arXiv:2002.00786*, 2020.'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] S. Mylavarapu, M. Sandhu, P. Vijayan, K. M. Krishna, B. Ravindran, 和 A.
    Namboodiri，“通过多关系图卷积网络实现准确的车辆行为分类”，*arXiv:2002.00786*，2020年。'
- en: '[66] J. Li, Z. Han, H. Cheng, J. Su, P. Wang, J. Zhang, and L. Pan, “Predicting
    path failure in time-evolving graphs,” in *KDD*, 2019, pp. 1279–1289.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] J. Li, Z. Han, H. Cheng, J. Su, P. Wang, J. Zhang, 和 L. Pan，“在时间演变图中预测路径失败”，发表于*KDD*，2019，第1279–1289页。'
- en: '[67] T. Nishi, K. Otaki, K. Hayakawa, and T. Yoshimura, “Traffic signal control
    based on reinforcement learning with graph convolutional neural nets,” in *ITSC*,
    2018, pp. 877–883.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] T. Nishi, K. Otaki, K. Hayakawa, 和 T. Yoshimura，“基于图卷积神经网络的强化学习交通信号控制”，发表于*ITSC*，2018，第877–883页。'
- en: '[68] Q. Zhang, Q. Jin, J. Chang, S. Xiang, and C. Pan, “Kernel-weighted graph
    convolutional network: A deep learning approach for traffic forecasting,” in *ICPR*,
    2018, pp. 1018–1023.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] Q. Zhang, Q. Jin, J. Chang, S. Xiang, 和 C. Pan，“核加权图卷积网络：一种用于交通预测的深度学习方法”，发表于*ICPR*，2018，第1018–1023页。'
- en: '[69] S. Guo, Y. Lin, N. Feng, C. Song, and H. Wan, “Attention based spatial-temporal
    graph convolutional networks for traffic flow forecasting,” in *AAAI*, 2019, pp.
    922–929.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] S. Guo, Y. Lin, N. Feng, C. Song, 和 H. Wan，“基于注意力的时空图卷积网络用于交通流量预测”，发表于*AAAI*，2019年，页码922–929。'
- en: '[70] L. Ge, H. Li, J. Liu, and A. Zhou, “Temporal graph convolutional networks
    for traffic speed prediction considering external factors,” in *MDM*, 2019, pp.
    234–242.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] L. Ge, H. Li, J. Liu, 和 A. Zhou，“考虑外部因素的交通速度预测的时间图卷积网络”，发表于*MDM*，2019年，页码234–242。'
- en: '[71] B. Yu, M. Li, J. Zhang, and Z. Zhu, “3d graph convolutional networks with
    temporal graphs: A spatial information free framework for traffic forecasting,”
    *arXiv:1903.00919*, 2019.'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] B. Yu, M. Li, J. Zhang, 和 Z. Zhu，“带有时间图的3D图卷积网络：用于交通预测的空间信息自由框架”，*arXiv:1903.00919*，2019年。'
- en: '[72] J. Hu, C. Guo, B. Yang, and C. S. Jensen, “Stochastic weight completion
    for road networks using graph convolutional networks,” in *ICDE*, 2019, pp. 1274–1285.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] J. Hu, C. Guo, B. Yang, 和 C. S. Jensen，“使用图卷积网络的道路网络随机权重补全”，发表于*ICDE*，2019年，页码1274–1285。'
- en: '[73] D. Wang, J. Zhang, W. Cao, J. Li, and Y. Zheng, “When will you arrive?
    estimating travel time based on deep neural networks,” in *AAAI*, 2018.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] D. Wang, J. Zhang, W. Cao, J. Li, 和 Y. Zheng，“你什么时候到？基于深度神经网络的旅行时间估计”，发表于*AAAI*，2018年。'
- en: '[74] L. Yan, H. Shen, Z. Li, A. Sarker, J. A. Stankovic, C. Qiu, J. Zhao, and
    C. Xu, “Employing opportunistic charging for electric taxicabs to reduce idle
    time,” *Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.*, vol. 2, no. 1,
    pp. 47:1–47:25, 2018.'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] L. Yan, H. Shen, Z. Li, A. Sarker, J. A. Stankovic, C. Qiu, J. Zhao, 和
    C. Xu，“利用机会充电减少电动出租车的空闲时间”，*Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.*，第2卷，第1期，页码47:1–47:25，2018年。'
- en: '[75] X. Geng, X. Wu, L. Zhang, Q. Yang, Y. Liu, and J. Ye, “Multi-modal graph
    interaction for multi-graph convolution network in urban spatiotemporal forecasting,”
    *arXiv:1905.11395*, 2019.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] X. Geng, X. Wu, L. Zhang, Q. Yang, Y. Liu, 和 J. Ye，“用于城市时空预测的多模态图交互多图卷积网络”，*arXiv:1905.11395*，2019年。'
- en: '[76] L. Bai, L. Yao, S. S. Kanhere, X. Wang, and Q. Z. Sheng, “Stg2seq: Spatial-temporal
    graph to sequence model for multi-step passenger demand forecasting,” in *IJCAI*,
    2019, pp. 1981–1987.'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] L. Bai, L. Yao, S. S. Kanhere, X. Wang, 和 Q. Z. Sheng，“Stg2seq: 空间-时间图到序列模型用于多步乘客需求预测”，发表于*IJCAI*，2019年，页码1981–1987。'
- en: '[77] J. Chen, L. Liu, H. Wu, J. Zhen, G. Li, and L. Lin, “Physical-virtual
    collaboration graph network for station-level metro ridership prediction,” *arXiv:2001.04889*,
    2020.'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] J. Chen, L. Liu, H. Wu, J. Zhen, G. Li, 和 L. Lin，“站级地铁乘客量预测的物理-虚拟协作图网络”，*arXiv:2001.04889*，2020年。'
- en: '[78] Z. Li, N. D. Sergin, H. Yan, C. Zhang, and F. Tsung, “Tensor completion
    for weakly-dependent data on graph for metro passenger flow prediction,” *AAAI*,
    2020.'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] Z. Li, N. D. Sergin, H. Yan, C. Zhang, 和 F. Tsung，“用于地铁乘客流预测的图上弱依赖数据的张量补全”，*AAAI*，2020年。'
- en: '[79] J. Ye, J. Zhao, L. Zhang, C. Xu, J. Zhang, and K. Ye, “A data-driven method
    for dynamic OD passenger flow matrix estimation in urban metro systems,” in *BigData
    2020*, vol. 12402.   Springer, 2020, pp. 116–126.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] J. Ye, J. Zhao, L. Zhang, C. Xu, J. Zhang, 和 K. Ye，“用于城市地铁系统动态OD乘客流矩阵估计的数据驱动方法”，发表于*BigData
    2020*，第12402卷。  Springer，2020年，页码116–126。'
- en: '[80] H. Shi, Q. Yao, Q. Guo, Y. Li, L. Zhang, J. Ye, Y. Li, and Y. Liu, “Predicting
    origin-destination flow via multi-perspective graph convolutional network,” in
    *ICDE*, 2020, pp. 1818–1821.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] H. Shi, Q. Yao, Q. Guo, Y. Li, L. Zhang, J. Ye, Y. Li, 和 Y. Liu，“通过多视角图卷积网络预测起始-目的地流量”，发表于*ICDE*，2020年，页码1818–1821。'
- en: '[81] J. Hu, B. Yang, C. Guo, C. S. Jensen, and H. Xiong, “Stochastic origin-destination
    matrix forecasting using dual-stage graph convolutional, recurrent neural networks,”
    in *ICDE*, 2020, pp. 1417–1428.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] J. Hu, B. Yang, C. Guo, C. S. Jensen, 和 H. Xiong，“使用双阶段图卷积和递归神经网络的随机起始-目的地矩阵预测”，发表于*ICDE*，2020年，页码1417–1428。'
- en: '[82] K. F. Chu, A. Y. S. Lam, and V. O. K. Li, “Deep multi-scale convolutional
    LSTM network for travel demand and origin-destination predictions,” *IEEE Transactions
    on Intelligent Transportation Systems*, vol. 21, no. 8, pp. 3219–3232, 2020.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] K. F. Chu, A. Y. S. Lam, 和 V. O. K. Li，“用于旅行需求和起始-目的地预测的深度多尺度卷积LSTM网络”，*IEEE
    Transactions on Intelligent Transportation Systems*，第21卷，第8期，页码3219–3232，2020年。'
- en: '[83] Y. Sun, T. He, J. Hu, H. Huang, and B. Chen, “Socially-aware graph convolutional
    network for human trajectory prediction,” in *ITNEC*, 2019, pp. 325–333.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] Y. Sun, T. He, J. Hu, H. Huang, 和 B. Chen，“社会感知图卷积网络用于人类轨迹预测”，发表于*ITNEC*，2019年，页码325–333。'
- en: '[84] A. Monti, A. Bertugli, S. Calderara, and R. Cucchiara, “Dag-net: Double
    attentive graph neural network for trajectory forecasting,” *Carxiv:2005.12661*,
    2020.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] A. Monti, A. Bertugli, S. Calderara, 和 R. Cucchiara，“Dag-net: 双重注意力图神经网络用于轨迹预测”，*Carxiv:2005.12661*，2020年。'
- en: '[85] A. Mohamed, K. Qian, M. Elhoseiny, and C. Claudel, “Social-stgcnn: A social
    spatio-temporal graph convolutional neural network for human trajectory prediction,”
    in *CVPR*, 2020, pp. 14 412–14 420.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] A. Mohamed, K. Qian, M. Elhoseiny, 和 C. Claudel, “Social-stgcnn：一种用于人类轨迹预测的社会时空图卷积神经网络，”
    在 *CVPR*，2020，pp. 14 412–14 420。'
- en: '[86] J. Li, F. Yang, M. Tomizuka, and C. Choi, “Evolvegraph: Heterogeneous
    multi-agent multi-modal trajectory prediction with evolving interaction graphs,”
    *arxiv:2003.13924*, 2020.'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] J. Li, F. Yang, M. Tomizuka, 和 C. Choi, “Evolvegraph：具有演变交互图的异质多智能体多模态轨迹预测，”
    *arxiv:2003.13924*，2020。'
- en: '[87] V. Kosaraju, A. Sadeghian, R. Martín-Martín, I. D. Reid, H. Rezatofighi,
    and S. Savarese, “Social-bigat: Multimodal trajectory forecasting using bicycle-gan
    and graph attention networks,” in *NIPS*, 2019, pp. 137–146.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] V. Kosaraju, A. Sadeghian, R. Martín-Martín, I. D. Reid, H. Rezatofighi,
    和 S. Savarese, “Social-bigat：使用自行车生成对抗网络和图注意力网络的多模态轨迹预测，” 在 *NIPS*，2019，pp. 137–146。'
- en: '[88] Z. Zhao, H. Fang, Z. Jin, and Q. Qiu, “Gisnet: Graph-based information
    sharing network for vehicle trajectory prediction,” *arXiv:2003.11973*, 2020.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] Z. Zhao, H. Fang, Z. Jin, 和 Q. Qiu, “Gisnet：基于图的信息共享网络用于车辆轨迹预测，” *arXiv:2003.11973*，2020。'
- en: '[89] X. Geng, Y. Li, L. Wang, L. Zhang, Q. Yang, J. Ye, and Y. Liu, “Spatiotemporal
    multi-graph convolution network for ride-hailing demand forecasting,” in *AAAI*,
    vol. 33, 2019, pp. 3656–3663.'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] X. Geng, Y. Li, L. Wang, L. Zhang, Q. Yang, J. Ye, 和 Y. Liu, “用于网约车需求预测的时空多图卷积网络，”
    在 *AAAI*，vol. 33，2019，pp. 3656–3663。'
- en: '[90] N. Laptev, J. Yosinski, L. E. Li, and S. Smyl, “Time-series extreme event
    forecasting with neural networks at uber,” in *ICML*, vol. 34, 2017, pp. 1–5.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] N. Laptev, J. Yosinski, L. E. Li, 和 S. Smyl, “在Uber使用神经网络进行时间序列极端事件预测，”
    在 *ICML*，vol. 34，2017，pp. 1–5。'
- en: '[91] Q. Xie, T. Guo, Y. Chen, Y. Xiao, X. Wang, and B. Y. Zhao, “How do urban
    incidents affect traffic speed? A deep graph convolutional network for incident-driven
    traffic speed prediction,” *arXiv:1912.01242*, 2019.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] Q. Xie, T. Guo, Y. Chen, Y. Xiao, X. Wang, 和 B. Y. Zhao, “城市事件如何影响交通速度？一种用于事件驱动交通速度预测的深度图卷积网络，”
    *arXiv:1912.01242*，2019。'
- en: '[92] B. Yu, H. Yin, and Z. Zhu, “Spatio-temporal graph convolutional networks:
    A deep learning framework for traffic forecasting,” in *IJCAI*, 2018, pp. 3634–3640.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] B. Yu, H. Yin, 和 Z. Zhu, “时空图卷积网络：一个用于交通预测的深度学习框架，” 在 *IJCAI*，2018，pp.
    3634–3640。'
- en: '[93] L. Zhao, Y. Song, C. Zhang, Y. Liu, P. Wang, T. Lin, M. Deng, and H. Li,
    “T-gcn: A temporal graph convolutional network for traffic prediction,” *IEEE
    Transactions on Intelligent Transportation Systems*, pp. 1–11, 2019.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] L. Zhao, Y. Song, C. Zhang, Y. Liu, P. Wang, T. Lin, M. Deng, 和 H. Li,
    “T-gcn：一种用于交通预测的时间图卷积网络，” *IEEE智能交通系统汇刊*，pp. 1–11，2019。'
- en: '[94] Z. Cui, K. Henrickson, R. Ke, and Y. Wang, “Traffic graph convolutional
    recurrent neural network: A deep learning framework for network-scale traffic
    learning and forecasting,” *IEEE Transactions on Intelligent Transportation Systems*,
    2019.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] Z. Cui, K. Henrickson, R. Ke, 和 Y. Wang, “交通图卷积递归神经网络：一个用于网络规模交通学习与预测的深度学习框架，”
    *IEEE智能交通系统汇刊*，2019。'
- en: '[95] J. J. Q. Yu and J. Gu, “Real-time traffic speed estimation with graph
    convolutional generative autoencoder,” *IEEE Transactions on Intelligent Transportation
    Systems*, vol. 20, no. 10, pp. 3940–3951, 2019.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] J. J. Q. Yu 和 J. Gu, “基于图卷积生成对抗自编码器的实时交通速度估计，” *IEEE智能交通系统汇刊*，vol. 20，no.
    10，pp. 3940–3951，2019。'
- en: '[96] Y. Huang, Y. Weng, S. Yu, and X. Chen, “Diffusion convolutional recurrent
    neural network with rank influence learning for traffic forecasting,” in *TrustCom*,
    2019, pp. 678–685.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] Y. Huang, Y. Weng, S. Yu, 和 X. Chen, “具有排名影响学习的扩散卷积递归神经网络用于交通预测，” 在 *TrustCom*，2019，pp.
    678–685。'
- en: '[97] J. Li, H. Peng, L. Liu, G. Xiong, B. Du, H. Ma, L. Wang, and M. Z. A.
    Bhuiyan, “Graph cnns for urban traffic passenger flows prediction,” in *SmartWorld*,
    2018, pp. 29–36.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] J. Li, H. Peng, L. Liu, G. Xiong, B. Du, H. Ma, L. Wang, 和 M. Z. A. Bhuiyan,
    “用于城市交通乘客流量预测的图卷积神经网络，” 在 *SmartWorld*，2018，pp. 29–36。'
- en: '[98] C. Zheng, X. Fan, C. Wang, and J. Qi, “Gman: A graph multi-attention network
    for traffic prediction,” 2020.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] C. Zheng, X. Fan, C. Wang, 和 J. Qi, “Gman：一种用于交通预测的图多重注意力网络，” 2020。'
- en: '[99] Z. Diao, X. Wang, D. Zhang, Y. Liu, K. Xie, and S. He, “Dynamic spatial-temporal
    graph convolutional neural networks for traffic forecasting,” in *AAAI*, 2019,
    pp. 890–897.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] Z. Diao, X. Wang, D. Zhang, Y. Liu, K. Xie, 和 S. He, “用于交通预测的动态时空图卷积神经网络，”
    在 *AAAI*，2019，pp. 890–897。'
- en: '[100] Y. Zhang, S. Wang, B. Chen, and J. Cao, “GCGAN: generative adversarial
    nets with graph CNN for network-scale traffic prediction,” in *IJCNN*, 2019, pp.
    1–8.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] Y. Zhang, S. Wang, B. Chen, 和 J. Cao, “GCGAN：用于网络规模交通预测的生成对抗网络与图卷积网络，”
    在 *IJCNN*，2019，pp. 1–8。'
- en: '[101] Y. Wang, H. Yin, H. Chen, T. Wo, J. Xu, and K. Zheng, “Origin-destination
    matrix prediction via graph convolution: a new perspective of passenger demand
    modeling,” in *KDD*, 2019.'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] Y. Wang, H. Yin, H. Chen, T. Wo, J. Xu, 和 K. Zheng，"通过图卷积预测起点-终点矩阵：乘客需求建模的新视角"，在*KDD*，2019年。'
- en: '[102] Z. Wu, S. Pan, G. Long, J. Jiang, and C. Zhang, “Graph wavenet for deep
    spatial-temporal graph modeling,” in *IJCAI*, 2019.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] Z. Wu, S. Pan, G. Long, J. Jiang, 和 C. Zhang，"用于深度空间-时间图建模的图wavenet"，在*IJCAI*，2019年。'
- en: '[103] J. Ke, X. Qin, H. Yang, Z. Zheng, Z. Zhu, and J. Ye, “Predicting origin-destination
    ride-sourcing demand with a spatio-temporal encoder-decoder residual multi-graph
    convolutional network,” *arXiv:1910.09103*, 2019.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] J. Ke, X. Qin, H. Yang, Z. Zheng, Z. Zhu, 和 J. Ye，"使用时空编码器-解码器残差多图卷积网络预测起点-终点乘车需求"，*arXiv:1910.09103*，2019年。'
- en: '[104] Z. Kang, H. Xu, J. Hu, and X. Pei, “Learning dynamic graph embedding
    for traffic flow forecasting: A graph self-attentive method,” 2019, pp. 2570–2576.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] Z. Kang, H. Xu, J. Hu, 和 X. Pei，"用于交通流量预测的动态图嵌入学习：一种图自注意力方法"，2019年，第2570–2576页。'
- en: '[105] B. Yu, H. Yin, and Z. Zhu, “St-unet: A spatio-temporal u-network for
    graph-structured time series modeling,” *arXiv:1903.05631*, 2019.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] B. Yu, H. Yin, 和 Z. Zhu，"St-unet: 用于图结构时间序列建模的时空u网络"，*arXiv:1903.05631*，2019年。'
- en: '[106] K. Guo, Y. Hu, Z. Qian, H. Liu, and e. Zhang, “Optimized graph convolution
    recurrent neural network for traffic prediction,” *IEEE Transactions on Intelligent
    Transportation Systems*, pp. 1–12, 2020.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] K. Guo, Y. Hu, Z. Qian, H. Liu, 和 e. Zhang，"用于交通预测的优化图卷积递归神经网络"，*IEEE
    Transactions on Intelligent Transportation Systems*，第1–12页，2020年。'
- en: '[107] C. Zhang, J. J. Q. Yu, and Y. Liu, “Spatial-temporal graph attention
    networks: A deep learning approach for traffic forecasting,” *IEEE Access*, vol. 7,
    pp. 166 246–166 256, 2019.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] C. Zhang, J. J. Q. Yu, 和 Y. Liu，"时空图注意力网络：用于交通预测的深度学习方法"，*IEEE Access*，第7卷，第166246–166256页，2019年。'
- en: '[108] Y. Li, R. Yu, C. Shahabi, and Y. Liu, “Diffusion convolutional recurrent
    neural network: Data-driven traffic forecasting,” in *ICLR*, 2018.'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] Y. Li, R. Yu, C. Shahabi, 和 Y. Liu，"扩散卷积递归神经网络：数据驱动的交通预测"，在*ICLR*，2018年。'
- en: '[109] M. Lu, K. Zhang, H. Liu, and N. Xiong, “Graph hierarchical convolutional
    recurrent neural network (GHCRNN) for vehicle condition prediction,” *arXiv:1903.06261*,
    2019.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] M. Lu, K. Zhang, H. Liu, 和 N. Xiong，"用于车辆状态预测的图层次卷积递归神经网络（GHCRNN）"，*arXiv:1903.06261*，2019年。'
- en: '[110] Z. Zhang, M. Li, X. Lin, Y. Wang, and F. He, “Multistep speed prediction
    on traffic networks: A deep learning approach considering spatio-temporal dependencies,”
    *Transportation Research Part C: Emerging Technologies*, vol. 105, pp. 297–322,
    2019.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] Z. Zhang, M. Li, X. Lin, Y. Wang, 和 F. He，"交通网络上的多步速度预测：考虑时空依赖的深度学习方法"，*Transportation
    Research Part C: Emerging Technologies*，第105卷，第297–322页，2019年。'
- en: '[111] S. Fang, Q. Zhang, G. Meng, S. Xiang, and C. Pan, “Gstnet: Global spatial-temporal
    network for traffic flow prediction,” in *IJCAI*, 2019, pp. 2286–2293.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] S. Fang, Q. Zhang, G. Meng, S. Xiang, 和 C. Pan，"Gstnet: 用于交通流量预测的全球空间-时间网络"，在*IJCAI*，2019年，第2286–2293页。'
- en: '[112] C. Chen, K. Li, S. G. Teo, X. Zou, K. Wang, J. Wang, and Z. Zeng, “Gated
    residual recurrent graph neural networks for traffic prediction,” in *AAAI*, 2019,
    pp. 485–492.'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] C. Chen, K. Li, S. G. Teo, X. Zou, K. Wang, J. Wang, 和 Z. Zeng，"用于交通预测的门控残差递归图神经网络"，在*AAAI*，2019年，第485–492页。'
- en: '[113] L. Bai, L. Yao, S. S. Kanhere, X. Wang, W. Liu, and Z. Yang, “Spatio-temporal
    graph convolutional and recurrent networks for citywide passenger demand prediction,”
    in *CIKM*, 2019, pp. 2293–2296.'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] L. Bai, L. Yao, S. S. Kanhere, X. Wang, W. Liu, 和 Z. Yang，"用于城市范围乘客需求预测的时空图卷积和递归网络"，在*CIKM*，2019年，第2293–2296页。'
- en: '[114] S. Yan, Y. Xiong, and D. Lin, “Spatial temporal graph convolutional networks
    for skeleton-based action recognition,” in *AAAI*, 2018, pp. 7444–7452.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] S. Yan, Y. Xiong, 和 D. Lin，"用于骨架动作识别的时空图卷积网络"，在*AAAI*，2018年，第7444–7452页。'
- en: '[115] M. Wang, B. Lai, Z. Jin, Y. Lin, X. Gong, J. Huang, and X. Hua, “Dynamic
    spatio-temporal graph-based cnns for traffic prediction,” *arXiv:1812.02019*,
    2018.'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] M. Wang, B. Lai, Z. Jin, Y. Lin, X. Gong, J. Huang, 和 X. Hua，"用于交通预测的动态时空图卷积神经网络"，*arXiv:1812.02019*，2018年。'
- en: '[116] J. Sun, J. Zhang, Q. Li, X. Yi, and Y. Zheng, “Predicting citywide crowd
    flows in irregular regions using multi-view graph convolutional networks,” *arXiv:1903.07789*,
    2019.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] J. Sun, J. Zhang, Q. Li, X. Yi, 和 Y. Zheng，"使用多视角图卷积网络预测不规则区域的城市范围人群流动"，*arXiv:1903.07789*，2019年。'
- en: '[117] Y. Zhang, T. Cheng, and Y. Ren, “A graph deep learning method for short-term
    traffic forecasting on large road networks,” *Computer-Aided Civil and Infrastructure
    Engineering*, vol. 34, no. 10, pp. 877–896, 2019.'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] Y. Zhang、T. Cheng 和 Y. Ren，“一种用于大型道路网络短期交通预测的图深度学习方法”，*计算机辅助土木与基础设施工程*，第34卷，第10期，第877–896页，2019年。'
- en: '[118] X. Zhou, Y. Shen, and L. Huang, “Revisiting flow information for traffic
    prediction,” *arXiv:1906.00560*, 2019.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] X. Zhou、Y. Shen 和 L. Huang，“重新审视流信息以进行交通预测”，*arXiv:1906.00560*，2019年。'
- en: '[119] J. Zhang, X. Shi, J. Xie, H. Ma, I. King, and D. Yeung, “Gaan: Gated
    attention networks for learning on large and spatiotemporal graphs,” in *UAI*,
    2018, pp. 339–349.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] J. Zhang、X. Shi、J. Xie、H. Ma、I. King 和 D. Yeung，“Gaan：用于大规模和时空图学习的门控注意力网络”，发表于
    *UAI*，2018年，第339–349页。'
- en: '[120] Y. Y. Shin and Y. Yoon, “Incorporating dynamicity of transportation network
    with multi-weight traffic graph convolution for traffic forecasting,” *arXiv:1909.07105*,
    2019.'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] Y. Y. Shin 和 Y. Yoon，“结合交通网络动态性的多权重交通图卷积用于交通预测”，*arXiv:1909.07105*，2019年。'
- en: '[121] A. Majumdar, “Graph structured autoencoder,” *Neural Networks*, vol.
    106, pp. 271–280, 2018.'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] A. Majumdar，“图结构自编码器”，*神经网络*，第106卷，第271–280页，2018年。'
- en: '[122] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Liò, and Y. Bengio,
    “Graph attention networks,” in *ICLR*, 2018.'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] P. Velickovic、G. Cucurull、A. Casanova、A. Romero、P. Liò 和 Y. Bengio，“图注意力网络”，发表于
    *ICLR*，2018年。'
- en: '[123] W. L. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation learning
    on large graphs,” in *NIPS*, 2017, pp. 1024–1034.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] W. L. Hamilton、Z. Ying 和 J. Leskovec，“大规模图上的归纳表示学习”，发表于 *NIPS*，2017年，第1024–1034页。'
- en: '[124] D. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, and P. Vandergheynst,
    “The emerging field of signal processing on graphs: Extending high-dimensional
    data analysis to networks and other irregular domains,” *IEEE Signal Processing
    Magazine*, vol. 30, no. 3, pp. 83–98, 2013.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] D. I. Shuman、S. K. Narang、P. Frossard、A. Ortega 和 P. Vandergheynst，“图上的信号处理新兴领域：将高维数据分析扩展到网络和其他不规则领域”，*IEEE信号处理杂志*，第30卷，第3期，第83–98页，2013年。'
- en: '[125] J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun, “Spectral networks and
    locally connected networks on graphs,” in *ICLR*, 2014.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] J. Bruna、W. Zaremba、A. Szlam 和 Y. LeCun，“图上的谱网络和局部连接网络”，发表于 *ICLR*，2014年。'
- en: '[126] M. Defferrard, X. Bresson, and P. Vandergheynst, “Convolutional neural
    networks on graphs with fast localized spectral filtering,” in *NIPS*, 2016, pp.
    3837–3845.'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] M. Defferrard、X. Bresson 和 P. Vandergheynst，“带有快速局部谱滤波的图卷积神经网络”，发表于 *NIPS*，2016年，第3837–3845页。'
- en: '[127] D. K. Hammond, P. Vandergheynst, and R. Gribonval, “Wavelets on graphs
    via spectral graph theory,” *Applied and Computational Harmonic Analysis*, vol. 30,
    no. 2, pp. 129–150, 2011.'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] D. K. Hammond、P. Vandergheynst 和 R. Gribonval，“通过谱图理论在图上进行小波变换”，*应用与计算谐波分析*，第30卷，第2期，第129–150页，2011年。'
- en: '[128] T. N. Kipf and M. Welling, “Semi-supervised classification with graph
    convolutional networks,” in *ICLR*, 2017.'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] T. N. Kipf 和 M. Welling，“使用图卷积网络的半监督分类”，发表于 *ICLR*，2017年。'
- en: '[129] S. Teng, “Scalable algorithms for data and network analysis,” *Foundations
    and Trends in Theoretical Computer Science*, vol. 12, no. 1-2, pp. 1–274, 2016.'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] S. Teng，“用于数据和网络分析的可扩展算法”，*理论计算机科学基础与趋势*，第12卷，第1-2期，第1–274页，2016年。'
- en: '[130] S.-H. Teng, “Scalable algorithms for data and network analysis,” *Foundations
    and Trends® in Theoretical Computer Science*, vol. 12, no. 1-2, pp. 1–274, 2016.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] S.-H. Teng，“用于数据和网络分析的可扩展算法”，*理论计算机科学基础与趋势®*，第12卷，第1-2期，第1–274页，2016年。'
- en: '[131] J. Zhang, Y. Zheng, and D. Qi, “Deep spatio-temporal residual networks
    for citywide crowd flows prediction,” in *AAAI*, 2017.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] J. Zhang、Y. Zheng 和 D. Qi，“用于城市范围人群流动预测的深度时空残差网络”，发表于 *AAAI*，2017年。'
- en: '[132] S. Du, T. Li, X. Gong, and S. Horng, “A hybrid method for traffic flow
    forecasting using multimodal deep learning,” *International Journal of Computational
    Intelligence Systems*, vol. 13, no. 1, pp. 85–97, 2020.'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] S. Du、T. Li、X. Gong 和 S. Horng，“一种使用多模态深度学习的交通流预测混合方法”，*国际计算智能系统期刊*，第13卷，第1期，第85–97页，2020年。'
- en: '[133] R. M. Schmidt, “Recurrent neural networks (rnns): A gentle introduction
    and overview,” *arXiv:1912.05911*, 2019.'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] R. M. Schmidt，“递归神经网络（RNNs）：温和介绍和概述”，*arXiv:1912.05911*，2019年。'
- en: '[134] Y. Bengio, P. Y. Simard, and P. Frasconi, “Learning long-term dependencies
    with gradient descent is difficult,” *IEEE Trans. Neural Networks*, vol. 5, no. 2,
    pp. 157–166, 1994.'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] Y. Bengio、P. Y. Simard 和 P. Frasconi，“通过梯度下降学习长期依赖关系是困难的”，*IEEE神经网络汇刊*，第5卷，第2期，第157–166页，1994年。'
- en: '[135] H. Salehinejad, S. Sankar, J. Barfett, E. Colak, and S. Valaee, “Recent
    advances in recurrent neural networks,” *arXiv:1801.01078*, 2017.'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] H. Salehinejad, S. Sankar, J. Barfett, E. Colak 和 S. Valaee, “递归神经网络的最新进展，”
    *arXiv:1801.01078*，2017年。'
- en: '[136] I. Sutskever, J. Martens, G. E. Dahl, and G. E. Hinton, “On the importance
    of initialization and momentum in deep learning,” in *ICML*, vol. 28, 2013, pp.
    1139–1147.'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] I. Sutskever, J. Martens, G. E. Dahl 和 G. E. Hinton, “深度学习中初始化和动量的重要性，”发表于
    *ICML*，第28卷，2013年，第1139–1147页。'
- en: '[137] G. Chen, “A gentle tutorial of recurrent neural network with error backpropagation,”
    *arXiv:1610.02583*, 2016.'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] G. Chen, “递归神经网络及误差反向传播的温和教程，” *arXiv:1610.02583*，2016年。'
- en: '[138] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” *Neural Computation*,
    vol. 9, no. 8, pp. 1735–1780, 1997.'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] S. Hochreiter 和 J. Schmidhuber, “长短期记忆，” *Neural Computation*，第9卷，第8期，第1735–1780页，1997年。'
- en: '[139] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, “Empirical evaluation of
    gated recurrent neural networks on sequence modeling,” in *NIPS Workshop*, 2014.'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] J. Chung, C. Gulcehre, K. Cho 和 Y. Bengio, “门控递归神经网络在序列建模中的实证评估，”发表于
    *NIPS Workshop*，2014年。'
- en: '[140] N. Kalchbrenner, L. Espeholt, K. Simonyan, A. v. d. Oord, A. Graves,
    and K. Kavukcuoglu, “Neural machine translation in linear time,” *arXiv:1610.10099*,
    2016.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] N. Kalchbrenner, L. Espeholt, K. Simonyan, A. v. d. Oord, A. Graves 和
    K. Kavukcuoglu, “线性时间的神经机器翻译，” *arXiv:1610.10099*，2016年。'
- en: '[141] Y. N. Dauphin, A. Fan, M. Auli, and D. Grangier, “Language modeling with
    gated convolutional networks,” in *ICML*, vol. 70, 2017, pp. 933–941.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] Y. N. Dauphin, A. Fan, M. Auli 和 D. Grangier, “使用门控卷积网络进行语言建模，”发表于 *ICML*，第70卷，2017年，第933–941页。'
- en: '[142] A. van den Oord, S. Dieleman, H. Zen, K. Simonyan, O. Vinyals, A. Graves,
    N. Kalchbrenner, A. W. Senior, and K. Kavukcuoglu, “Wavenet: A generative model
    for raw audio,” in *ISCA Workshop*, 2016, pp. 124–125.'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] A. van den Oord, S. Dieleman, H. Zen, K. Simonyan, O. Vinyals, A. Graves,
    N. Kalchbrenner, A. W. Senior 和 K. Kavukcuoglu, “WaveNet：一种生成原始音频的模型，”发表于 *ISCA
    Workshop*，2016年，第124–125页。'
- en: '[143] F. Yu and V. Koltun, “Multi-scale context aggregation by dilated convolutions,”
    in *ICLR*, 2016.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] F. Yu 和 V. Koltun, “通过膨胀卷积进行多尺度上下文聚合，”发表于 *ICLR*，2016年。'
- en: '[144] S. Bai, J. Z. Kolter, and V. Koltun, “An empirical evaluation of generic
    convolutional and recurrent networks for sequence modeling,” *arXiv:1803.01271*,
    2018.'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] S. Bai, J. Z. Kolter 和 V. Koltun, “通用卷积和递归网络在序列建模中的实证评估，” *arXiv:1803.01271*，2018年。'
- en: '[145] I. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to sequence learning
    with neural networks,” in *NIPS*, 2014, pp. 3104–3112.'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] I. Sutskever, O. Vinyals 和 Q. V. Le, “使用神经网络进行序列到序列学习，”发表于 *NIPS*，2014年，第3104–3112页。'
- en: '[146] D. Bahdanau, K. Cho, and Y. Bengio, “Neural machine translation by jointly
    learning to align and translate,” in *ICLR*, 2015.'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] D. Bahdanau, K. Cho 和 Y. Bengio, “通过联合学习对齐和翻译的神经机器翻译，”发表于 *ICLR*，2015年。'
- en: '[147] T. Luong, H. Pham, and C. D. Manning, “Effective approaches to attention-based
    neural machine translation,” in *EMNLP*, 2015, pp. 1412–1421.'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] T. Luong, H. Pham 和 C. D. Manning, “基于注意力的神经机器翻译的有效方法，”发表于 *EMNLP*，2015年，第1412–1421页。'
- en: '[148] S. Bengio, O. Vinyals, N. Jaitly, and N. Shazeer, “Scheduled sampling
    for sequence prediction with recurrent neural networks,” in *NIPS*, 2015, pp.
    1171–1179.'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] S. Bengio, O. Vinyals, N. Jaitly 和 N. Shazeer, “递归神经网络的序列预测中的计划采样，”发表于
    *NIPS*，2015年，第1171–1179页。'
- en: '[149] I. Goodfellow, J. Pouget-Abadie, M. Mirza, and e. Xu, “Generative adversarial
    nets,” in *NIPS*, 2014, pp. 2672–2680.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] I. Goodfellow, J. Pouget-Abadie, M. Mirza 和 e. Xu, “生成对抗网络，”发表于 *NIPS*，2014年，第2672–2680页。'
- en: '[150] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter,
    “Gans trained by a two time-scale update rule converge to a local nash equilibrium,”
    in *NIPS*, 2017, pp. 6626–6637.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler 和 S. Hochreiter, “由双时间尺度更新规则训练的GAN收敛到局部纳什均衡，”发表于
    *NIPS*，2017年，第6626–6637页。'
- en: '[151] A. Creswell, T. White, V. Dumoulin, K. Arulkumaran, B. Sengupta, and
    A. A. Bharath, “Generative adversarial networks: An overview,” *IEEE Signal Process.
    Mag.*, vol. 35, no. 1, pp. 53–65, 2018.'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] A. Creswell, T. White, V. Dumoulin, K. Arulkumaran, B. Sengupta 和 A.
    A. Bharath, “生成对抗网络：概述，” *IEEE Signal Process. Mag.*，第35卷，第1期，第53–65页，2018年。'
- en: '[152] K. Wang, C. Gou, Y. Duan, Y. Lin, X. Zheng, and F. Wang, “Generative
    adversarial networks: introduction and outlook,” *IEEE CAA J. Autom. Sinica*,
    vol. 4, no. 4, pp. 588–598, 2017.'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] K. Wang, C. Gou, Y. Duan, Y. Lin, X. Zheng 和 F. Wang, “生成对抗网络：介绍与展望，”
    *IEEE CAA J. Autom. Sinica*，第4卷，第4期，第588–598页，2017年。'
- en: '[153] Y. Lin, X. Dai, L. Li, and F. Wang, “Pattern sensitive prediction of
    traffic flow based on generative adversarial framework,” *IEEE Transactions on
    Intelligent Transportation Systems*, vol. 20, no. 6, pp. 2395–2400, 2019.'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] Y. Lin, X. Dai, L. Li, 和 F. Wang，“基于生成对抗框架的交通流模式敏感预测，” *IEEE智能交通系统汇刊*，第20卷，第6期，第2395–2400页，2019年。'
- en: '[154] Y. Liang, Z. Cui, Y. Tian, H. Chen, and Y. Wang, “A deep generative adversarial
    architecture for network-wide spatial-temporal traffic-state estimation,” *Transportation
    Research Record*, 2018.'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] Y. Liang, Z. Cui, Y. Tian, H. Chen, 和 Y. Wang，“一种用于网络范围空间-时间交通状态估计的深度生成对抗架构，”
    *交通研究记录*，2018年。'
- en: '[155] H. Yao, F. Wu, J. Ke, X. Tang, Y. Jia, S. Lu, P. Gong, J. Ye, and Z. Li,
    “Deep multi-view spatial-temporal network for taxi demand prediction,” in *AAAI*,
    2018.'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] H. Yao, F. Wu, J. Ke, X. Tang, Y. Jia, S. Lu, P. Gong, J. Ye, 和 Z. Li，“用于出租车需求预测的深度多视角空间-时间网络，”
    见 *AAAI*，2018年。'
- en: '[156] A. Hasanzadeh, E. Hajiramezanali, K. R. Narayanan, N. Duffield, M. Zhou,
    and X. Qian, “Semi-implicit graph variational auto-encoders,” in *NIPS*, 2019,
    pp. 10 711–10 722.'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] A. Hasanzadeh, E. Hajiramezanali, K. R. Narayanan, N. Duffield, M. Zhou,
    和 X. Qian，“半隐式图变分自编码器，” 见 *NIPS*，2019年，第10 711–10 722页。'
- en: '[157] M. Simonovsky and N. Komodakis, “Graphvae: Towards generation of small
    graphs using variational autoencoders,” in *International Conference on Artificial
    Neural Networks*, 2018, pp. 412–422.'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] M. Simonovsky 和 N. Komodakis，“Graphvae: 利用变分自编码器生成小图，” 见 *国际人工神经网络会议*，2018年，第412–422页。'
- en: '[158] H. Dai, Z. Kozareva, B. Dai, A. Smola, and L. Song, “Learning steady-states
    of iterative algorithms over graphs,” in *ICML*, 2018.'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] H. Dai, Z. Kozareva, B. Dai, A. Smola, 和 L. Song，“图上的迭代算法稳态学习，” 见 *ICML*，2018年。'
- en: '| ![[Uncaptioned image]](img/1d7fb309c9e595c71b931c456a475c51.png) | Jiexia
    Ye received the Bachelor’s degree in Economics from Sun Yat-sen University in
    2012\. She is currently working toward M.S. degree in Shenzhen Institutes of Advanced
    Technology, Chinese Academy of Sciences. Her research interests include graph
    neural networks / graph embedding in traffic and finance domain. |'
  id: totrans-628
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/1d7fb309c9e595c71b931c456a475c51.png) | 叶杰霞于2012年获得中山大学经济学学士学位。她目前在中国科学院深圳先进技术研究院攻读硕士学位。她的研究兴趣包括交通和金融领域的图神经网络/图嵌入。
    |'
- en: '| ![[Uncaptioned image]](img/1e81511f7c9e9ea7831b5064d31aa045.png) | Juanjuan
    Zhao received her Ph.D degree from Shenzhen College of Advanced Technology, University
    of Chinese Academy of Sciences in 2017, and received the M.S. degree from the
    Department of Computer Science, Wuhan University of Technology in 2009\. She is
    an Assistant Professor at Shenzhen Institutes of Advanced Technology, Chinese
    Academy of Sciences. Her research topics include data-driven urban systems, mobile
    data collection, cross-domain data fusion, heterogeneous model integration. |'
  id: totrans-629
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/1e81511f7c9e9ea7831b5064d31aa045.png) | 赵娟娟于2017年获得中国科学院大学深圳先进技术学院的博士学位，并于2009年获得武汉理工大学计算机科学系的硕士学位。她是中国科学院深圳先进技术研究院的助理教授。她的研究主题包括数据驱动的城市系统、移动数据采集、跨域数据融合、异构模型集成。
    |'
- en: '| ![[Uncaptioned image]](img/4cd2e27d31c079a359306593a72a77c4.png) | Kejiang
    Ye received his BSc and Ph.D degree in Computer Science from Zhejiang University
    in 2008 and 2013 respectively. He was also a joint Ph.D student at The University
    of Sydney from 2012 to 2013\. After graduation, he worked as Post-Doc Researcher
    at Carnegie Mellon University from 2014 to 2015 and Wayne State University from
    2015 to 2016\. He is currently an Associate Professor at Shenzhen Institutes of
    Advanced Technology, Chinese Academy of Science. His research interests include
    cloud computing, big data and network systems. |'
  id: totrans-630
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/4cd2e27d31c079a359306593a72a77c4.png) | 叶克江于2008年和2013年分别获得浙江大学计算机科学本科和博士学位。他还曾在2012到2013年期间担任悉尼大学的联合博士生。毕业后，他在2014至2015年期间担任卡内基梅隆大学的博士后研究员，并在2015至2016年期间在韦恩州立大学工作。他目前是中国科学院深圳先进技术研究院的副教授。他的研究兴趣包括云计算、大数据和网络系统。
    |'
- en: '| ![[Uncaptioned image]](img/42aa77c8c307ff7b9a0d293d5cee2820.png) | Chengzhong
    Xu received his Ph.D degree from the University of Hong Kong, China in 1993\.
    He is the Dean of the Faculty of State Key Lab of IOTSC, Department of Computer
    Science, University of Macau, Macao SAR, China and a Chair Professor of Computer
    Science of UM. He was a Chief Scientist of Shenzhen Institutes of Advanced Technology
    (SIAT) of Chinese Academy of Sciences and the Director of Institute of Advanced
    Computing and Digital Engineering of SIAT. He was also in the faculty of Wayne
    State University, USA for 18 years. Dr. Xu’s research interest is mainly in the
    areas of parallel and distributed systems, cloud and edge computing, and data-driven
    intelligence. He has published over 300 peer-reviewed papers on these topics with
    over 10K citations. Dr. Xu served in the editorial boards of leading journals,
    including IEEE Transactions on Computers, IEEE Transactions on Cloud Computing,
    IEEE Transactions on Parallel and Distributed Systems and Journal of Parallel
    and Distributed Computing. He is the Associate Editor-in-Chief of ZTE Communication.
    He is IEEE Fellow and the Chair of IEEE Technical Committee of Distributed Processing.
    |'
  id: totrans-631
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/42aa77c8c307ff7b9a0d293d5cee2820.png) | 徐成中于1993年获得香港大学的博士学位。他是澳门大学计算机科学系国家重点实验室的院长，同时也是澳门大学计算机科学的讲座教授。他曾担任中国科学院深圳先进技术研究院（SIAT）的首席科学家，以及SIAT先进计算与数字工程研究所所长。他还曾在美国韦恩州立大学任教18年。徐博士的研究兴趣主要集中在并行和分布式系统、云计算和边缘计算，以及数据驱动智能领域。他在这些领域发表了300多篇同行评审论文，引用超过1万次。徐博士曾在多个领先期刊的编辑委员会服务，包括《IEEE计算机学报》、《IEEE云计算学报》、《IEEE并行与分布式系统学报》和《并行与分布式计算学报》。他是《中兴通讯》的副主编，同时也是IEEE分布式处理技术委员会的主席。'
