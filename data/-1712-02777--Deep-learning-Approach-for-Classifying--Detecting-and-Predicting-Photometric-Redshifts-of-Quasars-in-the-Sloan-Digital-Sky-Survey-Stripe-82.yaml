- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: æœªåˆ†ç±»'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»åˆ«ï¼šæœªåˆ†ç±»
- en: 'date: 2024-09-06 20:08:32'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¥æœŸï¼š2024-09-06 20:08:32
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1712.02777] Deep learning Approach for Classifying, Detecting and Predicting
    Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1712.02777] åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥æ¡çº¹82ä¸­çš„ç±»æ˜Ÿä½“å…‰åº¦çº¢ç§»'
- en: æ¥æºï¼š[https://ar5iv.labs.arxiv.org/html/1712.02777](https://ar5iv.labs.arxiv.org/html/1712.02777)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://ar5iv.labs.arxiv.org/html/1712.02777](https://ar5iv.labs.arxiv.org/html/1712.02777)
- en: 'Â¹Â¹institutetext: LUPM UMR 5299 CNRS/UM, UniversitÃ© de Montpellier, CC 72, 34095
    Montpellier Cedex 05, France Â²Â²institutetext: CPPM, CNRS-IN2P3, UniversitÃ© Aix
    Marseille II, CC 907, 13288 Marseille cedex 9, France'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Â¹Â¹æœºæ„ï¼šLUPM UMR 5299 CNRS/UMï¼Œè’™å½¼åˆ©åŸƒå¤§å­¦ï¼ŒCC 72ï¼Œ34095 è’™å½¼åˆ©åŸƒ Cedex 05ï¼Œæ³•å›½ Â²Â²æœºæ„ï¼šCPPMï¼ŒCNRS-IN2P3ï¼Œæ™®ç½—æ—ºæ–¯-é˜¿å°”å‘æ–¯-è“è‰²æµ·å²¸å¤§å­¦ï¼ŒCC
    907ï¼Œ13288 é©¬èµ› Cedex 9ï¼Œæ³•å›½
- en: 'Â²Â²email: pasquet@cppm.in2p3.fr Â³Â³institutetext: LIRMM UMR 5506 - team ICAR,
    UniversitÃ© de Montpellier, Campus St Priest, 34090 Montpellier â´â´institutetext:
    LSIS UMR 7296, CNRS, ENSAM, UniversitÃ© De Toulon et Aix-Marseille, BÃ¢timent Polytech,
    13397 Marseille'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Â²Â²ç”µå­é‚®ä»¶ï¼špasquet@cppm.in2p3.fr Â³Â³æœºæ„ï¼šLIRMM UMR 5506 - ICARå›¢é˜Ÿï¼Œè’™å½¼åˆ©åŸƒå¤§å­¦ï¼Œåœ£æ™®é‡Œæ–¯ç‰¹æ ¡åŒºï¼Œ34090
    è’™å½¼åˆ©åŸƒ â´â´æœºæ„ï¼šLSIS UMR 7296ï¼ŒCNRSï¼ŒENSAMï¼Œæ‰˜é¾™å¤§å­¦å’Œè‰¾å…‹æ–¯-é©¬èµ›å¤§å­¦ï¼ŒPolytechå¤§æ¥¼ï¼Œ13397 é©¬èµ›
- en: 'â´â´email: jerome.pasquet@lsis.org'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: â´â´ç”µå­é‚®ä»¶ï¼šjerome.pasquet@lsis.org
- en: +
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: +
- en: Deep learning Approach for Classifying, Detecting and Predicting Photometric
    Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥æ¡çº¹82ä¸­çš„ç±»æ˜Ÿä½“å…‰åº¦çº¢ç§»
- en: J. Pasquet-Itam 1122 â€ƒâ€ƒ J. Pasquet 3344(Accepted November 3, 2017)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: J. Pasquet-Itam 1122 â€ƒâ€ƒ J. Pasquet 3344ï¼ˆæ¥å—äº2017å¹´11æœˆ3æ—¥ï¼‰
- en: We apply a convolutional neural network (CNN) to classify and detect quasars
    in the Sloan Digital Sky Survey Stripe 82 and also to predict the photometric
    redshifts of quasars. The network takes the variability of objects into account
    by converting light curves into images. The width of the images, noted $w$, corresponds
    to the five magnitudes ugriz and the height of the images, noted $h$, represents
    the date of the observation. The CNN provides good results since its precision
    is $0.988$ for a recall of $0.90$, compared to a precision of $0.985$ for the
    same recall with a random forest classifier. Moreover 175 new quasar candidates
    are found with the CNN considering a fixed recall of $0.97$. The combination of
    probabilities given by the CNN and the random forest makes good performance even
    better with a precision of $0.99$ for a recall of $0.90$.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åº”ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ¥åˆ†ç±»å’Œæ£€æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥æ¡çº¹82ä¸­çš„ç±»æ˜Ÿä½“ï¼Œå¹¶é¢„æµ‹ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»ã€‚è¯¥ç½‘ç»œé€šè¿‡å°†å…‰æ›²çº¿è½¬æ¢ä¸ºå›¾åƒæ¥è€ƒè™‘å¯¹è±¡çš„å˜åŒ–æ€§ã€‚å›¾åƒçš„å®½åº¦ï¼Œè®°ä½œ$w$ï¼Œå¯¹åº”äºäº”ä¸ªå…‰åº¦ugrizï¼Œå›¾åƒçš„é«˜åº¦ï¼Œè®°ä½œ$h$ï¼Œä»£è¡¨è§‚æµ‹æ—¥æœŸã€‚CNNè¡¨ç°è‰¯å¥½ï¼Œå› ä¸ºå…¶ç²¾åº¦ä¸º$0.988$ï¼Œå¬å›ç‡ä¸º$0.90$ï¼Œè€Œéšæœºæ£®æ—åˆ†ç±»å™¨çš„ç²¾åº¦ä¸º$0.985$ï¼Œå¬å›ç‡ç›¸åŒã€‚æ­¤å¤–ï¼ŒCNNè¿˜å‘ç°äº†175ä¸ªæ–°çš„ç±»æ˜Ÿä½“å€™é€‰è€…ï¼Œå›ºå®šå¬å›ç‡ä¸º$0.97$ã€‚CNNå’Œéšæœºæ£®æ—ç»“åˆçš„æ¦‚ç‡ä½¿å¾—æ€§èƒ½æ›´ä½³ï¼Œç²¾åº¦ä¸º$0.99$ï¼Œå¬å›ç‡ä¸º$0.90$ã€‚
- en: For the redshift predictions, the CNN presents excellent results which are higher
    than those obtained with a feature extraction step and different classifiers (a
    K-nearest-neighbors, a support vector machine, a random forest and a gaussian
    process classifier). Indeed, the accuracy of the CNN within $|\Delta z|<0.1$ can
    reach 78.09$\%$, within $|\Delta z|<0.2$ reaches 86.15$\%$, within $|\Delta z|<0.3$
    reaches 91.2$\%$ and the value of rms is 0.359\. The performance of the KNN decreases
    for the three $|\Delta z|$ regions, since within the accuracy of $|\Delta z|<0.1$,
    $|\Delta z|<0.2$ and $|\Delta z|<0.3$ is 73.72$\%$, 82.46$\%$ and 90.09$\%$ respectively,
    and the value of rms amounts to 0.395\. So the CNN successfully reduces the dispersion
    and the catastrophic redshifts of quasars. This new method is very promising for
    the future of big databases like the Large Synoptic Survey Telescope.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºçº¢ç§»é¢„æµ‹ï¼ŒCNNè¡¨ç°å‡ºä¼˜å¼‚çš„ç»“æœï¼Œä¼˜äºé€šè¿‡ç‰¹å¾æå–æ­¥éª¤å’Œä¸åŒåˆ†ç±»å™¨ï¼ˆKè¿‘é‚»ã€æ”¯æŒå‘é‡æœºã€éšæœºæ£®æ—å’Œé«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨ï¼‰è·å¾—çš„ç»“æœã€‚å®é™…ä¸Šï¼ŒCNNåœ¨$|\Delta
    z|<0.1$æ—¶çš„å‡†ç¡®ç‡å¯è¾¾78.09$\%$ï¼Œåœ¨$|\Delta z|<0.2$æ—¶ä¸º86.15$\%$ï¼Œåœ¨$|\Delta z|<0.3$æ—¶ä¸º91.2$\%$ï¼Œè€Œrmså€¼ä¸º0.359ã€‚KNNåœ¨ä¸‰ä¸ª$|\Delta
    z|$åŒºåŸŸçš„æ€§èƒ½ä¸‹é™ï¼Œå› ä¸ºåœ¨$|\Delta z|<0.1$ã€$|\Delta z|<0.2$å’Œ$|\Delta z|<0.3$çš„å‡†ç¡®ç‡åˆ†åˆ«ä¸º73.72$\%$ã€82.46$\%$å’Œ90.09$\%$ï¼Œè€Œrmså€¼ä¸º0.395ã€‚å› æ­¤ï¼ŒCNNæˆåŠŸå‡å°‘äº†ç±»æ˜Ÿä½“çš„ç¦»æ•£æ€§å’Œç¾éš¾æ€§çº¢ç§»ã€‚è¿™ç§æ–°æ–¹æ³•å¯¹åƒå¤§å‹å·¡å¤©æœ›è¿œé•œè¿™æ ·çš„å¤§å‹æ•°æ®åº“æœªæ¥éå¸¸æœ‰å‰æ™¯ã€‚
- en: 'Key Words.:'
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å…³é”®è¯ï¼š
- en: 'Methods: data analysis â€“ Techniques: photometric â€“ Techniques: image processing
    â€“ quasars: general â€“ Surveys'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹æ³•ï¼šæ•°æ®åˆ†æ â€“ æŠ€æœ¯ï¼šå…‰åº¦å­¦ â€“ æŠ€æœ¯ï¼šå›¾åƒå¤„ç† â€“ ç±»æ˜Ÿä½“ï¼šä¸€èˆ¬ â€“ è°ƒæŸ¥
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 å¼•è¨€
- en: Quasars are powered by accretion onto supermassive black holes at the dynamical
    centers of their host galaxies, producing high luminosities spanning a broad range
    of frequencies. They are of paramount importance in astronomy. For example, their
    studies can inform on massive blackhole (e.g. Portinari etÂ al. ([2012](#bib.bib38))).
    Moreover, as they are the most luminous Active Galactic Nuclei (AGN), they can
    be seen far across the Universe. So they give clues to the evolution and structure
    of galaxies (e.g. Hopkins etÂ al. ([2006](#bib.bib20))). They are also used as
    background objects to study the absorption of intergalactic matter in the line
    of sight, which have many applications in Cosmology (e.g. Lopez etÂ al. ([2008](#bib.bib30))).
    With the advent of large and dedicated surveys such as the Sloan Digital Sky Survey
    (SDSS; York etÂ al. ([2000](#bib.bib50))) and the 2dF Quasar Redshift Survey (2QZ;
    Croom etÂ al. ([2009](#bib.bib10))), the number of known quasars has rapidly increased.
    Thus, the SDSS DR7 Quasar catalog (Schneider etÂ al. ([2010](#bib.bib43))) contains
    105,783 spectroscopically confirmed quasars. The catalog covers an area of $\simeq
    9380\,\,\textrm{deg}^{2}$ and the quasar redshifts range from 0.065 to 5.46.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»æ˜Ÿä½“ç”±ä½äºå…¶å®¿ä¸»æ˜Ÿç³»åŠ¨åŠ›å­¦ä¸­å¿ƒçš„è¶…å¤§è´¨é‡é»‘æ´çš„å¸ç§¯é©±åŠ¨ï¼Œäº§ç”Ÿè·¨è¶Šå¹¿æ³›é¢‘ç‡èŒƒå›´çš„é«˜å…‰åº¦ã€‚å®ƒä»¬åœ¨å¤©æ–‡å­¦ä¸­å…·æœ‰è‡³å…³é‡è¦çš„æ„ä¹‰ã€‚ä¾‹å¦‚ï¼Œå®ƒä»¬çš„ç ”ç©¶å¯ä»¥æä¾›å…³äºå¤§è´¨é‡é»‘æ´çš„ä¿¡æ¯ï¼ˆä¾‹å¦‚
    Portinari ç­‰äºº ([2012](#bib.bib38))ï¼‰ã€‚æ­¤å¤–ï¼Œä½œä¸ºæœ€æ˜äº®çš„æ´»åŠ¨æ˜Ÿç³»æ ¸ï¼ˆAGNï¼‰ï¼Œå®ƒä»¬å¯ä»¥åœ¨å®‡å®™ä¸­é¥è¿œå¤„è¢«è§‚æµ‹åˆ°ã€‚å› æ­¤ï¼Œå®ƒä»¬ä¸ºæ˜Ÿç³»çš„æ¼”åŒ–å’Œç»“æ„æä¾›çº¿ç´¢ï¼ˆä¾‹å¦‚
    Hopkins ç­‰äºº ([2006](#bib.bib20))ï¼‰ã€‚å®ƒä»¬ä¹Ÿè¢«ç”¨ä½œèƒŒæ™¯å¤©ä½“æ¥ç ”ç©¶è§†çº¿ä¸­çš„é“¶æ²³ç³»é—´ç‰©è´¨çš„å¸æ”¶ï¼Œè¿™åœ¨å®‡å®™å­¦ä¸­æœ‰è®¸å¤šåº”ç”¨ï¼ˆä¾‹å¦‚ Lopez
    ç­‰äºº ([2008](#bib.bib30))ï¼‰ã€‚éšç€å¤§å‹ä¸“é—¨è°ƒæŸ¥å¦‚ Sloan Digital Sky Survey (SDSS; York ç­‰äºº ([2000](#bib.bib50)))
    å’Œ 2dF Quasar Redshift Survey (2QZ; Croom ç­‰äºº ([2009](#bib.bib10))) çš„å‡ºç°ï¼Œå·²çŸ¥çš„ç±»æ˜Ÿä½“æ•°é‡è¿…é€Ÿå¢åŠ ã€‚å› æ­¤ï¼ŒSDSS
    DR7 ç±»æ˜Ÿä½“ç›®å½•ï¼ˆSchneider ç­‰äºº ([2010](#bib.bib43))) åŒ…å«äº† 105,783 ä¸ªå…‰è°±ç¡®è®¤çš„ç±»æ˜Ÿä½“ã€‚è¯¥ç›®å½•è¦†ç›–äº† $\simeq
    9380\,\,\textrm{deg}^{2}$ çš„åŒºåŸŸï¼Œç±»æ˜Ÿä½“çš„çº¢ç§»èŒƒå›´ä» 0.065 åˆ° 5.46ã€‚
- en: With the soon coming of the Large Synoptic Survey Telescope (LSST Science Collaboration
    ([2009](#bib.bib31))), it is important to develop classification tools for quasar
    detection given the huge amount of future data. In this way, machine learning
    algorithms are being used increasingly. These algorithms permit to predict the
    label of an object thanks to the extraction of different features which characterize
    the object (e.g. the color of the source). Several classifiers are now commonly
    used in astronomy like random forests which are a set of decision trees (Quinlan
    ([1986](#bib.bib39))), Naives Bayes (Duda & Hart ([1973](#bib.bib12))), Neural
    Networks (Rumelhart etÂ al. ([1986](#bib.bib41))) and Support Vector Machines (Cortes
    & Vapnik ([1995](#bib.bib7))). These methods are very powerful in classification
    and detection of variable objects in astronomy (e.g. Eyer & Blake ([2005](#bib.bib13));
    Dubath etÂ al. ([2011](#bib.bib11)); Blomme etÂ al. ([2011](#bib.bib4)); Rimoldini
    etÂ al. ([2012](#bib.bib40)); Peng etÂ al. ([2012](#bib.bib36)); Peters etÂ al. ([2015](#bib.bib37))).
    We can also cite the recent work of Hernitschek etÂ al. ([2016](#bib.bib19)) on
    the classification and the detection of QSOs in the Pan-STARR S1 (PS1) $3\pi$
    survey. This is a multi-epoch survey that covered three quarters of the sky at
    typically 35 epochs between 2010 and the beginning of 2014 with five filters ($g_{P1}$,
    $r_{P1}$, $i_{P1}$, $z_{P1}$, $y_{P1}$). They use a random forest classifier and
    colors and a structure function as features, to identify 1,000,000 QSO candidates.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€å¤§å‹åŒæ­¥æµ‹å…‰æœ›è¿œé•œï¼ˆLSST Science Collaboration ([2009](#bib.bib31))) çš„å³å°†åˆ°æ¥ï¼Œé‰´äºæœªæ¥æ•°æ®é‡å·¨å¤§ï¼Œå¼€å‘ç±»æ˜Ÿä½“æ£€æµ‹çš„åˆ†ç±»å·¥å…·å˜å¾—å°¤ä¸ºé‡è¦ã€‚å› æ­¤ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•çš„ä½¿ç”¨è¶Šæ¥è¶Šå¤šã€‚è¿™äº›ç®—æ³•é€šè¿‡æå–ä¸åŒçš„ç‰¹å¾ï¼ˆä¾‹å¦‚æºçš„é¢œè‰²ï¼‰æ¥é¢„æµ‹å¯¹è±¡çš„æ ‡ç­¾ã€‚å¤©æ–‡å­¦ä¸­ç°åœ¨å¸¸ç”¨çš„å‡ ä¸ªåˆ†ç±»å™¨åŒ…æ‹¬éšæœºæ£®æ—ï¼ˆQuinlan
    ([1986](#bib.bib39)))ã€æœ´ç´ è´å¶æ–¯ï¼ˆDuda & Hart ([1973](#bib.bib12)))ã€ç¥ç»ç½‘ç»œï¼ˆRumelhart ç­‰äºº
    ([1986](#bib.bib41))) å’Œæ”¯æŒå‘é‡æœºï¼ˆCortes & Vapnik ([1995](#bib.bib7)))ã€‚è¿™äº›æ–¹æ³•åœ¨å¤©æ–‡å­¦ä¸­çš„åˆ†ç±»å’Œå˜æ˜Ÿæ£€æµ‹ä¸­éå¸¸å¼ºå¤§ï¼ˆä¾‹å¦‚
    Eyer & Blake ([2005](#bib.bib13)); Dubath ç­‰äºº ([2011](#bib.bib11)); Blomme ç­‰äºº ([2011](#bib.bib4));
    Rimoldini ç­‰äºº ([2012](#bib.bib40)); Peng ç­‰äºº ([2012](#bib.bib36)); Peters ç­‰äºº ([2015](#bib.bib37))ï¼‰ã€‚æˆ‘ä»¬è¿˜å¯ä»¥æåˆ°
    Hernitschek ç­‰äºº ([2016](#bib.bib19)) åœ¨ Pan-STARR S1 (PS1) $3\pi$ è°ƒæŸ¥ä¸­å…³äº QSO çš„åˆ†ç±»å’Œæ£€æµ‹çš„æœ€æ–°å·¥ä½œã€‚è¿™æ˜¯ä¸€ä¸ªå¤šæ—¶æœŸè°ƒæŸ¥ï¼Œè¦†ç›–äº†ä»
    2010 å¹´åˆ° 2014 å¹´åˆä¹‹é—´çš„ä¸‰åˆ†ä¹‹å››çš„å¤©ç©ºï¼Œé€šå¸¸ä¸º 35 ä¸ªæ—¶æœŸï¼Œä½¿ç”¨äº”ä¸ªæ»¤å…‰ç‰‡ï¼ˆ$g_{P1}$, $r_{P1}$, $i_{P1}$, $z_{P1}$,
    $y_{P1}$ï¼‰ã€‚ä»–ä»¬ä½¿ç”¨éšæœºæ£®æ—åˆ†ç±»å™¨å’Œé¢œè‰²ä»¥åŠç»“æ„å‡½æ•°ä½œä¸ºç‰¹å¾ï¼Œæ¥è¯†åˆ« 1,000,000 ä¸ª QSO å€™é€‰ä½“ã€‚
- en: The main motivation for this work is to propose a new classification and a detection
    method for quasars in the Sloan Digital Sky Survey Stripe 82, that can be easily
    adapted to large future surveys like LSST or DES (The Dark Energy Survey Collaboration
    ([2005](#bib.bib47))). The algorithms mentioned above, involves a feature extraction
    step but the set of features can be incomplete to characterize the variability
    of quasars. That is why we proposed to use another branch of machine learning
    namely deep learning. It is a supervised learning which takes raw data into account
    and extracts by itself the best features for a given problem. This method gives
    very good results in many fields. In particular we use a Convolutional Neural
    Network (CNN) architecture which gives excellent results in several signal processing
    challenges as Imagenet (Russakovsky etÂ al. ([2015](#bib.bib42))), LifeClef (Joly
    etÂ al. ([2016](#bib.bib26))) etcâ€¦ This approach is very recent in Astronomy and
    its first applications show good results, for example for the classification of
    galaxy morphologies from astronomical images (Huertas-Company etÂ al. ([2015](#bib.bib21))).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬å·¥ä½œçš„ä¸»è¦åŠ¨æœºæ˜¯æå‡ºä¸€ç§æ–°çš„åˆ†ç±»å’Œæ£€æµ‹æ–¹æ³•ï¼Œç”¨äºæ–¯éš†æ•°å­—å¤©ç©ºå·¡å¤© Stripe 82 ä¸­çš„ç±»æ˜Ÿä½“ï¼Œè¯¥æ–¹æ³•å¯ä»¥è½»æ¾é€‚åº”æœªæ¥çš„å¤§å‹è°ƒæŸ¥ï¼Œå¦‚ LSST æˆ–
    DESï¼ˆæš—èƒ½é‡è°ƒæŸ¥åˆä½œç»„ ([2005](#bib.bib47)ï¼‰ï¼‰ã€‚ä¸Šè¿°ç®—æ³•æ¶‰åŠç‰¹å¾æå–æ­¥éª¤ï¼Œä½†ç‰¹å¾é›†å¯èƒ½ä¸è¶³ä»¥è¡¨å¾ç±»æ˜Ÿä½“çš„å˜å¼‚æ€§ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬æå‡ºä½¿ç”¨å¦ä¸€ç§æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå³æ·±åº¦å­¦ä¹ ã€‚å®ƒæ˜¯ä¸€ç§ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œèƒ½å¤Ÿè€ƒè™‘åŸå§‹æ•°æ®ï¼Œå¹¶è‡ªè¡Œæå–ç»™å®šé—®é¢˜çš„æœ€ä½³ç‰¹å¾ã€‚è¿™ç§æ–¹æ³•åœ¨è®¸å¤šé¢†åŸŸéƒ½å–å¾—äº†éå¸¸å¥½çš„ç»“æœã€‚ç‰¹åˆ«æ˜¯æˆ‘ä»¬ä½¿ç”¨äº†ä¸€ç§å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ¶æ„ï¼Œå®ƒåœ¨å¤šä¸ªä¿¡å·å¤„ç†æŒ‘æˆ˜ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¦‚
    Imagenetï¼ˆRussakovsky et al. ([2015](#bib.bib42)ï¼‰ï¼‰ã€LifeClefï¼ˆJoly et al. ([2016](#bib.bib26)ï¼‰ï¼‰ç­‰â€¦â€¦è¿™ç§æ–¹æ³•åœ¨å¤©æ–‡å­¦ä¸­éå¸¸æ–°é¢–ï¼Œå…¶é¦–æ¬¡åº”ç”¨æ˜¾ç¤ºäº†è‰¯å¥½çš„ç»“æœï¼Œä¾‹å¦‚ç”¨äºä»å¤©æ–‡å›¾åƒä¸­åˆ†ç±»é“¶æ²³ç³»å½¢æ€ï¼ˆHuertas-Company
    et al. ([2015](#bib.bib21)ï¼‰ï¼‰ã€‚
- en: In this work, we propose an innovative architecture based on a CNN to detect
    and classify quasars from light curves, thus taking into account the variability
    of objects. We also apply this kind of architecture to estimate the photometric
    redshifts of quasars. The estimation of photometric redshifts by a CNN classifier
    is an original method which is very promising. This paper is organized as follows.
    In Section 2, we introduce the Stripe 82 data set. In Section 3, we describe the
    CNN architecture and processing. In Section 4, we propose our CNN architecture
    for the detection and the classification of quasars. In Section 5, we analyze
    and discuss the new quasar candidates detected by our method. Then, we compare
    our algorithm with a random forest classifier and combine them. In Section 6 we
    propose to use a similar CNN architecture to predict the photometric redshifts
    of quasars. Finally we summarize our results in Section 7.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäº CNN çš„åˆ›æ–°æ¶æ„ï¼Œç”¨äºä»å…‰å˜æ›²çº¿ä¸­æ£€æµ‹å’Œåˆ†ç±»ç±»æ˜Ÿä½“ï¼Œä»è€Œè€ƒè™‘äº†ç‰©ä½“çš„å˜å¼‚æ€§ã€‚æˆ‘ä»¬è¿˜åº”ç”¨è¿™ç§æ¶æ„æ¥ä¼°è®¡ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»ã€‚é€šè¿‡
    CNN åˆ†ç±»å™¨ä¼°è®¡å…‰åº¦çº¢ç§»æ˜¯ä¸€ç§éå¸¸æœ‰å‰æ™¯çš„åŸåˆ›æ–¹æ³•ã€‚æœ¬æ–‡çš„ç»„ç»‡ç»“æ„å¦‚ä¸‹ï¼šç¬¬ 2 èŠ‚ä»‹ç»äº† Stripe 82 æ•°æ®é›†ï¼›ç¬¬ 3 èŠ‚æè¿°äº† CNN æ¶æ„å’Œå¤„ç†ï¼›ç¬¬
    4 èŠ‚æå‡ºäº†æˆ‘ä»¬ç”¨äºç±»æ˜Ÿä½“æ£€æµ‹å’Œåˆ†ç±»çš„ CNN æ¶æ„ï¼›ç¬¬ 5 èŠ‚åˆ†æå¹¶è®¨è®ºäº†æˆ‘ä»¬æ–¹æ³•æ£€æµ‹åˆ°çš„æ–°ç±»æ˜Ÿä½“å€™é€‰è€…ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„ç®—æ³•ä¸éšæœºæ£®æ—åˆ†ç±»å™¨è¿›è¡Œæ¯”è¾ƒå¹¶è¿›è¡Œç»„åˆï¼›ç¬¬
    6 èŠ‚æå‡ºä½¿ç”¨ç±»ä¼¼çš„ CNN æ¶æ„æ¥é¢„æµ‹ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»ï¼›æœ€åï¼Œåœ¨ç¬¬ 7 èŠ‚ä¸­æ€»ç»“æˆ‘ä»¬çš„ç»“æœã€‚
- en: 2 Data
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 æ•°æ®
- en: '![Refer to caption](img/45439edb0bf45a05b95c66801f9bc2c9.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜æ–‡å­—](img/45439edb0bf45a05b95c66801f9bc2c9.png)'
- en: 'Figure 1: Two examples of variable object types in the UWVSC catalog. On left
    panel, it is a quasar light curve and on right panel a RR Lyrae light curve.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 1ï¼šUWVSC ç›®å½•ä¸­ä¸¤ç§å˜é‡ç‰©ä½“ç±»å‹çš„ç¤ºä¾‹ã€‚å·¦ä¾§é¢æ¿æ˜¯ç±»æ˜Ÿä½“å…‰å˜æ›²çº¿ï¼Œå³ä¾§é¢æ¿æ˜¯ RR Lyrae å…‰å˜æ›²çº¿ã€‚
- en: '![Refer to caption](img/6f6f92d6cb36e4d2f21af736f8f4a93f.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜æ–‡å­—](img/6f6f92d6cb36e4d2f21af736f8f4a93f.png)'
- en: 'Figure 2: Distribution of spectroscopic redshifts of known quasars in the UWVSC
    catalog.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 2ï¼šUWVSC ç›®å½•ä¸­å·²çŸ¥ç±»æ˜Ÿä½“çš„å…‰è°±çº¢ç§»åˆ†å¸ƒã€‚
- en: The Sloan Digital Sky Survey (SDSS) is a multi-filter imaging and spectroscopic
    redshift survey using a dedicated 2.5-meter telescope at Apache Point observatory
    in New Mexico. It provides deep photometry ($r<22.5$) in five passbands (ugriz).
    The SDSS has imaged a 2.5 degree wide stripe along the Celestial Equator in the
    Southern Galactic Cap several times, called Stripe 82\. It is a deeper survey
    of 275 $\textrm{deg}^{2}$. It was previously imaged about once to three times
    a year from 2000 to 2005 (SDSS-I), then with an increased cadence of 10-20 times
    a year from 2005 to 2008 (SDSS-II) as part of the SDSS-II supernovae survey (Frieman
    etÂ al. ([2008](#bib.bib15))). There are on average 53 epochs, over a time span
    of 5 to 10 years (Abazajian etÂ al. ([2009](#bib.bib1))).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥ï¼ˆSDSSï¼‰æ˜¯ä¸€ä¸ªå¤šæ»¤å…‰å™¨æˆåƒå’Œå…‰è°±çº¢ç§»è°ƒæŸ¥ï¼Œä½¿ç”¨ä½äºæ–°å¢¨è¥¿å“¥å·Apache Pointå¤©æ–‡å°çš„2.5ç±³ä¸“ç”¨æœ›è¿œé•œã€‚å®ƒæä¾›äº†äº”ä¸ªé€šå¸¦ï¼ˆugrizï¼‰ä¸­çš„æ·±åº¦å…‰åº¦æµ‹é‡ï¼ˆ$r<22.5$ï¼‰ã€‚SDSSå¯¹å—æ–¹é“¶æ²³å¸½æ²¿å¤©çƒèµ¤é“çš„2.5åº¦å®½çš„æ¡å¸¦è¿›è¡Œäº†å¤šæ¬¡æˆåƒï¼Œç§°ä¸ºStripe
    82ã€‚å®ƒæ˜¯275 $\textrm{deg}^{2}$ çš„æ›´æ·±å±‚è°ƒæŸ¥ã€‚2000åˆ°2005å¹´é—´ï¼Œå®ƒæ¯å¹´æˆåƒçº¦1åˆ°3æ¬¡ï¼ˆSDSS-Iï¼‰ï¼Œç„¶ååœ¨2005åˆ°2008å¹´æœŸé—´ï¼Œæ¯å¹´æˆåƒå¢åŠ åˆ°10-20æ¬¡ï¼ˆSDSS-IIï¼‰ï¼Œä½œä¸ºSDSS-IIè¶…æ–°æ˜Ÿè°ƒæŸ¥çš„ä¸€éƒ¨åˆ†ï¼ˆFrieman
    et al. ([2008](#bib.bib15)))ã€‚å¹³å‡æœ‰53ä¸ªè§‚æµ‹æ—¶æ®µï¼Œè·¨è¶Š5åˆ°10å¹´çš„æ—¶é—´è·¨åº¦ï¼ˆAbazajian et al. ([2009](#bib.bib1))ï¼‰ã€‚
- en: 'The imaging data used in our work consists of objects solely from the publicly
    available variable source catalog (UWVSC; IveziÄ‡ etÂ al. ([2007](#bib.bib24)),
    Sesar etÂ al. ([2007](#bib.bib44))) constructed by researchers at the University
    of Washington. This catalog contains 67,507 unresolved, variable candidates with
    $g\leq 20.5\,\,\textrm{mag}$, at least 10 observations in both g and r bands,
    and a light curve with a root-mean-scatter (rms) $>0.05$ mag and $\chi^{2}$ per
    degree of freedom $>3$ in both g and r bands. Among the data, some variable objects
    have been identified, they are essentially quasars and pulsating stars (see Figure
    [1](#S2.F1 "Figure 1 â€£ 2 Data â€£ Deep learning Approach for Classifying, Detecting
    and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey
    Stripe 82")). However a large part of the data consists of unknown variable objects.
    In this way this catalog is interesting to identify new variable objects. This
    catalog and all light curves are publicly available.Â¹Â¹1http://www.astro.washington.edu/users/ivezic/sdss/catalogs/S82variables.html
    We use the UWVSC as the basis for learning and testing for several reasons: 1)
    it contains over 9000 known spectroscopically confirmed quasars (Meusinger etÂ al.
    ([2011](#bib.bib32))) whose the distribution of redshifts is shown in Figure [2](#S2.F2
    "Figure 2 â€£ 2 Data â€£ Deep learning Approach for Classifying, Detecting and Predicting
    Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82") ;
    2) it is a robust variable catalog with a good photometry; 3) the catalog is a
    useful testbed for time domain science to prepare future data sets like LSST.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·¥ä½œä¸­ä½¿ç”¨çš„æˆåƒæ•°æ®ä»…åŒ…å«æ¥è‡ªåç››é¡¿å¤§å­¦ç ”ç©¶äººå‘˜æ„å»ºçš„å…¬å¼€å¯ç”¨çš„å˜æ˜Ÿæºç›®å½•ï¼ˆUWVSC; IveziÄ‡ et al. ([2007](#bib.bib24)),
    Sesar et al. ([2007](#bib.bib44))) çš„å¯¹è±¡ã€‚è¯¥ç›®å½•åŒ…å«67,507ä¸ªæœªè§£å†³çš„å˜æ˜Ÿå€™é€‰ä½“ï¼Œ$g\leq 20.5\,\,\textrm{mag}$ï¼Œåœ¨gå’Œræ³¢æ®µéƒ½æœ‰è‡³å°‘10æ¬¡è§‚æµ‹ï¼Œå¹¶ä¸”å…‰æ›²çº¿çš„å‡æ–¹æ ¹ï¼ˆrmsï¼‰$>0.05$
    magå’Œæ¯ä¸ªè‡ªç”±åº¦çš„$\chi^{2}$åœ¨gå’Œræ³¢æ®µä¸­éƒ½$>3$ã€‚åœ¨è¿™äº›æ•°æ®ä¸­ï¼Œä¸€äº›å˜æ˜Ÿå¯¹è±¡å·²è¢«è¯†åˆ«ï¼Œå®ƒä»¬åŸºæœ¬ä¸Šæ˜¯ç±»æ˜Ÿä½“å’Œè„‰åŠ¨æ˜Ÿï¼ˆè§å›¾ [1](#S2.F1
    "å›¾ 1 â€£ 2 æ•°æ® â€£ æ·±åº¦å­¦ä¹ æ–¹æ³•ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥Stripe 82ä¸­ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»")ï¼‰ã€‚ç„¶è€Œï¼Œæ•°æ®ä¸­å¾ˆå¤§ä¸€éƒ¨åˆ†æ˜¯æœªçŸ¥çš„å˜æ˜Ÿå¯¹è±¡ã€‚å› æ­¤ï¼Œè¿™ä¸ªç›®å½•å¯¹äºè¯†åˆ«æ–°çš„å˜æ˜Ÿå¯¹è±¡éå¸¸æœ‰è¶£ã€‚è¯¥ç›®å½•å’Œæ‰€æœ‰å…‰æ›²çº¿éƒ½æ˜¯å…¬å¼€å¯ç”¨çš„ã€‚Â¹Â¹1http://www.astro.washington.edu/users/ivezic/sdss/catalogs/S82variables.html
    æˆ‘ä»¬ä½¿ç”¨UWVSCä½œä¸ºå­¦ä¹ å’Œæµ‹è¯•çš„åŸºç¡€æœ‰å‡ ä¸ªåŸå› ï¼š1ï¼‰å®ƒåŒ…å«è¶…è¿‡9000ä¸ªå·²çŸ¥çš„å…‰è°±ç¡®è®¤çš„ç±»æ˜Ÿä½“ï¼ˆMeusinger et al. ([2011](#bib.bib32)))ï¼Œå…¶çº¢ç§»åˆ†å¸ƒå¦‚å›¾
    [2](#S2.F2 "å›¾ 2 â€£ 2 æ•°æ® â€£ æ·±åº¦å­¦ä¹ æ–¹æ³•ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥Stripe 82ä¸­ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»") æ‰€ç¤ºï¼›2ï¼‰è¿™æ˜¯ä¸€ä¸ªå…·æœ‰è‰¯å¥½å…‰åº¦æµ‹é‡çš„ç¨³å¥çš„å˜æ˜Ÿç›®å½•ï¼›3ï¼‰è¯¥ç›®å½•æ˜¯æ—¶é—´åŸŸç§‘å­¦çš„æœ‰ç”¨æµ‹è¯•å¹³å°ï¼Œç”¨äºå‡†å¤‡æœªæ¥çš„æ•°æ®é›†ï¼Œä¾‹å¦‚LSSTã€‚
- en: 3 The Convolutional Neural Network
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 å·ç§¯ç¥ç»ç½‘ç»œ
- en: In this work, we are particularly interested in CNN which are an approach to
    deep learning methods that are proving their worth in many research fields.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç‰¹åˆ«æ„Ÿå…´è¶£çš„æ˜¯å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œå·²ç»åœ¨è®¸å¤šç ”ç©¶é¢†åŸŸè¯æ˜äº†å…¶ä»·å€¼ã€‚
- en: 3.1 Light Curve Images
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 å…‰æ›²çº¿å›¾åƒ
- en: As a CNN takes images as input, we had to find a way to convert a light curve
    to an image taking into account the variability of objects which gives a crucial
    information for the classification of variable objects. Thus, we propose to create
    images whose the width is represented by the five magnitudes (u, g, r, i and z),
    and the height corresponds to the date of the observation. In Stripe 82, there
    are a maximum of 3340 days of observation so images should have a dimension of
    5$\times$3340 pixels. However processing these images is very costly in VRAM memory,
    so we divided the time interval of a light curve by averaging the observations
    taken on two consecutive days, so as to get images of dimensions of 5$\times$1670
    pixels. Then 60 pixels were appended to the edges of the image to avoid side-effects.
    Therefore the size of the final images, called hereafter, LCI (Light Curve Images),
    is 5$\times$1700 pixels.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº CNN ä»¥å›¾åƒä½œä¸ºè¾“å…¥ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ç§æ–¹æ³•å°†å…‰å˜æ›²çº¿è½¬æ¢ä¸ºå›¾åƒï¼ŒåŒæ—¶è€ƒè™‘åˆ°ç‰©ä½“çš„å˜åŒ–ï¼Œè¿™å¯¹å˜é‡ç‰©ä½“çš„åˆ†ç±»æä¾›äº†å…³é”®çš„ä¿¡æ¯ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å»ºè®®åˆ›å»ºå›¾åƒï¼Œå…¶å®½åº¦ç”±äº”ä¸ªäº®åº¦ï¼ˆuã€gã€rã€i
    å’Œ zï¼‰è¡¨ç¤ºï¼Œé«˜åº¦åˆ™å¯¹åº”äºè§‚å¯Ÿæ—¥æœŸã€‚åœ¨ Stripe 82 ä¸­ï¼Œæœ€å¤šæœ‰ 3340 å¤©çš„è§‚æµ‹ï¼Œå› æ­¤å›¾åƒçš„å°ºå¯¸åº”ä¸º 5$\times$3340 åƒç´ ã€‚ç„¶è€Œï¼Œå¤„ç†è¿™äº›å›¾åƒåœ¨
    VRAM å†…å­˜ä¸­éå¸¸æ˜‚è´µï¼Œæ‰€ä»¥æˆ‘ä»¬é€šè¿‡å¹³å‡å¤„ç†åœ¨è¿ç»­ä¸¤å¤©å†…è·å–çš„è§‚æµ‹å€¼æ¥åˆ’åˆ†å…‰å˜æ›²çº¿çš„æ—¶é—´é—´éš”ï¼Œä»è€Œå¾—åˆ° 5$\times$1670 åƒç´ çš„å›¾åƒã€‚ç„¶ååœ¨å›¾åƒçš„è¾¹ç¼˜é™„åŠ äº†
    60 åƒç´ ä»¥é¿å…å‰¯ä½œç”¨ã€‚å› æ­¤ï¼Œæœ€ç»ˆå›¾åƒçš„å¤§å°ï¼Œä»¥ä¸‹ç®€ç§° LCIï¼ˆå…‰å˜æ›²çº¿å›¾åƒï¼‰ï¼Œä¸º 5$\times$1700 åƒç´ ã€‚
- en: In order to increase the robustness of the network, the learning needs to be
    free of the positions of points. To do this, we generate new light curves by making
    time translations for all points on a given light curve. Thus only the global
    shape of the light curve is taken into account and no positions of points are
    considered as more important than others. This process is similar to that of classical
    data augmentation (LeÂ Guennec etÂ al. ([2016](#bib.bib29)); Krizhevsky etÂ al. ([2012](#bib.bib27)))
    in the CNN learning and increases the size of the database by a factor of 13.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æé«˜ç½‘ç»œçš„é²æ£’æ€§ï¼Œå­¦ä¹ éœ€è¦ä¸å—ç‚¹ä½ç½®çš„å½±å“ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é€šè¿‡å¯¹ç»™å®šå…‰å˜æ›²çº¿ä¸Šçš„æ‰€æœ‰ç‚¹è¿›è¡Œæ—¶é—´å¹³ç§»æ¥ç”Ÿæˆæ–°çš„å…‰å˜æ›²çº¿ã€‚å› æ­¤ï¼Œåªè€ƒè™‘å…‰å˜æ›²çº¿çš„æ•´ä½“å½¢çŠ¶ï¼Œä¸å°†ä»»ä½•ç‚¹çš„ä½ç½®è§†ä¸ºæ¯”å…¶ä»–ç‚¹æ›´é‡è¦ã€‚è¿™ä¸€è¿‡ç¨‹ç±»ä¼¼äº
    CNN å­¦ä¹ ä¸­çš„ç»å…¸æ•°æ®å¢å¼ºï¼ˆLe Guennec et al. ([2016](#bib.bib29)); Krizhevsky et al. ([2012](#bib.bib27)))ï¼Œå¹¶å°†æ•°æ®åº“çš„å¤§å°å¢åŠ äº†
    13 å€ã€‚
- en: 3.2 Introduction to the CNN
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 CNN ç®€ä»‹
- en: '![Refer to caption](img/1e2a8259be396cc77aab33cf1a282671.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/1e2a8259be396cc77aab33cf1a282671.png)'
- en: 'Figure 3: Representation of two convolution layers of a network. The first
    layer is composed of 3 neurons making a convolution between the input image and
    their kernels. The second layer includes two neurons making a sum of convolutions
    as defined in the equation [1](#S3.E1 "In 3.2.1 Convolution â€£ 3.2 Introduction
    to the CNN â€£ 3 The Convolutional Neural Network â€£ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82").'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3ï¼šç½‘ç»œä¸­ä¸¤ä¸ªå·ç§¯å±‚çš„è¡¨ç¤ºã€‚ç¬¬ä¸€å±‚ç”± 3 ä¸ªç¥ç»å…ƒç»„æˆï¼Œå¯¹è¾“å…¥å›¾åƒåŠå…¶å·ç§¯æ ¸è¿›è¡Œå·ç§¯ã€‚ç¬¬äºŒå±‚åŒ…æ‹¬ä¸¤ä¸ªç¥ç»å…ƒï¼Œå¯¹å·ç§¯ç»“æœè¿›è¡Œæ±‚å’Œï¼Œå¦‚æ–¹ç¨‹ [1](#S3.E1
    "åœ¨ 3.2.1 å·ç§¯ â€£ 3.2 CNN ç®€ä»‹ â€£ 3 å·ç§¯ç¥ç»ç½‘ç»œ â€£ æ·±åº¦å­¦ä¹ æ–¹æ³•ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹ Sloan Digital Sky Survey
    Stripe 82 ä¸­ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»") ä¸­å®šä¹‰ã€‚
- en: 'An artificial neuron is a computational model inspired by natural neurons.
    A natural neuron is an electrically excitable cell that processes and transmits
    information via synapses which are connected with other cells. When the signal
    received is strong enough (higher than a specific threshold), the neuron is activated
    and emits a signal which might activate other neurons. Artificial neurons do not
    reproduce the complexity of real neurons, but the global structure is quite similar.
    Indeed, input data are multiplied by weights and then computed by a mathematical
    function which determines the activation of the neuron. An artificial neural network
    is then composed of different neuron layers connected with each other. A layer
    of rank $n$ takes as input the output of the layer of rank $n-1$. The nomenclature
    of layers is the following: i) a layer whose input is not connected to the output
    of another layer, but to the raw data is called input layer; ii) a layer whose
    output is not connected is called an output layer; iii) a layer is called â€hiddenâ€
    if it has either input or output. Each layer is composed of several tens of thousands
    of neurons. In the specific case of a CNN, neurons perform convolution (see Section
    [3.2.1](#S3.SS2.SSS1 "3.2.1 Convolution â€£ 3.2 Introduction to the CNN â€£ 3 The
    Convolutional Neural Network â€£ Deep learning Approach for Classifying, Detecting
    and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey
    Stripe 82")) and pooling operations (see Section [3.2.2](#S3.SS2.SSS2 "3.2.2 Pooling
    â€£ 3.2 Introduction to the CNN â€£ 3 The Convolutional Neural Network â€£ Deep learning
    Approach for Classifying, Detecting and Predicting Photometric Redshifts of Quasars
    in the Sloan Digital Sky Survey Stripe 82")). Layers are sequentially processed
    as follows: first, a convolution operation is applied on raw input data; then
    the output signal is modified by a non linear function; finally a pooling operation
    can be processed. Note that the output of a layer could be considered as a set
    of images. In CNN terminology, each image has named feature map. After all convolution
    and pooling layers, the last convolution layer is connected to a succession of
    layers called â€fully connected layersâ€ and operating as a classical neural network.
    The last one uses a softmax operation to give a probability that the input light
    curve is either a quasar light curve or another object. To perform the learning
    phase, parameters of convolution and fully connected layers are tuned using a
    stochastic gradient descent specific to the given problem, in this case the recognition
    of quasar light curves. This optimization process is very costly, but it can be
    highly parallelizable. We use the Caffe (Jia etÂ al. ([2014](#bib.bib25))) framework
    to train our CNN. The results are obtained using a GTX Titan X card, packed in
    3,072 cores with a 1 GHz base.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: äººå·¥ç¥ç»å…ƒæ˜¯ä¸€ä¸ªå—è‡ªç„¶ç¥ç»å…ƒå¯å‘çš„è®¡ç®—æ¨¡å‹ã€‚è‡ªç„¶ç¥ç»å…ƒæ˜¯ä¸€ä¸ªç”µæ¿€æ´»çš„ç»†èƒï¼Œé€šè¿‡ä¸å…¶ä»–ç»†èƒç›¸è¿çš„çªè§¦å¤„ç†å’Œä¼ é€’ä¿¡æ¯ã€‚å½“æ¥æ”¶åˆ°çš„ä¿¡å·è¶³å¤Ÿå¼ºï¼ˆé«˜äºç‰¹å®šé˜ˆå€¼ï¼‰æ—¶ï¼Œç¥ç»å…ƒè¢«æ¿€æ´»å¹¶å‘å‡ºä¿¡å·ï¼Œè¿™å¯èƒ½ä¼šæ¿€æ´»å…¶ä»–ç¥ç»å…ƒã€‚äººå·¥ç¥ç»å…ƒå¹¶æ²¡æœ‰å†ç°çœŸå®ç¥ç»å…ƒçš„å¤æ‚æ€§ï¼Œä½†æ•´ä½“ç»“æ„ç›¸ä¼¼ã€‚å®é™…ä¸Šï¼Œè¾“å…¥æ•°æ®ä¼šè¢«æƒé‡ä¹˜ä»¥ï¼Œç„¶åé€šè¿‡ä¸€ä¸ªæ•°å­¦å‡½æ•°è®¡ç®—ï¼Œè¯¥å‡½æ•°å†³å®šç¥ç»å…ƒçš„æ¿€æ´»ã€‚äººå·¥ç¥ç»ç½‘ç»œç”±ä¸åŒçš„ç¥ç»å…ƒå±‚ç»„æˆï¼Œè¿™äº›å±‚å½¼æ­¤è¿æ¥ã€‚ä¸€ä¸ªæ’åä¸º
    $n$ çš„å±‚å°†æ¥æ”¶æ’åä¸º $n-1$ çš„å±‚çš„è¾“å‡ºä½œä¸ºè¾“å…¥ã€‚å±‚çš„å‘½åè§„åˆ™å¦‚ä¸‹ï¼ši) è¾“å…¥æœªè¿æ¥åˆ°å¦ä¸€ä¸ªå±‚çš„è¾“å‡ºï¼Œè€Œæ˜¯è¿æ¥åˆ°åŸå§‹æ•°æ®çš„å±‚ç§°ä¸ºè¾“å…¥å±‚ï¼›ii) è¾“å‡ºæœªè¿æ¥çš„å±‚ç§°ä¸ºè¾“å‡ºå±‚ï¼›iii)
    å¦‚æœä¸€ä¸ªå±‚æ—¢æœ‰è¾“å…¥åˆæœ‰è¾“å‡ºï¼Œåˆ™ç§°ä¸ºâ€œéšè—å±‚â€ã€‚æ¯ä¸€å±‚ç”±æ•°ä¸‡ä¸ªäººå·¥ç¥ç»å…ƒç»„æˆã€‚åœ¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„ç‰¹å®šæƒ…å†µä¸‹ï¼Œç¥ç»å…ƒæ‰§è¡Œå·ç§¯æ“ä½œï¼ˆè§[3.2.1èŠ‚](#S3.SS2.SSS1
    "3.2.1 å·ç§¯ â€£ 3.2 CNNç®€ä»‹ â€£ 3 å·ç§¯ç¥ç»ç½‘ç»œ â€£ æ·±åº¦å­¦ä¹ æ–¹æ³•ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥82å·æ¡çº¹ä¸­çš„ç±»æ˜Ÿä½“å…‰åº¦çº¢ç§»")ï¼‰å’Œæ± åŒ–æ“ä½œï¼ˆè§[3.2.2èŠ‚](#S3.SS2.SSS2
    "3.2.2 æ± åŒ– â€£ 3.2 CNNç®€ä»‹ â€£ 3 å·ç§¯ç¥ç»ç½‘ç»œ â€£ æ·±åº¦å­¦ä¹ æ–¹æ³•ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥82å·æ¡çº¹ä¸­çš„ç±»æ˜Ÿä½“å…‰åº¦çº¢ç§»")ï¼‰ã€‚å±‚æŒ‰ä»¥ä¸‹é¡ºåºå¤„ç†ï¼šé¦–å…ˆï¼Œå¯¹åŸå§‹è¾“å…¥æ•°æ®åº”ç”¨å·ç§¯æ“ä½œï¼›ç„¶åï¼Œé€šè¿‡éçº¿æ€§å‡½æ•°ä¿®æ”¹è¾“å‡ºä¿¡å·ï¼›æœ€åï¼Œå¯ä»¥å¤„ç†æ± åŒ–æ“ä½œã€‚æ³¨æ„ï¼Œå±‚çš„è¾“å‡ºå¯ä»¥è§†ä¸ºä¸€ç»„å›¾åƒã€‚åœ¨CNNæœ¯è¯­ä¸­ï¼Œæ¯ä¸ªå›¾åƒç§°ä¸ºç‰¹å¾å›¾ã€‚åœ¨æ‰€æœ‰å·ç§¯å’Œæ± åŒ–å±‚ä¹‹åï¼Œæœ€åçš„å·ç§¯å±‚è¿æ¥åˆ°ä¸€ç³»åˆ—ç§°ä¸ºâ€œå…¨è¿æ¥å±‚â€çš„å±‚ï¼Œå¹¶ä½œä¸ºç»å…¸ç¥ç»ç½‘ç»œè¿è¡Œã€‚æœ€åä¸€å±‚ä½¿ç”¨softmaxæ“ä½œæ¥ç»™å‡ºè¾“å…¥å…‰åº¦æ›²çº¿æ˜¯ç±»æ˜Ÿä½“å…‰åº¦æ›²çº¿è¿˜æ˜¯å…¶ä»–å¯¹è±¡çš„æ¦‚ç‡ã€‚ä¸ºäº†æ‰§è¡Œå­¦ä¹ é˜¶æ®µï¼Œå·ç§¯å±‚å’Œå…¨è¿æ¥å±‚çš„å‚æ•°é€šè¿‡ç‰¹å®šäºé—®é¢˜çš„éšæœºæ¢¯åº¦ä¸‹é™è¿›è¡Œè°ƒä¼˜ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯ç±»æ˜Ÿä½“å…‰åº¦æ›²çº¿çš„è¯†åˆ«ã€‚è¿™ä¸ªä¼˜åŒ–è¿‡ç¨‹éå¸¸æ˜‚è´µï¼Œä½†å…·æœ‰å¾ˆé«˜çš„å¹¶è¡Œæ€§ã€‚æˆ‘ä»¬ä½¿ç”¨Caffeï¼ˆJiaç­‰äººï¼ˆ[2014](#bib.bib25)ï¼‰ï¼‰æ¡†æ¶æ¥è®­ç»ƒæˆ‘ä»¬çš„CNNã€‚ç»“æœæ˜¯ä½¿ç”¨GTX
    Titan Xæ˜¾å¡è·å¾—çš„ï¼Œè¯¥å¡å…·æœ‰3,072ä¸ªæ ¸å¿ƒå’Œ1 GHzçš„åŸºå‡†é¢‘ç‡ã€‚
- en: 3.2.1 Convolution
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 å·ç§¯
- en: 'If we consider a layer or a set of feature maps as input, the first step is
    to apply convolutions. For the first layer, the convolution is done between the
    input image and a filter. Each filter leads to a filtered image. Convolution layers
    are composed of convolutif neurons. Each convolutif neuron applies the sum of
    2D convolutions between the input feature maps and its kernel. In the simple case
    where only one feature map is passed into the input convolutif neuron, the 2D
    convolution between the K kernel of size $w\times h$ and the input feature map
    $I\in\mathbb{R}^{2}$ is noted $\mathbf{I}*\mathbf{K}$ and is defined as: $(I*K)_{x,y}=\sum_{x^{\prime}=x-\frac{w}{2}}^{x+\frac{w}{2}}\,\,\sum_{y^{\prime}=y-\frac{h}{2}}^{y+\frac{h}{2}}\mathbf{K}_{x^{\prime}+\frac{w}{2}-x,\,y^{\prime}+\frac{h}{2}-y}\mathbf{I}_{x^{\prime},y^{\prime}}$
    with (x,y) the coordinates of a given pixel into the output feature map.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å°†ä¸€ä¸ªå±‚æˆ–ä¸€ç»„ç‰¹å¾å›¾è§†ä¸ºè¾“å…¥ï¼Œç¬¬ä¸€æ­¥æ˜¯åº”ç”¨å·ç§¯ã€‚å¯¹äºç¬¬ä¸€å±‚ï¼Œå·ç§¯æ˜¯åœ¨è¾“å…¥å›¾åƒå’Œä¸€ä¸ªæ»¤æ³¢å™¨ä¹‹é—´è¿›è¡Œçš„ã€‚æ¯ä¸ªæ»¤æ³¢å™¨éƒ½ä¼šäº§ç”Ÿä¸€ä¸ªæ»¤æ³¢åçš„å›¾åƒã€‚å·ç§¯å±‚ç”±å·ç§¯ç¥ç»å…ƒç»„æˆã€‚æ¯ä¸ªå·ç§¯ç¥ç»å…ƒå¯¹è¾“å…¥ç‰¹å¾å›¾å’Œå…¶å·ç§¯æ ¸è¿›è¡ŒäºŒç»´å·ç§¯çš„æ±‚å’Œã€‚åœ¨ä»…æœ‰ä¸€ä¸ªç‰¹å¾å›¾ä¼ é€’ç»™è¾“å…¥å·ç§¯ç¥ç»å…ƒçš„ç®€å•æƒ…å†µä¸‹ï¼Œå¤§å°ä¸º
    $w\times h$ çš„å·ç§¯æ ¸ $K$ ä¸è¾“å…¥ç‰¹å¾å›¾ $I\in\mathbb{R}^{2}$ ä¹‹é—´çš„äºŒç»´å·ç§¯è®°ä½œ $\mathbf{I}*\mathbf{K}$ï¼Œå…¶å®šä¹‰ä¸ºï¼š$(I*K)_{x,y}=\sum_{x^{\prime}=x-\frac{w}{2}}^{x+\frac{w}{2}}\,\,\sum_{y^{\prime}=y-\frac{h}{2}}^{y+\frac{h}{2}}\mathbf{K}_{x^{\prime}+\frac{w}{2}-x,\,y^{\prime}+\frac{h}{2}-y}\mathbf{I}_{x^{\prime},y^{\prime}}$ï¼Œå…¶ä¸­
    (x,y) æ˜¯è¾“å‡ºç‰¹å¾å›¾ä¸­ç»™å®šåƒç´ çš„åæ ‡ã€‚
- en: 'In the case of convolutional neural networks, a neuron takes as input each
    of $p$ feature maps of the previously layer noted $I^{l}$ with $l\in\{0...p\}$.
    The resulting feature map is the sum of $p$ 2D convolutions between the kernel
    $K^{l}$ and the map $I^{l}$ (see Figure [3](#S3.F3 "Figure 3 â€£ 3.2 Introduction
    to the CNN â€£ 3 The Convolutional Neural Network â€£ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82")) and is defined as:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å·ç§¯ç¥ç»ç½‘ç»œçš„æƒ…å†µä¸‹ï¼Œä¸€ä¸ªç¥ç»å…ƒä»¥å…ˆå‰å±‚çš„æ¯ä¸ª $p$ ä¸ªç‰¹å¾å›¾ $I^{l}$ ä½œä¸ºè¾“å…¥ï¼Œå…¶ä¸­ $l\in\{0...p\}$ã€‚ç»“æœç‰¹å¾å›¾æ˜¯ $p$
    ä¸ªäºŒç»´å·ç§¯çš„å’Œï¼Œå·ç§¯æ ¸ä¸º $K^{l}$ï¼Œç‰¹å¾å›¾ä¸º $I^{l}$ï¼ˆè§å›¾ [3](#S3.F3 "Figure 3 â€£ 3.2 Introduction to
    the CNN â€£ 3 The Convolutional Neural Network â€£ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82)ï¼‰ï¼Œå®šä¹‰ä¸ºï¼š
- en: '|  | $(\mathbf{I}*\mathbf{K})=\sum_{l=0}^{p}(\mathbf{K}^{l}\mathbf{*I}^{l})$
    |  | (1) |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '|  | $(\mathbf{I}*\mathbf{K})=\sum_{l=0}^{p}(\mathbf{K}^{l}\mathbf{*I}^{l})$
    |  | (1) |'
- en: In this work we propose to use two types of convolutions that we call â€œtemporal
    convolutionsâ€ and â€œfilter convolutionsâ€. The temporal convolutions use a kernel
    with a x-dimension of 1 pixel, so the five magnitudes (u, g, r, i and z) are convoluted
    separately, and with a y-dimension variable in the interval {5, 11, 21, 41} pixels.
    Thus the temporal convolutions take into account a value of magnitude at different
    times and at different resolutions. The advantage of this type of convolutions
    is to create a network which is able to detect short and long variability patterns.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æè®®ä½¿ç”¨ä¸¤ç§æˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œæ—¶é—´å·ç§¯â€å’Œâ€œæ»¤æ³¢å™¨å·ç§¯â€çš„å·ç§¯ç±»å‹ã€‚æ—¶é—´å·ç§¯ä½¿ç”¨å°ºå¯¸ä¸º 1 åƒç´ çš„ x-ç»´å·ç§¯æ ¸ï¼Œå› æ­¤äº”ä¸ªå¹…åº¦ï¼ˆuã€gã€rã€i
    å’Œ zï¼‰è¢«å•ç‹¬å·ç§¯ï¼Œå¹¶ä¸” y-ç»´åº¦åœ¨ {5, 11, 21, 41} åƒç´ çš„åŒºé—´å†…å¯å˜ã€‚å› æ­¤ï¼Œæ—¶é—´å·ç§¯è€ƒè™‘äº†åœ¨ä¸åŒæ—¶é—´å’Œä¸åŒåˆ†è¾¨ç‡ä¸‹çš„å¹…åº¦å€¼ã€‚è¿™ç§å·ç§¯çš„ä¼˜ç‚¹æ˜¯åˆ›å»ºä¸€ä¸ªèƒ½å¤Ÿæ£€æµ‹çŸ­æœŸå’Œé•¿æœŸå˜å¼‚æ¨¡å¼çš„ç½‘ç»œã€‚
- en: The filter convolutions use a kernel with a dimension of $5\times 1$ pixels,
    so they merge the values of the five magnitudes in order to integrate the information
    from color which is an important feature to characterize variable objects, at
    a given time.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æ»¤æ³¢å™¨å·ç§¯ä½¿ç”¨å°ºå¯¸ä¸º $5\times 1$ åƒç´ çš„å·ç§¯æ ¸ï¼Œå› æ­¤å®ƒä»¬åˆå¹¶äº†äº”ä¸ªå¹…åº¦çš„å€¼ï¼Œä»¥æ•´åˆé¢œè‰²ä¿¡æ¯ï¼Œè¿™æ˜¯æè¿°å¯å˜å¯¹è±¡çš„é‡è¦ç‰¹å¾ï¼Œåœ¨ç‰¹å®šæ—¶é—´å†…ã€‚
- en: 3.2.2 Pooling
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 æ± åŒ–
- en: The network can be composed of pooling layers which quantify the information
    while reducing the data volume. The Pooling Layer operates independently on each
    feature map. On each feature map, it slides a specific filter which represents
    the local distribution. The two most used methods consist in selecting only the
    maximal or the mean value of the data in the local region. As the observational
    data are not continuous in time, several pixels in the LCI are equal to zero.
    Thus we decide to adapt the pooling by the mean, i.e. we donâ€™t taking into account
    the null pixels in the computation of the mean. Our architecture includes this
    improvement of the pooling on the first pooling layers of the network. The others
    layers contain a max pooling.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç½‘ç»œå¯ä»¥ç”±æ± åŒ–å±‚ç»„æˆï¼Œè¿™äº›å±‚åœ¨å‡å°‘æ•°æ®é‡çš„åŒæ—¶é‡åŒ–ä¿¡æ¯ã€‚æ± åŒ–å±‚åœ¨æ¯ä¸ªç‰¹å¾å›¾ä¸Šç‹¬ç«‹æ“ä½œã€‚åœ¨æ¯ä¸ªç‰¹å¾å›¾ä¸Šï¼Œå®ƒæ»‘åŠ¨ä¸€ä¸ªè¡¨ç¤ºå±€éƒ¨åˆ†å¸ƒçš„ç‰¹å®šæ»¤æ³¢å™¨ã€‚æœ€å¸¸ç”¨çš„ä¸¤ç§æ–¹æ³•æ˜¯é€‰æ‹©å±€éƒ¨åŒºåŸŸå†…çš„æ•°æ®çš„æœ€å¤§å€¼æˆ–å‡å€¼ã€‚ç”±äºè§‚å¯Ÿæ•°æ®åœ¨æ—¶é—´ä¸Šä¸æ˜¯è¿ç»­çš„ï¼ŒLCIä¸­çš„å‡ ä¸ªåƒç´ ç­‰äºé›¶ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å†³å®šé€šè¿‡å‡å€¼æ¥é€‚åº”æ± åŒ–ï¼Œå³åœ¨è®¡ç®—å‡å€¼æ—¶ä¸è€ƒè™‘é›¶åƒç´ ã€‚æˆ‘ä»¬çš„æ¶æ„åœ¨ç½‘ç»œçš„ç¬¬ä¸€å±‚æ± åŒ–å±‚ä¸­åŒ…å«äº†è¿™ä¸€æ± åŒ–æ”¹è¿›ã€‚å…¶ä»–å±‚åŒ…å«æœ€å¤§æ± åŒ–ã€‚
- en: 3.2.3 Activation Functions
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 æ¿€æ´»å‡½æ•°
- en: 'The convolution layers are followed by non linear transformations whose goal
    is to solve the non-linear classification problems. The two most used functions
    are the ReLU (Rectify Lineair Unit, Nair & Hinton ([2010](#bib.bib33))) defined
    by $f(x)=max(x,0)$ and the hyperbolic tangent. In our network, to saturate the
    input signal we apply a hyperbolic tangent function on all of the first convolution
    layers. The other layers use a PReLU (He etÂ al. ([2015](#bib.bib18))) function
    defined as: <math   alttext="f(x)=\begin{cases}\alpha
    x&amp;x<0\\'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å·ç§¯å±‚åé¢è·Ÿéšéçº¿æ€§å˜æ¢ï¼Œå…¶ç›®æ ‡æ˜¯è§£å†³éçº¿æ€§åˆ†ç±»é—®é¢˜ã€‚æœ€å¸¸ç”¨çš„ä¸¤ä¸ªå‡½æ•°æ˜¯**ReLU**ï¼ˆçº¿æ€§æ•´æµå•å…ƒï¼ŒNair & Hinton ([2010](#bib.bib33)))ï¼Œå®šä¹‰ä¸º
    $f(x)=max(x,0)$ å’ŒåŒæ›²æ­£åˆ‡å‡½æ•°ã€‚åœ¨æˆ‘ä»¬çš„ç½‘ç»œä¸­ï¼Œä¸ºäº†é¥±å’Œè¾“å…¥ä¿¡å·ï¼Œæˆ‘ä»¬åœ¨æ‰€æœ‰ç¬¬ä¸€å±‚å·ç§¯å±‚ä¸Šåº”ç”¨åŒæ›²æ­£åˆ‡å‡½æ•°ã€‚å…¶ä»–å±‚ä½¿ç”¨**PReLU**ï¼ˆHe
    et al. ([2015](#bib.bib18))) å‡½æ•°ï¼Œå®šä¹‰ä¸ºï¼š<math  
    alttext="f(x)=\begin{cases}\alpha x&amp;x<0\\
- en: x&amp;x\geq 0\end{cases}" display="inline"><semantics ><mrow
     ><mrow 
    ><mi  >f</mi><mo
    lspace="0em" rspace="0em"  >â€‹</mo><mrow
     ><mo stretchy="false"
     >(</mo><mi
     >x</mi><mo stretchy="false"
     >)</mo></mrow></mrow><mo
     >=</mo><mrow
     ><mo 
    >{</mo><mtable columnspacing="5pt" rowspacing="0pt"
     ><mtr 
    ><mtd  columnalign="left"
     ><mrow
     ><mi
     >Î±</mi><mo
    lspace="0em" rspace="0em"  >â€‹</mo><mi
     >x</mi></mrow></mtd><mtd
     columnalign="left"  ><mrow
     ><mi
     >x</mi><mo
     ><</mo><mn
     >0</mn></mrow></mtd></mtr><mtr
     ><mtd 
    columnalign="left"  ><mi
     >x</mi></mtd><mtd
     columnalign="left"  ><mrow
     ><mi
     >x</mi><mo
     >â‰¥</mo><mn
     >0</mn></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply 
    ><apply  ><ci
     >ğ‘“</ci><ci
     >ğ‘¥</ci></apply><apply
     ><csymbol
    cd="latexml"  >cases</csymbol><apply
     ><ci
     >ğ›¼</ci><ci
     >ğ‘¥</ci></apply><apply
     ><ci
     >ğ‘¥</ci><cn
    type="integer"  >0</cn></apply><ci
     >ğ‘¥</ci><apply
     ><ci
     >ğ‘¥</ci><cn
    type="integer"  >0</cn></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >f(x)=\begin{cases}\alpha
    x&x<0\\ x&x\geq 0\end{cases}</annotation></semantics></math> , with $\alpha$ an
    hyperparameter defined by back-propagation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: \( f(x)=\begin{cases}\alpha x & x < 0\\ x & x \geq 0\end{cases} \)ï¼Œå…¶ä¸­ $\alpha$
    æ˜¯ä¸€ä¸ªé€šè¿‡åå‘ä¼ æ’­å®šä¹‰çš„è¶…å‚æ•°ã€‚
- en: 4 Our CNN architecture
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 æˆ‘ä»¬çš„CNNæ¶æ„
- en: '![Refer to caption](img/c33e458e9ba061261fcc91c78c44d0ba.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒæ ‡é¢˜](img/c33e458e9ba061261fcc91c78c44d0ba.png)'
- en: 'Figure 4: Representation of the architecture that we are proposing. The structure
    is subdivided into five successive processing blocks at different temporal resolutions.
    Two types of convolutions are used: temporal convolutions with four kernel sizes:
    $41\times 1$, $21\times 1$, $11\times 1$ and $5\times 1$ and filter convolutions
    with a kernel size of $5\times 1$.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4ï¼šæˆ‘ä»¬æ‰€æè®®çš„æ¶æ„çš„è¡¨ç¤ºã€‚è¯¥ç»“æ„è¢«ç»†åˆ†ä¸ºäº”ä¸ªè¿ç»­çš„å¤„ç†å—ï¼Œå…·æœ‰ä¸åŒçš„æ—¶é—´åˆ†è¾¨ç‡ã€‚ä½¿ç”¨äº†ä¸¤ç§ç±»å‹çš„å·ç§¯ï¼šå…·æœ‰å››ç§å†…æ ¸å¤§å°çš„æ—¶é—´å·ç§¯ï¼š$41\times
    1$ã€$21\times 1$ã€$11\times 1$ å’Œ $5\times 1$ï¼Œä»¥åŠå†…æ ¸å¤§å°ä¸º$5\times 1$çš„æ»¤æ³¢å™¨å·ç§¯ã€‚
- en: The overall structure can be subdivided into successive processing blocks at
    different temporal resolutions (4, 8, 16, 32 and 64 days) as shown in Figure [4](#S4.F4
    "Figure 4 â€£ 4 Our CNN architecture â€£ Deep learning Approach for Classifying, Detecting
    and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey
    Stripe 82"), on five levels of depth. The initial resolution of LCI is two days
    per pixel. At each processing level, this resolution is reduced by a factor of
    2, by a max-pooling. Moreover, each processing block is powered by a set of feature
    maps coming from an average-pooling retrieved a parallel on the first light curve
    image. These feature maps are then convoluted by three types of temporal convolutions,
    processing images by three different filter sizes. This set of temporal convolutions
    is similar to a multi-resolutions process which is used in modern architectures
    like the GoogleNet network (Szegedy etÂ al. ([2015](#bib.bib46))). The resulting
    feature maps are then transmitted to the processing block of the associated resolution.
    We note $\mathbb{F}_{i}$ the set of resulting feature maps transmitted to the
    processing block $i$. Thus as shown in Figure [4](#S4.F4 "Figure 4 â€£ 4 Our CNN
    architecture â€£ Deep learning Approach for Classifying, Detecting and Predicting
    Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82"),
    feature maps whose a pixel is represented by 4 days are transmitted to the module
    A, and those whose a pixel is represented by 8 days are transmitted to the module
    B, etcâ€¦
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ä½“ç»“æ„å¯ä»¥ç»†åˆ†ä¸ºåœ¨ä¸åŒæ—¶é—´åˆ†è¾¨ç‡ï¼ˆ4ã€8ã€16ã€32 å’Œ 64 å¤©ï¼‰ä¸‹çš„è¿ç»­å¤„ç†å—ï¼Œå¦‚å›¾[4](#S4.F4 "Figure 4 â€£ 4 Our CNN
    architecture â€£ Deep learning Approach for Classifying, Detecting and Predicting
    Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82")æ‰€ç¤ºï¼Œå…±äº”ä¸ªæ·±åº¦å±‚çº§ã€‚LCIçš„åˆå§‹åˆ†è¾¨ç‡ä¸ºæ¯åƒç´ ä¸¤å¤©ã€‚åœ¨æ¯ä¸ªå¤„ç†å±‚çº§ï¼Œè¿™ä¸€åˆ†è¾¨ç‡é€šè¿‡æœ€å¤§æ± åŒ–é™ä½ä¸€å€ã€‚æ­¤å¤–ï¼Œæ¯ä¸ªå¤„ç†å—ç”±ä¸€ç»„æ¥è‡ªå¹³å‡æ± åŒ–çš„ç‰¹å¾å›¾æä¾›ï¼Œè¿™äº›ç‰¹å¾å›¾ä»ç¬¬ä¸€æ¡å…‰æ›²çº¿å›¾åƒä¸­å¹¶è¡Œæ£€ç´¢è€Œæ¥ã€‚è¿™äº›ç‰¹å¾å›¾éšåç»è¿‡ä¸‰ç§ç±»å‹çš„æ—¶é—´å·ç§¯å¤„ç†ï¼Œä½¿ç”¨ä¸‰ç§ä¸åŒçš„æ»¤æ³¢å™¨å¤§å°å¤„ç†å›¾åƒã€‚è¿™ç»„æ—¶é—´å·ç§¯ç±»ä¼¼äºç°ä»£æ¶æ„ä¸­ä½¿ç”¨çš„å¤šåˆ†è¾¨ç‡è¿‡ç¨‹ï¼Œå¦‚GoogleNetç½‘ç»œï¼ˆSzegedy
    et al. ([2015](#bib.bib46)))ã€‚å¾—åˆ°çš„ç‰¹å¾å›¾ç„¶åä¼ è¾“åˆ°ç›¸åº”åˆ†è¾¨ç‡çš„å¤„ç†å—ã€‚æˆ‘ä»¬ç”¨$\mathbb{F}_{i}$è¡¨ç¤ºä¼ è¾“åˆ°å¤„ç†å—$i$çš„ç‰¹å¾å›¾é›†ã€‚å¦‚å›¾[4](#S4.F4
    "Figure 4 â€£ 4 Our CNN architecture â€£ Deep learning Approach for Classifying, Detecting
    and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey
    Stripe 82")æ‰€ç¤ºï¼Œè¡¨ç¤ºæ¯ä¸ªåƒç´ ä¸º4å¤©çš„ç‰¹å¾å›¾è¢«ä¼ è¾“åˆ°æ¨¡å—Aï¼Œè¡¨ç¤ºæ¯ä¸ªåƒç´ ä¸º8å¤©çš„ç‰¹å¾å›¾è¢«ä¼ è¾“åˆ°æ¨¡å—Bï¼Œç­‰ç­‰â€¦
- en: In a first step, a filter convolution (MC1 in schema [4](#S4.F4 "Figure 4 â€£
    4 Our CNN architecture â€£ Deep learning Approach for Classifying, Detecting and
    Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe
    82")) is applied on $\mathbb{F}_{A}$. The feature maps resulting from MC1 are
    noted $\mathbb{F}^{\prime}_{A}$. We then apply two temporal convolutions (TC7
    and TC8) with weights called â€sharedâ€. This term can be explained by the difference
    of the convolution kernels applied to the sets $\mathbb{F}_{A}$ and $\mathbb{F}^{\prime}_{A}$.
    We modify the standard convolutions so a given kernel can be applied on two sets
    of feature maps with different sizes. The goal is to highlight similar temporal
    patterns between two sets of feature maps $\mathbb{F}_{A}$ and $\mathbb{F}^{\prime}_{A}$,
    and so between mixed and not-mixed magnitudes amongst themselves. The feature
    maps coming from the convolution layers TC7 and TC8 on the set $\mathbb{F}_{A}$
    are concatenated and then pooled in the pooling layer P4\. The resulting feature
    maps are noted $\Omega_{B}$ and then transmitted to the processing block B. The
    same process is applied to the set of feature maps $\mathbb{F}^{\prime}_{A}$ giving
    the set $\Omega^{\prime}_{B}$.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬ä¸€æ­¥ä¸­ï¼Œå¯¹$\mathbb{F}_{A}$åº”ç”¨äº†ä¸€ä¸ªæ»¤æ³¢å·ç§¯ï¼ˆMC1ï¼Œè§[4](#S4.F4 "å›¾ 4 â€£ 4 æˆ‘ä»¬çš„CNNæ¶æ„ â€£ ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥æ¡çº¹82ä¸­ç±»æ˜Ÿä½“å…‰åº¦çº¢ç§»çš„æ·±åº¦å­¦ä¹ æ–¹æ³•")ï¼‰ã€‚MC1å¾—åˆ°çš„ç‰¹å¾å›¾è®°ä½œ$\mathbb{F}^{\prime}_{A}$ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯¹å…¶åº”ç”¨äº†ä¸¤ä¸ªæ—¶é—´å·ç§¯ï¼ˆTC7å’ŒTC8ï¼‰ï¼Œå…¶æƒé‡è¢«ç§°ä¸ºâ€œå…±äº«â€ã€‚è¿™ä¸ªæœ¯è¯­å¯ä»¥é€šè¿‡åº”ç”¨äºé›†åˆ$\mathbb{F}_{A}$å’Œ$\mathbb{F}^{\prime}_{A}$çš„å·ç§¯æ ¸çš„å·®å¼‚æ¥è§£é‡Šã€‚æˆ‘ä»¬ä¿®æ”¹äº†æ ‡å‡†å·ç§¯ï¼Œä»¥ä¾¿ä¸€ä¸ªç»™å®šçš„å·ç§¯æ ¸å¯ä»¥åº”ç”¨äºä¸¤ä¸ªä¸åŒå¤§å°çš„ç‰¹å¾å›¾é›†åˆã€‚ç›®æ ‡æ˜¯çªå‡ºæ˜¾ç¤ºä¸¤ä¸ªç‰¹å¾å›¾é›†åˆ$\mathbb{F}_{A}$å’Œ$\mathbb{F}^{\prime}_{A}$ä¹‹é—´çš„ç›¸ä¼¼æ—¶é—´æ¨¡å¼ï¼Œä»è€Œçªå‡ºæ··åˆå’Œæœªæ··åˆçš„é‡ä¹‹é—´çš„å·®å¼‚ã€‚æ¥è‡ªå·ç§¯å±‚TC7å’ŒTC8å¯¹é›†åˆ$\mathbb{F}_{A}$çš„ç‰¹å¾å›¾è¢«è¿æ¥èµ·æ¥ï¼Œç„¶ååœ¨æ± åŒ–å±‚P4ä¸­æ± åŒ–ã€‚å¾—åˆ°çš„ç‰¹å¾å›¾è®°ä½œ$\Omega_{B}$ï¼Œç„¶åä¼ é€’åˆ°å¤„ç†å—Bã€‚å¯¹ç‰¹å¾å›¾é›†åˆ$\mathbb{F}^{\prime}_{A}$åº”ç”¨ç›¸åŒçš„è¿‡ç¨‹ï¼Œå¾—åˆ°é›†åˆ$\Omega^{\prime}_{B}$ã€‚
- en: 'The second processing block performs a temporal convolution with two kernels
    of different sizes (TC12 and TC13) on $\mathbb{F}_{B}$. The resulting feature
    maps are then transmitted to two layers: C7 and MC2\. In the C7 layer, they are
    concatenated with the set $\Omega_{B}$. In the MC2 layer, they are convoluted
    by a filter. The resulting feature maps are concatenated with that of the set
    $\Omega^{\prime}_{B}$. The set of produced feature maps are temporally convoluted
    with shared weights in the TC14 layer. The result is then pooled and transmitted
    to the processing block C.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªå¤„ç†å—å¯¹$\mathbb{F}_{B}$æ‰§è¡Œäº†ä¸€ä¸ªå¸¦æœ‰ä¸åŒå¤§å°çš„ä¸¤ä¸ªå·ç§¯æ ¸ï¼ˆTC12å’ŒTC13ï¼‰çš„æ—¶é—´å·ç§¯ã€‚å¾—åˆ°çš„ç‰¹å¾å›¾ç„¶åè¢«ä¼ é€’åˆ°ä¸¤ä¸ªå±‚ï¼šC7å’ŒMC2ã€‚åœ¨C7å±‚ï¼Œå®ƒä»¬ä¸é›†åˆ$\Omega_{B}$è¿æ¥ã€‚åœ¨MC2å±‚ï¼Œå®ƒä»¬è¢«ä¸€ä¸ªæ»¤æ³¢å™¨å·ç§¯ã€‚å¾—åˆ°çš„ç‰¹å¾å›¾ä¸é›†åˆ$\Omega^{\prime}_{B}$çš„ç‰¹å¾å›¾è¿æ¥ã€‚ç”Ÿæˆçš„ç‰¹å¾å›¾é›†åˆåœ¨TC14å±‚è¿›è¡Œæ—¶é—´å·ç§¯ï¼Œä½¿ç”¨å…±äº«æƒé‡ã€‚ç»“æœç„¶åè¢«æ± åŒ–å¹¶ä¼ é€’åˆ°å¤„ç†å—Cã€‚
- en: The functioning of the rest of the blocks are similar to that of block B. The
    number of feature maps and the size of each layer are noted in Table [A1](#A1.T1
    "Table A1 â€£ Appendix A Appendix â€£ Deep learning Approach for Classifying, Detecting
    and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey
    Stripe 82") in the appendix. We can remark that the processing block E transmits
    only feature maps whose magnitudes are merged, which are then temporally convoluted
    and transmitted to the fully connected layers. After convolution layers, the size
    of feature maps are 53$\times$1 pixel.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä½™å—çš„åŠŸèƒ½ç±»ä¼¼äºå—Bã€‚æ¯å±‚çš„ç‰¹å¾å›¾æ•°é‡å’Œå¤§å°è®°è½½åœ¨é™„å½•ä¸­çš„è¡¨[A1](#A1.T1 "è¡¨ A1 â€£ é™„å½• A â€£ ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥æ¡çº¹82ä¸­ç±»æ˜Ÿä½“å…‰åº¦çº¢ç§»çš„æ·±åº¦å­¦ä¹ æ–¹æ³•")ã€‚æˆ‘ä»¬å¯ä»¥æ³¨æ„åˆ°å¤„ç†å—Eåªä¼ é€’å¹…åº¦å·²åˆå¹¶çš„ç‰¹å¾å›¾ï¼Œè¿™äº›ç‰¹å¾å›¾éšåè¢«æ—¶é—´å·ç§¯å¹¶ä¼ é€’åˆ°å®Œå…¨è¿æ¥å±‚ã€‚åœ¨å·ç§¯å±‚ä¹‹åï¼Œç‰¹å¾å›¾çš„å¤§å°ä¸º53$\times$1åƒç´ ã€‚
- en: In the network architecture we use two processes to avoid over fitting. First,
    all the feature maps are normalized using the batch normalization (Ioffe & Szegedy
    ([2015](#bib.bib23))). Second, the outputs of the fully connected layers are randomly
    dropout (Srivastava etÂ al. ([2014](#bib.bib45))). During the back-propagation
    processing, the network has to determine a large number of parameters, namely
    1,802,032 in the convolution layers and 11,468,80 in the fully-connected layers.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç½‘ç»œæ¶æ„ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸¤ä¸ªè¿‡ç¨‹æ¥é¿å…è¿‡æ‹Ÿåˆã€‚é¦–å…ˆï¼Œæ‰€æœ‰çš„ç‰¹å¾å›¾éƒ½ä½¿ç”¨æ‰¹é‡å½’ä¸€åŒ–ï¼ˆIoffe & Szegedy ([2015](#bib.bib23)))è¿›è¡Œå½’ä¸€åŒ–ã€‚å…¶æ¬¡ï¼Œå®Œå…¨è¿æ¥å±‚çš„è¾“å‡ºä¼šéšæœºä¸¢å¼ƒï¼ˆSrivastava
    et al. ([2014](#bib.bib45)))ã€‚åœ¨åå‘ä¼ æ’­å¤„ç†ä¸­ï¼Œç½‘ç»œéœ€è¦ç¡®å®šå¤§é‡çš„å‚æ•°ï¼Œå³å·ç§¯å±‚ä¸­ä¸º1,802,032ï¼Œå®Œå…¨è¿æ¥å±‚ä¸­ä¸º11,468,80ã€‚
- en: 5 Classification Results
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 åˆ†ç±»ç»“æœ
- en: 5.1 Experimental protocol
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 å®éªŒåè®®
- en: 'We did five cross-validations of the database by always selecting 75$\%$ of
    the LCI for the learning base and 25$\%$ for the testing base.For each of the
    five cross-validations, each CNN completed its learning on 60 epochs (during an
    epoch, each LCI is transmitted to the network and its error is back-propagated).
    Each CNN has three outputs on the softmax layer corresponding to the following
    classes : quasars, pulsating stars (RR Lyrae and $\delta$ Scuti) and other objects.
    During the testing phase, each CNN gives a list of detected quasars in the testing
    base. We merge the lists given by each CNN into one list that we evaluate.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯¹æ•°æ®åº“è¿›è¡Œäº†äº”æ¬¡äº¤å‰éªŒè¯ï¼Œæ¯æ¬¡äº¤å‰éªŒè¯éƒ½é€‰æ‹©äº†75$\%$çš„LCIä½œä¸ºå­¦ä¹ é›†å’Œ25$\%$ä½œä¸ºæµ‹è¯•é›†ã€‚å¯¹äºæ¯ä¸ªäº¤å‰éªŒè¯ï¼Œæ¯ä¸ªCNNè¿›è¡Œäº†60ä¸ªepochçš„å­¦ä¹ ï¼ˆåœ¨ä¸€ä¸ªepochæœŸé—´ï¼Œå°†æ¯ä¸ªLCIä¼ é€’ç»™ç½‘ç»œå¹¶è¿›è¡Œè¯¯å·®åå‘ä¼ æ’­ï¼‰ã€‚æ¯ä¸ªCNNåœ¨softmaxå±‚ä¸Šæœ‰ä¸‰ä¸ªè¾“å‡ºï¼Œåˆ†åˆ«å¯¹åº”ä»¥ä¸‹ç±»åˆ«ï¼šç±»æ˜Ÿä½“ã€è„‰åŠ¨æ˜Ÿï¼ˆRR
    Lyraeå’Œ$\delta$ Scutiï¼‰å’Œå…¶ä»–ç‰©ä½“ã€‚åœ¨æµ‹è¯•é˜¶æ®µï¼Œæ¯ä¸ªCNNåœ¨æµ‹è¯•é›†ä¸­ç»™å‡ºä¸€ä¸ªæ¢æµ‹åˆ°çš„ç±»æ˜Ÿä½“åˆ—è¡¨ã€‚æˆ‘ä»¬å°†æ¯ä¸ªCNNç»™å‡ºçš„åˆ—è¡¨åˆå¹¶æˆä¸€ä¸ªåˆ—è¡¨è¿›è¡Œè¯„ä¼°ã€‚
- en: 5.2 Results
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 ç»“æœ
- en: '![Refer to caption](img/c86faea7f802fe4da7ccb6996e5b6823.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/c86faea7f802fe4da7ccb6996e5b6823.png)'
- en: 'Figure 5: The left histogram illustrates the performance of the CNN depending
    on the median g-band magnitude. The right histogram shows the performance of the
    CNN in function of the redshift. On each histogram the blue bars represent the
    number of well detected quasars by the CNN and the green bars the total number
    of quasars inside the corresponding bin. The recall is indicated over each couple
    of bars.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾5ï¼šå·¦ä¾§ç›´æ–¹å›¾æ˜¾ç¤ºäº†CNNæ€§èƒ½ä¸ä¸­ä½g-bandå¹…åº¦çš„å…³ç³»ã€‚å³ä¾§ç›´æ–¹å›¾æ˜¾ç¤ºäº†CNNæ€§èƒ½ä¸çº¢ç§»çš„å‡½æ•°å…³ç³»ã€‚åœ¨æ¯ä¸ªç›´æ–¹å›¾ä¸Šï¼Œè“è‰²æŸ±ä»£è¡¨CNNæ­£ç¡®æ¢æµ‹åˆ°çš„ç±»æ˜Ÿä½“æ•°é‡ï¼Œç»¿è‰²æŸ±ä»£è¡¨ç›¸åº”åŒºé—´å†…çš„ç±»æ˜Ÿä½“æ€»æ•°ã€‚æ¯å¯¹æŸ±å­ä¸Šæ–¹æ ‡æ˜äº†å¬å›ç‡ã€‚
- en: The performance of the CNN is given on Figure [5](#S5.F5 "Figure 5 â€£ 5.2 Results
    â€£ 5 Classification Results â€£ Deep learning Approach for Classifying, Detecting
    and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey
    Stripe 82") in function of the magnitude and the redshift. We can notice that
    for a g-band magnitude below 17 magnitudes, the value of the recall decreases
    until a recall of 50%. It is due to the too low number of examples of very bright
    quasars in the training set. Indeed there are only 22 light curves of quasars
    in the training database with magnitudes between 15 and 17\. However the recall
    is similar whatever magnitudes above 17 for the g-band magnitude. It is a very
    interesting result because it means that the CNN performance does not depend on
    the magnitude but only on the number of objects in the training database. This
    effect is less visible on the right histogram of Figure [5](#S5.F5 "Figure 5 â€£
    5.2 Results â€£ 5 Classification Results â€£ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82"). Indeed, it is enough to consider only 5% of the training
    database to reach a recall between 98% and 99%. This experiment shows that the
    CNN is invariant to redshift.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: CNNçš„æ€§èƒ½åœ¨å›¾[5](#S5.F5 "å›¾5 â€£ 5.2 ç»“æœ â€£ 5 åˆ†ç±»ç»“æœ â€£ æ–¯éš†æ•°å­—å¤©ç©ºæµ‹é‡åŒºåŸŸ82æ¡å¸¦ä¸­çš„ç±»æ˜Ÿä½“çš„å…‰å­¦çº¢ç§»çš„æ·±åº¦å­¦ä¹ æ–¹æ³•")ä¸­ä»¥å¹…åº¦å’Œçº¢ç§»çš„å‡½æ•°ç»™å‡ºã€‚æˆ‘ä»¬å¯ä»¥æ³¨æ„åˆ°ï¼Œå¯¹äºg-bandå¹…åº¦ä½äº17ï¼Œå¬å›ç‡çš„å€¼ä¸‹é™åˆ°50%ã€‚è¿™æ˜¯å› ä¸ºè®­ç»ƒé›†ä¸­éå¸¸æ˜äº®çš„ç±»æ˜Ÿä½“çš„æ ·æœ¬æ•°é‡å¤ªå°‘ã€‚å®é™…ä¸Šï¼Œè®­ç»ƒæ•°æ®åº“ä¸­åœ¨15è‡³17å¹…åº¦ä¹‹é—´åªæœ‰22ä¸ªç±»æ˜Ÿä½“çš„å…‰å˜æ›²çº¿ã€‚ç„¶è€Œï¼Œå¯¹äºg-bandå¹…åº¦é«˜äº17ï¼Œå¬å›ç‡æ˜¯ç›¸ä¼¼çš„ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰è¶£çš„ç»“æœï¼Œå› ä¸ºå®ƒæ„å‘³ç€CNNçš„æ€§èƒ½å¹¶ä¸å–å†³äºå¹…åº¦ï¼Œè€Œåªå–å†³äºè®­ç»ƒæ•°æ®åº“ä¸­çš„ç‰©ä½“æ•°é‡ã€‚è¿™ç§æ•ˆåº”åœ¨å›¾[5](#S5.F5
    "å›¾5 â€£ 5.2 ç»“æœ â€£ 5 åˆ†ç±»ç»“æœ â€£ æ–¯éš†æ•°å­—å¤©ç©ºæµ‹é‡åŒºåŸŸ82æ¡å¸¦ä¸­çš„ç±»æ˜Ÿä½“çš„å…‰å­¦çº¢ç§»çš„æ·±åº¦å­¦ä¹ æ–¹æ³•") çš„å³ä¾§ç›´æ–¹å›¾ä¸Šä¸å¤ªæ˜æ˜¾ã€‚å®é™…ä¸Šï¼Œåªéœ€è€ƒè™‘è®­ç»ƒæ•°æ®åº“çš„5%å°±èƒ½è¾¾åˆ°98%è‡³99%ä¹‹é—´çš„å¬å›ç‡ã€‚è¿™ä¸ªå®éªŒè¯æ˜äº†CNNå¯¹çº¢ç§»ä¸å˜ã€‚
- en: In the testing base, for a fixed recall of 0.97, 175 new quasars detected by
    the CNN have never been identified before. We call them quasar candidates. Figure
    [6](#S5.F6 "Figure 6 â€£ 5.2 Results â€£ 5 Classification Results â€£ Deep learning
    Approach for Classifying, Detecting and Predicting Photometric Redshifts of Quasars
    in the Sloan Digital Sky Survey Stripe 82") represents the spatial distribution
    of found quasars in the testing base by the CNN. The red crosses characterize
    the new quasar candidates.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æµ‹è¯•é›†ä¸­ï¼Œå¯¹äºå›ºå®šå¬å›ç‡0.97ï¼ŒCNNæ£€æµ‹åˆ°çš„175ä¸ªæ–°ç±»æ˜Ÿä½“ä»¥å‰ä»æœªè¢«é‰´å®šå‡ºã€‚æˆ‘ä»¬ç§°ä¹‹ä¸ºç±»æ˜Ÿä½“å€™é€‰å¯¹è±¡ã€‚å›¾[6](#S5.F6 "å›¾6 â€£ 5.2
    ç»“æœ â€£ 5 åˆ†ç±»ç»“æœ â€£ æ–¯éš†æ•°å­—å¤©ç©ºæµ‹é‡åŒºåŸŸ82æ¡å¸¦ä¸­çš„ç±»æ˜Ÿä½“çš„å…‰å­¦çº¢ç§»çš„æ·±åº¦å­¦ä¹ æ–¹æ³•")è¡¨ç¤ºCNNåœ¨æµ‹è¯•é›†ä¸­å‘ç°çš„ç±»æ˜Ÿä½“çš„ç©ºé—´åˆ†å¸ƒã€‚çº¢è‰²åå­—æ ‡å¿—ç€æ–°çš„ç±»æ˜Ÿä½“å€™é€‰å¯¹è±¡ã€‚
- en: '![Refer to caption](img/5dfc422472d267dd837b18b98399658e.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/5dfc422472d267dd837b18b98399658e.png)'
- en: 'Figure 6: Spatial distribution of quasars detected by the CNN during the testing
    phase. The gray crosses represent the well-known detected quasars, and the red
    crosses are the 175 new quasar candidates. They are uniformly distributed in the
    sky.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾6ï¼šCNNåœ¨æµ‹è¯•é˜¶æ®µæ£€æµ‹åˆ°çš„ç±»æ˜Ÿä½“çš„ç©ºé—´åˆ†å¸ƒã€‚ç°è‰²çš„äº¤å‰ç‚¹è¡¨ç¤ºå·²çŸ¥çš„æ£€æµ‹åˆ°çš„ç±»æ˜Ÿä½“ï¼Œçº¢è‰²çš„äº¤å‰ç‚¹æ˜¯175ä¸ªæ–°çš„ç±»æ˜Ÿä½“å€™é€‰è€…ã€‚å®ƒä»¬åœ¨å¤©ç©ºä¸­å‡åŒ€åˆ†å¸ƒã€‚
- en: As we can see, the quasars detected by the CNN are distributed in an uniform
    manner. Figure [7](#S5.F7 "Figure 7 â€£ 5.2 Results â€£ 5 Classification Results â€£
    Deep learning Approach for Classifying, Detecting and Predicting Photometric Redshifts
    of Quasars in the Sloan Digital Sky Survey Stripe 82") shows the average number
    of quasars in the sky per square degree, detected by the CNN, against the recall.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘ä»¬æ‰€è§ï¼ŒCNNæ£€æµ‹åˆ°çš„ç±»æ˜Ÿä½“åˆ†å¸ƒå‡åŒ€ã€‚å›¾ [7](#S5.F7 "Figure 7 â€£ 5.2 Results â€£ 5 Classification
    Results â€£ Deep learning Approach for Classifying, Detecting and Predicting Photometric
    Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82") æ˜¾ç¤ºäº†CNNæ£€æµ‹åˆ°çš„å¤©ç©ºæ¯å¹³æ–¹åº¦çš„ç±»æ˜Ÿä½“å¹³å‡æ•°é‡ä¸å¬å›ç‡çš„å…³ç³»ã€‚
- en: '![Refer to caption](img/d6174c38a8f91ffc6e83fb84cb889ba9.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/d6174c38a8f91ffc6e83fb84cb889ba9.png)'
- en: 'Figure 7: Average number of quasars in the sky per square degree, detected
    by the CNN, against the recall. The larger the recall, the higher the number of
    the detected quasars is. For a recall of 0.92, the average number of detected
    quasars is 20 per square degree. Then this number is drastically increased since
    the precision is reduced and so the contamination of non-quasar sources is increased.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾7ï¼šCNNæ£€æµ‹åˆ°çš„å¤©ç©ºæ¯å¹³æ–¹åº¦çš„ç±»æ˜Ÿä½“å¹³å‡æ•°é‡ä¸å¬å›ç‡çš„å…³ç³»ã€‚å¬å›ç‡è¶Šå¤§ï¼Œæ£€æµ‹åˆ°çš„ç±»æ˜Ÿä½“æ•°é‡è¶Šé«˜ã€‚å¯¹äº0.92çš„å¬å›ç‡ï¼Œæ¯å¹³æ–¹åº¦çš„æ£€æµ‹åˆ°çš„ç±»æ˜Ÿä½“å¹³å‡æ•°é‡ä¸º20ä¸ªã€‚ç„¶åè¿™ä¸ªæ•°å­—æ€¥å‰§å¢åŠ ï¼Œå› ä¸ºç²¾åº¦é™ä½ï¼Œéç±»æ˜Ÿä½“æºçš„æ±¡æŸ“å¢åŠ ã€‚
- en: As the recall increases, the number of quasars per square degree increases,
    which is consistent as we detected more and more quasars. For a recall around
    0.92, the average number of quasars per square degree is about 20\. Then, this
    number is drastically increased because the precision is reduced and the sample
    is contaminated by sources which are not quasars.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€å¬å›ç‡çš„æé«˜ï¼Œæ¯å¹³æ–¹åº¦çš„ç±»æ˜Ÿä½“æ•°é‡å¢åŠ ï¼Œè¿™ä¸æˆ‘ä»¬æ£€æµ‹åˆ°è¶Šæ¥è¶Šå¤šçš„ç±»æ˜Ÿä½“æ˜¯ä¸€è‡´çš„ã€‚å¯¹äºçº¦0.92çš„å¬å›ç‡ï¼Œæ¯å¹³æ–¹åº¦çš„ç±»æ˜Ÿä½“å¹³å‡æ•°é‡çº¦ä¸º20ä¸ªã€‚ç„¶åï¼Œç”±äºç²¾åº¦é™ä½ä¸”æ ·æœ¬ä¸­æ··å…¥äº†éç±»æ˜Ÿä½“çš„æºï¼Œè¿™ä¸ªæ•°å­—æ€¥å‰§å¢åŠ ã€‚
- en: It is also interesting to highlight that a well known property of quasars is
    met by the new quasar candidates, namely a â€bluer when brighterâ€ tendency. This
    trend has been well established in the UV/optical color variations in quasar (e.g.
    Cristiani etÂ al. ([1997](#bib.bib9)), Giveon etÂ al. ([1999](#bib.bib16)), Vanden
    Berk etÂ al. ([2004](#bib.bib48))). Figure [8](#S5.F8 "Figure 8 â€£ 5.2 Results â€£
    5 Classification Results â€£ Deep learning Approach for Classifying, Detecting and
    Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe
    82") represents the amplitude of variations of detected quasars in the u-band
    filter against the r-band filter at different recalls. We note that $83.6\%$ and
    $88.7\%$ of variation amplitudes in the u-band filter are larger than in the r-band
    filter for a recall of 0.90 and 0.97 respectively. Thus the detected quasars show
    larger variation amplitudes in bluer bands and so a strong wavelength dependence.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜å€¼å¾—æŒ‡å‡ºçš„æ˜¯ï¼Œæ–°ç±»æ˜Ÿä½“å€™é€‰è€…ç¬¦åˆä¸€ä¸ªå·²çŸ¥çš„ç±»æ˜Ÿä½“ç‰¹æ€§ï¼Œå³â€œæ›´äº®æ—¶æ›´è“â€çš„è¶‹åŠ¿ã€‚è¿™ä¸€è¶‹åŠ¿åœ¨ç±»æ˜Ÿä½“çš„UV/å…‰å­¦é¢œè‰²å˜åŒ–ä¸­å·²ç»å¾—åˆ°å¾ˆå¥½çš„éªŒè¯ï¼ˆä¾‹å¦‚ï¼ŒCristianiç­‰äºº
    ([1997](#bib.bib9))ï¼ŒGiveonç­‰äºº ([1999](#bib.bib16))ï¼ŒVanden Berkç­‰äºº ([2004](#bib.bib48))ï¼‰ã€‚å›¾
    [8](#S5.F8 "Figure 8 â€£ 5.2 Results â€£ 5 Classification Results â€£ Deep learning
    Approach for Classifying, Detecting and Predicting Photometric Redshifts of Quasars
    in the Sloan Digital Sky Survey Stripe 82") æ˜¾ç¤ºäº†åœ¨ä¸åŒå¬å›ç‡ä¸‹ï¼Œuå¸¦æ»¤å…‰ç‰‡ä¸rå¸¦æ»¤å…‰ç‰‡æ£€æµ‹åˆ°çš„ç±»æ˜Ÿä½“çš„å˜åŒ–å¹…åº¦ã€‚æˆ‘ä»¬æ³¨æ„åˆ°ï¼Œåœ¨å¬å›ç‡ä¸º0.90å’Œ0.97æ—¶ï¼Œuå¸¦æ»¤å…‰ç‰‡ä¸­çš„å˜åŒ–å¹…åº¦åˆ†åˆ«æ¯”rå¸¦æ»¤å…‰ç‰‡å¤§$83.6\%$å’Œ$88.7\%$ã€‚å› æ­¤ï¼Œæ£€æµ‹åˆ°çš„ç±»æ˜Ÿä½“åœ¨è“å…‰å¸¦ä¸­çš„å˜åŒ–å¹…åº¦æ›´å¤§ï¼Œè¡¨ç°å‡ºå¼ºçš„æ³¢é•¿ä¾èµ–æ€§ã€‚
- en: '![Refer to caption](img/9fdc25b733207d4315de07102f7ead0a.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/9fdc25b733207d4315de07102f7ead0a.png)'
- en: 'Figure 8: Amplitudes of variation of quasars detected by the CNN from the u-band
    filter against those from the r-band filter at three different recalls: 0.90,
    0.95 and 0.97\. The black crosses represent all the known quasars during the testing
    phase. The red crosses are the 175 new quasar candidates. The dashed line represent
    the line $y=x$. The quasars show larger variation amplitudes in bluer-bands. This
    tendency highlights a strong wavelength dependence.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾8ï¼šCNNä»uå¸¦æ»¤å…‰ç‰‡æ£€æµ‹åˆ°çš„ç±»æ˜Ÿä½“çš„å˜åŒ–å¹…åº¦ä¸ä»rå¸¦æ»¤å…‰ç‰‡æ£€æµ‹åˆ°çš„ç±»æ˜Ÿä½“åœ¨ä¸‰ç§ä¸åŒå¬å›ç‡ï¼ˆ0.90ã€0.95å’Œ0.97ï¼‰ä¸‹çš„å˜åŒ–å¹…åº¦ã€‚é»‘è‰²äº¤å‰ç‚¹è¡¨ç¤ºæµ‹è¯•é˜¶æ®µæ‰€æœ‰å·²çŸ¥çš„ç±»æ˜Ÿä½“ã€‚çº¢è‰²äº¤å‰ç‚¹æ˜¯175ä¸ªæ–°çš„ç±»æ˜Ÿä½“å€™é€‰è€…ã€‚è™šçº¿è¡¨ç¤ºçº¿
    $y=x$ã€‚ç±»æ˜Ÿä½“åœ¨è“å…‰å¸¦ä¸­çš„å˜åŒ–å¹…åº¦è¾ƒå¤§ã€‚è¿™ç§è¶‹åŠ¿çªæ˜¾äº†å¼ºçš„æ³¢é•¿ä¾èµ–æ€§ã€‚
- en: 5.3 Comparison with a random forest classifier
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 ä¸éšæœºæ£®æ—åˆ†ç±»å™¨çš„æ¯”è¾ƒ
- en: We compare the performance of our algorithm with that of a random forest classifier
    whose we empirically estimated the best parameters on the same database. It contains
    400 decision trees and an unlimited depth. The features used are included in a
    python library named FATS (Feature Analysis for Time Series, Nun etÂ al. ([2015](#bib.bib34)))
    which is a compilation of some of the existing light-curve features.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æˆ‘ä»¬çš„ç®—æ³•æ€§èƒ½ä¸éšæœºæ£®æ—åˆ†ç±»å™¨çš„æ€§èƒ½è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬åœ¨ç›¸åŒæ•°æ®åº“ä¸Šé€šè¿‡ç»éªŒæ–¹æ³•ä¼°è®¡äº†å…¶æœ€ä½³å‚æ•°ã€‚è¯¥åˆ†ç±»å™¨åŒ…å« 400 æ£µå†³ç­–æ ‘ï¼Œæ·±åº¦ä¸é™ã€‚ä½¿ç”¨çš„ç‰¹å¾åŒ…å«åœ¨ä¸€ä¸ªåä¸º
    FATSï¼ˆFeature Analysis for Time Series, Nun et al. ([2015](#bib.bib34)ï¼‰ï¼‰çš„ Python
    åº“ä¸­ï¼Œè¯¥åº“æ˜¯ä¸€äº›ç°æœ‰å…‰å˜æ›²çº¿ç‰¹å¾çš„æ±‡ç¼–ã€‚
- en: At a fixed recall of 0.90, the precision is 0.988 for the CNN and 0.985 for
    the random forest. Then for a fixed recall of 0.97, the precision is 0.964 and
    0.973 for the CNN and the random forest respectively. The performances of the
    two methods are closed and a little better for the random forest. A possible explication
    concerns the number of freedom degrees. Indeed for the random forest, about 640
    000 parameters are defined whereas for the CNN there are about 13 000 000\. Thus,
    due to the large number of parameters that have to be determined by backpropagation,
    the CNN should have better performance with more data, especially with large surveys.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å›ºå®šå¬å›ç‡ä¸º 0.90 çš„æƒ…å†µä¸‹ï¼ŒCNN çš„ç²¾åº¦ä¸º 0.988ï¼Œè€Œéšæœºæ£®æ—çš„ç²¾åº¦ä¸º 0.985ã€‚ç„¶åï¼Œåœ¨å›ºå®šå¬å›ç‡ä¸º 0.97 çš„æƒ…å†µä¸‹ï¼ŒCNN å’Œéšæœºæ£®æ—çš„ç²¾åº¦åˆ†åˆ«ä¸º
    0.964 å’Œ 0.973ã€‚è¿™ä¸¤ç§æ–¹æ³•çš„è¡¨ç°æ¥è¿‘ï¼Œè€Œéšæœºæ£®æ—ç¨å¾®æ›´å¥½ã€‚ä¸€ç§å¯èƒ½çš„è§£é‡Šæ¶‰åŠè‡ªç”±åº¦çš„æ•°é‡ã€‚å®é™…ä¸Šï¼Œå¯¹äºéšæœºæ£®æ—ï¼Œå¤§çº¦å®šä¹‰äº† 640,000 ä¸ªå‚æ•°ï¼Œè€Œå¯¹äº
    CNNï¼Œå‚æ•°æ•°é‡çº¦ä¸º 13,000,000ã€‚å› æ­¤ï¼Œç”±äº CNN éœ€è¦é€šè¿‡åå‘ä¼ æ’­ç¡®å®šå¤§é‡å‚æ•°ï¼Œåœ¨æ•°æ®é‡æ›´å¤šçš„æƒ…å†µä¸‹ï¼ŒCNN åº”è¯¥èƒ½æœ‰æ›´å¥½çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§å‹è°ƒæŸ¥ä¸­ã€‚
- en: 5.4 Combination of a CNN and a random forest
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 CNN å’Œéšæœºæ£®æ—çš„ç»“åˆ
- en: We combine the probabilities given by the CNN and the random forest by averaging
    them. For a fixed recall of 0.90 the precision is 0.99 and for a recall of 0.97,
    the precision is 0.98\. Thus the combination of the two classifiers makes good
    performance even better. Figure [9](#S5.F9 "Figure 9 â€£ 5.4 Combination of a CNN
    and a random forest â€£ 5 Classification Results â€£ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82") shows the receiver operating characteristic curve (ROC
    curve hereafter) which is a graphical plot that illustrates the performance of
    a classifier by plotting the precision against the recall. We can see that the
    random forest performance (red curve) is better than that of the CNN (black curve)
    until a recall of 0.978, where the CNN performance slightly drops. Moreover the
    ROC curve representing the combination of the two classifiers (green curve) is
    above the two others and shows that combining a CNN classifier and a random forest
    classifier gives better classification performance. The improvement obtained by
    the combination of the CNN and the random forest can be explained by the complementarity
    between the features given to the random forest and the features extracted by
    the CNN. Indeed, features used by the random forest are defined by the user and
    are specific for the classification of light curves of variable objects in general
    but they could not be perfectly designed for this classification problem that
    we considered. On another side the CNN learns from scratch without any prior.
    The CNN found relevant features which are specific to the used database and so
    complete the information given by the features used by the RF. However, since
    the CNN learns features from the data, if there is not a large number of examples
    for a kind of objects, such as the high redshift quasars, the CNN does not find
    and learn the best features. In this case, it is relevant to use the results from
    the random forest to improve the classification. So depending on the number of
    data, the random forest features or the CNN features can complete each other.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡å¯¹ CNN å’Œéšæœºæ£®æ—ç»™å‡ºçš„æ¦‚ç‡è¿›è¡Œå¹³å‡æ¥è¿›è¡Œç»„åˆã€‚å¯¹äºå›ºå®šçš„å¬å›ç‡ 0.90ï¼Œç²¾åº¦ä¸º 0.99ï¼Œè€Œå¯¹äºå¬å›ç‡ 0.97ï¼Œç²¾åº¦ä¸º 0.98ã€‚å› æ­¤ï¼Œä¸¤ä¸ªåˆ†ç±»å™¨çš„ç»„åˆä½¿å¾—è‰¯å¥½çš„æ€§èƒ½æ›´ä¸Šä¸€å±‚æ¥¼ã€‚å›¾
    [9](#S5.F9 "å›¾ 9 â€£ 5.4 CNN å’Œéšæœºæ£®æ—çš„ç»„åˆ â€£ 5 åˆ†ç±»ç»“æœ â€£ ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥ç¬¬82æ¡çº¹çš„ç±»æ˜Ÿä½“å…‰åº¦çº¢ç§»çš„æ·±åº¦å­¦ä¹ æ–¹æ³•")
    æ˜¾ç¤ºäº†æ¥æ”¶è€…æ“ä½œç‰¹å¾æ›²çº¿ï¼ˆROC æ›²çº¿ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å›¾å½¢åŒ–çš„ç»˜å›¾æ–¹æ³•ï¼Œç”¨äºé€šè¿‡ç»˜åˆ¶ç²¾åº¦ä¸å¬å›ç‡çš„å…³ç³»æ¥å±•ç¤ºåˆ†ç±»å™¨çš„æ€§èƒ½ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œéšæœºæ£®æ—çš„æ€§èƒ½ï¼ˆçº¢è‰²æ›²çº¿ï¼‰ä¼˜äº
    CNNï¼ˆé»‘è‰²æ›²çº¿ï¼‰ï¼Œç›´åˆ°å¬å›ç‡ä¸º 0.978ï¼Œæ­¤æ—¶ CNN çš„æ€§èƒ½ç•¥å¾®ä¸‹é™ã€‚æ­¤å¤–ï¼Œä»£è¡¨ä¸¤ä¸ªåˆ†ç±»å™¨ç»„åˆçš„ ROC æ›²çº¿ï¼ˆç»¿è‰²æ›²çº¿ï¼‰é«˜äºå…¶ä»–ä¸¤æ¡æ›²çº¿ï¼Œæ˜¾ç¤ºäº†ç»„åˆ
    CNN åˆ†ç±»å™¨å’Œéšæœºæ£®æ—åˆ†ç±»å™¨å¯ä»¥æä¾›æ›´å¥½çš„åˆ†ç±»æ€§èƒ½ã€‚CNN å’Œéšæœºæ£®æ—çš„ç»„åˆæ‰€è·å¾—çš„æ”¹è¿›å¯ä»¥é€šè¿‡éšæœºæ£®æ—æä¾›çš„ç‰¹å¾å’Œ CNN æå–çš„ç‰¹å¾ä¹‹é—´çš„äº’è¡¥æ€§æ¥è§£é‡Šã€‚å®é™…ä¸Šï¼Œéšæœºæ£®æ—ä½¿ç”¨çš„ç‰¹å¾ç”±ç”¨æˆ·å®šä¹‰ï¼Œé€šå¸¸é’ˆå¯¹å˜é‡å¯¹è±¡çš„å…‰åº¦æ›²çº¿åˆ†ç±»ï¼Œä½†å®ƒä»¬å¯èƒ½æ— æ³•å®Œç¾åœ°è®¾è®¡ç”¨äºæˆ‘ä»¬è€ƒè™‘çš„åˆ†ç±»é—®é¢˜ã€‚è€Œ
    CNN ä»å¤´å¼€å§‹å­¦ä¹ ï¼Œæ²¡æœ‰ä»»ä½•å…ˆéªŒçŸ¥è¯†ã€‚CNN å‘ç°äº†å¯¹æ‰€ç”¨æ•°æ®åº“ç‰¹å®šçš„ç›¸å…³ç‰¹å¾ï¼Œä»è€Œè¡¥å……äº† RF ä½¿ç”¨çš„ç‰¹å¾æ‰€æä¾›çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œç”±äº CNN ä»æ•°æ®ä¸­å­¦ä¹ ç‰¹å¾ï¼Œå¦‚æœæŸç§å¯¹è±¡çš„æ ·æœ¬æ•°é‡ä¸å¤šï¼Œä¾‹å¦‚é«˜çº¢ç§»ç±»æ˜Ÿä½“ï¼ŒCNN
    å¯èƒ½æ— æ³•æ‰¾åˆ°å¹¶å­¦ä¹ æœ€ä½³ç‰¹å¾ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåˆ©ç”¨éšæœºæ£®æ—çš„ç»“æœæ¥æ”¹å–„åˆ†ç±»æ˜¯æœ‰æ„ä¹‰çš„ã€‚å› æ­¤ï¼Œæ ¹æ®æ•°æ®çš„æ•°é‡ï¼Œéšæœºæ£®æ—ç‰¹å¾æˆ– CNN ç‰¹å¾å¯ä»¥äº’ç›¸è¡¥å……ã€‚
- en: '![Refer to caption](img/129ebd81f2a9d23eac762b1f11226f12.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/129ebd81f2a9d23eac762b1f11226f12.png)'
- en: 'Figure 9: ROC curve which plots the precision of the classifier against the
    recall. The performance of the CNN classifier is represented by black dots, those
    of the random forest by red plus and the performance of the combination of the
    two classifiers is represented by green crosses.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾9ï¼šROC æ›²çº¿ç»˜åˆ¶äº†åˆ†ç±»å™¨çš„ç²¾åº¦ä¸å¬å›ç‡çš„å…³ç³»ã€‚CNN åˆ†ç±»å™¨çš„æ€§èƒ½ç”±é»‘ç‚¹è¡¨ç¤ºï¼Œéšæœºæ£®æ—çš„æ€§èƒ½ç”±çº¢è‰²åŠ å·è¡¨ç¤ºï¼Œè€Œä¸¤ä¸ªåˆ†ç±»å™¨ç»„åˆçš„æ€§èƒ½ç”±ç»¿è‰²äº¤å‰è¡¨ç¤ºã€‚
- en: 6 Photometric redshifts of quasars
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 ä¸ªç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»
- en: Photometric redshifts are a way to determine the redshift of an object by using
    only the apparent magnitudes through different filters, or photometric images.
    They constitute a powerful technique because they allow us to be free of spectroscopy
    data which are limited by the brightness of the source and by the cost of instruments.
    This methodology has been developed by Baum (Baum ([1962](#bib.bib2))) by observing
    the Spectral Energy Distribution (SED) of six elliptic galaxies in the Virgo cluster
    in nine bands from 3730Ã… to 9875Ã…. The approach using template-fitting models
    which extracts features from celestial observational information and then matches
    them with the designed templates constructed by theoretical models or real observations
    has been used intensively (e.g. Bolzonella etÂ al. ([2000](#bib.bib5)), Coupon
    etÂ al. ([2009](#bib.bib8)) Ilbert etÂ al. ([2010](#bib.bib22))). However the accuracy
    of the method strongly depends on simulated or real data. Moreover, the emergence
    of massive photometric data obtained by multiple large-scale sky surveys suggests
    the need of an automatic method such as machine learning algorithms. Several methods
    were used to estimate photometric redshifts of galaxies or quasars like a K-nearest
    neighbors (e.g. Zhang etÂ al. ([2013](#bib.bib52)), KÃ¼gler etÂ al. ([2015](#bib.bib28))),
    an artificial neural network (e.g. Firth etÂ al. ([2003](#bib.bib14)), Collister
    & Lahav ([2004](#bib.bib6)), Blake etÂ al. ([2007](#bib.bib3)), Oyaizu etÂ al. ([2008](#bib.bib35)),
    YÃ¨che etÂ al. ([2010](#bib.bib49)), Zhang etÂ al. ([2009](#bib.bib51))), both a
    K-nearest neighbors and a support vector machine (Han etÂ al. ([2016](#bib.bib17))).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å…‰åº¦çº¢ç§»æ˜¯ä¸€ç§é€šè¿‡ä»…ä½¿ç”¨ä¸åŒæ»¤å…‰ç‰‡æˆ–å…‰åº¦å›¾åƒä¸­çš„è§†æ˜Ÿç­‰ç¡®å®šç‰©ä½“çº¢ç§»çš„æ–¹æ³•ã€‚å®ƒä»¬æ˜¯ä¸€ç§å¼ºå¤§çš„æŠ€æœ¯ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥ä¸ä¾èµ–å—é™äºæºçš„äº®åº¦å’Œä»ªå™¨æˆæœ¬çš„å…‰è°±å­¦æ•°æ®ã€‚è¿™ç§æ–¹æ³•ç”±
    Baumï¼ˆBaum ([1962](#bib.bib2)ï¼‰æå‡ºï¼Œé€šè¿‡è§‚å¯Ÿç»´å°”æˆˆæ˜Ÿç³»å›¢ä¸­å…­ä¸ªæ¤­åœ†æ˜Ÿç³»åœ¨3730Ã…åˆ°9875Ã…çš„ä¹ä¸ªé¢‘æ®µçš„å…‰è°±èƒ½é‡åˆ†å¸ƒï¼ˆSEDï¼‰ã€‚ä½¿ç”¨æ¨¡æ¿æ‹Ÿåˆæ¨¡å‹çš„æ–¹æ³•æå–å¤©æ–‡è§‚æµ‹ä¿¡æ¯çš„ç‰¹å¾ï¼Œç„¶åå°†å…¶ä¸ç”±ç†è®ºæ¨¡å‹æˆ–çœŸå®è§‚æµ‹æ„å»ºçš„è®¾è®¡æ¨¡æ¿è¿›è¡ŒåŒ¹é…å·²ç»å¾—åˆ°å¹¿æ³›åº”ç”¨ï¼ˆä¾‹å¦‚
    Bolzonella etÂ al. ([2000](#bib.bib5)), Coupon etÂ al. ([2009](#bib.bib8)) Ilbert
    etÂ al. ([2010](#bib.bib22))ï¼‰ã€‚ç„¶è€Œï¼Œè¯¥æ–¹æ³•çš„å‡†ç¡®æ€§åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ¨¡æ‹Ÿæ•°æ®æˆ–çœŸå®æ•°æ®ã€‚æ­¤å¤–ï¼Œå¤šä¸ªå¤§è§„æ¨¡å¤©ç©ºè°ƒæŸ¥è·å¾—çš„å¤§è§„æ¨¡å…‰åº¦æ•°æ®çš„å‡ºç°è¡¨æ˜éœ€è¦è‡ªåŠ¨æ–¹æ³•ï¼Œå¦‚æœºå™¨å­¦ä¹ ç®—æ³•ã€‚å·²ç»ä½¿ç”¨äº†å‡ ç§æ–¹æ³•æ¥ä¼°è®¡æ˜Ÿç³»æˆ–ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»ï¼Œä¾‹å¦‚Kæœ€è¿‘é‚»æ–¹æ³•ï¼ˆä¾‹å¦‚
    Zhang etÂ al. ([2013](#bib.bib52)), KÃ¼gler etÂ al. ([2015](#bib.bib28))ï¼‰ï¼Œäººå·¥ç¥ç»ç½‘ç»œæ–¹æ³•ï¼ˆä¾‹å¦‚
    Firth etÂ al. ([2003](#bib.bib14)), Collister & Lahav ([2004](#bib.bib6)), Blake
    etÂ al. ([2007](#bib.bib3)), Oyaizu etÂ al. ([2008](#bib.bib35)), YÃ¨che etÂ al. ([2010](#bib.bib49)),
    Zhang etÂ al. ([2009](#bib.bib51))ï¼‰ï¼Œä»¥åŠåŒæ—¶ä½¿ç”¨Kæœ€è¿‘é‚»å’Œæ”¯æŒå‘é‡æœºçš„æ–¹æ³•ï¼ˆHan etÂ al. ([2016](#bib.bib17)))ã€‚
- en: We propose to predict the photometric redshifts of quasars with a CNN. For that,
    we use 80% of the quasar light curves for the training database and 20% for the
    testing database. To reduce the variability we cross validate the experiment and
    only show the mean of the results. The distribution of known spectroscopy redshifts
    are sliced in 60 bins of 0.04 in width. We used a network with a similar architecture
    that is represented in Figure [4](#S4.F4 "Figure 4 â€£ 4 Our CNN architecture â€£
    Deep learning Approach for Classifying, Detecting and Predicting Photometric Redshifts
    of Quasars in the Sloan Digital Sky Survey Stripe 82"). The softmax gives the
    probability of belonging to each redshifts class. To predict the final regression
    value, results of each class are added by weighting them by the probability given
    by the Softmax. Again, the network takes the LCI as input (see Section [3.1](#S3.SS1
    "3.1 Light Curve Images â€£ 3 The Convolutional Neural Network â€£ Deep learning Approach
    for Classifying, Detecting and Predicting Photometric Redshifts of Quasars in
    the Sloan Digital Sky Survey Stripe 82")) so as to include the information of
    the variability of objects in the estimation of redshifts.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æå‡ºä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œæ¥é¢„æµ‹ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†80%çš„ç±»æ˜Ÿä½“å…‰å˜æ›²çº¿ç”¨äºè®­ç»ƒæ•°æ®åº“ï¼Œå°†20%ç”¨äºæµ‹è¯•æ•°æ®åº“ã€‚ä¸ºäº†å‡å°‘å˜å¼‚æ€§ï¼Œæˆ‘ä»¬è¿›è¡Œäº¤å‰éªŒè¯å®éªŒï¼Œä»…å±•ç¤ºç»“æœçš„å‡å€¼ã€‚å·²çŸ¥å…‰è°±çº¢ç§»çš„åˆ†å¸ƒè¢«åˆ‡åˆ†æˆ60ä¸ª0.04å®½åº¦çš„binã€‚æˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªç±»ä¼¼çš„ç½‘ç»œæ¶æ„ï¼Œå¦‚å›¾[4](#S4.F4
    "å›¾4 â€£ 4æˆ‘ä»¬çš„CNNæ¶æ„ â€£ ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥Stripe 82ä¸­ç±»æ˜Ÿä½“å…‰åº¦çº¢ç§»çš„æ·±åº¦å­¦ä¹ æ–¹æ³•")æ‰€ç¤ºã€‚Softmaxç»™å‡ºäº†å±äºæ¯ä¸ªçº¢ç§»ç±»åˆ«çš„æ¦‚ç‡ã€‚ä¸ºäº†é¢„æµ‹æœ€ç»ˆçš„å›å½’å€¼ï¼Œé€šè¿‡ä½¿ç”¨Softmaxç»™å‡ºçš„æ¦‚ç‡å¯¹æ¯ä¸ªç±»åˆ«çš„ç»“æœè¿›è¡ŒåŠ æƒæ±‚å’Œã€‚åŒæ ·ï¼Œç½‘ç»œä»¥LCIä½œä¸ºè¾“å…¥ï¼ˆå‚è§ç¬¬[3.1](#S3.SS1
    "3.1å…‰æ›²çº¿å›¾åƒ â€£ 3å·ç§¯ç¥ç»ç½‘ç»œ â€£ ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥Stripe 82ä¸­ç±»æ˜Ÿä½“å…‰åº¦çº¢ç§»çš„æ·±åº¦å­¦ä¹ æ–¹æ³•")èŠ‚ï¼‰ï¼Œä»¥ä¾¿åœ¨ä¼°è®¡çº¢ç§»æ—¶åŒ…å«ç‰©ä½“å˜å¼‚æ€§çš„ä¿¡æ¯ã€‚
- en: To evaluate the proposed method, we compare it with a more classical approach
    using an extraction of features. For that, we compared the performances of four
    classifiers namely a K-nearest neighbors (KNN), a support vector machine (SVM,
    with linear and Gaussian kernels), a random forest (RF) and a Gaussian process
    classifier.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¯„ä¼°æå‡ºçš„æ–¹æ³•ï¼Œæˆ‘ä»¬å°†å…¶ä¸ä½¿ç”¨ç‰¹å¾æå–çš„ç»å…¸æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†å››ç§åˆ†ç±»å™¨çš„æ€§èƒ½ï¼Œå³K-æœ€è¿‘é‚»ï¼ˆKNNï¼‰ã€æ”¯æŒå‘é‡æœºï¼ˆSVMï¼Œå…·æœ‰çº¿æ€§å’Œé«˜æ–¯æ ¸ï¼‰ã€éšæœºæ£®æ—ï¼ˆRFï¼‰å’Œé«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨ã€‚
- en: '| Feature | Absolute error | $\chi^{2}$ | best K |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| ç‰¹å¾ | ç»å¯¹è¯¯å·® | $\chi^{2}$ | æœ€ä½³K |'
- en: '| --- | --- | --- | --- |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Mean | 0.282 | 0.239 | 2 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| å¹³å‡å€¼ | 0.282 | 0.239 | 2 |'
- en: '| Mean+error | 0.283 | 0.240 | 2 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| å¹³å‡å€¼+è¯¯å·® | 0.283 | 0.240 | 2 |'
- en: '| Mean+color+error | 0.263 | 0.199 | 3 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| å¹³å‡å€¼+é¢œè‰²+è¯¯å·® | 0.263 | 0.199 | 3 |'
- en: '| Mean+color amplitudes+error | 0.253 | 0.182 | 4 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| å¹³å‡å€¼+é¢œè‰²å¹…åº¦+è¯¯å·® | 0.253 | 0.182 | 4 |'
- en: '|  |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| color+error | 0.226 | 0.163 | 4 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| é¢œè‰²+è¯¯å·® | 0.226 | 0.163 | 4 |'
- en: '| color | 0.226 | 0.156 | 6 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| é¢œè‰² | 0.226 | 0.156 | 6 |'
- en: 'Table 1: Evaluation of the K-Nearest Neighbors classifier efficiency using
    different features based on the absolute error and the error given by a $\chi^{2}$
    test. K is the number of neighbors taking into account by the KNN algorithm.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 1ï¼šä½¿ç”¨ä¸åŒç‰¹å¾è¯„ä¼°K-æœ€è¿‘é‚»åˆ†ç±»å™¨çš„æ•ˆç‡ï¼ŒåŸºäºç»å¯¹è¯¯å·®å’Œ$\chi^{2}$æµ‹è¯•ç»™å‡ºçš„è¯¯å·®ã€‚Kæ˜¯KNNç®—æ³•ä¸­è€ƒè™‘çš„é‚»å±…æ•°é‡ã€‚
- en: For each of these classifiers, we used the best combination of features among
    the mean of magnitudes, the magnitude errors, the amplitude of magnitudes, the
    colors and all characteristics included in the python library FATS. In the evaluation,
    the best results are obtained by using a KNN and only the color as a characteristic.
    Indeed as we can see in Table [1](#S6.T1 "Table 1 â€£ 6 Photometric redshifts of
    quasars â€£ Deep learning Approach for Classifying, Detecting and Predicting Photometric
    Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82") a learning phase
    with only the color as a feature shows the lower absolute error of 0.226 and the
    lower residual of the $\chi^{2}$ test with a value of 0.156\. In this case, the
    number of neighbors taking into account, indicated by the number K in the Table
    [1](#S6.T1 "Table 1 â€£ 6 Photometric redshifts of quasars â€£ Deep learning Approach
    for Classifying, Detecting and Predicting Photometric Redshifts of Quasars in
    the Sloan Digital Sky Survey Stripe 82"), is equal to 6\. Thus we use the performance
    of the KNN by extracting only the color to be compared to the performance of the
    CNN (see Table [1](#S6.T1 "Table 1 â€£ 6 Photometric redshifts of quasars â€£ Deep
    learning Approach for Classifying, Detecting and Predicting Photometric Redshifts
    of Quasars in the Sloan Digital Sky Survey Stripe 82")).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™äº›åˆ†ç±»å™¨ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ç‰¹å¾çš„æœ€ä½³ç»„åˆï¼ŒåŒ…æ‹¬å¹…åº¦å‡å€¼ã€å¹…åº¦è¯¯å·®ã€å¹…åº¦å¹…åº¦ã€é¢œè‰²ä»¥åŠæ‰€æœ‰åŒ…å«åœ¨Pythonåº“FATSä¸­çš„ç‰¹å¾ã€‚åœ¨è¯„ä¼°ä¸­ï¼Œä½¿ç”¨KNNä¸”ä»…ä»¥é¢œè‰²ä½œä¸ºç‰¹å¾å¯ä»¥è·å¾—æœ€ä½³ç»“æœã€‚å®é™…ä¸Šï¼Œå¦‚è¡¨[1](#S6.T1
    "Table 1 â€£ 6 Photometric redshifts of quasars â€£ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82")æ‰€ç¤ºï¼Œåªæœ‰é¢œè‰²ä½œä¸ºç‰¹å¾çš„å­¦ä¹ é˜¶æ®µæ˜¾ç¤ºäº†æœ€ä½çš„ç»å¯¹è¯¯å·®0.226å’Œ$\chi^{2}$æµ‹è¯•çš„æœ€ä½æ®‹å·®å€¼0.156ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¡¨[1](#S6.T1
    "Table 1 â€£ 6 Photometric redshifts of quasars â€£ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82")ä¸­çš„Kå€¼ç­‰äº6ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨KNNæå–çš„é¢œè‰²æ€§èƒ½ä¸CNNçš„æ€§èƒ½è¿›è¡Œæ¯”è¾ƒï¼ˆå‚è§è¡¨[1](#S6.T1 "Table
    1 â€£ 6 Photometric redshifts of quasars â€£ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82")ï¼‰ã€‚
- en: '|  | $&#124;\Delta z&#124;<0.1$ (%) | $&#124;\Delta z&#124;<0.2$ (%) | $&#124;\Delta
    z&#124;<0.3$ (%) | RMS |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|  | $&#124;\Delta z&#124;<0.1$ (%) | $&#124;\Delta z&#124;<0.2$ (%) | $&#124;\Delta
    z&#124;<0.3$ (%) | RMS |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| CNN | 79.32 | 86.64 | 91.69 | 0.352 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 79.32 | 86.64 | 91.69 | 0.352 |'
- en: '| KNN | 73.72 | 82.46 | 90.09 | 0.395 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| KNN | 73.72 | 82.46 | 90.09 | 0.395 |'
- en: '| KNN+CNN | 80.43 | 87.07 | 91.75 | 0.349 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| KNN+CNN | 80.43 | 87.07 | 91.75 | 0.349 |'
- en: 'Table 2: Comparisons of the accuracy and the dispersion obtained with the CNN,
    the KNN and the merge of the KNN and the CNN, by computing the percentages in
    different $|\Delta z|$ ranges and the Root Mean Square (RMS).'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 2ï¼šé€šè¿‡è®¡ç®—ä¸åŒ$|\Delta z|$èŒƒå›´å†…çš„ç™¾åˆ†æ¯”å’Œå‡æ–¹æ ¹ï¼ˆRMSï¼‰ï¼Œæ¯”è¾ƒCNNã€KNNä»¥åŠKNNå’ŒCNNçš„åˆå¹¶çš„å‡†ç¡®æ€§å’Œç¦»æ•£åº¦ã€‚
- en: '![Refer to caption](img/50f0dab990e63319f2d216af2eceab30.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/50f0dab990e63319f2d216af2eceab30.png)'
- en: 'Figure 10: Panels A and B compare the photometric redshifts predicted by the
    KNN and the CNN respectively against the spectroscopic redshifts. The color indicates
    the density of quasars in percentages. Redder the color, higher the density of
    quasars is. The line $y=x$ is red which means that the density of quasars is the
    highest and so the two methods well estimate most of the photometric redshifts
    compared to spectroscopic redshifts. Panel C is the difference in percentages
    between the density of quasars given by the CNN and the density of quasars obtained
    by the KNN, noted $\Delta d$. In other words, when $\Delta d$ is positive (resp.
    negative), the color is red (resp. blue), and it means that the density of quasars
    given by the CNN (resp. KNN) is higher than those obtained by the KNN (resp. CNN).'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 10ï¼šé¢æ¿Aå’ŒBåˆ†åˆ«æ¯”è¾ƒäº†KNNå’ŒCNNé¢„æµ‹çš„å…‰åº¦çº¢ç§»ä¸å…‰è°±çº¢ç§»ã€‚é¢œè‰²è¡¨ç¤ºç±»æ˜Ÿä½“çš„å¯†åº¦ç™¾åˆ†æ¯”ã€‚é¢œè‰²è¶Šçº¢ï¼Œç±»æ˜Ÿä½“çš„å¯†åº¦è¶Šé«˜ã€‚çº¿$y=x$æ˜¯çº¢è‰²çš„ï¼Œæ„å‘³ç€ç±»æ˜Ÿä½“çš„å¯†åº¦æœ€é«˜ï¼Œå› æ­¤è¿™ä¸¤ç§æ–¹æ³•å¯¹å¤§å¤šæ•°å…‰åº¦çº¢ç§»çš„ä¼°è®¡éƒ½è¾ƒå¥½ã€‚é¢æ¿Cæ˜¯CNNç»™å‡ºçš„ç±»æ˜Ÿä½“å¯†åº¦ä¸KNNè·å¾—çš„ç±»æ˜Ÿä½“å¯†åº¦ä¹‹é—´çš„ç™¾åˆ†æ¯”å·®å¼‚ï¼Œè®°ä½œ$\Delta
    d$ã€‚æ¢å¥è¯è¯´ï¼Œå½“$\Delta d$ä¸ºæ­£ï¼ˆæˆ–è´Ÿï¼‰æ—¶ï¼Œé¢œè‰²ä¸ºçº¢è‰²ï¼ˆæˆ–è“è‰²ï¼‰ï¼Œè¿™æ„å‘³ç€CNNï¼ˆæˆ–KNNï¼‰ç»™å‡ºçš„ç±»æ˜Ÿä½“å¯†åº¦é«˜äºKNNï¼ˆæˆ–CNNï¼‰è·å¾—çš„å¯†åº¦ã€‚
- en: Figure [10](#S6.F10 "Figure 10 â€£ 6 Photometric redshifts of quasars â€£ Deep learning
    Approach for Classifying, Detecting and Predicting Photometric Redshifts of Quasars
    in the Sloan Digital Sky Survey Stripe 82") compares photometric redshifts predicted
    by the KNN (panel A) and the CNN (panel B) against the spectroscopic redshifts
    of around 9000 quasars. The color indicates the density of quasars in percentages.
    We note $d_{CNN}$ and $d_{KNN}$ the density of quasars in percentages given by
    the CNN and the KNN approaches respectively. Redder the color, higher the density
    of quasars is. For the two methods, the density of quasars is the highest on the
    line y=x, showing that the most of photometric redshifts are well estimated by
    the two classifiers. We remark that the density is the highest for redshifts below
    2.5, since the database contains a small number of high redshifts, less than 10$\%$
    which is then divided between the training and the testing databases.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾[10](#S6.F10 "å›¾ 10 â€£ 6 ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§» â€£ ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥æ¡çº¹82ä¸­ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»çš„æ·±åº¦å­¦ä¹ æ–¹æ³•")å¯¹æ¯”äº†KNNï¼ˆé¢æ¿Aï¼‰å’ŒCNNï¼ˆé¢æ¿Bï¼‰é¢„æµ‹çš„å…‰åº¦çº¢ç§»ä¸çº¦9000ä¸ªç±»æ˜Ÿä½“çš„å…‰è°±çº¢ç§»ã€‚é¢œè‰²è¡¨ç¤ºç±»æ˜Ÿä½“çš„å¯†åº¦ç™¾åˆ†æ¯”ã€‚æˆ‘ä»¬ç”¨$d_{CNN}$å’Œ$d_{KNN}$è¡¨ç¤ºCNNå’ŒKNNæ–¹æ³•ç»™å‡ºçš„ç±»æ˜Ÿä½“å¯†åº¦ç™¾åˆ†æ¯”ã€‚é¢œè‰²è¶Šçº¢ï¼Œç±»æ˜Ÿä½“çš„å¯†åº¦è¶Šé«˜ã€‚å¯¹äºè¿™ä¸¤ç§æ–¹æ³•ï¼Œç±»æ˜Ÿä½“çš„å¯†åº¦åœ¨y=xçº¿ä¸Šçš„å€¼æœ€é«˜ï¼Œæ˜¾ç¤ºå‡ºè¿™ä¸¤ç§åˆ†ç±»å™¨å¯¹å¤§å¤šæ•°å…‰åº¦çº¢ç§»çš„ä¼°è®¡éƒ½å¾ˆå¥½ã€‚æˆ‘ä»¬æ³¨æ„åˆ°åœ¨çº¢ç§»å°äº2.5æ—¶å¯†åº¦æœ€é«˜ï¼Œå› ä¸ºæ•°æ®åº“ä¸­åŒ…å«çš„é«˜çº¢ç§»æ•°é‡è¾ƒå°‘ï¼Œä¸åˆ°10$\%$ï¼Œè¿™äº›æ•°æ®åœ¨è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åº“ä¸­æœ‰æ‰€åˆ’åˆ†ã€‚
- en: Panel C in Figure [10](#S6.F10 "Figure 10 â€£ 6 Photometric redshifts of quasars
    â€£ Deep learning Approach for Classifying, Detecting and Predicting Photometric
    Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82") compares the
    two approaches in the estimation of the photometric redshifts since it represents
    the difference between the density in percentages, $d_{CNN}$ and $d_{KNN}$ noted
    $\Delta d$. When the value of $\Delta d$ is positive (positive values are represented
    by the red color on the plot), the density of quasars given by the CNN is higher
    than those obtained by the KNN. Contrariwise when the value of $\Delta d$ is negative
    (negative values are represented by the blue color on the plot) the density of
    quasars given by the KNN is higher than those given by the CNN. We can see that
    the line $y=x$ appears in red color, so the values of $\Delta d$ are positives
    showing that the density of quasars obtained by the CNN is higher than those given
    by the KNN and so that the CNN better predicts redshifts equals to spectroscopic
    redshifts than the KNN. On the contrary, the regions around the line $y=x$ are
    in blue meaning that the KNN has a higher error rate than the CNN and predict
    more catastrophic redshifts.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ [10](#S6.F10 "å›¾ 10 â€£ 6 ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§» â€£ æ·±åº¦å­¦ä¹ æ–¹æ³•ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹Sloanæ•°å­—å¤©ç©ºå·¡å¤©å¸¦82ä¸­çš„å…‰åº¦çº¢ç§»çš„æ–¹æ³•")
    ä¸­çš„é¢æ¿Cæ¯”è¾ƒäº†ä¸¤ç§æ–¹æ³•åœ¨å…‰åº¦çº¢ç§»ä¼°è®¡ä¸­çš„å·®å¼‚ï¼Œå› ä¸ºå®ƒè¡¨ç¤ºäº†ç™¾åˆ†æ¯”å¯†åº¦å·®å¼‚ï¼Œ$d_{CNN}$ å’Œ $d_{KNN}$ è®°ä¸º $\Delta d$ã€‚å½“ $\Delta
    d$ çš„å€¼ä¸ºæ­£ï¼ˆåœ¨å›¾ä¸­ä»¥çº¢è‰²è¡¨ç¤ºï¼‰ï¼ŒCNNç»™å‡ºçš„ç±»æ˜Ÿä½“å¯†åº¦é«˜äºKNNã€‚ç›¸åï¼Œå½“ $\Delta d$ çš„å€¼ä¸ºè´Ÿï¼ˆåœ¨å›¾ä¸­ä»¥è“è‰²è¡¨ç¤ºï¼‰ï¼ŒKNNç»™å‡ºçš„ç±»æ˜Ÿä½“å¯†åº¦é«˜äºCNNã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç›´çº¿
    $y=x$ ä»¥çº¢è‰²æ˜¾ç¤ºï¼Œå› æ­¤ $\Delta d$ çš„å€¼ä¸ºæ­£ï¼Œæ˜¾ç¤ºCNNæ¯”KNNæ›´å¥½åœ°é¢„æµ‹ç­‰äºå…‰è°±çº¢ç§»çš„çº¢ç§»ã€‚ç›¸åï¼Œå›´ç»•ç›´çº¿ $y=x$ çš„åŒºåŸŸä¸ºè“è‰²ï¼Œæ„å‘³ç€KNNæ¯”CNNæœ‰æ›´é«˜çš„è¯¯å·®ç‡ï¼Œå¹¶ä¸”é¢„æµ‹äº†æ›´å¤šçš„ç¾éš¾æ€§çº¢ç§»ã€‚
- en: The better accuracy of the CNN is also visible if we compare the distribution
    of the absolute error in the estimation of photometric redshifts of the two methods
    (see Figure [11](#S6.F11 "Figure 11 â€£ 6 Photometric redshifts of quasars â€£ Deep
    learning Approach for Classifying, Detecting and Predicting Photometric Redshifts
    of Quasars in the Sloan Digital Sky Survey Stripe 82")). Indeed we can see that
    the histogram is narrower for the estimations of photometric redshifts made by
    the CNN (red histogram) than those made by the KNN (blue histogram). In addition
    the percentage of redshift estimations with an absolute error higher than 0.1,
    0.2 and 0.3 are respectively of 38.03%, 24.06% and 19.07% for the CNN; for the
    KNN they are of 45.78%, 30.04% and 22.89%. Thus the number of catastrophic photometric
    redshifts is significantly reduced with the CNN.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æ¯”è¾ƒä¸¤ç§æ–¹æ³•åœ¨å…‰åº¦çº¢ç§»ä¼°è®¡ä¸­ç»å¯¹è¯¯å·®åˆ†å¸ƒçš„è¯ï¼ŒCNNçš„æ›´å¥½ç²¾åº¦ä¹Ÿæ˜¯æ˜¾è€Œæ˜“è§çš„ï¼ˆè§å›¾ [11](#S6.F11 "å›¾ 11 â€£ 6 ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»
    â€£ æ·±åº¦å­¦ä¹ æ–¹æ³•ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹Sloanæ•°å­—å¤©ç©ºå·¡å¤©å¸¦82ä¸­çš„å…‰åº¦çº¢ç§»çš„æ–¹æ³•")ï¼‰ã€‚äº‹å®ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°CNNè¿›è¡Œçš„å…‰åº¦çº¢ç§»ä¼°è®¡çš„ç›´æ–¹å›¾ï¼ˆçº¢è‰²ç›´æ–¹å›¾ï¼‰æ¯”KNNï¼ˆè“è‰²ç›´æ–¹å›¾ï¼‰æ›´çª„ã€‚æ­¤å¤–ï¼Œå¯¹äºç»å¯¹è¯¯å·®å¤§äº0.1ã€0.2å’Œ0.3çš„çº¢ç§»ä¼°è®¡ç™¾åˆ†æ¯”åˆ†åˆ«ä¸º38.03%ã€24.06%å’Œ19.07%ï¼ˆCNNï¼‰ï¼Œè€Œå¯¹äºKNNåˆ™åˆ†åˆ«ä¸º45.78%ã€30.04%å’Œ22.89%ã€‚å› æ­¤ï¼Œä½¿ç”¨CNNå¯ä»¥æ˜¾è‘—å‡å°‘ç¾éš¾æ€§å…‰åº¦çº¢ç§»çš„æ•°é‡ã€‚
- en: '![Refer to caption](img/a876c28d9da740e831f93e7c4fa5b40c.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/a876c28d9da740e831f93e7c4fa5b40c.png)'
- en: 'Figure 11: The blue and red histograms represent the distribution of the absolute
    error for the estimation of photometric redshifts by using a KNN and a CNN classifiers
    respectively. The number of catastrophic redshifts is reduced with the CNN as
    the percentage of redshift estimation with an absolute error higher than 0.1 is
    about 45.78% for the KNN and 38.03% for the CNN.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11ï¼šè“è‰²å’Œçº¢è‰²çš„ç›´æ–¹å›¾åˆ†åˆ«ä»£è¡¨äº†ä½¿ç”¨KNNå’ŒCNNåˆ†ç±»å™¨è¿›è¡Œå…‰åº¦çº¢ç§»ä¼°è®¡çš„ç»å¯¹è¯¯å·®åˆ†å¸ƒã€‚éšç€CNNçš„ä½¿ç”¨ï¼Œç¾éš¾æ€§çº¢ç§»çš„æ•°é‡å‡å°‘ï¼Œå› ä¸ºç»å¯¹è¯¯å·®å¤§äº0.1çš„çº¢ç§»ä¼°è®¡ç™¾åˆ†æ¯”çº¦ä¸º45.78%ï¼ˆKNNï¼‰å’Œ38.03%ï¼ˆCNNï¼‰ã€‚
- en: 'We also define two quantities frequently used to evaluate accuracy and dispersion
    of the used method that are the percentages in different $|\Delta z|$ ranges defined
    as:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å®šä¹‰äº†ä¸¤ä¸ªç”¨äºè¯„ä¼°æ‰€ä½¿ç”¨æ–¹æ³•ç²¾åº¦å’Œç¦»æ•£åº¦çš„ç»å¸¸ä½¿ç”¨çš„é‡ï¼Œå³åœ¨ä¸åŒ $|\Delta z|$ èŒƒå›´å†…çš„ç™¾åˆ†æ¯”ï¼Œå®šä¹‰ä¸ºï¼š
- en: '|  | $\Delta z=\frac{z_{spec}-z_{phot}}{1+z_{spec}}$ |  | (2) |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|  | $\Delta z=\frac{z_{spec}-z_{phot}}{1+z_{spec}}$ |  | (2) |'
- en: and the Root Mean Square (RMS) of $|\Delta z|$ to test our redshifts prediction
    approach. The better accuracy of the CNN is confirmed (see Table [2](#S6.T2 "Table
    2 â€£ 6 Photometric redshifts of quasars â€£ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82")) since the proportions of $|\Delta z|$ are equals to 78.09$\%$,
    86.15$\%$, 91.2$\%$ for the CNN, against 73.72$\%$, 82.46$\%$, 90.09$\%$ for the
    KNN. This means that more photometric redshifts are estimated with a low error
    by the CNN than the KNN. In addition, the dispersion of photometric redshifts
    is also lower with the CNN, since the RMS is 0.352 for the CNN against 0.395 for
    the KNN.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠæ ¹å‡æ–¹å·®ï¼ˆRMSï¼‰$|\Delta z|$ç”¨äºæµ‹è¯•æˆ‘ä»¬çš„çº¢ç§»é¢„æµ‹æ–¹æ³•ã€‚CNNçš„å‡†ç¡®æ€§å¾—åˆ°äº†ç¡®è®¤ï¼ˆè§è¡¨[2](#S6.T2 "è¡¨ 2 â€£ 6 æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»
    â€£ æ·±åº¦å­¦ä¹ æ–¹æ³•ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥æ¡çº¹82ä¸­çš„æ˜Ÿä½“å…‰åº¦çº¢ç§»")ï¼‰ï¼Œå› ä¸ºCNNçš„$|\Delta z|$çš„æ¯”ä¾‹åˆ†åˆ«ä¸º78.09$\%$ã€86.15$\%$ã€91.2$\%$ï¼Œè€ŒKNNçš„æ¯”ä¾‹åˆ†åˆ«ä¸º73.72$\%$ã€82.46$\%$ã€90.09$\%$ã€‚è¿™æ„å‘³ç€CNNå¯¹æ›´å¤šå…‰åº¦çº¢ç§»çš„ä½è¯¯å·®ä¼°è®¡ä¼˜äºKNNã€‚æ­¤å¤–ï¼ŒCNNçš„å…‰åº¦çº¢ç§»çš„ç¦»æ•£åº¦ä¹Ÿè¾ƒä½ï¼Œå› ä¸ºCNNçš„RMSä¸º0.352ï¼Œè€ŒKNNä¸º0.395ã€‚
- en: However the CNN has worse performance than the KNN for the prediction of redshifts
    higher than 2.5 (which is visible on Panel C in Figure [10](#S6.F10 "Figure 10
    â€£ 6 Photometric redshifts of quasars â€£ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82")). It is due to the small number of redshifts higher than
    2.5 in the database. There are only 600 quasars with $z_{spec}>2.5$ in the learning
    database and the CNN needs a lot of examples to converge.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼ŒCNNåœ¨é¢„æµ‹çº¢ç§»é«˜äº2.5çš„æƒ…å†µä¸‹è¡¨ç°ä¸å¦‚KNNï¼ˆè¿™åœ¨å›¾[10](#S6.F10 "å›¾ 10 â€£ 6 æ˜Ÿä½“çš„å…‰åº¦çº¢ç§» â€£ æ·±åº¦å­¦ä¹ æ–¹æ³•ç”¨äºåˆ†ç±»ã€æ£€æµ‹å’Œé¢„æµ‹æ–¯éš†æ•°å­—å¤©ç©ºè°ƒæŸ¥æ¡çº¹82ä¸­çš„æ˜Ÿä½“å…‰åº¦çº¢ç§»")ä¸­çš„Cé¢æ¿ä¸­å¯è§ï¼‰ã€‚è¿™æ˜¯ç”±äºæ•°æ®åº“ä¸­é«˜äº2.5çš„çº¢ç§»æ•°é‡è¾ƒå°‘ã€‚åœ¨å­¦ä¹ æ•°æ®åº“ä¸­ï¼Œåªæœ‰600ä¸ª$z_{spec}>2.5$çš„ç±»æ˜Ÿä½“ï¼Œè€ŒCNNéœ€è¦å¤§é‡ç¤ºä¾‹æ‰èƒ½æ”¶æ•›ã€‚
- en: 'To solve this problem, after the training of the KNN and the CNN we combine
    these two approaches in a KNN+CNN architecture. The final prediction of the KNN+CNN
    architecture will depend on the redshift predicted by the KNN model. If the KNN
    predicts a redshift higher than 2.5, this prediction is used as the final prediction.
    Otherwise, the prediction given by the CNN is used as the final prediction. We
    note $p_{KNN}$ and $p_{CNN}$ the prediction given by the KNN and the CNN respectively.
    The prediction given by the KNN+CNN architecture, noted $p_{KNN+CNN}$ is defined
    as:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åœ¨KNNå’ŒCNNçš„è®­ç»ƒåå°†è¿™ä¸¤ç§æ–¹æ³•ç»“åˆåœ¨ä¸€ä¸ªKNN+CNNæ¶æ„ä¸­ã€‚KNN+CNNæ¶æ„çš„æœ€ç»ˆé¢„æµ‹å°†å–å†³äºKNNæ¨¡å‹é¢„æµ‹çš„çº¢ç§»ã€‚å¦‚æœKNNé¢„æµ‹çš„çº¢ç§»é«˜äº2.5ï¼Œåˆ™è¯¥é¢„æµ‹å€¼ä½œä¸ºæœ€ç»ˆé¢„æµ‹å€¼ã€‚å¦åˆ™ï¼ŒCNNç»™å‡ºçš„é¢„æµ‹å€¼å°†ä½œä¸ºæœ€ç»ˆé¢„æµ‹å€¼ã€‚æˆ‘ä»¬ç”¨$p_{KNN}$å’Œ$p_{CNN}$åˆ†åˆ«è¡¨ç¤ºKNNå’ŒCNNç»™å‡ºçš„é¢„æµ‹å€¼ã€‚KNN+CNNæ¶æ„ç»™å‡ºçš„é¢„æµ‹å€¼ï¼Œè®°ä½œ$p_{KNN+CNN}$ï¼Œå®šä¹‰å¦‚ä¸‹ï¼š
- en: '|  | <math   alttext="p_{KNN+CNN}=\begin{cases}p_{KNN}&amp;\textrm{if
    }p_{KNN}>2.5\\ p_{CNN}&amp;\textrm{Otherwise}\\'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="p_{KNN+CNN}=\begin{cases}p_{KNN}&amp;\textrm{å¦‚æœ
    }p_{KNN}>2.5\\ p_{CNN}&amp;\textrm{å¦åˆ™}\\'
- en: \end{cases}" display="block"><semantics ><mrow 
    ><msub  ><mi
     >p</mi><mrow 
    ><mrow  ><mi
     >K</mi><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mi
     >N</mi><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mi
     >N</mi></mrow><mo 
    >+</mo><mrow  ><mi
     >C</mi><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mi
     >N</mi><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mi
     >N</mi></mrow></mrow></msub><mo
     >=</mo><mrow  ><mo
     >{</mo><mtable columnspacing="5pt"
    displaystyle="true" rowspacing="0pt"  ><mtr
     ><mtd 
    columnalign="left"  ><msub 
    ><mi  >p</mi><mrow
     ><mi 
    >K</mi><mo lspace="0em" rspace="0em" 
    >â€‹</mo><mi  >N</mi><mo
    lspace="0em" rspace="0em"  >â€‹</mo><mi
     >N</mi></mrow></msub></mtd><mtd
     columnalign="left"  ><mrow
     ><mrow 
    ><mtext  >ifÂ </mtext><mo
    lspace="0em" rspace="0em"  >â€‹</mo><msub
     ><mi 
    >p</mi><mrow 
    ><mi  >K</mi><mo
    lspace="0em" rspace="0em"  >â€‹</mo><mi
     >N</mi><mo
    lspace="0em" rspace="0em"  >â€‹</mo><mi
     >N</mi></mrow></msub></mrow><mo
     >></mo><mn 
    >2.5</mn></mrow></mtd></mtr><mtr 
    ><mtd  columnalign="left" 
    ><msub  ><mi
     >p</mi><mrow 
    ><mi  >C</mi><mo
    lspace="0em" rspace="0em"  >â€‹</mo><mi
     >N</mi><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mi
     >N</mi></mrow></msub></mtd><mtd
     columnalign="left"  ><mtext
     >Otherwise</mtext></mtd></mtr></mtable></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><apply
     ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci  >ğ‘</ci><apply
     ><apply 
    ><ci  >ğ¾</ci><ci
     >ğ‘</ci><ci 
    >ğ‘</ci></apply><apply 
    ><ci  >ğ¶</ci><ci
     >ğ‘</ci><ci 
    >ğ‘</ci></apply></apply></apply><apply 
    ><csymbol cd="latexml"  >cases</csymbol><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><ci
     >ğ‘</ci><apply 
    ><ci  >ğ¾</ci><ci
     >ğ‘</ci><ci 
    >ğ‘</ci></apply></apply><apply 
    ><apply  ><ci
     ><mtext 
    >ifÂ </mtext></ci><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >ğ‘</ci><apply 
    ><ci  >ğ¾</ci><ci
     >ğ‘</ci><ci
     >ğ‘</ci></apply></apply></apply><cn
    type="float"  >2.5</cn></apply><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><ci
     >ğ‘</ci><apply 
    ><ci  >ğ¶</ci><ci
     >ğ‘</ci><ci 
    >ğ‘</ci></apply></apply><ci 
    ><mtext  >Otherwise</mtext></ci></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >p_{KNN+CNN}=\begin{cases}p_{KNN}&\textrm{if
    }p_{KNN}>2.5\\ p_{CNN}&\textrm{Otherwise}\\ \end{cases}</annotation></semantics></math>
    |  | (3) |
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`p_{KNN+CNN}=\begin{cases}p_{KNN}&\textrm{å¦‚æœ }p_{KNN}>2.5\\ p_{CNN}&\textrm{å¦åˆ™}\\
    \end{cases}`'
- en: So, when the CNN does not have enough examples to learn a robust model, i.e
    for the high redshift estimations, the KNN model is used.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå½“CNNæ²¡æœ‰è¶³å¤Ÿçš„ä¾‹å­æ¥å­¦ä¹ ä¸€ä¸ªç¨³å¥çš„æ¨¡å‹æ—¶ï¼Œå³ç”¨äºé«˜çº¢ç§»ä¼°è®¡ï¼ŒKNNæ¨¡å‹ä¼šè¢«ä½¿ç”¨ã€‚
- en: The performance given by the KNN+CNN architecture is a very interesting results
    as shown in Table [2](#S6.T2 "Table 2 â€£ 6 Photometric redshifts of quasars â€£ Deep
    learning Approach for Classifying, Detecting and Predicting Photometric Redshifts
    of Quasars in the Sloan Digital Sky Survey Stripe 82"). Indeed, the combination
    of the two classifiers reduces the number of catastrophic redshifts and the dispersion,
    since the proportions of $|\Delta z|$ are now equal to 80.43$\%$, 87.07$\%$, 91.75$\%$
    and the value of RMS is 0.349.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: KNN+CNNæ¶æ„æ‰€ç»™å‡ºçš„æ€§èƒ½æ˜¯éå¸¸æœ‰è¶£çš„ç»“æœï¼Œå¦‚è¡¨[2](#S6.T2 "Table 2 â€£ 6 Photometric redshifts of quasars
    â€£ Deep learning Approach for Classifying, Detecting and Predicting Photometric
    Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82")æ‰€ç¤ºã€‚ç¡®å®ï¼Œä¸¤ç§åˆ†ç±»å™¨çš„ç»“åˆå‡å°‘äº†ç¾éš¾æ€§çº¢ç§»å’Œç¦»æ•£åº¦ï¼Œå› ä¸º$|\Delta
    z|$çš„æ¯”ä¾‹ç°åœ¨åˆ†åˆ«ä¸º80.43$\%$ï¼Œ87.07$\%$ï¼Œ91.75$\%$ï¼Œè€ŒRMSå€¼ä¸º0.349ã€‚
- en: 7 Conclusions
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 ç»“è®º
- en: First, we have presented an original method based on a convolution neural network
    to classify and identify quasars in Stripe 82\. The network takes the Light Curve
    Images as input which are built from light curves of each object in the five ugriz
    filters, so as to include both the crucial information of the variabiliy and the
    colors in the learning of the network. The CNN classifier presents good results
    for the classification of quasars with a precision of 0.988 at a fixed recall
    of 0.90\. For the same recall, the precision given by a random forest (RF) is
    0.985\. The very promising result is obtained by the combination of the CNN and
    the RF giving precisions of 0.99 for a recall of 0.90.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„åŸåˆ›æ–¹æ³•æ¥åˆ†ç±»å’Œè¯†åˆ«Stripe 82ä¸­çš„ç±»æ˜Ÿä½“ã€‚è¯¥ç½‘ç»œä»¥å…‰æ›²çº¿å›¾åƒä½œä¸ºè¾“å…¥ï¼Œè¿™äº›å›¾åƒæ˜¯ç”±äº”ä¸ª ugriz è¿‡æ»¤å™¨ä¸­çš„æ¯ä¸ªå¯¹è±¡çš„å…‰æ›²çº¿æ„å»ºçš„ï¼Œä»¥ä¾¿åœ¨ç½‘ç»œçš„å­¦ä¹ ä¸­åŒ…å«å˜å¼‚æ€§å’Œé¢œè‰²çš„å…³é”®ä¿¡æ¯ã€‚CNN
    åˆ†ç±»å™¨åœ¨ç±»æ˜Ÿä½“åˆ†ç±»æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œåœ¨å›ºå®šå¬å›ç‡ä¸º0.90çš„æƒ…å†µä¸‹ï¼Œç²¾ç¡®åº¦ä¸º0.988ã€‚å¯¹äºç›¸åŒçš„å¬å›ç‡ï¼Œéšæœºæ£®æ—ï¼ˆRFï¼‰æä¾›çš„ç²¾ç¡®åº¦ä¸º0.985ã€‚é€šè¿‡ç»“åˆCNNå’ŒRFï¼Œè·å¾—äº†éå¸¸æœ‰å‰æ™¯çš„ç»“æœï¼Œåœ¨å¬å›ç‡ä¸º0.90æ—¶ç²¾ç¡®åº¦ä¸º0.99ã€‚
- en: Then, during the testing phase 175 new quasar candidates were detected by the
    CNN, with a fixed recall of 0.97\. They are uniformly spatially distributed and
    they validate the tendency â€bluer when brighterâ€.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œåœ¨æµ‹è¯•é˜¶æ®µï¼ŒCNNæ£€æµ‹åˆ°äº†175ä¸ªæ–°çš„ç±»æ˜Ÿä½“å€™é€‰è€…ï¼Œå›ºå®šå¬å›ç‡ä¸º0.97ã€‚è¿™äº›å€™é€‰è€…å‡åŒ€åœ°ç©ºé—´åˆ†å¸ƒï¼Œå¹¶éªŒè¯äº†â€œæ›´äº®æ—¶æ›´è“â€çš„è¶‹åŠ¿ã€‚
- en: Finally, we have used a CNN to predict the photometric redshifts of quasars.
    The performance of the CNN is higher than that of the KNN at redshifts below 2.5
    with the best parameters determined experimentally. Indeed, the proportions of
    $|\Delta z|$ and rms error of predicted photometry redshifts are 78.09$\%$, 86.15$\%$,
    91.2$\%$ and 0.359 for the CNN; for the KNN they are 73.72$\%$, 82.46$\%$, 90.09$\%$
    and 0.395. The number of catastrophic redshift is also reduced by using a CNN,
    since the number of photometric redshifts with an absolute error higher than 0.1
    is about 38.03$\%$ for the CNN against 45.78$\%$ for the KNN. Moreover the combination
    of a CNN and a KNN is a very promising method which better estimates redshifts
    higher than 2.5 and reduces the dispersion and the number of catastrophic redshifts.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨CNNæ¥é¢„æµ‹ç±»æ˜Ÿä½“çš„å…‰åº¦çº¢ç§»ã€‚CNNçš„æ€§èƒ½é«˜äºKNNï¼Œåœ¨çº¢ç§»ä½äº2.5æ—¶ï¼Œæœ€ä½³å‚æ•°é€šè¿‡å®éªŒç¡®å®šã€‚ç¡®å®ï¼ŒCNNçš„$|\Delta z|$æ¯”ä¾‹å’Œé¢„æµ‹å…‰åº¦çº¢ç§»çš„RMSè¯¯å·®åˆ†åˆ«ä¸º78.09$\%$ï¼Œ86.15$\%$ï¼Œ91.2$\%$å’Œ0.359ï¼›è€ŒKNNçš„åˆ†åˆ«ä¸º73.72$\%$ï¼Œ82.46$\%$ï¼Œ90.09$\%$å’Œ0.395ã€‚ä½¿ç”¨CNNä¹Ÿå‡å°‘äº†ç¾éš¾æ€§çº¢ç§»çš„æ•°é‡ï¼Œå› ä¸ºCNNçš„ç»å¯¹è¯¯å·®å¤§äº0.1çš„å…‰åº¦çº¢ç§»æ•°é‡çº¦ä¸º38.03$\%$ï¼Œè€ŒKNNä¸º45.78$\%$ã€‚æ­¤å¤–ï¼ŒCNNä¸KNNçš„ç»“åˆæ˜¯ä¸€ç§éå¸¸æœ‰å‰æ™¯çš„æ–¹æ³•ï¼Œå¯ä»¥æ›´å¥½åœ°ä¼°è®¡é«˜äº2.5çš„çº¢ç§»ï¼Œå‡å°‘ç¦»æ•£åº¦å’Œç¾éš¾æ€§çº¢ç§»çš„æ•°é‡ã€‚
- en: Several improvements can be made for further studies. The most trivial is to
    use another catalog with a larger amount of data, because Deep Learning usually
    shows better results when there is more information. The second improvement consists
    of not dividing by averaging observations taken on two consecutive days, during
    the creation of the LCI. Indeed it is an approximation needed to reduce the computational
    cost, but it could be interesting to evaluate its impact on the results. Another
    interesting improvement is to take the errors into account in the learning phase
    which could show important information.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: è¿›ä¸€æ­¥ç ”ç©¶å¯ä»¥åšå‡ºå‡ é¡¹æ”¹è¿›ã€‚æœ€ç®€å•çš„æ˜¯ä½¿ç”¨æ•°æ®é‡æ›´å¤§çš„å…¶ä»–ç›®å½•ï¼Œå› ä¸ºæ·±åº¦å­¦ä¹ é€šå¸¸åœ¨ä¿¡æ¯æ›´å¤šæ—¶æ˜¾ç¤ºæ›´å¥½çš„ç»“æœã€‚ç¬¬äºŒé¡¹æ”¹è¿›æ˜¯åœ¨åˆ›å»ºLCIæ—¶ä¸é€šè¿‡å¹³å‡ä¸¤å¤©è¿ç»­è§‚æµ‹å€¼æ¥è¿›è¡Œï¼Œå› ä¸ºè¿™æ˜¯ä¸€ç§å‡å°‘è®¡ç®—æˆæœ¬çš„è¿‘ä¼¼æ–¹æ³•ï¼Œä½†è¯„ä¼°å…¶å¯¹ç»“æœçš„å½±å“å¯èƒ½ä¼šå¾ˆæœ‰è¶£ã€‚å¦ä¸€ä¸ªæœ‰è¶£çš„æ”¹è¿›æ˜¯åœ¨å­¦ä¹ é˜¶æ®µè€ƒè™‘è¯¯å·®ï¼Œè¿™å¯èƒ½ä¼šæä¾›é‡è¦çš„ä¿¡æ¯ã€‚
- en: In conclusion we wish to emphasis that the development of a method able to estimate
    well the photometric redshifts using only photometric information is essential
    for the future of big databases like LSST. Understanding that Deep Learning is
    more and more efficient as the size of the data increases, the future of this
    method is very promising.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“æ¥è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›å¼ºè°ƒçš„æ˜¯ï¼Œå¼€å‘ä¸€ç§ä»…ä½¿ç”¨å…‰åº¦ä¿¡æ¯å³å¯å‡†ç¡®ä¼°è®¡å…‰åº¦çº¢ç§»çš„æ–¹æ³•ï¼Œå¯¹äºåƒLSSTè¿™æ ·çš„åºå¤§æ•°æ®åº“çš„æœªæ¥è‡³å…³é‡è¦ã€‚ç†è§£åˆ°æ·±åº¦å­¦ä¹ éšç€æ•°æ®é‡çš„å¢åŠ å˜å¾—è¶Šæ¥è¶Šé«˜æ•ˆï¼Œè¿™ç§æ–¹æ³•çš„æœªæ¥éå¸¸æœ‰å‰é€”ã€‚
- en: References
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: Abazajian etÂ al. (2009) Abazajian, K.Â N., Adelman-McCarthy, J.Â K., AgÃ¼eros,
    M.Â A., etÂ al. 2009, ApJS, 182, 543
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abazajian ç­‰ï¼ˆ2009ï¼‰Abazajian, K. N., Adelman-McCarthy, J. K., AgÃ¼eros, M. A.,
    ç­‰ 2009, ApJS, 182, 543
- en: Baum (1962) Baum, W.Â A. 1962, in IAU Symposium, Vol.Â 15, Problems of Extra-Galactic
    Research, ed. G.Â C. McVittie, 390
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baumï¼ˆ1962ï¼‰Baum, W. A. 1962, åœ¨IAUç ”è®¨ä¼šï¼Œç¬¬15å·ï¼Œå¤–é“¶æ²³ç ”ç©¶é—®é¢˜ï¼Œç¼–è¾‘ G. C. McVittie, 390
- en: Blake etÂ al. (2007) Blake, C., Collister, A., Bridle, S., & Lahav, O. 2007,
    MNRAS, 374, 1527
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blake ç­‰ï¼ˆ2007ï¼‰Blake, C., Collister, A., Bridle, S., & Lahav, O. 2007, MNRAS,
    374, 1527
- en: Blomme etÂ al. (2011) Blomme, J., Sarro, L.Â M., Oâ€™Donovan, F.Â T., etÂ al. 2011,
    MNRAS, 418, 96
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blomme ç­‰ï¼ˆ2011ï¼‰Blomme, J., Sarro, L. M., Oâ€™Donovan, F. T., ç­‰ 2011, MNRAS, 418,
    96
- en: Bolzonella etÂ al. (2000) Bolzonella, M., Miralles, J.-M., & PellÃ³, R. 2000,
    A&A, 363, 476
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bolzonella ç­‰ï¼ˆ2000ï¼‰Bolzonella, M., Miralles, J.-M., & PellÃ³, R. 2000, A&A, 363,
    476
- en: Collister & Lahav (2004) Collister, A.Â A. & Lahav, O. 2004, PASP, 116, 345
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Collister & Lahavï¼ˆ2004ï¼‰Collister, A. A. & Lahav, O. 2004, PASP, 116, 345
- en: Cortes & Vapnik (1995) Cortes, C. & Vapnik, V. 1995, Mach. Learn., 20, 273
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cortes & Vapnikï¼ˆ1995ï¼‰Cortes, C. & Vapnik, V. 1995, Mach. Learn., 20, 273
- en: Coupon etÂ al. (2009) Coupon, J., Ilbert, O., Kilbinger, M., etÂ al. 2009, A&A,
    500, 981
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Coupon ç­‰ï¼ˆ2009ï¼‰Coupon, J., Ilbert, O., Kilbinger, M., ç­‰ 2009, A&A, 500, 981
- en: Cristiani etÂ al. (1997) Cristiani, S., Trentini, S., La Franca, F., & Andreani,
    P. 1997, A&A, 321, 123
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cristiani ç­‰ï¼ˆ1997ï¼‰Cristiani, S., Trentini, S., La Franca, F., & Andreani, P.
    1997, A&A, 321, 123
- en: Croom etÂ al. (2009) Croom, S.Â M., Richards, G.Â T., Shanks, T., etÂ al. 2009,
    MNRAS, 392, 19
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Croom ç­‰ï¼ˆ2009ï¼‰Croom, S. M., Richards, G. T., Shanks, T., ç­‰ 2009, MNRAS, 392,
    19
- en: Dubath etÂ al. (2011) Dubath, P., Rimoldini, L., SÃ¼veges, M., etÂ al. 2011, MNRAS,
    414, 2602
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dubath ç­‰ï¼ˆ2011ï¼‰Dubath, P., Rimoldini, L., SÃ¼veges, M., ç­‰ 2011, MNRAS, 414, 2602
- en: Duda & Hart (1973) Duda, R.Â O. & Hart, P.Â E. 1973, Pattern classification and
    scene analysis, A Wiley-interscience publication (J. Wiley & Sons)
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Duda & Hartï¼ˆ1973ï¼‰Duda, R. O. & Hart, P. E. 1973, æ¨¡å¼åˆ†ç±»ä¸åœºæ™¯åˆ†æï¼ŒWiley-ä¸ç§‘å­¦å‡ºç‰ˆç‰©ï¼ˆJ. Wiley
    & Sonsï¼‰
- en: Eyer & Blake (2005) Eyer, L. & Blake, C. 2005, MNRAS, 358, 30
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eyer & Blakeï¼ˆ2005ï¼‰Eyer, L. & Blake, C. 2005, MNRAS, 358, 30
- en: Firth etÂ al. (2003) Firth, A.Â E., Lahav, O., & Somerville, R.Â S. 2003, MNRAS,
    339, 1195
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Firth ç­‰ï¼ˆ2003ï¼‰Firth, A. E., Lahav, O., & Somerville, R. S. 2003, MNRAS, 339,
    1195
- en: Frieman etÂ al. (2008) Frieman, J.Â A., Bassett, B., Becker, A., etÂ al. 2008,
    AJ, 135, 338
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Frieman ç­‰ï¼ˆ2008ï¼‰Frieman, J. A., Bassett, B., Becker, A., ç­‰ 2008, AJ, 135, 338
- en: Giveon etÂ al. (1999) Giveon, U., Maoz, D., Kaspi, S., Netzer, H., & Smith, P.Â S.
    1999, MNRAS, 306, 637
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Giveon ç­‰ï¼ˆ1999ï¼‰Giveon, U., Maoz, D., Kaspi, S., Netzer, H., & Smith, P. S. 1999,
    MNRAS, 306, 637
- en: Han etÂ al. (2016) Han, B., Ding, H.-P., Zhang, Y.-X., & Zhao, Y.-H. 2016, Research
    in Astronomy and Astrophysics, 16, 074
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han ç­‰ï¼ˆ2016ï¼‰Han, B., Ding, H.-P., Zhang, Y.-X., & Zhao, Y.-H. 2016, å¤©æ–‡å­¦ä¸å¤©ä½“ç‰©ç†ç ”ç©¶ï¼Œ16,
    074
- en: 'He etÂ al. (2015) He, K., Zhang, X., Ren, S., & Sun, J. 2015, in Proceedings
    of the 2015 IEEE International Conference on Computer Vision (ICCV), ICCV â€™15
    (Washington, DC, USA: IEEE Computer Society), 1026â€“1034'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He ç­‰ï¼ˆ2015ï¼‰He, K., Zhang, X., Ren, S., & Sun, J. 2015, åœ¨2015å¹´IEEEå›½é™…è®¡ç®—æœºè§†è§‰å¤§ä¼šï¼ˆICCVï¼‰è®ºæ–‡é›†ï¼ŒICCV
    â€™15ï¼ˆåç››é¡¿ç‰¹åŒºï¼Œç¾å›½ï¼šIEEEè®¡ç®—æœºåä¼šï¼‰ï¼Œ1026â€“1034
- en: Hernitschek etÂ al. (2016) Hernitschek, N., Schlafly, E.Â F., Sesar, B., etÂ al.
    2016, ApJ, 817, 73
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hernitschek ç­‰ï¼ˆ2016ï¼‰Hernitschek, N., Schlafly, E. F., Sesar, B., ç­‰ 2016, ApJ,
    817, 73
- en: Hopkins etÂ al. (2006) Hopkins, P.Â F., Hernquist, L., Cox, T.Â J., etÂ al. 2006,
    ApJS, 163, 1
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hopkins ç­‰ (2006) Hopkins, P. F., Hernquist, L., Cox, T. J., ç­‰. 2006, ApJS, 163,
    1
- en: Huertas-Company etÂ al. (2015) Huertas-Company, M., Gravet, R., Cabrera-Vives,
    G., etÂ al. 2015, ApJS, 221, 8
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huertas-Company ç­‰ (2015) Huertas-Company, M., Gravet, R., Cabrera-Vives, G.,
    ç­‰. 2015, ApJS, 221, 8
- en: Ilbert etÂ al. (2010) Ilbert, O., Salvato, M., Le Flocâ€™h, E., etÂ al. 2010, ApJ,
    709, 644
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ilbert ç­‰ (2010) Ilbert, O., Salvato, M., Le Flocâ€™h, E., ç­‰. 2010, ApJ, 709, 644
- en: Ioffe & Szegedy (2015) Ioffe, S. & Szegedy, C. 2015, in Proceedings of the 32nd
    International Conference on Machine Learning (ICML-15), ed. D.Â Blei & F.Â Bach
    (JMLR Workshop and Conference Proceedings), 448â€“456
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ioffe & Szegedy (2015) Ioffe, S. & Szegedy, C. 2015, è§äºç¬¬32å±Šå›½é™…æœºå™¨å­¦ä¹ ä¼šè®®ï¼ˆICML-15ï¼‰è®ºæ–‡é›†ï¼Œç”±
    D. Blei & F. Bach ç¼–ï¼ˆJMLR Workshop and Conference Proceedingsï¼‰ï¼Œ448â€“456
- en: IveziÄ‡ etÂ al. (2007) IveziÄ‡, Å½., Smith, J.Â A., Miknaitis, G., etÂ al. 2007, AJ,
    134, 973
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IveziÄ‡ ç­‰ (2007) IveziÄ‡, Å½., Smith, J. A., Miknaitis, G., ç­‰. 2007, AJ, 134, 973
- en: Jia etÂ al. (2014) Jia, Y., Shelhamer, E., Donahue, J., etÂ al. 2014, arXiv preprint
    arXiv:1408.5093
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jia ç­‰ (2014) Jia, Y., Shelhamer, E., Donahue, J., ç­‰. 2014, arXiv é¢„å°æœ¬ arXiv:1408.5093
- en: 'Joly etÂ al. (2016) Joly, A., GoÃ«au, H., Glotin, H., etÂ al. 2016, LifeCLEF 2016:
    Multimedia Life Species Identification Challenges, ed. N.Â Fuhr, P.Â Quaresma, T.Â GonÃ§alves,
    B.Â Larsen, K.Â Balog, C.Â Macdonald, L.Â Cappellato, & N.Â Ferro (Cham: Springer International
    Publishing), 286â€“310'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Joly ç­‰ (2016) Joly, A., GoÃ«au, H., Glotin, H., ç­‰. 2016, LifeCLEF 2016: å¤šåª’ä½“ç”Ÿå‘½ç‰©ç§è¯†åˆ«æŒ‘æˆ˜,
    ç”± N. Fuhr, P. Quaresma, T. GonÃ§alves, B. Larsen, K. Balog, C. Macdonald, L. Cappellato,
    & N. Ferro ç¼–ï¼ˆCham: Springer International Publishingï¼‰ï¼Œ286â€“310'
- en: 'Krizhevsky etÂ al. (2012) Krizhevsky, A., Sutskever, I., & Hinton, G.Â E. 2012,
    in Advances in Neural Information Processing Systems 25: 26th Annual Conference
    on Neural Information Processing Systems 2012\. Proceedings of a meeting held
    December 3-6, 2012, Lake Tahoe, Nevada, United States., 1106â€“1114'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Krizhevsky ç­‰ (2012) Krizhevsky, A., Sutskever, I., & Hinton, G. E. 2012, è§äºã€Šç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•
    25: 2012å¹´ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿå¹´ä¼šã€‹. ä¼šè®®è®ºæ–‡é›†, 2012å¹´12æœˆ3-6æ—¥, å†…åè¾¾å·æ¹– Tahoe, ç¾å›½, 1106â€“1114'
- en: KÃ¼gler etÂ al. (2015) KÃ¼gler, S.Â D., Polsterer, K., & Hoecker, M. 2015, A&A,
    576, A132
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: KÃ¼gler ç­‰ (2015) KÃ¼gler, S. D., Polsterer, K., & Hoecker, M. 2015, A&A, 576,
    A132
- en: LeÂ Guennec etÂ al. (2016) LeÂ Guennec, A., Malinowski, S., & Tavenard, R. 2016,
    in ECML/PKDD Workshop on Advanced Analytics and Learning on Temporal Data, Riva
    Del Garda, Italy
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Le Guennec ç­‰ (2016) Le Guennec, A., Malinowski, S., & Tavenard, R. 2016, è§äº
    ECML/PKDD å…³äºæ—¶é—´æ•°æ®é«˜çº§åˆ†æå’Œå­¦ä¹ çš„ç ”è®¨ä¼šï¼Œæ„å¤§åˆ© Riva Del Garda
- en: Lopez etÂ al. (2008) Lopez, S., Barrientos, L.Â F., Lira, P., etÂ al. 2008, ApJ,
    679, 1144
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lopez ç­‰ (2008) Lopez, S., Barrientos, L. F., Lira, P., ç­‰. 2008, ApJ, 679, 1144
- en: LSST Science Collaboration (2009) LSST Science Collaboration. 2009, [arXiv :0912.0201]
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LSST Science Collaboration (2009) LSST Science Collaboration. 2009, [arXiv :0912.0201]
- en: Meusinger etÂ al. (2011) Meusinger, H., Hinze, A., & de Hoon, A. 2011, A&A, 525,
    A37
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meusinger ç­‰ (2011) Meusinger, H., Hinze, A., & de Hoon, A. 2011, A&A, 525, A37
- en: Nair & Hinton (2010) Nair, V. & Hinton, G.Â E. 2010, in Proceedings of the 27th
    International Conference on Machine Learning (ICML-10), ed. J.Â FÃ¼rnkranz & T.Â Joachims
    (Omnipress), 807â€“814
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nair & Hinton (2010) Nair, V. & Hinton, G. E. 2010, è§äºç¬¬27å±Šå›½é™…æœºå™¨å­¦ä¹ ä¼šè®®ï¼ˆICML-10ï¼‰è®ºæ–‡é›†ï¼Œç”±
    J. FÃ¼rnkranz & T. Joachims ç¼–ï¼ˆOmnipressï¼‰ï¼Œ807â€“814
- en: Nun etÂ al. (2015) Nun, I., Protopapas, P., Sim, B., etÂ al. 2015 [arXiv:1506.00010]
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nun ç­‰ (2015) Nun, I., Protopapas, P., Sim, B., ç­‰. 2015 [arXiv:1506.00010]
- en: Oyaizu etÂ al. (2008) Oyaizu, H., Lima, M., Cunha, C.Â E., etÂ al. 2008, ApJ, 674,
    768
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oyaizu ç­‰ (2008) Oyaizu, H., Lima, M., Cunha, C. E., ç­‰. 2008, ApJ, 674, 768
- en: Peng etÂ al. (2012) Peng, N., Zhang, Y., Zhao, Y., & Wu, X.-b. 2012, MNRAS, 425,
    2599
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng ç­‰ (2012) Peng, N., Zhang, Y., Zhao, Y., & Wu, X.-b. 2012, MNRAS, 425, 2599
- en: Peters etÂ al. (2015) Peters, C.Â M., Richards, G.Â T., Myers, A.Â D., etÂ al. 2015,
    ApJ, 811, 95
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peters ç­‰ (2015) Peters, C. M., Richards, G. T., Myers, A. D., ç­‰. 2015, ApJ,
    811, 95
- en: Portinari etÂ al. (2012) Portinari, L., Kotilainen, J., Falomo, R., & Decarli,
    R. 2012, MNRAS, 420, 732
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Portinari ç­‰ (2012) Portinari, L., Kotilainen, J., Falomo, R., & Decarli, R.
    2012, MNRAS, 420, 732
- en: 'Quinlan (1986) Quinlan, J.Â R. 1986 (Hingham, MA, USA: Kluwer Academic Publishers),
    81â€“106'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Quinlan (1986) Quinlan, J. R. 1986 (Hingham, MA, ç¾å›½: Kluwer Academic Publishers),
    81â€“106'
- en: Rimoldini etÂ al. (2012) Rimoldini, L., Dubath, P., SÃ¼veges, M., etÂ al. 2012,
    MNRAS, 427, 2917
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rimoldini ç­‰ (2012) Rimoldini, L., Dubath, P., SÃ¼veges, M., ç­‰. 2012, MNRAS, 427,
    2917
- en: 'Rumelhart etÂ al. (1986) Rumelhart, D.Â E., Hinton, G.Â E., & Williams, R.Â J.
    1986 (Cambridge, MA, USA: MIT Press), 318â€“362'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rumelhart ç­‰ (1986) Rumelhart, D. E., Hinton, G. E., & Williams, R. J. 1986
    (å‰‘æ¡¥, MA, ç¾å›½: MIT Press), 318â€“362'
- en: Russakovsky etÂ al. (2015) Russakovsky, O., Deng, J., Su, H., etÂ al. 2015, International
    Journal of Computer Vision (IJCV), 115, 211
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russakovsky ç­‰ (2015) Russakovsky, O., Deng, J., Su, H., ç­‰. 2015, å›½é™…è®¡ç®—æœºè§†è§‰æ‚å¿— (IJCV),
    115, 211
- en: Schneider etÂ al. (2010) Schneider, D.Â P., Richards, G.Â T., Hall, P.Â B., etÂ al.
    2010, AJ, 139, 2360
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schneider ç­‰ (2010) Schneider, D. P., Richards, G. T., Hall, P. B., ç­‰. 2010,
    AJ, 139, 2360
- en: Sesar etÂ al. (2007) Sesar, B., IveziÄ‡, Å½., Lupton, R.Â H., etÂ al. 2007, AJ, 134,
    2236
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sesar ç­‰ï¼ˆ2007ï¼‰Sesar, B., IveziÄ‡, Å½., Lupton, R. H., ç­‰. 2007, AJ, 134, 2236
- en: Srivastava etÂ al. (2014) Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever,
    I., & Salakhutdinov, R. 2014, Journal of Machine Learning Research, 15, 1929
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Srivastava ç­‰ï¼ˆ2014ï¼‰Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I.,
    & Salakhutdinov, R. 2014, æœºå™¨å­¦ä¹ ç ”ç©¶æœŸåˆŠ, 15, 1929
- en: Szegedy etÂ al. (2015) Szegedy, C., Liu, W., Jia, Y., etÂ al. 2015, in 2015 IEEE
    Conference on Computer Vision and Pattern Recognition (CVPR), 1â€“9
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy ç­‰ï¼ˆ2015ï¼‰Szegedy, C., Liu, W., Jia, Y., ç­‰. 2015, åœ¨ 2015 IEEE è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«å¤§ä¼šï¼ˆCVPRï¼‰ï¼Œ1â€“9
- en: The Dark Energy Survey Collaboration (2005) The Dark Energy Survey Collaboration.
    2005, ArXiv Astrophysics e-prints [astro-ph/0510346]
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: The Dark Energy Survey Collaborationï¼ˆ2005ï¼‰The Dark Energy Survey Collaboration.
    2005, ArXiv Astrophysics e-prints [astro-ph/0510346]
- en: Vanden Berk etÂ al. (2004) Vanden Berk, D.Â E., Wilhite, B.Â C., Kron, R.Â G., etÂ al.
    2004, ApJ, 601, 692
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vanden Berk ç­‰ï¼ˆ2004ï¼‰Vanden Berk, D. E., Wilhite, B. C., Kron, R. G., ç­‰. 2004,
    ApJ, 601, 692
- en: YÃ¨che etÂ al. (2010) YÃ¨che, C., Petitjean, P., Rich, J., etÂ al. 2010, A&A, 523,
    A14
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YÃ¨che ç­‰ï¼ˆ2010ï¼‰YÃ¨che, C., Petitjean, P., Rich, J., ç­‰. 2010, A&A, 523, A14
- en: York etÂ al. (2000) York, D.Â G., Adelman, J., Anderson, Jr., J.Â E., etÂ al. 2000,
    AJ, 120, 1579
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: York ç­‰ï¼ˆ2000ï¼‰York, D. G., Adelman, J., Anderson, Jr., J. E., ç­‰. 2000, AJ, 120,
    1579
- en: Zhang etÂ al. (2009) Zhang, Y., Li, L., & Zhao, Y. 2009, MNRAS, 392, 233
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang ç­‰ï¼ˆ2009ï¼‰Zhang, Y., Li, L., & Zhao, Y. 2009, MNRAS, 392, 233
- en: Zhang etÂ al. (2013) Zhang, Y., Ma, H., Peng, N., Zhao, Y., & Wu, X.-b. 2013,
    AJ, 146, 22
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang ç­‰ï¼ˆ2013ï¼‰Zhang, Y., Ma, H., Peng, N., Zhao, Y., & Wu, X.-b. 2013, AJ, 146,
    22
- en: Appendix A Appendix
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½• A é™„å½•
- en: '| Layers | Inputs | Kernel size | $h\times w$ | #feature maps |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| å±‚ | è¾“å…¥ | æ ¸å¤§å° | $h\times w$ | #ç‰¹å¾å›¾ |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| P1, P2 | LCI |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| P1, P2 | LCI |'
- en: '&#124; $5\times 1$, $11\times 1$ &#124;'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; $5\times 1$, $11\times 1$ &#124;'
- en: '&#124; (stride 2) &#124;'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124;ï¼ˆæ­¥å¹… 2ï¼‰&#124;'
- en: '| $850\times 5$ | 1, 1 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| $850\times 5$ | 1, 1 |'
- en: '| TC1, TC2, TC3 | P1 | $11\times 1$, $21\times 1$, $41\times 1$ | $850\times
    5$ | 16, 16,16 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| TC1, TC2, TC3 | P1 | $11\times 1$, $21\times 1$, $41\times 1$ | $850\times
    5$ | 16, 16,16 |'
- en: '| TC4, TC5, TC6 | P2 | $11\times 1$, $21\times 1$, $41\times 1$ | $850\times
    5$ | 16, 16, 16 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| TC4, TC5, TC6 | P2 | $11\times 1$, $21\times 1$, $41\times 1$ | $850\times
    5$ | 16, 16, 16 |'
- en: '| MC1 | C1 | $1\times 5$ | $850\times 1$ | 96 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| MC1 | C1 | $1\times 5$ | $850\times 1$ | 96 |'
- en: '| TC7, TC8 | MC1 and C1 | $11\times 1$, $21\times 1$ | $850\times 5$ or $850\times
    1$ | 24, 24 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| TC7, TC8 | MC1 å’Œ C1 | $11\times 1$, $21\times 1$ | $850\times 5$ æˆ– $850\times
    1$ | 24, 24 |'
- en: '| P3 | C2 | $3\times 1$ (stride 2) | $425\times 1$ | 48 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| P3 | C2 | $3\times 1$ï¼ˆæ­¥å¹… 2ï¼‰ | $425\times 1$ | 48 |'
- en: '| P4 | C3 | $3\times 1$ (stride 2) | $425\times 5$ | 48 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| P4 | C3 | $3\times 1$ï¼ˆæ­¥å¹… 2ï¼‰ | $425\times 5$ | 48 |'
- en: '| P5 | LCI | $21\times 1$ (stride 4) | $425\times 5$ | 1 |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| P5 | LCI | $21\times 1$ï¼ˆæ­¥å¹… 4ï¼‰ | $425\times 5$ | 1 |'
- en: '| TC9, TC10, TC11 | P5 | $5\times 1$, $11\times 1$, $21\times 1$ | $425\times
    5$ | 16,16,16 |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| TC9, TC10, TC11 | P5 | $5\times 1$, $11\times 1$, $21\times 1$ | $425\times
    5$ | 16,16,16 |'
- en: '| TC12, TC13 | C4 | $11\times 1$, $21\times 1$ | $425\times 5$ | 24, 24 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| TC12, TC13 | C4 | $11\times 1$, $21\times 1$ | $425\times 5$ | 24, 24 |'
- en: '| MC2 | C5 | $1\times 5$ | $425\times 1$ | 48 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| MC2 | C5 | $1\times 5$ | $425\times 1$ | 48 |'
- en: '| TC14 | C6 and C7 | $11\times 1$ | $425\times 1$ or $425\times 5$ | 96, 96
    |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| TC14 | C6 å’Œ C7 | $11\times 1$ | $425\times 1$ æˆ– $425\times 5$ | 96, 96 |'
- en: '| P6 | TC14 | $3\times 1$ (stride 2) | $212\times 1$ | 96 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| P6 | TC14 | $3\times 1$ï¼ˆæ­¥å¹… 2ï¼‰ | $212\times 1$ | 96 |'
- en: '| P7 | TC14 | $3\times 1$ (stride 2) | $212\times 5$ | 96 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| P7 | TC14 | $3\times 1$ï¼ˆæ­¥å¹… 2ï¼‰ | $212\times 5$ | 96 |'
- en: '| TC15 | P6 and P7 | $11\times 1$ | $425\times 1$ or $425\times 5$ | 48, 48
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| TC15 | P6 å’Œ P7 | $11\times 1$ | $425\times 1$ æˆ– $425\times 5$ | 48, 48 |'
- en: '| P8 | TC15 | $3\times 1$ (stride 2) | $106\times 1$ | 48 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| P8 | TC15 | $3\times 1$ï¼ˆæ­¥å¹… 2ï¼‰ | $106\times 1$ | 48 |'
- en: '| P9 | TC15 | $3\times 1$ (stride 2) | $106\times 5$ | 48 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| P9 | TC15 | $3\times 1$ï¼ˆæ­¥å¹… 2ï¼‰ | $106\times 5$ | 48 |'
- en: '| P10 | LCI | $41\times 1$ (stride 16) | $106\times 5$ | 1 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| P10 | LCI | $41\times 1$ï¼ˆæ­¥å¹… 16ï¼‰ | $106\times 5$ | 1 |'
- en: '| TC16, TC17, TC18 | P10 | $5\times 1$, $11\times 1$, $21\times 1$ | $106\times
    5$ | 16, 16, 16 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| TC16, TC17, TC18 | P10 | $5\times 1$, $11\times 1$, $21\times 1$ | $106\times
    5$ | 16, 16, 16 |'
- en: '| TC19 | C8 | $11\times 1$ | $106\times 5$ | 48 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| TC19 | C8 | $11\times 1$ | $106\times 5$ | 48 |'
- en: '| MC3 | TC19 | $1\times 5$ | $106\times 1$ | 48 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| MC3 | TC19 | $1\times 5$ | $106\times 1$ | 48 |'
- en: '| TC20 | C9 and C10 | $11\times 1$ | $106\times 1$ or $106\times 5$ | 128,
    128 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| TC20 | C9 å’Œ C10 | $11\times 1$ | $106\times 1$ æˆ– $106\times 5$ | 128, 128
    |'
- en: '| P11 | TC20 | $3\times 1$ (stride 2) | $53\times 1$ | 48 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| P11 | TC20 | $3\times 1$ï¼ˆæ­¥å¹… 2ï¼‰ | $53\times 1$ | 48 |'
- en: '| P12 | TC20 | $3\times 1$ (stride 2) | $53\times 5$ | 48 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| P12 | TC20 | $3\times 1$ï¼ˆæ­¥å¹… 2ï¼‰ | $53\times 5$ | 48 |'
- en: '| P13 | LCI | $61\times 1$ (stride 32) | $53\times 5$ | 1 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| P13 | LCI | $61\times 1$ï¼ˆæ­¥å¹… 32ï¼‰ | $53\times 5$ | 1 |'
- en: '| TC21, TC22, TC23 | P13 | $5\times 1$, $11\times 1$, $21\times 1$ | $53\times
    5$ | 16, 16, 16 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| TC21, TC22, TC23 | P13 | $5\times 1$, $11\times 1$, $21\times 1$ | $53\times
    5$ | 16, 16, 16 |'
- en: '| TC24 | C11 | $11\times 1$ | $53\times 5$ | 64 |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| TC24 | C11 | $11\times 1$ | $53\times 5$ | 64 |'
- en: '| TC25, TC26 | C12 | $11\times 1$, $21\times 1$ | $53\times 5$ | 64, 64 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| TC25, TC26 | C12 | $11\times 1$, $21\times 1$ | $53\times 5$ | 64, 64 |'
- en: '| MC4 | C13 | $1\times 5$ | $53\times 1$ | 64 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| MC4 | C13 | $1\times 5$ | $53\times 1$ | 64 |'
- en: '| TC27, TC28, TC29, TC30 | C14 | $5\times 1$, $11\times 1$, $21\times 1$, $41\times
    1$ | $53\times 1$ | 48, 48, 48, 48 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| TC27, TC28, TC29, TC30 | C14 | $5\times 1$, $11\times 1$, $21\times 1$, $41\times
    1$ | $53\times 1$ | 48, 48, 48, 48 |'
- en: '| FC1, FC2 | C15, FC1 | - | - | 1024, 1024 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| FC1, FC2 | C15, FC1 | - | - | 1024, 1024 |'
- en: 'Table A1: Characteristics of each layer of the CNN architecture: the name of
    the layer, the input layer, the size of the convolution kernel (in pixels), the
    size in pixels (height$\times$width) of resulting feature maps and the number
    of resulting feature maps. The concatenation layers are not represented here but
    they are present in Figure [4](#S4.F4 "Figure 4 â€£ 4 Our CNN architecture â€£ Deep
    learning Approach for Classifying, Detecting and Predicting Photometric Redshifts
    of Quasars in the Sloan Digital Sky Survey Stripe 82").'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ A1ï¼šCNN æ¶æ„æ¯å±‚çš„ç‰¹å¾ï¼šå±‚çš„åç§°ã€è¾“å…¥å±‚ã€å·ç§¯æ ¸çš„å¤§å°ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰ã€ç»“æœç‰¹å¾å›¾çš„å¤§å°ï¼ˆé«˜åº¦$\times$å®½åº¦ï¼‰ä»¥åŠç»“æœç‰¹å¾å›¾çš„æ•°é‡ã€‚è¿™é‡Œæœªè¡¨ç¤ºè¿æ¥å±‚ï¼Œä½†å®ƒä»¬åœ¨å›¾
    [4](#S4.F4 "Figure 4 â€£ 4 Our CNN architecture â€£ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82") ä¸­å­˜åœ¨ã€‚
