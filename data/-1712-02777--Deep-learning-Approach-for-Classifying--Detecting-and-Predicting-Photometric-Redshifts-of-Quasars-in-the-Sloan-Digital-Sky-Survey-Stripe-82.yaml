- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:08:32'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:08:32
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1712.02777] Deep learning Approach for Classifying, Detecting and Predicting
    Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1712.02777] 基于深度学习的方法用于分类、检测和预测斯隆数字天空调查条纹82中的类星体光度红移'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1712.02777](https://ar5iv.labs.arxiv.org/html/1712.02777)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1712.02777](https://ar5iv.labs.arxiv.org/html/1712.02777)
- en: '¹¹institutetext: LUPM UMR 5299 CNRS/UM, Université de Montpellier, CC 72, 34095
    Montpellier Cedex 05, France ²²institutetext: CPPM, CNRS-IN2P3, Université Aix
    Marseille II, CC 907, 13288 Marseille cedex 9, France'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ¹¹机构：LUPM UMR 5299 CNRS/UM，蒙彼利埃大学，CC 72，34095 蒙彼利埃 Cedex 05，法国 ²²机构：CPPM，CNRS-IN2P3，普罗旺斯-阿尔卑斯-蓝色海岸大学，CC
    907，13288 马赛 Cedex 9，法国
- en: '²²email: pasquet@cppm.in2p3.fr ³³institutetext: LIRMM UMR 5506 - team ICAR,
    Université de Montpellier, Campus St Priest, 34090 Montpellier ⁴⁴institutetext:
    LSIS UMR 7296, CNRS, ENSAM, Université De Toulon et Aix-Marseille, Bâtiment Polytech,
    13397 Marseille'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ²²电子邮件：pasquet@cppm.in2p3.fr ³³机构：LIRMM UMR 5506 - ICAR团队，蒙彼利埃大学，圣普里斯特校区，34090
    蒙彼利埃 ⁴⁴机构：LSIS UMR 7296，CNRS，ENSAM，托龙大学和艾克斯-马赛大学，Polytech大楼，13397 马赛
- en: '⁴⁴email: jerome.pasquet@lsis.org'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴⁴电子邮件：jerome.pasquet@lsis.org
- en: +
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: +
- en: Deep learning Approach for Classifying, Detecting and Predicting Photometric
    Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于深度学习的方法用于分类、检测和预测斯隆数字天空调查条纹82中的类星体光度红移
- en: J. Pasquet-Itam 1122    J. Pasquet 3344(Accepted November 3, 2017)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: J. Pasquet-Itam 1122    J. Pasquet 3344（接受于2017年11月3日）
- en: We apply a convolutional neural network (CNN) to classify and detect quasars
    in the Sloan Digital Sky Survey Stripe 82 and also to predict the photometric
    redshifts of quasars. The network takes the variability of objects into account
    by converting light curves into images. The width of the images, noted $w$, corresponds
    to the five magnitudes ugriz and the height of the images, noted $h$, represents
    the date of the observation. The CNN provides good results since its precision
    is $0.988$ for a recall of $0.90$, compared to a precision of $0.985$ for the
    same recall with a random forest classifier. Moreover 175 new quasar candidates
    are found with the CNN considering a fixed recall of $0.97$. The combination of
    probabilities given by the CNN and the random forest makes good performance even
    better with a precision of $0.99$ for a recall of $0.90$.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用卷积神经网络（CNN）来分类和检测斯隆数字天空调查条纹82中的类星体，并预测类星体的光度红移。该网络通过将光曲线转换为图像来考虑对象的变化性。图像的宽度，记作$w$，对应于五个光度ugriz，图像的高度，记作$h$，代表观测日期。CNN表现良好，因为其精度为$0.988$，召回率为$0.90$，而随机森林分类器的精度为$0.985$，召回率相同。此外，CNN还发现了175个新的类星体候选者，固定召回率为$0.97$。CNN和随机森林结合的概率使得性能更佳，精度为$0.99$，召回率为$0.90$。
- en: For the redshift predictions, the CNN presents excellent results which are higher
    than those obtained with a feature extraction step and different classifiers (a
    K-nearest-neighbors, a support vector machine, a random forest and a gaussian
    process classifier). Indeed, the accuracy of the CNN within $|\Delta z|<0.1$ can
    reach 78.09$\%$, within $|\Delta z|<0.2$ reaches 86.15$\%$, within $|\Delta z|<0.3$
    reaches 91.2$\%$ and the value of rms is 0.359\. The performance of the KNN decreases
    for the three $|\Delta z|$ regions, since within the accuracy of $|\Delta z|<0.1$,
    $|\Delta z|<0.2$ and $|\Delta z|<0.3$ is 73.72$\%$, 82.46$\%$ and 90.09$\%$ respectively,
    and the value of rms amounts to 0.395\. So the CNN successfully reduces the dispersion
    and the catastrophic redshifts of quasars. This new method is very promising for
    the future of big databases like the Large Synoptic Survey Telescope.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于红移预测，CNN表现出优异的结果，优于通过特征提取步骤和不同分类器（K近邻、支持向量机、随机森林和高斯过程分类器）获得的结果。实际上，CNN在$|\Delta
    z|<0.1$时的准确率可达78.09$\%$，在$|\Delta z|<0.2$时为86.15$\%$，在$|\Delta z|<0.3$时为91.2$\%$，而rms值为0.359。KNN在三个$|\Delta
    z|$区域的性能下降，因为在$|\Delta z|<0.1$、$|\Delta z|<0.2$和$|\Delta z|<0.3$的准确率分别为73.72$\%$、82.46$\%$和90.09$\%$，而rms值为0.395。因此，CNN成功减少了类星体的离散性和灾难性红移。这种新方法对像大型巡天望远镜这样的大型数据库未来非常有前景。
- en: 'Key Words.:'
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: 'Methods: data analysis – Techniques: photometric – Techniques: image processing
    – quasars: general – Surveys'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 方法：数据分析 – 技术：光度学 – 技术：图像处理 – 类星体：一般 – 调查
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Quasars are powered by accretion onto supermassive black holes at the dynamical
    centers of their host galaxies, producing high luminosities spanning a broad range
    of frequencies. They are of paramount importance in astronomy. For example, their
    studies can inform on massive blackhole (e.g. Portinari et al. ([2012](#bib.bib38))).
    Moreover, as they are the most luminous Active Galactic Nuclei (AGN), they can
    be seen far across the Universe. So they give clues to the evolution and structure
    of galaxies (e.g. Hopkins et al. ([2006](#bib.bib20))). They are also used as
    background objects to study the absorption of intergalactic matter in the line
    of sight, which have many applications in Cosmology (e.g. Lopez et al. ([2008](#bib.bib30))).
    With the advent of large and dedicated surveys such as the Sloan Digital Sky Survey
    (SDSS; York et al. ([2000](#bib.bib50))) and the 2dF Quasar Redshift Survey (2QZ;
    Croom et al. ([2009](#bib.bib10))), the number of known quasars has rapidly increased.
    Thus, the SDSS DR7 Quasar catalog (Schneider et al. ([2010](#bib.bib43))) contains
    105,783 spectroscopically confirmed quasars. The catalog covers an area of $\simeq
    9380\,\,\textrm{deg}^{2}$ and the quasar redshifts range from 0.065 to 5.46.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 类星体由位于其宿主星系动力学中心的超大质量黑洞的吸积驱动，产生跨越广泛频率范围的高光度。它们在天文学中具有至关重要的意义。例如，它们的研究可以提供关于大质量黑洞的信息（例如
    Portinari 等人 ([2012](#bib.bib38))）。此外，作为最明亮的活动星系核（AGN），它们可以在宇宙中遥远处被观测到。因此，它们为星系的演化和结构提供线索（例如
    Hopkins 等人 ([2006](#bib.bib20))）。它们也被用作背景天体来研究视线中的银河系间物质的吸收，这在宇宙学中有许多应用（例如 Lopez
    等人 ([2008](#bib.bib30))）。随着大型专门调查如 Sloan Digital Sky Survey (SDSS; York 等人 ([2000](#bib.bib50)))
    和 2dF Quasar Redshift Survey (2QZ; Croom 等人 ([2009](#bib.bib10))) 的出现，已知的类星体数量迅速增加。因此，SDSS
    DR7 类星体目录（Schneider 等人 ([2010](#bib.bib43))) 包含了 105,783 个光谱确认的类星体。该目录覆盖了 $\simeq
    9380\,\,\textrm{deg}^{2}$ 的区域，类星体的红移范围从 0.065 到 5.46。
- en: With the soon coming of the Large Synoptic Survey Telescope (LSST Science Collaboration
    ([2009](#bib.bib31))), it is important to develop classification tools for quasar
    detection given the huge amount of future data. In this way, machine learning
    algorithms are being used increasingly. These algorithms permit to predict the
    label of an object thanks to the extraction of different features which characterize
    the object (e.g. the color of the source). Several classifiers are now commonly
    used in astronomy like random forests which are a set of decision trees (Quinlan
    ([1986](#bib.bib39))), Naives Bayes (Duda & Hart ([1973](#bib.bib12))), Neural
    Networks (Rumelhart et al. ([1986](#bib.bib41))) and Support Vector Machines (Cortes
    & Vapnik ([1995](#bib.bib7))). These methods are very powerful in classification
    and detection of variable objects in astronomy (e.g. Eyer & Blake ([2005](#bib.bib13));
    Dubath et al. ([2011](#bib.bib11)); Blomme et al. ([2011](#bib.bib4)); Rimoldini
    et al. ([2012](#bib.bib40)); Peng et al. ([2012](#bib.bib36)); Peters et al. ([2015](#bib.bib37))).
    We can also cite the recent work of Hernitschek et al. ([2016](#bib.bib19)) on
    the classification and the detection of QSOs in the Pan-STARR S1 (PS1) $3\pi$
    survey. This is a multi-epoch survey that covered three quarters of the sky at
    typically 35 epochs between 2010 and the beginning of 2014 with five filters ($g_{P1}$,
    $r_{P1}$, $i_{P1}$, $z_{P1}$, $y_{P1}$). They use a random forest classifier and
    colors and a structure function as features, to identify 1,000,000 QSO candidates.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型同步测光望远镜（LSST Science Collaboration ([2009](#bib.bib31))) 的即将到来，鉴于未来数据量巨大，开发类星体检测的分类工具变得尤为重要。因此，机器学习算法的使用越来越多。这些算法通过提取不同的特征（例如源的颜色）来预测对象的标签。天文学中现在常用的几个分类器包括随机森林（Quinlan
    ([1986](#bib.bib39)))、朴素贝叶斯（Duda & Hart ([1973](#bib.bib12)))、神经网络（Rumelhart 等人
    ([1986](#bib.bib41))) 和支持向量机（Cortes & Vapnik ([1995](#bib.bib7)))。这些方法在天文学中的分类和变星检测中非常强大（例如
    Eyer & Blake ([2005](#bib.bib13)); Dubath 等人 ([2011](#bib.bib11)); Blomme 等人 ([2011](#bib.bib4));
    Rimoldini 等人 ([2012](#bib.bib40)); Peng 等人 ([2012](#bib.bib36)); Peters 等人 ([2015](#bib.bib37))）。我们还可以提到
    Hernitschek 等人 ([2016](#bib.bib19)) 在 Pan-STARR S1 (PS1) $3\pi$ 调查中关于 QSO 的分类和检测的最新工作。这是一个多时期调查，覆盖了从
    2010 年到 2014 年初之间的三分之四的天空，通常为 35 个时期，使用五个滤光片（$g_{P1}$, $r_{P1}$, $i_{P1}$, $z_{P1}$,
    $y_{P1}$）。他们使用随机森林分类器和颜色以及结构函数作为特征，来识别 1,000,000 个 QSO 候选体。
- en: The main motivation for this work is to propose a new classification and a detection
    method for quasars in the Sloan Digital Sky Survey Stripe 82, that can be easily
    adapted to large future surveys like LSST or DES (The Dark Energy Survey Collaboration
    ([2005](#bib.bib47))). The algorithms mentioned above, involves a feature extraction
    step but the set of features can be incomplete to characterize the variability
    of quasars. That is why we proposed to use another branch of machine learning
    namely deep learning. It is a supervised learning which takes raw data into account
    and extracts by itself the best features for a given problem. This method gives
    very good results in many fields. In particular we use a Convolutional Neural
    Network (CNN) architecture which gives excellent results in several signal processing
    challenges as Imagenet (Russakovsky et al. ([2015](#bib.bib42))), LifeClef (Joly
    et al. ([2016](#bib.bib26))) etc… This approach is very recent in Astronomy and
    its first applications show good results, for example for the classification of
    galaxy morphologies from astronomical images (Huertas-Company et al. ([2015](#bib.bib21))).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作的主要动机是提出一种新的分类和检测方法，用于斯隆数字天空巡天 Stripe 82 中的类星体，该方法可以轻松适应未来的大型调查，如 LSST 或
    DES（暗能量调查合作组 ([2005](#bib.bib47)））。上述算法涉及特征提取步骤，但特征集可能不足以表征类星体的变异性。这就是为什么我们提出使用另一种机器学习方法，即深度学习。它是一种监督学习方法，能够考虑原始数据，并自行提取给定问题的最佳特征。这种方法在许多领域都取得了非常好的结果。特别是我们使用了一种卷积神经网络（CNN）架构，它在多个信号处理挑战中表现出色，如
    Imagenet（Russakovsky et al. ([2015](#bib.bib42)））、LifeClef（Joly et al. ([2016](#bib.bib26)））等……这种方法在天文学中非常新颖，其首次应用显示了良好的结果，例如用于从天文图像中分类银河系形态（Huertas-Company
    et al. ([2015](#bib.bib21)））。
- en: In this work, we propose an innovative architecture based on a CNN to detect
    and classify quasars from light curves, thus taking into account the variability
    of objects. We also apply this kind of architecture to estimate the photometric
    redshifts of quasars. The estimation of photometric redshifts by a CNN classifier
    is an original method which is very promising. This paper is organized as follows.
    In Section 2, we introduce the Stripe 82 data set. In Section 3, we describe the
    CNN architecture and processing. In Section 4, we propose our CNN architecture
    for the detection and the classification of quasars. In Section 5, we analyze
    and discuss the new quasar candidates detected by our method. Then, we compare
    our algorithm with a random forest classifier and combine them. In Section 6 we
    propose to use a similar CNN architecture to predict the photometric redshifts
    of quasars. Finally we summarize our results in Section 7.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们提出了一种基于 CNN 的创新架构，用于从光变曲线中检测和分类类星体，从而考虑了物体的变异性。我们还应用这种架构来估计类星体的光度红移。通过
    CNN 分类器估计光度红移是一种非常有前景的原创方法。本文的组织结构如下：第 2 节介绍了 Stripe 82 数据集；第 3 节描述了 CNN 架构和处理；第
    4 节提出了我们用于类星体检测和分类的 CNN 架构；第 5 节分析并讨论了我们方法检测到的新类星体候选者。然后，我们将我们的算法与随机森林分类器进行比较并进行组合；第
    6 节提出使用类似的 CNN 架构来预测类星体的光度红移；最后，在第 7 节中总结我们的结果。
- en: 2 Data
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 数据
- en: '![Refer to caption](img/45439edb0bf45a05b95c66801f9bc2c9.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/45439edb0bf45a05b95c66801f9bc2c9.png)'
- en: 'Figure 1: Two examples of variable object types in the UWVSC catalog. On left
    panel, it is a quasar light curve and on right panel a RR Lyrae light curve.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：UWVSC 目录中两种变量物体类型的示例。左侧面板是类星体光变曲线，右侧面板是 RR Lyrae 光变曲线。
- en: '![Refer to caption](img/6f6f92d6cb36e4d2f21af736f8f4a93f.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/6f6f92d6cb36e4d2f21af736f8f4a93f.png)'
- en: 'Figure 2: Distribution of spectroscopic redshifts of known quasars in the UWVSC
    catalog.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：UWVSC 目录中已知类星体的光谱红移分布。
- en: The Sloan Digital Sky Survey (SDSS) is a multi-filter imaging and spectroscopic
    redshift survey using a dedicated 2.5-meter telescope at Apache Point observatory
    in New Mexico. It provides deep photometry ($r<22.5$) in five passbands (ugriz).
    The SDSS has imaged a 2.5 degree wide stripe along the Celestial Equator in the
    Southern Galactic Cap several times, called Stripe 82\. It is a deeper survey
    of 275 $\textrm{deg}^{2}$. It was previously imaged about once to three times
    a year from 2000 to 2005 (SDSS-I), then with an increased cadence of 10-20 times
    a year from 2005 to 2008 (SDSS-II) as part of the SDSS-II supernovae survey (Frieman
    et al. ([2008](#bib.bib15))). There are on average 53 epochs, over a time span
    of 5 to 10 years (Abazajian et al. ([2009](#bib.bib1))).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 斯隆数字天空调查（SDSS）是一个多滤光器成像和光谱红移调查，使用位于新墨西哥州Apache Point天文台的2.5米专用望远镜。它提供了五个通带（ugriz）中的深度光度测量（$r<22.5$）。SDSS对南方银河帽沿天球赤道的2.5度宽的条带进行了多次成像，称为Stripe
    82。它是275 $\textrm{deg}^{2}$ 的更深层调查。2000到2005年间，它每年成像约1到3次（SDSS-I），然后在2005到2008年期间，每年成像增加到10-20次（SDSS-II），作为SDSS-II超新星调查的一部分（Frieman
    et al. ([2008](#bib.bib15)))。平均有53个观测时段，跨越5到10年的时间跨度（Abazajian et al. ([2009](#bib.bib1))）。
- en: 'The imaging data used in our work consists of objects solely from the publicly
    available variable source catalog (UWVSC; Ivezić et al. ([2007](#bib.bib24)),
    Sesar et al. ([2007](#bib.bib44))) constructed by researchers at the University
    of Washington. This catalog contains 67,507 unresolved, variable candidates with
    $g\leq 20.5\,\,\textrm{mag}$, at least 10 observations in both g and r bands,
    and a light curve with a root-mean-scatter (rms) $>0.05$ mag and $\chi^{2}$ per
    degree of freedom $>3$ in both g and r bands. Among the data, some variable objects
    have been identified, they are essentially quasars and pulsating stars (see Figure
    [1](#S2.F1 "Figure 1 ‣ 2 Data ‣ Deep learning Approach for Classifying, Detecting
    and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey
    Stripe 82")). However a large part of the data consists of unknown variable objects.
    In this way this catalog is interesting to identify new variable objects. This
    catalog and all light curves are publicly available.¹¹1http://www.astro.washington.edu/users/ivezic/sdss/catalogs/S82variables.html
    We use the UWVSC as the basis for learning and testing for several reasons: 1)
    it contains over 9000 known spectroscopically confirmed quasars (Meusinger et al.
    ([2011](#bib.bib32))) whose the distribution of redshifts is shown in Figure [2](#S2.F2
    "Figure 2 ‣ 2 Data ‣ Deep learning Approach for Classifying, Detecting and Predicting
    Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82") ;
    2) it is a robust variable catalog with a good photometry; 3) the catalog is a
    useful testbed for time domain science to prepare future data sets like LSST.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们工作中使用的成像数据仅包含来自华盛顿大学研究人员构建的公开可用的变星源目录（UWVSC; Ivezić et al. ([2007](#bib.bib24)),
    Sesar et al. ([2007](#bib.bib44))) 的对象。该目录包含67,507个未解决的变星候选体，$g\leq 20.5\,\,\textrm{mag}$，在g和r波段都有至少10次观测，并且光曲线的均方根（rms）$>0.05$
    mag和每个自由度的$\chi^{2}$在g和r波段中都$>3$。在这些数据中，一些变星对象已被识别，它们基本上是类星体和脉动星（见图 [1](#S2.F1
    "图 1 ‣ 2 数据 ‣ 深度学习方法用于分类、检测和预测斯隆数字天空调查Stripe 82中类星体的光度红移")）。然而，数据中很大一部分是未知的变星对象。因此，这个目录对于识别新的变星对象非常有趣。该目录和所有光曲线都是公开可用的。¹¹1http://www.astro.washington.edu/users/ivezic/sdss/catalogs/S82variables.html
    我们使用UWVSC作为学习和测试的基础有几个原因：1）它包含超过9000个已知的光谱确认的类星体（Meusinger et al. ([2011](#bib.bib32)))，其红移分布如图
    [2](#S2.F2 "图 2 ‣ 2 数据 ‣ 深度学习方法用于分类、检测和预测斯隆数字天空调查Stripe 82中类星体的光度红移") 所示；2）这是一个具有良好光度测量的稳健的变星目录；3）该目录是时间域科学的有用测试平台，用于准备未来的数据集，例如LSST。
- en: 3 The Convolutional Neural Network
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 卷积神经网络
- en: In this work, we are particularly interested in CNN which are an approach to
    deep learning methods that are proving their worth in many research fields.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们特别感兴趣的是卷积神经网络（CNN），这是一种深度学习方法，已经在许多研究领域证明了其价值。
- en: 3.1 Light Curve Images
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 光曲线图像
- en: As a CNN takes images as input, we had to find a way to convert a light curve
    to an image taking into account the variability of objects which gives a crucial
    information for the classification of variable objects. Thus, we propose to create
    images whose the width is represented by the five magnitudes (u, g, r, i and z),
    and the height corresponds to the date of the observation. In Stripe 82, there
    are a maximum of 3340 days of observation so images should have a dimension of
    5$\times$3340 pixels. However processing these images is very costly in VRAM memory,
    so we divided the time interval of a light curve by averaging the observations
    taken on two consecutive days, so as to get images of dimensions of 5$\times$1670
    pixels. Then 60 pixels were appended to the edges of the image to avoid side-effects.
    Therefore the size of the final images, called hereafter, LCI (Light Curve Images),
    is 5$\times$1700 pixels.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 CNN 以图像作为输入，我们需要找到一种方法将光变曲线转换为图像，同时考虑到物体的变化，这对变量物体的分类提供了关键的信息。因此，我们建议创建图像，其宽度由五个亮度（u、g、r、i
    和 z）表示，高度则对应于观察日期。在 Stripe 82 中，最多有 3340 天的观测，因此图像的尺寸应为 5$\times$3340 像素。然而，处理这些图像在
    VRAM 内存中非常昂贵，所以我们通过平均处理在连续两天内获取的观测值来划分光变曲线的时间间隔，从而得到 5$\times$1670 像素的图像。然后在图像的边缘附加了
    60 像素以避免副作用。因此，最终图像的大小，以下简称 LCI（光变曲线图像），为 5$\times$1700 像素。
- en: In order to increase the robustness of the network, the learning needs to be
    free of the positions of points. To do this, we generate new light curves by making
    time translations for all points on a given light curve. Thus only the global
    shape of the light curve is taken into account and no positions of points are
    considered as more important than others. This process is similar to that of classical
    data augmentation (Le Guennec et al. ([2016](#bib.bib29)); Krizhevsky et al. ([2012](#bib.bib27)))
    in the CNN learning and increases the size of the database by a factor of 13.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高网络的鲁棒性，学习需要不受点位置的影响。为此，我们通过对给定光变曲线上的所有点进行时间平移来生成新的光变曲线。因此，只考虑光变曲线的整体形状，不将任何点的位置视为比其他点更重要。这一过程类似于
    CNN 学习中的经典数据增强（Le Guennec et al. ([2016](#bib.bib29)); Krizhevsky et al. ([2012](#bib.bib27)))，并将数据库的大小增加了
    13 倍。
- en: 3.2 Introduction to the CNN
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 CNN 简介
- en: '![Refer to caption](img/1e2a8259be396cc77aab33cf1a282671.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/1e2a8259be396cc77aab33cf1a282671.png)'
- en: 'Figure 3: Representation of two convolution layers of a network. The first
    layer is composed of 3 neurons making a convolution between the input image and
    their kernels. The second layer includes two neurons making a sum of convolutions
    as defined in the equation [1](#S3.E1 "In 3.2.1 Convolution ‣ 3.2 Introduction
    to the CNN ‣ 3 The Convolutional Neural Network ‣ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82").'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：网络中两个卷积层的表示。第一层由 3 个神经元组成，对输入图像及其卷积核进行卷积。第二层包括两个神经元，对卷积结果进行求和，如方程 [1](#S3.E1
    "在 3.2.1 卷积 ‣ 3.2 CNN 简介 ‣ 3 卷积神经网络 ‣ 深度学习方法用于分类、检测和预测 Sloan Digital Sky Survey
    Stripe 82 中类星体的光度红移") 中定义。
- en: 'An artificial neuron is a computational model inspired by natural neurons.
    A natural neuron is an electrically excitable cell that processes and transmits
    information via synapses which are connected with other cells. When the signal
    received is strong enough (higher than a specific threshold), the neuron is activated
    and emits a signal which might activate other neurons. Artificial neurons do not
    reproduce the complexity of real neurons, but the global structure is quite similar.
    Indeed, input data are multiplied by weights and then computed by a mathematical
    function which determines the activation of the neuron. An artificial neural network
    is then composed of different neuron layers connected with each other. A layer
    of rank $n$ takes as input the output of the layer of rank $n-1$. The nomenclature
    of layers is the following: i) a layer whose input is not connected to the output
    of another layer, but to the raw data is called input layer; ii) a layer whose
    output is not connected is called an output layer; iii) a layer is called ”hidden”
    if it has either input or output. Each layer is composed of several tens of thousands
    of neurons. In the specific case of a CNN, neurons perform convolution (see Section
    [3.2.1](#S3.SS2.SSS1 "3.2.1 Convolution ‣ 3.2 Introduction to the CNN ‣ 3 The
    Convolutional Neural Network ‣ Deep learning Approach for Classifying, Detecting
    and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey
    Stripe 82")) and pooling operations (see Section [3.2.2](#S3.SS2.SSS2 "3.2.2 Pooling
    ‣ 3.2 Introduction to the CNN ‣ 3 The Convolutional Neural Network ‣ Deep learning
    Approach for Classifying, Detecting and Predicting Photometric Redshifts of Quasars
    in the Sloan Digital Sky Survey Stripe 82")). Layers are sequentially processed
    as follows: first, a convolution operation is applied on raw input data; then
    the output signal is modified by a non linear function; finally a pooling operation
    can be processed. Note that the output of a layer could be considered as a set
    of images. In CNN terminology, each image has named feature map. After all convolution
    and pooling layers, the last convolution layer is connected to a succession of
    layers called ”fully connected layers” and operating as a classical neural network.
    The last one uses a softmax operation to give a probability that the input light
    curve is either a quasar light curve or another object. To perform the learning
    phase, parameters of convolution and fully connected layers are tuned using a
    stochastic gradient descent specific to the given problem, in this case the recognition
    of quasar light curves. This optimization process is very costly, but it can be
    highly parallelizable. We use the Caffe (Jia et al. ([2014](#bib.bib25))) framework
    to train our CNN. The results are obtained using a GTX Titan X card, packed in
    3,072 cores with a 1 GHz base.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经元是一个受自然神经元启发的计算模型。自然神经元是一个电激活的细胞，通过与其他细胞相连的突触处理和传递信息。当接收到的信号足够强（高于特定阈值）时，神经元被激活并发出信号，这可能会激活其他神经元。人工神经元并没有再现真实神经元的复杂性，但整体结构相似。实际上，输入数据会被权重乘以，然后通过一个数学函数计算，该函数决定神经元的激活。人工神经网络由不同的神经元层组成，这些层彼此连接。一个排名为
    $n$ 的层将接收排名为 $n-1$ 的层的输出作为输入。层的命名规则如下：i) 输入未连接到另一个层的输出，而是连接到原始数据的层称为输入层；ii) 输出未连接的层称为输出层；iii)
    如果一个层既有输入又有输出，则称为“隐藏层”。每一层由数万个人工神经元组成。在卷积神经网络（CNN）的特定情况下，神经元执行卷积操作（见[3.2.1节](#S3.SS2.SSS1
    "3.2.1 卷积 ‣ 3.2 CNN简介 ‣ 3 卷积神经网络 ‣ 深度学习方法用于分类、检测和预测斯隆数字天空调查82号条纹中的类星体光度红移")）和池化操作（见[3.2.2节](#S3.SS2.SSS2
    "3.2.2 池化 ‣ 3.2 CNN简介 ‣ 3 卷积神经网络 ‣ 深度学习方法用于分类、检测和预测斯隆数字天空调查82号条纹中的类星体光度红移")）。层按以下顺序处理：首先，对原始输入数据应用卷积操作；然后，通过非线性函数修改输出信号；最后，可以处理池化操作。注意，层的输出可以视为一组图像。在CNN术语中，每个图像称为特征图。在所有卷积和池化层之后，最后的卷积层连接到一系列称为“全连接层”的层，并作为经典神经网络运行。最后一层使用softmax操作来给出输入光度曲线是类星体光度曲线还是其他对象的概率。为了执行学习阶段，卷积层和全连接层的参数通过特定于问题的随机梯度下降进行调优，在这种情况下是类星体光度曲线的识别。这个优化过程非常昂贵，但具有很高的并行性。我们使用Caffe（Jia等人（[2014](#bib.bib25)））框架来训练我们的CNN。结果是使用GTX
    Titan X显卡获得的，该卡具有3,072个核心和1 GHz的基准频率。
- en: 3.2.1 Convolution
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 卷积
- en: 'If we consider a layer or a set of feature maps as input, the first step is
    to apply convolutions. For the first layer, the convolution is done between the
    input image and a filter. Each filter leads to a filtered image. Convolution layers
    are composed of convolutif neurons. Each convolutif neuron applies the sum of
    2D convolutions between the input feature maps and its kernel. In the simple case
    where only one feature map is passed into the input convolutif neuron, the 2D
    convolution between the K kernel of size $w\times h$ and the input feature map
    $I\in\mathbb{R}^{2}$ is noted $\mathbf{I}*\mathbf{K}$ and is defined as: $(I*K)_{x,y}=\sum_{x^{\prime}=x-\frac{w}{2}}^{x+\frac{w}{2}}\,\,\sum_{y^{\prime}=y-\frac{h}{2}}^{y+\frac{h}{2}}\mathbf{K}_{x^{\prime}+\frac{w}{2}-x,\,y^{\prime}+\frac{h}{2}-y}\mathbf{I}_{x^{\prime},y^{\prime}}$
    with (x,y) the coordinates of a given pixel into the output feature map.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将一个层或一组特征图视为输入，第一步是应用卷积。对于第一层，卷积是在输入图像和一个滤波器之间进行的。每个滤波器都会产生一个滤波后的图像。卷积层由卷积神经元组成。每个卷积神经元对输入特征图和其卷积核进行二维卷积的求和。在仅有一个特征图传递给输入卷积神经元的简单情况下，大小为
    $w\times h$ 的卷积核 $K$ 与输入特征图 $I\in\mathbb{R}^{2}$ 之间的二维卷积记作 $\mathbf{I}*\mathbf{K}$，其定义为：$(I*K)_{x,y}=\sum_{x^{\prime}=x-\frac{w}{2}}^{x+\frac{w}{2}}\,\,\sum_{y^{\prime}=y-\frac{h}{2}}^{y+\frac{h}{2}}\mathbf{K}_{x^{\prime}+\frac{w}{2}-x,\,y^{\prime}+\frac{h}{2}-y}\mathbf{I}_{x^{\prime},y^{\prime}}$，其中
    (x,y) 是输出特征图中给定像素的坐标。
- en: 'In the case of convolutional neural networks, a neuron takes as input each
    of $p$ feature maps of the previously layer noted $I^{l}$ with $l\in\{0...p\}$.
    The resulting feature map is the sum of $p$ 2D convolutions between the kernel
    $K^{l}$ and the map $I^{l}$ (see Figure [3](#S3.F3 "Figure 3 ‣ 3.2 Introduction
    to the CNN ‣ 3 The Convolutional Neural Network ‣ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82")) and is defined as:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积神经网络的情况下，一个神经元以先前层的每个 $p$ 个特征图 $I^{l}$ 作为输入，其中 $l\in\{0...p\}$。结果特征图是 $p$
    个二维卷积的和，卷积核为 $K^{l}$，特征图为 $I^{l}$（见图 [3](#S3.F3 "Figure 3 ‣ 3.2 Introduction to
    the CNN ‣ 3 The Convolutional Neural Network ‣ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82)），定义为：
- en: '|  | $(\mathbf{I}*\mathbf{K})=\sum_{l=0}^{p}(\mathbf{K}^{l}\mathbf{*I}^{l})$
    |  | (1) |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '|  | $(\mathbf{I}*\mathbf{K})=\sum_{l=0}^{p}(\mathbf{K}^{l}\mathbf{*I}^{l})$
    |  | (1) |'
- en: In this work we propose to use two types of convolutions that we call “temporal
    convolutions” and “filter convolutions”. The temporal convolutions use a kernel
    with a x-dimension of 1 pixel, so the five magnitudes (u, g, r, i and z) are convoluted
    separately, and with a y-dimension variable in the interval {5, 11, 21, 41} pixels.
    Thus the temporal convolutions take into account a value of magnitude at different
    times and at different resolutions. The advantage of this type of convolutions
    is to create a network which is able to detect short and long variability patterns.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们提议使用两种我们称之为“时间卷积”和“滤波器卷积”的卷积类型。时间卷积使用尺寸为 1 像素的 x-维卷积核，因此五个幅度（u、g、r、i
    和 z）被单独卷积，并且 y-维度在 {5, 11, 21, 41} 像素的区间内可变。因此，时间卷积考虑了在不同时间和不同分辨率下的幅度值。这种卷积的优点是创建一个能够检测短期和长期变异模式的网络。
- en: The filter convolutions use a kernel with a dimension of $5\times 1$ pixels,
    so they merge the values of the five magnitudes in order to integrate the information
    from color which is an important feature to characterize variable objects, at
    a given time.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波器卷积使用尺寸为 $5\times 1$ 像素的卷积核，因此它们合并了五个幅度的值，以整合颜色信息，这是描述可变对象的重要特征，在特定时间内。
- en: 3.2.2 Pooling
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 池化
- en: The network can be composed of pooling layers which quantify the information
    while reducing the data volume. The Pooling Layer operates independently on each
    feature map. On each feature map, it slides a specific filter which represents
    the local distribution. The two most used methods consist in selecting only the
    maximal or the mean value of the data in the local region. As the observational
    data are not continuous in time, several pixels in the LCI are equal to zero.
    Thus we decide to adapt the pooling by the mean, i.e. we don’t taking into account
    the null pixels in the computation of the mean. Our architecture includes this
    improvement of the pooling on the first pooling layers of the network. The others
    layers contain a max pooling.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 网络可以由池化层组成，这些层在减少数据量的同时量化信息。池化层在每个特征图上独立操作。在每个特征图上，它滑动一个表示局部分布的特定滤波器。最常用的两种方法是选择局部区域内的数据的最大值或均值。由于观察数据在时间上不是连续的，LCI中的几个像素等于零。因此，我们决定通过均值来适应池化，即在计算均值时不考虑零像素。我们的架构在网络的第一层池化层中包含了这一池化改进。其他层包含最大池化。
- en: 3.2.3 Activation Functions
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 激活函数
- en: 'The convolution layers are followed by non linear transformations whose goal
    is to solve the non-linear classification problems. The two most used functions
    are the ReLU (Rectify Lineair Unit, Nair & Hinton ([2010](#bib.bib33))) defined
    by $f(x)=max(x,0)$ and the hyperbolic tangent. In our network, to saturate the
    input signal we apply a hyperbolic tangent function on all of the first convolution
    layers. The other layers use a PReLU (He et al. ([2015](#bib.bib18))) function
    defined as: <math   alttext="f(x)=\begin{cases}\alpha
    x&amp;x<0\\'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层后面跟随非线性变换，其目标是解决非线性分类问题。最常用的两个函数是**ReLU**（线性整流单元，Nair & Hinton ([2010](#bib.bib33)))，定义为
    $f(x)=max(x,0)$ 和双曲正切函数。在我们的网络中，为了饱和输入信号，我们在所有第一层卷积层上应用双曲正切函数。其他层使用**PReLU**（He
    et al. ([2015](#bib.bib18))) 函数，定义为：<math  
    alttext="f(x)=\begin{cases}\alpha x&amp;x<0\\
- en: x&amp;x\geq 0\end{cases}" display="inline"><semantics ><mrow
     ><mrow 
    ><mi  >f</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
     ><mo stretchy="false"
     >(</mo><mi
     >x</mi><mo stretchy="false"
     >)</mo></mrow></mrow><mo
     >=</mo><mrow
     ><mo 
    >{</mo><mtable columnspacing="5pt" rowspacing="0pt"
     ><mtr 
    ><mtd  columnalign="left"
     ><mrow
     ><mi
     >α</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi
     >x</mi></mrow></mtd><mtd
     columnalign="left"  ><mrow
     ><mi
     >x</mi><mo
     ><</mo><mn
     >0</mn></mrow></mtd></mtr><mtr
     ><mtd 
    columnalign="left"  ><mi
     >x</mi></mtd><mtd
     columnalign="left"  ><mrow
     ><mi
     >x</mi><mo
     >≥</mo><mn
     >0</mn></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply 
    ><apply  ><ci
     >𝑓</ci><ci
     >𝑥</ci></apply><apply
     ><csymbol
    cd="latexml"  >cases</csymbol><apply
     ><ci
     >𝛼</ci><ci
     >𝑥</ci></apply><apply
     ><ci
     >𝑥</ci><cn
    type="integer"  >0</cn></apply><ci
     >𝑥</ci><apply
     ><ci
     >𝑥</ci><cn
    type="integer"  >0</cn></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >f(x)=\begin{cases}\alpha
    x&x<0\\ x&x\geq 0\end{cases}</annotation></semantics></math> , with $\alpha$ an
    hyperparameter defined by back-propagation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: \( f(x)=\begin{cases}\alpha x & x < 0\\ x & x \geq 0\end{cases} \)，其中 $\alpha$
    是一个通过反向传播定义的超参数。
- en: 4 Our CNN architecture
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 我们的CNN架构
- en: '![Refer to caption](img/c33e458e9ba061261fcc91c78c44d0ba.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/c33e458e9ba061261fcc91c78c44d0ba.png)'
- en: 'Figure 4: Representation of the architecture that we are proposing. The structure
    is subdivided into five successive processing blocks at different temporal resolutions.
    Two types of convolutions are used: temporal convolutions with four kernel sizes:
    $41\times 1$, $21\times 1$, $11\times 1$ and $5\times 1$ and filter convolutions
    with a kernel size of $5\times 1$.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：我们所提议的架构的表示。该结构被细分为五个连续的处理块，具有不同的时间分辨率。使用了两种类型的卷积：具有四种内核大小的时间卷积：$41\times
    1$、$21\times 1$、$11\times 1$ 和 $5\times 1$，以及内核大小为$5\times 1$的滤波器卷积。
- en: The overall structure can be subdivided into successive processing blocks at
    different temporal resolutions (4, 8, 16, 32 and 64 days) as shown in Figure [4](#S4.F4
    "Figure 4 ‣ 4 Our CNN architecture ‣ Deep learning Approach for Classifying, Detecting
    and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey
    Stripe 82"), on five levels of depth. The initial resolution of LCI is two days
    per pixel. At each processing level, this resolution is reduced by a factor of
    2, by a max-pooling. Moreover, each processing block is powered by a set of feature
    maps coming from an average-pooling retrieved a parallel on the first light curve
    image. These feature maps are then convoluted by three types of temporal convolutions,
    processing images by three different filter sizes. This set of temporal convolutions
    is similar to a multi-resolutions process which is used in modern architectures
    like the GoogleNet network (Szegedy et al. ([2015](#bib.bib46))). The resulting
    feature maps are then transmitted to the processing block of the associated resolution.
    We note $\mathbb{F}_{i}$ the set of resulting feature maps transmitted to the
    processing block $i$. Thus as shown in Figure [4](#S4.F4 "Figure 4 ‣ 4 Our CNN
    architecture ‣ Deep learning Approach for Classifying, Detecting and Predicting
    Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82"),
    feature maps whose a pixel is represented by 4 days are transmitted to the module
    A, and those whose a pixel is represented by 8 days are transmitted to the module
    B, etc…
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 总体结构可以细分为在不同时间分辨率（4、8、16、32 和 64 天）下的连续处理块，如图[4](#S4.F4 "Figure 4 ‣ 4 Our CNN
    architecture ‣ Deep learning Approach for Classifying, Detecting and Predicting
    Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82")所示，共五个深度层级。LCI的初始分辨率为每像素两天。在每个处理层级，这一分辨率通过最大池化降低一倍。此外，每个处理块由一组来自平均池化的特征图提供，这些特征图从第一条光曲线图像中并行检索而来。这些特征图随后经过三种类型的时间卷积处理，使用三种不同的滤波器大小处理图像。这组时间卷积类似于现代架构中使用的多分辨率过程，如GoogleNet网络（Szegedy
    et al. ([2015](#bib.bib46)))。得到的特征图然后传输到相应分辨率的处理块。我们用$\mathbb{F}_{i}$表示传输到处理块$i$的特征图集。如图[4](#S4.F4
    "Figure 4 ‣ 4 Our CNN architecture ‣ Deep learning Approach for Classifying, Detecting
    and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey
    Stripe 82")所示，表示每个像素为4天的特征图被传输到模块A，表示每个像素为8天的特征图被传输到模块B，等等…
- en: In a first step, a filter convolution (MC1 in schema [4](#S4.F4 "Figure 4 ‣
    4 Our CNN architecture ‣ Deep learning Approach for Classifying, Detecting and
    Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe
    82")) is applied on $\mathbb{F}_{A}$. The feature maps resulting from MC1 are
    noted $\mathbb{F}^{\prime}_{A}$. We then apply two temporal convolutions (TC7
    and TC8) with weights called ”shared”. This term can be explained by the difference
    of the convolution kernels applied to the sets $\mathbb{F}_{A}$ and $\mathbb{F}^{\prime}_{A}$.
    We modify the standard convolutions so a given kernel can be applied on two sets
    of feature maps with different sizes. The goal is to highlight similar temporal
    patterns between two sets of feature maps $\mathbb{F}_{A}$ and $\mathbb{F}^{\prime}_{A}$,
    and so between mixed and not-mixed magnitudes amongst themselves. The feature
    maps coming from the convolution layers TC7 and TC8 on the set $\mathbb{F}_{A}$
    are concatenated and then pooled in the pooling layer P4\. The resulting feature
    maps are noted $\Omega_{B}$ and then transmitted to the processing block B. The
    same process is applied to the set of feature maps $\mathbb{F}^{\prime}_{A}$ giving
    the set $\Omega^{\prime}_{B}$.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步中，对$\mathbb{F}_{A}$应用了一个滤波卷积（MC1，见[4](#S4.F4 "图 4 ‣ 4 我们的CNN架构 ‣ 用于分类、检测和预测斯隆数字天空调查条纹82中类星体光度红移的深度学习方法")）。MC1得到的特征图记作$\mathbb{F}^{\prime}_{A}$。接下来，我们对其应用了两个时间卷积（TC7和TC8），其权重被称为“共享”。这个术语可以通过应用于集合$\mathbb{F}_{A}$和$\mathbb{F}^{\prime}_{A}$的卷积核的差异来解释。我们修改了标准卷积，以便一个给定的卷积核可以应用于两个不同大小的特征图集合。目标是突出显示两个特征图集合$\mathbb{F}_{A}$和$\mathbb{F}^{\prime}_{A}$之间的相似时间模式，从而突出混合和未混合的量之间的差异。来自卷积层TC7和TC8对集合$\mathbb{F}_{A}$的特征图被连接起来，然后在池化层P4中池化。得到的特征图记作$\Omega_{B}$，然后传递到处理块B。对特征图集合$\mathbb{F}^{\prime}_{A}$应用相同的过程，得到集合$\Omega^{\prime}_{B}$。
- en: 'The second processing block performs a temporal convolution with two kernels
    of different sizes (TC12 and TC13) on $\mathbb{F}_{B}$. The resulting feature
    maps are then transmitted to two layers: C7 and MC2\. In the C7 layer, they are
    concatenated with the set $\Omega_{B}$. In the MC2 layer, they are convoluted
    by a filter. The resulting feature maps are concatenated with that of the set
    $\Omega^{\prime}_{B}$. The set of produced feature maps are temporally convoluted
    with shared weights in the TC14 layer. The result is then pooled and transmitted
    to the processing block C.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个处理块对$\mathbb{F}_{B}$执行了一个带有不同大小的两个卷积核（TC12和TC13）的时间卷积。得到的特征图然后被传递到两个层：C7和MC2。在C7层，它们与集合$\Omega_{B}$连接。在MC2层，它们被一个滤波器卷积。得到的特征图与集合$\Omega^{\prime}_{B}$的特征图连接。生成的特征图集合在TC14层进行时间卷积，使用共享权重。结果然后被池化并传递到处理块C。
- en: The functioning of the rest of the blocks are similar to that of block B. The
    number of feature maps and the size of each layer are noted in Table [A1](#A1.T1
    "Table A1 ‣ Appendix A Appendix ‣ Deep learning Approach for Classifying, Detecting
    and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey
    Stripe 82") in the appendix. We can remark that the processing block E transmits
    only feature maps whose magnitudes are merged, which are then temporally convoluted
    and transmitted to the fully connected layers. After convolution layers, the size
    of feature maps are 53$\times$1 pixel.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 其余块的功能类似于块B。每层的特征图数量和大小记载在附录中的表[A1](#A1.T1 "表 A1 ‣ 附录 A ‣ 用于分类、检测和预测斯隆数字天空调查条纹82中类星体光度红移的深度学习方法")。我们可以注意到处理块E只传递幅度已合并的特征图，这些特征图随后被时间卷积并传递到完全连接层。在卷积层之后，特征图的大小为53$\times$1像素。
- en: In the network architecture we use two processes to avoid over fitting. First,
    all the feature maps are normalized using the batch normalization (Ioffe & Szegedy
    ([2015](#bib.bib23))). Second, the outputs of the fully connected layers are randomly
    dropout (Srivastava et al. ([2014](#bib.bib45))). During the back-propagation
    processing, the network has to determine a large number of parameters, namely
    1,802,032 in the convolution layers and 11,468,80 in the fully-connected layers.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络架构中，我们使用了两个过程来避免过拟合。首先，所有的特征图都使用批量归一化（Ioffe & Szegedy ([2015](#bib.bib23)))进行归一化。其次，完全连接层的输出会随机丢弃（Srivastava
    et al. ([2014](#bib.bib45)))。在反向传播处理中，网络需要确定大量的参数，即卷积层中为1,802,032，完全连接层中为11,468,80。
- en: 5 Classification Results
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 分类结果
- en: 5.1 Experimental protocol
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 实验协议
- en: 'We did five cross-validations of the database by always selecting 75$\%$ of
    the LCI for the learning base and 25$\%$ for the testing base.For each of the
    five cross-validations, each CNN completed its learning on 60 epochs (during an
    epoch, each LCI is transmitted to the network and its error is back-propagated).
    Each CNN has three outputs on the softmax layer corresponding to the following
    classes : quasars, pulsating stars (RR Lyrae and $\delta$ Scuti) and other objects.
    During the testing phase, each CNN gives a list of detected quasars in the testing
    base. We merge the lists given by each CNN into one list that we evaluate.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对数据库进行了五次交叉验证，每次交叉验证都选择了75$\%$的LCI作为学习集和25$\%$作为测试集。对于每个交叉验证，每个CNN进行了60个epoch的学习（在一个epoch期间，将每个LCI传递给网络并进行误差反向传播）。每个CNN在softmax层上有三个输出，分别对应以下类别：类星体、脉动星（RR
    Lyrae和$\delta$ Scuti）和其他物体。在测试阶段，每个CNN在测试集中给出一个探测到的类星体列表。我们将每个CNN给出的列表合并成一个列表进行评估。
- en: 5.2 Results
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 结果
- en: '![Refer to caption](img/c86faea7f802fe4da7ccb6996e5b6823.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c86faea7f802fe4da7ccb6996e5b6823.png)'
- en: 'Figure 5: The left histogram illustrates the performance of the CNN depending
    on the median g-band magnitude. The right histogram shows the performance of the
    CNN in function of the redshift. On each histogram the blue bars represent the
    number of well detected quasars by the CNN and the green bars the total number
    of quasars inside the corresponding bin. The recall is indicated over each couple
    of bars.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：左侧直方图显示了CNN性能与中位g-band幅度的关系。右侧直方图显示了CNN性能与红移的函数关系。在每个直方图上，蓝色柱代表CNN正确探测到的类星体数量，绿色柱代表相应区间内的类星体总数。每对柱子上方标明了召回率。
- en: The performance of the CNN is given on Figure [5](#S5.F5 "Figure 5 ‣ 5.2 Results
    ‣ 5 Classification Results ‣ Deep learning Approach for Classifying, Detecting
    and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey
    Stripe 82") in function of the magnitude and the redshift. We can notice that
    for a g-band magnitude below 17 magnitudes, the value of the recall decreases
    until a recall of 50%. It is due to the too low number of examples of very bright
    quasars in the training set. Indeed there are only 22 light curves of quasars
    in the training database with magnitudes between 15 and 17\. However the recall
    is similar whatever magnitudes above 17 for the g-band magnitude. It is a very
    interesting result because it means that the CNN performance does not depend on
    the magnitude but only on the number of objects in the training database. This
    effect is less visible on the right histogram of Figure [5](#S5.F5 "Figure 5 ‣
    5.2 Results ‣ 5 Classification Results ‣ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82"). Indeed, it is enough to consider only 5% of the training
    database to reach a recall between 98% and 99%. This experiment shows that the
    CNN is invariant to redshift.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: CNN的性能在图[5](#S5.F5 "图5 ‣ 5.2 结果 ‣ 5 分类结果 ‣ 斯隆数字天空测量区域82条带中的类星体的光学红移的深度学习方法")中以幅度和红移的函数给出。我们可以注意到，对于g-band幅度低于17，召回率的值下降到50%。这是因为训练集中非常明亮的类星体的样本数量太少。实际上，训练数据库中在15至17幅度之间只有22个类星体的光变曲线。然而，对于g-band幅度高于17，召回率是相似的。这是一个非常有趣的结果，因为它意味着CNN的性能并不取决于幅度，而只取决于训练数据库中的物体数量。这种效应在图[5](#S5.F5
    "图5 ‣ 5.2 结果 ‣ 5 分类结果 ‣ 斯隆数字天空测量区域82条带中的类星体的光学红移的深度学习方法") 的右侧直方图上不太明显。实际上，只需考虑训练数据库的5%就能达到98%至99%之间的召回率。这个实验证明了CNN对红移不变。
- en: In the testing base, for a fixed recall of 0.97, 175 new quasars detected by
    the CNN have never been identified before. We call them quasar candidates. Figure
    [6](#S5.F6 "Figure 6 ‣ 5.2 Results ‣ 5 Classification Results ‣ Deep learning
    Approach for Classifying, Detecting and Predicting Photometric Redshifts of Quasars
    in the Sloan Digital Sky Survey Stripe 82") represents the spatial distribution
    of found quasars in the testing base by the CNN. The red crosses characterize
    the new quasar candidates.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试集中，对于固定召回率0.97，CNN检测到的175个新类星体以前从未被鉴定出。我们称之为类星体候选对象。图[6](#S5.F6 "图6 ‣ 5.2
    结果 ‣ 5 分类结果 ‣ 斯隆数字天空测量区域82条带中的类星体的光学红移的深度学习方法")表示CNN在测试集中发现的类星体的空间分布。红色十字标志着新的类星体候选对象。
- en: '![Refer to caption](img/5dfc422472d267dd837b18b98399658e.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/5dfc422472d267dd837b18b98399658e.png)'
- en: 'Figure 6: Spatial distribution of quasars detected by the CNN during the testing
    phase. The gray crosses represent the well-known detected quasars, and the red
    crosses are the 175 new quasar candidates. They are uniformly distributed in the
    sky.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：CNN在测试阶段检测到的类星体的空间分布。灰色的交叉点表示已知的检测到的类星体，红色的交叉点是175个新的类星体候选者。它们在天空中均匀分布。
- en: As we can see, the quasars detected by the CNN are distributed in an uniform
    manner. Figure [7](#S5.F7 "Figure 7 ‣ 5.2 Results ‣ 5 Classification Results ‣
    Deep learning Approach for Classifying, Detecting and Predicting Photometric Redshifts
    of Quasars in the Sloan Digital Sky Survey Stripe 82") shows the average number
    of quasars in the sky per square degree, detected by the CNN, against the recall.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，CNN检测到的类星体分布均匀。图 [7](#S5.F7 "Figure 7 ‣ 5.2 Results ‣ 5 Classification
    Results ‣ Deep learning Approach for Classifying, Detecting and Predicting Photometric
    Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82") 显示了CNN检测到的天空每平方度的类星体平均数量与召回率的关系。
- en: '![Refer to caption](img/d6174c38a8f91ffc6e83fb84cb889ba9.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d6174c38a8f91ffc6e83fb84cb889ba9.png)'
- en: 'Figure 7: Average number of quasars in the sky per square degree, detected
    by the CNN, against the recall. The larger the recall, the higher the number of
    the detected quasars is. For a recall of 0.92, the average number of detected
    quasars is 20 per square degree. Then this number is drastically increased since
    the precision is reduced and so the contamination of non-quasar sources is increased.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：CNN检测到的天空每平方度的类星体平均数量与召回率的关系。召回率越大，检测到的类星体数量越高。对于0.92的召回率，每平方度的检测到的类星体平均数量为20个。然后这个数字急剧增加，因为精度降低，非类星体源的污染增加。
- en: As the recall increases, the number of quasars per square degree increases,
    which is consistent as we detected more and more quasars. For a recall around
    0.92, the average number of quasars per square degree is about 20\. Then, this
    number is drastically increased because the precision is reduced and the sample
    is contaminated by sources which are not quasars.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 随着召回率的提高，每平方度的类星体数量增加，这与我们检测到越来越多的类星体是一致的。对于约0.92的召回率，每平方度的类星体平均数量约为20个。然后，由于精度降低且样本中混入了非类星体的源，这个数字急剧增加。
- en: It is also interesting to highlight that a well known property of quasars is
    met by the new quasar candidates, namely a ”bluer when brighter” tendency. This
    trend has been well established in the UV/optical color variations in quasar (e.g.
    Cristiani et al. ([1997](#bib.bib9)), Giveon et al. ([1999](#bib.bib16)), Vanden
    Berk et al. ([2004](#bib.bib48))). Figure [8](#S5.F8 "Figure 8 ‣ 5.2 Results ‣
    5 Classification Results ‣ Deep learning Approach for Classifying, Detecting and
    Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe
    82") represents the amplitude of variations of detected quasars in the u-band
    filter against the r-band filter at different recalls. We note that $83.6\%$ and
    $88.7\%$ of variation amplitudes in the u-band filter are larger than in the r-band
    filter for a recall of 0.90 and 0.97 respectively. Thus the detected quasars show
    larger variation amplitudes in bluer bands and so a strong wavelength dependence.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得指出的是，新类星体候选者符合一个已知的类星体特性，即“更亮时更蓝”的趋势。这一趋势在类星体的UV/光学颜色变化中已经得到很好的验证（例如，Cristiani等人
    ([1997](#bib.bib9))，Giveon等人 ([1999](#bib.bib16))，Vanden Berk等人 ([2004](#bib.bib48))）。图
    [8](#S5.F8 "Figure 8 ‣ 5.2 Results ‣ 5 Classification Results ‣ Deep learning
    Approach for Classifying, Detecting and Predicting Photometric Redshifts of Quasars
    in the Sloan Digital Sky Survey Stripe 82") 显示了在不同召回率下，u带滤光片与r带滤光片检测到的类星体的变化幅度。我们注意到，在召回率为0.90和0.97时，u带滤光片中的变化幅度分别比r带滤光片大$83.6\%$和$88.7\%$。因此，检测到的类星体在蓝光带中的变化幅度更大，表现出强的波长依赖性。
- en: '![Refer to caption](img/9fdc25b733207d4315de07102f7ead0a.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9fdc25b733207d4315de07102f7ead0a.png)'
- en: 'Figure 8: Amplitudes of variation of quasars detected by the CNN from the u-band
    filter against those from the r-band filter at three different recalls: 0.90,
    0.95 and 0.97\. The black crosses represent all the known quasars during the testing
    phase. The red crosses are the 175 new quasar candidates. The dashed line represent
    the line $y=x$. The quasars show larger variation amplitudes in bluer-bands. This
    tendency highlights a strong wavelength dependence.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：CNN从u带滤光片检测到的类星体的变化幅度与从r带滤光片检测到的类星体在三种不同召回率（0.90、0.95和0.97）下的变化幅度。黑色交叉点表示测试阶段所有已知的类星体。红色交叉点是175个新的类星体候选者。虚线表示线
    $y=x$。类星体在蓝光带中的变化幅度较大。这种趋势突显了强的波长依赖性。
- en: 5.3 Comparison with a random forest classifier
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 与随机森林分类器的比较
- en: We compare the performance of our algorithm with that of a random forest classifier
    whose we empirically estimated the best parameters on the same database. It contains
    400 decision trees and an unlimited depth. The features used are included in a
    python library named FATS (Feature Analysis for Time Series, Nun et al. ([2015](#bib.bib34)))
    which is a compilation of some of the existing light-curve features.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将我们的算法性能与随机森林分类器的性能进行比较，我们在相同数据库上通过经验方法估计了其最佳参数。该分类器包含 400 棵决策树，深度不限。使用的特征包含在一个名为
    FATS（Feature Analysis for Time Series, Nun et al. ([2015](#bib.bib34)））的 Python
    库中，该库是一些现有光变曲线特征的汇编。
- en: At a fixed recall of 0.90, the precision is 0.988 for the CNN and 0.985 for
    the random forest. Then for a fixed recall of 0.97, the precision is 0.964 and
    0.973 for the CNN and the random forest respectively. The performances of the
    two methods are closed and a little better for the random forest. A possible explication
    concerns the number of freedom degrees. Indeed for the random forest, about 640
    000 parameters are defined whereas for the CNN there are about 13 000 000\. Thus,
    due to the large number of parameters that have to be determined by backpropagation,
    the CNN should have better performance with more data, especially with large surveys.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在固定召回率为 0.90 的情况下，CNN 的精度为 0.988，而随机森林的精度为 0.985。然后，在固定召回率为 0.97 的情况下，CNN 和随机森林的精度分别为
    0.964 和 0.973。这两种方法的表现接近，而随机森林稍微更好。一种可能的解释涉及自由度的数量。实际上，对于随机森林，大约定义了 640,000 个参数，而对于
    CNN，参数数量约为 13,000,000。因此，由于 CNN 需要通过反向传播确定大量参数，在数据量更多的情况下，CNN 应该能有更好的表现，特别是在大型调查中。
- en: 5.4 Combination of a CNN and a random forest
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 CNN 和随机森林的结合
- en: We combine the probabilities given by the CNN and the random forest by averaging
    them. For a fixed recall of 0.90 the precision is 0.99 and for a recall of 0.97,
    the precision is 0.98\. Thus the combination of the two classifiers makes good
    performance even better. Figure [9](#S5.F9 "Figure 9 ‣ 5.4 Combination of a CNN
    and a random forest ‣ 5 Classification Results ‣ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82") shows the receiver operating characteristic curve (ROC
    curve hereafter) which is a graphical plot that illustrates the performance of
    a classifier by plotting the precision against the recall. We can see that the
    random forest performance (red curve) is better than that of the CNN (black curve)
    until a recall of 0.978, where the CNN performance slightly drops. Moreover the
    ROC curve representing the combination of the two classifiers (green curve) is
    above the two others and shows that combining a CNN classifier and a random forest
    classifier gives better classification performance. The improvement obtained by
    the combination of the CNN and the random forest can be explained by the complementarity
    between the features given to the random forest and the features extracted by
    the CNN. Indeed, features used by the random forest are defined by the user and
    are specific for the classification of light curves of variable objects in general
    but they could not be perfectly designed for this classification problem that
    we considered. On another side the CNN learns from scratch without any prior.
    The CNN found relevant features which are specific to the used database and so
    complete the information given by the features used by the RF. However, since
    the CNN learns features from the data, if there is not a large number of examples
    for a kind of objects, such as the high redshift quasars, the CNN does not find
    and learn the best features. In this case, it is relevant to use the results from
    the random forest to improve the classification. So depending on the number of
    data, the random forest features or the CNN features can complete each other.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过对 CNN 和随机森林给出的概率进行平均来进行组合。对于固定的召回率 0.90，精度为 0.99，而对于召回率 0.97，精度为 0.98。因此，两个分类器的组合使得良好的性能更上一层楼。图
    [9](#S5.F9 "图 9 ‣ 5.4 CNN 和随机森林的组合 ‣ 5 分类结果 ‣ 用于分类、检测和预测斯隆数字天空调查第82条纹的类星体光度红移的深度学习方法")
    显示了接收者操作特征曲线（ROC 曲线），这是一种图形化的绘图方法，用于通过绘制精度与召回率的关系来展示分类器的性能。我们可以看到，随机森林的性能（红色曲线）优于
    CNN（黑色曲线），直到召回率为 0.978，此时 CNN 的性能略微下降。此外，代表两个分类器组合的 ROC 曲线（绿色曲线）高于其他两条曲线，显示了组合
    CNN 分类器和随机森林分类器可以提供更好的分类性能。CNN 和随机森林的组合所获得的改进可以通过随机森林提供的特征和 CNN 提取的特征之间的互补性来解释。实际上，随机森林使用的特征由用户定义，通常针对变量对象的光度曲线分类，但它们可能无法完美地设计用于我们考虑的分类问题。而
    CNN 从头开始学习，没有任何先验知识。CNN 发现了对所用数据库特定的相关特征，从而补充了 RF 使用的特征所提供的信息。然而，由于 CNN 从数据中学习特征，如果某种对象的样本数量不多，例如高红移类星体，CNN
    可能无法找到并学习最佳特征。在这种情况下，利用随机森林的结果来改善分类是有意义的。因此，根据数据的数量，随机森林特征或 CNN 特征可以互相补充。
- en: '![Refer to caption](img/129ebd81f2a9d23eac762b1f11226f12.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/129ebd81f2a9d23eac762b1f11226f12.png)'
- en: 'Figure 9: ROC curve which plots the precision of the classifier against the
    recall. The performance of the CNN classifier is represented by black dots, those
    of the random forest by red plus and the performance of the combination of the
    two classifiers is represented by green crosses.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：ROC 曲线绘制了分类器的精度与召回率的关系。CNN 分类器的性能由黑点表示，随机森林的性能由红色加号表示，而两个分类器组合的性能由绿色交叉表示。
- en: 6 Photometric redshifts of quasars
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 个类星体的光度红移
- en: Photometric redshifts are a way to determine the redshift of an object by using
    only the apparent magnitudes through different filters, or photometric images.
    They constitute a powerful technique because they allow us to be free of spectroscopy
    data which are limited by the brightness of the source and by the cost of instruments.
    This methodology has been developed by Baum (Baum ([1962](#bib.bib2))) by observing
    the Spectral Energy Distribution (SED) of six elliptic galaxies in the Virgo cluster
    in nine bands from 3730Å to 9875Å. The approach using template-fitting models
    which extracts features from celestial observational information and then matches
    them with the designed templates constructed by theoretical models or real observations
    has been used intensively (e.g. Bolzonella et al. ([2000](#bib.bib5)), Coupon
    et al. ([2009](#bib.bib8)) Ilbert et al. ([2010](#bib.bib22))). However the accuracy
    of the method strongly depends on simulated or real data. Moreover, the emergence
    of massive photometric data obtained by multiple large-scale sky surveys suggests
    the need of an automatic method such as machine learning algorithms. Several methods
    were used to estimate photometric redshifts of galaxies or quasars like a K-nearest
    neighbors (e.g. Zhang et al. ([2013](#bib.bib52)), Kügler et al. ([2015](#bib.bib28))),
    an artificial neural network (e.g. Firth et al. ([2003](#bib.bib14)), Collister
    & Lahav ([2004](#bib.bib6)), Blake et al. ([2007](#bib.bib3)), Oyaizu et al. ([2008](#bib.bib35)),
    Yèche et al. ([2010](#bib.bib49)), Zhang et al. ([2009](#bib.bib51))), both a
    K-nearest neighbors and a support vector machine (Han et al. ([2016](#bib.bib17))).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 光度红移是一种通过仅使用不同滤光片或光度图像中的视星等确定物体红移的方法。它们是一种强大的技术，因为它们可以不依赖受限于源的亮度和仪器成本的光谱学数据。这种方法由
    Baum（Baum ([1962](#bib.bib2)）提出，通过观察维尔戈星系团中六个椭圆星系在3730Å到9875Å的九个频段的光谱能量分布（SED）。使用模板拟合模型的方法提取天文观测信息的特征，然后将其与由理论模型或真实观测构建的设计模板进行匹配已经得到广泛应用（例如
    Bolzonella et al. ([2000](#bib.bib5)), Coupon et al. ([2009](#bib.bib8)) Ilbert
    et al. ([2010](#bib.bib22))）。然而，该方法的准确性在很大程度上取决于模拟数据或真实数据。此外，多个大规模天空调查获得的大规模光度数据的出现表明需要自动方法，如机器学习算法。已经使用了几种方法来估计星系或类星体的光度红移，例如K最近邻方法（例如
    Zhang et al. ([2013](#bib.bib52)), Kügler et al. ([2015](#bib.bib28))），人工神经网络方法（例如
    Firth et al. ([2003](#bib.bib14)), Collister & Lahav ([2004](#bib.bib6)), Blake
    et al. ([2007](#bib.bib3)), Oyaizu et al. ([2008](#bib.bib35)), Yèche et al. ([2010](#bib.bib49)),
    Zhang et al. ([2009](#bib.bib51))），以及同时使用K最近邻和支持向量机的方法（Han et al. ([2016](#bib.bib17)))。
- en: We propose to predict the photometric redshifts of quasars with a CNN. For that,
    we use 80% of the quasar light curves for the training database and 20% for the
    testing database. To reduce the variability we cross validate the experiment and
    only show the mean of the results. The distribution of known spectroscopy redshifts
    are sliced in 60 bins of 0.04 in width. We used a network with a similar architecture
    that is represented in Figure [4](#S4.F4 "Figure 4 ‣ 4 Our CNN architecture ‣
    Deep learning Approach for Classifying, Detecting and Predicting Photometric Redshifts
    of Quasars in the Sloan Digital Sky Survey Stripe 82"). The softmax gives the
    probability of belonging to each redshifts class. To predict the final regression
    value, results of each class are added by weighting them by the probability given
    by the Softmax. Again, the network takes the LCI as input (see Section [3.1](#S3.SS1
    "3.1 Light Curve Images ‣ 3 The Convolutional Neural Network ‣ Deep learning Approach
    for Classifying, Detecting and Predicting Photometric Redshifts of Quasars in
    the Sloan Digital Sky Survey Stripe 82")) so as to include the information of
    the variability of objects in the estimation of redshifts.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出使用卷积神经网络来预测类星体的光度红移。为此，我们将80%的类星体光变曲线用于训练数据库，将20%用于测试数据库。为了减少变异性，我们进行交叉验证实验，仅展示结果的均值。已知光谱红移的分布被切分成60个0.04宽度的bin。我们使用了一个类似的网络架构，如图[4](#S4.F4
    "图4 ‣ 4我们的CNN架构 ‣ 用于分类、检测和预测斯隆数字天空调查Stripe 82中类星体光度红移的深度学习方法")所示。Softmax给出了属于每个红移类别的概率。为了预测最终的回归值，通过使用Softmax给出的概率对每个类别的结果进行加权求和。同样，网络以LCI作为输入（参见第[3.1](#S3.SS1
    "3.1光曲线图像 ‣ 3卷积神经网络 ‣ 用于分类、检测和预测斯隆数字天空调查Stripe 82中类星体光度红移的深度学习方法")节），以便在估计红移时包含物体变异性的信息。
- en: To evaluate the proposed method, we compare it with a more classical approach
    using an extraction of features. For that, we compared the performances of four
    classifiers namely a K-nearest neighbors (KNN), a support vector machine (SVM,
    with linear and Gaussian kernels), a random forest (RF) and a Gaussian process
    classifier.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估提出的方法，我们将其与使用特征提取的经典方法进行比较。为此，我们比较了四种分类器的性能，即K-最近邻（KNN）、支持向量机（SVM，具有线性和高斯核）、随机森林（RF）和高斯过程分类器。
- en: '| Feature | Absolute error | $\chi^{2}$ | best K |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 特征 | 绝对误差 | $\chi^{2}$ | 最佳K |'
- en: '| --- | --- | --- | --- |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Mean | 0.282 | 0.239 | 2 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 0.282 | 0.239 | 2 |'
- en: '| Mean+error | 0.283 | 0.240 | 2 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 平均值+误差 | 0.283 | 0.240 | 2 |'
- en: '| Mean+color+error | 0.263 | 0.199 | 3 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 平均值+颜色+误差 | 0.263 | 0.199 | 3 |'
- en: '| Mean+color amplitudes+error | 0.253 | 0.182 | 4 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 平均值+颜色幅度+误差 | 0.253 | 0.182 | 4 |'
- en: '|  |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| color+error | 0.226 | 0.163 | 4 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 颜色+误差 | 0.226 | 0.163 | 4 |'
- en: '| color | 0.226 | 0.156 | 6 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 颜色 | 0.226 | 0.156 | 6 |'
- en: 'Table 1: Evaluation of the K-Nearest Neighbors classifier efficiency using
    different features based on the absolute error and the error given by a $\chi^{2}$
    test. K is the number of neighbors taking into account by the KNN algorithm.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：使用不同特征评估K-最近邻分类器的效率，基于绝对误差和$\chi^{2}$测试给出的误差。K是KNN算法中考虑的邻居数量。
- en: For each of these classifiers, we used the best combination of features among
    the mean of magnitudes, the magnitude errors, the amplitude of magnitudes, the
    colors and all characteristics included in the python library FATS. In the evaluation,
    the best results are obtained by using a KNN and only the color as a characteristic.
    Indeed as we can see in Table [1](#S6.T1 "Table 1 ‣ 6 Photometric redshifts of
    quasars ‣ Deep learning Approach for Classifying, Detecting and Predicting Photometric
    Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82") a learning phase
    with only the color as a feature shows the lower absolute error of 0.226 and the
    lower residual of the $\chi^{2}$ test with a value of 0.156\. In this case, the
    number of neighbors taking into account, indicated by the number K in the Table
    [1](#S6.T1 "Table 1 ‣ 6 Photometric redshifts of quasars ‣ Deep learning Approach
    for Classifying, Detecting and Predicting Photometric Redshifts of Quasars in
    the Sloan Digital Sky Survey Stripe 82"), is equal to 6\. Thus we use the performance
    of the KNN by extracting only the color to be compared to the performance of the
    CNN (see Table [1](#S6.T1 "Table 1 ‣ 6 Photometric redshifts of quasars ‣ Deep
    learning Approach for Classifying, Detecting and Predicting Photometric Redshifts
    of Quasars in the Sloan Digital Sky Survey Stripe 82")).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些分类器，我们使用了特征的最佳组合，包括幅度均值、幅度误差、幅度幅度、颜色以及所有包含在Python库FATS中的特征。在评估中，使用KNN且仅以颜色作为特征可以获得最佳结果。实际上，如表[1](#S6.T1
    "Table 1 ‣ 6 Photometric redshifts of quasars ‣ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82")所示，只有颜色作为特征的学习阶段显示了最低的绝对误差0.226和$\chi^{2}$测试的最低残差值0.156。在这种情况下，表[1](#S6.T1
    "Table 1 ‣ 6 Photometric redshifts of quasars ‣ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82")中的K值等于6。因此，我们使用KNN提取的颜色性能与CNN的性能进行比较（参见表[1](#S6.T1 "Table
    1 ‣ 6 Photometric redshifts of quasars ‣ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82")）。
- en: '|  | $&#124;\Delta z&#124;<0.1$ (%) | $&#124;\Delta z&#124;<0.2$ (%) | $&#124;\Delta
    z&#124;<0.3$ (%) | RMS |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|  | $&#124;\Delta z&#124;<0.1$ (%) | $&#124;\Delta z&#124;<0.2$ (%) | $&#124;\Delta
    z&#124;<0.3$ (%) | RMS |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| CNN | 79.32 | 86.64 | 91.69 | 0.352 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 79.32 | 86.64 | 91.69 | 0.352 |'
- en: '| KNN | 73.72 | 82.46 | 90.09 | 0.395 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| KNN | 73.72 | 82.46 | 90.09 | 0.395 |'
- en: '| KNN+CNN | 80.43 | 87.07 | 91.75 | 0.349 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| KNN+CNN | 80.43 | 87.07 | 91.75 | 0.349 |'
- en: 'Table 2: Comparisons of the accuracy and the dispersion obtained with the CNN,
    the KNN and the merge of the KNN and the CNN, by computing the percentages in
    different $|\Delta z|$ ranges and the Root Mean Square (RMS).'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：通过计算不同$|\Delta z|$范围内的百分比和均方根（RMS），比较CNN、KNN以及KNN和CNN的合并的准确性和离散度。
- en: '![Refer to caption](img/50f0dab990e63319f2d216af2eceab30.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/50f0dab990e63319f2d216af2eceab30.png)'
- en: 'Figure 10: Panels A and B compare the photometric redshifts predicted by the
    KNN and the CNN respectively against the spectroscopic redshifts. The color indicates
    the density of quasars in percentages. Redder the color, higher the density of
    quasars is. The line $y=x$ is red which means that the density of quasars is the
    highest and so the two methods well estimate most of the photometric redshifts
    compared to spectroscopic redshifts. Panel C is the difference in percentages
    between the density of quasars given by the CNN and the density of quasars obtained
    by the KNN, noted $\Delta d$. In other words, when $\Delta d$ is positive (resp.
    negative), the color is red (resp. blue), and it means that the density of quasars
    given by the CNN (resp. KNN) is higher than those obtained by the KNN (resp. CNN).'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：面板A和B分别比较了KNN和CNN预测的光度红移与光谱红移。颜色表示类星体的密度百分比。颜色越红，类星体的密度越高。线$y=x$是红色的，意味着类星体的密度最高，因此这两种方法对大多数光度红移的估计都较好。面板C是CNN给出的类星体密度与KNN获得的类星体密度之间的百分比差异，记作$\Delta
    d$。换句话说，当$\Delta d$为正（或负）时，颜色为红色（或蓝色），这意味着CNN（或KNN）给出的类星体密度高于KNN（或CNN）获得的密度。
- en: Figure [10](#S6.F10 "Figure 10 ‣ 6 Photometric redshifts of quasars ‣ Deep learning
    Approach for Classifying, Detecting and Predicting Photometric Redshifts of Quasars
    in the Sloan Digital Sky Survey Stripe 82") compares photometric redshifts predicted
    by the KNN (panel A) and the CNN (panel B) against the spectroscopic redshifts
    of around 9000 quasars. The color indicates the density of quasars in percentages.
    We note $d_{CNN}$ and $d_{KNN}$ the density of quasars in percentages given by
    the CNN and the KNN approaches respectively. Redder the color, higher the density
    of quasars is. For the two methods, the density of quasars is the highest on the
    line y=x, showing that the most of photometric redshifts are well estimated by
    the two classifiers. We remark that the density is the highest for redshifts below
    2.5, since the database contains a small number of high redshifts, less than 10$\%$
    which is then divided between the training and the testing databases.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图[10](#S6.F10 "图 10 ‣ 6 类星体的光度红移 ‣ 用于分类、检测和预测斯隆数字天空调查条纹82中类星体的光度红移的深度学习方法")对比了KNN（面板A）和CNN（面板B）预测的光度红移与约9000个类星体的光谱红移。颜色表示类星体的密度百分比。我们用$d_{CNN}$和$d_{KNN}$表示CNN和KNN方法给出的类星体密度百分比。颜色越红，类星体的密度越高。对于这两种方法，类星体的密度在y=x线上的值最高，显示出这两种分类器对大多数光度红移的估计都很好。我们注意到在红移小于2.5时密度最高，因为数据库中包含的高红移数量较少，不到10$\%$，这些数据在训练和测试数据库中有所划分。
- en: Panel C in Figure [10](#S6.F10 "Figure 10 ‣ 6 Photometric redshifts of quasars
    ‣ Deep learning Approach for Classifying, Detecting and Predicting Photometric
    Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82") compares the
    two approaches in the estimation of the photometric redshifts since it represents
    the difference between the density in percentages, $d_{CNN}$ and $d_{KNN}$ noted
    $\Delta d$. When the value of $\Delta d$ is positive (positive values are represented
    by the red color on the plot), the density of quasars given by the CNN is higher
    than those obtained by the KNN. Contrariwise when the value of $\Delta d$ is negative
    (negative values are represented by the blue color on the plot) the density of
    quasars given by the KNN is higher than those given by the CNN. We can see that
    the line $y=x$ appears in red color, so the values of $\Delta d$ are positives
    showing that the density of quasars obtained by the CNN is higher than those given
    by the KNN and so that the CNN better predicts redshifts equals to spectroscopic
    redshifts than the KNN. On the contrary, the regions around the line $y=x$ are
    in blue meaning that the KNN has a higher error rate than the CNN and predict
    more catastrophic redshifts.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [10](#S6.F10 "图 10 ‣ 6 类星体的光度红移 ‣ 深度学习方法用于分类、检测和预测Sloan数字天空巡天带82中的光度红移的方法")
    中的面板C比较了两种方法在光度红移估计中的差异，因为它表示了百分比密度差异，$d_{CNN}$ 和 $d_{KNN}$ 记为 $\Delta d$。当 $\Delta
    d$ 的值为正（在图中以红色表示），CNN给出的类星体密度高于KNN。相反，当 $\Delta d$ 的值为负（在图中以蓝色表示），KNN给出的类星体密度高于CNN。我们可以看到直线
    $y=x$ 以红色显示，因此 $\Delta d$ 的值为正，显示CNN比KNN更好地预测等于光谱红移的红移。相反，围绕直线 $y=x$ 的区域为蓝色，意味着KNN比CNN有更高的误差率，并且预测了更多的灾难性红移。
- en: The better accuracy of the CNN is also visible if we compare the distribution
    of the absolute error in the estimation of photometric redshifts of the two methods
    (see Figure [11](#S6.F11 "Figure 11 ‣ 6 Photometric redshifts of quasars ‣ Deep
    learning Approach for Classifying, Detecting and Predicting Photometric Redshifts
    of Quasars in the Sloan Digital Sky Survey Stripe 82")). Indeed we can see that
    the histogram is narrower for the estimations of photometric redshifts made by
    the CNN (red histogram) than those made by the KNN (blue histogram). In addition
    the percentage of redshift estimations with an absolute error higher than 0.1,
    0.2 and 0.3 are respectively of 38.03%, 24.06% and 19.07% for the CNN; for the
    KNN they are of 45.78%, 30.04% and 22.89%. Thus the number of catastrophic photometric
    redshifts is significantly reduced with the CNN.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们比较两种方法在光度红移估计中绝对误差分布的话，CNN的更好精度也是显而易见的（见图 [11](#S6.F11 "图 11 ‣ 6 类星体的光度红移
    ‣ 深度学习方法用于分类、检测和预测Sloan数字天空巡天带82中的光度红移的方法")）。事实上，我们可以看到CNN进行的光度红移估计的直方图（红色直方图）比KNN（蓝色直方图）更窄。此外，对于绝对误差大于0.1、0.2和0.3的红移估计百分比分别为38.03%、24.06%和19.07%（CNN），而对于KNN则分别为45.78%、30.04%和22.89%。因此，使用CNN可以显著减少灾难性光度红移的数量。
- en: '![Refer to caption](img/a876c28d9da740e831f93e7c4fa5b40c.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a876c28d9da740e831f93e7c4fa5b40c.png)'
- en: 'Figure 11: The blue and red histograms represent the distribution of the absolute
    error for the estimation of photometric redshifts by using a KNN and a CNN classifiers
    respectively. The number of catastrophic redshifts is reduced with the CNN as
    the percentage of redshift estimation with an absolute error higher than 0.1 is
    about 45.78% for the KNN and 38.03% for the CNN.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：蓝色和红色的直方图分别代表了使用KNN和CNN分类器进行光度红移估计的绝对误差分布。随着CNN的使用，灾难性红移的数量减少，因为绝对误差大于0.1的红移估计百分比约为45.78%（KNN）和38.03%（CNN）。
- en: 'We also define two quantities frequently used to evaluate accuracy and dispersion
    of the used method that are the percentages in different $|\Delta z|$ ranges defined
    as:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还定义了两个用于评估所使用方法精度和离散度的经常使用的量，即在不同 $|\Delta z|$ 范围内的百分比，定义为：
- en: '|  | $\Delta z=\frac{z_{spec}-z_{phot}}{1+z_{spec}}$ |  | (2) |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|  | $\Delta z=\frac{z_{spec}-z_{phot}}{1+z_{spec}}$ |  | (2) |'
- en: and the Root Mean Square (RMS) of $|\Delta z|$ to test our redshifts prediction
    approach. The better accuracy of the CNN is confirmed (see Table [2](#S6.T2 "Table
    2 ‣ 6 Photometric redshifts of quasars ‣ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82")) since the proportions of $|\Delta z|$ are equals to 78.09$\%$,
    86.15$\%$, 91.2$\%$ for the CNN, against 73.72$\%$, 82.46$\%$, 90.09$\%$ for the
    KNN. This means that more photometric redshifts are estimated with a low error
    by the CNN than the KNN. In addition, the dispersion of photometric redshifts
    is also lower with the CNN, since the RMS is 0.352 for the CNN against 0.395 for
    the KNN.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 以及根均方差（RMS）$|\Delta z|$用于测试我们的红移预测方法。CNN的准确性得到了确认（见表[2](#S6.T2 "表 2 ‣ 6 星体的光度红移
    ‣ 深度学习方法用于分类、检测和预测斯隆数字天空调查条纹82中的星体光度红移")），因为CNN的$|\Delta z|$的比例分别为78.09$\%$、86.15$\%$、91.2$\%$，而KNN的比例分别为73.72$\%$、82.46$\%$、90.09$\%$。这意味着CNN对更多光度红移的低误差估计优于KNN。此外，CNN的光度红移的离散度也较低，因为CNN的RMS为0.352，而KNN为0.395。
- en: However the CNN has worse performance than the KNN for the prediction of redshifts
    higher than 2.5 (which is visible on Panel C in Figure [10](#S6.F10 "Figure 10
    ‣ 6 Photometric redshifts of quasars ‣ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82")). It is due to the small number of redshifts higher than
    2.5 in the database. There are only 600 quasars with $z_{spec}>2.5$ in the learning
    database and the CNN needs a lot of examples to converge.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，CNN在预测红移高于2.5的情况下表现不如KNN（这在图[10](#S6.F10 "图 10 ‣ 6 星体的光度红移 ‣ 深度学习方法用于分类、检测和预测斯隆数字天空调查条纹82中的星体光度红移")中的C面板中可见）。这是由于数据库中高于2.5的红移数量较少。在学习数据库中，只有600个$z_{spec}>2.5$的类星体，而CNN需要大量示例才能收敛。
- en: 'To solve this problem, after the training of the KNN and the CNN we combine
    these two approaches in a KNN+CNN architecture. The final prediction of the KNN+CNN
    architecture will depend on the redshift predicted by the KNN model. If the KNN
    predicts a redshift higher than 2.5, this prediction is used as the final prediction.
    Otherwise, the prediction given by the CNN is used as the final prediction. We
    note $p_{KNN}$ and $p_{CNN}$ the prediction given by the KNN and the CNN respectively.
    The prediction given by the KNN+CNN architecture, noted $p_{KNN+CNN}$ is defined
    as:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们在KNN和CNN的训练后将这两种方法结合在一个KNN+CNN架构中。KNN+CNN架构的最终预测将取决于KNN模型预测的红移。如果KNN预测的红移高于2.5，则该预测值作为最终预测值。否则，CNN给出的预测值将作为最终预测值。我们用$p_{KNN}$和$p_{CNN}$分别表示KNN和CNN给出的预测值。KNN+CNN架构给出的预测值，记作$p_{KNN+CNN}$，定义如下：
- en: '|  | <math   alttext="p_{KNN+CNN}=\begin{cases}p_{KNN}&amp;\textrm{if
    }p_{KNN}>2.5\\ p_{CNN}&amp;\textrm{Otherwise}\\'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="p_{KNN+CNN}=\begin{cases}p_{KNN}&amp;\textrm{如果
    }p_{KNN}>2.5\\ p_{CNN}&amp;\textrm{否则}\\'
- en: \end{cases}" display="block"><semantics ><mrow 
    ><msub  ><mi
     >p</mi><mrow 
    ><mrow  ><mi
     >K</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi
     >N</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi
     >N</mi></mrow><mo 
    >+</mo><mrow  ><mi
     >C</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi
     >N</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi
     >N</mi></mrow></mrow></msub><mo
     >=</mo><mrow  ><mo
     >{</mo><mtable columnspacing="5pt"
    displaystyle="true" rowspacing="0pt"  ><mtr
     ><mtd 
    columnalign="left"  ><msub 
    ><mi  >p</mi><mrow
     ><mi 
    >K</mi><mo lspace="0em" rspace="0em" 
    >​</mo><mi  >N</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi
     >N</mi></mrow></msub></mtd><mtd
     columnalign="left"  ><mrow
     ><mrow 
    ><mtext  >if </mtext><mo
    lspace="0em" rspace="0em"  >​</mo><msub
     ><mi 
    >p</mi><mrow 
    ><mi  >K</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi
     >N</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi
     >N</mi></mrow></msub></mrow><mo
     >></mo><mn 
    >2.5</mn></mrow></mtd></mtr><mtr 
    ><mtd  columnalign="left" 
    ><msub  ><mi
     >p</mi><mrow 
    ><mi  >C</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi
     >N</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi
     >N</mi></mrow></msub></mtd><mtd
     columnalign="left"  ><mtext
     >Otherwise</mtext></mtd></mtr></mtable></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><apply
     ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci  >𝑝</ci><apply
     ><apply 
    ><ci  >𝐾</ci><ci
     >𝑁</ci><ci 
    >𝑁</ci></apply><apply 
    ><ci  >𝐶</ci><ci
     >𝑁</ci><ci 
    >𝑁</ci></apply></apply></apply><apply 
    ><csymbol cd="latexml"  >cases</csymbol><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><ci
     >𝑝</ci><apply 
    ><ci  >𝐾</ci><ci
     >𝑁</ci><ci 
    >𝑁</ci></apply></apply><apply 
    ><apply  ><ci
     ><mtext 
    >if </mtext></ci><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑝</ci><apply 
    ><ci  >𝐾</ci><ci
     >𝑁</ci><ci
     >𝑁</ci></apply></apply></apply><cn
    type="float"  >2.5</cn></apply><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><ci
     >𝑝</ci><apply 
    ><ci  >𝐶</ci><ci
     >𝑁</ci><ci 
    >𝑁</ci></apply></apply><ci 
    ><mtext  >Otherwise</mtext></ci></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >p_{KNN+CNN}=\begin{cases}p_{KNN}&\textrm{if
    }p_{KNN}>2.5\\ p_{CNN}&\textrm{Otherwise}\\ \end{cases}</annotation></semantics></math>
    |  | (3) |
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`p_{KNN+CNN}=\begin{cases}p_{KNN}&\textrm{如果 }p_{KNN}>2.5\\ p_{CNN}&\textrm{否则}\\
    \end{cases}`'
- en: So, when the CNN does not have enough examples to learn a robust model, i.e
    for the high redshift estimations, the KNN model is used.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当CNN没有足够的例子来学习一个稳健的模型时，即用于高红移估计，KNN模型会被使用。
- en: The performance given by the KNN+CNN architecture is a very interesting results
    as shown in Table [2](#S6.T2 "Table 2 ‣ 6 Photometric redshifts of quasars ‣ Deep
    learning Approach for Classifying, Detecting and Predicting Photometric Redshifts
    of Quasars in the Sloan Digital Sky Survey Stripe 82"). Indeed, the combination
    of the two classifiers reduces the number of catastrophic redshifts and the dispersion,
    since the proportions of $|\Delta z|$ are now equal to 80.43$\%$, 87.07$\%$, 91.75$\%$
    and the value of RMS is 0.349.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: KNN+CNN架构所给出的性能是非常有趣的结果，如表[2](#S6.T2 "Table 2 ‣ 6 Photometric redshifts of quasars
    ‣ Deep learning Approach for Classifying, Detecting and Predicting Photometric
    Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82")所示。确实，两种分类器的结合减少了灾难性红移和离散度，因为$|\Delta
    z|$的比例现在分别为80.43$\%$，87.07$\%$，91.75$\%$，而RMS值为0.349。
- en: 7 Conclusions
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: First, we have presented an original method based on a convolution neural network
    to classify and identify quasars in Stripe 82\. The network takes the Light Curve
    Images as input which are built from light curves of each object in the five ugriz
    filters, so as to include both the crucial information of the variabiliy and the
    colors in the learning of the network. The CNN classifier presents good results
    for the classification of quasars with a precision of 0.988 at a fixed recall
    of 0.90\. For the same recall, the precision given by a random forest (RF) is
    0.985\. The very promising result is obtained by the combination of the CNN and
    the RF giving precisions of 0.99 for a recall of 0.90.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们提出了一种基于卷积神经网络的原创方法来分类和识别Stripe 82中的类星体。该网络以光曲线图像作为输入，这些图像是由五个 ugriz 过滤器中的每个对象的光曲线构建的，以便在网络的学习中包含变异性和颜色的关键信息。CNN
    分类器在类星体分类方面表现良好，在固定召回率为0.90的情况下，精确度为0.988。对于相同的召回率，随机森林（RF）提供的精确度为0.985。通过结合CNN和RF，获得了非常有前景的结果，在召回率为0.90时精确度为0.99。
- en: Then, during the testing phase 175 new quasar candidates were detected by the
    CNN, with a fixed recall of 0.97\. They are uniformly spatially distributed and
    they validate the tendency ”bluer when brighter”.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在测试阶段，CNN检测到了175个新的类星体候选者，固定召回率为0.97。这些候选者均匀地空间分布，并验证了“更亮时更蓝”的趋势。
- en: Finally, we have used a CNN to predict the photometric redshifts of quasars.
    The performance of the CNN is higher than that of the KNN at redshifts below 2.5
    with the best parameters determined experimentally. Indeed, the proportions of
    $|\Delta z|$ and rms error of predicted photometry redshifts are 78.09$\%$, 86.15$\%$,
    91.2$\%$ and 0.359 for the CNN; for the KNN they are 73.72$\%$, 82.46$\%$, 90.09$\%$
    and 0.395. The number of catastrophic redshift is also reduced by using a CNN,
    since the number of photometric redshifts with an absolute error higher than 0.1
    is about 38.03$\%$ for the CNN against 45.78$\%$ for the KNN. Moreover the combination
    of a CNN and a KNN is a very promising method which better estimates redshifts
    higher than 2.5 and reduces the dispersion and the number of catastrophic redshifts.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用CNN来预测类星体的光度红移。CNN的性能高于KNN，在红移低于2.5时，最佳参数通过实验确定。确实，CNN的$|\Delta z|$比例和预测光度红移的RMS误差分别为78.09$\%$，86.15$\%$，91.2$\%$和0.359；而KNN的分别为73.72$\%$，82.46$\%$，90.09$\%$和0.395。使用CNN也减少了灾难性红移的数量，因为CNN的绝对误差大于0.1的光度红移数量约为38.03$\%$，而KNN为45.78$\%$。此外，CNN与KNN的结合是一种非常有前景的方法，可以更好地估计高于2.5的红移，减少离散度和灾难性红移的数量。
- en: Several improvements can be made for further studies. The most trivial is to
    use another catalog with a larger amount of data, because Deep Learning usually
    shows better results when there is more information. The second improvement consists
    of not dividing by averaging observations taken on two consecutive days, during
    the creation of the LCI. Indeed it is an approximation needed to reduce the computational
    cost, but it could be interesting to evaluate its impact on the results. Another
    interesting improvement is to take the errors into account in the learning phase
    which could show important information.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步研究可以做出几项改进。最简单的是使用数据量更大的其他目录，因为深度学习通常在信息更多时显示更好的结果。第二项改进是在创建LCI时不通过平均两天连续观测值来进行，因为这是一种减少计算成本的近似方法，但评估其对结果的影响可能会很有趣。另一个有趣的改进是在学习阶段考虑误差，这可能会提供重要的信息。
- en: In conclusion we wish to emphasis that the development of a method able to estimate
    well the photometric redshifts using only photometric information is essential
    for the future of big databases like LSST. Understanding that Deep Learning is
    more and more efficient as the size of the data increases, the future of this
    method is very promising.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们希望强调的是，开发一种仅使用光度信息即可准确估计光度红移的方法，对于像LSST这样的庞大数据库的未来至关重要。理解到深度学习随着数据量的增加变得越来越高效，这种方法的未来非常有前途。
- en: References
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Abazajian et al. (2009) Abazajian, K. N., Adelman-McCarthy, J. K., Agüeros,
    M. A., et al. 2009, ApJS, 182, 543
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abazajian 等（2009）Abazajian, K. N., Adelman-McCarthy, J. K., Agüeros, M. A.,
    等 2009, ApJS, 182, 543
- en: Baum (1962) Baum, W. A. 1962, in IAU Symposium, Vol. 15, Problems of Extra-Galactic
    Research, ed. G. C. McVittie, 390
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baum（1962）Baum, W. A. 1962, 在IAU研讨会，第15卷，外银河研究问题，编辑 G. C. McVittie, 390
- en: Blake et al. (2007) Blake, C., Collister, A., Bridle, S., & Lahav, O. 2007,
    MNRAS, 374, 1527
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blake 等（2007）Blake, C., Collister, A., Bridle, S., & Lahav, O. 2007, MNRAS,
    374, 1527
- en: Blomme et al. (2011) Blomme, J., Sarro, L. M., O’Donovan, F. T., et al. 2011,
    MNRAS, 418, 96
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blomme 等（2011）Blomme, J., Sarro, L. M., O’Donovan, F. T., 等 2011, MNRAS, 418,
    96
- en: Bolzonella et al. (2000) Bolzonella, M., Miralles, J.-M., & Pelló, R. 2000,
    A&A, 363, 476
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bolzonella 等（2000）Bolzonella, M., Miralles, J.-M., & Pelló, R. 2000, A&A, 363,
    476
- en: Collister & Lahav (2004) Collister, A. A. & Lahav, O. 2004, PASP, 116, 345
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Collister & Lahav（2004）Collister, A. A. & Lahav, O. 2004, PASP, 116, 345
- en: Cortes & Vapnik (1995) Cortes, C. & Vapnik, V. 1995, Mach. Learn., 20, 273
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cortes & Vapnik（1995）Cortes, C. & Vapnik, V. 1995, Mach. Learn., 20, 273
- en: Coupon et al. (2009) Coupon, J., Ilbert, O., Kilbinger, M., et al. 2009, A&A,
    500, 981
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Coupon 等（2009）Coupon, J., Ilbert, O., Kilbinger, M., 等 2009, A&A, 500, 981
- en: Cristiani et al. (1997) Cristiani, S., Trentini, S., La Franca, F., & Andreani,
    P. 1997, A&A, 321, 123
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cristiani 等（1997）Cristiani, S., Trentini, S., La Franca, F., & Andreani, P.
    1997, A&A, 321, 123
- en: Croom et al. (2009) Croom, S. M., Richards, G. T., Shanks, T., et al. 2009,
    MNRAS, 392, 19
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Croom 等（2009）Croom, S. M., Richards, G. T., Shanks, T., 等 2009, MNRAS, 392,
    19
- en: Dubath et al. (2011) Dubath, P., Rimoldini, L., Süveges, M., et al. 2011, MNRAS,
    414, 2602
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dubath 等（2011）Dubath, P., Rimoldini, L., Süveges, M., 等 2011, MNRAS, 414, 2602
- en: Duda & Hart (1973) Duda, R. O. & Hart, P. E. 1973, Pattern classification and
    scene analysis, A Wiley-interscience publication (J. Wiley & Sons)
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Duda & Hart（1973）Duda, R. O. & Hart, P. E. 1973, 模式分类与场景分析，Wiley-与科学出版物（J. Wiley
    & Sons）
- en: Eyer & Blake (2005) Eyer, L. & Blake, C. 2005, MNRAS, 358, 30
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eyer & Blake（2005）Eyer, L. & Blake, C. 2005, MNRAS, 358, 30
- en: Firth et al. (2003) Firth, A. E., Lahav, O., & Somerville, R. S. 2003, MNRAS,
    339, 1195
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Firth 等（2003）Firth, A. E., Lahav, O., & Somerville, R. S. 2003, MNRAS, 339,
    1195
- en: Frieman et al. (2008) Frieman, J. A., Bassett, B., Becker, A., et al. 2008,
    AJ, 135, 338
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Frieman 等（2008）Frieman, J. A., Bassett, B., Becker, A., 等 2008, AJ, 135, 338
- en: Giveon et al. (1999) Giveon, U., Maoz, D., Kaspi, S., Netzer, H., & Smith, P. S.
    1999, MNRAS, 306, 637
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Giveon 等（1999）Giveon, U., Maoz, D., Kaspi, S., Netzer, H., & Smith, P. S. 1999,
    MNRAS, 306, 637
- en: Han et al. (2016) Han, B., Ding, H.-P., Zhang, Y.-X., & Zhao, Y.-H. 2016, Research
    in Astronomy and Astrophysics, 16, 074
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等（2016）Han, B., Ding, H.-P., Zhang, Y.-X., & Zhao, Y.-H. 2016, 天文学与天体物理研究，16,
    074
- en: 'He et al. (2015) He, K., Zhang, X., Ren, S., & Sun, J. 2015, in Proceedings
    of the 2015 IEEE International Conference on Computer Vision (ICCV), ICCV ’15
    (Washington, DC, USA: IEEE Computer Society), 1026–1034'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等（2015）He, K., Zhang, X., Ren, S., & Sun, J. 2015, 在2015年IEEE国际计算机视觉大会（ICCV）论文集，ICCV
    ’15（华盛顿特区，美国：IEEE计算机协会），1026–1034
- en: Hernitschek et al. (2016) Hernitschek, N., Schlafly, E. F., Sesar, B., et al.
    2016, ApJ, 817, 73
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hernitschek 等（2016）Hernitschek, N., Schlafly, E. F., Sesar, B., 等 2016, ApJ,
    817, 73
- en: Hopkins et al. (2006) Hopkins, P. F., Hernquist, L., Cox, T. J., et al. 2006,
    ApJS, 163, 1
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hopkins 等 (2006) Hopkins, P. F., Hernquist, L., Cox, T. J., 等. 2006, ApJS, 163,
    1
- en: Huertas-Company et al. (2015) Huertas-Company, M., Gravet, R., Cabrera-Vives,
    G., et al. 2015, ApJS, 221, 8
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huertas-Company 等 (2015) Huertas-Company, M., Gravet, R., Cabrera-Vives, G.,
    等. 2015, ApJS, 221, 8
- en: Ilbert et al. (2010) Ilbert, O., Salvato, M., Le Floc’h, E., et al. 2010, ApJ,
    709, 644
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ilbert 等 (2010) Ilbert, O., Salvato, M., Le Floc’h, E., 等. 2010, ApJ, 709, 644
- en: Ioffe & Szegedy (2015) Ioffe, S. & Szegedy, C. 2015, in Proceedings of the 32nd
    International Conference on Machine Learning (ICML-15), ed. D. Blei & F. Bach
    (JMLR Workshop and Conference Proceedings), 448–456
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ioffe & Szegedy (2015) Ioffe, S. & Szegedy, C. 2015, 见于第32届国际机器学习会议（ICML-15）论文集，由
    D. Blei & F. Bach 编（JMLR Workshop and Conference Proceedings），448–456
- en: Ivezić et al. (2007) Ivezić, Ž., Smith, J. A., Miknaitis, G., et al. 2007, AJ,
    134, 973
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ivezić 等 (2007) Ivezić, Ž., Smith, J. A., Miknaitis, G., 等. 2007, AJ, 134, 973
- en: Jia et al. (2014) Jia, Y., Shelhamer, E., Donahue, J., et al. 2014, arXiv preprint
    arXiv:1408.5093
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jia 等 (2014) Jia, Y., Shelhamer, E., Donahue, J., 等. 2014, arXiv 预印本 arXiv:1408.5093
- en: 'Joly et al. (2016) Joly, A., Goëau, H., Glotin, H., et al. 2016, LifeCLEF 2016:
    Multimedia Life Species Identification Challenges, ed. N. Fuhr, P. Quaresma, T. Gonçalves,
    B. Larsen, K. Balog, C. Macdonald, L. Cappellato, & N. Ferro (Cham: Springer International
    Publishing), 286–310'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Joly 等 (2016) Joly, A., Goëau, H., Glotin, H., 等. 2016, LifeCLEF 2016: 多媒体生命物种识别挑战,
    由 N. Fuhr, P. Quaresma, T. Gonçalves, B. Larsen, K. Balog, C. Macdonald, L. Cappellato,
    & N. Ferro 编（Cham: Springer International Publishing），286–310'
- en: 'Krizhevsky et al. (2012) Krizhevsky, A., Sutskever, I., & Hinton, G. E. 2012,
    in Advances in Neural Information Processing Systems 25: 26th Annual Conference
    on Neural Information Processing Systems 2012\. Proceedings of a meeting held
    December 3-6, 2012, Lake Tahoe, Nevada, United States., 1106–1114'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Krizhevsky 等 (2012) Krizhevsky, A., Sutskever, I., & Hinton, G. E. 2012, 见于《神经信息处理系统进展
    25: 2012年神经信息处理系统年会》. 会议论文集, 2012年12月3-6日, 内华达州湖 Tahoe, 美国, 1106–1114'
- en: Kügler et al. (2015) Kügler, S. D., Polsterer, K., & Hoecker, M. 2015, A&A,
    576, A132
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kügler 等 (2015) Kügler, S. D., Polsterer, K., & Hoecker, M. 2015, A&A, 576,
    A132
- en: Le Guennec et al. (2016) Le Guennec, A., Malinowski, S., & Tavenard, R. 2016,
    in ECML/PKDD Workshop on Advanced Analytics and Learning on Temporal Data, Riva
    Del Garda, Italy
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Le Guennec 等 (2016) Le Guennec, A., Malinowski, S., & Tavenard, R. 2016, 见于
    ECML/PKDD 关于时间数据高级分析和学习的研讨会，意大利 Riva Del Garda
- en: Lopez et al. (2008) Lopez, S., Barrientos, L. F., Lira, P., et al. 2008, ApJ,
    679, 1144
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lopez 等 (2008) Lopez, S., Barrientos, L. F., Lira, P., 等. 2008, ApJ, 679, 1144
- en: LSST Science Collaboration (2009) LSST Science Collaboration. 2009, [arXiv :0912.0201]
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LSST Science Collaboration (2009) LSST Science Collaboration. 2009, [arXiv :0912.0201]
- en: Meusinger et al. (2011) Meusinger, H., Hinze, A., & de Hoon, A. 2011, A&A, 525,
    A37
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meusinger 等 (2011) Meusinger, H., Hinze, A., & de Hoon, A. 2011, A&A, 525, A37
- en: Nair & Hinton (2010) Nair, V. & Hinton, G. E. 2010, in Proceedings of the 27th
    International Conference on Machine Learning (ICML-10), ed. J. Fürnkranz & T. Joachims
    (Omnipress), 807–814
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nair & Hinton (2010) Nair, V. & Hinton, G. E. 2010, 见于第27届国际机器学习会议（ICML-10）论文集，由
    J. Fürnkranz & T. Joachims 编（Omnipress），807–814
- en: Nun et al. (2015) Nun, I., Protopapas, P., Sim, B., et al. 2015 [arXiv:1506.00010]
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nun 等 (2015) Nun, I., Protopapas, P., Sim, B., 等. 2015 [arXiv:1506.00010]
- en: Oyaizu et al. (2008) Oyaizu, H., Lima, M., Cunha, C. E., et al. 2008, ApJ, 674,
    768
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oyaizu 等 (2008) Oyaizu, H., Lima, M., Cunha, C. E., 等. 2008, ApJ, 674, 768
- en: Peng et al. (2012) Peng, N., Zhang, Y., Zhao, Y., & Wu, X.-b. 2012, MNRAS, 425,
    2599
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng 等 (2012) Peng, N., Zhang, Y., Zhao, Y., & Wu, X.-b. 2012, MNRAS, 425, 2599
- en: Peters et al. (2015) Peters, C. M., Richards, G. T., Myers, A. D., et al. 2015,
    ApJ, 811, 95
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peters 等 (2015) Peters, C. M., Richards, G. T., Myers, A. D., 等. 2015, ApJ,
    811, 95
- en: Portinari et al. (2012) Portinari, L., Kotilainen, J., Falomo, R., & Decarli,
    R. 2012, MNRAS, 420, 732
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Portinari 等 (2012) Portinari, L., Kotilainen, J., Falomo, R., & Decarli, R.
    2012, MNRAS, 420, 732
- en: 'Quinlan (1986) Quinlan, J. R. 1986 (Hingham, MA, USA: Kluwer Academic Publishers),
    81–106'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Quinlan (1986) Quinlan, J. R. 1986 (Hingham, MA, 美国: Kluwer Academic Publishers),
    81–106'
- en: Rimoldini et al. (2012) Rimoldini, L., Dubath, P., Süveges, M., et al. 2012,
    MNRAS, 427, 2917
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rimoldini 等 (2012) Rimoldini, L., Dubath, P., Süveges, M., 等. 2012, MNRAS, 427,
    2917
- en: 'Rumelhart et al. (1986) Rumelhart, D. E., Hinton, G. E., & Williams, R. J.
    1986 (Cambridge, MA, USA: MIT Press), 318–362'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rumelhart 等 (1986) Rumelhart, D. E., Hinton, G. E., & Williams, R. J. 1986
    (剑桥, MA, 美国: MIT Press), 318–362'
- en: Russakovsky et al. (2015) Russakovsky, O., Deng, J., Su, H., et al. 2015, International
    Journal of Computer Vision (IJCV), 115, 211
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russakovsky 等 (2015) Russakovsky, O., Deng, J., Su, H., 等. 2015, 国际计算机视觉杂志 (IJCV),
    115, 211
- en: Schneider et al. (2010) Schneider, D. P., Richards, G. T., Hall, P. B., et al.
    2010, AJ, 139, 2360
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schneider 等 (2010) Schneider, D. P., Richards, G. T., Hall, P. B., 等. 2010,
    AJ, 139, 2360
- en: Sesar et al. (2007) Sesar, B., Ivezić, Ž., Lupton, R. H., et al. 2007, AJ, 134,
    2236
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sesar 等（2007）Sesar, B., Ivezić, Ž., Lupton, R. H., 等. 2007, AJ, 134, 2236
- en: Srivastava et al. (2014) Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever,
    I., & Salakhutdinov, R. 2014, Journal of Machine Learning Research, 15, 1929
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Srivastava 等（2014）Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I.,
    & Salakhutdinov, R. 2014, 机器学习研究期刊, 15, 1929
- en: Szegedy et al. (2015) Szegedy, C., Liu, W., Jia, Y., et al. 2015, in 2015 IEEE
    Conference on Computer Vision and Pattern Recognition (CVPR), 1–9
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等（2015）Szegedy, C., Liu, W., Jia, Y., 等. 2015, 在 2015 IEEE 计算机视觉与模式识别大会（CVPR），1–9
- en: The Dark Energy Survey Collaboration (2005) The Dark Energy Survey Collaboration.
    2005, ArXiv Astrophysics e-prints [astro-ph/0510346]
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: The Dark Energy Survey Collaboration（2005）The Dark Energy Survey Collaboration.
    2005, ArXiv Astrophysics e-prints [astro-ph/0510346]
- en: Vanden Berk et al. (2004) Vanden Berk, D. E., Wilhite, B. C., Kron, R. G., et al.
    2004, ApJ, 601, 692
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vanden Berk 等（2004）Vanden Berk, D. E., Wilhite, B. C., Kron, R. G., 等. 2004,
    ApJ, 601, 692
- en: Yèche et al. (2010) Yèche, C., Petitjean, P., Rich, J., et al. 2010, A&A, 523,
    A14
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yèche 等（2010）Yèche, C., Petitjean, P., Rich, J., 等. 2010, A&A, 523, A14
- en: York et al. (2000) York, D. G., Adelman, J., Anderson, Jr., J. E., et al. 2000,
    AJ, 120, 1579
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: York 等（2000）York, D. G., Adelman, J., Anderson, Jr., J. E., 等. 2000, AJ, 120,
    1579
- en: Zhang et al. (2009) Zhang, Y., Li, L., & Zhao, Y. 2009, MNRAS, 392, 233
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等（2009）Zhang, Y., Li, L., & Zhao, Y. 2009, MNRAS, 392, 233
- en: Zhang et al. (2013) Zhang, Y., Ma, H., Peng, N., Zhao, Y., & Wu, X.-b. 2013,
    AJ, 146, 22
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等（2013）Zhang, Y., Ma, H., Peng, N., Zhao, Y., & Wu, X.-b. 2013, AJ, 146,
    22
- en: Appendix A Appendix
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 附录
- en: '| Layers | Inputs | Kernel size | $h\times w$ | #feature maps |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 层 | 输入 | 核大小 | $h\times w$ | #特征图 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| P1, P2 | LCI |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| P1, P2 | LCI |'
- en: '&#124; $5\times 1$, $11\times 1$ &#124;'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; $5\times 1$, $11\times 1$ &#124;'
- en: '&#124; (stride 2) &#124;'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124;（步幅 2）&#124;'
- en: '| $850\times 5$ | 1, 1 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| $850\times 5$ | 1, 1 |'
- en: '| TC1, TC2, TC3 | P1 | $11\times 1$, $21\times 1$, $41\times 1$ | $850\times
    5$ | 16, 16,16 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| TC1, TC2, TC3 | P1 | $11\times 1$, $21\times 1$, $41\times 1$ | $850\times
    5$ | 16, 16,16 |'
- en: '| TC4, TC5, TC6 | P2 | $11\times 1$, $21\times 1$, $41\times 1$ | $850\times
    5$ | 16, 16, 16 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| TC4, TC5, TC6 | P2 | $11\times 1$, $21\times 1$, $41\times 1$ | $850\times
    5$ | 16, 16, 16 |'
- en: '| MC1 | C1 | $1\times 5$ | $850\times 1$ | 96 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| MC1 | C1 | $1\times 5$ | $850\times 1$ | 96 |'
- en: '| TC7, TC8 | MC1 and C1 | $11\times 1$, $21\times 1$ | $850\times 5$ or $850\times
    1$ | 24, 24 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| TC7, TC8 | MC1 和 C1 | $11\times 1$, $21\times 1$ | $850\times 5$ 或 $850\times
    1$ | 24, 24 |'
- en: '| P3 | C2 | $3\times 1$ (stride 2) | $425\times 1$ | 48 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| P3 | C2 | $3\times 1$（步幅 2） | $425\times 1$ | 48 |'
- en: '| P4 | C3 | $3\times 1$ (stride 2) | $425\times 5$ | 48 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| P4 | C3 | $3\times 1$（步幅 2） | $425\times 5$ | 48 |'
- en: '| P5 | LCI | $21\times 1$ (stride 4) | $425\times 5$ | 1 |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| P5 | LCI | $21\times 1$（步幅 4） | $425\times 5$ | 1 |'
- en: '| TC9, TC10, TC11 | P5 | $5\times 1$, $11\times 1$, $21\times 1$ | $425\times
    5$ | 16,16,16 |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| TC9, TC10, TC11 | P5 | $5\times 1$, $11\times 1$, $21\times 1$ | $425\times
    5$ | 16,16,16 |'
- en: '| TC12, TC13 | C4 | $11\times 1$, $21\times 1$ | $425\times 5$ | 24, 24 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| TC12, TC13 | C4 | $11\times 1$, $21\times 1$ | $425\times 5$ | 24, 24 |'
- en: '| MC2 | C5 | $1\times 5$ | $425\times 1$ | 48 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| MC2 | C5 | $1\times 5$ | $425\times 1$ | 48 |'
- en: '| TC14 | C6 and C7 | $11\times 1$ | $425\times 1$ or $425\times 5$ | 96, 96
    |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| TC14 | C6 和 C7 | $11\times 1$ | $425\times 1$ 或 $425\times 5$ | 96, 96 |'
- en: '| P6 | TC14 | $3\times 1$ (stride 2) | $212\times 1$ | 96 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| P6 | TC14 | $3\times 1$（步幅 2） | $212\times 1$ | 96 |'
- en: '| P7 | TC14 | $3\times 1$ (stride 2) | $212\times 5$ | 96 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| P7 | TC14 | $3\times 1$（步幅 2） | $212\times 5$ | 96 |'
- en: '| TC15 | P6 and P7 | $11\times 1$ | $425\times 1$ or $425\times 5$ | 48, 48
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| TC15 | P6 和 P7 | $11\times 1$ | $425\times 1$ 或 $425\times 5$ | 48, 48 |'
- en: '| P8 | TC15 | $3\times 1$ (stride 2) | $106\times 1$ | 48 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| P8 | TC15 | $3\times 1$（步幅 2） | $106\times 1$ | 48 |'
- en: '| P9 | TC15 | $3\times 1$ (stride 2) | $106\times 5$ | 48 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| P9 | TC15 | $3\times 1$（步幅 2） | $106\times 5$ | 48 |'
- en: '| P10 | LCI | $41\times 1$ (stride 16) | $106\times 5$ | 1 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| P10 | LCI | $41\times 1$（步幅 16） | $106\times 5$ | 1 |'
- en: '| TC16, TC17, TC18 | P10 | $5\times 1$, $11\times 1$, $21\times 1$ | $106\times
    5$ | 16, 16, 16 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| TC16, TC17, TC18 | P10 | $5\times 1$, $11\times 1$, $21\times 1$ | $106\times
    5$ | 16, 16, 16 |'
- en: '| TC19 | C8 | $11\times 1$ | $106\times 5$ | 48 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| TC19 | C8 | $11\times 1$ | $106\times 5$ | 48 |'
- en: '| MC3 | TC19 | $1\times 5$ | $106\times 1$ | 48 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| MC3 | TC19 | $1\times 5$ | $106\times 1$ | 48 |'
- en: '| TC20 | C9 and C10 | $11\times 1$ | $106\times 1$ or $106\times 5$ | 128,
    128 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| TC20 | C9 和 C10 | $11\times 1$ | $106\times 1$ 或 $106\times 5$ | 128, 128
    |'
- en: '| P11 | TC20 | $3\times 1$ (stride 2) | $53\times 1$ | 48 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| P11 | TC20 | $3\times 1$（步幅 2） | $53\times 1$ | 48 |'
- en: '| P12 | TC20 | $3\times 1$ (stride 2) | $53\times 5$ | 48 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| P12 | TC20 | $3\times 1$（步幅 2） | $53\times 5$ | 48 |'
- en: '| P13 | LCI | $61\times 1$ (stride 32) | $53\times 5$ | 1 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| P13 | LCI | $61\times 1$（步幅 32） | $53\times 5$ | 1 |'
- en: '| TC21, TC22, TC23 | P13 | $5\times 1$, $11\times 1$, $21\times 1$ | $53\times
    5$ | 16, 16, 16 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| TC21, TC22, TC23 | P13 | $5\times 1$, $11\times 1$, $21\times 1$ | $53\times
    5$ | 16, 16, 16 |'
- en: '| TC24 | C11 | $11\times 1$ | $53\times 5$ | 64 |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| TC24 | C11 | $11\times 1$ | $53\times 5$ | 64 |'
- en: '| TC25, TC26 | C12 | $11\times 1$, $21\times 1$ | $53\times 5$ | 64, 64 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| TC25, TC26 | C12 | $11\times 1$, $21\times 1$ | $53\times 5$ | 64, 64 |'
- en: '| MC4 | C13 | $1\times 5$ | $53\times 1$ | 64 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| MC4 | C13 | $1\times 5$ | $53\times 1$ | 64 |'
- en: '| TC27, TC28, TC29, TC30 | C14 | $5\times 1$, $11\times 1$, $21\times 1$, $41\times
    1$ | $53\times 1$ | 48, 48, 48, 48 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| TC27, TC28, TC29, TC30 | C14 | $5\times 1$, $11\times 1$, $21\times 1$, $41\times
    1$ | $53\times 1$ | 48, 48, 48, 48 |'
- en: '| FC1, FC2 | C15, FC1 | - | - | 1024, 1024 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| FC1, FC2 | C15, FC1 | - | - | 1024, 1024 |'
- en: 'Table A1: Characteristics of each layer of the CNN architecture: the name of
    the layer, the input layer, the size of the convolution kernel (in pixels), the
    size in pixels (height$\times$width) of resulting feature maps and the number
    of resulting feature maps. The concatenation layers are not represented here but
    they are present in Figure [4](#S4.F4 "Figure 4 ‣ 4 Our CNN architecture ‣ Deep
    learning Approach for Classifying, Detecting and Predicting Photometric Redshifts
    of Quasars in the Sloan Digital Sky Survey Stripe 82").'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 表 A1：CNN 架构每层的特征：层的名称、输入层、卷积核的大小（以像素为单位）、结果特征图的大小（高度$\times$宽度）以及结果特征图的数量。这里未表示连接层，但它们在图
    [4](#S4.F4 "Figure 4 ‣ 4 Our CNN architecture ‣ Deep learning Approach for Classifying,
    Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital
    Sky Survey Stripe 82") 中存在。
