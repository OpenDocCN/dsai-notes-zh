- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:04:36'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:04:36
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1909.11573] Deep Learning for Deepfakes Creation and Detection: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1909.11573] 深度学习在深度伪造创建与检测中的应用：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1909.11573](https://ar5iv.labs.arxiv.org/html/1909.11573)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1909.11573](https://ar5iv.labs.arxiv.org/html/1909.11573)
- en: 'Deep Learning for Deepfakes Creation and Detection: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在深度伪造创建与检测中的应用：综述
- en: Thanh Thi Nguyen Quoc Viet Hung Nguyen Dung Tien Nguyen Duc Thanh Nguyen Thien Huynh-The
    Saeid Nahavandi Thanh Tam Nguyen Quoc-Viet Pham Cuong M. Nguyen
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Thanh Thi Nguyen Quoc Viet Hung Nguyen Dung Tien Nguyen Duc Thanh Nguyen Thien
    Huynh-The Saeid Nahavandi Thanh Tam Nguyen Quoc-Viet Pham Cuong M. Nguyen
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep learning has been successfully applied to solve various complex problems
    ranging from big data analytics to computer vision and human-level control. Deep
    learning advances however have also been employed to create software that can
    cause threats to privacy, democracy and national security. One of those deep learning-powered
    applications recently emerged is deepfake. Deepfake algorithms can create fake
    images and videos that humans cannot distinguish them from authentic ones. The
    proposal of technologies that can automatically detect and assess the integrity
    of digital visual media is therefore indispensable. This paper presents a survey
    of algorithms used to create deepfakes and, more importantly, methods proposed
    to detect deepfakes in the literature to date. We present extensive discussions
    on challenges, research trends and directions related to deepfake technologies.
    By reviewing the background of deepfakes and state-of-the-art deepfake detection
    methods, this study provides a comprehensive overview of deepfake techniques and
    facilitates the development of new and more robust methods to deal with the increasingly
    challenging deepfakes.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习已成功应用于解决各种复杂问题，从大数据分析到计算机视觉和人类级控制。然而，深度学习的进展也被用于创建可能威胁隐私、民主和国家安全的软件。其中之一就是深度伪造。深度伪造算法可以创建假图像和视频，人们无法将其与真实的图像区分开。因此，提出能够自动检测和评估数字视觉媒体完整性的技术至关重要。本文综述了用于创建深度伪造的算法，及至今文献中提出的深度伪造检测方法。我们对深度伪造技术相关的挑战、研究趋势和方向进行了广泛讨论。通过回顾深度伪造的背景和最先进的深度伪造检测方法，本研究提供了对深度伪造技术的全面概述，并促进了应对日益复杂的深度伪造问题的新方法的发展。
- en: 'keywords:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: deepfakes , face manipulation , artificial intelligence , deep learning , autoencoders
    , GAN , forensics , survey\affiliation
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: deepfakes，面部操控，人工智能，深度学习，自编码器，生成对抗网络（GAN），取证，调查\affiliation
- en: '[inst1]organization=School of Information Technology, Deakin University,state=Victoria,
    country=Australia'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst1]组织=信息技术学院，迪肯大学，省=维多利亚，国家=澳大利亚'
- en: \affiliation
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: \affiliation
- en: '[inst2]organization=School of Information and Communication Technology, Griffith
    University, state=Queensland, country=Australia'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst2]组织=信息与通信技术学院，格里菲斯大学，省=昆士兰，国家=澳大利亚'
- en: \affiliation
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: \affiliation
- en: '[inst3]organization=ICT Convergence Research Center, Kumoh National Institute
    of Technology, state=Gyeongbuk, country=Republic of Korea'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst3]组织=信息通信技术融合研究中心，金五国立科技大学，省=庆北，国家=韩国'
- en: \affiliation
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: \affiliation
- en: '[inst4]organization=Institute for Intelligent Systems Research and Innovation,
    Deakin University, state=Victoria, country=Australia'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst4]组织=智能系统研究与创新学院，迪肯大学，省=维多利亚，国家=澳大利亚'
- en: \affiliation
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: \affiliation
- en: '[inst5]organization=Faculty of Information Technology, Ho Chi Minh City University
    of Technology (HUTECH), state=Ho Chi Minh City, country=Vietnam'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst5]组织=信息技术学院，胡志明市科技大学（HUTECH），省=胡志明市，国家=越南'
- en: \affiliation
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: \affiliation
- en: '[inst6]organization=Korean Southeast Center for the 4th Industrial Revolution
    Leader Education, Pusan National University, state=Busan, country=Republic of
    Korea'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst6]组织=韩国东南4.0工业革命领导者教育中心，釜山国立大学，省=釜山，国家=韩国'
- en: \affiliation
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: \affiliation
- en: '[inst7]organization=LAMIH UMR CNRS 8201, Universite Polytechnique Hauts-de-France,
    state=Valenciennes, country=France'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst7]组织=LAMIH UMR CNRS 8201，高法兰西理工大学，省=瓦朗谢讷，国家=法国'
- en: 1 Introduction
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: In a narrow definition, deepfakes (stemming from “deep learning” and “fake”)
    are created by techniques that can superimpose face images of a target person
    onto a video of a source person to make a video of the target person doing or
    saying things the source person does. This constitutes a category of deepfakes,
    namely *face-swap*. In a broader definition, deepfakes are artificial intelligence-synthesized
    content that can also fall into two other categories, i.e., *lip-sync* and *puppet-master*.
    Lip-sync deepfakes refer to videos that are modified to make the mouth movements
    consistent with an audio recording. Puppet-master deepfakes include videos of
    a target person (puppet) who is animated following the facial expressions, eye
    and head movements of another person (master) sitting in front of a camera [[1](#bib.bib1)].
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在狭义上，深度伪造（源于“深度学习”和“伪造”）是通过技术创建的，这些技术可以将目标人物的面部图像叠加到源人物的视频上，使目标人物在视频中做或说源人物所做的事。这构成了深度伪造的一类，即*面部替换*。在广义上，深度伪造是人工智能合成的内容，也可以分为另外两类，即*口型同步*和*木偶大师*。口型同步深度伪造指的是修改视频以使口部动作与音频录音一致。木偶大师深度伪造包括目标人物（木偶）的动画视频，该人物根据另一位坐在摄像机前的人的面部表情、眼睛和头部动作进行动画制作[[1](#bib.bib1)]。
- en: While some deepfakes can be created by traditional visual effects or computer-graphics
    approaches, the recent common underlying mechanism for deepfake creation is deep
    learning models such as autoencoders and generative adversarial networks (GANs),
    which have been applied widely in the computer vision domain [[2](#bib.bib2),
    [3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7),
    [8](#bib.bib8)]. These models are used to examine facial expressions and movements
    of a person and synthesize facial images of another person making analogous expressions
    and movements [[9](#bib.bib9)]. Deepfake methods normally require a large amount
    of image and video data to train models to create photo-realistic images and videos.
    As public figures such as celebrities and politicians may have a large number
    of videos and images available online, they are initial targets of deepfakes.
    Deepfakes were used to swap faces of celebrities or politicians to bodies in porn
    images and videos. The first deepfake video emerged in 2017 where face of a celebrity
    was swapped to the face of a porn actor. It is threatening to world security when
    deepfake methods can be employed to create videos of world leaders with fake speeches
    for falsification purposes [[10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12)].
    Deepfakes therefore can be abused to cause political or religion tensions between
    countries, to fool public and affect results in election campaigns, or create
    chaos in financial markets by creating fake news [[13](#bib.bib13), [14](#bib.bib14),
    [15](#bib.bib15)]. It can be even used to generate fake satellite images of the
    Earth to contain objects that do not really exist to confuse military analysts,
    e.g., creating a fake bridge across a river although there is no such a bridge
    in reality. This can mislead a troop who have been guided to cross the bridge
    in a battle [[16](#bib.bib16), [17](#bib.bib17)].
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管一些深度伪造（deepfake）可以通过传统的视觉效果或计算机图形方法创建，但最近用于深度伪造生成的共同基础机制是深度学习模型，如自动编码器和生成对抗网络（GANs），这些模型在计算机视觉领域得到了广泛应用[[2](#bib.bib2)、[3](#bib.bib3)、[4](#bib.bib4)、[5](#bib.bib5)、[6](#bib.bib6)、[7](#bib.bib7)、[8](#bib.bib8)]。这些模型用于检查一个人的面部表情和动作，并合成另一个人具有类似表情和动作的面部图像[[9](#bib.bib9)]。深度伪造方法通常需要大量的图像和视频数据来训练模型，以创建逼真的图像和视频。由于公众人物如名人和政治家的视频和图像数量可能很大，他们成为深度伪造的首要目标。深度伪造被用于将名人或政治家的面部替换到色情图像和视频中的身体上。第一个深度伪造视频出现在2017年，其中名人的面部被替换成色情演员的面部。当深度伪造方法被用于创建世界领导人的虚假演讲视频以进行伪造时，这对全球安全构成威胁[[10](#bib.bib10)、[11](#bib.bib11)、[12](#bib.bib12)]。因此，深度伪造可能被滥用于造成国家间的政治或宗教紧张局势，欺骗公众并影响选举活动的结果，或者通过制造假新闻在金融市场上制造混乱[[13](#bib.bib13)、[14](#bib.bib14)、[15](#bib.bib15)]。它甚至可以用来生成假的地球卫星图像，包含实际上不存在的物体，以混淆军事分析人员，例如，创建一个假桥梁穿越河流，尽管现实中并不存在这样的桥梁。这可能误导被指引去过桥的部队在战斗中[[16](#bib.bib16)、[17](#bib.bib17)]。
- en: As the democratization of creating realistic digital humans has positive implications,
    there is also positive use of deepfakes such as their applications in visual effects,
    digital avatars, snapchat filters, creating voices of those who have lost theirs
    or updating episodes of movies without reshooting them [[18](#bib.bib18)]. Deepfakes
    can have creative or productive impacts in photography, video games, virtual reality,
    movie productions, and entertainment, e.g., realistic video dubbing of foreign
    films, education through the reanimation of historical figures, virtually trying
    on clothes while shopping, and so on [[19](#bib.bib19), [20](#bib.bib20)]. However,
    the number of malicious uses of deepfakes largely dominates that of the positive
    ones. The development of advanced deep neural networks and the availability of
    large amount of data have made the forged images and videos almost indistinguishable
    to humans and even to sophisticated computer algorithms. The process of creating
    those manipulated images and videos is also much simpler today as it needs as
    little as an identity photo or a short video of a target individual. Less and
    less effort is required to produce a stunningly convincing tempered footage. Recent
    advances can even create a deepfake with just a still image [[21](#bib.bib21)].
    Deepfakes therefore can be a threat affecting not only public figures but also
    ordinary people. For example, a voice deepfake was used to scam a CEO out of $243,000
    [[22](#bib.bib22)]. A recent release of a software called DeepNude shows more
    disturbing threats as it can transform a person to a non-consensual porn [[23](#bib.bib23)].
    Likewise, the Chinese app Zao has gone viral lately as less-skilled users can
    swap their faces onto bodies of movie stars and insert themselves into well-known
    movies and TV clips [[24](#bib.bib24)]. These forms of falsification create a
    huge threat to violation of privacy and identity, and affect many aspects of human
    lives.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然创造逼真的数字人类具有积极的意义，但深度伪造也有其积极用途，如在视觉效果、数字头像、Snapchat滤镜中应用，创建失声者的声音或更新电影情节而不需要重新拍摄[[18](#bib.bib18)]。深度伪造在摄影、视频游戏、虚拟现实、电影制作和娱乐领域可能产生创造性或生产性的影响，例如，为外国影片进行逼真的视频配音，通过复活历史人物进行教育，购物时虚拟试衣等[[19](#bib.bib19),
    [20](#bib.bib20)]。然而，恶意使用深度伪造的情况远远超过了积极用途。先进的深度神经网络的发展以及大量数据的可用性使得伪造的图像和视频几乎无法被人类甚至复杂的计算机算法区分。如今，创建这些被操控的图像和视频的过程也变得更加简单，只需要一张身份证照片或一个目标个体的短视频即可。生产令人信服的伪造镜头所需的努力越来越少。最近的技术进展甚至可以仅用一张静态图像创建深度伪造[[21](#bib.bib21)]。因此，深度伪造可能对公众人物和普通人都构成威胁。例如，一种声音深度伪造被用来骗取一位首席执行官243,000美元[[22](#bib.bib22)]。最近发布的DeepNude软件显示了更令人不安的威胁，因为它可以将一个人转换为未经同意的色情内容[[23](#bib.bib23)]。同样，中国应用程序Zao最近也引起了广泛关注，因为技术水平较低的用户可以将自己的面孔换到电影明星的身体上，并将自己插入知名电影和电视片段中[[24](#bib.bib24)]。这些伪造形式对隐私和身份的侵犯构成了巨大的威胁，并影响到人们生活的许多方面。
- en: '![Refer to caption](img/128d6827701974df74f2d217f70fd0ec.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/128d6827701974df74f2d217f70fd0ec.png)'
- en: 'Figure 1: Number of papers related to deepfakes in years from 2016 to 2021,
    obtained from https://app.dimensions.ai at the end of 2021 with the search keyword
    “deepfake” applied to full text of scholarly papers.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：2016年至2021年与深度伪造相关的论文数量，数据来源于 https://app.dimensions.ai ，在2021年底时使用关键词“deepfake”对学术论文全文进行搜索得到的结果。
- en: 'Finding the truth in digital domain therefore has become increasingly critical.
    It is even more challenging when dealing with deepfakes as they are majorly used
    to serve malicious purposes and almost anyone can create deepfakes these days
    using existing deepfake tools. Thus far, there have been numerous methods proposed
    to detect deepfakes [[25](#bib.bib25), [26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28),
    [29](#bib.bib29)]. Most of them are based on deep learning, and thus a battle
    between malicious and positive uses of deep learning methods has been arising.
    To address the threat of face-swapping technology or deepfakes, the United States
    Defense Advanced Research Projects Agency (DARPA) initiated a research scheme
    in media forensics (named Media Forensics or MediFor) to accelerate the development
    of fake digital visual media detection methods [[30](#bib.bib30)]. Recently, Facebook
    Inc. teaming up with Microsoft Corp and the Partnership on AI coalition have launched
    the Deepfake Detection Challenge to catalyse more research and development in
    detecting and preventing deepfakes from being used to mislead viewers [[31](#bib.bib31)].
    Data obtained from https://app.dimensions.ai at the end of 2021 show that the
    number of deepfake papers has increased significantly in recent years (Fig. [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Deep Learning for Deepfakes Creation and Detection:
    A Survey")). Although the obtained numbers of deepfake papers may be lower than
    actual numbers but the research trend of this topic is obviously increasing.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，在数字领域寻找真相变得越来越关键。当面对深度伪造技术时，这一挑战尤为巨大，因为这些技术主要被用于恶意目的，而且如今几乎任何人都可以使用现有的深度伪造工具来创建深度伪造内容。迄今为止，已经提出了许多检测深度伪造的方法[[25](#bib.bib25),
    [26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28), [29](#bib.bib29)]。大多数方法基于深度学习，因此，恶意与积极使用深度学习方法之间的对抗正在上升。为了解决面部交换技术或深度伪造的威胁，美国国防高级研究计划局（DARPA）启动了一个媒体取证研究计划（称为媒体取证或MediFor），以加速假数字视觉媒体检测方法的发展[[30](#bib.bib30)]。最近，Facebook
    Inc. 联手微软公司以及人工智能合作伙伴关系联盟发起了深度伪造检测挑战，以催化更多关于检测和防止深度伪造被用于误导观众的研究与开发[[31](#bib.bib31)]。从
    https://app.dimensions.ai 获得的数据表明，2021年底，深度伪造论文的数量近年来显著增加（图 [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Deep Learning for Deepfakes Creation and Detection: A Survey")）。尽管获得的深度伪造论文数量可能低于实际数量，但这一话题的研究趋势显然在上升。'
- en: 'There have been existing survey papers about creating and detecting deepfakes,
    presented in [[32](#bib.bib32), [20](#bib.bib20), [19](#bib.bib19)]. For example,
    Mirsky and Lee [[19](#bib.bib19)] focused on reenactment approaches (i.e., to
    change a target’s expression, mouth, pose, gaze or body), and replacement approaches
    (i.e., to replace a target’s face by swap or transfer methods). Verdoliva [[20](#bib.bib20)]
    separated detection approaches into conventional methods (e.g., blind methods
    without using any external data for training, one-class sensor-based and model-based
    methods, and supervised methods with handcrafted features) and deep learning-based
    approaches (e.g., CNN models). Tolosana et al. [[32](#bib.bib32)] categorized
    both creation and detection methods based on the way deepfakes are created, including
    entire face synthesis, identity swap, attribute manipulation, and expression swap.
    On the other hand, we carry out the survey with a different perspective and taxonomy.
    We categorize the deepfake detection methods based on the data type, i.e., images
    or videos, as presented in Fig. [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Deep Learning
    for Deepfakes Creation and Detection: A Survey"). With fake image detection methods,
    we focus on the features that are used, i.e., whether they are handcrafted features
    or deep features. With fake video detection methods, two main subcategories are
    identified based on whether the method uses temporal features across frames or
    visual artifacts within a video frame. We also discuss extensively the challenges,
    research trends and directions on deepfake detection and multimedia forensics
    problems.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 已有关于深度伪造创建和检测的综述文献，如[[32](#bib.bib32)、[20](#bib.bib20)、[19](#bib.bib19)]。例如，Mirsky
    和 Lee [[19](#bib.bib19)] 关注了重现方法（即更改目标的表情、嘴巴、姿势、注视或身体）和替换方法（即通过交换或转移方法替换目标的面部）。Verdoliva
    [[20](#bib.bib20)] 将检测方法分为传统方法（例如，不使用任何外部数据进行训练的盲目方法、一类传感器方法和基于模型的方法，以及使用手工特征的监督方法）和基于深度学习的方法（例如，CNN
    模型）。Tolosana 等人 [[32](#bib.bib32)] 根据深度伪造的创建方式对创建和检测方法进行了分类，包括整个面部合成、身份交换、属性操控和表情交换。另一方面，我们从不同的视角和分类法来进行调查。我们根据数据类型，即图像或视频，对深度伪造检测方法进行分类，如图[2](#S1.F2
    "图2 ‣ 1 引言 ‣ 深度学习在深度伪造创建和检测中的应用：综述")所示。对于假图像检测方法，我们关注所使用的特征，即这些特征是手工特征还是深度特征。对于假视频检测方法，根据方法是否使用跨帧的时间特征或视频帧中的视觉伪影，识别出两个主要子类别。我们还广泛讨论了深度伪造检测和多媒体取证问题的挑战、研究趋势和方向。
- en: '![Refer to caption](img/42bdb910e34de12c9daaa0a9c3e53d65.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/42bdb910e34de12c9daaa0a9c3e53d65.png)'
- en: 'Figure 2: Categories of reviewed papers relevant to deepfake detection methods
    where we divide papers into two major groups, i.e., fake image detection and face
    video detection.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：与深度伪造检测方法相关的文献分类，我们将文献分为两个主要类别，即假图像检测和面部视频检测。
- en: 2 Deepfake Creation
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 深度伪造创建
- en: 'Deepfakes have become popular due to the quality of tampered videos and also
    the easy-to-use ability of their applications to a wide range of users with various
    computer skills from professional to novice. These applications are mostly developed
    based on deep learning techniques. Deep learning is well known for its capability
    of representing complex and high-dimensional data. One variant of the deep networks
    with that capability is deep autoencoders, which have been widely applied for
    dimensionality reduction and image compression [[33](#bib.bib33), [34](#bib.bib34),
    [35](#bib.bib35)]. The first attempt of deepfake creation was FakeApp, developed
    by a Reddit user using autoencoder-decoder pairing structure [[36](#bib.bib36),
    [37](#bib.bib37)]. In that method, the autoencoder extracts latent features of
    face images and the decoder is used to reconstruct the face images. To swap faces
    between source images and target images, there is a need of two encoder-decoder
    pairs where each pair is used to train on an image set, and the encoder’s parameters
    are shared between two network pairs. In other words, two pairs have the same
    encoder network. This strategy enables the common encoder to find and learn the
    similarity between two sets of face images, which are relatively unchallenging
    because faces normally have similar features such as eyes, nose, mouth positions.
    Fig. [3](#S2.F3 "Figure 3 ‣ 2 Deepfake Creation ‣ Deep Learning for Deepfakes
    Creation and Detection: A Survey") shows a deepfake creation process where the
    feature set of face A is connected with the decoder B to reconstruct face B from
    the original face A. This approach is applied in several works such as DeepFaceLab
    [[38](#bib.bib38)], DFaker [[39](#bib.bib39)], DeepFake_tf (tensorflow-based deepfakes)
    [[40](#bib.bib40)].'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造因其篡改视频的质量和应用程序的易用性而变得流行，这些应用程序适用于各种计算机技能水平的用户，从专业到新手。这些应用程序主要基于深度学习技术开发。深度学习因其表示复杂和高维数据的能力而闻名。具有这种能力的深度网络的一种变体是深度自编码器，这些自编码器已广泛应用于降维和图像压缩[[33](#bib.bib33),
    [34](#bib.bib34), [35](#bib.bib35)]。深度伪造创建的首次尝试是FakeApp，由一个Reddit用户开发，使用自编码器-解码器配对结构[[36](#bib.bib36),
    [37](#bib.bib37)]。在这种方法中，自编码器提取人脸图像的潜在特征，解码器用于重建人脸图像。为了在源图像和目标图像之间交换人脸，需要两个编码器-解码器对，每对用于训练一个图像集，并且编码器的参数在两个网络对之间共享。换句话说，这两个对具有相同的编码器网络。这种策略使得共同的编码器能够找到并学习两组人脸图像之间的相似性，这些人脸通常具有相似的特征，如眼睛、鼻子、嘴巴位置。图[3](#S2.F3
    "图3 ‣ 2 深度伪造创建 ‣ 深度学习在深度伪造创建和检测中的应用：综述")展示了一个深度伪造创建过程，其中人脸A的特征集与解码器B连接，以从原始人脸A重建人脸B。这种方法应用于多个工作中，如DeepFaceLab[[38](#bib.bib38)]、DFaker[[39](#bib.bib39)]、DeepFake_tf（基于tensorflow的深度伪造）[[40](#bib.bib40)]。
- en: 'Table 1: Summary of notable deepfake tools'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：主要深度伪造工具的总结
- en: '| Tools | Links | Key Features |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 工具 | 链接 | 关键特性 |'
- en: '| Faceswap | https://github.com/deepfakes/faceswap | - Using two encoder-decoder
    pairs. - Parameters of the encoder are shared. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| Faceswap | https://github.com/deepfakes/faceswap | - 使用两个编码器-解码器对。 - 编码器的参数共享。
    |'
- en: '| Faceswap-GAN | https://github.com/shaoanlu/faceswap-GAN | Adversarial loss
    and perceptual loss (VGGface) are added to an auto-encoder architecture. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| Faceswap-GAN | https://github.com/shaoanlu/faceswap-GAN | 在自编码器架构中添加了对抗损失和感知损失（VGGface）。
    |'
- en: '| Few-Shot Face Translation | https://github.com/shaoanlu/fewshot-face-translation-GAN
    | - Use a pre-trained face recognition model to extract latent embeddings for
    GAN processing. - Incorporate semantic priors obtained by modules from FUNIT [[41](#bib.bib41)]
    and SPADE [[42](#bib.bib42)]. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 少量样本人脸翻译 | https://github.com/shaoanlu/fewshot-face-translation-GAN | - 使用预训练的人脸识别模型提取潜在嵌入以进行GAN处理。
    - 结合通过FUNIT[[41](#bib.bib41)]和SPADE[[42](#bib.bib42)]模块获得的语义先验。 |'
- en: '| DeepFaceLab | https://github.com/iperov/DeepFaceLab | - Expand from the Faceswap
    method with new models, e.g. H64, H128, LIAEF128, SAE [[43](#bib.bib43)]. - Support
    multiple face extraction modes, e.g. S3FD, MTCNN, dlib, or manual [[43](#bib.bib43)].
    |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| DeepFaceLab | https://github.com/iperov/DeepFaceLab | - 从Faceswap方法扩展，包含新模型，如H64、H128、LIAEF128、SAE[[43](#bib.bib43)]。
    - 支持多种人脸提取模式，如S3FD、MTCNN、dlib或手动[[43](#bib.bib43)]。 |'
- en: '| DFaker | https://github.com/dfaker/df | - DSSIM loss function [[44](#bib.bib44)]
    is used to reconstruct face. - Implemented based on Keras library. |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| DFaker | https://github.com/dfaker/df | - 使用DSSIM损失函数[[44](#bib.bib44)]重建人脸。
    - 基于Keras库实现。 |'
- en: '| DeepFake_tf | https://github.com/StromWine/DeepFake_tf | Similar to DFaker
    but implemented based on tensorflow. |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| DeepFake_tf | https://github.com/StromWine/DeepFake_tf | 类似于DFaker，但基于tensorflow实现。
    |'
- en: '| AvatarMe | https://github.com/lattas/AvatarMe | - Reconstruct 3D faces from
    arbitrary “in-the-wild” images. - Can reconstruct authentic 4K by 6K-resolution
    3D faces from a single low-resolution image [[45](#bib.bib45)]. |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| AvatarMe | https://github.com/lattas/AvatarMe | - 从任意“野外”图像中重建3D面孔。 - 可以从单张低分辨率图像中重建真实的4K
    x 6K分辨率3D面孔 [[45](#bib.bib45)]。 |'
- en: '| MarioNETte | https://hyperconnect.github.io/MarioNETte | - A few-shot face
    reenactment framework that preserves the target identity. - No additional fine-tuning
    phase is needed for identity adaptation [[46](#bib.bib46)]. |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| MarioNETte | https://hyperconnect.github.io/MarioNETte | - 一种几-shot面部重演框架，保持目标身份。
    - 无需额外的微调阶段来进行身份适配 [[46](#bib.bib46)]。 |'
- en: '| DiscoFaceGAN | https://github.com/microsoft/DiscoFaceGAN | - Generate face
    images of virtual people with independent latent variables of identity, expression,
    pose, and illumination. - Embed 3D priors into adversarial learning [[47](#bib.bib47)].
    |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| DiscoFaceGAN | https://github.com/microsoft/DiscoFaceGAN | - 生成具有独立潜在变量（身份、表情、姿态和光照）的虚拟人物面部图像。
    - 将3D先验嵌入对抗学习中 [[47](#bib.bib47)]。'
- en: '| StyleRig | https://gvv.mpi-inf.mpg.de/projects/StyleRig | - Create portrait
    images of faces with a rig-like control over a pretrained and fixed StyleGAN via
    3D morphable face models. - Self-supervised without manual annotations [[48](#bib.bib48)].
    |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| StyleRig | https://gvv.mpi-inf.mpg.de/projects/StyleRig | - 通过3D可变形面部模型，使用预训练的固定StyleGAN创建面部肖像图像，并进行类似于机架的控制。
    - 无需人工标注，进行自监督 [[48](#bib.bib48)]。 |'
- en: '| FaceShifter | https://lingzhili.com/FaceShifterPage | - Face swapping in
    high-fidelity by exploiting and integrating the target attributes. - Can be applied
    to any new face pairs without requiring subject specific training [[49](#bib.bib49)].
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| FaceShifter | https://lingzhili.com/FaceShifterPage | - 通过利用和整合目标属性进行高保真面孔交换。
    - 可以应用于任何新的面孔对，而无需特定的受试者训练 [[49](#bib.bib49)]。 |'
- en: '| FSGAN | https://github.com/YuvalNirkin/fsgan | - A face swapping and reenactment
    model that can be applied to pairs of faces without requiring training on those
    faces. - Adjust to both pose and expression variations [[50](#bib.bib50)]. |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| FSGAN | https://github.com/YuvalNirkin/fsgan | - 一种面孔交换和重演模型，可以应用于面孔对，而无需对这些面孔进行训练。
    - 调整面孔的姿态和表情变化 [[50](#bib.bib50)]。 |'
- en: '| StyleGAN | https://github.com/NVlabs/stylegan | - A new generator architecture
    for GANs is proposed based on style transfer literature. - The new architecture
    leads to automatic, unsupervised separation of high-level attributes and enables
    intuitive, scale-specific control of the synthesis of images [[51](#bib.bib51)].
    |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| StyleGAN | https://github.com/NVlabs/stylegan | - 基于风格迁移文献提出了一种新的GAN生成器架构。
    - 新架构实现了高层次属性的自动、无监督分离，并支持直观、特定尺度的图像合成控制 [[51](#bib.bib51)]。 |'
- en: '| Face2Face | https://justusthies.github.io/posts/face2face/ | - Real-time
    facial reenactment of monocular target video sequence, e.g. Youtube video. - Animate
    the facial expressions of the target video by a source actor and re-render the
    manipulated output video in a photo-realistic fashion [[52](#bib.bib52)]. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| Face2Face | https://justusthies.github.io/posts/face2face/ | - 实时的单目目标视频序列面部重演，例如YouTube视频。
    - 通过源演员动画化目标视频中的面部表情，并以照片现实的方式重新渲染操作后的视频 [[52](#bib.bib52)]。 |'
- en: '| Neural Textures | https://github.com/SSRSGJYD/NeuralTexture | - Feature maps
    that are learned as part of the scene capture process and stored as maps on top
    of 3D mesh proxies. - Can coherently re-render or manipulate existing video content
    in both static and dynamic environments at real-time rates [[53](#bib.bib53)].
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| Neural Textures | https://github.com/SSRSGJYD/NeuralTexture | - 在场景捕捉过程中作为特征图进行学习，并作为映射存储在3D网格代理上。
    - 能够在静态和动态环境中以实时速率一致地重新渲染或操作现有视频内容 [[53](#bib.bib53)]。 |'
- en: '| Transformable Bottleneck Networks | https://github.com/kyleolsz/TB-Networks
    | - A method for fine-grained 3D manipulation of image content. - Apply spatial
    transformations in CNN models using a transformable bottleneck framework [[54](#bib.bib54)].
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| Transformable Bottleneck Networks | https://github.com/kyleolsz/TB-Networks
    | - 一种图像内容的细粒度3D操作方法。 - 使用可变形瓶颈框架在CNN模型中应用空间变换 [[54](#bib.bib54)]。 |'
- en: '| “Do as I Do” Motion Transfer | github.com/carolineec/EverybodyDanceNow |
    - Automatically transfer the motion from a source to a target person by learning
    a video-to-video translation. - Can create a motion-synchronized dancing video
    with multiple subjects [[55](#bib.bib55)]. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| “Do as I Do” Motion Transfer | github.com/carolineec/EverybodyDanceNow |
    - 通过学习视频到视频的转换自动将动作从源对象转移到目标对象。 - 可以创建多个主体的动作同步舞蹈视频 [[55](#bib.bib55)]。 |'
- en: '| Neural Voice Puppetry | https://justusthies.github.io/posts/neural-voice-puppetry
    | - A method for audio-driven facial video synthesis. - Synthesize videos of a
    talking head from an audio sequence of another person using 3D face representation.
    [[56](#bib.bib56)]. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| Neural Voice Puppetry | https://justusthies.github.io/posts/neural-voice-puppetry
    | - 一种基于音频驱动的面部视频合成方法。 - 使用 3D 面部表示从另一人的音频序列合成说话头的视频。 [[56](#bib.bib56)] |'
- en: '![Refer to caption](img/9907b7e31a2986374bd296789a04f03b.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/9907b7e31a2986374bd296789a04f03b.png)'
- en: 'Figure 3: A deepfake creation model using two encoder-decoder pairs. Two networks
    use the same encoder but different decoders for training process (top). An image
    of face A is encoded with the common encoder and decoded with decoder B to create
    a deepfake (bottom). The reconstructed image (in the bottom) is the face B with
    the mouth shape of face A. Face B originally has the mouth of an upside-down heart
    while the reconstructed face B has the mouth of a conventional heart.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：使用两个编码器-解码器对的 deepfake 创建模型。两个网络使用相同的编码器，但具有不同的解码器进行训练（上图）。面部 A 的图像通过公共编码器编码，并使用解码器
    B 解码以创建 deepfake（下图）。下方的重建图像是面部 B，嘴型是面部 A 的嘴型。面部 B 原本有一个倒心形的嘴，而重建的面部 B 则有一个传统心形的嘴。
- en: By adding adversarial loss and perceptual loss implemented in VGGFace [[57](#bib.bib57)]
    to the encoder-decoder architecture, an improved version of deepfakes based on
    the generative adversarial network [[4](#bib.bib4)], i.e., faceswap-GAN, was proposed
    in [[58](#bib.bib58)]. The VGGFace perceptual loss is added to make eye movements
    to be more realistic and consistent with input faces and help to smooth out artifacts
    in segmentation mask, leading to higher quality output videos. This model facilitates
    the creation of outputs with 64x64, 128x128, and 256x256 resolutions. In addition,
    the multi-task convolutional neural network (CNN) from the FaceNet implementation
    [[59](#bib.bib59)] is used to make face detection more stable and face alignment
    more reliable. The CycleGAN [[60](#bib.bib60)] is utilized for generative network
    implementation in this model.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将对抗损失和在 VGGFace 中实现的感知损失 [[57](#bib.bib57)] 添加到编码器-解码器架构中，提出了一种基于生成对抗网络 [[4](#bib.bib4)]
    的改进版 deepfakes，即 faceswap-GAN [[58](#bib.bib58)]。添加 VGGFace 感知损失使得眼睛运动更加逼真，并与输入面孔一致，同时帮助平滑分割掩模中的伪影，从而提高输出视频的质量。该模型支持创建
    64x64、128x128 和 256x256 分辨率的输出。此外，FaceNet 实现中的多任务卷积神经网络（CNN）[[59](#bib.bib59)]
    被用来提高面部检测的稳定性和面部对齐的可靠性。该模型中使用了 CycleGAN [[60](#bib.bib60)] 进行生成网络的实现。
- en: '![Refer to caption](img/c8adbcfdfc2352a144fc95b8e3d3da64.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/c8adbcfdfc2352a144fc95b8e3d3da64.png)'
- en: 'Figure 4: The GAN architecture consisting of a generator and a discriminator,
    and each can be implemented by a neural network. The entire system can be trained
    with backpropagation that allows both networks to improve their capabilities.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：包括生成器和判别器的 GAN 架构，每个都可以通过神经网络实现。整个系统可以通过反向传播进行训练，使两个网络都能提高其能力。
- en: 'A conventional GAN model comprises two neural networks: a generator and a discriminator
    as depicted in Fig. [4](#S2.F4 "Figure 4 ‣ 2 Deepfake Creation ‣ Deep Learning
    for Deepfakes Creation and Detection: A Survey"). Given a dataset of real images
    $x$ having a distribution of $p_{data}$, the aim of the generator $G$ is to produce
    images $G(z)$ similar to real images $x$ with $z$ being noise signals having a
    distribution of $p_{z}$. The aim of the discriminator $G$ is to correctly classify
    images generated by $G$ and real images $x$. The discriminator $D$ is trained
    to improve its classification capability, i.e., to maximize $D(x)$, which represents
    the probability that $x$ is a real image rather than a fake image generated by
    $G$. On the other hand, $G$ is trained to minimize the probability that its outputs
    are classified by $D$ as synthetic images, i.e., to minimize $1-D(G(z))$. This
    is a minimax game between two players $D$ and $G$ that can be described by the
    following value function [[4](#bib.bib4)]:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '一个传统的 GAN 模型包括两个神经网络：一个生成器和一个判别器，如图 [4](#S2.F4 "Figure 4 ‣ 2 Deepfake Creation
    ‣ Deep Learning for Deepfakes Creation and Detection: A Survey") 所示。给定一个真实图像数据集
    $x$，其分布为 $p_{data}$，生成器 $G$ 的目标是生成与真实图像 $x$ 相似的图像 $G(z)$，其中 $z$ 为具有分布 $p_{z}$
    的噪声信号。判别器 $D$ 的目标是正确区分由 $G$ 生成的图像和真实图像 $x$。判别器 $D$ 被训练以提高其分类能力，即最大化 $D(x)$，这表示
    $x$ 是真实图像而非由 $G$ 生成的假图像的概率。另一方面，$G$ 被训练以最小化其输出被 $D$ 分类为合成图像的概率，即最小化 $1-D(G(z))$。这是两个玩家
    $D$ 和 $G$ 之间的极小极大博弈，可以通过以下价值函数 [[4](#bib.bib4)] 描述：'
- en: '|  | $\min_{G}\max_{D}V(D,G)=\operatorname{\mathbb{E}}_{x\sim p_{data}(x)}[\log
    D(x)]\\ +\operatorname{\mathbb{E}}_{z\sim p_{z}(z)}[\log(1-D(G(z)))]$ |  | (1)
    |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{G}\max_{D}V(D,G)=\operatorname{\mathbb{E}}_{x\sim p_{data}(x)}[\log
    D(x)]\\ +\operatorname{\mathbb{E}}_{z\sim p_{z}(z)}[\log(1-D(G(z)))]$ |  | (1)
    |'
- en: After sufficient training, both networks improve their capabilities, i.e., the
    generator $G$ is able to produce images that are really similar to real images
    while the discriminator $D$ is highly capable of distinguishing fake images from
    real ones.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 经过充分训练后，两种网络都提升了其能力，即生成器$G$能够生成与真实图像非常相似的图像，而鉴别器$D$则能够高度区分虚假图像和真实图像。
- en: 'Table [1](#S2.T1 "Table 1 ‣ 2 Deepfake Creation ‣ Deep Learning for Deepfakes
    Creation and Detection: A Survey") presents a summary of popular deepfake tools
    and their typical features. Among them, a prominent method for face synthesis
    based on a GAN model, namely StyleGAN, was introduced in [[51](#bib.bib51)]. StyleGAN
    is motivated by style transfer [[61](#bib.bib61)] with a special generator network
    architecture that is able to create realistic face images. In a traditional GAN
    model, e.g., the progressive growing of GAN (PGGAN) [[62](#bib.bib62)], the signal
    noise (latent code) is fed to the input layer of a feedforward network that represents
    the generator. In StyleGAN, there are two networks constructed and linked together,
    a mapping network $f$ and a synthesis network $g$. The latent code $z\in Z$ is
    first converted to $w\in W$ (where $W$ is an intermediate latent space) through
    a non-linear function $f:Z\rightarrow W$, which is characterized by a neural network
    (i.e., the mapping network) consisting of several fully connected layers. Using
    an affine tranformation, the intermediate representation $w$ is specialized to
    styles $y=(y_{s},y_{b})$ that will be fed to the adaptive instance normalization
    (AdaIN) operations, specified as:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '表[1](#S2.T1 "Table 1 ‣ 2 Deepfake Creation ‣ Deep Learning for Deepfakes Creation
    and Detection: A Survey")展示了流行的deepfake工具及其典型特性的总结。其中，基于GAN模型的一个突出的人脸合成方法，即StyleGAN，在[[51](#bib.bib51)]中进行了介绍。StyleGAN受风格迁移[[61](#bib.bib61)]的启发，具有特殊的生成器网络架构，能够创建逼真的面部图像。在传统的GAN模型中，例如渐进式GAN（PGGAN）[[62](#bib.bib62)]，信号噪声（潜在代码）被输入到表示生成器的前馈网络的输入层中。在StyleGAN中，构建了两个相互连接的网络，一个是映射网络$f$，另一个是合成网络$g$。潜在代码$z\in
    Z$首先通过非线性函数$f:Z\rightarrow W$转换为$w\in W$（其中$W$是一个中间潜在空间），该函数由包含多个全连接层的神经网络（即映射网络）构成。通过仿射变换，中间表示$w$被专业化为风格$y=(y_{s},y_{b})$，将被输入到自适应实例归一化（AdaIN）操作中，如下所示：'
- en: '|  | $\mathrm{AdaIN}(x_{i},y)=y_{s,i}\frac{x_{i}-\mu(x_{i})}{\sigma(x_{i})}+y_{b,i}$
    |  | (2) |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathrm{AdaIN}(x_{i},y)=y_{s,i}\frac{x_{i}-\mu(x_{i})}{\sigma(x_{i})}+y_{b,i}$
    |  | (2) |'
- en: 'where each feature map $x_{i}$ is normalized separately. The StyleGAN generator
    architecture allows controlling the image synthesis by modifying the styles via
    different scales. In addition, instead of using one random latent code during
    training, this method uses two latent codes to generate a given proportion of
    images. More specifically, two latent codes $z_{1}$ and $z_{2}$ are fed to the
    mapping network to create respectively $w_{1}$ and $w_{2}$ that control the styles
    by applying $w_{1}$ before and $w_{2}$ after the crossover point. Fig. [5](#S2.F5
    "Figure 5 ‣ 2 Deepfake Creation ‣ Deep Learning for Deepfakes Creation and Detection:
    A Survey") demonstrates examples of images created by mixing two latent codes
    at three different scales where each subset of styles controls separate meaningful
    high-level attributes of the image. In other words, the generator architecture
    of StyleGAN is able to learn separation of high-level attributes (e.g., pose and
    identity when trained on human faces) and enables intuitive, scale-speciﬁc control
    of the face synthesis.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '其中每个特征图$x_{i}$是单独标准化的。StyleGAN生成器架构允许通过不同尺度的风格修改来控制图像合成。此外，这种方法在训练期间不使用一个随机潜在代码，而是使用两个潜在代码来生成给定比例的图像。更具体地说，将两个潜在代码$z_{1}$和$z_{2}$输入到映射网络中，分别创建$w_{1}$和$w_{2}$，通过在交叉点前应用$w_{1}$和在交叉点后应用$w_{2}$来控制风格。图[5](#S2.F5
    "Figure 5 ‣ 2 Deepfake Creation ‣ Deep Learning for Deepfakes Creation and Detection:
    A Survey")展示了在三个不同尺度下混合两个潜在代码生成的图像示例，其中每个风格子集控制图像的不同高层次属性。换句话说，StyleGAN的生成器架构能够学习高层次属性的分离（例如，当在面部图像上训练时，姿势和身份），并实现直观的、特定尺度的面部合成控制。'
- en: '![Refer to caption](img/8c0b982c233bf90f257b5c47b85d1b1e.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8c0b982c233bf90f257b5c47b85d1b1e.png)'
- en: 'Figure 5: Examples of mixing styles using StyleGAN: the output images are generated
    by copying a specified subset of styles from source B and taking the rest from
    source A. a) Copying coarse styles from source B will generate images that have
    high-level aspects from source B and all colors and finer facial features from
    source A; b) if copying the styles of middle resolutions from B, the output images
    will have smaller scale facial features from B and preserve the pose, general
    face shape, and eyeglasses from A; c) if copying the fine styles from source B,
    the generated images will have the color scheme and microstructure of source B
    [[51](#bib.bib51)].'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：使用 StyleGAN 混合风格的示例：输出图像是通过从源 B 复制指定子集的风格并从源 A 获取其余部分生成的。a) 从源 B 复制粗糙风格将生成具有源
    B 高级特征和源 A 的所有颜色及更细面部特征的图像；b) 如果从源 B 复制中等分辨率的风格，输出图像将具有源 B 的较小尺度面部特征，同时保留源 A 的姿势、一般面部形状和眼镜；c)
    如果从源 B 复制细节风格，生成的图像将具有源 B 的色彩方案和微观结构 [[51](#bib.bib51)]。
- en: 3 Deepfake Detection
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 深度伪造检测
- en: Deepfake detection is normally deemed a binary classification problem where
    classifiers are used to classify between authentic videos and tampered ones. This
    kind of methods requires a large database of real and fake videos to train classification
    models. The number of fake videos is increasingly available, but it is still limited
    in terms of setting a benchmark for validating various detection methods. To address
    this issue, Korshunov and Marcel [[63](#bib.bib63)] produced a notable deepfake
    dataset consisting of 620 videos based on the GAN model using the open source
    code Faceswap-GAN [[58](#bib.bib58)]. Videos from the publicly available VidTIMIT
    database [[64](#bib.bib64)] were used to generate low and high quality deepfake
    videos, which can effectively mimic the facial expressions, mouth movements, and
    eye blinking. These videos were then used to test various deepfake detection methods.
    Test results show that the popular face recognition systems based on VGG [[65](#bib.bib65)]
    and Facenet [[59](#bib.bib59), [66](#bib.bib66)] are unable to detect deepfakes
    effectively. Other methods such as lip-syncing approaches [[67](#bib.bib67), [68](#bib.bib68),
    [69](#bib.bib69)] and image quality metrics with support vector machine (SVM)
    [[70](#bib.bib70)] produce very high error rate when applied to detect deepfake
    videos from this newly produced dataset. This raises concerns about the critical
    need of future development of more robust methods that can detect deepfakes from
    genuine.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造检测通常被视为二分类问题，其中分类器用于区分真实视频和篡改视频。这种方法需要一个大量的真实和伪造视频数据库来训练分类模型。伪造视频的数量越来越多，但在为各种检测方法设定基准方面仍然有限。为解决这一问题，Korshunov
    和 Marcel [[63](#bib.bib63)] 制作了一个重要的深度伪造数据集，包含 620 个基于 GAN 模型的视频，使用开源代码 Faceswap-GAN
    [[58](#bib.bib58)]。使用公开的 VidTIMIT 数据库 [[64](#bib.bib64)] 中的视频生成了低质量和高质量的深度伪造视频，这些视频能有效模拟面部表情、嘴部动作和眼睛眨动。这些视频随后被用于测试各种深度伪造检测方法。测试结果显示，基于
    VGG [[65](#bib.bib65)] 和 Facenet [[59](#bib.bib59), [66](#bib.bib66)] 的流行面部识别系统无法有效检测深度伪造。其他方法，如唇同步方法
    [[67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69)] 和支持向量机（SVM） [[70](#bib.bib70)]
    的图像质量指标在检测来自这个新生成的数据集的深度伪造视频时产生了非常高的错误率。这引发了对未来发展更强大方法的迫切需求，以便能够从真实视频中检测深度伪造。
- en: 'This section presents a survey of deepfake detection methods where we group
    them into two major categories: fake image detection methods and fake video detection
    ones (Fig. [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Deep Learning for Deepfakes
    Creation and Detection: A Survey")). The latter is distinguished into two smaller
    groups: *visual artifacts* within single video frame-based methods and *temporal
    features* across frames-based ones. Whilst most of the methods based on temporal
    features use deep learning *recurrent* classification models, the methods use
    visual artifacts within video frame can be implemented by either deep or shallow
    classifiers.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了深度伪造检测方法的调查，我们将其分为两个主要类别：伪造图像检测方法和伪造视频检测方法（图[2](#S1.F2 "图 2 ‣ 1 引言 ‣ 深度学习在深度伪造创建和检测中的应用：综述")）。后者又分为两个小组：基于单帧视频中的*视觉伪影*的方法和基于跨帧的*时间特征*的方法。虽然大多数基于时间特征的方法使用深度学习*递归*分类模型，但使用视频帧中的视觉伪影的方法可以通过深度或浅层分类器实现。
- en: 3.1 Fake Image Detection
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 伪造图像检测
- en: Deepfakes are increasingly detrimental to privacy, society security and democracy
    [[71](#bib.bib71)]. Methods for detecting deepfakes have been proposed as soon
    as this threat was introduced. Early attempts were based on handcrafted features
    obtained from artifacts and inconsistencies of the fake image synthesis process.
    Recent methods, e.g., [[72](#bib.bib72), [73](#bib.bib73)], have commonly applied
    deep learning to automatically extract salient and discriminative features to
    detect deepfakes.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造对隐私、社会安全和民主造成的损害越来越严重[[71](#bib.bib71)]。检测深度伪造的方法在这一威胁出现后不久便被提出。早期尝试基于从伪造图像合成过程中的伪影和不一致性中获得的手工特征。最近的方法，例如[[72](#bib.bib72),
    [73](#bib.bib73)]，普遍应用了深度学习以自动提取显著且具有区分性的特征来检测深度伪造。
- en: 3.1.1 Handcrafted Features-based Methods
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 基于手工特征的方法
- en: Most works on detection of GAN generated images do not consider the generalization
    capability of the detection models although the development of GAN is ongoing,
    and many new extensions of GAN are frequently introduced. Xuan et al. [[74](#bib.bib74)]
    used an image preprocessing step, e.g., Gaussian blur and Gaussian noise, to remove
    low level high frequency clues of GAN images. This increases the pixel level statistical
    similarity between real images and fake images and allows the forensic classifier
    to learn more intrinsic and meaningful features, which has better generalization
    capability than previous image forensics methods [[75](#bib.bib75), [76](#bib.bib76)]
    or image steganalysis networks [[77](#bib.bib77)].
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数关于GAN生成图像检测的研究虽然GAN的开发持续进行，并且许多新的GAN扩展经常被引入，但并未考虑检测模型的泛化能力。Xuan等人[[74](#bib.bib74)]使用了图像预处理步骤，如高斯模糊和高斯噪声，以去除GAN图像的低级高频线索。这增加了真实图像和虚假图像之间的像素级统计相似性，使取证分类器能够学习更具内在性和有意义的特征，这比之前的图像取证方法[[75](#bib.bib75),
    [76](#bib.bib76)]或图像隐写分析网络[[77](#bib.bib77)]具有更好的泛化能力。
- en: Zhang et al. [[78](#bib.bib78)] used the bag of words method to extract a set
    of compact features and fed it into various classifiers such as SVM [[79](#bib.bib79)],
    random forest (RF) [[80](#bib.bib80)] and multi-layer perceptrons (MLP) [[81](#bib.bib81)]
    for discriminating swapped face images from the genuine. Among deep learning-generated
    images, those synthesised by GAN models are probably most difficult to detect
    as they are realistic and high-quality based on GAN’s capability to learn distribution
    of the complex input data and generate new outputs with similar input distribution.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Zhang等人[[78](#bib.bib78)]使用词袋方法提取了一组紧凑的特征，并将其输入到各种分类器中，如SVM[[79](#bib.bib79)]、随机森林（RF）[[80](#bib.bib80)]和多层感知机（MLP）[[81](#bib.bib81)]，用于区分交换面部图像与真实图像。在深度学习生成的图像中，由GAN模型合成的图像可能是最难检测的，因为它们基于GAN对复杂输入数据分布的学习能力生成了类似输入分布的新输出。
- en: On the other hand, Agarwal and Varshney [[82](#bib.bib82)] cast the GAN-based
    deepfake detection as a hypothesis testing problem where a statistical framework
    was introduced using the information-theoretic study of authentication [[83](#bib.bib83)].
    The minimum distance between distributions of legitimate images and images generated
    by a particular GAN is defined, namely the oracle error. The analytic results
    show that this distance increases when the GAN is less accurate, and in this case,
    it is easier to detect deepfakes. In case of high-resolution image inputs, an
    extremely accurate GAN is required to generate fake images that are hard to detect
    by this method.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Agarwal和Varshney[[82](#bib.bib82)]将基于GAN的深度伪造检测视为一个假设检验问题，提出了一个基于信息理论认证研究的统计框架[[83](#bib.bib83)]。定义了合法图像与特定GAN生成的图像之间的最小距离，即oracle误差。分析结果表明，当GAN的准确性较低时，这个距离会增加，此时更容易检测深度伪造。在高分辨率图像输入的情况下，需要一个极其准确的GAN来生成难以通过该方法检测的伪造图像。
- en: 3.1.2 Deep Features-based Methods
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 基于深度特征的方法
- en: Face swapping has a number of compelling applications in video compositing,
    transfiguration in portraits, and especially in identity protection as it can
    replace faces in photographs by ones from a collection of stock images. However,
    it is also one of the techniques that cyber attackers employ to penetrate identification
    or authentication systems to gain illegitimate access. The use of deep learning
    such as CNN and GAN has made swapped face images more challenging for forensics
    models as it can preserve pose, facial expression and lighting of the photographs
    [[84](#bib.bib84)].
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 面孔交换在视频合成、肖像变形以及特别是在身份保护方面有许多引人注目的应用，因为它可以用库存图像中的面孔替换照片中的面孔。然而，它也是网络攻击者用来渗透身份识别或认证系统以获取非法访问的技术之一。深度学习的使用，如
    CNN 和 GAN，使得交换的面孔图像对取证模型来说更具挑战性，因为它可以保留照片的姿势、面部表情和光照 [[84](#bib.bib84)]。
- en: Hsu et al. [[85](#bib.bib85)] introduced a two-phase deep learning method for
    detection of deepfake images. The first phase is a feature extractor based on
    the common fake feature network (CFFN) where the Siamese network architecture
    presented in [[86](#bib.bib86)] is used. The CFFN encompasses several dense units
    with each unit including different numbers of dense blocks [[61](#bib.bib61)]
    to improve the representative capability for the input images. Discriminative
    features between the fake and real images are extracted through the CFFN learning
    process based on the use of pairwise information, which is the label of each pair
    of two input images. If the two images are of the same type, i.e., fake-fake or
    real-real, the pairwise label is $1$. In contrast, if they are of different types,
    i.e., fake-real, the pairwise label is $0$. The CFFN-based discriminative features
    are then fed to a neural network classifier to distinguish deceptive images from
    genuine. The proposed method is validated for both fake face and fake general
    image detection. On the one hand, the face dataset is obtained from CelebA [[87](#bib.bib87)],
    containing 10,177 identities and 202,599 aligned face images of various poses
    and background clutter. Five GAN variants are used to generate fake images with
    size of 64x64, including deep convolutional GAN (DCGAN) [[88](#bib.bib88)], Wasserstein
    GAN (WGAN) [[89](#bib.bib89)], WGAN with gradient penalty (WGAN-GP) [[90](#bib.bib90)],
    least squares GAN [[91](#bib.bib91)], and PGGAN [[62](#bib.bib62)]. A total of
    385,198 training images and 10,000 test images of both real and fake ones are
    obtained for validating the proposed method. On the other hand, the general dataset
    is extracted from the ILSVRC12 [[92](#bib.bib92)]. The large scale GAN training
    model for high fidelity natural image synthesis (BIGGAN) [[93](#bib.bib93)], self-attention
    GAN [[94](#bib.bib94)] and spectral normalization GAN [[95](#bib.bib95)] are used
    to generate fake images with size of 128x128\. The training set consists of 600,000
    fake and real images whilst the test set includes 10,000 images of both types.
    Experimental results show the superior performance of the proposed method against
    its competing methods such as those introduced in [[96](#bib.bib96), [97](#bib.bib97),
    [98](#bib.bib98), [99](#bib.bib99)].
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Hsu 等人 [[85](#bib.bib85)] 提出了一个用于检测深度伪造图像的两阶段深度学习方法。第一阶段是基于常见伪造特征网络（CFFN）的特征提取器，其中使用了
    [[86](#bib.bib86)] 中提出的 Siamese 网络架构。CFFN 包含多个密集单元，每个单元包括不同数量的密集块 [[61](#bib.bib61)]，以提高对输入图像的表征能力。通过
    CFFN 学习过程，基于成对信息（即每对输入图像的标签）提取伪造图像和真实图像之间的判别特征。如果两幅图像类型相同，即伪造-伪造或真实-真实，则成对标签为
    $1$。相反，如果它们类型不同，即伪造-真实，则成对标签为 $0$。基于 CFFN 的判别特征随后被输入到神经网络分类器中，以区分欺骗性图像和真实图像。所提方法在伪造面孔和伪造一般图像检测中得到了验证。一方面，面孔数据集来自
    CelebA [[87](#bib.bib87)]，包含 10,177 个身份和 202,599 张不同姿势和背景杂乱的对齐面孔图像。使用了五种 GAN 变体生成
    64x64 尺寸的伪造图像，包括深度卷积 GAN (DCGAN) [[88](#bib.bib88)]、Wasserstein GAN (WGAN) [[89](#bib.bib89)]、带有梯度惩罚的
    WGAN (WGAN-GP) [[90](#bib.bib90)]、最小二乘 GAN [[91](#bib.bib91)] 和 PGGAN [[62](#bib.bib62)]。总共获得了
    385,198 张训练图像和 10,000 张真实与伪造图像用于验证所提方法。另一方面，通用数据集来自 ILSVRC12 [[92](#bib.bib92)]。大规模
    GAN 训练模型用于高保真自然图像合成 (BIGGAN) [[93](#bib.bib93)]、自注意力 GAN [[94](#bib.bib94)] 和谱归一化
    GAN [[95](#bib.bib95)] 用于生成 128x128 尺寸的伪造图像。训练集包括 600,000 张伪造和真实图像，而测试集包括 10,000
    张这两种类型的图像。实验结果显示，所提方法在性能上优于竞争方法，如 [[96](#bib.bib96)、[97](#bib.bib97)、[98](#bib.bib98)、[99](#bib.bib99)]
    中介绍的那些方法。
- en: 'Likewise, Guo et al. [[100](#bib.bib100)] proposed a CNN model, namely SCnet,
    to detect deepfake images, which are generated by the Glow-based facial forgery
    tool [[101](#bib.bib101)]. The fake images synthesized by the Glow model [[101](#bib.bib101)]
    have the facial expression maliciously tampered. These images are hyper-realistic
    with perfect visual qualities, but they still have subtle or noticeable manipulation
    traces, which are exploited by the SCnet. The SCnet is able to automatically learn
    high-level forensics features of image data thanks to a hierarchical feature extraction
    block, which is formed by stacking four convolutional layers. Each layer learns
    a new set of feature maps from the previous layer, with each convolutional operation
    is defined by:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，郭等人 [[100](#bib.bib100)] 提出了一个名为 SCnet 的 CNN 模型，用于检测由 Glow 基面部伪造工具 [[101](#bib.bib101)]
    生成的深伪图像。由 Glow 模型 [[101](#bib.bib101)] 合成的伪造图像具有恶意篡改的面部表情。这些图像高度逼真，视觉效果完美，但仍然有微妙或明显的操控痕迹，这些痕迹被
    SCnet 利用。得益于一个由四个卷积层堆叠形成的层次特征提取块，SCnet 能够自动学习图像数据的高级取证特征。每个层学习来自前一层的新特征图，每次卷积操作的定义为：
- en: '|  | $f_{j}^{(n)}=\sum_{i=1}^{i}f_{i}^{(n-1)}*\omega_{ij}^{(n)}+b_{j}^{(n)}$
    |  | (3) |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '|  | $f_{j}^{(n)}=\sum_{i=1}^{i}f_{i}^{(n-1)}*\omega_{ij}^{(n)}+b_{j}^{(n)}$
    |  | (3) |'
- en: where $f_{j}^{(n)}$ is the $j^{th}$ feature map of the $n^{th}$ layer, $\omega_{ij}^{(n)}$
    is the weight of the $i^{th}$ channel of the $j^{th}$ convolutional kernel in
    the $n^{th}$ layer, and $b_{j}^{(n)}$ is the bias term of the $j^{th}$ convolutional
    kernel in the $n^{th}$ layer. The proposed approach is evaluated using a dataset
    consisting of 321,378 face images, which are created by applying the Glow model
    [[101](#bib.bib101)] to the CelebA face image dataset [[87](#bib.bib87)]. Evaluation
    results show that the SCnet model obtains higher accuracy and better generalization
    than the Meso-4 model proposed in [[102](#bib.bib102)].
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $f_{j}^{(n)}$ 是第 $n^{th}$ 层的第 $j^{th}$ 特征图，$\omega_{ij}^{(n)}$ 是第 $n^{th}$
    层第 $j^{th}$ 卷积核的第 $i^{th}$ 通道的权重，$b_{j}^{(n)}$ 是第 $n^{th}$ 层第 $j^{th}$ 卷积核的偏置项。所提出的方法使用包含
    321,378 张面部图像的数据集进行评估，这些图像是通过将 Glow 模型 [[101](#bib.bib101)] 应用于 CelebA 面部图像数据集
    [[87](#bib.bib87)] 创建的。评估结果显示，SCnet 模型比 [[102](#bib.bib102)] 中提出的 Meso-4 模型具有更高的准确性和更好的泛化能力。
- en: '![Refer to caption](img/1429dcf5780882393df19011f7ad3557.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/1429dcf5780882393df19011f7ad3557.png)'
- en: 'Figure 6: A two-step process for face manipulation detection where the preprocessing
    step aims to detect, crop and align faces on a sequence of frames and the second
    step distinguishes manipulated and authentic face images by combining convolutional
    neural network (CNN) and recurrent neural network (RNN) [[103](#bib.bib103)].'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：一个面部操控检测的两步过程，其中预处理步骤旨在检测、裁剪和对齐一系列帧中的面部，第二步通过结合卷积神经网络（CNN）和递归神经网络（RNN）来区分操控过的面部图像和真实的面部图像
    [[103](#bib.bib103)]。
- en: Recently, Zhao et al. [[104](#bib.bib104)] proposed a method for deepfake detection
    using self-consistency of local source features, which are content-independent,
    spatially-local information of images. These features could come from either imaging
    pipelines, encoding methods or image synthesis approaches. The hypothesis is that
    a modified image would have different source features at different locations,
    while an original image will have the same source features across locations. These
    source features, represented in the form of down-sampled feature maps, are extracted
    by a CNN model using a special representation learning method called pairwise
    self-consistency learning. This learning method aims to penalize pairs of feature
    vectors that refer to locations from the same image for having a low cosine similarity
    score. At the same time, it also penalizes the pairs from different images for
    having a high similarity score. The learned feature maps are then fed to a classification
    method for deepfake detection. This proposed approach is evaluated on seven popular
    datasets, including FaceForensics++ [[105](#bib.bib105)], DeepfakeDetection [[106](#bib.bib106)],
    Celeb-DF-v1 & Celeb-DF-v2 [[107](#bib.bib107)], Deepfake Detection Challenge (DFDC)
    [[108](#bib.bib108)], DFDC Preview [[109](#bib.bib109)], and DeeperForensics-1.0
    [[110](#bib.bib110)]. Experimental results demonstrate that the proposed approach
    is superior to state-of-the-art methods. It however may have a limitation when
    dealing with fake images that are generated by methods that directly output the
    whole images whose source features are consistent across all positions within
    each image.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，赵等人[[104](#bib.bib104)] 提出了一个利用局部源特征自一致性进行深度伪造检测的方法，这些特征是图像的内容独立的空间局部信息。这些特征可以来自成像管道、编码方法或图像合成方法。假设是，修改过的图像在不同位置会有不同的源特征，而原始图像在各个位置的源特征是相同的。这些源特征以降采样特征图的形式表示，通过使用称为成对自一致性学习的特殊表示学习方法的CNN模型提取。该学习方法旨在惩罚来自同一图像的特征向量对的余弦相似度得分低，同时也惩罚来自不同图像的特征对的相似度得分高。然后将学习到的特征图输入到深度伪造检测分类方法中。该方法在七个流行的数据集上进行了评估，包括
    FaceForensics++ [[105](#bib.bib105)]、DeepfakeDetection [[106](#bib.bib106)]、Celeb-DF-v1
    & Celeb-DF-v2 [[107](#bib.bib107)]、深度伪造检测挑战（DFDC）[[108](#bib.bib108)]、DFDC 预览
    [[109](#bib.bib109)] 和 DeeperForensics-1.0 [[110](#bib.bib110)]。实验结果表明，该方法优于最先进的方法，但在处理由直接输出整个图像的方法生成的假图像时可能存在局限性，这些假图像的源特征在每个图像内的所有位置是一致的。
- en: 3.2 Fake Video Detection
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 假视频检测
- en: 'Most image detection methods cannot be used for videos because of the strong
    degradation of the frame data after video compression [[102](#bib.bib102)]. Furthermore,
    videos have temporal characteristics that are varied among sets of frames and
    they are thus challenging for methods designed to detect only still fake images.
    This subsection focuses on deepfake video detection methods and categorizes them
    into two smaller groups: methods that employ temporal features and those that
    explore visual artifacts within frames.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数图像检测方法不能用于视频，因为视频压缩后帧数据的强烈退化[[102](#bib.bib102)]。此外，视频具有时间特性，在帧组之间变化，因此对于仅设计用于检测静态假图像的方法来说，这些视频具有挑战性。本小节关注深度伪造视频检测方法，并将其分为两个较小的组：利用时间特征的方法和探索帧内视觉伪影的方法。
- en: 3.2.1 Temporal Features across Video Frames
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 视频帧中的时间特征
- en: 'Based on the observation that temporal coherence is not enforced effectively
    in the synthesis process of deepfakes, Sabir et al. [[103](#bib.bib103)] leveraged
    the use of spatio-temporal features of video streams to detect deepfakes. Video
    manipulation is carried out on a frame-by-frame basis so that low level artifacts
    produced by face manipulations are believed to further manifest themselves as
    temporal artifacts with inconsistencies across frames. A recurrent convolutional
    model (RCN) was proposed based on the integration of the convolutional network
    DenseNet [[61](#bib.bib61)] and the gated recurrent unit cells [[111](#bib.bib111)]
    to exploit temporal discrepancies across frames (see Fig. [6](#S3.F6 "Figure 6
    ‣ 3.1.2 Deep Features-based Methods ‣ 3.1 Fake Image Detection ‣ 3 Deepfake Detection
    ‣ Deep Learning for Deepfakes Creation and Detection: A Survey")). The proposed
    method is tested on the FaceForensics++ dataset, which includes 1,000 videos [[105](#bib.bib105)],
    and shows promising results.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 基于观察到在深伪合成过程中时间一致性未能有效强制实施的情况，Sabir 等人 [[103](#bib.bib103)] 利用视频流的时空特征来检测深伪。视频处理是逐帧进行的，因此由面部操作产生的低级伪影被认为会进一步表现为帧间不一致的时间伪影。基于卷积网络
    DenseNet [[61](#bib.bib61)] 和门控递归单元（GRU） [[111](#bib.bib111)] 的集成，提出了一种递归卷积模型（RCN），以利用帧间的时间差异（参见图
    [6](#S3.F6 "图 6 ‣ 3.1.2 基于深度特征的方法 ‣ 3.1 假图像检测 ‣ 3 深伪检测 ‣ 深度学习在深伪创建与检测中的应用综述")）。该方法在包括
    1,000 个视频的 FaceForensics++ 数据集上进行了测试 [[105](#bib.bib105)]，显示了有希望的结果。
- en: 'Likewise, Güera and Delp [[112](#bib.bib112)] highlighted that deepfake videos
    contain intra-frame inconsistencies and temporal inconsistencies between frames.
    They then proposed the temporal-aware pipeline method that uses CNN and long short
    term memory (LSTM) to detect deepfake videos. CNN is employed to extract frame-level
    features, which are then fed into the LSTM to create a temporal sequence descriptor.
    A fully-connected network is finally used for classifying doctored videos from
    real ones based on the sequence descriptor as illustrated in Fig. [7](#S3.F7 "Figure
    7 ‣ 3.2.1 Temporal Features across Video Frames ‣ 3.2 Fake Video Detection ‣ 3
    Deepfake Detection ‣ Deep Learning for Deepfakes Creation and Detection: A Survey").
    An accuracy of greater than 97% was obtained using a dataset of 600 videos, including
    300 deepfake videos collected from multiple video-hosting websites and 300 pristine
    videos randomly selected from the Hollywood human actions dataset in [[113](#bib.bib113)].'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，Güera 和 Delp [[112](#bib.bib112)] 强调了深伪视频中存在帧内不一致性和帧间时间不一致性。然后，他们提出了一种时间感知管道方法，该方法使用
    CNN 和长短期记忆（LSTM）来检测深伪视频。CNN 用于提取帧级特征，这些特征随后被输入到 LSTM 中以创建时间序列描述符。最后，使用全连接网络根据序列描述符对伪造视频和真实视频进行分类，如图
    [7](#S3.F7 "图 7 ‣ 3.2.1 视频帧间时间特征 ‣ 3.2 假视频检测 ‣ 3 深伪检测 ‣ 深度学习在深伪创建与检测中的应用综述") 所示。使用包含
    600 个视频的数据集（包括 300 个从多个视频托管网站收集的深伪视频和 300 个从 [[113](#bib.bib113)] 的好莱坞人类动作数据集中随机选择的原始视频），获得了超过
    97% 的准确率。
- en: '![Refer to caption](img/e01a1e6ea1cb5d8f433adf89204f0344.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e01a1e6ea1cb5d8f433adf89204f0344.png)'
- en: 'Figure 7: A deepfake detection method using convolutional neural network (CNN)
    and long short term memory (LSTM) to extract temporal features of a given video
    sequence, which are represented via the sequence descriptor. The detection network
    consisting of fully-connected layers is employed to take the sequence descriptor
    as input and calculate probabilities of the frame sequence belonging to either
    authentic or deepfake class [[112](#bib.bib112)].'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：一种使用卷积神经网络（CNN）和长短期记忆（LSTM）提取给定视频序列时间特征的深伪检测方法，这些特征通过序列描述符表示。检测网络由全连接层组成，用于将序列描述符作为输入并计算帧序列属于真实或深伪类别的概率
    [[112](#bib.bib112)]。
- en: On the other hand, the use of a physiological signal, eye blinking, to detect
    deepfakes was proposed in Li et al. [[114](#bib.bib114)] based on the observation
    that a person in deepfakes has a lot less frequent blinking than that in untampered
    videos. A healthy adult human would normally blink somewhere between 2 to 10 seconds,
    and each blink would take 0.1 and 0.4 seconds. Deepfake algorithms, however, often
    use face images available online for training, which normally show people with
    open eyes, i.e., very few images published on the internet show people with closed
    eyes. Thus, without having access to images of people blinking, deepfake algorithms
    do not have the capability to generate fake faces that can blink normally. In
    other words, blinking rates in deepfakes are much lower than those in normal videos.
    To discriminate real and fake videos, Li et al. [[114](#bib.bib114)] crop eye
    areas in the videos and distribute them into long-term recurrent convolutional
    networks (LRCN) [[115](#bib.bib115)] for dynamic state prediction. The LRCN consists
    of a feature extractor based on CNN, a sequence learning based on long short term
    memory (LSTM), and a state prediction based on a fully connected layer to predict
    probability of eye open and close state. The eye blinking shows strong temporal
    dependencies and thus the implementation of LSTM helps to capture these temporal
    patterns effectively.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Li等人提出了利用生理信号——眼睛眨动来检测深度伪造视频的方案[[114](#bib.bib114)]。这一方案基于观察到的事实，即深度伪造视频中的人眨眼频率远低于未被篡改的视频。健康的成年人通常每2到10秒眨一次眼，每次眨眼持续时间为0.1到0.4秒。然而，深度伪造算法通常使用在线获取的面部图像进行训练，这些图像通常显示的是睁开的眼睛，即互联网上很少有闭眼的图像。因此，由于没有闭眼的图像，深度伪造算法无法生成可以正常眨眼的伪造面孔。换句话说，深度伪造视频中的眨眼率远低于正常视频。为了区分真实和伪造视频，Li等人[[114](#bib.bib114)]将视频中的眼睛区域裁剪出来，并将其输入到长短期记忆网络（LRCN）[[115](#bib.bib115)]中进行动态状态预测。LRCN包括一个基于CNN的特征提取器，一个基于长短期记忆（LSTM）的序列学习模块，以及一个基于全连接层的状态预测模块，以预测眼睛开合的概率。眼睛眨动表现出强烈的时间依赖性，因此LSTM的实现有助于有效捕捉这些时间模式。
- en: Recently, Caldelli et al. [[116](#bib.bib116)] proposed the use of optical flow
    to gauge the information along the temporal axis of a frame sequence for video
    deepfake detection. The optical flow is a vector field calculated on two temporal-distinct
    frames of a video that can describe the movement of objects in a scene. The optical
    flow fields are expected to be different between synthetically created frames
    and naturally generated ones [[117](#bib.bib117)]. Unnatural movements of lips,
    eyes, or of the entire faces inserted into deepfake videos would introduce distinctive
    motion patterns when compared with pristine ones. Based on this assumption, features
    consisting of optical flow fields are fed into a CNN model for discriminating
    between deepfakes and original videos. More specifically, the ResNet50 architecture
    [[118](#bib.bib118)] is implemented as a CNN model for experiments. The results
    obtained using the FaceForensics++ dataset [[105](#bib.bib105)] show that this
    approach is comparable with state-of-the-art methods in terms of classification
    accuracy. A combination of this kind of feature with frame-based features is also
    experimented, which results in an improved deepfake detection performance. This
    demonstrates the usefulness of optical flow fields in capturing the inconsistencies
    on the temporal axis of video frames for deepfake detection.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Caldelli等人[[116](#bib.bib116)]提出了利用光流来衡量视频帧序列在时间轴上的信息，以检测视频深度伪造。光流是计算在两个时间上不同的帧上的向量场，能够描述场景中物体的运动。光流场在合成创建的帧和自然生成的帧之间应该有所不同[[117](#bib.bib117)]。与原始视频相比，插入到深度伪造视频中的嘴唇、眼睛或整个面部的非自然运动会引入独特的运动模式。基于这一假设，包含光流场的特征被输入到CNN模型中，用于区分深度伪造视频和原始视频。更具体地说，ResNet50架构[[118](#bib.bib118)]被作为CNN模型进行实验。使用FaceForensics++数据集[[105](#bib.bib105)]获得的结果表明，这种方法在分类准确性方面与最先进的方法相当。还实验了将这种特征与基于帧的特征相结合，结果提高了深度伪造检测性能。这表明光流场在捕捉视频帧时间轴上的不一致性方面非常有用。
- en: 3.2.2 Visual Artifacts within Video Frame
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 视频帧中的视觉伪影
- en: As can be noticed in the previous subsection, the methods using temporal patterns
    across video frames are mostly based on deep recurrent network models to detect
    deepfake videos. This subsection investigates the other approach that normally
    decomposes videos into frames and explores visual artifacts within single frames
    to obtain discriminant features. These features are then distributed into either
    a deep or shallow classifier to differentiate between fake and authentic videos.
    We thus group methods in this subsection based on the types of classifiers, i.e.
    either deep or shallow.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一节所述，使用视频帧间时间模式的方法大多基于深度递归网络模型来检测深度伪造视频。本节探讨了另一种方法，该方法通常将视频分解为帧，并在单帧内探索视觉伪影以获取判别特征。这些特征随后分配给深度或浅层分类器，以区分虚假视频和真实视频。因此，我们根据分类器的类型（即深度或浅层）对本节的方法进行分组。
- en: Deep classifiers
  id: totrans-99
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 深度分类器
- en: Deepfake videos are normally created with limited resolutions, which require
    an affine face warping approach (i.e., scaling, rotation and shearing) to match
    the configuration of the original ones. Because of the resolution inconsistency
    between the warped face area and the surrounding context, this process leaves
    artifacts that can be detected by CNN models such as VGG16 [[119](#bib.bib119)],
    ResNet50, ResNet101 and ResNet152 [[118](#bib.bib118)]. A deep learning method
    to detect deepfakes based on the artifacts observed during the face warping step
    of the deepfake generation algorithms was proposed in [[120](#bib.bib120)]. The
    proposed method is evaluated on two deepfake datasets, namely the UADFV and DeepfakeTIMIT.
    The UADFV dataset [[121](#bib.bib121)] contains 49 real videos and 49 fake videos
    with 32,752 frames in total. The DeepfakeTIMIT dataset [[69](#bib.bib69)] includes
    a set of low quality videos of 64 x 64 size and another set of high quality videos
    of 128 x 128 with totally 10,537 pristine images and 34,023 fabricated images
    extracted from 320 videos for each quality set. Performance of the proposed method
    is compared with other prevalent methods such as two deepfake detection MesoNet
    methods, i.e. Meso-4 and MesoInception-4 [[102](#bib.bib102)], HeadPose [[121](#bib.bib121)],
    and the face tampering detection method two-stream NN [[122](#bib.bib122)]. Advantage
    of the proposed method is that it needs not to generate deepfake videos as negative
    examples before training the detection models. Instead, the negative examples
    are generated dynamically by extracting the face region of the original image
    and aligning it into multiple scales before applying Gaussian blur to a scaled
    image of random pick and warping back to the original image. This reduces a large
    amount of time and computational resources compared to other methods, which require
    deepfakes are generated in advance.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造视频通常以有限的分辨率创建，这要求使用仿射人脸扭曲方法（即缩放、旋转和剪切）来匹配原始视频的配置。由于扭曲人脸区域与周围背景之间的分辨率不一致，这一过程留下了可以被
    CNN 模型（如 VGG16 [[119](#bib.bib119)]、ResNet50、ResNet101 和 ResNet152 [[118](#bib.bib118)]）检测到的伪影。在
    [[120](#bib.bib120)] 中提出了一种基于深度伪造生成算法在人脸扭曲步骤中观察到的伪影来检测深度伪造的方法。该方法在两个深度伪造数据集上进行了评估，即
    UADFV 和 DeepfakeTIMIT。UADFV 数据集 [[121](#bib.bib121)] 包含 49 个真实视频和 49 个虚假视频，总计
    32,752 帧。DeepfakeTIMIT 数据集 [[69](#bib.bib69)] 包含一组 64 x 64 的低质量视频和一组 128 x 128
    的高质量视频，共有 10,537 张原始图像和 34,023 张伪造图像，分别从每组 320 个视频中提取。该方法的性能与其他流行方法进行了比较，例如两种深度伪造检测
    MesoNet 方法，即 Meso-4 和 MesoInception-4 [[102](#bib.bib102)]、HeadPose [[121](#bib.bib121)]
    和人脸篡改检测方法两流神经网络 [[122](#bib.bib122)]。所提出的方法的优点在于，在训练检测模型之前不需要生成深度伪造视频作为负样本。相反，负样本是通过提取原始图像的人脸区域并将其对齐为多个尺度，然后对随机选取的缩放图像应用高斯模糊，再扭曲回原始图像来动态生成的。这与其他需要预先生成深度伪造的办法相比，减少了大量的时间和计算资源消耗。
- en: 'Nguyen et al. [[123](#bib.bib123)] proposed the use of capsule networks for
    detecting manipulated images and videos. The capsule network was initially introduced
    to address limitations of CNNs when applied to inverse graphics tasks, which aim
    to find physical processes used to produce images of the world [[124](#bib.bib124)].
    The recent development of capsule network based on dynamic routing algorithm [[125](#bib.bib125)]
    demonstrates its ability to describe the hierarchical pose relationships between
    object parts. This development is employed as a component in a pipeline for detecting
    fabricated images and videos as demonstrated in Fig. [8](#S3.F8 "Figure 8 ‣ Deep
    classifiers ‣ 3.2.2 Visual Artifacts within Video Frame ‣ 3.2 Fake Video Detection
    ‣ 3 Deepfake Detection ‣ Deep Learning for Deepfakes Creation and Detection: A
    Survey"). A dynamic routing algorithm is deployed to route the outputs of the
    three capsules to the output capsules through a number of iterations to separate
    between fake and real images. The method is evaluated through four datasets covering
    a wide range of forged image and video attacks. They include the well-known Idiap
    Research Institute replay-attack dataset [[126](#bib.bib126)], the deepfake face
    swapping dataset created by Afchar et al. [[102](#bib.bib102)], the facial reenactment
    FaceForensics dataset [[127](#bib.bib127)], produced by the Face2Face method [[52](#bib.bib52)],
    and the fully computer-generated image dataset generated by Rahmouni et al. [[128](#bib.bib128)].
    The proposed method yields the best performance compared to its competing methods
    in all of these datasets. This shows the potential of the capsule network in building
    a general detection system that can work effectively for various forged image
    and video attacks.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 'Nguyen 等人 [[123](#bib.bib123)] 提出了使用胶囊网络来检测被操控的图像和视频。胶囊网络最初是为了应对 CNN 在应用于逆向图形任务时的局限性而引入的，这些任务旨在寻找用于生成世界图像的物理过程
    [[124](#bib.bib124)]。基于动态路由算法 [[125](#bib.bib125)] 的胶囊网络的最新发展展示了它描述对象部件之间层次姿态关系的能力。正如图
    [8](#S3.F8 "Figure 8 ‣ Deep classifiers ‣ 3.2.2 Visual Artifacts within Video
    Frame ‣ 3.2 Fake Video Detection ‣ 3 Deepfake Detection ‣ Deep Learning for Deepfakes
    Creation and Detection: A Survey") 所示，这一发展作为检测伪造图像和视频的流程中的一个组件进行应用。一个动态路由算法被用来通过多个迭代将三个胶囊的输出路由到输出胶囊，以区分虚假图像和真实图像。该方法通过涵盖各种伪造图像和视频攻击的四个数据集进行评估。这些数据集包括著名的
    Idiap 研究所重播攻击数据集 [[126](#bib.bib126)]，由 Afchar 等人 [[102](#bib.bib102)] 创建的深度伪造面部交换数据集，FaceForensics
    数据集 [[127](#bib.bib127)]，由 Face2Face 方法 [[52](#bib.bib52)] 生成，以及由 Rahmouni 等人
    [[128](#bib.bib128)] 生成的完全计算机生成图像数据集。与其竞争方法相比，所提方法在所有这些数据集中表现出最佳性能。这表明胶囊网络在构建一个可以有效应对各种伪造图像和视频攻击的通用检测系统方面具有潜力。'
- en: '![Refer to caption](img/87549fa482a980002ce51113a4973ba0.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/87549fa482a980002ce51113a4973ba0.png)'
- en: 'Figure 8: Capsule network takes features obtained from the VGG-19 network [[119](#bib.bib119)]
    to distinguish fake images or videos from the real ones (top). The pre-processing
    step detects face region and scales it to the size of 128x128 before VGG-19 is
    used to extract latent features for the capsule network, which comprises three
    primary capsules and two output capsules, one for real and one for fake images
    (bottom). The statistical pooling constitutes an important part of capsule network
    that deals with forgery detection [[123](#bib.bib123)].'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：胶囊网络利用从 VGG-19 网络中获得的特征 [[119](#bib.bib119)] 来区分虚假图像或视频与真实图像或视频（上图）。预处理步骤检测面部区域，并在使用
    VGG-19 提取胶囊网络的潜在特征之前，将其缩放到 128x128 的大小，胶囊网络包括三个主要胶囊和两个输出胶囊，一个用于真实图像，一个用于虚假图像（下图）。统计池化是胶囊网络处理伪造检测的一个重要部分
    [[123](#bib.bib123)]。
- en: Shallow classifiers
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 浅层分类器
- en: Deepfake detection methods mostly rely on the artifacts or inconsistency of
    intrinsic features between fake and real images or videos. Yang et al. [[121](#bib.bib121)]
    proposed a detection method by observing the differences between 3D head poses
    comprising head orientation and position, which are estimated based on 68 facial
    landmarks of the central face region. The 3D head poses are examined because there
    is a shortcoming in the deepfake face generation pipeline. The extracted features
    are fed into an SVM classifier to obtain the detection results. Experiments on
    two datasets show the great performance of the proposed approach against its competing
    methods. The first dataset, namely UADFV, consists of 49 deep fake videos and
    their respective real videos [[121](#bib.bib121)]. The second dataset comprises
    241 real images and 252 deep fake images, which is a subset of data used in the
    DARPA MediFor GAN Image/Video Challenge [[129](#bib.bib129)]. Likewise, a method
    to exploit artifacts of deepfakes and face manipulations based on visual features
    of eyes, teeth and facial contours was studied in [[130](#bib.bib130)]. The visual
    artifacts arise from lacking global consistency, wrong or imprecise estimation
    of the incident illumination, or imprecise estimation of the underlying geometry.
    For deepfakes detection, missing reflections and missing details in the eye and
    teeth areas are exploited as well as texture features extracted from the facial
    region based on facial landmarks. Accordingly, the eye feature vector, teeth feature
    vector and features extracted from the full-face crop are used. After extracting
    the features, two classifiers including logistic regression and small neural network
    are employed to classify the deepfakes from real videos. Experiments carried out
    on a video dataset downloaded from YouTube show the best result of 0.851 in terms
    of the area under the receiver operating characteristics curve. The proposed method
    however has a disadvantage that requires images meeting certain prerequisite such
    as open eyes or visual teeth.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 深伪检测方法主要依赖于假图像和真实图像或视频之间内在特征的伪影或不一致性。杨等人[[121](#bib.bib121)]提出了一种检测方法，通过观察包括头部方向和位置的3D头部姿态之间的差异来进行检测，这些姿态是基于中央面部区域68个面部标志估计的。检查3D头部姿态是因为深伪面部生成流程存在一个缺陷。提取的特征被输入到SVM分类器中以获得检测结果。对两个数据集的实验表明，所提出的方法在与竞争方法相比时表现出色。第一个数据集，即UADFV，包含49个深伪视频及其相应的真实视频[[121](#bib.bib121)]。第二个数据集包括241张真实图像和252张深伪图像，这是DARPA
    MediFor GAN图像/视频挑战[[129](#bib.bib129)]中使用的数据子集。同样，在[[130](#bib.bib130)]中研究了一种利用基于眼睛、牙齿和面部轮廓的视觉特征的深伪和面部操控伪影的方法。视觉伪影源于缺乏全局一致性、错误或不精确的光照估计，或不精确的底层几何估计。对于深伪检测，利用了眼睛和牙齿区域的缺失反射和缺失细节，以及基于面部标志提取的面部区域纹理特征。因此，使用了眼部特征向量、牙齿特征向量和从全脸裁剪中提取的特征。在提取特征后，使用了包括逻辑回归和小型神经网络在内的两个分类器来区分深伪和真实视频。在YouTube下载的视频数据集上的实验表明，在接收者操作特征曲线下面积方面，取得了0.851的最佳结果。然而，所提出的方法有一个缺点，即需要满足某些先决条件的图像，例如睁开的眼睛或可见的牙齿。
- en: The use of photo response non uniformity (PRNU) analysis was proposed in [[131](#bib.bib131)]
    to detect deepfakes from authentic ones. PRNU is a component of sensor pattern
    noise, which is attributed to the manufacturing imperfection of silicon wafers
    and the inconsistent sensitivity of pixels to light because of the variation of
    the physical characteristics of the silicon wafers. The PRNU analysis is widely
    used in image forensics [[132](#bib.bib132), [133](#bib.bib133), [134](#bib.bib134),
    [135](#bib.bib135), [136](#bib.bib136)] and advocated to use in [[131](#bib.bib131)]
    because the swapped face is supposed to alter the local PRNU pattern in the facial
    area of video frames. The videos are converted into frames, which are cropped
    to the questioned facial region. The cropped frames are then separated sequentially
    into eight groups where an average PRNU pattern is computed for each group. Normalised
    cross correlation scores are calculated for comparisons of PRNU patterns among
    these groups. A test dataset was created, consisting of 10 authentic videos and
    16 manipulated videos, where the fake videos were produced from the genuine ones
    by the DeepFaceLab tool [[38](#bib.bib38)]. The analysis shows a significant statistical
    difference in terms of mean normalised cross correlation scores between deepfakes
    and the genuine. This analysis therefore suggests that PRNU has a potential in
    deepfake detection although a larger dataset would need to be tested.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[131](#bib.bib131)]中提出了使用光响应不均匀性（PRNU）分析来区分深度伪造和真实视频。PRNU 是传感器模式噪声的一部分，这归因于硅晶圆的制造缺陷以及由于硅晶圆物理特性的变化而导致的像素对光的敏感性不一致。PRNU
    分析在图像取证中被广泛使用 [[132](#bib.bib132), [133](#bib.bib133), [134](#bib.bib134), [135](#bib.bib135),
    [136](#bib.bib136)]，并在[[131](#bib.bib131)]中被提倡使用，因为交换的面孔可能会改变视频帧中面部区域的局部 PRNU
    模式。视频被转换成帧，并裁剪到有问题的面部区域。裁剪后的帧随后按顺序分为八组，每组计算一个平均 PRNU 模式。计算归一化互相关分数以比较这些组之间的 PRNU
    模式。创建了一个测试数据集，包括 10 个真实视频和 16 个操纵视频，其中伪造视频由 DeepFaceLab 工具 [[38](#bib.bib38)]
    从真实视频中生成。分析显示，深度伪造和真实视频之间的均值归一化互相关分数存在显著统计差异。因此，这项分析表明 PRNU 在深度伪造检测中具有潜力，尽管需要测试更大的数据集。
- en: When seeing a video or image with suspicion, users normally want to search for
    its origin. However, there is currently no feasibility for such a tool. Hasan
    and Salah [[137](#bib.bib137)] proposed the use of blockchain and smart contracts
    to help users detect deepfake videos based on the assumption that videos are only
    real when their sources are traceable. Each video is associated with a smart contract
    that links to its parent video and each parent video has a link to its child in
    a hierarchical structure. Through this chain, users can credibly trace back to
    the original smart contract associated with pristine video even if the video has
    been copied multiple times. An important attribute of the smart contract is the
    unique hashes of the interplanetary file system, which is used to store video
    and its metadata in a decentralized and content-addressable manner [[138](#bib.bib138)].
    The smart contract’s key features and functionalities are tested against several
    common security challenges such as distributed denial of services, replay and
    man in the middle attacks to ensure the solution meeting security requirements.
    This approach is generic, and it can be extended to other types of digital content,
    e.g., images, audios and manuscripts.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户对视频或图像产生怀疑时，通常希望查找其来源。然而，目前没有这样的工具可供使用。Hasan 和 Salah [[137](#bib.bib137)]
    提出了使用区块链和智能合约来帮助用户检测深度伪造视频的建议，前提是视频只有在其来源可追溯时才被认为是真实的。每个视频都与一个智能合约相关联，该合约链接到其母视频，每个母视频在层级结构中都有一个链接到其子视频。通过这一链条，即使视频被复制多次，用户也可以可靠地追溯到与原始视频相关联的智能合约。智能合约的一个重要属性是星际文件系统的唯一哈希值，该系统用于以去中心化和内容可寻址的方式存储视频及其元数据
    [[138](#bib.bib138)]。智能合约的关键特性和功能经过了多种常见安全挑战的测试，如分布式拒绝服务、重放和中间人攻击，以确保解决方案满足安全要求。这种方法是通用的，可以扩展到其他类型的数字内容，例如图像、音频和手稿。
- en: 'Table 2: Summary of prominent deepfake detection methods'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：主要深度伪造检测方法的总结
- en: '| Methods | Classifiers/ Techniques | Key Features | Dealing with | Datasets
    Used |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 分类器/技术 | 主要特征 | 处理方式 | 使用的数据集 |'
- en: '| Eye blinking [[114](#bib.bib114)] | LRCN | - Use LRCN to learn the temporal
    patterns of eye blinking. - Based on the observation that blinking frequency of
    deepfakes is much smaller than normal. | Videos | Consist of 49 interview and
    presentation videos, and their corresponding generated deepfakes. |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 眼睑眨动 [[114](#bib.bib114)] | LRCN | - 使用 LRCN 学习眼睑眨动的时间模式。 - 基于观察到的 deepfake
    的眨眼频率远低于正常水平。 | 视频 | 包含 49 个采访和演讲视频及其相应生成的 deepfake。 |'
- en: '| Intra-frame and temporal inconsistencies [[112](#bib.bib112)] | CNN and LSTM
    | CNN is employed to extract frame-level features, which are distributed to LSTM
    to construct sequence descriptor useful for classification. | Videos | A collection
    of 600 videos obtained from multiple websites. |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 帧内和时间不一致性 [[112](#bib.bib112)] | CNN 和 LSTM | CNN 被用来提取帧级特征，这些特征分发给 LSTM
    以构建对分类有用的序列描述符。 | 视频 | 从多个网站获得的 600 个视频集合。 |'
- en: '| Using face warping artifacts [[120](#bib.bib120)] | VGG16 [[119](#bib.bib119)],
    ResNet models [[118](#bib.bib118)] | Artifacts are discovered using CNN models
    based on resolution inconsistency between the warped face area and the surrounding
    context. | Videos | - UADFV [[121](#bib.bib121)], containing 49 real videos and
    49 fake videos with 32752 frames in total. - DeepfakeTIMIT [[69](#bib.bib69)]
    |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 使用面部变形伪影 [[120](#bib.bib120)] | VGG16 [[119](#bib.bib119)], ResNet 模型 [[118](#bib.bib118)]
    | 通过 CNN 模型发现伪影，这些模型基于变形面部区域与周围背景之间的分辨率不一致性。 | 视频 | - UADFV [[121](#bib.bib121)]，包含
    49 个真实视频和 49 个伪造视频，总共有 32752 帧。 - DeepfakeTIMIT [[69](#bib.bib69)] |'
- en: '| MesoNet [[102](#bib.bib102)] | CNN | - Two deep networks, i.e. Meso-4 and
    MesoInception-4 are introduced to examine deepfake videos at the mesoscopic analysis
    level. - Accuracy obtained on deepfake and FaceForensics datasets are 98% and
    95% respectively. | Videos | Two datasets: deepfake one constituted from online
    videos and the FaceForensics one created by the Face2Face approach [[52](#bib.bib52)].
    |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| MesoNet [[102](#bib.bib102)] | CNN | - 引入了两个深度网络，即 Meso-4 和 MesoInception-4，以在中观分析水平上检查
    deepfake 视频。 - 在 deepfake 和 FaceForensics 数据集上获得的准确率分别为 98% 和 95%。 | 视频 | 两个数据集：一个是由在线视频构成的
    deepfake 数据集，另一个是由 Face2Face 方法 [[52](#bib.bib52)] 创建的 FaceForensics 数据集。 |'
- en: '| Eye, teach and facial texture [[130](#bib.bib130)] | Logistic regression
    and neural network (NN) | - Exploit facial texture differences, and missing reflections
    and details in eye and teeth areas of deepfakes. - Logistic regression and NN
    are used for classifying. | Videos | A video dataset downloaded from YouTube.
    |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 眼睛、牙齿和面部纹理 [[130](#bib.bib130)] | 逻辑回归和神经网络 (NN) | - 利用深度伪造中面部纹理的差异以及眼睛和牙齿区域的缺失反射和细节。
    - 使用逻辑回归和 NN 进行分类。 | 视频 | 从 YouTube 下载的视频数据集。 |'
- en: '| Spatio-temporal features with RCN [[103](#bib.bib103)] | RCN | Temporal discrepancies
    across frames are explored using RCN that integrates convolutional network DenseNet
    [[61](#bib.bib61)] and the gated recurrent unit cells [[111](#bib.bib111)] | Videos
    | FaceForensics++ dataset, including 1,000 videos [[105](#bib.bib105)]. |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 使用 RCN 的时空特征 [[103](#bib.bib103)] | RCN | 通过整合卷积网络 DenseNet [[61](#bib.bib61)]
    和门控递归单元 (GRU) 的 RCN 探索帧间的时间差异。 | 视频 | FaceForensics++ 数据集，包括 1,000 个视频 [[105](#bib.bib105)]。'
- en: '| Spatio-temporal features with LSTM [[139](#bib.bib139)] | Convolutional bidirectional
    recurrent LSTM network | - An XceptionNet CNN is used for facial feature extraction
    while audio embeddings are obtained by stacking multiple convolution modules.
    - Two loss functions, i.e. cross-entropy and Kullback-Leibler divergence, are
    used. | Videos | FaceForensics++ [[105](#bib.bib105)] and Celeb-DF (5,639 deepfake
    videos) [[107](#bib.bib107)] datasets and the ASVSpoof 2019 Logical Access audio
    dataset [[140](#bib.bib140)]. |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 使用 LSTM 的时空特征 [[139](#bib.bib139)] | 卷积双向递归 LSTM 网络 | - 使用 XceptionNet CNN
    进行面部特征提取，同时通过堆叠多个卷积模块获得音频嵌入。 - 使用两个损失函数，即交叉熵和 Kullback-Leibler 散度。 | 视频 | FaceForensics++
    [[105](#bib.bib105)] 和 Celeb-DF（5,639 个 deepfake 视频） [[107](#bib.bib107)] 数据集以及
    ASVSpoof 2019 Logical Access 音频数据集 [[140](#bib.bib140)]。 |'
- en: '| Analysis of PRNU [[131](#bib.bib131)] | PRNU | - Analysis of noise patterns
    of light sensitive sensors of digital cameras due to their factory defects. -
    Explore the differences of PRNU patterns between the authentic and deepfake videos
    because face swapping is believed to alter the local PRNU patterns. | Videos |
    Created by the authors, including 10 authentic and 16 deepfake videos using DeepFaceLab
    [[38](#bib.bib38)]. |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| PRNU 分析 [[131](#bib.bib131)] | PRNU | - 分析数字相机由于工厂缺陷而产生的光敏传感器的噪声模式。 - 探索真实视频与深度伪造视频之间
    PRNU 模式的差异，因为面部替换被认为会改变局部 PRNU 模式。 | 视频 | 由作者创建，包括 10 个真实视频和 16 个使用 DeepFaceLab
    [[38](#bib.bib38)] 制作的深度伪造视频。 |'
- en: '| Phoneme-viseme mismatches [[141](#bib.bib141)] | CNN | - Exploit the mismatches
    between the dynamics of the mouth shape, i.e. visemes, with a spoken phoneme.
    - Focus on sounds associated with the M, B and P phonemes as they require complete
    mouth closure while deepfakes often incorrectly synthesize it. | Videos | Four
    in-the-wild lip-sync deepfakes from Instagram and YouTube (www.instagram.com/bill_posters_uk
    and youtu.be/VWMEDacz3L4) and others are created using synthesis techniques, i.e.
    Audio-to-Video (A2V) [[68](#bib.bib68)] and Text-to-Video (T2V) [[142](#bib.bib142)].
    |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 音素-视觉音素不匹配 [[141](#bib.bib141)] | CNN | - 利用口型（即视觉音素）与发音音素之间的动态不匹配。 - 关注
    M、B 和 P 音素相关的声音，因为它们需要完全闭合的嘴唇，而深度伪造技术往往不正确地合成这些声音。 | 视频 | 从 Instagram 和 YouTube（www.instagram.com/bill_posters_uk
    和 youtu.be/VWMEDacz3L4）获取的四个真实环境下的唇同步深度伪造视频，以及其他利用合成技术（即音频到视频 (A2V) [[68](#bib.bib68)]
    和文本到视频 (T2V) [[142](#bib.bib142)]）创建的视频。 |'
- en: '| Using attribution-based confidence (ABC) metric [[143](#bib.bib143)] | ResNet50
    model [[118](#bib.bib118)], pre-trained on VGGFace2 [[144](#bib.bib144)] | - The
    ABC metric [[145](#bib.bib145)] is used to detect deepfake videos without accessing
    to training data. - ABC values obtained for original videos are greater than 0.94
    while those of deepfakes have low ABC values. | Videos | VidTIMIT and two other
    original datasets obtained from the COHFACE (https://www.idiap.ch/dataset/cohface)
    and from YouTube. datasets from COHFACE [[146](#bib.bib146)] and YouTube are used
    to generate two deepfake datasets by commercial website https://deepfakesweb.com
    and another deepfake dataset is DeepfakeTIMIT [[147](#bib.bib147)]. |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 使用基于归属的置信度 (ABC) 指标 [[143](#bib.bib143)] | ResNet50 模型 [[118](#bib.bib118)]，预训练于
    VGGFace2 [[144](#bib.bib144)] | - 使用 ABC 指标 [[145](#bib.bib145)] 来检测深度伪造视频，而无需访问训练数据。
    - 原始视频的 ABC 值大于 0.94，而深度伪造视频的 ABC 值较低。 | 视频 | VidTIMIT 和两个从 COHFACE (https://www.idiap.ch/dataset/cohface)
    和 YouTube 获取的原始数据集。COHFACE [[146](#bib.bib146)] 和 YouTube 数据集用于通过商业网站 https://deepfakesweb.com
    生成两个深度伪造数据集，另一个深度伪造数据集是 DeepfakeTIMIT [[147](#bib.bib147)]。 |'
- en: '| Using appearance and behaviour [[148](#bib.bib148)] | Rules based on facial
    and behavioural features. | Temporal, behavioral biometric based on facial expressions
    and head movements are learned using ResNet-101 [[118](#bib.bib118)] while static
    facial biometric is obtained using VGG [[65](#bib.bib65)]. | Videos | The world
    leaders dataset [[1](#bib.bib1)], FaceForensics++ [[105](#bib.bib105)], Google/Jigsaw
    deepfake detection dataset [[106](#bib.bib106)], DFDC [[109](#bib.bib109)] and
    Celeb-DF [[107](#bib.bib107)]. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 使用外观和行为 [[148](#bib.bib148)] | 基于面部和行为特征的规则。 | 通过 ResNet-101 [[118](#bib.bib118)]
    学习面部表情和头部运动的时间性行为生物特征，而静态面部生物特征则使用 VGG [[65](#bib.bib65)] 获得。 | 视频 | 世界领导人数据集
    [[1](#bib.bib1)]、FaceForensics++ [[105](#bib.bib105)]、Google/Jigsaw 深度伪造检测数据集
    [[106](#bib.bib106)]、DFDC [[109](#bib.bib109)] 和 Celeb-DF [[107](#bib.bib107)]。
    |'
- en: '| FakeCatcher [[149](#bib.bib149)] | CNN | Extract biological signals in portrait
    videos and use them as an implicit descriptor of authenticity because they are
    not spatially and temporally well-preserved in deepfakes. | Videos | UADFV [[121](#bib.bib121)],
    FaceForensics [[127](#bib.bib127)], FaceForensics++ [[105](#bib.bib105)], Celeb-DF
    [[107](#bib.bib107)], and a new dataset of 142 videos, independent of the generative
    model, resolution, compression, content, and context. |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| FakeCatcher [[149](#bib.bib149)] | CNN | 提取肖像视频中的生物信号，并将其用作真实性的隐式描述，因为这些信号在深度伪造中空间和时间上都不被很好地保留。
    | 视频 | UADFV [[121](#bib.bib121)]、FaceForensics [[127](#bib.bib127)]、FaceForensics++
    [[105](#bib.bib105)]、Celeb-DF [[107](#bib.bib107)] 和一个包含 142 个视频的新数据集，独立于生成模型、分辨率、压缩、内容和背景。
    |'
- en: '| Emotion audio-visual affective cues [[150](#bib.bib150)] | Siamese network
    [[86](#bib.bib86)] | Modality and emotion embedding vectors for the face and speech
    are extracted for deepfake detection. | Videos | DeepfakeTIMIT [[147](#bib.bib147)]
    and DFDC [[109](#bib.bib109)]. |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 情感音频-视觉情感线索 [[150](#bib.bib150)] | 连体网络 [[86](#bib.bib86)] | 提取面部和语音的模态与情感嵌入向量用于深度伪造检测。
    | 视频 | DeepfakeTIMIT [[147](#bib.bib147)] 和 DFDC [[109](#bib.bib109)]。 |'
- en: '| Head poses [[121](#bib.bib121)] | SVM | - Features are extracted using 68
    landmarks of the face region. - Use SVM to classify using the extracted features.
    | Videos/ Images | - UADFV consists of 49 deep fake videos and their respective
    real videos. - 241 real images and 252 deep fake images from DARPA MediFor GAN
    Image/Video Challenge. |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 头部姿势 [[121](#bib.bib121)] | SVM | - 使用面部区域的 68 个标记点提取特征。 - 使用 SVM 对提取的特征进行分类。
    | 视频/ 图像 | - UADFV 包含 49 个深度伪造视频及其对应的真实视频。 - 241 张真实图像和 252 张深度伪造图像来自 DARPA MediFor
    GAN 图像/视频挑战。 |'
- en: '| Capsule-forensics [[123](#bib.bib123)] | Capsule networks | - Latent features
    extracted by VGG-19 network [[119](#bib.bib119)] are fed into the capsule network
    for classification. - A dynamic routing algorithm [[125](#bib.bib125)] is used
    to route the outputs of three convolutional capsules to two output capsules, one
    for fake and another for real images, through a number of iterations. | Videos/
    Images | Four datasets: the Idiap Research Institute replay-attack [[126](#bib.bib126)],
    deepfake face swapping by [[102](#bib.bib102)], facial reenactment FaceForensics
    [[127](#bib.bib127)], and fully computer-generated image set using [[128](#bib.bib128)].
    |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 胶囊取证 [[123](#bib.bib123)] | 胶囊网络 | - 由 VGG-19 网络 [[119](#bib.bib119)] 提取的潜在特征被输入到胶囊网络中进行分类。
    - 使用动态路由算法 [[125](#bib.bib125)] 将三个卷积胶囊的输出路由到两个输出胶囊，一个用于伪造图像，另一个用于真实图像，通过多个迭代完成。
    | 视频/ 图像 | 四个数据集：Idiap 研究所重放攻击 [[126](#bib.bib126)]，深度伪造人脸交换 [[102](#bib.bib102)]，面部重演
    FaceForensics [[127](#bib.bib127)]，以及完全计算机生成的图像集 [[128](#bib.bib128)]。'
- en: '| Methods | Classifiers/ Techniques | Key Features | Dealing with | Datasets
    Used |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 分类器/技术 | 关键特征 | 处理对象 | 使用的数据集 |'
- en: '| Preprocessing combined with deep network [[74](#bib.bib74)] | DCGAN, WGAN-GP
    and PGGAN. | - Enhance generalization ability of deep learning models to detect
    GAN generated images. - Remove low level features of fake images.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '| 预处理结合深度网络 [[74](#bib.bib74)] | DCGAN、WGAN-GP 和 PGGAN。 | - 提高深度学习模型检测 GAN
    生成图像的泛化能力。 - 移除伪造图像的低级特征。 |'
- en: '- Force deep networks to focus more on pixel level similarity between fake
    and real images to improve generalization ability. | Images | - Real dataset:
    CelebA-HQ [[62](#bib.bib62)], including high quality face images of 1024x1024
    resolution. - Fake datasets: generated by DCGAN [[88](#bib.bib88)], WGAN-GP [[90](#bib.bib90)]
    and PGGAN [[62](#bib.bib62)]. |'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '- 强迫深度网络更加关注伪造图像与真实图像之间的像素级相似性，以提高泛化能力。 | 图像 | - 真实数据集：CelebA-HQ [[62](#bib.bib62)]，包含分辨率为
    1024x1024 的高质量人脸图像。 - 伪造数据集：由 DCGAN [[88](#bib.bib88)]、WGAN-GP [[90](#bib.bib90)]
    和 PGGAN [[62](#bib.bib62)] 生成。 |'
- en: '| Analyzing convolutional traces [[151](#bib.bib151)] | KNN, SVM, and linear
    discriminant analysis (LDA) | Using expectation-maximization algorithm to extract
    local features pertaining to convolutional generative process of GAN-based image
    deepfake generators. | Images | Authentic images from CelebA and corresponding
    deepfakes are created by five different GANs (group-wise deep whitening-and-coloring
    transformation GDWCT [[152](#bib.bib152)], StarGAN [[153](#bib.bib153)], AttGAN
    [[154](#bib.bib154)], StyleGAN [[51](#bib.bib51)], StyleGAN2 [[155](#bib.bib155)]).
    |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 分析卷积痕迹 [[151](#bib.bib151)] | KNN, SVM 和线性判别分析 (LDA) | 使用期望最大化算法提取与 GAN 基于图像深度伪造生成器的卷积生成过程相关的局部特征。
    | 图像 | 从 CelebA 获取的真实图像及由五种不同 GAN（分组深度白化和着色变换 GDWCT [[152](#bib.bib152)]，StarGAN
    [[153](#bib.bib153)]，AttGAN [[154](#bib.bib154)]，StyleGAN [[51](#bib.bib51)]，StyleGAN2
    [[155](#bib.bib155)]）生成的对应深度伪造图像。 |'
- en: '| Bag of words and shallow classifiers [[78](#bib.bib78)] | SVM, RF, MLP |
    Extract discriminant features using bag of words method and feed these features
    into SVM, RF and MLP for binary classification: innocent vs fabricated. | Images
    | The well-known LFW face database [[156](#bib.bib156)], containing 13,223 images
    with resolution of 250x250. |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 词袋模型和浅层分类器 [[78](#bib.bib78)] | SVM, RF, MLP | 使用词袋模型提取判别特征，并将这些特征输入到 SVM、RF
    和 MLP 中进行二分类：真实与伪造。 | 图像 | 著名的 LFW 人脸数据库 [[156](#bib.bib156)]，包含 13,223 张分辨率为
    250x250 的图像。 |'
- en: '| Pairwise learning [[85](#bib.bib85)] | CNN concatenated to CFFN | Two-phase
    procedure: feature extraction using CFFN based on the Siamese network architecture
    [[86](#bib.bib86)] and classification using CNN. | Images | - Face images: real
    ones from CelebA [[87](#bib.bib87)], and fake ones generated by DCGAN [[88](#bib.bib88)],
    WGAN [[89](#bib.bib89)], WGAN-GP [[90](#bib.bib90)], least squares GAN [[91](#bib.bib91)],
    and PGGAN [[62](#bib.bib62)]. - General images: real ones from ILSVRC12 [[92](#bib.bib92)],
    and fake ones generated by BIGGAN [[93](#bib.bib93)], self-attention GAN [[94](#bib.bib94)]
    and spectral normalization GAN [[95](#bib.bib95)]. |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 成对学习 [[85](#bib.bib85)] | CNN 与 CFFN 连接 | 两阶段程序：基于 Siamese 网络架构 [[86](#bib.bib86)]
    使用 CFFN 进行特征提取，并使用 CNN 进行分类。 | 图像 | - 面部图像：来自 CelebA [[87](#bib.bib87)] 的真实图像，以及由
    DCGAN [[88](#bib.bib88)], WGAN [[89](#bib.bib89)], WGAN-GP [[90](#bib.bib90)],
    最小二乘 GAN [[91](#bib.bib91)] 和 PGGAN [[62](#bib.bib62)] 生成的假图像。 - 一般图像：来自 ILSVRC12
    [[92](#bib.bib92)] 的真实图像，以及由 BIGGAN [[93](#bib.bib93)], 自注意力 GAN [[94](#bib.bib94)]
    和光谱归一化 GAN [[95](#bib.bib95)] 生成的假图像。 |'
- en: '| Defenses against adversarial perturbations in deepfakes [[157](#bib.bib157)]
    | VGG [[65](#bib.bib65)] and ResNet [[118](#bib.bib118)] | - Introduce adversarial
    perturbations to enhance deepfakes and fool deepfake detectors. - Improve accuracy
    of deepfake detectors using Lipschitz regularization and deep image prior techniques.
    | Images | 5,000 real images from CelebA [[87](#bib.bib87)] and 5,000 fake images
    created by the “Few-Shot Face Translation GAN” method [[158](#bib.bib158)]. |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 针对深度伪造中的对抗性扰动的防御 [[157](#bib.bib157)] | VGG [[65](#bib.bib65)] 和 ResNet [[118](#bib.bib118)]
    | - 引入对抗性扰动以增强深度伪造并欺骗深度伪造检测器。 - 使用 Lipschitz 正则化和深度图像先验技术提高深度伪造检测器的准确性。 | 图像 |
    从 CelebA [[87](#bib.bib87)] 获得的 5,000 张真实图像和由“Few-Shot Face Translation GAN”方法
    [[158](#bib.bib158)] 生成的 5,000 张假图像。 |'
- en: '| Face X-ray [[159](#bib.bib159)] | CNN | - Try to locate the blending boundary
    between the target and original faces instead of capturing the synthesized artifacts
    of specific manipulations. - Can be trained without fake images. | Images | FaceForensics++
    [[105](#bib.bib105)], DeepfakeDetection (DFD) [[106](#bib.bib106)], DFDC [[109](#bib.bib109)]
    and Celeb-DF [[107](#bib.bib107)]. |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 面部 X 射线 [[159](#bib.bib159)] | CNN | - 尝试定位目标和原始面部之间的混合边界，而不是捕捉特定操作的合成伪影。
    - 可以在没有假图像的情况下进行训练。 | 图像 | FaceForensics++ [[105](#bib.bib105)], DeepfakeDetection
    (DFD) [[106](#bib.bib106)], DFDC [[109](#bib.bib109)] 和 Celeb-DF [[107](#bib.bib107)]。
    |'
- en: '| Using common artifacts of CNN-generated images [[160](#bib.bib160)] | ResNet-50
    [[118](#bib.bib118)] pre-trained with ImageNet [[92](#bib.bib92)] | Train the
    classifier using a large number of fake images generated by a high-performing
    unconditional GAN model, i.e., PGGAN [[62](#bib.bib62)] and evaluate how well
    the classifier generalizes to other CNN-synthesized images. | Images | A new dataset
    of CNN-generated images, namely ForenSynths, consisting of synthesized images
    from 11 models such as StyleGAN [[51](#bib.bib51)], super-resolution methods [[161](#bib.bib161)]
    and FaceForensics++ [[105](#bib.bib105)]. |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 使用 CNN 生成图像的常见伪影 [[160](#bib.bib160)] | 用 ImageNet [[92](#bib.bib92)] 预训练的
    ResNet-50 [[118](#bib.bib118)] | 使用大量由高性能无条件 GAN 模型生成的假图像来训练分类器，即 PGGAN [[62](#bib.bib62)]
    并评估分类器对其他 CNN 合成图像的泛化能力。 | 图像 | 一个新的 CNN 生成图像数据集，名为 ForenSynths，由 11 个模型合成的图像组成，例如
    StyleGAN [[51](#bib.bib51)], 超分辨率方法 [[161](#bib.bib161)] 和 FaceForensics++ [[105](#bib.bib105)]。
    |'
- en: '| Using convolutional traces on GAN-based images [[162](#bib.bib162)] | KNN,
    SVM, and LDA | Training the expectation-maximization algorithm [[163](#bib.bib163)]
    to detect and extract discriminative features via a fingerprint that represents
    the convolutional traces left by GANs during image generation. | Images | A dataset
    of images generated by ten GAN models, including CycleGAN [[164](#bib.bib164)],
    StarGAN [[153](#bib.bib153)], AttGAN [[154](#bib.bib154)], GDWCT [[152](#bib.bib152)],
    StyleGAN [[51](#bib.bib51)], StyleGAN2 [[155](#bib.bib155)], PGGAN [[62](#bib.bib62)],
    FaceForensics++ [[105](#bib.bib105)], IMLE [[165](#bib.bib165)], and SPADE [[42](#bib.bib42)].
    |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 在基于 GAN 的图像上使用卷积痕迹 [[162](#bib.bib162)] | KNN、SVM 和 LDA | 训练期望最大化算法 [[163](#bib.bib163)]
    来检测和提取通过代表 GAN 在图像生成过程中留下的卷积痕迹的指纹的区分特征。 | 图像 | 十个 GAN 模型生成的图像数据集，包括 CycleGAN [[164](#bib.bib164)],
    StarGAN [[153](#bib.bib153)], AttGAN [[154](#bib.bib154)], GDWCT [[152](#bib.bib152)],
    StyleGAN [[51](#bib.bib51)], StyleGAN2 [[155](#bib.bib155)], PGGAN [[62](#bib.bib62)],
    FaceForensics++ [[105](#bib.bib105)], IMLE [[165](#bib.bib165)] 和 SPADE [[42](#bib.bib42)]。
    |'
- en: '| Using deep features extracted by CNN [[100](#bib.bib100)] | A new CNN model,
    namely SCnet | The CNN-based SCnet is able to automatically learn high-level forensics
    features of image data thanks to a hierarchical feature extraction block, which
    is formed by stacking four convolutional layers. | Images | A dataset of 321,378
    face images, created by applying the Glow model [[101](#bib.bib101)] to the CelebA
    face image dataset [[87](#bib.bib87)]. |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 使用CNN提取的深度特征[[100](#bib.bib100)] | 一种新的CNN模型，即SCnet | 基于CNN的SCnet能够自动学习图像数据的高层次取证特征，这得益于一个由四层卷积层堆叠而成的层次化特征提取模块。
    | 图像 | 一个包含321,378张面部图像的数据集，该数据集通过将Glow模型[[101](#bib.bib101)]应用于CelebA面部图像数据集[[87](#bib.bib87)]创建。
    |'
- en: 4 Discussions and Future Research Directions
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 讨论与未来研究方向
- en: 'With the support of deep learning, deepfakes can be created easier than ever
    before. The spread of these fake contents is also quicker thanks to the development
    of social media platforms [[166](#bib.bib166)]. Sometimes deepfakes do not need
    to be spread to massive audience to cause detrimental effects. People who create
    deepfakes with malicious purpose only need to deliver them to target audiences
    as part of their sabotage strategy without using social media. For example, this
    approach can be utilized by intelligence services trying to influence decisions
    made by important people such as politicians, leading to national and international
    security threats [[167](#bib.bib167)]. Catching the deepfake alarming problem,
    research community has focused on developing deepfake detection algorithms and
    numerous results have been reported. This paper has reviewed the state-of-the-art
    methods and a summary of typical approaches is provided in Table [2](#S3.T2 "Table
    2 ‣ Shallow classifiers ‣ 3.2.2 Visual Artifacts within Video Frame ‣ 3.2 Fake
    Video Detection ‣ 3 Deepfake Detection ‣ Deep Learning for Deepfakes Creation
    and Detection: A Survey"). It is noticeable that a battle between those who use
    advanced machine learning to create deepfakes with those who make effort to detect
    deepfakes is growing.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '在深度学习的支持下，制造深度伪造变得比以往更容易。由于社交媒体平台的发展，这些虚假内容的传播也变得更快[[166](#bib.bib166)]。有时深度伪造不需要传播到大量观众即可产生有害效果。那些恶意制造深度伪造的人只需将其传递给目标受众作为其破坏策略的一部分，而无需使用社交媒体。例如，这种方法可以被情报部门利用，以影响政治家等重要人物的决策，从而导致国家和国际安全威胁[[167](#bib.bib167)]。针对深度伪造的警示性问题，研究界专注于开发深度伪造检测算法，并报告了大量结果。本文回顾了最先进的方法，并在表[2](#S3.T2
    "Table 2 ‣ Shallow classifiers ‣ 3.2.2 Visual Artifacts within Video Frame ‣ 3.2
    Fake Video Detection ‣ 3 Deepfake Detection ‣ Deep Learning for Deepfakes Creation
    and Detection: A Survey")中提供了典型方法的总结。值得注意的是，使用先进机器学习来制造深度伪造的人与努力检测深度伪造的人之间的竞争越来越激烈。'
- en: Deepfakes’ quality has been increasing and the performance of detection methods
    needs to be improved accordingly. The inspiration is that what AI has broken can
    be fixed by AI as well [[168](#bib.bib168)]. Detection methods are still in their
    early stage and various methods have been proposed and evaluated but using fragmented
    datasets. An approach to improve performance of detection methods is to create
    a growing updated benchmark dataset of deepfakes to validate the ongoing development
    of detection methods. This will facilitate the training process of detection models,
    especially those based on deep learning, which requires a large training set [[108](#bib.bib108)].
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造的质量不断提高，检测方法的性能需要相应改进。灵感在于AI所破坏的东西也可以通过AI修复[[168](#bib.bib168)]。检测方法仍处于早期阶段，提出并评估了各种方法，但使用的是碎片化的数据集。提高检测方法性能的一种方法是创建一个不断更新的深度伪造基准数据集，以验证检测方法的持续发展。这将有助于检测模型的训练过程，特别是那些基于深度学习的模型，它们需要大量的训练集[[108](#bib.bib108)]。
- en: Improving performance of deepfake detection methods is important, especially
    in cross-forgery and cross-dataset scenarios. Most detection models are designed
    and evaluated in the same-forgery and in-dataset experiments, which do not ensure
    their generalization capability. Some previous studies have addressed this issue,
    e.g., in [[160](#bib.bib160), [116](#bib.bib116), [104](#bib.bib104), [169](#bib.bib169),
    [170](#bib.bib170)], but more work needs to be done in this direction. A model
    trained on a specific forgery needs to be able to work against another unknown
    one because potential deepfake types are not normally known in the real-world
    scenarios. Likewise, current detection methods mostly focus on drawbacks of the
    deepfake generation pipelines, i.e., finding weakness of the competitors to attack
    them. This kind of information and knowledge is not always available in adversarial
    environments where attackers commonly attempt not to reveal such deepfake creation
    technologies. Recent works on adversarial perturbation attacks to fool DNN-based
    detectors make the deepfake detection task more difficult [[157](#bib.bib157),
    [171](#bib.bib171), [172](#bib.bib172), [173](#bib.bib173), [174](#bib.bib174)].
    These are real challenges for detection method development and a future study
    needs to focus on introducing more robust, scalable and generalizable methods.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 提高深伪检测方法的性能非常重要，特别是在跨伪造和跨数据集的场景中。大多数检测模型都是在同一伪造和数据集实验中设计和评估的，这并不能保证它们的泛化能力。一些以前的研究已经解决了这个问题，例如[[160](#bib.bib160)、[116](#bib.bib116)、[104](#bib.bib104)、[169](#bib.bib169)、[170](#bib.bib170)]，但在这个方向上还需要更多的工作。一个在特定伪造上训练的模型需要能够对抗另一种未知的伪造类型，因为在实际场景中，潜在的深伪类型通常是不知道的。同样，目前的检测方法大多集中于深伪生成管道的缺陷，即找出竞争对手的弱点以攻击它们。这种信息和知识在对抗性环境中并不总是可用，因为攻击者通常试图不透露这些深伪创建技术。最近对抗性扰动攻击以欺骗基于DNN的检测器的工作，使得深伪检测任务变得更加困难[[157](#bib.bib157)、[171](#bib.bib171)、[172](#bib.bib172)、[173](#bib.bib173)、[174](#bib.bib174)]。这些是真实的检测方法开发挑战，未来的研究需要专注于引入更强大、可扩展和具有泛化能力的方法。
- en: Another research direction is to integrate detection methods into distribution
    platforms such as social media to increase its effectiveness in dealing with the
    widespread impact of deepfakes. The screening or filtering mechanism using effective
    detection methods can be implemented on these platforms to ease the deepfakes
    detection [[167](#bib.bib167)]. Legal requirements can be made for tech companies
    who own these platforms to remove deepfakes quickly to reduce its impacts. In
    addition, watermarking tools can also be integrated into devices that people use
    to make digital contents to create immutable metadata for storing originality
    details such as time and location of multimedia contents as well as their untampered
    attestment [[167](#bib.bib167)]. This integration is difficult to implement but
    a solution for this could be the use of the disruptive blockchain technology.
    The blockchain has been used effectively in many areas and there are very few
    studies so far addressing the deepfake detection problems based on this technology.
    As it can create a chain of unique unchangeable blocks of metadata, it is a great
    tool for digital provenance solution. The integration of blockchain technologies
    to this problem has demonstrated certain results [[137](#bib.bib137)] but this
    research direction is far from mature.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个研究方向是将检测方法集成到分发平台如社交媒体中，以提高其在应对深伪广泛影响方面的效果。可以在这些平台上实施使用有效检测方法的筛选或过滤机制，以便简化深伪检测[[167](#bib.bib167)]。可以对拥有这些平台的科技公司制定法律要求，以快速移除深伪内容，减少其影响。此外，水印工具也可以集成到人们用于创建数字内容的设备中，以创建不可更改的元数据，用于存储原创性细节，如多媒体内容的时间和地点以及其未经篡改的认证[[167](#bib.bib167)]。这种集成实施起来困难，但一个解决方案可能是使用颠覆性的区块链技术。区块链在许多领域中已经被有效使用，目前只有少数研究基于这一技术解决深伪检测问题。由于它能够创建一链独特的不可更改的元数据块，因此它是数字来源解决方案的绝佳工具。将区块链技术集成到这个问题中已经展示了一定的结果[[137](#bib.bib137)]，但这一研究方向仍然远未成熟。
- en: Using detection methods to spot deepfakes is crucial, but understanding the
    real intent of people publishing deepfakes is even more important. This requires
    the judgement of users based on social context in which deepfake is discovered,
    e.g. who distributed it and what they said about it [[175](#bib.bib175)]. This
    is critical as deepfakes are getting more and more photorealistic and it is highly
    anticipated that detection software will be lagging behind deepfake creation technology.
    A study on social context of deepfakes to assist users in such judgement is thus
    worth performing.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 使用检测方法来识别深度伪造内容是至关重要的，但理解发布深度伪造内容的人的真实意图更为重要。这需要用户根据发现深度伪造内容的社会背景进行判断，例如，谁分发了它以及他们对它的评价[[175](#bib.bib175)]。这点至关重要，因为深度伪造技术正变得越来越逼真，检测软件很可能会滞后于深度伪造技术的发展。因此，关于深度伪造的社会背景的研究，以帮助用户进行这种判断，是值得进行的。
- en: Videos and photographics have been widely used as evidences in police investigation
    and justice cases. They may be introduced as evidences in a court of law by digital
    media forensics experts who have background in computer or law enforcement and
    experience in collecting, examining and analysing digital information. The development
    of machine learning and AI technologies might have been used to modify these digital
    contents and thus the experts’ opinions may not be enough to authenticate these
    evidences because even experts are unable to discern manipulated contents. This
    aspect needs to take into account in courtrooms nowadays when images and videos
    are used as evidences to convict perpetrators because of the existence of a wide
    range of digital manipulation methods [[176](#bib.bib176)]. The digital media
    forensics results therefore must be proved to be valid and reliable before they
    can be used in courts. This requires careful documentation for each step of the
    forensics process and how the results are reached. Machine learning and AI algorithms
    can be used to support the determination of the authenticity of digital media
    and have obtained accurate and reliable results, e.g., [[177](#bib.bib177), [178](#bib.bib178)],
    but most of these algorithms are unexplainable. This creates a huge hurdle for
    the applications of AI in forensics problems because not only the forensics experts
    oftentimes do not have expertise in computer algorithms, but the computer professionals
    also cannot explain the results properly as most of these algorithms are black
    box models [[179](#bib.bib179)]. This is more critical as the most recent models
    with the most accurate results are based on deep learning methods consisting of
    many neural network parameters. Researchers have recently attempted to create
    white box and explainable detection methods. An example is the approach proposed
    by Giudice et al. [[180](#bib.bib180)] in which they use discrete cosine transform
    statistics to detect so-called specific GAN frequencies to differentiate between
    real images and deepfakes. Through the analysis of particular frequency statistics,
    that method can be used to mathematically explain whether a multimedia content
    is a deepfake and why it is. More research must be conducted in this area and
    explainable AI in computer vision therefore is a research direction that is needed
    to promote and utilize the advances and advantages of AI and machine learning
    in digital media forensics.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 视频和照片已广泛作为警方调查和司法案件中的证据。它们可以通过拥有计算机或执法背景并具备收集、检查和分析数字信息经验的数字媒体取证专家在法庭上作为证据引入。机器学习和AI技术的发展可能已被用来修改这些数字内容，因此专家的意见可能不足以验证这些证据，因为即使是专家也无法识别被操控的内容。在如今法庭上使用图像和视频作为定罪证据时，这一点需要被考虑，因为存在各种数字操控方法[[176](#bib.bib176)]。因此，数字媒体取证结果必须被证明是有效和可靠的，才能在法庭上使用。这要求对取证过程的每一步以及结果的形成过程进行详细记录。机器学习和AI算法可以用于支持数字媒体真实性的判断，并已获得准确和可靠的结果，例如[[177](#bib.bib177),
    [178](#bib.bib178)]，但大多数这些算法是不可解释的。这为AI在取证问题中的应用带来了巨大障碍，因为取证专家通常没有计算机算法的专业知识，而计算机专业人士也无法正确解释结果，因为大多数这些算法是黑箱模型[[179](#bib.bib179)]。这一点尤为重要，因为最新的、结果最准确的模型基于深度学习方法，包含许多神经网络参数。研究人员最近尝试创建可解释的检测方法。例如，Giudice等人提出的方法[[180](#bib.bib180)]中，他们使用离散余弦变换统计来检测所谓的特定GAN频率，以区分真实图像和深伪图像。通过分析特定频率统计，这种方法可以用数学方法解释多媒体内容是否为深伪图像以及原因。因此，需要在这一领域进行更多研究，并且计算机视觉中的可解释AI是推动和利用AI及机器学习在数字媒体取证中进步和优势的研究方向。
- en: 5 Conclusions
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: Deepfakes have begun to erode trust of people in media contents as seeing them
    is no longer commensurate with believing in them. They could cause distress and
    negative effects to those targeted, heighten disinformation and hate speech, and
    even could stimulate political tension, inflame the public, violence or war. This
    is especially critical nowadays as the technologies for creating deepfakes are
    increasingly approachable and social media platforms can spread those fake contents
    quickly. This survey provides a timely overview of deepfake creation and detection
    methods and presents a broad discussion on challenges, potential trends, and future
    directions in this area. This study therefore will be valuable for the artificial
    intelligence research community to develop effective methods for tackling deepfakes.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造技术已经开始侵蚀人们对媒体内容的信任，因为看到这些内容不再等同于相信它们。它们可能会对被针对者造成困扰和负面影响，加剧虚假信息和仇恨言论，甚至可能刺激政治紧张，煽动公众情绪、暴力或战争。由于创建深度伪造技术的门槛越来越低，社交媒体平台能够迅速传播这些虚假内容，这一点尤为关键。本综述提供了对深度伪造创建和检测方法的及时概述，并对该领域中的挑战、潜在趋势和未来方向进行了广泛讨论。因此，这项研究对人工智能研究社区在应对深度伪造方面的有效方法开发具有重要价值。
- en: Declaration of Competing Interest
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 竞争利益声明
- en: Authors declare no conflict of interest.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 作者声明没有利益冲突。
- en: References
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Agarwal et al. [2019] Shruti Agarwal, Hany Farid, Yuming Gu, Mingming He, Koki
    Nagano, and Hao Li. Protecting world leaders against deep fakes. In *Computer
    Vision and Pattern Recognition Workshops*, volume 1, pages 38–45, 2019.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agarwal 等人 [2019] 舒瑞提·阿加瓦尔、哈尼·法里德、余明明、何明明、小木·长野和李浩。保护世界领导者免受深度伪造的威胁。在*计算机视觉与模式识别研讨会*，第1卷，第38–45页，2019年。
- en: Vincent et al. [2008] Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine
    Manzagol. Extracting and composing robust features with denoising autoencoders.
    In *Proceedings of the 25th International Conference on Machine learning*, pages
    1096–1103, 2008.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vincent 等人 [2008] 帕斯卡·文森特、雨果·拉罗谢尔、约书亚·本吉奥和皮埃尔-安托万·曼扎戈尔。通过去噪自编码器提取和组合鲁棒特征。在*第25届国际机器学习会议录*，第1096–1103页，2008年。
- en: Kingma and Welling [2013] Diederik P Kingma and Max Welling. Auto-encoding variational
    Bayes. *arXiv preprint arXiv:1312.6114*, 2013.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma 和 Welling [2013] 迪德里克·P·金马和马克斯·威林。自编码变分贝叶斯。*arXiv 预印本 arXiv:1312.6114*，2013年。
- en: Goodfellow et al. [2014] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
    Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative
    adversarial nets. *Advances in Neural Information Processing Systems*, 27:2672–2680,
    2014.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等人 [2014] 伊恩·古德费洛、让·普热特-阿巴迪、梅赫迪·米尔扎、冰·徐、大卫·瓦尔德-法利、谢尔吉尔·奥扎伊尔、亚伦·库尔维尔和约书亚·本吉奥。生成对抗网络。*神经信息处理系统进展*，27:2672–2680，2014年。
- en: Makhzani et al. [2015] Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian
    Goodfellow, and Brendan Frey. Adversarial autoencoders. *arXiv preprint arXiv:1511.05644*,
    2015.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Makhzani 等人 [2015] 阿利雷扎·马赫扎尼、乔纳森·施伦斯、纳夫迪普·贾特利、伊恩·古德费洛和布伦丹·弗雷。对抗自编码器。*arXiv 预印本
    arXiv:1511.05644*，2015年。
- en: Tewari et al. [2018] Ayush Tewari, Michael Zollhoefer, Florian Bernard, Pablo
    Garrido, Hyeongwoo Kim, Patrick Perez, and Christian Theobalt. High-fidelity monocular
    face reconstruction based on an unsupervised model-based face autoencoder. *IEEE
    Transactions on Pattern Analysis and Machine Intelligence*, 42(2):357–370, 2018.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tewari 等人 [2018] 阿尤什·特瓦里、迈克尔·佐尔霍费尔、弗洛里安·伯纳德、巴勃罗·加里多、赫永宇·金、帕特里克·佩雷斯和克里斯蒂安·泰奥巴特。基于无监督模型的单目人脸高保真重建。*IEEE
    模式分析与机器智能汇刊*，42(2):357–370，2018年。
- en: 'Lin et al. [2021] Jiacheng Lin, Yang Li, and Guanci Yang. FPGAN: Face de-identification
    method with generative adversarial networks for social robots. *Neural Networks*,
    133:132–147, 2021.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等人 [2021] 家成·林、杨·李和冠词·杨。FPGAN：一种用于社交机器人面部去识别的方法，基于生成对抗网络。*神经网络*，133:132–147，2021年。
- en: 'Liu et al. [2021] Ming-Yu Liu, Xun Huang, Jiahui Yu, Ting-Chun Wang, and Arun
    Mallya. Generative adversarial networks for image and video synthesis: Algorithms
    and applications. *Proceedings of the IEEE*, 109(5):839–862, 2021.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2021] 明宇·刘、荀·黄、佳慧·余、婷春·王和阿伦·马利亚。生成对抗网络在图像和视频合成中的算法与应用。*IEEE 会议录*，109(5):839–862，2021年。
- en: Lyu [2018] Siwei Lyu. Detecting ’deepfake’ videos in the blink of an eye. [http://theconversation.com/detecting-deepfake-videos-in-the-blink-of-an-eye-101072](http://theconversation.com/detecting-deepfake-videos-in-the-blink-of-an-eye-101072),
    August 2018.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lyu [2018] 司伟·吕。瞬间检测“深度伪造”视频。[http://theconversation.com/detecting-deepfake-videos-in-the-blink-of-an-eye-101072](http://theconversation.com/detecting-deepfake-videos-in-the-blink-of-an-eye-101072)，2018年8月。
- en: Bloomberg [2018] Bloomberg. How faking videos became easy and why that’s so
    scary. [https://fortune.com/2018/09/11/deep-fakes-obama-video/](https://fortune.com/2018/09/11/deep-fakes-obama-video/),
    September 2018.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bloomberg [2018] Bloomberg. How faking videos became easy and why that’s so
    scary. [https://fortune.com/2018/09/11/deep-fakes-obama-video/](https://fortune.com/2018/09/11/deep-fakes-obama-video/),
    September 2018.
- en: 'Chesney and Citron [2019] Robert Chesney and Danielle Citron. Deepfakes and
    the new disinformation war: The coming age of post-truth geopolitics. *Foreign
    Affairs*, 98:147, 2019.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chesney and Citron [2019] Robert Chesney and Danielle Citron. Deepfakes and
    the new disinformation war: The coming age of post-truth geopolitics. *《外交事务》*,
    98:147, 2019.'
- en: 'Hwang [2020] T. Hwang. Deepfakes: A grounded threat assessment. Technical report,
    Centre for Security and Emerging Technologies, Georgetown University, 2020.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hwang [2020] T. Hwang. Deepfakes: A grounded threat assessment. Technical report,
    Centre for Security and Emerging Technologies, Georgetown University, 2020.'
- en: 'Zhou and Zafarani [2020] Xinyi Zhou and Reza Zafarani. A survey of fake news:
    Fundamental theories, detection methods, and opportunities. *ACM Computing Surveys
    (CSUR)*, 53(5):1–40, 2020.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou and Zafarani [2020] Xinyi Zhou and Reza Zafarani. A survey of fake news:
    Fundamental theories, detection methods, and opportunities. *《ACM计算调查 (CSUR)》*,
    53(5):1–40, 2020.'
- en: 'Kaliyar et al. [2021] Rohit Kumar Kaliyar, Anurag Goswami, and Pratik Narang.
    Deepfake: improving fake news detection using tensor decomposition-based deep
    neural network. *The Journal of Supercomputing*, 77(2):1015–1037, 2021.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kaliyar et al. [2021] Rohit Kumar Kaliyar, Anurag Goswami, and Pratik Narang.
    Deepfake: improving fake news detection using tensor decomposition-based deep
    neural network. *《超级计算期刊》*, 77(2):1015–1037, 2021.'
- en: 'Guo et al. [2020] Bin Guo, Yasan Ding, Lina Yao, Yunji Liang, and Zhiwen Yu.
    The future of false information detection on social media: New perspectives and
    trends. *ACM Computing Surveys (CSUR)*, 53(4):1–36, 2020.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guo et al. [2020] Bin Guo, Yasan Ding, Lina Yao, Yunji Liang, and Zhiwen Yu.
    The future of false information detection on social media: New perspectives and
    trends. *《ACM计算调查 (CSUR)》*, 53(4):1–36, 2020.'
- en: 'Tucker [2019] Patrick Tucker. The newest AI-enabled weapon: ‘deep-faking’ photos
    of the earth. [https://www.defenseone.com/technology/2019/03/next-phase-ai-deep-faking-whole-world-and-china-ahead/155944/](https://www.defenseone.com/technology/2019/03/next-phase-ai-deep-faking-whole-world-and-china-ahead/155944/),
    March 2019.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tucker [2019] Patrick Tucker. The newest AI-enabled weapon: ‘deep-faking’ photos
    of the earth. [https://www.defenseone.com/technology/2019/03/next-phase-ai-deep-faking-whole-world-and-china-ahead/155944/](https://www.defenseone.com/technology/2019/03/next-phase-ai-deep-faking-whole-world-and-china-ahead/155944/),
    March 2019.'
- en: 'Fish [2019] T Fish. Deep fakes: AI-manipulated media will be ‘weaponised’ to
    trick military. [https://www.express.co.uk/news/science/1109783/deep-fakes-ai-artificial-intelligence-photos-video-weaponised-china](https://www.express.co.uk/news/science/1109783/deep-fakes-ai-artificial-intelligence-photos-video-weaponised-china),
    April 2019.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fish [2019] T Fish. Deep fakes: AI-manipulated media will be ‘weaponised’ to
    trick military. [https://www.express.co.uk/news/science/1109783/deep-fakes-ai-artificial-intelligence-photos-video-weaponised-china](https://www.express.co.uk/news/science/1109783/deep-fakes-ai-artificial-intelligence-photos-video-weaponised-china),
    April 2019.'
- en: Marr [2019] B Marr. The best (and scariest) examples of AI-enabled deepfakes.
    [https://www.forbes.com/sites/bernardmarr/2019/07/22/the-best-and-scariest-examples-of-ai-enabled-deepfakes/](https://www.forbes.com/sites/bernardmarr/2019/07/22/the-best-and-scariest-examples-of-ai-enabled-deepfakes/),
    July 2019.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marr [2019] B Marr. The best (and scariest) examples of AI-enabled deepfakes.
    [https://www.forbes.com/sites/bernardmarr/2019/07/22/the-best-and-scariest-examples-of-ai-enabled-deepfakes/](https://www.forbes.com/sites/bernardmarr/2019/07/22/the-best-and-scariest-examples-of-ai-enabled-deepfakes/),
    July 2019.
- en: 'Mirsky and Lee [2021] Yisroel Mirsky and Wenke Lee. The creation and detection
    of deepfakes: A survey. *ACM Computing Surveys (CSUR)*, 54(1):1–41, 2021.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mirsky and Lee [2021] Yisroel Mirsky and Wenke Lee. The creation and detection
    of deepfakes: A survey. *《ACM计算调查 (CSUR)》*, 54(1):1–41, 2021.'
- en: 'Verdoliva [2020] Luisa Verdoliva. Media forensics and deepfakes: an overview.
    *IEEE Journal of Selected Topics in Signal Processing*, 14(5):910–932, 2020.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Verdoliva [2020] Luisa Verdoliva. Media forensics and deepfakes: an overview.
    *《IEEE选定信号处理期刊》*, 14(5):910–932, 2020.'
- en: Zakharov et al. [2019] Egor Zakharov, Aliaksandra Shysheya, Egor Burkov, and
    Victor Lempitsky. Few-shot adversarial learning of realistic neural talking head
    models. In *Proceedings of the IEEE/CVF International Conference on Computer Vision*,
    pages 9459–9468, 2019.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zakharov et al. [2019] Egor Zakharov, Aliaksandra Shysheya, Egor Burkov, and
    Victor Lempitsky. Few-shot adversarial learning of realistic neural talking head
    models. In *《IEEE/CVF国际计算机视觉会议论文集》*, pages 9459–9468, 2019.
- en: Damiani [2019] J Damiani. A voice deepfake was used to scam a ceo out of $243,000.
    [https://www.forbes.com/sites/jessedamiani/2019/09/03/a-voice-deepfake-was-used-to-scam-a-ceo-out-of-243000/](https://www.forbes.com/sites/jessedamiani/2019/09/03/a-voice-deepfake-was-used-to-scam-a-ceo-out-of-243000/),
    September 2019.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Damiani [2019] J Damiani. 一次语音深伪被用来骗取CEO 243,000美元。[https://www.forbes.com/sites/jessedamiani/2019/09/03/a-voice-deepfake-was-used-to-scam-a-ceo-out-of-243000/](https://www.forbes.com/sites/jessedamiani/2019/09/03/a-voice-deepfake-was-used-to-scam-a-ceo-out-of-243000/)，2019年9月。
- en: Samuel [2019] S Samuel. A guy made a deepfake app to turn photos of women into
    nudes. it didn’t go well. [https://www.vox.com/2019/6/27/18761639/ai-deepfake-deepnude-app-nude-women-porn](https://www.vox.com/2019/6/27/18761639/ai-deepfake-deepnude-app-nude-women-porn),
    June 2019.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Samuel [2019] S Samuel. 一个人制作了一个深伪应用，将女性照片转变为裸体照片，但效果不佳。[https://www.vox.com/2019/6/27/18761639/ai-deepfake-deepnude-app-nude-women-porn](https://www.vox.com/2019/6/27/18761639/ai-deepfake-deepnude-app-nude-women-porn)，2019年6月。
- en: The Guardian [2019] The Guardian. Chinese deepfake app Zao sparks privacy row
    after going viral. [https://www.theguardian.com/technology/2019/sep/02/chinese-face-swap-app-zao-triggers-privacy-fears-viral](https://www.theguardian.com/technology/2019/sep/02/chinese-face-swap-app-zao-triggers-privacy-fears-viral),
    September 2019.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: The Guardian [2019] The Guardian. 中国深伪应用Zao在走红后引发隐私争议。[https://www.theguardian.com/technology/2019/sep/02/chinese-face-swap-app-zao-triggers-privacy-fears-viral](https://www.theguardian.com/technology/2019/sep/02/chinese-face-swap-app-zao-triggers-privacy-fears-viral)，2019年9月。
- en: 'Lyu [2020] Siwei Lyu. Deepfake detection: Current challenges and next steps.
    In *IEEE International Conference on Multimedia & Expo Workshops (ICMEW)*, pages
    1–6\. IEEE, 2020.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lyu [2020] Siwei Lyu. 深伪检测：当前挑战与下一步。载于*IEEE国际多媒体与博览会研讨会（ICMEW）*，页1–6。IEEE，2020年。
- en: Guarnera et al. [2020a] Luca Guarnera, Oliver Giudice, Cristina Nastasi, and
    Sebastiano Battiato. Preliminary forensics analysis of deepfake images. In *AEIT
    International Annual Conference (AEIT)*, pages 1–6. IEEE, 2020a.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guarnera et al. [2020a] Luca Guarnera, Oliver Giudice, Cristina Nastasi, 和 Sebastiano
    Battiato. 深伪图像的初步取证分析。载于*AEIT国际年会（AEIT）*，页1–6。IEEE，2020a年。
- en: Jafar et al. [2020] Mousa Tayseer Jafar, Mohammad Ababneh, Mohammad Al-Zoube,
    and Ammar Elhassan. Forensics and analysis of deepfake videos. In *The 11th International
    Conference on Information and Communication Systems (ICICS)*, pages 053–058\.
    IEEE, 2020.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jafar et al. [2020] Mousa Tayseer Jafar, Mohammad Ababneh, Mohammad Al-Zoube,
    和 Ammar Elhassan. 深伪视频的取证与分析。载于*第11届国际信息与通信系统会议（ICICS）*，页053–058。IEEE，2020年。
- en: Trinh et al. [2021] Loc Trinh, Michael Tsang, Sirisha Rambhatla, and Yan Liu.
    Interpretable and trustworthy deepfake detection via dynamic prototypes. In *Proceedings
    of the IEEE/CVF Winter Conference on Applications of Computer Vision*, pages 1973–1983,
    2021.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trinh et al. [2021] Loc Trinh, Michael Tsang, Sirisha Rambhatla, 和 Yan Liu.
    通过动态原型进行可解释且值得信赖的深伪检测。载于*IEEE/CVF计算机视觉应用冬季会议论文集*，页1973–1983，2021年。
- en: Younus and Hasan [2020] Mohammed Akram Younus and Taha Mohammed Hasan. Effective
    and fast deepfake detection method based on haar wavelet transform. In *International
    Conference on Computer Science and Software Engineering (CSASE)*, pages 186–190\.
    IEEE, 2020.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Younus and Hasan [2020] Mohammed Akram Younus 和 Taha Mohammed Hasan. 基于Haar小波变换的高效快速深伪检测方法。载于*国际计算机科学与软件工程会议（CSASE）*，页186–190。IEEE，2020年。
- en: Turek [2019] M Turek. Media Forensics (MediFor). [https://www.darpa.mil/program/media-forensics](https://www.darpa.mil/program/media-forensics),
    January 2019.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Turek [2019] M Turek. 媒体取证（MediFor）。[https://www.darpa.mil/program/media-forensics](https://www.darpa.mil/program/media-forensics)，2019年1月。
- en: Schroepfer [2019] M Schroepfer. Creating a data set and a challenge for deepfakes.
    [https://ai.facebook.com/blog/deepfake-detection-challenge](https://ai.facebook.com/blog/deepfake-detection-challenge),
    September 2019.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schroepfer [2019] M Schroepfer. 创建数据集和深伪挑战。[https://ai.facebook.com/blog/deepfake-detection-challenge](https://ai.facebook.com/blog/deepfake-detection-challenge)，2019年9月。
- en: 'Tolosana et al. [2020] Ruben Tolosana, Ruben Vera-Rodriguez, Julian Fierrez,
    Aythami Morales, and Javier Ortega-Garcia. Deepfakes and beyond: A survey of face
    manipulation and fake detection. *Information Fusion*, 64:131–148, 2020.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tolosana et al. [2020] Ruben Tolosana, Ruben Vera-Rodriguez, Julian Fierrez,
    Aythami Morales, 和 Javier Ortega-Garcia. 深伪及其扩展：面部操控与伪造检测的综述。*信息融合*，64:131–148，2020年。
- en: Punnappurath and Brown [2019] Abhijith Punnappurath and Michael S Brown. Learning
    raw image reconstruction-aware deep image compressors. *IEEE Transactions on Pattern
    Analysis and Machine Intelligence*, 42(4):1013–1019, 2019.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Punnappurath and Brown [2019] Abhijith Punnappurath 和 Michael S Brown. 学习原始图像重建感知的深度图像压缩器。*IEEE模式分析与机器智能汇刊*，42(4):1013–1019，2019年。
- en: Cheng et al. [2019] Zhengxue Cheng, Heming Sun, Masaru Takeuchi, and Jiro Katto.
    Energy compaction-based image compression using convolutional autoencoder. *IEEE
    Transactions on Multimedia*, 22(4):860–873, 2019.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng et al. [2019] 郑学成、孙亨铭、竹内雅、角井二郎。基于能量压缩的图像压缩方法使用卷积自编码器。*IEEE多媒体学报*，22(4):860–873，2019年。
- en: Chorowski et al. [2019] Jan Chorowski, Ron J Weiss, Samy Bengio, and Aäron van den
    Oord. Unsupervised speech representation learning using WaveNet autoencoders.
    *IEEE/ACM Transactions on Audio, Speech, and Language Processing*, 27(12):2041–2053,
    2019.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chorowski et al. [2019] 托扬·乔罗斯基、罗恩·J·韦斯、萨米·本吉奥、亚伦·范·登·奥德。使用WaveNet自编码器的无监督语音表示学习。*IEEE/ACM音频、语音与语言处理学报*，27(12):2041–2053，2019年。
- en: '[36] Faceswap: Deepfakes software for all. [https://github.com/deepfakes/faceswap](https://github.com/deepfakes/faceswap).'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Faceswap：适用于所有人的深度伪造软件。[https://github.com/deepfakes/faceswap](https://github.com/deepfakes/faceswap)。'
- en: '[37] FakeApp 2.2.0. [https://www.malavida.com/en/soft/fakeapp/](https://www.malavida.com/en/soft/fakeapp/).'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] FakeApp 2.2.0。[https://www.malavida.com/en/soft/fakeapp/](https://www.malavida.com/en/soft/fakeapp/)。'
- en: Dee [a] DeepFaceLab. [https://github.com/iperov/DeepFaceLab](https://github.com/iperov/DeepFaceLab),
    a.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dee [a] DeepFaceLab。[https://github.com/iperov/DeepFaceLab](https://github.com/iperov/DeepFaceLab)，a。
- en: '[39] DFaker. [https://github.com/dfaker/df](https://github.com/dfaker/df).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] DFaker。[https://github.com/dfaker/df](https://github.com/dfaker/df)。'
- en: 'Dee [b] DeepFake_tf: Deepfake based on tensorflow. [https://github.com/StromWine/DeepFake_tf](https://github.com/StromWine/DeepFake_tf),
    b.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dee [b] DeepFake_tf：基于TensorFlow的深度伪造。[https://github.com/StromWine/DeepFake_tf](https://github.com/StromWine/DeepFake_tf)，b。
- en: Liu et al. [2019] Ming-Yu Liu, Xun Huang, Arun Mallya, Tero Karras, Timo Aila,
    Jaakko Lehtinen, and Jan Kautz. Few-shot unsupervised image-to-image translation.
    In *Proceedings of the IEEE/CVF International Conference on Computer Vision*,
    pages 10551–10560, 2019.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. [2019] 刘铭宇、黄迅、阿伦·马利亚、特罗·卡拉斯、蒂莫·艾拉、雅科·雷赫宁、扬·考茨。少样本无监督图像到图像翻译。在*IEEE/CVF国际计算机视觉会议论文集*，页码10551–10560，2019年。
- en: Park et al. [2019] Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu.
    Semantic image synthesis with spatially-adaptive normalization. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages
    2337–2346, 2019.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park et al. [2019] 朴泰成、刘铭宇、汪廷春、朱军彦。具有空间自适应归一化的语义图像合成。在*IEEE/CVF计算机视觉与模式识别会议论文集*，页码2337–2346，2019年。
- en: '[43] DeepFaceLab: Explained and usage tutorial. [https://mrdeepfakes.com/forums/thread-deepfacelab-explained-and-usage-tutorial](https://mrdeepfakes.com/forums/thread-deepfacelab-explained-and-usage-tutorial).'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] DeepFaceLab：解释及使用教程。[https://mrdeepfakes.com/forums/thread-deepfacelab-explained-and-usage-tutorial](https://mrdeepfakes.com/forums/thread-deepfacelab-explained-and-usage-tutorial)。'
- en: '[44] DSSIM. [https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/losses/dssim.py](https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/losses/dssim.py).'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] DSSIM。[https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/losses/dssim.py](https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/losses/dssim.py)。'
- en: 'Lattas et al. [2020] Alexandros Lattas, Stylianos Moschoglou, Baris Gecer,
    Stylianos Ploumpis, Vasileios Triantafyllou, Abhijeet Ghosh, and Stefanos Zafeiriou.
    AvatarMe: Realistically renderable 3D facial reconstruction “in-the-wild”. In
    *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    pages 760–769, 2020.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lattas et al. [2020] 亚历山德罗斯·拉塔斯、斯提利亚诺斯·莫斯霍格鲁、巴里斯·杰瑟、斯提利亚诺斯·普鲁姆比斯、瓦西里奥斯·特里安塔菲卢、阿比吉特·戈什、斯特凡诺斯·扎费里乌。AvatarMe：现实可渲染的“在野外”3D面部重建。在*IEEE/CVF计算机视觉与模式识别会议论文集*，页码760–769，2020年。
- en: 'Ha et al. [2020] Sungjoo Ha, Martin Kersner, Beomsu Kim, Seokjun Seo, and Dongyoung
    Kim. Marionette: Few-shot face reenactment preserving identity of unseen targets.
    In *Proceedings of the AAAI Conference on Artificial Intelligence*, volume 34,
    pages 10893–10900, 2020.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ha et al. [2020] 河成珠、马丁·克尔斯纳、金범洙、徐锡俊、金东炫。Marionette：少样本面部再现保留未见目标的身份。在*AAAI人工智能会议论文集*，第34卷，页码10893–10900，2020年。
- en: Deng et al. [2020] Yu Deng, Jiaolong Yang, Dong Chen, Fang Wen, and Xin Tong.
    Disentangled and controllable face image generation via 3D imitative-contrastive
    learning. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition*, pages 5154–5163, 2020.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng et al. [2020] 邓宇、杨家龙、陈东、温方、童欣。通过3D模仿对比学习进行解耦和可控的面部图像生成。在*IEEE/CVF计算机视觉与模式识别会议论文集*，页码5154–5163，2020年。
- en: 'Tewari et al. [2020] Ayush Tewari, Mohamed Elgharib, Gaurav Bharaj, Florian
    Bernard, Hans-Peter Seidel, Patrick Pérez, Michael Zollhofer, and Christian Theobalt.
    StyleRig: Rigging StyleGAN for 3D control over portrait images. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages
    6142–6151, 2020.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tewari et al. [2020] Ayush Tewari, Mohamed Elgharib, Gaurav Bharaj, Florian
    Bernard, Hans-Peter Seidel, Patrick Pérez, Michael Zollhofer, 和 Christian Theobalt.
    StyleRig：将StyleGAN用于肖像图像的3D控制。发表于*IEEE/CVF计算机视觉与模式识别会议论文集*，第6142–6151页，2020年。
- en: 'Li et al. [2019a] Lingzhi Li, Jianmin Bao, Hao Yang, Dong Chen, and Fang Wen.
    FaceShifter: Towards high fidelity and occlusion aware face swapping. *arXiv preprint
    arXiv:1912.13457*, 2019a.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2019a] Lingzhi Li, Jianmin Bao, Hao Yang, Dong Chen, 和 Fang Wen.
    FaceShifter：面向高保真和遮挡感知的面部交换。*arXiv预印本 arXiv:1912.13457*，2019a。
- en: 'Nirkin et al. [2019] Yuval Nirkin, Yosi Keller, and Tal Hassner. FSGAN: Subject
    agnostic face swapping and reenactment. In *Proceedings of the IEEE/CVF International
    Conference on Computer Vision*, pages 7184–7193, 2019.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nirkin et al. [2019] Yuval Nirkin, Yosi Keller, 和 Tal Hassner. FSGAN：无视主观的面部交换和重现。发表于*IEEE/CVF国际计算机视觉大会论文集*，第7184–7193页，2019年。
- en: Karras et al. [2019] Tero Karras, Samuli Laine, and Timo Aila. A style-based
    generator architecture for generative adversarial networks. In *Proceedings of
    the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages 4401–4410,
    2019.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karras et al. [2019] Tero Karras, Samuli Laine, 和 Timo Aila. 一种基于风格的生成对抗网络生成器架构。发表于*IEEE/CVF计算机视觉与模式识别会议论文集*，第4401–4410页，2019年。
- en: 'Thies et al. [2016] Justus Thies, Michael Zollhofer, Marc Stamminger, Christian
    Theobalt, and Matthias Nießner. Face2Face: Real-time face capture and reenactment
    of RGB videos. In *Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition*, pages 2387–2395, 2016.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thies et al. [2016] Justus Thies, Michael Zollhofer, Marc Stamminger, Christian
    Theobalt, 和 Matthias Nießner. Face2Face：RGB视频的实时面部捕捉和重现。发表于*IEEE计算机视觉与模式识别会议论文集*，第2387–2395页，2016年。
- en: 'Thies et al. [2019] Justus Thies, Michael Zollhöfer, and Matthias Nießner.
    Deferred neural rendering: Image synthesis using neural textures. *ACM Transactions
    on Graphics (TOG)*, 38(4):1–12, 2019.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thies et al. [2019] Justus Thies, Michael Zollhöfer, 和 Matthias Nießner. 延迟神经渲染：使用神经纹理的图像合成。*ACM图形学通讯（TOG）*，38(4):1–12，2019年。
- en: Olszewski et al. [2019] Kyle Olszewski, Sergey Tulyakov, Oliver Woodford, Hao
    Li, and Linjie Luo. Transformable bottleneck networks. In *Proceedings of the
    IEEE/CVF International Conference on Computer Vision*, pages 7648–7657, 2019.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Olszewski et al. [2019] Kyle Olszewski, Sergey Tulyakov, Oliver Woodford, Hao
    Li, 和 Linjie Luo. 可变瓶颈网络。发表于*IEEE/CVF国际计算机视觉大会论文集*，第7648–7657页，2019年。
- en: Chan et al. [2019] Caroline Chan, Shiry Ginosar, Tinghui Zhou, and Alexei A
    Efros. Everybody dance now. In *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*, pages 5933–5942, 2019.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chan et al. [2019] Caroline Chan, Shiry Ginosar, Tinghui Zhou, 和 Alexei A Efros.
    现在大家都跳舞吧。发表于*IEEE/CVF 国际计算机视觉大会论文集*，第5933–5942页，2019年。
- en: 'Thies et al. [2020] Justus Thies, Mohamed Elgharib, Ayush Tewari, Christian
    Theobalt, and Matthias Nießner. Neural voice puppetry: Audio-driven facial reenactment.
    In *European Conference on Computer Vision*, pages 716–731. Springer, 2020.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thies et al. [2020] Justus Thies, Mohamed Elgharib, Ayush Tewari, Christian
    Theobalt, 和 Matthias Nießner. 神经语音偶像戏法：基于音频的面部重现。发表于*欧洲计算机视觉会议*，第716–731页。Springer，2020年。
- en: '[57] Keras-VGGFace: VGGFace implementation with Keras framework. [https://github.com/rcmalli/keras-vggface](https://github.com/rcmalli/keras-vggface).'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] Keras-VGGFace: 基于Keras框架的VGGFace实现。 [https://github.com/rcmalli/keras-vggface](https://github.com/rcmalli/keras-vggface)。'
- en: Fac [a] Faceswap-GAN. [https://github.com/shaoanlu/faceswap-GAN](https://github.com/shaoanlu/faceswap-GAN),
    a.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fac [a] Faceswap-GAN. [https://github.com/shaoanlu/faceswap-GAN](https://github.com/shaoanlu/faceswap-GAN)，a。
- en: Fac [b] FaceNet. [https://github.com/davidsandberg/facenet](https://github.com/davidsandberg/facenet),
    b.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fac [b] FaceNet. [https://github.com/davidsandberg/facenet](https://github.com/davidsandberg/facenet)，b。
- en: '[60] CycleGAN. [https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix).'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] CycleGAN. [https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)。'
- en: Huang et al. [2017] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q
    Weinberger. Densely connected convolutional networks. In *Proceedings of the IEEE
    Conference on Computer Vision and Pattern Recognition*, pages 4700–4708, 2017.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. [2017] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, 和 Kilian
    Q Weinberger. 密集连接卷积网络。发表于*IEEE计算机视觉与模式识别会议论文集*，第4700–4708页，2017年。
- en: Karras et al. [2017] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
    Progressive growing of GANs for improved quality, stability, and variation. *arXiv
    preprint arXiv:1710.10196*, 2017.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karras et al. [2017] 特罗·卡拉斯、蒂莫·艾拉、萨穆利·莱恩和贾科·莱赫提宁。渐进式生成对抗网络的质量、稳定性和变化改进。*arXiv
    预印本 arXiv:1710.10196*，2017年。
- en: Korshunov and Marcel [2019] Pavel Korshunov and Sébastien Marcel. Vulnerability
    assessment and detection of deepfake videos. In *2019 International Conference
    on Biometrics (ICB)*, pages 1–6\. IEEE, 2019.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Korshunov and Marcel [2019] 帕维尔·科尔舒诺夫和塞巴斯蒂安·马塞尔。深度伪造视频的脆弱性评估与检测。在*2019年国际生物识别会议（ICB）*，第1–6页。IEEE，2019年。
- en: '[64] VidTIMIT database. [http://conradsanderson.id.au/vidtimit/](http://conradsanderson.id.au/vidtimit/).'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] VidTIMIT 数据库。 [http://conradsanderson.id.au/vidtimit/](http://conradsanderson.id.au/vidtimit/)。'
- en: Parkhi et al. [2015] Omkar M Parkhi, Andrea Vedaldi, and Andrew Zisserman. Deep
    face recognition. In *Proceedings of the British Machine Vision Conference (BMVC)*,
    pages 41.1–41.12, 2015.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Parkhi et al. [2015] 奥姆卡尔·M·帕尔基、安德烈亚·维达尔迪和安德鲁·齐瑟曼。深度面部识别。在*英国机器视觉会议论文集（BMVC）*，第41.1–41.12页，2015年。
- en: 'Schroff et al. [2015] Florian Schroff, Dmitry Kalenichenko, and James Philbin.
    FaceNet: A unified embedding for face recognition and clustering. In *Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition*, pages 815–823,
    2015.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schroff et al. [2015] 弗洛里安·施罗夫、德米特里·卡连尼琴科和詹姆斯·菲尔宾。FaceNet：用于面部识别和聚类的统一嵌入。在*IEEE计算机视觉与模式识别大会论文集*，第815–823页，2015年。
- en: Chung et al. [2017] Joon Son Chung, Andrew Senior, Oriol Vinyals, and Andrew
    Zisserman. Lip reading sentences in the wild. In *2017 IEEE Conference on Computer
    Vision and Pattern Recognition (CVPR)*, pages 3444–3453\. IEEE, 2017.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung et al. [2017] 钟孫·钟、安德鲁·高级、奥里奥尔·维尼亚尔斯和安德鲁·齐瑟曼。在自然环境中进行句子唇读。在*2017年IEEE计算机视觉与模式识别大会（CVPR）*，第3444–3453页。IEEE，2017年。
- en: 'Suwajanakorn et al. [2017] Supasorn Suwajanakorn, Steven M Seitz, and Ira Kemelmacher-Shlizerman.
    Synthesizing Obama: learning lip sync from audio. *ACM Transactions on Graphics
    (ToG)*, 36(4):1–13, 2017.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suwajanakorn et al. [2017] 苏帕索恩·苏瓦贾纳科恩、斯蒂文·M·塞茨和艾拉·凯梅尔梅赫-施利泽曼。合成奥巴马：从音频学习唇同步。*ACM计算机图形学汇刊（ToG）*，36(4)：1–13，2017年。
- en: Korshunov and Marcel [2018a] Pavel Korshunov and Sébastien Marcel. Speaker inconsistency
    detection in tampered video. In *The 26th European Signal Processing Conference
    (EUSIPCO)*, pages 2375–2379\. IEEE, 2018a.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Korshunov and Marcel [2018a] 帕维尔·科尔舒诺夫和塞巴斯蒂安·马塞尔。篡改视频中的说话者不一致性检测。在*第26届欧洲信号处理大会（EUSIPCO）*，第2375–2379页。IEEE，2018年。
- en: Galbally and Marcel [2014] Javier Galbally and Sébastien Marcel. Face anti-spoofing
    based on general image quality assessment. In *The 22nd International Conference
    on Pattern Recognition*, pages 1173–1178\. IEEE, 2014.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Galbally and Marcel [2014] 哈维尔·加尔巴利和塞巴斯蒂安·马塞尔。基于通用图像质量评估的面部防伪。在*第22届国际模式识别大会*，第1173–1178页。IEEE，2014年。
- en: 'Chesney and Citron [2018a] Robert Chesney and Danielle Keats Citron. Deep fakes:
    A looming challenge for privacy, democracy, and national security. *Democracy,
    and National Security*, 107, 2018a.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chesney and Citron [2018a] 罗伯特·切斯尼和丹妮尔·基茨·西特龙。深度伪造：隐私、民主与国家安全面临的迫在眉睫的挑战。*民主与国家安全*，107，2018年。
- en: de Lima et al. [2020] Oscar de Lima, Sean Franklin, Shreshtha Basu, Blake Karwoski,
    and Annet George. Deepfake detection using spatiotemporal convolutional networks.
    *arXiv preprint arXiv:2006.14749*, 2020.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de Lima et al. [2020] 奥斯卡·德·利马、肖恩·富兰克林、施雷斯塔·巴苏、布莱克·卡沃斯基和安内特·乔治。基于时空卷积网络的深度伪造检测。*arXiv
    预印本 arXiv:2006.14749*，2020年。
- en: Amerini and Caldelli [2020] Irene Amerini and Roberto Caldelli. Exploiting prediction
    error inconsistencies through LSTM-based classifiers to detect deepfake videos.
    In *Proceedings of the 2020 ACM Workshop on Information Hiding and Multimedia
    Security*, pages 97–102, 2020.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amerini and Caldelli [2020] 艾琳·阿梅里尼和罗伯托·卡尔德利。通过基于LSTM的分类器利用预测错误不一致性检测深度伪造视频。在*2020年ACM信息隐藏与多媒体安全研讨会论文集*，第97–102页，2020年。
- en: Xuan et al. [2019] Xinsheng Xuan, Bo Peng, Wei Wang, and Jing Dong. On the generalization
    of GAN image forensics. In *Chinese Conference on Biometric Recognition*, pages
    134–141\. Springer, 2019.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xuan et al. [2019] 辛生·宣、博·彭、魏·王和静东。GAN图像取证的泛化性。在*中国生物识别会议*，第134–141页。Springer，2019年。
- en: Yang et al. [2016] Pengpeng Yang, Rongrong Ni, and Yao Zhao. Recapture image
    forensics based on laplacian convolutional neural networks. In *International
    Workshop on Digital Watermarking*, pages 119–128\. Springer, 2016.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. [2016] 彭鹏·杨、荣荣·倪和姚赵。基于拉普拉斯卷积神经网络的重新捕捉图像取证。在*数字水印国际研讨会*，第119–128页。Springer，2016年。
- en: Bayar and Stamm [2016] Belhassen Bayar and Matthew C Stamm. A deep learning
    approach to universal image manipulation detection using a new convolutional layer.
    In *Proceedings of the 4th ACM Workshop on Information Hiding and Multimedia Security*,
    pages 5–10, 2016.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bayar 和 Stamm [2016] Belhassen Bayar 和 Matthew C Stamm。使用新卷积层的深度学习方法进行通用图像操控检测。在
    *第4届ACM信息隐藏与多媒体安全研讨会论文集* 中，第5–10页，2016年。
- en: Qian et al. [2015] Yinlong Qian, Jing Dong, Wei Wang, and Tieniu Tan. Deep learning
    for steganalysis via convolutional neural networks. In *Media Watermarking, Security,
    and Forensics*, volume 9409, page 94090J, 2015.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian 等 [2015] Yinlong Qian、Jing Dong、Wei Wang 和 Tieniu Tan。通过卷积神经网络进行隐写分析的深度学习。在
    *媒体水印、安全与取证* 中，第9409卷，第94090J页，2015年。
- en: Zhang et al. [2017] Ying Zhang, Lilei Zheng, and Vrizlynn LL Thing. Automated
    face swapping and its detection. In *The 2nd International Conference on Signal
    and Image Processing (ICSIP)*, pages 15–19\. IEEE, 2017.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等 [2017] Ying Zhang、Lilei Zheng 和 Vrizlynn LL Thing。自动化人脸交换及其检测。在 *第2届信号与图像处理国际会议（ICSIP）*
    中，第15–19页。IEEE，2017年。
- en: Wang et al. [2017] Xin Wang, Nicolas Thome, and Matthieu Cord. Gaze latent support
    vector machine for image classification improved by weakly supervised region selection.
    *Pattern Recognition*, 72:59–71, 2017.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 [2017] Xin Wang、Nicolas Thome 和 Matthieu Cord。改进弱监督区域选择的注视潜在支持向量机进行图像分类。*模式识别*，72:59–71，2017年。
- en: Bai [2017] Shuang Bai. Growing random forest on deep convolutional neural networks
    for scene categorization. *Expert Systems with Applications*, 71:279–287, 2017.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai [2017] Shuang Bai。基于深度卷积神经网络的随机森林场景分类方法。*专家系统与应用*，71:279–287，2017年。
- en: Zheng et al. [2016] Lilei Zheng, Stefan Duffner, Khalid Idrissi, Christophe
    Garcia, and Atilla Baskurt. Siamese multi-layer perceptrons for dimensionality
    reduction and face identification. *Multimedia Tools and Applications*, 75(9):5055–5073,
    2016.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等 [2016] Lilei Zheng、Stefan Duffner、Khalid Idrissi、Christophe Garcia 和
    Atilla Baskurt。用于降维和人脸识别的Siamese多层感知器。*多媒体工具与应用*，75(9):5055–5073，2016年。
- en: 'Agarwal and Varshney [2019] Sakshi Agarwal and Lav R Varshney. Limits of deepfake
    detection: A robust estimation viewpoint. *arXiv preprint arXiv:1905.03493*, 2019.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agarwal 和 Varshney [2019] Sakshi Agarwal 和 Lav R Varshney。深度伪造检测的极限：一种稳健的估计视角。*arXiv预印本
    arXiv:1905.03493*，2019年。
- en: Maurer [2000] Ueli M Maurer. Authentication theory and hypothesis testing. *IEEE
    Transactions on Information Theory*, 46(4):1350–1356, 2000.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maurer [2000] Ueli M Maurer。认证理论与假设检验。*IEEE信息理论汇刊*，46(4):1350–1356，2000年。
- en: Korshunova et al. [2017] Iryna Korshunova, Wenzhe Shi, Joni Dambre, and Lucas
    Theis. Fast face-swap using convolutional neural networks. In *Proceedings of
    the IEEE International Conference on Computer Vision*, pages 3677–3685, 2017.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Korshunova 等 [2017] Iryna Korshunova、Wenzhe Shi、Joni Dambre 和 Lucas Theis。使用卷积神经网络进行快速人脸交换。在
    *IEEE国际计算机视觉大会论文集* 中，第3677–3685页，2017年。
- en: Hsu et al. [2020] Chih-Chung Hsu, Yi-Xiu Zhuang, and Chia-Yen Lee. Deep fake
    image detection based on pairwise learning. *Applied Sciences*, 10(1):370, 2020.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hsu 等 [2020] Chih-Chung Hsu、Yi-Xiu Zhuang 和 Chia-Yen Lee。基于成对学习的深度伪造图像检测。*应用科学*，10(1):370，2020年。
- en: Chopra et al. [2005] Sumit Chopra, Raia Hadsell, and Yann LeCun. Learning a
    similarity metric discriminatively, with application to face verification. In
    *IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)*,
    volume 1, pages 539–546\. IEEE, 2005.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chopra 等 [2005] Sumit Chopra、Raia Hadsell 和 Yann LeCun。以辨别方式学习相似性度量，并应用于人脸验证。在
    *IEEE计算机视觉与模式识别会议（CVPR’05）* 中，第1卷，第539–546页。IEEE，2005年。
- en: Liu et al. [2015] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep
    learning face attributes in the wild. In *Proceedings of the IEEE International
    Conference on Computer Vision*, pages 3730–3738, 2015.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 [2015] Ziwei Liu、Ping Luo、Xiaogang Wang 和 Xiaoou Tang。深度学习人脸属性识别。在 *IEEE国际计算机视觉大会论文集*
    中，第3730–3738页，2015年。
- en: Radford et al. [2015] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised
    representation learning with deep convolutional generative adversarial networks.
    *arXiv preprint arXiv:1511.06434*, 2015.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford 等 [2015] Alec Radford、Luke Metz 和 Soumith Chintala。使用深度卷积生成对抗网络进行无监督表征学习。*arXiv预印本
    arXiv:1511.06434*，2015年。
- en: Arjovsky et al. [2017] Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein
    generative adversarial networks. In *International Conference on Machine Learning*,
    pages 214–223\. PMLR, 2017.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arjovsky 等 [2017] Martin Arjovsky、Soumith Chintala 和 Léon Bottou。Wasserstein生成对抗网络。在
    *国际机器学习会议* 中，第214–223页。PMLR，2017年。
- en: Gulrajani et al. [2017] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent
    Dumoulin, and Aaron Courville. Improved training of Wasserstein GANs. *arXiv preprint
    arXiv:1704.00028*, 2017.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gulrajani等 [2017] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin,
    和 Aaron Courville. 改进的Wasserstein GANs训练。*arXiv预印本 arXiv:1704.00028*，2017年。
- en: Mao et al. [2017] Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang,
    and Stephen Paul Smolley. Least squares generative adversarial networks. In *Proceedings
    of the IEEE International Conference on Computer Vision*, pages 2794–2802, 2017.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mao等 [2017] Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, 和 Stephen
    Paul Smolley. 最小二乘生成对抗网络。在*IEEE国际计算机视觉会议论文集*，第2794–2802页，2017年。
- en: Russakovsky et al. [2015] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause,
    Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael
    Bernstein, et al. ImageNet large scale visual recognition challenge. *International
    Journal of Computer Vision*, 115(3):211–252, 2015.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russakovsky等 [2015] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev
    Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein
    等。ImageNet大规模视觉识别挑战。*计算机视觉国际期刊*，115(3):211–252，2015年。
- en: Brock et al. [2018] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale
    GAN training for high fidelity natural image synthesis. *arXiv preprint arXiv:1809.11096*,
    2018.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brock等 [2018] Andrew Brock, Jeff Donahue, 和 Karen Simonyan. 高保真自然图像合成的大规模GAN训练。*arXiv预印本
    arXiv:1809.11096*，2018年。
- en: Zhang et al. [2019] Han Zhang, Ian Goodfellow, Dimitris Metaxas, and Augustus
    Odena. Self-attention generative adversarial networks. In *International Conference
    on Machine Learning*, pages 7354–7363\. PMLR, 2019.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等 [2019] Han Zhang, Ian Goodfellow, Dimitris Metaxas, 和 Augustus Odena.
    自注意生成对抗网络。在*国际机器学习大会*，第7354–7363页。PMLR，2019年。
- en: Miyato et al. [2018] Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi
    Yoshida. Spectral normalization for generative adversarial networks. *arXiv preprint
    arXiv:1802.05957*, 2018.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miyato等 [2018] Takeru Miyato, Toshiki Kataoka, Masanori Koyama, 和 Yuichi Yoshida.
    生成对抗网络的谱归一化。*arXiv预印本 arXiv:1802.05957*，2018年。
- en: Farid [2009] Hany Farid. Image forgery detection. *IEEE Signal Processing Magazine*,
    26(2):16–25, 2009.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Farid [2009] Hany Farid. 图像伪造检测。*IEEE信号处理杂志*，26(2):16–25，2009年。
- en: Mo et al. [2018] Huaxiao Mo, Bolin Chen, and Weiqi Luo. Fake faces identification
    via convolutional neural network. In *Proceedings of the 6th ACM Workshop on Information
    Hiding and Multimedia Security*, pages 43–47, 2018.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mo等 [2018] Huaxiao Mo, Bolin Chen, 和 Weiqi Luo. 通过卷积神经网络识别假面孔。在*第6届ACM信息隐藏与多媒体安全研讨会论文集*，第43–47页，2018年。
- en: Marra et al. [2018] Francesco Marra, Diego Gragnaniello, Davide Cozzolino, and
    Luisa Verdoliva. Detection of GAN-generated fake images over social networks.
    In *2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)*,
    pages 384–389\. IEEE, 2018.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marra等 [2018] Francesco Marra, Diego Gragnaniello, Davide Cozzolino, 和 Luisa
    Verdoliva. 检测社交网络上的GAN生成的假图像。在*2018 IEEE多媒体信息处理与检索会议（MIPR）*，第384–389页。IEEE，2018年。
- en: Hsu et al. [2018] Chih-Chung Hsu, Chia-Yen Lee, and Yi-Xiu Zhuang. Learning
    to detect fake face images in the wild. In *2018 International Symposium on Computer,
    Consumer and Control (IS3C)*, pages 388–391\. IEEE, 2018.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hsu等 [2018] Chih-Chung Hsu, Chia-Yen Lee, 和 Yi-Xiu Zhuang. 学习检测野外假面部图像。在*2018国际计算机、消费和控制研讨会（IS3C）*，第388–391页。IEEE，2018年。
- en: Guo et al. [2021] Zhiqing Guo, Lipin Hu, Ming Xia, and Gaobo Yang. Blind detection
    of glow-based facial forgery. *Multimedia Tools and Applications*, 80(5):7687–7710,
    2021.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo等 [2021] Zhiqing Guo, Lipin Hu, Ming Xia, 和 Gaobo Yang. 基于Glow的面部伪造盲检测。*多媒体工具与应用*，80(5):7687–7710，2021年。
- en: 'Kingma and Dhariwal [2018] Diederik P Kingma and Prafulla Dhariwal. Glow: generative
    flow with invertible 1$\times$ 1 convolutions. In *Proceedings of the 32nd International
    Conference on Neural Information Processing Systems*, pages 10236–10245, 2018.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kingma和Dhariwal [2018] Diederik P Kingma 和 Prafulla Dhariwal. Glow: 使用可逆1$\times$
    1卷积的生成流。在*第32届国际神经信息处理系统会议论文集*，第10236–10245页，2018年。'
- en: 'Afchar et al. [2018] Darius Afchar, Vincent Nozick, Junichi Yamagishi, and
    Isao Echizen. MesoNet: a compact facial video forgery detection network. In *2018
    IEEE International Workshop on Information Forensics and Security (WIFS)*, pages
    1–7\. IEEE, 2018.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Afchar等 [2018] Darius Afchar, Vincent Nozick, Junichi Yamagishi, 和 Isao Echizen.
    MesoNet: 一个紧凑的面部视频伪造检测网络。在*2018 IEEE信息取证与安全国际研讨会（WIFS）*，第1–7页。IEEE，2018年。'
- en: Sabir et al. [2019] Ekraam Sabir, Jiaxin Cheng, Ayush Jaiswal, Wael AbdAlmageed,
    Iacopo Masi, and Prem Natarajan. Recurrent convolutional strategies for face manipulation
    detection in videos. *Proceedings of the IEEE Conference on Computer Vision and
    Pattern Recognition Workshops*, 3(1):80–87, 2019.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sabir 等 [2019] Ekraam Sabir、Jiaxin Cheng、Ayush Jaiswal、Wael AbdAlmageed、Iacopo
    Masi 和 Prem Natarajan。《视频中面部操纵检测的递归卷积策略》。发表于*IEEE 计算机视觉与模式识别会议论文集（工作坊）*，3(1):80–87，2019年。
- en: Zhao et al. [2021] Tianchen Zhao, Xiang Xu, Mingze Xu, Hui Ding, Yuanjun Xiong,
    and Wei Xia. Learning self-consistency for deepfake detection. In *Proceedings
    of the IEEE/CVF International Conference on Computer Vision*, pages 15023–15033,
    2021.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等 [2021] Tianchen Zhao、Xiang Xu、Mingze Xu、Hui Ding、Yuanjun Xiong 和 Wei
    Xia。《学习自一致性以进行深度伪造检测》。发表于*IEEE/CVF 国际计算机视觉会议论文集*，第15023–15033页，2021年。
- en: 'Rossler et al. [2019] Andreas Rossler, Davide Cozzolino, Luisa Verdoliva, Christian
    Riess, Justus Thies, and Matthias Nießner. FaceForensics++: Learning to detect
    manipulated facial images. In *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*, pages 1–11, 2019.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rossler 等 [2019] Andreas Rossler、Davide Cozzolino、Luisa Verdoliva、Christian
    Riess、Justus Thies 和 Matthias Nießner。《FaceForensics++：学习检测操纵的面部图像》。发表于*IEEE/CVF
    国际计算机视觉会议论文集*，第1–11页，2019年。
- en: Dufour and Gully [2019] Nick Dufour and Andrew Gully. Contributing data to deepfake
    detection research. [https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html](https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html),
    September 2019.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dufour 和 Gully [2019] Nick Dufour 和 Andrew Gully。《为深度伪造检测研究贡献数据》。[https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html](https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html)，2019年9月。
- en: 'Li et al. [2020a] Yuezun Li, Xin Yang, Pu Sun, Honggang Qi, and Siwei Lyu.
    Celeb-DF: A large-scale challenging dataset for deepfake forensics. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages
    3207–3216, 2020a.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 [2020a] Yuezun Li、Xin Yang、Pu Sun、Honggang Qi 和 Siwei Lyu。《Celeb-DF：一个用于深度伪造取证的大规模挑战数据集》。发表于*IEEE/CVF
    计算机视觉与模式识别会议论文集*，第3207–3216页，2020年。
- en: Dolhansky et al. [2020] Brian Dolhansky, Joanna Bitton, Ben Pflaum, Jikuo Lu,
    Russ Howes, Menglin Wang, and Cristian Canton Ferrer. The deepfake detection challenge
    dataset. *arXiv preprint arXiv:2006.07397*, 2020.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dolhansky 等 [2020] Brian Dolhansky、Joanna Bitton、Ben Pflaum、Jikuo Lu、Russ Howes、Menglin
    Wang 和 Cristian Canton Ferrer。《深度伪造检测挑战数据集》。*arXiv 预印本 arXiv:2006.07397*，2020年。
- en: Dolhansky et al. [2019] Brian Dolhansky, Russ Howes, Ben Pflaum, Nicole Baram,
    and Cristian Canton Ferrer. The deepfake detection challenge (DFDC) preview dataset.
    *arXiv preprint arXiv:1910.08854*, 2019.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dolhansky 等 [2019] Brian Dolhansky、Russ Howes、Ben Pflaum、Nicole Baram 和 Cristian
    Canton Ferrer。《深度伪造检测挑战（DFDC）预览数据集》。*arXiv 预印本 arXiv:1910.08854*，2019年。
- en: 'Jiang et al. [2020] Liming Jiang, Ren Li, Wayne Wu, Chen Qian, and Chen Change
    Loy. DeeperForensics-1.0: A large-scale dataset for real-world face forgery detection.
    In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    pages 2889–2898, 2020.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等 [2020] Liming Jiang、Ren Li、Wayne Wu、Chen Qian 和 Chen Change Loy。《DeeperForensics-1.0：一个用于现实世界面部伪造检测的大规模数据集》。发表于*IEEE/CVF
    计算机视觉与模式识别会议论文集*，第2889–2898页，2020年。
- en: Cho et al. [2014] Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry
    Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations
    using RNN encoder-decoder for statistical machine translation. *arXiv preprint
    arXiv:1406.1078*, 2014.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cho 等 [2014] Kyunghyun Cho、Bart Van Merriënboer、Caglar Gulcehre、Dzmitry Bahdanau、Fethi
    Bougares、Holger Schwenk 和 Yoshua Bengio。《使用 RNN 编码器-解码器学习短语表示以进行统计机器翻译》。*arXiv
    预印本 arXiv:1406.1078*，2014年。
- en: Güera and Delp [2018] David Güera and Edward J Delp. Deepfake video detection
    using recurrent neural networks. In *15th IEEE International Conference on Advanced
    Video and Signal based Surveillance (AVSS)*, pages 1–6\. IEEE, 2018.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Güera 和 Delp [2018] David Güera 和 Edward J Delp。《使用递归神经网络进行深度伪造视频检测》。发表于*第15届
    IEEE 高级视频与信号监控国际会议（AVSS）*，第1–6页。IEEE，2018年。
- en: Laptev et al. [2008] Ivan Laptev, Marcin Marszalek, Cordelia Schmid, and Benjamin
    Rozenfeld. Learning realistic human actions from movies. In *IEEE Conference on
    Computer Vision and Pattern Recognition*, pages 1–8\. IEEE, 2008.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Laptev 等 [2008] Ivan Laptev、Marcin Marszalek、Cordelia Schmid 和 Benjamin Rozenfeld。《从电影中学习现实的人类动作》。发表于*IEEE
    计算机视觉与模式识别会议*，第1–8页。IEEE，2008年。
- en: 'Li et al. [2018] Yuezun Li, Ming-Ching Chang, and Siwei Lyu. In ictu oculi:
    Exposing ai created fake videos by detecting eye blinking. In *2018 IEEE International
    Workshop on Information Forensics and Security (WIFS)*, pages 1–7\. IEEE, 2018.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2018] 李跃尊、张铭青和吕思伟。在眨眼中：通过检测眼睛眨动揭露 AI 创建的假视频。见于*2018 IEEE 国际信息取证与安全研讨会
    (WIFS)*，第 1–7 页。IEEE，2018。
- en: Donahue et al. [2015] Jeffrey Donahue, Lisa Anne Hendricks, Sergio Guadarrama,
    Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, and Trevor Darrell. Long-term
    recurrent convolutional networks for visual recognition and description. In *Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition*, pages 2625–2634,
    2015.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Donahue et al. [2015] 杰弗里·多纳休、丽莎·安·亨德里克斯、塞尔吉奥·瓜达拉马、马库斯·罗尔巴赫、苏巴希尼·韦努戈帕兰、凯特·塞恩科和特雷弗·达雷尔。用于视觉识别和描述的长期递归卷积网络。见于*IEEE
    计算机视觉与模式识别会议论文集*，第 2625–2634 页，2015。
- en: Caldelli et al. [2021] Roberto Caldelli, Leonardo Galteri, Irene Amerini, and
    Alberto Del Bimbo. Optical flow based CNN for detection of unlearnt deepfake manipulations.
    *Pattern Recognition Letters*, 146:31–37, 2021.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caldelli et al. [2021] 罗伯托·卡尔德利、莱昂纳多·加尔特里、艾琳·阿梅里尼和阿尔贝托·德尔·宾博。基于光流的 CNN 用于检测未学习的深度伪造操作。*模式识别快报*，146:31–37，2021。
- en: Amerini et al. [2019] Irene Amerini, Leonardo Galteri, Roberto Caldelli, and
    Alberto Del Bimbo. Deepfake video detection through optical flow based CNN. In
    *Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops*,
    pages 1205–1207, 2019.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amerini et al. [2019] 艾琳·阿梅里尼、莱昂纳多·加尔特里、罗伯托·卡尔德利和阿尔贝托·德尔·宾博。通过基于光流的 CNN 检测深度伪造视频。见于*IEEE/CVF
    国际计算机视觉会议研讨会论文集*，第 1205–1207 页，2019。
- en: He et al. [2016] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep
    residual learning for image recognition. In *Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition*, pages 770–778, 2016.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. [2016] 何凯明、张向宇、任少卿和孙剑。用于图像识别的深度残差学习。见于*IEEE 计算机视觉与模式识别会议论文集*，第 770–778
    页，2016。
- en: Simonyan and Zisserman [2014] Karen Simonyan and Andrew Zisserman. Very deep
    convolutional networks for large-scale image recognition. *arXiv preprint arXiv:1409.1556*,
    2014.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simonyan 和 Zisserman [2014] 卡伦·西蒙扬和安德鲁·齐瑟曼。用于大规模图像识别的非常深的卷积网络。*arXiv 预印本 arXiv:1409.1556*，2014。
- en: Li and Lyu [2018] Yuezun Li and Siwei Lyu. Exposing deepfake videos by detecting
    face warping artifacts. *arXiv preprint arXiv:1811.00656*, 2018.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 和 Lyu [2018] 李跃尊和吕思伟。通过检测面部变形伪影揭露深度伪造视频。*arXiv 预印本 arXiv:1811.00656*，2018。
- en: Yang et al. [2019] Xin Yang, Yuezun Li, and Siwei Lyu. Exposing deep fakes using
    inconsistent head poses. In *IEEE International Conference on Acoustics, Speech
    and Signal Processing (ICASSP)*, pages 8261–8265\. IEEE, 2019.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. [2019] 杨欣、李跃尊和吕思伟。使用不一致的头部姿态揭露深度伪造。见于*IEEE 国际声学、语音与信号处理会议 (ICASSP)*，第
    8261–8265 页。IEEE，2019。
- en: Zhou et al. [2017] Peng Zhou, Xintong Han, Vlad I Morariu, and Larry S Davis.
    Two-stream neural networks for tampered face detection. In *IEEE Conference on
    Computer Vision and Pattern Recognition Workshops (CVPRW)*, pages 1831–1839\.
    IEEE, 2017.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou et al. [2017] 周鹏、韩欣彤、弗拉德·I·莫拉留和拉里·S·戴维斯。用于篡改人脸检测的双流神经网络。见于*IEEE 计算机视觉与模式识别会议研讨会
    (CVPRW)*，第 1831–1839 页。IEEE，2017。
- en: 'Nguyen et al. [2019] Huy H Nguyen, Junichi Yamagishi, and Isao Echizen. Capsule-forensics:
    Using capsule networks to detect forged images and videos. In *IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP)*, pages 2307–2311\.
    IEEE, 2019.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nguyen et al. [2019] 阮辉、山岸纯一和越前功。胶囊取证：利用胶囊网络检测伪造的图像和视频。见于*IEEE 国际声学、语音与信号处理会议
    (ICASSP)*，第 2307–2311 页。IEEE，2019。
- en: Hinton et al. [2011] Geoffrey E Hinton, Alex Krizhevsky, and Sida D Wang. Transforming
    auto-encoders. In *International Conference on Artificial Neural Networks*, pages
    44–51\. Springer, 2011.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton et al. [2011] 杰弗里·E·欣顿、亚历克斯·克里日夫斯基和斯达·D·王。变换自编码器。见于*国际人工神经网络会议*，第 44–51
    页。Springer，2011。
- en: Sabour et al. [2017] Sara Sabour, Nicholas Frosst, and Geoffrey E Hinton. Dynamic
    routing between capsules. In *Proceedings of the 31st International Conference
    on Neural Information Processing Systems*, pages 3859–3869, 2017.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sabour et al. [2017] 萨拉·萨布尔、尼古拉斯·弗罗斯特和杰弗里·E·欣顿。胶囊之间的动态路由。见于*第 31 届国际神经信息处理系统会议论文集*，第
    3859–3869 页，2017。
- en: Chingovska et al. [2012] Ivana Chingovska, André Anjos, and Sébastien Marcel.
    On the effectiveness of local binary patterns in face anti-spoofing. In *Proceedings
    of the International Conference of Biometrics Secial Interest Group (BIOSIG)*,
    pages 1–7\. IEEE, 2012.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chingovska et al. [2012] 伊万娜·钦戈夫斯卡、安德烈·安乔斯和塞巴斯蒂安·马塞尔. 关于局部二值模式在面部防伪中的有效性. 见
    *国际生物识别会议特别兴趣小组（BIOSIG）会议录*，第1–7页. IEEE, 2012.
- en: 'Rössler et al. [2018] Andreas Rössler, Davide Cozzolino, Luisa Verdoliva, Christian
    Riess, Justus Thies, and Matthias Nießner. FaceForensics: A large-scale video
    dataset for forgery detection in human faces. *arXiv preprint arXiv:1803.09179*,
    2018.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rössler et al. [2018] 安德烈亚斯·罗斯勒、达维德·科佐利诺、路易莎·弗多利瓦、克里斯蒂安·里斯、贾斯图斯·蒂斯和马蒂亚斯·尼瑟纳.
    FaceForensics: 大规模视频数据集用于人脸伪造检测. *arXiv预印本arXiv:1803.09179*, 2018.'
- en: Rahmouni et al. [2017] Nicolas Rahmouni, Vincent Nozick, Junichi Yamagishi,
    and Isao Echizen. Distinguishing computer graphics from natural images using convolution
    neural networks. In *IEEE Workshop on Information Forensics and Security (WIFS)*,
    pages 1–6\. IEEE, 2017.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rahmouni et al. [2017] 尼古拉斯·拉赫穆尼、文森特·诺兹克、山岸顺一和伊萨奥·艾奇岑. 使用卷积神经网络区分计算机图形和自然图像.
    见 *IEEE信息取证与安全研讨会（WIFS）*，第1–6页. IEEE, 2017.
- en: 'Guan et al. [2019] Haiying Guan, Mark Kozak, Eric Robertson, Yooyoung Lee,
    Amy N Yates, Andrew Delgado, Daniel Zhou, Timothee Kheyrkhah, Jeff Smith, and
    Jonathan Fiscus. MFC datasets: Large-scale benchmark datasets for media forensic
    challenge evaluation. In *IEEE Winter Applications of Computer Vision Workshops
    (WACVW)*, pages 63–72\. IEEE, 2019.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guan et al. [2019] 关海英、马克·科扎克、埃里克·罗伯逊、李裕容、艾米·N·耶茨、安德鲁·德尔加多、丹尼尔·周、提摩太·凯尔哈、杰夫·史密斯和乔纳森·费斯卡斯.
    MFC数据集: 大规模基准数据集用于媒体取证挑战评估. 见 *IEEE计算机视觉冬季应用研讨会（WACVW）*，第63–72页. IEEE, 2019.'
- en: Matern et al. [2019] Falko Matern, Christian Riess, and Marc Stamminger. Exploiting
    visual artifacts to expose deepfakes and face manipulations. In *IEEE Winter Applications
    of Computer Vision Workshops (WACVW)*, pages 83–92\. IEEE, 2019.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matern et al. [2019] 法尔科·马特恩、克里斯蒂安·里斯和马克·斯塔明格. 利用视觉伪影揭露深伪和面部操控. 见 *IEEE计算机视觉冬季应用研讨会（WACVW）*，第83–92页.
    IEEE, 2019.
- en: Koopman et al. [2018] Marissa Koopman, Andrea Macarulla Rodriguez, and Zeno
    Geradts. Detection of deepfake video manipulation. In *The 20th Irish Machine
    Vision and Image Processing Conference (IMVIP)*, pages 133–136, 2018.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koopman et al. [2018] 玛丽莎·库普曼、安德烈亚·马卡鲁拉·罗德里格斯和泽诺·杰拉茨. 深伪视频操控检测. 见 *第20届爱尔兰机器视觉与图像处理会议（IMVIP）*，第133–136页,
    2018.
- en: Rosenfeld and Sencar [2009] Kurt Rosenfeld and Husrev Taha Sencar. A study of
    the robustness of PRNU-based camera identification. In *Media Forensics and Security*,
    volume 7254, page 72540M, 2009.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rosenfeld and Sencar [2009] 库尔特·罗森费尔德和胡斯雷夫·塔哈·森卡尔. 基于PRNU的相机识别的鲁棒性研究. 见 *媒体取证与安全*，第7254卷，第72540M页,
    2009.
- en: Li and Li [2011] Chang-Tsun Li and Yue Li. Color-decoupled photo response non-uniformity
    for digital image forensics. *IEEE Transactions on Circuits and Systems for Video
    Technology*, 22(2):260–271, 2011.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li and Li [2011] 李长勋和李岳. 数字图像取证中的颜色解耦光响应不均匀性. *IEEE视频技术电路与系统汇刊*, 22(2):260–271,
    2011.
- en: Lin and Li [2016] Xufeng Lin and Chang-Tsun Li. Large-scale image clustering
    based on camera fingerprints. *IEEE Transactions on Information Forensics and
    Security*, 12(4):793–808, 2016.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin and Li [2016] 林旭丰和李长勋. 基于相机指纹的大规模图像聚类. *IEEE信息取证与安全汇刊*, 12(4):793–808, 2016.
- en: Scherhag et al. [2019] Ulrich Scherhag, Luca Debiasi, Christian Rathgeb, Christoph
    Busch, and Andreas Uhl. Detection of face morphing attacks based on PRNU analysis.
    *IEEE Transactions on Biometrics, Behavior, and Identity Science*, 1(4):302–317,
    2019.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scherhag et al. [2019] 乌尔里希·舍尔哈格、卢卡·德比亚西、克里斯蒂安·拉斯赫和安德烈亚斯·乌尔. 基于PRNU分析的面部变形攻击检测.
    *IEEE生物识别、行为与身份科学汇刊*, 1(4):302–317, 2019.
- en: Phan et al. [2018] Quoc-Tin Phan, Giulia Boato, and Francesco GB De Natale.
    Accurate and scalable image clustering based on sparse representation of camera
    fingerprint. *IEEE Transactions on Information Forensics and Security*, 14(7):1902–1916,
    2018.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Phan et al. [2018]
- en: Hasan and Salah [2019] Haya R Hasan and Khaled Salah. Combating deepfake videos
    using blockchain and smart contracts. *IEEE Access*, 7:41596–41606, 2019.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hasan and Salah [2019] 哈亚·R·哈桑和卡勒德·萨拉赫. 使用区块链和智能合约对抗深伪视频. *IEEE Access*, 7:41596–41606,
    2019.
- en: '[138] IPFS powers the distributed web. [https://ipfs.io/](https://ipfs.io/).'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] IPFS 赋能分布式网络. [https://ipfs.io/](https://ipfs.io/).'
- en: Chintha et al. [2020] Akash Chintha, Bao Thai, Saniat Javid Sohrawardi, Kartavya
    Bhatt, Andrea Hickerson, Matthew Wright, and Raymond Ptucha. Recurrent convolutional
    structures for audio spoof and video deepfake detection. *IEEE Journal of Selected
    Topics in Signal Processing*, 14(5):1024–1037, 2020.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chintha 等 [2020] Akash Chintha, Bao Thai, Saniat Javid Sohrawardi, Kartavya
    Bhatt, Andrea Hickerson, Matthew Wright 和 Raymond Ptucha. 用于音频伪造和视频深伪检测的递归卷积结构。
    *IEEE 选择主题信号处理汇刊*，14(5):1024–1037，2020。
- en: 'Todisco et al. [2019] Massimiliano Todisco, Xin Wang, Ville Vestman, Md Sahidullah,
    Héctor Delgado, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Tomi Kinnunen,
    and Kong Aik Lee. ASVspoof 2019: Future horizons in spoofed and fake audio detection.
    *arXiv preprint arXiv:1904.05441*, 2019.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Todisco 等 [2019] Massimiliano Todisco, Xin Wang, Ville Vestman, Md Sahidullah,
    Héctor Delgado, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Tomi Kinnunen
    和 Kong Aik Lee. ASVspoof 2019: 伪造和虚假音频检测的未来前景。 *arXiv 预印本 arXiv:1904.05441*，2019。'
- en: Agarwal et al. [2020a] Shruti Agarwal, Hany Farid, Ohad Fried, and Maneesh Agrawala.
    Detecting deep-fake videos from phoneme-viseme mismatches. In *Proceedings of
    the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops*,
    pages 660–661, 2020a.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agarwal 等 [2020a] Shruti Agarwal, Hany Farid, Ohad Fried 和 Maneesh Agrawala.
    通过音素-视觉映像不匹配检测深伪视频。发表于 *IEEE/CVF 计算机视觉与模式识别会议工作坊论文集*，第 660–661 页，2020a。
- en: Fried et al. [2019] Ohad Fried, Ayush Tewari, Michael Zollhöfer, Adam Finkelstein,
    Eli Shechtman, Dan B Goldman, Kyle Genova, Zeyu Jin, Christian Theobalt, and Maneesh
    Agrawala. Text-based editing of talking-head video. *ACM Transactions on Graphics
    (TOG)*, 38(4):1–14, 2019.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fried 等 [2019] Ohad Fried, Ayush Tewari, Michael Zollhöfer, Adam Finkelstein,
    Eli Shechtman, Dan B Goldman, Kyle Genova, Zeyu Jin, Christian Theobalt 和 Maneesh
    Agrawala. 基于文本的对话视频编辑。 *ACM 图形学汇刊 (TOG)*，38(4):1–14，2019。
- en: Fernandes et al. [2020] Steven Fernandes, Sunny Raj, Rickard Ewetz, Jodh Singh
    Pannu, Sumit Kumar Jha, Eddy Ortiz, Iustina Vintila, and Margaret Salter. Detecting
    deepfake videos using attribution-based confidence metric. In *Proceedings of
    the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops*,
    pages 308–309, 2020.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fernandes 等 [2020] Steven Fernandes, Sunny Raj, Rickard Ewetz, Jodh Singh Pannu,
    Sumit Kumar Jha, Eddy Ortiz, Iustina Vintila 和 Margaret Salter. 使用基于归因的置信度度量检测深伪视频。发表于
    *IEEE/CVF 计算机视觉与模式识别会议工作坊论文集*，第 308–309 页，2020。
- en: 'Cao et al. [2018] Qiong Cao, Li Shen, Weidi Xie, Omkar M Parkhi, and Andrew
    Zisserman. VGGFace2: A dataset for recognising faces across pose and age. In *The
    13th IEEE International Conference on Automatic Face & Gesture Recognition (FG
    2018)*, pages 67–74\. IEEE, 2018.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cao 等 [2018] Qiong Cao, Li Shen, Weidi Xie, Omkar M Parkhi 和 Andrew Zisserman.
    VGGFace2: 一个用于跨姿态和年龄识别面孔的数据集。发表于 *第 13 届 IEEE 国际自动人脸与姿态识别会议 (FG 2018)*，第 67–74
    页，IEEE，2018。'
- en: Jha et al. [2019] Susmit Jha, Sunny Raj, Steven Fernandes, Sumit K Jha, Somesh
    Jha, Brian Jalaian, Gunjan Verma, and Ananthram Swami. Attribution-based confidence
    metric for deep neural networks. *Advances in Neural Information Processing Systems*,
    32:11826–11837, 2019.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jha 等 [2019] Susmit Jha, Sunny Raj, Steven Fernandes, Sumit K Jha, Somesh Jha,
    Brian Jalaian, Gunjan Verma 和 Ananthram Swami. 基于归因的深度神经网络置信度度量。 *神经信息处理系统进展*，32:11826–11837，2019。
- en: Fernandes et al. [2019] Steven Fernandes, Sunny Raj, Eddy Ortiz, Iustina Vintila,
    Margaret Salter, Gordana Urosevic, and Sumit Jha. Predicting heart rate variations
    of deepfake videos using neural ODE. In *Proceedings of the IEEE/CVF International
    Conference on Computer Vision Workshops*, pages 1721–1729, 2019.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fernandes 等 [2019] Steven Fernandes, Sunny Raj, Eddy Ortiz, Iustina Vintila,
    Margaret Salter, Gordana Urosevic 和 Sumit Jha. 使用神经常微分方程预测深伪视频的心率变化。发表于 *IEEE/CVF
    国际计算机视觉会议工作坊论文集*，第 1721–1729 页，2019。
- en: 'Korshunov and Marcel [2018b] Pavel Korshunov and Sébastien Marcel. Deepfakes:
    a new threat to face recognition? assessment and detection. *arXiv preprint arXiv:1812.08685*,
    2018b.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Korshunov 和 Marcel [2018b] Pavel Korshunov 和 Sébastien Marcel. 深伪技术: 对面部识别的新威胁？评估与检测。
    *arXiv 预印本 arXiv:1812.08685*，2018b。'
- en: Agarwal et al. [2020b] Shruti Agarwal, Hany Farid, Tarek El-Gaaly, and Ser-Nam
    Lim. Detecting deep-fake videos from appearance and behavior. In *IEEE International
    Workshop on Information Forensics and Security (WIFS)*, pages 1–6\. IEEE, 2020b.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agarwal 等 [2020b] Shruti Agarwal, Hany Farid, Tarek El-Gaaly 和 Ser-Nam Lim.
    从外观和行为中检测深伪视频。发表于 *IEEE 信息取证与安全国际研讨会 (WIFS)*，第 1–6 页，IEEE，2020b。
- en: 'Ciftci et al. [2020] Umur Aybars Ciftci, Ilke Demir, and Lijun Yin. FakeCatcher:
    Detection of synthetic portrait videos using biological signals. *IEEE Transactions
    on Pattern Analysis and Machine Intelligence*, 2020.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ciftci 等 [2020] Umur Aybars Ciftci, Ilke Demir 和 Lijun Yin. FakeCatcher: 使用生物信号检测合成肖像视频。
    *IEEE 模式分析与机器智能汇刊*，2020。'
- en: 'Mittal et al. [2020] Trisha Mittal, Uttaran Bhattacharya, Rohan Chandra, Aniket
    Bera, and Dinesh Manocha. Emotions don’t lie: A deepfake detection method using
    audio-visual affective cues. *arXiv preprint arXiv:2003.06711*, 3, 2020.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mittal 等 [2020] Trisha Mittal、Uttaran Bhattacharya、Rohan Chandra、Aniket Bera
    和 Dinesh Manocha。情感不会撒谎：一种使用视听情感线索的深伪检测方法。*arXiv 预印本 arXiv:2003.06711*，3，2020
    年。
- en: Guarnera et al. [2020b] Luca Guarnera, Oliver Giudice, and Sebastiano Battiato.
    Deepfake detection by analyzing convolutional traces. In *Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition Workshops*, pages 666–667,
    2020b.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guarnera 等 [2020b] Luca Guarnera、Oliver Giudice 和 Sebastiano Battiato。通过分析卷积痕迹进行深伪检测。在
    *IEEE/CVF 计算机视觉与模式识别会议研讨会论文集* 中，页码 666–667，2020b 年。
- en: Cho et al. [2019] Wonwoong Cho, Sungha Choi, David Keetae Park, Inkyu Shin,
    and Jaegul Choo. Image-to-image translation via group-wise deep whitening-and-coloring
    transformation. In *Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition*, pages 10639–10647, 2019.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cho 等 [2019] Wonwoong Cho、Sungha Choi、David Keetae Park、Inkyu Shin 和 Jaegul
    Choo。通过组wise 深度白化和着色变换进行图像到图像的转换。在 *IEEE/CVF 计算机视觉与模式识别会议论文集* 中，页码 10639–10647，2019
    年。
- en: 'Choi et al. [2018] Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun
    Kim, and Jaegul Choo. StarGAN: Unified generative adversarial networks for multi-domain
    image-to-image translation. In *Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition*, pages 8789–8797, 2018.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Choi 等 [2018] Yunjey Choi、Minje Choi、Munyoung Kim、Jung-Woo Ha、Sunghun Kim 和
    Jaegul Choo。StarGAN：用于多域图像到图像转换的统一生成对抗网络。在 *IEEE 计算机视觉与模式识别会议论文集* 中，页码 8789–8797，2018
    年。
- en: 'He et al. [2019] Zhenliang He, Wangmeng Zuo, Meina Kan, Shiguang Shan, and
    Xilin Chen. AttGAN: Facial attribute editing by only changing what you want. *IEEE
    Transactions on Image Processing*, 28(11):5464–5478, 2019.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等 [2019] Zhenliang He、Wangmeng Zuo、Meina Kan、Shiguang Shan 和 Xilin Chen。AttGAN：仅通过改变你想要的内容进行面部属性编辑。*IEEE
    图像处理汇刊*，28(11):5464–5478，2019 年。
- en: Karras et al. [2020] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten,
    Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of stylegan.
    In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    pages 8110–8119, 2020.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karras 等 [2020] Tero Karras、Samuli Laine、Miika Aittala、Janne Hellsten、Jaakko
    Lehtinen 和 Timo Aila。分析和改进 StyleGAN 的图像质量。在 *IEEE/CVF 计算机视觉与模式识别会议论文集* 中，页码 8110–8119，2020
    年。
- en: 'Huang et al. [2007] Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.
    Labeled faces in the wild: A database for studying face recognition in unconstrained
    environments. Technical Report 07-49, University of Massachusetts, Amherst, October
    2007.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等 [2007] Gary B. Huang、Manu Ramesh、Tamara Berg 和 Erik Learned-Miller。在野外标记的人脸：用于研究无约束环境下人脸识别的数据库。技术报告
    07-49，马萨诸塞大学阿默斯特分校，2007 年 10 月。
- en: Gandhi and Jain [2020] Apurva Gandhi and Shomik Jain. Adversarial perturbations
    fool deepfake detectors. In *IEEE International Joint Conference on Neural Networks
    (IJCNN)*, pages 1–8\. IEEE, 2020.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gandhi 和 Jain [2020] Apurva Gandhi 和 Shomik Jain。对抗性扰动欺骗深伪检测器。在 *IEEE 国际联合神经网络会议（IJCNN）*
    中，页码 1–8。IEEE，2020 年。
- en: '[158] Few-shot face translation GAN. [https://github.com/shaoanlu/fewshot-face-translation-GAN](https://github.com/shaoanlu/fewshot-face-translation-GAN).'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] 少样本人脸转换 GAN。 [https://github.com/shaoanlu/fewshot-face-translation-GAN](https://github.com/shaoanlu/fewshot-face-translation-GAN)。'
- en: Li et al. [2020b] Lingzhi Li, Jianmin Bao, Ting Zhang, Hao Yang, Dong Chen,
    Fang Wen, and Baining Guo. Face X-ray for more general face forgery detection.
    In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    pages 5001–5010, 2020b.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 [2020b] Lingzhi Li、Jianmin Bao、Ting Zhang、Hao Yang、Dong Chen、Fang Wen 和
    Baining Guo。Face X-ray 用于更通用的人脸伪造检测。在 *IEEE/CVF 计算机视觉与模式识别会议论文集* 中，页码 5001–5010，2020b
    年。
- en: Wang et al. [2020] Sheng-Yu Wang, Oliver Wang, Richard Zhang, Andrew Owens,
    and Alexei A Efros. CNN-generated images are surprisingly easy to spot… for now.
    In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    pages 8695–8704, 2020.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 [2020] Sheng-Yu Wang、Oliver Wang、Richard Zhang、Andrew Owens 和 Alexei
    A Efros。CNN 生成的图像现在 surprisingly 容易被发现。在 *IEEE/CVF 计算机视觉与模式识别会议论文集* 中，页码 8695–8704，2020
    年。
- en: Dai et al. [2019] Tao Dai, Jianrui Cai, Yongbing Zhang, Shu-Tao Xia, and Lei
    Zhang. Second-order attention network for single image super-resolution. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages
    11065–11074, 2019.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dai 等 [2019] Tao Dai、Jianrui Cai、Yongbing Zhang、Shu-Tao Xia 和 Lei Zhang。用于单图像超分辨率的二阶注意力网络。在
    *IEEE/CVF 计算机视觉与模式识别会议论文集* 中，页码 11065–11074，2019 年。
- en: Guarnera et al. [2020c] Luca Guarnera, Oliver Giudice, and Sebastiano Battiato.
    Fighting deepfake by exposing the convolutional traces on images. *IEEE Access*,
    8:165085–165098, 2020c.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guarnera 等 [2020c] Luca Guarnera, Oliver Giudice 和 Sebastiano Battiato。通过暴露图像上的卷积痕迹来对抗深度伪造。
    *IEEE Access*，8：165085–165098，2020年。
- en: Moon [1996] Todd K Moon. The expectation-maximization algorithm. *IEEE Signal
    Processing Magazine*, 13(6):47–60, 1996.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moon [1996] Todd K Moon。期望最大化算法。 *IEEE信号处理杂志*，13(6)：47–60，1996年。
- en: Zhu et al. [2017] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros.
    Unpaired image-to-image translation using cycle-consistent adversarial networks.
    In *Proceedings of the IEEE international conference on computer vision*, pages
    2223–2232, 2017.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等 [2017] Jun-Yan Zhu, Taesung Park, Phillip Isola 和 Alexei A Efros。使用循环一致对抗网络的无配对图像到图像转换。在
    *IEEE国际计算机视觉大会论文集*，第2223–2232页，2017年。
- en: Li et al. [2019b] Ke Li, Tianhao Zhang, and Jitendra Malik. Diverse image synthesis
    from semantic layouts via conditional imle. In *Proceedings of the IEEE/CVF International
    Conference on Computer Vision*, pages 4220–4229, 2019b.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 [2019b] Ke Li, Tianhao Zhang 和 Jitendra Malik。通过条件 IMLE 从语义布局生成多样化图像。在
    *IEEE/CVF国际计算机视觉会议论文集*，第4220–4229页，2019年。
- en: 'Zubiaga et al. [2018] Arkaitz Zubiaga, Ahmet Aker, Kalina Bontcheva, Maria
    Liakata, and Rob Procter. Detection and resolution of rumours in social media:
    A survey. *ACM Computing Surveys (CSUR)*, 51(2):1–36, 2018.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zubiaga 等 [2018] Arkaitz Zubiaga, Ahmet Aker, Kalina Bontcheva, Maria Liakata
    和 Rob Procter。社交媒体中的谣言检测与解决：综述。 *ACM计算调查（CSUR）*，51(2)：1–36，2018年。
- en: 'Chesney and Citron [2018b] R. Chesney and D. K. Citron. Disinformation on steroids:
    The threat of deep fakes. [https://www.cfr.org/report/deep-fake-disinformation-steroids](https://www.cfr.org/report/deep-fake-disinformation-steroids),
    October 2018b.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chesney 和 Citron [2018b] R. Chesney 和 D. K. Citron。强效假信息：深度伪造的威胁。 [https://www.cfr.org/report/deep-fake-disinformation-steroids](https://www.cfr.org/report/deep-fake-disinformation-steroids)，2018年10月。
- en: Floridi [2018] Luciano Floridi. Artificial intelligence, deepfakes and a future
    of ectypes. *Philosophy & Technology*, 31(3):317–321, 2018.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Floridi [2018] Luciano Floridi。人工智能、深度伪造与未来的形态。 *哲学与技术*，31(3)：317–321，2018年。
- en: 'Cozzolino et al. [2018] Davide Cozzolino, Justus Thies, Andreas Rössler, Christian
    Riess, Matthias Nießner, and Luisa Verdoliva. ForensicTransfer: Weakly-supervised
    domain adaptation for forgery detection. *arXiv preprint arXiv:1812.02510*, 2018.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cozzolino 等 [2018] Davide Cozzolino, Justus Thies, Andreas Rössler, Christian
    Riess, Matthias Nießner 和 Luisa Verdoliva。ForensicTransfer：用于伪造检测的弱监督领域适应。 *arXiv
    预印本 arXiv:1812.02510*，2018年。
- en: Marra et al. [2019] Francesco Marra, Cristiano Saltori, Giulia Boato, and Luisa
    Verdoliva. Incremental learning for the detection and classification of gan-generated
    images. In *2019 IEEE International Workshop on Information Forensics and Security
    (WIFS)*, pages 1–6\. IEEE, 2019.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marra 等 [2019] Francesco Marra, Cristiano Saltori, Giulia Boato 和 Luisa Verdoliva。增量学习用于生成对抗网络生成图像的检测与分类。在
    *2019 IEEE国际信息取证与安全研讨会（WIFS）*，第1–6页。IEEE，2019年。
- en: 'Hussain et al. [2021] Shehzeen Hussain, Paarth Neekhara, Malhar Jere, Farinaz
    Koushanfar, and Julian McAuley. Adversarial deepfakes: Evaluating vulnerability
    of deepfake detectors to adversarial examples. In *Proceedings of the IEEE/CVF
    Winter Conference on Applications of Computer Vision*, pages 3348–3357, 2021.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hussain 等 [2021] Shehzeen Hussain, Paarth Neekhara, Malhar Jere, Farinaz Koushanfar
    和 Julian McAuley。对抗性深度伪造：评估深度伪造检测器对对抗样本的脆弱性。在 *IEEE/CVF计算机视觉应用冬季会议论文集*，第3348–3357页，2021年。
- en: Carlini and Farid [2020] Nicholas Carlini and Hany Farid. Evading deepfake-image
    detectors with white-and black-box attacks. In *Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition Workshops*, pages 658–659, 2020.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carlini 和 Farid [2020] Nicholas Carlini 和 Hany Farid。利用白盒和黑盒攻击规避深度伪造图像检测器。在
    *IEEE/CVF计算机视觉与模式识别会议论文集*，第658–659页，2020年。
- en: Yang et al. [2021] Chaofei Yang, Leah Ding, Yiran Chen, and Hai Li. Defending
    against gan-based deepfake attacks via transformation-aware adversarial faces.
    In *IEEE International Joint Conference on Neural Networks (IJCNN)*, pages 1–8\.
    IEEE, 2021.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等 [2021] Chaofei Yang, Leah Ding, Yiran Chen 和 Hai Li。通过变换感知对抗面孔防御基于生成对抗网络的深度伪造攻击。在
    *IEEE国际神经网络联合会议（IJCNN）*，第1–8页。IEEE，2021年。
- en: Yeh et al. [2020] Chin-Yuan Yeh, Hsi-Wen Chen, Shang-Lun Tsai, and Sheng-De
    Wang. Disrupting image-translation-based deepfake algorithms with adversarial
    attacks. In *Proceedings of the IEEE/CVF Winter Conference on Applications of
    Computer Vision Workshops*, pages 53–62, 2020.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yeh et al. [2020] Chin-Yuan Yeh, Hsi-Wen Chen, Shang-Lun Tsai, 和 Sheng-De Wang.
    通过对抗攻击破坏基于图像翻译的深度伪造算法。在*IEEE/CVF冬季计算机视觉应用研讨会论文集*，第53–62页，2020年。
- en: Read [2019] M. Read. Can you spot a deepfake? does it matter? [http://nymag.com/intelligencer/2019/06/how-do-you-spot-a-deepfake-it-might-not-matter.html](http://nymag.com/intelligencer/2019/06/how-do-you-spot-a-deepfake-it-might-not-matter.html),
    June 2019.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Read [2019] M. Read. 你能识别深度伪造吗？这重要吗？[http://nymag.com/intelligencer/2019/06/how-do-you-spot-a-deepfake-it-might-not-matter.html](http://nymag.com/intelligencer/2019/06/how-do-you-spot-a-deepfake-it-might-not-matter.html)，2019年6月。
- en: Maras and Alexandrou [2019] Marie-Helen Maras and Alex Alexandrou. Determining
    authenticity of video evidence in the age of artificial intelligence and in the
    wake of deepfake videos. *The International Journal of Evidence & Proof*, 23(3):255–262,
    2019.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maras and Alexandrou [2019] Marie-Helen Maras 和 Alex Alexandrou. 在人工智能时代及深度伪造视频影响下，确定视频证据的真实性。*国际证据与证明期刊*,
    23(3):255–262, 2019年。
- en: Su et al. [2017] Lichao Su, Cuihua Li, Yuecong Lai, and Jianmei Yang. A fast
    forgery detection algorithm based on exponential-Fourier moments for video region
    duplication. *IEEE Transactions on Multimedia*, 20(4):825–840, 2017.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Su et al. [2017] Lichao Su, Cuihua Li, Yuecong Lai, 和 Jianmei Yang. 基于指数傅里叶矩的视频区域复制快速伪造检测算法。*IEEE多媒体交易*,
    20(4):825–840, 2017年。
- en: Iuliani et al. [2018] Massimo Iuliani, Dasara Shullani, Marco Fontani, Saverio
    Meucci, and Alessandro Piva. A video forensic framework for the unsupervised analysis
    of MP4-like file container. *IEEE Transactions on Information Forensics and Security*,
    14(3):635–645, 2018.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iuliani et al. [2018] Massimo Iuliani, Dasara Shullani, Marco Fontani, Saverio
    Meucci, 和 Alessandro Piva. 用于无监督分析MP4类文件容器的视频取证框架。*IEEE信息取证与安全交易*, 14(3):635–645,
    2018年。
- en: Malolan et al. [2020] Badhrinarayan Malolan, Ankit Parekh, and Faruk Kazi. Explainable
    deep-fake detection using visual interpretability methods. In *The 3rd International
    Conference on Information and Computer Technologies (ICICT)*, pages 289–293\.
    IEEE, 2020.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Malolan et al. [2020] Badhrinarayan Malolan, Ankit Parekh, 和 Faruk Kazi. 使用视觉可解释性方法的可解释深度伪造检测。在*第3届国际信息与计算机技术会议（ICICT）*，第289–293页。IEEE，2020年。
- en: Giudice et al. [2021] Oliver Giudice, Luca Guarnera, and Sebastiano Battiato.
    Fighting deepfakes by detecting GAN DCT anomalies. *arXiv preprint arXiv:2101.09781*,
    2021.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Giudice et al. [2021] Oliver Giudice, Luca Guarnera, 和 Sebastiano Battiato.
    通过检测GAN DCT异常来对抗深度伪造。*arXiv预印本arXiv:2101.09781*, 2021年。
