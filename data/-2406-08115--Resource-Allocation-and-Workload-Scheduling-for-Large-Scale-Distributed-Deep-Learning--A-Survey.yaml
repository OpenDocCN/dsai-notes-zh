- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:31:39'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:31:39
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2406.08115] Resource Allocation and Workload Scheduling for Large-Scale Distributed
    Deep Learning: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2406.08115] 大规模分布式深度学习的资源分配与工作负载调度：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.08115](https://ar5iv.labs.arxiv.org/html/2406.08115)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.08115](https://ar5iv.labs.arxiv.org/html/2406.08115)
- en: '10081'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '10081'
- en: 'Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey'
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大规模分布式深度学习的资源分配与工作负载调度：综述
- en: Feng Liang [fliang@smbu.edu.cn](mailto:fliang@smbu.edu.cn) [0000-0002-8542-9871](https://orcid.org/0000-0002-8542-9871
    "ORCID identifier") Artificial Intelligence Research Institute, Shenzhen MSU-BIT
    UniversityChina518107 Guangdong-Hong Kong-Macao Joint Laboratory for Emotional
    Intelligence and Pervasive Computing, Shenzhen MSU-BIT UniversityChina518107 , 
    Zhen Zhang [zhangzhen19@lzu.edu.cn](mailto:zhangzhen19@lzu.edu.cn) [0009-0007-9955-0916](https://orcid.org/0009-0007-9955-0916
    "ORCID identifier") ,  Haifeng Lu [luhf18@lzu.edu.cn](mailto:luhf18@lzu.edu.cn)
    [0000-0003-0155-8447](https://orcid.org/0000-0003-0155-8447 "ORCID identifier")
    Gansu Provincial Key Laboratory of Wearable Computing, School of Information Science
    and Engineering, Lanzhou UniversityChina730000 Guangdong-Hong Kong-Macao Joint
    Laboratory for Emotional Intelligence and Pervasive Computing, Shenzhen MSU-BIT
    UniversityChina518107 ,  Chengming Li [licm@smbu.edu.cn](mailto:licm@smbu.edu.cn)
    [0000-0002-8542-9871](https://orcid.org/0000-0002-8542-9871 "ORCID identifier")
    Artificial Intelligence Research Institute, Shenzhen MSU-BIT UniversityChina518107
    Guangdong-Hong Kong-Macao Joint Laboratory for Emotional Intelligence and Pervasive
    Computing, Shenzhen MSU-BIT UniversityChina518107 ,  Victor C. M. Leung [vleung@ieee.org](mailto:vleung@ieee.org)
    [0000-0003-3529-2640](https://orcid.org/0000-0003-3529-2640 "ORCID identifier")
    Artificial Intelligence Research Institute, Shenzhen MSU-BIT UniversityChina518107
    Department of Electrical and Computer Engineering, The University of British ColumbiaCanadaV6T
    1Z4 ,  Yanyi Guo [guoyy@smbu.edu.cn](mailto:guoyy@smbu.edu.cn) [0009-0000-7682-6667](https://orcid.org/0009-0000-7682-6667
    "ORCID identifier") Frontier Cross Disciplinary Research Institute, Shenzhen MSU-BIT
    UniversityChina School of Mechanical and Electrical Engineering, Beijing Institute
    of TechnologyChina  and  Xiping Hu [huxp@smbu.edu.cn](mailto:huxp@smbu.edu.cn)
    [0000-0002-4952-699X](https://orcid.org/0000-0002-4952-699X "ORCID identifier")
    Artificial Intelligence Research Institute, Shenzhen MSU-BIT UniversityChina518107
    Guangdong-Hong Kong-Macao Joint Laboratory for Emotional Intelligence and Pervasive
    Computing, Shenzhen MSU-BIT UniversityChina518107 School of Medical Technology,
    Beijing Institute of TechnologyChina10081
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 冯亮 [fliang@smbu.edu.cn](mailto:fliang@smbu.edu.cn) [0000-0002-8542-9871](https://orcid.org/0000-0002-8542-9871
    "ORCID identifier") 深圳市 MSU-BIT 大学人工智能研究院，中国518107 广东-香港-澳门情感智能与普适计算联合实验室，深圳市
    MSU-BIT 大学，中国518107 ， 张真 [zhangzhen19@lzu.edu.cn](mailto:zhangzhen19@lzu.edu.cn)
    [0009-0007-9955-0916](https://orcid.org/0009-0007-9955-0916 "ORCID identifier")
    ， 陆海峰 [luhf18@lzu.edu.cn](mailto:luhf18@lzu.edu.cn) [0000-0003-0155-8447](https://orcid.org/0000-0003-0155-8447
    "ORCID identifier") 甘肃省可穿戴计算重点实验室，兰州大学信息科学与工程学院，中国730000 广东-香港-澳门情感智能与普适计算联合实验室，深圳市
    MSU-BIT 大学，中国518107 ， 李成铭 [licm@smbu.edu.cn](mailto:licm@smbu.edu.cn) [0000-0002-8542-9871](https://orcid.org/0000-0002-8542-9871
    "ORCID identifier") 深圳市 MSU-BIT 大学人工智能研究院，中国518107 广东-香港-澳门情感智能与普适计算联合实验室，深圳市
    MSU-BIT 大学，中国518107 ， 梁维克 [vleung@ieee.org](mailto:vleung@ieee.org) [0000-0003-3529-2640](https://orcid.org/0000-0003-3529-2640
    "ORCID identifier") 深圳市 MSU-BIT 大学人工智能研究院，中国518107 不列颠哥伦比亚大学电气与计算机工程系，加拿大V6T 1Z4
    ， 郭彦毅 [guoyy@smbu.edu.cn](mailto:guoyy@smbu.edu.cn) [0009-0000-7682-6667](https://orcid.org/0009-0000-7682-6667
    "ORCID identifier") 深圳市 MSU-BIT 大学前沿交叉学科研究院，中国 北京理工大学机械与电气工程学院，中国  以及  胡西平 [huxp@smbu.edu.cn](mailto:huxp@smbu.edu.cn)
    [0000-0002-4952-699X](https://orcid.org/0000-0002-4952-699X "ORCID identifier")
    深圳市 MSU-BIT 大学人工智能研究院，中国518107 广东-香港-澳门情感智能与普适计算联合实验室，深圳市 MSU-BIT 大学，中国518107
    北京理工大学医学技术学院，中国10081
- en: Abstract.
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: With rapidly increasing distributed deep learning workloads in large-scale data
    centers, efficient distributed deep learning framework strategies for resource
    allocation and workload scheduling have become the key to high-performance deep
    learning. The large-scale environment with large volumes of datasets, models,
    and computational and communication resources raises various unique challenges
    for resource allocation and workload scheduling in distributed deep learning,
    such as scheduling complexity, resource and workload heterogeneity, and fault
    tolerance. To uncover these challenges and corresponding solutions, this survey
    reviews the literature, mainly from 2019 to 2024, on efficient resource allocation
    and workload scheduling strategies for large-scale distributed DL. We explore
    these strategies by focusing on various resource types, scheduling granularity
    levels, and performance goals during distributed training and inference processes.
    We highlight critical challenges for each topic and discuss key insights of existing
    technologies. To illustrate practical large-scale resource allocation and workload
    scheduling in real distributed deep learning scenarios, we use a case study of
    training large language models. This survey aims to encourage computer science,
    artificial intelligence, and communications researchers to understand recent advances
    and explore future research directions for efficient framework strategies for
    large-scale distributed deep learning.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大规模数据中心中分布式深度学习工作负载的迅速增加，高效的分布式深度学习框架策略对于资源分配和工作负载调度已成为高性能深度学习的关键。大规模环境下的数据集、模型以及计算和通信资源的大量存在带来了资源分配和工作负载调度的各种独特挑战，如调度复杂性、资源和工作负载异质性以及容错能力。为了解这些挑战及其对应的解决方案，本综述回顾了2019年至2024年的文献，主要针对大规模分布式深度学习的高效资源分配和工作负载调度策略。我们通过关注各种资源类型、调度粒度水平和分布式训练及推理过程中的性能目标来探讨这些策略。我们强调了每个主题的关键挑战，并讨论了现有技术的关键见解。为了说明实际大规模资源分配和工作负载调度在真实分布式深度学习场景中的应用，我们使用了训练大型语言模型的案例研究。本综述旨在鼓励计算机科学、人工智能和通信领域的研究人员了解近期进展，并探索大规模分布式深度学习高效框架策略的未来研究方向。
- en: 'Distributed deep learning, Resource allocation, GPU sharing, Task scheduling,
    Large model, Pipeline parallelism^†^†ccs: Computer systems organization Distributed
    architectures^†^†ccs: Computing methodologies Machine learning^†^†ccs: Computing
    methodologies Artificial intelligence^†^†ccs: Networks Cloud computing'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '分布式深度学习、资源分配、GPU共享、任务调度、大模型、流水线并行^†^†ccs: 计算机系统组织 分布式架构^†^†ccs: 计算方法 机器学习^†^†ccs:
    计算方法 人工智能^†^†ccs: 网络 云计算'
- en: 1\. Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 介绍
- en: With the rapid increase in the sizes of datasets and deep learning (DL) models,
    distributed DL (Liang et al., [2024](#bib.bib65); Yu et al., [2023](#bib.bib137))
    has become the state-of-the-art practice for various artificial intelligence technologies,
    federated learning (Liu et al., [2022b](#bib.bib68)) and smart Internet of Things (Al-Garadi
    et al., [2020](#bib.bib6)). In contrast to traditional single-node DL that works
    on a single computing node or even a single GPU, distributed DL can leverage multiple
    GPUs and computing nodes to handle massive training and inference workloads and
    improve learning throughput. Notably, in the era of extremely large models with
    tens of billions of parameters, distributed DL enables efficient large-model training (et al.,
    [2023](#bib.bib27)) across hundreds of computing nodes with thousands of GPUs
    in the data center.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据集和深度学习（DL）模型规模的迅速增长，分布式DL （Liang et al., [2024](#bib.bib65); Yu et al.,
    [2023](#bib.bib137)）已成为各种人工智能技术、联邦学习 （Liu et al., [2022b](#bib.bib68)）和智能物联网 （Al-Garadi
    et al., [2020](#bib.bib6)）的最先进实践。与传统的单节点DL（在单一计算节点或甚至单个GPU上运行）相比，分布式DL可以利用多个GPU和计算节点来处理大量的训练和推理工作负载，并提高学习吞吐量。特别是在具有数十亿参数的极大型模型时代，分布式DL使得在数据中心数百个计算节点和数千个GPU上进行高效的大模型训练成为可能。
- en: However, distributed DL faces numerous critical challenges related to efficient
    framework strategies for resource allocation and workload scheduling in large-scale
    environments. Firstly, with a large number of computational and communication
    devices in the data center for distributed DL, managing and allocating resources
    efficiently for distributed DL workloads to utilize resources fully becomes challenging.
    This challenge is amplified in heterogeneous resource environments, where GPUs
    have various computational capacities and networks have various communication
    capacities and topologies. Secondly, distributed DL workloads exhibits more complicated
    characteristics than those of single-node DL. On the one hand, various parallelism
    modes of distributed DL workloads give rise to new communication patterns involving
    significant communication overhead for data transfer and model synchronization.
    On the other hand, the combination of many computational and communication tasks
    in distributed DL workloads complicates the execution dependency paradigm, which
    allows for significant optimization. Thirdly, the exponential increase in large
    model sizes raises concerns about the cost of computational and communication
    resources and efficiency of distributed training in a large scale. Tackling these
    challenges is urgent and requires researchers in the fields of computer sciences,
    artificial intelligence, and communications to understand critical problems in
    this domain systematically.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，分布式 DL 面临着许多与大规模环境中资源分配和工作负载调度的高效框架策略相关的关键挑战。首先，由于数据中心内有大量计算和通信设备，如何高效管理和分配资源以充分利用分布式
    DL 工作负载中的资源成为一个挑战。在异构资源环境中，这一挑战尤为突出，因为 GPUs 的计算能力各异，网络的通信能力和拓扑结构也各不相同。其次，分布式 DL
    工作负载表现出比单节点 DL 更复杂的特性。一方面，各种分布式 DL 工作负载的并行模式产生了新的通信模式，这些模式涉及大量数据传输和模型同步的通信开销。另一方面，分布式
    DL 工作负载中许多计算和通信任务的组合使执行依赖关系模型变得复杂，从而带来了显著的优化空间。第三，大型模型规模的指数级增长引发了对计算和通信资源成本以及大规模分布式训练效率的担忧。解决这些挑战刻不容缓，需要计算机科学、人工智能和通信领域的研究人员系统性地理解这一领域中的关键问题。
- en: Several existing surveys (Zhou et al., [2019](#bib.bib151); Mayer and Jacobsen,
    [2020](#bib.bib78); Shi et al., [2020](#bib.bib101); Ouyang et al., [2021](#bib.bib85);
    Chen et al., [2021](#bib.bib17); Yu et al., [2023](#bib.bib137); Cao et al., [2023](#bib.bib15);
    Tang et al., [2023a](#bib.bib110); Ye et al., [2024a](#bib.bib134)) have touched
    on some topics of efficient resource allocation and workload scheduling strategies
    for distributed DL. For example, Ye et al. have introduced scheduling distributed
    training and inference workloads on GPUs at the job level. However, these surveys
    lack a systematic exploration of distributed DL framework strategies for scheduling
    computational and communication resources and workloads at various granularity
    levels in large-scale environments. Researchers in the fields of computer science,
    artificial intelligence, and communications need a comprehensive understanding
    of representative and critical challenges for framework strategies in large-scale
    distributed DL environments.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一些现有的调研（Zhou 等人，[2019](#bib.bib151)；Mayer 和 Jacobsen，[2020](#bib.bib78)；Shi
    等人，[2020](#bib.bib101)；Ouyang 等人，[2021](#bib.bib85)；Chen 等人，[2021](#bib.bib17)；Yu
    等人，[2023](#bib.bib137)；Cao 等人，[2023](#bib.bib15)；Tang 等人，[2023a](#bib.bib110)；Ye
    等人，[2024a](#bib.bib134)）已经触及了一些关于分布式深度学习（DL）的高效资源分配和工作负载调度策略的主题。例如，Ye 等人介绍了在作业层级调度分布式训练和推理工作负载于
    GPUs 上。然而，这些调研缺乏对大规模环境中各种粒度级别的计算和通信资源及工作负载调度的分布式 DL 框架策略的系统性探索。计算机科学、人工智能和通信领域的研究人员需要对大规模分布式
    DL 环境中的框架策略代表性和关键性挑战有一个全面的了解。
- en: 'To fill the gap in existing surveys on distributed DL framework strategies,
    this survey systematically investigates critical challenges and efficient distributed
    DL strategies for resource allocation and workload scheduling. We review the literature
    over the period mainly between the year 2019 and 2024. The discussion covers various
    resource types, scheduling granularity levels, and performance goals. For resource
    allocation strategies, we discuss GPU sharing technologies applying different
    approaches and network bandwidth-sharing technologies working at different granularity
    levels. For workload scheduling strategies, we categorize the technologies based
    on various performance goals and scheduling granularities. Both sets of strategies
    organized primarily based on the application stage: distributed training and inference.
    Focusing on efficient strategies for large-scale distributed DL, we highlight
    key challenges for each topic and provide insights about crucial research outputs.
    To illustrate how to apply these efficient framework strategies practically in
    real life, we conduct a case study on large-model distributed training, a rapidly
    trending and probably long-lasting research topic and one of the best application
    scenarios that require efficient distributed DL framework strategies. We also
    provide outlooks for future research directions.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为填补现有分布式深度学习框架策略调查中的空白，本调查系统地研究了资源分配和工作负载调度的关键挑战和高效的分布式深度学习策略。我们回顾了主要在2019年至2024年之间的文献。讨论涵盖了各种资源类型、调度粒度级别和性能目标。对于资源分配策略，我们讨论了应用不同方法的GPU共享技术和在不同粒度级别下工作的网络带宽共享技术。对于工作负载调度策略，我们根据不同的性能目标和调度粒度对技术进行了分类。这两组策略主要根据应用阶段进行组织：分布式训练和推理。我们聚焦于大规模分布式深度学习的高效策略，突出了每个主题的关键挑战，并提供了关于关键研究成果的见解。为了说明如何在实际生活中应用这些高效的框架策略，我们进行了大模型分布式训练的案例研究，这一研究主题快速增长，并且可能长期存在，是需要高效分布式深度学习框架策略的最佳应用场景之一。我们还提供了未来研究方向的展望。
- en: The major contribution of this survey is summarized as follows.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查的主要贡献总结如下。
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We thoroughly and comprehensively survey up-to-date resource allocation and
    workload scheduling framework strategies for large-scale distributed DL.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们彻底而全面地调查了最新的大规模分布式深度学习资源分配和工作负载调度框架策略。
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We highlight critical challenges for each topic of these framework strategies.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们突出了这些框架策略每个主题的关键挑战。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We use a case study on large-model training to illustrate how to apply efficient
    framework strategies in practice.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过对大模型训练的案例研究，说明如何在实践中应用高效的框架策略。
- en: Table 1\. A Comparison of Related Surveys
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1\. 相关调查的比较
- en: '|   |  | Resource Allocation | Workload Scheduling |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '|   |  | 资源分配 | 工作负载调度 |'
- en: '| Ref. | Year | GPU Allocation | Network Bandwidth Allocation | Job Scheduling
    | Pipeline Scheduling | Network Flow Scheduling |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 年份 | GPU 分配 | 网络带宽分配 | 作业调度 | 流水线调度 | 网络流调度 |'
- en: '|    (Mayer and Jacobsen, [2020](#bib.bib78)) | 2020 | ✓ |  | ✓ |  |  |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '|    (迈耶和雅各布森，[2020](#bib.bib78)) | 2020 | ✓ |  | ✓ |  |  |'
- en: '| (Shi et al., [2020](#bib.bib101)) | 2020 |  | ✓ |  |  |  |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| (施等，[2020](#bib.bib101)) | 2020 |  | ✓ |  |  |  |'
- en: '| (Ouyang et al., [2021](#bib.bib85)) | 2021 |  |  |  | ✓ | ✓ |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| (欧阳等，[2021](#bib.bib85)) | 2021 |  |  |  | ✓ | ✓ |'
- en: '| (Yu et al., [2023](#bib.bib137)) | 2023 |  |  |  | ✓ | ✓ |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| (余等，[2023](#bib.bib137)) | 2023 |  |  |  | ✓ | ✓ |'
- en: '| (Cao et al., [2023](#bib.bib15)) | 2023 |  | ✓ |  |  |  |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| (曹等，[2023](#bib.bib15)) | 2023 |  | ✓ |  |  |  |'
- en: '| (Tang et al., [2023a](#bib.bib110)) | 2023 |  |  |  | ✓ |  |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| (唐等，[2023a](#bib.bib110)) | 2023 |  |  |  | ✓ |  |'
- en: '| (Ye et al., [2024a](#bib.bib134)) | 2024 | ✓ |  | ✓ |  |  |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| (叶等，[2024a](#bib.bib134)) | 2024 | ✓ |  | ✓ |  |  |'
- en: '| (Liang et al., [2024](#bib.bib65)) | 2024 |  | ✓ |  |  | ✓ |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| (梁等，[2024](#bib.bib65)) | 2024 |  | ✓ |  |  | ✓ |'
- en: '|   Ours | - | ✓ | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|   我们的 | - | ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: '|   |  |  |  |  |  |  |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '|   |  |  |  |  |  |  |'
- en: 1.1\. Related Surveys
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1\. 相关调查
- en: 'Existing surveys on distributed DL lack systematic coverage over strategies
    for resource allocation of various resource types and workload scheduling at various
    levels. Table [1](#S1.T1 "Table 1 ‣ 1\. Introduction ‣ Resource Allocation and
    Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey") compares
    our survey with other related surveys on the covered topics in the domain of distributed
    DL framework strategies, including resource allocation based on the GPU and network
    bandwidth and workload scheduling based on the job, pipeline, and network flow.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '现有的分布式深度学习调查缺乏对各种资源类型的资源分配策略和各个层次的工作负载调度的系统性覆盖。表[1](#S1.T1 "Table 1 ‣ 1\. Introduction
    ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey")比较了我们的调查与领域内其他相关调查在分布式深度学习框架策略，包括基于GPU和网络带宽的资源分配以及基于作业、管道和网络流的工作负载调度方面所涵盖的主题。'
- en: Some surveys focus on scheduling distributed jobs on GPU data centers. Both
    Mayer and Jacobsen (Mayer and Jacobsen, [2020](#bib.bib78)) and Ye et al. (Ye
    et al., [2024a](#bib.bib134)) have conducted surveys on job-level GPU allocation
    and workload scheduling for distributed training and inference in the data center
    environment. However, these surveys concern only about job-level strategies focusing
    on the overall performance of the entire data center but not finer-grained strategies
    focusing on individual job performance. They also only investigate technologies
    related to the single resource type, the GPU, but not the network bandwidth, which
    is a significant performance factor for distributed DL with communication as the
    bottleneck.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一些调查关注于在GPU数据中心调度分布式作业。Mayer 和 Jacobsen（Mayer 和 Jacobsen，[2020](#bib.bib78)）和
    Ye 等人（Ye 等人，[2024a](#bib.bib134)）都对数据中心环境下的作业级GPU分配和工作负载调度进行了调查。然而，这些调查仅关注整体数据中心的作业级策略，而不关注单个作业性能的细粒度策略。它们还仅调查了与单一资源类型GPU相关的技术，但未涉及网络带宽，而网络带宽是通信作为瓶颈的分布式深度学习的重要性能因素。
- en: In contrast to the GPU-centric surveys, some works focus on communications technologies
    and network bandwidth-allocation strategies for distributed DL. Both Shi et al. (Shi
    et al., [2020](#bib.bib101)) and Cao et al. (Cao et al., [2023](#bib.bib15)) have
    reviewed the literature on bandwidth allocation strategies for federating learning
    over wireless networks. Liang et al. (Liang et al., [2024](#bib.bib65)) have not
    only investigated bandwidth-allocation strategies on general networks but also
    studied network-flow-scheduling strategies on different network layers. However,
    covering communications-only technologies does not reveal the whole picture of
    efficient scheduling in distributed DL, which requires the joint optimization
    of computation and communication.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 与以GPU为中心的调查相对，一些研究专注于分布式深度学习的通信技术和网络带宽分配策略。Shi 等人（Shi 等人，[2020](#bib.bib101)）和
    Cao 等人（Cao 等人，[2023](#bib.bib15)）回顾了无线网络中联邦学习的带宽分配策略的文献。Liang 等人（Liang 等人，[2024](#bib.bib65)）不仅调查了通用网络上的带宽分配策略，还研究了不同网络层上的网络流调度策略。然而，仅覆盖通信技术并未揭示分布式深度学习中高效调度的全貌，这需要计算和通信的联合优化。
- en: For finer-grained workload scheduling in distributed DL, some works (Ouyang
    et al., [2021](#bib.bib85); Yu et al., [2023](#bib.bib137); Tang et al., [2023a](#bib.bib110))
    explore pipeline-level scheduling strategies for overlapping computation and communication
    workloads to improve throughput. However, they do not highlight primary challenges
    related to this topic and lack the investigation into job-level resource allocation
    and workload scheduling strategies, which can orchestrate with these pipeline-level
    strategies as a synthesis framework solution for distributed DL in data centers.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式深度学习中的细粒度工作负载调度方面，一些研究（Ouyang 等人，[2021](#bib.bib85)；Yu 等人，[2023](#bib.bib137)；Tang
    等人，[2023a](#bib.bib110)）探讨了用于重叠计算和通信工作负载的管道级调度策略，以提高吞吐量。然而，这些研究并未突出与此主题相关的主要挑战，也缺乏对作业级资源分配和工作负载调度策略的调查，这些策略可以与这些管道级策略协调作为分布式深度学习在数据中心的综合框架解决方案。
- en: Our survey fills the gap in existing surveys. We instigate resource allocation
    strategies for both computational and communication resources, primarily the GPU
    and network bandwidth, to match the resource requirements of distributed DL workloads.
    We also explore workload scheduling strategies at the job, pipeline, and network
    flow levels to improve both overall data center throughput and individual job
    efficiency. The systematic literature study involving various resource types and
    scheduling granularity levels makes this article a comprehensive survey of up-to-date
    technologies in the distributed DL framework domain.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的调查填补了现有调查中的空白。我们提出了计算和通信资源（主要是GPU和网络带宽）的资源分配策略，以匹配分布式深度学习工作负载的资源需求。我们还探讨了作业、管道和网络流级别的工作负载调度策略，以提高数据中心的整体吞吐量和单个作业的效率。涉及各种资源类型和调度粒度水平的系统文献研究使本文成为分布式深度学习框架领域最新技术的全面调查。
- en: '![Refer to caption](img/302454633bb89b4b7bd583de75569faf.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/302454633bb89b4b7bd583de75569faf.png)'
- en: Figure 1\. The organization of the survey
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1\. 调查组织结构
- en: 1.2\. Survey Organization
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2\. 调查组织结构
- en: 'Fig. [1](#S1.F1 "Figure 1 ‣ 1.1\. Related Surveys ‣ 1\. Introduction ‣ Resource
    Allocation and Workload Scheduling for Large-Scale Distributed Deep Learning:
    A Survey") outlines the organization of the remaining sections in this survey.
    Section [2](#S2 "2\. Fundamentals of DL and Distributed DL ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    provides fundamental knowledge about distributed DL and the resource-management
    and workload scheduling framework. Sections [3](#S3 "3\. Resource Allocation ‣
    Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep Learning:
    A Survey") and [4](#S4 "4\. Workload Scheduling ‣ Resource Allocation and Workload
    Scheduling for Large-Scale Distributed Deep Learning: A Survey") introduce various
    framework strategies for resource allocation and workload scheduling, respectively.
    These framework strategies are categorized primarily based on their application
    scenarios, including distributed training and inference, and secondarily based
    on resource types, approaches, or performance goals. We discuss the insights at
    the end of each section. We use a case study of distributed large-model training
    to show how to apply these framework strategies practically in real-life data
    centers in Section [5](#S5 "5\. Distributed Training of LLMs: A Case Study ‣ Resource
    Allocation and Workload Scheduling for Large-Scale Distributed Deep Learning:
    A Survey"). In Section [6](#S6 "6\. Conclusion and Outlook ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey"),
    we conclude this survey and present outlooks of future research directions.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [1](#S1.F1 "图 1 ‣ 1.1\. 相关调查 ‣ 1\. 介绍 ‣ 大规模分布式深度学习的资源分配与工作负载调度：一项调查") 概述了本调查中剩余部分的组织结构。第 [2](#S2
    "2\. 深度学习及分布式深度学习基础 ‣ 大规模分布式深度学习的资源分配与工作负载调度：一项调查")节提供了关于分布式深度学习和资源管理及工作负载调度框架的基础知识。第 [3](#S3
    "3\. 资源分配 ‣ 大规模分布式深度学习的资源分配与工作负载调度：一项调查")节和第 [4](#S4 "4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配与工作负载调度：一项调查")节分别介绍了各种框架策略用于资源分配和工作负载调度。这些框架策略主要根据其应用场景（包括分布式训练和推断）进行分类，其次根据资源类型、方法或性能目标进行分类。我们在每节末尾讨论了见解。在第 [5](#S5
    "5\. 大型语言模型的分布式训练：案例研究 ‣ 大规模分布式深度学习的资源分配与工作负载调度：一项调查")节，我们使用分布式大模型训练的案例研究来展示如何在现实数据中心中实际应用这些框架策略。在第 [6](#S6
    "6\. 结论与展望 ‣ 大规模分布式深度学习的资源分配与工作负载调度：一项调查")节，我们总结了本调查并展望未来的研究方向。
- en: Table 2\. A List of Frequently Used Abbreviations
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2\. 常用缩写列表
- en: '|    Abbreviation | Description |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|    缩写 | 描述 |'
- en: '|   DL | Deep Learning |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|   DL | 深度学习 |'
- en: '| DRL | Deep Reinforcement Learning |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| DRL | 深度强化学习 |'
- en: '| DNN | Deep Neural Network |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| DNN | 深度神经网络 |'
- en: '| GPU | Graphics Processing Unit |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| GPU | 图形处理单元 |'
- en: '| LLM | Large Language Model |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| LLM | 大型语言模型 |'
- en: '| MPS | Multiple Process Sharing |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| MPS | 多进程共享 |'
- en: '| NLP | Natural Language Processing |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| NLP | 自然语言处理 |'
- en: '| PS | Parameter Server |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| PS | 参数服务器 |'
- en: '| SLO | Service-Level Objective |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| SLO | 服务级别目标 |'
- en: '|   |  |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '|   |  |'
- en: 2\. Fundamentals of DL and Distributed DL
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 深度学习及分布式深度学习基础
- en: 'In this section, we introduce the fundamental knowledge of DL, distributed
    DL, and the resource allocation and workload scheduling framework for distributed
    DL. Table [2](#S1.T2 "Table 2 ‣ 1.2\. Survey Organization ‣ 1\. Introduction ‣
    Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep Learning:
    A Survey") lists frequently used abbreviations used in this survey.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了深度学习（DL）的基础知识、分布式深度学习及其资源分配和工作负载调度框架。表 [2](#S1.T2 "表 2 ‣ 1.2\. 调查组织
    ‣ 1\. 引言 ‣ 大规模分布式深度学习的资源分配和工作负载调度：一项调查") 列出了本调查中常用的缩写。
- en: 2.1\. Deep Learning
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 深度学习
- en: DL is a subfield of machine learning that utilizes deep artificial neural networks,
    also known as deep neural networks (DNN), to extract complex patterns from training
    data in a hierarchical manner. The trained DNN is capable to recognize/predict
    patterns in unseen data. DL has been used in various fields, including NLP (Bahdanau
    et al., [2015](#bib.bib10)), computer vision (Dosovitskiy et al., [2020](#bib.bib24)),
    and biomedical engineering (Thieme et al., [2023](#bib.bib112)).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）是机器学习的一个子领域，利用深度人工神经网络（DNN）以分层方式从训练数据中提取复杂模式。训练好的 DNN 能够识别/预测未见数据中的模式。深度学习已被应用于各个领域，包括自然语言处理
    (NLP) (Bahdanau et al., [2015](#bib.bib10))、计算机视觉 (Dosovitskiy et al., [2020](#bib.bib24))
    和生物医学工程 (Thieme et al., [2023](#bib.bib112))。
- en: '![Refer to caption](img/d091d6bbd7853048f68ba8f4b3dc628c.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d091d6bbd7853048f68ba8f4b3dc628c.png)'
- en: (a) Fully Connected DNN
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 全连接 DNN
- en: '![Refer to caption](img/310eef3acdc5226a5be1ea92d3e41042.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/310eef3acdc5226a5be1ea92d3e41042.png)'
- en: (b) CNN
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: (b) CNN
- en: '![Refer to caption](img/3f583d867a1bc125d41a38e9e624ab5f.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3f583d867a1bc125d41a38e9e624ab5f.png)'
- en: (c) RNN
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: (c) RNN
- en: Figure 2\. Common artificial neural network models for DL
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. 常见的人工神经网络模型用于深度学习
- en: 2.1.1\. DL models
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.1\. 深度学习模型
- en: 'A DNN consists of multiple hidden layers. Each layer is comprised of neurons,
    which are typically activated by non-linear functions. Based on the connections
    between neurons within and between layers, there can be various types of DNN models.
    In this survey, when referring to models or DL models, we mean DNNs unless the
    context otherwise specifies. Fig. [2](#S2.F2 "Figure 2 ‣ 2.1\. Deep Learning ‣
    2\. Fundamentals of DL and Distributed DL ‣ Resource Allocation and Workload Scheduling
    for Large-Scale Distributed Deep Learning: A Survey") illustrates three basic
    DNN models: the fully connected DNN, convolutional neural network (CNN), and recurrent
    neural network (RNN).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 DNN 由多个隐藏层组成。每一层由神经元组成，这些神经元通常通过非线性函数进行激活。根据层内及层间神经元之间的连接方式，DNN 模型可以有多种类型。在本调查中，提到的模型或深度学习模型指的是
    DNN，除非上下文另有说明。图 [2](#S2.F2 "图 2 ‣ 2.1\. 深度学习 ‣ 2\. 深度学习和分布式深度学习的基础 ‣ 大规模分布式深度学习的资源分配和工作负载调度：一项调查")
    展示了三种基本的 DNN 模型：全连接 DNN、卷积神经网络 (CNN) 和递归神经网络 (RNN)。
- en: '$\bullet$ Fully connected DNN: The fully connected DNN, also known as the feedforward
    neural network, constitutes a dense network with an input layer, a number of hidden
    layers, and an output layer, as depicted in Fig. [2a](#S2.F2.sf1 "In Figure 2
    ‣ 2.1\. Deep Learning ‣ 2\. Fundamentals of DL and Distributed DL ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey").
    Neurons in a preceding layer connect to all neurons in the subsequent layer, and
    each connection has a learnable weight parameter indicating the strength of the
    connection. This architecture enables the fully connected DNN to capture complex
    relationships within data, finding extensive application in tasks such as classification (Sagduyu
    et al., [2023](#bib.bib94)), regression (Saikia et al., [2022](#bib.bib95)), and
    feature representation embedding (Ferrand et al., [2020](#bib.bib30)).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 全连接 DNN：全连接 DNN，也称为前馈神经网络，构成一个稠密的网络，包括一个输入层、若干隐藏层和一个输出层，如图 [2a](#S2.F2.sf1
    "在图 2 ‣ 2.1\. 深度学习 ‣ 2\. 深度学习和分布式深度学习的基础 ‣ 大规模分布式深度学习的资源分配和工作负载调度：一项调查") 所示。前一层的神经元与后一层的所有神经元连接，每个连接都有一个可学习的权重参数，表示连接的强度。这种结构使得全连接
    DNN 能够捕捉数据中的复杂关系，广泛应用于分类 (Sagduyu et al., [2023](#bib.bib94))、回归 (Saikia et al.,
    [2022](#bib.bib95)) 和特征表示嵌入 (Ferrand et al., [2020](#bib.bib30)) 等任务。
- en: '$\bullet$ CNN: CNN stands as a prevalent model designed for feature extraction
    and classification, primarily tailored for image and video data. As depicted in
    Fig. [2b](#S2.F2.sf2 "In Figure 2 ‣ 2.1\. Deep Learning ‣ 2\. Fundamentals of
    DL and Distributed DL ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey"), CNN comprises a stack of convolutional
    layers and pooling layers for context feature extraction. Unlike the fully connected
    layer, which assigns a weight parameter to each neuron connection, the convolutional
    layer substantially reduces the number of weight parameters by utilizing a number
    of kernels, each containing shared weights for feature extraction. The feature
    extraction process of the convolutional layer’s feature extraction process is
    empowered by the convolution operation, wherein kernels traverse the receptive
    fields of an image, extracting new features through weighted summations followed
    by a non-linear activation function. The pooling layer downsamples the data in
    the convolutional layer to reduce feature dimensions and alleviate overfitting
    issues. CNN has found widespread applications in various computer vision tasks,
    including image classification (Amerini et al., [2019](#bib.bib7)), semantic segmentation (Zhang
    et al., [2022](#bib.bib143)), and object detection (Bi et al., [2022](#bib.bib13)).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '$\bullet$ CNN: CNN 是一种流行的模型，旨在进行特征提取和分类，主要针对图像和视频数据。如图 [2b](#S2.F2.sf2 "图2
    ‣ 2.1. 深度学习 ‣ 2. 深度学习和分布式深度学习的基础 ‣ 大规模分布式深度学习的资源分配和工作负载调度：综述") 所示，CNN 由一系列卷积层和池化层组成，用于上下文特征提取。与将权重参数分配给每个神经元连接的全连接层不同，卷积层通过利用多个内核（每个内核包含共享权重）显著减少了权重参数的数量，从而进行特征提取。卷积层的特征提取过程通过卷积操作得到增强，其中内核遍历图像的感受野，通过加权求和提取新特征，然后通过非线性激活函数进行处理。池化层对卷积层中的数据进行下采样，以减少特征维度并缓解过拟合问题。CNN
    在各种计算机视觉任务中得到了广泛应用，包括图像分类 (Amerini et al., [2019](#bib.bib7))、语义分割 (Zhang et al.,
    [2022](#bib.bib143)) 和目标检测 (Bi et al., [2022](#bib.bib13))。'
- en: '$\bullet$ RNN: RNN, a DL model that deals with sequential data like time-series
    data, natural language, and speech audio, is illustrated in Fig. [2c](#S2.F2.sf3
    "In Figure 2 ‣ 2.1\. Deep Learning ‣ 2\. Fundamentals of DL and Distributed DL
    ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey"). The general architecture of RNN includes hidden units that
    capture and propagate temporal context from the input sequence to subsequent hidden
    unites. It updates continuously and utilizes the temporal context based on the
    current input and previous temporal context to make predictions. To address the
    challenge of capturing long-range temporal dependencies, two common variants of
    RNNs, known as Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU), have
    been developed, providing a trade-off between modeling such dependencies and reducing
    computation complexity effectively. Common applications of RNN include tasks such
    as time series forecasting (Hua et al., [2019](#bib.bib45)), NLP (Feng et al.,
    [2020](#bib.bib28)), and automated planning (Say, [2021](#bib.bib96)).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '$\bullet$ RNN: RNN 是一种处理序列数据（如时间序列数据、自然语言和语音音频）的深度学习模型，如图 [2c](#S2.F2.sf3 "图2
    ‣ 2.1. 深度学习 ‣ 2. 深度学习和分布式深度学习的基础 ‣ 大规模分布式深度学习的资源分配和工作负载调度：综述") 所示。RNN 的一般架构包括捕获和传播输入序列的时间上下文的隐藏单元。它不断更新，并利用当前输入和先前时间上下文来进行预测。为了解决捕获长期时间依赖性的问题，开发了两种常见的
    RNN 变体，即长短期记忆 (LSTM) 和门控循环单元 (GRU)，这两者在建模这些依赖性和有效减少计算复杂性之间提供了权衡。RNN 的常见应用包括时间序列预测
    (Hua et al., [2019](#bib.bib45))、自然语言处理 (Feng et al., [2020](#bib.bib28)) 和自动规划
    (Say, [2021](#bib.bib96))。'
- en: 2.1.2\. Training and inference
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.2. 训练与推理
- en: 'The training of a DL model is the process of optimizing its parameters to minimize
    the prediction error on a training dataset, as determined by a specified loss
    function, or objective function. Loss functions can be either convex or non-convex,
    leading to convex or non-convex optimization problems. Training can be decomposed
    into two key processes: feedforward and backpropagation. In the feedforward process,
    training data are passed into the model’s input layer, and the output prediction
    is computed by forwarding data through the network using the current model parameters.
    In the backpropagation process, the prediction error and gradients are calculated
    with respect to the loss function, and trainable parameters are updated iteratively
    in a backward manner, optimizing the model for the minimum loss. Common optimizers
    for backpropagation updating include mini-batch Stochastic Gradient Descent (SGD) (Li
    et al., [2014](#bib.bib59)), SGD with momentum (Sutskever et al., [2013](#bib.bib106)),
    Adagrad (Duchi et al., [2011](#bib.bib26)), and Adam (Kingma and Ba, [2015](#bib.bib56)).
    The training process usually operates on batches of training data iteratively
    over multiple epochs until the model converges. A model is said to have converged
    when the training error settles to within a predefined error range, and additional
    training will not further decrease the error. After completing the training process,
    the weight parameters in the DL model are learned and fixed. Following the training
    process, there is typically a validation process for validating the performance
    of the trained model, providing information for fine-tuning hyperparameters and
    retraining the model for better performance.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: DL模型的训练是优化其参数以最小化在训练数据集上的预测误差的过程，该过程由指定的损失函数或目标函数确定。损失函数可以是凸的或非凸的，导致凸优化或非凸优化问题。训练可以分解为两个关键过程：前向传播和反向传播。在前向传播过程中，训练数据被传入模型的输入层，通过使用当前模型参数将数据在网络中前向传播以计算输出预测。在反向传播过程中，计算相对于损失函数的预测误差和梯度，并以反向方式迭代更新可训练参数，优化模型以实现最小损失。反向传播更新的常见优化器包括小批量随机梯度下降（SGD）（Li
    et al., [2014](#bib.bib59)）、带动量的SGD（Sutskever et al., [2013](#bib.bib106)）、Adagrad（Duchi
    et al., [2011](#bib.bib26)）和Adam（Kingma和Ba, [2015](#bib.bib56)）。训练过程通常在多个周期内对训练数据的批量进行迭代，直到模型收敛。当训练误差收敛到预定义误差范围内时，模型被认为已经收敛，额外的训练不会进一步减少误差。完成训练过程后，DL模型中的权重参数被学习并固定。训练过程后，通常会有一个验证过程来验证训练模型的性能，为微调超参数和重新训练模型以获得更好的性能提供信息。
- en: The inference process passes forward unseen data through the trained DL model
    to make predictions. Depending on the specific requirements of an application,
    the resulting prediction can be extracted either either from the output layer
    or from the predicted latent representation in an intermediate hidden layer. For
    example, in the context of network traffic analysis, an end-to-end DNN model may
    be trained to classify traffic types directly (Lotfollahi et al., [2020](#bib.bib75)),
    Alternatively, an encoder-decoder model trained on traffic data can utilize the
    latent representation generated by the encoder for subsequent tasks such as attack
    detection (Vu et al., [2020](#bib.bib117)).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 推理过程将未见数据通过训练好的DL模型进行前向传播以进行预测。根据应用的具体要求，结果预测可以从输出层或从中间隐藏层中的预测潜在表示中提取。例如，在网络流量分析的背景下，可能会训练一个端到端的DNN模型以直接分类流量类型（Lotfollahi
    et al., [2020](#bib.bib75)），或者，训练在流量数据上的编码器-解码器模型可以利用编码器生成的潜在表示进行后续任务，如攻击检测（Vu
    et al., [2020](#bib.bib117)）。
- en: Computing tasks related to a specific portion of the DL model for specific epochs
    during the training or inference process are generally referred to as DL tasks
    in this survey, when it is not necessary to distinguish training tasks and inference
    tasks in the context.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项调查中，针对训练或推理过程中特定时期的DL模型特定部分的计算任务通常被称为DL任务，除非在上下文中有必要区分训练任务和推理任务。
- en: 2.2\. Distributed DL Parallelism Modes
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 分布式DL并行模式
- en: 'Distributed DL partitions data and models into multiple processing units (typically
    GPUs) for parallel execution to leverage the computational capacity of many computing
    nodes in a cluster. As illustrated in Fig. [3](#S2.F3 "Figure 3 ‣ 2.2\. Distributed
    DL Parallelism Modes ‣ 2\. Fundamentals of DL and Distributed DL ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey"),
    distributed DL has three basic parallelism modes: data parallelism, model parallelism,
    and pipeline parallelism.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式深度学习将数据和模型划分为多个处理单元（通常是 GPU），以便并行执行，从而利用集群中许多计算节点的计算能力。如图 [3](#S2.F3 "图 3
    ‣ 2.2\. 分布式深度学习并行模式 ‣ 2\. 深度学习与分布式深度学习基础 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述") 所示，分布式深度学习有三种基本的并行模式：数据并行、模型并行和流水线并行。
- en: '![Refer to caption](img/ec460a3b9ca782ade0e5a1091d8be231.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/ec460a3b9ca782ade0e5a1091d8be231.png)'
- en: (a) Data Parallelism
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 数据并行
- en: '![Refer to caption](img/f15f2f7a8a6be2e0a0ac238194239e20.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/f15f2f7a8a6be2e0a0ac238194239e20.png)'
- en: (b) Model Parallelism
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 模型并行
- en: '![Refer to caption](img/e2365c3f9ce66b00ac4682b176b1452c.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/e2365c3f9ce66b00ac4682b176b1452c.png)'
- en: (c) Pipeline Parallelism
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 流水线并行
- en: Figure 3\. Parallelism modes of distributed DL
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3\. 分布式深度学习的并行模式
- en: 2.2.1\. Data parallelism
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1\. 数据并行
- en: 'As illustrated in Fig. [3a](#S2.F3.sf1 "In Figure 3 ‣ 2.2\. Distributed DL
    Parallelism Modes ‣ 2\. Fundamentals of DL and Distributed DL ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey"),
    data-parallel training partitions the entire training dataset into several splits
    and distributes them across many GPUs for parallel training (Li et al., [2020c](#bib.bib61)).
    Each GPU has a replicate of a whole model with an identical structure and trains
    it on a specific dataset partition. Throughout the distributed training process,
    these local models share their knowledge to update a global model using a specific
    model synchronization mechanism, usually via a parameter server (PS).'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [3a](#S2.F3.sf1 "图 3 ‣ 2.2\. 分布式深度学习并行模式 ‣ 2\. 深度学习与分布式深度学习基础 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述")
    所示，数据并行训练将整个训练数据集划分为多个部分，并将这些部分分配到许多 GPU 上进行并行训练（Li 等， [2020c](#bib.bib61)）。每个
    GPU 都有一个结构相同的完整模型，并在特定的数据集部分上进行训练。在分布式训练过程中，这些本地模型通过特定的模型同步机制（通常通过参数服务器（PS））共享知识以更新全局模型。
- en: 2.2.2\. Model parallelism
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2\. 模型并行
- en: 'As illustrated in Fig. [3b](#S2.F3.sf2 "In Figure 3 ‣ 2.2\. Distributed DL
    Parallelism Modes ‣ 2\. Fundamentals of DL and Distributed DL ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey"),
    model-parallel training divides an entire DL model into submodels and distributes
    them onto many GPUs within a cluster when the model exceeds the capacity of a
    single GPU or computing node (Gomez et al., [2022](#bib.bib36)). This parallelism
    mode concerns the model division strategy focusing on workload balance and the
    submodel placement strategy focusing on communication overhead between submodels.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [3b](#S2.F3.sf2 "图 3 ‣ 2.2\. 分布式深度学习并行模式 ‣ 2\. 深度学习与分布式深度学习基础 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述")
    所示，模型并行训练将整个深度学习模型划分为子模型，并在模型超出单个 GPU 或计算节点的容量时将其分配到集群中的许多 GPU 上（Gomez 等，[2022](#bib.bib36)）。这种并行模式关注于模型划分策略，重点是工作负载平衡，以及子模型放置策略，重点是子模型之间的通信开销。
- en: 2.2.3\. Pipeline parallelism
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.3\. 流水线并行
- en: 'As illustrated in Fig. [3c](#S2.F3.sf3 "In Figure 3 ‣ 2.2\. Distributed DL
    Parallelism Modes ‣ 2\. Fundamentals of DL and Distributed DL ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey"),
    pipeline-parallel training enhances DL parallelism by ordering different stages
    of distributed training in a pipeline and preventing computational and communication
    resources from idling (Li and Hoefler, [2021](#bib.bib60); Liu et al., [2022c](#bib.bib73);
    Oh et al., [2022](#bib.bib84)). Pipeline-parallel training can be considered a
    special case of model-parallel training by decomposing the training of submodels
    layer by layer into subtasks and overlapping their computation of different stages
    across different GPUs. Computational and communication tasks can also overlap
    in the pipeline. This mode is typically applicable in the domains of LLM training (Narayanan
    et al., [2021](#bib.bib82)), edge computing (Yao et al., [2022](#bib.bib133)),
    and the Internet of Things (Baccour et al., [2022](#bib.bib9)), where devices
    have heterogeneous computational and communication capabilities to handle various
    distributed DL subtasks. In practice, pipeline parallelism can work with other
    parallelism modes to tackle complex distributed DL workloads with large model
    structures (Tarnawski et al., [2021](#bib.bib111); Ryabinin et al., [2023](#bib.bib93)).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[3c](#S2.F3.sf3 "在图 3 ‣ 2.2\. 分布式深度学习并行模式 ‣ 2\. 深度学习与分布式深度学习基础 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述")所示，管道并行训练通过将分布式训练的不同阶段排成流水线并防止计算和通信资源闲置来增强深度学习并行性（Li
    和 Hoefler，[2021](#bib.bib60)；Liu 等，[2022c](#bib.bib73)；Oh 等，[2022](#bib.bib84)）。管道并行训练可以被视为模型并行训练的一种特殊情况，通过将子模型的训练逐层分解为子任务，并在不同的
    GPU 之间重叠不同阶段的计算。计算和通信任务也可以在管道中重叠。这种模式通常适用于大语言模型训练（Narayanan 等，[2021](#bib.bib82)）、边缘计算（Yao
    等，[2022](#bib.bib133)）和物联网（Baccour 等，[2022](#bib.bib9)），其中设备具有异构的计算和通信能力来处理各种分布式深度学习子任务。在实践中，管道并行可以与其他并行模式一起工作，以处理具有大模型结构的复杂分布式深度学习工作负载（Tarnawski
    等，[2021](#bib.bib111)；Ryabinin 等，[2023](#bib.bib93)）。
- en: '![Refer to caption](img/26ec23f00301d8fcbfcc736ce4790460.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/26ec23f00301d8fcbfcc736ce4790460.png)'
- en: Figure 4\. An overview illustration of resource allocation and workload scheduling
    mechanisms in distributed DL
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4\. 分布式深度学习中资源分配与工作负载调度机制的概述
- en: 2.3\. Resource Allocation and Workload Scheduling for Distributed DL
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 分布式深度学习的资源分配与工作负载调度
- en: 'Resource allocation and workload scheduling strategies for high-performance
    distributed DL are typically integrated in cluster-level and distributed-DL-level
    frameworks. Fig. [4](#S2.F4 "Figure 4 ‣ 2.2.3\. Pipeline parallelism ‣ 2.2\. Distributed
    DL Parallelism Modes ‣ 2\. Fundamentals of DL and Distributed DL ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    illustrates the procedure of resource allocation and workload scheduling mechanisms
    for large-scale distributed DL within a cluster. This procedure comprises six
    major steps. (1) For a queue of distributed DL jobs, the task scheduler conducts
    job profiling based on various workload characters, such as resource-utilization
    status and working progress. (2) The resource manager allocates GPU and network
    resources distributed within the cluster for jobs based on their characteristic
    profiling. The resources can be represented in a physical or virtual manner, and
    virtual resources can be encapsulated in virtual machines or containers. (3) The
    job-level scheduler determines job-execution priorities based on resource constraints
    and job performance estimation. (4) The pipeline-level scheduler divides the job
    into subtasks and locates them onto available resources for the pipeline execution
    of the subtasks, aiming to increase task parallelism and overlap computational
    and communication workloads. (5) The network-flow-level scheduler optimizes the
    network flows or coflows of numerous subtasks by considering the relation and
    dependency of network flows. (6) Scheduled jobs, pipelines, and network flows
    run efficiently on the allocated GPU and network resources within the cluster.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 高性能分布式深度学习的资源分配和工作负载调度策略通常集成在集群级和分布式深度学习级框架中。图 [4](#S2.F4 "图 4 ‣ 2.2.3\. 流水线并行
    ‣ 2.2\. 分布式深度学习并行模式 ‣ 2\. 深度学习及分布式深度学习基础 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述") 说明了集群内大规模分布式深度学习的资源分配和工作负载调度机制的过程。该过程包括六个主要步骤。
    (1) 对于分布式深度学习作业队列，任务调度器根据各种工作负载特征，如资源利用状况和工作进展，进行作业分析。 (2) 资源管理器根据作业的特征分析，将集群内分布的
    GPU 和网络资源分配给作业。资源可以以物理或虚拟方式表示，虚拟资源可以封装在虚拟机或容器中。 (3) 作业级调度器根据资源约束和作业性能估计确定作业执行优先级。
    (4) 流水线级调度器将作业分解为子任务，并将它们分配到可用资源上进行子任务的流水线执行，旨在增加任务并行性并重叠计算和通信负载。 (5) 网络流级调度器通过考虑网络流的关系和依赖性来优化多个子任务的网络流或协同流。
    (6) 调度的作业、流水线和网络流在集群内分配的 GPU 和网络资源上高效运行。
- en: Table 3\. Studies on Resource Allocation Strategies for Large-Scale Distributed
    DL
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3\. 大规模分布式深度学习的资源分配策略研究
- en: '|    Category | Ref. | Year | Highlight |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '|    类别 | 参考文献 | 年份 | 亮点 |'
- en: '|    Training ([3.1](#S3.SS1 "3.1\. Resource Allocation for Distributed Training
    ‣ 3\. Resource Allocation ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey")) | GPU Sharing. Approach: (1) Workload Profiling
    [[C1]](#S3.SS1.SSS1.tab1 "3.1.1\. GPU sharing: ‣ 3.1\. Resource Allocation for
    Distributed Training ‣ 3\. Resource Allocation ‣ Resource Allocation and Workload
    Scheduling for Large-Scale Distributed Deep Learning: A Survey") ([3.1.1](#S3.SS1.SSS1
    "3.1.1\. GPU sharing: ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\.
    Resource Allocation ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey")) | Gandiva (Xiao et al., [2018](#bib.bib128))
    | 2018 | Using the profiles of the DL workload to improve efficiency of training
    DL models and latency in a GPU cluster. |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '|    训练 ([3.1](#S3.SS1 "3.1\. 分布式训练的资源分配 ‣ 3\. 资源分配 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述"))
    | GPU 共享。方法： (1) 工作负载分析 [[C1]](#S3.SS1.SSS1.tab1 "3.1.1\. GPU 共享: ‣ 3.1\. 分布式训练的资源分配
    ‣ 3\. 资源分配 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述") ([3.1.1](#S3.SS1.SSS1 "3.1.1\. GPU 共享:
    ‣ 3.1\. 分布式训练的资源分配 ‣ 3\. 资源分配 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述")) | Gandiva (肖等，[2018](#bib.bib128))
    | 2018 | 利用深度学习工作负载的配置文件提高 GPU 集群中深度学习模型训练的效率和延迟。 |'
- en: '| AntMan (Xiao et al., [2020](#bib.bib129)) | 2020 | Introducing co-designing
    the cluster scheduler and dynamic scaling mechanisms. |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| AntMan (肖等，[2020](#bib.bib129)) | 2020 | 介绍了集群调度器和动态扩展机制的共同设计。 |'
- en: '|  | FGD (Weng et al., [2023](#bib.bib126)) | 2023 | Monitoring the individual
    evaluation functions of DL jobs at runtime to make placement decisions and resource
    allocations elastically. |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|  | FGD (Weng et al., [2023](#bib.bib126)) | 2023 | 监控DL任务运行时的个体评估函数，以便弹性地做出放置决策和资源分配。
    |'
- en: '|  | TGS (Wu et al., [2023](#bib.bib127)) | 2023 | Designing adaptive rate-control
    and transparent unified-memory mechanisms . |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '|  | TGS (Wu et al., [2023](#bib.bib127)) | 2023 | 设计自适应速率控制和透明统一内存机制。 |'
- en: '|  | Orion (Strati et al., [2024](#bib.bib103)) | 2024 | Co-scheduling GPU
    kernels based on the computation and memory profiles of DNN workloads. |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '|  | Orion (Strati et al., [2024](#bib.bib103)) | 2024 | 基于DNN工作负载的计算和内存配置文件共同调度GPU内核。
    |'
- en: '| (2) Context Switching [[C2]](#S3.SS1.SSS1.tab2 "3.1.1\. GPU sharing: ‣ 3.1\.
    Resource Allocation for Distributed Training ‣ 3\. Resource Allocation ‣ Resource
    Allocation and Workload Scheduling for Large-Scale Distributed Deep Learning:
    A Survey") ([3.1.1](#S3.SS1.SSS1 "3.1.1\. GPU sharing: ‣ 3.1\. Resource Allocation
    for Distributed Training ‣ 3\. Resource Allocation ‣ Resource Allocation and Workload
    Scheduling for Large-Scale Distributed Deep Learning: A Survey")) | Salus (Yu
    and Chowdhury, [2020](#bib.bib139)) | 2019 | Achieving fine-grained GPU sharing
    among multiple DL applications. |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| (2) 上下文切换 [[C2]](#S3.SS1.SSS1.tab2 "3.1.1\. GPU共享: ‣ 3.1\. 分布式训练的资源分配 ‣ 3\.
    资源分配 ‣ 大规模分布式深度学习的资源分配与工作负载调度: 综述") ([3.1.1](#S3.SS1.SSS1 "3.1.1\. GPU共享: ‣ 3.1\.
    分布式训练的资源分配 ‣ 3\. 资源分配 ‣ 大规模分布式深度学习的资源分配与工作负载调度: 综述")) | Salus (Yu and Chowdhury,
    [2020](#bib.bib139)) | 2019 | 实现多个DL应用程序之间的细粒度GPU共享。 |'
- en: '| PipeSwitch (Bai et al., [2020](#bib.bib11)) | 2020 | Exploiting the profiles
    of DL applications to achieve millisecond-scale context switching. |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| PipeSwitch (Bai et al., [2020](#bib.bib11)) | 2020 | 利用DL应用程序的配置文件实现毫秒级的上下文切换。
    |'
- en: '|  | DistMind (Jin et al., [2024](#bib.bib54)) | 2024 | Exposing the abstractions
    of a GPU pool and a memory pool and designing high-performance three-stage pipelining.
    |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|  | DistMind (Jin et al., [2024](#bib.bib54)) | 2024 | 暴露GPU池和内存池的抽象，并设计高性能的三阶段流水线。
    |'
- en: '|  | G-Safe (Pavlidakis et al., [2024](#bib.bib87)) | 2024 | Offering transparent
    memory protection for context switching. |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '|  | G-Safe (Pavlidakis et al., [2024](#bib.bib87)) | 2024 | 提供透明的内存保护以支持上下文切换。
    |'
- en: '| (3) Performance Estimating [[C3]](#S3.SS1.SSS1.tab3 "3.1.1\. GPU sharing:
    ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\. Resource Allocation
    ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey") ([3.1.1](#S3.SS1.SSS1 "3.1.1\. GPU sharing: ‣ 3.1\. Resource
    Allocation for Distributed Training ‣ 3\. Resource Allocation ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey"))
    | Optimus (Peng et al., [2018](#bib.bib88)) | 2018 | Estimating a DL task’s remaining
    execution time and designing a marginal gain-based allocation algorithm. |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| (3) 性能估计 [[C3]](#S3.SS1.SSS1.tab3 "3.1.1\. GPU共享: ‣ 3.1\. 分布式训练的资源分配 ‣ 3\.
    资源分配 ‣ 大规模分布式深度学习的资源分配与工作负载调度: 综述") ([3.1.1](#S3.SS1.SSS1 "3.1.1\. GPU共享: ‣ 3.1\.
    分布式训练的资源分配 ‣ 3\. 资源分配 ‣ 大规模分布式深度学习的资源分配与工作负载调度: 综述")) | Optimus (Peng et al.,
    [2018](#bib.bib88)) | 2018 | 估算DL任务的剩余执行时间，并设计基于边际收益的分配算法。 |'
- en: '| Harmony (Bao et al., [2019](#bib.bib12)) | 2019 | Placing training jobs in
    a manner that minimizes interference and maximizes performance. |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| Harmony (Bao et al., [2019](#bib.bib12)) | 2019 | 以最小化干扰和最大化性能的方式放置训练任务。
    |'
- en: '|  | Horus (Yeung et al., [2021](#bib.bib136)) | 2021 | Proposing a data-driven
    approach to predict the GPU utilization of heterogeneous DL tasks. |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|  | Horus (Yeung et al., [2021](#bib.bib136)) | 2021 | 提出了一种数据驱动的方法来预测异构DL任务的GPU利用率。
    |'
- en: '|  | GPARS (Wang et al., [2024](#bib.bib122)) | 2024 | Leveraging spatiotemporal
    correlations among jobs to allocate suitable GPU types for newly submitted jobs.
    |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|  | GPARS (Wang et al., [2024](#bib.bib122)) | 2024 | 利用作业之间的时空相关性，为新提交的作业分配合适的GPU类型。
    |'
- en: '| (4) Elastic Scaling [[C4]](#S3.SS1.SSS1.tab4 "3.1.1\. GPU sharing: ‣ 3.1\.
    Resource Allocation for Distributed Training ‣ 3\. Resource Allocation ‣ Resource
    Allocation and Workload Scheduling for Large-Scale Distributed Deep Learning:
    A Survey") ([3.1.1](#S3.SS1.SSS1 "3.1.1\. GPU sharing: ‣ 3.1\. Resource Allocation
    for Distributed Training ‣ 3\. Resource Allocation ‣ Resource Allocation and Workload
    Scheduling for Large-Scale Distributed Deep Learning: A Survey")) | Pollux (Qiao
    et al., [2021](#bib.bib89)) | 2021 | Combining system throughput with statistical
    efficiency and introducing a formulation of goodput. |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| (4) 弹性扩展 [[C4]](#S3.SS1.SSS1.tab4 "3.1.1\. GPU sharing: ‣ 3.1\. Resource
    Allocation for Distributed Training ‣ 3\. Resource Allocation ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    ([3.1.1](#S3.SS1.SSS1 "3.1.1\. GPU sharing: ‣ 3.1\. Resource Allocation for Distributed
    Training ‣ 3\. Resource Allocation ‣ Resource Allocation and Workload Scheduling
    for Large-Scale Distributed Deep Learning: A Survey")) | Pollux (Qiao et al.,
    [2021](#bib.bib89)) | 2021 | 将系统吞吐量与统计效率相结合，并引入了良效比的定义。 |'
- en: '|  | Zico (Lim et al., [2021](#bib.bib67)) | 2021 | Monitoring the memory-usage
    pattern of individual DL jobs by tracking computational progress of training jobs.
    |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '|  | Zico (Lim et al., [2021](#bib.bib67)) | 2021 | 通过跟踪训练作业的计算进度来监控单个深度学习作业的内存使用模式。
    |'
- en: '|  | AFS (Hwang et al., [2021](#bib.bib48)) | 2021 | Handling future jobs requires
    proactive preparation based on current share calculations. |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|  | AFS (Hwang et al., [2021](#bib.bib48)) | 2021 | 处理未来作业需要基于当前份额计算进行主动准备。
    |'
- en: '|  | EasyScale (Li et al., [2023a](#bib.bib58)) | 2023 | Utilizing a thread
    abstraction called EasyScaleThread to preserve consistent training accuracy with
    scalable GPUs. |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '|  | EasyScale (Li et al., [2023a](#bib.bib58)) | 2023 | 利用一种名为 EasyScaleThread
    的线程抽象来保持可扩展 GPU 的一致训练精度。 |'
- en: '|  | FlowCon (Mao et al., [2023](#bib.bib77)) | 2023 | Minimizing the growth
    of GPU fragmentation through packing tasks. |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  | FlowCon (Mao et al., [2023](#bib.bib77)) | 2023 | 通过打包任务来最小化 GPU 片段的增长。
    |'
- en: '| (5) For Hyperparameter Tuning [[C5]](#S3.SS1.SSS1.tab5 "3.1.1\. GPU sharing:
    ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\. Resource Allocation
    ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey") ([3.1.1](#S3.SS1.SSS1 "3.1.1\. GPU sharing: ‣ 3.1\. Resource
    Allocation for Distributed Training ‣ 3\. Resource Allocation ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey"))
    | Fluid (Yu et al., [2021a](#bib.bib140)) | 2021 | Utilizing a water-filling approach
    to accelerate the hyperparameter optimization process. |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| (5) 超参数调优 [[C5]](#S3.SS1.SSS1.tab5 "3.1.1\. GPU sharing: ‣ 3.1\. Resource
    Allocation for Distributed Training ‣ 3\. Resource Allocation ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    ([3.1.1](#S3.SS1.SSS1 "3.1.1\. GPU sharing: ‣ 3.1\. Resource Allocation for Distributed
    Training ‣ 3\. Resource Allocation ‣ Resource Allocation and Workload Scheduling
    for Large-Scale Distributed Deep Learning: A Survey")) | Fluid (Yu et al., [2021a](#bib.bib140))
    | 2021 | 利用水填充方法加速超参数优化过程。 |'
- en: '| Titan (Gao et al., [2022](#bib.bib32)) | 2022 | Merging several fine-tuning
    workloads into one to improve resource utilization. |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| Titan (Gao et al., [2022](#bib.bib32)) | 2022 | 将多个微调工作负载合并为一个，以提高资源利用率。
    |'
- en: '|  | DISC (Liu et al., [2022d](#bib.bib70)) | 2022 | Leveraging adaptive scaling
    to adjust the size of GPU time slices and formalizing the dynamic allocation of
    GPU time slices into an optimization problem. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '|  | DISC (Liu et al., [2022d](#bib.bib70)) | 2022 | 利用自适应扩展来调整 GPU 时间片的大小，并将
    GPU 时间片的动态分配形式化为一个优化问题。 |'
- en: '|  | Hydro (Hu et al., [2023](#bib.bib44)) | 2023 | Expanding resources for
    hyperparameter tuning workloads by interleaving them with pipeline-enabled large-model
    training tasks. |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '|  | Hydro (Hu et al., [2023](#bib.bib44)) | 2023 | 通过将超参数调优工作负载与管道支持的大模型训练任务交替进行，来扩展资源。
    |'
- en: '| Network Bandwidth Sharing. Granularity: (1) Job; (2) Gradient Block; (3)
    Coflow [[C6]](#S3.SS1.SSS1.tab6 "3.1.1\. GPU sharing: ‣ 3.1\. Resource Allocation
    for Distributed Training ‣ 3\. Resource Allocation ‣ Resource Allocation and Workload
    Scheduling for Large-Scale Distributed Deep Learning: A Survey") ([3.1.2](#S3.SS1.SSS2
    "3.1.2\. Network bandwidth sharing: ‣ 3.1\. Resource Allocation for Distributed
    Training ‣ 3\. Resource Allocation ‣ Resource Allocation and Workload Scheduling
    for Large-Scale Distributed Deep Learning: A Survey")) | Liquid (Gu et al., [2022](#bib.bib39))
    | 2021 | (1) Proposing intelligent cluster network-efficient scheduling methods
    in both immediate and batch modes. |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 网络带宽共享。粒度：（1）作业；（2）梯度块；（3）协流 [[C6]](#S3.SS1.SSS1.tab6 "3.1.1\. GPU sharing:
    ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\. Resource Allocation
    ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey") ([3.1.2](#S3.SS1.SSS2 "3.1.2\. Network bandwidth sharing:
    ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\. Resource Allocation
    ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey")) | Liquid (Gu et al., [2022](#bib.bib39)) | 2021 | （1）提出在即时和批处理模式下智能的集群网络高效调度方法。
    |'
- en: '| Prophet (Zhang et al., [2021](#bib.bib146)) | 2021 | (2) Employing the monitored
    network bandwidth and the profiled gradient time interval to predict the number
    of gradients into gradient blocks. |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| Prophet (Zhang et al., [2021](#bib.bib146)) | 2021 | （2）利用监测到的网络带宽和分析的梯度时间间隔预测梯度块中的梯度数量。
    |'
- en: '|  | Parrot (Li et al., [2020a](#bib.bib62)) | 2020 | (3) Using a linear program
    (LP) solution to derive a weighted bandwidth scaling strategy to minimize the
    time cost in the communication stage. |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '|  | Parrot (Li et al., [2020a](#bib.bib62)) | 2020 | （3）使用线性规划（LP）解决方案推导加权带宽缩放策略，以最小化通信阶段的时间成本。
    |'
- en: '|    Inference ([3.2](#S3.SS2 "3.2\. Resource Allocation for Distributed Inference
    ‣ 3\. Resource Allocation ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey")) | Spatial Sharing [[C7]](#S3.SS1.SSS2.tab1
    "3.1.2\. Network bandwidth sharing: ‣ 3.1\. Resource Allocation for Distributed
    Training ‣ 3\. Resource Allocation ‣ Resource Allocation and Workload Scheduling
    for Large-Scale Distributed Deep Learning: A Survey") | GSLICE (Dhakal et al.,
    [2020](#bib.bib23)) | 2020 | Developing self-learning and adaptive GPU-resource
    allocation and batching schemes. |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|    推理 ([3.2](#S3.SS2 "3.2\. Resource Allocation for Distributed Inference
    ‣ 3\. Resource Allocation ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey")) | 空间共享 [[C7]](#S3.SS1.SSS2.tab1 "3.1.2\.
    Network bandwidth sharing: ‣ 3.1\. Resource Allocation for Distributed Training
    ‣ 3\. Resource Allocation ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey") | GSLICE (Dhakal et al., [2020](#bib.bib23))
    | 2020 | 开发自学习和自适应的GPU资源分配与批处理方案。 |'
- en: '| iGniter (Xu et al., [2022](#bib.bib130)) | 2022 | Leveraging inference performance
    model to calculate the appropriate batch size and lower bound of allocated GPU
    resources. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| iGniter (Xu et al., [2022](#bib.bib130)) | 2022 | 利用推理性能模型计算合适的批处理大小和分配的GPU资源下限。
    |'
- en: '|  | SLO-aware (Cho et al., [2022](#bib.bib20)) | 2022 | Distributing inference
    requests to the deployed functions based on the autoscaling decision. |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '|  | SLO-aware (Cho et al., [2022](#bib.bib20)) | 2022 | 根据自动伸缩决策将推理请求分配到已部署的功能上。
    |'
- en: '|  | AlpaServe (Li et al., [2023c](#bib.bib64)) | 2023 | Finding a partitioning
    strategy that minimizes the stage imbalance for inter-operator parallelism. |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '|  | AlpaServe (Li et al., [2023c](#bib.bib64)) | 2023 | 寻找一种分区策略，以最小化操作间并行性的阶段不平衡。
    |'
- en: '| Temporal Sharing [[C7]](#S3.SS1.SSS2.tab1 "3.1.2\. Network bandwidth sharing:
    ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\. Resource Allocation
    ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey") | Nexus (Shen et al., [2019](#bib.bib97)) | 2019 | Applying
    a heuristic approach to select the requests. |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 时间共享 [[C7]](#S3.SS1.SSS2.tab1 "3.1.2\. Network bandwidth sharing: ‣ 3.1\.
    Resource Allocation for Distributed Training ‣ 3\. Resource Allocation ‣ Resource
    Allocation and Workload Scheduling for Large-Scale Distributed Deep Learning:
    A Survey") | Nexus (Shen et al., [2019](#bib.bib97)) | 2019 | 采用启发式方法选择请求。 |'
- en: '| INFaaS (Romero et al., [2021](#bib.bib92)) | 2021 | Identifying the colocation
    interference caused by the shared hardware resources. |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| INFaaS (Romero et al., [2021](#bib.bib92)) | 2021 | 识别由共享硬件资源引起的共址干扰。 |'
- en: '|  | Cocktail (Gunasekaran et al., [2022](#bib.bib40)) | 2022 | Building a
    distributed-weighted auto-scaling policy that utilizes the importance sampling
    technique. |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '|  | Cocktail (Gunasekaran et al., [2022](#bib.bib40)) | 2022 | 构建一个利用重要性采样技术的分布式加权自动伸缩策略。
    |'
- en: '| Hybrid Sharing [[C7]](#S3.SS1.SSS2.tab1 "3.1.2\. Network bandwidth sharing:
    ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\. Resource Allocation
    ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey") | Gpulet (Choi et al., [2022](#bib.bib21)) | 2022 | Allowing
    heterogeneous ML models to be mapped to multiple gpulets in the most cost-effective
    way. |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 混合共享 [[C7]](#S3.SS1.SSS2.tab1 "3.1.2\. 网络带宽共享： ‣ 3.1\. 分布式训练的资源分配 ‣ 3\. 资源分配
    ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述") | Gpulet (Choi et al., [2022](#bib.bib21)) | 2022
    | 允许异构机器学习模型以最具成本效益的方式映射到多个gpulets上。 |'
- en: '| FaST-GShare (Gu et al., [2023](#bib.bib38)) | 2023 | Introducing the FaST-Manager
    to limit and isolate spatio-temporal resources. |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| FaST-GShare (Gu et al., [2023](#bib.bib38)) | 2023 | 引入FaST-Manager来限制和隔离时空资源。
    |'
- en: '|   |  |  |  |  |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '|   |  |  |  |  |'
- en: 3\. Resource Allocation
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 资源分配
- en: 'In this section, we introduce resource allocation strategies for both distributed
    training and inference, which have different workload characteristics and performance
    requirements. Table [3](#S2.T3 "Table 3 ‣ 2.3\. Resource Allocation and Workload
    Scheduling for Distributed DL ‣ 2\. Fundamentals of DL and Distributed DL ‣ Resource
    Allocation and Workload Scheduling for Large-Scale Distributed Deep Learning:
    A Survey") summarizes these strategies with related challenges [Cx], highlighted
    in box texts in the coming sections. Resource allocation strategies for distributed
    training are classified into two categories: GPU sharing and network bandwidth
    sharing. GPU sharing strategies are further classified into five approaches based
    on techniques they applied, including workload profiling, context switching, performance
    estimating, elastic scaling, and special considerations for hyperparameter tuning
    workloads. Network bandwidth sharing strategies are further classified based on
    the targeting granularity of resource, including the job, gradient block task,
    and coflow. Resource allocation strategies for distributed inference are classified
    into three categories based on sharing patterns of GPUs, including spatial, temporal,
    and hybrid sharing.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了针对分布式训练和推理的资源分配策略，这些策略具有不同的工作负载特征和性能要求。表[3](#S2.T3 "表 3 ‣ 2.3\. 分布式深度学习的资源分配与工作负载调度
    ‣ 2\. 深度学习和分布式深度学习的基本原理 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述")总结了这些策略及相关挑战 [Cx]，并在接下来的章节中以框文本形式进行突出。分布式训练的资源分配策略分为两类：GPU共享和网络带宽共享。GPU共享策略根据所应用的技术进一步分为五种方法，包括工作负载分析、上下文切换、性能估计、弹性扩展和针对超参数调优工作负载的特殊考虑。网络带宽共享策略根据资源的目标粒度进一步分类，包括作业、梯度块任务和共流。分布式推理的资源分配策略根据GPU共享模式分为三类，包括空间共享、时间共享和混合共享。
- en: 3.1\. Resource Allocation for Distributed Training
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 分布式训练的资源分配
- en: The training process of distributed DL requires an intensive consumption of
    computational power and memory of GPUs and network communication bandwidth across
    GPUs. Therefore, GPU and network bandwidth sharing is the focus of the discussion
    on resource allocation for distributed training.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式深度学习的训练过程需要大量的计算能力、GPU内存和GPU之间的网络通信带宽。因此，GPU和网络带宽共享是讨论分布式训练资源分配的重点。
- en: '3.1.1\. GPU sharing:'
  id: totrans-139
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1\. GPU共享：
- en: Although GPUs have found extensive applications in distributed DL, a prevalent
    issue of underutilization is observed in production clusters. The recorded GPU
    utilization typically ranges from 25% to below 50% (Narayanan et al., [2020](#bib.bib81);
    Hu et al., [2021](#bib.bib43); Weng et al., [2022](#bib.bib125); Li et al., [2023b](#bib.bib57);
    Weng et al., [2023](#bib.bib126); Cheng et al., [2023](#bib.bib19)). This concern
    is particularly noteworthy in large-scale distributed computing environments.
    To address this issue, various distributed technologies have been developed to
    enable DL tasks to run efficiently on numerous devices (Ye et al., [2024b](#bib.bib135)).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管GPU在分布式深度学习中得到了广泛应用，但在生产集群中常见到资源未充分利用的问题。记录的GPU利用率通常在25%到50%以下之间（Narayanan
    et al., [2020](#bib.bib81); Hu et al., [2021](#bib.bib43); Weng et al., [2022](#bib.bib125);
    Li et al., [2023b](#bib.bib57); Weng et al., [2023](#bib.bib126); Cheng et al.,
    [2023](#bib.bib19)）。在大规模分布式计算环境中，这一问题尤为突出。为了解决这个问题，开发了各种分布式技术，使得深度学习任务可以高效地在多个设备上运行（Ye
    et al., [2024b](#bib.bib135)）。
- en: GPU sharing strategies typically leverage partial resource allocation through
    virtualization to mitigate the challenge of low GPU utilization in large-scale
    distributed DL. NVIDIA, acknowledged as the leading GPU provider, introduces Multiple
    Process Sharing (MPS) (Nvi, [2024b](#bib.bib4)) that offers an operating-system-level
    virtualization solution. Nevertheless, its implementation requires application-specific
    expertise to define resource limits for ensuring performance isolation. Moreover,
    MPS lacks compatibility with various DL frameworks. To address the performance
    isolation issue with MPS, another NVIDIA technology, Multi-Instance GPU (MIG) (Nvi,
    [2024a](#bib.bib3)), enables the partitioning of a GPU into multiple discrete
    instances, each with dedicated resources. However, as MIG cannot dynamically adjust
    the partitions for GPU sharing to fit the GPU requirement of online workloads,
    it must initially allocate peak GPU resources for online workloads initially and
    retain them during the entire execution life cycle, leading to a significant waste
    of GPU resources. To address the problems with efficient performance isolation
    for online workloads in MPS and MIG, Muxflow (Zhao et al., [2023a](#bib.bib148))
    proposes a two-level protection mechanism to guarantee GPU isolation for online
    workloads. The workload level protection resides between the CUDA (cud, [2024a](#bib.bib2))
    drive layer and CUDA runtime layer and controls the offline workloads to protect
    online workloads. The GPU level protection monitors the GPU device status to enable
    dynamic adjustment of the GPU memory quota for offline workloads. ByteDance has
    successfully deployed Muxflow in clusters with more than 20,000 GPUs.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: GPU共享策略通常通过虚拟化利用部分资源分配来缓解大规模分布式深度学习中的低GPU利用率问题。NVIDIA被公认为领先的GPU提供商，推出了多进程共享（MPS）（Nvi,
    [2024b](#bib.bib4)），提供了一个操作系统级的虚拟化解决方案。然而，其实施需要应用程序特定的专业知识来定义资源限制，以确保性能隔离。此外，MPS与各种深度学习框架不兼容。为了解决MPS的性能隔离问题，NVIDIA的另一项技术，多实例GPU（MIG）（Nvi,
    [2024a](#bib.bib3)），能够将一个GPU分割成多个独立的实例，每个实例拥有专用资源。然而，由于MIG不能动态调整分区以适应在线工作负载的GPU需求，它必须在开始时为在线工作负载分配峰值GPU资源，并在整个执行生命周期中保留这些资源，导致GPU资源的显著浪费。为了解决MPS和MIG在在线工作负载中高效性能隔离的问题，Muxflow（Zhao
    et al., [2023a](#bib.bib148)）提出了一种两级保护机制，以保证在线工作负载的GPU隔离。工作负载级别的保护位于CUDA（cud,
    [2024a](#bib.bib2)）驱动层和CUDA运行时层之间，控制离线工作负载以保护在线工作负载。GPU级别的保护监控GPU设备状态，以实现对离线工作负载GPU内存配额的动态调整。字节跳动已经在超过20,000个GPU的集群中成功部署了Muxflow。
- en: '|   Challenge [C1]: Utilizing representative distributed DL workloads and profiling
    general characteristics so that the profiling result accurately reflects the workload
    characteristics of the working environment for the GPU-allocation strategy. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|   挑战[C1]：利用具有代表性的分布式深度学习工作负载，并分析一般特征，以便分析结果准确反映GPU分配策略工作环境中的工作负载特征。 |'
- en: '$\bullet$ Workload profiling: Some solutions leverage the profiling of complex
    distributed DL workloads of production large-scale clusters or clouds to instruct
    the GPU allocation strategies, tackling Challenge [[C1]](#S3.SS1.SSS1.tab1 "3.1.1\.
    GPU sharing: ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\. Resource
    Allocation ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed
    Deep Learning: A Survey"). Gandiva (Xiao et al., [2018](#bib.bib128)) leverages
    the profiles of distributed DL tasks and addresses the issue of GPU underutilization
    in three key ways. Initially, Gandiva allows incoming jobs to time-share GPUs
    with existing jobs when overloaded. Then, it permits time-sliced jobs to migrate
    to other GPUs. Lastly, it supports elastic GPU capacity, increasing the number
    of GPUs during idle times and reducing the number of GPUs as the load grows dynamically,
    thereby utilizing idle GPUs effectively. The performance of Gandiva is demonstrated
    on production clusters at Microsoft. AntMan (Xiao et al., [2020](#bib.bib129))
    is a production solution for distributed DL clusters at Alibaba. It analyzes the
    cause of GPU underutilization in distributed DL clusters for production use in
    three aspects: hardware, cluster scheduling, and job behavior. Exploiting the
    profiles of fluctuating resource demands from distributed training jobs, AntMan
    co-designs the cluster scheduler and distributed DL framework with dynamic scaling
    mechanisms for GPU resources during job execution. This approach ensures jobs’
    service-level objectives (SLOs) in large-scale clusters while enhancing cluster
    utilization through opportunistic scheduling. Leveraging the analysis of the production
    trace at Alibaba, Fragmentation Gradient Descent (FGD) (Weng et al., [2023](#bib.bib126))
    addresses severe GPU fragmentation in large clusters. FGD minimizes GPU fragmentation
    growth through task packing to achieve maximum GPU allocation rates. TGS (Wu et al.,
    [2023](#bib.bib127)) provides transparent GPU sharing at OS layer for distributed
    DL tasks in production clusters of containers. TGS addresses challenges of the
    lack of application profiling knowledge and the potential oversubscription of
    GPU memory during the sharing of GPU resources. It tackles the first challenge
    by monitoring and controlling the rate of sending GPU kernels to the GPU for each
    container adaptively, aiming to maximize the rate of opportunistic jobs while
    not affecting that of production jobs. It tackles the second challenge by unifying
    GPU memory and host memory in a single address space via CUDA unified-memory allocation (cud,
    [2024b](#bib.bib5)) that enables both performance isolation and transparency of
    GPU memory allocation. Oversubscribed memory of opportunistic jobs is evicted
    to the host memory automatically, ensuring the performance of production jobs.
    Strati et al. (Strati et al., [2024](#bib.bib103)) suggest that DNN workloads
    have numerous data-dependent operators with distinct computation and memory requirements.
    These individual operators can saturate the GPU computation units or memory bandwidth
    but often leave other resources underutilized. To address the issue of imbalanced
    utilization of GPU and other resources, they propose a fine-grained and interference-aware
    GPU allocator, named Orion, to co-schedule GPU kernels based on the computation
    and memory profiles of DNN workloads to optimize overall resource utilization.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 工作负载分析：一些解决方案利用生产大规模集群或云中复杂分布式深度学习工作负载的分析来指导 GPU 分配策略，从而应对挑战[[C1]](#S3.SS1.SSS1.tab1
    "3.1.1\. GPU共享：‣ 3.1\. 分布式训练的资源分配 ‣ 3\. 资源分配 ‣ 大规模分布式深度学习的资源分配和工作负载调度：调查"). Gandiva
    (Xiao 等，[2018](#bib.bib128)) 利用分布式深度学习任务的分析，解决了 GPU 使用不足的问题，主要有三种方法。首先，当负载过重时，Gandiva
    允许新进作业与现有作业共享 GPU 时间。接着，它允许时间分片的作业迁移到其他 GPU。最后，它支持弹性 GPU 容量，在空闲时增加 GPU 数量，并随着负载的动态增长减少
    GPU 数量，从而有效利用空闲 GPU。Gandiva 的性能在微软的生产集群上得到了验证。AntMan (Xiao 等，[2020](#bib.bib129))
    是阿里巴巴分布式深度学习集群的生产解决方案。它从硬件、集群调度和作业行为三个方面分析了分布式深度学习集群中 GPU 使用不足的原因。通过利用分布式训练作业的资源需求波动，AntMan
    共同设计了集群调度器和分布式深度学习框架，具备作业执行期间 GPU 资源的动态扩展机制。这种方法确保了大规模集群中作业的服务水平目标（SLO），同时通过机会调度提高了集群利用率。利用阿里巴巴生产跟踪的分析，Fragmentation
    Gradient Descent (FGD) (Weng 等，[2023](#bib.bib126)) 解决了大规模集群中严重的 GPU 碎片化问题。FGD
    通过任务打包最小化 GPU 碎片化增长，以实现最大 GPU 分配率。TGS (Wu 等，[2023](#bib.bib127)) 为生产集群中的容器分布式深度学习任务提供了操作系统层面的透明
    GPU 共享。TGS 解决了应用分析知识不足和 GPU 资源共享期间 GPU 内存潜在超额分配的问题。它通过自适应监控和控制每个容器向 GPU 发送 GPU
    内核的速率，来解决第一个问题，旨在最大化机会作业的速率，同时不影响生产作业的速率。它通过 CUDA 统一内存分配 (cud, [2024b](#bib.bib5))
    将 GPU 内存和主机内存在单一地址空间中统一，解决了第二个问题，实现了 GPU 内存分配的性能隔离和透明度。机会作业的超额分配内存会自动被驱逐到主机内存中，确保生产作业的性能。Strati
    等 (Strati 等，[2024](#bib.bib103)) 提出，DNN 工作负载中有许多数据依赖的运算符，这些运算符具有不同的计算和内存需求。这些单独的运算符可能会饱和
    GPU 计算单元或内存带宽，但往往会使其他资源未得到充分利用。为了解决 GPU 和其他资源利用不平衡的问题，他们提出了一种细粒度且考虑干扰的 GPU 分配器，名为
    Orion，以根据 DNN 工作负载的计算和内存分析共同调度 GPU 内核，从而优化整体资源利用。
- en: '|   Challenge [C2]: Reducing the latency of GPU context switching for distributed
    DL workloads, which include offloading and loading of models and data |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '|   挑战 [C2]：减少分布式深度学习工作负载的GPU上下文切换延迟，包括模型和数据的卸载和加载 |'
- en: '$\bullet$ Context switching: Some work utilizes fast context switching to reduce
    GPU latency, tackling Challenge [[C2]](#S3.SS1.SSS1.tab2 "3.1.1\. GPU sharing:
    ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\. Resource Allocation
    ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey"). GPU context switching refers to a GPU switching between
    processes when it is executing multiple training jobs or tasks in parallel or
    sequence. Salus (Yu and Chowdhury, [2020](#bib.bib139)) achieves low switching
    latency via a fine-grained GPU sharing policy that exposes two GPU sharing primitives:
    fast job switching and memory sharing. The former enables rapid preemption and
    efficient time sharing for the currently active DL job on a GPU, whereas the latter
    packs smaller distributed DL tasks on the same device to ensure high memory utilization
    and prevent memory fragmentation. In contrast, PipeSwitch (Bai et al., [2020](#bib.bib11))
    supports fast-context switching for pipelines of distributed DL jobs. PipeSwitch
    optimizes the context switching overhead through model-aware grouping for pipelines
    and proactive allocating of GPU memory. The model-aware grouping of layers aims
    to minimize the overhead of transferring the model between CPUs and GPUs during
    context switching. The proactive allocation of GPU memory for standby workers
    before it should be active expedites the speed of context switching. To prevent
    job interference, PipeSwitch enforces process-level isolation, by initialing a
    new separate process for each active-worker task. To minimize the overhead of
    loading an application from the memory pool to a GPU, DistMind (Jin et al., [2024](#bib.bib54))
    exposes the abstractions of the GPU pool and memory pool and incorporates three-stage
    pipelining, cache-aware load balancing, and DNN-aware sharding in the GPU scheduler
    to achieve low application loading overhead and high GPU efficiency. G-Safe (Pavlidakis
    et al., [2024](#bib.bib87)) focuses on the safety problem of GPU sharing in multi-tenant
    environments. It constrains the GPU kernels of each application to stay within
    the memory partition allocated to them during context switching.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 上下文切换：一些工作利用快速上下文切换来减少GPU延迟，从而解决挑战 [[C2]](#S3.SS1.SSS1.tab2 "3.1.1\.
    GPU共享： ‣ 3.1\. 分布式训练的资源分配 ‣ 3\. 资源分配 ‣ 大规模分布式深度学习的资源分配和工作负载调度：调查"). GPU上下文切换指的是在GPU执行多个训练任务或任务时，它在进程之间切换。Salus
    (Yu和Chowdhury, [2020](#bib.bib139)) 通过一种细粒度的GPU共享策略实现了低切换延迟，该策略提供了两种GPU共享原语：快速作业切换和内存共享。前者使当前活跃的深度学习作业能够在GPU上迅速抢占和有效时间共享，而后者则将较小的分布式深度学习任务打包在同一设备上，以确保高内存利用率并防止内存碎片化。相对而言，PipeSwitch
    (Bai等, [2020](#bib.bib11)) 支持分布式深度学习作业管道的快速上下文切换。PipeSwitch通过针对管道的模型感知分组和主动分配GPU内存来优化上下文切换开销。层的模型感知分组旨在最小化在上下文切换期间将模型在CPU和GPU之间传输的开销。主动分配GPU内存给待机工作者在其应激活之前，可以加快上下文切换速度。为了防止作业干扰，PipeSwitch通过为每个活跃工作任务初始化一个新的独立进程来执行进程级别隔离。为了最小化从内存池加载应用程序到GPU的开销，DistMind
    (Jin等, [2024](#bib.bib54)) 公开了GPU池和内存池的抽象，并在GPU调度器中结合了三阶段流水线、缓存感知负载均衡和DNN感知分片，以实现低应用程序加载开销和高GPU效率。G-Safe
    (Pavlidakis等, [2024](#bib.bib87)) 关注多租户环境中GPU共享的安全问题。它在上下文切换期间限制每个应用程序的GPU内核保持在分配给它们的内存分区内。
    |
- en: '|   Challenge [C3]: Ensuring that the intermediately defined performance goal
    used for guiding the resource allocation strategy leads to a straightforward improvement
    in the actual performance goal when estimating the performance of distributed
    DL jobs in the GPU-allocation strategy. |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|   挑战 [C3]：确保用于指导资源分配策略的中间定义性能目标在估算分布式深度学习任务的GPU分配策略的实际性能目标时能带来直接的改善。 |'
- en: '$\bullet$ Performance estimating: Some works employ the performance-estimate-guided
    approach to enhance GPU-resource allocation, tackling Challenge [[C3]](#S3.SS1.SSS1.tab3
    "3.1.1\. GPU sharing: ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\.
    Resource Allocation ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey"). Both the performance goal and performance-estimation
    method can vary in these approaches. To illustrate Challenge [[C3]](#S3.SS1.SSS1.tab3
    "3.1.1\. GPU sharing: ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\.
    Resource Allocation ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey"), when a strategy aims to reduce the average
    job completion time but uses GPU utilization as an intermediate performance estimate,
    it must ensure that a higher GPU utilization leads to a reduced average job completion
    time. Optimus (Peng et al., [2018](#bib.bib88)) introduces a dynamic allocation
    algorithm based on marginal gains, estimating the remaining execution time of
    a distributed DL task. In this greedy policy, a job with a larger marginal gain
    will be allocated a higher quota of GPU resources. Harmony (Bao et al., [2019](#bib.bib12))
    uses a deep reinforcement learning (DRL) algorithm to place distributed DL jobs
    on GPU resources that lead to the minimum training or inference time. The learning
    rewards for unseen placements are guided by historical allocation samples. Horus (Yeung
    et al., [2021](#bib.bib136)) builds a model to predict GPU utilization of heterogeneous
    distributed DL tasks from computation graph features. It identifies GPU utilization
    as a general proxy metric for making optimal placement decisions. GPARS (Wang
    et al., [2024](#bib.bib122)) leverages spatiotemporal correlations among jobs
    and adopts graph attention networks for precise job duration prediction. It designs
    a dynamic objective function to allocate suitable GPU types for newly submitted
    jobs.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '$\bullet$ 性能估计：一些研究采用性能估计指导方法来优化GPU资源分配，解决挑战[[C3]](#S3.SS1.SSS1.tab3 "3.1.1\.
    GPU sharing: ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\. Resource
    Allocation ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed
    Deep Learning: A Survey")。这些方法中的性能目标和性能估计方法可能有所不同。为了说明挑战[[C3]](#S3.SS1.SSS1.tab3
    "3.1.1\. GPU sharing: ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\.
    Resource Allocation ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey")，当一个策略旨在减少平均作业完成时间，但使用GPU利用率作为中间性能估计时，必须确保更高的GPU利用率会导致更短的平均作业完成时间。Optimus (Peng
    et al., [2018](#bib.bib88))引入了一种基于边际收益的动态分配算法，估计分布式DL任务的剩余执行时间。在这种贪婪策略中，边际收益较大的作业将被分配更多的GPU资源。Harmony (Bao
    et al., [2019](#bib.bib12))使用深度强化学习（DRL）算法将分布式DL作业放置到能够最小化训练或推断时间的GPU资源上。对于未见过的放置，其学习奖励由历史分配样本指导。Horus (Yeung
    et al., [2021](#bib.bib136))建立了一个模型，以从计算图特征中预测异构分布式DL任务的GPU利用率。它将GPU利用率确定为做出最佳放置决策的一般代理指标。GPARS (Wang
    et al., [2024](#bib.bib122))利用作业之间的时空相关性，并采用图注意网络进行精确的作业时长预测。它设计了一个动态目标函数，为新提交的作业分配合适的GPU类型。'
- en: '|   Challenge [C4]: Determining the timing and quota for expanding resources
    in elastic distributed training, which requires monitoring runtime performance
    statistics. |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '|   挑战[C4]：确定弹性分布式训练中扩展资源的时机和配额，这需要监控运行时性能统计数据。 |'
- en: '$\bullet$ Elastic training: Elastic training, which involves expanding and
    shrinking resource capacity dynamically, is an important strategy to improve resource
    utilization and save costs for distributed DL in the cloud environment. Many studies
    tackle Challenge [[C4]](#S3.SS1.SSS1.tab4 "3.1.1\. GPU sharing: ‣ 3.1\. Resource
    Allocation for Distributed Training ‣ 3\. Resource Allocation ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    and focus on elastic GPU memory allocation. For example, Pollux (Qiao et al.,
    [2021](#bib.bib89)) adjusts GPU resources available to distributed DL jobs dynamically,
    aiming to maximize the overall training goodput within the cluster. To improve
    the efficiency of GPU memory sharing, Zico (Lim et al., [2021](#bib.bib67)) monitors
    the memory-usage patterns of individual distributed DL jobs by tracking computational
    progress during training. Based on the monitoring statistics, Zico allocates and
    deallocates memory among concurrent jobs automatically, ensuring no exceeding
    of the memory budget. AFS (Hwang et al., [2021](#bib.bib48)) points out that handling
    future jobs requires proactive preparation of resources based on current share
    calculations. When the GPU scheduler estimates that the GPU contention will be
    heavy in the future, it allocates more resources to long-lasting jobs; otherwise
    it allocates more resources to short jobs. EasyScale (Li et al., [2023a](#bib.bib58))
    utilizes a thread abstraction called EasyScaleThread to preserve consistent training
    accuracy when the number of workers changes in data-parallel training and proposes
    intra-job and inter-job GPU schedulers to scale in or out GPUs for workers dynamically.
    The intra-job scheduler proposes online GPU allocation proposals to the inter-job
    scheduler to maximize distributed training throughput of a specific distributed
    DL job, and the inter-job scheduler approves or declines proposals based on marginal
    speedup and workload balancing considerations. EasyScale can improve GPU utilization
    in heterogeneous GPU clusters with such two-level elastic GPU scheduling. In contrast,
    some studies focus on elastic container resources. For instance, FlowCon (Mao
    et al., [2023](#bib.bib77)) introduces a container placement strategy based on
    growth efficiency and dynamic resource configuration for elastic allocation and
    withdrawal of resources during runtime.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 弹性训练：弹性训练涉及动态扩展和收缩资源容量，是在云环境中改善资源利用率和节省分布式深度学习成本的重要策略。许多研究解决了挑战 [[C4]](#S3.SS1.SSS1.tab4
    "3.1.1\. GPU 共享：‣ 3.1\. 分布式训练的资源分配 ‣ 3\. 资源分配 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述") 并集中于弹性
    GPU 内存分配。例如，Pollux (Qiao 等人, [2021](#bib.bib89)) 动态调整分布式深度学习任务的 GPU 资源，旨在最大化集群内的整体训练吞吐量。为了提高
    GPU 内存共享效率，Zico (Lim 等人, [2021](#bib.bib67)) 通过跟踪训练过程中的计算进展来监控各个分布式深度学习任务的内存使用模式。基于监控统计数据，Zico
    自动分配和回收并发任务之间的内存，确保不超出内存预算。AFS (Hwang 等人, [2021](#bib.bib48)) 指出，处理未来任务需要根据当前的共享计算进行资源的前瞻性准备。当
    GPU 调度器估计未来 GPU 竞争将会激烈时，它会将更多资源分配给长期任务；否则则将更多资源分配给短期任务。EasyScale (Li 等人, [2023a](#bib.bib58))
    使用一种名为 EasyScaleThread 的线程抽象，以在数据并行训练中在工作线程数量变化时保持一致的训练准确性，并提出了内部作业和作业间 GPU 调度器，以动态地为工作线程扩展或缩减
    GPU。内部作业调度器向作业间调度器提出在线 GPU 分配建议，以最大化特定分布式深度学习任务的分布式训练吞吐量，而作业间调度器根据边际加速和工作负载平衡的考虑来批准或拒绝建议。EasyScale
    可以通过这种两级弹性 GPU 调度提高异构 GPU 集群中的 GPU 利用率。相比之下，一些研究集中于弹性容器资源。例如，FlowCon (Mao 等人,
    [2023](#bib.bib77)) 引入了一种基于增长效率和动态资源配置的容器放置策略，用于在运行时弹性地分配和撤回资源。
- en: '|   Challenge [C5]: Improving GPU utilization for batches of multiple hyperparameter
    tuning jobs, which have mostly homogeneous workloads among different jobs to improve
    overall training throughput. |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|   挑战 [C5]：提高批量多超参数调整任务的 GPU 利用率，这些任务之间的工作负载大多是同质的，以提高整体训练吞吐量。 |'
- en: '$\bullet$ Hyperparameter tuning: Hyperparameter tuning workloads represent
    a batch of distributed jobs with highly similar workload characteristics, which
    can thus be leveraged for resource allocation. Several studies explore strategies
    for improving GPU utilization during hyperparameter tuning in distributed DL clusters,
    tackling Challenge [[C5]](#S3.SS1.SSS1.tab5 "3.1.1\. GPU sharing: ‣ 3.1\. Resource
    Allocation for Distributed Training ‣ 3\. Resource Allocation ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey").
    Fluid (Yu et al., [2021a](#bib.bib140)) is a distributed DL hyperparameter tuning
    execution engine that abstracts the hyperparameter tuning process as a sequence
    of trial groups. It employs a water-filling approach to expedite the hyperparameter
    tuning process to enhance GPU utilization. Titan (Gao et al., [2022](#bib.bib32))
    adopts a heuristic approach by consolidating multiple fine-tuning workloads into
    one, which is particularly advantageous considering that multiple fine-tuning
    workloads often share the same model parameters. DISC (Liu et al., [2022d](#bib.bib70))
    leverages adaptive scaling to adjust the size of GPU time slices occupied by hyperparameter-tuning
    jobs at runtime. This dynamic allocation of GPU time slices for each hyperparameter
    tuning job is based on its potential to create a steep increase in the model accuracy.
    Hydro (Hu et al., [2023](#bib.bib44)) addresses cluster-wise resource utilization
    and tuning efficiency by incorporating a heterogeneity-aware allocation strategy.
    This method extends the resources of hyperparameter-tuning workloads by interleaving
    them with pipeline-enabled large-model training tasks. By effectively utilizing
    idle time intervals on each node caused by the gaps between the forward and backward
    processing of micro-batches, Hydro enhances overall resource utilization and tuning
    efficiency in large-scale distributed DL clusters.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 超参数调优：超参数调优工作负载代表了一批具有高度相似工作负载特征的分布式作业，因此可以利用这些特征进行资源分配。一些研究探讨了在分布式深度学习集群中提高GPU利用率的策略，这些策略解决了挑战[[C5]](#S3.SS1.SSS1.tab5
    "3.1.1\. GPU共享： ‣ 3.1\. 分布式训练的资源分配 ‣ 3\. 资源分配 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述")。Fluid（Yu
    et al., [2021a](#bib.bib140)）是一个分布式深度学习超参数调优执行引擎，它将超参数调优过程抽象为一系列试验组。它采用水填充方法来加速超参数调优过程，从而提升GPU利用率。Titan（Gao
    et al., [2022](#bib.bib32)）通过将多个微调工作负载合并为一个工作负载来采用启发式方法，这在多个微调工作负载经常共享相同模型参数的情况下尤其有利。DISC（Liu
    et al., [2022d](#bib.bib70)）利用自适应扩展在运行时调整由超参数调优作业占用的GPU时间片的大小。这种基于模型准确性可能剧增的潜力的动态GPU时间片分配方法增强了每个超参数调优作业的处理能力。Hydro（Hu
    et al., [2023](#bib.bib44)）通过引入一种考虑异质性的分配策略来解决集群资源利用率和调优效率的问题。该方法通过将超参数调优工作负载与支持流水线的大模型训练任务交错，以扩展超参数调优工作负载的资源。通过有效利用每个节点上由于微批次前向和后向处理之间的间隔而产生的空闲时间间隔，Hydro提升了大规模分布式深度学习集群中的整体资源利用率和调优效率。
- en: '|   Challenge [C6]: Network bandwidth allocation for distributed DL must be
    based on sufficient knowledge of the workload and coordination of bandwidth resource
    across the application and network layers. |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '|   挑战 [C6]：分布式深度学习的网络带宽分配必须基于对工作负载的充分了解，并协调应用层和网络层的带宽资源。 |'
- en: '3.1.2\. Network bandwidth sharing:'
  id: totrans-153
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2\. 网络带宽共享：
- en: 'In large-scale distributed environments, where communication is often the performance
    bottleneck, network bandwidth is another significant factor determining the efficiency
    of distributed training. To tackle Challenge [[C6]](#S3.SS1.SSS1.tab6 "3.1.1\.
    GPU sharing: ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\. Resource
    Allocation ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed
    Deep Learning: A Survey"), network layers, e.g., the transport layer, usually
    work collaboratively with the application layer, and the network bandwidth allocator
    be implemented on either layer based on the level of tasks required to allocate
    network bandwidth.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在大规模分布式环境中，通信通常是性能瓶颈，网络带宽是决定分布式训练效率的另一个重要因素。为了解决挑战[[C6]](#S3.SS1.SSS1.tab6 "3.1.1\.
    GPU共享： ‣ 3.1\. 分布式训练的资源分配 ‣ 3\. 资源分配 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述")，网络层，例如传输层，通常与应用层协同工作，网络带宽分配器可以根据任务的需求在任一层上实现。
- en: '$\bullet$ Job: Some work focuses on network bandwidth sharing for multiple
    distributed training jobs. For instance, Liquid (Gu et al., [2022](#bib.bib39))
    proposes a computational and communication-resource-estimation algorithm and a
    network-efficient job-placement strategy for distributed training jobs. The resource-estimation
    algorithm models resource requirements of distributed training jobs, including
    GPU computing power, GPU memory, and network bandwidth requirements. The job-placement
    strategy assigns distributed training jobs to a cluster of computing nodes and
    containers, finding a best-fit job placement solution that satisfies the estimated
    computational and communication-resource requirements and exhibits less GPU fragmentation
    and network communication cost across containers.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 任务：一些工作关注于多个分布式训练任务的网络带宽共享。例如，Liquid（Gu 等， [2022](#bib.bib39)）提出了一种计算和通信资源估算算法以及一种高效的分布式训练任务网络部署策略。该资源估算算法对分布式训练任务的资源需求进行建模，包括
    GPU 计算能力、GPU 内存和网络带宽需求。任务部署策略将分布式训练任务分配给计算节点和容器集群，寻找最佳的任务部署方案，以满足估算的计算和通信资源需求，并减少
    GPU 分片和容器间网络通信成本。
- en: '$\bullet$ Gradient block task: A distributed training job can be break down
    into multiple training tasks of gradient blocks. Some work focuses on network
    bandwidth sharing at the granularity of the gradient block task. For instance,
    Prophet (Zhang et al., [2021](#bib.bib146)) groups into certain gradient blocks
    based on the profiled time interval and models the distributed training time in
    terms of the network bandwidth and order of network transfers of gradient blocks.
    Based on this model, Prophet searches for an optimal order of network transfers
    of gradient blocks, aiming to minimize the distributed training time. This optimal
    order of gradient block transfers optimizes both the network bandwidth sharing
    among gradient blocks and the overlapping between network transfers and GPU computation.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 梯度块任务：一个分布式训练任务可以分解为多个梯度块训练任务。一些工作关注于梯度块任务粒度上的网络带宽共享。例如，Prophet（Zhang
    等， [2021](#bib.bib146)）根据分析的时间间隔将梯度块分组，并在网络带宽和梯度块的网络传输顺序方面对分布式训练时间进行建模。基于该模型，Prophet
    寻找梯度块的最佳网络传输顺序，旨在最小化分布式训练时间。这个最佳的梯度块传输顺序优化了梯度块之间的网络带宽共享，并优化了网络传输和 GPU 计算之间的重叠。
- en: '$\bullet$ Coflow: A coflow is an abstraction several network flows related
    to a specific communication task, e.g., several or a fraction of gradient transfers,
    and is usually scheduled on the transport layer. Some work focuses on network
    bandwidth sharing for coflows. For instance, Parrot (Li et al., [2020a](#bib.bib62))
    perceives the communication pattern of a distributed training job as a series
    of dependent coflows and estimates the remaining processing time of distributed
    training jobs based on the amount of information carried per coflow. Parrot allocates
    network bandwidth to active coflows of concurrent jobs within the cluster, so
    that the effective completion time of coflows of the job with a shorter remaining
    processing time has a higher priority to be minimized.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ Coflow：Coflow 是多个网络流的抽象，这些网络流与特定的通信任务相关，例如，多个或一部分梯度传输，通常在传输层调度。一些工作关注于
    Coflow 的网络带宽共享。例如，Parrot（Li 等， [2020a](#bib.bib62)）将分布式训练任务的通信模式视为一系列相关的 coflow，并根据每个
    coflow 承载的信息量估算分布式训练任务的剩余处理时间。Parrot 将网络带宽分配给集群内并发任务的活跃 coflow，以使剩余处理时间较短的任务的
    coflow 的有效完成时间具有更高的优先级进行最小化。
- en: '|   Challenge [C7]: Satisfying SLOs, such as latency and throughput, for distributed
    inference jobs of various complexity within specific resource constraints. |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '|   挑战 [C7]：在特定资源约束下，为各种复杂度的分布式推理任务满足 SLO，如延迟和吞吐量。 |'
- en: 3.2\. Resource Allocation for Distributed Inference
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 分布式推理的资源分配
- en: 'In contrast to distributed training that caters to long-term offline workloads,
    distributed inference typically demands real-time execution with more stringent
    requirements on latency and accuracy. This difference in demands requires resource
    allocation solutions to address the distinct characteristics of inference workloads
    effectively. In the distributed inference process, GPU sharing is the focus of
    research, which primarily faces Challenge [[C7]](#S3.SS1.SSS2.tab1 "3.1.2\. Network
    bandwidth sharing: ‣ 3.1\. Resource Allocation for Distributed Training ‣ 3\.
    Resource Allocation ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey"). To tackle this challenge, various resource
    allocation methods can be divided into three major categories: spatial, temporal,
    and hybrid sharing. In the context of multiple distributed DL jobs, the spatial
    sharing of GPUs involves the sharing of GPU space partitions while the temporal
    sharing involves the sharing of computation time slices of an entire GPU. Hybrid
    approaches combine techniques from these two categories.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '与适应长期离线负载的分布式训练相比，分布式推理通常要求实时执行，并对延迟和准确性有更严格的要求。这种需求上的差异要求资源分配解决方案有效地应对推理负载的独特特征。在分布式推理过程中，GPU
    共享是研究的重点，主要面临挑战 [[C7]](#S3.SS1.SSS2.tab1 "3.1.2\. 网络带宽共享: ‣ 3.1\. 分布式训练的资源分配 ‣
    3\. 资源分配 ‣ 大规模分布式深度学习的资源分配与负载调度: 综述")。为了应对这一挑战，各种资源分配方法可以分为三大类：空间共享、时间共享和混合共享。在多个分布式深度学习作业的背景下，GPU
    的空间共享涉及GPU空间分区的共享，而时间共享则涉及整个GPU计算时间片的共享。混合方法结合了这两类技术的特点。'
- en: '$\bullet$ Spatial Sharing: Many existing works exploit spatial sharing of GPUs
    to optimize the performance of distributed inference tasks. GSLICE (Dhakal et al.,
    [2020](#bib.bib23)) introduces an inference system that achieves safe and efficient
    GPU sharing through spatial GPU multiplexing systematically. It utilizes MPS (Nvi,
    [2024b](#bib.bib4)), a GPU spatial-multiplexing framework with virtualization,
    to handle various inference requests. iGniter (Xu et al., [2022](#bib.bib130))
    employs an inference performance model to calculate an appropriate batch size
    and the lower bound of allocated GPU resources. Subsequently, it allocates GPU
    resources for each inference workload by employing a greedy approach to identify
    the placement GPU devices that can achieve minimal performance interference. The
    SLO-aware ML Inference Framework (Cho et al., [2022](#bib.bib20)) designs a resource
    auto-scaling strategy in the cloud by leveraging rich and precise workload-specific
    metrics, with a special consideration of the heterogeneity in the GPU computational
    capability. This effective and elastic management of resources ensures meeting
    the SLO for diverse inference workloads in the cloud. Tackling the problem that
    large models may not be deployed on a single GPU, AlpaServe (Li et al., [2023c](#bib.bib64))
    utilizes queuing theory to mathematically verify the benefits of model parallelism
    and searches for a partitioning strategy that minimizes the stage imbalance for
    inter-operator model parallelism.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 空间共享：许多现有工作利用GPU的空间共享来优化分布式推理任务的性能。GSLICE (Dhakal et al., [2020](#bib.bib23))
    引入了一种推理系统，通过系统化的空间GPU多路复用实现安全高效的GPU共享。它利用MPS (Nvi, [2024b](#bib.bib4))，一个具有虚拟化功能的GPU空间多路复用框架，来处理各种推理请求。iGniter
    (Xu et al., [2022](#bib.bib130)) 使用推理性能模型计算适当的批量大小和分配GPU资源的下界。随后，它采用贪心算法为每个推理负载分配GPU资源，以识别能够实现最小性能干扰的GPU设备。SLO-aware
    ML Inference Framework (Cho et al., [2022](#bib.bib20)) 通过利用丰富而精确的负载特定指标设计了一种资源自动扩展策略，特别考虑了GPU计算能力的异质性。这种有效且灵活的资源管理确保了在云环境中满足各种推理负载的SLO。针对大模型可能无法部署在单一GPU上的问题，AlpaServe (Li
    et al., [2023c](#bib.bib64)) 使用排队理论数学验证了模型并行的好处，并寻找一种最小化操作符间模型并行阶段不平衡的分区策略。
- en: '$\bullet$ Temporal Sharing: Recent temporal-sharing approaches designed for
    specific distributed inference systems have shown improvements in GPU utilization,
    especially in cloud environments shared by numerous tenants. Nexus (Shen et al.,
    [2019](#bib.bib97)) employs a heuristic approach to select requests for co-location
    on the same GPU. Initially, it determines the most suitable batch size to meet
    throughput and SLO requirements for the existing inference workloads. Subsequently,
    Nexus identifies all possible combinations within a GPU’s duty cycle on a single
    GPU in a best-fit manner, maximizing utilization without violating latency requirements.
    Focusing on inference services in the cloud, INFaaS (Romero et al., [2021](#bib.bib92))
    addresses the problem of co-location interference arising from shared hardware
    resources. It allocates available resources to interfered instances through workload
    migration or virtual-machine-level scaling, aiming to reduce monetary costs through
    GPU sharing while meeting latency requirements via virtual-machine-level scaling.
    Cocktail (Gunasekaran et al., [2022](#bib.bib40)) scales the virtual machine resources
    for various inference models in the cloud automatically and proactively based
    on the predicted workload and popularity of these models. This approach enhances
    the efficiency of resource allocation in distributed DL inference systems with
    a specific set of supported inference models.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 时间共享：最近为特定分布式推断系统设计的时间共享方法在GPU利用率方面取得了改进，特别是在由大量租户共享的云环境中。Nexus（Shen
    等人，[2019](#bib.bib97)）采用启发式方法选择在同一GPU上共同定位的请求。最初，它确定最合适的批处理大小以满足现有推断工作负载的吞吐量和SLO要求。随后，Nexus以最佳适配方式识别单个GPU的所有可能组合，最大化利用率而不违反延迟要求。INFaaS（Romero
    等人，[2021](#bib.bib92)）专注于云中的推断服务，解决了由于共享硬件资源导致的共同定位干扰问题。它通过工作负载迁移或虚拟机级别的扩展将可用资源分配给受干扰的实例，旨在通过GPU共享降低经济成本，同时通过虚拟机级别的扩展满足延迟要求。Cocktail（Gunasekaran
    等人，[2022](#bib.bib40)）基于预测的工作负载和这些模型的受欢迎程度，自动且主动地为云中的各种推断模型扩展虚拟机资源。这种方法提高了分布式深度学习推断系统中特定支持推断模型的资源分配效率。
- en: '$\bullet$ Hybrid Sharing: Several works study the hybrid GPU sharing approaches,
    considering both spatial and temporal sharing. Gpulet (Choi et al., [2022](#bib.bib21))
    supports spatial sharing of GPUs via the abstraction of virtual GPUs that are
    split partitions derived from physical GPUs. Given allocated virtual GPU resources,
    Gpulet supports temporal sharing by scheduling the batch sizes of inference jobs
    of multiple tenants, with a goal to guarantee the SLO. This hybrid design enables
    cost-effective cloud-resource allocation for the inference of numerous heterogeneous
    DL models. FaST-GShare (Gu et al., [2023](#bib.bib38)) utilizes spatial and temporal
    sharing of GPUs to maximize inference function throughput in the Function-as-a-Service
    serverless architecture for distributed DL. It supports auto-scaling of inference
    resources in the cloud based on the profiling of function throughput and resource
    allocation, maximizing GPU utilization while ensuring the SLO.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 混合共享：若干研究探讨了混合GPU共享方法，考虑了空间和时间共享。Gpulet（Choi 等人，[2022](#bib.bib21)）通过虚拟GPU的抽象来支持GPU的空间共享，这些虚拟GPU是从物理GPU中分割出来的分区。在分配的虚拟GPU资源下，Gpulet通过调度多个租户的推断任务的批处理大小来支持时间共享，目标是保证SLO。这种混合设计使得云资源的分配能够以成本效益高的方式支持大量异质深度学习模型的推断。FaST-GShare（Gu
    等人，[2023](#bib.bib38)）利用GPU的空间和时间共享，以最大化在无服务器架构中的功能推断吞吐量。它基于功能吞吐量和资源分配的分析支持云中推断资源的自动扩展，最大化GPU利用率，同时确保SLO。
- en: 3.3\. Discussion
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3. 讨论
- en: $\bullet$ Fine-grained and elastic GPU allocation strategies are critical for
    improving GPU utilization. Coarse-grained or even exclusive-access GPU allocation
    for individual distributed DL jobs is common in small clusters but can lead to
    extremely low GPU utilization in the data center environment. Fine-grained GPU
    allocation strategies for diverse distributed training and inference workloads,
    which share GPU computational resources for multiple jobs and subtasks, are crucial
    for improving GPU utilization, reducing memory fragmentation, and ensuring performance
    isolation. However, as resource requirements can fluctuate during the long-term
    distributed training process, elastic GPU allocation strategies are also important
    for fully utilizing GPU resources while maintaining SLO from the cloud providers’
    perspective. Both strategy approaches require the support of virtualization technologies
    and a deep understanding of the workload characteristics of distributed DL. Moreover,
    the latter approach also requires knowing the runtime workload performance, which
    can be achieved by performance monitoring and dynamic adaptation techniques.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 细粒度和弹性的 GPU 分配策略对提高 GPU 利用率至关重要。对于小型集群，粗粒度甚至独占访问的 GPU 分配是常见的，但在数据中心环境中，这可能导致极低的
    GPU 利用率。针对多种分布式训练和推理工作负载的细粒度 GPU 分配策略，通过为多个作业和子任务共享 GPU 计算资源，对于提高 GPU 利用率、减少内存碎片和确保性能隔离非常关键。然而，由于资源需求在长期分布式训练过程中可能会波动，弹性
    GPU 分配策略对于充分利用 GPU 资源，同时保持云服务提供商的服务水平目标 (SLO) 也非常重要。这些策略都需要虚拟化技术的支持以及对分布式深度学习工作负载特性的深入理解。此外，后者还需要了解运行时工作负载性能，这可以通过性能监控和动态调整技术来实现。
- en: $\bullet$ High-performance large-scale distributed DL requires the orchestration
    of efficient allocation of GPU and network resources. The allocation of network
    resources can frequently be overlooked as a bottleneck for efficient resource
    utilization in distributed DL. Many resource allocation strategies of distributed
    DL focus on addressing computation issues, such as low utilization, load imbalance,
    and long queuing delays. However, with the increase of the cluster scale, the
    complexity of GPU network connections increases exponentially, and lack of consideration
    to efficient network-resource allocation can result in significant low job-execution
    performance of large-scale distributed DL. Efficient network bandwidth allocation
    strategies can alleviate communication contention. Fully utilizing resources of
    both GPU and network bandwidth leads to enhanced overall performance of distributed
    training and inference on a large scale.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 高性能大规模分布式深度学习需要高效分配 GPU 和网络资源的协调。网络资源的分配往往被忽视，但它可能成为分布式深度学习中高效资源利用的瓶颈。许多分布式深度学习的资源分配策略关注于解决计算问题，如低利用率、负载不平衡和长时间排队延迟。然而，随着集群规模的扩大，GPU
    网络连接的复杂性呈指数增长，如果忽视高效的网络资源分配，可能会导致大规模分布式深度学习的作业执行性能显著降低。高效的网络带宽分配策略可以缓解通信争用。充分利用
    GPU 和网络带宽的资源可以提高大规模分布式训练和推理的整体性能。
- en: $\bullet$ Heterogeneity in resources and workloads is a significant consideration
    for effective resource allocation strategies for distributed DL. Heterogeneous
    resources and workloads are pervasive in the data center environment, which has
    large-scale resources and numerous tenants. On the one hand, Computing nodes and
    networks in various specifications and configurations introduce resource heterogeneity,
    and the heterogeneity that affects the performance of distributed DL most is in
    the heterogeneity in the GPU computation capacity and network protocol, bandwidth,
    and topology. Lack of consideration for resource heterogeneity can either underestimate
    the resource capacity of come resources and cause resource underutilization or
    overestimate the resource capacity of some other resources and cause resource
    contention. On the other hand, distributed DL workload characteristics of different
    tenants over different processing stages of the job in different periods can also
    be heterogeneous. Lack of consideration for heterogeneous workloads can cause
    inaccurate estimation of workload performance, which results in inferior resource
    allocation decisions.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 资源和工作负载的异质性是制定有效资源分配策略的一个重要考虑因素。数据中心环境中普遍存在异质资源和工作负载，该环境具有大规模资源和众多租户。一方面，各种规格和配置的计算节点和网络引入了资源异质性，而最影响分布式深度学习性能的异质性是在
    GPU 计算能力和网络协议、带宽及拓扑方面。忽视资源异质性可能会低估某些资源的资源能力，从而导致资源未得到充分利用，或高估其他资源的资源能力，从而引发资源争用。另一方面，不同租户在不同处理阶段的分布式深度学习工作负载特征也可能存在异质性。忽视异质工作负载可能导致对工作负载性能的估计不准确，从而导致不理想的资源分配决策。
    |
- en: Table 4\. Studies on Workload Scheduling Strategies for Large-Scale Distributed
    Training
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4\. 大规模分布式训练工作负载调度策略的研究
- en: '|    Category | Ref. | Year | Highlight |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '|    类别 | 参考 | 年份 | 亮点 |'
- en: '|    Training Scheduling ([4.1](#S4.SS1 "4.1\. Distributed Training Scheduling
    ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey")) | Throughput: Job Level [[C8]](#S4.SS1.SSS1.tab1
    "4.1.1\. Throughput ‣ 4.1\. Distributed Training Scheduling ‣ 4\. Workload Scheduling
    ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey") ([4.1.1](#S4.SS1.SSS1 "4.1.1\. Throughput ‣ 4.1\. Distributed
    Training Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload
    Scheduling for Large-Scale Distributed Deep Learning: A Survey")) | Tiresias (Gu
    et al., [2019](#bib.bib37))  [C8(1)] | 2019 | Using LAS algorithm to prioritize
    jobs based on their service, a metric defined as the multiplication of requested
    GPU resources and execution time. |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '|    训练调度 ([4.1](#S4.SS1 "4.1\. 分布式训练调度 ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配和工作负载调度：调查"))
    | 吞吐量：作业级别 [[C8]](#S4.SS1.SSS1.tab1 "4.1.1\. 吞吐量 ‣ 4.1\. 分布式训练调度 ‣ 4\. 工作负载调度
    ‣ 大规模分布式深度学习的资源分配和工作负载调度：调查") ([4.1.1](#S4.SS1.SSS1 "4.1.1\. 吞吐量 ‣ 4.1\. 分布式训练调度
    ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配和工作负载调度：调查")) | Tiresias （Gu 等，[2019](#bib.bib37)）  [C8(1)]
    | 2019 | 使用 LAS 算法根据服务优先级进行作业排序，这是一种定义为请求的 GPU 资源和执行时间乘积的度量。 |'
- en: '| OSDL (Wang et al., [2022a](#bib.bib118)) [C8(2)] | 2022 | Designing job-placement
    and scheduling algorithms in hybrid networks with OCS and EPS. |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| OSDL （Wang 等，[2022a](#bib.bib118)） [C8(2)] | 2022 | 设计在具有 OCS 和 EPS 的混合网络中的作业放置和调度算法。
    |'
- en: '|  | Heet (Mo et al., [2024](#bib.bib79))  [C8(2)] | 2024 | Measuring scaling
    efficiency on heterogeneous nodes and uses a price function to balance scaling
    and scheduling efficiency. |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '|  | Heet （Mo 等，[2024](#bib.bib79)）  [C8(2)] | 2024 | 在异质节点上测量扩展效率，并使用价格函数来平衡扩展和调度效率。
    |'
- en: '|  | FfDL (Jayaram et al., [2019](#bib.bib51))  [C8(2)] | 2019 | Using the
    operating lessons from the industry practice to guide the balance dependability
    with scalability, elasticity, flexibility, and efficiency. |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '|  | FfDL （Jayaram 等，[2019](#bib.bib51)）  [C8(2)] | 2019 | 使用行业实践中的操作经验来指导平衡可靠性与可扩展性、弹性、灵活性和效率。
    |'
- en: '|  | Philly (Jeon et al., [2019](#bib.bib52))  [C8(2)] | 2019 | Correlating
    scheduler logs with logs from individual jobs and conducting a thorough analysis
    about the impact of gang scheduling and locality constraints on the queuing delay
    and job runtime. |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '|  | Philly （Jeon 等，[2019](#bib.bib52)）  [C8(2)] | 2019 | 关联调度器日志与单个作业的日志，并对集群调度和局部约束对排队延迟和作业运行时间的影响进行全面分析。
    |'
- en: '|  | E-LAS (Sultana et al., [2020](#bib.bib104))  [C8(2)] | 2020 | Using real-time
    epoch progress rates specific to distributed training jobs, as well as services
    obtained from the temporal and spatial domains, to guide scheduling decisions
    |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '|  | E-LAS (Sultana et al., [2020](#bib.bib104))  [C8(2)] | 2020 | 使用特定于分布式训练作业的实时时期进度率，以及来自时间和空间领域的服务，来指导调度决策。
    |'
- en: '|  | CASSINI (Rajasekaran et al., [2024](#bib.bib91))  [C8(2)] | 2024 | Introducing
    a circle geometric abstraction to model communication workload patterns and shifting
    the angles of the circles to interleave workloads of different jobs on the same
    network link. |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '|  | CASSINI (Rajasekaran et al., [2024](#bib.bib91))  [C8(2)] | 2024 | 引入圆形几何抽象来建模通信工作负载模式，并将圆的角度移动，以在同一网络链路上交错不同作业的工作负载。
    |'
- en: '|  | Liu et al. (Liu et al., [2024b](#bib.bib69))  [C8(2)] | 2024 | Proportionally
    assigning job workloads on heterogeneous clusters for load balancing and high
    throughput. |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '|  | Liu et al. (Liu et al., [2024b](#bib.bib69))  [C8(2)] | 2024 | 在异构集群上按比例分配作业工作负载，以实现负载均衡和高吞吐量。
    |'
- en: '|  | AutoSched (Gao et al., [2024b](#bib.bib35))  [C8(2)] | 2024 | Generating
    simulated workload trace to search for the best framework configuration for existing
    distributed training schedulers. |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '|  | AutoSched (Gao et al., [2024b](#bib.bib35))  [C8(2)] | 2024 | 生成模拟的工作负载轨迹，以搜索现有分布式训练调度器的最佳框架配置。
    |'
- en: '|  | SMD (Yu et al., [2021b](#bib.bib138)) [C8(3)] | 2021 | Allowing multiple
    jobs to compete for the communication bandwidth. |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '|  | SMD (Yu et al., [2021b](#bib.bib138)) [C8(3)] | 2021 | 允许多个作业争夺通信带宽。 |'
- en: '|  | Sched² (Luan et al., [2019](#bib.bib76)) [C8(3)] | 2019 | Using DRL to
    perform smart locality-aware scheduling of distributed training jobs. |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|  | Sched² (Luan et al., [2019](#bib.bib76)) [C8(3)] | 2019 | 使用DRL来智能地感知本地性并调度分布式训练作业。
    |'
- en: '|  | MLFS (Wang et al., [2020b](#bib.bib120))  [C8(3)] | 2020 | Leveraging
    the data from the heuristic scheduling method for training a DRL model and making
    decisions on job scheduling using this trained DRL model automatically. |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '|  | MLFS (Wang et al., [2020b](#bib.bib120))  [C8(3)] | 2020 | 利用启发式调度方法的数据训练DRL模型，并使用该训练的DRL模型自动做出作业调度决策。
    |'
- en: '|  | Yang et al. (Yang et al., [2023a](#bib.bib131)) | 2023 | Utilizing a trainable
    performance model to guide the exploration of DRL and adaptively scheduling all-reduce
    communication workloads. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|  | Yang et al. (Yang et al., [2023a](#bib.bib131)) | 2023 | 利用可训练的性能模型指导DRL的探索，并自适应调度全规约通信工作负载。
    |'
- en: '| Throughput: Pipeline Level [[C9]](#S4.SS1.SSS1.tab2 "4.1.1\. Throughput ‣
    4.1\. Distributed Training Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    ([4.1.1](#S4.SS1.SSS1 "4.1.1\. Throughput ‣ 4.1\. Distributed Training Scheduling
    ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey")) | GPipe (Huang et al., [2019](#bib.bib47))
    | 2019 | Distributing layer-wise model partitions across multiple GPUs and splitting
    mini-batches into micro-batches for pipelining execution. |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| Throughput: Pipeline Level [[C9]](#S4.SS1.SSS1.tab2 "4.1.1\. Throughput ‣
    4.1\. Distributed Training Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    ([4.1.1](#S4.SS1.SSS1 "4.1.1\. Throughput ‣ 4.1\. Distributed Training Scheduling
    ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey")) | GPipe (Huang et al., [2019](#bib.bib47))
    | 2019 | 在多个GPU上分配层级模型划分，并将小批量分割成微批量以进行管道执行。 |'
- en: '| PipeDream (Narayanan et al., [2019](#bib.bib80)) | 2019 | Using a heuristic
    model to determine the workload partitioned on each worker to balance workloads
    and minimize communication overheads under various model and hardware constraints.
    |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| PipeDream (Narayanan et al., [2019](#bib.bib80)) | 2019 | 使用启发式模型确定每个工作节点的工作负载划分，以平衡工作负载并在各种模型和硬件约束下最小化通信开销。
    |'
- en: '|  | AutoPipe (Liu et al., [2022c](#bib.bib73)) | 2022 | An heuristic-based
    adaptive method to achieve balanced model partitioning. |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '|  | AutoPipe (Liu et al., [2022c](#bib.bib73)) | 2022 | 一种基于启发式的自适应方法，用于实现平衡的模型划分。
    |'
- en: '|  | HetPipe (Park et al., [2020](#bib.bib86)) | 2020 | Integrating pipeline
    parallelism with data parallelism in heterogeneous GPU clusters. |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '|  | HetPipe (Park et al., [2020](#bib.bib86)) | 2020 | 在异构GPU集群中将管道并行与数据并行相结合。
    |'
- en: '|  | Piper (Tarnawski et al., [2021](#bib.bib111)) | 2021 | A fine-grained
    pipeline workload partitioning scheme integrating various parallelism modes, including
    the data, layer-wise model, and tensor-wise model parallelism |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '|  | Piper (Tarnawski et al., [2021](#bib.bib111)) | 2021 | 一种精细的管道工作负载划分方案，集成了各种并行模式，包括数据并行、层级模型并行和张量模型并行。
    |'
- en: '|  | MG_WFBP (Shi et al., [2021](#bib.bib99)) | 2021 | Separating the computation
    of backpropagation into subtasks bounded by merged-gradient layers and overlapping
    it with the communication of model synchronization in data-parallel training.
    |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '|  | MG_WFBP (Shi et al., [2021](#bib.bib99)) | 2021 | 将反向传播的计算分解为由合并梯度层界定的子任务，并将其与数据并行训练中的模型同步通信重叠。
    |'
- en: '|  | DeAR (Zhang et al., [2023a](#bib.bib144)) | 2023 | Decoupling the all-reduce
    primitive into two continuous operations, which enables overlapping communication
    tasks with feedforward tasks and reducing the communication overhead of model
    synchronization in data-parallel training. |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '|  | DeAR (Zhang et al., [2023a](#bib.bib144)) | 2023 | 将全规约原语解耦为两个连续操作，使通信任务与前馈任务重叠，从而减少数据并行训练中的模型同步通信开销。
    |'
- en: '|  | ScheMoE (Shi et al., [2024](#bib.bib100)) | 2024 | Partitioning input
    tokens to smaller tensors in all-to-all communications to overlap communication
    and computation in MoE models training. |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '|  | ScheMoE (Shi et al., [2024](#bib.bib100)) | 2024 | 在MoE模型训练中将输入令牌分区为更小的张量，以便在全对全通信中重叠通信和计算。
    |'
- en: '|  | Chimera (Li and Hoefler, [2021](#bib.bib60)) | 2021 | Integrating bidirectional
    pipelines improve 1F1B stage execution order to reduce pipeline stall and memory
    overhead. |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '|  | Chimera (Li and Hoefler, [2021](#bib.bib60)) | 2021 | 通过集成双向管道来改善1F1B阶段执行顺序，从而减少管道停滞和内存开销。
    |'
- en: '|  | OOO BackProp (Oh et al., [2022](#bib.bib84)) | 2022 | Leveraging gradient
    computation dependencies to reorder stage executions in the pipeline, prioritizing
    critical gradient computations. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '|  | OOO BackProp (Oh et al., [2022](#bib.bib84)) | 2022 | 利用梯度计算依赖关系重新排序管道中的阶段执行，优先考虑关键梯度计算。
    |'
- en: '|  | Hanayo (Liu et al., [2023](#bib.bib74)) | 2023 | Running multiple waves
    of stages in a pipeline to reduce pipeline stall with low memory overhead. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '|  | Hanayo (Liu et al., [2023](#bib.bib74)) | 2023 | 在管道中运行多个阶段波次，以减少管道停滞并降低内存开销。
    |'
- en: '|  | MixPipe (Zhang et al., [2023b](#bib.bib145)) | 2023 | Bidirectional pipelines
    for synchronous data-parallel training, with a mixed scheduling of 1F1B and 2F1B
    to balance memory and pipeline stall. |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '|  | MixPipe (Zhang et al., [2023b](#bib.bib145)) | 2023 | 用于同步数据并行训练的双向管道，混合调度1F1B和2F1B以平衡内存和管道停滞。
    |'
- en: '|  | AdaPipe (Sun et al., [2024](#bib.bib105)) | 2024 | Adaptive recomputation
    for different stages in a pipeline to maximize saved recomputation cost within
    memory limits. |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '|  | AdaPipe (Sun et al., [2024](#bib.bib105)) | 2024 | 针对管道中不同阶段进行自适应重计算，以在内存限制内最大化节省的重计算成本。
    |'
- en: '| Throughput: Network Flow Level [[C10]](#S4.SS1.SSS1.tab3 "4.1.1\. Throughput
    ‣ 4.1\. Distributed Training Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    ([4.1.1](#S4.SS1.SSS1 "4.1.1\. Throughput ‣ 4.1\. Distributed Training Scheduling
    ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey")) | JPAS (Zhou et al., [2020](#bib.bib150))
    | 2020 | Using a simple greedy mechanism to order all DDL jobs periodically. |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| Throughput: Network Flow Level [[C10]](#S4.SS1.SSS1.tab3 "4.1.1\. Throughput
    ‣ 4.1\. Distributed Training Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    ([4.1.1](#S4.SS1.SSS1 "4.1.1\. Throughput ‣ 4.1\. Distributed Training Scheduling
    ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey")) | JPAS (Zhou et al., [2020](#bib.bib150))
    | 2020 | 使用简单的贪婪机制定期排序所有DDL作业。 |'
- en: '| Geryon (Wang et al., [2020a](#bib.bib123)) | 2020 | Employing multiple flows
    with varying priorities to transfer parameters of different urgency levels. |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| Geryon (Wang et al., [2020a](#bib.bib123)) | 2020 | 采用多条具有不同优先级的流来传输不同紧急级别的参数。
    |'
- en: '|  | TensorExpress (Kang et al., [2020](#bib.bib55)) | 2020 | Enables each
    switch to transmit tensor packets according to their priority using multiple queues.
    |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '|  | TensorExpress (Kang et al., [2020](#bib.bib55)) | 2020 | 使每个交换机能够根据优先级使用多个队列传输张量包。
    |'
- en: '|  | Beamer (He et al., [2021](#bib.bib42)) | 2021 | Reducing the SCT by considering
    stage information in its scheduling approach. |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '|  | Beamer (He et al., [2021](#bib.bib42)) | 2021 | 通过考虑阶段信息来减少SCT。 |'
- en: '|  | Tereis (Chen et al., [2023](#bib.bib16)) | 2023 | Exploring the utilization
    of idle GPU computational resources during data transmission periods. |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '|  | Tereis (Chen et al., [2023](#bib.bib16)) | 2023 | 探索在数据传输期间利用空闲GPU计算资源。
    |'
- en: '|  | Mercury (Duan et al., [2023](#bib.bib25)) | 2023 | Working on data packet
    to shift priority scheduling to the transport layer. |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '|  | Mercury (Duan et al., [2023](#bib.bib25)) | 2023 | 在数据包中工作，将优先级调度转移到传输层。
    |'
- en: '| Cost Efficiency [[C11]](#S4.SS1.SSS1.tab4 "4.1.1\. Throughput ‣ 4.1\. Distributed
    Training Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload
    Scheduling for Large-Scale Distributed Deep Learning: A Survey") ([4.1.2](#S4.SS1.SSS2
    "4.1.2\. Cost efficiency ‣ 4.1\. Distributed Training Scheduling ‣ 4\. Workload
    Scheduling ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed
    Deep Learning: A Survey")) | Cynthia (Zheng et al., [2019](#bib.bib149)) | 2019
    | Providing predictable distributed training performance and reducing the training
    budget. |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 成本效率 [[C11]](#S4.SS1.SSS1.tab4 "4.1.1\. 吞吐量 ‣ 4.1\. 分布式训练调度 ‣ 4\. 工作负载调度
    ‣ 大规模分布式深度学习的资源分配和工作负载调度：综述") ([4.1.2](#S4.SS1.SSS2 "4.1.2\. 成本效率 ‣ 4.1\. 分布式训练调度
    ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配和工作负载调度：综述")) | Cynthia (Zheng 等，[2019](#bib.bib149))
    | 2019 | 提供可预测的分布式训练性能并减少训练预算。 |'
- en: '| FC² (Ta, [2019](#bib.bib107)) | 2019 | A scheduler that recommends cost-effective
    cloud-resource allocations for distributed training tasks with a PS. |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| FC² (Ta，[2019](#bib.bib107)) | 2019 | 一种调度器，推荐具有参数服务器（PS）的分布式训练任务的成本效益云资源分配。
    |'
- en: '|  | Jahani (Jahani et al., [2019](#bib.bib49)) | 2019 | Modeling the scheduling
    process as a MILP problem to reduce the leasing cost in a global manner while
    maintaining the job latency. |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '|  | Jahani (Jahani 等，[2019](#bib.bib49)) | 2019 | 将调度过程建模为混合整数线性规划（MILP）问题，以在全球范围内减少租赁成本，同时保持作业延迟。'
- en: '|  | GPOEO (Wang et al., [2022b](#bib.bib119)) | 2022 | Saving power in GPU
    data centers and using a customized scheduler to orchestrate jobs. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '|  | GPOEO (Wang 等，[2022b](#bib.bib119)) | 2022 | 在GPU数据中心节省能源，并使用定制调度器来协调作业。
    |'
- en: '|  | STS (Filippini et al., [2023](#bib.bib31)) | 2023 | Exploiting the probability
    distribution of early termination and adapting the resource assignment during
    the execution of the jobs to minimize the expected energy cost |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '|  | STS (Filippini 等，[2023](#bib.bib31)) | 2023 | 利用早期终止的概率分布，并在作业执行过程中调整资源分配，以最小化预期的能源成本。
    |'
- en: '| Deadline Guarantee [[C12]](#S4.SS1.SSS2.tab1 "4.1.2\. Cost efficiency ‣ 4.1\.
    Distributed Training Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    ([4.1.3](#S4.SS1.SSS3 "4.1.3\. Deadline Guarantee ‣ 4.1\. Distributed Training
    Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling
    for Large-Scale Distributed Deep Learning: A Survey")) | GENIE (Chen et al., [2020](#bib.bib18))
    | 2020 | Proposing a prediction model derived from lightweight profiling to estimate
    the processing rate and response latency for diverse DL workloads. |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 截止日期保证 [[C12]](#S4.SS1.SSS2.tab1 "4.1.2\. 成本效率 ‣ 4.1\. 分布式训练调度 ‣ 4\. 工作负载调度
    ‣ 大规模分布式深度学习的资源分配和工作负载调度：综述") ([4.1.3](#S4.SS1.SSS3 "4.1.3\. 截止日期保证 ‣ 4.1\. 分布式训练调度
    ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配和工作负载调度：综述")) | GENIE (Chen 等，[2020](#bib.bib18))
    | 2020 | 提出了一种基于轻量级分析的预测模型，用于估计各种深度学习工作负载的处理速率和响应延迟。 |'
- en: '| Chronus (Gao et al., [2021](#bib.bib33)) | 2021 | Providing deadline guarantee
    for SLO jobs and maximizing the performance of best-effort jobs. |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| Chronus (Gao 等，[2021](#bib.bib33)) | 2021 | 为服务水平目标（SLO）作业提供截止日期保证，并最大化尽力而为作业的性能。
    |'
- en: '|  | Hydra (Yang et al., [2023b](#bib.bib132)) | 2023 | Adopting a sampling
    approach that exploits the inherent iterative periodicity of DL jobs to estimate
    job completion times accurately on heterogeneous GPUs. |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '|  | Hydra (Yang 等，[2023b](#bib.bib132)) | 2023 | 采用采样方法，利用深度学习作业的固有迭代周期性，在异构GPU上准确估计作业完成时间。
    |'
- en: '|  | UniSched (Gao et al., [2024a](#bib.bib34)) | 2024 | Jointly optimize job
    profiling, job scheduling, and resource allocation to guarantee deadline. |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '|  | UniSched (Gao 等，[2024a](#bib.bib34)) | 2024 | 联合优化作业分析、作业调度和资源分配，以保证截止日期。
    |'
- en: '|   |  |  |  |  |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|   |  |  |  |  |'
- en: 4\. Workload Scheduling
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 工作负载调度
- en: In large-scale GPU clusters with complex network connections, scheduling distributed
    DL workloads effectively is critical for ensuring the high performance of task
    execution, optimal hardware utilization, and achievement of various scheduling
    objectives. Training and inference stages of distributed DL are widely recognized
    as particularly computation and communication-intensive (Ye et al., [2024b](#bib.bib135)).
    The following section studies workload scheduling strategies on training and inference
    workloads and focuses on providing efficient communication or overlapping computational
    and communication tasks for overall efficiency in large-scale distributed DL.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有复杂网络连接的大规模 GPU 集群中，**有效地调度分布式 DL 工作负载**对于确保任务执行的高性能、最佳硬件利用率和实现各种调度目标至关重要。分布式
    DL 的训练和推理阶段被广泛认为是特别计算和通信密集型的 (Ye et al., [2024b](#bib.bib135))。以下部分研究了训练和推理工作负载的调度策略，并重点提供了高效的通信或重叠计算和通信任务，以提高大规模分布式
    DL 的整体效率。
- en: 4.1\. Distributed Training Scheduling
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1. 分布式训练调度
- en: 'Efficient workload scheduling strategies are crucial for distributed training
    workloads, especially in large-scale settings with large data, models, and device
    scales. Large-scale distributed training involves iteratively executing massive
    computational tasks for feedforward and backpropagation calculation and communication
    tasks for data flowing and model synchronization. It is a long-term and computation-intensive
    process that requires efficient scheduling strategies to improve execution parallelism
    and completion time and meet various performance goals. In this subsection, we
    survey workload scheduling strategies of large-scale distributed training with
    various performance goals and scheduling granularity levels. Table [4](#S3.T4
    "Table 4 ‣ 3.3\. Discussion ‣ 3\. Resource Allocation ‣ Resource Allocation and
    Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey") summarizes
    these strategies, which are categorized by various performance goals, including
    throughput, cost efficiency, and deadline guarantee goals, while the strategies
    focusing on distributed training throughput are further classified into three
    categories based on the scheduling granularity: the job, pipeline, and network
    flow.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '高效的工作负载调度策略对于分布式训练工作负载至关重要，特别是在具有大数据、模型和设备规模的大规模环境中。大规模分布式训练涉及迭代执行大规模计算任务以进行前向传播和反向传播计算，以及进行数据流动和模型同步的通信任务。这是一个长期且计算密集型的过程，需要高效的调度策略来提高执行并行性和完成时间，并满足各种性能目标。在本小节中，我们调查了具有各种性能目标和调度粒度级别的大规模分布式训练的工作负载调度策略。表
    [4](#S3.T4 "Table 4 ‣ 3.3. Discussion ‣ 3. Resource Allocation ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    总结了这些策略，根据吞吐量、成本效率和截止日期保证等各种性能目标对其进行分类，而关注分布式训练吞吐量的策略进一步根据调度粒度分为作业、流水线和网络流三类。'
- en: 4.1.1\. Throughput
  id: totrans-216
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1. 吞吐量
- en: The throughput of distributed DL refers to the speed at which jobs or tasks
    are completed or the amount of work accomplished per unit of time. It is one of
    the most critical performance goals of distributed training scheduling (Ye et al.,
    [2024b](#bib.bib135)) and is determined synthetically by various factors, including
    resource utilization, parallelism level, and communication overhead. Workload
    scheduling strategies usually work on the job, pipeline, and network flow levels
    to achieve high throughput.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式 DL 的吞吐量指的是完成作业或任务的速度，或单位时间内完成的工作量。它是分布式训练调度的最关键性能目标之一 (Ye et al., [2024b](#bib.bib135))，并由资源利用、并行程度和通信开销等多种因素综合决定。工作负载调度策略通常在作业、流水线和网络流层面上进行，以实现高吞吐量。
- en: '|   Challenge [C8]: (1) Online scheduling of distributed DL jobs whose arrival
    and completion times are unpredictable to achieve high throughput; (2) Resource-aware
    and workload-aware scheduling of distributed DL jobs in complicated, heterogeneous,
    or opaque resource structures; (3) Efficiently solving complex distributed DL
    workload scheduling problems with various resource constraints and workloads.
    |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '|   挑战 [C8]： (1) 在线调度到达和完成时间不可预测的分布式 DL 作业以实现高吞吐量； (2) 在复杂、异构或不透明资源结构中进行资源感知和工作负载感知的分布式
    DL 作业调度； (3) 高效解决具有各种资源约束和工作负载的复杂分布式 DL 工作负载调度问题。 |'
- en: '$\bullet$ Job-level scheduling. Scheduling distributed training at the job
    level, which involves the reordering job execution priorities and the placement
    of jobs on GPUs, is one of the most common and effective scheduling approaches (Gu
    et al., [2019](#bib.bib37); Jayaram et al., [2019](#bib.bib51)). Job-level scheduling
    for distributed training workloads faces several challenges as stated in Challenge
    [[C8]](#S4.SS1.SSS1.tab1 "4.1.1\. Throughput ‣ 4.1\. Distributed Training Scheduling
    ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey"), which include several aspects: online scheduling,
    resource-aware scheduling, and complexity. For Challenge [C8(1)] about online
    scheduling, on the one hand, the unpredictable job arrival time requires a prompt
    online scheduling decision for each job upon its arrival, which may trigger significant
    preemption overhead if the system allows preemptive scheduling. On the other hand,
    the complex workload characteristics and resource topology make it hard to predict
    the job completion time accurately, and an inaccurate estimate can impede the
    scheduling algorithm from achieving high throughput. For Challenge [C8(2)] about
    resource-aware scheduling, the distributed DL workload scheduler should match
    workloads with large-scale resources, especially when the network topology of
    GPUs and nodes is complicated, heterogeneous, and sometimes even opaque and unobservable,
    e.g., in a multi-available-zone cloud environment. For Challenge [C8(3)] about
    scheduling complexity, the complexity of the job-placement problem can increase
    exponentially with the scale of the cluster with various resource constraints
    and workloads, requiring efficient and practical algorithms to find the optimal
    scheduling solution.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 作业级调度。在作业级别调度分布式训练，包括重新排序作业执行优先级和作业在 GPU 上的放置，是最常见和有效的调度方法之一（Gu 等，[2019](#bib.bib37)；Jayaram
    等，[2019](#bib.bib51)）。分布式训练工作负载的作业级调度面临几个挑战，如挑战[[C8]](#S4.SS1.SSS1.tab1 "4.1.1\.
    吞吐量 ‣ 4.1\. 分布式训练调度 ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述")中所述，包括几个方面：在线调度、资源感知调度和复杂性。关于挑战[C8(1)]的在线调度，一方面，不可预测的作业到达时间要求对每个作业到达时作出及时的在线调度决策，这可能会触发显著的抢占开销（如果系统允许抢占调度）。另一方面，复杂的工作负载特征和资源拓扑使得难以准确预测作业完成时间，不准确的估计可能会阻碍调度算法实现高吞吐量。关于挑战[C8(2)]的资源感知调度，分布式深度学习工作负载调度器应将工作负载与大规模资源匹配，特别是在
    GPU 和节点的网络拓扑复杂、多样，有时甚至是不可观察的情况下，例如在多可用区的云环境中。关于挑战[C8(3)]的调度复杂性，作业放置问题的复杂性可能随着集群规模、各种资源约束和工作负载的增加而指数级增长，需要高效且实用的算法来找到最佳调度解决方案。
- en: Some studies refine the job priority algorithm to tackle the preemption problem
    of online job scheduling. For example, Tiresias (Gu et al., [2019](#bib.bib37))
    draws inspiration from the classic Multi-Level Feedback Queue (MLFQ) algorithm (Chowdhury
    and Stoica, [2015](#bib.bib22)) and develops a priority discretization approach
    to mitigate issues related to frequent preemption. In addition, Tiresias uses
    a Least-Attained-Service (LAS) algorithm to prioritize jobs based on their service
    levels, which are quantified by the product of requested GPU resources and execution
    time, to avoid scheduling starvation.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究通过改进作业优先级算法来解决在线作业调度中的抢占问题。例如，Tiresias（Gu 等，[2019](#bib.bib37)）从经典的多级反馈队列（MLFQ）算法（Chowdhury
    和 Stoica，[2015](#bib.bib22)）中汲取灵感，开发了一种优先级离散化方法，以缓解与频繁抢占相关的问题。此外，Tiresias 使用最少服务（LAS）算法，根据作业的服务水平（由请求的
    GPU 资源和执行时间的乘积量化）来优先排序作业，以避免调度饥饿。
- en: Some studies utilize resource topology-aware and workload-aware scheduling algorithms
    to improve performance estimation. For resource topology-aware solutions, OSDL (Wang
    et al., [2022a](#bib.bib118)) designs algorithms for job placing and scheduling
    of distributed training jobs in hybrid networks with optical circuit switching
    (OCS) and electrical packet switching (EPS). The job placing algorithm utilizes
    the hybrid network topology information to use lightpaths reasonably, and the
    job scheduling algorithm jointly optimizes bandwidth requests of distributed training
    jobs in the OCS and EPS domains. Heet (Mo et al., [2024](#bib.bib79)) proposes
    a 3D collaborative filtering method to accurately measure the scaling efficiency
    of all elastic configurations on heterogeneous nodes, substantially reducing profiling
    overhead. Meanwhile, Heet utilizes a price function to effectively balance scaling
    efficiency and scheduling efficiency.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究利用资源拓扑感知和负载感知的调度算法来改善性能估计。对于资源拓扑感知的解决方案，OSDL（Wang 等，[2022a](#bib.bib118)）设计了在光电混合网络（OCS
    和 EPS）中进行分布式训练作业放置和调度的算法。作业放置算法利用混合网络拓扑信息来合理使用光路径，而作业调度算法则联合优化了 OCS 和 EPS 域中的分布式训练作业的带宽请求。HEET（Mo
    等，[2024](#bib.bib79)）提出了一种 3D 协同过滤方法，以准确测量异构节点上所有弹性配置的扩展效率，显著减少了分析开销。同时，HEET 利用价格函数有效平衡了扩展效率和调度效率。
- en: For workload-aware solutions, FfDL (Jayaram et al., [2019](#bib.bib51)), an
    open-source scheduling platform developed by IBM, incorporates operational insights
    from industry practices to strike a balance between dependability and scalability,
    while maintaining elasticity, flexibility, and efficiency. In a related study,
    Philly (Jeon et al., [2019](#bib.bib52)) performs a comprehensive analysis by
    correlating logs of the scheduler with logs of individual jobs, examining the
    impact of gang scheduling and locality constraints on queuing delay and job completion
    time. Drawing on insights from this analysis, Philly advocates relaxing locality
    constraints to enhance job time efficiency. Unlike the above methods, which rely
    on job completion time estimates or prior knowledge, E-LAS (Sultana et al., [2020](#bib.bib104))
    utilizes real-time epoch progress rates specific to distributed training jobs,
    combined with service metrics derived from temporal and spatial domains, to inform
    scheduling decisions. E-LAS surpasses Tiresias in training throughput by reducing
    the average completion time for distributed training jobs. CASSINI (Rajasekaran
    et al., [2024](#bib.bib91)) is a network-workload-aware distributed training job
    scheduler that uses a geometric circle abstraction with angular rotations to represent
    time shifts for communication workload patterns. It schedules different time shifts
    to distribute communication workloads on network links, interleaves communication
    workloads on the same network link, and reduces job completion time. Liu et al. (Liu
    et al., [2024b](#bib.bib69)) leverage proportional workload assignment on a heterogeneous
    GPU cluster to maximize distributed training throughput and minimize job completion
    time. To reduce the scheduling computational complexity, they propose constructing
    the sparsification of feasible solutions through sampling, which can significantly
    decrease the decision-making latency.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 对于负载感知的解决方案，FfDL（Jayaram 等，[2019](#bib.bib51)）是 IBM 开发的一个开源调度平台，它结合了来自行业实践的操作洞察，以在可靠性和可扩展性之间取得平衡，同时保持弹性、灵活性和效率。在相关研究中，Philly（Jeon
    等，[2019](#bib.bib52)）通过将调度器的日志与各个作业的日志进行关联，进行全面分析，研究了联合调度和局部约束对排队延迟和作业完成时间的影响。基于这项分析的见解，Philly
    主张放宽局部约束以提高作业时间效率。与上述方法不同的是，E-LAS（Sultana 等，[2020](#bib.bib104)）利用特定于分布式训练作业的实时阶段进度率，并结合来自时间和空间领域的服务指标来指导调度决策。E-LAS
    通过减少分布式训练作业的平均完成时间，超越了 Tiresias 在训练吞吐量上的表现。CASSINI（Rajasekaran 等，[2024](#bib.bib91)）是一个网络负载感知的分布式训练作业调度器，它使用带有角度旋转的几何圆抽象来表示通信负载模式的时间偏移。它调度不同的时间偏移以分配网络链路上的通信负载，在同一网络链路上交错通信负载，并减少作业完成时间。Liu
    等（Liu 等，[2024b](#bib.bib69)）利用异构 GPU 集群上的比例负载分配来最大化分布式训练吞吐量并最小化作业完成时间。为了减少调度计算复杂性，他们提出通过采样构建可行解的稀疏化，这可以显著降低决策延迟。
- en: In addition to common workload schedulers, which schedule distributed training
    workloads, some studies explore various configurations of existing workload schedulers
    to find the best configuration for specific workloads. For example, AutoSched (Gao
    et al., [2024b](#bib.bib35)) develops a workload generation engine to produce
    training workloads that can reveal future trace patterns, which facilitates accurate
    and efficient configuration tuning of distributed training workload schedulers.
    With the generated workload trace, AutoSched searches for the best configuration
    via a learnable causal model. AutoSched is supposed to be a general configuration-turning
    framework for various off-the-shelf distributed training schedulers, including
    Tiresias.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 除了常见的工作负载调度器，这些调度器调度分布式训练工作负载外，一些研究探索了现有工作负载调度器的各种配置，以找到适合特定工作负载的最佳配置。例如，AutoSched （Gao
    et al.，[2024b](#bib.bib35)）开发了一个工作负载生成引擎，用于生成能够揭示未来跟踪模式的训练工作负载，这有助于准确和高效地配置分布式训练工作负载调度器。通过生成的工作负载跟踪，AutoSched通过可学习的因果模型搜索最佳配置。AutoSched
    应当成为一个通用的配置调整框架，适用于各种现成的分布式训练调度器，包括Tiresias。
- en: Several methods tackle the scheduling complexity by modeling the scheduling
    problem as an optimization problem and applying dynamic programming or DRL algorithms
    to solve the problem efficiently. SMD (Yu et al., [2021b](#bib.bib138)) presents
    a resource-scheduling analytical model that accommodates multiple jobs competing
    for communication bandwidth. This model treats the scheduling problem as a non-convex
    integer non-linear program with bin-packing constraints. SMD introduces an $\epsilon$-approximation
    algorithm for its resolution, termed the sum-of-ratios multi dimensional knapsack
    decomposition. Sched² (Luan et al., [2019](#bib.bib76)) utilizes DRL to schedule
    distributed training jobs with a locality-aware approach. This method tries to
    understand both the locality sensitivity of jobs and the fragmentation condition
    of clusters comprehensively within the entire learning stack. Through this heightened
    awareness, the DRL model adjusts its scheduling decisions dynamically and adaptively,
    responding effectively to the varying locality sensitivities of individual jobs
    and the evolving state of cluster fragmentation. MLFS (Wang et al., [2020b](#bib.bib120))
    employs data from heuristic scheduling methods to train a DRL model and subsequently
    uses this model to make informed decisions about job scheduling autonomously.
    Yang et al. (Yang et al., [2023a](#bib.bib131)) propose a meta-learning-based
    DRL method to improve the job completion time by adaptively scheduling all-reduce
    communication workloads in data-parallel training. To address the issue of massive
    samples in DRL and improve DRL efficiency, the proposed method trains a performance
    model to predict the training time and guide the DRL exploration strategy into
    an effective search space.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 一些方法通过将调度问题建模为优化问题并应用动态规划或深度强化学习（DRL）算法来高效解决调度复杂性。SMD （Yu et al.，[2021b](#bib.bib138)）提出了一个资源调度分析模型，以适应多个作业争夺通信带宽的情况。该模型将调度问题视为具有箱装约束的非凸整数非线性规划问题。SMD
    引入了一种$\epsilon$-近似算法来解决该问题，称为多维背包分解的比例和算法。Sched² （Luan et al.，[2019](#bib.bib76)）利用DRL以地方性感知的方法调度分布式训练作业。该方法试图全面理解作业的地方性敏感性和集群的碎片化情况。在这种高度意识的基础上，DRL模型动态且自适应地调整其调度决策，有效响应个别作业的地方性敏感性变化和集群碎片化状态的演变。MLFS （Wang
    et al.，[2020b](#bib.bib120)）利用启发式调度方法的数据来训练DRL模型，然后使用该模型自主地做出有关作业调度的决策。Yang et
    al. （Yang et al.，[2023a](#bib.bib131)）提出了一种基于元学习的DRL方法，通过自适应调度全规约通信工作负载来提高作业完成时间。为了应对DRL中的大量样本问题并提高DRL效率，所提出的方法训练了一个性能模型来预测训练时间，并指导DRL探索策略进入一个有效的搜索空间。
- en: '|   Challenge [C9]: Partitioning workloads for load balancing across different
    workers and optimizing the execution order to reduce pipeline stall and memory
    overhead in pipeline-level scheduling for distributed training workloads. |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '|   挑战[C9]：为负载均衡在不同工作节点之间划分工作负载，并优化执行顺序，以减少在分布式训练工作负载的管道级调度中的管道停滞和内存开销。 |'
- en: '$\bullet$ Pipeline-level scheduling. In the pipeline parallelism mode of distributed
    training, pipeline-level scheduling divides training mini-batches into micro-batches
    and manages the sequential processing of micro-batch tasks within a pipeline architecture.
    This level of scheduling is widely adopted by large-model distributed training
    jobs. This scheduling approach orchestrates computational and communication tasks
    across various stages in a pre-defined execution order and aims to improve their
    execution parallelism. As a result, the execution of computational and communication
    tasks of the same or different stages overlap, which increases the overall pipeline
    throughput. This approach primarily faces Challenge [[C9]](#S4.SS1.SSS1.tab2 "4.1.1\.
    Throughput ‣ 4.1\. Distributed Training Scheduling ‣ 4\. Workload Scheduling ‣
    Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep Learning:
    A Survey"). The pipeline stall refers to the phenomenon of a faster stage halting
    to wait for dependent slower stages to catch up, which can lead to low pipeline
    utilization and high memory overhead. The memory overhead is the space required
    to retain the results of the feedforward phase in the memory for the later calculation
    of the backpropagation phase in each micro-batch.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 流水线级调度。在分布式训练的流水线并行模式中，流水线级调度将训练小批量数据划分为微批量，并在流水线架构中管理微批量任务的顺序处理。这种调度级别被大模型分布式训练工作广泛采用。这种调度方法协调了在预定义执行顺序中的不同阶段的计算和通信任务，旨在提高其执行并行性。因此，相同或不同阶段的计算和通信任务的执行会重叠，从而提高整体流水线吞吐量。这种方法主要面临挑战[[C9]](#S4.SS1.SSS1.tab2
    "4.1.1\. 吞吐量 ‣ 4.1\. 分布式训练调度 ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配和工作负载调度：综述")。流水线停滞指的是一个更快的阶段暂停等待依赖的较慢阶段赶上，这可能导致低流水线利用率和高内存开销。内存开销是指为了在每个微批量中后续计算反向传播阶段而保留前馈阶段结果所需的空间。
- en: Pipeline parallelism is the state-of-the-art approach for large-model training.
    GPipe (Huang et al., [2019](#bib.bib47)), a pioneer in utilizing pipeline parallelism
    to train large models, distributes layer-wise model partitions across multiple
    GPUs and splits mini-batches into micro-batches for pipelining execution. It reduces
    the pipeline memory overhead by recomputing the activations of the feedforward
    phase again in the backpropagation phase. This library can achieve nearly linear
    convergence speedups and offer the flexibility to scale to various DNN models
    of immense sizes efficiently. However, GPipe assumes a partitioned model for pipelining
    is readily available or specified manually by users and does not design a model
    partitioning scheme for load balance.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线并行是大模型训练的最先进方法。GPipe（Huang 等，[2019](#bib.bib47)），作为利用流水线并行训练大模型的先锋，将逐层模型分区分布到多个
    GPU 上，并将小批量数据划分为微批量以进行流水线执行。它通过在反向传播阶段重新计算前馈阶段的激活来减少流水线内存开销。该库可以实现几乎线性的收敛加速，并提供灵活性以高效地扩展到各种规模巨大的
    DNN 模型。然而，GPipe 假设已经存在可用于流水线的分区模型或由用户手动指定，并未设计用于负载均衡的模型分区方案。
- en: To design an efficient model partitioning scheme for pipeline-level scheduling,
    some studies focus on balancing workloads across workers with hardware constraints.
    PipeDream (Narayanan et al., [2019](#bib.bib80)) builds a heuristic model to determine
    the workload to be partitioned on each worker to balance workloads and minimize
    communication overheads. The model considers various constraints, including the
    model scale, training iteration, device memory capacity, hardware topology and
    bandwidth, and number of workers, and the decision result relies on inputs from
    a short profiling run. To evenly distribute workload among worker, PipeDream also
    integrates data parallelism with pipeline parallelism at certain stages. AutoPipe (Liu
    et al., [2022c](#bib.bib73)) introduces an adaptive method to achieve balanced
    partitioning. It first generates a relatively balanced model partition scheme
    through dynamic programming. It then refines the scheme using the heuristic that
    pipeline completion time can be reduced by moving certain stages in the pipeline’s
    critical execution path forward or backward in the timeline. However, both PipeDream
    and AutoPipe focus only on the homogeneous GPU setting. To address pipeline load
    balancing in heterogeneous GPU clusters, HetPipe (Park et al., [2020](#bib.bib86))
    partitions large DNN models to minimize the maximum completion time of the partitions
    within heterogeneous GPU memory bounds of multiple virtual workers in the pipeline.
    To reduce the communication overhead of fully synchronous pipeline parallelism,
    HetPipe introduces a wave-synchronous-parallel approach to allow bounded model
    staleness within a wave of micro-batches but guarantees convergence.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设计一个高效的模型划分方案用于管道级调度，一些研究专注于在硬件约束下平衡工作负载。PipeDream（Narayanan 等，[2019](#bib.bib80)）构建了一个启发式模型来确定每个工作节点上需要划分的工作负载，以平衡工作负载并最小化通信开销。该模型考虑了各种约束，包括模型规模、训练迭代、设备内存容量、硬件拓扑和带宽以及工作节点的数量，决策结果依赖于短时间剖析运行的输入。为了均匀分配工作负载，PipeDream
    在某些阶段还将数据并行性与管道并行性结合起来。AutoPipe（Liu 等，[2022c](#bib.bib73)）引入了一种自适应方法以实现平衡划分。它首先通过动态规划生成一个相对平衡的模型划分方案，然后利用启发式方法，通过在管道的关键执行路径中前移或后移某些阶段，从而减少管道完成时间。然而，PipeDream
    和 AutoPipe 仅关注于同质 GPU 环境。为了在异构 GPU 集群中解决管道负载平衡问题，HetPipe（Park 等，[2020](#bib.bib86)）将大型
    DNN 模型划分为多个虚拟工作节点的异构 GPU 内存范围内，以最小化分区的最大完成时间。为了减少完全同步管道并行的通信开销，HetPipe 引入了一种波同步并行的方法，允许在一波微批次内模型陈旧性有界，但保证收敛。
- en: 'Some studies focus on fine-grained workload pipelining schemes to maximize
    pipeline throughput. For instance, Piper (Tarnawski et al., [2021](#bib.bib111))
    focuses on fine-grained model partitioning, while MG_WFBP (Shi et al., [2021](#bib.bib99)),
    DeAR (Zhang et al., [2023a](#bib.bib144)) and ScheMoE (Shi et al., [2024](#bib.bib100))
    focus on fine-grained overlapping of computational and communication tasks. For
    fine-grained model partitioning, Piper (Tarnawski et al., [2021](#bib.bib111))
    supports tensor-wise model parallelism in the model partitioning scheme for pipeline
    scheduling, which is not supported in prior work, in addition to data parallelism
    and layer-wise model parallelism. It applies a two-level dynamic programming algorithm
    to search for the optimal partitioning of a DNN model to maximize pipeline throughput
    within memory constraints. With increased search space, Piper can find high-quality
    parallelism configurations with high pipeline throughput. For fine-grained computation
    and communication overlapping, MG_WFBP (Shi et al., [2021](#bib.bib99)) divides
    the calculation of a backpropagation task into numerous subtasks separated by
    merged-gradient layers, which stand as trigger points for model synchronization
    in data-parallel training. As a result, the communication of model synchronization
    in a subtask can overlap with the computation of backpropagation in a subsequent
    subtask. In contrast, DeAR (Zhang et al., [2023a](#bib.bib144)) decouples the
    all-reduce primitive into two continuous operations: reduce-scatter and all-gather.
    This decouple enables overlapping communication tasks of the previous stage with
    feedforward tasks of the next stage in the pipeline execution, reducing the communication
    overhead of model synchronization in data-parallel training. Focusing on the distributed
    training of mixture-of-experts models, which has the communication bottleneck
    caused by the all-to-all collective communication, ScheMoE (Shi et al., [2024](#bib.bib100))
    pipelines all-to-all communications with expert computations by virtually partitioning
    input tokens to multiple smaller tensors to increase the chance of task overlapping.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究关注于细粒度的工作负载流水线方案，以最大化流水线吞吐量。例如，Piper (Tarnawski et al., [2021](#bib.bib111))
    专注于细粒度的模型划分，而 MG_WFBP (Shi et al., [2021](#bib.bib99))、DeAR (Zhang et al., [2023a](#bib.bib144))
    和 ScheMoE (Shi et al., [2024](#bib.bib100)) 则关注于计算和通信任务的细粒度重叠。在细粒度模型划分方面，Piper
    (Tarnawski et al., [2021](#bib.bib111)) 在模型划分方案中支持张量级模型并行，这在之前的工作中并未支持，除了数据并行和层级模型并行之外。它应用了二级动态规划算法来搜索最优的
    DNN 模型划分，以在内存限制下最大化流水线吞吐量。随着搜索空间的增加，Piper 可以找到具有高流水线吞吐量的高质量并行配置。在细粒度计算和通信重叠方面，MG_WFBP
    (Shi et al., [2021](#bib.bib99)) 将反向传播任务的计算划分为许多由合并梯度层分隔的子任务，这些子任务作为数据并行训练中的模型同步触发点。因此，子任务中的模型同步通信可以与随后的子任务中的反向传播计算重叠。相比之下，DeAR
    (Zhang et al., [2023a](#bib.bib144)) 将全规约原语解耦为两个连续操作：reduce-scatter 和 all-gather。这种解耦使得可以将前一阶段的通信任务与下一阶段的前馈任务重叠，减少了数据并行训练中的模型同步通信开销。关注于专家模型的分布式训练，ScheMoE
    (Shi et al., [2024](#bib.bib100)) 通过将输入令牌虚拟划分为多个较小的张量，以增加任务重叠的机会，从而将全到全通信与专家计算流水线化，这解决了由于全到全集体通信造成的通信瓶颈。
- en: Some studies focus on optimizing the pipeline execution order to reduce pipeline
    stall. For example, Chimera (Li and Hoefler, [2021](#bib.bib60)) applies bidirectional
    pipelines that are composed of two pipelines executing stages in reserve directions
    in a one-forward-one-backward (1F1B) manner. Computational tasks of different
    micro-batches are mostly overlapped on different workers and the resultant bidirectional
    pipelines execute in a compacter manner than in PipeDream. Chimera also builds
    a model for determining the optimal number of pipeline stages and number of replicated
    pipelines, whose values rely on empirical results as inputs. Out-Of-Order (OOO)
    BackProp (Oh et al., [2022](#bib.bib84)) leverages gradient computation dependencies
    to reorder stage executions in the pipeline to maximize GPU-resource utilization.
    In data-parallel training, OOO reorders the sequence of gradient computations
    to maximize the overlap between computation and parameter communication. In pipeline-parallel
    training, it prioritizes critical gradient computations to minimize pipeline stall.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究集中于优化流水线执行顺序以减少流水线停滞。例如，Chimera（Li 和 Hoefler，[2021](#bib.bib60)）应用了双向流水线，由两个流水线组成，它们以单向前进和反向（1F1B）的方式执行阶段。不同微批次的计算任务大多在不同的工作节点上重叠执行，因此生成的双向流水线比
    PipeDream 更紧凑。Chimera 还建立了一个模型，用于确定流水线阶段的最佳数量和复制流水线的数量，其值依赖于经验结果作为输入。Out-Of-Order
    (OOO) BackProp（Oh 等，[2022](#bib.bib84)）利用梯度计算依赖关系来重新排序流水线中的阶段执行，以最大化 GPU 资源利用率。在数据并行训练中，OOO
    重新排序梯度计算的顺序，以最大化计算和参数通信之间的重叠。在流水线并行训练中，它优先考虑关键梯度计算，以最小化流水线停滞。
- en: Some studies focus on reducing GPU memory consumption and recomputation cost
    for pipeline execution. On the one hand, though the bidirectional pipeline approach
    of Chimera can achieve low pipeline stall, it has multiple model replicas in two
    pipelines, which requires large GPU memory consumption. Hanayo (Liu et al., [2023](#bib.bib74))
    mitigates the issue of excessive memory consumption by running multiple waves
    of forward and backward stages in a pipeline to reduce pipeline stall while not
    increasing GPU memory consumption. MixPipe (Zhang et al., [2023b](#bib.bib145)),
    another bidirectional pipeline approach for synchronous data-parallel training,
    regulates a flexible number of micro-batches injected into the bidirectional pipelines
    to balance pipeline and device utilization. MixPipe also features a mixed scheduling
    of 1F1B and 2F1B to balance memory usage and pipeline stall. On the other hand,
    though the recomputation strategy for the backward stage in the pipeline can relieve
    memory consumption, its cost can be non-negligible. To balance memory saving and
    computation cost in recomputation, AdaPipe (Sun et al., [2024](#bib.bib105)) models
    the memory and time cost of different recomputation strategies and introduces
    an adaptive recomputation mechanism to allow different recomputation strategies,
    e.g., partial and full recomputation, for different stages in a pipeline. AdaPipe
    achieves maximum saved recomputation cost within memory limits.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究集中于减少流水线执行中的 GPU 内存消耗和重新计算成本。一方面，尽管 Chimera 的双向流水线方法可以实现低流水线停滞，但它在两个流水线中有多个模型副本，这需要大量的
    GPU 内存消耗。Hanayo（Liu 等，[2023](#bib.bib74)）通过在流水线中运行多个波次的前向和后向阶段来减轻过多内存消耗的问题，从而减少流水线停滞，同时不会增加
    GPU 内存消耗。MixPipe（Zhang 等，[2023b](#bib.bib145)），另一种用于同步数据并行训练的双向流水线方法，调整注入到双向流水线中的微批次数量，以平衡流水线和设备利用率。MixPipe
    还具有 1F1B 和 2F1B 的混合调度，以平衡内存使用和流水线停滞。另一方面，尽管流水线中后向阶段的重新计算策略可以缓解内存消耗，但其成本可能不可忽视。为了在重新计算中平衡内存节省和计算成本，AdaPipe（Sun
    等，[2024](#bib.bib105)）对不同重新计算策略的内存和时间成本进行建模，并引入了一种自适应重新计算机制，以允许流水线中不同阶段采用不同的重新计算策略，例如，部分和全量重新计算。AdaPipe
    实现了在内存限制内最大限度地节省重新计算成本。
- en: '|   Challenge [C10]: Scheduling network flows at different granularity level
    to increase bandwidth utilization, network latency, and network congestion for
    distributed DL workloads. |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '|   挑战 [C10]：在不同粒度水平上调度网络流量，以提高带宽利用率、网络延迟和网络拥塞，适用于分布式深度学习工作负载。 |'
- en: '$\bullet$ Network-flow-level scheduling. Efficient network flow scheduling
    determines the transmission priority of data packets, network flows, and coflows
    related to distributed DL jobs, aiming to significantly increase network bandwidth
    utilization, reduce network latency, and avoid network congestion, as stated in
    Challenge [[C10]](#S4.SS1.SSS1.tab3 "4.1.1\. Throughput ‣ 4.1\. Distributed Training
    Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling
    for Large-Scale Distributed Deep Learning: A Survey"). Network flow scheduling
    can work at various granularity levels, including the job, coflow, and data packet
    levels.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '$\bullet$ 网络流层调度。有效的网络流调度确定数据包、网络流和与分布式深度学习任务相关的协流的传输优先级，旨在显著提高网络带宽利用率，减少网络延迟，并避免网络拥堵，如挑战[[C10]](#S4.SS1.SSS1.tab3
    "4.1.1\. Throughput ‣ 4.1\. Distributed Training Scheduling ‣ 4\. Workload Scheduling
    ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey")中所述。网络流调度可以在不同粒度级别上工作，包括作业、协流和数据包级别。'
- en: Some studies focus on the job level. JPAS (Zhou et al., [2020](#bib.bib150))
    implements a straightforward greedy mechanism to organize all distributed training
    jobs periodically. This approach enables each host machine to prioritize its network
    flows according to the established job order, delegating the task of flow scheduling
    and rate allocation to the underlying priority-enabled networks. Tereis (Chen
    et al., [2023](#bib.bib16)) explores the utilization of idle GPU computational
    resources during data transmission periods. It predicts the completion time for
    a distributed DL job and its corresponding data transmission time, allowing for
    the simultaneous packaging of two jobs on the same GPU. This ensures that one
    job is completed before the other concludes its data transfer.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究关注于作业层面。JPAS (Zhou et al., [2020](#bib.bib150))实施了一种简单的贪婪机制，定期组织所有分布式训练作业。这种方法使每台主机能够根据既定的作业顺序优先处理其网络流，将流调度和速率分配的任务委托给底层的优先级网络。Tereis (Chen
    et al., [2023](#bib.bib16))探索了在数据传输期间利用闲置的GPU计算资源。它预测分布式深度学习作业的完成时间及其相应的数据传输时间，允许在同一GPU上同时打包两个作业。这确保了一个作业在另一个作业完成数据传输之前完成。
- en: Some studies focus on the coflow level. Geryon (Wang et al., [2020a](#bib.bib123))
    employs multiple flows with varying priorities to transfer parameters of different
    urgency levels. This approach coordinates multiple PSs effectively and gives precedence
    to urgent parameter transfers across the entire network fabric. Beamer (He et al.,
    [2021](#bib.bib42)) focuses on reducing the stage-completion time (SCT) by considering
    stage information in its scheduling approach. It proposes a stage-aware coflow-scheduling
    method to minimize the average SCT.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究关注于协流层面。Geryon (Wang et al., [2020a](#bib.bib123))使用多个具有不同优先级的流来传输不同紧急程度的参数。这种方法有效协调多个PS，并优先处理整个网络中的紧急参数传输。Beamer (He
    et al., [2021](#bib.bib42))通过在调度方法中考虑阶段信息，专注于减少阶段完成时间（SCT）。它提出了一种阶段感知的协流调度方法，以最小化平均SCT。
- en: Some other studies focus on the data packet level. To address in-network delays,
    such as queuing delays, TensorExpress (Kang et al., [2020](#bib.bib55)) shifts
    priority scheduling to the transport layer, focusing on the packet granularity.
    It enables each switch to transmit tensor packets according to their priorities
    using multiple queues. This method ensures that high-priority data packets are
    handled efficiently to minimize delays. Similarly, Mercury (Duan et al., [2023](#bib.bib25))
    transmits packets with the highest priority in the Mercury buffer first. Additionally,
    Mercury incorporates immediate aggregation at the transport layer, enabling full
    overlapping of gradient push-and-pull operations. This approach not only streamlines
    data flow but also maximizes the efficiency of network resource utilization.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 一些其他研究关注于数据包层面。为了解决网络内的延迟问题，例如排队延迟，TensorExpress (Kang et al., [2020](#bib.bib55))将优先级调度转移到传输层，专注于数据包的粒度。它使得每个交换机能够根据优先级使用多个队列传输张量数据包。这种方法确保高优先级的数据包能够高效处理，从而最小化延迟。类似地，Mercury (Duan
    et al., [2023](#bib.bib25))在Mercury缓冲区中首先传输最高优先级的数据包。此外，Mercury在传输层中加入了即时聚合，能够实现梯度推送和拉取操作的完全重叠。这种方法不仅简化了数据流动，还最大化了网络资源利用的效率。
- en: '|   Challenge [C11]: Jointly optimizing energy consumption, monetary cost,
    and throughput for distributed DL workloads with awareness of cloud resources
    and policies from the perspectives of cloud service providers or service users.
    |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '|   挑战 [C11]: 从云服务提供商或服务用户的角度，联合优化分布式深度学习工作负载的能源消耗、货币成本和吞吐量，同时考虑云资源和政策。 |'
- en: 4.1.2\. Cost efficiency
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2\. 成本效率
- en: 'The cost-efficiency objective of distributed training scheduling aims to minimize
    operational costs while ensuring optimal performance for distributed training
    workloads, especially in the cloud environment. It primarily faces Challenge [[C11]](#S4.SS1.SSS1.tab4
    "4.1.1\. Throughput ‣ 4.1\. Distributed Training Scheduling ‣ 4\. Workload Scheduling
    ‣ Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep
    Learning: A Survey") and focuses on a balance between resource utilization, energy
    consumption, and monetary expenditures in the scheduling decisions. Cynthia (Zheng
    et al., [2019](#bib.bib149)) offers predictable distributed training performance
    while reducing the training budget. This scheduler identifies the optimal resource
    type and maintains training throughput effectively, thereby minimizing monetary
    costs. Similar to Cynthia, FC² (Ta, [2019](#bib.bib107)) is a scheduler that recommends
    cost-effective cloud resource allocations for parameter servers in distributed
    training tasks. It prioritizes instances with the largest network bandwidth within
    the budget to circumvent communication bottlenecks. Furthermore, it introduces
    a heuristic named Scale-Opt for determining worker instances, ensuring job throughput,
    and maximizing cost savings. Jahani (Jahani et al., [2019](#bib.bib49)) considers
    computing nodes with varying numbers of GPUs as distinct virtual machines. The
    scheduling process is modeled as a mixed-integer linear programming (MILP) problem,
    aiming to reduce leasing costs globally while maintaining job latency. GPOEO (Wang
    et al., [2022b](#bib.bib119)) achieves significant power savings for training
    workloads. It can be integrated into GPU data centers easily, utilizing a customized
    scheduler to manage job orchestration. STS (Filippini et al., [2023](#bib.bib31))
    optimizes the scheduling of distributed training jobs from the perspective of
    cloud service providers operating data centers. It leverages the probability distribution
    of early job termination to adapt resource assignments during job execution, with
    the aim of minimizing the expected energy cost.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式训练调度的成本效率目标旨在在确保分布式训练工作负载的最佳性能的同时，尽量减少操作成本，特别是在云环境中。它主要面临挑战[[C11]](#S4.SS1.SSS1.tab4
    "4.1.1\. 吞吐量 ‣ 4.1\. 分布式训练调度 ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配和工作负载调度：综述")，并着重于在调度决策中平衡资源利用、能源消耗和货币支出。Cynthia (Zheng
    et al., [2019](#bib.bib149)) 提供了可预测的分布式训练性能，同时减少了训练预算。该调度器识别最佳资源类型，并有效维护训练吞吐量，从而最小化货币成本。与Cynthia类似，FC² (Ta,
    [2019](#bib.bib107)) 是一个为分布式训练任务中的参数服务器推荐具有成本效益的云资源分配的调度器。它在预算内优先考虑网络带宽最大的实例，以绕过通信瓶颈。此外，它引入了一种名为Scale-Opt的启发式方法来确定工作实例，确保作业吞吐量并最大化成本节省。Jahani (Jahani
    et al., [2019](#bib.bib49)) 将具有不同数量GPU的计算节点视为不同的虚拟机。调度过程被建模为一个混合整数线性规划（MILP）问题，旨在全球范围内减少租赁成本，同时保持作业延迟。GPOEO (Wang
    et al., [2022b](#bib.bib119)) 实现了对训练工作负载的显著节能。它可以轻松集成到GPU数据中心，利用定制的调度器来管理作业编排。STS (Filippini
    et al., [2023](#bib.bib31)) 从运营数据中心的云服务提供商的角度优化分布式训练作业的调度。它利用早期作业终止的概率分布，在作业执行过程中调整资源分配，旨在最小化预期的能源成本。
- en: '|   Challenge [C12]: Accurately estimating job completion or remaining times
    based on workload monitoring statistics in distributed DL workload scheduling
    to guarantee deadlines in the cloud environment. |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '|   挑战 [C12]: 在分布式深度学习工作负载调度中，基于工作负载监控统计数据准确估计作业完成或剩余时间，以保证云环境中的截止时间。 |'
- en: 4.1.3\. Deadline Guarantee
  id: totrans-241
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.3\. 截止时间保证
- en: 'Deadline-guaranteed scheduling focuses on ensuring the completion of distributed
    DL jobs before a specified deadline for jobs whose timing is a crucial consideration.
    This performance goal is more common in the cloud environment, where cloud providers
    can elastically scale resources for distributed training workloads to guarantee
    the SLO for cloud users. Achieving this performance goal primarily faces Challenge
    [[C12]](#S4.SS1.SSS2.tab1 "4.1.2\. Cost efficiency ‣ 4.1\. Distributed Training
    Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling
    for Large-Scale Distributed Deep Learning: A Survey"). GENIE (Chen et al., [2020](#bib.bib18)),
    a trailblazing deadline-aware scheduler for distributed training workloads, explores
    the key factors that impact the performance of distributed DL tasks. It introduces
    a predictive model based on lightweight profiling, enabling an accurate estimation
    of the processing rate and response latency for a variety of distributed DL workloads.
    However, a significant limitation of GENIE is that it is unable to handle mixed
    workloads that include both deadline-sensitive tasks and best-effort tasks simultaneously (Ye
    et al., [2024b](#bib.bib135)). Chronus (Gao et al., [2021](#bib.bib33)), an end-to-end
    scheduling system, meets SLOs by guaranteeing deadlines for SLO-aware jobs while
    also enhancing the performance of best-effort jobs. This dual-focused strategy
    enables Chronus to manage a wide range of workload requirements. By extending
    these studies, Hydra (Yang et al., [2023b](#bib.bib132)) emerges as a dynamic
    and multifaceted scheduler to tackle various scheduling challenges, including
    adhering to deadlines and reducing job completion times. Hydra introduces an sampling
    approach leveraging the iterative periodicity inherent in distributed DL jobs.
    This technique enables precise estimation of job completion times in heterogeneous
    GPU environments, thereby improving efficiency and effectiveness of scheduling
    for various distributed DL workloads. In contrast to other work that usually optimizes
    a specific scheduling stage to guarantee deadline for distributed training jobs,
    UniSched (Gao et al., [2024a](#bib.bib34)) adopts a mixed integer linear programming
    framework to jointly optimize job profiling, job scheduling, and resource allocation
    to satisfy various scheduling objectives, including the deadline SLO and latency.
    Two key components support the optimization of UniSched: an estimator for estimating
    job completion time and a selector for selecting jobs and allocating resources.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 截止时间保证调度关注于确保在指定的截止时间前完成分布式深度学习（DL）任务，对于那些时间要求关键的任务，这种性能目标在云环境中更为常见，云服务提供商可以弹性扩展资源以保证云用户的服务水平目标（SLO）。实现这一性能目标主要面临挑战[[C12]](#S4.SS1.SSS2.tab1
    "4.1.2\. 成本效率 ‣ 4.1\. 分布式训练调度 ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述")。GENIE
    (Chen et al., [2020](#bib.bib18))，一个开创性的截止时间感知调度器，探索了影响分布式深度学习任务性能的关键因素。它引入了基于轻量级分析的预测模型，能够准确估计各种分布式深度学习工作负载的处理速率和响应延迟。然而，GENIE的一个重大限制是它无法同时处理包括截止时间敏感任务和尽力而为任务的混合工作负载
    (Ye et al., [2024b](#bib.bib135))。Chronus (Gao et al., [2021](#bib.bib33))，一个端到端调度系统，通过保证SLO感知任务的截止时间，同时提高尽力而为任务的性能来满足SLO。这种双重聚焦策略使Chronus能够管理各种工作负载要求。通过扩展这些研究，Hydra
    (Yang et al., [2023b](#bib.bib132)) 作为一个动态且多面向的调度器，解决了包括遵守截止时间和减少任务完成时间在内的各种调度挑战。Hydra引入了一种采样方法，利用分布式深度学习任务固有的迭代周期性。这项技术能够在异构GPU环境中精确估计任务完成时间，从而提高各种分布式深度学习工作负载调度的效率和效果。与其他通常优化特定调度阶段以保证分布式训练任务截止时间的工作相比，UniSched
    (Gao et al., [2024a](#bib.bib34)) 采用了混合整数线性规划框架来联合优化任务分析、任务调度和资源分配，以满足包括截止时间SLO和延迟在内的各种调度目标。UniSched优化的两个关键组件是：用于估计任务完成时间的估算器和用于选择任务及分配资源的选择器。
- en: Table 5\. Studies on Workload Scheduling Strategies for Large-Scale Distributed
    Inference
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 表5\. 大规模分布式推理的工作负载调度策略研究
- en: '|    Category | Ref. | Year | Highlight |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '|   类别 | 参考文献 | 年份 | 重点 |'
- en: '|    Inference Scheduling ([4.2](#S4.SS2 "4.2\. Distributed Inference Scheduling
    ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey")) | Latency and Cost Efficiency [[C13]](#S4.SS2.tab1
    "4.2\. Distributed Inference Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    ([4.2.1](#S4.SS2.SSS1 "4.2.1\. Latency and cost efficiency ‣ 4.2\. Distributed
    Inference Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload
    Scheduling for Large-Scale Distributed Deep Learning: A Survey")) | Sniper (Liu
    et al., [2022a](#bib.bib71)) | 2022 | Using non-invasive performance characterization
    networks based on neural network similarity (NNS) to predict the inference time
    of DNNs accurately. |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '|    推理调度 ([4.2](#S4.SS2 "4.2\. 分布式推理调度 ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述"))
    | 延迟与成本效率 [[C13]](#S4.SS2.tab1 "4.2\. 分布式推理调度 ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述")
    ([4.2.1](#S4.SS2.SSS1 "4.2.1\. 延迟与成本效率 ‣ 4.2\. 分布式推理调度 ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述"))
    | Sniper (Liu et al., [2022a](#bib.bib71)) | 2022 | 使用基于神经网络相似性（NNS）的非侵入性性能特征网络来准确预测DNN的推理时间。
    |'
- en: '| Ace-Sniper (Liu et al., [2024a](#bib.bib72)) | 2024 | Including both hardware
    and software platform information in the resource abstraction to tackle heterogeneous
    hardware and platforms for distributed inference. |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| Ace-Sniper (Liu et al., [2024a](#bib.bib72)) | 2024 | 将硬件和软件平台信息纳入资源抽象，以应对异构硬件和平台的分布式推理问题。
    |'
- en: '|  | AP² (Shi et al., [2023](#bib.bib98)) | 2023 | Minimizing distributed inference
    latency in 6G mobile communication systems with communications, heterogeneous
    devices, and task dependency constraints. |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '|  | AP² (Shi et al., [2023](#bib.bib98)) | 2023 | 在6G移动通信系统中，针对通信、异构设备和任务依赖约束，最小化分布式推理延迟。
    |'
- en: '|  | AutoDeep (Li et al., [2020b](#bib.bib63)) | 2020 | Leveraging Bayesian
    Optimization and DRL to unearth the optimal cloud configuration and device placement
    with limited search time adaptively. |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '|  | AutoDeep (Li et al., [2020b](#bib.bib63)) | 2020 | 利用贝叶斯优化和DRL自适应地发掘最佳云配置和设备放置，且搜索时间有限。
    |'
- en: '|  | HexGen (Jiang et al., [2023](#bib.bib53)) | 2024 | Applying asymmetric
    tensor-wise and layer-wise partitioning for pipeline-parallel inference to minimize
    communication and computation costs over heterogeneous GPUs. |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '|  | HexGen (Jiang et al., [2023](#bib.bib53)) | 2024 | 采用不对称张量级和层级划分进行流水线并行推理，以最小化异构GPU上的通信和计算成本。
    |'
- en: '| Throughput [[C14]](#S4.SS2.SSS1.tab1 "4.2.1\. Latency and cost efficiency
    ‣ 4.2\. Distributed Inference Scheduling ‣ 4\. Workload Scheduling ‣ Resource
    Allocation and Workload Scheduling for Large-Scale Distributed Deep Learning:
    A Survey") ([4.2.2](#S4.SS2.SSS2 "4.2.2\. Throughput ‣ 4.2\. Distributed Inference
    Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling
    for Large-Scale Distributed Deep Learning: A Survey")) | Rafiki (Wang et al.,
    [2018](#bib.bib124)) | 2018 | Using a practical AIMD algorithm to adjust inference
    batch size. |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 吞吐量 [[C14]](#S4.SS2.SSS1.tab1 "4.2.1\. 延迟与成本效率 ‣ 4.2\. 分布式推理调度 ‣ 4\. 工作负载调度
    ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述") ([4.2.2](#S4.SS2.SSS2 "4.2.2\. 吞吐量 ‣ 4.2\. 分布式推理调度
    ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述")) | Rafiki (Wang et al., [2018](#bib.bib124))
    | 2018 | 使用实际的 AIMD 算法来调整推理批量大小。 |'
- en: '| Nanily (Tang et al., [2019](#bib.bib109)) | 2019 | Deriving the corresponding
    batch size so that the inference completion time is equal to or close to the maximum
    remaining time. |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| Nanily (Tang et al., [2019](#bib.bib109)) | 2019 | 推导出相应的批量大小，使推理完成时间等于或接近最大剩余时间。
    |'
- en: '|  | RRL (Qin et al., [2019](#bib.bib90)) | 2019 | Focusing on optimizing parallel
    configurations at different levels. |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '|  | RRL (Qin et al., [2019](#bib.bib90)) | 2019 | 专注于优化不同级别的并行配置。 |'
- en: '|  | IRIS (Ferikoglou et al., [2023](#bib.bib29)) | 2023 | Adaptively adjusting
    the number of inference threads or containers based on predicted QPS to increase
    computation resource utilization in the cloud. |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '|  | IRIS (Ferikoglou et al., [2023](#bib.bib29)) | 2023 | 根据预测的QPS自适应地调整推理线程或容器的数量，以提高云计算资源的利用率。
    |'
- en: '|  | Morphling (Wang et al., [2021](#bib.bib121)) | 2021 | Adapting the meta-model
    to a new inference service by sampling a small number of configurations and using
    it to find the optimal one. |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '|  | Morphling (Wang et al., [2021](#bib.bib121)) | 2021 | 通过对少量配置进行采样并使用它来找到最佳配置，将元模型适配到新的推理服务中。
    |'
- en: '|   |  |  |  |  |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '|   |  |  |  |  |'
- en: 4.2\. Distributed Inference Scheduling
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 分布式推理调度
- en: 'The scheduling of distributed inference workloads on available GPUs to meet
    various performance requirements is critical for the application of distributed
    DL models, especially as online services. Distinct from distributed training workloads,
    which are typically iterative, long-term, and resource-intensive, distributed
    inference workloads exhibit another set of characteristics: one-round, short-term,
    and lightweight (Ye et al., [2024b](#bib.bib135); Tang et al., [2023b](#bib.bib108)).
    In correspondence with such workload characteristic differences, the scheduling
    of distributed inference workloads also focuses on latency in addition to cost
    efficiency and throughput. Table [5](#S4.T5 "Table 5 ‣ 4.1.3\. Deadline Guarantee
    ‣ 4.1\. Distributed Training Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey")
    summarizes these distributed inference-scheduling strategies, focusing on various
    performance goals, including latency, cost efficiency, and throughput.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '在可用 GPU 上调度分布式推理负载以满足各种性能要求，对于分布式深度学习模型的应用至关重要，尤其是在线服务。与通常是迭代的、长期的、资源密集型的分布式训练负载不同，分布式推理负载具有另一组特征：单轮的、短期的和轻量级的（Ye
    et al., [2024b](#bib.bib135); Tang et al., [2023b](#bib.bib108)）。针对这些负载特征的差异，分布式推理负载的调度除了关注成本效率和吞吐量外，还注重延迟。表
    [5](#S4.T5 "Table 5 ‣ 4.1.3\. Deadline Guarantee ‣ 4.1\. Distributed Training
    Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling
    for Large-Scale Distributed Deep Learning: A Survey") 总结了这些分布式推理调度策略，重点关注包括延迟、成本效率和吞吐量在内的各种性能目标。'
- en: '|   Challenge [C13]: Profiling workload characteristics of distributed inference
    jobs and scheduling them in low-latency and cost-efficient manners with an awareness
    of resource budgets. |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '|   挑战 [C13]: 以低延迟和成本效率的方式配置分布式推理作业的工作负载特征，并注意资源预算。 |'
- en: 4.2.1\. Latency and cost efficiency
  id: totrans-259
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1\. 延迟与成本效率
- en: 'Scheduling distributed inference jobs faces Challenge [[C13]](#S4.SS2.tab1
    "4.2\. Distributed Inference Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation
    and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey").
    The inference latency refers to the time it takes to make a prediction given an
    inference query. To maintain satisfactory latency, distributed inference schedulers
    are designed to scale resources proactively in response to request density and
    to reorder execution sequences strategically at the job level. For example, Sniper (Liu
    et al., [2022a](#bib.bib71)) stands out as a self-updating cloud-edge collaborative
    inference scheduling system with a focus on time awareness. It abstracts heterogeneous
    hardware resources and employs a non-invasive performance characterization model
    to predict the inference time of DNNs accurately based on neural network similarity.
    This system achieves a stable increase in throughput successfully even in dynamic
    cloud-edge environments, demonstrating its effectiveness and robustness in optimizing
    the distributed inference scheduling. Ace-Sniper (Liu et al., [2024a](#bib.bib72))
    extends Sniper by including software platform information in the resource abstraction,
    such as the CUDA and PyTorch library, to tackle heterogeneous hardware and platforms
    for distributed inference. Distributed inference latency is more of a concern
    in wireless networks, where communications are usually unstable and devices are
    heterogeneous. AP² (Shi et al., [2023](#bib.bib98)) aims to minimize distributed
    inference latency in 6G mobile communication systems with communications, heterogeneous
    devices, and task dependency constraints. It estimates task completion time on
    different devices based on profiling results and adopts a genetic algorithm (Haldurai
    et al., [2016](#bib.bib41)) to optimize the task arrangement for minimized inference
    latency while maintaining system reliability.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '调度分布式推理任务面临挑战[[C13]](#S4.SS2.tab1 "4.2\. Distributed Inference Scheduling ‣
    4\. Workload Scheduling ‣ Resource Allocation and Workload Scheduling for Large-Scale
    Distributed Deep Learning: A Survey")。推理延迟指的是给定推理查询时进行预测所需的时间。为了保持令人满意的延迟，分布式推理调度器被设计为根据请求密度主动扩展资源，并在作业级别策略性地重新排序执行序列。例如，Sniper（Liu
    et al., [2022a](#bib.bib71)）作为一个关注时间意识的自更新云-边缘协作推理调度系统脱颖而出。它抽象了异构硬件资源，并采用非侵入性的性能表征模型，根据神经网络相似性准确预测深度神经网络（DNN）的推理时间。该系统即使在动态的云-边缘环境中也能成功实现吞吐量的稳定增加，展示了其在优化分布式推理调度方面的有效性和鲁棒性。Ace-Sniper（Liu
    et al., [2024a](#bib.bib72)）通过在资源抽象中包含软件平台信息（如CUDA和PyTorch库）来扩展Sniper，以应对异构硬件和平台的分布式推理问题。在无线网络中，分布式推理延迟是一个更大的问题，因为通信通常不稳定且设备异构。AP²（Shi
    et al., [2023](#bib.bib98)）旨在在6G移动通信系统中最小化分布式推理延迟，同时考虑通信、异构设备和任务依赖约束。它基于剖析结果估算不同设备上的任务完成时间，并采用遗传算法（Haldurai
    et al., [2016](#bib.bib41)）来优化任务安排，以在保持系统可靠性的同时最小化推理延迟。'
- en: In practice, cost efficiency is another critical factor for distributed inference,
    especially when used in cloud services. AutoDeep (Li et al., [2020b](#bib.bib63))
    automates cloud deployment for real-time online DNN inference, focusing on minimizing
    costs while satisfying latency constraints. To achieve this, AutoDeep utilizes
    Bayesian optimization combined with DRL, which enables the adaptive discovery
    of the optimal cloud configuration and device placement and reduces the required
    searching time significantly. Through this method, AutoDeep achieves a trade-off
    between operational costs and latency in DNN inference workloads efficiently.
    HexGen (Jiang et al., [2023](#bib.bib53)) improves distributed inference cost
    efficiency for large generative models over heterogeneous GPU devices. It applies
    asymmetric tensor-wise and layer-wise model partitioning for pipeline-parallel
    inference and aims to minimize communication and computation costs with heterogeneous
    GPU memory constraints.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，成本效率是分布式推理的另一个关键因素，尤其是在云服务中使用时。AutoDeep（Li et al., [2020b](#bib.bib63)）自动化了实时在线DNN推理的云部署，重点是最小化成本，同时满足延迟约束。为了实现这一目标，AutoDeep利用了结合了深度强化学习（DRL）的贝叶斯优化，这使得能够自适应地发现最佳云配置和设备布局，并显著减少所需的搜索时间。通过这种方法，AutoDeep在DNN推理工作负载中有效地实现了运营成本与延迟之间的权衡。HexGen（Jiang
    et al., [2023](#bib.bib53)）改善了在异构GPU设备上大规模生成模型的分布式推理成本效率。它应用了非对称张量级和层级模型分区进行管道并行推理，并旨在最小化通信和计算成本，同时考虑异构GPU内存约束。
- en: Latency and cost efficiency are recognized as interdependent objective in the
    inference system design. Improving one objective may inadvertently compromise
    the other if the solution is not designed meticulously, which motivates researchers
    to develop scheduling systems that optimizes both objectives simultaneously.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟和成本效率被认为是推理系统设计中的相互依赖目标。改进一个目标可能会不经意间妨碍另一个目标，如果解决方案设计不够精细，这就促使研究人员开发同时优化两个目标的调度系统。
- en: '|   Challenge [C14]: Scheduling many distributed inference jobs with diverse
    workload characteristics to improve the inference throughput in the cloud. |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '|   挑战 [C14]：调度许多具有不同工作负载特征的分布式推理任务，以提高云中的推理吞吐量。 |'
- en: 4.2.2\. Throughput
  id: totrans-264
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2\. 吞吐量
- en: 'Scheduling batches of distributed inference jobs in the cloud also faces Challenge
    [[C14]](#S4.SS2.SSS1.tab1 "4.2.1\. Latency and cost efficiency ‣ 4.2\. Distributed
    Inference Scheduling ‣ 4\. Workload Scheduling ‣ Resource Allocation and Workload
    Scheduling for Large-Scale Distributed Deep Learning: A Survey"). To tackle this
    challenge, researchers typically refine the scheduling system for distributed
    inference workloads to enhance throughput through batch execution and configuration
    adjustments.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在云中调度分布式推理任务的批量也面临挑战 [[C14]](#S4.SS2.SSS1.tab1 "4.2.1\. 延迟和成本效率 ‣ 4.2\. 分布式推理调度
    ‣ 4\. 工作负载调度 ‣ 大规模分布式深度学习的资源分配与工作负载调度：综述")。为了应对这一挑战，研究人员通常会通过批量执行和配置调整来优化分布式推理工作负载的调度系统，以提高吞吐量。
- en: '$\bullet$ Batch execution: Batching inference has been identified as an efficient
    method to enhance resource utilization and reduce scheduling overhead (Ye et al.,
    [2024b](#bib.bib135)). Various schedulers incorporate heuristic methods to fine-tune
    the batch size for the optimal performance. For instance, Rafiki (Wang et al.,
    [2018](#bib.bib124)) employs a practical Additive-Increase Multiplicative-Decrease
    (AIMD) algorithm to adjust the inference batch size dynamically. This approach
    allows for responsive adaptation to varying workload conditions. Nanily (Tang
    et al., [2019](#bib.bib109)) establishes an upper limit on the batch size by calculating
    the maximum remaining time for a request, which is determined by subtracting the
    minimum queuing time of available resources from the remaining time. It then computes
    an appropriate batch size such that the inference completion time equals to or
    approximates this maximum remaining time.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 批量执行：批量推理被确定为提高资源利用率和减少调度开销的有效方法 (Ye et al., [2024b](#bib.bib135))。各种调度器结合了启发式方法来微调批量大小，以获得最佳性能。例如，Rafiki
    (Wang et al., [2018](#bib.bib124)) 采用了实用的加法增长乘法减少 (AIMD) 算法来动态调整推理批量大小。这种方法允许对变化的工作负载条件做出响应性调整。Nanily
    (Tang et al., [2019](#bib.bib109)) 通过计算请求的最大剩余时间来确定批量大小的上限，这个最大剩余时间是通过从剩余时间中减去可用资源的最小排队时间来确定的。然后，它计算一个适当的批量大小，使推理完成时间等于或接近这个最大剩余时间。
- en: '$\bullet$ Configuration adjustment: In addition to the batch-execution approach,
    certain schedulers employ end-to-end configuration tuning to enhance distributed
    inference throughput. RRL (Qin et al., [2019](#bib.bib90)) emphasizes the optimization
    of parallel configurations at various levels, including inter-request-level and
    intra-request-level parallelisms. This optimization significantly reduces the
    overall system latency and improves the throughput. In cloud environments, distributed
    inference throughput is significantly affected by client queries per second (QPS)
    and the number of parallel workers in the inference system. IRIS (Ferikoglou et al.,
    [2023](#bib.bib29)) adaptively adjusts the parallelism level based on the online
    inference QPS predicted by a model pre-trained with monitoring profiles in an
    offline phase. IRIS integrates the parallelism level scheduling algorithm into
    the container orchestration platform, increasing overall computational resource
    utilization and throughput for distributed inference within the cluster. Morphling (Wang
    et al., [2021](#bib.bib121)), on the other hand, presents a rapid and near-optimal
    auto-configuration framework designed specifically for cloud-native model serving.
    This framework adapts to new inference services by sampling a limited set of configurations
    and then employs a meta-model to identify the most optimal configuration. This
    strategy allows Morphling to adjust quickly and efficiently to various service
    requirements while maintaining high system performance.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 配置调整：除了批量执行方法外，某些调度器采用端到端配置调优来提高分布式推理的吞吐量。RRL（秦等，[2019](#bib.bib90)）强调在各个层面优化并行配置，包括请求间层面和请求内层面的并行性。这种优化显著减少了系统的整体延迟，并提高了吞吐量。在云环境中，分布式推理的吞吐量受每秒客户端查询（QPS）和推理系统中并行工作的数量的显著影响。IRIS（Ferikoglou等，[2023](#bib.bib29)）根据通过离线阶段监控配置预训练的模型预测的在线推理QPS自适应地调整并行性级别。IRIS将并行性级别调度算法集成到容器编排平台中，从而提高了集群中分布式推理的整体计算资源利用率和吞吐量。另一方面，Morphling（王等，[2021](#bib.bib121)）提出了一个快速且接近最优的自动配置框架，专为云原生模型服务设计。该框架通过采样有限的配置集来适应新的推理服务，然后利用元模型识别最优配置。这一策略使Morphling能够快速有效地调整以满足各种服务需求，同时保持高系统性能。
- en: 4.3\. Discussion
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 讨论
- en: $\bullet$ Fine-grained workload ordering and overlapping is key to scheduling
    large-scale distributed DL workloads in various parallelism modes. Job-level scheduling
    is important for online instant workloads and offline batch workloads when the
    distributed DL workloads are relatively lightweight in the multi-tenant data center
    environment. However, as the volumes of models and resources increase rapidly,
    pipeline-level scheduling for large models in large-scale clusters, a scheduling
    approach orthogonal to job-level scheduling, is essential for contemporary distributed
    training. Though obeying different training procedures, data-parallel and model-parallel
    training can both leverage the pipeline to optimize the execution order and maximize
    the overlapping of different processing stages, including computation-computation,
    computation-communication, and communication-communication overlapping. In practice,
    people pipelines the workloads of hybrid training parallelism modes for greater
    training throughput.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 细粒度的工作负载排序和重叠是调度大规模分布式深度学习（DL）工作负载在各种并行模式下的关键。作业级调度对在线即时工作负载和离线批量工作负载非常重要，尤其是在多租户数据中心环境中分布式DL工作负载相对轻量时。然而，随着模型和资源量的快速增加，大规模集群中大模型的管道级调度——一种与作业级调度正交的调度方法——对于现代分布式训练至关重要。尽管遵循不同的训练过程，数据并行和模型并行训练都可以利用管道来优化执行顺序，并最大化不同处理阶段的重叠，包括计算-计算、计算-通信和通信-通信重叠。在实践中，人们将混合训练并行模式的工作负载进行管道化，以提高训练吞吐量。
- en: $\bullet$ Solving complex distributed DL workload scheduling problems typically
    requires DRL. Distributed DL workload scheduling can be a complex problem, especially
    in large-scale data centers with various resource and performance goal constraints.
    Firstly, DRL can quickly adapt to constantly changing distributed DL environments
    and workloads by optimizing the policy through trial and error. Secondly, DRL
    can internally train DNNs for policy and value decisions to efficiently explore
    the vast search space of large-scale distributed DL workload scheduling. Thirdly,
    DRL can make real-time decisions for distributed DL workload scheduling.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 解决复杂的分布式深度学习工作负载调度问题通常需要深度强化学习（DRL）。分布式深度学习工作负载调度可能是一个复杂的问题，特别是在具有各种资源和性能目标约束的大规模数据中心中。首先，DRL可以通过试错优化策略，快速适应不断变化的分布式深度学习环境和工作负载。其次，DRL可以在内部训练深度神经网络（DNN）以进行策略和价值决策，从而有效探索大规模分布式深度学习工作负载调度的广阔搜索空间。第三，DRL可以为分布式深度学习工作负载调度做出实时决策。
- en: $\bullet$ Though throughput is essential for distributed DL workload scheduling,
    cost efficiency is an increasing concern. As the energy and monetary cost of distributed
    training and inference increases exponentially with large datasets and models,
    cost efficiency has become a decisive factor when deploying a training or inference
    process in the cloud from both providers’ and users’ perspectives. On the one
    hand, cloud providers must measure the cost of scheduling dynamic distributed
    DL workloads on diverse resources and design a competitive cost model for distributed
    training and inference services. On the other hand, cloud users need to estimate
    the cost of distributed training or inference based on the cost model and strike
    a balance between cost and other performance goals, such as throughput.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 虽然吞吐量对于分布式深度学习工作负载调度至关重要，但成本效率正变得越来越重要。由于分布式训练和推理的能量和货币成本随着大数据集和模型的增大呈指数增长，成本效率已成为从提供者和用户的角度在云中部署训练或推理过程时的决定性因素。一方面，云提供商必须衡量在多样化资源上调度动态分布式深度学习工作负载的成本，并为分布式训练和推理服务设计具有竞争力的成本模型。另一方面，云用户需要基于成本模型估算分布式训练或推理的成本，并在成本与其他性能目标（如吞吐量）之间取得平衡。
- en: '5\. Distributed Training of LLMs: A Case Study'
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 分布式大语言模型（LLMs）的训练：案例研究
- en: Recently, with the tremendous success of the application of LLMs (Brown et al.,
    [2020](#bib.bib14); Thoppilan et al., [2022](#bib.bib114); Touvron et al., [2023a](#bib.bib115),
    [b](#bib.bib116); et al., [2023](#bib.bib27)) in various domains, such as NLP (Zhao
    et al., [2023b](#bib.bib147)), programming (Nijkamp et al., [2023](#bib.bib83)),
    finance (Huang et al., [2023](#bib.bib46)), and medicine (Thirunavukarasu et al.,
    [2023](#bib.bib113)), distributed training and fine-tuning LLMs efficiently have
    become a heated and important topic for researchers in the fields of computer
    science, artificial intelligence, and communications. As contemporary LLMs are
    in ultra-large sizes with up to hundreds of billions of parameters, training them
    typically requires hundreds of billions of tokens in the training dataset, hundreds
    of GPUs, and tens of days (Zhao et al., [2023b](#bib.bib147)). Efficient resource
    allocation and workload scheduling distributed DL strategies that can scale well
    to large data centers and workloads are critical for LLM training. This section
    examines several real cases of training LLMs in existing literature (Narayanan
    et al., [2021](#bib.bib82); Liao et al., [2021](#bib.bib66); Yuan et al., [2022](#bib.bib141);
    Athlur et al., [2022](#bib.bib8); Smith et al., [2022](#bib.bib102); Ryabinin
    et al., [2023](#bib.bib93); Jang et al., [2023](#bib.bib50)) to uncover insights
    and practical considerations for applying these distributed DL framework strategies
    in a large-scale setting.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，随着LLMs的应用取得了巨大的成功（Brown et al., [2020](#bib.bib14); Thoppilan et al., [2022](#bib.bib114);
    Touvron et al., [2023a](#bib.bib115), [b](#bib.bib116); et al., [2023](#bib.bib27)），在各种领域，如自然语言处理（Zhao
    et al., [2023b](#bib.bib147)）、编程（Nijkamp et al., [2023](#bib.bib83)）、金融（Huang
    et al., [2023](#bib.bib46)）和医学（Thirunavukarasu et al., [2023](#bib.bib113)），分布式训练和微调LLMs的高效性已成为计算机科学、人工智能和通信领域研究人员的热门且重要话题。由于现代LLMs的规模极其庞大，参数多达数百亿，训练它们通常需要数百亿的训练数据标记、数百个GPU和数十天的时间（Zhao
    et al., [2023b](#bib.bib147)）。高效的资源分配和工作负载调度的分布式深度学习策略能够很好地扩展到大型数据中心和工作负载，对于LLM训练至关重要。本节考察了现有文献中的若干LLM训练的真实案例（Narayanan
    et al., [2021](#bib.bib82); Liao et al., [2021](#bib.bib66); Yuan et al., [2022](#bib.bib141);
    Athlur et al., [2022](#bib.bib8); Smith et al., [2022](#bib.bib102); Ryabinin
    et al., [2023](#bib.bib93); Jang et al., [2023](#bib.bib50)），以揭示在大规模环境中应用这些分布式深度学习框架策略的见解和实际考虑。
- en: $\bullet$ What are the important considerations for allocating resources across
    multiple data centers for LLM training? As LLM training requires a large volume
    of computational resources, the resources available in a single data center may
    not be able to support an LLM training job. Collaborative training of LLMs across
    multiple geologically apart data centers, , which form a computational power network
    that share information and resources, has become a common practice (Yuan et al.,
    [2022](#bib.bib141)) and faced several new challenges. Firstly, compared to distributed
    training within a single data center, resource allocation across data centers
    faces significant challenges due to the heterogeneity in various computational
    and communication resources. Secondly, with many tenants across multiple data
    centers, performance isolation enabled by various virtual technologies must be
    ensured to prevent performance interference between different tenants and workloads.
    Thirdly, fault tolerance and data security are major concerns when considering
    the network transfer of the model and data to other data centers. The former concern
    will be discussed soon while the latter is solved mainly at the distributed DL
    algorithm level via federated learning (Liu et al., [2022b](#bib.bib68)), which
    is not a focus of this survey.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 在LLM训练中，跨多个数据中心进行资源分配的重要考虑因素是什么？由于LLM训练需要大量的计算资源，单个数据中心可用的资源可能无法支持LLM训练任务。跨多个地理位置分离的数据中心协作训练LLMs，形成一个共享信息和资源的计算能力网络，已成为一种常见的做法（Yuan
    et al., [2022](#bib.bib141)），并面临一些新挑战。首先，与单一数据中心内的分布式训练相比，跨数据中心的资源分配面临由于各种计算和通信资源的异质性带来的重大挑战。其次，在多个数据中心中存在许多租户时，必须确保通过各种虚拟技术实现性能隔离，以防止不同租户和工作负载之间的性能干扰。第三，考虑到模型和数据传输到其他数据中心时，容错性和数据安全是主要的关注点。前者的问题将很快讨论，而后者主要通过联邦学习（Liu
    et al., [2022b](#bib.bib68)）在分布式深度学习算法层面解决，这不是本调查的重点。
- en: $\bullet$ How to efficiently allocate resources for LLM training on a heterogeneous
    computational power network? Tackling heterogeneous resources in a computational
    power network, the resource allocator needs global knowledge about the resource
    capacity, pricing, and other specifications of all data centers (Liao et al.,
    [2021](#bib.bib66)). The computational power network should also monitor real-time
    resource usage status and workload profiles within each data center. While leveraging
    both global and local resource information of the computational power network,
    the resource allocator considers user-specific and workload-specific requirements,
    such as the geological preference, price and completion time constraint, cost
    of transferring the training model and dataset, and training performance estimate.
    Based on these factors, the resource allocator can distribute black-boxed resources
    efficiently for LLM training within the computational power network with heterogeneous
    resources.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 如何在异构计算网络中有效分配资源以进行 LLM 训练？在处理异构资源的计算网络时，资源分配器需要对所有数据中心的资源容量、定价及其他规格有全局了解
    (Liao 等人，[2021](#bib.bib66))。计算网络还应监控每个数据中心的实时资源使用状态和工作负载概况。资源分配器在利用计算网络的全局和本地资源信息的同时，考虑用户特定和工作负载特定的要求，如地理偏好、价格和完成时间约束、传输训练模型和数据集的成本，以及训练性能估计。基于这些因素，资源分配器可以在具有异构资源的计算网络中高效地分配黑箱资源用于
    LLM 训练。
- en: $\bullet$ How crucial is pipeline parallelism for LLM training? Pipeline parallelism
    is essential for LLM training. As indicated in (Narayanan et al., [2021](#bib.bib82)),
    by diminishing the impact of the communication volume and worker idle time during
    pipeline flushes, heuristic pipeline parallelism proves effective in practice
    with trillion-scale LLMs on more than 3,000 GPU. In contrast to layer-slicing
    parallelism, multiple-layer-slicing pipeline parallelism only communicates end-of-layer
    activations and gradients, which can be 300$times$ smaller in the communication
    volume in a 2.2-billion-parameter example (Athlur et al., [2022](#bib.bib8)).
    It is a common practice to use what is known as 3D parallelism (Smith et al.,
    [2022](#bib.bib102); Zeng et al., [2023](#bib.bib142)) for LLM training, which
    combines data, pipeline, and layer-slicing parallelisms, to maximize the training
    throughput.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 对于 LLM 训练，管道并行性有多重要？管道并行性对 LLM 训练至关重要。正如 (Narayanan 等人，[2021](#bib.bib82))
    所示，通过减少通信量和管道冲刷期间工人空闲时间的影响，启发式管道并行性在实际应用中证明了在超过 3,000 个 GPU 上处理万亿规模的 LLM 时的有效性。与层切分并行性相比，多层切分管道并行性仅通信层末激活值和梯度，在一个
    22 亿参数的示例中，这些可以比通信量小 300$倍$ (Athlur 等人，[2022](#bib.bib8))。在 LLM 训练中，结合数据、管道和层切分并行性的
    3D 并行性 (Smith 等人，[2022](#bib.bib102)；Zeng 等人，[2023](#bib.bib142)) 是一种常见做法，以最大化训练吞吐量。
- en: $\bullet$ How crucial is fault-tolerant scheduling for LLM training? Given the
    involvement of a large number of workers in prolonged training sessions for LLMs,
    ensuring fault-tolerance is of utmost importance for resilient scheduling. Frequent
    failure in devices or networks can potentially block the training process, degrade
    the convergence performance, and necessitate redundant restarting of failed tasks
    and pipelines. SWARM parallelism (Ryabinin et al., [2023](#bib.bib93)) incorporates
    the dynamic membership of unstable workers into account for fault-tolerant pipeline
    scheduling. This dynamic fault-tolerant pipeline scheduling allows rerouting a
    task from a disconnected worker to other workers and ensures continuous task execution
    in case of worker failure in the pipeline. According to Oobleck (Jang et al.,
    [2023](#bib.bib50)), a failed pipeline can be recovered by using pipeline replicas
    and templates swiftly. We can instantiate some logically equivalent pipeline replicas,
    which possess replicated model states. Additionally, we define pipeline templates,
    which include information about the number of workers and stages in the pipeline,
    as well as the mapping of stages to GPUs. Once a pipeline failure occurs, a new
    pipeline can be restored based on the pipeline template and replicas instantly.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 容错调度对于大规模语言模型（LLM）训练的重要性如何？鉴于LLM训练过程中涉及大量工作者且训练时间较长，确保容错性对于弹性调度至关重要。设备或网络的频繁故障可能会阻碍训练过程，降低收敛性能，并且需要重复重启失败的任务和管道。SWARM
    并行化（Ryabinin et al., [2023](#bib.bib93)）在容错管道调度中考虑了不稳定工作者的动态成员资格。这种动态容错管道调度允许将任务从断开的工作者重新路由到其他工作者，并在管道中工作者失败的情况下确保任务持续执行。根据
    Oobleck（Jang et al., [2023](#bib.bib50)）的研究，使用管道副本和模板可以迅速恢复失败的管道。我们可以实例化一些逻辑等价的管道副本，这些副本拥有复制的模型状态。此外，我们定义了管道模板，其中包含有关工作者数量和管道阶段的信息，以及阶段到
    GPU 的映射。一旦发生管道失败，可以基于管道模板和副本即时恢复新的管道。
- en: 6\. Conclusion and Outlook
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 结论与展望
- en: 6.1\. Conclusion
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1\. 结论
- en: With the explosive increase in the volume of data, models, and resources, efficient
    framework strategies, including resource allocation and workload scheduling, are
    crucial for distributed DL. This survey systematically investigates up-to-date
    efficient resource allocation and workload scheduling framework strategies for
    large-scale distributed DL. The discussion covers topics focusing on various resource
    types, scheduling granularity levels, and performance goals during the training
    and inference processes of distributed DL. We highlight the critical challenges
    for each topic and introduce the corresponding solutions. To illustrate the practical
    application of these framework strategies in real scenarios, we use a case study
    on distributed LLM training, typically with tens of billions of parameters on
    hundreds of GPUs.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据、模型和资源的爆炸性增长，高效的框架策略，包括资源分配和工作负载调度，对于分布式深度学习（DL）至关重要。本调查系统地研究了大规模分布式深度学习的最新高效资源分配和工作负载调度框架策略。讨论涵盖了关注各种资源类型、调度粒度级别和分布式深度学习训练与推理过程中的性能目标的话题。我们突出每个话题中的关键挑战，并介绍相应的解决方案。为了说明这些框架策略在实际场景中的应用，我们使用了一个关于分布式
    LLM 训练的案例研究，该研究通常涉及数十亿个参数和数百个 GPU。
- en: 6.2\. Outlook
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2\. 展望
- en: With the emergence of LLMs trained on ultra-large datasets, an increasing number
    of ultra-large GPU data centers are in use or on construction schedule. Distributed
    DL framework strategies targeting large-scale settings with ultra-large data,
    models, and clusters are deemed a future research trend in this domain. Compared
    to traditional distributed DL, large-scale distributed DL has new characteristics
    and poses new challenges for resource allocation and workload scheduling. We discuss
    these characteristics and challenges pertaining to the large scale as a hint of
    future research directions.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 随着在超大数据集上训练的 LLM 的出现，越来越多的超大 GPU 数据中心正在使用或建设中。针对大规模数据、模型和集群的分布式深度学习框架策略被认为是该领域未来的研究趋势。与传统的分布式深度学习相比，大规模分布式深度学习具有新的特征，并对资源分配和工作负载调度提出了新的挑战。我们讨论了这些与大规模相关的特征和挑战，并作为未来研究方向的提示。
- en: 6.2.1\. Multi-data center collaborative learning
  id: totrans-283
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1\. 多数据中心协作学习
- en: Many large technology corporations and research organizations are constructing
    computational power networks consisting of multiple geographically distributed
    GPU data centers. Promoting new computing paradigms for contemporary large-scale
    distributed DL, the computational power network enables the sharing and coordination
    of ultra-large computational resources across multiple data centers for large
    workloads. However, compared to distributed DL within a single data center, the
    computational power network case presents various resource allocation and workload
    scheduling challenges, including higher resource heterogeneity, higher communication
    overhead, and tighter requirements for fault tolerance and data security. Overcoming
    these challenges requires scalable algorithms that work efficiently in large-scale
    environments with various constraints.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 许多大型科技公司和研究机构正在构建由多个地理分布的GPU数据中心组成的计算力网络。推动现代大规模分布式深度学习的新计算范式，计算力网络使得跨多个数据中心共享和协调超大计算资源成为可能，从而应对大规模工作负载。然而，与单一数据中心内的分布式深度学习相比，计算力网络案例面临各种资源分配和工作负载调度挑战，包括更高的资源异质性、更高的通信开销以及更严格的容错和数据安全要求。克服这些挑战需要在具有各种约束的大规模环境中高效运行的可扩展算法。
- en: 6.2.2\. Resource and workload heterogeneity
  id: totrans-285
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.2\. 资源和工作负载异质性
- en: With the frequent upgrades of hardware devices for distributed DL, data centers
    commonly have heterogeneous computational and communication resources with various
    capacities in storage, computation speed, network bandwidth and latency, and energy
    and pricing costs. Distributed DL workloads also exhibit heterogeneity in various
    aspects, such as dataset distribution, model complexity, distributed training
    parallelism modes, model synchronization mechanisms, and training dynamics. A
    promising research direction is dynamic resource allocation to adjust resources
    based on resource availability across heterogeneous environments. Another is adaptive
    workload scheduling, which matches the dynamic nature of changing workloads during
    prolonged training and inference processes to continually optimize performance.
    Solving these scheduling problems with resource and workload heterogeneity also
    requires efficient optimization methods, such as DRL.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 随着分布式深度学习硬件设备的频繁升级，数据中心通常具有不同存储、计算速度、网络带宽和延迟以及能源和价格成本的异质计算和通信资源。分布式深度学习工作负载在数据集分布、模型复杂性、分布式训练并行模式、模型同步机制和训练动态等各个方面也表现出异质性。一个有前景的研究方向是动态资源分配，根据异质环境中的资源可用性调整资源。另一个方向是自适应工作负载调度，将动态变化的工作负载在长期训练和推理过程中与性能优化相匹配。解决这些涉及资源和工作负载异质性的调度问题还需要高效的优化方法，如DRL。
- en: 6.2.3\. Pipeline execution for large-model training
  id: totrans-287
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.3\. 大模型训练的流水线执行
- en: Pipelining has been applied to overlap various computational and communication
    workloads in large-model training. However, the optimization of pipeline execution
    for various training parallelism modes of large models has yet to be sufficiently
    explored. An example is related to adaptive pipeline scheduling. During the long-term
    execution of large-model training with dynamic workloads, the pipeline execution
    plan that initially balanced workloads can lead to significant workload skew among
    the workers. Fine-grained adaptive pipeline scheduling that dynamically adjusts
    the granularity of pipeline stages and rebalancing workloads can reduce pipeline
    stall throughout the training process. Another example is related to hierarchical
    pipeline scheduling. To isolate the negative influence of the pipeline stall,
    the global and multi-level local workload schedulers can use multiple pipelines
    hierarchically within a computing node, within a rack, within a data center, and
    across data centers.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线技术已被应用于重叠大模型训练中的各种计算和通信工作负载。然而，针对大模型各种训练并行模式的流水线执行优化尚未得到充分探索。一个例子是与自适应流水线调度有关。在动态工作负载下长期执行的大模型训练中，最初平衡负载的流水线执行计划可能会导致工作负载在工人之间显著不均。精细化的自适应流水线调度，通过动态调整流水线阶段的粒度和重新平衡工作负载，可以减少整个训练过程中的流水线停滞。另一个例子是与分层流水线调度有关。为了隔离流水线停滞的负面影响，全球和多级本地工作负载调度器可以在计算节点、机架、数据中心以及跨数据中心的多个流水线中分层使用。
- en: 6.2.4\. Resilient distributed DL
  id: totrans-289
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.4\. 弹性分布式深度学习
- en: Failure in devices and tasks are always in company with distributed frameworks,
    and its influence is non-negligible in large-scale environments. Resilient distributed
    DL framework strategies that can tolerate various failures become important for
    large-scale resource allocation and workload scheduling. When optimizing distributed
    DL framework strategies, the solution should consider GPU failures, network disruptions,
    and storage issues that can interrupt the distributed DL process and decay performance.
    Resource allocation strategies could proactively allocate redundant resources
    based on device failure considerations to tolerate failures. Workload scheduling
    strategies could replicate datasets and tasks to tolerate task failures or conduct
    checkpoints to reduce recovery overhead.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 设备和任务的故障总是与分布式框架相伴随，并且在大规模环境中其影响不可忽视。能够容忍各种故障的弹性分布式深度学习框架策略对大规模资源分配和工作负载调度变得至关重要。在优化分布式深度学习框架策略时，解决方案应考虑GPU故障、网络中断和存储问题，这些问题可能会中断分布式深度学习过程并降低性能。资源分配策略可以基于设备故障考虑主动分配冗余资源以容忍故障。工作负载调度策略可以复制数据集和任务以容忍任务故障，或进行检查点操作以减少恢复开销。
- en: 6.2.5\. Orchestration with distributed DL algorithms
  id: totrans-291
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.5. 与分布式深度学习算法的协调
- en: By being aware of the mechanisms of distributed DL algorithms, distributed DL
    framework strategies can be optimized for and orchestrated with them. For example,
    the workload scheduler can accurately estimate the communication overhead and
    effectively optimize the scheduling solution by orchestrating lossless or lossy
    compression technologies for gradient compression and model synchronization mechanisms
    for data-parallel training and federating learning. The resource allocator can
    promptly and dynamically adjust corresponding resources for distributed DL workloads
    by being aware of the adaptive policies of distributed DL algorithms. Distributed
    DL algorithms can also be jointly optimized with distributed DL framework strategies
    for their best configurations and adaptive policies.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 通过了解分布式深度学习算法的机制，分布式深度学习框架策略可以针对这些机制进行优化和协调。例如，工作负载调度器可以准确估计通信开销，并通过协调无损或有损压缩技术用于梯度压缩和数据并行训练及联邦学习的模型同步机制来有效优化调度方案。资源分配器可以通过了解分布式深度学习算法的自适应策略来及时动态调整对应资源。分布式深度学习算法还可以与分布式深度学习框架策略共同优化，以实现最佳配置和自适应策略。
- en: 6.2.6\. Orchestration with distributed DL infrastructures
  id: totrans-293
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.6. 与分布式深度学习基础设施的协调
- en: Modern distributed DL infrastructures usually apply virtualization technologies
    and programmable network devices to extend resource capacities. On the one hand,
    virtualization technologies change resource capacities and pricing costs of computational
    and communication devices. On the other hand, programmable network devices, such
    as programmable switches, extend the capability of network devices by integrating
    limited computational power. They often work to optimize distributed DL-aware
    network traffic, such as in-network aggregation for distributed gradients. These
    infrastructure technologies allow framework strategies to be optimized for various
    performance goals other than throughput, such as cost efficiency, performance
    isolation, and network congestion. Resource allocation strategies can leverage
    virtualization technologies to extend the allocation capability elastically, and
    workload scheduling strategies should consider virtualization performance and
    in-network aggregation when determining an optimal scheduling solution.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 现代分布式深度学习基础设施通常应用虚拟化技术和可编程网络设备来扩展资源容量。一方面，虚拟化技术改变了计算和通信设备的资源容量和定价成本。另一方面，可编程网络设备，如可编程交换机，通过集成有限的计算能力扩展了网络设备的功能。它们通常用于优化分布式深度学习感知的网络流量，例如分布式梯度的网络内聚合。这些基础设施技术使得框架策略可以针对吞吐量以外的各种性能目标进行优化，如成本效率、性能隔离和网络拥塞。资源分配策略可以利用虚拟化技术弹性地扩展分配能力，而工作负载调度策略在确定最佳调度方案时应考虑虚拟化性能和网络内聚合。
- en: References
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: cud (2024a) 2024a. *CUDA*. [https://developer.nvidia.com/cuda-zone](https://developer.nvidia.com/cuda-zone)
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: cud (2024a) 2024a. *CUDA*. [https://developer.nvidia.com/cuda-zone](https://developer.nvidia.com/cuda-zone)
- en: Nvi (2024a) 2024a. NVIDIA multi-instance GPU. [https://www.nvidia.com/en-us/technologies/multi-instance-gpu/](https://www.nvidia.com/en-us/technologies/multi-instance-gpu/)
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nvi (2024a) 2024a. NVIDIA 多实例 GPU。 [https://www.nvidia.com/en-us/technologies/multi-instance-gpu/](https://www.nvidia.com/en-us/technologies/multi-instance-gpu/)
- en: Nvi (2024b) 2024b. NVIDIA Multi-process service. [https://docs.nvidia.com/deploy/pdf/CUDA_Multi_Process_Service_Overview.pdf](https://docs.nvidia.com/deploy/pdf/CUDA_Multi_Process_Service_Overview.pdf)
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nvi (2024b) 2024b. NVIDIA 多进程服务。 [https://docs.nvidia.com/deploy/pdf/CUDA_Multi_Process_Service_Overview.pdf](https://docs.nvidia.com/deploy/pdf/CUDA_Multi_Process_Service_Overview.pdf)
- en: cud (2024b) 2024b. Unified Memory for CUDA. [https://developer.nvidia.com/blog/unified-memory-cuda-beginners/](https://developer.nvidia.com/blog/unified-memory-cuda-beginners/)
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: cud (2024b) 2024b. CUDA 的统一内存。 [https://developer.nvidia.com/blog/unified-memory-cuda-beginners/](https://developer.nvidia.com/blog/unified-memory-cuda-beginners/)
- en: Al-Garadi et al. (2020) Mohammed Ali Al-Garadi, Amr Mohamed, Abdulla Khalid
    Al-Ali, Xiaojiang Du, Ihsan Ali, and Mohsen Guizani. 2020. A Survey of Machine
    and Deep Learning Methods for Internet of Things (IoT) Security. *IEEE Communications
    Surveys & Tutorials* 22, 3 (2020), 1646–1685.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Al-Garadi et al. (2020) Mohammed Ali Al-Garadi, Amr Mohamed, Abdulla Khalid
    Al-Ali, Xiaojiang Du, Ihsan Ali, 和 Mohsen Guizani. 2020. 物联网 (IoT) 安全的机器学习和深度学习方法调查。*IEEE
    通信调查与教程* 22, 3 (2020), 1646–1685。
- en: Amerini et al. (2019) Irene Amerini, Chang-Tsun Li, and Roberto Caldelli. 2019.
    Social network identification through image classification with CNN. *IEEE access*
    7 (2019), 35264–35273.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amerini et al. (2019) Irene Amerini, Chang-Tsun Li, 和 Roberto Caldelli. 2019.
    通过 CNN 图像分类的社交网络识别。*IEEE Access* 7 (2019), 35264–35273。
- en: 'Athlur et al. (2022) Sanjith Athlur, Nitika Saran, Muthian Sivathanu, Ramachandran
    Ramjee, and Nipun Kwatra. 2022. Varuna: Scalable, Low-Cost Training of Massive
    Deep Learning Models. In *Proceedings of the Seventeenth European Conference on
    Computer Systems* (Rennes, France). New York, NY, USA, 472–487.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Athlur et al. (2022) Sanjith Athlur, Nitika Saran, Muthian Sivathanu, Ramachandran
    Ramjee, 和 Nipun Kwatra. 2022. Varuna: 可扩展、低成本的大规模深度学习模型训练。*第十七届欧洲计算机系统会议论文集* (法国雷恩)。纽约，NY，美国，472–487。'
- en: 'Baccour et al. (2022) Emna Baccour, Naram Mhaisen, Alaa Awad Abdellatif, Aiman
    Erbad, Amr Mohamed, Mounir Hamdi, and Mohsen Guizani. 2022. Pervasive AI for IoT
    Applications: A Survey on Resource-Efficient Distributed Artificial Intelligence.
    *IEEE Communications Surveys & Tutorials* 24, 4 (2022), 2366–2418.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baccour et al. (2022) Emna Baccour, Naram Mhaisen, Alaa Awad Abdellatif, Aiman
    Erbad, Amr Mohamed, Mounir Hamdi, 和 Mohsen Guizani. 2022. 用于物联网应用的普适人工智能：关于资源高效分布式人工智能的调查。*IEEE
    通信调查与教程* 24, 4 (2022), 2366–2418。
- en: Bahdanau et al. (2015) Dzmitry Bahdanau, Kyung Hyun Cho, and Yoshua Bengio.
    2015. Neural machine translation by jointly learning to align and translate. In
    *3rd International Conference on Learning Representations, ICLR 2015*.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bahdanau et al. (2015) Dzmitry Bahdanau, Kyung Hyun Cho, 和 Yoshua Bengio. 2015.
    通过联合学习对齐和翻译的神经机器翻译。*第三届国际学习表征会议, ICLR 2015*。
- en: 'Bai et al. (2020) Zhihao Bai, Zhen Zhang, Yibo Zhu, and Xin Jin. 2020. PipeSwitch:
    Fast pipelined context switching for deep learning applications. In *14th USENIX
    Symposium on Operating Systems Design and Implementation (OSDI 20)*. 499–514.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bai et al. (2020) Zhihao Bai, Zhen Zhang, Yibo Zhu, 和 Xin Jin. 2020. PipeSwitch:
    深度学习应用中的快速流水线上下文切换。*第十四届 USENIX 操作系统设计与实现研讨会 (OSDI 20)*。499–514。'
- en: Bao et al. (2019) Yixin Bao, Yanghua Peng, and Chuan Wu. 2019. Deep Learning-based
    Job Placement in Distributed Machine Learning Clusters. In *IEEE INFOCOM 2019
    - IEEE Conference on Computer Communications*. 505–513.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bao et al. (2019) Yixin Bao, Yanghua Peng, 和 Chuan Wu. 2019. 基于深度学习的分布式机器学习集群中的作业分配。*IEEE
    INFOCOM 2019 - IEEE 计算机通信会议*。505–513。
- en: Bi et al. (2022) Renwan Bi, Jinbo Xiong, Youliang Tian, Qi Li, and Kim-Kwang Raymond
    Choo. 2022. Achieving lightweight and privacy-preserving object detection for
    connected autonomous vehicles. *IEEE Internet of Things Journal* 10, 3 (2022),
    2314–2329.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bi et al. (2022) Renwan Bi, Jinbo Xiong, Youliang Tian, Qi Li, 和 Kim-Kwang Raymond
    Choo. 2022. 实现轻量级和隐私保护的连接自动驾驶车辆目标检测。*IEEE 物联网期刊* 10, 3 (2022), 2314–2329。
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems* 33 (2020), 1877–1901.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, 等等。2020. 语言模型是少样本学习者。*神经信息处理系统进展* 33 (2020), 1877–1901。
- en: 'Cao et al. (2023) Xuanyu Cao, Tamer Başar, Suhas Diggavi, Yonina C Eldar, Khaled B
    Letaief, H Vincent Poor, and Junshan Zhang. 2023. Communication-efficient distributed
    learning: An overview. *IEEE journal on selected areas in communications* (2023).'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等人（2023）Xuanyu Cao, Tamer Başar, Suhas Diggavi, Yonina C Eldar, Khaled B
    Letaief, H Vincent Poor 和 Junshan Zhang。2023年。通信高效的分布式学习：概述。*IEEE通信领域选定期刊*（2023）。
- en: 'Chen et al. (2023) Chen Chen, Sen Wang, Yingwen Chen, and Jianchen Han. 2023.
    Tereis: A Package-Based Scheduling in Deep Learning Systems. In *2022 IEEE 28th
    International Conference on Parallel and Distributed Systems (ICPADS)*. IEEE,
    867–874.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人（2023）Chen Chen, Sen Wang, Yingwen Chen 和 Jianchen Han。2023年。Tereis：深度学习系统中的包基调度。发表于*2022
    IEEE第28届国际并行与分布式系统会议（ICPADS）*。IEEE，867–874。
- en: Chen et al. (2021) Mingzhe Chen, Nir Shlezinger, H Vincent Poor, Yonina C Eldar,
    and Shuguang Cui. 2021. Communication-efficient federated learning. *Proceedings
    of the National Academy of Sciences* 118, 17 (2021), e2024789118.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人（2021）Mingzhe Chen, Nir Shlezinger, H Vinay Poor, Yonina C Eldar 和 Shuguang
    Cui。2021年。通信高效的联邦学习。*美国国家科学院院刊* 118, 17（2021），e2024789118。
- en: 'Chen et al. (2020) Zhaoyun Chen, Wei Quan, Mei Wen, Jianbin Fang, Jie Yu, Chunyuan
    Zhang, and Lei Luo. 2020. Deep Learning Research and Development Platform: Characterizing
    and Scheduling with QoS Guarantees on GPU Clusters. *IEEE Transactions on Parallel
    and Distributed Systems* 31, 1 (2020), 34–50.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人（2020）Zhaoyun Chen, Wei Quan, Mei Wen, Jianbin Fang, Jie Yu, Chunyuan
    Zhang 和 Lei Luo。2020年。深度学习研究与开发平台：在GPU集群上进行特性化和调度，并保证QoS。*IEEE并行与分布式系统汇刊* 31,
    1（2020），34–50。
- en: Cheng et al. (2023) Runxiang Cheng, Chris Cai, Selman Yilmaz, Rahul Mitra, Malay
    Bag, Mrinmoy Ghosh, and Tianyin Xu. 2023. Towards GPU Memory Efficiency for Distributed
    Training at Scale. In *Proceedings of the 2023 ACM Symposium on Cloud Computing*.
    281–297.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 等人（2023）Runxiang Cheng, Chris Cai, Selman Yilmaz, Rahul Mitra, Malay Bag,
    Mrinmoy Ghosh 和 Tianyin Xu。2023年。面向大规模分布式训练的GPU内存效率。发表于*2023年ACM云计算研讨会论文集*。281–297。
- en: Cho et al. (2022) Junguk Cho, Diman Zad Tootaghaj, Lianjie Cao, and Puneet Sharma.
    2022. Sla-driven ml inference framework for clouds with heterogeneous accelerators.
    *Proceedings of Machine Learning and Systems* 4 (2022), 20–32.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cho 等人（2022）Junguk Cho, Diman Zad Tootaghaj, Lianjie Cao 和 Puneet Sharma。2022年。针对具有异构加速器的云环境的SLA驱动的机器学习推理框架。*机器学习与系统会议论文集*
    4（2022），20–32。
- en: Choi et al. (2022) Seungbeom Choi, Sunho Lee, Yeonjae Kim, Jongse Park, Youngjin
    Kwon, and Jaehyuk Huh. 2022. Serving heterogeneous machine learning models on
    Multi-GPU servers with Spatio-Temporal sharing. In *2022 USENIX Annual Technical
    Conference (USENIX ATC 22)*. 199–216.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Choi 等人（2022）Seungbeom Choi, Sunho Lee, Yeonjae Kim, Jongse Park, Youngjin Kwon
    和 Jaehyuk Huh。2022年。通过时空共享在多GPU服务器上服务异构机器学习模型。发表于*2022年USENIX年会技术会议（USENIX ATC
    22）*。199–216。
- en: Chowdhury and Stoica (2015) Mosharaf Chowdhury and Ion Stoica. 2015. Efficient
    coflow scheduling without prior knowledge. *ACM SIGCOMM Computer Communication
    Review* 45, 4 (2015), 393–406.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chowdhury 和 Stoica（2015）Mosharaf Chowdhury 和 Ion Stoica。2015年。无需先验知识的高效流调度。*ACM
    SIGCOMM计算机通信评论* 45, 4（2015），393–406。
- en: 'Dhakal et al. (2020) Aditya Dhakal, Sameer G Kulkarni, and KK Ramakrishnan.
    2020. Gslice: controlled spatial sharing of gpus for a scalable inference platform.
    In *Proceedings of the 11th ACM Symposium on Cloud Computing*. 492–506.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dhakal 等人（2020）Aditya Dhakal, Sameer G Kulkarni 和 KK Ramakrishnan。2020年。Gslice：受控的GPU空间共享用于可扩展的推理平台。发表于*第11届ACM云计算研讨会论文集*。492–506。
- en: 'Dosovitskiy et al. (2020) Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
    Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias
    Minderer, Georg Heigold, Sylvain Gelly, et al. 2020. An Image is Worth 16x16 Words:
    Transformers for Image Recognition at Scale. In *International Conference on Learning
    Representations*.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dosovitskiy 等人（2020）Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk
    Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer,
    Georg Heigold, Sylvain Gelly 等。2020年。一张图像胜过16x16个词：用于大规模图像识别的变换器。发表于*国际学习表征会议*。
- en: Duan et al. (2023) Qingyang Duan, Chao Peng, Zeqin Wang, Yuedong Xu, Shaoteng
    Liu, Jun Wu, and John CS Lui. 2023. Accelerating Distributed DNN Training via
    Transport Layer Scheduling. *IEEE Transactions on Parallel and Distributed Systems*
    34, 5 (2023), 1650–1666.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Duan 等人（2023）Qingyang Duan, Chao Peng, Zeqin Wang, Yuedong Xu, Shaoteng Liu,
    Jun Wu 和 John CS Lui。2023年。通过传输层调度加速分布式DNN训练。*IEEE并行与分布式系统汇刊* 34, 5（2023），1650–1666。
- en: Duchi et al. (2011) John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive
    subgradient methods for online learning and stochastic optimization. *Journal
    of machine learning research* 12, 7 (2011).
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Duchi 等（2011）**John Duchi**、**Elad Hazan** 和 **Yoram Singer**。2011年。《在线学习和随机优化的自适应子梯度方法》。*Journal
    of machine learning research* 12，7（2011）。
- en: 'et al. (2023) Aakanksha Chowdhery et al. 2023. PaLM: Scaling Language Modeling
    with Pathways. *Journal of Machine Learning Research* 24, 240 (2023), 1–113.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: et al.（2023）**Aakanksha Chowdhery** 等人。2023年。《PaLM：通过路径扩展语言建模》。*Journal of Machine
    Learning Research* 24，240（2023），1–113。
- en: 'Feng et al. (2020) Qi Feng, Debiao He, Zhe Liu, Huaqun Wang, and Kim-Kwang Raymond
    Choo. 2020. SecureNLP: A system for multi-party privacy-preserving natural language
    processing. *IEEE Transactions on Information Forensics and Security* 15 (2020),
    3709–3721.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feng 等（2020）**Qi Feng**、**Debiao He**、**Zhe Liu**、**Huaqun Wang** 和 **Kim-Kwang
    Raymond Choo**。2020年。《SecureNLP：一个多方隐私保护自然语言处理系统》。*IEEE Transactions on Information
    Forensics and Security* 15（2020），3709–3721。
- en: 'Ferikoglou et al. (2023) Aggelos Ferikoglou, Panos Chrysomeris, Achilleas Tzenetopoulos,
    Manolis Katsaragakis, Dimosthenis Masouros, and Dimitrios Soudris. 2023. IRIS:
    Interference and Resource Aware Predictive Orchestration for ML Inference Serving.
    In *2023 IEEE 16th International Conference on Cloud Computing (CLOUD)*. IEEE,
    1–12.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ferikoglou 等（2023）**Aggelos Ferikoglou**、**Panos Chrysomeris**、**Achilleas Tzenetopoulos**、**Manolis
    Katsaragakis**、**Dimosthenis Masouros** 和 **Dimitrios Soudris**。2023年。《IRIS：干扰和资源感知的机器学习推理服务预测调度》。在
    *2023 IEEE 16th International Conference on Cloud Computing (CLOUD)* 上。IEEE，1–12。
- en: 'Ferrand et al. (2020) Paul Ferrand, Alexis Decurninge, and Maxime Guillaud.
    2020. DNN-based localization from channel estimates: Feature design and experimental
    results. In *GLOBECOM 2020-2020 IEEE Global Communications Conference*. IEEE,
    1–6.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ferrand 等（2020）**Paul Ferrand**、**Alexis Decurninge** 和 **Maxime Guillaud**。2020年。《基于
    DNN 的信道估计定位：特征设计和实验结果》。在 *GLOBECOM 2020-2020 IEEE Global Communications Conference*
    上。IEEE，1–6。
- en: Filippini et al. (2023) Federica Filippini, Jonatha Anselmi, Danilo Ardagna,
    and Bruno Gaujal. 2023. A Stochastic Approach for Scheduling AI Training Jobs
    in GPU-based Systems. *IEEE Transactions on Cloud Computing* (2023), 1–17.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Filippini 等（2023）**Federica Filippini**、**Jonatha Anselmi**、**Danilo Ardagna**
    和 **Bruno Gaujal**。2023年。《基于随机的方法调度 GPU 系统中的 AI 训练任务》。*IEEE Transactions on Cloud
    Computing*（2023），1–17。
- en: 'Gao et al. (2022) Wei Gao, Peng Sun, Yonggang Wen, and Tianwei Zhang. 2022.
    Titan: a scheduler for foundation model fine-tuning workloads. In *Proceedings
    of the 13th Symposium on Cloud Computing*. 348–354.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等（2022）**Wei Gao**、**Peng Sun**、**Yonggang Wen** 和 **Tianwei Zhang**。2022年。《Titan：一种用于基础模型微调任务的调度器》。在
    *Proceedings of the 13th Symposium on Cloud Computing* 上。348–354。
- en: 'Gao et al. (2021) Wei Gao, Zhisheng Ye, Peng Sun, Yonggang Wen, and Tianwei
    Zhang. 2021. Chronus: A novel deadline-aware scheduler for deep learning training
    jobs. In *Proceedings of the ACM Symposium on Cloud Computing*. 609–623.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等（2021）**Wei Gao**、**Zhisheng Ye**、**Peng Sun**、**Yonggang Wen** 和 **Tianwei
    Zhang**。2021年。《Chronus：一种新型的关注截止时间的深度学习训练任务调度器》。在 *Proceedings of the ACM Symposium
    on Cloud Computing* 上。609–623。
- en: 'Gao et al. (2024a) Wei Gao, Zhisheng Ye, Peng Sun, Tianwei Zhang, and Yonggang
    Wen. 2024a. UniSched: A Unified Scheduler for Deep Learning Training Jobs With
    Different User Demands. *IEEE Trans. Comput.* 73, 6 (2024), 1500–1515.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等（2024a）**Wei Gao**、**Zhisheng Ye**、**Peng Sun**、**Tianwei Zhang** 和 **Yonggang
    Wen**。2024a。《UniSched：一种统一的深度学习训练任务调度器，满足不同用户需求》。*IEEE Trans. Comput.* 73，6（2024），1500–1515。
- en: 'Gao et al. (2024b) Wei Gao, Xu Zhang, Shan Huang, Shangwei Guo, Peng Sun, Yonggang
    Wen, and Tianwei Zhang. 2024b. AutoSched: An Adaptive Self-configured Framework
    for Scheduling Deep Learning Training Workloads. In *ACM International Conference
    on Supercomputing (ICS)*. 1–12.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等（2024b）**Wei Gao**、**Xu Zhang**、**Shan Huang**、**Shangwei Guo**、**Peng
    Sun**、**Yonggang Wen** 和 **Tianwei Zhang**。2024b。《AutoSched：一种自适应自配置的深度学习训练负载调度框架》。在
    *ACM International Conference on Supercomputing (ICS)* 上。1–12。
- en: 'Gomez et al. (2022) Aidan N. Gomez, Oscar Key, Kuba Perlin, Stephen Gou, Nick
    Frosst, Jeff Dean, and Yarin Gal. 2022. Interlocking Backpropagation: Improving
    Depthwise Model-Parallelism. *J. Mach. Learn. Res.* 23, 1 (jan 2022), 1–28.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gomez 等（2022）**Aidan N. Gomez**、**Oscar Key**、**Kuba Perlin**、**Stephen Gou**、**Nick
    Frosst**、**Jeff Dean** 和 **Yarin Gal**。2022年。《互锁反向传播：改善深度模型并行性》。*J. Mach. Learn.
    Res.* 23，1（2022年1月），1–28。
- en: 'Gu et al. (2019) Juncheng Gu, Mosharaf Chowdhury, KangG. Shin, Yibo Zhu, Myeongjae
    Jeon, Junjie Qian, HongqiangHarry Liu, and Chuanxiong Guo. 2019. Tiresias: A GPU
    Cluster Manager for Distributed Deep Learning. *Networked Systems Design and Implementation,Networked
    Systems Design and Implementation* (Jan 2019), 485–500.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu 等（2019）**Juncheng Gu**、**Mosharaf Chowdhury**、**KangG. Shin**、**Yibo Zhu**、**Myeongjae
    Jeon**、**Junjie Qian**、**HongqiangHarry Liu** 和 **Chuanxiong Guo**。2019年。《Tiresias：用于分布式深度学习的
    GPU 集群管理器》。*Networked Systems Design and Implementation, Networked Systems Design
    and Implementation*（2019年1月），485–500。
- en: 'Gu et al. (2023) Jianfeng Gu, Yichao Zhu, Puxuan Wang, Mohak Chadha, and Michael
    Gerndt. 2023. FaST-GShare: Enabling efficient spatio-temporal GPU sharing in serverless
    computing for deep learning inference. In *Proceedings of the 52nd International
    Conference on Parallel Processing*. 635–644.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gu 等（2023）Jianfeng Gu, Yichao Zhu, Puxuan Wang, Mohak Chadha 和 Michael Gerndt。2023年。《FaST-GShare:
    实现深度学习推理中无服务器计算的高效时空GPU共享》。发表于 *第52届国际并行处理会议论文集*。635–644页。'
- en: 'Gu et al. (2022) Rong Gu, Yuquan Chen, Shuai Liu, Haipeng Dai, Guihai Chen,
    Kai Zhang, Yang Che, and Yihua Huang. 2022. Liquid: Intelligent resource estimation
    and network-efficient scheduling for deep learning jobs on distributed gpu clusters.
    *IEEE Transactions on Parallel and Distributed Systems* 33, 11 (2022), 2808–2820.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gu 等（2022）Rong Gu, Yuquan Chen, Shuai Liu, Haipeng Dai, Guihai Chen, Kai Zhang,
    Yang Che 和 Yihua Huang。2022年。《Liquid: 深度学习作业在分布式GPU集群上的智能资源估算与网络高效调度》。*IEEE并行与分布式系统汇刊*
    33卷，第11期（2022年），2808–2820页。'
- en: 'Gunasekaran et al. (2022) Jashwant Raj Gunasekaran, Cyan Subhra Mishra, Prashanth
    Thinakaran, Bikash Sharma, Mahmut Taylan Kandemir, and Chita R Das. 2022. Cocktail:
    A multidimensional optimization for model serving in cloud. In *19th USENIX Symposium
    on Networked Systems Design and Implementation (NSDI 22)*. 1041–1057.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gunasekaran 等（2022）Jashwant Raj Gunasekaran, Cyan Subhra Mishra, Prashanth
    Thinakaran, Bikash Sharma, Mahmut Taylan Kandemir 和 Chita R Das。2022年。《Cocktail:
    一种用于云端模型服务的多维优化》。发表于 *第19届USENIX网络系统设计与实现研讨会（NSDI 22）*。1041–1057页。'
- en: Haldurai et al. (2016) Lingaraj Haldurai, T Madhubala, and R Rajalakshmi. 2016.
    A study on genetic algorithm and its applications. *International Journal of computer
    sciences and Engineering* 4, 10 (2016), 139.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haldurai 等（2016）Lingaraj Haldurai, T Madhubala 和 R Rajalakshmi。2016年。《遗传算法及其应用研究》。*国际计算机科学与工程期刊*
    4卷，第10期（2016年），139页。
- en: 'He et al. (2021) Yihong He, Weibo Cai, Pan Zhou, Gang Sun, Shouxi Luo, Hongfang
    Yu, and Mohsen Guizani. 2021. Beamer: Stage-aware coflow scheduling to accelerate
    hyper-parameter tuning in deep learning clusters. *IEEE Transactions on Network
    and Service Management* 19, 2 (2021), 1083–1097.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'He 等（2021）Yihong He, Weibo Cai, Pan Zhou, Gang Sun, Shouxi Luo, Hongfang Yu
    和 Mohsen Guizani。2021年。《Beamer: 阶段感知的协流调度以加速深度学习集群中的超参数调整》。*IEEE网络与服务管理汇刊* 19卷，第2期（2021年），1083–1097页。'
- en: Hu et al. (2021) Qinghao Hu, Peng Sun, Shengen Yan, Yonggang Wen, and Tianwei
    Zhang. 2021. Characterization and prediction of deep learning workloads in large-scale
    gpu datacenters. In *Proceedings of the International Conference for High Performance
    Computing, Networking, Storage and Analysis*. 1–15.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等（2021）Qinghao Hu, Peng Sun, Shengen Yan, Yonggang Wen 和 Tianwei Zhang。2021年。《大规模GPU数据中心中深度学习工作负载的特征与预测》。发表于
    *国际高性能计算、网络、存储与分析会议论文集*。1–15页。
- en: 'Hu et al. (2023) Qinghao Hu, Zhisheng Ye, Meng Zhang, Qiaoling Chen, Peng Sun,
    Yonggang Wen, and Tianwei Zhang. 2023. Hydro: Surrogate-Based Hyperparameter Tuning
    Service in Datacenters. In *17th USENIX Symposium on Operating Systems Design
    and Implementation (OSDI 23)*. 757–777.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hu 等（2023）Qinghao Hu, Zhisheng Ye, Meng Zhang, Qiaoling Chen, Peng Sun, Yonggang
    Wen 和 Tianwei Zhang。2023年。《Hydro: 数据中心中的基于代理的超参数调整服务》。发表于 *第17届USENIX操作系统设计与实现研讨会（OSDI
    23）*。757–777页。'
- en: Hua et al. (2019) Yuxiu Hua, Zhifeng Zhao, Rongpeng Li, Xianfu Chen, Zhiming
    Liu, and Honggang Zhang. 2019. Deep learning with long short-term memory for time
    series prediction. *IEEE Communications Magazine* 57, 6 (2019), 114–119.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hua 等（2019）Yuxiu Hua, Zhifeng Zhao, Rongpeng Li, Xianfu Chen, Zhiming Liu 和
    Honggang Zhang。2019年。《使用长短期记忆网络进行时间序列预测的深度学习》。*IEEE通信杂志* 57卷，第6期（2019年），114–119页。
- en: 'Huang et al. (2023) Allen H Huang, Hui Wang, and Yi Yang. 2023. FinBERT: A
    large language model for extracting information from financial text. *Contemporary
    Accounting Research* 40, 2 (2023), 806–841.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang 等（2023）Allen H Huang, Hui Wang 和 Yi Yang。2023年。《FinBERT: 一种用于从金融文本中提取信息的大型语言模型》。*当代会计研究*
    40卷，第2期（2023年），806–841页。'
- en: 'Huang et al. (2019) Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat,
    Dehao Chen, Mia Chen, HyoukJoong Lee, Jiquan Ngiam, Quoc V Le, Yonghui Wu, et al.
    2019. Gpipe: Efficient training of giant neural networks using pipeline parallelism.
    *Advances in neural information processing systems* 32 (2019).'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang 等（2019）Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Dehao
    Chen, Mia Chen, HyoukJoong Lee, Jiquan Ngiam, Quoc V Le, Yonghui Wu 等。2019年。《Gpipe:
    使用流水线并行化有效训练大型神经网络》。*神经信息处理系统进展* 32卷（2019年）。'
- en: Hwang et al. (2021) Changho Hwang, Taehyun Kim, Sunghyun Kim, Jinwoo Shin, and
    KyoungSoo Park. 2021. Elastic resource sharing for distributed deep learning.
    In *18th USENIX Symposium on Networked Systems Design and Implementation (NSDI
    21)*. 721–739.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hwang 等（2021）Changho Hwang, Taehyun Kim, Sunghyun Kim, Jinwoo Shin 和 KyoungSoo
    Park. 2021. 分布式深度学习的弹性资源共享。在 *第18届 USENIX 网络系统设计与实现研讨会（NSDI 21）* 上。721–739。
- en: Jahani et al. (2019) Arezoo Jahani, Marco Lattuada, Michele Ciavotta, Danilo
    Ardagna, Edoardo Amaldi, and Li Zhang. 2019. Optimizing on-demand GPUs in the
    Cloud for Deep Learning Applications Training. In *2019 4th International Conference
    on Computing, Communications and Security (ICCCS)*.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jahani 等（2019）Arezoo Jahani, Marco Lattuada, Michele Ciavotta, Danilo Ardagna,
    Edoardo Amaldi 和 Li Zhang. 2019. 优化云中的按需 GPU 以进行深度学习应用训练。在 *2019年第4届国际计算、通信与安全会议（ICCCS）*
    上。
- en: 'Jang et al. (2023) Insu Jang, Zhenning Yang, Zhen Zhang, Xin Jin, and Mosharaf
    Chowdhury. 2023. Oobleck: Resilient Distributed Training of Large Models Using
    Pipeline Templates. In *Proceedings of the 29th Symposium on Operating Systems
    Principles* (Koblenz, Germany). New York, NY, USA, 382–395.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jang 等（2023）Insu Jang, Zhenning Yang, Zhen Zhang, Xin Jin 和 Mosharaf Chowdhury.
    2023. Oobleck：使用管道模板进行大型模型的弹性分布式训练。在 *第29届操作系统原理研讨会*（德国科布伦茨）上。纽约，NY，USA，382–395。
- en: 'Jayaram et al. (2019) K. R. Jayaram, Vinod Muthusamy, Parijat Dube, Vatche
    Ishakian, Chen Wang, Benjamin Herta, Scott Boag, Diana Arroyo, Asser Tantawi,
    Archit Verma, Falk Pollok, and Rania Khalaf. 2019. FfDL: A Flexible Multi-tenant
    Deep Learning Platform. In *Proceedings of the 20th International Middleware Conference*.
    82–95.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jayaram 等（2019）K. R. Jayaram, Vinod Muthusamy, Parijat Dube, Vatche Ishakian,
    Chen Wang, Benjamin Herta, Scott Boag, Diana Arroyo, Asser Tantawi, Archit Verma,
    Falk Pollok 和 Rania Khalaf. 2019. FfDL：一个灵活的多租户深度学习平台。在 *第20届国际中间件会议论文集* 上。82–95。
- en: Jeon et al. (2019) Myeongjae Jeon, Shivaram Venkataraman, Amar Phanishayee,
    Junjie Qian, Wencong Xiao, and Fan Yang. 2019. Analysis of Large-ScaleMulti-TenantGPU
    clusters for DNN training workloads. In *2019 USENIX Annual Technical Conference
    (USENIX ATC 19)*. 947–960.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jeon 等（2019）Myeongjae Jeon, Shivaram Venkataraman, Amar Phanishayee, Junjie
    Qian, Wencong Xiao 和 Fan Yang. 2019. 大规模多租户 GPU 集群对 DNN 训练工作负载的分析。在 *2019 USENIX
    年度技术会议（USENIX ATC 19）* 上。947–960。
- en: 'Jiang et al. (2023) Youhe Jiang, Ran Yan, Xiaozhe Yao, Beidi Chen, and Binhang
    Yuan. 2023. Hexgen: Generative inference of foundation model over heterogeneous
    decentralized environment. *arXiv preprint arXiv:2311.11514* (2023).'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等（2023）Youhe Jiang, Ran Yan, Xiaozhe Yao, Beidi Chen 和 Binhang Yuan. 2023.
    Hexgen：异构分散环境中基础模型的生成推断。*arXiv 预印本 arXiv:2311.11514*（2023）。
- en: 'Jin et al. (2024) Xin Jin, Zhihao Bai, Zhen Zhang, Yibo Zhu, Yinmin Zhong,
    and Xuanzhe Liu. 2024. DistMind: Efficient Resource Disaggregation for Deep Learning
    Workloads. *IEEE/ACM Transactions on Networking* (2024).'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin 等（2024）Xin Jin, Zhihao Bai, Zhen Zhang, Yibo Zhu, Yinmin Zhong 和 Xuanzhe
    Liu. 2024. DistMind：针对深度学习工作负载的高效资源解耦。*IEEE/ACM 网络通讯汇刊*（2024）。
- en: 'Kang et al. (2020) Minkoo Kang, Gyeongsik Yang, Yeonho Yoo, and Chuck Yoo.
    2020. TensorExpress: In-network communication scheduling for distributed deep
    learning. In *2020 IEEE 13th international conference on cloud computing (CLOUD)*.
    IEEE, 25–27.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang 等（2020）Minkoo Kang, Gyeongsik Yang, Yeonho Yoo 和 Chuck Yoo. 2020. TensorExpress：用于分布式深度学习的网络内通信调度。在
    *2020 IEEE第13届国际云计算会议（CLOUD）* 上。IEEE，25–27。
- en: 'Kingma and Ba (2015) Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method
    for Stochastic Optimization. In *3rd International Conference on Learning Representations,
    ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings*.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma 和 Ba（2015）Diederik P. Kingma 和 Jimmy Ba. 2015. Adam：一种随机优化方法。在 *第3届国际学习表征会议，ICLR
    2015，美国加州圣地亚哥，2015年5月7-9日，会议论文集* 上。
- en: 'Li et al. (2023b) Jiamin Li, Hong Xu, Yibo Zhu, Zherui Liu, Chuanxiong Guo,
    and Cong Wang. 2023b. Lyra: Elastic scheduling for deep learning clusters. In
    *Proceedings of the Eighteenth European Conference on Computer Systems*. 835–850.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2023b）Jiamin Li, Hong Xu, Yibo Zhu, Zherui Liu, Chuanxiong Guo 和 Cong Wang.
    2023b. Lyra：深度学习集群的弹性调度。在 *第十八届欧洲计算机系统会议论文集* 上。835–850。
- en: 'Li et al. (2023a) Mingzhen Li, Wencong Xiao, Hailong Yang, Biao Sun, Hanyu
    Zhao, Shiru Ren, Zhongzhi Luan, Xianyan Jia, Yi Liu, Yong Li, et al. 2023a. EasyScale:
    Elastic Training with Consistent Accuracy and Improved Utilization on GPUs. In
    *Proceedings of the International Conference for High Performance Computing, Networking,
    Storage and Analysis*. 1–14.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2023a）Mingzhen Li, Wencong Xiao, Hailong Yang, Biao Sun, Hanyu Zhao, Shiru
    Ren, Zhongzhi Luan, Xianyan Jia, Yi Liu, Yong Li 等。2023a. EasyScale：在 GPU 上实现一致精度和改进利用率的弹性训练。在
    *国际高性能计算、网络、存储和分析会议论文集* 上。1–14。
- en: Li et al. (2014) Mu Li, Tong Zhang, Yuqiang Chen, and Alexander J Smola. 2014.
    Efficient mini-batch training for stochastic optimization. In *Proceedings of
    the 20th ACM SIGKDD international conference on Knowledge discovery and data mining*.
    661–670.
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2014) Mu Li, Tong Zhang, Yuqiang Chen, 和 Alexander J Smola. 2014.
    高效的小批量训练用于随机优化. 载于 *第20届ACM SIGKDD国际知识发现与数据挖掘会议论文集*. 661–670.
- en: 'Li and Hoefler (2021) Shigang Li and Torsten Hoefler. 2021. Chimera: efficiently
    training large-scale neural networks with bidirectional pipelines. In *Proceedings
    of the International Conference for High Performance Computing, Networking, Storage
    and Analysis*. 1–14.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li and Hoefler (2021) Shigang Li 和 Torsten Hoefler. 2021. Chimera: 高效训练大规模神经网络的双向管道.
    载于 *国际高性能计算、网络、存储与分析会议论文集*. 1–14.'
- en: 'Li et al. (2020c) Shen Li, Yanli Zhao, Rohan Varma, Omkar Salpekar, Pieter
    Noordhuis, Teng Li, Adam Paszke, Jeff Smith, Brian Vaughan, Pritam Damania, and
    Soumith Chintala. 2020c. PyTorch Distributed: Experiences on Accelerating Data
    Parallel Training. *Proc. VLDB Endow.* 13, 12 (aug 2020), 3005–3018.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li et al. (2020c) Shen Li, Yanli Zhao, Rohan Varma, Omkar Salpekar, Pieter
    Noordhuis, Teng Li, Adam Paszke, Jeff Smith, Brian Vaughan, Pritam Damania, 和
    Soumith Chintala. 2020c. PyTorch Distributed: 加速数据并行训练的经验. *Proc. VLDB Endow.*
    13, 12 (2020年8月), 3005–3018.'
- en: Li et al. (2020a) Wenxin Li, Sheng Chen, Keqiu Li, Heng Qi, Renhai Xu, and Song
    Zhang. 2020a. Efficient online scheduling for coflow-aware machine learning clusters.
    *IEEE Transactions on Cloud Computing* 10, 4 (2020), 2564–2579.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2020a) Wenxin Li, Sheng Chen, Keqiu Li, Heng Qi, Renhai Xu, 和 Song
    Zhang. 2020a. 面向协同流感知的机器学习集群的高效在线调度. *IEEE云计算汇刊* 10, 4 (2020), 2564–2579.
- en: Li et al. (2020b) Yang Li, Zhenhua Han, Quanlu Zhang, Zhenhua Li, and Haisheng
    Tan. 2020b. Automating cloud deployment for deep learning inference of real-time
    online services. In *IEEE INFOCOM 2020-IEEE Conference on Computer Communications*.
    IEEE, 1668–1677.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2020b) Yang Li, Zhenhua Han, Quanlu Zhang, Zhenhua Li, 和 Haisheng
    Tan. 2020b. 自动化云部署用于实时在线服务的深度学习推理. 载于 *IEEE INFOCOM 2020-IEEE计算机通信会议*. IEEE, 1668–1677.
- en: 'Li et al. (2023c) Zhuohan Li, Lianmin Zheng, Yinmin Zhong, Vincent Liu, Ying
    Sheng, Xin Jin, Yanping Huang, Zhifeng Chen, Hao Zhang, Joseph E Gonzalez, et al.
    2023c. AlpaServe: Statistical multiplexing with model parallelism for deep learning
    serving. In *17th USENIX Symposium on Operating Systems Design and Implementation
    (OSDI 23)*. 663–679.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li et al. (2023c) Zhuohan Li, Lianmin Zheng, Yinmin Zhong, Vincent Liu, Ying
    Sheng, Xin Jin, Yanping Huang, Zhifeng Chen, Hao Zhang, Joseph E Gonzalez 等. 2023c.
    AlpaServe: 基于模型并行的深度学习服务的统计复用. 载于 *第17届USENIX操作系统设计与实现研讨会 (OSDI 23)*. 663–679.'
- en: 'Liang et al. (2024) Feng Liang, Zhen Zhang, Haifeng Lu, Victor C. M. Leung,
    Yanyi Guo, and Xiping Hu. 2024. Communication-Efficient Large-Scale Distributed
    Deep Learning: A Comprehensive Survey. arXiv:2404.06114 [cs.DC]'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liang et al. (2024) Feng Liang, Zhen Zhang, Haifeng Lu, Victor C. M. Leung,
    Yanyi Guo, 和 Xiping Hu. 2024. 通信高效的大规模分布式深度学习: 一项综合调查. arXiv:2404.06114 [cs.DC]'
- en: 'Liao et al. (2021) Heng Liao, Jiajin Tu, Jing Xia, Hu Liu, Xiping Zhou, Honghui
    Yuan, and Yuxing Hu. 2021. Ascend: a Scalable and Unified Architecture for Ubiquitous
    Deep Neural Network Computing : Industry Track Paper. In *2021 IEEE International
    Symposium on High-Performance Computer Architecture (HPCA)*. 789–801.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liao et al. (2021) Heng Liao, Jiajin Tu, Jing Xia, Hu Liu, Xiping Zhou, Honghui
    Yuan, 和 Yuxing Hu. 2021. Ascend: 一个可扩展且统一的普适深度神经网络计算架构 : 行业跟踪论文. 载于 *2021 IEEE国际高性能计算机架构研讨会
    (HPCA)*. 789–801.'
- en: 'Lim et al. (2021) Gangmuk Lim, Jeongseob Ahn, Wencong Xiao, Youngjin Kwon,
    and Myeongjae Jeon. 2021. Zico: Efficient GPU Memory Sharing for Concurrent DNN
    Training. In *2021 USENIX Annual Technical Conference (USENIX ATC 21)*. 161–175.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lim et al. (2021) Gangmuk Lim, Jeongseob Ahn, Wencong Xiao, Youngjin Kwon,
    和 Myeongjae Jeon. 2021. Zico: 高效的GPU内存共享用于并发DNN训练. 载于 *2021 USENIX年度技术会议 (USENIX
    ATC 21)*. 161–175.'
- en: 'Liu et al. (2022b) Ji Liu, Jizhou Huang, Yang Zhou, Xuhong Li, Shilei Ji, Haoyi
    Xiong, and Dejing Dou. 2022b. From distributed machine learning to federated learning:
    A survey. *Knowledge and Information Systems* 64, 4 (2022), 885–917.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2022b) Ji Liu, Jizhou Huang, Yang Zhou, Xuhong Li, Shilei Ji, Haoyi
    Xiong, 和 Dejing Dou. 2022b. 从分布式机器学习到联邦学习: 一项调查. *知识与信息系统* 64, 4 (2022), 885–917.'
- en: Liu et al. (2024b) Kaiyang Liu, Jingrong Wang, Zhiming Huang, and Jianping Pan.
    2024b. Sampling-Based Multi-Job Placement for Heterogeneous Deep Learning Clusters.
    *IEEE Transactions on Parallel and Distributed Systems* (2024).
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2024b) Kaiyang Liu, Jingrong Wang, Zhiming Huang, 和 Jianping Pan.
    2024b. 基于采样的多任务放置用于异构深度学习集群. *IEEE并行与分布式系统汇刊* (2024).
- en: Liu et al. (2022d) Liu Liu, Jian Yu, and Zhijun Ding. 2022d. Adaptive and Efficient
    GPU Time Sharing for Hyperparameter Tuning in Cloud. In *Proceedings of the 51st
    International Conference on Parallel Processing*. 1–11.
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等（2022d）刘刘、简宇和郑俊丁。2022d。云中超参数调优的自适应和高效 GPU 时间共享。见于*第51届国际并行处理会议论文集*。1–11。
- en: 'Liu et al. (2022a) Weihong Liu, Jiawei Geng, Zongwei Zhu, Jing Cao, and Zirui
    Lian. 2022a. Sniper: Cloud-Edge Collaborative Inference Scheduling with Neural
    Network Similarity Modeling. In *Proceedings of the 59th ACM/IEEE Design Automation
    Conference* (San Francisco, California) *(DAC ’22)*. New York, NY, USA, 505–510.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等（2022a）刘伟宏、耿家伟、朱宗伟、曹晶和连子瑞。2022a。Sniper：基于神经网络相似性建模的云边协作推理调度。见于*第59届ACM/IEEE设计自动化会议*（旧金山，加州）*(DAC
    ’22)*。纽约，NY，美国，505–510。
- en: 'Liu et al. (2024a) Weihong Liu, Jiawei Geng, Zongwei Zhu, Yang Zhao, Cheng
    Ji, Changlong Li, Zirui Lian, and Xuehai Zhou. 2024a. Ace-Sniper: Cloud–Edge Collaborative
    Scheduling Framework With DNN Inference Latency Modeling on Heterogeneous Devices.
    *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*
    43, 2 (2024), 534–547.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等（2024a）刘伟宏、耿家伟、朱宗伟、赵阳、季成、李长龙、连子瑞和周学海。2024a。Ace-Sniper：具有 DNN 推理延迟建模的异构设备云边协作调度框架。*IEEE
    集成电路与系统计算机辅助设计交易* 43, 2（2024），534–547。
- en: 'Liu et al. (2022c) Weijie Liu, Zhiquan Lai, Shengwei Li, Yabo Duan, Keshi Ge,
    and Dongsheng Li. 2022c. AutoPipe: A fast pipeline parallelism approach with balanced
    partitioning and micro-batch slicing. In *2022 IEEE International Conference on
    Cluster Computing (CLUSTER)*. IEEE, 301–312.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等（2022c）刘伟杰、赖志权、李盛伟、段雅博、葛克石和李东生。2022c。AutoPipe：一种具有平衡分区和微批切片的快速管道并行方法。见于*2022
    IEEE 国际集群计算会议（CLUSTER）*。IEEE，301–312。
- en: 'Liu et al. (2023) Ziming Liu, Shenggan Cheng, Haotian Zhou, and Yang You. 2023.
    Hanayo: Harnessing Wave-like Pipeline Parallelism for Enhanced Large Model Training
    Efficiency. In *Proceedings of the International Conference for High Performance
    Computing, Networking, Storage and Analysis*. 1–13.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等（2023）刘子鸣、程圣刚、周浩天和游阳。2023。Hanayo：利用波浪式管道并行提升大规模模型训练效率。见于*国际高性能计算、网络、存储与分析会议论文集*。1–13。
- en: 'Lotfollahi et al. (2020) Mohammad Lotfollahi, Mahdi Jafari Siavoshani, Ramin
    Shirali Hossein Zade, and Mohammdsadegh Saberian. 2020. Deep packet: A novel approach
    for encrypted traffic classification using deep learning. *Soft Computing* 24,
    3 (2020), 1999–2012.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lotfollahi 等（2020）穆罕默德·洛特弗拉希、马赫迪·贾法里·西亚沃沙尼、拉敏·希拉利·霍赛因·扎德和穆罕默德萨德赫·萨比里安。2020。Deep
    packet：一种利用深度学习进行加密流量分类的新方法。*软计算* 24, 3（2020），1999–2012。
- en: 'Luan et al. (2019) Yunteng Luan, Xukun Chen, Hanyu Zhao, Zhi Yang, and Yafei
    Dai. 2019. SCHED²: Scheduling Deep Learning Training via Deep Reinforcement Learning.
    In *2019 IEEE Global Communications Conference (GLOBECOM)*. IEEE, 1–7.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阮等（2019）阮运腾、陈旭坤、赵汉宇、杨志和戴亚飞。2019。SCHED²：通过深度强化学习调度深度学习训练。见于*2019 IEEE 全球通信会议（GLOBECOM）*。IEEE，1–7。
- en: Mao et al. (2023) Ying Mao, Vaishali Sharma, Wenjia Zheng, Long Cheng, Qiang
    Guan, and Ang Li. 2023. Elastic Resource Management for Deep Learning Applications
    in a Container Cluster. *IEEE Transactions on Cloud Computing* 11, 2 (2023), 2204–2216.
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 毛等（2023）毛颖、瓦伊莎莉·夏尔马、郑文佳、程龙、关强和李昂。2023。容器集群中深度学习应用的弹性资源管理。*IEEE 云计算交易* 11, 2（2023），2204–2216。
- en: 'Mayer and Jacobsen (2020) Ruben Mayer and Hans-Arno Jacobsen. 2020. Scalable
    deep learning on distributed infrastructures: Challenges, techniques, and tools.
    *ACM Computing Surveys (CSUR)* 53, 1 (2020), 1–37.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mayer 和 Jacobsen（2020）鲁本·梅耶和汉斯-阿诺·雅各布森。2020。在分布式基础设施上的可扩展深度学习：挑战、技术和工具。*ACM
    计算调查（CSUR）* 53, 1（2020），1–37。
- en: 'Mo et al. (2024) Zizhao Mo, Huanle Xu, and Chengzhong Xu. 2024. Heet: Accelerating
    Elastic Training in Heterogeneous Deep Learning Clusters. In *Proceedings of the
    29th ACM International Conference on Architectural Support for Programming Languages
    and Operating Systems, Volume 2*. 499–513.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 莫等（2024）莫自浩、徐欢乐和徐成中。2024。Heet：在异构深度学习集群中加速弹性训练。见于*第29届ACM国际编程语言和操作系统架构支持会议论文集，第二卷*。499–513。
- en: 'Narayanan et al. (2019) Deepak Narayanan, Aaron Harlap, Amar Phanishayee, Vivek
    Seshadri, Nikhil R Devanur, Gregory R Ganger, Phillip B Gibbons, and Matei Zaharia.
    2019. PipeDream: Generalized pipeline parallelism for DNN training. In *Proceedings
    of the 27th ACM Symposium on Operating Systems Principles*. 1–15.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Narayanan 等人（2019）Deepak Narayanan、Aaron Harlap、Amar Phanishayee、Vivek Seshadri、Nikhil
    R Devanur、Gregory R Ganger、Phillip B Gibbons 和 Matei Zaharia。2019。PipeDream：用于
    DNN 训练的通用管道并行性。在 *第 27 届 ACM 操作系统原则研讨会论文集* 上。1–15。
- en: Narayanan et al. (2020) Deepak Narayanan, Keshav Santhanam, Fiodar Kazhamiaka,
    Amar Phanishayee, and Matei Zaharia. 2020. Heterogeneity-Aware cluster scheduling
    policies for deep learning workloads. In *14th USENIX Symposium on Operating Systems
    Design and Implementation (OSDI 20)*. 481–498.
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Narayanan 等人（2020）Deepak Narayanan、Keshav Santhanam、Fiodar Kazhamiaka、Amar Phanishayee
    和 Matei Zaharia。2020。针对深度学习工作负载的异构感知集群调度策略。在 *第 14 届 USENIX 操作系统设计与实现研讨会 (OSDI
    20)* 上。481–498。
- en: Narayanan et al. (2021) Deepak Narayanan, Mohammad Shoeybi, Jared Casper, Patrick
    LeGresley, Mostofa Patwary, Vijay Korthikanti, Dmitri Vainbrand, Prethvi Kashinkunti,
    Julie Bernauer, Bryan Catanzaro, et al. 2021. Efficient large-scale language model
    training on gpu clusters using megatron-lm. In *Proceedings of the International
    Conference for High Performance Computing, Networking, Storage and Analysis*.
    1–15.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Narayanan 等人（2021）Deepak Narayanan、Mohammad Shoeybi、Jared Casper、Patrick LeGresley、Mostofa
    Patwary、Vijay Korthikanti、Dmitri Vainbrand、Prethvi Kashinkunti、Julie Bernauer、Bryan
    Catanzaro 等人。2021。在 GPU 集群上使用 Megatron-LM 高效进行大规模语言模型训练。在 *国际高性能计算、网络、存储和分析会议论文集*
    上。1–15。
- en: 'Nijkamp et al. (2023) Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan
    Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong. 2023. CodeGen: An Open
    Large Language Model for Code with Multi-Turn Program Synthesis. In *The Eleventh
    International Conference on Learning Representations*.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nijkamp 等人（2023）Erik Nijkamp、Bo Pang、Hiroaki Hayashi、Lifu Tu、Huan Wang、Yingbo
    Zhou、Silvio Savarese 和 Caiming Xiong。2023。CodeGen：一个用于代码的开放大型语言模型，支持多轮程序合成。在 *第十一届国际学习表征会议*
    上。
- en: 'Oh et al. (2022) Hyungjun Oh, Junyeol Lee, Hyeongju Kim, and Jiwon Seo. 2022.
    Out-of-order backprop: An effective scheduling technique for deep learning. In
    *Proceedings of the Seventeenth European Conference on Computer Systems*. 435–452.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oh 等人（2022）Hyungjun Oh、Junyeol Lee、Hyeongju Kim 和 Jiwon Seo。2022。乱序反向传播：一种有效的深度学习调度技术。在
    *第十七届欧洲计算机系统会议论文集* 上。435–452。
- en: 'Ouyang et al. (2021) Shuo Ouyang, Dezun Dong, Yemao Xu, and Liquan Xiao. 2021.
    Communication optimization strategies for distributed deep neural network training:
    A survey. *J. Parallel and Distrib. Comput.* 149 (2021), 52–65.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ouyang 等人（2021）Shuo Ouyang、Dezun Dong、Yemao Xu 和 Liquan Xiao。2021。分布式深度神经网络训练的通信优化策略：一项综述。*J.
    Parallel and Distrib. Comput.* 149（2021），52–65。
- en: 'Park et al. (2020) Jay H Park, Gyeongchan Yun, M Yi Chang, Nguyen T Nguyen,
    Seungmin Lee, Jaesik Choi, Sam H Noh, and Young-ri Choi. 2020. HetPipe: Enabling
    large DNN training on (whimpy) heterogeneous GPU clusters through integration
    of pipelined model parallelism and data parallelism. In *2020 USENIX Annual Technical
    Conference (USENIX ATC 20)*. 307–321.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等人（2020）Jay H Park、Gyeongchan Yun、M Yi Chang、Nguyen T Nguyen、Seungmin Lee、Jaesik
    Choi、Sam H Noh 和 Young-ri Choi。2020。HetPipe：通过集成流水线模型并行性和数据并行性来支持大规模 DNN 训练（在性能较弱的）异构
    GPU 集群。在 *2020 USENIX 年度技术会议 (USENIX ATC 20)* 上。307–321。
- en: 'Pavlidakis et al. (2024) Manos Pavlidakis, Giorgos Vasiliadis, Stelios Mavridis,
    Anargyros Argyros, Antony Chazapis, and Angelos Bilas. 2024. G-Safe: Safe GPU
    Sharing in Multi-Tenant Environments. *arXiv preprint arXiv:2401.09290* (2024).'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pavlidakis 等人（2024）Manos Pavlidakis、Giorgos Vasiliadis、Stelios Mavridis、Anargyros
    Argyros、Antony Chazapis 和 Angelos Bilas。2024。G-Safe：多租户环境中的安全 GPU 共享。*arXiv 预印本
    arXiv:2401.09290*（2024）。
- en: 'Peng et al. (2018) Yanghua Peng, Yixin Bao, Yangrui Chen, Chuan Wu, and Chuanxiong
    Guo. 2018. Optimus: an efficient dynamic resource scheduler for deep learning
    clusters. In *Proceedings of the Thirteenth EuroSys Conference*. 1–14.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng 等人（2018）Yanghua Peng、Yixin Bao、Yangrui Chen、Chuan Wu 和 Chuanxiong Guo。2018。Optimus：一个高效的深度学习集群动态资源调度器。在
    *第十三届 EuroSys 会议论文集* 上。1–14。
- en: 'Qiao et al. (2021) Aurick Qiao, Sang Keun Choe, Suhas Jayaram Subramanya, Willie
    Neiswanger, Qirong Ho, Hao Zhang, Gregory R. Ganger, and Eric P. Xing. 2021. Pollux:
    Co-adaptive Cluster Scheduling for Goodput-Optimized Deep Learning. In *15th USENIX
    Symposium on Operating Systems Design and Implementation (OSDI 21)*. 1–18.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qiao 等人（2021）Aurick Qiao、Sang Keun Choe、Suhas Jayaram Subramanya、Willie Neiswanger、Qirong
    Ho、Hao Zhang、Gregory R. Ganger 和 Eric P. Xing。2021。Pollux：良品优化深度学习的共适应集群调度。在 *第
    15 届 USENIX 操作系统设计与实现研讨会 (OSDI 21)* 上。1–18。
- en: 'Qin et al. (2019) Heyang Qin, Syed Zawad, Yanqi Zhou, Lei Yang, Dongfang Zhao,
    and Feng Yan. 2019. Swift machine learning model serving scheduling: a region
    based reinforcement learning approach. In *Proceedings of the International Conference
    for High Performance Computing, Networking, Storage and Analysis*. 1–23.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin 等（2019）Heyang Qin, Syed Zawad, Yanqi Zhou, Lei Yang, Dongfang Zhao 和 Feng
    Yan. 2019. 快速机器学习模型服务调度：基于区域的强化学习方法。发表于 *国际高性能计算、网络、存储和分析会议论文集*。1–23。
- en: Rajasekaran et al. (2024) Sudarsanan Rajasekaran, Manya Ghobadi, and Aditya
    Akella. 2024. CASSINI:Network-Aware Job Scheduling in Machine Learning Clusters.
    In *21st USENIX Symposium on Networked Systems Design and Implementation (NSDI
    24)*. 1403–1420.
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajasekaran 等（2024）Sudarsanan Rajasekaran, Manya Ghobadi 和 Aditya Akella. 2024.
    CASSINI：机器学习集群中的网络感知作业调度。发表于 *第21届 USENIX 网络系统设计与实施研讨会（NSDI 24）*。1403–1420。
- en: 'Romero et al. (2021) Francisco Romero, Qian Li, Neeraja J Yadwadkar, and Christos
    Kozyrakis. 2021. INFaaS: Automated model-less inference serving. In *2021 USENIX
    Annual Technical Conference (USENIX ATC 21)*. 397–411.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Romero 等（2021）Francisco Romero, Qian Li, Neeraja J Yadwadkar 和 Christos Kozyrakis.
    2021. INFaaS：自动化的无模型推理服务。发表于 *2021 USENIX 年度技术会议（USENIX ATC 21）*。397–411。
- en: 'Ryabinin et al. (2023) Max Ryabinin, Tim Dettmers, Michael Diskin, and Alexander
    Borzunov. 2023. SWARM Parallelism: Training Large Models Can Be Surprisingly Communication-Efficient.
    In *Proceedings of the 40th International Conference on Machine Learning* (Honolulu,
    Hawaii, USA). JMLR, 29416–29440.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ryabinin 等（2023）Max Ryabinin, Tim Dettmers, Michael Diskin 和 Alexander Borzunov.
    2023. SWARM 并行性：训练大型模型可以意外地高效沟通。发表于 *第40届国际机器学习会议论文集*（檀香山，夏威夷，美国）。JMLR，29416–29440。
- en: 'Sagduyu et al. (2023) Yalin E Sagduyu, Sennur Ulukus, and Aylin Yener. 2023.
    Task-oriented communications for nextG: End-to-end deep learning and AI security
    aspects. *IEEE Wireless Communications* 30, 3 (2023), 52–60.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sagduyu 等（2023）Yalin E Sagduyu, Sennur Ulukus 和 Aylin Yener. 2023. 面向任务的通信用于下一代：端到端深度学习和
    AI 安全方面。*IEEE 无线通信* 30, 3（2023），52–60。
- en: Saikia et al. (2022) Prajwalita Saikia, Sudip Biswas, Keshav Singh, and Chih-Peng
    Li. 2022. Signal Detection in GSM-Based In-Band Full-Duplex Communication Using
    DNN. *IEEE Transactions on Vehicular Technology* 72, 2 (2022), 2661–2666.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saikia 等（2022）Prajwalita Saikia, Sudip Biswas, Keshav Singh 和 Chih-Peng Li.
    2022. 使用 DNN 在基于 GSM 的带内全双工通信中进行信号检测。*IEEE 车辆技术交易期刊* 72, 2（2022），2661–2666。
- en: Say (2021) Buser Say. 2021. A unified framework for planning with learned neural
    network transition models. In *Proceedings of the AAAI Conference on Artificial
    Intelligence*, Vol. 35\. 5016–5024.
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Say（2021）Buser Say. 2021. 一个统一的框架用于使用学习的神经网络过渡模型进行规划。发表于 *AAAI 人工智能会议论文集*，第
    35 卷。5016–5024。
- en: 'Shen et al. (2019) Haichen Shen, Lequn Chen, Yuchen Jin, Liangyu Zhao, Bingyu
    Kong, Matthai Philipose, Arvind Krishnamurthy, and Ravi Sundaram. 2019. Nexus:
    A GPU cluster engine for accelerating DNN-based video analysis. In *Proceedings
    of the 27th ACM Symposium on Operating Systems Principles*. 322–337.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等（2019）Haichen Shen, Lequn Chen, Yuchen Jin, Liangyu Zhao, Bingyu Kong,
    Matthai Philipose, Arvind Krishnamurthy 和 Ravi Sundaram. 2019. Nexus：一个用于加速基于
    DNN 的视频分析的 GPU 集群引擎。发表于 *第27届 ACM 操作系统原理研讨会论文集*。322–337。
- en: 'Shi et al. (2023) Hongjian Shi, Weichu Zheng, Zifei Liu, Ruhui Ma, and Haibing
    Guan. 2023. Automatic pipeline parallelism: A parallel inference framework for
    deep learning applications in 6G mobile communication systems. *IEEE Journal on
    Selected Areas in Communications* (2023).'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等（2023）Hongjian Shi, Weichu Zheng, Zifei Liu, Ruhui Ma 和 Haibing Guan. 2023.
    自动管道并行性：一个用于深度学习应用的并行推理框架，适用于 6G 移动通信系统。*IEEE 选择领域通信期刊*（2023）。
- en: 'Shi et al. (2021) Shaohuai Shi, Xiaowen Chu, and Bo Li. 2021. MG-WFBP: Merging
    gradients wisely for efficient communication in distributed deep learning. *IEEE
    Transactions on Parallel and Distributed Systems* 32, 8 (2021), 1903–1917.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等（2021）Shaohuai Shi, Xiaowen Chu 和 Bo Li. 2021. MG-WFBP：智慧地合并梯度以提高分布式深度学习中的通信效率。*IEEE
    并行与分布式系统交易期刊* 32, 8（2021），1903–1917。
- en: 'Shi et al. (2024) Shaohuai Shi, Xinglin Pan, Qiang Wang, Chengjian Liu, Xiaozhe
    Ren, Zhongzhe Hu, Yu Yang, Bo Li, and Xiaowen Chu. 2024. ScheMoE: An Extensible
    Mixture-of-Experts Distributed Training System with Tasks Scheduling. In *Proceedings
    of the Nineteenth European Conference on Computer Systems*. 236–249.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等（2024）Shaohuai Shi, Xinglin Pan, Qiang Wang, Chengjian Liu, Xiaozhe Ren,
    Zhongzhe Hu, Yu Yang, Bo Li 和 Xiaowen Chu. 2024. ScheMoE：一个可扩展的专家混合分布式训练系统，具有任务调度功能。发表于
    *第十九届欧洲计算机系统会议论文集*。236–249。
- en: 'Shi et al. (2020) Yuanming Shi, Kai Yang, Tao Jiang, Jun Zhang, and Khaled B
    Letaief. 2020. Communication-efficient edge AI: Algorithms and systems. *IEEE
    Communications Surveys & Tutorials* 22, 4 (2020), 2167–2191.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi et al. (2020) Yuanming Shi, Kai Yang, Tao Jiang, Jun Zhang, and Khaled B
    Letaief. 2020. 通信高效的边缘AI：算法与系统。*IEEE Communications Surveys & Tutorials* 22，4（2020），2167–2191。
- en: Smith et al. (2022) Shaden Smith, Mostofa Patwary, Brandon Norick, Patrick LeGresley,
    Samyam Rajbhandari, Jared Casper, Zhun Liu, Shrimai Prabhumoye, George Zerveas,
    Vijay Korthikanti, et al. 2022. Using deepspeed and megatron to train megatron-turing
    nlg 530b, a large-scale generative language model. *arXiv preprint arXiv:2201.11990*
    (2022).
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Smith et al. (2022) Shaden Smith, Mostofa Patwary, Brandon Norick, Patrick LeGresley,
    Samyam Rajbhandari, Jared Casper, Zhun Liu, Shrimai Prabhumoye, George Zerveas,
    Vijay Korthikanti, 等人。2022. 使用deepspeed和megatron训练megatron-turing nlg 530b，一个大规模生成语言模型。*arXiv
    preprint arXiv:2201.11990*（2022）。
- en: 'Strati et al. (2024) Foteini Strati, Xianzhe Ma, and Ana Klimovic. 2024. Orion:
    Interference-aware, Fine-grained GPU Sharing for ML Applications. In *Proceedings
    of the Nineteenth European Conference on Computer Systems*. 1075–1092.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Strati et al. (2024) Foteini Strati, Xianzhe Ma, and Ana Klimovic. 2024. Orion：针对ML应用的干扰感知细粒度GPU共享。见于*第十九届欧洲计算机系统会议论文集*。1075–1092。
- en: 'Sultana et al. (2020) Abeda Sultana, Li Chen, Fei Xu, and Xu Yuan. 2020. E-LAS:
    Design and Analysis of Completion-Time Agnostic Scheduling for Distributed Deep
    Learning Cluster. In *49th International Conference on Parallel Processing - ICPP*.
    1–11.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sultana et al. (2020) Abeda Sultana, Li Chen, Fei Xu, and Xu Yuan. 2020. E-LAS：分布式深度学习集群的完成时间无关调度设计与分析。见于*第49届国际并行处理会议
    - ICPP*。1–11。
- en: 'Sun et al. (2024) Zhenbo Sun, Huanqi Cao, Yuanwei Wang, Guanyu Feng, Shengqi
    Chen, Haojie Wang, and Wenguang Chen. 2024. AdaPipe: Optimizing Pipeline Parallelism
    with Adaptive Recomputation and Partitioning. In *Proceedings of the 29th ACM
    International Conference on Architectural Support for Programming Languages and
    Operating Systems, Volume 3* (¡conf-loc¿, ¡city¿La Jolla¡/city¿, ¡state¿CA¡/state¿,
    ¡country¿USA¡/country¿, ¡/conf-loc¿) *(ASPLOS ’24)*. Association for Computing
    Machinery, New York, NY, USA, 86–100.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sun et al. (2024) Zhenbo Sun, Huanqi Cao, Yuanwei Wang, Guanyu Feng, Shengqi
    Chen, Haojie Wang, and Wenguang Chen. 2024. AdaPipe: 通过自适应重计算和分区优化管道并行性。见于*第29届ACM国际编程语言与操作系统架构支持会议论文集，第3卷*（¡conf-loc¿,
    ¡city¿La Jolla¡/city¿, ¡state¿CA¡/state¿, ¡country¿USA¡/country¿, ¡/conf-loc¿）（*ASPLOS
    ’24*）。计算机协会，纽约，NY，USA，86–100。'
- en: Sutskever et al. (2013) Ilya Sutskever, James Martens, George Dahl, and Geoffrey
    Hinton. 2013. On the importance of initialization and momentum in deep learning.
    In *Proceedings of the 30th International Conference on Machine Learning*, Vol. 28.
    PMLR, Atlanta, Georgia, USA, 1139–1147.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sutskever et al. (2013) Ilya Sutskever, James Martens, George Dahl, and Geoffrey
    Hinton. 2013. 深度学习中初始化和动量的重要性。见于*第30届国际机器学习会议论文集*，第28卷。PMLR，亚特兰大，乔治亚州，USA，1139–1147。
- en: 'Ta (2019) Nguyen Binh Duong Ta. 2019. $FC^{2}$: cloud-based cluster provisioning
    for distributed machine learning. *Cluster Computing* (Dec 2019), 1299–1315.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ta (2019) Nguyen Binh Duong Ta. 2019. $FC^{2}$: 基于云的分布式机器学习集群配置。*Cluster Computing*（2019年12月），1299–1315。'
- en: Tang et al. (2023b) Shujiong Tang, Yue Yu, Hui Wang, Guiliang Wang, Wuhui Chen,
    Zenglin Xu, Song Guo, and Wen Gao. 2023b. A Survey on Scheduling Techniques in
    Computing and Network Convergence. *IEEE Communications Surveys & Tutorials* (2023).
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang et al. (2023b) Shujiong Tang, Yue Yu, Hui Wang, Guiliang Wang, Wuhui Chen,
    Zenglin Xu, Song Guo, and Wen Gao. 2023b. 计算与网络融合中的调度技术综述。*IEEE Communications
    Surveys & Tutorials*（2023）。
- en: 'Tang et al. (2019) Xuehai Tang, Peng Wang, Qiuyang Liu, Wang Wang, and Jizhong
    Han. 2019. Nanily: A QoS-Aware Scheduling for DNN Inference Workload in Clouds.
    In *2019 IEEE 21st International Conference on High Performance Computing and
    Communications; IEEE 17th International Conference on Smart City; IEEE 5th International
    Conference on Data Science and Systems (HPCC/SmartCity/DSS)*.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang et al. (2019) Xuehai Tang, Peng Wang, Qiuyang Liu, Wang Wang, and Jizhong
    Han. 2019. Nanily：一种用于云中DNN推理工作负载的QoS感知调度。见于*2019 IEEE第21届高性能计算与通信国际会议；IEEE第17届智能城市国际会议；IEEE第5届数据科学与系统国际会议（HPCC/SmartCity/DSS）*。
- en: 'Tang et al. (2023a) Zhenheng Tang, Shaohuai Shi, Xiaowen Chu, Wei Wang, and
    Bo Li. 2023a. Communication-efficient distributed deep learning: A comprehensive
    survey. *arXiv preprint arXiv:2003.06307* (2023).'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang et al. (2023a) Zhenheng Tang, Shaohuai Shi, Xiaowen Chu, Wei Wang, and
    Bo Li. 2023a. 通信高效的分布式深度学习：综合调查。*arXiv preprint arXiv:2003.06307*（2023）。
- en: 'Tarnawski et al. (2021) Jakub M Tarnawski, Deepak Narayanan, and Amar Phanishayee.
    2021. Piper: Multidimensional planner for dnn parallelization. *Advances in Neural
    Information Processing Systems* 34 (2021), 24829–24840.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tarnawski et al. (2021) Jakub M Tarnawski, Deepak Narayanan, 和 Amar Phanishayee.
    2021. Piper: 用于深度神经网络并行化的多维规划器。*神经信息处理系统进展* 34 (2021)，24829–24840。'
- en: Thieme et al. (2023) Alexander H Thieme, Yuanning Zheng, Gautam Machiraju, Chris
    Sadee, Mirja Mittermaier, Maximilian Gertler, Jorge L Salinas, Krithika Srinivasan,
    Prashnna Gyawali, Francisco Carrillo-Perez, et al. 2023. A deep-learning algorithm
    to classify skin lesions from mpox virus infection. *Nature medicine* 29, 3 (2023),
    738–747.
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thieme et al. (2023) Alexander H Thieme, Yuanning Zheng, Gautam Machiraju, Chris
    Sadee, Mirja Mittermaier, Maximilian Gertler, Jorge L Salinas, Krithika Srinivasan,
    Prashnna Gyawali, Francisco Carrillo-Perez, 等。2023. 一种用于分类皮肤病变的深度学习算法，针对 mpox
    病毒感染。*自然医学* 29, 3 (2023)，738–747。
- en: Thirunavukarasu et al. (2023) Arun James Thirunavukarasu, Darren Shu Jeng Ting,
    Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, and Daniel Shu Wei Ting. 2023.
    Large language models in medicine. *Nature medicine* 29, 8 (2023), 1930–1940.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thirunavukarasu et al. (2023) Arun James Thirunavukarasu, Darren Shu Jeng Ting,
    Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, 和 Daniel Shu Wei Ting. 2023.
    大型语言模型在医学中的应用。*自然医学* 29, 8 (2023)，1930–1940。
- en: 'Thoppilan et al. (2022) Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam
    Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker,
    Yu Du, et al. 2022. Lamda: Language models for dialog applications. *arXiv preprint
    arXiv:2201.08239* (2022).'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Thoppilan et al. (2022) Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam
    Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker,
    Yu Du, 等。2022. Lamda: 对话应用的语言模型。*arXiv 预印本 arXiv:2201.08239* (2022)。'
- en: 'Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation
    language models. *arXiv preprint arXiv:2302.13971* (2023).'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, 等。2023a. Llama: 开放且高效的基础语言模型。*arXiv 预印本 arXiv:2302.13971*
    (2023)。'
- en: 'Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288* (2023).'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, 等。2023b. Llama 2: 开放的基础模型和微调的聊天模型。*arXiv 预印本 arXiv:2307.09288*
    (2023)。'
- en: Vu et al. (2020) Ly Vu, Quang Uy Nguyen, Diep N Nguyen, Dinh Thai Hoang, Eryk
    Dutkiewicz, et al. 2020. Learning latent representation for IoT anomaly detection.
    *IEEE Transactions on Cybernetics* 52, 5 (2020), 3769–3782.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vu et al. (2020) Ly Vu, Quang Uy Nguyen, Diep N Nguyen, Dinh Thai Hoang, Eryk
    Dutkiewicz, 等。2020. 用于物联网异常检测的潜在表示学习。*IEEE 网络控制论汇刊* 52, 5 (2020)，3769–3782。
- en: 'Wang et al. (2022a) Cen Wang, Noboru Yoshikane, Filippos Balasis, and Takehiro
    Tsuritani. 2022a. OSDL: Dedicated optical slice provisioning in support of distributed
    deep learning. *Computer Networks* 214 (2022), 109191.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2022a) Cen Wang, Noboru Yoshikane, Filippos Balasis, 和 Takehiro
    Tsuritani. 2022a. OSDL: 支持分布式深度学习的专用光切片配置。*计算机网络* 214 (2022)，109191。'
- en: Wang et al. (2022b) Farui Wang, Weizhe Zhang, Shichao Lai, Meng Hao, and Zheng
    Wang. 2022b. Dynamic GPU Energy Optimization for Machine Learning Training Workloads.
    *IEEE Transactions on Parallel and Distributed Systems* (Jan 2022), 1–1.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2022b) Farui Wang, Weizhe Zhang, Shichao Lai, Meng Hao, 和 Zheng
    Wang. 2022b. 针对机器学习训练工作负载的动态 GPU 能源优化。*IEEE 并行与分布式系统汇刊* (2022年1月)，1–1。
- en: Wang et al. (2020b) Haoyu Wang, Zetian Liu, and Haiying Shen. 2020b. Job scheduling
    for large-scale machine learning clusters. In *Proceedings of the 16th International
    Conference on emerging Networking EXperiments and Technologies*. 108–120.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2020b) Haoyu Wang, Zetian Liu, 和 Haiying Shen. 2020b. 大规模机器学习集群的作业调度。在
    *第16届国际新兴网络实验与技术会议论文集* 中。108–120。
- en: 'Wang et al. (2021) Luping Wang, Lingyun Yang, Yinghao Yu, Wei Wang, Bo Li,
    Xianchao Sun, Jian He, and Liping Zhang. 2021. Morphling: fast, near-optimal auto-configuration
    for cloud-native model serving. In *Proceedings of the ACM Symposium on Cloud
    Computing*. 639–653.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2021) Luping Wang, Lingyun Yang, Yinghao Yu, Wei Wang, Bo Li,
    Xianchao Sun, Jian He, 和 Liping Zhang. 2021. Morphling: 快速、近乎最优的云原生模型服务自动配置。在
    *ACM 云计算研讨会论文集* 中。639–653。'
- en: 'Wang et al. (2024) Sheng Wang, Shiping Chen, and Yumei Shi. 2024. GPARS: Graph
    predictive algorithm for efficient resource scheduling in heterogeneous GPU clusters.
    *Future Generation Computer Systems* 152 (2024), 127–137.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2024) Sheng Wang, Shiping Chen, 和 Yumei Shi. 2024. GPARS: 用于异构
    GPU 集群中高效资源调度的图预测算法。*未来一代计算机系统* 152 (2024), 127–137.'
- en: 'Wang et al. (2020a) Shuai Wang, Dan Li, and Jinkun Geng. 2020a. Geryon: Accelerating
    distributed CNN training by network-level flow scheduling. In *IEEE INFOCOM 2020-IEEE
    Conference on Computer Communications*. IEEE, 1678–1687.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2020a) Shuai Wang, Dan Li, 和 Jinkun Geng. 2020a. Geryon: 通过网络级流调度加速分布式
    CNN 训练。在 *IEEE INFOCOM 2020-IEEE 计算机通信会议*. IEEE, 1678–1687.'
- en: 'Wang et al. (2018) Wei Wang, Jinyang Gao, Meihui Zhang, Sheng Wang, Gang Chen,
    Teck Khim Ng, Beng Chin Ooi, Jie Shao, and Moaz Reyad. 2018. Rafiki: machine learning
    as an analytics service system. *Proceedings of the VLDB Endowment* (Oct 2018),
    128–140.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2018) Wei Wang, Jinyang Gao, Meihui Zhang, Sheng Wang, Gang Chen,
    Teck Khim Ng, Beng Chin Ooi, Jie Shao, 和 Moaz Reyad. 2018. Rafiki: 作为分析服务系统的机器学习。*VLDB
    纪要* (2018年10月), 128–140.'
- en: 'Weng et al. (2022) Qizhen Weng, Wencong Xiao, Yinghao Yu, Wei Wang, Cheng Wang,
    Jian He, Yong Li, Liping Zhang, Wei Lin, and Yu Ding. 2022. MLaaS in the wild:
    Workload analysis and scheduling in Large-Scale heterogeneous GPU clusters. In
    *19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22)*.
    945–960.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Weng et al. (2022) Qizhen Weng, Wencong Xiao, Yinghao Yu, Wei Wang, Cheng Wang,
    Jian He, Yong Li, Liping Zhang, Wei Lin, 和 Yu Ding. 2022. 野外的 MLaaS: 大规模异构 GPU
    集群中的负载分析与调度。在 *第19届 USENIX 网络系统设计与实现研讨会 (NSDI 22)*. 945–960.'
- en: 'Weng et al. (2023) Qizhen Weng, Lingyun Yang, Yinghao Yu, Wei Wang, Xiaochuan
    Tang, Guodong Yang, and Liping Zhang. 2023. Beware of Fragmentation: Scheduling
    GPU-Sharing Workloads with Fragmentation Gradient Descent. In *2023 USENIX Annual
    Technical Conference (USENIX ATC 23)*. 995–1008.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weng et al. (2023) Qizhen Weng, Lingyun Yang, Yinghao Yu, Wei Wang, Xiaochuan
    Tang, Guodong Yang, 和 Liping Zhang. 2023. 当心碎片化：带有碎片化梯度下降的 GPU 共享负载调度。在 *2023
    USENIX 年度技术大会 (USENIX ATC 23)*. 995–1008.
- en: Wu et al. (2023) Bingyang Wu, Zili Zhang, Zhihao Bai, Xuanzhe Liu, and Xin Jin.
    2023. Transparent GPU Sharing in Container Clouds for Deep Learning Workloads.
    In *20th USENIX Symposium on Networked Systems Design and Implementation (NSDI
    23)*. 69–85.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu et al. (2023) Bingyang Wu, Zili Zhang, Zhihao Bai, Xuanzhe Liu, 和 Xin Jin.
    2023. 透明的 GPU 共享在容器云中的深度学习负载。在 *第20届 USENIX 网络系统设计与实现研讨会 (NSDI 23)*. 69–85.
- en: 'Xiao et al. (2018) Wencong Xiao, Romil Bhardwaj, Ramachandran Ramjee, Muthian
    Sivathanu, Nipun Kwatra, Zhenhua Han, Pratyush Patel, Xuan Peng, Hanyu Zhao, Quanlu
    Zhang, et al. 2018. Gandiva: Introspective cluster scheduling for deep learning.
    In *13th USENIX Symposium on Operating Systems Design and Implementation (OSDI
    18)*. 595–610.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xiao et al. (2018) Wencong Xiao, Romil Bhardwaj, Ramachandran Ramjee, Muthian
    Sivathanu, Nipun Kwatra, Zhenhua Han, Pratyush Patel, Xuan Peng, Hanyu Zhao, Quanlu
    Zhang, 等. 2018. Gandiva: 深度学习的自省集群调度。在 *第13届 USENIX 操作系统设计与实现研讨会 (OSDI 18)*. 595–610.'
- en: 'Xiao et al. (2020) Wencong Xiao, Shiru Ren, Yong Li, Yang Zhang, Pengyang Hou,
    Zhi Li, Yihui Feng, Wei Lin, and Yangqing Jia. 2020. AntMan: Dynamic scaling on
    GPU clusters for deep learning. In *14th USENIX Symposium on Operating Systems
    Design and Implementation (OSDI 20)*. 533–548.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xiao et al. (2020) Wencong Xiao, Shiru Ren, Yong Li, Yang Zhang, Pengyang Hou,
    Zhi Li, Yihui Feng, Wei Lin, 和 Yangqing Jia. 2020. AntMan: 深度学习的 GPU 集群动态扩展。在
    *第14届 USENIX 操作系统设计与实现研讨会 (OSDI 20)*. 533–548.'
- en: 'Xu et al. (2022) Fei Xu, Jianian Xu, Jiabin Chen, Li Chen, Ruitao Shang, Zhi
    Zhou, and Fangming Liu. 2022. igniter: Interference-aware gpu resource provisioning
    for predictable dnn inference in the cloud. *IEEE Transactions on Parallel and
    Distributed Systems* 34, 3 (2022), 812–827.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xu et al. (2022) Fei Xu, Jianian Xu, Jiabin Chen, Li Chen, Ruitao Shang, Zhi
    Zhou, 和 Fangming Liu. 2022. igniter: 面向可预测 DNN 推理的干扰感知 GPU 资源配置。*IEEE 并行与分布式系统汇刊*
    34, 3 (2022), 812–827.'
- en: Yang et al. (2023a) Jin Yang, Liang Bao, Wenjing Liu, Rong Yang, and Chase Q.
    Wu. 2023a. On a Meta Learning-Based Scheduler for Deep Learning Clusters. *IEEE
    Transactions on Cloud Computing* 11, 4 (2023), 3631–3642.
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2023a) Jin Yang, Liang Bao, Wenjing Liu, Rong Yang, 和 Chase Q.
    Wu. 2023a. 基于元学习的深度学习集群调度器。*IEEE 云计算汇刊* 11, 4 (2023), 3631–3642.
- en: 'Yang et al. (2023b) Zichao Yang, Heng Wu, Yuanjia Xu, Yuewen Wu, Hua Zhong,
    and Wenbo Zhang. 2023b. Hydra: Deadline-Aware and Efficiency-Oriented Scheduling
    for Deep Learning Jobs on Heterogeneous GPUs. *IEEE Trans. Comput.* 72, 8 (2023),
    2224–2236.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang et al. (2023b) Zichao Yang, Heng Wu, Yuanjia Xu, Yuewen Wu, Hua Zhong,
    和 Wenbo Zhang. 2023b. Hydra: 面向异构 GPU 的深度学习任务的截止时间感知和效率导向调度。*IEEE 计算机汇刊* 72, 8
    (2023), 2224–2236.'
- en: 'Yao et al. (2022) Jiangchao Yao, Shengyu Zhang, Yang Yao, Feng Wang, Jianxin
    Ma, Jianwei Zhang, Yunfei Chu, Luo Ji, Kunyang Jia, Tao Shen, et al. 2022. Edge-cloud
    polarization and collaboration: A comprehensive survey for ai. *IEEE Transactions
    on Knowledge and Data Engineering* 35, 7 (2022), 6866–6886.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2022) Jiangchao Yao, Shengyu Zhang, Yang Yao, Feng Wang, Jianxin
    Ma, Jianwei Zhang, Yunfei Chu, Luo Ji, Kunyang Jia, Tao Shen, 等。2022. 边缘-云极化与协作：AI
    的综合综述。*IEEE 知识与数据工程汇刊* 35, 7 (2022), 6866–6886。
- en: 'Ye et al. (2024a) Zhisheng Ye, Wei Gao, Qinghao Hu, Peng Sun, Xiaolin Wang,
    Yingwei Luo, Tianwei Zhang, and Yonggang Wen. 2024a. Deep Learning Workload Scheduling
    in GPU Datacenters: A Survey. *ACM Comput. Surv.* 56, 6 (jan 2024), 1–38.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ye et al. (2024a) Zhisheng Ye, Wei Gao, Qinghao Hu, Peng Sun, Xiaolin Wang,
    Yingwei Luo, Tianwei Zhang, 和 Yonggang Wen. 2024a. GPU 数据中心中的深度学习工作负载调度：综述。*ACM
    计算机调查* 56, 6 (2024年1月), 1–38。
- en: 'Ye et al. (2024b) Zhisheng Ye, Wei Gao, Qinghao Hu, Peng Sun, Xiaolin Wang,
    Yingwei Luo, Tianwei Zhang, and Yonggang Wen. 2024b. Deep Learning Workload Scheduling
    in GPU Datacenters: A Survey. *Comput. Surveys* 56, 6 (2024), 1–38.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ye et al. (2024b) Zhisheng Ye, Wei Gao, Qinghao Hu, Peng Sun, Xiaolin Wang,
    Yingwei Luo, Tianwei Zhang, 和 Yonggang Wen. 2024b. GPU 数据中心中的深度学习工作负载调度：综述。*计算机调查*
    56, 6 (2024), 1–38。
- en: 'Yeung et al. (2021) Gingfung Yeung, Damian Borowiec, Renyu Yang, Adrian Friday,
    Richard Harper, and Peter Garraghan. 2021. Horus: Interference-aware and prediction-based
    scheduling in deep learning systems. *IEEE Transactions on Parallel and Distributed
    Systems* 33, 1 (2021), 88–100.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yeung et al. (2021) Gingfung Yeung, Damian Borowiec, Renyu Yang, Adrian Friday,
    Richard Harper, 和 Peter Garraghan. 2021. Horus: 具有干扰感知和预测的深度学习系统调度。*IEEE 并行与分布式系统汇刊*
    33, 1 (2021), 88–100。'
- en: 'Yu et al. (2023) Enda Yu, Dezun Dong, and Xiangke Liao. 2023. Communication
    Optimization Algorithms for Distributed Deep Learning Systems: A Survey. *IEEE
    Transactions on Parallel and Distributed Systems* 34, 12 (2023), 3294–3308.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu et al. (2023) Enda Yu, Dezun Dong, 和 Xiangke Liao. 2023. 分布式深度学习系统的通信优化算法：综述。*IEEE
    并行与分布式系统汇刊* 34, 12 (2023), 3294–3308。
- en: Yu et al. (2021b) Menglu Yu, Chuan Wu, Bo Ji, and Jia Liu. 2021b. A Sum-of-Ratios
    Multi-Dimensional-Knapsack Decomposition for DNN Resource Scheduling. In *IEEE
    INFOCOM 2021 - IEEE Conference on Computer Communications*. 1–10.
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu et al. (2021b) Menglu Yu, Chuan Wu, Bo Ji, 和 Jia Liu. 2021b. 一种用于 DNN 资源调度的比率和多维背包分解方法。在
    *IEEE INFOCOM 2021 - IEEE 计算机通信会议*。1–10。
- en: 'Yu and Chowdhury (2020) Peifeng Yu and Mosharaf Chowdhury. 2020. Salus: Fine-grained
    gpu sharing primitives for deep learning applications. In *Proceedings of the
    3rd MLSys Conference*. 1–14.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yu 和 Chowdhury (2020) Peifeng Yu 和 Mosharaf Chowdhury. 2020. Salus: 深度学习应用的细粒度
    GPU 共享原语。在 *第3届 MLSys 会议论文集*。1–14。'
- en: 'Yu et al. (2021a) Peifeng Yu, Jiachen Liu, and Mosharaf Chowdhury. 2021a. Fluid:
    Resource-aware Hyperparameter Tuning Engine. In *Proceedings of Machine Learning
    and Systems*, Vol. 3\. 502–516.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yu et al. (2021a) Peifeng Yu, Jiachen Liu, 和 Mosharaf Chowdhury. 2021a. Fluid:
    资源感知超参数调优引擎。在 *机器学习与系统会议论文集*，第3卷。502–516。'
- en: Yuan et al. (2022) Binhang Yuan, Yongjun He, Jared Davis, Tianyi Zhang, Tri
    Dao, Beidi Chen, Percy S Liang, Christopher Re, and Ce Zhang. 2022. Decentralized
    training of foundation models in heterogeneous environments. *Advances in Neural
    Information Processing Systems* 35 (2022), 25464–25477.
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan et al. (2022) Binhang Yuan, Yongjun He, Jared Davis, Tianyi Zhang, Tri
    Dao, Beidi Chen, Percy S Liang, Christopher Re, 和 Ce Zhang. 2022. 异构环境中基础模型的去中心化训练。*神经信息处理系统进展*
    35 (2022), 25464–25477。
- en: Zeng et al. (2023) Fanlong Zeng, Wensheng Gan, Yongheng Wang, and S Yu Philip.
    2023. Distributed training of large language models. In *2023 IEEE 29th International
    Conference on Parallel and Distributed Systems (ICPADS)*. IEEE, 840–847.
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeng et al. (2023) Fanlong Zeng, Wensheng Gan, Yongheng Wang, 和 S Yu Philip.
    2023. 大型语言模型的分布式训练。在 *2023 IEEE 第29届国际并行与分布式系统会议 (ICPADS)*。IEEE, 840–847。
- en: Zhang et al. (2022) Cheng Zhang, Wanshou Jiang, Yuan Zhang, Wei Wang, Qing Zhao,
    and Chenjie Wang. 2022. Transformer and CNN hybrid deep neural network for semantic
    segmentation of very-high-resolution remote sensing imagery. *IEEE Transactions
    on Geoscience and Remote Sensing* 60 (2022), 1–20.
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2022) Cheng Zhang, Wanshou Jiang, Yuan Zhang, Wei Wang, Qing Zhao,
    和 Chenjie Wang. 2022. Transformer 和 CNN 混合深度神经网络用于非常高分辨率遥感影像的语义分割。*IEEE 地球科学与遥感汇刊*
    60 (2022), 1–20。
- en: 'Zhang et al. (2023a) Lin Zhang, Shaohuai Shi, Xiaowen Chu, Wei Wang, Bo Li,
    and Chengjian Liu. 2023a. DeAR: Accelerating Distributed Deep Learning with Fine-Grained
    All-Reduce Pipelining. In *2023 IEEE 43rd International Conference on Distributed
    Computing Systems (ICDCS)*. IEEE, 142–153.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. (2023a) 林张、邵怀石、晓文初、魏王、博李和程建刘。2023a。《DeAR: 通过细粒度全归约流水线加速分布式深度学习》。发表于*2023
    IEEE第43届国际分布式计算系统会议（ICDCS）*。IEEE，142–153。'
- en: 'Zhang et al. (2023b) Weigang Zhang, Biyu Zhou, Xuehai Tang, Zhaoxing Wang,
    and Songlin Hu. 2023b. MixPipe: Efficient Bidirectional Pipeline Parallelism for
    Training Large-Scale Models. In *2023 60th ACM/IEEE Design Automation Conference
    (DAC)*. IEEE, 1–6.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. (2023b) 伟刚张、碧玉周、雪海唐、兆星王和松林胡。2023b。《MixPipe: 高效双向流水线并行用于大规模模型训练》。发表于*2023年第60届ACM/IEEE设计自动化会议（DAC）*。IEEE，1–6。'
- en: 'Zhang et al. (2021) Zhenwei Zhang, Qiang Qi, Ruitao Shang, Li Chen, and Fei
    Xu. 2021. Prophet: Speeding up distributed dnn training with predictable communication
    scheduling. In *Proceedings of the 50th International Conference on Parallel Processing*.
    1–11.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. (2021) 振伟张、强齐、瑞涛尚、李陈和费徐。2021。《Prophet: 通过可预测的通信调度加速分布式DNN训练》。发表于*第50届国际并行处理会议论文集*。1–11。'
- en: Zhao et al. (2023b) Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei
    Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan
    Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li,
    Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023b. A Survey
    of Large Language Models. arXiv:2303.18223 [cs.CL]
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao et al. (2023b) 韦恩·辛赵、昆周、俊义李、天一唐、晓雷王、玉鹏侯、颖倩敏、贝晨张、俊杰张、子灿董、依凡杜、陈杨、雨硕陈、志鹏陈、进豪姜、瑞阳任、依凡李、新宇唐、子康刘、佩瑜刘、剑云聂和季荣温。2023b。《大语言模型调查》。arXiv:2303.18223
    [cs.CL]
- en: 'Zhao et al. (2023a) Yihao Zhao, Xin Liu, Shufan Liu, Xiang Li, Yibo Zhu, Gang
    Huang, Xuanzhe Liu, and Xin Jin. 2023a. Muxflow: Efficient and safe gpu sharing
    in large-scale production deep learning clusters. *arXiv preprint arXiv:2303.13803*
    (2023).'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao et al. (2023a) 易浩赵、辛刘、舒凡刘、项李、亿博朱、刚黄、轩哲刘和辛金。2023a。《Muxflow: 在大规模生产深度学习集群中的高效和安全GPU共享》。*arXiv预印本
    arXiv:2303.13803*（2023）。'
- en: 'Zheng et al. (2019) Haoyue Zheng, Fei Xu, Li Chen, Zhi Zhou, and Fangming Liu.
    2019. Cynthia: Cost-efficient cloud resource provisioning for predictable distributed
    deep neural network training. In *Proceedings of the 48th International Conference
    on Parallel Processing*. 1–11.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zheng et al. (2019) 郝悦郑、费徐、李陈、志周和方明刘。2019。《Cynthia: 经济高效的云资源配置用于可预测的分布式深度神经网络训练》。发表于*第48届国际并行处理会议论文集*。1–11。'
- en: 'Zhou et al. (2020) Pan Zhou, Xinshu He, Shouxi Luo, Hongfang Yu, and Gang Sun.
    2020. JPAS: Job-progress-aware flow scheduling for deep learning clusters. *Journal
    of Network and Computer Applications* (May 2020), 102590.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou et al. (2020) 潘周、辛舒赫、守希罗、洪芳余和刚孙。2020。《JPAS: 面向深度学习集群的作业进度感知流调度》。*网络与计算机应用杂志*（2020年5月），102590。'
- en: 'Zhou et al. (2019) Zhi Zhou, Xu Chen, En Li, Liekang Zeng, Ke Luo, and Junshan
    Zhang. 2019. Edge intelligence: Paving the last mile of artificial intelligence
    with edge computing. *Proc. IEEE* 107, 8 (2019), 1738–1762.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou et al. (2019) 志周、徐陈、恩李、李康曾、柯罗和军山张。2019。《边缘智能: 用边缘计算铺平人工智能的最后一公里》。*IEEE汇刊*
    107, 8 (2019), 1738–1762。'
