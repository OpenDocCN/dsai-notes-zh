- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: æœªåˆ†ç±»'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»åˆ«ï¼šæœªåˆ†ç±»
- en: 'date: 2024-09-06 19:50:33'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¥æœŸï¼š2024-09-06 19:50:33
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2110.06880] A Survey of Online Auction Mechanism Design Using Deep Learning
    Approaches'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2110.06880] ä½¿ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡ç»¼è¿°'
- en: æ¥æºï¼š[https://ar5iv.labs.arxiv.org/html/2110.06880](https://ar5iv.labs.arxiv.org/html/2110.06880)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://ar5iv.labs.arxiv.org/html/2110.06880](https://ar5iv.labs.arxiv.org/html/2110.06880)
- en: A Survey of Online Auction Mechanism Design Using Deep Learning Approaches
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡ç»¼è¿°
- en: Zhanhao Zhang
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å¼ å±•è±ª
- en: Department of Statistics
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç»Ÿè®¡å­¦ç³»
- en: Columbia University
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å“¥ä¼¦æ¯”äºšå¤§å­¦
- en: zz2760@columbia.edu
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: zz2760@columbia.edu
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: Online auction has been very widespread in the recent years. Platform administrators
    are working hard to refine their auction mechanisms that will generate high profits
    while maintaining a fair resource allocation. With the advancement of computing
    technology and the bottleneck in theoretical frameworks, researchers are shifting
    gears towards online auction designs using deep learning approaches. In this article,
    we summarized some common deep learning infrastructures adopted in auction mechanism
    designs and showed how these architectures are evolving. We also discussed how
    researchers are tackling with the constraints and concerns in the large and dynamic
    industrial settings. Finally, we pointed out several currently unresolved issues
    for future directions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çº¿æ‹å–åœ¨è¿‘å¹´æ¥å˜å¾—éå¸¸æ™®åŠã€‚å¹³å°ç®¡ç†å‘˜æ­£åœ¨åŠªåŠ›å®Œå–„ä»–ä»¬çš„æ‹å–æœºåˆ¶ï¼Œä»¥å®ç°é«˜åˆ©æ¶¦ï¼ŒåŒæ—¶ä¿æŒå…¬å¹³çš„èµ„æºåˆ†é…ã€‚éšç€è®¡ç®—æŠ€æœ¯çš„è¿›æ­¥å’Œç†è®ºæ¡†æ¶çš„ç“¶é¢ˆï¼Œç ”ç©¶äººå‘˜æ­£è½¬å‘ä½¿ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–è®¾è®¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ€»ç»“äº†ä¸€äº›åœ¨æ‹å–æœºåˆ¶è®¾è®¡ä¸­é‡‡ç”¨çš„å¸¸è§æ·±åº¦å­¦ä¹ åŸºç¡€è®¾æ–½ï¼Œå¹¶å±•ç¤ºäº†è¿™äº›æ¶æ„çš„æ¼”å˜è¿‡ç¨‹ã€‚æˆ‘ä»¬è¿˜è®¨è®ºäº†ç ”ç©¶äººå‘˜å¦‚ä½•åœ¨å¤§å‹å’ŒåŠ¨æ€çš„å·¥ä¸šç¯å¢ƒä¸­åº”å¯¹çº¦æŸå’Œå…³æ³¨ç‚¹ã€‚æœ€åï¼Œæˆ‘ä»¬æŒ‡å‡ºäº†å‡ ä¸ªç›®å‰å°šæœªè§£å†³çš„é—®é¢˜ï¼Œä»¥ä¾›æœªæ¥çš„ç ”ç©¶æ–¹å‘å‚è€ƒã€‚
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 ä»‹ç»
- en: Auction has been adopted as a way to negotiate the exchanges of goods and commodities
    for centuries. Traditionally, Generalized second price auction (GSP) and Vickreyâ€“Clarkeâ€“Groves
    auction (VCG) are widely used. However, GSP is no longer a truthful mechanism
    if a seller has more than one item to bid. VCG is an auction mechanism based on
    sealed-second price auction, where winners are charged on the reductions of social
    welfare of other participants. Nevertheless, the VCG mechanism generates low seller
    revenues and does not enforce monotinicity of sellerâ€™s revenues in the set of
    bidders and the amounts bid. It is also a non-truthful mechanism that is susceptible
    to multiple bids under same person or collusion of losing bidders [[5](#bib.bib5)].
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ‹å–ä½œä¸ºä¸€ç§äº¤æ¢å•†å“å’Œè´§ç‰©çš„æ–¹å¼å·²ç»è¢«é‡‡ç”¨äº†å‡ ä¸ªä¸–çºªã€‚ä¼ ç»Ÿä¸Šï¼Œå¹¿ä¹‰ç¬¬äºŒä»·æ ¼æ‹å–ï¼ˆGSPï¼‰å’Œç»´å…‹é›·-å…‹æ‹‰å…‹-æ ¼ç½—å¤«æ–¯æ‹å–ï¼ˆVCGï¼‰è¢«å¹¿æ³›ä½¿ç”¨ã€‚ç„¶è€Œï¼Œå¦‚æœå–æ–¹æœ‰å¤šä¸ªç‰©å“è¿›è¡Œç«æ ‡ï¼ŒGSP
    ä¸å†æ˜¯ä¸€ä¸ªçœŸå®çš„æœºåˆ¶ã€‚VCG æ˜¯ä¸€ç§åŸºäºå°é—­ç¬¬äºŒä»·æ ¼æ‹å–çš„æ‹å–æœºåˆ¶ï¼Œè·èƒœè€…æ ¹æ®å…¶ä»–å‚ä¸è€…ç¤¾ä¼šç¦åˆ©çš„å‡å°‘æ¥æ”¶å–è´¹ç”¨ã€‚ç„¶è€Œï¼ŒVCG æœºåˆ¶äº§ç”Ÿçš„å–æ–¹æ”¶å…¥è¾ƒä½ï¼Œå¹¶ä¸”æœªèƒ½åœ¨ç«æ ‡è€…é›†å’Œç«æ ‡é‡‘é¢ä¸­å¼ºåˆ¶å–æ–¹æ”¶å…¥çš„å•è°ƒæ€§ã€‚å®ƒä¹Ÿæ˜¯ä¸€ç§ä¸çœŸå®çš„æœºåˆ¶ï¼Œæ˜“å—åˆ°åŒä¸€äººå¤šæ¬¡ç«æ ‡æˆ–å¤±è´¥ç«æ ‡è€…çš„å‹¾ç»“[[5](#bib.bib5)]ã€‚
- en: Auction mechanisms with the properties of incentive compatiblility (IC) and
    individual rationality (IR) are highly desirable. If an auction is IC, then all
    bidders will truthfully reveal their private valuations of the items, so that
    platform administrators do not have the burden of considering biddersâ€™ strategic
    behaviors and are therefore able to build a reliable and predictable system. All
    agents are guaranteed to have non-negative utilities if the auction system is
    IR, and it is a very important feature that allows the system to retain its customers
    in the long run.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‹¥æœ‰æ¿€åŠ±å…¼å®¹æ€§ï¼ˆICï¼‰å’Œä¸ªä½“ç†æ€§ï¼ˆIRï¼‰å±æ€§çš„æ‹å–æœºåˆ¶éå¸¸ç†æƒ³ã€‚å¦‚æœä¸€ä¸ªæ‹å–æ˜¯ICçš„ï¼Œé‚£ä¹ˆæ‰€æœ‰ç«æ ‡è€…å°†çœŸå®åœ°æ­ç¤ºä»–ä»¬å¯¹ç‰©å“çš„ç§äººä¼°ä»·ï¼Œè¿™æ ·å¹³å°ç®¡ç†å‘˜å°±ä¸å¿…è€ƒè™‘ç«æ ‡è€…çš„ç­–ç•¥è¡Œä¸ºï¼Œå› æ­¤èƒ½å¤Ÿå»ºç«‹ä¸€ä¸ªå¯é ä¸”å¯é¢„æµ‹çš„ç³»ç»Ÿã€‚å¦‚æœæ‹å–ç³»ç»Ÿæ˜¯IRçš„ï¼Œé‚£ä¹ˆæ‰€æœ‰å‚ä¸è€…éƒ½ä¿è¯å…·æœ‰éè´Ÿæ•ˆç”¨ï¼Œè¿™æ˜¯ä¸€é¡¹éå¸¸é‡è¦çš„ç‰¹æ€§ï¼Œä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿåœ¨é•¿æœŸå†…ç•™ä½å®¢æˆ·ã€‚
- en: The groundbreaking work by Myerson [[20](#bib.bib20)] has defined the optimal
    strategyproof auction for selling a single item, but limited progress has been
    made in characterizing strategyproof and revenue-maximizing auctions beyond this
    setting [[14](#bib.bib14)]. The dynamic nature of online auction platforms [[6](#bib.bib6),
    [27](#bib.bib27), [31](#bib.bib31)] has made the problems more challenging, as
    the bidders, items, and platformâ€™s objectives are changing over time. In the meantime,
    multiple performance metrics are required to be taken into considerations in order
    to make the auction system attractive to bidders, sellers, and the platform [[16](#bib.bib16),
    [27](#bib.bib27), [31](#bib.bib31)].
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Myerson çš„å¼€åˆ›æ€§å·¥ä½œ[[20](#bib.bib20)]å®šä¹‰äº†é”€å”®å•ä¸€ç‰©å“çš„æœ€ä½³ç­–ç•¥æ— å…³æ‹å–ï¼Œä½†åœ¨æ­¤è®¾ç½®ä¹‹å¤–ï¼Œå¯¹äºç­–ç•¥æ— å…³å’Œæ”¶ç›Šæœ€å¤§åŒ–çš„æ‹å–çš„ç‰¹å¾åŒ–è¿›å±•æœ‰é™[[14](#bib.bib14)]ã€‚åœ¨çº¿æ‹å–å¹³å°çš„åŠ¨æ€æ€§è´¨[[6](#bib.bib6),
    [27](#bib.bib27), [31](#bib.bib31)]ä½¿é—®é¢˜å˜å¾—æ›´åŠ å¤æ‚ï¼Œå› ä¸ºç«æ ‡è€…ã€ç‰©å“å’Œå¹³å°çš„ç›®æ ‡éšç€æ—¶é—´çš„æ¨ç§»è€Œå˜åŒ–ã€‚åŒæ—¶ï¼Œéœ€è¦è€ƒè™‘å¤šä¸ªæ€§èƒ½æŒ‡æ ‡ï¼Œä»¥ä½¿æ‹å–ç³»ç»Ÿå¯¹ç«æ ‡è€…ã€å–å®¶å’Œå¹³å°å…·æœ‰å¸å¼•åŠ›[[16](#bib.bib16),
    [27](#bib.bib27), [31](#bib.bib31)]ã€‚
- en: With the advancement of technology, researchers are shifting gears towards deep
    learning approaches for the design of auction mechanisms. To the best of our knowledge,
    the deep learning architecture is built on top of either the hybrid multiple linear
    perceptron infrastructure, the RegretNet infrastructure [[9](#bib.bib9)], the
    reinforcement learning infrastructure, or the DeepSet infrastructure [[30](#bib.bib30)].
    Blessed with the modern computing power, researchers are not only able to maximize
    the revenue, but also dealing with data sparsity and high-dimensional data, optimizing
    multiple performance metrics, preventing fraud, and enhancing fairness.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€æŠ€æœ¯çš„è¿›æ­¥ï¼Œç ”ç©¶äººå‘˜æ­£åœ¨å°†ç„¦ç‚¹è½¬å‘æ·±åº¦å­¦ä¹ æ–¹æ³•æ¥è®¾è®¡æ‹å–æœºåˆ¶ã€‚æ ¹æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæ·±åº¦å­¦ä¹ æ¶æ„å»ºç«‹åœ¨æ··åˆå¤šå±‚æ„ŸçŸ¥æœºåŸºç¡€è®¾æ–½ã€RegretNetåŸºç¡€è®¾æ–½[[9](#bib.bib9)]ã€å¼ºåŒ–å­¦ä¹ åŸºç¡€è®¾æ–½æˆ–DeepSetåŸºç¡€è®¾æ–½[[30](#bib.bib30)]ä¹‹ä¸Šã€‚å¾—ç›Šäºç°ä»£è®¡ç®—èƒ½åŠ›ï¼Œç ”ç©¶äººå‘˜ä¸ä»…èƒ½å¤Ÿæœ€å¤§åŒ–æ”¶ç›Šï¼Œè¿˜èƒ½å¤„ç†æ•°æ®ç¨€ç–æ€§å’Œé«˜ç»´æ•°æ®ï¼Œä¼˜åŒ–å¤šä¸ªæ€§èƒ½æŒ‡æ ‡ï¼Œé˜²æ­¢æ¬ºè¯ˆï¼Œå¹¶æå‡å…¬å¹³æ€§ã€‚
- en: 'This article is organized as follows: we will first introduce the four common
    infrastructure of the deep neural networks for auction mechanism design. Then,
    we will discuss how researchers are tackling with the constraints and concerns
    other than maximizing the total revenue. Lastly, we will point out some unresolved
    issues and potential future directions.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡ç»„ç»‡ç»“æ„å¦‚ä¸‹ï¼šæˆ‘ä»¬å°†é¦–å…ˆä»‹ç»æ‹å–æœºåˆ¶è®¾è®¡ä¸­æ·±åº¦ç¥ç»ç½‘ç»œçš„å››ç§å¸¸è§åŸºç¡€è®¾æ–½ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å°†è®¨è®ºç ”ç©¶äººå‘˜å¦‚ä½•è§£å†³é™¤æœ€å¤§åŒ–æ€»æ”¶ç›Šä¹‹å¤–çš„çº¦æŸå’Œé—®é¢˜ã€‚æœ€åï¼Œæˆ‘ä»¬å°†æŒ‡å‡ºä¸€äº›æœªè§£å†³çš„é—®é¢˜å’Œæ½œåœ¨çš„æœªæ¥æ–¹å‘ã€‚
- en: 2 Hybrid Multiple Linear Perceptron (MLP) Infrastructure
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 æ··åˆå¤šå±‚æ„ŸçŸ¥æœº (MLP) åŸºç¡€è®¾æ–½
- en: Many neural network structures are built by stacking several MLP structure into
    a cohesive one [[24](#bib.bib24), [32](#bib.bib32), [25](#bib.bib25), [17](#bib.bib17)].
    The network is usually comprised of more than one components, where each components
    is a fully-connected feedforward neural network.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šç¥ç»ç½‘ç»œç»“æ„é€šè¿‡å°†å‡ ä¸ªMLPç»“æ„å †å æˆä¸€ä¸ªè¿è´¯çš„ç½‘ç»œæ¥æ„å»º[[24](#bib.bib24), [32](#bib.bib32), [25](#bib.bib25),
    [17](#bib.bib17)]ã€‚è¯¥ç½‘ç»œé€šå¸¸ç”±å¤šä¸ªç»„ä»¶ç»„æˆï¼Œæ¯ä¸ªç»„ä»¶æ˜¯ä¸€ä¸ªå®Œå…¨è¿æ¥çš„å‰é¦ˆç¥ç»ç½‘ç»œã€‚
- en: The most delicate architecture is the MenuNet [[24](#bib.bib24)], which is comprised
    of a mechanism network and a buyer network. The mechanism takes a one-dimensional
    1 as input and outputs an allocation matrix and a pricing vector. The allocation
    matrix contains the allocation of all items, which is obtained by a fully-connected
    layer followed by a sigmoid activation function. The payment vector is obtained
    by simply multiplying the constant 1 by a vector and it is used to represent the
    prices for different menu items. The buyer network doesnâ€™t require any training.
    It takes the outputs from the mechanism network and computes the final utility
    based on buyerâ€™s value profile. The training of MenuNet is very fast as the network
    structure is very simple. It is built upon the taxation principle [[28](#bib.bib28)],
    which states that simply letting the buyer do the selection can give an IC mechanism.
    It does not require buyerâ€™s utility function since the network only outputs buyerâ€™s
    strategy. It does not make any assumptions about buyerâ€™s valuation and does not
    require any additional constraints (such as IC and IR) to be enforced to the network.
    Theoretical proofs have shown that the MenuNet always return revenue optimal mechanism
    with IC satisfied for menus of size 2 or 3.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç²¾è‡´çš„æ¶æ„æ˜¯ MenuNet [[24](#bib.bib24)]ï¼Œå®ƒç”±æœºåˆ¶ç½‘ç»œå’Œä¹°å®¶ç½‘ç»œç»„æˆã€‚æœºåˆ¶ç½‘ç»œä»¥ä¸€ç»´ 1 ä¸ºè¾“å…¥ï¼Œè¾“å‡ºåˆ†é…çŸ©é˜µå’Œå®šä»·å‘é‡ã€‚åˆ†é…çŸ©é˜µåŒ…å«æ‰€æœ‰ç‰©å“çš„åˆ†é…ï¼Œè¯¥çŸ©é˜µé€šè¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚åŠå…¶åè·Ÿçš„
    sigmoid æ¿€æ´»å‡½æ•°è·å¾—ã€‚æ”¯ä»˜å‘é‡æ˜¯é€šè¿‡å°†å¸¸æ•° 1 ä¹˜ä»¥ä¸€ä¸ªå‘é‡è·å¾—çš„ï¼Œç”¨äºè¡¨ç¤ºä¸åŒèœå•é¡¹çš„ä»·æ ¼ã€‚ä¹°å®¶ç½‘ç»œä¸éœ€è¦ä»»ä½•è®­ç»ƒã€‚å®ƒä»æœºåˆ¶ç½‘ç»œè·å–è¾“å‡ºï¼Œå¹¶æ ¹æ®ä¹°å®¶çš„ä»·å€¼é…ç½®è®¡ç®—æœ€ç»ˆæ•ˆç”¨ã€‚ç”±äºç½‘ç»œç»“æ„éå¸¸ç®€å•ï¼ŒMenuNet
    çš„è®­ç»ƒéå¸¸å¿«ã€‚å®ƒåŸºäºç¨æ”¶åŸåˆ™ [[28](#bib.bib28)]ï¼Œè¯¥åŸåˆ™è¡¨æ˜ï¼Œä»…è®©ä¹°å®¶è¿›è¡Œé€‰æ‹©å³å¯æä¾› IC æœºåˆ¶ã€‚å®ƒä¸éœ€è¦ä¹°å®¶çš„æ•ˆç”¨å‡½æ•°ï¼Œå› ä¸ºç½‘ç»œåªè¾“å‡ºä¹°å®¶çš„ç­–ç•¥ã€‚å®ƒä¸å¯¹ä¹°å®¶çš„ä¼°å€¼åšä»»ä½•å‡è®¾ï¼Œä¹Ÿä¸éœ€è¦å¯¹ç½‘ç»œæ–½åŠ ä»»ä½•é¢å¤–çš„çº¦æŸï¼ˆå¦‚
    IC å’Œ IRï¼‰ã€‚ç†è®ºè¯æ˜è¡¨æ˜ï¼ŒMenuNet æ€»æ˜¯è¿”å›åœ¨èœå•å¤§å°ä¸º 2 æˆ– 3 æ—¶ IC æ»¡è¶³çš„æ”¶å…¥æœ€ä¼˜æœºåˆ¶ã€‚
- en: Zhou et al has proposed Deep Interest Network [[32](#bib.bib32)] for the use
    of click-through rate prediction. It is built on the structure of MLP but aims
    to conquer the bottleneck caused by the fixed-length representation vector used
    in traditional MLP, which has limited ability in capturing userâ€™s diverse interests
    from rich historical behaviors. The authors designed a local activation unit that
    can adaptively learn the representation of user interests from historical behaviors
    with respect to a certain advertisements. The data adaptive activation they adopted
    is Dice (Equation [1](#S2.E1 "In 2 Hybrid Multiple Linear Perceptron (MLP) Infrastructure
    â€£ A Survey of Online Auction Mechanism Design Using Deep Learning Approaches")),
    which is a generalization of PReLu [[13](#bib.bib13)].
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Zhou ç­‰äººæå‡ºäº†ç”¨äºç‚¹å‡»ç‡é¢„æµ‹çš„ Deep Interest Network [[32](#bib.bib32)]ã€‚è¯¥ç½‘ç»œåŸºäº MLP ç»“æ„ï¼Œä½†æ—¨åœ¨è§£å†³ä¼ ç»Ÿ
    MLP ä¸­å›ºå®šé•¿åº¦è¡¨ç¤ºå‘é‡æ‰€å¸¦æ¥çš„ç“¶é¢ˆï¼Œè¿™ç§å›ºå®šé•¿åº¦è¡¨ç¤ºå‘é‡åœ¨æ•æ‰ç”¨æˆ·ä¸°å¯Œå†å²è¡Œä¸ºä¸­çš„å¤šæ ·å…´è¶£æ–¹é¢èƒ½åŠ›æœ‰é™ã€‚ä½œè€…è®¾è®¡äº†ä¸€ç§å±€éƒ¨æ¿€æ´»å•å…ƒï¼Œèƒ½å¤Ÿæ ¹æ®ç‰¹å®šå¹¿å‘Šä»å†å²è¡Œä¸ºä¸­è‡ªé€‚åº”åœ°å­¦ä¹ ç”¨æˆ·å…´è¶£çš„è¡¨ç¤ºã€‚ä»–ä»¬é‡‡ç”¨çš„æ•°æ®è‡ªé€‚åº”æ¿€æ´»æ˜¯
    Diceï¼ˆæ–¹ç¨‹ [1](#S2.E1 "åœ¨ 2 æ··åˆå¤šå±‚æ„ŸçŸ¥å™¨ (MLP) åŸºç¡€è®¾æ–½ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒæŸ¥")ï¼‰ï¼Œè¿™æ˜¯ PReLu [[13](#bib.bib13)]
    çš„ä¸€ç§æ¨å¹¿ã€‚
- en: '|  | $f(s)=p(s)\cdot s+(1-p(s))\cdot\alpha s,p(s)=\frac{1}{1+e^{-\frac{s-E[s]}{\sqrt{Var[s]+\epsilon}}}}$
    |  | (1) |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '|  | $f(s)=p(s)\cdot s+(1-p(s))\cdot\alpha s,p(s)=\frac{1}{1+e^{-\frac{s-E[s]}{\sqrt{Var[s]+\epsilon}}}}$
    |  | (1) |'
- en: In the training phase, $E[s]$ and $Var[s]$ are the mean and variance of input
    in each-minibatch, while in the testing phase, $E[s]$ and $Var[s]$ are moving
    averages of $E[s]$ and $Var[s]$ over data. $\epsilon$ is a small constant and
    is set to be $10^{-8}$ by authors.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒé˜¶æ®µï¼Œ$E[s]$ å’Œ $Var[s]$ æ˜¯æ¯ä¸ªå°æ‰¹é‡è¾“å…¥çš„å‡å€¼å’Œæ–¹å·®ï¼Œè€Œåœ¨æµ‹è¯•é˜¶æ®µï¼Œ$E[s]$ å’Œ $Var[s]$ æ˜¯æ•°æ®ä¸Š $E[s]$
    å’Œ $Var[s]$ çš„ç§»åŠ¨å¹³å‡ã€‚$\epsilon$ æ˜¯ä¸€ä¸ªå°å¸¸æ•°ï¼Œä½œè€…å°†å…¶è®¾ç½®ä¸º $10^{-8}$ã€‚
- en: They adopt different representation vector for different ads. The embedding
    layer uses single embedding vector (one-hot) and multiple embedding vectors (multi-hot)
    in combination. Pooling and concat layers are added to transform the list of embedding
    vectors into the same lengths, so that the network can allow different users to
    have different number of behaviors.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬å¯¹ä¸åŒçš„å¹¿å‘Šé‡‡ç”¨ä¸åŒçš„è¡¨ç¤ºå‘é‡ã€‚åµŒå…¥å±‚ç»“åˆäº†å•ä¸€åµŒå…¥å‘é‡ï¼ˆone-hotï¼‰å’Œå¤šä¸ªåµŒå…¥å‘é‡ï¼ˆmulti-hotï¼‰ã€‚æ·»åŠ äº†æ± åŒ–å’Œè¿æ¥å±‚ï¼Œå°†åµŒå…¥å‘é‡åˆ—è¡¨è½¬æ¢ä¸ºç›¸åŒé•¿åº¦ï¼Œä»¥ä¾¿ç½‘ç»œå¯ä»¥å…è®¸ä¸åŒç”¨æˆ·æœ‰ä¸åŒæ•°é‡çš„è¡Œä¸ºã€‚
- en: Shin et al transformed the charging scheduling problem into an auction problem
    using deep learning framework [[25](#bib.bib25)]. It is designed based on the
    concept of the Myerson auction [[20](#bib.bib20)], which is one of the most efficient
    revenue-optimal single-item auctions. One of the most challenging issues about
    charging scheduling is the lack of prior knowledge on the distribution of the
    number of bidders. Employing the auction approach is useful when there is no accurate
    information of buyerâ€™s true valuation, and buyers are not aware of the private
    true values of other buyers. Buyerâ€™s values are represented by the urgency of
    drone machines, while sellerâ€™s revenue is generated from the payment from resource
    allocation. As Myersonâ€™s auction system requires full knowledge of the distribution
    of bids in order to compute the expected payment, Shin et al used deep neural
    network to parametrize the virtual valuation function, the allocaton rule, and
    the payment rule.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Shin ç­‰äººä½¿ç”¨æ·±åº¦å­¦ä¹ æ¡†æ¶å°†å……ç”µè°ƒåº¦é—®é¢˜è½¬åŒ–ä¸ºæ‹å–é—®é¢˜[[25](#bib.bib25)]ã€‚è¯¥è®¾è®¡åŸºäºMyersonæ‹å–çš„æ¦‚å¿µ[[20](#bib.bib20)]ï¼Œè¿™æ˜¯æœ€æœ‰æ•ˆçš„å•é¡¹æ‹å–ä¹‹ä¸€ï¼Œèƒ½å¤Ÿå®ç°æ”¶å…¥æœ€ä¼˜åŒ–ã€‚å……ç”µè°ƒåº¦çš„ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜æ˜¯å¯¹ç«æ ‡è€…æ•°é‡åˆ†å¸ƒç¼ºä¹å…ˆéªŒçŸ¥è¯†ã€‚å½“ä¹°å®¶çš„çœŸå®ä¼°å€¼ä¿¡æ¯ä¸å‡†ç¡®ï¼Œä¸”ä¹°å®¶ä¸çŸ¥é“å…¶ä»–ä¹°å®¶çš„ç§äººçœŸå®ä»·å€¼æ—¶ï¼Œä½¿ç”¨æ‹å–æ–¹æ³•éå¸¸æœ‰ç”¨ã€‚ä¹°å®¶çš„ä»·å€¼ç”±æ— äººæœºçš„ç´§è¿«æ€§è¡¨ç¤ºï¼Œè€Œå–å®¶çš„æ”¶å…¥æ¥è‡ªäºèµ„æºåˆ†é…çš„æ”¯ä»˜ã€‚ç”±äºMyersonæ‹å–ç³»ç»Ÿè¦æ±‚å®Œå…¨äº†è§£ç«æ ‡åˆ†å¸ƒä»¥è®¡ç®—æœŸæœ›æ”¯ä»˜ï¼ŒShin
    ç­‰äººä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œå¯¹è™šæ‹Ÿä¼°å€¼å‡½æ•°ã€åˆ†é…è§„åˆ™å’Œæ”¯ä»˜è§„åˆ™è¿›è¡Œå‚æ•°åŒ–ã€‚
- en: The network begins with a monotonic network that transforms the bids $b_{i}$
    of the drone into $\bar{b}_{i}$ using the virtual valuation function $\phi^{mononet}$
    parametrized by the network. In the $\phi^{mononet}$, all outcomes of $\phi^{shared}$
    (Equation [3](#S2.E3 "In 2 Hybrid Multiple Linear Perceptron (MLP) Infrastructure
    â€£ A Survey of Online Auction Mechanism Design Using Deep Learning Approaches"))
    are computed using the same weights, while the $\phi_{i}$ (Equation [2](#S2.E2
    "In 2 Hybrid Multiple Linear Perceptron (MLP) Infrastructure â€£ A Survey of Online
    Auction Mechanism Design Using Deep Learning Approaches")) calculates the outcome
    using different weights for each bid.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ç½‘ç»œä»ä¸€ä¸ªå•è°ƒç½‘ç»œå¼€å§‹ï¼Œè¯¥ç½‘ç»œä½¿ç”¨ç”±ç½‘ç»œå‚æ•°åŒ–çš„è™šæ‹Ÿä¼°å€¼å‡½æ•°$\phi^{mononet}$å°†æ— äººæœºçš„ç«æ ‡ $b_{i}$ è½¬æ¢ä¸º $\bar{b}_{i}$ã€‚åœ¨
    $\phi^{mononet}$ ä¸­ï¼Œ$\phi^{shared}$ çš„æ‰€æœ‰ç»“æœï¼ˆæ–¹ç¨‹[3](#S2.E3 "åœ¨2æ··åˆå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰åŸºç¡€è®¾æ–½ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”")ï¼‰éƒ½ä½¿ç”¨ç›¸åŒçš„æƒé‡è®¡ç®—ï¼Œè€Œ
    $\phi_{i}$ï¼ˆæ–¹ç¨‹[2](#S2.E2 "åœ¨2æ··åˆå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰åŸºç¡€è®¾æ–½ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”")ï¼‰åˆ™ä½¿ç”¨ä¸åŒçš„æƒé‡è®¡ç®—æ¯ä¸ªç«æ ‡çš„ç»“æœã€‚
- en: '|  | $b_{i}^{\prime}=\phi_{i}(b_{i})=\min_{1\leq g\leq\mathcal{G}}\{\max_{1\leq
    n\leq\mathcal{N}}(w_{g,n}^{i}b_{i}+\beta_{g,n}^{i})\}$ |  | (2) |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '|  | $b_{i}^{\prime}=\phi_{i}(b_{i})=\min_{1\leq g\leq\mathcal{G}}\{\max_{1\leq
    n\leq\mathcal{N}}(w_{g,n}^{i}b_{i}+\beta_{g,n}^{i})\}$ |  | (2) |'
- en: '|  | $\bar{b}_{i}=\phi_{i}^{shared}(b_{i}^{\prime})=\min_{1\leq g\leq\mathcal{G}}\{\max_{1\leq
    n\leq\mathcal{N}}(w_{g,n}^{shared}b_{i}^{\prime}+\beta_{g,n}^{shared})\}$ |  |
    (3) |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '|  | $\bar{b}_{i}=\phi_{i}^{shared}(b_{i}^{\prime})=\min_{1\leq g\leq\mathcal{G}}\{\max_{1\leq
    n\leq\mathcal{N}}(w_{g,n}^{shared}b_{i}^{\prime}+\beta_{g,n}^{shared})\}$ |  |
    (3) |'
- en: The payment rule network takes in the output $\bar{b}_{i}$ from the monotonic
    network and returns $\bar{p}_{i}$ according to Equation [4](#S2.E4 "In 2 Hybrid
    Multiple Linear Perceptron (MLP) Infrastructure â€£ A Survey of Online Auction Mechanism
    Design Using Deep Learning Approaches"). Then, the payment value is computed using
    the inverse function of $\phi^{mononet}$ (Equation [5](#S2.E5 "In 2 Hybrid Multiple
    Linear Perceptron (MLP) Infrastructure â€£ A Survey of Online Auction Mechanism
    Design Using Deep Learning Approaches"), [6](#S2.E6 "In 2 Hybrid Multiple Linear
    Perceptron (MLP) Infrastructure â€£ A Survey of Online Auction Mechanism Design
    Using Deep Learning Approaches")). Finally, the allocation rule network assigns
    the highest winning probability to the highest bidder with positive transformed
    bid.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ”¯ä»˜è§„åˆ™ç½‘ç»œæ¥æ”¶æ¥è‡ªå•è°ƒç½‘ç»œçš„è¾“å‡º $\bar{b}_{i}$ï¼Œå¹¶æ ¹æ®æ–¹ç¨‹[4](#S2.E4 "åœ¨2æ··åˆå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰åŸºç¡€è®¾æ–½ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”")
    è¿”å› $\bar{p}_{i}$ã€‚ç„¶åï¼Œæ”¯ä»˜å€¼ä½¿ç”¨ $\phi^{mononet}$ çš„é€†å‡½æ•°ï¼ˆæ–¹ç¨‹[5](#S2.E5 "åœ¨2æ··åˆå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰åŸºç¡€è®¾æ–½
    â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”")ï¼Œ[6](#S2.E6 "åœ¨2æ··åˆå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰åŸºç¡€è®¾æ–½ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”")ï¼‰è®¡ç®—ã€‚æœ€åï¼Œåˆ†é…è§„åˆ™ç½‘ç»œå°†æœ€é«˜çš„èƒœå‡ºæ¦‚ç‡åˆ†é…ç»™å…·æœ‰æ­£å˜æ¢ç«æ ‡çš„æœ€é«˜ç«æ ‡è€…ã€‚
- en: '|  | $\bar{p}_{i}=ReLU\{\max_{j\neq i}(\bar{b}_{i})\}$ |  | (4) |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '|  | $\bar{p}_{i}=ReLU\{\max_{j\neq i}(\bar{b}_{i})\}$ |  | (4) |'
- en: '|  | $p_{i}^{\prime}=\phi_{shared}^{-1}(\bar{p}_{i})=\max_{1\leq g\leq\mathcal{G}}\{\min_{1\leq
    n\leq\mathcal{N}}(w_{g,n}^{shared})^{-1}(\bar{p}_{i}-\beta_{g,n}^{shared})\}$
    |  | (5) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '|  | $p_{i}^{\prime}=\phi_{shared}^{-1}(\bar{p}_{i})=\max_{1\leq g\leq\mathcal{G}}\{\min_{1\leq
    n\leq\mathcal{N}}(w_{g,n}^{shared})^{-1}(\bar{p}_{i}-\beta_{g,n}^{shared})\}$
    |  | (5) |'
- en: '|  | $p_{i}=\phi_{i}^{-1}(p_{i}^{\prime})=\max_{1\leq g\leq\mathcal{G}}\{\min_{1\leq
    n\leq\mathcal{N}}(w_{g,n}^{i})^{-1}(p_{i}^{\prime}-\beta_{g,n}^{i})\}$ |  | (6)
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '|  | $p_{i}=\phi_{i}^{-1}(p_{i}^{\prime})=\max_{1\leq g\leq\mathcal{G}}\{\min_{1\leq
    n\leq\mathcal{N}}(w_{g,n}^{i})^{-1}(p_{i}^{\prime}-\beta_{g,n}^{i})\}$ |  | (6)
    |'
- en: 'Luong et al constructed a neural network [[17](#bib.bib17)] for edge computing
    resource management based on analytical solution [[20](#bib.bib20)], which guarantees
    the revenue maximization while ensuring the IC and IR. The network structure also
    has three key components as in [[25](#bib.bib25)]: neural network parametrized
    monotone transformation functions that map bids into transformed versions, an
    allocation rule that maps the transformed bids to a vector of assignment probabilities,
    and a conditional payment rule that is based on the maximum non-negative transformed
    bids. The allocation and payment rules are derived from SPA-0, second price auction
    with 0 reserve price, where the reserve price is the mininum price a seller is
    willing to accept from the buyer.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Luong ç­‰äººåŸºäºåˆ†æè§£ [[20](#bib.bib20)] æ„å»ºäº†ä¸€ç§ç¥ç»ç½‘ç»œ [[17](#bib.bib17)] ç”¨äºè¾¹ç¼˜è®¡ç®—èµ„æºç®¡ç†ï¼Œè¯¥ç½‘ç»œåœ¨ç¡®ä¿
    IC å’Œ IR çš„åŒæ—¶ä¿è¯äº†æ”¶å…¥æœ€å¤§åŒ–ã€‚ç½‘ç»œç»“æ„è¿˜å…·æœ‰ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼Œå¦‚ [[25](#bib.bib25)] ä¸­æ‰€ç¤ºï¼šå°†ç«æ ‡è½¬åŒ–ä¸ºè½¬æ¢ç‰ˆæœ¬çš„å•è°ƒå˜æ¢å‡½æ•°çš„ç¥ç»ç½‘ç»œå‚æ•°åŒ–ã€å°†è½¬æ¢åçš„ç«æ ‡æ˜ å°„åˆ°åˆ†é…æ¦‚ç‡å‘é‡çš„åˆ†é…è§„åˆ™ï¼Œä»¥åŠåŸºäºæœ€å¤§éè´Ÿè½¬æ¢ç«æ ‡çš„æ¡ä»¶æ”¯ä»˜è§„åˆ™ã€‚åˆ†é…å’Œæ”¯ä»˜è§„åˆ™æ˜¯ä»
    SPA-0 æ¨å¯¼å‡ºçš„ï¼Œå³å…·æœ‰ 0 ä¿ç•™ä»·çš„ç¬¬äºŒä»·æ ¼æ‹å–ï¼Œå…¶ä¸­ä¿ç•™ä»·æ˜¯å–å®¶æ„¿æ„ä»ä¹°å®¶é‚£é‡Œæ¥å—çš„æœ€ä½ä»·æ ¼ã€‚
- en: 'RochetNet [[9](#bib.bib9)] proposed by Dutting et al. is also an application
    of MLP. The RochetNet is a single-layered neural network that takes in the bids
    and outputs the maximum non-negative transformed values. It is used to model a
    non-negative, monotone, convex, and Lipschitz utility function, using $J$ linear
    functions with non-negative coefficients. The RochetNet easily extends to a single
    bidder with a unit-demand valuation Â¹Â¹1Unit-demand valuation: the value of a subset
    is the maximum individual valuation within that subset.. Each linear function
    in the RochetNet corresponds to an option on the menue, with the allocation probabilities
    and payments encoded through its slope and intercept.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Dutting ç­‰äººæå‡ºçš„ RochetNet [[9](#bib.bib9)] ä¹Ÿæ˜¯ MLP çš„ä¸€ç§åº”ç”¨ã€‚RochetNet æ˜¯ä¸€ç§å•å±‚ç¥ç»ç½‘ç»œï¼Œå®ƒæ¥æ”¶ç«æ ‡å¹¶è¾“å‡ºæœ€å¤§éè´Ÿè½¬æ¢å€¼ã€‚å®ƒç”¨äºå»ºæ¨¡éè´Ÿã€å•è°ƒã€å‡¸å’Œ
    Lipschitz æ•ˆç”¨å‡½æ•°ï¼Œä½¿ç”¨ $J$ ä¸ªå…·æœ‰éè´Ÿç³»æ•°çš„çº¿æ€§å‡½æ•°ã€‚RochetNet å¾ˆå®¹æ˜“æ‰©å±•åˆ°å…·æœ‰å•ä½éœ€æ±‚ä¼°å€¼çš„å•ä¸€ç«æ ‡è€…Â¹Â¹å•ä½éœ€æ±‚ä¼°å€¼ï¼šå­é›†çš„ä»·å€¼æ˜¯è¯¥å­é›†å†…çš„æœ€å¤§ä¸ªäººä¼°å€¼ã€‚RochetNet
    ä¸­çš„æ¯ä¸ªçº¿æ€§å‡½æ•°å¯¹åº”äºèœå•ä¸Šçš„ä¸€ä¸ªé€‰é¡¹ï¼Œå…¶åˆ†é…æ¦‚ç‡å’Œæ”¯ä»˜é€šè¿‡å…¶æ–œç‡å’Œæˆªè·è¿›è¡Œç¼–ç ã€‚
- en: The MoulinNet [[11](#bib.bib11)] proposed by Golowich et al. also adopts the
    structure of MLP, which is used to determine the optimal facility locations preferred
    by agents. MoulinNet is a monotone feed-forward neural network that learns the
    generalized median rules [[19](#bib.bib19)]. For single-facility mechanisms, the
    mechanism in Equation [7](#S2.E7 "In 2 Hybrid Multiple Linear Perceptron (MLP)
    Infrastructure â€£ A Survey of Online Auction Mechanism Design Using Deep Learning
    Approaches") is strategy-proof, which selects the median of agentsâ€™ most preferred
    locations (the agentsâ€™ peaks). The inputs of the network are binary-encoded vectors
    $\nu(S)$ that represent whether the bidded items in $S$ are selected. $w$ and
    $b$ are parameters in MoulinNet. The $u_{i}$ is the utility function for agent
    $i$ and $\tau$ represents the peaks of the facility. The output of the network
    is the optimal selection rules based on utilities.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Golowich ç­‰äººæå‡ºçš„ MoulinNet [[11](#bib.bib11)] ä¹Ÿé‡‡ç”¨äº† MLP çš„ç»“æ„ï¼Œç”¨äºç¡®å®šä»£ç†äººåå¥½çš„æœ€ä¼˜è®¾æ–½ä½ç½®ã€‚MoulinNet
    æ˜¯ä¸€ç§å•è°ƒå‰é¦ˆç¥ç»ç½‘ç»œï¼Œå®ƒå­¦ä¹ å¹¿ä¹‰ä¸­ä½æ•°è§„åˆ™ [[19](#bib.bib19)]ã€‚å¯¹äºå•è®¾æ–½æœºåˆ¶ï¼Œæ–¹ç¨‹ [7](#S2.E7 "åœ¨ 2 æ··åˆå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰åŸºç¡€è®¾æ–½
    â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡ç»¼è¿°") ä¸­çš„æœºåˆ¶æ˜¯ç­–ç•¥æ— å…³çš„ï¼Œå®ƒé€‰æ‹©ä»£ç†äººæœ€åå¥½çš„ä½ç½®çš„ä¸­ä½æ•°ï¼ˆä»£ç†äººçš„å³°å€¼ï¼‰ã€‚ç½‘ç»œçš„è¾“å…¥æ˜¯äºŒè¿›åˆ¶ç¼–ç å‘é‡ $\nu(S)$ï¼Œè¡¨ç¤º
    $S$ ä¸­ç«æ ‡çš„é¡¹ç›®æ˜¯å¦è¢«é€‰æ‹©ã€‚$w$ å’Œ $b$ æ˜¯ MoulinNet ä¸­çš„å‚æ•°ã€‚$u_{i}$ æ˜¯ä»£ç†äºº $i$ çš„æ•ˆç”¨å‡½æ•°ï¼Œ$\tau$ è¡¨ç¤ºè®¾æ–½çš„å³°å€¼ã€‚ç½‘ç»œçš„è¾“å‡ºæ˜¯åŸºäºæ•ˆç”¨çš„æœ€ä¼˜é€‰æ‹©è§„åˆ™ã€‚
- en: '|  | $f^{w,b}(u)=\min_{S\subseteq N}\{\max_{i\in S}\{\tau(u_{i}),h^{w,b}(\nu(S))\}\}$
    |  | (7) |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  | $f^{w,b}(u)=\min_{S\subseteq N}\{\max_{i\in S}\{\tau(u_{i}),h^{w,b}(\nu(S))\}\}$
    |  | (7) |'
- en: 3 RegretNet Infrastructure
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 RegretNet åŸºç¡€è®¾æ–½
- en: The RegretNet [[9](#bib.bib9)] proposed by Dutting et al is comprised of an
    allocation network and a payment network. Both are built upon the MLP infrastructure,
    but the RegretNet has been adopted and extended in the auction designs in various
    settings [[10](#bib.bib10), [11](#bib.bib11), [21](#bib.bib21), [14](#bib.bib14)].
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: RegretNet [[9](#bib.bib9)]ç”±Duttingç­‰äººæå‡ºï¼ŒåŒ…å«ä¸€ä¸ªåˆ†é…ç½‘ç»œå’Œä¸€ä¸ªæ”¯ä»˜ç½‘ç»œã€‚è¿™ä¸¤è€…éƒ½åŸºäºMLPåŸºç¡€è®¾æ–½ï¼Œä½†RegretNetå·²åœ¨å„ç§è®¾ç½®ä¸­çš„æ‹å–è®¾è®¡ä¸­è¢«é‡‡ç”¨å’Œæ‰©å±•[[10](#bib.bib10)ï¼Œ[11](#bib.bib11)ï¼Œ[21](#bib.bib21)ï¼Œ[14](#bib.bib14)]ã€‚
- en: 'Two basic assumptions are required by the RegretNet architecture: additive
    valuation Â²Â²2Additive valuation: an agentâ€™s valuation for a subset of items is
    the sum of the individual itemsâ€™ valuations. and unit-demand valuation. Both of
    the allocation network and the payment network takes in the bids as inputs, feeds
    them into MLP-structured networks with separate parameters, and returns the total
    payments based on the outputs from two networks. Therefore, the two networks are
    trained together. The network uses a sigmoidal unit to normalize the payment vector
    into [0, 1], so that the IR constraint will be enforced, where bidders are never
    charged for more than their expected value for the allocation.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: RegretNetæ¶æ„éœ€è¦ä¸¤ä¸ªåŸºæœ¬å‡è®¾ï¼šåŠ æ€§ä¼°å€¼Â²Â²2åŠ æ€§ä¼°å€¼ï¼šä»£ç†äººå¯¹ä¸€ä¸ªå­é›†ç‰©å“çš„ä¼°å€¼æ˜¯å•ä¸ªç‰©å“ä¼°å€¼çš„æ€»å’Œã€‚å’Œå•ä½éœ€æ±‚ä¼°å€¼ã€‚åˆ†é…ç½‘ç»œå’Œæ”¯ä»˜ç½‘ç»œéƒ½å°†æŠ•æ ‡ä½œä¸ºè¾“å…¥ï¼Œå°†å…¶è¾“å…¥åˆ°å…·æœ‰ç‹¬ç«‹å‚æ•°çš„MLPç»“æ„ç½‘ç»œä¸­ï¼Œç„¶åæ ¹æ®ä¸¤ä¸ªç½‘ç»œçš„è¾“å‡ºè¿”å›æ€»æ”¯ä»˜ã€‚å› æ­¤ï¼Œè¿™ä¸¤ä¸ªç½‘ç»œä¸€èµ·è¿›è¡Œè®­ç»ƒã€‚ç½‘ç»œä½¿ç”¨sigmoidalå•å…ƒå°†æ”¯ä»˜å‘é‡æ ‡å‡†åŒ–ä¸º[0,
    1]ï¼Œä»¥ç¡®ä¿IRçº¦æŸå¾—åˆ°æ‰§è¡Œï¼Œå³æŠ•æ ‡äººä¸ä¼šä¸ºåˆ†é…æ”¯ä»˜è¶…å‡ºå…¶é¢„æœŸä»·å€¼çš„è´¹ç”¨ã€‚
- en: 'The objective function is aiming to minimize the empirical loss (negated revenue)
    subject to the IC and IR constraints. The IC constraint can be enforced by the
    notion of ex post regret for bidders, which is the maximum increase in their utility
    considering all possible non-truthful bids. The ex post regret is estimated by
    the empirical regret, which is denoted as $\hat{rgt}_{i}(w)$. Therefore, the objective
    function becomes (Equation [8](#S3.E8 "In 3 RegretNet Infrastructure â€£ A Survey
    of Online Auction Mechanism Design Using Deep Learning Approaches")):'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®æ ‡å‡½æ•°æ—¨åœ¨æœ€å°åŒ–ç»éªŒæŸå¤±ï¼ˆè´Ÿæ”¶å…¥ï¼‰ï¼ŒåŒæ—¶æ»¡è¶³ICå’ŒIRçº¦æŸã€‚ICçº¦æŸå¯ä»¥é€šè¿‡æŠ•æ ‡äººçš„ç»éªŒåæ‚”æ¦‚å¿µæ¥æ‰§è¡Œï¼Œå³è€ƒè™‘æ‰€æœ‰å¯èƒ½çš„ä¸è¯šå®æŠ•æ ‡çš„æƒ…å†µä¸‹ï¼Œæ•ˆç”¨çš„æœ€å¤§å¢åŠ ã€‚ç»éªŒåæ‚”ç”±ç»éªŒåæ‚”ä¼°è®¡ï¼Œè¡¨ç¤ºä¸º$\hat{rgt}_{i}(w)$ã€‚å› æ­¤ï¼Œç›®æ ‡å‡½æ•°å˜ä¸ºï¼ˆæ–¹ç¨‹å¼[8](#S3.E8
    "åœ¨3 RegretNetåŸºç¡€è®¾æ–½ â€£ ä½¿ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒæŸ¥")ï¼‰ï¼š
- en: '|  | $\begin{split}\min_{w\in\mathbb{R}^{d}}-\frac{1}{L}\sum_{l=1}^{L}\sum_{i=1}^{n}p_{i}^{w}(v^{(l)})\\
    \text{s.t. }\hat{rgt}_{i}(w)=0,\forall i\in N.\end{split}$ |  | (8) |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\min_{w\in\mathbb{R}^{d}}-\frac{1}{L}\sum_{l=1}^{L}\sum_{i=1}^{n}p_{i}^{w}(v^{(l)})\\
    \text{s.t. }\hat{rgt}_{i}(w)=0,\forall i\in N.\end{split}$ |  | (8) |'
- en: 'The optimization is achieved using Lagrange multipliers, augmented with a quadratic
    penalty term for violating the constraints (Equation [9](#S3.E9 "In 3 RegretNet
    Infrastructure â€£ A Survey of Online Auction Mechanism Design Using Deep Learning
    Approaches")):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼˜åŒ–é€šè¿‡æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°å®ç°ï¼Œå¢åŠ äº†ä¸€ä¸ªäºŒæ¬¡æƒ©ç½šé¡¹ä»¥è¿åçº¦æŸï¼ˆæ–¹ç¨‹å¼[9](#S3.E9 "åœ¨3 RegretNetåŸºç¡€è®¾æ–½ â€£ ä½¿ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒæŸ¥")ï¼‰ï¼š
- en: '|  | $\mathcal{C}_{\rho}(w;\lambda)=-\frac{1}{L}\sum_{l=1}^{L}\sum_{i=1}^{n}p_{i}^{w}(v^{(l)})+\sum_{i\in
    N}\lambda_{i}\hat{rgt}_{i}(w)+\frac{\rho}{2}\sum_{i\in N}(\hat{rgt}_{i}(w))^{2}$
    |  | (9) |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{C}_{\rho}(w;\lambda)=-\frac{1}{L}\sum_{l=1}^{L}\sum_{i=1}^{n}p_{i}^{w}(v^{(l)})+\sum_{i\in
    N}\lambda_{i}\hat{rgt}_{i}(w)+\frac{\rho}{2}\sum_{i\in N}(\hat{rgt}_{i}(w))^{2}$
    |  | (9) |'
- en: 'Feng et al constructed a neural network [[10](#bib.bib10)] built upon the structure
    of RegretNet, which consists of an allocation network and a payment network. It
    extends the RegretNet infrastructure by incorporating the budget constraints as
    well as handling Bayesian Incentive Compatible (BIC) Â³Â³3Bayesian Incentive Compatible:
    truth-telling is the optimal strategy for a bidder in expectation with respect
    to the types of others, given that the other bidders report truthfully. and conditional
    IC constraints. Dutting et al enforces IC by requiring the empirical ex post regret
    to be zero, while Feng et al are able to handle more general forms of IC by constructing
    an appropriate notion of regret.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Fengç­‰äººæ„å»ºäº†ä¸€ä¸ªåŸºäºRegretNetç»“æ„çš„ç¥ç»ç½‘ç»œ[[10](#bib.bib10)]ï¼ŒåŒ…æ‹¬ä¸€ä¸ªåˆ†é…ç½‘ç»œå’Œä¸€ä¸ªæ”¯ä»˜ç½‘ç»œã€‚å®ƒé€šè¿‡ç»“åˆé¢„ç®—çº¦æŸä»¥åŠå¤„ç†Bayesian
    Incentive Compatible (BIC) Â³Â³3Bayesian Incentive Compatibleï¼šåœ¨å…¶ä»–æŠ•æ ‡äººè¯šå®æŠ¥å‘Šçš„æƒ…å†µä¸‹ï¼ŒçœŸè¯šå‘ŠçŸ¥æ˜¯å¯¹æŠ•æ ‡äººæœ€ä¼˜ç­–ç•¥ã€‚å’Œæ¡ä»¶ICçº¦æŸæ¥æ‰©å±•RegretNetåŸºç¡€è®¾æ–½ã€‚Duttingç­‰äººé€šè¿‡è¦æ±‚ç»éªŒåæ‚”ä¸ºé›¶æ¥æ‰§è¡ŒICï¼Œè€ŒFengç­‰äººé€šè¿‡æ„å»ºé€‚å½“çš„åæ‚”æ¦‚å¿µæ¥å¤„ç†æ›´ä¸€èˆ¬çš„ICå½¢å¼ã€‚
- en: Assume we have an auction with rules $(a,p)$. To handle BIC, Feng et al constrain
    the empirical interim regret $rgt_{i}(a,p)$ (Equation [10](#S3.E10 "In 3 RegretNet
    Infrastructure â€£ A Survey of Online Auction Mechanism Design Using Deep Learning
    Approaches")) to zero. To handle conditional IC/BIC, they constrain the empirical
    conditional regret to zero. They also incorporate the individually rationality
    (IR) $irp_{i}(a,p)$ (Equation [11](#S3.E11 "In 3 RegretNet Infrastructure â€£ A
    Survey of Online Auction Mechanism Design Using Deep Learning Approaches")) and
    budget constraint (BC) $bcp_{i}(a,p)$ (Equation [12](#S3.E12 "In 3 RegretNet Infrastructure
    â€£ A Survey of Online Auction Mechanism Design Using Deep Learning Approaches"))
    as penalties.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªè§„åˆ™ä¸º $(a,p)$ çš„æ‹å–ã€‚ä¸ºå¤„ç† BICï¼ŒFeng ç­‰äººå°†ç»éªŒä¸­æœŸåæ‚” $rgt_{i}(a,p)$ï¼ˆæ–¹ç¨‹ [10](#S3.E10
    "In 3 RegretNet Infrastructure â€£ A Survey of Online Auction Mechanism Design Using
    Deep Learning Approaches")ï¼‰çº¦æŸä¸ºé›¶ã€‚ä¸ºå¤„ç†æ¡ä»¶ IC/BICï¼Œä»–ä»¬å°†ç»éªŒæ¡ä»¶åæ‚”çº¦æŸä¸ºé›¶ã€‚ä»–ä»¬è¿˜å°†ä¸ªä½“ç†æ€§ï¼ˆIRï¼‰ $irp_{i}(a,p)$ï¼ˆæ–¹ç¨‹
    [11](#S3.E11 "In 3 RegretNet Infrastructure â€£ A Survey of Online Auction Mechanism
    Design Using Deep Learning Approaches")ï¼‰å’Œé¢„ç®—çº¦æŸï¼ˆBCï¼‰ $bcp_{i}(a,p)$ï¼ˆæ–¹ç¨‹ [12](#S3.E12
    "In 3 RegretNet Infrastructure â€£ A Survey of Online Auction Mechanism Design Using
    Deep Learning Approaches")ï¼‰ä½œä¸ºæƒ©ç½šã€‚
- en: '|  | $rgt_{i}(a,p)=E_{t_{i}\sim F_{i}}[\max_{t_{i}^{\prime}\in\mathcal{T}_{i}}1_{\mathcal{P}_{i}(t_{i}^{\prime})\leq
    b_{i}}(\mathcal{U}_{i}(t_{i},t_{i}^{\prime})-\mathcal{U}_{i}(t_{i},t_{i}))]$ |  |
    (10) |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '|  | $rgt_{i}(a,p)=E_{t_{i}\sim F_{i}}[\max_{t_{i}^{\prime}\in\mathcal{T}_{i}}1_{\mathcal{P}_{i}(t_{i}^{\prime})\leq
    b_{i}}(\mathcal{U}_{i}(t_{i},t_{i}^{\prime})-\mathcal{U}_{i}(t_{i},t_{i}))]$ |  |
    (10) |'
- en: '|  | $irp_{i}(a,p)=E_{t_{i}\sim F_{i}}[\max\{0,-\mathcal{U}_{i}(t_{i},t_{i})\}]$
    |  | (11) |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|  | $irp_{i}(a,p)=E_{t_{i}\sim F_{i}}[\max\{0,-\mathcal{U}_{i}(t_{i},t_{i})\}]$
    |  | (11) |'
- en: '|  | $bcp_{i}(a,p)=E_{t_{i}\sim F_{i}}[\max\{0,\mathcal{P}_{i}(t_{i})-b_{i}\}]$
    |  | (12) |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | $bcp_{i}(a,p)=E_{t_{i}\sim F_{i}}[\max\{0,\mathcal{P}_{i}(t_{i})-b_{i}\}]$
    |  | (12) |'
- en: The loss function is the negated expected revenue $\mathcal{L}(a,p)=-E_{t\sim
    F}[\sum_{i=1}^{n}p_{i}(t)]$. Let $w\in\mathbb{R}^{d}$ denote the parameters of
    the allocation network, the induced allocation rule denoted by $a^{w}$, and $w^{\prime}\in\mathbb{R}^{d^{\prime}}$
    denote the parameters of the payment network, the induced payment rule is denoted
    by $p^{w^{\prime}}$. The objective function is finally in Equation [13](#S3.E13
    "In 3 RegretNet Infrastructure â€£ A Survey of Online Auction Mechanism Design Using
    Deep Learning Approaches"). The objective function is trained using Augmented
    Lagrangian Solver as in Dutting et al, where the quadratic penalty terms are added
    for each constraint.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æŸå¤±å‡½æ•°æ˜¯è´ŸæœŸæœ›æ”¶ç›Š $\mathcal{L}(a,p)=-E_{t\sim F}[\sum_{i=1}^{n}p_{i}(t)]$ã€‚ä»¤ $w\in\mathbb{R}^{d}$
    è¡¨ç¤ºåˆ†é…ç½‘ç»œçš„å‚æ•°ï¼Œç”± $a^{w}$ è¡¨ç¤ºçš„è¯±å¯¼åˆ†é…è§„åˆ™ï¼Œä»¥åŠ $w^{\prime}\in\mathbb{R}^{d^{\prime}}$ è¡¨ç¤ºæ”¯ä»˜ç½‘ç»œçš„å‚æ•°ï¼Œç”±
    $p^{w^{\prime}}$ è¡¨ç¤ºçš„è¯±å¯¼æ”¯ä»˜è§„åˆ™ã€‚ç›®æ ‡å‡½æ•°æœ€ç»ˆåœ¨æ–¹ç¨‹ [13](#S3.E13 "In 3 RegretNet Infrastructure
    â€£ A Survey of Online Auction Mechanism Design Using Deep Learning Approaches")
    ä¸­ç»™å‡ºã€‚ç›®æ ‡å‡½æ•°ä½¿ç”¨Augmented Lagrangian Solverè¿›è¡Œè®­ç»ƒï¼Œå¦‚Duttingç­‰æ‰€è¿°ï¼Œå…¶ä¸­å¯¹æ¯ä¸ªçº¦æŸæ·»åŠ äº†äºŒæ¬¡ç½šé¡¹ã€‚
- en: '|  | <math   alttext="\begin{split}\min_{w\in\mathbb{R}^{d},w^{\prime}\in\mathbb{R}^{d^{\prime}}}\mathcal{L}(a^{w},p^{w^{\prime}})\\
    \text{s.t. }rgt_{i}(a^{w},p^{w^{\prime}})=0,\forall i\in[n]\\'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}\min_{w\in\mathbb{R}^{d},w^{\prime}\in\mathbb{R}^{d^{\prime}}}\mathcal{L}(a^{w},p^{w^{\prime}})\\
    \text{s.t. }rgt_{i}(a^{w},p^{w^{\prime}})=0,\forall i\in[n]\\'
- en: irp_{i}(a^{w},p^{w^{\prime}})=0,\forall i\in[n]\\
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: $irp_{i}(a^{w},p^{w^{\prime}})=0,\forall i\in[n]\\$
- en: bcp_{i}(a^{w},p^{w^{\prime}})=0,\forall i\in[n]\\
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: bcp_{i}(a^{w},p^{w^{\prime}})=0,\forall i\in[n]\\
- en: \end{split}" display="block"><semantics ><mtable displaystyle="true" rowspacing="0pt"
    ><mtr ><mtd columnalign="right" ><mrow ><mrow ><munder ><mi >min</mi><mrow ><mrow  ><mi
    >w</mi><mo >âˆˆ</mo><msup ><mi >â„</mi><mi >d</mi></msup></mrow><mo >,</mo><mrow
    ><msup ><mi >w</mi><mo >â€²</mo></msup><mo >âˆˆ</mo><msup ><mi >â„</mi><msup ><mi >d</mi><mo
    >â€²</mo></msup></msup></mrow></mrow></munder><mo lspace="0.167em"  >â¡</mo><mi >â„’</mi></mrow><mo
    lspace="0em" rspace="0em"  >â€‹</mo><mrow ><mo stretchy="false" >(</mo><msup ><mi
    >a</mi><mi >w</mi></msup><mo >,</mo><msup ><mi >p</mi><msup ><mi  >w</mi><mo >â€²</mo></msup></msup><mo
    stretchy="false"  >)</mo></mrow></mrow></mtd></mtr><mtr ><mtd  columnalign="right"
    ><mrow ><mrow ><mrow ><mtext  >s.t.Â </mtext><mo lspace="0em" rspace="0em"  >â€‹</mo><mi
    >r</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><mi >g</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><msub
    ><mi  >t</mi><mi >i</mi></msub><mo lspace="0em" rspace="0em"  >â€‹</mo><mrow ><mo
    stretchy="false" >(</mo><msup ><mi >a</mi><mi >w</mi></msup><mo >,</mo><msup ><mi
    >p</mi><msup ><mi >w</mi><mo >â€²</mo></msup></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo
    >=</mo><mn >0</mn></mrow><mo >,</mo><mrow ><mrow ><mo rspace="0.167em" >âˆ€</mo><mi
    >i</mi></mrow><mo >âˆˆ</mo><mrow ><mo stretchy="false"  >[</mo><mi >n</mi><mo stretchy="false"  >]</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><mrow ><mrow ><mrow ><mi  >i</mi><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mi >r</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><msub ><mi  >p</mi><mi
    >i</mi></msub><mo lspace="0em" rspace="0em"  >â€‹</mo><mrow ><mo stretchy="false"
    >(</mo><msup ><mi >a</mi><mi >w</mi></msup><mo >,</mo><msup ><mi >p</mi><msup
    ><mi >w</mi><mo >â€²</mo></msup></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo
    >=</mo><mn >0</mn></mrow><mo >,</mo><mrow ><mrow ><mo rspace="0.167em" >âˆ€</mo><mi
    >i</mi></mrow><mo >âˆˆ</mo><mrow ><mo stretchy="false"  >[</mo><mi >n</mi><mo stretchy="false"  >]</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><mrow ><mrow ><mrow ><mi  >b</mi><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mi >c</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><msub ><mi  >p</mi><mi
    >i</mi></msub><mo lspace="0em" rspace="0em"  >â€‹</mo><mrow ><mo stretchy="false"
    >(</mo><msup ><mi >a</mi><mi >w</mi></msup><mo >,</mo><msup ><mi >p</mi><msup
    ><mi >w</mi><mo >â€²</mo></msup></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo
    >=</mo><mn >0</mn></mrow><mo >,</mo><mrow ><mrow ><mo rspace="0.167em" >âˆ€</mo><mi
    >i</mi></mrow><mo >âˆˆ</mo><mrow ><mo stretchy="false"  >[</mo><mi >n</mi><mo stretchy="false"  >]</mo></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply
    ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply ><apply ><apply ><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><apply ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply
    ><ci >ğ‘¤</ci><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >â„</ci><ci
    >ğ‘‘</ci></apply></apply><apply ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ğ‘¤</ci><ci >â€²</ci></apply><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >â„</ci><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >ğ‘‘</ci><ci >â€²</ci></apply></apply></apply></apply></apply><ci
    >â„’</ci></apply><interval closure="open"  ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >ğ‘</ci><ci >ğ‘¤</ci></apply><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ğ‘</ci><apply  ><csymbol cd="ambiguous"  >superscript</csymbol><ci >ğ‘¤</ci><ci
    >â€²</ci></apply></apply></interval><ci ><mtext >s.t.Â </mtext></ci><ci >ğ‘Ÿ</ci><ci  >ğ‘”</ci><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >ğ‘¡</ci><ci >ğ‘–</ci></apply><interval
    closure="open" ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >ğ‘</ci><ci
    >ğ‘¤</ci></apply><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >ğ‘</ci><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >ğ‘¤</ci><ci >â€²</ci></apply></apply></interval></apply><cn
    type="integer"  >0</cn></apply><apply ><apply ><apply ><csymbol cd="latexml"  >for-all</csymbol><ci
    >ğ‘–</ci></apply><apply ><apply ><csymbol cd="latexml"  >delimited-[]</csymbol><ci
    >ğ‘›</ci></apply><ci >ğ‘–</ci><ci >ğ‘Ÿ</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >ğ‘</ci><ci >ğ‘–</ci></apply><interval closure="open" ><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >ğ‘</ci><ci >ğ‘¤</ci></apply><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >ğ‘</ci><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ğ‘¤</ci><ci >â€²</ci></apply></apply></interval></apply></apply><apply ><cn type="integer"  >0</cn></apply></apply></apply><apply
    ><apply ><apply ><csymbol cd="latexml" >for-all</csymbol><ci >ğ‘–</ci></apply><apply
    ><apply ><csymbol cd="latexml" >delimited-[]</csymbol><ci >ğ‘›</ci></apply><ci >ğ‘</ci><ci  >ğ‘</ci><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >ğ‘</ci><ci >ğ‘–</ci></apply><interval
    closure="open" ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >ğ‘</ci><ci
    >ğ‘¤</ci></apply><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >ğ‘</ci><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >ğ‘¤</ci><ci >â€²</ci></apply></apply></interval></apply></apply><apply
    ><cn type="integer" >0</cn></apply></apply><apply ><apply ><csymbol cd="latexml"
    >for-all</csymbol><ci >ğ‘–</ci></apply><apply ><csymbol cd="latexml" >delimited-[]</csymbol><ci
    >ğ‘›</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >\begin{split}\min_{w\in\mathbb{R}^{d},w^{\prime}\in\mathbb{R}^{d^{\prime}}}\mathcal{L}(a^{w},p^{w^{\prime}})\\
    \text{s.t. }rgt_{i}(a^{w},p^{w^{\prime}})=0,\forall i\in[n]\\ irp_{i}(a^{w},p^{w^{\prime}})=0,\forall
    i\in[n]\\ bcp_{i}(a^{w},p^{w^{\prime}})=0,\forall i\in[n]\\ \end{split}</annotation></semantics></math>
    |  | (13) |
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: \end{split}" display="block"><semantics ><mtable displaystyle="true" rowspacing="0pt"
    ><mtr ><mtd columnalign="right" ><mrow ><mrow ><munder ><mi >min</mi><mrow ><mrow  ><mi
    >w</mi><mo >âˆˆ</mo><msup ><mi >â„</mi><mi >d</mi></msup></mrow><mo >,</mo><mrow
    ><msup ><mi >w</mi><mo >â€²</mo></msup><mo >âˆˆ</mo><msup ><mi >â„</mi><msup ><mi >d</mi><mo
    >â€²</mo></msup></msup></mrow></mrow></munder><mo lspace="0.167em"  >â¡</mo><mi >â„’</mi></mrow><mo
    lspace="0em" rspace="0em"  >â€‹</mo><mrow ><mo stretchy="false" >(</mo><msup ><mi
    >a</mi><mi >w</mi></msup><mo >,</mo><msup ><mi >p</mi><msup ><mi  >w</mi><mo >â€²</mo></msup></msup><mo
    stretchy="false"  >)</mo></mrow></mrow></mtd></mtr><mtr ><mtd  columnalign="right"
    ><mrow ><mrow ><mrow ><mtext  >s.t.Â </mtext><mo lspace="0em" rspace="0em"  >â€‹</mo><mi
    >r</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><mi >g</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><msub
    ><mi  >t</mi><mi >i</mi></msub><mo lspace="0em" rspace="0em"  >â€‹</mo><mrow ><mo
    stretchy="false" >(</mo><msup ><mi >a</mi><mi >w</mi></msup><mo >,</mo><msup ><mi
    >p</mi><msup ><mi >w</mi><mo >â€²</mo></msup></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo
    >=</mo><mn >0</mn></mrow><mo >,</mo><mrow ><mrow ><mo rspace="0.167em" >âˆ€</mo><mi
    >i</mi></mrow><mo >âˆˆ</mo><mrow ><mo stretchy="false"  >[</mo><mi >n</mi><mo stretchy="false"  >]</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><mrow ><mrow ><mrow ><mi  >i</mi><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mi >r</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><msub ><mi  >p</mi><mi
    >i</mi></msub><mo lspace="0em" rspace="0em"  >â€‹</mo><mrow ><mo stretchy="false"
    >(</mo><msup ><mi >a</mi><mi >w</mi></msup><mo >,</mo><msup ><mi >p</mi><msup
    ><mi >w</mi><mo >â€²</mo></msup></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo
    >=</mo><mn >0</mn></mrow><mo >,</mo><mrow ><mrow ><mo rspace="0.167em" >âˆ€</mo><mi
    >i</mi></mrow><mo >âˆˆ</mo><mrow ><mo stretchy="false"  >[</mo><mi >n</mi><mo stretchy="false"  >]</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><mrow ><mrow ><mrow ><mi  >b</mi><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mi >c</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><msub ><mi  >p</mi><mi
    >i</mi></msub><mo lspace="0em" rspace="0em"  >â€‹</mo><mrow ><mo stretchy="false"
    >(</mo><msup ><mi >a</mi><mi >w</mi></msup><mo >,</mo><msup ><mi >p</mi><msup
    ><mi >w</mi><mo >â€²</mo></msup></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo
    >=</mo><mn >0</mn></mrow><mo >,</mo><mrow ><mrow ><mo rspace="0.167em" >âˆ€</mo><mi
    >i</mi></mrow><mo >âˆˆ</mo><mrow ><mo stretchy="false"  >[</mo><mi >n</mi><mo stretchy="false"  >]</mo></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply
    ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply ><apply ><apply ><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><apply ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply
    ><ci >ğ‘¤</ci><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >â„</ci><ci
    >ğ‘‘</ci></apply></apply><apply ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ğ‘¤</ci><ci >â€²</ci></apply><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >â„</ci><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >ğ‘‘</ci><ci >â€²</ci></apply></apply></apply></apply></apply><ci
    >â„’</ci></apply><interval closure="open"  ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >ğ‘</ci><ci >ğ‘¤</ci></apply><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ğ‘</ci><apply  ><csymbol cd="ambiguous"  >superscript</csymbol><ci >ğ‘¤</ci><ci
    >â€²</ci></apply></apply></interval><ci ><mtext >s.t.Â </mtext></ci><ci >ğ‘Ÿ</ci><ci  >ğ‘”</ci><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >ğ‘¡</ci><ci >ğ‘–</ci></apply><interval
    closure="open" ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >ğ‘</ci><ci
    >ğ‘¤</ci></apply><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >ğ‘</ci><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >ğ‘¤</ci><ci >â€²</ci></apply></apply></interval></apply><cn
    type="integer"  >0</cn></apply><apply ><apply ><apply ><csymbol cd="latexml"  >for-all</csymbol><ci
    >ğ‘–</ci></apply><apply ><apply ><csymbol cd="latexml"  >delimited-[]</csymbol><ci
    >ğ‘›</ci></apply><ci >ğ‘–</ci><ci >ğ‘Ÿ</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >ğ‘</ci><ci >ğ‘–</ci></apply><interval closure="open" ><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >ğ‘</ci><ci >ğ‘¤</ci></apply><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >ğ‘</ci><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ğ‘¤</ci><ci >â€²</ci></apply></apply></interval></apply></apply><apply ><cn type="integer"  >0</cn></apply></apply></apply><apply
    ><apply ><apply ><csymbol cd="latexml" >for-all</csymbol><ci >ğ‘–</ci></apply><apply
    ><apply ><csymbol cd="latexml" >delimited-[]</csymbol><ci >ğ‘›</ci></apply
- en: Golowich et al proposed RegretNet-nm [[11](#bib.bib11)] that is able to give
    general mechanisms that are not limited by existing characterization results for
    multi-facility location problems. The notion of regret is extended to facility
    location mechanisms as the maximum expected utility gain agents can achieve by
    misreporting their preferences.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Golowich ç­‰äººæå‡ºäº† RegretNet-nm [[11](#bib.bib11)]ï¼Œå®ƒèƒ½å¤Ÿæä¾›ä¸å—ç°æœ‰å¤šè®¾æ–½ä½ç½®é—®é¢˜è¡¨å¾ç»“æœé™åˆ¶çš„ä¸€èˆ¬æœºåˆ¶ã€‚æ‚”æ¨çš„æ¦‚å¿µæ‰©å±•åˆ°è®¾æ–½ä½ç½®æœºåˆ¶ä¸­ï¼Œä½œä¸ºä»£ç†é€šè¿‡è¯¯æŠ¥å…¶åå¥½è€Œèƒ½å¤Ÿå®ç°çš„æœ€å¤§æœŸæœ›æ•ˆç”¨å¢ç›Šã€‚
- en: The network structure is the same as RegretNet, except for the inputs which
    are agentsâ€™ peaks. The misreported peaks are sampled uniformly within $[0,1]$,
    with a granularity of $\frac{1}{M}$. The ex post regret is integrated into the
    objective function using Augmented Lagrangian Solver, which uses a quadratic penalty
    term. The RegretNet-nm opens the door for mechanisms designs for settings without
    money, such as matching and allocation problems, using neural network approaches.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç½‘ç»œç»“æ„ä¸ RegretNet ç›¸åŒï¼Œåªæ˜¯è¾“å…¥æ˜¯ä»£ç†çš„å³°å€¼ã€‚è¯¯æŠ¥å‘Šçš„å³°å€¼åœ¨ $[0,1]$ èŒƒå›´å†…å‡åŒ€é‡‡æ ·ï¼Œç²’åº¦ä¸º $\frac{1}{M}$ã€‚äº‹åæ‚”æ¨è¢«é›†æˆåˆ°ç›®æ ‡å‡½æ•°ä¸­ï¼Œä½¿ç”¨å¢å¹¿æ‹‰æ ¼æœ—æ—¥æ±‚è§£å™¨ï¼Œè¯¥æ±‚è§£å™¨ä½¿ç”¨äºŒæ¬¡æƒ©ç½šé¡¹ã€‚RegretNet-nm
    ä¸ºä½¿ç”¨ç¥ç»ç½‘ç»œæ–¹æ³•è¿›è¡Œæ— é‡‘é’±è®¾ç½®çš„æœºåˆ¶è®¾è®¡ï¼ˆå¦‚åŒ¹é…å’Œåˆ†é…é—®é¢˜ï¼‰å¼€è¾Ÿäº†æ–°å¤©åœ°ã€‚
- en: 'PreferenceNet [[21](#bib.bib21)] is another extension of RegretNet. It encodes
    human preferences in auction designs. The network structure is comprised of RegretNet
    and a 3-layer MLP. These two components are trained in an EM-manner: MLP is first
    trained using a uniformly drawn sample of allocations as inputs, and it is optimized
    using binary cross entropy loss based on ground truth labels. Then, the RegretNet
    is trained using Augmented Lagrange Solver.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: PreferenceNet [[21](#bib.bib21)] æ˜¯ RegretNet çš„å¦ä¸€ä¸ªæ‰©å±•ã€‚å®ƒåœ¨æ‹å–è®¾è®¡ä¸­ç¼–ç äº†äººç±»çš„åå¥½ã€‚ç½‘ç»œç»“æ„ç”± RegretNet
    å’Œä¸€ä¸ª 3 å±‚çš„ MLP ç»„æˆã€‚è¿™ä¸¤ä¸ªç»„ä»¶ä»¥ EM æ–¹å¼è¿›è¡Œè®­ç»ƒï¼šé¦–å…ˆä½¿ç”¨å‡åŒ€æŠ½å–çš„åˆ†é…æ ·æœ¬è®­ç»ƒ MLPï¼Œå¹¶åŸºäºçœŸå®æ ‡ç­¾ä½¿ç”¨äºŒå…ƒäº¤å‰ç†µæŸå¤±è¿›è¡Œä¼˜åŒ–ã€‚ç„¶åï¼Œä½¿ç”¨å¢å¹¿æ‹‰æ ¼æœ—æ—¥æ±‚è§£å™¨è®­ç»ƒ
    RegretNetã€‚
- en: The loss function for the entire PreferenceNet is defined in Equation [14](#S3.E14
    "In 3 RegretNet Infrastructure â€£ A Survey of Online Auction Mechanism Design Using
    Deep Learning Approaches"), where $\mathcal{L}_{s}$ is the output of the trained
    MLP. Lastly, the allocations and payments are sampled every $c$ epochs from the
    partially trained RegretNet and use them to augment the MLP training set to adapt
    to the distributional shifts in allocations during training.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æ•´ä¸ª PreferenceNet çš„æŸå¤±å‡½æ•°åœ¨æ–¹ç¨‹ [14](#S3.E14 "åœ¨ 3 RegretNet åŸºç¡€è®¾æ–½ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒæŸ¥")
    ä¸­å®šä¹‰ï¼Œå…¶ä¸­ $\mathcal{L}_{s}$ æ˜¯è®­ç»ƒå¥½çš„ MLP çš„è¾“å‡ºã€‚æœ€åï¼Œä»éƒ¨åˆ†è®­ç»ƒå¥½çš„ RegretNet ä¸­æ¯ $c$ è½®é‡‡æ ·åˆ†é…å’Œæ”¯ä»˜ï¼Œå¹¶ç”¨å®ƒä»¬æ¥å¢å¼º
    MLP çš„è®­ç»ƒé›†ï¼Œä»¥é€‚åº”è®­ç»ƒè¿‡ç¨‹ä¸­åˆ†é…çš„åˆ†å¸ƒå˜åŒ–ã€‚
- en: '|  | $\begin{split}\mathcal{C}_{\rho}(w;\lambda)=-\frac{1}{L}\sum_{l=1}^{L}\sum_{i\in
    N}p_{i}^{w}(v^{(l)})+\mathcal{L}_{rgt}-\mathcal{L}_{s}\\ \text{Where }\mathcal{L}_{rgt}=\sum_{i\in
    N}\lambda_{(r,i)}\text{rgt}_{i}(w)+\frac{\rho_{r}}{2}(\sum_{i\in N}\text{rgt}_{i}(w))^{2},\mathcal{L}_{s}=\sum_{j\in
    M}s_{j}\end{split}$ |  | (14) |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\mathcal{C}_{\rho}(w;\lambda)=-\frac{1}{L}\sum_{l=1}^{L}\sum_{i\in
    N}p_{i}^{w}(v^{(l)})+\mathcal{L}_{rgt}-\mathcal{L}_{s}\\ \text{å…¶ä¸­ }\mathcal{L}_{rgt}=\sum_{i\in
    N}\lambda_{(r,i)}\text{rgt}_{i}(w)+\frac{\rho_{r}}{2}(\sum_{i\in N}\text{rgt}_{i}(w))^{2},\mathcal{L}_{s}=\sum_{j\in
    M}s_{j}\end{split}$ |  | (14) |'
- en: Peri et al. proposed Preference Classification Accuracy (PCA) metric to evaluate
    how well a learned auction model satisfies an arbitrary constraint. PCA is calculated
    by the fraction of test bids that satisfy the ground truth constraint. Then, authors
    use pairwise comparisons between allocations to elicit preferences. Each input
    set of allocations is compared against n other allocations on their preference
    scores and label it as either a positive or negative exemplar, based on if its
    preference score is higher than the majority of others.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Peri ç­‰äººæå‡ºäº†åå¥½åˆ†ç±»å‡†ç¡®åº¦ï¼ˆPCAï¼‰æŒ‡æ ‡æ¥è¯„ä¼°å­¦ä¹ åˆ°çš„æ‹å–æ¨¡å‹æ»¡è¶³ä»»æ„çº¦æŸçš„ç¨‹åº¦ã€‚PCA æ˜¯é€šè¿‡æ»¡è¶³çœŸå®çº¦æŸçš„æµ‹è¯•æŠ•æ ‡æ¯”ä¾‹æ¥è®¡ç®—çš„ã€‚ç„¶åï¼Œä½œè€…é€šè¿‡åˆ†é…ä¹‹é—´çš„æˆå¯¹æ¯”è¾ƒæ¥å¼•å‡ºåå¥½ã€‚æ¯ç»„è¾“å…¥åˆ†é…éƒ½ä¸å…¶ä»–
    n ä¸ªåˆ†é…åœ¨å…¶åå¥½åˆ†æ•°ä¸Šè¿›è¡Œæ¯”è¾ƒï¼Œå¹¶æ ¹æ®å…¶åå¥½åˆ†æ•°æ˜¯å¦é«˜äºå¤§å¤šæ•°å…¶ä»–åˆ†é…ï¼Œå°†å…¶æ ‡è®°ä¸ºæ­£é¢æˆ–è´Ÿé¢æ ·æœ¬ã€‚
- en: ProportionNet [[14](#bib.bib14)] proposed by Kuo et al. is also based on the
    infrastructure of RegretNet. Like most other neural networks that deal with auction
    mechanism designs, it does not work under the setting of combinatorial valuations.
    Under the assumption of additive valuations and unit-demand valuations, the input
    space of valuations reduces from $2^{M}$ to $M$, where $M$ is the number of items.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Kuo ç­‰äººæå‡ºçš„ ProportionNet [[14](#bib.bib14)] ä¹ŸåŸºäº RegretNet çš„åŸºç¡€è®¾æ–½ã€‚ä¸å¤§å¤šæ•°å¤„ç†æ‹å–æœºåˆ¶è®¾è®¡çš„ç¥ç»ç½‘ç»œä¸€æ ·ï¼Œå®ƒåœ¨ç»„åˆä¼°å€¼è®¾ç½®ä¸‹ä¸èµ·ä½œç”¨ã€‚åœ¨åŠ æ€§ä¼°å€¼å’Œå•ä½éœ€æ±‚ä¼°å€¼çš„å‡è®¾ä¸‹ï¼Œä¼°å€¼çš„è¾“å…¥ç©ºé—´ä»
    $2^{M}$ å‡å°‘åˆ° $M$ï¼Œå…¶ä¸­ $M$ æ˜¯ç‰©å“æ•°é‡ã€‚
- en: '|  | $\mathcal{C}_{\rho}(w;\lambda)=-\frac{1}{L}\sum_{l=1}^{L}\sum_{i\in N}p_{i}^{w}(v^{(l)})+\mathcal{L}_{rgt}+\mathcal{L}_{unf}$
    |  | (15) |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{C}_{\rho}(w;\lambda)=-\frac{1}{L}\sum_{l=1}^{L}\sum_{i\in N}p_{i}^{w}(v^{(l)})+\mathcal{L}_{rgt}+\mathcal{L}_{unf}$
    |  | (15) |'
- en: 'Kuo et al. follows the core idea of RegretNet: in the Bayesian auction setting,
    one knows the valuation distribution from which samples can presumably be drawn.
    In the meantime, as both of the allocation and payment rules are functions, we
    can parametrize them using neural networks. Strategyproofness can be enforced
    adding constraints that are solvable using Augmented Lagrange Optimizer.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Kuo ç­‰äººéµå¾ªäº† RegretNet çš„æ ¸å¿ƒæ€æƒ³ï¼šåœ¨è´å¶æ–¯æ‹å–è®¾ç½®ä¸­ï¼Œäººä»¬çŸ¥é“å¯ä»¥ä»ä¸­æŠ½å–æ ·æœ¬çš„ä¼°å€¼åˆ†å¸ƒã€‚åŒæ—¶ï¼Œç”±äºåˆ†é…å’Œæ”¯ä»˜è§„åˆ™éƒ½æ˜¯å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç¥ç»ç½‘ç»œå¯¹å…¶è¿›è¡Œå‚æ•°åŒ–ã€‚å¯ä»¥é€šè¿‡æ·»åŠ çº¦æŸæ¥å¼ºåˆ¶ç­–ç•¥æ— å…³æ€§ï¼Œè¿™äº›çº¦æŸå¯ä»¥é€šè¿‡å¢å¼ºæ‹‰æ ¼æœ—æ—¥ä¼˜åŒ–å™¨è§£å†³ã€‚
- en: It adopted same neural network architecture as RegretNet, but adding a constraint
    of unfairness in the loss function [15](#S3.E15 "In 3 RegretNet Infrastructure
    â€£ A Survey of Online Auction Mechanism Design Using Deep Learning Approaches"),
    so that discriminatory ad allocations among different demography can be mitigated.
    The regret term $\mathcal{L}_{rgt}$ is consistent with the definition in RegretNet.
    The term $\mathcal{L}_{unf}$ is for quantifying the unfairness and discrimination
    in the auction system, which will be described in more details in Section [6.4](#S6.SS4
    "6.4 Fairness & Fraud Prevention â€£ 6 Constraints and Concerns â€£ A Survey of Online
    Auction Mechanism Design Using Deep Learning Approaches").
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒé‡‡ç”¨äº†ä¸ RegretNet ç›¸åŒçš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œä½†åœ¨æŸå¤±å‡½æ•°ä¸­å¢åŠ äº†ä¸å…¬å¹³æ€§çš„çº¦æŸ [15](#S3.E15 "åœ¨ 3 RegretNet åŸºç¡€è®¾æ–½
    â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡ç»¼è¿°")ï¼Œä»¥å‡å°‘ä¸åŒäººç¾¤ä¹‹é—´çš„æ­§è§†æ€§å¹¿å‘Šåˆ†é…ã€‚é—æ†¾é¡¹ $\mathcal{L}_{rgt}$ ä¸ RegretNet
    ä¸­çš„å®šä¹‰ä¸€è‡´ã€‚é¡¹ $\mathcal{L}_{unf}$ ç”¨äºé‡åŒ–æ‹å–ç³»ç»Ÿä¸­çš„ä¸å…¬å¹³æ€§å’Œæ­§è§†ï¼Œè¿™å°†åœ¨ç¬¬ [6.4](#S6.SS4 "6.4 å…¬å¹³æ€§ä¸æ¬ºè¯ˆé˜²èŒƒ
    â€£ 6 çº¦æŸä¸å…³æ³¨ç‚¹ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡ç»¼è¿°") èŠ‚ä¸­è¯¦ç»†æè¿°ã€‚
- en: 4 Reinforcement Learning (RL) Infrastructure
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 å¼ºåŒ–å­¦ä¹  (RL) åŸºç¡€è®¾æ–½
- en: As the online auction is more often a dynamic system whose users and platform
    objectives are evolving over time, researchers are more inclined to use dynamically
    trained models to adapt to the current status quo, leveraging reinforcement learning
    infrastructures [[6](#bib.bib6), [27](#bib.bib27), [31](#bib.bib31)].
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºåœ¨çº¿æ‹å–é€šå¸¸æ˜¯ä¸€ä¸ªåŠ¨æ€ç³»ç»Ÿï¼Œå…¶ç”¨æˆ·å’Œå¹³å°ç›®æ ‡éšç€æ—¶é—´çš„æ¨ç§»è€Œä¸æ–­å˜åŒ–ï¼Œç ”ç©¶äººå‘˜æ›´å€¾å‘äºä½¿ç”¨åŠ¨æ€è®­ç»ƒçš„æ¨¡å‹æ¥é€‚åº”å½“å‰çš„ç°çŠ¶ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ åŸºç¡€è®¾æ–½ [[6](#bib.bib6),
    [27](#bib.bib27), [31](#bib.bib31)]ã€‚
- en: As in the RegretNet infrastructure, Cai et al. also adopted no-regret learning,
    in which case agents only need to reason about their own strategies and their
    interaction with the environment, while they donâ€™t have to know the values of
    competitors or compute payoff-maximizing strategies over a long sequence of rounds.
    Reasoning about the strategies of other parties usually require strong cognitive
    assumption and highly burdensome computing power, which most agents donâ€™t have
    access to.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ RegretNet åŸºç¡€è®¾æ–½ä¸€æ ·ï¼ŒCai ç­‰äººä¹Ÿé‡‡ç”¨äº†æ— æ‚”å­¦ä¹ ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»£ç†äººåªéœ€è¦è€ƒè™‘è‡ªå·±çš„ç­–ç•¥åŠå…¶ä¸ç¯å¢ƒçš„äº’åŠ¨ï¼Œè€Œä¸å¿…äº†è§£ç«äº‰è€…çš„ä»·å€¼æˆ–è®¡ç®—é•¿æœŸè½®æ¬¡ä¸­çš„æ”¶ç›Šæœ€å¤§åŒ–ç­–ç•¥ã€‚è€ƒè™‘å…¶ä»–æ–¹ç­–ç•¥é€šå¸¸éœ€è¦å¼ºå¤§çš„è®¤çŸ¥å‡è®¾å’Œé«˜æ˜‚çš„è®¡ç®—èƒ½åŠ›ï¼Œè€Œå¤§å¤šæ•°ä»£ç†äººæ— æ³•è·å¾—è¿™äº›ã€‚
- en: Based on well-known bandit algorithms, Cai et al. identified four possible strategies
    for sellers.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºè‘—åçš„å¤šè‡‚è€è™æœºç®—æ³•ï¼ŒCai ç­‰äººè¯†åˆ«å‡ºäº†å–å®¶çš„å››ç§å¯èƒ½ç­–ç•¥ã€‚
- en: '1.'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: '$\epsilon-$Greedy [[29](#bib.bib29)]: With probability $\epsilon$, each seller
    selects a strategy uniformly at random. With probability $1-\epsilon$, the strategy
    with the best observed empirical mean payoff is selected.'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '$\epsilon-$Greedy [[29](#bib.bib29)]: ä»¥æ¦‚ç‡ $\epsilon$ï¼Œæ¯ä¸ªå–å®¶éšæœºå‡åŒ€é€‰æ‹©ä¸€ä¸ªç­–ç•¥ã€‚ä»¥æ¦‚ç‡ $1-\epsilon$ï¼Œé€‰æ‹©å…·æœ‰æœ€ä½³è§‚å¯Ÿåˆ°çš„ç»éªŒå‡å€¼æ”¶ç›Šçš„ç­–ç•¥ã€‚'
- en: '2.'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: '$\epsilon-$First: For a horizon of $\mathcal{T}$ rounds, the seller picks a
    strategy uniformly at random for the first $\epsilon\cdot\mathcal{T}$ rounds,
    and then picks the strategy that maximizes the empirical mean of the observed
    rewards for all the subsequent rounds.'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '$\epsilon-$First: åœ¨ $\mathcal{T}$ è½®çš„è§†é‡ä¸­ï¼Œå–å®¶åœ¨å‰ $\epsilon\cdot\mathcal{T}$ è½®ä¸­å‡åŒ€éšæœºé€‰æ‹©ç­–ç•¥ï¼Œç„¶åé€‰æ‹©æœ€å¤§åŒ–è§‚å¯Ÿåˆ°çš„å¥–åŠ±ç»éªŒå‡å€¼çš„ç­–ç•¥ç”¨äºæ‰€æœ‰åç»­è½®æ¬¡ã€‚'
- en: '3.'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Exponential-weight Algorithm for Exploration and Exploitation (Exp3) [[2](#bib.bib2),
    [4](#bib.bib4)]: In short, Exp3 selects a price according to a weighted distribution
    and then adjust the weights based on payoffs. To be more precise, suppose there
    are $K+1$ possible prices, the probability distribution $\pi_{i}(t)$ of those
    prices at round $t$ is defined in Equation [16](#S4.E16 "In item 3 â€£ 4 Reinforcement
    Learning (RL) Infrastructure â€£ A Survey of Online Auction Mechanism Design Using
    Deep Learning Approaches"), where $w_{i}(t)$ are the current weight of $i^{th}$
    price at round $t$ and $\gamma$ is a real number between $[0,1]$.'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'æŒ‡æ•°åŠ æƒç®—æ³•ç”¨äºæ¢ç´¢å’Œåˆ©ç”¨ï¼ˆExp3ï¼‰[[2](#bib.bib2), [4](#bib.bib4)]: ç®€è€Œè¨€ä¹‹ï¼ŒExp3 æ ¹æ®åŠ æƒåˆ†å¸ƒé€‰æ‹©ä»·æ ¼ï¼Œç„¶åæ ¹æ®æ”¶ç›Šè°ƒæ•´æƒé‡ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œå‡è®¾æœ‰
    $K+1$ ä¸ªå¯èƒ½çš„ä»·æ ¼ï¼Œè½®æ¬¡ $t$ ä¸­è¿™äº›ä»·æ ¼çš„æ¦‚ç‡åˆ†å¸ƒ $\pi_{i}(t)$ åœ¨å…¬å¼ [16](#S4.E16 "åœ¨ç¬¬3é¡¹ â€£ ç¬¬4é¡¹ å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åŸºç¡€è®¾æ–½
    â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡ç»¼è¿°") ä¸­å®šä¹‰ï¼Œå…¶ä¸­ $w_{i}(t)$ æ˜¯è½®æ¬¡ $t$ ä¸­ $i^{th}$ ä»·æ ¼çš„å½“å‰æƒé‡ï¼Œ$\gamma$
    æ˜¯ $[0,1]$ ä¹‹é—´çš„å®æ•°ã€‚'
- en: '|  | $\pi_{i}(t)=(1-\gamma)\frac{w_{i}(t)}{\sum_{j=1}^{K+1}w_{j}(t)}+\gamma\frac{1}{K+1}$
    |  | (16) |'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\pi_{i}(t)=(1-\gamma)\frac{w_{i}(t)}{\sum_{j=1}^{K+1}w_{j}(t)}+\gamma\frac{1}{K+1}$
    |  | (16) |'
- en: Select a price $p_{j}(t)$ according to the distribution above and compute its
    payoff $u_{j}(t)$, then the weight for $j^{th}$ price is updated according to
    Equation [17](#S4.E17 "In item 3 â€£ 4 Reinforcement Learning (RL) Infrastructure
    â€£ A Survey of Online Auction Mechanism Design Using Deep Learning Approaches"),
    while the weights for all the other prices remain unchanged.
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ ¹æ®ä¸Šè¿°åˆ†å¸ƒé€‰æ‹©ä»·æ ¼ $p_{j}(t)$ å¹¶è®¡ç®—å…¶æ”¶ç›Š $u_{j}(t)$ï¼Œç„¶åæ ¹æ®å…¬å¼ [17](#S4.E17 "åœ¨ç¬¬3é¡¹ â€£ ç¬¬4é¡¹ å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åŸºç¡€è®¾æ–½
    â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡ç»¼è¿°") æ›´æ–° $j^{th}$ ä»·æ ¼çš„æƒé‡ï¼Œè€Œå…¶ä»–æ‰€æœ‰ä»·æ ¼çš„æƒé‡ä¿æŒä¸å˜ã€‚
- en: '|  | $w_{j}(t+1)=w_{j}(t)e^{\gamma\frac{u_{j}(t)}{(K+1)\pi_{j}(t)}}$ |  | (17)
    |'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $w_{j}(t+1)=w_{j}(t)e^{\gamma\frac{u_{j}(t)}{(K+1)\pi_{j}(t)}}$ |  | (17)
    |'
- en: '4.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: 'Upper confidence Bound Algorithm (UCB1) [[1](#bib.bib1), [3](#bib.bib3)]: In
    the first $K+1$ rounds, select a price not used before from $[0,\frac{1}{K},\dots,1]$
    and then select the price with the max weighted value in the subsequent rounds.'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'ä¸Šç½®ä¿¡ç•Œç®—æ³•ï¼ˆUCB1ï¼‰[[1](#bib.bib1), [3](#bib.bib3)]: åœ¨å‰ $K+1$ è½®ä¸­ï¼Œä» $[0,\frac{1}{K},\dots,1]$
    ä¸­é€‰æ‹©ä¸€ä¸ªä¹‹å‰æœªä½¿ç”¨çš„ä»·æ ¼ï¼Œç„¶ååœ¨éšåçš„è½®æ¬¡ä¸­é€‰æ‹©å…·æœ‰æœ€å¤§åŠ æƒå€¼çš„ä»·æ ¼ã€‚'
- en: Initialize the weights for all prices to be 0\. For any round $t\in\{0,\dots.K\}$,
    the seller chooses a price $p_{j}$ such that $p_{j}\in[0,\frac{1}{K},\dots,1]$,
    computes the utility $u_{j}(t)$, and updates the weights for $j^{th}$ price to
    be $x_{j}(t)=\frac{x_{j}(t-1)+u_{j}(t)}{t}$, and keeping the weights for all the
    other prices unchanged.
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰ä»·æ ¼çš„æƒé‡åˆå§‹åŒ–ä¸º 0ã€‚åœ¨ä»»ä½•è½®æ¬¡ $t\in\{0,\dots.K\}$ ä¸­ï¼Œå–å®¶é€‰æ‹©ä¸€ä¸ªä»·æ ¼ $p_{j}$ ä½¿å¾— $p_{j}\in[0,\frac{1}{K},\dots,1]$ï¼Œè®¡ç®—æ•ˆç”¨
    $u_{j}(t)$ï¼Œå¹¶å°† $j^{th}$ ä»·æ ¼çš„æƒé‡æ›´æ–°ä¸º $x_{j}(t)=\frac{x_{j}(t-1)+u_{j}(t)}{t}$ï¼Œå…¶ä½™ä»·æ ¼çš„æƒé‡ä¿æŒä¸å˜ã€‚
- en: For any round $t\geq K+1$, the seller chooses the price $p_{j}$ according to
    Equation.
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹äºä»»ä½•è½®æ¬¡ $t\geq K+1$ï¼Œå–å®¶æ ¹æ®å…¬å¼é€‰æ‹©ä»·æ ¼ $p_{j}$ã€‚
- en: '|  | $p_{j}(t)=argmax_{j\in\{0,\frac{1}{K},\dots,1\}}x_{j}(t)+\frac{\log_{2}t}{\sum_{\tau=1}^{t}1_{\{p_{j}\text{
    was chosen in round }\tau\}}}$ |  | (18) |'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $p_{j}(t)=argmax_{j\in\{0,\frac{1}{K},\dots,1\}}x_{j}(t)+\frac{\log_{2}t}{\sum_{\tau=1}^{t}1_{\{p_{j}\text{
    åœ¨è½®æ¬¡ }\tau\text{ è¢«é€‰æ‹©}\}}}$ |  | (18) |'
- en: $\epsilon-$First and $\epsilon-Greedy$ have a clear distinction between exploration
    and exploitation and belong to the class of semi-uniform strategies. Exp3 makes
    no distributional assumptions about the rewards and is widely used for the full
    information setting and works in the adversarial bandit feedback model [[4](#bib.bib4)].
    UCB1 maintains a certain level of optimism towards less frequently played actions
    and uses the empirical mean of observed actions to choose the action in the next
    round. UCB1 is best suited in scenarios where rewards follow some unknown distributions
    [[6](#bib.bib6)].
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: $\epsilon-$First å’Œ $\epsilon-Greedy$ åœ¨æ¢ç´¢ä¸åˆ©ç”¨ä¹‹é—´æœ‰æ˜æ˜¾çš„åŒºåˆ«ï¼Œå±äºåŠå‡åŒ€ç­–ç•¥çš„èŒƒç•´ã€‚Exp3 å¯¹å¥–åŠ±æ²¡æœ‰åˆ†å¸ƒå‡è®¾ï¼Œå¹¿æ³›ç”¨äºå…¨ä¿¡æ¯è®¾ç½®ï¼Œå¹¶åœ¨å¯¹æŠ—æ€§èµŒåšåé¦ˆæ¨¡å‹ä¸­æœ‰æ•ˆ
    [[4](#bib.bib4)]ã€‚UCB1 å¯¹è¾ƒå°‘è¢«é€‰æ‹©çš„è¡Œä¸ºä¿æŒä¸€å®šçš„ä¹è§‚æ€åº¦ï¼Œå¹¶ä½¿ç”¨è§‚å¯Ÿåˆ°çš„è¡Œä¸ºçš„ç»éªŒå‡å€¼æ¥é€‰æ‹©ä¸‹ä¸€è½®çš„è¡Œä¸ºã€‚UCB1 æœ€é€‚ç”¨äºå¥–åŠ±éµå¾ªæŸäº›æœªçŸ¥åˆ†å¸ƒçš„åœºæ™¯
    [[6](#bib.bib6)]ã€‚
- en: These sellersâ€™ models can model sellers with different degrees of sophistication
    or pricing philosophies, and it is consistent with the recent literature on algorithmic
    mechanism deisgn, in terms of modeling agetn rationality in complex dynamic environments.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å–å®¶æ¨¡å‹å¯ä»¥æ¨¡æ‹Ÿå…·æœ‰ä¸åŒå¤æ‚ç¨‹åº¦æˆ–å®šä»·ç†å¿µçš„å–å®¶ï¼Œå¹¶ä¸”ä¸è¿‘æœŸå…³äºç®—æ³•æœºåˆ¶è®¾è®¡çš„æ–‡çŒ®ä¸€è‡´ï¼Œåœ¨å»ºæ¨¡å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­çš„ä»£ç†ç†æ€§æ–¹é¢ã€‚
- en: Previous researchers have already come up with a few variants of reinforcement
    learning models. The disadvantage of Deep Q-Network (DQN) [[18](#bib.bib18)] is
    that it cannot handle continuous actions or high-dimensional action spaces, as
    stochastic actor-critic algorithms are hard to converge. The Deterministic Policy
    Gradient (DPG) algorithm [[26](#bib.bib26)] is developed to train a deterministic
    policy with parameter vector. The DPG consists of the critic and actor. The critic
    approximates the action-value function, while the actor adjusts the parameters
    of the deterministic policy. Deep Deterministic Policy Gradient (DDPG) [[15](#bib.bib15)]
    is then proposed, as DPG is severely impacted by the high degree of temporal correlation
    that introduces high variance. DDPG stores the experiences of the agetn at each
    time step in a replay buffer and uniformly samples mini-batch from it at random
    for learning, which can eliminate the temporal correlation. DDPG also employs
    target networks for the regularization of the learning algorithm, which updates
    the parameters at a slower rate.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹‹å‰çš„ç ”ç©¶äººå‘˜å·²ç»æå‡ºäº†ä¸€äº›å¼ºåŒ–å­¦ä¹ æ¨¡å‹çš„å˜ä½“ã€‚æ·±åº¦ Q ç½‘ç»œ (DQN) [[18](#bib.bib18)] çš„ç¼ºç‚¹æ˜¯å®ƒä¸èƒ½å¤„ç†è¿ç»­åŠ¨ä½œæˆ–é«˜ç»´åŠ¨ä½œç©ºé—´ï¼Œå› ä¸ºéšæœºæ¼”å‘˜-è¯„è®ºå®¶ç®—æ³•å¾ˆéš¾æ”¶æ•›ã€‚ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦
    (DPG) ç®—æ³• [[26](#bib.bib26)] æ˜¯ä¸ºäº†è®­ç»ƒå…·æœ‰å‚æ•°å‘é‡çš„ç¡®å®šæ€§ç­–ç•¥ã€‚DPG ç”±è¯„è®ºå®¶å’Œæ¼”å‘˜ç»„æˆã€‚è¯„è®ºå®¶è¿‘ä¼¼åŠ¨ä½œä»·å€¼å‡½æ•°ï¼Œè€Œæ¼”å‘˜åˆ™è°ƒæ•´ç¡®å®šæ€§ç­–ç•¥çš„å‚æ•°ã€‚ç„¶åæå‡ºäº†æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦
    (DDPG) [[15](#bib.bib15)]ï¼Œå› ä¸º DPG å—åˆ°é«˜æ—¶é—´ç›¸å…³æ€§çš„ä¸¥é‡å½±å“ï¼Œå¯¼è‡´é«˜æ–¹å·®ã€‚DDPG åœ¨æ¯ä¸ªæ—¶é—´æ­¥å°†ä»£ç†çš„ç»éªŒå­˜å‚¨åœ¨å›æ”¾ç¼“å†²åŒºä¸­ï¼Œå¹¶ä»ä¸­éšæœºå‡åŒ€æŠ½å–å°æ‰¹é‡è¿›è¡Œå­¦ä¹ ï¼Œä»è€Œæ¶ˆé™¤æ—¶é—´ç›¸å…³æ€§ã€‚DDPG
    è¿˜é‡‡ç”¨ç›®æ ‡ç½‘ç»œæ¥å¯¹å­¦ä¹ ç®—æ³•è¿›è¡Œæ­£åˆ™åŒ–ï¼Œä»¥è¾ƒæ…¢çš„é€Ÿåº¦æ›´æ–°å‚æ•°ã€‚
- en: However, the size of the action space blows up very sharply with the number
    of sellers increases, so an direct application of DDPG will fail to converge.
    In addition, the DDPG is not able to handle variability on the set of sellers,
    since the algorithm uses a two-layer fully connected network and the positions
    of each seller plays an important role [[6](#bib.bib6)].
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œéšç€å–å®¶æ•°é‡çš„å¢åŠ ï¼ŒåŠ¨ä½œç©ºé—´çš„å¤§å°æ€¥å‰§è†¨èƒ€ï¼Œå› æ­¤ç›´æ¥åº”ç”¨ DDPG ä¼šå¯¼è‡´ä¸æ”¶æ•›ã€‚æ­¤å¤–ï¼ŒDDPG æ— æ³•å¤„ç†å–å®¶é›†åˆä¸Šçš„å˜å¼‚æ€§ï¼Œå› ä¸ºè¯¥ç®—æ³•ä½¿ç”¨äº†ä¸€ä¸ªä¸¤å±‚çš„å…¨è¿æ¥ç½‘ç»œï¼Œè€Œæ¯ä¸ªå–å®¶çš„ä½ç½®å‘æŒ¥äº†é‡è¦ä½œç”¨
    [[6](#bib.bib6)]ã€‚
- en: Cai et al. proposed IA(GRU) [[6](#bib.bib6)] algorithm that aims to mitigate
    the problems from DDPG. It adopted the framework of DDPG by maintaining a sub-actor
    network and a sub-critic network. In each step of training, if utilizes a background
    network to perform a permutation transformations by ordering the sellers according
    to certain metrics, which maintains permutation invariance. In the meantime, it
    applies a recurrent neural network (RNN) on the history of sellers. The outputs
    from the permutation transformation and the outputs from the RNN on histories
    are then integrated together as inputs to the sub-actor and sub-critic networks.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Cai ç­‰äººæå‡ºäº† IA(GRU) [[6](#bib.bib6)] ç®—æ³•ï¼Œæ—¨åœ¨ç¼“è§£ DDPG çš„é—®é¢˜ã€‚å®ƒé‡‡ç”¨äº† DDPG çš„æ¡†æ¶ï¼Œé€šè¿‡ç»´æŠ¤ä¸€ä¸ªå­æ¼”å‘˜ç½‘ç»œå’Œä¸€ä¸ªå­è¯„è®ºå®¶ç½‘ç»œæ¥å®ç°ã€‚åœ¨æ¯ä¸€æ­¥è®­ç»ƒä¸­ï¼Œå¦‚æœåˆ©ç”¨ä¸€ä¸ªèƒŒæ™¯ç½‘ç»œé€šè¿‡æ ¹æ®æŸäº›æŒ‡æ ‡å¯¹å–å®¶è¿›è¡Œæ’åˆ—å˜æ¢ï¼Œä»è€Œä¿æŒæ’åˆ—ä¸å˜æ€§ã€‚åŒæ—¶ï¼Œå®ƒåœ¨å–å®¶çš„å†å²è®°å½•ä¸Šåº”ç”¨äº†é€’å½’ç¥ç»ç½‘ç»œ
    (RNN)ã€‚æ’åˆ—å˜æ¢çš„è¾“å‡ºå’Œ RNN åœ¨å†å²è®°å½•ä¸Šçš„è¾“å‡ºè¢«æ•´åˆåœ¨ä¸€èµ·ï¼Œä½œä¸ºå­æ¼”å‘˜å’Œå­è¯„è®ºå®¶ç½‘ç»œçš„è¾“å…¥ã€‚
- en: In reality, participants of online auctions are constrained from both informational
    and computational aspects and therefore they are not fully rational. In addition,
    the historical data can be limited to the ones generated by mechanisms that are
    defined by only few sets of parameters, and therefore we do not have enough exploration
    for the past data. Both participants and auction system designers are impacted
    by multiple and complicated factors, and therefore their decisions are changing
    over time. To overcome those difficulties, Tang et al. models each player as an
    independent local Markov decision process [[27](#bib.bib27)], where a local state
    encodes the part of historical actions and outcomes that the player can observe
    so far.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œåœ¨çº¿æ‹å–çš„å‚ä¸è€…åœ¨ä¿¡æ¯å’Œè®¡ç®—æ–¹é¢éƒ½å—åˆ°é™åˆ¶ï¼Œå› æ­¤ä»–ä»¬å¹¶ä¸å®Œå…¨ç†æ€§ã€‚æ­¤å¤–ï¼Œå†å²æ•°æ®å¯èƒ½ä»…é™äºç”±ä»…å°‘æ•°å‚æ•°é›†å®šä¹‰çš„æœºåˆ¶ç”Ÿæˆçš„æ•°æ®ï¼Œå› æ­¤æˆ‘ä»¬å¯¹è¿‡å»æ•°æ®çš„æ¢ç´¢ä¸è¶³ã€‚å‚ä¸è€…å’Œæ‹å–ç³»ç»Ÿè®¾è®¡å¸ˆå—åˆ°å¤šç§å¤æ‚å› ç´ çš„å½±å“ï¼Œå› æ­¤ä»–ä»¬çš„å†³ç­–éšç€æ—¶é—´å˜åŒ–ã€‚ä¸ºäº†å…‹æœè¿™äº›å›°éš¾ï¼ŒTangç­‰äººå°†æ¯ä¸ªç©å®¶å»ºæ¨¡ä¸ºä¸€ä¸ªç‹¬ç«‹çš„å±€éƒ¨é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹[[27](#bib.bib27)]ï¼Œå…¶ä¸­å±€éƒ¨çŠ¶æ€ç¼–ç äº†ç©å®¶è¿„ä»Šä¸ºæ­¢å¯ä»¥è§‚å¯Ÿåˆ°çš„å†å²è¡ŒåŠ¨å’Œç»“æœçš„ä¸€éƒ¨åˆ†ã€‚
- en: Tang et al. uses DDPG infrastructure to handle continuous action space, but
    it decomposes the original neural netowrk into a set of sub-networks, one for
    each seller, to handle the huge number of states. It depends on the assumption
    that sellers are independent and the Q-values are additive among multiple sellers.
    It uses LSTM to adaptively learn from its past bidding data and feedback to predict
    future bid distribution, while it does not explicitly model each advertiserâ€™s
    bidding strategy. In order to optimize the designerâ€™s markov decision process,
    it discretizes the action space and then use the Monte-Carlo tree search (MCTS)
    [[23](#bib.bib23)] to speed up the forward-looking search. Experiments and case
    studies show that the dynamic pricing scheme proposed by Tang et al. outperforms
    all static schemes with large margins.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Tangç­‰äººä½¿ç”¨DDPGåŸºç¡€è®¾æ–½å¤„ç†è¿ç»­åŠ¨ä½œç©ºé—´ï¼Œä½†å®ƒå°†åŸå§‹ç¥ç»ç½‘ç»œåˆ†è§£ä¸ºä¸€ç»„å­ç½‘ç»œï¼Œæ¯ä¸ªå–å®¶ä¸€ä¸ªï¼Œä»¥å¤„ç†å¤§é‡çŠ¶æ€ã€‚å®ƒä¾èµ–äºå–å®¶ç›¸äº’ç‹¬ç«‹å’Œå¤šä¸ªå–å®¶ä¹‹é—´Qå€¼å¯åŠ çš„å‡è®¾ã€‚å®ƒä½¿ç”¨LSTMä»è¿‡å»çš„ç«æ ‡æ•°æ®å’Œåé¦ˆä¸­è‡ªé€‚åº”åœ°å­¦ä¹ ï¼Œä»¥é¢„æµ‹æœªæ¥çš„ç«æ ‡åˆ†å¸ƒï¼Œè€Œä¸æ˜ç¡®å»ºæ¨¡æ¯ä¸ªå¹¿å‘Šä¸»çš„ç«æ ‡ç­–ç•¥ã€‚ä¸ºäº†ä¼˜åŒ–è®¾è®¡å¸ˆçš„é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹ï¼Œå®ƒå°†åŠ¨ä½œç©ºé—´ç¦»æ•£åŒ–ï¼Œç„¶åä½¿ç”¨è’™ç‰¹å¡ç½—æ ‘æœç´¢ï¼ˆMCTSï¼‰[[23](#bib.bib23)]æ¥åŠ é€Ÿå‰ç»æ€§æœç´¢ã€‚å®éªŒå’Œæ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼ŒTangç­‰äººæå‡ºçš„åŠ¨æ€å®šä»·æ–¹æ¡ˆåœ¨å¤§å¹…åº¦è¶…è¶Šæ‰€æœ‰é™æ€æ–¹æ¡ˆã€‚
- en: Another challenge in the dynamic online auction systems is the variety of performance
    metrics users and designers consider when making their decisions, while most state-of-the-art
    auction mechanisms only optimizes a single performance metrics, such as revenue
    or social welfare. Zhang et al. identified a list of performance metrics [[31](#bib.bib31)]
    that can be considered by users, advertisers, and the ad platform.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ¨æ€åœ¨çº¿æ‹å–ç³»ç»Ÿä¸­çš„å¦ä¸€ä¸ªæŒ‘æˆ˜æ˜¯ç”¨æˆ·å’Œè®¾è®¡å¸ˆåœ¨å†³ç­–æ—¶è€ƒè™‘çš„ç»©æ•ˆæŒ‡æ ‡ç§ç±»ï¼Œè€Œå¤§å¤šæ•°å…ˆè¿›çš„æ‹å–æœºåˆ¶åªä¼˜åŒ–å•ä¸€ç»©æ•ˆæŒ‡æ ‡ï¼Œå¦‚æ”¶å…¥æˆ–ç¤¾ä¼šç¦åˆ©ã€‚Zhangç­‰äººç¡®å®šäº†ä¸€ä»½æ€§èƒ½æŒ‡æ ‡åˆ—è¡¨[[31](#bib.bib31)]ï¼Œç”¨æˆ·ã€å¹¿å‘Šå•†å’Œå¹¿å‘Šå¹³å°å¯ä»¥è€ƒè™‘è¿™äº›æŒ‡æ ‡ã€‚
- en: '1.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Revenue Per Mille (RPM): $RPM=\frac{\sum click\times PPC}{\sum impression}\times
    1000$, where PPC is the payment for winning ads.'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¯åƒæ¬¡å±•ç¤ºçš„æ”¶å…¥ï¼ˆRPMï¼‰ï¼š$RPM=\frac{\sum click\times PPC}{\sum impression}\times 1000$ï¼Œå…¶ä¸­PPCæ˜¯èµ¢å¾—å¹¿å‘Šçš„ä»˜æ¬¾ã€‚
- en: '2.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Click-Through Rate (CTR): $CTR=\frac{\sum click}{\sum impression}$.'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç‚¹å‡»ç‡ï¼ˆCTRï¼‰ï¼š$CTR=\frac{\sum click}{\sum impression}$ã€‚
- en: '3.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Add-to-Cart Rate (ACR): $ACR=\frac{\sum add-to-cart}{\sum impression}$.'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŠ å…¥è´­ç‰©è½¦ç‡ï¼ˆACRï¼‰ï¼š$ACR=\frac{\sum add-to-cart}{\sum impression}$ã€‚
- en: '4.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: 'Conversion Rate (CVR): $CVR=\frac{\sum order}{\sum impression}$.'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è½¬åŒ–ç‡ï¼ˆCVRï¼‰ï¼š$CVR=\frac{\sum order}{\sum impression}$ã€‚
- en: '5.'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: 'GMV Per Mille (GPM): $GPM=\frac{\sum merchandisevolume}{\sum impression}\times
    1000$.'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¯åƒæ¬¡å±•ç¤ºçš„å•†å“äº¤æ˜“é¢ï¼ˆGPMï¼‰ï¼š$GPM=\frac{\sum merchandisevolume}{\sum impression}\times 1000$ã€‚
- en: Zhang et al. proposed the Deep GSP [[31](#bib.bib31)] that can optimize multiple
    performance metrics as in Equation [19](#S4.E19 "In 4 Reinforcement Learning (RL)
    Infrastructure â€£ A Survey of Online Auction Mechanism Design Using Deep Learning
    Approaches"), where $b$ is the bid vector from users, $\mathcal{M}$ is the auction
    mechanism, $f_{j}$ is the $j^{th}$ performance metrics function, and $w_{j}$ is
    the weights associated with $j^{th}$ performance metrics and can be adjusted by
    the auction platform administrators from time to time.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Zhangç­‰äººæå‡ºäº†æ·±åº¦GSP [[31](#bib.bib31)]ï¼Œå®ƒå¯ä»¥ä¼˜åŒ–å¤šä¸ªæ€§èƒ½æŒ‡æ ‡ï¼Œå¦‚å…¬å¼[19](#S4.E19 "åœ¨4å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åŸºç¡€è®¾æ–½
    â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡ç»¼è¿°")ï¼Œå…¶ä¸­$b$æ˜¯ç”¨æˆ·çš„ç«æ ‡å‘é‡ï¼Œ$\mathcal{M}$æ˜¯æ‹å–æœºåˆ¶ï¼Œ$f_{j}$æ˜¯ç¬¬$j$ä¸ªç»©æ•ˆæŒ‡æ ‡å‡½æ•°ï¼Œ$w_{j}$æ˜¯ä¸ç¬¬$j$ä¸ªç»©æ•ˆæŒ‡æ ‡ç›¸å…³çš„æƒé‡ï¼Œå¯ä»¥ç”±æ‹å–å¹³å°ç®¡ç†å‘˜ä¸æ—¶è°ƒæ•´ã€‚
- en: '|  | <math   alttext="\begin{split}\mathcal{M}=argmax_{\mathcal{M}}E_{b\sim\mathcal{D}}[\sum_{j=1}^{L}w_{j}\times
    f_{j}(b;\mathcal{M})]\\ \text{s.t. Game Equilibrium constraints,}\\'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}\mathcal{M}=argmax_{\mathcal{M}}E_{b\sim\mathcal{D}}[\sum_{j=1}^{L}w_{j}\times
    f_{j}(b;\mathcal{M})]\\ \text{s.t. æ¸¸æˆå‡è¡¡çº¦æŸï¼Œ}\\'
- en: \text{Smooth Transition constraints}\end{split}" display="block"><semantics
    ><mtable displaystyle="true" rowspacing="0pt" ><mtr  ><mtd columnalign="right"  ><mrow
    ><mi >â„³</mi><mo >=</mo><mrow ><mi  >a</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><mi
    >r</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><mi >g</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><mi
    >m</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><mi >a</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><msub
    ><mi >x</mi><mi >â„³</mi></msub><mo lspace="0em" rspace="0em" >â€‹</mo><msub ><mi
    >E</mi><mrow ><mi >b</mi><mo >âˆ¼</mo><mi >ğ’Ÿ</mi></mrow></msub><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mrow ><mo stretchy="false" >[</mo><mrow ><munderover ><mo
    lspace="0em" movablelimits="false" >âˆ‘</mo><mrow ><mi >j</mi><mo >=</mo><mn >1</mn></mrow><mi
    >L</mi></munderover><mrow ><mrow ><msub ><mi  >w</mi><mi >j</mi></msub><mo lspace="0.222em"
    rspace="0.222em"  >Ã—</mo><msub ><mi >f</mi><mi >j</mi></msub></mrow><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mrow ><mo stretchy="false"  >(</mo><mi >b</mi><mo >;</mo><mi
    >â„³</mi><mo stretchy="false"  >)</mo></mrow></mrow></mrow><mo stretchy="false"  >]</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><mtext >s.t. Game Equilibrium constraints,</mtext></mtd></mtr><mtr  ><mtd
    columnalign="right"  ><mtext >Smooth Transition constraints</mtext></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply  ><ci >â„³</ci><apply ><ci  >ğ‘</ci><ci >ğ‘Ÿ</ci><ci
    >ğ‘”</ci><ci  >ğ‘š</ci><ci >ğ‘</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >ğ‘¥</ci><ci  >â„³</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >ğ¸</ci><apply ><csymbol cd="latexml"  >similar-to</csymbol><ci >ğ‘</ci><ci >ğ’Ÿ</ci></apply></apply><apply
    ><csymbol cd="latexml" >delimited-[]</csymbol><apply ><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><apply ><csymbol cd="ambiguous" >subscript</csymbol><apply
    ><ci >ğ‘—</ci><cn type="integer" >1</cn></apply></apply><ci >ğ¿</ci></apply><apply
    ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >ğ‘¤</ci><ci >ğ‘—</ci></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >ğ‘“</ci><ci >ğ‘—</ci></apply></apply><list
    ><ci >ğ‘</ci><ci >â„³</ci></list></apply></apply></apply><ci ><mtext  >s.t. Game
    Equilibrium constraints,</mtext></ci><ci ><mtext  >Smooth Transition constraints</mtext></ci></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}\mathcal{M}=argmax_{\mathcal{M}}E_{b\sim\mathcal{D}}[\sum_{j=1}^{L}w_{j}\times
    f_{j}(b;\mathcal{M})]\\ \text{s.t. Game Equilibrium constraints,}\\ \text{Smooth
    Transition constraints}\end{split}</annotation></semantics></math> |  | (19) |
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: \text{å¹³æ»‘è¿‡æ¸¡çº¦æŸ}\end{split}" display="block"><semantics ><mtable displaystyle="true"
    rowspacing="0pt" ><mtr  ><mtd columnalign="right"  ><mrow ><mi >â„³</mi><mo >=</mo><mrow
    ><mi  >a</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><mi >r</mi><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mi >g</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><mi >m</mi><mo
    lspace="0em" rspace="0em"  >â€‹</mo><mi >a</mi><mo lspace="0em" rspace="0em"  >â€‹</mo><msub
    ><mi >x</mi><mi >â„³</mi></msub><mo lspace="0em" rspace="0em" >â€‹</mo><msub ><mi
    >E</mi><mrow ><mi >b</mi><mo >âˆ¼</mo><mi >ğ’Ÿ</mi></mrow></msub><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mrow ><mo stretchy="false" >[</mo><mrow ><munderover ><mo
    lspace="0em" movablelimits="false" >âˆ‘</mo><mrow ><mi >j</mi><mo >=</mo><mn >1</mn></mrow><mi
    >L</mi></munderover><mrow ><mrow ><msub ><mi  >w</mi><mi >j</mi></msub><mo lspace="0.222em"
    rspace="0.222em"  >Ã—</mo><msub ><mi >f</mi><mi >j</mi></msub></mrow><mo lspace="0em"
    rspace="0em"  >â€‹</mo><mrow ><mo stretchy="false"  >(</mo><mi >b</mi><mo >;</mo><mi
    >â„³</mi><mo stretchy="false"  >)</mo></mrow></mrow></mrow><mo stretchy="false"  >]</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd columnalign="right"  ><mtext >s.t. æ¸¸æˆå‡è¡¡çº¦æŸï¼Œ</mtext></mtd></mtr><mtr  ><mtd
    columnalign="right"  ><mtext >å¹³æ»‘è¿‡æ¸¡çº¦æŸ</mtext></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply  ><ci >â„³</ci><apply ><ci  >ğ‘</ci><ci >ğ‘Ÿ</ci><ci
    >ğ‘”</ci><ci  >ğ‘š</ci><ci >ğ‘</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >ğ‘¥</ci><ci  >â„³</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >ğ¸</ci><apply ><csymbol cd="latexml"  >similar-to</csymbol><ci >ğ‘</ci><ci >ğ’Ÿ</ci></apply></apply><apply
    ><csymbol cd="latexml" >delimited-[]</csymbol><apply ><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><apply ><csymbol cd="ambiguous" >subscript</csymbol><apply
    ><ci >ğ‘—</ci><cn type="integer" >1</cn></apply></apply><ci >ğ¿</ci></apply><apply
    ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >ğ‘¤</ci><ci >ğ‘—</ci></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >ğ‘“</ci><ci >ğ‘—</ci></apply></apply><list
    ><ci >ğ‘</ci><ci >â„³</ci></list></apply></apply></apply><ci ><mtext  >s.t. æ¸¸æˆå‡è¡¡çº¦æŸï¼Œ</mtext></ci><ci
    ><mtext  >å¹³æ»‘è¿‡æ¸¡çº¦æŸ</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >\begin{split}\mathcal{M}=argmax_{\mathcal{M}}E_{b\sim\mathcal{D}}[\sum_{j=1}^{L}w_{j}\times
    f_{j}(b;\mathcal{M})]\\ \text{s.t. æ¸¸æˆå‡è¡¡çº¦æŸï¼Œ}\\ \text{å¹³æ»‘è¿‡æ¸¡çº¦æŸ}\end{split}</annotation></semantics></math>
    |  | (19) |
- en: The Deep GSP auction is built upon the classical generalized second-price auction.
    It takes in the features of items (e.g. category, historical click-through rate),
    user profile (e.g. gender, age, income), and user preference (e.g. budget, marketing
    demands) as inputs to a deep neural network, which integrates those features with
    the bids into an input vector $x_{i}$ and map them to a rank score $r_{i}=R_{\theta}(b_{i};x_{i})$,
    where $R_{\theta}(b_{i};x_{i})$ is the mapping function. Bidders are then sorted
    based non-increasingly based on their rank scores, and the top-K bidders would
    win the auction. The payments of the winning bidders are based on the bids from
    the next highest bidders.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: æ·±åº¦GSPæ‹å–å»ºç«‹åœ¨ç»å…¸çš„å¹¿ä¹‰ç¬¬äºŒä»·æ ¼æ‹å–çš„åŸºç¡€ä¸Šã€‚å®ƒå°†é¡¹ç›®çš„ç‰¹å¾ï¼ˆä¾‹å¦‚ç±»åˆ«ã€å†å²ç‚¹å‡»ç‡ï¼‰ã€ç”¨æˆ·èµ„æ–™ï¼ˆä¾‹å¦‚æ€§åˆ«ã€å¹´é¾„ã€æ”¶å…¥ï¼‰ä»¥åŠç”¨æˆ·åå¥½ï¼ˆä¾‹å¦‚é¢„ç®—ã€å¸‚åœºéœ€æ±‚ï¼‰ä½œä¸ºè¾“å…¥ï¼Œé€å…¥æ·±åº¦ç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œå°†è¿™äº›ç‰¹å¾ä¸ç«æ ‡ç»“åˆæˆä¸€ä¸ªè¾“å…¥å‘é‡
    $x_{i}$ï¼Œå¹¶å°†å…¶æ˜ å°„åˆ°ä¸€ä¸ªæ’åå¾—åˆ† $r_{i}=R_{\theta}(b_{i};x_{i})$ï¼Œå…¶ä¸­ $R_{\theta}(b_{i};x_{i})$
    æ˜¯æ˜ å°„å‡½æ•°ã€‚ç„¶åï¼ŒæŠ•æ ‡è€…æ ¹æ®å…¶æ’åå¾—åˆ†æŒ‰éé€’å¢é¡ºåºæ’åºï¼Œå‰KåæŠ•æ ‡è€…å°†èµ¢å¾—æ‹å–ã€‚è·èƒœæŠ•æ ‡è€…çš„æ”¯ä»˜åŸºäºä¸‹ä¸€ä¸ªæœ€é«˜æŠ•æ ‡è€…çš„æŠ•æ ‡ã€‚
- en: The mapping function $R_{\theta}(b_{i};x_{i})$ needs to be monotone with respect
    to the bids $b_{i}$, in order to satisfy the game equilibrium constraint. Some
    pieces of previous research enforced monotonicity by designing specific neural
    network architectures, but it increases the computational complexity for the training
    procedure. Therefore, Zhang et al. directly incorporate the monotonicity constraint
    by introducing a point-wise monotonicity penalty term (Equation [20](#S4.E20 "In
    4 Reinforcement Learning (RL) Infrastructure â€£ A Survey of Online Auction Mechanism
    Design Using Deep Learning Approaches")) into the loss function, where $\pi_{\theta}(b_{i};x_{i})$
    is a non-linear function with bid and is parametrized using a deep neural network.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜ å°„å‡½æ•° $R_{\theta}(b_{i};x_{i})$ éœ€è¦å¯¹æŠ•æ ‡ $b_{i}$ ä¿æŒå•è°ƒæ€§ï¼Œä»¥æ»¡è¶³åšå¼ˆå‡è¡¡çº¦æŸã€‚ä¸€äº›æ—©æœŸç ”ç©¶é€šè¿‡è®¾è®¡ç‰¹å®šçš„ç¥ç»ç½‘ç»œæ¶æ„æ¥å¼ºåˆ¶å•è°ƒæ€§ï¼Œä½†è¿™å¢åŠ äº†è®­ç»ƒè¿‡ç¨‹çš„è®¡ç®—å¤æ‚åº¦ã€‚å› æ­¤ï¼Œå¼ ç­‰äººé€šè¿‡åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥é€ç‚¹å•è°ƒæ€§æƒ©ç½šé¡¹ï¼ˆæ–¹ç¨‹[20](#S4.E20
    "åœ¨4 å¼ºåŒ–å­¦ä¹  (RL) åŸºç¡€è®¾æ–½ â€£ ä½¿ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒæŸ¥")ï¼‰æ¥ç›´æ¥çº³å…¥å•è°ƒæ€§çº¦æŸï¼Œå…¶ä¸­ $\pi_{\theta}(b_{i};x_{i})$
    æ˜¯ä¸€ä¸ªéçº¿æ€§å‡½æ•°ï¼Œå¹¶é€šè¿‡æ·±åº¦ç¥ç»ç½‘ç»œå‚æ•°åŒ–ã€‚
- en: '|  | $\begin{split}\mathcal{L}_{mono}=&amp;\sum_{i=1}^{N}\max(0,-\triangledown_{b}R_{\theta}(b_{i};x_{i}))\\
    =&amp;\sum_{i=1}^{N}\max(0,-(\pi_{\theta}(b_{i};x_{i})+b_{i}\triangledown_{b}\pi_{\theta}(b_{i};x_{i})))\end{split}$
    |  | (20) |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\mathcal{L}_{mono}=&amp;\sum_{i=1}^{N}\max(0,-\triangledown_{b}R_{\theta}(b_{i};x_{i}))\\
    =&amp;\sum_{i=1}^{N}\max(0,-(\pi_{\theta}(b_{i};x_{i})+b_{i}\triangledown_{b}\pi_{\theta}(b_{i};x_{i})))\end{split}$
    |  | (20) |'
- en: The smooth transition constraint is imposed in Equation [21](#S4.E21 "In 4 Reinforcement
    Learning (RL) Infrastructure â€£ A Survey of Online Auction Mechanism Design Using
    Deep Learning Approaches"), which ensures that the advertiserâ€™s utility would
    not fluctuate too much when the auction mechanism is switched towards another
    objective.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: å¹³æ»‘è¿‡æ¸¡çº¦æŸåœ¨æ–¹ç¨‹[21](#S4.E21 "åœ¨4 å¼ºåŒ–å­¦ä¹  (RL) åŸºç¡€è®¾æ–½ â€£ ä½¿ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒæŸ¥")ä¸­æ–½åŠ ï¼Œè¿™ç¡®ä¿äº†å½“æ‹å–æœºåˆ¶åˆ‡æ¢åˆ°å¦ä¸€ä¸ªç›®æ ‡æ—¶ï¼Œå¹¿å‘Šä¸»çš„æ•ˆç”¨ä¸ä¼šæ³¢åŠ¨å¤ªå¤§ã€‚
- en: '|  | $u_{i}(\mathcal{M})\geq(1-\epsilon)\times\bar{u}_{i}(\mathcal{M}_{0})$
    |  | (21) |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '|  | $u_{i}(\mathcal{M})\geq(1-\epsilon)\times\bar{u}_{i}(\mathcal{M}_{0})$
    |  | (21) |'
- en: 5 DeepSet Infrastructure
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 æ·±åº¦é›†åŸºç¡€è®¾æ–½
- en: Most deep neural network has an implicit constraint on the position of each
    input, while in reality the items in auction do not have an inherent ordering.
    Cai et al. uses permutation transformation to mitigate the position effect by
    ordering the sellers based on some metrics. Liu et al. took a step further by
    removing the ordering effect completely. They introduced Deep Neural Auction (DNA)
    [[16](#bib.bib16)] that is built on the DeepSets [[30](#bib.bib30)] architecture.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°æ·±åº¦ç¥ç»ç½‘ç»œå¯¹æ¯ä¸ªè¾“å…¥çš„ä½ç½®æœ‰éšå«çº¦æŸï¼Œè€Œå®é™…ä¸Šæ‹å–ä¸­çš„ç‰©å“å¹¶æ²¡æœ‰å›ºæœ‰çš„æ’åºã€‚è”¡ç­‰äººé€šè¿‡æ ¹æ®ä¸€äº›æŒ‡æ ‡å¯¹å–å®¶è¿›è¡Œæ’åºæ¥ä½¿ç”¨æ’åˆ—å˜æ¢æ¥ç¼“è§£ä½ç½®æ•ˆåº”ã€‚åˆ˜ç­‰äººè¿›ä¸€æ­¥é€šè¿‡å®Œå…¨æ¶ˆé™¤æ’åºæ•ˆåº”è¿ˆå‡ºäº†æ­¥ä¼ã€‚ä»–ä»¬å¼•å…¥äº†åŸºäºDeepSets
    [[30](#bib.bib30)] æ¶æ„çš„æ·±åº¦ç¥ç»æ‹å–ï¼ˆDNAï¼‰ [[16](#bib.bib16)]ã€‚
- en: The set encoder for DNA is composed of two groups of layers $\phi_{1}$ and $\phi_{2}$.
    Each instance $x_{i}$ is first mapped to a high-dimensional latent space using
    the shared fully connected layers $\phi_{1}$, followed by the Exponential Linear
    Unit (ELU) [[7](#bib.bib7)] activation function $\sigma$. Then, it is processed
    with symmetric aggregation pooling (e.g. avgpool) to build the final set embedding
    $h_{i}^{\prime}$ for each ad $i$ with another fully connected layer $\phi_{2}$.
    The entire procedure is described in Equation [22](#S5.E22 "In 5 DeepSet Infrastructure
    â€£ A Survey of Online Auction Mechanism Design Using Deep Learning Approaches"),
    where $h_{-i}$ represent the hidden states from all bidders except $i$.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: DNA çš„é›†åˆç¼–ç å™¨ç”±ä¸¤ç»„å±‚ $\phi_{1}$ å’Œ $\phi_{2}$ ç»„æˆã€‚æ¯ä¸ªå®ä¾‹ $x_{i}$ é¦–å…ˆé€šè¿‡å…±äº«çš„å…¨è¿æ¥å±‚ $\phi_{1}$
    æ˜ å°„åˆ°é«˜ç»´æ½œåœ¨ç©ºé—´ï¼Œç„¶åé€šè¿‡æŒ‡æ•°çº¿æ€§å•å…ƒï¼ˆELUï¼‰ [[7](#bib.bib7)] æ¿€æ´»å‡½æ•° $\sigma$ å¤„ç†ã€‚æ¥ç€ï¼Œé€šè¿‡å¯¹ç§°èšåˆæ± åŒ–ï¼ˆä¾‹å¦‚ avgpoolï¼‰å¤„ç†ï¼Œä»¥å¦ä¸€å…¨è¿æ¥å±‚
    $\phi_{2}$ ä¸ºæ¯ä¸ªå¹¿å‘Š $i$ æ„å»ºæœ€ç»ˆçš„é›†åˆåµŒå…¥ $h_{i}^{\prime}$ã€‚æ•´ä¸ªè¿‡ç¨‹åœ¨æ–¹ç¨‹ [22](#S5.E22 "In 5 DeepSet
    Infrastructure â€£ A Survey of Online Auction Mechanism Design Using Deep Learning
    Approaches") ä¸­æè¿°ï¼Œå…¶ä¸­ $h_{-i}$ è¡¨ç¤ºé™¤ $i$ å¤–æ‰€æœ‰ç«æ ‡è€…çš„éšè—çŠ¶æ€ã€‚
- en: '|  | $\begin{split}h_{i}=\sigma(\phi_{1}(x_{i}))\\ h_{i}^{\prime}=\sigma(\phi_{2}(\text{avgpool}(h_{-i})))\end{split}$
    |  | (22) |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}h_{i}=\sigma(\phi_{1}(x_{i}))\\ h_{i}^{\prime}=\sigma(\phi_{2}(\text{avgpool}(h_{-i})))\end{split}$
    |  | (22) |'
- en: DNA uses context-aware rank score uses a strictly monotone neural network with
    respect to bid, and supports efficient inverse transform given the next highest
    rank score. The rank score can be obtained using Equation [23](#S5.E23 "In 5 DeepSet
    Infrastructure â€£ A Survey of Online Auction Mechanism Design Using Deep Learning
    Approaches") and the price can be obtained using Equation [24](#S5.E24 "In 5 DeepSet
    Infrastructure â€£ A Survey of Online Auction Mechanism Design Using Deep Learning
    Approaches"), where $w_{qz}$, $w_{qz}^{\prime}$, and $\alpha_{qz}$ are weights
    of the neural network.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: DNA ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ’ååˆ†æ•°ï¼Œåˆ©ç”¨ç›¸å¯¹äºæŠ•æ ‡çš„ä¸¥æ ¼å•è°ƒç¥ç»ç½‘ç»œï¼Œå¹¶åœ¨ç»™å®šä¸‹ä¸€ä¸ªæœ€é«˜æ’ååˆ†æ•°æ—¶æ”¯æŒé«˜æ•ˆçš„é€†å˜æ¢ã€‚æ’ååˆ†æ•°å¯ä»¥ä½¿ç”¨æ–¹ç¨‹ [23](#S5.E23
    "In 5 DeepSet Infrastructure â€£ A Survey of Online Auction Mechanism Design Using
    Deep Learning Approaches") è·å¾—ï¼Œä»·æ ¼å¯ä»¥ä½¿ç”¨æ–¹ç¨‹ [24](#S5.E24 "In 5 DeepSet Infrastructure
    â€£ A Survey of Online Auction Mechanism Design Using Deep Learning Approaches")
    è·å¾—ï¼Œå…¶ä¸­ $w_{qz}$ã€$w_{qz}^{\prime}$ å’Œ $\alpha_{qz}$ æ˜¯ç¥ç»ç½‘ç»œçš„æƒé‡ã€‚
- en: '|  | $r_{i}=\min_{q\in[Q]}\max_{z\in[Z]}(e^{w_{qz}}\times b_{i}+w_{qz}^{\prime}\times
    x_{i}^{\prime}+\alpha_{qz})$ |  | (23) |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '|  | $r_{i}=\min_{q\in[Q]}\max_{z\in[Z]}(e^{w_{qz}}\times b_{i}+w_{qz}^{\prime}\times
    x_{i}^{\prime}+\alpha_{qz})$ |  | (23) |'
- en: '|  | $p_{i}=\max_{z\in[Z]}\min_{q\in[Q]}e^{-W_{qz}}(r_{i+1}-\alpha_{qz}-w_{qz}^{\prime}\times
    x_{i}^{\prime})$ |  | (24) |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|  | $p_{i}=\max_{z\in[Z]}\min_{q\in[Q]}e^{-W_{qz}}(r_{i+1}-\alpha_{qz}-w_{qz}^{\prime}\times
    x_{i}^{\prime})$ |  | (24) |'
- en: This partially monotone MIN-MAX neural network represented by Equation [23](#S5.E23
    "In 5 DeepSet Infrastructure â€£ A Survey of Online Auction Mechanism Design Using
    Deep Learning Approaches") has been proved to be able to approximate any function
    [[8](#bib.bib8)].
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±æ–¹ç¨‹ [23](#S5.E23 "In 5 DeepSet Infrastructure â€£ A Survey of Online Auction Mechanism
    Design Using Deep Learning Approaches") è¡¨ç¤ºçš„éƒ¨åˆ†å•è°ƒ MIN-MAX ç¥ç»ç½‘ç»œå·²ç»è¢«è¯æ˜èƒ½å¤Ÿè¿‘ä¼¼ä»»ä½•å‡½æ•° [[8](#bib.bib8)]ã€‚
- en: '|  | $\hat{M}_{r}[k,:]=\text{softmax}(\frac{(N+1-2k)r-A_{r}\mathbbm{1}}{\tau})$
    |  | (25) |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{M}_{r}[k,:]=\text{softmax}(\frac{(N+1-2k)r-A_{r}\mathbbm{1}}{\tau})$
    |  | (25) |'
- en: The DNA also model the whole process of allocation and payment inside the neural
    network framework, as treating allocation and payment as an agnostic environment
    can limit the deep learning results. One of the challenges is that both the allocation
    and payment are built on a basic sorting operation, which is not differentiable.
    Liu et al. overcome this issue by proposing a differentiable sorting engine that
    caters to the top-K selection in the multi-slot auctions, leveraging Neural-Sort
    [[12](#bib.bib12)].
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: DNA è¿˜åœ¨ç¥ç»ç½‘ç»œæ¡†æ¶å†…å»ºæ¨¡äº†æ•´ä¸ªåˆ†é…å’Œæ”¯ä»˜è¿‡ç¨‹ï¼Œå› ä¸ºå°†åˆ†é…å’Œæ”¯ä»˜è§†ä¸ºä¸€ä¸ªä¸å¯çŸ¥ç¯å¢ƒå¯èƒ½ä¼šé™åˆ¶æ·±åº¦å­¦ä¹ çš„ç»“æœã€‚å…¶ä¸­ä¸€ä¸ªæŒ‘æˆ˜æ˜¯ï¼Œåˆ†é…å’Œæ”¯ä»˜éƒ½å»ºç«‹åœ¨ä¸€ä¸ªåŸºæœ¬çš„æ’åºæ“ä½œä¸Šï¼Œè€Œè¿™ä¸ªæ“ä½œæ˜¯ä¸å¯å¾®åˆ†çš„ã€‚Liu
    ç­‰äººé€šè¿‡æå‡ºä¸€ä¸ªé€‚ç”¨äºå¤šæ’æ§½æ‹å–ä¸­å‰ K åé€‰æ‹©çš„å¯å¾®åˆ†æ’åºå¼•æ“â€”â€”Neural-Sort [[12](#bib.bib12)] æ¥å…‹æœè¿™ä¸ªé—®é¢˜ã€‚
- en: In Equation [25](#S5.E25 "In 5 DeepSet Infrastructure â€£ A Survey of Online Auction
    Mechanism Design Using Deep Learning Approaches"), the intuitive interpretation
    of $\hat{M}_{r}[k,:]$ is the choice probabilities on all elements for getting
    the $k^{th}$ highest item. Where $A_{r}[i,j]=|r_{i}-r_{j}|$, and $\mathbbm{1}$
    denotes the column vector of all ones. The top-K payments can therefore by recovered
    by a simple matrix multiplication in Equation [26](#S5.E26 "In 5 DeepSet Infrastructure
    â€£ A Survey of Online Auction Mechanism Design Using Deep Learning Approaches").
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ–¹ç¨‹ [25](#S5.E25 "In 5 DeepSet Infrastructure â€£ A Survey of Online Auction Mechanism
    Design Using Deep Learning Approaches") ä¸­ï¼Œ$\hat{M}_{r}[k,:]$ çš„ç›´è§‚è§£é‡Šæ˜¯è·å–ç¬¬ $k^{th}$
    é«˜ç‰©å“çš„æ‰€æœ‰å…ƒç´ ä¸Šçš„é€‰æ‹©æ¦‚ç‡ã€‚å…¶ä¸­ $A_{r}[i,j]=|r_{i}-r_{j}|$ï¼Œ$\mathbbm{1}$ è¡¨ç¤ºå…¨ä¸ºä¸€çš„åˆ—å‘é‡ã€‚å› æ­¤ï¼Œé¡¶çº§æ”¯ä»˜å¯ä»¥é€šè¿‡æ–¹ç¨‹
    [26](#S5.E26 "In 5 DeepSet Infrastructure â€£ A Survey of Online Auction Mechanism
    Design Using Deep Learning Approaches") ä¸­çš„ç®€å•çŸ©é˜µä¹˜æ³•æ¥æ¢å¤ã€‚
- en: '|  | $f_{pay}=\hat{M}_{r}[1:K,:]\cdot[p_{1},p_{2},\dots,p_{N}]^{T}$ |  | (26)
    |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '|  | $f_{pay}=\hat{M}_{r}[1:K,:]\cdot[p_{1},p_{2},\dots,p_{N}]^{T}$ |  | (26)
    |'
- en: 6 Constraints and Concerns
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 çº¦æŸå’Œå…³æ³¨ç‚¹
- en: 'Online auction system is complex gaming system among bidders, sellers, and
    auction system administrators. Merely considering the revenue or social welfare
    for one party is more often sub-optimal. To the best of our knowledge, we have
    identified four large categories of constraints and concerns when administrators
    are designing their auction systems: IC & IR, data sparcity & high dimensionality,
    multiple performance metrics and objectives, and fairness & fraud prevention.
    We will illustrate below why these constraints matter and then summarize how current
    researchers are tackling with them.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çº¿æ‹å–ç³»ç»Ÿæ˜¯ä¸€ä¸ªå¤æ‚çš„æ¸¸æˆç³»ç»Ÿï¼Œæ¶‰åŠç«æ ‡è€…ã€å–å®¶å’Œæ‹å–ç³»ç»Ÿç®¡ç†å‘˜ã€‚ä»…è€ƒè™‘ä¸€ä¸ªæ–¹çš„æ”¶å…¥æˆ–ç¤¾ä¼šç¦åˆ©é€šå¸¸æ˜¯æ¬¡ä¼˜çš„ã€‚æ®æˆ‘ä»¬äº†è§£ï¼Œæˆ‘ä»¬å·²ç»è¯†åˆ«å‡ºåœ¨è®¾è®¡æ‹å–ç³»ç»Ÿæ—¶ç®¡ç†å‘˜é¢ä¸´çš„å››å¤§ç±»çº¦æŸå’Œå…³æ³¨ç‚¹ï¼šIC
    & IRã€æ•°æ®ç¨€ç–æ€§ä¸é«˜ç»´æ€§ã€å¤šç§æ€§èƒ½æŒ‡æ ‡å’Œç›®æ ‡ï¼Œä»¥åŠå…¬å¹³æ€§ä¸é˜²æ¬ºè¯ˆã€‚æˆ‘ä»¬å°†åœ¨ä¸‹é¢è¯´æ˜è¿™äº›çº¦æŸçš„é‡è¦æ€§ï¼Œç„¶åæ€»ç»“å½“å‰ç ”ç©¶äººå‘˜å¦‚ä½•åº”å¯¹è¿™äº›é—®é¢˜ã€‚
- en: 6.1 Incentive Compatibility (IC) & Individual Rationality (IR)
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 æ¿€åŠ±å…¼å®¹æ€§ (IC) å’Œä¸ªäººç†æ€§ (IR)
- en: Auction platform designers are more often interested in maximizing long-term
    objectives [[27](#bib.bib27)]. Therefore, building a reliable system that can
    adapt to the dynamic and complicated environment is crucial for the success.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æ‹å–å¹³å°è®¾è®¡è€…é€šå¸¸æ›´å…³æ³¨äºæœ€å¤§åŒ–é•¿æœŸç›®æ ‡ [[27](#bib.bib27)]ã€‚å› æ­¤ï¼Œå»ºç«‹ä¸€ä¸ªèƒ½å¤Ÿé€‚åº”åŠ¨æ€å’Œå¤æ‚ç¯å¢ƒçš„å¯é ç³»ç»Ÿå¯¹æˆåŠŸè‡³å…³é‡è¦ã€‚
- en: IC property ensures that all agents will achieve the best outcome by reporting
    their values truthfully. Auction participants may come from many different background
    and therefore informational, cognitive, and computational constraints will limit
    their rationality in different extent. The stability and reliability of the system
    will be much harder to maintain if IC cannot be satisfied, as designers and agents
    have to take all potential strategic behaviors of all other agents into account.
    Some researchers accomplished IC by adopting theoretical frameworks, such as GSP
    by DNA [[16](#bib.bib16)] and taxaction principal [[28](#bib.bib28)] by MenuNet
    [[24](#bib.bib24)]. Other researchers [[9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11),
    [14](#bib.bib14), [21](#bib.bib21)] achieved IC by enforcing ex post regret [[9](#bib.bib9)]
    to zero.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: IC æ€§è´¨ç¡®ä¿æ‰€æœ‰ä»£ç†é€šè¿‡çœŸå®æŠ¥å‘Šå…¶ä»·å€¼æ¥è·å¾—æœ€ä½³ç»“æœã€‚æ‹å–å‚ä¸è€…å¯èƒ½æ¥è‡ªä¸åŒçš„èƒŒæ™¯ï¼Œå› æ­¤ä¿¡æ¯ã€è®¤çŸ¥å’Œè®¡ç®—çº¦æŸä¼šåœ¨ä¸åŒç¨‹åº¦ä¸Šé™åˆ¶ä»–ä»¬çš„ç†æ€§ã€‚å¦‚æœæ— æ³•æ»¡è¶³
    ICï¼Œç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯é æ€§å°†æ›´éš¾ç»´æŒï¼Œå› ä¸ºè®¾è®¡è€…å’Œä»£ç†å¿…é¡»è€ƒè™‘æ‰€æœ‰å…¶ä»–ä»£ç†çš„æ½œåœ¨ç­–ç•¥è¡Œä¸ºã€‚ä¸€äº›ç ”ç©¶äººå‘˜é€šè¿‡é‡‡ç”¨ç†è®ºæ¡†æ¶æ¥å®ç° ICï¼Œä¾‹å¦‚ DNA çš„ GSP
    [[16](#bib.bib16)] å’Œ MenuNet [[24](#bib.bib24)] çš„ç¨æ”¶åŸåˆ™ [[28](#bib.bib28)]ã€‚å…¶ä»–ç ”ç©¶äººå‘˜
    [[9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11), [14](#bib.bib14), [21](#bib.bib21)]
    é€šè¿‡å°†äº‹åé—æ†¾ [[9](#bib.bib9)] å¼ºåˆ¶ä¸ºé›¶æ¥å®ç° ICã€‚
- en: IR property is also important as it ensures that all agents are receiving non-negative
    payoff. IR can be ensured by building upon the theoretical results from Myersonâ€™s
    system [[20](#bib.bib20)]. It can also be enforced by integrating an additional
    constraint into the objective function and solve it using Augmented Lagrange Solver
    [[9](#bib.bib9), [10](#bib.bib10)]
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: IR æ€§è´¨ä¹Ÿå¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒç¡®ä¿æ‰€æœ‰ä»£ç†éƒ½èƒ½è·å¾—éè´Ÿçš„æ”¶ç›Šã€‚å¯ä»¥é€šè¿‡åŸºäº Myerson ç³»ç»Ÿçš„ç†è®ºç»“æœæ¥ç¡®ä¿ IR [[20](#bib.bib20)]ã€‚ä¹Ÿå¯ä»¥é€šè¿‡å°†é¢å¤–çº¦æŸé›†æˆåˆ°ç›®æ ‡å‡½æ•°ä¸­å¹¶ä½¿ç”¨å¢å¼ºæ‹‰æ ¼æœ—æ—¥æ±‚è§£å™¨
    [[9](#bib.bib9), [10](#bib.bib10)] æ¥å¼ºåˆ¶æ‰§è¡Œã€‚
- en: 6.2 Data Sparsity & High Dimensionality
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 æ•°æ®ç¨€ç–æ€§ä¸é«˜ç»´æ€§
- en: The action space can blow up very quickly as the number of agents increase.
    The high dimensionality in action space can introduce severe computational burdens.
    In order to mitigate the computational burden, Tang et al. and Cai et al. decomposed
    the neural network into sub-networks for each seller and discretized the action
    spaces [[27](#bib.bib27), [6](#bib.bib6)].
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€ä»£ç†æ•°é‡çš„å¢åŠ ï¼ŒåŠ¨ä½œç©ºé—´å¯èƒ½è¿…é€Ÿè†¨èƒ€ã€‚åŠ¨ä½œç©ºé—´ä¸­çš„é«˜ç»´åº¦å¯èƒ½ä¼šå¼•å…¥ä¸¥é‡çš„è®¡ç®—è´Ÿæ‹…ã€‚ä¸ºäº†å‡è½»è®¡ç®—è´Ÿæ‹…ï¼Œå”ç­‰äººå’Œè”¡ç­‰äººå°†ç¥ç»ç½‘ç»œåˆ†è§£ä¸ºæ¯ä¸ªå–å®¶çš„å­ç½‘ç»œï¼Œå¹¶å¯¹åŠ¨ä½œç©ºé—´è¿›è¡Œç¦»æ•£åŒ–
    [[27](#bib.bib27), [6](#bib.bib6)]ã€‚
- en: In addition, many features are high-dimensional one-hot vectors, so data can
    be very sparse. The original regularization approaches take the entire vector
    into computations and the regularized vector has non-zero entries for most of
    the positions, which increases the computational time for sparse data drastically.
    Zhou et al. proposed a mini-batch aware regularization [[32](#bib.bib32)] approach,
    where only parameters of features appearing in the mini-batch participate in the
    computation of regularization.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œè®¸å¤šç‰¹å¾æ˜¯é«˜ç»´çš„ç‹¬çƒ­ç¼–ç å‘é‡ï¼Œå› æ­¤æ•°æ®å¯èƒ½éå¸¸ç¨€ç–ã€‚åŸå§‹æ­£åˆ™åŒ–æ–¹æ³•ä¼šå°†æ•´ä¸ªå‘é‡çº³å…¥è®¡ç®—ï¼Œå¹¶ä¸”æ­£åˆ™åŒ–å‘é‡åœ¨å¤§å¤šæ•°ä½ç½®ä¸Šéƒ½æœ‰éé›¶æ¡ç›®ï¼Œè¿™ä¼šå¤§å¹…å¢åŠ ç¨€ç–æ•°æ®çš„è®¡ç®—æ—¶é—´ã€‚å‘¨ç­‰äººæå‡ºäº†ä¸€ç§å°æ‰¹é‡æ„ŸçŸ¥çš„æ­£åˆ™åŒ–
    [[32](#bib.bib32)] æ–¹æ³•ï¼Œå…¶ä¸­åªæœ‰å‡ºç°åœ¨å°æ‰¹é‡ä¸­çš„ç‰¹å¾å‚æ•°å‚ä¸æ­£åˆ™åŒ–çš„è®¡ç®—ã€‚
- en: '|  | $w_{j}\leftarrow w_{j}-\eta[\frac{1}{&#124;\mathcal{B}_{m}&#124;}\sum_{(x,y)\in\mathcal{B}_{m}}\frac{\partial
    L(p(x),y)}{\partial w_{j}}+\lambda\frac{\max_{(x,y)\in\mathcal{B}_{m}}1_{x_{j}\neq
    0}}{n_{j}}w_{j}]$ |  | (27) |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '|  | $w_{j}\leftarrow w_{j}-\eta[\frac{1}{\lvert\mathcal{B}_{m}\rvert}\sum_{(x,y)\in\mathcal{B}_{m}}\frac{\partial
    L(p(x),y)}{\partial w_{j}}+\lambda\frac{\max_{(x,y)\in\mathcal{B}_{m}}1_{x_{j}\neq
    0}}{n_{j}}w_{j}]$ |  | (27) |'
- en: The mini-batch aware regularization is shown in Equation [27](#S6.E27 "In 6.2
    Data Sparsity & High Dimensionality â€£ 6 Constraints and Concerns â€£ A Survey of
    Online Auction Mechanism Design Using Deep Learning Approaches"), where $\eta$
    is the learning rate, $\mathcal{B}_{m}$ is the $m^{th}$ batch, $w_{j}$ is the
    weight of $j^{th}$ feature, $n_{j}$ is the number of occurrences of $j^{th}$ feature.
    The numerator $\max_{(x,y)\in\mathcal{B}_{m}}1_{x_{j}\neq 0}$ denotes if at least
    one instance in the $m^{th}$ mini-batch has feature $j$.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: å°æ‰¹é‡æ„ŸçŸ¥çš„æ­£åˆ™åŒ–å¦‚æ–¹ç¨‹ [27](#S6.E27 "åœ¨ 6.2 æ•°æ®ç¨€ç–æ€§ä¸é«˜ç»´åº¦ â€£ 6 çº¦æŸä¸å…³æ³¨ â€£ æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒæŸ¥") ä¸­æ‰€ç¤ºï¼Œå…¶ä¸­
    $\eta$ æ˜¯å­¦ä¹ ç‡ï¼Œ$\mathcal{B}_{m}$ æ˜¯ç¬¬ $m$ æ‰¹æ¬¡ï¼Œ$w_{j}$ æ˜¯ç¬¬ $j$ ç‰¹å¾çš„æƒé‡ï¼Œ$n_{j}$ æ˜¯ç¬¬ $j$ ç‰¹å¾çš„å‡ºç°æ¬¡æ•°ã€‚åˆ†å­
    $\max_{(x,y)\in\mathcal{B}_{m}}1_{x_{j}\neq 0}$ è¡¨ç¤ºç¬¬ $m$ æ‰¹æ¬¡ä¸­æ˜¯å¦è‡³å°‘æœ‰ä¸€ä¸ªå®ä¾‹å…·æœ‰ç‰¹å¾ $j$ã€‚
- en: 6.3 Multiple Performance Metrics and Objectives
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 å¤šé‡æ€§èƒ½æŒ‡æ ‡ä¸ç›®æ ‡
- en: The most intuitive objective for most auction designers is to maximize their
    profit. However, to adapt to the dynamic and complex nature of todayâ€™s online
    auction systems, designers may be better-off if they consider multiple performance
    metrics. Zhang et al. listed out several commonly used performance metrics (See
    [4](#S4 "4 Reinforcement Learning (RL) Infrastructure â€£ A Survey of Online Auction
    Mechanism Design Using Deep Learning Approaches")). Zhang et al. and Liu et al.
    optimizes a linear combination of functions of those metrics, where both the linear
    weights and functions of those metrics and be specified by auction designers [[31](#bib.bib31),
    [16](#bib.bib16)]. Over the time, designers are free to adjust the weights and
    functions if their objectives have changed.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¤§å¤šæ•°æ‹å–è®¾è®¡å¸ˆæ¥è¯´ï¼Œæœ€ç›´è§‚çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–ä»–ä»¬çš„åˆ©æ¶¦ã€‚ç„¶è€Œï¼Œä¸ºäº†é€‚åº”ç°ä»£åœ¨çº¿æ‹å–ç³»ç»Ÿçš„åŠ¨æ€å’Œå¤æ‚æ€§è´¨ï¼Œè®¾è®¡å¸ˆä»¬å¯èƒ½éœ€è¦è€ƒè™‘å¤šä¸ªæ€§èƒ½æŒ‡æ ‡ã€‚å¼ ç­‰äººåˆ—å‡ºäº†å‡ ä¸ªå¸¸ç”¨çš„æ€§èƒ½æŒ‡æ ‡ï¼ˆè§
    [4](#S4 "4 å¼ºåŒ–å­¦ä¹  (RL) åŸºç¡€è®¾æ–½ â€£ æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒæŸ¥")ï¼‰ã€‚å¼ ç­‰äººå’Œåˆ˜ç­‰äººä¼˜åŒ–äº†è¿™äº›æŒ‡æ ‡çš„çº¿æ€§ç»„åˆï¼Œå…¶ä¸­çº¿æ€§æƒé‡å’Œè¿™äº›æŒ‡æ ‡çš„å‡½æ•°éƒ½ç”±æ‹å–è®¾è®¡å¸ˆæŒ‡å®š
    [[31](#bib.bib31), [16](#bib.bib16)]ã€‚éšç€æ—¶é—´çš„æ¨ç§»ï¼Œå¦‚æœç›®æ ‡å‘ç”Ÿå˜åŒ–ï¼Œè®¾è®¡å¸ˆå¯ä»¥è‡ªç”±è°ƒæ•´æƒé‡å’Œå‡½æ•°ã€‚
- en: 6.4 Fairness & Fraud Prevention
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 å…¬å¹³æ€§ä¸é˜²æ¬ºè¯ˆ
- en: Due to the biases in the training data, many online platforms have discriminatory
    ad allocations among different demography [[14](#bib.bib14)]. One of the major
    social problems associated with online advertising is the use in the job market,
    where unfairness can be very detrimental to the equality and the protection of
    underrepresented groups.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºè®­ç»ƒæ•°æ®ä¸­çš„åå·®ï¼Œè®¸å¤šåœ¨çº¿å¹³å°åœ¨ä¸åŒäººç¾¤ä¸­çš„å¹¿å‘Šåˆ†é…å­˜åœ¨æ­§è§† [[14](#bib.bib14)]ã€‚ä¸åœ¨çº¿å¹¿å‘Šç›¸å…³çš„ä¸€ä¸ªä¸»è¦ç¤¾ä¼šé—®é¢˜æ˜¯åœ¨å°±ä¸šå¸‚åœºä¸Šçš„ä½¿ç”¨ï¼Œå…¶ä¸­ä¸å…¬å¹³æ€§å¯èƒ½å¯¹å¹³ç­‰å’Œä¿æŠ¤å¼±åŠ¿ç¾¤ä½“é€ æˆä¸¥é‡æŸå®³ã€‚
- en: To mitigate the unfairness, PreferenceNet [[21](#bib.bib21)] integrated three
    definitions of fairness into the model, all of which map the allocations $g(b)$
    onto $\mathbb{R}$. In all these equations (Equation [28](#S6.E28 "In item 1 â€£
    6.4 Fairness & Fraud Prevention â€£ 6 Constraints and Concerns â€£ A Survey of Online
    Auction Mechanism Design Using Deep Learning Approaches"), Equation [29](#S6.E29
    "In item 2 â€£ 6.4 Fairness & Fraud Prevention â€£ 6 Constraints and Concerns â€£ A
    Survey of Online Auction Mechanism Design Using Deep Learning Approaches"), and
    Equation [30](#S6.E30 "In item 3 â€£ 6.4 Fairness & Fraud Prevention â€£ 6 Constraints
    and Concerns â€£ A Survey of Online Auction Mechanism Design Using Deep Learning
    Approaches")), $i$ refers to $i^{th}$ item while $j$ and $j^{\prime}$ refer to
    $j^{th}$ and $j^{\prime th}$ agents.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å‡è½»ä¸å…¬å¹³æ€§ï¼ŒPreferenceNet [[21](#bib.bib21)] å°†ä¸‰ç§å…¬å¹³æ€§å®šä¹‰é›†æˆåˆ°æ¨¡å‹ä¸­ï¼Œè¿™äº›å®šä¹‰å°†åˆ†é… $g(b)$ æ˜ å°„åˆ°
    $\mathbb{R}$ã€‚åœ¨æ‰€æœ‰è¿™äº›æ–¹ç¨‹ï¼ˆæ–¹ç¨‹ [28](#S6.E28 "åœ¨é¡¹ç›® 1 â€£ 6.4 å…¬å¹³æ€§ä¸æ¬ºè¯ˆé¢„é˜² â€£ 6 çº¦æŸä¸å…³æ³¨ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”")ã€æ–¹ç¨‹
    [29](#S6.E29 "åœ¨é¡¹ç›® 2 â€£ 6.4 å…¬å¹³æ€§ä¸æ¬ºè¯ˆé¢„é˜² â€£ 6 çº¦æŸä¸å…³æ³¨ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”") å’Œæ–¹ç¨‹ [30](#S6.E30
    "åœ¨é¡¹ç›® 3 â€£ 6.4 å…¬å¹³æ€§ä¸æ¬ºè¯ˆé¢„é˜² â€£ 6 çº¦æŸä¸å…³æ³¨ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”")ï¼‰ä¸­ï¼Œ$i$ æŒ‡ä»£ç¬¬ $i$ é¡¹ï¼Œè€Œ $j$
    å’Œ $j^{\prime}$ åˆ†åˆ«æŒ‡ä»£ç¬¬ $j$ ä¸ªå’Œç¬¬ $j^{\prime}$ ä¸ªä»£ç†ã€‚
- en: '1.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Total Variation Fairness (Equation [28](#S6.E28 "In item 1 â€£ 6.4 Fairness &
    Fraud Prevention â€£ 6 Constraints and Concerns â€£ A Survey of Online Auction Mechanism
    Design Using Deep Learning Approaches")): the distance between allocations cannot
    be larger than the discrepancies between these two users.'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ€»å˜å·®å…¬å¹³æ€§ï¼ˆæ–¹ç¨‹ [28](#S6.E28 "åœ¨é¡¹ç›® 1 â€£ 6.4 å…¬å¹³æ€§ä¸æ¬ºè¯ˆé¢„é˜² â€£ 6 çº¦æŸä¸å…³æ³¨ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”")ï¼‰ï¼šåˆ†é…ä¹‹é—´çš„è·ç¦»ä¸èƒ½å¤§äºè¿™ä¸¤ä¸ªç”¨æˆ·ä¹‹é—´çš„å·®å¼‚ã€‚
- en: '|  | $\sum_{i\in C_{k}}&#124;g(b)_{i,j}-g(b)_{i,j^{\prime}}&#124;\leq d^{k}(j,j^{\prime}),\forall
    k\in\{1,\dots,c\},\forall j,j^{\prime}\in M$ |  | (28) |'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\sum_{i\in C_{k}}&#124;g(b)_{i,j}-g(b)_{i,j^{\prime}}&#124;\leq d^{k}(j,j^{\prime}),\forall
    k\in\{1,\dots,c\},\forall j,j^{\prime}\in M$ |  | (28) |'
- en: '2.'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Entropy (Equation [29](#S6.E29 "In item 2 â€£ 6.4 Fairness & Fraud Prevention
    â€£ 6 Constraints and Concerns â€£ A Survey of Online Auction Mechanism Design Using
    Deep Learning Approaches")): the allocation for an agent tends to be more uniformly
    distributed.'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç†µï¼ˆæ–¹ç¨‹ [29](#S6.E29 "åœ¨é¡¹ç›® 2 â€£ 6.4 å…¬å¹³æ€§ä¸æ¬ºè¯ˆé¢„é˜² â€£ 6 çº¦æŸä¸å…³æ³¨ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”")ï¼‰ï¼šä¸€ä¸ªä»£ç†çš„åˆ†é…è¶‹å‘äºæ›´å‡åŒ€åˆ†å¸ƒã€‚
- en: '|  | $\max-\sum_{i=1}^{n}P(\frac{g(b)_{i.}}{\sum_{j}g(b)_{ij}})\log P(\frac{g(b)_{i.}}{\sum_{j}g(b)_{ij}})$
    |  | (29) |'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\max-\sum_{i=1}^{n}P(\frac{g(b)_{i.}}{\sum_{j}g(b)_{ij}})\log P(\frac{g(b)_{i.}}{\sum_{j}g(b)_{ij}})$
    |  | (29) |'
- en: '3.'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Quota (Equation [30](#S6.E30 "In item 3 â€£ 6.4 Fairness & Fraud Prevention â€£
    6 Constraints and Concerns â€£ A Survey of Online Auction Mechanism Design Using
    Deep Learning Approaches")): the smallest allocation to any agent should be greater
    than some threshold.'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é…é¢ï¼ˆæ–¹ç¨‹ [30](#S6.E30 "åœ¨é¡¹ç›® 3 â€£ 6.4 å…¬å¹³æ€§ä¸æ¬ºè¯ˆé¢„é˜² â€£ 6 çº¦æŸä¸å…³æ³¨ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”")ï¼‰ï¼šå¯¹ä»»ä½•ä»£ç†çš„æœ€å°åˆ†é…åº”å¤§äºæŸä¸ªé˜ˆå€¼ã€‚
- en: '|  | $\min_{j}(\frac{g(b)_{.j}}{\sum_{i}g(b)_{ij}})>t$ |  | (30) |'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\min_{j}(\frac{g(b)_{.j}}{\sum_{i}g(b)_{ij}})>t$ |  | (30) |'
- en: ProportionNet [[14](#bib.bib14)] also adopted the notion of total variation
    fairness, so that the allocations to similar users cannot differ by too much.
    It converted the Equation [28](#S6.E28 "In item 1 â€£ 6.4 Fairness & Fraud Prevention
    â€£ 6 Constraints and Concerns â€£ A Survey of Online Auction Mechanism Design Using
    Deep Learning Approaches") into an unfairness constraint (Equation [31](#S6.E31
    "In 6.4 Fairness & Fraud Prevention â€£ 6 Constraints and Concerns â€£ A Survey of
    Online Auction Mechanism Design Using Deep Learning Approaches")) that can be
    fed into the Augmented Lagrange Solver, which allows us to quantify the unfairness
    of the auction outcome for all users involved.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ProportionNet [[14](#bib.bib14)] ä¹Ÿé‡‡ç”¨äº†æ€»å˜å·®å…¬å¹³æ€§çš„æ¦‚å¿µï¼Œä»¥ç¡®ä¿å¯¹ç›¸ä¼¼ç”¨æˆ·çš„åˆ†é…å·®å¼‚ä¸ä¼šè¿‡å¤§ã€‚å®ƒå°†æ–¹ç¨‹ [28](#S6.E28
    "åœ¨é¡¹ç›® 1 â€£ 6.4 å…¬å¹³æ€§ä¸æ¬ºè¯ˆé¢„é˜² â€£ 6 çº¦æŸä¸å…³æ³¨ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”") è½¬åŒ–ä¸ºä¸€ä¸ªä¸å…¬å¹³æ€§çº¦æŸï¼ˆæ–¹ç¨‹ [31](#S6.E31
    "åœ¨ 6.4 å…¬å¹³æ€§ä¸æ¬ºè¯ˆé¢„é˜² â€£ 6 çº¦æŸä¸å…³æ³¨ â€£ åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„åœ¨çº¿æ‹å–æœºåˆ¶è®¾è®¡è°ƒç ”")ï¼‰ï¼Œå¯ä»¥è¾“å…¥åˆ°æ‰©å±•æ‹‰æ ¼æœ—æ—¥æ±‚è§£å™¨ä¸­ï¼Œä»è€Œä½¿æˆ‘ä»¬èƒ½å¤Ÿé‡åŒ–æ‰€æœ‰ç›¸å…³ç”¨æˆ·çš„æ‹å–ç»“æœä¸å…¬å¹³æ€§ã€‚
- en: '|  | $unf_{j}=\sum_{j^{\prime}\in M}\sum_{C_{k}\in C}\max(0,\sum_{i\in C_{k}}\max(0,z_{ij}-z_{ij^{\prime}}))-d^{k}(j,j^{\prime}))$
    |  | (31) |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '|  | $unf_{j}=\sum_{j^{\prime}\in M}\sum_{C_{k}\in C}\max(0,\sum_{i\in C_{k}}\max(0,z_{ij}-z_{ij^{\prime}}))-d^{k}(j,j^{\prime}))$
    |  | (31) |'
- en: 'While unfairness can be introduced by the biases in auction mechanisms, it
    can also be induced by shill bidding behaviors in auctions. Sellers can adopt
    a variety of shill bidding strategies to inflate the final selling price of an
    item. The common four shill bidding strategies have been identified [[22](#bib.bib22)]:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æ‹å–æœºåˆ¶ä¸­çš„åè§å¯èƒ½å¼•å…¥ä¸å…¬å¹³ï¼Œä½†æ‹å–ä¸­çš„è™šå‡ç«æ ‡è¡Œä¸ºä¹Ÿä¼šå¯¼è‡´ä¸å…¬å¹³ã€‚å–å®¶å¯ä»¥é‡‡ç”¨å„ç§è™šå‡ç«æ ‡ç­–ç•¥æ¥æŠ¬é«˜ç‰©å“çš„æœ€ç»ˆå”®ä»·ã€‚å·²ç»ç¡®å®šäº†å¸¸è§çš„å››ç§è™šå‡ç«æ ‡ç­–ç•¥[[22](#bib.bib22)]ï¼š
- en: '1.'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Evaluator: single bid engagement at an early time with a high amount.'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¯„ä¼°è€…ï¼šåœ¨æ—©æœŸæ—¶é—´ä»¥é«˜é¢å‡ºä»·è¿›è¡Œå•æ¬¡ç«æ ‡ã€‚
- en: '2.'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Sniping: single bid engagement in the last moment, not leaving opportunity
    for anybody else to outbid.'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å†²åˆºï¼šåœ¨æœ€åæ—¶åˆ»è¿›è¡Œå•æ¬¡ç«æ ‡ï¼Œä¸ç•™ä¸‹ä»»ä½•å…¶ä»–äººè¶…å‡ºå‡ºä»·çš„æœºä¼šã€‚
- en: '3.'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Unmasking: multiple bid engagement in a short span of time with a probability
    of intend to exposing the maximum bid or the highest bidders.'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ­ç¤ºï¼šåœ¨çŸ­æ—¶é—´å†…è¿›è¡Œå¤šæ¬¡ç«æ ‡ï¼Œæ„å›¾æš´éœ²æœ€å¤§å‡ºä»·æˆ–æœ€é«˜ç«æ ‡è€…çš„æ¦‚ç‡ã€‚
- en: '4.'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: 'Skeptic: multiple bid engagement with lowest possible bids each time.'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ€€ç–‘è€…ï¼šæ¯æ¬¡ä»¥æœ€ä½å¯èƒ½çš„å‡ºä»·è¿›è¡Œå¤šæ¬¡ç«æ ‡ã€‚
- en: 7 Conclusion
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 ç»“è®º
- en: In this article, we have gone through the rough evolving process of deep learning
    based online auction systems. Mechanisms designed using MLP infrastructure are
    usually built upon some theoretical results, and the MLP structure is used to
    represent the functions given in the theories. A more sophisticated structure
    came with the appearance of RegretNet, which parametrizes allocation rules and
    payment rules using separate networks. Many researchers have built extensions
    of RegretNet by integrating more constraints into the objective function or slightly
    adjusting the network structure but still keeping allocation and payment networks
    separate. The dynamic nature of online auction has encouraged researchers to adopt
    the deep reinforcement learning framework, which is more often a model-free approach
    that requires less assumptions on the data and is able to keep adapting itself
    as time progresses. As most traditional neural network has an implicit constraints
    on the positions of inputs, it integrates the ordering of auction participants
    into the model training, while in reality there is no inherent ordering among
    them. As a result, a deep learning based on DeepSet infrastructure has emerged,
    which can remove the effects of positions completely. We have also discussed the
    constraints and concerns faced by auction designers and we pointed out how researchers
    have attempted to address them.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å›é¡¾äº†åŸºäºæ·±åº¦å­¦ä¹ çš„åœ¨çº¿æ‹å–ç³»ç»Ÿçš„ç²—ç•¥æ¼”å˜è¿‡ç¨‹ã€‚ä½¿ç”¨MLPåŸºç¡€è®¾æ–½è®¾è®¡çš„æœºåˆ¶é€šå¸¸å»ºç«‹åœ¨ä¸€äº›ç†è®ºç»“æœä¹‹ä¸Šï¼ŒMLPç»“æ„ç”¨äºè¡¨ç¤ºç†è®ºä¸­ç»™å‡ºçš„å‡½æ•°ã€‚éšç€RegretNetçš„å‡ºç°ï¼Œå‡ºç°äº†æ›´å¤æ‚çš„ç»“æ„ï¼Œè¯¥ç»“æ„ä½¿ç”¨ç‹¬ç«‹çš„ç½‘ç»œå¯¹åˆ†é…è§„åˆ™å’Œæ”¯ä»˜è§„åˆ™è¿›è¡Œå‚æ•°åŒ–ã€‚è®¸å¤šç ”ç©¶äººå‘˜é€šè¿‡å°†æ›´å¤šçº¦æŸé›†æˆåˆ°ç›®æ ‡å‡½æ•°ä¸­æˆ–ç¨å¾®è°ƒæ•´ç½‘ç»œç»“æ„æ¥æ„å»ºRegretNetçš„æ‰©å±•ï¼Œä½†ä»ä¿æŒåˆ†é…å’Œæ”¯ä»˜ç½‘ç»œçš„åˆ†ç¦»ã€‚åœ¨çº¿æ‹å–çš„åŠ¨æ€ç‰¹æ€§ä¿ƒä½¿ç ”ç©¶äººå‘˜é‡‡ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œè¿™é€šå¸¸æ˜¯ä¸€ç§æ¨¡å‹æ— å…³çš„æ–¹æ³•ï¼Œè¦æ±‚å¯¹æ•°æ®çš„å‡è®¾è¾ƒå°‘ï¼Œå¹¶èƒ½å¤Ÿéšç€æ—¶é—´çš„æ¨ç§»ä¸æ–­é€‚åº”ã€‚ç”±äºå¤§å¤šæ•°ä¼ ç»Ÿç¥ç»ç½‘ç»œå¯¹è¾“å…¥çš„ä½ç½®æœ‰éšå«çº¦æŸï¼Œå®ƒå°†æ‹å–å‚ä¸è€…çš„æ’åºé›†æˆåˆ°æ¨¡å‹è®­ç»ƒä¸­ï¼Œè€Œå®é™…ä¸Šå®ƒä»¬ä¹‹é—´æ²¡æœ‰å›ºæœ‰çš„æ’åºã€‚å› æ­¤ï¼ŒåŸºäºDeepSetåŸºç¡€è®¾æ–½çš„æ·±åº¦å­¦ä¹ åº”è¿è€Œç”Ÿï¼Œè¿™å¯ä»¥å®Œå…¨æ¶ˆé™¤ä½ç½®çš„å½±å“ã€‚æˆ‘ä»¬è¿˜è®¨è®ºäº†æ‹å–è®¾è®¡å¸ˆé¢ä¸´çš„çº¦æŸå’Œé—®é¢˜ï¼Œå¹¶æŒ‡å‡ºäº†ç ”ç©¶äººå‘˜å¦‚ä½•å°è¯•è§£å†³è¿™äº›é—®é¢˜ã€‚
- en: Although researchers are progressing rapidly to the development of an online
    auction mechanism that can be reliable and profitable in the long term, there
    are still a lot of unresolved issues left for future researchers to investigate.
    As the size of users for online auction system is usually gigantic, the computational
    constraint and convergence problems for high-dimensional data are still non-negligible
    issues. Researchers are either mapping the data to lower dimension or reducing
    the action space by discretizing it, but it remains unclear how much information
    we are losing. In addition, most models assume the unit-demand and additive valuations,
    while this assumption might not be true in the real world. Last but not least,
    as most mechanism frameworks rely on the assumption that auction participants
    are independent from each other, their IC and IR constraints are also computed
    at individual levels. Therefore, their strategies might not be robust to the non-truthful
    behaviors conducted by participants in collusion.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ç ”ç©¶äººå‘˜åœ¨å¼€å‘ä¸€ç§åœ¨é•¿æœŸå†…å¯é ä¸”æœ‰åˆ©å¯å›¾çš„åœ¨çº¿æ‹å–æœºåˆ¶æ–¹é¢è¿›å±•è¿…é€Ÿï¼Œä½†ä»æœ‰è®¸å¤šæœªè§£å†³çš„é—®é¢˜ç•™å¾…æœªæ¥çš„ç ”ç©¶è€…è°ƒæŸ¥ã€‚ç”±äºåœ¨çº¿æ‹å–ç³»ç»Ÿçš„ç”¨æˆ·è§„æ¨¡é€šå¸¸éå¸¸åºå¤§ï¼Œé«˜ç»´æ•°æ®çš„è®¡ç®—çº¦æŸå’Œæ”¶æ•›é—®é¢˜ä»ç„¶æ˜¯ä¸å¯å¿½è§†çš„é—®é¢˜ã€‚ç ”ç©¶äººå‘˜è¦ä¹ˆå°†æ•°æ®æ˜ å°„åˆ°è¾ƒä½ç»´åº¦ï¼Œè¦ä¹ˆé€šè¿‡ç¦»æ•£åŒ–å‡å°‘åŠ¨ä½œç©ºé—´ï¼Œä½†æˆ‘ä»¬ç©¶ç«ŸæŸå¤±äº†å¤šå°‘ä¿¡æ¯ä»ä¸æ¸…æ¥šã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°æ¨¡å‹å‡è®¾å•ä½éœ€æ±‚å’ŒåŠ æ€§ä¼°å€¼ï¼Œè€Œè¿™ä¸€å‡è®¾åœ¨ç°å®ä¸–ç•Œä¸­å¯èƒ½å¹¶ä¸æˆç«‹ã€‚æœ€åä½†åŒæ ·é‡è¦çš„æ˜¯ï¼Œç”±äºå¤§å¤šæ•°æœºåˆ¶æ¡†æ¶ä¾èµ–äºæ‹å–å‚ä¸è€…å½¼æ­¤ç‹¬ç«‹çš„å‡è®¾ï¼Œå®ƒä»¬çš„ICå’ŒIRçº¦æŸä¹Ÿåœ¨ä¸ªä½“å±‚é¢è¿›è¡Œè®¡ç®—ã€‚å› æ­¤ï¼Œå®ƒä»¬çš„ç­–ç•¥å¯èƒ½å¯¹å‚ä¸è€…ä¹‹é—´çš„å‹¾ç»“è¡Œä¸ºä¸å¤Ÿç¨³å¥ã€‚
- en: References
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] Rajeev Agrawal. Sample mean based index policies by o(log n) regret for
    the multi-armed bandit problem. Advances in Applied Probability, 27(4):1054â€“1078,
    1995.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] æ‹‰å‰å¤«Â·é˜¿æ ¼æ‹‰ç“¦å°”ã€‚ã€ŠåŸºäºæ ·æœ¬å‡å€¼çš„å¤šè‡‚è€è™æœºé—®é¢˜çš„o(log n)é—æ†¾æŒ‡æ•°ç­–ç•¥ã€‹ã€‚åº”ç”¨æ¦‚ç‡å­¦è¿›å±•ï¼Œ27(4):1054â€“1078ï¼Œ1995å¹´ã€‚'
- en: '[2] P.Â Auer, N.Â Cesa-Bianchi, Y.Â Freund, and R.E. Schapire. Gambling in a rigged
    casino: The adversarial multi-armed bandit problem. In Proceedings of IEEE 36th
    Annual Foundations of Computer Science, pages 322â€“331, 1995.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] PÂ·å¥¥å°”ï¼ŒNÂ·åˆ‡è¨-æ¯”å®‰å¥‡ï¼ŒYÂ·å¼—ä¼¦å¾·ï¼Œå’ŒRÂ·EÂ·æ²™çš®é›·ã€‚ã€Šåœ¨ä¸€ä¸ªè¢«æ“æ§çš„èµŒåœºé‡ŒèµŒåšï¼šå¯¹æŠ—æ€§å¤šè‡‚è€è™æœºé—®é¢˜ã€‹ã€‚åœ¨IEEEç¬¬36å±Šå¹´åº¦è®¡ç®—æœºç§‘å­¦åŸºç¡€ä¼šè®®è®ºæ–‡é›†ä¸­ï¼Œ322â€“331é¡µï¼Œ1995å¹´ã€‚'
- en: '[3] Peter Auer, NicolÃ² Cesa-Bianchi, and Paul Fischer. Finite-time analysis
    of the multiarmed bandit problem. Machine Learning, 47(2â€“3):235â€“256, 2002.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] å½¼å¾—Â·å¥¥å°”ï¼Œå°¼ç§‘æ´›Â·åˆ‡è¨-æ¯”å®‰å¥‡ï¼Œå’Œä¿ç½—Â·è´¹èˆå°”ã€‚ã€Šå¤šè‡‚è€è™æœºé—®é¢˜çš„æœ‰é™æ—¶é—´åˆ†æã€‹ã€‚æœºå™¨å­¦ä¹ ï¼Œ47(2â€“3):235â€“256ï¼Œ2002å¹´ã€‚'
- en: '[4] Peter Auer, NicolÃ² Cesa-Bianchi, Yoav Freund, and RobertÂ E. Schapire. The
    nonstochastic multiarmed bandit problem. SIAM J. Comput., 32(1):48â€“77, January
    2003.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] å½¼å¾—Â·å¥¥å°”ï¼Œå°¼ç§‘æ´›Â·åˆ‡è¨-æ¯”å®‰å¥‡ï¼Œçº¦é˜¿å¤«Â·å¼—ä¼¦å¾·ï¼Œå’Œç½—ä¼¯ç‰¹Â·EÂ·æ²™çš®é›·ã€‚ã€Šééšæœºå¤šè‡‚è€è™æœºé—®é¢˜ã€‹ã€‚SIAMè®¡ç®—æ‚å¿—ï¼Œ32(1):48â€“77ï¼Œ2003å¹´1æœˆã€‚'
- en: '[5] LawrenceÂ M. Ausubel and Paul Milgrom. The Lovely but Lonely Vickrey Auction.
    In Combinatorial Auctions, chapterÂ 1, pages 17â€“40\. MIT Press, 2006.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] åŠ³ä¼¦æ–¯Â·MÂ·å¥¥è‹è´å°”å’Œä¿ç½—Â·ç±³å°”æ ¼ç½—å§†ã€‚ã€Šå¯çˆ±ä½†å­¤ç‹¬çš„ç»´å…‹é›·æ‹å–ã€‹ã€‚åœ¨ã€Šç»„åˆæ‹å–ã€‹ï¼Œç¬¬1ç« ï¼Œ17â€“40é¡µã€‚éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ï¼Œ2006å¹´ã€‚'
- en: '[6] Qingpeng Cai, Aris Filos-Ratsikas, Pingzhong Tang, and Yiwei Zhang. Reinforcement
    mechanism design for e-commerce, 2018.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] è”¡é’é¹ï¼Œé˜¿é‡Œæ–¯Â·è´¹æ´›æ–¯-æ‹‰è¥¿å¡æ–¯ï¼Œå”å¹³ä¸­ï¼Œå’Œå¼ è‰ºä¼Ÿã€‚ã€Šç”µå­å•†åŠ¡çš„å¼ºåŒ–æœºåˆ¶è®¾è®¡ã€‹ï¼Œ2018å¹´ã€‚'
- en: '[7] Djork-ArnÃ© Clevert, Thomas Unterthiner, and Sepp Hochreiter. Fast and accurate
    deep network learning by exponential linear units (elus), 2016.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] ä¹”å…‹-é˜¿å°”å†…Â·å…‹è±ç»´ç‰¹ï¼Œæ‰˜é©¬æ–¯Â·ä¹Œç‰¹ç‰¹çº³ï¼Œå’Œå¡æ™®Â·éœèµ«èµ–ç‰¹ã€‚ã€Šé€šè¿‡æŒ‡æ•°çº¿æ€§å•å…ƒï¼ˆelusï¼‰è¿›è¡Œå¿«é€Ÿå‡†ç¡®çš„æ·±åº¦ç½‘ç»œå­¦ä¹ ã€‹ï¼Œ2016å¹´ã€‚'
- en: '[8] Hennie Daniels and Marina Velikova. Monotone and partially monotone neural
    networks. IEEE Transactions on Neural Networks, 21(6):906â€“917, 2010.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] äº¨å°¼Â·ä¸¹å°¼å°”æ–¯å’Œç›ä¸½å¨œÂ·ç»´åˆ©ç§‘å¨ƒã€‚ã€Šå•è°ƒå’Œéƒ¨åˆ†å•è°ƒç¥ç»ç½‘ç»œã€‹ã€‚IEEEç¥ç»ç½‘ç»œå­¦æŠ¥ï¼Œ21(6):906â€“917ï¼Œ2010å¹´ã€‚'
- en: '[9] Paul DÃ¼tting, Zhe Feng, Harikrishna Narasimhan, DavidÂ C. Parkes, and SaiÂ Srivatsa
    Ravindranath. Optimal auctions through deep learning, 2020.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] ä¿ç½—Â·æœå»·ï¼Œå†¯å“²ï¼Œå“ˆé‡Œå…‹é‡Œå¸Œçº³Â·çº³æ‹‰è¥¿æ›¼ï¼Œå¤§å«Â·CÂ·å¸•å…‹æ–¯ï¼Œå’Œèµ›Â·æ–¯é‡Œç“¦è¨Â·æ‹‰æ–‡å¾·æ‹‰çº³æ–¯ã€‚ã€Šé€šè¿‡æ·±åº¦å­¦ä¹ å®ç°æœ€ä¼˜æ‹å–ã€‹ï¼Œ2020å¹´ã€‚'
- en: '[10] Zhe Feng, Harikrishna Narasimhan, and DavidÂ C. Parkes. Deep learning for
    revenue-optimal auctions with budgets. In Proceedings of the 17th International
    Conference on Autonomous Agents and MultiAgent Systems, AAMAS â€™18, page 354â€“362,
    Richland, SC, 2018\. International Foundation for Autonomous Agents and Multiagent
    Systems.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] å†¯å“²ï¼Œå“ˆé‡Œå…‹é‡Œå¸Œçº³Â·çº³æ‹‰è¥¿æ›¼ï¼Œå’Œå¤§å«Â·CÂ·å¸•å…‹æ–¯ã€‚ã€Šç”¨äºé¢„ç®—çš„æ”¶ç›Šæœ€ä¼˜æ‹å–çš„æ·±åº¦å­¦ä¹ ã€‹ã€‚åœ¨ç¬¬17å±Šå›½é™…è‡ªä¸»ä»£ç†å’Œå¤šä»£ç†ç³»ç»Ÿä¼šè®®è®ºæ–‡é›†ä¸­ï¼ŒAAMAS
    â€™18ï¼Œç¬¬354â€“362é¡µï¼Œå—å¡ç½—æ¥çº³å·é‡Œå£«æ»¡ï¼Œ2018å¹´ã€‚å›½é™…è‡ªä¸»ä»£ç†å’Œå¤šä»£ç†ç³»ç»ŸåŸºé‡‘ä¼šã€‚'
- en: '[11] Noah Golowich, Harikrishna Narasimhan, and DavidÂ C. Parkes. Deep learning
    for multi-facility location mechanism design. In Proceedings of the Twenty-Seventh
    International Joint Conference on Artificial Intelligence, IJCAI-18, pages 261â€“267.
    International Joint Conferences on Artificial Intelligence Organization, 7 2018.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Noah Golowich, Harikrishna Narasimhan å’Œ David C. Parkes. å¤šè®¾æ–½ä½ç½®æœºåˆ¶è®¾è®¡çš„æ·±åº¦å­¦ä¹ ã€‚å‘è¡¨äºç¬¬äºŒåä¸ƒå±Šå›½é™…äººå·¥æ™ºèƒ½è”åˆä¼šè®®è®ºæ–‡é›†ï¼ŒIJCAI-18ï¼Œé¡µé¢261â€“267ã€‚å›½é™…äººå·¥æ™ºèƒ½è”åˆä¼šè®®ç»„ç»‡ï¼Œ2018å¹´7æœˆã€‚'
- en: '[12] Aditya Grover, Eric Wang, Aaron Zweig, and Stefano Ermon. Stochastic optimization
    of sorting networks via continuous relaxations, 2019.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Aditya Grover, Eric Wang, Aaron Zweig å’Œ Stefano Ermon. é€šè¿‡è¿ç»­æ¾å¼›çš„æ’åºç½‘ç»œçš„éšæœºä¼˜åŒ–ï¼Œ2019å¹´ã€‚'
- en: '[13] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into
    rectifiers: Surpassing human-level performance on imagenet classification. In
    2015 IEEE International Conference on Computer Vision (ICCV), pages 1026â€“1034,
    2015.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Kaiming He, Xiangyu Zhang, Shaoqing Ren å’Œ Jian Sun. æ·±å…¥ç ”ç©¶æ•´æµå™¨ï¼šåœ¨Imagenetåˆ†ç±»ä¸Šè¶…è¶Šäººç±»æ°´å¹³çš„è¡¨ç°ã€‚å‘è¡¨äº2015å¹´IEEEå›½é™…è®¡ç®—æœºè§†è§‰ä¼šè®®ï¼ˆICCVï¼‰ï¼Œé¡µé¢1026â€“1034ï¼Œ2015å¹´ã€‚'
- en: '[14] Kevin Kuo, Anthony Ostuni, Elizabeth Horishny, MichaelÂ J. Curry, Samuel
    Dooley, Ping yeh Chiang, Tom Goldstein, and JohnÂ P. Dickerson. Proportionnet:
    Balancing fairness and revenue for auction design with deep learning, 2020.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Kevin Kuo, Anthony Ostuni, Elizabeth Horishny, Michael J. Curry, Samuel
    Dooley, Ping Yeh Chiang, Tom Goldstein å’Œ John P. Dickerson. Proportionnet: åœ¨æ‹å–è®¾è®¡ä¸­å¹³è¡¡å…¬å¹³æ€§å’Œæ”¶ç›Šï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ ï¼Œ2020å¹´ã€‚'
- en: '[15] TimothyÂ P. Lillicrap, JonathanÂ J. Hunt, Alexander Pritzel, Nicolas Heess,
    Tom Erez, Yuval Tassa, David Silver, and Daan Wierstra. Continuous control with
    deep reinforcement learning, 2019.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Timothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Heess,
    Tom Erez, Yuval Tassa, David Silver å’Œ Daan Wierstra. æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„è¿ç»­æ§åˆ¶ï¼Œ2019å¹´ã€‚'
- en: '[16] Xiangyu Liu, Chuan Yu, Zhilin Zhang, Zhenzhe Zheng, YuÂ Rong, Hongtao Lv,
    DaÂ Huo, Yiqing Wang, Dagui Chen, Jian Xu, Fan Wu, Guihai Chen, and Xiaoqiang Zhu.
    Neural auction: End-to-end learning of auction mechanisms for e-commerce advertising,
    2021.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Xiangyu Liu, Chuan Yu, Zhilin Zhang, Zhenzhe Zheng, Yu Rong, Hongtao Lv,
    Da Huo, Yiqing Wang, Dagui Chen, Jian Xu, Fan Wu, Guihai Chen å’Œ Xiaoqiang Zhu.
    ç¥ç»æ‹å–ï¼šç”µå­å•†åŠ¡å¹¿å‘Šçš„ç«¯åˆ°ç«¯æ‹å–æœºåˆ¶å­¦ä¹ ï¼Œ2021å¹´ã€‚'
- en: '[17] NguyenÂ Cong Luong, Zehui Xiong, Ping Wang, and Dusit Niyato. Optimal auction
    for edge computing resource management in mobile blockchain networks: A deep learning
    approach, 2017.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Nguyen Cong Luong, Zehui Xiong, Ping Wang å’Œ Dusit Niyato. é’ˆå¯¹ç§»åŠ¨åŒºå—é“¾ç½‘ç»œä¸­çš„è¾¹ç¼˜è®¡ç®—èµ„æºç®¡ç†çš„æœ€ä¼˜æ‹å–ï¼šä¸€ç§æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œ2017å¹´ã€‚'
- en: '[18] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, AndreiÂ A. Rusu, Joel
    Veness, MarcÂ G. Bellemare, Alex Graves, Martin Riedmiller, AndreasÂ K. Fidjeland,
    Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou,
    Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and Demis Hassabis. Human-level
    control through deep reinforcement learning. Nature, 518(7540):529â€“533, February
    2015.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel
    Veness, Marc G. Bellemare, Alex Graves, Martin Riedmiller, Andreas K. Fidjeland,
    Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou,
    Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg å’Œ Demis Hassabis. é€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ å®ç°äººç±»æ°´å¹³çš„æ§åˆ¶ã€‚è‡ªç„¶ï¼Œ518(7540):529â€“533ï¼Œ2015å¹´2æœˆã€‚'
- en: '[19] H.Â Moulin. On strategy-proofness and single peakedness. Public Choice,
    35(4):437â€“455, 1980.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] H. Moulin. å…³äºç­–ç•¥æ— å…³æ€§å’Œå•å³°æ€§çš„ç ”ç©¶ã€‚å…¬å…±é€‰æ‹©ï¼Œ35(4):437â€“455ï¼Œ1980å¹´ã€‚'
- en: '[20] RogerÂ B. Myerson. Optimal auction design. Mathematics of Operations Research,
    6(1):58â€“73, 1981.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Roger B. Myerson. æœ€ä¼˜æ‹å–è®¾è®¡ã€‚è¿ç­¹å­¦æ•°å­¦ï¼Œ6(1):58â€“73ï¼Œ1981å¹´ã€‚'
- en: '[21] Neehar Peri, MichaelÂ J. Curry, Samuel Dooley, and JohnÂ P. Dickerson. Preferencenet:
    Encoding human preferences in auction design with deep learning, 2021.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Neehar Peri, Michael J. Curry, Samuel Dooley å’Œ John P. Dickerson. Preferencenet:
    ç”¨æ·±åº¦å­¦ä¹ åœ¨æ‹å–è®¾è®¡ä¸­ç¼–ç äººç±»åå¥½ï¼Œ2021å¹´ã€‚'
- en: '[22] SaurabhÂ R. Sangwan and Anshika Arora. Supervised machine learning based
    buyerâ€™s bidding behaviour detection in online auction. Social Science Research
    Network, 2019.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Saurabh R. Sangwan å’Œ Anshika Arora. åŸºäºç›‘ç£å­¦ä¹ çš„ä¹°å®¶ç«æ ‡è¡Œä¸ºæ£€æµ‹åœ¨çº¿æ‹å–ã€‚ç¤¾ä¼šç§‘å­¦ç ”ç©¶ç½‘ç»œï¼Œ2019å¹´ã€‚'
- en: '[23] Weiran Shen, Binghui Peng, Hanpeng Liu, Michael Zhang, Ruohan Qian, Yan
    Hong, Zhi Guo, Zongyao Ding, Pengjun Lu, and Pingzhong Tang. Reinforcement mechanism
    design, with applications to dynamic pricing in sponsored search auctions, 2017.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Weiran Shen, Binghui Peng, Hanpeng Liu, Michael Zhang, Ruohan Qian, Yan
    Hong, Zhi Guo, Zongyao Ding, Pengjun Lu å’Œ Pingzhong Tang. å¼ºåŒ–æœºåˆ¶è®¾è®¡åŠå…¶åœ¨èµåŠ©æœç´¢æ‹å–ä¸­çš„åŠ¨æ€å®šä»·åº”ç”¨ï¼Œ2017å¹´ã€‚'
- en: '[24] Weiran Shen, Pingzhong Tang, and Song Zuo. Automated mechanism design
    via neural networks, 2021.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Weiran Shen, Pingzhong Tang å’Œ Song Zuo. é€šè¿‡ç¥ç»ç½‘ç»œå®ç°è‡ªåŠ¨åŒ–æœºåˆ¶è®¾è®¡ï¼Œ2021å¹´ã€‚'
- en: '[25] MyungJae Shin, Joongheon Kim, and Marco Levorato. Auction-based charging
    scheduling with deep learning framework for multi-drone networks. IEEE Transactions
    on Vehicular Technology, 68(5):4235â€“4248, 2019.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] MyungJae Shin, Joongheon Kim, å’Œ Marco Levorato. åŸºäºæ‹å–çš„å……ç”µè°ƒåº¦ä¸æ·±åº¦å­¦ä¹ æ¡†æ¶ç”¨äºå¤šæ— äººæœºç½‘ç»œã€‚IEEE
    è½¦è¾†æŠ€æœ¯å­¦æŠ¥, 68(5):4235â€“4248, 2019ã€‚'
- en: '[26] David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra,
    and Martin Riedmiller. Deterministic policy gradient algorithms. In Proceedings
    of the 31st International Conference on International Conference on Machine Learning
    - Volume 32, ICMLâ€™14, page Iâ€“387â€“Iâ€“395\. JMLR.org, 2014.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra,
    å’Œ Martin Riedmiller. ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ç®—æ³•ã€‚è§äºç¬¬31å±Šå›½é™…æœºå™¨å­¦ä¹ å¤§ä¼šè®ºæ–‡é›† - ç¬¬32å·ï¼ŒICMLâ€™14ï¼Œç¬¬Iâ€“387â€“Iâ€“395é¡µã€‚JMLR.org,
    2014ã€‚'
- en: '[27] Pingzhong Tang. Reinforcement mechanism design. In Proceedings of the
    Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17,
    pages 5146â€“5150, 2017.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Pingzhong Tang. å¼ºåŒ–æœºåˆ¶è®¾è®¡ã€‚è§äºç¬¬26å±Šå›½é™…äººå·¥æ™ºèƒ½è”åˆä¼šè®®è®ºæ–‡é›†ï¼ŒIJCAI-17ï¼Œç¬¬5146â€“5150é¡µï¼Œ2017å¹´ã€‚'
- en: '[28] Rakesh Vohra. Mechanism design. a linear programming approach. Mechanism
    Design: A Linear Programming Approach, 01 2010.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Rakesh Vohra. æœºåˆ¶è®¾è®¡ï¼šçº¿æ€§è§„åˆ’æ–¹æ³•ã€‚ã€Šæœºåˆ¶è®¾è®¡ï¼šçº¿æ€§è§„åˆ’æ–¹æ³•ã€‹ï¼Œ2010å¹´1æœˆã€‚'
- en: '[29] Christopher John CornishÂ Hellaby Watkins. Learning from Delayed Rewards.
    PhD thesis, Kingâ€™s College, Cambridge, UK, May 1989.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Christopher John Cornish Hellaby Watkins. ä»å»¶è¿Ÿå¥–åŠ±ä¸­å­¦ä¹ ã€‚åšå£«è®ºæ–‡ï¼Œå‰‘æ¡¥å¤§å­¦å›½ç‹å­¦é™¢ï¼Œè‹±å›½ï¼Œ1989å¹´5æœˆã€‚'
- en: '[30] Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, BarnabÃ¡s PÃ³czos, Ruslan
    Salakhutdinov, and AlexanderÂ J. Smola. Deep sets. CoRR, abs/1703.06114, 2017.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, BarnabÃ¡s PÃ³czos, Ruslan
    Salakhutdinov, å’Œ Alexander J. Smola. æ·±åº¦é›†åˆã€‚CoRR, abs/1703.06114, 2017ã€‚'
- en: '[31] Zhilin Zhang, Xiangyu Liu, Zhenzhe Zheng, Chenrui Zhang, Miao Xu, Junwei
    Pan, Chuan Yu, Fan Wu, Jian Xu, and Kun Gai. Optimizing multiple performance metrics
    with deep gsp auctions for e-commerce advertising, 2021.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Zhilin Zhang, Xiangyu Liu, Zhenzhe Zheng, Chenrui Zhang, Miao Xu, Junwei
    Pan, Chuan Yu, Fan Wu, Jian Xu, å’Œ Kun Gai. ä½¿ç”¨æ·±åº¦ GSP æ‹å–ä¼˜åŒ–å¤šç§æ€§èƒ½æŒ‡æ ‡ç”¨äºç”µå­å•†åŠ¡å¹¿å‘Š, 2021ã€‚'
- en: '[32] Guorui Zhou, Chengru Song, Xiaoqiang Zhu, Ying Fan, Han Zhu, Xiao Ma,
    Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. Deep interest network for click-through
    rate prediction, 2018.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Guorui Zhou, Chengru Song, Xiaoqiang Zhu, Ying Fan, Han Zhu, Xiao Ma,
    Yanghui Yan, Junqi Jin, Han Li, å’Œ Kun Gai. ç‚¹å‡»ç‡é¢„æµ‹çš„æ·±åº¦å…´è¶£ç½‘ç»œ, 2018ã€‚'
