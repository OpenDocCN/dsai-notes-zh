- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 19:39:57'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:39:57
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2305.05959] Survey of Code Search Based on Deep Learning'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2305.05959] 基于深度学习的代码搜索调研'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2305.05959](https://ar5iv.labs.arxiv.org/html/2305.05959)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2305.05959](https://ar5iv.labs.arxiv.org/html/2305.05959)
- en: Survey of Code Search Based on Deep Learning
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于深度学习的代码搜索调研
- en: Yutao Xie Peking University & International Digital Economy AcademyNo. 5 Shihua
    RoadFutian DistrictShenzhenChina518017 [yutaoxie@idea.edu.cn](mailto:yutaoxie@idea.edu.cn)
    ,  Jiayi Lin International Digital Economy AcademyNo. 5 Shihua RoadFutian DistrictShenzhenChina518017
    [jiayilin1024@gmail.com](mailto:jiayilin1024@gmail.com) ,  Hande Dong International
    Digital Economy AcademyNo. 5 Shihua RoadFutian DistrictShenzhenChina518017 [donghd66@gmail.com](mailto:donghd66@gmail.com)
    ,  Lei Zhang International Digital Economy AcademyNo. 5 Shihua RoadFutian DistrictShenzhenChina518017
    [leizhang@idea.edu.cn](mailto:leizhang@idea.edu.cn)  and  Zhonghai Wu Key Lab
    of High Confidence Software Technologies (MOE), Peking UniversityNo. 5 Yiheyuan
    RoadHaidian DistrictBeijingChina100871 [wuzh@pku.edu.cn](mailto:wuzh@pku.edu.cn)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 谢宇涛，北京大学与国际数字经济学院，深圳市福田区石化路5号，中国518017 [yutaoxie@idea.edu.cn](mailto:yutaoxie@idea.edu.cn)，林佳怡，国际数字经济学院，深圳市福田区石化路5号，中国518017
    [jiayilin1024@gmail.com](mailto:jiayilin1024@gmail.com)，董汉德，国际数字经济学院，深圳市福田区石化路5号，中国518017
    [donghd66@gmail.com](mailto:donghd66@gmail.com)，张磊，国际数字经济学院，深圳市福田区石化路5号，中国518017
    [leizhang@idea.edu.cn](mailto:leizhang@idea.edu.cn) 以及 吴忠海，北京大学高信任软件技术重点实验室（MOE），北京市海淀区颐和园路5号，中国100871
    [wuzh@pku.edu.cn](mailto:wuzh@pku.edu.cn)
- en: Abstract.
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: 'Code writing is repetitive and predictable, inspiring us to develop various
    code intelligence techniques. This survey focuses on code search, that is, to
    retrieve code that matches a given natural language query by effectively capturing
    the semantic similarity between the query and code. Deep learning, being able
    to extract complex semantics information, has achieved great success in this field.
    Recently, various deep learning methods, such as graph neural networks and pretraining
    models, have been applied to code search with significant progress. Deep learning
    is now the leading paradigm for code search. In this survey, we provide a comprehensive
    overview of deep learning-based code search. We review the existing deep learning-based
    code search framework which maps query/code to vectors and measures their similarity.
    Furthermore, we propose a new taxonomy to illustrate the state-of-the-art deep
    learning-based code search in a three-steps process: query semantics modeling,
    code semantics modeling, and matching modeling which involves the deep learning
    model training. Finally, we suggest potential avenues for future research in this
    promising field.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 代码编写具有重复性和可预测性，这激励我们开发各种代码智能技术。本调研专注于代码搜索，即通过有效捕捉查询与代码之间的语义相似性，检索匹配给定自然语言查询的代码。深度学习能够提取复杂的语义信息，并在这一领域取得了巨大的成功。近年来，各种深度学习方法，如图神经网络和预训练模型，已应用于代码搜索，并取得了显著进展。深度学习现在是代码搜索的主流范式。在本调研中，我们提供了基于深度学习的代码搜索的全面概述。我们回顾了现有的基于深度学习的代码搜索框架，该框架将查询/代码映射为向量并衡量其相似性。此外，我们提出了一种新的分类法，以三步骤过程说明最先进的基于深度学习的代码搜索：查询语义建模、代码语义建模和匹配建模，其中涉及深度学习模型训练。最后，我们建议了在这一有前景的领域的未来研究潜在方向。
- en: 'code search, code understanding, natural language processing, deep learning,
    pre-training^†^†journal: JACM^†^†ccs: General and reference Surveys and overviews^†^†ccs:
    Software and its engineering^†^†ccs: Software and its engineering Software notations
    and tools^†^†ccs: Software and its engineering Software creation and management^†^†copyright:
    acmlicensed^†^†journal: TOSEM^†^†journalyear: 2023^†^†journalvolume: 1^†^†journalnumber:
    1^†^†article: 1^†^†publicationmonth: 1^†^†price: 15.00^†^†doi: 10.1145/3628161'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '代码搜索, 代码理解, 自然语言处理, 深度学习, 预训练^†^†期刊: JACM^†^†ccs: 一般与参考 调研与概述^†^†ccs: 软件及其工程^†^†ccs:
    软件及其工程 软件标注与工具^†^†ccs: 软件及其工程 软件创建与管理^†^†版权: acmlicensed^†^†期刊: TOSEM^†^†期刊年份:
    2023^†^†期刊卷号: 1^†^†期刊期号: 1^†^†文章: 1^†^†出版月份: 1^†^†价格: 15.00^†^†doi: 10.1145/3628161'
- en: 1\. Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 介绍
- en: Programming is the process of using a programming language to write code that
    performs a specific function. Despite being a creative endeavor, programming also
    exhibits repetitive and predictable attributes (Hindle et al., [2016](#bib.bib31)),
    with many codes already implemented to some extent. By analyzing historical codes,
    it is possible to anticipate the content of the code to be written. Building on
    this insight, code intelligence techniques such as code search, code completion,
    and code generation can be employed to enhance the productivity of software developers.
    In recent years, the application of deep learning in the field of code intelligence
    has led to remarkable achievements (Wang et al., [2022d](#bib.bib85), [2021a](#bib.bib89);
    Chen et al., [2021](#bib.bib11); Li et al., [2022c](#bib.bib48); Zhu et al., [2022](#bib.bib103);
    Guo et al., [2022](#bib.bib25)), thanks to its powerful representation capability
    and capacity to uncover hidden patterns. At present, a number of code intelligence
    tools leveraging deep learning, including Copilot and ChatGPT, have been developed
    and commercialized. These advanced tools enable software developers to write efficient
    and accurate code with greater ease and speed.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 编程是使用编程语言编写执行特定功能的代码的过程。尽管编程是一项创造性工作，但它也展现出重复和可预测的特性（Hindle等，[2016](#bib.bib31)），许多代码已在某种程度上实现。通过分析历史代码，可以预测即将编写的代码内容。基于这一洞察，可以采用代码智能技术，如代码搜索、代码补全和代码生成，以提高软件开发人员的生产力。近年来，深度学习在代码智能领域的应用取得了显著成果（Wang等，[2022d](#bib.bib85)，[2021a](#bib.bib89)；Chen等，[2021](#bib.bib11)；Li等，[2022c](#bib.bib48)；Zhu等，[2022](#bib.bib103)；Guo等，[2022](#bib.bib25)），这得益于其强大的表征能力和揭示隐藏模式的能力。目前，已开发并商业化了许多利用深度学习的代码智能工具，包括Copilot和ChatGPT。这些先进工具使得软件开发人员能够更加轻松和迅速地编写高效且准确的代码。
- en: This survey focuses on the nl-to-code search task. Code search is one of the
    three main software engineering tasks that has remained active over the years
    (Watson et al., [2022](#bib.bib90)). While code-to-code search falls within the
    research domain of code search, its role bears a closer affinity to code clone
    detection, thus rendering it outside the scope of this survey. The goal of nl-to-code
    search (henceforth referred to as code search) is to retrieve code fragments that
    match developers’ natural language queries from a large code corpus (Stolee et al.,
    [2014](#bib.bib75)). Software development is a creative work that requires software
    developers to write code that meets product requirements. During software development,
    developers often use search engines to search for code-related information (Shuai
    et al., [2020](#bib.bib72)), such as reusable code snippets, API understanding,
    and examples of specific functionality. They seek high-quality open source code
    for reference or reuse, which enhances the productivity of development (Gharehyazie
    et al., [2017](#bib.bib19)). Developers typically use general search engines such
    as Google, Bing, and Baidu to search for target codes. However, these general
    search engines usually search in the full database and are not specifically designed
    for code-related information. Consequently, they are inefficient on the code search
    task and the search results are not satisfactory.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查专注于nl-to-code搜索任务。代码搜索是三大主要软件工程任务之一，多年来一直保持活跃（Watson等，[2022](#bib.bib90)）。虽然code-to-code搜索属于代码搜索的研究领域，但它与代码克隆检测的关系更为密切，因此不在本调查范围之内。nl-to-code搜索（以下简称代码搜索）的目标是从大型代码库中检索与开发者自然语言查询匹配的代码片段（Stolee等，[2014](#bib.bib75)）。软件开发是一项创造性工作，需要软件开发人员编写符合产品要求的代码。在软件开发过程中，开发者经常使用搜索引擎查找与代码相关的信息（Shuai等，[2020](#bib.bib72)），例如可重用的代码片段、API理解和特定功能的示例。他们寻求高质量的开源代码以供参考或重用，这提升了开发效率（Gharehyazie等，[2017](#bib.bib19)）。开发者通常使用Google、Bing和百度等通用搜索引擎来搜索目标代码。然而，这些通用搜索引擎通常在整个数据库中进行搜索，并未专门针对代码相关信息进行设计。因此，它们在代码搜索任务中效率较低，搜索结果也不尽如人意。
- en: 'The transformative impact of deep learning on code search. Early code search
    engines primarily utilized Information Retrieval (IR) technology. They treated
    source code as text, and searched for the target code by matching keywords in
    query and code (Chatterjee et al., [2009](#bib.bib10); McMillan et al., [2011](#bib.bib59);
    Hill et al., [2014](#bib.bib30); Nie et al., [2016](#bib.bib61)). These methods
    mainly rely on the textual similarity between code and query. However, this approach
    has drawbacks since programming languages and natural languages differ greatly
    from each other, making it difficult for IR-based methods to comprehend the semantics.
    Fortunately, deep learning boasts an exceptional capability for extracting high-level
    semantic representations. As a result, compared to conventional IR-based approaches,
    code search has been improved significantly since deep learning incorporation
    (Gu et al., [2018](#bib.bib24)). Deep learning has received great attention in
    recent years in code search research. Code search is one of the first software
    engineering tasks to use deep learning techniques (Watson et al., [2022](#bib.bib90)).
    Hence, this paper primarily investigates code search methods based on deep learning.
    We provide a taxonomy which groups the current series of work into three categories:
    various techniques are employed to enhance the semantics of the query text for
    a more precise search intent (Sirres et al., [2018](#bib.bib73); Rahman and Roy,
    [2018](#bib.bib67); Rahman et al., [2019](#bib.bib68); Rahman, [2019](#bib.bib66);
    Zhang et al., [2018](#bib.bib100); Liu et al., [2019a](#bib.bib52); Cao et al.,
    [2021](#bib.bib8); Huang et al., [2019](#bib.bib35); Wu and Yang, [2019](#bib.bib91);
    Wang et al., [2022b](#bib.bib83); Eberhart and McMillan, [2022](#bib.bib17); Sivaraman
    et al., [2019](#bib.bib74)); sequence and graph-based deep learning technologies
    are introduced to model code representation and enhance code comprehension (Cambronero
    et al., [2019](#bib.bib7); Feng et al., [2020](#bib.bib18); Ling et al., [2020](#bib.bib49);
    Huang et al., [2021](#bib.bib34); Lachaux et al., [2021](#bib.bib42); Du et al.,
    [2021](#bib.bib16); Salza et al., [2023](#bib.bib70); Wang et al., [2022a](#bib.bib84);
    Chai et al., [2022](#bib.bib9); Li et al., [2022a](#bib.bib45), [b](#bib.bib46),
    [d](#bib.bib44); Guo et al., [2021](#bib.bib26); Gu et al., [2021a](#bib.bib21);
    Xu et al., [2021](#bib.bib92); Wang et al., [2021b](#bib.bib87), [2022c](#bib.bib88);
    Niu et al., [2022](#bib.bib62); Guo et al., [2022](#bib.bib25); Gu et al., [2018](#bib.bib24);
    Sachdev et al., [2018](#bib.bib69); Wan et al., [2019](#bib.bib79); Zeng et al.,
    [2023](#bib.bib99); Ling et al., [2021](#bib.bib50); Sun et al., [2022a](#bib.bib76);
    Liu et al., [2023](#bib.bib53); Yao et al., [2019](#bib.bib95); Haldar et al.,
    [2020](#bib.bib27); Wang et al., [2020](#bib.bib86); Zhao and Sun, [2020](#bib.bib102);
    Ye et al., [2020](#bib.bib97); Gu et al., [2021b](#bib.bib22); Cheng and Kuang,
    [2022](#bib.bib13); Arakelyan et al., [2022](#bib.bib3); Cai et al., [2023](#bib.bib6);
    Han et al., [2022](#bib.bib28); Ma et al., [2023](#bib.bib57)); more efficient
    training techniques are introduced or proposed, making the training of large models
    a great success (Feng et al., [2020](#bib.bib18); Guo et al., [2021](#bib.bib26);
    Wang et al., [2021b](#bib.bib87); Guo et al., [2022](#bib.bib25); Wang et al.,
    [2022c](#bib.bib88); Niu et al., [2022](#bib.bib62); Lachaux et al., [2021](#bib.bib42);
    Li et al., [2022b](#bib.bib46); Huang et al., [2021](#bib.bib34); Gu et al., [2018](#bib.bib24);
    Wan et al., [2019](#bib.bib79); Zeng et al., [2023](#bib.bib99); Ling et al.,
    [2021](#bib.bib50); Sun et al., [2022a](#bib.bib76); Xu et al., [2021](#bib.bib92);
    Ling et al., [2020](#bib.bib49); Liu et al., [2023](#bib.bib53); Li et al., [2022a](#bib.bib45),
    [d](#bib.bib44); Chen and Zhou, [2018](#bib.bib12); Chai et al., [2022](#bib.bib9);
    Wang et al., [2022a](#bib.bib84); Han et al., [2022](#bib.bib28); Yao et al.,
    [2019](#bib.bib95); Haldar et al., [2020](#bib.bib27); Wang et al., [2020](#bib.bib86);
    Zhao and Sun, [2020](#bib.bib102); Ye et al., [2020](#bib.bib97); Gu et al., [2021b](#bib.bib22);
    Bui et al., [2021](#bib.bib5); Cheng and Kuang, [2022](#bib.bib13); Arakelyan
    et al., [2022](#bib.bib3); Park et al., [2023](#bib.bib64); Cai et al., [2023](#bib.bib6);
    Ma et al., [2023](#bib.bib57); Hu et al., [2023](#bib.bib32)).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习对代码搜索的变革性影响。早期的代码搜索引擎主要利用信息检索（IR）技术。它们将源代码视为文本，通过匹配查询和代码中的关键词来搜索目标代码（Chatterjee
    et al., [2009](#bib.bib10); McMillan et al., [2011](#bib.bib59); Hill et al.,
    [2014](#bib.bib30); Nie et al., [2016](#bib.bib61)）。这些方法主要依赖于代码和查询之间的文本相似性。然而，由于编程语言与自然语言有很大差异，这种方法的缺陷在于IR方法难以理解语义。幸运的是，深度学习具有提取高级语义表示的卓越能力。因此，与传统的IR方法相比，深度学习的引入显著提高了代码搜索的效果（Gu
    et al., [2018](#bib.bib24)）。近年来，深度学习在代码搜索研究中受到了极大的关注。代码搜索是第一个应用深度学习技术的软件工程任务之一（Watson
    et al., [2022](#bib.bib90)）。因此，本文主要研究基于深度学习的代码搜索方法。我们提供了一个分类法，将当前的一系列工作分为三类：各种技术被应用于增强查询文本的语义，以实现更精确的搜索意图（Sirres
    et al., [2018](#bib.bib73); Rahman and Roy, [2018](#bib.bib67); Rahman et al.,
    [2019](#bib.bib68); Rahman, [2019](#bib.bib66); Zhang et al., [2018](#bib.bib100);
    Liu et al., [2019a](#bib.bib52); Cao et al., [2021](#bib.bib8); Huang et al.,
    [2019](#bib.bib35); Wu and Yang, [2019](#bib.bib91); Wang et al., [2022b](#bib.bib83);
    Eberhart and McMillan, [2022](#bib.bib17); Sivaraman et al., [2019](#bib.bib74)）；引入序列和图形基础的深度学习技术来建模代码表示并增强代码理解（Cambronero
    et al., [2019](#bib.bib7); Feng et al., [2020](#bib.bib18); Ling et al., [2020](#bib.bib49);
    Huang et al., [2021](#bib.bib34); Lachaux et al., [2021](#bib.bib42); Du et al.,
    [2021](#bib.bib16); Salza et al., [2023](#bib.bib70); Wang et al., [2022a](#bib.bib84);
    Chai et al., [2022](#bib.bib9); Li et al., [2022a](#bib.bib45), [b](#bib.bib46),
    [d](#bib.bib44); Guo et al., [2021](#bib.bib26); Gu et al., [2021a](#bib.bib21);
    Xu et al., [2021](#bib.bib92); Wang et al., [2021b](#bib.bib87), [2022c](#bib.bib88);
    Niu et al., [2022](#bib.bib62); Guo et al., [2022](#bib.bib25); Gu et al., [2018](#bib.bib24);
    Sachdev et al., [2018](#bib.bib69); Wan et al., [2019](#bib.bib79); Zeng et al.,
    [2023](#bib.bib99); Ling et al., [2021](#bib.bib50); Sun et al., [2022a](#bib.bib76);
    Liu et al., [2023](#bib.bib53); Yao et al., [2019](#bib.bib95); Haldar et al.,
    [2020](#bib.bib27); Wang et al., [2020](#bib.bib86); Zhao and Sun, [2020](#bib.bib102);
    Ye et al., [2020](#bib.bib97); Gu et al., [2021b](#bib.bib22); Cheng and Kuang,
    [2022](#bib.bib13); Arakelyan et al., [2022](#bib.bib3); Cai et al., [2023](#bib.bib6);
    Han et al., [2022](#bib.bib28); Ma et al., [2023](#bib.bib57)）；引入或提出了更高效的训练技术，使得大型模型的训练取得了巨大的成功（Feng
    et al., [2020](#bib.bib18); Guo et al., [2021](#bib.bib26); Wang et al., [2021b](#bib.bib87);
    Guo et al., [2022](#bib.bib25); Wang et al., [2022c](#bib.bib88); Niu et al.,
    [2022](#bib.bib62); Lachaux et al., [2021](#bib.bib42); Li et al., [2022b](#bib.bib46);
    Huang et al., [2021](#bib.bib34); Gu et al., [2018](#bib.bib24); Wan et al., [2019](#bib.bib79);
    Zeng et al., [2023](#bib.bib99); Ling et al., [2021](#bib.bib50); Sun et al.,
    [2022a](#bib.bib76); Xu et al., [2021](#bib.bib92); Ling et al., [2020](#bib.bib49);
    Liu et al., [2023](#bib.bib53); Li et al., [2022a](#bib.bib45), [d](#bib.bib44);
    Chen and Zhou, [2018](#bib.bib12); Chai et al., [2022](#bib.bib9); Wang et al.,
    [2022a](#bib.bib84); Han et al., [2022](#bib.bib28); Yao et al., [2019](#bib.bib95);
    Haldar et al., [2020](#bib.bib27); Wang et al., [2020](#bib.bib86); Zhao and Sun,
    [2020](#bib.bib102); Ye et al., [2020](#bib.bib97); Gu et al., [2021b](#bib.bib22);
    Bui et al., [2021](#bib.bib5); Cheng and Kuang, [2022](#bib.bib13); Arakelyan
    et al., [2022](#bib.bib3); Park et al., [2023](#bib.bib64); Cai et al., [2023](#bib.bib6);
    Ma et al., [2023](#bib.bib57); Hu et al., [2023](#bib.bib32)）。
- en: 'Significance of this review. With numerous deep learning-based code search
    works published, especially the advent of pre-training technology in recent years,
    the field of code search has entered a new era. Despite the existence of several
    studies in the field of deep learning and code search, there has not been a thorough
    and organized examination of the correlation between them. As a result, we undertake
    a study of recent deep learning research in code search, develop a new taxonomy
    and provide insights into the future research opportunities from our discoveries.
    This review serves to fill this gap. We believe that this review will be useful
    for both relevant academic researchers and industrial practitioners as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本综述的意义。随着众多基于深度学习的代码搜索工作被发表，尤其是近年来预训练技术的出现，代码搜索领域进入了一个新时代。尽管在深度学习和代码搜索领域存在若干研究，但尚未对它们之间的关系进行全面和系统的审查。因此，我们对近期的深度学习在代码搜索中的研究进行了研究，发展了新的分类法，并从我们的发现中提供了对未来研究机会的洞察。本综述旨在填补这一空白。我们相信本综述对相关学术研究人员和行业从业者都将有所帮助，如下所示：
- en: (1)
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: Individuals who are new to the field of code search and wish to gain a foundational
    understanding through a review.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对代码搜索领域新手，期望通过综述获得基础理解的个人。
- en: (2)
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: Individuals who already have some understanding of the field of code search,
    but lack an organized summary and classification, and are unable to establish
    a coherent knowledge structure for the field.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 针对那些对代码搜索领域已有一定了解，但缺乏系统总结和分类，无法建立连贯的知识结构的个人。
- en: (3)
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: Individuals who are interested in learning about the latest advancements and
    state-of-the-art methods in the field of deep code search.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对学习代码搜索领域最新进展和最先进方法感兴趣的个人。
- en: (4)
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: Individuals who aim to develop code search tools in the industry.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 针对行业中希望开发代码搜索工具的个人。
- en: (5)
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (5)
- en: Individuals who are currently seeking a research direction in the field of deep
    code search.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当前在深度代码搜索领域寻求研究方向的个人。
- en: 'Differences from prior reviews. At present, there have been several surveys
    on code search, but their focus is different from ours. Khalifa (Khalifa, [2019](#bib.bib41))
    discusses existing code search techniques, focusing on IR-based and deep-learning-based
    approaches, but only covers 5 relevant papers. Liu et al. (Liu et al., [2022](#bib.bib51))
    focus on publication trends, application scenarios, and evaluation metrics of
    code search. Grazia and Pradel (Grazia and Pradel, [2023](#bib.bib20)) provide
    a review of the historical development of code search and covers the various stages
    of the code search process, including query formulation, query processing, indexing,
    and ranking. However, the review lacks theoretical analysis and in-depth summaries,
    especially in terms of the relationship between query and code semantic matching
    models. Different from the previous reviews, we concentrate on code search technology
    based on deep learning. We collect and organize high-quality conference/journal
    papers published in the past 5 years and propose a new taxonomy. In this survey,
    we have discussed the following research questions (RQs):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 与以往综述的不同。目前，已经有几篇关于代码搜索的调查，但它们的重点不同于我们的。Khalifa（Khalifa, [2019](#bib.bib41)）讨论了现有的代码搜索技术，重点在于基于信息检索和基于深度学习的方法，但仅涵盖了5篇相关论文。Liu等（Liu
    et al., [2022](#bib.bib51)）关注代码搜索的发表趋势、应用场景和评估指标。Grazia和Pradel（Grazia and Pradel,
    [2023](#bib.bib20)）提供了代码搜索的历史发展综述，并涵盖了代码搜索过程的各个阶段，包括查询制定、查询处理、索引和排名。然而，该综述缺乏理论分析和深入总结，特别是在查询和代码语义匹配模型之间的关系方面。不同于以往的综述，我们集中于基于深度学习的代码搜索技术。我们收集并整理了过去5年中发表的高质量会议/期刊论文，并提出了新的分类法。在本调查中，我们讨论了以下研究问题（RQs）：
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: RQ1. How to accurately capture the user’s query intent?
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ1. 如何准确捕捉用户的查询意图？
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: RQ2. How to enhance the semantic understanding of code?
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ2. 如何增强对代码的语义理解？
- en: •
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: RQ3. How to train a deep code search model?
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ3. 如何训练深度代码搜索模型？
- en: •
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: RQ4. How to evaluate a code search model?
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ4. 如何评估代码搜索模型？
- en: •
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: RQ5. What are some potential avenues for future research in this promising field?
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ5. 在这一有前景的领域中，未来可能的研究方向有哪些？
- en: 'Literatures collection process. Our aim is to equip novice researchers and
    non-experts with a quick and systematic grasp of the latest code search techniques
    and motivate their future research. Considering that Gu et al. (Gu et al., [2018](#bib.bib24))
    were the pioneers in applying deep neural networks to code search tasks in 2018,
    we establish 2018 as our reference point and adhere to the guidelines proposed
    by Kitchenham and Charters (Keele, [2007](#bib.bib40)) as well as Petersen et
    al (Petersen et al., [2015](#bib.bib65)). This allows us to perform a comprehensive
    examination of the relevant literature spanning the last six years (from 2018
    to the present). Specifically, we identified a set of search strings, namely “code
    search” and “code retrieval”, from the existing literature on code search that
    we are already known. Subsequently, capitalizing on our emphasis on the precise
    technological domain of deep learning, we broadened our search strings to encompass
    the advanced concepts of “deep code search” and “deep code retrieval”. Based on
    the aforementioned four search strings, we conducted initial manual searches on
    Google Scholar, DBLP, ACM Digital Library, and Papers With Code, resulting in
    693 relevant papers. After removing duplicate papers, we identified a total of
    431 candidate papers. Our comprehensive search was finalized on June 12, 2023,
    encompassing research published prior to this date. Subsequently, we meticulously
    applied a set of well-defined inclusion and exclusion criteria to identify the
    most relevant literature that aligns with our research topic:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 文献收集过程。我们的目标是为新手研究人员和非专家提供快速而系统的最新代码搜索技术概览，并激发他们未来的研究。考虑到 Gu 等人（Gu et al., [2018](#bib.bib24)）是
    2018 年将深度神经网络应用于代码搜索任务的先驱，我们以 2018 年作为参考点，并遵循 Kitchenham 和 Charters（Keele, [2007](#bib.bib40)）以及
    Petersen 等人（Petersen et al., [2015](#bib.bib65)）提出的指南。这使我们能够对过去六年（从 2018 年到现在）的相关文献进行全面审查。具体来说，我们从现有的代码搜索文献中确定了一组搜索字符串，即“代码搜索”和“代码检索”。随后，基于我们对深度学习技术领域的重视，我们扩展了搜索字符串，涵盖了“深度代码搜索”和“深度代码检索”的高级概念。基于上述四个搜索字符串，我们在
    Google Scholar、DBLP、ACM Digital Library 和 Papers With Code 上进行了初步手动搜索，共检索到 693
    篇相关论文。去除重复论文后，我们确定了总计 431 篇候选论文。我们的全面搜索于 2023 年 6 月 12 日完成，涵盖了此日期之前发表的研究论文。随后，我们仔细应用了一套明确的纳入和排除标准，以识别与我们的研究主题最相关的文献：
- en: ✓
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ✓
- en: 'Complete research papers published in top-ranked international academic conferences
    or journals. Specifically, venues ranked A* or A in the CORE ranking: [http://portal.core.edu.au](https://www.core.edu.au/conference-portal).'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 发表在顶级国际学术会议或期刊上的完整研究论文。具体来说，CORE 排名中排名 A* 或 A 的场所：[http://portal.core.edu.au](https://www.core.edu.au/conference-portal)。
- en: ✓
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ✓
- en: Significantly impactful papers from workshops, arXiv, and lower-ranked venues.
    Specifically, these papers have received no less than 15 citations and are highly
    relevant to the subject of our investigation.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 来自研讨会、arXiv 和低级别会议的显著影响论文。具体来说，这些论文至少获得了15次引用，并且与我们研究的主题高度相关。
- en: ✓
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ✓
- en: The paper must include a discussion or evaluation of the model on the task of
    natural language code search.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 论文必须包括对自然语言代码搜索任务中模型的讨论或评估。
- en: ✗
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ✗
- en: The preprints of accepted papers are excluded.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接受的论文预印本被排除。
- en: ✗
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ✗
- en: Journal papers that are extensions of conference proceedings are discarded.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作为会议论文扩展的期刊论文被丢弃。
- en: ✗
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ✗
- en: Non-deep learning-based code search papers are ruled out.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 非深度学习基础的代码搜索论文被排除。
- en: ✗
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ✗
- en: Papers focusing on code-to-code search are excluded.
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关注代码到代码搜索的论文被排除。
- en: ✗
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ✗
- en: Papers that focus on utilizing code search models to assist other code intelligence
    tasks, such as code generation and code repair, are discarded.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关注于利用代码搜索模型辅助其他代码智能任务（如代码生成和代码修复）的论文被丢弃。
- en: Table 1. Selection of relevant papers.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1. 相关论文的选择。
- en: '| Process | Number of papers |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 处理步骤 | 论文数量 |'
- en: '| Total papers retrieved | 693 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 检索到的论文总数 | 693 |'
- en: '| After removing duplicate papers | 431 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 去除重复论文后 | 431 |'
- en: '| After excluding based on title, abstract, and keywords | 97 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 根据标题、摘要和关键词排除后 | 97 |'
- en: '| After excluding based on the full text | 64 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 根据全文排除后 | 64 |'
- en: Table 2. Top publication venues with at least two deep code search papers.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2. 至少有两篇深度代码搜索论文的顶级出版场所。
- en: '| Publication venue types | Short Name | Full Name | Number of papers |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 出版场所类型 | 简称 | 全称 | 论文数量 |'
- en: '| Conference | ICSE | International Conference on Software Engineering | 9
    |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| Conference | ICSE | 国际软件工程会议 | 9 |'
- en: '| EMNLP | Conference on Empirical Methods in Natural Language Processing |
    6 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| EMNLP | 自然语言处理实证方法会议 | 6 |'
- en: '| SANER | IEEE International Conference on Software Analysis, Evolution, and
    Reengineering | 5 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| SANER | IEEE国际软件分析、演化与重构会议 | 5 |'
- en: '| ACL | Annual Meeting of the Association for Computational Linguistics | 4
    |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| ACL | 计算语言学协会年会 | 4 |'
- en: '| FSE/ESEC | ACM Joint European Software Engineering Conference and Symposium
    on the Foundations of Software Engineering | 3 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| FSE/ESEC | ACM欧洲软件工程联合会议及软件工程基础研讨会 | 3 |'
- en: '| ASE | International Conference on Automated Software Engineering | 3 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| ASE | 国际自动化软件工程会议 | 3 |'
- en: '| TSE | IEEE Transactions on Software Engineering | 3 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| TSE | IEEE软件工程汇刊 | 3 |'
- en: '| NeurIPS | Conference on Neural Information Processing Systems | 3 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| NeurIPS | 神经信息处理系统会议 | 3 |'
- en: '| ICPC | IEEE International Conference on Program Comprehension | 3 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| ICPC | IEEE国际程序理解会议 | 3 |'
- en: '| WWW | World Wide Web | 3 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| WWW | 万维网 | 3 |'
- en: '| PLDI | ACM SIGPLAN Conference on Programming Language Design and Implementation
    | 2 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| PLDI | ACM SIGPLAN编程语言设计与实现会议 | 2 |'
- en: '| ICSME | International Conference on Software Maintenance and Evolution |
    2 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| ICSME | 国际软件维护与演化会议 | 2 |'
- en: '| Journal | TOSEM | ACM Transactions on Software Engineering and Methodology
    | 2 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| Journal | TOSEM | ACM软件工程与方法学汇刊 | 2 |'
- en: '| - | Neural Networks | 2 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| - | Neural Networks | 2 |'
- en: '| Total | - | - | 50 | ![Refer to caption](img/37f461c68989e37ba608518d99705dc6.png)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '| 总计 | - | - | 50 | ![请参阅说明](img/37f461c68989e37ba608518d99705dc6.png)'
- en: Figure 1. Number of publications per year.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图1. 每年的出版数量。
- en: As presented in Table [1](#S1.T1 "Table 1 ‣ 1\. Introduction ‣ Survey of Code
    Search Based on Deep Learning"), through a thorough analysis of the titles, abstracts,
    and keywords of the papers, we successfully identified 97 papers. Subsequently,
    after carefully cross-checking the full texts of the remaining papers, we ultimately
    obtained a collection of 64 papers on code search leveraging deep learning techniques.
    These papers primarily encompass international top conferences and journals in
    the domains of Software Engineering, Content Retrieval, and Artificial Intelligence.
    Table [2](#S1.T2 "Table 2 ‣ 1\. Introduction ‣ Survey of Code Search Based on
    Deep Learning") presents the esteemed publication venues have published at least
    two deep code search papers. These venues collectively feature 50 papers, constituting
    78.1% of the entire obtained papers. Notably, conference proceedings accounted
    for 92% of the published works. Among these 14 venues, we observed that the top
    five most popular conferences are ICSE, EMNLP, SANER, ACL, and FSE/ESEC, while
    the top two preferred journals are TOSEM and Neural Networks. Figure [1](#S1.F1
    "Figure 1 ‣ 1\. Introduction ‣ Survey of Code Search Based on Deep Learning")
    showcases a compelling upward trajectory in the annual publication quantity of
    relevant literature following the integration of deep learning techniques into
    the field of code search. This notable trend serves as a testament to the escalating
    attention and burgeoning interest surrounding deep code search.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如表[1](#S1.T1 "表 1 ‣ 1\. 引言 ‣ 基于深度学习的代码搜索调查")所示，通过对论文标题、摘要和关键词的全面分析，我们成功识别出了97篇论文。随后，在仔细核对了剩余论文的全文后，我们最终获得了一组利用深度学习技术进行代码搜索的64篇论文。这些论文主要涵盖了软件工程、内容检索和人工智能领域的国际顶级会议和期刊。表[2](#S1.T2
    "表 2 ‣ 1\. 引言 ‣ 基于深度学习的代码搜索调查")展示了至少发表过两篇深度代码搜索论文的著名出版场所。这些出版场所共刊登了50篇论文，占所有获得论文的78.1%。值得注意的是，会议论文占已发表作品的92%。在这14个场所中，我们观察到最受欢迎的前五个会议是ICSE、EMNLP、SANER、ACL和FSE/ESEC，而排名前两的期刊是TOSEM和Neural
    Networks。图[1](#S1.F1 "图 1 ‣ 1\. 引言 ‣ 基于深度学习的代码搜索调查")展示了将深度学习技术融入代码搜索领域后的相关文献年发表量呈现出显著的上升趋势。这一显著趋势证明了对深度代码搜索的关注和兴趣不断上升。
- en: 'Our contributions. The main contributions of this paper are as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献。本论文的主要贡献如下：
- en: (1)
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: 'New taxonomy. We review 64 related works on deep code search published until
    June 12, 2023, and propose a new taxonomy which groups code search based on deep
    learning into three categories: query semantics modeling, code semantics modeling,
    and matching modeling.'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 新的分类法。我们回顾了截至2023年6月12日发布的64项相关的深度代码搜索研究，并提出了一种新的分类法，将基于深度学习的代码搜索分为三类：查询语义建模、代码语义建模和匹配建模。
- en: (2)
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: Comprehensive review. We present a comprehensive overview of deep learning techniques
    in code search, offering in-depth descriptions of representative models, thorough
    comparisons, and summarized algorithms.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 综合评述。我们提供了深度学习技术在代码搜索中的全面概述，详细描述了代表性模型，进行了彻底的比较，并总结了算法。
- en: (3)
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: Abundant resources. We gather a vast array of code search resources, including
    large-scale training corpus, benchmark datasets, and evaluation metrics suitable
    for various scenarios, to aid in comparing deep code search models.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 丰富资源。我们收集了大量的代码搜索资源，包括大规模训练语料库、基准数据集以及适用于各种场景的评估指标，以帮助比较深度代码搜索模型。
- en: (4)
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: Future directions. We highlight the limitations of current deep code search
    methods and suggest various valuable research directions, aiming to spur further
    exploration in this area.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 未来方向。我们强调了当前深度代码搜索方法的局限性，并提出了各种有价值的研究方向，旨在激发该领域的进一步探索。
- en: The rest of this paper is organized as follows. Section 2 introduces the deep
    learning-based code search framework and defines the core problem of code search.
    Section 3 covers methods for enriching the semantics of natural language text
    queries. Section 4 categorizes various code representation and vectorization techniques.
    Section 5 outlines the training methods and objectives of models. Section 6 summarizes
    commonly used datasets and evaluation metrics in this field. Section 7 highlights
    potential future research directions in this promising field. Section 8 provides
    a summary of this survey.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的其余部分组织如下。第2节介绍了基于深度学习的代码搜索框架，并定义了代码搜索的核心问题。第3节涵盖了丰富自然语言文本查询语义的方法。第4节对各种代码表示和向量化技术进行了分类。第5节概述了模型的训练方法和目标。第6节总结了该领域常用的数据集和评估指标。第7节突出介绍了该有前景领域的潜在未来研究方向。第8节提供了本次调查的总结。
- en: 2\. Deep Learning-Based Code Search Framework
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 基于深度学习的代码搜索框架
- en: Deep learning has seen rapid development in the field of software engineering
    in recent years, with code search being one of the most successful applications.
    Compared with traditional methods, deep code search leverages the powerful ability
    of deep neural network to extract hidden features from data, generating semantic
    representation of natural language and code for improved performance.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在软件工程领域近年来取得了快速发展，代码搜索是最成功的应用之一。与传统方法相比，深度代码搜索利用深度神经网络强大的能力从数据中提取隐藏特征，为自然语言和代码生成语义表示，从而提高性能。
- en: '![Refer to caption](img/32c893a26078e58b4e9288b3692c2912.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/32c893a26078e58b4e9288b3692c2912.png)'
- en: Figure 2. Code search framework based on deep learning.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图2. 基于深度学习的代码搜索框架。
- en: 'Figure [2](#S2.F2 "Figure 2 ‣ 2\. Deep Learning-Based Code Search Framework
    ‣ Survey of Code Search Based on Deep Learning") illustrates the overall framework
    of deep learning-based code search. The framework consists primarily of three
    components: encoding the query, encoding the code, and measuring their similarity.
    During training, a bimodal deep neural network is trained on a large parallel
    corpus of code and natural language to learn how to encode query and code into
    high-dimensional vectors, q and c. Subsequently, the similarity between the query
    vector q and the code vector c in a high-dimensional vector space is calculated,
    such as Cosine similarity $s(\textbf{q},\textbf{c})=\frac{\textbf{q}^{T}\cdot\textbf{c}}{\|\textbf{q}\|\cdot\|\textbf{c}\|}$
    or Euclidean distance $s(\boldsymbol{q},\boldsymbol{c})=\sqrt{\sum_{i=1}^{n}\left(q_{i}-c_{i}\right)^{2}}$.
    Among these options, Cosine similarity stands out as the widely preferred calculation
    method (Gu et al., [2018](#bib.bib24); Wan et al., [2019](#bib.bib79); Ling et al.,
    [2020](#bib.bib49), [2021](#bib.bib50); Xu et al., [2021](#bib.bib92); Li et al.,
    [2022a](#bib.bib45); Zeng et al., [2023](#bib.bib99); Hu et al., [2023](#bib.bib32)).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [2](#S2.F2 "Figure 2 ‣ 2\. Deep Learning-Based Code Search Framework ‣ Survey
    of Code Search Based on Deep Learning") 说明了基于深度学习的代码搜索的整体框架。该框架主要包括三个组成部分：编码查询、编码代码以及测量它们的相似度。在训练过程中，一个双模态深度神经网络在大规模的代码和自然语言平行语料库上进行训练，以学习如何将查询和代码编码为高维向量
    $q$ 和 $c$。随后，计算查询向量 $q$ 和代码向量 $c$ 在高维向量空间中的相似度，例如余弦相似度 $s(\textbf{q},\textbf{c})=\frac{\textbf{q}^{T}\cdot\textbf{c}}{\|\textbf{q}\|\cdot\|\textbf{c}\|}$
    或欧几里得距离 $s(\boldsymbol{q},\boldsymbol{c})=\sqrt{\sum_{i=1}^{n}\left(q_{i}-c_{i}\right)^{2}}$。在这些选项中，余弦相似度脱颖而出，成为广泛采用的计算方法
    (Gu et al., [2018](#bib.bib24); Wan et al., [2019](#bib.bib79); Ling et al., [2020](#bib.bib49),
    [2021](#bib.bib50); Xu et al., [2021](#bib.bib92); Li et al., [2022a](#bib.bib45);
    Zeng et al., [2023](#bib.bib99); Hu et al., [2023](#bib.bib32))。
- en: To improve code search accuracy, the model should make query representation
    similar to correct code representation while distinct from incorrect code representation.
    Hence, training instances are typically structured as triplets $\left\langle q,c^{+},c^{-}\right\rangle$,
    and the model is trained to minimize the triplet sorting loss $\mathcal{L}\left(q,c^{+},c^{-}\right)=\max\left(0,\delta-s\left(q,c^{+}\right)+s\left(q,c^{-}\right)\right)$,
    where $q$ denotes the natural language query text, $c^{+}$ denotes correct code
    fragment, $c^{-}$ is a randomly selected negative sample code fragment from the
    rest of the code corpus, and $\delta$ denotes the margin that ensures $c^{+}$
    is closer to $q$ than $c^{-}$ in the vector space.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高代码搜索的准确性，模型应使查询表示与正确的代码表示相似，同时与错误的代码表示有所区分。因此，训练实例通常被结构化为三元组 $\left\langle
    q,c^{+},c^{-}\right\rangle$，模型的训练目标是最小化三元组排序损失 $\mathcal{L}\left(q,c^{+},c^{-}\right)=\max\left(0,\delta-s\left(q,c^{+}\right)+s\left(q,c^{-}\right)\right)$，其中
    $q$ 表示自然语言查询文本，$c^{+}$ 表示正确的代码片段，$c^{-}$ 是从代码库中随机选取的负样本代码片段，$\delta$ 表示一个边界，确保
    $c^{+}$ 在向量空间中比 $c^{-}$ 更接近 $q$。
- en: To enhance the response efficiency of the online code search service, the trained
    model typically pre-calculates the vector representation of the candidate code
    fragments in the codebase. Upon receiving a query, the code search engine computes
    the vector representation of the query, traverses the codebase to compute the
    similarity between the query and each code fragment in the semantic space, and
    finally returns the top $k$ code fragments based on the relevance scores.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高在线代码搜索服务的响应效率，训练好的模型通常会预先计算代码库中候选代码片段的向量表示。接收到查询后，代码搜索引擎计算查询的向量表示，遍历代码库计算查询与每个代码片段在语义空间中的相似度，最后根据相关性分数返回前
    $k$ 个代码片段。
- en: '![Refer to caption](img/d40d292c8173835d1284d71208982247.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/d40d292c8173835d1284d71208982247.png)'
- en: Figure 3. Overview of techniques for deep code search.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3. 深度代码搜索技术概述。
- en: 'As shown in Figure [3](#S2.F3 "Figure 3 ‣ 2\. Deep Learning-Based Code Search
    Framework ‣ Survey of Code Search Based on Deep Learning"), deep learning-based
    code search engines mainly deal with two types of input: natural language query
    and source code. Deep learning techniques are widely employed to learn the semantic
    encoding of both inputs, especially the deep semantic information of source code.
    Following this overview, we want to categorize, analyze, and summarize 64 papers
    that are highly relevant to date and deep code search. To accomplish this objective,
    we undertook an exploration of five research questions (RQs):'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [3](#S2.F3 "Figure 3 ‣ 2\. Deep Learning-Based Code Search Framework ‣ Survey
    of Code Search Based on Deep Learning") 所示，基于深度学习的代码搜索引擎主要处理两种输入：自然语言查询和源代码。深度学习技术被广泛用于学习这两种输入的语义编码，尤其是源代码的深层语义信息。在这个概述之后，我们希望对64篇高度相关的论文进行分类、分析和总结，这些论文涉及深度代码搜索。为实现这一目标，我们对五个研究问题（RQs）进行了探讨：
- en: •
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: RQ1. How to accurately capture the user’s query intent? To achieve the desired
    level of search result quality, it is crucial for the model to possess a good
    understanding of the user’s query intent. The goal of this RQ is to investigate
    how to model the representation of queries and enhance the semantic representation
    of query, thereby assisting the model in accurately capturing the user’s query
    intent.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ1. 如何准确捕捉用户的查询意图？为了达到期望的搜索结果质量，模型必须对用户的查询意图有良好的理解。这个RQ的目标是研究如何建模查询的表示和增强查询的语义表示，从而帮助模型准确捕捉用户的查询意图。
- en: •
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: RQ2. How to enhance the semantic understanding of code? The syntax of programming
    languages differs from natural language, giving rise to a semantic gap between
    them. This RQ investigates through multiple perspectives, encompassing the representation
    and vectorization of code, as well as diminishing the semantic gap between code
    and natural language through interaction.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ2. 如何增强代码的语义理解？编程语言的语法与自然语言不同，这导致了它们之间存在语义差距。这个RQ从多个角度进行研究，包括代码的表示和向量化，以及通过交互来缩小代码与自然语言之间的语义差距。
- en: •
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: RQ3. How to train a deep code search model? This RQ aims to investigate how
    to pretrain code intelligence large models and how to fine-tune code search models.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ3. 如何训练深度代码搜索模型？这个RQ旨在研究如何预训练代码智能大型模型以及如何微调代码搜索模型。
- en: •
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: RQ4. How to evaluate a code search model? The goal of this RQ is to analyze
    code search datasets, evaluation metrics, and the selection of appropriate code
    search methods.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ4. 如何评估代码搜索模型？这个RQ的目标是分析代码搜索数据集、评估指标以及选择合适的代码搜索方法。
- en: •
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: RQ5. What are some potential avenues for future research in this promising field?
    Through analysis of the aforementioned RQs, we have identified several limitations
    and challenges. Building upon this foundation, this RQ discusses twelve valuable
    future research directions in the field of deep code search.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ5. 在这个有前景的领域中有哪些潜在的未来研究方向？通过对上述RQ的分析，我们已经识别出一些局限性和挑战。在此基础上，RQ讨论了深度代码搜索领域的十二个有价值的未来研究方向。
- en: In the following sections, we will delve into a comprehensive and detailed discussion
    of each RQ.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将对每个RQ进行全面而详细的讨论。
- en: 3\. Query Representation and Enhancement (RQ1)
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 查询表示和增强（RQ1）
- en: 'Processing a user’s input query is the initial step in conducting a code search
    task. Accurately comprehending the search intention within the query text is crucial
    in providing satisfying results to users. This section covers the query processing
    procedure from two perspectives: modeling the query representation and enhancing
    the semantic representation of the query.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 处理用户输入查询是进行代码搜索任务的初步步骤。准确理解查询文本中的搜索意图对提供令人满意的结果至关重要。本节从两个角度覆盖查询处理过程：建模查询表示和增强查询的语义表示。
- en: 3.1\. Query Representation
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1. 查询表示
- en: The deep learning-based code search represents queries and code fragments as
    vectors in high-dimensional space by encoding them. The query encoder and the
    code encoder can use the same or different network architectures. To derive the
    vector representation of the query, tokenization of the input query text is required.
    Tokenization involves reassembling continuous word sequences into token sequences
    based on specific criteria. As shown in Figure [3](#S2.F3 "Figure 3 ‣ 2\. Deep
    Learning-Based Code Search Framework ‣ Survey of Code Search Based on Deep Learning"),
    the developer inputs a query “get the maximum value”, and the tokenizer processes
    it into a token sequence [“get”, “the”, “maximum”, “value”], which is then looked
    up in the dictionary to get the id list [459, 448, 6098, 767] as the input for
    the query encoder. The query encoder $E_{q}$ is an embedding network that converts
    the developer-given query text into a $d$-dimensional vector representation. To
    train the query encoder, existing deep learning-based code search methods have
    tried various neural network architectures, such as RNN (Gu et al., [2018](#bib.bib24)),
    LSTM (Zeng et al., [2023](#bib.bib99)), GNN (Ling et al., [2021](#bib.bib50)),
    and transformer (Feng et al., [2020](#bib.bib18)). As collecting and annotating
    real (query, code) pairs is costly, comments are often treated as queries during
    training.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 基于深度学习的代码搜索通过对查询和代码片段进行编码，将它们表示为高维空间中的向量。查询编码器和代码编码器可以使用相同或不同的网络架构。为了推导查询的向量表示，需要对输入的查询文本进行分词。分词涉及根据特定标准将连续的词序列重新组装成标记序列。如图
    [3](#S2.F3 "Figure 3 ‣ 2\. Deep Learning-Based Code Search Framework ‣ Survey
    of Code Search Based on Deep Learning")所示，开发者输入查询“获取最大值”，分词器将其处理为标记序列 [“get”,
    “the”, “maximum”, “value”]，然后在词典中查找以获取 id 列表 [459, 448, 6098, 767] 作为查询编码器的输入。查询编码器
    $E_{q}$ 是一个嵌入网络，将开发者给定的查询文本转换为 $d$ 维向量表示。为了训练查询编码器，现有的基于深度学习的代码搜索方法尝试了各种神经网络架构，如
    RNN (Gu et al., [2018](#bib.bib24))、LSTM (Zeng et al., [2023](#bib.bib99))、GNN
    (Ling et al., [2021](#bib.bib50)) 和 transformer (Feng et al., [2020](#bib.bib18))。由于收集和标注真实的
    (查询，代码) 对成本高昂，因此在训练过程中，注释通常被视为查询。
- en: 3.2\. Methods For Enhancing query Representation
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 提升查询表示的方法
- en: Developers often struggle to clearly articulate their target requirements when
    searching for code and prefer to use short initial queries with broad meanings,
    such as keywords splicing. In this case, the code search engine is likely to return
    many irrelevant code fragments. As a result, Developers have to waste time reviewing
    non-relevant results and adjusting queries. To address this, several studies have
    focused on enhancing query semantics to improve code search efficiency by enabling
    the code search engine to expand or reconstruct the query automatically. Table
    [3](#S3.T3 "Table 3 ‣ 3.2\. Methods For Enhancing query Representation ‣ 3\. Query
    Representation and Enhancement (RQ1) ‣ Survey of Code Search Based on Deep Learning")
    summarizes the different approaches along based on API or class name, based on
    co-occurring terms, based on commit versions, based on query generation, based
    on search logs, based on user feedback, and based on multiple perspectives. We
    will discuss them in detail below.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者在搜索代码时常常难以清晰表达他们的目标需求，更倾向于使用含义广泛的简短初始查询，如关键词拼接。在这种情况下，代码搜索引擎可能会返回许多不相关的代码片段。结果是，开发者不得不浪费时间查看无关结果并调整查询。为了解决这个问题，一些研究集中在提升查询语义上，以通过使代码搜索引擎能够自动扩展或重构查询来提高代码搜索效率。表
    [3](#S3.T3 "Table 3 ‣ 3.2\. Methods For Enhancing query Representation ‣ 3\. Query
    Representation and Enhancement (RQ1) ‣ Survey of Code Search Based on Deep Learning")
    总结了基于 API 或类名、基于共现术语、基于提交版本、基于查询生成、基于搜索日志、基于用户反馈和基于多个视角等不同方法。我们将详细讨论这些方法。
- en: Table 3. Overview of approaches for enhancing query representation.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3. 提升查询表示的不同方法概述。
- en: '| Year | Work | Based on |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 年份 | 工作 | 基于'
- en: '| API or class name | co-occurring terms | commit versions | query generation
    | Others |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| API 或类名 | 共现术语 | 提交版本 | 查询生成 | 其他 |'
- en: '| 2018 | NLP2API (Rahman and Roy, [2018](#bib.bib67)) | ✓ |  |  |  |  |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | NLP2API (Rahman and Roy, [2018](#bib.bib67)) | ✓ |  |  |  |  |'
- en: '| 2018 | COCABU (Sirres et al., [2018](#bib.bib73)) | ✓ |  |  |  |  |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | COCABU (Sirres et al., [2018](#bib.bib73)) | ✓ |  |  |  |  |'
- en: '| 2018 | Zhang et al. (Zhang et al., [2018](#bib.bib100)) | ✓ |  |  |  |  |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | Zhang et al. (Zhang et al., [2018](#bib.bib100)) | ✓ |  |  |  |  |'
- en: '| 2019 | RACK (Rahman et al., [2019](#bib.bib68)) |  | ✓ |  |  |  |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | RACK (Rahman et al., [2019](#bib.bib68)) |  | ✓ |  |  |  |'
- en: '| 2019 | Rahman (Rahman, [2019](#bib.bib66)) |  | ✓ |  |  | ✓ |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | Rahman (Rahman, [2019](#bib.bib66)) |  | ✓ |  |  | ✓ |'
- en: '| 2019 | ALICE (Sivaraman et al., [2019](#bib.bib74)) |  |  |  |  | ✓ |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | ALICE (Sivaraman 等, [2019](#bib.bib74)) |  |  |  |  | ✓ |'
- en: '| 2019 | NQE (Liu et al., [2019a](#bib.bib52)) | ✓ |  |  |  |  |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | NQE (Liu 等, [2019a](#bib.bib52)) | ✓ |  |  |  |  |'
- en: '| 2019 | QESC (Huang et al., [2019](#bib.bib35)) |  |  | ✓ |  |  |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | QESC (Huang 等, [2019](#bib.bib35)) |  |  | ✓ |  |  |'
- en: '| 2019 | Wu and Yang (Wu and Yang, [2019](#bib.bib91)) |  |  | ✓ |  |  |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | Wu 和 Yang (Wu 和 Yang, [2019](#bib.bib91)) |  |  | ✓ |  |  |'
- en: '| 2021 | SEQUER (Cao et al., [2021](#bib.bib8)) |  |  |  |  | ✓ |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | SEQUER (Cao 等, [2021](#bib.bib8)) |  |  |  |  | ✓ |'
- en: '| 2022 | QueCos (Wang et al., [2022b](#bib.bib83)) |  |  |  | ✓ |  |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | QueCos (Wang 等, [2022b](#bib.bib83)) |  |  |  | ✓ |  |'
- en: '| 2022 | ZaCQ (Eberhart and McMillan, [2022](#bib.bib17)) |  |  |  | ✓ |  |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | ZaCQ (Eberhart 和 McMillan, [2022](#bib.bib17)) |  |  |  | ✓ |  |'
- en: Based on API or class name. Enhancing natural language queries with semantically
    related identifiers has significant potential. Researchers have leveraged source
    code knowledge from platforms such as Stack Overflow and Github to reformulate
    natural language queries. The commonality among query reformulation methods is
    using similarity measures to compare the words or identifiers in the query to
    words or identifiers such as API and class names in source code (Sirres et al.,
    [2018](#bib.bib73); Rahman and Roy, [2018](#bib.bib67); Rahman et al., [2019](#bib.bib68);
    Rahman, [2019](#bib.bib66); Zhang et al., [2018](#bib.bib100)). For instance,
    based on posts on Stack Overflow, Sirres et al. (Sirres et al., [2018](#bib.bib73))
    extend users’ free-form queries with API methods or class names in code snippets
    marked as acceptable. Rahman and Roy (Rahman and Roy, [2018](#bib.bib67)) propose
    automatically identifying relevant or specific API classes from Stack Overflow
    to reformulate queries. They first use pseudo-relevance feedback and term weighting
    algorithm to gather candidate API classes from Stack Overflow, and then apply
    the maximum likelihood estimation between the keywords in the query and API classes
    to rank them. Finally, the top-$k$ correlated classes are used to reformulate
    the query. Zhang et al. (Zhang et al., [2018](#bib.bib100)) apply a continuous
    bag-of-words model to learn the vector representation of API class names in the
    code corpus. These vectors are then utilized to calculate the semantic distance
    between the initial query and API class names. The most semantically relevant
    API class names are selected for query expansion.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 API 或类名。用语义相关的标识符增强自然语言查询具有重要潜力。研究人员利用来自 Stack Overflow 和 Github 等平台的源代码知识来重新构造自然语言查询。查询重新构造方法的共同点在于使用相似性度量来比较查询中的词或标识符与源代码中的词或标识符（如
    API 和类名）（Sirres 等, [2018](#bib.bib73); Rahman 和 Roy, [2018](#bib.bib67); Rahman
    等, [2019](#bib.bib68); Rahman, [2019](#bib.bib66); Zhang 等, [2018](#bib.bib100)）。例如，基于
    Stack Overflow 上的帖子，Sirres 等（Sirres 等, [2018](#bib.bib73)）通过接受的代码片段中的 API 方法或类名来扩展用户的自由形式查询。Rahman
    和 Roy（Rahman 和 Roy, [2018](#bib.bib67)）提出自动识别 Stack Overflow 中相关或特定的 API 类以重新构造查询。他们首先使用伪相关反馈和术语加权算法从
    Stack Overflow 中收集候选 API 类，然后应用查询中的关键字与 API 类之间的最大似然估计进行排名。最后，使用前 $k$ 个相关类来重新构造查询。Zhang
    等（Zhang 等, [2018](#bib.bib100)）应用连续词袋模型来学习代码语料库中 API 类名的向量表示。这些向量然后用于计算初始查询与 API
    类名之间的语义距离。选择最具语义相关性的 API 类名用于查询扩展。
- en: Based on co-occurring terms. A few approaches explore term co-occurrence relationships
    when reconstructing queries. These methods identify query keywords within structured
    entities like method and field signatures and then propose their co-occurring
    terms as candidates for query reformulation. For example, Liu et al. (Liu et al.,
    [2019a](#bib.bib52)) present a model called NQE that uses an encoder-decoder architecture
    to predict co-occurring keywords with query keywords in codebase. NQE takes an
    initial query as input to obtain the corresponding encoding, and then inputs this
    encoding into a Recurrent Neural Network (RNN) decoder as the initial state. By
    collecting the output at each time step, NQE generates a sequence of method names.
    Finally, an output set of expanded keywords is obtained by splitting each method
    name in the sequence.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 基于共现词。几种方法在重构查询时探索术语共现关系。这些方法在结构化实体（如方法和字段签名）中识别查询关键字，然后将其共现词作为查询重新构造的候选。例如，Liu
    等（Liu 等, [2019a](#bib.bib52)）提出了一种名为 NQE 的模型，该模型使用编码器-解码器架构预测代码库中与查询关键字共现的关键字。NQE
    将初始查询作为输入以获取相应的编码，然后将该编码输入到递归神经网络（RNN）解码器中作为初始状态。通过在每个时间步收集输出，NQE 生成方法名称序列。最后，通过将序列中的每个方法名称拆分，得到扩展关键字的输出集合。
- en: Based on commit versions. The code retrieved via code search engines may require
    modification prior to use, such as for compatibility with different API versions.
    A few approaches take this potential code change into account when expanding queries,
    freeing developers from manually modifying codes. Huang et al. (Huang et al.,
    [2019](#bib.bib35)) analyze the changes made to codes through extracted sequences
    from GitHub commits to determine what modifications were made and the reasons.
    This aids in inferring fine-grained changes to queries. They expand the query
    with relevant terms and eliminate irrelevant terms to minimize the negative effects
    of excessive query expansion. Wu and Yang (Wu and Yang, [2019](#bib.bib91)) analyze
    recurrent code changes within the versions history of open source projects. For
    example, if token “$a$” in the code snippet is frequently modified to token “$b$”,
    then when the target code contains token “$a$”, the token “$b$” can be used to
    expand the initial query. By expanding the query in this way, the search engine
    can retrieve the updated code snippets, avoiding developers manually updating
    query.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 基于提交版本。通过代码搜索引擎检索到的代码在使用之前可能需要修改，例如与不同的API版本兼容。一些方法在扩展查询时考虑了这种潜在的代码更改，免去了开发者手动修改代码的麻烦。黄等（黄等，[2019](#bib.bib35)）分析了通过从GitHub提交中提取的序列对代码进行的更改，以确定所做的修改及其原因。这有助于推断对查询的细粒度更改。他们通过相关术语扩展查询，并消除不相关的术语，以最小化过度查询扩展的负面影响。吴和杨（吴和杨，[2019](#bib.bib91)）分析了开源项目版本历史中的重复代码更改。例如，如果代码片段中的标记“$a$”经常被修改为标记“$b$”，那么当目标代码包含标记“$a$”时，可以使用标记“$b$”来扩展初始查询。通过这种方式扩展查询，搜索引擎可以检索到更新后的代码片段，从而避免开发者手动更新查询。
- en: Based on query generation. Besides extracting relevant identifiers or keywords
    from codebases to expand queries, a few approaches aim to generate queries with
    richer semantics. Wang et al. (Wang et al., [2022b](#bib.bib83)) argue that many
    existing deep learning methods in the field overlook the knowledge gap between
    query and code description. They note that queries are typically shorter than
    the corresponding code descriptions. Moreover, using (code, description) pairs
    as training data may not generalize well to real-world user queries. To address
    these issues, they propose the model QueCos. QueCos employs LSTM with an attention
    mechanism as its architecture and uses reinforcement learning to capture the key
    semantics of a given query. It then generates a semantically enhanced query, and
    blends the results of the initial query and the semantically enhanced query using
    a mix-ranking technique to prioritize relevant code snippets. To solve the problem
    that the ground-truth answer does not have a high rank, Eberhart and McMillan
    (Eberhart and McMillan, [2022](#bib.bib17)) propose the model ZaCQ to generate
    questions that clarify the developers’ search intent. When given a code search
    query and the top-$k$ most relevant results, ZaCQ identifies ambiguous aspects
    in the query, extracts task information from attributes such as function names
    and comments, and generates a targeted clarifying question for unclear requirements.
    Eventually, it employs the feedback association algorithm to boost the ranking
    of relevant results.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 基于查询生成。除了从代码库中提取相关的标识符或关键词来扩展查询外，一些方法旨在生成具有更丰富语义的查询。王等（王等，[2022b](#bib.bib83)）认为，许多现有的深度学习方法在这一领域忽视了查询与代码描述之间的知识差距。他们指出，查询通常比相应的代码描述要短。此外，使用（代码，描述）对作为训练数据可能不适用于现实世界的用户查询。为了解决这些问题，他们提出了模型QueCos。QueCos使用带有注意力机制的LSTM作为其架构，并利用强化学习来捕捉给定查询的关键语义。然后，它生成一个语义增强的查询，并使用混合排序技术将初始查询和语义增强查询的结果进行融合，以优先排序相关的代码片段。为了解决真实答案排名不高的问题，Eberhart和McMillan（Eberhart和McMillan，[2022](#bib.bib17)）提出了模型ZaCQ，以生成能够澄清开发者搜索意图的问题。在给定代码搜索查询和前$k$个最相关的结果时，ZaCQ识别查询中的模糊方面，从函数名和注释等属性中提取任务信息，并生成一个针对不明确需求的澄清问题。最终，它利用反馈关联算法来提升相关结果的排名。
- en: Others. Rahman (Rahman, [2019](#bib.bib66)) reformulates the query from multiple
    perspectives to further enrich its semantics. He gathers search keywords from
    texts and source codes, structured entities from bug reports and documents, and
    relevant API classes from Stack Overflow Q&A posts. After that, he uses this information
    to reformulate queries and improve code search performance with appropriate term
    weighting and context awareness. To explore the search logs from Stack Overflow,
    Cao et al. (Cao et al., [2021](#bib.bib8)) provide a unique insight into query
    reformulation patterns based on large-scale real search logs from Stack Overflow.
    They build a large-scale query reconstruction corpus, incorporating both original
    queries and their corresponding reconstructed queries, to train the model. When
    given a user query, the trained model automatically generates a list of candidate
    reconstructed queries for selection. User feedback can also be actively included
    to help users refine query. Sivaraman et al. (Sivaraman et al., [2019](#bib.bib74))
    leverage user feedback to label whether the returned samples are desired or not
    desired, and then extract the logical information of the code from these positive
    and negative samples to reconstruct the query.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 其他。Rahman（Rahman，[2019](#bib.bib66)）从多个角度重新构造查询，以进一步丰富其语义。他从文本和源代码中收集搜索关键字，从错误报告和文档中收集结构化实体，以及从Stack
    Overflow问答帖子中获取相关的API类。之后，他利用这些信息重新构造查询，并通过适当的术语加权和上下文感知来提高代码搜索性能。为了探索来自Stack
    Overflow的搜索日志，Cao等人（Cao等，[2021](#bib.bib8)）基于来自Stack Overflow的大规模真实搜索日志提供了对查询重构模式的独特见解。他们建立了一个大规模的查询重建语料库，包含原始查询及其相应的重建查询，以训练模型。给定用户查询时，训练好的模型会自动生成候选重建查询列表供选择。用户反馈也可以主动纳入，以帮助用户优化查询。Sivaraman等人（Sivaraman等，[2019](#bib.bib74)）利用用户反馈标记返回的样本是否满足需求，然后从这些正负样本中提取代码的逻辑信息以重构查询。
- en: 3.3\. Summary
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 总结
- en: Current code search engines struggle with understanding natural language queries
    and only return relevant code fragments if the query includes specific identifiers
    like class and function names. However, developers may not know the relevant identifiers.
    To overcome this, data from sources such as Stack Overflow, GitHub, and codebases
    are fully mined to extract valuable information, such as code elements and term
    tokens, based on API, co-occurrence relations, search logs, and commit information.
    This information is then added to natural language queries with appropriate term
    weighting, significantly improving the representation of the query. Moreover,
    techniques exist to produce a query with a more lucid search intent by leveraging
    the extracted information, thereby enhancing search efficiency and performance.
    However, semantically related terms may not always co-occur, and simple co-occurrence
    frequencies may not be sufficient for selecting appropriate search keywords for
    query reformulation. More importantly, the success of the extended query method
    also relies on the quality of the extracted words. The crowdsourced knowledge
    from Stack Overflow may contain noise and if the words are not extracted properly,
    it can lead to excessive query expansion and negatively impact search accuracy.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的代码搜索引擎在理解自然语言查询方面存在困难，只有当查询包含特定的标识符如类名和函数名时，才能返回相关的代码片段。然而，开发者可能不知道相关的标识符。为了解决这个问题，从Stack
    Overflow、GitHub和代码库等来源中充分挖掘数据，以提取有价值的信息，如代码元素和术语标记，这些信息基于API、共现关系、搜索日志和提交信息。这些信息随后被加入到自然语言查询中，并进行适当的术语加权，从而显著提高查询的表示效果。此外，还存在通过利用提取的信息来生成更清晰搜索意图的查询，从而提高搜索效率和性能的技术。然而，语义相关的术语可能并不总是共现，而简单的共现频率可能不足以选择适当的搜索关键字用于查询重构。更重要的是，扩展查询方法的成功还依赖于提取词汇的质量。来自Stack
    Overflow的众包知识可能包含噪声，如果词汇提取不当，可能导致过度扩展查询并对搜索准确性产生负面影响。
- en: '<svg   height="105.75" overflow="visible" version="1.1" width="600"><g transform="translate(0,105.75)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    width="556.69" height="78.2" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">Summary of answers to RQ1: • Information such as API or class
    name, co-occurring terms, commit versions, search logs and user feedback are often
    used to reformulate the query. • Reformulating query based on API or class name
    is the most popular method in the past 6 years. • When reconstructing the query,
    it is important to avoid introducing noisy words that could result in excessive
    query expansion.</foreignobject></g></g></svg>'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: <svg height="105.75" overflow="visible" version="1.1" width="600"><g transform="translate(0,105.75)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    width="556.69" height="78.2" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">RQ1的答案总结：• API或类名、共现术语、提交版本、搜索日志和用户反馈等信息常用于重新制定查询。• 基于API或类名重新制定查询是过去6年中最流行的方法。•
    在重建查询时，重要的是避免引入可能导致查询扩展过度的噪声词。</foreignobject></g></g></svg>
- en: 4\. Code representation and vectorization (RQ2)
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 代码表示和向量化（RQ2）
- en: The goal of a code search engine is to retrieve code fragments that match the
    query semantics from the codebase. To close the semantic gap between programming
    language and natural language, deepening the understanding of code semantics and
    fostering robust interaction between code and query are essential in addition
    to improving the accuracy of query intent. In this section, we discuss the code
    encoding model, examining it through the lenses of code representation and code
    vectorization. Additionally, we discuss the crucial aspect of the interaction
    between query and code, shedding light on its significance for the comprehensive
    semantic understanding of both elements.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 代码搜索引擎的目标是从代码库中检索与查询语义匹配的代码片段。为了缩小编程语言与自然语言之间的语义差距，除了提高查询意图的准确性外，深入理解代码语义并促进代码与查询之间的稳健交互也是至关重要的。在这一部分，我们讨论代码编码模型，从代码表示和代码向量化的角度进行审视。此外，我们还讨论了查询与代码之间交互的关键方面，揭示了它对全面语义理解的意义。
- en: 4.1\. Code Representation
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 代码表示
- en: 4.1.1\. Preliminaries
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1\. 基础知识
- en: Source code is the original program text written by developers in a programming
    language, consisting of instructions and statements. It is typically compiled
    into machine language that a computer can understand and execute. During the compilation
    process from source code to machine code, various intermediate representation
    forms are generated, such as Abstract Syntax Tree (AST), Data Flow Graph (DFG),
    Control Flow Graph (CFG), and LLVM Intermediate Representation (IR). In this process,
    the compiler automatically performs program analysis techniques, including lexical,
    syntactic, and semantic analysis, to verify the correctness of the source code.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码是由开发人员使用编程语言编写的原始程序文本，包含指令和语句。它通常会被编译成计算机可以理解和执行的机器语言。在从源代码到机器代码的编译过程中，会生成各种中间表示形式，如抽象语法树（AST）、数据流图（DFG）、控制流图（CFG）和LLVM中间表示（IR）。在此过程中，编译器会自动执行程序分析技术，包括词法、语法和语义分析，以验证源代码的正确性。
- en: '![Refer to caption](img/9153d070697d454960c7461d90913a99.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/9153d070697d454960c7461d90913a99.png)'
- en: Figure 4. Multiple Modalities of Source Code.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4. 源代码的多模态。
- en: Abstract Syntax Tree (AST) is a tree-like representation of the source code’s
    syntax. It consists of leaf nodes, non-leaf nodes and the edges between them,
    reflecting the source code’s rich syntax structure. For example, in Figure [4](#S4.F4
    "Figure 4 ‣ 4.1.1\. Preliminaries ‣ 4.1\. Code Representation ‣ 4\. Code representation
    and vectorization (RQ2) ‣ Survey of Code Search Based on Deep Learning")(e), the
    assignment statement “$x=0$” is represented by a non-leaf node “$assignment$”
    and three leaf nodes “$x$”, “$=$”, and “$0$” connected by directed edges. A conditional
    jump statement like $if-condition-else$ can be represented by a node with three
    branches. Typically, the standard compiler tool $tree-sitter$ ¹¹1https://github.com/tree-sitter/tree-sitter
    is commonly used to parse source code into AST.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 抽象语法树（AST）是源代码语法的树状表示。它由叶子节点、非叶子节点及其之间的边组成，反映了源代码丰富的语法结构。例如，在图[4](#S4.F4 "Figure
    4 ‣ 4.1.1\. Preliminaries ‣ 4.1\. Code Representation ‣ 4\. Code representation
    and vectorization (RQ2) ‣ Survey of Code Search Based on Deep Learning")(e)中，赋值语句“$x=0$”由一个非叶子节点“$assignment$”和三个叶子节点“$x$”、“$=$”以及“$0$”通过有向边连接表示。像$if-condition-else$这样的条件跳转语句可以由一个具有三个分支的节点表示。通常，标准编译器工具$tree-sitter$
    ¹¹1https://github.com/tree-sitter/tree-sitter常用于将源代码解析为AST。
- en: Data Flow Graph (DFG) represents the logical relationships of the code, the
    direction of data transmission and the process of logical transformation. DFG
    abstracts the dependencies between variables in the source code, where nodes represent
    variables and edges represent the source of each variable’s value (Guo et al.,
    [2021](#bib.bib26)). As shown in Figure [4](#S4.F4 "Figure 4 ‣ 4.1.1\. Preliminaries
    ‣ 4.1\. Code Representation ‣ 4\. Code representation and vectorization (RQ2)
    ‣ Survey of Code Search Based on Deep Learning")(b), the variable $x^{11}$ returned
    by the function has two sources which can either come from $a^{10}$ or $b^{8}$
    based on the outcome of the $if$ condition. Evidently, adhering to naming conventions
    is not universal among software developers, and this can pose a challenge in comprehending
    variable semantics at times. Fortunately, DFG helps overcome the semantic deviation
    caused by inconsistent naming.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 数据流图（DFG）表示代码的逻辑关系、数据传输方向和逻辑转换过程。DFG抽象了源代码中变量之间的依赖关系，其中节点表示变量，边表示每个变量值的来源（Guo
    et al., [2021](#bib.bib26)）。如图[4](#S4.F4 "Figure 4 ‣ 4.1.1\. Preliminaries ‣ 4.1\.
    Code Representation ‣ 4\. Code representation and vectorization (RQ2) ‣ Survey
    of Code Search Based on Deep Learning")(b)所示，函数返回的变量$x^{11}$有两个来源，这些来源可以是基于$if$条件结果的$a^{10}$或$b^{8}$。显然，遵守命名规范并不是所有软件开发人员的普遍做法，这有时会对理解变量语义造成挑战。幸运的是，DFG有助于克服因命名不一致造成的语义偏差。
- en: Control Flow Graph (CFG) is an abstract representation of a program’s structure,
    composed of basic blocks and directed edges between them. Each directed edge reflects
    the execution order of two basic blocks. For example, as shown in Figure [4](#S4.F4
    "Figure 4 ‣ 4.1.1\. Preliminaries ‣ 4.1\. Code Representation ‣ 4\. Code representation
    and vectorization (RQ2) ‣ Survey of Code Search Based on Deep Learning")(c), the
    outcome of an $if$ statement results in two different execution paths, namely
    “$x=a$” and “$x=b$”. CFG represents the running sequence and logical relationship
    of the code, effectively reflecting the execution semantics of the program.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 控制流图（CFG）是程序结构的抽象表示，由基本块及其之间的有向边组成。每个有向边反映两个基本块的执行顺序。例如，如图[4](#S4.F4 "Figure
    4 ‣ 4.1.1\. Preliminaries ‣ 4.1\. Code Representation ‣ 4\. Code representation
    and vectorization (RQ2) ‣ Survey of Code Search Based on Deep Learning")(c)所示，$if$语句的结果产生了两个不同的执行路径，即“$x=a$”和“$x=b$”。CFG表示代码的运行序列和逻辑关系，有效地反映了程序的执行语义。
- en: Intermediate Representation (IR) is a structured and language-agnostic representation
    of the source code that captures the essential semantics and structure of the
    code, while abstracting away language-specific details. It serves as an intermediate
    step during compilation or interpretation and enables various optimizations and
    transformations to be performed on the code. For example, as shown in Figure [4](#S4.F4
    "Figure 4 ‣ 4.1.1\. Preliminaries ‣ 4.1\. Code Representation ‣ 4\. Code representation
    and vectorization (RQ2) ‣ Survey of Code Search Based on Deep Learning")(d), the
    assignment statement “$x=0$” is represented by the IR instruction `%x = alloca
    i32; store i32 0, i32 %x;` , that is, first allocate storage space for the temporary
    variable “$x$”, and then store the constant “$0$” in it. IR serves as the foundation
    for building CFG and DFG. The common IR is shared by multiple objects and can
    realize the unified representation of different programming languages.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 中间表示（IR）是源代码的结构化且语言无关的表示，捕捉了代码的基本语义和结构，同时抽象掉语言特定的细节。它作为编译或解释过程中的中间步骤，并使对代码进行各种优化和变换成为可能。例如，如图
    [4](#S4.F4 "Figure 4 ‣ 4.1.1\. Preliminaries ‣ 4.1\. Code Representation ‣ 4\.
    Code representation and vectorization (RQ2) ‣ Survey of Code Search Based on Deep
    Learning")(d) 所示，赋值语句“$x=0$”由IR指令 `%x = alloca i32; store i32 0, i32 %x;` 表示，即首先为临时变量“$x$”分配存储空间，然后将常量“$0$”存储其中。IR作为构建CFG和DFG的基础。公共IR被多个对象共享，并能实现不同编程语言的统一表示。
- en: Program Transformation (PT) denotes a code snippet that performs the same task
    as a given program. It allows for the creation of numerous versions that fulfill
    identical functional requirements. For example, Figure [4](#S4.F4 "Figure 4 ‣
    4.1.1\. Preliminaries ‣ 4.1\. Code Representation ‣ 4\. Code representation and
    vectorization (RQ2) ‣ Survey of Code Search Based on Deep Learning")(f) is another
    representation of the functionality expressed in Figure [4](#S4.F4 "Figure 4 ‣
    4.1.1\. Preliminaries ‣ 4.1\. Code Representation ‣ 4\. Code representation and
    vectorization (RQ2) ‣ Survey of Code Search Based on Deep Learning")(a).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 程序变换（PT）指的是执行与给定程序相同任务的代码片段。它允许创建多个版本，以满足相同的功能需求。例如，图 [4](#S4.F4 "Figure 4 ‣
    4.1.1\. Preliminaries ‣ 4.1\. Code Representation ‣ 4\. Code representation and
    vectorization (RQ2) ‣ Survey of Code Search Based on Deep Learning")(f) 是图 [4](#S4.F4
    "Figure 4 ‣ 4.1.1\. Preliminaries ‣ 4.1\. Code Representation ‣ 4\. Code representation
    and vectorization (RQ2) ‣ Survey of Code Search Based on Deep Learning")(a) 所表达功能的另一种表示。
- en: 4.1.2\. Sequence
  id: totrans-151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2\. 序列
- en: The triumph of embedding technology in NLP has spurred researchers to investigate
    its potential use in code analysis. Presently, several studies treat source code
    as a straightforward text sequence and employ NLP techniques directly on code
    snippets.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入技术在自然语言处理（NLP）中的成功促使研究人员探索其在代码分析中的潜在应用。目前，已有几项研究将源代码视为简单的文本序列，并直接在代码片段上应用NLP技术。
- en: 'Source code Token Sequence (STS). Some approaches consider the tokenized code
    token sequence itself as the code representation and feed it into the model training
    process to learn the semantics of the code (Cambronero et al., [2019](#bib.bib7);
    Yao et al., [2019](#bib.bib95); Zhao and Sun, [2020](#bib.bib102); Ye et al.,
    [2020](#bib.bib97); Feng et al., [2020](#bib.bib18); Ling et al., [2020](#bib.bib49);
    Huang et al., [2021](#bib.bib34); Lachaux et al., [2021](#bib.bib42); Du et al.,
    [2021](#bib.bib16); Salza et al., [2023](#bib.bib70); Arakelyan et al., [2022](#bib.bib3);
    Cai et al., [2023](#bib.bib6); Wang et al., [2022a](#bib.bib84); Chai et al.,
    [2022](#bib.bib9); Li et al., [2022a](#bib.bib45), [b](#bib.bib46), [d](#bib.bib44)).
    For instance, based on the powerful learning ability of Transformer, Feng et al.
    (Feng et al., [2020](#bib.bib18)) build CodeBERT, the first large-scale program
    language pre-training model. Inspired by BERT-based NLP, they directly feed the
    token sequence of a code fragment into a multi-layer Transformer. This allows
    the model to incorporate context information and learn to identify tokens that
    are critical to the code’s semantics. Nevertheless, obtaining all the tokens of
    the source code directly through tokenization ignores syntactic details, making
    it difficult to discern whether a term originates from a variable name or a method
    call. To this end, Du et al. (Du et al., [2021](#bib.bib16)) perform data augmentation
    on code fragments from three perspectives: code structure, variable names, and
    APIs. They construct structure-centric datasets, variable-centric datasets, and
    API-centric datasets, which are respectively fed into the model for training.
    To assist the model in learning code features that are invariant across semantically
    equivalent programs, Wang et al. (Wang et al., [2022a](#bib.bib84)) develop a
    semantic-preserving transformation for code snippets. The transformation preserves
    the code’s semantics but changes its lexical appearance and syntactic structure.
    Specifically, they modify the control structure, APIs, and declarations of the
    code to enable the model to extract and learn relevant features, while preserving
    code semantics. Transformation-based approaches (such as generating semantically
    equivalent code fragments through variable renaming) often produce code with highly
    similar superficial forms, causing the model to focus on surface-level code structure
    rather than its semantic information. To mitigate this, Li et al. (Li et al.,
    [2022b](#bib.bib46)) construct positive samples using code comments and abstract
    syntax tree subtrees, encouraging the model to capture semantic information.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码令牌序列（STS）。一些方法将标记化的代码令牌序列本身视为代码表示，并将其输入到模型训练过程中以学习代码的语义（Cambronero et al.,
    [2019](#bib.bib7); Yao et al., [2019](#bib.bib95); Zhao and Sun, [2020](#bib.bib102);
    Ye et al., [2020](#bib.bib97); Feng et al., [2020](#bib.bib18); Ling et al., [2020](#bib.bib49);
    Huang et al., [2021](#bib.bib34); Lachaux et al., [2021](#bib.bib42); Du et al.,
    [2021](#bib.bib16); Salza et al., [2023](#bib.bib70); Arakelyan et al., [2022](#bib.bib3);
    Cai et al., [2023](#bib.bib6); Wang et al., [2022a](#bib.bib84); Chai et al.,
    [2022](#bib.bib9); Li et al., [2022a](#bib.bib45), [b](#bib.bib46), [d](#bib.bib44))。例如，基于Transformer的强大学习能力，Feng等人（Feng
    et al., [2020](#bib.bib18)）构建了CodeBERT，这是第一个大规模程序语言预训练模型。受BERT-based NLP的启发，他们直接将代码片段的令牌序列输入到多层Transformer中。这使得模型能够融入上下文信息并学习识别对代码语义至关重要的令牌。然而，通过标记化直接获取源代码的所有令牌忽略了语法细节，使得很难辨别一个术语是否来源于变量名或方法调用。为此，Du等人（Du
    et al., [2021](#bib.bib16)）从三个角度对代码片段进行数据增强：代码结构、变量名和API。他们构建了以结构为中心的数据集、以变量为中心的数据集和以API为中心的数据集，这些数据集分别输入模型进行训练。为了帮助模型学习在语义等效程序中不变的代码特征，Wang等人（Wang
    et al., [2022a](#bib.bib84)）开发了一种保持语义的代码片段转换。该转换保持代码的语义，但改变其词汇外观和语法结构。具体而言，他们修改了代码的控制结构、API和声明，以使模型能够提取和学习相关特征，同时保持代码的语义。基于转换的方法（如通过变量重命名生成语义等效的代码片段）通常会产生具有高度相似表面形式的代码，导致模型关注于表面级代码结构而非其语义信息。为了缓解这一问题，Li等人（Li
    et al., [2022b](#bib.bib46)）使用代码注释和抽象语法树子树构建了正样本，鼓励模型捕获语义信息。
- en: Multimodal Token Sequence (MTS). Code snippets have different information dimensions.
    A code token sequence only captures shallow features of source code, such as method
    names and code tokens, but ignores structural features like AST and CFG, which
    hold rich and well-defined source code semantics.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态令牌序列（MTS）。代码片段具有不同的信息维度。代码令牌序列只捕获源代码的浅层特征，如方法名称和代码令牌，但忽略了诸如AST和CFG等结构特征，这些特征包含丰富且明确定义的源代码语义。
- en: Multimodal learning aims to build models that can process and aggregate information
    from multiple modalities. Recently, many studies have attempted to utilize program
    analysis techniques to capture the structural and syntactic representation of
    programs. These works capture multiple code modalities to form complementary code
    representations (Haldar et al., [2020](#bib.bib27); Guo et al., [2021](#bib.bib26);
    Gu et al., [2021b](#bib.bib22), [a](#bib.bib21); Xu et al., [2021](#bib.bib92);
    Wang et al., [2021b](#bib.bib87), [2022c](#bib.bib88); Han et al., [2022](#bib.bib28);
    Niu et al., [2022](#bib.bib62); Guo et al., [2022](#bib.bib25)). For instance,
    Xu et al. (Xu et al., [2021](#bib.bib92)) extract AST from the method body as
    a structural feature and parse a code fragment into a syntax tree. The nodes in
    the tree represent various code types, such as loop structures, conditional judgment
    structures, method calls, and variable declarations. They traverse the AST through
    a breadth-first traversal strategy to obtain the AST node sequence, which they
    use for model training along with method names, API sequences, and code tokens.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态学习旨在构建能够处理和整合来自多个模态的信息的模型。最近，许多研究尝试利用程序分析技术来捕捉程序的结构和语法表示。这些工作捕捉了多种代码模态，以形成互补的代码表示（Haldar
    等，[2020](#bib.bib27)；Guo 等，[2021](#bib.bib26)；Gu 等，[2021b](#bib.bib22)，[a](#bib.bib21)；Xu
    等，[2021](#bib.bib92)；Wang 等，[2021b](#bib.bib87)，[2022c](#bib.bib88)；Han 等，[2022](#bib.bib28)；Niu
    等，[2022](#bib.bib62)；Guo 等，[2022](#bib.bib25)）。例如，Xu 等（Xu 等，[2021](#bib.bib92)）从方法体中提取抽象语法树（AST）作为结构特征，并将代码片段解析成语法树。树中的节点表示各种代码类型，如循环结构、条件判断结构、方法调用和变量声明。他们通过广度优先遍历策略遍历AST，以获得AST节点序列，并将其与方法名称、API序列和代码令牌一起用于模型训练。
- en: To enhance the semantic suitability of the AST tree structure for code search,
    Gu et al. (Gu et al., [2021a](#bib.bib21)) transform AST into Simplified Semantic
    Tree (SST). In contrast to AST, SST eliminates redundant nodes, enhances node
    labels, accentuates the semantic information of code snippets, and has broader
    applicability across diverse programming languages. Then they obtain tree-serialized
    representations from SST by sampling tree paths or traversing tree structures,
    which are used in multimodal learning to complement traditional source code token
    sequence representations. Similarly, Niu et al. (Niu et al., [2022](#bib.bib62))
    enrich the input representation of source code pre-trained models with simplified
    and linearized AST versions. To facilitate the transformer in encoding AST, Guo
    et al. (Guo et al., [2022](#bib.bib25)) propose a method for lossless serialization
    of AST. They transform AST into a sequential structure that maintains all tree
    information and use it as input to enhance the code representation. To provide
    complementary information for program semantic understanding, Guo et al. (Guo
    et al., [2021](#bib.bib26)) construct data flow graphs based on AST. Given a code
    fragment, they use a standard compiler to generate a AST, identify the variable
    sequence through the leaf nodes of the AST, and retain the source of each variable
    value to obtain the code’s data flow information. Compared to AST, the data flow
    information is lighter and does not bring redundant structures, making the model
    more efficient.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增强AST树结构在代码搜索中的语义适用性，Gu 等（Guo 等，[2021a](#bib.bib21)）将AST转化为简化语义树（SST）。与AST不同，SST消除了冗余节点，增强了节点标签，突出了代码片段的语义信息，并在不同编程语言中具有更广泛的适用性。然后，他们通过采样树路径或遍历树结构从SST中获得树序列化表示，这些表示在多模态学习中用于补充传统源代码令牌序列表示。类似地，Niu
    等（Niu 等，[2022](#bib.bib62)）用简化和线性化的AST版本丰富了源代码预训练模型的输入表示。为了便于转换器对AST进行编码，Guo 等（Guo
    等，[2022](#bib.bib25)）提出了一种AST无损序列化的方法。他们将AST转化为保持所有树信息的序列结构，并将其作为输入，以增强代码表示。为了提供程序语义理解的补充信息，Guo
    等（Guo 等，[2021](#bib.bib26)）基于AST构建数据流图。给定一个代码片段，他们使用标准编译器生成AST，通过AST的叶节点识别变量序列，并保留每个变量值的来源，以获得代码的数据流信息。与AST相比，数据流信息更轻量，不会带来冗余结构，使模型更加高效。
- en: Wang et al. (Wang et al., [2022c](#bib.bib88)) recognize that different views
    of code offer complementary semantics. They utilize the compiler to convert the
    program into multiple views, such as AST, CFG, and equivalent programs. AST provides
    the grammatical information of the code, CFG reveals the execution information
    of the code, and different variants of the same program offer the functional information
    of the code. They use a depth-first traversal to convert a AST into a sequence
    of AST tokens, and traverse a CFG along directed edges to parse it into a sequence
    of tokens. Finally, the model learns complementary information among multiple
    views under the framework of contrastive learning.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Wang 等人（Wang et al., [2022c](#bib.bib88)）认识到代码的不同视图提供了互补的语义。他们利用编译器将程序转换成多个视图，如
    AST、CFG 和等效程序。AST 提供了代码的语法信息，CFG 揭示了代码的执行信息，而相同程序的不同变体则提供了代码的功能信息。他们使用深度优先遍历将
    AST 转换为 AST 标记序列，并沿着有向边遍历 CFG 将其解析为标记序列。最终，模型在对比学习框架下学习多个视图之间的互补信息。
- en: '![Refer to caption](img/c248151fce727429220fe5f0c57063fa.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c248151fce727429220fe5f0c57063fa.png)'
- en: Figure 5. Extract feature tokens from code snippet.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5. 从代码片段中提取特征标记。
- en: 'Feature Token Sequence (FTS). Gu et al. (Gu et al., [2018](#bib.bib24)) propose
    CODEnn, the first deep learning-based supervised model for code search tasks.
    Considering that the source code is not plain text, they represent it from three
    aspects: method name, API call sequence, and code tokens, as shown in Figure [5](#S4.F5
    "Figure 5 ‣ 4.1.2\. Sequence ‣ 4.1\. Code Representation ‣ 4\. Code representation
    and vectorization (RQ2) ‣ Survey of Code Search Based on Deep Learning"). They
    encode each aspect separately and then combine them into a single vector to represent
    the entire code fragment. Sachdev et al. (Sachdev et al., [2018](#bib.bib69))
    assume that source code tokens contain enough natural language information. To
    represent code information at the method level, they construct a natural language
    document by extracting method names, method calls, enumerations, string constants,
    and comments. These methods generally follow the convention of not extracting
    variable names, which can vary from one software developer to another. Cheng and
    Kuang (Cheng and Kuang, [2022](#bib.bib13)) employ a comprehensive approach to
    represent code fragments by utilizing method name, API sequence, and code tokens.
    They effectively convert each type of feature into its respective n-gram vector
    using the embedding layer. Eventually, they intelligently concatenate the three
    distinct feature vectors, resulting in the acquisition of the final code fragment
    feature matrix.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 特征标记序列（FTS）。Gu 等人（Gu et al., [2018](#bib.bib24)）提出了 CODEnn，这是第一个基于深度学习的代码搜索任务的监督模型。考虑到源代码不是纯文本，他们从三个方面对其进行表示：方法名称、API
    调用序列和代码标记，如图 [5](#S4.F5 "Figure 5 ‣ 4.1.2\. Sequence ‣ 4.1\. Code Representation
    ‣ 4\. Code representation and vectorization (RQ2) ‣ Survey of Code Search Based
    on Deep Learning") 所示。他们分别对每个方面进行编码，然后将它们结合成一个单一的向量来表示整个代码片段。Sachdev 等人（Sachdev
    et al., [2018](#bib.bib69)）假设源代码标记包含足够的自然语言信息。为了在方法级别表示代码信息，他们通过提取方法名称、方法调用、枚举、字符串常量和注释构建自然语言文档。这些方法通常遵循不提取变量名称的惯例，因为变量名称可能因软件开发人员而异。Cheng
    和 Kuang（Cheng and Kuang, [2022](#bib.bib13)）采用一种综合方法通过利用方法名称、API 序列和代码标记来表示代码片段。他们有效地将每种特征类型转换为相应的
    n-gram 向量，最终智能地连接这三种不同的特征向量，获得最终的代码片段特征矩阵。
- en: 4.1.3\. Tree/Graph
  id: totrans-161
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.3\. 树/图
- en: Converting natural graph structures such as AST or CFG into sequences can result
    in loss of key structural information. To address this, some approaches try to
    directly use the graph structure as the code representation. Wan et al. (Wan et al.,
    [2019](#bib.bib79)) regard CFG as a directed graph and use Gated Graph Neural
    Network (GGNN) to obtain the vector representation of CFG. They define a graph
    as $\mathcal{G}=\{\mathcal{V},\mathcal{E}\}$, where $\mathcal{V}$ is a set of
    vertices $\left(v,\ell_{v}\right)$, $\mathcal{E}$ is a set of edges $\left(v_{i},v_{j},\ell_{e}\right)$,
    and $\ell_{v}$ and $\ell_{e}$ are the labels of vertices and edges, respectively.
    In the code retrieval scenario, each vertex represents a node in the CFG, and
    each edge signifies the control flow of the code.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 将自然图结构，如 AST 或 CFG，转换为序列可能会导致关键结构信息的丢失。为了解决这个问题，一些方法尝试直接使用图结构作为代码表示。Wan 等（Wan
    et al., [2019](#bib.bib79)）将 CFG 视为有向图，并使用门控图神经网络（GGNN）来获得 CFG 的向量表示。他们将图定义为 $\mathcal{G}=\{\mathcal{V},\mathcal{E}\}$，其中
    $\mathcal{V}$ 是一组顶点 $\left(v,\ell_{v}\right)$，$\mathcal{E}$ 是一组边 $\left(v_{i},v_{j},\ell_{e}\right)$，$\ell_{v}$
    和 $\ell_{e}$ 分别是顶点和边的标签。在代码检索场景中，每个顶点代表 CFG 中的一个节点，每条边表示代码的控制流。
- en: The code snippets with the same functionality may have different implementations,
    while the code snippets with different code semantics may have similar structural
    features. To achieve satisfactory results in code search, Zeng et al. (Zeng et al.,
    [2023](#bib.bib99)) aim to find a more precise representation for the source code.
    They address the limitations of structural feature-based code representation methods
    by incorporating data and control dependencies. This allows semantically similar
    codes to have similar representations. To achieve this, they analyze various types
    of LLVM IR instructions, integrate data dependencies and control dependencies
    into a graph, and build a Variable-based Flow Graph (VFG). The nodes in this graph
    can be variables, opcode, or tag identifier. Considering that excessive information
    can obstruct the model from learning the fine-grained relationship between source
    code and query, they optimize VFG to minimize noise during training. Finally,
    they feed the optimized graph into a GGNN with an attention mechanism to learn
    the vector representation of the code.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 具有相同功能的代码片段可能有不同的实现，而具有不同代码语义的代码片段可能具有类似的结构特征。为了在代码搜索中获得令人满意的结果，Zeng 等（Zeng
    et al., [2023](#bib.bib99)）旨在找到更精确的源代码表示。他们通过结合数据和控制依赖性来解决基于结构特征的代码表示方法的局限性。这使得语义上相似的代码可以具有类似的表示。为此，他们分析了各种类型的
    LLVM IR 指令，将数据依赖性和控制依赖性整合到一个图中，并构建了一个基于变量的流图（VFG）。该图中的节点可以是变量、操作码或标签标识符。考虑到过多的信息可能会阻碍模型学习源代码和查询之间的细粒度关系，他们优化了
    VFG 以最小化训练中的噪音。最后，他们将优化后的图输入到带有注意机制的 GGNN 中，以学习代码的向量表示。
- en: With the aim of aligning the semantics of query and code, Ling et al. (Ling
    et al., [2021](#bib.bib50)) represent query text and source code as a unified
    graph structure. The program graph is generated from the AST of a code fragment.
    The AST is represented as a tuple $\langle\mathbb{N},\mathbb{T},\mathbb{X},\Delta,\phi,s\rangle$,
    where $\mathbb{N}$ denotes a set of non-terminal nodes, $\mathbb{T}$ denotes a
    set of terminal nodes, $\mathbb{X}$ represents a set of values, $\Delta:\mathbb{N}\rightarrow(\mathbb{N}\cup\mathbb{T})^{*}$
    is a function that maps a non-terminal node to its child nodes, $\phi:\mathbb{T}\rightarrow\mathbb{X}$
    is a function that maps a terminal node to an associated value, and $s$ represents
    the root node. Specifically, the program graph is composed of syntactic nodes
    (terminal and non-terminal nodes in AST) and grammatical tokens (the corresponding
    values of terminal nodes in the source code). This graph uses various types of
    edges to model syntactic and semantic relationships between nodes and tokens,
    including Child edges to link syntactic nodes in the AST, NextToken edges to connect
    each syntactic token to its subsequent in the original code, and LastLexicalUse
    edges to associate identifiers with their nearest lexical usage in the code.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对齐查询和代码的语义，Ling 等人（Ling et al., [2021](#bib.bib50)）将查询文本和源代码表示为统一的图结构。程序图是从代码片段的抽象语法树生成的。抽象语法树被表示为一个元组
    $\langle\mathbb{N},\mathbb{T},\mathbb{X},\Delta,\phi,s\rangle$，其中 $\mathbb{N}$
    表示非终结节点集合，$\mathbb{T}$ 表示终结节点集合，$\mathbb{X}$ 表示值的集合，$\Delta:\mathbb{N}\rightarrow(\mathbb{N}\cup\mathbb{T})^{*}$
    是一个将非终结节点映射到其子节点的函数，$\phi:\mathbb{T}\rightarrow\mathbb{X}$ 是一个将终结节点映射到相关值的函数，$s$
    表示根节点。具体来说，程序图由语法节点（抽象语法树中的终结节点和非终结节点）和语法标记（源代码中终结节点的相应值）组成。该图使用各种类型的边来建模节点和标记之间的语法和语义关系，包括**Child**
    边来连接抽象语法树中的语法节点，**NextToken** 边来将每个语法标记连接到其在原始代码中的后续标记，以及**LastLexicalUse** 边来将标识符与代码中最近的词法使用相关联。
- en: 4.2\. Code Vectorization
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2. **代码向量化**
- en: 'Once the code representation is obtained, we can embed it in a vector space.
    The choice of network architecture for encoding depends on the type of code representation
    (such as source code tokens or AST) and data structure (such as AST sequences
    or graphs). The deep neural network exhibits its excellent performance in this
    process. In this section, the code embedding network based on deep learning is
    divided into five categories: Word Embedding, Recurrent Neural Network (RNN),
    Graph Neural Network (GNN), Transformer, and mixed mode. These will be discussed
    in details below.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获取了代码表示，我们可以将其嵌入到向量空间中。编码的网络架构选择取决于代码表示的类型（如源代码标记或抽象语法树）和数据结构（如抽象语法树序列或图）。在这个过程中，深度神经网络展示了其卓越的性能。在本节中，基于深度学习的代码嵌入网络被分为五类：**词嵌入**、**递归神经网络**（RNN）、**图神经网络**（GNN）、**变换器**和**混合模式**。这些将在下面详细讨论。
- en: 4.2.1\. Based on Word Embedding
  id: totrans-167
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1. 基于**词嵌入**
- en: 'code2vec (Alon et al., [2019](#bib.bib2)) is a seminal work in the field of
    code understanding, which realizes the representation of a code snippet as a single
    fixed-length code vector. These vectors serve as powerful tools to predict the
    semantic properties of the code snippet. Prior to this, the traditional word embedding
    algorithms include Word2Vec and GloVe. Word2Vec employs a two-layer dense neural
    network to calculate the vector representation of words. It can be trained unsupervisedly
    on large corpora, ensuring that words with common context are closely located
    in the vector space. FastText, a variant of Word2Vec, enhances word vectors with
    subword information and was once popular among researchers for code vectorization
    (Sachdev et al., [2018](#bib.bib69); Cambronero et al., [2019](#bib.bib7); Ling
    et al., [2020](#bib.bib49)). Saksham et al. (Sachdev et al., [2018](#bib.bib69))
    extract five types of information from each method: namely method name, method
    call, enumeration, string constant, and comment, to obtain the token sequence
    $c=\left\{c_{1},\ldots,c_{n}\right\}$ in the source code. Then they utilize FastText
    to calculate the vector representation of the extracted tokens sequence and obtain
    the embedding matrix $T\in\mathbb{R}^{\left|V_{c}\right|\times d}$, where $\left|V_{c}\right|$
    is the size of the extracted code vocabulary, $d$ is the dimension of selected
    token embedding, and the $k$-th row in $T$ is the vector representation of the
    $k$-th extracted word in $V_{c}$, corresponding to the set of embedding vectors
    $\left\{T\left[c_{1}\right],\ldots,T\left[c_{n}\right]\right\}$ of the code. To
    combine a set of embedding vectors of code tokens into a single vector, they apply
    a weighted sum using TF-IDF weights. TF-IDF weights are designed to enhance the
    importance of tokens that frequently appear in code snippets, and reduce the weight
    of tokens that are commonly used across all codebases. When searching for code,
    they use $T$ to calculate the embedding vector $\left\{T\left[q_{1}\right],\ldots,T\left[q_{m}\right]\right\}$
    of a given query $q=\left\{q_{1},\ldots,q_{m}\right\}$, take its average value
    to obtain the final query vector $e_{q}$, and then use FAISS to calculate the
    distance between $e_{c}$ and $e_{q}$, representing the relevance of the code fragment
    to the given query. In the second year, they further optimize the code vectorization
    process by using supervised learning to update the token matrix $T$ obtained from
    FastText and replacing the TF-IDF weight of the merged token embedding with an
    attention-based scheme (Cambronero et al., [2019](#bib.bib7)). The attention weight
    $a_{c}\in\mathbb{R}^{d}$ is a $d$-dimensional vector learned during training.
    For the code token embedding vector $\left\{T\left[c_{1}\right],\ldots,T\left[c_{n}\right]\right\}$,
    the attention weight of each token is calculated as follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: code2vec (Alon et al., [2019](#bib.bib2)) 是代码理解领域的开创性工作，它实现了将代码片段表示为单个固定长度的代码向量。这些向量作为预测代码片段语义属性的强大工具。在此之前，传统的词嵌入算法包括
    Word2Vec 和 GloVe。Word2Vec 采用两层密集神经网络来计算单词的向量表示。它可以在大型语料库上进行无监督训练，确保具有相似上下文的单词在向量空间中紧密相邻。FastText
    是 Word2Vec 的一个变体，通过子词信息增强了词向量，曾在代码向量化研究中广受欢迎（Sachdev et al., [2018](#bib.bib69);
    Cambronero et al., [2019](#bib.bib7); Ling et al., [2020](#bib.bib49)）。Saksham
    等（Sachdev et al., [2018](#bib.bib69)）从每种方法中提取五种类型的信息：即方法名、方法调用、枚举、字符串常量和注释，以获得源代码中的标记序列
    $c=\left\{c_{1},\ldots,c_{n}\right\}$。然后，他们利用 FastText 计算提取的标记序列的向量表示，并获得嵌入矩阵
    $T\in\mathbb{R}^{\left|V_{c}\right|\times d}$，其中 $\left|V_{c}\right|$ 是提取的代码词汇表的大小，$d$
    是选定标记嵌入的维度，而 $T$ 中第 $k$ 行是 $V_{c}$ 中第 $k$ 个提取单词的向量表示，对应于代码的嵌入向量集合 $\left\{T\left[c_{1}\right],\ldots,T\left[c_{n}\right]\right\}$。为了将一组代码标记的嵌入向量合并为单个向量，他们应用了加权和，使用
    TF-IDF 权重。TF-IDF 权重旨在增强在代码片段中频繁出现的标记的重要性，并减少在所有代码库中常见的标记的权重。在搜索代码时，他们使用 $T$ 计算给定查询
    $q=\left\{q_{1},\ldots,q_{m}\right\}$ 的嵌入向量 $\left\{T\left[q_{1}\right],\ldots,T\left[q_{m}\right]\right\}$，取其平均值以获得最终查询向量
    $e_{q}$，然后使用 FAISS 计算 $e_{c}$ 和 $e_{q}$ 之间的距离，表示代码片段与给定查询的相关性。在第二年，他们通过使用监督学习来更新从
    FastText 获得的标记矩阵 $T$ 并用基于注意力的方案替代合并标记嵌入的 TF-IDF 权重，进一步优化了代码向量化过程（Cambronero et
    al., [2019](#bib.bib7)）。注意力权重 $a_{c}\in\mathbb{R}^{d}$ 是在训练过程中学习的 $d$ 维向量。对于代码标记嵌入向量
    $\left\{T\left[c_{1}\right],\ldots,T\left[c_{n}\right]\right\}$，每个标记的注意力权重计算如下：
- en: '| (1) |  | $\alpha_{i}=\frac{\exp\left(a_{c}\cdot T\left[c_{i}\right]^{\top}\right)}{\sum_{i=1}^{n}\exp\left(a_{c}\cdot
    T\left[c_{i}\right]^{\top}\right)}.$ |  |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| (1) |  | $\alpha_{i}=\frac{\exp\left(a_{c}\cdot T\left[c_{i}\right]^{\top}\right)}{\sum_{i=1}^{n}\exp\left(a_{c}\cdot
    T\left[c_{i}\right]^{\top}\right)}.$ |  |'
- en: 'Finally, the code’s embedding vector is obtained by weighted summation of the
    attention weight $\alpha_{i}$:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，代码的嵌入向量通过加权求和注意力权重$\alpha_{i}$获得：
- en: '| (2) |  | $e_{c}=\sum_{i=1}^{n}\alpha_{i}T\left[c_{i}\right].$ |  |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| (2) |  | $e_{c}=\sum_{i=1}^{n}\alpha_{i}T\left[c_{i}\right].$ |  |'
- en: 4.2.2\. Based on Recurrent Neural Networks
  id: totrans-172
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2\. 基于循环神经网络
- en: 'Recurrent Neural Networks (RNNs) are widely used for embedding sequences in
    natural language processing. Inspired by natural language processing techniques,
    some researchers have attempted to use RNN to encode code token sequences. For
    instance, Gu et al. (Gu et al., [2018](#bib.bib24)) extract method names, API
    call sequences, and tokens from code snippets, represented as $C=[M,A,\Gamma]$,
    where $M=w_{1},\ldots,w_{N_{M}}$ is a sequence of $N_{M}$ tokens obtained by dividing
    the method name with camel case, $A=a_{1},\ldots,a_{N_{A}}$ is a sequence of $N_{A}$
    consecutive API calls, and $\Gamma=\left\{\tau_{1},\ldots,\tau_{N_{\Gamma}}\right\}$
    is a collection of tokens in code fragments. They then encode the method name
    sequence and the API sequence separately using an RNN with a max-pooling layer.
    Since the tokens do not have a strict order in the source code, they are encoded
    using a multi-layer perceptron. Finally, the three vectors are combined into a
    single vector $c$, representing the entire code snippet:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 循环神经网络（RNNs）广泛用于自然语言处理中的序列嵌入。受到自然语言处理技术的启发，一些研究人员尝试使用RNN对代码标记序列进行编码。例如，Gu等人（Gu
    et al., [2018](#bib.bib24)）从代码片段中提取方法名称、API调用序列和标记，表示为$C=[M,A,\Gamma]$，其中$M=w_{1},\ldots,w_{N_{M}}$是通过驼峰式命名划分的$N_{M}$个标记的序列，$A=a_{1},\ldots,a_{N_{A}}$是$N_{A}$个连续的API调用序列，$\Gamma=\left\{\tau_{1},\ldots,\tau_{N_{\Gamma}}\right\}$是代码片段中的标记集合。他们然后使用带有最大池化层的RNN分别对方法名称序列和API序列进行编码。由于标记在源代码中没有严格的顺序，它们通过多层感知机进行编码。最后，将三个向量组合成一个表示整个代码片段的向量$c$：
- en: '| (3) |  | $c={LSTM}_{1}(M)+{LSTM}_{2}(A)+{MLP}(\Gamma).$ |  |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| (3) |  | $c={LSTM}_{1}(M)+{LSTM}_{2}(A)+{MLP}(\Gamma).$ |  |'
- en: 'Sun et al. (Sun et al., [2022a](#bib.bib76)) translate the code into a natural
    language description to obtain a translation, and apply the LSTM architecture
    to build a translation encoder. They use word embedding to map words in the translation
    sequence, $s=w_{1},\cdots,w_{N^{s}}$, to vector representations $\boldsymbol{w}_{i}=\psi\left(w_{i}\right)$.
    These vectors are then arranged in an embedding matrix $E\in\mathbb{R}^{n\times
    m}$, where $n$ is the size of the vocabulary, $m$ is the dimension of the embedding
    vector. The embedding matrix $E=\left(\psi\left(w_{1}\right),\ldots,\psi\left(w_{i}\right)\right)^{T}$
    is randomly initialized and learned together with the encoder during training.
    The translation’s vector representation $v^{s}$ is obtained from the embedding
    matrix and inputted into the translation encoder to obtain the final embedding
    vector $e^{s}$. The hidden state $h_{i}^{s}$ for the $i$-th word in $s$ is calculated
    as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Sun等人（Sun et al., [2022a](#bib.bib76)）将代码转换为自然语言描述以获得翻译，并应用LSTM架构构建翻译编码器。他们使用词嵌入将翻译序列中的词，$s=w_{1},\cdots,w_{N^{s}}$，映射为向量表示$\boldsymbol{w}_{i}=\psi\left(w_{i}\right)$。这些向量然后排列在嵌入矩阵$E\in\mathbb{R}^{n\times
    m}$中，其中$n$是词汇表的大小，$m$是嵌入向量的维度。嵌入矩阵$E=\left(\psi\left(w_{1}\right),\ldots,\psi\left(w_{i}\right)\right)^{T}$在训练过程中与编码器一起随机初始化并学习。翻译的向量表示$v^{s}$从嵌入矩阵中获得，并输入到翻译编码器中以获得最终的嵌入向量$e^{s}$。$s$中第$i$个词的隐藏状态$h_{i}^{s}$计算如下：
- en: '| (4) |  | $h_{i}^{s}={LSTM}\left(h_{i-1}^{s},\boldsymbol{w}_{i}\right).$ |  |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| (4) |  | $h_{i}^{s}={LSTM}\left(h_{i-1}^{s},\boldsymbol{w}_{i}\right).$ |  |'
- en: 'In addition, they also employ an attention mechanism to alleviate the long
    dependency problem in long text sequences. The attention weight for each word
    is calculated as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，他们还采用了注意力机制以缓解长文本序列中的长依赖问题。每个词的注意力权重计算如下：
- en: '| (5) |  | $\alpha_{i}^{s}=\frac{\exp\left(f\left(h_{i}^{s}\right)\cdot u^{s}\right)}{\sum_{j=1}^{N}\exp\left(f\left(h_{j}^{s}\right)\cdot
    u^{s}\right)},$ |  |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| (5) |  | $\alpha_{i}^{s}=\frac{\exp\left(f\left(h_{i}^{s}\right)\cdot u^{s}\right)}{\sum_{j=1}^{N}\exp\left(f\left(h_{j}^{s}\right)\cdot
    u^{s}\right)},$ |  |'
- en: 'where $f(\cdot)$ represents the linear layer; $u^{s}$ represents the context
    vector, which is the high-level representation of all words in $s$. $\cdot$ represents
    the inner product of $h_{i}^{s}$ and $u^{s}$. $u^{s}$ is randomly initialized
    and jointly learned during training. The final embedding representation $e^{s}$
    of $s$ is computed as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $f(\cdot)$ 表示线性层；$u^{s}$ 表示上下文向量，它是 $s$ 中所有单词的高级表示。$\cdot$ 表示 $h_{i}^{s}$
    和 $u^{s}$ 的内积。$u^{s}$ 是随机初始化的，并在训练过程中共同学习。$s$ 的最终嵌入表示 $e^{s}$ 计算如下：
- en: '| (6) |  | $e^{s}=\sum_{j=1}^{N^{s}}\alpha_{i}^{s}\cdot h_{i}^{s}.$ |  |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| (6) |  | $e^{s}=\sum_{j=1}^{N^{s}}\alpha_{i}^{s}\cdot h_{i}^{s}.$ |  |'
- en: 4.2.3\. Based on Graph Neural Networks
  id: totrans-181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.3\. 基于图神经网络
- en: As mentioned earlier, the code can be represented as a graph structure. This
    representation is superior to a sequence representation as it retains more information
    about the code. Some approaches use Graph Neural Networks (GNNs) to encode the
    graph structure, which is constructed based on structures such as AST and CFG
    (Zeng et al., [2023](#bib.bib99); Ling et al., [2021](#bib.bib50); Liu et al.,
    [2023](#bib.bib53)).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，代码可以表示为图结构。这种表示优于序列表示，因为它保留了更多关于代码的信息。一些方法使用图神经网络（GNN）来编码基于 AST 和 CFG 等结构构建的图结构（曾等人，[2023](#bib.bib99)；Ling
    等人，[2021](#bib.bib50)；刘等人，[2023](#bib.bib53)）。
- en: 'Zeng et al. (Zeng et al., [2023](#bib.bib99)) construct a variable-based flow
    graph (VFG) based on the data dependencies and control dependencies of the source
    code. VFG is a directed graph with multiple types of edges, represented as $G=(V,E)$.
    They then use a GGNN model, which is well suited for handling graph-structured
    data, to learn the vector representation of code. Here, $V$ represents a set of
    nodes $\left(v,l_{v}\right)$, $E$ represents a set of edges $\left(v_{i},v_{j},l_{\left(v_{i},v_{j}\right)}\right)$,
    and $l_{v}$ represents the label of node $v$, which consists of variables in the
    IR instruction. $l_{\left(v_{i},v_{j}\right)}$ represents the label of the edge
    from $v_{i}$ to $v_{j}$, including data dependency and control dependency. GGNN
    learns the vector representation of $G$ through the message passing mechanism.
    In each iteration, each node $v_{i}$ receives a message $m_{t}^{v_{j}\mapsto v_{j}}=W_{l_{\left(v_{i},v_{j}\right)}}h_{v_{j}}^{t-1}$
    from its neighbor $v_{j}$, which is determined by the type of edge between them.
    GGNN then aggregates all messages $m_{t}^{i}=\sum_{v_{j}\in{Neibour}\left(v_{i}\right)}\left(m_{t}^{v_{j}\mapsto
    v_{i}}\right)$ from neighbors of $v_{i}$, and updates the embedding $h_{v_{i}}^{t}=GRU\left(m_{t}^{i},h_{v_{i}}^{t-1}\right)$
    of each node $v_{i}$ using GRU. Considering that different nodes contribute differently
    to code semantics, they use an attention mechanism to calculate the importance
    of different nodes:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 曾等人（Zeng et al., [2023](#bib.bib99)）基于源代码的数据依赖和控制依赖构建了一个基于变量的流图（VFG）。VFG 是一个具有多种边类型的有向图，表示为
    $G=(V,E)$。他们随后使用适合处理图结构数据的 GGNN 模型来学习代码的向量表示。在这里，$V$ 表示节点集合 $\left(v,l_{v}\right)$，$E$
    表示边集合 $\left(v_{i},v_{j},l_{\left(v_{i},v_{j}\right)}\right)$，$l_{v}$ 表示节点 $v$
    的标签，它由 IR 指令中的变量组成。$l_{\left(v_{i},v_{j}\right)}$ 表示从 $v_{i}$ 到 $v_{j}$ 的边的标签，包括数据依赖和控制依赖。GGNN
    通过消息传递机制学习 $G$ 的向量表示。在每次迭代中，每个节点 $v_{i}$ 从其邻居 $v_{j}$ 接收消息 $m_{t}^{v_{j}\mapsto
    v_{j}}=W_{l_{\left(v_{i},v_{j}\right)}}h_{v_{j}}^{t-1}$，该消息由它们之间的边类型决定。GGNN 然后聚合所有来自
    $v_{i}$ 的邻居的消息 $m_{t}^{i}=\sum_{v_{j}\in{Neibour}\left(v_{i}\right)}\left(m_{t}^{v_{j}\mapsto
    v_{i}}\right)$，并使用 GRU 更新每个节点 $v_{i}$ 的嵌入 $h_{v_{i}}^{t}=GRU\left(m_{t}^{i},h_{v_{i}}^{t-1}\right)$。考虑到不同节点对代码语义的贡献不同，他们使用注意力机制来计算不同节点的重要性：
- en: '| (7) |  | $\alpha_{i}={sigmoid}\left(f\left(h_{v_{i}}\right)\cdot u_{vfg}\right),$
    |  |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| (7) |  | $\alpha_{i}={sigmoid}\left(f\left(h_{v_{i}}\right)\cdot u_{vfg}\right),$
    |  |'
- en: 'where $f(\cdot)$ is a linear layer and $u_{vfg}$ represents the context vector,
    which is a high-level representation of the entire nodes in the graph, learned
    together during training. The final embedding of the entire graph is expressed
    as:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $f(\cdot)$ 是一个线性层，$u_{vfg}$ 代表上下文向量，它是图中所有节点的高级表示，在训练过程中一起学习。整个图的最终嵌入表示为：
- en: '| (8) |  | $h_{vfg}=\sum_{v_{i}\in V}\left(\alpha_{i}h_{v_{i}}\right).$ |  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| (8) |  | $h_{vfg}=\sum_{v_{i}\in V}\left(\alpha_{i}h_{v_{i}}\right).$ |  |'
- en: 'Given that query text has sequence characteristics as a natural language, Zeng
    et al. (Zeng et al., [2023](#bib.bib99)) use LSTM to encode a query into a vector
    space and calculate its similarity with the code’s semantic vector. Different
    from this, Ling et al. (Ling et al., [2021](#bib.bib50)) design a unified graph
    structure for both query and code. They then use RGCN to encode text graph and
    code graph, which is a variant of GNN. Given a code graph $G_{e}=\left(\mathcal{V}_{e},\mathcal{E}_{e},\mathcal{R}_{e}\right)$,
    to calculate the updated embedding vector $\mathbf{e}_{i}$ of each node $e_{i}$
    in the code graph $G_{e}$, RGCN defines the propagation model as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于查询文本具有自然语言的序列特征，Zeng 等人（Zeng et al., [2023](#bib.bib99)）使用 LSTM 将查询编码为向量空间，并计算其与代码语义向量的相似度。与此不同，Ling
    等人（Ling et al., [2021](#bib.bib50)）为查询和代码设计了统一的图结构。然后，他们使用 RGCN 编码文本图和代码图，这是一种
    GNN 的变体。给定一个代码图 $G_{e}=\left(\mathcal{V}_{e},\mathcal{E}_{e},\mathcal{R}_{e}\right)$，为了计算代码图
    $G_{e}$ 中每个节点 $e_{i}$ 的更新嵌入向量 $\mathbf{e}_{i}$，RGCN 定义了以下传播模型：
- en: '| (9) |  | $\mathbf{e}_{i}^{(l+1)}={ReLU}\left(W_{\Theta}^{(l)}\mathbf{e}_{i}^{(l)}+\sum_{r\in\mathcal{R}_{e}}\sum_{j\in\mathcal{N}_{i}^{r}}\frac{1}{\left&#124;\mathcal{N}_{i}^{r}\right&#124;}W_{r}^{(l)}\mathbf{e}_{j}^{(l)}\right),$
    |  |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| (9) |  | $\mathbf{e}_{i}^{(l+1)}={ReLU}\left(W_{\Theta}^{(l)}\mathbf{e}_{i}^{(l)}+\sum_{r\in\mathcal{R}_{e}}\sum_{j\in\mathcal{N}_{i}^{r}}\frac{1}{\left|\mathcal{N}_{i}^{r}\right|}W_{r}^{(l)}\mathbf{e}_{j}^{(l)}\right),$
    |  |'
- en: where $\mathbf{e}_{i}^{(l+1)}$ represents the updated embedding vector of node
    $\mathbf{e}_{i}$ in the $(l+1)$th layer of RGCN, $\mathcal{R}_{e}$ represents
    a set of relations (that is, the types of edge), $\mathcal{N}_{i}^{r}$ is a set
    of neighbors of node $e_{i}$ under the edge type $r\in\mathcal{R}_{q}$, and $W_{\Theta}^{(l)}$
    and $W_{r}^{(l)}$ are the parameters that the RGCN model needs to learn. By encoding
    the graph structure of the code with the RGCN model, they obtain the node embedding
    $\mathbf{X}_{e}=\left\{\mathbf{e}_{j}\right\}_{j=1}^{N}\in\mathbb{R}^{(N,d)}$
    of the code graph. The embedding $\mathbf{X}_{q}=\left\{\mathbf{q}_{i}\right\}_{i=1}^{M}\in\mathbb{R}^{(M,d)}$
    of the query text graph can be obtained similarly.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\mathbf{e}_{i}^{(l+1)}$ 表示在 RGCN 的第 $(l+1)$ 层中节点 $\mathbf{e}_{i}$ 的更新嵌入向量，$\mathcal{R}_{e}$
    表示关系集（即边的类型），$\mathcal{N}_{i}^{r}$ 是在边类型 $r \in \mathcal{R}_{q}$ 下节点 $e_{i}$ 的邻居集合，$W_{\Theta}^{(l)}$
    和 $W_{r}^{(l)}$ 是 RGCN 模型需要学习的参数。通过使用 RGCN 模型对代码的图结构进行编码，他们获得了代码图的节点嵌入 $\mathbf{X}_{e}=\left\{\mathbf{e}_{j}\right\}_{j=1}^{N}\in\mathbb{R}^{(N,d)}$。查询文本图的嵌入
    $\mathbf{X}_{q}=\left\{\mathbf{q}_{i}\right\}_{i=1}^{M}\in\mathbb{R}^{(M,d)}$
    也可以类似地获得。
- en: 4.2.4\. Based on Transformers
  id: totrans-190
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.4\. 基于 Transformers
- en: In recent years, large pre-trained models have brought significant improvements
    to many NLP tasks. Many approaches train deep learning models on massive plain
    text data using self-supervised objectives, with the Transformer neural network
    architecture being the most prominent. Transformer contains multiple self-attention
    layers and can continuously learn in an end-to-end manner through gradient descent,
    because each of its components is differentiable. The success of pre-training
    models in NLP has inspired researchers to create code understanding pre-training
    models based on transformers, driving the growth of code intelligence.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型预训练模型在许多 NLP 任务中带来了显著的改进。许多方法利用自监督目标在大量的纯文本数据上训练深度学习模型，其中 Transformer
    神经网络架构最为突出。Transformer 包含多个自注意力层，并能够通过梯度下降以端到端的方式不断学习，因为它的每个组件都是可微分的。预训练模型在 NLP
    中的成功激发了研究人员创建基于 Transformer 的代码理解预训练模型，从而推动了代码智能的发展。
- en: Feng et al. (Feng et al., [2020](#bib.bib18)) propose CodeBERT, the first large-scale
    natural language-programming language pre-training model for multiple programming
    languages. During pre-training, they use special tokens to splice natural language
    text sequences and code token sequences, which are fed into a multi-layer Transformer-based
    CodeBERT. The model learns the semantic relationship between natural language
    and programming language through Masked Language Modeling (MLM) and Replaced Token
    Detection (RTD) tasks, ultimately yielding a general vector for code understanding
    tasks.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Feng 等人（Feng et al., [2020](#bib.bib18)）提出了 CodeBERT，这是第一个大规模自然语言-编程语言预训练模型，支持多种编程语言。在预训练过程中，他们使用特殊的标记将自然语言文本序列和代码标记序列拼接在一起，然后输入到多层
    Transformer 基于 CodeBERT 的模型中。该模型通过掩码语言建模（MLM）和替换标记检测（RTD）任务学习自然语言与编程语言之间的语义关系，最终生成一个通用的代码理解向量。
- en: Some methods aim to provide a more comprehensive understanding of code by feeding
    multiple modal representations of the source code into the Transformer. For instance,
    Guo et al. (Guo et al., [2021](#bib.bib26)) combine the sequence of variables
    extracted from the data flow graph with the sequence of code tokens, and feed
    both into the multi-layer transformer-based GraphCodeBERT. They then use Masked
    Language Modeling (MLM), Edge Prediction (EP) and Node Alignment (NA) tasks to
    guide the model to learn the code structure and data dependencies. Additionally,
    Guo et al. (Guo et al., [2022](#bib.bib25)) merge the serialized AST with the
    comment text sequence and feed both into the multi-layer Transformer-based UnixCoder.
    They then use Masked Language Modeling (MLM), Unidirectional Language Modeling
    (ULM), DeNoiSing (DNS), Multi-modal Contrastive Learning (MCL), and Cross-Modal
    Generation (CMG) to learn the syntactic information of the code and enhance the
    understanding of the code semantics. Wang et al. (Wang et al., [2022c](#bib.bib88))
    add not only the serialized AST, which reflects the grammatical information of
    the code, but also the CFG sequence, which reflects the logical information, and
    the token sequence of code fragments that have different implementation but the
    same semantics. All these are fed into the CODE-MVP. They then use Multi-View
    Contrastive Learning (MVCL), Fine-Grained Type Inference (FGTI), and Multi-View
    Masked Language Modeling (MMLM) tasks to help the model learn the structural information
    of the code.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 一些方法旨在通过将源代码的多种模态表示输入到Transformer中，提供对代码更全面的理解。例如，Guo等人（Guo et al., [2021](#bib.bib26)）将从数据流图中提取的变量序列与代码令牌序列相结合，并将这两者输入到多层Transformer基础的GraphCodeBERT中。他们然后使用**Masked
    Language Modeling (MLM)**、**Edge Prediction (EP)** 和 **Node Alignment (NA)** 任务来引导模型学习代码结构和数据依赖。此外，Guo等人（Guo
    et al., [2022](#bib.bib25)）将序列化的AST与评论文本序列合并，并将这两者输入到多层Transformer基础的UnixCoder中。他们然后使用**Masked
    Language Modeling (MLM)**、**Unidirectional Language Modeling (ULM)**、**DeNoiSing
    (DNS)**、**Multi-modal Contrastive Learning (MCL)** 和 **Cross-Modal Generation
    (CMG)** 来学习代码的句法信息并增强对代码语义的理解。Wang等人（Wang et al., [2022c](#bib.bib88)）不仅添加了反映代码语法信息的序列化AST，还添加了反映逻辑信息的CFG序列，以及具有不同实现但相同语义的代码片段的令牌序列。所有这些都被输入到**CODE-MVP**中。他们然后使用**Multi-View
    Contrastive Learning (MVCL)**、**Fine-Grained Type Inference (FGTI)** 和 **Multi-View
    Masked Language Modeling (MMLM)** 任务来帮助模型学习代码的结构信息。
- en: To ensure accurate code search results for each query, it’s essential for the
    model to make the query and correct code vectors as close as possible in the shared
    vector space, and as far away as possible from incorrect code vectors. To achieve
    this, some researchers integrate contrastive learning into the Transformer network
    architecture and enhance the performance of code search engines by constructing
    positive and negative samples. For instance, Huang et al. (Huang et al., [2021](#bib.bib34))
    form negative sample pairs by randomly selecting the query and code within the
    same batch. Meanwhile, they generate positive sample pairs by duplicating the
    query, meaning they rephrase the query without altering its semantics. Developers
    often split a complete comment over several lines to improve readability. Inspired
    by this, Li et al. (Li et al., [2022a](#bib.bib45)) combine consecutive comment
    lines into a single line to make the most of code snippets without comments to
    form positive sample pairs for contrastive learning. When multiple modalities
    of code are available, Wang et al. (Wang et al., [2021b](#bib.bib87)) combine
    different modalities to create positive sample pairs and use both in-batch and
    cross-batch sampling methods to generate negative sample pairs.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保每个查询的代码搜索结果的准确性，模型需要在共享向量空间中尽可能将查询向量与正确代码向量拉近，同时尽可能将其与错误代码向量拉远。为了实现这一点，一些研究人员将对比学习集成到Transformer网络架构中，并通过构造正负样本来提升代码搜索引擎的性能。例如，Huang等人（Huang
    et al., [2021](#bib.bib34)）通过随机选择同一批次中的查询和代码形成负样本对。同时，他们通过重复查询生成正样本对，即在不改变其语义的情况下重新措辞查询。开发人员通常将完整的评论分成几行以提高可读性。受到此启发，Li等人（Li
    et al., [2022a](#bib.bib45)）将连续的评论行合并成一行，以充分利用没有评论的代码片段形成对比学习的正样本对。当有多种代码模态可用时，Wang等人（Wang
    et al., [2021b](#bib.bib87)）将不同的模态结合起来创建正样本对，并使用批内和跨批次采样方法生成负样本对。
- en: Transformer is favored by researchers for its general and powerful modeling
    capabilities. To improve code semantic understanding, researchers have explored
    various pre-training tasks such as MLM, RTD, EP, and FGTI, etc. to guide model
    learning and enable the model to learn the grammatical and structural information
    of the code.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 因其通用而强大的建模能力受到研究人员的青睐。为了提高代码语义理解能力，研究人员探索了各种预训练任务，如 MLM、RTD、EP 和
    FGTI 等，以指导模型学习，并使模型能够学习代码的语法和结构信息。
- en: 4.2.5\. Mixed Mode
  id: totrans-196
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.5. 混合模式
- en: The structures used to represent different modes of the code may vary, and some
    methods choose the proper model to deal with each mode accordingly. For instance,
    Wan et al. (Wan et al., [2019](#bib.bib79)) extract AST and CFG as code representations,
    and propose Tree-LSTM for the tree structure of AST. Compared with the traditional
    LTSM unit, the Tree-LSTM unit contains multiple forgetting gates. For the directed
    graph structure of the CFG, they employ the Gated Graph Neural Network (GGNN)
    for encoding, and the Gated Recurrent Unit (GRU) for updating the hidden state
    of each vertex. Finally, they obtain the overall embedding vector of CFG by aggregating
    the embeddings of all vertices.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 用于表示代码不同模式的结构可能会有所不同，一些方法选择适当的模型来处理每种模式。例如，Wan 等人（Wan et al., [2019](#bib.bib79)）提取
    AST 和 CFG 作为代码表示，并提出了 Tree-LSTM 用于 AST 的树结构。与传统的 LSTM 单元相比，Tree-LSTM 单元包含多个遗忘门。对于
    CFG 的有向图结构，他们采用了门控图神经网络（GGNN）进行编码，并使用门控循环单元（GRU）来更新每个顶点的隐藏状态。最后，他们通过聚合所有顶点的嵌入向量来获得
    CFG 的整体嵌入向量。
- en: 4.3\. Interaction Between Code and Query
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3. 代码与查询之间的交互
- en: The existence of a semantic gap between natural language queries and code snippets
    has posed a significant challenge. However, several methods have emerged to bridge
    this gap by effectively modeling the interaction between the two, thus enhancing
    the understanding of their respective semantics (Haldar et al., [2020](#bib.bib27);
    Xu et al., [2021](#bib.bib92); Arakelyan et al., [2022](#bib.bib3); Cheng and
    Kuang, [2022](#bib.bib13); Cai et al., [2023](#bib.bib6)). For instance, leveraging
    the widely adopted approach of calculating the overall similarity between queries
    and code, Haldar et al. (Haldar et al., [2020](#bib.bib27)) additionally introduced
    the concept of evaluating local similarity between the two components. This perspective
    provides valuable insights into the finer-grained aspects of their correlation.
    Xu et al. (Xu et al., [2021](#bib.bib92)) proposed an innovative two-stage attention
    network architecture. In the initial stage, the semantics of both the query and
    the code are extracted. Subsequently, in the second stage, a joint attention mechanism
    is employed to facilitate the interaction between the two, enabling the capture
    of their semantic relevance. This approach presents a significant advancement
    in bridging the gap between natural language queries and code snippets. Similarly,
    Cheng and Kuang (Cheng and Kuang, [2022](#bib.bib13)) combined neural information
    retrieval (IR) and semantic matching to enhance the interaction between queries
    and code. Their approach involved capturing two matching signals simultaneously.
    Firstly, neural IR captured keyword matching signals, encompassing words, terms,
    and phrases, within query-code pairs. Secondly, semantic matching employed a joint
    attention mechanism to simultaneously focus on description attention and code
    attention, thereby acquiring comprehensive semantic vector representations for
    both components. Particularly, Arakelyan et al. (Arakelyan et al., [2022](#bib.bib3))
    proposed a meticulous approach wherein they parse the query by leveraging distinct
    part-of-speech roles to decompose it into concise semantic phrases. Specifically,
    nouns and noun phrases are associated with data entities within the code, while
    verbs depict operations or transformations performed on those entities. The interaction
    between the query and code is facilitated through an entity discovery module and
    an action module. The entity discovery module receives a string referencing a
    data entity and aims to identify code tokens that exhibit strong correlation with
    the given string. The output of this module is then employed as input for the
    action module, enabling prediction of the target entity object for the intended
    operational behavior. This comprehensive methodology offers valuable insights
    into enhancing the understanding and alignment between natural language queries
    and code snippets.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言查询与代码片段之间存在语义差距，这带来了显著的挑战。然而，几种方法已经出现，以有效建模二者之间的交互，从而增强对它们各自语义的理解（Haldar
    等，[2020](#bib.bib27)；Xu 等，[2021](#bib.bib92)；Arakelyan 等，[2022](#bib.bib3)；Cheng
    和 Kuang，[2022](#bib.bib13)；Cai 等，[2023](#bib.bib6)）。例如，Haldar 等（Haldar 等，[2020](#bib.bib27)）利用广泛采用的计算查询与代码之间整体相似度的方法，另外引入了评估二者局部相似度的概念。这一视角提供了对它们相关性的更细粒度的见解。Xu
    等（Xu 等，[2021](#bib.bib92)）提出了一种创新的两阶段注意力网络架构。在初始阶段，提取查询和代码的语义。随后，在第二阶段，采用联合注意力机制促进二者之间的交互，捕捉它们的语义相关性。这一方法在弥合自然语言查询与代码片段之间的差距方面取得了显著进展。类似地，Cheng
    和 Kuang（Cheng 和 Kuang，[2022](#bib.bib13)）结合了神经信息检索（IR）和语义匹配，以增强查询与代码之间的交互。他们的方法涉及同时捕捉两个匹配信号。首先，神经
    IR 捕捉关键词匹配信号，包括查询-代码对中的单词、术语和短语。其次，语义匹配采用联合注意力机制，同时关注描述注意力和代码注意力，从而获取两个组件的全面语义向量表示。特别地，Arakelyan
    等（Arakelyan 等，[2022](#bib.bib3)）提出了一种细致的方法，通过利用不同的词性角色解析查询，将其分解为简洁的语义短语。具体而言，名词和名词短语与代码中的数据实体相关联，而动词描述对这些实体执行的操作或变换。查询与代码之间的交互通过实体发现模块和动作模块来实现。实体发现模块接收一个引用数据实体的字符串，并旨在识别与该字符串具有强相关性的代码标记。该模块的输出作为动作模块的输入，预测目标实体对象的预期操作行为。这一全面的方法提供了有价值的见解，增强了自然语言查询与代码片段之间的理解和对齐。
- en: 4.4\. Summary
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4\. 总结
- en: 'Source code can be represented in various modes, including code token sequences,
    Abstract Syntax Trees (AST), Control Flow Graphs (CFG), Data Flow Graphs (DFG),
    and Program Transformation (PT). Code token sequences are commonly utilized for
    extracting textual features of the code, while AST and CFG are frequently employed
    for extracting the structural features of the code. As Table [4](#S4.T4 "Table
    4 ‣ 4.4\. Summary ‣ 4\. Code representation and vectorization (RQ2) ‣ Survey of
    Code Search Based on Deep Learning") demonstrates, the multiple modes of code
    are mainly fed into the network in two forms of data structures: sequence and
    graph. The information from these different modes can complement each other, enabling
    the model to fully grasp the semantic information of the code. Based on the type
    of input data structure, an appropriate sequence embedding model or graph embedding
    model is selected to obtain the code vector representation. As depicted in Figure
    5, the predominant choice for code representation is source code token sequence
    (STS), while Transformer architecture has emerged as the widely adopted code encoder
    of choice. Not all modalities will have equal impact on the final representation
    of the code. By aggregating embedding vectors from different modes of the source
    code, assigning attention weights, and taking the weighted sum, a more semantically
    rich code vector representation can be obtained. Furthermore, it is crucial to
    foster a fine-grained interaction between the query and code, facilitating a more
    robust learning of their intricate semantics.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码可以用多种模式表示，包括代码令牌序列、抽象语法树（AST）、控制流图（CFG）、数据流图（DFG）和程序变换（PT）。代码令牌序列通常用于提取代码的文本特征，而AST和CFG则常用于提取代码的结构特征。如表[4](#S4.T4
    "Table 4 ‣ 4.4\. Summary ‣ 4\. Code representation and vectorization (RQ2) ‣ Survey
    of Code Search Based on Deep Learning")所示，代码的多种模式主要以两种数据结构形式输入到网络中：序列和图。这些不同模式的信息可以相互补充，使模型能够充分理解代码的语义信息。根据输入数据结构的类型，选择适当的序列嵌入模型或图嵌入模型来获得代码的向量表示。如图5所示，代码表示的主要选择是源代码令牌序列（STS），而Transformer架构已经成为广泛采用的代码编码器选择。并非所有模态对代码的最终表示都有相同的影响。通过聚合来自不同模式的嵌入向量、分配注意力权重并进行加权求和，可以获得更具语义丰富的代码向量表示。此外，促进查询与代码之间的细粒度交互，有助于更强的学习其复杂的语义。
- en: Table 4. Overview of approaches for code representation and code vectorization.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 表4. 代码表示和代码向量化方法概述。
- en: '| Year | Work | Code Representation | Code Vectorization | Interaction |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| Year | Work | Code Representation | Code Vectorization | Interaction |'
- en: '| STS | MTS | FTS | Tree/Graph | Word Embedding | RNN | GNN | Transformer |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| STS | MTS | FTS | Tree/Graph | Word Embedding | RNN | GNN | Transformer |'
- en: '| 2018 | CODEnn (Gu et al., [2018](#bib.bib24)) |  |  | ✓ |  |  | ✓ |  |  |  |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | CODEnn (Gu et al., [2018](#bib.bib24)) |  |  | ✓ |  |  | ✓ |  |  |  |'
- en: '| 2018 | NCS (Sachdev et al., [2018](#bib.bib69)) |  |  | ✓ |  | ✓ |  |  |  |  |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | NCS (Sachdev et al., [2018](#bib.bib69)) |  |  | ✓ |  | ✓ |  |  |  |  |'
- en: '| 2019 | UNIF (Cambronero et al., [2019](#bib.bib7)) | ✓ |  |  |  | ✓ |  |  |  |  |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | UNIF (Cambronero et al., [2019](#bib.bib7)) | ✓ |  |  |  | ✓ |  |  |  |  |'
- en: '| 2019 | MMAN (Wan et al., [2019](#bib.bib79)) | ✓ |  |  | ✓ |  | ✓ | ✓ |  |  |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | MMAN (Wan et al., [2019](#bib.bib79)) | ✓ |  |  | ✓ |  | ✓ | ✓ |  |  |'
- en: '| 2019 | CoaCor (Yao et al., [2019](#bib.bib95)) | ✓ |  |  |  |  | ✓ |  |  |  |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | CoaCor (Yao et al., [2019](#bib.bib95)) | ✓ |  |  |  |  | ✓ |  |  |  |'
- en: '| 2020 | CodeBERT (Feng et al., [2020](#bib.bib18)) | ✓ |  |  |  |  |  |  |
    ✓ |  |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | CodeBERT (Feng et al., [2020](#bib.bib18)) | ✓ |  |  |  |  |  |  |
    ✓ |  |'
- en: '| 2020 | AdaCS (Ling et al., [2020](#bib.bib49)) | ✓ |  |  |  |  | ✓ |  |  |  |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | AdaCS (Ling et al., [2020](#bib.bib49)) | ✓ |  |  |  |  | ✓ |  |  |  |'
- en: '| 2020 | MP-CAT (Haldar et al., [2020](#bib.bib27)) |  | ✓ |  |  |  | ✓ |  |  |
    ✓ |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | MP-CAT (Haldar et al., [2020](#bib.bib27)) |  | ✓ |  |  |  | ✓ |  |  |
    ✓ |'
- en: '| 2020 | ${TranS}^{3}$ (Wang et al., [2020](#bib.bib86)) |  |  |  | ✓ |  |  |  |
    ✓ |  |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | ${TranS}^{3}$ (Wang et al., [2020](#bib.bib86)) |  |  |  | ✓ |  |  |  |
    ✓ |  |'
- en: '| 2020 | Zhao and Sun (Zhao and Sun, [2020](#bib.bib102)) | ✓ |  |  |  |  |
    ✓ |  |  |  |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | Zhao and Sun (Zhao and Sun, [2020](#bib.bib102)) | ✓ |  |  |  |  |
    ✓ |  |  |  |'
- en: '| 2020 | CO3 (Ye et al., [2020](#bib.bib97)) | ✓ |  |  |  |  | ✓ |  |  |  |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | CO3 (Ye et al., [2020](#bib.bib97)) | ✓ |  |  |  |  | ✓ |  |  |  |'
- en: '| 2021 | CRaDLe (Gu et al., [2021b](#bib.bib22)) |  | ✓ |  |  |  | ✓ |  |  |  |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | CRaDLe (Gu et al., [2021b](#bib.bib22)) |  | ✓ |  |  |  | ✓ |  |  |  |'
- en: '| 2021 | GraphCodeBERT (Guo et al., [2021](#bib.bib26)) |  | ✓ |  | ✓ |  |  |  |
    ✓ |  |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | GraphCodeBERT (Guo et al., [2021](#bib.bib26)) |  | ✓ |  | ✓ |  |  |  |
    ✓ |  |'
- en: '| 2021 | DGMS (Ling et al., [2021](#bib.bib50)) |  |  |  | ✓ |  |  | ✓ |  |  |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | DGMS (Ling et al., [2021](#bib.bib50)) |  |  |  | ✓ |  |  | ✓ |  |  |'
- en: '| 2021 | CoCLR (Huang et al., [2021](#bib.bib34)) | ✓ |  |  |  |  |  |  | ✓
    |  |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | CoCLR (Huang et al., [2021](#bib.bib34)) | ✓ |  |  |  |  |  |  | ✓
    |  |'
- en: '| 2021 | DOBF (Lachaux et al., [2021](#bib.bib42)) | ✓ |  |  |  |  |  |  |
    ✓ |  |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | DOBF (Lachaux et al., [2021](#bib.bib42)) | ✓ |  |  |  |  |  |  |
    ✓ |  |'
- en: '| 2021 | Gu et al. (Gu et al., [2021a](#bib.bib21)) |  | ✓ |  |  |  |  |  |
    ✓ |  |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | Gu et al. (Gu et al., [2021a](#bib.bib21)) |  | ✓ |  |  |  |  |  |
    ✓ |  |'
- en: '| 2021 | TabCS (Xu et al., [2021](#bib.bib92)) |  | ✓ |  |  |  |  |  | ✓ |
    ✓ |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | TabCS (Xu et al., [2021](#bib.bib92)) |  | ✓ |  |  |  |  |  | ✓ |
    ✓ |'
- en: '| 2021 | MuCoS (Du et al., [2021](#bib.bib16)) | ✓ |  |  |  |  |  |  | ✓ |  |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | MuCoS (Du et al., [2021](#bib.bib16)) | ✓ |  |  |  |  |  |  | ✓ |  |'
- en: '| 2021 | SynCoBERT (Wang et al., [2021b](#bib.bib87)) |  | ✓ |  |  |  |  |  |
    ✓ |  |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | SynCoBERT (Wang et al., [2021b](#bib.bib87)) |  | ✓ |  |  |  |  |  |
    ✓ |  |'
- en: '| 2022 | Salza et al. (Salza et al., [2023](#bib.bib70)) | ✓ |  |  |  |  |  |  |
    ✓ |  |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | Salza et al. (Salza et al., [2023](#bib.bib70)) | ✓ |  |  |  |  |  |  |
    ✓ |  |'
- en: '| 2022 | G2SC (Shi et al., [2022](#bib.bib71)) |  | ✓ |  |  |  | ✓ |  | ✓ |  |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | G2SC (Shi et al., [2022](#bib.bib71)) |  | ✓ |  |  |  | ✓ |  | ✓ |  |'
- en: '| 2022 | CSRS (Cheng and Kuang, [2022](#bib.bib13)) |  |  | ✓ |  | ✓ |  |  |  |
    ✓ |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CSRS (Cheng and Kuang, [2022](#bib.bib13)) |  |  | ✓ |  | ✓ |  |  |  |
    ✓ |'
- en: '| 2022 | TranCS (Sun et al., [2022a](#bib.bib76)) | ✓ |  |  |  |  | ✓ |  |  |  |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | TranCS (Sun et al., [2022a](#bib.bib76)) | ✓ |  |  |  |  | ✓ |  |  |  |'
- en: '| 2022 | Wang et al. (Wang et al., [2022a](#bib.bib84)) | ✓ |  |  |  |  |  |  |
    ✓ |  |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | Wang et al. (Wang et al., [2022a](#bib.bib84)) | ✓ |  |  |  |  |  |  |
    ✓ |  |'
- en: '| 2022 | ${NS}^{3}$ (Arakelyan et al., [2022](#bib.bib3)) | ✓ |  |  |  |  |  |  |
    ✓ | ✓ |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | ${NS}^{3}$ (Arakelyan et al., [2022](#bib.bib3)) | ✓ |  |  |  |  |  |  |
    ✓ | ✓ |'
- en: '| 2022 | CodeRetriever (Li et al., [2022a](#bib.bib45)) | ✓ |  |  |  |  |  |  |
    ✓ |  |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CodeRetriever (Li et al., [2022a](#bib.bib45)) | ✓ |  |  |  |  |  |  |
    ✓ |  |'
- en: '| 2022 | CDCS (Chai et al., [2022](#bib.bib9)) | ✓ |  |  |  |  |  |  | ✓ |  |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CDCS (Chai et al., [2022](#bib.bib9)) | ✓ |  |  |  |  |  |  | ✓ |  |'
- en: '| 2022 | CSSAM (Cai et al., [2023](#bib.bib6)) | ✓ |  |  | ✓ |  | ✓ | ✓ |  |
    ✓ |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CSSAM (Cai et al., [2023](#bib.bib6)) | ✓ |  |  | ✓ |  | ✓ | ✓ |  |
    ✓ |'
- en: '| 2022 | SCodeR (Li et al., [2022b](#bib.bib46)) | ✓ |  |  |  |  |  |  | ✓
    |  |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | SCodeR (Li et al., [2022b](#bib.bib46)) | ✓ |  |  |  |  |  |  | ✓
    |  |'
- en: '| 2022 | SPT-Code (Niu et al., [2022](#bib.bib62)) |  | ✓ |  |  |  |  |  |
    ✓ |  |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | SPT-Code (Niu et al., [2022](#bib.bib62)) |  | ✓ |  |  |  |  |  |
    ✓ |  |'
- en: '| 2022 | Li et al. (Li et al., [2022d](#bib.bib44)) | ✓ |  |  |  |  |  |  |
    ✓ |  |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | Li et al. (Li et al., [2022d](#bib.bib44)) | ✓ |  |  |  |  |  |  |
    ✓ |  |'
- en: '| 2022 | CTBERT (Han et al., [2022](#bib.bib28)) |  | ✓ |  |  |  |  |  | ✓
    |  |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CTBERT (Han et al., [2022](#bib.bib28)) |  | ✓ |  |  |  |  |  | ✓
    |  |'
- en: '| 2022 | CODE-MVP (Wang et al., [2022c](#bib.bib88)) |  | ✓ |  |  |  |  |  |
    ✓ |  |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CODE-MVP (Wang et al., [2022c](#bib.bib88)) |  | ✓ |  |  |  |  |  |
    ✓ |  |'
- en: '| 2022 | UniXcoder (Guo et al., [2022](#bib.bib25)) |  | ✓ |  |  |  |  |  |
    ✓ |  |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | UniXcoder (Guo et al., [2022](#bib.bib25)) |  | ✓ |  |  |  |  |  |
    ✓ |  |'
- en: '| 2023 | deGraphCS (Zeng et al., [2023](#bib.bib99)) |  |  |  | ✓ |  |  | ✓
    |  |  |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | deGraphCS (Zeng et al., [2023](#bib.bib99)) |  |  |  | ✓ |  |  | ✓
    |  |  |'
- en: '| 2023 | MulCS (Ma et al., [2023](#bib.bib57)) |  |  |  | ✓ |  |  | ✓ |  |  |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | MulCS (Ma et al., [2023](#bib.bib57)) |  |  |  | ✓ |  |  | ✓ |  |  |'
- en: '| 2023 | GraphSearchNet (Liu et al., [2023](#bib.bib53)) |  |  |  | ✓ |  |  |
    ✓ |  |  | ![Refer to caption](img/1c9810d15ace10937155ce4435486ef0.png)'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '| 2023 | GraphSearchNet (Liu et al., [2023](#bib.bib53)) |  |  |  | ✓ |  |  |
    ✓ |  |  | ![参考说明](img/1c9810d15ace10937155ce4435486ef0.png)'
- en: (a) Code representation
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 代码表示
- en: '![Refer to caption](img/abcf4941f39e9a298a479fedc7e8e362.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/abcf4941f39e9a298a479fedc7e8e362.png)'
- en: (b) Code vectorization
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 代码向量化
- en: Figure 6. Code representation and code vectorization.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6. 代码表示和代码向量化。
- en: '<svg   height="149.96" overflow="visible" version="1.1" width="600"><g transform="translate(0,149.96)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    width="556.69" height="122.4" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">Summary of answers to RQ2: • An array of diverse modalities, including
    Abstract Syntax Trees (AST), Data Flow Graphs (DFG), Control Flow Graphs (CFG),
    Program Trees (PT), and other code representations, can be leveraged to effectively
    augment the model’s ability to learn the intricate semantics of the code. • When
    feeding the code into the encoder, it is common practice to represent it as a
    sequence or a graph. Among these forms, the source code token sequence (STS) is
    the prevailing choice in most scenarios. • Transformer is the most popular code
    encoder in the past 6 years. • Facilitating a fine-grained interaction between
    the query and code can enhance the model’s ability to grasp their semantics.</foreignobject></g></g></svg>'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: <svg height="149.96" overflow="visible" version="1.1" width="600"><g transform="translate(0,149.96)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    width="556.69" height="122.4" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">RQ2的回答总结： • 可以利用多种不同的模态，包括抽象语法树（AST）、数据流图（DFG）、控制流图（CFG）、程序树（PT）及其他代码表示方式，有效增强模型学习代码复杂语义的能力。
    • 在将代码输入到编码器时，通常会将其表示为序列或图形。在这些形式中，源代码令牌序列（STS）在大多数情况下是首选。 • Transformer是过去6年中最受欢迎的代码编码器。
    • 促进查询与代码之间的细粒度交互可以提升模型掌握其语义的能力。</foreignobject></g></g></svg>
- en: 5\. Training Method (RQ3)
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 训练方法（RQ3）
- en: 'As previously stated, the core problem of code search based on deep learning
    is to employ a model $f_{\theta}(q,c)=E_{\theta_{1}}(q)\cdot E_{\theta_{2}}(c)$
    to estimate the relevance scores of query and code, and then sort according to
    the scores to obtain the code that matches the query. Sections 3 and 4 elaborate
    on the utilization of deep learning models to obtain representations for both
    the query and code. This section provides an overview of the existing techniques
    for training the model parameter $\theta$. The section is organized as follows:
    first, the pre-training technology of the Transformer-based large model relevant
    to code intelligence is introduced, encompassing three categories: sequence tasks,
    code structure tasks, and multimodal tasks. Second, the training of the code search
    model is described. Finally, alternative training methods for other scenarios,
    such as meta-learning and data enhancement, are introduced.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，基于深度学习的代码搜索的核心问题是使用模型 $f_{\theta}(q,c)=E_{\theta_{1}}(q)\cdot E_{\theta_{2}}(c)$
    来估计查询和代码的相关性分数，然后根据分数排序以获取与查询匹配的代码。第3节和第4节详细阐述了利用深度学习模型为查询和代码获得表示的方法。本节概述了现有的模型参数
    $\theta$ 的训练技术。该节组织如下：首先介绍与代码智能相关的基于Transformer的大型模型的预训练技术，包括三个类别：序列任务、代码结构任务和多模态任务。其次，描述了代码搜索模型的训练。最后，介绍了其他场景下的替代训练方法，如元学习和数据增强。
- en: 5.1\. Pre-training of Code Intelligence Large Models
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. 代码智能大型模型的预训练
- en: 'Encoding query and code using Transformer encoder is an important encoding
    strategy in code search tasks. Pre-trained Transformers have proven their effectiveness
    in many fields (Devlin et al., [2019](#bib.bib14); Liu et al., [2019b](#bib.bib54)).
    Large-scale pre-training enables the model to start from a better initial state,
    thereby facilitating efficient training and fine-tuning for downstream tasks.
    At present, there have been many works to introduce pre-training technology into
    the field of code intelligence, resulting in the design of various pre-training
    tasks. These tasks can be classified into three categories: sequence tasks, code
    structure tasks, and multi-modal matching tasks. Table [5](#S5.T5 "Table 5 ‣ 5.1\.
    Pre-training of Code Intelligence Large Models ‣ 5\. Training Method (RQ3) ‣ Survey
    of Code Search Based on Deep Learning") summarizes the approaches along these
    three dimensions. Sequence tasks treat the input as a sequence and train by using
    popular NLP tasks. Code structure tasks build upon sequences and utilize the relationships
    between tokens in a code structure graph for training. Multi-modal matching tasks
    try to introduce contrastive learning into pre-training, and use different modalities
    to construct matching positive samples.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Transformer 编码器对查询和代码进行编码是代码搜索任务中的一种重要编码策略。预训练的 Transformer 在许多领域（Devlin
    et al., [2019](#bib.bib14); Liu et al., [2019b](#bib.bib54)）中已证明其有效性。大规模的预训练使得模型从更好的初始状态开始，从而促进了下游任务的高效训练和微调。目前，已有许多工作将预训练技术引入代码智能领域，设计出了各种预训练任务。这些任务可以分为三类：序列任务、代码结构任务和多模态匹配任务。表
    [5](#S5.T5 "Table 5 ‣ 5.1\. Pre-training of Code Intelligence Large Models ‣ 5\.
    Training Method (RQ3) ‣ Survey of Code Search Based on Deep Learning") 总结了这三类任务的相关方法。序列任务将输入视为序列，通过流行的
    NLP 任务进行训练。代码结构任务在序列的基础上利用代码结构图中标记之间的关系进行训练。多模态匹配任务尝试将对比学习引入预训练，并使用不同的模态构建匹配正样本。
- en: Table 5. Overview of pre-training tasks.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5. 预训练任务概述。
- en: '| Year | Work | Sequence Tasks | Code Structure Tasks | Multimodal Matching
    Tasks |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| 年份 | 工作 | 序列任务 | 代码结构任务 | 多模态匹配任务 |'
- en: '| MLM | RTD | ULM | DNS | EP | IP | ICP | MMP | MCCL | CMG |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| MLM | RTD | ULM | DNS | EP | IP | ICP | MMP | MCCL | CMG |'
- en: '| 2020 | CodeBERT (Feng et al., [2020](#bib.bib18)) | ✓ | ✓ |  |  |  |  |  |  |  |  |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | CodeBERT (Feng et al., [2020](#bib.bib18)) | ✓ | ✓ |  |  |  |  |  |  |  |  |'
- en: '| 2021 | GraphCodeBERT (Guo et al., [2021](#bib.bib26)) | ✓ |  |  |  | ✓ |  |  |  |  |  |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | GraphCodeBERT (Guo et al., [2021](#bib.bib26)) | ✓ |  |  |  | ✓ |  |  |  |  |  |'
- en: '| 2021 | Syncobert (Wang et al., [2021b](#bib.bib87)) | ✓ |  |  |  | ✓ | ✓
    |  |  |  |  |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | Syncobert (Wang et al., [2021b](#bib.bib87)) | ✓ |  |  |  | ✓ | ✓
    |  |  |  |  |'
- en: '| 2022 | CODE-MVP (Wang et al., [2022c](#bib.bib88)) | ✓ |  |  |  |  | ✓ |  |  |  |  |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CODE-MVP (Wang et al., [2022c](#bib.bib88)) | ✓ |  |  |  |  | ✓ |  |  |  |  |'
- en: '| 2022 | CTBERT (Han et al., [2022](#bib.bib28)) |  |  |  |  | ✓ |  |  |  |  |  |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CTBERT (Han et al., [2022](#bib.bib28)) |  |  |  |  | ✓ |  |  |  |  |  |'
- en: '| 2022 | SPT-Code (Niu et al., [2022](#bib.bib62)) |  |  |  | ✓ |  |  | ✓ |
    ✓ |  |  |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | SPT-Code (Niu et al., [2022](#bib.bib62)) |  |  |  | ✓ |  |  | ✓ |
    ✓ |  |  |'
- en: '| 2022 | DOBF (Lachaux et al., [2021](#bib.bib42)) |  |  |  |  |  |  | ✓ |  |  |  |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | DOBF (Lachaux et al., [2021](#bib.bib42)) |  |  |  |  |  |  | ✓ |  |  |  |'
- en: '| 2022 | SCodeR (Li et al., [2022b](#bib.bib46)) |  |  |  |  |  |  |  |  |
    ✓ |  |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | SCodeR (Li et al., [2022b](#bib.bib46)) |  |  |  |  |  |  |  |  |
    ✓ |  |'
- en: '| 2022 | UniXcoder (Guo et al., [2022](#bib.bib25)) | ✓ |  | ✓ | ✓ |  |  |  |  |  |
    ✓ |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | UniXcoder (Guo et al., [2022](#bib.bib25)) | ✓ |  | ✓ | ✓ |  |  |  |  |  |
    ✓ |'
- en: 5.1.1\. Sequence Tasks
  id: totrans-264
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1\. 序列任务
- en: Sequences are the most straightforward and efficient way of representing code
    and text. Data structures like AST and CFG can be transformed into sequences through
    a serialization algorithm. There are many established pre-training tasks in NLP
    for encoding sequences in Transformer models, which can be directly introduced
    into code intelligence.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 序列是表示代码和文本最直接且有效的方式。像 AST 和 CFG 这样的数据结构可以通过序列化算法转换为序列。NLP 中有许多已建立的预训练任务用于在 Transformer
    模型中编码序列，这些任务可以直接引入到代码智能中。
- en: 'Masked Language Model (MLM) (Feng et al., [2020](#bib.bib18); Guo et al., [2021](#bib.bib26);
    Wang et al., [2021b](#bib.bib87); Guo et al., [2022](#bib.bib25); Wang et al.,
    [2022c](#bib.bib88)). Given a token sequence $X=\left\{[cls],x_{1},x_{2},\cdots\right.$
    $\left.,x_{N},[end]\right\}$, some tokens are randomly masked as $[mask]$ and
    a new token sequence is denoted as $X^{mask}=\left\{x_{1},x_{2},\cdots,[mask],\cdots,x_{N}\right\}$.
    $X^{mask}$ is input ted into the model, and the objective-task can restore the
    original tokens through the representation at the output layer. The loss function
    can be expressed as follows:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 掩码语言模型（MLM）（Feng 等人，[2020](#bib.bib18)；Guo 等人，[2021](#bib.bib26)；Wang 等人，[2021b](#bib.bib87)；Guo
    等人，[2022](#bib.bib25)；Wang 等人，[2022c](#bib.bib88)）。给定一个标记序列 $X=\left\{[cls],x_{1},x_{2},\cdots\right.$
    $\left.,x_{N},[end]\right\}$，一些标记被随机掩码为 $[mask]$，新的标记序列表示为 $X^{mask}=\left\{x_{1},x_{2},\cdots,[mask],\cdots,x_{N}\right\}$。将
    $X^{mask}$ 输入到模型中，目标任务可以通过输出层的表示恢复原始标记。损失函数可以表示如下：
- en: '| (10) |  | ${Loss}_{MLM}=-\sum_{i}\log p\left(x_{i}\mid X^{mask}\right).$
    |  |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| (10) |  | ${Loss}_{MLM}=-\sum_{i}\log p\left(x_{i}\mid X^{mask}\right).$
    |  |'
- en: MLM can be extended to the input of multiple modal splicing, that is, splicing
    query, code, and other modalities of code (such as flattened AST and CFG sequences).
    This results in a new sequence $X=\left\{[cls],x_{1}^{(1)},x_{2}^{(1)},\cdots,x_{N}^{(1)},[{sep}],x_{1}^{(2)},x_{2}^{(2)},\cdots,x_{M}^{(2)},[end]\right\}$,
    on which the MLM task is performed. In some literatures, this type of Masked Language
    Model that combines multiple modalities is referred to as Multi-Modal Masked Language
    Modeling (MMLM) (Wang et al., [2021b](#bib.bib87)).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: MLM 可以扩展到多模态拼接的输入，即拼接查询、代码和其他模态的代码（如扁平化的 AST 和 CFG 序列）。这会产生一个新的序列 $X=\left\{[cls],x_{1}^{(1)},x_{2}^{(1)},\cdots,x_{N}^{(1)},[{sep}],x_{1}^{(2)},x_{2}^{(2)},\cdots,x_{M}^{(2)},[end]\right\}$，在其上执行
    MLM 任务。在一些文献中，这种结合多种模态的掩码语言模型被称为多模态掩码语言建模（MMLM）（Wang 等人，[2021b](#bib.bib87)）。
- en: 'Replaced Token Detection (RTD) (Feng et al., [2020](#bib.bib18)). A token sequence
    is given, and some of its tokens are randomly replaced with others, creating a
    new token sequence, denoted as $X^{corrupt}=\left\{[cls],x_{1}^{\prime},x_{2}^{\prime},\cdots,\right.$
    $\left.x_{N}^{\prime},[end]\right\}$. The task makes predictions at the output
    layer regarding whether a token in $X^{corrupt}$ is a replacement token. The loss
    function can be expressed as follows:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 替换标记检测（RTD）（Feng 等人，[2020](#bib.bib18)）。给定一个标记序列，其中一些标记被随机替换为其他标记，创建一个新的标记序列，表示为
    $X^{corrupt}=\left\{[cls],x_{1}^{\prime},x_{2}^{\prime},\cdots,\right.$ $\left.x_{N}^{\prime},[end]\right\}$。任务是在输出层对
    $X^{corrupt}$ 中的标记是否为替换标记进行预测。损失函数可以表示如下：
- en: '| (11) |  | ${Loss}_{RTD}=-\sum_{i}\left(\delta(i)\log\left(i\mid X^{corrupt}\right)+(1-\delta(i))(1-\left.\log
    p\left(i\mid X^{corrupt}\right)\right)\right).$ |  |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| (11) |  | ${Loss}_{RTD}=-\sum_{i}\left(\delta(i)\log\left(i\mid X^{corrupt}\right)+(1-\delta(i))(1-\left.\log
    p\left(i\mid X^{corrupt}\right)\right)\right).$ |  |'
- en: When the token is not replaced (that is, $x_{i}^{\prime}=x_{i}$), $\delta(i)=1$,
    otherwise $\delta(i)=0$.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 当标记未被替换（即 $x_{i}^{\prime}=x_{i}$）时，$\delta(i)=1$，否则 $\delta(i)=0$。
- en: 'Unidirectional Language Modeling (ULM) (Guo et al., [2022](#bib.bib25)). ULM
    predicts the tokens in the sequence from start to end and is a widely used auxiliary
    task for training the Transformer decoder. In some models that train both the
    encoder and decoder (Guo et al., [2022](#bib.bib25)), ULM is selected to train
    the decoder. The loss function can be expressed as follows:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 单向语言建模（ULM）（Guo 等人，[2022](#bib.bib25)）。ULM 从头到尾预测序列中的标记，是训练 Transformer 解码器的广泛使用的辅助任务。在一些同时训练编码器和解码器的模型中（Guo
    等人，[2022](#bib.bib25)），选择 ULM 来训练解码器。损失函数可以表示如下：
- en: '| (12) |  | ${Loss}_{ULM}=-\sum_{i}\log p\left(x_{i}\mid X[<i]\right),$ |  |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| (12) |  | ${Loss}_{ULM}=-\sum_{i}\log p\left(x_{i}\mid X[<i]\right),$ |  |'
- en: where $X[<i]$ represents the tokens before the $i$-th token.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $X[<i]$ 表示第 $i$ 个标记之前的标记。
- en: 'DeNoiSing (DNS) (Guo et al., [2022](#bib.bib25); Niu et al., [2022](#bib.bib62)).
    The DeNoiSing pre-training objective uses $[mask_{i}]$ to mask multiple spans
    in the input tokens sequence to obtain $X^{mask}$, where $i$ represents the $i$-th
    masked span. All $X^{mask}$ are concatenated and represented as $Y=\left\{y_{1},y_{2},\cdots\right\}$.
    The corresponding output can be reconstructed through the encoder-decoder framework,
    and the objective function can be expressed as follows:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 去噪（DNS）（Guo 等人，[2022](#bib.bib25)；Niu 等人，[2022](#bib.bib62)）。去噪预训练目标使用 $[mask_{i}]$
    来掩码输入标记序列中的多个跨度，得到 $X^{mask}$，其中 $i$ 表示第 $i$ 个掩码跨度。所有 $X^{mask}$ 被拼接并表示为 $Y=\left\{y_{1},y_{2},\cdots\right\}$。可以通过编码器-解码器框架重建相应的输出，目标函数可以表示如下：
- en: '| (13) |  | ${Loss}_{DNS}=-\sum_{i}\log\left(y_{i}\mid X^{mask},Y[<i]\right).$
    |  |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| (13) |  | ${Loss}_{DNS}=-\sum_{i}\log\left(y_{i}\mid X^{mask},Y[<i]\right).$
    |  |'
- en: 5.1.2\. Code Structure Tasks
  id: totrans-277
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.2\. 代码结构任务
- en: The structured representation of code, such as AST and CFG, often holds a lot
    of information, such as the variable jump relationships, code execution order,
    etc. These information can be mined to design auxiliary tasks that aid in pre-training
    code intelligence models.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的结构化表示，如 AST 和 CFG，通常包含大量信息，例如变量跳转关系、代码执行顺序等。这些信息可以被挖掘出来，以设计辅助任务来帮助预训练代码智能模型。
- en: 'Edge Prediction (EP) (Guo et al., [2021](#bib.bib26); Wang et al., [2021b](#bib.bib87);
    Han et al., [2022](#bib.bib28)). When encoding structured code representations
    using a Transformer, it’s common to flatten it into a sequence $X=\left\{[cls],x_{1},x_{2},\cdots,x_{N},[end]\right\}$.
    After that, the connection relationship of the nodes in the original graph/tree
    can be inherited into the tokens sequence. For example, if node $i$ points to
    node $j$ in the original graph, then token $x_{i}$ and token $x_{j}$ will inherit
    this connection, allowing it to guide the model’s pre-training. The probability
    $p\left(e_{ij}\mid X\right)$ of whether there is an edge between two tokens is
    measured by the similarity of representations $\vec{e}_{i}$ and $\vec{e}_{j}$
    of $x_{i}$ and $x_{j}$, namely $<\vec{e}_{i},\vec{e}_{j}>$. The objective function
    of EP can be expressed as follows:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 边预测（EP）（Guo 等，[2021](#bib.bib26)；Wang 等，[2021b](#bib.bib87)；Han 等，[2022](#bib.bib28)）。在使用
    Transformer 对结构化代码表示进行编码时，通常将其展平为序列 $X=\left\{[cls],x_{1},x_{2},\cdots,x_{N},[end]\right\}$。之后，原始图/树中节点的连接关系可以继承到标记序列中。例如，如果节点
    $i$ 在原始图中指向节点 $j$，那么标记 $x_{i}$ 和标记 $x_{j}$ 将继承这种连接，从而引导模型的预训练。两个标记之间是否存在边的概率 $p\left(e_{ij}\mid
    X\right)$ 通过 $x_{i}$ 和 $x_{j}$ 的表示 $\vec{e}_{i}$ 和 $\vec{e}_{j}$ 的相似度来衡量，即 $<\vec{e}_{i},\vec{e}_{j}>$。EP
    的目标函数可以表示如下：
- en: '| (14) |  | ${Loss}_{EP}=-\sum_{ij}\left(\delta\left(e_{ij}\right)\log\left(e_{ij}\mid
    X\right)+\left(1-\delta\left(e_{ij}\right)\right)(1-\left.{logp}\left(e_{ij}\mid
    X\right)\right)\right).$ |  |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| (14) |  | ${Loss}_{EP}=-\sum_{ij}\left(\delta\left(e_{ij}\right)\log\left(e_{ij}\mid
    X\right)+\left(1-\delta\left(e_{ij}\right)\right)(1-\left.{logp}\left(e_{ij}\mid
    X\right)\right)\right).$ |  |'
- en: When there is an edge between token $x_{i}$ and token $x_{j}$, $\delta\left(e_{ij}\right)=1$,
    otherwise $\delta\left(e_{ij}\right)=0$. Besides single-modal structures, cross-modal
    structures can also be used to construct edges between tokens, for example, by
    combining code sequence tokens with data flow tokens. There is a correspondence
    between them, and edges can be constructed according to the corresponding relationship.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 当标记 $x_{i}$ 和标记 $x_{j}$ 之间存在边时，$\delta\left(e_{ij}\right)=1$，否则 $\delta\left(e_{ij}\right)=0$。除了单模态结构，还可以使用跨模态结构来构建标记之间的边，例如，通过将代码序列标记与数据流标记结合起来。它们之间存在对应关系，可以根据该对应关系构建边。
- en: 'Identifier Prediction (IP) (Wang et al., [2022c](#bib.bib88), [2021b](#bib.bib87)).
    The tokens in the code snippet can be classified into two types: identifiers (such
    as variable and function names, etc.) and non-identifiers (keywords that indicate
    grammatical operations). This classification can be performed through AST-based
    code analysis. The information helps construct auxiliary tasks to determine whether
    a token is an identifier. The probability $p(i\mid X)$ that a token is an identifier
    can be predicted based on its representation through a simple transformation,
    namely $\sigma\left(\vec{w}^{T}\cdot\vec{e}_{i}\right)$, where $\sigma$ is a sigmoid
    function that maps the score to 0-1. The objective function of IP can be expressed
    as follows:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 标识符预测（IP）（Wang 等，[2022c](#bib.bib88)，[2021b](#bib.bib87)）。代码片段中的标记可以分为两类：标识符（例如变量和函数名等）和非标识符（指示语法操作的关键字）。这种分类可以通过基于
    AST 的代码分析来进行。这些信息有助于构建辅助任务，以确定标记是否为标识符。标记是标识符的概率 $p(i\mid X)$ 可以通过一个简单的变换来预测，即
    $\sigma\left(\vec{w}^{T}\cdot\vec{e}_{i}\right)$，其中 $\sigma$ 是一个将分数映射到 0-1 的 sigmoid
    函数。IP 的目标函数可以表示如下：
- en: '| (15) |  | ${Loss}_{IP}=-\sum_{i}(\delta(i)\log p(i\mid X)+(1-\delta(i))(1-\log
    p(i\mid X))).$ |  |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| (15) |  | ${Loss}_{IP}=-\sum_{i}(\delta(i)\log p(i\mid X)+(1-\delta(i))(1-\log
    p(i\mid X))).$ |  |'
- en: If the node is an identifier, $\delta(i)=1$; otherwise $\delta(i)=0$.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 如果节点是标识符，则 $\delta(i)=1$；否则 $\delta(i)=0$。
- en: 'Identifier Content Prediction (ICP) (Lachaux et al., [2021](#bib.bib42); Niu
    et al., [2022](#bib.bib62)). Identifiers such as function names and variable names
    carry significant information that can be considered as a general expression of
    functions. To allow the model to learn this high-level semantic information, the
    following proxy tasks can be designed: masking the identifier as $[mask]$, and
    predicting the masked content. Compared to randomly masking tokens, accurately
    masking identifiers by analyzing the code structure increases the difficulty of
    the task and makes the model learn higher-level information. When masking identifiers,
    to avoid the model dependence on the same variable name appearing in the context
    for inference, all the same tokens can be replaced by $[mask_{i}]$ at the same
    time, where $i$ represents the $i$-th replaced identifier. When actually designing
    the training task, $[mask_{i}]$ can be connected to the masked token. All masked
    information is concatenated as output and then the model is trained using the
    encoder-decoder framework. The corresponding objective function can be expressed
    as follows:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 标识符内容预测（ICP）（Lachaux 等，[2021](#bib.bib42)；Niu 等，[2022](#bib.bib62)）。标识符，如函数名称和变量名称，携带着重要信息，可以看作是函数的一种通用表达。为了让模型学习这些高级语义信息，可以设计以下代理任务：将标识符掩蔽为
    $[mask]$，并预测掩蔽内容。与随机掩蔽令牌相比，通过分析代码结构准确掩蔽标识符增加了任务的难度，使模型能够学习到更高级的信息。在掩蔽标识符时，为了避免模型依赖上下文中相同变量名进行推理，可以同时将所有相同的令牌替换为
    $[mask_{i}]$，其中 $i$ 代表第 $i$ 个被替换的标识符。在实际设计训练任务时，$[mask_{i}]$ 可以连接到掩蔽的令牌。所有掩蔽信息被串联为输出，然后使用编码器-解码器框架训练模型。相应的目标函数可以表示为：
- en: '| (16) |  | ${Loss}_{ICP}=-\sum_{i}\log p\left(y_{i}\mid X^{mask},y[<i]\right).$
    |  |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| (16) |  | ${Loss}_{ICP}=-\sum_{i}\log p\left(y_{i}\mid X^{mask},y[<i]\right).$
    |  |'
- en: 5.1.3\. Multimodal Matching Tasks
  id: totrans-287
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.3\. 多模态匹配任务
- en: From a multi-modal viewpoint, code intelligence is a multi-modal task involving
    natural language, code sequence representation, and code structure representation.
    At present, many studies are also examining this problem from a multi-modal perspective
    and designing pre-training tasks for multi-modal matching.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 从多模态视角来看，代码智能是一个涉及自然语言、代码序列表示和代码结构表示的多模态任务。目前，许多研究也从多模态视角审视这个问题，并设计多模态匹配的预训练任务。
- en: 'Multi-Modal Matching Prediction (MMP) (Niu et al., [2022](#bib.bib62)). The
    multiple modalities of code can be seen as different ways of describing information
    with the same semantics. MMP splices the descriptions of these different modalities
    to obtain $M^{(1)}//M^{(2)}//\cdots//M^{(N)}$, where $M^{(i)}$ represents the
    token sequence composed of modality $i$. The number of modalities can be greater
    than or equal to 2, but attention should be paid to controlling the total amount,
    as sequences that are too long can result in a high computational complexity for
    the Transformer. Usually, $N$ is set to 2 or 3. Assuming $N=2$, the spliced sequence
    is denoted as $M_{i}^{(1)}//M_{j}^{(2)}$, where $M_{i}^{(j)}$ represents the $j$-th
    modal sequence representation of code $i$. The training objective is to determine
    if the two modalities in the spliced sequence describe the same piece of code
    information. If they do, the label is $\delta(ij)=1$, otherwise it is $\delta(ij)=0$.
    The spliced sequence can be input ted to the model, and the probability of $i=j$
    can be estimated by the representation of $[cls]$. The loss function can be expressed
    as follows:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态匹配预测（MMP）（Niu 等，[2022](#bib.bib62)）。代码的多种模态可以看作是用相同语义描述信息的不同方式。MMP 将这些不同模态的描述拼接以获得
    $M^{(1)}//M^{(2)}//\cdots//M^{(N)}$，其中 $M^{(i)}$ 代表由模态 $i$ 组成的令牌序列。模态的数量可以大于或等于
    2，但应注意控制总量，因为过长的序列会导致 Transformer 的计算复杂度较高。通常，$N$ 设置为 2 或 3。假设 $N=2$，拼接后的序列表示为
    $M_{i}^{(1)}//M_{j}^{(2)}$，其中 $M_{i}^{(j)}$ 代表代码 $i$ 的第 $j$ 个模态序列表示。训练目标是确定拼接序列中的两个模态是否描述了相同的代码信息。如果是，则标签为
    $\delta(ij)=1$，否则为 $\delta(ij)=0$。拼接序列可以输入到模型中，通过 $[cls]$ 的表示可以估计 $i=j$ 的概率。损失函数可以表示为：
- en: '| (17) |  | ${Loss}_{MMP}=-\sum_{ij}\left(\delta(ij)\log p\left(cls\mid M_{i}^{(1)}//M_{j}^{(2)}\right)+(1-\delta(ij))\left(1-\log
    p\left(cls\mid M_{i}^{(1)}//M_{j}^{(2)}\right)\right)\right).$ |  |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| (17) |  | ${Loss}_{MMP}=-\sum_{ij}\left(\delta(ij)\log p\left(cls\mid M_{i}^{(1)}//M_{j}^{(2)}\right)+(1-\delta(ij))\left(1-\log
    p\left(cls\mid M_{i}^{(1)}//M_{j}^{(2)}\right)\right)\right).$ |  |'
- en: 'Multi-modal Concatenation Contrastive Learning (MCCL) (Li et al., [2022b](#bib.bib46)).
    In multi-modal contrastive learning, the model encodes information from two modalities
    and calculates similarity in the representation space, namely $s_{ij}=<E\left(M_{i}^{(1)}\right),E\left(M_{j}^{(2)}\right)>$.
    However, this approach doesn’t model the fine-grained interaction of $M_{i}^{(i)}$
    and $M_{i}^{(j)}$ at the token level. To address this limitation, the token sequences
    of the two modalities can be spliced and encoded together with a single encoder,
    namely $s_{ij}=E\left(M_{i}^{(1)}//M_{j}^{(2)}\right)$. Based on the similarity,
    the loss function is constructed as follows:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态拼接对比学习 (MCCL) (Li et al., [2022b](#bib.bib46))。在多模态对比学习中，模型对来自两种模态的信息进行编码，并在表示空间中计算相似性，即
    $s_{ij}=<E\left(M_{i}^{(1)}\right),E\left(M_{j}^{(2)}\right)>$。然而，这种方法没有在标记级别上建模
    $M_{i}^{(i)}$ 和 $M_{i}^{(j)}$ 的细粒度交互。为了解决这个限制，可以将两种模态的标记序列拼接起来，并使用单个编码器对其进行编码，即
    $s_{ij}=E\left(M_{i}^{(1)}//M_{j}^{(2)}\right)$。根据相似性，损失函数构建如下：
- en: '| (18) |  | ${Loss}_{MCCL}=-\sum_{i}\log\frac{\exp\left(s_{ii}/\tau\right)}{\sum_{j}\exp\left(s_{ij}/\tau\right)}.$
    |  |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| (18) |  | ${Loss}_{MCCL}=-\sum_{i}\log\frac{\exp\left(s_{ii}/\tau\right)}{\sum_{j}\exp\left(s_{ij}/\tau\right)}.$
    |  |'
- en: After training with this objective, researchers can continue to use $s_{ij}$
    to weight the samples effectively in multi-modal contrastive learning, thereby
    enhancing its performance.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用此目标进行训练后，研究人员可以继续使用 $s_{ij}$ 在多模态对比学习中有效地加权样本，从而提升其性能。
- en: 'Cross Modal Generation (CMG) (Guo et al., [2022](#bib.bib25)). CMG aims to
    predict the information of another modal sequence through the information of one
    modal sequence. For example, the comment of the code can be predicted based on
    the function body sequence. If the source modality is denoted as $X$ and the target
    modality is denoted as $Y$, the objective function can be expressed as follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 跨模态生成 (CMG) (Guo et al., [2022](#bib.bib25))。CMG 旨在通过一种模态序列的信息来预测另一种模态序列的信息。例如，可以基于函数体序列来预测代码的注释。如果源模态记作
    $X$，目标模态记作 $Y$，则目标函数可以表示为：
- en: '| (19) |  | ${Loss}_{CMG}=-\sum_{i}\log p\left(y_{i}\mid X,Y[<i]\right).$ |  |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| (19) |  | ${Loss}_{CMG}=-\sum_{i}\log p\left(y_{i}\mid X,Y[<i]\right).$ |  |'
- en: CMG can be regarded as a generation task that utilizes multi-modal matching
    information, similar to an implicit matching task.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: CMG 可以被视为一种利用多模态匹配信息的生成任务，类似于隐式匹配任务。
- en: 5.1.4\. Summary
  id: totrans-297
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.4\. 总结
- en: This section introduces ten pre-training tasks for code intelligence, covering
    code sequence, code structure, and code multimodality. These tasks allow for training
    large models using extensive amounts of unlabeled data, leading to pre-trained
    models that can excel in various downstream tasks, such as code search, with minimal
    fine-tuning efforts. In practical applications, simple training tasks like MLM
    are often highly effective and play a fundamental role. Their simplicity and effectiveness
    make them a staple in most pre-training models, such as CodeBERT (Feng et al.,
    [2020](#bib.bib18)) and GraphCodeBERT (Guo et al., [2021](#bib.bib26)). Complex
    tasks show limited improvement in the presence of simple training tasks as seen
    in some ablation experiments (Guo et al., [2022](#bib.bib25)), and they do not
    generalize well to all data and tasks (Wang et al., [2021b](#bib.bib87)). Despite
    this, the variety of tasks also expands the possibilities for pre-training code
    intelligence, increasing its potential. Furthermore, for code search, pre-training
    with multimodal contrastive learning has produced better results due to its greater
    alignment with the downstream task (Li et al., [2022a](#bib.bib45)). This confirms
    that pre-training tasks perform better when they are consistent with the downstream
    tasks (Zhang et al., [2020](#bib.bib101)).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了十种用于代码智能的预训练任务，涵盖了代码序列、代码结构和代码多模态。这些任务允许使用大量未标记的数据来训练大模型，生成的预训练模型可以在各种下游任务中表现出色，例如代码搜索，且只需少量的微调。在实际应用中，像
    MLM 这样的简单训练任务通常非常有效，并且扮演了基础性角色。它们的简单性和有效性使其成为大多数预训练模型中的主流，例如 CodeBERT (Feng et
    al., [2020](#bib.bib18)) 和 GraphCodeBERT (Guo et al., [2021](#bib.bib26))。复杂任务在存在简单训练任务的情况下显示出有限的改进，这在一些消融实验中也有所体现
    (Guo et al., [2022](#bib.bib25))，并且它们对所有数据和任务的泛化能力较差 (Wang et al., [2021b](#bib.bib87))。尽管如此，任务的多样性也扩展了预训练代码智能的可能性，增加了其潜力。此外，对于代码搜索，通过多模态对比学习进行预训练取得了更好的结果，因为它与下游任务的对齐度更高
    (Li et al., [2022a](#bib.bib45))。这确认了当预训练任务与下游任务一致时，它们的表现更佳 (Zhang et al., [2020](#bib.bib101))。
- en: 5.2\. Code Search Model Training/Fine-tuning
  id: totrans-299
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 代码搜索模型训练/微调
- en: The pre-training tasks for training large models for code understanding are
    described above. Pre-training helps the parameters of the model reach a better
    state, which benefits the training of downstream tasks. This process is commonly
    referred to as fine-tuning. It is important to note that pre-training goals may
    not align with the target task, but training/fine-tuning should be focused on
    the target task and evaluated using the target task’s evaluation method. Models
    that do not require pre-training, like Graph Neural Networks, also require design
    goals for optimization. For simplicity and consistency with models without pre-training,
    we refer to fine-tuning as training below.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 上述描述了用于代码理解的大模型的预训练任务。预训练有助于模型参数达到更好的状态，这有利于下游任务的训练。这个过程通常称为微调。需要注意的是，预训练目标可能与目标任务不完全一致，但训练/微调应专注于目标任务，并使用目标任务的评估方法进行评估。像图神经网络这样的模型不需要预训练，但也需要设计优化目标。为了简化起见，并与没有预训练的模型保持一致，我们在下面将微调称为训练。
- en: During training, the model is guided by task-specific labels, known as supervision
    information. For code search, supervision information consists of paired (query,
    code) samples. Based on different training scenarios, we categorize existing code
    search training into discriminative model training and generative model training.
    Table [6](#S5.T6 "Table 6 ‣ 5.2.1\. Discriminative Model Training ‣ 5.2\. Code
    Search Model Training/Fine-tuning ‣ 5\. Training Method (RQ3) ‣ Survey of Code
    Search Based on Deep Learning") summarizes the approaches along these two dimensions.
    The discriminative model is the most commonly used in code search and models the
    similarity $s_{qc}=f_{\theta}(q,c)$. The generative model in code search mainly
    involves a Variational Auto-Encoder, encoding the input query/code into a distribution,
    and then decoding the distribution back to the original query/code. By designing
    a suitable training strategy for the encoder-decoder framework, the trained Variational
    Auto-Encoder model has a good generalization ability for its distribution in the
    latent space, and similarity can be calculated based on the matching of the mean
    vector in the latent space distribution.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，模型通过任务特定的标签进行指导，这些标签称为监督信息。对于代码搜索，监督信息由配对的（查询，代码）样本组成。根据不同的训练场景，我们将现有的代码搜索训练分为判别模型训练和生成模型训练。表格[6](#S5.T6
    "Table 6 ‣ 5.2.1\. Discriminative Model Training ‣ 5.2\. Code Search Model Training/Fine-tuning
    ‣ 5\. Training Method (RQ3) ‣ Survey of Code Search Based on Deep Learning")总结了这两种维度的方法。判别模型在代码搜索中最为常用，模型化相似度
    $s_{qc}=f_{\theta}(q,c)$。代码搜索中的生成模型主要涉及变分自编码器（Variational Auto-Encoder），将输入查询/代码编码成一个分布，然后将分布解码回原始查询/代码。通过为编码器-解码器框架设计适当的训练策略，训练后的变分自编码器模型对其潜在空间中的分布具有良好的泛化能力，并且相似度可以基于潜在空间分布中均值向量的匹配来计算。
- en: 5.2.1\. Discriminative Model Training
  id: totrans-302
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1\. 判别模型训练
- en: 'There are three types: point-level, pair-level, and sequence-level, which will
    be introduced separately.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种类型：点级、对级和序列级，它们将分别介绍。
- en: 'Point-wise (Huang et al., [2021](#bib.bib34); Arakelyan et al., [2022](#bib.bib3)).
    In this task, paired (query, code) sample pairs are labeled as 1, while unpaired
    (query, code) sample pairs are labeled as 0. Therefore, the training data can
    be viewed as a set of (query, code, label) triplets, with labels being either
    1 or 0. This task is a binary classification problem, and the model can be optimized
    using a binary classification objective such as Mean Squared Error loss:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 点级（Huang et al., [2021](#bib.bib34); Arakelyan et al., [2022](#bib.bib3)）。在此任务中，配对的（查询，代码）样本对标记为1，而未配对的（查询，代码）样本对标记为0。因此，训练数据可以视为（查询，代码，标签）三元组的集合，标签为1或0。此任务是一个二分类问题，模型可以使用二分类目标进行优化，如均方误差损失：
- en: '| (20) |  | ${Loss}_{MSE}=\frac{1}{&#124;D&#124;}\sum_{(q,c)\in D}\left&#124;\hat{y}_{qc}-y_{qc}\right&#124;^{2},$
    |  |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| (20) |  | ${Loss}_{MSE}=\frac{1}{|D|}\sum_{(q,c)\in D}\left|\hat{y}_{qc}-y_{qc}\right|^{2},$
    |  |'
- en: where $y_{qc}$ represents the true label of the sample pair $(q,c)$, $\hat{y}_{qc}=\sigma\left(f_{\theta}(q,c)\right)$
    represents the similarity score output by the model, $\sigma$ is the sigmoid function
    to ensure that the value of $\hat{y}_{qc}$ is between 0 and 1, and $D$ represents
    the sample set. During optimization, to maintain a balance between positive and
    negative samples, it is necessary to sample an equal number of negative samples.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $y_{qc}$ 代表样本对 $(q,c)$ 的真实标签，$\hat{y}_{qc}=\sigma\left(f_{\theta}(q,c)\right)$
    代表模型输出的相似度得分，$\sigma$ 是 sigmoid 函数，用于确保 $\hat{y}_{qc}$ 的值在 0 和 1 之间，$D$ 代表样本集。在优化过程中，为了保持正负样本之间的平衡，需要抽取相等数量的负样本。
- en: Table 6. Overview of code search model training/fine-tuning.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6. 代码搜索模型的训练/微调概述。
- en: '| Year | Work | Discriminative Model Training | Generative Model Training |
    Other |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| 年份 | 工作 | 判别模型训练 | 生成模型训练 | 其他 |'
- en: '| Point-wise | Pair-wise | List-wise |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| 点对点 | 对对对 | 列对列 |'
- en: '| 2018 | CODEnn (Gu et al., [2018](#bib.bib24)) |  | ✓ |  |  |  |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | CODEnn (Gu et al., [2018](#bib.bib24)) |  | ✓ |  |  |  |'
- en: '| 2018 | Chen and Zhou (Chen and Zhou, [2018](#bib.bib12)) |  |  |  | ✓ |  |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | Chen and Zhou (Chen and Zhou, [2018](#bib.bib12)) |  |  |  | ✓ |  |'
- en: '| 2019 | MMAN (Wan et al., [2019](#bib.bib79)) |  | ✓ |  |  |  |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | MMAN (Wan et al., [2019](#bib.bib79)) |  | ✓ |  |  |  |'
- en: '| 2019 | CoaCor (Yao et al., [2019](#bib.bib95)) |  | ✓ |  |  |  |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | CoaCor (Yao et al., [2019](#bib.bib95)) |  | ✓ |  |  |  |'
- en: '| 2020 | AdaCS (Ling et al., [2020](#bib.bib49)) |  | ✓ |  |  |  |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | AdaCS (Ling et al., [2020](#bib.bib49)) |  | ✓ |  |  |  |'
- en: '| 2020 | MP-CAT (Haldar et al., [2020](#bib.bib27)) |  | ✓ |  |  |  |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | MP-CAT (Haldar et al., [2020](#bib.bib27)) |  | ✓ |  |  |  |'
- en: '| 2020 | ${TranS}^{3}$ (Wang et al., [2020](#bib.bib86)) |  |  | ✓ |  |  |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | ${TranS}^{3}$ (Wang et al., [2020](#bib.bib86)) |  |  | ✓ |  |  |'
- en: '| 2020 | Zhao and Sun (Zhao and Sun, [2020](#bib.bib102)) |  | ✓ |  |  |  |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | Zhao and Sun (Zhao and Sun, [2020](#bib.bib102)) |  | ✓ |  |  |  |'
- en: '| 2020 | CO3 (Ye et al., [2020](#bib.bib97)) |  |  | ✓ |  |  |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | CO3 (Ye et al., [2020](#bib.bib97)) |  |  | ✓ |  |  |'
- en: '| 2021 | DGMS (Ling et al., [2021](#bib.bib50)) |  | ✓ |  |  |  |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | DGMS (Ling et al., [2021](#bib.bib50)) |  | ✓ |  |  |  |'
- en: '| 2021 | CoCLR (Huang et al., [2021](#bib.bib34)) | ✓ |  |  |  |  |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | CoCLR (Huang et al., [2021](#bib.bib34)) | ✓ |  |  |  |  |'
- en: '| 2021 | TabCS (Xu et al., [2021](#bib.bib92)) |  | ✓ |  |  |  |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | TabCS (Xu et al., [2021](#bib.bib92)) |  | ✓ |  |  |  |'
- en: '| 2021 | CRaDLe (Gu et al., [2021b](#bib.bib22)) |  | ✓ |  |  |  |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | CRaDLe (Gu et al., [2021b](#bib.bib22)) |  | ✓ |  |  |  |'
- en: '| 2021 | Corder (Bui et al., [2021](#bib.bib5)) |  | ✓ |  |  |  |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | Corder (Bui et al., [2021](#bib.bib5)) |  | ✓ |  |  |  |'
- en: '| 2022 | TranCS (Sun et al., [2022a](#bib.bib76)) |  | ✓ |  |  |  |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | TranCS (Sun et al., [2022a](#bib.bib76)) |  | ✓ |  |  |  |'
- en: '| 2022 | CSRS (Cheng and Kuang, [2022](#bib.bib13)) |  |  | ✓ |  |  |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CSRS (Cheng and Kuang, [2022](#bib.bib13)) |  |  | ✓ |  |  |'
- en: '| 2022 | G2SC (Shi et al., [2022](#bib.bib71)) |  | ✓ |  |  |  |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | G2SC (Shi et al., [2022](#bib.bib71)) |  | ✓ |  |  |  |'
- en: '| 2022 | Li et al. (Li et al., [2022d](#bib.bib44)) |  |  | ✓ |  |  |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | Li et al. (Li et al., [2022d](#bib.bib44)) |  |  | ✓ |  |  |'
- en: '| 2022 | CodeRetriever (Li et al., [2022a](#bib.bib45)) |  |  | ✓ |  |  |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CodeRetriever (Li et al., [2022a](#bib.bib45)) |  |  | ✓ |  |  |'
- en: '| 2022 | CDCS (Chai et al., [2022](#bib.bib9)) |  |  |  |  | ✓ |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CDCS (Chai et al., [2022](#bib.bib9)) |  |  |  |  | ✓ |'
- en: '| 2022 | ${NS}^{3}$ (Arakelyan et al., [2022](#bib.bib3)) | ✓ |  |  |  |  |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | ${NS}^{3}$ (Arakelyan et al., [2022](#bib.bib3)) | ✓ |  |  |  |  |'
- en: '| 2022 | Wang et al. (Wang et al., [2022a](#bib.bib84)) |  |  |  |  | ✓ |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | Wang et al. (Wang et al., [2022a](#bib.bib84)) |  |  |  |  | ✓ |'
- en: '| 2023 | deGraphCS (Zeng et al., [2023](#bib.bib99)) |  | ✓ |  |  |  |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | deGraphCS (Zeng et al., [2023](#bib.bib99)) |  | ✓ |  |  |  |'
- en: '| 2023 | KeyDAC (Park et al., [2023](#bib.bib64)) |  |  | ✓ |  |  |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | KeyDAC (Park et al., [2023](#bib.bib64)) |  |  | ✓ |  |  |'
- en: '| 2023 | CSSAM (Cai et al., [2023](#bib.bib6)) |  | ✓ |  |  |  |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | CSSAM (Cai et al., [2023](#bib.bib6)) |  | ✓ |  |  |  |'
- en: '| 2023 | MulCS (Ma et al., [2023](#bib.bib57)) |  | ✓ |  |  |  |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | MulCS (Ma et al., [2023](#bib.bib57)) |  | ✓ |  |  |  |'
- en: '| 2023 | GraphSearchNet (Liu et al., [2023](#bib.bib53)) |  |  | ✓ |  |  |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | GraphSearchNet (Liu et al., [2023](#bib.bib53)) |  |  | ✓ |  |  |'
- en: '| 2023 | TOSS (Hu et al., [2023](#bib.bib32)) |  |  | ✓ |  |  |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | TOSS (Hu et al., [2023](#bib.bib32)) |  |  | ✓ |  |  |'
- en: 'Pair-wise (Gu et al., [2018](#bib.bib24); Yao et al., [2019](#bib.bib95); Wan
    et al., [2019](#bib.bib79); Haldar et al., [2020](#bib.bib27); Ling et al., [2020](#bib.bib49);
    Zhao and Sun, [2020](#bib.bib102); Ling et al., [2021](#bib.bib50); Xu et al.,
    [2021](#bib.bib92); Bui et al., [2021](#bib.bib5); Gu et al., [2021b](#bib.bib22);
    Sun et al., [2022a](#bib.bib76); Cai et al., [2023](#bib.bib6); Ma et al., [2023](#bib.bib57);
    Zeng et al., [2023](#bib.bib99)). For the paired (query, code) positive sample
    pair, the negative sample code can be randomly selected to construct a triplet
    $\left(q,c^{+},c^{-}\right)$ called (query, positive sample code, negative sample
    code). The objective of training is to maximize the gap between positive sample
    $\left(q,c^{+}\right)$ and negative sample $\left(q,c^{-}\right)$. The loss function
    commonly used for this purpose is the Hinge loss, which can be represented as
    follows:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 配对方法（Gu et al., [2018](#bib.bib24); Yao et al., [2019](#bib.bib95); Wan et al.,
    [2019](#bib.bib79); Haldar et al., [2020](#bib.bib27); Ling et al., [2020](#bib.bib49);
    Zhao and Sun, [2020](#bib.bib102); Ling et al., [2021](#bib.bib50); Xu et al.,
    [2021](#bib.bib92); Bui et al., [2021](#bib.bib5); Gu et al., [2021b](#bib.bib22);
    Sun et al., [2022a](#bib.bib76); Cai et al., [2023](#bib.bib6); Ma et al., [2023](#bib.bib57);
    Zeng et al., [2023](#bib.bib99))。对于配对的（查询，代码）正样本对，负样本代码可以随机选择，以构建一个三元组$\left(q,c^{+},c^{-}\right)$，称为（查询，正样本代码，负样本代码）。训练的目标是最大化正样本$\left(q,c^{+}\right)$和负样本$\left(q,c^{-}\right)$之间的差距。用于此目的的常见损失函数是Hinge损失，其表示如下：
- en: '| (21) |  | $Loss_{hinge}=\sum_{\left(q,c^{+},c^{-}\right)\in D}\max\left(0,\epsilon-s_{{qc}^{+}}+s_{{qc}^{-}}\right),$
    |  |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| (21) |  | $Loss_{hinge}=\sum_{\left(q,c^{+},c^{-}\right)\in D}\max\left(0,\epsilon-s_{{qc}^{+}}+s_{{qc}^{-}}\right),$
    |  |'
- en: where $s_{qc}=f_{\theta}(q,c)$ represents the similarity between query $q$ and
    code $c$, $\epsilon$ is a hyperparameter, and $D$ represents the sample set. For
    paired $(q,c)$ samples, negative samples $c^{-}$ are randomly selected to construct
    triplet sample $\left(q,c^{+},c^{-}\right)$.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$s_{qc}=f_{\theta}(q,c)$表示查询$q$与代码$c$之间的相似度，$\epsilon$是一个超参数，而$D$表示样本集。对于配对的$(q,c)$样本，负样本$c^{-}$被随机选择以构建三元组样本$\left(q,c^{+},c^{-}\right)$。
- en: 'List-wise (Ye et al., [2020](#bib.bib97); Wang et al., [2020](#bib.bib86);
    Cheng and Kuang, [2022](#bib.bib13); Li et al., [2022a](#bib.bib45), [d](#bib.bib44);
    Liu et al., [2023](#bib.bib53); Hu et al., [2023](#bib.bib32)). For paired (query,
    code) positive sample pairs, several negative sample codes can be randomly selected
    to construct the sequence $\left(q,c^{+},c_{1}^{-},\cdots,c_{n-1}^{-}\right)$.
    The training goal is to optimize the similarity ranking of positive sample $c^{+}$
    in the entire sequence $\left(c^{+},c_{1}^{-},\cdots,c_{n-1}^{-}\right)$ for the
    query $q$. The InfoNCE loss function can be utilized as the related loss function,
    viewing the problem as an $n$ classification task with the number of categories
    equal to the number of positive sample categories. After passing the similarity
    through softmax, the cross-entropy is used to construct the loss. The loss function
    can be expressed as:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 列表方法（Ye et al., [2020](#bib.bib97); Wang et al., [2020](#bib.bib86); Cheng and
    Kuang, [2022](#bib.bib13); Li et al., [2022a](#bib.bib45), [d](#bib.bib44); Liu
    et al., [2023](#bib.bib53); Hu et al., [2023](#bib.bib32)）。对于配对的（查询，代码）正样本对，可以随机选择多个负样本代码来构建序列$\left(q,c^{+},c_{1}^{-},\cdots,c_{n-1}^{-}\right)$。训练目标是优化整个序列$\left(c^{+},c_{1}^{-},\cdots,c_{n-1}^{-}\right)$中正样本$c^{+}$的相似度排名。可以使用InfoNCE损失函数，将问题视为一个分类任务，其中类别数等于正样本类别的数量。在通过softmax计算相似度后，使用交叉熵构建损失。损失函数可以表示为：
- en: '| (22) |  | ${Loss}_{InfoNCE}=-\sum_{\left(q,c^{+},c_{1}^{-},\cdots,c_{n-1}^{-}\right)\in
    D}\log\left(\frac{\exp\left(s_{qc^{+}}/\tau\right)}{\exp\left(s_{qc^{+}}/\tau\right)+\sum_{j}\exp\left(s_{qc_{j}^{-}}/\tau\right)}\right),$
    |  |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| (22) |  | ${Loss}_{InfoNCE}=-\sum_{\left(q,c^{+},c_{1}^{-},\cdots,c_{n-1}^{-}\right)\in
    D}\log\left(\frac{\exp\left(s_{qc^{+}}/\tau\right)}{\exp\left(s_{qc^{+}}/\tau\right)+\sum_{j}\exp\left(s_{qc_{j}^{-}}/\tau\right)}\right),$
    |  |'
- en: where $\tau$ is the temperature hyperparameter. In practice, the batch negative
    sampling strategy is commonly used to generate negative samples, meaning that
    for a batch of positive sample pairs, other codes within the batch are considered
    as negative samples. For instance, (Li et al., [2022a](#bib.bib45)) employs various
    strategies to sample negative samples to improve model performance, while (Li
    et al., [2022d](#bib.bib44)) improves the representation space data and generates
    more positive and negative samples.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\tau$ 是温度超参数。在实际操作中，通常使用批量负样本采样策略来生成负样本，这意味着对于一批正样本对，批次中的其他代码被视为负样本。例如，（Li
    et al., [2022a](#bib.bib45)）采用了多种策略来采样负样本以提高模型性能，而（Li et al., [2022d](#bib.bib44)）改进了表示空间数据并生成了更多正样本和负样本。
- en: The above three optimization objectives are all designed for discriminative
    models in supervised learning. Among them, the sequence-level optimization objective
    is currently the most popular due to its effectiveness.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 上述三个优化目标都是为监督学习中的判别模型设计的。其中，序列级优化目标因其有效性而目前最受欢迎。
- en: 5.2.2\. Generative Model Training
  id: totrans-345
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2\. 生成模型训练
- en: 'The Variational Auto-Encoder (VAE) map the input $\vec{x}$ to a distribution
    in the hidden space through the function $f_{\theta}(\cdot)$ (assumed to be a
    Gaussian distribution, which can be represented by a mean and variance vector),
    and then the vector obtained from sampling the distribution is then mapped to
    the input space by the function $g_{\phi}(\cdot)$, hoping to reconstruct $\vec{x}$.
    A regularization term is added to make the latent space distribution closer to
    a standard Gaussian distribution. The loss function of VAE is:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 变分自编码器（VAE）通过函数 $f_{\theta}(\cdot)$（假设为高斯分布，可以由均值和方差向量表示）将输入 $\vec{x}$ 映射到隐藏空间中的分布，然后通过函数
    $g_{\phi}(\cdot)$ 将从分布中采样得到的向量映射到输入空间，希望能重建 $\vec{x}$。添加了一个正则化项，使潜在空间分布更接近标准高斯分布。VAE
    的损失函数为：
- en: '| (23) |  | ${Loss}_{VAE}=\mathcal{R}(\vec{x};\theta,\phi)+KL\left(q_{\theta}(\vec{z}\mid\vec{x}),\mathcal{N}(0,1)\right),$
    |  |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| (23) |  | ${Loss}_{VAE}=\mathcal{R}(\vec{x};\theta,\phi)+KL\left(q_{\theta}(\vec{z}\mid\vec{x}),\mathcal{N}(0,1)\right),$
    |  |'
- en: where $\mathcal{R}(\vec{x};\theta,\phi)$ denotes the error loss for reconstructing
    $\vec{x}$ through the encoder-decoder framework, and $KL\left(q_{\theta}(\vec{z}\mid\vec{x}),\mathcal{N}(0,1)\right)$
    denotes the KL divergence of $q_{\theta}(\vec{z}\mid\vec{x})$ over $\mathcal{N}(0,1)$.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{R}(\vec{x};\theta,\phi)$ 表示通过编码器-解码器框架重建 $\vec{x}$ 的误差损失，而 $KL\left(q_{\theta}(\vec{z}\mid\vec{x}),\mathcal{N}(0,1)\right)$
    表示 $q_{\theta}(\vec{z}\mid\vec{x})$ 与 $\mathcal{N}(0,1)$ 的 KL 散度。
- en: '![Refer to caption](img/4825156cab89d7d554fb76a4097e2b4f.png)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4825156cab89d7d554fb76a4097e2b4f.png)'
- en: Figure 7. Bimodal Variational Auto-Encoder.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7. 双模态变分自编码器。
- en: 'The bimodal VAE, unlike general VAE, addresses the two modalities in code search
    and focuses on learning the matching relationships. The bimodal VAE has two improvements
    over the general VAE to make it more suitable for code search tasks (Chen and
    Zhou, [2018](#bib.bib12)), as shown in Figure [7](#S5.F7 "Figure 7 ‣ 5.2.2\. Generative
    Model Training ‣ 5.2\. Code Search Model Training/Fine-tuning ‣ 5\. Training Method
    (RQ3) ‣ Survey of Code Search Based on Deep Learning"). (a) Bimodal encoder-decoder
    framework: this framework inputs both the query and the code into the respective
    encoder-decoder models (the parameters of each model can be the same), and they
    operate in parallel. (b) Cross-modal regularization term: the regularization involves
    minimizing the difference in distribution between two modes of a sample pair instead
    of using the standard normal distribution regularization term. This unifies the
    query and code representations in the latent space, making the subsequent similarity
    matching more rational. The regularization term can be the KL divergence between
    the two modes or the KL divergence between one mode and the mean of both modes.
    Here, we use the KL divergence from query to code, expressed as ${KL}\left(q_{\theta}^{(1)}\left(\vec{z}_{q}\mid\vec{x}_{q}\right),q_{\theta}^{(2)}\left(\vec{z}_{\boldsymbol{c}}\mid\vec{x}_{\boldsymbol{c}}\right)\right)$,
    where $q_{\theta}^{(1)}\left(\vec{z}_{q}\mid\vec{x}_{q}\right)$ and $q_{\theta}^{(2)}\left(\vec{z}_{\boldsymbol{c}}\mid\vec{x}_{\boldsymbol{c}}\right)$
    represent the normal distribution consisting of the mean and variance of the query
    and code. The KL divergence from code to query can be obtained by reversing the
    above formula. The average distribution of queries and codes can be obtained by
    averaging their mean and variance, and the mean can also be used as a regularization
    term in the KL divergence.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 双模态变分自编码器（bimodal VAE），不同于一般的变分自编码器（VAE），处理代码搜索中的两个模态，并专注于学习匹配关系。双模态 VAE 相比于一般的
    VAE 有两个改进，使其更适合代码搜索任务（Chen 和 Zhou，[2018](#bib.bib12)），如图 [7](#S5.F7 "Figure 7
    ‣ 5.2.2\. Generative Model Training ‣ 5.2\. Code Search Model Training/Fine-tuning
    ‣ 5\. Training Method (RQ3) ‣ Survey of Code Search Based on Deep Learning") 所示。
    (a) 双模态编码器-解码器框架：该框架将查询和代码分别输入到各自的编码器-解码器模型中（每个模型的参数可以相同），并且它们并行操作。 (b) 跨模态正则化项：正则化涉及最小化样本对两个模态之间分布的差异，而不是使用标准的正态分布正则化项。这将查询和代码的表示统一到潜在空间中，使得后续的相似性匹配更加合理。正则化项可以是两个模态之间的
    KL 散度，也可以是一个模态与两个模态均值之间的 KL 散度。在这里，我们使用从查询到代码的 KL 散度，表示为 ${KL}\left(q_{\theta}^{(1)}\left(\vec{z}_{q}\mid\vec{x}_{q}\right),q_{\theta}^{(2)}\left(\vec{z}_{\boldsymbol{c}}\mid\vec{x}_{\boldsymbol{c}}\right)\right)$，其中
    $q_{\theta}^{(1)}\left(\vec{z}_{q}\mid\vec{x}_{q}\right)$ 和 $q_{\theta}^{(2)}\left(\vec{z}_{\boldsymbol{c}}\mid\vec{x}_{\boldsymbol{c}}\right)$
    表示查询和代码的均值和方差组成的正态分布。代码到查询的 KL 散度可以通过反转上述公式得到。查询和代码的平均分布可以通过它们的均值和方差的平均来获得，均值也可以作为
    KL 散度中的正则化项。
- en: 5.2.3\. Other Training Methods
  id: totrans-352
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.3\. 其他训练方法
- en: Besides the pre-training and training techniques introduced above, there are
    also works exploring model training techniques from other perspectives. For example,
    meta-learning in (Chai et al., [2022](#bib.bib9)) uses a small verification set
    to improve model initialization for better performance with small data. (Wang
    et al., [2022a](#bib.bib84)) proposes data enhancement that preserves semantics
    and uses curriculum learning to control sample weight for better model convergence.
    In zero-shot settings, with no label training process, pre-training is crucial
    for developing a representation ability. Hence, the input is transformed into
    the representation space, where the resulting vectors carry semantic information.
    Decisions are made based on the similarity evaluation within this space (Guo et al.,
    [2022](#bib.bib25)).
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述介绍的预训练和训练技术，还有一些研究从其他角度探索模型训练技术。例如，（Chai 等，[2022](#bib.bib9)）的元学习使用一个小的验证集来改进模型初始化，以便在小数据情况下获得更好的性能。（Wang
    等，[2022a](#bib.bib84)）提出了保持语义的数据增强技术，并使用课程学习来控制样本权重以获得更好的模型收敛。在零样本设置中，没有标签训练过程，预训练对于开发表示能力至关重要。因此，输入被转换到表示空间，其中得到的向量携带语义信息。决策基于该空间内的相似性评估（Guo
    等，[2022](#bib.bib25)）。
- en: '<svg   height="122.73" overflow="visible" version="1.1" width="600"><g transform="translate(0,122.73)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    width="556.69" height="95.17" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">Summary of answers to RQ3: • Over the past six years, the Masked
    Language Model (MLM) has emerged as the prevailing choice for pre-training tasks
    in code understanding. Despite its apparent simplicity, this task has consistently
    demonstrated remarkable effectiveness and serves as a fundamental cornerstone
    in achieving comprehensive code comprehension. • The training/fine-tuning of code
    search models predominantly adopt a discriminative model training approach, with
    pair-wise training being the most prevalent form.</foreignobject></g></g></svg>'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: <svg height="122.73" overflow="visible" version="1.1" width="600"><g transform="translate(0,122.73)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    width="556.69" height="95.17" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">对RQ3的回答总结： • 在过去的六年中，掩码语言模型（MLM）已成为代码理解预训练任务的主要选择。尽管其表面上看起来简单，但该任务始终表现出卓越的效果，并作为实现全面代码理解的基础支柱。
    • 代码搜索模型的训练/微调主要采用判别模型训练方法，其中配对训练是最常见的形式。</foreignobject></g></g></svg>
- en: 6\. Datasets and Evaluation (RQ4)
  id: totrans-355
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 数据集与评估（RQ4）
- en: Datasets have had a significant impact on the evolution of code search technology.
    They not only serve as a mean to assess the performance of various models, but
    also play a crucial role in addressing real-world challenges faced in code search,
    thus driving the growth of this field. In this section, we present an overview
    of 12 code search datasets that have been proposed since 2018 and 8 commonly used
    metrics for evaluating code search models. To provide some guidelines for industrial
    practitioners, we further discuss how to choose proper code search approaches
    to fit their needs.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集对代码搜索技术的发展产生了重大影响。它们不仅作为评估各种模型性能的手段，还在解决代码搜索中遇到的实际挑战方面发挥了关键作用，从而推动了这一领域的成长。在本节中，我们概述了自2018年以来提出的12个代码搜索数据集以及8种常用的代码搜索模型评估指标。为了为工业实践者提供一些指导，我们进一步讨论了如何选择适当的代码搜索方法以满足他们的需求。
- en: 6.1\. Code Search Datasets
  id: totrans-357
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1\. 代码搜索数据集
- en: To drive the advancement of code search, various datasets comprising of (text,
    code) pairs have been introduced. This section summarizes the existing datasets
    on natural language code search research, including release year, data sources,
    programming languages, data statistics, dataset division, data annotation, and
    acquisition methods, as displayed in Table [7](#S6.T7 "Table 7 ‣ 6.1\. Code Search
    Datasets ‣ 6\. Datasets and Evaluation (RQ4) ‣ Survey of Code Search Based on
    Deep Learning"). In the subsequent section, we give a concise overview of some
    of the classic corpora outlined in Table [7](#S6.T7 "Table 7 ‣ 6.1\. Code Search
    Datasets ‣ 6\. Datasets and Evaluation (RQ4) ‣ Survey of Code Search Based on
    Deep Learning"). Furthermore, We conduct meticulous statistical analysis on data
    sources and programming languages. As depicted in Figure [8](#S6.F8 "Figure 8
    ‣ 6.1\. Code Search Datasets ‣ 6\. Datasets and Evaluation (RQ4) ‣ Survey of Code
    Search Based on Deep Learning"), GitHub emerges as the primary source of code
    search task datasets, with Python and Java being the predominant languages of
    interest for this task.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 为了推动代码搜索的进展，各种由（文本，代码）对组成的数据集被引入。本节总结了现有的自然语言代码搜索研究数据集，包括发行年份、数据来源、编程语言、数据统计、数据集划分、数据注释和获取方法，如表[7](#S6.T7
    "表7 ‣ 6.1\. 代码搜索数据集 ‣ 6\. 数据集与评估（RQ4） ‣ 基于深度学习的代码搜索调查")所示。在接下来的部分，我们简要概述了表[7](#S6.T7
    "表7 ‣ 6.1\. 代码搜索数据集 ‣ 6\. 数据集与评估（RQ4） ‣ 基于深度学习的代码搜索调查")中列出的一些经典语料库。此外，我们对数据来源和编程语言进行了细致的统计分析。如图[8](#S6.F8
    "图8 ‣ 6.1\. 代码搜索数据集 ‣ 6\. 数据集与评估（RQ4） ‣ 基于深度学习的代码搜索调查")所示，GitHub是代码搜索任务数据集的主要来源，而Python和Java是该任务的主要关注语言。
- en: Table 7. Overview of existing datasets on code search.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 表7. 现有代码搜索数据集概述。
- en: '| Release year | Corpus | Data sources | Programming languages | Data statistics
    | Data splits | Data annotation | Acquisition methods |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| 发行年份 | 语料库 | 数据来源 | 编程语言 | 数据统计 | 数据划分 | 数据注释 | 获取方法 |'
- en: '| 2018 | StaQC (Yao et al., [2018](#bib.bib96)) | SO | Python, SQL | 147,546
    Python (question,code) pairs; 119,519 SQL (question,code) pairs | training set,
    dev set, test set | manual, automatic | https://github.com/ LittleYUYU/StackOverflow-
    Question-Code-Dataset |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | StaQC (Yao et al., [2018](#bib.bib96)) | SO | Python, SQL | 147,546个Python（问题,代码）对；119,519个SQL（问题,代码）对
    | 训练集，开发集，测试集 | 手动，自动 | https://github.com/LittleYUYU/StackOverflow-Question-Code-Dataset
    |'
- en: '| 2018 | CoNaLa (Yin et al., [2018](#bib.bib98)) | SO | Python, Java | 42 Python
    questions, 736 code blocks; 100 Java questions, 434 code blocks | training set,
    dev set, test set | manual, automatic | https://conala-corpus.github.io/ |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | CoNaLa (Yin et al., [2018](#bib.bib98)) | SO | Python, Java | 42个Python问题，736个代码块；100个Java问题，434个代码块
    | 训练集，开发集，测试集 | 手动，自动 | https://conala-corpus.github.io/ |'
- en: '| 2018 | Gu et al. (Gu et al., [2018](#bib.bib24)) | GitHub | Java | 18,233,872
    Java methods with docstring | training set | automatic | https://github.com/ guxd/deep-code-search
    |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | Gu et al. (Gu et al., [2018](#bib.bib24)) | GitHub | Java | 18,233,872个带文档字符串的Java方法
    | 训练集 | 自动 | https://github.com/guxd/deep-code-search |'
- en: '| 2018 | Java-50 (Gu et al., [2018](#bib.bib24)) | SO, GitHub | Java | 9,950
    Java projects; 16,262,602 Java methods; 50 queries | codebase, evaluation set
    | manual | https://github.com/ guxd/deep-code-search |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | Java-50 (Gu et al., [2018](#bib.bib24)) | SO, GitHub | Java | 9,950个Java项目；16,262,602个Java方法；50个查询
    | 代码库，评估集 | 手动 | https://github.com/guxd/deep-code-search |'
- en: '| 2019 | FB-Java (Li et al., [2019](#bib.bib43)) | SO, GitHub | Java | 24,549
    repositories; 4,716,814 methods; 287 (question,answer) pairs | codebase, evaluation
    set | manual | https://github.com/ facebookresearch/Neural-Code -Search-Evaluation-Dataset
    |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | FB-Java (Li et al., [2019](#bib.bib43)) | SO, GitHub | Java | 24,549个代码库；4,716,814个方法；287个（问题,答案）对
    | 代码库，评估集 | 手动 | https://github.com/facebookresearch/Neural-Code-Search-Evaluation-Dataset
    |'
- en: '| 2019 | CSN (Husain et al., [2019](#bib.bib36)) | GitHub | Python, Java, Ruby,
    Go, PHP, JavaScript | 2,326,976 (documentation,function) pairs; 4,125,470 functions
    without documentation | training set, dev set, test set, codebase | automatic
    | https://github.com /github/CodeSearchNet |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | CSN (Husain et al., [2019](#bib.bib36)) | GitHub | Python, Java, Ruby,
    Go, PHP, JavaScript | 2,326,976个（文档,函数）对；4,125,470个没有文档的函数 | 训练集，开发集，测试集，代码库 |
    自动 | https://github.com/github/CodeSearchNet |'
- en: '| 2019 | CSN-99 (Husain et al., [2019](#bib.bib36)) | Bing, GitHub | Python,
    Java, Ruby, Go, PHP, JavaScript | 99 queries; 4,026 (query,code) pairs | evaluation
    set | manual | https://github.com /github/CodeSearchNet |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | CSN-99 (Husain et al., [2019](#bib.bib36)) | Bing, GitHub | Python,
    Java, Ruby, Go, PHP, JavaScript | 99个查询；4,026个（查询,代码）对 | 评估集 | 手动 | https://github.com/github/CodeSearchNet
    |'
- en: '| 2020 | SO-DS (Heyman and Cutsem, [2020](#bib.bib29)) | SO, GitHub | Python
    | 1,113 queries; 12,137 code snippets | training set, dev set, test set | automatic
    | https://github.com/ nokia/codesearch |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | SO-DS (Heyman and Cutsem, [2020](#bib.bib29)) | SO, GitHub | Python
    | 1,113个查询；12,137个代码片段 | 训练集，开发集，测试集 | 自动 | https://github.com/nokia/codesearch
    |'
- en: '| 2020 | CosBench (Yan et al., [2020](#bib.bib93)) | SO, GitHub | Java | 1,000
    Java projects; 475,783 Java files; 4,199,769 code snippets; 52 queries | codebase,
    evaluation set | manual | https://github.com/ BASE-LAB-SJTU/CosBench |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | CosBench (Yan et al., [2020](#bib.bib93)) | SO, GitHub | Java | 1,000个Java项目；475,783个Java文件；4,199,769个代码片段；52个查询
    | 代码库，评估集 | 手动 | https://github.com/BASE-LAB-SJTU/CosBench |'
- en: '| 2020 | WebQueryTest (Lu et al., [2021](#bib.bib55)) | Bing, GitHub | Python
    | 1,046 (web query, code) pairs | test set | manual | https://github.com/microsoft/
    CodeXGLUE/tree/main/Text-Code/ NL-code-search-WebQuery |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | WebQueryTest (Lu et al., [2021](#bib.bib55)) | Bing, GitHub | Python
    | 1,046个（网页查询, 代码）对 | 测试集 | 手动 | https://github.com/microsoft/CodeXGLUE/tree/main/Text-Code/NL-code-search-WebQuery
    |'
- en: '| 2020 | AdvTest (Lu et al., [2021](#bib.bib55)) | GitHub | Python | 280,634
    (documentation, function) pairs | training set, dev set, test set | automatic
    | https://github.com/microsoft/ CodeXGLUE/tree/main/Text-Code/ NL-code-search-Adv
    |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | AdvTest (Lu et al., [2021](#bib.bib55)) | GitHub | Python | 280,634个（文档,函数）对
    | 训练集，开发集，测试集 | 自动 | https://github.com/microsoft/CodeXGLUE/tree/main/Text-Code/NL-code-search-Adv
    |'
- en: '| 2021 | CoSQA (Huang et al., [2021](#bib.bib34)) | Bing, GitHub | Python |
    20,604 (web query, code) pairs | training set, dev set, test set | manual | https://github.com/
    Jun-jie-Huang/CoCLR |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | CoSQA (Huang et al., [2021](#bib.bib34)) | Bing, GitHub | Python |
    20,604个（网页查询, 代码）对 | 训练集，开发集，测试集 | 手动 | https://github.com/Jun-jie-Huang/CoCLR
    |'
- en: StaQC (Stack Overflow Question-Code pairs) (Yao et al., [2018](#bib.bib96))
    is a dataset of (question,code) pairs that has been automatically extracted from
    Stack Overflow (SO), which makes it ideal for predicting whether a code snippet
    can answer a particular question. Stack Overflow is a well-known website where
    developers can ask programming-related questions, such as “how to read a file
    in Python”. There are various user-generated solutions available on the site,
    and the “accepted” label is used to indicate the quality of these solutions. To
    construct the StaQC dataset, Yao et al. (Yao et al., [2018](#bib.bib96)) filtered
    posts in the Python and SQL domains on Stack Overflow using tags, and used a binary
    classifier to select posts that had ”how-to” type questions. They then combined
    manual labeling and automatic extraction methods to select questions and independent,
    “accepted” solutions from these posts to create (question, code) pairs. As a result,
    they obtained 147,546 Python (question, code) pairs and 119,519 SQL (question,
    code) pairs.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: StaQC（Stack Overflow 问题-代码对）（Yao et al., [2018](#bib.bib96)）是一个自动从 Stack Overflow（SO）中提取的（问题，代码）对的数据集，这使其非常适合预测代码片段是否可以回答特定问题。Stack
    Overflow 是一个知名的网站，开发者可以在上面提出编程相关的问题，如“如何在 Python 中读取文件”。网站上提供了各种用户生成的解决方案，并使用“接受”标签来指示这些解决方案的质量。为了构建
    StaQC 数据集，Yao et al.（Yao et al., [2018](#bib.bib96)）通过标签过滤了 Stack Overflow 上的
    Python 和 SQL 领域的帖子，并使用二分类器选择了包含“如何做”类型问题的帖子。然后，他们结合了人工标注和自动提取方法，从这些帖子中选择问题和独立的“接受”解决方案，以创建（问题，代码）对。因此，他们获得了
    147,546 个 Python（问题，代码）对和 119,519 个 SQL（问题，代码）对。
- en: However, collecting questions from Stack Overflow can be a tedious and time-consuming
    process, which limits the quality and quantity of the collected corpus and may
    pose challenges for systematic comparison of various models. With the exponential
    growth of open-source software projects on GitHub, it has become the main source
    for obtaining code corpus.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，从 Stack Overflow 收集问题可能是一个繁琐且耗时的过程，这限制了收集到的语料库的质量和数量，并且可能会对各种模型的系统比较带来挑战。随着
    GitHub 上开源软件项目的指数增长，它已成为获取代码语料库的主要来源。
- en: CSN (CodeSearchNet) (Husain et al., [2019](#bib.bib36)) is a code search dataset
    that has been constructed using the open-source projects on GitHub. This corpus
    encompasses 6 different programming languages, including Python, Java, Go, PHP,
    JavaScript, and Ruby. In order to minimize the manual labeling effort, Husain
    et al. (Husain et al., [2019](#bib.bib36)) replaced natural language queries with
    documentations, forming pairs of (documentation, function) along with code snippets.
    To ensure the corpus’s quality, multiple filtering rules were established. This
    involved eliminating (documentation, function) pairs with fewer than 3 documentation
    tokens, functions containing less than 3 lines of code, functions with “test”
    in their names, and duplicated functions. As a result, the CSN corpus comprises
    a total of 6 million samples, including 2 million (documentation, function) pairs
    and 4 million functions without paired documents. The arrival of the CSN corpus
    presents exciting opportunities for training large models of code intelligence.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: CSN（CodeSearchNet）（Husain et al., [2019](#bib.bib36)）是一个使用 GitHub 上的开源项目构建的代码搜索数据集。该语料库涵盖了包括
    Python、Java、Go、PHP、JavaScript 和 Ruby 在内的 6 种不同的编程语言。为了最小化人工标注工作，Husain et al.（Husain
    et al., [2019](#bib.bib36)）用文档替换了自然语言查询，形成了（文档，函数）对以及代码片段。为了确保语料库的质量，建立了多个过滤规则。这包括去除包含少于
    3 个文档标记的（文档，函数）对、代码行少于 3 行的函数、名称中含有“test”的函数以及重复的函数。因此，CSN 语料库总共包含 600 万个样本，其中包括
    200 万个（文档，函数）对和 400 万个没有配对文档的函数。CSN 语料库的到来为训练大型代码智能模型提供了令人兴奋的机会。
- en: AdvTest (Lu et al., [2021](#bib.bib55)) is designed for evaluating the generalization
    capability of code search models. It is constructed using the CodeSearchNet’s
    Python corpus. To guard against over-fitting, Lu et al. (Lu et al., [2021](#bib.bib55))
    replaced the function and variable names in the test set with special tokens (e.g.,
    “Func” in place of a function name). This helps prevent the model from over-relying
    on keyword matching during training and decrease the rate of keyword coincidence
    between query and code at the token level.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: AdvTest (Lu 等, [2021](#bib.bib55)) 旨在评估代码搜索模型的泛化能力。它使用 CodeSearchNet 的 Python
    语料库构建。为了防止过拟合，Lu 等 (Lu 等, [2021](#bib.bib55)) 用特殊标记 (例如，用“Func”代替函数名) 替换了测试集中的函数和变量名。这有助于防止模型在训练中过度依赖关键词匹配，并减少查询和代码之间的关键词重合率。
- en: CoSQA (Huang et al., [2021](#bib.bib34)) is a unique code search dataset that
    is more representative of real-world code search scenarios compared to other datasets.
    Unlike other datasets that utilize documents, docstrings, or comments as queries,
    CoSQA is based on real user queries collected from Microsoft’s Bing search engine
    logs. To construct the CoSQA dataset, Huang et al. (Huang et al., [2021](#bib.bib34))
    filtered queries that did not contain the keyword “Python” or showed no code search
    intent. To build (query, code) pairs, Huang et al. (Huang et al., [2021](#bib.bib34))
    utilized CodeBERT to pre-select high-confidence functions from the CodeSearchNet
    Python corpus for each query. Subsequently, the annotators were tasked with determining
    whether the query was a match for the selected function. Finally, they obtained
    20,604 (web query, code) pairs that could assist the model in learning the semantic
    relationship between queries and codes in real-world scenarios.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: CoSQA (Huang 等, [2021](#bib.bib34)) 是一个独特的代码搜索数据集，与其他数据集相比，更能代表真实世界的代码搜索场景。与使用文档、文档字符串或注释作为查询的其他数据集不同，CoSQA
    基于从微软 Bing 搜索引擎日志中收集的真实用户查询。为了构建 CoSQA 数据集，Huang 等 (Huang 等, [2021](#bib.bib34))
    过滤掉了不包含关键词“Python”或没有代码搜索意图的查询。为了建立 (查询, 代码) 对，Huang 等 (Huang 等, [2021](#bib.bib34))
    利用 CodeBERT 从 CodeSearchNet Python 语料库中预选出高置信度的函数，然后由注释员判断查询是否与选定的函数匹配。最终，他们获得了
    20,604 个 (网页查询, 代码) 对，帮助模型学习查询与代码在真实场景中的语义关系。
- en: Table 8. Manually labeled datasets.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8. 手动标记的数据集。
- en: '| Release year | Corpus | number of languages | number of participants | type
    of participant | type of query | type of codebase |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| 发布年份 | 语料库 | 语言数量 | 参与者数量 | 参与者类型 | 查询类型 | 代码库类型 |'
- en: '| 2018 | StaQC (Yao et al., [2018](#bib.bib96)) | 2 | 4 | undergraduate student
    | question in SO post | answer in SO post |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | StaQC (Yao 等, [2018](#bib.bib96)) | 2 | 4 | 本科生 | SO 文章中的问题 | SO 文章中的回答
    |'
- en: '| 2018 | CoNaLa (Yin et al., [2018](#bib.bib98)) | 2 | 5 | researcher and programmer
    | question in SO post | answer in SO post |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | CoNaLa (Yin 等, [2018](#bib.bib98)) | 2 | 5 | 研究员和程序员 | SO 文章中的问题 |
    SO 文章中的回答 |'
- en: '| 2018 | Java-50 (Gu et al., [2018](#bib.bib24)) | 1 | 2 | programmer | question
    in SO post | code in GitHub |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | Java-50 (Gu 等, [2018](#bib.bib24)) | 1 | 2 | 程序员 | SO 文章中的问题 | GitHub
    上的代码 |'
- en: '| 2019 | FB-Java (Li et al., [2019](#bib.bib43)) | 1 | unknown | unknown |
    question in SO post | answer in SO post |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | FB-Java (Li 等, [2019](#bib.bib43)) | 1 | 未知 | 未知 | SO 文章中的问题 | SO
    文章中的回答 |'
- en: '| 2019 | CSN-99 (Husain et al., [2019](#bib.bib36)) | 6 | unknown | programmer
    | query from Bing | code in GitHub |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | CSN-99 (Husain 等, [2019](#bib.bib36)) | 6 | 未知 | 程序员 | 从 Bing 的查询
    | GitHub 上的代码 |'
- en: '| 2020 | CosBench (Yan et al., [2020](#bib.bib93)) | 1 | unknown | unknown
    | question in SO post | answer in SO post and code in GitHub |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | CosBench (Yan 等, [2020](#bib.bib93)) | 1 | 未知 | 未知 | SO 文章中的问题 | SO
    文章中的回答和 GitHub 上的代码 |'
- en: '| 2020 | WebQueryTest (Lu et al., [2021](#bib.bib55)) | 1 | 13 | programmer
    | query from Bing | code in GitHub |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | WebQueryTest (Lu 等, [2021](#bib.bib55)) | 1 | 13 | 程序员 | 从 Bing 的查询
    | GitHub 上的代码 |'
- en: '| 2021 | CoSQA (Huang et al., [2021](#bib.bib34)) | 1 | more than 100 | programmer
    | query from Bing | code in GitHub |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | CoSQA (Huang 等, [2021](#bib.bib34)) | 1 | 超过 100 | 程序员 | 从 Bing 的查询
    | GitHub 上的代码 |'
- en: We present a detailed analysis of the manually annotated datasets in Table [8](#S6.T8
    "Table 8 ‣ 6.1\. Code Search Datasets ‣ 6\. Datasets and Evaluation (RQ4) ‣ Survey
    of Code Search Based on Deep Learning"). Our findings reveal that within these
    datasets, the queries predominantly originate from questions in Stack Overflow
    (SO) posts, closely followed by real queries entered by users in the Bing search
    engine. In comparison to source code comments, both of these queries bear a closer
    resemblance to queries encountered in real search scenarios. Notably, the primary
    source of code in the codebase is the open-source code repository, Github. Moreover,
    code embodies knowledge within the professional realm, thereby necessitating the
    involvement of programmers in the annotation process. This factor significantly
    escalates the costs associated with code annotation.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在表[8](#S6.T8 "表8 ‣ 6.1\. 代码搜索数据集 ‣ 6\. 数据集与评估（RQ4） ‣ 基于深度学习的代码搜索调查")中详细分析了手动标注的数据集。我们的发现揭示，在这些数据集中，查询主要来源于Stack
    Overflow（SO）帖子中的问题，其次是用户在Bing搜索引擎中输入的真实查询。与源代码注释相比，这两种查询与实际搜索场景中的查询更为相似。值得注意的是，代码库中的主要代码来源是开源代码仓库Github。此外，代码体现了专业领域的知识，因此需要程序员参与标注过程。这一因素显著增加了代码标注的成本。
- en: '![Refer to caption](img/267430d6a636f3a784867850fb135812.png)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/267430d6a636f3a784867850fb135812.png)'
- en: (a) Data source
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: （a）数据来源
- en: '![Refer to caption](img/a08177de53cf047e2867da379283b5c4.png)'
  id: totrans-391
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a08177de53cf047e2867da379283b5c4.png)'
- en: (b) Programming language
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: （b）编程语言
- en: Figure 8. Data source and programming language of the datasets.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 图8. 数据集的数据来源和编程语言。
- en: 'Based on the analysis above, there are three main challenges in the current
    code search datasets: (1) Inconsistency between training data and real user queries.
    The existing datasets primarily consist of (question, code) pairs, (document,
    code) pairs, and (comment, code) pairs. However, there is a discrepancy between
    the query text input by a user in the search engine and the text found in a question
    on Stack Overflow or a document/comment in the source code, leading to a poor
    performance of the trained model in real-world scenarios. (2) Scarcity of high-quality
    labeled data. Due to the high cost of code labeling, the existing datasets are
    mainly manually labeled in the evaluation set, and there is a shortage of a large
    number of manually labeled training sets, restricting the training of supervised
    learning models. (3) Limited data volume. The number of training data in existing
    datasets is limited and currently only reaches a few million, which is insufficient
    for training large-scale code understanding pre-training models. Although Markovtsev
    and Long (Markovtsev and Long, [2018](#bib.bib58)) selected 182,014 repositories
    from Github to create the first large-scale public code dataset for large-scale
    programming analysis, it is currently not accessible. In the future, obtaining
    a large-scale code corpus from Google BigQuery, which collects active data on
    GitHub including complete snapshots of over one million open source repositories
    and hundreds of millions of code submissions, may be explored.'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 基于上述分析，目前代码搜索数据集中主要存在三大挑战：（1）训练数据与真实用户查询之间的不一致。现有数据集主要包含（问题，代码）对，（文档，代码）对和（评论，代码）对。然而，用户在搜索引擎中输入的查询文本与在Stack
    Overflow中的问题或源代码中的文档/评论中的文本存在差异，导致训练模型在实际场景中的表现不佳。（2）高质量标注数据的稀缺。由于代码标注成本高昂，现有数据集主要在评估集上进行手动标注，且缺乏大量手动标注的训练集，限制了监督学习模型的训练。（3）数据量有限。现有数据集中的训练数据数量有限，目前仅达到几百万，这对于训练大规模的代码理解预训练模型来说还不够。尽管Markovtsev和Long（Markovtsev和Long，[2018](#bib.bib58)）从Github中选择了182,014个仓库来创建第一个大规模公开代码数据集以进行大规模编程分析，但该数据集目前无法访问。未来，获取来自Google
    BigQuery的大规模代码语料库，Google BigQuery收集了Github上的活跃数据，包括超过一百万个开源仓库的完整快照和数亿条代码提交，可能是一个值得探索的方向。
- en: 6.2\. Evaluation Metrics
  id: totrans-395
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2\. 评估指标
- en: Code search evaluation datasets typically include carefully selected queries
    and annotated functions. The purpose of evaluating a code search model is to assess
    its ability to accurately retrieve relevant code snippets from the codebase in
    response to a given natural language query. The evaluation of code search models
    is largely conducted through automatic methods. Common metrics used in recent
    studies for evaluating code search models include Precision, Recall, F1-score,
    MAP, MRR, Frank, and SuccessRate.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 代码搜索评估数据集通常包括精心挑选的查询和标注函数。评估代码搜索模型的目的是评估其从代码库中准确检索相关代码片段的能力。代码搜索模型的评估主要通过自动化方法进行。近年来用于评估代码搜索模型的常见指标包括
    Precision、Recall、F1-score、MAP、MRR、Frank 和 SuccessRate。
- en: '![Refer to caption](img/b2baf4b95c95b4bb22170c733c3ba6de.png)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/b2baf4b95c95b4bb22170c733c3ba6de.png)'
- en: Figure 9. Schematic diagram of $top@k$ and $hit@k$.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9. $top@k$ 和 $hit@k$ 的示意图。
- en: Assume that a given set of queries to be executed, denoted as $Q=\left[q_{1},q_{2},\ldots,q_{n}\right]$,
    and each query is marked with its corresponding set of ground-truth answers $G$.
    As depicted in Figure [9](#S6.F9 "Figure 9 ‣ 6.2\. Evaluation Metrics ‣ 6\. Datasets
    and Evaluation (RQ4) ‣ Survey of Code Search Based on Deep Learning"), $top@k$
    represents the top-$k$ result sets returned for a particular query, and $hit@k$
    refers to the answer set among the top-$k$ results that correctly belongs to the
    ground-truth answer.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有一组查询，记作 $Q=\left[q_{1},q_{2},\ldots,q_{n}\right]$，每个查询都有其对应的真实答案集 $G$。如图
    [9](#S6.F9 "Figure 9 ‣ 6.2\. Evaluation Metrics ‣ 6\. Datasets and Evaluation
    (RQ4) ‣ Survey of Code Search Based on Deep Learning") 所示，$top@k$ 代表特定查询返回的前-$k$
    结果集，$hit@k$ 指的是前-$k$ 结果中正确属于真实答案的答案集。
- en: 'Precision@k is a metric that shows the relationship between the results of
    a query and the ground-truth set. It measures, on average, how many of the top
    $k$ results returned by a query belong to the ground-truth set for a query set
    $Q$. The higher the value of $Precision@k$, the stronger the correlation between
    the returned results and the query. It is calculated as follows:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: Precision@k 是一个衡量查询结果与真实答案集之间关系的指标。它测量了查询返回的前 $k$ 个结果中，平均有多少属于查询集 $Q$ 的真实答案集。$Precision@k$
    值越高，返回结果与查询的相关性越强。计算方法如下：
- en: '| (24) |  | $Precision@k=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}\frac{\mid
    Hit@k\left(q_{i}\right)\mid}{k}.$ |  |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| (24) |  | $Precision@k=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}\frac{\mid
    Hit@k\left(q_{i}\right)\mid}{k}.$ |  |'
- en: 'Recall@k indicates the average percentage of the ground-truth answer set for
    each query that is hit. The higher the $Recall@k$ value, the more ground-truth
    answers are retrieved. It is calculated as follows:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: Recall@k 表示每个查询中真实答案集的平均命中百分比。$Recall@k$ 值越高，检索到的真实答案越多。计算方法如下：
- en: '| (25) |  | $Recall@k=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}\frac{\mid
    Hit@k\left(q_{i}\right)\mid}{\left&#124;G_{i}\right&#124;}.$ |  |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| (25) |  | $Recall@k=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}\frac{\mid
    Hit@k\left(q_{i}\right)\mid}{\left&#124;G_{i}\right&#124;}.$ |  |'
- en: 'F1-Score is employed to evaluate the performance of a model when both precision
    and recall carry equal weight. It is calculated as follows:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: F1-Score 用于评估模型在精度和召回率等权重下的表现。计算方法如下：
- en: '| (26) |  | $F1-Score=\frac{2\cdot Precision\cdot Recall}{Precision+Recall}.$
    |  |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| (26) |  | $F1-Score=\frac{2\cdot Precision\cdot Recall}{Precision+Recall}.$
    |  |'
- en: 'MAP@k, which stands for Mean Average Precision, reflects the average precision
    of the rankings produced by all queries. It is calculated as follows:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: MAP@k，即平均准确率，反映了所有查询产生的排名的平均准确度。计算方法如下：
- en: '| (27) |  | $MAP@k=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}\frac{1}{m}\sum_{j=1}^{m}\frac{j}{{rank}\left({hit}_{j},{Top@k}\left(q_{i}\right)\right)},$
    |  |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| (27) |  | $MAP@k=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}\frac{1}{m}\sum_{j=1}^{m}\frac{j}{{rank}\left({hit}_{j},{Top@k}\left(q_{i}\right)\right)},$
    |  |'
- en: where $m$ is $|Hit@k|$, $hit_{j}$ is an element in $Hit@k$, and ${rank}(e,l)$
    is the rank (i.e., index) of element $e$ in list $l$. When $\left|Hit@k\left(q_{i}\right)\right|=0$,
    $hit_{j}$ does not exist, and the average precision of query $q$ is 0. It is evident
    that a larger $MAP@k$ value signifies that a greater number of answers that hit
    the ground-truth are present in the top-$k$ results returned.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $m$ 是 $|Hit@k|$，$hit_{j}$ 是 $Hit@k$ 中的一个元素，而 ${rank}(e,l)$ 是元素 $e$ 在列表 $l$
    中的排名（即索引）。当 $\left|Hit@k\left(q_{i}\right)\right|=0$ 时，$hit_{j}$ 不存在，查询 $q$ 的平均准确度为
    0。显然，$MAP@k$ 值越大，表示返回的前-$k$ 结果中命中真实答案的数量越多。
- en: 'MRR@k, which stands for Mean Reciprocal Rank, indicates the average of the
    reciprocals of the rankings of all search results. It is calculated as follows:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: MRR@k（Mean Reciprocal Rank）表示所有搜索结果排名倒数的平均值。计算方法如下：
- en: '| (28) |  | $MRR@k=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}\frac{1}{{rank}\left({hit}_{1},{Top@k}\left(q_{i}\right)\right)}.$
    |  |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| (28) |  | $MRR@k=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}\frac{1}{{rank}\left({hit}_{1},{Top@k}\left(q_{i}\right)\right)}.$
    |  |'
- en: When $\left|Hit@k\left(q_{i}\right)\right|=0$, the reciprocal of the ranking
    is 0. Typically, only the first answer that hits the ground-truth is taken into
    account when calculating $MRR@k$. The greater the $MRR@k$ value, the higher the
    ranking of the answer that hits the ground-truth in $Top@k$.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 当$\left|Hit@k\left(q_{i}\right)\right|=0$时，排名的倒数为0。通常，在计算$MRR@k$时，只考虑第一个击中真实答案的答案。$MRR@k$值越大，击中真实答案的答案在$Top@k$中的排名越高。
- en: 'Frank@k represents the average rank of the first hit answer across all queries.
    It is calculated as follows:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: Frank@k表示在所有查询中第一个击中答案的平均排名。计算方法如下：
- en: '| (29) |  | $Frank@k=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}{rank}\left({hit}_{1}\left(q_{i}\right),{Top@k}\left(q_{i}\right)\right).$
    |  |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| (29) |  | $Frank@k=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}{rank}\left({hit}_{1}\left(q_{i}\right),{Top@k}\left(q_{i}\right)\right).$
    |  |'
- en: It is evident that a smaller $Frank@k$ value corresponds to a higher ranking
    of the ground-truth answer in the search results.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，较小的$Frank@k$值对应于真实答案在搜索结果中的更高排名。
- en: 'SuccessRate@k indicates the proportion of queries for which there are more
    than one ground-truth answers among the top-$k$ results returned. It is calculated
    as follows:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: SuccessRate@k表示返回的前-$k$结果中存在多个真实答案的查询的比例。计算方法如下：
- en: '| (30) |  | $SuccessRate@k=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}\tau\left({Frank}_{q_{i}}\leq
    k\right),$ |  |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| (30) |  | $SuccessRate@k=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}\tau\left({Frank}_{q_{i}}\leq
    k\right),$ |  |'
- en: where $\tau$ is an indicator function that returns 1 when the ranking of the
    hit answer for query $q_{i}$ is less than $k$ and 0 otherwise. $SuccessRate@k$
    is a crucial evaluation metric because an effective code search engine should
    enable software developers to find the desired code snippets by examining fewer
    results.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\tau$是一个指示函数，当查询$q_{i}$的击中答案的排名小于$k$时返回1，否则返回0。$SuccessRate@k$是一个重要的评估指标，因为一个有效的代码搜索引擎应使软件开发人员通过检查较少的结果找到所需的代码片段。
- en: 'NDCG, which stands for Normalized Discounted Cumulative Gain, serves as a crucial
    metric to quantify the similarity between the ranking of candidate code fragments
    and the ideal ranking, placing significant emphasis on the overall ranking order
    among all candidate results. It is calculated as follows:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: NDCG（Normalized Discounted Cumulative Gain）是一个重要的指标，用于量化候选代码片段排名与理想排名之间的相似性，强调所有候选结果中的整体排名顺序。计算方法如下：
- en: '| (31) |  | $NDCG=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{k}\frac{2^{r_{i}}-1}{\log_{2}(i+1)},$
    |  |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| (31) |  | $NDCG=\frac{1}{&#124;Q&#124;}\sum_{i=1}^{k}\frac{2^{r_{i}}-1}{\log_{2}(i+1)},$
    |  |'
- en: where $r_{i}$ is the relevance score of the top-$k$ results at position $i$.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$r_{i}$是位置$i$处的前-$k$结果的相关性得分。
- en: Table [9](#S6.T9 "Table 9 ‣ 6.2\. Evaluation Metrics ‣ 6\. Datasets and Evaluation
    (RQ4) ‣ Survey of Code Search Based on Deep Learning") provides an in-depth analysis
    of 53 deep learning-based code search models, encompassing the evaluated datasets,
    the baseline model utilized for comparison, and the selected evaluation metrics.
    Figure [10](#S6.F10 "Figure 10 ‣ 6.2\. Evaluation Metrics ‣ 6\. Datasets and Evaluation
    (RQ4) ‣ Survey of Code Search Based on Deep Learning") highlights that the CSN
    dataset holds prominence in the code search task, while the most widely adopted
    evaluation metric is MRR@k, with a utilization rate of 90.6%.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 表[9](#S6.T9 "Table 9 ‣ 6.2\. Evaluation Metrics ‣ 6\. Datasets and Evaluation
    (RQ4) ‣ Survey of Code Search Based on Deep Learning")对53种基于深度学习的代码搜索模型进行了深入分析，包括评估的数据集、用于比较的基线模型以及选择的评估指标。图[10](#S6.F10
    "Figure 10 ‣ 6.2\. Evaluation Metrics ‣ 6\. Datasets and Evaluation (RQ4) ‣ Survey
    of Code Search Based on Deep Learning")突显了CSN数据集在代码搜索任务中的重要性，而最广泛采用的评估指标是MRR@k，使用率为90.6%。
- en: Table 9. Deep code search models and their performance metrics.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 表9. 深度代码搜索模型及其性能指标。
- en: '| Year | Models | Dataset | Baselines | Metric |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| 年份 | 模型 | 数据集 | 基线 | 指标 |'
- en: '| 2018 | CODEnn (Gu et al., [2018](#bib.bib24)) | Gu et al. (Gu et al., [2018](#bib.bib24))
    | CodeHow (Lv et al., [2015](#bib.bib56)) | Frank@k, Precision@k, MRR@k, SuccessRate@k
    |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | CODEnn（Gu 等，[2018](#bib.bib24)） | Gu 等（Gu 等，[2018](#bib.bib24)） |
    CodeHow（Lv 等，[2015](#bib.bib56)） | Frank@k，Precision@k，MRR@k，SuccessRate@k |'
- en: '| 2018 | NCS (Sachdev et al., [2018](#bib.bib69)) | Sachdev et al. (Sachdev
    et al., [2018](#bib.bib69)) | TF-IDF, BM25 | Precision@k |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | NCS（Sachdev 等，[2018](#bib.bib69)） | Sachdev 等（Sachdev 等，[2018](#bib.bib69)）
    | TF-IDF，BM25 | Precision@k |'
- en: '| 2018 | NLP2API (Rahman and Roy, [2018](#bib.bib67)) | Rahman and Roy (Rahman
    and Roy, [2018](#bib.bib67)) | Rahman and Roy(Rahman and Roy, [2018](#bib.bib67))
    | Precision@k, MRR@K, MAP@K, Recall@K, Frank@k |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | NLP2API（Rahman 和 Roy，[2018](#bib.bib67)） | Rahman 和 Roy（Rahman 和 Roy，[2018](#bib.bib67)）
    | Rahman 和 Roy（Rahman 和 Roy，[2018](#bib.bib67)） | Precision@k，MRR@K，MAP@K，Recall@K，Frank@k
    |'
- en: '| 2018 | COCABU (Sirres et al., [2018](#bib.bib73)) | Sirres et al. (Sirres
    et al., [2018](#bib.bib73)) | Codota, OpenHub | Precision@k, MRR@k |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | COCABU（Sirres 等，[2018](#bib.bib73)） | Sirres 等（Sirres 等，[2018](#bib.bib73)）
    | Codota，OpenHub | Precision@k，MRR@k |'
- en: '| 2018 | Zhang et al. (Zhang et al., [2018](#bib.bib100)) | Zhang et al. (Zhang
    et al., [2018](#bib.bib100)) | Dice, Rocchio, RSV | MRR@k, SuccessRate@k |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | Zhang 等（Zhang 等，[2018](#bib.bib100)） | Zhang 等（Zhang 等，[2018](#bib.bib100)）
    | Dice，Rocchio，RSV | MRR@k，SuccessRate@k |'
- en: '| 2019 | UNIF (Cambronero et al., [2019](#bib.bib7)) | Gu et al. (Gu et al.,
    [2018](#bib.bib24)) | CODEnn (Gu et al., [2018](#bib.bib24)), NCS (Sachdev et al.,
    [2018](#bib.bib69)) | SuccessRate@k |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | UNIF（Cambronero 等，[2019](#bib.bib7)） | Gu 等（Gu 等，[2018](#bib.bib24)）
    | CODEnn（Gu 等，[2018](#bib.bib24)），NCS（Sachdev 等，[2018](#bib.bib69)） | SuccessRate@k
    |'
- en: '| 2019 | MMAN (Wan et al., [2019](#bib.bib79)) | Wan et al. (Wan et al., [2019](#bib.bib79))
    | CodeHow (Lv et al., [2015](#bib.bib56)), CODEnn (Gu et al., [2018](#bib.bib24))
    | MRR@k, SuccessRate@k |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | MMAN（Wan 等，[2019](#bib.bib79)） | Wan 等（Wan 等，[2019](#bib.bib79)） |
    CodeHow（Lv 等，[2015](#bib.bib56)），CODEnn（Gu 等，[2018](#bib.bib24)） | MRR@k，SuccessRate@k
    |'
- en: '| 2019 | RACK (Rahman et al., [2019](#bib.bib68)) | Rahman (Rahman et al.,
    [2019](#bib.bib68)) | NL Keywords (Rahman et al., [2019](#bib.bib68)) | Precision@k,
    MRR@K, MAP@K, Recall@K, NDCG, Frank@k |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | RACK（Rahman 等，[2019](#bib.bib68)） | Rahman（Rahman 等，[2019](#bib.bib68)）
    | NL Keywords（Rahman 等，[2019](#bib.bib68)） | Precision@k，MRR@K，MAP@K，Recall@K，NDCG，Frank@k
    |'
- en: '| 2019 | Rahman (Rahman, [2019](#bib.bib66)) | Rahman (Rahman, [2019](#bib.bib66))
    | - | Hit@K, MAP@k, MRR@k, Recall@k, Frank@k |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | Rahman（Rahman，[2019](#bib.bib66)） | Rahman（Rahman，[2019](#bib.bib66)）
    | - | Hit@K，MAP@k，MRR@k，Recall@k，Frank@k |'
- en: '| 2019 | NQE (Liu et al., [2019a](#bib.bib52)) | Liu et al. (Liu et al., [2019a](#bib.bib52))
    | BM25, NCS (Sachdev et al., [2018](#bib.bib69)) | Precision@k, MRR@k |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | NQE（Liu 等，[2019a](#bib.bib52)） | Liu 等（Liu 等，[2019a](#bib.bib52)）
    | BM25，NCS（Sachdev 等，[2018](#bib.bib69)） | Precision@k，MRR@k |'
- en: '| 2019 | QESC (Huang et al., [2019](#bib.bib35)) | Huang et al. (Huang et al.,
    [2019](#bib.bib35)) | CodeHow (Lv et al., [2015](#bib.bib56)), QECK (Nie et al.,
    [2016](#bib.bib61)) | Precision@k, NDCG |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | QESC（Huang 等，[2019](#bib.bib35)） | Huang 等（Huang 等，[2019](#bib.bib35)）
    | CodeHow（Lv 等，[2015](#bib.bib56)），QECK（Nie 等，[2016](#bib.bib61)） | Precision@k，NDCG
    |'
- en: '| 2019 | CoaCor (Yao et al., [2019](#bib.bib95)) | StaQC (Yao et al., [2018](#bib.bib96)),
    DEV and EVAL (Iyer et al., [2016](#bib.bib37)) | CODEnn (Gu et al., [2018](#bib.bib24)),
    CODE-NN (Iyer et al., [2016](#bib.bib37)) | MRR@k |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | CoaCor（Yao 等，[2019](#bib.bib95)） | StaQC（Yao 等，[2018](#bib.bib96)），DEV
    和 EVAL（Iyer 等，[2016](#bib.bib37)） | CODEnn（Gu 等，[2018](#bib.bib24)），CODE-NN（Iyer
    等，[2016](#bib.bib37)） | MRR@k |'
- en: '| 2019 | Wu and Yang (Wu and Yang, [2019](#bib.bib91)) | Wu and Yang (Wu and
    Yang, [2019](#bib.bib91)) | CodeHow (Lv et al., [2015](#bib.bib56)) | Precision@k,
    NDCG |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | Wu 和 Yang（Wu 和 Yang，[2019](#bib.bib91)） | Wu 和 Yang（Wu 和 Yang，[2019](#bib.bib91)）
    | CodeHow（Lv 等，[2015](#bib.bib56)） | Precision@k，NDCG |'
- en: '| 2020 | OCoR (Zhu et al., [2020](#bib.bib104)) | StaQC (Yao et al., [2018](#bib.bib96)),
    DEV and EVAL (Iyer et al., [2016](#bib.bib37)) | CODEnn (Gu et al., [2018](#bib.bib24)),
    CODE-NN (Iyer et al., [2016](#bib.bib37)), CoaCor (Yao et al., [2019](#bib.bib95))
    | MRR@k |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | OCoR（Zhu 等，[2020](#bib.bib104)） | StaQC（Yao 等，[2018](#bib.bib96)），DEV
    和 EVAL（Iyer 等，[2016](#bib.bib37)） | CODEnn（Gu 等，[2018](#bib.bib24)），CODE-NN（Iyer
    等，[2016](#bib.bib37)），CoaCor（Yao 等，[2019](#bib.bib95)） | MRR@k |'
- en: '| 2020 | CodeBERT (Feng et al., [2020](#bib.bib18)) | CSN (Husain et al., [2019](#bib.bib36))
    | NBoW, 1D-CNN, biRNN, SelfAtt, RoBERTa(code) | MRR@k |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | CodeBERT（Feng 等，[2020](#bib.bib18)） | CSN（Husain 等，[2019](#bib.bib36)）
    | NBoW，1D-CNN，biRNN，SelfAtt，RoBERTa(code) | MRR@k |'
- en: '| 2020 | AdaCS (Ling et al., [2020](#bib.bib49)) | Ling et al. (Ling et al.,
    [2020](#bib.bib49)) | CodeHow (Lv et al., [2015](#bib.bib56)), CODEnn (Gu et al.,
    [2018](#bib.bib24)), BVAE (Chen and Zhou, [2018](#bib.bib12)) | Hit@K, MRR@k |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | AdaCS（Ling 等，[2020](#bib.bib49)） | Ling 等（Ling 等，[2020](#bib.bib49)）
    | CodeHow（Lv 等，[2015](#bib.bib56)），CODEnn（Gu 等，[2018](#bib.bib24)），BVAE（Chen 和
    Zhou，[2018](#bib.bib12)） | Hit@K，MRR@k |'
- en: '| 2020 | MP-CAT (Haldar et al., [2020](#bib.bib27)) | CoNaLa (Yin et al., [2018](#bib.bib98))
    | CT | Recall@k, MRR@k |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | MP-CAT (Haldar et al., [2020](#bib.bib27)) | CoNaLa (Yin et al., [2018](#bib.bib98))
    | CT | Recall@k, MRR@k |'
- en: '| 2020 | ${TranS}^{3}$ (Wang et al., [2020](#bib.bib86)) | Barone and Sennrich
    (Barone and Sennrich, [2017](#bib.bib4)) | CODEnn (Gu et al., [2018](#bib.bib24)),
    CoaCor (Yao et al., [2019](#bib.bib95)), Hybrid-DeepCom (Hu et al., [2020](#bib.bib33)),
    AutoSum (Wan et al., [2018](#bib.bib82)) | MRR@k, NDCG, SuccessRate@k |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | ${TranS}^{3}$ (Wang et al., [2020](#bib.bib86)) | Barone and Sennrich
    (Barone and Sennrich, [2017](#bib.bib4)) | CODEnn (Gu et al., [2018](#bib.bib24)),
    CoaCor (Yao et al., [2019](#bib.bib95)), Hybrid-DeepCom (Hu et al., [2020](#bib.bib33)),
    AutoSum (Wan et al., [2018](#bib.bib82)) | MRR@k, NDCG, SuccessRate@k |'
- en: '| 2020 | Zhao and Sun (Zhao and Sun, [2020](#bib.bib102)) | StaQC (Yao et al.,
    [2018](#bib.bib96)) | CODEnn (Gu et al., [2018](#bib.bib24)), CoaCor (Yao et al.,
    [2019](#bib.bib95)) | MAP@k, NDCG |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | Zhao and Sun (Zhao and Sun, [2020](#bib.bib102)) | StaQC (Yao et al.,
    [2018](#bib.bib96)) | CODEnn (Gu et al., [2018](#bib.bib24)), CoaCor (Yao et al.,
    [2019](#bib.bib95)) | MAP@k, NDCG |'
- en: '| 2020 | CO3 (Ye et al., [2020](#bib.bib97)) | StaQC (Yao et al., [2018](#bib.bib96))
    | CODEnn (Gu et al., [2018](#bib.bib24)), CoaCor (Yao et al., [2019](#bib.bib95))
    | MRR@k, NDCG |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | CO3 (Ye et al., [2020](#bib.bib97)) | StaQC (Yao et al., [2018](#bib.bib96))
    | CODEnn (Gu et al., [2018](#bib.bib24)), CoaCor (Yao et al., [2019](#bib.bib95))
    | MRR@k, NDCG |'
- en: '| 2021 | GraphCodeBERT (Guo et al., [2021](#bib.bib26)) | CSN (Husain et al.,
    [2019](#bib.bib36)) | NBoW, 1D-CNN, biRNN, SelfAtt, RoBERTa(code), CodeBERT (Feng
    et al., [2020](#bib.bib18)) | MRR@k |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | GraphCodeBERT (Guo et al., [2021](#bib.bib26)) | CSN (Husain et al.,
    [2019](#bib.bib36)) | NBoW, 1D-CNN, biRNN, SelfAtt, RoBERTa(code), CodeBERT (Feng
    et al., [2020](#bib.bib18)) | MRR@k |'
- en: '| 2021 | DGMS (Ling et al., [2021](#bib.bib50)) | FB-Java (Li et al., [2019](#bib.bib43)),
    CSN-Python (Husain et al., [2019](#bib.bib36)) | NBoW, 1D-CNN, biRNN, SelfAtt,
    CODEnn (Gu et al., [2018](#bib.bib24)), UNIF (Cambronero et al., [2019](#bib.bib7)),
    CAT (Haldar et al., [2020](#bib.bib27)) | MRR@k, SuccessRate@k |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | DGMS (Ling et al., [2021](#bib.bib50)) | FB-Java (Li et al., [2019](#bib.bib43)),
    CSN-Python (Husain et al., [2019](#bib.bib36)) | NBoW, 1D-CNN, biRNN, SelfAtt,
    CODEnn (Gu et al., [2018](#bib.bib24)), UNIF (Cambronero et al., [2019](#bib.bib7)),
    CAT (Haldar et al., [2020](#bib.bib27)) | MRR@k, SuccessRate@k |'
- en: '| 2021 | CoCLR (Huang et al., [2021](#bib.bib34)) | CoSQA (Huang et al., [2021](#bib.bib34)),
    WebQueryTest (Lu et al., [2021](#bib.bib55)) | RoBERTa (Liu et al., [2019b](#bib.bib54)),
    CodeBERT (Feng et al., [2020](#bib.bib18)) | MRR@k |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | CoCLR (Huang et al., [2021](#bib.bib34)) | CoSQA (Huang et al., [2021](#bib.bib34)),
    WebQueryTest (Lu et al., [2021](#bib.bib55)) | RoBERTa (Liu et al., [2019b](#bib.bib54)),
    CodeBERT (Feng et al., [2020](#bib.bib18)) | MRR@k |'
- en: '| 2021 | SEQUER (Cao et al., [2021](#bib.bib8)) | Cao et al. (Cao et al., [2021](#bib.bib8))
    | seq2seq (Sutskever et al., [2014](#bib.bib78)) | MRR@k |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | SEQUER (Cao et al., [2021](#bib.bib8)) | Cao et al. (Cao et al., [2021](#bib.bib8))
    | seq2seq (Sutskever et al., [2014](#bib.bib78)) | MRR@k |'
- en: '| 2021 | DOBF (Lachaux et al., [2021](#bib.bib42)) | CSN-Python (Husain et al.,
    [2019](#bib.bib36)) | CodeBERT (Feng et al., [2020](#bib.bib18)), GraphCodeBERT
    (Guo et al., [2021](#bib.bib26)) | MRR@k |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | DOBF (Lachaux et al., [2021](#bib.bib42)) | CSN-Python (Husain et al.,
    [2019](#bib.bib36)) | CodeBERT (Feng et al., [2020](#bib.bib18)), GraphCodeBERT
    (Guo et al., [2021](#bib.bib26)) | MRR@k |'
- en: '| 2021 | CRaDLe (Gu et al., [2021b](#bib.bib22)) | CSN (Husain et al., [2019](#bib.bib36))
    | CODEnn (Gu et al., [2018](#bib.bib24)), UNIF (Cambronero et al., [2019](#bib.bib7)),
    NBoW, 1D-CNN, biRNN, SelfAtt, ConvSelfAtt | MRR@k, SuccessRate@k |'
  id: totrans-449
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | CRaDLe (Gu et al., [2021b](#bib.bib22)) | CSN (Husain et al., [2019](#bib.bib36))
    | CODEnn (Gu et al., [2018](#bib.bib24)), UNIF (Cambronero et al., [2019](#bib.bib7)),
    NBoW, 1D-CNN, biRNN, SelfAtt, ConvSelfAtt | MRR@k, SuccessRate@k |'
- en: '| 2021 | Corder (Bui et al., [2021](#bib.bib5)) | Gu et al. (Gu et al., [2018](#bib.bib24))
    | NBoW, biRNN, SelfAtt, TBCNN (Mou et al., [2016](#bib.bib60)), Code2vec (Alon
    et al., [2019](#bib.bib2)) | Precision@k, MRR@k |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | Corder (Bui et al., [2021](#bib.bib5)) | Gu et al. (Gu et al., [2018](#bib.bib24))
    | NBoW, biRNN, SelfAtt, TBCNN (Mou et al., [2016](#bib.bib60)), Code2vec (Alon
    et al., [2019](#bib.bib2)) | Precision@k, MRR@k |'
- en: '| 2021 | Gu et al. (Gu et al., [2021a](#bib.bib21)) | CSN (Husain et al., [2019](#bib.bib36))
    | NBoW, 1D-CNN, biRNN, SelfAtt | MRR@k, NDCG |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | Gu et al. (Gu et al., [2021a](#bib.bib21)) | CSN (Husain et al., [2019](#bib.bib36))
    | NBoW, 1D-CNN, biRNN, SelfAtt | MRR@k, NDCG |'
- en: '| 2021 | TabCS (Xu et al., [2021](#bib.bib92)) | Hu et al. (Hu et al., [2020](#bib.bib33)),
    CSN (Husain et al., [2019](#bib.bib36)) | CODEnn (Gu et al., [2018](#bib.bib24)),
    CARLCS-CNN (Shuai et al., [2020](#bib.bib72)), CARLCS-TS (Shuai et al., [2020](#bib.bib72)),
    UNIF (Cambronero et al., [2019](#bib.bib7)) | MRR@k, SuccessRate@k |'
  id: totrans-452
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | TabCS (Xu et al., [2021](#bib.bib92)) | Hu et al. (Hu et al., [2020](#bib.bib33)),
    CSN (Husain et al., [2019](#bib.bib36)) | CODEnn (Gu et al., [2018](#bib.bib24)),
    CARLCS-CNN (Shuai et al., [2020](#bib.bib72)), CARLCS-TS (Shuai et al., [2020](#bib.bib72)),
    UNIF (Cambronero et al., [2019](#bib.bib7)) | MRR@k, SuccessRate@k |'
- en: '| 2021 | MuCoS (Du et al., [2021](#bib.bib16)) | CSN (Husain et al., [2019](#bib.bib36))
    | NBoW, 1D-CNN, biRNN, SelfAtt, ConvSelfAtt, CODEnn (Gu et al., [2018](#bib.bib24)),
    CodeBERT (Feng et al., [2020](#bib.bib18)) | MRR@k, SuccessRate@k |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | MuCoS (Du et al., [2021](#bib.bib16)) | CSN (Husain et al., [2019](#bib.bib36))
    | NBoW, 1D-CNN, biRNN, SelfAtt, ConvSelfAtt, CODEnn (Gu et al., [2018](#bib.bib24)),
    CodeBERT (Feng et al., [2020](#bib.bib18)) | MRR@k, SuccessRate@k |'
- en: '| 2021 | SynCoBERT (Wang et al., [2021b](#bib.bib87)) | CSN (Husain et al.,
    [2019](#bib.bib36)), AdvTest (Lu et al., [2021](#bib.bib55)) | NBow, CNN, BiRNN,
    SelfAttn, RoBERTa (Liu et al., [2019b](#bib.bib54)), RoBERTa(code), CodeBERT (Feng
    et al., [2020](#bib.bib18)), GraphCodeBERT (Guo et al., [2021](#bib.bib26)) |
    MRR@k |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | SynCoBERT (Wang et al., [2021b](#bib.bib87)) | CSN (Husain et al.,
    [2019](#bib.bib36)), AdvTest (Lu et al., [2021](#bib.bib55)) | NBow, CNN, BiRNN,
    SelfAttn, RoBERTa (Liu et al., [2019b](#bib.bib54)), RoBERTa(code), CodeBERT (Feng
    et al., [2020](#bib.bib18)), GraphCodeBERT (Guo et al., [2021](#bib.bib26)) |
    MRR@k |'
- en: '| 2022 | TranCS (Sun et al., [2022a](#bib.bib76)) | CSN-Java (Husain et al.,
    [2019](#bib.bib36)) | CODEnn (Gu et al., [2018](#bib.bib24)), MMAN (Wan et al.,
    [2019](#bib.bib79)) | MRR@k, SuccessRate@k |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | TranCS (Sun et al., [2022a](#bib.bib76)) | CSN-Java (Husain et al.,
    [2019](#bib.bib36)) | CODEnn (Gu et al., [2018](#bib.bib24)), MMAN (Wan et al.,
    [2019](#bib.bib79)) | MRR@k, SuccessRate@k |'
- en: '| 2022 | Wang et al. (Wang et al., [2022a](#bib.bib84)) | CSN (Husain et al.,
    [2019](#bib.bib36)) | NBoW, 1D-CNN, biRNN, SelfAtt, RoBERTa (Liu et al., [2019b](#bib.bib54)),
    RoBERTa(code), CodeBERT (Feng et al., [2020](#bib.bib18)), GraphCodeBERT (Guo
    et al., [2021](#bib.bib26)) | MRR@k |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | Wang et al. (Wang et al., [2022a](#bib.bib84)) | CSN (Husain et al.,
    [2019](#bib.bib36)) | NBoW, 1D-CNN, biRNN, SelfAtt, RoBERTa (Liu et al., [2019b](#bib.bib54)),
    RoBERTa(code), CodeBERT (Feng et al., [2020](#bib.bib18)), GraphCodeBERT (Guo
    et al., [2021](#bib.bib26)) | MRR@k |'
- en: '| 2022 | CodeRetriever (Li et al., [2022a](#bib.bib45)) | CSN (Husain et al.,
    [2019](#bib.bib36)), AdvTest (Lu et al., [2021](#bib.bib55)), CoSQA (Huang et al.,
    [2021](#bib.bib34)), CoNaLa (Yin et al., [2018](#bib.bib98)), SO-DS (Heyman and
    Cutsem, [2020](#bib.bib29)), StaQC (Yao et al., [2018](#bib.bib96)) | CodeBERT
    (Feng et al., [2020](#bib.bib18)), GraphCodeBERT (Guo et al., [2021](#bib.bib26)),
    SynCoBERT (Wang et al., [2021b](#bib.bib87)) | MRR@k |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CodeRetriever (Li et al., [2022a](#bib.bib45)) | CSN (Husain et al.,
    [2019](#bib.bib36)), AdvTest (Lu et al., [2021](#bib.bib55)), CoSQA (Huang et
    al., [2021](#bib.bib34)), CoNaLa (Yin et al., [2018](#bib.bib98)), SO-DS (Heyman
    and Cutsem, [2020](#bib.bib29)), StaQC (Yao et al., [2018](#bib.bib96)) | CodeBERT
    (Feng et al., [2020](#bib.bib18)), GraphCodeBERT (Guo et al., [2021](#bib.bib26)),
    SynCoBERT (Wang et al., [2021b](#bib.bib87)) | MRR@k |'
- en: '| 2022 | CDCS (Chai et al., [2022](#bib.bib9)) | CSN-Python (Husain et al.,
    [2019](#bib.bib36)), CSN-Java (Husain et al., [2019](#bib.bib36)), Solidity and
    SQL (Yang et al., [2021](#bib.bib94)) | Roberta (Liu et al., [2019b](#bib.bib54)),
    CodeBERT (Feng et al., [2020](#bib.bib18)) | MRR@k, SuccessRate@k |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CDCS (Chai et al., [2022](#bib.bib9)) | CSN-Python (Husain et al.,
    [2019](#bib.bib36)), CSN-Java (Husain et al., [2019](#bib.bib36)), Solidity and
    SQL (Yang et al., [2021](#bib.bib94)) | Roberta (Liu et al., [2019b](#bib.bib54)),
    CodeBERT (Feng et al., [2020](#bib.bib18)) | MRR@k, SuccessRate@k |'
- en: '| 2022 | CSRS (Cheng and Kuang, [2022](#bib.bib13)) | Gu et al. (Gu et al.,
    [2018](#bib.bib24)) | CODEnn (Gu et al., [2018](#bib.bib24)), CARLCS-CNN (Shuai
    et al., [2020](#bib.bib72)) | Recall@k, MRR@k, NDCG |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CSRS (Cheng and Kuang, [2022](#bib.bib13)) | Gu et al. (Gu et al.,
    [2018](#bib.bib24)) | CODEnn (Gu et al., [2018](#bib.bib24)), CARLCS-CNN (Shuai
    et al., [2020](#bib.bib72)) | Recall@k, MRR@k, NDCG |'
- en: '| 2022 | ${NS}^{3}$ (Arakelyan et al., [2022](#bib.bib3)) | CSN (Husain et al.,
    [2019](#bib.bib36)), CoSQA (Huang et al., [2021](#bib.bib34)) | BM25, RoBERTa(code),
    CuBERT (Kanade et al., [2020](#bib.bib38)), CodeBERT (Feng et al., [2020](#bib.bib18)),
    GraphCodeBERT (Guo et al., [2021](#bib.bib26)) | MRR@k, Precision@k |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | ${NS}^{3}$ (Arakelyan et al., [2022](#bib.bib3)) | CSN (Husain et
    al., [2019](#bib.bib36)), CoSQA (Huang et al., [2021](#bib.bib34)) | BM25, RoBERTa(code),
    CuBERT (Kanade et al., [2020](#bib.bib38)), CodeBERT (Feng et al., [2020](#bib.bib18)),
    GraphCodeBERT (Guo et al., [2021](#bib.bib26)) | MRR@k, Precision@k |'
- en: '| 2022 | CSSAM (Cai et al., [2023](#bib.bib6)) | Hu et al. (Hu et al., [2020](#bib.bib33)),
    CSN (Husain et al., [2019](#bib.bib36)) | CodeHow (Lv et al., [2015](#bib.bib56)),
    CODEnn (Gu et al., [2018](#bib.bib24)), MP-CAT (Haldar et al., [2020](#bib.bib27)),
    TabCS (Xu et al., [2021](#bib.bib92)) | MRR@k, SuccessRate@k, NDCG |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CSSAM (Cai et al., [2023](#bib.bib6)) | Hu et al. (Hu et al., [2020](#bib.bib33)),
    CSN (Husain et al., [2019](#bib.bib36)) | CodeHow (Lv et al., [2015](#bib.bib56)),
    CODEnn (Gu et al., [2018](#bib.bib24)), MP-CAT (Haldar et al., [2020](#bib.bib27)),
    TabCS (Xu et al., [2021](#bib.bib92)) | MRR@k, SuccessRate@k, NDCG |'
- en: '| 2022 | CTBERT (Han et al., [2022](#bib.bib28)) | CSN (Husain et al., [2019](#bib.bib36)),
    AdvTest (Lu et al., [2021](#bib.bib55)) | CodeBERT (Feng et al., [2020](#bib.bib18)),
    GraphCodeBERT (Guo et al., [2021](#bib.bib26)), SynCoBERT (Wang et al., [2021b](#bib.bib87))
    | MRR@k |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CTBERT (Han et al., [2022](#bib.bib28)) | CSN (Husain et al., [2019](#bib.bib36)),
    AdvTest (Lu et al., [2021](#bib.bib55)) | CodeBERT (Feng et al., [2020](#bib.bib18)),
    GraphCodeBERT (Guo et al., [2021](#bib.bib26)), SynCoBERT (Wang et al., [2021b](#bib.bib87))
    | MRR@k |'
- en: '| 2022 | QueCos (Wang et al., [2022b](#bib.bib83)) | CSN-Python (Husain et al.,
    [2019](#bib.bib36)), CSN-Java (Husain et al., [2019](#bib.bib36)), Wang et al.
    (Wang et al., [2022b](#bib.bib83)) | CODEnn (Gu et al., [2018](#bib.bib24)), UNIF
    (Cambronero et al., [2019](#bib.bib7)), OCoR (Zhu et al., [2020](#bib.bib104))
    | MRR@k, SuccessRate@k |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | QueCos（Wang et al., [2022b](#bib.bib83)) | CSN-Python（Husain et al.,
    [2019](#bib.bib36)），CSN-Java（Husain et al., [2019](#bib.bib36)），Wang 等（Wang et
    al., [2022b](#bib.bib83)） | CODEnn（Gu et al., [2018](#bib.bib24)），UNIF（Cambronero
    et al., [2019](#bib.bib7)），OCoR（Zhu et al., [2020](#bib.bib104)） | MRR@k, SuccessRate@k
    |'
- en: '| 2022 | ZaCQ (Eberhart and McMillan, [2022](#bib.bib17)) | CSN (Husain et al.,
    [2019](#bib.bib36)) | V-DO, KW | MRR@k, MAP@k, NDCG |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | ZaCQ（Eberhart 和 McMillan, [2022](#bib.bib17)) | CSN（Husain et al.,
    [2019](#bib.bib36)) | V-DO, KW | MRR@k, MAP@k, NDCG |'
- en: '| 2022 | G2SC (Shi et al., [2022](#bib.bib71)) | CSN (Husain et al., [2019](#bib.bib36))
    | CODEnn (Gu et al., [2018](#bib.bib24)), MMAN (Wan et al., [2019](#bib.bib79)),
    CodeBERT (Feng et al., [2020](#bib.bib18)), GraphCodeBERT (Guo et al., [2021](#bib.bib26))
    | MRR@k |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | G2SC（Shi et al., [2022](#bib.bib71)) | CSN（Husain et al., [2019](#bib.bib36))
    | CODEnn（Gu et al., [2018](#bib.bib24)），MMAN（Wan et al., [2019](#bib.bib79)），CodeBERT（Feng
    et al., [2020](#bib.bib18)），GraphCodeBERT（Guo et al., [2021](#bib.bib26)） | MRR@k
    |'
- en: '| 2022 | SPT-Code (Niu et al., [2022](#bib.bib62)) | CSN (Husain et al., [2019](#bib.bib36))
    | CNN, Bi-GRU, SelfAtt, CodeBERT (Feng et al., [2020](#bib.bib18)), GraphCodeBERT
    (Guo et al., [2021](#bib.bib26)) | MRR@k |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | SPT-Code（Niu et al., [2022](#bib.bib62)) | CSN（Husain et al., [2019](#bib.bib36))
    | CNN, Bi-GRU, SelfAtt, CodeBERT（Feng et al., [2020](#bib.bib18)），GraphCodeBERT（Guo
    et al., [2021](#bib.bib26)） | MRR@k |'
- en: '| 2022 | CODE-MVP (Wang et al., [2022c](#bib.bib88)) | AdvTest (Lu et al.,
    [2021](#bib.bib55)), CoNaLa (Yin et al., [2018](#bib.bib98)), CoSQA (Huang et al.,
    [2021](#bib.bib34)) | RoBERTa (Liu et al., [2019b](#bib.bib54)), CodeBERT (Feng
    et al., [2020](#bib.bib18)), GraphCodeBERT (Guo et al., [2021](#bib.bib26)), SynCoBERT
    (Wang et al., [2021b](#bib.bib87)) | MRR@k |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | CODE-MVP（Wang et al., [2022c](#bib.bib88)) | AdvTest（Lu et al., [2021](#bib.bib55)），CoNaLa（Yin
    et al., [2018](#bib.bib98)），CoSQA（Huang et al., [2021](#bib.bib34)） | RoBERTa（Liu
    et al., [2019b](#bib.bib54)），CodeBERT（Feng et al., [2020](#bib.bib18)），GraphCodeBERT（Guo
    et al., [2021](#bib.bib26)），SynCoBERT（Wang et al., [2021b](#bib.bib87)） | MRR@k
    |'
- en: '| 2022 | UniXcoder (Guo et al., [2022](#bib.bib25)) | CSN (Husain et al., [2019](#bib.bib36)),
    AdvTest (Lu et al., [2021](#bib.bib55)), CoSQA (Huang et al., [2021](#bib.bib34))
    | RoBERTa (Liu et al., [2019b](#bib.bib54)), CodeBERT (Feng et al., [2020](#bib.bib18)),
    GraphCodeBERT (Guo et al., [2021](#bib.bib26)), SynCoBERT (Wang et al., [2021b](#bib.bib87))
    | MRR@k |'
  id: totrans-468
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | UniXcoder（Guo et al., [2022](#bib.bib25)) | CSN（Husain et al., [2019](#bib.bib36)），AdvTest（Lu
    et al., [2021](#bib.bib55)），CoSQA（Huang et al., [2021](#bib.bib34)） | RoBERTa（Liu
    et al., [2019b](#bib.bib54)），CodeBERT（Feng et al., [2020](#bib.bib18)），GraphCodeBERT（Guo
    et al., [2021](#bib.bib26)），SynCoBERT（Wang et al., [2021b](#bib.bib87)） | MRR@k
    |'
- en: '| 2022 | Li et al. (Li et al., [2022d](#bib.bib44)) | CSN (Husain et al., [2019](#bib.bib36))
    | RoBERTa(code), CodeBERT (Feng et al., [2020](#bib.bib18)), GraphCodeBERT (Guo
    et al., [2021](#bib.bib26)), UniXCoder (Guo et al., [2022](#bib.bib25)) | MRR@k
    |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | Li 等（Li et al., [2022d](#bib.bib44)) | CSN（Husain et al., [2019](#bib.bib36))
    | RoBERTa(`code`), CodeBERT（Feng et al., [2020](#bib.bib18)），GraphCodeBERT（Guo
    et al., [2021](#bib.bib26)），UniXCoder（Guo et al., [2022](#bib.bib25)） | MRR@k
    |'
- en: '| 2022 | SCodeR (Li et al., [2022b](#bib.bib46)) | CSN (Husain et al., [2019](#bib.bib36)),
    AdvTest (Lu et al., [2021](#bib.bib55)), CoSQA (Huang et al., [2021](#bib.bib34))
    | CodeBERT (Feng et al., [2020](#bib.bib18)), GraphCodeBERT (Guo et al., [2021](#bib.bib26)),
    SyncoBERT (Wang et al., [2021b](#bib.bib87)), CodeRetriever (Li et al., [2022a](#bib.bib45)),
    Code-MVP (Wang et al., [2022c](#bib.bib88)), UniXcoder (Guo et al., [2022](#bib.bib25))
    | MRR@k |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | SCodeR（Li et al., [2022b](#bib.bib46)) | CSN（Husain et al., [2019](#bib.bib36)），AdvTest（Lu
    et al., [2021](#bib.bib55)），CoSQA（Huang et al., [2021](#bib.bib34)） | CodeBERT（Feng
    et al., [2020](#bib.bib18)），GraphCodeBERT（Guo et al., [2021](#bib.bib26)），SyncoBERT（Wang
    et al., [2021b](#bib.bib87)），CodeRetriever（Li et al., [2022a](#bib.bib45)），Code-MVP（Wang
    et al., [2022c](#bib.bib88)），UniXcoder（Guo et al., [2022](#bib.bib25)） | MRR@k
    |'
- en: '| 2023 | Salza et al. (Salza et al., [2023](#bib.bib70)) | Salza et al. (Salza
    et al., [2023](#bib.bib70)) | LUCENE, CODEnn (Gu et al., [2018](#bib.bib24)) |
    MRR@k, SuccessRate@k |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | Salza 等（Salza et al., [2023](#bib.bib70)) | Salza 等（Salza et al.,
    [2023](#bib.bib70)) | LUCENE, CODEnn（Gu et al., [2018](#bib.bib24)） | MRR@k, SuccessRate@k
    |'
- en: '| 2023 | deGraphCS (Zeng et al., [2023](#bib.bib99)) | Zeng et al. (Zeng et al.,
    [2023](#bib.bib99)) | CODEnn (Gu et al., [2018](#bib.bib24)), UNIF (Cambronero
    et al., [2019](#bib.bib7)), MMAN (Wan et al., [2019](#bib.bib79)) | MRR@k, SuccessRate@k
    |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | deGraphCS（Zeng et al., [2023](#bib.bib99)) | Zeng 等（Zeng et al., [2023](#bib.bib99))
    | CODEnn（Gu et al., [2018](#bib.bib24)），UNIF（Cambronero et al., [2019](#bib.bib7)），MMAN（Wan
    et al., [2019](#bib.bib79)） | MRR@k, SuccessRate@k |'
- en: '| 2023 | GraphSearchNet (Liu et al., [2023](#bib.bib53)) | CSN-Python (Husain
    et al., [2019](#bib.bib36)), CSN-Java (Husain et al., [2019](#bib.bib36)) | NBoW,
    1D-CNN, biRNN, SelfAtt, UNIF (Cambronero et al., [2019](#bib.bib7)), CODEnn (Gu
    et al., [2018](#bib.bib24)), CARLCS-CNN (Shuai et al., [2020](#bib.bib72)), TabCS
    (Xu et al., [2021](#bib.bib92)), Coacor (Yao et al., [2019](#bib.bib95)) | MRR@k,
    NDCG, SuccessRate@k |'
  id: totrans-473
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | GraphSearchNet (Liu et al., [2023](#bib.bib53)) | CSN-Python (Husain
    et al., [2019](#bib.bib36)), CSN-Java (Husain et al., [2019](#bib.bib36)) | NBoW,
    1D-CNN, biRNN, SelfAtt, UNIF (Cambronero et al., [2019](#bib.bib7)), CODEnn (Gu
    et al., [2018](#bib.bib24)), CARLCS-CNN (Shuai et al., [2020](#bib.bib72)), TabCS
    (Xu et al., [2021](#bib.bib92)), Coacor (Yao et al., [2019](#bib.bib95)) | MRR@k,
    NDCG, SuccessRate@k |'
- en: '| 2023 | MulCS (Ma et al., [2023](#bib.bib57)) | CSN (Husain et al., [2019](#bib.bib36)),
    C dataset (Ma et al., [2023](#bib.bib57)) | CODEnn (Gu et al., [2018](#bib.bib24)),
    TabCS (Xu et al., [2021](#bib.bib92)), NBoW, 1D-CNN, biRNN, SelfAtt | MRR@k, SuccessRate@k
    |'
  id: totrans-474
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | MulCS (Ma et al., [2023](#bib.bib57)) | CSN (Husain et al., [2019](#bib.bib36)),
    C dataset (Ma et al., [2023](#bib.bib57)) | CODEnn (Gu et al., [2018](#bib.bib24)),
    TabCS (Xu et al., [2021](#bib.bib92)), NBoW, 1D-CNN, biRNN, SelfAtt | MRR@k, SuccessRate@k
    |'
- en: '| 2023 | KeyDAC (Park et al., [2023](#bib.bib64)) | CoSQA (Huang et al., [2021](#bib.bib34)),
    WebQueryTest (Lu et al., [2021](#bib.bib55)) | CoCLR (Huang et al., [2021](#bib.bib34))
    | MRR@k |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | KeyDAC (Park et al., [2023](#bib.bib64)) | CoSQA (Huang et al., [2021](#bib.bib34)),
    WebQueryTest (Lu et al., [2021](#bib.bib55)) | CoCLR (Huang et al., [2021](#bib.bib34))
    | MRR@k |'
- en: '| 2023 | TOSS (Hu et al., [2023](#bib.bib32)) | CSN (Husain et al., [2019](#bib.bib36))
    | Jaccard, BOW, TFIDF, BM25, CODEnn (Gu et al., [2018](#bib.bib24)), CodeBERT
    (Feng et al., [2020](#bib.bib18)), GraphCodeBERT (Guo et al., [2021](#bib.bib26)),
    CoCLR (Huang et al., [2021](#bib.bib34)) | MRR@k, Precision@k | ![Refer to caption](img/aaa4647cef89638c7d94677ebbd9eaae.png)'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: '| 2023 | TOSS (Hu et al., [2023](#bib.bib32)) | CSN (Husain et al., [2019](#bib.bib36))
    | Jaccard, BOW, TFIDF, BM25, CODEnn (Gu et al., [2018](#bib.bib24)), CodeBERT
    (Feng et al., [2020](#bib.bib18)), GraphCodeBERT (Guo et al., [2021](#bib.bib26)),
    CoCLR (Huang et al., [2021](#bib.bib34)) | MRR@k, Precision@k | ![参见说明](img/aaa4647cef89638c7d94677ebbd9eaae.png)'
- en: (a) Datasets adopted by at least two papers.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 至少被两篇论文采用的数据集。
- en: '![Refer to caption](img/11b8b7869b620e3ef08c8251c9ce1efd.png)'
  id: totrans-478
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/11b8b7869b620e3ef08c8251c9ce1efd.png)'
- en: (b) Metrics adopted by at least two papers.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 至少被两篇论文采用的指标。
- en: Figure 10. Datasets and metrics adopted by at least two papers.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 图10. 至少被两篇论文采用的数据集和指标。
- en: 6.3\. Usage Scenarios
  id: totrans-481
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3\. 使用场景
- en: 'The rapid evolution of code search technology has presented the industry with
    a multitude of fresh opportunities. An interesting and important question for
    industrial practitioners is how to choose proper code search approaches to fit
    their needs. This section discusses this question from three aspects: effectiveness,
    efficiency, and multi-language.'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 代码搜索技术的迅速发展为行业带来了众多新机会。对工业从业者来说，一个有趣且重要的问题是如何选择合适的代码搜索方法以满足其需求。本节从三个方面讨论了这个问题：有效性、效率和多语言。
- en: Effectiveness. By placing a heightened emphasis on the accuracy of code search,
    industrial practitioners can leverage a suite of powerful techniques. Methods
    such as RACK (Rahman et al., [2019](#bib.bib68)), NQE (Liu et al., [2019a](#bib.bib52)),
    SEQUER (Cao et al., [2021](#bib.bib8)), and ZaCQ (Eberhart and McMillan, [2022](#bib.bib17))
    offer effective means to reconstruct queries, aiding in the clarification of user
    search intent. To deepen the understanding of code semantics, practitioners can
    employ methods such as MP-CAT (Haldar et al., [2020](#bib.bib27)), CRaDLe (Gu
    et al., [2021b](#bib.bib22)), GraphCodeBERT (Guo et al., [2021](#bib.bib26)),
    TabCS (Xu et al., [2021](#bib.bib92)), SynCoBERT (Wang et al., [2021b](#bib.bib87)),
    G2SC (Shi et al., [2022](#bib.bib71)), SPT-Code (Niu et al., [2022](#bib.bib62)),
    and UniXcoder (Guo et al., [2022](#bib.bib25)). Furthermore, methods such as MP-CAT
    (Haldar et al., [2020](#bib.bib27)), TabCS (Xu et al., [2021](#bib.bib92)), CSRS
    (Cheng and Kuang, [2022](#bib.bib13)), ${NS}^{3}$ (Arakelyan et al., [2022](#bib.bib3)),
    and CSSAM (Cai et al., [2023](#bib.bib6)) enable fine-grained interaction between
    query and code, effectively bridging the semantic gap that exists between them.
    Considering the pivotal role of the training corpus in determining the performance
    of neural code search (Sun et al., [2022b](#bib.bib77)), it is imperative for
    practitioners to prioritize the quality of their data. By meticulously cleaning
    the training corpus, practitioners can attain a high-quality dataset that fosters
    the establishment of a precise mapping from natural language to programming language.
    Furthermore, practitioners can leverage CodeRetriever (Li et al., [2022a](#bib.bib45))
    to specifically concentrate on examining the semantic distinctions between query
    and code via Contrastive Learning. This approach facilitates a detailed analysis
    of the nuanced differences, thereby enhancing the overall search accuracy. Additionally,
    the recall and rerank framework offered by TOSS (Hu et al., [2023](#bib.bib32))
    presents an invaluable opportunity to augment the accuracy of code search. By
    integrating this framework, practitioners can achieve further improvements in
    the accuracy of their products.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 效率。通过优先考虑代码搜索的准确性，工业从业者可以利用一系列强大的技术。例如，RACK（Rahman et al., [2019](#bib.bib68)）、NQE（Liu
    et al., [2019a](#bib.bib52)）、SEQUER（Cao et al., [2021](#bib.bib8)）和ZaCQ（Eberhart
    and McMillan, [2022](#bib.bib17)）等方法提供了有效的手段来重构查询，帮助澄清用户的搜索意图。为了深入理解代码语义，从业者可以采用诸如MP-CAT（Haldar
    et al., [2020](#bib.bib27)）、CRaDLe（Gu et al., [2021b](#bib.bib22)）、GraphCodeBERT（Guo
    et al., [2021](#bib.bib26)）、TabCS（Xu et al., [2021](#bib.bib92)）、SynCoBERT（Wang
    et al., [2021b](#bib.bib87)）、G2SC（Shi et al., [2022](#bib.bib71)）、SPT-Code（Niu
    et al., [2022](#bib.bib62)）和UniXcoder（Guo et al., [2022](#bib.bib25)）等方法。此外，MP-CAT（Haldar
    et al., [2020](#bib.bib27)）、TabCS（Xu et al., [2021](#bib.bib92)）、CSRS（Cheng and
    Kuang, [2022](#bib.bib13)）、${NS}^{3}$（Arakelyan et al., [2022](#bib.bib3)）和CSSAM（Cai
    et al., [2023](#bib.bib6)）等方法可以实现查询与代码之间的精细交互，有效地弥合它们之间的语义差距。考虑到训练语料库在确定神经代码搜索（Sun
    et al., [2022b](#bib.bib77)）性能中的关键作用，从业者必须优先考虑数据质量。通过仔细清理训练语料库，从业者可以获得高质量的数据集，促进自然语言与编程语言之间精确映射的建立。此外，从业者可以利用CodeRetriever（Li
    et al., [2022a](#bib.bib45)）专注于通过对比学习检查查询和代码之间的语义差异。这种方法有助于详细分析微妙的差异，从而提高整体搜索准确性。此外，TOSS（Hu
    et al., [2023](#bib.bib32)）提供的召回和重新排序框架为提高代码搜索准确性提供了宝贵的机会。通过整合该框架，从业者可以进一步提高产品的准确性。
- en: Efficiency. By prioritizing search efficiency, industrial practitioners can
    leverage the offline calculation of code fragment embeddings within their codebases.
    This approach offers a time-saving alternative to the online calculation of vector
    similarity. Moreover, the utilization of CoSHC (Gu et al., [2022](#bib.bib23)),
    a code search acceleration method based on deep hashing and code classification,
    enables efficient code search while accepting a minor trade-off in precision.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 效率。通过优先考虑搜索效率，工业从业者可以利用代码库中代码片段嵌入的离线计算。这种方法提供了一种节省时间的替代方案，避免了在线计算向量相似度。此外，利用基于深度哈希和代码分类的代码搜索加速方法CoSHC（Gu
    et al., [2022](#bib.bib23)）可以实现高效的代码搜索，同时接受精度上的小幅折衷。
- en: Multi-language. By emphasizing the generalization of code search tools across
    multiple programming languages, industrial practitioners can use MulCS (Ma et al.,
    [2023](#bib.bib57)) to break down the semantic barriers between different programming
    languages, which uses a unified data structure to represent multiple programming
    languages.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 多语言。通过强调代码搜索工具在多种编程语言中的通用性，工业从业者可以使用 MulCS（Ma et al., [2023](#bib.bib57)）来打破不同编程语言之间的语义障碍，该工具使用统一的数据结构来表示多种编程语言。
- en: '<svg   height="136.64" overflow="visible" version="1.1" width="600"><g transform="translate(0,136.64)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    width="556.69" height="109.08" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">Summary of answers to RQ4: • The primary source of the code in
    the code search datasets originates from the open-source code repository, Github.
    On the other hand, Stack Overflow (SO) serves as the main source of queries these
    the datasets. • Python and Java are the two most concerned programming languages
    for code search tasks. • For nearly 6 years, the CSN dataset has dominated the
    evaluation of code search tasks. • The prevalent evaluation metrics employed in
    code search encompass Precision@k, Recall@k, F1-score, MAP@k, MRR@k, Frank@k,
    and SuccessRate@k, with MRR@k widely utilized indicator among them.</foreignobject></g></g></svg>'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: <svg height="136.64" overflow="visible" version="1.1" width="600"><g transform="translate(0,136.64)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    width="556.69" height="109.08" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">对 RQ4 的回答总结：• 代码搜索数据集中的主要代码来源于开源代码库 Github。另一方面，Stack Overflow
    (SO) 是这些数据集查询的主要来源。• Python 和 Java 是代码搜索任务中最受关注的两种编程语言。• 近 6 年来，CSN 数据集一直主导代码搜索任务的评估。•
    代码搜索中使用的常见评估指标包括 Precision@k、Recall@k、F1-score、MAP@k、MRR@k、Frank@k 和 SuccessRate@k，其中
    MRR@k 是其中被广泛使用的指标。</foreignobject></g></g></svg>
- en: 7\. Open Challenges and Future Directions (RQ5)
  id: totrans-487
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 开放挑战与未来方向（RQ5）
- en: This section addresses the outstanding challenges in the field of code search
    and identifies potential avenues for future advancements.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了代码搜索领域中的突出挑战，并确定了未来发展的潜在途径。
- en: (1)
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Understanding code structure. The information contained in code can be divided
    into two parts: structured information determined by keywords that define the
    code’s function, and auxiliary information reflected by identifiers such as function
    and variable names, which indicate a software developer’s generalization of code
    functions. However, studies have shown that anonymizing function and variable
    names can lead to a significant drop in model performance (Guo et al., [2022](#bib.bib25)),
    indicating that current methods rely too heavily on identifier information for
    inference. Identifier content serves as a convenient shortcut for code intelligence
    tasks, but an overreliance on it may hinder the model’s ability to learn the code
    functions defined by structured information, thereby hindering its overall understanding
    of code structure. The challenge is to design a strategy that allows the model
    to better focus on and understand the code’s structural information, and to strike
    a balance between the structural information defined by keywords and the auxiliary
    information provided by identifiers during both training and inference. This is
    a direction worthy of further research. First steps toward that goal have been
    taken, e.g., by Li et al. (Li et al., [2022b](#bib.bib46)) and Wang et al. (Wang
    et al., [2022c](#bib.bib88)).'
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 理解代码结构。代码中包含的信息可以分为两部分：由定义代码功能的关键字决定的结构化信息，以及由函数和变量名称等标识符反映的辅助信息，这些信息指示了软件开发人员对代码功能的概括。然而，研究表明，匿名化函数和变量名称会导致模型性能显著下降（Guo
    et al., [2022](#bib.bib25)），这表明当前方法过于依赖标识符信息进行推断。标识符内容作为代码智能任务的便利捷径，但过度依赖它可能会阻碍模型学习由结构化信息定义的代码功能，从而妨碍对代码结构的全面理解。挑战在于设计一种策略，使模型能够更好地关注和理解代码的结构信息，并在训练和推断过程中在由关键字定义的结构化信息和标识符提供的辅助信息之间取得平衡。这是一个值得进一步研究的方向。向这一目标迈出的第一步已经采取，例如
    Li et al.（Li et al., [2022b](#bib.bib46)）和 Wang et al.（Wang et al., [2022c](#bib.bib88)）。
- en: (2)
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: Graph pre-training technology. Code can be analyzed and represented as a graph
    data structure (e.g., Data Flow Graph (Guo et al., [2021](#bib.bib26)) and Variable-based
    Flow Graph (Zeng et al., [2023](#bib.bib99))). Compared to sequential structures,
    using a graph structure to represent code provides a larger amount of information
    and higher accuracy. We believe that this graph structure encompasses valuable
    insights that can lead to breakthroughs in understanding the meaning of code.
    However, based on the results of existing research, methods utilizing Transformer-encoded
    sequences (Guo et al., [2022](#bib.bib25); Wang et al., [2021b](#bib.bib87); Li
    et al., [2022a](#bib.bib45); Wang et al., [2022c](#bib.bib88)) continue to maintain
    their lead over those based on graph neural network approaches for graph encoding
    (Zeng et al., [2023](#bib.bib99); Ling et al., [2021](#bib.bib50); Ma et al.,
    [2023](#bib.bib57); Liu et al., [2023](#bib.bib53)). The remarkable success of
    the Transformer-based methods can be largely attributed to the substantial improvement
    in model capacity achieved through pre-training techniques. We believe that the
    potential of graph-based methods in code intelligence has not been fully explored
    yet. A valuable research direction lies in exploring how to incorporate graph
    pre-training into code intelligence, aiming to fully unleash the performance of
    graph-based models.
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图预训练技术。代码可以被分析并表示为图数据结构（例如，数据流图（Guo et al., [2021](#bib.bib26)）和基于变量的流图（Zeng
    et al., [2023](#bib.bib99)））。与顺序结构相比，使用图结构表示代码提供了更多的信息和更高的准确性。我们相信，这种图结构包含了有价值的见解，可以引领对代码意义的突破性理解。然而，基于现有研究结果，利用Transformer编码序列的方法（Guo
    et al., [2022](#bib.bib25)；Wang et al., [2021b](#bib.bib87)；Li et al., [2022a](#bib.bib45)；Wang
    et al., [2022c](#bib.bib88)）仍然在图编码方面优于基于图神经网络的方法（Zeng et al., [2023](#bib.bib99)；Ling
    et al., [2021](#bib.bib50)；Ma et al., [2023](#bib.bib57)；Liu et al., [2023](#bib.bib53)）。Transformer方法的显著成功很大程度上归功于通过预训练技术实现的模型容量显著提升。我们认为，基于图的方法在代码智能领域的潜力尚未完全探索。一个有价值的研究方向是探索如何将图预训练融入代码智能，以充分释放基于图模型的性能。
- en: (3)
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: Robust optimization. Research has indicated that current code intelligence methods
    are susceptible to adversarial attacks (Li et al., [2022e](#bib.bib47)). Perturbing
    identifiers significantly decreases the model’s performance, highlighting its
    lack of robustness. Efforts have been made to enhance robustness through adversarial
    training (Wan et al., [2022a](#bib.bib80)), but further studies are required.
    At the same time, it is crucial to establish a standard evaluation method or dataset
    to evaluate the robustness of these models.
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 强健优化。研究表明，当前的代码智能方法易受到对抗攻击（Li et al., [2022e](#bib.bib47)）。扰动标识符会显著降低模型的性能，突显其缺乏鲁棒性。虽然通过对抗训练（Wan
    et al., [2022a](#bib.bib80)）已经做出了一些增强鲁棒性的努力，但仍需进一步研究。同时，建立一个标准评估方法或数据集来评估这些模型的鲁棒性也至关重要。
- en: (4)
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: Interpretability research. Like other deep learning models, code search models
    are trained and operate in a relatively black-box manner. Interpretability research
    aims to understand the reasons behind a model’s decisions, improve our understanding
    of the model’s inference process, and identify the information that the model
    considers important. This research is crucial as it can boost user confidence
    in the model and, in case of errors, enable the identification of the cause and
    development of a solution in a timely manner. Karmakar and Robbes (Karmakar and
    Robbes, [2021](#bib.bib39)) and Wan et al. (Wan et al., [2022b](#bib.bib81)) propose
    promising first steps into this direction.
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可解释性研究。与其他深度学习模型类似，代码搜索模型是在相对黑箱的方式下进行训练和操作的。可解释性研究旨在理解模型决策的原因，提高对模型推理过程的理解，并识别模型认为重要的信息。这项研究至关重要，因为它可以增强用户对模型的信任，并且在出现错误时，能够及时识别原因并制定解决方案。Karmakar和Robbes（Karmakar和Robbes,
    [2021](#bib.bib39)）以及Wan et al.（Wan et al., [2022b](#bib.bib81)）提出了这一方向的有希望的初步步骤。
- en: (5)
  id: totrans-497
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (5)
- en: Comprehensive evaluation. Presently, the most efficient approach in the field
    of code search is the pre-training & fine-tuning paradigm (e.g., CodeBERT (Feng
    et al., [2020](#bib.bib18)), GraphCodeBERT (Guo et al., [2021](#bib.bib26)), Syncobert
    (Wang et al., [2021b](#bib.bib87)), and UniXcoder (Guo et al., [2022](#bib.bib25))).
    This paradigm encompasses several crucial design elements, including data preprocessing
    strategy, tokenizer, pre-training task, pre-training model & training parameters,
    fine-tuning model & training parameters, and negative sample construction strategy.
    However, there is a shortage of analytical experiments on these key elements that
    can guide practitioners in choosing the most effective training strategies for
    code intelligence. For example, Guo et al. (Guo et al., [2021](#bib.bib26)) adopt
    the parameters of CodeBERT (Feng et al., [2020](#bib.bib18)) to initialize the
    GraphCodeBERT model and proceed with continue pre-training on the CSN dataset
    using tasks like MLM. However, the performance improvement has not been validated
    to determine whether it is a result of additional iterations on the MLM task.
    Investigating the significance of these design elements will offer more direction
    to practitioners and also provide new insights for future research by uncovering
    the unique properties of code intelligence.
  id: totrans-498
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 综合评估。目前，代码搜索领域中最有效的方法是预训练与微调范式（例如，CodeBERT (Feng et al., [2020](#bib.bib18))、GraphCodeBERT
    (Guo et al., [2021](#bib.bib26))、Syncobert (Wang et al., [2021b](#bib.bib87))
    和 UniXcoder (Guo et al., [2022](#bib.bib25))）。这一范式包括几个关键设计要素，如数据预处理策略、分词器、预训练任务、预训练模型及训练参数、微调模型及训练参数，以及负样本构建策略。然而，对这些关键要素的分析实验仍然不足，这些实验可以指导从业者选择最有效的代码智能训练策略。例如，Guo
    et al. (Guo et al., [2021](#bib.bib26)) 采用了 CodeBERT (Feng et al., [2020](#bib.bib18))
    的参数来初始化 GraphCodeBERT 模型，并在 CSN 数据集上使用 MLM 任务继续预训练。然而，性能提升尚未得到验证，以确定是否是由于在 MLM
    任务上的额外迭代。研究这些设计要素的意义将为从业者提供更多方向，同时通过揭示代码智能的独特属性为未来研究提供新的见解。
- en: (6)
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (6)
- en: 'High-quality datasets. At present, the most widely used datasets in code search
    come from three sources: crawling from Github (e.g., CSN (Husain et al., [2019](#bib.bib36))),
    which consists of code comments as queries and the rest as code; crawling from
    Stack Overflow (e.g., StaQC (Yao et al., [2018](#bib.bib96)) and CoNaLa (Yin et al.,
    [2018](#bib.bib98))), which consists of questions and code answers in posts; and
    actual user queries collected from search engines (e.g., CoSQA (Huang et al.,
    [2021](#bib.bib34))), with codes annotated by annotators . Each of these data
    sources has its own limitations: in the Github data, code comments are significantly
    different from actual queries; in the Stack Overflow data, the answered code is
    often not a complete function; and in the annotated data, a vast amount of background
    knowledge is required to understand the code, making it difficult to guarantee
    the scale and quality of the data. Therefore, we believe it is essential to create
    a more practical dataset for model training and evaluation. One potential solution
    is to collect online user behavior records, such as clicks and stays, which would
    require a highly performing code search engine with a large user base. Hence,
    there is a potential to use the existing model to build a preliminary code search
    engine, attract a group of users, and collect user data to create a new dataset.'
  id: totrans-500
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高质量数据集。目前，代码搜索中最广泛使用的数据集来自三个来源：从 Github 爬取（例如，CSN (Husain et al., [2019](#bib.bib36))，其包括代码注释作为查询，其他作为代码）；从
    Stack Overflow 爬取（例如，StaQC (Yao et al., [2018](#bib.bib96)) 和 CoNaLa (Yin et al.,
    [2018](#bib.bib98))），其中包括帖子中的问题和代码答案；以及从搜索引擎收集的实际用户查询（例如，CoSQA (Huang et al.,
    [2021](#bib.bib34))），代码由注释员标注。这些数据来源各有其局限性：在 Github 数据中，代码注释与实际查询差异较大；在 Stack
    Overflow 数据中，回答的代码通常不是完整的函数；而在标注数据中，理解代码需要大量背景知识，难以保证数据的规模和质量。因此，我们认为创建一个更实用的数据集以进行模型训练和评估是至关重要的。一个潜在的解决方案是收集在线用户行为记录，如点击和停留，这需要一个具有大用户基础的高性能代码搜索引擎。因此，有潜力利用现有模型构建初步的代码搜索引擎，吸引一组用户，并收集用户数据以创建新的数据集。
- en: (7)
  id: totrans-501
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (7)
- en: More fine-grained interaction. Current methods of code search have limitations
    in their ability to model the interaction between query and code. These limitations
    stem from the fact that existing methods only model the interaction at the representation
    level (Cheng and Kuang, [2022](#bib.bib13); Xu et al., [2021](#bib.bib92)) and
    fail to consider cross-modal interaction at the token level. Additionally, these
    methods use a single level for discrimination, which limits the ability to capture
    hierarchical information. Hence, the model architecture used for code search still
    holds potential for improvement. First steps toward that goal have been taken,
    e.g., by Dong et al. (Dong et al., [2023](#bib.bib15)).
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更加细粒度的交互。目前的代码搜索方法在建模查询与代码之间的交互能力方面存在局限。这些局限源于现有方法仅在表示层次上建模交互（Cheng和Kuang, [2022](#bib.bib13);
    Xu et al., [2021](#bib.bib92)），而未考虑在令牌层次上的跨模态交互。此外，这些方法使用单一层次进行区分，这限制了捕获层级信息的能力。因此，代码搜索中使用的模型架构仍然有改进的潜力。例如，Dong等人（Dong
    et al., [2023](#bib.bib15)）已朝着这个目标迈出了第一步。
- en: (8)
  id: totrans-503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (8)
- en: Improving code search efficiency. Deep learning-based code search methods have
    demonstrated promising results. However, previous approaches have predominantly
    focused on retrieval accuracy while neglecting the consideration of retrieval
    efficiency. If the code search model is intended for real-world online scenarios,
    enhancing retrieval efficiency becomes a challenge that demands immediate attention.
    Addressing this crucial concern is vital to successfully deploy and utilize the
    model in practical applications. Gu et al. (Gu et al., [2022](#bib.bib23)) propose
    promising first steps into this direction.
  id: totrans-504
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提高代码搜索效率。基于深度学习的代码搜索方法已展示出良好的效果。然而，之前的方法主要关注检索准确性，却忽略了检索效率。如果代码搜索模型用于实际的在线场景，提升检索效率将成为一个需要立即关注的挑战。解决这一关键问题对于成功部署和利用模型在实际应用中至关重要。Gu等人（Gu
    et al., [2022](#bib.bib23)）提出了朝这一方向迈出的有前景的第一步。
- en: (9)
  id: totrans-505
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (9)
- en: Context-related code search. The current method assumes that functions in a
    project are independent (Gu et al., [2018](#bib.bib24); Husain et al., [2019](#bib.bib36);
    Huang et al., [2021](#bib.bib34)), disregarding their relationships within the
    project. However, functions in a project are actually interdependent, with function
    calls and shared variables. To accurately model a function’s role, its context
    must be considered. Designing a method to model contextual information and efficiently
    search for functions with context information online is a valuable research direction.
  id: totrans-506
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 语境相关的代码搜索。当前的方法假设项目中的函数是独立的（Gu et al., [2018](#bib.bib24); Husain et al., [2019](#bib.bib36);
    Huang et al., [2021](#bib.bib34)），忽视了它们在项目中的关系。然而，项目中的函数实际上是相互依赖的，具有函数调用和共享变量。要准确建模函数的角色，必须考虑其上下文。设计一种方法来建模上下文信息并高效地在线搜索带有上下文信息的函数是一个有价值的研究方向。
- en: (10)
  id: totrans-507
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (10)
- en: Personalized code search. Software developers possess unique programming habits,
    leading to varying speeds of understanding and preferences for different forms
    of code for the same function. Consequently, code search results should be tailored
    to individual users based on their programming preferences. A potential area for
    research is the implementation of a personalized code search service.
  id: totrans-508
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 个性化的代码搜索。软件开发者拥有独特的编程习惯，导致理解速度和对同一功能不同形式代码的偏好各异。因此，代码搜索结果应该根据个人用户的编程偏好进行定制。一个潜在的研究领域是实现个性化的代码搜索服务。
- en: (11)
  id: totrans-509
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (11)
- en: Better code analysis tools. Different data structures like Abstract Syntax Trees,
    Control Flow Graphs, Program Dependency Graphs, and Data Flow Graphs can assist
    in comprehending the semantics of code. However, the absence of useful open source
    tools to extract these structures impedes the progress of code intelligence research.
    For instance, the extraction of program dependency graphs is currently limited
    to tools designed specifically for the Java programming language. This poses a
    hindrance to research in the field of code intelligence. Thus, developing better
    open-source code analysis tools for multiple programming languages would be a
    beneficial direction to further advance related research.
  id: totrans-510
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更好的代码分析工具。不同的数据结构，如抽象语法树、控制流图、程序依赖图和数据流图，有助于理解代码的语义。然而，缺乏有效的开源工具来提取这些结构阻碍了代码智能研究的进展。例如，程序依赖图的提取目前仅限于专为
    Java 编程语言设计的工具。这对代码智能领域的研究构成了障碍。因此，为多种编程语言开发更好的开源代码分析工具将是进一步推动相关研究的有益方向。
- en: (12)
  id: totrans-511
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (12)
- en: Exploring new search paradigms. Recently, large-scale language models used for
    code generation have provided functionality akin to code search. For instance,
    GitHub’s Copilot tool ²²2https://github.com/features/copilot, backed by Codex
    (Chen et al., [2021](#bib.bib11)) at its core, maps natural language descriptions
    of desired functionalities to corresponding code snippets that provide those functionalities.
    Similarly, OpenAI’s ChatGPT tool ³³3https://openai.com/blog/chatgpt, powered by
    GPT-4 (OpenAI, [2023](#bib.bib63)), maps natural language descriptions of desired
    functionalities to code snippets that offer the desired functionalities, accompanied
    by explanatory natural language text to enhance developers’ understanding and
    usability. In light of the impact of these tools, it is imperative that we reconsider
    the significance and form of code search tasks. Exploring new paradigms may usher
    in a new era of transformation for code search. One promising direction worth
    exploring is cross-fertilization with other code intelligence tasks, such as leveraging
    code search results to assist code completion or code generation.
  id: totrans-512
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 探索新的搜索范式。最近，用于代码生成的大规模语言模型提供了类似代码搜索的功能。例如，GitHub 的 Copilot 工具 ²²2https://github.com/features/copilot，以
    Codex (Chen et al., [2021](#bib.bib11)) 为核心，将自然语言描述的功能映射到提供这些功能的代码片段上。类似地，OpenAI
    的 ChatGPT 工具 ³³3https://openai.com/blog/chatgpt，由 GPT-4 (OpenAI, [2023](#bib.bib63))
    驱动，将自然语言描述的功能映射到提供所需功能的代码片段上，并附有解释性自然语言文本，以增强开发者的理解和可用性。鉴于这些工具的影响，我们必须重新考虑代码搜索任务的意义和形式。探索新范式可能会为代码搜索带来新时代的变革。一个值得探索的有前途的方向是与其他代码智能任务的交叉融合，例如利用代码搜索结果来协助代码补全或代码生成。
- en: 8\. Conclusion
  id: totrans-513
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 结论
- en: In this survey, we have presented a comprehensive overview of deep learning-based
    methods for the code search task. We start by introducing the code search task
    and outlining the framework of deep learning-based code search method. Next, we
    detail the methods for extracting representations of query and code, respectively.
    Furthermore, we categorize many loss functions about the model training. Finally,
    we identify several open challenges and promising research directions in this
    area. We hope this survey can help both academic researchers and industry practitioners,
    and inspire more meaningful work in this field.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次调查中，我们全面概述了基于深度学习的代码搜索方法。我们首先介绍了代码搜索任务，并概述了基于深度学习的代码搜索方法的框架。接着，我们详细描述了查询和代码表示的提取方法。此外，我们对模型训练的多个损失函数进行了分类。最后，我们识别了该领域的一些开放挑战和有前途的研究方向。我们希望本次调查能够帮助学术研究者和行业从业者，并激发更多有意义的工作。
- en: References
  id: totrans-515
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Alon et al. (2019) Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav.
    2019. code2vec: learning distributed representations of code. *Proc. ACM Program.
    Lang.* 3, POPL (2019), 40:1–40:29. [https://doi.org/10.1145/3290353](https://doi.org/10.1145/3290353)'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Alon 等人 (2019) Uri Alon, Meital Zilberstein, Omer Levy 和 Eran Yahav. 2019.
    code2vec: 学习代码的分布式表示。*Proc. ACM Program. Lang.* 3, POPL (2019), 40:1–40:29. [https://doi.org/10.1145/3290353](https://doi.org/10.1145/3290353)'
- en: 'Arakelyan et al. (2022) Shushan Arakelyan, Anna Hakhverdyan, Miltiadis Allamanis,
    Luis Garcia, Christophe Hauser, and Xiang Ren. 2022. NS3: Neuro-symbolic Semantic
    Code Search. In *NeurIPS*. [http://papers.nips.cc/paper_files/paper/2022/hash/43f5f6c5cb333115914c8448b8506411-Abstract-Conference.html](http://papers.nips.cc/paper_files/paper/2022/hash/43f5f6c5cb333115914c8448b8506411-Abstract-Conference.html)'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Arakelyan等（2022）Shushan Arakelyan、Anna Hakhverdyan、Miltiadis Allamanis、Luis
    Garcia、Christophe Hauser和Xiang Ren。2022年。NS3: 神经符号语义代码搜索。发表于*NeurIPS*。[http://papers.nips.cc/paper_files/paper/2022/hash/43f5f6c5cb333115914c8448b8506411-Abstract-Conference.html](http://papers.nips.cc/paper_files/paper/2022/hash/43f5f6c5cb333115914c8448b8506411-Abstract-Conference.html)'
- en: 'Barone and Sennrich (2017) Antonio Valerio Miceli Barone and Rico Sennrich.
    2017. A Parallel Corpus of Python Functions and Documentation Strings for Automated
    Code Documentation and Code Generation. In *Proceedings of the Eighth International
    Joint Conference on Natural Language Processing, IJCNLP 2017, Taipei, Taiwan,
    November 27 - December 1, 2017, Volume 2: Short Papers*, Greg Kondrak and Taro
    Watanabe (Eds.). Asian Federation of Natural Language Processing, 314–319. [https://aclanthology.org/I17-2053/](https://aclanthology.org/I17-2053/)'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barone和Sennrich（2017）Antonio Valerio Miceli Barone和Rico Sennrich。2017年。用于自动化代码文档生成和代码生成的Python函数和文档字符串的平行语料库。发表于*第八届国际自然语言处理联合会议论文集，IJCNLP
    2017，台北，台湾，2017年11月27日至12月1日，第二卷：短文*，Greg Kondrak和Taro Watanabe（编）。亚洲自然语言处理联合会，314–319。[https://aclanthology.org/I17-2053/](https://aclanthology.org/I17-2053/)
- en: 'Bui et al. (2021) Nghi D. Q. Bui, Yijun Yu, and Lingxiao Jiang. 2021. Self-Supervised
    Contrastive Learning for Code Retrieval and Summarization via Semantic-Preserving
    Transformations. In *SIGIR ’21: The 44th International ACM SIGIR Conference on
    Research and Development in Information Retrieval, Virtual Event, Canada, July
    11-15, 2021*, Fernando Diaz, Chirag Shah, Torsten Suel, Pablo Castells, Rosie
    Jones, and Tetsuya Sakai (Eds.). ACM, 511–521. [https://doi.org/10.1145/3404835.3462840](https://doi.org/10.1145/3404835.3462840)'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bui等（2021）Nghi D. Q. Bui、Yijun Yu和Lingxiao Jiang。2021年。通过语义保留变换进行自监督对比学习以实现代码检索和总结。发表于*SIGIR
    ’21: 第44届国际ACM SIGIR信息检索研究与发展会议，虚拟会议，加拿大，2021年7月11-15日*，Fernando Diaz、Chirag Shah、Torsten
    Suel、Pablo Castells、Rosie Jones和Tetsuya Sakai（编）。ACM，511–521。[https://doi.org/10.1145/3404835.3462840](https://doi.org/10.1145/3404835.3462840)'
- en: 'Cai et al. (2023) Bo Cai, Yaoxiang Yu, and Yi Hu. 2023. CSSAM: Code Search
    via Attention Matching of Code Semantics and Structures. In *IEEE International
    Conference on Software Analysis, Evolution and Reengineering, SANER 2023, Taipa,
    Macao, March 21-24, 2023*, Tao Zhang, Xin Xia, and Nicole Novielli (Eds.). IEEE,
    402–413. [https://doi.org/10.1109/SANER56733.2023.00045](https://doi.org/10.1109/SANER56733.2023.00045)'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cai等（2023）Bo Cai、Yaoxiang Yu和Yi Hu。2023年。CSSAM: 基于代码语义和结构的注意力匹配代码搜索。发表于*IEEE国际软件分析、演变与重构会议，SANER
    2023，澳门塔石，2023年3月21-24日*，Tao Zhang、Xin Xia和Nicole Novielli（编）。IEEE，402–413。[https://doi.org/10.1109/SANER56733.2023.00045](https://doi.org/10.1109/SANER56733.2023.00045)'
- en: Cambronero et al. (2019) José Cambronero, Hongyu Li, Seohyun Kim, Koushik Sen,
    and Satish Chandra. 2019. When deep learning met code search. In *Proceedings
    of the ACM Joint Meeting on European Software Engineering Conference and Symposium
    on the Foundations of Software Engineering, ESEC/SIGSOFT FSE 2019, Tallinn, Estonia,
    August 26-30, 2019*, Marlon Dumas, Dietmar Pfahl, Sven Apel, and Alessandra Russo
    (Eds.). ACM, 964–974. [https://doi.org/10.1145/3338906.3340458](https://doi.org/10.1145/3338906.3340458)
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cambronero等（2019）José Cambronero、Hongyu Li、Seohyun Kim、Koushik Sen和Satish Chandra。2019年。当深度学习遇上代码搜索。发表于*ACM欧洲软件工程会议与软件工程基础会议联合会议论文集，ESEC/SIGSOFT
    FSE 2019，爱沙尼亚塔林，2019年8月26-30日*，Marlon Dumas、Dietmar Pfahl、Sven Apel和Alessandra
    Russo（编）。ACM，964–974。[https://doi.org/10.1145/3338906.3340458](https://doi.org/10.1145/3338906.3340458)
- en: Cao et al. (2021) Kaibo Cao, Chunyang Chen, Sebastian Baltes, Christoph Treude,
    and Xiang Chen. 2021. Automated Query Reformulation for Efficient Search based
    on Query Logs From Stack Overflow. In *43rd IEEE/ACM International Conference
    on Software Engineering, ICSE 2021, Madrid, Spain, 22-30 May 2021*. IEEE, 1273–1285.
    [https://doi.org/10.1109/ICSE43902.2021.00116](https://doi.org/10.1109/ICSE43902.2021.00116)
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao等（2021）Kaibo Cao、Chunyang Chen、Sebastian Baltes、Christoph Treude和Xiang Chen。2021年。基于Stack
    Overflow查询日志的高效搜索自动化查询重构。发表于*第43届IEEE/ACM国际软件工程会议，ICSE 2021，西班牙马德里，2021年5月22-30日*。IEEE，1273–1285。[https://doi.org/10.1109/ICSE43902.2021.00116](https://doi.org/10.1109/ICSE43902.2021.00116)
- en: Chai et al. (2022) Yitian Chai, Hongyu Zhang, Beijun Shen, and Xiaodong Gu.
    2022. Cross-Domain Deep Code Search with Meta Learning. In *44th IEEE/ACM 44th
    International Conference on Software Engineering, ICSE 2022, Pittsburgh, PA, USA,
    May 25-27, 2022*. ACM, 487–498. [https://doi.org/10.1145/3510003.3510125](https://doi.org/10.1145/3510003.3510125)
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 柴等人（2022）易天·柴、洪宇·张、北君·沈和晓东·顾。2022年。跨领域深度代码搜索与元学习。见于*第44届IEEE/ACM国际软件工程会议，ICSE
    2022，宾夕法尼亚州匹兹堡，美国，2022年5月25-27日*。ACM，第487–498页。 [https://doi.org/10.1145/3510003.3510125](https://doi.org/10.1145/3510003.3510125)
- en: 'Chatterjee et al. (2009) Shaunak Chatterjee, Sudeep Juvekar, and Koushik Sen.
    2009. SNIFF: A Search Engine for Java Using Free-Form Queries. In *Fundamental
    Approaches to Software Engineering, 12th International Conference, FASE 2009,
    Held as Part of the Joint European Conferences on Theory and Practice of Software,
    ETAPS 2009, York, UK, March 22-29, 2009\. Proceedings* *(Lecture Notes in Computer
    Science, Vol. 5503)*, Marsha Chechik and Martin Wirsing (Eds.). Springer, 385–400.
    [https://doi.org/10.1007/978-3-642-00593-0_26](https://doi.org/10.1007/978-3-642-00593-0_26)'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查特吉等人（2009）绍纳克·查特吉、苏迪普·朱维卡和考希克·森。2009年。SNIFF：使用自由形式查询的Java搜索引擎。见于*基础软件工程方法，第12届国际会议，FASE
    2009，作为欧洲软件理论与实践联合会议的一部分，ETAPS 2009，英国约克，2009年3月22-29日\. 会议录* *(计算机科学讲义，第5503卷)*，玛莎·切奇克和马丁·维尔辛（编辑）。施普林格，第385–400页。
    [https://doi.org/10.1007/978-3-642-00593-0_26](https://doi.org/10.1007/978-3-642-00593-0_26)
- en: Chen et al. (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pondé
    de Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf,
    Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,
    Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet,
    Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth
    Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas
    Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,
    Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan
    Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer,
    Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and
    Wojciech Zaremba. 2021. Evaluating Large Language Models Trained on Code. *CoRR*
    abs/2107.03374 (2021). arXiv:2107.03374 [https://arxiv.org/abs/2107.03374](https://arxiv.org/abs/2107.03374)
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等人（2021）马克·陈、杰瑞·特沃雷克、赫宇·君、邱铭·袁、亨里克·庞德·德·奥利维拉·平托、贾瑞德·卡普兰、哈里森·爱德华兹、尤里·布尔达、尼古拉斯·约瑟夫、格雷格·布罗克曼、亚历克斯·雷、劳尔·普里、格雷琴·克鲁格、迈克尔·彼得罗夫、海迪·克拉夫、吉里什·萨斯特里、帕梅拉·米什金、布鲁克·陈、斯科特·格雷、尼克·赖德、米哈伊尔·帕夫洛夫、阿莱西娅·鲍尔、卢卡斯·凯瑟、穆罕默德·巴瓦里安、克莱门斯·温特、菲利普·蒂耶、费利佩·佩特罗斯基·苏奇、戴夫·卡明斯、马蒂亚斯·普拉普特、福托斯·昌齐斯、伊丽莎白·巴恩斯、阿里尔·赫伯特-沃斯、威廉·赫布根·古斯、亚历克斯·尼科尔、亚历克斯·佩诺、尼科拉斯·特扎克、杰·唐、伊戈尔·巴布什金、苏奇尔·巴拉吉、尚坦努·简、威廉·宋德斯、克里斯托弗·赫斯、安德鲁·N·卡尔、扬·莱克、约书亚·阿奇亚姆、维丹特·米斯拉、埃文·莫里卡瓦、亚历克·拉德福德、马修·奈特、迈尔斯·布伦戴奇、米拉·穆拉蒂、凯蒂·梅耶、彼得·韦林德、鲍勃·麦克格鲁、达里奥·阿莫代、山姆·麦坎德利什、伊利亚·苏茨克维尔和沃伊切赫·扎伦巴。2021年。评估在代码上训练的大型语言模型。*CoRR*
    abs/2107.03374（2021年）。arXiv:2107.03374 [https://arxiv.org/abs/2107.03374](https://arxiv.org/abs/2107.03374)
- en: Chen and Zhou (2018) Qingying Chen and Minghui Zhou. 2018. A neural framework
    for retrieval and summarization of source code. In *Proceedings of the 33rd ACM/IEEE
    International Conference on Automated Software Engineering, ASE 2018, Montpellier,
    France, September 3-7, 2018*, Marianne Huchard, Christian Kästner, and Gordon
    Fraser (Eds.). ACM, 826–831. [https://doi.org/10.1145/3238147.3240471](https://doi.org/10.1145/3238147.3240471)
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈和周（2018）青颖·陈和明辉·周。2018年。用于检索和总结源代码的神经框架。见于*第33届ACM/IEEE国际自动化软件工程会议，ASE 2018，法国蒙彼利埃，2018年9月3-7日*，玛丽安娜·赫查德、克里斯蒂安·凯斯特纳和戈登·弗雷泽（编辑）。ACM，第826–831页。
    [https://doi.org/10.1145/3238147.3240471](https://doi.org/10.1145/3238147.3240471)
- en: 'Cheng and Kuang (2022) Yi Cheng and Li Kuang. 2022. CSRS: code search with
    relevance matching and semantic matching. In *Proceedings of the 30th IEEE/ACM
    International Conference on Program Comprehension, ICPC 2022, Virtual Event, May
    16-17, 2022*, Ayushi Rastogi, Rosalia Tufano, Gabriele Bavota, Venera Arnaoudova,
    and Sonia Haiduc (Eds.). ACM, 533–542. [https://doi.org/10.1145/3524610.3527889](https://doi.org/10.1145/3524610.3527889)'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程和匡（2022）程一和李匡。2022年。CSRS：基于相关性匹配和语义匹配的代码搜索。见于*第30届IEEE/ACM国际程序理解会议，ICPC 2022，虚拟活动，2022年5月16-17日*，阿尤希·拉斯托吉、罗莎莉亚·图法诺、加布里埃尔·巴沃塔、维内拉·阿尔诺多娃和索尼娅·海杜克（编辑）。ACM，第533–542页。
    [https://doi.org/10.1145/3524610.3527889](https://doi.org/10.1145/3524610.3527889)
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language
    Understanding. In *Proceedings of the 2019 Conference of the North American Chapter
    of the Association for Computational Linguistics: Human Language Technologies,
    NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short
    Papers)*, Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association
    for Computational Linguistics, 4171–4186. [https://doi.org/10.18653/v1/n19-1423](https://doi.org/10.18653/v1/n19-1423)'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Devlin等（2019）雅各布·德夫林、明伟·张、肯顿·李和克里斯蒂娜·图托诺娃。2019年。《BERT: Pre-training of Deep
    Bidirectional Transformers for Language Understanding》。发表于*Proceedings of the
    2019 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA,
    June 2-7, 2019, Volume 1 (Long and Short Papers)*，吉尔·伯斯坦、克里斯蒂·多兰和塔玛尔·索洛里奥（编）。计算语言学协会，4171–4186。
    [https://doi.org/10.18653/v1/n19-1423](https://doi.org/10.18653/v1/n19-1423)'
- en: Dong et al. (2023) Hande Dong, Jiayi Lin, Yichong Leng, Jiawei Chen, and Yutao
    Xie. 2023. Retriever and Ranker Framework with Probabilistic Hard Negative Sampling
    for Code Search. *CoRR* abs/2305.04508 (2023). [https://doi.org/10.48550/arXiv.2305.04508](https://doi.org/10.48550/arXiv.2305.04508)
    arXiv:2305.04508
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong等（2023）董涵德、林佳怡、冷亦冲、陈家伟和谢宇涛。2023年。《Retriever and Ranker Framework with Probabilistic
    Hard Negative Sampling for Code Search》。*CoRR* abs/2305.04508（2023）。 [https://doi.org/10.48550/arXiv.2305.04508](https://doi.org/10.48550/arXiv.2305.04508)
    arXiv:2305.04508
- en: 'Du et al. (2021) Lun Du, Xiaozhou Shi, Yanlin Wang, Ensheng Shi, Shi Han, and
    Dongmei Zhang. 2021. Is a Single Model Enough? MuCoS: A Multi-Model Ensemble Learning
    Approach for Semantic Code Search. In *CIKM ’21: The 30th ACM International Conference
    on Information and Knowledge Management, Virtual Event, Queensland, Australia,
    November 1 - 5, 2021*, Gianluca Demartini, Guido Zuccon, J. Shane Culpepper, Zi Huang,
    and Hanghang Tong (Eds.). ACM, 2994–2998. [https://doi.org/10.1145/3459637.3482127](https://doi.org/10.1145/3459637.3482127)'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Du等（2021）杜伦、施晓舟、王彦林、石恩胜、韩时和张冬梅。2021年。《Is a Single Model Enough? MuCoS: A Multi-Model
    Ensemble Learning Approach for Semantic Code Search》。发表于*CIKM ’21: The 30th ACM
    International Conference on Information and Knowledge Management, Virtual Event,
    Queensland, Australia, November 1 - 5, 2021*，吉安卢卡·德马尔蒂尼、圭多·祖克隆、J·肖恩·卡尔佩珀、黄子和童杭杭（编）。ACM，2994–2998。
    [https://doi.org/10.1145/3459637.3482127](https://doi.org/10.1145/3459637.3482127)'
- en: Eberhart and McMillan (2022) Zachary Eberhart and Collin McMillan. 2022. Generating
    Clarifying Questions for Query Refinement in Source Code Search. In *IEEE International
    Conference on Software Analysis, Evolution and Reengineering, SANER 2022, Honolulu,
    HI, USA, March 15-18, 2022*. IEEE, 140–151. [https://doi.org/10.1109/SANER53432.2022.00028](https://doi.org/10.1109/SANER53432.2022.00028)
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eberhart和McMillan（2022）扎卡里·埃伯哈特和科林·麦克米兰。2022年。《Generating Clarifying Questions
    for Query Refinement in Source Code Search》。发表于*IEEE International Conference
    on Software Analysis, Evolution and Reengineering, SANER 2022, Honolulu, HI, USA,
    March 15-18, 2022*。IEEE，140–151。 [https://doi.org/10.1109/SANER53432.2022.00028](https://doi.org/10.1109/SANER53432.2022.00028)
- en: 'Feng et al. (2020) Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng
    Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou.
    2020. CodeBERT: A Pre-Trained Model for Programming and Natural Languages. In
    *Findings of the Association for Computational Linguistics: EMNLP 2020, Online
    Event, 16-20 November 2020* *(Findings of ACL, Vol. EMNLP 2020)*, Trevor Cohn,
    Yulan He, and Yang Liu (Eds.). Association for Computational Linguistics, 1536–1547.
    [https://doi.org/10.18653/v1/2020.findings-emnlp.139](https://doi.org/10.18653/v1/2020.findings-emnlp.139)'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Feng等（2020）张印丰、郭大雅、唐独雨、段楠、冯晓程、龚鸣、邵林军、秦冰、刘婷、姜大欣和周明。2020年。《CodeBERT: A Pre-Trained
    Model for Programming and Natural Languages》。发表于*Findings of the Association for
    Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020* *(Findings
    of ACL, Vol. EMNLP 2020)*，特雷弗·科恩、赫月岚和杨柳（编）。计算语言学协会，1536–1547。 [https://doi.org/10.18653/v1/2020.findings-emnlp.139](https://doi.org/10.18653/v1/2020.findings-emnlp.139)'
- en: 'Gharehyazie et al. (2017) Mohammad Gharehyazie, Baishakhi Ray, and Vladimir
    Filkov. 2017. Some from here, some from there: cross-project code reuse in GitHub.
    In *Proceedings of the 14th International Conference on Mining Software Repositories,
    MSR 2017, Buenos Aires, Argentina, May 20-28, 2017*, Jesús M. González-Barahona,
    Abram Hindle, and Lin Tan (Eds.). IEEE Computer Society, 291–301. [https://doi.org/10.1109/MSR.2017.15](https://doi.org/10.1109/MSR.2017.15)'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gharehyazie等（2017）穆罕默德·加雷哈耶齐、巴伊莎基·雷和弗拉基米尔·菲尔科夫。2017年。《Some from here, some
    from there: cross-project code reuse in GitHub》。发表于*Proceedings of the 14th International
    Conference on Mining Software Repositories, MSR 2017, Buenos Aires, Argentina,
    May 20-28, 2017*，耶苏斯·M·冈萨雷斯-巴拉赫纳、亚伯拉罕·辛德尔和林谭（编）。IEEE计算机协会，291–301。 [https://doi.org/10.1109/MSR.2017.15](https://doi.org/10.1109/MSR.2017.15)'
- en: 'Grazia and Pradel (2023) Luca Di Grazia and Michael Pradel. 2023. Code Search:
    A Survey of Techniques for Finding Code. *ACM Comput. Surv.* 55, 11 (2023), 220:1–220:31.
    [https://doi.org/10.1145/3565971](https://doi.org/10.1145/3565971)'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grazia和Pradel（2023）卢卡·迪·格拉齐亚和迈克尔·普拉德尔。2023年。代码搜索：代码查找技术的调查。*ACM计算机调查* 55，11（2023），220:1–220:31。[https://doi.org/10.1145/3565971](https://doi.org/10.1145/3565971)
- en: Gu et al. (2021a) Jian Gu, Zimin Chen, and Martin Monperrus. 2021a. Multimodal
    Representation for Neural Code Search. In *IEEE International Conference on Software
    Maintenance and Evolution, ICSME 2021, Luxembourg, September 27 - October 1, 2021*.
    IEEE, 483–494. [https://doi.org/10.1109/ICSME52107.2021.00049](https://doi.org/10.1109/ICSME52107.2021.00049)
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu等（2021a）简·顾、子民·陈和马丁·蒙佩鲁斯。2021a年。用于神经代码搜索的多模态表示。见于*IEEE国际软件维护与演化会议，ICSME 2021，卢森堡，2021年9月27日-10月1日*。IEEE，483–494。[https://doi.org/10.1109/ICSME52107.2021.00049](https://doi.org/10.1109/ICSME52107.2021.00049)
- en: 'Gu et al. (2021b) Wenchao Gu, Zongjie Li, Cuiyun Gao, Chaozheng Wang, Hongyu
    Zhang, Zenglin Xu, and Michael R. Lyu. 2021b. CRaDLe: Deep code retrieval based
    on semantic Dependency Learning. *Neural Networks* 141 (2021), 385–394. [https://doi.org/10.1016/j.neunet.2021.04.019](https://doi.org/10.1016/j.neunet.2021.04.019)'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu等（2021b）文超·顾、宗杰·李、崔云·高、超征·王、洪宇·张、增林·徐和迈克尔·R·吕。2021b年。CRaDLe：基于语义依赖学习的深度代码检索。*神经网络*
    141（2021），385–394。[https://doi.org/10.1016/j.neunet.2021.04.019](https://doi.org/10.1016/j.neunet.2021.04.019)
- en: 'Gu et al. (2022) Wenchao Gu, Yanlin Wang, Lun Du, Hongyu Zhang, Shi Han, Dongmei
    Zhang, and Michael R. Lyu. 2022. Accelerating Code Search with Deep Hashing and
    Code Classification. In *Proceedings of the 60th Annual Meeting of the Association
    for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland,
    May 22-27, 2022*, Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (Eds.).
    Association for Computational Linguistics, 2534–2544. [https://doi.org/10.18653/v1/2022.acl-long.181](https://doi.org/10.18653/v1/2022.acl-long.181)'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu等（2022）文超·顾、彦霖·王、伦·杜、洪宇·张、石汉、董梅·张和迈克尔·R·吕。2022年。利用深度哈希和代码分类加速代码搜索。见于*第60届计算语言学协会年会（第1卷：长篇论文），ACL
    2022，爱尔兰都柏林，2022年5月22-27日*，斯玛兰达·穆雷桑、普雷斯拉夫·纳科夫和艾琳·维拉维辛西奥（编）。计算语言学协会，2534–2544。[https://doi.org/10.18653/v1/2022.acl-long.181](https://doi.org/10.18653/v1/2022.acl-long.181)
- en: Gu et al. (2018) Xiaodong Gu, Hongyu Zhang, and Sunghun Kim. 2018. Deep code
    search. In *Proceedings of the 40th International Conference on Software Engineering,
    ICSE 2018, Gothenburg, Sweden, May 27 - June 03, 2018*, Michel Chaudron, Ivica
    Crnkovic, Marsha Chechik, and Mark Harman (Eds.). ACM, 933–944. [https://doi.org/10.1145/3180155.3180167](https://doi.org/10.1145/3180155.3180167)
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu等（2018）肖东·顾、洪宇·张和成勋·金。2018年。深度代码搜索。见于*第40届国际软件工程大会论文集，ICSE 2018，瑞典哥德堡，2018年5月27日-6月3日*，米歇尔·肖德隆、伊维卡·茨尔科维奇、玛莎·切奇克和马克·哈曼（编）。ACM，933–944。[https://doi.org/10.1145/3180155.3180167](https://doi.org/10.1145/3180155.3180167)
- en: 'Guo et al. (2022) Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming Zhou, and
    Jian Yin. 2022. UniXcoder: Unified Cross-Modal Pre-training for Code Representation.
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022*,
    Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (Eds.). Association for
    Computational Linguistics, 7212–7225. [https://doi.org/10.18653/v1/2022.acl-long.499](https://doi.org/10.18653/v1/2022.acl-long.499)'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo等（2022）达亚·郭、帅·卢、楠·段、彦霖·王、明·周和简·尹。2022年。UniXcoder：统一跨模态预训练的代码表示。见于*第60届计算语言学协会年会（第1卷：长篇论文），ACL
    2022，爱尔兰都柏林，2022年5月22-27日*，斯玛兰达·穆雷桑、普雷斯拉夫·纳科夫和艾琳·维拉维辛西奥（编）。计算语言学协会，7212–7225。[https://doi.org/10.18653/v1/2022.acl-long.499](https://doi.org/10.18653/v1/2022.acl-long.499)
- en: 'Guo et al. (2021) Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie
    Liu, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, Michele Tufano, Shao Kun
    Deng, Colin B. Clement, Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang, and
    Ming Zhou. 2021. GraphCodeBERT: Pre-training Code Representations with Data Flow.
    In *9th International Conference on Learning Representations, ICLR 2021, Virtual
    Event, Austria, May 3-7, 2021*. OpenReview.net. [https://openreview.net/forum?id=jLoC4ez43PZ](https://openreview.net/forum?id=jLoC4ez43PZ)'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo等（2021）达亚·郭、硕·任、帅·卢、章银·冯、杜宇·唐、舒杰·刘、龙·周、楠·段、阿列克谢·斯维亚特科夫斯基、盛宇·傅、米歇尔·图法诺、邵坤·邓、科林·B·克莱门特、道恩·德雷恩、尼尔·孙达雷桑、简·尹、大新·姜和明·周。2021年。GraphCodeBERT：利用数据流进行代码表示的预训练。见于*第9届国际学习表征会议，ICLR
    2021，虚拟会议，奥地利，2021年5月3-7日*。OpenReview.net。[https://openreview.net/forum?id=jLoC4ez43PZ](https://openreview.net/forum?id=jLoC4ez43PZ)
- en: Haldar et al. (2020) Rajarshi Haldar, Lingfei Wu, Jinjun Xiong, and Julia Hockenmaier.
    2020. A Multi-Perspective Architecture for Semantic Code Search. In *Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics, ACL
    2020, Online, July 5-10, 2020*, Dan Jurafsky, Joyce Chai, Natalie Schluter, and
    Joel R. Tetreault (Eds.). Association for Computational Linguistics, 8563–8568.
    [https://doi.org/10.18653/v1/2020.acl-main.758](https://doi.org/10.18653/v1/2020.acl-main.758)
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haldar et al. (2020) Rajarshi Haldar, Lingfei Wu, Jinjun Xiong, 和 Julia Hockenmaier.
    2020. 一种多视角架构用于语义代码搜索。见于*第58届计算语言学协会年会，ACL 2020，在线，2020年7月5-10日*，Dan Jurafsky,
    Joyce Chai, Natalie Schluter, 和 Joel R. Tetreault（编者）。计算语言学协会，8563–8568。 [https://doi.org/10.18653/v1/2020.acl-main.758](https://doi.org/10.18653/v1/2020.acl-main.758)
- en: Han et al. (2022) Hojae Han, Seung-won Hwang, Shuai Lu, Nan Duan, and Seungtaek
    Choi. 2022. Towards Compositional Generalization in Code Search. In *Proceedings
    of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP
    2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022*, Yoav Goldberg, Zornitsa
    Kozareva, and Yue Zhang (Eds.). Association for Computational Linguistics, 10743–10750.
    [https://aclanthology.org/2022.emnlp-main.737](https://aclanthology.org/2022.emnlp-main.737)
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han et al. (2022) Hojae Han, Seung-won Hwang, Shuai Lu, Nan Duan, 和 Seungtaek
    Choi. 2022. 代码搜索中的组合泛化。见于*2022年自然语言处理实证方法会议，EMNLP 2022，阿布扎比，阿拉伯联合酋长国，2022年12月7-11日*，Yoav
    Goldberg, Zornitsa Kozareva, 和 Yue Zhang（编者）。计算语言学协会，10743–10750。 [https://aclanthology.org/2022.emnlp-main.737](https://aclanthology.org/2022.emnlp-main.737)
- en: 'Heyman and Cutsem (2020) Geert Heyman and Tom Van Cutsem. 2020. Neural Code
    Search Revisited: Enhancing Code Snippet Retrieval through Natural Language Intent.
    *CoRR* abs/2008.12193 (2020). arXiv:2008.12193 [https://arxiv.org/abs/2008.12193](https://arxiv.org/abs/2008.12193)'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heyman and Cutsem (2020) Geert Heyman 和 Tom Van Cutsem. 2020. 神经代码搜索再探：通过自然语言意图增强代码片段检索。*CoRR*
    abs/2008.12193 (2020)。 arXiv:2008.12193 [https://arxiv.org/abs/2008.12193](https://arxiv.org/abs/2008.12193)
- en: 'Hill et al. (2014) Emily Hill, Manuel Roldan-Vega, Jerry Alan Fails, and Greg
    Mallet. 2014. NL-based query refinement and contextualized code search results:
    A user study. In *2014 Software Evolution Week - IEEE Conference on Software Maintenance,
    Reengineering, and Reverse Engineering, CSMR-WCRE 2014, Antwerp, Belgium, February
    3-6, 2014*, Serge Demeyer, Dave W. Binkley, and Filippo Ricca (Eds.). IEEE Computer
    Society, 34–43. [https://doi.org/10.1109/CSMR-WCRE.2014.6747190](https://doi.org/10.1109/CSMR-WCRE.2014.6747190)'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hill et al. (2014) Emily Hill, Manuel Roldan-Vega, Jerry Alan Fails, 和 Greg
    Mallet. 2014. 基于自然语言的查询优化和上下文化的代码搜索结果：一项用户研究。见于*2014年软件演化周 - IEEE 软件维护、重构和逆向工程会议，CSMR-WCRE
    2014，比利时安特卫普，2014年2月3-6日*，Serge Demeyer, Dave W. Binkley, 和 Filippo Ricca（编者）。IEEE
    计算机学会，34–43。 [https://doi.org/10.1109/CSMR-WCRE.2014.6747190](https://doi.org/10.1109/CSMR-WCRE.2014.6747190)
- en: Hindle et al. (2016) Abram Hindle, Earl T. Barr, Mark Gabel, Zhendong Su, and
    Premkumar T. Devanbu. 2016. On the naturalness of software. *Commun. ACM* 59,
    5 (2016), 122–131. [https://doi.org/10.1145/2902362](https://doi.org/10.1145/2902362)
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hindle et al. (2016) Abram Hindle, Earl T. Barr, Mark Gabel, Zhendong Su, 和
    Premkumar T. Devanbu. 2016. 软件的自然性。*Commun. ACM* 59, 5 (2016), 122–131。 [https://doi.org/10.1145/2902362](https://doi.org/10.1145/2902362)
- en: Hu et al. (2023) Fan Hu, Yanlin Wang, Lun Du, Xirong Li, Hongyu Zhang, Shi Han,
    and Dongmei Zhang. 2023. Revisiting Code Search in a Two-Stage Paradigm. In *Proceedings
    of the Sixteenth ACM International Conference on Web Search and Data Mining, WSDM
    2023, Singapore, 27 February 2023 - 3 March 2023*, Tat-Seng Chua, Hady W. Lauw,
    Luo Si, Evimaria Terzi, and Panayiotis Tsaparas (Eds.). ACM, 994–1002. [https://doi.org/10.1145/3539597.3570383](https://doi.org/10.1145/3539597.3570383)
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. (2023) Fan Hu, Yanlin Wang, Lun Du, Xirong Li, Hongyu Zhang, Shi Han,
    和 Dongmei Zhang. 2023. 在双阶段范式下重新审视代码搜索。见于*第十六届 ACM 国际网络搜索与数据挖掘会议，WSDM 2023，新加坡，2023年2月27日
    - 3月3日*，Tat-Seng Chua, Hady W. Lauw, Luo Si, Evimaria Terzi, 和 Panayiotis Tsaparas（编者）。ACM，994–1002。
    [https://doi.org/10.1145/3539597.3570383](https://doi.org/10.1145/3539597.3570383)
- en: Hu et al. (2020) Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2020. Deep
    code comment generation with hybrid lexical and syntactical information. *Empir.
    Softw. Eng.* 25, 3 (2020), 2179–2217. [https://doi.org/10.1007/s10664-019-09730-9](https://doi.org/10.1007/s10664-019-09730-9)
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. (2020) Xing Hu, Ge Li, Xin Xia, David Lo, 和 Zhi Jin. 2020. 结合词汇和句法信息的深度代码注释生成。*Empir.
    Softw. Eng.* 25, 3 (2020), 2179–2217。 [https://doi.org/10.1007/s10664-019-09730-9](https://doi.org/10.1007/s10664-019-09730-9)
- en: 'Huang et al. (2021) Junjie Huang, Duyu Tang, Linjun Shou, Ming Gong, Ke Xu,
    Daxin Jiang, Ming Zhou, and Nan Duan. 2021. CoSQA: 20, 000+ Web Queries for Code
    Search and Question Answering. In *Proceedings of the 59th Annual Meeting of the
    Association for Computational Linguistics and the 11th International Joint Conference
    on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual
    Event, August 1-6, 2021*, Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli
    (Eds.). Association for Computational Linguistics, 5690–5700. [https://doi.org/10.18653/v1/2021.acl-long.442](https://doi.org/10.18653/v1/2021.acl-long.442)'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang 等 (2021) Junjie Huang, Duyu Tang, Linjun Shou, Ming Gong, Ke Xu, Daxin
    Jiang, Ming Zhou 和 Nan Duan. 2021. CoSQA: 20,000+ 用于代码搜索和问答的网页查询。载于 *第59届计算语言学协会年会和第11届国际自然语言处理联合会议论文集，ACL/IJCNLP
    2021，（第1卷：长篇论文），虚拟会议，2021年8月1-6日*，Chengqing Zong, Fei Xia, Wenjie Li 和 Roberto
    Navigli (编)。计算语言学协会，5690–5700。[https://doi.org/10.18653/v1/2021.acl-long.442](https://doi.org/10.18653/v1/2021.acl-long.442)'
- en: Huang et al. (2019) Qing Huang, Yang Yang, and Ming Cheng. 2019. Deep learning
    the semantics of change sequences for query expansion. *Softw. Pract. Exp.* 49,
    11 (2019), 1600–1617. [https://doi.org/10.1002/spe.2736](https://doi.org/10.1002/spe.2736)
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等 (2019) Qing Huang, Yang Yang 和 Ming Cheng. 2019. 深度学习变化序列的语义以扩展查询。*Softw.
    Pract. Exp.* 49, 11 (2019), 1600–1617。[https://doi.org/10.1002/spe.2736](https://doi.org/10.1002/spe.2736)
- en: 'Husain et al. (2019) Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis,
    and Marc Brockschmidt. 2019. CodeSearchNet Challenge: Evaluating the State of
    Semantic Code Search. *CoRR* abs/1909.09436 (2019). arXiv:1909.09436 [http://arxiv.org/abs/1909.09436](http://arxiv.org/abs/1909.09436)'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Husain 等 (2019) Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis
    和 Marc Brockschmidt. 2019. CodeSearchNet 挑战：评估语义代码搜索的现状。*CoRR* abs/1909.09436
    (2019). arXiv:1909.09436 [http://arxiv.org/abs/1909.09436](http://arxiv.org/abs/1909.09436)
- en: 'Iyer et al. (2016) Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke
    Zettlemoyer. 2016. Summarizing Source Code using a Neural Attention Model. In
    *Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics,
    ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers*. The Association
    for Computer Linguistics. [https://doi.org/10.18653/v1/p16-1195](https://doi.org/10.18653/v1/p16-1195)'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iyer 等 (2016) Srinivasan Iyer, Ioannis Konstas, Alvin Cheung 和 Luke Zettlemoyer.
    2016. 使用神经注意力模型总结源代码。载于 *第54届计算语言学协会年会论文集，ACL 2016，2016年8月7-12日，德国柏林，第1卷：长篇论文*。计算机语言学协会。[https://doi.org/10.18653/v1/p16-1195](https://doi.org/10.18653/v1/p16-1195)
- en: Kanade et al. (2020) Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, and
    Kensen Shi. 2020. Learning and Evaluating Contextual Embedding of Source Code.
    In *Proceedings of the 37th International Conference on Machine Learning, ICML
    2020, 13-18 July 2020, Virtual Event* *(Proceedings of Machine Learning Research,
    Vol. 119)*. PMLR, 5110–5121. [http://proceedings.mlr.press/v119/kanade20a.html](http://proceedings.mlr.press/v119/kanade20a.html)
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kanade 等 (2020) Aditya Kanade, Petros Maniatis, Gogul Balakrishnan 和 Kensen
    Shi. 2020. 学习和评估源代码的上下文嵌入。载于 *第37届国际机器学习会议论文集，ICML 2020，2020年7月13-18日，虚拟会议* *(机器学习研究论文集，第119卷)*。PMLR，5110–5121。[http://proceedings.mlr.press/v119/kanade20a.html](http://proceedings.mlr.press/v119/kanade20a.html)
- en: Karmakar and Robbes (2021) Anjan Karmakar and Romain Robbes. 2021. What do pre-trained
    code models know about code?. In *36th IEEE/ACM International Conference on Automated
    Software Engineering, ASE 2021, Melbourne, Australia, November 15-19, 2021*. IEEE,
    1332–1336. [https://doi.org/10.1109/ASE51524.2021.9678927](https://doi.org/10.1109/ASE51524.2021.9678927)
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karmakar 和 Robbes (2021) Anjan Karmakar 和 Romain Robbes. 2021. 预训练代码模型对代码了解多少？载于
    *第36届IEEE/ACM自动化软件工程国际会议，ASE 2021，2021年11月15-19日，澳大利亚墨尔本*。IEEE，1332–1336。[https://doi.org/10.1109/ASE51524.2021.9678927](https://doi.org/10.1109/ASE51524.2021.9678927)
- en: Keele (2007) Staffs Keele. 2007. *Guidelines for performing systematic literature
    reviews in software engineering*. Technical Report. Ver. 2.3 EBSE Technical Report.
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keele (2007) Staffs Keele. 2007. *在软件工程中执行系统文献综述的指南*。技术报告。Ver. 2.3 EBSE技术报告。
- en: 'Khalifa (2019) Muhammad Khalifa. 2019. Semantic Source Code Search: A Study
    of the Past and a Glimpse at the Future. *CoRR* abs/1908.06738 (2019). arXiv:1908.06738
    [http://arxiv.org/abs/1908.06738](http://arxiv.org/abs/1908.06738) Withdrawn..'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khalifa (2019) Muhammad Khalifa. 2019. 语义源代码搜索：对过去的研究和对未来的展望。*CoRR* abs/1908.06738
    (2019). arXiv:1908.06738 [http://arxiv.org/abs/1908.06738](http://arxiv.org/abs/1908.06738)
    已撤回。
- en: 'Lachaux et al. (2021) Marie-Anne Lachaux, Baptiste Rozière, Marc Szafraniec,
    and Guillaume Lample. 2021. DOBF: A Deobfuscation Pre-Training Objective for Programming
    Languages. In *Advances in Neural Information Processing Systems 34: Annual Conference
    on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021,
    virtual*, Marc’Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang,
    and Jennifer Wortman Vaughan (Eds.). 14967–14979. [https://proceedings.neurips.cc/paper/2021/hash/7d6548bdc0082aacc950ed35e91fcccb-Abstract.html](https://proceedings.neurips.cc/paper/2021/hash/7d6548bdc0082aacc950ed35e91fcccb-Abstract.html)'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lachaux et al. (2021) Marie-Anne Lachaux, Baptiste Rozière, Marc Szafraniec,
    和 Guillaume Lample. 2021. DOBF：编程语言的去混淆预训练目标。见于 *神经信息处理系统进展34：2021年神经信息处理系统年会，NeurIPS
    2021，2021年12月6-14日，虚拟会议*，Marc’Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin,
    Percy Liang, 和 Jennifer Wortman Vaughan（编辑）。14967–14979。 [https://proceedings.neurips.cc/paper/2021/hash/7d6548bdc0082aacc950ed35e91fcccb-Abstract.html](https://proceedings.neurips.cc/paper/2021/hash/7d6548bdc0082aacc950ed35e91fcccb-Abstract.html)
- en: Li et al. (2019) Hongyu Li, Seohyun Kim, and Satish Chandra. 2019. Neural Code
    Search Evaluation Dataset. *CoRR* abs/1908.09804 (2019). arXiv:1908.09804 [http://arxiv.org/abs/1908.09804](http://arxiv.org/abs/1908.09804)
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2019) Hongyu Li, Seohyun Kim, 和 Satish Chandra. 2019. 神经代码搜索评估数据集。*CoRR*
    abs/1908.09804 (2019). arXiv:1908.09804 [http://arxiv.org/abs/1908.09804](http://arxiv.org/abs/1908.09804)
- en: Li et al. (2022d) Haochen Li, Chunyan Miao, Cyril Leung, Yanxian Huang, Yuan
    Huang, Hongyu Zhang, and Yanlin Wang. 2022d. Exploring Representation-level Augmentation
    for Code Search. In *Proceedings of the 2022 Conference on Empirical Methods in
    Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December
    7-11, 2022*, Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (Eds.). Association
    for Computational Linguistics, 4924–4936. [https://aclanthology.org/2022.emnlp-main.327](https://aclanthology.org/2022.emnlp-main.327)
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2022d) Haochen Li, Chunyan Miao, Cyril Leung, Yanxian Huang, Yuan
    Huang, Hongyu Zhang, and Yanlin Wang. 2022d. 探索表示层级的数据增强用于代码搜索。见于 *2022年自然语言处理实证方法会议论文集，EMNLP
    2022，阿布扎比，阿拉伯联合酋长国，2022年12月7-11日*，Yoav Goldberg, Zornitsa Kozareva, 和 Yue Zhang（编辑）。计算语言学协会，4924–4936。
    [https://aclanthology.org/2022.emnlp-main.327](https://aclanthology.org/2022.emnlp-main.327)
- en: 'Li et al. (2022a) Xiaonan Li, Yeyun Gong, Yelong Shen, Xipeng Qiu, Hang Zhang,
    Bolun Yao, Weizhen Qi, Daxin Jiang, Weizhu Chen, and Nan Duan. 2022a. CodeRetriever:
    Unimodal and Bimodal Contrastive Learning. In *Proceedings of the 2022 Conference
    on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United
    Arab Emirates, December 7-11, 2022*. Association for Computational Linguistics.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2022a) Xiaonan Li, Yeyun Gong, Yelong Shen, Xipeng Qiu, Hang Zhang,
    Bolun Yao, Weizhen Qi, Daxin Jiang, Weizhu Chen, 和 Nan Duan. 2022a. CodeRetriever：单模态和双模态对比学习。见于
    *2022年自然语言处理实证方法会议论文集，EMNLP 2022，阿布扎比，阿拉伯联合酋长国，2022年12月7-11日*。计算语言学协会。
- en: 'Li et al. (2022b) Xiaonan Li, Daya Guo, Yeyun Gong, Yun Lin, Yelong Shen, Xipeng
    Qiu, Daxin Jiang, Weizhu Chen, and Nan Duan. 2022b. Soft-Labeled Contrastive Pre-Training
    for Function-Level Code Representation. In *Findings of the Association for Computational
    Linguistics: EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022*,
    Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (Eds.). Association for Computational
    Linguistics, 118–129. [https://aclanthology.org/2022.findings-emnlp.9](https://aclanthology.org/2022.findings-emnlp.9)'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2022b) Xiaonan Li, Daya Guo, Yeyun Gong, Yun Lin, Yelong Shen, Xipeng
    Qiu, Daxin Jiang, Weizhu Chen, 和 Nan Duan. 2022b. 用于函数级代码表示的软标签对比预训练。见于 *计算语言学协会发现：EMNLP
    2022，阿布扎比，阿拉伯联合酋长国，2022年12月7-11日*，Yoav Goldberg, Zornitsa Kozareva, 和 Yue Zhang（编辑）。计算语言学协会，118–129。
    [https://aclanthology.org/2022.findings-emnlp.9](https://aclanthology.org/2022.findings-emnlp.9)
- en: Li et al. (2022e) Yiyang Li, Hongqiu Wu, and Hai Zhao. 2022e. Semantic-Preserving
    Adversarial Code Comprehension. In *Proceedings of the 29th International Conference
    on Computational Linguistics, COLING 2022, Gyeongju, Republic of Korea, October
    12-17, 2022*, Nicoletta Calzolari, Chu-Ren Huang, Hansaem Kim, James Pustejovsky,
    Leo Wanner, Key-Sun Choi, Pum-Mo Ryu, Hsin-Hsi Chen, Lucia Donatelli, Heng Ji,
    Sadao Kurohashi, Patrizia Paggio, Nianwen Xue, Seokhwan Kim, Younggyun Hahm, Zhong
    He, Tony Kyungil Lee, Enrico Santus, Francis Bond, and Seung-Hoon Na (Eds.). International
    Committee on Computational Linguistics, 3017–3028. [https://aclanthology.org/2022.coling-1.267](https://aclanthology.org/2022.coling-1.267)
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2022e) Yiyang Li, Hongqiu Wu, 和 Hai Zhao. 2022e. 语义保留对抗性代码理解. 在 *第29届国际计算语言学会议论文集，COLING
    2022，韩国庆州，2022年10月12-17日*，Nicoletta Calzolari, Chu-Ren Huang, Hansaem Kim, James
    Pustejovsky, Leo Wanner, Key-Sun Choi, Pum-Mo Ryu, Hsin-Hsi Chen, Lucia Donatelli,
    Heng Ji, Sadao Kurohashi, Patrizia Paggio, Nianwen Xue, Seokhwan Kim, Younggyun
    Hahm, Zhong He, Tony Kyungil Lee, Enrico Santus, Francis Bond, 和 Seung-Hoon Na
    (编辑). 国际计算语言学委员会，3017–3028. [https://aclanthology.org/2022.coling-1.267](https://aclanthology.org/2022.coling-1.267)
- en: Li et al. (2022c) Zhiyu Li, Shuai Lu, Daya Guo, Nan Duan, Shailesh Jannu, Grant
    Jenks, Deep Majumder, Jared Green, Alexey Svyatkovskiy, Shengyu Fu, and Neel Sundaresan.
    2022c. Automating code review activities by large-scale pre-training. In *Proceedings
    of the 30th ACM Joint European Software Engineering Conference and Symposium on
    the Foundations of Software Engineering, ESEC/FSE 2022, Singapore, Singapore,
    November 14-18, 2022*, Abhik Roychoudhury, Cristian Cadar, and Miryung Kim (Eds.).
    ACM, 1035–1047. [https://doi.org/10.1145/3540250.3549081](https://doi.org/10.1145/3540250.3549081)
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2022c) Zhiyu Li, Shuai Lu, Daya Guo, Nan Duan, Shailesh Jannu, Grant Jenks,
    Deep Majumder, Jared Green, Alexey Svyatkovskiy, Shengyu Fu, 和 Neel Sundaresan.
    2022c. 通过大规模预训练自动化代码审查活动. 在 *第30届ACM欧洲联合软件工程会议与软件工程基础研讨会，ESEC/FSE 2022，新加坡，2022年11月14-18日*，Abhik
    Roychoudhury, Cristian Cadar, 和 Miryung Kim (编辑). ACM，1035–1047. [https://doi.org/10.1145/3540250.3549081](https://doi.org/10.1145/3540250.3549081)
- en: 'Ling et al. (2020) Chunyang Ling, Zeqi Lin, Yanzhen Zou, and Bing Xie. 2020.
    Adaptive Deep Code Search. In *ICPC ’20: 28th International Conference on Program
    Comprehension, Seoul, Republic of Korea, July 13-15, 2020*. ACM, 48–59. [https://doi.org/10.1145/3387904.3389278](https://doi.org/10.1145/3387904.3389278)'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ling 等 (2020) Chunyang Ling, Zeqi Lin, Yanzhen Zou, 和 Bing Xie. 2020. 自适应深度代码搜索.
    在 *ICPC ’20: 第28届国际程序理解会议，韩国首尔，2020年7月13-15日*. ACM，48–59. [https://doi.org/10.1145/3387904.3389278](https://doi.org/10.1145/3387904.3389278)'
- en: Ling et al. (2021) Xiang Ling, Lingfei Wu, Saizhuo Wang, Gaoning Pan, Tengfei
    Ma, Fangli Xu, Alex X. Liu, Chunming Wu, and Shouling Ji. 2021. Deep Graph Matching
    and Searching for Semantic Code Retrieval. *ACM Trans. Knowl. Discov. Data* 15,
    5 (2021), 88:1–88:21. [https://doi.org/10.1145/3447571](https://doi.org/10.1145/3447571)
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ling 等 (2021) Xiang Ling, Lingfei Wu, Saizhuo Wang, Gaoning Pan, Tengfei Ma,
    Fangli Xu, Alex X. Liu, Chunming Wu, 和 Shouling Ji. 2021. 深度图匹配与语义代码检索. *ACM 知识发现与数据*
    15, 5 (2021), 88:1–88:21. [https://doi.org/10.1145/3447571](https://doi.org/10.1145/3447571)
- en: Liu et al. (2022) Chao Liu, Xin Xia, David Lo, Cuiyun Gao, Xiaohu Yang, and
    John C. Grundy. 2022. Opportunities and Challenges in Code Search Tools. *ACM
    Comput. Surv.* 54, 9 (2022), 196:1–196:40. [https://doi.org/10.1145/3480027](https://doi.org/10.1145/3480027)
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 (2022) Chao Liu, Xin Xia, David Lo, Cuiyun Gao, Xiaohu Yang, 和 John C.
    Grundy. 2022. 代码搜索工具中的机遇与挑战. *ACM 计算机调查* 54, 9 (2022), 196:1–196:40. [https://doi.org/10.1145/3480027](https://doi.org/10.1145/3480027)
- en: Liu et al. (2019a) Jason Liu, Seohyun Kim, Vijayaraghavan Murali, Swarat Chaudhuri,
    and Satish Chandra. 2019a. Neural query expansion for code search. In *Proceedings
    of the 3rd ACM SIGPLAN International Workshop on Machine Learning and Programming
    Languages, MAPL@PLDI 2019, Phoenix, AZ, USA, June 22, 2019*, Tim Mattson, Abdullah
    Muzahid, and Armando Solar-Lezama (Eds.). ACM, 29–37. [https://doi.org/10.1145/3315508.3329975](https://doi.org/10.1145/3315508.3329975)
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 (2019a) Jason Liu, Seohyun Kim, Vijayaraghavan Murali, Swarat Chaudhuri,
    和 Satish Chandra. 2019a. 用于代码搜索的神经查询扩展. 在 *第3届ACM SIGPLAN国际机器学习与编程语言研讨会论文集，MAPL@PLDI
    2019，美国亚利桑那州凤凰城，2019年6月22日*，Tim Mattson, Abdullah Muzahid, 和 Armando Solar-Lezama
    (编辑). ACM，29–37. [https://doi.org/10.1145/3315508.3329975](https://doi.org/10.1145/3315508.3329975)
- en: 'Liu et al. (2023) Shangqing Liu, Xiaofei Xie, Jing Kai Siow, Lei Ma, Guozhu
    Meng, and Yang Liu. 2023. GraphSearchNet: Enhancing GNNs via Capturing Global
    Dependencies for Semantic Code Search. *IEEE Trans. Software Eng.* 49, 4 (2023),
    2839–2855. [https://doi.org/10.1109/TSE.2022.3233901](https://doi.org/10.1109/TSE.2022.3233901)'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 (2023) Shangqing Liu, Xiaofei Xie, Jing Kai Siow, Lei Ma, Guozhu Meng
    和 Yang Liu. 2023. GraphSearchNet：通过捕捉全局依赖提升 GNNs 用于语义代码搜索。*IEEE 软件工程学报* 49, 4
    (2023), 2839–2855. [https://doi.org/10.1109/TSE.2022.3233901](https://doi.org/10.1109/TSE.2022.3233901)
- en: 'Liu et al. (2019b) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019b.
    RoBERTa: A Robustly Optimized BERT Pretraining Approach. *CoRR* abs/1907.11692
    (2019). arXiv:1907.11692 [http://arxiv.org/abs/1907.11692](http://arxiv.org/abs/1907.11692)'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 (2019b) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi
    Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer 和 Veselin Stoyanov. 2019b. RoBERTa：一种强健优化的
    BERT 预训练方法。*CoRR* abs/1907.11692 (2019). arXiv:1907.11692 [http://arxiv.org/abs/1907.11692](http://arxiv.org/abs/1907.11692)
- en: 'Lu et al. (2021) Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy,
    Ambrosio Blanco, Colin B. Clement, Dawn Drain, Daxin Jiang, Duyu Tang, Ge Li,
    Lidong Zhou, Linjun Shou, Long Zhou, Michele Tufano, Ming Gong, Ming Zhou, Nan
    Duan, Neel Sundaresan, Shao Kun Deng, Shengyu Fu, and Shujie Liu. 2021. CodeXGLUE:
    A Machine Learning Benchmark Dataset for Code Understanding and Generation. In
    *Proceedings of the Neural Information Processing Systems Track on Datasets and
    Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual*, Joaquin
    Vanschoren and Sai-Kit Yeung (Eds.). [https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/c16a5320fa475530d9583c34fd356ef5-Abstract-round1.html](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/c16a5320fa475530d9583c34fd356ef5-Abstract-round1.html)'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu 等 (2021) Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy,
    Ambrosio Blanco, Colin B. Clement, Dawn Drain, Daxin Jiang, Duyu Tang, Ge Li,
    Lidong Zhou, Linjun Shou, Long Zhou, Michele Tufano, Ming Gong, Ming Zhou, Nan
    Duan, Neel Sundaresan, Shao Kun Deng, Shengyu Fu 和 Shujie Liu. 2021. CodeXGLUE：用于代码理解和生成的机器学习基准数据集。收录于
    *神经信息处理系统数据集与基准跟踪会议论文集 1，NeurIPS 数据集与基准 2021，2021年12月，虚拟*，Joaquin Vanschoren 和
    Sai-Kit Yeung (编). [https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/c16a5320fa475530d9583c34fd356ef5-Abstract-round1.html](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/c16a5320fa475530d9583c34fd356ef5-Abstract-round1.html)
- en: 'Lv et al. (2015) Fei Lv, Hongyu Zhang, Jian-Guang Lou, Shaowei Wang, Dongmei
    Zhang, and Jianjun Zhao. 2015. CodeHow: Effective Code Search Based on API Understanding
    and Extended Boolean Model (E). In *30th IEEE/ACM International Conference on
    Automated Software Engineering, ASE 2015, Lincoln, NE, USA, November 9-13, 2015*,
    Myra B. Cohen, Lars Grunske, and Michael Whalen (Eds.). IEEE Computer Society,
    260–270. [https://doi.org/10.1109/ASE.2015.42](https://doi.org/10.1109/ASE.2015.42)'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lv 等 (2015) Fei Lv, Hongyu Zhang, Jian-Guang Lou, Shaowei Wang, Dongmei Zhang
    和 Jianjun Zhao. 2015. CodeHow：基于 API 理解和扩展布尔模型 (E) 的有效代码搜索。收录于 *第30届 IEEE/ACM
    国际自动化软件工程会议，ASE 2015，美国内布拉斯加州林肯，2015年11月9-13日*，Myra B. Cohen, Lars Grunske 和 Michael
    Whalen (编). IEEE 计算机协会, 260–270. [https://doi.org/10.1109/ASE.2015.42](https://doi.org/10.1109/ASE.2015.42)
- en: 'Ma et al. (2023) Yingwei Ma, Yue Yu, Shanshan Li, Zhouyang Jia, Jun Ma, Rulin
    Xu, Wei Dong, and Xiangke Liao. 2023. MulCS: Towards a Unified Deep Representation
    for Multilingual Code Search. In *IEEE International Conference on Software Analysis,
    Evolution and Reengineering, SANER 2023, Taipa, Macao, March 21-24, 2023*, Tao
    Zhang, Xin Xia, and Nicole Novielli (Eds.). IEEE, 120–131. [https://doi.org/10.1109/SANER56733.2023.00021](https://doi.org/10.1109/SANER56733.2023.00021)'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma 等 (2023) Yingwei Ma, Yue Yu, Shanshan Li, Zhouyang Jia, Jun Ma, Rulin Xu,
    Wei Dong 和 Xiangke Liao. 2023. MulCS：面向多语言代码搜索的统一深度表示。收录于 *IEEE 国际软件分析、演化与重构会议，SANER
    2023，澳门塔石，2023年3月21-24日*，Tao Zhang, Xin Xia 和 Nicole Novielli (编). IEEE, 120–131.
    [https://doi.org/10.1109/SANER56733.2023.00021](https://doi.org/10.1109/SANER56733.2023.00021)
- en: 'Markovtsev and Long (2018) Vadim Markovtsev and Waren Long. 2018. Public git
    archive: a big code dataset for all. In *Proceedings of the 15th International
    Conference on Mining Software Repositories, MSR 2018, Gothenburg, Sweden, May
    28-29, 2018*, Andy Zaidman, Yasutaka Kamei, and Emily Hill (Eds.). ACM, 34–37.
    [https://doi.org/10.1145/3196398.3196464](https://doi.org/10.1145/3196398.3196464)'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Markovtsev 和 Long (2018) Vadim Markovtsev 和 Waren Long. 2018. 公共 Git 归档：一个大型代码数据集。收录于
    *第15届国际软件仓库挖掘会议论文集，MSR 2018，瑞典哥德堡，2018年5月28-29日*，Andy Zaidman, Yasutaka Kamei
    和 Emily Hill (编). ACM, 34–37. [https://doi.org/10.1145/3196398.3196464](https://doi.org/10.1145/3196398.3196464)
- en: 'McMillan et al. (2011) Collin McMillan, Mark Grechanik, Denys Poshyvanyk, Qing
    Xie, and Chen Fu. 2011. Portfolio: finding relevant functions and their usage.
    In *Proceedings of the 33rd International Conference on Software Engineering,
    ICSE 2011, Waikiki, Honolulu , HI, USA, May 21-28, 2011*, Richard N. Taylor, Harald C.
    Gall, and Nenad Medvidovic (Eds.). ACM, 111–120. [https://doi.org/10.1145/1985793.1985809](https://doi.org/10.1145/1985793.1985809)'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McMillan 等（2011）Collin McMillan、Mark Grechanik、Denys Poshyvanyk、Qing Xie 和 Chen
    Fu。2011。Portfolio：查找相关函数及其使用。见于 *第33届国际软件工程会议论文集，ICSE 2011，怀基基，檀香山，HI，美国，2011年5月21-28日*，Richard
    N. Taylor、Harald C. Gall 和 Nenad Medvidovic（编辑）。ACM，111–120。 [https://doi.org/10.1145/1985793.1985809](https://doi.org/10.1145/1985793.1985809)
- en: Mou et al. (2016) Lili Mou, Ge Li, Lu Zhang, Tao Wang, and Zhi Jin. 2016. Convolutional
    Neural Networks over Tree Structures for Programming Language Processing. In *Proceedings
    of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016,
    Phoenix, Arizona, USA*, Dale Schuurmans and Michael P. Wellman (Eds.). AAAI Press,
    1287–1293. [http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11775](http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11775)
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mou 等（2016）Lili Mou、Ge Li、Lu Zhang、Tao Wang 和 Zhi Jin。2016。基于树结构的卷积神经网络用于编程语言处理。见于
    *第三十届美国人工智能协会会议论文集，2016年2月12-17日，凤凰城，亚利桑那州，美国*，Dale Schuurmans 和 Michael P. Wellman（编辑）。AAAI
    Press，1287–1293。 [http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11775](http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11775)
- en: Nie et al. (2016) Liming Nie, He Jiang, Zhilei Ren, Zeyi Sun, and Xiaochen Li.
    2016. Query Expansion Based on Crowd Knowledge for Code Search. *IEEE Trans. Serv.
    Comput.* 9, 5 (2016), 771–783. [https://doi.org/10.1109/TSC.2016.2560165](https://doi.org/10.1109/TSC.2016.2560165)
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nie 等（2016）Liming Nie、He Jiang、Zhilei Ren、Zeyi Sun 和 Xiaochen Li。2016。基于众包知识的查询扩展用于代码搜索。*IEEE服务计算汇刊*
    9, 5（2016），771–783。 [https://doi.org/10.1109/TSC.2016.2560165](https://doi.org/10.1109/TSC.2016.2560165)
- en: 'Niu et al. (2022) Changan Niu, Chuanyi Li, Vincent Ng, Jidong Ge, Liguo Huang,
    and Bin Luo. 2022. SPT-Code: Sequence-to-Sequence Pre-Training for Learning Source
    Code Representations. In *44th IEEE/ACM 44th International Conference on Software
    Engineering, ICSE 2022, Pittsburgh, PA, USA, May 25-27, 2022*. ACM, 1–13. [https://doi.org/10.1145/3510003.3510096](https://doi.org/10.1145/3510003.3510096)'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Niu 等（2022）Changan Niu、Chuanyi Li、Vincent Ng、Jidong Ge、Liguo Huang 和 Bin Luo。2022。SPT-Code：序列到序列预训练用于学习源代码表示。见于
    *第44届IEEE/ACM国际软件工程会议，ICSE 2022，匹兹堡，PA，美国，2022年5月25-27日*。ACM，1–13。 [https://doi.org/10.1145/3510003.3510096](https://doi.org/10.1145/3510003.3510096)
- en: OpenAI (2023) OpenAI. 2023. GPT-4 Technical Report. *CoRR* abs/2303.08774 (2023).
    [https://doi.org/10.48550/arXiv.2303.08774](https://doi.org/10.48550/arXiv.2303.08774)
    arXiv:2303.08774
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2023）OpenAI。2023。GPT-4技术报告。*计算机科学报告* abs/2303.08774（2023）。 [https://doi.org/10.48550/arXiv.2303.08774](https://doi.org/10.48550/arXiv.2303.08774)
    arXiv:2303.08774
- en: Park et al. (2023) Shinwoo Park, Youngwook Kim, and Yo-Sub Han. 2023. Contrastive
    Learning with Keyword-based Data Augmentation for Code Search and Code Question
    Answering. In *Proceedings of the 17th Conference of the European Chapter of the
    Association for Computational Linguistics, EACL 2023, Dubrovnik, Croatia, May
    2-6, 2023*, Andreas Vlachos and Isabelle Augenstein (Eds.). Association for Computational
    Linguistics, 3591–3601. [https://aclanthology.org/2023.eacl-main.262](https://aclanthology.org/2023.eacl-main.262)
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等（2023）Shinwoo Park、Youngwook Kim 和 Yo-Sub Han。2023。基于关键词的数据增强对比学习用于代码搜索和代码问题回答。见于
    *第17届欧洲计算语言学协会会议论文集，EACL 2023，杜布罗夫尼克，克罗地亚，2023年5月2-6日*，Andreas Vlachos 和 Isabelle
    Augenstein（编辑）。计算语言学协会，3591–3601。 [https://aclanthology.org/2023.eacl-main.262](https://aclanthology.org/2023.eacl-main.262)
- en: 'Petersen et al. (2015) Kai Petersen, Sairam Vakkalanka, and Ludwik Kuzniarz.
    2015. Guidelines for conducting systematic mapping studies in software engineering:
    An update. *Inf. Softw. Technol.* 64 (2015), 1–18. [https://doi.org/10.1016/j.infsof.2015.03.007](https://doi.org/10.1016/j.infsof.2015.03.007)'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Petersen 等（2015）Kai Petersen、Sairam Vakkalanka 和 Ludwik Kuzniarz。2015。软件工程系统映射研究的指南：更新版。*信息与软件技术*
    64（2015），1–18。 [https://doi.org/10.1016/j.infsof.2015.03.007](https://doi.org/10.1016/j.infsof.2015.03.007)
- en: 'Rahman (2019) Mohammad Masudur Rahman. 2019. Supporting code search with context-aware,
    analytics-driven, effective query reformulation. In *Proceedings of the 41st International
    Conference on Software Engineering: Companion Proceedings, ICSE 2019, Montreal,
    QC, Canada, May 25-31, 2019*, Joanne M. Atlee, Tevfik Bultan, and Jon Whittle
    (Eds.). IEEE / ACM, 226–229. [https://doi.org/10.1109/ICSE-Companion.2019.00088](https://doi.org/10.1109/ICSE-Companion.2019.00088)'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rahman（2019）Mohammad Masudur Rahman. 2019. 通过上下文感知、分析驱动的有效查询重构支持代码搜索。见 *第 41
    届国际软件工程大会：附录论文集，ICSE 2019，蒙特利尔，QC，加拿大，2019 年 5 月 25-31 日*，Joanne M. Atlee、Tevfik
    Bultan 和 Jon Whittle（编辑）。IEEE / ACM，226–229。 [https://doi.org/10.1109/ICSE-Companion.2019.00088](https://doi.org/10.1109/ICSE-Companion.2019.00088)
- en: Rahman and Roy (2018) Mohammad Masudur Rahman and Chanchal K. Roy. 2018. Effective
    Reformulation of Query for Code Search Using Crowdsourced Knowledge and Extra-Large
    Data Analytics. In *2018 IEEE International Conference on Software Maintenance
    and Evolution, ICSME 2018, Madrid, Spain, September 23-29, 2018*. IEEE Computer
    Society, 473–484. [https://doi.org/10.1109/ICSME.2018.00057](https://doi.org/10.1109/ICSME.2018.00057)
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rahman 和 Roy（2018）Mohammad Masudur Rahman 和 Chanchal K. Roy. 2018. 利用众包知识和超大数据分析进行代码搜索的有效查询重构。见
    *2018 IEEE 国际软件维护与演化会议，ICSME 2018，马德里，西班牙，2018 年 9 月 23-29 日*。IEEE 计算机学会，473–484。
    [https://doi.org/10.1109/ICSME.2018.00057](https://doi.org/10.1109/ICSME.2018.00057)
- en: Rahman et al. (2019) Mohammad Masudur Rahman, Chanchal K. Roy, and David Lo.
    2019. Automatic query reformulation for code search using crowdsourced knowledge.
    *Empir. Softw. Eng.* 24, 4 (2019), 1869–1924. [https://doi.org/10.1007/s10664-018-9671-0](https://doi.org/10.1007/s10664-018-9671-0)
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rahman 等（2019）Mohammad Masudur Rahman、Chanchal K. Roy 和 David Lo. 2019. 利用众包知识进行代码搜索的自动查询重构。*Empir.
    Softw. Eng.* 24, 4（2019），1869–1924。 [https://doi.org/10.1007/s10664-018-9671-0](https://doi.org/10.1007/s10664-018-9671-0)
- en: 'Sachdev et al. (2018) Saksham Sachdev, Hongyu Li, Sifei Luan, Seohyun Kim,
    Koushik Sen, and Satish Chandra. 2018. Retrieval on source code: a neural code
    search. In *Proceedings of the 2nd ACM SIGPLAN International Workshop on Machine
    Learning and Programming Languages, MAPL@PLDI 2018, Philadelphia, PA, USA, June
    18-22, 2018*, Justin Gottschlich and Alvin Cheung (Eds.). ACM, 31–41. [https://doi.org/10.1145/3211346.3211353](https://doi.org/10.1145/3211346.3211353)'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sachdev 等（2018）Saksham Sachdev、Hongyu Li、Sifei Luan、Seohyun Kim、Koushik Sen
    和 Satish Chandra. 2018. 在源代码上的检索：一种神经代码搜索方法。见 *第二届 ACM SIGPLAN 国际机器学习与编程语言研讨会论文集，MAPL@PLDI
    2018，费城，PA，美国，2018 年 6 月 18-22 日*，Justin Gottschlich 和 Alvin Cheung（编辑）。ACM，31–41。
    [https://doi.org/10.1145/3211346.3211353](https://doi.org/10.1145/3211346.3211353)
- en: Salza et al. (2023) Pasquale Salza, Christoph Schwizer, Jian Gu, and Harald C.
    Gall. 2023. On the Effectiveness of Transfer Learning for Code Search. *IEEE Trans.
    Software Eng.* 49, 4 (2023), 1804–1822. [https://doi.org/10.1109/TSE.2022.3192755](https://doi.org/10.1109/TSE.2022.3192755)
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salza 等（2023）Pasquale Salza、Christoph Schwizer、Jian Gu 和 Harald C. Gall. 2023.
    转移学习在代码搜索中的有效性。*IEEE Trans. Software Eng.* 49, 4（2023），1804–1822。 [https://doi.org/10.1109/TSE.2022.3192755](https://doi.org/10.1109/TSE.2022.3192755)
- en: Shi et al. (2022) Yucen Shi, Ying Yin, Zhengkui Wang, David Lo, Tao Zhang, Xin
    Xia, Yuhai Zhao, and Bowen Xu. 2022. How to better utilize code graphs in semantic
    code search?. In *Proceedings of the 30th ACM Joint European Software Engineering
    Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE
    2022, Singapore, Singapore, November 14-18, 2022*, Abhik Roychoudhury, Cristian
    Cadar, and Miryung Kim (Eds.). ACM, 722–733. [https://doi.org/10.1145/3540250.3549087](https://doi.org/10.1145/3540250.3549087)
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等（2022）Yucen Shi、Ying Yin、Zhengkui Wang、David Lo、Tao Zhang、Xin Xia、Yuhai
    Zhao 和 Bowen Xu. 2022. 如何更好地利用代码图进行语义代码搜索？见 *第 30 届 ACM 欧洲软件工程联合会议暨软件工程基础研讨会论文集，ESEC/FSE
    2022，新加坡，新加坡，2022 年 11 月 14-18 日*，Abhik Roychoudhury、Cristian Cadar 和 Miryung
    Kim（编辑）。ACM，722–733。 [https://doi.org/10.1145/3540250.3549087](https://doi.org/10.1145/3540250.3549087)
- en: 'Shuai et al. (2020) Jianhang Shuai, Ling Xu, Chao Liu, Meng Yan, Xin Xia, and
    Yan Lei. 2020. Improving Code Search with Co-Attentive Representation Learning.
    In *ICPC ’20: 28th International Conference on Program Comprehension, Seoul, Republic
    of Korea, July 13-15, 2020*. ACM, 196–207. [https://doi.org/10.1145/3387904.3389269](https://doi.org/10.1145/3387904.3389269)'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shuai 等（2020）Jianhang Shuai、Ling Xu、Chao Liu、Meng Yan、Xin Xia 和 Yan Lei. 2020.
    通过协同注意力表示学习提高代码搜索。见 *ICPC ’20：第 28 届程序理解国际会议，首尔，韩国，2020 年 7 月 13-15 日*。ACM，196–207。
    [https://doi.org/10.1145/3387904.3389269](https://doi.org/10.1145/3387904.3389269)
- en: Sirres et al. (2018) Raphael Sirres, Tegawendé F. Bissyandé, Dongsun Kim, David
    Lo, Jacques Klein, Kisub Kim, and Yves Le Traon. 2018. Augmenting and structuring
    user queries to support efficient free-form code search. In *Proceedings of the
    40th International Conference on Software Engineering, ICSE 2018, Gothenburg,
    Sweden, May 27 - June 03, 2018*, Michel Chaudron, Ivica Crnkovic, Marsha Chechik,
    and Mark Harman (Eds.). ACM, 945. [https://doi.org/10.1145/3180155.3182513](https://doi.org/10.1145/3180155.3182513)
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sirres et al. (2018) Raphael Sirres, Tegawendé F. Bissyandé, Dongsun Kim, David
    Lo, Jacques Klein, Kisub Kim, 和 Yves Le Traon. 2018. 增强和结构化用户查询以支持高效的自由形式代码搜索。在
    *第40届国际软件工程会议论文集，ICSE 2018，瑞典哥德堡，2018年5月27日 - 6月3日*，Michel Chaudron, Ivica Crnkovic,
    Marsha Chechik, 和 Mark Harman（编辑）。ACM，945。 [https://doi.org/10.1145/3180155.3182513](https://doi.org/10.1145/3180155.3182513)
- en: Sivaraman et al. (2019) Aishwarya Sivaraman, Tianyi Zhang, Guy Van den Broeck,
    and Miryung Kim. 2019. Active inductive logic programming for code search. In
    *Proceedings of the 41st International Conference on Software Engineering, ICSE
    2019, Montreal, QC, Canada, May 25-31, 2019*, Joanne M. Atlee, Tevfik Bultan,
    and Jon Whittle (Eds.). IEEE / ACM, 292–303. [https://doi.org/10.1109/ICSE.2019.00044](https://doi.org/10.1109/ICSE.2019.00044)
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sivaraman et al. (2019) Aishwarya Sivaraman, Tianyi Zhang, Guy Van den Broeck,
    和 Miryung Kim. 2019. 用于代码搜索的主动归纳逻辑编程。在 *第41届国际软件工程会议论文集，ICSE 2019，加拿大蒙特利尔，2019年5月25日至31日*，Joanne
    M. Atlee, Tevfik Bultan, 和 Jon Whittle（编辑）。IEEE / ACM，292–303。 [https://doi.org/10.1109/ICSE.2019.00044](https://doi.org/10.1109/ICSE.2019.00044)
- en: Stolee et al. (2014) Kathryn T. Stolee, Sebastian G. Elbaum, and Daniel Dobos.
    2014. Solving the Search for Source Code. *ACM Trans. Softw. Eng. Methodol.* 23,
    3 (2014), 26:1–26:45. [https://doi.org/10.1145/2581377](https://doi.org/10.1145/2581377)
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stolee et al. (2014) Kathryn T. Stolee, Sebastian G. Elbaum, 和 Daniel Dobos.
    2014. 解决源代码搜索问题。 *ACM软件工程方法学学报* 23, 3 (2014), 26:1–26:45。 [https://doi.org/10.1145/2581377](https://doi.org/10.1145/2581377)
- en: Sun et al. (2022a) Weisong Sun, Chunrong Fang, Yuchen Chen, Guanhong Tao, Tingxu
    Han, and Quanjun Zhang. 2022a. Code Search based on Context-aware Code Translation.
    In *44th IEEE/ACM 44th International Conference on Software Engineering, ICSE
    2022, Pittsburgh, PA, USA, May 25-27, 2022*. ACM, 388–400. [https://doi.org/10.1145/3510003.3510140](https://doi.org/10.1145/3510003.3510140)
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun et al. (2022a) Weisong Sun, Chunrong Fang, Yuchen Chen, Guanhong Tao, Tingxu
    Han, 和 Quanjun Zhang. 2022a. 基于上下文感知代码翻译的代码搜索。在 *第44届IEEE/ACM国际软件工程会议，ICSE 2022，美国宾夕法尼亚州匹兹堡，2022年5月25日至27日*。ACM，388–400。
    [https://doi.org/10.1145/3510003.3510140](https://doi.org/10.1145/3510003.3510140)
- en: Sun et al. (2022b) Zhensu Sun, Li Li, Yan Liu, Xiaoning Du, and Li Li. 2022b.
    On the Importance of Building High-quality Training Datasets for Neural Code Search.
    In *44th IEEE/ACM 44th International Conference on Software Engineering, ICSE
    2022, Pittsburgh, PA, USA, May 25-27, 2022*. ACM, 1609–1620. [https://doi.org/10.1145/3510003.3510160](https://doi.org/10.1145/3510003.3510160)
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun et al. (2022b) Zhensu Sun, Li Li, Yan Liu, Xiaoning Du, 和 Li Li. 2022b.
    构建高质量训练数据集用于神经代码搜索的重要性。在 *第44届IEEE/ACM国际软件工程会议，ICSE 2022，美国宾夕法尼亚州匹兹堡，2022年5月25日至27日*。ACM，1609–1620。
    [https://doi.org/10.1145/3510003.3510160](https://doi.org/10.1145/3510003.3510160)
- en: 'Sutskever et al. (2014) Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.
    Sequence to Sequence Learning with Neural Networks. In *Advances in Neural Information
    Processing Systems 27: Annual Conference on Neural Information Processing Systems
    2014, December 8-13 2014, Montreal, Quebec, Canada*, Zoubin Ghahramani, Max Welling,
    Corinna Cortes, Neil D. Lawrence, and Kilian Q. Weinberger (Eds.). 3104–3112.
    [https://proceedings.neurips.cc/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html](https://proceedings.neurips.cc/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html)'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sutskever et al. (2014) Ilya Sutskever, Oriol Vinyals, 和 Quoc V. Le. 2014. 基于神经网络的序列到序列学习。在
    *神经信息处理系统进展27：2014年神经信息处理系统年会，2014年12月8日至13日，加拿大魁北克蒙特利尔*，Zoubin Ghahramani, Max
    Welling, Corinna Cortes, Neil D. Lawrence, 和 Kilian Q. Weinberger（编辑）。3104–3112。
    [https://proceedings.neurips.cc/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html](https://proceedings.neurips.cc/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html)
- en: Wan et al. (2019) Yao Wan, Jingdong Shu, Yulei Sui, Guandong Xu, Zhou Zhao,
    Jian Wu, and Philip S. Yu. 2019. Multi-modal Attention Network Learning for Semantic
    Source Code Retrieval. In *34th IEEE/ACM International Conference on Automated
    Software Engineering, ASE 2019, San Diego, CA, USA, November 11-15, 2019*. IEEE,
    13–25. [https://doi.org/10.1109/ASE.2019.00012](https://doi.org/10.1109/ASE.2019.00012)
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wan et al. (2019) Yao Wan, Jingdong Shu, Yulei Sui, Guandong Xu, Zhou Zhao,
    Jian Wu, 和 Philip S. Yu. 2019. 多模态注意力网络学习用于语义源代码检索。在 *第34届IEEE/ACM自动化软件工程国际会议，ASE
    2019，加州圣地亚哥，美国，2019年11月11日至15日*。IEEE，13–25。 [https://doi.org/10.1109/ASE.2019.00012](https://doi.org/10.1109/ASE.2019.00012)
- en: 'Wan et al. (2022a) Yao Wan, Shijie Zhang, Hongyu Zhang, Yulei Sui, Guandong
    Xu, Dezhong Yao, Hai Jin, and Lichao Sun. 2022a. You see what I want you to see:
    poisoning vulnerabilities in neural code search. In *Proceedings of the 30th ACM
    Joint European Software Engineering Conference and Symposium on the Foundations
    of Software Engineering, ESEC/FSE 2022, Singapore, Singapore, November 14-18,
    2022*, Abhik Roychoudhury, Cristian Cadar, and Miryung Kim (Eds.). ACM, 1233–1245.
    [https://doi.org/10.1145/3540250.3549153](https://doi.org/10.1145/3540250.3549153)'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wan 等 (2022a) Yao Wan, Shijie Zhang, Hongyu Zhang, Yulei Sui, Guandong Xu, Dezhong
    Yao, Hai Jin, 和 Lichao Sun. 2022a. 你看到我想让你看到的：神经代码搜索中的中毒漏洞。见 *第30届ACM联合欧洲软件工程会议暨软件工程基础研讨会，ESEC/FSE
    2022，新加坡，新加坡，2022年11月14-18日*，Abhik Roychoudhury, Cristian Cadar, 和 Miryung Kim
    (编辑). ACM, 1233–1245. [https://doi.org/10.1145/3540250.3549153](https://doi.org/10.1145/3540250.3549153)
- en: Wan et al. (2022b) Yao Wan, Wei Zhao, Hongyu Zhang, Yulei Sui, Guandong Xu,
    and Hai Jin. 2022b. What Do They Capture? - A Structural Analysis of Pre-Trained
    Language Models for Source Code. In *44th IEEE/ACM 44th International Conference
    on Software Engineering, ICSE 2022, Pittsburgh, PA, USA, May 25-27, 2022*. ACM,
    2377–2388. [https://doi.org/10.1145/3510003.3510050](https://doi.org/10.1145/3510003.3510050)
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wan 等 (2022b) Yao Wan, Wei Zhao, Hongyu Zhang, Yulei Sui, Guandong Xu, 和 Hai
    Jin. 2022b. 他们捕捉到了什么？ - 预训练语言模型对源代码的结构分析。见 *第44届IEEE/ACM国际软件工程大会，ICSE 2022，宾夕法尼亚州匹兹堡，美国，2022年5月25-27日*。ACM,
    2377–2388. [https://doi.org/10.1145/3510003.3510050](https://doi.org/10.1145/3510003.3510050)
- en: Wan et al. (2018) Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian
    Wu, and Philip S. Yu. 2018. Improving automatic source code summarization via
    deep reinforcement learning. In *Proceedings of the 33rd ACM/IEEE International
    Conference on Automated Software Engineering, ASE 2018, Montpellier, France, September
    3-7, 2018*, Marianne Huchard, Christian Kästner, and Gordon Fraser (Eds.). ACM,
    397–407. [https://doi.org/10.1145/3238147.3238206](https://doi.org/10.1145/3238147.3238206)
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wan 等 (2018) Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu,
    和 Philip S. Yu. 2018. 通过深度强化学习改进自动源代码摘要生成。见 *第33届ACM/IEEE自动化软件工程国际会议，ASE 2018，法国蒙彼利埃，2018年9月3-7日*，Marianne
    Huchard, Christian Kästner, 和 Gordon Fraser (编辑). ACM, 397–407. [https://doi.org/10.1145/3238147.3238206](https://doi.org/10.1145/3238147.3238206)
- en: Wang et al. (2022b) Chaozheng Wang, Zhenhao Nong, Cuiyun Gao, Zongjie Li, Jichuan
    Zeng, Zhenchang Xing, and Yang Liu. 2022b. Enriching query semantics for code
    search with reinforcement learning. *Neural Networks* 145 (2022), 22–32. [https://doi.org/10.1016/j.neunet.2021.09.025](https://doi.org/10.1016/j.neunet.2021.09.025)
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 (2022b) Chaozheng Wang, Zhenhao Nong, Cuiyun Gao, Zongjie Li, Jichuan
    Zeng, Zhenchang Xing, 和 Yang Liu. 2022b. 使用强化学习丰富代码搜索的查询语义。*Neural Networks* 145
    (2022), 22–32. [https://doi.org/10.1016/j.neunet.2021.09.025](https://doi.org/10.1016/j.neunet.2021.09.025)
- en: Wang et al. (2022a) Deze Wang, Zhouyang Jia, Shanshan Li, Yue Yu, Yun Xiong,
    Wei Dong, and Xiangke Liao. 2022a. Bridging Pre-trained Models and Downstream
    Tasks for Source Code Understanding. In *44th IEEE/ACM 44th International Conference
    on Software Engineering, ICSE 2022, Pittsburgh, PA, USA, May 25-27, 2022*. ACM,
    287–298. [https://doi.org/10.1145/3510003.3510062](https://doi.org/10.1145/3510003.3510062)
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 (2022a) Deze Wang, Zhouyang Jia, Shanshan Li, Yue Yu, Yun Xiong, Wei
    Dong, 和 Xiangke Liao. 2022a. 构建预训练模型与下游任务的桥梁以理解源代码。见 *第44届IEEE/ACM国际软件工程大会，ICSE
    2022，宾夕法尼亚州匹兹堡，美国，2022年5月25-27日*。ACM, 287–298. [https://doi.org/10.1145/3510003.3510062](https://doi.org/10.1145/3510003.3510062)
- en: Wang et al. (2022d) Wenhua Wang, Yuqun Zhang, Yulei Sui, Yao Wan, Zhou Zhao,
    Jian Wu, Philip S. Yu, and Guandong Xu. 2022d. Reinforcement-Learning-Guided Source
    Code Summarization Using Hierarchical Attention. *IEEE Trans. Software Eng.* 48,
    2 (2022), 102–119. [https://doi.org/10.1109/TSE.2020.2979701](https://doi.org/10.1109/TSE.2020.2979701)
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 (2022d) Wenhua Wang, Yuqun Zhang, Yulei Sui, Yao Wan, Zhou Zhao, Jian
    Wu, Philip S. Yu, 和 Guandong Xu. 2022d. 强化学习指导的源代码摘要生成使用层次注意力。*IEEE Trans. Software
    Eng.* 48, 2 (2022), 102–119. [https://doi.org/10.1109/TSE.2020.2979701](https://doi.org/10.1109/TSE.2020.2979701)
- en: 'Wang et al. (2020) Wenhua Wang, Yuqun Zhang, Zhengran Zeng, and Guandong Xu.
    2020. TranS^3: A Transformer-based Framework for Unifying Code Summarization and
    Code Search. *CoRR* abs/2003.03238 (2020). arXiv:2003.03238 [https://arxiv.org/abs/2003.03238](https://arxiv.org/abs/2003.03238)'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等 (2020) Wenhua Wang, Yuqun Zhang, Zhengran Zeng, 和 Guandong Xu. 2020.
    TranS^3: 一个基于Transformer的框架，用于统一代码摘要和代码搜索。*CoRR* abs/2003.03238 (2020). arXiv:2003.03238
    [https://arxiv.org/abs/2003.03238](https://arxiv.org/abs/2003.03238)'
- en: 'Wang et al. (2021b) Xin Wang, Yasheng Wang, Fei Mi, Pingyi Zhou, Yao Wan, Xiao
    Liu, Li Li, Hao Wu, Jin Liu, and Xin Jiang. 2021b. Syncobert: Syntax-guided multi-modal
    contrastive pre-training for code representation. *arXiv preprint arXiv:2108.04556*
    (2021).'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2021b) Xin Wang, Yasheng Wang, Fei Mi, Pingyi Zhou, Yao Wan, Xiao
    Liu, Li Li, Hao Wu, Jin Liu, 和 Xin Jiang. 2021b. Syncobert: 语法引导的多模态对比预训练用于代码表示。*arXiv
    预印本 arXiv:2108.04556* (2021)。'
- en: 'Wang et al. (2022c) Xin Wang, Yasheng Wang, Yao Wan, Jiawei Wang, Pingyi Zhou,
    Li Li, Hao Wu, and Jin Liu. 2022c. CODE-MVP: Learning to Represent Source Code
    from Multiple Views with Contrastive Pre-Training. In *Findings of the Association
    for Computational Linguistics: NAACL 2022, Seattle, WA, United States, July 10-15,
    2022*, Marine Carpuat, Marie-Catherine de Marneffe, and Iván Vladimir Meza Ruíz
    (Eds.). Association for Computational Linguistics, 1066–1077. [https://doi.org/10.18653/v1/2022.findings-naacl.80](https://doi.org/10.18653/v1/2022.findings-naacl.80)'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2022c) Xin Wang, Yasheng Wang, Yao Wan, Jiawei Wang, Pingyi Zhou,
    Li Li, Hao Wu, 和 Jin Liu. 2022c. CODE-MVP: 从多个视角学习表示源代码的对比预训练。在 *计算语言学协会发现: NAACL
    2022, 西雅图, WA, 美国, 2022年7月10-15日*，Marine Carpuat, Marie-Catherine de Marneffe,
    和 Iván Vladimir Meza Ruíz (编辑)。计算语言学协会，1066–1077。 [https://doi.org/10.18653/v1/2022.findings-naacl.80](https://doi.org/10.18653/v1/2022.findings-naacl.80)'
- en: 'Wang et al. (2021a) Yue Wang, Weishi Wang, Shafiq R. Joty, and Steven C. H.
    Hoi. 2021a. CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models
    for Code Understanding and Generation. In *Proceedings of the 2021 Conference
    on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event
    / Punta Cana, Dominican Republic, 7-11 November, 2021*, Marie-Francine Moens,
    Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (Eds.). Association for Computational
    Linguistics, 8696–8708. [https://doi.org/10.18653/v1/2021.emnlp-main.685](https://doi.org/10.18653/v1/2021.emnlp-main.685)'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2021a) Yue Wang, Weishi Wang, Shafiq R. Joty, 和 Steven C. H. Hoi.
    2021a. CodeT5: 识别符感知的统一预训练编码器-解码器模型用于代码理解和生成。在 *2021年自然语言处理经验方法会议论文集, EMNLP 2021,
    虚拟会议 / 多米尼加共和国蓬塔卡纳, 2021年11月7-11日*，Marie-Francine Moens, Xuanjing Huang, Lucia
    Specia, 和 Scott Wen-tau Yih (编辑)。计算语言学协会，8696–8708。 [https://doi.org/10.18653/v1/2021.emnlp-main.685](https://doi.org/10.18653/v1/2021.emnlp-main.685)'
- en: Watson et al. (2022) Cody Watson, Nathan Cooper, David Nader-Palacio, Kevin
    Moran, and Denys Poshyvanyk. 2022. A Systematic Literature Review on the Use of
    Deep Learning in Software Engineering Research. *ACM Trans. Softw. Eng. Methodol.*
    31, 2 (2022), 32:1–32:58. [https://doi.org/10.1145/3485275](https://doi.org/10.1145/3485275)
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Watson et al. (2022) Cody Watson, Nathan Cooper, David Nader-Palacio, Kevin
    Moran, 和 Denys Poshyvanyk. 2022. 关于深度学习在软件工程研究中的应用的系统文献综述。*ACM Trans. Softw. Eng.
    Methodol.* 31, 2 (2022), 32:1–32:58。 [https://doi.org/10.1145/3485275](https://doi.org/10.1145/3485275)
- en: Wu and Yang (2019) Huaiguang Wu and Yang Yang. 2019. Code Search Based on Alteration
    Intent. *IEEE Access* 7 (2019), 56796–56802. [https://doi.org/10.1109/ACCESS.2019.2913560](https://doi.org/10.1109/ACCESS.2019.2913560)
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu and Yang (2019) Huaiguang Wu 和 Yang Yang. 2019. 基于修改意图的代码搜索。*IEEE Access*
    7 (2019), 56796–56802。 [https://doi.org/10.1109/ACCESS.2019.2913560](https://doi.org/10.1109/ACCESS.2019.2913560)
- en: Xu et al. (2021) Ling Xu, Huanhuan Yang, Chao Liu, Jianhang Shuai, Meng Yan,
    Yan Lei, and Zhou Xu. 2021. Two-Stage Attention-Based Model for Code Search with
    Textual and Structural Features. In *28th IEEE International Conference on Software
    Analysis, Evolution and Reengineering, SANER 2021, Honolulu, HI, USA, March 9-12,
    2021*. IEEE, 342–353. [https://doi.org/10.1109/SANER50967.2021.00039](https://doi.org/10.1109/SANER50967.2021.00039)
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2021) Ling Xu, Huanhuan Yang, Chao Liu, Jianhang Shuai, Meng Yan,
    Yan Lei, 和 Zhou Xu. 2021. 基于文本和结构特征的两阶段注意力模型用于代码搜索。在 *第28届IEEE国际软件分析、演化与重构会议,
    SANER 2021, 夏威夷, HI, 美国, 2021年3月9-12日*。IEEE，342–353。 [https://doi.org/10.1109/SANER50967.2021.00039](https://doi.org/10.1109/SANER50967.2021.00039)
- en: Yan et al. (2020) Shuhan Yan, Hang Yu, Yuting Chen, Beijun Shen, and Lingxiao
    Jiang. 2020. Are the Code Snippets What We Are Searching for? A Benchmark and
    an Empirical Study on Code Search with Natural-Language Queries. In *27th IEEE
    International Conference on Software Analysis, Evolution and Reengineering, SANER
    2020, London, ON, Canada, February 18-21, 2020*, Kostas Kontogiannis, Foutse Khomh,
    Alexander Chatzigeorgiou, Marios-Eleftherios Fokaefs, and Minghui Zhou (Eds.).
    IEEE, 344–354. [https://doi.org/10.1109/SANER48275.2020.9054840](https://doi.org/10.1109/SANER48275.2020.9054840)
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yan et al. (2020) Shuhan Yan, Hang Yu, Yuting Chen, Beijun Shen, 和 Lingxiao
    Jiang。2020年。我们寻找的代码片段是我们所需要的吗？自然语言查询下的代码搜索基准和实证研究。在 *第27届IEEE国际软件分析、演化与重构会议，SANER
    2020，2020年2月18-21日，加拿大安大略省伦敦*，Kostas Kontogiannis, Foutse Khomh, Alexander Chatzigeorgiou,
    Marios-Eleftherios Fokaefs, 和 Minghui Zhou (编者)。IEEE，第344–354页。[https://doi.org/10.1109/SANER48275.2020.9054840](https://doi.org/10.1109/SANER48275.2020.9054840)
- en: Yang et al. (2021) Zhen Yang, Jacky Keung, Xiao Yu, Xiaodong Gu, Zhengyuan Wei,
    Xiaoxue Ma, and Miao Zhang. 2021. A Multi-Modal Transformer-based Code Summarization
    Approach for Smart Contracts. In *29th IEEE/ACM International Conference on Program
    Comprehension, ICPC 2021, Madrid, Spain, May 20-21, 2021*. IEEE, 1–12. [https://doi.org/10.1109/ICPC52881.2021.00010](https://doi.org/10.1109/ICPC52881.2021.00010)
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2021) Zhen Yang, Jacky Keung, Xiao Yu, Xiaodong Gu, Zhengyuan Wei,
    Xiaoxue Ma, 和 Miao Zhang。2021年。一种基于多模态变换器的智能合约代码摘要方法。在 *第29届IEEE/ACM国际程序理解会议，ICPC
    2021，2021年5月20-21日，西班牙马德里*。IEEE，第1–12页。[https://doi.org/10.1109/ICPC52881.2021.00010](https://doi.org/10.1109/ICPC52881.2021.00010)
- en: 'Yao et al. (2019) Ziyu Yao, Jayavardhan Reddy Peddamail, and Huan Sun. 2019.
    CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning. In *The
    World Wide Web Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019*,
    Ling Liu, Ryen W. White, Amin Mantrach, Fabrizio Silvestri, Julian J. McAuley,
    Ricardo Baeza-Yates, and Leila Zia (Eds.). ACM, 2203–2214. [https://doi.org/10.1145/3308558.3313632](https://doi.org/10.1145/3308558.3313632)'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2019) Ziyu Yao, Jayavardhan Reddy Peddamail, 和 Huan Sun。2019年。CoaCor：用于代码检索的代码注释与强化学习。在
    *世界万维网大会，WWW 2019，2019年5月13-17日，美国加州旧金山*，Ling Liu, Ryen W. White, Amin Mantrach,
    Fabrizio Silvestri, Julian J. McAuley, Ricardo Baeza-Yates, 和 Leila Zia (编者)。ACM，第2203–2214页。[https://doi.org/10.1145/3308558.3313632](https://doi.org/10.1145/3308558.3313632)
- en: 'Yao et al. (2018) Ziyu Yao, Daniel S. Weld, Wei-Peng Chen, and Huan Sun. 2018.
    StaQC: A Systematically Mined Question-Code Dataset from Stack Overflow. In *Proceedings
    of the 2018 World Wide Web Conference on World Wide Web, WWW 2018, Lyon, France,
    April 23-27, 2018*, Pierre-Antoine Champin, Fabien Gandon, Mounia Lalmas, and
    Panagiotis G. Ipeirotis (Eds.). ACM, 1693–1703. [https://doi.org/10.1145/3178876.3186081](https://doi.org/10.1145/3178876.3186081)'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2018) Ziyu Yao, Daniel S. Weld, Wei-Peng Chen, 和 Huan Sun。2018年。StaQC：从Stack
    Overflow系统性挖掘的问题-代码数据集。在 *2018年世界万维网大会论文集，WWW 2018，2018年4月23-27日，法国里昂*，Pierre-Antoine
    Champin, Fabien Gandon, Mounia Lalmas, 和 Panagiotis G. Ipeirotis (编者)。ACM，第1693–1703页。[https://doi.org/10.1145/3178876.3186081](https://doi.org/10.1145/3178876.3186081)
- en: 'Ye et al. (2020) Wei Ye, Rui Xie, Jinglei Zhang, Tianxiang Hu, Xiaoyin Wang,
    and Shikun Zhang. 2020. Leveraging Code Generation to Improve Code Retrieval and
    Summarization via Dual Learning. In *WWW ’20: The Web Conference 2020, Taipei,
    Taiwan, April 20-24, 2020*, Yennun Huang, Irwin King, Tie-Yan Liu, and Maarten
    van Steen (Eds.). ACM / IW3C2, 2309–2319. [https://doi.org/10.1145/3366423.3380295](https://doi.org/10.1145/3366423.3380295)'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ye et al. (2020) Wei Ye, Rui Xie, Jinglei Zhang, Tianxiang Hu, Xiaoyin Wang,
    和 Shikun Zhang。2020年。利用代码生成通过双重学习改进代码检索和总结。在 *WWW ’20：2020年网络大会，2020年4月20-24日，台湾台北*，Yennun
    Huang, Irwin King, Tie-Yan Liu, 和 Maarten van Steen (编者)。ACM / IW3C2，第2309–2319页。[https://doi.org/10.1145/3366423.3380295](https://doi.org/10.1145/3366423.3380295)
- en: Yin et al. (2018) Pengcheng Yin, Bowen Deng, Edgar Chen, Bogdan Vasilescu, and
    Graham Neubig. 2018. Learning to mine aligned code and natural language pairs
    from stack overflow. In *Proceedings of the 15th International Conference on Mining
    Software Repositories, MSR 2018, Gothenburg, Sweden, May 28-29, 2018*, Andy Zaidman,
    Yasutaka Kamei, and Emily Hill (Eds.). ACM, 476–486. [https://doi.org/10.1145/3196398.3196408](https://doi.org/10.1145/3196398.3196408)
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yin et al. (2018) Pengcheng Yin, Bowen Deng, Edgar Chen, Bogdan Vasilescu, 和
    Graham Neubig。2018年。学习从Stack Overflow中挖掘对齐的代码和自然语言对。在 *第15届国际软件仓库挖掘会议，MSR 2018，2018年5月28-29日，瑞典哥德堡*，Andy
    Zaidman, Yasutaka Kamei, 和 Emily Hill (编者)。ACM，第476–486页。[https://doi.org/10.1145/3196398.3196408](https://doi.org/10.1145/3196398.3196408)
- en: 'Zeng et al. (2023) Chen Zeng, Yue Yu, Shanshan Li, Xin Xia, Zhiming Wang, Mingyang
    Geng, Linxiao Bai, Wei Dong, and Xiangke Liao. 2023. deGraphCS: Embedding Variable-based
    Flow Graph for Neural Code Search. *ACM Trans. Softw. Eng. Methodol.* 32, 2 (2023),
    34:1–34:27. [https://doi.org/10.1145/3546066](https://doi.org/10.1145/3546066)'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeng等（2023）Chen Zeng, Yue Yu, Shanshan Li, Xin Xia, Zhiming Wang, Mingyang Geng,
    Linxiao Bai, Wei Dong, 和 Xiangke Liao。2023。deGraphCS：基于变量的流图嵌入用于神经代码搜索。*ACM软件工程方法论学报*
    32, 2（2023），34:1–34:27。 [https://doi.org/10.1145/3546066](https://doi.org/10.1145/3546066)
- en: Zhang et al. (2018) Feng Zhang, Haoran Niu, Iman Keivanloo, and Ying Zou. 2018.
    Expanding Queries for Code Search Using Semantically Related API Class-names.
    *IEEE Transactions on Software Engineering* 44, 11 (2018), 1070–1082. [https://doi.org/10.1109/TSE.2017.2750682](https://doi.org/10.1109/TSE.2017.2750682)
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等（2018）Feng Zhang, Haoran Niu, Iman Keivanloo, 和 Ying Zou。2018。使用语义相关的API类名扩展代码搜索查询。*IEEE软件工程学报*
    44, 11（2018），1070–1082。 [https://doi.org/10.1109/TSE.2017.2750682](https://doi.org/10.1109/TSE.2017.2750682)
- en: 'Zhang et al. (2020) Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J.
    Liu. 2020. PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive
    Summarization. In *Proceedings of the 37th International Conference on Machine
    Learning, ICML 2020, 13-18 July 2020, Virtual Event* *(Proceedings of Machine
    Learning Research, Vol. 119)*. PMLR, 11328–11339. [http://proceedings.mlr.press/v119/zhang20ae.html](http://proceedings.mlr.press/v119/zhang20ae.html)'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等（2020）Jingqing Zhang, Yao Zhao, Mohammad Saleh, 和 Peter J. Liu。2020。PEGASUS：基于提取的缺失句子进行抽象摘要的预训练。发表于*第37届国际机器学习会议论文集，ICML
    2020，2020年7月13-18日，虚拟活动* *(机器学习研究论文集，第119卷)*。PMLR, 11328–11339。 [http://proceedings.mlr.press/v119/zhang20ae.html](http://proceedings.mlr.press/v119/zhang20ae.html)
- en: 'Zhao and Sun (2020) Jie Zhao and Huan Sun. 2020. Adversarial Training for Code
    Retrieval with Question-Description Relevance Regularization. In *Findings of
    the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20
    November 2020* *(Findings of ACL, Vol. EMNLP 2020)*, Trevor Cohn, Yulan He, and
    Yang Liu (Eds.). Association for Computational Linguistics, 4049–4059. [https://doi.org/10.18653/v1/2020.findings-emnlp.361](https://doi.org/10.18653/v1/2020.findings-emnlp.361)'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao和Sun（2020）Jie Zhao和Huan Sun。2020。带有问题描述相关性正则化的代码检索对抗训练。发表于*计算语言学协会发现：EMNLP
    2020，在线活动，2020年11月16-20日* *(ACL发现，第EMNLP 2020卷)*，Trevor Cohn, Yulan He, 和 Yang
    Liu（编）。计算语言学协会, 4049–4059。 [https://doi.org/10.18653/v1/2020.findings-emnlp.361](https://doi.org/10.18653/v1/2020.findings-emnlp.361)
- en: Zhu et al. (2022) Ming Zhu, Karthik Suresh, and Chandan K. Reddy. 2022. Multilingual
    Code Snippets Training for Program Translation. In *Thirty-Sixth AAAI Conference
    on Artificial Intelligence, AAAI 2022, Thirty-Fourth Conference on Innovative
    Applications of Artificial Intelligence, IAAI 2022, The Twelveth Symposium on
    Educational Advances in Artificial Intelligence, EAAI 2022 Virtual Event, February
    22 - March 1, 2022*. AAAI Press, 11783–11790. [https://ojs.aaai.org/index.php/AAAI/article/view/21434](https://ojs.aaai.org/index.php/AAAI/article/view/21434)
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu等（2022）Ming Zhu, Karthik Suresh, 和 Chandan K. Reddy。2022。多语言代码片段训练用于程序翻译。发表于*第36届AAAI人工智能大会，AAAI
    2022，第34届创新应用人工智能会议，IAAI 2022，第12届人工智能教育进展研讨会，EAAI 2022 虚拟活动，2022年2月22日-3月1日*。AAAI
    Press, 11783–11790。 [https://ojs.aaai.org/index.php/AAAI/article/view/21434](https://ojs.aaai.org/index.php/AAAI/article/view/21434)
- en: 'Zhu et al. (2020) Qihao Zhu, Zeyu Sun, Xiran Liang, Yingfei Xiong, and Lu Zhang.
    2020. OCoR: An Overlapping-Aware Code Retriever. In *35th IEEE/ACM International
    Conference on Automated Software Engineering, ASE 2020, Melbourne, Australia,
    September 21-25, 2020*. IEEE, 883–894. [https://doi.org/10.1145/3324884.3416530](https://doi.org/10.1145/3324884.3416530)'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu等（2020）Qihao Zhu, Zeyu Sun, Xiran Liang, Yingfei Xiong, 和 Lu Zhang。2020。OCoR：一个考虑重叠的代码检索器。发表于*第35届IEEE/ACM自动化软件工程国际会议，ASE
    2020，澳大利亚墨尔本，2020年9月21-25日*。IEEE, 883–894。 [https://doi.org/10.1145/3324884.3416530](https://doi.org/10.1145/3324884.3416530)
