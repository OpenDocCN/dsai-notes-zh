- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-06 19:42:02'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 19:42:02'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2302.02173] A Survey on Deep Learning based Time Series Analysis with Frequency
    Transformation'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2302.02173] 关于基于深度学习的时间序列分析中的频率变换的调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2302.02173](https://ar5iv.labs.arxiv.org/html/2302.02173)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2302.02173](https://ar5iv.labs.arxiv.org/html/2302.02173)
- en: A Survey on Deep Learning based Time Series Analysis with Frequency Transformation
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于基于深度学习的时间序列分析中的频率变换的调查
- en: Kun Yi [yikun@bit.edu.cn](mailto:yikun@bit.edu.cn) Beijing Institute of TechnologyBeijingChina
    ,  Qi Zhang [zhangqi˙cs@tongji.edu.cn](mailto:zhangqi%CB%99cs@tongji.edu.cn) Tongji
    UniversityShanghaiChina ,  Longbing Cao [longbing.cao@mq.edu.au](mailto:longbing.cao@mq.edu.au)
    Macquarie UniversitySydneyAustralia ,  Shoujin Wang, Guodong Long [shoujin.wang,guodong.long@uts.edu.au](mailto:shoujin.wang,guodong.long@uts.edu.au)
    University of Technology SydneySydneyAustralia ,  Liang Hu [milkrain@gmail.com](mailto:milkrain@gmail.com)
    Tongji UniversityShanghaiChina ,  Hui He, Zhendong Niu [hehui617,zniu@bit.edu.cn](mailto:hehui617,zniu@bit.edu.cn)
    Beijing Institute of TechnologyBeijingChina ,  Wei Fan [weifan@knights.ucf.edu](mailto:weifan@knights.ucf.edu)
    University of Central FloridaOrlandoUSA  and  Hui Xiong [xionghui@ust.hk](mailto:xionghui@ust.hk)
    Hong Kong University of Science and TechnologyGuangzhouChina(2023)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 孔毅 [yikun@bit.edu.cn](mailto:yikun@bit.edu.cn) 北京理工大学 北京 中国，  张琪 [zhangqi˙cs@tongji.edu.cn](mailto:zhangqi%CB%99cs@tongji.edu.cn)
    同济大学 上海 中国，  曹龙兵 [longbing.cao@mq.edu.au](mailto:longbing.cao@mq.edu.au) 麦考瑞大学
    悉尼 澳大利亚，  王守金, 龙国栋 [shoujin.wang,guodong.long@uts.edu.au](mailto:shoujin.wang,guodong.long@uts.edu.au)
    悉尼科技大学 悉尼 澳大利亚，  胡亮 [milkrain@gmail.com](mailto:milkrain@gmail.com) 同济大学 上海 中国，  贺辉,
    牛振东 [hehui617,zniu@bit.edu.cn](mailto:hehui617,zniu@bit.edu.cn) 北京理工大学 北京 中国，  范伟
    [weifan@knights.ucf.edu](mailto:weifan@knights.ucf.edu) 中佛罗里达大学 奥兰多 美国 和  熊辉 [xionghui@ust.hk](mailto:xionghui@ust.hk)
    香港科技大学 广州 中国 (2023)
- en: Abstract.
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: Recently, frequency transformation (FT) has been increasingly incorporated into
    deep learning models to significantly enhance state-of-the-art accuracy and efficiency
    in time series analysis. The advantages of FT, such as high efficiency and a global
    view, have been rapidly explored and exploited in various time series tasks and
    applications, demonstrating the promising potential of FT as a new deep learning
    paradigm for time series analysis. Despite the growing attention and the proliferation
    of research in this emerging field, there is currently a lack of a systematic
    review and in-depth analysis of deep learning-based time series models with FT.
    It is also unclear why FT can enhance time series analysis and what its limitations
    in the field are. To address these gaps, we present a comprehensive review that
    systematically investigates and summarizes the recent research advancements in
    deep learning-based time series analysis with FT. Specifically, we explore the
    primary approaches used in current models that incorporate FT, the types of neural
    networks that leverage FT, and the representative FT-equipped models in deep time
    series analysis. We propose a novel taxonomy to categorize the existing methods
    in this field, providing a structured overview of the diverse approaches employed
    in incorporating FT into deep learning models for time series analysis. Finally,
    we highlight the advantages and limitations of FT for time series modeling and
    identify potential future research directions that can further contribute to the
    community of time series analysis.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，频率变换（FT）越来越多地被纳入深度学习模型中，以显著提高时间序列分析的最先进准确性和效率。FT的优势，如高效率和全局视角，已在各种时间序列任务和应用中被迅速探索和利用，展示了FT作为一种新的深度学习范式在时间序列分析中的广阔前景。尽管这个新兴领域的关注度不断上升，研究也在增多，但目前仍缺乏关于基于深度学习的时间序列模型与FT的系统综述和深入分析。为什么FT能提升时间序列分析及其在该领域的局限性仍不清楚。为填补这些空白，我们提供了一个全面的综述，系统调查并总结了基于深度学习的时间序列分析中FT的最新研究进展。具体来说，我们探讨了当前模型中使用FT的主要方法、利用FT的神经网络类型以及在深度时间序列分析中代表性的FT装备模型。我们提出了一种新颖的分类法，以分类该领域现有的方法，为将FT纳入深度学习模型的时间序列分析提供结构化概述。最后，我们强调了FT在时间序列建模中的优势和局限性，并确定了可能的未来研究方向，以进一步贡献于时间序列分析的社区。
- en: 'time series, neural networks, frequency transformation^†^†copyright: acmcopyright^†^†journalyear:
    2023^†^†doi: XXXXXXX.XXXXXXX^†^†journal: JACM^†^†journalvolume: 37^†^†journalnumber:
    4^†^†article: 111^†^†publicationmonth: 8^†^†ccs: General and reference Surveys
    and overviews^†^†ccs: Information systems Information systems application'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列，神经网络，频率变换^†^†版权：acmcopyright^†^†期刊年份：2023^†^†doi：XXXXXXX.XXXXXXX^†^†期刊：JACM^†^†期刊卷号：37^†^†期刊号：4^†^†文章：111^†^†出版月份：8^†^†ccs：一般和参考
    调查和概述^†^†ccs：信息系统 信息系统应用
- en: 1\. Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: Time series data is amongst the most ubiquitous data types, and has penetrated
    nearly every corner of our daily life (Dama and Sinoquet, [2021](#bib.bib14)),
    e.g., user-item interaction series in e-commerce and stock price series over time
    in finance. In recent years, time series analysis has attracted rapidly increasing
    attention from academia and industry, particularly in areas such as time series
    forecasting (Benidis et al., [2022](#bib.bib6)), anomaly detection (Darban et al.,
    [2022](#bib.bib15)), and classification (Fawaz et al., [2019b](#bib.bib21)). Time
    series analysis has played a critical role in a wide variety of real-world applications
    to address significant challenges around us long-lastingly, such as traffic monitoring (Bai
    et al., [2020](#bib.bib4)), financial analysis (Feng et al., [2019](#bib.bib22)),
    and COVID-19 prediction (Chen et al., [2022c](#bib.bib9)). However, time series
    analysis is extremely challenging due to the intricate inter-series correlations
    and intra-series dependencies.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据是最普遍的数据类型之一，几乎渗透到我们日常生活的每一个角落（Dama 和 Sinoquet，[2021](#bib.bib14)），例如，电子商务中的用户-项目交互序列和金融中随时间变化的股价序列。近年来，时间序列分析在学术界和工业界引起了迅速增长的关注，特别是在时间序列预测（Benidis
    等，[2022](#bib.bib6)）、异常检测（Darban 等，[2022](#bib.bib15)）和分类（Fawaz 等，[2019b](#bib.bib21)）等领域。时间序列分析在各种实际应用中发挥了关键作用，以应对我们周围长期存在的重要挑战，例如交通监控（Bai
    等，[2020](#bib.bib4)）、金融分析（Feng 等，[2019](#bib.bib22)）和 COVID-19 预测（Chen 等，[2022c](#bib.bib9)）。然而，由于复杂的系列间相关性和系列内依赖性，时间序列分析极具挑战性。
- en: '![Refer to caption](img/116fe458e06e07b4a14c496cb7ca2561.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/116fe458e06e07b4a14c496cb7ca2561.png)'
- en: Figure 1\. Illustration of various working mechanisms applied to time series
    data. We take an example of four variables and $T$ timestamps, as shown in the
    left portion of the figure. (a) GNN constructs a graph connecting variables for
    each timestamp. (b) Self-attention builds temporal connections for each variable.
    (c) RNN creates a recursive cycle for capturing temporal transitions. (d) TCN
    consists of a stack of causal convolutional layers over timestamps.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 展示了应用于时间序列数据的各种工作机制。我们以四个变量和$T$个时间戳为例，如图的左侧部分所示。 (a) GNN 为每个时间戳构建一个连接变量的图。
    (b) 自注意力为每个变量建立时间连接。 (c) RNN 创建一个递归周期以捕捉时间过渡。 (d) TCN 由时间戳上的因果卷积层堆叠而成。
- en: Previous time series models based on deep learning have been devoted to modeling
    complex intra- and inter-series dependencies in the time domain to enhance downstream
    tasks. Representative sequential models such as recurrent neural networks (RNNs) (Lai
    et al., [2018](#bib.bib31); Hundman et al., [2018](#bib.bib27)), temporal convolutional
    networks (TCNs) (Bai et al., [2018](#bib.bib5)), and attention networks (Wu et al.,
    [2021](#bib.bib57)) are utilized to capture intra-series dependencies, while convolutional
    networks such as convolutional neural networks (CNNs) (Li et al., [2018](#bib.bib32))
    and graph neural networks (GNNs) (Chen et al., [2022a](#bib.bib10)) are preferred
    to attend to inter-series correlations. Although achieving good results, those
    networks have inherent drawbacks of time-domain modeling, limiting their capabilities
    in capturing critical patterns for time series analysis. For example, GNNs are
    constructed based on variable-wise connections as illustrated in Fig. [1](#S1.F1
    "Figure 1 ‣ 1\. Introduction ‣ A Survey on Deep Learning based Time Series Analysis
    with Frequency Transformation")(a), and the sequential models (i.e., Transformer,
    RNN, and TCN) are based on timestamp-wise connections as shown in Fig. [1](#S1.F1
    "Figure 1 ‣ 1\. Introduction ‣ A Survey on Deep Learning based Time Series Analysis
    with Frequency Transformation")(b), (c), and (d), respectively. These modelings
    consider point-wise (e.g., variable/timestamp-wise) connections and fail to attend
    to whole or sub time series. Therefore, they are usually incapable of modeling
    common but complex global patterns, such as periodic patterns of seasonality,
    in time series (Yang et al., [2022](#bib.bib61); Woo et al., [2022a](#bib.bib54)).
    These inherent drawbacks inspire researchers to address the intricate inter-series
    correlations and intra-series dependencies of time series from a different perspective.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 之前基于深度学习的时间序列模型致力于在时间域中建模复杂的序列内和序列间依赖关系，以提升下游任务。代表性的序列模型，如递归神经网络（RNNs）(Lai et
    al., [2018](#bib.bib31); Hundman et al., [2018](#bib.bib27))、时间卷积网络（TCNs）(Bai
    et al., [2018](#bib.bib5))和注意力网络（Wu et al., [2021](#bib.bib57)）用于捕捉序列内依赖关系，而卷积网络，如卷积神经网络（CNNs）(Li
    et al., [2018](#bib.bib32))和图神经网络（GNNs）(Chen et al., [2022a](#bib.bib10))则更倾向于关注序列间相关性。尽管取得了良好结果，这些网络在时间域建模中存在固有缺陷，限制了它们在捕捉时间序列分析关键模式方面的能力。例如，GNNs是基于变量级连接构建的，如图[1](#S1.F1
    "Figure 1 ‣ 1\. Introduction ‣ A Survey on Deep Learning based Time Series Analysis
    with Frequency Transformation")(a)所示，而序列模型（即Transformer、RNN和TCN）则基于时间戳级连接，如图[1](#S1.F1
    "Figure 1 ‣ 1\. Introduction ‣ A Survey on Deep Learning based Time Series Analysis
    with Frequency Transformation")(b)、(c)和(d)所示。这些建模方法考虑了点对点（例如变量/时间戳级）连接，但未能关注整体或子时间序列。因此，它们通常无法建模时间序列中的常见但复杂的全球模式，如季节性周期模式（Yang
    et al., [2022](#bib.bib61); Woo et al., [2022a](#bib.bib54)）。这些固有缺陷激发了研究人员从不同角度解决时间序列的复杂序列间相关性和序列内依赖关系的兴趣。
- en: Recently, deep learning methods leveraging frequency transformation (FT) (Roberts
    and Mullis, [1987](#bib.bib43)), e.g., Discrete Fourier Transform (DFT) (Winograd,
    [1976](#bib.bib53)), Discrete Cosine Transform (DCT) (Ahmed et al., [1974](#bib.bib2)),
    and Discrete Wavelet Transform (DWT) (Shensa et al., [1992](#bib.bib45)), have
    gained a surge of interest within the machine learning community (Xu et al., [2020](#bib.bib58);
    Chi et al., [2020](#bib.bib12); Guibas et al., [2022](#bib.bib25); Zhou et al.,
    [2022c](#bib.bib68)). These neural models incorporating frequency transformation
    have demonstrated an efficient learning paradigm in time series analysis and achieved
    state-of-the-art performance in terms of both efficiency and effectiveness (Wu
    et al., [2021](#bib.bib57); Zhou et al., [2022b](#bib.bib70); Zhang et al., [2022b](#bib.bib63)).
    This can be attributed to the distinctive advantages of FT (see Section [6.1](#S6.SS1
    "6.1\. Advantages ‣ 6\. Summary of Frequency Transformation ‣ A Survey on Deep
    Learning based Time Series Analysis with Frequency Transformation")) that the
    frequency spectrums generated by FT contain abundant vital patterns, e.g., seasonal
    trends, and provide a global view of the characteristics of time series. In addition,
    FT facilitates obtaining multi-scale representations and multi-frequency components
    of time series for capturing informative representations and patterns. This motivates
    us to systematically summarize and analyze the advantages of FT to instruct researchers
    in this area and to deliver a comprehensive survey on the emerging area, i.e.,
    deep learning based time series analysis with FT, thereby enlightening the time
    series community. While the literature includes various studies that discuss time
    series analysis from different perspectives (Fakhrazari and Vakilzadian, [2017](#bib.bib18);
    Benidis et al., [2022](#bib.bib6); Fawaz et al., [2019a](#bib.bib20); Chen et al.,
    [2021](#bib.bib11), [2022b](#bib.bib8); Schäfer et al., [2021](#bib.bib44)), there
    remains a lack of comprehensive summaries on the topic of time series analysis
    with FT. To the best of our knowledge, there is a notable absence of such a review
    covering the latest research progress of existing neural time series models based
    on FT. Moreover, the reasons why FT can enhance the time series analysis have
    not yet been summarized, and its limitations have not been thoroughly analyzed.
    These gaps have hindered the theoretical development and practical applications
    of time series analysis with FT.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，利用频率变换（FT）（Roberts 和 Mullis，[1987](#bib.bib43)）的深度学习方法，例如离散傅里叶变换（DFT）（Winograd，[1976](#bib.bib53)），离散余弦变换（DCT）（Ahmed
    等，[1974](#bib.bib2)），以及离散小波变换（DWT）（Shensa 等，[1992](#bib.bib45)），在机器学习领域引起了广泛的关注（Xu
    等，[2020](#bib.bib58)；Chi 等，[2020](#bib.bib12)；Guibas 等，[2022](#bib.bib25)；Zhou
    等，[2022c](#bib.bib68)）。这些结合频率变换的神经模型在时间序列分析中展示了高效的学习范式，并在效率和有效性方面都达到了最先进的性能（Wu
    等，[2021](#bib.bib57)；Zhou 等，[2022b](#bib.bib70)；Zhang 等，[2022b](#bib.bib63)）。这可以归因于FT的独特优势（见[6.1节](#S6.SS1
    "6.1\. 优势 ‣ 6\. 频率变换总结 ‣ 基于频率变换的深度学习时间序列分析调查")），即FT生成的频谱包含丰富的关键模式，例如季节性趋势，并提供了时间序列特征的全局视图。此外，FT有助于获得时间序列的多尺度表示和多频率分量，以捕捉信息丰富的表示和模式。这促使我们系统地总结和分析FT的优势，以指导该领域的研究人员，并提供对新兴领域的全面调查，即基于FT的深度学习时间序列分析，从而启发时间序列社区。尽管文献中包含了从不同角度讨论时间序列分析的各种研究（Fakhrazari
    和 Vakilzadian，[2017](#bib.bib18)；Benidis 等，[2022](#bib.bib6)；Fawaz 等，[2019a](#bib.bib20)；Chen
    等，[2021](#bib.bib11)，[2022b](#bib.bib8)；Schäfer 等，[2021](#bib.bib44)），但关于FT时间序列分析的综合总结仍然不足。根据我们所知，缺乏涵盖基于FT的现有神经时间序列模型最新研究进展的评述。此外，FT能够提升时间序列分析的原因尚未总结，其局限性也未被彻底分析。这些空白阻碍了FT时间序列分析的理论发展和实际应用。
- en: 'In this paper, we aim to fill the aforementioned gaps by reviewing existing
    deep learning methods for time series analysis with FT. Specifically, our primary
    objective is to provide answers to four crucial perspectives: i) the strategies
    employed by current neural time series models in incorporating neural networks
    with FT; ii) the specific types of neural networks utilized in conjunction with
    FT; iii) the representative FT-equipped neural models commonly employed in time
    series applications; and iv) an exploration of the reasons behind FT to enhance
    neural models as well as an analysis of its limitations in the context of time
    series analysis. By addressing these questions, we provide valuable insights into
    the realm of neural time series analysis with FT. To our knowledge, this paper
    is the first work to comprehensively and systematically review neural time series
    analysis with FT and to propose a new taxonomy for this emerging area, as depicted
    in Fig. [2](#S1.F2 "Figure 2 ‣ 1\. Introduction ‣ A Survey on Deep Learning based
    Time Series Analysis with Frequency Transformation").'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在通过回顾现有的深度学习时间序列分析方法和频率变换（FT），填补上述空白。具体而言，我们的主要目标是回答四个关键问题：i) 当前神经时间序列模型在结合神经网络和FT时所采用的策略；ii)
    与FT结合使用的具体神经网络类型；iii) 在时间序列应用中常用的代表性FT-equipped神经模型；以及 iv) 探索FT如何增强神经模型的原因，以及在时间序列分析中的局限性分析。通过回答这些问题，我们为神经时间序列分析和FT领域提供了宝贵的见解。据我们所知，本文是首个全面且系统地回顾神经时间序列分析与FT的工作，并提出了这一新兴领域的新分类法，如图[2](#S1.F2
    "图 2 ‣ 1\. 引言 ‣ 基于频率变换的深度学习时间序列分析综述")所示。
- en: 'The subsequent sections of this paper are structured as follows: Section [2](#S2
    "2\. Preliminaries ‣ A Survey on Deep Learning based Time Series Analysis with
    Frequency Transformation") initially presents the fundamental concepts of time
    series analysis and frequency transformation. Following that, Section [3](#S3
    "3\. Incorporation Approach ‣ A Survey on Deep Learning based Time Series Analysis
    with Frequency Transformation") summarizes existing FT-equipped models in terms
    of approaches incorporating FT to enhance the accuracy or efficiency of time series
    analysis. In Section [4](#S4 "4\. Neural Network Design ‣ A Survey on Deep Learning
    based Time Series Analysis with Frequency Transformation"), we delve into the
    practical implementations of these models and examine the types of neural works
    utilized in conjunction with FT. Subsequently, Section [5](#S5 "5\. Applications
    ‣ A Survey on Deep Learning based Time Series Analysis with Frequency Transformation")
    categorizes representative frequency-based methods based on common time series
    tasks, including forecasting, anomaly detection, and classification. In Section
    [6](#S6 "6\. Summary of Frequency Transformation ‣ A Survey on Deep Learning based
    Time Series Analysis with Frequency Transformation"), we discuss the advantages
    and limitations of the frequency domain. Finally, we enlighten new avenues of
    future directions for time series analysis in Section [7](#S7 "7\. Discussion
    for Future Opportunities ‣ A Survey on Deep Learning based Time Series Analysis
    with Frequency Transformation").'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的后续部分结构如下：[2](#S2 "2\. 基础知识 ‣ 基于频率变换的深度学习时间序列分析综述")节最初介绍了时间序列分析和频率变换的基本概念。接着，[3](#S3
    "3\. 融合方法 ‣ 基于频率变换的深度学习时间序列分析综述")节总结了现有的频率变换（FT）模型，重点介绍了如何将FT融入时间序列分析中，以提高准确性或效率。[4](#S4
    "4\. 神经网络设计 ‣ 基于频率变换的深度学习时间序列分析综述")节则深入探讨了这些模型的实际实现，并研究了与FT结合使用的神经网络类型。[5](#S5
    "5\. 应用 ‣ 基于频率变换的深度学习时间序列分析综述")节对基于频率的方法进行分类，涵盖了预测、异常检测和分类等常见时间序列任务。[6](#S6 "6\.
    频率变换总结 ‣ 基于频率变换的深度学习时间序列分析综述")节讨论了频率域的优缺点。最后，在[7](#S7 "7\. 未来机会讨论 ‣ 基于频率变换的深度学习时间序列分析综述")节中，我们展望了时间序列分析的未来发展方向。
- en: '![Refer to caption](img/6a4150198eadec8cad2ab9a9aae7a5b1.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6a4150198eadec8cad2ab9a9aae7a5b1.png)'
- en: Figure 2\. A taxonomy of deep learning based time series analysis with frequency
    transformation.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. 基于频率变换的深度学习时间序列分析的分类。
- en: 2\. Preliminaries
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 基础知识
- en: 2.1\. Time Series Analysis
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 时间序列分析
- en: In this section, we provide a brief introduction to the three fundamental tasks
    of time series analysis before diving into neural time series analysis with Fourier
    Transform (FT).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们在深入探讨使用傅里叶变换（FT）的神经时间序列分析之前，简要介绍时间序列分析的三个基本任务。
- en: 2.1.1\. Forecasting
  id: totrans-24
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.1. 预测
- en: Time series forecasting is the task of extrapolating time series into the future (Benidis
    et al., [2022](#bib.bib6)). For a given time series $\mathbf{X}=[{X}_{1},{X}_{2},\cdots,{X}_{T}]\in\mathbb{R}^{N\times
    T}$ with $N$ series and $T$ timestamps, where ${X}_{t}\in\mathbb{R}^{N}$ denotes
    the multi-variate values of $N$ distinct series at timestamp $t$. We consider
    a time series lookback window of length-$L$ at timestamp $t$, namely $\mathbf{X}_{t}=[{X}_{t-L+1},{X}_{t-L+2},\cdots,{X}_{t}]\in\mathbb{R}^{N\times
    L}$; also, we consider a horizon window of length-$\tau$ at timestamp $t$ as the
    prediction target, denoted as $\mathbf{Y}_{t}=[{X}_{t+1},{X}_{t+2},\cdots,{X}_{t+\tau}]\in\mathbb{R}^{N\times\tau}$.
    Then the time series forecasting task is to use historical observations $\mathbf{X}_{t}$
    to predict future values $\hat{\mathbf{Y}}_{t}$ and the typical forecasting model
    $f_{\theta}$ parameterized by $\theta$ is to produce forecasting results by $\hat{\mathbf{Y}}_{t}=f_{\theta}(\mathbf{X}_{t})$.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列预测是将时间序列外推到未来的任务（Benidis et al., [2022](#bib.bib6)）。对于给定的时间序列 $\mathbf{X}=[{X}_{1},{X}_{2},\cdots,{X}_{T}]\in\mathbb{R}^{N\times
    T}$，其中 $N$ 是序列的数量，$T$ 是时间戳的数量，${X}_{t}\in\mathbb{R}^{N}$ 表示时间戳 $t$ 上 $N$ 个不同序列的多变量值。我们考虑在时间戳
    $t$ 上长度为 $L$ 的时间序列回溯窗口，即 $\mathbf{X}_{t}=[{X}_{t-L+1},{X}_{t-L+2},\cdots,{X}_{t}]\in\mathbb{R}^{N\times
    L}$；此外，我们考虑在时间戳 $t$ 上长度为 $\tau$ 的预测目标窗口，记为 $\mathbf{Y}_{t}=[{X}_{t+1},{X}_{t+2},\cdots,{X}_{t+\tau}]\in\mathbb{R}^{N\times\tau}$。然后，时间序列预测任务是利用历史观测值
    $\mathbf{X}_{t}$ 来预测未来值 $\hat{\mathbf{Y}}_{t}$，典型的预测模型 $f_{\theta}$ 由 $\theta$
    参数化，通过 $\hat{\mathbf{Y}}_{t}=f_{\theta}(\mathbf{X}_{t})$ 生成预测结果。
- en: 2.1.2\. Classification
  id: totrans-26
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.2. 分类
- en: Time series classification seeks to assign labels to each series of a dataset (Fawaz
    et al., [2019a](#bib.bib20)). Generally, for a time series dataset $D=\{(X_{1},Y_{1}),(X_{2},Y_{2}),\cdots,(X_{N},Y_{N})\}$
    where $X_{i}\in\mathbb{R}^{T}$ is a time series with $T$ timestamps and $Y_{i}$
    is its corresponding one-hot vector label. For the dataset $D$ containing $K$
    classes, $Y_{i}$ is a vector of length $K$ where each element $j\in[1,K]$ is equal
    to 1 if the class of $X_{i}$ is $j$ and 0 otherwise. Then the classification task
    is to train a classifier $f_{\theta}$ parameterized by $\theta$ on the dataset
    $D$ to map from the space of possible inputs to a probability distribution over
    the class variable labels, formulated as $Y_{i}=f_{\theta}(X_{i})$.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列分类旨在为数据集中的每个序列分配标签（Fawaz et al., [2019a](#bib.bib20)）。通常，对于一个时间序列数据集 $D=\{(X_{1},Y_{1}),(X_{2},Y_{2}),\cdots,(X_{N},Y_{N})\}$，其中
    $X_{i}\in\mathbb{R}^{T}$ 是一个具有 $T$ 个时间戳的时间序列，$Y_{i}$ 是其对应的 one-hot 向量标签。对于包含 $K$
    类别的数据集 $D$，$Y_{i}$ 是一个长度为 $K$ 的向量，其中每个元素 $j\in[1,K]$ 如果 $X_{i}$ 的类别是 $j$ 则等于 1，否则为
    0。然后，分类任务是训练一个由 $\theta$ 参数化的分类器 $f_{\theta}$，以便将可能的输入空间映射到类别变量标签的概率分布，公式为 $Y_{i}=f_{\theta}(X_{i})$。
- en: 2.1.3\. Anomaly Detection
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.3. 异常检测
- en: Time series anomaly detection seeks to find abnormal subsequences in a series (Chen
    et al., [2021](#bib.bib11)). The goal is to develop algorithms or models that
    can effectively distinguish between normal and anomalous behavior, thereby providing
    early detection and alerting for unusual events or behaviors in the time series
    data. Given a time series $X=[x_{1},x_{2},\cdots,x_{T}]$ with $T$ timestamps where
    $x_{i}$ represent the data point at time index $i$, the anomaly detection is to
    identify a subset of data points $X_{s}\subseteq X$ that represents the anomalous
    or abnormal instances.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列异常检测旨在发现序列中的异常子序列（Chen et al., [2021](#bib.bib11)）。目标是开发能够有效区分正常行为和异常行为的算法或模型，从而提供早期检测和警报，以应对时间序列数据中的异常事件或行为。给定一个时间序列
    $X=[x_{1},x_{2},\cdots,x_{T}]$，其中 $T$ 是时间戳的数量，$x_{i}$ 代表时间索引 $i$ 的数据点，异常检测的任务是识别一个数据点子集
    $X_{s}\subseteq X$，该子集表示异常或异常实例。
- en: 2.2\. Frequency Transformation
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2. 频率变换
- en: In this section, we briefly introduce commonly used frequency transformations
    that convert time-domain data into the frequency domain, including Discrete Fourier
    Transform (DFT), Discrete Cosine Transform (DCT), and Discrete Wavelet Transform
    (DWT). Additionally, we describe the convolution theorem, which is a fundamental
    property in the frequency domain.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们简要介绍了常用的频域变换，将时域数据转换为频域，包括离散傅里叶变换（DFT）、离散余弦变换（DCT）和离散小波变换（DWT）。此外，我们还描述了卷积定理，它是频域中的一个基本性质。
- en: 2.2.1\. Discrete Fourier Transform
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1\. 离散傅里叶变换
- en: 'Discrete Fourier Transform (DFT) (Winograd, [1976](#bib.bib53)) plays an important
    role in the area of digital signal processing. Given a sequence $x[n]$ with the
    length of N, DFT converts $x[n]$ into the frequency domain by:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 离散傅里叶变换（DFT）(Winograd，[1976](#bib.bib53)) 在数字信号处理领域发挥着重要作用。给定长度为 N 的序列 $x[n]$，DFT
    通过以下方式将 $x[n]$ 转换到频域：
- en: '| (1) |  | $\mathcal{X}[k]=\sum_{n=0}^{N-1}x[n]e^{-j(2\pi/N)kn},\ s.t.,\ k=0,1,...,N-1$
    |  |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| (1) |  | $\mathcal{X}[k]=\sum_{n=0}^{N-1}x[n]e^{-j(2\pi/N)kn},\ \text{其中}\
    k=0,1,...,N-1$ |  |'
- en: 'where $j$ is the imaginary unit and $\mathcal{X}[k]$ represents the spectrum
    of $x[n]$ at the frequency $\omega_{k}=2\pi k/N$. The spectrum $\mathcal{X}\in\mathbb{C}^{k}$
    consists of real parts $\operatorname{Re}=\sum_{n=0}^{N-1}x[n]\cos{(2\pi/N)kn}\in\mathbb{R}^{k}$
    and imaginary parts $\operatorname{Im}=-\sum_{n=0}^{N-1}x[n]\sin{(2\pi/N)kn}\in\mathbb{R}^{k}$
    as:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $j$ 是虚数单位，$\mathcal{X}[k]$ 表示频率 $\omega_{k}=2\pi k/N$ 下的 $x[n]$ 的谱。谱 $\mathcal{X}\in\mathbb{C}^{k}$
    由实部 $\operatorname{Re}=\sum_{n=0}^{N-1}x[n]\cos{(2\pi/N)kn}\in\mathbb{R}^{k}$
    和虚部 $\operatorname{Im}=-\sum_{n=0}^{N-1}x[n]\sin{(2\pi/N)kn}\in\mathbb{R}^{k}$
    组成：
- en: '| (2) |  | $\mathcal{X}=\operatorname{Re}+j\operatorname{Im}$ |  |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| (2) |  | $\mathcal{X}=\operatorname{Re}+j\operatorname{Im}$ |  |'
- en: 'The amplitude part $A$ and phase part $\theta$ of $\mathcal{X}$ is defined
    as:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: $\mathcal{X}$ 的幅度部分 $A$ 和相位部分 $\theta$ 定义为：
- en: '| (3) |  | $A=\sqrt{\operatorname{Re}^{2}+\operatorname{Im}^{2}}$ |  |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| (3) |  | $A=\sqrt{\operatorname{Re}^{2}+\operatorname{Im}^{2}}$ |  |'
- en: '| (4) |  | $\theta=\arctan(\frac{\operatorname{Im}}{\operatorname{Re}})$ |  |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| (4) |  | $\theta=\arctan(\frac{\operatorname{Im}}{\operatorname{Re}})$ |  |'
- en: 2.2.2\. Discrete Cosine Transform
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2\. 离散余弦变换
- en: Discrete Cosine Transform (DCT) (Ahmed et al., [1974](#bib.bib2)) has emerged
    as the de-facto image transformation in most visual systems. The most common 1-D
    DCT $C(k)$ of a data sequence $x[n]$ is defined as
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 离散余弦变换（DCT）(Ahmed 等，[1974](#bib.bib2)) 已成为大多数视觉系统中的事实上的图像变换。数据序列 $x[n]$ 的最常见的
    1-D DCT $C(k)$ 定义为
- en: '| (5) |  | $C(k)=\alpha(k)\sum_{n=0}^{N-1}x[n]\cos\left[\frac{\pi(2n+1)k}{2N}\right]$
    |  |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| (5) |  | $C(k)=\alpha(k)\sum_{n=0}^{N-1}x[n]\cos\left[\frac{\pi(2n+1)k}{2N}\right]$
    |  |'
- en: where $k=0,1,...,N-1$, and $\alpha(k)$ is defined as
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $k=0,1,...,N-1$，且 $\alpha(k)$ 定义为
- en: '| (6) |  | $\alpha(k)=\left\{\begin{matrix}\sqrt{\frac{1}{N}},for\quad k=0\\
    \sqrt{\frac{2}{N}},for\quad k\neq 0\end{matrix}\right.$ |  |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| (6) |  | $\alpha(k)=\left\{\begin{matrix}\sqrt{\frac{1}{N}},\quad \text{当}\
    k=0\\ \sqrt{\frac{2}{N}},\quad \text{当}\ k\neq 0\end{matrix}\right.$ |  |'
- en: DCT only retains the real parts of DFT and is roughly equivalent to DFT that
    has twice its length. It often performs on real data with even symmetry or in
    some variants where the input or output data are shifted by half a sample.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: DCT 仅保留 DFT 的实部，且大致等于长度为 DFT 两倍的 DFT。它通常在具有偶对称性的实数据上执行，或在一些变体中输入或输出数据偏移半个样本。
- en: 2.2.3\. Discrete Wavelet Transform
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.3\. 离散小波变换
- en: Discrete Wavelet Transform (DWT) (Shensa et al., [1992](#bib.bib45)) has been
    shown to be an appropriate tool for time-frequency analysis. It decomposes a given
    signal into a number of sets in which each set is a time series of coefficients
    describing the time evolution of the signal in the corresponding frequency band.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 离散小波变换（DWT）(Shensa 等，[1992](#bib.bib45)) 已被证明是进行时频分析的适当工具。它将给定信号分解为多个集合，每个集合是描述信号在相应频段时间演变的系数时间序列。
- en: 'For a signal $x(t)$, the wavelet transform $\operatorname{WT}$ can be expressed
    as $\operatorname{WT}(a,b)=\int_{-\infty}^{\infty}x(t)\Psi_{a,b}(t)\mathrm{d}t=\left\langle
    x(t),\Psi_{a,b}(t)\right\rangle$ where $\Psi$ is the wavelet basis function. The
    basis generation can be defined by $\Psi_{a,b}(t)=\frac{1}{\sqrt{a}}\Psi\left(\frac{t-b}{a}\right)$
    where $a$ and $b$ are the scaling and translation factors respectively. $\operatorname{DWT}$
    discretizes the scale factor a and the translation factor b as $a=a_{0}^{m},b=ka_{0}^{m}b_{0},m,k\in\mathbb{Z}$.
    Typically, $a_{0}$ is set to 2, and $b_{0}$ is set to 1\. Accordingly, the $\operatorname{DWT}$
    can be defined as:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于信号 $x(t)$，小波变换 $\operatorname{WT}$ 可以表示为 $\operatorname{WT}(a,b)=\int_{-\infty}^{\infty}x(t)\Psi_{a,b}(t)\mathrm{d}t=\left\langle
    x(t),\Psi_{a,b}(t)\right\rangle$，其中 $\Psi$ 是小波基函数。基函数生成可以定义为 $\Psi_{a,b}(t)=\frac{1}{\sqrt{a}}\Psi\left(\frac{t-b}{a}\right)$，其中
    $a$ 和 $b$ 分别是尺度因子和平移因子。$\operatorname{DWT}$ 将尺度因子 $a$ 和平移因子 $b$ 离散化为 $a=a_{0}^{m},b=ka_{0}^{m}b_{0},m,k\in\mathbb{Z}$。通常，$a_{0}$
    设为 2，$b_{0}$ 设为 1。因此，$\operatorname{DWT}$ 可以定义为：
- en: '| (7) |  | $\operatorname{DWT}(a,b)=a_{0}^{-m/2}\int_{-\infty}^{\infty}x(t)\Psi(a_{0}^{-m}t-kb_{0})(t)\mathrm{d}t$
    |  |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| (7) |  | $\operatorname{DWT}(a,b)=a_{0}^{-m/2}\int_{-\infty}^{\infty}x(t)\Psi(a_{0}^{-m}t-kb_{0})(t)\mathrm{d}t$
    |  |'
- en: In contrast to $\operatorname{DFT}$ and $\operatorname{DCT}$, a wavelet transform
    has the ability to identify the locations containing observed frequency content,
    while the DFT and DCT can only extract pure frequencies from the signal. Hence,
    $\operatorname{DWT}$ can perform time-frequency analysis. In addition, $\operatorname{DWT}$
    can obtain different resolution representations (Mallat, [1989](#bib.bib36)) by
    changing the scaling and translation factors. In Table [1](#S2.T1 "Table 1 ‣ 2.2.3\.
    Discrete Wavelet Transform ‣ 2.2\. Frequency Transformation ‣ 2\. Preliminaries
    ‣ A Survey on Deep Learning based Time Series Analysis with Frequency Transformation"),
    we compare the three frequency analysis methods, including their pros and cons
    of them.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 与 $\operatorname{DFT}$ 和 $\operatorname{DCT}$ 相比，小波变换具有识别包含观察到的频率内容的位置的能力，而
    DFT 和 DCT 只能从信号中提取纯频率。因此，$\operatorname{DWT}$ 可以执行时间-频率分析。此外，$\operatorname{DWT}$
    可以通过改变尺度和翻译因子获得不同分辨率的表示 (Mallat, [1989](#bib.bib36))。在表 [1](#S2.T1 "Table 1 ‣
    2.2.3\. Discrete Wavelet Transform ‣ 2.2\. Frequency Transformation ‣ 2\. Preliminaries
    ‣ A Survey on Deep Learning based Time Series Analysis with Frequency Transformation")
    中，我们比较了三种频率分析方法及其优缺点。
- en: Table 1\. Comparison of DFT, DCT, and DWT for time series analysis.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1\. DFT、DCT 和 DWT 在时间序列分析中的比较。
- en: '| FT | Basis Function | Value Type | Time-Frequency | Pros | Cons |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| FT | 基函数 | 值类型 | 时间-频率 | 优点 | 缺点 |'
- en: '| DFT | Sine+Cosine | Complex | No | Shift-invariant | Leakage effect Lack
    of time localization |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| DFT | 正弦+余弦 | 复数 | 否 | 移位不变 | 泄漏效应 缺乏时间局部化 |'
- en: '| DCT | Cosine | Real | No | Computationally efficient | No phase information
    Lack of time localization |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| DCT | 余弦 | 实数 | 否 | 计算效率高 | 无相位信息 缺乏时间局部化 |'
- en: '| DWT | Wavelet | Real | Yes | Multi-resolution analysis Localization in time
    and frequency | Computation complexity |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| DWT | 小波变换 | 实数 | 是 | 多分辨率分析 时间和频率的局部化 | 计算复杂度 |'
- en: 2.2.4\. Convolution Theorem
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.4\. 卷积定理
- en: 'The convolution theorem (Soliman and Srinath, [1990](#bib.bib46)) states the
    Fourier transform of a circular convolution of two signals equals the point-wise
    product of their Fourier transforms. Given a signal $x[n]$ and a filter $h[n]$,
    the convolution theorem can be defined as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积定理 (Soliman 和 Srinath, [1990](#bib.bib46)) 说明两个信号的循环卷积的傅里叶变换等于它们傅里叶变换的点乘。给定一个信号
    $x[n]$ 和一个滤波器 $h[n]$，卷积定理可以定义如下：
- en: '| (8) |  | $\mathcal{F}(x[n]*h[n])=\mathcal{F}(x)\mathcal{F}(h)$ |  |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| (8) |  | $\mathcal{F}(x[n]*h[n])=\mathcal{F}(x)\mathcal{F}(h)$ |  |'
- en: where $x[n]*h[n]=\sum_{m=0}^{N-1}h[m]x[(n-m)_{N}]$, $(n-m)_{N}$ denotes $(n-m)$
    modulo N, and $\mathcal{F}(x)$ and $\mathcal{F}(h)$ denote discrete Fourier transform
    of $x[n]$ and $h[n]$, respectively.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $x[n]*h[n]=\sum_{m=0}^{N-1}h[m]x[(n-m)_{N}]$，$(n-m)_{N}$ 表示 $(n-m)$ 模 N，$\mathcal{F}(x)$
    和 $\mathcal{F}(h)$ 分别表示 $x[n]$ 和 $h[n]$ 的离散傅里叶变换。
- en: According to the convolution theorem, the point-wise product of frequency spectrums
    of two sequences is equivalent to their circular convolution in the time domain,
    where the product with a larger receptive field of the whole sequences better
    captures the overall characteristics (e.g., periodicity) and requires less computation
    cost (Alaa et al., [2021](#bib.bib3)).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 根据卷积定理，两个序列的频谱点乘等价于它们在时间域上的循环卷积，其中具有更大感受野的整体序列的乘积能够更好地捕捉总体特征（例如周期性），并且计算成本更低
    (Alaa 等, [2021](#bib.bib3))。
- en: 3\. Incorporation Approach
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 融合方法
- en: In this section, we present a systematic summary and discussion of the research
    categorization and progress regarding incorporating the frequency transformation
    to enhance time series analysis.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们系统地总结和讨论了将频率变换应用于增强时间序列分析的研究分类和进展。
- en: 3.1\. Feature Engineering
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1. 特征工程
- en: 'Previous works employ frequency transformation (DFT, DCT, and DWT) as feature
    engineering tools to obtain frequency domain patterns. Basically, they utilize
    frequency transformation to capture three primary types of information: periodic
    patterns, multi-scale patterns, and global dependencies.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 以前的工作利用频率变换（DFT、DCT 和 DWT）作为特征工程工具来获取频域模式。基本上，它们利用频率变换来捕获三种主要的信息类型：周期模式、多尺度模式和全局依赖关系。
- en: Periodicity
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 周期性
- en: Compared to the time domain, the frequency domain can provide vital information
    for time series, such as periodic information. Prior models take advantage of
    frequency domain information for periodic analysis and use it as an important
    complement to the time domain information. (Yang et al., [2022](#bib.bib61)) proposes
    a frequency-domain block to capture dynamic and complicated periodic patterns
    of time series data, and integrates deep learning networks with frequency patterns.
    (Zhang et al., [2022b](#bib.bib63)) utilizes a frequency domain analysis branch
    to detect complex pattern anomalies, e.g., periodic anomalies. (Woo et al., [2022a](#bib.bib54))
    learns the trend representations in the time domain, whereas the seasonal representations
    are learned by a Fourier layer in the frequency domain. (Sun and Boning, [2022](#bib.bib47))
    is a frequency domain-based neural network model that is built on top of the baseline
    model to enhance its performance. (Woo et al., [2022b](#bib.bib55)) utilized DFT
    to design a frequency attention mechanism to replace the self-attention mechanism
    to identify seasonal patterns. (Woo et al., [2023](#bib.bib56)) leverages a novel
    concatenated Fourier features module to efficiently learn high-frequency patterns
    in time series.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 与时间域相比，频域可以为时间序列提供重要的信息，例如周期性信息。以前的模型利用频域信息进行周期性分析，并将其作为时间域信息的重要补充。（Yang 等，
    [2022](#bib.bib61)）提出了一种频域块，用于捕获时间序列数据的动态和复杂周期模式，并将深度学习网络与频率模式结合。（Zhang 等， [2022b](#bib.bib63)）利用频域分析分支来检测复杂模式异常，例如周期性异常。（Woo
    等， [2022a](#bib.bib54)）在时间域中学习趋势表示，而季节性表示则通过频域中的傅里叶层进行学习。（Sun 和 Boning， [2022](#bib.bib47)）是一个基于频域的神经网络模型，建立在基线模型之上，以增强其性能。（Woo
    等， [2022b](#bib.bib55)）利用 DFT 设计了一种频率注意机制来替代自注意机制，以识别季节性模式。（Woo 等， [2023](#bib.bib56)）利用一种新型的串联傅里叶特征模块，高效学习时间序列中的高频模式。
- en: Multi-Scale
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 多尺度
- en: One big challenge for time series analysis is that there are intricate entangled
    temporal dynamics among time series data. To address this challenge, some methods
    try to solve it in terms of the frequency domain. They disentangle temporal patterns
    by decomposing time series data into different frequency components. (Hu and Qi,
    [2017](#bib.bib26)) separates the memory states of RNN into different frequency
    states such that they can explicitly learn the dependencies of both the low- and
    high-frequency patterns. (Zhang et al., [2017](#bib.bib64)) explicitly decomposes
    trading patterns into various frequency components and each component models a
    particular frequency of latent trading pattern underlying the fluctuation of stock
    price. Recently, wavelet-based models have shown competitive performances since
    wavelet transform can retain both time and frequency information and obtain multi-resolution
    representations. (Wang et al., [2018](#bib.bib49)) proposes a wavelet-based neural
    network structure for building frequency-aware deep learning models for time series
    analysis. (Wen et al., [2021a](#bib.bib51)) applies maximal overlap discrete wavelet
    transform to decouple time series into multiple levels of wavelet coefficients
    and then detect single periodicity at each level. (Wang et al., [2023](#bib.bib50))
    devises a novel data-dependent wavelet attention mechanism for dynamic frequency
    analysis of non-stationary time series analysis. (Yang et al., [2023](#bib.bib59))
    proposes an end-to-end graph enhanced Wavelet learning framework for long sequence
    forecasting which utilizes DWT to represent MTS in the wavelet domain.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列分析面临的一个重大挑战是时间序列数据之间存在复杂的纠缠的时间动态。为了应对这一挑战，一些方法尝试在频率域中解决它。它们通过将时间序列数据分解为不同的频率分量来解开时间模式。(Hu
    和 Qi, [2017](#bib.bib26)) 将 RNN 的记忆状态分解为不同的频率状态，以便它们可以明确地学习低频和高频模式的依赖关系。(Zhang
    等, [2017](#bib.bib64))  explicitly 将交易模式分解为各种频率分量，每个分量模型代表了潜在的交易模式的特定频率，这些模式在股票价格波动中潜藏。最近，基于小波的模型显示出竞争力，因为小波变换能够保留时间和频率信息，并获得多分辨率表示。(Wang
    等, [2018](#bib.bib49)) 提出了一个基于小波的神经网络结构，用于构建频率感知的深度学习模型以进行时间序列分析。(Wen 等, [2021a](#bib.bib51))
    应用最大重叠离散小波变换将时间序列解耦为多个级别的小波系数，然后在每个级别检测单一的周期性。(Wang 等, [2023](#bib.bib50)) 设计了一种新型的数据依赖小波注意机制，用于非平稳时间序列分析的动态频率分析。(Yang
    等, [2023](#bib.bib59)) 提出了一个端到端的图增强小波学习框架，用于长序列预测，该框架利用 DWT 在小波域中表示 MTS。
- en: Global Dependencies
  id: totrans-69
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 全局依赖关系
- en: Existing time domain methods construct their models based on point-wise connections
    (see Fig. [1](#S1.F1 "Figure 1 ‣ 1\. Introduction ‣ A Survey on Deep Learning
    based Time Series Analysis with Frequency Transformation")), which prevent them
    from capturing series-level patterns, such as overall characteristics of time
    series. By leveraging the global view property of the frequency domain, some works
    utilize frequency information to attend to series-level patterns. (Zhou et al.,
    [2022b](#bib.bib70)) combines Fourier analysis with the Transformer which helps
    the Transformer better capture the global properties of time series. (Zhang et al.,
    [2022b](#bib.bib63)) integrates the frequency domain analysis branch with the
    time domain analysis branch and detects seasonality anomalies in the frequency
    domain. Besides, some works introduce frequency domain analysis to improve neural
    networks in order to address their inherent drawbacks. Vanilla convolutions in
    modern deep networks are known to operate locally, which causes low efficacy in
    connecting two distant locations in the network. To mitigate the locality limitation
    of convolutions, (Chi et al., [2019](#bib.bib13)) converts data into the frequency
    domain and proposes spectral residual learning for achieving a fully global receptive
    field, and (Chi et al., [2020](#bib.bib12)) harnesses the Fourier spectral theory
    and designs an operation unit to leverage frequency information for enlarging
    the receptive field of vanilla convolutions.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的时间域方法基于逐点连接构建其模型（见图 [1](#S1.F1 "图 1 ‣ 1\. 介绍 ‣ 基于频率变换的深度学习时间序列分析综述")），这使得它们无法捕捉系列级别的模式，例如时间序列的总体特征。通过利用频域的全局视角属性，一些研究利用频率信息来关注系列级别的模式。（Zhou
    et al., [2022b](#bib.bib70)）将傅里叶分析与Transformer相结合，帮助Transformer更好地捕捉时间序列的全局属性。（Zhang
    et al., [2022b](#bib.bib63)）将频域分析分支与时间域分析分支结合起来，并在频域中检测季节性异常。此外，一些研究引入频域分析以改进神经网络，以解决其固有的缺陷。现代深度网络中的普通卷积已知是局部操作，这导致在连接网络中两个远程位置时效率较低。为了解决卷积的局部限制，（Chi
    et al., [2019](#bib.bib13)）将数据转换到频域，并提出了谱残差学习以实现完全的全局感受野，而（Chi et al., [2020](#bib.bib12)）利用傅里叶谱理论设计了一个操作单元，以利用频率信息扩大普通卷积的感受野。
- en: 3.2\. Compression
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 压缩
- en: Previous works utilize frequency transformation to obtain sparse representations
    and remove redundant information in the frequency domain. Moreover, since noise
    signals usually appear as high frequencies, it is easy to filter out them in the
    frequency domain. For example, in (Zhou et al., [2022a](#bib.bib69)), authors
    view time series forecasting from the sequence compression perspective and apply
    Fourier analysis to keep the part of the representation related to low-frequency
    Fourier components to remove the impact of noises. (Rippel et al., [2015](#bib.bib42))
    proposes spectral pooling that performs dimensionality reduction by truncating
    the representation in the frequency domain because energy is heavily concentrated
    in the lower frequencies. (Xu et al., [2020](#bib.bib58)) proposes a learning-based
    frequency selection method to identify the trivial frequency components while
    removing redundant information.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的研究利用频率变换获得稀疏表示，并在频域中去除冗余信息。此外，由于噪声信号通常表现为高频，因此在频域中很容易将其过滤掉。例如，在（Zhou et al.,
    [2022a](#bib.bib69)）中，作者从序列压缩的角度看待时间序列预测，并应用傅里叶分析来保留与低频傅里叶分量相关的表示部分，以去除噪声的影响。（Rippel
    et al., [2015](#bib.bib42)）提出了谱池化，通过截断频域中的表示来执行降维，因为能量在低频部分高度集中。（Xu et al., [2020](#bib.bib58)）提出了一种基于学习的频率选择方法，用于识别微不足道的频率分量，同时去除冗余信息。
- en: 3.3\. Data Augmentation
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 数据增强
- en: Recently, a few studies investigate data augmentation from a frequency domain
    perspective for time series (Wen et al., [2021b](#bib.bib52)). Since the frequency
    domain contains some vital information for time series analysis, such as periodic
    patterns, existing methods incorporate frequency domain features with time domain
    features for data augmentations with the aim of enhancing time series representations.
    For example, CoST (Woo et al., [2022a](#bib.bib54)) incorporates a novel frequency
    domain contrastive loss which encourages discriminative seasonal representations
    and sidesteps the issue of determining the period of seasonal patterns present
    in the time series data. BTSF (Yang and Hong, [2022](#bib.bib60)) fuses the temporal
    and spectral features to enhance the discriminativity and expressiveness of the
    representations. TS-TFC (Liu et al., [2023](#bib.bib34)) proposes a temporal-frequency
    co-training model for time-series semi-supervised learning, utilizing the complementary
    information from two distinct views for unlabeled data learning.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，一些研究从频域角度探讨了时间序列的数据增强（Wen et al., [2021b](#bib.bib52)）。由于频域包含时间序列分析的一些关键性信息，如周期性模式，现有方法将频域特征与时间域特征结合，以增强时间序列表示。例如，CoST（Woo
    et al., [2022a](#bib.bib54)）结合了一种新颖的频域对比损失，鼓励区分季节性表示，并绕过了确定时间序列数据中季节性模式周期的问题。BTSF（Yang
    and Hong, [2022](#bib.bib60)）融合了时间和光谱特征，以增强表示的区分性和表现力。TS-TFC（Liu et al., [2023](#bib.bib34)）提出了一种时间-频率联合训练模型，用于时间序列半监督学习，利用来自两个不同视角的互补信息进行无标签数据学习。
- en: More recently, different from CoST and BTSF that apply DFT after augmenting
    samples in the time domain, one new approach named TF-C (Zhang et al., [2022a](#bib.bib65))
    introduces frequency domain augmentations that directly perturb the frequency
    spectrum. It develops frequency-based contrastive augmentation to leverage rich
    spectral information and directly perturbs the frequency spectrum to leverage
    frequency-invariance for contrastive learning. Compared to performing data augmentations
    directly in the frequency domain (e.g., TF-C), applying the FFT after augmenting
    samples in the time domain (e.g., CoST and BTSF) may lead to information loss.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，不同于在时间域中增强样本后应用DFT的CoST和BTSF，一种名为TF-C（Zhang et al., [2022a](#bib.bib65)）的新方法引入了直接扰动频谱的频域增强。它发展了基于频率的对比增强，以利用丰富的光谱信息，并直接扰动频谱，以利用频率不变性进行对比学习。与直接在频率域中进行数据增强（例如，TF-C）相比，在时间域中增强样本后应用FFT（例如，CoST和BTSF）可能会导致信息丢失。
- en: 3.4\. Fourier Neural Operator Learning
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4\. 傅里叶神经算子学习
- en: According to the convolution theorem, differentiation is equivalent to multiplication
    in the Fourier domain (Li et al., [2021](#bib.bib33)). This efficiency property
    makes DFT frequently used to solve differential equations.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 根据卷积定理，微分在傅里叶域中等同于乘法（Li et al., [2021](#bib.bib33)）。这一效率特性使得离散傅里叶变换（DFT）在解决微分方程时被频繁使用。
- en: Recently, Fourier Neural Operators (FNOs) (Li et al., [2021](#bib.bib33)), which
    is currently the most promising one of the neural operators (Kovachki et al.,
    [2021](#bib.bib30)), have been proposed as an effective framework to solve partial
    differential equations (PDEs). More recently, FNO has been introduced in time
    series forecasting. (Zhou et al., [2022b](#bib.bib70)) proposes Fourier-enhanced
    blocks and Wavelet-enhanced blocks to capture important structures in time series
    through frequency domain mapping. (Yi et al., [2022](#bib.bib62)) reformulates
    the graph convolution operator in the frequency domain and efficiently computes
    graph convolutions over a supra-graph which represents non-static correlations
    between any two variables at any two timestamps.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，傅里叶神经算子（FNOs）（Li et al., [2021](#bib.bib33)），目前是最有前景的神经算子之一（Kovachki et al.,
    [2021](#bib.bib30)），被提出作为解决偏微分方程（PDEs）的有效框架。更近期，FNO已被引入时间序列预测。 (Zhou et al., [2022b](#bib.bib70))
    提出了傅里叶增强块和小波增强块，通过频域映射捕捉时间序列中的重要结构。(Yi et al., [2022](#bib.bib62)) 在频域中重新表述了图卷积算子，并高效地计算超图上的图卷积，表示任意两个变量在任意两个时间戳之间的非静态相关性。
- en: 4\. Neural Network Design
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 神经网络设计
- en: In this section, we delve deeper into existing related models that utilize specific
    types of neural networks to leverage frequency information. Considering that frequency
    transformation outputs can be either complex values or real values (as shown in
    Table [1](#S2.T1 "Table 1 ‣ 2.2.3\. Discrete Wavelet Transform ‣ 2.2\. Frequency
    Transformation ‣ 2\. Preliminaries ‣ A Survey on Deep Learning based Time Series
    Analysis with Frequency Transformation")), and each value type requires distinct
    handling methods, we discuss the models from the perspectives of these two value
    types.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将**深入探讨**利用特定类型神经网络来利用频率信息的现有相关模型。考虑到频率变换输出可以是复数值或实数值（如表 [1](#S2.T1 "表
    1 ‣ 2.2.3\. 离散小波变换 ‣ 2.2\. 频率变换 ‣ 2\. 初步研究 ‣ 基于深度学习的时间序列分析与频率变换综述") 所示），每种值类型需要不同的处理方法，我们将从这两种值类型的角度讨论这些模型。
- en: 4.1\. Complex-Value Data
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 复数值数据
- en: The DFT output values are complex and can be represented in two ways. One representation
    is through the real and imaginary parts (as shown in Equation ([2](#S2.E2 "In
    2.2.1\. Discrete Fourier Transform ‣ 2.2\. Frequency Transformation ‣ 2\. Preliminaries
    ‣ A Survey on Deep Learning based Time Series Analysis with Frequency Transformation"))),
    while the other representation is through the amplitude and phase parts (as depicted
    in Equations ([3](#S2.E3 "In 2.2.1\. Discrete Fourier Transform ‣ 2.2\. Frequency
    Transformation ‣ 2\. Preliminaries ‣ A Survey on Deep Learning based Time Series
    Analysis with Frequency Transformation")) and ([4](#S2.E4 "In 2.2.1\. Discrete
    Fourier Transform ‣ 2.2\. Frequency Transformation ‣ 2\. Preliminaries ‣ A Survey
    on Deep Learning based Time Series Analysis with Frequency Transformation"))).
    While it is possible to simplify the calculation by retaining only one part, such
    as discarding the imaginary components (Godfrey and Gashler, [2018](#bib.bib24)),
    this approach may result in information loss.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: DFT 输出值是复数，可以通过两种方式表示。一种表示方式是通过实部和虚部（如方程 ([2](#S2.E2 "在 2.2.1\. 离散傅里叶变换 ‣ 2.2\.
    频率变换 ‣ 2\. 初步研究 ‣ 基于深度学习的时间序列分析与频率变换综述") 中所示），另一种表示方式是通过幅度和相位部分（如方程 ([3](#S2.E3
    "在 2.2.1\. 离散傅里叶变换 ‣ 2.2\. 频率变换 ‣ 2\. 初步研究 ‣ 基于深度学习的时间序列分析与频率变换综述") 和 ([4](#S2.E4
    "在 2.2.1\. 离散傅里叶变换 ‣ 2.2\. 频率变换 ‣ 2\. 初步研究 ‣ 基于深度学习的时间序列分析与频率变换综述")) 中所示）。虽然可以通过保留其中一个部分来简化计算，例如丢弃虚部
    (Godfrey and Gashler, [2018](#bib.bib24))，这种方法可能会导致信息丢失。
- en: In fact, there are mainly two approaches for performing neural networks on complex
    values. One approach is to treat each part of the complex value as a feature and
    then feed them to neural networks, respectively. Afterward, the output of corresponding
    networks is combined as a complex type (e.g., like Equation ([2](#S2.E2 "In 2.2.1\.
    Discrete Fourier Transform ‣ 2.2\. Frequency Transformation ‣ 2\. Preliminaries
    ‣ A Survey on Deep Learning based Time Series Analysis with Frequency Transformation"))),
    then the inverse DFT is executed and transmitted to the time domain. For example,
    StemGNN (Cao et al., [2020](#bib.bib7)) conducts GLU (Dauphin et al., [2017](#bib.bib16))
    on real and imaginary parts, respectively, which concatenates them as a complex
    value and applies IDFT. ATFN (Yang et al., [2022](#bib.bib61)) utilizes two linear
    layers to process the amplitude part and phase part, respectively, and then combine
    them as a whole. The other one is to conduct complex multiplication in the frequency
    domain directly. For example, FEDformer (Zhou et al., [2022b](#bib.bib70)) randomly
    samples a few frequencies and conducts complex multiplication with a parameterized
    kernel incorporated with attention architecture.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，主要有两种方法在复数值上执行神经网络。一种方法是将复数值的每个部分作为特征，然后分别输入神经网络。之后，将相应网络的输出结合为复数类型（例如，像方程
    ([2](#S2.E2 "在 2.2.1\. 离散傅里叶变换 ‣ 2.2\. 频率变换 ‣ 2\. 初步研究 ‣ 基于深度学习的时间序列分析与频率变换综述")
    中所示），然后执行逆DFT并传输到时域。例如，StemGNN (Cao et al., [2020](#bib.bib7)) 对实部和虚部分别进行 GLU
    (Dauphin et al., [2017](#bib.bib16))，然后将它们连接为复数值并应用 IDFT。ATFN (Yang et al., [2022](#bib.bib61))
    使用两个线性层分别处理幅度部分和相位部分，然后将它们组合为整体。另一种方法是在频域中直接进行复数乘法。例如，FEDformer (Zhou et al.,
    [2022b](#bib.bib70)) 随机抽取一些频率，并使用结合了注意力架构的参数化核进行复数乘法。
- en: 4.2\. Real-Value Data
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 实值数据
- en: The output value type of DCT and DWT is real, hence commonly used network structures
    can be directly applied to them, such as RNN and CNN. Besides, although the output
    value type of DFT is complex, some work discards one part, such as phase part (Zhang
    et al., [2017](#bib.bib64)), and thus their network design also belongs to a real
    value network. However, except for capturing frequency patterns, in contrast to
    other network designs, one main purpose of network design for frequency-based
    models is the frequency component selection to decide which component is discriminative
    or critical.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: DCT 和 DWT 的输出值类型为实数，因此常见的网络结构可以直接应用于它们，例如 RNN 和 CNN。此外，虽然 DFT 的输出值类型为复数，但一些工作会舍弃其中一部分，如相位部分 （Zhang
    等， [2017](#bib.bib64)），因此它们的网络设计也属于实值网络。然而，除了捕捉频率模式外，与其他网络设计相比，基于频率的模型网络设计的一个主要目的就是选择频率成分，以决定哪些成分具有判别性或关键性。
- en: For example, (Xu et al., [2020](#bib.bib58)) converts the input to the frequency
    domain by DCT and groups the same frequency into one channel, and then proposes
    a learning-based dynamic channel selection method to identify the trivial frequency
    components. (Qin et al., [2021](#bib.bib39)) proposes to generalize global average
    pooling to more frequency components of DCT and designs three kinds of frequency
    components selection criteria. RobustPeriod (Wen et al., [2021a](#bib.bib51))
    applies DWT to decouple time series into multiple levels of wavelet coefficients
    and then proposes a method to robustly calculate unbiased wavelet variance at
    each level and rank periodic possibilities.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，（Xu 等， [2020](#bib.bib58)）通过 DCT 将输入转换到频域，并将相同频率的成分分到一个通道中，然后提出了一种基于学习的动态通道选择方法，以识别微不足道的频率成分。（Qin
    等， [2021](#bib.bib39)）建议将全局平均池化推广到 DCT 的更多频率成分，并设计了三种频率成分选择标准。RobustPeriod （Wen
    等， [2021a](#bib.bib51)）应用 DWT 将时间序列解耦为多个级别的小波系数，然后提出了一种在每个级别上稳健地计算无偏小波方差并排名周期性可能性的方法。
- en: 5\. Applications
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 应用
- en: In this section, we review the representative FT-equipped neural time series
    models. We categorize them into three main applications, including forecasting,
    anomaly detection, and classification. In Table [2](#S5.T2 "Table 2 ‣ 5\. Applications
    ‣ A Survey on Deep Learning based Time Series Analysis with Frequency Transformation"),
    we further compare them from six dimensions.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们回顾了具有代表性的 FT 装备神经时间序列模型。我们将它们分为三大类应用，包括预测、异常检测和分类。在表 [2](#S5.T2 "Table
    2 ‣ 5\. Applications ‣ A Survey on Deep Learning based Time Series Analysis with
    Frequency Transformation") 中，我们从六个维度进一步比较了这些模型。
- en: Table 2\. Summary of representative FT-equipped neural models in time series
    analysis.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2\. 具有代表性的 FT 装备神经模型在时间序列分析中的总结。
- en: '| Models | Frequency Transformation | Incorporation Approach | Value Type |
    Neural Network | Application Domains | Leveraged Advantages |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 频率变换 | 融合方法 | 值类型 | 神经网络 | 应用领域 | 利用的优势 |'
- en: '| SFM (Zhang et al., [2017](#bib.bib64)) | DFT | Feature engineering | Real-value
    | RNN | Forecasting | Decomposition |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| SFM （Zhang 等， [2017](#bib.bib64)） | DFT | 特征工程 | 实数值 | RNN | 预测 | 分解 |'
- en: '| StemGNN (Cao et al., [2020](#bib.bib7)) | DFT | Feature engineering | Complex-value
    | GLU | Forecasting | Decomposition |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| StemGNN （Cao 等， [2020](#bib.bib7)） | DFT | 特征工程 | 复数值 | GLU | 预测 | 分解 |'
- en: '| Autoformer (Wu et al., [2021](#bib.bib57)) | DFT | Feature engineering |
    Complex-value | Attention Network | Forecasting | Global view Efficiency |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| Autoformer （Wu 等， [2021](#bib.bib57)） | DFT | 特征工程 | 复数值 | 注意力网络 | 预测 | 全局视角效率
    |'
- en: '| AFTN (Yang et al., [2022](#bib.bib61)) | DFT | Feature engineering | Complex-value
    | MLP | Forecasting | Decomposition |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| AFTN （Yang 等， [2022](#bib.bib61)） | DFT | 特征工程 | 复数值 | MLP | 预测 | 分解 |'
- en: '| DEPTS (Fan et al., [2022](#bib.bib19)) | DCT | Feature engineering | Real-value
    | MLP | Forecasting | Decomposition |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| DEPTS （Fan 等， [2022](#bib.bib19)） | DCT | 特征工程 | 实数值 | MLP | 预测 | 分解 |'
- en: '| FEDformer (Zhou et al., [2022b](#bib.bib70)) | DFT | Feature engineering
    Operator learning | Complex-value | Attention Network | Forecasting | Global view
    Efficiency |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| FEDformer （Zhou 等， [2022b](#bib.bib70)） | DFT | 特征工程 | 复数值 | 注意力网络 | 预测 |
    全局视角效率 |'
- en: '| CoST (Woo et al., [2022a](#bib.bib54)) | DFT | Data augmentation | Complex-value
    | MLP | Forecasting | Decomposition |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| CoST （Woo 等， [2022a](#bib.bib54)） | DFT | 数据增强 | 复数值 | MLP | 预测 | 分解 |'
- en: '| FiLM (Zhou et al., [2022a](#bib.bib69)) | DFT | Compression | Complex-value
    | MLP | Forecasting | Sparse Representation |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| FiLM （Zhou 等， [2022a](#bib.bib69)） | DFT | 压缩 | 复数值 | MLP | 预测 | 稀疏表示 |'
- en: '| EV-FGN (Yi et al., [2022](#bib.bib62)) | DFT | Operator learning | Complex-value
    | MLP | Forecasting | Efficiency |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| EV-FGN (Yi et al., [2022](#bib.bib62)) | DFT | 操作学习 | 复数值 | MLP | 预测 | 效率
    |'
- en: '| FreDo (Sun and Boning, [2022](#bib.bib47)) | DFT | Feature engineering |
    Complex-value | MLP | Forecasting | Decompostion |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| FreDo (Sun and Boning, [2022](#bib.bib47)) | DFT | 特征工程 | 复数值 | MLP | 预测
    | 分解 |'
- en: '| WAVEFORM (Yang et al., [2023](#bib.bib59)) | DWT | Feature engineering |
    Real-value | GCN | Forecasting | Decompostion |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| WAVEFORM (Yang et al., [2023](#bib.bib59)) | DWT | 特征工程 | 实数值 | GCN | 预测
    | 分解 |'
- en: '| SR-CNN (Ren et al., [2019](#bib.bib40)) | DFT | Feature engineering | Real-value
    | CNN | Anomaly Detection | Decomposition |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| SR-CNN (Ren et al., [2019](#bib.bib40)) | DFT | 特征工程 | 实数值 | CNN | 异常检测 |
    分解 |'
- en: '| RobustTAD (Gao et al., [2020](#bib.bib23)) | DFT | Data augmentation | Complex-value
    | CNN | Anomaly Detection | Decomposition |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| RobustTAD (Gao et al., [2020](#bib.bib23)) | DFT | 数据增强 | 复数值 | CNN | 异常检测
    | 分解 |'
- en: '| TFAD (Zhang et al., [2022b](#bib.bib63)) | DWT | Feature engineering | Real-value
    | TCN | Anomaly Detection | Decomposition |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| TFAD (Zhang et al., [2022b](#bib.bib63)) | DWT | 特征工程 | 实数值 | TCN | 异常检测
    | 分解 |'
- en: '| RCF (Wang et al., [2018](#bib.bib49)) | DWT | Feature engineering | Real-value
    | CNN | Classification | Decomposition |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| RCF (Wang et al., [2018](#bib.bib49)) | DWT | 特征工程 | 实数值 | CNN | 分类 | 分解
    |'
- en: '| WD (Khan and Yener, [2018](#bib.bib29)) | DWT | Feature engineering | Real-value
    | CNN | Classification | Decomposition |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| WD (Khan and Yener, [2018](#bib.bib29)) | DWT | 特征工程 | 实数值 | CNN | 分类 | 分解
    |'
- en: '| BTSF (Yang and Hong, [2022](#bib.bib60)) | DFT | Data augmentation | Real-value
    | CNN | Classification Forecasting | Decomposition |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| BTSF (Yang and Hong, [2022](#bib.bib60)) | DFT | 数据增强 | 实数值 | CNN | 分类 预测
    | 分解 |'
- en: '| TF-C (Zhang et al., [2022a](#bib.bib65)) | DFT | Data augmentation | Real-value
    | Transformer | Classification | Decomposition |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| TF-C (Zhang et al., [2022a](#bib.bib65)) | DFT | 数据增强 | 实数值 | Transformer
    | 分类 | 分解 |'
- en: 5.1\. Time Series Forecasting
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. 时间序列预测
- en: Time series forecasting is essential in various domains, such as decision making
    and financial analysis. Recently, some methods leverage frequency information
    to improve the accuracy or efficiency of time series forecasting. SFM (Zhang et al.,
    [2017](#bib.bib64)) decomposes the hidden states of memory cells into multiple
    frequency components and models multi-frequency trading patterns. StemGNN (Cao
    et al., [2020](#bib.bib7)) learns spectral representations which are easier to
    recognize after DFT. Autoformer (Wu et al., [2021](#bib.bib57)) leverages FFT
    to calculate auto-correlation efficiently. DEPTS (Fan et al., [2022](#bib.bib19))
    conducts DCT to extract periodic features and then applies multi-layer perceptrons
    on these features for periodicity dependencies in time series. FEDformer (Zhou
    et al., [2022b](#bib.bib70)) captures the global view of time series in the frequency
    domain. CoST (Woo et al., [2022a](#bib.bib54)) learns the seasonal representations
    in the frequency domain. FiLM (Zhou et al., [2022a](#bib.bib69)) utilizes Fourier
    analysis to keep low-frequency Fourier components.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列预测在决策制定和金融分析等各个领域中至关重要。最近，一些方法利用频率信息来提高时间序列预测的准确性或效率。SFM (Zhang et al.,
    [2017](#bib.bib64)) 将记忆单元的隐状态分解为多个频率分量，并建模多频率交易模式。StemGNN (Cao et al., [2020](#bib.bib7))
    学习在DFT之后更易于识别的谱表示。Autoformer (Wu et al., [2021](#bib.bib57)) 利用FFT高效计算自相关。DEPTS (Fan
    et al., [2022](#bib.bib19)) 执行DCT提取周期特征，然后将这些特征应用于多层感知机，以捕捉时间序列中的周期性依赖关系。FEDformer (Zhou
    et al., [2022b](#bib.bib70)) 捕捉时间序列在频域中的全局视图。CoST (Woo et al., [2022a](#bib.bib54))
    学习频域中的季节性表示。FiLM (Zhou et al., [2022a](#bib.bib69)) 利用傅里叶分析保持低频傅里叶分量。
- en: 5.2\. Time Series Anomaly Detection
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 时间序列异常检测
- en: In recent years, frequency-based models have been introduced in anomaly detection.
    SR (Ren et al., [2019](#bib.bib40)) extracts the spectral residual in the frequency
    domain for detecting the anomaly. RobustTAD (Gao et al., [2020](#bib.bib23)) explores
    the data augmentation methods in the frequency domain to further increase labeled
    data. PFT (Park et al., [2021](#bib.bib38)) proposes a partial Fourier transform
    for anomaly detection with an order of magnitude of speedup without sacrificing
    accuracy. TFAD (Zhang et al., [2022b](#bib.bib63)) takes advantage of frequency
    domain analysis for seasonality anomaly.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，基于频率的模型在异常检测中得到了应用。SR（Ren et al., [2019](#bib.bib40)）在频率域中提取谱残差以检测异常。RobustTAD（Gao
    et al., [2020](#bib.bib23)）探索了频率域中的数据增强方法，以进一步增加标记数据。PFT（Park et al., [2021](#bib.bib38)）提出了一种部分傅里叶变换用于异常检测，具有显著的速度提升而不牺牲准确性。TFAD（Zhang
    et al., [2022b](#bib.bib63)）利用频率域分析来处理季节性异常。
- en: 5.3\. Time Series Classification
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. 时间序列分类
- en: Time series classification is an important and challenging problem in time series
    analysis. Recently, a few models have considered frequency domain information
    to perform this task. RCF (Wang et al., [2018](#bib.bib49)) extracts distinguishing
    features from the DWT decomposed results. WD (Khan and Yener, [2018](#bib.bib29))
    uses wavelet functions with adjustable scale parameters to learn the spectral
    decomposition directly from the signal. BTSF (Yang and Hong, [2022](#bib.bib60))
    fuses time and spectral information to enhance the discriminativity and expressiveness
    of the representations. TF-C (Zhang et al., [2022a](#bib.bib65)) develops frequency-based
    contrastive augmentation to leverage rich spectral information and explore time-frequency
    consistency in time series.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列分类是时间序列分析中的一个重要且具有挑战性的问题。最近，一些模型考虑了频率域信息来执行这一任务。RCF（Wang et al., [2018](#bib.bib49)）从DWT分解结果中提取区分特征。WD（Khan
    and Yener, [2018](#bib.bib29)）使用具有可调尺度参数的小波函数直接从信号中学习谱分解。BTSF（Yang and Hong, [2022](#bib.bib60)）融合了时间和频谱信息，以增强表示的区分性和表达能力。TF-C（Zhang
    et al., [2022a](#bib.bib65)）开发了基于频率的对比增强技术，以利用丰富的谱信息并探索时间-频率一致性。
- en: 6\. Summary of Frequency Transformation
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 频率变换总结
- en: In this section, to investigate why FT can enhance the neural models and what
    are its limitations for time series analysis, we summarize the advantages and
    limitations of frequency transformation.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，为了探讨为什么FT可以增强神经模型以及它在时间序列分析中的限制，我们总结了频率变换的优势和局限性。
- en: 6.1\. Advantages
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1\. 优势
- en: Decomposition
  id: totrans-118
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 分解
- en: Frequency transformation can decompose the original time series into different
    frequency components that embody vital information of time series, such as periodic
    patterns of seasonality. In particular, DWT can decompose a time series into a
    group of sub-series with frequencies ranked from high to low and obtains multi-scale
    representations. By decomposing time series in the time domain into different
    components in the frequency domain, it is naturally helpful to figure out and
    obtain beneficial information for time series analysis.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 频率变换可以将原始时间序列分解为不同的频率成分，这些成分体现了时间序列的重要信息，例如季节性的周期模式。特别是，DWT可以将时间序列分解为一组频率从高到低排序的子序列，并获得多尺度表示。通过将时间域中的时间序列分解为频率域中的不同成分，这自然有助于发现和获取对时间序列分析有益的信息。
- en: Global View
  id: totrans-120
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 全局视角
- en: According to Equations ([1](#S2.E1 "In 2.2.1\. Discrete Fourier Transform ‣
    2.2\. Frequency Transformation ‣ 2\. Preliminaries ‣ A Survey on Deep Learning
    based Time Series Analysis with Frequency Transformation")), ([5](#S2.E5 "In 2.2.2\.
    Discrete Cosine Transform ‣ 2.2\. Frequency Transformation ‣ 2\. Preliminaries
    ‣ A Survey on Deep Learning based Time Series Analysis with Frequency Transformation")),
    and ([7](#S2.E7 "In 2.2.3\. Discrete Wavelet Transform ‣ 2.2\. Frequency Transformation
    ‣ 2\. Preliminaries ‣ A Survey on Deep Learning based Time Series Analysis with
    Frequency Transformation")), a frequency spectrum is calculated through the summation
    of all signals over time. Accordingly, each spectrum element in the frequency
    domain attends to all timestamps in the time domain, illustrating that a spectrum
    has a global view of the whole sequence of time series. In addition, according
    to the convolution theorem (see Equation ([8](#S2.E8 "In 2.2.4\. Convolution Theorem
    ‣ 2.2\. Frequency Transformation ‣ 2\. Preliminaries ‣ A Survey on Deep Learning
    based Time Series Analysis with Frequency Transformation"))), the point-wise product
    of frequency spectrums also captures the global characteristics of the whole sequence,
    inspiring to parameterize global learnable filters in the frequency domain.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 根据方程式（[1](#S2.E1 "在2.2.1. 离散傅里叶变换 ‣ 2.2. 频率变换 ‣ 2. 初步 ‣ 基于深度学习的时间序列分析调查")）、（[5](#S2.E5
    "在2.2.2. 离散余弦变换 ‣ 2.2. 频率变换 ‣ 2. 初步 ‣ 基于深度学习的时间序列分析调查")）和（[7](#S2.E7 "在2.2.3.
    离散小波变换 ‣ 2.2. 频率变换 ‣ 2. 初步 ‣ 基于深度学习的时间序列分析调查")），频谱是通过对所有信号在时间上的求和来计算的。因此，频率域中的每个频谱元素都涉及时间域中的所有时间戳，说明频谱具有对整个时间序列的全局视角。此外，根据卷积定理（见方程式（[8](#S2.E8
    "在2.2.4. 卷积定理 ‣ 2.2. 频率变换 ‣ 2. 初步 ‣ 基于深度学习的时间序列分析调查")）），频率谱的点积也捕捉了整个序列的全局特征，这激发了在频率域中对全局可学习滤波器的参数化。
- en: Sparse Representation
  id: totrans-122
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 稀疏表示
- en: Frequency transformation enables the provision of sparse representations for
    sequences. Taking DFT as an example, a substantial number of coefficients are
    close to zero, indicating that we can employ a reduced number of coefficients
    to represent the entire sequence. In other words, the corresponding representations
    in the frequency domain have a property of energy compaction. For example, the
    important features of signals captured by a subset of DWT coefficients are typically
    much smaller than the original. Specifically, using DWT, it ends up with the same
    number of coefficients as the original signal where many of the coefficients may
    be close to zero. As a result, we can effectively represent the original signal
    using only a small number of non-zero coefficients.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 频率变换使得为序列提供稀疏表示成为可能。以离散傅里叶变换（DFT）为例，大量系数接近于零，这表明我们可以使用较少的系数来表示整个序列。换句话说，频率域中的对应表示具有能量压缩的特性。例如，使用离散小波变换（DWT）捕获信号的重要特征通常比原始信号要小得多。具体而言，使用DWT时，最终得到的系数数量与原始信号相同，其中许多系数可能接近于零。因此，我们可以仅用少量非零系数有效地表示原始信号。
- en: Efficiency
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 效率
- en: As mentioned earlier, frequency transformation often leads to sparse representations,
    where a substantial number of coefficients are close to zero. Exploiting this
    sparsity allows for efficient computations by discarding or compressing the negligible
    coefficients, resulting in reduced memory requirements and faster processing.
    Moreover, according to the convolution theorem, convolution in the time domain
    corresponds to Hadamard’s point-wise product in the frequency domain, which allows
    for convolution to be calculated more efficiently in the frequency domain. Therefore,
    considering the equivalence of the convolution theorem, convolution calculated
    in the frequency domain involves significantly fewer computational operations.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，频率变换通常会导致稀疏表示，其中大量系数接近于零。利用这种稀疏性可以通过丢弃或压缩微不足道的系数来实现高效计算，从而减少内存需求并加快处理速度。此外，根据卷积定理，时间域中的卷积对应于频率域中的Hadamard点积，这使得在频率域中计算卷积更加高效。因此，考虑到卷积定理的等价性，在频率域计算卷积涉及的计算操作显著减少。
- en: 6.2\. Limitations
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2\. 局限性
- en: Loss of temporal information
  id: totrans-127
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 时间信息的丢失
- en: Frequency transformation techniques, including DFT and DCT, primarily emphasize
    capturing the frequency characteristics of a time series. While these techniques
    offer valuable insights into the frequency domain, they may overlook or inadequately
    represent temporal information. Certain temporal patterns or dynamics inherent
    in the time series may not be fully captured in the frequency domain, thereby
    limiting the comprehensive analysis and understanding of the temporal aspects (Godfrey
    and Gashler, [2018](#bib.bib24)).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 频率变换技术，包括DFT和DCT，主要强调捕捉时间序列的频率特征。虽然这些技术提供了频率域的宝贵见解，但它们可能忽视或不足以表示时间信息。时间序列中固有的某些时间模式或动态可能未能在频率域中充分捕捉，从而限制了对时间方面的全面分析和理解（Godfrey
    和 Gashler，[2018](#bib.bib24)）。
- en: Dependence on pre-defined parameters
  id: totrans-129
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 对预定义参数的依赖
- en: Frequency transformation techniques often require setting parameters, such as
    window size, sampling rate, or frequency bands. Selecting appropriate parameter
    values can be challenging, and suboptimal choices may lead to inaccurate frequency
    representations or missed important frequency components (Khan and Yener, [2018](#bib.bib29);
    Michau et al., [2022](#bib.bib37)). Accordingly, parameter tuning and optimization
    are necessary to ensure the effectiveness of frequency transformation in time
    series analysis.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 频率变换技术通常需要设置参数，例如窗口大小、采样率或频率带宽。选择合适的参数值可能具有挑战性，不当选择可能导致频率表示不准确或遗漏重要的频率成分（Khan
    和 Yener，[2018](#bib.bib29)；Michau 等，[2022](#bib.bib37)）。因此，参数调优和优化是确保频率变换在时间序列分析中有效性的必要步骤。
- en: 7\. Discussion for Future Opportunities
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 未来机会讨论
- en: In this section, we explore the prospects for future research in neural time
    series analysis with frequency transformation. We begin by outlining the current
    limitations of frequency transformation and propose innovative directions to overcome
    these challenges. Subsequently, we delve into open research issues and emerging
    trends in the field of time series analysis that can be addressed through the
    utilization of frequency transformations.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了频率变换在神经时间序列分析中的未来研究前景。我们首先概述了频率变换的当前局限性，并提出了克服这些挑战的创新方向。随后，我们深入讨论了时间序列分析领域中的开放研究问题和新兴趋势，这些问题和趋势可以通过利用频率变换来解决。
- en: 7.1\. From the Perspective of Frequency Transformation
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1\. 从频率变换的角度
- en: 7.1.1\. Leveraging New Orthogonal Transform Technology
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.1\. 利用新型正交变换技术
- en: Recent studies have shown the efficiency and effectiveness of orthogonal transform
    which serves as a plug-in operation in neural networks, including frequency analysis
    and polynomial family. Some new orthogonal transform technologies have been introduced
    in neural networks and achieved good results. For example, FiLM (Zhou et al.,
    [2022a](#bib.bib69)) exploits the Legendre projection, which is one type of orthogonal
    polynomials, to update the representation of time series. (Park et al., [2021](#bib.bib38))
    proposes Partial Fourier Transform (PFT) to reduce complexity from $O(N\log{N})$
    to $O(N+M\log{M})$ where $M\ll N$. The Fractional Fourier transform (FrFT) has
    been proven to be desirable for noise removal and can enhance the discrimination
    between anomalies and background (Tao et al., [2019](#bib.bib48)). In (Zhao et al.,
    [2022a](#bib.bib66)), authors utilize FrFT to enhance efficient feature fusion
    and comprehensive feature extraction. (Zhao et al., [2022b](#bib.bib67)) leverages
    FrFT to enable flexible extraction of global contexts and sequential spectral
    information. In the future, it would be a promising direction to incorporate more
    new orthogonal transform technologies for deep learning in time series analysis,
    such as orthogonal polynomials, DCT, and FrFT.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究表明，正交变换作为神经网络中的插件操作在频率分析和多项式家族中表现出了高效性和有效性。一些新的正交变换技术已经在神经网络中得到应用并取得了良好成果。例如，FiLM（Zhou
    等，[2022a](#bib.bib69)）利用Legendre投影，这是一种正交多项式，用于更新时间序列的表示。（Park 等，[2021](#bib.bib38)）提出了部分傅里叶变换（PFT），将复杂度从$O(N\log{N})$降低到$O(N+M\log{M})$，其中$M\ll
    N$。分数傅里叶变换（FrFT）已被证明适用于噪声去除，并能增强异常与背景之间的区分（Tao 等，[2019](#bib.bib48)）。在（Zhao 等，[2022a](#bib.bib66)）中，作者利用FrFT增强了高效特征融合和综合特征提取。（Zhao
    等，[2022b](#bib.bib67)）利用FrFT实现了对全球上下文和序列光谱信息的灵活提取。未来，将更多新型正交变换技术融入时间序列分析的深度学习中，如正交多项式、DCT和FrFT，将是一个有前景的方向。
- en: 7.1.2\. Integrating Frequency Transformation with Deep Learning
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.2\. 将频率变换与深度学习结合
- en: The basis functions used in frequency transformation, such as sine, cosine,
    and wavelet functions, are fixed across different domains. As a result, the frequency
    features extracted through these basis functions are domain-invariant. In other
    words, the features are insensitive to unexpected noise or to changing conditions.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在频率变换中使用的基函数，如正弦、余弦和小波函数，在不同领域中都是固定的。因此，通过这些基函数提取的频率特征是领域不变的。换句话说，这些特征对意外噪声或变化条件不敏感。
- en: To mitigate the limitation, few previous works combine frequency transformation
    with the learning ability of neural networks. mWDN (Wang et al., [2018](#bib.bib49))
    proposes a wavelet-based neural network structure, in which all parameters can
    be fine-tuned to fit training data of different learning tasks. (Khan and Yener,
    [2018](#bib.bib29)) proposes a method to efficiently optimize the parameters of
    the spectral decomposition based on the wavelet transform in a neural network
    framework. (Michau et al., [2022](#bib.bib37)) mimics the fast DWT cascade architecture
    utilizing the deep learning framework. These methods have shown promising performances,
    and in the future, the combination of frequency transformation with deep learning
    deserves further investigation.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻限制，之前的研究很少将频率变换与神经网络的学习能力结合。mWDN（Wang 等，[2018](#bib.bib49)）提出了一种基于小波的神经网络结构，其中所有参数可以微调以适应不同学习任务的训练数据。（Khan
    和 Yener，[2018](#bib.bib29)）提出了一种在神经网络框架中基于小波变换的光谱分解参数的高效优化方法。（Michau 等，[2022](#bib.bib37)）模拟了利用深度学习框架的快速DWT级联结构。这些方法显示了有前景的性能，未来频率变换与深度学习的结合值得进一步探讨。
- en: 7.1.3\. Jointly Learning in the Time and Frequency Domain
  id: totrans-139
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.3\. 在时间和频率领域的联合学习
- en: The frequency domain only uses periodic components, and thus cannot accurately
    model the non-periodic aspects of a signal, such as a linear trend (Godfrey and
    Gashler, [2018](#bib.bib24)). Moreover, according to the uncertainty principle (Zhang
    et al., [2022b](#bib.bib63)), designing a model with a single structure that can
    capture the time and frequency patterns simultaneously is difficult.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 频率领域只使用周期性成分，因此无法准确建模信号的非周期性方面，如线性趋势（Godfrey 和 Gashler，[2018](#bib.bib24)）。此外，根据不确定性原理（Zhang
    等，[2022b](#bib.bib63)），设计一个能够同时捕捉时间和频率模式的单一结构模型是困难的。
- en: As a result, in the future, an interesting direction is to take advantage of
    corresponding characteristics of learning in the time and frequency domain to
    improve the accuracy and efficiency of time series analysis. Few works have tried
    to learn representations in the time and frequency domain, respectively. For example,
    CoST (Woo et al., [2022a](#bib.bib54)) learns the trend representations in the
    time domain and the seasonal representations in the frequency domain. However,
    it only performs data augmentations in the time domain and learns time and frequency
    representations separately. More time-frequency representation learning methods
    are required in the future.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，将来的一个有趣方向是利用时间和频率领域学习的对应特征来提高时间序列分析的准确性和效率。目前很少有研究尝试分别在时间和频率领域学习表示。例如，CoST（Woo
    等，[2022a](#bib.bib54)）在时间领域学习趋势表示，在频率领域学习季节性表示。然而，它仅在时间领域进行数据增强，并且分别学习时间和频率表示。未来需要更多的时间-频率表示学习方法。
- en: 7.2\. From the Perspective of Time Series Analysis
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2\. 从时间序列分析的角度
- en: 7.2.1\. Applying Frequency Transformation to Enhance Time Series Applications
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.1\. 应用频率变换来增强时间序列应用
- en: Applying frequency transformation techniques to a wider range of time series
    applications has the potential to unlock valuable insights and enhance decision-making
    in various domains. No matter in detecting anomalies in physiological signals,
    uncovering market cycles in financial data, or identifying patterns in environmental
    parameters, frequency transformation enables a deeper understanding of complex
    temporal patterns and trends. By harnessing the power of frequency analysis, researchers
    and practitioners can uncover hidden relationships, improve forecasting accuracy,
    optimize resource management, and advance knowledge in diverse fields, ultimately
    driving innovation and enabling data-driven decision-making in a wide range of
    time series applications.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 将频率变换技术应用于更广泛的时间序列应用，有潜力揭示宝贵的见解，并增强各个领域的决策能力。无论是在检测生理信号中的异常、揭示金融数据中的市场周期，还是识别环境参数中的模式，频率变换都能深入理解复杂的时间模式和趋势。通过利用频率分析的力量，研究人员和从业者可以揭示隐藏的关系，提高预测准确性，优化资源管理，推动各个领域的知识进步，*最终推动创新并实现基于数据的决策*。
- en: 7.2.2\. Scalability
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.2. 可扩展性
- en: Scalability (Keogh and Kasetty, [2003](#bib.bib28)) is a key consideration in
    time series analysis. When coupled with frequency transformation techniques, it
    offers the potential for efficient and scalable analysis of large-scale time series
    data. Frequency transformation allows for the extraction of frequency components,
    reducing the dimensionality of the data and enabling more efficient processing.
    This reduction in dimensionality can significantly improve the scalability of
    time series analysis algorithms, as it reduces computational complexity and memory
    requirements. Scalable time series analysis with frequency transformation can
    pave the way for analyzing and extracting insights from big data time series applications
    in domains such as the Internet of Things (IoT), financial markets, or sensor
    networks.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性（Keogh and Kasetty, [2003](#bib.bib28)）是时间序列分析中的关键考虑因素。结合频率变换技术时，它提供了对大规模时间序列数据进行高效和可扩展分析的潜力。频率变换允许提取频率成分，减少数据的维度，从而实现更高效的处理。维度的减少可以显著提高时间序列分析算法的可扩展性，因为它减少了计算复杂性和内存需求。结合频率变换的可扩展时间序列分析可以为分析和提取来自大数据时间序列应用的见解铺平道路，适用于物联网（IoT）、金融市场或传感器网络等领域。
- en: 7.2.3\. Interpretability and Explainability
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.3. 可解释性和解释能力
- en: Interpretability and explainability (Ribeiro et al., [2016](#bib.bib41); Lundberg
    and Lee, [2017](#bib.bib35)) are crucial aspects of time series analysis especially
    in practical applications. Intuitively, frequency transformation capably transforms
    time series into a more intuitive and interpretable representation in the frequency
    domain, offering valuable insights into the underlying patterns and behaviors.
    The frequency components obtained from the transformation can be analyzed to understand
    the dominant frequencies, periodicities, or significant events embodied in the
    data. This not only enhances the interpretability of the analysis but also enables
    the explanation of observed phenomena and anomalies in terms of frequency patterns.
    The interpretability and explainability of time series analysis with frequency
    transformation offer valuable advantages, enabling analysts and domain experts
    to attain deeper insights and establish trust in the analysis outcomes.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性和解释能力（Ribeiro et al., [2016](#bib.bib41); Lundberg and Lee, [2017](#bib.bib35)）是时间序列分析中的关键方面，尤其是在实际应用中。从直观上讲，频率变换能够将时间序列转化为频域中更直观、易于解释的表示，提供对潜在模式和行为的有价值见解。从变换中获得的频率成分可以进行分析，以理解数据中表现出的主要频率、周期性或重要事件。这不仅提升了分析的可解释性，还能够从频率模式的角度解释观察到的现象和异常。频率变换下的时间序列分析的可解释性和解释能力提供了宝贵的优势，使分析师和领域专家能够获得更深入的见解，并建立对分析结果的信任。
- en: 7.2.4\. Privacy-preserving
  id: totrans-149
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.4. 隐私保护
- en: Leveraging frequency transformation offers a powerful approach to data privacy-preserving (Dwork
    et al., [2016](#bib.bib17)) in time series analysis. By applying frequency transformation,
    time series data can be transformed into frequency domain representations without
    revealing the underlying raw data. This transformation allows for the extraction
    of frequency components and patterns while maintaining the confidentiality of
    the original information. Privacy-preserving with frequency transformation techniques
    can ensure individual privacy and data confidentiality, and enable collaborative
    analysis, data sharing, and research collaborations while mitigating privacy risks.
    This approach is particularly valuable in domains where data sensitivity is critical,
    such as healthcare, finance, or personal monitoring, allowing for the utilization
    of frequency analysis while protecting the privacy of individuals or organizations
    involved.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 利用频率变换提供了一种强大的数据隐私保护方法（Dwork等，[2016](#bib.bib17)）在时间序列分析中。通过应用频率变换，时间序列数据可以被转化为频率域表示，而不揭示底层的原始数据。这种变换允许提取频率成分和模式，同时保持原始信息的机密性。使用频率变换技术保护隐私可以确保个人隐私和数据机密性，并促进协作分析、数据共享和研究合作，同时减少隐私风险。这种方法在数据敏感性至关重要的领域（如医疗、金融或个人监控）尤其有价值，允许利用频率分析的同时保护涉及的个人或组织的隐私。
- en: 8\. Conclusion
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 结论
- en: In this paper, we provide a comprehensive survey on deep learning based time
    series analysis with frequency transformation. We organize the reviewed methods
    from the perspectives of incorporation approaches, neural network design, and
    application domains, and we summarize the advantages and limitations of frequency
    transformation for time series analysis. To the best of our knowledge, this paper
    is the first work to comprehensively and systematically review neural time series
    analysis with frequency transformation, which would greatly benefit the time series
    community. Additionally, we offer a curated collection of sources, accessible
    at [https://github.com/BIT-Yi/time_series_frequency](https://github.com/BIT-Yi/time_series_frequency),
    to further assist the research community.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提供了基于深度学习的时间序列分析与频率变换的综合调查。我们从整合方法、神经网络设计和应用领域的角度组织了所审阅的方法，并总结了频率变换在时间序列分析中的优缺点。根据我们所知，本文是首次全面系统地回顾了具有频率变换的神经时间序列分析，这将极大地惠及时间序列社区。此外，我们还提供了一个精选的资源集合，可在[https://github.com/BIT-Yi/time_series_frequency](https://github.com/BIT-Yi/time_series_frequency)访问，以进一步帮助研究社区。
- en: References
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: Ahmed et al. (1974) Nasir Ahmed, T_ Natarajan, and Kamisetty R Rao. 1974. Discrete
    cosine transform. *IEEE transactions on Computers* 100, 1 (1974), 90–93.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ahmed等（1974）Nasir Ahmed, T_ Natarajan, 和Kamisetty R Rao. 1974. 《离散余弦变换》。*IEEE
    transactions on Computers* 100, 1（1974），90–93。
- en: Alaa et al. (2021) Ahmed M. Alaa, Alex James Chan, and Mihaela van der Schaar.
    2021. Generative Time-series Modeling with Fourier Flows. In *ICLR*. OpenReview.net.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alaa等（2021）Ahmed M. Alaa, Alex James Chan, 和Mihaela van der Schaar. 2021. 《利用傅里叶流的生成时间序列建模》。发表于*ICLR*。OpenReview.net。
- en: Bai et al. (2020) Lei Bai, Lina Yao, Can Li, Xianzhi Wang, and Can Wang. 2020.
    Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting. In *NeurIPS*.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai等（2020）Lei Bai, Lina Yao, Can Li, Xianzhi Wang, 和Can Wang. 2020. 《用于交通预测的自适应图卷积递归网络》。发表于*NeurIPS*。
- en: Bai et al. (2018) Shaojie Bai, J. Zico Kolter, and Vladlen Koltun. 2018. An
    Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence
    Modeling. *CoRR* abs/1803.01271 (2018).
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai等（2018）Shaojie Bai, J. Zico Kolter, 和Vladlen Koltun. 2018. 《对序列建模的通用卷积和递归网络的实证评估》。*CoRR*
    abs/1803.01271（2018）。
- en: 'Benidis et al. (2022) Konstantinos Benidis, Syama Sundar Rangapuram, Valentin
    Flunkert, Yuyang Wang, Danielle Maddix, Caner Turkmen, Jan Gasthaus, Michael Bohlke-Schneider,
    David Salinas, Lorenzo Stella, Franç ois-Xavier Aubet, Laurent Callot, and Tim
    Januschowski. 2022. Deep Learning for Time Series Forecasting: Tutorial and Literature
    Survey. *Comput. Surveys* 55 (2022).'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Benidis等（2022）Konstantinos Benidis, Syama Sundar Rangapuram, Valentin Flunkert,
    Yuyang Wang, Danielle Maddix, Caner Turkmen, Jan Gasthaus, Michael Bohlke-Schneider,
    David Salinas, Lorenzo Stella, François-Xavier Aubet, Laurent Callot, 和Tim Januschowski.
    2022. 《时间序列预测中的深度学习：教程和文献综述》。*Comput. Surveys* 55（2022）。
- en: Cao et al. (2020) Defu Cao, Yujing Wang, Juanyong Duan, Ce Zhang, Xia Zhu, Congrui
    Huang, Yunhai Tong, Bixiong Xu, Jing Bai, Jie Tong, and Qi Zhang. 2020. Spectral
    Temporal Graph Neural Network for Multivariate Time-series Forecasting. In *NeurIPS*.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等 (2020) Defu Cao、Yujing Wang、Juanyong Duan、Ce Zhang、Xia Zhu、Congrui Huang、Yunhai
    Tong、Bixiong Xu、Jing Bai、Jie Tong 和 Qi Zhang。2020。用于多变量时间序列预测的光谱时序图神经网络。发表于 *NeurIPS*。
- en: Chen et al. (2022b) Irene Y. Chen, Rahul G. Krishnan, and David A. Sontag. 2022b.
    Clustering Interval-Censored Time-Series for Disease Phenotyping. In *AAAI*. AAAI
    Press, 6211–6221.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2022b) Irene Y. Chen、Rahul G. Krishnan 和 David A. Sontag。2022b。用于疾病表型化的区间删失时间序列聚类。发表于
    *AAAI*。AAAI Press，6211–6221。
- en: 'Chen et al. (2022c) Yuzhou Chen, Ignacio Segovia-Dominguez, Baris Coskunuzer,
    and Yulia Gel. 2022c. TAMP-S2GCNets: Coupling Time-Aware Multipersistence Knowledge
    Representation with Spatio-Supra Graph Convolutional Networks for Time-Series
    Forecasting. In *ICLR*.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2022c) Yuzhou Chen、Ignacio Segovia-Dominguez、Baris Coskunuzer 和 Yulia
    Gel。2022c。TAMP-S2GCNets：将时间感知的多持久知识表示与空间超图卷积网络耦合用于时间序列预测。发表于 *ICLR*。
- en: Chen et al. (2022a) Zekai Chen, Dingshuo Chen, Xiao Zhang, Zixuan Yuan, and
    Xiuzhen Cheng. 2022a. Learning Graph Structures With Transformer for Multivariate
    Time-Series Anomaly Detection in IoT. *IEEE Internet Things J.* 9, 12 (2022),
    9179–9189.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2022a) Zekai Chen、Dingshuo Chen、Xiao Zhang、Zixuan Yuan 和 Xiuzhen Cheng。2022a。使用
    Transformer 学习图结构以实现物联网中的多变量时间序列异常检测。*IEEE Internet Things J.* 9, 12 (2022)，9179–9189。
- en: 'Chen et al. (2021) Zhipeng Chen, Zhang Peng, Xueqiang Zou, and Haoqi Sun. 2021.
    Deep Learning Based Anomaly Detection for Muti-dimensional Time Series: A Survey.
    In *CNCERT* *(Communications in Computer and Information Science, Vol. 1506)*.
    Springer, 71–92.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2021) Zhipeng Chen、Zhang Peng、Xueqiang Zou 和 Haoqi Sun。2021。基于深度学习的多维时间序列异常检测：综述。发表于
    *CNCERT* *(计算机与信息科学通讯，卷 1506)*。Springer，71–92。
- en: Chi et al. (2020) Lu Chi, Borui Jiang, and Yadong Mu. 2020. Fast Fourier Convolution.
    In *NeurIPS*.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chi 等 (2020) Lu Chi、Borui Jiang 和 Yadong Mu。2020。快速傅里叶卷积。发表于 *NeurIPS*。
- en: Chi et al. (2019) Lu Chi, Guiyu Tian, Yadong Mu, Lingxi Xie, and Qi Tian. 2019.
    Fast Non-Local Neural Networks with Spectral Residual Learning. In *ACM Multimedia*.
    ACM, 2142–2151.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chi 等 (2019) Lu Chi、Guiyu Tian、Yadong Mu、Lingxi Xie 和 Qi Tian。2019。基于光谱残差学习的快速非局部神经网络。发表于
    *ACM Multimedia*。ACM，2142–2151。
- en: 'Dama and Sinoquet (2021) Fatoumata Dama and Christine Sinoquet. 2021. Analysis
    and modeling to forecast in time series: a systematic review. *CoRR* abs/2104.00164
    (2021).'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dama 和 Sinoquet (2021) Fatoumata Dama 和 Christine Sinoquet。2021。分析和建模以预测时间序列：系统评价。*CoRR*
    abs/2104.00164 (2021)。
- en: 'Darban et al. (2022) Zahra Zamanzadeh Darban, Geoffrey I. Webb, Shirui Pan,
    Charu C. Aggarwal, and Mahsa Salehi. 2022. Deep Learning for Time Series Anomaly
    Detection: A Survey. *CoRR* abs/2211.05244 (2022).'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Darban 等 (2022) Zahra Zamanzadeh Darban、Geoffrey I. Webb、Shirui Pan、Charu C.
    Aggarwal 和 Mahsa Salehi。2022。用于时间序列异常检测的深度学习：综述。*CoRR* abs/2211.05244 (2022)。
- en: Dauphin et al. (2017) Yann N. Dauphin, Angela Fan, Michael Auli, and David Grangier.
    2017. Language Modeling with Gated Convolutional Networks. In *ICML* *(Proceedings
    of Machine Learning Research, Vol. 70)*. PMLR, 933–941.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dauphin 等 (2017) Yann N. Dauphin、Angela Fan、Michael Auli 和 David Grangier。2017。使用门控卷积网络进行语言建模。发表于
    *ICML* *(机器学习研究论文集，卷 70)*。PMLR，933–941。
- en: Dwork et al. (2016) Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam D.
    Smith. 2016. Calibrating Noise to Sensitivity in Private Data Analysis. *J. Priv.
    Confidentiality* 7, 3 (2016), 17–51.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dwork 等 (2016) Cynthia Dwork、Frank McSherry、Kobbi Nissim 和 Adam D. Smith。2016。私密数据分析中的噪声与敏感度校准。*J.
    Priv. Confidentiality* 7, 3 (2016)，17–51。
- en: Fakhrazari and Vakilzadian (2017) Amin Fakhrazari and Hamid Vakilzadian. 2017.
    A survey on time series data mining. In *EIT*. IEEE, 476–481.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fakhrazari 和 Vakilzadian (2017) Amin Fakhrazari 和 Hamid Vakilzadian。2017。时间序列数据挖掘综述。发表于
    *EIT*。IEEE，476–481。
- en: 'Fan et al. (2022) Wei Fan, Shun Zheng, Xiaohan Yi, Wei Cao, Yanjie Fu, Jiang
    Bian, and Tie-Yan Liu. 2022. DEPTS: Deep Expansion Learning for Periodic Time
    Series Forecasting. In *ICLR*. OpenReview.net.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan 等 (2022) Wei Fan、Shun Zheng、Xiaohan Yi、Wei Cao、Yanjie Fu、Jiang Bian 和 Tie-Yan
    Liu。2022。DEPTS：用于周期性时间序列预测的深度扩展学习。发表于 *ICLR*。OpenReview.net。
- en: 'Fawaz et al. (2019a) Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber,
    Lhassane Idoumghar, and Pierre-Alain Muller. 2019a. Deep learning for time series
    classification: a review. *Data Min. Knowl. Discov.* 33, 4 (2019), 917–963.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fawaz 等 (2019a) Hassan Ismail Fawaz、Germain Forestier、Jonathan Weber、Lhassane
    Idoumghar 和 Pierre-Alain Muller。2019a。用于时间序列分类的深度学习：综述。*Data Min. Knowl. Discov.*
    33, 4 (2019)，917–963。
- en: 'Fawaz et al. (2019b) Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber,
    Lhassane Idoumghar, and Pierre-Alain Muller. 2019b. Deep learning for time series
    classification: a review. *Data Mining and Knowledge Discovery* 33 (2019).'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fawaz et al. (2019b) **哈桑·伊斯梅尔·法瓦兹**、**热尔曼·福雷斯捷**、**乔纳森·韦伯**、**拉萨内·伊杜姆加赫** 和
    **皮埃尔-阿兰·穆勒**。2019b。深度学习在时间序列分类中的应用：综述。*数据挖掘与知识发现* 33 (2019)。
- en: Feng et al. (2019) Fuli Feng, Xiangnan He, Xiang Wang, Cheng Luo, Yiqun Liu,
    and Tat-Seng Chua. 2019. Temporal Relational Ranking for Stock Prediction. *ACM
    Trans. Inf. Syst.* 37, 2 (2019), 27:1–27:30.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feng et al. (2019) **冯丽**、**贺翔南**、**王翔**、**罗成**、**刘一群** 和 **蔡达生**。2019。时间关系排序用于股票预测。*ACM
    Trans. Inf. Syst.* 37, 2 (2019), 27:1–27:30。
- en: 'Gao et al. (2020) Jingkun Gao, Xiaomin Song, Qingsong Wen, Pichao Wang, Liang
    Sun, and Huan Xu. 2020. RobustTAD: Robust Time Series Anomaly Detection via Decomposition
    and Convolutional Neural Networks. *CoRR* abs/2002.09545 (2020).'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao et al. (2020) **高靖昆**、**宋小敏**、**温青松**、**王毗超**、**孙梁** 和 **徐焕**。2020。RobustTAD：通过分解和卷积神经网络进行鲁棒时间序列异常检测。*CoRR*
    abs/2002.09545 (2020)。
- en: Godfrey and Gashler (2018) Luke B. Godfrey and Michael S. Gashler. 2018. Neural
    Decomposition of Time-Series Data for Effective Generalization. *IEEE Trans. Neural
    Networks Learn. Syst.* 29, 7 (2018), 2973–2985.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Godfrey and Gashler (2018) **卢克·B·戈弗雷** 和 **迈克尔·S·盖什勒**。2018。时间序列数据的神经分解以实现有效泛化。*IEEE
    Trans. Neural Networks Learn. Syst.* 29, 7 (2018), 2973–2985。
- en: 'Guibas et al. (2022) John Guibas, Morteza Mardani, Zongyi Li, Andrew Tao, Anima
    Anandkumar, and Bryan Catanzaro. 2022. Adaptive Fourier Neural Operators: Efficient
    Token Mixers for Transformers. In *ICLR*.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guibas et al. (2022) **约翰·圭巴斯**、**莫尔特扎·马尔达尼**、**李宗义**、**安德鲁·陶**、**安尼玛·安南德库马尔**
    和 **布莱恩·卡坦扎罗**。2022。自适应傅里叶神经算子：高效的变换器令牌混合器。在 *ICLR*。
- en: Hu and Qi (2017) Hao Hu and Guo-Jun Qi. 2017. State-Frequency Memory Recurrent
    Neural Networks. In *ICML* *(Proceedings of Machine Learning Research, Vol. 70)*.
    PMLR, 1568–1577.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu and Qi (2017) **胡浩** 和 **戈俊琪**。2017。状态-频率记忆递归神经网络。在 *ICML* *(机器学习研究的会议论文集，第70卷)*。PMLR,
    1568–1577。
- en: Hundman et al. (2018) Kyle Hundman, Valentino Constantinou, Christopher Laporte,
    Ian Colwell, and Tom Söderström. 2018. Detecting Spacecraft Anomalies Using LSTMs
    and Nonparametric Dynamic Thresholding. In *KDD*. ACM, 387–395.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hundman et al. (2018) **凯尔·亨德曼**、**瓦伦蒂诺·康斯坦丁努**、**克里斯托弗·拉波特**、**伊恩·科尔韦尔** 和
    **汤姆·索德斯特伦**。2018。使用 LSTM 和非参数动态阈值检测航天器异常。在 *KDD*。ACM, 387–395。
- en: 'Keogh and Kasetty (2003) Eamonn J. Keogh and Shruti Kasetty. 2003. On the Need
    for Time Series Data Mining Benchmarks: A Survey and Empirical Demonstration.
    *Data Min. Knowl. Discov.* 7, 4 (2003), 349–371.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keogh and Kasetty (2003) **艾蒙·J·基奥赫** 和 **舒鲁蒂·卡塞提**。2003。时间序列数据挖掘基准的必要性：一项调查和实证演示。*数据挖掘与知识发现*
    7, 4 (2003), 349–371。
- en: Khan and Yener (2018) Haidar Khan and Bülent Yener. 2018. Learning filter widths
    of spectral decompositions with wavelets. In *NeurIPS*. 4606–4617.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan and Yener (2018) **海达尔·汗** 和 **比伦特·耶纳**。2018。使用小波学习谱分解的滤波器宽度。在 *NeurIPS*。4606–4617。
- en: 'Kovachki et al. (2021) Nikola B. Kovachki, Zongyi Li, Burigede Liu, Kamyar
    Azizzadenesheli, Kaushik Bhattacharya, Andrew M. Stuart, and Anima Anandkumar.
    2021. Neural Operator: Learning Maps Between Function Spaces. *CoRR* abs/2108.08481
    (2021).'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kovachki et al. (2021) **尼古拉·B·科瓦奇基**、**李宗义**、**布里格德·刘**、**卡姆亚尔·阿齐兹代内什利**、**考希克·巴塔查亚**、**安德鲁·M·斯图尔特**
    和 **安尼玛·安南德库马尔**。2021。神经算子：学习函数空间之间的映射。*CoRR* abs/2108.08481 (2021)。
- en: Lai et al. (2018) Guokun Lai, Wei-Cheng Chang, Yiming Yang, and Hanxiao Liu.
    2018. Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks.
    In *SIGIR*. 95–104.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lai et al. (2018) **赖国坤**、**张伟诚**、**杨弥明** 和 **刘汉晓**。2018。使用深度神经网络建模长短期时间模式。在
    *SIGIR*。95–104。
- en: 'Li et al. (2018) Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion
    Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting. In *ICLR
    (Poster)*.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2018) **李亚光**、**于玫瑰**、**赛勒斯·沙哈比** 和 **刘燕**。2018。扩散卷积递归神经网络：数据驱动的交通预测。在
    *ICLR (海报)*。
- en: Li et al. (2021) Zongyi Li, Nikola Borislavov Kovachki, Kamyar Azizzadenesheli,
    Burigede Liu, Kaushik Bhattacharya, Andrew M. Stuart, and Anima Anandkumar. 2021.
    Fourier Neural Operator for Parametric Partial Differential Equations. In *ICLR*.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2021) **李宗义**、**尼古拉·博里斯拉沃夫·科瓦奇基**、**卡姆亚尔·阿齐兹代内什利**、**布里格德·刘**、**考希克·巴塔查亚**、**安德鲁·M·斯图尔特**
    和 **安尼玛·安南德库马尔**。2021。用于参数偏微分方程的傅里叶神经算子。在 *ICLR*。
- en: Liu et al. (2023) Zhen Liu, Qianli Ma, Peitian Ma, and Linghao Wang. 2023. Temporal-Frequency
    Co-training for Time Series Semi-supervised Learning. In *AAAI*. AAAI Press, 8923–8931.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023) **刘震**、**马千里**、**马培田** 和 **王灵浩**。2023。时间-频率共同训练用于时间序列半监督学习。在
    *AAAI*。AAAI Press, 8923–8931。
- en: Lundberg and Lee (2017) Scott M. Lundberg and Su-In Lee. 2017. A Unified Approach
    to Interpreting Model Predictions. In *NIPS*. 4765–4774.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lundberg 和 Lee（2017）Scott M. Lundberg 和 Su-In Lee. 2017. 统一的模型预测解释方法。发表于 *NIPS*。4765–4774。
- en: 'Mallat (1989) Stéphane Mallat. 1989. A Theory for Multiresolution Signal Decomposition:
    The Wavelet Representation. *IEEE Trans. Pattern Anal. Mach. Intell.* 11, 7 (1989),
    674–693.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mallat（1989）Stéphane Mallat. 1989. 多分辨率信号分解理论：小波表示。*IEEE Trans. Pattern Anal.
    Mach. Intell.* 11, 7 (1989), 674–693。
- en: Michau et al. (2022) Gabriel Michau, Gaetan Frusque, and Olga Fink. 2022. Fully
    learnable deep wavelet transform for unsupervised monitoring of high-frequency
    time series. *Proceedings of the National Academy of Sciences* 119, 8 (2022).
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Michau 等（2022）Gabriel Michau, Gaetan Frusque 和 Olga Fink. 2022. 完全可学习的深度小波变换用于无监督高频时间序列监控。*Proceedings
    of the National Academy of Sciences* 119, 8 (2022)。
- en: Park et al. (2021) Yong-chan Park, Jun-Gi Jang, and U Kang. 2021. Fast and Accurate
    Partial Fourier Transform for Time Series Data. In *KDD*. ACM, 1309–1318.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等（2021）Yong-chan Park, Jun-Gi Jang 和 U Kang. 2021. 时间序列数据的快速准确部分傅里叶变换。发表于
    *KDD*。ACM, 1309–1318。
- en: 'Qin et al. (2021) Zequn Qin, Pengyi Zhang, Fei Wu, and Xi Li. 2021. FcaNet:
    Frequency Channel Attention Networks. In *ICCV*. IEEE, 763–772.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin 等（2021）Zequn Qin, Pengyi Zhang, Fei Wu 和 Xi Li. 2021. FcaNet：频率通道注意力网络。发表于
    *ICCV*。IEEE, 763–772。
- en: Ren et al. (2019) Hansheng Ren, Bixiong Xu, Yujing Wang, Chao Yi, Congrui Huang,
    Xiaoyu Kou, Tony Xing, Mao Yang, Jie Tong, and Qi Zhang. 2019. Time-Series Anomaly
    Detection Service at Microsoft. In *KDD*. ACM, 3009–3017.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ren 等（2019）Hansheng Ren, Bixiong Xu, Yujing Wang, Chao Yi, Congrui Huang, Xiaoyu
    Kou, Tony Xing, Mao Yang, Jie Tong 和 Qi Zhang. 2019. 微软的时间序列异常检测服务。发表于 *KDD*。ACM,
    3009–3017。
- en: 'Ribeiro et al. (2016) Marco Túlio Ribeiro, Sameer Singh, and Carlos Guestrin.
    2016. ”Why Should I Trust You?”: Explaining the Predictions of Any Classifier.
    In *KDD*. ACM, 1135–1144.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ribeiro 等（2016）Marco Túlio Ribeiro, Sameer Singh 和 Carlos Guestrin. 2016. “我为什么要相信你？”：解释任何分类器的预测。发表于
    *KDD*。ACM, 1135–1144。
- en: Rippel et al. (2015) Oren Rippel, Jasper Snoek, and Ryan P. Adams. 2015. Spectral
    Representations for Convolutional Neural Networks. In *NIPS*. 2449–2457.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rippel 等（2015）Oren Rippel, Jasper Snoek 和 Ryan P. Adams. 2015. 卷积神经网络的谱表示。发表于
    *NIPS*。2449–2457。
- en: Roberts and Mullis (1987) Richard A Roberts and Clifford T Mullis. 1987. *Digital
    signal processing*. Addison-Wesley Longman Publishing Co., Inc.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roberts 和 Mullis（1987）Richard A Roberts 和 Clifford T Mullis. 1987. *数字信号处理*。Addison-Wesley
    Longman Publishing Co., Inc.
- en: Schäfer et al. (2021) Patrick Schäfer, Arik Ermshaus, and Ulf Leser. 2021. ClaSP
    - Time Series Segmentation. In *CIKM*. ACM, 1578–1587.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schäfer 等（2021）Patrick Schäfer, Arik Ermshaus 和 Ulf Leser. 2021. ClaSP - 时间序列分割。发表于
    *CIKM*。ACM, 1578–1587。
- en: 'Shensa et al. (1992) Mark J Shensa et al. 1992. The discrete wavelet transform:
    wedding the a trous and Mallat algorithms. *IEEE Transactions on signal processing*
    40, 10 (1992), 2464–2482.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shensa 等（1992）Mark J Shensa 等. 1992. 离散小波变换：结合 a trous 和 Mallat 算法。*IEEE Transactions
    on signal processing* 40, 10 (1992), 2464–2482。
- en: Soliman and Srinath (1990) S. S. Soliman and MD Srinath. 1990. Continuous and
    discrete signals and systems. *Prentice Hall,* (1990).
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Soliman 和 Srinath（1990）S. S. Soliman 和 MD Srinath. 1990. 连续和离散信号及系统。*Prentice
    Hall,*（1990）。
- en: 'Sun and Boning (2022) Fan-Keng Sun and Duane S. Boning. 2022. FreDo: Frequency
    Domain-based Long-Term Time Series Forecasting. *CoRR* abs/2205.12301 (2022).'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 和 Boning（2022）Fan-Keng Sun 和 Duane S. Boning. 2022. FreDo：基于频域的长期时间序列预测。*CoRR*
    abs/2205.12301（2022）。
- en: Tao et al. (2019) Ran Tao, Xudong Zhao, Wei Li, Heng-Chao Li, and Qian Du. 2019.
    Hyperspectral Anomaly Detection by Fractional Fourier Entropy. *IEEE J. Sel. Top.
    Appl. Earth Obs. Remote. Sens.* 12, 12 (2019), 4920–4929.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tao 等（2019）Ran Tao, Xudong Zhao, Wei Li, Heng-Chao Li 和 Qian Du. 2019. 通过分数傅里叶熵进行高光谱异常检测。*IEEE
    J. Sel. Top. Appl. Earth Obs. Remote. Sens.* 12, 12 (2019), 4920–4929。
- en: Wang et al. (2018) Jingyuan Wang, Ze Wang, Jianfeng Li, and Junjie Wu. 2018.
    Multilevel Wavelet Decomposition Network for Interpretable Time Series Analysis.
    In *KDD*. ACM, 2437–2446.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2018）Jingyuan Wang, Ze Wang, Jianfeng Li 和 Junjie Wu. 2018. 用于可解释时间序列分析的多层小波分解网络。发表于
    *KDD*。ACM, 2437–2446。
- en: 'Wang et al. (2023) Jingyuan Wang, Chen Yang, Xiaohan Jiang, and Junjie Wu.
    2023. WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series
    Analysis. In *KDD*. ACM, 2361–2373.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2023）Jingyuan Wang, Chen Yang, Xiaohan Jiang 和 Junjie Wu. 2023. WHEN：一种用于异构时间序列分析的Wavelet-DTW混合注意力网络。发表于
    *KDD*。ACM, 2361–2373。
- en: 'Wen et al. (2021a) Qingsong Wen, Kai He, Liang Sun, Yingying Zhang, Min Ke,
    and Huan Xu. 2021a. RobustPeriod: Robust Time-Frequency Mining for Multiple Periodicity
    Detection. In *SIGMOD Conference*. ACM, 2328–2337.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wen 等（2021a）Qingsong Wen, Kai He, Liang Sun, Yingying Zhang, Min Ke 和 Huan Xu.
    2021a. RobustPeriod：用于多周期性检测的鲁棒时频挖掘。发表于 *SIGMOD Conference*。ACM, 2328–2337。
- en: 'Wen et al. (2021b) Qingsong Wen, Liang Sun, Fan Yang, Xiaomin Song, Jingkun
    Gao, Xue Wang, and Huan Xu. 2021b. Time Series Data Augmentation for Deep Learning:
    A Survey. In *IJCAI*. ijcai.org, 4653–4660.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wen 等（2021b）Qingsong Wen、Liang Sun、Fan Yang、Xiaomin Song、Jingkun Gao、Xue Wang
    和 Huan Xu。2021b。深度学习中的时间序列数据增强：综述。见 *IJCAI*。ijcai.org，4653–4660。
- en: Winograd (1976) Shmuel Winograd. 1976. On computing the discrete Fourier transform.
    *Proceedings of the National Academy of Sciences* 73, 4 (1976), 1005–1006.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Winograd（1976）Shmuel Winograd。1976。离散傅里叶变换的计算。*国家科学院院刊* 73, 4（1976），1005–1006。
- en: 'Woo et al. (2022a) Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, and
    Steven C. H. Hoi. 2022a. CoST: Contrastive Learning of Disentangled Seasonal-Trend
    Representations for Time Series Forecasting. In *ICLR*. OpenReview.net.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Woo 等（2022a）Gerald Woo、Chenghao Liu、Doyen Sahoo、Akshat Kumar 和 Steven C. H.
    Hoi。2022a。CoST：用于时间序列预测的对比学习分解季节-趋势表示。见 *ICLR*。OpenReview.net。
- en: 'Woo et al. (2022b) Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, and
    Steven C. H. Hoi. 2022b. ETSformer: Exponential Smoothing Transformers for Time-series
    Forecasting. *CoRR* abs/2202.01381 (2022).'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Woo 等（2022b）Gerald Woo、Chenghao Liu、Doyen Sahoo、Akshat Kumar 和 Steven C. H.
    Hoi。2022b。ETSformer：用于时间序列预测的指数平滑变换器。*CoRR* abs/2202.01381（2022）。
- en: Woo et al. (2023) Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, and Steven
    C. H. Hoi. 2023. Learning Deep Time-index Models for Time Series Forecasting.
    In *ICML* *(Proceedings of Machine Learning Research, Vol. 202)*. PMLR, 37217–37237.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Woo 等（2023）Gerald Woo、Chenghao Liu、Doyen Sahoo、Akshat Kumar 和 Steven C. H. Hoi。2023。用于时间序列预测的深度时间索引模型学习。见
    *ICML*（*机器学习研究论文集，第 202 卷*）。PMLR，37217–37237。
- en: 'Wu et al. (2021) Haixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. 2021.
    Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series
    Forecasting. In *NeurIPS*. 22419–22430.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等（2021）Haixu Wu、Jiehui Xu、Jianmin Wang 和 Mingsheng Long。2021。Autoformer：用于长期序列预测的分解变换器与自相关。见
    *NeurIPS*。22419–22430。
- en: Xu et al. (2020) Kai Xu, Minghai Qin, Fei Sun, Yuhao Wang, Yen-Kuang Chen, and
    Fengbo Ren. 2020. Learning in the Frequency Domain. In *CVPR*. 1737–1746.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等（2020）Kai Xu、Minghai Qin、Fei Sun、Yuhao Wang、Yen-Kuang Chen 和 Fengbo Ren。2020。在频域中学习。见
    *CVPR*。1737–1746。
- en: 'Yang et al. (2023) Fuhao Yang, Xin Li, Min Wang, Hongyu Zang, Wei Pang, and
    Mingzhong Wang. 2023. WaveForM: Graph Enhanced Wavelet Learning for Long Sequence
    Forecasting of Multivariate Time Series. In *AAAI*. AAAI Press, 10754–10761.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等（2023）Fuhao Yang、Xin Li、Min Wang、Hongyu Zang、Wei Pang 和 Mingzhong Wang。2023。WaveForM：用于多变量时间序列长序列预测的图增强小波学习。见
    *AAAI*。AAAI Press，10754–10761。
- en: Yang and Hong (2022) Ling Yang and Shenda Hong. 2022. Unsupervised Time-Series
    Representation Learning with Iterative Bilinear Temporal-Spectral Fusion. In *ICML*
    *(Proceedings of Machine Learning Research, Vol. 162)*. PMLR, 25038–25054.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 和 Hong（2022）Ling Yang 和 Shenda Hong。2022。基于迭代双线性时间-频谱融合的无监督时间序列表示学习。见 *ICML*（*机器学习研究论文集，第
    162 卷*）。PMLR，25038–25054。
- en: Yang et al. (2022) Zhangjing Yang, Weiwu Yan, Xiaolin Huang, and Lin Mei. 2022.
    Adaptive Temporal-Frequency Network for Time-Series Forecasting. *IEEE Trans.
    Knowl. Data Eng.* 34, 4 (2022), 1576–1587.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等（2022）Zhangjing Yang、Weiwu Yan、Xiaolin Huang 和 Lin Mei。2022。用于时间序列预测的自适应时间-频率网络。*IEEE
    Trans. Knowl. Data Eng.* 34, 4（2022），1576–1587。
- en: Yi et al. (2022) Kun Yi, Qi Zhang, Liang Hu, Hui He, Ning An, Longbing Cao,
    and Zhendong Niu. 2022. Edge-Varying Fourier Graph Networks for Multivariate Time
    Series Forecasting. *CoRR* abs/2210.03093 (2022).
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yi 等（2022）Kun Yi、Qi Zhang、Liang Hu、Hui He、Ning An、Longbing Cao 和 Zhendong Niu。2022。用于多变量时间序列预测的边变傅里叶图网络。*CoRR*
    abs/2210.03093（2022）。
- en: 'Zhang et al. (2022b) Chaoli Zhang, Tian Zhou, Qingsong Wen, and Liang Sun.
    2022b. TFAD: A Decomposition Time Series Anomaly Detection Architecture with Time-Frequency
    Analysis. In *CIKM*. ACM, 2497–2507.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等（2022b）Chaoli Zhang、Tian Zhou、Qingsong Wen 和 Liang Sun。2022b。TFAD：一种具有时间-频率分析的分解时间序列异常检测架构。见
    *CIKM*。ACM，2497–2507。
- en: Zhang et al. (2017) Liheng Zhang, Charu C. Aggarwal, and Guo-Jun Qi. 2017. Stock
    Price Prediction via Discovering Multi-Frequency Trading Patterns. In *KDD*. ACM,
    2141–2149.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等（2017）Liheng Zhang、Charu C. Aggarwal 和 Guo-Jun Qi。2017。通过发现多频率交易模式进行股价预测。见
    *KDD*。ACM，2141–2149。
- en: Zhang et al. (2022a) Xiang Zhang, Ziyuan Zhao, Theodoros Tsiligkaridis, and
    Marinka Zitnik. 2022a. Self-Supervised Contrastive Pre-Training For Time Series
    via Time-Frequency Consistency. In *NeurIPS*.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等（2022a）Xiang Zhang、Ziyuan Zhao、Theodoros Tsiligkaridis 和 Marinka Zitnik。2022a。通过时间-频率一致性进行时间序列的自监督对比预训练。见
    *NeurIPS*。
- en: Zhao et al. (2022a) Xudong Zhao, Ran Tao, Wei Li, Wilfried Philips, and Wenzhi
    Liao. 2022a. Fractional Gabor Convolutional Network for Multisource Remote Sensing
    Data Classification. *IEEE Trans. Geosci. Remote. Sens.* 60 (2022), 1–18.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao等人（2022a）Xudong Zhao、Ran Tao、Wei Li、Wilfried Philips 和 Wenzhi Liao. 2022a.
    分数Gabor卷积网络用于多源遥感数据分类。*IEEE Trans. Geosci. Remote. Sens.* 60（2022），1–18。
- en: Zhao et al. (2022b) Xudong Zhao, Mengmeng Zhang, Ran Tao, Wei Li, Wenzhi Liao,
    Lianfang Tian, and Wilfried Philips. 2022b. Fractional Fourier Image Transformer
    for Multimodal Remote Sensing Data Classification. *IEEE Trans. Neural Networks
    Learn. Syst.* (2022), 1–13.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao等人（2022b）Xudong Zhao、Mengmeng Zhang、Ran Tao、Wei Li、Wenzhi Liao、Lianfang
    Tian 和 Wilfried Philips. 2022b. 分数傅里叶图像变换器用于多模态遥感数据分类。*IEEE Trans. Neural Networks
    Learn. Syst.*（2022），1–13。
- en: Zhou et al. (2022c) Kun Zhou, Hui Yu, Wayne Xin Zhao, and Ji-Rong Wen. 2022c.
    Filter-enhanced MLP is All You Need for Sequential Recommendation. In *WWW*. 2388–2399.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou等人（2022c）Kun Zhou、Hui Yu、Wayne Xin Zhao 和 Ji-Rong Wen. 2022c. 过滤器增强的MLP是序列推荐所需的一切。发表于*WWW*，2388–2399。
- en: 'Zhou et al. (2022a) Tian Zhou, Ziqing Ma, Xue Wang, Qingsong Wen, Liang Sun,
    Tao Yao, Wotao Yin, and Rong Jin. 2022a. FiLM: Frequency improved Legendre Memory
    Model for Long-term Time Series Forecasting. In *NeurIPS*.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou等人（2022a）Tian Zhou、Ziqing Ma、Xue Wang、Qingsong Wen、Liang Sun、Tao Yao、Wotao
    Yin 和 Rong Jin. 2022a. FiLM: 频率改进的Legendre记忆模型用于长期时间序列预测。发表于*NeurIPS*。'
- en: 'Zhou et al. (2022b) Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun,
    and Rong Jin. 2022b. FEDformer: Frequency enhanced decomposed transformer for
    long-term series forecasting. In *ICML*.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou等人（2022b）Tian Zhou、Ziqing Ma、Qingsong Wen、Xue Wang、Liang Sun 和 Rong Jin.
    2022b. FEDformer: 频率增强的分解变换器用于长期序列预测。发表于*ICML*。'
