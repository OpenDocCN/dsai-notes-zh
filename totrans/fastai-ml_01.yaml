- en: 'Machine Learning 1: Lesson 1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-1-84a1dc2b5236](https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-1-84a1dc2b5236)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*My personal notes from* [*machine learning class*](http://forums.fast.ai/t/another-treat-early-access-to-intro-to-machine-learning-videos/6826/1)*.
    These notes will continue to be updated and improved as I continue to review the
    course to “really” understand it. Much appreciation to* [*Jeremy*](https://twitter.com/jeremyphoward)
    *and* [*Rachel*](https://twitter.com/math_rachel) *who gave me this opportunity
    to learn.*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Syllabus in brief
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Depending on time and class interests, we’ll cover something like (not necessarily
    in this order):'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Train vs. test
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Effective validation set construction
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trees and ensembles
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Creating random forests
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpreting random forests
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is ML? Why do we use it?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: What makes a good ML project?
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Structured vs unstructured data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of failures/mistakes
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature engineering
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Domain specific — dates, URLs, text
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Embeddings / latent factors
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regularized models trained with SGD
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: 'GLMs, Elasticnet, etc (NB: see what James covered)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic neural nets
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Broadcasting, Matrix Multiplication
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training loop, backpropagation
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: KNN
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: CV / bootstrap (Diabetes data set?)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Ethical considerations
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'Skip:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality reduction
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interactions
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring training
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaborative filtering
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Momentum and LR annealing
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Random Forest: Blue Book for Bulldozers'
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Notebook](https://github.com/fastai/fastai/blob/master/courses/ml1/lesson1-rf.ipynb)
    / [Kaggle](https://www.kaggle.com/c/bluebook-for-bulldozers)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Data science ≠Software engineering [[08:43](https://youtu.be/CzdWqFTmn0Y?t=8m43s)].
    You will see code that does not follow PEP 8 and things like `import *`, but go
    along with it for a while. What we are doing right now is prototyping models,
    and prototyping models has a very different set of best practices that are taught
    nowhere. The key is to be able to do things very interactively and iteratively.
    Jupyter notebook makes this easy. If you ever wondered what `display` is, you
    can do one of the three things:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: type `display` in a cell and press shift+enter — it will tell you where it came
    from `<function IPython.core.display.display>`
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: type `?display` in a cell and press shift+enter — it will show you the documentation
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: type `??display` in a cell and press shift+enter — it will show you the source
    code. This is particularly useful for fastai library because most of the functions
    are easy to read and no longer than 5 lines long.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Download data [[12:05](https://youtu.be/CzdWqFTmn0Y?t=12m5s)]
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Entering to Kaggle competition will let you know whether you are competent at
    this kind of data in this kind of model. Is the accuracy bad because the the data
    is so noisy that you cannot do better? Or is it actually an easy dataset and you
    have made a mistake? When you are working on your own project with your own dataset,
    you will not get this kind of feedback — we just have to know that we have good
    effective techniques to reliably building baseline model.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning should help us understand a dataset, not just make predictions
    about it [[15:36](https://youtu.be/CzdWqFTmn0Y?t=15m36s)]. So by picking an area
    which we are not familiar with, it is a good test of whether we can build an understanding.
    Otherwise what can happen is that your intuition about the data can make it very
    difficult for you to be open-minded enough to see what the data really says.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few options to download the data:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Download to your computer and `scp` to AWS
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From Firefox [[17:32](https://youtu.be/CzdWqFTmn0Y?t=17m32s)], press `ctrl +
    shift + i` to open web developer tool. Go to `Network` tab, click on `Download`
    button, and cancel out of the dialog box. It shows network connections that were
    initiated. You then right-click on it and select `Copy as cURL`. Paste the command
    and add `-o bulldozer.zip` at the end (possibly remove `— — 2.0` in the cURL command)
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/39bb75eff81c8b80c0fc0e395c308c80.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: 'Jupyter trick [[21:39](https://youtu.be/CzdWqFTmn0Y?t=21m39s)] — you can open
    web-based terminal like so:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dbc7aa79ff287b6ca056702071c907b9.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: The goal of this competition is to use the training set which contains data
    through the end of 2011 to predict the sale price of bulldozers.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '**Let’s look at the data[**[**25:25**](https://youtu.be/CzdWqFTmn0Y?t=25m25s)**]:**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '**Structured data**: Columns representing a wide range of different types of
    things such as identifier, currency, date, size.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '**Unstructured data**: Images'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '`pandas` is the most important library when you are working with structured
    data which is usually imported as `pd`.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`parse_dates` — A list of any columns that contain dates'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`low_memory=False` — Forces it to read more of the file to decide what the
    types are.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In Jupyter Notebook, if you type a variable name and press `ctrl+enter` whether
    that being Dataframe, video, HTML, etc — it will generally figure out a way of
    displaying it for you [[32:13](https://youtu.be/CzdWqFTmn0Y?t=32m13s)].
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2deaf71a3f0c05a9ab50b41f47da1ac4.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: The variable we want to predict is called **Dependent Variable** in this case
    our dependent variable is `SalePrice`
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: Should you never look at the data because of the risk of overfit?
    [33:08] We want to find out at least enough to know that we have managed to imported
    okay, but tend not to really study it at all at this point, because we do not
    want to make too many assumptions about it. Many books say to do a lot of exploratory
    data analysis (EDA) first. We will learn machine learning driven EDA today.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '**Purpose of the project — Evaluation [**[**34:06**](https://youtu.be/CzdWqFTmn0Y?t=34m6s)**]**'
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Root mean squared log error. The reason we use log is because generally, you
    care not so much about missing by $10 but missing by 10%. So if it was $1000,000
    item and you are $100,000 off or if it was a $10,000 item and you are $1,000 off
    — we would consider those equivalent scale issues.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`np` — Numpy lets us treat arrays, matrices, vectors, high dimensional tensors
    as if they are Python variables.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is a random forest? [[36:37](https://youtu.be/CzdWqFTmn0Y?t=36m37s)]
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Random forest is a universal machine learning technique.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: It can predict something that can be of any kind — it could be a category (classification),
    a continuous variable (regression).
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can predict with columns of any kind — pixels, zip codes, revenues, etc (i.e.
    both structured and unstructured data).
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It does not generally overfit too badly, and it is very easy to stop it from
    overfitting.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You do not need a separate validation set in general. It can tell you how well
    it generalizes even if you only have one dataset.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has few, if any, statistical assumptions. It does not assume that your data
    is normally distributed, the relationship is linear, or you have specified interactions.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It requires very few pieces of feature engineering. For many different types
    of situation, you do not have to take the log of the data or multiply interactions
    together.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Question**: What about a curse of dimensionality? [[38:16](https://youtu.be/CzdWqFTmn0Y?t=38m16s)]
    There are two concepts you often hear — curse of dimensionality and no free lunch
    theorem. They are both largely meaningless and basically stupid and yet many people
    in the field not only know that but think the opposite so it is well worth explaining.
    The curse of dimensionality is this idea that the more columns you have, it creates
    a space that is more and more empty. There is this fascinating mathematical idea
    that the more dimensions you have, the more all of the points sit on the edge
    of that space. If you just have a single dimension where things are random, then
    they are spread out all over. Where else, if it is a square then the probability
    that they are in the middle means that they cannot be on the edge of either dimension
    so it is a little less likely that they are not on the edge. Each dimension you
    add, it becomes multiplicatively less likely that the point is not on the edge
    of at least one dimension, so in high dimensions, everything sits on the edge.
    What that means in theory is that the distance between points is much less meaningful.
    So if we assume it matters, then it would suggest that when you have lots of columns
    and you just use them without being careful to remove the ones you do not care
    about that things will not work. This turns out not to be the case for number
    of reasons'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：维度的诅咒是什么？[38:16] 你经常听到两个概念 - 维度的诅咒和没有免费午餐定理。它们两者在很大程度上是毫无意义的，基本上是愚蠢的，然而许多领域的人不仅知道这一点，而且认为相反，因此值得解释。维度的诅咒是这样一个想法，即你拥有的列越多，就会创造出一个越来越空的空间。有这样一个迷人的数学思想，即你拥有的维度越多，所有点就越多地位于该空间的边缘。如果你只有一个随机的维度，那么它们就会分散在各处。另一方面，如果是一个正方形，那么它们在中间的概率意味着它们不能在任一维度的边缘，因此它们不太可能不在边缘。每增加一个维度，点不在至少一个维度的边缘上的可能性就会成倍减少，因此在高维度中，一切都位于边缘。从理论上讲，这意味着点之间的距离变得不那么有意义。因此，如果我们认为这很重要，那么它会暗示当你有很多列并且没有小心删除你不关心的列时，事情将不起作用。出于许多原因，结果并非如此
- en: Points still do have different distances away from each other. Just because
    they are on the edge, they still vary on how far away they are from each other
    and so this point is more similar at this point than it is to that point.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点之间仍然有不同的距离。只是因为它们在边缘上，它们仍然在彼此之间的距离上有所不同，因此这一点在这一点上比在那一点上更相似。
- en: So things like k-nearest neighbors actually work really well in high dimensions
    despite what the theoreticians claimed.What really happened here was that in 90’s,
    theory took over machine learning. There was this concept of support vector machines
    that were theoretically well justified, extremely easy to analyze mathematically,
    and you can prove things about them — and we lost a decade of real practical development.
    And all these theories became very popular like the curse of dimensionality. Nowadays
    the world of machine learning has become very empirical and it turns out that
    in practice, building models on lots of columns works really well.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所以像k最近邻居这样的东西在高维度中实际上表现得非常好，尽管理论家们声称的不同。这里真正发生的是，在90年代，理论主导了机器学习。有这样一个概念，支持向量机在理论上得到了很好的证明，极易进行数学分析，你可以证明关于它们的事情
    - 我们失去了十年的真正实际发展。所有这些理论变得非常流行，比如维度的诅咒。如今，机器学习的世界变得非常经验主义，事实证明，在实践中，在许多列上构建模型确实效果非常好。
- en: No free lunch theorem [[41:08](https://youtu.be/CzdWqFTmn0Y?t=41m8s)] — their
    claim is that there is no type of model that works well for any kind of dataset.
    In the mathematical sense, any random dataset by definition is random, so there
    is not going to be some way of looking at every possible random dataset that is
    in someway more useful than any other approach. In real world, we look at data
    which is not random. Mathematically we would say it sits on some lower dimensional
    manifold. It was created by some kind of causal structure. There are some relationships
    in there, so the truth is that we are not using random datasets and hence there
    are actually techniques that work much better than other techniques for nearly
    all of the datasets you look at. Nowadays, there are empirical researchers who
    study which techniques work a lot of the time. Ensembles of decisions trees, which
    random forest for one, is perhaps the technique which most often comes at the
    top. Fast.ai provides a standard way to pre-process them properly and set their
    parameters.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有免费午餐定理[41:08] - 他们声称没有一种模型适用于任何类型的数据集。在数学意义上，任何随机数据集的定义都是随机的，因此不会有一种方法可以查看每个可能的随机数据集，使其在某种程度上比其他方法更有用。在现实世界中，我们看的是不随机的数据。从数学上讲，我们会说它位于某个较低维度的流形上。它是由某种因果结构创建的。其中存在一些关系，因此事实是我们并没有使用随机数据集，因此实际上有一些技术比其他技术在你查看的几乎所有数据集上都要好得多。如今，有经验的研究人员研究哪些技术在大多数情况下效果很好。决策树的集成，其中随机森林是其中最常见的技术之一。Fast.ai提供了一种标准的方法来适当地预处理它们并设置它们的参数。
- en: scikit-learn [[42:54](https://youtu.be/CzdWqFTmn0Y?t=42m54s)]
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: scikit-learn[42:54]
- en: Most popular and important package for machine learning in Python. It is not
    the best at everything (e.g. XGBoost is better than Gradient Boosting Tree), but
    pretty good at nearly everything.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Python中最受欢迎和重要的机器学习包。它并非在所有方面都是最好的（例如，XGBoost比梯度提升树更好），但在几乎所有方面都表现得相当不错。
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: RandomForestRegressor — regressor is a method for predicting continuous variables
    (i.e. regression)
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RandomForestRegressor - 回归器是一种预测连续变量（即回归）的方法
- en: RandomForestClassifier — classifier is a method for predicting categorical variables
    (i.e. classification)
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RandomForestClassifier - 分类器是一种预测分类变量（即分类）的方法
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Everything in scikit-learn has the same form.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn中的所有内容都具有相同的形式。
- en: Create an instance of an object for the machine learning model
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为机器学习模型创建一个对象的实例
- en: Call `fit` by passing in the independent variables (the things you are going
    to use to predict) and dependent variable (the thing you want to predict).
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过传入独立变量（你要用来预测的东西）和因变量（你想要预测的东西）来调用`fit`。
- en: '`axis=1` means remove columns.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`axis=1`表示删除列。'
- en: '`shift + tab` in Jupyter Notebook will bring up the inspection of the parameters
    of a function.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Jupyter Notebook中按下`shift + tab`将显示函数的参数检查。
- en: “list-like” means anything you can index in Python.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “类似列表”意味着任何你可以在Python中索引的东西。
- en: '![](../Images/c410ec71be1ad925a0e186cc75bc6879.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c410ec71be1ad925a0e186cc75bc6879.png)'
- en: The above code will result in an error. There was a value inside the dataset
    “Conventional”, and it did not know how to create a model using that String. We
    have to pass numbers to most machine learning models and certainly to random forests.
    So step 1 is to convert everything into numbers.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 以上的代码会导致错误。数据集“Conventional”中有一个值，它不知道如何使用该字符串创建模型。我们必须将大多数机器学习模型和随机森林转换为数字。因此，第一步是将所有内容转换为数字。
- en: This dataset contains a mix of **continuous** and **categorical** variables.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集包含了**连续**和**分类**变量的混合。
- en: continuous — numbers where the meaning is numeric such as price.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: continuous — 数字，其含义是数值，比如价格。
- en: categorical — either numbers where the meaning is not continuous like zip code
    or string such as “large”, “medium”, “small”
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: categorical — 要么是数字，其含义不是连续的，比如邮政编码，要么是字符串，比如“大”，“中”，“小”
- en: Here are some of the information we can extract from date — year, month, quarter,
    day of month, day of week, week of year, is it a holiday? weekend? was it raining?
    was there a sport event that day? It really depends on what you are doing. If
    you are predicting soda sales in SoMa, you would probably want to know if there
    was a San Francisco Giants ball game that day. What is in a date is one of the
    most important piece of feature engineering you can do and no machine learning
    algorithm can tell you whether the Giants were playing that day and that it was
    important. So this is where you need to do feature engineering.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们可以从日期中提取的一些信息 — 年份、月份、季度、月中的日期、星期几、一年中的周数、是否是假期？周末？下雨了吗？那天有体育赛事吗？这取决于你在做什么。如果你正在预测SoMa地区的苏打销售额，你可能想知道那天是否有旧金山巨人队的比赛。日期中包含的信息是你可以进行的最重要的特征工程之一，没有任何机器学习算法可以告诉你那天巨人队是否在比赛，以及这一点有多重要。因此，这就是你需要进行特征工程的地方。
- en: The `add_datepart` method extracts particular date fields from a complete datetime
    for the purpose of constructing categoricals. You should always consider this
    feature extraction step when working with date-time. Without expanding your date-time
    into these additional fields, you can’t capture any trend/cyclical behavior as
    a function of time at any of these granularities.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`add_datepart`方法从完整的日期时间中提取特定的日期字段，以构建分类变量。在处理日期时间时，你应该始终考虑这个特征提取步骤。如果不将日期时间扩展到这些额外字段，你就无法捕捉到任何趋势/周期性行为，作为时间的函数在任何这些粒度上。'
- en: '[PRE6]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`getattr` — look inside of an object and finds an attribute with that name'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getattr` — 查找对象内部并找到具有该名称的属性'
- en: '`drop=True` — unless specified, it will drop the date time field because we
    cannot use “saledate” directly because it is not a number.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`drop=True` — 除非指定，它将删除日期时间字段，因为我们不能直接使用“saledate”，因为它不是一个数字。'
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`fld` — Pandas series'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fld` — Pandas系列'
- en: '`dt` — `fld` does not have “year” because it only apply to Pandas series that
    are date time objects. So what Pandas does is it splits out different methods
    inside attributes that are specific to what they are. So date time objects will
    have `dt` attribute defined and that is where you will find all the date time
    specific attributes.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dt` — `fld`没有“year”，因为它只适用于Pandas系列，这些系列是日期时间对象。因此，Pandas会将不同的方法拆分到特定于它们的属性中。因此，日期时间对象将有`dt`属性定义，那里你会找到所有日期时间特定的属性。'
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**Question**: [[55:40](https://youtu.be/CzdWqFTmn0Y?t=55m40s)] What is the
    difference between `df[''saleYear'']` and `df.saleYear` ? It is safer to use square
    brackets especially when assigning values and there is a possibility that the
    column does not already exist.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：[[55:40](https://youtu.be/CzdWqFTmn0Y?t=55m40s)] `df[''saleYear'']`
    和 `df.saleYear` 之间有什么区别？在分配值时最好使用方括号，尤其是在列不存在的情况下。'
- en: After running `add_datepart`, it added many numerical columns and removed `saledate`
    column. This is not quite enough to get passed the error we saw earlier as we
    still have other columns that contain string values. Pandas has a concept of a
    category data type, but by default it would not turn anything into a category
    for you. Fast.ai provides a function called `train_cats` which creates categorical
    variables for everything that is a String. Behind the scenes, it creates a column
    that is an integer and it is going to store a mapping from the integers to the
    strings. `train_cats` is called “train” because it is training data specific.
    It is important that validation and test sets will use the same category mappings
    (in other words, if you used 1 for “high” for a training dataset, then 1 should
    also be for “high” in validation and test datasets). For validation and test dataset,
    use `apply_cats` instead.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`add_datepart`后，它添加了许多数字列并删除了`saledate`列。这还不足以解决我们之前看到的错误，因为我们仍然有其他包含字符串值的列。Pandas有一个类别数据类型的概念，但默认情况下它不会将任何内容转换为类别。Fast.ai提供了一个名为`train_cats`的函数，它会为所有是字符串的内容创建分类变量。在幕后，它创建了一个整数列，并将从整数到字符串的映射存储在其中。`train_cats`被称为“train”，因为它是特定于训练数据的。验证和测试集将使用相同的类别映射（换句话说，如果你在训练数据集中使用1表示“高”，那么在验证和测试数据集中1也应该表示“高”）。对于验证和测试数据集，使用`apply_cats`。
- en: '[PRE9]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`df_raw.UsageBand.cat` — Similar to`fld.dt.year` , `.cat` gives you access
    to things assuming something is a category.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`df_raw.UsageBand.cat` — 类似于`fld.dt.year`，`.cat`让你可以访问假设某个东西是一个类别的内容。'
- en: 'The order does not matter too much, but since we are going to be creating a
    decision tree that split things at a single point (i.e. `High` vs. `Low` and `Medium`
    , `High` and `Low` vs. `Medium` ) which is a little bit weird. To order them in
    a sensible manner, you can do the following:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序并不太重要，但由于我们将创建一个在单个点（即`高` vs. `低` 和 `中`，`高` 和 `低` vs. `中`）分割事物的决策树，这有点奇怪。为了以合理的方式对它们进行排序，您可以执行以下操作：
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`inplace` will ask Pandas to change the existing dataframe rather than returning
    a new one.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inplace`将要求Pandas更改现有数据框而不是返回一个新的。'
- en: There is a kind of categorical variable called “ordinal”. An ordinal categorical
    variable has some kind of order (e.g. “Low” < “Medium” < “High”). Random forests
    are not terribly sensitive for that fact, but it is worth noting.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种称为“有序”的分类变量。有序分类变量具有某种顺序（例如“低” < “中” < “高”）。随机森林对此事实并不敏感，但值得注意。
- en: '[PRE11]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The above will add a number of empty values for each series, we sort them by
    the index (`[pandas.Series.sort_index](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.sort_index.html)`),
    and divide by a number of dataset.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 上述操作将为每个系列添加一些空值，我们按索引排序它们（`[pandas.Series.sort_index](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.sort_index.html)`），并除以数据集的数量。
- en: Reading CSV took about 10 seconds, and processing took another 10 seconds, so
    if we do not want to wait again, it is a good idea to save them. Here we will
    save it in a feather format. What this is going to do is to save it to disk in
    exactly the same basic format that it is in RAM. This is by far the fastest way
    to save something, and also to read it back. Feather format is becoming standard
    in not only Pandas but in Java, Apache Spark, etc.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 读取CSV大约需要10秒，处理另外需要10秒，因此如果我们不想再等待，最好将它们保存下来。这里我们将以feather格式保存。这将以与RAM中相同基本格式保存到磁盘。这是迄今为止最快的保存和读取方式。Feather格式不仅在Pandas中成为标准，而且在Java、Apache
    Spark等中也是如此。
- en: '[PRE12]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can read it back as so:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样读取它：
- en: '[PRE13]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We will replace categories with their numeric codes, handle missing continuous
    values, and split the dependent variable into a separate variable.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用它们的数字代码替换类别，处理缺失的连续值，并将因变量拆分为一个单独的变量。
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/4dc727212fbd19c945c24b2a18cdc13a.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4dc727212fbd19c945c24b2a18cdc13a.png)'
- en: proc_df in structured.py
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: structured.py中的proc_df
- en: '`df` — data frame'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`df` — 数据框'
- en: '`y_fld` — name of the dependent variable'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_fld` — 依赖变量的名称'
- en: It makes a copy of the data frame, grab the dependent variable values (`y_fld`),
    and drop the dependent variable from the data frame.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它会复制数据框，获取依赖变量值（`y_fld`），并从数据框中删除依赖变量。
- en: Then it will `fix_missing` (see below)
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后它将`fix_missing`（见下文）
- en: We then will go through the data frame and call `numericalize` (see below).
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们将遍历数据框并调用`numericalize`（见下文）。
- en: '`dummies` — There are columns with a small number of possible values, you can
    put into dummies instead of numericalizing them. But we will not do that for now.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dummies` — 有少量可能值的列，可以放入虚拟变量而不是数值化它们。但我们现在不会这样做。'
- en: '**fix_missing**'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**fix_missing**'
- en: '![](../Images/6f5e52295a7fb83ee4c92e579f0121ac.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6f5e52295a7fb83ee4c92e579f0121ac.png)'
- en: For numeric data type, first we check if there is null column. If so, it will
    create a new column with a name with `_na` appended at the end and set it to 1
    if it is missing; 0 otherwise (boolean). It will then replace the missing value
    with a median.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于数值数据类型，首先我们检查是否有空列。如果有，它将创建一个新列，名称末尾附加`_na`，如果缺失则设置为1；否则设置为0（布尔值）。然后将缺失值替换为中位数。
- en: We do not need to do this for categorical variables because Pandas handles them
    automatically by setting them to `-1` .
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不需要为分类变量执行此操作，因为Pandas会自动处理它们并将它们设置为`-1`。
- en: '**numericalize**'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**numericalize**'
- en: '![](../Images/99aa5bf4d1516b7307b5f4c1cacc248c.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99aa5bf4d1516b7307b5f4c1cacc248c.png)'
- en: If it is not numeric and is a categorical type, we will replace the column with
    its code plus 1\. By default pandas uses `-1` for missing, so now missing will
    have an ID of `0` .
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果不是数字且是分类类型，我们将用其代码加1替换该列。默认情况下，Pandas对缺失使用`-1`，因此现在缺失将具有ID为`0`。
- en: '[PRE15]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/0e7cb3fd754beb09922ee1267f1ddbef.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e7cb3fd754beb09922ee1267f1ddbef.png)'
- en: Now we have all numerical values. Note that booleans are treated as numbers.
    So we can create a random forest.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有所有的数值值。请注意，布尔值被视为数字。因此我们可以创建一个随机森林。
- en: '[PRE16]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Random forests are **trivially parallelizable** — meaning if you have more than
    one CPU, you can split up the data across different CPUs and it linearly scale.
    So the more CPUs you have, it will divide the time it takes by that number (not
    exactly but roughly). `n_jobs=-1` tells the random forest regressor to create
    a separate job/process for each CPU you have.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是**极易并行化**的 — 意味着如果您有多个CPU，可以将数据分配到不同的CPU上并且它会线性扩展。因此，您拥有的CPU越多，花费的时间就会按照该数字减少（不完全准确，但大致如此）。`n_jobs=-1`告诉随机森林回归器为每个CPU创建一个单独的作业/进程。
- en: '`m.score` will return r² value (1 is good, 0 is bad). We will learn r² next
    week.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`m.score`将返回r²值（1是好的，0是坏的）。我们将在下周学习r²。'
- en: Wow, an r² of 0.98 — that’s great, right? Well, perhaps not…
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，r²为0.98 — 那很棒，对吧？嗯，也许不是...
- en: 'Possibly **the most important idea** in machine learning is that of having
    separate training & validation data sets. As motivation, suppose you don’t divide
    up your data, but instead use all of it. And suppose you have lots of parameters:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中**最重要的想法**之一是拥有单独的训练和验证数据集。作为动机，假设您不将数据分割，而是使用全部数据。假设您有很多参数：
- en: '![](../Images/46b9cf6077e1962a6a2dec160380826e.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46b9cf6077e1962a6a2dec160380826e.png)'
- en: '[Underfitting and Overfitting](https://datascience.stackexchange.com/questions/361/when-is-a-model-underfitted)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[欠拟合和过拟合](https://datascience.stackexchange.com/questions/361/when-is-a-model-underfitted)'
- en: The error for the pictured data points is lowest for the model on the far right
    (the blue curve passes through the red points almost perfectly), yet it’s not
    the best choice. Why is that? If you were to gather some new data points, they
    most likely would not be on that curve in the graph on the right, but would be
    closer to the curve in the middle graph.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图片中数据点的误差对于最右侧的模型最低（蓝色曲线几乎完美地穿过红色点），但这并不是最佳选择。为什么呢？如果您收集一些新的数据点，它们很可能不会在右侧图表中的那条曲线上，而是会更接近中间图表中的曲线。
- en: This illustrates how using all our data can lead to **overfitting**. A validation
    set helps diagnose this problem.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这说明如何使用所有数据可能导致**过拟合**。验证集有助于诊断这个问题。
- en: '[PRE17]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Base Model
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基础模型
- en: By using validation set, you see that the r² is 0.88 for validation set.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用验证集，您会发现验证集的r²为0.88。
- en: '[PRE18]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**[training rmse, validation rmse, r² for training set, r² for validation set]*'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**[训练集rmse，验证集rmse，训练集r²，验证集r²]*'
- en: If you check Kaggle competition’s public board, RMSE of 0.25 will fall around
    top 25%. Random forests are insanely powerful and this totally standardized process
    is insanely good for any datasets.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您查看Kaggle竞赛的公共榜单，RMSE为0.25的排名将在前25%左右。随机森林非常强大，这种完全标准化的过程对任何数据集都非常好。
- en: Before the next class
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下节课之前
- en: Please try this process to solve as many Kaggle competitions as possible. What
    will likely happen is that you will be pleasantly surprised that you will do pretty
    well with just an hour of lecture.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 请尝试使用这个过程尽可能多地解决Kaggle竞赛。您很可能会惊喜地发现，仅仅一小时的讲座您就能做得相当不错。
