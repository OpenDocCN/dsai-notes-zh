- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:50:47'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:50:47
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2110.04596] Deep Long-Tailed Learning: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2110.04596] 深度长尾学习：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2110.04596](https://ar5iv.labs.arxiv.org/html/2110.04596)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2110.04596](https://ar5iv.labs.arxiv.org/html/2110.04596)
- en: 'Deep Long-Tailed Learning: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度长尾学习：综述
- en: 'Yifan Zhang, Bingyi Kang, Bryan Hooi, Shuicheng Yan, , and Jiashi Feng Y. Zhang
    and B. Hooi are with School of Computing, National University of Singapore. E-mail:
    yifan.zhang@u.nus.edu, dcsbhk@nus.edu.sg. B. Kang and J. Feng are with ByteDance
    AI Lab. E-mail: bingykang@gmail.com, jshfeng@bytedance.com. S. Yan is with SEA
    AI Lab. E-mail: yansc@sea.com.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 张一凡、康冰怡、霍辉、颜水成以及冯佳士 Y. Zhang 和 B. Hooi 供职于新加坡国立大学计算机学院。电子邮件：yifan.zhang@u.nus.edu,
    dcsbhk@nus.edu.sg。B. Kang 和 J. Feng 供职于字节跳动 AI 实验室。电子邮件：bingykang@gmail.com, jshfeng@bytedance.com。S.
    Yan 供职于 SEA AI 实验室。电子邮件：yansc@sea.com。
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep long-tailed learning, one of the most challenging problems in visual recognition,
    aims to train well-performing deep models from a large number of images that follow
    a long-tailed class distribution. In the last decade, deep learning has emerged
    as a powerful recognition model for learning high-quality image representations
    and has led to remarkable breakthroughs in generic visual recognition. However,
    long-tailed class imbalance, a common problem in practical visual recognition
    tasks, often limits the practicality of deep network based recognition models
    in real-world applications, since they can be easily biased towards dominant classes
    and perform poorly on tail classes. To address this problem, a large number of
    studies have been conducted in recent years, making promising progress in the
    field of deep long-tailed learning. Considering the rapid evolution of this field,
    this paper aims to provide a comprehensive survey on recent advances in deep long-tailed
    learning. To be specific, we group existing deep long-tailed learning studies
    into three main categories (*i.e.,* class re-balancing, information augmentation
    and module improvement), and review these methods following this taxonomy in detail.
    Afterward, we empirically analyze several state-of-the-art methods by evaluating
    to what extent they address the issue of class imbalance via a newly proposed
    evaluation metric, *i.e.,* relative accuracy. We conclude the survey by highlighting
    important applications of deep long-tailed learning and identifying several promising
    directions for future research.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 深度长尾学习是视觉识别中最具挑战性的问题之一，旨在从遵循长尾类别分布的大量图像中训练表现良好的深度模型。在过去十年中，深度学习作为一种强大的识别模型，能够学习高质量的图像表示，并在通用视觉识别领域取得了显著突破。然而，长尾类别不平衡是实际视觉识别任务中常见的问题，往往限制了基于深度网络的识别模型在实际应用中的实用性，因为这些模型容易对主导类别产生偏见，并在尾部类别上表现不佳。为了解决这一问题，近年来进行了大量研究，并在深度长尾学习领域取得了有希望的进展。考虑到这一领域的快速发展，本文旨在提供对深度长尾学习最新进展的全面综述。具体而言，我们将现有的深度长尾学习研究分为三大类（*即，*类别重平衡、信息增强和模块改进），并详细回顾这些方法。随后，我们通过一种新提出的评价指标*即，*相对准确性，实证分析了几种最先进的方法，以评估它们在解决类别不平衡问题方面的效果。最后，我们通过突出深度长尾学习的重要应用，并识别几个有前景的未来研究方向，来总结本综述。
- en: 'Index Terms:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Long-tailed Learning, Deep Learning, Imbalanced Learning
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 长尾学习，深度学习，不平衡学习
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Deep learning allows computational models, composed of multiple processing layers,
    to learn data representations with multiple levels of abstraction [[1](#bib.bib1),
    [2](#bib.bib2)] and has made incredible progress in computer vision [[3](#bib.bib3),
    [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8)].
    The key enablers of deep learning are the availability of large-scale datasets,
    the emergence of GPUs, and the advancement of deep network architectures [[9](#bib.bib9)].
    Thanks to the strong ability of learning high-quality data representations, deep
    neural networks have been applied with great success to many visual discriminative
    tasks, including image classification [[6](#bib.bib6), [10](#bib.bib10)], object
    detection [[11](#bib.bib11), [7](#bib.bib7)] and semantic segmentation [[12](#bib.bib12),
    [8](#bib.bib8)].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习允许由多个处理层组成的计算模型学习具有多个抽象级别的数据表示[[1](#bib.bib1), [2](#bib.bib2)]，并在计算机视觉领域取得了令人惊讶的进展[[3](#bib.bib3),
    [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8)]。深度学习的关键因素是大规模数据集的可用性、GPU的出现以及深度网络架构的进步[[9](#bib.bib9)]。由于学习高质量数据表示的强大能力，深度神经网络已成功应用于许多视觉识别任务，包括图像分类[[6](#bib.bib6),
    [10](#bib.bib10)]、目标检测[[11](#bib.bib11), [7](#bib.bib7)]和语义分割[[12](#bib.bib12),
    [8](#bib.bib8)]。
- en: 'In real-world applications, training samples typically exhibit a long-tailed
    class distribution, where a small portion of classes have a massive number of
    sample points but the others are associated with only a few samples [[13](#bib.bib13),
    [14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16)]. Such class imbalance of
    training sample numbers, however, makes the training of deep network based recognition
    models very challenging. As shown in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Deep Long-Tailed Learning: A Survey"), the trained model can be easily biased
    towards head classes with massive training data, leading to poor model performance
    on tail classes that have limited data [[17](#bib.bib17), [18](#bib.bib18), [19](#bib.bib19)].
    Therefore, the deep models trained by the common practice of empirical risk minimization [[20](#bib.bib20)]
    cannot handle real-world applications with long-tailed class imbalance, *e.g.,*
    face recognition [[21](#bib.bib21), [22](#bib.bib22)], species classification [[23](#bib.bib23),
    [24](#bib.bib24)], medical image diagnosis [[25](#bib.bib25)], urban scene understanding [[26](#bib.bib26)]
    and unmanned aerial vehicle detection [[27](#bib.bib27)].'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '在实际应用中，训练样本通常表现出长尾类分布，其中一小部分类拥有大量样本点，而其他类只有少量样本[[13](#bib.bib13), [14](#bib.bib14),
    [15](#bib.bib15), [16](#bib.bib16)]。然而，这种训练样本数量的不平衡使得基于深度网络的识别模型训练非常具有挑战性。如图[1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Deep Long-Tailed Learning: A Survey")所示，训练的模型容易偏向于拥有大量训练数据的主类，导致在数据有限的尾类上模型性能较差[[17](#bib.bib17),
    [18](#bib.bib18), [19](#bib.bib19)]。因此，采用经验风险最小化的常见实践训练的深度模型无法处理具有长尾类不平衡的实际应用，如面部识别[[21](#bib.bib21),
    [22](#bib.bib22)]、物种分类[[23](#bib.bib23), [24](#bib.bib24)]、医学影像诊断[[25](#bib.bib25)]、城市场景理解[[26](#bib.bib26)]和无人机检测[[27](#bib.bib27)]。'
- en: '![Refer to caption](img/79ec732a408eedf1ea4baa7f4c78747d.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/79ec732a408eedf1ea4baa7f4c78747d.png)'
- en: 'Figure 1: The label distribution of a long-tailed dataset (*e.g.,* the iNaturalist
    species dataset [[23](#bib.bib23)] with more than 8,000 classes). The head-class
    feature space learned on these sampled is often larger than tail classes, while
    the decision boundary is usually biased towards dominant classes.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：长尾数据集的标签分布（*例如，*iNaturalist物种数据集[[23](#bib.bib23)]，具有超过8,000个类）。在这些采样上学习的头部类特征空间通常大于尾部类，而决策边界通常偏向于占主导地位的类。
- en: To address long-tailed class imbalance, massive deep long-tailed learning studies
    have been conducted in recent years [[16](#bib.bib16), [28](#bib.bib28), [15](#bib.bib15),
    [29](#bib.bib29), [30](#bib.bib30)]. Despite the rapid evolution in this field,
    there is still no systematic study to review and discuss existing progress. To
    fill this gap, we aim to provide a comprehensive survey for recent long-tailed
    learning studies conducted before mid-2021.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决长尾类不平衡问题，近年来进行了大量的深度长尾学习研究[[16](#bib.bib16), [28](#bib.bib28), [15](#bib.bib15),
    [29](#bib.bib29), [30](#bib.bib30)]。尽管该领域迅速发展，但仍缺乏系统性的研究来回顾和讨论现有的进展。为填补这一空白，我们旨在提供一个关于2021年中期之前进行的最新长尾学习研究的全面调查。
- en: 'As shown in Fig. [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Deep Long-Tailed Learning:
    A Survey"), we group existing methods into three main categories based on their
    main technical contributions, *i.e.,* class re-balancing, information augmentation
    and module improvement; these categories can be further classified into nine sub-categories:
    re-sampling, class-sensitive learning, logit adjustment, transfer learning, data
    augmentation, representation learning, classifier design, decoupled training and
    ensemble learning. According to this taxonomy, we provide a comprehensive review
    of existing methods, and also empirically analyze several state-of-the-art methods
    by evaluating their abilities of handling class imbalance using a new evaluation
    metric, namely relative accuracy. We conclude the survey by introducing several
    real-world application scenarios of deep long-tailed learning and identifying
    several promising research directions that can be explored by the community in
    the future.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '如图[2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Deep Long-Tailed Learning: A Survey")所示，我们将现有方法根据其主要技术贡献分为三大类，即：类别重新平衡、信息增强和模块改进；这些类别可以进一步细分为九个子类别：重采样、类别敏感学习、logit
    调整、迁移学习、数据增强、表征学习、分类器设计、解耦训练和集成学习。根据这一分类法，我们提供了对现有方法的全面回顾，并通过使用一种新的评估指标，即相对准确性，实证分析了几种先进方法在处理类别不平衡方面的能力。我们通过介绍深度长尾学习的几个实际应用场景，并指出社区未来可以探索的几个有前景的研究方向来结束本次调查。'
- en: We summarize the key contributions of this survey as follows.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这项调查的关键贡献总结如下。
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: To the best of our knowledge, this is the first comprehensive survey of deep
    long-tailed learning, which will provide a better understanding of long-tailed
    visual learning with deep neural networks for researchers and the community.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 据我们所知，这是第一份全面的深度长尾学习调查，旨在为研究人员和社区提供对深度神经网络下长尾视觉学习的更好理解。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We provide an in-depth review of advanced long-tailed learning studies, and
    empirically study state-of-the-art methods by evaluating to what extent they handle
    long-tailed class imbalance via a new relative accuracy metric.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对先进的长尾学习研究进行了深入回顾，并通过评估它们在多大程度上通过新的相对准确性指标处理长尾类别不平衡来进行实证研究。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We identify four potential directions for method innovation as well as eight
    new deep long-tailed learning task settings for future research.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们确定了四个潜在的方法创新方向以及八个新的深度长尾学习任务设置以供未来研究。
- en: 'The rest of this survey will be organized as follows: Section [2](#S2 "2 Problem
    Overview ‣ Deep Long-Tailed Learning: A Survey") presents the problem definition
    and introduces widely-used datasets, metrics and applications. Section [3](#S3
    "3 Classic Methods ‣ Deep Long-Tailed Learning: A Survey") provides a comprehensive
    review of advanced long-tailed learning methods and Section [4](#S4 "4 Empirical
    Studies ‣ Deep Long-Tailed Learning: A Survey") empirically analyzes several state-of-the-art
    methods based on a new evaluation metric. Section [5](#S5 "5 Future Directions
    ‣ Deep Long-Tailed Learning: A Survey") identifies future research directions.
    We conclude the survey in Section [6](#S6 "6 Conclusion ‣ Deep Long-Tailed Learning:
    A Survey").'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '本次调查的其余部分将按以下方式组织：第[2](#S2 "2 Problem Overview ‣ Deep Long-Tailed Learning:
    A Survey")节介绍问题定义，并介绍广泛使用的数据集、指标和应用。第[3](#S3 "3 Classic Methods ‣ Deep Long-Tailed
    Learning: A Survey")节全面回顾了先进的长尾学习方法，第[4](#S4 "4 Empirical Studies ‣ Deep Long-Tailed
    Learning: A Survey")节基于新的评估指标对几种最先进的方法进行了实证分析。第[5](#S5 "5 Future Directions ‣
    Deep Long-Tailed Learning: A Survey")节确定了未来的研究方向。第[6](#S6 "6 Conclusion ‣ Deep
    Long-Tailed Learning: A Survey")节总结了本次调查。'
- en: '![Refer to caption](img/57b6bf9b30e833e586450bf6932e1820.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/57b6bf9b30e833e586450bf6932e1820.png)'
- en: 'Figure 2: Taxonomy of existing deep long-tailed learning methods.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：现有深度长尾学习方法的分类。
- en: 2 Problem Overview
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 问题概述
- en: 2.1 Problem Definition
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 问题定义
- en: 'Deep long-tailed learning seeks to learn a deep neural network model from a
    training dataset with a long-tailed class distribution, where a small fraction
    of classes have a massive number of samples, and the rest of the classes are associated
    with only a few samples (c.f. Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Deep
    Long-Tailed Learning: A Survey")). Let $\{x_{i},y_{i}\}_{i=1}^{n}$ be the long-tailed
    training set, where each sample $x_{i}$ has a corresponding class label $y_{i}$.
    The total number of training set over $K$ classes is $n=\sum_{k=1}^{K}n_{k}$,
    where $n_{k}$ denotes the data number of class $k$; let $\pi$ denote the vector
    of label frequencies, where $\pi_{k}=n_{k}/n$ indicates the label frequency of
    class $k$. Without loss of generality, a common assumption in long-tailed learning [[31](#bib.bib31),
    [32](#bib.bib32)] is that the classes are sorted by cardinality in decreasing
    order (*i.e.,* if $i_{1}<i_{2}$, then $n_{i_{1}}\geq n_{i_{2}}$, and $n_{1}\gg
    n_{K}$), and then the imbalance ratio is defined as $n_{1}$/$n_{K}$.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '深度长尾学习旨在从具有长尾类分布的训练数据集中学习深度神经网络模型，其中少量类别有大量样本，而其余类别则仅有少量样本（参见图 [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Deep Long-Tailed Learning: A Survey")）。设 $\{x_{i},y_{i}\}_{i=1}^{n}$
    为长尾训练集，其中每个样本 $x_{i}$ 具有相应的类别标签 $y_{i}$。训练集在 $K$ 类中的总数为 $n=\sum_{k=1}^{K}n_{k}$，其中
    $n_{k}$ 表示类别 $k$ 的数据数量；设 $\pi$ 为标签频率向量，其中 $\pi_{k}=n_{k}/n$ 表示类别 $k$ 的标签频率。为了不失一般性，长尾学习中的一个常见假设 [[31](#bib.bib31),
    [32](#bib.bib32)] 是类按数量降序排序（*即*，如果 $i_{1}<i_{2}$，则 $n_{i_{1}}\geq n_{i_{2}}$，并且
    $n_{1}\gg n_{K}$），然后不平衡比定义为 $n_{1}$/$n_{K}$。'
- en: 'This task is challenging due to two difficulties: (1) imbalanced data numbers
    across classes make deep models biased to head classes and performs poorly on
    tail classes; (2) lack of tail-class samples makes it further challenging to train
    models for tail-class classification. Such a task is fundamental and may occur
    in various visual recognition tasks, such as image classification [[15](#bib.bib15),
    [32](#bib.bib32)], detection [[19](#bib.bib19), [33](#bib.bib33)] and segmentation [[34](#bib.bib34),
    [35](#bib.bib35), [26](#bib.bib26)].'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个任务具有两个挑战：（1）类别之间的数据数量不平衡使得深度模型对头类有偏倚，对尾类表现较差；（2）尾类样本的缺乏使得为尾类分类训练模型更加困难。这样的任务是基础性的，并可能出现在各种视觉识别任务中，如图像分类 [[15](#bib.bib15),
    [32](#bib.bib32)]、检测 [[19](#bib.bib19), [33](#bib.bib33)] 和分割 [[34](#bib.bib34),
    [35](#bib.bib35), [26](#bib.bib26)]。
- en: 'TABLE I: Statistics of long-tailed datasets. “Cls.” indicates image classification;
    “Det.” represents object detection; “Seg.” means instance segmentation.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '表 I: 长尾数据集的统计数据。“分类”表示图像分类；“检测”代表目标检测；“分割”表示实例分割。'
- en: '| Task | Dataset | $\#$ classes | $\#$ training data | $\#$ test data |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 数据集 | $\#$ 类别 | $\#$ 训练数据 | $\#$ 测试数据 |'
- en: '| Cls. | ImageNet-LT [[15](#bib.bib15)] | 1,000 | 115,846 | 50,000 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 分类 | ImageNet-LT [[15](#bib.bib15)] | 1,000 | 115,846 | 50,000 |'
- en: '| CIFAR100-LT [[18](#bib.bib18)] | 100 | 50,000 | 10,000 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR100-LT [[18](#bib.bib18)] | 100 | 50,000 | 10,000 |'
- en: '| Places-LT [[15](#bib.bib15)] | 365 | 62,500 | 36,500 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| Places-LT [[15](#bib.bib15)] | 365 | 62,500 | 36,500 |'
- en: '| iNaturalist 2018 [[23](#bib.bib23)] | 8,142 | 437,513 | 24,426 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| iNaturalist 2018 [[23](#bib.bib23)] | 8,142 | 437,513 | 24,426 |'
- en: '| Det./Seg. | LVIS v0.5 [[36](#bib.bib36)] | 1,230 | 57,000 | 20,000 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 检测/分割 | LVIS v0.5 [[36](#bib.bib36)] | 1,230 | 57,000 | 20,000 |'
- en: '| LVIS v1 [[36](#bib.bib36)] | 1,203 | 100,000 | 19,800 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| LVIS v1 [[36](#bib.bib36)] | 1,203 | 100,000 | 19,800 |'
- en: '| Multi-label Cls. | VOC-LT [[37](#bib.bib37)] | 20 | 1,142 | 4,952 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 多标签分类 | VOC-LT [[37](#bib.bib37)] | 20 | 1,142 | 4,952 |'
- en: '| COCO-LT [[37](#bib.bib37)] | 80 | 1,909 | 5,000 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| COCO-LT [[37](#bib.bib37)] | 80 | 1,909 | 5,000 |'
- en: '| Video Cls. | VideoLT [[38](#bib.bib38)] | 1,004 | 179,352 | 51,244 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 视频分类 | VideoLT [[38](#bib.bib38)] | 1,004 | 179,352 | 51,244 |'
- en: 2.2 Datasets
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 数据集
- en: 'In recent years, a variety of visual datasets have been released for long-tailed
    learning, differing in tasks, class numbers and sample numbers. In Table [I](#S2.T1
    "TABLE I ‣ 2.1 Problem Definition ‣ 2 Problem Overview ‣ Deep Long-Tailed Learning:
    A Survey"), we summarize nine visual datasets that are widely used in the deep
    long-tailed learning community.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '近年来，已经发布了各种视觉数据集用于长尾学习，这些数据集在任务、类别数量和样本数量上有所不同。在表 [I](#S2.T1 "TABLE I ‣ 2.1
    Problem Definition ‣ 2 Problem Overview ‣ Deep Long-Tailed Learning: A Survey")中，我们总结了深度长尾学习社区广泛使用的九个视觉数据集。'
- en: 'In long-tailed image classification, there are four benchmark datasets: ImageNet-LT [[15](#bib.bib15)],
    CIFAR100-LT [[18](#bib.bib18)], Places-LT [[15](#bib.bib15)], and iNaturalist
    2018 [[23](#bib.bib23)]. The previous three are sampled from ImageNet [[39](#bib.bib39)],
    CIFAR100 [[40](#bib.bib40)] and Places365 [[41](#bib.bib41)] following Pareto
    distributions, respectively, while iNaturalist is a real-world long-tailed dataset.
    The imbalance ratio of ImageNet-LT, Places-LT and iNaturalist are 256, 996 and
    500, respectively; CIFAR100-LT has three variants with various imbalance ratios
    $\{10,50,100\}$.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在长尾图像分类中，有四个基准数据集：ImageNet-LT [[15](#bib.bib15)]、CIFAR100-LT [[18](#bib.bib18)]、Places-LT [[15](#bib.bib15)]
    和 iNaturalist 2018 [[23](#bib.bib23)]。前面三个数据集分别从 ImageNet [[39](#bib.bib39)]、CIFAR100 [[40](#bib.bib40)]
    和 Places365 [[41](#bib.bib41)] 中按照 Pareto 分布采样，而 iNaturalist 是一个真实世界的长尾数据集。ImageNet-LT、Places-LT
    和 iNaturalist 的不平衡比率分别为 256、996 和 500；CIFAR100-LT 有三种变体，其不平衡比率分别为 $\{10,50,100\}$。
- en: In long-tailed object detection and instance segmentation, LVIS [[36](#bib.bib36)],
    providing precise bounding box and mask annotations, is the widely-used benchmark.
    In multi-label image classification, the benchmarks are VOC-LT [[37](#bib.bib37)]
    and COCO-LT [[37](#bib.bib37)], which are sampled from PASCAL VOC 2012 [[42](#bib.bib42)]
    and COCO [[43](#bib.bib43)], respectively. Recently, a large-scale “untrimmed”
    video dataset, namely VideoLT [[38](#bib.bib38)], was released for long-tailed
    video recognition.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在长尾目标检测和实例分割中，提供精确的边界框和掩码注释的 LVIS [[36](#bib.bib36)] 是广泛使用的基准。在多标签图像分类中，基准数据集是
    VOC-LT [[37](#bib.bib37)] 和 COCO-LT [[37](#bib.bib37)]，它们分别从 PASCAL VOC 2012 [[42](#bib.bib42)]
    和 COCO [[43](#bib.bib43)] 中采样。最近，一个大规模的“未裁剪”视频数据集 VideoLT [[38](#bib.bib38)] 被发布，用于长尾视频识别。
- en: 2.3 Evaluation Metrics
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 评估指标
- en: Long-tailed learning seeks to train a well-performing model on the data with
    long-tailed class imbalance. To evaluate how well class imbalance is resolved,
    the model performance on all classes and the performance on class subsets (*i.e.,*
    head, middle and tail classes) are usually reported. Note that the evaluation
    metrics should treat each class equally. Following this principle, top-1 accuracy
    or error rate is often used for balanced test sets, where every test sample is
    equally important. When the test set is not balanced, mean Average Precision (mAP)
    or macro accuracy is often adopted since the two metrics treat each class equally.
    For example, in previous studies, top-1 accuracy or error rate was widely used
    for long-tailed image classification, in which the test set is usually assumed
    to be near-balanced. Meanwhile, mAP was adopted for long-tailed object detection,
    instance segmentation and multi-label image classification, where the test set
    is usually not balanced.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 长尾学习旨在对具有长尾类别不平衡的数据训练出表现良好的模型。为了评估类别不平衡解决得如何，通常会报告模型在所有类别上的表现以及在类别子集（*即*，头部、中部和尾部类别）上的表现。请注意，评估指标应平等对待每个类别。遵循这一原则，top-1
    准确率或错误率通常用于平衡测试集，其中每个测试样本的重要性相同。当测试集不平衡时，通常采用平均精度（mAP）或宏观准确率，因为这两项指标对每个类别的处理是平等的。例如，在以前的研究中，top-1
    准确率或错误率被广泛用于长尾图像分类，其中测试集通常被假定为近似平衡。同时，mAP 被用于长尾目标检测、实例分割和多标签图像分类，其中测试集通常不平衡。
- en: 2.4 Applications
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 应用
- en: The main applications of deep long-tailed learning include image classification,
    detection segmentation, and visual relation learning.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 深度长尾学习的主要应用包括图像分类、检测分割和视觉关系学习。
- en: 'Image Classification. The most common applications of long-tailed learning
    are multi-class classification [[15](#bib.bib15), [32](#bib.bib32), [44](#bib.bib44),
    [45](#bib.bib45)] and multi-label classification [[37](#bib.bib37), [46](#bib.bib46)].
    As mentioned in Section [2.2](#S2.SS2 "2.2 Datasets ‣ 2 Problem Overview ‣ Deep
    Long-Tailed Learning: A Survey"), there are many artificially sampled long-tailed
    datasets from widely-used multi-class classification datasets (*i.e.,* ImageNet,
    CIFAR, and Places) and multi-label classification datasets (*i.e.,* VOC and COCO).
    Based on these datasets, various long-tailed learning methods have been proposed,
    as shown in Section [3](#S3 "3 Classic Methods ‣ Deep Long-Tailed Learning: A
    Survey"). Besides these artificial tasks, long-tailed learning is also applied
    to real-world applications, including species classification [[23](#bib.bib23),
    [24](#bib.bib24), [47](#bib.bib47)], face recognition [[21](#bib.bib21), [22](#bib.bib22),
    [48](#bib.bib48), [49](#bib.bib49)], face attribute classification [[50](#bib.bib50)],
    cloth attribute classification [[50](#bib.bib50)], age classification [[51](#bib.bib51)],
    rail surface defect detection [[52](#bib.bib52)], and medical image diagnosis [[25](#bib.bib25),
    [53](#bib.bib53)]. These real applications usually require more fine-grained discrimination
    abilities, since the differences among their classes are more subtle. Due to this
    new challenge, existing deep long-tailed learning methods tend to fail in these
    applications, since they only focus on addressing the class imbalance and cannot
    essentially identify subtle class differences. Therefore, when exploring new methods
    to handle these applications, it is worth considering how to tackle the challenges
    of class imbalance and fine-grained information identification, simultaneously.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类。长尾学习的最常见应用是多类分类[[15](#bib.bib15), [32](#bib.bib32), [44](#bib.bib44), [45](#bib.bib45)]和多标签分类[[37](#bib.bib37),
    [46](#bib.bib46)]。如第[2.2节](#S2.SS2 "2.2 数据集 ‣ 2 问题概述 ‣ 深度长尾学习：综述")所述，许多人造采样的长尾数据集来自广泛使用的多类分类数据集（*即，*
    ImageNet、CIFAR 和 Places）和多标签分类数据集（*即，* VOC 和 COCO）。基于这些数据集，已经提出了各种长尾学习方法，如第[3节](#S3
    "3 经典方法 ‣ 深度长尾学习：综述")所示。除了这些人工任务，长尾学习还应用于真实世界的应用，包括物种分类[[23](#bib.bib23), [24](#bib.bib24),
    [47](#bib.bib47)]、面部识别[[21](#bib.bib21), [22](#bib.bib22), [48](#bib.bib48), [49](#bib.bib49)]、面部属性分类[[50](#bib.bib50)]、服装属性分类[[50](#bib.bib50)]、年龄分类[[51](#bib.bib51)]、轨道表面缺陷检测[[52](#bib.bib52)]和医学图像诊断[[25](#bib.bib25),
    [53](#bib.bib53)]。这些真实应用通常需要更细致的辨别能力，因为它们的类别之间的差异更加微妙。由于这一新的挑战，现有的深度长尾学习方法在这些应用中往往会失败，因为它们只关注解决类别不平衡问题，无法实质性地识别微妙的类别差异。因此，在探索新方法以应对这些应用时，值得考虑如何同时解决类别不平衡和细粒度信息识别的挑战。
- en: Image Detection / Segmentation. Object detection and instance segmentation has
    attracted increasing attention in the long-tailed learning community [[54](#bib.bib54),
    [55](#bib.bib55), [56](#bib.bib56), [57](#bib.bib57), [58](#bib.bib58), [59](#bib.bib59)],
    where most existing studies are conducted based on LVIS and COCO. In addition
    to these widely-used benchmarks, many other applications have also been explored,
    including urban scene understanding [[26](#bib.bib26), [60](#bib.bib60)] and unmanned
    aerial vehicle detection [[27](#bib.bib27)]. Compared to artificial tasks on LVIS
    and COCO, these real applications are more challenging due to more complex environments
    in the wild. For example, the images may be collected from different weather conditions
    or different times in a day, which may lead to multiple image domains with different
    data distributions and inconsistent class skewness. When facing these new challenges,
    existing deep long-tailed learning methods tend to fail. Hence, it is worth exploring
    how to simultaneously resolve the challenges of class imbalance and domain shifts
    for handling these applications.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图像检测/分割。目标检测和实例分割在长尾学习社区中引起了越来越多的关注[[54](#bib.bib54), [55](#bib.bib55), [56](#bib.bib56),
    [57](#bib.bib57), [58](#bib.bib58), [59](#bib.bib59)]，大多数现有研究基于LVIS和COCO进行。除了这些广泛使用的基准外，还探索了许多其他应用，包括城市场景理解[[26](#bib.bib26),
    [60](#bib.bib60)]和无人机检测[[27](#bib.bib27)]。与LVIS和COCO上的人工任务相比，这些真实应用由于复杂的环境条件更具挑战性。例如，图像可能来自不同的天气条件或一天中的不同时间，这可能导致具有不同数据分布和不一致类别偏斜的多个图像领域。在面对这些新挑战时，现有的深度长尾学习方法往往会失败。因此，值得探索如何同时解决类别不平衡和领域迁移的挑战，以应对这些应用。
- en: Visual Relation Learning. Visual relation learning is important for image understanding
    and is attracting rising attention in the long-tailed learning community. Important
    applications include long-tailed scene graph generation [[61](#bib.bib61), [62](#bib.bib62)],
    long-tailed visual question answering and image captioning [[63](#bib.bib63),
    [64](#bib.bib64)]. Most existing long-tailed studies focus on discriminative tasks,
    so they cannot be applied to the aforementioned applications that require modeling
    relations between objects or those between images and texts. Even so, it is interesting
    to explore the high-level ideas (*e.g.,* class re-balancing) in existing long-tailed
    studies to design application-customized approaches for visual relation learning.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉关系学习。视觉关系学习对图像理解非常重要，并且在长尾学习社区中越来越受到关注。重要的应用包括长尾场景图生成[[61](#bib.bib61), [62](#bib.bib62)]、长尾视觉问答和图像描述[[63](#bib.bib63),
    [64](#bib.bib64)]。目前大多数现有的长尾研究集中在区分性任务上，因此无法应用于需要建模对象之间或图像与文本之间关系的上述应用。即便如此，探索现有长尾研究中的高级理念（*例如*，类别重新平衡）以设计针对视觉关系学习的定制方法仍然是有趣的。
- en: 2.5 Relationships with Related Tasks
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5 与相关任务的关系
- en: We then briefly discuss several related tasks, including non-deep long-tailed
    learning, class-imbalanced learning, few-shot learning, and out-of-domain generalization.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们简要讨论几个相关任务，包括非深度长尾学习、类别不平衡学习、少样本学习和领域外泛化。
- en: Non-deep long-tailed learning. There are a lot of non-deep learning approaches
    for long-tailed problems [[65](#bib.bib65), [66](#bib.bib66), [67](#bib.bib67)].
    They usually explore prior knowledge to enhance classic machine learning algorithms
    for handling the long-tailed problem. For example, the prior of similarity among
    categories is used to regularize kernel machine algorithm for long-tailed object
    recognition [[65](#bib.bib65)]. Moreover, the prior of a long-tailed power-law
    distribution produced by the Pitman-Yor Processes (PYP) method [[68](#bib.bib68)]
    is applied to enhance the Bayesian non-parametric framework for long-tailed active
    learning [[66](#bib.bib66)]. An artificial distribution prior is adopted to construct
    tail-class data augmentation to enhance KNN and SVM for long-tailed scene parsing [[67](#bib.bib67)].
    Almost all these approaches extract image features based on Scale Invariant Feature
    Transform (SIFT) [[69](#bib.bib69)], Histogram of Gradient Orientation (HOG) [[70](#bib.bib70)],
    or RGB color histogram [[71](#bib.bib71)]. Such representation approaches, however,
    cannot extract highly informative and discriminative features for real visual
    applications [[1](#bib.bib1)] and thus lead to limited performance in long-tailed
    learning. Recently, in light of the powerful abilities of deep networks for image
    representation, deep long-tailed methods have achieved significant performance
    improvement for long-tailed learning. More encouragingly, the use of deep networks
    also inspires plenty of new solution paradigms for long-tailed learning, such
    as transfer learning, decoupled training and ensemble learning, which will be
    introduced in the next section.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 非深度长尾学习。对于长尾问题，有许多非深度学习的方法[[65](#bib.bib65), [66](#bib.bib66), [67](#bib.bib67)]。它们通常通过探索先验知识来增强经典的机器学习算法，以处理长尾问题。例如，类别之间的相似性先验被用于正则化核机器算法，以进行长尾对象识别[[65](#bib.bib65)]。此外，由Pitman-Yor过程（PYP）方法[[68](#bib.bib68)]生成的长尾幂律分布先验被应用于增强贝叶斯非参数框架，以进行长尾主动学习[[66](#bib.bib66)]。一种人工分布先验被采用来构建尾部类别的数据增强，以增强KNN和SVM用于长尾场景解析[[67](#bib.bib67)]。几乎所有这些方法都基于尺度不变特征变换（SIFT）[[69](#bib.bib69)]、梯度方向直方图（HOG）[[70](#bib.bib70)]或RGB颜色直方图[[71](#bib.bib71)]提取图像特征。然而，这些表示方法无法为真实的视觉应用提取高度信息量和区分性的特征[[1](#bib.bib1)]，因此在长尾学习中表现有限。最近，鉴于深度网络在图像表示中的强大能力，深度长尾方法在长尾学习中取得了显著的性能提升。更令人鼓舞的是，深度网络的使用也激发了许多新的解决方案范式，如迁移学习、解耦训练和集成学习，这些将在下一节中介绍。
- en: Class-imbalanced learning [[72](#bib.bib72), [5](#bib.bib5)] also seeks to train
    models from class-imbalanced samples. In this sense, long-tailed learning can
    be regarded as a challenging sub-task of class-imbalanced learning. The dominant
    distinction is that the classes of long-tailed learning follow a *long-tailed
    class distribution*, which is not necessary for class-imbalanced learning. More
    differences include that in long-tailed learning the number of classes is usually
    large and the tail-class samples are often very scarce, whereas the number of
    minority-class samples in class-imbalanced learning is not necessarily small in
    an absolute sense. These extra challenges lead long-tailed learning to be a more
    challenging task than class-imbalanced learning. Despite these differences, both
    seek to resolve the class imbalance, so some high-level solution ideas (*e.g.,*
    class re-balancing) are shared between them.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**类别不平衡学习** [[72](#bib.bib72), [5](#bib.bib5)] 也旨在从类别不平衡的样本中训练模型。从这个意义上讲，长尾学习可以被看作是类别不平衡学习中的一个具有挑战性的子任务。主要的区别在于，长尾学习的类别遵循*长尾分布*，而类别不平衡学习并不一定需要这种分布。更多的区别包括，在长尾学习中类别的数量通常很大，而尾类样本通常非常稀少，而在类别不平衡学习中，少数类样本的数量并不一定是绝对小的。这些额外的挑战使得长尾学习比类别不平衡学习更具挑战性。尽管存在这些差异，但两者都致力于解决类别不平衡问题，因此它们之间有一些高级解决方案的想法（比如，类别重新平衡）是共享的。'
- en: Few-shot learning [[73](#bib.bib73), [74](#bib.bib74), [75](#bib.bib75), [76](#bib.bib76)]
    aims to train models from a limited number of labeled samples (*e.g.,* 1 or 5)
    per class. In this regard, few-shot learning can be regarded as a sub-task of
    long-tailed learning, in which the tail classes generally have a very small number
    of samples.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**小样本学习** [[73](#bib.bib73), [74](#bib.bib74), [75](#bib.bib75), [76](#bib.bib76)]
    旨在从有限数量的标记样本（例如，1或5个）中训练模型。在这个意义上，小样本学习可以被看作是长尾学习的一个子任务，在这个任务中，尾部类通常具有非常少的样本。'
- en: Out-of-domain Generalization [[77](#bib.bib77), [78](#bib.bib78)] indicates
    a class of tasks, in which the training distribution is inconsistent with the
    unknown test distribution. Such inconsistency includes inconsistent data marginal
    distributions (e.g., domain adaptation [[79](#bib.bib79), [80](#bib.bib80), [81](#bib.bib81),
    [82](#bib.bib82), [83](#bib.bib83), [84](#bib.bib84)] and domain generalization [[85](#bib.bib85),
    [86](#bib.bib86)]), inconsistent class distributions (e.g., long-tailed learning [[15](#bib.bib15),
    [32](#bib.bib32), [28](#bib.bib28)], open-set learning [[87](#bib.bib87), [88](#bib.bib88)]),
    and the combination of the previous two situations. From this perspective, long-tailed
    learning can be viewed as a specific task within out-of-domain generalization.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**领域外泛化** [[77](#bib.bib77), [78](#bib.bib78)] 指的是一类任务，其中训练分布与未知的测试分布不一致。这种不一致包括数据边际分布不一致（例如，领域自适应
    [[79](#bib.bib79), [80](#bib.bib80), [81](#bib.bib81), [82](#bib.bib82), [83](#bib.bib83),
    [84](#bib.bib84)] 和领域泛化 [[85](#bib.bib85), [86](#bib.bib86)]），类别分布不一致（例如，长尾学习
    [[15](#bib.bib15), [32](#bib.bib32), [28](#bib.bib28)]，开放集学习 [[87](#bib.bib87),
    [88](#bib.bib88)]），以及前两种情况的组合。从这个角度来看，长尾学习可以被视为领域外泛化中的一个具体任务。'
- en: 'TABLE II: Summary of existing deep long-tailed learning methods published in
    the top-tier conferences before mid-2021\. There are three main categories: class
    re-balancing, information augmentation and module improvement. In this table,
    “CSL” indicates class-sensitive learning; “LA” indicates logit adjustment; “TL”
    represents transfer learning; “Aug” indicates data augmentation; “RL” indicates
    representation learning; “CD” indicates classifier design, which seeks to design
    new classifiers or prediction schemes for long-tailed recognition; “DT” indicates
    decoupled training, where the feature extractor and the classifier are trained
    separately; “Ensemble” indicates ensemble learning based methods. In addition,
    “Target Aspect” indicates from which aspect an approach seeks to resolve the class
    imbalance. We also make our codebase and our collected long-tailed learning resources
    available at [https://github.com/Vanint/Awesome-LongTailed-Learning](https://github.com/Vanint/Awesome-LongTailed-Learning).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：总结了2021年中期之前在顶级会议上发布的现有深度长尾学习方法。主要分为三大类：类别重平衡、信息增强和模块改进。在此表中，“CSL”表示类敏感学习；“LA”表示逻辑调整；“TL”代表迁移学习；“Aug”表示数据增强；“RL”表示表示学习；“CD”表示分类器设计，旨在为长尾识别设计新的分类器或预测方案；“DT”表示解耦训练，其中特征提取器和分类器分别训练；“Ensemble”表示集成学习方法。此外，“目标方面”表示方法试图从哪个方面解决类别不平衡。我们还在[https://github.com/Vanint/Awesome-LongTailed-Learning](https://github.com/Vanint/Awesome-LongTailed-Learning)提供了我们的代码库和收集的长尾学习资源。
- en: '| Method | Year | Class Re-balancing |  | Augmentation |  | Module Improvement
    | Target Aspect |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 年份 | 类别重平衡 |  | 增强 |  | 模块改进 | 目标方面 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Re-sampling | CSL | LA |  | TL | Aug |  | RL | CD | DT | Ensemble |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 重新采样 | CSL | LA |  | TL | Aug |  | RL | CD | DT | 集成 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| LMLE [[89](#bib.bib89)] | 2016 |  |  |  |  |  |  |  | ✓ |  |  |  | feature
    |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| LMLE [[89](#bib.bib89)] | 2016 |  |  |  |  |  |  |  | ✓ |  |  |  | 特征 |'
- en: '| HFL [[90](#bib.bib90)] | 2016 |  |  |  |  |  |  |  | ✓ |  |  |  | feature
    |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| HFL [[90](#bib.bib90)] | 2016 |  |  |  |  |  |  |  | ✓ |  |  |  | 特征 |'
- en: '| Focal loss [[54](#bib.bib54)] | 2017 |  | ✓ |  |  |  |  |  |  |  |  |  |
    objective |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 焦点损失 [[54](#bib.bib54)] | 2017 |  | ✓ |  |  |  |  |  |  |  |  |  | 目标 |'
- en: '| Range loss [[21](#bib.bib21)] | 2017 |  |  |  |  |  |  |  | ✓ |  |  |  |
    feature |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 范围损失 [[21](#bib.bib21)] | 2017 |  |  |  |  |  |  |  | ✓ |  |  |  | 特征 |'
- en: '| CRL [[50](#bib.bib50)] | 2017 |  |  |  |  |  |  |  | ✓ |  |  |  | feature
    |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| CRL [[50](#bib.bib50)] | 2017 |  |  |  |  |  |  |  | ✓ |  |  |  | 特征 |'
- en: '| MetaModelNet [[91](#bib.bib91)] | 2017 |  |  |  |  | ✓ |  |  |  |  |  |  |  |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| MetaModelNet [[91](#bib.bib91)] | 2017 |  |  |  |  | ✓ |  |  |  |  |  |  |  |'
- en: '| DSTL [[92](#bib.bib92)] | 2018 |  |  |  |  | ✓ |  |  |  |  |  |  |  |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| DSTL [[92](#bib.bib92)] | 2018 |  |  |  |  | ✓ |  |  |  |  |  |  |  |'
- en: '| DCL [[93](#bib.bib93)] | 2019 | ✓ |  |  |  |  |  |  |  |  |  |  | sample
    |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| DCL [[93](#bib.bib93)] | 2019 | ✓ |  |  |  |  |  |  |  |  |  |  | 样本 |'
- en: '| Meta-Weight-Net [[94](#bib.bib94)] | 2019 |  | ✓ |  |  |  |  |  |  |  |  |  |
    objective |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| Meta-Weight-Net [[94](#bib.bib94)] | 2019 |  | ✓ |  |  |  |  |  |  |  |  |  |
    目标 |'
- en: '| LDAM [[18](#bib.bib18)] | 2019 |  | ✓ |  |  |  |  |  |  |  |  |  | objective
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| LDAM [[18](#bib.bib18)] | 2019 |  | ✓ |  |  |  |  |  |  |  |  |  | 目标 |'
- en: '| CB [[16](#bib.bib16)] | 2019 |  | ✓ |  |  |  |  |  |  |  |  |  | objective
    |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| CB [[16](#bib.bib16)] | 2019 |  | ✓ |  |  |  |  |  |  |  |  |  | 目标 |'
- en: '| UML [[95](#bib.bib95)] | 2019 |  | ✓ |  |  |  |  |  |  |  |  |  | feature
    |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| UML [[95](#bib.bib95)] | 2019 |  | ✓ |  |  |  |  |  |  |  |  |  | 特征 |'
- en: '| FTL [[96](#bib.bib96)] | 2019 |  |  |  |  | ✓ | ✓ |  |  |  |  |  | feature
    |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| FTL [[96](#bib.bib96)] | 2019 |  |  |  |  | ✓ | ✓ |  |  |  |  |  | 特征 |'
- en: '| Unequal-training [[48](#bib.bib48)] | 2019 |  |  |  |  |  |  |  | ✓ |  |  |  |
    feature |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 不平等训练 [[48](#bib.bib48)] | 2019 |  |  |  |  |  |  |  | ✓ |  |  |  | 特征 |'
- en: '| OLTR [[15](#bib.bib15)] | 2019 |  |  |  |  |  |  |  | ✓ |  |  |  | feature
    |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| OLTR [[15](#bib.bib15)] | 2019 |  |  |  |  |  |  |  | ✓ |  |  |  | 特征 |'
- en: '| Balanced Meta-Softmax [[97](#bib.bib97)] | 2020 | ✓ | ✓ |  |  |  |  |  |  |  |  |  |
    sample, objective |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 平衡Meta-Softmax [[97](#bib.bib97)] | 2020 | ✓ | ✓ |  |  |  |  |  |  |  |  |  |
    样本，目标 |'
- en: '| Decoupling [[32](#bib.bib32)] | 2020 | ✓ | ✓ |  |  |  |  |  | ✓ | ✓ | ✓ |  |
    feature, classifier |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 解耦 [[32](#bib.bib32)] | 2020 | ✓ | ✓ |  |  |  |  |  | ✓ | ✓ | ✓ |  | 特征，分类器
    |'
- en: '| LST [[98](#bib.bib98)] | 2020 | ✓ |  |  |  | ✓ |  |  |  |  |  |  | sample
    |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| LST [[98](#bib.bib98)] | 2020 | ✓ |  |  |  | ✓ |  |  |  |  |  |  | 样本 |'
- en: '| Domain adaptation [[28](#bib.bib28)] | 2020 |  | ✓ |  |  |  |  |  |  |  |  |  |
    objective |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 领域适应 [[28](#bib.bib28)] | 2020 |  | ✓ |  |  |  |  |  |  |  |  |  | 目标 |'
- en: '| Equalization loss (ESQL) [[19](#bib.bib19)] | 2020 |  | ✓ |  |  |  |  |  |  |  |  |  |
    objective |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 等式损失 (ESQL) [[19](#bib.bib19)] | 2020 |  | ✓ |  |  |  |  |  |  |  |  |  |
    目标 |'
- en: '| DBM [[22](#bib.bib22)] | 2020 |  | ✓ |  |  |  |  |  |  |  |  |  | objective
    |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| DBM [[22](#bib.bib22)] | 2020 |  | ✓ |  |  |  |  |  |  |  |  |  | 目标 |'
- en: '| Distribution-balanced loss [[37](#bib.bib37)] | 2020 |  | ✓ |  |  |  |  |  |  |  |  |  |
    objective |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| Distribution-balanced loss [[37](#bib.bib37)] | 2020 |  | ✓ |  |  |  |  |  |  |  |  |  |
    目标 |'
- en: '| UNO-IC [[99](#bib.bib99)] | 2020 |  |  | ✓ |  |  |  |  |  |  |  |  | prediction
    |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| UNO-IC [[99](#bib.bib99)] | 2020 |  |  | ✓ |  |  |  |  |  |  |  |  | 预测 |'
- en: '| De-confound-TDE [[45](#bib.bib45)] | 2020 |  |  | ✓ |  |  |  |  |  | ✓ |  |  |
    prediction |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| De-confound-TDE [[45](#bib.bib45)] | 2020 |  |  | ✓ |  |  |  |  |  | ✓ |  |  |
    预测 |'
- en: '| M2m [[100](#bib.bib100)] | 2020 |  |  |  |  | ✓ | ✓ |  |  |  |  |  | sample
    |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| M2m [[100](#bib.bib100)] | 2020 |  |  |  |  | ✓ | ✓ |  |  |  |  |  | 样本 |'
- en: '| LEAP [[49](#bib.bib49)] | 2020 |  |  |  |  | ✓ | ✓ |  | ✓ |  |  |  | feature
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| LEAP [[49](#bib.bib49)] | 2020 |  |  |  |  | ✓ | ✓ |  | ✓ |  |  |  | 特征 |'
- en: '| OFA [[101](#bib.bib101)] | 2020 |  |  |  |  | ✓ | ✓ |  |  |  | ✓ |  | feature
    |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| OFA [[101](#bib.bib101)] | 2020 |  |  |  |  | ✓ | ✓ |  |  |  | ✓ |  | 特征
    |'
- en: '| SSP [[102](#bib.bib102)] | 2020 |  |  |  |  | ✓ |  |  | ✓ |  |  |  | feature
    |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| SSP [[102](#bib.bib102)] | 2020 |  |  |  |  | ✓ |  |  | ✓ |  |  |  | 特征 |'
- en: '| LFME [[103](#bib.bib103)] | 2020 |  |  |  |  | ✓ |  |  |  |  |  | ✓ | sample,
    model |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| LFME [[103](#bib.bib103)] | 2020 |  |  |  |  | ✓ |  |  |  |  |  | ✓ | 样本，模型
    |'
- en: '| IEM [[104](#bib.bib104)] | 2020 |  |  |  |  |  |  |  | ✓ |  |  |  | feature
    |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| IEM [[104](#bib.bib104)] | 2020 |  |  |  |  |  |  |  | ✓ |  |  |  | 特征 |'
- en: '| Deep-RTC [[105](#bib.bib105)] | 2020 |  |  |  |  |  |  |  |  | ✓ |  |  |
    classifier |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| Deep-RTC [[105](#bib.bib105)] | 2020 |  |  |  |  |  |  |  |  | ✓ |  |  |
    分类器 |'
- en: '| SimCal [[34](#bib.bib34)] | 2020 |  |  |  |  |  |  |  |  |  | ✓ | ✓ | sample,
    model |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| SimCal [[34](#bib.bib34)] | 2020 |  |  |  |  |  |  |  |  |  | ✓ | ✓ | 样本，模型
    |'
- en: '| BBN [[44](#bib.bib44)] | 2020 |  |  |  |  |  |  |  |  |  |  | ✓ | sample,
    model |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| BBN [[44](#bib.bib44)] | 2020 |  |  |  |  |  |  |  |  |  |  | ✓ | 样本，模型 |'
- en: '| BAGS [[56](#bib.bib56)] | 2020 |  |  |  |  |  |  |  |  |  |  | ✓ | sample,
    model |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| BAGS [[56](#bib.bib56)] | 2020 |  |  |  |  |  |  |  |  |  |  | ✓ | 样本，模型
    |'
- en: '| VideoLT [[38](#bib.bib38)] | 2021 | ✓ |  |  |  |  |  |  |  |  |  |  | sample
    |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| VideoLT [[38](#bib.bib38)] | 2021 | ✓ |  |  |  |  |  |  |  |  |  |  | 样本
    |'
- en: '| LOCE [[33](#bib.bib33)] | 2021 | ✓ | ✓ |  |  |  |  |  |  |  |  |  | sample,
    objective |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| LOCE [[33](#bib.bib33)] | 2021 | ✓ | ✓ |  |  |  |  |  |  |  |  |  | 样本，目标
    |'
- en: '| DARS [[26](#bib.bib26)] | 2021 | ✓ | ✓ |  |  | ✓ |  |  |  |  |  |  | sample,
    objective |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| DARS [[26](#bib.bib26)] | 2021 | ✓ | ✓ |  |  | ✓ |  |  |  |  |  |  | 样本，目标
    |'
- en: '| CReST [[106](#bib.bib106)] | 2021 | ✓ |  |  |  | ✓ |  |  |  |  |  |  | sample
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| CReST [[106](#bib.bib106)] | 2021 | ✓ |  |  |  | ✓ |  |  |  |  |  |  | 样本
    |'
- en: '| GIST [[107](#bib.bib107)] | 2021 | ✓ |  |  |  | ✓ |  |  |  | ✓ |  |  | classifier
    |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| GIST [[107](#bib.bib107)] | 2021 | ✓ |  |  |  | ✓ |  |  |  | ✓ |  |  | 分类器
    |'
- en: '| FASA [[58](#bib.bib58)] | 2021 | ✓ |  |  |  |  | ✓ |  |  |  |  |  | feature
    |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| FASA [[58](#bib.bib58)] | 2021 | ✓ |  |  |  |  | ✓ |  |  |  |  |  | 特征 |'
- en: '| Equalization loss v2 [[108](#bib.bib108)] | 2021 |  | ✓ |  |  |  |  |  |  |  |  |  |
    objective |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| Equalization loss v2 [[108](#bib.bib108)] | 2021 |  | ✓ |  |  |  |  |  |  |  |  |  |
    目标 |'
- en: '| Seesaw loss [[109](#bib.bib109)] | 2021 |  | ✓ |  |  |  |  |  |  |  |  |  |
    objective |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Seesaw loss [[109](#bib.bib109)] | 2021 |  | ✓ |  |  |  |  |  |  |  |  |  |
    目标 |'
- en: '| ACSL [[110](#bib.bib110)] | 2021 |  | ✓ |  |  |  |  |  |  |  |  |  | objective
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| ACSL [[110](#bib.bib110)] | 2021 |  | ✓ |  |  |  |  |  |  |  |  |  | 目标 |'
- en: '| IB [[111](#bib.bib111)] | 2021 |  | ✓ |  |  |  |  |  |  |  |  |  | objective
    |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| IB [[111](#bib.bib111)] | 2021 |  | ✓ |  |  |  |  |  |  |  |  |  | 目标 |'
- en: '| PML [[51](#bib.bib51)] | 2021 |  | ✓ |  |  |  |  |  |  |  |  |  | objective
    |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| PML [[51](#bib.bib51)] | 2021 |  | ✓ |  |  |  |  |  |  |  |  |  | 目标 |'
- en: '| VS [[112](#bib.bib112)] | 2021 |  | ✓ |  |  |  |  |  |  |  |  |  | objective
    |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| VS [[112](#bib.bib112)] | 2021 |  | ✓ |  |  |  |  |  |  |  |  |  | 目标 |'
- en: '| LADE [[31](#bib.bib31)] | 2021 |  | ✓ | ✓ |  |  |  |  |  |  |  |  | objective,
    prediction |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| LADE [[31](#bib.bib31)] | 2021 |  | ✓ | ✓ |  |  |  |  |  |  |  |  | 目标，预测
    |'
- en: '| RoBal [[113](#bib.bib113)] | 2021 |  | ✓ | ✓ |  |  |  |  |  | ✓ |  |  | objective,
    prediction |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| RoBal [[113](#bib.bib113)] | 2021 |  | ✓ | ✓ |  |  |  |  |  | ✓ |  |  | 目标，预测
    |'
- en: '| DisAlign [[29](#bib.bib29)] | 2021 |  | ✓ | ✓ |  |  |  |  |  |  | ✓ |  |
    objective, classifier |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| DisAlign [[29](#bib.bib29)] | 2021 |  | ✓ | ✓ |  |  |  |  |  |  | ✓ |  |
    目标，分类器 |'
- en: '| MiSLAS [[114](#bib.bib114)] | 2021 |  | ✓ |  |  |  | ✓ |  |  |  | ✓ |  |
    objective, feature, classifier |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| MiSLAS [[114](#bib.bib114)] | 2021 |  | ✓ |  |  |  | ✓ |  |  |  | ✓ |  |
    目标，特征，分类器 |'
- en: '| Logit adjustment [[14](#bib.bib14)] | 2021 |  |  | ✓ |  |  |  |  |  |  |  |  |
    prediction |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| Logit adjustment [[14](#bib.bib14)] | 2021 |  |  | ✓ |  |  |  |  |  |  |  |  |
    预测 |'
- en: '| Conceptual 12M [[115](#bib.bib115)] | 2021 |  |  |  |  | ✓ |  |  |  |  |  |  |  |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| Conceptual 12M [[115](#bib.bib115)] | 2021 |  |  |  |  | ✓ |  |  |  |  |  |  |  |'
- en: '| DiVE [[116](#bib.bib116)] | 2021 |  |  |  |  | ✓ |  |  |  |  |  |  |  |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| DiVE [[116](#bib.bib116)] | 2021 |  |  |  |  | ✓ |  |  |  |  |  |  |  |'
- en: '| MosaicOS [[117](#bib.bib117)] | 2021 |  |  |  |  | ✓ |  |  |  |  |  |  |  |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| MosaicOS [[117](#bib.bib117)] | 2021 |  |  |  |  | ✓ |  |  |  |  |  |  |  |'
- en: '| RSG [[118](#bib.bib118)] | 2021 |  |  |  |  | ✓ | ✓ |  |  |  |  |  | feature
    |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| RSG [[118](#bib.bib118)] | 2021 |  |  |  |  | ✓ | ✓ |  |  |  |  |  | 特征 |'
- en: '| SSD [[119](#bib.bib119)] | 2021 |  |  |  |  | ✓ |  |  |  |  | ✓ |  |  |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| SSD [[119](#bib.bib119)] | 2021 |  |  |  |  | ✓ |  |  |  |  | ✓ |  |  |'
- en: '| RIDE [[17](#bib.bib17)] | 2021 |  |  |  |  | ✓ |  |  |  |  |  | ✓ | model
    |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| RIDE [[17](#bib.bib17)] | 2021 |  |  |  |  | ✓ |  |  |  |  |  | ✓ | 模型 |'
- en: '| MetaSAug [[120](#bib.bib120)] | 2021 |  |  |  |  |  | ✓ |  |  |  |  |  |
    sample |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| MetaSAug [[120](#bib.bib120)] | 2021 |  |  |  |  |  | ✓ |  |  |  |  |  |
    样本 |'
- en: '| PaCo [[121](#bib.bib121)] | 2021 |  |  |  |  |  |  |  | ✓ |  |  |  | feature
    |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| PaCo [[121](#bib.bib121)] | 2021 |  |  |  |  |  |  |  | ✓ |  |  |  | 特征 |'
- en: '| DRO-LT [[122](#bib.bib122)] | 2021 |  |  |  |  |  |  |  | ✓ |  |  |  | feature
    |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| DRO-LT [[122](#bib.bib122)] | 2021 |  |  |  |  |  |  |  | ✓ |  |  |  | 特征
    |'
- en: '| Unsupervised discovery [[35](#bib.bib35)] | 2021 |  |  |  |  |  |  |  | ✓
    |  |  |  | feature |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| Unsupervised discovery [[35](#bib.bib35)] | 2021 |  |  |  |  |  |  |  | ✓
    |  |  |  | 特征 |'
- en: '| Hybrid [[123](#bib.bib123)] | 2021 |  |  |  |  |  |  |  | ✓ |  |  |  | feature
    |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| Hybrid [[123](#bib.bib123)] | 2021 |  |  |  |  |  |  |  | ✓ |  |  |  | 特征
    |'
- en: '| KCL [[13](#bib.bib13)] | 2021 |  |  |  |  |  |  |  | ✓ |  | ✓ |  | feature
    |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| KCL [[13](#bib.bib13)] | 2021 |  |  |  |  |  |  |  | ✓ |  | ✓ |  | 特征 |'
- en: '| DT2 [[61](#bib.bib61)] | 2021 |  |  |  |  |  |  |  |  |  | ✓ |  | feature,
    classifier |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| DT2 [[61](#bib.bib61)] | 2021 |  |  |  |  |  |  |  |  |  | ✓ |  | 特征，分类器
    |'
- en: '| LTML [[46](#bib.bib46)] | 2021 |  |  |  |  |  |  |  |  |  |  | ✓ | sample,
    model |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| LTML [[46](#bib.bib46)] | 2021 |  |  |  |  |  |  |  |  |  |  | ✓ | 样本，模型
    |'
- en: '| ACE [[124](#bib.bib124)] | 2021 |  |  |  |  |  |  |  |  |  |  | ✓ | sample,
    model |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| ACE [[124](#bib.bib124)] | 2021 |  |  |  |  |  |  |  |  |  |  | ✓ | 样本，模型
    |'
- en: '| ResLT [[125](#bib.bib125)] | 2021 |  |  |  |  |  |  |  |  |  |  | ✓ | sample,
    model |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| ResLT [[125](#bib.bib125)] | 2021 |  |  |  |  |  |  |  |  |  |  | ✓ | 样本，模型
    |'
- en: '| SADE [[30](#bib.bib30)] | 2021 |  |  |  |  |  |  |  |  |  |  | ✓ | objective,
    model |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| SADE [[30](#bib.bib30)] | 2021 |  |  |  |  |  |  |  |  |  |  | ✓ | 目标，模型
    |'
- en: 3 Classic Methods
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 经典方法
- en: 'As shown in Fig. [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Deep Long-Tailed Learning:
    A Survey"), we divide existing deep long-tailed learning methods into three main
    categories according to their main technical characteristics, including class
    re-balancing, information augmentation, and module improvement. More specifically,
    class re-balancing consists of three sub-categories: re-sampling, class-sensitive
    learning (CSL), and logit adjustment (LA). Information augmentation comprises
    transfer learning (TL) and data augmentation (Aug). Module improvement includes
    representation learning (RL), classifier design (CD), decoupled training (DT)
    and ensemble learning (Ensemble). According to this taxonomy, we sort out existing
    methods in Table [II](#S2.T2 "TABLE II ‣ 2.5 Relationships with Related Tasks
    ‣ 2 Problem Overview ‣ Deep Long-Tailed Learning: A Survey") and review them in
    detail as follows.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [2](#S1.F2 "图 2 ‣ 1 介绍 ‣ 深度长尾学习：综述")所示，我们根据主要技术特征将现有的深度长尾学习方法分为三大类，包括类别重新平衡、信息增强和模块改进。更具体地，类别重新平衡包括三个子类别：重新采样、类别敏感学习（CSL）和对数调整（LA）。信息增强包括迁移学习（TL）和数据增强（Aug）。模块改进包括表示学习（RL）、分类器设计（CD）、解耦训练（DT）和集成学习（Ensemble）。根据这一分类法，我们在表 [II](#S2.T2
    "表 II ‣ 2.5 与相关任务的关系 ‣ 2 问题概述 ‣ 深度长尾学习：综述")中整理了现有的方法，并详细回顾如下。
- en: 3.1 Class Re-balancing
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 类别重新平衡
- en: 'Class re-balancing, a mainstream paradigm in long-tailed learning, seeks to
    re-balance the negative influence brought by the class imbalance in training sample
    numbers. This type of methods has three main sub-categories: re-sampling, class-sensitive
    learning, and logit adjustment. We begin with re-sampling based methods, followed
    by class-sensitive learning and logit adjustment.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 类别重新平衡是长尾学习中的一个主流范式，旨在重新平衡训练样本数量不平衡带来的负面影响。这类方法主要有三个子类别：重新采样、类别敏感学习和对数调整。我们从基于重新采样的方法开始，随后介绍类别敏感学习和对数调整。
- en: 3.1.1 Re-sampling
  id: totrans-138
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 重新采样
- en: Conventional training of deep networks is based on mini-batch gradient descent
    with random sampling, *i.e.,* each sample has an equal probability of being sampled.
    Such a sampling manner, however, ignores the imbalance issue in long-tailed learning,
    and naturally samples more head-class samples than tail-class samples in each
    sample mini-batch. This makes the resulting deep models biased towards head classes
    and perform poorly on tail classes. To address this issue, re-sampling [[126](#bib.bib126),
    [127](#bib.bib127), [128](#bib.bib128), [129](#bib.bib129)] has been explored
    to re-balance classes by adjusting the number of samples per class in each sample
    batch for model training.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的深度网络训练基于随机采样的迷你批次梯度下降，即每个样本被采样的概率相等。然而，这种采样方式忽略了长尾学习中的不平衡问题，自然会在每个样本迷你批次中采样更多的头部类样本而非尾部类样本。这使得最终的深度模型偏向于头部类，并在尾部类上的表现较差。为了解决这一问题，已经探索了通过调整每个样本批次中的每类样本数量来重新平衡类别的重采样方法
    [[126](#bib.bib126), [127](#bib.bib127), [128](#bib.bib128), [129](#bib.bib129)]。
- en: In the non-deep learning era, the most classic re-sampling approaches are random
    over-sampling (ROS) and random under-sampling (RUS). Specifically, ROS randomly
    repeats the samples from minority classes to re-balance classes before training,
    while RUS randomly discards the samples from majority classes. When applying them
    to deep long-tailed learning where the classes are highly skewed, ROS with duplicated
    tail-class data might lead to overfitting over tail classes, while RUS might discard
    precious head-class samples and degrade model performance on head classes [[44](#bib.bib44)].
    Instead of using random re-sampling, recent deep long-tailed studies have developed
    various class-balanced sampling methods for mini-batch training of deep models.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在非深度学习时代，最经典的重采样方法是随机过采样（ROS）和随机欠采样（RUS）。具体来说，ROS 随机重复少数类的样本以在训练前重新平衡各类，而 RUS
    则随机丢弃多数类的样本。当将这些方法应用于深度长尾学习中，类分布极其不均时，带有重复尾部类数据的 ROS 可能导致尾部类的过拟合，而 RUS 可能丢弃珍贵的头部类样本，从而降低模型在头部类上的表现[[44](#bib.bib44)]。最近的深度长尾研究开发了各种类别平衡采样方法，用于深度模型的迷你批次训练。
- en: We begin with Decoupling [[32](#bib.bib32)], in which four sampling strategies
    were evaluated for representation learning of long-tailed data, including random
    sampling, class-balanced sampling, square-root sampling and progressively-balanced
    sampling. Specifically, class-balanced sampling means that each class has an equal
    probability of being selected. Square-root sampling [[130](#bib.bib130)] is a
    variant of class-balanced sampling, where the sampling probability of each class
    is related to the square root of the sample size in the corresponding class. Progressively-balanced
    sampling [[32](#bib.bib32)] interpolates progressively between random and class-balanced
    sampling. Based on empirical results, Decoupling [[32](#bib.bib32)] found that
    square-root sampling and progressively-balanced sampling are better strategies
    for standard model training in long-tailed recognition. The two strategies, however,
    require knowing the training sample frequencies of different classes in advance,
    which may be unavailable in real applications.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 Decoupling [[32](#bib.bib32)] 开始，该方法评估了四种采样策略用于长尾数据的表示学习，包括随机采样、类别平衡采样、平方根采样和逐步平衡采样。具体来说，类别平衡采样意味着每个类别被选择的概率相等。平方根采样
    [[130](#bib.bib130)] 是类别平衡采样的变体，其中每个类别的采样概率与相应类别的样本数量的平方根有关。逐步平衡采样 [[32](#bib.bib32)]
    在随机采样和类别平衡采样之间逐步插值。基于实证结果，Decoupling [[32](#bib.bib32)] 发现平方根采样和逐步平衡采样是长尾识别中标准模型训练的更好策略。然而，这两种策略都需要事先知道不同类别的训练样本频率，这在实际应用中可能无法获得。
- en: To address the above issue, recent studies proposed various adaptive sampling
    strategies. Dynamic Curriculum Learning (DCL) [[93](#bib.bib93)] developed a new
    curriculum strategy to dynamically sample data for class re-balancing. The basic
    idea is that the more instances from one class are sampled as training proceeds,
    the lower probability of this class would be sampled in later stages. Following
    this idea, DCL first conducts random sampling to learn general representations,
    and then samples more tail-class instances based on the curriculum strategy to
    handle the imbalance. In addition to using the accumulated sampling times, Long-tailed
    Object Detector with Classification Equilibrium (LOCE) [[33](#bib.bib33)] proposed
    to monitor model training on different classes via the *mean classification prediction
    score* (*i.e.,* running prediction probability), and used this score to guide
    the sampling rates for different classes. Furthermore, VideoLT [[38](#bib.bib38)],
    focusing on long-tailed video recognition, introduced a new FrameStack method
    that dynamically adjusts the sampling rates of different classes based on *running
    model performance* during training, so that it can sample more video frames from
    tail classes (generally with lower running performance).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决上述问题，近期研究提出了各种自适应采样策略。动态课程学习（DCL）[[93](#bib.bib93)]开发了一种新的课程策略，以动态采样数据进行类别重新平衡。基本思路是随着训练的进行，越多的实例来自某一类别，该类别在后续阶段的采样概率就越低。基于这一思路，DCL首先进行随机采样以学习一般性表示，然后基于课程策略对尾部类别实例进行更多采样以处理不平衡问题。除了使用累积的采样次数外，带有分类平衡的长尾对象检测器（LOCE）[[33](#bib.bib33)]提出通过*均值分类预测分数*（*即*，运行预测概率）来监控不同类别上的模型训练，并使用该分数来指导不同类别的采样率。此外，VideoLT[[38](#bib.bib38)]专注于长尾视频识别，介绍了一种新的FrameStack方法，该方法基于训练过程中*运行模型性能*动态调整不同类别的采样率，从而能从尾部类别（通常运行性能较低）中采样更多视频帧。
- en: Besides using the statistics computed during model training, some re-sampling
    approaches resorted to meta learning [[131](#bib.bib131)]. Balanced Meta-softmax [[97](#bib.bib97)]
    developed a meta-learning-based sampling method to estimate the optimal sampling
    rates of different classes for long-tailed learning. Specifically, the developed
    meta learning method seeks to learn the best sample distribution parameter by
    optimizing the *model classification performance* on a balanced *meta* validation
    set. Similarly, Feature Augmentation and Sampling Adaptation (FASA) [[58](#bib.bib58)]
    explored the *model classification loss* on a balanced *meta* validation set as
    a score, which is used to adjust the sampling rate for different classes so that
    the under-represented tail classes can be sampled more.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用模型训练期间计算的统计数据外，一些重新采样方法还求助于元学习[[131](#bib.bib131)]。平衡元-软最大值（Balanced Meta-softmax）[[97](#bib.bib97)]开发了一种基于元学习的采样方法，以估计长尾学习中不同类别的最佳采样率。具体而言，开发的元学习方法通过优化*模型分类性能*在一个平衡的*元*验证集上来学习最佳样本分布参数。类似地，特征增强和采样适应（FASA）[[58](#bib.bib58)]探讨了在平衡的*元*验证集上的*模型分类损失*作为评分，并用此评分调整不同类别的采样率，以便更多地采样代表性不足的尾部类别。
- en: Note that some long-tailed visual tasks may have multiple levels of imbalance.
    For example, long-tailed instance segmentation is imbalanced in terms of both
    images and instances (*i.e.,* the number of instances per image is also imbalanced).
    To address this task, Simple Calibration (SimCal) [[34](#bib.bib34)] proposed
    a new bi-level class-balanced sampling strategy that combines image-level and
    instance-level re-sampling for class re-balancing.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，一些长尾视觉任务可能存在多级不平衡。例如，长尾实例分割在图像和实例层面上都是不平衡的（*即*，每图像的实例数量也不平衡）。为了解决这一任务，简单校准（SimCal）[[34](#bib.bib34)]提出了一种新的双层类别平衡采样策略，该策略结合了图像级和实例级的重新采样进行类别重新平衡。
- en: Discussions. Re-sampling methods seek to address the class imbalance issue at
    the sample level. When the label frequencies of different classes are known a
    priori, progressively-balanced sampling [[32](#bib.bib32)] is recommended. Otherwise,
    using the statistics of model training to guide re-sampling [[33](#bib.bib33)]
    is a preferred solution for real applications. For meta-learning-based re-sampling,
    it may be difficult to construct a meta validation set in real scenarios. Note
    that if one re-sampling strategy has already addressed class imbalance well, further
    using other re-sampling methods may not bring extra benefits. Moreover, the high-level
    ideas of these re-sampling methods can be applied to design multi-level re-sampling
    strategies if there are multiple levels of imbalance in real applications.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论。重新采样方法旨在在样本级别解决类别不平衡问题。当不同类别的标签频率已知时，建议使用逐步平衡采样 [[32](#bib.bib32)]。否则，使用模型训练的统计数据来指导重新采样
    [[33](#bib.bib33)] 是实际应用中的首选方案。对于基于元学习的重新采样，在实际场景中可能很难构建元验证集。请注意，如果某种重新采样策略已经很好地解决了类别不平衡问题，进一步使用其他重新采样方法可能不会带来额外的好处。此外，这些重新采样方法的高级思想可以应用于设计多级重新采样策略，如果实际应用中存在多个不平衡级别。
- en: 3.1.2 Class-sensitive Learning
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 类别敏感学习
- en: 'Conventional training of deep networks is based on the softmax cross-entropy
    loss (c.f. Table [III](#S3.T3 "TABLE III ‣ 3.1.2 Class-sensitive Learning ‣ 3.1
    Class Re-balancing ‣ 3 Classic Methods ‣ Deep Long-Tailed Learning: A Survey")).
    This loss ignores the class imbalance in data sizes and tends to generate uneven
    gradients for different classes. That is, each positive sample of one class can
    be seen as a negative sample for other classes in cross-entropy, which leads head
    classes to receive more supporting gradients (as they usually are positive samples)
    and causes tail classes to receive more suppressed gradients (as they usually
    are negative samples)  [[19](#bib.bib19), [55](#bib.bib55)]. To address this,
    class-sensitive learning seeks to particularly adjust the training loss values
    for various classes to re-balance the uneven training effects caused by the imbalance
    issue [[132](#bib.bib132), [133](#bib.bib133), [134](#bib.bib134), [135](#bib.bib135),
    [136](#bib.bib136), [137](#bib.bib137)]. There are two main types of class-sensitive
    strategies, *i.e.,* re-weighting and re-margining. We begin with class re-weighting
    as follows.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '深度网络的传统训练方法基于 softmax 交叉熵损失（参见表 [III](#S3.T3 "TABLE III ‣ 3.1.2 Class-sensitive
    Learning ‣ 3.1 Class Re-balancing ‣ 3 Classic Methods ‣ Deep Long-Tailed Learning:
    A Survey")）。这种损失忽略了数据规模的类别不平衡，往往会导致不同类别的梯度不均匀。也就是说，一个类别的每个正样本在交叉熵中可以被视为其他类别的负样本，这使得头部类别获得更多支持梯度（因为它们通常是正样本），而尾部类别获得更多压制梯度（因为它们通常是负样本）
    [[19](#bib.bib19), [55](#bib.bib55)]。为了解决这个问题，类别敏感学习寻求特别调整不同类别的训练损失值，以重新平衡由于不平衡问题造成的不均匀训练效果
    [[132](#bib.bib132), [133](#bib.bib133), [134](#bib.bib134), [135](#bib.bib135),
    [136](#bib.bib136), [137](#bib.bib137)]。类别敏感策略主要有两种类型，即重新加权和重新调整边距。我们首先讨论类别重新加权。'
- en: 'TABLE III: Summary of losses. In this table, $z$ and $p$ indicate the predicted
    logits and the softmax probability of the sample $x$, where $z_{y}$ and $p_{y}$
    correspond to the class $y$. Moreover, $n$ indicates the total number of training
    data, where $n_{y}$ is the sample number of the class $y$. In addition, $\pi$
    denotes the vector of sample frequencies, where $\pi_{y}\small{=}n_{y}/n$ represents
    the label frequency of the class $y$. The class-wise weight is denoted by $\omega$
    and the class-wise margin is denoted by $\Delta$, if no more specific value is
    given. Loss-related parameters include $\gamma$.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 表 III：损失汇总。在此表中，$z$ 和 $p$ 表示样本 $x$ 的预测 logits 和 softmax 概率，其中 $z_{y}$ 和 $p_{y}$
    对应于类别 $y$。此外，$n$ 表示训练数据的总数，其中 $n_{y}$ 是类别 $y$ 的样本数。此外，$\pi$ 表示样本频率的向量，其中 $\pi_{y}\small{=}n_{y}/n$
    代表类别 $y$ 的标签频率。类别权重用 $\omega$ 表示，类别边距用 $\Delta$ 表示，如果没有给出更具体的值。损失相关参数包括 $\gamma$。
- en: '| Loss | Formulation | Type |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 损失 | 公式 | 类型 |'
- en: '| --- | --- | --- |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Softmax loss | ${\mathcal{L}_{\rm ce}}=-\log(p_{y})$ | - |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| Softmax 损失 | ${\mathcal{L}_{\rm ce}}=-\log(p_{y})$ | - |'
- en: '| Focal loss [[54](#bib.bib54)] | ${\mathcal{L}_{\rm fl}}=-(1-p_{y})^{\gamma}\log(p_{y})$
    | re-weighting |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| Focal loss [[54](#bib.bib54)] | ${\mathcal{L}_{\rm fl}}=-(1-p_{y})^{\gamma}\log(p_{y})$
    | 重新加权 |'
- en: '| Weighted Softmax loss | ${\mathcal{L}_{\rm wce}}=-\frac{1}{\pi_{y}}\log(p_{y})$
    | re-weighting |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 加权 Softmax 损失 | ${\mathcal{L}_{\rm wce}}=-\frac{1}{\pi_{y}}\log(p_{y})$ |
    重新加权 |'
- en: '| Class-balanced loss [[16](#bib.bib16)] | ${\mathcal{L}_{\rm cb}}=-\frac{1-\gamma}{1-\gamma^{n_{y}}}\log(p_{y})$
    | re-weighting |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 类别平衡损失 [[16](#bib.bib16)] | ${\mathcal{L}_{\rm cb}}=-\frac{1-\gamma}{1-\gamma^{n_{y}}}\log(p_{y})$
    | 重新加权 |'
- en: '| Balanced Softmax loss [[97](#bib.bib97)] | ${\mathcal{L}_{\rm bs}}=-\log(\frac{\pi_{y}\exp(z_{y})}{\sum_{j}\pi_{j}\exp(z_{j})})$
    | re-weighting |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 平衡 Softmax 损失 [[97](#bib.bib97)] | ${\mathcal{L}_{\rm bs}}=-\log(\frac{\pi_{y}\exp(z_{y})}{\sum_{j}\pi_{j}\exp(z_{j})})$
    | 重新加权 |'
- en: '| Equalization loss [[19](#bib.bib19)] | ${\mathcal{L}_{\rm eq}}=-\log(\frac{\exp(z_{y})}{\sum_{j}\omega_{j}\exp(z_{j})})$
    | re-weighting |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 均衡损失 [[19](#bib.bib19)] | ${\mathcal{L}_{\rm eq}}=-\log(\frac{\exp(z_{y})}{\sum_{j}\omega_{j}\exp(z_{j})})$
    | 重新加权 |'
- en: '| LDAM loss [[18](#bib.bib18)] | ${\mathcal{L}_{\rm ldam}}=-\log(\frac{\exp(z_{y}-\Delta_{y})}{\sum_{j}\exp(z_{j}-\Delta_{j})})$
    | re-margining |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| LDAM 损失 [[18](#bib.bib18)] | ${\mathcal{L}_{\rm ldam}}=-\log(\frac{\exp(z_{y}-\Delta_{y})}{\sum_{j}\exp(z_{j}-\Delta_{j})})$
    | 重新边际化 |'
- en: 'Re-weighting. To address the class imbalance, re-weighting attempts to adjust
    the training loss values for different classes by multiplying them with different
    weights. The most intuitive method is to directly use the *label frequencies of
    training samples* for loss re-weighting to re-balance the uneven positive gradients
    among classes. For example, weighted softmax (c.f. Table [III](#S3.T3 "TABLE III
    ‣ 3.1.2 Class-sensitive Learning ‣ 3.1 Class Re-balancing ‣ 3 Classic Methods
    ‣ Deep Long-Tailed Learning: A Survey")) directly multiplies the loss values of
    different classes by the inverse of training label frequencies. However, simply
    multiplying by its inverse may not be the optimal solution. Recent studies thus
    proposed to tune the influence of training label frequencies based on sample-aware
    influences [[111](#bib.bib111)]. Moreover, Class-balanced loss (CB) [[16](#bib.bib16)]
    introduced a novel concept of *effective number* to approximate the expected sample
    number of different classes, which is an exponential function of their training
    label number. Following this, CB loss enforces a class-balanced re-weighting term,
    inversely proportional to the effective number of classes, to address the class
    imbalance (c.f. Table [III](#S3.T3 "TABLE III ‣ 3.1.2 Class-sensitive Learning
    ‣ 3.1 Class Re-balancing ‣ 3 Classic Methods ‣ Deep Long-Tailed Learning: A Survey")).
    Besides the aforementioned re-weighting at the level of log probabilities, we
    can also use the training label frequencies to re-weight prediction logits. Balanced
    Softmax [[97](#bib.bib97)] proposed to adjust prediction logits by multiplying
    by the label frequencies, so that the bias of class imbalance can be alleviated
    by the label prior before computing final losses. Afterwards, Vector-scaling loss
    (VS) [[112](#bib.bib112)] intuitively analyzed the distinct effects of additive
    and multiplicative logit-adjusted losses, leading to a novel VS loss to combine
    the advantages of both forms of adjustment.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '重新加权。为了应对类别不平衡问题，重新加权尝试通过将训练损失值乘以不同的权重来调整不同类别的训练损失值。最直观的方法是直接使用*训练样本的标签频率*进行损失重新加权，以重新平衡各类别之间不均匀的正梯度。例如，加权
    softmax（参见表 [III](#S3.T3 "TABLE III ‣ 3.1.2 Class-sensitive Learning ‣ 3.1 Class
    Re-balancing ‣ 3 Classic Methods ‣ Deep Long-Tailed Learning: A Survey)")直接将不同类别的损失值乘以训练标签频率的倒数。然而，简单地乘以倒数可能不是最佳解决方案。最近的研究因此提出了基于样本感知影响调整训练标签频率的影响 [[111](#bib.bib111)]。此外，类别平衡损失（CB） [[16](#bib.bib16)]
    引入了*有效样本数*的新概念，以近似不同类别的期望样本数，这是一种训练标签数的指数函数。随后，CB 损失强制执行与类别有效数量成反比的类别平衡重新加权项，以解决类别不平衡（参见表 [III](#S3.T3
    "TABLE III ‣ 3.1.2 Class-sensitive Learning ‣ 3.1 Class Re-balancing ‣ 3 Classic
    Methods ‣ Deep Long-Tailed Learning: A Survey)")。除了上述基于对数概率的重新加权外，我们还可以使用训练标签频率来重新加权预测
    logit。平衡 Softmax [[97](#bib.bib97)] 提出了通过乘以标签频率来调整预测 logit，从而在计算最终损失之前，通过标签先验来减轻类别不平衡的偏差。之后，向量缩放损失（VS） [[112](#bib.bib112)]
    直观地分析了加法和乘法 logit 调整损失的不同效果，提出了一种新型 VS 损失，以结合两种调整形式的优势。'
- en: 'Instead of using training label frequencies, Focal loss [[54](#bib.bib54)]
    explored *class prediction hardness* for re-weighting. This is inspired by the
    observation that *class imbalance usually increases the prediction hardness of
    tail classes, whose prediction probabilities would be lower than those of head
    classes*. Following this, Focal loss uses the prediction probabilities to inversely
    re-weight classes (c.f. Table [III](#S3.T3 "TABLE III ‣ 3.1.2 Class-sensitive
    Learning ‣ 3.1 Class Re-balancing ‣ 3 Classic Methods ‣ Deep Long-Tailed Learning:
    A Survey")), so that it can assign higher weights to the harder tail classes but
    lower weights to the easier head classes. Besides using a pre-defined weighting
    function, the class weights can also be learned from data. For instance, Meta-Weight-Net [[94](#bib.bib94)]
    proposed to learn an MLP-approximated weighting function based on a balanced validation
    set for class-sensitive learning.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '相比于使用训练标签频率，Focal loss [[54](#bib.bib54)] 探索了 *类别预测难度* 以进行重新加权。这一方法的灵感源于观察到的现象，即
    *类别不平衡通常会增加尾部类别的预测难度，这些类别的预测概率会低于头部类别*。因此，Focal loss 使用预测概率来逆向重新加权类别（参见表 [III](#S3.T3
    "TABLE III ‣ 3.1.2 Class-sensitive Learning ‣ 3.1 Class Re-balancing ‣ 3 Classic
    Methods ‣ Deep Long-Tailed Learning: A Survey")），从而为更难的尾部类别分配更高的权重，而为较容易的头部类别分配较低的权重。除了使用预定义的加权函数，类别权重也可以通过数据学习。例如，Meta-Weight-Net [[94](#bib.bib94)]
    提出了基于平衡验证集来学习 MLP 近似加权函数，以实现类别敏感学习。'
- en: Some recent studies [[37](#bib.bib37), [19](#bib.bib19)] also seek to address
    the negative gradient over-suppression issue of tail classes. For example, Equalization
    loss [[19](#bib.bib19)] directly down-weights the loss values of tail-class samples
    when they serve as negative labels for head-class samples. However, simply down-weighting
    negative gradients may harm the discriminative abilities of deep models. To address
    this, Adaptive Class Suppression loss (ACSL) [[110](#bib.bib110)] uses the *output
    confidence* to decide whether to suppress the gradient for a negative label. Specifically,
    if the prediction probability of a negative label is larger than a pre-defined
    threshold, it means that the model is confused about this class so the weight
    for this class is set to 1 to improve model discrimination; otherwise, the weight
    is set to 0 to avoid negative over-suppression. Moreover, Equalization loss v2 [[108](#bib.bib108)]
    extended the equalization loss [[19](#bib.bib19)] by introducing a novel gradient-guided
    re-weighting mechanism that dynamically up-weights the positive gradients and
    down-weights the negative gradients for different classes. Similarly, Seesaw loss [[109](#bib.bib109)]
    re-balances positive and negative gradients for each class with two re-weighting
    factors, *i.e.,* mitigation and compensation. Specifically, to address gradient
    over-suppression, the mitigation factor alleviates the penalty to tail classes
    based on a dynamically cumulative sampling number of different classes. Meanwhile,
    if a false positive sample is observed, the compensation factor up-weights the
    penalty to the corresponding class for improving model discrimination.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 一些近期的研究 [[37](#bib.bib37), [19](#bib.bib19)] 也尝试解决尾部类别的负梯度过度抑制问题。例如，Equalization
    loss [[19](#bib.bib19)] 在尾部类别样本作为头部类别样本的负标签时直接降低了其损失值。然而，简单地降低负梯度可能会损害深度模型的判别能力。为了解决这个问题，Adaptive
    Class Suppression loss (ACSL) [[110](#bib.bib110)] 使用 *输出置信度* 来决定是否抑制负标签的梯度。具体来说，如果负标签的预测概率大于预定义的阈值，这意味着模型对该类别感到困惑，因此该类别的权重设置为
    1，以提高模型的判别能力；否则，权重设置为 0，以避免负梯度过度抑制。此外，Equalization loss v2 [[108](#bib.bib108)]
    通过引入一种新的梯度引导重新加权机制扩展了 Equalization loss [[19](#bib.bib19)]，动态地提高正梯度的权重并降低负梯度的权重。类似地，Seesaw
    loss [[109](#bib.bib109)] 为每个类别用两个重新加权因子，即减轻和补偿，来重新平衡正负梯度。具体而言，为了解决梯度过度抑制问题，减轻因子基于不同类别的动态累积采样数量来减轻对尾部类别的惩罚。同时，如果观察到一个假阳性样本，补偿因子则提高对相应类别的惩罚，以改善模型的判别能力。
- en: Re-margining. To handle the class imbalance, re-margining attempts to adjust
    losses by subtracting different margin factors for different classes, so that
    they have a different minimal margin (*i.e.,* distance) between features and the
    classifier. Directly using existing soft margin losses [[138](#bib.bib138), [139](#bib.bib139)]
    is unfeasible, since they ignore the issue of class imbalance. To address this,
    Label-Distribution-Aware Margin (LDAM) [[18](#bib.bib18)] enforces class-dependent
    margin factors for different classes based on their training label frequencies,
    which encourages tail classes to have larger margins.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 再边际调整。为了处理类别不平衡问题，再边际调整尝试通过为不同类别减去不同的边际因子来调整损失，使它们在特征与分类器之间具有不同的最小边际（*即，*距离）。直接使用现有的软边际损失[[138](#bib.bib138),
    [139](#bib.bib139)] 是不可行的，因为它们忽略了类别不平衡的问题。为了解决这一问题，标签分布感知边际（LDAM）[[18](#bib.bib18)]
    根据训练标签频率对不同类别施加依赖于类别的边际因子，从而鼓励尾部类别具有更大的边际。
- en: However, the training label frequencies may be unknown in real applications,
    and simply using them for re-margining also ignores the status of model training
    on different classes. To address this, recent studies explored various adaptive
    re-margining methods. Uncertainty-based margin learning (UML) [[95](#bib.bib95)]
    found that *the class prediction uncertainty is inversely proportional to the
    training label frequencies, i.e., tail classes are more uncertain*. Inspired by
    this, UML proposed to use the estimated class-level uncertainty to re-margin losses,
    so that the tail classes with higher class uncertainty incur a higher loss value
    and thus have a larger margin between features and the classifier. Moreover, LOCE [[33](#bib.bib33)]
    proposed to use the *mean class prediction score* to monitor the learning status
    of different classes and apply it to guide class-level margin adjustment for enhancing
    tail classes. Domain balancing [[22](#bib.bib22)] introduced a novel frequency
    indicator based on the *inter-class compactness of features*, and uses this indicator
    to re-margin the feature space of tail domains. Despite effectiveness, the above
    re-margining methods for encouraging large tail-class margins may degrade the
    feature learning of head classes. To address this, RoBal [[113](#bib.bib113)]
    further enforces a margin factor to also enlarge head-class margins.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在实际应用中，训练标签频率可能是未知的，仅仅使用它们进行再边际调整也忽略了模型在不同类别上的训练状态。为了解决这一问题，最近的研究探索了各种自适应再边际调整方法。基于不确定性的边际学习（UML）[[95](#bib.bib95)]
    发现，*类别预测的不确定性与训练标签频率成反比，即尾部类别的不确定性更高*。受到这一发现的启发，UML 提出了使用估计的类别级不确定性来进行再边际调整，使得具有更高类别不确定性的尾部类别承担更高的损失值，从而在特征与分类器之间形成更大的边际。此外，LOCE
    [[33](#bib.bib33)] 提出了使用*均值类别预测得分*来监控不同类别的学习状态，并将其用于指导类别级边际调整，以增强尾部类别。领域平衡[[22](#bib.bib22)]
    引入了一种基于*类别间特征紧凑性的*新型频率指标，并使用该指标来再边际调整尾部领域的特征空间。尽管这些方法有效地鼓励了尾部类别的较大边际，但也可能降低了头部类别的特征学习。为了解决这一问题，RoBal
    [[113](#bib.bib113)] 进一步施加了一个边际因子，以增大头部类别的边际。
- en: 'Discussions. These class-sensitive learning methods aim to resolve the class
    imbalance issue at the objective level. We summarize some of them in Table [III](#S3.T3
    "TABLE III ‣ 3.1.2 Class-sensitive Learning ‣ 3.1 Class Re-balancing ‣ 3 Classic
    Methods ‣ Deep Long-Tailed Learning: A Survey"). Both re-weighting and re-margining
    methods have a similar effect on re-balancing classes. If the negative influence
    of class imbalance can be addressed by one class-sensitive approach well, it is
    unnecessary to further apply other class-sensitive methods, which would not bring
    further performance gain and even harm performance. More specifically, if the
    training label frequencies are available, directly using them for re-weighting
    (*e.g.,* Balanced Softmax [[97](#bib.bib97)] and VS [[112](#bib.bib112)]) or re-margining
    (*e.g.,* LDAM [[18](#bib.bib18)]) provides a simple and generally effective solution
    for real applications. If not, it is preferred to use the mean class prediction
    score to guide class-sensitive learning (*e.g.,* ACSL [[110](#bib.bib110)] and
    LOCE [[33](#bib.bib33)]) thanks to its simplicity. One can also consider other
    guidance, like intra-class compactness. However, inter-class compactness of features [[22](#bib.bib22)]
    may be not that informative when the feature dimensions are very high, while the
    prediction uncertainty [[95](#bib.bib95)] may be difficult to estimate accurately
    in practice. Moreover, using prediction hardness for re-weighting in Focal loss
    performs well when the number of classes is not large, but may fail when facing
    a large number of classes. Furthermore, Equalization loss v2, Seesaw loss and
    RoBal can also be considered if the challenges that they try to resolve appear
    in real applications.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '讨论。这些类敏感学习方法旨在从目标层面解决类不平衡问题。我们在表[III](#S3.T3 "TABLE III ‣ 3.1.2 Class-sensitive
    Learning ‣ 3.1 Class Re-balancing ‣ 3 Classic Methods ‣ Deep Long-Tailed Learning:
    A Survey")中总结了一些方法。无论是重加权还是重边距方法，对重新平衡类都有类似的效果。如果一种类敏感方法能够很好地解决类不平衡的负面影响，那么就没有必要进一步应用其他类敏感方法，因为这不会带来进一步的性能提升，甚至可能损害性能。更具体地说，如果训练标签频率可用，直接使用它们进行重加权（*例如，*
    Balanced Softmax [[97](#bib.bib97)] 和 VS [[112](#bib.bib112)]）或重边距（*例如，* LDAM
    [[18](#bib.bib18)]）为实际应用提供了简单且通常有效的解决方案。如果不可用，则建议使用均值类预测分数来指导类敏感学习（*例如，* ACSL
    [[110](#bib.bib110)] 和 LOCE [[33](#bib.bib33)]），因为其简单性。也可以考虑其他指导，如类内紧凑性。然而，当特征维度非常高时，特征的类间紧凑性[[22](#bib.bib22)]
    可能信息量不大，而预测不确定性[[95](#bib.bib95)] 在实践中可能难以准确估计。此外，当类别数不多时，使用预测难度进行重加权在 Focal loss
    中表现良好，但面对大量类别时可能失败。此外，如果实际应用中出现了它们试图解决的挑战，还可以考虑 Equalization loss v2、Seesaw loss
    和 RoBal。'
- en: 3.1.3 Logit Adjustment
  id: totrans-164
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.3 Logit 调整
- en: Logit adjustment [[140](#bib.bib140), [14](#bib.bib14)] seeks to resolve the
    class imbalance by adjusting the prediction logits of a class-biased deep model.
    One recent study [[14](#bib.bib14)] comprehensively analyzed logit adjustment
    via training label frequencies of different classes in long-tailed recognition,
    and theoretically showed that *logit adjustment is Fisher consistent to minimize
    the average per-class error*. Following this idea, RoBal [[113](#bib.bib113)]
    applied a post-processing strategy to adjust the cosine classifier based on training
    label frequencies.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: Logit 调整[[140](#bib.bib140), [14](#bib.bib14)] 试图通过调整类偏见深度模型的预测 logit 来解决类不平衡问题。最近的一项研究[[14](#bib.bib14)]
    通过长尾识别中的不同类的训练标签频率对 logit 调整进行了全面分析，并理论上表明*logit 调整在最小化每类平均误差方面是 Fisher 一致的*。基于这一思想，RoBal[[113](#bib.bib113)]
    应用了一种后处理策略，根据训练标签频率调整余弦分类器。
- en: However, the above methods tent to fail when the training label frequencies
    are unavailable. To address this this, UNO-IC [[99](#bib.bib99)] proposed to learn
    the logit offset based on a *balanced* meta validation set and use it to calibrate
    the biased model predictions. Instead of using a meta validation set, DisAlign [[29](#bib.bib29)]
    applied an adaptive calibration function for logit adjustment, where the calibration
    function is learned by matching the calibrated prediction distribution to a pre-defined
    relatively balanced class distribution.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，上述方法在训练标签频率不可用时往往会失败。为了解决这个问题，UNO-IC[[99](#bib.bib99)] 提出了基于*平衡*的元验证集学习 logit
    偏移量，并用它来校准偏置模型预测。与使用元验证集不同，DisAlign[[29](#bib.bib29)] 应用了一种自适应校准函数进行 logit 调整，其中校准函数通过将校准后的预测分布与预定义的相对平衡的类分布进行匹配来学习。
- en: The idea of logit adjustment naturally suits agnostic test class distributions.
    If the test label frequencies are available, LADE [[31](#bib.bib31)] proposed
    to use them to post-adjust model outputs so that the trained model can be calibrated
    for arbitrary test class distributions. However, the test label frequencies are
    usually unavailable, which makes LADE less practical in real scenarios.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: logit调整的思想自然适用于无关测试类别分布。如果测试标签频率可用，LADE [[31](#bib.bib31)]建议使用它们来后调整模型输出，以便将训练好的模型校准到任意测试类别分布。然而，测试标签频率通常不可用，这使得LADE在实际场景中不够实用。
- en: Discussions. To summarize, these logit adjustment methods address the class
    imbalance at the prediction level. If the training label frequencies are known,
    directly using them to post-adjust the predictions of biased deep models is recommended [[14](#bib.bib14),
    [113](#bib.bib113)]. If such information is unknown, it is preferred to exploit
    the idea of DisAlign [[29](#bib.bib29)] to learn an adaptive calibration function.
    These logit adjustment methods are exclusive to each other, so using a well-performing
    one is enough for real applications.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论。总结来说，这些logit调整方法在预测层面上解决类别不平衡。如果已知训练标签频率，建议直接使用它们来后调整偏置深度模型的预测 [[14](#bib.bib14),
    [113](#bib.bib113)]。如果这些信息未知，建议利用DisAlign的思想 [[29](#bib.bib29)]来学习自适应校准函数。这些logit调整方法彼此排斥，因此在实际应用中，使用性能良好的一个即可。
- en: 3.1.4 Summary
  id: totrans-169
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.4 总结
- en: Class re-balancing is relatively simple among the three main method types of
    long-tailed learning, but it can achieve comparable or even better performance.
    Some methods, especially class-sensitive learning, are theoretically inspired
    or guaranteed to handle long-tailed problems [[16](#bib.bib16), [18](#bib.bib18),
    [31](#bib.bib31)]. These advantages enable class re-balancing to be a good candidate
    for real-world applications.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在长尾学习的三种主要方法中，类别重新平衡相对简单，但可以实现可比甚至更好的性能。一些方法，特别是类别敏感学习，理论上受到启发或保证能处理长尾问题 [[16](#bib.bib16),
    [18](#bib.bib18), [31](#bib.bib31)]。这些优势使得类别重新平衡成为实际应用中的一个良好选择。
- en: The ultimate goal of its three sub-categories (*i.e.,* re-sampling, class-sensitive
    learning and logit adjustment) are the same, *i.e.,* re-balancing classes. Hence,
    when the class imbalance is not addressed well, combining them may achieve better
    performance. However, these subtypes are sometimes exclusive to each other. For
    example, if we have trained a class-balanced deep model via class-sensitive learning,
    then further using logit adjustment methods to post-adjust model inference will
    instead lead to biased predictions and suffer poor performance. Therefore, if
    one wants to combine them, the pipeline should be designed carefully.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个子类别的**最终目标**（*即*，重新采样、类别敏感学习和logit调整）是相同的，*即*，重新平衡类别。因此，当类别不平衡没有得到很好解决时，结合它们可能会实现更好的性能。然而，这些子类型有时彼此排斥。例如，如果我们通过类别敏感学习训练了一个类别平衡的深度模型，那么进一步使用logit调整方法来后处理模型推断将会导致预测偏差并遭遇较差的性能。因此，如果想要结合它们，管道设计应当谨慎。
- en: One drawback of class re-balancing is that most methods improve tail-class performance
    at the cost of lower head-class performance, which is like playing on a performance
    seesaw. Although the overall performance is improved, it cannot essentially handle
    the issue of lacking information, particularly on tail classes due to limited
    data sizes. To address this limitation, one feasible solution is to conduct information
    augmentation as follows.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 类别重新平衡的一个缺点是，大多数方法在提高尾部类别性能的同时会降低头部类别性能，这就像在玩性能的跷跷板。尽管整体性能有所提升，但它无法从根本上解决信息不足的问题，特别是在尾部类别由于数据量有限。为了解决这一限制，一种可行的解决方案是进行如下的信息增强。
- en: 3.2 Information Augmentation
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 信息增强
- en: 'Information augmentation seeks to introduce additional information into model
    training, so that the model performance can be improved for long-tailed learning.
    There are two kinds of methods in this method type: transfer learning and data
    augmentation.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 信息增强旨在向模型训练中引入额外信息，以便提升长尾学习的模型性能。这种方法类型中有两种方法：转移学习和数据增强。
- en: 3.2.1 Transfer Learning
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 转移学习
- en: Transfer learning [[141](#bib.bib141), [142](#bib.bib142), [91](#bib.bib91),
    [118](#bib.bib118), [101](#bib.bib101)] seeks to transfer the knowledge from a
    source domain (*e.g.,* datasets) to enhance model training on a target domain.
    In long-tailed learning, there are four main transfer schemes, *i.e.,* model pre-training,
    knowledge distillation, head-to-tail model transfer, and self-training.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习[[141](#bib.bib141), [142](#bib.bib142), [91](#bib.bib91), [118](#bib.bib118),
    [101](#bib.bib101)]旨在将源领域（*例如*，数据集）的知识转移到目标领域，以增强模型训练。在长尾学习中，主要有四种迁移方案，即模型预训练、知识蒸馏、头尾模型迁移和自训练。
- en: Model pre-training is a popular scheme for deep model training [[143](#bib.bib143),
    [144](#bib.bib144), [145](#bib.bib145), [146](#bib.bib146), [147](#bib.bib147)]
    and has also been explored in long-tailed learning. For example, Domain-Specific
    Transfer Learning (DSTL) [[92](#bib.bib92)] first pre-trains the model with all
    long-tailed samples for representation learning, and then fine-tunes the model
    on a more class-balanced training subset. In this way, DSTL slowly transfers the
    learned features to tail classes, obtaining more balanced performance among all
    classes. Rather than supervised pre-training, Self-supervised Pre-training (SSP) [[102](#bib.bib102)]
    proposed to first use self-supervised learning (*e.g.,* contrastive learning [[148](#bib.bib148)]
    or rotation prediction [[149](#bib.bib149)]) for model pre-training, followed
    by standard training on long-tailed data. Empirical results show self-supervised
    learning helps to learn a balanced feature space for long-tailed learning [[13](#bib.bib13)].
    Such a scheme has also been explored to handle long-tailed data with noisy labels [[150](#bib.bib150)].
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 模型预训练是深度模型训练中的一种流行方案[[143](#bib.bib143), [144](#bib.bib144), [145](#bib.bib145),
    [146](#bib.bib146), [147](#bib.bib147)]，也已在长尾学习中进行探索。例如，领域特定迁移学习（DSTL）[[92](#bib.bib92)]首先用所有长尾样本进行模型预训练以进行表示学习，然后在一个类别更均衡的训练子集上对模型进行微调。通过这种方式，DSTL慢慢将学习到的特征转移到尾部类别，从而在所有类别之间获得更平衡的性能。与监督式预训练不同，自监督式预训练（SSP）[[102](#bib.bib102)]建议首先使用自监督学习（*例如*，对比学习[[148](#bib.bib148)]或旋转预测[[149](#bib.bib149)]）进行模型预训练，然后在长尾数据上进行标准训练。实证结果表明，自监督学习有助于学习长尾学习的平衡特征空间[[13](#bib.bib13)]。这种方案也被探索用于处理具有噪声标签的长尾数据[[150](#bib.bib150)]。
- en: 'Knowledge distillation seeks to train a student model based on the outputs
    of a well-trained teacher model [[151](#bib.bib151), [152](#bib.bib152)]. Recent
    studies have explored knowledge distillation for long-tailed learning. For example,
    Learning from Multiple Experts (LFME) [[103](#bib.bib103)] first trains multiple
    experts on several less imbalanced sample subsets (*e.g.,* head, middle and tail
    sets), and then distills these experts into a unified student model. Similarly,
    Routing Diverse Experts (RIDE) [[17](#bib.bib17)] introduced a knowledge distillation
    method to reduce the parameters of the multi-expert model by learning a student
    network with fewer experts. Instead of multi-expert teachers, Distill the Virtual
    Examples (DiVE) [[116](#bib.bib116)] showed that learning a class-balanced model
    as the teacher is also beneficial for long-tailed learning. Following DiVE, Self-Supervision
    to Distillation (SSD) [[119](#bib.bib119)] developed a new self-distillation scheme
    to enhance decoupled training (c.f. Section [3.3.3](#S3.SS3.SSS3 "3.3.3 Decoupled
    Training ‣ 3.3 Module Improvement ‣ 3 Classic Methods ‣ Deep Long-Tailed Learning:
    A Survey")). Specifically, SSD first trains a calibrated model based on supervised
    and self-supervised information via the decoupled training scheme, and then uses
    the calibrated model to generate soft labels for all samples. Following that,
    both the generated soft labels and original long-tailed hard labels are used to
    distill a new student model, followed by a new classifier fine-tuning stage.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '知识蒸馏旨在基于经过良好训练的教师模型的输出训练学生模型 [[151](#bib.bib151), [152](#bib.bib152)]。近期研究探讨了知识蒸馏在长尾学习中的应用。例如，**从多个专家学习**（LFME）[[103](#bib.bib103)]
    首先在若干不太不平衡的样本子集（*例如*，头部、中部和尾部集合）上训练多个专家，然后将这些专家蒸馏成一个统一的学生模型。类似地，**路由多样专家**（RIDE）[[17](#bib.bib17)]
    引入了一种知识蒸馏方法，通过学习一个具有更少专家的学生网络来减少多专家模型的参数。与多专家教师不同，**蒸馏虚拟示例**（DiVE）[[116](#bib.bib116)]
    表明，将类平衡模型作为教师进行学习对长尾学习也有好处。在 DiVE 的基础上，**自监督蒸馏**（SSD）[[119](#bib.bib119)] 开发了一种新的自蒸馏方案，以增强解耦训练（参见第[3.3.3节](#S3.SS3.SSS3
    "3.3.3 Decoupled Training ‣ 3.3 Module Improvement ‣ 3 Classic Methods ‣ Deep
    Long-Tailed Learning: A Survey")）。具体来说，SSD 首先通过解耦训练方案基于监督和自监督信息训练一个校准模型，然后利用该校准模型为所有样本生成软标签。随后，使用生成的软标签和原始长尾硬标签来蒸馏一个新的学生模型，并进行新的分类器微调阶段。'
- en: Head-to-tail model transfer seeks to transfer the model knowledge from head
    classes to enhance model performance on tail classes. For example, MetaModelNet [[91](#bib.bib91)]
    proposed to learn a meta-network that can map few-shot model parameters to many-shot
    model parameters. To this end, MetaModelNet first trains a many-shot model on
    the head-class training set, and trains a fake few-shot model on a sampled subset
    from these classes with a very limited number of data to mimic tail classes. Then,
    the meta-network is learned by mapping the learned fake few-shot model to the
    many-shot model. Following that, the learned meta-network on head classes is applied
    to map the true few-shot model trained on tail classes for obtaining better tail-class
    performance. Instead of model mapping, Geometric Structure Transfer (GIST)  [[107](#bib.bib107)]
    proposed to conduct head-to-tail transfer at the classifier level. Specifically,
    GIST uses the relatively large classifier geometry information of head classes
    to enhance the tail-class classifier weights, so that the performance of tail
    classes can be improved.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 头尾模型迁移旨在将模型知识从头类转移到尾类，以增强尾类的模型性能。例如，**MetaModelNet**[[91](#bib.bib91)] 提出了学习一个可以将少样本模型参数映射到多样本模型参数的元网络。为此，MetaModelNet
    首先在头类训练集上训练一个多样本模型，并在这些类的一个采样子集上训练一个虚假的少样本模型，该子集数据非常有限以模拟尾类。然后，通过将学习到的虚假少样本模型映射到多样本模型来学习元网络。随后，将在头类上学到的元网络应用于将真实的少样本模型映射到尾类上，以获得更好的尾类性能。与模型映射不同，**几何结构迁移**（GIST）[[107](#bib.bib107)]
    提出了在分类器层面进行头尾迁移。具体来说，GIST 利用头类的相对较大分类器几何信息来增强尾类分类器的权重，从而提高尾类的性能。
- en: Self-training aims to learn well-performing models from a small number of labeled
    samples and massive unlabeled samples [[153](#bib.bib153), [154](#bib.bib154),
    [155](#bib.bib155)]. To be specific, it firstly uses labeled samples to train
    a supervised model, which is then applied to generate pseudo labels for unlabeled
    data. Following that, both the labeled and pseudo-labeled samples are used to
    re-train models. In this way, self-training can exploit the knowledge from massive
    unlabeled samples to enhance long-tailed learning performance. Such a paradigm,
    however, cannot be directly used to handle long-tailed problems, because both
    labeled and unlabeled datasets may follow long-tailed class distributions with
    different degrees. In such cases, the trained model on labeled samples may be
    biased to head classes and tends to generate more head-class pseudo labels for
    unlabeled samples, leading to a more skewed degree of imbalance.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 自训练旨在从少量已标记样本和大量未标记样本中学习性能良好的模型[[153](#bib.bib153), [154](#bib.bib154), [155](#bib.bib155)]。具体来说，它首先使用已标记样本训练一个有监督模型，然后将该模型应用于未标记数据生成伪标签。随后，同时使用已标记样本和伪标记样本对模型进行重新训练。通过这种方式，自训练可以利用大量未标记样本的知识来提升长尾学习性能。然而，这种方法无法直接处理长尾问题，因为已标记和未标记数据集都可能遵循不同程度的长尾类别分布。在这种情况下，已标记样本上训练的模型可能会对头类别有偏好，并倾向于为未标记样本生成更多头类别的伪标签，导致不平衡程度更加偏斜。
- en: To address this issue, Distribution Alignment and Random Sampling (DARS) [[26](#bib.bib26)]
    proposed to regard the label frequencies of labeled data as a reference and enforce
    the label frequencies of the generated pseudo labels to be consistent with the
    labeled ones. Instead of using training label frequencies, Class-rebalancing Self-training
    (CReST) [[106](#bib.bib106)] found that *the precision of the supervised model
    on tail classes is surprisingly high*, and thus proposed to select more tail-class
    samples for online pseudo labeling in each iteration, so that the re-trained model
    can obtain better performance on tail classes. Beyond classification tasks, MosaicOS [[117](#bib.bib117)]
    resorted to other object-centric images to boost long-tailed object detection.
    Specifically, it first pre-trains the model with labeled scene-centric images
    from the original detection dataset, and then uses the pre-trained model to generate
    pseudo bounding boxes for object-centric images, *e.g.,* ImageNet-1K [[39](#bib.bib39)].
    After that, MosaicOS fine-tunes the pre-trained model in two stages, *i.e.,* first
    fine-tuning with the pseudo-labeled object-centric images and then fine-tuning
    with the original labeled scene-centric images. In this way, MosaicOS alleviates
    the negative influence of data discrepancies and effectively improves long-tailed
    performance.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，《分布对齐和随机采样》（Distribution Alignment and Random Sampling，DARS）[[26](#bib.bib26)]提出将标记数据集的标签频率作为参考，并确保生成的伪标签的标签频率与已标记数据集一致。《类别再平衡自训练》（Class-rebalancing
    Self-training，CReST）[[106](#bib.bib106)]发现在尾类别上的有监督模型的精度出奇的高，并因此提议每次迭代在在线伪标签中选择更多尾类别样本，以便重新训练的模型在尾类别上能够获得更好的性能。在分类任务之外，《镶嵌OS》（MosaicOS）[[117](#bib.bib117)]利用其他以物体为中心的图像提升长尾目标检测。具体来说，它首先使用原始检测数据集中以场景为中心的已标记图像对模型进行预训练，然后使用预训练模型为以物体为中心的图像生成伪边界框，例如ImageNet-1K[[39](#bib.bib39)]。然后，MosaicOS分两个阶段对预训练模型进行微调，即先使用伪标记的以物体为中心的图像进行微调，然后再使用原始已标记的以场景为中心的图像进行微调。通过这种方式，MosaicOS缓解了数据差异的负面影响，有效提升了长尾性能。
- en: Discussions. These transfer learning methods are complementary to each other,
    which brings additional information from different perspectives to long-tailed
    learning. Most of them can be used together for real applications if the resources
    permit and the combination pipeline is designed well. More concretely, when using
    model pre-training, the trade-off between supervised discrimination learning and
    self-supervised class-balanced learning should be tuned [[13](#bib.bib13)], which
    contributes to better long-tailed learning performance. In addition, knowledge
    distillation with multi-experts can usually achieve better performance than distillation
    with a single teacher. In head-to-tail model transfer, GIST is a better candidate
    than MetaModelNet due to its simplicity. Lastly, the use of self-training methods
    depends on task requirements and what unlabeled samples are available at hand.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论。这些转移学习方法相互补充，从不同的角度为长尾学习带来了额外的信息。如果资源允许并且组合管道设计得当，它们大多数可以一起用于实际应用。更具体地说，在使用模型预训练时，应该调整监督性区分学习和自监督性类别平衡学习之间的权衡[[13](#bib.bib13)]，这有助于更好的长尾学习性能。此外，具有多个专家的知识蒸馏通常能比单一教师的蒸馏取得更好的性能。在头到尾的模型转移中，由于其简单性，GIST
    是比 MetaModelNet 更好的候选者。最后，自训练方法的使用取决于任务需求和手头上可用的无标签样本。
- en: 3.2.2 Data Augmentation
  id: totrans-183
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 数据增强
- en: Data Augmentation aims to enhance the size and quality of datasets by applying
    pre-defined transformations to each data$/$feature for model training [[156](#bib.bib156),
    [157](#bib.bib157)]. In long-tailed learning, there are two types of augmentation
    methods that have been explored, *i.e.,* transfer-based augmentation and non-transfer
    augmentation.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强旨在通过对每个数据/特征应用预定义的变换来提升数据集的大小和质量，以用于模型训练[[156](#bib.bib156), [157](#bib.bib157)]。在长尾学习中，已经探索了两种类型的增强方法，即*基于转移的增强*和*非转移增强*。
- en: Head-to-tail transfer augmentation seeks to transfer the knowledge from head
    classes to augment tail-class samples. For example, Major-to-Minor translation
    (M2m) [[100](#bib.bib100)] proposed to augment tail classes by translating head-class
    samples to tail-class ones via perturbation-based optimization, which is essentially
    similar to adversarial attack. The translated tail-class samples are used to construct
    a more balanced training set for model training.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 头到尾的转移增强旨在将知识从头部类别转移到增强尾部类别样本。例如，主要到次要翻译（M2m）[[100](#bib.bib100)] 提出通过基于扰动的优化将头部类别样本翻译为尾部类别样本，从而增强尾部类别，这本质上类似于对抗攻击。翻译后的尾部类别样本用于构建更平衡的训练集以进行模型训练。
- en: Besides the data-level transfer in M2m, most studies explore feature-level transfer.
    For instance, Feature Transfer Learning (FTL) [[96](#bib.bib96)] found that *tail-class
    samples have much smaller intra-class variance than head-class samples, leading
    to biased feature spaces and decision boundaries*. To address this, FTL exploits
    the knowledge of intra-class variance from head classes to guide feature augmentation
    for tail-class samples, so that the tail-class features have higher intra-class
    variance. Similarly, LEAP [[49](#bib.bib49)] constructs “feature cloud” for each
    class, and transfers the distribution knowledge of head-class feature clouds to
    enhance the intra-class variation of tail-class feature clouds. As a result, the
    distortion of the intra-class feature variance among classes is alleviated, leading
    to better tail-class performance.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 M2m 中的数据级转移，大多数研究探讨了特征级转移。例如，特征转移学习（FTL）[[96](#bib.bib96)] 发现*尾部类别样本的类内方差远小于头部类别样本，从而导致特征空间和决策边界的偏差*。为了解决这个问题，FTL
    利用头部类别的类内方差知识来指导尾部类别样本的特征增强，使尾部类别特征具有更高的类内方差。类似地，LEAP [[49](#bib.bib49)] 为每个类别构建“特征云”，并将头部类别特征云的分布知识转移到尾部类别特征云，以增强尾部类别特征云的类内变异性。因此，缓解了各类别间类内特征方差的扭曲，从而改善了尾部类别的性能。
- en: Instead of using the intra-class variation information, Rare-class Sample Generator
    (RSG) [[118](#bib.bib118)] proposed to dynamically estimate a set of feature centers
    for each class, and use *the feature displacement between head-class sample features
    and their nearest intra-class feature center* to augment each tail sample feature
    for enlarging the tail-class feature space. Moreover, Online Feature Augmentation
    (OFA) [[101](#bib.bib101)] proposed to use class activation maps [[158](#bib.bib158)]
    to decouple sample features into class-specific and class-agnostic ones. Following
    that, OFA augments tail classes by combining the class-specific features of tail-class
    samples with class-agnostic features from head-class samples.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 代替使用类内变异信息，Rare-class Sample Generator (RSG) [[118](#bib.bib118)] 提出了动态估计每个类别的一组特征中心，并使用*头部类别样本特征与其最近的类内特征中心之间的特征位移*来增强每个尾部样本特征，从而扩展尾部类别的特征空间。此外，Online
    Feature Augmentation (OFA) [[101](#bib.bib101)] 提出了使用类别激活图 [[158](#bib.bib158)]
    将样本特征解耦为类别特定和类别无关的特征。随后，OFA通过将尾部类别样本的类别特定特征与头部类别样本的类别无关特征结合来增强尾部类别。
- en: Non-transfer augmentation seeks to improve or design conventional data augmentation
    methods to address long-tailed problems. SMOTE [[159](#bib.bib159)], a classic
    over-sampling method for non-deep class imbalance, can be applied to deep long-tailed
    problems to generate tail-class samples by mixing several intra-class neighbouring
    samples. Recently, MiSLAS [[114](#bib.bib114)] further investigated data mixup
    in deep long-tailed learning, and found that (1) *data mixup helps to remedy model
    over-confidence*; (2) *mixup has a positive effect on representation learning
    but a negative or negligible effect on classifier learning in the decoupled training
    scheme* [[32](#bib.bib32)]. Following these observations, MiSLAS proposed to use
    data mixup to enhance representation learning in the decoupled scheme. In addition,
    Remix [[160](#bib.bib160)] also resorted to data mixup for long-tailed learning
    and introduced a re-balanced mixup method to particularly enhance tail classes.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 非转移增强旨在改进或设计传统数据增强方法以解决长尾问题。SMOTE [[159](#bib.bib159)]，一种经典的过采样方法，可以应用于深度长尾问题，通过混合几个类内邻近样本来生成尾部类别样本。最近，MiSLAS [[114](#bib.bib114)]
    进一步研究了深度长尾学习中的数据混合，并发现（1）*数据混合有助于缓解模型过度自信*；（2）*在解耦训练方案中，混合对表征学习有积极影响，但对分类器学习有负面或微不足道的影响* [[32](#bib.bib32)]。基于这些观察结果，MiSLAS
    提出了在解耦方案中使用数据混合来增强表征学习。此外，Remix [[160](#bib.bib160)] 也采用了数据混合来进行长尾学习，并引入了一种重新平衡的混合方法来特别增强尾部类别。
- en: Instead of using data mixup, FASA [[58](#bib.bib58)] proposed to generate new
    data features for each class, based on class-wise Gaussian priors with their mean
    and variance estimated from previously observed samples. Here, FASA exploits the
    model classification loss on a balanced validation set to adjust feature sampling
    rates for different classes, so that the under-represented tail classes can be
    augmented more than head classes. With a similar idea, Meta Semantic Augmentation
    (MetaSAug) [[120](#bib.bib120)] proposed to augment tail classes with a variant
    of implicit semantic data augmentation (ISDA) [[161](#bib.bib161)]. Specifically,
    ISDA estimates the class-conditional statistics (*i.e.,* covariance matrices from
    sample features) to obtain semantic directions, and generates diversified augmented
    samples by translating sample features along with diverse semantically meaningful
    directions. To better estimate the covariance matrices for tail classes, MetaSAug
    explored meta learning to guide the learning of covariance matrices for each class
    with the class-balanced loss [[16](#bib.bib16)], leading to more informative synthetic
    features.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 代替使用数据混合，FASA [[58](#bib.bib58)] 提出了基于从以前观察到的样本中估计的均值和方差的类别高斯先验，为每个类别生成新的数据特征。在这里，FASA利用模型分类损失在平衡验证集上调整不同类别的特征采样率，以便于增强尾部类别的样本多于头部类别。基于类似的理念，Meta
    Semantic Augmentation (MetaSAug) [[120](#bib.bib120)] 提出了用隐式语义数据增强 (ISDA) [[161](#bib.bib161)]
    的变体来增强尾部类别。具体而言，ISDA 估计类别条件统计（*即*，样本特征的协方差矩阵）以获得语义方向，并通过沿不同的语义上有意义的方向转换样本特征来生成多样化的增强样本。为了更好地估计尾部类别的协方差矩阵，MetaSAug
    探索了元学习来指导每个类别协方差矩阵的学习，使用了类别平衡损失 [[16](#bib.bib16)]，从而得到更具信息性的合成特征。
- en: Discussions. Data augmentation based methods attempt to address the class imbalance
    at the sample or feature levels. The goals of these methods are consistent, so
    they can be used simultaneously if the combination pipeline is constructed well.
    Among its two subtypes, head-to-tail transfer augmentation is more intuitive than
    non-transfer augmentation. More specifically, head-to-tail transfer at the feature
    level (*e.g.,* RSG) seems to perform better than transfer at the sample level
    (*e.g.,* M2m). In the feature-level transfer augmentation, RSG is preferred thanks
    to its easy-to-use source code, whereas the intra-class variation in FTL and LEAP
    may be less informative for augmentation when the feature dimension is very high.
    In non-transfer augmentation, mixup-based strategies are usually used thanks to
    their simplicity, where MiSLAS has demonstrated promising performance. In contrast,
    the class-wise Gaussian priors in FASA and the covariance matrices in MetaSAug
    may be difficult to estimate in various real scenarios.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论。基于数据增强的方法试图在样本或特征级别解决类别不平衡问题。这些方法的目标是一致的，因此如果组合流程构建得当，它们可以同时使用。在其两种子类型中，头到尾的迁移增强比非迁移增强更直观。更具体地说，在特征级别的迁移增强中（*例如*
    RSG），由于其易于使用的源代码，RSG被认为性能更佳，而在特征维度非常高时，FTL和LEAP中的类内变异可能对增强影响较小。在非迁移增强中，基于混合的策略通常得到使用，MIslas已展示出令人期待的性能。相比之下，FASA中的类别高斯先验和MetaSAug中的协方差矩阵在各种真实场景中可能难以估计。
- en: 3.2.3 Summary
  id: totrans-191
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 总结
- en: Information augmentation addresses the long-tailed problems by introducing additional
    knowledge, and thus is compatible with and complementary to other two method types,
    *i.e.,* class re-balancing and module improvement. For the same reason, its two
    method subtypes, *i.e.,* transfer learning and data augmentation, are also complementary
    to each other. More concretely, both the subtypes are able to improve tail-class
    performance without sacrificing head-class performance if designed carefully.
    Considering that all classes are important in long-tailed learning, this type
    of method is worth further exploring. Moreover, data augmentation is a very fundamental
    technique and can be used for a variety of long-tailed problems, which makes it
    more practical than other paradigms in real-world applications. However, simply
    using existing *class-agnostic* augmentation techniques for improving long-tailed
    learning is unfavorable, since they ignore the class imbalance and inevitably
    augment more head-class samples than tail-class samples. How to better conduct
    data augmentation for long-tailed learning is still an open question.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 信息增强通过引入额外知识来解决长尾问题，因此与其他两种方法类型兼容并且互补，*即*类别重平衡和模块改进。出于同样的原因，其两种子类型，*即*迁移学习和数据增强，也互为补充。更具体地说，如果设计得当，这两种子类型都能够在不牺牲头类性能的情况下改善尾类性能。考虑到长尾学习中所有类别都很重要，这种方法值得进一步探索。此外，数据增强是一种非常基础的技术，可用于各种长尾问题，使其在实际应用中比其他范例更为实用。然而，单纯使用现有*与类别无关*的增强技术改善长尾学习并不理想，因为它们忽视了类别不平衡，不可避免地会增强更多头类样本而非尾类样本。如何更好地进行数据增强以改善长尾学习仍然是一个未解之谜。
- en: 3.3 Module Improvement
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 模块改进
- en: 'Besides re-balancing and information augmentation, researchers also explored
    methods to improve network modules in long-tailed learning. These methods can
    be divided into four categories: (1) representation learning improves the feature
    extractor; (2) classifier design enhances the model classifier; (3) decoupled
    training aims to boost the learning of both the feature extractor and the classifier;
    (4) ensemble learning improves the whole architecture.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 除了重平衡和信息增强，研究人员还探索了改进长尾学习中的网络模块的方法。这些方法可以分为四类：(1) 表示学习改进特征提取器；(2) 分类器设计增强模型分类器；(3)
    分离训练旨在增强特征提取器和分类器的学习；(4) 集成学习改进整个架构。
- en: 3.3.1 Representation Learning
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1 表示学习
- en: Existing long-tailed learning methods improve representation learning based
    on three main paradigms, *i.e.,* metric learning, prototype learning, and sequential
    training.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的长尾学习方法基于三种主要范例改进了表示学习，*即*度量学习、原型学习和顺序训练。
- en: Metric learning aims at designing task-specific distance metrics for establishing
    similarity or dissimilarity between data. In deep long-tailed learning, metric
    learning based methods seek to explore various distance-based losses to learn
    a discriminative feature space for long-tailed data. One example is Large Margin
    Local Embedding (LMLE) [[89](#bib.bib89)], which introduced a quintuplet loss
    to learn representations that maintain both inter-cluster and inter-class margins.
    Unlike the triplet loss [[162](#bib.bib162)] that samples two contrastive pairs,
    LMLE presented a quintuplet sampler to sample four contrastive pairs, including
    a positive pair and three negative pairs. The positive pair is the most distant
    intra-cluster sample, while the negative pairs include two inter-clusters samples
    from the same class (one is the nearest and one is the most distant within the
    same cluster) and the nearest inter-class sample. Following that, LMLE introduced
    a quintuplet loss to encourage the sampled quintuplet to follow a specific distance
    order. In this way, the learned representations preserve not only locality across
    intra-class clusters but also discrimination between classes. Moreover, each data
    batch contains the same number of samples from different classes for class re-balancing.
    However, LMLE does not consider the sample differences among head and tail classes.
    To address this, Class Rectification Loss (CRL) [[50](#bib.bib50)] explored hard
    pair mining and proposed to construct more hard-pair triplets for tail classes,
    so that tail-class features can have a larger degree of intra-class compactness
    and inter-class distances.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 度量学习旨在设计任务特定的距离度量，用于建立数据之间的相似性或差异性。在深度长尾学习中，基于度量学习的方法试图探索各种基于距离的损失，以学习适用于长尾数据的判别特征空间。一个例子是大边距局部嵌入（LMLE）[[89](#bib.bib89)]，它引入了五元组损失，以学习保持簇间和类别间边距的表示。与采样两个对比对的三元组损失[[162](#bib.bib162)]不同，LMLE提出了一种五元组采样器，用于采样四个对比对，包括一个正对和三个负对。正对是最远的簇内样本，而负对包括来自同一类别的两个簇间样本（一个是最近的，一个是同一簇内最远的）以及最近的类别间样本。随后，LMLE引入了五元组损失，以鼓励采样的五元组遵循特定的距离顺序。这样，学习到的表示不仅保持了簇内的局部性，还保持了类别间的判别性。此外，每个数据批次包含来自不同类别的相同数量的样本，以进行类别重平衡。然而，LMLE没有考虑头类和尾类之间的样本差异。为了解决这个问题，类别校正损失（CRL）[[50](#bib.bib50)]探索了困难对挖掘，并提出为尾类构造更多的困难对三元组，以使尾类特征具有更大的簇内紧凑度和类别间距离。
- en: Rather than sampling triplets or quintuplets, range loss [[21](#bib.bib21)]
    innovated representation learning by using the overall distances among all sample
    pairs within one mini-batch. In other words, the range loss uses statistics over
    the whole batch and thus alleviates the bias of data number imbalance over classes.
    Specifically, range loss enlarges the inter-class distance by maximizing the distances
    of any two class centers within the mini-batch, and reduces the intra-class variation
    by minimizing the largest distances between intra-class samples. In this way,
    the range loss obtains features with better discriminative abilities and less
    imbalanced bias.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 与其采样三元组或五元组，范围损失[[21](#bib.bib21)]通过使用一个小批次内所有样本对之间的整体距离来创新表示学习。换句话说，范围损失使用整个批次的统计数据，从而减轻了类别之间的数据数量不平衡的偏差。具体而言，范围损失通过最大化小批次内任何两个类别中心之间的距离来扩大类别间距离，并通过最小化簇内样本之间的最大距离来减少簇内变异。通过这种方式，范围损失获得了具有更好判别能力和更少不平衡偏差的特征。
- en: Recent studies also explored contrastive learning for long-tailed problems.
    KCL [[13](#bib.bib13)] proposed a $k$-positive contrastive loss to learn a balanced
    feature space, which helps to alleviate the class imbalance and improve model
    generalization. Parametric contrastive learning (PaCo) [[121](#bib.bib121)] further
    innovated supervised contrastive learning by adding a set of parametric learnable
    class centers, which plays the same role as a classifier if regarding the class
    centers as the classifier weights. Following that, Hybrid [[123](#bib.bib123)]
    introduced a prototypical contrastive learning strategy to enhance long-tailed
    learning. DRO-LT [[122](#bib.bib122)] extended the prototypical contrastive learning
    with distribution robust optimization [[163](#bib.bib163)], which makes the learned
    model more robust to distribution shift.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究还探讨了对比学习在长尾问题上的应用。KCL [[13](#bib.bib13)] 提出了 $k$-正对比损失，以学习平衡的特征空间，这有助于缓解类别不平衡并提高模型的泛化能力。参数对比学习（PaCo）[[121](#bib.bib121)]
    通过添加一组可学习的类别中心进一步创新了监督对比学习，这些类别中心在将其视为分类器权重时扮演着分类器的角色。随后，Hybrid [[123](#bib.bib123)]
    引入了原型对比学习策略，以增强长尾学习。DRO-LT [[122](#bib.bib122)] 通过分布鲁棒优化 [[163](#bib.bib163)]
    扩展了原型对比学习，使得学习到的模型对分布变化更加鲁棒。
- en: Prototype learning based methods seek to learn class-specific feature prototypes
    to enhance long-tailed learning performance. Open Long-Tailed Recognition (OLTR) [[15](#bib.bib15)]
    innovatively explored the idea of feature prototypes to handle long-tailed recognition
    in an open world, where the test set also includes open classes that do not appear
    in training data. To address this task, OLTR maintains a visual meta memory containing
    discriminative feature prototypes, and uses the features sampled from the visual
    memory to augment the original features for better discrimination. Meanwhile,
    the sample features from novel classes are enforced to be far away from the memory
    and closer to the origin point. In this way, the learned feature space enables
    OLTR to classify all seen classes and detect novel classes. However, OLTR only
    maintains a static prototype memory and each class has only one prototype. Such
    a single prototype per class may fail to represent the real data distribution.
    To address this issue, Inflated Episodic Memory (IEM) [[104](#bib.bib104)] further
    innovated the meta-embedding memory by a dynamical update scheme, in which each
    class has independent and differentiable memory blocks. Each memory block is updated
    to record the most discriminative feature prototypes of the corresponding categories,
    thus leading to better performance than OLTR.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 原型学习方法寻求学习类别特定的特征原型，以提升长尾学习性能。开放长尾识别（OLTR）[[15](#bib.bib15)]创新性地探索了特征原型的思想，以应对在开放世界中的长尾识别问题，其中测试集还包括训练数据中未出现的开放类别。为了解决这一任务，OLTR
    维护一个包含区分特征原型的视觉元记忆，并使用从视觉记忆中采样的特征来增强原始特征，从而提高区分能力。同时，新类别的样本特征被强制与记忆远离，接近原点。通过这种方式，学习到的特征空间使
    OLTR 能够对所有已见类别进行分类，并检测新类别。然而，OLTR 仅维护一个静态的原型记忆，每个类别只有一个原型。这种每类单一原型可能无法代表真实的数据分布。为了解决这个问题，膨胀式情节记忆（IEM）[[104](#bib.bib104)]通过动态更新方案进一步创新了元嵌入记忆，其中每个类别具有独立且可区分的记忆块。每个记忆块被更新以记录对应类别的最具区分性的特征原型，从而比
    OLTR 实现了更好的性能。
- en: Sequential training based methods learn data representation in a continual way.
    For example, Hierarchical Feature Learning (HFL) [[90](#bib.bib90)] took inspiration
    from that each class has its individuality in discriminative visual representation.
    Therefore, HFL hierarchically clusters objects into visually similar class groups,
    forming a hierarchical cluster tree. In this cluster tree, the model in the original
    node is pre-trained on ImageNet-1K; the model in each child node inherits the
    model parameters from its parent node and is then fine-tuned based on samples
    in the cluster node. In this way, the knowledge from the groups with massive classes
    is gradually transferred to their sub-groups with fewer classes. Similarly, Unequal-training [[48](#bib.bib48)]
    proposed to divide the dataset into head-class and tail-class subsets, and treat
    them differently in the training process. First, unequal-training uses the head-class
    samples to train relatively discriminative and noise-resistant features with a
    new noise-resistant loss. After that, it uses tail-class samples to enhance the
    inter-class discrimination of representations via hard identity mining and a novel
    center-dispersed loss.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序训练方法以连续的方式学习数据表示。例如，层次特征学习（HFL）[[90](#bib.bib90)] 从每个类别在判别视觉表示中的独特性获得灵感。因此，HFL
    将对象分层聚类成视觉上相似的类别组，形成一个层次聚类树。在这个聚类树中，原始节点中的模型在 ImageNet-1K 上进行预训练；每个子节点中的模型继承其父节点的模型参数，然后基于聚类节点中的样本进行微调。通过这种方式，来自大类组的知识逐渐转移到其子类组中。类似地，不平衡训练
    [[48](#bib.bib48)] 提出了将数据集分为头类和尾类子集，并在训练过程中对它们进行不同处理。首先，不平衡训练使用头类样本通过一种新的抗噪声损失函数来训练相对判别性和抗噪声的特征。之后，它使用尾类样本通过困难的身份挖掘和一种新型的中心分散损失来增强表示的类别间判别性。
- en: Discussions. These representation learning methods seek to address the class
    imbalance at the feature level. The methods within each subtype are competing
    with each other (*e.g.,* KCL [[13](#bib.bib13)] vs PaCo [[121](#bib.bib121)] and
    OLTR [[15](#bib.bib15)] vs IEM [[104](#bib.bib104)]), while the methods from different
    subtypes may be complementary to each other (*e.g.,* KCL [[13](#bib.bib13)] and
    Unequal-training [[48](#bib.bib48)]). Therefore, the pipeline must be carefully
    designed, if one wants to combine them together. Moreover, when handling real
    long-tailed applications, PaCo [[121](#bib.bib121)] is recommended to use thanks
    to its promising performance and open-source code. If there are open classes in
    test data, IEM [[104](#bib.bib104)] is preferred. Other methods, like Unequal-training [[48](#bib.bib48)],
    can also be considered if they suit real scenarios.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论。这些表示学习方法试图在特征层面上解决类别不平衡的问题。每个子类型中的方法相互竞争（*例如*，KCL [[13](#bib.bib13)] 与 PaCo
    [[121](#bib.bib121)] 和 OLTR [[15](#bib.bib15)] 与 IEM [[104](#bib.bib104)]），而不同子类型的方法可能互为补充（*例如*，KCL
    [[13](#bib.bib13)] 和 不平衡训练 [[48](#bib.bib48)]）。因此，如果要将它们结合在一起，管道设计必须小心。此外，在处理真实的长尾应用时，推荐使用
    PaCo [[121](#bib.bib121)]，因为它具有良好的性能和开源代码。如果测试数据中存在开放类别，则首选 IEM [[104](#bib.bib104)]。如果它们适合实际场景，也可以考虑其他方法，如不平衡训练
    [[48](#bib.bib48)]。
- en: 3.3.2 Classifier Design
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2 分类器设计
- en: In addition to representation learning, researchers also explored different
    types of classifiers to address long-tailed problems. In generic visual problems [[10](#bib.bib10),
    [148](#bib.bib148)], the common practice of deep learning is to use linear classifier
    $p=\phi(w^{\top}f\small{+}b)$, where $\phi$ denotes the softmax function and the
    bias term $b$ can be discarded. However, long-tailed class imbalance often results
    in larger classifier weight norms for head classes than tail classes [[96](#bib.bib96)],
    which makes the linear classifier easily biased to dominant classes.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 除了表示学习，研究人员还探索了不同类型的分类器来解决长尾问题。在通用视觉问题 [[10](#bib.bib10), [148](#bib.bib148)]
    中，深度学习的常见做法是使用线性分类器 $p=\phi(w^{\top}f\small{+}b)$，其中 $\phi$ 表示 softmax 函数，偏置项
    $b$ 可以被忽略。然而，长尾类别的不平衡通常导致头类的分类器权重范数大于尾类 [[96](#bib.bib96)]，这使得线性分类器容易偏向主导类别。
- en: To address this, recent studies [[49](#bib.bib49), [113](#bib.bib113)] proposed
    to use the scale-invariant cosine classifier $p=\phi((\frac{w^{\top}f}{\|w\|\|f\|})/\tau+b)$,
    where both the classifier weights and sample features are normalized. Here, the
    temperature $\tau$ should be chosen reasonably [[164](#bib.bib164)], or the classifier
    performance would be negatively influenced. However, normalizing the feature space
    may harm its representation abilities. Therefore, the $\tau$-normalized classifier [[32](#bib.bib32)]
    rectifies the imbalance by only adjusting the classifier weight norms through
    a $\tau$-normalization procedure. Formally, let $\tilde{w}=\frac{w}{\|w\|^{\tau}_{2}}$,
    where $\tau$ is the temperature factor for normalization. When $\tau=1$, the $\tau$-normalization
    reduces to $L_{2}$ normalization, while when $\tau=0$, no scaling is imposed.
    Note that, the hyper-parameter $\tau$ can also be trained with class-balanced
    sampling, and the resulting classifier is named the learnable weight scaling classifier [[32](#bib.bib32)].
    Another approach to address classifier weight imbalance is to use the nearest
    class mean classifier [[32](#bib.bib32)], which first computes the mean features
    for each class on the training set as the classifier, and then conducts prediction
    based on the nearest neighbor algorithm [[165](#bib.bib165)].
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，最近的研究[[49](#bib.bib49), [113](#bib.bib113)]提出使用尺度不变的余弦分类器$p=\phi((\frac{w^{\top}f}{\|w\|\|f\|})/\tau+b)$，其中分类器权重和样本特征都进行了归一化。在这里，温度$\tau$需要合理选择[[164](#bib.bib164)]，否则分类器性能会受到负面影响。然而，归一化特征空间可能会损害其表示能力。因此，$\tau$-归一化分类器[[32](#bib.bib32)]通过仅调整分类器权重范数来纠正不平衡，采用$\tau$-归一化过程。形式上，设$\tilde{w}=\frac{w}{\|w\|^{\tau}_{2}}$，其中$\tau$是归一化的温度因子。当$\tau=1$时，$\tau$-归一化还原为$L_{2}$归一化，而当$\tau=0$时，则不施加缩放。注意，超参数$\tau$也可以通过类别平衡采样进行训练，得到的分类器称为可学习的权重缩放分类器[[32](#bib.bib32)]。解决分类器权重不平衡的另一种方法是使用最近类均值分类器[[32](#bib.bib32)]，它首先计算训练集中每个类别的均值特征作为分类器，然后基于最近邻算法[[165](#bib.bib165)]进行预测。
- en: There are also some more complicated classifier designs based on hierarchical
    classification, causal inference or classifier knowledge transfer. For example,
    Realistic Taxonomic Classifier (RTC) [[105](#bib.bib105)] proposed to address
    class imbalance with hierarchical classification by mapping images into a class
    taxonomic tree structure, where the hierarchy is defined by a set of classification
    nodes and node relations. Different samples are adaptively classified at different
    hierarchical levels, where the level at which the prediction is made depends on
    the sample classification difficulty and the classifier confidence. Such a design
    favors correct decisions at intermediate levels rather than incorrect decisions
    at the leaves.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些基于层次分类、因果推断或分类器知识转移的更复杂的分类器设计。例如，现实分类器（RTC）[[105](#bib.bib105)]提出通过将图像映射到一个类别分类树结构来解决类别不平衡，其中层次结构由一组分类节点和节点关系定义。不同的样本在不同的层次级别上自适应分类，其中预测进行的层次级别取决于样本分类的难度和分类器的置信度。这种设计更倾向于在中间层做出正确决策，而不是在叶子节点做出错误决策。
- en: Causal classifier [[45](#bib.bib45)] resorted to causal inference for keeping
    the good and removing the bad momentum causal effects in long-tailed learning.
    The good causal effect indicates the beneficial factor that stabilizes gradients
    and accelerates training, while the bad causal effect indicates the accumulated
    long-tailed bias that leads to poor tail-class performance. To better approximate
    the bias information, the causal classifier applies a multi-head strategy to divide
    the channel (or dimensions) of model weights and data features equally into $K$
    groups. Formally, the causal classifier calculates the original logits by $p=\phi(\frac{\tau}{K}\sum_{k=1}^{K}\frac{(w^{k})^{\top}f^{k}}{(\|w^{k}\|+\gamma)\|f^{k}\|})$,
    where $\tau$ is the temperature factor and $\gamma$ is a hyper-parameter. This
    classifier is essentially the cosine classifier when $\gamma=0$. In inference,
    the causal classifier removes the bad causal effect by subtracting the prediction
    when the input is null, *i.e.,* $p=\phi(\frac{\tau}{K}\sum_{k=1}^{K}\frac{(w^{k})^{\top}f^{k}}{(\|w^{k}\|+\gamma)\|f^{k}\|}-\alpha\frac{cos(x^{k},\hat{d}^{k})(w^{k})^{\top}\hat{d}^{k}}{\|w^{k}\|+\gamma})$,
    where $\hat{d}$ is the unit vector of the exponential moving average features,
    and $\alpha$ is a trade-off parameter to control the direct and indirect effects.
    More intuitively, the classifier records the bias by computing the exponential
    moving average features during training, and then removes the bad causal effect
    by subtracting the bias from prediction logits during inference.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 因果分类器 [[45](#bib.bib45)] 通过因果推断来保持良好的因果效应并去除不良的动量因果效应，从而应对长尾学习中的问题。良好的因果效应指的是稳定梯度和加速训练的有益因素，而不良的因果效应则指的是导致尾部类别表现不佳的累积长尾偏差。为了更好地近似偏差信息，因果分类器应用了多头策略，将模型权重和数据特征的通道（或维度）均等地分成
    $K$ 组。正式地，因果分类器通过 $p=\phi(\frac{\tau}{K}\sum_{k=1}^{K}\frac{(w^{k})^{\top}f^{k}}{(\|w^{k}\|+\gamma)\|f^{k}\|})$
    计算原始的 logits，其中 $\tau$ 是温度因子，$\gamma$ 是一个超参数。当 $\gamma=0$ 时，这个分类器本质上是余弦分类器。在推理过程中，因果分类器通过减去输入为空时的预测来去除不良的因果效应，*即*，$p=\phi(\frac{\tau}{K}\sum_{k=1}^{K}\frac{(w^{k})^{\top}f^{k}}{(\|w^{k}\|+\gamma)\|f^{k}\|}-\alpha\frac{cos(x^{k},\hat{d}^{k})(w^{k})^{\top}\hat{d}^{k}}{\|w^{k}\|+\gamma})$，其中
    $\hat{d}$ 是指数移动平均特征的单位向量，$\alpha$ 是控制直接和间接效应的权衡参数。更直观地说，分类器通过计算训练期间的指数移动平均特征来记录偏差，然后通过在推理过程中从预测
    logits 中减去偏差来去除不良因果效应。
- en: GIST classifier [[107](#bib.bib107)] seeks to transfer the classifier geometric
    structure of head classes to tail classes. Specifically, the GIST classifier consists
    of a class-specific weight center (for encoding the class location) and a set
    of displacements (for encoding the class geometry). By exploiting the relatively
    large displacements from head classes to enhance tail-class weight centers, the
    GIST classifier is able to obtain better performance on tail classes.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: GIST 分类器 [[107](#bib.bib107)] 旨在将头部类别的分类器几何结构转移到尾部类别。具体而言，GIST 分类器由一个特定于类别的权重中心（用于编码类别位置）和一组位移（用于编码类别几何形状）组成。通过利用从头部类别到尾部类别的相对较大位移来增强尾部类别的权重中心，GIST
    分类器能够在尾部类别上获得更好的性能。
- en: '![Refer to caption](img/906202066c498b08a10ac6734d886098.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/906202066c498b08a10ac6734d886098.png)'
- en: (a) Standard training
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 标准训练
- en: '![Refer to caption](img/f6f0ff18448b1f5348d88952de24b345.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/f6f0ff18448b1f5348d88952de24b345.png)'
- en: (b) BBN [[44](#bib.bib44)], TLML [[46](#bib.bib46)], SimCAL [[34](#bib.bib34)]
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: (b) BBN [[44](#bib.bib44)]，TLML [[46](#bib.bib46)]，SimCAL [[34](#bib.bib34)]
- en: '![Refer to caption](img/0406ad67f8d7d2c9d4c4c1c416f8f219.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/0406ad67f8d7d2c9d4c4c1c416f8f219.png)'
- en: (c) BAGS [[56](#bib.bib56)], LFME [[103](#bib.bib103)]
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: (c) BAGS [[56](#bib.bib56)]，LFME [[103](#bib.bib103)]
- en: '![Refer to caption](img/1b1d411a198891af88fd3aeccbbd2d1b.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/1b1d411a198891af88fd3aeccbbd2d1b.png)'
- en: (d) ACE [[124](#bib.bib124)], ResLT [[125](#bib.bib125)]
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: (d) ACE [[124](#bib.bib124)]，ResLT [[125](#bib.bib125)]
- en: '![Refer to caption](img/c76d9a875943def09c60a94d24806ed3.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/c76d9a875943def09c60a94d24806ed3.png)'
- en: (e) RIDE [[17](#bib.bib17)]
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: (e) RIDE [[17](#bib.bib17)]
- en: '![Refer to caption](img/31fabcb2a70c6f96840ee740800737f6.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/31fabcb2a70c6f96840ee740800737f6.png)'
- en: (f) SADE [[30](#bib.bib30)]
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: (f) SADE [[30](#bib.bib30)]
- en: 'Figure 3: Illustrations of existing ensemble-based long-tailed methods. Compared
    to standard training (a), the trained experts by ensemble-based methods (b-f)
    may have different expertise, *e.g.,* being skilled in different class distributions
    or different class subsets (indicated by different colors). For example, BBN and
    SimCAL train two experts for simulating the original long-tailed and uniform distributions
    so that they can address the two distributions well. BAGS, LFME, ACE, and ResLT
    train multiple experts by sampling class subsets, so that different experts can
    particularly handle different sets of classes. SADE directly trains multiple experts
    to separately simulate long-tailed, uniform and inverse long-tailed class distributions
    from a stationary long-tailed distribution, which enables it to handle test sets
    with agnostic class distributions based on self-supervised aggregation.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：现有的基于集成的长尾方法的示意图。与标准训练（a）相比，通过集成方法训练的专家（b-f）可能具有不同的专业技能，*例如*，擅长不同的类别分布或不同的类别子集（用不同的颜色表示）。例如，BBN
    和 SimCAL 训练两个专家以模拟原始的长尾分布和均匀分布，使它们能够很好地处理这两种分布。BAGS、LFME、ACE 和 ResLT 通过采样类别子集来训练多个专家，以便不同的专家可以特别处理不同的类别集合。SADE
    直接训练多个专家，以从静态的长尾分布中分别模拟长尾、均匀和逆长尾类别分布，这使得它能够基于自监督聚合处理具有无关类别分布的测试集。
- en: Discussions. These methods address the imbalance at the classifier level. Note
    that these classifiers are exclusive to each other, and the choice of classifiers
    also influences other long-tailed methods. For example, the effects of data mixup
    are different for the linear classifier and the cosine classifier. Hence, when
    exploring new long-tailed approaches, it is better to first determine which classifier
    is used. Generally, the cosine classifier or the learnable weight-scaling classifier
    are recommended, as they are empirically robust to the imbalance and also easy
    to use. Moreover, when designing feature prototype-based methods, the nearest
    class mean classifier is a good choice. More complicated classifier designs (*e.g.,*
    RTC, Causal and GIST) can also be considered if real applications are complex
    and hard to handle.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论。这些方法在分类器层面解决了不平衡问题。请注意，这些分类器是相互排斥的，分类器的选择也会影响其他长尾方法。例如，数据混合的效果在线性分类器和余弦分类器之间有所不同。因此，在探索新的长尾方法时，最好先确定使用哪个分类器。一般来说，推荐使用余弦分类器或可学习的权重缩放分类器，因为它们在面对不平衡时经验上更为稳健且易于使用。此外，在设计基于特征原型的方法时，最近类均值分类器是一个不错的选择。如果实际应用复杂且难以处理，也可以考虑更复杂的分类器设计（*例如*，RTC、Causal
    和 GIST）。
- en: 3.3.3 Decoupled Training
  id: totrans-223
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.3 解耦训练
- en: 'Decoupled training decouples the learning procedure into representation learning
    and classifier training. Here, decoupled training represents a general paradigm
    for long-tailed learning instead of a specific approach. Decoupling [[32](#bib.bib32)]
    was the pioneering work to introduce such a two-stage decoupled training scheme.
    It empirically evaluated different sampling strategies (mentioned in Section [3.1.1](#S3.SS1.SSS1
    "3.1.1 Re-sampling ‣ 3.1 Class Re-balancing ‣ 3 Classic Methods ‣ Deep Long-Tailed
    Learning: A Survey")) for representation learning in the first stage, and then
    evaluated different classifier training schemes by fixing the trained feature
    extractor in the second stage. In the classifier learning stage, there are also
    four methods, including classifier re-training with class-balanced sampling, the
    nearest class mean classifier, the $\tau$-normalized classifier, and the learnable
    weight-scaling classifier. The main observations are twofold: (1) *random sampling
    is surprisingly the best strategy for representation learning* in decoupled training;
    (2) *re-adjusting the classifier leads to significant performance improvement*
    in long-tailed recognition.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '解耦训练将学习过程分为表示学习和分类器训练两个阶段。这里，解耦训练代表了一种长尾学习的一般范式，而不是特定的方法。解耦 [[32](#bib.bib32)]
    是引入这种两阶段解耦训练方案的开创性工作。它在第一阶段通过评估不同的采样策略（在第 [3.1.1](#S3.SS1.SSS1 "3.1.1 Re-sampling
    ‣ 3.1 Class Re-balancing ‣ 3 Classic Methods ‣ Deep Long-Tailed Learning: A Survey")
    节中提到）来进行表示学习，然后在第二阶段通过固定训练好的特征提取器来评估不同的分类器训练方案。在分类器学习阶段，还包括四种方法，包括使用类别平衡采样的分类器再训练、最近类均值分类器、$\tau$-归一化分类器和可学习的权重缩放分类器。主要观察结果有两个：（1）*随机采样在解耦训练中的表示学习中意外地是最佳策略*；（2）*重新调整分类器可以显著提高长尾识别的性能*。'
- en: Following this scheme, KCL [[13](#bib.bib13)] empirically observed that *a balanced
    feature space is beneficial to long-tailed learning*. Therefore, it innovated
    the decoupled training scheme by developing a $k$-positive contrastive loss to
    learn a more class-balanced and class-discriminative feature space, which leads
    to better long-tailed learning performance. Moreover, MiSLAS [[114](#bib.bib114)]
    empirically observed that *data mixup is beneficial to features learning but has
    a negative/negligible effect on classifier training under the two-stage decoupled
    training scheme*. Therefore, MiSLAS proposed to enhance the representation learning
    with data mixup in the first stage, while applying a label-aware smoothing strategy
    for better classifier generalization in the second stage.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 按照这一方案，KCL [[13](#bib.bib13)] 经验性地观察到*平衡的特征空间对长尾学习有益*。因此，它通过开发一种$k$-正对比损失创新了解耦训练方案，以学习更平衡和类区分度更强的特征空间，从而带来更好的长尾学习表现。此外，MiSLAS [[114](#bib.bib114)]
    经验性地观察到*数据mixup对特征学习有益，但在两阶段解耦训练方案下对分类器训练有负面/微不足道的影响*。因此，MiSLAS建议在第一阶段通过数据mixup增强表示学习，而在第二阶段应用标签感知平滑策略以获得更好的分类器泛化。
- en: Several recent studies particularly enhanced the classifier training stage.
    For example, OFA [[101](#bib.bib101)] innovated the classifier re-training through
    tail-class feature augmentation. SimCal [[34](#bib.bib34)] enhanced the classifier
    training stage by calibrating the classification head with a novel bi-level class-balanced
    sampling strategy for long-tailed instance segmentation. DisAlign [[29](#bib.bib29)]
    innovated the classifier training with a new adaptive logit adjustment strategy.
    Very recently, DT2 [[61](#bib.bib61)] applied the scheme of decoupled training
    to the scene graph generation task, which demonstrates the effectiveness of decoupled
    training in handling long-tailed visual relation learning.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 几项最近的研究特别加强了分类器训练阶段。例如，OFA [[101](#bib.bib101)]通过尾类特征增强创新了分类器再训练。SimCal [[34](#bib.bib34)]通过采用新颖的双层类平衡采样策略来校准分类头，从而提升了长尾实例分割任务中的分类器训练阶段。DisAlign [[29](#bib.bib29)]通过一种新的自适应logit调整策略创新了分类器训练。最近，DT2 [[61](#bib.bib61)]将解耦训练方案应用于场景图生成任务，展示了解耦训练在处理长尾视觉关系学习中的有效性。
- en: Discussions. Decoupled training methods resolve the class imbalance issue at
    both the feature and classifier levels. Under ideal conditions, combining different
    methods can lead to better long-tailed performance, *e.g.,* using self-supervised
    pre-training [[13](#bib.bib13)] and mixup augmentation [[114](#bib.bib114)] together
    for better representation learning, and applying label-aware smoothing [[114](#bib.bib114)]
    and tail-class feature augmentation [[101](#bib.bib101)] together for better classifier
    tuning. Therefore, it is recommended to use MiSLAS [[114](#bib.bib114)] as a base
    method and use different tricks on it. Note that some representation methods are
    also competing to each other, *e.g.,* different sampling methods for representation
    learning [[32](#bib.bib32)].
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论。解耦训练方法在特征和分类器层面上解决了类不平衡问题。在理想条件下，结合不同的方法可以带来更好的长尾表现，*例如*，将自监督预训练 [[13](#bib.bib13)]和mixup增强 [[114](#bib.bib114)]结合使用以获得更好的表示学习，或将标签感知平滑 [[114](#bib.bib114)]和尾类特征增强 [[101](#bib.bib101)]结合使用以获得更好的分类器调整。因此，建议使用MiSLAS [[114](#bib.bib114)]作为基础方法，并在其上应用不同的技巧。请注意，一些表示方法也在竞争，例如，不同的采样方法用于表示学习 [[32](#bib.bib32)]。
- en: The classifier learning stage does not introduce too many computation costs
    but can lead to significant performance gains. This makes decoupled training attract
    increasing attention. One critique is that the accumulated training stages make
    decoupled training less practical to be integrated with existing well-formulated
    methods for other long-tailed problems like object detection and instance segmentation.
    Despite this, the idea of decoupled training is conceptually simple and thus can
    be easily used to design new methods for resolving various long-tailed problems,
    like DT2 [[61](#bib.bib61)].
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器学习阶段不会引入太多计算成本，但可以带来显著的性能提升。这使得解耦训练越来越受到关注。一个批评意见是，累积的训练阶段使解耦训练在与现有的针对其他长尾问题如目标检测和实例分割的良好方法集成时变得不够实用。尽管如此，解耦训练的概念简单，因此可以很容易地用于设计解决各种长尾问题的新方法，例如DT2 [[61](#bib.bib61)]。
- en: 3.3.4 Ensemble Learning
  id: totrans-229
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.4 集成学习
- en: 'Ensemble learning based methods strategically generate and combine multiple
    network modules (namely, multiple experts) to solve long-tailed visual learning
    problems. We summarize the main schemes of existing ensemble-based methods in
    Fig. [3](#S3.F3 "Figure 3 ‣ 3.3.2 Classifier Design ‣ 3.3 Module Improvement ‣
    3 Classic Methods ‣ Deep Long-Tailed Learning: A Survey"), which will be detailed
    as follows.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '集成学习方法通过战略性地生成和结合多个网络模块（即多个专家）来解决长尾视觉学习问题。我们在图 [3](#S3.F3 "Figure 3 ‣ 3.3.2
    Classifier Design ‣ 3.3 Module Improvement ‣ 3 Classic Methods ‣ Deep Long-Tailed
    Learning: A Survey") 中总结了现有集成方法的主要方案，下面将详细介绍。'
- en: 'BBN [[44](#bib.bib44)] proposed to use two network branches, *i.e.,* a conventional
    learning branch and a re-balancing branch (cf. Table [3](#S3.F3 "Figure 3 ‣ 3.3.2
    Classifier Design ‣ 3.3 Module Improvement ‣ 3 Classic Methods ‣ Deep Long-Tailed
    Learning: A Survey")(b)), to handle long-tailed recognition. To be specific, the
    conventional learning branch applies uniform sampling to simulate the original
    long-tailed training distribution, while the re-balancing branch applies a reversed
    sampler to sample more tail-class samples in each mini-batch for improving tail-class
    performance. The predictions of two branches are dynamically combined during training,
    so that the learning focus of BBN gradually changes from head classes to tail
    classes. Following BBN, LTML [[46](#bib.bib46)] applied the bilateral-branch network
    scheme to solve long-tailed multi-label classification. To be specific, LTML trains
    each branch using the sigmoid cross-entropy loss for multi-label classification
    and enforces a logit consistency loss to improve the consistency of the two branches.
    Similarly, SimCal [[34](#bib.bib34)] explored a dual classification head scheme,
    a conventional classification head and a calibrated classification head, to address
    long-tail instance segmentation. Based on a new bi-level sampling strategy, the
    calibrated classification head is able to improve the performance on tail classes,
    while the original head aims to maintain the performance on head classes.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 'BBN [[44](#bib.bib44)] 提出了使用两个网络分支，*即* 一个常规学习分支和一个重平衡分支（参见表 [3](#S3.F3 "Figure
    3 ‣ 3.3.2 Classifier Design ‣ 3.3 Module Improvement ‣ 3 Classic Methods ‣ Deep
    Long-Tailed Learning: A Survey")(b)），以处理长尾识别。具体来说，常规学习分支应用均匀采样来模拟原始的长尾训练分布，而重平衡分支则使用反向采样器在每个小批量中采样更多的尾部类别样本，以提高尾部类别的表现。这两个分支的预测在训练过程中动态结合，从而使得
    BBN 的学习重点逐渐从头部类别转向尾部类别。继 BBN 之后，LTML [[46](#bib.bib46)] 应用了双分支网络方案来解决长尾多标签分类问题。具体而言，LTML
    使用 sigmoid 交叉熵损失训练每个分支进行多标签分类，并施加 logit 一致性损失以提高两个分支的一致性。类似地，SimCal [[34](#bib.bib34)]
    探索了一种双分类头方案，即常规分类头和校准分类头，以解决长尾实例分割问题。基于一种新的双层采样策略，校准分类头能够提高尾部类别的表现，而原始分类头则旨在保持头部类别的表现。'
- en: 'Instead of bilateral branches, BAGS [[56](#bib.bib56)] explored a multi-head
    scheme to address long-tailed object detection. Specifically, BAGS took inspiration
    from an observation that learning a more uniform distribution with fewer samples
    is sometimes easier than learning a long-tailed distribution with more samples.
    Therefore, BAGS divides classes into several groups, where the classes in each
    group have a similar number of training data. Then, BAGS applies multiple classification
    heads for prediction, where different heads are trained on different class groups
    (cf. Table [3](#S3.F3 "Figure 3 ‣ 3.3.2 Classifier Design ‣ 3.3 Module Improvement
    ‣ 3 Classic Methods ‣ Deep Long-Tailed Learning: A Survey")(c)). In this way,
    each classification head performs the softmax operation on classes with a similar
    number of training data, thus avoiding the negative influence of class imbalance.
    Moreover, BAGS also introduces a label of “other classes” into each group to alleviate
    the contradiction among different heads. Similar to BAGS, LFME [[103](#bib.bib103)]
    divides the long-tailed dataset into several subsets with smaller class imbalance
    degrees, and trains multiple experts with different sample subsets. Based on these
    experts, LFME then learns a unified student model using adaptive knowledge distillation
    from multiple teachers.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 'BAGS [[56](#bib.bib56)]没有采用双边分支，而是探索了多头方案来解决长尾目标检测问题。具体而言，BAGS 从一个观察中得到启发，即用较少样本学习更均匀的分布有时比用更多样本学习长尾分布更容易。因此，BAGS
    将类别划分为多个组，每组中的类别拥有相似数量的训练数据。然后，BAGS 应用多个分类头进行预测，其中不同的头部在不同的类别组上进行训练（参见 表[3](#S3.F3
    "Figure 3 ‣ 3.3.2 Classifier Design ‣ 3.3 Module Improvement ‣ 3 Classic Methods
    ‣ Deep Long-Tailed Learning: A Survey")(c)）。这样，每个分类头在样本数量相似的类别上执行 softmax 操作，从而避免了类别不平衡的负面影响。此外，BAGS
    还在每个组中引入了“其他类别”标签，以缓解不同头部之间的矛盾。与 BAGS 类似，LFME [[103](#bib.bib103)] 将长尾数据集划分为几个具有较小类别不平衡度的子集，并使用不同的样本子集训练多个专家。在这些专家的基础上，LFME
    然后通过自适应知识蒸馏从多个教师那里学习一个统一的学生模型。'
- en: 'Instead of division into several balanced sub-groups, ACE [[124](#bib.bib124)]
    divides classes into several skill-diverse subsets: one subset contains all classes;
    one contains middle and tail classes; another one has only tail classes (cf. Table [3](#S3.F3
    "Figure 3 ‣ 3.3.2 Classifier Design ‣ 3.3 Module Improvement ‣ 3 Classic Methods
    ‣ Deep Long-Tailed Learning: A Survey")(d)). ACE then trains multiple experts
    with various class subsets, so that different experts have specific and complementary
    skills. Moreover, considering that various subsets have different sample numbers,
    ACE also applies a distributed-adaptive optimizer to adjust the learning rate
    for different experts. A similar idea of ACE was also explored in ResLT [[125](#bib.bib125)].'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 'ACE [[124](#bib.bib124)]并非将类别划分为多个平衡子组，而是将其划分为几个技能多样的子集：一个子集包含所有类别；一个包含中间和尾部类别；另一个仅包含尾部类别（参见 表[3](#S3.F3
    "Figure 3 ‣ 3.3.2 Classifier Design ‣ 3.3 Module Improvement ‣ 3 Classic Methods
    ‣ Deep Long-Tailed Learning: A Survey")(d)）。ACE 然后训练多个专家，每个专家负责不同的类别子集，使得不同专家拥有特定且互补的技能。此外，考虑到不同子集的样本数量不同，ACE
    还应用了分布式自适应优化器，以调整不同专家的学习率。类似的 ACE 思路也在 ResLT [[125](#bib.bib125)]中得到探讨。'
- en: 'Instead of dividing the dataset, RIDE [[17](#bib.bib17)] uses all training
    samples to train multiple experts with softmax loss respectively (cf. Table [3](#S3.F3
    "Figure 3 ‣ 3.3.2 Classifier Design ‣ 3.3 Module Improvement ‣ 3 Classic Methods
    ‣ Deep Long-Tailed Learning: A Survey")(e)), and enforces a KL-divergence based
    loss to improve the diversity among various experts. Following that, RIDE applies
    an expert assignment module to improve computing efficiency. Note that training
    each expert with the softmax loss independently boosts the ensemble performance
    on long-tailed learning a lot. However, the learned experts by RIDE are not diverse
    enough.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 'RIDE [[17](#bib.bib17)]并未划分数据集，而是使用所有训练样本分别训练多个专家，并采用 softmax 损失（参见 表[3](#S3.F3
    "Figure 3 ‣ 3.3.2 Classifier Design ‣ 3.3 Module Improvement ‣ 3 Classic Methods
    ‣ Deep Long-Tailed Learning: A Survey")(e)），并施加基于 KL 散度的损失，以提升不同专家之间的多样性。随后，RIDE
    引入了专家分配模块以提高计算效率。需要注意的是，独立使用 softmax 损失训练每个专家大大提升了长尾学习中的集成性能。然而，RIDE 学到的专家之间的多样性仍然不够。'
- en: 'Self-supervised Aggregation of Diverse Experts (SADE) [[30](#bib.bib30)] explored
    a new multi-expert scheme to handle test-agnostic long-tailed recognition, where
    the test class distribution can be either uniform, long-tailed or even inversely
    long-tailed. To be specific, SADE developed a novel spectrum-spanned multi-expert
    framework (cf. Table [3](#S3.F3 "Figure 3 ‣ 3.3.2 Classifier Design ‣ 3.3 Module
    Improvement ‣ 3 Classic Methods ‣ Deep Long-Tailed Learning: A Survey")(f)), and
    innovated the expert training scheme by introducing diversity-promoting expertise-guided
    losses that train different experts to handle different class distributions, respectively.
    In this way, the learned experts are more diverse than RIDE, leading to better
    ensemble performance, and integratedly span a wide spectrum of possible class
    distributions. In light of this, SADE further introduced a self-supervised learning
    method, namely prediction stability maximization, to adaptively aggregate experts
    at test time for better handling unknown test class distribution.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '自监督多样化专家聚合 (SADE) [[30](#bib.bib30)] 探索了一种新的多专家方案来处理与测试无关的长尾识别，其中测试类别分布可以是均匀的、长尾的，甚至是反向长尾的。具体来说，SADE
    开发了一种新颖的跨光谱多专家框架（参见表 [3](#S3.F3 "Figure 3 ‣ 3.3.2 Classifier Design ‣ 3.3 Module
    Improvement ‣ 3 Classic Methods ‣ Deep Long-Tailed Learning: A Survey")(f)），并通过引入促进多样性的专家指导损失创新了专家训练方案，分别训练不同专家来处理不同的类别分布。通过这种方式，学习到的专家比
    RIDE 更具多样性，从而提高了集成性能，并全面覆盖了可能的类别分布光谱。鉴于此，SADE 进一步引入了一种自监督学习方法，即预测稳定性最大化，以适应性地在测试时聚合专家，以更好地处理未知的测试类别分布。'
- en: 'Discussions. These ensemble-based methods address the class imbalance at the
    model level. As they require particular manners for multi-model design and training
    (cf. Fig. [3](#S3.F3 "Figure 3 ‣ 3.3.2 Classifier Design ‣ 3.3 Module Improvement
    ‣ 3 Classic Methods ‣ Deep Long-Tailed Learning: A Survey")), they are exclusive
    to each other and usually cannot be used together. More specifically, the methods
    with bilateral branches like BBN and TLML only have two experts, whose empirical
    performance has been shown worse than the approaches with more experts. Moreover,
    the methods with experts trained on class subsets like BAGS and ACE may suffer
    from expert inconsistency in terms of different label spaces, which makes the
    aggregation of experts difficult and may lead to poor performance in real applications.
    Instead, RIDE trains multiple experts with all samples but the resulting multiple
    experts are not diverse enough. In contrast, SADE is able to train skill-diverse
    experts with the same label space, and thus is recommended for real applications.
    One concern of these ensemble-based methods is that they generally lead to higher
    computational costs due to the use of multiple experts. Such a concern, however,
    can be alleviated by using a shared feature extractor. Moreover, efficiency-oriented
    expert assignment and knowledge distillation strategies [[103](#bib.bib103), [17](#bib.bib17)]
    can also reduce computational complexity.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '讨论。这些基于集成的方法在模型层面上解决类别不平衡问题。由于它们需要特定的多模型设计和训练方式（参见图 [3](#S3.F3 "Figure 3 ‣
    3.3.2 Classifier Design ‣ 3.3 Module Improvement ‣ 3 Classic Methods ‣ Deep Long-Tailed
    Learning: A Survey")），因此彼此排斥，通常无法同时使用。更具体来说，像 BBN 和 TLML 这样具有双分支的方法只有两个专家，其经验性能已被证明不如拥有更多专家的方法。此外，像
    BAGS 和 ACE 这样在类别子集上训练的专家可能会遇到专家不一致的问题，即不同标签空间导致专家聚合困难，并可能导致实际应用中的性能较差。相反，RIDE
    训练多个专家使用所有样本，但结果是多个专家的多样性不足。相比之下，SADE 能够训练具有相同标签空间的技能多样化专家，因此推荐用于实际应用。这些基于集成的方法的一个担忧是，它们通常会导致更高的计算成本，因为使用了多个专家。然而，通过使用共享特征提取器，可以减轻这种担忧。此外，以效率为导向的专家分配和知识蒸馏策略
    [[103](#bib.bib103), [17](#bib.bib17)] 也可以降低计算复杂度。'
- en: 3.3.5 Summary
  id: totrans-237
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.5 总结
- en: Module improvement based methods seek to address long-tailed problems by improving
    network modules. Specifically, representation learning and classifier design are
    fundamental problems of deep learning, being worth further exploring for long-tailed
    problems. Both representation learning and classifier design are complementary
    to decoupled training. The scheme of decoupled training is conceptually simple
    and can be easily used to design new methods for resolving real long-tailed applications.
    In addition, ensemble-based methods, thanks to the aggregation of multiple experts,
    are able to achieve better long-tailed performance without sacrificing the performance
    on any class subsets, *e.g.,* head classes. Since all classes are important, such
    a superiority enables ensemble-based methods to be a better choice for real applications
    compared to existing class re-balancing methods that usually improve tail-class
    performance at the cost of lower head-class performance. Here, both ensemble-based
    methods and decoupled training require specific model training and design manners,
    so it is not easy to use them together unless very careful design.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 基于模块改进的方法试图通过改进网络模块来解决长尾问题。具体而言，表示学习和分类器设计是深度学习的基础问题，值得进一步探讨以解决长尾问题。表示学习和分类器设计与解耦训练是互补的。解耦训练的方案在概念上很简单，可以很容易地用于设计解决实际长尾应用的新方法。此外，基于集成的方法，由于聚合了多个专家，能够在不牺牲任何类别子集（*例如*，头部类别）的性能的情况下实现更好的长尾性能。由于所有类别都很重要，这种优越性使得基于集成的方法相比现有的类别重平衡方法（通常在牺牲头部类别性能的情况下提高尾部类别性能）成为实际应用中的更好选择。这里，基于集成的方法和解耦训练都需要特定的模型训练和设计方式，因此除非非常仔细设计，否则将它们一起使用并不容易。
- en: Note that most module improvement methods are developed based on fundamental
    class re-balancing methods. Moreover, module improvement methods are complementary
    to information augmentation methods. Using them together can usually achieve better
    performance for real-world long-tailed applications.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，大多数模块改进方法是基于基础的类别重平衡方法开发的。此外，模块改进方法与信息增强方法是互补的。将它们结合使用通常可以在实际的长尾应用中获得更好的性能。
- en: 4 Empirical Studies
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实证研究
- en: This section empirically analyzes existing long-tailed learning methods. To
    begin with, we introduce a new evaluation metric.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 本节从经验上分析现有的长尾学习方法。首先，我们介绍一种新的评估指标。
- en: 4.1 Novel Evaluation Metric
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 新颖评估指标
- en: The key goal of long-tailed learning is to handle the class imbalance for better
    model performance. Therefore, the common evaluation protocol [[22](#bib.bib22),
    [13](#bib.bib13)] is directly using the top-1 test accuracy (denoted by $A_{t}$)
    to judge how well long-tailed methods perform and which method handles class imbalance
    better. Such a metric, however, cannot accurately reflect the relative superiority
    among different methods when handling class imbalance, as the top-1 accuracy is
    also influenced by other factors apart from class imbalance. For example, long-tailed
    methods like ensemble learning (or data augmentation) also improve the performance
    of models, trained on a balanced training set. In such cases, it is hard to tell
    if the performance gain is from the alleviation of class imbalance or from better
    network architectures (or more data information).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 长尾学习的主要目标是处理类别不平衡，以提高模型性能。因此，常见的评估协议[[22](#bib.bib22), [13](#bib.bib13)]直接使用
    top-1 测试准确率（用 $A_{t}$ 表示）来判断长尾方法的效果以及哪种方法更好地处理类别不平衡。然而，这种指标不能准确反映不同方法在处理类别不平衡时的相对优越性，因为
    top-1 准确率还受其他因素的影响，比如类别不平衡之外的因素。例如，像集成学习（或数据增强）这样的长尾方法也能提高在平衡训练集上训练的模型的性能。在这种情况下，很难判断性能提升是来源于缓解类别不平衡，还是来自于更好的网络架构（或更多的数据信息）。
- en: To better evaluate the method effectiveness in handling class imbalance, we
    explore a new metric, namely relative accuracy $A_{r}$, to alleviate the influence
    of unnecessary factors in long-tailed learning. To this end, we first compute
    an empirically upper reference accuracy $A_{u}=\max(A_{v},A_{b})$, which is the
    maximal value between the *vanilla accuracy* $A_{v}$ of the backbone trained on
    a balanced training set with cross-entropy and the *balanced accuracy* $A_{b}$
    of the model trained on a balanced training set with the corresponding long-tailed
    method. Here, the balanced training set is *a variant of the long-tailed training
    set, where the total data number is similar but each class has the same number
    of data*. This upper reference accuracy, obtained from the balanced training set,
    is used to alleviate the influence apart from class imbalance, and then the *relative
    accuracy* is defined by $A_{r}=\frac{A_{t}}{A_{u}}$. Note that this metric is
    mainly designed for empirical understanding, *i.e.,* to evaluate to what extent
    existing methods resolve the class imbalance. We conduct this analysis based on
    the ImageNet-LT dataset [[15](#bib.bib15)], where a corresponding balanced training
    set variant can be built by sampling from the original ImageNet following [[13](#bib.bib13)].
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地评估方法在处理类别不平衡方面的有效性，我们探索了一种新度量，即相对准确率 $A_{r}$，以减轻长尾学习中不必要因素的影响。为此，我们首先计算一个经验上限参考准确率
    $A_{u}=\max(A_{v},A_{b})$，这是 *vanilla accuracy* $A_{v}$（在平衡训练集上使用交叉熵训练的骨干网络的准确率）和
    *balanced accuracy* $A_{b}$（在平衡训练集上使用相应长尾方法训练的模型的准确率）之间的最大值。这里，平衡训练集是 *长尾训练集的一种变体，其中总数据量相似但每个类别的数据量相同*。从平衡训练集中获得的这个上限参考准确率，用于减轻类别不平衡之外的影响，然后
    *相对准确率* 定义为 $A_{r}=\frac{A_{t}}{A_{u}}$。请注意，这一度量主要用于实证理解，即评估现有方法在多大程度上解决了类别不平衡问题。我们基于
    ImageNet-LT 数据集 [[15](#bib.bib15)] 进行此分析，其中可以通过从原始 ImageNet 中采样来构建相应的平衡训练集变体，参考
    [[13](#bib.bib13)]。
- en: 4.2 Experimental Settings
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 实验设置
- en: We then introduce the experimental settings.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们介绍实验设置。
- en: 'Datasets. We adopt the widely-used ImageNet-LT [[15](#bib.bib15)] and iNaturalist
    2018 [[23](#bib.bib23)] as the benchmark long-tailed dataset for empirical studies.
    Their dataset statistics can be found in Table [I](#S2.T1 "TABLE I ‣ 2.1 Problem
    Definition ‣ 2 Problem Overview ‣ Deep Long-Tailed Learning: A Survey"). Besides
    the performance regarding all classes, we also report performance on three class
    subsets: Head (more than 100 images), Middle (20$\sim$100 images) and Tail (less
    than 20 images).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '数据集。我们采用广泛使用的 ImageNet-LT [[15](#bib.bib15)] 和 iNaturalist 2018 [[23](#bib.bib23)]
    作为用于实证研究的基准长尾数据集。它们的数据集统计信息可以在表格 [I](#S2.T1 "TABLE I ‣ 2.1 Problem Definition
    ‣ 2 Problem Overview ‣ Deep Long-Tailed Learning: A Survey") 中找到。除了所有类别的性能外，我们还报告了三个类别子集的性能：头部（超过
    100 张图像）、中部（20$\sim$100 张图像）和尾部（少于 20 张图像）。'
- en: 'Baselines. We select long-tailed methods via two criteria: (1) the source codes
    are publicly available or easy to re-implement; (2) the methods are evaluated
    on ImageNet-LT in the corresponding papers. As a result, more than 20 methods
    are empirically evaluated in this paper, including baseline (Softmax), class-sensitive
    learning (Weighted Softmax, Focal loss [[54](#bib.bib54)], LDAM [[18](#bib.bib18)],
    ESQL [[19](#bib.bib19)], Balanced Softmax [[97](#bib.bib97)], LADE [[31](#bib.bib31)]),
    logit adjustment (UNO-IC [[99](#bib.bib99)]), transfer learning (SSP [[102](#bib.bib102)]),
    data augmentation (RSG [[118](#bib.bib118)]) representation learning (OLTR [[15](#bib.bib15)],
    PaCo [[121](#bib.bib121)]). classifier design (De-confound [[45](#bib.bib45)]),
    decoupled training (Decouple-IB-CRT [[32](#bib.bib32)], CB-CRT [[32](#bib.bib32)],
    SR-CRT [[32](#bib.bib32)], PB-CRT [[32](#bib.bib32)], MiSLAS [[114](#bib.bib114)]),
    ensemble learning (BBN [[44](#bib.bib44)], LFME [[103](#bib.bib103)], RIDE [[17](#bib.bib17)],
    ResLT [[125](#bib.bib125)], SADE [[30](#bib.bib30)]).'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 基线。我们通过两个标准选择长尾方法：（1）源代码公开或易于重新实现；（2）方法在相关论文中在 ImageNet-LT 上进行了评估。因此，本文实证评估了
    20 多种方法，包括基线（Softmax）、类敏感学习（加权 Softmax、焦点损失 [[54](#bib.bib54)]、LDAM [[18](#bib.bib18)]、ESQL
    [[19](#bib.bib19)]、平衡 Softmax [[97](#bib.bib97)]、LADE [[31](#bib.bib31)]）、对数调整（UNO-IC
    [[99](#bib.bib99)]）、迁移学习（SSP [[102](#bib.bib102)]）、数据增强（RSG [[118](#bib.bib118)]）、表示学习（OLTR
    [[15](#bib.bib15)]、PaCo [[121](#bib.bib121)]）、分类器设计（De-confound [[45](#bib.bib45)]）、解耦训练（Decouple-IB-CRT
    [[32](#bib.bib32)]、CB-CRT [[32](#bib.bib32)]、SR-CRT [[32](#bib.bib32)]、PB-CRT
    [[32](#bib.bib32)]、MiSLAS [[114](#bib.bib114)]）、集成学习（BBN [[44](#bib.bib44)]、LFME
    [[103](#bib.bib103)]、RIDE [[17](#bib.bib17)]、ResLT [[125](#bib.bib125)]、SADE [[30](#bib.bib30)]]。
- en: Implementation details. We implement all experiments in PyTorch. Following [[31](#bib.bib31),
    [17](#bib.bib17), [32](#bib.bib32)], we use ResNeXt-50 for ImageNet-LT and and
    ResNet-50 for iNaturalist 2018 as the network backbones for all methods. We conduct
    model training with the SGD optimizer based on batch size 256, momentum 0.9 and
    weight decay factor 0.0005, and learning rate 0.1 (linear LR decay). For method-related
    hyper-parameters, we set the values by either directly following the original
    papers or manual tuning if the default values perform poorly. Moreover, we use
    the same basic data augmentation (*i.e.,* random resize and crop to 224, random
    horizontal flip, color jitter, and normalization) for all methods.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 实施细节。我们在 PyTorch 中实现了所有实验。根据 [[31](#bib.bib31), [17](#bib.bib17), [32](#bib.bib32)]，我们为
    ImageNet-LT 使用 ResNeXt-50，为 iNaturalist 2018 使用 ResNet-50 作为所有方法的网络骨干。我们使用 SGD
    优化器进行模型训练，批量大小 256，动量 0.9，权重衰减因子 0.0005，学习率 0.1（线性 LR 衰减）。对于与方法相关的超参数，我们要么直接遵循原始论文中的值，要么在默认值表现不佳时进行手动调整。此外，我们对所有方法使用相同的基本数据增强，*即*，随机调整大小并裁剪到
    224，随机水平翻转，颜色抖动和归一化。
- en: 4.3 Results on ImageNet-LT
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 ImageNet-LT 结果
- en: 'Observations on all classes. Table [V](#S4.T5 "TABLE V ‣ 4.3 Results on ImageNet-LT
    ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey") and Fig. [4](#S4.F4
    "Figure 4 ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed
    Learning: A Survey") report the average performance of ImageNet-LT over all classes.
    From these results, we have several observations on the overall method progress
    and different method types. As shown in Table [V](#S4.T5 "TABLE V ‣ 4.3 Results
    on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey"),
    almost all long-tailed methods perform better than the Softmax baseline in terms
    of accuracy, which demonstrates the effectiveness of long-tailed learning. Even
    so, there are two methods performing slightly worse than Softmax, *i.e.,* Decouple-CB-CRT [[32](#bib.bib32)]
    and BBN [[44](#bib.bib44)]. We speculate that the poor performance of Decouple-CB-CRT
    results from poor representation learning by class-balanced sampling in the first
    stage of decoupled training (refer to [[32](#bib.bib32)] for more empirical observations).
    The poor results of BBN (based on the official codes) may come from the cumulative
    learning strategy, which gradually adjusts the learning focus from head classes
    to tail classes; at the end of the training, however, it may put too much focus
    on the tail ones. As a result, despite the better tail-class performance, the
    model accuracy on head classes drops significantly (c.f. Table [V](#S4.T5 "TABLE
    V ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning:
    A Survey")), leading to worse average performance.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '关于所有类别的观察。表格 [V](#S4.T5 "TABLE V ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical
    Studies ‣ Deep Long-Tailed Learning: A Survey") 和图 Fig. [4](#S4.F4 "Figure 4 ‣
    4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning:
    A Survey") 报告了 ImageNet-LT 在所有类别上的平均性能。从这些结果中，我们对整体方法进展和不同方法类型有若干观察。如表格 [V](#S4.T5
    "TABLE V ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed
    Learning: A Survey") 所示，几乎所有长尾方法在准确性方面均优于 Softmax 基线，这表明了长尾学习的有效性。即便如此，有两种方法的表现稍逊于
    Softmax，*即*，Decouple-CB-CRT [[32](#bib.bib32)] 和 BBN [[44](#bib.bib44)]。我们推测 Decouple-CB-CRT
    表现不佳的原因是第一阶段的类别平衡采样导致的表示学习不佳（更多实证观察请参见 [[32](#bib.bib32)]）。BBN（基于官方代码）的差劲结果可能源于逐步调整学习焦点从头部类别到尾部类别的累积学习策略；然而，在训练结束时，可能过分关注尾部类别。结果是，尽管尾部类别的表现更好，但头部类别的模型准确性显著下降（参见表格 [V](#S4.T5
    "TABLE V ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed
    Learning: A Survey")），导致平均性能更差。'
- en: 'In addition to accuracy, we also evaluate long-tailed methods based on upper
    reference accuracy (UA) and relative accuracy (RA). Table [V](#S4.T5 "TABLE V
    ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning:
    A Survey") shows that most methods have the same UA as the baseline model, but
    there are still some methods having higher UA, *e.g.,* SSP, MiSLAS, and SADE.
    For these methods, the performance improvement comes not only from the alleviation
    of class imbalance, but also from other factors, like data augmentation or better
    network architectures. Therefore, simply using accuracy for evaluation is not
    comprehensive enough, while the proposed RA metric provides a good complement
    as it alleviates the influences of factors apart from class imbalance. For example,
    MiSLAS, based on data mixup, has higher accuracy than Balanced Softmax under 90
    training epochs, but it also has higher UA. As a result, the relative accuracy
    of MiSLAS is lower than Balanced Softmax, which means that Balanced Softmax alleviates
    class imbalance better than MiSLAS under 90 training epochs.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '除了准确率，我们还基于上界参考准确率（UA）和相对准确率（RA）评估长尾方法。表[V](#S4.T5 "TABLE V ‣ 4.3 Results on
    ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey")显示，大多数方法的
    UA 与基线模型相同，但仍有一些方法的 UA 较高，如SSP、MiSLAS 和 SADE。对于这些方法，性能的提升不仅来自于缓解类别不平衡，还来自于其他因素，如数据增强或更好的网络架构。因此，单纯使用准确率进行评估并不全面，而提出的
    RA 指标则提供了良好的补充，因为它缓解了除了类别不平衡之外的其他因素的影响。例如，基于数据混合的 MiSLAS 在 90 次训练周期下的准确率高于 Balanced
    Softmax，但其 UA 也较高。因此，MiSLAS 的相对准确率低于 Balanced Softmax，这意味着 Balanced Softmax 在
    90 次训练周期下比 MiSLAS 更好地缓解了类别不平衡。'
- en: 'Although some recent high-accuracy methods have lower RA, the overall development
    trend of long-tailed learning is still positive, as shown in Fig. [4](#S4.F4 "Figure
    4 ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning:
    A Survey"). Such a performance trend demonstrates that recent studies of long-tailed
    learning make real progress. Moreover, the RA of the state-of-the-art SADE is
    93.0, which implies that there is still room for improvement in the future.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管一些近期高准确率的方法 RA 较低，但长尾学习的整体发展趋势仍然积极，如图[4](#S4.F4 "Figure 4 ‣ 4.3 Results on
    ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey")所示。这种性能趋势表明，近期的长尾学习研究取得了实质性的进展。此外，最先进的
    SADE 的 RA 为 93.0，这意味着未来仍有提升的空间。'
- en: 'TABLE IV: Results on ImageNet-LT in terms of accuracy (Acc), upper reference
    accuracy (UA), relative accuracy (RA) under 90 or 200 training epochs. In this
    table, CR, IA and MI indicate class re-balancing, information augmentation and
    module improvement, respectively.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 表 IV：在 ImageNet-LT 上的准确率（Acc）、上界参考准确率（UA）、在 90 或 200 次训练周期下的相对准确率（RA）结果。在此表中，CR、IA
    和 MI 分别表示类别重平衡、信息增强和模块改进。
- en: '| Type | Method | 90 epochs |  | 200 epochs |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 方法 | 90 周期 |  | 200 周期 |'
- en: '| Acc | UA | RA |  | Acc | UA | RA |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| Acc | UA | RA |  | Acc | UA | RA |'
- en: '| Baseline | Softmax | 45.5 | 57.3 | 79.4 |  | 46.8 | 57.8 | 81.0 |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 基线 | Softmax | 45.5 | 57.3 | 79.4 |  | 46.8 | 57.8 | 81.0 |'
- en: '| CR | Weighted Softmax | 47.9 | 57.3 | 83.6 |  | 49.1 | 57.8 | 84.9 |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| CR | 加权 Softmax | 47.9 | 57.3 | 83.6 |  | 49.1 | 57.8 | 84.9 |'
- en: '| Focal loss [[54](#bib.bib54)] | 45.8 | 57.3 | 79.9 |  | 47.2 | 57.8 | 81.7
    |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| Focal loss [[54](#bib.bib54)] | 45.8 | 57.3 | 79.9 |  | 47.2 | 57.8 | 81.7
    |'
- en: '| LDAM [[18](#bib.bib18)] | 51.1 | 57.3 | 89.2 |  | 51.1 | 57.8 | 88.4 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| LDAM [[18](#bib.bib18)] | 51.1 | 57.3 | 89.2 |  | 51.1 | 57.8 | 88.4 |'
- en: '| ESQL [[19](#bib.bib19)] | 47.3 | 57.3 | 82.5 |  | 48.0 | 57.8 | 83.0 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| ESQL [[19](#bib.bib19)] | 47.3 | 57.3 | 82.5 |  | 48.0 | 57.8 | 83.0 |'
- en: '| UNO-IC [[99](#bib.bib99)] | 45.7 | 57.3 | 81.4 |  | 46.8 | 58.6 | 79.9 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| UNO-IC [[99](#bib.bib99)] | 45.7 | 57.3 | 81.4 |  | 46.8 | 58.6 | 79.9 |'
- en: '| Balanced Softmax [[97](#bib.bib97)] | 50.8 | 57.3 | 88.7 |  | 51.2 | 57.8
    | 88.6 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| Balanced Softmax [[97](#bib.bib97)] | 50.8 | 57.3 | 88.7 |  | 51.2 | 57.8
    | 88.6 |'
- en: '| LADE [[31](#bib.bib31)] | 51.5 | 57.8 | 89.1 |  | 51.6 | 57.8 | 89.3 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| LADE [[31](#bib.bib31)] | 51.5 | 57.8 | 89.1 |  | 51.6 | 57.8 | 89.3 |'
- en: '| IA | SSP [[102](#bib.bib102)] | 53.1 | 59.6 | 89.1 |  | 53.3 | 59.9 | 89.0
    |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| IA | SSP [[102](#bib.bib102)] | 53.1 | 59.6 | 89.1 |  | 53.3 | 59.9 | 89.0
    |'
- en: '| RSG [[118](#bib.bib118)] | 49.6 | 57.3 | 86.7 |  | 52.9 | 57.8 | 91.5 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| RSG [[118](#bib.bib118)] | 49.6 | 57.3 | 86.7 |  | 52.9 | 57.8 | 91.5 |'
- en: '| MI | OLTR [[15](#bib.bib15)] | 46.7 | 57.3 | 81.5 |  | 48.0 | 58.4 | 82.2
    |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| MI | OLTR [[15](#bib.bib15)] | 46.7 | 57.3 | 81.5 |  | 48.0 | 58.4 | 82.2
    |'
- en: '| PaCo [[121](#bib.bib121)] | 52.7 | 58.7 | 89.9 |  | 54.4 | 59.6 | 91.3 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| PaCo [[121](#bib.bib121)] | 52.7 | 58.7 | 89.9 |  | 54.4 | 59.6 | 91.3 |'
- en: '| De-confound [[45](#bib.bib45)] | 51.8 | 57.7 | 89.8 |  | 51.3 | 57.8 | 88.8
    |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| De-confound [[45](#bib.bib45)] | 51.8 | 57.7 | 89.8 |  | 51.3 | 57.8 | 88.8
    |'
- en: '| Decouple-IB-CRT [[32](#bib.bib32)] | 49.9 | 57.3 | 87.1 |  | 50.3 | 58.1
    | 86.6 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| Decouple-IB-CRT [[32](#bib.bib32)] | 49.9 | 57.3 | 87.1 |  | 50.3 | 58.1
    | 86.6 |'
- en: '| Decouple-CB-CRT [[32](#bib.bib32)] | 44.9 | 57.3 | 78.4 |  | 43.0 | 57.8
    | 74.4 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| Decouple-CB-CRT [[32](#bib.bib32)] | 44.9 | 57.3 | 78.4 |  | 43.0 | 57.8
    | 74.4 |'
- en: '| Decouple-SR-CRT [[32](#bib.bib32)] | 49.3 | 57.3 | 86.0 |  | 48.5 | 57.8
    | 83.9 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| Decouple-SR-CRT [[32](#bib.bib32)] | 49.3 | 57.3 | 86.0 |  | 48.5 | 57.8
    | 83.9 |'
- en: '| Decouple-PB-CRT [[32](#bib.bib32)] | 48.4 | 57.3 | 84.5 |  | 48.1 | 57.8
    | 83.2 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| Decouple-PB-CRT [[32](#bib.bib32)] | 48.4 | 57.3 | 84.5 |  | 48.1 | 57.8
    | 83.2 |'
- en: '| MiSLAS [[114](#bib.bib114)] | 51.4 | 58.3 | 88.2 |  | 53.4 | 59.7 | 89.4
    |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| MiSLAS [[114](#bib.bib114)] | 51.4 | 58.3 | 88.2 |  | 53.4 | 59.7 | 89.4
    |'
- en: '| BBN [[44](#bib.bib44)] | 41.2 | 57.3 | 71.9 |  | 44.7 | 57.8 | 77.3 |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| BBN [[44](#bib.bib44)] | 41.2 | 57.3 | 71.9 |  | 44.7 | 57.8 | 77.3 |'
- en: '| LFME [[103](#bib.bib103)] | 47.0 | 57.3 | 82.0 |  | 48.0 | 57.8 | 83.0 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| LFME [[103](#bib.bib103)] | 47.0 | 57.3 | 82.0 |  | 48.0 | 57.8 | 83.0 |'
- en: '| ResLT [[125](#bib.bib125)] | 51.6 | 57.3 | 90.1 |  | 53.2 | 58.1 | 91.6 |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| ResLT [[125](#bib.bib125)] | 51.6 | 57.3 | 90.1 |  | 53.2 | 58.1 | 91.6 |'
- en: '| RIDE [[17](#bib.bib17)] | 55.5 | 60.2 | 92.2 |  | 56.1 | 60.9 | 92.1 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| RIDE [[17](#bib.bib17)] | 55.5 | 60.2 | 92.2 |  | 56.1 | 60.9 | 92.1 |'
- en: '| SADE [[30](#bib.bib30)] | 57.3 | 61.9 | 92.6 |  | 58.8 | 63.2 | 93.0 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| SADE [[30](#bib.bib30)] | 57.3 | 61.9 | 92.6 |  | 58.8 | 63.2 | 93.0 |'
- en: 'TABLE V: Accuracy results on ImageNet-LT regarding head, middle and tail classes
    under 90 or 200 training epochs. In this table, WS indicates weighed softmax and
    BS indicates balanced softmax. The types of methods are the same to Table [V](#S4.T5
    "TABLE V ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed
    Learning: A Survey").'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 'TABLE V: 关于头部、中部和尾部类别在90或200训练周期下的ImageNet-LT准确性结果。在此表中，WS表示加权softmax，BS表示平衡softmax。方法类型与表[V](#S4.T5
    "TABLE V ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed
    Learning: A Survey")相同。'
- en: '| Method | 90 epochs |  | 200 epochs |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 90 epochs |  | 200 epochs |'
- en: '| Head | Middle | Tail |  | Head | Middle | Tail |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 头部 | 中部 | 尾部 |  | 头部 | 中部 | 尾部 |'
- en: '| Softmax | 66.5 | 39.0 | 8.6 |  | 66.9 | 40.4 | 12.6 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| Softmax | 66.5 | 39.0 | 8.6 |  | 66.9 | 40.4 | 12.6 |'
- en: '| WS | 66.3 | 42.2 | 15.6 |  | 57.9 | 46.2 | 34.0 |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| WS | 66.3 | 42.2 | 15.6 |  | 57.9 | 46.2 | 34.0 |'
- en: '| Focal loss [[54](#bib.bib54)] | 66.9 | 39.2 | 9.2 |  | 67.0 | 41.0 | 13.1
    |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| Focal loss [[54](#bib.bib54)] | 66.9 | 39.2 | 9.2 |  | 67.0 | 41.0 | 13.1
    |'
- en: '| LDAM [[18](#bib.bib18)] | 62.3 | 47.4 | 32.5 |  | 60.0 | 49.2 | 31.9 |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| LDAM [[18](#bib.bib18)] | 62.3 | 47.4 | 32.5 |  | 60.0 | 49.2 | 31.9 |'
- en: '| ESQL [[19](#bib.bib19)] | 62.5 | 44.0 | 15.7 |  | 63.1 | 44.6 | 17.2 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| ESQL [[19](#bib.bib19)] | 62.5 | 44.0 | 15.7 |  | 63.1 | 44.6 | 17.2 |'
- en: '| UNO-IC [[99](#bib.bib99)] | 66.3 | 38.7 | 9.3 |  | 67.0 | 40.3 | 12.7 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| UNO-IC [[99](#bib.bib99)] | 66.3 | 38.7 | 9.3 |  | 67.0 | 40.3 | 12.7 |'
- en: '| BS [[97](#bib.bib97)] | 61.7 | 48.0 | 29.9 |  | 62.4 | 47.7 | 32.1 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| BS [[97](#bib.bib97)] | 61.7 | 48.0 | 29.9 |  | 62.4 | 47.7 | 32.1 |'
- en: '| LADE [[31](#bib.bib31)] | 62.2 | 48.6 | 31.8 |  | 63.1 | 47.7 | 32.7 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| LADE [[31](#bib.bib31)] | 62.2 | 48.6 | 31.8 |  | 63.1 | 47.7 | 32.7 |'
- en: '| SSP [[102](#bib.bib102)] | 65.6 | 49.6 | 30.3 |  | 67.3 | 49.1 | 28.3 |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| SSP [[102](#bib.bib102)] | 65.6 | 49.6 | 30.3 |  | 67.3 | 49.1 | 28.3 |'
- en: '| RSG [[118](#bib.bib118)] | 68.7 | 43.7 | 16.2 |  | 65.0 | 49.4 | 31.1 |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| RSG [[118](#bib.bib118)] | 68.7 | 43.7 | 16.2 |  | 65.0 | 49.4 | 31.1 |'
- en: '| OLTR [[15](#bib.bib15)] | 58.2 | 45.5 | 19.5 |  | 62.9 | 44.6 | 18.8 |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| OLTR [[15](#bib.bib15)] | 58.2 | 45.5 | 19.5 |  | 62.9 | 44.6 | 18.8 |'
- en: '| PaCo [[121](#bib.bib121)] | 59.7 | 51.7 | 36.6 |  | 63.2 | 51.6 | 39.2 |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| PaCo [[121](#bib.bib121)] | 59.7 | 51.7 | 36.6 |  | 63.2 | 51.6 | 39.2 |'
- en: '| De-confound [[45](#bib.bib45)] | 63.0 | 48.5 | 31.4 |  | 64.9 | 46.9 | 28.1
    |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| De-confound [[45](#bib.bib45)] | 63.0 | 48.5 | 31.4 |  | 64.9 | 46.9 | 28.1
    |'
- en: '| IB-CRT [[32](#bib.bib32)] | 62.6 | 46.2 | 26.7 |  | 64.2 | 46.1 | 26.0 |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| IB-CRT [[32](#bib.bib32)] | 62.6 | 46.2 | 26.7 |  | 64.2 | 46.1 | 26.0 |'
- en: '| CB-CRT [[32](#bib.bib32)] | 62.4 | 39.3 | 14.9 |  | 60.9 | 36.9 | 13.5 |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| CB-CRT [[32](#bib.bib32)] | 62.4 | 39.3 | 14.9 |  | 60.9 | 36.9 | 13.5 |'
- en: '| SR-CRT [[32](#bib.bib32)] | 64.1 | 43.9 | 19.5 |  | 66.0 | 42.3 | 18.0 |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| SR-CRT [[32](#bib.bib32)] | 64.1 | 43.9 | 19.5 |  | 66.0 | 42.3 | 18.0 |'
- en: '| PB-CRT [[32](#bib.bib32)] | 63.9 | 45.0 | 23.2 |  | 64.9 | 43.1 | 20.6 |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| PB-CRT [[32](#bib.bib32)] | 63.9 | 45.0 | 23.2 |  | 64.9 | 43.1 | 20.6 |'
- en: '| MiSLAS [[114](#bib.bib114)] | 62.1 | 48.9 | 32.6 |  | 65.3 | 50.6 | 33.0
    |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| MiSLAS [[114](#bib.bib114)] | 62.1 | 48.9 | 32.6 |  | 65.3 | 50.6 | 33.0
    |'
- en: '| BBN [[44](#bib.bib44)] | 40.0 | 43.3 | 40.8 |  | 43.3 | 45.9 | 43.7 |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| BBN [[44](#bib.bib44)] | 40.0 | 43.3 | 40.8 |  | 43.3 | 45.9 | 43.7 |'
- en: '| LFME [[103](#bib.bib103)] | 60.6 | 43.5 | 22.0 |  | 64.1 | 42.3 | 22.8 |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| LFME [[103](#bib.bib103)] | 60.6 | 43.5 | 22.0 |  | 64.1 | 42.3 | 22.8 |'
- en: '| ResLT [[125](#bib.bib125)] | 57.8 | 50.4 | 40.0 |  | 61.6 | 51.4 | 38.8 |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| ResLT [[125](#bib.bib125)] | 57.8 | 50.4 | 40.0 |  | 61.6 | 51.4 | 38.8 |'
- en: '| RIDE [[17](#bib.bib17)] | 66.9 | 52.3 | 34.5 |  | 67.9 | 52.3 | 36.0 |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| RIDE [[17](#bib.bib17)] | 66.9 | 52.3 | 34.5 |  | 67.9 | 52.3 | 36.0 |'
- en: '| SADE [[30](#bib.bib30)] | 65.3 | 55.2 | 42.0 |  | 67.2 | 55.3 | 40.0 |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| SADE [[30](#bib.bib30)] | 65.3 | 55.2 | 42.0 |  | 67.2 | 55.3 | 40.0 |'
- en: '![Refer to caption](img/e1d02f7697496381952de5472ba2bfa2.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e1d02f7697496381952de5472ba2bfa2.png)'
- en: 'Figure 4: Performance trends of long-tailed learning methods in terms of accuracy
    and relative accuracy under 200 epochs. Here, the shape of $\circ$ indicates the
    softmax baseline; $\square$ indicates class re-balancing; $\bigtriangleup$ and
    $\diamondsuit$ are information augmentation and module improvement methods, respectively.
    Different colors represent different methods.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：在 200 个周期下，长尾学习方法的准确率和相对准确率的性能趋势。在这里，$\circ$ 的形状表示 softmax 基线；$\square$
    表示类别重新平衡；$\bigtriangleup$ 和 $\diamondsuit$ 分别表示信息增强和模块改进方法。不同的颜色代表不同的方法。
- en: 'We also evaluate the influence of different training epochs (*i.e.,* 90 and
    200) in Table [V](#S4.T5 "TABLE V ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies
    ‣ Deep Long-Tailed Learning: A Survey"). Overall, training with 200 epochs leads
    to better performance for most long-tailed methods, because sufficient training
    enables deep models to fit data better and learn better visual representations.
    However, there are also some methods that perform better when only training 90
    epochs, *e.g.,* De-confound and Decouple-CB-CRT. We speculate that, for these
    methods, 90 epochs are enough to train models well, while training more epochs
    does not bring additional benefits but increases the training difficulties since
    it also influences the learning rate decay scheme.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '我们还评估了不同训练周期（*即*，90 和 200）的影响，见表格 [V](#S4.T5 "TABLE V ‣ 4.3 Results on ImageNet-LT
    ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey")。总体而言，训练 200 个周期对于大多数长尾方法而言性能更好，因为充足的训练使深度模型能够更好地拟合数据并学习更好的视觉表示。然而，也有一些方法在仅训练
    90 个周期时表现更好，例如，**De-confound** 和 **Decouple-CB-CRT**。我们推测，对于这些方法，90 个周期足以训练模型，而更多的训练周期不会带来额外的好处，反而增加了训练难度，因为这也影响了学习率衰减方案。'
- en: 'Observations on different method types. We next analyze different method types
    in Table [V](#S4.T5 "TABLE V ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies
    ‣ Deep Long-Tailed Learning: A Survey"). To begin with, almost all class re-balancing
    (CR) methods all beneficial to long-tailed learning performance, compared to the
    baseline model. Among them, LADE, Balanced Softmax and LDAM achieve state-of-the-art.
    Moreover, Focal loss was initially proposed to handle object detection [[54](#bib.bib54)].
    However, when handling a highly large number of classes (*e.g.,* 1,000 in ImageNet-LT),
    Focal loss cannot perform well and only leads to marginal improvement. In LDAM,
    there is a deferred re-balancing optimization schedule in addition to the LDAM
    loss. Simply learning with the LDAM loss without the deferred scheme cannot achieve
    promising results. In addition, as shown in Table [V](#S4.T5 "TABLE V ‣ 4.3 Results
    on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey"),
    the upper reference accuracy of most class-sensitive methods is the same, so their
    relative accuracy is positively correlated to accuracy. Hence, the accuracy improvement
    in this method type can accurately reflect the alleviation of class imbalance.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '对不同方法类型的观察。接下来我们分析了表格 [V](#S4.T5 "TABLE V ‣ 4.3 Results on ImageNet-LT ‣ 4
    Empirical Studies ‣ Deep Long-Tailed Learning: A Survey")中的不同方法类型。首先，几乎所有的类别重新平衡（CR）方法都对长尾学习性能有益，相较于基线模型。其中，**LADE**、**Balanced
    Softmax** 和 **LDAM** 达到了最先进的水平。此外，**Focal loss** 最初是为了处理目标检测而提出的 [[54](#bib.bib54)]。然而，在处理大量类别（*例如*，ImageNet-LT
    中的 1,000 类）时，**Focal loss** 的表现并不好，仅带来边际改进。在 **LDAM** 中，除了 **LDAM** 损失之外，还有一个延期的重新平衡优化计划。仅使用
    **LDAM** 损失而没有延期方案无法实现理想的结果。此外，如表格 [V](#S4.T5 "TABLE V ‣ 4.3 Results on ImageNet-LT
    ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey")所示，大多数类别敏感方法的上限参考准确率相同，因此它们的相对准确率与准确性正相关。因此，这种方法类型中的准确性提高可以准确反映类别不平衡的缓解情况。'
- en: In information augmentation (IA), both SSP (transfer learning) and RSG (data
    augmentation) help to handle long-tailed imbalance. Although SSP also improves
    upper reference accuracy, its relative accuracy is increased more significantly,
    implying that the performance gain mostly comes from handling the class imbalance.
    In module improvement (MI), all methods contribute to addressing the imbalance.
    By now, the state of the art is ensemble-based long-tailed methods, *i.e.,* SADE
    and RIDE, in terms of both accuracy and relative accuracy. Although ensemble learning
    also improves upper reference accuracy, the performance gain from handling imbalance
    is more significant, leading to higher relative accuracy.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在信息增强 (IA) 中，SSP（迁移学习）和 RSG（数据增强）都有助于处理长尾不平衡。尽管 SSP 也提高了上参考准确度，但它的相对准确度增加更显著，表明性能增益主要来自处理类别不平衡。在模块改进
    (MI) 中，所有方法都有助于解决不平衡问题。截至目前，基于集成的长尾方法，*即* SADE 和 RIDE，在准确度和相对准确度方面都是最先进的。尽管集成学习也提高了上参考准确度，但处理不平衡问题带来的性能增益更为显著，导致更高的相对准确度。
- en: 'Results on different class subsets. We then report the performance in terms
    of different class subsets. As shown in Table [V](#S4.T5 "TABLE V ‣ 4.3 Results
    on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey"),
    almost all methods improve tail-class and middle-class performance at the cost
    of lower head-class performance. The head classes, however, are also important
    in long-tailed learning, so it is necessary to improve long-tailed performance
    without sacrificing the performance of the head. Potential solutions include information
    augmentation and ensemble learning, *e.g.,* SSP and SADE. By comparing both Tables [V](#S4.T5
    "TABLE V ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed
    Learning: A Survey") and [V](#S4.T5 "TABLE V ‣ 4.3 Results on ImageNet-LT ‣ 4
    Empirical Studies ‣ Deep Long-Tailed Learning: A Survey"), one can find that the
    overall performance gain largely depends on the improvement of middle and tail
    classes; hence, how to improve their performance is still the most important goal
    of long-tailed learning in the future.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '对不同类别子集的结果。然后我们报告了不同类别子集的表现。如表[V](#S4.T5 "TABLE V ‣ 4.3 Results on ImageNet-LT
    ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey")所示，几乎所有方法在牺牲头部类别表现的情况下提高了尾部类别和中间类别的性能。然而，头部类别在长尾学习中也很重要，因此有必要在不牺牲头部性能的情况下提高长尾性能。潜在的解决方案包括信息增强和集成学习，*例如*
    SSP 和 SADE。通过比较表[V](#S4.T5 "TABLE V ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical
    Studies ‣ Deep Long-Tailed Learning: A Survey")和表[V](#S4.T5 "TABLE V ‣ 4.3 Results
    on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey")，可以发现整体性能增益在很大程度上取决于中部和尾部类别的改进；因此，如何提高它们的性能仍然是未来长尾学习的最重要目标。'
- en: 'By now, SADE [[30](#bib.bib30)] achieves the best overall performance in terms
    of accuracy and RA (c.f. Table [V](#S4.T5 "TABLE V ‣ 4.3 Results on ImageNet-LT
    ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey")), but SADE does
    not perform state-of-the-art on all class subsets (c.f. Table [V](#S4.T5 "TABLE
    V ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning:
    A Survey")). For example, when training 200 epochs, the head-class performance
    of SADE is worse than RIDE and its tail-class performance is worse than BBN. To
    summarize, the higher average performance of SADE implies that the key to obtaining
    better long-tailed performance is a better trade-off among all classes. In summary,
    the current best practice for deep long-tailed learning is using ensemble learning
    and class re-balancing, simultaneously.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '到目前为止，SADE [[30](#bib.bib30)] 在准确度和 RA 方面取得了最佳整体性能（参见表[V](#S4.T5 "TABLE V ‣
    4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning:
    A Survey")），但 SADE 并不在所有类别子集上表现最先进（参见表[V](#S4.T5 "TABLE V ‣ 4.3 Results on ImageNet-LT
    ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey")）。例如，当训练200个周期时，SADE
    的头部类别表现比 RIDE 更差，其尾部类别表现比 BBN 更差。总而言之，SADE 的较高平均表现意味着获得更好长尾性能的关键是在所有类别之间取得更好的折衷。总之，目前深度长尾学习的最佳实践是同时使用集成学习和类别再平衡。'
- en: 'TABLE VI: Results on iNaturalist 2018 in terms of accuracy under 200 training
    epochs. In this table, CR, IA and MI indicate class re-balancing, information
    augmentation and module improvement, respectively.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: TABLE VI：在200个训练周期下在 iNaturalist 2018 上的准确度结果。在这个表格中，CR、IA 和 MI 分别代表类别再平衡、信息增强和模块改进。
- en: '| Type | Method | Head | Middle | Tail | All |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 方法 | 头部 | 中间 | 尾部 | 全部 |'
- en: '| Baseline | Softmax | 75.3 | 66.4 | 60.4 | 64.9 |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 基准 | 软最大化 | 75.3 | 66.4 | 60.4 | 64.9 |'
- en: '| CR | Weighted Softmax | 66.5 | 68.0 | 69.2 | 68.3 |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| CR | Weighted Softmax | 66.5 | 68.0 | 69.2 | 68.3 |'
- en: '| Focal loss [[54](#bib.bib54)] | 58.8 | 66.5 | 66.8 | 66.6 |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| Focal loss [[54](#bib.bib54)] | 58.8 | 66.5 | 66.8 | 66.6 |'
- en: '| LDAM [[18](#bib.bib18)] | 57.4 | 62.7 | 63.8 | 62.8 |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| LDAM [[18](#bib.bib18)] | 57.4 | 62.7 | 63.8 | 62.8 |'
- en: '| Balanced Softmax [[97](#bib.bib97)] | 70.9 | 70.7 | 70.4 | 70.6 |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| Balanced Softmax [[97](#bib.bib97)] | 70.9 | 70.7 | 70.4 | 70.6 |'
- en: '| LADE [[31](#bib.bib31)] | 70.1 | 69.5 | 69.9 | 69.7 |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| LADE [[31](#bib.bib31)] | 70.1 | 69.5 | 69.9 | 69.7 |'
- en: '| IA | SSP [[102](#bib.bib102)] | 72.0 | 68.9 | 66.3 | 68.2 |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| IA | SSP [[102](#bib.bib102)] | 72.0 | 68.9 | 66.3 | 68.2 |'
- en: '| RSG [[118](#bib.bib118)] | 70.7 | 69.9 | 69.3 | 70.0 |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| RSG [[118](#bib.bib118)] | 70.7 | 69.9 | 69.3 | 70.0 |'
- en: '| MI | PaCo [[121](#bib.bib121)] | 68.5 | 72.0 | 71.8 | 71.6 |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| MI | PaCo [[121](#bib.bib121)] | 68.5 | 72.0 | 71.8 | 71.6 |'
- en: '| Decouple-IB-CRT [[32](#bib.bib32)] | 73.2 | 68.8 | 65.1 | 67.8 |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| Decouple-IB-CRT [[32](#bib.bib32)] | 73.2 | 68.8 | 65.1 | 67.8 |'
- en: '| Decouple-IB-LWS [[32](#bib.bib32)] | 71.3 | 69.2 | 68.1 | 69.0 |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| Decouple-IB-LWS [[32](#bib.bib32)] | 71.3 | 69.2 | 68.1 | 69.0 |'
- en: '| MiSLAS [[114](#bib.bib114)] | 71.7 | 71.5 | 69.7 | 70.7 |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| MiSLAS [[114](#bib.bib114)] | 71.7 | 71.5 | 69.7 | 70.7 |'
- en: '| ResLT [[125](#bib.bib125)] | 67.5 | 69.2 | 70.1 | 69.4 |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| ResLT [[125](#bib.bib125)] | 67.5 | 69.2 | 70.1 | 69.4 |'
- en: '| RIDE [[17](#bib.bib17)] | 71.5 | 70.0 | 71.6 | 71.8 |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| RIDE [[17](#bib.bib17)] | 71.5 | 70.0 | 71.6 | 71.8 |'
- en: '| SADE [[30](#bib.bib30)] | 74.4 | 72.5 | 73.1 | 72.9 |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| SADE [[30](#bib.bib30)] | 74.4 | 72.5 | 73.1 | 72.9 |'
- en: 4.4 Results on iNaturalist 2018
  id: totrans-330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 iNaturalist 2018 的结果
- en: 'iNaturalist 2018 is not a synthetic dataset sampled from a larger data pool,
    so we cannot build a corresponding *balanced training set with a similar data
    size* for it through sampling. As a result, it is infeasible to compute relative
    accuracy for it, so we only report the performance in terms of accuracy. As shown
    in Table [VI](#S4.T6 "TABLE VI ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies
    ‣ Deep Long-Tailed Learning: A Survey"), most observations are similar to those
    on ImageNet-LT. For example, most long-tailed methods outperform Softmax. Although
    LDAM (based on the official codes) performs slightly worse, its tail-class performance
    is better than the baseline, which demonstrates that LDAM can alleviate the class
    imbalance. However, its head-class performance drops significantly due to the
    head-tail trade-off, thus leading to poor overall performance. In addition, the
    current state-of-the-art method is SADE [[30](#bib.bib30)] in terms of accuracy,
    which further demonstrates the superiority of ensemble-based methods over other
    types of methods. All these baselines, except data augmentation based methods,
    adopt only basic augmentation operations. If we adopt stronger data augmentation
    and longer training, their model performance can be further improved.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 'iNaturalist 2018 不是从更大的数据池中抽样得到的合成数据集，因此我们无法通过抽样构建一个具有类似数据规模的*平衡训练集*。因此，计算相对准确性是不切实际的，因此我们仅报告准确性方面的性能。如表[VI](#S4.T6
    "TABLE VI ‣ 4.3 Results on ImageNet-LT ‣ 4 Empirical Studies ‣ Deep Long-Tailed
    Learning: A Survey")所示，大多数观察结果与ImageNet-LT上的类似。例如，大多数长尾方法优于Softmax。虽然LDAM（基于官方代码）表现稍差，但其尾部类别的表现优于基线，表明LDAM可以缓解类别不平衡。然而，由于头尾权衡，其头部类别的表现显著下降，从而导致总体性能较差。此外，目前准确性方面的最先进方法是SADE
    [[30](#bib.bib30)]，这进一步证明了基于集成的方法优于其他类型的方法。所有这些基线方法，除了基于数据增强的方法外，仅采用了基本的增强操作。如果我们采用更强的数据增强和更长的训练时间，它们的模型性能可以进一步提升。'
- en: 'TABLE VII: Analysis of class re-balancing on ImageNet-LT based on ResNeXt-50\.
    LA indicates logit post-adjustment, while re-sampling indicates class-balance
    re-sampling [[32](#bib.bib32)]. BS indicates Balanced Softmax [[97](#bib.bib97)].'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 表VII：基于ResNeXt-50对ImageNet-LT上类别重新平衡的分析。LA表示logit后调整，而re-sampling表示类别平衡重新抽样[[32](#bib.bib32)]。BS表示Balanced
    Softmax [[97](#bib.bib97)]。
- en: '| Loss | LA | Re-sampling | Head | Middle | Tail | All |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| 损失 | LA | 重新抽样 | 头部 | 中间 | 尾部 | 全部 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| Softmax |  |  | 66.9 | 40.4 | 12.6 | 46.8 |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| Softmax |  |  | 66.9 | 40.4 | 12.6 | 46.8 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| BS [[97](#bib.bib97)] |  |  | 62.4 | 47.7 | 32.1 | 51.2 |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| BS [[97](#bib.bib97)] |  |  | 62.4 | 47.7 | 32.1 | 51.2 |'
- en: '|  |  | 47.2 | 45.5 | 48.5 | 46.6 |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 47.2 | 45.5 | 48.5 | 46.6 |'
- en: '|  |  | 57.6 | 47.5 | 30.6 | 49.1 |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 57.6 | 47.5 | 30.6 | 49.1 |'
- en: '|  |  | 42.6 | 46.6 | 43.6 | 44.6 |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 42.6 | 46.6 | 43.6 | 44.6 |'
- en: 'TABLE VIII: Analysis of whether transfer-based methods (*e.g.,* SSP pre-training [[102](#bib.bib102)])
    are beneficial to other types of long-tailed learning. Here, we use ResNet-50
    as the backbone since SSP provides an open-source self-supervised pre-trained
    ResNet-50.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 表 VIII：分析基于迁移的方法（*例如*，SSP 预训练 [[102](#bib.bib102)]) 是否对其他类型的长尾学习有益。在这里，我们使用
    ResNet-50 作为骨干网，因为 SSP 提供了一个开源的自监督预训练 ResNet-50。
- en: '| Method | SSP pre-training [[102](#bib.bib102)] | Head | Middle | Tail | All
    |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | SSP 预训练 [[102](#bib.bib102)] | 头部 | 中部 | 尾部 | 全部 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Softmax |  | 64.7 | 35.9 | 7.1 | 43.1 |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| Softmax |  | 64.7 | 35.9 | 7.1 | 43.1 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Re-sampling [[32](#bib.bib32)] |  | 51.7 | 48.2 | 32.4 | 47.4 |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| 重新采样 [[32](#bib.bib32)] |  | 51.7 | 48.2 | 32.4 | 47.4 |'
- en: '|  | 63.5 | 45.3 | 20.5 | 49.0 |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '|  | 63.5 | 45.3 | 20.5 | 49.0 |'
- en: '| BS [[97](#bib.bib97)] |  | 61.7 | 47.8 | 28.5 | 50.5 |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| BS [[97](#bib.bib97)] |  | 61.7 | 47.8 | 28.5 | 50.5 |'
- en: '|  | 62.9 | 50.0 | 30.4 | 52.3 |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '|  | 62.9 | 50.0 | 30.4 | 52.3 |'
- en: '| Decouple [[32](#bib.bib32)] |  | 64.2 | 46.1 | 26.0 | 50.3 |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 解耦 [[32](#bib.bib32)] |  | 64.2 | 46.1 | 26.0 | 50.3 |'
- en: '|  | 67.3 | 49.1 | 28.3 | 53.3 |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '|  | 67.3 | 49.1 | 28.3 | 53.3 |'
- en: '| SADE [[30](#bib.bib30)] |  | 66.0 | 56.1 | 41.0 | 57.8 |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| SADE [[30](#bib.bib30)] |  | 66.0 | 56.1 | 41.0 | 57.8 |'
- en: '|  | 66.3 | 56.9 | 42.4 | 58.6 |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '|  | 66.3 | 56.9 | 42.4 | 58.6 |'
- en: 4.5 Analysis
  id: totrans-354
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 分析
- en: We next analyze the relationship between various types of methods.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来分析各种方法之间的关系。
- en: 'Discussions on class re-balancing. Class re-balancing has three subtypes of
    methods, *i.e.,* re-sampling, class-sensitive learning and logit adjustment. Although
    they have the same goal for re-balancing classes, they are exclusive to each other
    to some degree. As shown in Table [VII](#S4.T7 "TABLE VII ‣ 4.4 Results on iNaturalist
    2018 ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey"), Balanced Softmax
    (class-sensitive learning) alone greatly outperforms Softmax. However, when further
    using logit adjustment, it performs only comparably to Softmax. The reason is
    that the trained model by class-sensitive learning is already relatively class-balanced,
    so further using logit adjustment to post-adjust model inference will cause the
    predictions to become biased again and result in inferior performance. The performance
    is even worse when further combining class-balanced re-sampling. Therefore, simply
    combining existing class re-balancing without a careful design cannot lead to
    better performance.'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '讨论类重新平衡。类重新平衡有三种子方法，*即*，重新采样、类敏感学习和 logits 调整。虽然它们都有相同的目标——重新平衡类，但它们在某种程度上是相互排斥的。如表
    [VII](#S4.T7 "TABLE VII ‣ 4.4 Results on iNaturalist 2018 ‣ 4 Empirical Studies
    ‣ Deep Long-Tailed Learning: A Survey") 所示，Balanced Softmax（类敏感学习）单独使用远远优于 Softmax。然而，当进一步使用
    logits 调整时，其性能仅与 Softmax 相当。原因在于通过类敏感学习训练的模型已经相对类平衡，因此进一步使用 logits 调整来后处理模型推断会导致预测再次偏向，从而性能下降。当进一步结合类平衡重新采样时，性能甚至更差。因此，简单地结合现有的类重新平衡方法而没有仔细设计，无法带来更好的性能。'
- en: 'Discussions on the relationship between pre-training and other long-tailed
    methods. As mentioned in Section [3.2](#S3.SS2 "3.2 Information Augmentation ‣
    3 Classic Methods ‣ Deep Long-Tailed Learning: A Survey"), model pre-training
    is a transfer-based scheme for long-tailed learning. In this experiment, we analyze
    whether it is beneficial to other long-tailed paradigms. As shown in Table [VIII](#S4.T8
    "TABLE VIII ‣ 4.4 Results on iNaturalist 2018 ‣ 4 Empirical Studies ‣ Deep Long-Tailed
    Learning: A Survey"), SSP pre-training brings consistent performance gains to
    class re-balancing (class-balanced sampling [[32](#bib.bib32)] and BS [[97](#bib.bib97)])
    and module improvement (Decouple [[32](#bib.bib32)] and SADE [[30](#bib.bib30)]).
    We thus conclude that transfer-based methods are complementary to other long-tailed
    paradigms.'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '讨论预训练与其他长尾方法之间的关系。如第 [3.2](#S3.SS2 "3.2 Information Augmentation ‣ 3 Classic
    Methods ‣ Deep Long-Tailed Learning: A Survey") 节所述，模型预训练是一种针对长尾学习的迁移式方案。在此实验中，我们分析了它是否对其他长尾范式有益。如表
    VIII 所示，SSP 预训练对类重新平衡（类平衡采样 [[32](#bib.bib32)] 和 BS [[97](#bib.bib97)]）和模块改进（解耦 [[32](#bib.bib32)]
    和 SADE [[30](#bib.bib30)]）带来了持续的性能提升。因此，我们得出结论，基于迁移的方法与其他长尾范式是互补的。'
- en: 'Discussions on the relationship between data augmentation and other long-tailed
    methods. We then analyze whether data augmentation methods are beneficial to other
    long-tailed paradigms. As shown in Table [IX](#S4.T9 "TABLE IX ‣ 4.5 Analysis
    ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey"), RandAugment [[166](#bib.bib166)]
    brings consistent performance improvement to BS (a class re-balancing method),
    PaCo (representation learning), De-confound (classifier design) and SADE (ensemble
    learning). Such a result demonstrates that augmentation-based methods are complementary
    to other paradigms of long-tailed learning.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '关于数据增强与其他长尾方法之间关系的讨论。我们接着分析数据增强方法是否对其他长尾范式有益。如表 [IX](#S4.T9 "TABLE IX ‣ 4.5
    Analysis ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey") 所示，RandAugment [[166](#bib.bib166)]
    为 BS（类别重平衡方法）、PaCo（表示学习）、De-confound（分类器设计）和 SADE（集成学习）带来了稳定的性能提升。这样的结果表明，基于增强的方法与其他长尾学习范式是互补的。'
- en: 'TABLE IX: Analysis of whether augmentation methods (*e.g.,* RandAugment) are
    beneficial to other types of long-tailed learning, based on ResNeXt-50.'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 表 IX：基于 ResNeXt-50 的数据增强方法（*例如，*RandAugment）是否对其他类型的长尾学习有益的分析。
- en: '| Method | RandAugment [[166](#bib.bib166)] | Head | Middle | Tail | All |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | RandAugment [[166](#bib.bib166)] | 头类 | 中等类 | 尾类 | 所有 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Softmax |  | 66.9 | 40.4 | 12.6 | 46.8 |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| Softmax |  | 66.9 | 40.4 | 12.6 | 46.8 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| BS [[97](#bib.bib97)] |  | 62.4 | 47.7 | 32.1 | 51.2 |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| BS [[97](#bib.bib97)] |  | 62.4 | 47.7 | 32.1 | 51.2 |'
- en: '|  | 64.1 | 50.4 | 32.3 | 53.2 |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '|  | 64.1 | 50.4 | 32.3 | 53.2 |'
- en: '| PaCo [[121](#bib.bib121)] |  | 63.2 | 51.6 | 39.2 | 54.4 |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| PaCo [[121](#bib.bib121)] |  | 63.2 | 51.6 | 39.2 | 54.4 |'
- en: '|  | 63.7 | 56.6 | 39.2 | 57.0 |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '|  | 63.7 | 56.6 | 39.2 | 57.0 |'
- en: '| De-confound [[45](#bib.bib45)] |  | 64.9 | 46.9 | 28.1 | 51.3 |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| De-confound [[45](#bib.bib45)] |  | 64.9 | 46.9 | 28.1 | 51.3 |'
- en: '|  | 66.1 | 50.5 | 32.2 | 54.0 |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '|  | 66.1 | 50.5 | 32.2 | 54.0 |'
- en: '| SADE [[30](#bib.bib30)] |  | 67.2 | 55.3 | 40.0 | 58.8 |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| SADE [[30](#bib.bib30)] |  | 67.2 | 55.3 | 40.0 | 58.8 |'
- en: '|  | 67.3 | 60.4 | 46.4 | 61.2 |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '|  | 67.3 | 60.4 | 46.4 | 61.2 |'
- en: 'TABLE X: The decoupled training performance of various class-sensitive losses
    under 200 training epochs on ImageNet-LT. Here, “Joint” indicates one-stage end-to-end
    joint training; “NCM” is the nearest class mean classifier [[32](#bib.bib32)];
    “CRT” represents class-balanced classifier re-training [[32](#bib.bib32)]; “LWS”
    means learnable weight scaling [[32](#bib.bib32)]. Moreover, BS indicates the
    balanced softmax method [[97](#bib.bib97)].'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 表 X：在 ImageNet-LT 上进行 200 次训练周期的各种类别敏感损失的解耦训练性能。这里，“结合”表示一阶段端到端的联合训练；“NCM”是最近类均值分类器 [[32](#bib.bib32)];
    “CRT”代表类别平衡分类器再训练 [[32](#bib.bib32)]; “LWS”表示可学习权重缩放 [[32](#bib.bib32)]。此外，BS
    表示平衡 softmax 方法 [[97](#bib.bib97)]。
- en: '| Test Dist. | Accuracy on all classes |  | Accuracy on head classes |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| 测试分布 | 所有类的准确率 |  | 头类的准确率 |'
- en: '| Joint | NCM | CRT | LWS |  | Joint | NCM | CRT | LWS |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| 结合 | NCM | CRT | LWS |  | 结合 | NCM | CRT | LWS |'
- en: '| Softmax | 46.8 | 50.2 | 50.2 | 50.8 |  | 66.9 | 63.5 | 65.0 | 64.6 |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| Softmax | 46.8 | 50.2 | 50.2 | 50.8 |  | 66.9 | 63.5 | 65.0 | 64.6 |'
- en: '| Focal loss [[54](#bib.bib54)] | 47.2 | 50.7 | 50.7 | 51.5 |  | 67.0 | 62.6
    | 64.5 | 64.3 |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| Focal loss [[54](#bib.bib54)] | 47.2 | 50.7 | 50.7 | 51.5 |  | 67.0 | 62.6
    | 64.5 | 64.3 |'
- en: '| ESQL [[19](#bib.bib19)] | 48.0 | 49.8 | 50.6 | 50.5 |  | 63.1 | 60.2 | 64.0
    | 63.3 |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| ESQL [[19](#bib.bib19)] | 48.0 | 49.8 | 50.6 | 50.5 |  | 63.1 | 60.2 | 64.0
    | 63.3 |'
- en: '| BS [[97](#bib.bib97)] | 51.2 | 50.4 | 50.6 | 51.1 |  | 62.4 | 62.4 | 64.9
    | 64.3 |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| BS [[97](#bib.bib97)] | 51.2 | 50.4 | 50.6 | 51.1 |  | 62.4 | 62.4 | 64.9
    | 64.3 |'
- en: '| Test Dist. | Accuracy on middle classes |  | Accuracy on tail classes |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| 测试分布 | 中等类的准确率 |  | 尾类的准确率 |'
- en: '| Joint | NCM | CRT | LWS |  | Joint | NCM | CRT | LWS |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| 结合 | NCM | CRT | LWS |  | 结合 | NCM | CRT | LWS |'
- en: '| Softmax | 40.4 | 45.8 | 45.3 | 46.1 |  | 12.6 | 28.1 | 25.5 | 28.2 |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| Softmax | 40.4 | 45.8 | 45.3 | 46.1 |  | 12.6 | 28.1 | 25.5 | 28.2 |'
- en: '| Focal loss [[54](#bib.bib54)] | 41.0 | 47.0 | 46.4 | 47.3 |  | 13.1 | 30.1
    | 26.9 | 30.2 |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| Focal loss [[54](#bib.bib54)] | 41.0 | 47.0 | 46.4 | 47.3 |  | 13.1 | 30.1
    | 26.9 | 30.2 |'
- en: '| ESQL [[19](#bib.bib19)] | 44.6 | 46.6 | 46.5 | 46.1 |  | 17.2 | 31.1 | 27.1
    | 29.5 |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| ESQL [[19](#bib.bib19)] | 44.6 | 46.6 | 46.5 | 46.1 |  | 17.2 | 31.1 | 27.1
    | 29.5 |'
- en: '| BS [[97](#bib.bib97)] | 47.7 | 46.8 | 46.1 | 46.7 |  | 32.1 | 29.1 | 26.2
    | 29.4 |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| BS [[97](#bib.bib97)] | 47.7 | 46.8 | 46.1 | 46.7 |  | 32.1 | 29.1 | 26.2
    | 29.4 |'
- en: 'Discussions on class-sensitive losses in the decoupled training scheme. We
    further evaluate the performance of different class-sensitive learning losses
    on the decoupled training scheme [[32](#bib.bib32)]. In the first stage, we use
    different class-sensitive learning losses to train the model backbone for learning
    representations, while in the second stage, we use four different strategies for
    classifier training [[32](#bib.bib32)], *i.e.,* joint training without re-training,
    the nearest class mean classifier (NCM), class-balanced classifier re-training
    (CRT), and learnable weight scaling (LWS). As shown in Table [X](#S4.T10 "TABLE
    X ‣ 4.5 Analysis ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey"),
    decoupled training can further improve the overall performance of most class-sensitive
    methods with joint training, except BS. Among these methods, BS performs the best
    under joint training, but the others perform comparably to BS under decoupled
    training. Such results are particularly interesting, as they imply that although
    these class-sensitive losses perform differently under joint training, they essentially
    learn the similar quality of feature representations. The worse overall performance
    of BS under decoupled training than joint training may imply that BS has conducted
    class re-balancing very well; further using classifier re-training for re-balancing
    does not bring additional benefits but even degenerates the consistency of network
    parameters by end-to-end joint training.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '对解耦训练方案中类别敏感损失的讨论。我们进一步评估了不同类别敏感学习损失在解耦训练方案中的表现[[32](#bib.bib32)]。在第一阶段，我们使用不同的类别敏感学习损失来训练模型骨干以学习表示，而在第二阶段，我们使用四种不同的策略进行分类器训练[[32](#bib.bib32)]，*即*，没有重新训练的联合训练、最近类别均值分类器（NCM）、类别平衡分类器重新训练（CRT）和可学习的权重缩放（LWS）。如表[X](#S4.T10
    "TABLE X ‣ 4.5 Analysis ‣ 4 Empirical Studies ‣ Deep Long-Tailed Learning: A Survey")所示，解耦训练可以进一步提高大多数类别敏感方法的整体性能，除了BS。
    在这些方法中，BS在联合训练下表现最佳，但其他方法在解耦训练下表现与BS相当。这些结果尤其有趣，因为它们暗示虽然这些类别敏感损失在联合训练下表现不同，但它们实质上学到了相似质量的特征表示。BS在解耦训练下的整体表现比联合训练差可能意味着BS在进行类别重平衡时做得非常好；进一步使用分类器重新训练进行重平衡并不会带来额外的好处，反而可能通过端到端联合训练降低了网络参数的一致性。'
- en: 4.6 Summary of Empirical Observations
  id: totrans-386
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 实证观察总结
- en: We then summarize main take-home messages from our empirical studies. First,
    we analyze to what extent existing long-tailed methods resolve the class imbalance
    in terms of relative accuracy, and confirm that existing research is making positive
    progress in resolving class imbalance instead of just chasing state-of-the-art
    performance through tricks. Second, we determine the relative performance of existing
    long-tailed methods in a unified setup, and find that ensemble-based methods are
    the current state-of-the-art. Third, we analyze method performance on various
    class subsets, and find that most methods improve tail-class performance at the
    cost of lower head-class performance. Considering that all classes are important
    in long-tailed learning, it is worth exploring how to improve all classes at the
    same time in the future. Fourth, we empirically show that the three subtypes of
    class re-balancing are exclusive to each other to some degree. Moreover, information
    augmentation methods are complementary to other long-tailed paradigms. Lastly,
    by evaluating class-sensitive learning on the decoupled training scheme, we find
    class re-balancing and decoupled training play an interchangeable role in resolving
    class imbalance. Moreover, the representations learned by different class-sensitive
    losses perform similarly under decoupled training.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们总结了实证研究的主要收获。首先，我们分析了现有的长尾方法在相对准确度方面解决类别不平衡的程度，并确认现有研究在解决类别不平衡方面取得了积极进展，而不仅仅是通过技巧追求最新的性能。第二，我们在统一的设置下确定了现有长尾方法的相对性能，发现基于集成的方法是目前的**最先进**方法。第三，我们分析了方法在不同类别子集上的表现，发现大多数方法在改善尾部类别表现的同时，牺牲了头部类别的表现。考虑到在长尾学习中所有类别都很重要，未来值得探索如何同时提高所有类别的表现。第四，我们通过实证研究表明，三种类别重平衡的子类型在一定程度上是互斥的。此外，信息增强方法对其他长尾范式具有互补性。最后，通过评估解耦训练方案下的类别敏感学习，我们发现类别重平衡和解耦训练在解决类别不平衡方面扮演了可互换的角色。此外，不同类别敏感损失下学到的表示在解耦训练下表现相似。
- en: 5 Future Directions
  id: totrans-388
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 未来方向
- en: In this section, we identify several future research directions for deep long-tailed
    learning.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们识别了深度长尾学习的几个未来研究方向。
- en: Test-agnostic long-tailed learning. Existing long-tailed learning methods generally
    hypothesize a balanced test class distribution. The practical test distribution,
    however, often violates this hypothesis (*e.g.,* being long-tailed or even inversely
    long-tailed), which may lead existing methods to fail in real-world applications.
    To overcome this limitation, LADE [[31](#bib.bib31)] relaxes this hypothesis by
    assuming that the test class distribution can be skewed arbitrarily but the prior
    of test distribution is available. Afterward, SADE [[30](#bib.bib30)] further
    innovates the task, in which the test class distribution is not only arbitrarily
    skewed but also unknown. Besides class imbalance, this task poses another challenge,
    *i.e.,* unidentified class distribution shift between the training and test samples.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 测试无关长尾学习。现有的长尾学习方法通常假设测试类别分布是平衡的。然而，实际测试分布通常违背这一假设（*例如，* 可能是长尾或甚至是反向长尾），这可能导致现有方法在实际应用中失败。为了解决这一限制，LADE
    [[31](#bib.bib31)] 通过假设测试类别分布可以任意偏斜但测试分布的先验是可用的，来放宽这一假设。随后，SADE [[30](#bib.bib30)]
    进一步创新了任务，其中测试类别分布不仅任意偏斜而且未知。除了类别不平衡外，这一任务还带来了另一个挑战，*即，* 训练和测试样本之间的类别分布未知变化。
- en: 'Open-set long-tailed learning. Real-world samples often have a long-tailed
    and open-ended class distribution. Open-set long-tailed learning [[15](#bib.bib15),
    [104](#bib.bib104)] seeks to learn from long-tailed data and optimize the classification
    accuracy over a balanced test set that includes head, tail and open classes. There
    are two main challenges: (1) how to share visual knowledge between head and tail
    classes; (2) how to reduce confusion between tail and open classes.'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 开放集长尾学习。现实世界中的样本通常具有长尾和开放式的类别分布。开放集长尾学习[[15](#bib.bib15), [104](#bib.bib104)]
    旨在从长尾数据中学习，并优化在包含头部、尾部和开放类别的平衡测试集上的分类准确率。主要面临两个挑战：（1）如何在头部和尾部类别之间共享视觉知识；（2）如何减少尾部和开放类别之间的混淆。
- en: 'Federated long-tailed learning. Existing long-tailed studies generally assume
    that all training samples are accessible during model training. However, in real
    applications, long-tailed training data may be distributed on numerous mobile
    devices or the Internet of Things [[167](#bib.bib167)], which requires decentralized
    training of deep models. Such a task is called federated long-tailed learning,
    which has two key challenges: (1) long-tail class imbalance; (2) unknown class
    distribution shift among the local data of different clients.'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦长尾学习。现有的长尾研究通常假设在模型训练期间所有训练样本都是可访问的。然而，在实际应用中，长尾训练数据可能分布在大量移动设备或物联网[[167](#bib.bib167)]上，这需要对深度模型进行去中心化训练。这种任务称为联邦长尾学习，面临两个主要挑战：（1）长尾类别不平衡；（2）不同客户端本地数据之间的未知类别分布变化。
- en: 'Class-incremental long-tailed learning. In real-world applications, long-tailed
    data may come in a continual and class-incremental manner [[168](#bib.bib168),
    [98](#bib.bib98), [169](#bib.bib169)]. To deal with this scenario, class-incremental
    long-tailed learning aims to learn deep models from class-incremental long-tailed
    data, suffering two key challenges: (1) how to handle long-tailed class imbalance
    when different classes come sequentially, and the model has no information about
    the future input regarding classes as well as label frequencies; (2) how to overcome
    catastrophic forgetting of previous class knowledge when learning new classes.
    Such a task setting can also be named continual long-tailed learning.'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 类增量长尾学习。在实际应用中，长尾数据可能以持续和类别增量的方式出现[[168](#bib.bib168), [98](#bib.bib98), [169](#bib.bib169)]。为了处理这种情况，类增量长尾学习旨在从类增量长尾数据中学习深度模型，面临两个主要挑战：（1）如何处理不同类别按顺序出现时的长尾类别不平衡，以及模型对未来类别及标签频率没有信息；（2）如何克服在学习新类别时对之前类别知识的灾难性遗忘。这种任务设置也可以称为持续长尾学习。
- en: Multi-domain long-tailed learning. Current long-tailed methods generally assume
    that all long-tailed samples come from the same data marginal distribution. However,
    in practice, long-tailed data may also get from different domains with distinct
    data distributions [[170](#bib.bib170), [28](#bib.bib28)], *e.g.,* the DomainNet
    dataset [[171](#bib.bib171)]. Motivated by this, multi-domain long-tailed learning
    seeks to handle both class imbalance and domain distribution shift, simultaneously.
    One more challenging issue may be the inconsistency of class imbalance among different
    domains. In other words, various domains may have different class distributions,
    which further enlarges the domain shift in multi-domain long-tailed learning.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 多领域长尾学习。当前的长尾方法通常假设所有长尾样本来自相同的数据边际分布。然而，在实际应用中，长尾数据也可能来自具有不同数据分布的不同领域[[170](#bib.bib170),
    [28](#bib.bib28)]，*例如*，DomainNet数据集[[171](#bib.bib171)]。基于此，多领域长尾学习旨在同时处理类别不平衡和领域分布的变化。另一个更具挑战性的问题可能是不同领域之间类别不平衡的一致性。换句话说，不同领域可能有不同的类别分布，这进一步扩大了多领域长尾学习中的领域偏移。
- en: Robust long-tailed learning. Real-world long-tailed samples may also suffer
    image noise [[113](#bib.bib113), [172](#bib.bib172)] or label noise [[155](#bib.bib155),
    [150](#bib.bib150)]. Most long-tailed methods, however, assume all images and
    labels are clean, leading to poor model robustness in practical applications.
    This issue would be particularly severe for tail classes, as they have very limited
    training samples. Inspired by this, robust long-tailed learning seeks to handle
    the class imbalance and improve model robustness, simultaneously.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 鲁棒长尾学习。现实世界中的长尾样本可能还会遭受图像噪声[[113](#bib.bib113), [172](#bib.bib172)]或标签噪声[[155](#bib.bib155),
    [150](#bib.bib150)]。然而，大多数长尾方法假设所有图像和标签都是干净的，从而导致实际应用中模型的鲁棒性较差。这个问题对于尾部类别尤其严重，因为它们的训练样本非常有限。基于此，鲁棒长尾学习旨在同时处理类别不平衡并提高模型鲁棒性。
- en: Long-tailed regression. Most existing studies of long-tailed visual learning
    focus on classification, detection and segmentation, which have discrete labels
    with class indices. However, many tasks involve continuous labels, where hard
    classification boundaries among classes do not exist. Motivated by this, long-tailed
    regression [[173](#bib.bib173)] aims to deal with long-tailed learning with continuous
    label space. In such a task, how to simultaneously resolve long-tailed class imbalance
    and handle potential missing data for certain labels remains an open question.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 长尾回归。现有的大多数长尾视觉学习研究集中于分类、检测和分割，这些方法有离散的标签和类别索引。然而，许多任务涉及连续标签，其中不存在明确的分类边界。基于此，长尾回归[[173](#bib.bib173)]旨在处理具有连续标签空间的长尾学习任务。在这样的任务中，如何同时解决长尾类别不平衡和处理某些标签的潜在缺失数据仍然是一个未解的问题。
- en: Long-tailed video learning. Most existing deep long-tailed learning studies
    focus on the image level, but ignore that the video domain also suffers from the
    issue of long-tail class imbalance. Considering the additional temporal dimension
    in video data, long-tailed video learning should be more difficult than long-tailed
    image learning. Thanks to the recent release of a VideoLT dataset [[38](#bib.bib38)],
    long-tailed video learning can be explored in the near future.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 长尾视频学习。现有的大多数深度长尾学习研究集中在图像层面，但忽视了视频领域也面临长尾类别不平衡的问题。考虑到视频数据中的额外时间维度，长尾视频学习应比长尾图像学习更具挑战性。由于最近发布了VideoLT数据集[[38](#bib.bib38)]，长尾视频学习有望在不久的将来得到探索。
- en: 6 Conclusion
  id: totrans-398
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this survey, we have extensively reviewed classic deep long-tailed learning
    methods proposed before mid-2021, according to the taxonomy of class re-balancing,
    information augmentation and module improvement. We have empirically analyzed
    several state-of-the-art long-tailed methods by evaluating to what extent they
    address the issue of class imbalance, based on a newly proposed relative accuracy
    metric. Following that, we discussed the main application scenarios of long-tailed
    learning, and identified potential innovation directions for methods and task
    settings. We expect that this timely survey not only provides a better understanding
    of long-tailed learning for researchers and the community, but also facilitates
    future research.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项综述中，我们详细回顾了2021年中期之前提出的经典深度长尾学习方法，根据类别重平衡、信息增强和模块改进的分类法。我们通过评估这些方法在解决类别不平衡问题方面的效果，基于新提出的相对准确性指标，实证分析了几种最先进的长尾方法。随后，我们讨论了长尾学习的主要应用场景，并确定了方法和任务设置的潜在创新方向。我们期望这项及时的综述不仅为研究人员和社区提供了对长尾学习的更好理解，还促进了未来的研究。
- en: Acknowledgements
  id: totrans-400
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work was partially supported by NUS ODPRT Grant A-0008067-00-00.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作部分得到了NUS ODPRT资助A-0008067-00-00的支持。
- en: References
  id: totrans-402
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” *Nature*, vol. 521,
    no. 7553, pp. 436–444, 2015.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Y. LeCun, Y. Bengio, 和 G. Hinton, “深度学习,” *自然*, 第521卷，第7553期，页码436–444，2015年。'
- en: '[2] I. Goodfellow, Y. Bengio, and A. Courville, *Deep learning*.   MIT press,
    2016.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] I. Goodfellow, Y. Bengio, 和 A. Courville, *深度学习*. MIT出版社, 2016年。'
- en: '[3] A. Voulodimos, N. Doulamis, A. Doulamis, and E. Protopapadakis, “Deep learning
    for computer vision: A brief review,” *Computational Intelligence and Neuroscience*,
    2018.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] A. Voulodimos, N. Doulamis, A. Doulamis, 和 E. Protopapadakis, “计算机视觉中的深度学习：简要回顾,”
    *计算智能与神经科学*, 2018年。'
- en: '[4] C. Dong, C. C. Loy, K. He, and X. Tang, “Image super-resolution using deep
    convolutional networks,” *IEEE Transactions on Pattern Analysis and Machine Intelligence*,
    vol. 38, no. 2, pp. 295–307, 2015.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] C. Dong, C. C. Loy, K. He, 和 X. Tang, “利用深度卷积网络进行图像超分辨率,” *IEEE模式分析与机器智能学报*,
    第38卷，第2期，页码295–307，2015年。'
- en: '[5] Z. Wang, J. Chen, and S. C. Hoi, “Deep learning for image super-resolution:
    A survey,” *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 2020.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Z. Wang, J. Chen, 和 S. C. Hoi, “图像超分辨率的深度学习：综述,” *IEEE模式分析与机器智能学报*, 2020年。'
- en: '[6] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
    with deep convolutional neural networks,” *Advances in Neural Information Processing
    Systems*, vol. 25, pp. 1097–1105, 2012.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] A. Krizhevsky, I. Sutskever, 和 G. E. Hinton, “使用深度卷积神经网络进行ImageNet分类,”
    *神经信息处理系统进展*, 第25卷，页码1097–1105，2012年。'
- en: '[7] S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: towards real-time
    object detection with region proposal networks,” *IEEE Transactions on Pattern
    Analysis and Machine Intelligence*, vol. 39, no. 6, pp. 1137–1149, 2016.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] S. Ren, K. He, R. Girshick, 和 J. Sun, “Faster R-CNN：基于区域提议网络的实时目标检测,” *IEEE模式分析与机器智能学报*,
    第39卷，第6期，页码1137–1149，2016年。'
- en: '[8] E. Shelhamer, J. Long, and T. Darrell, “Fully convolutional networks for
    semantic segmentation.” *IEEE Transactions on Pattern Analysis and Machine Intelligence*,
    vol. 39, no. 4, pp. 640–651, 2016.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] E. Shelhamer, J. Long, 和 T. Darrell, “用于语义分割的全卷积网络。” *IEEE模式分析与机器智能学报*,
    第39卷，第4期，页码640–651，2016年。'
- en: '[9] Y. Bengio, Y. LeCun, and G. Hinton, “Deep learning for ai,” *Communications
    of the ACM*, vol. 64, no. 7, pp. 58–65, 2021.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Y. Bengio, Y. LeCun, 和 G. Hinton, “人工智能中的深度学习,” *ACM通讯*, 第64卷，第7期，页码58–65，2021年。'
- en: '[10] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
    recognition,” in *Computer Vision and Pattern Recognition*, 2016.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] K. He, X. Zhang, S. Ren, 和 J. Sun, “用于图像识别的深度残差学习,” 见于 *计算机视觉与模式识别会议*,
    2016年。'
- en: '[11] C. Szegedy, A. Toshev, and D. Erhan, “Deep neural networks for object
    detection,” 2013.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] C. Szegedy, A. Toshev, 和 D. Erhan, “用于目标检测的深度神经网络,” 2013年。'
- en: '[12] R. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich feature hierarchies
    for accurate object detection and semantic segmentation,” in *Computer Vision
    and Pattern Recognition*, 2014, pp. 580–587.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] R. Girshick, J. Donahue, T. Darrell, 和 J. Malik, “用于准确目标检测和语义分割的丰富特征层级,”
    见于 *计算机视觉与模式识别会议*, 2014年，页码580–587。'
- en: '[13] B. Kang, Y. Li, S. Xie, Z. Yuan, and J. Feng, “Exploring balanced feature
    spaces for representation learning,” in *International Conference on Learning
    Representations*, 2021.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] B. Kang, Y. Li, S. Xie, Z. Yuan, 和 J. Feng, “探索用于表示学习的平衡特征空间,” 见于 *国际表示学习会议*,
    2021年。'
- en: '[14] A. K. Menon, S. Jayasumana, A. S. Rawat, H. Jain, A. Veit, and S. Kumar,
    “Long-tail learning via logit adjustment,” in *International Conference on Learning
    Representations*, 2021.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] A. K. Menon, S. Jayasumana, A. S. Rawat, H. Jain, A. Veit, 和 S. Kumar，“通过对数调整进行长尾学习，”
    收录于 *学习表征国际会议*，2021年。'
- en: '[15] Z. Liu, Z. Miao, X. Zhan, J. Wang, B. Gong, and S. X. Yu, “Large-scale
    long-tailed recognition in an open world,” in *Computer Vision and Pattern Recognition*,
    2019, pp. 2537–2546.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Z. Liu, Z. Miao, X. Zhan, J. Wang, B. Gong, 和 S. X. Yu，“开放世界中的大规模长尾识别，”
    收录于 *计算机视觉与模式识别*，2019年，第2537–2546页。'
- en: '[16] Y. Cui, M. Jia, T.-Y. Lin, Y. Song, and S. Belongie, “Class-balanced loss
    based on effective number of samples,” in *Computer Vision and Pattern Recognition*,
    2019, pp. 9268–9277.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Y. Cui, M. Jia, T.-Y. Lin, Y. Song, 和 S. Belongie，“基于有效样本数量的类平衡损失，” 收录于
    *计算机视觉与模式识别*，2019年，第9268–9277页。'
- en: '[17] X. Wang, L. Lian, Z. Miao, Z. Liu, and S. X. Yu, “Long-tailed recognition
    by routing diverse distribution-aware experts,” in *International Conference on
    Learning Representations*, 2021.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] X. Wang, L. Lian, Z. Miao, Z. Liu, 和 S. X. Yu，“通过路由多样化的分布感知专家进行长尾识别，”
    收录于 *学习表征国际会议*，2021年。'
- en: '[18] K. Cao, C. Wei, A. Gaidon, N. Arechiga, and T. Ma, “Learning imbalanced
    datasets with label-distribution-aware margin loss,” in *Advances in Neural Information
    Processing Systems*, 2019.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] K. Cao, C. Wei, A. Gaidon, N. Arechiga, 和 T. Ma，“使用标签分布感知边际损失学习不平衡数据集，”
    收录于 *神经信息处理系统进展*，2019年。'
- en: '[19] J. Tan, C. Wang, B. Li, Q. Li, W. Ouyang, C. Yin, and J. Yan, “Equalization
    loss for long-tailed object recognition,” in *Computer Vision and Pattern Recognition*,
    2020, pp. 11 662–11 671.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] J. Tan, C. Wang, B. Li, Q. Li, W. Ouyang, C. Yin, 和 J. Yan，“用于长尾目标识别的均衡损失，”
    收录于 *计算机视觉与模式识别*，2020年，第11,662–11,671页。'
- en: '[20] V. Vapnik, “Principles of risk minimization for learning theory,” in *Advances
    in Neural Information Processing Systems*, 1992, pp. 831–838.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] V. Vapnik，“学习理论的风险最小化原则，” 收录于 *神经信息处理系统进展*，1992年，第831–838页。'
- en: '[21] X. Zhang, Z. Fang, Y. Wen, Z. Li, and Y. Qiao, “Range loss for deep face
    recognition with long-tailed training data,” in *International Conference on Computer
    Vision*, 2017, pp. 5409–5418.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] X. Zhang, Z. Fang, Y. Wen, Z. Li, 和 Y. Qiao，“用于深度人脸识别的范围损失与长尾训练数据，” 收录于
    *计算机视觉国际会议*，2017年，第5409–5418页。'
- en: '[22] D. Cao, X. Zhu, X. Huang, J. Guo, and Z. Lei, “Domain balancing: Face
    recognition on long-tailed domains,” in *Computer Vision and Pattern Recognition*,
    2020, pp. 5671–5679.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] D. Cao, X. Zhu, X. Huang, J. Guo, 和 Z. Lei，“领域平衡：长尾领域中的人脸识别，” 收录于 *计算机视觉与模式识别*，2020年，第5671–5679页。'
- en: '[23] G. Van Horn, O. Mac Aodha, Y. Song, Y. Cui, C. Sun, A. Shepard, H. Adam,
    P. Perona, and S. Belongie, “The inaturalist species classification and detection
    dataset,” in *Computer Vision and Pattern Recognition*, 2018, pp. 8769–8778.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] G. Van Horn, O. Mac Aodha, Y. Song, Y. Cui, C. Sun, A. Shepard, H. Adam,
    P. Perona, 和 S. Belongie，“iNaturalist物种分类和检测数据集，” 收录于 *计算机视觉与模式识别*，2018年，第8769–8778页。'
- en: '[24] Z. Miao, Z. Liu, K. M. Gaynor, M. S. Palmer, S. X. Yu, and W. M. Getz,
    “Iterative human and automated identification of wildlife images,” *arXiv:2105.02320*,
    2021.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Z. Miao, Z. Liu, K. M. Gaynor, M. S. Palmer, S. X. Yu, 和 W. M. Getz，“迭代的人类和自动化野生动物图像识别，”
    *arXiv:2105.02320*，2021年。'
- en: '[25] L. Ju, X. Wang, L. Wang, T. Liu, X. Zhao, T. Drummond, D. Mahapatra, and
    Z. Ge, “Relational subsets knowledge distillation for long-tailed retinal diseases
    recognition,” *arXiv:2104.11057*, 2021.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] L. Ju, X. Wang, L. Wang, T. Liu, X. Zhao, T. Drummond, D. Mahapatra, 和
    Z. Ge，“针对长尾视网膜疾病识别的关系子集知识蒸馏，” *arXiv:2104.11057*，2021年。'
- en: '[26] R. He, J. Yang, and X. Qi, “Re-distributing biased pseudo labels for semi-supervised
    semantic segmentation: A baseline investigation,” in *International Conference
    on Computer Vision*, 2021.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] R. He, J. Yang, 和 X. Qi，“针对半监督语义分割的偏置伪标签再分配：基线研究，” 收录于 *计算机视觉国际会议*，2021年。'
- en: '[27] W. Yu, T. Yang, and C. Chen, “Towards resolving the challenge of long-tail
    distribution in uav images for object detection,” in *IEEE Winter Conference on
    Applications of Computer Vision*, 2021, pp. 3258–3267.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] W. Yu, T. Yang, 和 C. Chen，“解决无人机图像中长尾分布的挑战以进行目标检测，” 收录于 *IEEE冬季计算机视觉应用会议*，2021年，第3258–3267页。'
- en: '[28] M. A. Jamal, M. Brown, M.-H. Yang, L. Wang, and B. Gong, “Rethinking class-balanced
    methods for long-tailed visual recognition from a domain adaptation perspective,”
    in *Computer Vision and Pattern Recognition*, 2020, pp. 7610–7619.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] M. A. Jamal, M. Brown, M.-H. Yang, L. Wang, 和 B. Gong，“从领域适配的角度重新思考长尾视觉识别中的类平衡方法，”
    收录于 *计算机视觉与模式识别*，2020年，第7610–7619页。'
- en: '[29] S. Zhang, Z. Li, S. Yan, X. He, and J. Sun, “Distribution alignment: A
    unified framework for long-tail visual recognition,” in *Computer Vision and Pattern
    Recognition*, 2021, pp. 2361–2370.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] S. Zhang, Z. Li, S. Yan, X. He 和 J. Sun, “分布对齐：一个统一的长尾视觉识别框架，”发表在 *计算机视觉与模式识别*，2021年，页2361–2370。'
- en: '[30] Y. Zhang, B. Hooi, L. Hong, and J. Feng, “Self-supervised aggregation
    of diverse experts for test-agnostic long-tailed recognition,” in *Advances in
    Neural Information Processing Systems*, 2022.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Y. Zhang, B. Hooi, L. Hong 和 J. Feng, “自监督聚合多样专家以进行测试无关的长尾识别，”发表在 *神经信息处理系统进展*，2022年。'
- en: '[31] Y. Hong, S. Han, K. Choi, S. Seo, B. Kim, and B. Chang, “Disentangling
    label distribution for long-tailed visual recognition,” in *Computer Vision and
    Pattern Recognition*, 2021.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Y. Hong, S. Han, K. Choi, S. Seo, B. Kim 和 B. Chang, “为长尾视觉识别解开标签分布，”发表在
    *计算机视觉与模式识别*，2021年。'
- en: '[32] B. Kang, S. Xie, M. Rohrbach, Z. Yan, A. Gordo, J. Feng, and Y. Kalantidis,
    “Decoupling representation and classifier for long-tailed recognition,” in *International
    Conference on Learning Representations*, 2020.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] B. Kang, S. Xie, M. Rohrbach, Z. Yan, A. Gordo, J. Feng 和 Y. Kalantidis,
    “为长尾识别解耦表示和分类器，”发表在 *学习表示国际会议*，2020年。'
- en: '[33] C. Feng, Y. Zhong, and W. Huang, “Exploring classification equilibrium
    in long-tailed object detection,” in *International Conference on Computer Vision*,
    2021.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] C. Feng, Y. Zhong 和 W. Huang, “探索长尾目标检测中的分类平衡，”发表在 *国际计算机视觉会议*，2021年。'
- en: '[34] T. Wang, Y. Li, B. Kang, J. Li, J. Liew, S. Tang, S. Hoi, and J. Feng,
    “The devil is in classification: A simple framework for long-tail instance segmentation,”
    in *European Conference on Computer Vision*, 2020.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] T. Wang, Y. Li, B. Kang, J. Li, J. Liew, S. Tang, S. Hoi 和 J. Feng, “分类中的魔鬼：长尾实例分割的简单框架，”发表在
    *欧洲计算机视觉会议*，2020年。'
- en: '[35] Z. Weng, M. G. Ogut, S. Limonchik, and S. Yeung, “Unsupervised discovery
    of the long-tail in instance segmentation using hierarchical self-supervision,”
    in *Computer Vision and Pattern Recognition*, 2021.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Z. Weng, M. G. Ogut, S. Limonchik 和 S. Yeung, “使用分层自监督学习实例分割中的长尾问题的无监督发现，”发表在
    *计算机视觉与模式识别*，2021年。'
- en: '[36] A. Gupta, P. Dollar, and R. Girshick, “Lvis: A dataset for large vocabulary
    instance segmentation,” in *Computer Vision and Pattern Recognition*, 2019, pp.
    5356–5364.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] A. Gupta, P. Dollar 和 R. Girshick, “Lvis：一个大词汇量实例分割数据集，”发表在 *计算机视觉与模式识别*，2019年，页5356–5364。'
- en: '[37] T. Wu, Q. Huang, Z. Liu, Y. Wang, and D. Lin, “Distribution-balanced loss
    for multi-label classification in long-tailed datasets,” in *European Conference
    on Computer Vision*, 2020, pp. 162–178.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] T. Wu, Q. Huang, Z. Liu, Y. Wang 和 D. Lin, “长尾数据集中多标签分类的分布平衡损失，”发表在 *欧洲计算机视觉会议*，2020年，页162–178。'
- en: '[38] X. Zhang, Z. Wu, Z. Weng, H. Fu, J. Chen, Y.-G. Jiang, and L. Davis, “Videolt:
    Large-scale long-tailed video recognition,” in *International Conference on Computer
    Vision*, 2021.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] X. Zhang, Z. Wu, Z. Weng, H. Fu, J. Chen, Y.-G. Jiang 和 L. Davis, “Videolt：大规模长尾视频识别，”发表在
    *国际计算机视觉会议*，2021年。'
- en: '[39] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “Imagenet:
    A large-scale hierarchical image database,” in *Computer Vision and Pattern Recognition*,
    2009, pp. 248–255.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li 和 L. Fei-Fei, “Imagenet：一个大规模分层图像数据库，”发表在
    *计算机视觉与模式识别*，2009年，页248–255。'
- en: '[40] A. Krizhevsky, G. Hinton *et al.*, “Learning multiple layers of features
    from tiny images,” 2009.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] A. Krizhevsky, G. Hinton *等*，“从微小图像中学习多层特征，”2009年。'
- en: '[41] B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva, “Learning deep
    features for scene recognition using places database,” *Advances in Neural Information
    Processing Systems*, vol. 27, pp. 487–495, 2014.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] B. Zhou, A. Lapedriza, J. Xiao, A. Torralba 和 A. Oliva, “利用places数据库进行场景识别的深度特征学习，”
    *神经信息处理系统进展*，第27卷，页487–495，2014年。'
- en: '[42] M. Everingham, S. A. Eslami, L. Van Gool, C. K. Williams, J. Winn, and
    A. Zisserman, “The pascal visual object classes challenge: A retrospective,” *International
    Journal of Computer Vision*, vol. 111, no. 1, pp. 98–136, 2015.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] M. Everingham, S. A. Eslami, L. Van Gool, C. K. Williams, J. Winn 和 A.
    Zisserman, “Pascal视觉目标类别挑战：回顾，” *国际计算机视觉杂志*，第111卷，第1期，页98–136，2015年。'
- en: '[43] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár,
    and C. L. Zitnick, “Microsoft coco: Common objects in context,” in *European Conference
    on Computer Vision*, 2014.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár
    和 C. L. Zitnick, “Microsoft coco：背景中的常见物体，”发表在 *欧洲计算机视觉会议*，2014年。'
- en: '[44] B. Zhou, Q. Cui, X.-S. Wei, and Z.-M. Chen, “Bbn: Bilateral-branch network
    with cumulative learning for long-tailed visual recognition,” in *Computer Vision
    and Pattern Recognition*, 2020, pp. 9719–9728.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] B. Zhou, Q. Cui, X.-S. Wei, 和 Z.-M. Chen，“Bbn: 双边分支网络与累积学习用于长尾视觉识别”，发表于*计算机视觉与模式识别*，2020年，第9719–9728页。'
- en: '[45] K. Tang, J. Huang, and H. Zhang, “Long-tailed classification by keeping
    the good and removing the bad momentum causal effect,” in *Advances in Neural
    Information Processing Systems*, vol. 33, 2020.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] K. Tang, J. Huang, 和 H. Zhang，“通过保持好的和去除坏的动量因果效应进行长尾分类”，发表于*神经信息处理系统进展*，第33卷，2020年。'
- en: '[46] H. Guo and S. Wang, “Long-tailed multi-label visual recognition by collaborative
    training on uniform and re-balanced samplings,” in *Computer Vision and Pattern
    Recognition*, 2021, pp. 15 089–15 098.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] H. Guo 和 S. Wang，“通过在均匀和重新平衡采样上的协同训练进行长尾多标签视觉识别”，发表于*计算机视觉与模式识别*，2021年，第15 089–15 098页。'
- en: '[47] M. R. Keaton, R. J. Zaveri, M. Kovur, C. Henderson, D. A. Adjeroh, and
    G. Doretto, “Fine-grained visual classification of plant species in the wild:
    Object detection as a reinforced means of attention,” *arXiv:2106.02141*, 2021.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] M. R. Keaton, R. J. Zaveri, M. Kovur, C. Henderson, D. A. Adjeroh, 和 G. Doretto，“野外植物物种的细粒度视觉分类：将目标检测作为增强注意力的手段”，*arXiv:2106.02141*，2021年。'
- en: '[48] Y. Zhong, W. Deng, M. Wang, J. Hu, J. Peng, X. Tao, and Y. Huang, “Unequal-training
    for deep face recognition with long-tailed noisy data,” in *Computer Vision and
    Pattern Recognition*, 2019, pp. 7812–7821.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Y. Zhong, W. Deng, M. Wang, J. Hu, J. Peng, X. Tao, 和 Y. Huang，“用于长尾噪声数据的深度人脸识别的不平等训练”，发表于*计算机视觉与模式识别*，2019年，第7812–7821页。'
- en: '[49] J. Liu, Y. Sun, C. Han, Z. Dou, and W. Li, “Deep representation learning
    on long-tailed data: A learnable embedding augmentation perspective,” in *Computer
    Vision and Pattern Recognition*, 2020.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] J. Liu, Y. Sun, C. Han, Z. Dou, 和 W. Li，“在长尾数据上的深度表示学习：可学习的嵌入增强视角”，发表于*计算机视觉与模式识别*，2020年。'
- en: '[50] Q. Dong, S. Gong, and X. Zhu, “Class rectification hard mining for imbalanced
    deep learning,” in *International Conference on Computer Vision*, 2017, pp. 1851–1860.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] Q. Dong, S. Gong, 和 X. Zhu，“用于不平衡深度学习的类别修正硬挖掘”，发表于*计算机视觉国际会议*，2017年，第1851–1860页。'
- en: '[51] Z. Deng, H. Liu, Y. Wang, C. Wang, Z. Yu, and X. Sun, “Pml: Progressive
    margin loss for long-tailed age classification,” in *Computer Vision and Pattern
    Recognition*, 2021, pp. 10 503–10 512.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Z. Deng, H. Liu, Y. Wang, C. Wang, Z. Yu, 和 X. Sun，“Pml: 用于长尾年龄分类的渐进边际损失”，发表于*计算机视觉与模式识别*，2021年，第10 503–10 512页。'
- en: '[52] Z. Zhang, S. Yu, S. Yang, Y. Zhou, and B. Zhao, “Rail-5k: a real-world
    dataset for rail surface defects detection,” *arXiv:2106.14366*, 2021.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] Z. Zhang, S. Yu, S. Yang, Y. Zhou, 和 B. Zhao，“Rail-5k: 用于铁路表面缺陷检测的现实世界数据集”，*arXiv:2106.14366*，2021年。'
- en: '[53] A. Galdran, G. Carneiro, and M. A. G. Ballester, “Balanced-mixup for highly
    imbalanced medical image classification,” in *International Conference on Medical
    Image Computing and Computer-Assisted Intervention*, 2021.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] A. Galdran, G. Carneiro, 和 M. A. G. Ballester，“用于高度不平衡医学图像分类的平衡混合方法”，发表于*医学图像计算与计算机辅助手术国际会议*，2021年。'
- en: '[54] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár, “Focal loss for
    dense object detection,” in *International Conference on Computer Vision*, 2017,
    pp. 2980–2988.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] T.-Y. Lin, P. Goyal, R. Girshick, K. He, 和 P. Dollár，“密集目标检测的焦点损失”，发表于*计算机视觉国际会议*，2017年，第2980–2988页。'
- en: '[55] T.-I. Hsieh, E. Robb, H.-T. Chen, and J.-B. Huang, “Droploss for long-tail
    instance segmentation,” in *AAAI Conference on Artificial Intelligence*, vol. 35,
    no. 2, 2021, pp. 1549–1557.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] T.-I. Hsieh, E. Robb, H.-T. Chen, 和 J.-B. Huang，“长尾实例分割的丢失函数”，发表于*人工智能AAAI会议*，第35卷，第2期，2021年，第1549–1557页。'
- en: '[56] Y. Li, T. Wang, B. Kang, S. Tang, C. Wang, J. Li, and J. Feng, “Overcoming
    classifier imbalance for long-tail object detection with balanced group softmax,”
    in *Computer Vision and Pattern Recognition*, 2020, pp. 10 991–11 000.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Y. Li, T. Wang, B. Kang, S. Tang, C. Wang, J. Li, 和 J. Feng，“通过平衡组软最大值克服长尾目标检测中的分类器不平衡”，发表于*计算机视觉与模式识别*，2020年，第10 991–11 000页。'
- en: '[57] T. Weyand, A. Araujo, B. Cao, and J. Sim, “Google landmarks dataset v2-a
    large-scale benchmark for instance-level recognition and retrieval,” in *Computer
    Vision and Pattern Recognition*, 2020, pp. 2575–2584.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] T. Weyand, A. Araujo, B. Cao, 和 J. Sim，“Google地标数据集v2-用于实例级识别和检索的大规模基准”，发表于*计算机视觉与模式识别*，2020年，第2575–2584页。'
- en: '[58] Y. Zang, C. Huang, and C. C. Loy, “Fasa: Feature augmentation and sampling
    adaptation for long-tailed instance segmentation,” in *International Conference
    on Computer Vision*, 2021.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] Y. Zang, C. Huang, 和 C. C. Loy，“Fasa: 特征增强与采样适应用于长尾实例分割”，发表于*计算机视觉国际会议*，2021年。'
- en: '[59] J. Wu, L. Song, T. Wang, Q. Zhang, and J. Yuan, “Forest r-cnn: Large-vocabulary
    long-tailed object detection and instance segmentation,” in *ACM International
    Conference on Multimedia*, 2020, pp. 1570–1578.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] J. Wu, L. Song, T. Wang, Q. Zhang, 和 J. Yuan, “森林 R-CNN：大词汇量长尾对象检测与实例分割”，发表于*ACM
    国际多媒体大会*，2020年，页码1570–1578。'
- en: '[60] J. Mao, M. Niu, C. Jiang, H. Liang, X. Liang, Y. Li, C. Ye, W. Zhang,
    Z. Li, J. Yu *et al.*, “One million scenes for autonomous driving: Once dataset,”
    in *NeurIPS 2021 Datasets and Benchmarks Track*, 2021.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] J. Mao, M. Niu, C. Jiang, H. Liang, X. Liang, Y. Li, C. Ye, W. Zhang,
    Z. Li, J. Yu *等*，“百万场景用于自动驾驶：Once数据集”，发表于*NeurIPS 2021 数据集和基准测试*，2021年。'
- en: '[61] A. Desai, T.-Y. Wu, S. Tripathi, and N. Vasconcelos, “Learning of visual
    relations: The devil is in the tails,” in *International Conference on Computer
    Vision*, 2021.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] A. Desai, T.-Y. Wu, S. Tripathi, 和 N. Vasconcelos, “视觉关系学习：隐含在尾部的魔鬼”，发表于*国际计算机视觉大会*，2021年。'
- en: '[62] N. Dhingra, F. Ritter, and A. Kunz, “Bgt-net: Bidirectional gru transformer
    network for scene graph generation,” in *Computer Vision and Pattern Recognition*,
    2021, pp. 2150–2159.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] N. Dhingra, F. Ritter, 和 A. Kunz, “Bgt-net：用于场景图生成的双向 GRU 变换网络”，发表于*计算机视觉与模式识别*，2021年，页码2150–2159。'
- en: '[63] J. Chen, A. Agarwal, S. Abdelkarim, D. Zhu, and M. Elhoseiny, “Reltransformer:
    Balancing the visual relationship detection from local context, scene and memory,”
    *arXiv:2104.11934*, 2021.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] J. Chen, A. Agarwal, S. Abdelkarim, D. Zhu, 和 M. Elhoseiny, “Reltransformer：平衡来自局部上下文、场景和记忆的视觉关系检测”，*arXiv:2104.11934*，2021年。'
- en: '[64] Z. Li, E. Stengel-Eskin, Y. Zhang, C. Xie, Q. Tran, B. Van Durme, and
    A. Yuille, “Calibrating concepts and operations: Towards symbolic reasoning on
    real images,” in *International Conference on Computer Vision*, 2021.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Z. Li, E. Stengel-Eskin, Y. Zhang, C. Xie, Q. Tran, B. Van Durme, 和 A.
    Yuille, “校准概念和操作：迈向对真实图像的符号推理”，发表于*国际计算机视觉大会*，2021年。'
- en: '[65] G. Wang, D. Forsyth, and D. Hoiem, “Comparative object similarity for
    improved recognition with few or no examples,” in *Computer Vision and Pattern
    Recognition*, 2010, pp. 3525–3532.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] G. Wang, D. Forsyth, 和 D. Hoiem, “通过比较对象相似性提升少量或没有示例的识别”，发表于*计算机视觉与模式识别*，2010年，页码3525–3532。'
- en: '[66] C. C. Loy, T. M. Hospedales, T. Xiang, and S. Gong, “Stream-based joint
    exploration-exploitation active learning,” in *Computer Vision and Pattern Recognition*,
    2012, pp. 1560–1567.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] C. C. Loy, T. M. Hospedales, T. Xiang, 和 S. Gong, “基于流的联合探索-利用主动学习”，发表于*计算机视觉与模式识别*，2012年，页码1560–1567。'
- en: '[67] J. Yang, B. Price, S. Cohen, and M.-H. Yang, “Context driven scene parsing
    with attention to rare classes,” in *Computer Vision and Pattern Recognition*,
    2014, pp. 3294–3301.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] J. Yang, B. Price, S. Cohen, 和 M.-H. Yang, “基于上下文的场景解析，关注稀有类别”，发表于*计算机视觉与模式识别*，2014年，页码3294–3301。'
- en: '[68] J. Pitman and M. Yor, “The two-parameter poisson-dirichlet distribution
    derived from a stable subordinator,” *The Annals of Probability*, pp. 855–900,
    1997.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] J. Pitman 和 M. Yor, “从稳定次级分布得出的双参数泊松-狄利克雷分布”，*概率年鉴*，页码855–900，1997年。'
- en: '[69] D. G. Lowe, “Distinctive image features from scale-invariant keypoints,”
    *International Journal of Computer Vision*, vol. 60, no. 2, pp. 91–110, 2004.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] D. G. Lowe, “从尺度不变关键点中提取独特图像特征”，*国际计算机视觉期刊*，第60卷，第2期，页码91–110，2004年。'
- en: '[70] N. Dalal and B. Triggs, “Histograms of oriented gradients for human detection,”
    in *Computer Vision and Pattern Recognition*, vol. 1, 2005, pp. 886–893.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] N. Dalal 和 B. Triggs, “用于人体检测的方向梯度直方图”，发表于*计算机视觉与模式识别*，第1卷，2005年，页码886–893。'
- en: '[71] M. J. Swain and D. H. Ballard, “Color indexing,” *International Journal
    of Computer Vision*, vol. 7, no. 1, pp. 11–32, 1991.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] M. J. Swain 和 D. H. Ballard, “颜色索引”，*国际计算机视觉期刊*，第7卷，第1期，页码11–32，1991年。'
- en: '[72] H. He and E. A. Garcia, “Learning from imbalanced data,” *IEEE Transactions
    on Knowledge and Data Engineering*, vol. 21, no. 9, pp. 1263–1284, 2009.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] H. He 和 E. A. Garcia, “从不平衡数据中学习”，*IEEE 知识与数据工程学报*，第21卷，第9期，页码1263–1284，2009年。'
- en: '[73] J. Snell, K. Swersky, and R. Zemel, “Prototypical networks for few-shot
    learning,” *Advances in Neural Information Processing Systems*, 2017.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] J. Snell, K. Swersky, 和 R. Zemel, “用于少样本学习的原型网络”，*神经信息处理系统进展*，2017年。'
- en: '[74] F. Sung, Y. Yang, L. Zhang, T. Xiang, P. H. Torr, and T. M. Hospedales,
    “Learning to compare: Relation network for few-shot learning,” in *Computer Vision
    and Pattern Recognition*, 2018, pp. 1199–1208.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] F. Sung, Y. Yang, L. Zhang, T. Xiang, P. H. Torr, 和 T. M. Hospedales,
    “学习比较：少样本学习的关系网络”，发表于*计算机视觉与模式识别*，2018年，页码1199–1208。'
- en: '[75] Q. Sun, Y. Liu, T.-S. Chua, and B. Schiele, “Meta-transfer learning for
    few-shot learning,” in *Computer Vision and Pattern Recognition*, 2019.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] Q. Sun, Y. Liu, T.-S. Chua, 和 B. Schiele, “少样本学习的元转移学习，” 见 *计算机视觉与模式识别*，2019
    年。'
- en: '[76] Y. Wang, Q. Yao, J. T. Kwok, and L. M. Ni, “Generalizing from a few examples:
    A survey on few-shot learning,” *ACM Computing Surveys*, vol. 53, no. 3, pp. 1–34,
    2020.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] Y. Wang, Q. Yao, J. T. Kwok, 和 L. M. Ni, “从少量示例中泛化：少样本学习综述，” *ACM 计算机调查*，第
    53 卷，第 3 期，页码 1–34，2020 年。'
- en: '[77] D. Krueger, E. Caballero *et al.*, “Out-of-distribution generalization
    via risk extrapolation,” in *International Conference on Machine Learning*, 2021,
    pp. 5815–5826.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] D. Krueger, E. Caballero *等*，“通过风险外推实现分布外泛化，” 见 *国际机器学习大会*，2021 年，页码 5815–5826。'
- en: '[78] Z. Shen, J. Liu, Y. He, X. Zhang, R. Xu, H. Yu, and P. Cui, “Towards out-of-distribution
    generalization: A survey,” *arXiv:2108.13624*, 2021.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] Z. Shen, J. Liu, Y. He, X. Zhang, R. Xu, H. Yu, 和 P. Cui, “面向分布外泛化：综述，”
    *arXiv:2108.13624*，2021 年。'
- en: '[79] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang, “Domain adaptation via
    transfer component analysis,” *IEEE Transactions on Neural Networks*, vol. 22,
    no. 2, pp. 199–210, 2010.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] S. J. Pan, I. W. Tsang, J. T. Kwok, 和 Q. Yang, “通过转移成分分析进行领域适配，” *IEEE
    神经网络汇刊*，第 22 卷，第 2 期，页码 199–210，2010 年。'
- en: '[80] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell, “Adversarial discriminative
    domain adaptation,” in *Computer Vision and Pattern Recognition*, 2017, pp. 7167–7176.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] E. Tzeng, J. Hoffman, K. Saenko, 和 T. Darrell, “对抗性判别领域适配，” 见 *计算机视觉与模式识别*，2017
    年，页码 7167–7176。'
- en: '[81] Y. Zhang, H. Chen, Y. Wei, P. Zhao, J. Cao, X. Fan, X. Lou, H. Liu, J. Hou,
    X. Han *et al.*, “From whole slide imaging to microscopy: Deep microscopy adaptation
    network for histopathology cancer image classification,” in *International Conference
    on Medical Image Computing and Computer-Assisted Intervention*, 2019, pp. 360–368.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] Y. Zhang, H. Chen, Y. Wei, P. Zhao, J. Cao, X. Fan, X. Lou, H. Liu, J.
    Hou, X. Han *等*，“从全切片成像到显微镜：用于组织病理学癌症图像分类的深度显微镜适配网络，” 见 *医学图像计算与计算机辅助干预国际会议*，2019
    年，页码 360–368。'
- en: '[82] Y. Zhang, Y. Wei *et al.*, “Collaborative unsupervised domain adaptation
    for medical image diagnosis,” *IEEE Transactions on Image Processing*, 2020.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] Y. Zhang, Y. Wei *等*，“面向医学图像诊断的协作式无监督领域适配，” *IEEE 图像处理汇刊*，2020 年。'
- en: '[83] Z. Qiu, Y. Zhang, H. Lin, S. Niu, Y. Liu, Q. Du, and M. Tan, “Source-free
    domain adaptation via avatar prototype generation and adaptation,” in *International
    Joint Conference on Artificial Intelligence*, 2021.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] Z. Qiu, Y. Zhang, H. Lin, S. Niu, Y. Liu, Q. Du, 和 M. Tan, “通过化身原型生成和适配实现无源领域适配，”
    见 *国际人工智能联合会议*，2021 年。'
- en: '[84] H. Wu, H. Zhu, Y. Yan, J. Wu, Y. Zhang, and M. K. Ng, “Heterogeneous domain
    adaptation by information capturing and distribution matching,” *IEEE Transactions
    on Image Processing*, vol. 30, pp. 6364–6376, 2021.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] H. Wu, H. Zhu, Y. Yan, J. Wu, Y. Zhang, 和 M. K. Ng, “通过信息捕获和分布匹配进行异构领域适配，”
    *IEEE 图像处理汇刊*，第 30 卷，页码 6364–6376，2021 年。'
- en: '[85] D. Li, Y. Yang, Y.-Z. Song, and T. M. Hospedales, “Deeper, broader and
    artier domain generalization,” in *International Conference on Computer Vision*,
    2017, pp. 5542–5550.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] D. Li, Y. Yang, Y.-Z. Song, 和 T. M. Hospedales, “更深、更广、更具艺术性的领域泛化，” 见
    *国际计算机视觉大会*，2017 年，页码 5542–5550。'
- en: '[86] H. Li, S. J. Pan, S. Wang, and A. C. Kot, “Domain generalization with
    adversarial feature learning,” in *Computer Vision and Pattern Recognition*, 2018,
    pp. 5400–5409.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] H. Li, S. J. Pan, S. Wang, 和 A. C. Kot, “通过对抗特征学习进行领域泛化，” 见 *计算机视觉与模式识别*，2018
    年，页码 5400–5409。'
- en: '[87] L. Neal, M. Olson, X. Fern, W.-K. Wong, and F. Li, “Open set learning
    with counterfactual images,” in *European Conference on Computer Vision*, 2018,
    pp. 613–628.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] L. Neal, M. Olson, X. Fern, W.-K. Wong, 和 F. Li, “通过反事实图像实现开放集学习，” 见 *欧洲计算机视觉大会*，2018
    年，页码 613–628。'
- en: '[88] Y. Fu, X. Wang, H. Dong, Y.-G. Jiang, M. Wang, X. Xue, and L. Sigal, “Vocabulary-informed
    zero-shot and open-set learning,” *IEEE Transactions on Pattern Analysis and Machine
    Intelligence*, vol. 42, no. 12, pp. 3136–3152, 2019.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] Y. Fu, X. Wang, H. Dong, Y.-G. Jiang, M. Wang, X. Xue, 和 L. Sigal, “词汇信息驱动的零样本和开放集学习，”
    *IEEE 计算机学会模式分析与机器智能汇刊*，第 42 卷，第 12 期，页码 3136–3152，2019 年。'
- en: '[89] C. Huang, Y. Li, C. C. Loy, and X. Tang, “Learning deep representation
    for imbalanced classification,” in *Computer Vision and Pattern Recognition*,
    2016.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] C. Huang, Y. Li, C. C. Loy, 和 X. Tang, “学习用于不平衡分类的深度表示，” 见 *计算机视觉与模式识别*，2016
    年。'
- en: '[90] W. Ouyang, X. Wang, C. Zhang, and X. Yang, “Factors in finetuning deep
    model for object detection with long-tail distribution,” in *Computer Vision and
    Pattern Recognition*, 2016, pp. 864–873.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] W. Ouyang, X. Wang, C. Zhang, 和 X. Yang, “针对长尾分布的目标检测深度模型微调因素，”发表于*计算机视觉与模式识别*，2016年，第864–873页。'
- en: '[91] Y.-X. Wang, D. Ramanan, and M. Hebert, “Learning to model the tail,” in
    *Advances in Neural Information Processing Systems*, 2017.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] Y.-X. Wang, D. Ramanan, 和 M. Hebert, “学习建模长尾，”发表于*神经信息处理系统进展*，2017年。'
- en: '[92] Y. Cui, Y. Song, C. Sun, A. Howard, and S. Belongie, “Large scale fine-grained
    categorization and domain-specific transfer learning,” in *Computer Vision and
    Pattern Recognition*, 2018, pp. 4109–4118.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] Y. Cui, Y. Song, C. Sun, A. Howard, 和 S. Belongie, “大规模细粒度分类与领域特定迁移学习，”发表于*计算机视觉与模式识别*，2018年，第4109–4118页。'
- en: '[93] Y. Wang, W. Gan, J. Yang, W. Wu, and J. Yan, “Dynamic curriculum learning
    for imbalanced data classification,” in *International Conference on Computer
    Vision*, 2019, pp. 5017–5026.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] Y. Wang, W. Gan, J. Yang, W. Wu, 和 J. Yan, “针对不平衡数据分类的动态课程学习，”发表于*国际计算机视觉会议*，2019年，第5017–5026页。'
- en: '[94] J. Shu, Q. Xie, L. Yi, Q. Zhao, S. Zhou, Z. Xu, and D. Meng, “Meta-weight-net:
    Learning an explicit mapping for sample weighting,” *Advances in Neural Information
    Processing Systems*, 2019.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] J. Shu, Q. Xie, L. Yi, Q. Zhao, S. Zhou, Z. Xu, 和 D. Meng, “Meta-weight-net：学习样本加权的显式映射，”*神经信息处理系统进展*，2019年。'
- en: '[95] S. Khan, M. Hayat, S. W. Zamir, J. Shen, and L. Shao, “Striking the right
    balance with uncertainty,” in *Computer Vision and Pattern Recognition*, 2019,
    pp. 103–112.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] S. Khan, M. Hayat, S. W. Zamir, J. Shen, 和 L. Shao, “用不确定性找到正确的平衡，”发表于*计算机视觉与模式识别*，2019年，第103–112页。'
- en: '[96] X. Yin, X. Yu, K. Sohn, X. Liu, and M. Chandraker, “Feature transfer learning
    for face recognition with under-represented data,” in *Computer Vision and Pattern
    Recognition*, 2019, pp. 5704–5713.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] X. Yin, X. Yu, K. Sohn, X. Liu, 和 M. Chandraker, “面部识别中的特征迁移学习：应对数据不足问题，”发表于*计算机视觉与模式识别*，2019年，第5704–5713页。'
- en: '[97] R. Jiawei, C. Yu, X. Ma, H. Zhao, S. Yi *et al.*, “Balanced meta-softmax
    for long-tailed visual recognition,” in *Advances in Neural Information Processing
    Systems*, 2020.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] R. Jiawei, C. Yu, X. Ma, H. Zhao, S. Yi *等*，“长尾视觉识别中的平衡元软最大，”发表于*神经信息处理系统进展*，2020年。'
- en: '[98] X. Hu, Y. Jiang, K. Tang, J. Chen, C. Miao, and H. Zhang, “Learning to
    segment the tail,” in *Computer Vision and Pattern Recognition*, 2020.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] X. Hu, Y. Jiang, K. Tang, J. Chen, C. Miao, 和 H. Zhang, “学习分割长尾数据，”发表于*计算机视觉与模式识别*，2020年。'
- en: '[99] J. Tian, Y.-C. Liu, N. Glaser, Y.-C. Hsu, and Z. Kira, “Posterior re-calibration
    for imbalanced datasets,” in *Advances in Neural Information Processing Systems*,
    2020.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] J. Tian, Y.-C. Liu, N. Glaser, Y.-C. Hsu, 和 Z. Kira, “不平衡数据集的后验重新校准，”发表于*神经信息处理系统进展*，2020年。'
- en: '[100] J. Kim, J. Jeong, and J. Shin, “M2m: Imbalanced classification via major-to-minor
    translation,” in *Computer Vision and Pattern Recognition*, 2020.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] J. Kim, J. Jeong, 和 J. Shin, “M2m：通过主到次的转换进行不平衡分类，”发表于*计算机视觉与模式识别*，2020年。'
- en: '[101] P. Chu, X. Bian, S. Liu, and H. Ling, “Feature space augmentation for
    long-tailed data,” in *European Conference on Computer Vision*, 2020.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] P. Chu, X. Bian, S. Liu, 和 H. Ling, “针对长尾数据的特征空间扩展，”发表于*欧洲计算机视觉会议*，2020年。'
- en: '[102] Y. Yang and Z. Xu, “Rethinking the value of labels for improving class-imbalanced
    learning,” in *Advances in Neural Information Processing Systems*, 2020.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] Y. Yang 和 Z. Xu, “重新思考标签在改进类别不平衡学习中的价值，”发表于*神经信息处理系统进展*，2020年。'
- en: '[103] L. Xiang, G. Ding, and J. Han, “Learning from multiple experts: Self-paced
    knowledge distillation for long-tailed classification,” in *European Conference
    on Computer Vision*, 2020, pp. 247–263.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] L. Xiang, G. Ding, 和 J. Han, “来自多个专家的学习：自适应知识蒸馏用于长尾分类，”发表于*欧洲计算机视觉会议*，2020年，第247–263页。'
- en: '[104] L. Zhu and Y. Yang, “Inflated episodic memory with region self-attention
    for long-tailed visual recognition,” in *Computer Vision and Pattern Recognition*,
    2020, pp. 4344–4353.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] L. Zhu 和 Y. Yang, “带区域自注意力的膨胀情景记忆用于长尾视觉识别，”发表于*计算机视觉与模式识别*，2020年，第4344–4353页。'
- en: '[105] T.-Y. Wu, P. Morgado, P. Wang, C.-H. Ho, and N. Vasconcelos, “Solving
    long-tailed recognition with deep realistic taxonomic classifier,” in *European
    Conference on Computer Vision*, 2020, pp. 171–189.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] T.-Y. Wu, P. Morgado, P. Wang, C.-H. Ho, 和 N. Vasconcelos, “通过深度现实分类器解决长尾识别问题，”发表于*欧洲计算机视觉会议*，2020年，第171–189页。'
- en: '[106] C. Wei, K. Sohn, C. Mellina, A. Yuille, and F. Yang, “Crest: A class-rebalancing
    self-training framework for imbalanced semi-supervised learning,” in *Computer
    Vision and Pattern Recognition*, 2021.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] C. Wei, K. Sohn, C. Mellina, A. Yuille, 和 F. Yang，“Crest：一种用于不平衡半监督学习的类重平衡自训练框架”，见于
    *计算机视觉与模式识别*，2021。'
- en: '[107] B. Liu, H. Li, H. Kang, G. Hua, and N. Vasconcelos, “Gistnet: a geometric
    structure transfer network for long-tailed recognition,” in *International Conference
    on Computer Vision*, 2021.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] B. Liu, H. Li, H. Kang, G. Hua, 和 N. Vasconcelos，“Gistnet：用于长尾识别的几何结构转移网络”，见于
    *国际计算机视觉大会*，2021。'
- en: '[108] J. Tan, X. Lu, G. Zhang, C. Yin, and Q. Li, “Equalization loss v2: A
    new gradient balance approach for long-tailed object detection,” in *Computer
    Vision and Pattern Recognition*, 2021, pp. 1685–1694.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] J. Tan, X. Lu, G. Zhang, C. Yin, 和 Q. Li，“均衡损失v2：一种用于长尾对象检测的新梯度平衡方法”，见于
    *计算机视觉与模式识别*，2021，第1685–1694页。'
- en: '[109] J. Wang, W. Zhang, Y. Zang, Y. Cao, J. Pang, T. Gong, K. Chen, Z. Liu,
    C. C. Loy, and D. Lin, “Seesaw loss for long-tailed instance segmentation,” in
    *Computer Vision and Pattern Recognition*, 2021.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] J. Wang, W. Zhang, Y. Zang, Y. Cao, J. Pang, T. Gong, K. Chen, Z. Liu,
    C. C. Loy, 和 D. Lin，“长尾实例分割的跷跷板损失”，见于 *计算机视觉与模式识别*，2021。'
- en: '[110] T. Wang, Y. Zhu, C. Zhao, W. Zeng, J. Wang, and M. Tang, “Adaptive class
    suppression loss for long-tail object detection,” in *Computer Vision and Pattern
    Recognition*, 2021, pp. 3103–3112.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] T. Wang, Y. Zhu, C. Zhao, W. Zeng, J. Wang, 和 M. Tang，“用于长尾对象检测的自适应类抑制损失”，见于
    *计算机视觉与模式识别*，2021，第3103–3112页。'
- en: '[111] S. Park, J. Lim, Y. Jeon, and J. Y. Choi, “Influence-balanced loss for
    imbalanced visual classification,” in *International Conference on Computer Vision*,
    2021.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] S. Park, J. Lim, Y. Jeon, 和 J. Y. Choi，“用于不平衡视觉分类的影响平衡损失”，见于 *国际计算机视觉大会*，2021。'
- en: '[112] G. R. Kini, O. Paraskevas, S. Oymak, and C. Thrampoulidis, “Label-imbalanced
    and group-sensitive classification under overparameterization,” in *Advances in
    Neural Information Processing Systems*, vol. 34, 2021, pp. 18 970–18 983.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] G. R. Kini, O. Paraskevas, S. Oymak, 和 C. Thrampoulidis，“在过参数化下的标签不平衡和组敏感分类”，见于
    *神经信息处理系统进展*，第34卷，2021，第18 970–18 983页。'
- en: '[113] T. Wu, Z. Liu, Q. Huang, Y. Wang, and D. Lin, “Adversarial robustness
    under long-tailed distribution,” in *Computer Vision and Pattern Recognition*,
    2021, pp. 8659–8668.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] T. Wu, Z. Liu, Q. Huang, Y. Wang, 和 D. Lin，“长尾分布下的对抗性鲁棒性”，见于 *计算机视觉与模式识别*，2021，第8659–8668页。'
- en: '[114] Z. Zhong, J. Cui, S. Liu, and J. Jia, “Improving calibration for long-tailed
    recognition,” in *Computer Vision and Pattern Recognition*, 2021.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] Z. Zhong, J. Cui, S. Liu, 和 J. Jia，“提高长尾识别的校准”，见于 *计算机视觉与模式识别*，2021。'
- en: '[115] S. Changpinyo, P. Sharma, N. Ding, and R. Soricut, “Conceptual 12m: Pushing
    web-scale image-text pre-training to recognize long-tail visual concepts,” in
    *Computer Vision and Pattern Recognition*, 2021.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] S. Changpinyo, P. Sharma, N. Ding, 和 R. Soricut，“概念性12m：推动网页规模的图像-文本预训练以识别长尾视觉概念”，见于
    *计算机视觉与模式识别*，2021。'
- en: '[116] Y.-Y. He, J. Wu, and X.-S. Wei, “Distilling virtual examples for long-tailed
    recognition,” in *International Conference on Computer Vision*, 2021.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] Y.-Y. He, J. Wu, 和 X.-S. Wei，“用于长尾识别的虚拟样本蒸馏”，见于 *国际计算机视觉大会*，2021。'
- en: '[117] C. Zhang, T.-Y. Pan, Y. Li, H. Hu, D. Xuan, S. Changpinyo, B. Gong, and
    W.-L. Chao, “Mosaicos: A simple and effective use of object-centric images for
    long-tailed object detection,” in *International Conference on Computer Vision*,
    2021.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] C. Zhang, T.-Y. Pan, Y. Li, H. Hu, D. Xuan, S. Changpinyo, B. Gong, 和
    W.-L. Chao，“Mosaicos：一种简单而有效的使用对象中心图像进行长尾对象检测的方法”，见于 *国际计算机视觉大会*，2021。'
- en: '[118] J. Wang, T. Lukasiewicz, X. Hu, J. Cai, and Z. Xu, “Rsg: A simple but
    effective module for learning imbalanced datasets,” in *Computer Vision and Pattern
    Recognition*, 2021, pp. 3784–3793.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] J. Wang, T. Lukasiewicz, X. Hu, J. Cai, 和 Z. Xu，“Rsg：一种简单但有效的模块，用于学习不平衡数据集”，见于
    *计算机视觉与模式识别*，2021，第3784–3793页。'
- en: '[119] T. Li, L. Wang, and G. Wu, “Self supervision to distillation for long-tailed
    visual recognition,” in *International Conference on Computer Vision*, 2021.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] T. Li, L. Wang, 和 G. Wu，“自监督到蒸馏用于长尾视觉识别”，见于 *国际计算机视觉大会*，2021。'
- en: '[120] S. Li, K. Gong, C. H. Liu, Y. Wang, F. Qiao, and X. Cheng, “Metasaug:
    Meta semantic augmentation for long-tailed visual recognition,” in *Computer Vision
    and Pattern Recognition*, 2021, pp. 5212–5221.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] S. Li, K. Gong, C. H. Liu, Y. Wang, F. Qiao, 和 X. Cheng，“Metasaug：用于长尾视觉识别的元语义增强”，见于
    *计算机视觉与模式识别*，2021，第5212–5221页。'
- en: '[121] J. Cui, Z. Zhong, S. Liu, B. Yu, and J. Jia, “Parametric contrastive
    learning,” in *International Conference on Computer Vision*, 2021.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] J. Cui、Z. Zhong、S. Liu、B. Yu 和 J. Jia，“参数对比学习，”在*国际计算机视觉会议*，2021年。'
- en: '[122] D. Samuel and G. Chechik, “Distributional robustness loss for long-tail
    learning,” in *International Conference on Computer Vision*, 2021.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] D. Samuel 和 G. Chechik，“长尾学习的分布鲁棒损失，”在*国际计算机视觉会议*，2021年。'
- en: '[123] P. Wang, K. Han, X.-S. Wei, L. Zhang, and L. Wang, “Contrastive learning
    based hybrid networks for long-tailed image classification,” in *Computer Vision
    and Pattern Recognition*, 2021, pp. 943–952.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] P. Wang、K. Han、X.-S. Wei、L. Zhang 和 L. Wang，“基于对比学习的混合网络用于长尾图像分类，”在*计算机视觉与模式识别*，2021年，页码943–952。'
- en: '[124] J. Cai, Y. Wang, and J.-N. Hwang, “Ace: Ally complementary experts for
    solving long-tailed recognition in one-shot,” in *International Conference on
    Computer Vision*, 2021.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] J. Cai、Y. Wang 和 J.-N. Hwang，“Ace: 解决一次性长尾识别的互补专家，”在*国际计算机视觉会议*，2021年。'
- en: '[125] J. Cui, S. Liu, Z. Tian, Z. Zhong, and J. Jia, “Reslt: Residual learning
    for long-tailed recognition,” *IEEE Transactions on Pattern Analysis and Machine
    Intelligence*, 2022.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] J. Cui、S. Liu、Z. Tian、Z. Zhong 和 J. Jia，“Reslt: 长尾识别的残差学习，”*IEEE模式分析与机器智能学报*，2022年。'
- en: '[126] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, “Smote:
    synthetic minority over-sampling technique,” *Journal of artificial intelligence
    research*, vol. 16, pp. 321–357, 2002.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] N. V. Chawla、K. W. Bowyer、L. O. Hall 和 W. P. Kegelmeyer，“SMOTE: 合成少数类过采样技术，”*人工智能研究期刊*，第16卷，页码321–357，2002年。'
- en: '[127] A. Estabrooks, T. Jo, and N. Japkowicz, “A multiple resampling method
    for learning from imbalanced data sets,” *Computational Intelligence*, vol. 20,
    no. 1, pp. 18–36, 2004.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] A. Estabrooks、T. Jo 和 N. Japkowicz，“一种用于不平衡数据集的多重重采样方法，”*计算智能*，第20卷，第1期，页码18–36，2004年。'
- en: '[128] X.-Y. Liu, J. Wu, and Z.-H. Zhou, “Exploratory undersampling for class-imbalance
    learning,” *IEEE Transactions on Systems, Man, and Cybernetics*, vol. 39, no. 2,
    pp. 539–550, 2008.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] X.-Y. Liu、J. Wu 和 Z.-H. Zhou，“用于类别不平衡学习的探索性欠采样，”*IEEE系统、人类与控制论学报*，第39卷，第2期，页码539–550，2008年。'
- en: '[129] Z. Zhang and T. Pfister, “Learning fast sample re-weighting without reward
    data,” in *International Conference on Computer Vision*, 2021.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] Z. Zhang 和 T. Pfister，“无需奖励数据的快速样本重加权学习，”在*国际计算机视觉会议*，2021年。'
- en: '[130] D. Mahajan, R. Girshick, V. Ramanathan, K. He, M. Paluri, Y. Li, A. Bharambe,
    and L. Van Der Maaten, “Exploring the limits of weakly supervised pretraining,”
    in *European conference on computer vision*, 2018, pp. 181–196.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] D. Mahajan、R. Girshick、V. Ramanathan、K. He、M. Paluri、Y. Li、A. Bharambe
    和 L. Van Der Maaten，“探索弱监督预训练的极限，”在*欧洲计算机视觉会议*，2018年，页码181–196。'
- en: '[131] T. Hospedales, A. Antoniou, P. Micaelli, and A. Storkey, “Meta-learning
    in neural networks: A survey,” *IEEE Transactions on Pattern Analysis and Machine
    Intelligence*, vol. 44, no. 9, pp. 5149–5169, 2021.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] T. Hospedales、A. Antoniou、P. Micaelli 和 A. Storkey，“神经网络中的元学习：综述，”*IEEE模式分析与机器智能学报*，第44卷，第9期，页码5149–5169，2021年。'
- en: '[132] C. Elkan, “The foundations of cost-sensitive learning,” in *International
    Joint Conference on Artificial Intelligence*, 2001.'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] C. Elkan，“成本敏感学习的基础，”在*国际人工智能联合会议*，2001年。'
- en: '[133] Z.-H. Zhou and X.-Y. Liu, “Training cost-sensitive neural networks with
    methods addressing the class imbalance problem,” *IEEE Transactions on Knowledge
    and Data Engineering*, vol. 18, no. 1, pp. 63–77, 2005.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] Z.-H. Zhou 和 X.-Y. Liu，“用方法解决类别不平衡问题的训练成本敏感神经网络，”*IEEE知识与数据工程学报*，第18卷，第1期，页码63–77，2005年。'
- en: '[134] P. Zhao, Y. Zhang, M. Wu, S. C. Hoi, M. Tan, and J. Huang, “Adaptive
    cost-sensitive online classification,” *IEEE Transactions on Knowledge and Data
    Engineering*, vol. 31, no. 2, pp. 214–228, 2018.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] P. Zhao、Y. Zhang、M. Wu、S. C. Hoi、M. Tan 和 J. Huang，“自适应成本敏感在线分类，”*IEEE知识与数据工程学报*，第31卷，第2期，页码214–228，2018年。'
- en: '[135] Y. Zhang, P. Zhao, J. Cao, W. Ma, J. Huang, Q. Wu, and M. Tan, “Online
    adaptive asymmetric active learning for budgeted imbalanced data,” in *SIGKDD
    International Conference on Knowledge Discovery $\&amp;$ Data Mining*, 2018, pp.
    2768–2777.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] Y. Zhang、P. Zhao、J. Cao、W. Ma、J. Huang、Q. Wu 和 M. Tan，“用于预算不平衡数据的在线自适应非对称主动学习，”在*SIGKDD国际知识发现与数据挖掘会议*，2018年，页码2768–2777。'
- en: '[136] Y. Zhang, P. Zhao, S. Niu, Q. Wu, J. Cao, J. Huang, and M. Tan, “Online
    adaptive asymmetric active learning with limited budgets,” *IEEE Transactions
    on Knowledge and Data Engineering*, 2019.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] Y. Zhang、P. Zhao、S. Niu、Q. Wu、J. Cao、J. Huang 和 M. Tan，“有限预算下的在线自适应非对称主动学习，”*IEEE知识与数据工程学报*，2019年。'
- en: '[137] Y. Sun, M. S. Kamel, A. K. Wong, and Y. Wang, “Cost-sensitive boosting
    for classification of imbalanced data,” *Pattern Recognition*, vol. 40, no. 12,
    pp. 3358–3378, 2007.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] Y. Sun, M. S. Kamel, A. K. Wong, 和 Y. Wang，“针对不平衡数据分类的成本敏感提升”，*模式识别*，第40卷，第12期，第3358–3378页，2007年。'
- en: '[138] F. Wang, J. Cheng, W. Liu, and H. Liu, “Additive margin softmax for face
    verification,” *IEEE Signal Processing Letters*, vol. 25, no. 7, pp. 926–930,
    2018.'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] F. Wang, J. Cheng, W. Liu, 和 H. Liu，“面部验证的加性边际 softmax”，*IEEE信号处理通讯*，第25卷，第7期，第926–930页，2018年。'
- en: '[139] V. Koltchinskii and D. Panchenko, “Empirical margin distributions and
    bounding the generalization error of combined classifiers,” *The Annals of Statistics*,
    vol. 30, no. 1, pp. 1–50, 2002.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] V. Koltchinskii 和 D. Panchenko，“经验边际分布及结合分类器的泛化误差界限”，*统计年鉴*，第30卷，第1期，第1–50页，2002年。'
- en: '[140] F. Provost, “Machine learning from imbalanced data sets 101,” in *AAAI
    Workshop on Imbalanced Data Sets*, vol. 68, no. 2000, 2000, pp. 1–3.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] F. Provost，“不平衡数据集的机器学习101”，发表于*AAAI不平衡数据集研讨会*，第68卷，第2000号，2000年，第1–3页。'
- en: '[141] S. J. Pan and Q. Yang, “A survey on transfer learning,” *IEEE Transactions
    on Knowledge and Data Engineering*, vol. 22, no. 10, pp. 1345–1359, 2009.'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] S. J. Pan 和 Q. Yang，“迁移学习综述”，*IEEE知识与数据工程汇刊*，第22卷，第10期，第1345–1359页，2009年。'
- en: '[142] C. Tan, F. Sun, T. Kong, W. Zhang, C. Yang, and C. Liu, “A survey on
    deep transfer learning,” in *International Conference on Artificial Neural Networks*,
    2018, pp. 270–279.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] C. Tan, F. Sun, T. Kong, W. Zhang, C. Yang, 和 C. Liu，“深度迁移学习综述”，发表于*国际人工神经网络大会*，2018年，第270–279页。'
- en: '[143] D. Erhan, A. Courville, Y. Bengio, and P. Vincent, “Why does unsupervised
    pre-training help deep learning?” in *International Conference on Artificial Intelligence
    and Statistics*, 2010, pp. 201–208.'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] D. Erhan, A. Courville, Y. Bengio, 和 P. Vincent，“为什么无监督预训练有助于深度学习？”发表于*国际人工智能与统计学会议*，2010年，第201–208页。'
- en: '[144] K. He, R. Girshick, and P. Dollár, “Rethinking imagenet pre-training,”
    in *International Conference on Computer Vision*, 2019, pp. 4918–4927.'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] K. He, R. Girshick, 和 P. Dollár，“重新思考 imagenet 预训练”，发表于*国际计算机视觉大会*，2019年，第4918–4927页。'
- en: '[145] D. Hendrycks, K. Lee, and M. Mazeika, “Using pre-training can improve
    model robustness and uncertainty,” in *International Conference on Machine Learning*,
    2019, pp. 2712–2721.'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] D. Hendrycks, K. Lee, 和 M. Mazeika，“使用预训练可以提高模型的鲁棒性和不确定性”，发表于*国际机器学习大会*，2019年，第2712–2721页。'
- en: '[146] B. Zoph, G. Ghiasi, T.-Y. Lin, Y. Cui, H. Liu, E. D. Cubuk, and Q. Le,
    “Rethinking pre-training and self-training,” *Advances in Neural Information Processing
    Systems*.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] B. Zoph, G. Ghiasi, T.-Y. Lin, Y. Cui, H. Liu, E. D. Cubuk, 和 Q. Le，“重新思考预训练和自训练”，*神经信息处理系统进展*。'
- en: '[147] Y. Zhang, B. Hooi, D. Hu, J. Liang, and J. Feng, “Unleashing the power
    of contrastive self-supervised visual models via contrast-regularized fine-tuning,”
    in *Advances in Neural Information Processing Systems*, 2021.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] Y. Zhang, B. Hooi, D. Hu, J. Liang, 和 J. Feng，“通过对比正则化微调释放对比自监督视觉模型的力量”，发表于*神经信息处理系统进展*，2021年。'
- en: '[148] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick, “Momentum contrast for
    unsupervised visual representation learning,” in *Computer Vision and Pattern
    Recognition*, 2020.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] K. He, H. Fan, Y. Wu, S. Xie, 和 R. Girshick，“用于无监督视觉表征学习的动量对比”，发表于*计算机视觉与模式识别*，2020年。'
- en: '[149] S. Gidaris, P. Singh, and N. Komodakis, “Unsupervised representation
    learning by predicting image rotations,” in *International Conference on Learning
    Representations*, 2018.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] S. Gidaris, P. Singh, 和 N. Komodakis，“通过预测图像旋转进行无监督表征学习”，发表于*国际学习表征大会*，2018年。'
- en: '[150] S. Karthik, J. Revaud, and C. Boris, “Learning from long-tailed data
    with noisy labels,” *arXiv:2108.11096*, 2021.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] S. Karthik, J. Revaud, 和 C. Boris，“从长尾数据中学习带有噪声标签的知识”，*arXiv:2108.11096*，2021年。'
- en: '[151] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural
    network,” *arXiv:1503.02531*, 2015.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] G. Hinton, O. Vinyals, 和 J. Dean，“蒸馏神经网络中的知识”，*arXiv:1503.02531*，2015年。'
- en: '[152] J. Gou, B. Yu, S. J. Maybank, and D. Tao, “Knowledge distillation: A
    survey,” *International Journal of Computer Vision*, vol. 129, no. 6, pp. 1789–1819,
    2021.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] J. Gou, B. Yu, S. J. Maybank, 和 D. Tao，“知识蒸馏：综述”，*国际计算机视觉杂志*，第129卷，第6期，第1789–1819页，2021年。'
- en: '[153] X. J. Zhu, “Semi-supervised learning literature survey,” 2005.'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] X. J. Zhu，“半监督学习文献综述”，2005年。'
- en: '[154] C. Rosenberg, M. Hebert, and H. Schneiderman, “Semi-supervised self-training
    of object detection models,” 2005.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] C. Rosenberg, M. Hebert, 和 H. Schneiderman，“对象检测模型的半监督自训练”，2005年。'
- en: '[155] T. Wei, J.-X. Shi, W.-W. Tu, and Y.-F. Li, “Robust long-tailed learning
    under label noise,” *arXiv:2108.11569*, 2021.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] T. Wei, J.-X. Shi, W.-W. Tu, 和 Y.-F. Li，“标签噪声下的鲁棒长尾学习，”*arXiv:2108.11569*，2021年。'
- en: '[156] L. Perez and J. Wang, “The effectiveness of data augmentation in image
    classification using deep learning,” *arXiv:1712.04621*, 2017.'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] L. Perez 和 J. Wang，“深度学习中数据增强在图像分类中的有效性，”*arXiv:1712.04621*，2017年。'
- en: '[157] C. Shorten and T. M. Khoshgoftaar, “A survey on image data augmentation
    for deep learning,” *Journal of Big Data*, vol. 6, no. 1, pp. 1–48, 2019.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] C. Shorten 和 T. M. Khoshgoftaar，“关于深度学习图像数据增强的调查，”*大数据杂志*，第6卷，第1期，页码1–48，2019年。'
- en: '[158] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba, “Learning
    deep features for discriminative localization,” in *Computer Vision and Pattern
    Recognition*, 2016, pp. 2921–2929.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, 和 A. Torralba，“用于判别定位的深度特征学习，”发表于*计算机视觉与模式识别*，2016年，页码2921–2929。'
- en: '[159] H. Han, W.-Y. Wang, and B.-H. Mao, “Borderline-smote: a new over-sampling
    method in imbalanced data sets learning,” in *International Conference on Intelligent
    Computing*, 2005, pp. 878–887.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[159] H. Han, W.-Y. Wang, 和 B.-H. Mao，“Borderline-smote: 一种用于不平衡数据集学习的新过采样方法，”发表于*国际智能计算会议*，2005年，页码878–887。'
- en: '[160] H.-P. Chou, S.-C. Chang, J.-Y. Pan, W. Wei, and D.-C. Juan, “Remix: Rebalanced
    mixup,” in *European Conference on Computer Vision Workshop*, 2020, pp. 95–110.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[160] H.-P. Chou, S.-C. Chang, J.-Y. Pan, W. Wei, 和 D.-C. Juan，“Remix: Rebalanced
    mixup，”发表于*欧洲计算机视觉会议研讨会*，2020年，页码95–110。'
- en: '[161] Y. Wang, X. Pan, S. Song, H. Zhang, G. Huang, and C. Wu, “Implicit semantic
    data augmentation for deep networks,” in *Advances in Neural Information Processing
    Systems*, vol. 32, 2019, pp. 12 635–12 644.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[161] Y. Wang, X. Pan, S. Song, H. Zhang, G. Huang, 和 C. Wu，“深度网络的隐式语义数据增强，”发表于*神经信息处理系统进展*，第32卷，2019年，页码12 635–12 644。'
- en: '[162] A. Hermans, L. Beyer, and B. Leibe, “In defense of the triplet loss for
    person re-identification,” *arXiv:1703.07737*, 2017.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[162] A. Hermans, L. Beyer, 和 B. Leibe，“为人员重识别辩护的三元组损失，”*arXiv:1703.07737*，2017年。'
- en: '[163] J. Goh and M. Sim, “Distributionally robust optimization and its tractable
    approximations,” *Operations Research*, vol. 58, no. 4-part-1, pp. 902–917, 2010.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[163] J. Goh 和 M. Sim，“分布鲁棒优化及其可处理的近似方法，”*运筹学*，第58卷，第4期第1部分，页码902–917，2010年。'
- en: '[164] H.-J. Ye, H.-Y. Chen, D.-C. Zhan, and W.-L. Chao, “Identifying and compensating
    for feature deviation in imbalanced deep learning,” *arXiv:2001.01385*, 2020.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[164] H.-J. Ye, H.-Y. Chen, D.-C. Zhan, 和 W.-L. Chao，“在不平衡深度学习中识别和补偿特征偏差，”*arXiv:2001.01385*，2020年。'
- en: '[165] T. Cover and P. Hart, “Nearest neighbor pattern classification,” *IEEE
    transactions on information theory*, vol. 13, no. 1, pp. 21–27, 1967.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[165] T. Cover 和 P. Hart，“最近邻模式分类，”*IEEE信息理论交易*，第13卷，第1期，页码21–27，1967年。'
- en: '[166] E. D. Cubuk, B. Zoph, J. Shlens, and Q. Le, “Randaugment: Practical automated
    data augmentation with a reduced search space,” in *Advances in Neural Information
    Processing Systems*, vol. 33, 2020.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[166] E. D. Cubuk, B. Zoph, J. Shlens, 和 Q. Le，“Randaugment: 实用的自动数据增强与减少的搜索空间，”发表于*神经信息处理系统进展*，第33卷，2020年。'
- en: '[167] M. Luo, F. Chen, D. Hu, Y. Zhang, J. Liang, and J. Feng, “No fear of
    heterogeneity: Classifier calibration for federated learning with non-iid data,”
    in *Advances in Neural Information Processing Systems*, 2021.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[167] M. Luo, F. Chen, D. Hu, Y. Zhang, J. Liang, 和 J. Feng，“不惧异质性：针对非独立同分布数据的联邦学习分类器校准，”发表于*神经信息处理系统进展*，2021年。'
- en: '[168] C. D. Kim, J. Jeong, and G. Kim, “Imbalanced continual learning with
    partitioning reservoir sampling,” in *European Conference on Computer Vision*,
    2020, pp. 411–428.'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[168] C. D. Kim, J. Jeong, 和 G. Kim，“使用分区储备抽样的非平衡持续学习，”发表于*欧洲计算机视觉会议*，2020年，页码411–428。'
- en: '[169] S. Niu, J. Wu, G. Xu, Y. Zhang, Y. Guo, P. Zhao, P. Wang, and M. Tan,
    “Adaxpert: Adapting neural architecture for growing data,” in *International Conference
    on Machine Learning*, 2021, pp. 8184–8194.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[169] S. Niu, J. Wu, G. Xu, Y. Zhang, Y. Guo, P. Zhao, P. Wang, 和 M. Tan，“Adaxpert:
    为增长的数据调整神经结构，”发表于*国际机器学习会议*，2021年，页码8184–8194。'
- en: '[170] Y. Zhang, S. Niu, Z. Qiu, Y. Wei, P. Zhao, J. Yao, J. Huang, Q. Wu, and
    M. Tan, “Covid-da: Deep domain adaptation from typical pneumonia to covid-19,”
    *arXiv:2005.01577*, 2020.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[170] Y. Zhang, S. Niu, Z. Qiu, Y. Wei, P. Zhao, J. Yao, J. Huang, Q. Wu, 和
    M. Tan，“Covid-da: 从典型肺炎到Covid-19的深度领域适应，”*arXiv:2005.01577*，2020年。'
- en: '[171] X. Peng, Q. Bai, X. Xia, Z. Huang, K. Saenko, and B. Wang, “Moment matching
    for multi-source domain adaptation,” in *International Conference on Computer
    Vision*, 2019, pp. 1406–1415.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[171] X. Peng, Q. Bai, X. Xia, Z. Huang, K. Saenko, 和 B. Wang，“多源领域适应的时刻匹配，”发表于*国际计算机视觉会议*，2019年，页码1406–1415。'
- en: '[172] K. Cao, Y. Chen, J. Lu, N. Arechiga, A. Gaidon, and T. Ma, “Heteroskedastic
    and imbalanced deep learning with adaptive regularization,” in *International
    Conference on Learning Representations*, 2021.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[172] K. Cao, Y. Chen, J. Lu, N. Arechiga, A. Gaidon, 和 T. Ma，“具有自适应正则化的异方差和不平衡深度学习，”发表于
    *国际学习表征会议*，2021年。'
- en: '[173] Y. Yang, K. Zha, Y.-C. Chen, H. Wang, and D. Katabi, “Delving into deep
    imbalanced regression,” in *International Conference on Machine Learning*, 2021.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[173] Y. Yang, K. Zha, Y.-C. Chen, H. Wang, 和 D. Katabi，“深入探讨深度不平衡回归，”发表于 *国际机器学习会议*，2021年。'
- en: '| ![[Uncaptioned image]](img/3fb9f5fc01cad2bd817cbef3e1e1db11.png) | Yifan
    Zhang is working toward the Ph.D. degree in computer science at National University
    of Singapore. His research interests are broadly in machine learning, now with
    high self-motivation to solve domain shifts problems for deep learning. He has
    published papers in top venues, including NeurIPS, ICML, ICLR, SIGKDD, ECCV, IJCAI,
    TPAMI, TIP, and TKDE. He has been invited as a reviewer for top-tier conferences
    and journals, including NeurIPS, ICML, ICLR, CVPR, ECCV, AAAI, IJCAI, TPAMI, TIP,
    IJCV, and JMLR. |'
  id: totrans-576
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图像]](img/3fb9f5fc01cad2bd817cbef3e1e1db11.png) | Yifan Zhang 目前在新加坡国立大学攻读计算机科学博士学位。他的研究兴趣广泛地涉及机器学习，现在高度自我激励于解决深度学习中的领域转移问题。他在顶级会议上发表了论文，包括
    NeurIPS、ICML、ICLR、SIGKDD、ECCV、IJCAI、TPAMI、TIP 和 TKDE。他曾被邀请担任顶级会议和期刊的审稿人，包括 NeurIPS、ICML、ICLR、CVPR、ECCV、AAAI、IJCAI、TPAMI、TIP、IJCV
    和 JMLR。'
- en: '| ![[Uncaptioned image]](img/e544329df5d308f7724e97c84534e9a3.png) | Bingyi
    Kang is currently a research scientist at TikTok. Before joining TikTok, got his
    Ph.D degree in Electronic and Computer Engineering from National University of
    Singapore. He received his B.E. degree in automation from Zhejiang University,
    Hangzhou, Zhejiang in 2016\. His current research interest focuses on sample-efficient
    learning and reinforcement learning. |'
  id: totrans-577
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图像]](img/e544329df5d308f7724e97c84534e9a3.png) | Bingyi Kang 目前是 TikTok
    的研究科学家。在加入 TikTok 之前，他在新加坡国立大学获得了电子与计算机工程的博士学位。他于2016年在浙江大学获得自动化的学士学位。他当前的研究兴趣集中在样本高效学习和强化学习。
    |'
- en: '| ![[Uncaptioned image]](img/17134cd4cb89a5a7d2aa9bf94524865f.png) | Bryan
    Hooi is an assistant professor in the School of Computing and the Institute of
    Data Science in National University of Singapore. He received his PhD degree in
    Machine Learning from Carnegie Mellon University, USA in 2019\. His research interests
    include methods for learning from graphs and other complex or multimodal datasets,
    with the goal of developing efficient and practical approaches for applications
    such as the detection of anomalies or malicious behavior, and automatic monitoring
    of medical, traffic, and environmental sensor data. |'
  id: totrans-578
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图像]](img/17134cd4cb89a5a7d2aa9bf94524865f.png) | Bryan Hooi 是新加坡国立大学计算机学院和数据科学研究所的助理教授。他于2019年在美国卡内基梅隆大学获得了机器学习的博士学位。他的研究兴趣包括从图形及其他复杂或多模态数据集中学习的方法，目标是开发有效且实用的方法，用于检测异常或恶意行为，以及自动监测医疗、交通和环境传感器数据。
    |'
- en: '| ![[Uncaptioned image]](img/04354d71f783c161e9f6993e8c89de24.png) | Shuicheng
    Yan is currently the director of Sea AI Lab and group chief scientist of Sea.
    He is an IEEE Fellow, ACM Fellow, IAPR Fellow, and Fellow of Academy of Engineering,
    Singapore. His research areas include computer vision, machine learning and multimedia
    analysis. Till now, he has published over 1,000 papers in top international journals
    and conferences, with Google Scholar Citation over 93,000 times and H-index 137\.
    He had been among “Thomson Reuters Highly Cited Researchers” in 2014, 2015, 2016,
    2018, 2019\. His team has received winner or honorable-mention prizes for 10 times
    of two core competitions, Pascal VOC and ImageNet (ILSVRC), which are deemed as
    “World Cup” in the computer vision community. Also, his team won over 10 best
    paper or best student paper prizes and especially, a grand slam in ACM MM, the
    top conference in multimedia, including Best Paper Award, Best Student Paper Award
    and Best Demo Award. |'
  id: totrans-579
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/04354d71f783c161e9f6993e8c89de24.png) | 闫水成目前是 Sea AI Lab
    的主任和 Sea 的集团首席科学家。他是 IEEE 会员、ACM 会员、IAPR 会员，以及新加坡工程院院士。他的研究领域包括计算机视觉、机器学习和多媒体分析。迄今为止，他在顶级国际期刊和会议上发表了超过
    1,000 篇论文，Google Scholar 引用次数超过 93,000 次，H 指数为 137。他曾在 2014、2015、2016、2018、2019
    年被列为“汤森路透高被引研究者”。他的团队在两个核心比赛 Pascal VOC 和 ImageNet (ILSVRC) 中获得了 10 次冠军或荣誉提名，这些比赛被视为计算机视觉领域的“世界杯”。此外，他的团队还获得了
    10 多个最佳论文或最佳学生论文奖，尤其是在多媒体领域顶级会议 ACM MM 中获得了大满贯，包括最佳论文奖、最佳学生论文奖和最佳演示奖。'
- en: '| ![[Uncaptioned image]](img/4f99245b704dc5651ec977a6e5d6814c.png) | Jiashi
    Feng is currently a research manager at TikTok and is leading a fundamental research
    team. Before TikTok, he was an assistant professor with Department of Electrical
    and Computer Engineering at National University of Singapore and a postdoc researcher
    in the EECS department and ICSI at the University of California, Berkeley. He
    received his Ph.D. degree from NUS in 2014\. His research areas include deep learning
    and their applications in computer vision. He has authored/co-authored more than
    300 technical papers on deep learning, image classification, object detection,
    machine learning theory. His recent research interest focuses on foundation models,
    transfer learning, 3D vision and deep neural networks. He received the best technical
    demo award from ACM MM 2012, best paper award from TASK-CV ICCV 2015, best student
    paper award from ACM MM 2018\. He is also the recipient of Innovators Under 35
    Asia, MIT Technology Review 2018\. He served as the area chairs for NeurIPS, ICML,
    CVPR, ICLR, WACV, ACM MM and program chair for ICMR 2017. |'
  id: totrans-580
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/4f99245b704dc5651ec977a6e5d6814c.png) | 冯佳时目前是 TikTok 的研究经理，领导一个基础研究团队。在加入
    TikTok 之前，他曾是新加坡国立大学电气与计算机工程系的助理教授，并在加州大学伯克利分校的 EECS 系和 ICSI 从事博士后研究。他于 2014 年获得新加坡国立大学的博士学位。他的研究领域包括深度学习及其在计算机视觉中的应用。他已发表/合著了
    300 多篇有关深度学习、图像分类、目标检测、机器学习理论的技术论文。他近期的研究兴趣集中在基础模型、迁移学习、3D 视觉和深度神经网络。他曾获得 ACM
    MM 2012 最佳技术演示奖、TASK-CV ICCV 2015 最佳论文奖、ACM MM 2018 最佳学生论文奖。他还是 2018 年《麻省理工学院科技评论》35
    位创新者之一。他曾担任 NeurIPS、ICML、CVPR、ICLR、WACV、ACM MM 的领域主席，以及 ICMR 2017 的程序主席。 |'
