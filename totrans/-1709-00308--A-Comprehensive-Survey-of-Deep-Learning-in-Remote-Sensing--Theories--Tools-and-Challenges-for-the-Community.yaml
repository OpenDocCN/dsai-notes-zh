- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-06 20:08:43'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 20:08:43'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1709.00308] A Comprehensive Survey of Deep Learning in Remote Sensing: Theories,
    Tools and Challenges for the Community'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1709.00308] 深度学习在遥感中的全面综述：理论、工具与社区挑战'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1709.00308](https://ar5iv.labs.arxiv.org/html/1709.00308)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1709.00308](https://ar5iv.labs.arxiv.org/html/1709.00308)
- en: \cftpagenumbersoff
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \cftpagenumbersoff
- en: figure \cftpagenumbersofftable
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图 \cftpagenumbersofftable
- en: 'A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools
    and Challenges for the Community'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在遥感中的全面综述：理论、工具与社区挑战
- en: John E. Ball Mississippi State University, Department of Electrical and Computer
    Engineering, 406 Hardy Rd., Mississippi State, MS, USA, 39762 Derek T. Anderson
    Mississippi State University, Department of Electrical and Computer Engineering,
    406 Hardy Rd., Mississippi State, MS, USA, 39762 Chee Seng Chan University of
    Malaya, Faculty of Computer Science and Information Technology, 50603 Lembah Pantai,
    Kuala Lumpur, Malaysia
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: John E. Ball 密西西比州立大学，电气与计算机工程系，406 Hardy Rd., Mississippi State, MS, USA, 39762
    Derek T. Anderson 密西西比州立大学，电气与计算机工程系，406 Hardy Rd., Mississippi State, MS, USA,
    39762 Chee Seng Chan 马来亚大学，计算机科学与信息技术学院，50603 Lembah Pantai, Kuala Lumpur, Malaysia
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: In recent years, deep learning (DL), a re-branding of neural networks (NNs),
    has risen to the top in numerous areas, namely computer vision (CV), speech recognition,
    natural language processing, etc. Whereas remote sensing (RS) possesses a number
    of unique challenges, primarily related to sensors and applications, inevitably
    RS draws from many of the same theories as CV; e.g., statistics, fusion, and machine
    learning, to name a few. This means that the RS community should be aware of,
    if not at the leading edge of, of advancements like DL. Herein, we provide the
    most comprehensive survey of state-of-the-art RS DL research. We also review recent
    new developments in the DL field that can be used in DL for RS. Namely, we focus
    on theories, tools and challenges for the RS community. Specifically, we focus
    on unsolved challenges and opportunities as it relates to (i) inadequate data
    sets, (ii) human-understandable solutions for modelling physical phenomena, (iii)
    Big Data, (iv) non-traditional heterogeneous data sources, (v) DL architectures
    and learning algorithms for spectral, spatial and temporal data, (vi) transfer
    learning, (vii) an improved theoretical understanding of DL systems, (viii) high
    barriers to entry, and (ix) training and optimizing the DL.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度学习（DL），即神经网络（NNs）的新名称，在计算机视觉（CV）、语音识别、自然语言处理等多个领域中迅速崛起。尽管遥感（RS）面临许多独特的挑战，主要与传感器和应用相关，但RS不可避免地借鉴了许多与CV相同的理论，例如统计学、融合和机器学习等等。这意味着RS社区应该了解，甚至处于深度学习等技术的前沿。本文提供了对最先进的RS
    DL研究的最全面综述。我们还回顾了DL领域的最新进展，这些进展可以应用于RS的DL中。具体来说，我们关注于RS社区的理论、工具和挑战。特别地，我们关注与以下方面相关的未解决的挑战和机会：（i）数据集不足，（ii）对物理现象建模的可理解解决方案，（iii）大数据，（iv）非传统的异构数据源，（v）用于光谱、空间和时间数据的DL架构和学习算法，（vi）迁移学习，（vii）对DL系统的理论理解的提升，（viii）高门槛，以及（ix）DL的训练和优化。
- en: 'keywords:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '关键词:'
- en: Remote Sensing, Deep Learning, Hyperspectral, Multispectral, Big Data, Computer
    Vision
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 遥感、深度学习、高光谱、多光谱、大数据、计算机视觉
- en: '*John E. Ball, \linkablejeball@ece.msstate.edu'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*John E. Ball, \linkablejeball@ece.msstate.edu'
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: In recent years, deep learning (DL) has led to leaps, versus incremental gain,
    in fields like computer vision (CV), speech recognition, and natural language
    processing, to name a few. The irony is that DL, a surrogate for neural networks
    (NNs), is an age old branch of artificial intelligence that has been resurrected
    due to factors like algorithmic advancements, high performance computing, and
    Big Data. The idea of DL is simple; the machine is learning the features and decision
    making (classification), versus a human manually designing the system. The reason
    this article exists is remote sensing (RS). The reality is, RS draws from core
    theories such as physics, statistics, fusion, and machine learning, to name a
    few. This means that the RS community should be aware of, if not at the leading
    edge of, advancements like DL. The aim of this article is to provide resources
    with respect to theory, tools and challenges for the RS community. Specifically,
    we focus on unsolved challenges and opportunities as it relates to (i) inadequate
    data sets, (ii) human-understandable solutions for modelling physical phenomena,
    (iii) Big Data, (iv) non-traditional heterogeneous data sources, (v) DL architectures
    and learning algorithms for spectral, spatial and temporal data, (vi) transfer
    learning, (vii) an improved theoretical understanding of DL systems, (viii) high
    barriers to entry, and (ix) training and optimizing the DL.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度学习（DL）在计算机视觉（CV）、语音识别和自然语言处理等领域取得了飞跃性进展，而不是逐步提升。讽刺的是，DL作为神经网络（NNs）的替代品，实际上是人工智能的一个古老分支，由于算法进步、高性能计算和大数据等因素而被复兴。DL的理念很简单；机器学习特征和决策（分类），而不是人工手动设计系统。本文的存在是为了遥感（RS）。现实是，RS借鉴了核心理论，如物理学、统计学、融合技术和机器学习等。这意味着RS社区应该了解，甚至站在DL等进展的前沿。本文的目的是提供关于理论、工具和挑战的资源，特别是我们关注于未解决的挑战和机会，涉及以下方面：（i）数据集不足，（ii）对物理现象建模的易理解解决方案，（iii）大数据，（iv）非传统的异质数据源，（v）用于光谱、空间和时间数据的DL架构和学习算法，（vi）迁移学习，（vii）对DL系统的理论理解的提升，（viii）高门槛，以及（ix）DL的训练和优化。
- en: Herein, RS is a technological challenge where objects or scenes are analyzed
    by remote means. This includes the traditional remote sensing areas, such as satellite-based
    and aerial imaging. This definition also includes non-traditional areas, such
    as unmanned aerial vehicles (UAVs), crowdsourcing (phone imagery, tweets, etc.),
    advanced driver assistance systems (ADAS), etc. These types of remote sensing
    offer different types of data and have different processing needs, and thus also
    come with new challenges to algorithms that analyze the data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，遥感（RS）是一项技术挑战，其中对象或场景通过远程手段进行分析。这包括传统的遥感领域，例如基于卫星和航空影像。这一定义还包括非传统领域，如无人机（UAVs）、众包（手机影像、推文等）、先进驾驶辅助系统（ADAS）等。这些类型的遥感提供了不同类型的数据，并具有不同的处理需求，因此也带来了对数据分析算法的新挑战。
- en: 'The contributions of this paper are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的贡献如下：
- en: '1.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Thorough list of challenges and open problems in DL RS. We focus on unsolved
    challenges and opportunities as it relates to (i) inadequate data sets, (ii) human-understandable
    solutions for modelling physical phenomena, (iii) Big Data, (iv) non-traditional
    heterogeneous data sources, (v) DL architectures and learning algorithms for spectral,
    spatial and temporal data, (vi) transfer learning, (vii) an improved theoretical
    understanding of DL systems, (viii) high barriers to entry, and (ix) training
    and optimizing the DL. These observations are based on surveying RS DL and feature
    learning literature, as well as numerous RS survey papers. This topic is the majority
    of our paper and is discussed in section [4](#S4 "4 Unsolved challenges and opportunities
    for DL in RS ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories,
    Tools and Challenges for the Community").'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '深度学习（DL）遥感（RS）中的挑战和未解决问题的全面列表。我们关注于未解决的挑战和机会，涉及以下方面：（i）数据集不足，（ii）对物理现象建模的易理解解决方案，（iii）大数据，（iv）非传统的异质数据源，（v）用于光谱、空间和时间数据的DL架构和学习算法，（vi）迁移学习，（vii）对DL系统的理论理解的提升，（viii）高门槛，以及（ix）DL的训练和优化。这些观察基于对遥感DL和特征学习文献的调查，以及大量遥感调查论文。这个话题是我们论文的大部分内容，并在[4](#S4
    "4 Unsolved challenges and opportunities for DL in RS ‣ A Comprehensive Survey
    of Deep Learning in Remote Sensing: Theories, Tools and Challenges for the Community")节中讨论。'
- en: '2.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Thorough literature survey. Herein, we review 207 RS application papers, and
    57 survey papers in remote sensing and DL. In addition, many relevant DL papers
    are cited. Our work extends the previous DL survey papers [[1](#bib.bib1), [2](#bib.bib2),
    [3](#bib.bib3)] to be more comprehensive. We also cluster DL approaches into different
    application areas and provide detailed discussions of some relevant example papers
    in these areas in section [3](#S3 "3 DL approaches in RS ‣ A Comprehensive Survey
    of Deep Learning in Remote Sensing: Theories, Tools and Challenges for the Community").'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '详细的文献调查。在这里，我们回顾了207篇遥感应用论文和57篇遥感与深度学习的综述论文。此外，还引用了许多相关的深度学习论文。我们的工作将之前的深度学习综述论文
    [[1](#bib.bib1), [2](#bib.bib2), [3](#bib.bib3)] 扩展得更为全面。我们还将深度学习方法聚类到不同的应用领域，并在章节
    [3](#S3 "3 DL approaches in RS ‣ A Comprehensive Survey of Deep Learning in Remote
    Sensing: Theories, Tools and Challenges for the Community") 中提供了对这些领域中一些相关示例论文的详细讨论。'
- en: '3.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Detailed discussions of modifying DL architectures to tackle RS problems. We
    highlight approaches in DL in RS, including new architectures, tools and DL components,
    that current RS researchers have implemented in DL. This is discussed in section
    [4.5](#S4.SS5 "4.5 DL architectures and learning algorithms for spectral, spatial
    and temporal data ‣ 4 Unsolved challenges and opportunities for DL in RS ‣ A Comprehensive
    Survey of Deep Learning in Remote Sensing: Theories, Tools and Challenges for
    the Community").'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '讨论修改深度学习（DL）架构以应对遥感（RS）问题的详细内容。我们强调了在遥感中的深度学习方法，包括新架构、工具和深度学习组件，这些都是当前遥感研究人员在深度学习中实现的。这在章节
    [4.5](#S4.SS5 "4.5 DL architectures and learning algorithms for spectral, spatial
    and temporal data ‣ 4 Unsolved challenges and opportunities for DL in RS ‣ A Comprehensive
    Survey of Deep Learning in Remote Sensing: Theories, Tools and Challenges for
    the Community") 中进行了讨论。'
- en: '4.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: 'Overview of DL. For RS researchers not familiar with DL, section [2](#S2 "2
    Related work in CV ‣ A Comprehensive Survey of Deep Learning in Remote Sensing:
    Theories, Tools and Challenges for the Community") provides a high-level overview
    of DL and lists many good references for interested readers to pursue.'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '深度学习概述。对于不熟悉深度学习的遥感研究人员，章节 [2](#S2 "2 Related work in CV ‣ A Comprehensive
    Survey of Deep Learning in Remote Sensing: Theories, Tools and Challenges for
    the Community") 提供了深度学习的高层次概述，并列出了许多对感兴趣的读者有帮助的参考文献。'
- en: '5.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: 'Deep learning tool list. Tools are a major enabler of DL, and we review the
    more popular DL tools. We also list pros and cons of several of the most popular
    toolsets and provide a table summarizing the tools, with references and links
    (refer to Table [2](#S2.T2 "Table 2 ‣ 2.4.4 Tools ‣ 2.4 DL Meets the Real World
    ‣ 2 Related work in CV ‣ A Comprehensive Survey of Deep Learning in Remote Sensing:
    Theories, Tools and Challenges for the Community")). For more details, see section
    [2.4.4](#S2.SS4.SSS4 "2.4.4 Tools ‣ 2.4 DL Meets the Real World ‣ 2 Related work
    in CV ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools
    and Challenges for the Community").'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '深度学习工具列表。工具是深度学习的一个重要推动因素，我们回顾了更受欢迎的深度学习工具。我们还列出了几个最受欢迎的工具集的优缺点，并提供了一个总结工具的表格，其中包含参考文献和链接（参见表
    [2](#S2.T2 "Table 2 ‣ 2.4.4 Tools ‣ 2.4 DL Meets the Real World ‣ 2 Related work
    in CV ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools
    and Challenges for the Community")）。更多详细信息，请参见章节 [2.4.4](#S2.SS4.SSS4 "2.4.4 Tools
    ‣ 2.4 DL Meets the Real World ‣ 2 Related work in CV ‣ A Comprehensive Survey
    of Deep Learning in Remote Sensing: Theories, Tools and Challenges for the Community")。'
- en: '6.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: 'Online summaries of RS datasets and DL RS papers reviewed. First, an extensive
    online table with details about each DL RS paper we reviewed: sensor modalities,
    a compilation of the datasets used, a summary of the main contribution, and references.
    Second, a dataset summary for all the DL RS papers analyzed in this paper is provided
    online. It contains the dataset name, a description, a URL (if one is available)
    and a list of references. Since the literature review for this paper was so extensive,
    these tables are too large to put in the main article, but are provided online
    for the readers’ benefit. These tables are located at [http://www.cs-chan.com/source/FADL/Online_Dataset_Summary_Table.pdf](http://www.cs-chan.com/source/FADL/Online_Dataset_Summary_Table.pdf)
    and [http://www.cs-chan.com/source/FADL/Online_Paper_Summary_Table.pdf](http://www.cs-chan.com/source/FADL/Online_Paper_Summary_Table.pdf).'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在线总结了 RS 数据集和 DL RS 论文的内容。首先，提供了一个详细的在线表格，包含我们审查的每篇 DL RS 论文的细节：传感器模态、使用的数据集汇编、主要贡献的总结以及参考文献。其次，提供了本文分析的所有
    DL RS 论文的数据集总结，包含数据集名称、描述、网址（如果有的话）和参考文献列表。由于本文的文献综述非常广泛，这些表格过大，不便放在主文章中，但为了读者的方便，提供了在线访问。这些表格位于
    [http://www.cs-chan.com/source/FADL/Online_Dataset_Summary_Table.pdf](http://www.cs-chan.com/source/FADL/Online_Dataset_Summary_Table.pdf)
    和 [http://www.cs-chan.com/source/FADL/Online_Paper_Summary_Table.pdf](http://www.cs-chan.com/source/FADL/Online_Paper_Summary_Table.pdf)。
- en: As an aid to the reader, Table LABEL:table:Acronyms lists acronyms used in this
    paper.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 作为读者的辅助，表 LABEL:table:Acronyms 列出了本文中使用的缩略语。
- en: 'Table 1: Acronym list.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：缩略语列表。
- en: '| Acronym | Meaning | Acronym | Meaning |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 缩略语 | 含义 | 缩略语 | 含义 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| ADAS | Advanced Driver Assistance System | AE | AutoEncoder |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| ADAS | 高级驾驶辅助系统 | AE | 自编码器 |'
- en: '| ANN | Artificial Neural Network | ATR | Automated Target Recognition |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| ANN | 人工神经网络 | ATR | 自动目标识别 |'
- en: '| AVHRR | Advanced Very High Resolution Radiometer | AVIRIS | Airborne Visible
    / Infrared Imaging Spectrometer |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| AVHRR | 高级非常高分辨率辐射计 | AVIRIS | 空载可见/红外成像光谱仪 |'
- en: '| BP | Backpropagation | CAD | Computer Aided Design |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| BP | 反向传播 | CAD | 计算机辅助设计 |'
- en: '| CFAR | Constant False Alarm Rate | CG | Conjugate Gradient |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| CFAR | 恒虚警率 | CG | 共轭梯度 |'
- en: '| ChI | Choquet Integral | CV | Computer Vision |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| ChI | 乔凯积分 | CV | 计算机视觉 |'
- en: '| CNN | Convolutional Neural Network | DAE | Denoising AE |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 卷积神经网络 | DAE | 去噪自编码器 |'
- en: '| DAG | Directed Acyclic Graph | DBM | Deep Boltzmann Machine |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| DAG | 有向无环图 | DBM | 深度玻尔兹曼机 |'
- en: '| DBN | Deep Belief Network | DeconvNet | DeConvolutional Neural Network |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| DBN | 深度置信网络 | DeconvNet | 反卷积神经网络 |'
- en: '| DEM | Digital Elevation Model | DIDO | Decision In Decision Out |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| DEM | 数字高程模型 | DIDO | 决策中的决策输出 |'
- en: '| DL | Deep Learning | DNN | Deep Neural Network |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| DL | 深度学习 | DNN | 深度神经网络 |'
- en: '| DSN | Deep Stacking Network | DWT | Discrete Wavelet Transform |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| DSN | 深度堆叠网络 | DWT | 离散小波变换 |'
- en: '| FC | Fully Connected | FCN | Fully Convolutional Network |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| FC | 全连接 | FCN | 全卷积网络 |'
- en: '| FC-CNN | Fully Convolutional CNN | FC-LSTM | Fully Connected LSTM |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| FC-CNN | 全卷积 CNN | FC-LSTM | 全连接 LSTM |'
- en: '| FIFO | Feature In Feature Out | FL | Feature Learning |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| FIFO | 特征输入特征输出 | FL | 特征学习 |'
- en: '| GBRCN | Gradient-Boosting Random Convolutional Network | GIS | Geographic
    Information System |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| GBRCN | 梯度提升随机卷积网络 | GIS | 地理信息系统 |'
- en: '| GPU | Graphical Processing Unit | HOG | Histogram of Ordered Gradients |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| GPU | 图形处理单元 | HOG | 有序梯度直方图 |'
- en: '| HR | High Resolution | HSI | HyperSpectral Imagery |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| HR | 高分辨率 | HSI | 高光谱影像 |'
- en: '| ILSVRC | ImageNet Large Scale Visual Recognition Challenge | L-BGFS | Limited
    Memory BGFS |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| ILSVRC | ImageNet 大规模视觉识别挑战赛 | L-BGFS | 有限内存 BGFS |'
- en: '| LBP | Local Binary Patterns | LiDAR | Light Detection and Ranging |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| LBP | 局部二值模式 | LiDAR | 激光雷达 |'
- en: '| LR | Low Resolution | LSTM | Long Short-Term Memory |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| LR | 低分辨率 | LSTM | 长短期记忆 |'
- en: '| LWIR | Long-Wave InfraRed | MKL | Multi-Kernel Learning |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| LWIR | 长波红外 | MKL | 多核学习 |'
- en: '| MLP | Multi-Layer Perceptron | MSDAE | Modified Sparse Denoising Autoencoder
    |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| MLP | 多层感知器 | MSDAE | 修改的稀疏去噪自编码器 |'
- en: '| MSI | MultiSpectral Imagery | MWIR | Mid-wave InfraRed |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| MSI | 多光谱影像 | MWIR | 中波红外 |'
- en: '| NASA | National Aeronautics and Space Administration | NN | Neural Network
    |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| NASA | 国家航空航天局 | NN | 神经网络 |'
- en: '| NOAA | National Oceanic and Atmospheric Administration | PCA | Principal
    Component Analysis |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| NOAA | 国家海洋和大气管理局 | PCA | 主成分分析 |'
- en: '| PGM | Probabilistic Graphical Model | PReLU | Parametric Rectified Linear
    Unit |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| PGM | 概率图模型 | PReLU | 参数化整流线性单元 |'
- en: '| RANSAC | RANdom SAmple Concesus | RBM | Restricted Boltzmann Machine |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| RANSAC | 随机采样一致性 | RBM | 限制玻尔兹曼机 |'
- en: '| ReLU | Rectified Linear Unit | RGB | Red, Green and Blue image |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| ReLU | 修正线性单元 | RGB | 红色、绿色和蓝色图像 |'
- en: '| RGBD | RGB + Depth image | RF | Receptive Field |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| RGBD | RGB + 深度图像 | RF | 感受野 |'
- en: '| RICNN | Rotation Invariant CNN | RNN | Recurrent NN |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| RICNN | 旋转不变卷积神经网络 | RNN | 循环神经网络 |'
- en: '| RS | Remote Sensing | R-VCANet | Rolling guidance filter Vertex Component
    Analysis NETwork |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| RS | 遥感 | R-VCANet | 滚动引导滤波器顶点组件分析网络 |'
- en: '| S-MSDAE | Stacked MSDAE | SAE | Stacked AE |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| S-MSDAE | 堆叠MSDAE | SAE | 堆叠自编码器 |'
- en: '| SAR | Synthetic Aperture Radar | SDAE | Stacked DAE |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| SAR | 合成孔径雷达 | SDAE | 堆叠去噪自编码器 |'
- en: '| SIDO | Signal In Decision Out | SIFT | Scale Invariant Feature Transform
    |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| SIDO | 信号输入输出 | SIFT | 尺度不变特征变换 |'
- en: '| SISO | Signal In Signal Out | SGD | Stochastic Gradient Descent |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| SISO | 信号输入信号输出 | SGD | 随机梯度下降 |'
- en: '| SPI | Standardized Precipitation Index | SSAE | Stacked Sparse Autoencoder
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| SPI | 标准化降水指数 | SSAE | 堆叠稀疏自编码器 |'
- en: '| SVM | Support Vector Machine | UAV | Unmanned Aerial Vehicle |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| SVM | 支持向量机 | UAV | 无人驾驶飞行器 |'
- en: '| VGG | Visual Geometry Group | VHR | Very High Resolution |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| VGG | 视觉几何组 | VHR | 超高分辨率 |'
- en: 'This paper is organized as follows. Section [2](#S2 "2 Related work in CV ‣
    A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and
    Challenges for the Community") discusses related work in CV. This section contrasts
    deep and “shallow” learning, and discusses DL architectures. The main reasons
    for success of DL are also discussed in this section. Section [3](#S3 "3 DL approaches
    in RS ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools
    and Challenges for the Community") provides an overview of DL in RS, highlighting
    DL approaches in many disparate areas of RS. Section [4](#S4 "4 Unsolved challenges
    and opportunities for DL in RS ‣ A Comprehensive Survey of Deep Learning in Remote
    Sensing: Theories, Tools and Challenges for the Community") discusses the unique
    challenges and open issues in applying DL to RS. Conclusions and recommendations
    are listed in section [5](#S5 "5 Conclusions ‣ A Comprehensive Survey of Deep
    Learning in Remote Sensing: Theories, Tools and Challenges for the Community").'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 本文组织如下。第[2](#S2 "2 计算机视觉中的相关工作 ‣ 深度学习在遥感中的全面调查：理论、工具和社区挑战")节讨论了计算机视觉中的相关工作。本节对比了深度学习和“浅层”学习，并讨论了深度学习架构。本节还讨论了深度学习成功的主要原因。第[3](#S3
    "3 深度学习在遥感中的方法 ‣ 深度学习在遥感中的全面调查：理论、工具和社区挑战")节概述了遥感中的深度学习，强调了遥感中许多不同领域的深度学习方法。第[4](#S4
    "4 深度学习在遥感中的未解决挑战和机会 ‣ 深度学习在遥感中的全面调查：理论、工具和社区挑战")节讨论了将深度学习应用于遥感中的独特挑战和开放问题。结论和建议列在第[5](#S5
    "5 结论 ‣ 深度学习在遥感中的全面调查：理论、工具和社区挑战")节。
- en: 2 Related work in CV
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 计算机视觉中的相关工作
- en: CV is a field of study trying to achieve visual understanding through computer
    analysis of imagery. In the past, typical approaches utilized a processing chain
    which usually started with image denoising or enhancement, followed by feature
    extraction (with human coded features), a feature optimization stage, and then
    processing on the extracted features. These architectures were mostly “shallow”,
    in the sense that they usually had only one to two processing layers between the
    features and the output. Shallow learners (Support Vector Machines (SVMs), Gaussian
    Mixture Models, Hidden Markov Models, Conditional Random Fields, etc.) have been
    the backbone of traditional research efforts for many years [[2](#bib.bib2)] .
    In contrast, DL usually has many layers (the exact demarcation between “shallow”
    and “deep” learning is not a set number), which allows a rich variety of highly
    complex, nonlinear and hierarchical features to be learned from the data. The
    following sections contrast deep and shallow learning, discuss DL approaches and
    DL enablers, and finally discuss DL success in domains other than RS.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉（CV）是一个通过计算机图像分析实现视觉理解的研究领域。过去，典型的方法采用了一个处理链，通常以图像去噪或增强开始，接着进行特征提取（采用人工编码特征），然后是特征优化阶段，最后对提取的特征进行处理。这些架构大多是“浅层”的，因为它们通常只有一到两层处理层在特征和输出之间。浅层学习者（如支持向量机（SVMs）、高斯混合模型、隐马尔可夫模型、条件随机场等）多年来一直是传统研究的主干[[2](#bib.bib2)]。相比之下，深度学习（DL）通常有许多层（“浅层”与“深层”学习的确切界限并没有固定的数字），这使得从数据中可以学习到丰富的、非常复杂的、非线性和分层的特征。以下部分对比了深度学习和浅层学习，讨论了深度学习方法和深度学习的推动因素，并最终讨论了深度学习在遥感以外领域的成功。
- en: 2.1 Deep vs. shallow learning
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 深度学习与浅层学习
- en: Shallow learning is a term used to describe learning networks that usually have
    at most one to two layers. Examples of shallow learners include the popular SVM,
    Gaussian mixture models, hidden Markov models, conditional random fields, logistic
    regression models, and the extreme learning machine [[2](#bib.bib2)] . Shallow
    learning models usually have one or two layers that compute a linear or non-linear
    function of the input data (often hand-designed features). DL, on the other hand,
    usually means a deeper network, with many layers of (usually) non-linear transformations.
    Although there is no universally accepted definition of how many layers constitute
    a “deep” learner, typical networks are typically at least four or five layers
    deep. Three main features of DL systems are that DL systems (1) can learn features
    directly from the data itself, versus human-designed features, (2) can learn hierarchical
    features which increase in complexity through the deep network, and (3) can be
    more generalizable and more efficiently encode the model compared to a shallower
    NN approach; that is, a shallow system will require exponentially more neurons
    (and thus more free parameters) and more training data [[4](#bib.bib4), [5](#bib.bib5)]
    . An interesting study on deep and shallow nets is given by Ba and Caruana [[6](#bib.bib6)]
    , where they perform model compression, by training a Deep NN (DNN). The unlabeled
    data is then evaluated by the DNN and the scores produced by that model are used
    to train a compressed (shallower) model. If the compressed model learns to mimic
    the large model perfectly it makes exactly the same predictions and mistakes as
    the complex model. The key is the compressed model has to have enough complexity
    to regenerate the more complex model output.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 浅层学习是用来描述通常只有一到两层的学习网络的术语。浅层学习者的例子包括流行的支持向量机（SVM）、高斯混合模型、隐马尔可夫模型、条件随机场、逻辑回归模型以及极限学习机[[2](#bib.bib2)]。浅层学习模型通常只有一层或两层，用于计算输入数据（通常是手工设计的特征）的线性或非线性函数。另一方面，深度学习（DL）通常意味着一个更深的网络，具有许多（通常是）非线性变换的层。尽管没有普遍接受的“深度”学习者的层数定义，但典型的网络通常至少有四层或五层。深度学习系统的三个主要特点是：深度学习系统（1）可以直接从数据本身中学习特征，而不是依赖于人工设计的特征，（2）可以学习通过深度网络增加复杂性的层次化特征，以及（3）与浅层神经网络方法相比，具有更好的泛化能力和更高效的模型编码；也就是说，浅层系统需要指数级增加的神经元（以及更多的自由参数）和更多的训练数据[[4](#bib.bib4),
    [5](#bib.bib5)]。Ba 和 Caruana [[6](#bib.bib6)] 提供了一项关于深度和浅层网络的有趣研究，他们通过训练一个深度神经网络（DNN）来进行模型压缩。然后用DNN评估未标记的数据，并将该模型生成的分数用于训练一个压缩（较浅层）模型。如果压缩模型能够完美地模仿大模型，它会做出与复杂模型完全相同的预测和错误。关键在于压缩模型必须具有足够的复杂性以再现更复杂模型的输出。
- en: 'DL systems are often designed to loosely mimic human or animal processing,
    in which there are many layers of interconnected components, e.g. human vision.
    So there is a natural motivation to use deep architectures in CV-related problems.
    For the interested reader, we provide some useful survey paper references. Arel
    et al. provide a survey paper on DL [[7](#bib.bib7)] . Deng et al. [[2](#bib.bib2)]
    provide two important reasons for DL success: (1) Graphical Processing Unit (GPU)
    units and (2) recent advances in DL research. They discuss generative, discriminative,
    and hybrid deep architectures and show there is vast room to improve the current
    optimization techniques in DL. Liu et al. [[8](#bib.bib8)] give an overview of
    the autoencoder, the CNN, and DL applications. Wang et al. provide a history of
    DL [[4](#bib.bib4)] . Yu et al. [[9](#bib.bib9)] provide a review of DL in signal
    and image processing. Comparisons are made to shallow learning, and DL advantages
    are given. Two good overviews of DL are the survey paper of Schmidhuber et al.
    [[10](#bib.bib10)] and the book by Goodfellow et al. [[11](#bib.bib11)]. Zhang
    et al. [[3](#bib.bib3)] give a general framework for DL in remote sensing, which
    covers four RS perspectives: (1) image processing, (2) pixel-based classification,
    (3) target recognition, and (4) scene understanding. In addition, they review
    many DL applications in remote sensing. Cheng et al. discuss both shallow and
    DL methods for feature extraction [[1](#bib.bib1)]. Some good DL papers are the
    introductory DL papers of Arnold et al. [[12](#bib.bib12)] and Wang et al. [[4](#bib.bib4)]
    , the DL book by Goodfellow et al. [[11](#bib.bib11)] , and the DL survey papers
    [[10](#bib.bib10), [13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15), [2](#bib.bib2),
    [8](#bib.bib8), [16](#bib.bib16), [4](#bib.bib4), [5](#bib.bib5)] .'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: DL 系统通常被设计为松散地模仿人类或动物的处理方式，其中包含许多互联的层，例如人类视觉。因此，在计算机视觉相关问题中使用深度架构具有自然的动机。对于感兴趣的读者，我们提供了一些有用的调查论文参考。Arel
    等人提供了一篇关于 DL 的综述论文 [[7](#bib.bib7)]。Deng 等人 [[2](#bib.bib2)] 提出了 DL 成功的两个重要原因：（1）图形处理单元（GPU）和（2）DL
    研究的最新进展。他们讨论了生成性、判别性和混合深度架构，并表明当前的 DL 优化技术仍有广阔的改进空间。Liu 等人 [[8](#bib.bib8)] 概述了自编码器、卷积神经网络（CNN）和
    DL 应用。Wang 等人提供了 DL 的历史 [[4](#bib.bib4)]。Yu 等人 [[9](#bib.bib9)] 综述了 DL 在信号和图像处理中的应用。与浅层学习进行了比较，并给出了
    DL 的优势。两篇较好的 DL 概述文章是 Schmidhuber 等人的综述论文 [[10](#bib.bib10)] 和 Goodfellow 等人的书籍
    [[11](#bib.bib11)]。Zhang 等人 [[3](#bib.bib3)] 提出了一个 DL 在遥感中的通用框架，涵盖了四个遥感视角：（1）图像处理，（2）基于像素的分类，（3）目标识别和（4）场景理解。此外，他们还回顾了许多
    DL 在遥感中的应用。Cheng 等人讨论了浅层和 DL 方法在特征提取中的应用 [[1](#bib.bib1)]。一些好的 DL 论文包括 Arnold
    等人的 DL 入门论文 [[12](#bib.bib12)] 和 Wang 等人的论文 [[4](#bib.bib4)]，Goodfellow 等人的 DL
    书籍 [[11](#bib.bib11)]，以及 DL 综述论文 [[10](#bib.bib10), [13](#bib.bib13), [14](#bib.bib14),
    [15](#bib.bib15), [2](#bib.bib2), [8](#bib.bib8), [16](#bib.bib16), [4](#bib.bib4),
    [5](#bib.bib5)]。
- en: 2.2 Traditional Feature Learning methods
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 传统特征学习方法
- en: Traditional methods of feature extraction involve hand-coded features to extract
    information based on spatial, spectral, textural, morphological content, etc.
    These traditional methods are discussed in detail in the following references,
    and we will not give extensive algorithmic details herein. All of these hand-derived
    features are designed for a specific task, e.g. characterizing image texture.
    In contrast, DL systems derive complicated, (usually) non-linear and hierarchical
    features from the data itself.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的特征提取方法涉及手工编码的特征，以根据空间、光谱、纹理、形态学内容等提取信息。这些传统方法在以下参考文献中有详细讨论，本文不提供详细的算法细节。所有这些手工提取的特征都是为特定任务设计的，例如特征化图像纹理。相比之下，DL
    系统从数据本身派生出复杂的（通常是）非线性和层次化的特征。
- en: Cheng et al. [[1](#bib.bib1)] discuss traditional handcrafted features such
    as the Histogram of Ordered Gradients (HOG), the Scale-Invariant Feature Transform
    (SIFT) and SIFT variants, color histograms, etc. They also discuss unsupervised
    FL methods, such as principal components analysis, $k$-means clustering, sparse
    coding, etc. Other good survey papers discuss hyperspectral image (HSI) data analysis
    [[17](#bib.bib17)] , kernel-based methods [[18](#bib.bib18)] , statistical learning
    methods in HSI [[19](#bib.bib19)] , spectral distance functions [[20](#bib.bib20)]
    , pedestrian detection [[21](#bib.bib21)] , multi-classifier systems [[22](#bib.bib22)]
    , spectral-spatial classification [[23](#bib.bib23)] , change detection [[24](#bib.bib24),
    [25](#bib.bib25)] , machine learning in RS [[26](#bib.bib26)] , manifold learning
    [[27](#bib.bib27)] , transfer learning [[28](#bib.bib28)] , endmember extraction
    [[29](#bib.bib29)] , and spectral unmixing [[30](#bib.bib30), [31](#bib.bib31),
    [32](#bib.bib32), [33](#bib.bib33), [34](#bib.bib34)] .
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Cheng 等人 [[1](#bib.bib1)] 讨论了传统的手工特征，如有序梯度直方图（HOG）、尺度不变特征变换（SIFT）及其变体、颜色直方图等。他们还讨论了无监督的
    FL 方法，如主成分分析、$k$-均值聚类、稀疏编码等。其他优秀的综述论文讨论了高光谱图像（HSI）数据分析 [[17](#bib.bib17)]，基于核的方法
    [[18](#bib.bib18)]，HSI 中的统计学习方法 [[19](#bib.bib19)]，光谱距离函数 [[20](#bib.bib20)]，行人检测
    [[21](#bib.bib21)]，多分类器系统 [[22](#bib.bib22)]，光谱空间分类 [[23](#bib.bib23)]，变化检测 [[24](#bib.bib24),
    [25](#bib.bib25)]，RS 中的机器学习 [[26](#bib.bib26)]，流形学习 [[27](#bib.bib27)]，迁移学习 [[28](#bib.bib28)]，端成员提取
    [[29](#bib.bib29)]，以及光谱混合 [[30](#bib.bib30), [31](#bib.bib31), [32](#bib.bib32),
    [33](#bib.bib33), [34](#bib.bib34)]。
- en: 2.3 DL Approaches
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 DL 方法
- en: To date, the auto-encoder (AE), the CNN, Deep Belief Networks (DBNs), and the
    Recurrent NN (RNN), have been the four mainstream DL architectures. The deconvolutional
    NN (DeconvNet) is a relative newcomer to the DL community. The following sections
    discuss each of these architectures at a high level. Many good references are
    provided for the interested reader.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，自动编码器（AE）、卷积神经网络（CNN）、深度置信网络（DBN）和递归神经网络（RNN）已成为四种主流的 DL 架构。去卷积神经网络（DeconvNet）是
    DL 社区中的相对新手。以下章节将高层次地讨论这些架构。提供了许多良好的参考文献供感兴趣的读者参考。
- en: 2.3.1 Autoencoder (AE)
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1 自动编码器（AE）
- en: 'An AE is a network designed to learn useful features from unsupervised data.
    One of the first applications of AEs was dimensionality reduction, which is required
    in many RS applications. By reducing the size of the adjacent layers, the AE is
    forced to learn a compact representation of the data. The AE maps the input through
    an encoder function $f$ to generate an internal (latent) representation, or code,
    $h$, that is, $h=f(\textbf{x})$. The autoencoder also has a decoder function,
    $g$ that maps $h$ to the output $\hat{\textbf{x}}$. In general, the AE is constrained,
    either through its architecture, or through a sparsity constraint (or both), to
    learn a useful mapping (but not the trivial identity mapping). A loss function
    $L$ measures how close the AE can reconstruct the output: $L$ is a function of
    x and $\hat{\textbf{x}}=g(f(\textbf{x}))$. A regularization function $\Omega(h)$
    can also be added to the loss function to force a more sparse solution. The regularization
    function can involve penalty terms for model complexity, model prior information,
    penalizing based on derivatives, or penalties based on some other criteria such
    as supervised classification results, etc. (reference §14.2 of [[11](#bib.bib11)]
    ).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: AE 是一个旨在从无监督数据中学习有用特征的网络。AE 的一个早期应用是降维，这在许多 RS 应用中是必需的。通过减少相邻层的大小，AE 被迫学习数据的紧凑表示。AE
    通过编码器函数 $f$ 将输入映射为内部（潜在）表示或代码 $h$，即 $h=f(\textbf{x})$。自动编码器还具有解码器函数 $g$，将 $h$
    映射到输出 $\hat{\textbf{x}}$。一般来说，AE 被约束，无论是通过其架构，还是通过稀疏约束（或两者），以学习有用的映射（但不是简单的恒等映射）。损失函数
    $L$ 衡量 AE 能重构输出的接近程度：$L$ 是 $x$ 和 $\hat{\textbf{x}}=g(f(\textbf{x}))$ 的函数。也可以向损失函数中添加正则化函数
    $\Omega(h)$，以强制更稀疏的解决方案。正则化函数可以涉及模型复杂度、模型先验信息、基于导数的惩罚，或基于其他标准如监督分类结果的惩罚等的惩罚项（参考
    [[11](#bib.bib11)] 的 §14.2）。
- en: 'A Denoising AE (DAE) is an AE designed to remove noise from a signal or an
    image. Chen et al. developed an efficient DAE, which marginalizes the noise and
    has a computationally efficient closed form solution [[35](#bib.bib35)]. To provide
    robustness, the system is trained using additive Gaussian noise or binary masking
    noise (force some percentage of inputs to zero). Many RS applications utilize
    an AE for denoising. Figure [1](#S2.F1 "Figure 1 ‣ 2.3.1 Autoencoder (AE) ‣ 2.3
    DL Approaches ‣ 2 Related work in CV ‣ A Comprehensive Survey of Deep Learning
    in Remote Sensing: Theories, Tools and Challenges for the Community")(a) shows
    an example of a AE. The diabolo shape results in dimensionality reduction.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '去噪自编码器（DAE）是一种旨在去除信号或图像噪声的自编码器。陈等人开发了一种高效的DAE，该DAE能够减少噪声，并且具有计算上高效的闭式解 [[35](#bib.bib35)]。为了提供鲁棒性，该系统使用加性高斯噪声或二进制掩蔽噪声（将某些输入强制设为零）进行训练。许多RS应用利用自编码器进行去噪。图[1](#S2.F1
    "Figure 1 ‣ 2.3.1 Autoencoder (AE) ‣ 2.3 DL Approaches ‣ 2 Related work in CV
    ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and
    Challenges for the Community")(a)展示了一个自编码器的示例。二阶锥形状导致了维度的减少。'
- en: '![Refer to caption](img/6dc176702229d88dba156cd7ee5ad6dd.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6dc176702229d88dba156cd7ee5ad6dd.png)'
- en: 'Figure 1: Block diagrams of DL architectures. (a) AE. (b) CNN. (c) DBN. (d)
    RNN.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：深度学习架构的块图。(a) 自编码器。 (b) 卷积神经网络。 (c) 深度置信网络。 (d) 循环神经网络。
- en: 2.3.2 Convolutional Neural Network (CNN)
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.2 卷积神经网络（CNN）
- en: 'A CNN is a network that is loosely inspired by the human visual cortex. A typical
    CNN is composed of multiple dual-layers of convolutional masks followed by pooling,
    and these layers are then usually followed by either fully-connected or partially-connected
    layers, which perform classification or class probability estimation. Some CNNs
    also utilize data normalization layers. The convolution masks have coefficients
    that are learned by the CNN. A CNN that analyzes grayscale imagery will employ
    2D convolution masks, while a CNN using Red-Green-Blue (RGB) imagery will use
    3D masks. Through training, these masks learn to extract features directly from
    the data, in stark contrast to traditional machine learning approaches, which
    utilize ”hand-crafted” features. The pooling layers are non-linear operators (usually
    maximum operators), which allows the CNN to learn non-linear features, which greatly
    increases its learning capabilities. Figure [1](#S2.F1 "Figure 1 ‣ 2.3.1 Autoencoder
    (AE) ‣ 2.3 DL Approaches ‣ 2 Related work in CV ‣ A Comprehensive Survey of Deep
    Learning in Remote Sensing: Theories, Tools and Challenges for the Community")(b)
    shows an example CNN, where the input is a HSI, and there are two convolution
    and pooling layers, followed by two fully connected (FC) layers.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 'CNN是受到人类视觉皮层启发的网络。典型的CNN由多个卷积掩膜的双层组成，后跟池化层，这些层通常后跟全连接层或部分连接层，进行分类或类别概率估计。一些CNN还利用数据归一化层。卷积掩膜的系数由CNN学习。分析灰度图像的CNN将采用二维卷积掩膜，而使用红绿蓝（RGB）图像的CNN将使用三维掩膜。通过训练，这些掩膜直接从数据中学习提取特征，与传统的机器学习方法（利用“手工制作”的特征）形成鲜明对比。池化层是非线性操作符（通常是最大操作符），这使得CNN能够学习非线性特征，极大地提高了其学习能力。图[1](#S2.F1
    "Figure 1 ‣ 2.3.1 Autoencoder (AE) ‣ 2.3 DL Approaches ‣ 2 Related work in CV
    ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and
    Challenges for the Community")(b)展示了一个CNN的示例，其中输入是HSI，有两个卷积和池化层，后跟两个全连接（FC）层。'
- en: The number of convolution masks, the size of the masks, and the pooling functions
    are all parameters of the CNN. The masks at the first layers of the CNN typically
    learn basic features, and as one traverses the depths of the network, the features
    become more complex and are built-up hierarchically. Normalization layers provide
    regularization and can aid in training. The fully-connected layers (or partially-connected
    layers) are usually near the end of the CNN network, and allow complex non-linear
    functions to be learned from the hierarchical outputs of the previous layers.
    These final layers typically output class labels or estimates of the probabilities
    of the class label.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积掩膜的数量、掩膜的大小和池化函数都是CNN的参数。CNN的第一层掩膜通常学习基本特征，随着网络深度的增加，特征变得更加复杂，并以层次结构构建。归一化层提供正则化，并可以帮助训练。全连接层（或部分连接层）通常位于CNN网络的末端，允许从前面层次的层次输出中学习复杂的非线性函数。这些最终层通常输出类别标签或类别标签概率的估计。
- en: CNNs have dominated in many perceptual tasks. Following Ujjwalkarn [[36](#bib.bib36)]
    , the image recognition community has shown keen interest in CNNs. Starting in
    the 1990s, LeNet was developed by LeCun et al. [[37](#bib.bib37)] , and was designed
    for reading zip codes. It generated great interest in the image processing community.
    In 2012, Krizhevsky et al. [[38](#bib.bib38)] introduced AlexNet, a deep CNN.
    It won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012
    by a significant margin. In 2013, Zeiler and Fergus [[39](#bib.bib39)] created
    ZFNet, which was AlexNet with tweaked parameters and won ILSVRC. Szegedy et al.
    [[40](#bib.bib40)] won ILSVRC with GoogLeNet in 2014, which used a much smaller
    number of parameters (4 million) than AlexNet (60 million). In 2015, ResNets were
    developed by He et al [[41](#bib.bib41)] , which allowed CNNs to have very deep
    networks. In 2016, Huang et al. [[42](#bib.bib42)] published DenseNet, where each
    layer is directly connected to every other layer in a feedforward fashion. This
    architecture also eliminates the vanishing-gradient problem, allowing very deep
    networks. The examples above are only a few examples of CNNs.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）在许多感知任务中占据了主导地位。根据 Ujjwalkarn [[36](#bib.bib36)] 的研究，图像识别社区对 CNN
    表现出浓厚的兴趣。从 1990 年代开始，LeCun 等人开发了 LeNet [[37](#bib.bib37)]，该网络设计用于读取邮政编码。这在图像处理社区引起了极大的关注。2012
    年，Krizhevsky 等人 [[38](#bib.bib38)] 引入了深度 CNN AlexNet。它在 2012 年以显著的优势赢得了 ImageNet
    大规模视觉识别挑战赛（ILSVRC）。2013 年，Zeiler 和 Fergus [[39](#bib.bib39)] 创建了 ZFNet，这是一种对 AlexNet
    参数进行微调的网络，并赢得了 ILSVRC。Szegedy 等人 [[40](#bib.bib40)] 在 2014 年通过 GoogLeNet 赢得了 ILSVRC，该网络使用的参数数量（400
    万）远少于 AlexNet（6000 万）。2015 年，He 等人 [[41](#bib.bib41)] 开发了 ResNets，使 CNN 能够拥有非常深的网络结构。2016
    年，Huang 等人 [[42](#bib.bib42)] 发表了 DenseNet，其中每一层都以前馈的方式直接连接到其他所有层。这种架构还消除了梯度消失问题，使得非常深的网络成为可能。以上示例只是
    CNN 的一些实例。
- en: 2.3.3 Deep Belief Network (DBN)
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.3 深度信念网络（DBN）
- en: 'A DBN is a type (generative) of Probabilistic Graphical Model (PGM), the marriage
    of probability and graph theory. Specifically, a DBN is a “deep” (large) Directed
    Acyclic Graph (DAG). A number of well-known algorithms exist for exact and approximate
    inference (infer the states of unobserved (hidden) variables) and learning (learn
    the interactions between variables) in PGMs. A DBN can also be thought of as a
    type of deep NN. In [[43](#bib.bib43)] , Hinton showed that a DBN can be viewed
    and trained (in a greedy manner) as a stack of simple unsupervised networks, namely
    Restricted Boltzmann Machines (RBMs), or generative AEs. To date, CNNs have demonstrated
    better performance on various benchmark CV data sets. However, in theory DBNs
    are arguably superior. CNNs possess generally a lot more “constraints”. The DBN
    versus CNN topic is likely subject to change as better algorithms are proposed
    for DBN learning. Figure [1](#S2.F1 "Figure 1 ‣ 2.3.1 Autoencoder (AE) ‣ 2.3 DL
    Approaches ‣ 2 Related work in CV ‣ A Comprehensive Survey of Deep Learning in
    Remote Sensing: Theories, Tools and Challenges for the Community")(c) depicts
    a DBN, which is made up of RBM layers and a visible layer.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 深度置信网络（DBN）是一种（生成的）概率图模型（PGM），是概率与图论的结合。具体来说，DBN 是一个“大型”（深度的）有向无环图（DAG）。在 PGM
    中，存在许多著名的算法用于精确和近似推断（推断未观察到的（隐藏的）变量的状态）和学习（学习变量之间的交互）。DBN 也可以被视为一种深度神经网络（NN）。在
    [[43](#bib.bib43)] 中，Hinton 证明了 DBN 可以被视为并训练（以贪婪方式）为一系列简单的无监督网络，即限制玻尔兹曼机（RBM）或生成自编码器（AE）。迄今为止，CNN
    在各种基准计算机视觉数据集上表现出了更好的性能。然而，从理论上讲，DBN 可以被认为是更优的。CNN 通常具有更多的“约束”。随着 DBN 学习算法的改进，DBN
    与 CNN 的比较话题可能会发生变化。图 [1](#S2.F1 "图 1 ‣ 2.3.1 自编码器（AE） ‣ 2.3 深度学习方法 ‣ 2 计算机视觉相关工作
    ‣ 深度学习在遥感中的全面调查：理论、工具和社区挑战")(c) 展示了一个由 RBM 层和一个可见层组成的 DBN。
- en: 2.3.4 Recurrent Neural Network (RNN)
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.4 循环神经网络（RNN）
- en: 'The RNN is a network where connections form directed cycles. The RNN is primarily
    used for analyzing non-stationary processes such as speech and time-series analysis.
    The RNN has memory, so the RNN has persistence, which the AE and CNN don’t possess.
    A RNN can be unrolled and analyzed as a series of interconnected networks that
    process time-series data. A major breakthrough for RNNs was the seminal work of
    Hochreiter and Schmidhuber [[44](#bib.bib44)] , the long short-term memory (LSTM)
    unit, which allows information to be written to a cell, output from the cell,
    and stored in the cell. The LSTM allows information to flow and helps counteract
    the vanishing/exploding gradient problems in very deep networks. Figure [1](#S2.F1
    "Figure 1 ‣ 2.3.1 Autoencoder (AE) ‣ 2.3 DL Approaches ‣ 2 Related work in CV
    ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and
    Challenges for the Community")(d) shows a RNN and its unfolded version.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 'RNN 是一个连接形成定向循环的网络。RNN 主要用于分析非平稳过程，如语音和时间序列分析。RNN 具有记忆，因此 RNN 具有持久性，而 AE 和
    CNN 不具备。RNN 可以展开并作为处理时间序列数据的一系列互连网络进行分析。RNN 的一个重大突破是 Hochreiter 和 Schmidhuber
    的开创性工作[[44](#bib.bib44)]，即长短期记忆（LSTM）单元，它允许信息写入单元、从单元输出并存储在单元中。LSTM 允许信息流动，并帮助应对非常深层网络中的梯度消失/爆炸问题。图
    [1](#S2.F1 "Figure 1 ‣ 2.3.1 Autoencoder (AE) ‣ 2.3 DL Approaches ‣ 2 Related
    work in CV ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories,
    Tools and Challenges for the Community")(d) 显示了 RNN 及其展开版本。'
- en: 2.3.5 Deconvolutional Neural Network (DeconvNet)
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.5 反卷积神经网络（DeconvNet）
- en: CNNs are often used for classification only. However, a wealth of questions
    exist beyond classification, e.g., what are our filters really learning, how transferable
    are these filters, what filters are the most active in a given image, where is
    a filter the most active at in a given image (or images), or more holistically,
    where in the image is our object(s) of interest (soft or hard segmentation). To
    this end, researchers have recently explored deconvolutional NN (DeconvNet) [[39](#bib.bib39),
    [45](#bib.bib45), [46](#bib.bib46), [47](#bib.bib47)] . Whereas CNNs use pooling,
    which helps us filter noisy activations and address affine transformations, a
    DeconvNet uses unpooling–the “inverse” of pooling. Unpooling makes use of “switch
    variables”, which help us place activation in layer $l$ back to its original pooled
    location in layer $l-1$. Unpooling results in an enlarged, be it sparse, activation
    map that is fed to deconvolution filters (that are either learned or derived from
    the CNN filters). In [[47](#bib.bib47)] , the Visual Geometry Group (VGG) developed
    the VGG 16-layer CNN, thus no deconvolution, with its last classification layer
    removed was used relative to computer vision on non-remotely sensed data. The
    resultant DeconvNet is twice as large as the VGG CNN. The first part of the network
    is the VGG CNN and the second part is an architecturally reversed copy of the
    VGG CNN with pooling replaced by unpooling. The entire network was trained and
    used for semantic image segmentation. In a different work, Zeiler et al. showed
    that a DeconvNet can be used to visualize a single CNN filter at any layer or
    a combination of CNN filters can be visualized for one or more images [[45](#bib.bib45),
    [39](#bib.bib39)] . The point is, relevant DeconvNet research exists in the CV
    literature.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 通常只用于分类。然而，除了分类之外，还有许多问题存在，例如，我们的滤波器真正学习了什么，这些滤波器的迁移性如何，哪些滤波器在给定图像中最为活跃，给定图像（或图像）中滤波器最活跃的地方在哪里，或者更整体地，我们图像中的兴趣对象（软分割或硬分割）在哪里。为此，研究人员最近探索了反卷积神经网络（DeconvNet）[[39](#bib.bib39),
    [45](#bib.bib45), [46](#bib.bib46), [47](#bib.bib47)]。而 CNN 使用池化，帮助我们过滤噪声激活并解决仿射变换，DeconvNet
    则使用反池化——池化的“逆”。反池化利用“开关变量”，帮助我们将层 $l$ 中的激活放回层 $l-1$ 中的原始池化位置。反池化产生一个扩大但稀疏的激活图，该图被输入到反卷积滤波器中（这些滤波器可以是学习的或源自
    CNN 滤波器）。在 [[47](#bib.bib47)] 中，视觉几何组（VGG）开发了 VGG 16 层 CNN，因此没有反卷积，其最后的分类层被去除，作为计算机视觉在非遥感数据上的应用。结果，DeconvNet
    的大小是 VGG CNN 的两倍。网络的第一部分是 VGG CNN，第二部分是 VGG CNN 的架构逆向副本，池化被反池化取代。整个网络被训练并用于语义图像分割。在另一项工作中，Zeiler
    等人展示了 DeconvNet 可用于可视化单个 CNN 滤波器在任何层中的表现，或可视化多个 CNN 滤波器在一个或多个图像中的表现[[45](#bib.bib45),
    [39](#bib.bib39)]。关键是，相关的 DeconvNet 研究在计算机视觉文献中存在。
- en: Two high-level comments are worth noting. First, DeconvNets have been used by
    some to help rationalize their architecture and operation selections in the context
    of a visual odyssey of its impact on the filters relative to one another, e.g.,
    existence of a single dominant feature versus a diverse set of features. In many
    cases its not a rationalization of the final network performance per se, but instead
    a DeconvNet is a helpful tool that aids them in exploring the vast sea of choices
    in designing the network. Second, whereas DeconvNet can be used in many cases
    for segmentation, they do not always produce the segmentation that we might desire.
    Meaning, if the CNN learned parts, not the full object, then activation of those
    parts, or a subset thereof, may not equate to the whole and those parts might
    also be spatially separated in the image. The later makes it challenging to construct
    a high quality full object segmentation, or segmentation’s if there are more than
    one instance of that object in an image. DeconvNets are basically very recent
    and have not (yet) been widely adopted by the RS community.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个高级评论值得注意。首先，DeconvNets 已被一些人用来帮助理清它们在滤镜之间的影响的视觉探索中的架构和操作选择，例如，单一主导特征的存在与多样特征集的对比。在许多情况下，这并不是对最终网络性能的合理化，而是
    DeconvNet 是一个有用的工具，帮助他们在设计网络时探索广阔的选择空间。其次，虽然 DeconvNet 在许多情况下可以用于分割，但它们并不总是产生我们可能期望的分割。这意味着，如果
    CNN 学到的是部分而非完整对象，则这些部分或其子集的激活可能不等于整体，而且这些部分在图像中可能空间上分离。后者使得构建高质量的完整对象分割或当图像中有多个该对象实例时的分割变得具有挑战性。DeconvNets
    基本上是非常新的，并且尚未（尚未）被 RS 社区广泛采用。
- en: 2.4 DL Meets the Real World
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 DL 遇见现实世界
- en: 'It is important to understand the different “factors” related to the rise and
    success of DL. This section discusses these factors: GPUs, DL NN expressivness,
    big data, and tools.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 理解 DL 的兴起和成功相关的不同“因素”是很重要的。本节讨论这些因素：GPU、DL NN 表达力、大数据和工具。
- en: 2.4.1 GPUs
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.1 GPUs
- en: GPUs are hardware devices that are optimized for fast parallel processing. GPUs
    enable DL by offloading computations from the computer’s main processor (which
    is basically optimized for serial tasks) and efficiently performing the matrix-based
    computations at the heart of many DL algorithms. The DL community can leverage
    the personal computer gaming industry, which demands relatively inexpensive and
    powerful GPUs. A major driver of the research interest in CNNs is the Imagenet
    contest, which has over one million training images and 1,000 classes [[48](#bib.bib48)]
    . DNNs are inherently parallel, utilize matrix operations, and use a large number
    of floating point operations per second. GPUs are a match because they have the
    same characteristics [[49](#bib.bib49)] . GPU speedups have been measured at 8.5
    to 9 [[49](#bib.bib49)] and even higher depending on the GPU and the code being
    optimized. The CNN convolution, pooling and activation calculation operations
    are readily portable to GPUs.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: GPUs 是专门优化用于快速并行处理的硬件设备。GPU 通过将计算从计算机的主处理器（基本上优化用于串行任务）转移出来，并高效地执行许多 DL 算法核心的矩阵计算，从而使
    DL 成为可能。DL 社区可以利用个人电脑游戏行业，这个行业对相对便宜且强大的 GPU 有需求。CNN 研究兴趣的一个主要驱动力是 Imagenet 竞赛，它有超过一百万张训练图像和
    1000 个类别 [[48](#bib.bib48)] 。DNN 本质上是并行的，利用矩阵操作，并使用大量的浮点操作每秒。GPU 与之匹配，因为它们具有相同的特征
    [[49](#bib.bib49)] 。GPU 的加速已被测量为 8.5 到 9 [[49](#bib.bib49)]，甚至更高，具体取决于 GPU 和优化的代码。CNN
    的卷积、池化和激活计算操作都可以轻松移植到 GPU 上。
- en: 2.4.2 DL NN Expressiveness
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.2 DL NN 表达力
- en: Cybenko [[50](#bib.bib50)] proved that MLPs are universal function approximators.
    Specifically, Cybenko showed that a feed-forward network with a single hidden
    layer containing a finite number of neurons can approximate continuous functions
    on compact subsets of $\Re^{n}$, with respect to relatively minimalistic assumptions
    regarding the activation function. However, Cybenok’s proof is an existence theorem,
    meaning it tells us a solution exists, but it does not tell us how to design or
    learn such a network. The point is, NNs have an intriguing mathematical foundation
    that make them attractive with respect to machine learning. Furthermore, in a
    theoretical work, Telgarsky [[51](#bib.bib51)] has shown that for NN with Rectified
    Linear Units (ReLU) (1) functions with few oscillations poorly approximate functions
    with many oscillations, and (2) functions computed by NN with few (many) layers
    have few (many) oscillations. Basically, a deep network allows decision functions
    with high oscillations. This gives evidence to show why DL performs well in classification
    tasks, and that shallower networks have limitations with highly oscillatory functions.
    Sharir et al. [[52](#bib.bib52)] showed that having overlapping local receptive
    fields and more broadly denser connectivity gives an exponential increase in the
    expressive capacity of the NN. Liang et al. [[53](#bib.bib53)] showed that shallow
    networks require exponentially more neurons than a deep network to achieve the
    level of accuracy for function approximation.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Cybenko [[50](#bib.bib50)] 证明了多层感知器（MLPs）是通用函数逼近器。具体而言，Cybenko 显示了一个具有有限神经元数目的单隐层前馈网络可以在
    $\Re^{n}$ 的紧致子集上逼近连续函数，并且对于激活函数的假设相对简单。然而，Cybenko 的证明是存在性定理，这意味着它告诉我们一个解决方案存在，但没有告诉我们如何设计或学习这样的网络。关键在于，神经网络（NNs）具有引人入胜的数学基础，使其在机器学习中具有吸引力。此外，在理论工作中，Telgarsky
    [[51](#bib.bib51)] 表明，对于具有修正线性单元（ReLU）的神经网络，(1) 少波动的函数对多波动的函数的逼近效果较差，(2) 少（多）层的神经网络计算的函数具有少（多）波动。基本上，深层网络允许具有高波动的决策函数。这为深度学习在分类任务中表现良好的原因提供了证据，并且较浅的网络在处理高波动函数时存在限制。Sharir
    等人 [[52](#bib.bib52)] 显示，具有重叠局部感受野和更广泛的密集连接会使神经网络的表现能力呈指数增长。Liang 等人 [[53](#bib.bib53)]
    表示，浅层网络需要比深层网络多得多的神经元才能实现函数逼近的精度。
- en: 2.4.3 Big Data
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.3 大数据
- en: Every day, approximately $350$ million images are uploaded to Facebook [[49](#bib.bib49)]
    , Wal-Mart collects approximately $2.5$ petabytes of data per day [[49](#bib.bib49)]
    , and National Aeronautics and Space Administration (NASA) alone is actively streaming
    $1.73$ gigabytes of spacecraft borne observation data for active missions alone
    [[54](#bib.bib54)]. IBM reports that $2.5$ quintillion bytes of data are now generated
    every data, which means that “$90\%$ of the data in the world today has been created
    in the last two years alone” [[55](#bib.bib55)] . The point is, an unprecedented
    amount of (varying quality) data exists due to technologies like remote sensing,
    smart phones, inexpensive data storage, etc. In times past, researchers used tens
    to hundreds, maybe thousands of data training samples, but nothing on the order
    of magnitude as today. In areas like CV, high data volume and variety have been
    at the heart of advancements in performance. Meaning, reported results are a reflection
    of advances in both data and machine learning.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 每天，大约有 $350$ 万张图片被上传到 Facebook [[49](#bib.bib49)]，沃尔玛每天收集大约 $2.5$ PB 的数据 [[49](#bib.bib49)]，而美国国家航空航天局（NASA）仅在进行中的任务中，就活跃地传输
    $1.73$ GB 的航天器观察数据 [[54](#bib.bib54)]。IBM 报告称，现在每天生成的数据量达到 $2.5$ 恩字节，这意味着“今天世界上
    $90\%$ 的数据是在过去两年内创建的” [[55](#bib.bib55)]。关键在于，由于遥感、智能手机、廉价数据存储等技术，存在着前所未有的大量（质量各异的）数据。过去，研究人员使用数十到数百，甚至可能是几千个数据训练样本，但没有达到今天这样的大量级。在计算机视觉等领域，高数据量和多样性一直是性能进步的核心。这意味着，报告的结果反映了数据和机器学习的进步。
- en: To date, a number of approaches have been explored relative to large scale deep
    networks (e.g., hundreds of layers) and Big Data (e.g., high volume of data).
    For example, in [[56](#bib.bib56)] Raina et al. put forth CPU and GPU ideas to
    accelerate DBNs and sparse coding. They reported a 5 to 15-fold speed up for networks
    with 100 million plus parameters versus previous works that used only a few million
    parameters at best. On the other hand, CNNs typically use back propagation and
    they can be implemented either by pulling of pushing [[57](#bib.bib57)] . Furthermore,
    ideas like circular buffers [[58](#bib.bib58)] and multi GPU based CNN architectures,
    e.g., Krizhevsky [[38](#bib.bib38)] , have been put forth. Outside of hardware
    speedups, operators like ReLUs have been shown to run sever times faster than
    other common nonlinear functions. In [[59](#bib.bib59)] , Deng et al. put forth
    a Deep Stacking Network (DSN) that consists of specialized NNs (called modules),
    each of which have a single hidden layer. Hutchinson et al. put forth Tensor-DSN
    is an efficient and parallel extension of DSNs for CPU clusters [[60](#bib.bib60)]
    . Furthermore, DistBelief is a library for distributed training and learning of
    deep networks with large models (billions of parameters) and massive sized data
    sets [[61](#bib.bib61)] . DistBelief makes use of machine clusters to manage the
    data and parallelism via methods like multi-threading, message passing, synchronization
    and machine-to-machine communication. DistBelief uses different optimization methods,
    namely SGD and Sandblaster [[62](#bib.bib62)] . Last, but not least, there are
    network architectures such as highway networks, residual networks and dense nets
    [[63](#bib.bib63), [64](#bib.bib64), [65](#bib.bib65), [66](#bib.bib66), [67](#bib.bib67)]
    . For example, highway networks are based on LSTM recurrent networks and they
    allow for the efficient training of deep networks with hundreds of layers based
    on gradient descent [[64](#bib.bib64), [65](#bib.bib65), [66](#bib.bib66)] .
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 至今，已经探索了许多与大规模深度网络（例如，数百层）和大数据（例如，大量数据）相关的方法。例如，在[[56](#bib.bib56)]中，Raina等人提出了加速DBNs和稀疏编码的CPU和GPU方案。他们报告了对于拥有超过1亿参数的网络，与之前仅使用几百万参数的工作相比，速度提高了5到15倍。另一方面，CNN通常使用反向传播，并且可以通过拉取或推送来实现[[57](#bib.bib57)]。此外，像循环缓冲区[[58](#bib.bib58)]和基于多GPU的CNN架构（例如，Krizhevsky
    [[38](#bib.bib38)]）等理念也被提出。除了硬件加速外，像ReLUs这样的操作符已经显示出比其他常见非线性函数快数倍。在[[59](#bib.bib59)]中，Deng等人提出了一种深度堆叠网络（DSN），由多个专门的NN（称为模块）组成，每个模块只有一个隐藏层。Hutchinson等人提出了Tensor-DSN，这是DSN在CPU集群上的高效并行扩展[[60](#bib.bib60)]。此外，DistBelief是一个用于大模型（数十亿参数）和大规模数据集的深度网络分布式训练和学习库[[61](#bib.bib61)]。DistBelief利用机器集群通过多线程、消息传递、同步和机器间通信等方法来管理数据和并行性。DistBelief使用不同的优化方法，即SGD和Sandblaster[[62](#bib.bib62)]。最后但同样重要的是，还有像高速公路网络、残差网络和密集网络[[63](#bib.bib63),
    [64](#bib.bib64), [65](#bib.bib65), [66](#bib.bib66), [67](#bib.bib67)]这样的网络架构。例如，高速公路网络基于LSTM递归网络，并允许基于梯度下降的深度网络有效训练，网络层数可达数百层[[64](#bib.bib64),
    [65](#bib.bib65), [66](#bib.bib66)]。
- en: 2.4.4 Tools
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.4 工具
- en: Tools are also a large factor in DL research and development. Wan et al. observe
    that DL is at the intersection of NNs, graphical modeling, optimization, pattern
    recognition and signal processing [[5](#bib.bib5)] , which means there is a fairly
    high background level required for this area. Good DL tools allow researchers
    and students to try some basic architectures and create new ones more efficiently.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 工具也是深度学习研究和开发中的一个重要因素。Wan等人观察到深度学习位于NN、图形建模、优化、模式识别和信号处理的交叉点[[5](#bib.bib5)]，这意味着该领域需要相当高的背景知识。好的深度学习工具使研究人员和学生能够更高效地尝试一些基本架构并创建新的架构。
- en: 'Table [2](#S2.T2 "Table 2 ‣ 2.4.4 Tools ‣ 2.4 DL Meets the Real World ‣ 2 Related
    work in CV ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories,
    Tools and Challenges for the Community") lists some popular DL toolkits and links
    to the code. Herein, we review some of the DL tools, and the tool analysis below
    are based on our experiences with these tools. We thank our graduate students
    for providing detailed feedback on these tools.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '表[2](#S2.T2 "Table 2 ‣ 2.4.4 Tools ‣ 2.4 DL Meets the Real World ‣ 2 Related
    work in CV ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories,
    Tools and Challenges for the Community")列出了一些流行的深度学习工具包和代码链接。在此，我们回顾了一些深度学习工具，下面的工具分析基于我们对这些工具的使用经验。感谢我们的研究生提供了对这些工具的详细反馈。'
- en: AlexNet [[38](#bib.bib38)] was a revolutionary paper that re-introduced the
    world to the results that DL can offer. AlexNet utilizes ReLU because it is several
    times faster to evaluate than the hyperbolic tangent. AlexNet revealed the importance
    of pre-processing by incorporating some data augmentation techniques and was able
    to combat overfitting by using max pooling and dropout layers.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet [[38](#bib.bib38)] 是一篇具有革命性的论文，它重新向世界展示了深度学习能提供的成果。AlexNet 使用 ReLU，因为它的计算速度比双曲正切函数快几倍。AlexNet
    通过结合一些数据增强技术，揭示了预处理的重要性，并且通过使用最大池化和 dropout 层来对抗过拟合。
- en: Caffe [[68](#bib.bib68)] was the first widely used deep learning toolkit. Caffe
    is C++ based and can be compiled on various devices, and offers command line,
    Python, and Matlab interfaces. There are many useful examples provided. The cons
    of Caffe are that is is relatively hard to install, due to lack of documentation
    and not being developed by an organized company. For those interested in something
    other than image processing, (e.g. image classification, image segmentation),
    it is not really suitable for other areas, such as audio signal processing.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Caffe [[68](#bib.bib68)] 是第一个广泛使用的深度学习工具包。Caffe 基于 C++，可以在各种设备上编译，并提供命令行、Python
    和 Matlab 接口。提供了许多有用的示例。Caffe 的缺点是相对较难安装，由于缺乏文档且不是由有组织的公司开发。对于那些对图像处理以外的内容感兴趣的用户（例如图像分类、图像分割），它并不适合其他领域，例如音频信号处理。
- en: TensorFlow [[69](#bib.bib69)] is arguably the most popular DL tool available.
    It’s pros are that TensorFlow (1) is relatively easy to install both with CPU
    and GPU version on Ubuntu (The GPU version needs CUDA and cuDNN to be installed
    ahead of time, which is a little complicated); (2) has most of the state-of-the-art
    models implemented, and while some original implementation are not implemented
    in TensorFlow, but it is relatively easy to find a re-implementation in TensorFlow;
    (3) has very good documentation and regular updates; (4) supports both Python
    and C++ interfaces; and (5) is relatively easy to expand to other areas besides
    image processing, as long as you understand the tensor processing. One con of
    TensorFlow is that it is really restricted to Linux applications, as the windows
    version is barely usable.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow [[69](#bib.bib69)] 可以说是目前最受欢迎的深度学习工具。它的优点是 TensorFlow (1) 在 Ubuntu
    上安装相对简单，包括 CPU 和 GPU 版本（GPU 版本需要提前安装 CUDA 和 cuDNN，这有点复杂）；(2) 实现了大多数最先进的模型，虽然一些原始实现没有在
    TensorFlow 中实现，但相对容易找到 TensorFlow 中的重新实现；(3) 文档非常好，并且定期更新；(4) 支持 Python 和 C++
    接口；(5) 相对容易扩展到图像处理以外的其他领域，只要你理解张量处理。TensorFlow 的一个缺点是它确实局限于 Linux 应用程序，因为 Windows
    版本几乎不可用。
- en: MatConvNet [[70](#bib.bib70)] is a convenient tool, with unique abstract implementations
    for those very comfortable with using Matlab. It offers many popular trained CNN’s,
    and the data sets used to train them. It is fairly easy to install. Once the GPU
    setup is ready (installation of drivers + CUDA support), training with the GPU
    is very simple. It also offers Windows support. The cons are (1) there is a substantially
    smaller online community compared to TensorFlow and Caffe, (2) code documentation
    is not very detailed and in general does not have good online tutorials besides
    the manual. Lack of “getting started” help besides a very simple example, and
    (3) GPU setup can be quite tedious. For Windows, Visual Studio is required, due
    to restrictions on Matlab and its mex setup, as well as Nvidia drivers and CUDA
    support. On Linux, one has much more freedom, but must be willing to adapt to
    manual installations of Nvidia drivers, CUDA-support, and more.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: MatConvNet [[70](#bib.bib70)] 是一个方便的工具，为那些非常熟悉使用 Matlab 的用户提供了独特的抽象实现。它提供了许多流行的训练过的
    CNN 及其训练所用的数据集。安装相对简单。一旦 GPU 设置完成（安装驱动程序 + CUDA 支持），使用 GPU 进行训练非常简单。它还支持 Windows。缺点是
    (1) 与 TensorFlow 和 Caffe 相比，在线社区相对较小，(2) 代码文档不够详细，一般没有好的在线教程，除了手册之外。除了一个非常简单的示例之外，没有“入门”帮助，(3)
    GPU 设置可能相当繁琐。对于 Windows，由于 Matlab 及其 mex 设置的限制以及 Nvidia 驱动程序和 CUDA 支持，需要 Visual
    Studio。在 Linux 上，用户有更多的自由，但必须愿意适应 Nvidia 驱动程序、CUDA 支持等的手动安装。
- en: 'Table 2: Some popular DL tools.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：一些流行的深度学习工具。
- en: '| Tool & Citation | Tool Summary and Website |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 工具与引用 | 工具总结与网站 |'
- en: '| --- | --- |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| AlexNet [[38](#bib.bib38)] | A large-scale CNN with a non-saturating,neurons
    and a very efficient GPU parallel implementation of the convolution operation
    to make training faster. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| AlexNet [[38](#bib.bib38)] | 一个大规模的 CNN，具有非饱和神经元，并且在卷积操作的 GPU 并行实现上非常高效，从而加快了训练速度。
    |'
- en: '|  | Website: [http://code.google.com/p/cuda-convnet/](http://code.google.com/p/cuda-convnet/)
    |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '|  | 网站: [http://code.google.com/p/cuda-convnet/](http://code.google.com/p/cuda-convnet/)
    |'
- en: '| Caffe [[68](#bib.bib68)] | C++ library with Python and Matlab interfaces.
    |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| Caffe [[68](#bib.bib68)] | 一个具有 Python 和 Matlab 接口的 C++ 库。 |'
- en: '|  | Website: [http://caffe.berkeleyvision.org/](http://caffe.berkeleyvision.org/)
    |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '|  | 网站: [http://caffe.berkeleyvision.org/](http://caffe.berkeleyvision.org/)
    |'
- en: '| cuda-convnet2 [[38](#bib.bib38)] | The DL tool cuda-convnet2 is a fast C++/CUDA
    CNN implementation, and can also model any directed acyclic graphs. Training is
    performed using back-propagation. Offers faster training on Kepler-generation
    GPUs and multi-GPU training support. |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| cuda-convnet2 [[38](#bib.bib38)] | DL 工具 cuda-convnet2 是一个快速的 C++/CUDA CNN
    实现，也可以建模任何有向无环图。训练使用反向传播进行。提供在 Kepler 代 GPU 上更快的训练速度和多 GPU 训练支持。 |'
- en: '|  | Website: [https://code.google.com/p/cuda-convnet2/](https://code.google.com/p/cuda-convnet2/)
    |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|  | 网站: [https://code.google.com/p/cuda-convnet2/](https://code.google.com/p/cuda-convnet2/)
    |'
- en: '| gvnn [[71](#bib.bib71)] | The DL package gvnn is a NN library in Torch aimed
    towards bridging the gap between classic geometric computer vision and DL. This
    DL package is used for recognition, end-to-end visual odometry, depth estimation,
    etc. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| gvnn [[71](#bib.bib71)] | DL 包 gvnn 是一个 Torch 中的 NN 库，旨在弥合经典几何计算机视觉与 DL 之间的差距。此
    DL 包用于识别、端到端视觉里程计、深度估计等。 |'
- en: '|  | Website: [https://github.com/ankurhanda/gvnn](https://github.com/ankurhanda/gvnn)
    |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '|  | 网站: [https://github.com/ankurhanda/gvnn](https://github.com/ankurhanda/gvnn)
    |'
- en: '| Keras [[72](#bib.bib72)] | Keras is a high-level Python NN library capable
    of running on top of either TensorFlow or Theano and was developed with a focus
    on enabling fast experimentation. Keras (1) allows for easy and fast prototyping,
    (2) supports both convolutional networks and recurrent networks, (3) supports
    arbitrary connectivity schemes, and (4) runs seamlessly on CPUs and GPUs. |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| Keras [[72](#bib.bib72)] | Keras 是一个高级 Python NN 库，能够在 TensorFlow 或 Theano
    上运行，开发时着重于快速实验。Keras (1) 允许轻松和快速的原型开发，(2) 支持卷积网络和递归网络，(3) 支持任意连接方案，以及 (4) 能在 CPU
    和 GPU 上无缝运行。 |'
- en: '|  | Website: [https://keras.io/](https://keras.io/) and [https://github.com/fchollet/keras](https://github.com/fchollet/keras)
    |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '|  | 网站: [https://keras.io/](https://keras.io/) 和 [https://github.com/fchollet/keras](https://github.com/fchollet/keras)
    |'
- en: '| MatConvNet [[70](#bib.bib70)] | A Matlab toolbox implementing CNNs with many
    pre-trained CNNs for image classification, segmentation, etc. |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| MatConvNet [[70](#bib.bib70)] | 一个实现 CNN 的 Matlab 工具箱，包含许多用于图像分类、分割等的预训练
    CNN。 |'
- en: '|  | Website: [http://www.vlfeat.org/matconvnet/](http://www.vlfeat.org/matconvnet/)
    |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '|  | 网站: [http://www.vlfeat.org/matconvnet/](http://www.vlfeat.org/matconvnet/)
    |'
- en: '| MXNet [[73](#bib.bib73)] | MXNet is a DL library. Features include declarative
    symbolic expression with imperative tensor computation and differentiation to
    derive gradients. MXNet runs on mobile devices to distributed GPU clusters. |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| MXNet [[73](#bib.bib73)] | MXNet 是一个 DL 库。其特点包括声明式符号表达与命令式张量计算和微分以导出梯度。MXNet
    可以在移动设备到分布式 GPU 集群上运行。 |'
- en: '|  | Website: [https://github.com/dmlc/mxnet/](https://github.com/dmlc/mxnet/)
    |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|  | 网站: [https://github.com/dmlc/mxnet/](https://github.com/dmlc/mxnet/) |'
- en: '| TensorFlow [[69](#bib.bib69)] | An open source software library for tensor
    data flow graph computation. The flexible architecture allows you to deploy computation
    to one or more CPUs or GPUs in a desktop, server, or mobile devices. |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| TensorFlow [[69](#bib.bib69)] | 一个开源的软件库，用于张量数据流图计算。灵活的架构允许你在桌面、服务器或移动设备上将计算部署到一个或多个
    CPU 或 GPU。 |'
- en: '|  | Website: [https://www.tensorflow.org/](https://www.tensorflow.org/) |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '|  | 网站: [https://www.tensorflow.org/](https://www.tensorflow.org/) |'
- en: '| Theano [[74](#bib.bib74)] | A Python library that allows you to define, optimize,
    and efficiently evaluate mathematical expressions involving multi-dimensional
    arrays. Theano features (1) tight integration with NumPy, (2) transparent use
    of a GPU, (3) efficient symbolic differentiation, and (4) dynamic C code generation.
    |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| Theano [[74](#bib.bib74)] | 一个 Python 库，允许你定义、优化并高效评估涉及多维数组的数学表达式。Theano
    具有以下特点：(1) 与 NumPy 的紧密集成，(2) 透明的 GPU 使用，(3) 高效的符号微分，以及 (4) 动态 C 代码生成。 |'
- en: '|  | Website: [http://deeplearning.net/software/theano](http://deeplearning.net/software/theano)
    |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '|  | 网站: [http://deeplearning.net/software/theano](http://deeplearning.net/software/theano)
    |'
- en: '| Torch [[75](#bib.bib75)] | Torch is an embeddable scientific computing framework
    with GPU optimizations, which uses the LuaJIT scripting language and a C/CUDA
    implementation. Torch includes (1) optimized linear algebra and numeric routines,
    (2) neural network and energy-based models, and (3) GPU support. |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| Torch [[75](#bib.bib75)] | Torch是一个可嵌入的科学计算框架，具有GPU优化，使用LuaJIT脚本语言和C/CUDA实现。Torch包括（1）优化的线性代数和数值例程，（2）神经网络和基于能量的模型，（3）GPU支持。
    |'
- en: '|  | Website: [http://torch.ch/](http://torch.ch/) |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '|  | 网站：[http://torch.ch/](http://torch.ch/) |'
- en: 2.5 DL in other domains
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5 DL在其他领域
- en: DL has been utilized in other areas than RS, namely human behavior analysis
    [[76](#bib.bib76), [77](#bib.bib77), [78](#bib.bib78), [79](#bib.bib79)] , speech
    recognition [[80](#bib.bib80), [81](#bib.bib81), [82](#bib.bib82)] , stereo vision
    [[83](#bib.bib83)] , robotics [[84](#bib.bib84)] , signal-to-text [[85](#bib.bib85),
    [86](#bib.bib86), [87](#bib.bib87), [88](#bib.bib88), [89](#bib.bib89)] , physics
    [[90](#bib.bib90), [91](#bib.bib91)] , cancer detection [[92](#bib.bib92), [93](#bib.bib93),
    [94](#bib.bib94)] , time-series analysis [[95](#bib.bib95), [96](#bib.bib96),
    [97](#bib.bib97)] , image synthesis [[98](#bib.bib98), [99](#bib.bib99), [100](#bib.bib100),
    [101](#bib.bib101), [102](#bib.bib102), [103](#bib.bib103), [104](#bib.bib104)]
    , stock market analysis [[105](#bib.bib105)] , and security applications [[106](#bib.bib106)]
    . These diverse set of applications show the power of DL.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: DL已经在遥感以外的其他领域得到了应用，即人类行为分析[[76](#bib.bib76), [77](#bib.bib77), [78](#bib.bib78),
    [79](#bib.bib79)]，语音识别[[80](#bib.bib80), [81](#bib.bib81), [82](#bib.bib82)]，立体视觉[[83](#bib.bib83)]，机器人技术[[84](#bib.bib84)]，信号转文本[[85](#bib.bib85),
    [86](#bib.bib86), [87](#bib.bib87), [88](#bib.bib88), [89](#bib.bib89)]，物理学[[90](#bib.bib90),
    [91](#bib.bib91)]，癌症检测[[92](#bib.bib92), [93](#bib.bib93), [94](#bib.bib94)]，时间序列分析[[95](#bib.bib95),
    [96](#bib.bib96), [97](#bib.bib97)]，图像合成[[98](#bib.bib98), [99](#bib.bib99), [100](#bib.bib100),
    [101](#bib.bib101), [102](#bib.bib102), [103](#bib.bib103), [104](#bib.bib104)]，股票市场分析[[105](#bib.bib105)]，以及安全应用[[106](#bib.bib106)]。这些多样化的应用展示了DL的强大能力。
- en: 3 DL approaches in RS
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 遥感中的3种DL方法
- en: 'There are many RS tasks that utilize RS data, including automated target detection,
    pansharpening, land cover and land use classification, time series analysis, change
    detection, etc. Many of these tasks utilize shape analysis, object recognition,
    dimensionality reduction, image enhancement, and other techniques, which are all
    amenable to DL approaches. Table [3](#S3.T3 "Table 3 ‣ 3 DL approaches in RS ‣
    A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and
    Challenges for the Community") groups DL papers reviewed in this paper into these
    basic categories. From the table, it can be seen that there is a large diversity
    of applications, indicating that RS researchers have seen value in using DL methods
    in many different areas. Several representative papers are reviewed and discussed.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '有许多遥感任务利用遥感数据，包括自动目标检测、全色融合、土地覆盖和土地利用分类、时间序列分析、变化检测等。许多这些任务利用形状分析、物体识别、降维、图像增强等技术，这些技术都适合DL方法。表[3](#S3.T3
    "Table 3 ‣ 3 DL approaches in RS ‣ A Comprehensive Survey of Deep Learning in
    Remote Sensing: Theories, Tools and Challenges for the Community")将本文回顾的DL论文分为这些基本类别。从表中可以看出，应用领域非常广泛，这表明遥感研究人员在许多不同领域看到了使用DL方法的价值。几个代表性论文被回顾和讨论。'
- en: 'Table 3: DL paper subject areas in remote sensing.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：遥感中的DL论文主题领域。
- en: '| Area | References | Area | References |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 领域 | 参考文献 | 领域 | 参考文献 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 3D (depth and shape) analysis | [[107](#bib.bib107), [108](#bib.bib108),
    [109](#bib.bib109), [110](#bib.bib110), [111](#bib.bib111), [112](#bib.bib112),
    [113](#bib.bib113), [114](#bib.bib114), [115](#bib.bib115)] | Advanced driver
    assistance systems | [[116](#bib.bib116), [117](#bib.bib117), [118](#bib.bib118),
    [119](#bib.bib119), [120](#bib.bib120)] |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 3D（深度和形状）分析 | [[107](#bib.bib107), [108](#bib.bib108), [109](#bib.bib109),
    [110](#bib.bib110), [111](#bib.bib111), [112](#bib.bib112), [113](#bib.bib113),
    [114](#bib.bib114), [115](#bib.bib115)] | 高级驾驶员辅助系统 | [[116](#bib.bib116), [117](#bib.bib117),
    [118](#bib.bib118), [119](#bib.bib119), [120](#bib.bib120)] |'
- en: '| Animal detection | [[121](#bib.bib121)] | Anomaly detection | [[122](#bib.bib122)]
    |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 动物检测 | [[121](#bib.bib121)] | 异常检测 | [[122](#bib.bib122)] |'
- en: '| Automated Target Recognition | [[123](#bib.bib123), [124](#bib.bib124), [125](#bib.bib125),
    [126](#bib.bib126), [127](#bib.bib127), [128](#bib.bib128), [129](#bib.bib129),
    [130](#bib.bib130), [131](#bib.bib131), [132](#bib.bib132), [133](#bib.bib133),
    [134](#bib.bib134)] | Change detection | [[135](#bib.bib135), [136](#bib.bib136),
    [137](#bib.bib137), [138](#bib.bib138), [139](#bib.bib139)] |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 自动目标识别 | [[123](#bib.bib123), [124](#bib.bib124), [125](#bib.bib125), [126](#bib.bib126),
    [127](#bib.bib127), [128](#bib.bib128), [129](#bib.bib129), [130](#bib.bib130),
    [131](#bib.bib131), [132](#bib.bib132), [133](#bib.bib133), [134](#bib.bib134)]
    | 变化检测 | [[135](#bib.bib135), [136](#bib.bib136), [137](#bib.bib137), [138](#bib.bib138),
    [139](#bib.bib139)] |'
- en: '| Classification | [[140](#bib.bib140), [141](#bib.bib141), [142](#bib.bib142),
    [143](#bib.bib143), [144](#bib.bib144), [145](#bib.bib145), [146](#bib.bib146),
    [147](#bib.bib147), [148](#bib.bib148), [149](#bib.bib149), [150](#bib.bib150),
    [151](#bib.bib151), [152](#bib.bib152), [153](#bib.bib153), [154](#bib.bib154),
    [155](#bib.bib155), [156](#bib.bib156), [157](#bib.bib157), [158](#bib.bib158),
    [159](#bib.bib159), [160](#bib.bib160), [161](#bib.bib161), [162](#bib.bib162),
    [163](#bib.bib163), [164](#bib.bib164), [165](#bib.bib165), [166](#bib.bib166),
    [167](#bib.bib167), [168](#bib.bib168), [169](#bib.bib169), [170](#bib.bib170),
    [171](#bib.bib171), [172](#bib.bib172), [173](#bib.bib173), [174](#bib.bib174),
    [175](#bib.bib175), [176](#bib.bib176), [177](#bib.bib177), [178](#bib.bib178),
    [179](#bib.bib179), [180](#bib.bib180), [181](#bib.bib181), [182](#bib.bib182),
    [183](#bib.bib183), [184](#bib.bib184), [185](#bib.bib185), [186](#bib.bib186),
    [187](#bib.bib187), [188](#bib.bib188), [189](#bib.bib189), [190](#bib.bib190)]
    | Data fusion | [[191](#bib.bib191)] |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 分类 | [[140](#bib.bib140), [141](#bib.bib141), [142](#bib.bib142), [143](#bib.bib143),
    [144](#bib.bib144), [145](#bib.bib145), [146](#bib.bib146), [147](#bib.bib147),
    [148](#bib.bib148), [149](#bib.bib149), [150](#bib.bib150), [151](#bib.bib151),
    [152](#bib.bib152), [153](#bib.bib153), [154](#bib.bib154), [155](#bib.bib155),
    [156](#bib.bib156), [157](#bib.bib157), [158](#bib.bib158), [159](#bib.bib159),
    [160](#bib.bib160), [161](#bib.bib161), [162](#bib.bib162), [163](#bib.bib163),
    [164](#bib.bib164), [165](#bib.bib165), [166](#bib.bib166), [167](#bib.bib167),
    [168](#bib.bib168), [169](#bib.bib169), [170](#bib.bib170), [171](#bib.bib171),
    [172](#bib.bib172), [173](#bib.bib173), [174](#bib.bib174), [175](#bib.bib175),
    [176](#bib.bib176), [177](#bib.bib177), [178](#bib.bib178), [179](#bib.bib179),
    [180](#bib.bib180), [181](#bib.bib181), [182](#bib.bib182), [183](#bib.bib183),
    [184](#bib.bib184), [185](#bib.bib185), [186](#bib.bib186), [187](#bib.bib187),
    [188](#bib.bib188), [189](#bib.bib189), [190](#bib.bib190)] | 数据融合 | [[191](#bib.bib191)]
    |'
- en: '| Dimensionality reduction | [[192](#bib.bib192), [193](#bib.bib193)] | Disaster
    analysis/assessment | [[194](#bib.bib194)] |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 降维 | [[192](#bib.bib192), [193](#bib.bib193)] | 灾难分析/评估 | [[194](#bib.bib194)]
    |'
- en: '| Environment and water analysis | [[195](#bib.bib195), [196](#bib.bib196),
    [197](#bib.bib197), [198](#bib.bib198)] | Geo-information extraction | [[199](#bib.bib199)]
    |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 环境和水分析 | [[195](#bib.bib195), [196](#bib.bib196), [197](#bib.bib197), [198](#bib.bib198)]
    | 地理信息提取 | [[199](#bib.bib199)] |'
- en: '| Human detection | [[200](#bib.bib200), [201](#bib.bib201), [202](#bib.bib202),
    [203](#bib.bib203)] | Image denoising/enhancement | [[204](#bib.bib204), [205](#bib.bib205)]
    |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 人体检测 | [[200](#bib.bib200), [201](#bib.bib201), [202](#bib.bib202), [203](#bib.bib203)]
    | 图像去噪/增强 | [[204](#bib.bib204), [205](#bib.bib205)] |'
- en: '| Image Registration | [[206](#bib.bib206)] | Land cover classification | [[207](#bib.bib207),
    [208](#bib.bib208), [209](#bib.bib209), [210](#bib.bib210), [211](#bib.bib211)]
    |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 图像配准 | [[206](#bib.bib206)] | 土地覆盖分类 | [[207](#bib.bib207), [208](#bib.bib208),
    [209](#bib.bib209), [210](#bib.bib210), [211](#bib.bib211)] |'
- en: '| Land use/classification | [[212](#bib.bib212), [213](#bib.bib213), [214](#bib.bib214),
    [215](#bib.bib215), [216](#bib.bib216), [217](#bib.bib217), [218](#bib.bib218),
    [219](#bib.bib219), [220](#bib.bib220), [221](#bib.bib221), [222](#bib.bib222)]
    | Object recognition and detection | [[223](#bib.bib223), [224](#bib.bib224),
    [225](#bib.bib225), [226](#bib.bib226), [227](#bib.bib227), [228](#bib.bib228),
    [229](#bib.bib229), [230](#bib.bib230), [231](#bib.bib231), [232](#bib.bib232),
    [233](#bib.bib233)] |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 土地使用/分类 | [[212](#bib.bib212), [213](#bib.bib213), [214](#bib.bib214), [215](#bib.bib215),
    [216](#bib.bib216), [217](#bib.bib217), [218](#bib.bib218), [219](#bib.bib219),
    [220](#bib.bib220), [221](#bib.bib221), [222](#bib.bib222)] | 目标识别和检测 | [[223](#bib.bib223),
    [224](#bib.bib224), [225](#bib.bib225), [226](#bib.bib226), [227](#bib.bib227),
    [228](#bib.bib228), [229](#bib.bib229), [230](#bib.bib230), [231](#bib.bib231),
    [232](#bib.bib232), [233](#bib.bib233)] |'
- en: '| Object tracking | [[234](#bib.bib234), [235](#bib.bib235)] | Pansharpening
    | [[236](#bib.bib236)] |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 目标跟踪 | [[234](#bib.bib234), [235](#bib.bib235)] | 全色锐化 | [[236](#bib.bib236)]
    |'
- en: '| Planetary studies | [[237](#bib.bib237)] | Plant and agricultural analysis
    | [[238](#bib.bib238), [239](#bib.bib239), [240](#bib.bib240), [241](#bib.bib241),
    [242](#bib.bib242), [243](#bib.bib243)] |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 行星研究 | [[237](#bib.bib237)] | 植物和农业分析 | [[238](#bib.bib238), [239](#bib.bib239),
    [240](#bib.bib240), [241](#bib.bib241), [242](#bib.bib242), [243](#bib.bib243)]
    |'
- en: '| Road segmentation/extraction | [[244](#bib.bib244), [245](#bib.bib245), [246](#bib.bib246),
    [247](#bib.bib247), [248](#bib.bib248), [249](#bib.bib249), [250](#bib.bib250)]
    | Scene understanding | [[251](#bib.bib251), [252](#bib.bib252), [253](#bib.bib253)]
    |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 道路分割/提取 | [[244](#bib.bib244), [245](#bib.bib245), [246](#bib.bib246), [247](#bib.bib247),
    [248](#bib.bib248), [249](#bib.bib249), [250](#bib.bib250)] | 场景理解 | [[251](#bib.bib251),
    [252](#bib.bib252), [253](#bib.bib253)] |'
- en: '| Semantic segmentation/annotation | [[254](#bib.bib254), [255](#bib.bib255),
    [256](#bib.bib256), [257](#bib.bib257), [258](#bib.bib258), [259](#bib.bib259),
    [260](#bib.bib260), [261](#bib.bib261), [262](#bib.bib262), [263](#bib.bib263),
    [264](#bib.bib264), [265](#bib.bib265), [266](#bib.bib266)] | Segmentation | [[267](#bib.bib267),
    [268](#bib.bib268), [269](#bib.bib269), [270](#bib.bib270), [271](#bib.bib271),
    [272](#bib.bib272)] |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 语义分割/标注 | [[254](#bib.bib254), [255](#bib.bib255), [256](#bib.bib256), [257](#bib.bib257),
    [258](#bib.bib258), [259](#bib.bib259), [260](#bib.bib260), [261](#bib.bib261),
    [262](#bib.bib262), [263](#bib.bib263), [264](#bib.bib264), [265](#bib.bib265),
    [266](#bib.bib266)] | 分割 | [[267](#bib.bib267), [268](#bib.bib268), [269](#bib.bib269),
    [270](#bib.bib270), [271](#bib.bib271), [272](#bib.bib272)] |'
- en: '| Ship classification/detection | [[273](#bib.bib273), [274](#bib.bib274),
    [275](#bib.bib275)] | Super-resolution | [[276](#bib.bib276), [277](#bib.bib277),
    [278](#bib.bib278), [279](#bib.bib279)] |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 船只分类/检测 | [[273](#bib.bib273), [274](#bib.bib274), [275](#bib.bib275)] |
    超分辨率 | [[276](#bib.bib276), [277](#bib.bib277), [278](#bib.bib278), [279](#bib.bib279)]
    |'
- en: '| Traffic flow analysis | [[280](#bib.bib280), [281](#bib.bib281)] | Underwater
    detection | [[282](#bib.bib282), [283](#bib.bib283), [284](#bib.bib284), [285](#bib.bib285)]
    |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 交通流量分析 | [[280](#bib.bib280), [281](#bib.bib281)] | 水下探测 | [[282](#bib.bib282),
    [283](#bib.bib283), [284](#bib.bib284), [285](#bib.bib285)] |'
- en: '| Urban/building | [[286](#bib.bib286), [287](#bib.bib287), [288](#bib.bib288),
    [289](#bib.bib289), [290](#bib.bib290), [291](#bib.bib291), [292](#bib.bib292),
    [293](#bib.bib293), [294](#bib.bib294), [295](#bib.bib295), [296](#bib.bib296)]
    | Vehicle detection/recognition | [[297](#bib.bib297), [298](#bib.bib298), [299](#bib.bib299),
    [300](#bib.bib300), [301](#bib.bib301), [302](#bib.bib302), [303](#bib.bib303),
    [304](#bib.bib304), [305](#bib.bib305), [306](#bib.bib306), [307](#bib.bib307),
    [308](#bib.bib308), [309](#bib.bib309), [310](#bib.bib310)] |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 城市/建筑 | [[286](#bib.bib286), [287](#bib.bib287), [288](#bib.bib288), [289](#bib.bib289),
    [290](#bib.bib290), [291](#bib.bib291), [292](#bib.bib292), [293](#bib.bib293),
    [294](#bib.bib294), [295](#bib.bib295), [296](#bib.bib296)] | 车辆检测/识别 | [[297](#bib.bib297),
    [298](#bib.bib298), [299](#bib.bib299), [300](#bib.bib300), [301](#bib.bib301),
    [302](#bib.bib302), [303](#bib.bib303), [304](#bib.bib304), [305](#bib.bib305),
    [306](#bib.bib306), [307](#bib.bib307), [308](#bib.bib308), [309](#bib.bib309),
    [310](#bib.bib310)] |'
- en: '| Weather forecasting | [[311](#bib.bib311), [312](#bib.bib312), [313](#bib.bib313)]
    |  |  |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 天气预报 | [[311](#bib.bib311), [312](#bib.bib312), [313](#bib.bib313)] |  |  |'
- en: Due to the large number of recent RS papers, we can’t review all of the papers
    utilizing DL or FL in RS applications. Instead, herein we focus on several papers
    in different areas of interest that offer creative solutions to problems encountered
    in DL and FL and should also have a wide interest to the readers. We do provide
    a summary of all of the DL in RS papers we reviewed online at [http://www.cs-chan.com/source/FADL/Online_Paper_Summary_Table.pdf](http://www.cs-chan.com/source/FADL/Online_Paper_Summary_Table.pdf).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 由于最近RS领域的论文数量众多，我们无法审查所有在RS应用中利用DL或FL的论文。相反，本节重点介绍了几个在不同兴趣领域提供创新解决方案的论文，这些解决方案解决了DL和FL中遇到的问题，并且应当对读者具有广泛的兴趣。我们确实提供了我们在线审阅的所有DL在RS论文的总结，见[http://www.cs-chan.com/source/FADL/Online_Paper_Summary_Table.pdf](http://www.cs-chan.com/source/FADL/Online_Paper_Summary_Table.pdf)。
- en: 3.1 Classification
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 分类
- en: Classification is the task of labeling pixels (or regions in an image) into
    one of several classes. The DL methods outlined below utilize many forms of DL
    to learn features from the data itself and perform classification at state-of-the-art
    levels. The following discusses classification in HSI, 3D, satellite imagery,
    traffic sign detection and Synthetic Aperture Radar (SAR).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是将像素（或图像中的区域）标记为几个类别中的一种的任务。以下概述的深度学习（DL）方法利用多种形式的DL从数据本身学习特征，并在最先进的水平上执行分类。以下讨论了HSI、3D、卫星图像、交通标志检测和合成孔径雷达（SAR）中的分类。
- en: 'HSI: HSI data classification is of major importance to RS applications, so
    many of the DL results we reviewed were on HSI classification. HSI processing
    has many challenges, including high data dimensionality and usually low numbers
    of training samples. Chen et al. [[314](#bib.bib314)] propose an DBN-based HSI
    classification framework. The input data is converted to a 1D vector and processed
    via a DBN with three RBM layers, and the class labels are output from a two-layer
    logistic regression NN. A spatial classifier using Principal Component Analysis
    (PCA) on the spectral dimension followed by 1D flattening of a 3D box, a three-level
    DBN and two level logistic regression classifier. A third architecture uses a
    combinations of the 1D spectrum and the spatial classifier architecture. He et
    al. [[151](#bib.bib151)] developed a DBN for HSI classification that does not
    require stochastic gradient descent (SGD) training. Nonlinear layers in the DBN
    allow for the nonlinear nature of HSI data and a logistic regression classifier
    is used to classify the outputs of the DBN layers. A parametric depth study showed
    depth of nine layers produced the best results of depths of 1 to 15, and after
    a depth of nine, no improvement resulted by adding more layers.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: HSI：HSI 数据分类对遥感应用至关重要，因此我们审查的许多深度学习结果都集中在 HSI 分类上。HSI 处理面临许多挑战，包括数据维度高且通常训练样本数量少。陈等人
    [[314](#bib.bib314)] 提出了一个基于 DBN 的 HSI 分类框架。输入数据被转换为一维向量，并通过具有三层 RBM 的 DBN 进行处理，类别标签则通过一个两层的逻辑回归神经网络输出。一个空间分类器使用主成分分析（PCA）对光谱维度进行处理，接着对三维盒子进行一维展平，然后是三层
    DBN 和两层逻辑回归分类器。第三种架构结合了一维光谱和空间分类器架构。何等人 [[151](#bib.bib151)] 开发了一种 DBN，用于 HSI
    分类，该方法不需要随机梯度下降（SGD）训练。DBN 中的非线性层允许适应 HSI 数据的非线性特性，逻辑回归分类器用于对 DBN 层的输出进行分类。一项参数化深度研究表明，九层深度产生了最佳结果，相比于深度为
    1 到 15 的层数，增加更多层数没有带来改进。
- en: Some of the HSI DL approaches utilize both spectral and spatial information.
    Ma et al. [[169](#bib.bib169)] created a HSI spatial updated deep AE which integrates
    spatial information. Small training sets are mitigated by a collaborative, representation-based
    classifier and salt-and-pepper noise is mitigated by a graph-cut-based spatial
    regularization. Their method is more efficient than comparable kernel-based methods,
    and the collaborative representation-based classification makes their system relatively
    robust to small training sets. Yang et al. [[181](#bib.bib181)] use a two-channel
    CNN to jointly learn spectral and spatial features. Transfer learning is used
    when the number of training samples is limited, where low-level and mid-level
    features are transferred from other scenes. The network has a spectral CNN and
    a spatial CNN, and the results are combined in three FC layers. A softmax classifier
    produces the final class labels. Pan et al. [[175](#bib.bib175)] proposed the
    so called rolling guidance filter and vertex component analysis network (R-VCANet),
    which also attempts to solve the common problem of lack of HSI training data.
    The network combines spectral and spatial information. The rolling guidance filter
    is an edge-preserving filter used to remove noise and small details from imagery.
    The VCANet is a combination of vertex component analysis [[315](#bib.bib315)]
    , which is used to extract pure endmembers, and PCANet [[316](#bib.bib316)] .
    A parameter analysis of the number of training samples, rolling times, and the
    number and size of the convolution kernels. The system performs well even when
    the training ratio is only 4%. Lee et al. [[158](#bib.bib158)] designed a contextual
    deep fully convolutional DL network with fourteen layers that jointly exploits
    spatial and HSI spectral features. Variable size convolutional features are utilized
    to create a spectral-spatial feature map. A novel feature of the architecture
    is the initial layers uses both $[3\times 3\times B]$ convolutional masks to learn
    spatial features, and $[1\times 1\times B]$ for spectral features, where $B$ is
    the number of spectral bands. The system is trained with a very small number of
    training samples (200/class).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 一些HSI DL方法利用了光谱和空间信息。Ma等人[[169](#bib.bib169)]创建了一种HSI空间更新的深度自动编码器，该方法集成了空间信息。通过基于协作的表示分类器减少了小训练集的影响，并且通过基于图割的空间正则化减少了椒盐噪声。他们的方法比可比较的基于核的方法更为高效，而基于协作表示的分类使得他们的系统对小训练集相对稳健。Yang等人[[181](#bib.bib181)]使用了一个双通道CNN来共同学习光谱和空间特征。当训练样本数量有限时，采用了迁移学习，在这种情况下，从其他场景转移了低级和中级特征。网络包括一个光谱CNN和一个空间CNN，并且结果在三个FC层中组合。Softmax分类器生成最终的类标签。Pan等人[[175](#bib.bib175)]提出了所谓的滚动引导滤波器和顶点成分分析网络（R-VCANet），试图解决HSI训练数据缺乏的常见问题。该网络结合了光谱和空间信息。滚动引导滤波器是一种保持边缘的滤波器，用于去除图像中的噪声和小细节。VCANet是顶点成分分析[[315](#bib.bib315)]和PCANet[[316](#bib.bib316)]的组合。对于训练样本数量、滚动次数以及卷积核的数量和大小进行了参数分析。即使训练比例仅为4%，该系统也表现出色。Lee等人[[158](#bib.bib158)]设计了一个具有十四层的上下文深度全卷积DL网络，共同利用了空间和HSI光谱特征。利用可变尺寸的卷积特征创建了光谱-空间特征图。该架构的一个新特点是初始层同时使用了$[3\times
    3\times B]$的卷积掩模来学习空间特征，以及$[1\times 1\times B]$用于光谱特征，其中$B$是光谱波段数。该系统用极少量的训练样本（每类200个）进行了训练。
- en: '3D: In 3D analysis, there are several interesting DL approaches. Chen et al.
    [[317](#bib.bib317)] used a 3D CNN-based feature extraction model with regularization
    to extract effective spectral-spatial features from HSI. $L_{2}$ regularization
    and dropout are used to help prevent overfitting. In addition, a virtual enhanced
    method imputes training samples. Three different CNN architectures are examined:
    (1) a 1D using only spectral information, consisting of convolution, pooling,
    convolution, pooling, stacking and logistic regression; (2) a 2D CNN with spatial
    features, with 2D convolution, pooling, 2D convolution, pooling, stacking, and
    logistic regression; (3) 3D convolution (2D for spatial and third dimension is
    spectral); the organization is same as 2D case except with 3D convolution. The
    3D CNN achieves near-perfect classification on the data sets.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 3D：在 3D 分析中，有几种有趣的深度学习方法。Chen 等人 [[317](#bib.bib317)] 使用了基于 3D CNN 的特征提取模型，并通过正则化来提取
    HSI 的有效光谱-空间特征。使用 $L_{2}$ 正则化和 dropout 来帮助防止过拟合。此外，还通过虚拟增强方法来输入训练样本。研究了三种不同的 CNN
    架构：（1）仅使用光谱信息的 1D CNN，包括卷积、池化、卷积、池化、堆叠和逻辑回归；（2）具有空间特征的 2D CNN，包括 2D 卷积、池化、2D 卷积、池化、堆叠和逻辑回归；（3）3D
    卷积（空间维度为 2D，第三维度为光谱）；结构与 2D 情况相同，只是使用了 3D 卷积。3D CNN 在数据集上实现了近乎完美的分类。
- en: Chen et al. [[191](#bib.bib191)] propose a novel 3D CNN to extract the spectral-spatial
    features of HSI data, a deep 2D CNN to extract the elevation features of Light
    Detection and Ranging (LiDAR) data, and then a FC DNN to fuse the 2D and 3D CNN
    outputs. The HSI data are processed via two layers of 3D convolution followed
    by pooling. The LiDAR elevation data are processed via two layers of 2D convolution
    followed by pooling. The results are stacked and processed by a FC layer followed
    by a logistic regression layer.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Chen 等人 [[191](#bib.bib191)] 提出了一个新颖的 3D CNN，用于提取 HSI 数据的光谱-空间特征，一个深度 2D CNN
    用于提取光学雷达（LiDAR）数据的高程特征，然后使用全连接深度神经网络（FC DNN）融合 2D 和 3D CNN 的输出。HSI 数据经过两层 3D 卷积处理，然后进行池化。LiDAR
    高程数据经过两层 2D 卷积处理，然后进行池化。结果被堆叠并通过一个全连接层处理，最后经过一个逻辑回归层。
- en: Cheng et al. [[226](#bib.bib226)] developed a rotation-invariant CNN (RICNN),
    which is trained by optimizing a objective function with a regularization constraint
    that explicitly enforces the training feature representations before and after
    rotating to be mapped close to each other. New training samples are imputed by
    rotating the original samples by $k$ rotation angles. The system is based on AlexNet
    [[38](#bib.bib38)], which has five convolutional layers followed by three FC layers.
    The AlexNet architecture is modified by adding a rotation-invariant layer that
    used the output of AlexNet’s FC7 layer, and replacing the 1000-way softmax classification
    layer with a $(C+1)$-layer softmax classifier layer. AlexNet is pretrained, then
    fine tuned using the small number of HSI training samples. Haque et al. [[109](#bib.bib109)]
    developed a attention-based human body detector that leverages 4D spatio-temporal
    signatures and detects humans in the dark (depth images with no RGB content).
    Their DL system extracts voxels then encodes data using a CNN, followed by a LSTM.
    An action network gives the class label and a location network selects the next
    glimpse location. The process repeats at the next time step.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Cheng 等人 [[226](#bib.bib226)] 开发了一种旋转不变的卷积神经网络（RICNN），该网络通过优化目标函数来进行训练，目标函数具有正则化约束，明确地强制训练特征表示在旋转前后相互映射接近。通过对原始样本进行
    $k$ 个旋转角度的旋转来输入新的训练样本。该系统基于 AlexNet [[38](#bib.bib38)]，AlexNet 包含五个卷积层和三个全连接层。AlexNet
    的架构通过添加一个旋转不变层来进行修改，该层使用 AlexNet 的 FC7 层的输出，并将 1000 类的 softmax 分类层替换为一个 $(C+1)$
    层的 softmax 分类器层。AlexNet 先进行预训练，然后使用少量的 HSI 训练样本进行微调。Haque 等人 [[109](#bib.bib109)]
    开发了一种基于注意力的人的身体检测器，该检测器利用 4D 时空特征，在黑暗中（没有 RGB 内容的深度图像）检测人。其深度学习系统首先提取体素，然后使用卷积神经网络（CNN）对数据进行编码，接着是长短期记忆网络（LSTM）。一个动作网络提供类别标签，一个位置网络选择下一个瞥见位置。这个过程在下一个时间步重复进行。
- en: 'Traffic Sign Recognition: In the area of traffic sign recognition, a nice result
    came from Ciresan et al. [[119](#bib.bib119)] , who created a biologically plausible
    DNN is based on the feline visual cortex. The network is composed of multiple
    columns of DNNs, coded for parallel GPU speedup. The output of the columns is
    averaged. It outperforms humans by a factor of two in traffic sign recognition.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 交通标志识别：在交通标志识别领域，Ciresan等人[[119](#bib.bib119)]取得了一个很好的结果，他们创建了一个生物学上合理的DNN，基于猫的视觉皮层。该网络由多个DNN列组成，编码为并行GPU加速。列的输出被平均化。它在交通标志识别中比人类表现高出两倍。
- en: 'Satellite Imagery: In the area of satellite imagery analysis, Zhang et al.
    [[186](#bib.bib186)] propose a gradient-boosting random convolutional network
    (GBRCN) to classify very high resolution (VHR) satellite imagery. In GBRCN, a
    sum of functions (called boosts) are optimized. A modified multi-class softmax
    function is used for optimization, making the optimization task easier. SGD is
    used for optimization. Proposed future work was to utilize a variant of this method
    on HSI. Zhong et al. [[190](#bib.bib190)] use efficient small CNN kernels and
    a deep architecture to learn hierarchical spatial relationships in satellite imagery.
    A softmax classifier output class labels based on the CNN DL outputs. The CPU
    handles preprocessing (data splitting and normalization), while the GPU performs
    convolution, ReLU and pooling operations, and the the CPU handles dropout and
    softmax classification. Networks with one to three convolution layers are analyzed,
    with receptive fields of $10\times 10$ to $1000\times 1000$. SGD is used for optimization.
    A hyper-parameter analysis of the learning rate, momentum, training-to-test ratio,
    and number of kernels in the first convolutional layer were also performed.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 卫星图像：在卫星图像分析领域，Zhang等人[[186](#bib.bib186)]提出了一种梯度提升随机卷积网络（GBRCN），用于分类非常高分辨率（VHR）卫星图像。在GBRCN中，优化了多个函数（称为提升）。使用修改后的多类softmax函数进行优化，使优化任务更容易。使用SGD进行优化。未来工作的建议是将该方法的变体应用于HSI。Zhong等人[[190](#bib.bib190)]使用高效的小CNN内核和深层架构来学习卫星图像中的层次空间关系。softmax分类器根据CNN
    DL输出的类别标签。CPU负责预处理（数据拆分和归一化），而GPU执行卷积、ReLU和池化操作，CPU负责dropout和softmax分类。分析了具有一个到三个卷积层的网络，接收场为$10\times
    10$到$1000\times 1000$。使用SGD进行优化。还对学习率、动量、训练与测试比例以及第一个卷积层中的内核数量进行了超参数分析。
- en: 'SAR: In the area of SAR processing, De et al. [[288](#bib.bib288)] use DL to
    classify urban areas, even when rotated. Rotated urban target exhibit different
    scattering mechanisms, and the network learns the $\alpha$ and $\gamma$ parameters
    from the HH, VV and HV bands (H=Horizontal, V-Vertical polarization). Bentes et
    al. [[124](#bib.bib124)] use a constant false alarm rate (CFAR) processor on SAR
    data followed by $N$ AEs. The final layer associates the learned features with
    class labels. Geng et al. [[149](#bib.bib149)] used a eight-layer network with
    a convolutional layer to extract texture features from SAR imagery, a scale transformation
    layer to aggregate neighbor features, four Stacked AE (SAE) layers for feature
    optimization and classification, and a two-layer post processor. Gray level co-occurrence
    matrix and Gabor features are also extracted, and average pooling is used in layer
    two to mitigate noise.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: SAR：在SAR处理领域，De等人[[288](#bib.bib288)]使用深度学习（DL）对城市区域进行分类，即使在旋转的情况下也是如此。旋转的城市目标表现出不同的散射机制，网络从HH、VV和HV波段（H=水平，V=垂直极化）中学习$\alpha$和$\gamma$参数。Bentes等人[[124](#bib.bib124)]在SAR数据上使用恒定虚警率（CFAR）处理器，随后使用$N$个自编码器（AEs）。最终层将学习到的特征与类别标签关联。Geng等人[[149](#bib.bib149)]使用一个八层网络，其中包含一个卷积层来从SAR图像中提取纹理特征，一个尺度变换层来聚合邻域特征，四个堆叠自编码器（SAE）层进行特征优化和分类，以及一个两层后处理器。还提取了灰度共现矩阵和Gabor特征，并在第二层使用平均池化来减少噪声。
- en: 3.2 Transfer Learning
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 迁移学习
- en: Transfer learning utilizes training in one image (or domain) to enable better
    results in another image (or domain). If the learning crosses domains, then it
    may be possible to utilize lower to mid-level features learned from on domain
    in the other domain.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习利用在一个图像（或领域）上的训练来在另一个图像（或领域）上实现更好的结果。如果学习跨领域进行，则可以在另一个领域利用从一个领域学习的低到中级特征。
- en: Marmanis et al. [[259](#bib.bib259)] attacked the common problem in RS of limited
    training data by utilizing transfer learning across domains. They utilized a CNN
    pretrained on the ImageNet dataset, and extracted an initial set of representations
    from orthoimagery. These representations are then transferred to a CNN classifier.
    This paper developed a novel cross-domain feature fusion system. Their system
    has seven convolution layers followed by two long MLP layers, three convolution
    layers, two more large MLP layers, and finally a softmax classifier. They extract
    feature from the last layer, since the work of Donahue et al. [[318](#bib.bib318)]
    showed that most of the discriminative information is contained in the deeper
    layers. In addition, they take features from the large ($1\times 1\times 4096$)
    MLP, which is a very long vector output, and transform it into a 2D array followed
    by a large convolution ($91\times$91) mask layer. This is done because the large
    feature vector is a computational bottleneck, while the 2D data can very effectively
    be processed via a second CNN. This approach will work if the second CNN can learn
    (disentangle) the information in the 2D representation through its layers. This
    approach is very unique and it raises some interesting questions about alternate
    DL architectures. This approach was also successful because the features learned
    by the original CNN were effective in the new image domain.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: Marmanis 等人 [[259](#bib.bib259)] 通过跨领域迁移学习解决了遥感领域中有限训练数据的常见问题。他们利用在 ImageNet
    数据集上预训练的 CNN，并从正射影像中提取初始的表示。这些表示然后被转移到 CNN 分类器中。本文开发了一个新颖的跨领域特征融合系统。该系统有七个卷积层，接着是两个长的
    MLP 层，三个卷积层，两个更大的 MLP 层，最后是一个 softmax 分类器。他们从最后一层提取特征，因为 Donahue 等人 [[318](#bib.bib318)]
    的研究表明，大部分判别信息存在于更深的层次。此外，他们从大型 ($1\times 1\times 4096$) MLP 中提取特征，该 MLP 是一个非常长的向量输出，并将其转换为
    2D 数组，随后通过一个大卷积 ($91\times$91) 掩膜层进行处理。这么做是因为大型特征向量是计算瓶颈，而 2D 数据可以通过第二个 CNN 高效处理。如果第二个
    CNN 能够通过其层次学习（解开）2D 表示中的信息，这种方法将有效。这种方法非常独特，并提出了一些关于替代深度学习架构的有趣问题。这种方法也取得了成功，因为原始
    CNN 学到的特征在新的图像领域中表现有效。
- en: Penatti et al. [[219](#bib.bib219)] asked if deep features generalize from everyday
    objects to remote sensing and aerial scene domains? A CNN was trained for recognizing
    everyday objects using ImageNet. The CNNs analyzed performed well, in areas well
    outside of their training. In a similar vein, Salberg [[121](#bib.bib121)] use
    CNNs pretrained on ImageNet to detect seal pups in aerial RS imagery. A linear
    SVM was used for classification. The system was able to detect seals with high
    accuracy.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Penatti 等人 [[219](#bib.bib219)] 询问深度特征是否能从日常物体泛化到遥感和空中场景领域？一个 CNN 被训练用于识别日常物体，使用的是
    ImageNet。CNN 的分析表现良好，甚至在训练之外的区域也表现出色。类似地，Salberg [[121](#bib.bib121)] 使用在 ImageNet
    上预训练的 CNN 来检测空中遥感图像中的海豹幼崽。使用了线性 SVM 进行分类。该系统能够高准确度地检测到海豹。
- en: 3.3 3D Processing and Depth Estimation
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 3D 处理与深度估计
- en: Cadena et al. [[107](#bib.bib107)] utilized multi-modal AEs for RGB imagery,
    depth images, and semantic labels. Through the AE, the system learns a shared
    representation of the distinct inputs. The AEs first denoise the given inputs.
    Depth information is processed as inverse depth (so sky can be handled). Three
    different architectures are investigated. Their system was able to make a sparse
    depth map more dense by fusing RGB data.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Cadena 等人 [[107](#bib.bib107)] 利用多模态自编码器（AE）处理 RGB 图像、深度图像和语义标签。通过自编码器，系统学习了不同输入的共享表示。自编码器首先对给定的输入进行去噪处理。深度信息被处理为反向深度（以便可以处理天空区域）。研究了三种不同的架构。他们的系统能够通过融合
    RGB 数据使稀疏的深度图变得更密集。
- en: Feng et al. [[108](#bib.bib108)] developed a content-based 3D shape retrieval
    system. The system uses a low-cost 3D sensor (e.g. Kinect or Realsense) and a
    database of 3D objects. An ensemble of AEs learns compressed representations of
    the 3D objects, and the AE act as probabilistic models which output a likelihood
    score. A domain adaptation layer uses weakly supervised learning to learn cross-domain
    representations (noisy imagery and 3D computer aided design (CAD)). The system
    uses the AE encoded objects to reconstruct the objects, and then additional layers
    rank the outputs based on similarity scores. Segaghat et al. [[114](#bib.bib114)]
    use a 3D voxel net that predicts the object pose as well as its class label, since
    3D objects can appear very differently based on their poses. The results were
    tested on LiDAR data, CAD models, and RGB plus depth (RGBD) imagery. Finally,
    Zelener et al. [[319](#bib.bib319)] labels missing 3D LiDAR points to enable the
    CNN to have higher accuracy. A major contribution of this method is creating normalized
    patches of low-level features from the 3D LiDAR point cloud. The LiDAR data is
    divided into multiple scan lines, and positive and negative samples. Patches are
    randomly selected for training. A sliding block scheme is used to classify the
    entire image.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: Feng 等人 [[108](#bib.bib108)] 开发了一个基于内容的 3D 形状检索系统。该系统使用低成本的 3D 传感器（如 Kinect
    或 Realsense）和 3D 对象数据库。一个自编码器（AE）集合学习 3D 对象的压缩表示，自编码器作为概率模型输出可能性得分。一个领域适应层使用弱监督学习来学习跨领域表示（噪声图像和
    3D 计算机辅助设计（CAD））。该系统使用自编码器编码的对象来重建这些对象，然后额外的层根据相似性得分对输出进行排名。Segaghat 等人 [[114](#bib.bib114)]
    使用一个 3D 体素网络来预测对象的姿态以及其类别标签，因为 3D 对象在不同姿态下可能会显得非常不同。结果在 LiDAR 数据、CAD 模型和 RGB 加深度（RGBD）图像上进行了测试。最后，Zelener
    等人 [[319](#bib.bib319)] 对缺失的 3D LiDAR 点进行标记，以提高 CNN 的准确性。该方法的主要贡献是从 3D LiDAR 点云中创建归一化的低级特征补丁。LiDAR
    数据被分割成多个扫描线和正负样本。补丁被随机选择用于训练。使用滑动块方案来对整个图像进行分类。
- en: 3.4 Segmentation
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 分割
- en: Segmentation means to process imagery and divide it into regions (segments)
    based on the content. Basaeed et al. [[269](#bib.bib269)] use a committee of CNNs
    that perform multi-scale analysis on each band to estimate region boundary confidence
    maps, which are then inter-fused to produce an overall confidence map. A morphological
    scheme integrates these maps into a hierarchical segmentation map for the satellite
    imagery.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 分割指的是处理图像并根据内容将其划分为区域（段）。Basaeed 等人 [[269](#bib.bib269)] 使用一个 CNN 委员会对每个波段进行多尺度分析，以估计区域边界置信度图，然后将这些图进行融合以生成总体置信度图。一个形态学方案将这些图整合为一个分层分割图用于卫星图像。
- en: Couprie et al. [[254](#bib.bib254)] utilized a multi-scale CNN to learn features
    directly from RGBD imagery. The image RGB channels and the depth image are transformed
    through a Laplacian pyramid approach, where each scale is fed to a 3-stage convolutional
    network that create feature maps. The feature maps of all scales are concatenated
    (the coarser-scale feature maps are upsampled to match the size of the finest-scale
    map). A parallel segmentation of the image into superpixels is computed to exploit
    the natural contours of the image. The final labeling is obtained by the aggregation
    of the classifier predictions into the superpixels.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Couprie 等人 [[254](#bib.bib254)] 利用多尺度 CNN 直接从 RGBD 图像中学习特征。图像的 RGB 通道和深度图像通过拉普拉斯金字塔方法进行转换，每个尺度的图像被送入一个
    3 阶卷积网络以创建特征图。所有尺度的特征图被连接在一起（较粗尺度的特征图被上采样以匹配最细尺度的特征图大小）。图像的平行超像素分割被计算以利用图像的自然轮廓。最终的标记通过将分类器预测聚合到超像素中来获得。
- en: In his Master’s thesis, Kaiser [[257](#bib.bib257)] (1) generated new ground
    truth datasets for three different cities consisting of VHR aerial images with
    ground sampling distance on the order of centimeters and corresponding pixel-wise
    object labels, (2) developed FC networks (FCNs) were used to perform pixel-dense
    semantic segmentation, (3) created two modifications of the FCN architecture were
    found that gave performance improvements, and (4) utilized transfer learning was
    shown using FCN model was trained on huge and diverse ground truth data of the
    three cities, which achieved good semantic segmentations of areas not used for
    training.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在他的硕士论文中，Kaiser [[257](#bib.bib257)] (1) 为三个不同城市生成了新的真实数据集，这些数据集包括地面采样距离为厘米级别的高分辨率航拍图像及其对应的像素级物体标签；(2)
    开发了全卷积网络（FCNs），用于执行像素密集的语义分割；(3) 创造了两种FCN架构的修改，发现这些修改提高了性能；(4) 利用迁移学习，通过FCN模型在三个城市的庞大且多样化的真实数据上进行训练，展示了迁移学习的效果，这实现了对未用于训练区域的良好语义分割。
- en: Längkvist et al. [[157](#bib.bib157)] applied a CNN to orthorectified multispectral
    imagery (MSI) and a digital surface model of a small city for a full, fast and
    accurate per-pixel classification. The predicted low-level pixel classes are then
    used to improve the high-level segmentation. Various design choices of the CNN
    architecture are evaluated and analyzed.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Längkvist等人 [[157](#bib.bib157)] 将卷积神经网络（CNN）应用于正射校正的多光谱影像（MSI）和小城市的数字表面模型，实现了全面、快速且准确的每像素分类。预测的低级像素类别随后用于改善高级分割。评估和分析了CNN架构的各种设计选择。
- en: 3.5 Object Detection and tracking
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 物体检测与跟踪
- en: Object detection and tracking is important in many RS applications. It requires
    understanding at a higher level than just at the pixel-level. Tracking then takes
    the process one step further and estimates the location of the object over time.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 物体检测和跟踪在许多遥感应用中都很重要。它需要比像素级别更高层次的理解。跟踪进一步推动了这一过程，并估计了物体随时间的位置信息。
- en: Diao et al. [[228](#bib.bib228)] propose a pixel-wise DBN for object recognition.
    A sparse RBM is trained in an unsupervised manner. Several layers of RBM are stacked
    to generate a DBN. For fine-tuning, a supervised layer is attached to the top
    of the DBN and the network is trained using BP with a sparse penalty constraint.
    Ondruska et al. [[234](#bib.bib234)] used RNN to track multiple objects from 2D
    laser data. This system uses no hand-coded plant or sensor models (these are required
    in Kalman filters). Their system uses an end-to-end RNN approach that maps raw
    sensor data to a hidden sensor space. The system then predicts the unoccluded
    state from the sensor space data. The system learns directly from the data and
    does not require a plant or sensor model.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: Diao等人 [[228](#bib.bib228)] 提出了用于物体识别的像素级DBN。稀疏的限制玻尔兹曼机（RBM）以无监督的方式进行训练。通过堆叠多个RBM层生成DBN。为了细化，DBN的顶部附加了一层有监督的层，并使用带有稀疏惩罚约束的BP进行训练。Ondruska等人
    [[234](#bib.bib234)] 使用递归神经网络（RNN）跟踪来自2D激光数据的多个物体。该系统不使用手工编写的植物或传感器模型（这些模型在卡尔曼滤波器中是必需的）。他们的系统使用端到端的RNN方法，将原始传感器数据映射到隐藏的传感器空间。然后，系统根据传感器空间数据预测未遮挡的状态。该系统直接从数据中学习，不需要植物或传感器模型。
- en: Schwegmann et al. [[273](#bib.bib273)] use a very deep Highway Network for ship
    discrimination in SAR imagery, and a three-class SAR dataset is also provided.
    Deep networks of 2, 20, 50 and 100 layers were tested, and the 20 layer network
    had the best performance. Tang et al. [[274](#bib.bib274)] utilized a hybrid approach
    in both feature extraction and machine learning. For feature extraction, the Discrete
    Wavelet Transform (DWT) LL, LH, HL and HH (L=Low Frequency, H = High Frequency)
    features from the JPEG2000 CDF9/7 encoder were utilized. The LL features were
    inputs to a Stacked DAE (SDAE). The high frequency DWT subbands LH, HL and HH
    are inputs to a second SDAE. Thus the hand-coded wavelets provide features, while
    the two SDAEs learn features from the wavelet data. After initial segmentation,
    the segmentation area, major-to-minor axis ratio and compactness, which are classical
    machine learning features, are also used to reduce false positives. The training
    data are normalized to zero mean and unity variance, and the wavelet features
    are normalized to the $[0,1]$ range. The training batches have different class
    mixtures, and 20% of inputs are dropped to the SDAEs and there is a 50% dropout
    in the hidden units. The extreme learning machine is used to fuse the low-frequency
    and high-frequency subbands. An online-sequential extreme learning machine, which
    is a feedforward shallow NN, is used for classification.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Schwegmann 等人 [[273](#bib.bib273)] 使用了一个非常深的 Highway Network 来对 SAR 图像中的船只进行分类，并提供了一个三类
    SAR 数据集。测试了 2、20、50 和 100 层的深度网络，结果发现 20 层网络表现最佳。Tang 等人 [[274](#bib.bib274)]
    在特征提取和机器学习中采用了混合方法。在特征提取方面，利用了 JPEG2000 CDF9/7 编码器的离散小波变换（DWT）LL、LH、HL 和 HH（L=低频，H=高频）特征。LL
    特征作为输入进入一个 Stacked DAE（SDAE）。高频 DWT 子带 LH、HL 和 HH 作为输入进入第二个 SDAE。因此，手工编码的小波提供了特征，而两个
    SDAE 从小波数据中学习特征。初步分割后，还使用经典的机器学习特征，如分割区域、长轴与短轴比和紧凑度，来减少假阳性。训练数据被标准化为零均值和单位方差，小波特征被标准化到
    $[0,1]$ 范围内。训练批次具有不同的类别混合，20% 的输入被丢弃到 SDAE 中，隐藏单元中有 50% 的 dropout。极限学习机用于融合低频和高频子带。用于分类的在线序列极限学习机是一个前馈浅层神经网络。
- en: Two of the most interesting results were developed to handle incomplete training
    data, and how object detectors emerge from CNN scene classifiers. Mnih et al.
    [[246](#bib.bib246)] developed two robust loss functions to deal with incomplete
    training labeling and misregistration (location of object in map) is inaccurate.
    A NN is used to model pixel distributions (assuming they are independent). Optimization
    is performed using expectation maximization. Zhou et al. [[233](#bib.bib233)]
    show that object detectors emerge from CNNs trained to perform scene classification.
    They demonstrated that the same CNN can perform both scene recognition and object
    localization in a single forward pass, without having to explicitly learn the
    notion of objects. Images had their edges removed such that each edge removal
    produces the smallest change to the classification discriminant function. This
    process is repeated until the image is misclassified. The final product of that
    analysis is a set of simplified images which still have high classification accuracies.
    For instance, in bedroom scenes, 87% of these contained a bed. To estimate the
    empirical receptive field (RF), the images were replicated and random $11\times
    11$ occluded patches were overlaid. Each occluded image is input to the trained
    DL network and the activation function changes are observed; a large discrepancy
    indicates the patch was important to the classification task. From this analysis,
    a discrepancy map is built for each image. As the layers get deeper in the network,
    the RF size gradually increases and the activation regions are semantically meaningful.
    Finally, the objects that emerging in one specific layer indicated that the network
    was learning object categories (dogs, humans, etc.) This work indicates there
    is still extensive research to be performed in this area.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 两个最有趣的结果是处理不完整训练数据的方法，以及物体检测器如何从CNN场景分类器中出现。Mnih等人[[246](#bib.bib246)]开发了两个鲁棒的损失函数来处理不完整的训练标记和不准确的误配（地图上物体的位置）。使用神经网络（NN）来建模像素分布（假设它们是独立的）。优化是通过期望最大化进行的。Zhou等人[[233](#bib.bib233)]表明，物体检测器从训练有素的CNN场景分类器中出现。他们展示了同一个CNN可以在单次前向传递中同时进行场景识别和物体定位，而无需明确地学习物体的概念。图像的边缘被去除，使得每次边缘去除对分类判别函数的变化最小。这个过程重复进行，直到图像被误分类。该分析的最终产物是一组简化的图像，这些图像仍然具有高分类准确率。例如，在卧室场景中，87%的图像包含一张床。为了估计经验接收场（RF），图像被复制，随机的$11\times
    11$遮挡块被叠加。每个遮挡图像输入训练好的DL网络，观察激活函数的变化；较大的差异表明该块对分类任务很重要。从这个分析中，为每个图像建立了一个差异图。随着网络层的加深，RF的大小逐渐增加，激活区域具有语义意义。最后，出现在特定层中的对象表明网络正在学习对象类别（如狗、人等）。这项工作表明，该领域仍有广泛的研究要进行。
- en: 3.6 Super-resolution
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.6 超分辨率
- en: Super-resolution analysis attempts to infer sub-pixel information from the data.
    Dong et al. [[277](#bib.bib277)] utilized a DL network that learns a mapping between
    the low and high-resolution images. The CNN takes the low-resolution (LR) image
    as input and outputs the high-resolution (HR) image. In this method, all layers
    of the DL system are jointly optimized. In a typical super-resolution pipeline
    with sparse dictionary learning, image patches are densely sampled from the image
    and encoded in a sparse dictionary. The DL system does not explicitly learn the
    sparse dictionaries or manifolds for modeling the image patches. The proposed
    system provides better results than traditional methods and has a fast on-line
    implementation. The results improve when more data is available or when deeper
    networks are utilized.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 超分辨率分析试图从数据中推断子像素信息。Dong等人[[277](#bib.bib277)]利用了一种深度学习（DL）网络，该网络学习低分辨率和高分辨率图像之间的映射。CNN以低分辨率（LR）图像作为输入，输出高分辨率（HR）图像。在这种方法中，DL系统的所有层都是联合优化的。在典型的超分辨率流程中，通过稀疏字典学习，从图像中密集地采样图像块，并在稀疏字典中进行编码。DL系统没有明确地学习用于建模图像块的稀疏字典或流形。提出的系统提供了比传统方法更好的结果，并具有快速的在线实现。当有更多数据可用或使用更深的网络时，结果会得到改善。
- en: 3.7 Weather Forecasting
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.7 天气预报
- en: Weather forecasting attempts to use physical laws combined with atmospheric
    measurements to predict weather patterns, precipitation, etc. The weather effects
    virtually every person on the planet, so it is natural that there are several
    RS papers utilizing DL to improve weather forecasting. DL ability to learn from
    data and understand highly-nonlinear behavior shows much promise in this area
    of RS.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 天气预报试图利用物理定律结合大气测量来预测天气模式、降水等。天气几乎影响地球上的每一个人，因此自然会有几个RS论文利用DL来改进天气预报。DL从数据中学习并理解高度非线性行为的能力在这一领域展示了很大的潜力。
- en: Chen et al. [[195](#bib.bib195)] utilize DBNs for drought prediction. A three-step
    process (1) computes the Standardized Precipitation Index (SPI), which is effectively
    a probability of precipitation, (2) normalizes the SPI, and (3) determines the
    optimal network architecture (number of hidden layers) experimentally. Firth [[311](#bib.bib311)]
    introduced a Differential Integration Time Step network composed of a traditional
    NN and a weighted summation layer to produce weather predictions. The NN computes
    the derivatives of the inputs. These elemental building blocks are used to model
    the various equations that govern weather. Using time series data, forecast convolutions
    feed time derivative networks which perform time integration. The output images
    are then fed back to the inputs at the next time step. The recurrent deep network
    can be unrolled. The network is trained using backpropagation. A pipelined, parallel
    version is also developed for efficient computation. The model outperformed standard
    models. The model is efficient and works on a regional level, versus previous
    models which are constrained to local levels.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 陈等人[[195](#bib.bib195)]利用DBNs进行干旱预测。该过程分为三个步骤：（1）计算标准化降水指数（SPI），这实际上是降水的概率；（2）对SPI进行归一化；（3）通过实验确定最佳网络架构（隐藏层数量）。Firth
    [[311](#bib.bib311)]提出了一种由传统NN和加权求和层组成的差分积分时间步网络，用于生成天气预测。NN计算输入的导数。这些基本构建块用于建模支配天气的各种方程。利用时间序列数据，预测卷积喂入时间导数网络，这些网络执行时间积分。输出图像随后被反馈到下一个时间步的输入。递归深度网络可以展开。该网络使用反向传播进行训练。还开发了一种流水线并行版本，以提高计算效率。该模型优于标准模型。该模型高效且适用于区域级别，而以前的模型仅限于局部级别。
- en: 'Kovordanyi et al. [[312](#bib.bib312)] utilized NNs in cyclone track forecasting.
    The system uses a multi-layer NN designed to mimic portions of the human visual
    system to analyze National Oceanic and Atmospheric Administration’s Advanced Very
    High Resolution Radiometer (NOAA AVHRR) imagery. At the first network level, shape
    recognition focuses on narrow spatial regions, e.g. detecting small cloud segments.
    Regions in the image can be processed in parallel using a matrix feature detector
    architecture. Rotational variations, which are paramount in cyclone analysis,
    are incorporated into the architecture. Later stages combine previous activations
    to learn more complex and larger structures from the imagery. The output at the
    end of the processing system is a directional estimator of cyclone motion. The
    simulation tool Leabra++ ([http://ccnbook.colorado.edu/](http://ccnbook.colorado.edu/))
    was used. This tool is designed for simulating brain-like artificial NNs (ANNs).
    There are a total of five layers in the system: an input layer, three processing
    layers, and an output layer. During training, images were divided into smaller
    blocks and rotated, shifted, and enlarged. During training, the network was first
    given inputs and allowed to settle to steady state. Weak activations were suppressed,
    with at most $k$ nodes were allowed to stay active. Then the inputs and correct
    outputs were presented to the network and the weights are all zeroed. The learned
    weights are a combination of the two schemes. Conditional PCA and contrastive
    Hebbian learning were used to train the network. The system was very effective
    if the Cyclone’s center varied about 6% or less of the original image size, and
    less effective if there was more variation.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Kovordanyi 等人[[312](#bib.bib312)]在气旋路径预测中利用了神经网络。该系统使用多层神经网络，设计用于模拟部分人类视觉系统，分析美国国家海洋和大气管理局（NOAA）高分辨率辐射计（AVHRR）图像。在第一网络级别上，形状识别侧重于狭窄的空间区域，例如检测小云片段。图像中的区域可以使用矩阵特征检测器架构并行处理。在体现旋转变化的架构中，旋转变化被引入。后续阶段结合先前的激活来学习更复杂和更大的结构。处理系统末端的输出是气旋运动的方向估计器。使用仿真工具Leabra++
    ([http://ccnbook.colorado.edu/](http://ccnbook.colorado.edu/))。该工具设计用于模拟类似大脑的人工神经网络（ANNs）。系统共有五层：一个输入层，三个处理层和一个输出层。在训练期间，图像被分成较小的块并进行旋转、移动和放大。在训练期间，网络首先接收输入并稳定到稳定状态。弱激活被抑制，最多允许$k$个节点保持活动。然后将输入和正确的输出呈现给网络，权重全部归零。学到的权重是两种方案的结合。条件PCA和对比性Hebbian学习用于训练网络。如果气旋中心变化约为原始图像尺寸的6%或更少，该系统效果非常好，如果变化更大，则效果较差。
- en: Shi et al. [[198](#bib.bib198)] extended the FC LSTM (FC-LSTM) network that
    they call ConvLSTM, which has convolutional structures in the input-to-state and
    state-to-state transitions. The application is precipitation nowcasting, which
    takes weather data and predicts immediate future precipitation. ConvLSTM used
    3D tensors whose last two dimensions are spatial to encode spatial data into the
    system. An encoding LSTM compresses the input sequence into a latent tensor, while
    the forecasting LSTM provides the predictions.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Shi 等人[[198](#bib.bib198)]扩展了他们称之为ConvLSTM的FC LSTM（FC-LSTM）网络，该网络在输入到状态和状态到状态的转换中具有卷积结构。应用于现在天气预报，该系统使用天气数据预测即将发生的降水。ConvLSTM使用3D张量，其最后两个维度是空间维度，将空间数据编码到系统中。编码的LSTM将输入序列压缩为潜在张量，而预测的LSTM提供预测。
- en: 3.8 Automated object and target detection and identification
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8 自动目标和目标检测与识别
- en: Automated object and atutomated target detection and identification is an important
    RS task for military applications, border security, intrusion detection, advanced
    driver assistance systems, etc. Both automated target detection and identification
    are hard tasks, because usually there are very few training samples for the target
    (but almost all samples of the training data are available as non-target), and
    often there are large variations in aspect angles, lighting, etc.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 自动对象和自动目标检测与识别是军事应用、边境安全、入侵检测、高级驾驶员辅助系统等遥感任务中的重要任务。自动目标检测和识别都是艰巨的任务，因为通常目标的训练样本很少（但几乎所有训练数据样本都可以作为非目标），而且往往在方位角、光照等方面存在很大的变化。
- en: Ghazi et al. [[238](#bib.bib238)] used DL to identify plants in photographs
    using transfer parameter optimization. The main contributions of this work are
    (1) a state-of-the-art plant detection transfer learning system, and (2) an extensive
    study of fine-tuning, iteration size, batch size and data augmentation (rotation,
    translation, reflection, and scaling). It was found that transfer learning (and
    fine tuning) provided better results than training from scratch. Also, if training
    from scratch, smaller networks performed better, probably due to smaller training
    data. The authors suggest using smaller networks in these cases. Performance was
    also directly related to the network depth. By varying the iteration sizes, it
    is seen that the validation accuracies rise quickly initially, then grow slowly.
    The networks studied are all resilient to overfitting. The batch sizes were varied,
    and larger batch sizes resulted in higher performance at the expense of longer
    training times. Data augmentation also had a significant effect on performance.
    The number of iterations had the most effect on the output, followed by the number
    of patches, and the batch size had the least significant effect. There were significant
    differences in training times of the systems. Li et al. [[122](#bib.bib122)] used
    DL for anomaly detection. In this work, a reference image with pixel pairs (a
    pair of samples from the same class, and a pair from different classes) is required.
    By using transfer learning, the system is utilized on another image from the same
    sensor. Using vicinal pixels, the algorithm recognizes central pixels as anomalies.
    A 16-level network contains layers of convolution followed by ReLUs. A fully-connected
    layer then provides output labels.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Ghazi 等人[[238](#bib.bib238)] 使用深度学习（DL）通过传递参数优化来识别照片中的植物。这项工作的主要贡献有：（1）一种最先进的植物检测迁移学习系统，以及（2）对微调、迭代大小、批量大小和数据增强（旋转、平移、反射和缩放）的广泛研究。研究发现，迁移学习（及微调）比从头开始训练提供了更好的结果。此外，如果从头开始训练，较小的网络表现更好，这可能是由于训练数据较少。作者建议在这些情况下使用较小的网络。性能还直接与网络的深度相关。通过改变迭代大小，发现验证准确率最初快速上升，然后缓慢增长。研究中的网络都对过拟合具有较强的抗性。批量大小有所不同，较大的批量大小导致性能更高，但训练时间更长。数据增强对性能也有显著影响。迭代次数对输出影响最大，其次是补丁数量，批量大小的影响最小。系统的训练时间差异显著。Li
    等人[[122](#bib.bib122)] 使用深度学习进行异常检测。在这项工作中，需要一个带有像素对的参考图像（同类样本对和不同类别样本对）。通过使用迁移学习，该系统可以在来自同一传感器的另一张图像上进行应用。通过使用近邻像素，算法将中心像素识别为异常。一个16层的网络包含卷积层和ReLU层，然后由一个全连接层提供输出标签。
- en: 3.9 Image Enhancement
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.9 图像增强
- en: Image enhancement includes many areas such as pansharpening, denoising, image
    registration, etc. Image enhancement is often performed prior to feature extraction
    or other image processing steps. Huang et al. [[236](#bib.bib236)] utilize a modified
    sparse denoising AE (SPDAE), denoted MSDA, which uses the SPDAE to represent the
    relationship between the HR image patches as clean data to the lower spatial resolution,
    high spectral resolution MSI image as corrupted data. The reconstruction error
    drives the cost function and layer-by-layer training is utilized. Quan et al.
    [[206](#bib.bib206)] use DL for SAR image registration, which is in general a
    harder problem than RGB image registration due to high speckle noise. The RBM
    learns features useful for image registration, and the random sample consensus
    (RANSAC) algorithm is run multiple times to reduce outlier points.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图像增强包括许多领域，如全色融合、去噪、图像配准等。图像增强通常在特征提取或其他图像处理步骤之前进行。Huang 等人[[236](#bib.bib236)]
    利用修改后的稀疏去噪自编码器（SPDAE），表示为MSDA，该方法使用SPDAE将HR图像补丁之间的关系表示为干净数据，而较低空间分辨率、高光谱分辨率的MSI图像作为被损坏数据。重建误差驱动成本函数，并采用逐层训练。Quan
    等人[[206](#bib.bib206)] 使用深度学习进行SAR图像配准，这通常比RGB图像配准更难，因为存在高斑点噪声。RBM学习对图像配准有用的特征，随机样本一致性（RANSAC）算法被多次运行以减少离群点。
- en: Wei et al. [[204](#bib.bib204)] applied a five-layer DL network to perform image
    quality improvement. In their approach, degraded images are modeled as downsampled
    images that are degraded by a blurring function and additive noise. Instead of
    trying to estimate the inverse function, a DL network performs feature extraction
    at layer 1, then the second layer learns a matrix of kernels and biases to perform
    non-linear operations to layer 1 outputs. Layers 3 and 4 repeat the operations
    of layers 1 and 2\. Finally, an output layer reconstructs the enhanced imagery.
    They demonstrated results with non-uniform haze removal and random amounts of
    Gaussian noise. Zhang et al. [[205](#bib.bib205)] applied DL to enhance thermal
    imagery, based on first compensating for the camera transfer function (small-scale
    and large-scale nonlinearities), and then super-resolution target signature enhancement
    via DL. Patches are extracted from low-resolution imagery, and the DL learns feature
    maps from this imagery. A nonlinear mapping of these feature maps to a HR image
    are then learned. SGD is utilized to train the network.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: Wei 等人 [[204](#bib.bib204)] 应用了一个五层深度学习网络来进行图像质量改善。在他们的方法中，退化图像被建模为经过模糊函数和加性噪声退化的下采样图像。深度学习网络并不尝试估计逆函数，而是在第一层进行特征提取，然后第二层学习一个核和偏置矩阵以对第一层输出执行非线性操作。第三层和第四层重复第一层和第二层的操作。最后，一个输出层重建增强后的图像。他们展示了在非均匀雾霾去除和随机高斯噪声处理方面的结果。Zhang
    等人 [[205](#bib.bib205)] 采用深度学习增强热成像图像，首先补偿相机传递函数（小尺度和大尺度非线性），然后通过深度学习进行超分辨率目标特征增强。从低分辨率图像中提取补丁，深度学习网络从这些图像中学习特征图。然后学习这些特征图到高分辨率图像的非线性映射。使用
    SGD 训练网络。
- en: 3.10 Change Detection
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.10 变化检测
- en: Change detection is the process of utilizing two registered RS images taken
    at different times and detecting the changes, which can be due to natural phenomenon
    such as drought or flooding, or due to man-made phenomenon, such as adding a new
    road or tearing down an old building. We note that there is a paucity of DL research
    into change detection. Pacifici et al. [[137](#bib.bib137)] used DL for change
    detection in VHR satellite imagery. The DL system exploits the multispectral and
    multitemporal nature of the imagery. Saturation is avoided by normalizing data
    to $[-1,1]$ range. To mitigate illumination changes, band ratios such as blue/green
    are utilized. These images are classified according to (1) man-made surfaces,
    (2) green vegetation, (3) bare soil and dry vegetation, and (4) water. Each image
    undergoes a classification and a multitemporal operator creates a change mask.
    The two classification maps and the change mask are fused using an AND operator.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 变化检测是利用在不同时间拍摄的两幅注册的遥感图像来检测变化的过程，这些变化可能是由于自然现象如干旱或洪水，也可能是由于人为现象，如新增道路或拆除旧建筑。我们注意到，关于变化检测的深度学习研究相对较少。Pacifici
    等人 [[137](#bib.bib137)] 使用深度学习对高分辨率卫星图像进行变化检测。深度学习系统利用了图像的多光谱和多时间特性。通过将数据标准化到
    $[-1,1]$ 范围来避免饱和。为了缓解光照变化，使用了如蓝色/绿色等波段比。这些图像根据（1）人工表面，（2）绿色植被，（3）裸土和干燥植被，以及（4）水进行分类。每幅图像经过分类处理，随后一个多时相操作符创建一个变化掩膜。这两幅分类图和变化掩膜通过
    AND 操作符融合在一起。
- en: 3.11 Semantic Labeling
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.11 语义标注
- en: Semantic labeling attempts to label scenes or objects semantically, such as
    “there is a truck next to the tree”. Sherrah et al. [[263](#bib.bib263)] utilized
    the recent development of FC NNs (FC-CNNs), which were developed by Long et al.
    [[320](#bib.bib320)]. The FC-CNN is applied to remote sensed VHR imagery. In their
    network, there is no downsampling. The system labels images semantically pixel-by-pixel.
    Xie et al. [[293](#bib.bib293)] used transfer learning to avoid training issues
    due to scarce training data, transfer learning is utilized. A FC CNN trains in
    daytime imagery and predicts nighttime lights. The system also can infer poverty
    data from the night lights, as well as delineating man-made structures such as
    roads, buildings and farmlands. The CNN was trained on ImageNet and uses the NOAA
    nighttime remote sensing satellite imagery. Poverty data was derived from a living
    standards measurement survey in Uganda. Mini-batch gradient descent with momentum,
    random mirroring for data augmentation, and 50% dropout was used to help avoid
    overfitting. The transfer learning approach gave higher performance in accuracy,
    F1 scores, precision and area under the curve.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 语义标记试图对场景或对象进行语义标记，例如“卡车在树旁边”。Sherrah 等人 [[263](#bib.bib263)] 利用了 Long 等人 [[320](#bib.bib320)]
    开发的最新 FC NNs（全卷积神经网络，FC-CNNs）。FC-CNNs 应用于遥感的超高分辨率图像。在他们的网络中，没有下采样。系统逐像素地对图像进行语义标记。Xie
    等人 [[293](#bib.bib293)] 利用迁移学习来避免由于训练数据稀缺而引起的训练问题。FC CNN 在白天图像训练并预测夜间光亮度。系统还可以从夜间光亮度推断贫困数据，以及描绘人造结构如道路、建筑物和农田。CNN
    在 ImageNet 上训练，并使用 NOAA 夜间遥感卫星图像。贫困数据来源于乌干达的生活水平调查。采用了带动量的小批量梯度下降、随机镜像数据增强和 50%
    的 dropout 以帮助避免过拟合。迁移学习方法在准确性、F1 分数、精确度和曲线下面积上表现更好。
- en: 3.12 Dimensionality reduction
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.12 降维
- en: HSI are inherently highly dimensional, and often contain highly correlated data.
    Dimensionality reduction can significantly improve results in HSI processing.
    Ran et al. [[192](#bib.bib192)] split the spectrum into groups based on correlation,
    then apply $m$ CNNs in parallel, one for each band group. The CNN output are concatenated
    and then classified via a two-layer FC-CNN. Zabalza et al. [[193](#bib.bib193)]
    used segmented SAEs are utilized for dimensionality reduction. The spectral data
    are segmented into $k$ regions, each of which has a SAE to reduce dimensionality.
    Then the features are concatenated into a reduced profile vector. The segmented
    regions are determine by using the correlation matrix of the spectrum. In Ball
    et al. [[321](#bib.bib321)] , it was shown that band selection is task and data
    dependent, and often better results can be found by fusing similarity measures
    versus using correlation, so both of these methods could be improved using similar
    approaches. Dimensionality reduction is an important processing step in many classification
    algorithms [[322](#bib.bib322), [323](#bib.bib323)] , pixel unmixing [[31](#bib.bib31),
    [30](#bib.bib30), [324](#bib.bib324), [325](#bib.bib325), [326](#bib.bib326),
    [327](#bib.bib327), [328](#bib.bib328)] , etc.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: HSI 本质上具有高维特性，并且通常包含高度相关的数据。降维可以显著改善 HSI 处理结果。Ran 等人 [[192](#bib.bib192)] 根据相关性将光谱分成组，然后并行应用
    $m$ 个 CNN，每个波段组一个。CNN 的输出被串联起来，然后通过两层 FC-CNN 进行分类。Zabalza 等人 [[193](#bib.bib193)]
    使用分段 SAEs 来进行降维。光谱数据被分成 $k$ 个区域，每个区域有一个 SAE 用于降维。然后将特征串联成一个减少的配置文件向量。分段区域是通过使用光谱的相关矩阵确定的。在
    Ball 等人 [[321](#bib.bib321)] 中，显示波段选择是任务和数据相关的，通常通过融合相似性度量来获得更好的结果，而不是使用相关性，因此可以通过类似的方法改进这两种方法。降维是许多分类算法
    [[322](#bib.bib322), [323](#bib.bib323)] 、像素解混合 [[31](#bib.bib31), [30](#bib.bib30),
    [324](#bib.bib324), [325](#bib.bib325), [326](#bib.bib326), [327](#bib.bib327),
    [328](#bib.bib328)] 等的重要处理步骤。
- en: 4 Unsolved challenges and opportunities for DL in RS
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 深度学习在遥感中的未解决挑战和机遇
- en: 'DL applied to RS has many challenges and open issues. Table [4](#S4.T4 "Table
    4 ‣ 4 Unsolved challenges and opportunities for DL in RS ‣ A Comprehensive Survey
    of Deep Learning in Remote Sensing: Theories, Tools and Challenges for the Community")
    gives some representative DL and FL survey papers and discusses their main content.
    Based on these reviews, and the reviews of many survey papers in RS, we have identified
    the following major open issues in DL in RS. Herein, we focus on unsolved challenges
    and opportunities as it relates to (i) inadequate data sets ([4.1](#S4.SS1 "4.1
    Inadequate data sets ‣ 4 Unsolved challenges and opportunities for DL in RS ‣
    A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and
    Challenges for the Community")), (ii) human-understandable solutions for modelling
    physical phenomena ([4.2](#S4.SS2 "4.2 Human-understandable solutions for modelling
    physical phenomena ‣ 4 Unsolved challenges and opportunities for DL in RS ‣ A
    Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and Challenges
    for the Community")), (iii) Big Data ([4.3](#S4.SS3 "4.3 Big Data ‣ 4 Unsolved
    challenges and opportunities for DL in RS ‣ A Comprehensive Survey of Deep Learning
    in Remote Sensing: Theories, Tools and Challenges for the Community")), (iv) non-traditional
    heterogeneous data sources ([4.4](#S4.SS4 "4.4 Non-traditional heterogeneous data
    sources ‣ 4 Unsolved challenges and opportunities for DL in RS ‣ A Comprehensive
    Survey of Deep Learning in Remote Sensing: Theories, Tools and Challenges for
    the Community")), (v) DL architectures and learning algorithms for spectral, spatial
    and temporal data ([4.5](#S4.SS5 "4.5 DL architectures and learning algorithms
    for spectral, spatial and temporal data ‣ 4 Unsolved challenges and opportunities
    for DL in RS ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories,
    Tools and Challenges for the Community")), (vi) transfer learning ([4.6](#S4.SS6
    "4.6 Transfer Learning ‣ 4 Unsolved challenges and opportunities for DL in RS
    ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and
    Challenges for the Community")), (vii) an improved theoretical understanding of
    DL systems ([4.7](#S4.SS7 "4.7 An improved theoretical understanding of DL systems
    ‣ 4 Unsolved challenges and opportunities for DL in RS ‣ A Comprehensive Survey
    of Deep Learning in Remote Sensing: Theories, Tools and Challenges for the Community")),
    (viii) high barriers to entry ([4.8](#S4.SS8 "4.8 High barriers to entry ‣ 4 Unsolved
    challenges and opportunities for DL in RS ‣ A Comprehensive Survey of Deep Learning
    in Remote Sensing: Theories, Tools and Challenges for the Community")), and (ix)
    training and optimizing the DL ([4.9](#S4.SS9 "4.9 Training ‣ 4 Unsolved challenges
    and opportunities for DL in RS ‣ A Comprehensive Survey of Deep Learning in Remote
    Sensing: Theories, Tools and Challenges for the Community")).'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在遥感（RS）中的应用面临许多挑战和未解决的问题。表格 [4](#S4.T4 "表 4 ‣ 4 深度学习在遥感中的未解决挑战和机遇 ‣ 遥感深度学习综合调研：理论、工具和社区面临的挑战")
    列出了一些代表性的深度学习和联邦学习调研论文，并讨论了它们的主要内容。基于这些评审，以及对遥感领域许多调研论文的评审，我们确定了深度学习在遥感中存在的以下主要未解决问题。在此，我们关注与以下方面相关的未解决挑战和机遇：(i)
    不足的数据集 ([4.1](#S4.SS1 "4.1 不足的数据集 ‣ 4 深度学习在遥感中的未解决挑战和机遇 ‣ 遥感深度学习综合调研：理论、工具和社区面临的挑战"))，(ii)
    模拟物理现象的可理解解决方案 ([4.2](#S4.SS2 "4.2 模拟物理现象的可理解解决方案 ‣ 4 深度学习在遥感中的未解决挑战和机遇 ‣ 遥感深度学习综合调研：理论、工具和社区面临的挑战"))，(iii)
    大数据 ([4.3](#S4.SS3 "4.3 大数据 ‣ 4 深度学习在遥感中的未解决挑战和机遇 ‣ 遥感深度学习综合调研：理论、工具和社区面临的挑战"))，(iv)
    非传统异质数据源 ([4.4](#S4.SS4 "4.4 非传统异质数据源 ‣ 4 深度学习在遥感中的未解决挑战和机遇 ‣ 遥感深度学习综合调研：理论、工具和社区面临的挑战"))，(v)
    针对光谱、空间和时间数据的深度学习架构和学习算法 ([4.5](#S4.SS5 "4.5 针对光谱、空间和时间数据的深度学习架构和学习算法 ‣ 4 深度学习在遥感中的未解决挑战和机遇
    ‣ 遥感深度学习综合调研：理论、工具和社区面临的挑战"))，(vi) 迁移学习 ([4.6](#S4.SS6 "4.6 迁移学习 ‣ 4 深度学习在遥感中的未解决挑战和机遇
    ‣ 遥感深度学习综合调研：理论、工具和社区面临的挑战"))，(vii) 深度学习系统的理论理解改进 ([4.7](#S4.SS7 "4.7 深度学习系统的理论理解改进
    ‣ 4 深度学习在遥感中的未解决挑战和机遇 ‣ 遥感深度学习综合调研：理论、工具和社区面临的挑战"))，(viii) 高门槛 ([4.8](#S4.SS8
    "4.8 高门槛 ‣ 4 深度学习在遥感中的未解决挑战和机遇 ‣ 遥感深度学习综合调研：理论、工具和社区面临的挑战"))，以及 (ix) 深度学习的训练和优化
    ([4.9](#S4.SS9 "4.9 训练 ‣ 4 深度学习在遥感中的未解决挑战和机遇 ‣ 遥感深度学习综合调研：理论、工具和社区面临的挑战"))。
- en: 'Table 4: Representative DL and FL Survey papers.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：代表性的深度学习（DL）和联邦学习（FL）调研论文。
- en: '| Ref. | Paper Contents |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| Ref. | 论文内容 |'
- en: '| --- | --- |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| [[7](#bib.bib7)] | A survey paper on DL. Covers CNNs, DBNs, etc. |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| [[7](#bib.bib7)] | 关于深度学习的调查论文。涵盖了卷积神经网络（CNN）、深度玻尔兹曼机（DBN）等。 |'
- en: '| [[329](#bib.bib329)] | Brief intro to neural networks in remote sensing.
    |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| [[329](#bib.bib329)] | 遥感中神经网络的简要介绍。 |'
- en: '| [[13](#bib.bib13)] | Overview of unsupervised feature learning and deep learning.
    Provides overview of probabilistic models (undirected graphical, RBM, AE, SAE,
    DAE, contractive autoencoders, manifold learning, difficulty in training deep
    networks, handling high-dimensional inputs, evaluating performance, etc.) |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| [[13](#bib.bib13)] | 无监督特征学习和深度学习的概述。提供了概率模型（无向图模型、RBM、自编码器（AE）、堆叠自编码器（SAE）、去噪自编码器（DAE）、收缩自编码器、流形学习、训练深度网络的困难、高维输入的处理、性能评估等）的概述。
    |'
- en: '| [[330](#bib.bib330)] | Examines big-data impacts on SVM machine learning.
    |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| [[330](#bib.bib330)] | 检视大数据对SVM机器学习的影响。 |'
- en: '| [[1](#bib.bib1)] | Covers about 170 publications in the area of scene classification
    and discusses limitations of datasets and problems associated with high-resolution
    imagery. They discuss limitations of handcrafted features such as texture descriptors,
    GIST, SIFT, HOG. |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| [[1](#bib.bib1)] | 涵盖了大约170篇关于场景分类的出版物，并讨论了数据集的局限性和高分辨率图像相关的问题。他们讨论了手工特征的局限性，如纹理描述符、GIST、SIFT、HOG。
    |'
- en: '| [[2](#bib.bib2)] | A good overview of architectures, algorithms, and applications
    for DL. Three important reasons for DL success are (1) GPU units, (2) recent advances
    in DL research. In addition, we note that (3) would be success of DL in many image
    processing challenges. DL is at the intersection of machine learning, Neural Networks,
    optimization, graphical modeling, pattern recognition, probability theory and
    signal processing. They discuss generative, discriminative, and hybrid deep architectures.
    They show there is vast room to improve the current optimization techniques in
    DL. |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| [[2](#bib.bib2)] | 关于深度学习架构、算法和应用的良好概述。深度学习成功的三个重要原因是（1）GPU单元，（2）最近在深度学习研究中的进展。此外，我们注意到（3）是深度学习在许多图像处理挑战中的成功。深度学习位于机器学习、神经网络、优化、图形建模、模式识别、概率论和信号处理的交汇点。他们讨论了生成、判别和混合深度架构。他们展示了深度学习中当前优化技术有广泛的改进空间。
    |'
- en: '| [[331](#bib.bib331)] | Overview of NN in image processing. |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| [[331](#bib.bib331)] | 图像处理中的神经网络概述。'
- en: '| [[332](#bib.bib332)] | Discusses trends in extreme learning machines, which
    are linear, single hidden layer feedforward neural networks. ELMs are comparable
    or better than SVMs in generalization ability. In some cases, ELMs have comparable
    performance to DL approaches. They generally have high generalization capability,
    are universal approximators, don’t require iterative learning, and have a unified
    learning theory. |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| [[332](#bib.bib332)] | 讨论了极限学习机的趋势，极限学习机是线性、单隐层前馈神经网络。与支持向量机（SVM）在泛化能力方面相当或更好。在某些情况下，极限学习机的性能与深度学习方法相当。它们通常具有高泛化能力，是通用逼近器，不需要迭代学习，并且有统一的学习理论。
    |'
- en: '| [[333](#bib.bib333)] | Provides overview of feature reduction in remote sensing
    imagery. |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| [[333](#bib.bib333)] | 提供了遥感图像中特征降维的概述。 |'
- en: '| [[8](#bib.bib8)] | A survey of deep neural networks, including the AE, the
    CNN, and applications. |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| [[8](#bib.bib8)] | 深度神经网络的调查，包括自编码器（AE）、卷积神经网络（CNN）及其应用。 |'
- en: '| [[334](#bib.bib334)] | Survey of image classification methods in remote sensing.
    |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| [[334](#bib.bib334)] | 遥感图像分类方法的调查。 |'
- en: '| [[335](#bib.bib335)] | Short survey of DL in hyperspectral remote sensing.
    In particular, in one study, there was a definite sweet spot shown in the DL depth.
    |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| [[335](#bib.bib335)] | 关于高光谱遥感中深度学习的简要调查。特别是在一项研究中，深度学习的深度显示出了明显的甜点。 |'
- en: '| [[336](#bib.bib336)] | Overview of shallow HSI processing. |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| [[336](#bib.bib336)] | 浅层HSI处理的概述。 |'
- en: '| [[29](#bib.bib29)] | Overview of shallow endmember extraction algorithms.
    |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| [[29](#bib.bib29)] | 浅层端成员提取算法的概述。 |'
- en: '| [[10](#bib.bib10)] | An in-depth historical overview of DL. |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| [[10](#bib.bib10)] | 深度学习的深入历史概述。 |'
- en: '| [[4](#bib.bib4)] | History of DL. |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| [[4](#bib.bib4)] | 深度学习的历史。 |'
- en: '| [[337](#bib.bib337)] | A review of road extraction from remote sensing imagery.
    |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| [[337](#bib.bib337)] | 遥感图像中道路提取的综述。 |'
- en: '| [[9](#bib.bib9)] | A review of DL in signal and image processing. Comparisons
    are made to shallow learning, and DL advantages are given. |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| [[9](#bib.bib9)] | 深度学习在信号和图像处理中的综述。与浅层学习进行比较，并给出了深度学习的优势。 |'
- en: '| [[3](#bib.bib3)] | Provides a general framework for DL in remote sensing.
    Covers four RS perspectives: (1) image processing, (2) pixel-based classification,
    (3) target recognition, and (4) scene understanding. |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| [[3](#bib.bib3)] | 提供了一个遥感深度学习的通用框架。涵盖了四个遥感视角：（1）图像处理，（2）基于像素的分类，（3）目标识别，以及（4）场景理解。
    |'
- en: 4.1 Inadequate data sets
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 不足的数据集
- en: 'Open Question #1a: How can DL systems work well with limited datasets?'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '开放问题 #1a：深度学习系统如何在有限的数据集上表现良好？'
- en: 'There are two main issues with most current RS data sets. Table [5](#S4.T5
    "Table 5 ‣ 4.1 Inadequate data sets ‣ 4 Unsolved challenges and opportunities
    for DL in RS ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories,
    Tools and Challenges for the Community") provides a summary of the more common
    open-source datasets for the DL papers utilizing HSI data. Many of these papers
    utilized custom datasets, and these are not reported. Table [5](#S4.T5 "Table
    5 ‣ 4.1 Inadequate data sets ‣ 4 Unsolved challenges and opportunities for DL
    in RS ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools
    and Challenges for the Community") shows that the most commonly used datasets
    were Indian Pines, Pavia University, Pavia City Center, and Salinas.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数当前遥感数据集存在两个主要问题。表 [5](#S4.T5 "表 5 ‣ 4.1 不足的数据集 ‣ 4 深度学习在遥感中的未解挑战与机遇 ‣ 遥感中深度学习的全面调查：理论、工具和挑战")
    提供了一个总结，列出了利用HSI数据的深度学习论文中较为常见的开源数据集。其中许多论文使用了自定义数据集，而这些数据集并未被报告。表 [5](#S4.T5
    "表 5 ‣ 4.1 不足的数据集 ‣ 4 深度学习在遥感中的未解挑战与机遇 ‣ 遥感中深度学习的全面调查：理论、工具和挑战") 显示，使用最频繁的数据集是印第安纳松林、帕维亚大学、帕维亚市中心和萨利纳斯。
- en: 'Table 5: HSI Dataset Usage.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：HSI 数据集使用情况。
- en: '| Dataset and Reference | Number of uses |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 数据集和参考 | 使用次数 |'
- en: '| --- | --- |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| IEEE GRSS 2013 Data Fusion Contest [[338](#bib.bib338)] | 4 |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| IEEE GRSS 2013 数据融合竞赛 [[338](#bib.bib338)] | 4 |'
- en: '| IEEE GRSS 2015 Data Fusion Contest [[339](#bib.bib339)] | 1 |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| IEEE GRSS 2015 数据融合竞赛 [[339](#bib.bib339)] | 1 |'
- en: '| IEEE GRSS 2016 Data Fusion Contest [[340](#bib.bib340)] | 2 |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| IEEE GRSS 2016 数据融合竞赛 [[340](#bib.bib340)] | 2 |'
- en: '| Indian Pines [[341](#bib.bib341)] | 27 |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 印第安纳松林 [[341](#bib.bib341)] | 27 |'
- en: '| Kennedy Space Center [[342](#bib.bib342)] | 8 |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| 肯尼迪航天中心 [[342](#bib.bib342)] | 8 |'
- en: '| Pavia City Center [[343](#bib.bib343)] | 13 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 帕维亚市中心 [[343](#bib.bib343)] | 13 |'
- en: '| Pavia University [[343](#bib.bib343)] | 19 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 帕维亚大学 [[343](#bib.bib343)] | 19 |'
- en: '| Salinas [[344](#bib.bib344)] | 11 |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 萨利纳斯 [[344](#bib.bib344)] | 11 |'
- en: '| Washington DC Mall [[345](#bib.bib345)] | 2 |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 华盛顿特区购物中心 [[345](#bib.bib345)] | 2 |'
- en: 'A very detailed online table (too large to put in this paper) is provided which
    lists each paper cited in Table [3](#S3.T3 "Table 3 ‣ 3 DL approaches in RS ‣
    A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and
    Challenges for the Community"). For each paper, a summary of the contributions
    is given, the datasets utilized are listed, and the papers are categorized in
    areas (e.g. HSI/MSI, SAR, 3D, etc.). The interested reader can find this at [http://www.cs-chan.com/source/FADL/Online_Dataset_Summary_Table.pdf](http://www.cs-chan.com/source/FADL/Online_Dataset_Summary_Table.pdf).'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了一个非常详细的在线表格（过于庞大以至于无法放入本文），列出了表 [3](#S3.T3 "表 3 ‣ 3 种深度学习方法 ‣ 遥感中深度学习的全面调查：理论、工具和挑战")
    中引用的每篇论文。每篇论文都有贡献总结，列出了使用的数据集，并按领域（如HSI/MSI、SAR、3D等）对论文进行分类。感兴趣的读者可以在 [http://www.cs-chan.com/source/FADL/Online_Dataset_Summary_Table.pdf](http://www.cs-chan.com/source/FADL/Online_Dataset_Summary_Table.pdf)
    找到该表格。
- en: 'While these are all good datasets, the accuracies from many of the DL papers
    are nearly saturated. This is shown clearly in Table [6](#S4.T6 "Table 6 ‣ 4.1
    Inadequate data sets ‣ 4 Unsolved challenges and opportunities for DL in RS ‣
    A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and
    Challenges for the Community"). Table [6](#S4.T6 "Table 6 ‣ 4.1 Inadequate data
    sets ‣ 4 Unsolved challenges and opportunities for DL in RS ‣ A Comprehensive
    Survey of Deep Learning in Remote Sensing: Theories, Tools and Challenges for
    the Community") shows results for the HSI DL papers against the commonly-used
    datasets Indian Pines, Kennedy Space Center, Pavia City Center, Pavia University,
    Salinas, and the Washington DC Mall. First, OA results must be taken with a grain
    of salt, since (1) the number of training samples per class can differ for each
    paper, (2) the number of testing samples can also differ, (3) classes with few
    relative training samples can even have 0% overall accuracy, and if there is a
    large number of test samples of the other classes, the final overall accuracies
    can still be high. Nevertheless, it is clear from examination of the table that
    the Indian Pines, Pavia City Center, Pavia University and Salinas datasets are
    basically saturated.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管这些数据集都很好，但许多DL论文中的准确率几乎已经饱和。这在表[6](#S4.T6 "Table 6 ‣ 4.1 Inadequate data
    sets ‣ 4 Unsolved challenges and opportunities for DL in RS ‣ A Comprehensive
    Survey of Deep Learning in Remote Sensing: Theories, Tools and Challenges for
    the Community")中显示得非常清楚。表[6](#S4.T6 "Table 6 ‣ 4.1 Inadequate data sets ‣ 4 Unsolved
    challenges and opportunities for DL in RS ‣ A Comprehensive Survey of Deep Learning
    in Remote Sensing: Theories, Tools and Challenges for the Community")展示了HSI DL论文在常用数据集印度松、肯尼迪航天中心、帕维亚市中心、帕维亚大学、萨利纳斯和华盛顿特区购物中心的结果。首先，OA结果必须谨慎对待，因为（1）每篇论文的每类训练样本数量可能不同，（2）测试样本数量也可能不同，（3）相对训练样本较少的类别甚至可能有0%的总体准确率，而如果其他类别有大量的测试样本，最终的总体准确率仍可能很高。然而，从表格的检查结果来看，印度松、帕维亚市中心、帕维亚大学和萨利纳斯数据集基本上已经饱和。'
- en: 'In general, it is good to compare new methods to commonly-used datasets, new
    and challenging datasets are required. Cheng et al. [[1](#bib.bib1), [346](#bib.bib346)]
    point out that many existing RS datasets lack image variation, diversity, and
    have a small number of classes. Datasets are also saturating with accuracy. They
    created a large-scale benchmark dataset, ”NWPU-RESISC45”, which attempts to address
    all of these issues, and made it available to the RS community. The RS community
    can also benefit from a common practice in the CV community: publishing both datasets
    and algorithms online, allowing for more comparisons. A typical RS paper may only
    test their algorithm on two or three images and against only a few other methods.
    In the CV community, papers usually compare against a large amount of other methods
    and with many datasets, which may provide more insight about the proposed solution
    and how it compares to previous work.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，将新方法与常用数据集进行比较是很好的，同时也需要新的和具有挑战性的数据集。Cheng 等人 [[1](#bib.bib1), [346](#bib.bib346)]
    指出，许多现有的RS数据集缺乏图像变化和多样性，并且类别数量较少。数据集的准确率也趋于饱和。他们创建了一个大规模基准数据集，”NWPU-RESISC45”，旨在解决这些问题，并向RS社区提供。RS社区还可以借鉴CV社区的一个常见做法：在线发布数据集和算法，允许更多的比较。一个典型的RS论文可能只会在两到三张图像上测试其算法，并与少数其他方法进行比较。而在CV社区，论文通常会与大量其他方法和许多数据集进行比较，这可能提供更多关于提议解决方案的洞察，并与以往的工作进行对比。
- en: 'Table 6: HSI Overall Accuracy Results in percent. IP = Indian Pines, KSC =
    Kennedy Space Center, PaCC = Pavia City Center, Pau = Pavia University, Sal =
    Salinas, DCM = Washington DC Mall. Results higher than 99% are in bold.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：HSI总体准确率结果（百分比）。IP = 印度松，KSC = 肯尼迪航天中心，PaCC = 帕维亚市中心，Pau = 帕维亚大学，Sal = 萨利纳斯，DCM
    = 华盛顿特区购物中心。结果高于99%的用粗体显示。
- en: '| Ref | IP | KSC | PaCC | PaU | Sal | DCM |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| Ref | IP | KSC | PaCC | PaU | Sal | DCM |'
- en: '| [[267](#bib.bib267)] | 93.4 |  |  |  |  |  |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| [[267](#bib.bib267)] | 93.4 |  |  |  |  |  |'
- en: '| [[141](#bib.bib141)] | 98.0 | 98.0 |  | 98.4 |  | 95.4 |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| [[141](#bib.bib141)] | 98.0 | 98.0 |  | 98.4 |  | 95.4 |'
- en: '| [[142](#bib.bib142)] | 97.6 |  |  |  |  |  |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| [[142](#bib.bib142)] | 97.6 |  |  |  |  |  |'
- en: '| [[143](#bib.bib143)] | 97.6 |  |  |  |  |  |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| [[143](#bib.bib143)] | 97.6 |  |  |  |  |  |'
- en: '| [[347](#bib.bib347)] |  | 98.8 | 98.5 |  |  |  |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| [[347](#bib.bib347)] |  | 98.8 | 98.5 |  |  |  |'
- en: '| [[314](#bib.bib314)] | 96.0 |  | 99.1 |  |  |  |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| [[314](#bib.bib314)] | 96.0 |  | 99.1 |  |  |  |'
- en: '| [[148](#bib.bib148)] |  |  |  | 94.3 |  |  |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| [[148](#bib.bib148)] |  |  |  | 94.3 |  |  |'
- en: '| [[191](#bib.bib191)] | 89.6 |  |  | 87.1 |  |  |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| [[191](#bib.bib191)] | 89.6 |  |  | 87.1 |  |  |'
- en: '| [[151](#bib.bib151)] |  | 96.6 |  |  |  |  |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| [[151](#bib.bib151)] |  | 96.6 |  |  |  |  |'
- en: '| [[153](#bib.bib153)] | 90.2 |  |  | 92.6 | 92.6 |  |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| [[153](#bib.bib153)] | 90.2 |  |  | 92.6 | 92.6 |  |'
- en: '| [[155](#bib.bib155)] |  | 84.2 |  |  |  |  |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| [[155](#bib.bib155)] |  | 84.2 |  |  |  |  |'
- en: '| [[158](#bib.bib158)] | 92.1 |  |  | 94.0 |  |  |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| [[158](#bib.bib158)] | 92.1 |  |  | 94.0 |  |  |'
- en: '| [[159](#bib.bib159)] |  |  |  | 99.9 |  |  |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| [[159](#bib.bib159)] |  |  |  | 99.9 |  |  |'
- en: '| [[160](#bib.bib160)] | 96.3 |  |  |  |  |  |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| [[160](#bib.bib160)] | 96.3 |  |  |  |  |  |'
- en: '| [[162](#bib.bib162)] | 94.3 |  |  | 96.5 | 94.8 |  |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| [[162](#bib.bib162)] | 94.3 |  |  | 96.5 | 94.8 |  |'
- en: '| [[163](#bib.bib163)] | 97.6 |  |  | 99.4 | 98.8 |  |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| [[163](#bib.bib163)] | 97.6 |  |  | 99.4 | 98.8 |  |'
- en: '| [[164](#bib.bib164)] |  | 96.0 | 85.6 |  |  |  |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| [[164](#bib.bib164)] |  | 96.0 | 85.6 |  |  |  |'
- en: '| [[167](#bib.bib167)] | 91.9 |  | 99.8 | 96.7 | 95.5 |  |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| [[167](#bib.bib167)] | 91.9 |  | 99.8 | 96.7 | 95.5 |  |'
- en: '| [[168](#bib.bib168)] |  |  | 94.0 | 93.5 |  |  |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| [[168](#bib.bib168)] |  |  | 94.0 | 93.5 |  |  |'
- en: '| [[216](#bib.bib216)] | 86.5 |  |  | 82.6 |  |  |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| [[216](#bib.bib216)] | 86.5 |  |  | 82.6 |  |  |'
- en: '| [[169](#bib.bib169)] | 99.2 |  | 99.9 |  |  |  |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| [[169](#bib.bib169)] | 99.2 |  | 99.9 |  |  |  |'
- en: '| [[170](#bib.bib170)] |  |  | 96.0 |  |  | 83.8 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| [[170](#bib.bib170)] |  |  | 96.0 |  |  | 83.8 |'
- en: '| [[211](#bib.bib211)] | 98.9 |  | 99.9 |  | 99.5 |  |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| [[211](#bib.bib211)] | 98.9 |  | 99.9 |  | 99.5 |  |'
- en: '| [[172](#bib.bib172)] | 95.7 |  |  | 99.6 | 97.4 |  |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| [[172](#bib.bib172)] | 95.7 |  |  | 99.6 | 97.4 |  |'
- en: '| [[173](#bib.bib173)] | 96.8 |  |  |  |  |  |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| [[173](#bib.bib173)] | 96.8 |  |  |  |  |  |'
- en: '| [[217](#bib.bib217)] | 79.3 |  |  |  |  |  |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| [[217](#bib.bib217)] | 79.3 |  |  |  |  |  |'
- en: '| [[175](#bib.bib175)] | 97.9 | 97.9 |  | 96.8 |  |  |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| [[175](#bib.bib175)] | 97.9 | 97.9 |  | 96.8 |  |  |'
- en: '| [[179](#bib.bib179)] |  | 80.5 |  |  |  |  |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| [[179](#bib.bib179)] |  | 80.5 |  |  |  |  |'
- en: '| [[192](#bib.bib192)] | 93.1 |  |  | 95.6 |  |  |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| [[192](#bib.bib192)] | 93.1 |  |  | 95.6 |  |  |'
- en: '| [[348](#bib.bib348)] | 96.6 |  |  |  |  |  |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| [[348](#bib.bib348)] | 96.6 |  |  |  |  |  |'
- en: '| [[221](#bib.bib221)] | 73.0 | 89.0 |  |  |  |  |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| [[221](#bib.bib221)] | 73.0 | 89.0 |  |  |  |  |'
- en: '| [[180](#bib.bib180)] | 93.1 |  |  | 90.4 | 99.4 |  |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| [[180](#bib.bib180)] | 93.1 |  |  | 90.4 | 99.4 |  |'
- en: '| [[181](#bib.bib181)] | 95.6 |  |  |  |  |  |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| [[181](#bib.bib181)] | 95.6 |  |  |  |  |  |'
- en: '| [[183](#bib.bib183)] |  |  |  | 67.9 | 85.2 |  |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| [[183](#bib.bib183)] |  |  |  | 67.9 | 85.2 |  |'
- en: '| [[184](#bib.bib184)] |  |  | 95.2 |  |  |  |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| [[184](#bib.bib184)] |  |  | 95.2 |  |  |  |'
- en: '| [[193](#bib.bib193)] | 82.1 |  | 97.4 |  |  |  |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| [[193](#bib.bib193)] | 82.1 |  | 97.4 |  |  |  |'
- en: '| [[187](#bib.bib187)] | 99.7 |  |  | 98.8 |  |  |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| [[187](#bib.bib187)] | 99.7 |  |  | 98.8 |  |  |'
- en: '| [[188](#bib.bib188)] |  |  | 99.7 | 96.8 |  |  |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| [[188](#bib.bib188)] |  |  | 99.7 | 96.8 |  |  |'
- en: An extensive table of all the datasets utilized in the papers reviewed for this
    survey paper is made available online, because it is too large to include in this
    paper. The table is available at [http://www.cs-chan.com/source/FADL/Online_Dataset_Summary_Table.pdf](http://www.cs-chan.com/source/FADL/Online_Dataset_Summary_Table.pdf).
    The table lists the dataset name, briefly describes the datasets, provides a URL
    (if one is available), and a reference. Hopefully, this table will assist researchers
    starting work and looking for publicly available datasets.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包含所有在本调查论文中审查的论文所使用数据集的详细表格已经在线提供，因为它太大而无法包含在本文中。表格可以在 [http://www.cs-chan.com/source/FADL/Online_Dataset_Summary_Table.pdf](http://www.cs-chan.com/source/FADL/Online_Dataset_Summary_Table.pdf)
    处找到。该表格列出了数据集名称，简要描述了数据集，提供了网址（如果有的话），以及参考文献。希望这个表格能帮助研究人员开始工作并寻找公开可用的数据集。
- en: 'Open Question #1b: How can DL systems work well with limited training data?'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '开放性问题 #1b：深度学习系统如何在有限的训练数据下良好运作？'
- en: The second issue is that most RS data has a very small amount of training data
    available. Ironically, in the CV community, DL has an insatiable hunger for larger
    and larger data sets (millions or tens of millions of training images), while
    in the RS field, there is also a large amount of imagery, however, there is usually
    only a small amount with labeled training samples. RS training data is expensive,
    error-prone, and usually requires some expert interpretation, which is typically
    expensive (in terms of time, effort involved, and money) and often requires large
    amounts of field work and many hours or days post processing the data. Many DL
    systems, especially those with large numbers of parameters, require large amounts
    of training data, or else they can easily overtrain and not generalize well. This
    problem has also plagued other shallow systems as well, such as SVMs.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个问题是大多数 RS 数据只有很少的训练数据。具有讽刺意味的是，在计算机视觉领域，深度学习对更大数据集（数百万或数千万的训练图像）有着难以满足的需求，而在
    RS 领域，虽然也有大量图像，但通常只有少量标记的训练样本。RS 训练数据昂贵、易出错，并且通常需要一些专家解释，这通常是昂贵的（从时间、精力和金钱方面来看），并且通常需要大量的实地工作和许多小时或几天的后处理。许多深度学习系统，尤其是那些具有大量参数的系统，需要大量的训练数据，否则它们可能会过度训练而无法很好地泛化。这个问题也困扰着其他浅层系统，例如支持向量机。
- en: 'Approaches used to mitigate small training samples are (1) transfer learning,
    where one trains on other imagery to obtain low-level to mid-level features which
    can still be used, or on other images from the same sensor - Transfer learning
    is discussed in section [4.6](#S4.SS6 "4.6 Transfer Learning ‣ 4 Unsolved challenges
    and opportunities for DL in RS ‣ A Comprehensive Survey of Deep Learning in Remote
    Sensing: Theories, Tools and Challenges for the Community") below; (2) data augmentation,
    including affine transformations, rotations, small patch removal, etc.; (3) using
    ancillary data, such as data from other sensor modalities (e.g. LiDAR, digital
    elevation models (DEMs), etc.); and (4) unsupervised training, where training
    labels are not required, e.g. AEs and SAEs. SAEs that have a diabolo shape will
    force the AE network to learn a lower-dimensional representation.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '缓解小训练样本的方法有 (1) 迁移学习，通过对其他图像进行训练以获得低级到中级特征，这些特征仍然可以使用，或对来自相同传感器的其他图像进行训练 -
    迁移学习在下面的 [4.6](#S4.SS6 "4.6 Transfer Learning ‣ 4 Unsolved challenges and opportunities
    for DL in RS ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories,
    Tools and Challenges for the Community") 节中进行了讨论；(2) 数据增强，包括仿射变换、旋转、小补丁去除等；(3)
    使用辅助数据，例如来自其他传感器模态的数据（如 LiDAR、数字高程模型（DEMs）等）；(4) 无监督训练，不需要训练标签，例如 AEs 和 SAEs。具有沙漏形状的
    SAEs 将强制 AE 网络学习低维表示。'
- en: Ma et al. [[169](#bib.bib169)] utilized a DAE and employed a collaborative representation-based
    classification, where each test sample can be linearly represented by the training
    samples in the same class with the minimum residual. In classification, features
    of each sample are approximated with a linear combination of features of all training
    sample within each class, and the label can be derived according to the class
    which best approximates the test features. Interested reader is referred to references
    $46$–$48$ in [[169](#bib.bib169)] for more information on collaborative representation.
    Tao et al. [[349](#bib.bib349)] utilized a Stacked Sparse AE (SSAE) that was shown
    to be very generalizable and performed well in cases when there were limited training
    samples. Ghamasi et al. [[207](#bib.bib207)] use Darwinian particle swarm optimization
    in conjunction with CNNs to select an optimal band set for classifying HSI data.
    By reducing the input dimensionality, fewer training samples are required. Yang
    et al. [[181](#bib.bib181)] utilized dual CNNs and transfer learning to improve
    performance. In this method, the lower and middle layers can be trained on other
    scenes, and train the top layers on the limited training samples. Ma et al. [[170](#bib.bib170)]
    imposed a relative distance prior on the SAE DL network to deal with training
    instabilities. This approach extends the SAE by adding the new distance prior
    term and corresponding SGD optimization. LeCun reviews a number of unsupervised
    learning algorithms using AEs, which can possibly aid when training data is minimal
    [[350](#bib.bib350)] . Pal [[351](#bib.bib351)] reviews kernel methods in RS and
    argues that SVMs are a good choice when there are a small number of training samples.
    Petersson et al. [[335](#bib.bib335)] suggest using SAEs to handle small training
    samples in HSI processing.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: Ma 等人 [[169](#bib.bib169)] 利用 DAE 并采用基于协同表示的分类方法，其中每个测试样本可以通过同一类别中的训练样本线性表示，从而得到最小残差。在分类中，每个样本的特征通过类别内所有训练样本特征的线性组合来近似，标签可以根据最能近似测试特征的类别来推导。感兴趣的读者可以参阅
    [[169](#bib.bib169)] 中的参考文献 $46$–$48$ 以获取关于协同表示的更多信息。Tao 等人 [[349](#bib.bib349)]
    利用了一种堆叠稀疏自编码器（SSAE），这被证明具有很好的泛化能力，并在训练样本有限的情况下表现良好。Ghamasi 等人 [[207](#bib.bib207)]
    结合了达尔文粒子群优化和 CNNs 来选择用于分类 HSI 数据的最佳波段集。通过减少输入维度，所需的训练样本更少。Yang 等人 [[181](#bib.bib181)]
    利用双 CNNs 和迁移学习来提高性能。在这种方法中，较低层和中间层可以在其他场景上进行训练，而在有限的训练样本上训练顶层。Ma 等人 [[170](#bib.bib170)]
    在 SAE DL 网络上施加了相对距离先验，以处理训练不稳定性。这种方法通过添加新的距离先验项和相应的 SGD 优化来扩展 SAE。LeCun 回顾了多种使用
    AEs 的无监督学习算法，这可能在训练数据有限时提供帮助 [[350](#bib.bib350)]。Pal [[351](#bib.bib351)] 回顾了
    RS 中的核方法，并认为在训练样本数量较少的情况下，SVMs 是一个不错的选择。Petersson 等人 [[335](#bib.bib335)] 建议使用
    SAEs 来处理 HSI 处理中的小训练样本。
- en: 4.2 Human-understandable solutions for modelling physical phenomena
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 可理解的物理现象建模解决方案
- en: 'Open Question #2a: How can DL improve model-based RS?'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '开放问题 #2a：深度学习如何改善基于模型的遥感？'
- en: Many RS applications depend on models (e.g. a model of crop output given rain,
    fertilizer and soil nitrogen content, and time of year), many of which are very
    complicated and often highly nonlinear. Model outputs can be very inaccurate if
    the models don’t adequately capture the true input data and properly handle the
    intricate inter-relationships between input variables.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 许多遥感（RS）应用依赖于模型（例如，在给定降雨、肥料和土壤氮含量及年份的情况下的作物产量模型），其中许多模型非常复杂且通常高度非线性。如果模型没有充分捕捉真实输入数据并正确处理输入变量之间复杂的相互关系，则模型输出可能非常不准确。
- en: Abdel-Rahman et al. [[352](#bib.bib352)] pointed out that more accurate estimation
    of nitrogen content and water availability can aid biophysical parameter estimation
    for improving plant yield models. Ali et al. [[353](#bib.bib353)] examine biomass
    estimation, which is a nonlinear and highly complex problem. The retrieval problem
    is ill-posed and the electromagnetic response is the complex result of many contributions.
    The data pixels are usually mixed, making this a hard problem. ANNs and support
    vector regression have shown good results. They anticipate that DL models can
    provide good results. Both Adam et al. [[354](#bib.bib354)] and Ozesmi et al.
    [[355](#bib.bib355)] agree that there is need for improvement in wetland vegetation
    mapping. Wetland species are hard to detect and identify compared to terrestrial
    plants. Hyperspectral sensing with narrow bandwidths in frequency can aid. Pixel
    unmixing is important since canopy spectra are similar and combine with underlying
    hydrologic regime and atmospheric vapor. Vegetation spectra highly correlated
    among species, making separation difficult. Dorigo et al. [[356](#bib.bib356)]
    analyzed inversion-based models for plant analysis, which is inherently an ill-posed
    and hard task. They found that using ANN inversion techniques have shown good
    results. DL may be able to help improve results. Canopy reflections are governed
    by large number of canopy elements interacting and by external factors. Since
    DL networks can learn very complex non-linear systems, it seems like there is
    much room for improvement in applying DL models. DBNs or other DL systems seem
    like a natural fit for these types of problems.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: Abdel-Rahman 等人 [[352](#bib.bib352)] 指出，更准确的氮含量和水分可用性估算有助于生物物理参数估算，从而改善植物产量模型。Ali
    等人 [[353](#bib.bib353)] 研究了生物质估算，这是一个非线性且高度复杂的问题。检索问题是病态的，电磁响应是多种因素复杂作用的结果。数据像素通常是混合的，使得这个问题很难解决。人工神经网络（ANNs）和支持向量回归已显示出良好的结果。他们预测深度学习（DL）模型能够提供良好的结果。Adam
    等人 [[354](#bib.bib354)] 和 Ozesmi 等人 [[355](#bib.bib355)] 都同意湿地植物绘图需要改进。与陆生植物相比，湿地物种更难以检测和识别。具有窄带宽的高光谱传感可以提供帮助。像冠层光谱这样的像素解混至关重要，因为冠层光谱相似并且与底层水文状态和大气蒸汽结合。植物光谱在物种之间高度相关，使得分离变得困难。Dorigo
    等人 [[356](#bib.bib356)] 分析了用于植物分析的反演模型，这本质上是一个病态且困难的任务。他们发现，使用ANN反演技术已显示出良好的结果。深度学习可能有助于改善结果。冠层反射受大量冠层元素相互作用和外部因素的影响。由于深度学习网络可以学习非常复杂的非线性系统，应用深度学习模型似乎有很大的改进空间。深度置信网络（DBNs）或其他深度学习系统似乎很适合这些类型的问题。
- en: Kuenzer et al. [[357](#bib.bib357)] and Wang et al. [[358](#bib.bib358)] assess
    biodiversity modeling. Biodiversity occurs at all levels from molecular to individual
    animals, to ecosystem, to global. This requires a large variety of sensors and
    analysis at multiple scales. However, a main challenge is low temporal resolution.
    There needs to be a focus beyond just pixel-level processing, and utilizing spatial
    patterns and objects. DL systems have been shown to learn hierarchical features,
    with smaller scale features learned at the beginning of the network, and more
    complex and abstract features learned in the deeper portions.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: Kuenzer 等人 [[357](#bib.bib357)] 和 Wang 等人 [[358](#bib.bib358)] 评估了生物多样性建模。生物多样性发生在从分子到个体动物，到生态系统，再到全球的所有层面。这需要各种传感器和多个尺度的分析。然而，一个主要挑战是低时间分辨率。需要关注超越像素级处理，并利用空间模式和对象。深度学习系统已显示能够学习层次特征，在网络的开始阶段学习较小尺度的特征，在更深层次学习更复杂和抽象的特征。
- en: 'Open Question #2b: What tools and techniques are required to “understand” how
    the DL works?'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '开放性问题 #2b：理解深度学习（DL）工作原理需要哪些工具和技术？'
- en: It is also worth mentioning that many of these applications involve biological
    and scientific end-users, who will definitely want to understand how the DL systems
    work. For instance, a linear model that models some biological process is easily
    understood - both the mathematical model and the statistics resulting from estimating
    the model parameters are well understood by scientists and biologists. However,
    a DL system can be so large and complex as to defy analysis. We note that this
    is not specific to RS, but a general problem in the broader DL community.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，这些应用中的许多涉及生物和科学领域的最终用户，他们肯定希望了解深度学习系统是如何工作的。例如，建模某些生物过程的线性模型很容易理解——数学模型和通过估计模型参数得到的统计结果都被科学家和生物学家很好地理解。然而，深度学习系统可能复杂到无法进行分析。我们指出，这不仅仅是推荐系统（RS）的特有问题，而是深度学习（DL）领域的普遍问题。
- en: The DL system is seen by many researchers, especially scientists and RS end-users,
    as a black box that is hard to understand what is happening “under the hood”.
    Egmont-Peterson et al. [[331](#bib.bib331)] and Fassnacht et al. [[359](#bib.bib359)]
    both state that disadvantages of NNs are understanding what they are actually
    doing, which can be difficult to understand. In many RS applications, just making
    a decision is not enough; people need to understand how reliable the decision
    is and how the system arrived at that decision. Ali et al. [[360](#bib.bib360)]
    also echo this view in their review paper on improving biomass estimation. Visualization
    tools which show the convolutional filters, learning rates, and tools with deconvolution
    capabilities to localize the convolutional firings are all helpful [[361](#bib.bib361),
    [362](#bib.bib362), [39](#bib.bib39), [363](#bib.bib363), [364](#bib.bib364)]
    . Visualization of what the DL is actually learning is an open area of research.
    Tools and techniques capable of visualizing what the network is learning and measures
    of how robust the network is (estimating how well it may genralize) would be of
    great benefit to the RS community (and the general DL community).
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究人员，特别是科学家和推荐系统最终用户，将深度学习系统视为一个难以理解其“内部运作”的黑箱。Egmont-Peterson 等人[[331](#bib.bib331)]
    和 Fassnacht 等人[[359](#bib.bib359)] 都表示，神经网络的劣势在于理解它们实际上在做什么，这可能很难理解。在许多推荐系统应用中，仅仅做出决策是不够的；人们需要了解决策的可靠性以及系统是如何得出这个决策的。Ali
    等人[[360](#bib.bib360)] 在他们关于改进生物量估计的综述论文中也表达了这一观点。可视化工具，如显示卷积滤波器、学习率的工具，以及具备去卷积能力的工具来定位卷积激发，都是有帮助的[[361](#bib.bib361),
    [362](#bib.bib362), [39](#bib.bib39), [363](#bib.bib363), [364](#bib.bib364)]。深度学习实际学习内容的可视化仍是一个开放的研究领域。能够可视化网络所学习内容的工具和技术，以及衡量网络鲁棒性（估计其泛化能力）的工具，将对推荐系统社区（以及广泛的深度学习社区）大有裨益。
- en: 4.3 Big Data
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 大数据
- en: 'Open Question #3: What happens when DL meets Big Data?'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '开放问题 #3：当深度学习遇到大数据时会发生什么？'
- en: 'As already discussed in Section [2.4.3](#S2.SS4.SSS3 "2.4.3 Big Data ‣ 2.4
    DL Meets the Real World ‣ 2 Related work in CV ‣ A Comprehensive Survey of Deep
    Learning in Remote Sensing: Theories, Tools and Challenges for the Community"),
    a number of mathematics, algorithms and hardware have been put forth to date relative
    to large scale DL networks and DL in Big Data. However, this challenge is not
    close to being solved. Most approaches to date have focused on Big Data challenges
    in RGB or RGBD data for tasks like face and object detection or speech. With respect
    to remote sensing, we have many of the same problems as CV, but there are unique
    challenges related to different sensors and data. First, we can break Big Data
    into its different so-called “parts”, e.g., volume, variety and velocity. With
    respect to DBNs, CNNs, AEs, etc., we are primarily concerned with creating new
    robust and distributed mathematics, algorithms and hardware that can ingest massive
    streams of large, missing, noisy data from different sources, such as sensors,
    humans and machines. This means being able to combine image stills, video, audio,
    text, etc., with symbolic and semantic variation. Furthermore, we require real-time
    evaluation and possibly online learning. As Big Data in DL is a large topic, we
    restrict our focus herein to factors that are unique to remote sensing.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '如[2.4.3](#S2.SS4.SSS3 "2.4.3 Big Data ‣ 2.4 DL Meets the Real World ‣ 2 Related
    work in CV ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories,
    Tools and Challenges for the Community")节中讨论的那样，至今已经提出了许多与大规模深度学习网络和大数据中的深度学习相关的数学、算法和硬件。然而，这一挑战离解决还有很远。到目前为止，大多数方法集中在RGB或RGBD数据的大数据挑战上，例如面部和物体检测或语音处理。关于遥感，我们面临与计算机视觉相似的许多问题，但也存在与不同传感器和数据相关的独特挑战。首先，我们可以将大数据分解为不同的所谓“部分”，例如体积、种类和速度。关于深度置信网络（DBNs）、卷积神经网络（CNNs）、自编码器（AEs）等，我们主要关注的是创建新的、健壮的和分布式的数学、算法和硬件，这些可以处理来自不同来源（如传感器、人工和机器）的大量、缺失、噪声数据流。这意味着能够将图像静帧、视频、音频、文本等与符号和语义变异相结合。此外，我们还需要实时评估和可能的在线学习。由于深度学习中的大数据是一个庞大的话题，我们在这里将重点关注遥感中的独特因素。'
- en: The first factor that we focus on is high spatial and more-so spectral dimensionality.
    Traditional DLs operate on relatively small grayscale or RGB imagery. However,
    SAR imagery has challenges due to noise, and MSI and HSI can have from four to
    hundreds to possibly thousands of channels. As Arel et al. [[7](#bib.bib7)] pointed
    out, a very difficult question is how well DL architectures scale with dimensionality.
    To date, preliminary research has tried to combat dimensionality by applying dimensionality
    reduction or feature selection prior to DL, e.g., Benediktsson et al. [[365](#bib.bib365)]
    reference different band selection, grouping, feature extraction and subspace
    identification in HSI remote sensing.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关注的第一个因素是高空间和更高的光谱维度。传统的深度学习（DL）处理的是相对较小的灰度或RGB图像。然而，SAR图像由于噪声而面临挑战，而多光谱成像（MSI）和高光谱成像（HSI）可能拥有从四个到数百甚至可能上千个通道。正如Arel等人[[7](#bib.bib7)]指出的那样，一个非常困难的问题是深度学习架构在维度扩展方面的表现如何。迄今为止，初步研究尝试通过在深度学习之前应用降维或特征选择来应对维度问题，例如，Benediktsson等人[[365](#bib.bib365)]在HSI遥感中参考了不同的波段选择、分组、特征提取和子空间识别。
- en: Ironically, most RS areas suffer from a lack of training data. Whereas they
    may have massive amounts of temporal and spatial data, there may not be the seasonal
    variations, times of day, object variation (e.g., plants, crops, etc.), and other
    factors that ultimately lead to sufficient variety needed to train a DL model.
    For example, most online hyperspectral data sets have little-to-no variety and
    it is questionable about what they are, and really can at that, learn. In stark
    contrast, most DL systems in CV use very large training sets, e.g., millions or
    billions of faces in different illuminations, poses, inner class variations, etc.
    Unless the remote sensing DL applies a method like transfer learning, DL in RS
    often have very limited training data. For example, in [[170](#bib.bib170)] Ma
    et at. tried to address this challenge by developing a new prior to deal with
    the instability of parameter estimation for HSI classification with small training
    samples. The SAE is modified by adding the relative distance prior in the fine-tuning
    process to cluster the samples with the same label and separate the ones with
    different labels. Instead of minimizing classification error, this network enforces
    intra-class compactness and attempts to increase inter-class discrepancy.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 具有讽刺意味的是，大多数遥感领域都缺乏训练数据。尽管它们可能拥有大量的时间和空间数据，但可能缺乏季节性变化、时间段、物体变异（例如，植物、作物等）以及其他因素，这些因素最终会导致训练深度学习模型所需的足够多样性。例如，大多数在线高光谱数据集几乎没有多样性，对于它们能学习到什么内容存在疑问。与之形成鲜明对比的是，大多数计算机视觉领域的深度学习系统使用非常大的训练集，例如，数百万或数十亿张不同光照、姿态、内部类变化等的面孔。除非遥感深度学习应用了类似迁移学习的方法，否则遥感领域的深度学习通常拥有非常有限的训练数据。例如，在[[170](#bib.bib170)]中，Ma
    等人尝试通过开发一种新的先验来应对小样本训练下高光谱图像分类参数估计的不稳定性。该 SAE 通过在微调过程中添加相对距离先验来对样本进行聚类，以便将具有相同标签的样本聚集在一起，并分开不同标签的样本。这个网络不是最小化分类错误，而是强化了类内紧凑性，并试图增加类间差异。
- en: 4.4 Non-traditional heterogeneous data sources
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 非传统异构数据源
- en: 'Open Question #4a: How can DL work with non-traditional data sources?'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '开放问题 #4a：深度学习如何处理非传统数据源？'
- en: Non-traditional data sources, such a twitter, YouTube, etc. offer data that
    can be useful to RS. These methods will probably never replace RS, but usually
    offer benefits to augment RS data, or provide quality real-time data before RS
    methods, which usually take longer, can provide RS-based data.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 非传统数据源，如 Twitter、YouTube 等，提供的数据对遥感可能有用。这些方法可能永远无法替代遥感，但通常能提供增强遥感数据的好处，或者在遥感方法（通常需要更长时间）能够提供基于遥感的数据之前，提供高质量的实时数据。
- en: Fohringer et al. [[366](#bib.bib366)] utilized information extracted from social
    media photos to enhance RS data for flood assessments. They found one major challenge
    was filtering posts to a manageable amount of relevant ones to further assess.
    The data from Twitter and Flickr proved useful for flood depth estimation prior
    to RS-based methods, which typically take 24-28 hours. Frias-Martinez et al. [[367](#bib.bib367)]
    take advantage of large amounts of geolocated content in social media by analyzing
    Twitter tweets as a complimentary source of data for urban land-use planning.
    Data from Manhattan (New York, USA), London (UK), and Madrid (Spain) was analyzed
    using a self-organizing map [[368](#bib.bib368)] followed by a Voronoi tesselation.
    Middleton et al. [[369](#bib.bib369)] match geolocated tweets and created real-time
    crisis maps via statistical analysis, which are compared to the US National Geospatial
    Agency post-event impact assessments. A major issue is that only about $1\%$ of
    tweets contain geolocation data. The tweets usually follow a pattern of a small
    number of first-hand reports and many re-tweets and comments. High-precision results
    were obtained. Singh et al. [[370](#bib.bib370)] aggregate user’s social interest
    about any particular theme from any particular location into so called “social
    pixels”, which are amenable to media processing techniques (e.g., segmentation,
    convolution), which allow semantic information to be derived. They also developed
    a declarative operator set to allow queries to visualize, characterize, and analyze
    social media data. Their approach would be a promising front-end to any social
    media analysis system. In the survey paper of Sui and Goodchild [[371](#bib.bib371)]
    , the convergence of Geographic Information System (GIS) and social media are
    examined. They observed that GIS has moved from software helping a user at a desk
    to a means of communicating earth surface data to the masses (e.g. OpenStreetMap,
    Google Maps, etc.).
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: Fohringer 等人 [[366](#bib.bib366)] 利用从社交媒体照片中提取的信息来增强用于洪水评估的遥感数据。他们发现一个主要挑战是将帖子筛选到一个可管理的相关数量，以便进一步评估。来自
    Twitter 和 Flickr 的数据在遥感方法之前，通常需要 24-28 小时的情况下，对于洪水深度估计 proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved proved proved proved proved
    proved proved proved proved proved proved proved proved-   Fohringer 等人 [[366](#bib.bib366)]
    利用从社交媒体照片中提取的信息来增强用于洪水评估的遥感数据。他们发现一个主要挑战是将帖子筛选到一个可管理的相关数量，以便进一步评估。来自 Twitter 和
    Flickr 的数据在遥感方法通常需要 24-28 小时的情况下，证明了在洪水深度估计中的有效性。Frias-Martinez 等人 [[367](#bib.bib367)]
    通过分析 Twitter 推文，利用社交媒体中大量的地理定位内容，作为城市土地使用规划的补充数据来源。使用自组织地图 [[368](#bib.bib368)]
    和 Voronoi 分割分析了来自曼哈顿（美国纽约）、伦敦（英国）和马德里（西班牙）的数据。Middleton 等人 [[369](#bib.bib369)]
    匹配了地理定位的推文，并通过统计分析创建了实时危机地图，这些地图与美国国家地理空间情报局的事件后影响评估进行了比较。一个主要问题是只有大约 $1\%$ 的推文包含地理定位数据。这些推文通常遵循少量的第一手报告和大量的转发和评论的模式。取得了高精度的结果。Singh
    等人 [[370](#bib.bib370)] 将用户对特定主题的社交兴趣从特定地点汇聚成所谓的“社交像素”，这些像素适用于媒体处理技术（例如，分割、卷积），从而可以推导出语义信息。他们还开发了一组声明性操作符，以便查询、可视化、描述和分析社交媒体数据。他们的方法将成为任何社交媒体分析系统的一个有前途的前端。在
    Sui 和 Goodchild 的调查论文 [[371](#bib.bib371)] 中，探讨了地理信息系统（GIS）与社交媒体的融合。他们观察到 GIS
    从帮助用户在桌面上的软件，转变为向大众传达地球表面数据的手段（例如 OpenStreetMap、Google Maps 等）。
- en: In all of the above mentioned methods, DL can play a significant role of parsing
    data, analyzing data and estimating results from the data. It seems that social
    media is not going away, and data from social media can often be used to augment
    RS data in many applications. Thus the question is what novel work awaits the
    researcher in the area of using DL to combine non-traditional data sources with
    RS?
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述所有方法中，深度学习可以在数据解析、数据分析和结果估计中发挥重要作用。社交媒体似乎不会消失，而且社交媒体中的数据经常可以用于增强遥感数据在许多应用中的效果。因此，问题是，研究人员在使用深度学习结合非传统数据源与遥感方面，还会遇到哪些新颖的工作？
- en: 'Open Question #4b: How does DL ingest heterogeneous data?'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '开放性问题 #4b：深度学习如何处理异构数据？'
- en: Fusion can take place at numerous so-called “levels”, including signal, feature,
    algorithm and decision. For example, Signal In Signal Out (SISO) is where multiple
    signals are used to produce a signal out. For $\Re$-valued signal data, a common
    example is the trivial concatenation of their underlying vectorial data, i.e.,
    $X=\{\hat{x}_{1},...,\hat{x}_{N}\}$ becomes $[\hat{x}_{1}\hat{x}_{2}...\hat{x}_{N}]$
    of length $|\hat{x}_{1}|+...+|\hat{x}_{N}|$. Feature In Feature Out (FIFO), which
    is often related to if not the same as SISO, is where multiple features are combined,
    e.g., a HOG and a Local Binary Pattern (LBP), and the result is a new feature.
    One example is Multiple Kernel Learning (MKL), e.g., $\ell$-$p$ norm genetic algorithm
    MKL (GAMKLp) [[372](#bib.bib372)] . Typically the input is $N$ $\Re$-valued Cartesian
    spaces and the result is a Cartesian space. Most often, one engages in MKL to
    search for space in which pattern obey some property, e.g., they are nicely linearly
    separable and a machine learning tool like a SVM can be employed. On the other
    hand, Decision In Decision Out (DIDO), e.g., the Choquet integral (ChI), is often
    used for the fusion of input from *decision makers*, e.g., human experts, algorithms,
    classifiers, etc. [[373](#bib.bib373)]. Technically speaking, a CNN is typically
    a Signal In Decision Out (SIDO) or Feature In Decision Out (FIDO) system. Internally,
    the *feature learning* part of the CNN is a SIFO or FIFO and the classifier is
    a FIDO. To date, most DL approaches have “fused” via (1) concatenation of $\Re$-valued
    input data (SISO or FIFO) relative to a single DL, (2) each source has its own
    DL, minus classification, that is later combined into a single DL, or (3) multiple
    DLs are used, one for each source, and their results are once again concatenated
    and subjected to the classifier (either a MLP, SVM or other classifier).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 融合可以发生在多个所谓的“层次”上，包括信号、特征、算法和决策。例如，信号输入信号输出（SISO）是指使用多个信号来生成一个输出信号。对于$\Re$-值信号数据，一个常见的例子是它们底层向量数据的简单连接，即$X=\{\hat{x}_{1},...,\hat{x}_{N}\}$变成$[\hat{x}_{1}\hat{x}_{2}...\hat{x}_{N}]$，长度为$|\hat{x}_{1}|+...+|\hat{x}_{N}|$。特征输入特征输出（FIFO），通常与SISO相关或相同，是指将多个特征组合在一起，例如HOG和局部二值模式（LBP），结果是一个新的特征。一个例子是多核学习（MKL），例如$\ell$-$p$范数遗传算法MKL（GAMKLp）[[372](#bib.bib372)]。通常输入是$N$个$\Re$-值的笛卡尔空间，结果是一个笛卡尔空间。通常，人们会进行MKL以搜索模式遵循某些属性的空间，例如它们是良好线性可分的，并且可以使用像SVM这样的机器学习工具。另一方面，决策输入决策输出（DIDO），例如Choquet积分（ChI），通常用于融合来自*决策者*的输入，例如人类专家、算法、分类器等[[373](#bib.bib373)]。从技术上讲，CNN通常是信号输入决策输出（SIDO）或特征输入决策输出（FIDO）系统。在内部，CNN的*特征学习*部分是SIFO或FIFO，分类器是FIDO。到目前为止，大多数DL方法通过（1）将$\Re$-值输入数据的连接（SISO或FIFO）相对于单一DL，（2）每个源都有自己的DL，去除分类，然后合并为一个单一DL，或（3）使用多个DL，每个源一个，然后将它们的结果再次连接并提交给分类器（MLP、SVM或其他分类器）。
- en: Herein, we highlight the challenges of syntactic and semantic fusion. Most DL
    approaches to date syntactically have addressed how $N$ things, which are typically
    homogeneous mathematically, can be ingested by a DL. However, the more difficult
    challenge is semantically how should these sources be combined, what is a proper
    architecture, what is learned (can we understand it) and why should we trust the
    solution. This is of particular importance to numerous challenges in remote sensing
    that require a physically meaningful/grounded solution, e.g., model-based approaches.
    The most typical example of fusion in remote sensing is the combining of data
    from two (or more) sensors. Whereas there may be semantic variation but little-to-no
    semantic variation, e.g., both are possibly $\Re$-valued vector data, the reality
    is most sensors record objective evidence about our universe. However, if human
    information (e.g., linguistic or text) is involved or algorithmic outputs (e.g.,
    binary decisions, labels/symbols, probabilities, etc.), fusion becomes increasingly
    more difficult syntactically and semantically. Many theoretical (mathematical
    and philosophical) investigations, which are beyond the scope of this work, have
    concerned themselves with how to meaningfully combine objective vs. subjective
    data/information, qualitative vs. quantitative data/information, or evidences
    with beliefs other numerous other flavors information. It is a naive and dangerous
    belief that one can simply just “cram” data/information into a DL and get a meaningful
    and useful result. How is fusion occurring? Where is it occurring? Fusion is further
    compounded if one is using uncertain information, e.g., probabilistic, possibilities,
    or other interval or distribution-based input. The point is, heterogeneous, be
    it mathematical representation, associated uncertainty, etc., is a real and serious
    challenge and if the DL community wishes to fuse multiple inputs or sources (humans,
    sensors and algorithms) then DL must theoretically rise to the occasion to ensure
    that the architectures and what is subsequently being learned is useful and meaningful.
    Example, and really preliminary at that, associated DL works to date include fusing
    hyperspectral with LiDAR [[374](#bib.bib374)] (two sensors yielding objective
    data) and text with imagery or video [[375](#bib.bib375)] (thus high-level human
    information sensor data), to name a few. The point is, the question remains, how
    can/does DL fuse data/information arising from one or more sources?
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们突出了句法和语义融合的挑战。迄今为止，大多数 DL 方法在句法上已经解决了 $N$ 个通常在数学上是同质的事物如何被 DL 吸收的问题。然而，更困难的挑战在于语义上如何将这些来源结合起来，什么是适当的架构，学到了什么（我们能理解吗）以及我们为何应该信任这个解决方案。这对许多需要物理上有意义/有根源的解决方案的遥感挑战尤为重要，例如基于模型的方法。遥感中最典型的融合例子是将来自两个（或更多）传感器的数据结合起来。虽然可能存在语义变异，但语义变化很小，例如，两个可能都是
    $\Re$-值向量数据，现实是大多数传感器记录了关于我们宇宙的客观证据。然而，如果涉及人类信息（例如语言或文本）或算法输出（例如二元决策、标签/符号、概率等），融合在句法和语义上变得越来越困难。许多理论（数学和哲学）研究，这些超出了本工作的范围，关注如何有意义地结合客观与主观数据/信息、定性与定量数据/信息，或证据与信念等其他多种信息。认为可以简单地将数据/信息“填充”到
    DL 中并获得有意义和有用的结果是一种幼稚且危险的信念。融合是如何发生的？在哪里发生？如果使用不确定的信息，例如概率、可能性或其他区间或分布型输入，融合问题会进一步复杂化。关键是，无论是数学表示、相关不确定性等，异质性都是一个真实且严重的挑战。如果
    DL 社区希望融合多个输入或来源（人类、传感器和算法），那么 DL 必须在理论上迎接挑战，以确保架构和随后的学习结果是有用且有意义的。例如，到目前为止，与
    DL 相关的初步工作包括融合高光谱与 LiDAR [[374](#bib.bib374)]（两个传感器产生的客观数据）和文本与图像或视频 [[375](#bib.bib375)]（因此是高层次的人类信息传感器数据），仅举几例。关键问题是，DL
    如何/是否融合来自一个或多个来源的数据/信息？
- en: 4.5 DL architectures and learning algorithms for spectral, spatial and temporal
    data
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 DL 架构和学习算法用于光谱、空间和时间数据
- en: 'DL Open Question #5: What architectural extensions will DL systems require
    in order to tackle complicated RS problems?'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 'DL 开放问题 #5：DL 系统需要什么架构扩展才能处理复杂的 RS 问题？'
- en: 'Current DL architectures, components (e.g. convolution), and optimization techniques
    may not be adequate to solve complex RS problems. In many cases, researchers have
    developed novel network architectures, new layer structures with their associated
    SGD or BP equations for training, or new combinations of multiple DL networks.
    This problem is also an open issue in the broader CV community. This question
    is at the heart of DL research. Other questions related to the open issues are:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的深度学习（DL）架构、组件（例如卷积）和优化技术可能不足以解决复杂的遥感（RS）问题。在许多情况下，研究人员已经开发出了新型网络架构、新的层结构及其关联的SGD或BP方程用于训练，或多种深度学习网络的新组合。这个问题在更广泛的计算机视觉（CV）社区中也是一个开放性问题。这个问题是深度学习研究的核心。与这些开放性问题相关的其他问题包括：
- en: •
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: What architecture should be used?
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 应该使用什么架构？
- en: •
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How deep should a DL system be, and what architectural elements will allow it
    to work at that depth?
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度学习系统应该有多深，什么样的架构元素能够使其在这个深度下有效工作？
- en: •
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: What architectural extensions (new components) are required to solve this problem?
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了解决这个问题，需要什么样的建筑扩展（新组件）？
- en: •
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: What training methods are required to solve this problem?
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解决这个问题需要什么样的训练方法？
- en: 'We examine several general areas where DL systems have evolved to handle RS
    data: (i) multi-sensor processing, (ii) utilizing multiple DL systems, (iii) Rotation
    and displacement-invariant DL systems, (iv) new DL architectures, (v) SAR, (vi)
    Ocean and atmospheric processing, (vii) 3D processing, (viii) spectral-spatial
    processing, and (ix) multi-temporal analysis. Furthermore, we examine some specific
    RS applications noted in several RS survey papers as areas that DL can benefit:
    (a) Oil spill detection, (b) pedestrian detection, (c) urban structure detection,
    (d) pixel unmixing, and (e) road extraction. This is by no means an exhaustive
    list, but meant to highlight some of the important areas.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查了几个深度学习系统已发展以处理遥感数据的领域：(i) 多传感器处理，(ii) 利用多个深度学习系统，(iii) 旋转和位移不变的深度学习系统，(iv)
    新的深度学习架构，(v) 合成孔径雷达（SAR），(vi) 海洋和大气处理，(vii) 3D处理，(viii) 光谱空间处理，以及 (ix) 多时相分析。此外，我们还考察了在几篇遥感综述论文中提到的一些深度学习可以受益的特定遥感应用：(a)
    油污检测，(b) 行人检测，(c) 城市结构检测，(d) 像素解混，和 (e) 道路提取。这并不是一个详尽无遗的列表，而是旨在突出一些重要领域。
- en: 'Multi-Sensor Processing: Chen et al. [[191](#bib.bib191)] utilize two deep
    networks, one analyzing HSI pixel neighbors (spatial data), and the other LiDAR
    data. The outputs are stacked and a FC and logistic regression lay provides outputs.
    Huang et al. [[236](#bib.bib236)] use a modified sparse DAE (MSDAE) to train the
    relationship between HR and LR image patches. The stacked MSDAE (S-MSDAE) are
    used to pretrain a DNN. The HR MSI image is then reconstructed from the observed
    LR MSI image using the trained DNN.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 多传感器处理：Chen等人[[191](#bib.bib191)]利用了两个深度网络，一个分析高光谱影像（HSI）像素邻域（空间数据），另一个分析激光雷达（LiDAR）数据。这些输出被堆叠在一起，通过全连接层和逻辑回归层提供结果。Huang等人[[236](#bib.bib236)]使用了修改后的稀疏去噪自编码器（MSDAE）来训练高分辨率（HR）和低分辨率（LR）图像块之间的关系。堆叠的MSDAE（S-MSDAE）用于预训练深度神经网络（DNN）。然后使用训练好的DNN从观测到的低分辨率MSI图像中重建高分辨率MSI图像。
- en: 'Multi-DL system: In certain problems, multiple DL systems can provide significant
    benefit. Chen et al. [[298](#bib.bib298)] utilize parallel DNNs with no cross-connections
    to both speed up processing and provide good results in vehicle detection from
    satellite imagery. Ciresan et al. [[119](#bib.bib119)] utilize multiple parallel
    DNNs that are averaged for image classification. Firth et al. [[311](#bib.bib311)]
    use 186 RNNs to perform accurate weather prediction. Hou et al. [[152](#bib.bib152)]
    use RBMs to train from polarimetric SAR data and a three-layer DBN is used for
    classification. Kira et al. [[376](#bib.bib376)] used stereo-imaging for robotic
    human detection, utilizing a CNN which was trained on appearance and stereo disparity-based
    features, and a second CNN, which is used for long-range detection. Marmanis et
    al. [[260](#bib.bib260)] utilized an ensemble of CNNs to segment VHR aerial imagery
    using a FCN to perform pixel-based classification. They trained multiple networks
    with different initializations and average the ensemble results. The authors also
    found errors in the dataset, Vaihingen [[377](#bib.bib377)] .'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 多重深度学习系统：在某些问题中，多重深度学习系统可以提供显著的好处。Chen等人[[298](#bib.bib298)] 使用了多个没有交叉连接的并行深度神经网络（DNN），以加快处理速度并在卫星图像中的车辆检测中提供良好的结果。Ciresan等人[[119](#bib.bib119)]
    使用了多个并行的DNN，这些DNN经过平均用于图像分类。Firth等人[[311](#bib.bib311)] 使用了186个递归神经网络（RNN）进行准确的天气预测。Hou等人[[152](#bib.bib152)]
    使用了限制玻尔兹曼机（RBM）从极化SAR数据中进行训练，并使用三层深度信念网络（DBN）进行分类。Kira等人[[376](#bib.bib376)] 使用了立体成像进行机器人人体检测，采用了在外观和立体视差特征上训练的CNN，并且使用了一个用于长距离检测的第二个CNN。Marmanis等人[[260](#bib.bib260)]
    利用CNN的集成来分割超高分辨率（VHR）航空影像，使用全卷积网络（FCN）进行基于像素的分类。他们训练了多个网络，使用不同的初始化方法，并对集成结果进行了平均。作者还发现了数据集中存在错误，Vaihingen[[377](#bib.bib377)]。
- en: 'Rotation- and displacement-invariant systems: Some RS problems require systems
    that are rotation and displacement-invariant. CNNs have some robustness to translation,
    but not in general to rotations. Cheng et al. [[226](#bib.bib226)] incorporated
    a rotation-invarint layer into a DL CNN architecture to detect objects in satellite
    imagery. Du et al. [[127](#bib.bib127)] developed a displacement- and rotation-insensitive
    deep CNN for SAR Automated Target Recognition (ATR) processing that is trained
    by augmented dataset and specialized training procedure.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 旋转和位移不变系统：一些遥感问题需要系统具备旋转和位移不变性。卷积神经网络（CNN）对平移具有一定的鲁棒性，但对旋转则通常不够鲁棒。Cheng等人[[226](#bib.bib226)]
    在深度学习CNN架构中引入了一个旋转不变层，以检测卫星图像中的物体。Du等人[[127](#bib.bib127)] 开发了一种位移和旋转不敏感的深度CNN，用于SAR自动目标识别（ATR）处理，该CNN通过增强数据集和专业的训练程序进行训练。
- en: 'Novel DL architectures: Some problems in RS require novel DL architectures.
    Dong et al. [[277](#bib.bib277)] use a CNN that takes the LR image and outputs
    the HR image. He et al. [[151](#bib.bib151)] proposed a deep stacking network
    for HSI classification that utilizes nonlinear activations in the hidden layers
    and does not require SGD for training. Kontschieder et al. [[156](#bib.bib156)]
    developed deep neural decision forests, which uses a stochastic and differentiable
    decision tree model that steers the representation learning usually conducted
    in the initial layers of a deep CNN. Lee et al. [[158](#bib.bib158)] analyze HSI
    by applying multiple local 3D convolutional filters of different sizes jointly
    exploiting spatial and spectral features, followed by a fully-convolutional layers
    to predict pixel classes. Zhang et al. [[186](#bib.bib186)] propose GBRCN to classify
    VHR satellite imagery. Ouyang et al. [[202](#bib.bib202)] developed a probabilistic
    parts-detector based model to robustly handle human detection with occlusions
    are large deformations utilizing a discriminative RBM to learn the visibility
    relationship among overlapping parts. The RBM has three layers that handle different
    size parts. Their results can possibly be improved by adding additional rotation
    invariance.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 新颖的深度学习架构：一些遥感问题需要新颖的深度学习架构。Dong等人[[277](#bib.bib277)] 使用了一个CNN，该CNN接受低分辨率图像并输出高分辨率图像。He等人[[151](#bib.bib151)]
    提出了一个用于高光谱图像分类的深度堆叠网络，该网络在隐藏层中利用了非线性激活，并且不需要随机梯度下降（SGD）进行训练。Kontschieder等人[[156](#bib.bib156)]
    开发了深度神经决策森林，这是一种使用随机且可微分的决策树模型来引导表示学习的模型，通常在深度CNN的初始层中进行。Lee等人[[158](#bib.bib158)]
    通过应用多个不同尺寸的局部3D卷积滤波器，联合利用空间和光谱特征，然后通过全卷积层预测像素类别，来分析高光谱图像。Zhang等人[[186](#bib.bib186)]
    提出了GBRCN来分类超高分辨率卫星影像。Ouyang等人[[202](#bib.bib202)] 开发了一种基于概率部分检测器的模型，利用区分性RBM来学习重叠部分之间的可见性关系，从而稳健地处理具有遮挡和大变形的人体检测。RBM具有处理不同尺寸部件的三层。他们的结果可能通过增加额外的旋转不变性来进一步改进。
- en: 'Novel DL SAR architectures: SAR imagery has unique challenges due to noise
    and the grainy nature of the images. Geng et al. [[149](#bib.bib149)] developed
    a deep convolutional AE, which is a combination of a CNN, AE, classification,
    and post-processing layers to classify high-resolution SAR images. Hou et al.
    [[152](#bib.bib152)] developed a polarimetric SAR DBN. Filters are extracted from
    the RBMs and a final three-layer DBN performs classification. Liu et al. [[210](#bib.bib210)]
    utilize a Deep Sparse Filtering Network to classify terrain using polarimetric
    SAR data. The proposed network is based on sparse filtering [[378](#bib.bib378)]
    , and the proposed network performs a minimization on the output $L_{1}$ norm
    to enforce sparsity. Qin et al. [[178](#bib.bib178)] performed object-oriented
    classification of polarimetric SAR data using a RBM and built an adaptive boosting
    framework (AdaBoost [[379](#bib.bib379)] ) vice a stacked DBN in order to handle
    small training data. They also put forth the RBM-AdaBoost algorithm. Schwegmann
    et al. [[273](#bib.bib273)] utilized a very deep Highway Network configuration
    as a ship discrimination stage for SAR ship detection. They also presented a three-class
    SAR dataset that allows for more meaningful analysis of ship discrimination performances.
    Zhou et al. [[380](#bib.bib380)] proposed a three-class change detection approach
    for multitemporal SAR images using a RBM. These images either have increases or
    decreases in the backscattering values for changes, so the proposed approach classifies
    the changed areas into the positive and negative change classes, or no change
    if none is detected.'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 新颖的深度学习合成孔径雷达（SAR）架构：SAR 图像由于噪声和图像的颗粒状特性面临独特的挑战。Geng 等人 [[149](#bib.bib149)]
    开发了一种深度卷积自编码器（AE），它结合了卷积神经网络（CNN）、自编码器（AE）、分类和后处理层，用于分类高分辨率 SAR 图像。Hou 等人 [[152](#bib.bib152)]
    开发了一种极化 SAR 深度玻尔兹曼机（DBN）。从受限玻尔兹曼机（RBM）中提取的过滤器与最终的三层 DBN 一起进行分类。Liu 等人 [[210](#bib.bib210)]
    利用深度稀疏过滤网络来分类使用极化 SAR 数据的地形。所提议的网络基于稀疏过滤 [[378](#bib.bib378)] ，并对输出的 $L_{1}$ 范数进行最小化以强制稀疏性。Qin
    等人 [[178](#bib.bib178)] 使用 RBM 对极化 SAR 数据进行面向对象的分类，并构建了自适应增强框架（AdaBoost [[379](#bib.bib379)]
    ）以处理小样本训练数据。他们还提出了 RBM-AdaBoost 算法。Schwegmann 等人 [[273](#bib.bib273)] 利用非常深的高速公路网络配置作为
    SAR 船舶检测的船舶鉴别阶段。他们还展示了一个三类 SAR 数据集，以便对船舶鉴别性能进行更有意义的分析。Zhou 等人 [[380](#bib.bib380)]
    提出了一个基于 RBM 的三类变化检测方法，用于多时相 SAR 图像。这些图像中的反向散射值会发生增加或减少，因此所提议的方法将变化区域分类为正变化和负变化类，如果没有检测到变化则标记为无变化。
- en: 'Oceanic and atmospheric studies: Oceanic and atmospheric studies present unique
    challenges to DL systems that require novel developments. Ducournau et al. [[278](#bib.bib278)]
    developed a CNN architecture, which analyzes sea surface temperature fields and
    provides a significant gain in terms of peak signal-to-noise ratio compared to
    classical downscaling techniques. Shi et al. [[198](#bib.bib198)] extended the
    FC-LSTM network that they call ConvLSTM, which has convolutional structures in
    the input-to-state and state-to-state transitions for precipitation nowcasting.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 海洋和大气研究：海洋和大气研究对深度学习系统提出了独特的挑战，需要新的发展。Ducournau 等人 [[278](#bib.bib278)] 开发了一种卷积神经网络（CNN）架构，该架构分析海面温度场，并在峰值信噪比方面相较于经典的降尺度技术提供了显著的提升。Shi
    等人 [[198](#bib.bib198)] 扩展了他们称之为 ConvLSTM 的全连接长短期记忆网络（FC-LSTM），该网络在降水短期预报中具有输入到状态和状态到状态转换中的卷积结构。
- en: '3D Processing: Guan et al. [[239](#bib.bib239)] use voxel-based filtering removes
    ground points from LiDAR data, then a DL architecture generates high-level features
    from the trees’ 3D geometric structure. Haque et al. [[109](#bib.bib109)] utilize
    both of CNN and RNN to process 4D spatio-temporal signatures to idenify humans
    in the dark.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 三维处理：Guan 等人 [[239](#bib.bib239)] 使用基于体素的过滤方法从 LiDAR 数据中移除地面点，然后使用深度学习架构从树木的三维几何结构中生成高级特征。Haque
    等人 [[109](#bib.bib109)] 利用卷积神经网络（CNN）和递归神经网络（RNN）处理 4D 时空特征，以在黑暗中识别人体。
- en: 'Spectral-spatial HSI processing: HSI processing can be improved by fusion of
    spectral and spatial information. Ma et al. [[169](#bib.bib169)] propose a spatial
    updated deep AE which adds a similarity regularization term to the energy function
    to enforce spectral similarity. The regularization terms is a a cosine similarity
    term (basically the spectral angle mapper) between the edges of a graph, which
    the nodes are samples, which enforces keeping the sample correlations. Ran et
    al. [[192](#bib.bib192)] classify HSI data by learning multiple CNN-based submodels
    for each correlated set of bands, while in parallel a conventional CNN learns
    spatial-spectral characteristics. The models are combined at the end. Li et al.
    [[162](#bib.bib162)] incorporated vicinal pixel information by combining the center
    pixel and vicinal pixels, and utilizing a voting strategy to classify the pixels.'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 光谱-空间 HSI 处理：通过融合光谱和空间信息，可以改善 HSI 处理。Ma 等人 [[169](#bib.bib169)] 提出了一个空间更新深度自编码器（AE），该编码器在能量函数中添加了一个相似性正则化项，以强制保持光谱相似性。这个正则化项是图形边缘之间的余弦相似度项（基本上是光谱角映射器），图的节点是样本，这样可以强制保持样本相关性。Ran
    等人 [[192](#bib.bib192)] 通过为每组相关的波段学习多个基于 CNN 的子模型来对 HSI 数据进行分类，同时一个传统的 CNN 并行地学习空间-光谱特征。这些模型在最后被结合在一起。Li
    等人 [[162](#bib.bib162)] 通过结合中心像素和邻近像素，并利用投票策略来分类像素，从而融入了邻近像素信息。
- en: 'Multi-temporal analysis: Multi-temporal analysis is a subset of RS analysis
    that has its own challenges. Data revisit rates are often long, and ground-truth
    data is even more expensive as multiple imagery sets have to be analyzed, and
    images must be co-registered for most applications.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 多时相分析：多时相分析是遥感分析的一个子集，具有其自身的挑战。数据重访率通常较长，地面实况数据更为昂贵，因为必须分析多个影像集，并且在大多数应用中图像必须共同注册。
- en: Jianya et al. [[25](#bib.bib25)] review multi-temporal analysis, and observe
    that it is hard, the changes are often non-linear, and changes occur on different
    timescales (seasons, weeks, years, etc.). The process from ground objects to images
    is not reversible, and image change to earth change is a very difficult task.
    Hybrid method involving classification, object analysis, physical modeling, and
    time series analysis can all potentially benefit from DL approaches. Arel et al.
    [[7](#bib.bib7)] ask if DL frameworks can understand trends over short, medium
    and long times? This is an open question for RNNs.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: Jianya 等人 [[25](#bib.bib25)] 综述了多时相分析，并观察到这一过程是困难的，因为变化通常是非线性的，并且变化发生在不同的时间尺度（季节、周、年等）。从地面对象到图像的过程是不可逆的，而图像变化到地球变化是一个非常困难的任务。涉及分类、对象分析、物理建模和时间序列分析的混合方法都有可能从深度学习（DL）方法中受益。Arel
    等人 [[7](#bib.bib7)] 询问深度学习框架是否能够理解短期、中期和长期的趋势？这是一个 RNN 的开放问题。
- en: Change detection is an important subset of multi-temporal analysis. Hussain
    et al. [[24](#bib.bib24)] state that change detection can benefit from texture
    analysis, accurate classifications, and ability to detect anomalies. DL has huge
    potential to address these issues, but it is recognized that DL algorithms are
    not common in image processing software in this field and large training sets
    and large training times may also be required. In cases of non-normal distributions,
    ANNs have shown superior results to other statistical methods. They also recognize
    that DL-based change detection can go beyond traditional pixel-based change detection
    methods. Tewkesbury et al. [[381](#bib.bib381)] observe that change detection
    can occur at the pixel, kernel (group of pixels), image-object, multi-temporal
    image-object (created by segmenting over time series), vector-polygon, and hybrid.
    While the pixel level is suitable for many applications, hybrid approaches can
    yield better results in many cases. Approaches to change detection can utilize
    DL to (1) co-register images and (2) detect changes at hierarchical (e.g. more
    than just pixel levels).
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 变化检测是多时相分析的一个重要子集。Hussain 等人 [[24](#bib.bib24)] 认为变化检测可以从纹理分析、准确分类和检测异常的能力中受益。深度学习在解决这些问题方面具有巨大的潜力，但已认识到深度学习算法在该领域的图像处理软件中并不常见，可能还需要大规模的训练集和较长的训练时间。在非正常分布的情况下，人工神经网络（ANNs）已显示出优于其他统计方法的结果。他们还认识到，基于深度学习的变化检测可以超越传统的基于像素的变化检测方法。Tewkesbury
    等人 [[381](#bib.bib381)] 观察到，变化检测可以发生在像素、核（像素组）、图像-对象、多时相图像-对象（通过时间序列分割创建）、矢量-多边形以及混合层级上。虽然像素级适用于许多应用，但混合方法在许多情况下可以产生更好的结果。变化检测的方法可以利用深度学习来
    (1) 共同注册图像和 (2) 在层次结构（例如，不仅仅是像素级别）上检测变化。
- en: 'Some selected specific applications that can benefit from DL analysis: This
    section discusses some selected applications where DL can benefit the results.
    This is by no means an exhaustive list, and many other areas can potentially benefit
    from DL approaches. In oil spill detection, Brekke et al. [[382](#bib.bib382)]
    point out that training data is scarce. Oil spills are very rare, which usually
    means oil spill detection approaches are anomaly detectors. Physical proximity,
    slick shape, and texture play important roles. SAR imagery is very useful, but
    there are look-alike phenomena that cause false positives. Algal information fusion
    from optical sensors and probability models can aid detection. Current algorithms
    are not reliable, and DL has great promise in this area.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 一些特定的应用可以从深度学习分析中受益：本节讨论了一些可以从深度学习中受益的应用。这并不是一个详尽无遗的列表，许多其他领域也可能从深度学习方法中受益。在石油泄漏检测中，Brekke
    等人 [[382](#bib.bib382)] 指出训练数据稀缺。石油泄漏非常稀少，这通常意味着石油泄漏检测方法是异常检测器。物理接近性、油污形状和纹理扮演重要角色。SAR
    影像非常有用，但存在类似现象导致假阳性。来自光学传感器和概率模型的藻类信息融合可以辅助检测。目前的算法不可靠，深度学习在这一领域有很大潜力。
- en: In the area of pedestrian detection, Dollar et al. [[21](#bib.bib21)] discuss
    that many images with pedestrians have only a small number of pixels. Robust detectors
    must handle occlusions. Motion features can achieve very high performance, but
    few have utilized them. Context (ground plane) approaches are needed, especially
    at lower resolutions. More datasets are needed, especially with occlusions. Again,
    DL can provide significant results in this area.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在行人检测领域，Dollar 等人 [[21](#bib.bib21)] 讨论了许多含有行人的图像只有少量像素。稳健的检测器必须处理遮挡问题。运动特征可以达到非常高的性能，但很少有人利用这些特征。需要背景（地面平面）方法，尤其是在较低分辨率下。需要更多的数据集，特别是包含遮挡的。深度学习在这一领域可以提供显著的结果。
- en: For urban structure analysis, Mayer et al. [[383](#bib.bib383)] report that
    scale-space analysis is required due to different scales of urban structures.
    Local contexts can be utilized in the analysis. Analyzing parts (dormers, windows,
    etc) can improve results. Sensor fusion can aid results. Object variability is
    not treated sufficiently (e.g. highly non-planar roofs). The DL system’s ability
    to learn hierarchical components and learn parts makes is a good candidate for
    improving results in this area.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 对于城市结构分析，Mayer 等人 [[383](#bib.bib383)] 报告说，由于城市结构的不同尺度，需要进行尺度空间分析。分析中可以利用局部背景。分析部分（如天窗、窗户等）可以改善结果。传感器融合可以帮助提高结果。对象的变异性处理不足（例如，高度非平面的屋顶）。深度学习系统学习分层组件和部件的能力使其成为改善这一领域结果的良好候选者。
- en: In pixel unmixing, Shi et al. [[34](#bib.bib34)] and Somers et al. [[384](#bib.bib384)]
    review papers both point out that whether an unmixing system uses a spectral library
    or extracts endmembers spectra from the imagery, the accuracy highly depends on
    the selection of appropriate endmembers. Adding information from a spatial neighborhood
    can enhance the unmixing results. DL methods such as CNNs or other tailored systems
    can potentially inherently combine spectral and spatial information. DL systems
    utilizing denoising, iterative unmixing, feature selection, spectral weighting,
    and spectral transformations can benefit unmixing.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在像素解混中，Shi 等人 [[34](#bib.bib34)] 和 Somers 等人 [[384](#bib.bib384)] 的综述论文都指出，无论解混系统使用光谱库还是从影像中提取端元光谱，准确性都高度依赖于适当端元的选择。添加空间邻域的信息可以增强解混结果。深度学习方法如
    CNNs 或其他定制系统可以潜在地将光谱和空间信息结合起来。利用去噪、迭代解混、特征选择、光谱加权和光谱变换的深度学习系统可以使解混受益。
- en: Finally in the area of road extraction, Wang et al. [[337](#bib.bib337)] point
    out that roads can have large variability, are often curves, and can change size.
    In bad weather, roads can be very hard to identify. Object shadows, occlusions,
    etc. can cause the road segmentation to miss sections. Multiple models and multiple
    features can improve results. The natural ability of DL to learn complicated hierarchical
    features from data makes them a good candidate for this application area also.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在道路提取领域，Wang 等人 [[337](#bib.bib337)] 指出道路具有较大的变异性，通常是曲线，并且可能会改变大小。在恶劣天气条件下，道路可能很难识别。对象阴影、遮挡等可能导致道路分割遗漏部分。多个模型和多个特征可以改善结果。深度学习自然从数据中学习复杂分层特征的能力也使其成为这一应用领域的良好候选者。
- en: 4.6 Transfer Learning
  id: totrans-347
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 迁移学习
- en: 'Open Question #6: How can DL in RS successfully utilize transfer learning?'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '开放问题 #6：深度学习如何在遥感中成功利用迁移学习？'
- en: 'In general, we note that transfer learning is also an open question in DL in
    general, not just in DL related to remote sensing. Section [4.9](#S4.SS9 "4.9
    Training ‣ 4 Unsolved challenges and opportunities for DL in RS ‣ A Comprehensive
    Survey of Deep Learning in Remote Sensing: Theories, Tools and Challenges for
    the Community") discusses transfer learning in the broader contect of the entire
    field of DL, which this section discusses transfer learning in a RS context.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '总的来说，我们注意到迁移学习在深度学习领域也是一个未解的问题，不仅仅是与遥感相关的深度学习。第 [4.9](#S4.SS9 "4.9 Training
    ‣ 4 Unsolved challenges and opportunities for DL in RS ‣ A Comprehensive Survey
    of Deep Learning in Remote Sensing: Theories, Tools and Challenges for the Community")
    节讨论了在整个深度学习领域的更广泛背景下的迁移学习，本节则讨论了遥感背景下的迁移学习。'
- en: 'According to Tuia et al. [[385](#bib.bib385)] and Pan et al. [[28](#bib.bib28)]
    , transfer learning seeks to learn from one area to another in one of four ways:
    instance-transfer, feature-representation transfer, parameter transfer, and relational-knowledge
    transfer. Typically in remote sensing, when changing sensors or changing to a
    different part of a large image or other imagery collected at different times,
    the transfer fails. Remote sensing systems need to be robust, but doesn’t necessarily
    require near-perfect knowledge. Transfer between HSI images where the number and
    types of endmembers are different has very few studies. Ghazi et al. [[238](#bib.bib238)]
    suggest that two options for transfer learning are to (1) utilize pre-trained
    network and learn new features in the imagery to be analyzed, or (2) fine-tune
    the weights of the pre-trained network using the imagery to be analyzed. The choice
    depends on the size and similarity of the training and testing datasets.'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Tuia 等人 [[385](#bib.bib385)] 和 Pan 等人 [[28](#bib.bib28)] 的研究，迁移学习有四种方式：实例迁移、特征表示迁移、参数迁移和关系知识迁移。在遥感中，通常在更换传感器或切换到大图像的不同部分或在不同时间收集的其他影像时，迁移会失败。遥感系统需要具有鲁棒性，但不一定要求近乎完美的知识。当高光谱图像中的
    endmembers 数量和类型不同的情况下，迁移学习的研究非常少。Ghazi 等人 [[238](#bib.bib238)] 建议迁移学习的两种选择是（1）利用预训练网络并在待分析的影像中学习新特征，或（2）通过待分析的影像微调预训练网络的权重。选择取决于训练和测试数据集的大小和相似性。
- en: 'There are many open questions about transfer learning in HSI RS:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 关于高光谱遥感中的迁移学习，仍存在许多未解的问题：
- en: •
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How does HSI transfer work when the number and type of endmembers are different?
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当 endmembers 的数量和类型不同，高光谱遥感的迁移如何进行？
- en: •
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How can DL systems transfer low-level to mid-level features from other domains
    into RS?
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度学习系统如何将低级特征转移到中级特征，从其他领域应用到遥感中？
- en: •
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How can DL transfer learning be made robust to imagery collected at different
    times and under different atmospheric conditions?
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如何使深度学习的迁移学习在不同时间和不同大气条件下采集的影像中保持鲁棒性？
- en: 'Although in general these open questions remain, we do note that the following
    papers have successfully utilized transfer learning in RS applications: Yang et
    al. [[181](#bib.bib181)] trained on other remote sensing imagery and transferred
    low-level to mid-level features to other imagery. Othman et al. [[218](#bib.bib218)]
    utilized transfer learning by training on the ILSVRC-12 challenge data set, which
    has 1.2 million $224\times 224$ RGB images belonging to 1,000 classes. The trained
    system was applied to the UC Merced Land Use [[386](#bib.bib386)] and Banja-Luka
    [[387](#bib.bib387)] datasets. Iftene et al. [[154](#bib.bib154)] applied a pretrained
    CaffeNet and GoogleNet models on the ImageNet dataset, and then applying the results
    to the VHR imagery denoted the WHU-RS dataset [[388](#bib.bib388), [389](#bib.bib389)].
    Xie et al. [[293](#bib.bib293)] trained a CNN on night-time imagery and used it
    in a poverty mapping. Ghazi et al. [[238](#bib.bib238)] and Lee et al. [[390](#bib.bib390)]
    used a pre-trained networks AlexNet, GoogLeNet and VGGNet on the LifeCLEF 2015
    plant task dataset [[391](#bib.bib391)] and MalayaKew dataset [[392](#bib.bib392)]
    for plant identification. Alexandre [[223](#bib.bib223)] used four independent
    CNNs, one for each channel of RGBD, instead of using a single CNN receiving the
    four input channels. The four independent CNNs are then trained in a sequence
    by using the weights of a trained CNN as starting point to train the other CNNs
    that will process the remaining channels. Ding et al. [[393](#bib.bib393)] utilized
    transfer learning for automatic target recognition from mid-wave infrared (MWIR)
    to longwave IR (LWIR). Li et al. [[122](#bib.bib122)] used transfer learning by
    utilizing pixel-pairs based o reference data with labeled sampled using Airborne
    Visible / Infrared Imaging Spectrometer (AVIRIS) hyperspectral data.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些开放问题通常仍然存在，但我们注意到以下论文成功地在遥感应用中利用了迁移学习：Yang 等人 [[181](#bib.bib181)] 通过在其他遥感图像上训练，将低级到中级特征转移到其他图像上。Othman
    等人 [[218](#bib.bib218)] 利用迁移学习，通过在 ILSVRC-12 挑战数据集上训练，该数据集包含 120 万张 $224\times
    224$ RGB 图像，属于 1,000 个类别。训练后的系统被应用于 UC Merced 土地利用 [[386](#bib.bib386)] 和 Banja-Luka
    [[387](#bib.bib387)] 数据集。Iftene 等人 [[154](#bib.bib154)] 在 ImageNet 数据集上应用了预训练的
    CaffeNet 和 GoogleNet 模型，然后将结果应用于标记为 WHU-RS 数据集 [[388](#bib.bib388), [389](#bib.bib389)]
    的 VHR 图像。Xie 等人 [[293](#bib.bib293)] 在夜间图像上训练了一个 CNN 并用于贫困映射。Ghazi 等人 [[238](#bib.bib238)]
    和 Lee 等人 [[390](#bib.bib390)] 在 LifeCLEF 2015 植物任务数据集 [[391](#bib.bib391)] 和 MalayaKew
    数据集 [[392](#bib.bib392)] 上使用了预训练的网络 AlexNet、GoogLeNet 和 VGGNet 进行植物识别。Alexandre
    [[223](#bib.bib223)] 使用了四个独立的 CNN，每个 CNN 对应 RGBD 的一个通道，而不是使用一个接收四个输入通道的单一 CNN。然后，四个独立的
    CNN 通过使用训练好的 CNN 的权重作为起点来训练其他 CNN，从而按顺序进行训练，这些 CNN 将处理其余的通道。Ding 等人 [[393](#bib.bib393)]
    利用迁移学习实现了从中波红外（MWIR）到长波红外（LWIR）的自动目标识别。Li 等人 [[122](#bib.bib122)] 通过利用基于参考数据的像素对进行迁移学习，这些参考数据使用了
    Airborne Visible / Infrared Imaging Spectrometer (AVIRIS) 高光谱数据。
- en: 4.7 An improved theoretical understanding of DL systems
  id: totrans-359
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7 对深度学习系统的理论理解的改进
- en: 'DL Open Question #7: What new developments will allow researchers to better
    understand DL systems theoretically?'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '深度学习开放问题 #7：哪些新进展将使研究人员能够更好地从理论上理解深度学习系统？'
- en: 'The CV and NN image processing communities understand BP and SGD, but until
    recently, researchers struggled to train deep networks. One issue has been identified
    as vanishing or exploding gradients [[394](#bib.bib394), [395](#bib.bib395)] .
    Using normalized initialization and normalization layers can help alleviate this
    problem. Using special architectures, such as deep residual learning [[41](#bib.bib41)]
    or highway networks [[396](#bib.bib396)] feed data into the deeper layers, thus
    allowing very deep networks to be trained. FC networks [[320](#bib.bib320)] have
    achieved success in pixel-based semantic segmentation tasks, and are another alternative
    to going deep. Sokolić et al. [[397](#bib.bib397)] determined that the spectral
    norm of the NN’s Jacobian matrix in the neighbourhood of the training samples
    must be bounded in order for the network to generalize well. All of these methods
    deal with a central problem in training very deep NNs: The gradients must not
    vanish, explode, or become too uncorrelated, or else learning is severely hindered.'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: CV和NN图像处理社区理解BP和SGD，但直到最近，研究人员仍在为训练深度网络而挣扎。其中一个问题被确定为梯度消失或爆炸[[394](#bib.bib394)，[395](#bib.bib395)]。使用标准化初始化和标准化层可以帮助缓解这个问题。使用特殊架构，如深度残差学习[[41](#bib.bib41)]或高速公路网络[[396](#bib.bib396)]将数据输入更深的层，从而使非常深的网络能够进行训练。FC网络[[320](#bib.bib320)]在基于像素的语义分割任务中取得了成功，是另一个深度学习的替代方案。Sokolić等人[[397](#bib.bib397)]确定，为了使网络具有良好的泛化能力，NN的Jacobian矩阵在训练样本邻域的谱范数必须被界限。所有这些方法都涉及到训练非常深的NN中的一个核心问题：梯度不能消失、爆炸或变得过于不相关，否则学习将受到严重阻碍。
- en: The DL field needs practical (and theoretical) methods to go deep, and ways
    to train efficiently with good generalization capabilities. Many DL RS systems
    will probably require new components, and these networks with the new components
    need to be analyzed to see if the methods above (or new methods not yet invented)
    will enable efficient and robust network training. Egmont-Peterson et al. [[331](#bib.bib331)]
    point out that DL training is sensitive to the initial training samples, and it
    is a well-known problem in SGD and BP of potentially reaching a local minimum
    solution but not being at the global minimum. In the past, seminal papers such
    as Hinton’s [[398](#bib.bib398)] which allow efficient training of the network,
    allow researchers to break past a previously difficult barrier. What new algorithmic
    and theoretical developments will spur the next large surge in DL?
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: DL领域需要实际的（以及理论上的）方法来深入研究，并寻找高效训练且具有良好泛化能力的方法。许多DL推荐系统可能需要新的组件，而这些带有新组件的网络需要被分析，以确定上述方法（或尚未发明的新方法）是否能实现高效且稳健的网络训练。Egmont-Peterson等人[[331](#bib.bib331)]指出，DL训练对初始训练样本非常敏感，这在SGD和BP中是一个众所周知的问题，即可能达到局部最小值而非全局最小值。过去，像Hinton的[[398](#bib.bib398)]这样的开创性论文允许网络的高效训练，使研究人员能够突破之前难以逾越的障碍。哪些新的算法和理论发展将促进DL领域的下一个重大飞跃？
- en: 4.8 High barriers to entry
  id: totrans-363
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.8 高入门门槛
- en: 'DL Open Question #8: How to best handle high entry barriers to DL?'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 'DL开放问题 #8：如何最好地处理DL的高入门门槛？'
- en: Most DL papers assume that the reader is familiar with DL concepts, backpropagation,
    etc. This is in reality a steep learning curve that takes a long time to master.
    Good tutorials and online training can aid students and practitioners who are
    willing to learn. Implementing BP or SGD on a large DL system is a difficult task,
    and simple errors can be hard to determine. Furthermore, BP can fail in large
    networks, so alternate architectures such as highway nets are usually required.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数DL论文假设读者对DL概念、反向传播等已有了解。实际上，这是一个需要长时间掌握的陡峭学习曲线。良好的教程和在线培训可以帮助愿意学习的学生和从业者。在大型DL系统上实现BP或SGD是一项困难的任务，简单的错误可能难以确定。此外，BP在大型网络中可能失败，因此通常需要采用诸如高速公路网络等替代架构。
- en: Many DL systems have a large number of parameters to learn, and often require
    large amounts of training data. Computers with GPUs and GPU-capable DL programs
    can greatly benefit by offloading computations onto the GPUs. However, multi-GPU
    systems are expensive, and students often use laptops that cannot be equipped
    with a GPU. Some DL systems run under Microsoft Windows, while others run under
    variants of Linux (e.g. Ubuntu or Red Hat). Futhermore, DL systems are programmed
    in a variety of languages, including Matlab, C, C++, Lua, Python, etc. Thus practitioners
    and researchers have a potentially steep learning curve to create custom DL solutions.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 许多深度学习系统有大量的参数需要学习，并且通常需要大量的训练数据。配备GPU和支持GPU的深度学习程序的计算机可以通过将计算任务转移到GPU上来大大受益。然而，多GPU系统价格昂贵，学生们通常使用无法配备GPU的笔记本电脑。一些深度学习系统在Microsoft
    Windows下运行，而其他则在不同的Linux变种（如Ubuntu或Red Hat）下运行。此外，深度学习系统用多种语言编程，包括Matlab、C、C++、Lua、Python等。因此，实践者和研究人员在创建定制的深度学习解决方案时可能面临陡峭的学习曲线。
- en: Finally, the large variety of data types in remote sensing, including RGB imagery,
    RGBD imagery, MSI, HSI, SAR, LiDAR, stereo imagery, tweets, GPS data, etc., all
    of which may require different architectures of DL systems. Often, many of the
    tasks in the RS community require components that are not part of a standard DL
    library tool. A good understanding of DL systems and programming is required to
    integrate these components into off-the-shelf DL systems.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，遥感中的数据类型种类繁多，包括RGB图像、RGBD图像、MSI、HSI、SAR、LiDAR、立体图像、推文、GPS数据等，这些都可能需要不同架构的深度学习系统。通常，遥感社区中的许多任务需要的组件不在标准深度学习库工具中。需要对深度学习系统和编程有良好的理解，以将这些组件集成到现成的深度学习系统中。
- en: 4.9 Training
  id: totrans-368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.9 训练
- en: 'Open Question #9: How to train and optimize the DL system?'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '开放问题 #9：如何训练和优化深度学习系统？'
- en: Training a DL system can be difficult. Large systems can have millions of parameters.
    There are many methods that DL researchers use to effectively train systems. These
    methods are discussed below.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 训练深度学习系统可能很困难。大型系统可以有数百万个参数。深度学习研究人员使用许多方法来有效地训练系统。以下将讨论这些方法。
- en: 'Data imputation: Data imputation [[398](#bib.bib398)] is important in RS, since
    there are often a small number of training samples. In imagery, image patched
    can be extracted and stretched with affine transformations, rotated, and made
    lighter or darker (scaling). Also, patched can be zeroed (removed) from training
    data to help the DL be more robust to occlusions. Data can also be augmented by
    simulations. Another method that can be useful in some circumstances is domain
    transfer, discussed below (transfer learning).'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 数据填补：数据填补[[398](#bib.bib398)]在推荐系统中非常重要，因为训练样本通常很少。在图像处理中，可以提取和拉伸图像补丁，进行仿射变换，旋转，并调整亮度或暗度（缩放）。此外，也可以将补丁置为零（移除），以帮助深度学习系统更好地应对遮挡。数据还可以通过模拟进行增强。另一个在某些情况下可能有用的方法是领域迁移，下面会讨论（迁移学习）。
- en: 'Pre-training: Erhan et al. [[399](#bib.bib399)] performed a detailed study
    trying to answer the questions “How does unsupervised pre-training work?” and
    “Why does unsupervised pre-training help DL?”. Their empirical analysis shows
    that unsupervised pre-training guides the learning towards attraction basins of
    minima that support better generalization and pre-training also acts as a regularizer.
    Furthermore, early training example have a large impact on the overall DL performance.
    Of course, these are experimental results, and results on other datasets or using
    other DL methods can yield different results. Many DL systems utilize pre-training
    followed by fine-tuning.'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练：Erhan等人[[399](#bib.bib399)]进行了详细研究，试图回答“无监督预训练是如何工作的？”和“无监督预训练为何有助于深度学习？”他们的实证分析表明，无监督预训练将学习引导到支持更好泛化的最小值吸引盆地，并且预训练也作为一种正则化器。此外，早期的训练样本对整体深度学习性能有很大影响。当然，这些是实验结果，其他数据集或使用其他深度学习方法的结果可能会有所不同。许多深度学习系统采用预训练后进行微调。
- en: 'Transfer Learning: Transfer learning is also discussed in section [4.6](#S4.SS6
    "4.6 Transfer Learning ‣ 4 Unsolved challenges and opportunities for DL in RS
    ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and
    Challenges for the Community"). Transfer learning attempts to transfer learned
    features (which can also be thought of as DL layer activations or outputs) from
    one image to another, from one part of an image to another part, or from one sensor
    to another. This is a particularly thorny issue in RS, due to variations in atmosphere,
    lighting conditions, etc. Pan et al. [[28](#bib.bib28)] point out that typically
    in remote sensing, when changing sensors or changing to a different part of a
    large image or other imagery collected at different times, the transfer fails.
    Remote sensing systems need to be robust, but they don’t necessarily require near-perfect
    knowledge. Also, transfer between images where the number and types of endmembers
    are different has very few studies. Zhang et al. [[3](#bib.bib3)] also cite transfer
    learning as an open issue in DL in general, and not just in RS.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '迁移学习：迁移学习也在[4.6](#S4.SS6 "4.6 Transfer Learning ‣ 4 Unsolved challenges and
    opportunities for DL in RS ‣ A Comprehensive Survey of Deep Learning in Remote
    Sensing: Theories, Tools and Challenges for the Community")节中讨论。迁移学习尝试将从一个图像中学到的特征（也可以看作是深度学习层的激活或输出）转移到另一个图像、图像的另一部分，或从一个传感器转移到另一个传感器。这在遥感中是一个特别棘手的问题，因为大气、光照条件等的变化。潘等人
    [[28](#bib.bib28)] 指出，在遥感中，当更换传感器或更换到大图像的不同部分或其他时间收集的图像时，迁移通常会失败。遥感系统需要具有鲁棒性，但不一定要求近乎完美的知识。此外，图像之间的迁移，其中终极目标的数量和类型不同的研究非常少。张等人
    [[3](#bib.bib3)] 还将迁移学习列为深度学习中的一个开放问题，而不仅仅是在遥感中。'
- en: 'Regularization: Regularization is defined by Goodfellow et al. [[11](#bib.bib11)]
    as “any modification we make to a learning algorithm that is intended to reduce
    its generalization error but not its training error.” There are many forms of
    regularizer - parameter size penalty terms (such as the $L_{2}$ or $L_{1}$ norm,
    and other regularizers that enforce sparse solutions; diagonal loading of a matrix
    so the matrix inverse (which is required for some algorithms) is better conditioned;
    Dropout and early stopping (both are described below); adding noise to weights
    or inputs; semi-supervised learning, which usually means that some function that
    has a very similar representation to examples from the same class is learned by
    the NN; Bagging (combining multiple models); and adversarial training, where a
    weighted sum of the sample and an adversarial sample is used to boost performance.
    The interested reader is referred to chapter 7 of [[11](#bib.bib11)] for further
    information. An interesting DL example in RS is, Mei et al. [[172](#bib.bib172)]
    , who utilized a Parametric Rectified Linear unit (PReLu) [[400](#bib.bib400)]
    , which can help improve model fitting without adding computational cost and with
    little overfitting risk.'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化：Goodfellow 等人 [[11](#bib.bib11)] 将正则化定义为“我们对学习算法所做的任何修改，其目的是减少其泛化误差而不是训练误差。”
    正则化有多种形式 - 参数大小惩罚项（如 $L_{2}$ 或 $L_{1}$ 范数，以及其他强制稀疏解的正则化器）；矩阵的对角加载，使得矩阵的逆（某些算法所需）更好地条件化；Dropout
    和提前停止（这两者在下文中描述）；向权重或输入中添加噪声；半监督学习，这通常意味着神经网络学习与同一类别的示例具有非常相似表示的某些函数；Bagging（组合多个模型）；以及对抗训练，其中使用样本和对抗样本的加权和来提高性能。感兴趣的读者可以参阅
    [[11](#bib.bib11)] 的第七章以获取更多信息。一个有趣的深度学习遥感例子是，梅等人 [[172](#bib.bib172)] 使用了参数化整流线性单元（PReLu）
    [[400](#bib.bib400)]，这种方法可以在不增加计算成本且过拟合风险较小的情况下改善模型拟合。
- en: 'Early stopping: Early stopping is a method where the training validation error
    is monitored and previous coefficient values are recorded. Once the training level
    reaches a stopping criteria, then the coefficients are used. Early stopping helps
    to mitigate overtraining. It also acts as a regularizer, constraining the parameter
    space to be close to the initial configuration [[399](#bib.bib399)] .'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 提前停止：提前停止是一种方法，其中监控训练验证误差并记录先前的系数值。一旦训练水平达到停止标准，就使用这些系数。提前停止有助于减轻过度训练。它还作为正则化器，约束参数空间接近初始配置
    [[399](#bib.bib399)]。
- en: 'Dropout: Dropout usually uses some number of randomly selected links (or a
    probability that a link will be dropped) [[401](#bib.bib401)] . As the network
    is trained, these links are zeroed, basically stopping data from flowing from
    the shallower to deeper layers in the DL system. Dropout basically allows a bagging-like
    effect, but instead of the individual networks being independent, they share values,
    but the mixing occurs at the dropout layer, and the individual subnetworks share
    parameters [[11](#bib.bib11)] .'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout：Dropout通常使用一些随机选择的连接数量（或连接被丢弃的概率）[[401](#bib.bib401)]。随着网络的训练，这些连接被置零，基本上阻止数据从浅层流向深层。Dropout基本上允许类似于bagging的效果，但不同的是，个体网络并非独立，它们共享值，而混合发生在dropout层，个体子网络共享参数[[11](#bib.bib11)]。
- en: 'Batch Normalization: Batch normalization was developed by Ioffe et al. [[402](#bib.bib402)].
    Batch normalization breaks the data into small batches and then normalizes the
    data to be zero mean and unity variance. Batch normalization can also be added
    internally as layers in the network. Batch normalization reduces the so-called
    internal covariate shift problem for each training mini-batch. Applying batch
    normalization had the following benefits: (1) allowed a higher learning rate;
    (2) the DL network was not as sensitive to initialization; (3) dropout was not
    required to mitigate overfitting; (4) The $L_{2}$ weight regularization could
    be reduced, increasing accuracy. Adding batch normalization increases the two
    extra parameters per activation.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 批量归一化：批量归一化由Ioffe等人[[402](#bib.bib402)]开发。批量归一化将数据划分为小批量，然后将数据标准化为零均值和单位方差。批量归一化也可以作为网络中的内部层添加。批量归一化减少了每个训练小批量的所谓内部协方差偏移问题。应用批量归一化有以下好处：（1）允许更高的学习率；（2）深度学习网络对初始化不那么敏感；（3）不需要dropout来缓解过拟合；（4）$L_{2}$权重正则化可以减少，提高准确性。添加批量归一化会增加每个激活两个额外的参数。
- en: 'Optimization: Optimization of DL networks is a major area of study in DL. It
    is nontrivial to train a DL netowrk, much less squeeze out high performance on
    both the training and testing datasets. SGD is a training method that uses small
    batches of training data to generate an estimate of the gradients. Li et al. [[403](#bib.bib403)]
    argues the SGD is not inherently parallel, and often requires training many models
    and choosing the one that performs best on the validation set. They also show
    that no one method works best in all cases. They found that optimization performance
    varies per problem. A nice review paper for many gradient descent algorithms is
    provided by Ruder [[404](#bib.bib404)] . According to Ruder, complications for
    gradient descent algorithms include:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 优化：深度学习网络的优化是深度学习中的一个主要研究领域。训练深度学习网络并非易事，更不用说在训练和测试数据集上获得高性能。SGD是一种训练方法，利用小批量的训练数据生成梯度估计。Li等人[[403](#bib.bib403)]认为SGD本质上不是并行的，通常需要训练多个模型并选择在验证集上表现最佳的那个。他们还表明，没有一种方法在所有情况下都表现最佳。他们发现优化性能因问题而异。Ruder[[404](#bib.bib404)]提供了许多梯度下降算法的综述论文。根据Ruder的说法，梯度下降算法的复杂性包括：
- en: •
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How to choose a proper learning rate?
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如何选择适当的学习率？
- en: •
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How to properly adjust learning-rate schedules for optimal performance?
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如何正确调整学习率的时间表以获得最佳性能？
- en: •
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How to adjust learning rates independently for each parameter?
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如何为每个参数独立调整学习率？
- en: •
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How to avoid getting trapped in local minima and saddle points when one dimension
    slopes up and one down (the gradients can get very small and training halts)
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如何避免在一个维度上升而另一个维度下降时陷入局部最小值和鞍点（梯度可能非常小，训练中断）
- en: Various gradient descent methods such as Adagrad [[405](#bib.bib405)] , which
    adapts the learning rate to the parameters, AdaDelta [[406](#bib.bib406)] , which
    uses a fixed size window of past data, and Adam [[407](#bib.bib407)] , which also
    has both mean and variance terms for the gradient descent, can be utilized for
    training. Another recent approach seeks to optimize the learning rate from the
    data is described in Schaul et al. [[408](#bib.bib408)] . Finally, Sokolić et
    al. [[397](#bib.bib397)] concluded experimentally that for a DNN to generalize
    well, the spectral norm of the NN’s Jacobian matrix in the neighbourhood of the
    training samples must be bounded. They furthermore show that the generalization
    error can be bounded independent of the DL network’s depth or width, provided
    that the Jacobian spectral norm is bounded. They also analyze residual networks,
    weight normalized networks, CNN’s with batch normalization and Jacobian regularization,
    and residual networks with Jacobian regularization. The interested reader is referred
    to chapter 8 of [[11](#bib.bib11)] for further information.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 各种梯度下降方法，如Adagrad [[405](#bib.bib405)]，它根据参数调整学习率，AdaDelta [[406](#bib.bib406)]，它使用固定大小的过去数据窗口，以及Adam
    [[407](#bib.bib407)]，它也有均值和方差项用于梯度下降，都可以用于训练。Schaul等人[[408](#bib.bib408)]描述了一种最新方法，旨在从数据中优化学习率。最后，Sokolić等人[[397](#bib.bib397)]通过实验得出结论：为了使DNN具有良好的泛化能力，NN雅可比矩阵在训练样本附近的谱范数必须被限制。他们进一步表明，只要雅可比谱范数是有限的，泛化误差可以在DL网络的深度或宽度无关的情况下被界限。他们还分析了残差网络、权重归一化网络、具有批归一化和雅可比正则化的CNN，以及具有雅可比正则化的残差网络。感兴趣的读者可以参阅[[11](#bib.bib11)]第8章获取更多信息。
- en: 'Data Propagation: Both highway networks [[409](#bib.bib409)] and residual networks
    [[410](#bib.bib410)] are methods that take data from one layer and incorporate
    it, either directly (highway networks) or as a difference (residual networks)
    into deeper layers. These methods both allow very deep networks to be trained,
    at the expense of some additional components. Balduzzi et al. [[411](#bib.bib411)]
    examined networks and determined that there is a so-called “shattered gradient”
    problem in DNN, which is manifested by the gradient correlation decaying exponentially
    with depth and thus gradients resemble white noise. A “looks linear” initialization
    is developed that prevents the gradient shattering. This method appears not to
    require skip connections (highway networks, residual networks).'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 数据传播：高速公路网络[[409](#bib.bib409)]和残差网络[[410](#bib.bib410)]都是从一个层获取数据并将其直接（高速公路网络）或以差异形式（残差网络）纳入更深层的方法。这些方法都允许非常深的网络进行训练，但代价是增加了一些额外的组件。Balduzzi等人[[411](#bib.bib411)]检查了网络并确定DNN中存在所谓的“碎裂梯度”问题，其表现为梯度相关性随着深度的增加而指数衰减，因此梯度类似于白噪声。开发了一种“看似线性”的初始化方法来防止梯度碎裂。这种方法似乎不需要跳跃连接（高速公路网络、残差网络）。
- en: 5 Conclusions
  id: totrans-389
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: In this letter, we have performed a thorough review and analyzed 207 RS papers
    that utilize FL and DL, as well as 57 survey papers in DL and RS. We provide researches
    with a clustered set of 12 areas where DL RS papers have been applied. We examine
    why DL is popular and what is enabling DL. We examined many DL tools and provided
    opinions about the tools pros and cons. We critically looked at the DL RS field
    and identified nine general areas with unsolved challenges and opportunities,
    specifically enumerated 11 difficult and thought-provoking open questions in this
    area. We reviewed current DL research in CV and discussed recent methods that
    could be utilized in DL in RS. We provide a table of DL survey papers covering
    DL in RS and feature learning in RS.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在这封信中，我们对207篇利用FL和DL的RS论文以及57篇DL和RS领域的调查论文进行了彻底的回顾和分析。我们为研究者提供了一个包含12个领域的集群，其中DL
    RS论文得到了应用。我们考察了DL为何受欢迎以及DL的驱动因素。我们审查了许多DL工具，并提供了对这些工具优缺点的意见。我们批判性地审视了DL RS领域，并确定了九个存在未解挑战和机会的常见领域，特别列出了该领域的11个困难且引人深思的开放性问题。我们回顾了当前在CV中的DL研究，并讨论了可以在RS中的DL中利用的近期方法。我们提供了一个覆盖DL在RS中的应用及RS中特征学习的DL调查论文表格。
- en: Disclosures
  id: totrans-391
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 披露
- en: The authors declare no conflict of interest.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 作者声明没有利益冲突。
- en: Acknowledgements.
  id: totrans-393
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 致谢。
- en: The authors wish to thank graduate students Vivi Wei, Julie White and Charlie
    Veal for their valuable inputs related to DL tools.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 作者感谢研究生Vivi Wei、Julie White和Charlie Veal对DL工具的宝贵意见。
- en: References
  id: totrans-395
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] G. Cheng, J. Han, and X. Lu, “Remote Sensing Image Scene Classification:
    Benchmark and State of the Art,” arXiv:1703.00121 [cs.CV] (2017). DOI:10.1109/JPROC.2017.2675998.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] G. Cheng, J. Han 和 X. Lu, “遥感图像场景分类：基准与现状，”arXiv:1703.00121 [cs.CV] (2017).
    DOI:10.1109/JPROC.2017.2675998.'
- en: '[2] L. Deng, “A tutorial survey of architectures, algorithms, and applications
    for deep learning,” APSIPA Transactions on Signal and Information Processing 3
    (e2)(January), 1–29 (2014).'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] L. Deng, “深度学习架构、算法和应用的教程综述，”《APSIPA 信号与信息处理交易》3 (e2)(一月), 1–29 (2014).'
- en: '[3] L. Zhang, L. Zhang, and V. Kumar, “Deep learning for Remote Sensing Data,”
    IEEE Geoscience and Remote Sensing Magazine 4(June), 22–40 (2016). DOI:10.1155/2016/7954154.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] L. Zhang, L. Zhang 和 V. Kumar, “遥感数据的深度学习，”《IEEE 地球科学与遥感杂志》4(六月), 22–40
    (2016). DOI:10.1155/2016/7954154.'
- en: '[4] H. Wang and B. Raj, “A survey: Time travel in deep learning space: An introduction
    to deep learning models and how deep learning models evolved from the initial
    ideas,” arXiv preprint arXiv:1510.04781 abs/1510.04781 (2015).'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] H. Wang 和 B. Raj, “综述：深度学习领域的时间旅行：深度学习模型的介绍及其演变历程，”arXiv 预印本 arXiv:1510.04781
    abs/1510.04781 (2015).'
- en: '[5] J. Wan, D. Wang, S. C. H. Hoi, et al., “Deep learning for content-based
    image retrieval: A comprehensive study,” in Proceedings of the 22nd ACM international
    conference on Multimedia, 157–166 (2014).'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] J. Wan, D. Wang, S. C. H. Hoi 等, “基于内容的图像检索的深度学习：全面研究，”在第22届ACM国际多媒体会议论文集，157–166
    (2014).'
- en: '[6] J. Ba and R. Caruana, “Do deep nets really need to be deep?,” in Advances
    in neural information processing systems, 2654–2662 (2014).'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] J. Ba 和 R. Caruana, “深度网络真的需要很深吗？”，在《神经信息处理系统进展》，2654–2662 (2014).'
- en: '[7] I. Arel, D. C. Rose, and T. P. Karnowski, “Deep Machine Learning - A New
    Frontier in Artificial Intelligence Research,” IEEE Computational Intelligence
    Magazine 5(4), 13–18 (2010). DOI:10.1109/MCI.2010.938364.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] I. Arel, D. C. Rose 和 T. P. Karnowski, “深度机器学习 - 人工智能研究的新前沿，”《IEEE 计算智能杂志》5(4),
    13–18 (2010). DOI:10.1109/MCI.2010.938364.'
- en: '[8] W. Liu, Z. Wang, X. Liu, et al., “A survey of deep neural network architectures
    and their applications,” Neurocomputing 234, 11–26 (2016). DOI:10.1016/j.neucom.2016.12.038.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] W. Liu, Z. Wang, X. Liu 等, “深度神经网络架构及其应用的综述，”《神经计算》234, 11–26 (2016). DOI:10.1016/j.neucom.2016.12.038.'
- en: '[9] D. Yu and L. Deng, “Deep Learning and Its Applications to Signal and Information
    Processing [Exploratory DSP],” Signal Processing Magazine, IEEE 28(1), 145–154
    (2011). DOI:10.1109/MSP.2010.939038.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] D. Yu 和 L. Deng, “深度学习及其在信号与信息处理中的应用 [探索性 DSP]，”《IEEE 信号处理杂志》28(1), 145–154
    (2011). DOI:10.1109/MSP.2010.939038.'
- en: '[10] J. Schmidhuber, “Deep Learning in neural networks: An overview,” Neural
    Networks 61, 85–117 (2015). DOI:10.1016/j.neunet.2014.09.003.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] J. Schmidhuber, “深度学习在神经网络中的概述，”《神经网络》61, 85–117 (2015). DOI:10.1016/j.neunet.2014.09.003.'
- en: '[11] I. Goodfellow, Y. Bengio, and A. Courville, Deep learning, MIT Press (2016).'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] I. Goodfellow, Y. Bengio 和 A. Courville, 《深度学习》，麻省理工学院出版社 (2016).'
- en: '[12] L. Arnold, S. Rebecchi, S. Chevallier, et al., “An introduction to deep
    learning,” in 2012 11th International Conference on Information Science, Signal
    Processing and their Applications, ISSPA 2012, (April), 1438–1439 (2012).'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] L. Arnold, S. Rebecchi, S. Chevallier 等, “深度学习简介，”在 2012年第11届国际信息科学、信号处理及其应用会议，ISSPA
    2012, (四月), 1438–1439 (2012).'
- en: '[13] Y. Bengio, A. C. Courville, and P. Vincent, “Unsupervised feature learning
    and deep learning: A review and new perspectives,” CoRR, abs/1206.5538 1 (2012).'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Y. Bengio, A. C. Courville 和 P. Vincent, “无监督特征学习和深度学习：综述与新视角，”《CoRR》，abs/1206.5538
    1 (2012).'
- en: '[14] X.-w. Chen and X. Len, “Big Data Deep Learning: Challenges and Perspectives,”
    IEEE Access 2, 514–525 (2014). DOI:10.1109/ACCESS.2014.2325029.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] X.-w. Chen 和 X. Len, “大数据深度学习：挑战与展望，”《IEEE 访问》2, 514–525 (2014). DOI:10.1109/ACCESS.2014.2325029.'
- en: '[15] L. Deng and D. Yu, “Deep Learning: Methods and Applications,” Foundations
    and Trends® in Signal Processing 7(3-4), 197–387 (2013).'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] L. Deng 和 D. Yu, “深度学习：方法与应用，”《信号处理基础与趋势®》7(3-4), 197–387 (2013).'
- en: '[16] M. M. Najafabadi, F. Villanustre, T. M. Khoshgoftaar, et al., “Deep learning
    applications and challenges in big data analytics,” Journal of Big Data 2(1),
    1–21 (2015).'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] M. M. Najafabadi, F. Villanustre, T. M. Khoshgoftaar 等, “深度学习在大数据分析中的应用与挑战，”《大数据杂志》2(1),
    1–21 (2015).'
- en: '[17] J. M. Bioucas-dias, A. Plaza, G. Camps-valls, et al., “Hyperspectral Remote
    Sensing Data Analysis and Future Challenges,” IEEE Geoscience and Remote Sensing
    Magazine (June), 6–36 (2013).'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] J. M. Bioucas-dias, A. Plaza, G. Camps-valls 等, “高光谱遥感数据分析及未来挑战，”《IEEE
    地球科学与遥感杂志》 (六月), 6–36 (2013).'
- en: '[18] G. Camps-Valls and L. Bruzzone, “Kernel-based methods for hyperspectral
    image classification,” Geoscience and Remote Sensing, IEEE Transactions on 43(6),
    1351–1362 (2005).'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] G. Camps-Valls 和 L. Bruzzone， “用于高光谱图像分类的基于核的方法，” IEEE 地球科学与遥感学报 43(6),
    1351–1362 (2005)。'
- en: '[19] G. Camps-Valls, D. Tuia, L. Bruzzone, et al., “Advances in hyperspectral
    image classification: Earth monitoring with statistical learning methods,” IEEE
    Signal Processing Magazine 31(1), 45–54 (2013). DOI:10.1109/MSP.2013.2279179.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] G. Camps-Valls, D. Tuia, L. Bruzzone 等， “高光谱图像分类的进展：利用统计学习方法进行地球监测，” IEEE
    信号处理杂志 31(1), 45–54 (2013)。 DOI:10.1109/MSP.2013.2279179。'
- en: '[20] H. Deborah, N. Richard, and J. Y. Hardeberg, “A comprehensive evaluation
    of spectral distance functions and metrics for hyperspectral image processing,”
    IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing
    8(6), 3224–3234 (2015).'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] H. Deborah, N. Richard 和 J. Y. Hardeberg， “光谱距离函数和度量在高光谱图像处理中的全面评估，” IEEE
    应用地球观测与遥感精选主题学报 8(6), 3224–3234 (2015)。'
- en: '[21] P. Dollar, C. Wojek, B. Schiele, et al., “Pedestrian detection: An evaluation
    of the state of the art,” IEEE transactions on pattern analysis and machine intelligence
    34(4), 743–761 (2012). DOI:10.1109/TPAMI.2011.155.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] P. Dollar, C. Wojek, B. Schiele 等， “行人检测：对当前技术状态的评估，” IEEE 模式分析与机器智能学报
    34(4), 743–761 (2012)。 DOI:10.1109/TPAMI.2011.155。'
- en: '[22] P. Du, J. Xia, W. Zhang, et al., “Multiple classifier system for remote
    sensing image classification: A review,” Sensors 12(4), 4764–4792 (2012).'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] P. Du, J. Xia, W. Zhang 等， “遥感图像分类的多重分类器系统：综述，” Sensors 12(4), 4764–4792
    (2012)。'
- en: '[23] M. Fauvel, Y. Tarabalka, J. A. Benediktsson, et al., “Advances in spectral-spatial
    classification of hyperspectral images,” Proceedings of the IEEE 101(3), 652–675
    (2013).'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] M. Fauvel, Y. Tarabalka, J. A. Benediktsson 等， “高光谱图像的光谱-空间分类进展，” Proceedings
    of the IEEE 101(3), 652–675 (2013)。'
- en: '[24] M. Hussain, D. Chen, A. Cheng, et al., “Change detection from remotely
    sensed images: From pixel-based to object-based approaches,” ISPRS Journal of
    Photogrammetry and Remote Sensing 80, 91–106 (2013). DOI:10.1016/j.isprsjprs.2013.03.006.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] M. Hussain, D. Chen, A. Cheng 等， “从遥感图像中的变化检测：从基于像素的方法到基于对象的方法，” ISPRS
    摄影测量与遥感杂志 80, 91–106 (2013)。 DOI:10.1016/j.isprsjprs.2013.03.006。'
- en: '[25] G. Jianya, S. Haigang, M. Guorui, et al., “A review of multi-temporal
    remote sensing data change detection algorithms,” The International Archives of
    the Photogrammetry, Remote Sensing and Spatial Information Sciences 37(B7), 757–762
    (2008).'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] G. Jianya, S. Haigang, M. Guorui 等， “多时相遥感数据变化检测算法的综述，” 国际摄影测量、遥感与空间信息科学档案
    37(B7), 757–762 (2008)。'
- en: '[26] D. J. Lary, A. H. Alavi, A. H. Gandomi, et al., “Machine learning in geosciences
    and remote sensing,” Geoscience Frontiers 7(1), 3–10 (2016).'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] D. J. Lary, A. H. Alavi, A. H. Gandomi 等， “地球科学与遥感中的机器学习，” Geoscience
    Frontiers 7(1), 3–10 (2016)。'
- en: '[27] D. Lunga, S. Prasad, M. M. Crawford, et al., “Manifold-learning-based
    feature extraction for classification of hyperspectral data: A review of advances
    in manifold learning,” IEEE Signal Processing Magazine 31(1), 55–66 (2014).'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] D. Lunga, S. Prasad, M. M. Crawford 等， “基于流形学习的高光谱数据分类特征提取：流形学习进展的综述，”
    IEEE 信号处理杂志 31(1), 55–66 (2014)。'
- en: '[28] S. J. Pan and Q. Yang, “A survey on transfer learning,” IEEE Transactions
    on knowledge and data engineering 22(10), 1345–1359 (2010). DOI:10.1109/TKDE.2009.191.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] S. J. Pan 和 Q. Yang， “迁移学习综述，” IEEE 知识与数据工程学报 22(10), 1345–1359 (2010)。
    DOI:10.1109/TKDE.2009.191。'
- en: '[29] A. Plaza, P. Martinez, R. Pérez, et al., “A quantitative and comparative
    analysis of endmember extraction algorithms from hyperspectral data,” IEEE transactions
    on geoscience and remote sensing 42(3), 650–663 (2004). DOI:10.1109/TGRS.2003.820314.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] A. Plaza, P. Martinez, R. Pérez 等， “从高光谱数据中提取端元算法的定量和比较分析，” IEEE 地球科学与遥感学报
    42(3), 650–663 (2004)。 DOI:10.1109/TGRS.2003.820314。'
- en: '[30] N. Keshava and J. F. Mustard, “Spectral unmixing,” IEEE signal processing
    magazine 19(1), 44–57 (2002).'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] N. Keshava 和 J. F. Mustard， “光谱解混，” IEEE 信号处理杂志 19(1), 44–57 (2002)。'
- en: '[31] N. Keshava, “A survey of spectral unmixing algorithms,” Lincoln Laboratory
    Journal 14(1), 55–78 (2003).'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] N. Keshava， “光谱解混算法综述，” 林肯实验室学报 14(1), 55–78 (2003)。'
- en: '[32] M. Parente and A. Plaza, “Survey of geometric and statistical unmixing
    algorithms for hyperspectral images,” in Hyperspectral Image and Signal Processing:
    Evolution in Remote Sensing (WHISPERS), 2010 2nd Workshop on, 1–4, IEEE (2010).'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] M. Parente 和 A. Plaza， “高光谱图像几何和统计解混算法的综述，” 2010年第二届高光谱图像与信号处理研讨会（WHISPERS），1–4，IEEE
    (2010)。'
- en: '[33] A. Plaza, G. Martín, J. Plaza, et al., “Recent developments in endmember
    extraction and spectral unmixing,” in Optical Remote Sensing, S. Prasad, L. M.
    Bruce, and J. Chanussot, Eds., 235–267, Springer (2011). DOI:10.1007/978-3-642-14212-3_12.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] A. Plaza, G. Martín, J. Plaza 等，“端成员提取和光谱解混的最新进展”，在光学遥感中，S. Prasad, L.
    M. Bruce 和 J. Chanussot 编著，235–267，Springer (2011)。 DOI:10.1007/978-3-642-14212-3_12。'
- en: '[34] C. Shi and L. Wang, “Incorporating spatial information in spectral unmixing:
    A review,” Remote Sensing of Environment 149, 70–87 (2014). DOI:10.1016/j.rse.2014.03.034.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] C. Shi 和 L. Wang, “在光谱解混中结合空间信息：综述”，环境遥感 149, 70–87 (2014)。 DOI:10.1016/j.rse.2014.03.034。'
- en: '[35] M. Chen, Z. Xu, K. Weinberger, et al., “Marginalized denoising autoencoders
    for domain adaptation,” arXiv preprint arXiv:1206.4683 (2012).'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] M. Chen, Z. Xu, K. Weinberger 等，“用于领域适应的边际去噪自编码器”，arXiv 预印本 arXiv:1206.4683
    (2012)。'
- en: '[36] ujjwalkarn, “An Intuitive Explanation of Convolutional Neural Networks.”
    https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/ (2016).'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] ujjwalkarn, “卷积神经网络的直观解释。” https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/
    (2016)。'
- en: '[37] Y. LeCun, L. Bottou, Y. Bengio, et al., “Gradient-based learning applied
    to document recognition,” Proceedings of the IEEE 86(11), 2278–2324 (1998).'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Y. LeCun, L. Bottou, Y. Bengio 等，“应用于文档识别的基于梯度的学习”，IEEE 会议论文集 86(11),
    2278–2324 (1998)。'
- en: '[38] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
    with deep convolutional neural networks,” in Advances in neural information processing
    systems, 1097–1105 (2012).'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] A. Krizhevsky, I. Sutskever 和 G. E. Hinton, “使用深度卷积神经网络进行 Imagenet 分类”，在神经信息处理系统进展中，1097–1105
    (2012)。'
- en: '[39] M. D. Zeiler and R. Fergus, “Visualizing and understanding convolutional
    networks,” in European conference on computer vision, 818–833, Springer (2014).'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] M. D. Zeiler 和 R. Fergus, “可视化与理解卷积网络”，在欧洲计算机视觉大会中，818–833，Springer (2014)。'
- en: '[40] C. Szegedy, W. Liu, Y. Jia, et al., “Going deeper with convolutions,”
    in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    1–9 (2015).'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] C. Szegedy, W. Liu, Y. Jia 等，“通过卷积深入探索”，在 IEEE 计算机视觉与模式识别大会论文集中，1–9 (2015)。'
- en: '[41] K. He, X. Zhang, S. Ren, et al., “Deep residual learning for image recognition,”
    in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    770–778 (2016).'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] K. He, X. Zhang, S. Ren 等，“深度残差学习用于图像识别”，在 IEEE 计算机视觉与模式识别大会论文集中，770–778
    (2016)。'
- en: '[42] G. Huang, Z. Liu, K. Q. Weinberger, et al., “Densely connected convolutional
    networks,” arXiv preprint arXiv:1608.06993 (2016).'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] G. Huang, Z. Liu, K. Q. Weinberger 等，“密集连接卷积网络”，arXiv 预印本 arXiv:1608.06993
    (2016)。'
- en: '[43] G. Hinton and R. Salakhutdinov, “Reducing the dimensionality of data with
    neural networks,” Science 313(5786), 504 – 507 (2006).'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] G. Hinton 和 R. Salakhutdinov, “利用神经网络降低数据维度”，Science 313(5786), 504 –
    507 (2006)。'
- en: '[44] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural computation
    9(8), 1735–1780 (1997).'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] S. Hochreiter 和 J. Schmidhuber, “长短期记忆”，Neural computation 9(8), 1735–1780
    (1997)。'
- en: '[45] M. D. Zeiler, G. W. Taylor, and R. Fergus, “Adaptive deconvolutional networks
    for mid and high level feature learning,” in 2011 International Conference on
    Computer Vision, 2018–2025 (2011).'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] M. D. Zeiler, G. W. Taylor 和 R. Fergus, “用于中高层特征学习的自适应反卷积网络”，在 2011 年国际计算机视觉大会中，2018–2025
    (2011)。'
- en: '[46] M. D. Zeiler, D. Krishnan, G. W. Taylor, et al., “Deconvolutional networks,”
    in In CVPR, (2010).'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] M. D. Zeiler, D. Krishnan, G. W. Taylor 等，“反卷积网络”，在 CVPR 中，(2010)。'
- en: '[47] H. Noh, S. Hong, and B. Han, “Learning deconvolution network for semantic
    segmentation,” CoRR abs/1505.04366 (2015).'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] H. Noh, S. Hong 和 B. Han, “学习反卷积网络进行语义分割”，CoRR abs/1505.04366 (2015)。'
- en: '[48] O. Russakovsky, J. Deng, H. Su, et al., “Imagenet large scale visual recognition
    challenge,” International Journal of Computer Vision 115(3), 211–252 (2015).'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] O. Russakovsky, J. Deng, H. Su 等，“Imagenet 大规模视觉识别挑战”，国际计算机视觉杂志 115(3),
    211–252 (2015)。'
- en: '[49] L. Brown, “Deep Learning with GPUs.” www.nvidia.com/content/events/geoInt2015/'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] L. Brown, “使用 GPU 的深度学习。” www.nvidia.com/content/events/geoInt2015/'
- en: LBrown_DL.pdf (2015).
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LBrown_DL.pdf (2015)。
- en: '[50] G. Cybenko, “Approximation by superpositions of a sigmoidal function,”
    Mathematics of Control, Signals and Systems 2(4), 303–314 (1989).'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] G. Cybenko, “通过 sigmoid 函数的叠加进行近似”，控制、信号与系统的数学 2(4), 303–314 (1989)。'
- en: '[51] M. Telgarsky, “Benefits of depth in neural networks,” arXiv preprint arXiv:1602.04485
    (2016).'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] M. Telgarsky, “神经网络中深度的好处”，arXiv 预印本 arXiv:1602.04485 (2016)。'
- en: '[52] O. Sharir and A. Shashua, “On the Expressive Power of Overlapping Operations
    of Deep Networks,” arXiv preprint arXiv:1703.02065 (2017).'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] S. Liang and R. Srikant, “Why deep neural networks for function approximation?,”
    arXiv preprint arXiv:1610.04161 (2016).'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] Y. Ma, H. Wu, L. Wang, et al., “Remote sensing big data computing: Challenges
    and opportunities,” Future Generation Computer Systems 51, 47 – 60 (2015). Special
    Section: A Note on New Trends in Data-Aware Scheduling and Resource Provisioning
    in Modern HPC Systems.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] M. Chi, A. Plaza, J. A. Benediktsson, et al., “Big data for remote sensing:
    Challenges and opportunities,” Proceedings of the IEEE 104, 2207–2219 (2016).'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] R. Raina, A. Madhavan, and A. Y. Ng, “Large-scale deep unsupervised learning
    using graphics processors,” in Proceedings of the 26th Annual International Conference
    on Machine Learning, ICML ’09, 873–880, ACM, (New York, NY, USA) (2009).'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] D. C. Cireşan, U. Meier, J. Masci, et al., “Flexible, high performance
    convolutional neural networks for image classification,” in Proceedings of the
    Twenty-Second International Joint Conference on Artificial Intelligence - Volume
    Volume Two, IJCAI’11, 1237–1242, AAAI Press (2011).'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] D. Scherer, A. Müller, and S. Behnke, “Evaluation of pooling operations
    in convolutional architectures for object recognition,” in Proceedings of the
    20th International Conference on Artificial Neural Networks: Part III, ICANN’10,
    92–101, Springer-Verlag, (Berlin, Heidelberg) (2010).'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] L. Deng, D. Yu, and J. Platt, “Scalable stacking and learning for building
    deep architectures,” in 2012 IEEE International Conference on Acoustics, Speech
    and Signal Processing (ICASSP), 2133–2136 (2012).'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] B. Hutchinson, L. Deng, and D. Yu, “Tensor deep stacking networks,” IEEE
    Trans. Pattern Anal. Mach. Intell. 35, 1944–1957 (2013).'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] J. Dean, G. S. Corrado, R. Monga, et al., “Large scale distributed deep
    networks,” in Proceedings of the 25th International Conference on Neural Information
    Processing Systems, NIPS’12, 1223–1231, Curran Associates Inc., (USA) (2012).'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] J. Dean, G. Corrado, R. Monga, et al., “Large scale distributed deep networks,”
    in Advances in neural information processing systems, 1223–1231 (2012).'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] K. He, X. Zhang, S. Ren, et al., “Deep residual learning for image recognition,”
    CoRR abs/1512.03385 (2015).'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] R. K. Srivastava, K. Greff, and J. Schmidhuber, “Highway networks,” CoRR
    abs/1505.00387 (2015).'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] K. Greff, R. K. Srivastava, and J. Schmidhuber, “Highway and residual
    networks learn unrolled iterative estimation,” CoRR abs/1612.07771 (2016).'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] J. G. Zilly, R. K. Srivastava, J. Koutník, et al., “Recurrent highway
    networks,” CoRR abs/1607.03474 (2016).'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] R. K. Srivastava, K. Greff, and J. Schmidhuber, “Training very deep networks,”
    CoRR abs/1507.06228 (2015).'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] Y. Jia, E. Shelhamer, J. Donahue, et al., “Caffe: Convolutional Architecture
    for Fast Feature Embedding,” in ACM International Conference on Multimedia, 675–678
    (2014).'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] Y. Jia, E. Shelhamer, J. Donahue, 等，“Caffe: 快速特征嵌入的卷积架构，” 在 ACM 国际多媒体会议论文集中，675–678
    (2014)。'
- en: '[69] M. Abadi, P. Barham, J. Chen, et al., “TensorFlow: A system for large-scale
    machine learning,” in Proceedings of the 12th USENIX Symposium on Operating Systems
    Design and Implementation (OSDI). Savannah, Georgia, USA, (2016).'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] M. Abadi, P. Barham, J. Chen, 等，“TensorFlow: 一个用于大规模机器学习的系统，” 在第12届 USENIX
    操作系统设计与实现（OSDI）研讨会论文集中，乔治亚州萨凡纳，美国 (2016)。'
- en: '[70] A. Vedaldi and K. Lenc, “Matconvnet: Convolutional neural networks for
    matlab,” in Proceedings of the 23rd ACM international conference on Multimedia,
    689–692, ACM (2015).'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] A. Vedaldi 和 K. Lenc，“Matconvnet: 用于 Matlab 的卷积神经网络，” 在第23届 ACM 国际多媒体会议论文集中，689–692，ACM
    (2015)。'
- en: '[71] A. Handa, M. Bloesch, V. Patraucean, et al., “Gvnn: Neural Network Library
    for Geometric Computer Vision,” in Computer Vision-ECCV 2016 Workshop, 67–82,
    Springer International (2016).'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] A. Handa, M. Bloesch, V. Patraucean, 等，“Gvnn: 用于几何计算机视觉的神经网络库，” 在计算机视觉-ECCV
    2016 研讨会中，67–82，Springer International (2016)。'
- en: '[72] F. Chollet, “Keras,” (2015). https://github.com/fchollet/keras.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] F. Chollet，“Keras，” (2015)。 https://github.com/fchollet/keras。'
- en: '[73] T. Chen, M. Li, Y. Li, et al., “MXNet: A Flexible and Efficient Machine
    Learning Library for Heterogeneous Distributed Systems,” eprint arXiv:1512.01274
    , 1–6 (2015).'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] T. Chen, M. Li, Y. Li, 等，“MXNet: 一种灵活高效的异构分布式系统机器学习库，” eprint arXiv:1512.01274，1–6
    (2015)。'
- en: '[74] R. Al-Rfou, G. Alain, A. Almahairi, et al., “Theano: A Python framework
    for fast computation of mathematical expressions,” arXiv preprint arXiv:1605.02688
    (2016).'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] R. Al-Rfou, G. Alain, A. Almahairi, 等，“Theano: 一种用于快速计算数学表达式的 Python 框架，”
    arXiv 预印本 arXiv:1605.02688 (2016)。'
- en: '[75] “Deep Learning with Torch: The 60-minute Blitz.” https://github.com/soumith/'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] “Deep Learning with Torch: The 60-minute Blitz。” https://github.com/soumith/'
- en: cvpr2015/blob/master/Deep Learning with Torch.ipynb.
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: cvpr2015/blob/master/Deep Learning with Torch.ipynb。
- en: '[76] M. Baccouche, F. Mamalet, C. Wolf, et al., “Sequential deep learning for
    human action recognition,” in International Workshop on Human Behavior Understanding,
    29–39, Springer (2011).'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] M. Baccouche, F. Mamalet, C. Wolf, 等，“用于人类动作识别的序列深度学习，” 在国际人类行为理解研讨会中，29–39，Springer
    (2011)。'
- en: '[77] Z. Shou, J. Chan, A. Zareian, et al., “Cdc: Convolutional-de-convolutional
    networks for precise temporal action localization in untrimmed videos,” arXiv
    preprint arXiv:1703.01515 (2017).'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] Z. Shou, J. Chan, A. Zareian, 等，“Cdc: 卷积-反卷积网络用于未裁剪视频中的精确时序动作定位，” arXiv
    预印本 arXiv:1703.01515 (2017)。'
- en: '[78] D. Tran, L. Bourdev, R. Fergus, et al., “Learning spatiotemporal features
    with 3d convolutional networks,” in Computer Vision (ICCV), 2015 IEEE International
    Conference on, 4489–4497 (2015).'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] D. Tran, L. Bourdev, R. Fergus, 等，“使用 3D 卷积网络学习时空特征，” 在计算机视觉（ICCV）中，2015
    IEEE 国际会议，4489–4497 (2015)。'
- en: '[79] L. Wang, Y. Xiong, Z. Wang, et al., “Temporal segment networks: towards
    good practices for deep action recognition,” in European Conference on Computer
    Vision, 20–36 (2016).'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] L. Wang, Y. Xiong, Z. Wang, 等，“时间段网络：深度动作识别的良好实践，” 在欧洲计算机视觉会议中，20–36 (2016)。'
- en: '[80] G. E. Dahl, D. Yu, L. Deng, et al., “Context-dependent pre-trained deep
    neural networks for large-vocabulary speech recognition,” IEEE Transactions on
    Audio, Speech, and Language Processing 20(1), 30–42 (2012).'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] G. E. Dahl, D. Yu, L. Deng, 等，“用于大词汇量语音识别的上下文相关预训练深度神经网络，” IEEE 音频、语音和语言处理汇刊
    20(1)，30–42 (2012)。'
- en: '[81] G. Hinton, L. Deng, D. Yu, et al., “Deep neural networks for acoustic
    modeling in speech recognition: The shared views of four research groups,” IEEE
    Signal Processing Magazine 29(6), 82–97 (2012).'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] G. Hinton, L. Deng, D. Yu, 等，“语音识别中的深度神经网络：四个研究小组的共同观点，” IEEE 信号处理杂志 29(6)，82–97
    (2012)。'
- en: '[82] A. Graves, A.-r. Mohamed, and G. Hinton, “Speech recognition with deep
    recurrent neural networks,” in Acoustics, speech and signal processing (icassp),
    2013 IEEE international conference on, 6645–6649, IEEE (2013).'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] A. Graves, A.-r. Mohamed, 和 G. Hinton，“基于深度递归神经网络的语音识别，” 在声学、语音和信号处理（icassp）中，2013
    IEEE 国际会议，6645–6649，IEEE (2013)。'
- en: '[83] W. Luo, A. G. Schwing, and R. Urtasun, “Efficient deep learning for stereo
    matching,” in Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition, 5695–5703 (2016).'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] W. Luo, A. G. Schwing, 和 R. Urtasun，“高效深度学习用于立体匹配，” 在 IEEE 计算机视觉与模式识别会议论文集中，5695–5703
    (2016)。'
- en: '[84] S. Levine, P. Pastor, A. Krizhevsky, et al., “Learning hand-eye coordination
    for robotic grasping with deep learning and large-scale data collection,” arXiv
    preprint arXiv:1603.02199 (2016).'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] S. Levine，P. Pastor，A. Krizhevsky 等，"利用深度学习和大规模数据收集学习手眼协调以进行机器人抓取"，arXiv
    预印本 arXiv:1603.02199 (2016)。'
- en: '[85] S. Venugopalan, M. Rohrbach, J. Donahue, et al., “Sequence to sequence-video
    to text,” in Proceedings of the IEEE International Conference on Computer Vision,
    4534–4542 (2015).'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] S. Venugopalan，M. Rohrbach，J. Donahue 等，"序列到序列-视频到文本"，发表于 IEEE 国际计算机视觉会议论文集，4534–4542
    (2015)。'
- en: '[86] R. Collobert, “Deep learning for efficient discriminative parsing.,” in
    AISTATS, 15, 224–232 (2011).'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] R. Collobert，"高效判别解析的深度学习"，发表于 AISTATS，15，224–232 (2011)。'
- en: '[87] S. Venugopalan, H. Xu, J. Donahue, et al., “Translating videos to natural
    language using deep recurrent neural networks,” arXiv preprint arXiv:1412.4729
    (2014).'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] S. Venugopalan，H. Xu，J. Donahue 等，"使用深度递归神经网络将视频翻译为自然语言"，arXiv 预印本 arXiv:1412.4729
    (2014)。'
- en: '[88] Y. H. Tan and C. S. Chan, “phi-lstm: A phrase-based hierarchical LSTM
    model for image captioning,” in 13th Asian Conference on Computer Vision (ACCV),
    101–117 (2016).'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] Y. H. Tan 和 C. S. Chan，"phi-lstm：一种用于图像描述的基于短语的层次化 LSTM 模型"，发表于第十三届亚洲计算机视觉大会（ACCV），101–117
    (2016)。'
- en: '[89] A. Karpathy and L. Fei-Fei, “Deep visual-semantic alignments for generating
    image descriptions,” in Proceedings of the IEEE Conference on Computer Vision
    and Pattern Recognition (CVPR), 3128–3137 (2015).'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] A. Karpathy 和 L. Fei-Fei，"深度视觉-语义对齐生成图像描述"，发表于 IEEE 计算机视觉与模式识别会议（CVPR）论文集，3128–3137
    (2015)。'
- en: '[90] P. Baldi, P. Sadowski, and D. Whiteson, “Searching for exotic particles
    in high-energy physics with deep learning,” Nature communications 5 (2014).'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] P. Baldi，P. Sadowski 和 D. Whiteson，"在高能物理中使用深度学习寻找异质粒子"，自然通讯 5 (2014)。'
- en: '[91] J. Wu, I. Yildirim, J. J. Lim, et al., “Galileo: Perceiving physical object
    properties by integrating a physics engine with deep learning,” in Advances in
    neural information processing systems, 127–135 (2015).'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] J. Wu，I. Yildirim，J. J. Lim 等，"Galileo：通过将物理引擎与深度学习结合感知物理对象属性"，发表于神经信息处理系统进展，127–135
    (2015)。'
- en: '[92] A. A. Cruz-Roa, J. E. A. Ovalle, A. Madabhushi, et al., “A deep learning
    architecture for image representation, visual interpretability and automated basal-cell
    carcinoma cancer detection,” in International Conference on Medical Image Computing
    and Computer-Assisted Intervention, 403–410, Springer (2013).'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] A. A. Cruz-Roa，J. E. A. Ovalle，A. Madabhushi 等，"用于图像表示、视觉可解释性和自动化基底细胞癌检测的深度学习架构"，发表于国际医学图像计算与计算机辅助手术会议，403–410，Springer
    (2013)。'
- en: '[93] R. Fakoor, F. Ladhak, A. Nazi, et al., “Using deep learning to enhance
    cancer diagnosis and classification,” in Proceedings of the International Conference
    on Machine Learning, (2013).'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] R. Fakoor，F. Ladhak，A. Nazi 等，"使用深度学习增强癌症诊断与分类"，发表于国际机器学习会议论文集，(2013)。'
- en: '[94] K. Sirinukunwattana, S. E. A. Raza, Y.-W. Tsang, et al., “Locality sensitive
    deep learning for detection and classification of nuclei in routine colon cancer
    histology images,” IEEE transactions on medical imaging 35(5), 1196–1206 (2016).'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] K. Sirinukunwattana，S. E. A. Raza，Y.-W. Tsang 等，"用于常规结肠癌组织学图像中核检测与分类的局部敏感深度学习"，IEEE
    医学影像学期刊 35(5)，1196–1206 (2016)。'
- en: '[95] M. Längkvist, L. Karlsson, and A. Loutfi, “A review of unsupervised feature
    learning and deep learning for time-series modeling,” Pattern Recognition Letters
    42, 11–24 (2014).'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] M. Längkvist，L. Karlsson 和 A. Loutfi，"时间序列建模中的无监督特征学习和深度学习综述"，模式识别快报 42，11–24
    (2014)。'
- en: '[96] S. Sarkar, K. G. Lore, S. Sarkar, et al., “Early detection of combustion
    instability from hi-speed flame images via deep learning and symbolic time series
    analysis,” in Annual Conference of The Prognostics and Health Management, (2015).'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] S. Sarkar，K. G. Lore，S. Sarkar 等，"通过深度学习和符号时间序列分析从高速火焰图像中早期检测燃烧不稳定性"，发表于预测与健康管理年会，(2015)。'
- en: '[97] T. Kuremoto, S. Kimura, K. Kobayashi, et al., “Time series forecasting
    using a deep belief network with restricted boltzmann machines,” Neurocomputing
    137, 47–56 (2014).'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] T. Kuremoto，S. Kimura，K. Kobayashi 等，"使用限制玻尔兹曼机的深度信念网络进行时间序列预测"，神经计算 137，47–56
    (2014)。'
- en: '[98] A. Dosovitskiy, J. Tobias Springenberg, and T. Brox, “Learning to generate
    chairs with convolutional neural networks,” in Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition, 1538–1546 (2015).'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] A. Dosovitskiy，J. Tobias Springenberg 和 T. Brox，"利用卷积神经网络生成椅子"，发表于 IEEE
    计算机视觉与模式识别会议论文集，1538–1546 (2015)。'
- en: '[99] J. Zhao, M. Mathieu, and Y. LeCun, “Energy-based generative adversarial
    network,” arXiv preprint arXiv:1609.03126 (2016).'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] S. E. Reed, Z. Akata, S. Mohan, et al., “Learning what and where to draw,”
    in Advances in Neural Information Processing Systems, 217–225 (2016).'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] D. Berthelot, T. Schumm, and L. Metz, “Began: Boundary equilibrium generative
    adversarial networks,” arXiv preprint arXiv:1703.10717 (2017).'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] W. R. Tan, C. S. Chan, H. Aguirre, et al., “Artgan: Artwork synthesis
    with conditional categorial gans,” arXiv preprint arXiv:1702.03410 (2017).'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] K. Gregor, I. Danihelka, A. Graves, et al., “Draw: A recurrent neural
    network for image generation,” arXiv preprint arXiv:1502.04623 (2015).'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] A. Radford, L. Metz, and S. Chintala, “Unsupervised representation learning
    with deep convolutional generative adversarial networks,” arXiv preprint arXiv:1511.06434
    (2015).'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] X. Ding, Y. Zhang, T. Liu, et al., “Deep learning for event-driven stock
    prediction,” in IJCAI, 2327–2333 (2015).'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] Z. Yuan, Y. Lu, Z. Wang, et al., “Droid-sec: deep learning in android
    malware detection,” in ACM SIGCOMM Computer Communication Review, 44(4), 371–372,
    ACM (2014).'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] C. Cadena, A. Dick, and I. D. Reid, “Multi-modal Auto-Encoders as Joint
    Estimators for Robotics Scene Understanding,” in Proceedings of Robotics: Science
    and Systems Conference (RSS), (2016).'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] J. Feng, Y. Wang, and S.-F. Chang, “3D Shape Retrieval Using a Single
    Depth Image from Low-cost Sensors,” in 2016 IEEE Winter Conference on Applications
    of Computer Vision (WACV), 1–9 (2016).'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] A. Haque, A. Alahi, and L. Fei-fei, “Recurrent Attention Models for Depth-Based
    Person Identification,” in 2016 IEEE Conference on Computer Vision and Pattern
    Recognition (CVPR), 1229–1238 (2016).'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] V. Hegde Stanford and R. Zadeh Stanford, “FusionNet: 3D Object Classification
    Using Multiple Data Representations,” arXiv preprint arXiv:1607.05695 (2016).'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] J. Huang and S. You, “Point Cloud Labeling using 3D Convolutional Neural
    Network,” in International Conference on Pattern Recognition, (December) (2016).'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] W. Kehl, F. Milletari, F. Tombari, et al., “Deep Learning of Local RGB-D
    Patches for 3D Object Detection and 6D Pose Estimation,” in European Conference
    on Computer Vision, 205–220 (2016).'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] C. Li, A. Reiter, and G. D. Hager, “Beyond Spatial Pooling: Fine-Grained
    Representation Learning in Multiple Domains,” Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition 2(1), 4913–4922 (2015).'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] N. Sedaghat, M. Zolfaghari, and T. Brox, “Orientation-boosted Voxel Nets
    for 3D Object Recognition,” arXiv preprint arXiv:1604.03351 (2016).'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] Z. Xie, K. Xu, W. Shan, et al., “Projective Feature Learning for 3D Shapes
    with Multi-View Depth Images,” in Computer Graphics Forum, 34(7), 1–11, Wiley
    Online Library (2015).'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[116] C. Chen, “DeepDriving : Learning Affordance for Direct Perception in
    Autonomous Driving,” in Proceedings of the IEEE International Conference on Computer
    Vision, 2722–2730 (2015).'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] C. Chen，“DeepDriving : 学习自动驾驶中的直接感知能力，”见于 IEEE 国际计算机视觉会议论文集, 2722–2730
    (2015)。'
- en: '[117] X. Chen, H. Ma, J. Wan, et al., “Multi-View 3D Object Detection Network
    for Autonomous Driving,” arXiv preprint arXiv:1611.07759 (2016).'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] X. Chen, H. Ma, J. Wan 等，“用于自动驾驶的多视图3D目标检测网络，”arXiv 预印本 arXiv:1611.07759
    (2016)。'
- en: '[118] A. Chigorin and A. Konushin, “A system for large-scale automatic traffic
    sign recognition and mapping,” CMRT13–City Models, Roads and Traffic 2013, 13–17
    (2013).'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] A. Chigorin 和 A. Konushin，“大规模自动交通标志识别与映射系统，”CMRT13–城市模型、道路与交通 2013,
    13–17 (2013)。'
- en: '[119] D. Ciresan, U. Meier, and J. Schmidhuber, “Multi-column deep neural networks
    for image classification,” in 2012 IEEE Conf. on Computer Vision and Pattern Recog.
    (CVPR), (February), 3642–3649 (2012).'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] D. Ciresan, U. Meier 和 J. Schmidhuber，“用于图像分类的多列深度神经网络，”见于 2012 IEEE
    计算机视觉与模式识别会议 (CVPR), (2月), 3642–3649 (2012)。'
- en: '[120] Y. Zeng, X. Xu, Y. Fang, et al., “Traffic sign recognition using extreme
    learning classifier with deep convolutional features,” in The 2015 international
    conference on intelligence science and big data engineering (IScIDE 2015), Suzhou,
    China, (2015).'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] Y. Zeng, X. Xu, Y. Fang 等，“使用极限学习分类器和深度卷积特征的交通标志识别，”见于 2015 国际智能科学与大数据工程会议
    (IScIDE 2015), 苏州, 中国 (2015)。'
- en: '[121] A.-B. Salberg, “Detection of seals in remote sensing images using features
    extracted from deep convolutional neural networks,” in 2015 IEEE International
    Geoscience and Remote Sensing Symposium (IGARSS), (0373), 1893–1896 (2015).'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] A.-B. Salberg，“使用深度卷积神经网络提取的特征检测遥感图像中的海豹，”见于 2015 IEEE 国际地球科学与遥感研讨会 (IGARSS),
    (0373), 1893–1896 (2015)。'
- en: '[122] W. Li, G. Wu, and Q. Du, “Transferred Deep Learning for Anomaly Detection
    in Hyperspectral Imagery,” IEEE Geoscience and Remote Sensing Letters PP(99),
    1–5 (2017).'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] W. Li, G. Wu 和 Q. Du，“用于高光谱图像异常检测的迁移深度学习，”IEEE 地球科学与遥感快报 PP(99), 1–5
    (2017)。'
- en: '[123] J. Becker, T. C. Havens, A. Pinar, et al., “Deep belief networks for
    false alarm rejection in forward-looking ground-penetrating radar,” in SPIE Defense+
    Security, 94540W–94540W, International Society for Optics and Photonics (2015).'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] J. Becker, T. C. Havens, A. Pinar 等，“用于前视地面穿透雷达中虚警拒绝的深度置信网络，”见于 SPIE
    Defense+ Security, 94540W–94540W, 国际光学与光子学学会 (2015)。'
- en: '[124] C. Bentes, D. Velotto, and S. Lehner, “Target classification in oceanographic
    SAR images with deep neural networks: Architecture and initial results,” in 2015
    IEEE International Geoscience and Remote Sensing Symposium (IGARSS), 3703–3706,
    IEEE (2015).'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] C. Bentes, D. Velotto 和 S. Lehner，“基于深度神经网络的海洋SAR图像目标分类：架构和初步结果，”见于 2015
    IEEE 国际地球科学与遥感研讨会 (IGARSS), 3703–3706, IEEE (2015)。'
- en: '[125] L. E. Besaw, “Detecting buried explosive hazards with handheld GPR and
    deep learning,” in SPIE Defense+ Security, 98230N–98230N, International Society
    for Optics and Photonics (2016).'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] L. E. Besaw，“使用手持 GPR 和深度学习检测埋藏的爆炸性危险，”见于 SPIE Defense+ Security, 98230N–98230N,
    国际光学与光子学学会 (2016)。'
- en: '[126] L. E. Besaw and P. J. Stimac, “Deep learning algorithms for detecting
    explosive hazards in ground penetrating radar data,” in SPIE Defense+ Security,
    90720Y–90720Y, International Society for Optics and Photonics (2014).'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] L. E. Besaw 和 P. J. Stimac，“用于检测地面穿透雷达数据中爆炸性危险的深度学习算法，”见于 SPIE Defense+
    Security, 90720Y–90720Y, 国际光学与光子学学会 (2014)。'
- en: '[127] K. Du, Y. Deng, R. Wang, et al., “SAR ATR based on displacement-and rotation-insensitive
    CNN,” Remote Sensing Letters 7(9), 895–904 (2016). DOI:10.1080/2150704X.2016.1196837.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] K. Du, Y. Deng, R. Wang 等，“基于位移和旋转不敏感CNN的SAR ATR，”遥感快报 7(9), 895–904
    (2016)。DOI:10.1080/2150704X.2016.1196837。'
- en: '[128] S. Chen and H. Wang, “SAR target recognition based on deep learning,”
    in Data Science and Advanced Analytics (DSAA), 2014 International Conference on,
    541–547, IEEE (2014). DOI:10.1109/dsaa.2014.7058124.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] S. Chen 和 H. Wang，“基于深度学习的SAR目标识别，”见于 数据科学与高级分析 (DSAA), 2014 国际会议, 541–547,
    IEEE (2014)。DOI:10.1109/dsaa.2014.7058124。'
- en: '[129] D. A. E. Morgan, “Deep convolutional neural networks for ATR from SAR
    imagery,” in SPIE Defense+ Security, 94750F–94750F, International Society for
    Optics and Photonics (2015). DOI:10.1117/12.2176558.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] D. A. E. Morgan，“用于SAR图像的深度卷积神经网络自动目标识别，”见于 SPIE Defense+ Security, 94750F–94750F,
    国际光学与光子学学会 (2015)。DOI:10.1117/12.2176558。'
- en: '[130] J. C. Ni and Y. L. Xu, “SAR automatic target recognition based on a visual
    cortical system,” in Image and Signal Processing (CISP), 2013 6th International
    Congress on, 2, 778–782, IEEE (2013). DOI:10.1109/cisp.2013.6745270.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] J. C. Ni 和 Y. L. Xu，“基于视觉皮层系统的SAR自动目标识别”，发表于2013年第六届国际图像与信号处理大会（CISP），2，778–782，IEEE（2013）。DOI:10.1109/cisp.2013.6745270。'
- en: '[131] Z. Sun, L. Xue, and Y. Xu, “Recognition of sar target based on multilayer
    auto-encoder and snn,” International Journal of Innovative Computing, Information
    and Control 9(11), 4331–4341 (2013).'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] Z. Sun, L. Xue, 和 Y. Xu，“基于多层自编码器和SNN的SAR目标识别”，《国际创新计算、信息与控制杂志》9(11)，4331–4341（2013）。'
- en: '[132] H. Wang, S. Chen, F. Xu, et al., “Application of deep-learning algorithms
    to MSTAR data,” in Geoscience and Remote Sensing Symposium (IGARSS), 2015 IEEE
    International, 3743–3745, IEEE (2015). DOI:10.1109/igarss.2015.7326637.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] H. Wang, S. Chen, F. Xu, 等，“深度学习算法在MSTAR数据中的应用”，发表于2015年IEEE国际地球科学与遥感研讨会（IGARSS），3743–3745，IEEE（2015）。DOI:10.1109/igarss.2015.7326637。'
- en: '[133] L. Zhang, L. Zhang, D. Tao, et al., “A multifeature tensor for remote-sensing
    target recognition,” IEEE Geoscience and Remote Sensing Letters 8(2), 374–378
    (2011). DOI:10.1109/LGRS.2010.2077272.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] L. Zhang, L. Zhang, D. Tao, 等，“一种多特征张量用于遥感目标识别”，《IEEE地球科学与遥感快报》8(2)，374–378（2011）。DOI:10.1109/LGRS.2010.2077272。'
- en: '[134] L. Zhang, Z. Shi, and J. Wu, “A hierarchical oil tank detector with deep
    surrounding features for high-resolution optical satellite imagery,” IEEE Journal
    of Selected Topics in Applied Earth Observations and Remote Sensing 8(10), 4895–4909
    (2015).'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] L. Zhang, Z. Shi, 和 J. Wu，“一种针对高分辨率光学卫星图像的具有深度周边特征的分层油罐检测器”，《IEEE应用地球观测与遥感精选主题杂志》8(10)，4895–4909（2015）。'
- en: '[135] P. F. Alcantarilla, S. Stent, G. Ros, et al., “Streetview change detection
    with deconvolutional networks,” in Robotics: Science and Systems Conference (RSS),
    (2016).'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] P. F. Alcantarilla, S. Stent, G. Ros, 等，“使用反卷积网络进行街景变化检测”，发表于机器人：科学与系统会议（RSS）（2016）。'
- en: '[136] M. Gong, Z. Zhou, and J. Ma, “Change Detection in Synthetic aperture
    Radar Images Based on Deep Neural Networks,” IEEE Transactions on Neural Networks
    and Learning Systems 27(4), 2141–51 (2016).'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] M. Gong, Z. Zhou, 和 J. Ma，“基于深度神经网络的合成孔径雷达图像变化检测”，《IEEE神经网络与学习系统汇刊》27(4)，2141–2151（2016）。'
- en: '[137] F. Pacifici, F. Del Frate, C. Solimini, et al., “An Innovative Neural-Net
    Method to Detect Temporal Changes in High-Resolution Optical Satellite Imagery,”
    IEEE Transactions on Geoscience and Remote Sensing 45(9), 2940–2952 (2007).'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] F. Pacifici, F. Del Frate, C. Solimini, 等，“一种创新的神经网络方法用于检测高分辨率光学卫星图像中的时间变化”，《IEEE地球科学与遥感汇刊》45(9)，2940–2952（2007）。'
- en: '[138] S. Stent, “Detecting Change for Multi-View, Long-Term Surface Inspection,”
    in Proceedings of the 2015 British Machine Vision Conference (BCMV), 1–12 (2015).'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] S. Stent, “用于多视角长期表面检测的变化检测”，发表于2015年英国机器视觉会议（BCMV）论文集，1–12（2015）。'
- en: '[139] J. Zhao, M. Gong, J. Liu, et al., “Deep learning to classify difference
    image for image change detection,” in Neural Networks (IJCNN), 2014 International
    Joint Conference on, 411–417, IEEE (2014).'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] J. Zhao, M. Gong, J. Liu, 等，“使用深度学习对差异图像进行分类以进行图像变化检测”，发表于2014年国际联合神经网络会议（IJCNN），411–417，IEEE（2014）。'
- en: '[140] S. Basu, S. Ganguly, S. Mukhopadhyay, et al., “DeepSat - A Learning framework
    for Satellite Imagery,” in Proceedings of the 23rd SIGSPATIAL International Conference
    on Advances in Geographic Information Systems, 1–22 (2015).'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] S. Basu, S. Ganguly, S. Mukhopadhyay, 等，“DeepSat - 卫星影像学习框架”，发表于第23届SIGSPATIAL国际地理信息系统进展会议论文集，1–22（2015）。'
- en: '[141] Y. Bazi, N. Alajlan, F. Melgani, et al., “Differential Evolution Extreme
    Learning Machine for the Classification of Hyperspectral Images,” IEEE Geoscience
    and Remote Sensing Letters 11(6), 1066–1070 (2014).'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] Y. Bazi, N. Alajlan, F. Melgani, 等，“用于高光谱图像分类的差分进化极限学习机”，《IEEE地球科学与遥感快报》11(6)，1066–1070（2014）。'
- en: '[142] J. Cao, Z. Chen, and B. Wang, “Deep Convolutional Networks With Superpixel
    Segmentation for Hyperspectral Image Classification,” in 2016 IEEE Geoscience
    and Remote Sensing Symposium (IGARSS), 3310–3313 (2016).'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] J. Cao, Z. Chen, 和 B. Wang，“结合超像素分割的深度卷积网络用于高光谱图像分类”，发表于2016年IEEE地球科学与遥感研讨会（IGARSS），3310–3313（2016）。'
- en: '[143] J. Cao, Z. Chen, and B. Wang, “Graph-Based Deep Convolutional Networks
    With Superpixel Segmentation for Hyperspectral Image Classification,” in 2016
    IEEE Geoscience and Remote Sensing Symposium (IGARSS), 3310–3313 (2016).'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] J. Cao, Z. Chen, 和 B. Wang，“基于图的深度卷积网络与超像素分割用于高光谱图像分类”，发表于2016年IEEE地球科学与遥感研讨会（IGARSS），3310–3313（2016）。'
- en: '[144] C. Chen, W. Li, H. Su, et al., “Spectral-spatial classification of hyperspectral
    image based on kernel extreme learning machine,” Remote Sensing 6(6), 5795–5814
    (2014).'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] C. Chen, W. Li, H. Su, 等，“基于核极限学习机的高光谱图像光谱空间分类”，遥感6(6)，5795–5814（2014年）。'
- en: '[145] G. Cheng, C. Ma, P. Zhou, et al., “Scene Classification of High Resolution
    Remote Sensing Images Using Convolutional Neural Networks,” in 2016 IEEE Geoscience
    and Remote Sensing Symposium (IGARSS), 767–770 (2016).'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] G. Cheng, C. Ma, P. Zhou, 等，“使用卷积神经网络的高分辨率遥感图像场景分类”，见于2016 IEEE地球科学与遥感研讨会（IGARSS），767–770（2016年）。'
- en: '[146] F. Del Frate, F. Pacifici, G. Schiavon, et al., “Use of neural networks
    for automatic classification from high-resolution images,” IEEE Transactions on
    Geoscience and Remote Sensing 45(4), 800–809 (2007).'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] F. Del Frate, F. Pacifici, G. Schiavon, 等，“使用神经网络进行高分辨率图像的自动分类”，IEEE地球科学与遥感汇刊45(4)，800–809（2007年）。'
- en: '[147] Z. Fang, W. Li, and Q. Du, “Using CNN-based high-level features for remote
    sensing scene classification,” in IEEE Geoscience and Remote Sensing Symposium
    (IGARSS), 2610–2613 (2016).'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] Z. Fang, W. Li, 和 Q. Du，“使用基于CNN的高级特征进行遥感场景分类”，见于IEEE地球科学与遥感研讨会（IGARSS），2610–2613（2016年）。'
- en: '[148] Q. Fu, X. Yu, X. Wei, et al., “Semi-supervised classification of hyperspectral
    imagery based on stacked autoencoders,” in Eighth International Conference on
    Digital Image Processing (ICDIP 2016), 100332B–100332B, International Society
    for Optics and Photonics (2016).'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] Q. Fu, X. Yu, X. Wei, 等，“基于堆叠自编码器的高光谱图像半监督分类”，见于第八届数字图像处理国际会议（ICDIP 2016），100332B–100332B，国际光学与光子学学会（2016年）。'
- en: '[149] J. Geng, J. Fan, H. Wang, et al., “High-Resolution SAR Image Classification
    via Deep Convolutional Autoencoders,” IEEE Geoscience and Remote Sensing Letters
    12(11), 2351–2355 (2015).'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] J. Geng, J. Fan, H. Wang, 等，“通过深度卷积自编码器进行高分辨率SAR图像分类”，IEEE地球科学与遥感快报12(11)，2351–2355（2015年）。'
- en: '[150] X. Han, Y. Zhong, B. Zhao, et al., “Scene classification based on a hierarchical
    convolutional sparse auto-encoder for high spatial resolution imagery,” International
    Journal of Remote Sensing 38(2), 514–536 (2017).'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] X. Han, Y. Zhong, B. Zhao, 等，“基于分层卷积稀疏自编码器的高空间分辨率图像场景分类”，国际遥感杂志38(2)，514–536（2017年）。'
- en: '[151] M. He, X. Li, Y. Zhang, et al., “Hyperspectral image classification based
    on deep stacking network,” in 2016 IEEE Geoscience and Remote Sensing Symposium
    (IGARSS), 3286–3289 (2016).'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] M. He, X. Li, Y. Zhang, 等，“基于深度堆叠网络的高光谱图像分类”，见于2016 IEEE地球科学与遥感研讨会（IGARSS），3286–3289（2016年）。'
- en: '[152] B. Hou, X. Luo, S. Wang, et al., “Polarimetric Sar Images Classification
    Using Deep Belief Networks with Learning Features,” in 2015 IEEE International
    Geoscience and Remote Sensing Symposium (IGARSS), (2), 2366–2369 (2015).'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] B. Hou, X. Luo, S. Wang, 等，“使用深度信念网络与学习特征的极化SAR图像分类”，见于2015 IEEE国际地球科学与遥感研讨会（IGARSS），（2），2366–2369（2015年）。'
- en: '[153] W. Hu, Y. Huang, L. Wei, et al., “Deep convolutional neural networks
    for hyperspectral image classification,” Journal of Sensors 2015, 1–12 (2015).'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] W. Hu, Y. Huang, L. Wei, 等，“用于高光谱图像分类的深度卷积神经网络”，传感器期刊2015，1–12（2015年）。'
- en: '[154] M. Iftene, Q. Liu, and Y. Wang, “Very high resolution images classification
    by fine tuning deep convolutional neural networks,” in Eighth International Conference
    on Digital Image Processing (ICDIP 2016), 100332D–100332D, International Society
    for Optics and Photonics (2016).'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] M. Iftene, Q. Liu, 和 Y. Wang，“通过微调深度卷积神经网络进行超高分辨率图像分类”，见于第八届数字图像处理国际会议（ICDIP
    2016），100332D–100332D，国际光学与光子学学会（2016年）。'
- en: '[155] P. Jia, M. Zhang, Wenbo Yu, et al., “Convolutional Neural Network Based
    Classification for Hyperspectral Data,” in 2016 IEEE Geoscience and Remote Sensing
    Symposium (IGARSS), 5075–5078 (2016).'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] P. Jia, M. Zhang, Wenbo Yu, 等，“基于卷积神经网络的高光谱数据分类”，见于2016 IEEE地球科学与遥感研讨会（IGARSS），5075–5078（2016年）。'
- en: '[156] P. Kontschieder, M. Fiterau, A. Criminisi, et al., “Deep neural decision
    forests,” in Proceedings of the IEEE International Conference on Computer Vision,
    1467–1475 (2015).'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] P. Kontschieder, M. Fiterau, A. Criminisi, 等，“深度神经决策森林”，见于IEEE国际计算机视觉会议论文集，1467–1475（2015年）。'
- en: '[157] M. Längkvist, A. Kiselev, M. Alirezaie, et al., “Classification and segmentation
    of satellite orthoimagery using convolutional neural networks,” Remote Sensing
    8(4), 1–21 (2016).'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] M. Längkvist, A. Kiselev, M. Alirezaie, 等，“使用卷积神经网络的卫星正射影像分类与分割”，遥感8(4)，1–21（2016年）。'
- en: '[158] H. Lee and H. Kwon, “Contextual Deep CNN Based Hyperspectral Classification,”
    in 2016 IEEE Geoscience and Remote Sensing Symposium (IGARSS), 1604.03519, 2–4
    (2016).'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] H. Lee 和 H. Kwon, “基于上下文深度卷积神经网络的高光谱分类，” 见于2016 IEEE 地球科学与遥感研讨会 (IGARSS),
    1604.03519, 2–4 (2016)。'
- en: '[159] J. Li, “Active learning for hyperspectral image classification with a
    stacked autoencoders based neural network,” in 2016 IEEE Internation Conference
    on Image Processing (ICIP), 1062–1065 (2016).'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[159] J. Li, “基于堆叠自编码器的神经网络进行高光谱图像分类的主动学习，” 见于2016 IEEE 国际图像处理大会 (ICIP), 1062–1065
    (2016)。'
- en: '[160] J. Li, L. Bruzzone, and S. Liu, “Deep feature representation for hyperspectral
    image classification,” in 2015 IEEE International Geoscience and Remote Sensing
    Symposium (IGARSS), 4951–4954 (2015).'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[160] J. Li, L. Bruzzone 和 S. Liu, “高光谱图像分类的深度特征表示，” 见于2015 IEEE 国际地球科学与遥感研讨会
    (IGARSS), 4951–4954 (2015)。'
- en: '[161] T. Li, J. Zhang, and Y. Zhang, “Classification of hyperspectral image
    based on deep belief networks,” in 2014 IEEE International Conference on Image
    Processing (ICIP), 5132–5136 (2014).'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[161] T. Li, J. Zhang 和 Y. Zhang, “基于深度置信网络的高光谱图像分类，” 见于2014 IEEE 国际图像处理大会
    (ICIP), 5132–5136 (2014)。'
- en: '[162] W. Li, G. Wu, F. Zhang, et al., “Hyperspectral image classification using
    deep pixel-pair features,” IEEE Transactions on Geoscience and Remote Sensing
    55(2), 844–853 (2017).'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[162] W. Li, G. Wu, F. Zhang 等, “使用深度像素对特征的高光谱图像分类，” 《IEEE 地球科学与遥感学报》 55(2),
    844–853 (2017)。'
- en: '[163] Y. Li, W. Xie, and H. Li, “Hyperspectral image reconstruction by deep
    convolutional neural network for classification,” Pattern Recognition 63(August
    2016), 371–383 (2016).'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[163] Y. Li, W. Xie 和 H. Li, “通过深度卷积神经网络进行高光谱图像重建以进行分类，” 《模式识别》 63(2016年8月),
    371–383 (2016)。'
- en: '[164] Z. Lin, Y. Chen, X. Zhao, et al., “Spectral-spatial classification of
    hyperspectral image using autoencoders,” in Information, Communications and Signal
    Processing (ICICS) 2013 9th International Conference on, 1–5, IEEE (2013).'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[164] Z. Lin, Y. Chen, X. Zhao 等, “使用自编码器的高光谱图像光谱空间分类，” 见于信息、通信与信号处理 (ICICS)
    2013年第九届国际会议, 1–5, IEEE (2013)。'
- en: '[165] Z. Lin, Y. Chen, X. Zhao, et al., “Spectral-spatial classification of
    hyperspectral image using autoencoders,” in 2013 9th International Conference
    on Information, Communications & Signal Processing, (61301206), 1–5 (2013).'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[165] Z. Lin, Y. Chen, X. Zhao 等, “使用自编码器的高光谱图像光谱空间分类，” 见于2013年第九届国际信息、通信与信号处理会议,
    (61301206), 1–5 (2013)。'
- en: '[166] Y. Liu, G. Cao, Q. Sun, et al., “Hyperspectral classification via deep
    networks and superpixel segmentation,” International Journal of Remote Sensing
    36(13), 3459–3482 (2015).'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[166] Y. Liu, G. Cao, Q. Sun 等, “通过深度网络和超像素分割进行高光谱分类，” 《国际遥感杂志》 36(13), 3459–3482
    (2015)。'
- en: '[167] Y. Liu, P. Lasang, M. Siegel, et al., “Hyperspectral Classification via
    Learnt Features,” in International Conference on Image Processing (ICIP), 1–5
    (2015).'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[167] Y. Liu, P. Lasang, M. Siegel 等, “通过学习特征进行高光谱分类，” 见于国际图像处理大会 (ICIP), 1–5
    (2015)。'
- en: '[168] P. Liu, H. Zhang, and K. B. Eom, “Active Deep Learning for Classification
    of Hyperspectral Images,” IEEE Journal of Selected Topics in Applied Earth Observations
    and Remote Sensing 10(2), 712–724 (2016).'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[168] P. Liu, H. Zhang 和 K. B. Eom, “用于高光谱图像分类的主动深度学习，” 《IEEE 应用地球观测与遥感精选专题期刊》
    10(2), 712–724 (2016)。'
- en: '[169] X. Ma, H. Wang, and J. Geng, “Spectral-spatial classification of hyperspectral
    image based on deep auto-encoder,” IEEE Journal of Selected Topics in Applied
    Earth Observations and Remote Sensing 9(9), 4073–4085 (2016).'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[169] X. Ma, H. Wang 和 J. Geng, “基于深度自编码器的高光谱图像光谱空间分类，” 《IEEE 应用地球观测与遥感精选专题期刊》
    9(9), 4073–4085 (2016)。'
- en: '[170] X. Ma, H. Wang, J. Geng, et al., “Hyperspectral image classification
    with small training set by deep network and relative distance prior,” in 2016
    IEEE Geoscience and Remote Sensing Symposium (IGARSS), 3282–3285, IEEE (2016).'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[170] X. Ma, H. Wang, J. Geng 等, “通过深度网络和相对距离先验对小训练集的高光谱图像分类，” 见于2016 IEEE
    地球科学与遥感研讨会 (IGARSS), 3282–3285, IEEE (2016)。'
- en: '[171] X. Mei, Y. Ma, F. Fan, et al., “Infrared ultraspectral signature classification
    based on a restricted Boltzmann machine with sparse and prior constraints,” International
    Journal of Remote Sensing 36(18), 4724–4747 (2015).'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[171] X. Mei, Y. Ma, F. Fan 等, “基于具有稀疏和先验约束的限制玻尔兹曼机的红外超光谱特征分类，” 《国际遥感杂志》 36(18),
    4724–4747 (2015)。'
- en: '[172] S. Mei, J. Ji, Q. Bi, et al., “Integrating spectral and spatial information
    into deep convolutional Neural Networks for hyperspectral classification,” in
    2016 IEEE Geoscience and Remote Sensing Symposium (IGARSS), 5067–5070 (2016).'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[173] A. Merentitis and C. Debes, “Automatic Fusion and Classification Using
    Random Forests and Features Extracted with Deep Learning,” in 2015 IEEE International
    Geoscience and Remote Sensing Symposium (IGARSS), 2943–2946 (2015).'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[174] K. Nogueira, O. A. B. Penatti, and J. A. dos Santos, “Towards better
    exploiting convolutional neural networks for remote sensing scene classification,”
    Pattern Recognition 61, 539–556 (2017).'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[175] B. Pan, Z. Shi, and X. Xu, “R-VCANet: A New Deep-Learning-Based Hyperspectral
    Image Classification Method,” IEEE Journal of Selected Topics in Applied Earth
    Observations and Remote Sensing PP(99), 1–12 (2017).'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[176] M. Papadomanolaki, M. Vakalopoulou, S. Zagoruyko, et al., “Benchmarking
    Deep Learning Frameworks for the Classification of Very High Resolution Satellite
    Multispectral Data,” ISPRS Annals of Photogrammetry, Remote Sensing and Spatial
    Information Sciences , 83–88 (2016).'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[177] S. Piramanayagam, W. Schwartzkopf, F. W. Koehler, et al., “Classification
    of remote sensed images using random forests and deep learning framework,” in
    SPIE Remote Sensing, 100040L–100040L, International Society for Optics and Photonics
    (2016).'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[178] F. Qin, J. Guo, and W. Sun, “Object-oriented ensemble classification
    for polarimetric SAR Imagery using restricted Boltzmann machines,” Remote Sensing
    Letters 8(3), 204–213 (2017).'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[179] S. Rajan, J. Ghosh, and M. M. Crawford, “An Active Learning Approach
    to Hyperspectral Data Classification,” IEEE Transactions on Geoscience and Remote
    Sensing 46(4), 1231–1242 (2008).'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[180] Z. Wang, N. M. Nasrabadi, and T. S. Huang, “Semisupervised hyperspectral
    classification using task-driven dictionary learning with laplacian regularization,”
    IEEE Transactions on Geoscience and Remote Sensing 53(3), 1161–1173 (2015).'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[181] J. Yang, Y. Zhao, J. Cheung, et al., “Hyperspectral Image Classification
    Using Two-Channel Deep Convolutional Neural Network,” in 2016 IEEE Geoscience
    and Remote Sensing Symposium (IGARSS), 5079–5082 (2016).'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[182] S. Yu, S. Jia, and C. Xu, “Convolutional neural networks for hyperspectral
    image classification,” Neurocomputing 219, 88–98 (2017).'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[183] J. Yue, S. Mao, and M. Li, “A deep learning framework for hyperspectral
    image classification using spatial pyramid pooling,” Remote Sensing Letters 7(9),
    875–884 (2016).'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[184] J. Yue, W. Zhao, S. Mao, et al., “Spectral-spatial classification of
    hyperspectral images using deep convolutional neural networks,” Remote Sensing
    Letters 6(6), 468–477 (2015).'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[185] A. Zeggada and F. Melgani, “Multilabel classification of UAV images with
    Convolutional Neural Networks,” in 2016 IEEE Geoscience and Remote Sensing Symposium
    (IGARSS), 5083–5086, IEEE (2016).'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[186] F. Zhang, B. Du, and L. Zhang, “Scene classification via a gradient boosting
    random convolutional network framework,” IEEE Transactions on Geoscience and Remote
    Sensing 54(3), 1793–1802 (2016).'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[186] F. Zhang, B. Du, 和 L. Zhang， “通过梯度提升随机卷积网络框架进行场景分类，” IEEE地球科学与遥感学报 54(3)，1793–1802（2016）。'
- en: '[187] H. Zhang, Y. Li, Y. Zhang, et al., “Spectral-spatial classification of
    hyperspectral imagery using a dual-channel convolutional neural network,” Remote
    Sensing Letters 8(5), 438–447 (2017).'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[187] H. Zhang, Y. Li, Y. Zhang, 等， “使用双通道卷积神经网络的高光谱图像光谱空间分类，” 遥感快报 8(5)，438–447（2017）。'
- en: '[188] W. Zhao and S. Du, “Learning multiscale and deep representations for
    classifying remotely sensed imagery,” ISPRS Journal of Photogrammetry and Remote
    Sensing 113(March), 155–165 (2016).'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[188] W. Zhao 和 S. Du， “学习多尺度和深层表示以分类遥感图像，” ISPRS摄影测量与遥感期刊 113（3月），155–165（2016）。'
- en: '[189] Y. Zhong, F. Fei, and L. Zhang, “Large patch convolutional neural networks
    for the scene classification of high spatial resolution imagery,” Journal of Applied
    Remote Sensing 10(2), 25006 (2016).'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[189] Y. Zhong, F. Fei, 和 L. Zhang， “用于高空间分辨率图像场景分类的大块卷积神经网络，” 应用遥感期刊 10(2)，25006（2016）。'
- en: '[190] Y. Zhong, F. Fei, Y. Liu, et al., “SatCNN: satellite image dataset classification
    using agile convolutional neural networks,” Remote Sensing Letters 8(2), 136–145
    (2017).'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[190] Y. Zhong, F. Fei, Y. Liu, 等， “SatCNN：使用灵活卷积神经网络的卫星图像数据集分类，” 遥感快报 8(2)，136–145（2017）。'
- en: '[191] Y. Chen, C. Li, P. Ghamisi, et al., “Deep Fusion Of Hyperspectral And
    Lidar Data For Thematic Classification,” in 2016 IEEE Geoscience and Remote Sensing
    Symposium (IGARSS), 3591–3594 (2016).'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[191] Y. Chen, C. Li, P. Ghamisi, 等， “高光谱和Lidar数据深度融合用于主题分类，” 见于2016年IEEE地球科学与遥感研讨会（IGARSS），3591–3594（2016）。'
- en: '[192] L. Ran, Y. Zhang, W. Wei, et al., “Bands Sensitive Convolutional Network
    for Hyperspectral Image Classification,” in Proceedings of the International Conference
    on Internet Multimedia Computing and Service, 268–272, ACM (2016).'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[192] L. Ran, Y. Zhang, W. Wei, 等， “用于高光谱图像分类的波段敏感卷积网络，” 见于国际互联网多媒体计算与服务会议论文集，268–272，ACM（2016）。'
- en: '[193] J. Zabalza, J. Ren, J. Zheng, et al., “Novel segmented stacked autoencoder
    for effective dimensionality reduction and feature extraction in hyperspectral
    imaging,” Neurocomputing 185, 1–10 (2016).'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[193] J. Zabalza, J. Ren, J. Zheng, 等， “用于高光谱成像的有效降维和特征提取的新型分段堆叠自编码器，” 神经计算
    185，1–10（2016）。'
- en: '[194] Y. Liu and L. Wu, “Geological Disaster Recognition on Optical Remote
    Sensing Images Using Deep Learning,” Procedia Computer Science 91, 566–575 (2016).'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[194] Y. Liu 和 L. Wu， “使用深度学习的光学遥感图像地质灾害识别，” 计算机科学程序 91，566–575（2016）。'
- en: '[195] J. Chen, Q. Jin, and J. Chao, “Design of deep belief networks for short-term
    prediction of drought index using data in the Huaihe river basin,” Mathematical
    Problems in Engineering 2012 (2012).'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[195] J. Chen, Q. Jin, 和 J. Chao， “基于淮河流域数据的短期干旱指数预测深度信念网络设计，” 工程中的数学问题 2012（2012）。'
- en: '[196] P. Landschützer, N. Gruber, D. C. E. Bakker, et al., “A neural network-based
    estimate of the seasonal to inter-annual variability of the Atlantic Ocean carbon
    sink,” Biogeosciences 10(11), 7793–7815 (2013).'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[196] P. Landschützer, N. Gruber, D. C. E. Bakker, 等， “基于神经网络的北大西洋碳汇季节性至年际变率估计，”
    生物地球化学 10(11)，7793–7815（2013）。'
- en: '[197] M. Shi, F. Xie, Y. Zi, et al., “Cloud detection of remote sensing images
    by deep learning,” in 2016 IEEE Geoscience and Remote Sensing Symposium (IGARSS),
    701–704, IEEE (2016).'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[197] M. Shi, F. Xie, Y. Zi, 等， “深度学习的遥感图像云检测，” 见于2016年IEEE地球科学与遥感研讨会（IGARSS），701–704，IEEE（2016）。'
- en: '[198] X. Shi, Z. Chen, H. Wang, et al., “Convolutional LSTM network: A machine
    learning approach for precipitation nowcasting,” Advances in Neural Information
    Processing Systems 28 , 802–810 (2015).'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[198] X. Shi, Z. Chen, H. Wang, 等， “卷积LSTM网络：一种用于降水即时预报的机器学习方法，” 神经信息处理系统进展
    28，802–810（2015）。'
- en: '[199] S. Lee, H. Zhang, and D. J. Crandall, “Predicting Geo-informative Attributes
    in Large-scale Image Collections using Convolutional Neural Networks,” in 2015
    IEEE Winter Conference on Applications of Computer Vision (WACV), 550–557 (2015).'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[199] S. Lee, H. Zhang, 和 D. J. Crandall， “使用卷积神经网络预测大规模图像集合中的地理信息属性，” 见于2015年IEEE计算机视觉应用冬季会议（WACV），550–557（2015）。'
- en: '[200] W. Kehl, F. Milletari, F. Tombari, et al., “Deep Learning of Local RGB-D
    Patches for 3D Object Detection and 6D Pose Estimation,” in European Conference
    on Computer Vision, 205–220 (2016).'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[200] W. Kehl, F. Milletari, F. Tombari, 等， “用于3D物体检测和6D姿态估计的局部RGB-D补丁深度学习，”
    见于欧洲计算机视觉大会，205–220（2016）。'
- en: '[201] Y. Kim and T. Moon, “Human Detection and Activity Classification Based
    on Micro-Doppler Signatures Using Deep Convolutional Neural Networks,” IEEE Geoscience
    and Remote Sensing Letters 13(1), 1–5 (2015).'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[201] Y. Kim 和 T. Moon，“基于微多普勒特征的行人检测与活动分类，使用深度卷积神经网络，”IEEE 地球科学与遥感快报 13(1)，1–5
    (2015)。'
- en: '[202] W. Ouyang and X. Wang, “A discriminative deep model for pedestrian detection
    with occlusion handling,” in 2012 IEEE Conf. on Computer Vision and Pattern Recog.
    (CVPR), 3258–3265, IEEE (2012).'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[202] W. Ouyang 和 X. Wang，“一种处理遮挡的行人检测的判别性深度模型，”在 2012 IEEE 计算机视觉与模式识别会议 (CVPR)，3258–3265，IEEE
    (2012)。'
- en: '[203] D. Tomè, F. Monti, L. Baroffio, et al., “Deep convolutional neural networks
    for pedestrian detection,” Signal Processing: Image Communication 47, 482–489
    (2016).'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[203] D. Tomè, F. Monti, L. Baroffio 等人，“用于行人检测的深度卷积神经网络，”信号处理：图像通信 47，482–489
    (2016)。'
- en: '[204] Y. Wei, Q. Yuan, H. Shen, et al., “A Universal Remote Sensing Image Quality
    Improvement Method with Deep Learning,” in 2016 IEEE Geoscience and Remote Sensing
    Symposium (IGARSS), 6950–6953 (2016).'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[204] Y. Wei, Q. Yuan, H. Shen 等人，“基于深度学习的通用遥感图像质量改进方法，”在 2016 IEEE 地球科学与遥感研讨会
    (IGARSS)，6950–6953 (2016)。'
- en: '[205] H. Zhang, P. Casaseca-de-la Higuera, C. Luo, et al., “Systematic infrared
    image quality improvement using deep learning based techniques,” in SPIE Remote
    Sensing, 100080P–100080P, International Society for Optics and Photonics (2016).'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[205] H. Zhang, P. Casaseca-de-la Higuera, C. Luo 等人，“使用基于深度学习的技术系统性改进红外图像质量，”在
    SPIE 遥感，100080P–100080P，国际光学与光子学学会 (2016)。'
- en: '[206] D. Quan, S. Wang, M. Ning, et al., “Using Deep Neural Networks for Synthetic
    Aperture Radar Image Registration,” in 2016 IEEE Geoscience and Remote Sensing
    Symposium (IGARSS), 2799–2802 (2016).'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[206] D. Quan, S. Wang, M. Ning 等人，“使用深度神经网络进行合成孔径雷达图像配准，”在 2016 IEEE 地球科学与遥感研讨会
    (IGARSS)，2799–2802 (2016)。'
- en: '[207] P. Ghamisi, Y. Chen, and X. X. Zhu, “A Self-Improving Convolution Neural
    Network for the Classification of Hyperspectral Data,” IEEE Geoscience and Remote
    Sensing Letters 13(10), 1–5 (2016).'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[207] P. Ghamisi, Y. Chen 和 X. X. Zhu，“自我改进的卷积神经网络用于高光谱数据分类，”IEEE 地球科学与遥感快报
    13(10)，1–5 (2016)。'
- en: '[208] N. Kussul, A. Shelestov, M. Lavreniuk, et al., “Deep learning approach
    for large scale land cover mapping based on remote sensing data fusion,” in 2016
    IEEE Geoscience and Remote Sensing Symposium (IGARSS), 198–201, IEEE (2016).'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[208] N. Kussul, A. Shelestov, M. Lavreniuk 等人，“基于遥感数据融合的大规模土地覆盖映射深度学习方法，”在
    2016 IEEE 地球科学与遥感研讨会 (IGARSS)，198–201，IEEE (2016)。'
- en: '[209] W. Li, H. Fu, L. Yu, et al., “Stacked Autoencoder-based deep learning
    for remote-sensing image classification: a case study of African land-cover mapping,”
    International Journal of Remote Sensing 37(23), 5632–5646 (2016).'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[209] W. Li, H. Fu, L. Yu 等人，“基于堆叠自编码器的深度学习用于遥感图像分类：以非洲土地覆盖映射为案例研究，”国际遥感杂志
    37(23)，5632–5646 (2016)。'
- en: '[210] H. Liu, Q. Min, C. Sun, et al., “Terrain Classification With Polarimetric
    Sar Based on Deep Sparse Filtering Network,” in 2016 IEEE Geoscience and Remote
    Sensing Symposium (IGARSS), 64–67 (2016).'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[210] H. Liu, Q. Min, C. Sun 等人，“基于深度稀疏滤波网络的极化 SAR 地形分类，”在 2016 IEEE 地球科学与遥感研讨会
    (IGARSS)，64–67 (2016)。'
- en: '[211] K. Makantasis, K. Karantzalos, A. Doulamis, et al., “Deep Supervised
    Learning for Hyperspectral Data Classification through Convolutional Neural Networks,”
    2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS) , 4959–4962
    (2015).'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[211] K. Makantasis, K. Karantzalos, A. Doulamis 等人，“通过卷积神经网络进行高光谱数据分类的深度监督学习，”2015
    IEEE 国际地球科学与遥感研讨会 (IGARSS)，4959–4962 (2015)。'
- en: '[212] M. Castelluccio, G. Poggi, C. Sansone, et al., “Land Use Classification
    in Remote Sensing Images by Convolutional Neural Networks,” arXiv preprint arXiv:1508.00092
    , 1–11 (2015).'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[212] M. Castelluccio, G. Poggi, C. Sansone 等人，“通过卷积神经网络在遥感图像中进行土地利用分类，”arXiv
    预印本 arXiv:1508.00092，1–11 (2015)。'
- en: '[213] G. Cheng, J. Han, L. Guo, et al., “Effective and Efficient Midlevel Visual
    Elements-Oriented Land-Use Classification using VHR Remote Sensing Images,” IEEE
    Transactions on Geoscience and Remote Sensing 53(8), 4238–4249 (2015).'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[213] G. Cheng, J. Han, L. Guo 等人，“使用 VHR 遥感图像的有效且高效的中级视觉元素导向土地利用分类，”IEEE 地球科学与遥感事务
    53(8)，4238–4249 (2015)。'
- en: '[214] F. P. S. Luus, B. P. Salmon, F. Van Den Bergh, et al., “Multiview Deep
    Learning for Land-Use Classification,” IEEE Geoscience and Remote Sensing Letters
    12(12), 2448–2452 (2015).'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[214] F. P. S. Luus, B. P. Salmon, F. Van Den Bergh 等人，“多视角深度学习用于土地利用分类，”IEEE
    地球科学与遥感快报 12(12)，2448–2452 (2015)。'
- en: '[215] Q. Lv, Y. Dou, X. Niu, et al., “Urban land use and land cover classification
    using remotely sensed SAR data through deep belief networks,” Journal of Sensors
    2015 (2015).'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[215] Q. Lv, Y. Dou, X. Niu, 等人，“使用遥感 SAR 数据通过深度信念网络进行城市土地利用和覆盖分类”，Journal
    of Sensors 2015 (2015).'
- en: '[216] X. Ma, H. Wang, and J. Wang, “Semisupervised classification for hyperspectral
    image based on multi-decision labeling and deep feature learning,” ISPRS Journal
    of Photogrammetry and Remote Sensing 120, 99–107 (2016).'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[216] X. Ma, H. Wang, 和 J. Wang，“基于多决策标签和深度特征学习的半监督高光谱图像分类”，ISPRS Journal of
    Photogrammetry and Remote Sensing 120, 99–107 (2016).'
- en: '[217] M. E. Midhun, S. R. Nair, V. T. N. Prabhakar, et al., “Deep Model for
    Classification of Hyperspectral image using Restricted Boltzmann Machine,” in
    Proceedings of the 2014 International Conference on Interdisciplinary Advances
    in Applied Computing - ICONIAAC ’14, 1–7 (2014).'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[217] M. E. Midhun, S. R. Nair, V. T. N. Prabhakar, 等人，“使用受限玻尔兹曼机的深度模型进行高光谱图像分类”，in
    Proceedings of the 2014 International Conference on Interdisciplinary Advances
    in Applied Computing - ICONIAAC ’14，1–7 (2014).'
- en: '[218] E. Othman, Y. Bazi, N. Alajlan, et al., “Using convolutional features
    and a sparse autoencoder for land-use scene classification,” International Journal
    of Remote Sensing 37(10), 1977–1995 (2016).'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[218] E. Othman, Y. Bazi, N. Alajlan, 等人，“使用卷积特征和稀疏自编码器进行土地利用场景分类”，International
    Journal of Remote Sensing 37(10), 1977–1995 (2016).'
- en: '[219] A. B. Penatti, K. Nogueira, and J. A. Santos, “Do Deep Features Generalize
    from Everyday Objects to Remote Sensing and Aerial Scenes Domains ?,” in Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 44–51
    (2015).'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[219] A. B. Penatti, K. Nogueira, 和 J. A. Santos，“深度特征从日常物体到遥感和航空场景领域的泛化能力？”，in
    Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
    Workshops，44–51 (2015).'
- en: '[220] A. Romero, C. Gatta, and G. Camps-Valls, “Unsupervised deep feature extraction
    for remote sensing image classification,” IEEE Transactions on Geoscience and
    Remote Sensing 54(3), 1349–1362 (2016).'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[220] A. Romero, C. Gatta, 和 G. Camps-Valls，“遥感图像分类的无监督深度特征提取”，IEEE Transactions
    on Geoscience and Remote Sensing 54(3), 1349–1362 (2016).'
- en: '[221] Y. Sun, J. Li, W. Wang, et al., “Active learning based autoencoder for
    hyperspectral imagery classification,” in 2016 IEEE Geoscience and Remote Sensing
    Symposium (IGARSS), 469–472 (2016).'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[221] Y. Sun, J. Li, W. Wang, 等人，“基于主动学习的高光谱图像分类自编码器”，in 2016 IEEE Geoscience
    and Remote Sensing Symposium (IGARSS)，469–472 (2016).'
- en: '[222] N. K. Uba, Land Use and Land Cover Classification Using Deep Learning
    Techniques. PhD thesis, Arizona State University (2016).'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[222] N. K. Uba，“使用深度学习技术的土地利用和覆盖分类”，博士论文，Arizona State University (2016).'
- en: '[223] L. Alexandre, “3D Object Recognition using Convolutional Neural Networks
    with Transfer Learning between Input Channels,” in 13th International Conference
    on Intelligent Autonomous Systems, 889–898, Springer International (2016).'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[223] L. Alexandre，“使用卷积神经网络进行 3D 物体识别，输入通道之间的迁移学习”，in 13th International Conference
    on Intelligent Autonomous Systems，889–898，Springer International (2016).'
- en: '[224] X. Chen, S. Xiang, C. L. Liu, et al., “Aircraft detection by deep belief
    nets,” in Proceedings - 2nd IAPR Asian Conference on Pattern Recognition, ACPR
    2013, 54–58 (2013).'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[224] X. Chen, S. Xiang, C. L. Liu, 等人，“飞机检测的深度信念网络”，in Proceedings - 2nd IAPR
    Asian Conference on Pattern Recognition, ACPR 2013，54–58 (2013).'
- en: '[225] X. Chen and Y. Zhu, “3D Object Proposals for Accurate Object Class Detection,”
    Advances in Neural Information Processing Systems , 424–432 (2015).'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[225] X. Chen 和 Y. Zhu, “准确的物体类别检测的 3D 物体提议,” Advances in Neural Information
    Processing Systems , 424–432 (2015).'
- en: '[226] G. Cheng, P. Zhou, and J. Han, “Learning Rotation-Invariant Convolutional
    Neural Networks for Object Detection in VHR Optical Remote Sensing Images,” IEEE
    Transactions on Geoscience and Remote Sensing 54(12), 7405–7415 (2016).'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[226] G. Cheng, P. Zhou, 和 J. Han，“学习旋转不变的高分辨率光学遥感图像中的物体检测的卷积神经网络”，IEEE Transactions
    on Geoscience and Remote Sensing 54(12), 7405–7415 (2016).'
- en: '[227] M. Dahmane, S. Foucher, M. Beaulieu, et al., “Object Detection in Pleiades
    Images using Deep Features,” in 2016 IEEE Geoscience and Remote Sensing Symposium
    (IGARSS), 1552–1555 (2016).'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[227] M. Dahmane, S. Foucher, M. Beaulieu, 等人，“使用深度特征在 Pleiades 图像中进行物体检测”，in
    2016 IEEE Geoscience and Remote Sensing Symposium (IGARSS)，1552–1555 (2016).'
- en: '[228] W. Diao, X. Sun, F. Dou, et al., “Object recognition in remote sensing
    images using sparse deep belief networks,” Remote Sensing Letters 6(10), 745–754
    (2015).'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[228] W. Diao, X. Sun, F. Dou, 等人，“使用稀疏深度信念网络在遥感图像中进行物体识别”，Remote Sensing Letters
    6(10), 745–754 (2015).'
- en: '[229] G. Georgakis, M. A. Reza, A. Mousavian, et al., “Multiview RGB-D Dataset
    for Object Instance Detection,” in 2016 IEEE Fourth International Conference on
    3D Vision (3DV), 426–434 (2016).'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[229] G. Georgakis, M. A. Reza, A. Mousavian 等人，“用于物体实例检测的多视角RGB-D数据集”，在2016年IEEE第四届国际3D视觉会议（3DV）上，426–434
    (2016)。'
- en: '[230] D. Maturana and S. Scherer, “3D Convolutional Neural Networks for Landing
    Zone Detection from LiDAR,” International Conference on Robotics and Automation
    (Figure 1), 3471–3478 (2015).'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[230] D. Maturana 和 S. Scherer，“用于着陆区检测的3D卷积神经网络来自LiDAR”，国际机器人与自动化会议（图1），3471–3478
    (2015)。'
- en: '[231] C. Wang and K. Siddiqi, “Differential geometry boosts convolutional neural
    networks for object detection,” in Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition Workshops, 51–58 (2016).'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[231] C. Wang 和 K. Siddiqi，“微分几何提升卷积神经网络的物体检测”，在IEEE计算机视觉与模式识别会议研讨会上，51–58
    (2016)。'
- en: '[232] Q. Wu, W. Diao, F. Dou, et al., “Shape-based object extraction in high-resolution
    remote-sensing images using deep Boltzmann machine,” International Journal of
    Remote Sensing 37(24), 6012–6022 (2016).'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[232] Q. Wu, W. Diao, F. Dou 等人，“基于形状的对象提取在高分辨率遥感图像中使用深度玻尔兹曼机”，《国际遥感杂志》37(24)，6012–6022
    (2016)。'
- en: '[233] B. Zhou, A. Khosla, A. Lapedriza, et al., “Object Detectors Emerge in
    Deep Scene CNNs.” http://hdl.handle.net/1721.1/96942 (2015).'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[233] B. Zhou, A. Khosla, A. Lapedriza 等人，“在深度场景CNN中出现的对象检测器。” http://hdl.handle.net/1721.1/96942
    (2015)。'
- en: '[234] P. Ondruska and I. Posner, “Deep Tracking: Seeing Beyond Seeing Using
    Recurrent Neural Networks,” in Proceedings of the 30th Conference on Artificial
    Intelligence (AAAI 2016), 3361–3367 (2016).'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[234] P. Ondruska 和 I. Posner，“深度跟踪：使用递归神经网络超越视觉的视角”，在第30届人工智能会议（AAAI 2016）上，3361–3367
    (2016)。'
- en: '[235] G. Masi, D. Cozzolino, L. Verdoliva, et al., “Pansharpening by Convolutional
    Neural Networks,” Remote Sensing 8(7), 594 (2016).'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[235] G. Masi, D. Cozzolino, L. Verdoliva 等人，“通过卷积神经网络进行全色锐化”，《遥感》8(7)，594
    (2016)。'
- en: '[236] W. Huang, L. Xiao, Z. Wei, et al., “A new pan-sharpening method with
    deep neural networks,” IEEE Geoscience and Remote Sensing Letters 12(5), 1037–1041
    (2015).'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[236] W. Huang, L. Xiao, Z. Wei 等人，“一种基于深度神经网络的新全色锐化方法”，IEEE《地球科学与遥感通讯》12(5)，1037–1041
    (2015)。'
- en: '[237] L. Palafox, A. Alvarez, and C. Hamilton, “Automated Detection of Impact
    Craters and Volcanic Rootless Cones in Mars Satellite Imagery Using Convolutional
    Neural Networks and Support Vector Machines,” in 46th Lunar and Planetary Science
    Conference, 1–2 (2015).'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[237] L. Palafox, A. Alvarez, 和 C. Hamilton，“使用卷积神经网络和支持向量机在火星卫星图像中自动检测撞击坑和火山无根锥”，在第46届月球与行星科学会议上，1–2
    (2015)。'
- en: '[238] M. M. Ghazi, B. Yanikoglu, and E. Aptoula, “Plant Identification Using
    Deep Neural Networks via Optimization of Transfer Learning Parameters,” Neurocomputing
    (2017).'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[238] M. M. Ghazi, B. Yanikoglu 和 E. Aptoula，“通过优化迁移学习参数的深度神经网络进行植物识别”，《神经计算》
    (2017)。'
- en: '[239] H. Guan, Y. Yu, Z. Ji, et al., “Deep learning-based tree classification
    using mobile LiDAR data,” Remote Sensing Letters 6(11), 864–873 (2015).'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[239] H. Guan, Y. Yu, Z. Ji 等人，“基于深度学习的树木分类使用移动LiDAR数据”，《遥感通讯》6(11)，864–873
    (2015)。'
- en: '[240] P. K. Goel, S. O. Prasher, R. M. Patel, et al., “Classification of hyperspectral
    data by decision trees and artificial neural networks to identify weed stress
    and nitrogen status of corn,” Computers and Electronics in Agriculture 39(2),
    67–93 (2003).'
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[240] P. K. Goel, S. O. Prasher, R. M. Patel 等人，“通过决策树和人工神经网络分类高光谱数据以识别玉米的杂草压力和氮状态”，《计算机与农业电子学》39(2)，67–93
    (2003)。'
- en: '[241] K. Kuwata and R. Shibasaki, “Estimating crop yields with deep learning
    and remotely sensed data,” in 2015 IEEE International Geoscience and Remote Sensing
    Symposium (IGARSS), 858–861 (2015).'
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[241] K. Kuwata 和 R. Shibasaki，“利用深度学习和遥感数据估算作物产量”，在2015年IEEE国际地球科学与遥感研讨会（IGARSS）上，858–861
    (2015)。'
- en: '[242] J. Rebetez, H. F. Satizábal, M. Mota, et al., “Augmenting a convolutional
    neural network with local histograms-A case study in crop classification from
    high-resolution UAV imagery,” in European Symposium on Artificial Neural Networks,
    Computational Intelligence and Machine Learning, 515–520 (2016).'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[242] J. Rebetez, H. F. Satizábal, M. Mota 等人，“通过局部直方图增强卷积神经网络——以高分辨率UAV图像中的作物分类为案例研究”，在欧洲人工神经网络、计算智能与机器学习研讨会上，515–520
    (2016)。'
- en: '[243] S. Sladojevic, M. Arsenovic, A. Anderla, et al., “Deep Neural Networks
    Based Recognition of Plant Diseases by Leaf Image Classification,” Computational
    Intelligence and Neuroscience 2016, 1–11 (2016).'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[243] S. Sladojevic, M. Arsenovic, A. Anderla 等人，“基于深度神经网络的植物病害识别通过叶片图像分类”，《计算智能与神经科学》2016，1–11
    (2016)。'
- en: '[244] D. Levi, N. Garnett, and E. Fetaya, “StixelNet: a deep convolutional
    network for obstacle detection and road segmentation,” in BMCV, (2015).'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[245] P. Li, Y. Zang, C. Wang, et al., “Road network extraction via deep learning
    and line integral convolution,” in Geoscience and Remote Sensing Symposium (IGARSS),
    2016 IEEE International, 1599–1602, IEEE (2016).'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[246] V. Mnih and G. Hinton, “Learning to Label Aerial Images from Noisy Data,”
    in Proceedings of the 29th International Conference on Machine Learning (ICML-12),
    567–574 (2012).'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[247] J. Wang, J. Song, M. Chen, et al., “Road network extraction: a neural-dynamic
    framework based on deep learning and a finite state machine,” International Journal
    of Remote Sensing 36(12), 3144–3169 (2015).'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[248] Y. Yu, J. Li, H. Guan, et al., “Automated Extraction of 3D Trees from
    Mobile LiDAR Point Clouds,” ISPRS - International Archives of the Photogrammetry,
    Remote Sensing and Spatial Information Sciences XL-5(June), 629–632 (2014).'
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[249] Y. Yu, H. Guan, and Z. Ji, “Automated Extraction of Urban Road Manhole
    Covers Using Mobile Laser Scanning Data,” IEEE Transactions on Intelligent Transportation
    Systems 16(4), 1–12 (2015).'
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[250] Z. Zhong, J. Li, W. Cui, et al., “Fully convolutional networks for building
    and road extraction: preliminary results,” in 2016 IEEE Geoscience and Remote
    Sensing Symposium (IGARSS), 1591–1594 (2016).'
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[251] R. Hadsell, P. Sermanet, J. Ben, et al., “Learning long-range vision
    for autonomous off-road driving,” Journal of Field Robotics 26(2), 120–144 (2009).'
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[252] L. Mou and X. X. Zhu, “Spatiotemporal scene interpretation of space videos
    via deep neural network and tracklet analysis,” in 2016 IEEE Geoscience and Remote
    Sensing Symposium (IGARSS), 1823–1826, IEEE (2016).'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[253] Y. Yuan, L. Mou, and X. Lu, “Scene Recognition by Manifold Regularized
    Deep Learning Architecture,” IEEE Transactions on Neural Networks and Learning
    Systems 26(10), 2222–2233 (2015).'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[254] C. Couprie, C. Farabet, L. Najman, et al., “Indoor Semantic Segmentation
    using depth information,” arXiv preprint arXiv:1301.3572 , 1–8 (2013).'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[255] Y. Gong, Y. Jia, T. Leung, et al., “Deep Convolutional Ranking for Multilabel
    Image Annotation,” arXiv preprint arXiv:1312.4894 , 1–9 (2013).'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[256] M. Kampffmeyer, A.-B. Salberg, and R. Jenssen, “Semantic segmentation
    of small objects and modeling of uncertainty in urban remote sensing images using
    deep convolutional neural networks,” in Proceedings of the IEEE Conference on
    Computer Vision and Pattern Recognition Workshops, 1–9 (2016).'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[257] P. Kaiser, “Learning City Structures from Online Maps,” Master’s thesis,
    ETH Zurich (2016).'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[258] A. Lagrange, B. L. Saux, A. Beaup, et al., “Benchmarking classification
    of earth-observation data: from learning explicit features to convolutional networks,”
    in 2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), 4173–4176
    (2015).'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[259] D. Marmanis, M. Datcu, T. Esch, et al., “Deep learning earth observation
    classification using ImageNet pretrained networks,” IEEE Geoscience and Remote
    Sensing Letters 13(1), 105–109 (2016).'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[260] D. Marmanis, J. D. Wegner, S. Galliani, et al., “Semantic Segmentation
    of Aerial Images with an Ensemble of CNNs,” in ISPRS Annals of the Photogrammetry,
    Remote Sensing and Spatial Information Sciences, 2016, 3, 473–480 (2016).'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[261] S. Paisitkriangkrai, J. Sherrah, P. Janney, et al., “Effective semantic
    pixel labelling with convolutional networks and Conditional Random Fields,” in
    IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops,
    2015-Oct, 36–43 (2015).'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[262] B. Qu, X. Li, D. Tao, et al., “Deep Semantic Understanding of High Resolution
    Remote Sensing Image,” in International Conference on Computer, Information and
    Telecommunication Systems (CITS), 1–5 (2016).'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[263] J. Sherrah, “Fully convolutional networks for dense semantic labelling
    of high-resolution aerial imagery,” arXiv preprint arXiv:1606.02585 (2016).'
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[264] C. Vaduva, I. Gavat, and M. Datcu, “Deep learning in very high resolution
    remote sensing image information mining communication concept,” in Signal Processing
    Conference (EUSIPCO), 2012 Proceedings of the 20th European, 2506–2510, IEEE (2012).'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[265] M. Volpi and D. Tuia, “Dense semantic labeling of sub-decimeter resolution
    images with convolutional neural networks,” IEEE Transactions on Geoscience and
    Remote Sensing , 1–13 (2016).'
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[266] D. Zhang, J. Han, C. Li, et al., “Co-saliency detection via looking deep
    and wide,” Proceedings of the IEEE Computer Society Conference on Computer Vision
    and Pattern Recognition 07-12-June, 2994–3002 (2015).'
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[267] F. I. Alam, J. Zhou, A. W.-C. Liew, et al., “CRF learning with CNN features
    for hyperspectral image segmentation,” in 2016 IEEE Geoscience and Remote Sensing
    Symposium (IGARSS), 6890–6893 (2016).'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[268] N. Audebert, B. L. Saux, and S. Lefèvre, “How Useful is Region-based
    Classification of Remote Sensing Images in a Deep Learning Framework?,” in 2016
    IEEE Geoscience and Remote Sensing Symposium (IGARSS), 5091–5094 (2016).'
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[269] E. Basaeed, H. Bhaskar, P. Hill, et al., “A supervised hierarchical segmentation
    of remote-sensing images using a committee of multi-scale convolutional neural
    networks,” International Journal of Remote Sensing 37(7), 1671–1691 (2016).'
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[270] E. Basaeed, H. Bhaskar, and M. Al-Mualla, “Supervised remote sensing
    image segmentation using boosted convolutional neural networks,” Knowledge-Based
    Systems 99, 19–27 (2016).'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[271] S. Pal, S. Chowdhury, and S. K. Ghosh, “DCAP: A deep convolution architecture
    for prediction of urban growth,” in Geoscience and Remote Sensing Symposium (IGARSS),
    2016 IEEE International, 1812–1815, IEEE (2016).'
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[272] J. Wang, Q. Qin, Z. Li, et al., “Deep hierarchical representation and
    segmentation of high resolution remote sensing images,” in 2015 IEEE International
    Geoscience and Remote Sensing Symposium (IGARSS), 4320–4323 (2015).'
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[273] C. P. Schwegmann, W. Kleynhans, B. P. Salmon, et al., “Very deep learning
    for ship discrimination in Synthetic Aperture Radar imagery,” in 2016 IEEE Geoscience
    and Remote Sensing Symposium (IGARSS), 104–107, IEEE (2016).'
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[274] J. Tang, C. Deng, G.-b. Huang, et al., “Compressed-Domain Ship Detection
    on Spaceborne Optical Image Using Deep Neural Network and Extreme Learning Machine,”
    IEEE Transactions on Geoscience and Remote Sensing 53(3), 1174–1185 (2015).'
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[275] R. Zhang, J. Yaoa, K. Zhanga, et al., “S-CNN-Based Ship Detection From
    High-Resolution Remote Sensing Images,” in The International Archives of the Photogrammetry,
    Remote Sensing and Spatial Information Sciences, Volume XLI-B7, 423–430 (2016).'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[276] Z. Cui, H. Chang, S. Shan, et al., “Deep network cascade for image super-resolution,”
    Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial
    Intelligence and Lecture Notes in Bioinformatics) 8693 LNCS(PART 5), 49–64 (2014).'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[277] C. Dong, C. C. Loy, K. He, et al., “Image super-resolution using deep
    convolutional networks,” IEEE transactions on pattern analysis and machine intelligence
    38(2), 295–307 (2016).'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[278] A. Ducournau and R. Fablet, “Deep Learning for Ocean Remote Sensing :
    An Application of Convolutional Neural Networks for Super-Resolution on Satellite-Derived
    SST Data,” in 9th Workshop on Pattern Recognition in Remote Sensing, (October)
    (2016).'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[279] L. Liebel and M. Körner, “Single-Image Super Resolution for Multispectral
    Remote Sensing Data Using Convolutional Neural Networks,” in XXIII ISPRS Congress
    proceedings, XXIII(July), 883–890 (2016).'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[280] W. Huang, G. Song, H. Hong, et al., “Deep architecture for traffic flow
    prediction: Deep belief networks with multitask learning,” IEEE Transactions on
    Intelligent Transportation Systems 15(5), 2191–2201 (2014).'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[281] Y. Lv, Y. Duan, W. Kang, et al., “Traffic Flow Prediction With Big Data:
    A Deep Learning Approach,” IEEE Transactions on Intelligent Transportation Systems
    16(2), 865–873 (2015).'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[282] M. Elawady, Sparse Coral Classification Using Deep Convolutional Neural
    Networks. PhD thesis, University of Burgundy, University of Girona, Heriot-Watt
    University (2014).'
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[283] H. Qin, X. Li, J. Liang, et al., “DeepFish: Accurate underwater live
    fish recognition with a deep architecture,” Neurocomputing 187, 49–58 (2016).'
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[284] H. Qin, X. Li, Z. Yang, et al., “When Underwater Imagery Analysis Meets
    Deep Learning : a Solution at the Age of Big Visual Data,” in 2011 7th International
    Symposium on Image and Signal Processing and Analysis (ISPA), 259–264 (2015).'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[285] D. P. Williams, “Underwater Target Classification in Synthetic Aperture
    Sonar Imagery Using Deep Convolutional Neural Networks,” in Proc. 23rd International
    Conference on Pattern Recognition (ICPR), (2016).'
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[286] F. Alidoost and H. Arefi, “Knowledge Based 3D Building Model Recognition
    Using Convolutional Neural Networks From Lidar and Aerial Imageries,” ISPRS-International
    Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences
    XLI-B3(July), 833–840 (2016).'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[287] C.-A. Brust, S. Sickert, M. Simon, et al., “Efficient Convolutional Patch
    Networks for Scene Understanding,” in CVPR Workshop, 1–9 (2015).'
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[288] S. De and A. Bhattacharya, “Urban classification using PolSAR data and
    deep learning,” in 2015 IEEE International Geoscience and Remote Sensing Symposium
    (IGARSS), 353–356, IEEE (2015).'
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[289] Z. Huang, G. Cheng, H. Wang, et al., “Building extraction from multi-source
    remote sensing images via deep deconvolution neural networks,” in Geoscience and
    Remote Sensing Symposium (IGARSS), 2016 IEEE International, 1835–1838, IEEE (2016).'
  id: totrans-686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[290] D. Marmanis, F. Adam, M. Datcu, et al., “Deep Neural Networks for Above-Ground
    Detection in Very High Spatial Resolution Digital Elevation Models,” ISPRS Annals
    of Photogrammetry, Remote Sensing and Spatial Information Sciences II-3/W4(March),
    103–110 (2015).'
  id: totrans-687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[291] S. Saito and Y. Aoki, “Building and road detection from large aerial
    imagery,” in SPIE/IS&T Electronic Imaging, 94050K–94050K, International Society
    for Optics and Photonics (2015).'
  id: totrans-688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[292] M. Vakalopoulou, K. Karantzalos, N. Komodakis, et al., “Building detection
    in very high resolution multispectral data with deep learning features,” 2015
    IEEE International Geoscience and Remote Sensing Symposium (IGARSS) , 1873–1876
    (2015).'
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[293] M. Xie, N. Jean, M. Burke, et al., “Transfer learning from deep features
    for remote sensing and poverty mapping,” arXiv preprint arXiv:1510.00098 , 16
    (2015).'
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[294] W. Yao, P. Poleswki, and P. Krzystek, “Classification of urban aerial
    data based on pixel labelling with deep convolutional neural networks and logistic
    regression,” International Archives of the Photogrammetry, Remote Sensing and
    Spatial Information Sciences - ISPRS Archives 41(July), 405–410 (2016).'
  id: totrans-691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[295] Q. Zhang, Y. Wang, Q. Liu, et al., “CNN based suburban building detection
    using monocular high resolution Google Earth images,” in Geoscience and Remote
    Sensing Symposium (IGARSS), 2016 IEEE International, 661–664, IEEE (2016).'
  id: totrans-692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[296] Z. Zhang, Y. Wang, Q. Liu, et al., “A CNN based functional zone classification
    method for aerial images,” in Geoscience and Remote Sensing Symposium (IGARSS),
    2016 IEEE International, 5449–5452, IEEE (2016).'
  id: totrans-693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[297] L. Cao, Q. Jiang, M. Cheng, et al., “Robust vehicle detection by combining
    deep features with exemplar classification,” Neurocomputing 215, 225–231 (2016).'
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[298] X. Chen, S. Xiang, C.-L. Liu, et al., “Vehicle detection in satellite
    images by hybrid deep convolutional neural networks,” IEEE Geoscience and remote
    sensing letters 11(10), 1797–1801 (2014).'
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[299] K. Goyal and D. Kaur, “A Novel Vehicle Classification Model for Urban
    Traffic Surveillance Using the Deep Neural Network Model,” International Journal
    of Education and Management Engineering 6(1), 18–31 (2016).'
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[300] A. Hu, H. Li, F. Zhang, et al., “Deep Boltzmann Machines based vehicle
    recognition,” in The 26th Chinese Control and Decision Conference (2014 CCDC),
    3033–3038 (2014).'
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[301] J. Huang and S. You, “Vehicle detection in urban point clouds with orthogonal-view
    convolutional neural network,” in 2016 IEEE International Conference on Image
    Processing (ICIP), (2), 2593–2597 (2016).'
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[302] B. Huval, T. Wang, S. Tandon, et al., “An Empirical Evaluation of Deep
    Learning on Highway Driving,” arXiv preprint arXiv:1504.01716 , 1–7 (2015).'
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[303] Q. Jiang, L. Cao, M. Cheng, et al., “Deep neural networks-based vehicle
    detection in satellite images,” in Bioelectronics and Bioinformatics (ISBB), 2015
    International Symposium on, 184–187, IEEE (2015).'
  id: totrans-700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[304] G. V. Konoplich, E. O. Putin, and A. A. Filchenkov, “Application of deep
    learning to the problem of vehicle detection in UAV images,” in Soft Computing
    and Measurements (SCM), 2016 XIX IEEE International Conference on, 4–6, IEEE (2016).'
  id: totrans-701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[305] A. Krishnan and J. Larsson, Vehicle Detection and Road Scene Segmentation
    using Deep Learning. PhD thesis, Chalmers University of Technology (2016).'
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[306] S. Lange, F. Ulbrich, and D. Goehring, “Online vehicle detection using
    deep neural networks and lidar based preselected image patches,” IEEE Intelligent
    Vehicles Symposium, Proceedings 2016-Augus(Iv), 954–959 (2016).'
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[307] B. Li, “3D Fully Convolutional Network for Vehicle Detection in Point
    Cloud,” arXiv preprint arXiv:1611.08069 (2016).'
  id: totrans-704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[308] H. Wang, Y. Cai, and L. Chen, “A vehicle detection algorithm based on
    deep belief network,” The scientific world journal 2014 (2014).'
  id: totrans-705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[309] J.-G. Wang, L. Zhou, Y. Pan, et al., “Appearance-based Brake-Lights recognition
    using deep learning and vehicle detection,” in Intelligent Vehicles Symposium
    (IV), 2016 IEEE, (Iv), 815–820, IEEE (2016).'
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[310] H. Wang, Y. Cai, X. Chen, et al., “Night-Time Vehicle Sensing in Far
    Infrared Image with Deep Learning,” Journal of Sensors 2016 (2015).'
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[311] R. J. Firth, A Novel Recurrent Convolutional Neural Network for Ocean
    and Weather Forecasting. PhD thesis, Louisiana State University (2016).'
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[312] R. Kovordányi and C. Roy, “Cyclone track forecasting based on satellite
    images using artificial neural networks,” ISPRS Journal of Photogrammetry and
    Remote Sensing 64(6), 513–521 (2009).'
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[313] C. Yang and J. Guo, “Improved cloud phase retrieval approaches for China’s
    FY-3A/VIRR multi-channel data using Artificial Neural Networks,” Optik-International
    Journal for Light and Electron Optics 127(4), 1797–1803 (2016).'
  id: totrans-710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[314] Y. Chen, X. Zhao, and X. Jia, “Spectral – Spatial Classification of Hyperspectral
    Data Based on Deep Belief Network,” IEEE Journal of Selected Topics in Applied
    Earth Observations and Remote Sensing 8(6), 2381–2392 (2015).'
  id: totrans-711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[314] Y. Chen, X. Zhao 和 X. Jia，“基于深度置信网络的高光谱数据光谱–空间分类，”《IEEE应用地球观测与遥感精选杂志》8(6)，2381–2392
    (2015)。'
- en: '[315] J. M. P. Nascimento and J. M. B. Dias, “Vertex component analysis: A
    fast algorithm to unmix hyperspectral data,” IEEE transactions on Geoscience and
    Remote Sensing 43(4), 898–910 (2005).'
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[315] J. M. P. Nascimento 和 J. M. B. Dias，“顶点分量分析：一种快速的高光谱数据解混算法，”《IEEE地球科学与遥感汇刊》43(4)，898–910
    (2005)。'
- en: '[316] T. H. Chan, K. Jia, S. Gao, et al., “PCANet: A Simple Deep Learning Baseline
    for Image Classification?,” IEEE Transactions on Image Processing 24(12), 5017–5032
    (2015).'
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[316] T. H. Chan, K. Jia, S. Gao 等，“PCANet：一种用于图像分类的简单深度学习基准？”，《IEEE图像处理汇刊》24(12)，5017–5032
    (2015)。'
- en: '[317] Y. Chen, H. Jiang, C. Li, et al., “Deep Feature Extraction and Classification
    of Hyperspectral Images Based on Convolutional Neural Networks,” IEEE Transactions
    on Geoscience and Remote Sensing 54(10), 6232–6251 (2016).'
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[317] Y. Chen, H. Jiang, C. Li 等，“基于卷积神经网络的高光谱图像深度特征提取与分类，”《IEEE地球科学与遥感汇刊》54(10)，6232–6251
    (2016)。'
- en: '[318] J. Donahue, Y. Jia, O. Vinyals, et al., “DeCAF: A Deep Convolutional
    Activation Feature for Generic Visual Recognition,” Icml 32, 647–655 (2014).'
  id: totrans-715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[318] J. Donahue, Y. Jia, O. Vinyals 等，“DeCAF：用于通用视觉识别的深度卷积激活特征，”《ICML 32》，647–655
    (2014)。'
- en: '[319] A. Zelener and I. Stamos, “CNN-based Object Segmentation in Urban LIDAR
    With Missing Points,” in 3D Vision (3DV), 2016 Fourth International Conference
    on, 417–425, IEEE (2016).'
  id: totrans-716
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[319] A. Zelener 和 I. Stamos，“基于CNN的城市LIDAR对象分割与缺失点，”发表于2016年第四届国际3D视觉会议（3DV），417–425，IEEE
    (2016)。'
- en: '[320] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks
    for semantic segmentation,” in Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition, 3431–3440 (2015).'
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[320] J. Long, E. Shelhamer 和 T. Darrell，“用于语义分割的全卷积网络，”发表于《IEEE计算机视觉与模式识别会议论文集》，3431–3440
    (2015)。'
- en: '[321] J. E. Ball, D. T. Anderson, and S. Samiappan, “Hyperspectral band selection
    based on the aggregation of proximity measures for automated target detection,”
    in SPIE Defense+ Security, 908814–908814, International Society for Optics and
    Photonics (2014).'
  id: totrans-718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[321] J. E. Ball, D. T. Anderson 和 S. Samiappan，“基于接近度测量汇聚的高光谱波段选择用于自动目标检测，”发表于SPIE国防+安全，908814–908814，国际光学与光子学学会
    (2014)。'
- en: '[322] J. E. Ball and L. M. Bruce, “Level Set Hyperspectral Image Classification
    Using Best Band Analysis,” IEEE Transactions on Geoscience and Remote Sensing
    45(10), 3022–3027 (2007). DOI:10.1109/TGRS.2007.905629.'
  id: totrans-719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[322] J. E. Ball 和 L. M. Bruce，“基于最佳波段分析的高光谱图像分类，”《IEEE地球科学与遥感汇刊》45(10)，3022–3027
    (2007)。 DOI:10.1109/TGRS.2007.905629。'
- en: '[323] J. E. Ball, L. M. Bruce, T. West, et al., “Level set hyperspectral image
    segmentation using spectral information divergence-based best band selection,”
    in Geoscience and Remote Sensing Symposium, 2007\. IGARSS 2007\. IEEE International,
    4053–4056, IEEE (2007). DOI:10.1109/IGARSS.2007.4423739.'
  id: totrans-720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[323] J. E. Ball, L. M. Bruce, T. West 等，“基于光谱信息散度的最佳波段选择的高光谱图像分割，”发表于地球科学与遥感研讨会，2007年IGARSS
    2007 IEEE国际会议，4053–4056，IEEE (2007)。 DOI:10.1109/IGARSS.2007.4423739。'
- en: '[324] D. T. Anderson and A. Zare, “Spectral unmixing cluster validity index
    for multiple sets of endmembers,” IEEE Journal of Selected Topics in Applied Earth
    Observations and Remote Sensing 5(4), 1282–1295 (2012).'
  id: totrans-721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[324] D. T. Anderson 和 A. Zare，“多组端成员的光谱解混集群有效性指数，”《IEEE应用地球观测与遥感精选杂志》5(4)，1282–1295
    (2012)。'
- en: '[325] M. E. Winter, “Comparison of approaches for determining end-members in
    hyperspectral data,” in Aerospace Conference Proceedings, 2000 IEEE, 3, 305–313,
    IEEE (2000).'
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[325] M. E. Winter，“高光谱数据中端成员确定方法的比较，”发表于《航空航天会议论文集》，2000 IEEE，第3卷，305–313，IEEE
    (2000)。'
- en: '[326] A. S. Charles, B. A. Olshausen, and C. J. Rozell, “Learning sparse codes
    for hyperspectral imagery,” IEEE Journal of Selected Topics in Signal Processing
    5(5), 963–978 (2011).'
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[326] A. S. Charles, B. A. Olshausen 和 C. J. Rozell，“为高光谱图像学习稀疏编码，”《IEEE信号处理精选杂志》5(5)，963–978
    (2011)。'
- en: '[327] A. Romero, C. Gatta, and G. Camps-Valls, “Unsupervised deep feature extraction
    of hyperspectral images,” in Proc. 6th Workshop Hyperspectral Image Signal Process.
    Evol. Remote Sens.(WHISPERS), (2014).'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[327] A. Romero, C. Gatta 和 G. Camps-Valls，“高光谱图像的无监督深度特征提取，”发表于第六届高光谱图像信号处理演变遥感研讨会（WHISPERS），(2014)。'
- en: '[328] J. E. Ball, L. M. Bruce, and N. H. Younan, “Hyperspectral pixel unmixing
    via spectral band selection and DC-insensitive singular value decomposition,”
    IEEE Geoscience and Remote Sensing Letters 4(3), 382–386 (2007).'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[329] P. M. Atkinson and A. Tatnall, “Introduction neural networks in remote
    sensing,” International Journal of remote sensing 18(4), 699–709 (1997). DOI:10.1080/014311697218700.'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[330] G. Cavallaro, M. Riedel, M. Richerzhagen, et al., “On understanding big
    data impacts in remotely sensed image classification using support vector machine
    methods,” IEEE journal of selected topics in applied earth observations and remote
    sensing 8(10), 4634–4646 (2015). DOI:10.1109/JSTARS.2015.2458855.'
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[331] M. Egmont-Petersen, D. DeRidder, and H. Handels, “Image Processing with
    neural networks - a review,” Pattern Recognition 35, 2279–2301 (2002). DOI:10.1016/S0031-3203(01)00178-9.'
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[332] G. Huang, G.-B. Huang, S. Song, et al., “Trends in extreme learning machines:
    A review,” Neural Networks 61, 32–48 (2015). DOI:10.1016/j.neunet.2014.10.001.'
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[333] X. Jia, B.-C. Kuo, and M. M. Crawford, “Feature mining for hyperspectral
    image classification,” Proceedings of the IEEE 101(3), 676–697 (2013). DOI:10.1109/JPROC.2012.2229082.'
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[334] D. Lu and Q. Weng, “A survey of image classification methods and techniques
    for improving classification performance,” International journal of Remote sensing
    28(5), 823–870 (2007). DOI:10.1080/01431160600746456.'
  id: totrans-731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[335] H. Petersson, D. Gustafsson, and D. Bergstrom, “Hyperspectral image analysis
    using deep learning–A review,” in Image Processing Theory Tools and Applications
    (IPTA), 2016 6th International Conference on, 1–6, IEEE (2016). DOI:10.1109/ipta.2016.7820963.'
  id: totrans-732
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[336] A. Plaza, J. A. Benediktsson, J. W. Boardman, et al., “Recent advances
    in techniques for hyperspectral image processing,” Remote sensing of environment
    113, S110–S122 (2009). DOI:10.1016/j.rse.2007.07.028.'
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[337] W. Wang, N. Yang, Y. Zhang, et al., “A review of road extraction from
    remote sensing images,” Journal of Traffic and Transportation Engineering (English
    Edition) 3(3), 271–282 (2016).'
  id: totrans-734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[338] “2013 IEEE GRSS Data Fusion Contest.” http://www.grss-ieee.org/community/technical-committees/data-fusion/.'
  id: totrans-735
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[339] “2015 IEEE GRSS Data Fusion Contest.” http://www.grss-ieee.org/community/technical-committees/data-fusion/.'
  id: totrans-736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[340] “2016 IEEE GRSS Data Fusion Contest.” http://www.grss-ieee.org/community/
    technical-committees/data-fusion/.'
  id: totrans-737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[341] “Indian Pines Dataset.” http://dynamo.ecn.purdue.edu/biehl/MultiSpec.'
  id: totrans-738
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[342] “Kennedy Space Center.” http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral'
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: _Remote_Sensing_Scenes#Kennedy_Space_Center_.28KSC.29.
  id: totrans-740
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[343] “Pavia Dataset.” http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral'
  id: totrans-741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: _Remote_Sensing_Scenes#Pavia_Centre_and_University.
  id: totrans-742
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[344] “Salinas Dataset.” http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral'
  id: totrans-743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: _Remote_Sensing_Scenes#Salinas.
  id: totrans-744
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[345] “Washington DC Mall.” https://engineering.purdue.edu/ biehl/MultiSpec/hyperspectral.html.'
  id: totrans-745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[346] G. Cheng and J. Han, “A survey on object detection in optical remote
    sensing images,” ISPRS Journal of Photogrammetry and Remote Sensing 117, 11–28
    (2016). DOI:10.1016/j.isprsjprs.2016.03.014.'
  id: totrans-746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[347] Y. Chen, Z. Lin, X. Zhao, et al., “Deep Learning-Based Classification
    of Hyperspectral Data,” Ieee Journal of Selected Topics in Applied Earth Observations
    and Remote Sensing 7(6), 2094–2107 (2014).'
  id: totrans-747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[348] V. Slavkovikj, S. Verstockt, W. De Neve, et al., “Hyperspectral image
    classification with convolutional neural networks,” in Proceedings of the 23rd
    ACM international conference on Multimedia, 1159–1162, ACM (2015).'
  id: totrans-748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[349] C. Tao, H. Pan, Y. Li, et al., “Unsupervised Spectral-Spatial Feature
    Learning With Stacked Sparse Autoencoder for Hyperspectral Imagery Classification,”
    IEEE Geoscience and Remote Sensing Letters 12(12), 2438–2442 (2015).'
  id: totrans-749
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[350] Y. LeCun, “Learning invariant feature hierarchies,” in Computer vision–ECCV
    2012\. Workshops and demonstrations, 496–505, Springer (2012).'
  id: totrans-750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[351] M. Pal, “Kernel methods in remote sensing: a review,” ISH Journal of
    Hydraulic Engineering 15(sup1), 194–215 (2009).'
  id: totrans-751
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[352] E. M. Abdel-Rahman and F. B. Ahmed, “The application of remote sensing
    techniques to sugarcane (Saccharum spp. hybrid) production: a review of the literature,”
    International Journal of Remote Sensing 29(13), 3753–3767 (2008).'
  id: totrans-752
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[353] I. Ali, F. Greifeneder, J. Stamenkovic, et al., “Review of machine learning
    approaches for biomass and soil moisture retrievals from remote sensing data,”
    Remote Sensing 7(12), 16398–16421 (2015).'
  id: totrans-753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[354] E. Adam, O. Mutanga, and D. Rugege, “Multispectral and hyperspectral
    remote sensing for identification and mapping of wetland vegetation: A review,”
    Wetlands Ecology and Management 18(3), 281–296 (2010).'
  id: totrans-754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[355] S. L. Ozesmi and M. E. Bauer, “Satellite remote sensing of wetlands,”
    Wetlands ecology and management 10(5), 381–402 (2002). DOI:10.1023/A:1020908432489.'
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[356] W. A. Dorigo, R. Zurita-Milla, A. J. W. de Wit, et al., “A review on
    reflective remote sensing and data assimilation techniques for enhanced agroecosystem
    modeling,” International journal of applied earth observation and geoinformation
    9(2), 165–193 (2007). DOI:10.1016/j.jag.2006.05.003.'
  id: totrans-756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[357] C. Kuenzer, M. Ottinger, M. Wegmann, et al., “Earth observation satellite
    sensors for biodiversity monitoring: potentials and bottlenecks,” International
    Journal of Remote Sensing 35(18), 6599–6647 (2014). DOI:10.1080/01431161.2014.964349.'
  id: totrans-757
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[358] K. Wang, S. E. Franklin, X. Guo, et al., “Remote sensing of ecology,
    biodiversity and conservation: a review from the perspective of remote sensing
    specialists,” Sensors 10(11), 9647–9667 (2010). DOI:10.3390/s101109647.'
  id: totrans-758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[359] F. E. Fassnacht, H. Latifi, K. Stereńczak, et al., “Review of studies
    on tree species classification from remotely sensed data,” Remote Sensing of Environment
    186, 64–87 (2016). DOI:10.1016/j.rse.2016.08.013.'
  id: totrans-759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[360] I. Ali, F. Greifeneder, J. Stamenkovic, et al., “Review of machine learning
    approaches for biomass and soil moisture retrievals from remote sensing data,”
    Remote Sensing 7(12), 16398–16421 (2015). DOI:10.3390/rs71215841.'
  id: totrans-760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[361] A. Mahendran and A. Vedaldi, “Understanding deep image representations
    by inverting them,” in Proceedings of the IEEE Conference on Computer Vision and
    Pattern Recognition, 5188–5196 (2015).'
  id: totrans-761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[362] J. Yosinski, J. Clune, A. Nguyen, et al., “Understanding neural networks
    through deep visualization,” arXiv preprint arXiv:1506.06579 (2015).'
  id: totrans-762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[363] K. Simonyan, A. Vedaldi, and A. Zisserman, “Deep inside convolutional
    networks: Visualising image classification models and saliency maps,” arXiv preprint
    arXiv:1312.6034 (2013).'
  id: totrans-763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[364] D. Erhan, Y. Bengio, A. Courville, et al., “Visualizing higher-layer
    features of a deep network,” University of Montreal 1341, 3 (2009).'
  id: totrans-764
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[365] J. A. Benediktsson, J. Chanussot, and W. W. Moon, “Very High-Resolution
    Remote Sensing : Challenges and Opportunities,” Proceedings of the IEEE 100(6),
    1907–1910 (2012). DOI:10.1109/JPROC.2012.2190811.'
  id: totrans-765
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[366] J. Fohringer, D. Dransch, H. Kreibich, et al., “Social media as an information
    source for rapid flood inundation mapping,” Natural Hazards and Earth System Sciences
    15(12), 2725–2738 (2015).'
  id: totrans-766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[367] V. Frias-Martinez and E. Frias-Martinez, “Spectral clustering for sensing
    urban land use using Twitter activity,” Engineering Applications of Artificial
    Intelligence 35, 237–245 (2014).'
  id: totrans-767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[368] T. Kohonen, “The self-organizing map,” Neurocomputing 21(1), 1–6 (1998).'
  id: totrans-768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[369] S. E. Middleton, L. Middleton, and S. Modafferi, “Real-time crisis mapping
    of natural disasters using social media,” IEEE Intelligent Systems 29(2), 9–17
    (2014).'
  id: totrans-769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[370] V. K. Singh, “Social Pixels : Genesis and Evaluation,” in Proceedings
    of the 18th ACM international conference on Multimedia (ACMM), 481–490 (2010).'
  id: totrans-770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[371] D. Sui and M. Goodchild, “The convergence of GIS and social media: challenges
    for GIScience,” International Journal of Geographical Information Science 25(11),
    1737–1748 (2011).'
  id: totrans-771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[372] A. J. Pinar, J. Rice, L. Hu, et al., “Efficient multiple kernel classification
    using feature and decision level fusion,” IEEE Transactions on Fuzzy Systems PP(99),
    1–1 (2016).'
  id: totrans-772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[373] D. T. Anderson, T. C. Havens, C. Wagner, et al., “Extension of the fuzzy
    integral for general fuzzy set-valued information,” IEEE Transactions on Fuzzy
    Systems 22, 1625–1639 (2014).'
  id: totrans-773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[374] P. Ghamisi, B. Höfle, and X. X. Zhu, “Hyperspectral and lidar data fusion
    using extinction profiles and deep convolutional neural network,” IEEE Journal
    of Selected Topics in Applied Earth Observations and Remote Sensing PP(99), 1–14
    (2016).'
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[375] J. Ngiam, A. Khosla, M. Kim, et al., “Multimodal deep learning,” in ICML,
    L. Getoor and T. Scheffer, Eds., 689–696, Omnipress (2011).'
  id: totrans-775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[376] Z. Kira, R. Hadsell, G. Salgian, et al., “Long-Range Pedestrian Detection
    using stereo and a cascade of convolutional network classifiers,” in IEEE International
    Conference on Intelligent Robots and Systems, 2396–2403 (2012).'
  id: totrans-776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[377] F. Rottensteiner, G. Sohn, J. Jung, et al., “The ISPRS benchmark on urban
    object classification and 3D building reconstruction,” ISPRS Ann. Photogramm.
    Remote Sens. Spat. Inf. Sci 1, 293–298 (2012).'
  id: totrans-777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[378] J. Ngiam, Z. Chen, S. A. Bhaskar, et al., “Sparse filtering,” in Advances
    in neural information processing systems, 1125–1133 (2011).'
  id: totrans-778
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[379] Y. Freund and R. E. Schapire, “A desicion-theoretic generalization of
    on-line learning and an application to boosting,” in European conference on computational
    learning theory, 23–37, Springer (1995).'
  id: totrans-779
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[380] Q. Zhao, M. Gong, H. Li, et al., “Three–Class Change Detection in Synthetic
    Aperture Radar Images Based on Deep Belief Network,” in Bio-Inspired Computing-Theories
    and Applications, 696–705, Springer (2015).'
  id: totrans-780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[381] A. P. Tewkesbury, A. J. Comber, N. J. Tate, et al., “A critical synthesis
    of remotely sensed optical image change detection techniques,” Remote Sensing
    of Environment 160, 1–14 (2015).'
  id: totrans-781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[382] C. Brekke and A. H. S. Solberg, “Oil spill detection by satellite remote
    sensing,” Remote sensing of environment 95(1), 1–13 (2005). [DOI:10.1016/j.rse.2004.11.015].'
  id: totrans-782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[383] H. Mayer, “Automatic object extraction from aerial imagery—a survey focusing
    on buildings,” Computer vision and image understanding 74(2), 138–149 (1999).
    DOI:10.1006/cviu.1999.0750.'
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[384] B. Somers, G. P. Asner, L. Tits, et al., “Endmember variability in spectral
    mixture analysis: A review,” Remote Sensing of Environment 115(7), 1603–1616 (2011).
    DOI:10.1016/j.rse.2011.03.003.'
  id: totrans-784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[385] D. Tuia, C. Persello, and L. Bruzzone, “Domain Adaptation for the Classification
    of Remote Sensing Data: An Overview of Recent Advances,” IEEE Geoscience and Remote
    Sensing Magazine 4(2), 41–57 (2016). DOI:10.1109/MGRS.2016.2548504.'
  id: totrans-785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[386] Y. Yang and S. Newsam, “Bag-of-visual-words and spatial extensions for
    land-use classification,” in Proceedings of the 18th SIGSPATIAL international
    conference on advances in geographic information systems, 270–279, ACM (2010).'
  id: totrans-786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[387] V. Risojević, S. Momić, and Z. Babić, “Gabor descriptors for aerial image
    classification,” in International Conference on Adaptive and Natural Computing
    Algorithms, 51–60, Springer (2011).'
  id: totrans-787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[388] K. Chatfield, K. Simonyan, A. Vedaldi, et al., “Return of the devil in
    the details: Delving deep into convolutional nets,” arXiv preprint arXiv:1405.3531
    (2014).'
  id: totrans-788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[389] G. Sheng, W. Yang, T. Xu, et al., “High-resolution satellite scene classification
    using a sparse coding based multiple feature combination,” International journal
    of remote sensing 33(8), 2395–2412 (2012).'
  id: totrans-789
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[390] S. H. Lee, C. S. Chan, S. J. Mayo, et al., “How deep learning extracts
    and learns leaf features for plant classification,” Pattern Recognition 71, 1
    – 13 (2017).'
  id: totrans-790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[391] A. Joly, H. Goëau, H. Glotin, et al., “LifeCLEF 2016: multimedia life
    species identification challenges,” in International Conference of the Cross-Language
    Evaluation Forum for European Languages, 286–310, Springer (2016).'
  id: totrans-791
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[392] S. H. Lee, C. S. Chan, P. Wilkin, et al., “Deep-plant: Plant identification
    with convolutional neural networks,” in 2015 IEEE International Conference on
    Image Processing (ICIP), 452–456 (2015).'
  id: totrans-792
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[393] Z. Ding, N. Nasrabadi, and Y. Fu, “Deep transfer learning for automatic
    target classification: MWIR to LWIR,” in SPIE Defense+ Security, 984408, International
    Society for Optics and Photonics (2016).'
  id: totrans-793
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[394] Y. Bengio, P. Simard, and P. Frasconi, “Learning long-term dependencies
    with gradient descent is difficult,” IEEE transactions on neural networks 5(2),
    157–166 (1994).'
  id: totrans-794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[395] X. Glorot and Y. Bengio, “Understanding the difficulty of training deep
    feedforward neural networks.,” in Aistats, 9, 249–256 (2010).'
  id: totrans-795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[396] R. K. Srivastava, K. Greff, and J. Schmidhuber, “Training very deep networks,”
    in Advances in neural information processing systems, 2377–2385 (2015).'
  id: totrans-796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[397] J. Sokolic, R. Giryes, G. Sapiro, et al., “Robust large margin deep neural
    networks,” arXiv preprint arXiv:1605.08254 (2016).'
  id: totrans-797
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[398] G. E. Hinton, S. Osindero, and Y.-W. Teh, “A fast learning algorithm
    for deep belief nets,” Neural computation 18(7), 1527–1554 (2006).'
  id: totrans-798
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[399] D. Erhan, A. Courville, and P. Vincent, “Why Does Unsupervised Pre-training
    Help Deep Learning ?,” Journal of Machine Learning Research 11, 625–660 (2010).
    DOI:10.1145/1756006.1756025.'
  id: totrans-799
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[400] K. He, X. Zhang, S. Ren, et al., “Delving deep into rectifiers: Surpassing
    human-level performance on imagenet classification,” in Proceedings of the IEEE
    International Conference on Computer Vision, 1026–1034 (2015).'
  id: totrans-800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[401] N. Srivastava, G. E. Hinton, A. Krizhevsky, et al., “Dropout: A Simple
    Way to Prevent Neural Networks from Overfitting,” Journal of Machine Learning
    Research (JMLR) 15(1), 1929–1958 (2014).'
  id: totrans-801
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[402] S. Ioffe and C. Szegedy, “Batch normalization: Accelerating deep network
    training by reducing internal covariate shift,” arXiv preprint arXiv:1502.03167
    (2015).'
  id: totrans-802
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[403] Q. V. Le, A. Coates, B. Prochnow, et al., “On Optimization Methods for
    Deep Learning,” in Proceedings of The 28th International Conference on Machine
    Learning (ICML), 265–272 (2011).'
  id: totrans-803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[404] S. Ruder, “An overview of gradient descent optimization algorithms,”
    arXiv preprint arXiv:1609.04747 (2016).'
  id: totrans-804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[405] J. Duchi, E. Hazan, and Y. Singer, “Adaptive subgradient methods for
    online learning and stochastic optimization,” Journal of Machine Learning Research
    12(Jul), 2121–2159 (2011).'
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[406] M. D. Zeiler, “Adadelta: an adaptive learning rate method,” arXiv preprint
    arXiv:1212.5701 (2012).'
  id: totrans-806
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[407] D. Kingma and J. Ba, “Adam: A method for stochastic optimization,” arXiv
    preprint arXiv:1412.6980 (2014).'
  id: totrans-807
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[408] T. Schaul, S. Zhang, and Y. LeCun, “No more pesky learning rates.,” ICML
    (3) 28, 343–351 (2013).'
  id: totrans-808
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[409] R. K. Srivastava, K. Greff, and J. Schmidhuber, “Highway networks,” arXiv
    preprint arXiv:1505.00387 (2015).'
  id: totrans-809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[410] K. He, X. Zhang, S. Ren, et al., “Deep residual learning for image recognition,”
    arXiv preprint arXiv:1512.03385 (2015).'
  id: totrans-810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[411] D. Balduzzi, B. McWilliams, and T. Butler-Yeoman, “Neural taylor approximations:
    Convergence and exploration in rectifier networks,” arXiv preprint arXiv:1611.02345
    (2016).'
  id: totrans-811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: John E. Ball is an Assistant professor of Electrical and Computer Engineering
    at Mississippi State University (MSU), USA. He received the Ph.D. degree in in
    Electrical Engineering from Mississippi State University in 2007, with a certificate
    in remote sensing. He is a co-director of the Sensor Analysis and Intelligence
    Laboratory (SAIL) at MSU and the director of the Simrall Radar Laboratory. He
    is the author of 45 journal and conference papers, and 22 technical tutorials,
    white papers, and technical reports, and has written one book chapter. He received
    best research paper of the year from the Veterinary and Comparative Orthopaedics
    and Traumatology in 2016 and technical paper of the year award from the Georgia
    Tech Research Institute in 2012\. His current research interests include deep
    learning, remote sensing, remote sensing, machine learning, digital signal and
    image processing, and radar systems. Dr. Ball is an associate editor for the SPIE
    Journal of Applied Remote Sensing.
  id: totrans-812
  prefs: []
  type: TYPE_NORMAL
- en: Derek T. Anderson received the Ph.D. in electrical and computer engineering
    (ECE) in 2010 from the University of Missouri, Columbia, MO, USA. He is currently
    an Associate Professor and the Robert D. Guyton Chair in ECE at Mississippi State
    University (MSU), USA, an Intermittent Faculty Member with the Naval Research
    Laboratory, co-director of the Sensor Analysis and Intelligence Laboratory (SAIL)
    at MSU and an Associate Editor for the IEEE Transactions on Fuzzy Systems. His
    research interests include new frontiers in data/information fusion for pattern
    recognition and automated decision making in signal/image understanding and computer
    vision with an emphasis on uncertainty and heterogeneity. Prof. Anderson’s primary
    research contributions to date include multi-source (sensor, algorithm and human)
    fusion, Choquet integrals (extensions, embeddings, learning), signal/image feature
    learning, multi-kernel learning, cluster validation, hyperspectral image understanding
    and linguistic summarization of video. He has published 100+ (journal, conference
    and book chapter) articles, he is the program co-chair of FUZZ-IEEE 2019, he co-authored
    the 2013 best student paper in Automatic Target Recognition at SPIE, he received
    the best overall paper award at the IEEE International Conference on Fuzzy Systems
    (FUZZ-IEEE) 2012, and he received the 2008 FUZZ-IEEE best student paper award.
  id: totrans-813
  prefs: []
  type: TYPE_NORMAL
- en: Chee Seng Chan received the Ph.D. degree from the University of Portsmouth,
    Hampshire, U.K., in 2008\. He is currently a Senior Lecturer with the Department
    of Artificial Intelligence, Faculty of Computer Science and Information Technology,
    University of Malaya, Kuala Lumpur, Malaysia. His current research interests include
    computer vision and fuzzy qualitative reasoning, with an emphasis on image and
    video understanding. Dr. Chan was a recipient of the Institution of Engineering
    and Technology (Malaysia) Young Engineer Award in 2010, the Hitachi Research Fellowship
    in 2013, and the Young Scientist Network-Academy of Sciences Malaysia in 2015\.
    He is the Founding Chair of the IEEE Computational Intelligence Society, Malaysia
    Chapter, and the Founder of Malaysian Image Analysis and Machine Intelligence
    Association. He is a Chartered Engineer of the Institution of Engineering and
    Technology, U.K.
  id: totrans-814
  prefs: []
  type: TYPE_NORMAL
- en: List of Figures
  id: totrans-815
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[1 Block diagrams of DL architectures. (a) AE. (b) CNN. (c) DBN. (d) RNN.](#S2.F1
    "Figure 1In 2.3 DL Approaches ‣ 2 Related work in CV ‣ A Comprehensive Survey
    of Deep Learning in Remote Sensing: Theories, Tools and Challenges for the Community")'
  id: totrans-816
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List of Tables
  id: totrans-817
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[1 Acronym list.](#S1.T1 "Table 1In A Comprehensive Survey of Deep Learning
    in Remote Sensing: Theories, Tools and Challenges for the Community")'
  id: totrans-818
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[2 Some popular DL tools.](#S2.T2 "Table 2In 2.4 DL Meets the Real World ‣
    2 Related work in CV ‣ A Comprehensive Survey of Deep Learning in Remote Sensing:
    Theories, Tools and Challenges for the Community")'
  id: totrans-819
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3 DL paper subject areas in remote sensing.](#S3.T3 "Table 3In A Comprehensive
    Survey of Deep Learning in Remote Sensing: Theories, Tools and Challenges for
    the Community")'
  id: totrans-820
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[4 Representative DL and FL Survey papers.](#S4.T4 "Table 4In A Comprehensive
    Survey of Deep Learning in Remote Sensing: Theories, Tools and Challenges for
    the Community")'
  id: totrans-821
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[5 HSI Dataset Usage.](#S4.T5 "Table 5In 4 Unsolved challenges and opportunities
    for DL in RS ‣ A Comprehensive Survey of Deep Learning in Remote Sensing: Theories,
    Tools and Challenges for the Community")'
  id: totrans-822
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[6 HSI Overall Accuracy Results in percent. IP = Indian Pines, KSC = Kennedy
    Space Center, PaCC = Pavia City Center, Pau = Pavia University, Sal = Salinas,
    DCM = Washington DC Mall. Results higher than 99% are in bold.](#S4.T6 "Table
    6In 4 Unsolved challenges and opportunities for DL in RS ‣ A Comprehensive Survey
    of Deep Learning in Remote Sensing: Theories, Tools and Challenges for the Community")'
  id: totrans-823
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
