- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 19:46:30'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:46:30
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2205.09904] Deep transfer learning for image classification: a survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2205.09904] 图像分类的深度迁移学习：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2205.09904](https://ar5iv.labs.arxiv.org/html/2205.09904)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2205.09904](https://ar5iv.labs.arxiv.org/html/2205.09904)
- en: \jyear
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \jyear
- en: '2021'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '2021'
- en: '[1]\fnmJo \surPlested'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]\fnm乔 \sur普莱斯特'
- en: '[1]\orgdivSchool of Engineering and Information Technology, \orgnameUniversity
    of New South Wales, \orgaddress\streetNorthcott Drive, \cityCampbell, \postcode2612,
    \stateACT, \countryAustralia'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]\orgdiv工程与信息技术学院，\orgname新南威尔士大学，\orgaddress\street诺斯科特大道，\city坎贝尔，\postcode2612，\stateACT，\country澳大利亚'
- en: 2]\orgdivOptus Centre for Artificial Intelligence, \orgnameCurtin University,
    \orgaddress\streetKent Street, \cityBentley, \postcode6102, \stateWA, \countryAustralia
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 2]\orgdiv人工智能中心，\orgname科廷大学，\orgaddress\street肯特街，\city本特利，\postcode6102，\stateWA，\country澳大利亚
- en: 'Deep transfer learning for image classification: a survey'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像分类的深度迁移学习：综述
- en: '[j.plested@unsw.edu.au](mailto:j.plested@unsw.edu.au)    \fnmTom \surGedeon
    [tom.gedeon@curtin.edu.au](mailto:tom.gedeon@curtin.edu.au) * ['
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[j.plested@unsw.edu.au](mailto:j.plested@unsw.edu.au)    \fnm汤姆 \sur盖迪恩 [tom.gedeon@curtin.edu.au](mailto:tom.gedeon@curtin.edu.au)
    *'
- en: Abstract
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep neural networks such as convolutional neural networks (CNNs) and transformers
    have achieved many successes in image classification in recent years. It has been
    consistently demonstrated that best practice for image classification is when
    large deep models can be trained on abundant labelled data. However there are
    many real world scenarios where the requirement for large amounts of training
    data to get the best performance cannot be met. In these scenarios transfer learning
    can help improve performance. To date there have been no surveys that comprehensively
    review deep transfer learning as it relates to image classification overall. However,
    several recent general surveys of deep transfer learning and ones that relate
    to particular specialised target image classification tasks have been published.
    We believe it is important for the future progress in the field that all current
    knowledge is collated and the overarching patterns analysed and discussed. In
    this survey we formally define deep transfer learning and the problem it attempts
    to solve in relation to image classification. We survey the current state of the
    field and identify where recent progress has been made. We show where the gaps
    in current knowledge are and make suggestions for how to progress the field to
    fill in these knowledge gaps. We present a new taxonomy of the applications of
    transfer learning for image classification. This taxonomy makes it easier to see
    overarching patterns of where transfer learning has been effective and, where
    it has failed to fulfill its potential. This also allows us to suggest where the
    problems lie and how it could be used more effectively. We demonstrate that under
    this new taxonomy, many of the applications where transfer learning has been shown
    to be ineffective or even hinder performance are to be expected when taking into
    account the source and target datasets and the techniques used. In many of these
    cases, the key problem is that methods and hyperparameter settings designed for
    large and very similar target datasets are used for smaller and much less similar
    target datasets. We identify alternative choices that could lead to better outcomes.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络，如卷积神经网络（CNNs）和变换器，近年来在图像分类领域取得了许多成功。**最佳实践**的表现是当大型深度模型能够在丰富的标注数据上进行训练时。然而，在许多现实世界的场景中，无法满足获得最佳性能所需的大量训练数据。在这些场景中，迁移学习可以帮助提高性能。迄今为止，还没有对深度迁移学习在图像分类中的整体情况进行全面综述的调查。然而，已经出版了一些关于深度迁移学习的最近综述，以及与特定专业化目标图像分类任务相关的综述。我们认为，为了未来该领域的发展，汇总所有当前知识并分析和讨论总体模式是重要的。在本调查中，我们正式定义了深度迁移学习及其在图像分类中试图解决的问题。我们调查了该领域的现状，并确定了最近取得的进展。我们展示了当前知识的空白之处，并提出了填补这些知识空白的建议。我们提出了一种新的迁移学习在图像分类中应用的分类法。这一分类法使我们更容易看到迁移学习有效和未能发挥其潜力的总体模式。这也让我们能够建议问题所在以及如何更有效地使用迁移学习。我们展示了在这一新分类法下，许多迁移学习被证明无效或甚至阻碍性能的应用是可以预期的，这些情况考虑了源数据集和目标数据集及使用的技术。在许多情况下，关键问题是针对大型且非常相似的目标数据集设计的方法和超参数设置被用于较小且相似度较低的目标数据集。我们确定了可能导致更好结果的替代选择。
- en: 'keywords:'
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Deep Transfer Learning, Image Classification, Convolutional Neural Networks,
    Deep Learning
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 深度迁移学习，图像分类，卷积神经网络，深度学习
- en: 1 Introduction
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: 'Deep neural network architectures such as convolutional neural networks (CNNs)
    and more recently transformers have achieved many successes in image classification
    [krizhevsky2012imagenet](#bib.bib58) ; [girshick2014rich](#bib.bib26) ; [li2020deep](#bib.bib62)
    ; [masi2018deep](#bib.bib73) ; [mazurowski2019deep](#bib.bib74) . It has been
    consistently demonstrated that these models perform best when there is abundant
    labelled data available for the task and large models can be trained [ngiam2018domain](#bib.bib87)
    ; [mahajan2018exploring](#bib.bib70) ; [kolesnikov2019big](#bib.bib50) . However
    there are many real world scenarios where the requirement for large amounts of
    training data cannot be met. Some of these are:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络架构，如卷积神经网络（CNNs）和最近的变压器，在图像分类中取得了许多成功 [krizhevsky2012imagenet](#bib.bib58)；
    [girshick2014rich](#bib.bib26)； [li2020deep](#bib.bib62)； [masi2018deep](#bib.bib73)；
    [mazurowski2019deep](#bib.bib74)。已一致证明，当任务有大量标记数据可用且可以训练大型模型时，这些模型表现最佳 [ngiam2018domain](#bib.bib87)；
    [mahajan2018exploring](#bib.bib70)； [kolesnikov2019big](#bib.bib50)。然而，许多现实世界场景中无法满足大量训练数据的要求。一些原因包括：
- en: '1.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Insufficient data because the data is very rare or there are issues with privacy
    etc. For example new and rare disease diagnosis tasks in the medical domain have
    limited training data due to both the examples themselves being rare and privacy
    concerns.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据不足因为数据非常稀少或存在隐私等问题。例如，医学领域中新型和稀有疾病的诊断任务由于样本稀少和隐私问题而有有限的训练数据。
- en: '2.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: It is prohibitively expensive to collect and/or label data. For example labelling
    can only be done by highly qualified experts in the field.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 收集和/或标注数据的成本非常高。例如，标注工作只能由领域内的高资质专家完成。
- en: '3.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: The long tail distribution where a small number of objects/words/classes are
    very frequent and thus easy to model, while many many more are rare and thus hard
    to model [bengio2015sharing](#bib.bib6) . For example most language generation
    problems.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 长尾分布中，少量对象/词汇/类别非常频繁，因此容易建模，而许多更多的对象则很稀有，因此难以建模 [bengio2015sharing](#bib.bib6)。例如，大多数语言生成问题。
- en: 'There are a several other reasons why we may want to learn from a small number
    of training examples:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能还希望从少量训练示例中学习的原因还有几个：
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: It is interesting from a cognitive science perspective to attempt to mimic the
    human ability to learn general concepts from a small number of examples.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从认知科学的角度来看，尝试模仿人类从少量示例中学习一般概念的能力是很有趣的。
- en: •
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: There may be restraints on compute resources that limit training a large model
    from random initialisation with large amounts of data. For example environmental
    concerns [strubell2019energy](#bib.bib124) .
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可能存在计算资源的限制，这限制了从随机初始化的大量数据中训练大型模型。例如，环境问题 [strubell2019energy](#bib.bib124)。
- en: In all these scenarios transfer learning can often greatly improve performance.
    In this paradigm the model is trained on a related dataset and task for which
    more data is available and the trained weights are used to initialise a model
    for the target task. In order for this process to improve rather than harm performance
    the dataset must related closely enough and best practice methods used.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些场景中，迁移学习通常可以大大提高性能。在这种范式中，模型在相关的数据集和任务上进行训练，利用更多的数据，训练后的权重被用于初始化目标任务的模型。为了使这个过程提高而不是损害性能，数据集必须足够相关，并且使用最佳实践方法。
- en: In this survey we review recent progress in deep transfer learning for image
    classification and highlight areas where knowledge is lacking and could be improved.
    With the exponentially increasing demand for the application of modern deep CNN
    models to a wider array of real world application areas, work in transfer learning
    has increased at a commensurable pace. It is important to regularly take stock
    and survey the current state of the field, where recent progress has been made
    and where the gaps in current knowledge are. We also make suggestions for how
    to progress the field to fill in these knowledge gaps. While there are many surveys
    in related domains and specific sub areas, to the best of our knowledge there
    are none that focus on deep transfer learning for image classification in general.
    We believe it is important for the future progress in the field that all the knowledge
    is collated together and the overarching patterns analysed and discussed.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次调查中，我们回顾了图像分类领域中深度迁移学习的最新进展，并指出了知识缺乏和可以改进的领域。随着现代深度CNN模型在更广泛的实际应用领域中的需求呈指数增长，迁移学习领域的工作也在以相应的速度增长。定期评估和调查当前领域的状态、近期进展和现有知识的空白至关重要。我们还提出了如何推进该领域以填补这些知识空白的建议。虽然在相关领域和具体子领域有很多调查，但据我们所知，没有针对图像分类中的深度迁移学习进行的综合性调查。我们认为，为了未来领域的进步，将所有知识汇总并分析和讨论总体模式是重要的。
- en: 'We make the following contributions:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们做出以下贡献：
- en: '1.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: formally defining deep transfer learning and the problem it attempts to solve
    as it relates to image classification
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正式定义深度迁移学习及其在图像分类中的问题
- en: '2.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: performing a thorough review of recent progress in the field
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对该领域近期进展进行彻底审查
- en: '3.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: presenting a taxonomy of source and target dataset relationships in transfer
    learning applications that helps highlight why transfer learning does not perform
    as expected in certain application areas
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提出迁移学习应用中源数据集和目标数据集关系的分类法，以突出为何迁移学习在某些应用领域表现不如预期
- en: '4.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: giving a detailed summary of source and target datasets commonly used in the
    area to provide an easy reference for the reader looking to understand relationships
    between where transfer learning has performed best and where results have been
    less consistent
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对该领域常用的源数据集和目标数据集进行详细总结，为希望了解迁移学习最佳表现与结果不一致之间关系的读者提供便捷的参考
- en: '5.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: summarizing current knowledge in the area as well as pointing out knowledge
    gaps and suggested directions for future research.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 总结该领域的当前知识，并指出知识空白以及未来研究的建议方向。
- en: 'In Section [2](#S2 "2 Related work ‣ Deep transfer learning for image classification:
    a survey") we review all surveys in the area from general transfer learning, to
    more closely related domains. In section [3](#S3 "3 Overview ‣ Deep transfer learning
    for image classification: a survey") we introduce the problem domain and formalise
    the difficulties with learning from small datasets that transfer learning attempts
    to solve. This section includes terminology and definitions that are used throughout
    this paper. Section [4](#S4 "4 Datasets commonly used in transfer learning for
    image classification ‣ Deep transfer learning for image classification: a survey")
    details the source and target datasets commonly used in deep learning for image
    classification. Section [5](#S5 "5 Deep transfer learning progress and areas for
    improvement ‣ Deep transfer learning for image classification: a survey") provides
    a detailed analysis of all recent advances and improvements to transfer learning
    and specific application areas and highlights gaps in current knowledge. In Section
    [6](#S6 "6 Areas related to deep transfer learning for image classification ‣
    Deep transfer learning for image classification: a survey") we give an overview
    of other problem domains that are closely related to deep transfer learning for
    image classification including the similarities and differences in each. Finally
    Section [7](#S7 "7 Discussion and suggestions for future directions ‣ Deep transfer
    learning for image classification: a survey") summarises all current knowledge,
    gaps and problems and recommends directions for future work in the area.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '在第[2节](#S2 "2 Related work ‣ Deep transfer learning for image classification:
    a survey")中，我们回顾了该领域所有的综述，从一般迁移学习到更为相关的领域。在第[3节](#S3 "3 Overview ‣ Deep transfer
    learning for image classification: a survey")中，我们介绍了问题领域，并形式化了迁移学习试图解决的小数据集学习中的困难。本节包括本文中使用的术语和定义。第[4节](#S4
    "4 Datasets commonly used in transfer learning for image classification ‣ Deep
    transfer learning for image classification: a survey")详细说明了在图像分类的深度学习中常用的源数据集和目标数据集。第[5节](#S5
    "5 Deep transfer learning progress and areas for improvement ‣ Deep transfer learning
    for image classification: a survey")提供了对迁移学习所有最新进展和改进的详细分析，并突出当前知识中的空白。在第[6节](#S6
    "6 Areas related to deep transfer learning for image classification ‣ Deep transfer
    learning for image classification: a survey")中，我们概述了与图像分类的深度迁移学习紧密相关的其他问题领域，包括每个领域的相似性和差异。最后，第[7节](#S7
    "7 Discussion and suggestions for future directions ‣ Deep transfer learning for
    image classification: a survey")总结了所有当前的知识、空白和问题，并推荐了未来工作的方向。'
- en: 2 Related work
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 'Many reviews related to deep transfer learning have been published in the past
    decade and the pace has only increased in the last few years. However, they differ
    from ours in two main ways. The first group consists of more general reviews,
    that provide a high level overview of transfer learning and attempt to include
    all machine learning sub-fields and all task sub-fields. Reviews in this group
    are covered in Section [2.1](#S2.SS1 "2.1 General transfer learning surveys ‣
    2 Related work ‣ Deep transfer learning for image classification: a survey").
    The second group is more specific with reviews providing a comprehensive breakdown
    of the progress on a particular narrow domain specific task. They are discussed
    in the relevant parts of Section [5.7](#S5.SS7 "5.7 Smaller target datasets with
    less similar tasks ‣ 5 Deep transfer learning progress and areas for improvement
    ‣ Deep transfer learning for image classification: a survey"). There are a few
    surveys that are more closely related to ours with differences discussed in Section
    [2.2](#S2.SS2 "2.2 Closely related work ‣ 2 Related work ‣ Deep transfer learning
    for image classification: a survey").'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '在过去十年中，许多关于深度迁移学习的综述已经发布，且在最近几年其数量增长更快。然而，它们与我们的综述有两个主要区别。第一类综述是更为一般性的，提供了迁移学习的高层次概述，并尝试涵盖所有机器学习子领域和所有任务子领域。这类综述在第[2.1节](#S2.SS1
    "2.1 General transfer learning surveys ‣ 2 Related work ‣ Deep transfer learning
    for image classification: a survey")中讨论。第二类综述则更为具体，提供了某一狭窄领域特定任务进展的全面分解。这些综述在第[5.7节](#S5.SS7
    "5.7 Smaller target datasets with less similar tasks ‣ 5 Deep transfer learning
    progress and areas for improvement ‣ Deep transfer learning for image classification:
    a survey")的相关部分讨论。还有一些与我们的综述更为相关的调查，它们的差异在第[2.2节](#S2.SS2 "2.2 Closely related
    work ‣ 2 Related work ‣ Deep transfer learning for image classification: a survey")中讨论。'
- en: 2.1 General transfer learning surveys
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 一般迁移学习综述
- en: 'The most recent general transfer learning survey [jiang2022transferability](#bib.bib46)
    , is an extremely broad overview of most areas related to deep transfer learning
    including those areas related to deep transfer learning for image classification
    outlined in Section [6](#S6 "6 Areas related to deep transfer learning for image
    classification ‣ Deep transfer learning for image classification: a survey").
    As it is a broad general survey there is no emphasis on how deep transfer learning
    applies to image classification and thus the trends seen in this area are not
    covered.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '最新的一般迁移学习综述 [jiang2022transferability](#bib.bib46) 是对深度迁移学习相关的大多数领域的极其广泛的概述，包括第
    [6](#S6 "6 Areas related to deep transfer learning for image classification ‣
    Deep transfer learning for image classification: a survey") 节中概述的深度迁移学习在图像分类中的应用。由于这是一个广泛的一般性综述，因此没有强调深度迁移学习如何应用于图像分类，因此没有涵盖这一领域的趋势。'
- en: A thorough theoretical analysis of general transfer learning techniques is given
    in [zhuang2020comprehensive](#bib.bib158) . Transfer learning techniques are split
    into data-based and model-based, then further divided into subcategories. Deep
    learning models are explicitly discussed as a sub-Section of model-based categorisation.
    The focus is on generative models such as auto-encoders and Generative Adversarial
    Networks (GANs) and several papers are reviewed. Neural networks are also mentioned
    briefly under the Parameter Control Strategy and Feature Transformation Strategy
    Sections. However, the focus is on unsupervised pretraining strategies, rather
    than best practice for transferring learning.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[zhuang2020comprehensive](#bib.bib158) 中给出了对一般迁移学习技术的深入理论分析。迁移学习技术被分为基于数据和基于模型的两大类，然后进一步细分为子类。深度学习模型作为模型分类的一个子部分被明确讨论。重点在于生成模型，如自编码器和生成对抗网络（GANs），并回顾了几篇相关论文。神经网络在参数控制策略和特征变换策略部分也有简要提及。然而，重点在于无监督预训练策略，而不是迁移学习的最佳实践。'
- en: Zhang et al. [zhang2019recent](#bib.bib153) take the most similar approach to
    categorizing the transfer learning task space as ours. They divide transfer learning
    into 17 categories based on source and target dataset and label attributes. They
    then review approaches taken within each category. Since it is a general transfer
    learning survey with no focus on deep learning and image classification the trends
    in this area are not covered.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 张等人 [zhang2019recent](#bib.bib153) 的方法与我们在分类迁移学习任务空间中的方法最为相似。他们根据源数据集和目标数据集及其标签属性将迁移学习分为17类。随后，他们回顾了每一类中的方法。由于这是一个一般性的迁移学习综述，没有专注于深度学习和图像分类，因此没有涵盖这一领域的趋势。
- en: Weiss et al. [weiss2016survey](#bib.bib141) divide general transfer learning
    into homogeneous, where the source and target dataset distributions are the same,
    and heterogeneous, where they are not, and give a thorough description of each.
    They review many different approaches in each category, but few of them are related
    to deep neural networks.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Weiss 等人 [weiss2016survey](#bib.bib141) 将一般迁移学习分为同质迁移（源数据集和目标数据集分布相同）和异质迁移（分布不同），并对每种情况进行了详细描述。他们回顾了每一类中的许多不同方法，但其中很少与深度神经网络相关。
- en: 2.2 Closely related work
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 紧密相关的工作
- en: There are some recent review papers that based on their title seem to be more
    closely related. However, they are short summary papers containing limited details
    on the subject matter rather than full review papers.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些最近的综述论文，从标题上看似乎与主题更为相关。然而，这些论文是简短的总结性论文，包含了有限的细节，而不是全面的综述论文。
- en: A Survey on Deep Transfer Learning [tan2018survey](#bib.bib127) defines deep
    transfer learning and separates it into four categories based on the subset of
    techniques used. The focus is more on showing a broad selection of methods rather
    than providing much detail or focusing particularly on deep transfer learning
    methods. Most major works in the area from the past decade are missing.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一项关于深度迁移学习的综述 [tan2018survey](#bib.bib127) 定义了深度迁移学习，并根据使用的技术子集将其分为四类。重点更多地放在展示广泛的技术选择上，而不是提供详细信息或特别关注深度迁移学习方法。过去十年间的大多数重要工作未被涵盖。
- en: Deep Learning and Transfer Learning Approaches for Image Classification [krishna2019deep](#bib.bib56)
    focuses on defining CNNs along with some of the major architectures and results
    from the past decade. The paper includes a few brief paragraphs defining transfer
    learning and some of the image classification results incorporate transfer learning,
    but no review of the topic is performed.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: “图像分类的深度学习和迁移学习方法” [krishna2019deep](#bib.bib56) 专注于定义CNN以及过去十年的一些主要架构和结果。论文包括一些简短的段落定义迁移学习，并且一些图像分类结果包含迁移学习，但没有对该主题进行综述。
- en: A Survey of Transfer Learning for Convolutional Neural Networks [ribani2019survey](#bib.bib106)
    is a short paper which briefly introduces the transfer learning task and settings,
    and introduces general categories of approaches and applications. It does not
    review any specific approaches or applications.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: “卷积神经网络的迁移学习综述” [ribani2019survey](#bib.bib106) 是一篇简短的论文，简要介绍了迁移学习任务和设置，并介绍了一般类别的方法和应用。它没有综述任何特定的方法或应用。
- en: 'Transfer Learning for Visual Categorization: A Survey [shao2014transfer](#bib.bib115)
    . Is a full review paper, but is older with no deep learning techniques included.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: “视觉分类的迁移学习：综述” [shao2014transfer](#bib.bib115) 是一篇完整的综述论文，但较旧，未包括深度学习技术。
- en: In Small Sample Learning in Big Data Era [shu2018small](#bib.bib119) deep transfer
    learning is a large part of the work, but not the focus. Some examples of deep
    learning applied to image classification domains are mentioned, but there is no
    discussion of methods for improving deep transfer learning as it relates to image
    classification.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在“大数据时代的小样本学习” [shu2018small](#bib.bib119) 中，深度迁移学习是大量工作的一个部分，但不是重点。虽然提到了应用于图像分类领域的深度学习示例，但没有讨论与图像分类相关的深度迁移学习方法的改进。
- en: 3 Overview
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 概述
- en: 3.1 Problem Definition
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 问题定义
- en: In this Section definitions used throughout the paper are introduced. Transfer
    learning can be categorised by both the task and the mode. We start by defining
    the model, then the task and finally how they interact together in this case.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，介绍了论文中使用的定义。迁移学习可以通过任务和模式进行分类。我们首先定义模型，然后定义任务，最后说明它们在这种情况下如何相互作用。
- en: 'Deep learning is a modern name for neural networks with more than one hidden
    layer. Neural networks are themselves a sub-area of machine learning. Mitchell
    [mitchell1997machine](#bib.bib79) provides a succinct definition of machine learning:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是神经网络的现代名称，神经网络具有多个隐藏层。神经网络本身是机器学习的一个子领域。Mitchell [mitchell1997machine](#bib.bib79)
    提供了机器学习的简明定义：
- en: Definition 1.
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 1。
- en: ”A computer program is said to learn from experience E with respect to some
    class of tasks T and performance measure P, if its performance at tasks in T,
    as measured by P, improves with experience E.”
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: “如果计算机程序在某类任务 T 和性能测量 P 上的表现随着经验 E 的增加而改善，则称该程序从经验 E 中学习。”
- en: 'Neural networks are defined by Gurney [gurney1997introduction](#bib.bib33)
    as:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络被Gurney [gurney1997introduction](#bib.bib33) 定义为：
- en: Definition 2.
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 2。
- en: ”A neural network is an interconnected assembly of simple processing elements,
    units or nodes, called neurons, whose functionality is loosely based on the animal
    neuron. The processing ability of the network is stored in the inter unit connection
    strengths, or weights, obtained by a process of adaptation to, or learning from,
    a set of training patterns.”
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: “神经网络是一个由简单处理单元、单元或节点（称为神经元）相互连接的集合，其功能大致基于动物神经元。网络的处理能力存储在单元间的连接强度或权重中，这些权重通过适应或从一组训练模式中学习获得。”
- en: The neurons in a multilayer feed forward neural network of the type that we
    consider in this review have nonlinear activation functions [goodfellow2016deep](#bib.bib29)
    and are arranged in layers with weights $W$ feeding forward from one layer to
    the next.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本综述中考虑的多层前馈神经网络中的神经元具有非线性激活函数 [goodfellow2016deep](#bib.bib29)，并且以层的形式排列，权重
    $W$ 从一层向下一层前馈。
- en: Generally, a neural network learns to improve its performance at task T from
    Experience E, being the set of training patterns, via gradient descent and backpropagation.
    Backpropagation is an application of the chain rule applied to propagate derivatives
    from final layers of the neural network to the hidden and input weights [rumelhart1986learning](#bib.bib110)
    . There are other less frequently used ways to train neural networks, such as
    with genetic algorithms, that have shown to be successful in particular applications.
    In this paper we assume training is done via backpropagation for generality.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，神经网络通过梯度下降和反向传播从经验 E（即训练模式集合）中学习以改善其在任务 T 上的性能。反向传播是链式法则的应用，用于将导数从神经网络的最终层传播到隐藏层和输入权重
    [rumelhart1986learning](#bib.bib110)。还有一些较少使用的训练神经网络的方法，例如遗传算法，它们在特定应用中已显示出成功。在本文中，我们假设训练是通过反向传播进行的，以确保通用性。
- en: While it has been proven that neural networks with one hidden layer are universal
    approximators [hornik1989multilayer](#bib.bib41) , in practice because the loss
    function is non-convex with respect to the weights it is difficult to optimise.
    For this reason modern networks are often arranged in very deep networks and task
    specific architectures, like CNNs and transformers for images, to allow for easier
    training of parameters.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管已证明具有一个隐藏层的神经网络是通用近似器 [hornik1989multilayer](#bib.bib41)，但实际上，由于损失函数相对于权重是非凸的，因此优化起来很困难。出于这个原因，现代网络通常被安排成非常深的网络和特定任务的架构，例如用于图像的卷积神经网络（CNNs）和变换器，以便于参数的训练。
- en: 'The hierarchical structure of these networks allows for ever more complex patterns
    to be learned. This is one of the things that has allowed deep learning to be
    successful at many different tasks in recent years, when compared to other machine
    learning algorithms. However, this only applies if there is enough data to train
    them. Figure [1](#S3.F1 "Figure 1 ‣ 3.1 Problem Definition ‣ 3 Overview ‣ Deep
    transfer learning for image classification: a survey") shows the increase in ImageNet
    1K performance with the number of model parameters. Figure [2](#S3.F2 "Figure
    2 ‣ 3.1 Problem Definition ‣ 3 Overview ‣ Deep transfer learning for image classification:
    a survey") shows that for large modern CNN models in general the performance on
    ImageNet 1K increases with the number of training examples in the source dataset.
    This suggests that large modern CNNS are likely overfitting when trained from
    random initialization on ImageNet 1K. Of course there are some outliers as the
    increase in performance from additional source data also depends on how related
    the source data is to the target data. This is discussed further in in Section
    [5.3.1](#S5.SS3.SSS1 "5.3.1 More versus better matched pretraining data ‣ 5.3
    Large closely related target datasets ‣ 5 Deep transfer learning progress and
    areas for improvement ‣ Deep transfer learning for image classification: a survey").
    These two results combine to show the stated effect that deep learning performance
    scales with the size of the dataset and model.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这些网络的层次结构使得可以学习越来越复杂的模式。这是近年来深度学习在许多不同任务中成功的原因之一，相较于其他机器学习算法。然而，这仅在有足够数据进行训练的情况下适用。图
    [1](#S3.F1 "图 1 ‣ 3.1 问题定义 ‣ 3 概述 ‣ 图像分类的深度迁移学习：综述") 显示了随着模型参数数量的增加，ImageNet 1K
    上性能的提升。图 [2](#S3.F2 "图 2 ‣ 3.1 问题定义 ‣ 3 概述 ‣ 图像分类的深度迁移学习：综述") 显示，对于大型现代 CNN 模型，通常在源数据集中的训练样本数量增加时，ImageNet
    1K 上的性能也会提升。这表明，当从随机初始化训练到 ImageNet 1K 时，大型现代 CNN 可能会过拟合。当然，也有一些异常值，因为额外源数据的性能提升还取决于源数据与目标数据的相关性。这个问题在
    [5.3.1](#S5.SS3.SSS1 "5.3.1 更多或更好匹配的预训练数据 ‣ 5.3 大量相关目标数据集 ‣ 5 深度迁移学习的进展与改进领域 ‣
    图像分类的深度迁移学习：综述") 节中有进一步讨论。这两个结果结合起来表明，深度学习的性能随着数据集和模型的大小而扩展。
- en: '![Refer to caption](img/fb78de1a7a6c085418bf57f109eb93e4.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/fb78de1a7a6c085418bf57f109eb93e4.png)'
- en: 'Figure 1: Increase in performance on ImageNet 1K due to model size, measured
    by number of parameters in millions'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：由于模型大小的增加，在 ImageNet 1K 上性能的提升，以百万个参数的数量来衡量
- en: '![Refer to caption](img/bd5516c4f3056721e53eecc94e704744.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/bd5516c4f3056721e53eecc94e704744.png)'
- en: 'Figure 2: Percentage increase in performance on ImageNet 1K due to increased
    source dataset size'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：由于源数据集大小增加，在 ImageNet 1K 上性能的百分比提升
- en: 'As noted in section [1](#S1 "1 Introduction ‣ Deep transfer learning for image
    classification: a survey") there are many real world scenarios where large amounts
    of data are unavailable or we are interested in training a model on a small amount
    of data for other reasons.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '如第 [1](#S1 "1 Introduction ‣ Deep transfer learning for image classification:
    a survey") 节所述，在许多现实场景中，大量数据不可用，或者我们由于其他原因希望在少量数据上训练模型。'
- en: 3.2 Learning from small vs large datasets
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 从小数据集与大数据集学习
- en: A thorough review of the problems of learning from a small number of training
    examples is given in [wang2020generalizing](#bib.bib139) .
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 对于从少量训练示例中学习的问题进行了详细回顾，见 [wang2020generalizing](#bib.bib139)。
- en: 3.2.1 Empirical Risk Minimization
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 经验风险最小化
- en: 'We are interested in finding a function $f$ that minimises the expected risk:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望找到一个最小化预期风险的函数 $f$：
- en: '|  | $R_{TRUE}\left(f\right)=E[\ell(f(x),y)]=\intop\ell(f(x),y)\,dp(x,y)$ |  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|  | $R_{TRUE}\left(f\right)=E[\ell(f(x),y)]=\intop\ell(f(x),y)\,dp(x,y)$ |  |'
- en: with
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '|  | $f^{*}=arg\,min_{f}R_{TRUE}\left(f\right)$ |  |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  | $f^{*}=arg\,min_{f}R_{TRUE}\left(f\right)$ |  |'
- en: $R_{TRUE}\left(f\right)$ is the true risk if we have access to an infinite set
    of all possible data and labels, with $\hat{f}$ being the function that minimizes
    the true risk. In practical applications however the joint probability distribution
    $P(x,y)=P(y|x)P(x)$ is unknown and the only available information is contained
    in the training set. For this reason the true risk is replaced by the empirical
    risk, which is the average of sample losses over the training set $D$
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: $R_{TRUE}\left(f\right)$ 是实际风险，如果我们能够访问所有可能的数据和标签的无限集合，那么 $\hat{f}$ 是最小化实际风险的函数。然而在实际应用中，联合概率分布
    $P(x,y)=P(y|x)P(x)$ 是未知的，唯一可用的信息包含在训练集里。因此，实际风险被经验风险所替代，经验风险是训练集 $D$ 上样本损失的平均值。
- en: '|  | $R_{n}\left(f\right)=\frac{1}{n}\sum_{i=1}^{n}\ell(f(x_{i}),y_{i}),$ |  |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '|  | $R_{n}\left(f\right)=\frac{1}{n}\sum_{i=1}^{n}\ell(f(x_{i}),y_{i}),$ |  |'
- en: leading to empirical risk minimisation [vapnik1992principles](#bib.bib132) .
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 导致经验风险最小化 [vapnik1992principles](#bib.bib132)。
- en: 'Before we begin training our model we must choose a family of candidate functions
    $\mathcal{F}$. In the case of CNNs this involves choosing the relevant hyperparameters
    that determine our model architecture, including number of layers, the number
    and shape of filters in each convolutional layer, whether and where to include
    features like residual connections and normalization layers, and many more. This
    constrains our final function to the family of candidate functions defined by
    the free parameters that make up the given architecture. We are then attempting
    to find a function in $\mathcal{F}$ which minimises the empirical risk:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练模型之前，我们必须选择一组候选函数 $\mathcal{F}$。在 CNN 的情况下，这涉及选择确定模型架构的相关超参数，包括层数、每个卷积层中的滤波器数量和形状、是否以及在哪里包含诸如残差连接和归一化层等特性，以及更多。这将我们的最终函数限制在由构成给定架构的自由参数定义的候选函数集
    $\mathcal{F}$ 中。我们尝试找到一个在 $\mathcal{F}$ 中最小化经验风险的函数：
- en: '|  | $f_{n}=arg\,min_{f}R_{n}\left(f\right)$ |  |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '|  | $f_{n}=arg\,min_{f}R_{n}\left(f\right)$ |  |'
- en: 'Since the optimal function $f^{*}$ is unlikely to be in $\mathcal{F}$ we also
    define:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 由于最优函数 $f^{*}$ 不太可能在 $\mathcal{F}$ 中，我们还定义：
- en: '|  | $f_{\mathcal{F}}^{*}=arg\,min_{f\epsilon\mathcal{F}}R_{TRUE}\left(f\right)$
    |  |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '|  | $f_{\mathcal{F}}^{*}=arg\,min_{f\epsilon\mathcal{F}}R_{TRUE}\left(f\right)$
    |  |'
- en: 'to be the function in $\mathcal{F}$ that minimises the true risk. We can then
    decompose the excess error that comes from choosing the function in $\mathcal{F}$
    that minimizes $R_{n}\left(f\right)$:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 成为最小化实际风险的函数 $\mathcal{F}$ 中的函数。然后我们可以分解从选择 $\mathcal{F}$ 中最小化 $R_{n}\left(f\right)$
    的函数所带来的额外误差：
- en: '|  | $\displaystyle E[R(f_{n})-R(f^{*})]$ | $\displaystyle=E[R(f_{\mathcal{F}}^{*})-R(f^{*})]$
    |  |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle E[R(f_{n})-R(f^{*})]$ | $\displaystyle=E[R(f_{\mathcal{F}}^{*})-R(f^{*})]$
    |  |'
- en: '|  |  | $\displaystyle+E[R(f_{n})-R(f_{\mathcal{F}}^{*})]$ |  |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle+E[R(f_{n})-R(f_{\mathcal{F}}^{*})]$ |  |'
- en: '|  |  | $\displaystyle=\varepsilon_{app}+\varepsilon_{est}$ |  |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\varepsilon_{app}+\varepsilon_{est}$ |  |'
- en: 'The approximation error $\varepsilon_{app}$ measures how closely functions
    in $\mathcal{F}$ can approximate the optimal solution $f^{*}$ . The estimation
    error $\varepsilon_{est}$ measures the effect of minimizing the empirical risk
    $R(f_{n})$ instead of the expected risk $R(f^{*})$ [bottou2008tradeoffs](#bib.bib9)
    . So finding a function that is as close as possible to $f^{*}$ can be broken
    down into:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 近似误差$\varepsilon_{app}$衡量了$\mathcal{F}$中的函数能多接近地逼近最优解$f^{*}$。估计误差$\varepsilon_{est}$衡量了最小化经验风险$R(f_{n})$而不是期望风险$R(f^{*})$的效果[bottou2008tradeoffs](#bib.bib9)。因此，找到尽可能接近$f^{*}$的函数可以分解为：
- en: '1.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: choosing a class of models that is more likely to contain the optimal function
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 选择一个更可能包含最优函数的模型类
- en: '2.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: having a large and broad range of training examples in $D$ to better approximate
    an infinite set of all possible data and labels.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在$D$中拥有大量且广泛的训练样本，以更好地逼近所有可能的数据和标签的无限集合。
- en: 3.2.2 Unreliable Empirical Risk Minimizer
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 不可靠的经验风险最小化器
- en: In general, $\varepsilon_{est}$ can be reduced by having a larger number of
    examples [wang2020generalizing](#bib.bib139) . Thus, when there are sufficient
    and varied labelled training examples in $D$, the empirical risk $R(f_{n})$ can
    provide a good approximation to $R(f_{\mathcal{F}}^{*})$ the optimal $f$ in $\mathcal{F}$.
    When $n$ the number of training examples in $D$ is small the empirical risk $R(f_{n})$
    may not be a good approximation of the expected risk $R(f_{\mathcal{F}}^{*})$.
    In this case the empirical risk minimizer overfits.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，$\varepsilon_{est}$可以通过拥有更多样本来减少[wang2020generalizing](#bib.bib139)。因此，当$D$中有足够且多样化的标记训练样本时，经验风险$R(f_{n})$可以对$\mathcal{F}$中的最优$f$即$R(f_{\mathcal{F}}^{*})$提供良好的近似。当$D$中训练样本的数量$n$很少时，经验风险$R(f_{n})$可能不是期望风险$R(f_{\mathcal{F}}^{*})$的良好近似。在这种情况下，经验风险最小化器会发生过拟合。
- en: To alleviate the problem of having an unreliable empirical risk minimizer when
    $D_{train}$ is not sufficient, prior knowledge can be used. Prior knowledge can
    be used to augment the data in $D_{train}$, constrain the candidate functions
    $\mathcal{F}$, or constrain the parameters of $f$ via initialization or regularization
    [wang2020generalizing](#bib.bib139) . Task specific deep neural network architectures
    such as CNNs and Recurrent Neural Networks (RNNs) are examples of constraining
    the candidate functions $\mathcal{F}$ through prior knowledge of what the optimal
    function form may be.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解当$D_{train}$不足时，使用不可靠的经验风险最小化器的问题，可以利用先验知识。先验知识可以用于增强$D_{train}$中的数据、限制候选函数$\mathcal{F}$，或者通过初始化或正则化来约束$f$的参数[wang2020generalizing](#bib.bib139)。如CNNs和递归神经网络（RNNs）等任务特定的深度神经网络架构就是通过对最优函数形式的先验知识来约束候选函数$\mathcal{F}$的例子。
- en: 'In this review we focus on transfer learning as a form of constraining the
    parameters of $f$ to address the unreliable empirical risk minimizer problem.
    Section [6](#S6 "6 Areas related to deep transfer learning for image classification
    ‣ Deep transfer learning for image classification: a survey") discusses how deep
    transfer learning relates to other techniques that use prior knowledge to solve
    the small dataset problem.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '在这篇综述中，我们重点关注迁移学习作为一种约束$f$参数的形式，以解决不可靠的经验风险最小化器问题。[6](#S6 "6 Areas related
    to deep transfer learning for image classification ‣ Deep transfer learning for
    image classification: a survey")节讨论了深度迁移学习如何与其他使用先验知识来解决小数据集问题的技术相关联。'
- en: 3.3 Deep transfer learning
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 深度迁移学习
- en: 'Deep transfer learning is transfer learning applied to deep neural networks.
    Pan and Yang [pan2009survey](#bib.bib91) define transfer learning as:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 深度迁移学习是应用于深度神经网络的迁移学习。Pan和Yang [pan2009survey](#bib.bib91)将迁移学习定义为：
- en: Definition 3.
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 3.
- en: ”Given a source domain $\mathcal{D\mathrm{{}_{S}}}$ and learning task $T_{S}$,
    a target domain $\mathcal{D\mathrm{{}_{T}}}$ and learning task $T_{T}$, transfer
    learning aims to help improve the learning of the target predictive function $f_{T}\left(.\right)$
    in $\mathcal{D\mathrm{{}_{T}}}$ using the knowledge in $\mathcal{D\mathrm{{}_{S}}}$
    and $T_{S}$, where $\mathcal{D\mathrm{{}_{S}}}$$\neq\mathcal{D\mathrm{{}_{T}}}$
    , or $T_{S}\neq T_{T}$.”
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: “给定源领域$\mathcal{D\mathrm{{}_{S}}}$和学习任务$T_{S}$，目标领域$\mathcal{D\mathrm{{}_{T}}}$和学习任务$T_{T}$，迁移学习旨在通过利用$\mathcal{D\mathrm{{}_{S}}}$和$T_{S}$中的知识来帮助提高在$\mathcal{D\mathrm{{}_{T}}}$中目标预测函数$f_{T}\left(.\right)$的学习，其中$\mathcal{D\mathrm{{}_{S}}}$$\neq\mathcal{D\mathrm{{}_{T}}}$，或$T_{S}\neq
    T_{T}$。”
- en: 'For the purposes of this paper we define deep transfer learning as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将深度迁移学习定义如下：
- en: Definition 4.
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 4.
- en: Given a source domain $\mathcal{D\mathrm{{}_{S}}}$ and learning task $T_{S}$,
    a target domain $\mathcal{D\mathrm{{}_{T}}}$ and learning task $T_{T}$ deep transfer
    learning aims to improve the performance of the target model $M$ on the target
    task $T_{T}$ by initialising it with weights $W$ that are trained on source task
    $T_{S}$ using source dataset $D_{S}$ (pretraining), where $\mathcal{D\mathrm{{}_{S}}}$$\neq\mathcal{D\mathrm{{}_{T}}}$
    , or $T_{S}\neq T_{T}$.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 给定源领域 $\mathcal{D\mathrm{{}_{S}}}$ 和学习任务 $T_{S}$，目标领域 $\mathcal{D\mathrm{{}_{T}}}$
    和学习任务 $T_{T}$，深度迁移学习旨在通过用在源任务 $T_{S}$ 上使用源数据集 $D_{S}$ 训练得到的权重 $W$ 来初始化目标模型 $M$，以提高其在目标任务
    $T_{T}$ 上的性能，其中 $\mathcal{D\mathrm{{}_{S}}}\neq\mathcal{D\mathrm{{}_{T}}}$，或 $T_{S}\neq
    T_{T}$。
- en: 'Some or all of $W$ are retained when the model is “transferred” to the target
    task $T_{T}$ and dataset $D_{T}$. The model is used for prediction on $T_{T}$
    after fully training any reinitialised weights and with or without continuing
    training on the pretrained weights (fine-tuning). Figure [3](#S3.F3 "Figure 3
    ‣ 3.3 Deep transfer learning ‣ 3 Overview ‣ Deep transfer learning for image classification:
    a survey") shows the pretraining and fine-tuning pipeline when applying transfer
    learning with a deep neural network.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型被“转移”到目标任务 $T_{T}$ 和数据集 $D_{T}$ 时，一些或所有的 $W$ 会被保留。在完全训练任何重新初始化的权重之后，模型用于在
    $T_{T}$ 上进行预测，并且可以选择继续在预训练的权重上进行训练（微调）。图[3](#S3.F3 "图 3 ‣ 3.3 深度迁移学习 ‣ 3 概述 ‣
    图像分类的深度迁移学习：综述")展示了应用深度神经网络进行迁移学习时的预训练和微调流程。
- en: '![Refer to caption](img/d671de83f4500f2cfdef1cb6e89e2ead.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d671de83f4500f2cfdef1cb6e89e2ead.png)'
- en: 'Figure 3: Deep transfer learning'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：深度迁移学习
- en: 'Combining the discussion from Section [3.2.2](#S3.SS2.SSS2 "3.2.2 Unreliable
    Empirical Risk Minimizer ‣ 3.2 Learning from small vs large datasets ‣ 3 Overview
    ‣ Deep transfer learning for image classification: a survey") with Definition
    [4](#Thmdefinition4 "Definition 4\. ‣ 3.3 Deep transfer learning ‣ 3 Overview
    ‣ Deep transfer learning for image classification: a survey"), using deep transfer
    learning techniques to pretrain weights W can be thought of as regularizing W
    . Initialising W with weights that have been well trained on a large source dataset
    rather than with very small random values results in a flatter loss surface and
    smaller gradients, which in turn results in more stable updates [neyshabur2020being](#bib.bib85)
    ; [liu2019towards](#bib.bib67) . In the classic transfer learning setting the
    source dataset is many orders of magnitude larger than the target dataset. One
    example is pretraining on ImageNet 1K with 1.3 million training images and transferring
    to medical imaging tasks which often only have 100s of labelled examples. So even
    with the same learning rate and number of epochs, the number of updates to the
    weights while training on the target dataset will be orders of magnitude less
    than for pretraining. This also prevents the model from creating large weights
    that are based on noise or idiosyncrasies in the small target dataset.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 将第[3.2.2节](#S3.SS2.SSS2 "3.2.2 不可靠的经验风险最小化器 ‣ 3.2 从小数据集与大数据集中学习 ‣ 3 概述 ‣ 图像分类的深度迁移学习：综述")的讨论与定义[4](#Thmdefinition4
    "定义 4 ‣ 3.3 深度迁移学习 ‣ 3 概述 ‣ 图像分类的深度迁移学习：综述")结合起来，使用深度迁移学习技术进行预训练权重W可以看作是对W的正则化。用在大源数据集上经过良好训练的权重来初始化W，而不是使用非常小的随机值，结果会得到一个更平坦的损失面和更小的梯度，这反过来会导致更稳定的更新[neyshabur2020being](#bib.bib85)；[liu2019towards](#bib.bib67)。在经典的迁移学习设置中，源数据集通常比目标数据集大几个数量级。一个例子是对包含130万训练图像的ImageNet
    1K进行预训练，然后转移到医学成像任务中，这些任务通常只有数百个标记样本。因此，即使在相同的学习率和训练轮数下，训练目标数据集时权重更新的次数也会比预训练时少几个数量级。这也防止了模型创建基于小目标数据集中噪声或特性的过大权重。
- en: 'Advances in transfer learning can be categorized based on ways of constraining
    the parameters of W as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习的进展可以根据对W参数进行约束的方式进行分类，具体如下：
- en: '1.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Initialization. Answering questions like:'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 初始化。回答如下问题：
- en: •
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: how much pretraining should be done?
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预训练应该进行多少？
- en: •
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: is more source data or more closely related source data better?
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更多的源数据还是更相关的源数据更好？
- en: •
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: which pretrained parameters should be transferred vs reinitialized?
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 哪些预训练参数应该被转移或重新初始化？
- en: '2.'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Parameter regularization. Regularizing weights, with the assumption that if
    the parameters are constrained to be close to a set point, they will be less likely
    to overfit.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参数正则化。正则化权重，假设如果将参数约束到接近某个设定点，它们就不太容易过拟合。
- en: '3.'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Feature regularization. Regularizing the features for each training example
    that are produced by the weights. Based on the assumption that if the features
    stay close to those trained by the large source data set the model will be less
    likely to overfit.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 特征正则化。对每个训练样本所产生的特征进行正则化，这些特征由权重产生。基于这样的假设，即如果特征与大型源数据集中的特征接近，则模型不容易过拟合。
- en: We describe progress and problems with deep transfer learning under these categories
    as well as based on the relationship between source and target dataset in section
    4\. Then, in section 5, we describe how deep transfer learning relates to other
    methods.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第4节中描述了基于这些类别以及源数据集与目标数据集之间关系的深度迁移学习的进展和问题。然后，在第5节中，我们描述了深度迁移学习如何与其他方法相关。
- en: 3.4 Negative Transfer
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 负迁移
- en: 'The stated goal of transfer learning as per Definition [3](#Thmdefinition3
    "Definition 3\. ‣ 3.3 Deep transfer learning ‣ 3 Overview ‣ Deep transfer learning
    for image classification: a survey") is to improve the learning of the target
    predictive function $f_{T}\left(.\right)$ in $\mathcal{D\mathrm{{}_{T}}}$ using
    the knowledge in $\mathcal{D\mathrm{{}_{S}}}$ and $T_{S}$. To achieve this goal
    the source dataset must be similar enough to the target dataset to ensure that
    the features learned in pretraining are relevant to the target task. If the source
    dataset is not well related to the target dataset the target model can be negatively
    impacted by pretraining. This is negative transfer [rosenstein2005transfer](#bib.bib108)
    ; [pan2009survey](#bib.bib91) . Wang et al. [wang2019characterizing](#bib.bib140)
    ; [wang2019transferable](#bib.bib138) define the negative transfer gap (NTG) as
    follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 根据定义 [3](#Thmdefinition3 "定义 3\. ‣ 3.3 深度迁移学习 ‣ 3 概述 ‣ 图像分类的深度迁移学习：综述")，迁移学习的既定目标是利用
    $\mathcal{D\mathrm{{}_{S}}}$ 和 $T_{S}$ 中的知识来改善 $\mathcal{D\mathrm{{}_{T}}}$ 中目标预测函数
    $f_{T}\left(.\right)$ 的学习。为了实现这一目标，源数据集必须足够类似于目标数据集，以确保在预训练中学习的特征与目标任务相关。如果源数据集与目标数据集关系不密切，预训练可能对目标模型产生负面影响。这就是负迁移
    [rosenstein2005transfer](#bib.bib108) ; [pan2009survey](#bib.bib91) 。Wang 等人 [wang2019characterizing](#bib.bib140)
    ; [wang2019transferable](#bib.bib138) 定义了负迁移间隙（NTG）如下：
- en: Definition 5.
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 5。
- en: '”Let $\epsilon_{\tau}$ represent the test error on the target domain, $\theta$
    a specific transfer learning algorithm under which the negative transfer gap is
    defined and $\varnothing$ is used to represent the case where the source domain
    data/information are not used by the target domain learner. Then, negative transfer
    happens when the error using the source data is larger than the error without
    using the source data: $\epsilon_{\tau}(\theta(S,\tau))>\epsilon_{\tau}(\theta(\varnothing,\tau))$,
    and the degree of negative transfer can be evaluated by the negative transfer
    gap”'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: “让 $\epsilon_{\tau}$ 代表目标领域的测试误差，$\theta$ 是特定的迁移学习算法，其负迁移间隙被定义，$\varnothing$
    用来表示源领域数据/信息未被目标领域学习者使用的情况。那么，当使用源数据的误差大于不使用源数据的误差时，就会发生负迁移：$\epsilon_{\tau}(\theta(S,\tau))>\epsilon_{\tau}(\theta(\varnothing,\tau))$，负迁移的程度可以通过负迁移间隙来评估。”
- en: '|  | $NTG=\epsilon_{\tau}(\theta(S,\tau))-\epsilon_{\tau}(\theta(\varnothing,\tau))$
    |  |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '|  | $NTG=\epsilon_{\tau}(\theta(S,\tau))-\epsilon_{\tau}(\theta(\varnothing,\tau))$
    |  |'
- en: 'From this definition we see that negative transfer occurs when the negative
    transfer gap is positive. Wang et al. elaborate on factors that affect negative
    transfer [wang2019characterizing](#bib.bib140) ; [wang2019transferable](#bib.bib138)
    :'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个定义中我们可以看到，当负迁移间隙为正时，负迁移发生。Wang 等人详细阐述了影响负迁移的因素 [wang2019characterizing](#bib.bib140)
    ; [wang2019transferable](#bib.bib138)：
- en: •
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Divergence between the source and target domains. Transfer learning makes the
    assumption that there is some similarity between joint distributions in source
    domain $P_{S}(X,Y)$ and target domain $P_{T}(X,Y)$. The higher the divergence
    between these values the less information there is in the source domain that can
    be exploited to to improve performance in the target domain. In the extreme case
    if there is no similarity it is not possible for transfer learning to improve
    performance.
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 源领域与目标领域之间的差异。迁移学习假设源领域 $P_{S}(X,Y)$ 和目标领域 $P_{T}(X,Y)$ 的联合分布之间存在某种相似性。这些值之间的差异越大，源领域中可以利用来提高目标领域性能的信息就越少。在极端情况下，如果没有相似性，迁移学习将无法改善性能。
- en: •
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Negative transfer is relative to the size and quality of the source and target
    datasets. For example, if labelled target data is abundant enough, a model trained
    on this data only may perform well. In this example, transfer learning methods
    are more likely to impair the target learning performance. Conversely, if there
    is no labelled target data, a bad transfer learning method would perform better
    than a random guess, which means negative transfer would not happen.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 负迁移相对与源数据集和目标数据集的规模及质量。例如，如果标记的目标数据足够丰富，仅在这些数据上训练的模型可能表现良好。在这种情况下，迁移学习方法更可能会削弱目标学习性能。相反，如果没有标记的目标数据，劣质的迁移学习方法会比随机猜测表现更好，这意味着负迁移不会发生。
- en: With deep neural networks, once the weights have been pretrained to respond
    to particular features in a large source dataset the weights will not change far
    from their pretrained values during fine-tuning [neyshabur2020being](#bib.bib85)
    . This is particularly so if the target dataset is orders of magnitude smaller
    as is often the case. This premise allows transfer learning to improve performance
    and also allows for negative transfer. If the weights transferred are pretrained
    to respond to unsuitable features then this training will not be fully reversed
    during the fine-tuning phase and the model could be more likely to overfit to
    these inappropriate features. Scenarios such as this usually lead to overfitting
    the idiosyncrasies of the target training set [plested2019analysis](#bib.bib95)
    ; [kornblith2021better](#bib.bib51) . A related scenario is explored in [kornblith2021better](#bib.bib51)
    where it is shown that alternative loss functions that improve how well the pretrained
    features fit the source dataset lead to a reduction in performance on the target
    dataset. The authors state that ”.. there exists a trade-off between learning
    invariant features for the original task and features relevant for transfer tasks.”
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用深度神经网络时，一旦权重经过预训练以响应大型源数据集中的特定特征，权重在微调期间不会远离其预训练值[neyshabur2020being](#bib.bib85)。如果目标数据集的规模比源数据集小几个数量级，这种情况尤为明显。这一前提允许迁移学习提高性能，但也可能导致负迁移。如果迁移的权重预训练以响应不适合的特征，那么这种训练在微调阶段不会完全逆转，模型可能更容易对这些不适当的特征过拟合。这种情况通常导致对目标训练集的特异性进行过拟合[plested2019analysis](#bib.bib95)；[kornblith2021better](#bib.bib51)。相关情境在[kornblith2021better](#bib.bib51)中探讨，其中显示改善预训练特征与源数据集拟合的替代损失函数会导致目标数据集上的性能下降。作者指出“……在原始任务的不可变特征学习与迁移任务相关特征之间存在权衡。”
- en: In image classification models, features learned through lower layers are more
    general, and those learned in higher layers are more task specific [yosinski2014transferable](#bib.bib149)
    . It is likely that if less layers are transferred negative transfer should be
    less prevalent, with training all layers from random initialization being the
    extreme end of this. There has been limited work to test this, however it is shown
    to an extent in [abnar2021exploring](#bib.bib1) .
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像分类模型中，通过较低层学习到的特征较为通用，而在较高层学习到的特征更为特定于任务[yosinski2014transferable](#bib.bib149)。如果迁移的层数较少，负迁移的可能性应该较小，而从随机初始化训练所有层则是这一情况的极端。虽然对此的研究有限，但在[abnar2021exploring](#bib.bib1)中已显示出一定程度的效果。
- en: 4 Datasets commonly used in transfer learning for image classification
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 用于图像分类的迁移学习常用数据集
- en: 4.1 Source
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 来源
- en: ImageNet 1K, 5K, 9K, 21K
  id: totrans-142
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ImageNet 1K、5K、9K、21K
- en: ImageNet is an image database organized according to the WordNet hierarchy [imagenet_cvpr09](#bib.bib18)
    . ImageNet 1K or ILSVRC2012 is a well known subset of ImageNet that is used for
    an annual challenge. ImageNet 1K consists of 1,000 common image classes with at
    least 1,000 total images in each class for a total of just over 1.3 million images
    in the training set. ImageNet 5K, 9K and 21K are larger subsets of the full ImageNet
    dataset containing the most common 5,000, 9,000 and 21,000 image classes respectively.
    All three ImageNet datasets have been used as both source and target datasets,
    depending on the type of experiments being performed. They are most commonly used
    as a source dataset because of their large sizes and general classes.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ImageNet 是一个根据 WordNet 层级组织的图像数据库 [imagenet_cvpr09](#bib.bib18) 。ImageNet 1K
    或 ILSVRC2012 是 ImageNet 的一个知名子集，用于年度挑战。ImageNet 1K 包含 1,000 个常见图像类别，每个类别至少有 1,000
    张图像，总共略超过 130 万张训练图像。ImageNet 5K、9K 和 21K 是更大的 ImageNet 数据集子集，分别包含最常见的 5,000、9,000
    和 21,000 个图像类别。这三个 ImageNet 数据集都可以作为源数据集和目标数据集使用，具体取决于进行的实验类型。由于其庞大的规模和通用类别，它们最常被用作源数据集。
- en: JFT dataset
  id: totrans-144
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: JFT 数据集
- en: JFT is an internal Google dataset for large-scale image classification, which
    comprises over 300 million high-resolution images [hinton2015distilling](#bib.bib40)
    . Images are annotated with labels from a set of 18291 categories. For example,
    1165 type of animals and 5720 types of vehicles are labelled in the dataset [sun2017revisiting](#bib.bib125)
    . There are 375M labels and on average each image has 1.26 labels.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: JFT 是一个用于大规模图像分类的内部 Google 数据集，包含超过 3 亿张高分辨率图像 [hinton2015distilling](#bib.bib40)
    。图像的标签来自 18,291 个类别。例如，该数据集中标注了 1,165 种动物和 5,720 种车辆 [sun2017revisiting](#bib.bib125)
    。共有 3.75 亿个标签，平均每张图像有 1.26 个标签。
- en: Instagram hashtag datasets
  id: totrans-146
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Instagram 标签数据集
- en: Mahajan et al. [mahajan2018exploring](#bib.bib70) collected a weakly labelled
    image dataset with a maximum size of 3.5 billion labelled images from Instagram,
    being over 3,000 times larger than the commonly used large source dataset ImageNet
    1K. The hashtags were used as labels for training and evaluation. By varying the
    selected hashtags and the number of images to sample, a variety of datasets of
    different sizes and visual distributions were created. One of the datasets created
    contained 1,500 hashtags that closely matched the 1,000 ImagNet 1K classes.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Mahajan 等人 [mahajan2018exploring](#bib.bib70) 收集了一个最大规模为 35 亿张标注图像的弱标注图像数据集，这个数据集比常用的大型源数据集
    ImageNet 1K 大 3,000 多倍。使用标签作为训练和评估的依据。通过变化所选的标签和样本图像的数量，创建了不同大小和视觉分布的各种数据集。创建的一个数据集包含了
    1,500 个与 1,000 个 ImagNet 1K 类别高度匹配的标签。
- en: Places365
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Places365
- en: 'Places365 (Places) [zhou2017places](#bib.bib155) contains 365 categories of
    scenes collected by counting all the entries that corresponded to names of scenes,
    places and environments in WordNet English dictionary. They included any concrete
    noun which could reasonably complete the phrase I am in a place, or let’s go to
    the place. There are two datasets:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Places365 (Places) [zhou2017places](#bib.bib155) 包含了 365 个场景类别，这些场景类别是通过计算与
    WordNet 英语词典中场景、地点和环境名称对应的所有条目而获得的。他们包括任何能够合理完成短语“我在一个地方”或“我们去那个地方”的具体名词。共有两个数据集：
- en: •
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Places365-standard has 1.8 million training examples total with a minimum of
    3,068 images per class.
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Places365-standard 总共有 180 万个训练样本，每个类别最少有 3,068 张图像。
- en: •
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Places365-challenge has 8 million training examples.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Places365-challenge 拥有 800 万个训练样本。
- en: Places365 is generally used as a source dataset when the target dataset is scene
    based such as SUN.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Places365 通常作为源数据集使用，当目标数据集基于场景时，例如 SUN。
- en: Inaturalist
  id: totrans-155
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Inaturalist
- en: Inaturalist [van2018inaturalist](#bib.bib131) consists of 859,000 images from
    over 5,000 different species of plants and animals. Inaturalist is generally used
    as a source dataset when the target dataset is when the target dataset contains
    fine-grained plants or animal classes.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Inaturalist [van2018inaturalist](#bib.bib131) 包含来自超过 5,000 种植物和动物的 859,000 张图像。当目标数据集包含细粒度的植物或动物类别时，Inaturalist
    通常作为源数据集使用。
- en: 4.2 Target
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 目标
- en: General
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 一般
- en: General image classification datasets contain a variety of classes with a mixture
    of superordinate and subordinate classes from many different categories in WordNet
    [miller1995wordnet](#bib.bib77) . ImageNet is a canonical example of a general
    image classification dataset.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 一般的图像分类数据集包含来自 WordNet [miller1995wordnet](#bib.bib77) 中许多不同类别的各种类别，包括上位类和下位类。ImageNet
    是一个典型的通用图像分类数据集。
- en: 'Examples of general image classification datasets commonly used as target datasets
    are:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常用于目标数据集的通用图像分类数据集示例如下：
- en: •
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'CIFAR-10 and CIFAR-100 [krizhevsky2009learning](#bib.bib57) : Each have a total
    of 50,000 training and 10,000 test images of 32x32 colour images from 10 and 100
    classes respectively.'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CIFAR-10 和 CIFAR-100 [krizhevsky2009learning](#bib.bib57)：每个数据集总共有 50,000 个训练图像和
    10,000 个测试图像，图像尺寸为 32x32 彩色图像，分别来自 10 个和 100 个类别。
- en: •
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'PASCAL VOC 2007 [pascal-voc-2007](#bib.bib20) : Has 20 classes belonging to
    the superordinate categories of person, animal, vehicle, and indoor objects. It
    contains 9,963 images with 24,640 annotated objects and a 50/50 train test split.
    The size of each image is roughly $501\times 375$.'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: PASCAL VOC 2007 [pascal-voc-2007](#bib.bib20)：包含 20 个类别，属于人员、动物、车辆和室内物体的上级类别。包含
    9,963 张图像，有 24,640 个标注对象，并且训练/测试划分为 50/50。每张图像的尺寸大约为 $501\times 375$。
- en: •
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Caltech-101 [fei2004learning](#bib.bib21) : has pictures of objects belonging
    to 101 categories. About 40 to 800 images per category, with most categories having
    around 50 images. The size of each image is roughly $300\times 200$ pixels.'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Caltech-101 [fei2004learning](#bib.bib21)：包含 101 个类别的物体图像。每个类别约有 40 到 800 张图像，大多数类别约有
    50 张图像。每张图像的尺寸大约为 $300\times 200$ 像素。
- en: •
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Caltech-256 [griffin2007caltech](#bib.bib31) . An extension of Caltech-101 with
    256 categories and a minimum of 80 images per category. It includes a large clutter
    category for testing background rejection.
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Caltech-256 [griffin2007caltech](#bib.bib31)：是 Caltech-101 的扩展，包含 256 个类别，每个类别至少有
    80 张图像。它包括一个大杂乱类别，用于测试背景排除。
- en: Fine-grained
  id: totrans-169
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 精细分类
- en: 'Fine-grained image classification datasets contain subordinate classes from
    one particular superordinate class. examples are:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 精细分类图像数据集包含一个特定上级类别的下属类别。示例如下：
- en: •
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Food-101 (Food) [bossard14](#bib.bib8) : Contains 101 different classes of
    food objects with 75,750 training examples and 25,250 test examples.'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Food-101（Food）[bossard14](#bib.bib8)：包含 101 种不同的食物类别，共有 75,750 个训练样本和 25,250
    个测试样本。
- en: •
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Birdsnap (Birds) [berg2014birdsnap](#bib.bib7) : Contains 500 different species
    of birds, with 47,386 training examples and 2,443 test examples.'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Birdsnap（Birds）[berg2014birdsnap](#bib.bib7)：包含 500 种不同的鸟类，共有 47,386 个训练样本和
    2,443 个测试样本。
- en: •
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Stanford Cars (Cars) [KrauseStarkDengFei-Fei_3DRR2013](#bib.bib55) : Contains
    196 different makes and models of cars with 8,144 training examples and 8,041
    test examples.'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Stanford Cars（Cars）[KrauseStarkDengFei-Fei_3DRR2013](#bib.bib55)：包含 196 种不同的汽车型号，共有
    8,144 个训练样本和 8,041 个测试样本。
- en: •
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'FGVC Aircraft (Aircraft) [maji13fine-grained](#bib.bib71) : Contains 100 different
    makes and models of aircraft with 6,667 training examples and 3,333 test examples.'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: FGVC 飞机（Aircraft）[maji13fine-grained](#bib.bib71)：包含 100 种不同的飞机型号，共有 6,667 个训练样本和
    3,333 个测试样本。
- en: •
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Oxford-IIIT Pets (Pets)[parkhi2012cats](#bib.bib92) : Contains 37 different
    breeds of cats and dogs with 3,680 training examples and 3,369 test examples.'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Oxford-IIIT Pets（Pets）[parkhi2012cats](#bib.bib92)：包含 37 种不同的猫和狗品种，共有 3,680
    个训练样本和 3,369 个测试样本。
- en: •
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Oxford 102 Flowers (Flowers) [nilsback2008automated](#bib.bib89) : Contains
    102 different types of flowers with 2,040 training examples and 6,149 test examples.'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Oxford 102 Flowers（Flowers）[nilsback2008automated](#bib.bib89)：包含 102 种不同类型的花卉，共有
    2,040 个训练样本和 6,149 个测试样本。
- en: •
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Caltech-uscd Birds 200 (CUB) [wah2011caltech](#bib.bib134) : Contains 200 different
    species of birds with around 60 training examples per class.'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Caltech-uscd Birds 200（CUB）[wah2011caltech](#bib.bib134)：包含 200 种不同的鸟类，每个类别大约有
    60 个训练样本。
- en: •
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Stanford Dogs (Dogs) [khosla2011novel](#bib.bib49) : Contains 20,580 images
    of 120 breeds of dogs'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Stanford Dogs（Dogs）[khosla2011novel](#bib.bib49)：包含 120 个犬种的 20,580 张图像。
- en: Scenes
  id: totrans-187
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 场景
- en: 'Scene datasets contain examples of different indoor and/or outdoor scene settings.
    Examples are:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 场景数据集包含不同的室内和/或室外场景设置的示例。示例如下：
- en: •
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'SUN397 (SUN) [xiao2010sun](#bib.bib145) : Contains 397 categories of scenes.
    This dataset preceded Places-365 and used the same techniques for data collection.
    The scenes with at least 100 training examples were included in the final dataset.'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: SUN397（SUN）[xiao2010sun](#bib.bib145)：包含 397 个场景类别。该数据集在 Places-365 之前使用了相同的数据收集技术。最终数据集包含至少有
    100 个训练样本的场景。
- en: •
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'MIT 67 Indoor Scenes [quattoni2009recognizing](#bib.bib98) : Contains 67 Indoor
    categories, and a total of 15620 images. There are at least 100 images per category.'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MIT 67 室内场景 [quattoni2009recognizing](#bib.bib98)：包含 67 个室内类别，总计 15,620 张图像。每个类别至少有
    100 张图像。
- en: Others
  id: totrans-193
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 其他
- en: 'There are a number of other datasets that have less of an overarching theme
    and are less related to the common source datasets. These are often used in conjunction
    with deep transfer learning for image classification to show models and techniques
    are widely applicable. Examples of these are:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些其他数据集没有明确的主题，并且与常见源数据集的关联较小。这些数据集通常与深度迁移学习结合使用，用于图像分类，展示模型和技术的广泛适用性。这些例子包括：
- en: •
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Describable Textures (DTD) [cimpoi2014describing](#bib.bib14) : Consists of
    3,760 training examples of texture images with 47 classes of texture adjectives.'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可描述纹理（DTD）[cimpoi2014describing](#bib.bib14)：包含了3,760个纹理图像的训练样本，涵盖47类纹理形容词。
- en: •
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Daimler pedestrian classification [munder2006experimental](#bib.bib81) : Contains
    23,520 training images with two classes, being contains pedestrians and does not
    contain pedestrians.'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 戴姆勒行人分类 [munder2006experimental](#bib.bib81)：包含了23,520张有两个类别的训练图像，即包含行人和不包含行人。
- en: •
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'German road signs (GTSRB) [stallkamp2012man](#bib.bib123) : Contains 39,209
    training images of German road signs in 43 classes.'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 德国交通标志（GTSRB）[stallkamp2012man](#bib.bib123)：包含了39,209张分类为43类的德国交通标志的训练图像。
- en: •
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Omniglot [lake2015human](#bib.bib59) : Contains over 1.2 million training examples
    of 1,623 different handwritten characters from 50 writing systems.'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Omniglot [lake2015human](#bib.bib59)：包含了超过120万个来自50种书写系统的1,623种不同手写字符的训练样本。
- en: •
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'SVHN digits in the wild (SVHN) [netzer2011reading](#bib.bib84) : Contains 73,257
    training examples of labelled digits cropped from Street View images.'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 野外的SVHN数字（SVHN）[netzer2011reading](#bib.bib84)：包含了73,257个从街景图像中裁剪出的标记数字的训练样本。
- en: •
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'UCF101 Dynamic Images (UCF101) [soomro2012ucf101](#bib.bib121) : Contains 9,537
    static frames of 101 classes of actions cropped from action videos.'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: UCF101动态图像（UCF101）[soomro2012ucf101](#bib.bib121)：包含了9,537张从动作视频中裁剪出的101类动作的静态帧。
- en: •
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Visual Decathlon Challenge (Decathlon) [rebuffi2017learning](#bib.bib103) :
    A challenge designed to simultaneously solve 10 image classification problems
    being: ImageNet, CIFAR-100, Aircraft, Daimler pedestrian, Describable textures,
    German traffic signs, Omniglot, SVHN, UCF101, VGG-Flowers. All images resized
    to have a shorter side of 72 pixels'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 视觉十项全能挑战（Decathlon）[rebuffi2017learning](#bib.bib103)：一个旨在同时解决10个图像分类问题的挑战，包括：ImageNet、CIFAR-100、飞机、戴姆勒行人、可描述纹理、德国交通标志、Omniglot、SVHN、UCF101、VGG-Flowers。所有图像的短边都调整为72像素。
- en: 5 Deep transfer learning progress and areas for improvement
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 深度迁移学习的进展和改进领域
- en: 'In the past decade, the successes of CNNs on image classification tasks have
    inspired many researchers to apply them to an increasingly wide range of domains.
    Model performance is strongly affected by the relationship between the amount
    of training data and the number of trainable parameters in a model as shown in
    Figures [1](#S3.F1 "Figure 1 ‣ 3.1 Problem Definition ‣ 3 Overview ‣ Deep transfer
    learning for image classification: a survey") and [2](#S3.F2 "Figure 2 ‣ 3.1 Problem
    Definition ‣ 3 Overview ‣ Deep transfer learning for image classification: a survey").
    As a result there has been ever growing interest in using transfer learning to
    allow large CNN models to be trained in domains where there is only limited training
    data available or other constraints exist.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '在过去的十年中，卷积神经网络（CNN）在图像分类任务上的成功激励了许多研究人员将其应用于越来越广泛的领域。模型性能受训练数据量和模型中可训练参数数量之间关系的强烈影响，如图[1](#S3.F1
    "Figure 1 ‣ 3.1 Problem Definition ‣ 3 Overview ‣ Deep transfer learning for image
    classification: a survey")和图[2](#S3.F2 "Figure 2 ‣ 3.1 Problem Definition ‣ 3
    Overview ‣ Deep transfer learning for image classification: a survey")所示。因此，利用迁移学习使大型CNN模型在训练数据有限或存在其他约束的领域中进行训练的兴趣日益增长。'
- en: As deep learning gained popularity in 2012 to 2016 transferability of features
    and best practices for performing deep transfer learning was explored [agrawal2014analyzing](#bib.bib2)
    ; [azizpour2015factors](#bib.bib4) ; [huh2016makes](#bib.bib42) ; [sharif2014cnn](#bib.bib116)
    ; [yosinski2014transferable](#bib.bib149) . While there are some recent works
    that have introduced improvement to transfer learning techniques and insights,
    there are many more that have focused on best practice for either general [kornblith2019better](#bib.bib52)
    ; [mahajan2018exploring](#bib.bib70) ; [li2020rethinking](#bib.bib61) ; [plested2021non](#bib.bib96)
    or specific [raghu2019transfusion](#bib.bib100) ; [heker2020joint](#bib.bib37)
    application domains rather than techniques. We fully review both.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习在2012年至2016年间变得流行，研究了特征的可转移性以及执行深度转移学习的最佳实践 [agrawal2014analyzing](#bib.bib2)；[azizpour2015factors](#bib.bib4)；[huh2016makes](#bib.bib42)；[sharif2014cnn](#bib.bib116)；[yosinski2014transferable](#bib.bib149)
    。虽然一些最近的作品介绍了改进的迁移学习技术和见解，但更多的作品专注于一般 [kornblith2019better](#bib.bib52)；[mahajan2018exploring](#bib.bib70)；[li2020rethinking](#bib.bib61)；[plested2021non](#bib.bib96)
    或特定 [raghu2019transfusion](#bib.bib100)；[heker2020joint](#bib.bib37) 应用领域的最佳实践，而不是技术。我们将对这两者进行全面的审查。
- en: When reviewing the application of deep transfer learning for image classification
    we divide applications into categories. We split tasks in two directions being
    small versus large target datasets and closely versus loosely related source and
    target datasets. For example using ImagNet [imagenet_cvpr09](#bib.bib18) as a
    source dataset to pretrain a model for classifying tumours on medical images is
    a loosely related transfer and is likely to be a small target dataset due to privacy
    and scarcity of disease. This category division aligns with the factors that affect
    negative transfer outlined in [wang2019characterizing](#bib.bib140) ; [wang2019transferable](#bib.bib138)
    .
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在审查深度迁移学习用于图像分类的应用时，我们将应用程序分为几个类别。我们将任务分为两个方向：小目标数据集与大目标数据集，以及紧密相关的源和目标数据集与松散相关的源和目标数据集。例如，使用ImageNet
    [imagenet_cvpr09](#bib.bib18) 作为源数据集来预训练医学图像上的肿瘤分类模型，这是一种松散相关的迁移，并且由于隐私和疾病的稀缺性，目标数据集可能相对较小。这种类别划分与影响负迁移的因素一致，如[wang2019characterizing](#bib.bib140)；[wang2019transferable](#bib.bib138)
    所述。
- en: The distinction between target dataset sizes is useful as it has been shown
    that small target datasets are much more sensitive to changes in transfer learning
    hyperparameters [plested2019analysis](#bib.bib95) . It has also been shown that
    standard transfer learning hyperparamters do not perform as well when transferring
    to a less related target task [he2018rethinking](#bib.bib34) ; [kornblith2019better](#bib.bib52)
    ; [plested2021non](#bib.bib96) , with negative transfer being an extreme example
    of this [wang2019characterizing](#bib.bib140) ; [wang2019transferable](#bib.bib138)
    , and that the similarity between datasets should be considered when deciding
    on hyperparameters [li2020rethinking](#bib.bib61) ; [plested2021non](#bib.bib96)
    . These distinctions go some way to explaining conflicting performance of deep
    transfer learning methods in recent years [he2018rethinking](#bib.bib34) ; [li2020rethinking](#bib.bib61)
    ; [wan2019towards](#bib.bib135) ; [zoph2020rethinking](#bib.bib159) .
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 目标数据集大小的区分是有用的，因为已经证明小目标数据集对迁移学习超参数的变化更为敏感 [plested2019analysis](#bib.bib95)。同时也表明，当向不太相关的目标任务进行迁移时，标准迁移学习超参数的表现并不理想
    [he2018rethinking](#bib.bib34)；[kornblith2019better](#bib.bib52)；[plested2021non](#bib.bib96)，负迁移是这一现象的一个极端例子
    [wang2019characterizing](#bib.bib140)；[wang2019transferable](#bib.bib138)，在确定超参数时应考虑数据集之间的相似性
    [li2020rethinking](#bib.bib61)；[plested2021non](#bib.bib96)。这些区别在一定程度上解释了近年来深度迁移学习方法性能出现矛盾的原因
    [he2018rethinking](#bib.bib34)；[li2020rethinking](#bib.bib61)；[wan2019towards](#bib.bib135)；[zoph2020rethinking](#bib.bib159)。
- en: 'We start this section by describing general studies on deep transfer learning
    techniques, including recent advances. Then we review work in each of the application
    areas described by our split above. Section [7](#S7 "7 Discussion and suggestions
    for future directions ‣ Deep transfer learning for image classification: a survey")
    summarizes current knowledge and makes final recommendation for future directions
    of research in the field.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '我们通过描述深度迁移学习技术的一般研究，包括最新进展，来开始本节。然后，我们审查我们上面划分的每个应用领域的工作。第[7](#S7 "7 Discussion
    and suggestions for future directions ‣ Deep transfer learning for image classification:
    a survey") 节总结了当前知识，并对该领域的未来研究方向提出最终建议。'
- en: 5.1 General deep transfer learning for image classification
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 图像分类的一般深度迁移学习
- en: 'Early work on deep transfer learning showed that:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的深度迁移学习工作显示：
- en: '1.'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Deep transfer learning results in comparable or above state of the art performance
    in many different tasks, particularly when compared to shallow machine learning
    methods [sharif2014cnn](#bib.bib116) ; [azizpour2015factors](#bib.bib4) .
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度迁移学习在许多不同任务中结果与最先进的性能相当或更好，特别是与浅层机器学习方法相比 [sharif2014cnn](#bib.bib116) ; [azizpour2015factors](#bib.bib4)
    。
- en: '2.'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: More pretraining both in terms of the number of training examples and the number
    of iterations tends to result in better performance [agrawal2014analyzing](#bib.bib2)
    ; [azizpour2015factors](#bib.bib4) ; [huh2016makes](#bib.bib42) .
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更多的预训练，无论是在训练样本数量还是迭代次数上，通常会带来更好的性能 [agrawal2014analyzing](#bib.bib2) ; [azizpour2015factors](#bib.bib4)
    ; [huh2016makes](#bib.bib42) 。
- en: '3.'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Fine-tuning the weights on the target task tends to result in better performance
    particularly when the target dataset is larger and less similar to the source
    dataset [agrawal2014analyzing](#bib.bib2) ; [yosinski2014transferable](#bib.bib149)
    ; [azizpour2015factors](#bib.bib4) .
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在目标任务上进行权重微调通常会带来更好的性能，特别是当目标数据集更大且与源数据集的相似性较低时 [agrawal2014analyzing](#bib.bib2)
    ; [yosinski2014transferable](#bib.bib149) ; [azizpour2015factors](#bib.bib4) 。
- en: '4.'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Transferring more layers tends to result in better performance when the source
    and target dataset and task are closely matched, but less layers are better when
    they are less related [agrawal2014analyzing](#bib.bib2) ; [yosinski2014transferable](#bib.bib149)
    ; [azizpour2015factors](#bib.bib4) ; [chu2016best](#bib.bib13) ; [abnar2021exploring](#bib.bib1)
    .
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当源数据集和目标数据集及任务紧密匹配时，迁移更多层通常会带来更好的性能，但当它们关系较少时，迁移较少的层更为有效 [agrawal2014analyzing](#bib.bib2)
    ; [yosinski2014transferable](#bib.bib149) ; [azizpour2015factors](#bib.bib4) ;
    [chu2016best](#bib.bib13) ; [abnar2021exploring](#bib.bib1) 。
- en: '5.'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: Deeper networks result in better performance [azizpour2015factors](#bib.bib4)
    .
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更深的网络通常会带来更好的性能 [azizpour2015factors](#bib.bib4) 。
- en: It should be noted that all the studies referenced above were completed prior
    to advances in residual networks [he2016deep](#bib.bib36) and other modern very
    deep CNNs. It has been argued that residual networks when combined with fine-tuning
    makes features more transferable [he2016deep](#bib.bib36) . As many of the above
    studies were carried out within a similar time period some results have not been
    combined. For instance, most were done with AlexNet, a relatively shallow network,
    as a base and many did not perform fine tuning and/or simply used a deep neural
    network as a feature detector at whatever layer it was transferred. It has since
    been shown that when fine-tuning is used effectively, transferring less than the
    maximum number of layers can result in better performance. This applies even when
    the source and target datasets are highly related, particularly with smaller target
    datasets [plested2019analysis](#bib.bib95) ; [plested2021non](#bib.bib96) ; [abnar2021exploring](#bib.bib1)
    .
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 应注意，以上所有引用的研究在残差网络 [he2016deep](#bib.bib36) 和其他现代非常深的卷积神经网络出现之前完成。有人认为，当残差网络与微调结合使用时，特征的可迁移性会更强
    [he2016deep](#bib.bib36) 。由于许多上述研究是在类似时间段内进行的，因此一些结果尚未结合。例如，大多数研究是以相对较浅的网络 AlexNet
    作为基础进行的，许多研究没有进行微调和/或仅仅将深度神经网络作为特征检测器，不论其迁移到哪个层次。后来证明，当有效使用微调时，迁移少于最大层数可以带来更好的性能。即使在源数据集和目标数据集高度相关的情况下，特别是对于较小的目标数据集
    [plested2019analysis](#bib.bib95) ; [plested2021non](#bib.bib96) ; [abnar2021exploring](#bib.bib1)
    ，这一点也适用。
- en: More recently it has been shown that the performance of models on ImageNet 1K
    correlates well with performance when the pretrained model is transferred to other
    tasks [kornblith2019better](#bib.bib52) . The authors additionally demonstrate
    that the increase in performance of deep transfer learning over random initialization
    is highly dependent on both the target dataset size and the relationship between
    the classes in the source and target datasets. This will be discussed more in
    the following sections.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究表明，模型在 ImageNet 1K 上的表现与预训练模型迁移到其他任务时的表现有很好的相关性 [kornblith2019better](#bib.bib52)
    。作者进一步展示了深度迁移学习相比于随机初始化的性能提升高度依赖于目标数据集的大小以及源数据集和目标数据集类别之间的关系。以下章节将对此进行更多讨论。
- en: 5.2 Recent advances
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 最近的进展
- en: 'Recent advances in the body of knowledge related to deep transfer learning
    for image classification can be divided into advances in techniques, and general
    insights on best practice. We describe advances in transfer learning techniques
    here and insights on best practice in Section [5.2.4](#S5.SS2.SSS4 "5.2.4 Insights
    on best practice ‣ 5.2 Recent advances ‣ 5 Deep transfer learning progress and
    areas for improvement ‣ Deep transfer learning for image classification: a survey").
    Recent advances in techniques are divided into regularization, hyperparameter
    based, matching the source domain to the target domain, and a few others that
    do not fit the previous categories. We discuss matching the source domain to the
    target domain under the relevant source versus task domains in Sections [5.3.1](#S5.SS3.SSS1
    "5.3.1 More versus better matched pretraining data ‣ 5.3 Large closely related
    target datasets ‣ 5 Deep transfer learning progress and areas for improvement
    ‣ Deep transfer learning for image classification: a survey") and [5.6.1](#S5.SS6.SSS1
    "5.6.1 More vs better matched pretraining data part 2 ‣ 5.6 Smaller target datasets
    with similar tasks ‣ 5 Deep transfer learning progress and areas for improvement
    ‣ Deep transfer learning for image classification: a survey") and the rest below.
    In our reviews of recent work we attempt to present a balanced view of the evidence
    for the improvements offered by newer models compared to prior ones and the limitations
    of those improvements. However, in some of the more recent cases this is difficult
    as the original papers provide limited evidence and new work showing the limitations
    of the methods has not yet been done.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 与图像分类的深度迁移学习相关的知识进展可以分为技术进展和最佳实践的一般见解。我们在这里描述迁移学习技术的进展，最佳实践的见解见于第[5.2.4](#S5.SS2.SSS4
    "5.2.4 最佳实践的见解 ‣ 5.2 最近的进展 ‣ 5 深度迁移学习的进展和改进领域 ‣ 图像分类的深度迁移学习：调查")节。技术的最新进展分为正则化、基于超参数的、源领域与目标领域匹配以及其他一些不符合前述类别的技术。我们在第[5.3.1](#S5.SS3.SSS1
    "5.3.1 更多与更好匹配的预训练数据 ‣ 5.3 大规模相关目标数据集 ‣ 5 深度迁移学习的进展和改进领域 ‣ 图像分类的深度迁移学习：调查")节和第[5.6.1](#S5.SS6.SSS1
    "5.6.1 更多与更好匹配的预训练数据第2部分 ‣ 5.6 小规模的目标数据集与相似任务 ‣ 5 深度迁移学习的进展和改进领域 ‣ 图像分类的深度迁移学习：调查")节讨论源领域与目标领域的匹配及其他内容。在我们对最新工作的审查中，我们尝试展示新模型相对于旧模型的改进证据的平衡视角以及这些改进的局限性。然而，在一些较新的案例中，这很困难，因为原始论文提供的证据有限，且尚未有新工作展示这些方法的局限性。
- en: 5.2.1 Regularization based technique advances
  id: totrans-231
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1 基于正则化的技术进展
- en: 'Most regularization based techniques aim to solve the problem of the unreliable
    empirical risk minimizer [3.2.2](#S3.SS2.SSS2 "3.2.2 Unreliable Empirical Risk
    Minimizer ‣ 3.2 Learning from small vs large datasets ‣ 3 Overview ‣ Deep transfer
    learning for image classification: a survey") by restricting the model weights
    or the features produced by them so they can’t fit small idiosyncrasies in the
    data. They achieve this by adding a regularization term $\lambda\cdot\Omega\left(.\right)$
    to the loss function to make it:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数基于正则化的技术旨在通过限制模型权重或其产生的特征，解决不可靠的经验风险最小化问题[3.2.2](#S3.SS2.SSS2 "3.2.2 不可靠的经验风险最小化者
    ‣ 3.2 从小数据集与大数据集学习 ‣ 3 概述 ‣ 图像分类的深度迁移学习：调查")，以防其拟合数据中的小的特性。这些技术通过向损失函数添加正则化项 $\lambda\cdot\Omega\left(.\right)$
    来实现：
- en: '|  | $min_{w}L\left(w\right)=\left\{\frac{1}{n}\sum_{i=1}^{n}L\left(z\left(x_{i},w\right),y_{i}\right)+\lambda\cdot\Omega\left(.\right)\right\}$
    |  |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '|  | $min_{w}L\left(w\right)=\left\{\frac{1}{n}\sum_{i=1}^{n}L\left(z\left(x_{i},w\right),y_{i}\right)+\lambda\cdot\Omega\left(.\right)\right\}$
    |  |'
- en: with the first term $\frac{1}{n}\sum_{i=1}^{n}L\left(z\left(x_{i},w\right),y_{i}\right)$
    being the empirical loss and the second term being the regularization term. The
    tuning parameter $\lambda>0$ balances the trade-off between the two.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 其中第一个项 $\frac{1}{n}\sum_{i=1}^{n}L\left(z\left(x_{i},w\right),y_{i}\right)$
    是经验损失，第二项是正则化项。调整参数 $\lambda>0$ 平衡了两者之间的权衡。
- en: Weight regularization directly restricts how much the model weights can move.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 权重正则化直接限制了模型权重的移动范围。
- en: 'Knowledge distillation or feature based regularization uses the distance between
    the feature maps output from one or more layers of the source and target networks
    to regularize the model:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 知识蒸馏或基于特征的正则化使用源网络和目标网络中一个或多个层的特征图输出之间的距离来正则化模型：
- en: '|  | $\Omega(w,w_{s})=\frac{1}{n}\sum_{j=1}^{N}\sum_{i=1}^{n}d\left(F_{j}\left(w_{t},x_{i}\right),F_{j}\left(w_{s},x_{i}\right)\right)$
    |  |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '|  | $\Omega(w,w_{s})=\frac{1}{n}\sum_{j=1}^{N}\sum_{i=1}^{n}d\left(F_{j}\left(w_{t},x_{i}\right),F_{j}\left(w_{s},x_{i}\right)\right)$
    |  |'
- en: where $F_{j}\left(w_{t},x_{i}\right)$ is the feature map output by the jth filter
    in the target network defined by weights $w_{t}$ for input value $x_{i}$, and
    $d\left(.\right)$ is a measure of dissimilarity between two feature maps.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $F_{j}\left(w_{t},x_{i}\right)$ 是由目标网络中第j个滤波器以权重 $w_{t}$ 对输入值 $x_{i}$ 输出的特征图，而
    $d\left(.\right)$ 是两个特征图之间的不相似度度量。
- en: The success of regularization based techniques for deep transfer learning rely
    heavily on the assumption that the source and target datasets are closely related.
    This is required to ensure that the optimal weights or features for the target
    dataset are not far from those trained on the source dataset.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 基于正则化的深度迁移学习技术的成功在很大程度上依赖于源数据集和目标数据集密切相关的假设。这是为了确保目标数据集的最佳权重或特征不会与在源数据集上训练的那些权重或特征相差太远。
- en: There have been many new regularization based techniques introduced in the last
    three years. We review major new techniques in chronological order.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去三年里，已经出现了许多新的基于正则化的技术。我们按时间顺序回顾了主要的新技术。
- en: '1.'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: L2-SP [li2018explicit](#bib.bib64) ; [li2020baseline](#bib.bib65) is a form
    of weight regularization. The aim of transfer learning is to create models that
    are regularized by keeping features that are reasonably close to those trained
    on a source dataset for which overfitting is not as much of a problem. The authors
    argue that because of this, during the target dataset training phase the fine
    tuned weights should be decayed towards the pretrained weights, not zero. Several
    regularizers that decay weights towards their starting point, denoted SP regularizers,
    were tested in the original papers. The L2-SP regularizer $\Omega(w)=\frac{\alpha}{2}\left\|w-w^{0}\right\|_{2}^{2}$
    which is the L2 loss between the source weights and the current weights is shown
    to significantly outperform the standard L2 loss on the four target datasets shown
    in the paper with a Resent-101 model. The original paper showed results for transferring
    to four small target datasets that were very similar to the two source datasets
    used for pretraining. It has since been shown that the L2-SP regularizer can result
    in minimal improvement or even negative transfer when the source and target datasets
    are less related [li2020rethinking](#bib.bib61) ; [wan2019towards](#bib.bib135)
    ; [plested2021non](#bib.bib96) ; [chen2019catastrophic](#bib.bib12) . More recent
    work has showed that in some cases using L2-SP regularization for lower layers
    and L2 regularization for higher layers can improve performance [plested2021non](#bib.bib96)
    .
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: L2-SP [li2018explicit](#bib.bib64) ; [li2020baseline](#bib.bib65) 是一种权重正则化的形式。迁移学习的目的是创建通过保持特征接近那些在源数据集上训练的模型来进行正则化，从而减少过拟合问题。作者认为，由于这一点，在目标数据集训练阶段，微调的权重应该向预训练权重衰减，而不是衰减到零。原论文测试了几种将权重衰减到其起始点的正则化器，称为SP正则化器。L2-SP正则化器
    $\Omega(w)=\frac{\alpha}{2}\left\|w-w^{0}\right\|_{2}^{2}$，即源权重与当前权重之间的L2损失，已被证明在论文中使用Resent-101模型的四个目标数据集上显著优于标准L2损失。原论文展示了在四个与预训练时使用的两个源数据集非常相似的小目标数据集上的迁移结果。后来已经证明，当源数据集和目标数据集关系较远时，L2-SP正则化器可能会导致最小的改进甚至负迁移
    [li2020rethinking](#bib.bib61) ; [wan2019towards](#bib.bib135) ; [plested2021non](#bib.bib96)
    ; [chen2019catastrophic](#bib.bib12) 。更近期的工作表明，在某些情况下，使用L2-SP正则化用于较低层，并在较高层使用L2正则化，可以提高性能
    [plested2021non](#bib.bib96) 。
- en: '2.'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'DELTA [li2019delta](#bib.bib63) is an example of knowledge distillation or
    feature map based regularization. It is based on the idea of re-using CNN channels
    that are not useful to the target task while not changing channels that are useful.
    Training on the target task is regularized by the attention weighted L2 loss between
    the final layer feature maps of the source and target models:'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DELTA [li2019delta](#bib.bib63) 是知识蒸馏或特征图基于正则化的一个例子。它基于重复使用对目标任务没有用处的CNN通道，而不改变有用的通道的思想。通过源模型和目标模型的最终层特征图之间的加权L2损失来正则化目标任务的训练：
- en: '|  | $\displaystyle\Omega(w,w^{0},x_{i},y_{i})=\sum_{j=1}^{N}(W_{j}(w^{0},x_{i},y_{i})$
    |  |'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\displaystyle\Omega(w,w^{0},x_{i},y_{i})=\sum_{j=1}^{N}(W_{j}(w^{0},x_{i},y_{i})$
    |  |'
- en: '|  | $\displaystyle\cdot\left\&#124;FM_{j}(w,x_{i})-FM_{j}(w^{0},x_{i}))\right\&#124;_{2}^{2}$
    |  |'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\displaystyle\cdot\left\|FM_{j}(w,x_{i})-FM_{j}(w^{0},x_{i}))\right\|_{2}^{2}$
    |  |'
- en: Where $FM_{j}(w,x_{i})$ is the output from the $jth$ filter applied to the $ith$
    input. The attention weights $W_{j}$ for each filter are calculated by removing
    the model’s filters one by one (setting its output weights to 0), calculating
    the increase in loss. Filters resulting in a high increase in loss are then set
    with a higher weight for regularization, encouraging them to stay similar to those
    trained on the source task. Others that are not as useful in the target task are
    less regularized and can change more. This regularization resulted in performance
    that was slightly better than the L2-SP regularization in most cases with ResNet-101
    and Inceptionv3 models, ImageNet 1K as the source dataset and a variety of target
    datasets. The original paper showed state of the art performance for DELTA on
    Caltech 256-30, however they used mostly the same datasets as the original L2-SP
    paper [li2018explicit](#bib.bib64) and for the two additional datasets used they
    showed that L2-SP outperformed the baseline L2 regularization. It has since been
    shown that like L2-SP, DELTA can also hinder performance when the source and target
    datasets are less similar [kou2020stochastic](#bib.bib53) ; [chen2019catastrophic](#bib.bib12)
    ; [jeon2020sample](#bib.bib45) .
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中 $FM_{j}(w,x_{i})$ 是第 $j$ 个滤波器对第 $i$ 个输入的输出。每个滤波器的注意力权重 $W_{j}$ 是通过逐个去除模型的滤波器（将其输出权重设为
    0），计算损失的增加来计算的。那些导致损失大幅增加的滤波器将被设置为更高的正则化权重，鼓励它们保持与源任务上训练的滤波器相似。而在目标任务中不那么有用的滤波器则正则化较少，可以有更多变化。这种正则化在大多数情况下使用
    ResNet-101 和 Inceptionv3 模型时，图像数据集 ImageNet 1K 作为源数据集和多种目标数据集，其性能略好于 L2-SP 正则化。原始论文在
    Caltech 256-30 上展示了 DELTA 的最先进性能，但他们使用的主要是与原始 L2-SP 论文 [li2018explicit](#bib.bib64)
    相同的数据集，并且对于使用的两个额外数据集，他们展示了 L2-SP 优于基准 L2 正则化。之后已经证明，与 L2-SP 类似，当源数据集和目标数据集不够相似时，DELTA
    也可能阻碍性能 [kou2020stochastic](#bib.bib53) ; [chen2019catastrophic](#bib.bib12) ;
    [jeon2020sample](#bib.bib45) 。
- en: '3.'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Wan et al. [wan2019towards](#bib.bib135) propose decomposing the transfer learning
    gradient update into the empirical loss and regularization loss gradient vectors.
    Then when the angle between the two vectors is greater than 90 degrees they further
    decompose the regularization loss gradient vector into the portion perpendicular
    to the empirical loss gradient and the remaining vector in the opposite direction
    of the empirical loss gradient. They remove the latter term, in the hopes that
    not allowing the regularization term to move the weights in the opposite direction
    of the empirical loss term will stop negative transfer. They show that their proposal
    improves performance slightly with a ResNet 18 on four different datasets. However,
    their results are poor compared to state of the art as they do not test on modern
    very deep models. For this reason, it is difficult to judge how well their regularization
    method performs in general.
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Wan 等人 [wan2019towards](#bib.bib135) 提出了将迁移学习梯度更新分解为经验损失和正则化损失梯度向量。然后，当两个向量之间的角度大于
    90 度时，他们进一步将正则化损失梯度向量分解为垂直于经验损失梯度的部分和朝向经验损失梯度的相反方向的剩余向量。他们去除了后者，希望通过不允许正则化项将权重移动到经验损失项的相反方向来防止负迁移。他们展示了他们的建议在四个不同的数据集上使用
    ResNet 18 时性能略有提升。然而，由于他们没有在现代深度模型上进行测试，因此与当前最先进的技术相比，他们的结果较差。因此，很难判断他们的正则化方法在一般情况下的表现。
- en: '4.'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Batch spectral shrinkage (BSS) [chen2019catastrophic](#bib.bib12) introduces
    a loss penalty applied to smaller singular values of channelwise features in each
    batch update during fine-tuning so that untransferable spectral components are
    suppressed. They test this method using a ResNet50 pretrained on ImageNet 1K and
    fine-tuned on a range of different target datasets. The results show that their
    method never hurts performance on the given datasets and often produces significant
    performance gains over L2, L2-SP and DELTA regularization for smaller target datasets.
    They also show that BSS can improve performance for less similar target datasets
    where L2-SP hinders performance.
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 批量光谱收缩（BSS）[chen2019catastrophic](#bib.bib12) 引入了一种损失惩罚机制，该机制在每次批量更新期间对每个批次的通道特征中的较小奇异值施加惩罚，从而抑制不可转移的光谱成分。他们使用在
    ImageNet 1K 上预训练的 ResNet50，并在多个不同目标数据集上进行微调来测试这种方法。结果表明，他们的方法从未对给定的数据集造成性能损害，并且在较小的目标数据集上通常比
    L2、L2-SP 和 DELTA 正则化产生显著的性能提升。他们还表明 BSS 可以在 L2-SP 阻碍性能的情况下提高对不太相似的目标数据集的性能。
- en: '5.'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: Sample-based regularization [jeon2020sample](#bib.bib45) proposes regularization
    using the distance between feature maps of pairs of inputs in the same class,
    as well as weight regularization. The model was tested using a ResNet-50 and transferring
    from ImageNet 1K and Places365 to a number of different, fine grained classification
    tasks. The authors report an improvement over L2-SP, DELTA and BSS in all tests.
    Their results reconfirm that BSS performs better than DELTA and L2SP in most cases
    and in some cases DELTA and L2SP decrease performance compared to the standard
    L2 regularization baseline.
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于样本的正则化[jeon2020sample](#bib.bib45) 提出了使用同一类别的输入对的特征图之间的距离以及权重正则化进行正则化。该模型使用ResNet-50进行测试，并从ImageNet
    1K和Places365转移到许多不同的细粒度分类任务中。作者在所有测试中都报告了比L2-SP、DELTA和BSS更好的结果。他们的结果再次证实，在大多数情况下，BSS的性能优于DELTA和L2SP，并且在某些情况下，与标准的L2正则化基线相比，DELTA和L2SP会降低性能。
- en: 5.2.2 Normalization based technique advances
  id: totrans-254
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2 基于归一化的技术进展
- en: Further to regularization based methods, there are several recent techniques
    that attempt to better align fine-tuning in the target domain with the source
    domain. This is achieved by making adjustments to the standard batch normalization
    or other forms of normalization that are used between layers in modern CNNs.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 除了基于正则化的方法外，还有一些最近的技术试图更好地将目标域的微调与源域对齐。这是通过对现代CNN中的层之间使用的标准批量归一化或其他形式的归一化进行调整实现的。
- en: '1.'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Sharing batch normalization hyperparameters across source and target domains
    has been shown to be more effective than having separate ones across many domain
    adaptation tasks [wang2019transferable](#bib.bib138) ; [maria2017autodial](#bib.bib72)
    . Wang et al. [wang2019transferable](#bib.bib138) introduce an additional batch
    normalization hyperparameter called domain adaptive $\alpha$. This takes standard
    batch normalization with $\gamma$ and $\beta$ shared across source and target
    domain and scales them based on the transferability value of each channel calculated
    using the mean and variance statistics prior to normalization. As far as we are
    aware these techniques have not been applied to the general supervised transfer
    learning case.
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在许多域适应任务中，将源域和目标域共享批量归一化超参数比拥有独立的超参数更有效[wang2019transferable](#bib.bib138) ；[maria2017autodial](#bib.bib72)
    。王等人[wang2019transferable](#bib.bib138)引入了一个称为域自适应α的额外批量归一化超参数。这使用了基于每个通道的可转移性值的标准批量归一化，并使用规范化之前的均值和方差统计数据对其进行缩放。就我们所知，尚未将这些技术应用于一般的监督式迁移学习案例。
- en: '2.'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Stochastic normalization [kou2020stochastic](#bib.bib53) samples batch normalization
    based on mini-batch statistics or based on moving statistics for each filter with
    probability hyperparameter p. At the start of fine-tuning on the target dataset
    the moving statistics are initialised with those calculated during pretraining
    in order to act as a regularizer. This is designed to overcome problems with small
    batch sizes resulting in noisy batch-statistics or the collapse in training associated
    with using moving statistics to normalize all feature maps [ioffe2017batch](#bib.bib43)
    ; [ioffe2015batch](#bib.bib44) . The authors results show that their methods improve
    over BSS, DELTA and L2-SP for low sampling versions of three standard target datasets
    and improve over all but BSS for larger versions of the same datasets. Their results
    again show that BSS performs better than DELTA and L2SP in most cases and in many
    cases DELTA and L2-SP decrease performance compared to the standard L2 regularization
    baseline.
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随机归一化[kou2020stochastic](#bib.bib53)基于小批量统计数据或基于每个滤波器的移动统计数据对批量归一化进行抽样，概率超参数为p。在对目标数据集进行微调时，移动统计数据使用在预训练期间计算的统计数据初始化，以起到正则化的作用。这旨在解决小批量大小导致批次统计嘈杂或使用移动统计量对所有特征图进行归一化时训练崩溃的问题[ioffe2017batch](#bib.bib43)
    ；[ioffe2015batch](#bib.bib44) 。作者的结果显示，他们的方法在三个标准目标数据集的低采样版本上改进了BSS、DELTA和L2-SP，并在相同数据集的较大版本中除了BSS之外的所有结果都有所改进。他们的结果再次表明，在大多数情况下，BSS的性能优于DELTA和L2SP，并且在许多情况下，与标准的L2正则化基线相比，DELTA和L2SP会降低性能。
- en: 5.2.3 Other recent new techniques
  id: totrans-260
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.3 其他最近的新技术
- en: Guo et al. [guo2019spottune](#bib.bib32) make two copies of their ResNet models
    pretrained on ImageNet 1K. One model is used as a fixed feature selector with
    the pretrained layers frozen and the other model is fine-tuned. They reinitialize
    the final classification layer in both. A policy net trained with reinforcement
    learning is then used to create a mask to combine layers from each model together
    in a unique way for each target example. They show that their SpotTune model improves
    performance compared to fine-tuning with an equivalent size single model (double
    the size of the two individual models within the SpotTune architecture) and achieves
    close to or better than state of the art in most cases. MultiTune simplifies SpotTune
    by removing the policy network and concatenating the features from each model
    prior to the final classification layer rather than selecting layers. It also
    improves on SpotTune by using two different non-binary fine-tuning hyperparameter
    settings [plested2021non](#bib.bib96) rather than one fine-tuned and one frozen
    model. The results show that MultiTune improves or equals accuracy compared to
    SpotTune in most cases tested, with significantly less training time.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: Guo等人[guo2019spottune](#bib.bib32)对在ImageNet 1K上预训练的ResNet模型进行了两个副本的操作。一个模型作为固定特征选择器使用，预训练层被冻结，另一个模型则进行微调。他们重新初始化了两个模型中的最终分类层。然后使用强化学习训练的策略网络来创建一个掩码，以独特的方式将每个模型的层结合在一起，针对每个目标示例。他们展示了SpotTune模型在与等效尺寸的单一模型（SpotTune架构中的两个单独模型的双倍大小）进行微调时，提高了性能，并在大多数情况下达到了接近或优于最先进水平的效果。MultiTune通过去除策略网络并在最终分类层之前将每个模型的特征串联起来，从而简化了SpotTune，而不是选择层。它还通过使用两种不同的非二元微调超参数设置[plested2021non](#bib.bib96)而不是一个微调和一个冻结的模型，改进了SpotTune。结果显示，在大多数测试情况下，MultiTune的准确度改善或等于SpotTune，并且训练时间显著减少。
- en: Co-tuning for transfer learning [you2020co](#bib.bib150) uses a probabilistic
    mapping of hard labels in the source dataset to soft labels in the target dataset.
    This mapping allows them to keep the final classification layer in a ResNet50
    and train it using both the target data and soft labels from the source dataset.
    As with many other recent results, they show that their algorithm improves on
    all others, including BSS, DELTA and L2SP, but their results are significantly
    below state of the art for identical model sizes, source and target dataset. They
    do show the same ordering for the target datasets, using BSS improves on DELTA
    which improves on L2SP.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习中的共调节方法[you2020co](#bib.bib150)使用了源数据集中硬标签到目标数据集中软标签的概率映射。这种映射允许他们保留ResNet50中的最终分类层，并使用目标数据和源数据集中的软标签进行训练。与许多其他最近的结果一样，他们展示了他们的算法在所有其他算法中表现更佳，包括BSS、DELTA和L2SP，但在相同模型尺寸、源数据集和目标数据集下，他们的结果显著低于最先进水平。他们确实展示了对目标数据集的相同排序，使用BSS优于DELTA，DELTA优于L2SP。
- en: 5.2.4 Insights on best practice
  id: totrans-263
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.4 最佳实践的见解
- en: 'Further to advances in techniques and models, there has been a large body of
    recent research that extends the early work on best practice for deep transfer
    learning for image classification described in Section [5.1](#S5.SS1 "5.1 General
    deep transfer learning for image classification ‣ 5 Deep transfer learning progress
    and areas for improvement ‣ Deep transfer learning for image classification: a
    survey"). These studies give insights on the following decisions that need to
    be made when performing deep transfer learning for image classification:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 除了技术和模型的进展外，最近还有大量研究扩展了早期关于图像分类深度迁移学习最佳实践的工作，如第[5.1](#S5.SS1 "5.1 一般深度迁移学习用于图像分类
    ‣ 5 深度迁移学习的进展及改进领域 ‣ 图像分类的深度迁移学习：综述")节所述。这些研究提供了在进行图像分类深度迁移学习时需要做出的以下决策的见解：
- en: •
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Selecting the best model for the task*. Models that perform better on ImageNet
    were found to perform better on a range of target datasets in [kornblith2019better](#bib.bib52)
    , however this effect eventually saturates [abnar2021exploring](#bib.bib1) . Given
    a set of models with similar accuracy on a source task, the best model for target
    tasks can vary between target datasets [abnar2021exploring](#bib.bib1) .'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*选择适合任务的最佳模型*。在[kornblith2019better](#bib.bib52)中发现，在ImageNet上表现更好的模型在一系列目标数据集上表现更好，但这种效果最终会饱和[abnar2021exploring](#bib.bib1)。给定一组在源任务上具有类似准确度的模型，目标任务的最佳模型在不同目标数据集之间可能有所不同[abnar2021exploring](#bib.bib1)。'
- en: •
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Choosing the best data for pretraining*. In many cases pretraining with smaller
    more closely related source datasets was found to produce better results on target
    datasets than with larger less closely related source datasets [mensink2021factors](#bib.bib76)
    ; [ngiam2018domain](#bib.bib87) ; [mahajan2018exploring](#bib.bib70) ; [cui2016fine](#bib.bib17)
    ; [cui2018large](#bib.bib16) ; [puigcerver2020scalable](#bib.bib97) . For best
    results the source dataset should include the image domain of the target dataset
    [mensink2021factors](#bib.bib76) . For example ImageNet 1k contains more classes
    of pets than Oxford Pets making them an ideal source and target dataset combination.
    There are various measures of similarity used to define closely related that are
    outlined in Section [5.3.1](#S5.SS3.SSS1 "5.3.1 More versus better matched pretraining
    data ‣ 5.3 Large closely related target datasets ‣ 5 Deep transfer learning progress
    and areas for improvement ‣ Deep transfer learning for image classification: a
    survey").'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*选择最佳的预训练数据*。在许多情况下，与目标数据集更为相关的小规模源数据集进行预训练，往往能比与目标数据集关系较远的大规模源数据集获得更好的结果 [mensink2021factors](#bib.bib76)
    ; [ngiam2018domain](#bib.bib87) ; [mahajan2018exploring](#bib.bib70) ; [cui2016fine](#bib.bib17)
    ; [cui2018large](#bib.bib16) ; [puigcerver2020scalable](#bib.bib97) 。为了获得最佳结果，源数据集应包括目标数据集的图像领域
    [mensink2021factors](#bib.bib76) 。例如，ImageNet 1k 包含比 Oxford Pets 更多的宠物类别，使其成为理想的源数据集和目标数据集组合。有关定义“更相关”的相似度的各种度量方法在第
    [5.3.1](#S5.SS3.SSS1 "5.3.1 More versus better matched pretraining data ‣ 5.3
    Large closely related target datasets ‣ 5 Deep transfer learning progress and
    areas for improvement ‣ Deep transfer learning for image classification: a survey")
    节中有所概述。'
- en: •
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Finding the best hyperparameters for fine-tuning*. Several studies include
    extensive hyperparameter searches over learning rate, learning rate decay, weight
    decay, and momentum [kornblith2019better](#bib.bib52) ; [li2018explicit](#bib.bib64)
    ; [mahajan2018exploring](#bib.bib70) ; [li2020rethinking](#bib.bib61) ; [plested2021non](#bib.bib96)
    . These studies show the relationship between the size of the target dataset and
    its similarity to the source dataset with fine-tuning hyperparameter settings.
    Optimal learning rate and momentum, are both shown to be lower for more related
    source and target datasets [li2020rethinking](#bib.bib61) ; [plested2021non](#bib.bib96)
    . Also the number of layers to reinitialise from random weights is strongly related
    to the optimal learning rate [neyshabur2020being](#bib.bib85) ; [plested2021non](#bib.bib96)
    .'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*寻找最佳的微调超参数*。几项研究包括对学习率、学习率衰减、权重衰减和动量的广泛超参数搜索 [kornblith2019better](#bib.bib52)
    ; [li2018explicit](#bib.bib64) ; [mahajan2018exploring](#bib.bib70) ; [li2020rethinking](#bib.bib61)
    ; [plested2021non](#bib.bib96) 。这些研究展示了目标数据集的大小与其与源数据集的相似性与微调超参数设置之间的关系。最佳学习率和动量在更相关的源和目标数据集上都显示较低
    [li2020rethinking](#bib.bib61) ; [plested2021non](#bib.bib96) 。此外，从随机权重重新初始化的层数与最佳学习率有很强的关系
    [neyshabur2020being](#bib.bib85) ; [plested2021non](#bib.bib96) 。'
- en: •
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Whether a multi-step transfer process is better than a single step process*.
    A multi-step pretraining process, where the intermediate dataset is smaller and
    more closely related to the target dataset, often outperform a single step pretraining
    process when originating from a very different, large source dataset [mensink2021factors](#bib.bib76)
    ; [ng2015deep](#bib.bib86) ; [puigcerver2020scalable](#bib.bib97) ; [gonthier2020analysis](#bib.bib28)
    . Related to this, using a self-supervised learning technique for pretraining
    on a more closely related source dataset can outperform using a supervised learning
    technique on a less closely related dataset [zoph2020rethinking](#bib.bib159)
    .'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*多步骤迁移过程是否优于单步骤过程*。当源数据集非常不同且较大时，多步骤预训练过程（其中中间数据集较小且与目标数据集更为相关）通常优于单步骤预训练过程
    [mensink2021factors](#bib.bib76) ; [ng2015deep](#bib.bib86) ; [puigcerver2020scalable](#bib.bib97)
    ; [gonthier2020analysis](#bib.bib28) 。与此相关的是，在更相关的源数据集上使用自监督学习技术进行预训练，可以优于在不太相关的数据集上使用监督学习技术
    [zoph2020rethinking](#bib.bib159) 。'
- en: •
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Which type of regularization to use*. L2-SP or other more recent transfer
    learning specific regularization techniques like DELTA, BSS, stochastic normalization,
    etc, improve performance when the source and target dataset are closely related,
    but often hinder it when they are less related [li2018explicit](#bib.bib64) ;
    [li2019delta](#bib.bib63) ; [wan2019towards](#bib.bib135) ; [plested2021non](#bib.bib96)
    . These regularization techniques are discussed in more detail in Section [5.2.1](#S5.SS2.SSS1
    "5.2.1 Regularization based technique advances ‣ 5.2 Recent advances ‣ 5 Deep
    transfer learning progress and areas for improvement ‣ Deep transfer learning
    for image classification: a survey").'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*使用哪种类型的正则化*。当源数据集和目标数据集密切相关时，L2-SP或其他更现代的迁移学习特定正则化技术如DELTA、BSS、随机归一化等能够提高性能，但当它们不太相关时往往会阻碍性能[li2018explicit](#bib.bib64)；[li2019delta](#bib.bib63)；[wan2019towards](#bib.bib135)；[plested2021non](#bib.bib96)。这些正则化技术在第[5.2.1](#S5.SS2.SSS1
    "5.2.1 Regularization based technique advances ‣ 5.2 Recent advances ‣ 5 Deep
    transfer learning progress and areas for improvement ‣ Deep transfer learning
    for image classification: a survey")节中有更详细的讨论。'
- en: •
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Which loss function to use*. Alternatives to the cross-entropy loss function
    are shown to produce representations with higher class separation that obtain
    higher accuracy on the source task, but are less useful for target tasks in [kornblith2021better](#bib.bib51)
    . The results show a trade-off between learning features that perform better on
    the source task and features relevant for the target task.'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*使用哪种损失函数*。与交叉熵损失函数相比，其他替代损失函数在源任务上产生更高类别分离的表示，从而获得更高的准确性，但在目标任务中效果较差[kornblith2021better](#bib.bib51)。结果显示了在源任务上表现更好的特征与在目标任务中相关特征之间的权衡。'
- en: 'In an attempt to generalize hyperparameters and protocols when pretraining
    with source source datasets that are larger than ImageNet 1K, Kolesnikov et al.
    created Big Transfer (BiT) [kolesnikov2019big](#bib.bib50) . They pretrain various
    sizes of ResNet on ImageNet 1K and 21K, and JFT and transfer them to four small
    to medium closely related image classification target datasets as well as the
    COCO-2017 object detection dataset [lin2014microsoft](#bib.bib66) . Based on these
    experiments they make a number of general claims about deep transfer learning
    when pretraining on very large datasets including:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对源数据集（大于ImageNet 1K）进行超参数和协议的泛化，Kolesnikov等人创建了Big Transfer（BiT）[kolesnikov2019big](#bib.bib50)。他们在ImageNet
    1K和21K以及JFT上预训练了不同大小的ResNet，然后将其转移到四个小到中等规模的相关图像分类目标数据集以及COCO-2017目标检测数据集[lin2014microsoft](#bib.bib66)。基于这些实验，他们对在非常大的数据集上预训练时的深度迁移学习做出了一些一般性声明，包括：
- en: '1.'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Batch normalization (BN) [ioffe2015batch](#bib.bib44) is detrimental to BiT,
    and Group Normalization [wu2018group](#bib.bib144) combined with Weight Standardization
    performs well with large batches.
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 批量归一化（BN）[ioffe2015batch](#bib.bib44) 对BiT有害，而结合了权重标准化的组归一化[wu2018group](#bib.bib144)
    在大批量下表现良好。
- en: '2.'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: MixUp [zhang2017mixup](#bib.bib151) is not useful for pretraining on large source
    datasets and is only useful during fine-tuning for mid-sized target datasets (20-500K
    training examples)
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MixUp [zhang2017mixup](#bib.bib151) 对于在大源数据集上的预训练没有帮助，仅在微调中对中等大小目标数据集（20-500K训练样本）有用。
- en: '3.'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Regularization (L2, L2-SP, dropout) does not enhance performance in the fine-tuning
    phase, even with very large models (the largest model used for experiments has
    928 million parameters). Adjusting the training and learning rate decay time based
    on the size of the target dataset, longer for larger datasets, provides sufficient
    regularization.
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正则化（L2，L2-SP，dropout）在微调阶段不会提升性能，即使是非常大的模型（实验中使用的最大模型有9.28亿个参数）。根据目标数据集的大小调整训练和学习率衰减时间，较大的数据集时间更长，能够提供足够的正则化。
- en: 'The authors use general fine-tuning hyperparameters for learning rate scheduling,
    training time and amount/usage of MixUp that are only adjusted based on the target
    dataset size, not for individual target datasets. They achieve performance that
    is comparable to models with selectively tuned hyperparameters for their model
    pretrained on ImageNet and state of the art, or close to in many cases, for their
    model pretrained on the 300 times larger source dataset JFT. However their target
    datasets, ImageNet, CIFAR 10 & 100, and Pets are very closely related to their
    source datasets making them easier to transfer to. Their final target dataset,
    Flowers, is also known to be better suited to transfer to from their source datasets.
    See section [5.6](#S5.SS6 "5.6 Smaller target datasets with similar tasks ‣ 5
    Deep transfer learning progress and areas for improvement ‣ Deep transfer learning
    for image classification: a survey") for further discussion of which target datasets
    are easier to transfer to.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用一般的微调超参数来调整学习率调度、训练时间和MixUp的使用量/量，这些仅根据目标数据集的大小进行调整，而不是针对单个目标数据集。他们在ImageNet上预训练的模型和在300倍大源数据集JFT上预训练的模型都表现出可比的性能，或在许多情况下接近最先进水平。然而，他们的目标数据集ImageNet、CIFAR
    10 & 100和Pets与源数据集非常相关，使得迁移更容易。他们的最终目标数据集Flowers也被认为更适合从源数据集进行迁移。有关哪些目标数据集更容易迁移的进一步讨论请参见[5.6](#S5.SS6
    "5.6 较小的目标数据集与相似任务 ‣ 5 深度迁移学习进展与改进领域 ‣ 深度迁移学习在图像分类中的应用：综述")。
- en: 'We expect that best practice recommendations developed for closely related
    datasets will not be applicable to less closely related target datasets as has
    been shown for many other methods and recommendations [li2018explicit](#bib.bib64)
    ; [li2019delta](#bib.bib63) ; [wan2019towards](#bib.bib135) ; [plested2021non](#bib.bib96)
    ; [li2020rethinking](#bib.bib61) ; [chen2019catastrophic](#bib.bib12) ; [kou2020stochastic](#bib.bib53)
    . To test this hypothesis we reran a selection of the experiments in BiT using
    Stanford Cars as the target dataset which is very different from the source dataset
    ImageNet 21K and known to be more difficult to transfer to [kornblith2019better](#bib.bib52)
    ; [plested2021non](#bib.bib96) . We first confirmed that we could reproduce their
    state of the art results for the datasets listed in the paper, then produced the
    results in Table [1](#S5.T1 "Table 1 ‣ 5.2.4 Insights on best practice ‣ 5.2 Recent
    advances ‣ 5 Deep transfer learning progress and areas for improvement ‣ Deep
    transfer learning for image classification: a survey") using Stanford Cars. These
    results show that BiT produces far below state of the art results for this less
    related dataset. The first column shows the results with all the recommended hyperparameters
    from the paper. While the performance can be improved with increases in learning
    rates and number of epochs before the learning rate is decayed, final results
    are still well below state of the art for a comparable model, source and target
    dataset. The fine grained classification task in Stanford Cars is known to be
    less similar to the more general ImageNet and JFT datasets. Because of this it
    is not surprising that recommendations developed for more closely related target
    datasets do not apply.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们预计为密切相关的数据集制定的最佳实践建议将不适用于关系较远的目标数据集，这已被许多其他方法和建议所证明[li2018explicit](#bib.bib64)
    ; [li2019delta](#bib.bib63) ; [wan2019towards](#bib.bib135) ; [plested2021non](#bib.bib96)
    ; [li2020rethinking](#bib.bib61) ; [chen2019catastrophic](#bib.bib12) ; [kou2020stochastic](#bib.bib53)。为了验证这一假设，我们重新进行了BiT中的一些实验，使用Stanford
    Cars作为目标数据集，该数据集与源数据集ImageNet 21K差异很大，并且已知更难迁移[kornblith2019better](#bib.bib52)
    ; [plested2021non](#bib.bib96)。我们首先确认了可以重现论文中列出的数据集的最先进结果，然后使用Stanford Cars得出了表[1](#S5.T1
    "Table 1 ‣ 5.2.4 关于最佳实践的见解 ‣ 5.2 近期进展 ‣ 5 深度迁移学习进展与改进领域 ‣ 深度迁移学习在图像分类中的应用：综述")中的结果。这些结果表明，对于这个关系较远的数据集，BiT的表现远低于最先进水平。第一列显示了使用论文中所有推荐的超参数的结果。尽管通过增加学习率和在学习率衰减之前增加训练轮数可以提高性能，但最终结果仍远低于可比模型、源数据集和目标数据集的最先进水平。Stanford
    Cars中的细粒度分类任务与更通用的ImageNet和JFT数据集已知相差较大。因此，建议针对更密切相关的目标数据集不适用也就不足为奇了。
- en: 'Table 1: Big transfer (BiT): General visual representation learning [kolesnikov2019big](#bib.bib50)
    extended results using BiT-M pretrained on ImageNet 21K . State of the art is
    the best known result for this model, source and target dataset. Default is the
    learning rate decay schedule specified by the paper for this size target dataset
    and x2 is two times the number of batches before decaying the learning rate compared
    to the default.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 大规模迁移 (BiT): 一般视觉表示学习 [kolesnikov2019big](#bib.bib50) 使用在 ImageNet 21K
    上预训练的 BiT-M 扩展的结果。最佳效果是该模型、源数据集和目标数据集的已知最佳结果。默认值是论文中为此大小的目标数据集指定的学习率衰减计划，x2 是与默认值相比，学习率衰减之前的批次数量的两倍。'
- en: '| Dataset | Default lr (0.003) | lr 0.01 | lr 0.03 | lr 0.1 | State of the
    art |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 默认 lr (0.003) | lr 0.01 | lr 0.03 | lr 0.1 | 最佳效果 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '|  | default decay | x2 | default decay | x2 | default decay | x2 | default
    decay | x2 |  |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '|  | 默认衰减 | x2 | 默认衰减 | x2 | 默认衰减 | x2 | 默认衰减 | x2 |  |'
- en: '| Cars | 86.20 | 86.15 | 85.81 | 87.49 | 81.41 | 88.96 | 27.51 | 5.22 | 95.3[ngiam2018domain](#bib.bib87)
    |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 86.20 | 86.15 | 85.81 | 87.49 | 81.41 | 88.96 | 27.51 | 5.22 | 95.3[ngiam2018domain](#bib.bib87)
    |'
- en: 5.2.5 Insights on transferability
  id: totrans-291
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.5 关于可迁移性的见解
- en: Here we review works that give more general insight as to what is happening
    with model weights, representations and the loss landscape when transfer learning
    is performed as well as measures of transferability of pretrained weights to target
    tasks.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们回顾了那些对迁移学习过程中模型权重、表示和损失景观的变化提供更一般见解的工作，以及对预训练权重在目标任务上的可迁移性进行测量的研究。
- en: Several methods for analysing the feature space were used in [neyshabur2020being](#bib.bib85)
    . They found that models trained from pretrained weights make similar mistakes
    on the target domain, have similar features and are surprisingly close in $\ell_{2}$
    distance in the parameter space. They are in the same basins of the loss landscape.
    Models trained from random initialization do not live in the same basin, make
    different mistakes, have different features and are farther away in $\ell_{2}$
    distance in the parameter space.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '[neyshabur2020being](#bib.bib85) 使用了几种分析特征空间的方法。他们发现，从预训练权重训练的模型在目标领域上犯相似的错误，具有相似的特征，并且在参数空间中的
    $\ell_{2}$ 距离惊人地接近。它们处于损失景观的相同盆地。从随机初始化训练的模型则不在同一盆地中，犯不同的错误，具有不同的特征，并且在参数空间中的
    $\ell_{2}$ 距离较远。'
- en: A flatter and easier to navigate loss landscape for pretrained models compared
    to their randomly initialized counterparts was also shown in [liu2019towards](#bib.bib67)
    . They showed improved Lipschitzness and that this accelerates and stabilizes
    training substantially. Particularly that the singular vectors of the weight gradient
    with large singular values are shrunk in the weight matrices. Thus, the magnitude
    of gradient back-propagated through a pretrained layer is controlled, and pretrained
    weight matrices stabilize the magnitude of gradient, especially in lower layers,
    leading to more stable training.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 与随机初始化的模型相比，[liu2019towards](#bib.bib67) 还展示了预训练模型具有更平坦和更易于导航的损失景观。他们展示了改进的
    Lipschitz 连续性，这大大加速并稳定了训练。特别是，具有大奇异值的权重梯度的奇异向量在权重矩阵中被缩小。因此，通过预训练层反向传播的梯度幅度被控制，预训练权重矩阵稳定了梯度的幅度，尤其是在较低层，从而导致更稳定的训练。
- en: 'Several recent techniques have been proposed for measuring the transferability
    of pretrained weights:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 最近提出了几种用于测量预训练权重可迁移性的技术：
- en: '1.'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: H-score [bao2019information](#bib.bib5) is a measure of how well a pretrained
    model $f$ is likely to perform on a new task with input space $X$ and output space
    $Y$ based on the inter-class covariance $cov(\mathbb{E}_{P_{X|Y}}[f(X)|Y])$ and
    the feature redundancy $tr(cov(f(X)))$
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: H-score [bao2019information](#bib.bib5) 是一种衡量预训练模型 $f$ 在新的输入空间 $X$ 和输出空间 $Y$
    上表现如何的指标，基于类间协方差 $cov(\mathbb{E}_{P_{X|Y}}[f(X)|Y])$ 和特征冗余 $tr(cov(f(X)))$。
- en: '|  | $\mathcal{H}(f)=tr(cov(f(X))^{-1}cov(\mathbb{E}_{P_{X&#124;Y}}[f(X)&#124;Y])$
    |  |'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\mathcal{H}(f)=tr(cov(f(X))^{-1}cov(\mathbb{E}_{P_{X&#124;Y}}[f(X)&#124;Y])$
    |  |'
- en: 'the H-score increases as interclass covariance increases and feature redundancy
    decreases. The authors show that H-score has a strong correlation with target
    task performance. They also show that it can be used to rank transferability and
    create minimum spanning trees of task transferability. The latter may be useful
    in guiding multi-step transfer learning for less related tasks as discussed in
    Section [5.2.4](#S5.SS2.SSS4 "5.2.4 Insights on best practice ‣ 5.2 Recent advances
    ‣ 5 Deep transfer learning progress and areas for improvement ‣ Deep transfer
    learning for image classification: a survey").'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'H-score 随着类间协方差的增加和特征冗余的减少而增加。作者展示了 H-score 与目标任务性能有很强的相关性。他们还展示了它可以用来对迁移性进行排名，并创建任务迁移的最小生成树。后者可能在指导多步骤迁移学习时对不相关的任务有用，如第
    [5.2.4](#S5.SS2.SSS4 "5.2.4 Insights on best practice ‣ 5.2 Recent advances ‣
    5 Deep transfer learning progress and areas for improvement ‣ Deep transfer learning
    for image classification: a survey") 节中讨论的那样。'
- en: '2.'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Transferability and negative conditional entropy (NCE) for transfer learning
    tasks where the source and target datasets are the same, but the tasks differ,
    are defined in [tran2019transferability](#bib.bib130) . The authors define transferability
    as the log-likelihood $l_{Y}(w_{Z},k_{Y})$, where $w_{z}$ is the weights of the
    model backbone pretrained on the source task $Z$ and $k_{Y}$ is the weights of
    the classifier trained on the target task. They then define conditional cross-entropy
    (NCE) as another measure of transferability, defined as being the empirical cross
    entropy of label $\bar{y}$ from the target domain given a lablel $\bar{z}$ from
    the source domain. To empirically demonstrate the effectiveness of the NCE measure
    a ResNet18 model as the backbone was paired with an SVM classifier. NCE was demonstrated
    to have strong correlation with accuracy on the target tasks for combinations
    of 437 source and target tasks.
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 迁移学习任务中的迁移性和负条件熵（NCE），其中源数据集和目标数据集相同，但任务不同，定义在 [tran2019transferability](#bib.bib130)
    中。作者将迁移性定义为对数似然 $l_{Y}(w_{Z},k_{Y})$，其中 $w_{z}$ 是在源任务 $Z$ 上预训练的模型主干的权重，$k_{Y}$
    是在目标任务上训练的分类器的权重。他们然后将条件交叉熵（NCE）定义为另一种迁移性度量，定义为给定源领域标签 $\bar{z}$ 的目标领域标签 $\bar{y}$
    的经验交叉熵。为了实证证明 NCE 度量的有效性，将 ResNet18 模型作为主干与 SVM 分类器配对。对于 437 个源任务和目标任务的组合，NCE
    被证明与目标任务的准确性有很强的相关性。
- en: '3.'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'LEEP [nguyen2020leep](#bib.bib88) is another measure of transferability. Using
    the pretrained model, the joint distribution over labels in the source dataset
    and the target dataset labels is estimated to construct an empirical predictor.
    LEEP is the log expectation of the empirical predictor. LEEP is defined mathematically
    as:'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LEEP [nguyen2020leep](#bib.bib88) 是另一个迁移性的度量。利用预训练模型，估计源数据集和目标数据集标签上的标签的联合分布来构建经验预测器。LEEP
    是经验预测器的对数期望。LEEP 数学上定义为：
- en: '|  | $T(\theta,D)=\frac{1}{n}\sum_{i=1}^{n}log\left(\sum_{z\epsilon Z}\hat{P}\left(y_{i}&#124;z\right)\theta\left(x_{i}\right)_{z}\right)$
    |  |'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $T(\theta,D)=\frac{1}{n}\sum_{i=1}^{n}log\left(\sum_{z\epsilon Z}\hat{P}\left(y_{i}&#124;z\right)\theta\left(x_{i}\right)_{z}\right)$
    |  |'
- en: where $\theta\left(x_{i}\right)_{z}$ is is the probability of the source label
    $z$ for target input data $x_{i}$ predicted using the pretrained weights $\theta$,
    and $\hat{P}\left(y_{i}|z\right)$ is the empirical conditional probability of
    target label $y_{i}$ given source label $z$. LEEP is shown to have good theoretical
    properties and empirically it is demonstrated to have strong correlation with
    performance gain from pretraining weights on the source tasks. This is shown on
    source tasks ImageNet 1K and CIFAR10 and 200 random target tasks taken from the
    closely related CIFAR100 and less closely related FashionMNIST. The authors expand
    NCE to the case where the source and target datasets are different by creating
    dummy labels for the target data based on the source task using the pretrained
    model $\theta$. They show that LEEP has a stronger correlation with performance
    gain than the expanded NCE measure and H-score.
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中 $\theta\left(x_{i}\right)_{z}$ 是使用预训练权重 $\theta$ 对目标输入数据 $x_{i}$ 的源标签 $z$
    的概率预测，$\hat{P}\left(y_{i}|z\right)$ 是给定源标签 $z$ 的目标标签 $y_{i}$ 的经验条件概率。LEEP 被证明具有良好的理论属性，并且在经验上证明其与源任务上预训练权重的性能增益有很强的相关性。这在源任务
    ImageNet 1K 和 CIFAR10 以及从密切相关的 CIFAR100 和不太相关的 FashionMNIST 中随机选择的 200 个目标任务上得到证明。作者通过使用预训练模型
    $\theta$ 为目标数据创建虚拟标签，将 NCE 扩展到源数据集和目标数据集不同的情况。他们展示了 LEEP 与性能增益的相关性强于扩展的 NCE 度量和
    H-score。
- en: 5.3 Large closely related target datasets
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 大规模密切相关的目标数据集
- en: An early, systematic and extremely thorough treatment of deep transfer learning
    for large closely related image datasets was performed by Yosinski et al. [yosinski2014transferable](#bib.bib149)
    . They did two experiments using AlexNet [krizhevsky2012imagenet](#bib.bib58)
    . One split ImageNet 1K [imagenet_cvpr09](#bib.bib18) into two randomly chosen
    sets of 500 object classes. The other split ImageNet into two sets of classes
    that were as different as possible to make up the source and target dataset. These
    two sets of classes were natural object classes and man-made object classes. In
    both experiments they used the full 1,000 plus training examples per class, so
    both are examples of a very large target dataset. After creating the source and
    target datasets they pretrained an AlexNet [krizhevsky2012imagenet](#bib.bib58)
    on the source dataset, then transferred varying numbers of layers of weights to
    the target dataset reinitializing the remaining layers with small random weights.
    They then trained either the entire model or just the reinitialised layers applying
    the standard training hyperparameters of the day to fine tuning, these being a
    learning rate of 0.1 decayed by multiplying by 0.1 every 30 epochs.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: Yosinski 等人对大规模紧密相关的图像数据集进行了早期的系统性和极其深入的深度迁移学习研究 [yosinski2014transferable](#bib.bib149)。他们使用了
    AlexNet [krizhevsky2012imagenet](#bib.bib58) 进行了两个实验。第一个实验将 ImageNet 1K [imagenet_cvpr09](#bib.bib18)
    划分为两个随机选择的 500 个对象类别的集合。另一个实验将 ImageNet 划分为两个尽可能不同的类别集合，以构成源数据集和目标数据集。这两个类别集合分别是自然物体类别和人造物体类别。在这两个实验中，他们使用了每个类别的完整
    1,000 多个训练样本，因此都属于非常大的目标数据集。在创建源数据集和目标数据集后，他们在源数据集上对 AlexNet [krizhevsky2012imagenet](#bib.bib58)
    进行了预训练，然后将不同层数的权重转移到目标数据集，同时将剩余的层用小随机权重重新初始化。接着，他们训练了整个模型或仅重新初始化的层，应用当时的标准训练超参数进行微调，这些参数包括学习率
    0.1，每 30 个周期乘以 0.1 衰减一次。
- en: Yosinski et al. [yosinski2014transferable](#bib.bib149) concluded that weights
    from the lower layers of a CNN trained on an image task are more general and easily
    transferable between tasks, while the upper layers are more task specific. They
    showed that fine-tuning is important in transfer learning to allow fragile co-adapted
    features from the middle layers to retrain together for the new task. Finally,
    they demonstrated that for the more related source and target datasets (the randomly
    chosen classes), the more layers transferred the better the final performance.
    Whereas for the less related datasets the upper layers were less transferable.
    It should be noted that experiments with fine-tuning were not done for the less
    related source and target datasets. The only experiments performed froze the weights
    that were transferred to show the raw transferability of the weights.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: Yosinski 等人 [yosinski2014transferable](#bib.bib149) 认为，在图像任务上训练的 CNN 的低层权重更加通用，容易在任务之间转移，而高层则更具任务特异性。他们展示了微调在迁移学习中的重要性，以便中层的脆弱共适应特征能够共同重新训练以适应新任务。最后，他们证明了对于更相关的源和目标数据集（随机选择的类别），转移的层数越多，最终性能越好。而对于相关性较低的数据集，高层的可转移性较差。需要注意的是，对于相关性较低的源和目标数据集，没有进行微调的实验。唯一进行的实验是冻结了转移的权重，以展示权重的原始可转移性。
- en: The finding that more layers transferred results in better performance [yosinski2014transferable](#bib.bib149)
    has heavily influenced transfer learning hyperparameters. It is important to note
    that their results were only shown to hold for large and closely related target
    datasets and their specific fine-tuning hyperparameters. In fact they demonstrated
    that higher layers are less transferable when the source and target datasets are
    less related. Despite this their results and training hyperparameters have been
    used as a template to inform transfer learning procedures on a wide variety of
    datasets and tasks [he2018rethinking](#bib.bib34) ; [scott2018adapted](#bib.bib114)
    ; [wu2018facial](#bib.bib143) ; [tan2019efficientnet](#bib.bib128) ; [mormont2018comparison](#bib.bib80)
    ; [kornblith2019better](#bib.bib52) .
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 发现转移更多层数能获得更好性能 [yosinski2014transferable](#bib.bib149) 对迁移学习的超参数产生了深远的影响。重要的是要注意，他们的结果仅在大规模且紧密相关的目标数据集以及他们特定的微调超参数下有效。实际上，他们展示了当源数据集和目标数据集关系较少时，高层的可转移性较差。尽管如此，他们的结果和训练超参数已被用作模板，以指导各种数据集和任务的迁移学习程序
    [he2018rethinking](#bib.bib34)；[scott2018adapted](#bib.bib114)；[wu2018facial](#bib.bib143)；[tan2019efficientnet](#bib.bib128)；[mormont2018comparison](#bib.bib80)；[kornblith2019better](#bib.bib52)。
- en: The original experiments performed by Yosinski et al. on closely related datasets
    (the randomly chosen classes from ImageNet 1K) have since been repeated while
    varying the size of the target dataset and fine-tuning hyperparameters [plested2019analysis](#bib.bib95)
    . These experiments established that transferring more layers did not generally
    result in better performance when optimal fine-tuning hyperparameters were used.
    They also demonstrated that transferring the correct number of layers and using
    optimal fine-tuning hyperparameters had a much larger impact on performance as
    the size of the target dataset was reduced. Recent work [plested2021non](#bib.bib96)
    has expanded these experiments to more current and deeper models that are known
    to perform better for transfer learning [he2016deep](#bib.bib36) and less closely
    related source and target datasets. This work has confirmed that for some datasets
    transferring more layers is better. However, for others, reinitialising with random
    weights, multiple layers, or even whole blocks of layers of an Inception v4 model,
    improves performance over the baseline of transferring all but the final classification
    layer.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: Yosinski等人对紧密相关的数据集（从ImageNet 1K中随机选择的类别）进行的原始实验已被重复进行，同时改变目标数据集的大小和微调超参数[plested2019analysis](#bib.bib95)
    。这些实验表明，当使用最佳的微调超参数时，迁移更多层通常不会导致更好的性能。它们还表明，迁移正确数量的层和使用最佳微调超参数对性能的影响要大得多，尤其是在目标数据集的大小减少时。最近的工作[plested2021non](#bib.bib96)
    扩展了这些实验，涵盖了更多当前的、更深层的模型，这些模型在迁移学习中表现更好[he2016deep](#bib.bib36) 以及相关性较低的源数据集和目标数据集。这项工作确认了对于某些数据集，迁移更多的层效果更好。然而，对于其他数据集，重新初始化随机权重、多层甚至整个Inception
    v4模型的块，会比迁移所有层但最终分类层的基线性能更好。
- en: 5.3.1 More versus better matched pretraining data
  id: totrans-311
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.1 更多 versus 更好匹配的预训练数据
- en: Recent works have tested the limits of the effectiveness of transfer learning
    with large source and target datasets by pretraining on datasets that that are
    6$\times$[he2017mask](#bib.bib35) , 300$\times$ [sun2017revisiting](#bib.bib125)
    ; [ngiam2018domain](#bib.bib87) ; [xie2020self](#bib.bib146) , and even 3000$\times$
    [mahajan2018exploring](#bib.bib70) larger than ImageNet 1K and target datasets
    that are up to 9$\times$ larger [mahajan2018exploring](#bib.bib70) .
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究通过在数据集上进行预训练，测试了迁移学习在大规模源数据集和目标数据集上的有效性，这些数据集比ImageNet 1K大6$\times$[he2017mask](#bib.bib35)
    、300$\times$ [sun2017revisiting](#bib.bib125) ; [ngiam2018domain](#bib.bib87)
    ; [xie2020self](#bib.bib146) ，甚至比ImageNet 1K大3000$\times$ [mahajan2018exploring](#bib.bib70)
    ，目标数据集的规模最大可达[mahajan2018exploring](#bib.bib70) 的9$\times$。
- en: In general, increasing the size of the source dataset increases the performance
    on the target dataset. This occurs even when the target dataset is large such
    as ImageNet 1K (1K classes, 1.3M training images) and ImageNet 5k (5K classes,
    6.6M training images) or 9k (9K classes 10.5M training images) [ngiam2018domain](#bib.bib87)
    ; [mahajan2018exploring](#bib.bib70) ; [kolesnikov2019big](#bib.bib50) . However,
    source data that is carefully curated to match target data more closely can perform
    better than pretraining on larger more general source datasets [ngiam2018domain](#bib.bib87)
    ; [mahajan2018exploring](#bib.bib70) .
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，增加源数据集的规模会提高目标数据集的性能。这种情况即使在目标数据集很大时也会发生，例如ImageNet 1K（1K类别，1.3M训练图像）和ImageNet
    5k（5K类别，6.6M训练图像）或9k（9K类别10.5M训练图像）[ngiam2018domain](#bib.bib87) ; [mahajan2018exploring](#bib.bib70)
    ; [kolesnikov2019big](#bib.bib50) 。然而，与目标数据更紧密匹配的精心策划的源数据比在更大、更通用的源数据集上进行预训练可能表现更好[ngiam2018domain](#bib.bib87)
    ; [mahajan2018exploring](#bib.bib70) 。
- en: Early work in [huh2016makes](#bib.bib42) showed that additional pretraining
    data is useful only if it is well correlated to the target task. In some cases
    adding additional unrelated training data can actually hinder performance.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 早期研究在[huh2016makes](#bib.bib42)中表明，额外的预训练数据仅在与目标任务高度相关时才有用。在某些情况下，添加额外的不相关训练数据实际上可能会降低性能。
- en: In more recent work a ResNeXt-101 32×16d was pretrained on various large Instagram
    source datasets. When using ImageNet 1K as the target dataset, the model was found
    to have the same performance when pretrained on a source dataset of 960M images
    with hashtags that most closely matched the ImageNet 1K classes as when the model
    that was pretrained with 3.5B images with 17K different hashtags [mahajan2018exploring](#bib.bib70)
    . However, pretraining with the smaller source dataset produced significantly
    worse performance when the target dataset was ImageNet 5K or 9K, or the more task
    specific Caltech Birds [wah2011caltech](#bib.bib134) and Places365 [zhou2017places](#bib.bib155)
    .
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在较近期的工作中，一种ResNeXt-101 32×16d在各种大型Instagram源数据集上进行了预训练。当使用ImageNet 1K作为目标数据集时，模型在预训练源数据集（其中包含与ImageNet
    1K类别最为匹配的960M张图像和标签）上的性能与使用3.5B张图像和17K不同标签进行预训练的模型相同[mahajan2018exploring](#bib.bib70)。然而，当目标数据集为ImageNet
    5K或9K，或者是任务更为特定的Caltech Birds [wah2011caltech](#bib.bib134)和Places365 [zhou2017places](#bib.bib155)时，使用较小源数据集的预训练表现显著更差。
- en: A similar result was found in [ngiam2018domain](#bib.bib87) . Pretraining using
    data from subgroups of classes that closely matched the target classes, consistently
    achieved better performance than using the entire JFT dataset with 300 million
    images and 18,291 classes. Similar performance was achieved using their technique
    of reweighting classes during source pretraining so that the class distribution
    statistics more closely matched the target class distribution. Interestingly though,
    applying the same technique to pretraining with the much smaller ImageNet 1K dataset
    resulted in minimal performance gains in most cases and a significant decrease
    in performance for one target dataset. This suggests a minimum threshold for the
    number of training examples where better matched training data is better than
    more training data. In contradiction to [mahajan2018exploring](#bib.bib70) these
    results showed that pretraining with the entire JFT dataset resulted in worse
    performance than pretraining with just ImageNet 1K for most target classes. In
    some cases performance was worse with pretraining on the entire JFT dataset rather
    than initialising with random weights without pretraining. This may be an indication
    of issues with the suitability of the JFT dataset, where image labels are non-mutually
    exclusive and on average, each image has 1.26 labels, as a source task for a mutually
    exclusive target classification task.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在[ngiam2018domain](#bib.bib87)中发现了类似的结果。使用与目标类别紧密匹配的类别子组数据进行预训练，一贯地取得了比使用包含3亿张图像和18,291个类别的整个JFT数据集更好的性能。使用他们的重新加权类别技术进行源预训练时，也达到了类似的性能，这样类别分布统计与目标类别分布更为匹配。有趣的是，将相同技术应用于预训练较小的ImageNet
    1K数据集时，大多数情况下性能提升甚微，对一个目标数据集的性能甚至显著下降。这表明存在一个训练样本数量的最小阈值，在此阈值下，更好匹配的训练数据优于更多的训练数据。与[mahajan2018exploring](#bib.bib70)的结果相反，这些结果显示，对于大多数目标类别，使用整个JFT数据集进行预训练的表现不如仅使用ImageNet
    1K进行预训练。在某些情况下，使用整个JFT数据集进行预训练的性能甚至不如用随机权重初始化而不进行预训练。这可能表明JFT数据集的适用性存在问题，该数据集中的图像标签是非互斥的，平均每张图像有1.26个标签，这可能不适合作为具有互斥目标分类任务的源任务。
- en: 'With a similar set up to [ngiam2018domain](#bib.bib87) , Puigcerver et al.
    [puigcerver2020scalable](#bib.bib97) produced a large number of different “expert”
    models by starting from one model pretrained on all of JFT then fine-tuning copies
    of this model on different subclasses. Performance proxies such as K nearest neighbours
    were then used to select the relevant expert for each target task. They found
    that selecting the best expert pretrained on the whole of JFT then fine-tuned
    on just a subset of classes resulted in better performance than just pretraining
    on the whole of JFT. These results are consistent with those from [ng2015deep](#bib.bib86)
    outlined in Section [5.7.2](#S5.SS7.SSS2 "5.7.2 Facial expression recognition
    ‣ 5.7 Smaller target datasets with less similar tasks ‣ 5 Deep transfer learning
    progress and areas for improvement ‣ Deep transfer learning for image classification:
    a survey") in showing that a multi-stage fine tuning pipeline with an intermediate
    dataset that is more closely matched to the target dataset can produce better
    performance than transferring straight from a larger, less related source dataset.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 与 [ngiam2018domain](#bib.bib87) 相似的设置，Puigcerver 等人 [puigcerver2020scalable](#bib.bib97)
    通过从一个预训练在全部 JFT 的模型开始，然后在不同子类上微调该模型的副本，产生了大量不同的“专家”模型。然后使用 K 最近邻等性能代理来选择每个目标任务的相关专家。他们发现，从预训练在整个
    JFT 的最佳专家开始，再在仅子集类别上进行微调的结果，比仅在整个 JFT 上进行预训练的表现更好。这些结果与 [ng2015deep](#bib.bib86)
    的结果一致，显示出一个中间数据集更接近目标数据集的多阶段微调流程可以比直接从较大且不相关的源数据集转移得到更好的性能。
- en: Sun et al. [sun2017revisiting](#bib.bib125) found that pretraining a ResNet
    101 [he2016deep](#bib.bib36) with the 300 million images from the full JFT dataset
    resulted in significantly better performance on ImageNet 1K classification compared
    to random initialisation. When the target task was object detection on the COCO-2017
    dataset [lin2014microsoft](#bib.bib66) pretraining with the full JFT dataset or
    JFT plus ImageNet 1K produced a much larger increase in performance than pretraining
    with only ImageNet 1K as the source dataset. Both sets of results seem to indicate
    that the large ResNet 101 model generally overfits to the ImageNet 1K classification
    task when trained from random initialization, despite the dataset having over
    1 million labelled training examples. They found that larger ResNet models produced
    greater performance gains than smaller models on the COCO object detection task
    with ResNet 152 outperforming both ResNet 101 and 50\. Given that the difference
    between the mAP@[0.5,0.95] of the ResNet 101 and 152 was not significant when
    they were both pretrained on ImageNet 1K, but was when they were pretrained on
    the 300 times large JFT dataset it again indicates that larger models may overfit
    to ImageNet 1K.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: Sun 等人 [sun2017revisiting](#bib.bib125) 发现，用来自完整 JFT 数据集的 3 亿张图片对 ResNet 101
    [he2016deep](#bib.bib36) 进行预训练，在 ImageNet 1K 分类上的表现明显优于随机初始化。当目标任务是 COCO-2017
    数据集上的物体检测时，[lin2014microsoft](#bib.bib66) 使用完整 JFT 数据集或 JFT 加 ImageNet 1K 进行预训练，性能提升比仅用
    ImageNet 1K 作为源数据集要大得多。这些结果表明，大型 ResNet 101 模型在从随机初始化训练时通常会对 ImageNet 1K 分类任务过拟合，尽管数据集有超过
    100 万个标记的训练样本。他们发现，较大的 ResNet 模型在 COCO 物体检测任务上比小型模型表现更好，ResNet 152 的表现优于 ResNet
    101 和 50。考虑到 ResNet 101 和 152 在 ImageNet 1K 上预训练时 mAP@[0.5,0.95] 的差异不显著，但在 300
    倍大的 JFT 数据集上预训练时有显著差异，这再次表明较大的模型可能会对 ImageNet 1K 过拟合。
- en: 'Yalniz et al. [yalniz2019billion](#bib.bib147) created a multi-step semi-supervised
    training procedure that consisted of:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: Yalniz 等人 [yalniz2019billion](#bib.bib147) 创建了一个多步骤半监督训练程序，包括：
- en: '1.'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: training a model on ImageNet 1K
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 ImageNet 1K 上训练模型
- en: '2.'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: using that model to label a much larger dataset of up to one billion social
    media images with hashtags related to the ImageNet 1K classes.
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用该模型为高达 10 亿张社交媒体图片打标签，这些图片的标签与 ImageNet 1K 类别相关。
- en: '3.'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: using these weak self-labelled examples to train a new model
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用这些弱自标记的示例来训练新模型
- en: '4.'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: finally, fine-tuning the new model with the ImageNet 1K training set.
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最终，用 ImageNet 1K 训练集对新模型进行微调。
- en: They showed a significant increase in ImageNet 1K performance across a range
    of smaller ResNet architectures.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 他们展示了在一系列较小的 ResNet 架构上，ImageNet 1K 性能的显著提升。
- en: Xie et al. [xie2020self](#bib.bib146) extended the training procedure outlined
    above [yalniz2019billion](#bib.bib147) to iterate between training a large EfficientNet
    [tan2019efficientnet](#bib.bib128) model on ImageNet 1K, then using that model
    to label the 300 million images from the full JFT dataset and training the model
    using both the weak self-labelled images from JFT and real labelled images from
    ImageNet 1K. This resulted in state of the art performance on ImageNet 1K. They
    also found that testing this model on more difficult ImageNet test sets being
    ImageNet-A (particularly difficult ImageNet 1K test examples) [hendrycks2019benchmarking](#bib.bib38)
    , as well as ImageNet-C and ImageNet-P (test images with corruptions and perturbations
    such as blurring, fogging, rotation and scaling) [hendrycks2021natural](#bib.bib39)
    resulted in large increases in state of the art performance. State of the art
    accuracy was doubled on two out of the three more difficult ImageNet test sets.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: Xie 等人 [xie2020self](#bib.bib146) 扩展了上述训练程序 [yalniz2019billion](#bib.bib147)，在ImageNet
    1K上训练一个大型EfficientNet [tan2019efficientnet](#bib.bib128) 模型，然后使用该模型标记来自完整JFT数据集的3亿张图像，并使用来自JFT的弱自标记图像和来自ImageNet
    1K的真实标记图像来训练模型。这在ImageNet 1K上实现了最先进的性能。他们还发现，将此模型测试于更困难的ImageNet测试集，例如ImageNet-A（特别困难的ImageNet
    1K测试样本）[hendrycks2019benchmarking](#bib.bib38)，以及ImageNet-C和ImageNet-P（含有模糊、雾化、旋转和缩放等干扰和扰动的测试图像）[hendrycks2021natural](#bib.bib39)
    也显著提高了最先进的性能。在三个更困难的ImageNet测试集中的两个测试集上，最先进的准确率翻了一番。
- en: 5.3.2 Similarity measures for matching source and target datasets
  id: totrans-330
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.2 匹配源数据集和目标数据集的相似性度量
- en: 'In light of the findings in the previous section the question of how to measure
    similarity between source and target datasets is important. In some cases source
    and target domain similarity can be effectively estimated through human intuition
    and/or similarity between class labels [mahajan2018exploring](#bib.bib70) ; [ngiam2018domain](#bib.bib87)
    ; [puigcerver2020scalable](#bib.bib97) . Further to this there are many methods
    for using calculations of domain similarity in the hopes of finding the best source
    data for pretraining:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于前一节的发现，如何测量源数据集和目标数据集之间的相似性是一个重要问题。在某些情况下，源和目标域的相似性可以通过人类直觉和/或类别标签之间的相似性 [mahajan2018exploring](#bib.bib70)
    ; [ngiam2018domain](#bib.bib87) ; [puigcerver2020scalable](#bib.bib97) 有效估计。此外，还有许多方法通过计算域相似性来寻找最佳源数据进行预训练：
- en: •
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Cui et al. [cui2018large](#bib.bib16) showed that performance on the target
    dataset increases as a measure of similarity based on the earth mover distance
    between the source and target domains increases.
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Cui 等人 [cui2018large](#bib.bib16) 表明，目标数据集的性能随着源域和目标域之间的地球移动者距离的相似性度量的增加而提高。
- en: •
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Domain adaptive transfer learning (DATL) [ngiam2018domain](#bib.bib87) uses
    importance weights based on the ratio $P_{t}(y)/P_{s}(y)$ to reweight classes
    during source pretraining so that the class distribution statistics match the
    target statistic $P_{t}(y)$. Where $P_{t}(y)$ and $P_{s}(y)$ describe the distribution
    of labels in the target and source datasets respectively. They show that using
    adaptive transfer or a subset of the source dataset that more closely matches
    the target dataset improves performance over using the entire unweighted 300 million
    JFT training examples.
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 域自适应迁移学习（DATL）[ngiam2018domain](#bib.bib87) 使用基于比率 $P_{t}(y)/P_{s}(y)$ 的重要性权重来重新加权类别，从而在源预训练期间使类别分布统计匹配目标统计
    $P_{t}(y)$。其中 $P_{t}(y)$ 和 $P_{s}(y)$ 描述了目标数据集和源数据集中标签的分布。他们表明，使用自适应迁移或与目标数据集更为匹配的源数据集子集能提高性能，相较于使用整个未加权的3亿JFT训练样本。
- en: •
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Puigcerver et al. [puigcerver2020scalable](#bib.bib97) train a large selection
    of expert models on particular subsets of JFT source data based on class labels.
    They then determine the best model to use for each prediction based on performance
    proxies such as k nearest neighbours. This technique was shown to increase performance
    on several target datasets compared to training on the whole JFT dataset.
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Puigcerver 等人 [puigcerver2020scalable](#bib.bib97) 在特定的JFT源数据子集上训练了一大批专家模型，基于类别标签。然后，他们根据如k近邻等性能代理来确定每次预测的最佳模型。该技术在多个目标数据集上的表现优于在整个JFT数据集上进行训练。
- en: •
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Using reinforcement learning to learn a weight for each class in the source
    dataset so as to rely more heavily on more effective training examples during
    pretraining [zhu2019learning](#bib.bib156) . Also using reinforcement learning
    to value individual training samples for a particular task and rely more heavily
    on more valuable examples during training [yoon2020data](#bib.bib148) .
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用强化学习为源数据集中的每个类别学习权重，以便在预训练期间更加依赖更有效的训练样本，[zhu2019learning](#bib.bib156) 也使用强化学习来评估特定任务中的单个训练样本，并在训练过程中更加依赖更有价值的样本，[yoon2020data](#bib.bib148)。
- en: •
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Ge et al [ge2017borrowing](#bib.bib24) create histograms for images from the
    source and target domain using the activation maps from the first two layers of
    filters in a CNN. They then use nearest neighbour ranking to find the most similar
    images in the source dataset to those in the target dataset. Samples in the source
    domain are then weighted based on their KL-divergence from a given target sample.
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Ge 等人 [ge2017borrowing](#bib.bib24) 使用 CNN 中前两层滤波器的激活图为源域和目标域的图像创建直方图。然后，他们使用最近邻排序找到与目标数据集中图像最相似的源数据集图像。源域中的样本根据其与给定目标样本的
    KL 散度进行加权。
- en: 5.4 Large target datasets with less similar tasks
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 大规模目标数据集与较少相似任务
- en: There are very few large image datasets that are not closely related to the
    image classification tasks that are usually used for pretraining. The Places365
    with 1.8 million training images was used as a source task in [mahajan2018exploring](#bib.bib70)
    . It was shown that with less related source and target datasets the bigger and
    more diverse the source training dataset the better the results on the target
    dataset.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎没有与通常用于预训练的图像分类任务密切相关的大规模图像数据集。Places365 数据集包含180万张训练图像，在[mahajan2018exploring](#bib.bib70)中被用作源任务。研究表明，当源数据集和目标数据集相关性较低时，源训练数据集越大、越多样化，目标数据集的结果就越好。
- en: 'The largest object detection dataset is COCO [lin2014microsoft](#bib.bib66)
    with 135,000 training images across 80 classes. There have been mixed results
    shown in whether pretraining with ImageNet 1K and other common source datasets
    improve object detection performance on the COCO dataset. These results are discussed
    in detail in Section [5.7.5](#S5.SS7.SSS5 "5.7.5 Pretraining with image classification
    datasets for object detection tasks ‣ 5.7 Smaller target datasets with less similar
    tasks ‣ 5 Deep transfer learning progress and areas for improvement ‣ Deep transfer
    learning for image classification: a survey").'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 最大的物体检测数据集是 COCO [lin2014microsoft](#bib.bib66)，包含135,000张图像，涉及80个类别。关于使用 ImageNet
    1K 和其他常见源数据集进行预训练是否提高 COCO 数据集上的物体检测性能的结果存在不一致。这些结果在第[5.7.5](#S5.SS7.SSS5 "5.7.5
    使用图像分类数据集进行物体检测任务的预训练 ‣ 5.7 大规模目标数据集与较少相似任务 ‣ 5 深度迁移学习的进展与改进领域 ‣ 图像分类的深度迁移学习：综述")节中详细讨论。
- en: 5.5 Smaller target datasets
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 较小的目标数据集
- en: 'It is often not possible to train deep neural networks on small datasets from
    random initialization [mazurowski2019deep](#bib.bib74) ; [mormont2018comparison](#bib.bib80)
    ; [kraus2017automated](#bib.bib54) ; [heker2020joint](#bib.bib37) . This means
    that transfer learning becomes more heavily relied on as the size of the target
    dataset decreases. It has also been shown that transfer learning hyperparameters
    have a much great impact on performance as the size of the target dataset reduces
    [plested2019analysis](#bib.bib95) . As the size of the target dataset decreases
    two competing factors affect transfer learning performance:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 通常无法在随机初始化的小数据集上训练深度神经网络，[mazurowski2019deep](#bib.bib74) ; [mormont2018comparison](#bib.bib80)
    ; [kraus2017automated](#bib.bib54) ; [heker2020joint](#bib.bib37)。这意味着随着目标数据集大小的减少，对迁移学习的依赖性会增加。研究还表明，迁移学习的超参数对性能的影响在目标数据集减小时更为显著，[plested2019analysis](#bib.bib95)。随着目标数据集大小的减少，有两个相互竞争的因素影响迁移学习的性能：
- en: '1.'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'The empirical risk estimate becomes less reliable, as detailed in Section [3.2.2](#S3.SS2.SSS2
    "3.2.2 Unreliable Empirical Risk Minimizer ‣ 3.2 Learning from small vs large
    datasets ‣ 3 Overview ‣ Deep transfer learning for image classification: a survey"),
    making overfitting idiosyncrasies in the target dataset more likely.'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 经验风险估计变得不那么可靠，如第[3.2.2](#S3.SS2.SSS2 "3.2.2 不可靠的经验风险最小化器 ‣ 3.2 从小数据集与大数据集学习
    ‣ 3 概述 ‣ 图像分类的深度迁移学习：综述")节中详细描述的，这使得目标数据集中出现过拟合特性的可能性更大。
- en: '2.'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: The pretrained weights implicitly regularize the fine-tuned model and the final
    weights do not move far from their pretrained values [neyshabur2020being](#bib.bib85)
    ; [liu2019towards](#bib.bib67) ; [raghu2019transfusion](#bib.bib100)
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预训练权重隐式地对微调模型进行正则化，最终权重不会远离其预训练值 [neyshabur2020being](#bib.bib85) ; [liu2019towards](#bib.bib67)
    ; [raghu2019transfusion](#bib.bib100)。
- en: The outcome of Point 1 is an increasing need to use transfer learning and other
    methods to reduce overfitting. The implicit regularization noted in Point 2 can
    have a positive impact in reducing overfitting the empirical risk estimate as
    per Point 1\. It can also have a negative impact (negative transfer) if the weights
    transferred from the source dataset are far from optimal for the target dataset.
    When the weights, and thus the features produced, are restricted to being far
    from optimal the negative effect on performance can be compounded by Point 1 [plested2019analysis](#bib.bib95)
    .
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 第一点的结果是需要越来越多地使用迁移学习和其他方法来减少过拟合。第二点中提到的隐式正则化可以对减少第1点中的经验风险估计的过拟合产生积极影响。如果从源数据集转移的权重对目标数据集来说距离最优值较远，它也可能产生负面影响（负迁移）。当权重及其产生的特征被限制在远离最优时，性能的负面影响可能会因为第1点而加剧
    [plested2019analysis](#bib.bib95)。
- en: 5.6 Smaller target datasets with similar tasks
  id: totrans-352
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6 较小的目标数据集和类似任务。
- en: The most well known study on transfer learning [yosinski2014transferable](#bib.bib149)
    was performed with an AlexNet [krizhevsky2012imagenet](#bib.bib58) on strongly
    related and very large source and target datasets. The same experiment was repeated
    in [plested2019analysis](#bib.bib95) , but included a range of smaller target
    dataset sizes. They demonstrated a significant improvement in performance using
    more optimal transfer learning hyperparameters compared to common hyperparameters
    from [yosinski2014transferable](#bib.bib149) . This improvement increased considerably
    as the size of the dataset decreased. By using optimal compared to commonly used
    hyperparameters the average accuracy was found to increase from 20.86 to 30.12%
    for the smallest target dataset of just 10 examples for each of the 500 classes.
    The commonly used practice of transferring all layers except the final classification
    layer was shown not to be optimal in any of the experiments.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名的迁移学习研究 [yosinski2014transferable](#bib.bib149) 是在强相关和非常大的源和目标数据集上使用AlexNet
    [krizhevsky2012imagenet](#bib.bib58) 进行的。相同的实验在 [plested2019analysis](#bib.bib95)
    中重复进行了，但包括了不同规模的小目标数据集。他们展示了使用更优迁移学习超参数相比于 [yosinski2014transferable](#bib.bib149)
    的常见超参数在性能上的显著改善。随着数据集规模的减少，这种改善显著增加。通过使用相对于常用超参数的最优超参数，发现平均准确率从仅10个示例的500类中最小目标数据集的20.86%提高到30.12%。在任何实验中，转移所有层（除了最后的分类层）的常用做法被证明都不是最优的。
- en: When pretraining CNN models on ImageNet 1K [imagenet_cvpr09](#bib.bib18) and
    transferring to significantly smaller target datasets the improvement of deep
    transfer learning over random initialization correlates positively with how closely
    the target dataset relates to the source dataset. The improvement correlates negatively
    with the size of the target dataset. Both correlations are seen strongly in [kornblith2019better](#bib.bib52)
    , The positive correlation of performance improvement using transfer learning
    with the similarity between source and target datasets is most obvious. The authors
    state that on Stanford Cars and FGVC Aircraft, the improvement was unexpectedly
    small. The improvement over equivalent models trained from scratch is marginal
    for these two datasets, at 0.6% and 0.2%. Stanford Cars and FGVC Aircraft both
    contain fine-grained makes and models of cars and aircraft respectively, whereas
    ImageNet 1K contains no makes and models, just a few coarse categories for each.
    This means that the similarity between the source and target datasets for these
    two tasks is much lower than for example the more general CIFAR-10/100 or Oxford-IIIT
    Pets for which there are actually slightly more fine-grained classes in the source
    than the target dataset.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ImageNet 1K [imagenet_cvpr09](#bib.bib18) 上预训练 CNN 模型并转移到显著较小的目标数据集时，深度迁移学习相比于随机初始化的改进与目标数据集与源数据集的关系越紧密正相关。改进与目标数据集的大小负相关。这两种相关性在
    [kornblith2019better](#bib.bib52) 中都被强烈观察到。使用迁移学习的性能提升与源数据集和目标数据集的相似性之间的正相关性最为明显。作者指出，在斯坦福汽车和
    FGVC 飞机数据集上，改进意外地很小。与从头训练的等效模型相比，这两个数据集的改进仅为 0.6% 和 0.2%。斯坦福汽车和 FGVC 飞机数据集分别包含了细粒度的汽车和飞机品牌及型号，而
    ImageNet 1K 不包含品牌和型号，仅有一些粗略的类别。这意味着这两个任务中源数据集和目标数据集之间的相似性远低于例如更通用的 CIFAR-10/100
    或牛津-印度理工学院宠物数据集，其中源数据集中的细粒度类别比目标数据集多。
- en: The improvement in using fine-tuning over fixed pretrained features for Stanford
    Cars and FGVC Aircraft is significantly larger, at 25.4% and 25.7%, than for any
    of the 10 other datasets used in the experiments. This indicates that the pretrained
    features are not well suited to the task. For comparison, at the other end of
    the similarity scale, Oxford-IIIT Pets shows one of the largest improvements from
    83.2% accuracy for training from random initialisation to 94.5% accuracy for fine
    tuning a pretrained model. For this dataset the increase in performance using
    fine-tuning compared to fixed pretrained weights is marginal at 1.1%. This shows
    that the pretrained features are well suited to the task without fine-tuning.
    This difference in performance is likely compounded by the fact that Oxford-IIIT
    Pets is around half the size of both Stanford Cars and FGVC Aircraft. More recent
    work has shown that the difference between performance on the target task using
    fixed pretrained weights versus fine-tuning with even very poor hyperparameters
    can be used to predict transfer learning hyperparameters for a given source and
    target task and model [plested2021non](#bib.bib96) .
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在斯坦福汽车和 FGVC 飞机任务中，使用微调（fine-tuning）相比于固定的预训练特征的改进显著更大，分别为 25.4% 和 25.7%，相比于实验中使用的其他
    10 个数据集。这表明预训练特征不适合该任务。作为对比，在相似性尺度的另一端，牛津-印度理工学院宠物数据集（Oxford-IIIT Pets）显示了从随机初始化训练
    83.2% 的准确率到微调预训练模型后的 94.5% 准确率的最大改进之一。在这个数据集中，使用微调相比于固定的预训练权重的性能提升为 1.1%。这表明预训练特征在没有微调的情况下已经很好地适应了任务。这种性能差异很可能由于牛津-印度理工学院宠物数据集的规模大约是斯坦福汽车和
    FGVC 飞机数据集的一半。最近的工作显示，使用固定预训练权重与微调即使使用非常差的超参数在目标任务上的性能差异可以用来预测给定源任务和目标任务及模型的迁移学习超参数
    [plested2021non](#bib.bib96)。
- en: 'The negative correlation between the size of the target dataset and the improvement
    over the baselines in [kornblith2019better](#bib.bib52) can be seen clearly when
    the increase in performance is compared to the target training set size as presented
    in Table [2](#S5.T2 "Table 2 ‣ 5.6 Smaller target datasets with similar tasks
    ‣ 5 Deep transfer learning progress and areas for improvement ‣ Deep transfer
    learning for image classification: a survey"). Another obvious correlation is
    that target datasets with lower baseline accuracy figures increase by a larger
    amount as there is more room for improvement. If we remove all the datasets where
    the baseline performance was above 88% which would likely limit the performance
    increase, the increases are close to reverse order based on the size of the target
    dataset. This highlights the negative correlation between target dataset size
    and transfer learning performance. The only discrepancies in the ordering come
    from general and scene tasks getting larger performance increases than fine-grained
    and texture tasks Tables [3](#S5.T3 "Table 3 ‣ 5.6 Smaller target datasets with
    similar tasks ‣ 5 Deep transfer learning progress and areas for improvement ‣
    Deep transfer learning for image classification: a survey") and [4](#S5.T4 "Table
    4 ‣ 5.6 Smaller target datasets with similar tasks ‣ 5 Deep transfer learning
    progress and areas for improvement ‣ Deep transfer learning for image classification:
    a survey"). We would expect the former to be more closely related to the ImageNet
    1K source dataset than the latter.'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '在 [kornblith2019better](#bib.bib52) 中，目标数据集大小与基线性能改进之间的负相关关系在表 [2](#S5.T2 "Table
    2 ‣ 5.6 Smaller target datasets with similar tasks ‣ 5 Deep transfer learning
    progress and areas for improvement ‣ Deep transfer learning for image classification:
    a survey") 中的性能提升与目标训练集大小的比较中明显可见。另一个明显的相关性是，基线准确度较低的目标数据集的性能提升幅度较大，因为改进空间更大。如果我们移除基线性能超过
    88% 的所有数据集，这些数据集的性能提升大致会按目标数据集的大小倒序排列。这突显了目标数据集大小与迁移学习性能之间的负相关关系。唯一的差异来自于一般任务和场景任务的性能提升大于细粒度和纹理任务，如表
    [3](#S5.T3 "Table 3 ‣ 5.6 Smaller target datasets with similar tasks ‣ 5 Deep
    transfer learning progress and areas for improvement ‣ Deep transfer learning
    for image classification: a survey") 和 [4](#S5.T4 "Table 4 ‣ 5.6 Smaller target
    datasets with similar tasks ‣ 5 Deep transfer learning progress and areas for
    improvement ‣ Deep transfer learning for image classification: a survey")。我们预计前者与
    ImageNet 1K 源数据集的关系会更紧密。'
- en: Both Flowers and Food-101 are interesting outliers when looking at the performance
    increase compared to the baseline performance, and the size of the target datasets.
    They are both fine-grained tasks, and ImageNet 1K has very few classes of each.
    A future research direction could involve looking at the reliance on colours in
    features for both ImageNet 1K pretrained models and models fine-tuned on these
    two target datasets as we would expect colour to be useful in classifying both.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在比较与基线性能的提高以及目标数据集的大小时，Flowers 和 Food-101 都是有趣的异常值。它们都是细粒度任务，而 ImageNet 1K 每个类别的样本非常少。未来的研究方向可以深入探讨
    ImageNet 1K 预训练模型以及在这两个目标数据集上微调的模型中对颜色特征的依赖，因为我们预计颜色在分类中会很有用。
- en: 'Table 2: Performance increase compared to target dataset size for experiment
    results from [kornblith2019better](#bib.bib52)'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：与目标数据集大小相比的性能提升，来自 [kornblith2019better](#bib.bib52) 的实验结果
- en: '| Dataset | Type | Size in 1,000s | Performance increase / baseline performance
    | Performance increase rank |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 类型 | 大小（千） | 性能提升 / 基线性能 | 性能提升排名 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Food-101 | fine-grained | 78 | 3 / 87 | 8 |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| Food-101 | 细粒度 | 78 | 3 / 87 | 8 |'
- en: '| CIFAR-10 | general | 50 | 1.98 / 96.06 | 10 |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR-10 | 一般 | 50 | 1.98 / 96.06 | 10 |'
- en: '| CIFAR-100 | general | 50 | 6.7 / 81 | 6 |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR-100 | 一般 | 50 | 6.7 / 81 | 6 |'
- en: '| Birdsnap | fine-grained | 47 | 2.5 / 75.9 | 9 |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| Birdsnap | 细粒度 | 47 | 2.5 / 75.9 | 9 |'
- en: '| SUN397 | scenes | 20 | 11.4 / 55 | 3 |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| SUN397 | 场景 | 20 | 11.4 / 55 | 3 |'
- en: '| Stanford Cars | fine-grained | 8 | 0.6 / 92.7 | 11 |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| Stanford Cars | 细粒度 | 8 | 0.6 / 92.7 | 11 |'
- en: '| FGVC Aircraft | fine-grained | 7 | 0.2 / 88.8 | 12 |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| FGVC Aircraft | 细粒度 | 7 | 0.2 / 88.8 | 12 |'
- en: '| PASCAL VOC 2007 | general | 5 | 16.5 / 70.9 | 2 |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| PASCAL VOC 2007 | 一般 | 5 | 16.5 / 70.9 | 2 |'
- en: '| Describable Textures | textures | 4 | 11.3 / 66.8 | 4 |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| 可描述的纹理 | 纹理 | 4 | 11.3 / 66.8 | 4 |'
- en: '| Oxford-IIIT Pets | fine-grained | 4 | 11.3 / 83.2 | 4 |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| Oxford-IIIT Pets | 细粒度 | 4 | 11.3 / 83.2 | 4 |'
- en: '| Caltech-101 | general | 3 | 17.9 / 77 | 1 |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| Caltech-101 | 一般 | 3 | 17.9 / 77 | 1 |'
- en: '| Oxford 102 Flowers | fine-grained | 2 | 4.55 / 93.9 | 7 |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| Oxford 102 Flowers | 细粒度 | 2 | 4.55 / 93.9 | 7 |'
- en: 'Table 3: Performance increase compared to target dataset size for general and
    scene target datasets. Experiment results from [kornblith2019better](#bib.bib52)'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：针对一般和场景目标数据集的目标数据集大小的性能提升。实验结果来自[kornblith2019better](#bib.bib52)
- en: '| Dataset | Type | Size in 1,000s | Performance increase / baseline performance
    | Performance increase rank |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 类型 | 大小（千） | 性能提升 / 基准性能 | 性能提升排名 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| CIFAR-100 | general | 50 | 6.7 / 81 | 4 |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR-100 | 一般 | 50 | 6.7 / 81 | 4 |'
- en: '| SUN397 | scenes | 20 | 11.4 / 55 | 3 |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| SUN397 | 场景 | 20 | 11.4 / 55 | 3 |'
- en: '| PASCAL VOC 2007 | general | 5 | 16.5 / 70.9 | 2 |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| PASCAL VOC 2007 | 一般 | 5 | 16.5 / 70.9 | 2 |'
- en: '| Caltech-101 | general | 3 | 17.9 / 77 | 1 |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| Caltech-101 | 一般 | 3 | 17.9 / 77 | 1 |'
- en: 'Table 4: Performance increase compared to target dataset size for fine-grained
    classification target datasets. Experiment results from [kornblith2019better](#bib.bib52)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：针对细粒度分类目标数据集的目标数据集大小的性能提升。实验结果来自[kornblith2019better](#bib.bib52)
- en: '| Dataset | Type | Size in 1,000s | Performance increase / baseline performance
    | Performance increase rank |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 类型 | 大小（千） | 性能提升 / 基准性能 | 性能提升排名 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Food-101 | fine-grained | 78 | 3 / 87 | 3 |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| Food-101 | 细粒度 | 78 | 3 / 87 | 3 |'
- en: '| Birdsnap | fine-grained | 47 | 2.5 / 75.9 | 4 |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| Birdsnap | 细粒度 | 47 | 2.5 / 75.9 | 4 |'
- en: '| Describable Textures | textures | 4 | 11.3 / 66.8 | 2 |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| 可描述的纹理 | 纹理 | 4 | 11.3 / 66.8 | 2 |'
- en: '| Oxford-IIIT Pets | fine-grained | 4 | 11.3 / 83.2 | 1 |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| Oxford-IIIT Pets | 细粒度 | 4 | 11.3 / 83.2 | 1 |'
- en: 5.6.1 More vs better matched pretraining data part 2
  id: totrans-387
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.6.1 更多与更好匹配的预训练数据 第二部分
- en: Similarly to large target tasks, better matched pretraining data has been shown
    to produce better performance on the target task than more pretraining data.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 与大型目标任务类似，匹配更好的预训练数据已被证明能在目标任务上产生比更多预训练数据更好的性能。
- en: Pretraining on the scene classification task Places365 achieved considerably
    better performance on the scene classification dataset MIT Indoor 67 as compared
    to pretraining with the smaller and less related ImageNet 1K in [li2018explicit](#bib.bib64)
    . However the reverse was true for the target tasks that were more related to
    ImageNet 1K, being Stanford Dogs and Caltech256-30 and 60.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 在场景分类任务Places365上进行预训练，相比于用较小且不相关的ImageNet 1K预训练，取得了在场景分类数据集MIT Indoor 67上显著更好的性能。然而，对与ImageNet
    1K更相关的目标任务（如Stanford Dogs和Caltech256-30和60），情况则相反。
- en: Source and target data classes were matched using the Earth Mover’s Distance
    [peleg1989unified](#bib.bib94) ; [rubner2000earth](#bib.bib109) in [cui2018large](#bib.bib16)
    . Pretraining with well matched subsets was shown to perform better than with
    the largest source dataset on a variety of fine-grained visual classification
    (FGVC) tasks. They also showed a strong correlation between source and target
    domain similarity as calculated by the Earth Mover’s Distance and performance
    on the target task for all but one target task.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 源数据和目标数据类通过地球移动者距离[peleg1989unified](#bib.bib94)；[rubner2000earth](#bib.bib109)在[cui2018large](#bib.bib16)中进行匹配。结果表明，使用匹配良好的子集进行预训练比使用最大源数据集在各种细粒度视觉分类（FGVC）任务中表现更好。他们还展示了地球移动者距离计算的源域与目标域相似性与目标任务性能之间的强相关性，除了一个目标任务外。
- en: 'Ge and Yu [ge2017borrowing](#bib.bib24) found model performance was improved
    by fine-tuning a model on the target task along with the most related data from
    the source task. Related data was calculated using nearest neighbour on the activations
    of Gabor filters. Sabatelli et al. [sabatelli2018deep](#bib.bib111) found that
    performance was improved when pretraining on a smaller art classification source
    dataset rather than the larger unrelated ImageNet 1K when the target task was
    art classification. In the same domain Gonthier et al. [gonthier2020analysis](#bib.bib28)
    used a two step fine-tuning process consisting of:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: Ge和Yu[ge2017borrowing](#bib.bib24)发现，通过在目标任务上微调模型并结合源任务中最相关的数据，可以提升模型性能。相关数据是通过在Gabor滤波器激活上使用最近邻计算得到的。Sabatelli等人[sabatelli2018deep](#bib.bib111)发现，当目标任务是艺术分类时，使用较小的艺术分类源数据集进行预训练，相比于较大且不相关的ImageNet
    1K，性能得到改善。在相同领域，Gonthier等人[gonthier2020analysis](#bib.bib28)使用了一个包含以下步骤的两步微调过程：
- en: '1.'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: pretraining on ImageNet 1K
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在ImageNet 1K上进行预训练
- en: '2.'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: fine tuning on an art classification dataset that was an order of magnitude
    larger than the target task
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对一个比目标任务大一个数量级的艺术分类数据集进行微调。
- en: '3.'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: fine-tuning on the final target art classification dataset.
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对最终目标艺术分类数据集进行微调。
- en: They found that this improved performance over pretraining on only ImageNet
    1K or only the intermediate art classification dataset.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 他们发现，这种方法比仅在ImageNet 1K或仅在中间艺术分类数据集上进行预训练的表现更好。
- en: 5.7 Smaller target datasets with less similar tasks
  id: totrans-399
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7 较小的目标数据集与任务相似性较低
- en: 'Transfer learning has been shown to be effective in many areas where the target
    datasets are small and less related to ImageNet 1K and other common source datasets.
    However, there have also been several recent results that fit into this category
    where deep transfer learning has shown little or no improvement over random initialization
    [zoph2020rethinking](#bib.bib159) ; [he2018rethinking](#bib.bib34) ; [raghu2019transfusion](#bib.bib100)
    . Transfer learning shows better performance on smaller target datasets that are
    more closely related to the source dataset than larger less related datasets in
    general see Section [5.6](#S5.SS6 "5.6 Smaller target datasets with similar tasks
    ‣ 5 Deep transfer learning progress and areas for improvement ‣ Deep transfer
    learning for image classification: a survey") and [kornblith2019better](#bib.bib52)
    . Task specific self-supervised learning methods applied to source datasets that
    are more closely related but unlabelled, often perform better than supervised
    learning methods applied to less closely related source datasets [zoph2020rethinking](#bib.bib159)
    ; [azizi2021big](#bib.bib3) . Recent work has shown that even when the target
    dataset is very dissimilar to the source dataset and transfer learning brings
    no performance gain it can accelerate the convergence speed [he2018rethinking](#bib.bib34)
    ; [raghu2019transfusion](#bib.bib100) .'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '转移学习在许多目标数据集较小且与ImageNet 1K及其他常见源数据集关联较少的领域已被证明有效。然而，也有一些最近的结果显示，在这一类别中，深度转移学习相对于随机初始化几乎没有改进
    [zoph2020rethinking](#bib.bib159)；[he2018rethinking](#bib.bib34)；[raghu2019transfusion](#bib.bib100)。与源数据集更紧密相关的小型目标数据集通常比与源数据集关联较少的大型目标数据集表现更好，见[5.6](#S5.SS6
    "5.6 Smaller target datasets with similar tasks ‣ 5 Deep transfer learning progress
    and areas for improvement ‣ Deep transfer learning for image classification: a
    survey")和[kornblith2019better](#bib.bib52)。应用于更紧密相关但未标记的源数据集的任务特定自监督学习方法，通常比应用于关联较少的源数据集的监督学习方法表现更好
    [zoph2020rethinking](#bib.bib159)；[azizi2021big](#bib.bib3)。最近的研究表明，即使目标数据集与源数据集非常不相似，且转移学习没有带来性能提升，它仍然可以加速收敛速度
    [he2018rethinking](#bib.bib34)；[raghu2019transfusion](#bib.bib100)。'
- en: 5.7.1 Face recognition
  id: totrans-401
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.7.1 人脸识别
- en: 'Face recognition often relies on pretraining of deep CNN architectures on general
    image classification datasets like ImageNet 1K. However this area of research
    presents its own unique challenges [masi2018deep](#bib.bib73) :'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸识别通常依赖于在类似ImageNet 1K的一般图像分类数据集上对深度CNN架构进行预训练。然而，这一研究领域也存在其独特的挑战 [masi2018deep](#bib.bib73)：
- en: '1.'
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: With each class representing only one individual there are often only slight
    differences between classes and a small number of training images per class.
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于每个类别仅代表一个个体，类别之间往往只有细微的差别，每个类别的训练图像数量也较少。
- en: '2.'
  id: totrans-405
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: There can be many more classes than is common for an image classification task
    with common face recognition datasets having 10’s or 100’s of thousands or even
    millions of different subjects.
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与图像分类任务相比，人脸识别数据集中的类别数量可以多得多，常见的人脸识别数据集可能有数十、数百甚至数百万个不同的个体。
- en: 'Related to Point 1, a common challenge for facial recognition models is to
    pretrain them on a large number of publicly available faces of celebrities then
    use them to quickly learn to classify new faces with limited examples via transfer
    learning techniques. Several additions to the typically used cross-entropy loss
    have been proposed to help with this challenge they:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 与第1点相关，人脸识别模型的一个常见挑战是：在大量公开可用的名人面孔上进行预训练，然后利用转移学习技术快速学习分类新面孔，即便样本有限。为应对这一挑战，已提出了几种对典型的交叉熵损失进行改进的方法：
- en: •
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: explicitly minimize the intraclass variance [wen2016discriminative](#bib.bib142)
    ,
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 明确最小化类内方差 [wen2016discriminative](#bib.bib142)，
- en: •
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: increase the margin between classes [liu2016large](#bib.bib69) ; [liu2017sphereface](#bib.bib68)
    ,
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 增加类别之间的间距 [liu2016large](#bib.bib69)；[liu2017sphereface](#bib.bib68)，
- en: •
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: encourage features to lie on a hypersphere [ranjan2017l2](#bib.bib101) ; [zheng2018ring](#bib.bib154)
    .
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 鼓励特征位于超球面上 [ranjan2017l2](#bib.bib101)；[zheng2018ring](#bib.bib154)。
- en: 'These methods are all designed to produce a well defined feature space during
    pretraining so that there is likely to be a good separation between subjects for
    both source and target subjects. When the number of subjects in face recognition
    datasets get very large, deep metric learning losses are generally used instead
    of classification losses [schroff2015facenet](#bib.bib113) ; [wang2018cosface](#bib.bib136)
    ; [deng2019arcface](#bib.bib19) . It has recently been shown that metrics designed
    specifically for face recognition such as CosFace [wang2018cosface](#bib.bib136)
    and ArcFace [deng2019arcface](#bib.bib19) can be more successful when applied
    to common deep metric learning benchmark datasets or small fine-grained image
    classification tasks [musgrave2020metric](#bib.bib82) . Deep metric learning is
    discussed further in Section [6.3](#S6.SS3 "6.3 K-shot or few shot learning ‣
    6 Areas related to deep transfer learning for image classification ‣ Deep transfer
    learning for image classification: a survey").'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '这些方法都旨在通过预训练生成一个定义明确的特征空间，以便源受试者和目标受试者之间可能会有良好的分离。当面部识别数据集中的受试者数量变得非常庞大时，通常使用深度度量学习损失而不是分类损失[schroff2015facenet](#bib.bib113)；[wang2018cosface](#bib.bib136)；[deng2019arcface](#bib.bib19)。最近的研究表明，专为面部识别设计的度量，如CosFace[wang2018cosface](#bib.bib136)和ArcFace[deng2019arcface](#bib.bib19)，在应用于常见的深度度量学习基准数据集或小规模细粒度图像分类任务时可能更为成功[musgrave2020metric](#bib.bib82)。深度度量学习在第[6.3](#S6.SS3
    "6.3 K-shot or few shot learning ‣ 6 Areas related to deep transfer learning for
    image classification ‣ Deep transfer learning for image classification: a survey")节中有进一步讨论。'
- en: 5.7.2 Facial expression recognition
  id: totrans-415
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.7.2 面部表情识别
- en: Like many fine-grained classification problems facial expression recognition
    (FER) datasets are often challenging because they are small. Most well known FER
    datasets have less than 10,000 images or videos. Even the larger ones often have
    only around 100 different subjects, making the individual images highly correlated.
    An additional challenge unique to facial expression recognition is that high intersubject
    (intraclass) variations exist due to different personal attributes, such as age,
    gender, ethnic backgrounds and level of expressiveness [li2020deep](#bib.bib62)
    .
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 像许多细粒度分类问题一样，面部表情识别（FER）数据集通常面临挑战，因为它们规模较小。大多数知名的FER数据集少于10,000张图像或视频。即使是较大的数据集，通常也只有约100个不同的受试者，这使得个体图像高度相关。面部表情识别的一个额外挑战是，由于不同的个人属性（如年龄、性别、种族背景和表达能力水平），存在较大的受试者间（类内）变化[li2020deep](#bib.bib62)。
- en: Again, for this task it has been shown that pretraining with source data more
    closely matched to the target dataset results in better performance. pretraining
    on a large facial recognition dataset has been shown to perform better than pretraining
    on the more general and less closely related ImageNet 1K [imagenet_cvpr09](#bib.bib18)
    . A multi-stage pretraining pipeline, using a larger FER dataset for interim fine-tuning
    prior to the final fine-tuning on the smaller target dataset, was shown to improve
    performance in [ng2015deep](#bib.bib86) .
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，对于此任务，已显示使用更接近目标数据集的源数据进行预训练会获得更好的性能。对大型面部识别数据集进行预训练已被证明比对更通用且关系较远的ImageNet
    1K进行预训练效果更佳[imagenet_cvpr09](#bib.bib18)。多阶段预训练管道，通过在较小的目标数据集上进行最终微调之前，使用较大的FER数据集进行中期微调，已被证明在[ng2015deep](#bib.bib86)中提高了性能。
- en: 5.7.3 Pretraining with general image classification datasets for medical imaging
    classification tasks
  id: totrans-418
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.7.3 使用通用图像分类数据集进行医学影像分类任务的预训练
- en: 'The two major problems presented when using deep neural networks for medical
    imaging tasks that are most relevant to this review are:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 使用深度神经网络进行医学影像任务时，两个主要问题与本综述最相关的是：
- en: '1.'
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Scarcity of data. Training data in medical image datasets often numbers in just
    the 100’s or 1,000’s of examples as opposed to the 100,000s, millions or even
    billions of examples often available in more general image datasets [mazurowski2019deep](#bib.bib74)
    .
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据稀缺。在医学图像数据集中，训练数据的数量通常只有几百或几千个样本，而不是在更通用的图像数据集中通常可用的十万、百万甚至十亿个样本[mazurowski2019deep](#bib.bib74)。
- en: '2.'
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Severely unbalanced classes. There are often many more examples of healthy images
    as opposed to those with a rare disease [mazurowski2019deep](#bib.bib74) .
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 类别严重不平衡。健康图像的样本通常比罕见疾病图像的样本多得多[mazurowski2019deep](#bib.bib74)。
- en: Training very deep networks from scratch is problematic in many medical imaging
    cases due to the problems listed above. Deep transfer learning is adopted in almost
    every modality of medical imaging, including X-rays, CT scans, pathological images,
    positron emission tomography (PET), and MRI [mazurowski2019deep](#bib.bib74) .
    Despite this there has been limited work addressing best practice for deep transfer
    learning in the medical imaging classification domain.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 由于上述问题，从头开始训练非常深的网络在许多医学成像案例中是有问题的。深度迁移学习已被几乎所有医学成像模态采用，包括 X 射线、CT 扫描、病理图像、正电子发射断层扫描（PET）和
    MRI。[mazurowski2019deep](#bib.bib74) 。尽管如此，针对医学成像分类领域中深度迁移学习的最佳实践的研究仍然有限。
- en: 'Early experiments [tajbakhsh2016convolutional](#bib.bib126) compared an AlexNet
    pretrained on ImageNet 1K with and without fine-tuning, an AlexNet trained from
    scratch, and traditional models with hand crafted features. They demonstrated
    that:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 早期实验[tajbakhsh2016convolutional](#bib.bib126) 比较了在 ImageNet 1K 上预训练的 AlexNet（带和不带细化调整）、从头开始训练的
    AlexNet 和使用手工特征的传统模型。他们证明了：
- en: '1.'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: The use of a pretrained AlexNet CNN with adequate fine-tuning consistently improved
    on or matched training from random initialisation and traditional methods.
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用经过适当细化调整的预训练 AlexNet CNN 一致地优于或匹配了随机初始化和传统方法的训练效果。
- en: '2.'
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: While the increase in performance using a pretrained and fine-tuned AlexNet
    was marginal for relatively larger target datasets the performance improvement
    was much more significant as the size of the target datasets was reduced.
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 尽管使用预训练和细化调整的 AlexNet 对于相对较大的目标数据集的性能提升是微小的，但随着目标数据集大小的减少，性能提升则显著增加。
- en: More recent experiments in deep transfer learning for digital pathology classification
    using a range of modern models with residual connections and four different target
    datasets were performed by Mormont et al. [mormont2018comparison](#bib.bib80)
    . The models were pretrained on ImageNet 1K. When using the pretrained models
    as fixed feature extractors the last layer features were always outperformed by
    features taken from an inner layer of the network. In keeping with previous results
    in the field they found that fine tuning improves on fixed extraction. However,
    they did not combine fine tuning with testing different layers in the network
    for optimal performance, which we suggest for future work.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Mormont 等人进行了关于数字病理分类的深度迁移学习实验，使用了带有残差连接的现代模型和四个不同的目标数据集。[mormont2018comparison](#bib.bib80)
    。这些模型是在 ImageNet 1K 上进行预训练的。当使用预训练模型作为固定特征提取器时，最后一层的特征总是被网络内部某一层的特征所超越。与该领域之前的结果一致，他们发现细化调整比固定提取效果更好。然而，他们没有将细化调整与测试网络中不同层以获得最佳性能结合起来，这一点我们建议未来的工作中加以考虑。
- en: 5.7.4 More vs better matched pretraining data in the medical image domain
  id: totrans-431
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.7.4 医学图像领域中更多 vs 更好匹配的预训练数据
- en: There have been a number of studies in the last two years examining whether
    a very large less related source dataset is better, for pretraining for image
    classification in the medical domain, when compared to a within domain dataset
    that is orders of magnitude smaller [raghu2019transfusion](#bib.bib100) ; [heker2020joint](#bib.bib37)
    . Both these scenarios have also been compared to self-supervised pretraining
    on a medium sized unlabelled within domain dataset [azizi2021big](#bib.bib3) .
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去两年中，有许多研究探讨了当与领域内数据集（其规模小几个数量级）相比时，一个非常大但关联较少的源数据集是否更适合用于医学领域的图像分类预训练。[raghu2019transfusion](#bib.bib100)
    ; [heker2020joint](#bib.bib37) 。这两种情境也与在中等规模的领域内无标签数据集上进行的自监督预训练进行了比较。[azizi2021big](#bib.bib3)
    。
- en: Previous results showing that pretraining with much larger source datasets increases
    performance on the target task were extended to the medical image domain in [mustafa2021supervised](#bib.bib83)
    . Performance on three well known small medical image classification target tasks
    was shown to improve as the size of the source dataset increased from ImageNet
    1K with 1.3 million training examples to JFT with 300 million training examples.
    All pretraining produced better performance than random initialization. There
    has also been some work showing that performing supervised pretraining on a moderately
    sized medical image dataset and transferring to a smaller one can increase performance
    compared to training from random initialisation [kraus2017automated](#bib.bib54)
    ; [heker2020joint](#bib.bib37) , other shallow machine learning methods [kraus2017automated](#bib.bib54)
    , and even pretraining with ImageNet 1K [heker2020joint](#bib.bib37) .
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 以前的研究结果表明，使用更大规模的源数据集进行预训练会提高目标任务的性能，这一结果在[mustafa2021supervised](#bib.bib83)中被扩展到了医学图像领域。研究表明，当源数据集的规模从含有130万训练样本的ImageNet
    1K增加到含有3亿训练样本的JFT时，三个著名的小型医学图像分类目标任务的性能有所提升。所有预训练的结果都优于随机初始化。还有一些研究表明，在适中规模的医学图像数据集上进行监督式预训练，并转移到一个较小的数据集上，可以提高性能，相较于从随机初始化开始训练[
    Kraus2017automated](#bib.bib54)； [heker2020joint](#bib.bib37) ，以及其他浅层机器学习方法[Kraus2017automated](#bib.bib54)和甚至ImageNet
    1K的预训练[heker2020joint](#bib.bib37)。
- en: Raghu et al. [raghu2019transfusion](#bib.bib100) showed that when medical image
    datasets are large (around two hundred thousand training examples), pretraining
    on ImageNet 1K results in limited improvements over random initialisation. This
    applies to both the large CNN models large ResNet50 and Inception v3 and small
    CNN models designed for better performance on medical datasets. When the number
    of training examples was reduced to a small dataset size of 5,000, pretraining
    with ImageNet 1K resulted in small improvements over random initialisation. They
    also reaffirm that lower layers are more transferable than higher more task specific
    layers as per [yosinski2014transferable](#bib.bib149) , even when the source and
    target tasks are very different.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: Raghu等人[raghu2019transfusion](#bib.bib100)表明，当医学图像数据集较大（约二十万个训练样本）时，使用ImageNet
    1K进行预训练仅能在性能上带来有限的提升。 这适用于大型CNN模型，如大型ResNet50和Inception v3，以及为医学数据集优化的小型CNN模型。当训练样本数量减少到5000的小型数据集时，使用ImageNet
    1K进行预训练相较于随机初始化只带来小幅提升。他们还重申，较低层次的特征比较高层次更具迁移性，即使源任务和目标任务非常不同，[yosinski2014transferable](#bib.bib149)。
- en: 'A two step self-supervised pretraining process was used on two different medical
    imaging classification target tasks in [azizi2021big](#bib.bib3) . This involved:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 在[azizi2021big](#bib.bib3)中，使用了两步自监督预训练过程来处理两种不同的医学影像分类目标任务。 这一过程包括：
- en: '1.'
  id: totrans-436
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: self-supervised pretraining on ImageNet 1K
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在ImageNet 1K上的自监督预训练
- en: '2.'
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: followed by self-supervised fine-tuning on a large unlabelled medical dataset
    from same source as the target task
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随后在与目标任务相同来源的大型未标记医学数据集上进行自监督微调
- en: '3.'
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: then fine-tuning on the final labelled medical image classification task.
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随后在最终的标记医学图像分类任务上进行微调。
- en: This was found to produce significantly better results on the target task compared
    to self-supervised pretraining on only ImageNet and slightly better results than
    pretraining on the unlabelled medical dataset only or pretraining on ImageNet
    1K with supervised methods.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 研究发现，这种方法在目标任务上的结果显著优于仅在ImageNet上进行自监督预训练，并且相比仅在未标记医学数据集上预训练或使用监督方法在ImageNet
    1K上预训练，结果略有改善。
- en: Using a multi-stage supervised pretraining pipeline such as in [ng2015deep](#bib.bib86)
    does not appear to have been applied to classifying medical images with deep CNNs.
    This could be a useful area of further research.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 使用类似于[ng2015deep](#bib.bib86)中的多阶段监督预训练流程似乎尚未应用于深度CNN对医学图像的分类。这可能是一个有用的进一步研究领域。
- en: 5.7.5 Pretraining with image classification datasets for object detection tasks
  id: totrans-444
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.7.5 使用图像分类数据集进行预训练以用于目标检测任务
- en: Although it is somewhat beyond the scope of this paper, we briefly review the
    evidence on whether pretraining on image classification datasets is beneficial
    for object detection tasks.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这有些超出本文的范围，但我们简要回顾一下在图像分类数据集上进行预训练是否对目标检测任务有益的证据。
- en: Starting with [girshick2014rich](#bib.bib26) many studies have shown improved
    performance on object detection tasks when ImageNet pretraining is used [ren2015faster](#bib.bib105)
    ; [redmon2016you](#bib.bib104) . It has become the conventional wisdom that pretraining
    is needed to achieve top results on object detection tasks as the datasets tend
    to be smaller than image classification datasets like ImageNet [imagenet_cvpr09](#bib.bib18)
    . However, a number of recent results have challenged this idea.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 从 [girshick2014rich](#bib.bib26) 开始，许多研究表明，当使用 ImageNet 预训练时，目标检测任务的性能有所提升 [ren2015faster](#bib.bib105)；[redmon2016you](#bib.bib104)。预训练已成为实现目标检测任务最佳结果的常识，因为数据集通常比图像分类数据集如
    ImageNet [imagenet_cvpr09](#bib.bib18) 要小。然而，许多最新结果对此观点提出了挑战。
- en: Comparable results on the COCO object detection task [lin2014microsoft](#bib.bib66)
    are shown with random initialisation of weights compared to pretraining on ImageNet
    1K [imagenet_cvpr09](#bib.bib18) when training protocols are adjusted to be optimal
    for training from random initialization [he2018rethinking](#bib.bib34) . This
    result is repeated even when the target dataset is reduced to be on 10K images
    total, or 10% of the full COCO size. A number of other experiments show similar
    results with and without pretraining [shen2017dsod](#bib.bib117) ; [shen2017learning](#bib.bib118)
    ; [zhu2019scratchdet](#bib.bib157) and that performance is often better without
    pretraining when more exact measures of bounding box overlap are used [he2018rethinking](#bib.bib34)
    ; [zhu2019scratchdet](#bib.bib157) .
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 在 COCO 目标检测任务上，[lin2014microsoft](#bib.bib66) 的结果显示，与 ImageNet 1K [imagenet_cvpr09](#bib.bib18)
    的预训练相比，随机初始化权重的结果相当，当训练协议调整为适合从随机初始化训练的最优设置时 [he2018rethinking](#bib.bib34)。即使目标数据集减少到总共
    10K 张图像，或者 COCO 全部数据集的 10%，这个结果仍然被重复。许多其他实验显示了有无预训练的类似结果 [shen2017dsod](#bib.bib117)；[shen2017learning](#bib.bib118)；[zhu2019scratchdet](#bib.bib157)，并且当使用更精确的边界框重叠度量时，性能通常在没有预训练的情况下更好
    [he2018rethinking](#bib.bib34)；[zhu2019scratchdet](#bib.bib157)。
- en: Mixed results from pretraining on the 300 $\times$ larger Instagram hashtag
    dataset for the same COCO task are reported in [mahajan2018exploring](#bib.bib70)
    . The improvements were marginal at best, whereas the improvements reported on
    the ImageNet and CUB2011 classification tasks are larger. However in [sun2017revisiting](#bib.bib125)
    performance on COCO was significantly improved when pretraining on the large JFT
    source dataset with 300 million training examples, compared to ImageNet 1K. Again,
    these mixed results seem to indicate that deep transfer learning training hyperparameters
    can have a large influence on results when target datasets are smaller and less
    similar to source datasets.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '[mahajan2018exploring](#bib.bib70) 报告了在 300 倍大的 Instagram 标签数据集上进行预训练的混合结果，相同
    COCO 任务的改进充其量是微小的，而在 ImageNet 和 CUB2011 分类任务上报告的改进则更大。然而，在 [sun2017revisiting](#bib.bib125)
    中，与 ImageNet 1K 相比，当在包含 3 亿训练样本的大型 JFT 源数据集上进行预训练时，COCO 的性能显著提高。再次，这些混合结果似乎表明，当目标数据集较小且与源数据集不太相似时，深度迁移学习训练超参数可能对结果有很大影响。'
- en: A multi-stage pretraining pipeline [ng2015deep](#bib.bib86) may again be useful
    to consider in this domain. Developing more domain specific self-supervised pretraining
    techniques could also be considered.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个领域，多阶段预训练管道 [ng2015deep](#bib.bib86) 可能再次值得考虑。开发更多领域特定的自监督预训练技术也可以考虑。
- en: 5.7.6 Semantic Image segmentation
  id: totrans-450
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.7.6 语义图像分割
- en: Due to the inherent difficulty of gathering and creating per pixel labelled
    segmentation datasets, their scale is not as large as the size of classification
    datasets such as ImageNet. For this reason semantic image segmentation models
    have traditionally been pretrained on ImageNet 1K and other image classification
    datasets such as JFT [garcia2018survey](#bib.bib23) ; [ghosh2019understanding](#bib.bib25)
    ; [minaee2020image](#bib.bib78) . The same pattern is noted here as with other
    transfer learning applications in that more training data tends to produce better
    results [chen2018encoder](#bib.bib11) . Recently it has been shown that self-training
    on unlabelled but more closely related data consistently improves performance
    over training the same model from scratch. Whereas pretraining on ImageNet 1K
    can reduce performance (negative transfer), particularly when the target dataset
    is larger [zoph2020rethinking](#bib.bib159) .
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 由于收集和创建逐像素标记的分割数据集本身的困难，它们的规模不如图像分类数据集（如ImageNet）的大。因此，语义图像分割模型通常在ImageNet 1K和其他图像分类数据集（如JFT）上进行预训练[garcia2018survey](#bib.bib23)；[ghosh2019understanding](#bib.bib25)；[minaee2020image](#bib.bib78)。在这里注意到的模式与其他迁移学习应用相同，即更多的训练数据往往会产生更好的结果[chen2018encoder](#bib.bib11)。最近的研究表明，对未标记但更相关的数据进行自我训练可以持续改善性能，而从头开始训练相同模型则会减少性能（负迁移），特别是当目标数据集更大时[zoph2020rethinking](#bib.bib159)。
- en: 5.8 Comparison to label based taxonomy
  id: totrans-452
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8 **与基于标签的分类法的比较**
- en: Transfer learning is often categorised based on the labels available for the
    source and target task as well as whether the source domain and target domain
    are from the same distribution as follows [pan2009survey](#bib.bib91) .
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: '**迁移学习**通常根据源任务和目标任务的标签可用性以及源领域和目标领域是否来自同一分布进行分类，如[pan2009survey](#bib.bib91)所示。'
- en: '1.'
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Inductive transfer learning: In this case the label information of the target-domain
    instances is available. The source and target tasks are different but related
    and the data can be from the same or a different but related domain. This is the
    broader category and is generally the case with image classification. For this
    reason, it is the primary focus of this review.'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**归纳迁移学习**：在这种情况下，目标领域实例的标签信息是可用的。源任务和目标任务不同但相关，数据可以来自相同或不同但相关的领域。这是一个更广泛的类别，通常适用于图像分类。因此，这也是本综述的主要焦点。'
- en: '2.'
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Transductive transfer learning: In transductive transfer learning the label
    information only comes from the source domain. The tasks are the same, but the
    source and target domains are different. A common example of this is domain adaptation
    which is covered in Section [6.1](#S6.SS1 "6.1 Domain adaptation ‣ 6 Areas related
    to deep transfer learning for image classification ‣ Deep transfer learning for
    image classification: a survey"). Transductive transfer learning is not a focus
    of this review as it is rare in image classification that the source and target
    domain have the exact same class labels. This situation is more common in natural
    language processing where you may find for example a sentiment analysis model
    transferred between two slightly different product review domains.'
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**迁移学习中的传导性迁移学习**：在传导性迁移学习中，标签信息仅来自源领域。任务是相同的，但源领域和目标领域不同。一个常见的例子是领域适配，这在第[6.1节](#S6.SS1
    "6.1 领域适配 ‣ 深度迁移学习在图像分类中的相关领域 ‣ 图像分类的深度迁移学习：综述")中讨论。传导性迁移学习不是本综述的重点，因为在图像分类中，源领域和目标领域具有完全相同的类别标签的情况很少见。这种情况在自然语言处理领域更为常见，例如，在两个略微不同的产品评价领域之间转移的情感分析模型。'
- en: '3.'
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Unsupervised or semi-supervised transfer learning: Pure unsupervised learning
    where both the source and target domains have no labels is rarely useful in transfer
    learning. However, domain adaptation with no target task labels is sometimes referred
    to as unsupervised domain adaptation. Semi-supervised learning is the more common
    scenario and refers to when the source domain does not have labels but the target
    domain does. Semi-supervised learning is most commonly used when there are orders
    of magnitude more unlabelled data for the target domain or a closely related domain
    [srivastava2015unsupervised](#bib.bib122) ; [pathak2016context](#bib.bib93) ;
    [jing2020self](#bib.bib47) ; [radford2015unsupervised](#bib.bib99) ; [ledig2017photo](#bib.bib60)
    . In this situation an unsupervised or self-supervised learning algorithm is used
    to train on the unlabelled data before fine-tuning on the labelled data. This
    technique tends to result in negative transfer if the amount of unlabelled data
    is not significantly larger than the labelled data [paine2014analysis](#bib.bib90)
    .'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 无监督或半监督迁移学习：纯无监督学习，即源领域和目标领域都没有标签，在迁移学习中很少有用。然而，通常称没有目标任务标签的领域适应为无监督领域适应。半监督学习是更常见的情况，指的是源领域没有标签而目标领域有标签。半监督学习最常用于目标领域或相关领域中有数量级更多的未标记数据的情况
    [srivastava2015unsupervised](#bib.bib122) ; [pathak2016context](#bib.bib93) ;
    [jing2020self](#bib.bib47) ; [radford2015unsupervised](#bib.bib99) ; [ledig2017photo](#bib.bib60)
    。在这种情况下，使用无监督或自监督学习算法在未标记数据上进行训练，然后在标记数据上进行微调。如果未标记数据的量没有显著大于标记数据，这种技术往往会导致负迁移
    [paine2014analysis](#bib.bib90) 。
- en: We argue that for modern very deep CNNs with millions of parameters in 100s
    of layers used for image classification, the size of and similarity between source
    and target domains are much more important than the labels used in pretraining.
    The robustness and generality of the features learned are similarly much more
    important than the final classification task they are trained on. For example
    a source domain that is very large and identical or similar to the target domain
    but without labels, or with weak labels, will produce better results than a fully
    labelled source dataset that is very different to the target domain [zoph2020rethinking](#bib.bib159)
    ; [azizi2021big](#bib.bib3) .
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为，对于现代深度卷积神经网络（CNN），这些网络拥有数百万个参数和上百层用于图像分类，源领域和目标领域的大小及相似性比预训练时使用的标签更为重要。学到的特征的鲁棒性和普适性也比最终的分类任务更为重要。例如，一个非常大且与目标领域完全相同或相似但没有标签，或者标签较弱的源领域，会比一个完全标注但与目标领域差异很大的源数据集产生更好的结果
    [zoph2020rethinking](#bib.bib159) ; [azizi2021big](#bib.bib3) 。
- en: 5.9 Discussion
  id: totrans-461
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.9 讨论
- en: 'There are two overarching themes throughout this review of transfer learning
    techniques and applications:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次迁移学习技术和应用的综述中有两个主要主题：
- en: '1.'
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: More source data is better in general, but a more closely related source dataset
    for pretraining will often produce better performance on the target task than
    a larger source dataset.
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一般来说，更多的源数据更好，但与目标任务更密切相关的源数据集通常会比更大的源数据集在目标任务上表现得更好。
- en: '2.'
  id: totrans-465
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: The size of the target dataset and how closely related it is to the source dataset
    strongly impacts the performance of transfer learning. In particular using sub-optimal
    transfer learning hyperparameters can result in negative transfer when the target
    dataset is less related and large enough to be trained from random initialisation.
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标数据集的大小以及它与源数据集的相关性会强烈影响迁移学习的性能。特别是，使用次优的迁移学习超参数可能会导致负迁移，尤其当目标数据集与源数据集关系较远且足够大到可以从随机初始化进行训练时。
- en: Currently, there tends to be an all or nothing approach to transfer learning.
    Either transferring all layers improves performance or it doesn’t and possibly
    decreases performance (negative transfer). The same approach is often taken to
    freezing layers, either layers are frozen or they are fine-tuned at the same learning
    rate as the rest of the model, and weight regularization, either all transferred
    weights are decayed towards their pretrained values (L2SP or other recent regularization
    techniques) or towards zero (or sometimes not at all). We advocate that the all
    or nothing approach should be discarded and instead all decisions made about how
    to perform transfer learning should be thought of as a sliding scale. Transferring
    all layers, freezing layers and decaying all weights towards pretrained values
    is at one extreme of the scale and is likely to only be optimal for source and
    target datasets that are extremely similar. Training from scratch is at the other
    end of the scale and is likely to only be optimal if the source and target domain
    have no similarities. This lines up with the observations in [yosinski2014transferable](#bib.bib149)
    that “first-layer features appear not to be specific to a particular dataset or
    task, but general in that they are applicable to many datasets and tasks”. Recent
    work by Abnar et al. has shown the potential for improvements in transfer learning
    by taking into account the similarities of the source and target task [abnar2021exploring](#bib.bib1)
    . More work is needed to show how to perform transfer learning optimally for a
    given source and target dataset relationship and target dataset size, rather than
    showing whether transfer learning is effective at all.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 当前，迁移学习通常采取全有或全无的方法。要么迁移所有层提升性能，要么不提升甚至可能降低性能（负迁移）。冻结层也常用相同的方法，要么层被冻结，要么以与模型其余部分相同的学习率进行微调，权重正则化也是如此，要么所有迁移的权重都衰减到其预训练值（L2SP或其他最近的正则化技术），要么衰减到零（有时根本不衰减）。我们主张摒弃全有或全无的方法，改为将所有迁移学习的决策视为一个滑动尺度。迁移所有层、冻结层和将所有权重衰减到预训练值的做法处于尺度的一个极端，可能仅对源数据集和目标数据集极其相似的情况是最优的。从头开始训练则处于尺度的另一端，可能仅在源领域和目标领域没有任何相似性时才是最优的。这与[yosinski2014transferable](#bib.bib149)中的观察一致，即“第一层特征似乎并非特定于某一数据集或任务，而是通用的，适用于许多数据集和任务”。Abnar等人的最新工作显示了通过考虑源任务和目标任务的相似性来改善迁移学习的潜力[abnar2021exploring](#bib.bib1)。需要更多的工作来展示如何在给定的源和目标数据集关系及目标数据集大小下，最优地执行迁移学习，而不是仅仅展示迁移学习是否有效。
- en: 6 Areas related to deep transfer learning for image classification
  id: totrans-468
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 图像分类中的深度迁移学习相关领域
- en: There are several different problem domains that are either closely related
    to deep transfer learning or that use it as a standard part of state of the art
    models. We briefly examine how they relate to deep transfer learning for image
    classification below.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个不同的问题领域与深度迁移学习紧密相关，或者将其作为最先进模型的标准部分。我们简要地审视了它们如何与图像分类的深度迁移学习相关。
- en: 6.1 Domain adaptation
  id: totrans-470
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 域适应
- en: 'Domain adaptation (DA) could be considered the most closely related problem
    domain. In domain adaptation the task $T$ remains the same, but the Domain $D$
    differs between source and target task. According to the definition [3](#Thmdefinition3
    "Definition 3\. ‣ 3.3 Deep transfer learning ‣ 3 Overview ‣ Deep transfer learning
    for image classification: a survey") by Pan and Yang [pan2009survey](#bib.bib91)
    domain adaptation falls under general transfer learning as transductive transfer
    learning as described in Section [5.8](#S5.SS8 "5.8 Comparison to label based
    taxonomy ‣ 5 Deep transfer learning progress and areas for improvement ‣ Deep
    transfer learning for image classification: a survey"). Others define it as a
    separate area [goodfellow2016deep](#bib.bib29) . Either way domain adaptation
    is not a focus of this review as it is rare in image classification that the source
    and target domain have the exact same class labels. This situation is more common
    in natural language processing where you may find for example, a sentiment analysis
    model transferred between two slightly different product review domains [csurka2017domain](#bib.bib15)
    ; [wang2018deep1](#bib.bib137) ; [zhang2017transfer](#bib.bib152) . The few datasets
    that are used in domain adaptation for image classification are carefully curated
    to have identical object classes in different domains [gong2012geodesic](#bib.bib27)
    ; [saenko2010adapting](#bib.bib112) ; [tommasi2014testbed](#bib.bib129) .'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 领域适应（DA）可以被认为是最相关的问题领域。在领域适应中，任务 $T$ 保持不变，但领域 $D$ 在源任务和目标任务之间有所不同。根据 Pan 和 Yang
    的定义 [3](#Thmdefinition3 "Definition 3\. ‣ 3.3 深度迁移学习 ‣ 3 概述 ‣ 图像分类的深度迁移学习：调查")
    [pan2009survey](#bib.bib91)，领域适应属于一般迁移学习中的传递迁移学习，如第 [5.8](#S5.SS8 "5.8 与标签基础分类法的比较
    ‣ 5 深度迁移学习的进展与改进领域 ‣ 图像分类的深度迁移学习：调查") 节所述。其他人将其定义为一个独立领域 [goodfellow2016deep](#bib.bib29)。无论如何，领域适应并不是这篇综述的重点，因为在图像分类中，源领域和目标领域有完全相同的类别标签的情况很少见。这种情况在自然语言处理领域更为常见，例如，你可能会发现情感分析模型在两个略有不同的产品评论领域之间的迁移
    [csurka2017domain](#bib.bib15)；[wang2018deep1](#bib.bib137)；[zhang2017transfer](#bib.bib152)。在图像分类的领域适应中使用的少数数据集经过精心策划，以确保不同领域中的对象类别相同
    [gong2012geodesic](#bib.bib27)；[saenko2010adapting](#bib.bib112)；[tommasi2014testbed](#bib.bib129)。
- en: 'Despite there being few examples of domain adaptation problems in image classification
    there are techniques that have been developed for these tasks that could be more
    broadly useful to deep transfer learning for image classification. Wang and Deng
    state that ”When the labeled samples from the target domain are available in supervised
    DA, soft label and metric learning are always effective” [wang2018deep1](#bib.bib137)
    . Metric learning has been shown to be effective in K-shot learning as described
    in Section [6.3](#S6.SS3 "6.3 K-shot or few shot learning ‣ 6 Areas related to
    deep transfer learning for image classification ‣ Deep transfer learning for image
    classification: a survey"). It has recently been shown to improve performance
    with slightly larger but still small fine-grained target datasets with up to 42
    examples per class [ridnik2020tresnet](#bib.bib107) . It is also common in domain
    adaptation to use a multi-stage adaptation similar to that shown to be effective
    for facial expression recognition in [ng2015deep](#bib.bib86) .'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在图像分类中关于领域适应问题的例子较少，但已经开发出了一些技术，这些技术可能对图像分类的深度迁移学习更广泛地有用。Wang 和 Deng 指出：“当目标领域的标记样本在监督式领域适应中可用时，软标签和度量学习总是有效的”
    [wang2018deep1](#bib.bib137)。度量学习在 K-shot 学习中被证明是有效的，如第 [6.3](#S6.SS3 "6.3 K-shot
    或少样本学习 ‣ 6 与图像分类深度迁移学习相关的领域 ‣ 图像分类的深度迁移学习：调查") 节所述。最近的研究表明，它可以在稍微大一点但仍然较小的细粒度目标数据集中提高性能，每类最多可达
    42 个样本 [ridnik2020tresnet](#bib.bib107)。在领域适应中，使用类似于在 [ng2015deep](#bib.bib86)
    中对面部表情识别有效的多阶段适应也是很常见的。
- en: 6.2 Concept drift and multitask learning
  id: totrans-473
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 概念漂移和多任务学习
- en: 'The concept drift problem is related to domain adaptation in that it deals
    with adapting models to distributions that change over time. Multitask learning
    is another related problem domain where the focus is on learning one model that
    can perform well at multiple tasks in multiple domains. While both can be seen
    as types of transfer learning, the distinction between pure transfer learning
    focused tasks and concept drift or multitask learning is an important one. The
    focus in the former is to learn just the target task as well as possible and performance
    is only judged on this. Whereas in both concept drift and multitask learning the
    focus is to learn more than one task well:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 概念漂移问题与领域适应相关，因为它涉及到将模型适应于随时间变化的分布。多任务学习是另一个相关的问题领域，重点是学习一个能够在多个领域的多个任务中表现良好的模型。尽管两者都可以视为迁移学习的一种类型，但纯迁移学习任务与概念漂移或多任务学习之间的区别非常重要。前者的重点是尽可能好地学习目标任务，表现仅根据这一点来评估。而在概念漂移和多任务学习中，重点则是要很好地学习多个任务：
- en: •
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: in concept drift learning the new distribution needs to be modelled well without
    forgetting all learning about the old distribution
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在概念漂移学习中，需要很好地建模新分布，而不忘记对旧分布的所有学习。
- en: •
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: in multitask learning many tasks need to be learned well. This needs to be achieved
    without new tasks overwriting previously learned tasks.
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在多任务学习中，需要很好地学习多个任务。这需要在不让新任务覆盖已学任务的情况下实现。
- en: The issues described above are examples of catastrophic forgetting. Catastrophic
    forgetting is defined as the scenario where learning a new set of patterns suddenly
    and completely erases a network’s knowledge of what it has already learned [french1999catastrophic](#bib.bib22)
    ; [mccloskey1989catastrophic](#bib.bib75) ; [ratcliff1990connectionist](#bib.bib102)
    . The major difference between general transfer learning and concept drift or
    multitask learning is that usually catastrophic forgetting is not a consideration
    in the former.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 上述问题是灾难性遗忘的例子。灾难性遗忘定义为在学习一组新模式时，网络对已学知识的突然和完全的遗忘 [french1999catastrophic](#bib.bib22)
    ; [mccloskey1989catastrophic](#bib.bib75) ; [ratcliff1990connectionist](#bib.bib102)
    。一般迁移学习与概念漂移或多任务学习之间的主要区别在于，前者通常不会考虑灾难性遗忘。
- en: 6.3 K-shot or few shot learning
  id: totrans-480
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 K-shot 或少样本学习
- en: The K-shot or few shot (K-shot) learning problem domain is specifically focused
    on learning from very few or even zero labelled examples. The focus of new work
    in this domain is generally on improving metrics for defining and learning the
    best embedding spaces and comparisons to new examples, plus tricks of data augmentation.
    Transfer learning is implicit in most of the techniques used as weights are pretrained
    on a related task [wang2020generalizing](#bib.bib139) ; [kaya2019deep](#bib.bib48)
    .
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: K-shot 或少样本（K-shot）学习问题领域特别关注从非常少量甚至零标记样本中学习。该领域新工作的重点通常是改善定义和学习最佳嵌入空间的度量标准、与新样本的比较以及数据增强技巧。迁移学习在大多数使用的技术中是隐含的，因为权重在相关任务上进行了预训练
    [wang2020generalizing](#bib.bib139) ; [kaya2019deep](#bib.bib48) 。
- en: 'Methods for refining deep transfer learning methods for k-shot image classification
    tasks can be divided into:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 对于k-shot图像分类任务，改进深度迁移学习方法可以分为：
- en: •
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: data augmentation and other methods for improving the source dataset
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据增强和其他改进源数据集的方法
- en: •
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: metrics that define the “goodness” of the embedding space and how that information
    should be used to classify small target classes
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 定义嵌入空间“优度”的度量标准，以及如何利用这些信息来对小目标类别进行分类
- en: •
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: methods that look at the best way to update weights based on the target dataset.
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 考察基于目标数据集更新权重的最佳方法。
- en: We focus on methods that fall under the last heading, as they are most relevant
    to this review. However, as stated previously, we note that metric methods have
    recently been shown to improve transfer learning performance for some small datasets
    that fall outside of the standard K-shot learning definition [ridnik2020tresnet](#bib.bib107)
    . More research is recommended to extend these results.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关注于最后一项内容下的方法，因为它们与本次综述最为相关。然而，如前所述，度量方法最近被证明能提高一些超出标准K-shot学习定义的小数据集的迁移学习表现
    [ridnik2020tresnet](#bib.bib107) 。建议进一步研究以扩展这些结果。
- en: Weight update methods
  id: totrans-490
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 权重更新方法
- en: Weight update methods look at the best way to update weights from the source
    or other related tasks, including the decision not to update any weights. Many
    models across a broad spectrum of K-shot learning techniques do not perform any
    updates to weights using the target dataset. There is some recent evidence that
    shows that weight updates are superior in a variety of cases [scott2018adapted](#bib.bib114)
    , but again given the small target dataset sizes the right transfer learning hyperparameters
    must be used. Many models that do not update weights to the target task do simulate
    the few-shot learning scenario in training on related datasets. They train on
    a subset of the available classes, then optimize the model by maximising performance
    on the unseen classes. This results in a model that generalises well to unseen
    examples [vinyals2016matching](#bib.bib133) ; [snell2017prototypical](#bib.bib120)
    .
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 权重更新方法探讨了从源任务或其他相关任务中更新权重的最佳方式，包括决定是否更新任何权重。许多模型在广泛的 K-shot 学习技术中不对权重进行任何更新。最近有一些证据表明，在各种情况下权重更新是优越的
    [scott2018adapted](#bib.bib114) ，但考虑到目标数据集较小，必须使用正确的迁移学习超参数。许多不对权重进行更新的模型确实在相关数据集上模拟了少样本学习场景。它们在可用类别的子集上进行训练，然后通过最大化在未见类别上的性能来优化模型。这将导致模型对未见示例具有良好的泛化能力
    [vinyals2016matching](#bib.bib133) ; [snell2017prototypical](#bib.bib120) 。
- en: 'In Generalizing from a Few Examples: A Survey on Few-shot Learning [wang2020generalizing](#bib.bib139)
    Wang et al. define transfer learning as falling under the informing the parameter
    space umbrella of few-shot learning techniques. Under this general umbrella transfer
    learning and related topics can be split into several different strategies for
    dealing with very small target datasets:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 在《从少数例子中泛化：关于少样本学习的调查》[wang2020generalizing](#bib.bib139)中，Wang 等人将迁移学习定义为少样本学习技术中“告知参数空间”这一范畴的一部分。在这个总体范畴下，迁移学习和相关主题可以分为几种不同的策略，以处理非常小的目标数据集：
- en: '1.'
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Refining pretrained parameters: these methods explicitly look at ways for improving
    deep transfer learning methods for very small target datasets. They are grouped
    into ways of explicitly regularizing to avoid overfitting, including:'
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 精炼预训练参数：这些方法明确关注于提高深度迁移学习方法在非常小目标数据集上的效果。它们被分为明确正则化以避免过拟合的方法，包括：
- en: •
  id: totrans-495
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: early stopping
  id: totrans-496
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提前停止
- en: •
  id: totrans-497
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: selectively updating only certain weights
  id: totrans-498
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有选择地仅更新某些权重
- en: •
  id: totrans-499
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: updating certain groups of weights together
  id: totrans-500
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一起更新某些权重组
- en: •
  id: totrans-501
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: weight regularization.
  id: totrans-502
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 权重正则化。
- en: '2.'
  id: totrans-503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Refining meta-learned parameters: these methods are drawn from multitask learning.
    Parameters $W_{0}$ are learned from several related tasks, then again fine-tuned
    on the target task. The models differ in the way the weights are updated from
    the multitask to the task specific model. Regularizing methods that use task specific
    information or model the uncertainty of using meta-learned parameters can also
    be included in this heading.'
  id: totrans-504
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 精炼元学习参数：这些方法源于多任务学习。参数 $W_{0}$ 是从几个相关任务中学习得到的，然后在目标任务上再次进行微调。模型在从多任务模型到任务特定模型的权重更新方式上有所不同。使用任务特定信息或对使用元学习参数的不确定性建模的正则化方法也可以包括在此分类中。
- en: '3.'
  id: totrans-505
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Learning the optimizer: These methods work on learning optimizers that can
    perform better than hand designed optimizers in a specific problem domain when
    fine-tuning a pretrained model with a small number of training examples.'
  id: totrans-506
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学习优化器：这些方法致力于学习优化器，以便在用少量训练样本微调预训练模型时，能比手工设计的优化器在特定问题领域表现得更好。
- en: While there is a lot of cross-over of deep transfer learning for image classification
    from the refining pretrained parameters category of K-shot learning, the latter
    focuses only on very small target datasets. This means they also do not consider
    how the change in size of the target dataset and the relationship between the
    source and target dataset affect the optimal transfer learning methods and hyperparameters.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在图像分类的深度迁移学习中，来自 K-shot 学习的精炼预训练参数类别有很多交集，但后者仅关注非常小的目标数据集。这意味着它们也没有考虑目标数据集的大小变化以及源数据集和目标数据集之间的关系如何影响最佳迁移学习方法和超参数。
- en: 6.4 Unsupervised or self-supervised learning
  id: totrans-508
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 无监督或自监督学习
- en: In unsupervised or self-supervised deep learning (self-supervised) a model of
    a dataset distribution is learned by using an aspect of the data itself as a training
    signal. The most general example is autoencoders which consist of an encoder and
    decoder with the target being the same as the input. The middle encoding is regularized
    in some way, in the hopes of producing a meaningful semantic encoding. Other examples
    of task specific self-supervised learning include predicting the next frame of
    a video [srivastava2015unsupervised](#bib.bib122) , predicting the next word in
    a sentence [brown2020language](#bib.bib10) , image inpainting or upsampling [pathak2016context](#bib.bib93)
    ; [ledig2017photo](#bib.bib60) , and many more. For a detailed treatment of self-supervised
    methods for learning image representations see [jing2020self](#bib.bib47) . Generative
    Adversarial Networks (GANs) are also an example of self-supervised learning [radford2015unsupervised](#bib.bib99)
    ; [goodfellow2014generative](#bib.bib30) . In learning to classify real vs fake
    training examples the discriminator in a GAN learns useful features of the data
    distribution and the weights can then be used to initialise a classification model.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督或自监督深度学习（自监督）中，通过使用数据本身的某个方面作为训练信号来学习数据集分布的模型。最一般的例子是自编码器，它由编码器和解码器组成，目标是与输入相同。中间的编码以某种方式被正则化，希望能产生有意义的语义编码。其他任务特定的自监督学习例子包括预测视频的下一帧[srivastava2015unsupervised](#bib.bib122)、预测句子的下一个词[brown2020language](#bib.bib10)、图像修补或上采样[pathak2016context](#bib.bib93)；[ledig2017photo](#bib.bib60)，还有许多其他例子。有关学习图像表示的自监督方法的详细讨论，参见[jing2020self](#bib.bib47)。生成对抗网络（GANs）也是自监督学习的一个例子[radford2015unsupervised](#bib.bib99)；[goodfellow2014generative](#bib.bib30)。在学习分类真实与虚假的训练样本时，GAN中的判别器学习数据分布的有用特征，这些权重可以用于初始化分类模型。
- en: 'Self-supervised learning relates closely to transfer learning as it is often
    used for pretraining when there is limited labelled data for a source task, but
    a large amount of related unlabelled data. Self-supervised learning has been shown
    to be beneficial to performance when the ratio of unlabelled to labelled training
    examples is high, but may harm performance when the ratio is low [paine2014analysis](#bib.bib90)
    . This relates back to the question of more versus better related source training
    data that comes up regularly in deep transfer learning and is covered in sections
    [5.3.1](#S5.SS3.SSS1 "5.3.1 More versus better matched pretraining data ‣ 5.3
    Large closely related target datasets ‣ 5 Deep transfer learning progress and
    areas for improvement ‣ Deep transfer learning for image classification: a survey")
    and [5.6.1](#S5.SS6.SSS1 "5.6.1 More vs better matched pretraining data part 2
    ‣ 5.6 Smaller target datasets with similar tasks ‣ 5 Deep transfer learning progress
    and areas for improvement ‣ Deep transfer learning for image classification: a
    survey").'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: '自监督学习与迁移学习密切相关，因为在源任务的数据标注有限但有大量相关的未标注数据时，常常使用自监督学习进行预训练。研究表明，当未标注数据与标注数据的比例较高时，自监督学习对性能有益，但当比例较低时可能会损害性能[paine2014analysis](#bib.bib90)。这与深度迁移学习中经常出现的更多与更好匹配的源训练数据的问题相关，详细讨论见[5.3.1](#S5.SS3.SSS1
    "5.3.1 More versus better matched pretraining data ‣ 5.3 Large closely related
    target datasets ‣ 5 Deep transfer learning progress and areas for improvement
    ‣ Deep transfer learning for image classification: a survey")和[5.6.1](#S5.SS6.SSS1
    "5.6.1 More vs better matched pretraining data part 2 ‣ 5.6 Smaller target datasets
    with similar tasks ‣ 5 Deep transfer learning progress and areas for improvement
    ‣ Deep transfer learning for image classification: a survey")。'
- en: 7 Discussion and suggestions for future directions
  id: totrans-511
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 讨论和未来方向建议
- en: 7.1 Summary of current knowledge
  id: totrans-512
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 当前知识总结
- en: Early work in deep transfer learning for image classification showed that transfer
    learning is effective compared to training from randomly initialised weights,
    particularly when it involves small target datasets and the source and target
    datasets are similar [agrawal2014analyzing](#bib.bib2) ; [yosinski2014transferable](#bib.bib149)
    ; [azizpour2015factors](#bib.bib4) .
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像分类的深度迁移学习的早期工作中，显示了迁移学习相对于从随机初始化权重开始的训练是有效的，特别是在涉及小目标数据集且源数据集与目标数据集相似时[agrawal2014analyzing](#bib.bib2)；[yosinski2014transferable](#bib.bib149)；[azizpour2015factors](#bib.bib4)。
- en: 'Our review has highlighted the limits of current knowledge in each area and
    suggested future research directions to expand the current body of knowledge:'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的综述突出了当前知识的局限性，并提出了未来研究方向，以扩展现有的知识体系：
- en: '1.'
  id: totrans-515
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Fine tuning tends to work better than freezing weights in most cases [agrawal2014analyzing](#bib.bib2)
    ; [yosinski2014transferable](#bib.bib149) ; [azizpour2015factors](#bib.bib4) .
    Freezing lower layers may work better in limited cases where the target domain
    is small and the tasks are extremely similar [plested2019analysis](#bib.bib95)
    . More work is needed to see whether this applies with modern deep CNNs.
  id: totrans-516
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 微调通常比冻结权重在大多数情况下效果更好 [agrawal2014analyzing](#bib.bib2) ; [yosinski2014transferable](#bib.bib149)
    ; [azizpour2015factors](#bib.bib4) 。在目标领域较小且任务极其相似的有限情况下，冻结较低层可能效果更好 [plested2019analysis](#bib.bib95)
    。需要更多工作来验证这一点是否适用于现代深度卷积神经网络。
- en: '2.'
  id: totrans-517
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Recent regularization techniques such as L2-SP, DELTA, BSS and stochastic normalization
    tend to improve performance when source and target tasks are very similar. However,
    it has been shown that L2-SP and DELTA particularly can result in minimal improvement
    or even worse performance when the source and target datasets are less related
    [li2020rethinking](#bib.bib61) ; [wan2019towards](#bib.bib135) ; [plested2021non](#bib.bib96)
    ; [chen2019catastrophic](#bib.bib12) . Most work so far has focused on how these
    techniques compare when the source and target dataset are very closely related.
    More work is needed to show how each of these methods perform when they are applied
    to less similar datasets. Recent work has shown that in some cases using L2-SP
    regularization for lower layers and L2 regularization for higher layers can improve
    performance over using either one for all layers [plested2021non](#bib.bib96)
    . While the evidence for this is so far limited it does align with observations
    from [yosinski2014transferable](#bib.bib149) and [abnar2021exploring](#bib.bib1)
    that lower layers are more transferable than higher layers.
  id: totrans-518
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最近的正则化技术，如 L2-SP、DELTA、BSS 和随机归一化，通常在源任务和目标任务非常相似时能够提高性能。然而，研究表明，L2-SP 和 DELTA
    特别是在源数据集和目标数据集相关性较低时，可能会导致最小的改进甚至更差的性能 [li2020rethinking](#bib.bib61) ; [wan2019towards](#bib.bib135)
    ; [plested2021non](#bib.bib96) ; [chen2019catastrophic](#bib.bib12) 。到目前为止，大多数工作集中在这些技术在源数据集和目标数据集非常紧密相关时的比较。需要更多工作来展示这些方法在应用于相似性较低的数据集时的表现。近期的研究表明，在某些情况下，使用
    L2-SP 正则化用于较低层，L2 正则化用于较高层，能够比对所有层使用同一种正则化方法提高性能 [plested2021non](#bib.bib96)
    。虽然迄今为止的证据有限，但这与 [yosinski2014transferable](#bib.bib149) 和 [abnar2021exploring](#bib.bib1)
    的观察结果相一致，即较低层比较高层更具可迁移性。
- en: '3.'
  id: totrans-519
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Both the learning rate and momentum should be lower during fine-tuning for more
    similar source and target tasks and higher for less closely related datasets [li2020rethinking](#bib.bib61)
    ; [plested2021non](#bib.bib96) . The learning rate should also be decayed more
    quickly the more similar the source and target tasks are, so as not to change
    the pretrained parameters as much [kolesnikov2019big](#bib.bib50) . Similarly
    the learning rate should be decayed more quickly with smaller target datasets
    where the empirical risk estimate is likely to be less reliable and overfitting
    more of a problem [plested2019analysis](#bib.bib95) ; [kolesnikov2019big](#bib.bib50)
    . However, when the target data set is small it must be taken into account that
    the number of weight updates per epoch will be lower and the number of updates
    should be reduced, not necessarily the number of epochs. When the source and target
    datasets are less similar it may be optimal to fine-tune higher layers at a higher
    learning rate than lower layers [plested2021non](#bib.bib96) . More work is needed
    to show how the learning rate, momentum and number of updates before decaying
    the learning rate change when the source and target tasks are very different.
  id: totrans-520
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在对源任务和目标任务较相似时，微调过程中学习率和动量应设定较低，而对相关性较低的数据集则应设定较高 [li2020rethinking](#bib.bib61)
    ; [plested2021non](#bib.bib96) 。学习率也应在源任务和目标任务越相似时更快衰减，以避免过多改变预训练参数 [kolesnikov2019big](#bib.bib50)
    。类似地，在目标数据集较小的情况下，学习率应更快衰减，因为经验风险估计可能不太可靠，过拟合问题更为严重 [plested2019analysis](#bib.bib95)
    ; [kolesnikov2019big](#bib.bib50) 。然而，当目标数据集较小时，必须考虑到每个周期的权重更新次数较少，应减少更新次数，而不一定减少周期数。当源数据集和目标数据集相关性较低时，可能需要对较高层以较高的学习率进行微调，而不是对较低层
    [plested2021non](#bib.bib96) 。需要更多工作来展示当源任务和目标任务差异很大时，学习率、动量和更新次数在衰减学习率前的变化。
- en: '4.'
  id: totrans-521
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Transferring more layers is better than less layers when source and target datasets
    are large and very similar and learning rates are high for all layers [yosinski2014transferable](#bib.bib149)
    . This does not necessarily hold true when target datasets are smaller and fine
    tuning hyperparameters are more optimal [plested2019analysis](#bib.bib95) ; [plested2021non](#bib.bib96)
    ; [abnar2021exploring](#bib.bib1) . This relates back to Point 3 that the learning
    rate and momentum should be lower for more similar tasks. As the empirical risk
    minimizer is unreliable for small datasets it is more prone to overfitting. Pretraining
    weights limits how far they can move based on this unreliable risk minimizer [neyshabur2020being](#bib.bib85)
    ; [liu2019towards](#bib.bib67) , so it acts as a regularizer to prevent overfitting.
    An additional way to limit overfitting is to use a smaller learning rate and momentum,
    and also decay the learning rate quickly to prevent weights becoming too large
    based on unreliable statistics. These two items combined together mean it is likely
    that a larger fine-tuning learning rate is optimal when more layers are pretrained
    and a lower learning rate when less layers are pretrained [plested2019analysis](#bib.bib95)
    ; [plested2021non](#bib.bib96) . For this reason it is important to tune both
    the number of layers pretrained and optimal learning rate together. Recent work
    has also shown that using fixed pretrained features from lower layers without
    fine-tuning can result in better performance than features from higher layers
    when source and target datasets are less similar and the target dataset is small
    [mormont2018comparison](#bib.bib80) ; [abnar2021exploring](#bib.bib1) .
  id: totrans-522
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当源数据集和目标数据集都很大且非常相似，并且所有层的学习率都很高时，传输更多层比传输更少层更好 [yosinski2014transferable](#bib.bib149)
    。当目标数据集较小且微调超参数更为优化时，这种情况并不一定成立 [plested2019analysis](#bib.bib95) ; [plested2021non](#bib.bib96)
    ; [abnar2021exploring](#bib.bib1) 。这与第3点相关，即对于更相似的任务，学习率和动量应较低。由于经验风险最小化器在小数据集上不可靠，因此更容易过拟合。预训练权重限制了它们在这种不可靠的风险最小化器下能够移动的距离
    [neyshabur2020being](#bib.bib85) ; [liu2019towards](#bib.bib67) ，因此它充当正则化器来防止过拟合。限制过拟合的另一种方法是使用较小的学习率和动量，并且迅速衰减学习率，以防止权重因不可靠的统计数据而变得过大。这两项因素结合在一起意味着当预训练层更多时，更大的微调学习率可能是最佳的，而当预训练层较少时，则较低的学习率更为合适
    [plested2019analysis](#bib.bib95) ; [plested2021non](#bib.bib96) 。因此，重要的是同时调整预训练层的数量和最佳学习率。近期研究还表明，当源数据集和目标数据集不太相似且目标数据集较小时，使用固定的低层预训练特征而不进行微调，可以比使用高层特征获得更好的性能
    [mormont2018comparison](#bib.bib80) ; [abnar2021exploring](#bib.bib1) 。
- en: '5.'
  id: totrans-523
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: More source and target training data is better in general. Improvements in performance
    from pretraining on datasets that are up to 3,000 times larger than ImageNet 1K
    have shown that the largest modern models are overfitting on ImageNet 1K. Pretraining
    with much larger datasets helps prevent this [ngiam2018domain](#bib.bib87) ; [mahajan2018exploring](#bib.bib70)
    ; [kolesnikov2019big](#bib.bib50) . However, closely related data is better than
    more data when data is abundant [ngiam2018domain](#bib.bib87) ; [mahajan2018exploring](#bib.bib70)
    . Self-supervised learning on a more related unlabelled source dataset has been
    shown to improve performance over supervised learning on a less related labelled
    dataset in some cases [heker2020joint](#bib.bib37) ; [zoph2020rethinking](#bib.bib159)
    . More work is needed to identify under what circumstances the former is better
    than the latter. A multi-step fine-tuning process including a more closely related
    intermediate task has been shown to improve performance over a single step transfer
    from ImageNet 1K in a number of specialised tasks with target datasets that are
    very different from ImageNet 1K [ng2015deep](#bib.bib86) ; [gonthier2020analysis](#bib.bib28)
    ; [azizi2021big](#bib.bib3) . More work is needed to see if this technique could
    benefit other tasks where limited closely related data is available.
  id: totrans-524
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一般来说，更多的源数据和目标数据更好。预训练在比 ImageNet 1K 大 3,000 倍的数据集上所带来的性能改进表明，最大的现代模型在 ImageNet
    1K 上出现了过拟合。使用更大的数据集进行预训练有助于防止这种情况 [ngiam2018domain](#bib.bib87) ; [mahajan2018exploring](#bib.bib70)
    ; [kolesnikov2019big](#bib.bib50) 。然而，当数据丰富时，相关性较高的数据比更多的数据更好 [ngiam2018domain](#bib.bib87)
    ; [mahajan2018exploring](#bib.bib70) 。在某些情况下，使用更多相关的未标记源数据集进行自监督学习已被证明比在相关性较低的标记数据集上进行监督学习效果更好
    [heker2020joint](#bib.bib37) ; [zoph2020rethinking](#bib.bib159) 。还需要更多的研究来确定在什么情况下前者优于后者。包括一个更相关的中间任务的多步骤微调过程已被证明在多个与
    ImageNet 1K 非常不同的目标数据集的专业任务中，相比于单步从 ImageNet 1K 转移能提高性能 [ng2015deep](#bib.bib86)
    ; [gonthier2020analysis](#bib.bib28) ; [azizi2021big](#bib.bib3) 。还需要更多研究来观察这种技术是否能在其他有限的相关数据可用的任务中带来好处。
- en: '6.'
  id: totrans-525
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: Measures of transferability can predict the performance of a pretrained model
    on a particular target task [bao2019information](#bib.bib5) ; [tran2019transferability](#bib.bib130)
    ; [nguyen2020leep](#bib.bib88) . The performance of a simple classification model
    with frozen weights can give some insight into transfer learning best practice
    for the target task [plested2021non](#bib.bib96) . More work is needed to determine
    if transferability measures in general can help determine optimal transfer learning
    hyperparameters across a wide range of source and target datasets.
  id: totrans-526
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 迁移性度量可以预测预训练模型在特定目标任务上的表现 [bao2019information](#bib.bib5) ; [tran2019transferability](#bib.bib130)
    ; [nguyen2020leep](#bib.bib88) 。一个具有冻结权重的简单分类模型的表现可以为目标任务的迁移学习最佳实践提供一些见解 [plested2021non](#bib.bib96)
    。还需要更多的研究来确定迁移性度量是否可以帮助确定在各种源和目标数据集上优化迁移学习超参数。
- en: 7.2 Recommendations for best practice
  id: totrans-527
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 最佳实践建议
- en: Our recommendations for best practice in deep transfer learning for image classification
    broken down by target dataset size and similarity to the source dataset are summarized
    below.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 我们针对图像分类深度迁移学习的最佳实践建议，根据目标数据集的大小和与源数据集的相似性，汇总如下。
- en: Larger, similar target datasets
  id: totrans-529
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 较大且相似的目标数据集
- en: Most techniques will work well in this case, so less time needs to be spent
    finding the best technique for the given task. A lower learning rate and momentum
    are better for fine-tuning when the source and target datasets are similar. This
    may not be necessary when the target dataset is very large, for example ImageNet
    1K, and overfitting a poor empirical risk minimizer is less of a problem. All
    weights should be fine-tuned not frozen. L2-SP regularization or other more recent
    techniques like DELTA, BSS, stochastic normalization etc. are likely to work reasonably
    well. Generally, less regularization will be needed with a very large target dataset.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，大多数技术都能很好地工作，因此不需要花费太多时间寻找适合给定任务的最佳技术。当源数据集和目标数据集相似时，较低的学习率和动量更适合微调。当目标数据集非常大，例如
    ImageNet 1K 时，这可能不是必需的，因为对一个表现不佳的经验风险最小化器的过拟合问题较小。所有权重应进行微调而不是冻结。L2-SP 正则化或其他更近期的技术，如
    DELTA、BSS、随机归一化等，可能会表现得相当好。一般来说，对于非常大的目标数据集，需要的正则化会较少。
- en: Larger, less similar target datasets
  id: totrans-531
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 较大且不太相似的目标数据集
- en: Pretraining weights may not improve performance and negative transfer is more
    likely in this scenario, so care needs to be taken. When fine-tuning a higher
    learning rate, momentum and training for longer before decaying the learning rate
    should be used. This is to attempt to move weights out of the flat basin of the
    loss landscape, that is created when using pretrained weights, and further away
    from their pretrained values [neyshabur2020being](#bib.bib85) ; [liu2019towards](#bib.bib67)
    . Recent regularization techniques like L2-SP, DELTA, BSS, stochastic normalization,
    etc. should not be used in this case as weights should be allowed to move freely
    away from their pretrained values based on the larger target dataset. Reinitializing
    more layers of weights could also be attempted in order to take advantage of the
    more general lower layers, while allowing the more task specific higher layers
    to train from random initialization [yosinski2014transferable](#bib.bib149) ;
    [plested2021non](#bib.bib96) ; [abnar2021exploring](#bib.bib1) .
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练权重可能不会提高性能，在这种情况下负迁移的可能性更大，因此需要谨慎处理。微调时应使用较高的学习率、动量，并在衰减学习率之前训练更长时间。这是为了尝试将权重从使用预训练权重时产生的损失景观的平坦盆地中移出，并进一步远离其预训练值[neyshabur2020being](#bib.bib85)；[liu2019towards](#bib.bib67)。最近的正则化技术，如L2-SP、DELTA、BSS、随机归一化等，在这种情况下不应使用，因为权重应该允许根据更大的目标数据集自由移动。也可以尝试重新初始化更多的权重层，以便利用更一般的较低层，同时让更具体的较高层从随机初始化中训练[yosinski2014transferable](#bib.bib149)；[plested2021non](#bib.bib96)；[abnar2021exploring](#bib.bib1)。
- en: Smaller, more similar datasets
  id: totrans-533
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 更小、相似度更高的数据集
- en: This scenario is where transfer learning really excels, although more care needs
    to be taken to use effective hyperparameters when the dataset is small [plested2019analysis](#bib.bib95)
    . The optimal learning rate and momentum will likely be low as the weights will
    not need to be moved far from their pretrained values. If they are, overfitting
    the unreliable empirical risk minimizer is more likely with a small dataset. Recent
    regularization techniques like L2-SP, DELTA, BSS, stochastic normalization, etc.
    are likely to improve performance significantly in this case.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，迁移学习确实表现突出，尽管在数据集较小时，需要更加小心使用有效的超参数[plested2019analysis](#bib.bib95)。最优的学习率和动量可能会较低，因为权重不需要从预训练值中移动太远。如果移动距离过大，小数据集更容易导致过拟合不可靠的经验风险最小化器。最近的正则化技术，如L2-SP、DELTA、BSS、随机归一化等，可能会在这种情况下显著提高性能。
- en: Smaller, less similar datasets
  id: totrans-535
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 更小、相似度较低的数据集
- en: In this case transfer learning can be very useful if done well, but can also
    lead to poor results. It is difficult to strike an optimal balance between
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，迁移学习如果做得好，可以非常有用，但也可能导致差劲的结果。很难在
- en: '1.'
  id: totrans-537
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Allowing the weights to move far enough from their pretrained values that the
    model is not using inappropriate features for the classification task
  id: totrans-538
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 允许权重从预训练值中移动足够远，以免模型使用不适合分类任务的特征
- en: '2.'
  id: totrans-539
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Not allowing the weights to overfit the unreliable empirical risk minimizer.
  id: totrans-540
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不允许权重过拟合不可靠的经验风险最小化器。
- en: Given this if there is any way to use a more closely related dataset it is likely
    to improve results. This could be
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有任何方法可以使用更相关的数据集，这可能会改善结果。可能是
- en: '1.'
  id: totrans-542
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Doing unsupervised pretraining on a large, unlabelled, more closely related
    dataset instead of a large, labelled, less similar dataset.
  id: totrans-543
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在一个大型、未标记的、更相关的数据集上进行无监督预训练，而不是在一个大型、标记的、相似度较低的数据集上。
- en: '2.'
  id: totrans-544
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Using a moderately sized closely related dataset either instead of a large source
    dataset for pretraining or as an intermediary fine-tuning step when transferring
    weights from a less related source task to the final target task.
  id: totrans-545
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用一个中等大小、密切相关的数据集，作为预训练的大型源数据集的替代，或在将权重从不太相关的源任务转移到最终目标任务时作为中介微调步骤。
- en: If it is not possible to use a more related dataset then a high initial learning
    rate and momentum should be used, but the learning rate should be decayed quickly.
    Recent regularization techniques like L2-SP, DELTA, BSS, stochastic normalization,
    etc. should not be used on all layers, but in some cases may be beneficial on
    lower layers.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 如果无法使用更相关的数据集，则应使用较高的初始学习率和动量，但学习率应快速衰减。最近的正则化技术，如L2-SP、DELTA、BSS、随机归一化等，不应在所有层中使用，但在某些情况下，可能在较低层中有利。
- en: References
  id: totrans-547
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Samira Abnar, Mostafa Dehghani, Behnam Neyshabur, and Hanie Sedghi. Exploring
    the limits of large scale pre-training. arXiv preprint arXiv:2110.02095, 2021.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Samira Abnar, Mostafa Dehghani, Behnam Neyshabur 和 Hanie Sedghi。探索大规模预训练的极限。arXiv
    预印本 arXiv:2110.02095，2021 年。'
- en: '[2] Pulkit Agrawal, Ross Girshick, and Jitendra Malik. Analyzing the performance
    of multilayer neural networks for object recognition. In European conference on
    computer vision, pages 329–344. Springer, 2014.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Pulkit Agrawal, Ross Girshick 和 Jitendra Malik。分析多层神经网络在物体识别中的性能。在欧洲计算机视觉会议，页面
    329–344。Springer，2014 年。'
- en: '[3] Shekoofeh Azizi, Basil Mustafa, Fiona Ryan, Zachary Beaver, Jan Freyberg,
    Jonathan Deaton, Aaron Loh, Alan Karthikesalingam, Simon Kornblith, Ting Chen,
    et al. Big self-supervised models advance medical image classification. arXiv
    preprint arXiv:2101.05224, 2021.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Shekoofeh Azizi, Basil Mustafa, Fiona Ryan, Zachary Beaver, Jan Freyberg,
    Jonathan Deaton, Aaron Loh, Alan Karthikesalingam, Simon Kornblith, Ting Chen
    等人。大型自监督模型推动医学图像分类的进展。arXiv 预印本 arXiv:2101.05224，2021 年。'
- en: '[4] Hossein Azizpour, Ali Sharif Razavian, Josephine Sullivan, Atsuto Maki,
    and Stefan Carlsson. Factors of transferability for a generic convnet representation.
    IEEE transactions on pattern analysis and machine intelligence, 38(9):1790–1802,
    2015.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Hossein Azizpour, Ali Sharif Razavian, Josephine Sullivan, Atsuto Maki
    和 Stefan Carlsson。通用卷积网络表示的迁移性因素。IEEE 模式分析与机器智能汇刊，38(9)：1790–1802，2015 年。'
- en: '[5] Yajie Bao, Yang Li, Shao-Lun Huang, Lin Zhang, Lizhong Zheng, Amir Zamir,
    and Leonidas Guibas. An information-theoretic approach to transferability in task
    transfer learning. In 2019 IEEE International Conference on Image Processing (ICIP),
    pages 2309–2313\. IEEE, 2019.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Yajie Bao, Yang Li, Shao-Lun Huang, Lin Zhang, Lizhong Zheng, Amir Zamir
    和 Leonidas Guibas。任务迁移学习中的信息论方法。在 2019 年 IEEE 国际图像处理会议（ICIP），页面 2309–2313。IEEE，2019
    年。'
- en: '[6] Samy Bengio. Sharing representations for long tail computer vision problems.
    In Proceedings of the 2015 ACM on International Conference on Multimodal Interaction,
    pages 1–1, 2015.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Samy Bengio。在 2015 年 ACM 多模态互动国际会议论文集，页面 1–1，2015 年。'
- en: '[7] Thomas Berg, Jiongxin Liu, Seung Woo Lee, Michelle L Alexander, David W
    Jacobs, and Peter N Belhumeur. Birdsnap: Large-scale fine-grained visual categorization
    of birds. In Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition, pages 2011–2018, 2014.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Thomas Berg, Jiongxin Liu, Seung Woo Lee, Michelle L Alexander, David W
    Jacobs 和 Peter N Belhumeur。Birdsnap：大规模细粒度鸟类视觉分类。在 IEEE 计算机视觉与模式识别会议论文集，页面 2011–2018，2014
    年。'
- en: '[8] Lukas Bossard, Matthieu Guillaumin, and Luc Van Gool. Food-101 – mining
    discriminative components with random forests. In European Conference on Computer
    Vision, 2014.'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Lukas Bossard, Matthieu Guillaumin 和 Luc Van Gool。Food-101 – 使用随机森林挖掘判别性组件。在欧洲计算机视觉会议，2014
    年。'
- en: '[9] Léon Bottou and Olivier Bousquet. The tradeoffs of large scale learning.
    In Advances in neural information processing systems, pages 161–168, 2008.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Léon Bottou 和 Olivier Bousquet。大规模学习的权衡。在神经信息处理系统进展中，页面 161–168，2008 年。'
- en: '[10] Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
    Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
    et al. Language models are few-shot learners. arXiv preprint arXiv:2005.14165,
    2020.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
    Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell
    等人。语言模型是少量样本学习者。arXiv 预印本 arXiv:2005.14165，2020 年。'
- en: '[11] Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig
    Adam. Encoder-decoder with atrous separable convolution for semantic image segmentation.
    In Proceedings of the European conference on computer vision (ECCV), pages 801–818,
    2018.'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff 和 Hartwig
    Adam。用于语义图像分割的 atrous 可分离卷积编码器-解码器。在欧洲计算机视觉会议（ECCV）论文集，页面 801–818，2018 年。'
- en: '[12] Xinyang Chen, Sinan Wang, Bo Fu, Mingsheng Long, and Jianmin Wang. Catastrophic
    forgetting meets negative transfer: Batch spectral shrinkage for safe transfer
    learning. openreview, 2019.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Xinyang Chen, Sinan Wang, Bo Fu, Mingsheng Long 和 Jianmin Wang。灾难性遗忘遇上负迁移：用于安全迁移学习的批光谱收缩。openreview，2019
    年。'
- en: '[13] Brian Chu, Vashisht Madhavan, Oscar Beijbom, Judy Hoffman, and Trevor
    Darrell. Best practices for fine-tuning visual classifiers to new domains. In
    European conference on computer vision, pages 435–442. Springer, 2016.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Brian Chu, Vashisht Madhavan, Oscar Beijbom, Judy Hoffman 和 Trevor Darrell。将视觉分类器微调到新领域的最佳实践。在欧洲计算机视觉会议，页面
    435–442。Springer，2016 年。'
- en: '[14] Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea
    Vedaldi. Describing textures in the wild. In Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition, pages 3606–3613, 2014.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, 和 Andrea
    Vedaldi. 描述自然界中的纹理. 在 IEEE 计算机视觉与模式识别会议论文集, 页码 3606–3613, 2014.'
- en: '[15] Gabriela Csurka. Domain adaptation for visual applications: A comprehensive
    survey. arXiv preprint arXiv:1702.05374, 2017.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Gabriela Csurka. 视觉应用中的领域适应: 一项全面的调查. arXiv 预印本 arXiv:1702.05374, 2017.'
- en: '[16] Yin Cui, Yang Song, Chen Sun, Andrew Howard, and Serge Belongie. Large
    scale fine-grained categorization and domain-specific transfer learning. In Proceedings
    of the IEEE conference on computer vision and pattern recognition, pages 4109–4118,
    2018.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Yin Cui, Yang Song, Chen Sun, Andrew Howard, 和 Serge Belongie. 大规模细粒度分类和领域特定迁移学习.
    在 IEEE 计算机视觉与模式识别会议论文集, 页码 4109–4118, 2018.'
- en: '[17] Yin Cui, Feng Zhou, Yuanqing Lin, and Serge Belongie. Fine-grained categorization
    and dataset bootstrapping using deep metric learning with humans in the loop.
    In Proceedings of the IEEE conference on computer vision and pattern recognition,
    pages 1153–1162, 2016.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Yin Cui, Feng Zhou, Yuanqing Lin, 和 Serge Belongie. 使用深度度量学习与人工参与的细粒度分类和数据集引导.
    在 IEEE 计算机视觉与模式识别会议论文集, 页码 1153–1162, 2016.'
- en: '[18] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet:
    A Large-Scale Hierarchical Image Database. In CVPR09, 2009.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, 和 L. Fei-Fei. ImageNet:
    一个大规模的层次化图像数据库. 在 CVPR09, 2009.'
- en: '[19] Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos Zafeiriou. Arcface:
    Additive angular margin loss for deep face recognition. In Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4690–4699,
    2019.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Jiankang Deng, Jia Guo, Niannan Xue, 和 Stefanos Zafeiriou. Arcface: 用于深度人脸识别的附加角度边际损失.
    在 IEEE/CVF 计算机视觉与模式识别会议论文集, 页码 4690–4699, 2019.'
- en: '[20] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman.
    The PASCAL Visual Object Classes Challenge 2007 (VOC2007) Results. http://www.pascal-network.org/challenges/VOC/voc2007/
    workshop/index.html.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, 和 A. Zisserman.
    PASCAL 视觉对象类别挑战 2007 (VOC2007) 结果. http://www.pascal-network.org/challenges/VOC/voc2007/
    workshop/index.html.'
- en: '[21] Li Fei-Fei, Rob Fergus, and Pietro Perona. Learning generative visual
    models from few training examples: An incremental bayesian approach tested on
    101 object categories. In 2004 conference on computer vision and pattern recognition
    workshop, pages 178–178\. IEEE, 2004.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Li Fei-Fei, Rob Fergus, 和 Pietro Perona. 从少量训练样本中学习生成视觉模型: 一种增量贝叶斯方法，在
    101 个对象类别上进行测试. 在 2004 计算机视觉与模式识别会议研讨会, 页码 178–178. IEEE, 2004.'
- en: '[22] Robert M French. Catastrophic forgetting in connectionist networks. Trends
    in cognitive sciences, 3(4):128–135, 1999.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Robert M French. 连接主义网络中的灾难性遗忘. 认知科学趋势, 3(4):128–135, 1999.'
- en: '[23] Alberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor Villena-Martinez,
    Pablo Martinez-Gonzalez, and Jose Garcia-Rodriguez. A survey on deep learning
    techniques for image and video semantic segmentation. Applied Soft Computing,
    70:41–65, 2018.'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Alberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor Villena-Martinez,
    Pablo Martinez-Gonzalez, 和 Jose Garcia-Rodriguez. 深度学习技术在图像和视频语义分割中的应用调查. 应用软计算,
    70:41–65, 2018.'
- en: '[24] Weifeng Ge and Yizhou Yu. Borrowing treasures from the wealthy: Deep transfer
    learning through selective joint fine-tuning. In Proceedings of the IEEE conference
    on computer vision and pattern recognition, pages 1086–1095, 2017.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Weifeng Ge 和 Yizhou Yu. 从富有者那里借取宝贵的知识: 通过选择性联合微调的深度迁移学习. 在 IEEE 计算机视觉与模式识别会议论文集,
    页码 1086–1095, 2017.'
- en: '[25] Swarnendu Ghosh, Nibaran Das, Ishita Das, and Ujjwal Maulik. Understanding
    deep learning techniques for image segmentation. ACM Computing Surveys (CSUR),
    52(4):1–35, 2019.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Swarnendu Ghosh, Nibaran Das, Ishita Das, 和 Ujjwal Maulik. 理解图像分割的深度学习技术.
    ACM 计算机调查 (CSUR), 52(4):1–35, 2019.'
- en: '[26] Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik. Rich
    feature hierarchies for accurate object detection and semantic segmentation. In
    Proceedings of the IEEE conference on computer vision and pattern recognition,
    pages 580–587, 2014.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Ross Girshick, Jeff Donahue, Trevor Darrell, 和 Jitendra Malik. 精确目标检测和语义分割的丰富特征层次.
    在 IEEE 计算机视觉与模式识别会议论文集, 页码 580–587, 2014.'
- en: '[27] Boqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman. Geodesic flow kernel
    for unsupervised domain adaptation. In 2012 IEEE Conference on Computer Vision
    and Pattern Recognition, pages 2066–2073\. IEEE, 2012.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Boqing Gong, Yuan Shi, Fei Sha, 和 Kristen Grauman. 用于无监督领域适应的测地流核。发表于
    2012 年 IEEE 计算机视觉与模式识别会议，第2066–2073页。IEEE，2012年。'
- en: '[28] Nicolas Gonthier, Yann Gousseau, and Saïd Ladjal. An analysis of the transfer
    learning of convolutional neural networks for artistic images. arXiv preprint
    arXiv:2011.02727, 2020.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Nicolas Gonthier, Yann Gousseau, 和 Saïd Ladjal. 卷积神经网络在艺术图像中的迁移学习分析。arXiv
    预印本 arXiv:2011.02727，2020年。'
- en: '[29] Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep
    learning, volume 1. MIT press Cambridge, 2016.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Ian Goodfellow, Yoshua Bengio, Aaron Courville, 和 Yoshua Bengio. 深度学习，第1卷。MIT出版社剑桥，2016年。'
- en: '[30] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
    Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets.
    Advances in neural information processing systems, 27, 2014.'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
    Sherjil Ozair, Aaron Courville, 和 Yoshua Bengio. 生成对抗网络。神经信息处理系统进展，第27卷，2014年。'
- en: '[31] Gregory Griffin, Alex Holub, and Pietro Perona. Caltech-256 object category
    dataset. authors.library.caltech.edu, 2007.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Gregory Griffin, Alex Holub, 和 Pietro Perona. Caltech-256 物体类别数据集。authors.library.caltech.edu，2007年。'
- en: '[32] Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman, Tajana Rosing,
    and Rogerio Feris. Spottune: transfer learning through adaptive fine-tuning. In
    Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    pages 4805–4814, 2019.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman, Tajana Rosing,
    和 Rogerio Feris. Spottune：通过自适应微调进行迁移学习。发表于 IEEE 计算机视觉与模式识别会议论文集，第4805–4814页，2019年。'
- en: '[33] Kevin Gurney. An introduction to neural networks. CRC press, 1997.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Kevin Gurney. 神经网络导论。CRC出版社，1997年。'
- en: '[34] Kaiming He, Ross Girshick, and Piotr Dollár. Rethinking imagenet pre-training.
    arXiv preprint arXiv:1811.08883, 2018.'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Kaiming He, Ross Girshick, 和 Piotr Dollár. 重新思考 ImageNet 预训练。arXiv 预印本
    arXiv:1811.08883，2018年。'
- en: '[35] Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick. Mask r-cnn.
    In Proceedings of the IEEE international conference on computer vision, pages
    2961–2969, 2017.'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Kaiming He, Georgia Gkioxari, Piotr Dollár, 和 Ross Girshick. Mask R-CNN。发表于
    IEEE 国际计算机视觉会议论文集，第2961–2969页，2017年。'
- en: '[36] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning
    for image recognition. In Proceedings of the IEEE conference on computer vision
    and pattern recognition, pages 770–778, 2016.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Kaiming He, Xiangyu Zhang, Shaoqing Ren, 和 Jian Sun. 深度残差学习用于图像识别。发表于
    IEEE 计算机视觉与模式识别会议论文集，第770–778页，2016年。'
- en: '[37] Michal Heker and Hayit Greenspan. Joint liver lesion segmentation and
    classification via transfer learning. arXiv preprint arXiv:2004.12352, 2020.'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Michal Heker 和 Hayit Greenspan. 通过迁移学习联合肝脏病变分割与分类。arXiv 预印本 arXiv:2004.12352，2020年。'
- en: '[38] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness
    to common corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Dan Hendrycks 和 Thomas Dietterich. 基准测试神经网络对常见扰动和干扰的鲁棒性。arXiv 预印本 arXiv:1903.12261，2019年。'
- en: '[39] Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song.
    Natural adversarial examples. In Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition, pages 15262–15271, 2021.'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, 和 Dawn Song.
    自然对抗样本。发表于 IEEE/CVF 计算机视觉与模式识别会议论文集，第15262–15271页，2021年。'
- en: '[40] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge
    in a neural network. arXiv preprint arXiv:1503.02531, 2015.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Geoffrey Hinton, Oriol Vinyals, 和 Jeff Dean. 提炼神经网络中的知识。arXiv 预印本 arXiv:1503.02531，2015年。'
- en: '[41] Kurt Hornik, Maxwell Stinchcombe, Halbert White, et al. Multilayer feedforward
    networks are universal approximators. Neural networks, 2(5):359–366, 1989.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Kurt Hornik, Maxwell Stinchcombe, Halbert White 等. 多层前馈网络是通用逼近器。神经网络，第2卷，第5期：359–366，1989年。'
- en: '[42] Minyoung Huh, Pulkit Agrawal, and Alexei A Efros. What makes imagenet
    good for transfer learning? arXiv preprint arXiv:1608.08614, 2016.'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Minyoung Huh, Pulkit Agrawal, 和 Alexei A Efros. 什么使得 ImageNet 适合迁移学习？arXiv
    预印本 arXiv:1608.08614，2016年。'
- en: '[43] Sergey Ioffe. Batch renormalization: Towards reducing minibatch dependence
    in batch-normalized models. arXiv preprint arXiv:1702.03275, 2017.'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Sergey Ioffe. 批量重标定：减少批量归一化模型中的小批量依赖。arXiv 预印本 arXiv:1702.03275，2017年。'
- en: '[44] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating
    deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167,
    2015.'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Sergey Ioffe 和 Christian Szegedy. 批量归一化：通过减少内部协变量偏移加速深度网络训练。arXiv 预印本
    arXiv:1502.03167, 2015。'
- en: '[45] Yunho Jeon, Yongseok Choi, Jaesun Park, Subin Yi, Dongyeon Cho, and Jiwon
    Kim. Sample-based regularization: A transfer learning strategy toward better generalization.
    arXiv preprint arXiv:2007.05181, 2020.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] Yunho Jeon, Yongseok Choi, Jaesun Park, Subin Yi, Dongyeon Cho 和 Jiwon
    Kim. 基于样本的正则化：一种面向更好泛化的迁移学习策略。arXiv 预印本 arXiv:2007.05181, 2020。'
- en: '[46] Junguang Jiang, Yang Shu, Jianmin Wang, and Mingsheng Long. Transferability
    in deep learning: A survey. arXiv preprint arXiv:2201.05867, 2022.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] Junguang Jiang, Yang Shu, Jianmin Wang 和 Mingsheng Long. 深度学习中的迁移性：综述。arXiv
    预印本 arXiv:2201.05867, 2022。'
- en: '[47] Longlong Jing and Yingli Tian. Self-supervised visual feature learning
    with deep neural networks: A survey. IEEE transactions on pattern analysis and
    machine intelligence, 2020.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Longlong Jing 和 Yingli Tian. 使用深度神经网络的自监督视觉特征学习：综述。IEEE 模式分析与机器智能学报, 2020。'
- en: '[48] Mahmut Kaya and Hasan Şakir Bilge. Deep metric learning: A survey. Symmetry,
    11(9):1066, 2019.'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Mahmut Kaya 和 Hasan Şakir Bilge. 深度度量学习：综述。对称性, 11(9):1066, 2019。'
- en: '[49] Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, and Fei-Fei Li.
    Novel dataset for fine-grained image categorization: Stanford dogs. In Proc. CVPR
    Workshop on Fine-Grained Visual Categorization (FGVC), volume 2, 2011.'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao 和 Fei-Fei Li.
    用于细粒度图像分类的新数据集：斯坦福犬。CVPR细粒度视觉分类研讨会论文集, 卷2, 2011。'
- en: '[50] Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica
    Yung, Sylvain Gelly, and Neil Houlsby. Big transfer (bit): General visual representation
    learning. arXiv preprint arXiv:1912.11370, 2019.'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica
    Yung, Sylvain Gelly 和 Neil Houlsby. 大规模迁移 (BIT)：通用视觉表示学习。arXiv 预印本 arXiv:1912.11370,
    2019。'
- en: '[51] Simon Kornblith, Ting Chen, Honglak Lee, and Mohammad Norouzi. Why do
    better loss functions lead to less transferable features? Advances in Neural Information
    Processing Systems, 34, 2021.'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Simon Kornblith, Ting Chen, Honglak Lee 和 Mohammad Norouzi. 为什么更好的损失函数会导致更少的可迁移特征？神经信息处理系统进展,
    34, 2021。'
- en: '[52] Simon Kornblith, Jonathon Shlens, and Quoc V Le. Do better imagenet models
    transfer better? In Proceedings of the IEEE Conference on Computer Vision and
    Pattern Recognition, pages 2661–2671, 2019.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] Simon Kornblith, Jonathon Shlens 和 Quoc V Le. 更好的 Imagenet 模型是否能更好迁移？在
    IEEE 计算机视觉与模式识别会议论文集, 页码 2661–2671, 2019。'
- en: '[53] Zhi Kou, Kaichao You, Mingsheng Long, and Jianmin Wang. Stochastic normalization.
    Advances in Neural Information Processing Systems, 33, 2020.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] Zhi Kou, Kaichao You, Mingsheng Long 和 Jianmin Wang. 随机归一化。神经信息处理系统进展,
    33, 2020。'
- en: '[54] Oren Z Kraus, Ben T Grys, Jimmy Ba, Yolanda Chong, Brendan J Frey, Charles
    Boone, and Brenda J Andrews. Automated analysis of high-content microscopy data
    with deep learning. Molecular systems biology, 13(4):924, 2017.'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] Oren Z Kraus, Ben T Grys, Jimmy Ba, Yolanda Chong, Brendan J Frey, Charles
    Boone 和 Brenda J Andrews. 使用深度学习的高内容显微镜数据自动分析。分子系统生物学, 13(4):924, 2017。'
- en: '[55] Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3d object representations
    for fine-grained categorization. In 4th International IEEE Workshop on 3D Representation
    and Recognition (3dRR-13), Sydney, Australia, 2013.'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Jonathan Krause, Michael Stark, Jia Deng 和 Li Fei-Fei. 用于细粒度分类的 3D 物体表示。在第四届国际
    IEEE 3D 表示与识别研讨会 (3dRR-13), 悉尼, 澳大利亚, 2013。'
- en: '[56] Sajja Tulasi Krishna and Hemantha Kumar Kalluri. Deep learning and transfer
    learning approaches for image classification. International Journal of Recent
    Technology and Engineering (IJRTE), 7(5S4):427–432, 2019.'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Sajja Tulasi Krishna 和 Hemantha Kumar Kalluri. 图像分类的深度学习和迁移学习方法。国际近期技术与工程期刊
    (IJRTE), 7(5S4):427–432, 2019。'
- en: '[57] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features
    from tiny images. cs.toronto.edu, 2009.'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] Alex Krizhevsky, Geoffrey Hinton 等. 从微小图像中学习多层特征。cs.toronto.edu, 2009。'
- en: '[58] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification
    with deep convolutional neural networks. In Advances in neural information processing
    systems, pages 1097–1105, 2012.'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] Alex Krizhevsky, Ilya Sutskever 和 Geoffrey E Hinton. 使用深度卷积神经网络的 ImageNet
    分类。在神经信息处理系统进展, 页码 1097–1105, 2012。'
- en: '[59] Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum. Human-level
    concept learning through probabilistic program induction. Science, 350(6266):1332–1338,
    2015.'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Brenden M Lake, Ruslan Salakhutdinov 和 Joshua B Tenenbaum. 通过概率程序归纳实现人类水平的概念学习。科学,
    350(6266):1332–1338, 2015。'
- en: '[60] Christian Ledig, Lucas Theis, Ferenc Huszár, Jose Caballero, Andrew Cunningham,
    Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et al.
    Photo-realistic single image super-resolution using a generative adversarial network.
    In Proceedings of the IEEE conference on computer vision and pattern recognition,
    pages 4681–4690, 2017.'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] 克里斯蒂安·莱迪格、卢卡斯·泰斯、费伦茨·胡萨尔、何塞·卡巴列罗、安德鲁·坎宁安、亚历杭德罗·阿科斯塔、安德鲁·艾特肯、阿利汗·特贾尼、约翰内斯·托茨、泽汉·王等。**使用生成对抗网络的真实感单图像超分辨率**。在IEEE计算机视觉与模式识别会议录，第4681–4690页，2017年。'
- en: '[61] Hao Li, Pratik Chaudhari, Hao Yang, Michael Lam, Avinash Ravichandran,
    Rahul Bhotika, and Stefano Soatto. Rethinking the hyperparameters for fine-tuning.
    arXiv preprint arXiv:2002.11770, 2020.'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] 李浩、普拉提克·乔杜哈里、杨浩、迈克尔·拉姆、阿维纳什·拉维钱德兰、拉胡尔·博提卡和斯特凡诺·索托。**重新思考微调的超参数**。arXiv预印本
    arXiv:2002.11770，2020年。'
- en: '[62] Shan Li and Weihong Deng. Deep facial expression recognition: A survey.
    IEEE Transactions on Affective Computing, 2020.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] 李山和邓伟宏。**深度面部表情识别：综述**。IEEE情感计算汇刊，2020年。'
- en: '[63] Xingjian Li, Haoyi Xiong, Hanchao Wang, Yuxuan Rao, Liping Liu, and Jun
    Huan. Delta: Deep learning transfer using feature map with attention for convolutional
    networks. arXiv preprint arXiv:1901.09229, 2019.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] 李兴建、熊浩毅、王汉超、饶玉轩、刘丽萍和关军。**Delta：使用注意力的深度学习迁移**。arXiv预印本 arXiv:1901.09229，2019年。'
- en: '[64] Xuhong Li, Yves Grandvalet, and Franck Davoine. Explicit inductive bias
    for transfer learning with convolutional networks. arXiv preprint arXiv:1802.01483,
    2018.'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] 李旭红、伊夫·格朗瓦莱和弗朗克·达沃内。用于卷积网络迁移学习的**显式归纳偏差**。arXiv预印本 arXiv:1802.01483，2018年。'
- en: '[65] Xuhong Li, Yves Grandvalet, and Franck Davoine. A baseline regularization
    scheme for transfer learning with convolutional neural networks. Pattern Recognition,
    98:107049, 2020.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] 李旭红、伊夫·格朗瓦莱和弗朗克·达沃内。用于卷积神经网络迁移学习的**基线正则化方案**。模式识别，98:107049，2020年。'
- en: '[66] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona,
    Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. Microsoft coco: Common objects
    in context. In European conference on computer vision, pages 740–755. Springer,
    2014.'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] 林宗义、迈克尔·马伊尔、塞尔日·贝隆吉、詹姆斯·海斯、皮耶特罗·佩罗纳、德瓦·拉马南、皮奥特·多拉尔和C·劳伦斯·齐特尼克。**Microsoft
    COCO：上下文中的常见物体**。在欧洲计算机视觉会议上，第740–755页。斯普林格，2014年。'
- en: '[67] Hong Liu, Mingsheng Long, Jianmin Wang, and Michael I Jordan. Towards
    understanding the transferability of deep representations. arXiv preprint arXiv:1909.12031,
    2019.'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] 刘洪、龙铭胜、王建民和迈克尔·I·乔丹。**理解深度表示的可迁移性**。arXiv预印本 arXiv:1909.12031，2019年。'
- en: '[68] Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, and Le Song.
    Sphereface: Deep hypersphere embedding for face recognition. In Proceedings of
    the IEEE conference on computer vision and pattern recognition, pages 212–220,
    2017.'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] 刘伟扬、温艳东、俞智定、李明、比克沙·拉杰和宋乐。**SphereFace：用于面部识别的深度超球面嵌入**。在IEEE计算机视觉与模式识别会议录，第212–220页，2017年。'
- en: '[69] Weiyang Liu, Yandong Wen, Zhiding Yu, and Meng Yang. Large-margin softmax
    loss for convolutional neural networks. In ICML, volume 2, page 7, 2016.'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] 刘伟扬、温艳东、俞智定和杨萌。卷积神经网络的**大边距软最大损失**。在ICML，第2卷，第7页，2016年。'
- en: '[70] Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar
    Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. Exploring the
    limits of weakly supervised pretraining. In Proceedings of the European Conference
    on Computer Vision (ECCV), pages 181–196, 2018.'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] 德鲁夫·马哈詹、罗斯·吉尔希克、维尼什·拉曼纳坦、何恺明、马诺哈尔·帕卢里、李翼轩、阿什温·巴兰比和劳伦斯·范德马滕。探索**弱监督预训练的极限**。在欧洲计算机视觉会议（ECCV）会议录，第181–196页，2018年。'
- en: '[71] S. Maji, J. Kannala, E. Rahtu, M. Blaschko, and A. Vedaldi. Fine-grained
    visual classification of aircraft. Technical report, Toyota Technological Institute
    at Chicago, 2013.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] S. 马吉、J. 卡纳拉、E. 拉赫图、M. 布拉什科和A. 维达尔迪。**飞机的细粒度视觉分类**。技术报告，芝加哥丰田技术学院，2013年。'
- en: '[72] Fabio Maria Carlucci, Lorenzo Porzi, Barbara Caputo, Elisa Ricci, and
    Samuel Rota Bulo. Autodial: Automatic domain alignment layers. In Proceedings
    of the IEEE International Conference on Computer Vision, pages 5067–5075, 2017.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] 法比奥·玛丽亚·卡尔鲁奇、洛伦佐·波尔齐、芭芭拉·卡普托、艾丽莎·里奇和塞缪尔·罗塔·布洛。**Autodial：自动域对齐层**。在IEEE国际计算机视觉会议上，第5067–5075页，2017年。'
- en: '[73] Iacopo Masi, Yue Wu, Tal Hassner, and Prem Natarajan. Deep face recognition:
    A survey. In 2018 31st SIBGRAPI conference on graphics, patterns and images (SIBGRAPI),
    pages 471–478\. IEEE, 2018.'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] 伊亚科波·马西、吴越、塔尔·哈斯纳和普瑞姆·纳塔拉詹。**深度面部识别：综述**。在2018年第31届SIBGRAPI图形、模式和图像会议（SIBGRAPI）上，第471–478页。IEEE，2018年。'
- en: '[74] Maciej A Mazurowski, Mateusz Buda, Ashirbani Saha, and Mustafa R Bashir.
    Deep learning in radiology: An overview of the concepts and a survey of the state
    of the art with focus on mri. Journal of magnetic resonance imaging, 49(4):939–954,
    2019.'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] Maciej A Mazurowski, Mateusz Buda, Ashirbani Saha, 和 Mustafa R Bashir.
    放射学中的深度学习：概念概述及聚焦于 MRI 的最新进展调查。*《磁共振成像杂志》*，49(4):939–954, 2019.'
- en: '[75] Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist
    networks: The sequential learning problem. In Psychology of learning and motivation,
    volume 24, pages 109–165\. Elsevier, 1989.'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] Michael McCloskey 和 Neal J Cohen. 连接主义网络中的灾难性干扰：序列学习问题。发表于《学习与动机心理学》，第
    24 卷，页码 109–165\. Elsevier, 1989.'
- en: '[76] Thomas Mensink, Jasper Uijlings, Alina Kuznetsova, Michael Gygli, and
    Vittorio Ferrari. Factors of influence for transfer learning across diverse appearance
    domains and task types. arXiv preprint arXiv:2103.13318, 2021.'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] Thomas Mensink, Jasper Uijlings, Alina Kuznetsova, Michael Gygli, 和 Vittorio
    Ferrari. 在不同外观领域和任务类型中的迁移学习影响因素。arXiv 预印本 arXiv:2103.13318, 2021.'
- en: '[77] George A Miller. Wordnet: a lexical database for english. Communications
    of the ACM, 38(11):39–41, 1995.'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] George A Miller. Wordnet：一个英语词汇数据库。*《ACM 通讯》*，38(11):39–41, 1995.'
- en: '[78] Shervin Minaee, Yuri Boykov, Fatih Porikli, Antonio Plaza, Nasser Kehtarnavaz,
    and Demetri Terzopoulos. Image segmentation using deep learning: A survey. arXiv
    preprint arXiv:2001.05566, 2020.'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] Shervin Minaee, Yuri Boykov, Fatih Porikli, Antonio Plaza, Nasser Kehtarnavaz,
    和 Demetri Terzopoulos. 使用深度学习进行图像分割：综述。arXiv 预印本 arXiv:2001.05566, 2020.'
- en: '[79] Tom M Mitchell et al. Machine learning. 1997. Burr Ridge, IL: McGraw Hill,
    45(37):870–877, 1997.'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] Tom M Mitchell 等. 《机器学习》。1997年。Burr Ridge, IL: McGraw Hill, 45(37):870–877,
    1997.'
- en: '[80] Romain Mormont, Pierre Geurts, and Raphaël Marée. Comparison of deep transfer
    learning strategies for digital pathology. In Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition Workshops, pages 2262–2271, 2018.'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] Romain Mormont, Pierre Geurts, 和 Raphaël Marée. 数字病理学深度迁移学习策略的比较。发表于 IEEE
    计算机视觉与模式识别会议论文集，页码 2262–2271, 2018.'
- en: '[81] Stefan Munder and Dariu M Gavrila. An experimental study on pedestrian
    classification. IEEE transactions on pattern analysis and machine intelligence,
    28(11):1863–1868, 2006.'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] Stefan Munder 和 Dariu M Gavrila. 关于行人分类的实验研究。*IEEE 模式分析与机器智能学报*，28(11):1863–1868,
    2006.'
- en: '[82] Kevin Musgrave, Serge Belongie, and Ser-Nam Lim. A metric learning reality
    check. In European Conference on Computer Vision, pages 681–699. Springer, 2020.'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] Kevin Musgrave, Serge Belongie, 和 Ser-Nam Lim. 量度学习的现实检验。发表于欧洲计算机视觉会议，页码
    681–699. Springer, 2020.'
- en: '[83] Basil Mustafa, Aaron Loh, Jan Freyberg, Patricia MacWilliams, Megan Wilson,
    Scott Mayer McKinney, Marcin Sieniek, Jim Winkens, Yuan Liu, Peggy Bui, et al.
    Supervised transfer learning at scale for medical imaging. arXiv preprint arXiv:2101.05913,
    2021.'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] Basil Mustafa, Aaron Loh, Jan Freyberg, Patricia MacWilliams, Megan Wilson,
    Scott Mayer McKinney, Marcin Sieniek, Jim Winkens, Yuan Liu, Peggy Bui 等. 大规模医疗影像的监督迁移学习。arXiv
    预印本 arXiv:2101.05913, 2021.'
- en: '[84] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y
    Ng. Reading digits in natural images with unsupervised feature learning. research.google,
    2011.'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, 和 Andrew
    Y Ng. 在自然图像中通过无监督特征学习读取数字。research.google, 2011.'
- en: '[85] Behnam Neyshabur, Hanie Sedghi, and Chiyuan Zhang. What is being transferred
    in transfer learning? arXiv preprint arXiv:2008.11687, 2020.'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] Behnam Neyshabur, Hanie Sedghi, 和 Chiyuan Zhang. 迁移学习中转移的是什么？arXiv 预印本
    arXiv:2008.11687, 2020.'
- en: '[86] Hong-Wei Ng, Viet Dung Nguyen, Vassilios Vonikakis, and Stefan Winkler.
    Deep learning for emotion recognition on small datasets using transfer learning.
    In Proceedings of the 2015 ACM on international conference on multimodal interaction,
    pages 443–449, 2015.'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] Hong-Wei Ng, Viet Dung Nguyen, Vassilios Vonikakis, 和 Stefan Winkler.
    使用迁移学习对小数据集进行情感识别的深度学习。发表于 2015 年 ACM 国际多模态互动会议，页码 443–449, 2015.'
- en: '[87] Jiquan Ngiam, Daiyi Peng, Vijay Vasudevan, Simon Kornblith, Quoc V Le,
    and Ruoming Pang. Domain adaptive transfer learning with specialist models. arXiv
    preprint arXiv:1811.07056, 2018.'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] Jiquan Ngiam, Daiyi Peng, Vijay Vasudevan, Simon Kornblith, Quoc V Le,
    和 Ruoming Pang. 使用专门模型的领域自适应迁移学习。arXiv 预印本 arXiv:1811.07056, 2018.'
- en: '[88] Cuong Nguyen, Tal Hassner, Matthias Seeger, and Cedric Archambeau. Leep:
    A new measure to evaluate transferability of learned representations. In International
    Conference on Machine Learning, pages 7294–7305\. PMLR, 2020.'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] Cuong Nguyen, Tal Hassner, Matthias Seeger, 和 Cedric Archambeau. Leep：一种新的衡量学习表示转移能力的指标。发表于国际机器学习大会，页码
    7294–7305\. PMLR, 2020.'
- en: '[89] Maria-Elena Nilsback and Andrew Zisserman. Automated flower classification
    over a large number of classes. In 2008 Sixth Indian Conference on Computer Vision,
    Graphics & Image Processing, pages 722–729\. IEEE, 2008.'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] Maria-Elena Nilsback 和 Andrew Zisserman. 在大量类别中进行自动化花卉分类。发表于 2008 第六届印度计算机视觉、图形与图像处理会议，页码
    722–729。IEEE，2008年。'
- en: '[90] Tom Le Paine, Pooya Khorrami, Wei Han, and Thomas S Huang. An analysis
    of unsupervised pre-training in light of recent advances. arXiv preprint arXiv:1412.6597,
    2014.'
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] Tom Le Paine、Pooya Khorrami、Wei Han 和 Thomas S Huang. 针对近期进展的无监督预训练分析。arXiv
    预印本 arXiv:1412.6597，2014年。'
- en: '[91] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions
    on knowledge and data engineering, 22(10):1345–1359, 2009.'
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] Sinno Jialin Pan 和 Qiang Yang. 迁移学习综述。IEEE 知识与数据工程汇刊，22(10):1345–1359，2009年。'
- en: '[92] Omkar M Parkhi, Andrea Vedaldi, Andrew Zisserman, and CV Jawahar. Cats
    and dogs. In 2012 IEEE conference on computer vision and pattern recognition,
    pages 3498–3505\. IEEE, 2012.'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] Omkar M Parkhi、Andrea Vedaldi、Andrew Zisserman 和 CV Jawahar. 猫与狗。发表于 2012
    IEEE 计算机视觉与模式识别会议，页码 3498–3505。IEEE，2012年。'
- en: '[93] Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A
    Efros. Context encoders: Feature learning by inpainting. In Proceedings of the
    IEEE conference on computer vision and pattern recognition, pages 2536–2544, 2016.'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] Deepak Pathak、Philipp Krahenbuhl、Jeff Donahue、Trevor Darrell 和 Alexei
    A Efros. 上下文编码器：通过修复进行特征学习。发表于 IEEE 计算机视觉与模式识别会议论文集，页码 2536–2544，2016年。'
- en: '[94] Shmuel Peleg, Michael Werman, and Hillel Rom. A unified approach to the
    change of resolution: Space and gray-level. IEEE Transactions on Pattern Analysis
    and Machine Intelligence, 11(7):739–742, 1989.'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] Shmuel Peleg、Michael Werman 和 Hillel Rom. 统一的分辨率变化方法：空间和灰度级别。IEEE 模式分析与机器智能汇刊，11(7):739–742，1989年。'
- en: '[95] Jo Plested and Tom Gedeon. An analysis of the interaction between transfer
    learning protocols in deep neural networks. In International Conference on Neural
    Information Processing, pages 312–323\. Springer, 2019.'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] Jo Plested 和 Tom Gedeon. 深度神经网络中迁移学习协议之间的交互分析。发表于国际神经信息处理会议，页码 312–323。Springer，2019年。'
- en: '[96] Jo Plested, Xuyang Shen, and Tom Gedeon. Non-binary deep transfer learning
    for imageclassification. arXiv e-prints, page arXiv:2107.08585, July 2021.'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] Jo Plested、Xuyang Shen 和 Tom Gedeon. 非二元深度迁移学习用于图像分类。arXiv 电子印刷本，页面 arXiv:2107.08585，2021年7月。'
- en: '[97] Joan Puigcerver, Carlos Riquelme, Basil Mustafa, Cedric Renggli, André Susano
    Pinto, Sylvain Gelly, Daniel Keysers, and Neil Houlsby. Scalable transfer learning
    with expert models. arXiv preprint arXiv:2009.13239, 2020.'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] Joan Puigcerver、Carlos Riquelme、Basil Mustafa、Cedric Renggli、André Susano
    Pinto、Sylvain Gelly、Daniel Keysers 和 Neil Houlsby. 可扩展的专家模型迁移学习。arXiv 预印本 arXiv:2009.13239，2020年。'
- en: '[98] Ariadna Quattoni and Antonio Torralba. Recognizing indoor scenes. In 2009
    IEEE Conference on Computer Vision and Pattern Recognition, pages 413–420\. IEEE,
    2009.'
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] Ariadna Quattoni 和 Antonio Torralba. 室内场景识别。发表于 2009 IEEE 计算机视觉与模式识别会议，页码
    413–420。IEEE，2009年。'
- en: '[99] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation
    learning with deep convolutional generative adversarial networks. arXiv preprint
    arXiv:1511.06434, 2015.'
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] Alec Radford、Luke Metz 和 Soumith Chintala. 使用深度卷积生成对抗网络的无监督表示学习。arXiv
    预印本 arXiv:1511.06434，2015年。'
- en: '[100] Maithra Raghu, Chiyuan Zhang, Jon Kleinberg, and Samy Bengio. Transfusion:
    Understanding transfer learning for medical imaging. arXiv preprint arXiv:1902.07208,
    2019.'
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] Maithra Raghu、Chiyuan Zhang、Jon Kleinberg 和 Samy Bengio. Transfusion:
    理解医学影像的迁移学习。arXiv 预印本 arXiv:1902.07208，2019年。'
- en: '[101] Rajeev Ranjan, Carlos D Castillo, and Rama Chellappa. L2-constrained
    softmax loss for discriminative face verification. arXiv preprint arXiv:1703.09507,
    2017.'
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] Rajeev Ranjan、Carlos D Castillo 和 Rama Chellappa. 用于判别性人脸验证的 L2 约束 softmax
    损失。arXiv 预印本 arXiv:1703.09507，2017年。'
- en: '[102] Roger Ratcliff. Connectionist models of recognition memory: constraints
    imposed by learning and forgetting functions. Psychological review, 97(2):285,
    1990.'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] Roger Ratcliff. 识别记忆的联结主义模型：学习和遗忘函数所施加的约束。心理学评论，97(2):285，1990年。'
- en: '[103] Sylvestre-Alvise Rebuffi, Hakan Bilen, and Andrea Vedaldi. Learning multiple
    visual domains with residual adapters. In Advances in Neural Information Processing
    Systems, pages 506–516, 2017.'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] Sylvestre-Alvise Rebuffi、Hakan Bilen 和 Andrea Vedaldi. 使用残差适配器学习多个视觉领域。发表于神经信息处理系统进展，页码
    506–516，2017年。'
- en: '[104] Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only
    look once: Unified, real-time object detection. In Proceedings of the IEEE conference
    on computer vision and pattern recognition, pages 779–788, 2016.'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] Joseph Redmon、Santosh Divvala、Ross Girshick 和 Ali Farhadi。你只看一次：统一的实时物体检测。发表于
    IEEE 计算机视觉与模式识别会议论文集，页码 779–788，2016年。'
- en: '[105] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn:
    Towards real-time object detection with region proposal networks. Advances in
    neural information processing systems, 28:91–99, 2015.'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] Shaoqing Ren、Kaiming He、Ross Girshick 和 Jian Sun。Faster R-CNN：通过区域提议网络实现实时物体检测。神经信息处理系统进展，28:91–99，2015年。'
- en: '[106] Ricardo Ribani and Mauricio Marengoni. A survey of transfer learning
    for convolutional neural networks. In 2019 32nd SIBGRAPI Conference on Graphics,
    Patterns and Images Tutorials (SIBGRAPI-T), pages 47–57\. IEEE, 2019.'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] Ricardo Ribani 和 Mauricio Marengoni。卷积神经网络迁移学习的综述。发表于2019年第32届 SIBGRAPI
    图形、模式与图像教程会议（SIBGRAPI-T），页码 47–57。IEEE，2019年。'
- en: '[107] Tal Ridnik, Hussam Lawen, Asaf Noy, and Itamar Friedman. Tresnet: High
    performance gpu-dedicated architecture. arXiv preprint arXiv:2003.13630, 2020.'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] Tal Ridnik、Hussam Lawen、Asaf Noy 和 Itamar Friedman。TResNet：高性能 GPU 专用架构。arXiv
    预印本 arXiv:2003.13630，2020年。'
- en: '[108] Michael T Rosenstein, Zvika Marx, Leslie Pack Kaelbling, and Thomas G
    Dietterich. To transfer or not to transfer. In NIPS 2005 workshop on transfer
    learning, volume 898, pages 1–4, 2005.'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] Michael T Rosenstein、Zvika Marx、Leslie Pack Kaelbling 和 Thomas G Dietterich。迁移还是不迁移。发表于
    NIPS 2005 迁移学习研讨会，卷 898，页码 1–4，2005年。'
- en: '[109] Yossi Rubner, Carlo Tomasi, and Leonidas J Guibas. The earth mover’s
    distance as a metric for image retrieval. International journal of computer vision,
    40(2):99–121, 2000.'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] Yossi Rubner、Carlo Tomasi 和 Leonidas J Guibas。地球移动者距离作为图像检索的度量。国际计算机视觉期刊，40(2):99–121，2000年。'
- en: '[110] David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning
    representations by back-propagating errors. nature, 323(6088):533–536, 1986.'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] David E Rumelhart、Geoffrey E Hinton 和 Ronald J Williams。通过反向传播错误学习表示。自然，323(6088):533–536，1986年。'
- en: '[111] Matthia Sabatelli, Mike Kestemont, Walter Daelemans, and Pierre Geurts.
    Deep transfer learning for art classification problems. In Proceedings of the
    European Conference on Computer Vision (ECCV), pages 0–0, 2018.'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] Matthia Sabatelli、Mike Kestemont、Walter Daelemans 和 Pierre Geurts。艺术分类问题的深度迁移学习。发表于欧洲计算机视觉会议
    (ECCV) 论文集，页码 0–0，2018年。'
- en: '[112] Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. Adapting visual
    category models to new domains. In European conference on computer vision, pages
    213–226. Springer, 2010.'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] Kate Saenko、Brian Kulis、Mario Fritz 和 Trevor Darrell。将视觉类别模型适应到新领域。发表于欧洲计算机视觉会议，页码
    213–226。Springer，2010年。'
- en: '[113] Florian Schroff, Dmitry Kalenichenko, and James Philbin. Facenet: A unified
    embedding for face recognition and clustering. In Proceedings of the IEEE conference
    on computer vision and pattern recognition, pages 815–823, 2015.'
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] Florian Schroff、Dmitry Kalenichenko 和 James Philbin。FaceNet：用于人脸识别和聚类的统一嵌入。发表于
    IEEE 计算机视觉与模式识别会议论文集，页码 815–823，2015年。'
- en: '[114] Tyler Scott, Karl Ridgeway, and Michael C Mozer. Adapted deep embeddings:
    A synthesis of methods for k-shot inductive transfer learning. In Advances in
    Neural Information Processing Systems, pages 76–85, 2018.'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] Tyler Scott、Karl Ridgeway 和 Michael C Mozer。适应的深度嵌入：K-shot 归纳迁移学习方法的综合。发表于神经信息处理系统进展，页码
    76–85，2018年。'
- en: '[115] Ling Shao, Fan Zhu, and Xuelong Li. Transfer learning for visual categorization:
    A survey. IEEE transactions on neural networks and learning systems, 26(5):1019–1034,
    2014.'
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] Ling Shao、Fan Zhu 和 Xuelong Li。视觉分类的迁移学习：综述。IEEE 神经网络与学习系统汇刊，26(5):1019–1034，2014年。'
- en: '[116] Ali Sharif Razavian, Hossein Azizpour, Josephine Sullivan, and Stefan
    Carlsson. Cnn features off-the-shelf: an astounding baseline for recognition.
    In Proceedings of the IEEE conference on computer vision and pattern recognition
    workshops, pages 806–813, 2014.'
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] Ali Sharif Razavian、Hossein Azizpour、Josephine Sullivan 和 Stefan Carlsson。CNN
    特征即取即用：一个令人惊叹的识别基准。发表于 IEEE 计算机视觉与模式识别会议研讨会论文集，页码 806–813，2014年。'
- en: '[117] Zhiqiang Shen, Zhuang Liu, Jianguo Li, Yu-Gang Jiang, Yurong Chen, and
    Xiangyang Xue. Dsod: Learning deeply supervised object detectors from scratch.
    In Proceedings of the IEEE international conference on computer vision, pages
    1919–1927, 2017.'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] Zhiqiang Shen、Zhuang Liu、Jianguo Li、Yu-Gang Jiang、Yurong Chen 和 Xiangyang
    Xue。DSOD：从零开始学习深度监督物体检测器。发表于 IEEE 国际计算机视觉会议论文集，页码 1919–1927，2017年。'
- en: '[118] Zhiqiang Shen, Honghui Shi, Rogerio Feris, Liangliang Cao, Shuicheng
    Yan, Ding Liu, Xinchao Wang, Xiangyang Xue, and Thomas S Huang. Learning object
    detectors from scratch with gated recurrent feature pyramids. arXiv preprint arXiv:1712.00886,
    1, 2017.'
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] 沈志强、施宏辉、罗杰里奥·费里斯、曹亮亮、闫水成、刘丁、王新超、薛向阳和托马斯·S·黄。使用门控递归特征金字塔从头学习目标检测器。arXiv
    预印本 arXiv:1712.00886，1，2017年。'
- en: '[119] Jun Shu, Zongben Xu, and Deyu Meng. Small sample learning in big data
    era. arXiv preprint arXiv:1808.04572, 2018.'
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] 朱军、徐宗本和孟德宇。大数据时代的小样本学习。arXiv 预印本 arXiv:1808.04572，2018年。'
- en: '[120] Jake Snell, Kevin Swersky, and Richard S Zemel. Prototypical networks
    for few-shot learning. arXiv preprint arXiv:1703.05175, 2017.'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] 杰克·斯内尔、凯文·斯威尔斯基和理查德·S·泽梅尔。用于少样本学习的原型网络。arXiv 预印本 arXiv:1703.05175，2017年。'
- en: '[121] Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah. Ucf101: A dataset
    of 101 human actions classes from videos in the wild. arXiv preprint arXiv:1212.0402,
    2012.'
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] 胡拉姆·苏姆罗、阿米尔·罗尚·扎米尔和穆巴拉克·沙赫。UCF101：一个包含101种人类动作类别的野外视频数据集。arXiv 预印本 arXiv:1212.0402，2012年。'
- en: '[122] Nitish Srivastava, Elman Mansimov, and Ruslan Salakhudinov. Unsupervised
    learning of video representations using lstms. In International conference on
    machine learning, pages 843–852, 2015.'
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] 尼提什·斯里瓦斯塔瓦、埃尔曼·曼西莫夫和鲁斯兰·萨拉赫丁诺夫。使用LSTM的无监督视频表示学习。发表于《国际机器学习会议》，第843–852页，2015年。'
- en: '[123] Johannes Stallkamp, Marc Schlipsing, Jan Salmen, and Christian Igel.
    Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition.
    Neural networks, 32:323–332, 2012.'
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] 约翰内斯·斯塔尔坎普、马克·施利普辛、简·萨尔门和克里斯蒂安·伊格尔。人与计算机：交通标志识别的机器学习算法基准测试。《神经网络》，32:323–332，2012年。'
- en: '[124] Emma Strubell, Ananya Ganesh, and Andrew McCallum. Energy and policy
    considerations for deep learning in nlp. arXiv preprint arXiv:1906.02243, 2019.'
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] 艾玛·斯特鲁贝尔、阿南雅·甘尼什和安德鲁·麦卡勒姆。深度学习在自然语言处理中的能量和政策考虑。arXiv 预印本 arXiv:1906.02243，2019年。'
- en: '[125] Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta. Revisiting
    unreasonable effectiveness of data in deep learning era. In Proceedings of the
    IEEE international conference on computer vision, pages 843–852, 2017.'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] 陈孙、阿布希纳夫·斯里瓦斯塔瓦、索拉布·辛格和阿布希纳夫·古普塔。重新审视深度学习时代数据的非理性有效性。发表于《IEEE计算机视觉国际会议论文集》，第843–852页，2017年。'
- en: '[126] Nima Tajbakhsh, Jae Y Shin, Suryakanth R Gurudu, R Todd Hurst, Christopher B
    Kendall, Michael B Gotway, and Jianming Liang. Convolutional neural networks for
    medical image analysis: Full training or fine tuning? IEEE transactions on medical
    imaging, 35(5):1299–1312, 2016.'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] 尼玛·塔伊巴赫什、申嘉瑜、苏利亚坎特·R·古鲁杜、R·托德·赫斯特、克里斯托弗·B·肯德尔、迈克尔·B·戈特韦和姜明。医学图像分析中的卷积神经网络：全训练还是微调？《IEEE医学影像学事务》，35(5):1299–1312，2016年。'
- en: '[127] Chuanqi Tan, Fuchun Sun, Tao Kong, Wenchang Zhang, Chao Yang, and Chunfang
    Liu. A survey on deep transfer learning. In International conference on artificial
    neural networks, pages 270–279\. Springer, 2018.'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] 谭传琪、孙福春、孔涛、张文昌、杨超和刘春芳。深度迁移学习综述。发表于《国际人工神经网络会议》，第270–279页。施普林格，2018年。'
- en: '[128] Mingxing Tan and Quoc V Le. Efficientnet: Rethinking model scaling for
    convolutional neural networks. arXiv preprint arXiv:1905.11946, 2019.'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] 谭铭星和阮国维。EfficientNet：重新思考卷积神经网络的模型缩放。arXiv 预印本 arXiv:1905.11946，2019年。'
- en: '[129] Tatiana Tommasi and Tinne Tuytelaars. A testbed for cross-dataset analysis.
    In European Conference on Computer Vision, pages 18–31. Springer, 2014.'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] 塔蒂亚娜·托马西和廷内·图特拉斯。跨数据集分析的测试平台。发表于《欧洲计算机视觉会议》，第18–31页。施普林格，2014年。'
- en: '[130] Anh T Tran, Cuong V Nguyen, and Tal Hassner. Transferability and hardness
    of supervised classification tasks. In Proceedings of the IEEE/CVF International
    Conference on Computer Vision, pages 1395–1405, 2019.'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] 安·T·陈、阮国维和塔尔·哈斯纳。监督分类任务的可迁移性和难度。发表于《IEEE/CVF国际计算机视觉会议论文集》，第1395–1405页，2019年。'
- en: '[131] Grant Van Horn, Oisin Mac Aodha, Yang Song, Yin Cui, Chen Sun, Alex Shepard,
    Hartwig Adam, Pietro Perona, and Serge Belongie. The inaturalist species classification
    and detection dataset. In Proceedings of the IEEE conference on computer vision
    and pattern recognition, pages 8769–8778, 2018.'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] 格兰特·范·霍恩、奥伊辛·麦克·阿奥达、杨宋、尹崔、陈孙、亚历克斯·谢泼德、哈特维格·亚当、皮耶特罗·佩罗纳和谢尔盖·贝隆吉。iNaturalist物种分类和检测数据集。发表于《IEEE计算机视觉与模式识别会议论文集》，第8769–8778页，2018年。'
- en: '[132] Vladimir Vapnik. Principles of risk minimization for learning theory.
    In Advances in neural information processing systems, pages 831–838, 1992.'
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] 弗拉基米尔·瓦普尼克。学习理论中的风险最小化原则。发表于《神经信息处理系统进展》，第831–838页，1992年。'
- en: '[133] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al.
    Matching networks for one shot learning. Advances in neural information processing
    systems, 29:3630–3638, 2016.'
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] Oriol Vinyals、Charles Blundell、Timothy Lillicrap、Daan Wierstra 等. 用于一次性学习的匹配网络。《神经信息处理系统进展》，29:3630–3638,
    2016。'
- en: '[134] Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge
    Belongie. The caltech-ucsd birds-200-2011 dataset. vision.caltech.edu, 2011.'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] Catherine Wah、Steve Branson、Peter Welinder、Pietro Perona 和 Serge Belongie.
    Caltech-UCSD Birds-200-2011 数据集。vision.caltech.edu, 2011。'
- en: '[135] Ruosi Wan, Haoyi Xiong, Xingjian Li, Zhanxing Zhu, and Jun Huan. Towards
    making deep transfer learning never hurt. In 2019 IEEE International Conference
    on Data Mining (ICDM), pages 578–587\. IEEE, 2019.'
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] Ruosi Wan、Haoyi Xiong、Xingjian Li、Zhanxing Zhu 和 Jun Huan. 致力于让深度迁移学习永远不会造成伤害。在
    2019 IEEE 国际数据挖掘大会（ICDM）论文集中，页码 578–587。IEEE, 2019。'
- en: '[136] Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou,
    Zhifeng Li, and Wei Liu. Cosface: Large margin cosine loss for deep face recognition.
    In Proceedings of the IEEE conference on computer vision and pattern recognition,
    pages 5265–5274, 2018.'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] Hao Wang、Yitong Wang、Zheng Zhou、Xing Ji、Dihong Gong、Jingchao Zhou、Zhifeng
    Li 和 Wei Liu. Cosface：用于深度人脸识别的大间隔余弦损失。在 IEEE 计算机视觉与模式识别会议论文集中，页码 5265–5274, 2018。'
- en: '[137] Mei Wang and Weihong Deng. Deep visual domain adaptation: A survey. Neurocomputing,
    312:135–153, 2018.'
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] Mei Wang 和 Weihong Deng. 深度视觉领域适应：综述。《神经计算》，312:135–153, 2018。'
- en: '[138] Ximei Wang, Ying Jin, Mingsheng Long, Jianmin Wang, and Michael Jordan.
    Transferable normalization: Towards improving transferability of deep neural networks.
    openreview.net, 2019.'
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] Ximei Wang、Ying Jin、Mingsheng Long、Jianmin Wang 和 Michael Jordan. 可迁移归一化：提高深度神经网络的可迁移性。openreview.net,
    2019。'
- en: '[139] Yaqing Wang, Quanming Yao, James T Kwok, and Lionel M Ni. Generalizing
    from a few examples: A survey on few-shot learning. ACM Computing Surveys (CSUR),
    53(3):1–34, 2020.'
  id: totrans-686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] Yaqing Wang、Quanming Yao、James T Kwok 和 Lionel M Ni. 从少量示例中进行泛化：少样本学习综述。《ACM计算调查》（CSUR），53(3):1–34,
    2020。'
- en: '[140] Zirui Wang, Zihang Dai, Barnabás Póczos, and Jaime Carbonell. Characterizing
    and avoiding negative transfer. In Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition, pages 11293–11302, 2019.'
  id: totrans-687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] Zirui Wang、Zihang Dai、Barnabás Póczos 和 Jaime Carbonell. 描述和避免负迁移。在 IEEE/CVF
    计算机视觉与模式识别会议论文集中，页码 11293–11302, 2019。'
- en: '[141] Karl Weiss, Taghi M Khoshgoftaar, and DingDing Wang. A survey of transfer
    learning. Journal of Big data, 3(1):9, 2016.'
  id: totrans-688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] Karl Weiss、Taghi M Khoshgoftaar 和 DingDing Wang. 迁移学习综述。《大数据杂志》，3(1):9,
    2016。'
- en: '[142] Yandong Wen, Kaipeng Zhang, Zhifeng Li, and Yu Qiao. A discriminative
    feature learning approach for deep face recognition. In European conference on
    computer vision, pages 499–515. Springer, 2016.'
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] Yandong Wen、Kaipeng Zhang、Zhifeng Li 和 Yu Qiao. 一种用于深度人脸识别的区分特征学习方法。在欧洲计算机视觉会议论文集中，页码
    499–515。Springer, 2016。'
- en: '[143] Yue Wu, Tal Hassner, KangGeon Kim, Gerard Medioni, and Prem Natarajan.
    Facial landmark detection with tweaked convolutional neural networks. IEEE transactions
    on pattern analysis and machine intelligence, 40(12):3067–3074, 2018.'
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] Yue Wu、Tal Hassner、KangGeon Kim、Gerard Medioni 和 Prem Natarajan. 使用调整的卷积神经网络进行面部标志点检测。《IEEE模式分析与机器智能交易》，40(12):3067–3074,
    2018。'
- en: '[144] Yuxin Wu and Kaiming He. Group normalization. In Proceedings of the European
    conference on computer vision (ECCV), pages 3–19, 2018.'
  id: totrans-691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] Yuxin Wu 和 Kaiming He. 组归一化。在欧洲计算机视觉会议（ECCV）论文集中，页码 3–19, 2018。'
- en: '[145] Jianxiong Xiao, James Hays, Krista A Ehinger, Aude Oliva, and Antonio
    Torralba. Sun database: Large-scale scene recognition from abbey to zoo. In 2010
    IEEE computer society conference on computer vision and pattern recognition, pages
    3485–3492\. IEEE, 2010.'
  id: totrans-692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] Jianxiong Xiao、James Hays、Krista A Ehinger、Aude Oliva 和 Antonio Torralba.
    Sun 数据库：从修道院到动物园的大规模场景识别。在 2010 IEEE 计算机学会计算机视觉与模式识别会议论文集中，页码 3485–3492。IEEE,
    2010。'
- en: '[146] Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le. Self-training
    with noisy student improves imagenet classification. In Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, pages 10687–10698, 2020.'
  id: totrans-693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] Qizhe Xie、Minh-Thang Luong、Eduard Hovy 和 Quoc V Le. 使用噪声学生的自训练改进 Imagenet
    分类。在 IEEE/CVF 计算机视觉与模式识别会议论文集中，页码 10687–10698, 2020。'
- en: '[147] I Zeki Yalniz, Hervé Jégou, Kan Chen, Manohar Paluri, and Dhruv Mahajan.
    Billion-scale semi-supervised learning for image classification. arXiv preprint
    arXiv:1905.00546, 2019.'
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] I Zeki Yalniz、Hervé Jégou、Kan Chen、Manohar Paluri 和 Dhruv Mahajan. 十亿级半监督学习用于图像分类。arXiv
    预印本 arXiv:1905.00546, 2019。'
- en: '[148] Jinsung Yoon, Sercan Arik, and Tomas Pfister. Data valuation using reinforcement
    learning. In International Conference on Machine Learning, pages 10842–10851\.
    PMLR, 2020.'
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] Jinsung Yoon, Sercan Arik, 和 Tomas Pfister. 使用强化学习的数据估值。发表于国际机器学习大会，页码
    10842–10851\. PMLR，2020年。'
- en: '[149] Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. How transferable
    are features in deep neural networks? In Advances in neural information processing
    systems, pages 3320–3328, 2014.'
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] Jason Yosinski, Jeff Clune, Yoshua Bengio, 和 Hod Lipson. 深度神经网络中的特征可迁移性有多高？发表于神经信息处理系统进展，页码
    3320–3328，2014年。'
- en: '[150] Kaichao You, Zhi Kou, Mingsheng Long, and Jianmin Wang. Co-tuning for
    transfer learning. Advances in Neural Information Processing Systems, 33, 2020.'
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] Kaichao You, Zhi Kou, Mingsheng Long, 和 Jianmin Wang. 迁移学习的协同调整。神经信息处理系统进展，33，2020年。'
- en: '[151] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup:
    Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412, 2017.'
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, 和 David Lopez-Paz. mixup:
    超越经验风险最小化。arXiv 预印本 arXiv:1710.09412，2017年。'
- en: '[152] Jing Zhang, Wanqing Li, and Philip Ogunbona. Transfer learning for cross-dataset
    recognition: a survey. arXiv preprint arXiv:1705.04396, 2017.'
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] Jing Zhang, Wanqing Li, 和 Philip Ogunbona. 跨数据集识别的迁移学习：一项调查。arXiv 预印本
    arXiv:1705.04396，2017年。'
- en: '[153] Jing Zhang, Wanqing Li, Philip Ogunbona, and Dong Xu. Recent advances
    in transfer learning for cross-dataset visual recognition: A problem-oriented
    perspective. ACM Computing Surveys (CSUR), 52(1):1–38, 2019.'
  id: totrans-700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] Jing Zhang, Wanqing Li, Philip Ogunbona, 和 Dong Xu. 跨数据集视觉识别的迁移学习的最新进展：面向问题的视角。ACM计算机调查（CSUR），52(1)：1–38，2019年。'
- en: '[154] Yutong Zheng, Dipan K Pal, and Marios Savvides. Ring loss: Convex feature
    normalization for face recognition. In Proceedings of the IEEE conference on computer
    vision and pattern recognition, pages 5089–5097, 2018.'
  id: totrans-701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] Yutong Zheng, Dipan K Pal, 和 Marios Savvides. Ring loss: 面部识别的凸特征归一化。发表于IEEE计算机视觉与模式识别会议，页码
    5089–5097，2018年。'
- en: '[155] Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba.
    Places: A 10 million image database for scene recognition. IEEE transactions on
    pattern analysis and machine intelligence, 40(6):1452–1464, 2017.'
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, 和 Antonio Torralba.
    Places: 一个1000万图像的场景识别数据库。IEEE模式分析与机器智能学报，40(6)：1452–1464，2017年。'
- en: '[156] Linchao Zhu, Sercan O Arik, Yi Yang, and Tomas Pfister. Learning to transfer
    learn. openreview.net, 2019.'
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] Linchao Zhu, Sercan O Arik, Yi Yang, 和 Tomas Pfister. 学习迁移学习。openreview.net，2019年。'
- en: '[157] Rui Zhu, Shifeng Zhang, Xiaobo Wang, Longyin Wen, Hailin Shi, Liefeng
    Bo, and Tao Mei. Scratchdet: Training single-shot object detectors from scratch.
    In Proceedings of the IEEE conference on computer vision and pattern recognition,
    pages 2268–2277, 2019.'
  id: totrans-704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] Rui Zhu, Shifeng Zhang, Xiaobo Wang, Longyin Wen, Hailin Shi, Liefeng
    Bo, 和 Tao Mei. Scratchdet: 从头开始训练单次目标检测器。发表于IEEE计算机视觉与模式识别会议，页码 2268–2277，2019年。'
- en: '[158] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu
    Zhu, Hui Xiong, and Qing He. A comprehensive survey on transfer learning. Proceedings
    of the IEEE, 2020.'
  id: totrans-705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu
    Zhu, Hui Xiong, 和 Qing He. 关于迁移学习的综合调查。IEEE会议录，2020年。'
- en: '[159] Barret Zoph, Golnaz Ghiasi, Tsung-Yi Lin, Yin Cui, Hanxiao Liu, Ekin D
    Cubuk, and Quoc V Le. Rethinking pre-training and self-training. arXiv preprint
    arXiv:2006.06882, 2020.'
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[159] Barret Zoph, Golnaz Ghiasi, Tsung-Yi Lin, Yin Cui, Hanxiao Liu, Ekin
    D Cubuk, 和 Quoc V Le. 重新思考预训练和自训练。arXiv 预印本 arXiv:2006.06882，2020年。'
