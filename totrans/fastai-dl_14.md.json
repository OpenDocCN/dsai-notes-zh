["```py\nmatplotlib inline\n%reload_ext autoreload\n%autoreload 2\n```", "```py\n**from** **fastai.conv_learner** **import** *\n**from** **pathlib** **import** Path\n\ntorch.backends.cudnn.benchmark=**True**PATH = Path('data/imagenet')\nPATH_TRN = PATH/'train'\n```", "```py\nfnames_full,label_arr_full,all_labels = folder_source(PATH, 'train')\nfnames_full = ['/'.join(Path(fn).parts[-2:]) **for** fn **in** fnames_full]\nlist(zip(fnames_full[:5],label_arr_full[:5]))*[('n01440764/n01440764_9627.JPEG', 0),\n ('n01440764/n01440764_9609.JPEG', 0),\n ('n01440764/n01440764_5176.JPEG', 0),\n ('n01440764/n01440764_6936.JPEG', 0),\n ('n01440764/n01440764_4005.JPEG', 0)]*all_labels[:5]*['n01440764', 'n01443537', 'n01484850', 'n01491361', 'n01494475']*\n```", "```py\nnp.random.seed(42)\n# keep_pct = 1.\n*keep_pct = 0.02*\nkeeps = np.random.rand(len(fnames_full)) < keep_pct\nfnames = np.array(fnames_full, copy=**False**)[keeps]\nlabel_arr = np.array(label_arr_full, copy=**False**)[keeps]\n```", "```py\narch = vgg16\nsz_lr = 72\n```", "```py\nscale,bs = 2,64\n*# scale,bs = 4,32*\nsz_hr = sz_lr*scale\n```", "```py\n**class** **MatchedFilesDataset**(FilesDataset):\n    **def** __init__(self, fnames, y, transform, path):\n        self.y=y\n        **assert**(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n    **def** get_y(self, i): \n        **return** open_image(os.path.join(self.path, self.y[i]))\n    **def** get_c(self): **return** 0\n```", "```py\naug_tfms = [RandomDihedral(tfm_y=TfmType.PIXEL)]\n```", "```py\nval_idxs = get_cv_idxs(len(fnames), val_pct=min(0.01/keep_pct, 0.1))\n((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, \n                                np.array(fnames), np.array(fnames))\nlen(val_x),len(trn_x)*(12811, 1268356)*img_fn = PATH/'train'/'n01558993'/'n01558993_9684.JPEG'\n```", "```py\ntfms = tfms_from_model(arch, sz_lr, tfm_y=TfmType.PIXEL, \n          aug_tfms=aug_tfms, sz_y=sz_hr)\ndatasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), \n               (val_x,val_y), tfms, path=PATH_TRN)\nmd = ImageData(PATH, datasets, bs, num_workers=16, classes=**None**)\n```", "```py\ndenorm = md.val_ds.denorm\n```", "```py\n**def** show_img(ims, idx, figsize=(5,5), normed=**True**, ax=**None**):\n    **if** ax **is** **None**: fig,ax = plt.subplots(figsize=figsize)\n    **if** normed: ims = denorm(ims)\n    **else**:      ims = np.rollaxis(to_np(ims),1,4)\n    ax.imshow(np.clip(ims,0,1)[idx])\n    ax.axis('off')x,y = next(iter(md.val_dl))\nx.size(),y.size()*(torch.Size([32, 3, 72, 72]), torch.Size([32, 3, 288, 288]))*\n```", "```py\nidx=1\nfig,axes = plt.subplots(1, 2, figsize=(9,5))\nshow_img(x,idx, ax=axes[0])\nshow_img(y,idx, ax=axes[1])\n```", "```py\nbatches = [next(iter(md.aug_dl)) **for** i **in** range(9)]\n```", "```py\nfig, axes = plt.subplots(3, 6, figsize=(18, 9))\n**for** i,(x,y) **in** enumerate(batches):\n    show_img(x,idx, ax=axes.flat[i*2])\n    show_img(y,idx, ax=axes.flat[i*2+1])\n```", "```py\n**def** conv(ni, nf, kernel_size=3, actn=**False**):\n    layers = [nn.Conv2d(ni, nf, kernel_size, \n              padding=kernel_size//2)]\n    **if** actn: layers.append(nn.ReLU(**True**))\n    **return** nn.Sequential(*layers)\n```", "```py\n**class** **ResSequential**(nn.Module):\n    **def** __init__(self, layers, res_scale=1.0):\n        super().__init__()\n        self.res_scale = res_scale\n        self.m = nn.Sequential(*layers)\n\n    **def** forward(self, x): **return** x + self.m(x) * self.res_scale\n```", "```py\n**def** res_block(nf):\n    **return** ResSequential(\n        [conv(nf, nf, actn=**True**), conv(nf, nf)],\n        0.1)\n```", "```py\n**def** upsample(ni, nf, scale):\n    layers = []\n    **for** i **in** range(int(math.log(scale,2))):\n        layers += [conv(ni, nf*4), nn.PixelShuffle(2)]\n    **return** nn.Sequential(*layers)\n```", "```py\n**class** **SrResnet**(nn.Module):\n    **def** __init__(self, nf, scale):\n        super().__init__()\n        features = [conv(3, 64)]\n        **for** i **in** range(8): features.append(res_block(64))\n        features += [conv(64,64), upsample(64, 64, scale),\n                     nn.BatchNorm2d(64),\n                     conv(64, 3)]\n        self.features = nn.Sequential(*features)\n\n    **def** forward(self, x): **return** self.features(x)\n```", "```py\nm = to_gpu(SrResnet(64, scale))\nm = nn.DataParallel(m, [0,2])\nlearn = Learner(md, SingleModel(m), opt_fn=optim.Adam)\nlearn.crit = F.mse_loss\n```", "```py\nlearn.lr_find(start_lr=1e-5, end_lr=10000)\nlearn.sched.plot()31%|\u2588\u2588\u2588\u258f      | 225/720 [00:24<00:53,  9.19it/s, loss=0.0482]\n```", "```py\nlr=2e-3learn.fit(lr, 1, cycle_len=1, use_clr_beta=(40,10))2%|\u258f         | 15/720 [00:02<01:52,  6.25it/s, loss=0.042]  \nepoch      trn_loss   val_loss                                 \n    0      0.007431   0.008192*[array([0.00819])]*x,y = next(iter(md.val_dl))\npreds = learn.model(VV(x))\n```", "```py\nidx=4\nshow_img(y,idx,normed=**False**)\n```", "```py\nshow_img(preds,idx,normed=**False**);\n```", "```py\nshow_img(x,idx,normed=**True**);\n```", "```py\nx,y = next(iter(md.val_dl))\npreds = learn.model(VV(x))show_img(y,idx,normed=**False**)\n```", "```py\nshow_img(preds,idx,normed=**False**);\n```", "```py\nshow_img(x,idx);\n```", "```py\n**def** icnr(x, scale=2, init=nn.init.kaiming_normal):\n    new_shape = [int(x.shape[0] / (scale ** 2))] + list(x.shape[1:])\n    subkernel = torch.zeros(new_shape)\n    subkernel = init(subkernel)\n    subkernel = subkernel.transpose(0, 1)\n    subkernel = subkernel.contiguous().view(subkernel.shape[0],\n                                            subkernel.shape[1], -1)\n    kernel = subkernel.repeat(1, 1, scale ** 2)\n    transposed_shape = [x.shape[1]] + [x.shape[0]] + \n                          list(x.shape[2:])\n    kernel = kernel.contiguous().view(transposed_shape)\n    kernel = kernel.transpose(0, 1)\n    **return** kernelm_vgg = vgg16(**True**)\n\nblocks = [i-1 **for** i,o **in** enumerate(children(m_vgg))\n              **if** isinstance(o,nn.MaxPool2d)]\nblocks, [m_vgg[i] **for** i **in** blocks]*([5, 12, 22, 32, 42],\n [ReLU(inplace), ReLU(inplace), ReLU(inplace), ReLU(inplace), ReLU(inplace)])*\n```", "```py\nvgg_layers = children(m_vgg)[:23]\nm_vgg = nn.Sequential(*vgg_layers).cuda().eval()\nset_trainable(m_vgg, **False**)**def** flatten(x): **return** x.view(x.size(0), -1)\n```", "```py\n**class** **SaveFeatures**():\n    features=**None**\n    **def** __init__(self, m): \n        self.hook = m.register_forward_hook(self.hook_fn)\n    **def** hook_fn(self, module, input, output): self.features = output\n    **def** remove(self): self.hook.remove()\n```", "```py\n**class** **FeatureLoss**(nn.Module):\n    **def** __init__(self, m, layer_ids, layer_wgts):\n        super().__init__()\n        self.m,self.wgts = m,layer_wgts\n        self.sfs = [SaveFeatures(m[i]) **for** i **in** layer_ids]\n\n    **def** forward(self, input, target, sum_layers=**True**):\n        self.m(VV(target.data))\n        res = [F.l1_loss(input,target)/100]\n        targ_feat = [V(o.features.data.clone()) **for** o **in** self.sfs]\n        self.m(input)\n        res += [F.l1_loss(flatten(inp.features),flatten(targ))*wgt\n               **for** inp,targ,wgt **in** zip(self.sfs, targ_feat, \n                                       self.wgts)]\n        **if** sum_layers: res = sum(res)\n        **return** res\n\n    **def** close(self):\n        **for** o **in** self.sfs: o.remove()\n```", "```py\nm = SrResnet(64, scale)\n```", "```py\nconv_shuffle = m.features[10][0][0]\nkernel = icnr(conv_shuffle.weight, scale=scale)\nconv_shuffle.weight.data.copy_(kernel);\n```", "```py\nm = to_gpu(m)learn = Learner(md, SingleModel(m), opt_fn=optim.Adam)t = torch.load(learn.get_model_path('sr-samp0'), \n         map_location=**lambda** storage, loc: storage)\nlearn.model.load_state_dict(t, strict=**False**)learn.freeze_to(999)**for** i **in** range(10,13): set_trainable(m.features[i], **True**)conv_shuffle = m.features[10][2][0]\nkernel = icnr(conv_shuffle.weight, scale=scale)\nconv_shuffle.weight.data.copy_(kernel);\n```", "```py\nm = nn.DataParallel(m, [0,2])\nlearn = Learner(md, SingleModel(m), opt_fn=optim.Adam)learn.set_data(md)\n```", "```py\nlearn.crit = FeatureLoss(m_vgg, blocks[:3], [0.2,0.7,0.1])lr=6e-3\nwd=1e-7\n```", "```py\nlearn.lr_find(1e-4, 0.1, wds=wd, linear=**True**) 1%|          | 15/1801 [00:06<12:55,  2.30it/s, loss=0.0965]\n12%|\u2588\u258f        | 220/1801 [01:16<09:08,  2.88it/s, loss=0.42]learn.sched.plot(n_skip_end=1)\n```", "```py\nlearn.fit(lr, 1, cycle_len=2, wds=wd, use_clr=(20,10))epoch      trn_loss   val_loss                                  \n    0      0.04523    0.042932  \n    1      0.043574   0.041242[array([0.04124])]learn.save('sr-samp0')learn.save('sr-samp1')\n```", "```py\nlearn.load('sr-samp1')lr=3e-3learn.fit(lr, 1, cycle_len=1, wds=wd, use_clr=(20,10))epoch      trn_loss   val_loss                                \n    0      0.069054   0.06638[array([0.06638])]learn.save('sr-samp2')learn.unfreeze()learn.load('sr-samp2')learn.fit(lr/3, 1, cycle_len=1, wds=wd, use_clr=(20,10))epoch      trn_loss   val_loss           \n    0      0.06042    0.057613[array([0.05761])]learn.save('sr1')learn.sched.plot_loss()\n```", "```py\n**def** plot_ds_img(idx, ax=**None**, figsize=(7,7), normed=**True**):\n    **if** ax **is** **None**: fig,ax = plt.subplots(figsize=figsize)\n    im = md.val_ds[idx][0]\n    **if** normed: im = denorm(im)[0]\n    **else**:      im = np.rollaxis(to_np(im),0,3)\n    ax.imshow(im)\n    ax.axis('off')fig,axes=plt.subplots(6,6,figsize=(20,20))\n**for** i,ax **in** enumerate(axes.flat): \n    plot_ds_img(i+200,ax=ax, normed=**True**)\n```", "```py\nx,y=md.val_ds[215]y=y[**None**]learn.model.eval()\npreds = learn.model(VV(x[**None**]))\nx.shape,y.shape,preds.shape*((3, 72, 72), (1, 3, 288, 288), torch.Size([1, 3, 288, 288]))*learn.crit(preds, V(y), sum_layers=**False**)[Variable containing:\n 1.00000e-03 *\n   1.1935\n [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n 1.00000e-03 *\n   8.5054\n [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n 1.00000e-02 *\n   3.4656\n [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n 1.00000e-03 *\n   3.8243\n [torch.cuda.FloatTensor of size 1 (GPU 0)]]learn.crit.close()\n```", "```py\n_,axes=plt.subplots(1,2,figsize=(14,7))\nshow_img(x[**None**], 0, ax=axes[0])\nshow_img(preds,0, normed=**True**, ax=axes[1])\n```", "```py\n%matplotlib inline\n%reload_ext autoreload\n%autoreload 2**from** **fastai.conv_learner** **import** *\n**from** **pathlib** **import** Path\ntorch.cuda.set_device(0)torch.backends.cudnn.benchmark=**True**PATH = Path('data/imagenet')\nPATH_TRN = PATH/'train'fnames_full,label_arr_full,all_labels = folder_source(PATH, 'train')\nfnames_full = ['/'.join(Path(fn).parts[-2:]) **for** fn **in** fnames_full]\nlist(zip(fnames_full[:5],label_arr_full[:5]))*[('n01440764/n01440764_9627.JPEG', 0),\n ('n01440764/n01440764_9609.JPEG', 0),\n ('n01440764/n01440764_5176.JPEG', 0),\n ('n01440764/n01440764_6936.JPEG', 0),\n ('n01440764/n01440764_4005.JPEG', 0)]*all_labels[:5]*['n01440764', 'n01443537', 'n01484850', 'n01491361', 'n01494475']*np.random.seed(42)\n*# keep_pct = 1.*\n*# keep_pct = 0.01*\nkeep_pct = 0.1\nkeeps = np.random.rand(len(fnames_full)) < keep_pct\nfnames = np.array(fnames_full, copy=**False**)[keeps]\nlabel_arr = np.array(label_arr_full, copy=**False**)[keeps]arch = vgg16\n*# sz,bs = 96,32*\nsz,bs = 256,24\n*# sz,bs = 128,32***class** **MatchedFilesDataset**(FilesDataset):\n    **def** __init__(self, fnames, y, transform, path):\n        self.y=y\n        **assert**(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n    **def** get_y(self, i): \n        **return** open_image(os.path.join(self.path, self.y[i]))\n    **def** get_c(self): **return** 0val_idxs = get_cv_idxs(len(fnames), val_pct=min(0.01/keep_pct, 0.1))\n((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, \n                                 np.array(fnames), np.array(fnames))\nlen(val_x),len(trn_x)(12800, 115206)img_fn = PATH/'train'/'n01558993'/'n01558993_9684.JPEG'tfms = tfms_from_model(arch, sz, tfm_y=TfmType.PIXEL)\ndatasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), \n                   (val_x,val_y), tfms, path=PATH_TRN)\nmd = ImageData(PATH, datasets, bs, num_workers=16, classes=**None**)denorm = md.val_ds.denorm**def** show_img(ims, idx, figsize=(5,5), normed=**True**, ax=**None**):\n    **if** ax **is** **None**: fig,ax = plt.subplots(figsize=figsize)\n    **if** normed: ims = denorm(ims)\n    **else**:      ims = np.rollaxis(to_np(ims),1,4)\n    ax.imshow(np.clip(ims,0,1)[idx])\n    ax.axis('off')\n```", "```py\n**def** conv(ni, nf, kernel_size=3, stride=1, actn=**True**, pad=**None**, \n         bn=**True**):\n    **if** pad **is** **None**: pad = kernel_size//2\n    layers = [nn.Conv2d(ni, nf, kernel_size, stride=stride,\n                          padding=pad, bias=**not** bn)]\n    **if** actn: layers.append(nn.ReLU(inplace=**True**))\n    **if** bn: layers.append(nn.BatchNorm2d(nf))\n    **return** nn.Sequential(*layers)\n```", "```py\n**class** **ResSequentialCenter**(nn.Module):\n    **def** __init__(self, layers):\n        super().__init__()\n        self.m = nn.Sequential(*layers) **def** forward(self, x): **return** x[:, :, 2:-2, 2:-2] + self.m(x)**def** res_block(nf):\n    **return** ResSequentialCenter([conv(nf, nf, actn=**True**, pad=0), \n              conv(nf, nf, pad=0)])\n```", "```py\n**def** upsample(ni, nf):\n    **return** nn.Sequential(nn.Upsample(scale_factor=2), conv(ni, nf))\n```", "```py\n**class** **StyleResnet**(nn.Module):\n    **def** __init__(self):\n        super().__init__()\n        features = [nn.ReflectionPad2d(40),\n                    conv(3, 32, 9),\n                    conv(32, 64, stride=2), conv(64, 128, stride=2)]\n        **for** i **in** range(5): features.append(res_block(128))\n        features += [upsample(128, 64), upsample(64, 32),\n                     conv(32, 3, 9, actn=**False**)]\n        self.features = nn.Sequential(*features)\n\n    **def** forward(self, x): **return** self.features(x)\n```", "```py\nstyle_fn = PATH/'style'/'starry_night.jpg'\nstyle_img = open_image(style_fn)\nstyle_img.shape*(1198, 1513, 3)*plt.imshow(style_img);\n```", "```py\nh,w,_ = style_img.shape\nrat = max(sz/h,sz/h)\nres = cv2.resize(style_img, (int(w*rat), int(h*rat)), interpolation=cv2.INTER_AREA)\nresz_style = res[:sz,-sz:]\n```", "```py\nplt.imshow(resz_style);\n```", "```py\nstyle_tfm,_ = tfms[1](resz_style,resz_style)style_tfm = np.broadcast_to(style_tfm[**None**], (bs,)+style_tfm.shape)\n```", "```py\nstyle_tfm.shape(24, 3, 256, 256)\n```", "```py\nm_vgg = vgg16(**True**)blocks = [i-1 **for** i,o **in** enumerate(children(m_vgg))\n              **if** isinstance(o,nn.MaxPool2d)]\nblocks, [m_vgg[i] **for** i **in** blocks[1:]]*([5, 12, 22, 32, 42],\n [ReLU(inplace), ReLU(inplace), ReLU(inplace), ReLU(inplace)])*vgg_layers = children(m_vgg)[:43]\nm_vgg = nn.Sequential(*vgg_layers).cuda().eval()\nset_trainable(m_vgg, **False**)**def** flatten(x): **return** x.view(x.size(0), -1)**class** **SaveFeatures**():\n    features=**None**\n    **def** __init__(self, m): \n        self.hook = m.register_forward_hook(self.hook_fn)\n    **def** hook_fn(self, module, input, output): self.features = output\n    **def** remove(self): self.hook.remove()**def** ct_loss(input, target): **return** F.mse_loss(input,target)**def** gram(input):\n        b,c,h,w = input.size()\n        x = input.view(b, c, -1)\n        **return** torch.bmm(x, x.transpose(1,2))/(c*h*w)*1e6**def** gram_loss(input, target):\n    **return** F.mse_loss(gram(input), gram(target[:input.size(0)]))\n```", "```py\n**class** **CombinedLoss**(nn.Module):\n    **def** __init__(self, m, layer_ids, style_im, ct_wgt, style_wgts):\n        super().__init__()\n        self.m,self.ct_wgt,self.style_wgts = m,ct_wgt,style_wgts\n        self.sfs = [SaveFeatures(m[i]) **for** i **in** layer_ids]\n        m(VV(style_im))\n        self.style_feat = [V(o.features.data.clone()) \n                              **for** o **in** self.sfs] **def** forward(self, input, target, sum_layers=**True**):\n        self.m(VV(target.data))\n        targ_feat = self.sfs[2].features.data.clone()\n        self.m(input)\n        inp_feat = [o.features **for** o **in** self.sfs]\n\n        res = [ct_loss(inp_feat[2],V(targ_feat)) * self.ct_wgt]\n        res += [gram_loss(inp,targ)*wgt **for** inp,targ,wgt\n                **in** zip(inp_feat, self.style_feat, self.style_wgts)]\n\n        **if** sum_layers: res = sum(res)\n        **return** res\n\n    **def** close(self):\n        **for** o **in** self.sfs: o.remove()\n```", "```py\nm = StyleResnet()\nm = to_gpu(m)learn = Learner(md, SingleModel(m), opt_fn=optim.Adam)\n```", "```py\nlearn.crit = CombinedLoss(m_vgg, blocks[1:], style_tfm, 1e4,\n                             [0.025,0.275,5.,0.2])wd=1e-7learn.lr_find(wds=wd)\nlearn.sched.plot(n_skip_end=1) 1%|\u258f         | 7/482 [00:04<05:32,  1.43it/s, loss=2.48e+04] \n 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 254/482 [02:27<02:12,  1.73it/s, loss=1.13e+12]\n```", "```py\nlr=5e-3\n```", "```py\nlearn.fit(lr, 1, cycle_len=1, wds=wd, use_clr=(20,10))epoch      trn_loss   val_loss                               \n    0      105.351372 105.833994[array([105.83399])]learn.save('style-2')x,y=md.val_ds[201]learn.model.eval()\npreds = learn.model(VV(x[**None**]))\nx.shape,y.shape,preds.shape*((3, 256, 256), (3, 256, 256), torch.Size([1, 3, 256, 256]))*\n```", "```py\nlearn.crit(preds, VV(y[**None**]), sum_layers=**False**)*[Variable containing:\n  53.2221\n [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n  3.8336\n [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n  4.0612\n [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n  5.0639\n [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n  53.0019\n [torch.cuda.FloatTensor of size 1 (GPU 0)]]*learn.crit.close()_,axes=plt.subplots(1,2,figsize=(14,7))\nshow_img(x[**None**], 0, ax=axes[0])\nshow_img(preds, 0, ax=axes[1])\n```", "```py\n%matplotlib inline\n%reload_ext autoreload\n%autoreload 2**from** **fastai.conv_learner** **import** *\n**from** **fastai.dataset** **import** *\n\n**from** **pathlib** **import** Path\n**import** **json**\n```", "```py\nPATH = Path('data/carvana')\nlist(PATH.iterdir())*[PosixPath('data/carvana/train_masks.csv'),\n PosixPath('data/carvana/train_masks-128'),\n PosixPath('data/carvana/sample_submission.csv'),\n PosixPath('data/carvana/train_masks_png'),\n PosixPath('data/carvana/train.csv'),\n PosixPath('data/carvana/train-128'),\n PosixPath('data/carvana/train'),\n PosixPath('data/carvana/metadata.csv'),\n PosixPath('data/carvana/tmp'),\n PosixPath('data/carvana/models'),\n PosixPath('data/carvana/train_masks')]*MASKS_FN = 'train_masks.csv'\nMETA_FN = 'metadata.csv'\nTRAIN_DN = 'train'\nMASKS_DN = 'train_masks'masks_csv = pd.read_csv(PATH/MASKS_FN)\nmasks_csv.head()\n```", "```py\nmeta_csv = pd.read_csv(PATH/META_FN)\nmeta_csv.head()\n```", "```py\n**def** show_img(im, figsize=**None**, ax=**None**, alpha=**None**):\n    **if** **not** ax: fig,ax = plt.subplots(figsize=figsize)\n    ax.imshow(im, alpha=alpha)\n    ax.set_axis_off()\n    **return** axCAR_ID = '00087a6bd4dc'list((PATH/TRAIN_DN).iterdir())[:5][PosixPath('data/carvana/train/5ab34f0e3ea5_15.jpg'),\n PosixPath('data/carvana/train/de3ca5ec1e59_07.jpg'),\n PosixPath('data/carvana/train/28d9a149cb02_13.jpg'),\n PosixPath('data/carvana/train/36a3f7f77e85_12.jpg'),\n PosixPath('data/carvana/train/843763f47895_08.jpg')]Image.open(PATH/TRAIN_DN/f'**{CAR_ID}**_01.jpg').resize((300,200))\n```", "```py\nlist((PATH/MASKS_DN).iterdir())[:5][PosixPath('data/carvana/train_masks/6c0cd487abcd_03_mask.gif'),\n PosixPath('data/carvana/train_masks/351c583eabd6_01_mask.gif'),\n PosixPath('data/carvana/train_masks/90fdd8932877_02_mask.gif'),\n PosixPath('data/carvana/train_masks/28d9a149cb02_10_mask.gif'),\n PosixPath('data/carvana/train_masks/88bc32b9e1d9_14_mask.gif')]Image.open(PATH/MASKS_DN/f'**{CAR_ID}**_01_mask.gif').resize((300,200))\n```", "```py\nims = [open_image(PATH/TRAIN_DN/f'**{CAR_ID}**_{i+1:02d}.jpg') \n          **for** i **in** range(16)]fig, axes = plt.subplots(4, 4, figsize=(9, 6))\n**for** i,ax **in** enumerate(axes.flat): show_img(ims[i], ax=ax)\nplt.tight_layout(pad=0.1)\n```", "```py\n(PATH/'train_masks_png').mkdir(exist_ok=**True**)**def** convert_img(fn):\n    fn = fn.name\n    Image.open(PATH/'train_masks'/fn).save(PATH/'train_masks_png'/\n                     f'**{fn[:-4]}**.png')files = list((PATH/'train_masks').iterdir())\n**with** ThreadPoolExecutor(8) **as** e: e.map(convert_img, files)(PATH/'train_masks-128').mkdir(exist_ok=**True**)**def** resize_mask(fn):\n    Image.open(fn).resize((128,128)).save((fn.parent.parent)\n        /'train_masks-128'/fn.name)\n\nfiles = list((PATH/'train_masks_png').iterdir())\n**with** ThreadPoolExecutor(8) **as** e: e.map(resize_img, files)(PATH/'train-128').mkdir(exist_ok=**True**)**def** resize_img(fn):\n    Image.open(fn).resize((128,128)).save((fn.parent.parent)\n         /'train-128'/fn.name)\n\nfiles = list((PATH/'train').iterdir())\n**with** ThreadPoolExecutor(8) **as** e: e.map(resize_img, files)\n```", "```py\nTRAIN_DN = 'train-128'\nMASKS_DN = 'train_masks-128'\nsz = 128\nbs = 64ims = [open_image(PATH/TRAIN_DN\n            /f'**{CAR_ID}**_{i+1:02d}.jpg') **for** i **in** range(16)]\nim_masks = [open_image(PATH/MASKS_DN\n            /f'**{CAR_ID}**_{i+1:02d}_mask.png') **for** i **in** range(16)]\n```", "```py\nfig, axes = plt.subplots(4, 4, figsize=(9, 6))\n**for** i,ax **in** enumerate(axes.flat):\n    ax = show_img(ims[i], ax=ax)\n    show_img(im_masks[i][...,0], ax=ax, alpha=0.5)\nplt.tight_layout(pad=0.1)\n```", "```py\n**class** **MatchedFilesDataset**(FilesDataset):\n    **def** __init__(self, fnames, y, transform, path):\n        self.y=y\n        **assert**(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n    **def** get_y(self, i): \n        **return** open_image(os.path.join(self.path, self.y[i]))\n    **def** get_c(self): **return** 0x_names = np.array([Path(TRAIN_DN)/o **for** o **in** masks_csv['img']])\ny_names = np.array([Path(MASKS_DN)/f'**{o[:-4]}**_mask.png' \n                       **for** o **in** masks_csv['img']])len(x_names)//16//5*16*1008*\n```", "```py\nval_idxs = list(range(1008))\n((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names, \n                                              y_names)\nlen(val_x),len(trn_x)*(1008, 4080)*\n```", "```py\naug_tfms = [RandomRotate(4, tfm_y=TfmType.CLASS),\n            RandomFlip(tfm_y=TfmType.CLASS),\n            RandomLighting(0.05, 0.05)]\n*# aug_tfms = []*\n```", "```py\ntfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\ndatasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), (val_x,val_y), tfms, path=PATH)\nmd = ImageData(PATH, datasets, bs, num_workers=8, classes=**None**)denorm = md.trn_ds.denorm\nx,y = next(iter(md.aug_dl))\nx = denorm(x)\n```", "```py\nfig, axes = plt.subplots(5, 6, figsize=(12, 10))\n**for** i,ax **in** enumerate(axes.flat):\n    ax=show_img(x[i], ax=ax)\n    show_img(y[i], ax=ax, alpha=0.5)\nplt.tight_layout(pad=0.1)\n```", "```py\n**class** **Empty**(nn.Module): \n    **def** forward(self,x): **return** x\n\nmodels = ConvnetBuilder(resnet34, 0, 0, 0, custom_head=Empty())\nlearn = ConvLearner(md, models)\nlearn.summary()**class** **StdUpsample**(nn.Module):\n    **def** __init__(self, nin, nout):\n        super().__init__()\n        self.conv = nn.ConvTranspose2d(nin, nout, 2, stride=2)\n        self.bn = nn.BatchNorm2d(nout)\n\n    **def** forward(self, x): **return** self.bn(F.relu(self.conv(x)))flatten_channel = Lambda(**lambda** x: x[:,0])simple_up = nn.Sequential(\n    nn.ReLU(),\n    StdUpsample(512,256),\n    StdUpsample(256,256),\n    StdUpsample(256,256),\n    StdUpsample(256,256),\n    nn.ConvTranspose2d(256, 1, 2, stride=2),\n    flatten_channel\n)\n```", "```py\nmodels = ConvnetBuilder(resnet34, 0, 0, 0, custom_head=simple_up)\nlearn = ConvLearner(md, models)\nlearn.opt_fn=optim.Adam\nlearn.crit=nn.BCEWithLogitsLoss()\nlearn.metrics=[accuracy_thresh(0.5)]learn.lr_find()\nlearn.sched.plot()94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 30/32 [00:05<00:00,  5.48it/s, loss=10.6]\n```", "```py\nlr=4e-2learn.fit(lr,1,cycle_len=5,use_clr=(20,5))*epoch      trn_loss   val_loss   <lambda>                  \n    0      0.124078   0.133566   0.945951  \n    1      0.111241   0.112318   0.954912                  \n    2      0.099743   0.09817    0.957507                   \n    3      0.090651   0.092375   0.958117                   \n    4      0.084031   0.086026   0.963243**[0.086025625, 0.96324310824275017]*\n```", "```py\nlearn.save('tmp')learn.load('tmp')py,ay = learn.predict_with_targs()ay.shape*(1008, 128, 128)*\n```", "```py\nshow_img(ay[0]);\n```", "```py\nshow_img(py[0]>0);\n```", "```py\nlearn.unfreeze()learn.bn_freeze(**True**)lrs = np.array([lr/100,lr/10,lr])/4learn.fit(lrs,1,cycle_len=20,use_clr=(20,10))*epoch      trn_loss   val_loss   <lambda>                   \n    0      0.06577    0.053292   0.972977  \n    1      0.049475   0.043025   0.982559                   \n    2      0.039146   0.035927   0.98337                    \n    3      0.03405    0.031903   0.986982                   \n    4      0.029788   0.029065   0.987944                   \n    5      0.027374   0.027752   0.988029                   \n    6      0.026041   0.026718   0.988226                   \n    7      0.024302   0.025927   0.989512                   \n    8      0.022921   0.026102   0.988276                   \n    9      0.021944   0.024714   0.989537                   \n    10     0.021135   0.0241     0.990628                   \n    11     0.020494   0.023367   0.990652                   \n    12     0.01988    0.022961   0.990989                   \n    13     0.019241   0.022498   0.991014                   \n    14     0.018697   0.022492   0.990571                   \n    15     0.01812    0.021771   0.99105                    \n    16     0.017597   0.02183    0.991365                   \n    17     0.017192   0.021434   0.991364                   \n    18     0.016768   0.021383   0.991643                   \n    19     0.016418   0.021114   0.99173**[0.021113895, 0.99172959849238396]*\n```", "```py\nlearn.save('0')x,y = next(iter(md.val_dl))\npy = to_np(learn.model(V(x)))\n```", "```py\nax = show_img(denorm(x)[0])\nshow_img(py[0]>0, ax=ax, alpha=0.5);\n```", "```py\nax = show_img(denorm(x)[0])\nshow_img(y[0], ax=ax, alpha=0.5);\n```", "```py\nTRAIN_DN = 'train'\nMASKS_DN = 'train_masks_png'\nsz = 512\nbs = 16x_names = np.array([Path(TRAIN_DN)/o **for** o **in** masks_csv['img']])\ny_names = np.array([Path(MASKS_DN)/f'**{o[:-4]}**_mask.png' \n                      **for** o **in** masks_csv['img']])((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names, \n                                      y_names)\nlen(val_x),len(trn_x)*(1008, 4080)*tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO,\n                         tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\ndatasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y),\n                      (val_x,val_y), tfms, path=PATH)\nmd = ImageData(PATH, datasets, bs, num_workers=8, classes=**None**)denorm = md.trn_ds.denorm\nx,y = next(iter(md.aug_dl))\nx = denorm(x)\n```", "```py\nfig, axes = plt.subplots(4, 4, figsize=(10, 10))\n**for** i,ax **in** enumerate(axes.flat):\n    ax=show_img(x[i], ax=ax)\n    show_img(y[i], ax=ax, alpha=0.5)\nplt.tight_layout(pad=0.1)\n```", "```py\nsimple_up = nn.Sequential(\n    nn.ReLU(),\n    StdUpsample(512,256),\n    StdUpsample(256,256),\n    StdUpsample(256,256),\n    StdUpsample(256,256),\n    nn.ConvTranspose2d(256, 1, 2, stride=2),\n    flatten_channel\n)models = ConvnetBuilder(resnet34, 0, 0, 0, custom_head=simple_up)\nlearn = ConvLearner(md, models)\nlearn.opt_fn=optim.Adam\nlearn.crit=nn.BCEWithLogitsLoss()\nlearn.metrics=[accuracy_thresh(0.5)]learn.load('0')learn.lr_find()\nlearn.sched.plot()85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 218/255 [02:12<00:22,  1.64it/s, loss=8.91]\n```", "```py\nlr=4e-2learn.fit(lr,1,cycle_len=5,use_clr=(20,5))epoch      trn_loss   val_loss   <lambda>                     \n    0      0.02178    0.020653   0.991708  \n    1      0.017927   0.020653   0.990241                     \n    2      0.015958   0.016115   0.993394                     \n    3      0.015172   0.015143   0.993696                     \n    4      0.014315   0.014679   0.99388[0.014679321, 0.99388032489352751]learn.save('tmp')learn.load('tmp')learn.unfreeze()\nlearn.bn_freeze(**True**)lrs = np.array([lr/100,lr/10,lr])/4learn.fit(lrs,1,cycle_len=8,use_clr=(20,8))epoch      trn_loss   val_loss   mask_acc                     \n    0      0.038687   0.018685   0.992782  \n    1      0.024906   0.014355   0.994933                     \n    2      0.025055   0.014737   0.995526                     \n    3      0.024155   0.014083   0.995708                     \n    4      0.013446   0.010564   0.996166                     \n    5      0.01607    0.010555   0.996096                     \n    6      0.019197   0.010883   0.99621                      \n    7      0.016157   0.00998    0.996393[0.0099797687, 0.99639255659920833]learn.save('512')x,y = next(iter(md.val_dl))\npy = to_np(learn.model(V(x)))ax = show_img(denorm(x)[0])\nshow_img(py[0]>0, ax=ax, alpha=0.5);\n```", "```py\nax = show_img(denorm(x)[0])\nshow_img(y[0], ax=ax, alpha=0.5);\n```", "```py\nsz = 1024\nbs = 4tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO,\n                         tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\ndatasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), \n                            (val_x,val_y), tfms, path=PATH)\nmd = ImageData(PATH, datasets, bs, num_workers=8, classes=**None**)denorm = md.trn_ds.denorm\nx,y = next(iter(md.aug_dl))\nx = denorm(x)\ny = to_np(y)fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n**for** i,ax **in** enumerate(axes.flat):\n    show_img(x[i], ax=ax)\n    show_img(y[i], ax=ax, alpha=0.5)\nplt.tight_layout(pad=0.1)\n```", "```py\nsimple_up = nn.Sequential(\n    nn.ReLU(),\n    StdUpsample(512,256),\n    StdUpsample(256,256),\n    StdUpsample(256,256),\n    StdUpsample(256,256),\n    nn.ConvTranspose2d(256, 1, 2, stride=2),\n    flatten_channel,\n)models = ConvnetBuilder(resnet34, 0, 0, 0, custom_head=simple_up)\nlearn = ConvLearner(md, models)\nlearn.opt_fn=optim.Adam\nlearn.crit=nn.BCEWithLogitsLoss()\nlearn.metrics=[accuracy_thresh(0.5)]learn.load('512')learn.lr_find()\nlearn.sched.plot()85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 218/255 [02:12<00:22,  1.64it/s, loss=8.91]\n```", "```py\nlr=4e-2learn.fit(lr,1,cycle_len=2,use_clr=(20,4))*epoch      trn_loss   val_loss   <lambda>                       \n    0      0.01066    0.011119   0.996227  \n    1      0.009357   0.009696   0.996553**[0.0096957013, 0.99655332546385511]*learn.save('tmp')learn.load('tmp')learn.unfreeze()\nlearn.bn_freeze(**True**)lrs = np.array([lr/100,lr/10,lr])/8learn.fit(lrs,1,cycle_len=40,use_clr=(20,10))*epoch      trn_loss   val_loss   mask_acc                       \n    0      0.015565   0.007449   0.997661  \n    1      0.01979    0.008376   0.997542                       \n    2      0.014874   0.007826   0.997736                       \n    3      0.016104   0.007854   0.997347                       \n    4      0.023386   0.009745   0.997218                       \n    5      0.018972   0.008453   0.997588                       \n    6      0.013184   0.007612   0.997588                       \n    7      0.010686   0.006775   0.997688                       \n    8      0.0293     0.015299   0.995782                       \n    9      0.018713   0.00763    0.997638                       \n    10     0.015432   0.006575   0.9978                         \n    11     0.110205   0.060062   0.979043                      \n    12     0.014374   0.007753   0.997451                       \n    13     0.022286   0.010282   0.997587                       \n    14     0.015645   0.00739    0.997776                       \n    15     0.013821   0.00692    0.997869                       \n    16     0.022389   0.008632   0.997696                       \n    17     0.014607   0.00677    0.997837                       \n    18     0.018748   0.008194   0.997657                       \n    19     0.016447   0.007237   0.997899                       \n    20     0.023596   0.008211   0.997918                       \n    21     0.015721   0.00674    0.997848                       \n    22     0.01572    0.006415   0.998006                       \n    23     0.019519   0.007591   0.997876                       \n    24     0.011159   0.005998   0.998053                       \n    25     0.010291   0.005806   0.998012                       \n    26     0.010893   0.005755   0.998046                       \n    27     0.014534   0.006313   0.997901                       \n    28     0.020971   0.006855   0.998018                       \n    29     0.014074   0.006107   0.998053                       \n    30     0.01782    0.006561   0.998114                       \n    31     0.01742    0.006414   0.997942                       \n    32     0.016829   0.006514   0.9981                         \n    33     0.013148   0.005819   0.998033                       \n    34     0.023495   0.006261   0.997856                       \n    35     0.010931   0.005516   0.99812                        \n    36     0.015798   0.006176   0.998126                       \n    37     0.021636   0.005931   0.998067                       \n    38     0.012133   0.005496   0.998158                       \n    39     0.012562   0.005678   0.998172**[0.0056782686, 0.99817223208291195]*learn.save('1024')x,y = next(iter(md.val_dl))\npy = to_np(learn.model(V(x)))ax = show_img(denorm(x)[0])\nshow_img(py[0][0]>0, ax=ax, alpha=0.5);\n```", "```py\nax = show_img(denorm(x)[0])\nshow_img(y[0,...,-1], ax=ax, alpha=0.5);\n```", "```py\nshow_img(py[0][0]>0);\n```", "```py\nshow_img(y[0,...,-1]);\n```", "```py\n%matplotlib inline\n%reload_ext autoreload\n%autoreload 2**from** **fastai.conv_learner** **import** *\n**from** **fastai.dataset** **import** *\n**from** **fastai.models.resnet** **import** vgg_resnet50\n\n**import** **json**torch.backends.cudnn.benchmark=**True**\n```", "```py\nPATH = Path('data/carvana')\nMASKS_FN = 'train_masks.csv'\nMETA_FN = 'metadata.csv'\nmasks_csv = pd.read_csv(PATH/MASKS_FN)\nmeta_csv = pd.read_csv(PATH/META_FN)**def** show_img(im, figsize=**None**, ax=**None**, alpha=**None**):\n    **if** **not** ax: fig,ax = plt.subplots(figsize=figsize)\n    ax.imshow(im, alpha=alpha)\n    ax.set_axis_off()\n    **return** axTRAIN_DN = 'train-128'\nMASKS_DN = 'train_masks-128'\nsz = 128\nbs = 64\nnw = 16TRAIN_DN = 'train'\nMASKS_DN = 'train_masks_png'\nsz = 128\nbs = 64\nnw = 16**class** **MatchedFilesDataset**(FilesDataset):\n    **def** __init__(self, fnames, y, transform, path):\n        self.y=y\n        **assert**(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n    **def** get_y(self, i): \n        **return** open_image(os.path.join(self.path, self.y[i]))\n    **def** get_c(self): **return** 0x_names = np.array([Path(TRAIN_DN)/o **for** o **in** masks_csv['img']])\ny_names = np.array([Path(MASKS_DN)/f'**{o[:-4]}**_mask.png' \n                        **for** o **in** masks_csv['img']])val_idxs = list(range(1008))\n((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names, \n                                             y_names)aug_tfms = [RandomRotate(4, tfm_y=TfmType.CLASS),\n            RandomFlip(tfm_y=TfmType.CLASS),\n            RandomLighting(0.05, 0.05, tfm_y=TfmType.CLASS)]tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO, \n                        tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\ndatasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), \n                             (val_x,val_y), tfms, path=PATH)\nmd = ImageData(PATH, datasets, bs, num_workers=16, classes=**None**)\ndenorm = md.trn_ds.denormx,y = next(iter(md.trn_dl))x.shape,y.shape*(torch.Size([64, 3, 128, 128]), torch.Size([64, 128, 128]))*\n```", "```py\nf = resnet34\ncut,lr_cut = model_meta[f]**def** get_base():\n    layers = cut_model(f(**True**), cut)\n    **return** nn.Sequential(*layers)**def** dice(pred, targs):\n    pred = (pred>0).float()\n    **return** 2\\. * (pred*targs).sum() / (pred+targs).sum()\n```", "```py\n**class** **StdUpsample**(nn.Module):\n    **def** __init__(self, nin, nout):\n        super().__init__()\n        self.conv = nn.ConvTranspose2d(nin, nout, 2, stride=2)\n        self.bn = nn.BatchNorm2d(nout)\n\n    **def** forward(self, x): **return** self.bn(F.relu(self.conv(x)))\n```", "```py\n**class** **Upsample34**(nn.Module):\n    **def** __init__(self, rn):\n        super().__init__()\n        self.rn = rn\n        self.features = nn.Sequential(\n            rn, nn.ReLU(),\n            StdUpsample(512,256),\n            StdUpsample(256,256),\n            StdUpsample(256,256),\n            StdUpsample(256,256),\n            nn.ConvTranspose2d(256, 1, 2, stride=2))\n\n    **def** forward(self,x): **return** self.features(x)[:,0]**class** **UpsampleModel**():\n    **def** __init__(self,model,name='upsample'):\n        self.model,self.name = model,name\n\n    **def** get_layer_groups(self, precompute):\n        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n        **return** lgs + [children(self.model.features)[1:]]m_base = get_base() m = to_gpu(Upsample34(m_base))\nmodels = UpsampleModel(m)learn = ConvLearner(md, models)\nlearn.opt_fn=optim.Adam\nlearn.crit=nn.BCEWithLogitsLoss()\nlearn.metrics=[accuracy_thresh(0.5),dice]learn.freeze_to(1)learn.lr_find()\nlearn.sched.plot()86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588          | 55/64 [00:22<00:03,  2.46it/s, loss=3.21]\n```", "```py\nlr=4e-2\nwd=1e-7\nlrs = np.array([lr/100,lr/10,lr])/2learn.fit(lr,1, wds=wd, cycle_len=4,use_clr=(20,8))0%|          | 0/64 [00:00<?, ?it/s]\nepoch      trn_loss   val_loss   <lambda>   dice           \n    0      0.216882   0.133512   0.938017   0.855221  \n    1      0.169544   0.115158   0.946518   0.878381       \n    2      0.153114   0.099104   0.957748   0.903353       \n    3      0.144105   0.093337   0.964404   0.915084[0.09333742126112893, 0.9644036065964472, 0.9150839788573129]learn.save('tmp')learn.load('tmp')learn.unfreeze()\nlearn.bn_freeze(**True**)learn.fit(lrs,1,cycle_len=4,use_clr=(20,8))epoch      trn_loss   val_loss   <lambda>   dice           \n    0      0.174897   0.061603   0.976321   0.94382   \n    1      0.122911   0.053625   0.982206   0.957624       \n    2      0.106837   0.046653   0.985577   0.965792       \n    3      0.099075   0.042291   0.986519   0.968925[0.042291240323157536, 0.986519161670927, 0.9689251193924556]\n```", "```py\nlearn.save('128')x,y = next(iter(md.val_dl))\npy = to_np(learn.model(V(x)))show_img(py[0]>0);\n```", "```py\nshow_img(y[0]);\n```", "```py\n**class** **SaveFeatures**():\n    features=**None**\n    **def** __init__(self, m):\n        self.hook = m.register_forward_hook(self.hook_fn)\n    **def** hook_fn(self, module, input, output): self.features = output\n    **def** remove(self): self.hook.remove()\n```", "```py\n**class** **UnetBlock**(nn.Module):\n    **def** __init__(self, up_in, x_in, n_out):\n        super().__init__()\n        up_out = x_out = n_out//2\n        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, \n                                          stride=2)\n        self.bn = nn.BatchNorm2d(n_out)\n\n    **def** forward(self, up_p, x_p):\n        up_p = self.tr_conv(up_p)\n        x_p = self.x_conv(x_p)\n        cat_p = torch.cat([up_p,x_p], dim=1)\n        **return** self.bn(F.relu(cat_p))**class** **Unet34**(nn.Module):\n    **def** __init__(self, rn):\n        super().__init__()\n        self.rn = rn\n        self.sfs = [SaveFeatures(rn[i]) **for** i **in** [2,4,5,6]]\n        self.up1 = UnetBlock(512,256,256)\n        self.up2 = UnetBlock(256,128,256)\n        self.up3 = UnetBlock(256,64,256)\n        self.up4 = UnetBlock(256,64,256)\n        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n\n    **def** forward(self,x):\n        x = F.relu(self.rn(x))\n        x = self.up1(x, self.sfs[3].features)\n        x = self.up2(x, self.sfs[2].features)\n        x = self.up3(x, self.sfs[1].features)\n        x = self.up4(x, self.sfs[0].features)\n        x = self.up5(x)\n        **return** x[:,0]\n\n    **def** close(self):\n        **for** sf **in** self.sfs: sf.remove()**class** **UnetModel**():\n    **def** __init__(self,model,name='unet'):\n        self.model,self.name = model,name\n\n    **def** get_layer_groups(self, precompute):\n        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n        **return** lgs + [children(self.model)[1:]]\n```", "```py\nm_base = get_base()\nm = to_gpu(Unet34(m_base))\nmodels = UnetModel(m)learn = ConvLearner(md, models)\nlearn.opt_fn=optim.Adam\nlearn.crit=nn.BCEWithLogitsLoss()\nlearn.metrics=[accuracy_thresh(0.5),dice]learn.summary()OrderedDict([('Conv2d-1',\n              OrderedDict([('input_shape', [-1, 3, 128, 128]),\n                           ('output_shape', [-1, 64, 64, 64]),\n                           ('trainable', False),\n                           ('nb_params', 9408)])),\n             ('BatchNorm2d-2',\n              OrderedDict([('input_shape', [-1, 64, 64, 64]),\n                           ('output_shape', [-1, 64, 64, 64]),\n                           ('trainable', False),\n                           ('nb_params', 128)])),\n             ('ReLU-3',\n              OrderedDict([('input_shape', [-1, 64, 64, 64]),\n                           ('output_shape', [-1, 64, 64, 64]),\n                           ('nb_params', 0)])),\n             ('MaxPool2d-4',\n              OrderedDict([('input_shape', [-1, 64, 64, 64]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('nb_params', 0)])),\n             ('Conv2d-5',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('trainable', False),\n                           ('nb_params', 36864)])),\n             ('BatchNorm2d-6',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('trainable', False),\n                           ('nb_params', 128)])),\n             ('ReLU-7',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('nb_params', 0)])),\n             ('Conv2d-8',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('trainable', False),\n                           ('nb_params', 36864)])),\n             ('BatchNorm2d-9',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('trainable', False),\n                           ('nb_params', 128)])),\n             ('ReLU-10',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-11',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('nb_params', 0)])),\n             ('Conv2d-12',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('trainable', False),\n                           ('nb_params', 36864)])),\n             ('BatchNorm2d-13',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('trainable', False),\n                           ('nb_params', 128)])),\n             ('ReLU-14',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('nb_params', 0)])),\n             ('Conv2d-15',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('trainable', False),\n                           ('nb_params', 36864)])),\n             ('BatchNorm2d-16',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('trainable', False),\n                           ('nb_params', 128)])),\n             ('ReLU-17',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-18',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('nb_params', 0)])),\n             ('Conv2d-19',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('trainable', False),\n                           ('nb_params', 36864)])),\n             ('BatchNorm2d-20',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('trainable', False),\n                           ('nb_params', 128)])),\n             ('ReLU-21',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('nb_params', 0)])),\n             ('Conv2d-22',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('trainable', False),\n                           ('nb_params', 36864)])),\n             ('BatchNorm2d-23',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('trainable', False),\n                           ('nb_params', 128)])),\n             ('ReLU-24',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-25',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 64, 32, 32]),\n                           ('nb_params', 0)])),\n             ('Conv2d-26',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 73728)])),\n             ('BatchNorm2d-27',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 256)])),\n             ('ReLU-28',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('nb_params', 0)])),\n             ('Conv2d-29',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 147456)])),\n             ('BatchNorm2d-30',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 256)])),\n             ('Conv2d-31',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 8192)])),\n             ('BatchNorm2d-32',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 256)])),\n             ('ReLU-33',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-34',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('nb_params', 0)])),\n             ('Conv2d-35',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 147456)])),\n             ('BatchNorm2d-36',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 256)])),\n             ('ReLU-37',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('nb_params', 0)])),\n             ('Conv2d-38',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 147456)])),\n             ('BatchNorm2d-39',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 256)])),\n             ('ReLU-40',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-41',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('nb_params', 0)])),\n             ('Conv2d-42',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 147456)])),\n             ('BatchNorm2d-43',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 256)])),\n             ('ReLU-44',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('nb_params', 0)])),\n             ('Conv2d-45',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 147456)])),\n             ('BatchNorm2d-46',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 256)])),\n             ('ReLU-47',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-48',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('nb_params', 0)])),\n             ('Conv2d-49',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 147456)])),\n             ('BatchNorm2d-50',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 256)])),\n             ('ReLU-51',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('nb_params', 0)])),\n             ('Conv2d-52',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 147456)])),\n             ('BatchNorm2d-53',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', False),\n                           ('nb_params', 256)])),\n             ('ReLU-54',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-55',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('nb_params', 0)])),\n             ('Conv2d-56',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 294912)])),\n             ('BatchNorm2d-57',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('ReLU-58',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('Conv2d-59',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 589824)])),\n             ('BatchNorm2d-60',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('Conv2d-61',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 32768)])),\n             ('BatchNorm2d-62',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('ReLU-63',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-64',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('Conv2d-65',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 589824)])),\n             ('BatchNorm2d-66',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('ReLU-67',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('Conv2d-68',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 589824)])),\n             ('BatchNorm2d-69',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('ReLU-70',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-71',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('Conv2d-72',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 589824)])),\n             ('BatchNorm2d-73',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('ReLU-74',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('Conv2d-75',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 589824)])),\n             ('BatchNorm2d-76',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('ReLU-77',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-78',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('Conv2d-79',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 589824)])),\n             ('BatchNorm2d-80',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('ReLU-81',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('Conv2d-82',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 589824)])),\n             ('BatchNorm2d-83',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('ReLU-84',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-85',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('Conv2d-86',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 589824)])),\n             ('BatchNorm2d-87',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('ReLU-88',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('Conv2d-89',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 589824)])),\n             ('BatchNorm2d-90',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('ReLU-91',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-92',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('Conv2d-93',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 589824)])),\n             ('BatchNorm2d-94',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('ReLU-95',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('Conv2d-96',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 589824)])),\n             ('BatchNorm2d-97',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', False),\n                           ('nb_params', 512)])),\n             ('ReLU-98',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-99',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('Conv2d-100',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 1179648)])),\n             ('BatchNorm2d-101',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 1024)])),\n             ('ReLU-102',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('nb_params', 0)])),\n             ('Conv2d-103',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 2359296)])),\n             ('BatchNorm2d-104',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 1024)])),\n             ('Conv2d-105',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 131072)])),\n             ('BatchNorm2d-106',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 1024)])),\n             ('ReLU-107',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-108',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('nb_params', 0)])),\n             ('Conv2d-109',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 2359296)])),\n             ('BatchNorm2d-110',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 1024)])),\n             ('ReLU-111',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('nb_params', 0)])),\n             ('Conv2d-112',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 2359296)])),\n             ('BatchNorm2d-113',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 1024)])),\n             ('ReLU-114',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-115',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('nb_params', 0)])),\n             ('Conv2d-116',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 2359296)])),\n             ('BatchNorm2d-117',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 1024)])),\n             ('ReLU-118',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('nb_params', 0)])),\n             ('Conv2d-119',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 2359296)])),\n             ('BatchNorm2d-120',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('trainable', False),\n                           ('nb_params', 1024)])),\n             ('ReLU-121',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('nb_params', 0)])),\n             ('BasicBlock-122',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 512, 4, 4]),\n                           ('nb_params', 0)])),\n             ('ConvTranspose2d-123',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 128, 8, 8]),\n                           ('trainable', True),\n                           ('nb_params', 262272)])),\n             ('Conv2d-124',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 128, 8, 8]),\n                           ('trainable', True),\n                           ('nb_params', 32896)])),\n             ('BatchNorm2d-125',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('trainable', True),\n                           ('nb_params', 512)])),\n             ('UnetBlock-126',\n              OrderedDict([('input_shape', [-1, 512, 4, 4]),\n                           ('output_shape', [-1, 256, 8, 8]),\n                           ('nb_params', 0)])),\n             ('ConvTranspose2d-127',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', True),\n                           ('nb_params', 131200)])),\n             ('Conv2d-128',\n              OrderedDict([('input_shape', [-1, 128, 16, 16]),\n                           ('output_shape', [-1, 128, 16, 16]),\n                           ('trainable', True),\n                           ('nb_params', 16512)])),\n             ('BatchNorm2d-129',\n              OrderedDict([('input_shape', [-1, 256, 16, 16]),\n                           ('output_shape', [-1, 256, 16, 16]),\n                           ('trainable', True),\n                           ('nb_params', 512)])),\n             ('UnetBlock-130',\n              OrderedDict([('input_shape', [-1, 256, 8, 8]),\n                           ('output_shape', [-1, 256, 16, 16]),\n                           ('nb_params', 0)])),\n             ('ConvTranspose2d-131',\n              OrderedDict([('input_shape', [-1, 256, 16, 16]),\n                           ('output_shape', [-1, 128, 32, 32]),\n                           ('trainable', True),\n                           ('nb_params', 131200)])),\n             ('Conv2d-132',\n              OrderedDict([('input_shape', [-1, 64, 32, 32]),\n                           ('output_shape', [-1, 128, 32, 32]),\n                           ('trainable', True),\n                           ('nb_params', 8320)])),\n             ('BatchNorm2d-133',\n              OrderedDict([('input_shape', [-1, 256, 32, 32]),\n                           ('output_shape', [-1, 256, 32, 32]),\n                           ('trainable', True),\n                           ('nb_params', 512)])),\n             ('UnetBlock-134',\n              OrderedDict([('input_shape', [-1, 256, 16, 16]),\n                           ('output_shape', [-1, 256, 32, 32]),\n                           ('nb_params', 0)])),\n             ('ConvTranspose2d-135',\n              OrderedDict([('input_shape', [-1, 256, 32, 32]),\n                           ('output_shape', [-1, 128, 64, 64]),\n                           ('trainable', True),\n                           ('nb_params', 131200)])),\n             ('Conv2d-136',\n              OrderedDict([('input_shape', [-1, 64, 64, 64]),\n                           ('output_shape', [-1, 128, 64, 64]),\n                           ('trainable', True),\n                           ('nb_params', 8320)])),\n             ('BatchNorm2d-137',\n              OrderedDict([('input_shape', [-1, 256, 64, 64]),\n                           ('output_shape', [-1, 256, 64, 64]),\n                           ('trainable', True),\n                           ('nb_params', 512)])),\n             ('UnetBlock-138',\n              OrderedDict([('input_shape', [-1, 256, 32, 32]),\n                           ('output_shape', [-1, 256, 64, 64]),\n                           ('nb_params', 0)])),\n             ('ConvTranspose2d-139',\n              OrderedDict([('input_shape', [-1, 256, 64, 64]),\n                           ('output_shape', [-1, 1, 128, 128]),\n                           ('trainable', True),\n                           ('nb_params', 1025)]))])[o.features.size() **for** o **in** m.sfs]*[torch.Size([3, 64, 64, 64]),\n torch.Size([3, 64, 32, 32]),\n torch.Size([3, 128, 16, 16]),\n torch.Size([3, 256, 8, 8])]*learn.freeze_to(1)learn.lr_find()\nlearn.sched.plot() 0%|                                                                                           | 0/64 [00:00<?, ?it/s]92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d     | 59/64 [00:22<00:01,  2.68it/s, loss=2.45]\n```", "```py\nlr=4e-2\nwd=1e-7\n\nlrs = np.array([lr/100,lr/10,lr])learn.fit(lr,1,wds=wd,cycle_len=8,use_clr=(5,8))*epoch      trn_loss   val_loss   <lambda>   dice           \n    0      0.12936    0.03934    0.988571   0.971385  \n    1      0.098401   0.039252   0.990438   0.974921        \n    2      0.087789   0.02539    0.990961   0.978927        \n    3      0.082625   0.027984   0.988483   0.975948        \n    4      0.079509   0.025003   0.99171    0.981221        \n    5      0.076984   0.022514   0.992462   0.981881        \n    6      0.076822   0.023203   0.992484   0.982321        \n    7      0.075488   0.021956   0.992327   0.982704**[0.021955982234979434, 0.9923273126284281, 0.9827044502137199]*learn.save('128urn-tmp')learn.load('128urn-tmp')learn.unfreeze()\nlearn.bn_freeze(**True**)learn.fit(lrs/4, 1, wds=wd, cycle_len=20,use_clr=(20,10))0%|          | 0/64 [00:00<?, ?it/s]\nepoch      trn_loss   val_loss   <lambda>   dice            \n    0      0.073786   0.023418   0.99297    0.98283   \n    1      0.073561   0.020853   0.992142   0.982725        \n    2      0.075227   0.023357   0.991076   0.980879        \n    3      0.074245   0.02352    0.993108   0.983659        \n    4      0.073434   0.021508   0.993024   0.983609        \n    5      0.073092   0.020956   0.993188   0.983333        \n    6      0.073617   0.019666   0.993035   0.984102        \n    7      0.072786   0.019844   0.993196   0.98435         \n    8      0.072256   0.018479   0.993282   0.984277        \n    9      0.072052   0.019479   0.993164   0.984147        \n    10     0.071361   0.019402   0.993344   0.984541        \n    11     0.070969   0.018904   0.993139   0.984499        \n    12     0.071588   0.018027   0.9935     0.984543        \n    13     0.070709   0.018345   0.993491   0.98489         \n    14     0.072238   0.019096   0.993594   0.984825        \n    15     0.071407   0.018967   0.993446   0.984919        \n    16     0.071047   0.01966    0.993366   0.984952        \n    17     0.072024   0.018133   0.993505   0.98497         \n    18     0.071517   0.018464   0.993602   0.985192        \n    19     0.070109   0.018337   0.993614   0.9852[0.018336569653853538, 0.9936137114252362, 0.9852004420189631]\n```", "```py\nlearn.save('128urn-0')learn.load('128urn-0')x,y = next(iter(md.val_dl))\npy = to_np(learn.model(V(x)))\n```", "```py\nshow_img(py[0]>0);\n```", "```py\nshow_img(y[0]);\n```", "```py\nm.close()\n```", "```py\nsz=512\nbs=16tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO, \n                       tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\ndatasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), \n                            (val_x,val_y), tfms, path=PATH)\nmd = ImageData(PATH, datasets, bs, num_workers=4, classes=**None**)\ndenorm = md.trn_ds.denormm_base = get_base()\nm = to_gpu(Unet34(m_base))\nmodels = UnetModel(m)learn = ConvLearner(md, models)\nlearn.opt_fn=optim.Adam\nlearn.crit=nn.BCEWithLogitsLoss()\nlearn.metrics=[accuracy_thresh(0.5),dice]learn.freeze_to(1)**learn.load('128urn-0')**learn.fit(lr,1,wds=wd, cycle_len=5,use_clr=(5,5))epoch      trn_loss   val_loss   <lambda>   dice              \n    0      0.071421   0.02362    0.996459   0.991772  \n    1      0.070373   0.014013   0.996558   0.992602          \n    2      0.067895   0.011482   0.996705   0.992883          \n    3      0.070653   0.014256   0.996695   0.992771          \n    4      0.068621   0.013195   0.996993   0.993359[0.013194938530288046, 0.996993034604996, 0.993358936574724]\n```", "```py\nlearn.save('512urn-tmp')learn.unfreeze()\nlearn.bn_freeze(**True**)learn.load('512urn-tmp')learn.fit(lrs/4,1,wds=wd, cycle_len=8,use_clr=(20,8))epoch      trn_loss   val_loss   <lambda>   dice              \n    0      0.06605    0.013602   0.997      0.993014  \n    1      0.066885   0.011252   0.997248   0.993563          \n    2      0.065796   0.009802   0.997223   0.993817          \n    3      0.065089   0.009668   0.997296   0.993744          \n    4      0.064552   0.011683   0.997269   0.993835          \n    5      0.065089   0.010553   0.997415   0.993827          \n    6      0.064303   0.009472   0.997431   0.994046          \n    7      0.062506   0.009623   0.997441   0.994118[0.009623114736602894, 0.9974409020136273, 0.9941179137381296]\n```", "```py\nlearn.save('512urn')learn.load('512urn')x,y = next(iter(md.val_dl))\npy = to_np(learn.model(V(x)))\n```", "```py\nshow_img(py[0]>0);\n```", "```py\nshow_img(y[0]);\n```", "```py\nm.close()\n```", "```py\nsz=1024\nbs=4tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO, \n                         tfm_y=TfmType.CLASS)\ndatasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), \n                            (val_x,val_y), tfms, path=PATH)\nmd = ImageData(PATH, datasets, bs, num_workers=16, classes=**None**)\ndenorm = md.trn_ds.denormm_base = get_base()\nm = to_gpu(Unet34(m_base))\nmodels = UnetModel(m)learn = ConvLearner(md, models)\nlearn.opt_fn=optim.Adam\nlearn.crit=nn.BCEWithLogitsLoss()\nlearn.metrics=[accuracy_thresh(0.5),dice]\n```", "```py\nlearn.load('512urn')learn.freeze_to(1)learn.fit(lr,1, wds=wd, cycle_len=2,use_clr=(5,4))epoch      trn_loss   val_loss   <lambda>   dice                 \n    0      0.007656   0.008155   0.997247   0.99353   \n    1      0.004706   0.00509    0.998039   0.995437[0.005090427414942828, 0.9980387706605215, 0.995437301104031]\n```", "```py\nlearn.save('1024urn-tmp')learn.load('1024urn-tmp')learn.unfreeze()\nlearn.bn_freeze(**True**)lrs = np.array([lr/200,lr/30,lr])learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))epoch      trn_loss   val_loss   <lambda>   dice                 \n    0      0.005688   0.006135   0.997616   0.994616  \n    1      0.004412   0.005223   0.997983   0.995349             \n    2      0.004186   0.004975   0.99806    0.99554              \n    3      0.004016   0.004899   0.99812    0.995627[0.004898778487196458, 0.9981196409180051, 0.9956271404784823]learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))epoch      trn_loss   val_loss   <lambda>   dice                 \n    0      0.004169   0.004962   0.998049   0.995517  \n    1      0.004022   0.004595   0.99823    0.995818             \n    2      0.003772   0.004497   0.998215   0.995916             \n    3      0.003618   0.004435   0.998291   0.995991[0.004434524739663753, 0.9982911745707194, 0.9959913929776539]\n```", "```py\nlearn.sched.plot_loss()\n```", "```py\nlearn.save('1024urn')learn.load('1024urn')x,y = next(iter(md.val_dl))\npy = to_np(learn.model(V(x)))\n```", "```py\nshow_img(py[0]>0);\n```", "```py\nshow_img(y[0]);\n```"]