- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:58:41'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2011.00940] Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors:
    A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2011.00940](https://ar5iv.labs.arxiv.org/html/2011.00940)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Dan Zhao Guizhi Xu Zhenghua Xu [zhenghua.xu@hebut.edu.cn](mailto:zhenghua.xu@hebut.edu.cn)
    Thomas Lukasiewicz Minmin Xue Zhigang Fu State Key Laboratory of Reliability and
    Intelligence of Electrical Equipment, Hebei University of Technology, China Key
    Laboratory of Electromagnetic Field and Electrical Apparatus Reliability of Hebei
    Province, Hebei University of Technology, China Department of Computer Science,
    University of Oxford, UK Department of Health Management Center, 983 Hospital
    of Joint Logistics Support Force, Tianjin, 300142, China
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Computer-Aided Diagnosis and Treatment of Tumors is a hot topic of deep learning
    in recent years, which constitutes a series of medical tasks, such as detection
    of tumor markers, the outline of tumor leisures, subtypes and stages of tumors,
    prediction of therapeutic effect, and drug development. Meanwhile, there are some
    deep learning models with precise positioning and excellent performance produced
    in mainstream task scenarios. Thus follow to introduce deep learning methods from
    task-orient, mainly focus on the improvements for medical tasks. Then to summarize
    the recent progress in four stages of tumor diagnosis and treatment, which named
    In-Vitro Diagnosis (IVD), Imaging Diagnosis (ID), Pathological Diagnosis (PD),
    and Treatment Planning (TP). According to the specific data types and medical
    tasks of each stage, we present the applications of deep learning in the Computer-Aided
    Diagnosis and Treatment of Tumors and analyzing the excellent works therein. This
    survey concludes by discussing research issues and suggesting challenges for future
    improvement.
  prefs: []
  type: TYPE_NORMAL
- en: 'keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Deep learning, tumor diagnosis, tumor treatment, tumor prediction, medical
    application.^†^†journal: Journal of Neurocomputing\MakePerPage'
  prefs: []
  type: TYPE_NORMAL
- en: footnote
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cancer is a leading cause of death and a notable public health problem worldwide.
    According to Global Cancer Statistics [[1](#bib.bib1)], by 2018, there will be
    an estimation of 18.1 million new cancer cases and 9.6 million deaths caused by
    cancer. Thus to diagnose early and treat compatibly becomes one of the most important
    research topics in medicine. Previously, people devote to the simple medical method
    to approach the above goal, which depends on the information obtained by the doctor’s
    perception and the experiences gained by years. While the perception can be influenced
    by objective factors (e.g., sensory threshold, fatigue, and prior knowledge.)
    and the acquisition of experience often costs more time, and such experience is
    often subjective. With the tremendous development of artificial intelligence,
    considerable attention has been paid to plentiful applications based on artificial
    intelligence that was used for Computer-Aided Diagnosis and Treatment of Tumors
    because this technique could assist solve the above two issues. Since Hinton et
    al. [[2](#bib.bib2)] prove that traditional statistical methods are not necessary
    to extract features as long as computing resources are sufficient, deep neural
    networks have been asked to learn useful latent features from big data. After
    that, deep learning has become a new force in Computer-Aided Diagnosis and Treatment
    of Tumors.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, deep learning differentiates many delicate branches to perform different
    tasks for different data types. The two most commonly branches are Computer Vision
    (CV), Natural Language Processing (NLP). In Computer Vision, deep learning works
    well in many tasks, such as classification, object detection, semantic segmentation.
    Also, in Natural Language Processing, these tasks (such as text classification,
    question answering, text abstraction) could accomplish using deep learning. For
    different requirements of diverse tasks, there are generating several state-of-the-art
    models. Commonly, these models have their specialties and focus on the specific
    work. For instance, Convolutional Neural Network (CNN [[3](#bib.bib3)]) works
    very well on classification; Region-CNN series (R-CNNs [[4](#bib.bib4), [5](#bib.bib5),
    [6](#bib.bib6)]) are excellent on object detection; Fully Convolutional Network
    (FCN [[7](#bib.bib7)]) and U-Net [[8](#bib.bib8)] do well in semantic segmentation;
    Recurrent Neural Network (RNN [[9](#bib.bib9)]) and Long Short-Term Memory (LSTM [[10](#bib.bib10)])
    are good at text classification.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the ability of data fusion in deep learning and the needs to model the
    data features of tumor in diagnosis and treatment process, there are numerous
    researches to construct Computer-Aided Diagnosis and Treatment of Tumors based
    on deep learning. Therefore, many recent efforts have been conducted to summarize
    the relevant researches in this area [[11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13),
    [14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17), [18](#bib.bib18),
    [19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22), [23](#bib.bib23),
    [24](#bib.bib24), [25](#bib.bib25)].
  prefs: []
  type: TYPE_NORMAL
- en: Mainly, Shen et al. summarized the contributions in computer-aided analysis
    of medical images, such as image registration, structural detection, tissue segmentation,
    computer-aided disease diagnosis, and prognosis [[22](#bib.bib22)]. Ching et al.
    introduced the opportunities and obstacles to deep learning regarding biology,
    which focuses on the perspective of medicine [[24](#bib.bib24)]. Sahiner et al.
    focus on Convolutional Neural Networks, investigated image segmentation, detection,
    characterization, processing and reconstruction, tasks involving imaging and treatment
    in medical imaging and radiotherapy, and discussed methods for dataset expansion [[14](#bib.bib14)].
  prefs: []
  type: TYPE_NORMAL
- en: However, there exist some drawbacks to these review works. In brief, like the
    work from shen et al. [[22](#bib.bib22)], these works based on respective medical
    tasks [[21](#bib.bib21), [23](#bib.bib23), [24](#bib.bib24)], which contents ,
    lack systematization. Similar to Ching et al. [[24](#bib.bib24)] focus on biology
    and medicine, these works based on a single type of medical imaging [[17](#bib.bib17),
    [18](#bib.bib18), [19](#bib.bib19), [20](#bib.bib20), [25](#bib.bib25)], ignoring
    that the diagnosis and treatment of tumor is essentially a process of multi-department
    coordination and multi-technology integration in clinical practice. Also, like
    the work from Sahiner et al. [[14](#bib.bib14)], these researchers whose work
    based on a few deep learning models and does not clearly explain the relationship
    and advantages of each state-of-the-art method in deep learning [[11](#bib.bib11),
    [12](#bib.bib12), [13](#bib.bib13), [15](#bib.bib15), [16](#bib.bib16)]. Furthermore,
    some review works are kinds of outdated [[22](#bib.bib22), [11](#bib.bib11)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, in this work, we aim to summarize the recent progress (basically
    concentrated in 2017-2019) in Computer-Aided Diagnosis and Treatment of Tumors
    to fill the above gaps. The contributions of this work were shown as follow:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This paper reviews the medical applications by deep learning in 2017-2019, which
    introduces neoteric state-of-the-art and latest applications.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This paper introduces the primary network of deep learning from task-oriented
    and expounds the superior model of improving network according to the characteristics
    of medical tasks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This paper follows a clear clue - the process of Computer-Aided Diagnosis and
    Treatment of Tumors, which organized a transparent knowledge system to summarize
    recent work.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This paper will service clinical and computer researchers, which improvement
    can optimize the knowledge structure for both of them and promote interdisciplinary
    mutual understanding and learning for each other.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given the existing gaps in Computer-Aided Diagnosis and Treatment of Tumors,
    this paper looks forward to the challenges in data types, organs, medical tasks,
    deep learning methods. Also, this paper points out the blank in adversarial study
    like the work of Finlayson et al. [[26](#bib.bib26)], which needs to be paid attention
    by researchers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2 Classic Deep Learning Models and Improvements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section reviews classic deep learning models which widely used in Computer-Aided
    Diagnosis and Treatment of Tumors. Thus to mainly introduce Convolutional Neural
    Network (CNN [[3](#bib.bib3)]), Fully Convolutional Network (FCN [[7](#bib.bib7)]),
    Region-CNN (R-CNN [[4](#bib.bib4)]) and their improved models.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth mentioning that there are still exist state-of-the-art in-depth
    learning model series work well on computer science, such as Mask Region-CNN (Mask
    R-CNN [[27](#bib.bib27)]) in instance segmentation and Transformer [[28](#bib.bib28)]
    series in Natural Language Processing (NLP). However, in Computer-Aided Diagnosis
    and Treatment of Tumors, the target organ, lesion, or tissue of tumors are generally
    stable in structure. It means that the instance segmentation hard to play to its
    strengths at the current research stage, which is especially good at multi-class
    and multi-object detection and segmentation. Also, clinical data (such as clinical
    case, prescription, and treatment plan) has never received the attention it deserves,
    which could be intellectualized by NLP. Therefore, this paper chooses to introduce
    CNN, FCN, and RCNN series in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Convolutional Neural Network and DeepMedic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 2.1.1 CNN
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Convolutional Neural Network (CNN [[3](#bib.bib3)]) was widely used in medical
    tasks as the foundational deep learning method. The structure of CNN with details
    shows in Figure [1](#S2.F1 "Figure 1 ‣ 2.1.1 CNN ‣ 2.1 Convolutional Neural Network
    and DeepMedic ‣ 2 Classic Deep Learning Models and Improvements ‣ Deep Learning
    in Computer-Aided Diagnosis and Treatment of Tumors: A Survey"). There are three
    integral parts named the convolutional layer, the pooling layer, and the Fully
    Connected layer (FC). Followed by the pooling layer, there will be an activate
    function that could enhance the ability to fit nonlinear problems.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/70917a163394cd40bdcf9471c19a29d5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The structure of CNN.'
  prefs: []
  type: TYPE_NORMAL
- en: Stem from CNN’s unique structure - the convolutional layer realizes the local
    region connection and weight sharing, the pooling layer achieves dimension reduction,
    and the fully connected layer implements the task of the classifier. There are
    four ways to improve the CNN except for exchange activation function.
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Specific to the fully connected layer, researchers exchange this layer into
    other networks such as Conditional Random Fields (CRF [[29](#bib.bib29)]). This
    improvement makes CNN no longer limited to classification tasks but keeps the
    ability of the feature extraction.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increasing the depth of CNN by stacking multiple convolution and pooling layers.
    However, this method hard to achieve a super deep network due to the problems
    of gradient vanishing and gradient exploding. Therefore, Visual Geometry Group
    Network (VGGnet [[30](#bib.bib30)]) adopted 16-layer and 19-layer structures.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To solve the degradation problem with skip connection, such as Deep Residual
    Network (ResNet [[31](#bib.bib31)]), solves the problem of the higher error rate
    generated in a deeper network.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increasing the diversity of features by adding convolution kernel of different
    sizes and introducing the dimension reduction of 1*1 convolution kernel, such
    as GoogLeNet [[32](#bib.bib32)].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, Table [1](#S2.T1 "Table 1 ‣ 2.1.1 CNN ‣ 2.1 Convolutional Neural Network
    and DeepMedic ‣ 2 Classic Deep Learning Models and Improvements ‣ Deep Learning
    in Computer-Aided Diagnosis and Treatment of Tumors: A Survey") shown the recent
    works in Computer-Aided Diagnosis and Treatment of Tumors using CNN.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: CNN in Computer-Aided Diagnosis and Treatment of Tumors'
  prefs: []
  type: TYPE_NORMAL
- en: '| Tasks | Reference |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Detection | [[33](#bib.bib33)] |'
  prefs: []
  type: TYPE_TB
- en: '| Location | [[34](#bib.bib34)] |'
  prefs: []
  type: TYPE_TB
- en: '| Classification | [[35](#bib.bib35)], [[36](#bib.bib36)], [[37](#bib.bib37)],
    [[38](#bib.bib38)], [[39](#bib.bib39)], [[40](#bib.bib40)] |'
  prefs: []
  type: TYPE_TB
- en: '| Segmentation |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [[41](#bib.bib41)], [[42](#bib.bib42)], [[34](#bib.bib34)], [[43](#bib.bib43)],
    [[44](#bib.bib44)], [[45](#bib.bib45)], &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [[46](#bib.bib46)], [[47](#bib.bib47)], [[33](#bib.bib33)] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Prediction |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [[42](#bib.bib42)], [[48](#bib.bib48)], [[49](#bib.bib49)], [[50](#bib.bib50)],
    [[51](#bib.bib51)], [[52](#bib.bib52)], &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [[42](#bib.bib42)], [[53](#bib.bib53)], [[54](#bib.bib54)], [[55](#bib.bib55)]
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'The location and detection focus on pointing out the position of the object,
    except the latter one could distinguish different objects. Table [1](#S2.T1 "Table
    1 ‣ 2.1.1 CNN ‣ 2.1 Convolutional Neural Network and DeepMedic ‣ 2 Classic Deep
    Learning Models and Improvements ‣ Deep Learning in Computer-Aided Diagnosis and
    Treatment of Tumors: A Survey") shows that CNN has been used to detect or locate
    the tumor in medical tasks, which usually is the first step of a two-stage work,
    such as locating or detecting first and then segmenting for the MRI of brain [[34](#bib.bib34)].
    Similarly, Bellver et al. exchange the last layer into a single neuron to detect
    healthy/unhealthy liver tissues [[33](#bib.bib33)]. However, these researches
    using CNN are often ancillary products of tasks because the detection or location
    was not the ultimate purpose of the research. Thus detection and location using
    CNN cannot be regarded as independent medical tasks. There is another computer
    science method named Region-CNN series (R-CNNs), which will introduce after, are
    the start-of-the-art of object detection.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The classification is CNN’s turf, thanks to its excellent ability of feature
    extraction, lots of researchers prefer to address the medical data by CNN. As
    the Table [1](#S2.T1 "Table 1 ‣ 2.1.1 CNN ‣ 2.1 Convolutional Neural Network and
    DeepMedic ‣ 2 Classic Deep Learning Models and Improvements ‣ Deep Learning in
    Computer-Aided Diagnosis and Treatment of Tumors: A Survey") shows, these researchers
    focus the tumor diagnosis and treatment on breast [[35](#bib.bib35), [36](#bib.bib36),
    [38](#bib.bib38), [40](#bib.bib40)], kidney [[39](#bib.bib39)], bladder [[40](#bib.bib40)],
    and even 13 cancer types [[37](#bib.bib37)] based on histology images.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Segmentation is another application of CNN which was demanded a lot in medical
    tasks, weather the initial screening, subtype identification or treatment of tumors
    all revolve around the precise segmentation. Researchers in this area usual adopt
    the first variant (exchange the last layer in CNN) we introduce above to achieve
    the goal of lesion’s segmentation. In details, the researches in Table [1](#S2.T1
    "Table 1 ‣ 2.1.1 CNN ‣ 2.1 Convolutional Neural Network and DeepMedic ‣ 2 Classic
    Deep Learning Models and Improvements ‣ Deep Learning in Computer-Aided Diagnosis
    and Treatment of Tumors: A Survey") reflects the extensive applications of segmentation
    using CNN to deal with multi-modal data and multi-tissue organs, such as brain’s
    MRI [[41](#bib.bib41), [42](#bib.bib42), [34](#bib.bib34), [43](#bib.bib43)],
    rectum’s MRI [[45](#bib.bib45)], nasopharynx’s MRI [[46](#bib.bib46)], lung’s
    PET [[44](#bib.bib44)], liver’s CT [[33](#bib.bib33)], prostate’s [[56](#bib.bib56)]
    and breast’s [[47](#bib.bib47)] histology image.'
  prefs: []
  type: TYPE_NORMAL
- en: The prediction can be regarded as an extension of classification, since its
    essence is to classify whether or not a certain situation will occur in the future.
    In general, we usually need to make the following predictions, such as tumor growth
    prediction [[52](#bib.bib52)], tumor invasiveness prediction [[55](#bib.bib55)],
    motion estimation of radiotherapy targets [[49](#bib.bib49)], radiation dose estimation [[48](#bib.bib48)],
    radiation toxicity prediction [[50](#bib.bib50)], outcome prediction [[53](#bib.bib53)],
    recurrence prediction [[54](#bib.bib54)], and life prediction [[51](#bib.bib51)].
  prefs: []
  type: TYPE_NORMAL
- en: Above all, CNN is a method with excellent feature extraction capability and
    is specialized in classification tasks. These two advantages of CNN depend on
    its structure. Based on this, researchers began to improve the model from four
    aspects that we reviewed before to promote the performance of CNN, make it easy
    to train and adapt to specific tasks. In tumor diagnosis and treatment, CNN has
    used to initially screen tumors, determine subtypes, outline tumors, and even
    predict treatment plans and outcomes. All in all, CNN can be said to be one of
    the most widely used models of Computer-Aided Diagnosis and Treatment of Tumors.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.2 DeepMedic
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'DeepMedic is an efficient 11-layers deep, multi-scale, 3D CNN architecture,
    which is an improved model specific to brain MRI images from BRATS 2015 and ISLES
    2015 [[29](#bib.bib29)]. Figure [2](#S2.F2 "Figure 2 ‣ 2.1.2 DeepMedic ‣ 2.1 Convolutional
    Neural Network and DeepMedic ‣ 2 Classic Deep Learning Models and Improvements
    ‣ Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors: A Survey")
    is the structure of DeepMedic. The baseline of DeepMedic is a CNN, followed by
    Conditional Random Fields (CRF).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3a6e0c0011dfd81f0e3cbf5f503ce212.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The structure of DeepMedic.'
  prefs: []
  type: TYPE_NORMAL
- en: It proposes a solution with parallel convolutional pathways for multi-scale
    processing, which efficiently incorporate both local and contextual information
    and improves the segmentation results. At last, the author uses CRF to achieve
    space regularization.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most valuable contribution of DeepMedic is dense-training, which can balance
    the distribution of training samples from different segmentation classes, which
    is a massive problem in medical datasets because, in clinical practice, there
    are many tiny objects. Meanwhile, DeepMedic could make a dense prediction over
    multiple adjacent pixels at one time, thus saving computing costs. In recent years,
    there are several works based on DeepMedic, which shows in Table [2](#S2.T2 "Table
    2 ‣ 2.1.2 DeepMedic ‣ 2.1 Convolutional Neural Network and DeepMedic ‣ 2 Classic
    Deep Learning Models and Improvements ‣ Deep Learning in Computer-Aided Diagnosis
    and Treatment of Tumors: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: DeepMedic in Computer-Aided Diagnosis and Treatment of Tumors'
  prefs: []
  type: TYPE_NORMAL
- en: '|         Tasks |         Reference |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|         Segmentation |         [[57](#bib.bib57)], [[58](#bib.bib58)], [[59](#bib.bib59)],
    [[60](#bib.bib60)], [[43](#bib.bib43)] |'
  prefs: []
  type: TYPE_TB
- en: '|         Prediction |         [[58](#bib.bib58)] |'
  prefs: []
  type: TYPE_TB
- en: 'DeepMedic is a trial variant of CNN that it focuses on the segmentation of
    medical tasks. Also, because of the original use for brain MRI, the most common
    application scenario is still the segmentation of brain MRI, which shows in Table [2](#S2.T2
    "Table 2 ‣ 2.1.2 DeepMedic ‣ 2.1 Convolutional Neural Network and DeepMedic ‣
    2 Classic Deep Learning Models and Improvements ‣ Deep Learning in Computer-Aided
    Diagnosis and Treatment of Tumors: A Survey"). The majority of the researches
    in the table is segmentation due to the improvement in the last layer. This structure
    makes the DeepMedic better in the brain’s segmentation. Except for the work of
    Kamnitsas et al. [[58](#bib.bib58)], they predict the population survival using
    SVM after the specific lesion was segmented.'
  prefs: []
  type: TYPE_NORMAL
- en: In general, DeepMedic’s improvements to medical data are groundbreaking and
    widely used in brain tumor segmentation tasks, but its bright spot is also its
    shortcoming. That is, its applications are limited to brain segmentation. In this
    respect, u-net, which will be introduced later, breaks the stereotype that the
    improvement of the deep learning model based on medical data is just an appendage
    of deep learning and will not affect the development in the field of computer
    science.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Fully Convolutional Network and U-Net
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 2.2.1 FCN
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As an improved method, Fully Convolutional Network (FCN [[7](#bib.bib7)]) exchanged
    the fully connected layer into a deconvolution layer. The structure of the FCN
    is shown in Figure [3](#S2.F3 "Figure 3 ‣ 2.2.1 FCN ‣ 2.2 Fully Convolutional
    Network and U-Net ‣ 2 Classic Deep Learning Models and Improvements ‣ Deep Learning
    in Computer-Aided Diagnosis and Treatment of Tumors: A Survey"), which is an encoder-decoder
    model. The form of FCN provides a foundation for the future development of semantic
    segmentation. In this way, FCN allows end-to-end pixel-level classification, the
    original size of the feature map in up-sampling, and several roughnesses of the
    up-sampling. Above all, FCN can accept input images of any size and do well in
    medical image segmentation at medical tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/18b278dcd0951ace034753ca948f3f70.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: The structure of FCN.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Because of the structure, FCN opened the gate of segmentation by its inherent
    advantages. Indeed, FCN has a vital status in Computer-Aided Diagnosis and Treatment
    of Tumors. Table [3](#S2.T3 "Table 3 ‣ 2.2.1 FCN ‣ 2.2 Fully Convolutional Network
    and U-Net ‣ 2 Classic Deep Learning Models and Improvements ‣ Deep Learning in
    Computer-Aided Diagnosis and Treatment of Tumors: A Survey") shows the works using
    FCN in the clinical practice of tumors.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: FCN in Computer-Aided Diagnosis and Treatment of Tumors'
  prefs: []
  type: TYPE_NORMAL
- en: '| Tasks | Reference |'
  prefs: []
  type: TYPE_TB
- en: '| Segmentation | [[61](#bib.bib61)], [[62](#bib.bib62)], [[63](#bib.bib63)],
    [[64](#bib.bib64)], [[65](#bib.bib65)], [[66](#bib.bib66)], [[56](#bib.bib56)]
    |'
  prefs: []
  type: TYPE_TB
- en: 'FCN was born for semantic segmentation. Hence, it is no surprise that FCN has
    been a milestone in medical images’ segmentation. As Table [3](#S2.T3 "Table 3
    ‣ 2.2.1 FCN ‣ 2.2 Fully Convolutional Network and U-Net ‣ 2 Classic Deep Learning
    Models and Improvements ‣ Deep Learning in Computer-Aided Diagnosis and Treatment
    of Tumors: A Survey") shows, FCN could segment the CT of liver [[33](#bib.bib33)]
    and heart [[61](#bib.bib61)] (which focus on the dangerous organ segmentation
    when planning radiotherapy), the MRI of brain [[62](#bib.bib62), [63](#bib.bib63)],
    liver [[64](#bib.bib64)], colorectum [[65](#bib.bib65)] and prostate [[66](#bib.bib66)].'
  prefs: []
  type: TYPE_NORMAL
- en: As a pioneer of the segmentation era, FCN occupies a place in the task of tumor
    image segmentation and opens a new chapter of the precise definition of tumor
    contour.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.2 U-Net
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As the extension of FCN, U-Net is arguably the advanced deep learning model
    that improved based on medical data. U-Net inherits all advantages form FCN but
    improves the number of deconvolution layer and skip connection layer [[8](#bib.bib8)].
    Also, it has a symmetrical U-shape shown in Figure [4](#S2.F4 "Figure 4 ‣ 2.2.2
    U-Net ‣ 2.2 Fully Convolutional Network and U-Net ‣ 2 Classic Deep Learning Models
    and Improvements ‣ Deep Learning in Computer-Aided Diagnosis and Treatment of
    Tumors: A Survey"). The left side of U-Net is a contractive path, which extracts
    features by convolution and max pooling. Also, the right side is an expansive
    path, which combines the feature map from the left side using concat and sampling
    the feature map.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ab28043d7ef4c6044f3b96202cb09a7e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: The structure of U-Net.'
  prefs: []
  type: TYPE_NORMAL
- en: 'U-Net focuses on the characteristics of medical images, which could be summarized
    as a simple image structure, large image size, a small amount of data, multi-mode,
    and interpretability. Thus, having the contractive path to capture semantics and
    the expansive path to locate accurately, U-Net is suitable for the segmentation
    of the large image, such as histology images (which usually 2GB an image). Moreover,
    the two paths amount to a trade-off between higher resolution and more abstract
    features. There are recent works in Table [4](#S2.T4 "Table 4 ‣ 2.2.2 U-Net ‣
    2.2 Fully Convolutional Network and U-Net ‣ 2 Classic Deep Learning Models and
    Improvements ‣ Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors:
    A Survey") using U-Net in Computer-Aided Diagnosis and Treatment of Tumors.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: U-Net in Computer-Aided Diagnosis and Treatment of Tumors'
  prefs: []
  type: TYPE_NORMAL
- en: '| Tasks | Reference |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Segmentation | [[67](#bib.bib67)], [[68](#bib.bib68)], [[69](#bib.bib69)],
    [[70](#bib.bib70)], [[71](#bib.bib71)], [[56](#bib.bib56)] |'
  prefs: []
  type: TYPE_TB
- en: '| Prediction | [[72](#bib.bib72)], [[73](#bib.bib73)], [[74](#bib.bib74)],
    [[75](#bib.bib75)], [[67](#bib.bib67)] |'
  prefs: []
  type: TYPE_TB
- en: '| Detection | [[67](#bib.bib67)] |'
  prefs: []
  type: TYPE_TB
- en: The most important uses of U-Net are semantic segmentation, either. However,
    its excellent performance also could support subsequent tasks. In segmentation,
    Beers et al. [[68](#bib.bib68)] and Isensee et al. [[69](#bib.bib69)] focuses
    on brain’s MRI, Bulten et al. [[56](#bib.bib56)] works on prostate’s histology
    image, Falk et al. [[67](#bib.bib67)] researches the microscopic video, Guo et
    al. [[70](#bib.bib70)] focus on pancreas’s CT , and Zhong et al. [[71](#bib.bib71)]
    uses CT and PET of lung. Furthermore, Falk et al. [[67](#bib.bib67)] also finished
    the detection of biomarkers, and Isensee et al. [[69](#bib.bib69)] realized survival
    prediction in radiobiology.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, there are other researchers such as Nguyen et al. uses U-Net for prediction.
    In brief, these works respectively studied prostate [[72](#bib.bib72), [74](#bib.bib74)]
    and head and neck (H&N) [[73](#bib.bib73), [75](#bib.bib75)] on radiotherapy dose
    prediction based on the data of treatment plan.
  prefs: []
  type: TYPE_NORMAL
- en: Have to say, U-Net is a significant breakthrough in improving the deep learning
    model based on medical data, which improvement is according to the characteristics
    of simple medical data structure, small size, and few kinds of targets. This optimization
    for task objectives also further promotes the exploration of fine segmentation
    in the field of computer science. So, four years later, u-net is still firmly
    in the top spot in both medicine and computer science. This phenomenon is very
    thought-provoking.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 R-CNN Series
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Region-CNN (R-CNN) series is a two-stage method that selects proposals on the
    image first and fixes bounding boxes based on the proposal. As a primitive model,
    R-CNN [[4](#bib.bib4)] is divided into three parts, finding the candidate box,
    using CNN to extract feature vectors, and using Support Vector Machine (SVM [[76](#bib.bib76)])
    to classify feature vectors. Figure [5](#S2.F5 "Figure 5 ‣ 2.3 R-CNN Series ‣
    2 Classic Deep Learning Models and Improvements ‣ Deep Learning in Computer-Aided
    Diagnosis and Treatment of Tumors: A Survey") shows the specific method, which
    locates 2000 candidate boxes of objects in the input picture and extracts feature
    vectors of images in each candidate box, next, classifies and identifies objects
    in each candidate box.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/62dc848200d93bff5ff8092d349b935c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The structure of R-CNN.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The improvement of R-CNN is focussing on the training speed. The Fast R-CNN [[5](#bib.bib5)]
    improves the multi-stage pipeline training of R-CNN and solves the urgent problem
    for time and space of training. There are two improvements in this work, adding
    an ROI pooling layer after the last convolution layer, and using a multi-task
    loss function to add frame regression directly to the training of the CNN network.
    Moreover, Faster RCNN [[6](#bib.bib6)] can view as Fast R-CNN work with the Region
    Proposal Network (RPN [[6](#bib.bib6)]). The corresponding work summarizes in
    Table [5](#S2.T5 "Table 5 ‣ 2.3 R-CNN Series ‣ 2 Classic Deep Learning Models
    and Improvements ‣ Deep Learning in Computer-Aided Diagnosis and Treatment of
    Tumors: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: R-CNNs in Computer-Aided Diagnosis and Treatment of Tumors'
  prefs: []
  type: TYPE_NORMAL
- en: '| Tasks | Reference |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Detection | [[77](#bib.bib77)], [[78](#bib.bib78)], [[79](#bib.bib79)], [[80](#bib.bib80)],
    [[81](#bib.bib81)] |'
  prefs: []
  type: TYPE_TB
- en: '| Classification | [[80](#bib.bib80)], [[81](#bib.bib81)] |'
  prefs: []
  type: TYPE_TB
- en: Detection is the most basic function of the R-CNN series, and it is easy to
    see that the work based on R-CNN has completed the detection work very well. For
    instance, Li et al. [[77](#bib.bib77)] uses Faster R-CNN to detect thyroid ultrasound
    images. Rao et al. [[78](#bib.bib78)] works on R-CNN and Cai et al. [[79](#bib.bib79)]
    research Faster R-CNN to detect breast histology images. Also, Faster R-CNN in
    the researches of Akselrod et al. [[80](#bib.bib80)] and Ribli et al. [[81](#bib.bib81)]
    are both using for breast mammography to detect and classify malignant or benign
    lesions.
  prefs: []
  type: TYPE_NORMAL
- en: As the pioneer of target detection, R-CNNs, the two-stage method, has completed
    the detection of biomarkers well in the process of tumor diagnosis and treatment.
    It is worth mention that in the field of computer science, there are actually
    other object detection methods that are being updated, such as You Only Look Once
    series (YOLO [[82](#bib.bib82)], YOLOv2 [[83](#bib.bib83)], YOLOv3 [[84](#bib.bib84)]),
    and Segmentation is all you need [[85](#bib.bib85)] which written by Wu et al.
    in 2019\. The reason why the above works are not described in detail here is that
    the YOLO series, as one-stage methods, has lost parts of precision (which is a
    crucial indicator in tumor diagnosis and treatment). Meanwhile, the work named
    Segmentation is all you need, which is the latest and most breakthrough deep learning
    method for object detection that has not been the star in the medical field. However,
    one of the advantages of the work finished by Cheng et al. is the detection of
    difficult small targets, and its performance in subsequent medical tasks is expected.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Recent Work in Intelligent Diagnosis and Treatment of Tumors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 3.1 In-Vitro Diagnosis (IVD)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In-Vitro Diagnosis (IVD) is the first stage of tumor diagnosis, which is mainly
    responsible for the detection and screening of tumor markers or tumor characteristics.
    Early detection of cancer often determines the prognosis of patients’ quality
    of life or even life. It is the crucial reason why deep learning is needed at
    this stage. IVD uses three kinds of data, which will introduce as follow.
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Images or videos of cells in blood and tissue fluid generated from microscope
    to discover if there exists Circulating Tumor Cell (CTC).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Indicators in biophysics and biochemistry from Flow Cytometer (FCM) to discover
    the specified subset of cells.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Gene expression by arrays obtained from the public datasets to discover if there
    exists a gene disorder.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Currently, there are public datasets online with labels in this stage. Such
    as, National Cancer Institute Genomic Data Commons (GDC) Data Portal (see: [https://portal.gdc.cancer.gov/](https://portal.gdc.cancer.gov/)),
    Genomics of Drug Sensitivity in Cancer (GDSC, see: [https://www.cancerrxgene.org/](https://www.cancerrxgene.org/)),
    MICCAI Challenge on Circuit Reconstruction from Electron Microscopy Images (CREMI,
    see: [https://cremi.org/data/](https://cremi.org/data/)), and LYmphocyte aSsessmenT
    hackathOn (LYSTO, see: [https://lysto.grand-challenge.org/](https://lysto.grand-challenge.org/)).
    The vast majority of open datasets can be found at Grand Challenge (see: [https://grand-challenge.org/challenges/](https://grand-challenge.org/challenges/)),
    or even the data types to be introduced in the next three stages in Computer-Aided
    Diagnosis and Treatment of Tumors.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main clinical problems at this stage are the early screening of tumors,
    identifying tumor stages and subtypes, monitoring the efficacy of therapy, and
    predicting prognosis of tumors. All of these medical tasks can be seen as a classification
    task in computer science. Of course, segmentation and object detection can also
    accomplish the above tasks if it is necessary. Now, with the development of CNN,
    there is a practical approach to solve the above problems in deep learning. Table [6](#S3.T6
    "Table 6 ‣ 3.1 In-Vitro Diagnosis (IVD) ‣ 3 Recent Work in Intelligent Diagnosis
    and Treatment of Tumors ‣ Deep Learning in Computer-Aided Diagnosis and Treatment
    of Tumors: A Survey") summarizes recent work for CNN in IVD.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6: Recent work in In-Vitro Diagnosis'
  prefs: []
  type: TYPE_NORMAL
- en: '| Data | Tasks | Reference |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Image | Detection | [[67](#bib.bib67)] |'
  prefs: []
  type: TYPE_TB
- en: '| Segmentation | [[67](#bib.bib67)], [[86](#bib.bib86)], [[66](#bib.bib66)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Indicators | Classification | [[87](#bib.bib87)] |'
  prefs: []
  type: TYPE_TB
- en: '| Gene | Prediction | [[88](#bib.bib88)], [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: 3.1.1 Image data diagnosis in IVD
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In detection, the work of Falk et al. [[67](#bib.bib67)] is excellent by using
    U-Net, which enables non-machine-learning experts to analyze their data and could
    save manual annotation effort in a wide variety of quantification tasks. Also,
    this work supports single-cell segmentation with conditional adaptability. Furthermore,
    the datasets in this work (such as F1-MSC, F2-GOWT1, F3-SIM, F4-HeLa, DIC1-HeLa,
    PC1-U373, and PC2-PSC) are from the International Symposium on Biomedical Imaging
    (ISBI) Cell Tracking Challenge 2015\. Figure [6](#S3.F6 "Figure 6 ‣ 3.1.1 Image
    data diagnosis in IVD ‣ 3.1 In-Vitro Diagnosis (IVD) ‣ 3 Recent Work in Intelligent
    Diagnosis and Treatment of Tumors ‣ Deep Learning in Computer-Aided Diagnosis
    and Treatment of Tumors: A Survey") shows the pipeline of this work. Firstly,
    training the U-net on the local machine, a dedicated remote server, or a cloud
    service. After that, the adaptation of U-Net to newly annotated data by using
    transfer learning. This work performance well in follows tests.'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detection (2D) of colocalization in two-channel epifluorescence images.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detection (3D) of fluorescent-protein-tagged microglial cells in a five-channel
    confocal-image.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Segmentation (2D) of morphometric cell description from fluorescence, differential
    interference contrast, phase-contrast, and bright-field microscopy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Segmentation (3D) of 3D bright-field images and neurite is tracing in electron
    microscopy images.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ce032042cc7ff4b8948c17dd7528db0e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: The pipeline of the research worked by falk et al. [[67](#bib.bib67)]
    which is basically different annotation types of data learning using U-Net.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In segmentation, Tran et al. [[86](#bib.bib86)] uses SegNet (which is a variant
    of FCN [[90](#bib.bib90)]) to efficiently segment both Red Blood Cells (WBCs)
    and White Blood Cells (RBCs). The dataset is the peripheral blood smear images
    from the ALL-IDB1 database. The details of this work are shown in Figure [7](#S3.F7
    "Figure 7 ‣ 3.1.1 Image data diagnosis in IVD ‣ 3.1 In-Vitro Diagnosis (IVD) ‣
    3 Recent Work in Intelligent Diagnosis and Treatment of Tumors ‣ Deep Learning
    in Computer-Aided Diagnosis and Treatment of Tumors: A Survey"). The first step
    utilizes SegNet to label all of WBCs and RBCs in input images with different colors.
    Then, it separated all leucocytes and erythrocytes into two individual images.
    Finally, using the result images for various purposes, such as early detection
    of leukemia (a type of white blood cell cancer) and count of the complete blood
    cell.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3a1326513037c06794759429ab372424.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: The pipeline of [[86](#bib.bib86)] depends on SegNet to segment WBCs
    and RBCs.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 Gene data diagnosis in IVD
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now, genomic data is generally used for prediction, such as cancer prediction
    and anticancer drug responsiveness prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a standard work written by Chang et al. [[88](#bib.bib88)] in the
    Table [6](#S3.T6 "Table 6 ‣ 3.1 In-Vitro Diagnosis (IVD) ‣ 3 Recent Work in Intelligent
    Diagnosis and Treatment of Tumors ‣ Deep Learning in Computer-Aided Diagnosis
    and Treatment of Tumors: A Survey") researches for drug efficacy prediction, which
    employs CNN to process the genomic mutational fingerprints of cell lines and the
    molecular fingerprints of drugs (these data comes from CCLP1, GDSC6, CGC, GDSC).
    It may allow the selection of the most effective anticancer drugs for the genomic
    profile of the individual patient in the future. The details will show in Figure [8](#S3.F8
    "Figure 8 ‣ 3.1.2 Gene data diagnosis in IVD ‣ 3.1 In-Vitro Diagnosis (IVD) ‣
    3 Recent Work in Intelligent Diagnosis and Treatment of Tumors ‣ Deep Learning
    in Computer-Aided Diagnosis and Treatment of Tumors: A Survey"). In this research,
    the model consists of two parts, a dual convergence CNN and a generalizable prediction
    model. Furthermore, the inputs of the model can be molecular information of a
    particular small molecule, and the model could predict which of Genomics in Drug
    Sensitivity in Cancer (GDSC) anticancer drugs would be valid.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1ab340e552cc8a180b9b0a47e6d097e1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: The pipeline of the work written by Chang et al. [[88](#bib.bib88)]
    depends on two-step CNN to predict anticancer drugs responsiveness.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.3 Indicators data diagnosis in IVD
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'With the increasing maturity of deep learning methods, more and more types
    of data are expected to be processed by deep learning methods, and Doan et al. [[87](#bib.bib87)]
    shown in Table [6](#S3.T6 "Table 6 ‣ 3.1 In-Vitro Diagnosis (IVD) ‣ 3 Recent Work
    in Intelligent Diagnosis and Treatment of Tumors ‣ Deep Learning in Computer-Aided
    Diagnosis and Treatment of Tumors: A Survey") is one of them. Doan et al. analysis
    the diagnostic potential of Imaging Flow Cytometry (FCM), which database contains
    the image of each cell and the quantified multiple properties constituents of
    interest indicators (including proteins, nucleic acids, glycolipids) in multiple
    subcellular compartments (nucleus, mitochondria). Figure [9](#S3.F9 "Figure 9
    ‣ 3.1.3 Indicators data diagnosis in IVD ‣ 3.1 In-Vitro Diagnosis (IVD) ‣ 3 Recent
    Work in Intelligent Diagnosis and Treatment of Tumors ‣ Deep Learning in Computer-Aided
    Diagnosis and Treatment of Tumors: A Survey") is the illustration of the assumption
    by using general CNN in the research. This work may use to analyze the rare cell
    types such as circulating tumor cells (which are cancer cells that escaped from
    a primary tumor and circulate in the bloodstream) and transition states, such
    as cell cycle phases (mitosis).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dd4a6c3209548c7e3ca4d85759544632.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: The illustration of the work written by Doan et al. [[87](#bib.bib87)]
    depends on CNN to analysis the cells by classification. For instance, Class1 and
    2 could correspond to leukemic and normal cells.'
  prefs: []
  type: TYPE_NORMAL
- en: As a summary, even the In-Vitro Diagnosis is the earliest stage for the diagnosis
    of tumors, the data types and the large data sources are pool. There are several
    reasons which based on the clinical practice for In-Vitro Diagnosis mainly causes
    it.
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many cytology reports do not require the same photographic evidence as imaging
    diagnosis, so doctors have no needs to gather image data during the diagnosis;
    instead, they record the values detected.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Currently, general health examination conducted by hospitals do not include
    the genomic testing of tumors, and so do the medical institutions. Also, most
    patients lack awareness of genetic risk prediction. Therefore, to obtain a large
    number of high-quality tumor genome screening data is difficult.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clinical indicator data are presented in the form of text, and Natural Language
    Processing (NLP) is required to complete the task of text abstract before further
    analysis. However, text abstract is rarely used in medical reports, which results
    in a lack of available data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3.2 Imaging Diagnosis (ID)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If abnormal discoveries are finding in IVD or simply because of the physical
    discomfort reaching the diagnostic range, patients may have to follow a doctor’s
    orders to finish imaging diagnosis. The Imaging Diagnosis uses medical images
    to discover if there exist leisures and dangerous organs. These images come from
    UB, X-ray, CT, MRI, Digital Subtraction Angiography (DSA), RadioNuclide Imaging
    (RNI), Positron Emission Computed Tomography (PET), and Single-Photon Emission
    Computed Tomography (SPECT). There are plenty of public datasets about medical
    images. As usual, these datasets could be found in Grand Challenge, such as Kidney
    Tumor Segmentation Challenge (KiTS), Combined Healthy Abdominal Organ Segmentation
    (CHAOS), Decathlon-10\. Furthermore, The Cancer Imaging Archive (TCIA, see: [https://www.cancerimagingarchive.net/](https://www.cancerimagingarchive.net/))
    contains packaged datasets, such as multi-modal or multi-type data of tumors.
    Of course, some datasets have histology images, multiple types of medical images,
    genomic data, and clinical information, which are suitable for the integration
    of multi-modal data and tumor diagnosis and treatment.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this stage, the essential clinical demands include diagnosing, detecting,
    and delineating the tumors or dangerous organs. Thanks to the applications supported
    by CNN, FCN, U-net, and R-CNNs, most of the problems in Imaging Diagnosis could
    be solved in deep learning. Among these models, CNN could be used to diagnose
    tumors and extract features before delineating the tumors; FCN and U-Net mostly
    be used to delineate the tumors; R-CNNs are good at object detection for tumors.
    Recent works are shown in Table [7](#S3.T7 "Table 7 ‣ 3.2 Imaging Diagnosis (ID)
    ‣ 3 Recent Work in Intelligent Diagnosis and Treatment of Tumors ‣ Deep Learning
    in Computer-Aided Diagnosis and Treatment of Tumors: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7: Recent work in Imaging Diagnosis'
  prefs: []
  type: TYPE_NORMAL
- en: '| Data | Tasks | Reference |'
  prefs: []
  type: TYPE_TB
- en: '| MRI | Segmentation |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [[41](#bib.bib41)], [[57](#bib.bib57)], [[59](#bib.bib59)], [[34](#bib.bib34)],
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [[43](#bib.bib43)], [[45](#bib.bib45)], [[46](#bib.bib46)], [[58](#bib.bib58)],
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [[62](#bib.bib62)], [[63](#bib.bib63)], [[64](#bib.bib64)], [[65](#bib.bib65)],
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [[66](#bib.bib66)], [[69](#bib.bib69)], [[68](#bib.bib68)], [[42](#bib.bib42)]
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Prediction | [[42](#bib.bib42)], [[58](#bib.bib58)], [[69](#bib.bib69)] |'
  prefs: []
  type: TYPE_TB
- en: '| CT | Segmentation |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [[33](#bib.bib33)], [[61](#bib.bib61)], [[64](#bib.bib64)], [[66](#bib.bib66)],
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [[70](#bib.bib70)], [[91](#bib.bib91)] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Prediction |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [[48](#bib.bib48)], [[49](#bib.bib49)], [[51](#bib.bib51)], [[54](#bib.bib54)],
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [[55](#bib.bib55)]  [[91](#bib.bib91)] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| PET | Segmentation | [[44](#bib.bib44)], [[71](#bib.bib71)] |'
  prefs: []
  type: TYPE_TB
- en: '| Prediction | [[52](#bib.bib52)] |'
  prefs: []
  type: TYPE_TB
- en: '| Mammography | Detection | [[92](#bib.bib92)], [[81](#bib.bib81)] |'
  prefs: []
  type: TYPE_TB
- en: '| Classification |'
  prefs: []
  type: TYPE_TB
- en: '| US | Detection | [[77](#bib.bib77)] |'
  prefs: []
  type: TYPE_TB
- en: 3.2.1 MRI diagnosis in ID
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: MRI has good discrimination of soft tissue and no ionizing radiation damage
    to the human body, so it is good at imaging tumors in the brain, bladder, rectum,
    reproductive system, and other parts.
  prefs: []
  type: TYPE_NORMAL
- en: 'In segmentation, we have to introduce the work written by Drozdzal et al. [[66](#bib.bib66)],
    which combines Fully Convolutional Networks (FCNs) with Fully Convolutional Residual
    Networks (FC-ResNets [[93](#bib.bib93)]) to segment medical images, such as electron
    microscopy (EM) image, CT of the liver, and MRI of the prostate. The results reveal
    that this model is working well in both 2D and 3D medical images, which means
    that it could achieve accurate segmentations on a variety of image modalities
    and different anatomical regions. Details are shown in Figure [10](#S3.F10 "Figure
    10 ‣ 3.2.1 MRI diagnosis in ID ‣ 3.2 Imaging Diagnosis (ID) ‣ 3 Recent Work in
    Intelligent Diagnosis and Treatment of Tumors ‣ Deep Learning in Computer-Aided
    Diagnosis and Treatment of Tumors: A Survey"), which uses the FCN to obtain pre-normalized
    images, and then iteratively refined employing the FC-ResNet to generate a segmentation
    prediction.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b2dc4f4abd128559cbc883ead6fe3421.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: The illustration of the work written by Drozdzal et al. [[66](#bib.bib66)]
    depends on FCN and FC-ResNet to segment both 2D and 3D medical images, such as
    EM, CT, and MRI.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In prediction, Isensee et al. [[69](#bib.bib69)] finished the survival prediction
    by training an ensemble of Random Forest (RF [[94](#bib.bib94)]) regressor and
    multi-layer perceptrons on shape features describing the tumor subregions. Figure [11](#S3.F11
    "Figure 11 ‣ 3.2.1 MRI diagnosis in ID ‣ 3.2 Imaging Diagnosis (ID) ‣ 3 Recent
    Work in Intelligent Diagnosis and Treatment of Tumors ‣ Deep Learning in Computer-Aided
    Diagnosis and Treatment of Tumors: A Survey") is the pipeline of the work, which
    is derived from the U-Net. In short, the context pathway (left) aggregates high-level
    information that is subsequently localized precisely in the localization pathway
    (right). Also, this work injects gradient signals deep into the network through
    depth supervision.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c6f9238956c9e8e3d1c5c3eba417a494.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: The illustration of the work written by Isensee et al. [[69](#bib.bib69)]
    depends on U-Net to segment brain MRI and RF to predict radiomics survival.'
  prefs: []
  type: TYPE_NORMAL
- en: Different from the work mentioned above [[69](#bib.bib69)], these works [[42](#bib.bib42),
    [58](#bib.bib58)] also have a prediction part using Support Vector Machine (SVM [[76](#bib.bib76)]).
    Noticed that both Random Forest (RF) and Support Vector Machine (SVM) are the
    machine learning method, maybe there will be a more deep learning method using
    for prediction soon in this field.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2 CT diagnosis in ID
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: CT is of high diagnostic value for tumors of the central nervous system, head
    and neck, chest and abdomen, and pelvic cavity. It is widely used in the diagnosis
    and treatment of computer-assisted tumors.
  prefs: []
  type: TYPE_NORMAL
- en: 'In segmentation, Guo et al. [[70](#bib.bib70)] employs U-Net which refined
    by Gaussian Mixture Model (GMM) and morphological operations to segment 3D pancreas
    tumor. To finish the morphological operations, the authors adopt a model named
    LOGISMOS, which is a graph-based framework that translates geometric constraints
    of interacting surfaces and objects into graph arcs and the likelihood of segmentation
    surface positioning into graph node/arc costs. The details are shown in Figure [12](#S3.F12
    "Figure 12 ‣ 3.2.2 CT diagnosis in ID ‣ 3.2 Imaging Diagnosis (ID) ‣ 3 Recent
    Work in Intelligent Diagnosis and Treatment of Tumors ‣ Deep Learning in Computer-Aided
    Diagnosis and Treatment of Tumors: A Survey"), which combines U-Net (to integrate
    intra-slice and adjacent-slice contexts) and LOGISMOS (to regulate the 3D shape)
    for 3D tumor segmentation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dfef659ca018422faa5d11420131dba8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: The pipeline of the work written by Guo et al. [[70](#bib.bib70)]
    which adopts the U-Net to integrate intra-slice and adjacent-slice contexts, and
    regulates the 3D shape by LOGISMOS in pancreas tumor segmentation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In prediction, Ardila et al. [[91](#bib.bib91)] built an end-to-end approach
    based on CNN for CT images, which outputs overall malignancy prediction for the
    case, a risk bucket score (LUMAS) and localization for predicted cancerous nodules.
    The pipeline shows in Figure [13](#S3.F13 "Figure 13 ‣ 3.2.2 CT diagnosis in ID
    ‣ 3.2 Imaging Diagnosis (ID) ‣ 3 Recent Work in Intelligent Diagnosis and Treatment
    of Tumors ‣ Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors:
    A Survey"), which contains three parts based on CNN. There is a full-volume model
    (to perform end-to-end analysis of LDCT), cancer Region of Interest (ROI) detection
    model (to detect 3D cancer candidate regions), and cancer risk prediction model
    (to operate on outputs from above two models). This work achieved an outstanding
    result, about 94.4% area under the curve on National Lung Cancer Screening Trial
    cases (NLST).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8b8eefc3a5e5e0804fdbc1c9784025b3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: The pipeline of the work of Ardila et al. [[91](#bib.bib91)] which
    is basically based on CNN.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.3 PET diagnosis in ID
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Positron Emission Tomography and Computed Tomography (PET-CT) dual-modality
    imaging provide critical diagnostic information in current cancer diagnosis and
    therapy.
  prefs: []
  type: TYPE_NORMAL
- en: 'In segmentation, Zhong et al. [[71](#bib.bib71)] employ a model that combines
    3D U-Net, and the graph cut based co-segmentation model to automated, accurate
    tumor delineation based on PET-CT, which is essential in computer-assisted tumor
    reading and interpretation. The details are shown in Figure [14](#S3.F14 "Figure
    14 ‣ 3.2.3 PET diagnosis in ID ‣ 3.2 Imaging Diagnosis (ID) ‣ 3 Recent Work in
    Intelligent Diagnosis and Treatment of Tumors ‣ Deep Learning in Computer-Aided
    Diagnosis and Treatment of Tumors: A Survey"). In this work, the researchers focus
    on lung cancer PET-CT and generate high-quality voxel-level tumor confidences
    that were further used to locate the tumor boundary with the powerful co-segmentation
    model.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/14cf249b82d0d712df034cdcf82a6df4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: The pipeline of the work from Zhong et al. [[71](#bib.bib71)] which
    designed two independent 3D U-Net for PET and CT to produce high-quality regions
    costs for subsequent graph-based co-segmentation in lung’s dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In prediction, Zhang et al. [[52](#bib.bib52)] propose a CNN to predict the
    pancreas tumor growth pattern that incorporates both the population trend and
    personalized data. Figure [15](#S3.F15 "Figure 15 ‣ 3.2.3 PET diagnosis in ID
    ‣ 3.2 Imaging Diagnosis (ID) ‣ 3 Recent Work in Intelligent Diagnosis and Treatment
    of Tumors ‣ Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors:
    A Survey") shows the structure. The deep features extracted by CNN are combined
    with the time intervals and the clinical factors to feed a process of feature
    selection and after that, selected a robust feature subset by the Support Vector
    Machine Recursive Feature Elimination (SVM RFE). Finally, a SVM predictive model
    was used to predict the tumor’s spatiotemporal growth and progression.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8cf9935374c69626ce6528dbde2d8edc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: The structure of the work from Zhang et al. [[52](#bib.bib52)] which
    is a framework of the voxel-wise prediction of tumor growth via CNN and SVM.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.4 Mammography diagnosis in ID
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Now, mammography only uses for breast screening. Thus most of the researchers
    focus on the detection and classification of early cancer. As Figure [16](#S3.F16
    "Figure 16 ‣ 3.2.4 Mammography diagnosis in ID ‣ 3.2 Imaging Diagnosis (ID) ‣
    3 Recent Work in Intelligent Diagnosis and Treatment of Tumors ‣ Deep Learning
    in Computer-Aided Diagnosis and Treatment of Tumors: A Survey") shown, Ribli et
    al. [[81](#bib.bib81)] adopt Faster R-CNN by optimized both the object detection
    and classifier part to detect and classify malignant or benign lesions on mammogram
    without any human intervention. Also, the mammogram images come from the public
    INbreast database. This research could realize computer-aided detection in mammographic
    screening.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a913c6fdf0c6a53884a381f7ed99c2c9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: The structure of the work from Ribli et al. [[81](#bib.bib81)] which
    is a framework of the object detection in tumor early screening via Faster R-CNN
    and SVM.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.5 Ultrasound (US) diagnosis in ID
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Ultrasound (US) is the most widely used tumor screening method, thanks to its
    non-radioactive, multi-directional cross-sectional imaging, real-time dynamic,
    easy to operate, fast, and other characteristics. However, ultrasound needs the
    assistance of deep learning because of its disadvantages of lack of specificity,
    focus on local areas, and is easily influenced by doctors’ experience.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, Li et al. [[77](#bib.bib77)] employs Faster R-CNN to add a spatial
    constrained layer before the output layer of CNN, as the pipeline is shown in
    Figure [17](#S3.F17 "Figure 17 ‣ 3.2.5 Ultrasound (US) diagnosis in ID ‣ 3.2 Imaging
    Diagnosis (ID) ‣ 3 Recent Work in Intelligent Diagnosis and Treatment of Tumors
    ‣ Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors: A Survey"),
    which concatenated and normalized the conv3 and conv5 layer and then add a spatial
    constrained layer before the output layer. This work is more suitable for thyroid
    papillary carcinoma detection in ultrasound images, and the property of classification
    is better than SVM. This work could improve the ability of screening cancer in
    thyroid papillary carcinoma images fast.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9ed61f6102319f62f3aad8e44b318526.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17: The structure of the work from Li et al. [[77](#bib.bib77)] which
    adopt Faster R-CNN to detect thyroid papillary carcinoma.'
  prefs: []
  type: TYPE_NORMAL
- en: As a summary, Image Diagnosis runs through the whole process of tumor diagnosis
    and treatment. Its data is easy to obtain and the data is huge. It is an essential
    part of the current research on computer-assisted tumor diagnosis and treatment
    thanks to the rapid development of computer vision. As can be seen from this section,
    the research on individual organs (especially large organs or organs that are
    easy to inspect) has reached a saturation point, and the future trend is nothing
    more than improvement in accuracy and speed. However, targeted studies are still
    needed for small organ tumors, such as pancreas and ovary. These small organ tumors
    are high malignancy and a short course of the disease (which means the data is
    scarcity). Besides, there is still little research on multi-modal data (although
    such multi-modal databases like TCIA has existed).
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Pathological Diagnosis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Pathological Diagnosis is the gold standard in the tumor’s diagnosis and treatment,
    which determines the stage and subtype of tumors. Moreover, treatment planning
    depends on the results of the Pathological Diagnosis. However, because of its
    invasive nature, Pathological Diagnosis can not be used for early screening.
  prefs: []
  type: TYPE_NORMAL
- en: Pathological Diagnosis based on deep learning uses the images of leisures, which
    prepared by histopathological methods (such as H&E-stained) to discover the exceptions
    on the tissue structure, cell morphology, and growth pattern of the lesion. Now,
    the amount of public datasets is available. As usual, Grand Challenge and TCIA
    are available.
  prefs: []
  type: TYPE_NORMAL
- en: 'This stage has to screen the cell nucleus of tumors, delineate the pathological
    leisure, and detect the object of tumors. Same as Imaging Diagnosis, which input
    data is the image, and deep learning methods (such as CNN, FCN, U-Net, and R-CNNs)
    work well on Pathological Diagnosis. Follow Table [8](#S3.T8 "Table 8 ‣ 3.3 Pathological
    Diagnosis ‣ 3 Recent Work in Intelligent Diagnosis and Treatment of Tumors ‣ Deep
    Learning in Computer-Aided Diagnosis and Treatment of Tumors: A Survey") is the
    collection of recent works.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 8: Recent work in Pathological Diagnosis'
  prefs: []
  type: TYPE_NORMAL
- en: '| Data | Tasks | Reference |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Histology images | Classification |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [[35](#bib.bib35)], [[36](#bib.bib36)], [[37](#bib.bib37)], [[38](#bib.bib38)],
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [[39](#bib.bib39)],[[95](#bib.bib95)], [[40](#bib.bib40)], [[55](#bib.bib55)]
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Segmentation | [[56](#bib.bib56)], [[47](#bib.bib47)], [[96](#bib.bib96)],
    [[55](#bib.bib55)] |'
  prefs: []
  type: TYPE_TB
- en: '| Prediction | [[97](#bib.bib97)], [[53](#bib.bib53)], [[55](#bib.bib55)] |'
  prefs: []
  type: TYPE_TB
- en: 'In Classification, Saltz et al. [[37](#bib.bib37)] is standard research that
    using CNN to classify 13 cancer types in lymphocytes on pathology images compared
    with The Cancer Genome Atlas (TCGA). In this research, as Figure [18](#S3.F18
    "Figure 18 ‣ 3.3 Pathological Diagnosis ‣ 3 Recent Work in Intelligent Diagnosis
    and Treatment of Tumors ‣ Deep Learning in Computer-Aided Diagnosis and Treatment
    of Tumors: A Survey") shows, each patch was annotated with a necrosis region mask
    segmented by a pathologist, and the expert reviewed and corrected predicted Tumor-Infiltrating
    lymphocytes (TIL) during the CNN training stage. This effort assess lymphocytic
    infiltrates across multiple TCGA tumor types for correlation. Genomic and epigenomic
    assessments of lymphocytic infiltrate, as well as clinical outcome, which utilizes
    well of TCGA and shows that molecular assessments of TILs (generated by the molecular
    platforms of the TCGA) can correlate with clinical outcome for specific tumor
    types.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3c897bddf74339e6f02b1d7b2e547494.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18: The pipeline of the work from Saltz et al. [[37](#bib.bib37)] which
    could realize a global structure classification in lymphocytes by CNN.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In segmentation, Coudray et al. [[96](#bib.bib96)] show an excellent work on
    whole-slide images (obtained from The Cancer Genome Atlas, TCGA) to classify the
    Adenocarcinoma (LUAD), Squamous Cell Carcinoma (LUSC), and healthy lung tissue
    using Inception v3 (improved model of CNN [[98](#bib.bib98)]). Figure [19](#S3.F19
    "Figure 19 ‣ 3.3 Pathological Diagnosis ‣ 3 Recent Work in Intelligent Diagnosis
    and Treatment of Tumors ‣ Deep Learning in Computer-Aided Diagnosis and Treatment
    of Tumors: A Survey") is the structure of this work. Also, the author validated
    their work on independent datasets of frozen tissues, formalin-fixed paraffin-embedded
    tissues, and biopsies obtained at the New York University (NYU) Langone Medical
    Center. Furthermore, the trained network in this work could predict gene mutations
    using images as the only input in LUAD, which is meant to assist pathologists
    in the detection of cancer subtype or gene mutations. The Average area Under the
    Curve (AUC) of classification is 0.97, and AUCs of prediction is from 0.733 to
    0.856.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5a118be483eb2f854c22ed17cf22e075.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19: The pipeline of work from Coudray et al. [[96](#bib.bib96)] which
    mainly including data preprocessing and model training by CNN.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In prediction, Bychkov et al. [[53](#bib.bib53)] combines CNN and Long Short-Term
    Memory (LSTM [[10](#bib.bib10)]) to predict colorectal cancer outcome based on
    images of Haematoxylin and Eosin (H & E) stained Tumour Tissue Microarray (TMA),
    which was shown in Figure [20](#S3.F20 "Figure 20 ‣ 3.3 Pathological Diagnosis
    ‣ 3 Recent Work in Intelligent Diagnosis and Treatment of Tumors ‣ Deep Learning
    in Computer-Aided Diagnosis and Treatment of Tumors: A Survey"). Also, this work
    can directly predict five-year disease-specific survival without any intermediate
    tissue classification. This work shows that extract more prognostic information
    from the tissue morphology of colorectal cancer than an experienced human observer.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7bd84a20a6445bff2f116787dbd66323.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20: The pipeline of the work written by Bychkov et al. [[53](#bib.bib53)]
    which using CNN and LSTM to predict survival rate.'
  prefs: []
  type: TYPE_NORMAL
- en: As a summery, histology images in clinical practice are mainly used for tumor
    staging, grading, and cancer diagnosis. Therefore, classification is the priority
    in computer-assisted pathological diagnosis. In contrast, segmentation is about
    better identification of target cells, whereas prediction is about broader classification
    (predicting the likely consequences of future tumors). Therefore, it seems that
    there is no room for further development in the application of histology images.
    However, caused by the large capacity of pathological images, the current mainstream
    processing methods are training by blocks. It means that newer and better deep
    learning methods may be developed in the field to improve training speed or realize
    end-to-end.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Treatment Planning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After the diagnosis in the first three stages, doctors set out Treatment Plans
    according to the obtained diagnosis results, including operation therapy, radiotherapy,
    chemical therapy, and targeted molecular therapy. Operation therapy and radiotherapy
    belong to local treatment, which requires a clear division of Gross Tumor Volume
    (GTV), Clinical Tumor Volume (CTV), and Plan Tumor Volume (PTV) at the leisure.
    Therefore, images of tumors will be a suitable medium for operation therapy and
    radiotherapy. Chemotherapy is systemic therapy, which evaluated according to the
    improvement of clinical symptoms and objective indicators such as medical imaging.
    Molecular targeted therapy based on the level of cell molecules and therapeutic
    drug designs for oncogenic sites (such as protein molecules or gene fragments
    inside tumor cells), which can lead to specific death of tumor cells. Therefore,
    the data type in Treatment Planning is still image and gene expression by arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, in the stage of treatment planning, doctors have demands on accurate lesion
    segmentation and reliable prediction of toxicity, survival, and efficacy, the
    details shown in Table [9](#S3.T9 "Table 9 ‣ 3.4 Treatment Planning ‣ 3 Recent
    Work in Intelligent Diagnosis and Treatment of Tumors ‣ Deep Learning in Computer-Aided
    Diagnosis and Treatment of Tumors: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 9: Recent work in Treatment Planning'
  prefs: []
  type: TYPE_NORMAL
- en: '| Data | Tasks | Reference |'
  prefs: []
  type: TYPE_TB
- en: '| MRI | Prediction | [[42](#bib.bib42)], [[58](#bib.bib58)], [[69](#bib.bib69)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| CT |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [[48](#bib.bib48)], [[49](#bib.bib49)], [[51](#bib.bib51)], [[54](#bib.bib54)],
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [[55](#bib.bib55)], [[91](#bib.bib91)] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| PET-CT | [[52](#bib.bib52)] |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Histology &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; images &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| [[53](#bib.bib53)], [[97](#bib.bib97)], [[55](#bib.bib55)] |'
  prefs: []
  type: TYPE_TB
- en: '| Gene | [[88](#bib.bib88)], [[89](#bib.bib89)], [[99](#bib.bib99)] |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Treatment &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; plans &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [[72](#bib.bib72)], [[73](#bib.bib73)], [[74](#bib.bib74)], &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [[75](#bib.bib75)] [[50](#bib.bib50)] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: The prediction of the tumor through MRI, CT, PET-CT, and histology images has
    been introduced a lot before; next, the researches about genomic data, treatment
    plans, Rectum Surface Dose Maps (RSDM) will be analyzed mainly.
  prefs: []
  type: TYPE_NORMAL
- en: 'In genomic data, Chaudhary et al. [[99](#bib.bib99)] uses a synthesis method
    combined by AutoEncoder (AE [[2](#bib.bib2)]), K-means clustering [[100](#bib.bib100)],
    and Support Vector Machine (SVM [[76](#bib.bib76)]), see Figure [21](#S3.F21 "Figure
    21 ‣ 3.4 Treatment Planning ‣ 3 Recent Work in Intelligent Diagnosis and Treatment
    of Tumors ‣ Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors:
    A Survey"), to predict Hepatocellular Carcinoma (HCC) survival. The data in this
    work contains RNA sequencing (RNA-Seq), miRNA sequencing (miRNA-Seq), and methylation
    data from The Cancer Genome Atlas (TCGA). This effort predicts prognosis as good
    as an alternative model where genomics and clinical data are both considered.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/99e316fcd153da4a9881af6f51c5700f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21: The pipeline of the work from Chaudhary et al. [[99](#bib.bib99)],
    an AutoEncoder architecture used to integrate 3 omics of HCC data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In treatment plans, Nguyen et al. focus on predicting the dose distribution
    of radiotherapy, all the papers published by them [[72](#bib.bib72), [73](#bib.bib73),
    [74](#bib.bib74), [75](#bib.bib75)] used U-Net to predict dose of radiotherapy.
    Such as the work [[74](#bib.bib74)], which shows in Figure [22](#S3.F22 "Figure
    22 ‣ 3.4 Treatment Planning ‣ 3 Recent Work in Intelligent Diagnosis and Treatment
    of Tumors ‣ Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors:
    A Survey"), it is the first fully 3D dose distribution prediction for prostate
    IMRT plans. In this study, they use a similar set of 7 beam angles and criteria
    for treatment, which means that the model has currently learned only to predict
    the dose coming from approximately the same orientations, and may not be able
    to account for more intricate beam geometries. Also, the current model is unable
    to account for any physician preferences for predicting the dose, limiting the
    level of treatment personalization for the patient. However, the works of Nguyen
    et al. develop the dose prediction of cancer, which is meaningful.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/505a1526c06e48c1da43572b2175c8e1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22: The piplilne of treatment planning advanced by U-Net to predict
    the dose of radiotheropy [[74](#bib.bib74)].'
  prefs: []
  type: TYPE_NORMAL
- en: As a summary, the works in this part are heavy and complex, which contains many
    kinds of prediction, but only a few of them are relevant. Although these efforts
    cover many areas (such as prediction of cancer [[89](#bib.bib89)], life [[51](#bib.bib51)]
    and survival [[58](#bib.bib58), [69](#bib.bib69)]), few actually assist doctors
    in planning their treatment (such as prediction of radiation dose [[48](#bib.bib48),
    [72](#bib.bib72), [73](#bib.bib73), [74](#bib.bib74), [75](#bib.bib75)], radiotoxicity [[50](#bib.bib50)],
    anticancer drug response [[88](#bib.bib88)], and recurrence forecast [[54](#bib.bib54)]).
    There is still a dearth of real value studies on treatment plans, perhaps because
    it is difficult for non-medical researchers to collect data on treatment plans.
    Most studies only use some prediction as an ancillary result of research work,
    and there is still a huge gap in research that focuses on deep learning to assist
    tumor therapy. At this stage, the Computer-Aided Treatment of Tumors still needs
    more attention.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Conclusion and Outlook
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1 Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In conclusion, how to achieve early detection of tumors, accurate diagnosis,
    proper treatment, and better prognosis becomes the key to tumor treatment. With
    the rapid development of deep learning, doctors increasingly need Computer-Aided
    Diagnosis and Treatment of Tumors, because the material defects of human beings
    limit the further development of this field. These defects usually caused by sensory
    thresholds, cognitive biases, and personal experience differences. In particular,
    deep learning has achieved great success in natural datasets to different task
    types. Specific to the data types (such as images, indicators and gene expression
    by arrays) and different medical tasks (such as classification, segmentation,
    detection, and prediction) in Computer-Aided Diagnosis and Treatment of Tumors,
    deep learning can provide effective methods (such as CNN, FCN, R-CNNs). These
    successes provide good reference cases and experience for a series of medical
    tasks of tumor diagnosis and treatment.
  prefs: []
  type: TYPE_NORMAL
- en: In order to entirely solve clinical problems by using deep learning requires
    a detailed understanding of the specific characteristics of the medical data and
    medical tasks in tumor diagnosis and treatment, which have been summarised as
    follows.
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Medical tasks focus on a single organ and kinds of leisure on the organ, such
    as the calcification, nodule, cyst, and tumor on the lung.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Medical tasks rely on stable human structures, such as the primary or metastatic
    lesions of the intracranial tumor within the skull.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The object in medical tasks is small and has individual differences, such as
    the pancreas and the thyroid.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Medical tasks are multidisciplinary collaborative diagnosis and treatment.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Compared with these research which published in top magazine [[37](#bib.bib37),
    [29](#bib.bib29), [63](#bib.bib63), [66](#bib.bib66), [95](#bib.bib95), [99](#bib.bib99),
    [96](#bib.bib96), [67](#bib.bib67), [91](#bib.bib91)], it is easy to see, these
    works are either a meaningful breakthrough in the improvement of the new model
    (such as DeepMedic and U-Net) based on medical datasets or very close to the professional
    needs of medical tasks. Both types of studies have fully understood the clinical
    need and put it into practice. It means, when we are task-oriented and familiar
    with the characteristics of medical data, the deep learning method in computer
    science enables the rapid development of Computer-Aided Diagnosis and Treatment
    of Tumors. On the other hand, with the rapid development of deep learning in computer
    science, only by clarifying the nature and factions of various deep learning methods
    can researchers avoid detours.
  prefs: []
  type: TYPE_NORMAL
- en: This paper reviews the recent work in Computer-Aided Diagnosis and Treatment
    of Tumors from the following four points, data type, organs, medical tasks, and
    deep learning method. These works are of great significance in the Computer-Aided
    Diagnosis and Treatment of Tumors. The specific content is summarized as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, the survey summarizes the data type of tumor diagnosis and treatment
    from four stages. Each stage may have a different data type depending on its characteristics
    or may have a different tendency to process the data according to the requirements
    of the medical task.
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stage of In-Vitro Diagnosis (IVD). There are three kinds of medical data in
    this stage. 1) Images from the microscope, blood smear, and Flow Cytometer (FCM).
    2) arrays of cancer-associated genomic regions. Also, 3) numerical indices from
    a Flow Cytometer (FCM).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stage of Image Diagnosis. In this stage, most data is images from various medical
    imaging devices, such as Magnetic Resonance Imaging (MRI), Computed Tomography
    (CT), Single-PPhoton EEmission Computed Tomography (SPECT), Positron Emission
    Tomography (PET), Ultrasound (US), mammography.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stage of Pathological Diagnosis. In this stage, histology images stained by
    H & E is the mean medical data type.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stage of Treatment Plan. In this stage, except for the images and genomic data
    summarised above, radiotherapy data such as rectum surface dose maps (RSDM) is
    meaningful.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Secondly, the article reviews majority of organs and tissues which easy to have
    tumors.
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The target organ of the tumor. Such as the brain, lung, colorectum, nasopharynx,
    liver, kidney, bladder, stomach, cervix, head & neck.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The target gland of the tumor. Such as breast, prostate, thyroid, ovary, and
    pancreas.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The organ at risk (OAR). Such as the heart, esophagus, trachea, and aorta.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connective tissue, such as blood.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Thirdly, this work contains several medical tasks in four stages of tumor diagnosis
    and treatment, details was shown as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detection, common medical tasks include in this part are screening the tumor,
    the carcinoma cells, and the biomarkers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Segmentation, such as delineating the lesion and organ at risk (OAR).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classification, such as identifying the tumor subtypes and stages.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prediction, which contains a lot of clinical practice types. Including 1) prediction
    of radiation dose, radiotoxicity, anticancer drug response, and recurrence forecast;
    2) motion prediction under the action of breathing; 3) prediction of cancer, tumor
    invasiveness, tumor growth; and 4) prediction of life and survival.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Finally, the state-of-the-art in the Computer-Aided Diagnosis and Treatment
    of Tumors have been introduced detailedly before. It is a task-oriented review
    of different task types and their appropriate deep learning methods, such as the
    CNN series in the field of classification, the FCN series in the field of segmentation,
    and the R-CNN series of object detection. In general, these models are better
    at image data processing. However, recently researches are feeble in the area
    of non-image data which is also an essential source of clinical data.
  prefs: []
  type: TYPE_NORMAL
- en: Impressively, there are still plenty of reasons limit to the development of
    the Computer-Aided Diagnosis and Treatment of Tumors, which need the medical industry
    and the computer industry through cooperation can be targeted to solve. Such as
    medical imaging lacking high-quality datasets with unified standards and accurate
    labeling, existing models easy to over-fit with less robustness, data security,
    and diagnostic reliability. Therefore, there are still plenty of works is waiting
    for researchers.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Outlook and Challenge
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: According to the above summary and analysis, the Computer-Aided Diagnosis and
    Treatment of Tumors have thrived in all aspects of clinical practice. However,
    there are still many gaps and challenges worth noted based on this work. The following
    sections elaborate on these issues in four ways.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1 From Data Types
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The data types in recent researches seem to be quite comprehensive, but more
    often than not, people tend to focus on the Image Diagnosis data. Even this tendency
    extends to a few kinds of medical images, such as MRI and CT. Histology images
    and cancer-associated genomic regions have been partially concerned. However,
    some problems limit the progress of the research. For individual histology images,
    it can be up to 2G in size, which requires advanced servers for researchers. Also,
    lots of primary hospitals have no conditions for genetic testing. Besides, the
    data from stages of In-Vitro Diagnosis (IVD) and Treatment Plan have the same
    predicaments - there is not exist a sophisticated system to store the data of
    tumor diagnosis and treatment in bulks.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, the multi-disciplinary collaboration of medical tasks makes the multi-type
    datasets of the same task have a strong correlation, and taking data groups as
    research objects will gradually become a trend. Such as the integration of genomics
    and histopathology mentioned in this review [[96](#bib.bib96)].
  prefs: []
  type: TYPE_NORMAL
- en: Above all, deep learning is an art of big data, the gaps in early screening,
    treatment of tumors, and the study of multi-omics still need to be filled.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2 From Organs and Tissues
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are almost 20 different organs have been mentioned in this survey. However,
    the researchers prefer to focus on a few large organs (such as brain, liver, and
    lung), and the organ who has special examination (such as breast image from mammography,
    and thyroid image from ultrasound). Therefore, some structurally specific organ
    which is tiny and deep in humans body lacks the correlational research, such as
    the pancreas. The diagnosis and treatment of tumors in these organs is more challenging
    and meaningful,especially the pancreatic cancer is short disease duration and
    fatal. In this part, there is plenty of work which focus on tiny organs and tissues
    has to follow up.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.3 From Medical Tasks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this paper, more than 17 kinds of medical tasks in the Computer-Aided Diagnosis
    and Treatment of Tumors have been summarized. It is shown that the majority of
    the research priorities are detection, segmentation, and classification. There
    are screening the tumors, carcinoma cells, and biomarkers; delineating the lesion
    and Organ At Risk (OAR); and identifying the tumor subtypes and stages. However,
    in the prediction tasks of tumors, a unique phenomenon has emerged. Interestingly,
    the vast majority of studies on prediction of survival, prediction of life span
    do not contribute to clinical practice; they are usually just additional contributions
    from other studies. Although it seems significant, this kind of research tells
    us that patients are more likely to die if they get malignant tumors. These works
    do not provide constructive Suggestions to help doctors plan their next treatment.
    On the contrary, studies on actual adjuvant therapy, such as exercise management,
    radiation dose distribution prediction, radiation toxicity prediction, drug effect
    prediction, and tumor erosion prediction, are of clinical significance. However,
    due to the scarcity of data sources, this kind of research progress is languid,
    and more researchers need to put in relevant work.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.4 From Deep Learning Methods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although the application in the Computer-Aided Diagnosis and Treatment of Tumors
    of various deep learning models is generally in line with the development trend
    of computer science, the application is still sluggish. At present, the research
    in the field is still limited to simple deep learning model handling, and U-Net
    is the only influential model improved by medical data. There are gaps that state-of-the-art
    models published recently are not yet widely used in the Computer-Aided Diagnosis
    and Treatment of Tumors, such as Segmentation is all you need [[85](#bib.bib85)],
    a new revolution in object detection which good at difficulty tiny object; Transformer [[28](#bib.bib28)],
    BERT [[101](#bib.bib101)], Transformer-XL [[102](#bib.bib102)], XLNet [[103](#bib.bib103)],
    Sparse Transformers [[104](#bib.bib104)] in Natural Language Processing (NLP),
    which could be used for clinical data, such as medical history. It may revolutionize
    the performance of current oncology adjuvant therapy if the researchers introduce
    these advanced methods. Of course, it is particularly welcome if researchers are
    working on improving deep or creating learning models based on medical data and
    aim at medical tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.5 Adversarial Study
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Given the existing problems in tumor diagnosis and treatment in the whole industry,
    this paper has made a prospect and put forward the vacancy of existing research.
    However, in essence, some critical studies have never been done before, and it
    is worth noting. Adversarial study is one of such field.
  prefs: []
  type: TYPE_NORMAL
- en: Any research in deep learning is bound to encounter the question of whether
    the results are credible. In such an information age, information security and
    ethics are worth discussing. It remains to be seen whether researchers will be
    able to achieve consistent results in simple information confrontation experiments
    in the field of tumor diagnosis and treatment, not to mention that the diagnosis
    and treatment of tumors are vital and should be treated with caution. As far as
    we know, this field is almost blank except the recent work [[26](#bib.bib26)],
    which is a very terrible blank, but also a blank with infinite opportunities.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a summary, Computer-Aided Diagnosis and Treatment of Tumors are highly cross-disciplinary
    that ask researchers know medicine and computer science, but few people are proficient
    in both, and not everyone can find a partner with expertise. This problem has
    led to a situation in the field where computer scientists do not know how to make
    medical advances in combination with specific conditions, and doctors do not know
    which deep learning methods can better achieve their goals. It is also the reason
    why a large number of studies have been conducted which cannot guide clinical
    tumor treatment. For now, this paper could quickly guide doctors to choose a proper
    deep learning method, and computer researchers may learn more about tumor diagnosis
    and treatment. In clinical practice, the international standard for tumor diagnosis
    and treatment refer to the National Comprehensive Cancer Network (NCCN) Clinical
    Practice Guidelines in Oncology. (see: [https://www.nccn.org/professionals/physician_gls/default.aspx](https://www.nccn.org/professionals/physician_gls/default.aspx)).
    If researchers want to further improve the fit between their works and the medical
    task, clicking on it would be a good start.'
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work was supported in part by the National Natural Science Foundation of
    China under grant 61906063, in part by the Natural Science Foundation of Tianjin,
    China, under grant 19JCQNJC00400, and in part by the Yuanguang Scholar Fund of
    Hebei University of Technology, China.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] F. Bray, J. Ferlay, I. Soerjomataram, R. L. Siegel, L. A. Torre, A. Jemal,
    Global cancer statistics 2018: Globocan estimates of incidence and mortality worldwide
    for 36 cancers in 185 countries, CA: A Cancer Journal for Clinicians 68 (6) (2018)
    394–424.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] G. E. Hinton, R. R. Salakhutdinov, Reducing the dimensionality of data
    with neural networks, Science 313 (5786) (2006) 504–507.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Y. LeCun, L. Bottou, Y. Bengio, P. Haffner, et al., Gradient-based learning
    applied to document recognition, Proceedings of the IEEE 86 (11) (1998) 2278–2324.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] R. Girshick, J. Donahue, T. Darrell, J. Malik, Rich feature hierarchies
    for accurate object detection and semantic segmentation, in: In Proceedings of
    the IEEE Conference on Computer Vision and Pattern Recognition, 2014, pp. 580–587.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] R. Girshick, Fast r-cnn, in: In Proceedings of the IEEE International Conference
    on Computer Vision, 2015, pp. 1440–1448.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] S. Ren, K. He, R. Girshick, J. Sun, Faster r-cnn: Towards real-time object
    detection with region proposal networks, in: Advances in Neural Information Processing
    Systems, 2015, pp. 91–99.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] J. Long, E. Shelhamer, T. Darrell, Fully convolutional networks for semantic
    segmentation, in: In Proceedings of the IEEE Conference on Computer Vision and
    Pattern Recognition, 2015, pp. 3431–3440.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks for
    biomedical image segmentation, in: In Proceedings of the International Conference
    on Medical Image Computing and Computer-Assisted Intervention, 2015, pp. 234–241.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Z. C. Lipton, J. Berkowitz, C. Elkan, A critical review of recurrent neural
    networks for sequence learning, ArXiv Preprint ArXiv:1506.00019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] S. Hochreiter, J. Schmidhuber, Long short-term memory, Neural Computation
    9 (8) (1997) 1735–1780.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] J. Ker, L. Wang, J. Rao, T. Lim, Deep learning applications in medical
    image analysis, IEEE Access 6 (2017) 9375–9389.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] P. Meyer, V. Noblet, C. Mazzara, A. Lallement, Survey on deep learning
    for radiotherapy, Computers in Biology and Medicine 98 (2018) 126–146.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] K. Yasaka, H. Akai, A. Kunimatsu, S. Kiryu, O. Abe, Deep learning with
    convolutional neural network in radiology, Japanese Journal of Radiology 36 (4)
    (2018) 257–272.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] B. Sahiner, A. Pezeshk, L. M. Hadjiiski, X. Wang, K. Drukker, K. H. Cha,
    R. M. Summers, M. L. Giger, Deep learning in medical imaging and radiation therapy,
    Medical Physics 46 (1) (2019) e1–e36.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] Z. Hu, J. Tang, Z. Wang, K. Zhang, L. Zhang, Q. Sun, Deep learning for
    image-based cancer detection and diagnosis- a survey, Pattern Recognition 83 (2018)
    134–149.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] D. Ueda, A. Shimazaki, Y. Miki, Technical and clinical overview of deep
    learning in radiology, Japanese Journal of Radiology 37 (1) (2019) 15–33.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] J. Liu, Y. Pan, M. Li, Z. Chen, L. Tang, C. Lu, J. Wang, Applications
    of deep learning to mri images: A survey, Big Data Mining and Analytics 1 (1)
    (2018) 1–18.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] M. A. Mazurowski, M. Buda, A. Saha, M. R. Bashir, Deep learning in radiology:
    An overview of the concepts and a survey of the state of the art with focus on
    mri, Journal of Magnetic Resonance Imaging 49 (4) (2019) 939–954.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] S. Liu, Y. Wang, X. Yang, B. Lei, L. Liu, S. X. Li, D. Ni, T. Wang, Deep
    learning in medical ultrasound analysis: A review, Engineering 5 (2) (2019) 261–275.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] S. Napel, W. Mu, B. V. Jardim-Perassi, H. J. Aerts, R. J. Gillies, Quantitative
    imaging of cancer in the postgenomic era: Radio (geno) mics, deep learning, and
    habitats, Cancer 124 (24) (2018) 4633–4649.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] C. Cao, F. Liu, H. Tan, D. Song, W. Shu, W. Li, Y. Zhou, X. Bo, Z. Xie,
    Deep learning and its applications in biomedicine, Genomics, Proteomics & Bioinformatics
    16 (1) (2018) 17–32.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] D. Shen, G. Wu, H.-I. Suk, Deep learning in medical image analysis, Annual
    Review of Biomedical Engineering 19 (2017) 221–248.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] M. I. Razzak, S. Naz, A. Zaib, Deep learning for medical image processing:
    Overview, challenges and the future, in: Classification in BioApps, 2018, pp.
    323–350.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] T. Ching, D. S. Himmelstein, B. K. Beaulieu-Jones, A. A. Kalinin, B. T.
    Do, G. P. Way, E. Ferrero, P.-M. Agapow, M. Zietz, M. M. Hoffman, et al., Opportunities
    and obstacles for deep learning in biology and medicine, Journal of The Royal
    Society Interface 15 (141) (2018) 20170387.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] Z. Akkus, J. Cai, A. Boonrod, A. Zeinoddini, A. D. Weston, K. A. Philbrick,
    B. J. Erickson, A survey of deep-learning applications in ultrasound: Artificial
    intelligence–powered ultrasound for improving clinical workflow, Journal of the
    American College of Radiology 16 (9) (2019) 1318–1328.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] S. G. Finlayson, J. D. Bowers, J. Ito, J. L. Zittrain, A. L. Beam, I. S.
    Kohane, Adversarial attacks on medical machine learning, Science 363 (6433) (2019)
    1287–1289.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] K. He, G. Gkioxari, P. Dollár, R. Girshick, Mask r-cnn, in: In Proceedings
    of the IEEE international conference on computer vision, 2017, pp. 2961–2969.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, I. Polosukhin, Attention is all you need, in: Advances in neural information
    processing systems, 2017, pp. 5998–6008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] K. Kamnitsas, C. Ledig, V. F. Newcombe, J. P. Simpson, A. D. Kane, D. K.
    Menon, D. Rueckert, B. Glocker, Efficient multi-scale 3d cnn with fully connected
    crf for accurate brain lesion segmentation, Medical Image Analysis 36 (2017) 61–78.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale
    image recognition, ArXiv Preprint ArXiv:1409.1556.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition,
    in: In Proceedings of the IEEE conference on computer vision and pattern recognition,
    2016, pp. 770–778.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan,
    V. Vanhoucke, A. Rabinovich, Going deeper with convolutions, in: In Proceedings
    of the IEEE conference on computer vision and pattern recognition, 2015, pp. 1–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] M. Bellver, K.-K. Maninis, J. Pont-Tuset, X. Giró-i Nieto, J. Torres,
    L. Van Gool, Detection-aided liver lesion segmentation using deep learning, ArXiv
    Preprint ArXiv:1711.11069.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] F. Milletari, S.-A. Ahmadi, C. Kroll, A. Plate, V. Rozanski, J. Maiostre,
    J. Levin, O. Dietrich, B. Ertl-Wagner, K. Bötzel, et al., Hough-cnn: deep learning
    for segmentation of deep brain regions in mri and ultrasound, Computer Vision
    and Image Understanding 164 (2017) 92–102.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] T. Araújo, G. Aresta, E. Castro, J. Rouco, P. Aguiar, C. Eloy, A. Polónia,
    A. Campilho, Classification of breast cancer histology images using convolutional
    neural networks, PloS One 12 (6) (2017) e0177544.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] A. Cruz-Roa, H. Gilmore, A. Basavanhally, M. Feldman, S. Ganesan, N. N.
    Shih, J. Tomaszewski, F. A. González, A. Madabhushi, Accurate and reproducible
    invasive breast cancer detection in whole-slide images: A deep learning approach
    for quantifying tumor extent, Scientific Reports 7 (2017) 46450.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] J. Saltz, R. Gupta, L. Hou, T. Kurc, P. Singh, V. Nguyen, D. Samaras,
    K. R. Shroyer, T. Zhao, R. Batiste, et al., Spatial organization and molecular
    correlation of tumor-infiltrating lymphocytes using deep learning on pathology
    images, Cell Reports 23 (1) (2018) 181–193.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] A. Golatkar, D. Anand, A. Sethi, Classification of breast cancer histology
    using deep learning, in: In Proceedings of the International Conference on Image
    Analysis and Recognition, 2018, pp. 837–844.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] M. Khoshdeli, A. Borowsky, B. Parvin, Deep learning models differentiate
    tumor grades from h&e stained histology sections, in: In Proceedings of the IEEE
    Engineering in Medicine and Biology Society, 2018, pp. 620–623.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] P. Khosravi, E. Kazemi, M. Imielinski, O. Elemento, I. Hajirasouliha,
    Deep convolutional neural networks enable discrimination of heterogeneous digital
    pathology images, EBioMedicine 27 (2018) 317–328.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] R. Saouli, M. Akil, R. Kachouri, et al., Fully automatic brain tumor segmentation
    using end-to-end incremental deep neural networks in mri images, Computer Methods
    and Programs in Biomedicine 166 (2018) 39–49.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] Z. Li, Y. Wang, J. Yu, Y. Guo, W. Cao, Deep learning based radiomics (dlr)
    and its usage in noninvasive idh1 prediction for low grade glioma, Scientific
    Reports 7 (1) (2017) 5467.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] K. R. Laukamp, F. Thiele, G. Shakirin, D. Zopfs, A. Faymonville, M. Timmer,
    D. Maintz, M. Perkuhn, J. Borggrefe, Fully automated detection and segmentation
    of meningiomas using deep learning on routine multiparametric mri, European Radiology
    29 (1) (2019) 124–132.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] K. Leung, W. Marashdeh, R. Wray, S. Ashrafinia, A. Rahmim, M. Pomper,
    A. Jha, A deep-learning-based fully automated segmentation approach to delineate
    tumors in fdg-pet images of patients with lung cancer, Journal of Nuclear Medicine
    59 (supplement 1) (2018) 323–323.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] S. Trebeschi, J. J. van Griethuysen, D. M. Lambregts, M. J. Lahaye, C. Parmar,
    F. C. Bakers, N. H. Peters, R. G. Beets-Tan, H. J. Aerts, Deep learning for fully-automated
    localization and segmentation of rectal cancer on multiparametric mr, Scientific
    Reports 7 (1) (2017) 5301.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] Q. Li, Y. Xu, Z. Chen, D. Liu, S.-T. Feng, M. Law, Y. Ye, B. Huang, Tumor
    segmentation in contrast-enhanced magnetic resonance imaging for nasopharyngeal
    carcinoma: Deep learning with convolutional neural network, BioMed Research International
    2018 (2018) 9128527.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] A. Janowczyk, S. Doyle, H. Gilmore, A. Madabhushi, A resolution adaptive
    deep hierarchical (radhical) learning scheme applied to nuclear segmentation of
    digital pathology images, Computer Methods in Biomechanics and Biomedical Engineering:
    Imaging & Visualization 6 (3) (2018) 270–276.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] P. Jackson, N. Hardcastle, N. Dawe, T. Kron, M. Hofman, R. J. Hicks, Deep
    learning renal segmentation for fully automated radiation dose estimation in unsealed
    source therapy, Frontiers in Oncology 8 (2018) 215.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] M. D. Foote, B. Zimmerman, A. Sawant, S. Joshi, Real-time patient-specific
    lung radiotherapy targeting using deep learning, ArXiv Preprint ArXiv:1807.08388.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] X. Zhen, J. Chen, Z. Zhong, B. Hrycushko, L. Zhou, S. Jiang, K. Albuquerque,
    X. Gu, Deep convolutional neural network with transfer learning for rectum toxicity
    prediction in cervical cancer radiotherapy: a feasibility study, Physics in Medicine
    & Biology 62 (21) (2017) 8246.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] L. Oakden-Rayner, G. Carneiro, T. Bessen, J. C. Nascimento, A. P. Bradley,
    L. J. Palmer, Precision radiology: predicting longevity using feature engineering
    and deep learning methods in a radiomics framework, Scientific Reports 7 (1) (2017)
    1648.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] L. Zhang, L. Lu, R. M. Summers, E. Kebebew, J. Yao, Personalized pancreatic
    tumor growth prediction via group learning, in: In Proceedings of the International
    Conference on Medical Image Computing and Computer-Assisted Intervention, 2017,
    pp. 424–432.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] D. Bychkov, N. Linder, R. Turkki, S. Nordling, P. E. Kovanen, C. Verrill,
    M. Walliander, M. Lundin, C. Haglund, J. Lundin, Deep learning based tissue analysis
    predicts outcome in colorectal cancer, Scientific Reports 8 (1) (2018) 3395.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] S. Wang, Z. Liu, Y. Rong, B. Zhou, Y. Bai, W. Wei, M. Wang, Y. Guo, J. Tian,
    Deep learning provides a new computed tomography-based prognostic biomarker for
    recurrence prediction in high-grade serous ovarian cancer, Radiotherapy and Oncology
    132 (2019) 171–177.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] W. Zhao, J. Yang, Y. Sun, C. Li, W. Wu, L. Jin, Z. Yang, B. Ni, P. Gao,
    P. Wang, et al., 3d deep learning from ct scans predicts tumor invasiveness of
    subcentimeter pulmonary adenocarcinomas, Cancer Research 78 (24) (2018) 6881–6889.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] W. Bulten, P. Bándi, J. Hoven, R. van de Loo, J. Lotz, N. Weiss, J. van der
    Laak, B. van Ginneken, C. Hulsbergen-van de Kaa, G. Litjens, Epithelium segmentation
    using deep learning in h&e-stained prostate specimens with immunohistochemistry
    as reference standard, Scientific Reports 9 (1) (2019) 864.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] M. Perkuhn, P. Stavrinou, F. Thiele, G. Shakirin, M. Mohan, D. Garmpis,
    C. Kabbasch, J. Borggrefe, Clinical evaluation of a multiparametric deep learning
    model for glioblastoma segmentation using heterogeneous magnetic resonance imaging
    data from clinical routine, Investigative Radiology 53 (11) (2018) 647–654.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] P.-Y. Kao, T. Ngo, A. Zhang, J. W. Chen, B. Manjunath, Brain tumor segmentation
    and tractographic feature extraction from structural mr images for overall survival
    prediction, in: In Proceedings of the International Conference on Medical Image
    Computing and Computer Assisted Intervention Brainlesion Workshop, 2018, pp. 128–141.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] K. Kamnitsas, W. Bai, E. Ferrante, S. McDonagh, M. Sinclair, N. Pawlowski,
    M. Rajchl, M. Lee, B. Kainz, D. Rueckert, et al., Ensembles of multiple models
    and architectures for robust brain tumour segmentation, in: In Proceedings of
    the International Conference on Medical Image Computing and Computer Assisted
    Intervention Brainlesion Workshop, 2017, pp. 450–462.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] L. S. Castillo, L. A. Daza, L. C. Rivera, P. Arbeláez, Volumetric multimodality
    neural network for brain tumor segmentation, in: In Proceedings of the International
    Conference on Medical Information Processing and Analysis, Vol. 10572, 2017, p.
    105720E.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] R. Trullo, C. Petitjean, S. Ruan, B. Dubray, D. Nie, D. Shen, Segmentation
    of organs at risk in thoracic ct images using a sharpmask architecture and conditional
    random fields, in: In Proceedings of the IEEE International Symposium on Biomedical
    Imaging, 2017, pp. 1003–1006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] H. Shen, R. Wang, J. Zhang, S. J. McKenna, Boundary-aware fully convolutional
    network for brain tumor segmentation, in: In Proceedings of the International
    Conference on Medical Image Computing and Computer-Assisted Intervention, 2017,
    pp. 433–441.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] X. Zhao, Y. Wu, G. Song, Z. Li, Y. Zhang, Y. Fan, A deep learning model
    integrating fcnns and crfs for brain tumor segmentation, Medical Image Analysis
    43 (2018) 98–111.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] P. F. Christ, F. Ettlinger, F. Grün, M. E. A. Elshaera, J. Lipkova, S. Schlecht,
    F. Ahmaddy, S. Tatavarty, M. Bickel, P. Bilic, et al., Automatic liver and tumor
    segmentation of ct and mri volumes using cascaded fully convolutional neural networks,
    ArXiv Preprint ArXiv:1702.05970.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] M. H. Soomro, G. De Cola, S. Conforto, M. Schmid, G. Giunta, E. Guidi,
    E. Neri, D. Caruso, M. Ciolina, A. Laghi, Automatic segmentation of colorectal
    cancer in 3d mri by combining deep learning and 3d level-set algorithm-a preliminary
    study, in: In Proceedings of the IEEE Middle East Conference on Biomedical Engineering,
    2018, pp. 198–203.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] M. Drozdzal, G. Chartrand, E. Vorontsov, M. Shakeri, L. Di Jorio, A. Tang,
    A. Romero, Y. Bengio, C. Pal, S. Kadoury, Learning normalized inputs for iterative
    estimation in medical image segmentation, Medical Image Analysis 44 (2018) 1–13.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] T. Falk, D. Mai, R. Bensch, Ö. Çiçek, A. Abdulkadir, Y. Marrakchi, A. Böhm,
    J. Deubner, Z. Jäckel, K. Seiwald, et al., U-net: deep learning for cell counting,
    detection, and morphometry, Nature Methods 16 (1) (2019) 67.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] A. Beers, K. Chang, J. Brown, E. Sartor, C. Mammen, E. Gerstner, B. Rosen,
    J. Kalpathy-Cramer, Sequential 3d u-nets for biologically-informed brain tumor
    segmentation, ArXiv Preprint ArXiv:1709.02967.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] F. Isensee, P. Kickingereder, W. Wick, M. Bendszus, K. H. Maier-Hein,
    Brain tumor segmentation and radiomics survival prediction: Contribution to the
    brats 2017 challenge, in: In Proceedings of the International Conference on Medical
    Image Computing and Computer Assisted Intervention Brainlesion Workshop, 2017,
    pp. 287–297.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] Z. Guo, L. Zhang, L. Lu, M. Bagheri, R. M. Summers, M. Sonka, J. Yao,
    Deep logismos: Deep learning graph-based 3d segmentation of pancreatic tumors
    on ct scans, in: In Proceedings of the IEEE International Symposium on Biomedical
    Imaging, 2018, pp. 1230–1233.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] Z. Zhong, Y. Kim, L. Zhou, K. Plichta, B. Allen, J. Buatti, X. Wu, 3d
    fully convolutional networks for co-segmentation of tumors on pet-ct images, in:
    In Proceedings of the IEEE International Symposium on Biomedical Imaging, 2018,
    pp. 228–231.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] D. Nguyen, T. Long, X. Jia, W. Lu, X. Gu, Z. Iqbal, S. Jiang, Dose prediction
    with u-net: a feasibility study for predicting dose distributions from contours
    using deep learning on prostate imrt patients, ArXiv Preprint ArXiv:1709.09233.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] D. Nguyen, X. Jia, D. Sher, M.-H. Lin, Z. Iqbal, H. Liu, S. Jiang, Three-dimensional
    radiotherapy dose prediction on head and neck cancer patients with a hierarchically
    densely connected u-net deep learning architecture, ArXiv Preprint ArXiv:1805.10397.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] D. Nguyen, T. Long, X. Jia, W. Lu, X. Gu, Z. Iqbal, S. Jiang, A feasibility
    study for predicting optimal radiation therapy dose distributions of prostate
    cancer patients from patient anatomy using deep learning, Scientific Reports 9 (1)
    (2019) 1076.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] D. Nguyen, X. Jia, D. Sher, M.-H. Lin, Z. Iqbal, H. Liu, S. Jiang, 3d
    radiotherapy dose prediction on head and neck cancer patients with a hierarchically
    densely connected u-net deep learning architecture, Physics in Medicine & Biology
    64 (6) (2019) 065020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] C. J. Burges, A tutorial on support vector machines for pattern recognition,
    Data Mining and Knowledge Discovery 2 (2) (1998) 121–167.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] H. Li, J. Weng, Y. Shi, W. Gu, Y. Mao, Y. Wang, W. Liu, J. Zhang, An improved
    deep learning approach for detection of thyroid papillary cancer in ultrasound
    images, Scientific Reports 8 (2018) 6600.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] S. Rao, Mitos-rcnn: A novel approach to mitotic figure detection in breast
    cancer histopathology images using region based convolutional neural networks,
    ArXiv Preprint ArXiv:1807.01788.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] D. Cai, X. Sun, N. Zhou, X. Han, J. Yao, Efficient mitosis detection in
    breast cancer histology images by rcnn, in: In Proceedings of the IEEE International
    Symposium on Biomedical Imaging, 2019, pp. 919–922.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] A. Akselrod-Ballin, L. Karlinsky, S. Alpert, S. Hashoul, R. Ben-Ari, E. Barkan,
    A cnn based method for automatic mass detection and classification in mammograms,
    Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization
    7 (3) (2019) 242–249.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] D. Ribli, A. Horváth, Z. Unger, P. Pollner, I. Csabai, Detecting and classifying
    lesions in mammograms with deep learning, Scientific Reports 8 (1) (2018) 4165.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] J. Redmon, S. Divvala, R. Girshick, A. Farhadi, You only look once: Unified,
    real-time object detection, in: In Proceedings of the IEEE conference on computer
    vision and pattern recognition, 2016, pp. 779–788.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] J. Redmon, A. Farhadi, Yolo9000: better, faster, stronger, in: In Proceedings
    of the IEEE conference on computer vision and pattern recognition, 2017, pp. 7263–7271.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] J. Redmon, A. Farhadi, Yolov3: An incremental improvement, ArXiv Preprint
    ArXiv:1804.02767.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] Y. Wu, Z. Cheng, Z. Xu, W. Wang, Segmentation is all you need, ArXiv Preprint
    ArXiv:1904.13300.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] T. Tran, O.-H. Kwon, K.-R. Kwon, S.-H. Lee, K.-W. Kang, Blood cell images
    segmentation using deep learning semantic segmentation, in: In Proceedings of
    the IEEE International Conference on Electronics and Communication Engineering,
    2018, pp. 13–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] M. Doan, I. Vorobjev, P. Rees, A. Filby, O. Wolkenhauer, A. E. Goldfeld,
    J. Lieberman, N. Barteneva, A. E. Carpenter, H. Hennig, Diagnostic potential of
    imaging flow cytometry, Trends in Biotechnology 36 (7) (2018) 649–652.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] Y. Chang, H. Park, H.-J. Yang, S. Lee, K.-Y. Lee, T. S. Kim, J. Jung,
    J.-M. Shin, Cancer drug response profile scan (cdrscan): a deep learning model
    that predicts drug effectiveness from cancer genomic signature, Scientific Reports
    8 (1) (2018) 8857.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] Y. Xiao, J. Wu, Z. Lin, X. Zhao, A deep learning-based multi-model ensemble
    method for cancer prediction, Computer Methods and Programs in Biomedicine 153
    (2018) 1–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] V. Badrinarayanan, A. Kendall, R. Cipolla, Segnet: A deep convolutional
    encoder-decoder architecture for image segmentation, IEEE transactions on pattern
    analysis and machine intelligence 39 (12) (2017) 2481–2495.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] D. Ardila, A. P. Kiraly, S. Bharadwaj, B. Choi, J. J. Reicher, L. Peng,
    D. Tse, M. Etemadi, W. Ye, G. Corrado, et al., End-to-end lung cancer screening
    with three-dimensional deep learning on low-dose chest computed tomography, Nature
    Medicine 25 (6) (2019) 954.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] A. Akselrod-Ballin, L. Karlinsky, S. Alpert, S. Hasoul, R. Ben-Ari, E. Barkan,
    A region based convolutional network for tumor detection and classification in
    breast mammography, in: Deep Learning and Data Labeling for Medical Applications,
    2016, pp. 197–205.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] M. Drozdzal, E. Vorontsov, G. Chartrand, S. Kadoury, C. Pal, The importance
    of skip connections in biomedical image segmentation, in: Deep Learning and Data
    Labeling for Medical Applications, 2016, pp. 179–187.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] L. Breiman, Random forests, Machine Learning 45 (1) (2001) 5–32.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] O. Klein, F. Kanter, H. Kulbe, P. Jank, C. Denkert, G. Nebrich, W. D.
    Schmitt, Z. Wu, C. A. Kunze, J. Sehouli, et al., Maldi-imaging for classification
    of epithelial ovarian cancer histotypes from a tissue microarray using machine
    learning methods, Proteomics Clinical Applications 13 (1) (2019) 1700181.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] N. Coudray, P. S. Ocampo, T. Sakellaropoulos, N. Narula, M. Snuderl, D. Fenyö,
    A. L. Moreira, N. Razavian, A. Tsirigos, Classification and mutation prediction
    from non–small cell lung cancer histopathology images using deep learning, Nature
    Medicine 24 (10) (2018) 1559.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] A. J. Schaumberg, M. A. Rubin, T. J. Fuchs, H&e-stained whole slide image
    deep learning predicts spop mutation state in prostate cancer, BioRxiv (2018)
    064279.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna, Rethinking the
    inception architecture for computer vision, in: In Proceedings of the IEEE conference
    on computer vision and pattern recognition, 2016, pp. 2818–2826.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] K. Chaudhary, O. B. Poirion, L. Lu, L. X. Garmire, Deep learning–based
    multi-omics integration robustly predicts survival in liver cancer, Clinical Cancer
    Research 24 (6) (2018) 1248–1259.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] J. A. Hartigan, M. A. Wong, Algorithm as 136: A k-means clustering algorithm,
    Journal of the Royal Statistical Society. Series C (Applied Statistics) 28 (1)
    (1979) 100–108.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, Bert: Pre-training of deep
    bidirectional transformers for language understanding, ArXiv Preprint ArXiv:1810.04805.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] Z. Dai, Z. Yang, Y. Yang, W. W. Cohen, J. Carbonell, Q. V. Le, R. Salakhutdinov,
    Transformer-xl: Attentive language models beyond a fixed-length context, ArXiv
    Preprint ArXiv:1901.02860.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] Z. Yang, Z. Dai, Y. Yang, J. Carbonell, R. Salakhutdinov, Q. V. Le, Xlnet:
    Generalized autoregressive pretraining for language understanding, ArXiv Preprint
    ArXiv:1906.08237.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] R. Child, S. Gray, A. Radford, I. Sutskever, Generating long sequences
    with sparse transformers, ArXiv Preprint ArXiv:1904.10509.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
