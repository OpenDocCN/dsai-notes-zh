- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 20:08:05'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[1803.04311] Deep Learning in Mobile and Wireless Networking: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1803.04311](https://ar5iv.labs.arxiv.org/html/1803.04311)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Deep Learning in Mobile and Wireless Networking: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Chaoyun Zhang, Paul Patras, and Hamed Haddadi C. Zhang and P. Patras are with
    the Institute for Computing Systems Architecture (ICSA), School of Informatics,
    University of Edinburgh, Edinburgh, UK. Emails: {chaoyun.zhang, paul.patras}@ed.ac.uk.
    H. Haddadi is with the Dyson School of Design Engineering at Imperial College
    London. Email: h.haddadi@imperial.ac.uk.'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The rapid uptake of mobile devices and the rising popularity of mobile applications
    and services pose unprecedented demands on mobile and wireless networking infrastructure.
    Upcoming 5G systems are evolving to support exploding mobile traffic volumes,
    real-time extraction of fine-grained analytics, and agile management of network
    resources, so as to maximize user experience. Fulfilling these tasks is challenging,
    as mobile environments are increasingly complex, heterogeneous, and evolving.
    One potential solution is to resort to advanced machine learning techniques, in
    order to help manage the rise in data volumes and algorithm-driven applications.
    The recent success of deep learning underpins new and powerful tools that tackle
    problems in this space.
  prefs: []
  type: TYPE_NORMAL
- en: In this paper we bridge the gap between deep learning and mobile and wireless
    networking research, by presenting a comprehensive survey of the crossovers between
    the two areas. We first briefly introduce essential background and state-of-the-art
    in deep learning techniques with potential applications to networking. We then
    discuss several techniques and platforms that facilitate the efficient deployment
    of deep learning onto mobile systems. Subsequently, we provide an encyclopedic
    review of mobile and wireless networking research based on deep learning, which
    we categorize by different domains. Drawing from our experience, we discuss how
    to tailor deep learning to mobile environments. We complete this survey by pinpointing
    current challenges and open future directions for research.
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Deep Learning, Machine Learning, Mobile Networking, Wireless Networking, Mobile
    Big Data, 5G Systems, Network Management.
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Internet connected mobile devices are penetrating every aspect of individuals’
    life, work, and entertainment. The increasing number of smartphones and the emergence
    of evermore diverse applications trigger a surge in mobile data traffic. Indeed,
    the latest industry forecasts indicate that the annual worldwide IP traffic consumption
    will reach 3.3 zettabytes (10^(15) MB) by 2021, with smartphone traffic exceeding
    PC traffic by the same year [[1](#bib.bib1)]. Given the shift in user preference
    towards wireless connectivity, current mobile infrastructure faces great capacity
    demands. In response to this increasing demand, early efforts propose to agilely
    provision resources [[2](#bib.bib2)] and tackle mobility management distributively [[3](#bib.bib3)].
    In the long run, however, Internet Service Providers (ISPs) must develop *intelligent*
    heterogeneous architectures and tools that can spawn the 5^(th) generation of
    mobile systems (5G) and gradually meet more stringent end-user application requirements [[4](#bib.bib4),
    [5](#bib.bib5)].
  prefs: []
  type: TYPE_NORMAL
- en: The growing diversity and complexity of mobile network architectures has made
    monitoring and managing the multitude of network elements intractable. Therefore,
    embedding versatile machine intelligence into future mobile networks is drawing
    unparalleled research interest [[6](#bib.bib6), [7](#bib.bib7)]. This trend is
    reflected in machine learning (ML) based solutions to problems ranging from radio
    access technology (RAT) selection [[8](#bib.bib8)] to malware detection [[9](#bib.bib9)],
    as well as the development of networked systems that support machine learning
    practices (e.g. [[10](#bib.bib10), [11](#bib.bib11)]). ML enables systematic mining
    of valuable information from traffic data and automatically uncover correlations
    that would otherwise have been too complex to extract by human experts [[12](#bib.bib12)].
    As the flagship of machine learning, deep learning has achieved remarkable performance
    in areas such as computer vision [[13](#bib.bib13)] and natural language processing
    (NLP) [[14](#bib.bib14)]. Networking researchers are also beginning to recognize
    the power and importance of deep learning, and are exploring its potential to
    solve problems specific to the mobile networking domain [[15](#bib.bib15), [16](#bib.bib16)].
  prefs: []
  type: TYPE_NORMAL
- en: Embedding deep learning into the 5G mobile and wireless networks is well justified.
    In particular, data generated by mobile environments are increasingly heterogeneous,
    as these are usually collected from various sources, have different formats, and
    exhibit complex correlations [[17](#bib.bib17)]. As a consequence, a range of
    specific problems become too difficult or impractical for traditional machine
    learning tools (e.g., shallow neural networks). This is because *(i)* their performance
    does not improve if provided with more data [[18](#bib.bib18)] and *(ii)* they
    cannot handle highly dimensional state/action spaces in control problems [[19](#bib.bib19)].
    In contrast, big data fuels the performance of deep learning, as it eliminates
    domain expertise and instead employs hierarchical feature extraction. In essence
    this means information can be distilled efficiently and increasingly abstract
    correlations can be obtained from the data, while reducing the pre-processing
    effort. Graphics Processing Unit (GPU)-based parallel computing further enables
    deep learning to make inferences within milliseconds. This facilitates network
    analysis and management with high accuracy and in a timely manner, overcoming
    the run-time limitations of traditional mathematical techniques (e.g. convex optimization,
    game theory, meta heuristics).
  prefs: []
  type: TYPE_NORMAL
- en: Despite growing interest in deep learning in the mobile networking domain, existing
    contributions are scattered across different research areas and a comprehensive
    survey is lacking. This article fills this gap between deep learning and mobile
    and wireless networking, by presenting an up-to-date survey of research that lies
    at the intersection between these two fields. Beyond reviewing the most relevant
    literature, we discuss the key pros and cons of various deep learning architectures,
    and outline deep learning model selection strategies, in view of solving mobile
    networking problems. We further investigate methods that tailor deep learning
    to individual mobile networking tasks, to achieve the best performance in complex
    environments. We wrap up this paper by pinpointing future research directions
    and important problems that remain unsolved and are worth pursing with deep neural
    networks. Our ultimate goal is to provide a definite guide for networking researchers
    and practitioners, who intend to employ deep learning to solve problems of interest.
  prefs: []
  type: TYPE_NORMAL
- en: 'Survey Organization: We structure this article in a top-down manner, as shown
    in Figure [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Deep Learning in Mobile and
    Wireless Networking: A Survey"). We begin by discussing work that gives a high-level
    overview of deep learning, future mobile networks, and networking applications
    built using deep learning, which help define the scope and contributions of this
    paper (Section [II](#S2 "II Related High-level Articles and The Scope of This
    Survey ‣ Deep Learning in Mobile and Wireless Networking: A Survey")). Since deep
    learning techniques are relatively new in the mobile networking community, we
    provide a basic deep learning background in Section [III](#S3 "III Deep Learning
    101 ‣ Deep Learning in Mobile and Wireless Networking: A Survey"), highlighting
    immediate advantages in addressing mobile networking problems. There exist many
    factors that enable implementing deep learning for mobile networking applications
    (including dedicated deep learning libraries, optimization algorithms, etc.).
    We discuss these enablers in Section [IV](#S4 "IV Enabling Deep Learning in Mobile
    Networking ‣ Deep Learning in Mobile and Wireless Networking: A Survey"), aiming
    to help mobile network researchers and engineers in choosing the right software
    and hardware platforms for their deep learning deployments.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/37658e3eb377942e1efdc02ac0522a97.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Diagramatic view of the organization of this survey.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Section [V](#S5 "V Deep Learning: State-of-the-Art ‣ Deep Learning in Mobile
    and Wireless Networking: A Survey"), we introduce and compare state-of-the-art
    deep learning models and provide guidelines for model selection toward solving
    networking problems. In Section [VI](#S6 "VI Deep Learning Driven Mobile and Wireless
    Networks ‣ Deep Learning in Mobile and Wireless Networking: A Survey") we review
    recent deep learning applications to mobile and wireless networking, which we
    group by different scenarios ranging from mobile traffic analytics to security,
    and emerging applications. We then discuss how to tailor deep learning models
    to mobile networking problems (Section [VII](#S7 "VII Tailoring Deep Learning
    to Mobile Networks ‣ Deep Learning in Mobile and Wireless Networking: A Survey"))
    and conclude this article with a brief discussion of open challenges, with a view
    to future research directions (Section [VIII](#S8 "VIII Future Research Perspectives
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey")).¹¹1We list the
    abbreviations used throughout this paper in Table [I](#S1.T1 "TABLE I ‣ I Introduction
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE I: List of abbreviations in alphabetical order.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Acronym | Explanation |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 5G | 5^(th) Generation mobile networks |'
  prefs: []
  type: TYPE_TB
- en: '| A3C | Asynchronous Advantage Actor-Critic |'
  prefs: []
  type: TYPE_TB
- en: '| AdaNet | Adaptive learning of neural Network |'
  prefs: []
  type: TYPE_TB
- en: '| AE | Auto-Encoder |'
  prefs: []
  type: TYPE_TB
- en: '| AI | Artificial Intelligence |'
  prefs: []
  type: TYPE_TB
- en: '| AMP | Approximate Message Passing |'
  prefs: []
  type: TYPE_TB
- en: '| ANN | Artificial Neural Network |'
  prefs: []
  type: TYPE_TB
- en: '| ASR | Automatic Speech Recognition |'
  prefs: []
  type: TYPE_TB
- en: '| BSC | Base Station Controller |'
  prefs: []
  type: TYPE_TB
- en: '| BP | Back-Propagation |'
  prefs: []
  type: TYPE_TB
- en: '| CDR | Call Detail Record |'
  prefs: []
  type: TYPE_TB
- en: '| CNN or ConvNet | Convolutional Neural Network |'
  prefs: []
  type: TYPE_TB
- en: '| ConvLSTM | Convolutional Long Short-Term Memory |'
  prefs: []
  type: TYPE_TB
- en: '| CPU | Central Processing Unit |'
  prefs: []
  type: TYPE_TB
- en: '| CSI | Channel State Information |'
  prefs: []
  type: TYPE_TB
- en: '| CUDA | Compute Unified Device Architecture |'
  prefs: []
  type: TYPE_TB
- en: '| cuDNN | CUDA Deep Neural Network library |'
  prefs: []
  type: TYPE_TB
- en: '| D2D | Device to Device communication |'
  prefs: []
  type: TYPE_TB
- en: '| DAE | Denoising Auto-Encoder |'
  prefs: []
  type: TYPE_TB
- en: '| DBN | Deep Belief Network |'
  prefs: []
  type: TYPE_TB
- en: '| OFDM | Orthogonal Frequency-Division Multiplexing |'
  prefs: []
  type: TYPE_TB
- en: '| DPPO | Distributed Proximal Policy Optimization |'
  prefs: []
  type: TYPE_TB
- en: '| DQN | Deep Q-Network |'
  prefs: []
  type: TYPE_TB
- en: '| DRL | Deep Reinforcement Learning |'
  prefs: []
  type: TYPE_TB
- en: '| DT | Decision Tree |'
  prefs: []
  type: TYPE_TB
- en: '| ELM | Extreme Learning Machine |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Generative Adversarial Network |'
  prefs: []
  type: TYPE_TB
- en: '| GP | Gaussian Process |'
  prefs: []
  type: TYPE_TB
- en: '| GPS | Global Positioning System |'
  prefs: []
  type: TYPE_TB
- en: '| GPU | Graphics Processing Unit |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | Gate Recurrent Unit |'
  prefs: []
  type: TYPE_TB
- en: '| HMM | Hidden Markov Model |'
  prefs: []
  type: TYPE_TB
- en: '| HTTP | HyperText Transfer Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| IDS | Intrusion Detection System |'
  prefs: []
  type: TYPE_TB
- en: '| IoT | Internet of Things |'
  prefs: []
  type: TYPE_TB
- en: '| IoV | Internet of Vehicle |'
  prefs: []
  type: TYPE_TB
- en: '| ISP | Internet Service Provider |'
  prefs: []
  type: TYPE_TB
- en: '| LAN | Local Area Network |'
  prefs: []
  type: TYPE_TB
- en: '| LTE | Long-Term Evolution |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM | Long Short-Term Memory |'
  prefs: []
  type: TYPE_TB
- en: '| LSVRC | Large Scale Visual Recognition Challenge |'
  prefs: []
  type: TYPE_TB
- en: '| MAC | Media Access Control |'
  prefs: []
  type: TYPE_TB
- en: '| MDP | Markov Decision Process |'
  prefs: []
  type: TYPE_TB
- en: '| MEC | Mobile Edge Computing |'
  prefs: []
  type: TYPE_TB
- en: '| ML | Machine Learning |'
  prefs: []
  type: TYPE_TB
- en: '| MLP | Multilayer Perceptron |'
  prefs: []
  type: TYPE_TB
- en: '| MIMO | Multi-Input Multi-Output |'
  prefs: []
  type: TYPE_TB
- en: '| MTSR | Mobile Traffic Super-Resolution |'
  prefs: []
  type: TYPE_TB
- en: '| NFL | No Free Lunch theorem |'
  prefs: []
  type: TYPE_TB
- en: '| NLP | Natural Language Processing |'
  prefs: []
  type: TYPE_TB
- en: '| NMT | Neural Machine Translation |'
  prefs: []
  type: TYPE_TB
- en: '| NPU | Neural Processing Unit |'
  prefs: []
  type: TYPE_TB
- en: '| PCA | Principal Components Analysis |'
  prefs: []
  type: TYPE_TB
- en: '| PIR | Passive Infra-Red |'
  prefs: []
  type: TYPE_TB
- en: '| QoE | Quality of Experience |'
  prefs: []
  type: TYPE_TB
- en: '| RBM | Restricted Boltzmann Machine |'
  prefs: []
  type: TYPE_TB
- en: '| ReLU | Rectified Linear Unit |'
  prefs: []
  type: TYPE_TB
- en: '| RFID | Radio Frequency Identification |'
  prefs: []
  type: TYPE_TB
- en: '| RNC | Radio Network Controller |'
  prefs: []
  type: TYPE_TB
- en: '| RNN | Recurrent Neural Network |'
  prefs: []
  type: TYPE_TB
- en: '| SARSA | State-Action-Reward-State-Action |'
  prefs: []
  type: TYPE_TB
- en: '| SELU | Scaled Exponential Linear Unit |'
  prefs: []
  type: TYPE_TB
- en: '| SGD | Stochastic Gradient Descent |'
  prefs: []
  type: TYPE_TB
- en: '| SON | Self-Organising Network |'
  prefs: []
  type: TYPE_TB
- en: '| SNR | Signal-to-Noise Ratio |'
  prefs: []
  type: TYPE_TB
- en: '| SVM | Support Vector Machine |'
  prefs: []
  type: TYPE_TB
- en: '| TPU | Tensor Processing Unit |'
  prefs: []
  type: TYPE_TB
- en: '| VAE | Variational Auto-Encoder |'
  prefs: []
  type: TYPE_TB
- en: '| VR | Virtual Reality |'
  prefs: []
  type: TYPE_TB
- en: '| WGAN | Wasserstein Generative Adversarial Network |'
  prefs: []
  type: TYPE_TB
- en: '| WSN | Wireless Sensor Network |'
  prefs: []
  type: TYPE_TB
- en: II Related High-level Articles and
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Scope of This Survey
  prefs: []
  type: TYPE_NORMAL
- en: 'Mobile networking and deep learning problems have been researched mostly independently.
    Only recently crossovers between the two areas have emerged. Several notable works
    paint a comprehensives picture of the deep learning and/or mobile networking research
    landscape. We categorize these works into *(i)* pure overviews of deep learning
    techniques, *(ii)* reviews of analyses and management techniques in modern mobile
    networks, and *(iii)* reviews of works at the intersection between deep learning
    and computer networking. We summarize these earlier efforts in Table [II](#S2.T2
    "TABLE II ‣ II Related High-level Articles and The Scope of This Survey ‣ Deep
    Learning in Mobile and Wireless Networking: A Survey") and in this section discuss
    the most representative publications in each class.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE II: Summary of existing surveys, magazine papers, and books related to
    deep learning and mobile networking. The symbol ✓ indicates a publication is in
    the scope of a domain; ✗ marks papers that do not directly cover that area, but
    from which readers may retrieve some related insights. Publications related to
    both deep learning and mobile networks are shaded.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Publication | One-sentence summary | Scope |'
  prefs: []
  type: TYPE_TB
- en: '| Machine learning | Mobile networking |'
  prefs: []
  type: TYPE_TB
- en: '| Deep learning | Other ML methods | Mobile big data | 5G technology |'
  prefs: []
  type: TYPE_TB
- en: '| LeCun *et al.* [[20](#bib.bib20)] | A milestone overview of deep learning.
    | ✓ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Schmidhuber [[21](#bib.bib21)] | A comprehensive deep learning survey. |
    ✓ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Liu *et al.* [[22](#bib.bib22)] | A survey on deep learning and its applications.
    | ✓ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Deng *et al.* [[23](#bib.bib23)] | An overview of deep learning methods and
    applications. | ✓ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Deng [[24](#bib.bib24)] | A tutorial on deep learning. | ✓ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Goodfellow *et al.* [[18](#bib.bib18)] | An essential deep learning textbook.
    | ✓ | ✗ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Pouyanfar *et al.* [[25](#bib.bib25)] | A recent survey on deep learning.
    | ✓ | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Arulkumaran *et al.* [[26](#bib.bib26)] | A survey of deep reinforcement
    learning. | ✓ | ✗ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Hussein *et al.* [[27](#bib.bib27)] | A survey of imitation learning. | ✓
    | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Chen *et al.* [[28](#bib.bib28)] | An introduction to deep learning for big
    data. | ✓ | ✗ | ✗ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Najafabadi [[29](#bib.bib29)] | An overview of deep learning applications
    for big data analytics. | ✓ | ✗ | ✗ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Hordri *et al.* [[30](#bib.bib30)] | A brief of survey of deep learning for
    big data applications. | ✓ | ✗ | ✗ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Gheisari *et al.* [[31](#bib.bib31)] | A high-level literature review on
    deep learning for big data analytics. | ✓ |  | ✗ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang *et al.* [[32](#bib.bib32)] | A survey and outlook of deep learning
    for recommender systems. | ✓ | ✗ | ✗ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Yu *et al.* [[33](#bib.bib33)] | A survey on networking big data. |  |  |
    ✓ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Alsheikh *et al.* [[34](#bib.bib34)] | A survey on machine learning in wireless
    sensor networks. |  | ✓ | ✓ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Tsai *et al.* [[35](#bib.bib35)] | A survey on data mining in IoT. |  | ✓
    | ✓ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Cheng *et al.* [[36](#bib.bib36)] | An introductions mobile big data its
    applications. |  |  | ✓ | ✗ |'
  prefs: []
  type: TYPE_TB
- en: '| Bkassiny *et al.* [[37](#bib.bib37)] | A survey on machine learning in cognitive
    radios. |  | ✓ | ✗ | ✗ |'
  prefs: []
  type: TYPE_TB
- en: '| Andrews *et al.* [[38](#bib.bib38)] | An introduction and outlook of 5G networks.
    |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Gupta *et al.* [[5](#bib.bib5)] | A survey of 5G architecture and technologies.
    |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Agiwal *et al.* [[4](#bib.bib4)] | A survey of 5G mobile networking techniques.
    |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Panwar *et al.* [[39](#bib.bib39)] | A survey of 5G networks features, research
    progress and open issues. |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Elijah *et al.* [[40](#bib.bib40)] | A survey of 5G MIMO systems. |  |  |  |
    ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Buzzi *et al.* [[41](#bib.bib41)] | A survey of 5G energy-efficient techniques.
    |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Peng *et al.* [[42](#bib.bib42)] | An overview of radio access networks in
    5G. |  |  | ✗ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Niu *et al.* [[43](#bib.bib43)] | A survey of 5G millimeter wave communications.
    |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[2](#bib.bib2)] | 5G backhauling techniques and radio resource
    management. |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Giust *et al.* [[3](#bib.bib3)] | An overview of 5G distributed mobility
    management. |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Foukas *et al.* [[44](#bib.bib44)] | A survey and insights on network slicing
    in 5G. |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Taleb *et al.* [[45](#bib.bib45)] | A survey on 5G edge architecture and
    orchestration. |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Mach and Becvar [[46](#bib.bib46)] | A survey on MEC. |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Mao *et al.* [[47](#bib.bib47)] | A survey on mobile edge computing. |  |  |
    ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[48](#bib.bib48)] | An architecture for personalized QoE management
    in 5G. |  |  | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Han *et al.* [[49](#bib.bib49)] | Insights to mobile cloud sensing, big data,
    and 5G. |  |  | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Singh *et al.* [[50](#bib.bib50)] | A survey on social networks over 5G.
    |  | ✗ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Chen *et al.* [[51](#bib.bib51)] | An introduction to 5G cognitive systems
    for healthcare. | ✗ | ✗ | ✗ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Chen *et al.* [[52](#bib.bib52)] | Machine learning for traffic offloading
    in cellular network |  | ✓ |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Wu *et al.* [[53](#bib.bib53)] | Big data toward green cellular networks
    |  | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Buda *et al.* [[54](#bib.bib54)] | Machine learning aided use cases and scenarios
    in 5G. |  | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Imran *et al.* [[55](#bib.bib55)] | An introductions to big data analysis
    for self-organizing networks (SON) in 5G. |  | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Keshavamurthy *et al.* [[56](#bib.bib56)] | Machine learning perspectives
    on SON in 5G. |  | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Klaine *et al.* [[57](#bib.bib57)] | A survey of machine learning applications
    in SON. | ✗ | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Jiang *et al.* [[7](#bib.bib7)] | Machine learning paradigms for 5G. | ✗
    | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Li *et al.* [[58](#bib.bib58)] | Insights into intelligent 5G. | ✗ | ✓ |
    ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Bui *et al.* [[59](#bib.bib59)] | A survey of future mobile networks analysis
    and optimization. | ✗ | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Kasnesis *et al.* [[60](#bib.bib60)] | Insights into employing deep learning
    for mobile data analysis. | ✓ |  | ✓ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Alsheikh *et al.* [[17](#bib.bib17)] | Applying deep learning and Apache
    Spark for mobile data analytics. | ✓ |  | ✓ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Cheng *et al.* [[61](#bib.bib61)] | Survey of mobile big data analysis and
    outlook. | ✓ | ✓ | ✓ | ✗ |'
  prefs: []
  type: TYPE_TB
- en: '| Wang and Jones [[62](#bib.bib62)] | A survey of deep learning-driven network
    intrusion detection. | ✓ | ✓ | ✓ | ✗ |'
  prefs: []
  type: TYPE_TB
- en: '| Kato *et al.* [[63](#bib.bib63)] | Proof-of-concept deep learning for network
    traffic control. | ✓ |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Zorzi *et al.* [[64](#bib.bib64)] | An introduction to machine learning driven
    network optimization. | ✓ | ✓ |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Fadlullah *et al.* [[65](#bib.bib65)] | A comprehensive survey of deep learning
    for network traffic control. | ✓ | ✓ | ✓ | ✗ |'
  prefs: []
  type: TYPE_TB
- en: '| Zheng *et al.* [[6](#bib.bib6)] | An introduction to big data-driven 5G optimization.
    | ✓ | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: 'TABLE III: Continued from Table [II](#S2.T2 "TABLE II ‣ II Related High-level
    Articles and The Scope of This Survey ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey")'
  prefs: []
  type: TYPE_NORMAL
- en: '| Publication | One-sentence summary | Scope |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Machine learning | Mobile networking |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Deep learning | Other ML methods | Mobile big data | 5G technology
    |'
  prefs: []
  type: TYPE_TB
- en: '| Mohammadi *et al.* [[66](#bib.bib66)] | A survey of deep learning in IoT
    data analytics. | ✓ | ✓ | ✓ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Ahad *et al.* [[67](#bib.bib67)] | A survey of neural networks in wireless
    networks. | ✓ | ✗ | ✗ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Mao *et al.* [[68](#bib.bib68)] | A survey of deep learning for wireless
    networks. | ✓ | ✓ | ✓ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Luong *et al.* [[69](#bib.bib69)] | A survey of deep reinforcement learning
    for networking. | ✓ | ✓ |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Zhou *et al.* [[70](#bib.bib70)] | A survey of ML and cognitive wireless
    communications. | ✓ | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Chen *et al.* [[71](#bib.bib71)] | A tutorial on neural networks for wireless
    networks. | ✓ | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Gharaibeh *et al.* [[72](#bib.bib72)] | A survey of smart cities. | ✓ | ✓
    | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Lane *et al.* [[73](#bib.bib73)] | An overview and introduction of deep learning-driven
    mobile sensing. | ✓ | ✓ | ✓ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Ota *et al.* [[74](#bib.bib74)] | A survey of deep learning for mobile multimedia.
    | ✓ |  | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Mishra *et al.* [[75](#bib.bib75)] | A survey machine learning driven intrusion
    detection. | ✓ | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Our work | A comprehensive survey of deep learning for mobile and wireless
    network. | ✓ | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: II-A Overviews of Deep Learning and its Applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The era of big data is triggering wide interest in deep learning across different
    research disciplines [[28](#bib.bib28), [29](#bib.bib29), [31](#bib.bib31), [30](#bib.bib30)]
    and a growing number of surveys and tutorials are emerging (e.g. [[23](#bib.bib23),
    [24](#bib.bib24)]). LeCun *et al.* give a milestone overview of deep learning,
    introduce several popular models, and look ahead at the potential of deep neural
    networks [[20](#bib.bib20)]. Schmidhuber undertakes an encyclopedic survey of
    deep learning, likely the most comprehensive thus far, covering the evolution,
    methods, applications, and open research issues [[21](#bib.bib21)]. Liu *et al.*
    summarize the underlying principles of several deep learning models, and review
    deep learning developments in selected applications, such as speech processing,
    pattern recognition, and computer vision [[22](#bib.bib22)].
  prefs: []
  type: TYPE_NORMAL
- en: Arulkumaran *et al.* present several architectures and core algorithms for deep
    reinforcement learning, including deep Q-networks, trust region policy optimization,
    and asynchronous advantage actor-critic [[26](#bib.bib26)]. Their survey highlights
    the remarkable performance of deep neural networks in different control problem
    (e.g., video gaming, Go board game play, etc.). Similarly, deep reinforcement
    learning has also been surveyed in [[76](#bib.bib76)], where the authors shed
    more light on applications. Zhang *et al.* survey developments in deep learning
    for recommender systems [[32](#bib.bib32)], which have potential to play an important
    role in mobile advertising. As deep learning becomes increasingly popular, Goodfellow
    *et al.* provide a comprehensive tutorial of deep learning in a book that covers
    prerequisite knowledge, underlying principles, and popular applications [[18](#bib.bib18)].
  prefs: []
  type: TYPE_NORMAL
- en: II-B Surveys on Future Mobile Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The emerging 5G mobile networks incorporate a host of new techniques to overcome
    the performance limitations of current deployments and meet new application requirements.
    Progress to date in this space has been summarized through surveys, tutorials,
    and magazine papers (e.g. [[38](#bib.bib38), [4](#bib.bib4), [5](#bib.bib5), [39](#bib.bib39),
    [47](#bib.bib47)]). Andrews *et al.* highlight the differences between 5G and
    prior mobile network architectures, conduct a comprehensive review of 5G techniques,
    and discuss research challenges facing future developments[[38](#bib.bib38)].
    Agiwal *et al.* review new architectures for 5G networks, survey emerging wireless
    technologies, and point out research problems that remain unsolved [[4](#bib.bib4)].
    Gupta *et al.* also review existing work on 5G cellular network architectures,
    subsequently proposing a framework that incorporates networking ingredients such
    as Device-to-Device (D2D) communication, small cells, cloud computing, and the
    IoT [[5](#bib.bib5)].
  prefs: []
  type: TYPE_NORMAL
- en: Intelligent mobile networking is becoming a popular research area and related
    work has been reviewed in the literature (e.g. [[7](#bib.bib7), [54](#bib.bib54),
    [56](#bib.bib56), [34](#bib.bib34), [58](#bib.bib58), [37](#bib.bib37), [59](#bib.bib59),
    [57](#bib.bib57)]). Jiang *et al.* discuss the potential of applying machine learning
    to 5G network applications including massive MIMO and smart grids [[7](#bib.bib7)].
    This work further identifies several research gaps between ML and 5G that remain
    unexplored. Li *et al.* discuss opportunities and challenges of incorporating
    artificial intelligence (AI) into future network architectures and highlight the
    significance of AI in the 5G era [[58](#bib.bib58)]. Klaine *et al.* present several
    successful ML practices in Self-Organizing Networks (SONs), discuss the pros and
    cons of different algorithms, and identify future research directions in this
    area [[57](#bib.bib57)]. Potential exists to apply AI and exploit big data for
    energy efficiency purposes [[53](#bib.bib53)]. Chen *et al.* survey traffic offloading
    approaches in wireless networks, and propose a novel reinforcement learning based
    solution [[52](#bib.bib52)]. This opens a new research direction toward embedding
    machine learning towards greening cellular networks.
  prefs: []
  type: TYPE_NORMAL
- en: II-C Deep Learning Driven Networking Applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A growing number of papers survey recent works that bring deep learning into
    the computer networking domain. Alsheikh *et al.* identify benefits and challenges
    of using big data for mobile analytics and propose a Spark based deep learning
    framework for this purpose [[17](#bib.bib17)]. Wang and Jones discuss evaluation
    criteria, data streaming and deep learning practices for network intrusion detection,
    pointing out research challenges inherent to such applications [[62](#bib.bib62)].
    Zheng *et al.* put forward a big data-driven mobile network optimization framework
    in 5G networks, to enhance QoE performance [[6](#bib.bib6)]. More recently, Fadlullah
    *et al.* deliver a survey on the progress of deep learning in a board range of
    areas, highlighting its potential application to network traffic control systems
    [[65](#bib.bib65)]. Their work also highlights several unsolved research issues
    worthy of future study.
  prefs: []
  type: TYPE_NORMAL
- en: Ahad *et al.* introduce techniques, applications, and guidelines on applying
    neural networks to wireless networking problems [[67](#bib.bib67)]. Despite several
    limitations of neural networks identified, this article focuses largely on old
    neural networks models, ignoring recent progress in deep learning and successful
    applications in current mobile networks. Lane *et al.* investigate the suitability
    and benefits of employing deep learning in mobile sensing, and emphasize on the
    potential for accurate inference on mobile devices [[73](#bib.bib73)]. Ota *et
    al.* report novel deep learning applications in mobile multimedia. Their survey
    covers state-of-the-art deep learning practices in mobile health and wellbeing,
    mobile security, mobile ambient intelligence, language translation, and speech
    recognition. Mohammadi *et al.* survey recent deep learning techniques for Internet
    of Things (IoT) data analytics [[66](#bib.bib66)]. They overview comprehensively
    existing efforts that incorporate deep learning into the IoT domain and shed light
    on current research challenges and future directions. Mao *et al.* focus on deep
    learning in wireless networking [[68](#bib.bib68)]. Their work surveys state-of-the-art
    deep learning applications in wireless networks, and discusses research challenges
    to be solved in the future.
  prefs: []
  type: TYPE_NORMAL
- en: II-D Our Scope
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The objective of this survey is to provide a comprehensive view on state-of-the-art
    deep learning practices in the mobile networking area. By this we aim to answer
    the following key questions:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is deep learning promising for solving mobile networking problems?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the cutting-edge deep learning models relevant to mobile and wireless
    networking?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the most recent successful deep learning applications in the mobile
    networking domain?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can researchers tailor deep learning to specific mobile networking problems?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which are the most important and promising directions worthy of further study?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The research papers and books we mentioned previously only partially answer
    these questions. This article goes beyond these previous works and specifically
    focuses on the crossovers between deep learning and mobile networking. We cover
    a range of neural network (NN) structures that are increasingly important and
    have not been explicitly discussed in earlier tutorials, e.g., [[77](#bib.bib77)].
    This includes auto-encoders and Generative Adversarial Networks. Unlike such existing
    tutorials, we also review open-source libraries for deploying and training neural
    networks, a range of optimization algorithms, and the parallelization of neural
    networks models and training across large numbers of mobile devices. We also review
    applications not looked at in other related surveys, including traffic/user analytics,
    security and privacy, mobile health, etc.
  prefs: []
  type: TYPE_NORMAL
- en: 'While our main scope remains the mobile networking domain, for completeness
    we also discuss deep learning applications to wireless networks, and identify
    emerging application domains intimately connected to these areas. We differentiate
    between mobile networking, which refers to scenarios where devices are portable,
    battery powered, potentially wearable, and routinely connected to cellular infrastructure,
    and wireless networking, where devices are mostly fixed, and part of a distributed
    infrastructure (including WLANs and WSNs), and serve a single application. Overall,
    our paper distinguishes itself from earlier surveys from the following perspectives:'
  prefs: []
  type: TYPE_NORMAL
- en: '*(i)*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We particularly focus on deep learning applications for mobile network analysis
    and management, instead of broadly discussing deep learning methods (as, e.g.,
    in  [[20](#bib.bib20), [21](#bib.bib21)]) or centering on a single application
    domain, e.g. mobile big data analysis with a specific platform [[17](#bib.bib17)].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*(ii)*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We discuss cutting-edge deep learning techniques from the perspective of mobile
    networks (e.g., [[78](#bib.bib78), [79](#bib.bib79)]), focusing on their applicability
    to this area, whilst giving less attention to conventional deep learning models
    that may be out-of-date.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*(iii)*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We analyze similarities between existing non-networking problems and those specific
    to mobile networks; based on this analysis we provide insights into both best
    deep learning architecture selection strategies and adaptation approaches, so
    as to exploit the characteristics of mobile networks for analysis and management
    tasks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To the best of our knowledge, this is the first time that mobile network analysis
    and management are jointly reviewed from a deep learning angle. We also provide
    for the first time insights into how to tailor deep learning to mobile networking
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: III Deep Learning 101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We begin with a brief introduction to deep learning, highlighting the basic
    principles behind computation techniques in this field, as well as key advantages
    that lead to their success. Deep learning is essentially a sub-branch of ML, which
    essentially enables an algorithm to make predictions, classifications, or decisions
    based on data, without being explicitly programmed. Classic examples include linear
    regression, the k-nearest neighbors classifier, and Q-learning. In contrast to
    traditional ML tools that rely heavily on features defined by domain experts,
    deep learning algorithms hierarchically extract knowledge from raw data through
    multiple layers of nonlinear processing units, in order to make predictions or
    take actions according to some target objective. The most well-known deep learning
    models are neural networks (NNs), but only NNs that have a sufficient number of
    hidden layers (usually more than one) can be regarded as ‘deep’ models. Besides
    deep NNs, other architectures have multiple layers, such as deep Gaussian processes
    [[80](#bib.bib80)], neural processes [[81](#bib.bib81)], and deep random forests [[82](#bib.bib82)],
    and can also be regarded as deep learning structures. The major benefit of deep
    learning over traditional ML is thus the automatic feature extraction, by which
    expensive hand-crafted feature engineering can be circumvented. We illustrate
    the relation between deep learning, machine learning, and artificial intelligence
    (AI) at a high level in Fig. [2](#S3.F2 "Figure 2 ‣ III Deep Learning 101 ‣ Deep
    Learning in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: In general, AI is a computation paradigm that endows machines with intelligence,
    aiming to teach them how to work, react, and learn like humans. Many techniques
    fall under this broad umbrella, including machine learning, expert systems, and
    evolutionary algorithms. Among these, machine learning enables the artificial
    processes to absorb knowledge from data and make decisions without being explicitly
    programmed. Machine learning algorithms are typically categorized into supervised,
    unsupervised, and reinforcement learning. Deep learning is a family of machine
    learning techniques that mimic biological nervous systems and perform representation
    learning through multi-layer transformations, extending across all three learning
    paradigms mentioned before. As deep learning has growing number of applications
    in mobile an wireless networking, the crossovers between these domains make the
    scope of this manuscript.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d7cd04d24877f03d1355321086439341.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Venn diagram of the relation between deep learning, machine learning,
    and AI. This survey particularly focuses on deep learning applications in mobile
    and wireless networks.'
  prefs: []
  type: TYPE_NORMAL
- en: III-A The Evolution of Deep Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The discipline traces its origins 75 years back, when threshold logic was employed
    to produce a computational model for neural networks [[83](#bib.bib83)]. However,
    it was only in the late 1980s that neural networks (NNs) gained interest, as Rumelhart
    *et al.* showed that multi-layer NNs could be trained effectively by back-propagating
    errors [[84](#bib.bib84)]. LeCun and Bengio subsequently proposed the now popular
    Convolutional Neural Network (CNN) architecture [[85](#bib.bib85)], but progress
    stalled due to computing power limitations of systems available at that time.
    Following the recent success of GPUs, CNNs have been employed to dramatically
    reduce the error rate in the Large Scale Visual Recognition Challenge (LSVRC) [[86](#bib.bib86)]. This
    has drawn unprecedented interest in deep learning and breakthroughs continue to
    appear in a wide range of computer science areas.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0b5f2ac37d40e9be6b6a428c53bc3a0c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Illustration of the learning and inference processes of a 4-layer
    CNN. $w_{(\cdot)}$ denote weights of each hidden layer, $\sigma(\cdot)$ is an
    activation function, $\lambda$ refers to the learning rate, $*(\cdot)$ denotes
    the convolution operation and $\mathcal{L}(w)$ is the loss function to be optimized.'
  prefs: []
  type: TYPE_NORMAL
- en: III-B Fundamental Principles of Deep Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The key aim of deep neural networks is to approximate complex functions through
    a composition of simple and predefined operations of units (or neurons). Such
    an objective function can be almost of any type, such as a mapping between images
    and their class labels (classification), computing future stock prices based on
    historical values (regression), or even deciding the next optimal chess move given
    the current status on the board (control). The operations performed are usually
    defined by a weighted combination of a specific group of hidden units with a non-linear
    activation function, depending on the structure of the model. Such operations
    along with the output units are named “layers”. The neural network architecture
    resembles the perception process in a brain, where a specific set of units are
    activated given the current environment, influencing the output of the neural
    network model.
  prefs: []
  type: TYPE_NORMAL
- en: III-C Forward and Backward Propagation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In mathematical terms, the architecture of deep neural networks is usually
    differentiable, therefore the weights (or parameters) of the model can be learned
    by minimizing a loss function using gradient descent methods through back-propagation,
    following the fundamental chain rule [[84](#bib.bib84)]. We illustrate the principles
    of the learning and inference processes of a deep neural network in Fig. [3](#S3.F3
    "Figure 3 ‣ III-A The Evolution of Deep Learning ‣ III Deep Learning 101 ‣ Deep
    Learning in Mobile and Wireless Networking: A Survey"), where we use a two-dimensional
    (2D) Convolutional Neural Network (CNN) as an example.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Forward propagation: The figure shows a CNN with 5 layers, i.e., an input layer
    (grey), 3 hidden layers (blue) and an output layer (orange). In forward propagation,
    A 2D input $\mathbf{x}$ (e.g images) is first processed by a convolutional layer,
    which perform the following convolutional operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $h_{1}=\sigma(w_{1}\ast\mathbf{x}).$ |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: Here $h_{1}$ is the output of the first hidden layer, $w_{1}$ is the convolutional
    filter and $\sigma(\cdot)$ is the activation function, aiming at improving the
    non-linearity and representability of the model. The output $h_{1}$ is subsequently
    provided as input to and processed by the following two convolutional layers,
    which eventually produces a final output $\mathbf{y}$. This could be for instance
    vector of probabilities for different possible patterns (shapes) discovered in
    the (image) input. To train the CNN appropriately, one uses a loss function $\mathcal{L}(w)$
    to measure the distance between the output $\mathbf{y}$ and the ground truth $\mathbf{y^{*}}$.
    The purpose of training is to find the best weights $\mathbf{w}$, so as to minimize
    the loss function $\mathcal{L}(w)$. This can be achieved by the back propagation
    through gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Backward propagation: During backward propagation, one computes the gradient
    of the loss function $\mathcal{L}(w)$ over the weight of the last hidden layer,
    and updates the weight by computing:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $w_{4}=w_{4}-\lambda\frac{\mathrm{d}\mathcal{L}(w)}{\mathrm{d}w_{4}}.$
    |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: Here $\lambda$ denotes the learning rate, which controls the step size of moving
    in the direction indicated by the gradient. The same operation is performed for
    each weight, following the chain rule. The process is repeated and eventually
    the gradient descent will lead to a set $w$ that minimizes the $\mathcal{L}(w)$.
  prefs: []
  type: TYPE_NORMAL
- en: 'For other NN structures, the training and inference processes are similar.
    To help less expert readers we detail the principles and computational details
    of various deep learning techniques in Sec.[V](#S5 "V Deep Learning: State-of-the-Art
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE IV: Summary of the benefits of applying deep learning to solve problems
    in mobile and wireless networks.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Key aspect | Description | Benefits |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Feature extraction | Deep neural networks can automatically extract high-level
    features through layers of different depths. | Reduce expensive hand-crafted feature
    engineering in processing heterogeneous and noisy mobile big data. |'
  prefs: []
  type: TYPE_TB
- en: '| Big data exploitation | Unlike traditional ML tools, the performance of deep
    learning usually grow significantly with the size of training data. | Efficiently
    utilize huge amounts of mobile data generated at high rates. |'
  prefs: []
  type: TYPE_TB
- en: '| Unsupervised learning | Deep learning is effective in processing un-/semi-
    labeled data, enabling unsupervised learning. | Handling large amounts of unlabeled
    data, which are common in mobile system. |'
  prefs: []
  type: TYPE_TB
- en: '| Multi-task learning | Features learned by neural networks through hidden
    layers can be applied to different tasks by transfer learning. | Reduce computational
    and memory requirements when performing multi-task learning in mobile systems.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Geometric mobile data learning | Dedicated deep learning architectures exist
    to model geometric mobile data | Revolutionize geometric mobile data analysis
    |'
  prefs: []
  type: TYPE_TB
- en: III-D Advantages of Deep Learning in Mobile and Wireless Networking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We recognize several benefits of employing deep learning to address network
    engineering problems, as summarized in Table [IV](#S3.T4 "TABLE IV ‣ III-C Forward
    and Backward Propagation ‣ III Deep Learning 101 ‣ Deep Learning in Mobile and
    Wireless Networking: A Survey"). Specifically:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is widely acknowledged that, while vital to the performance of traditional
    ML algorithms, feature engineering is costly [[87](#bib.bib87)]. A key advantage
    of deep learning is that it can automatically extract high-level features from
    data that has complex structure and inner correlations. The learning process does
    not need to be designed by a human, which tremendously simplifies prior feature
    handcrafting [[20](#bib.bib20)]. The importance of this is amplified in the context
    of mobile networks, as mobile data is usually generated by heterogeneous sources,
    is often noisy, and exhibits non-trivial spatial/temporal patterns [[17](#bib.bib17)],
    whose labeling would otherwise require outstanding human effort.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Secondly, deep learning is capable of handling large amounts of data. Mobile
    networks generate high volumes of different types of data at fast pace. Training
    traditional ML algorithms (e.g., Support Vector Machine (SVM) [[88](#bib.bib88)]
    and Gaussian Process (GP) [[89](#bib.bib89)]) sometimes requires to store all
    the data in memory, which is computationally infeasible under big data scenarios.
    Furthermore, the performance of ML does not grow significantly with large volumes
    of data and plateaus relatively fast [[18](#bib.bib18)]. In contrast, Stochastic
    Gradient Descent (SGD) employed to train NNs only requires sub-sets of data at
    each training step, which guarantees deep learning’s scalability with big data.
    Deep neural networks further benefit as training with big data prevents model
    over-fitting.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Traditional supervised learning is only effective when sufficient labeled data
    is available. However, most current mobile systems generate unlabeled or semi-labeled
    data [[17](#bib.bib17)]. Deep learning provides a variety of methods that allow
    exploiting unlabeled data to learn useful patterns in an unsupervised manner,
    e.g., Restricted Boltzmann Machine (RBM) [[90](#bib.bib90)], Generative Adversarial
    Network (GAN) [[91](#bib.bib91)]. Applications include clustering [[92](#bib.bib92)],
    data distributions approximation [[91](#bib.bib91)], un/semi-supervised learning [[93](#bib.bib93),
    [94](#bib.bib94)], and one/zero shot learning [[95](#bib.bib95), [96](#bib.bib96)],
    among others.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compressive representations learned by deep neural networks can be shared across
    different tasks, while this is limited or difficult to achieve in other ML paradigms
    (e.g., linear regression, random forest, etc.). Therefore, a single model can
    be trained to fulfill multiple objectives, without requiring complete model retraining
    for different tasks. We argue that this is essential for mobile network engineering,
    as it reduces computational and memory requirements of mobile systems when performing
    multi-task learning applications [[97](#bib.bib97)].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep learning is effective in handing geometric mobile data [[98](#bib.bib98)],
    while this is a conundrum for other ML approaches. Geometric data refers to multivariate
    data represented by coordinates, topology, metrics and order [[99](#bib.bib99)].
    Mobile data, such as mobile user location and network connectivity can be naturally
    represented by point clouds and graphs, which have important geometric properties.
    These data can be effectively modelled by dedicated deep learning architectures,
    such as PointNet++ [[100](#bib.bib100)] and Graph CNN [[101](#bib.bib101)]. Employing
    these architectures has great potential to revolutionize the geometric mobile
    data analysis [[102](#bib.bib102)].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: III-E Limitations of Deep Learning in Mobile and Wireless Networking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although deep learning has unique advantages when addressing mobile network
    problems, it also has several shortcomings, which partially restricts its applicability
    in this domain. Specifically,
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In general, deep learning (including deep reinforcement learning) is vulnerable
    to adversarial examples [[103](#bib.bib103), [104](#bib.bib104)]. These refer
    to artifact inputs that are intentionally designed by an attacker to fool machine
    learning models into making mistakes [[103](#bib.bib103)]. While it is difficult
    to distinguish such samples from genuine ones, they can trigger mis-adjustments
    of a model with high likelihood. We illustrate an example of such an adversarial
    attack in Fig. [4](#S3.F4 "Figure 4 ‣ item 1 ‣ III-E Limitations of Deep Learning
    in Mobile and Wireless Networking ‣ III Deep Learning 101 ‣ Deep Learning in Mobile
    and Wireless Networking: A Survey"). Deep learning, especially CNNs are vulnerable
    to these types of attacks. This may also affect the applicability of deep learning
    in mobile systems. For instance, hackers may exploit this vulnerability and construct
    cyber attacks that subvert deep learning based detectors [[105](#bib.bib105)].
    Constructing deep models that are robust to adversarial examples is imperative,
    but remains challenging.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c322683e9c998c864b2ae7daf3879b95.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 4: An example of an adversarial attack on deep learning.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep learning algorithms are largely black boxes and have low interpretability.
    Their major breakthroughs are in terms of accuracy, as they significantly improve
    performance of many tasks in different areas. However, although deep learning
    enables creating “machines” that have high accuracy in specific tasks, we still
    have limited knowledge as of why NNs make certain decisions. This limits the applicability
    of deep learning, e.g. in network economics. Therefore, businesses would rather
    continue to employ statistical methods that have high interpretability, whilst
    sacrificing on accuracy. Researchers have recognized this problem and investing
    continuous efforts to address this limitation of deep learning (e.g. [[106](#bib.bib106),
    [107](#bib.bib107), [108](#bib.bib108)]).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep learning is heavily reliant on data, which sometimes can be more important
    than the model itself. Deep models can further benefit from training data augmentation
    [[109](#bib.bib109)]. This is indeed an opportunity for mobile networking, as
    networks generates tremendous amounts of data. However, data collection may be
    costly, and face privacy concern, therefore it may be difficult to obtain sufficient
    information for model training. In such scenarios, the benefits of employing deep
    learning may be outweigth by the costs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deep learning can be computationally demanding. Advanced parallel computing
    (e.g. GPUs, high-performance chips) fostered the development and popularity of
    deep learning, yet deep learning also heavily relies on these. Deep NNs usually
    require complex structures to obtain satisfactory accuracy performance. However,
    when deploying NNs on embedded and mobile devices, energy and capability constraints
    have to be considered. Very deep NNs may not be suitable for such scenario and
    this would inevitably compromise accuracy. Solutions are being developed to mitigate
    this problem and we will dive deeper into these in Sec. [IV](#S4 "IV Enabling
    Deep Learning in Mobile Networking ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey") and [VII](#S7 "VII Tailoring Deep Learning to Mobile Networks ‣ Deep
    Learning in Mobile and Wireless Networking: A Survey").'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep neural networks usually have many hyper-parameters and finding their optimal
    configuration can be difficult. For a single convolutional layer, we need to configure
    at least hyper-parameters for the number, shape, stride, and dilation of filters,
    as well as for the residual connections. The number of such hyper-parameters grows
    exponentially with the depth of the model and can highly influence its performance.
    Finding a good set of hyper-parameters can be similar to looking for a needle
    in a haystack. The AutoML platform²²2AutoML – training high-quality custom machine
    learning models with minimum effort and machine learning expertise. https://cloud.google.com/automl/
    provides a first solution to this problem, by employing progressive neural architecture
    search [[110](#bib.bib110)]. This task, however, remains costly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To circumvent some of the aforementioned problems and allow for effective deployment
    in mobile networks, deep learning requires certain system and software support.
    We review and discuss such enablers in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: IV Enabling Deep Learning in Mobile Networking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '5G systems seek to provide high throughput and ultra-low latency communication
    services, to improve users’ QoE [[4](#bib.bib4)]. Implementing deep learning to
    build intelligence into 5G systems, so as to meet these objectives is expensive.
    This is because powerful hardware and software is required to support training
    and inference in complex settings. Fortunately, several tools are emerging, which
    make deep learning in mobile networks tangible; namely, *(i)* advanced parallel
    computing, *(ii)* distributed machine learning systems, *(iii)* dedicated deep
    learning libraries, *(iv)* fast optimization algorithms, and *(v)* fog computing.
    These tools can be seen as forming a hierarchical structure, as illustrated in
    Fig. [5](#S4.F5 "Figure 5 ‣ IV Enabling Deep Learning in Mobile Networking ‣ Deep
    Learning in Mobile and Wireless Networking: A Survey"); synergies between them
    exist that makes networking problem amenable to deep learning based solutions.
    By employing these tools, once the training is completed, inferences can be made
    within millisecond timescales, as already reported by a number of papers for a
    range of tasks (e.g., [[111](#bib.bib111), [112](#bib.bib112), [113](#bib.bib113)]
    ). We summarize these advances in Table [V](#S4.T5 "TABLE V ‣ IV Enabling Deep
    Learning in Mobile Networking ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey") and review them in what follows.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a76ea6e6f3d03911e10e0ad33ebd3573.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Hierarchical view of deep learning enablers. Parallel computing and
    hardware in fog computing lay foundations for deep learning. Distributed machine
    learning systems can build upon them, to support large-scale deployment of deep
    learning. Deep learning libraries run at the software level, to enable fast deep
    learning implementation. Higher-level optimizers are used to train the NN, to
    fulfill specific objectives.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE V: Summary of tools and techniques that enable deploying deep learning
    in mobile systems.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Technique | Examples | Scope | Functionality | Performance improvement |
    Energy consumption | Economic cost |'
  prefs: []
  type: TYPE_TB
- en: '| Advanced parallel computing | GPU, TPU [[114](#bib.bib114)], CUDA [[115](#bib.bib115)],
    cuDNN [[116](#bib.bib116)] | Mobile servers, workstations | Enable fast, parallel
    training/inference of deep learning models in mobile applications | High | High
    | Medium (hardware) |'
  prefs: []
  type: TYPE_TB
- en: '| Dedicated deep learning library | TensorFlow [[117](#bib.bib117)], Theano
    [[118](#bib.bib118)], Caffe [[119](#bib.bib119)], Torch [[120](#bib.bib120)] |
    Mobile servers and devices | High-level toolboxes that enable network engineers
    to build purpose-specific deep learning architectures | Medium | Associated with
    hardware | Low (software) |'
  prefs: []
  type: TYPE_TB
- en: '| Fog computing | nn-X [[121](#bib.bib121)], ncnn [[122](#bib.bib122)], Kirin
    970 [[123](#bib.bib123)], Core ML [[124](#bib.bib124)] | Mobile devices | Support
    edge-based deep learning computing | Medium | Low | Medium (hardware) |'
  prefs: []
  type: TYPE_TB
- en: '| Fast optimization algorithms | Nesterov [[125](#bib.bib125)], Adagrad [[126](#bib.bib126)],
    RMSprop, Adam [[127](#bib.bib127)] | Training deep architectures | Accelerate
    and stabilize the model optimization process | Medium | Associated with hardware
    | Low (software) |'
  prefs: []
  type: TYPE_TB
- en: '| Distributed machine learning systems | MLbase [[128](#bib.bib128)], Gaia [[10](#bib.bib10)],
    Tux² [[11](#bib.bib11)], Adam [[129](#bib.bib129)], GeePS [[130](#bib.bib130)]
    | Distributed data centers, cross-server | Support deep learning frameworks in
    mobile systems across data centers | High | High | High (hardware) |'
  prefs: []
  type: TYPE_TB
- en: IV-A Advanced Parallel Computing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Compared to traditional machine learning models, deep neural networks have significantly
    larger parameters spaces, intermediate outputs, and number of gradient values.
    Each of these need to be updated during every training step, requiring powerful
    computation resources. The training and inference processes involve huge amounts
    of matrix multiplications and other operations, though they could be massively
    parallelized. Traditional Central Processing Units (CPUs) have a limited number
    of cores, thus they only support restricted computing parallelism. Employing CPUs
    for deep learning implementations is highly inefficient and will not satisfy the
    low-latency requirements of mobile systems.
  prefs: []
  type: TYPE_NORMAL
- en: Engineers address these issues by exploiting the power of GPUs. GPUs were originally
    designed for high performance video games and graphical rendering, but new techniques
    such as Compute Unified Device Architecture (CUDA) [[115](#bib.bib115)] and the
    CUDA Deep Neural Network library (cuDNN) [[116](#bib.bib116)] developed by NVIDIA
    add flexibility to this type of hardware, allowing users to customize their usage
    for specific purposes. GPUs usually incorporate thousand of cores and perform
    exceptionally in fast matrix multiplications required for training neural networks.
    This provides higher memory bandwidth over CPUs and dramatically speeds up the
    learning process. Recent advanced Tensor Processing Units (TPUs) developed by
    Google even demonstrate 15-30$\times$ higher processing speeds and 30-80$\times$
    higher performance-per-watt, as compared to CPUs and GPUs [[114](#bib.bib114)].
  prefs: []
  type: TYPE_NORMAL
- en: Diffractive neural networks (D²NNs) that completely rely on light communication
    were recently introduced in [[131](#bib.bib131)], to enable zero-consumption and
    zero-delay deep learning. The D²NN is composed of several transmissive layers,
    where points on these layers act as neurons in a NN. The structure is trained
    to optimize the transmission/reflection coefficients, which are equivalent to
    weights in a NN. Once trained, transmissive layers will be materialized via 3D
    printing and they can subsequently be used for inference.
  prefs: []
  type: TYPE_NORMAL
- en: There are also a number of toolboxes that can assist the computational optimization
    of deep learning on the server side. Spring and Shrivastava introduce a hashing
    based technique that substantially reduces computation requirements of deep network
    implementations [[132](#bib.bib132)]. Mirhoseini *et al.* employ a reinforcement
    learning scheme to enable machines to learn the optimal operation placement over
    mixture hardware for deep neural networks. Their solution achieves up to 20% faster
    computation speed than human experts’ designs of such placements [[133](#bib.bib133)].
  prefs: []
  type: TYPE_NORMAL
- en: Importantly, these systems are easy to deploy, therefore mobile network engineers
    do not need to rebuild mobile servers from scratch to support deep learning computing.
    This makes implementing deep learning in mobile systems feasible and accelerates
    the processing of mobile data streams.
  prefs: []
  type: TYPE_NORMAL
- en: IV-B Distributed Machine Learning Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Mobile data is collected from heterogeneous sources (e.g., mobile devices, network
    probes, etc.), and stored in multiple distributed data centers. With the increase
    of data volumes, it is impractical to move all mobile data to a central data center
    to run deep learning applications [[10](#bib.bib10)]. Running network-wide deep
    learning algorithms would therefore require distributed machine learning systems
    that support different interfaces (e.g., operating systems, programming language,
    libraries), so as to enable training and evaluation of deep models across geographically
    distributed servers simultaneously, with high efficiency and low overhead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploying deep learning in a distributed fashion will inevitably introduce
    several system-level problems, which require satisfying the following properties:'
  prefs: []
  type: TYPE_NORMAL
- en: Consistency – Guaranteeing that model parameters and computational processes
    are consistent across all machines. Fault tolerance – Effectively dealing with
    equipment breakdowns in large-scale distributed machine learning systems. Communication
    – Optimizing communication between nodes in a cluster and to avoid congestion.
    Storage – Designing efficient storage mechanisms tailored to different environments
    (e.g., distributed clusters, single machines, GPUs), given I/O and data processing
    diversity. Resource management – Assigning workloads and ensuring that nodes work
    well-coordinated. Programming model – Designing programming interfaces to support
    multiple programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: There exist several distributed machine learning systems that facilitate deep
    learning in mobile networking applications. Kraska *et al.* introduce a distributed
    system named MLbase, which enables to intelligently specify, select, optimize,
    and parallelize ML algorithms [[128](#bib.bib128)]. Their system helps non-experts
    deploy a wide range of ML methods, allowing optimization and running ML applications
    across different servers. Hsieh *et al.* develop a geography-distributed ML system
    called Gaia, which breaks the throughput bottleneck by employing an advanced communication
    mechanism over Wide Area Networks, while preserving the accuracy of ML algorithms [[10](#bib.bib10)].
    Their proposal supports versatile ML interfaces (e.g. TensorFlow, Caffe), without
    requiring significant changes to the ML algorithm itself. This system enables
    deployments of complex deep learning applications over large-scale mobile networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Xing *et al.* develop a large-scale machine learning platform to support big
    data applications [[134](#bib.bib134)]. Their architecture achieves efficient
    model and data parallelization, enabling parameter state synchronization with
    low communication cost. Xiao *et al.* propose a distributed graph engine for ML
    named TUX², to support data layout optimization across machines and reduce cross-machine
    communication [[11](#bib.bib11)]. They demonstrate remarkable performance in terms
    of runtime and convergence on a large dataset with up to 64 billion edges. Chilimbi *et
    al.* build a distributed, efficient, and scalable system named “Adam"³³3Note that
    this is distinct from the Adam optimizer discussed in Sec. [IV-D](#S4.SS4 "IV-D
    Fast Optimization Algorithms ‣ IV Enabling Deep Learning in Mobile Networking
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey") tailored to the
    training of deep models [[129](#bib.bib129)]. Their architecture demonstrates
    impressive performance in terms of throughput, delay, and fault tolerance. Another
    dedicated distributed deep learning system called GeePS is developed by Cui *et
    al.* [[130](#bib.bib130)]. Their framework allows data parallelization on distributed
    GPUs, and demonstrates higher training throughput and faster convergence rate.
    More recently, Moritz *et al.* designed a dedicated distributed framework named
    Ray to underpin reinforcement learning applications [[135](#bib.bib135)]. Their
    framework is supported by an dynamic task execution engine, which incorporates
    the actor and task-parallel abstractions. They further introduce a bottom-up distributed
    scheduling strategy and a dedicated state storage scheme, to improve scalability
    and fault tolerance.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-C Dedicated Deep Learning Libraries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'TABLE VI: Summary and comparison of mainstream deep learning libraries.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Library | Low-Layer Language | Available Interface | Pros | Cons | Mobile
    Supported | Popularity | Upper-Level Library |'
  prefs: []
  type: TYPE_TB
- en: '| TensorFlow | C++ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Python, Java, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; C, C++, Go &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Large user community &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Well-written document &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Complete functionality &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Provides visualization &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; tool (TensorBoard) &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Multiple interfaces support &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Allows distributed training &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; and model serving &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Difficult to debug &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ The package is heavy &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Higher entry barrier &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; for beginners &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Yes | High |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Keras, TensorLayer, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Luminoth &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Theano | Python | Python |'
  prefs: []
  type: TYPE_TB
- en: '&#124; $\bullet$ Flexible &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Good running speed &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Difficult to learn &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Long compilation time &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ No longer maintained &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| No | Low | Keras, Blocks, Lasagne |'
  prefs: []
  type: TYPE_TB
- en: '| Caffe(2) | C++ | Python, Matlab |'
  prefs: []
  type: TYPE_TB
- en: '&#124; $\bullet$ Fast runtime &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Multiple platform &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; s support &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Small user base &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Modest documentation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Yes | Medium | None |'
  prefs: []
  type: TYPE_TB
- en: '| (Py)Torch | Lua, C++ | Lua, Python, C, C++ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; $\bullet$ Easy to build models &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Flexible &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Well documented &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Easy to debug &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Rich pretrained models &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; available &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Declarative data parallelism &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Has limited resource &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Lacks model serving &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Lacks visualization tools &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Yes | High | None |'
  prefs: []
  type: TYPE_TB
- en: '| MXNET | C++ | C++, Python, Matlab, R |'
  prefs: []
  type: TYPE_TB
- en: '&#124; $\bullet$ Lightweight &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Memory-efficient &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Fast training &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Simple model serving &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Highly scalable &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Small user base &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Difficult to learn &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Yes | Low | Gluon |'
  prefs: []
  type: TYPE_TB
- en: 'Building a deep learning model from scratch can prove complicated to engineers,
    as this requires definitions of forwarding behaviors and gradient propagation
    operations at each layer, in addition to CUDA coding for GPU parallelization.
    With the growing popularity of deep learning, several dedicated libraries simplify
    this process. Most of these toolboxes work with multiple programming languages,
    and are built with GPU acceleration and automatic differentiation support. This
    eliminates the need of hand-crafted definition of gradient propagation. We summarize
    these libraries below, and give a comparison among them in Table [VI](#S4.T6 "TABLE
    VI ‣ IV-C Dedicated Deep Learning Libraries ‣ IV Enabling Deep Learning in Mobile
    Networking ‣ Deep Learning in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow⁴⁴4TensorFlow, https://www.tensorflow.org/ is a machine learning library
    developed by Google [[117](#bib.bib117)]. It enables deploying computation graphs
    on CPUs, GPUs, and even mobile devices [[136](#bib.bib136)], allowing ML implementation
    on both single and distributed architectures. This permits fast implementation
    of deep NNs on both cloud and fog services. Although originally designed for ML
    and deep neural networks applications, TensorFlow is also suitable for other data-driven
    research purposes. It provides TensorBoard,⁵⁵5TensorBoard – A visualization tool
    for TensorFlow, https://www.tensorflow.org/guide/summaries_and_tensorboard. a
    sophisticated visualization tool, to help users understand model structures and
    data flows, and perform debugging. Detailed documentation and tutorials for Python
    exist, while other programming languages such as C, Java, and Go are also supported.
    currently it is the most popular deep learning library. Building upon TensorFlow,
    several dedicated deep learning toolboxes were released to provide higher-level
    programming interfaces, including Keras⁶⁶6Keras deep learning library, https://github.com/fchollet/keras,
    Luminoth ⁷⁷7Luminoth deep learning library for computer vision, https://github.com/tryolabs/luminoth
    and TensorLayer [[137](#bib.bib137)].
  prefs: []
  type: TYPE_NORMAL
- en: Theano is a Python library that allows to efficiently define, optimize, and
    evaluate numerical computations involving multi-dimensional data [[118](#bib.bib118)].
    It provides both GPU and CPU modes, which enables users to tailor their programs
    to individual machines. Learning Theano is however difficult and building a NNs
    with it involves substantial compiling time. Though Theano has a large user base
    and a support community, and at some stage was one of the most popular deep learning
    tools, its popularity is decreasing rapidly, as core ideas and attributes are
    absorbed by TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: Caffe(2) is a dedicated deep learning framework developed by Berkeley AI Research
    [[119](#bib.bib119)] and the latest version, Caffe2,⁸⁸8Caffe2, https://caffe2.ai/
    was recently released by Facebook. Inheriting all the advantages of the old version,
    Caffe2 has become a very flexible framework that enables users to build their
    models efficiently. It also allows to train neural networks on multiple GPUs within
    distributed systems, and supports deep learning implementations on mobile operating
    systems, such as iOS and Android. Therefore, it has the potential to play an important
    role in the future mobile edge computing.
  prefs: []
  type: TYPE_NORMAL
- en: (Py)Torch is a scientific computing framework with wide support for machine
    learning models and algorithms [[120](#bib.bib120)]. It was originally developed
    in the Lua language, but developers later released an improved Python version
    [[138](#bib.bib138)]. In essence PyTorch is a lightweight toolbox that can run
    on embedded systems such as smart phones, but lacks comprehensive documentations.
    Since building NNs in PyTorch is straightforward, the popularity of this library
    is growing rapidly. It also offers rich pretrained models and modules that are
    easy to reuse and combine. PyTorch is now officially maintained by Facebook and
    mainly employed for research purposes.
  prefs: []
  type: TYPE_NORMAL
- en: MXNET is a flexible and scalable deep learning library that provides interfaces
    for multiple languages (e.g., C++, Python, Matlab, R, etc.) [[139](#bib.bib139)].
    It supports different levels of machine learning models, from logistic regression
    to GANs. MXNET provides fast numerical computation for both single machine and
    distributed ecosystems. It wraps workflows commonly used in deep learning into
    high-level functions, such that standard neural networks can be easily constructed
    without substantial coding effort. However, learning how to work with this toolbox
    in short time frame is difficult, hence the number of users who prefer this library
    is relatively small. MXNET is the official deep learning framework in Amazon.
  prefs: []
  type: TYPE_NORMAL
- en: Although less popular, there are other excellent deep learning libraries, such
    as CNTK,⁹⁹9MS Cognitive Toolkit, https://www.microsoft.com/en-us/cognitive-toolkit/
    Deeplearning4j,^(10)^(10)10Deeplearning4j, http://deeplearning4j.org Blocks,^(11)^(11)11Blocks,
    A Theano framework for building and training neural networks https://github.com/mila-udem/blocks
    Gluon,^(12)^(12)12Gluon, A deep learning library https://gluon.mxnet.io/ and Lasagne,^(13)^(13)13Lasagne,
    https://github.com/Lasagne which can also be employed in mobile systems. Selecting
    among these varies according to specific applications. For AI beginners who intend
    to employ deep learning for the networking domain, PyTorch is a good candidate,
    as it is easy to build neural networks in this environment and the library is
    well optimized for GPUs. On the other hand, if for people who pursue advanced
    operations and large-scale implementation, Tensorflow might be a better choice,
    as it is well-established, under good maintainance and has standed the test of
    many Google industrial projects.
  prefs: []
  type: TYPE_NORMAL
- en: IV-D Fast Optimization Algorithms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The objective functions to be optimized in deep learning are usually complex,
    as they involve sums of extremely large numbers of data-wise likelihood functions.
    As the depth of the model increases, such functions usually exhibit high non-convexity
    with multiple local minima, critical points, and saddle points. In this case,
    conventional Stochastic Gradient Descent (SGD) algorithms [[140](#bib.bib140)]
    are slow in terms of convergence, which will restrict their applicability to latency
    constrained mobile systems. To overcome this problem and stabilize the optimization
    process, many algorithms evolve the traditional SGD, allowing NN models to be
    trained faster for mobile applications. We summarize the key principles behind
    these optimizers and make a comparison between them in Table [VII](#S4.T7 "TABLE
    VII ‣ IV-D Fast Optimization Algorithms ‣ IV Enabling Deep Learning in Mobile
    Networking ‣ Deep Learning in Mobile and Wireless Networking: A Survey"). We delve
    into the details of their operation next.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE VII: Summary and comparison of different optimization algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Optimization algorithm | Core idea | Pros | Cons |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| SGD [[140](#bib.bib140)] | Computes the gradient of mini-batches iteratively
    and updates the parameters | $\bullet$ Easy to implement |'
  prefs: []
  type: TYPE_TB
- en: '&#124; $\bullet$ Setting a global learning rate required &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Algorithm may get stuck on saddle &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; points or local minima &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Slow in terms of convergence &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Unstable &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Nesterov’s momentum [[125](#bib.bib125)] | Introduces momentum to maintain
    the last gradient direction for the next update |'
  prefs: []
  type: TYPE_TB
- en: '&#124; $\bullet$ Stable &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Faster learning &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Can escape local minima &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| $\bullet$ Setting a learning rate needed |'
  prefs: []
  type: TYPE_TB
- en: '| Adagrad [[126](#bib.bib126)] | Applies different learning rates to different
    parameters |'
  prefs: []
  type: TYPE_TB
- en: '&#124; $\bullet$ Learning rate tailored to each &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; parameter &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Handle sparse gradients well &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Still requires setting a global &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; learning rate &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Gradients sensitive to the regularizer &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Learning rate becomes very slow in &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; the late stages &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Adadelta [[141](#bib.bib141)] | Improves Adagrad, by applying a self-adaptive
    learning rate |'
  prefs: []
  type: TYPE_TB
- en: '&#124; $\bullet$ Does not rely on a global learning rate &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Faster speed of convergence &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Fewer hyper-parameters to adjust &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| $\bullet$ May get stuck in a local minima at late training |'
  prefs: []
  type: TYPE_TB
- en: '| RMSprop [[140](#bib.bib140)] | Employs root mean square as a constraint of
    the learning rate |'
  prefs: []
  type: TYPE_TB
- en: '&#124; $\bullet$ Learning rate tailored to each &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; parameter &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Learning rate do not decrease &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; dramatically at late training &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Works well in RNN training &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Still requires a global learning rate &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Not good at handling sparse gradients &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Adam [[127](#bib.bib127)] | Employs a momentum mechanism to store an exponentially
    decaying average of past gradients |'
  prefs: []
  type: TYPE_TB
- en: '&#124; $\bullet$ Learning rate stailored to each &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; parameter &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Good at handling sparse gradients and &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; non-stationary problems &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Memory-efficient &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Fast convergence &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| $\bullet$ It may turn unstable during training |'
  prefs: []
  type: TYPE_TB
- en: '| Nadam [[142](#bib.bib142)] | Incorporates Nesterov accelerated gradients
    into Adam | $\bullet$ Works well in RNN training | — |'
  prefs: []
  type: TYPE_TB
- en: '| Learn to optimize [[143](#bib.bib143)] | Casts the optimization problem as
    a learning problem using a RNN | $\bullet$ Does not require to design the learning
    by hand | $\bullet$ Require an additional RNN for learning in the optimizer |'
  prefs: []
  type: TYPE_TB
- en: '| Quantized training [[144](#bib.bib144)] | Quantizes the gradients into {-1,
    0, 1} for training |'
  prefs: []
  type: TYPE_TB
- en: '&#124; $\bullet$ Good for distributed training &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Memory-efficient &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| $\bullet$ Loses training accuracy |'
  prefs: []
  type: TYPE_TB
- en: '| Stable gradient descent [[145](#bib.bib145)] | Employs a differential private
    mechanism to compare training and validation gradients, to reuse samples and keep
    them fresh. |'
  prefs: []
  type: TYPE_TB
- en: '&#124; $\bullet$ More stable &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Less overfitting &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\bullet$ Converges faster than SGD &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| $\bullet$ Only validated on convex functions |'
  prefs: []
  type: TYPE_TB
- en: 'Fixed Learning Rate SGD Algorithms: Suskever *et al.* introduce a variant of
    the SGD optimizer with Nesterov’s momentum, which evaluates gradients after the
    current velocity is applied [[125](#bib.bib125)]. Their method demonstrates faster
    convergence rate when optimizing convex functions. Another approach is Adagrad,
    which performs adaptive learning to model parameters according to their update
    frequency. This is suitable for handling sparse data and significantly outperforms
    SGD in terms of robustness [[126](#bib.bib126)]. Adadelta improves the traditional
    Adagrad algorithm, enabling it to converge faster, and does not rely on a global
    learning rate [[141](#bib.bib141)]. RMSprop is a popular SGD based method introduced
    by G. Hinton. RMSprop divides the learning rate by an exponential smoothing the
    average of gradients and does not require one to set the learning rate for each
    training step [[140](#bib.bib140)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'Adaptive Learning Rate SGD Algorithms: Kingma and Ba propose an adaptive learning
    rate optimizer named Adam, which incorporates momentum by the first-order moment
    of the gradient [[127](#bib.bib127)]. This algorithm is fast in terms of convergence,
    highly robust to model structures, and is considered as the first choice if one
    cannot decide what algorithm to use. By incorporating the momentum into Adam,
    Nadam applies stronger constraints to the gradients, which enables faster convergence
    [[142](#bib.bib142)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'Other Optimizers: Andrychowicz *et al.* suggest that the optimization process
    can be even learned dynamically [[143](#bib.bib143)]. They pose the gradient descent
    as a trainable learning problem, which demonstrates good generalization ability
    in neural network training. Wen *et al.* propose a training algorithm tailored
    to distributed systems [[146](#bib.bib146)]. They quantize float gradient values
    to {-1, 0 and +1} in the training processing, which theoretically require 20 times
    less gradient communications between nodes. The authors prove that such gradient
    approximation mechanism allows the objective function to converge to optima with
    probability 1, where in their experiments only a 2% accuracy loss is observed
    on average on GoogleLeNet [[144](#bib.bib144)] training. Zhou *et al.* employ
    a differential private mechanism to compare training and validation gradients,
    to reuse samples and keep them fresh [[145](#bib.bib145)]. This can dramatically
    reduce overfitting during training.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-E Fog Computing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The fog computing paradigm presents a new opportunity to implement deep learning
    in mobile systems. Fog computing refers to a set of techniques that permit deploying
    applications or data storage at the edge of networks [[147](#bib.bib147)], e.g.,
    on individual mobile devices. This reduces the communications overhead, offloads
    data traffic, reduces user-side latency, and lightens the sever-side computational
    burdens [[148](#bib.bib148), [149](#bib.bib149)]. A formal definition of fog computing
    is given in [[150](#bib.bib150)], where this is interpreted as *’a huge number
    of heterogeneous (wireless and sometimes autonomous) ubiquitous and decentralized
    devices [that] communicate and potentially cooperate among them and with the network
    to perform storage and processing tasks without the intervention of third parties.’*
    To be more concrete, it can refer to smart phones, wearables devices and vehicles
    which store, analyze and exchange data, to offload the burden from cloud and perform
    more delay-sensitive tasks [[151](#bib.bib151), [152](#bib.bib152)]. Since fog
    computing involves deployment at the edge, participating devices usually have
    limited computing resource and battery power. Therefore, special hardware and
    software are required for deep learning implementation, as we explain next.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hardware: There exist several efforts that attempt to shift deep learning computing
    from the cloud side to mobile devices [[153](#bib.bib153)]. For example, Gokhale
    *et al.* develop a mobile coprocessor named neural network neXt (nn-X), which
    accelerates the deep neural networks execution in mobile devices, while retaining
    low energy consumption [[121](#bib.bib121)]. Bang *et al.* introduce a low-power
    and programmable deep learning processor to deploy mobile intelligence on edge
    devices [[154](#bib.bib154)]. Their hardware only consumes 288 $\mu$W but achieves
    374 GOPS/W efficiency. A Neurosynaptic Chip called TrueNorth is proposed by IBM
    [[155](#bib.bib155)]. Their solution seeks to support computationally intensive
    applications on embedded battery-powered mobile devices. Qualcomm introduces a
    Snapdragon neural processing engine to enable deep learning computational optimization
    tailored to mobile devices.^(14)^(14)14Qualcomm Helps Make Your Mobile Devices
    Smarter With New Snapdragon Machine Learning Software Development Kit: https://www.qualcomm.com/news/releases/2016/05/02/qualcomm-helps-make-your-mobile-devices-smarter-new-snapdragon-machine
    Their hardware allows developers to execute neural network models on Snapdragon
    820 boards to serve a variety of applications. In close collaboration with Google,
    Movidius^(15)^(15)15Movidius, an Intel company, provides cutting edge solutions
    for deploying deep learning and computer vision algorithms on ultra-low power
    devices. https://www.movidius.com/ develops an embedded neural network computing
    framework that allows user-customized deep learning deployments at the edge of
    mobile networks. Their products can achieve satisfying runtime efficiency, while
    operating with ultra-low power requirements. It further supports difference frameworks,
    such as TensorFlow and Caffe, providing users with flexibility in choosing among
    toolkits. More recently, Huawei officially announced the Kirin 970 as a mobile
    AI computing system on chip.^(16)^(16)16Huawei announces the Kirin 970 – new flagship
    SoC with AI capabilities http://www.androidauthority.com/huawei-announces-kirin-970-797788/
    Their innovative framework incorporates dedicated Neural Processing Units (NPUs),
    which dramatically accelerates neural network computing, enabling classification
    of 2,000 images per second on mobile devices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Software: Beyond these hardware advances, there are also software platforms
    that seek to optimize deep learning on mobile devices (e.g., [[156](#bib.bib156)]).
    We compare and summarize all these platforms in Table [VIII](#S4.T8 "TABLE VIII
    ‣ IV-E Fog Computing ‣ IV Enabling Deep Learning in Mobile Networking ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey").^(17)^(17)17Adapted from https://mp.weixin.qq.com/s/3gTp1kqkiGwdq5olrpOvKw
    In addition to the mobile version of TensorFlow and Caffe, Tencent released a
    lightweight, high-performance neural network inference framework tailored to mobile
    platforms, which relies on CPU computing.^(18)^(18)18ncnn is a high-performance
    neural network inference framework optimized for the mobile platform, https://github.com/Tencent/ncnn
    This toolbox performs better than all known CPU-based open source frameworks in
    terms of inference speed. Apple has developed “Core ML", a private ML framework
    to facilitate mobile deep learning implementation on iOS 11.^(19)^(19)19Core ML:
    Integrate machine learning models into your app, https://developer.apple.com/documentation/coreml
    This lowers the entry barrier for developers wishing to deploy ML models on Apple
    equipment. Yao *et al.* develop a deep learning framework called DeepSense dedicated
    to mobile sensing related data processing, which provides a general machine learning
    toolbox that accommodates a wide range of edge applications. It has moderate energy
    consumption and low latency, thus being amenable to deployment on smartphones.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE VIII: Comparison of mobile deep learning platform.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Platform | Developer | Mobile hardware supported | Speed | Code size | Mobile
    compatibility | Open-sourced |'
  prefs: []
  type: TYPE_TB
- en: '| TensorFlow | Google | CPU | Slow | Medium | Medium | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Caffe | Facebook | CPU | Slow | Large | Medium | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| ncnn | Tencent | CPU | Medium | Small | Good | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| CoreML | Apple | CPU/GPU | Fast | Small | Only iOS 11+ supported | No |'
  prefs: []
  type: TYPE_TB
- en: '| DeepSense | Yao *et al.* | CPU | Medium | Unknown | Medium | No |'
  prefs: []
  type: TYPE_TB
- en: The techniques and toolboxes mentioned above make the deployment of deep learning
    practices in mobile network applications feasible. In what follows, we briefly
    introduce several representative deep learning architectures and discuss their
    applicability to mobile networking problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'V Deep Learning: State-of-the-Art'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Revisiting Fig. [2](#S3.F2 "Figure 2 ‣ III Deep Learning 101 ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey"), machine learning methods can be
    naturally categorized into three classes, namely supervised learning, unsupervised
    learning, and reinforcement learning. Deep learning architectures have achieved
    remarkable performance in all these areas. In this section, we introduce the key
    principles underpinning several deep learning models and discuss their largely
    unexplored potential to solve mobile networking problems. Technical details of
    classical models are provided to readers who seek to obtain a deeper understanding
    of neural networks. The more experienced can continue reading with Sec. [VI](#S6
    "VI Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning in Mobile
    and Wireless Networking: A Survey"). We illustrate and summarize the most salient
    architectures that we present in Fig. [6](#S5.F6 "Figure 6 ‣ V Deep Learning:
    State-of-the-Art ‣ Deep Learning in Mobile and Wireless Networking: A Survey")
    and Table [IX](#S5.T9 "TABLE IX ‣ V Deep Learning: State-of-the-Art ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey"), respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6be9b6ad36fd3831c40790ee830b7f7d.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Structure of an MLP with 2 hidden layers (blue circles).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7af6bfcf9c8e377c6da09f2e923338c9.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Graphical model and training process of an RBM. $\mathbf{v}$ and $\mathbf{h}$
    denote visible and hidden variables, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/65be7a6590137029c7257bce9a3a97b4.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Operating principle of an auto-encoder, which seeks to reconstruct the input
    from the hidden layer.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/47313d214561f3e89bce6877fe365a0e.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) Operating principle of a convolutional layer.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e96cc863aee02bcc1b06b913e6b59f70.png)'
  prefs: []
  type: TYPE_IMG
- en: (e) Recurrent layer – $x_{1:t}$ is the input sequence, indexed by time $t$,
    $s_{t}$ denotes the state vector and $h_{t}$ the hidden outputs.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ce432b78e2d440f0c2b0b54ea56b970f.png)'
  prefs: []
  type: TYPE_IMG
- en: (f) The inner structure of an LSTM layer.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/032cb7f3e4f482c1c87c2cafb5ec68e4.png)'
  prefs: []
  type: TYPE_IMG
- en: (g) Underlying principle of a generative adversarial network (GAN).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/21458e1f18dd6c9a7dcdf722800eabc3.png)'
  prefs: []
  type: TYPE_IMG
- en: (h) Typical deep reinforcement learning architecture. The agent is a neural
    network model that approximates the required function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6: Typical structure and operation principles of MLP, RBM, AE, CNN,
    RNN, LSTM, GAN, and DRL.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE IX: Summary of different deep learning architectures. GAN and DRL are
    shaded, since they are built upon other models.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Learning scenarios | Example architectures | Suitable problems |
    Pros | Cons | Potential applications in mobile networks |'
  prefs: []
  type: TYPE_TB
- en: '| MLP | Supervised, unsupervised, reinforcement | ANN, AdaNet [[157](#bib.bib157)]
    | Modeling data with simple correlations | Naive structure and straightforward
    to build | High complexity, modest performance and slow convergence | Modeling
    multi-attribute mobile data; auxiliary or component of other deep architectures
    |'
  prefs: []
  type: TYPE_TB
- en: '| RBM | Unsupervised | DBN [[158](#bib.bib158)], Convolutional DBN [[159](#bib.bib159)]
    | Extracting robust representations | Can generate virtual samples | Difficult
    to train well | Learning representations from unlabeled mobile data; model weight
    initialization; network flow prediction |'
  prefs: []
  type: TYPE_TB
- en: '| AE | Unsupervised | DAE [[160](#bib.bib160)], VAE [[161](#bib.bib161)] |
    Learning sparse and compact representations | Powerful and effective unsupervised
    learning | Expensive to pretrain with big data | model weight initialization;
    mobile data dimension reduction; mobile anomaly detection |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | Supervised, unsupervised, reinforcement | AlexNet [[86](#bib.bib86)],
    ResNet [[162](#bib.bib162)], 3D-ConvNet [[163](#bib.bib163)], GoogLeNet [[144](#bib.bib144)],
    DenseNet [[164](#bib.bib164)] | Spatial data modeling | Weight sharing; affine
    invariance | High computational cost; challenging to find optimal hyper-parameters;
    requires deep structures for complex tasks | Spatial mobile data analysis |'
  prefs: []
  type: TYPE_TB
- en: '| RNN | Supervised, unsupervised, reinforcement | LSTM [[165](#bib.bib165)],
    Attention based RNN [[166](#bib.bib166)], ConvLSTM [[167](#bib.bib167)] | Sequential
    data modeling | Expertise in capturing temporal dependencies | High model complexity;
    gradient vanishing and exploding problems | Individual traffic flow analysis;
    network- wide (spatio-) temporal data modeling |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Unsupervised | WGAN [[79](#bib.bib79)], LS-GAN [[168](#bib.bib168)],
    BigGAN [[169](#bib.bib169)] | Data generation | Can produce lifelike artifacts
    from a target distribution | Training process is unstable (convergence difficult)
    | Virtual mobile data generation; assisting supervised learning tasks in network
    data analysis |'
  prefs: []
  type: TYPE_TB
- en: '| DRL | Reinforcement | DQN [[19](#bib.bib19)], Deep Policy Gradient [[170](#bib.bib170)],
    A3C [[78](#bib.bib78)], Rainbow [[171](#bib.bib171)], DPPO [[172](#bib.bib172)]
    | Control problems with high- dimensional inputs | Ideal for high-dimensional
    environment modeling | Slow in terms of convergence | Mobile network control and
    management. |'
  prefs: []
  type: TYPE_TB
- en: V-A Multilayer Perceptron
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Multilayer Perceptrons (MLPs) is the initial Artificial Neural Network
    (ANN) design, which consists of at least three layers of operations [[173](#bib.bib173)].
    Units in each layer are densely connected, hence require to configure a substantial
    number of weights. We show an MLP with two hidden layers in Fig. [6(a)](#S5.F6.sf1
    "In Figure 6 ‣ V Deep Learning: State-of-the-Art ‣ Deep Learning in Mobile and
    Wireless Networking: A Survey"). Note that usually only MLPs containing more than
    one hidden layer are regarded as deep learning structures.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given an input vector $\mathbf{x}$, a standard MLP layer performs the following
    operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{y}=\sigma(W\cdot\mathbf{x}+b).$ |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: Here $\mathbf{y}$ denotes the output of the layer, $W$ are the weights and $b$
    the biases. $\sigma(\cdot)$ is an activation function, which aims at improving
    the non-linearity of the model. Commonly used activation function are the sigmoid,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\textbf{sigmoid}(\mathbf{x})=\frac{1}{1+e^{-\mathbf{x}}},$ |  |'
  prefs: []
  type: TYPE_TB
- en: the Rectified Linear Unit (ReLU) [[174](#bib.bib174)],
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\textbf{ReLU}(\mathbf{x})=\max(\mathbf{x},0),$ |  |'
  prefs: []
  type: TYPE_TB
- en: tanh,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\textbf{tanh}(\mathbf{x})=\frac{e^{\mathbf{x}}-e^{\mathbf{-x}}}{e^{\mathbf{x}}+e^{\mathbf{-x}}},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: and the Scaled Exponential Linear Units (SELUs) [[175](#bib.bib175)],
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\textbf{SELU}(\mathbf{x})=\lambda\begin{cases}\mathbf{x},&amp;\text{if}\>\mathbf{x}>0;\\
    \alpha e^{\mathbf{x}}-\alpha,&amp;\text{if}\>\mathbf{x}\leq 0,\end{cases}$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where the parameters $\lambda=1.0507$ and $\alpha=1.6733$ are frequently used.
    In addition, the softmax function is typically employed in the last layer when
    performing classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\textbf{softmax}(\mathbf{x}_{i})=\frac{e^{\mathbf{x}_{i}}}{\sum_{j=0}^{k}e^{\mathbf{x}_{k}}},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $k$ is the number of labels involved in classification. Until recently,
    sigmoid and tanh have been the activation functions most widely used. However,
    they suffer from a known gradient vanishing problem, which hinders gradient propagation
    through layers. Therefore these functions are increasingly more often replaced
    by ReLU or SELU. SELU enables to normalize the output of each layer, which dramatically
    accelerates the training convergence, and can be viewed as a replacement of Batch
    Normalization [[176](#bib.bib176)].
  prefs: []
  type: TYPE_NORMAL
- en: The MLP can be employed for supervised, unsupervised, and even reinforcement
    learning purposes. Although this structure was the most popular neural network
    in the past, its popularity is decreasing because it entails high complexity (fully-connected
    structure), modest performance, and low convergence efficiency. MLPs are mostly
    used as a baseline or integrated into more complex architectures (e.g., the final
    layer in CNNs used for classification). Building an MLP is straightforward, and
    it can be employed, e.g., to assist with feature extraction in models built for
    specific objectives in mobile network applications. The advanced Adaptive learning
    of neural Network (AdaNet) enables MLPs to dynamically train their structures
    to adapt to the input [[157](#bib.bib157)]. This new architecture can be potentially
    explored for analyzing continuously changing mobile environments.
  prefs: []
  type: TYPE_NORMAL
- en: V-B Boltzmann Machine
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Restricted Boltzmann Machines (RBMs) [[90](#bib.bib90)] were originally designed
    for unsupervised learning purposes. They are essentially a type of energy-based
    undirected graphical models, and include a visible layer and a hidden layer, and
    where each unit can only assume binary values (i.e., 0 and 1). The probabilities
    of these values are given by:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle P(h_{j}=1&#124;v)=\frac{1}{1+e^{-\mathbf{W\cdot v+b_{j}}}}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle P(v_{j}=1&#124;h)=\frac{1}{1+e^{-\mathbf{W^{T}\cdot h+a_{j}}}},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $h,v$ are the hidden and visible units respectively, and $\mathbf{W}$
    are weights and $\mathbf{a},\mathbf{b}$ are biases. The visible units are conditional
    independent to the hidden units, and *vice versa*. A typical structure of an RBM
    is shown in Fig. [6(b)](#S5.F6.sf2 "In Figure 6 ‣ V Deep Learning: State-of-the-Art
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey"). In general, input
    data are assigned to visible units $v$. Hidden units $h$ are invisible and they
    fully connect to all $v$ through weights $W$, which is similar to a standard feed
    forward neural network. However, unlike in MLPs where only the input vector can
    affect the hidden units, with RBMs the state of $v$ can affect the state of $h$,
    and *vice versa*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'RBMs can be effectively trained using the contrastive divergence algorithm [[177](#bib.bib177)]
    through multiple steps of Gibbs sampling [[178](#bib.bib178)]. We illustrate the
    structure and the training process of an RBM in Fig. [6(b)](#S5.F6.sf2 "In Figure
    6 ‣ V Deep Learning: State-of-the-Art ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey"). RBM-based models are usually employed to initialize the weights of
    a neural network in more recent applications. The pre-trained model can be subsequently
    fine-tuned for supervised learning purposes using a standard back-propagation
    algorithm. A stack of RBMs is called a Deep Belief Network (DBN) [[158](#bib.bib158)],
    which performs layer-wise training and achieves superior performance as compared
    to MLPs in many applications, including time series forecasting [[179](#bib.bib179)],
    ratio matching [[180](#bib.bib180)], and speech recognition [[181](#bib.bib181)].
    Such structures can be even extended to a convolutional architecture, to learn
    hierarchical spatial representations [[159](#bib.bib159)].'
  prefs: []
  type: TYPE_NORMAL
- en: V-C Auto-Encoders
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Auto-Encoders (AEs) are also designed for unsupervised learning and attempt
    to copy inputs to outputs. The underlying principle of an AE is shown in Fig. [6(c)](#S5.F6.sf3
    "In Figure 6 ‣ V Deep Learning: State-of-the-Art ‣ Deep Learning in Mobile and
    Wireless Networking: A Survey"). AEs are frequently used to learn compact representation
    of data for dimension reduction [[182](#bib.bib182)]. Extended versions can be
    further employed to initialize the weights of a deep architecture, e.g., the Denoising
    Auto-Encoder (DAE) [[160](#bib.bib160)]), and generate virtual examples from a
    target data distribution, e.g. Variational Auto-Encoders (VAEs) [[161](#bib.bib161)].'
  prefs: []
  type: TYPE_NORMAL
- en: A VAE typically comprises two neural networks – an encoder and a decoder. The
    input of the encoder is a data point $\mathbf{x}$ (e.g., images) and its functionality
    is to encode this input into a latent representation space $\mathbf{z}$. Let $f_{\Theta}(\mathbf{z}|\mathbf{x})$
    be an encoder parameterized by $\Theta$ and $\mathbf{z}$ is sampled from a Gaussian
    distribution, the objective of the encoder is to output the mean and variance
    of the Gaussian distribution. Similarly, denoting $g_{\Omega}(\mathbf{x}|\mathbf{z})$
    the decoder parameterized by $\Omega$, this accepts the latent representation
    $\mathbf{z}$ as input, and outputs the parameter of the distribution of $\mathbf{x}$.
    The objective of the VAE is to minimize the reconstruction error of the data and
    the Kullback-Leibler (KL) divergence between $p(\mathbf{z})$ and $f_{\Theta}(\mathbf{z}|\mathbf{x})$.
    Once trained, the VAE can generate new data point samples by *(i)* drawing latent
    variables $z_{i}\sim p(\mathbf{z})$ and *(ii)* drawing a new data point $x_{i}\sim
    p(\mathbf{x}|\mathbf{z})$.
  prefs: []
  type: TYPE_NORMAL
- en: 'AEs can be employed to address network security problems, as several research
    papers confirm their effectiveness in detecting anomalies under different circumstances [[183](#bib.bib183),
    [184](#bib.bib184), [185](#bib.bib185)], which we will further discuss in subsection [VI-H](#S6.SS8
    "VI-H Deep Learning Driven Network Security ‣ VI Deep Learning Driven Mobile and
    Wireless Networks ‣ Deep Learning in Mobile and Wireless Networking: A Survey").
    The structures of RBMs and AEs are based upon MLPs, CNNs or RNNs. Their goals
    are similar, while their learning processes are different. Both can be exploited
    to extract patterns from unlabeled mobile data, which may be subsequently employed
    for various supervised learning tasks, e.g., routing [[186](#bib.bib186)], mobile
    activity recognition [[187](#bib.bib187), [188](#bib.bib188)], periocular verification [[189](#bib.bib189)]
    and base station user number prediction [[190](#bib.bib190)].'
  prefs: []
  type: TYPE_NORMAL
- en: V-D Convolutional Neural Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Instead of employing full connections between layers, Convolutional Neural
    Networks (CNNs or ConvNets) employ a set of locally connected kernels (filters)
    to capture correlations between different data regions. Mathematically, for each
    location $\boldsymbol{p}_{y}$ of the output $\mathbf{y}$, the standard convolution
    performs the following operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{y}(\boldsymbol{p}_{y})=\sum_{\boldsymbol{p}_{G}\in\mathbb{G}}\mathbf{w}(\boldsymbol{p}_{G})\cdot\mathbf{x}(\boldsymbol{p}_{y}+\boldsymbol{p}_{G}),$
    |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: 'where $\boldsymbol{p}_{G}$ denotes all positions in the receptive field $\mathbb{G}$
    of the convolutional filter $W$, effectively representing the receptive range
    of each neuron to inputs in a convolutional layer. Here the weights $W$ are shared
    across different locations of the input map. We illustrate the operation of one
    2D convolutional layer in Fig. [6(d)](#S5.F6.sf4 "In Figure 6 ‣ V Deep Learning:
    State-of-the-Art ‣ Deep Learning in Mobile and Wireless Networking: A Survey").
    Specifically, the inputs of a 2D CNN layer are multiple 2D matrices with different
    channels (e.g. the RGB representation of images). A convolutional layer employs
    multiple filters shared across different locations, to “scan” the inputs and produce
    output maps. In general, if the inputs and outputs have $M$ and $N$ filters respectively,
    the convolutional layer will require $M\times N$ filters to perform the convolution
    operation.'
  prefs: []
  type: TYPE_NORMAL
- en: CNNs improve traditional MLPs by leveraging three important ideas, namely, *(i)*
    sparse interactions, *(ii)* parameter sharing, and *(iii)* equivariant representations [[18](#bib.bib18)].
    This reduces the number of model parameters significantly and maintains the affine
    invariance (i.e., recognition results are robust to the affine transformation
    of objects). Specifically, The sparse interactions imply that the weight kernel
    has smaller size than the input. It performs moving filtering to produce outputs
    (with roughly the same size as the inputs) for the current layer. Parameter sharing
    refers to employing the same kernel to scan the whole input map. This significantly
    reduces the number of parameters needed, which mitigates the risk of over-fitting.
    Equivariant representations indicate that convolution operations are invariant
    in terms of translation, scale, and shape. This is particularly useful for image
    processing, since essential features may show up at different locations in the
    image, with various affine patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Owing to the properties mentioned above, CNNs achieve remarkable performance
    in imaging applications. Krizhevsky *et al.* [[86](#bib.bib86)] exploit a CNN
    to classify images on the ImageNet dataset [[191](#bib.bib191)]. Their method
    reduces the top-5 error by 39.7% and revolutionizes the imaging classification
    field. GoogLeNet [[144](#bib.bib144)] and ResNet [[162](#bib.bib162)] significantly
    increase the depth of CNN structures, and propose inception and residual learning
    techniques to address problems such as over-fitting and gradient vanishing introduced
    by “depth”. Their structure is further improved by the Dense Convolutional Network
    (DenseNet) [[164](#bib.bib164)], which reuses feature maps from each layer, thereby
    achieving significant accuracy improvements over other CNN based models, while
    requiring fewer layers. CNNs have also been extended to video applications. Ji
    *et al.* propose 3D convolutional neural networks for video activity recognition [[163](#bib.bib163)],
    demonstrating superior accuracy as compared to 2D CNN. More recent research focuses
    on learning the shape of convolutional kernels [[192](#bib.bib192), [193](#bib.bib193),
    [194](#bib.bib194)]. These dynamic architectures allow to automatically focus
    on important regions in input maps. Such properties are particularly important
    in analyzing large-scale mobile environments exhibiting clustering behaviors (e.g.,
    surge of mobile traffic associated with a popular event).
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the high similarity between image and spatial mobile data (e.g., mobile
    traffic snapshots, users’ mobility, etc.), CNN-based models have huge potential
    for network-wide mobile data analysis. This is a promising future direction that
    we further discuss in Sec. [VIII](#S8 "VIII Future Research Perspectives ‣ Deep
    Learning in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: V-E Recurrent Neural Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Recurrent Neural Networks (RNNs) are designed for modeling sequential data,
    where sequential correlations exist between samples. At each time step, they produce
    output via recurrent connections between hidden units [[18](#bib.bib18)], as shown
    in Fig. [6(e)](#S5.F6.sf5 "In Figure 6 ‣ V Deep Learning: State-of-the-Art ‣ Deep
    Learning in Mobile and Wireless Networking: A Survey"). Given a sequence of inputs
    $\mathbf{x}=\{x_{1},x_{2},\cdots,x_{T}\}$, a standard RNN performs the following
    operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle s_{t}=\sigma_{s}(W_{x}x_{t}+W_{s}s_{t-1}+b_{s})$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle h_{t}=\sigma_{h}(W_{h}s_{t}+b_{h}),$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $s_{t}$ represents the state of the network at time $t$ and it constructs
    a memory unit for the network. Its values are computed by a function of the input
    $x_{t}$ and previous state $s_{t-1}$. $h_{t}$ is the output of the network at
    time $t$. In natural language processing applications, this usually represents
    a language vector and becomes the input at $t+1$ after being processed by an embedding
    layer. The weights $W_{x},W_{h}$ and biases $b_{s},b_{h}$ are shared across different
    temporal locations. This reduces the model complexity and the degree of over-fitting.
  prefs: []
  type: TYPE_NORMAL
- en: 'The RNN is trained via a Backpropagation Through Time (BPTT) algorithm. However,
    gradient vanishing and exploding problems are frequently reported in traditional
    RNNs, which make them particularly hard to train [[195](#bib.bib195)]. The Long
    Short-Term Memory (LSTM) mitigates these issues by introducing a set of “gates” [[165](#bib.bib165)],
    which has been proven successful in many applications (e.g., speech recognition [[196](#bib.bib196)],
    text categorization [[197](#bib.bib197)], and wearable activity recognition [[112](#bib.bib112)]).
    A standard LSTM performs the following operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle i_{t}=\sigma(W_{xi}X_{t}+W_{hi}H_{t-1}+W_{ci}\odot C_{t-1}+b_{i}),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle f_{t}=\sigma(W_{xf}X_{t}+W_{hf}H_{t-1}+W_{cf}\odot C_{t-1}+b_{f}),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle C_{t}=f_{t}\odot C_{t-1}+i_{t}\odot\tanh(W_{xc}X_{t}+W_{hc}H_{t-1}+b_{c}),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle o_{t}=\sigma(W_{xo}X_{t}+W_{ho}H_{t-1}+W_{co}\odot C_{t}+b_{o}),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle H_{t}=o_{t}\odot\tanh(C_{t}).$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'Here, ‘$\odot$’ denotes the Hadamard product, $C_{t}$ denotes the cell outputs,
    $H_{t}$ are the hidden states, $i_{t}$, $f_{t}$, and $o_{t}$ are input gates,
    forget gates, and output gates, respectively. These gates mitigate the gradient
    issues and significantly improve the RNN. We illustrated the structure of an LSTM
    in Fig. [6(f)](#S5.F6.sf6 "In Figure 6 ‣ V Deep Learning: State-of-the-Art ‣ Deep
    Learning in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Sutskever *et al.* introduce attention mechanisms to RNNs, which achieves outstanding
    accuracy in tokenized predictions [[166](#bib.bib166)]. Shi *et al.* substitute
    the dense matrix multiplication in LSTMs with convolution operations, designing
    a Convolutional Long Short-Term Memory (ConvLSTM) [[167](#bib.bib167)]. Their
    proposal reduces the complexity of traditional LSTM and demonstrates significantly
    lower prediction errors in precipitation nowcasting (i.e., forecasting the volume
    of precipitation).
  prefs: []
  type: TYPE_NORMAL
- en: Mobile networks produce massive sequential data from various sources, such as
    data traffic flows, and the evolution of mobile network subscribers’ trajectories
    and application latencies. Exploring the RNN family is promising to enhance the
    analysis of time series data in mobile networks.
  prefs: []
  type: TYPE_NORMAL
- en: V-F Generative Adversarial Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Algorithm 1 Typical GAN training algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 1:Inputs:2:      Batch size $m$. The number of steps for the discriminator $K$.
    Learning rate $\lambda$ and an optimizer Opt($\cdot$) Noise vector $z\sim p_{g}(z)$.
    Target data set $x\sim p_{data}(x)$.3:Initialise:4:      Generative and discriminative
    models, $\mathcal{G}$and $\mathcal{D}$, parameterized by $\Theta_{\mathcal{G}}$
    and $\Theta_{\mathcal{D}}$.5:while $\Theta_{\mathcal{G}}$ and $\Theta_{\mathcal{D}}$
    have not convergeddo6:     for $k=1$ to $K$ do7:Sample $m$-element noise vector
    $\{z^{(1)},\cdots,z^{(m)}\}$8:from the noise prior $p_{g}(z)$9:Sample $m$ data
    points $\{x^{(1)},\cdots,x^{(m)}\}$ from the10:target data distribution $p_{data}(x)$11:         $g_{\mathcal{D}}\leftarrow\Delta_{\Theta_{\mathcal{D}}}[\frac{1}{m}\sum_{i=1}^{m}\log\mathcal{D}(x^{(i)})+$12:                  $+\frac{1}{m}\sum_{i=1}^{m}\log(1-\mathcal{D}(\mathcal{G}(z^{(i)})))]$.13:         $\Theta_{\mathcal{D}}\leftarrow\Theta_{\mathcal{D}}+\lambda\cdot\text{Opt}(\Theta_{\mathcal{D}},g_{\mathcal{D}})$.14:     end for15:Sample
    $m$-element noise vector $\{z^{(1)},\cdots,z^{(m)}\}$ from16:the noise prior $p_{g}(z)$17:     $g_{\mathcal{G}}\leftarrow\frac{1}{m}\sum_{i=1}^{m}\log(1-\mathcal{D}(\mathcal{G}(z^{(i)})))$18:     $\Theta_{\mathcal{G}}\leftarrow\Theta_{\mathcal{G}}-\lambda\cdot\text{Opt}(\Theta_{\mathcal{G}},g_{\mathcal{G}})$.19:end while
  prefs: []
  type: TYPE_NORMAL
- en: 'The Generative Adversarial Network (GAN) is a framework that trains generative
    models using the following adversarial process. It simultaneously trains two models:
    a generative one $\mathcal{G}$ that seeks to approximate the target data distribution
    from training data, and a discriminative model $\mathcal{D}$ that estimates the
    probability that a sample comes from the real training data rather than the output
    of $\mathcal{G}$ [[91](#bib.bib91)]. Both of $\mathcal{G}$ and $\mathcal{D}$ are
    normally neural networks. The training procedure for $\mathcal{G}$ aims to maximize
    the probability of $\mathcal{D}$ making a mistake. The overall objective is solving
    the following minimax problem [[91](#bib.bib91)]:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\min\limits_{\mathcal{G}}\max\limits_{\mathcal{D}}\mathbb{E}_{x\sim
    P_{r}(x)}[\log\mathcal{D}(x)]+\mathbb{E}_{z\sim P_{n}(z)}[\log(1-\mathcal{D}(\mathcal{G}(z)))].$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'Algorithm [1](#alg1 "Algorithm 1 ‣ V-F Generative Adversarial Network ‣ V Deep
    Learning: State-of-the-Art ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey") shows the typical routine used to train a simple GAN. Both the generators
    and the discriminator are trained iteratively while fixing the other one. Finally
    $\mathcal{G}$ can produce data close to a target distribution (the same with training
    examples), if the model converges. We show the overall structure of a GAN in Fig.
    [6(g)](#S5.F6.sf7 "In Figure 6 ‣ V Deep Learning: State-of-the-Art ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey"). In practice, the generator $\mathcal{G}$
    takes a noise vector $z$ as input, and generates an output $\mathcal{G}(z)$ that
    follows the target distribution. $\mathcal{D}$ will try to discriminate whether
    $\mathcal{G}(z)$ is a real sample or an artifact [[198](#bib.bib198)]. This effectively
    constructs a dynamic game, for which a Nash Equilibrium is reached if both $\mathcal{G}$
    and $\mathcal{D}$ become optimal, and $\mathcal{G}$ can produce lifelike data
    that $\mathcal{D}$ can no longer discriminate, i.e. $\mathcal{D}(\mathcal{G}(z))=0.5,\forall
    z$.'
  prefs: []
  type: TYPE_NORMAL
- en: The training process of traditional GANs is highly sensitive to model structures,
    learning rates, and other hyper-parameters. Researchers are usually required to
    employ numerous ad hoc ‘tricks’ to achieve convergence and improve the fidelity
    of data generated. There exist several solutions for mitigating this problem,
    e.g., Wasserstein Generative Adversarial Network (WGAN) [[79](#bib.bib79)], Loss-Sensitive
    Generative Adversarial Network (LS-GAN) [[168](#bib.bib168)] and BigGAN [[169](#bib.bib169)],
    but research on the theory of GANs remains shallow. Recent work confirms that
    GANs can promote the performance of some supervised tasks (e.g., super-resolution
    [[199](#bib.bib199)], object detection [[200](#bib.bib200)], and face completion
    [[201](#bib.bib201)]) by minimizing the divergence between inferred and real data
    distributions. Exploiting the unsupervised learning abilities of GANs is promising
    in terms of generating synthetic mobile data for simulations, or assisting specific
    supervised tasks in mobile network applications. This becomes more important in
    tasks where appropriate datasets are lacking, given that operators are generally
    reluctant to share their network data.
  prefs: []
  type: TYPE_NORMAL
- en: V-G Deep Reinforcement Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Deep Reinforcement Learning (DRL) refers to a set of methods that approximate
    value functions (deep Q learning) or policy functions (policy gradient method)
    through deep neural networks. An agent (neural network) continuously interacts
    with an environment and receives reward signals as feedback. The agent selects
    an action at each step, which will change the state of the environment. The training
    goal of the neural network is to optimize its parameters, such that it can select
    actions that potentially lead to the best future return. We illustrate this principle
    in Fig. [6(h)](#S5.F6.sf8 "In Figure 6 ‣ V Deep Learning: State-of-the-Art ‣ Deep
    Learning in Mobile and Wireless Networking: A Survey"). DRL is well-suited to
    problems that have a huge number of possible states (i.e., environments are high-dimensional).
    Representative DRL methods include Deep Q-Networks (DQNs) [[19](#bib.bib19)],
    deep policy gradient methods [[170](#bib.bib170)], Asynchronous Advantage Actor-Critic [[78](#bib.bib78)],
    Rainbow [[171](#bib.bib171)] and Distributed Proximal Policy Optimization (DPPO)
    [[172](#bib.bib172)]. These perform remarkably in AI gaming (e.g., Gym^(20)^(20)20Gym
    is a toolkit for developing and comparing reinforcement learning algorithms. It
    supports teaching agents everything from walking to playing games like Pong or
    Pinball. In combination with the NS3 simulator Gym becomes applicable to networking
    research. [[202](#bib.bib202)] https://gym.openai.com/), robotics, and autonomous
    driving [[203](#bib.bib203), [204](#bib.bib204), [205](#bib.bib205), [206](#bib.bib206)],
    and have made inspiring deep learning breakthroughs recently.'
  prefs: []
  type: TYPE_NORMAL
- en: In particular, the DQN [[19](#bib.bib19)] is first proposed by DeepMind to play
    Atari video games. However, traditional DQN requires several important adjustments
    to work well. The A3C [[78](#bib.bib78)] employs an actor-critic mechanism, where
    the actor selects the action given the state of the environment, and the critic
    estimates the value given the state and the action, then delivers feedback to
    the actor. The A3C deploys different actors and critics on different threads of
    a CPU to break the dependency of data. This significantly improves training convergence,
    enabling fast training of DRL agents on CPUs. Rainbow [[171](#bib.bib171)] combines
    different variants of DQNs, and discovers that these are complementary to some
    extent. This insight improved performance in many Atari games. To solve the step
    size problem in policy gradients methods, Schulman *et al.* propose a Distributed
    Proximal Policy Optimization (DPPO) method to constrain the update step of new
    policies, and implement this on multi-threaded CPUs in a distributed manner [[172](#bib.bib172)].
    Based on this method, an agent developed by OpenAI defeated a human expert in
    Dota2 team in a 5v5 match.^(21)^(21)21Dota2 is a popular multiplayer online battle
    arena video game.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many mobile networking problems can be formulated as Markov Decision Processes
    (MDPs), where reinforcement learning can play an important role (e.g., base station
    on-off switching strategies [[207](#bib.bib207)], routing [[208](#bib.bib208)],
    and adaptive tracking control [[209](#bib.bib209)]). Some of these problems nevertheless
    involve high-dimensional inputs, which limits the applicability of traditional
    reinforcement learning algorithms. DRL techniques broaden the ability of traditional
    reinforcement learning algorithms to handle high dimensionality, in scenarios
    previously considered intractable. Employing DRL is thus promising to address
    network management and control problems under complex, changeable, and heterogeneous
    mobile environments. We further discuss this potential in Sec. [VIII](#S8 "VIII
    Future Research Perspectives ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: VI Deep Learning Driven Mobile and Wireless Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning has a wide range of applications in mobile and wireless networks.
    In what follows, we present the most important research contributions across different
    mobile networking areas and compare their design and principles. In particular,
    we first discuss a key prerequisite, that of mobile big data, then organize the
    review of relevant works into nine subsections, focusing on specific domains where
    deep learning has made advances. Specifically,
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep Learning Driven Network-Level Mobile Data Analysis focuses on deep learning
    applications built on mobile big data collected within the network, including
    network prediction, traffic classification, and Call Detail Record (CDR) mining.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep Learning Driven App-Level Mobile Data Analysis shifts the attention towards
    mobile data analytics on edge devices.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep Learning Driven User Mobility Analysis sheds light on the benefits of employing
    deep neural networks to understand the movement patterns of mobile users, either
    at group or individual levels.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep Learning Driven User Localization reviews literature that employ deep neural
    networks to localize users in indoor or outdoor environments, based on different
    signals received from mobile devices or wireless channels.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep Learning Driven Wireless Sensor Networks discusses important work on deep
    learning applications in WSNs from four different perspectives, namely centralized
    vs. decentralized sensing, WSN data analysis, WSN localization and other applications.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '6.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep Learning Driven Network Control investigate the usage of deep reinforcement
    learning and deep imitation learning on network optimization, routing, scheduling,
    resource allocation, and radio control.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '7.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep Learning Driven Network Security presents work that leverages deep learning
    to improve network security, which we cluster by focus as infrastructure, software,
    and privacy related.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '8.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep Learning Driven Signal Processing scrutinizes physical layer aspects that
    benefit from deep learning and reviews relevant work on signal processing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '9.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Emerging Deep Learning Driven Mobile Network Application warps up this section,
    presenting other interesting deep learning applications in mobile networking.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For each domain, we summarize work broadly in tabular form, providing readers
    with a general picture of individual topics. Most important works in each domain
    are discussed in more details in text. Lessons learned are also discussed at the
    end of each subsection. We give a diagramatic view of the topics dealt with by
    the literature reviewed in this section in Fig. [7](#S6.F7 "Figure 7 ‣ VI Deep
    Learning Driven Mobile and Wireless Networks ‣ Deep Learning in Mobile and Wireless
    Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: \smartdiagramset
  prefs: []
  type: TYPE_NORMAL
- en: distance text center bubble=0.15cm, bubble center node size=3cm, bubble node
    size=2cm, distance center/other bubbles=1.2cm, bubble center node font=, bubble
    node font=, bubble center node color=bittersweet, module y sep=13, set color list
    = saffron, mediumaquamarine, salmonpink, limegreen, persianorange, violet, cyan,
    darkgray \smartdiagram[bubble diagram]Deep Learning Driven
  prefs: []
  type: TYPE_NORMAL
- en: Mobile and Wireless
  prefs: []
  type: TYPE_NORMAL
- en: Networks, Network-Level Mobile
  prefs: []
  type: TYPE_NORMAL
- en: Data Analysis
  prefs: []
  type: TYPE_NORMAL
- en: '[[210](#bib.bib210), [211](#bib.bib211), [212](#bib.bib212), [213](#bib.bib213),
    [214](#bib.bib214), [215](#bib.bib215), [216](#bib.bib216), [217](#bib.bib217),
    [218](#bib.bib218), [77](#bib.bib77), [219](#bib.bib219), [220](#bib.bib220),
    [221](#bib.bib221), [222](#bib.bib222), [223](#bib.bib223), [224](#bib.bib224),
    [225](#bib.bib225), [226](#bib.bib226), [227](#bib.bib227), [228](#bib.bib228),
    [229](#bib.bib229), [102](#bib.bib102), [230](#bib.bib230), [231](#bib.bib231),
    [232](#bib.bib232), [233](#bib.bib233), [234](#bib.bib234)], App-Level Mobile
    Data'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs: []
  type: TYPE_NORMAL
- en: '[[235](#bib.bib235), [236](#bib.bib236), [237](#bib.bib237), [238](#bib.bib238),
    [239](#bib.bib239), [240](#bib.bib240), [241](#bib.bib241), [242](#bib.bib242),
    [243](#bib.bib243), [244](#bib.bib244), [245](#bib.bib245), [246](#bib.bib246),
    [247](#bib.bib247), [248](#bib.bib248), [249](#bib.bib249), [250](#bib.bib250),
    [251](#bib.bib251), [252](#bib.bib252), [253](#bib.bib253), [254](#bib.bib254),
    [255](#bib.bib255), [256](#bib.bib256), [112](#bib.bib112), [257](#bib.bib257),
    [258](#bib.bib258), [259](#bib.bib259), [260](#bib.bib260), [261](#bib.bib261),
    [262](#bib.bib262), [263](#bib.bib263), [264](#bib.bib264), [265](#bib.bib265),
    [266](#bib.bib266), [17](#bib.bib17)]'
  prefs: []
  type: TYPE_NORMAL
- en: '[[267](#bib.bib267), [268](#bib.bib268), [269](#bib.bib269), [270](#bib.bib270),
    [271](#bib.bib271), [187](#bib.bib187), [272](#bib.bib272), [273](#bib.bib273),
    [274](#bib.bib274), [275](#bib.bib275), [276](#bib.bib276), [277](#bib.bib277),
    [278](#bib.bib278), [279](#bib.bib279), [280](#bib.bib280), [281](#bib.bib281),
    [97](#bib.bib97), [282](#bib.bib282), [283](#bib.bib283), [284](#bib.bib284),
    [285](#bib.bib285), [286](#bib.bib286), [287](#bib.bib287), [288](#bib.bib288),
    [289](#bib.bib289), [73](#bib.bib73), [290](#bib.bib290), [291](#bib.bib291)],
    Mobility Analysis'
  prefs: []
  type: TYPE_NORMAL
- en: '[[292](#bib.bib292), [293](#bib.bib293), [294](#bib.bib294), [295](#bib.bib295),
    [227](#bib.bib227), [296](#bib.bib296), [297](#bib.bib297), [298](#bib.bib298),
    [299](#bib.bib299), [300](#bib.bib300), [301](#bib.bib301), [302](#bib.bib302),
    [303](#bib.bib303), [304](#bib.bib304), [305](#bib.bib305), [306](#bib.bib306),
    [307](#bib.bib307), [308](#bib.bib308), [309](#bib.bib309), [310](#bib.bib310)],
    User Localization'
  prefs: []
  type: TYPE_NORMAL
- en: '[[311](#bib.bib311), [272](#bib.bib272), [273](#bib.bib273), [312](#bib.bib312),
    [313](#bib.bib313), [314](#bib.bib314), [315](#bib.bib315)]'
  prefs: []
  type: TYPE_NORMAL
- en: '[[316](#bib.bib316), [317](#bib.bib317), [318](#bib.bib318), [319](#bib.bib319),
    [320](#bib.bib320), [321](#bib.bib321), [322](#bib.bib322), [111](#bib.bib111),
    [323](#bib.bib323), [324](#bib.bib324), [325](#bib.bib325), [326](#bib.bib326),
    [327](#bib.bib327), [328](#bib.bib328), [329](#bib.bib329), [330](#bib.bib330),
    [331](#bib.bib331), [332](#bib.bib332), [333](#bib.bib333), [334](#bib.bib334)],
    Wireless Sensor Networks'
  prefs: []
  type: TYPE_NORMAL
- en: '[[335](#bib.bib335), [336](#bib.bib336), [337](#bib.bib337), [338](#bib.bib338),
    [339](#bib.bib339), [340](#bib.bib340), [341](#bib.bib341), [342](#bib.bib342),
    [343](#bib.bib343), [344](#bib.bib344), [345](#bib.bib345), [346](#bib.bib346),
    [347](#bib.bib347), [348](#bib.bib348), [349](#bib.bib349), [350](#bib.bib350),
    [351](#bib.bib351), [352](#bib.bib352), [353](#bib.bib353), [346](#bib.bib346),
    [354](#bib.bib354), [355](#bib.bib355), [356](#bib.bib356)], Network Control'
  prefs: []
  type: TYPE_NORMAL
- en: '[[357](#bib.bib357), [358](#bib.bib358), [359](#bib.bib359), [360](#bib.bib360),
    [361](#bib.bib361), [362](#bib.bib362), [363](#bib.bib363), [364](#bib.bib364),
    [365](#bib.bib365), [293](#bib.bib293), [186](#bib.bib186), [366](#bib.bib366),
    [367](#bib.bib367), [368](#bib.bib368)]'
  prefs: []
  type: TYPE_NORMAL
- en: '[[369](#bib.bib369), [368](#bib.bib368), [370](#bib.bib370), [371](#bib.bib371),
    [372](#bib.bib372), [373](#bib.bib373), [374](#bib.bib374), [375](#bib.bib375),
    [376](#bib.bib376), [377](#bib.bib377), [378](#bib.bib378), [379](#bib.bib379),
    [380](#bib.bib380), [381](#bib.bib381), [382](#bib.bib382), [383](#bib.bib383),
    [384](#bib.bib384), [385](#bib.bib385), [386](#bib.bib386), [387](#bib.bib387),
    [388](#bib.bib388), [389](#bib.bib389), [390](#bib.bib390), [391](#bib.bib391),
    [392](#bib.bib392), [393](#bib.bib393), [234](#bib.bib234), [394](#bib.bib394),
    [395](#bib.bib395), [396](#bib.bib396), [397](#bib.bib397), [398](#bib.bib398),
    [399](#bib.bib399), [400](#bib.bib400), [401](#bib.bib401), [402](#bib.bib402),
    [403](#bib.bib403)], Network Security'
  prefs: []
  type: TYPE_NORMAL
- en: '[[404](#bib.bib404), [185](#bib.bib185), [405](#bib.bib405), [406](#bib.bib406),
    [407](#bib.bib407), [408](#bib.bib408), [409](#bib.bib409), [410](#bib.bib410),
    [411](#bib.bib411), [345](#bib.bib345), [412](#bib.bib412), [413](#bib.bib413),
    [414](#bib.bib414), [415](#bib.bib415), [416](#bib.bib416), [417](#bib.bib417),
    [418](#bib.bib418), [419](#bib.bib419)]'
  prefs: []
  type: TYPE_NORMAL
- en: '[[420](#bib.bib420), [421](#bib.bib421), [223](#bib.bib223), [422](#bib.bib422),
    [423](#bib.bib423), [424](#bib.bib424), [425](#bib.bib425), [426](#bib.bib426),
    [427](#bib.bib427), [428](#bib.bib428), [429](#bib.bib429), [430](#bib.bib430),
    [431](#bib.bib431), [432](#bib.bib432), [429](#bib.bib429), [433](#bib.bib433),
    [434](#bib.bib434), [435](#bib.bib435), [436](#bib.bib436)], Signal Processing'
  prefs: []
  type: TYPE_NORMAL
- en: '[[378](#bib.bib378), [380](#bib.bib380), [437](#bib.bib437), [438](#bib.bib438),
    [439](#bib.bib439), [440](#bib.bib440), [441](#bib.bib441), [442](#bib.bib442),
    [443](#bib.bib443), [444](#bib.bib444)]'
  prefs: []
  type: TYPE_NORMAL
- en: '[[322](#bib.bib322), [445](#bib.bib445), [446](#bib.bib446), [447](#bib.bib447),
    [448](#bib.bib448), [449](#bib.bib449), [450](#bib.bib450), [451](#bib.bib451),
    [452](#bib.bib452), [453](#bib.bib453), [454](#bib.bib454), [455](#bib.bib455),
    [456](#bib.bib456), [457](#bib.bib457), [458](#bib.bib458)], Emerging Applications'
  prefs: []
  type: TYPE_NORMAL
- en: '[[459](#bib.bib459), [460](#bib.bib460), [461](#bib.bib461), [462](#bib.bib462),
    [463](#bib.bib463)]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7: Classification of the literature reviewed in Sec. [VI](#S6 "VI Deep
    Learning Driven Mobile and Wireless Networks ‣ Deep Learning in Mobile and Wireless
    Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: VI-A Mobile Big Data as a Prerequisite
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ae4e009676bb3469e6f61736b5209edc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Typical pipeline of an app-level mobile data processing system.'
  prefs: []
  type: TYPE_NORMAL
- en: The development of mobile technology (e.g. smartphones, augmented reality, etc.)
    are forcing mobile operators to evolve mobile network infrastructures. As a consequence,
    both the cloud and edge side of mobile networks are becoming increasingly sophisticated
    to cater for users who produce and consume huge amounts of mobile data daily.
    These data can be either generated by the sensors of mobile devices that record
    individual user behaviors, or from the mobile network infrastructure, which reflects
    dynamics in urban environments. Appropriately mining these data can benefit multidisciplinary
    research fields and the industry in areas such mobile network management, social
    analysis, public transportation, personal services provision, and so on [[36](#bib.bib36)].
    Network operators, however, could become overwhelmed when managing and analyzing
    massive amounts of heterogeneous mobile data [[464](#bib.bib464)]. Deep learning
    is probably the most powerful methodology that can overcoming this burden. We
    begin therefore by introducing characteristics of mobile big data, then present
    a holistic review of deep learning driven mobile data analysis research.
  prefs: []
  type: TYPE_NORMAL
- en: 'Yazti and Krishnaswamy propose to categorize mobile data into two groups, namely
    *network-level* data and *app-level* data [[465](#bib.bib465)]. The key difference
    between them is that in the former data is usually collected by the edge mobile
    devices, while in the latter obtained throughout network infrastructure. We summarize
    these two types of data and their information comprised in Table [X](#S6.T10 "TABLE
    X ‣ VI-A Mobile Big Data as a Prerequisite ‣ VI Deep Learning Driven Mobile and
    Wireless Networks ‣ Deep Learning in Mobile and Wireless Networking: A Survey").
    Before delving into mobile data analytics, we illustrate the typical data collection
    process in Figure [9](#S6.F9 "Figure 9 ‣ VI-A Mobile Big Data as a Prerequisite
    ‣ VI Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning in Mobile
    and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e29b7b35b606900c78f379b96cfddd04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Illustration of the mobile data collection process in cellular, WiFi
    and wireless sensor networks. BSC: Base Station Controller; RNC: Radio Network
    Controller.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE X: The taxonomy of mobile big data.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Mobile data | Source | Information |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Network-level data | Infrastructure | Infrastructure locations, capability,
    equipment holders, etc |'
  prefs: []
  type: TYPE_TB
- en: '| Performance indicators | Data traffic, end-to-end delay, QoE, jitter, etc.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Call detail records (CDR) | Session start and end times, type, sender and
    receiver, etc. |'
  prefs: []
  type: TYPE_TB
- en: '| Radio information | Signal power, frequency, spectrum, modulation etc. |'
  prefs: []
  type: TYPE_TB
- en: '| App-level data | Device | Device type, usage, Media Access Control (MAC)
    address, etc. |'
  prefs: []
  type: TYPE_TB
- en: '| Profile | User settings, personal information, etc |'
  prefs: []
  type: TYPE_TB
- en: '| Sensors | Mobility, temperature, magnetic field, movement, etc |'
  prefs: []
  type: TYPE_TB
- en: '| Application | Picture, video, voice, health condition, preference, etc. |'
  prefs: []
  type: TYPE_TB
- en: '| System log | Software and hardware failure logs, etc. |'
  prefs: []
  type: TYPE_TB
- en: '*Network-level* mobile data generated by the networking infrastructure not
    only deliver a global view of mobile network performance (e.g. throughput, end-to-end
    delay, jitter, etc.), but also log individual session times, communication types,
    sender and receiver information, through Call Detail Records (CDRs). Network-level
    data usually exhibit significant spatio-temporal variations resulting from users’
    behaviors [[466](#bib.bib466)], which can be utilized for network diagnosis and
    management, user mobility analysis and public transportation planning [[216](#bib.bib216)].
    Some network-level data (e.g. mobile traffic snapshots) can be viewed as pictures
    taken by ‘panoramic cameras’, which provide a city-scale sensing system for urban
    sensing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, *App-level* data is directly recorded by sensors or mobile
    applications installed in various mobile devices. These data are frequently collected
    through crowd-sourcing schemes from heterogeneous sources, such as Global Positioning
    Systems (GPS), mobile cameras and video recorders, and portable medical monitors.
    Mobile devices act as sensor hubs, which are responsible for data gathering and
    preprocessing, and subsequently distributing such data to specific locations,
    as required [[36](#bib.bib36)]. We show a typical app-level data processing system
    in Fig. [8](#S6.F8 "Figure 8 ‣ VI-A Mobile Big Data as a Prerequisite ‣ VI Deep
    Learning Driven Mobile and Wireless Networks ‣ Deep Learning in Mobile and Wireless
    Networking: A Survey"). App-level mobile data is generated and collected by a
    Software Development Kit (SDK) installed on mobile devices. Such data is subsequently
    processed by real-time collection and computing services (e.g., Storm,^(22)^(22)22Storm
    is a free and open-source distributed real-time computation system, http://storm.apache.org/
    Kafka,^(23)^(23)23Kafka^® is used for building real-time data pipelines and streaming
    apps, https://kafka.apache.org/ HBase,^(24)^(24)24Apache HBase™ is the Hadoop
    database, a distributed, scalable, big data store, https://hbase.apache.org/ Redis,^(25)^(25)25Redis
    is an open source, in-memory data structure store, used as a database, cache and
    message broker, https://redis.io/ etc.) as required. Further offline storage and
    computing with mobile data can be performed with various tools, such as Hadoop
    Distribute File System (HDFS),^(26)^(26)26The Hadoop Distributed File System (HDFS)
    is a distributed file system designed to run on commodity hardware, https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html
    Python, Mahout,^(27)^(27)27Apache Mahout™ is a distributed linear algebra framework,
    https://mahout.apache.org/ Pig,^(28)^(28)28Apache Pig is a high-level platform
    for creating programs that run on Apache Hadoop, https://pig.apache.org/ or Oozie.^(29)^(29)29Oozie
    is a workflow scheduler system to manage Apache Hadoop jobs, http://oozie.apache.org/
    The raw data and analysis results will be further transferred to databases (e.g.,
    MySQL^(30)^(30)30MySQL is the open source database, https://www.oracle.com/technetwork/database/mysql/index.html)
    Business Intelligence – BI (e.g. Online Analytical Processing – OLAP), and data
    warehousing (e.g., Hive^(31)^(31)31The Apache Hive™ is a data warehouse software,
    https://hive.apache.org/). Among these, the algorithms container is the core of
    the entire system as it connects to front-end access and fog computing, real-time
    collection and computing, and offline computing and analysis modules, while it
    links directly to mobile applications, such as mobile healthcare, pattern recognition,
    and advertising platforms. Deep learning logic can be placed within the algorithms
    container.'
  prefs: []
  type: TYPE_NORMAL
- en: App-level data may directly or indirectly reflect users’ behaviors, such as
    mobility, preferences, and social links [[61](#bib.bib61)]. Analyzing app-level
    data from individuals can help reconstructing one’s personality and preferences,
    which can be used in recommender systems and users targeted advertising. Some
    of these data comprise explicit information about individuals’ identities. Inappropriate
    sharing and use can raise significant privacy issues. Therefore, extracting useful
    patterns from multi-modal sensing devices without compromising user’s privacy
    remains a challenging endeavor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Compared to traditional data analysis techniques, deep learning embraces several
    unique features to address the aforementioned challenges [[17](#bib.bib17)]. Namely:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep learning achieves remarkable performance in various data analysis tasks,
    on both structured and unstructured data. Some types of mobile data can be represented
    as image-like (e.g. [[216](#bib.bib216)]) or sequential data [[224](#bib.bib224)].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep learning performs remarkably well in feature extraction from raw data.
    This saves tremendous effort of hand-crafted feature engineering, which allows
    spending more time on model design and less on sorting through the data itself.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deep learning offers excellent tools (e.g. RBM, AE, GAN) for handing unlabeled
    data, which is common in mobile network logs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Multi-modal deep learning allows to learn features over multiple modalities
    [[467](#bib.bib467)], which makes it powerful in modeling with data collected
    from heterogeneous sensors and data sources.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: These advantages make deep learning as a powerful tool for mobile data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE XI: A summary of work on network-level mobile data analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Domain | Reference | Applications | Model | Optimizer | Key contribution
    |'
  prefs: []
  type: TYPE_TB
- en: '| Network prediction | Pierucci and Micheli [[210](#bib.bib210)] | QoE prediction
    | MLP | Unknown | Uses NNs to correlate Quality of Service parameters and QoE
    estimations. |'
  prefs: []
  type: TYPE_TB
- en: '| Gwon and Kung [[211](#bib.bib211)] | Inferring Wi-Fi flow patterns | Sparse
    coding + Max pooling | SGD | Semi-supervised learning. |'
  prefs: []
  type: TYPE_TB
- en: '| Nie *et al.* [[212](#bib.bib212)] | Wireless mesh network traffic prediction
    | DBN + Gaussian models | SGD | Considers both long-term dependency and short-term
    fluctuations. |'
  prefs: []
  type: TYPE_TB
- en: '| Moyo and Sibanda [[213](#bib.bib213)] | TCP/IP traffic prediction | MLP |
    Unknown | Investigates the impact of learning in traffic forecasting. |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[214](#bib.bib214)] | Mobile traffic forecasting | AE + LSTM
    | SGD | Uses an AE to model spatial correlations and an LSTM to model temporal
    correlation |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang and Patras [[215](#bib.bib215)] | Long-term mobile traffic forecasting
    | ConvLSTM + 3D-CNN | Adam | Combines 3D-CNNs and ConvLSTMs to perform long-term
    forecasting |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang *et al.* [[216](#bib.bib216)] | Mobile traffic super-resolution | CNN
    + GAN | Adam | Introduces the MTSR concept and applies image processing techniques
    for mobile traffic analysis |'
  prefs: []
  type: TYPE_TB
- en: '| Huang *et al.* [[217](#bib.bib217)] | Mobile traffic forecasting | LSTM +
    3D-CNN | Unknown | Combines CNNs and RNNs to extract geographical and temporal
    features from mobile traffic. |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang *et al.* [[218](#bib.bib218)] | Cellular traffic prediction | Densely
    connected CNN | Adam | Uses separate CNNs to model closeness and periods in temporal
    dependency. |'
  prefs: []
  type: TYPE_TB
- en: '| Chen *et al.* [[77](#bib.bib77)] | Cloud RAN optimization | Multivariate
    LSTM | Unknown | Uses mobile traffic forecasting to aid cloud radio access network
    optimization |'
  prefs: []
  type: TYPE_TB
- en: '| Navabi *et al.* [[219](#bib.bib219)] | Wireless WiFi channel feature prediction
    | MLP | SGD | Infers non-observable channel information from observable features.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Feng *et al.* [[233](#bib.bib233)] | Mobile cellular traffic prediction |
    LSTM | Adam | Extracts spatial and temporal dependencies using separate modules.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Alawe *et al.* [[468](#bib.bib468)] | Mobile traffic load forecasting | MLP,
    LSTM | Unknown | Employs traffic forecasting to improve 5G network scalability.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[102](#bib.bib102)] | Cellular traffic prediction | Graph
    neural networks | Pineda algorithm | Represents spatio-temporal dependency via
    graphs and first work employing Graph neural networks for traffic forecasting.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Fang *et al.* [[230](#bib.bib230)] | Mobile demand forecasting | Graph
    CNN, LSTM, Spatio-temporal graph ConvLSTM | Unknown | Modelling the spatial correlations
    between cells using a dependency graph. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Luo *et al.* [[231](#bib.bib231)] | Channel state information prediction
    | CNN and LSTM | RMSprop | Employing a two-stage offline-online training scheme
    to improve the stability of framework. |'
  prefs: []
  type: TYPE_TB
- en: '| Traffic classification | Wang [[220](#bib.bib220)] | Traffic classification
    | MLP, stacked AE | Unknown | Performs feature learning, protocol identification
    and anomalous protocol detection simultaneously. |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[221](#bib.bib221)] | Encrypted traffic classification | CNN
    | SGD | Employs an end-to-end deep learning approach to perform encrypted traffic
    classification. |'
  prefs: []
  type: TYPE_TB
- en: '| Lotfollahi *et al.* [[222](#bib.bib222)] | Encrypted traffic classification
    | CNN | Adam | Can perform both traffic characterization and application identification.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[223](#bib.bib223)] | Malware traffic classification | CNN
    | SGD | First work to use representation learning for malware classification from
    raw traffic. |'
  prefs: []
  type: TYPE_TB
- en: '| Aceto *et al.* [[469](#bib.bib469)] | Mobile encrypted traffic classification
    | MLP, CNN, LSTM | SGD, Adam | Comprehensive evaluations of different NN architectures
    and excellent performance. |'
  prefs: []
  type: TYPE_TB
- en: '| Li *et al.* [[232](#bib.bib232)] | Network traffic classification | Bayesian
    auto-encoder | SGD | Applying Bayesian probability theory to obtain the a posteriori
    distribution of model parameters. |'
  prefs: []
  type: TYPE_TB
- en: '| CDR mining | Liang *et al.* [[224](#bib.bib224)] | Metro density prediction
    | RNN | SGD | Employs geo-spatial data processing, a weight-sharing RNN and parallel
    stream analytic programming. |'
  prefs: []
  type: TYPE_TB
- en: '| Felbo *et al.* [[225](#bib.bib225)] | Demographics prediction | CNN | Adam
    | Exploits the temporal correlation inherent to mobile phone metadata. |'
  prefs: []
  type: TYPE_TB
- en: '| Chen *et al.* [[226](#bib.bib226)] | Tourists’ next visit location prediction
    | MLP, RNN | Scaled conjugate gradient descent | LSTM that performs significantly
    better than other ML approaches. |'
  prefs: []
  type: TYPE_TB
- en: '| Lin *et al.* [[227](#bib.bib227)] | Human activity chains generation | Input-Output
    HMM + LSTM | Adam | First work that uses an RNN to generate human activity chains.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Others | Xu *et al.* [[228](#bib.bib228)] | Wi-Fi hotpot classification |
    CNN | Unknown | Combining deep learning with frequency analysis. |'
  prefs: []
  type: TYPE_TB
- en: '| Meng *et al.* [[229](#bib.bib229)] | QoE-driven big data analysis | CNN |
    SGD | Investigates trade-off between accuracy of high-dimensional big data analysis
    and model training speed. |'
  prefs: []
  type: TYPE_TB
- en: VI-B Deep Learning Driven Network-level Mobile Data Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Network-level mobile data refers broadly to logs recorded by Internet service
    providers, including infrastructure metadata, network performance indicators and
    call detail records (CDRs) (see Table. [XI](#S6.T11 "TABLE XI ‣ VI-A Mobile Big
    Data as a Prerequisite ‣ VI Deep Learning Driven Mobile and Wireless Networks
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey")). The recent remarkable
    success of deep learning ignites global interests in exploiting this methodology
    for mobile network-level data analysis, so as to optimize mobile networks configurations,
    thereby improving end-uses’ QoE. These work can be categorized into four types:
    network state prediction, network traffic classification, CDR mining and radio
    analysis. In what follows, we review work in these directions, which we first
    summarize and compare in Table [XI](#S6.T11 "TABLE XI ‣ VI-A Mobile Big Data as
    a Prerequisite ‣ VI Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Network State Prediction refers to inferring mobile network traffic or performance
    indicators, given historical measurements or related data. Pierucci and Micheli
    investigate the relationship between key objective metrics and QoE [[210](#bib.bib210)].
    They employ MLPs to predict users’ QoE in mobile communications, based on average
    user throughput, number of active users in a cells, average data volume per user,
    and channel quality indicators, demonstrating high prediction accuracy. Network
    traffic forecasting is another field where deep learning is gaining importance.
    By leveraging sparse coding and max-pooling, Gwon and Kung develop a semi-supervised
    deep learning model to classify received frame/packet patterns and infer the original
    properties of flows in a WiFi network [[211](#bib.bib211)]. Their proposal demonstrates
    superior performance over traditional ML techniques. Nie *et al.* investigate
    the traffic demand patterns in wireless mesh network [[212](#bib.bib212)]. They
    design a DBN along with Gaussian models to precisely estimate traffic distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the above, several researchers employ deep learning to forecast
    mobile traffic at city scale, by considering spatio-temporal correlations of geographic
    mobile traffic measurements. We illustrate the underlying principle in Fig. [10](#S6.F10
    "Figure 10 ‣ VI-B Deep Learning Driven Network-level Mobile Data Analysis ‣ VI
    Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning in Mobile and
    Wireless Networking: A Survey"). In [[214](#bib.bib214)], Wang *et al.* propose
    to use an AE-based architecture and LSTMs to model spatial and temporal correlations
    of mobile traffic distribution, respectively. In particular, the authors use a
    global and multiple local stacked AEs for spatial feature extraction, dimension
    reduction and training parallelism. Compressed representations extracted are subsequently
    processed by LSTMs, to perform final forecasting. Experiments with a real-world
    dataset demonstrate superior performance over SVM and the Autoregressive Integrated
    Moving Average (ARIMA) model. The work in [[215](#bib.bib215)] extends mobile
    traffic forecasting to long time frames. The authors combine ConvLSTMs and 3D
    CNNs to construct spatio-temporal neural networks that capture the complex spatio-temporal
    features at city scale. They further introduce a fine-tuning scheme and lightweight
    approach to blend predictions with historical means, which significantly extends
    the length of reliable prediction steps. Deep learning was also employed in [[217](#bib.bib217),
    [468](#bib.bib468), [233](#bib.bib233)] and [[77](#bib.bib77)], where the authors
    employ CNNs and LSTMs to perform mobile traffic forecasting. By effectively extracting
    spatio-temporal features, their proposals gain significantly higher accuracy than
    traditional approaches, such as ARIMA. Wang *et al.* represent spatio-temporal
    dependencies in mobile traffic using graphs, and learn such dependencies using
    Graph Neural Networks [[102](#bib.bib102)]. Beyond the accurate inference achieved
    in their study, this work also demonstrates potential for precise social events
    inference.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a1b7d96f4e3d1e35ed0781854c700f12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: The underlying principle of city-scale mobile traffic forecasting.
    The deep learning predictor takes as input a sequence of mobile traffic measurements
    in a region (snapshots $t-s$ to $t$), and forecasts how much mobile traffic will
    be consumed in the same areas in the future $t+1$ to $t+n$ instances.'
  prefs: []
  type: TYPE_NORMAL
- en: 'More recently, Zhang *et al.* propose an original Mobile Traffic Super-Resolution
    (MTSR) technique to infer network-wide fine-grained mobile traffic consumption
    given coarse-grained counterparts obtained by probing, thereby reducing traffic
    measurement overheads [[216](#bib.bib216)]. We illustrate the principle of MTSR
    in Fig. [11](#S6.F11 "Figure 11 ‣ VI-B Deep Learning Driven Network-level Mobile
    Data Analysis ‣ VI Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey"). Inspired by image super-resolution
    techniques, they design a dedicated CNN with multiple skip connections between
    layers, named deep zipper network, along with a Generative Adversarial Network
    (GAN) to perform precise MTSR and improve the fidelity of inferred traffic snapshots.
    Experiments with a real-world dataset show that this architecture can improve
    the granularity of mobile traffic measurements over a city by up to 100$\times$,
    while significantly outperforming other interpolation techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8590bd987696a35e1cebd5525db03f20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Illustration of the image super-resolution (SR) principle (above)
    and the mobile traffic super-resolution (MTSR) technique (below). Figure adapted
    from [[216](#bib.bib216)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'Traffic Classification is aimed at identifying specific applications or protocols
    among the traffic in networks. Wang recognizes the powerful feature learning ability
    of deep neural networks and uses a deep AE to identify protocols in a TCP flow
    dataset, achieving excellent precision and recall rates [[220](#bib.bib220)].
    Work in [[221](#bib.bib221)] proposes to use a 1D CNN for encrypted traffic classification.
    The authors suggest that this structure works well for modeling sequential data
    and has lower complexity, thus being promising in addressing the traffic classification
    problem. Similarly, Lotfollahi *et al.* present Deep Packet, which is based on
    a CNN, for encrypted traffic classification [[222](#bib.bib222)]. Their framework
    reduces the amount of hand-crafted feature engineering and achieves great accuracy.
    An improved stacked AE is employed in [[232](#bib.bib232)], where Li *et al.*
    incorporate Bayesian methods into AEs to enhance the inference accuracy in network
    traffic classification. More recently, Aceto *et al.* employ MLPs, CNNs, and LSTMs
    to perform encrypted mobile traffic classification [[469](#bib.bib469)], arguing
    that deep NNs can automatically extract complex features present in mobile traffic.
    As reflected by their results, deep learning based solutions obtain superior accuracy
    over RFs in classifying Android, IOS and Facebook traffic. CNNs have also been
    used to identify malware traffic, where work in [[223](#bib.bib223)] regards traffic
    data as images and unusual patterns that malware traffic exhibit are classified
    by representation learning. Similar work on mobile malware detection will be further
    discussed in subsection [VI-H](#S6.SS8 "VI-H Deep Learning Driven Network Security
    ‣ VI Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning in Mobile
    and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: CDR Mining involves extracting knowledge from specific instances of telecommunication
    transactions such as phone number, cell ID, session start/end time, traffic consumption,
    etc. Using deep learning to mine useful information from CDR data can serve a
    variety of functions. For example, Liang *et al.* propose Mercury to estimate
    metro density from streaming CDR data, using RNNs [[224](#bib.bib224)]. They take
    the trajectory of a mobile phone user as a sequence of locations; RNN-based models
    work well in handling such sequential data. Likewise, Felbo *et al.* use CDR data
    to study demographics [[225](#bib.bib225)]. They employ a CNN to predict the age
    and gender of mobile users, demonstrating the superior accuracy of these structures
    over other ML tools. More recently, Chen *et al.* compare different ML models
    to predict tourists’ next locations of visit by analyzing CDR data [[226](#bib.bib226)].
    Their experiments suggest that RNN-based predictors significantly outperform traditional
    ML methods, including Naive Bayes, SVM, RF, and MLP.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lessons learned: Network-level mobile data, such as mobile traffic, usually
    involves essential spatio-temporal correlations. These correlations can be effectively
    learned by CNNs and RNNs, as they are specialized in modeling spatial and temporal
    data (e.g., images, traffic series). An important observation is that large-scale
    mobile network traffic can be processed as sequential snapshots, as suggested
    in [[216](#bib.bib216), [215](#bib.bib215)], which resemble images and videos.
    Therefore, potential exists to exploit image processing techniques for network-level
    analysis. Techniques previously used for imaging usually, however, cannot be directly
    employed with mobile data. Efforts must be made to adapt them to the particularities
    of the mobile networking domain. We expand on this future research direction in
    Sec. [VIII-B](#S8.SS2 "VIII-B Deep Learning for Spatio-Temporal Mobile Data Mining
    ‣ VIII Future Research Perspectives ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, although deep learning brings precision in network-level
    mobile data analysis, making causal inference remains challenging, due to limited
    model interpretability. For example, a NN may predict there will be a traffic
    surge in a certain region in the near future, but it is hard to explain why this
    will happen and what triggers such a surge. Additional efforts are required to
    enable explanation and confident decision making. At this stage, the community
    should rather use deep learning algorithms as intelligent assistants that can
    make accurate inferences and reduce human effort, instead of relying exclusively
    on these.
  prefs: []
  type: TYPE_NORMAL
- en: VI-C Deep Learning Driven App-level Mobile Data Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Triggered by the increasing popularity of Internet of Things (IoT), current
    mobile devices bundle increasing numbers of applications and sensors that can
    collect massive amounts of app-level mobile data [[470](#bib.bib470)]. Employing
    artificial intelligence to extract useful information from these data can extend
    the capability of devices [[74](#bib.bib74), [471](#bib.bib471), [472](#bib.bib472)],
    thus greatly benefiting users themselves, mobile operators, and indirectly device
    manufacturers. Analysis of mobile data therefore becomes an important and popular
    research direction in the mobile networking domain. Nonetheless, mobile devices
    usually operate in noisy, uncertain and unstable environments, where their users
    move fast and change their location and activity contexts frequently. As a result,
    app-level mobile data analysis becomes difficult for traditional machine learning
    tools, which performs relatively poorly. Advanced deep learning practices provide
    a powerful solution for app-level data mining, as they demonstrate better precision
    and higher robustness in IoT applications [[473](#bib.bib473)].
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/33117337af34c8c0b903484402fa76fc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: Illustration of two deployment approaches for app-level mobile data
    analysis, namely cloud-based (left) and edge-based (right). The cloud-based approach
    makes inference on clouds and send results to edge devices. On the contrary, the
    edge-based approach deploys models on edge devices which can make local inference.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There exist two approaches to app-level mobile data analysis, namely *(i)*
    cloud-based computing and *(ii)* edge-based computing. We illustrate the difference
    between these scenarios in Fig. [12](#S6.F12 "Figure 12 ‣ VI-C Deep Learning Driven
    App-level Mobile Data Analysis ‣ VI Deep Learning Driven Mobile and Wireless Networks
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey").^(31)^(31)footnotetext:
    Human profile source: https://lekeart.deviantart.com/art/male-body-profile-251793336
    As shown in the left part of the figure, the cloud-based computing treats mobile
    devices as data collectors and messengers that constantly send data to cloud servers,
    via local points of access with limited data preprocessing capabilities. This
    scenario typically includes the following steps: *(i)* users query on/interact
    with local mobile devices; *(ii)* queries are transmitted to severs in the cloud;
    *(iii)* servers gather the data received for model training and inference; *(iv)*
    query results are subsequently sent back to each device, or stored and analyzed
    without further dissemination, depending on specific application requirements.
    The drawback of this scenario is that constantly sending and receiving messages
    to/from servers over the Internet introduces overhead and may result in severe
    latency. In contrast, in the edge-based computing scenario pre-trained models
    are offloaded from the cloud to individual mobile devices, such that they can
    make inferences locally. As illustrated in the right part of Fig. [12](#S6.F12
    "Figure 12 ‣ VI-C Deep Learning Driven App-level Mobile Data Analysis ‣ VI Deep
    Learning Driven Mobile and Wireless Networks ‣ Deep Learning in Mobile and Wireless
    Networking: A Survey"), this scenario typically consists of the following: *(i)*
    servers use offline datasets to per-train a model; *(ii)* the pre-trained model
    is offloaded to edge devices; *(iii)* mobile devices perform inferences locally
    using the model; *(iv)* cloud servers accept data from local devices; *(v)* the
    model is updated using these data whenever necessary. While this scenario requires
    less interactions with the cloud, its applicability is limited by the computing
    and battery capabilities of edge hardware. Therefore, it can only support tasks
    that require light computations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Many researchers employ deep learning for app-level mobile data analysis. We
    group the works reviewed according to their application domains, namely mobile
    healthcare, mobile pattern recognition, and mobile Natural Language Processing
    (NLP) and Automatic Speech Recognition (ASR). Table [XII](#S6.T12 "TABLE XII ‣
    VI-C Deep Learning Driven App-level Mobile Data Analysis ‣ VI Deep Learning Driven
    Mobile and Wireless Networks ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey") gives a high-level summary of existing research efforts and we discuss
    representative work next.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE XII: A summary of works on app-level mobile data analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Subject | Reference | Application | Deployment | Model |'
  prefs: []
  type: TYPE_TB
- en: '| Mobile Healthcare | Liu and Du [[235](#bib.bib235)] | Mobile ear | Edge-based
    | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Liu *at al.* [[236](#bib.bib236)] | Mobile ear | Edge-based | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Jindal [[237](#bib.bib237)] | Heart rate prediction | Cloud-based | DBN |'
  prefs: []
  type: TYPE_TB
- en: '| Kim *et al.* [[238](#bib.bib238)] | Cytopathology classification | Cloud-based
    | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Sathyanarayana *et al.* [[239](#bib.bib239)] | Sleep quality prediction |
    Cloud-based | MLP, CNN, LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Li and Trocan [[240](#bib.bib240)] | Health conditions analysis | Cloud-based
    | Stacked AE |'
  prefs: []
  type: TYPE_TB
- en: '| Hosseini *et al.* [[241](#bib.bib241)] | Epileptogenicity localisation |
    Cloud-based | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Stamate *et al.* [[242](#bib.bib242)] | Parkinson’s symptoms management |
    Cloud-based | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Quisel *et al.* [[243](#bib.bib243)] | Mobile health data analysis | Cloud-based
    | CNN, RNN |'
  prefs: []
  type: TYPE_TB
- en: '| Khan *et al.*[[244](#bib.bib244)] | Respiration surveillance | Cloud-based
    | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Mobile Pattern Recognition | Li *et al.* [[245](#bib.bib245)] | Mobile object
    recognition | Edge-based | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Tobías *et al.* [[246](#bib.bib246)] | Mobile object recognition | Edge-based
    & Cloud based | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Pouladzadeh and Shirmohammadi [[247](#bib.bib247)] | Food recognition system
    | Cloud-based | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Tanno *et al.* [[248](#bib.bib248)] | Food recognition system | Edge-based
    | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Kuhad *et al.* [[249](#bib.bib249)] | Food recognition system | Cloud-based
    | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Teng and Yang [[250](#bib.bib250)] | Facial recognition | Cloud-based | CNN
    |'
  prefs: []
  type: TYPE_TB
- en: '| Wu *et al.* [[291](#bib.bib291)] | Mobile visual search | Edge-based | CNN
    |'
  prefs: []
  type: TYPE_TB
- en: '| Rao *et al.* [[251](#bib.bib251)] | Mobile augmented reality | Edge-based
    | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Ohara *et al.* [[290](#bib.bib290)] | WiFi-driven indoor change detection
    | Cloud-based | CNN,LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Zeng *et al.* [[252](#bib.bib252)] | Activity recognition | Cloud-based |
    CNN, RBM |'
  prefs: []
  type: TYPE_TB
- en: '| Almaslukh *et al.* [[253](#bib.bib253)] | Activity recognition | Cloud-based
    | AE |'
  prefs: []
  type: TYPE_TB
- en: '| Li *et al.* [[254](#bib.bib254)] | RFID-based activity recognition | Cloud-based
    | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Bhattacharya and Lane [[255](#bib.bib255)] | Smart watch-based activity recognition
    | Edge-based | RBM |'
  prefs: []
  type: TYPE_TB
- en: '| Antreas and Angelov [[256](#bib.bib256)] | Mobile surveillance system | Edge-based
    & Cloud based | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Ordóñez and Roggen [[112](#bib.bib112)] | Activity recognition | Cloud-based
    | ConvLSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[257](#bib.bib257)] | Gesture recognition | Edge-based | CNN,
    RNN |'
  prefs: []
  type: TYPE_TB
- en: '| Gao *et al.* [[258](#bib.bib258)] | Eating detection | Cloud-based | DBM,
    MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Zhu *et al.* [[259](#bib.bib259)] | User energy expenditure estimation |
    Cloud-based | CNN, MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Sundsøy *et al.* [[260](#bib.bib260)] | Individual income classification
    | Cloud-based | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Chen and Xue [[261](#bib.bib261)] | Activity recognition | Cloud-based |
    CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Ha and Choi [[262](#bib.bib262)] | Activity recognition | Cloud-based | CNN
    |'
  prefs: []
  type: TYPE_TB
- en: '| Edel and Köppe [[263](#bib.bib263)] | Activity recognition | Edge-based |
    Binarized-LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Okita and Inoue [[266](#bib.bib266)] | Multiple overlapping activities recognition
    | Cloud-based | CNN+LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Alsheikh *et al.* [[17](#bib.bib17)] | Activity recognition using Apache
    Spark | Cloud-based | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Mittal *et al.* [[267](#bib.bib267)] | Garbage detection | Edge-based & Cloud
    based | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Seidenari *et al.* [[268](#bib.bib268)] | Artwork detection and retrieval
    | Edge-based | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Zeng *et al.* [[269](#bib.bib269)] | Mobile pill classification | Edge-based
    | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Lane and Georgiev [[73](#bib.bib73)] | Mobile activity recognition, emotion
    recognition and speaker identification | Edge-based | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Yao *et al.* [[289](#bib.bib289)] | Car tracking,heterogeneous human activity
    recognition and user identification | Edge-based | CNN, RNN |'
  prefs: []
  type: TYPE_TB
- en: '| Zou *et al.* [[270](#bib.bib270)] | IoT human activity recognition | Cloud-based
    | AE, CNN, LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Zeng [[271](#bib.bib271)] | Mobile object recognition | Edge-based | Unknown
    |'
  prefs: []
  type: TYPE_TB
- en: '| Katevas *et al.* [[288](#bib.bib288)] | Notification attendance prediction
    | Edge-based | RNN |'
  prefs: []
  type: TYPE_TB
- en: '| Radu *et al.* [[187](#bib.bib187)] | Activity recognition | Edge-based |
    RBM, CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[272](#bib.bib272), [273](#bib.bib273)] | Activity and gesture
    recognition | Cloud-based | Stacked AE |'
  prefs: []
  type: TYPE_TB
- en: '| Feng *et al.* [[274](#bib.bib274)] | Activity detection | Cloud-based | LSTM
    |'
  prefs: []
  type: TYPE_TB
- en: '| Cao *et al.* [[275](#bib.bib275)] | Mood detection | Cloud-based | GRU |'
  prefs: []
  type: TYPE_TB
- en: '| Ran *et al.* [[276](#bib.bib276)] | Object detection for AR applications.
    | Edge-based & cloud-based | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Zhao *et al.* [[287](#bib.bib287)] | Estimating 3D human skeleton from radio
    frequently signal | Cloud-based | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Mobile NLP and ASR | Siri [[277](#bib.bib277)] | Speech synthesis | Edge-based
    | Mixture density networks |'
  prefs: []
  type: TYPE_TB
- en: '| McGraw *et al.* [[278](#bib.bib278)] | Personalised speech recognition |
    Edge-based | LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Prabhavalkar *et al.* [[279](#bib.bib279)] | Embedded speech recognition
    | Edge-based | LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Yoshioka *et al.* [[280](#bib.bib280)] | Mobile speech recognition | Cloud-based
    | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Ruan *et al.* [[281](#bib.bib281)] | Shifting from typing to speech | Cloud-based
    | Unknown |'
  prefs: []
  type: TYPE_TB
- en: '| Georgiev *et al.* [[97](#bib.bib97)] | Multi-task mobile audio sensing |
    Edge-based | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Others | Ignatov *et al.* [[282](#bib.bib282)] | Mobile images quality enhancement
    | Cloud-based | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Lu *et al.* [[283](#bib.bib283)] | Information retrieval from videos in wireless
    network | Cloud-based | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Lee *et al.* [[284](#bib.bib284)] | Reducing distraction for smartwatch users
    | Cloud-based | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Vu *et al.* [[285](#bib.bib285)] | Transportation mode detection | Cloud-based
    | RNN |'
  prefs: []
  type: TYPE_TB
- en: '| Fang *et al.* [[286](#bib.bib286)] | Transportation mode detection | Cloud-based
    | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Xue *et al.* [[264](#bib.bib264)] | Mobile App classification | Cloud-based
    | AE, MLP, CNN, and LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Liu *et al.* [[265](#bib.bib265)] | Mobile motion sensor fingerprinting |
    Cloud-based | LSTM |'
  prefs: []
  type: TYPE_TB
- en: Mobile Health. There is an increasing variety of wearable health monitoring
    devices being introduced to the market. By incorporating medical sensors, these
    devices can capture the physical conditions of their carriers and provide real-time
    feedback (e.g. heart rate, blood pressure, breath status etc.), or trigger alarms
    to remind users of taking medical actions [[474](#bib.bib474)].
  prefs: []
  type: TYPE_NORMAL
- en: Liu and Du design a deep learning-driven MobiEar to aid deaf people’s awareness
    of emergencies [[235](#bib.bib235)]. Their proposal accepts acoustic signals as
    input, allowing users to register different acoustic events of interest. MobiEar
    operates efficiently on smart phones and only requires infrequent communications
    with servers for updates. Likewise, Liu *et al.* develop a UbiEar, which is operated
    on the Android platform to assist hard-to-hear sufferers in recognizing acoustic
    events, without requiring location information [[236](#bib.bib236)]. Their design
    adopts a lightweight CNN architecture for inference acceleration and demonstrates
    comparable accuracy over traditional CNN models.
  prefs: []
  type: TYPE_NORMAL
- en: Hosseini *et al.* design an edge computing system for health monitoring and
    treatment [[241](#bib.bib241)]. They use CNNs to extract features from mobile
    sensor data, which plays an important role in their epileptogenicity localization
    application. Stamate *et al.* develop a mobile Android app called cloudUPDRS to
    manage Parkinson’s symptoms [[242](#bib.bib242)]. In their work, MLPs are employed
    to determine the acceptance of data collected by smart phones, to maintain high-quality
    data samples. The proposed method outperforms other ML methods such as GPs and
    RFs. Quisel *et al.* suggest that deep learning can be effectively used for mobile
    health data analysis [[243](#bib.bib243)]. They exploit CNNs and RNNs to classify
    lifestyle and environmental traits of volunteers. Their models demonstrate superior
    prediction accuracy over RFs and logistic regression, over six datasets.
  prefs: []
  type: TYPE_NORMAL
- en: As deep learning performs remarkably in medical data analysis [[475](#bib.bib475)],
    we expect more and more deep learning powered health care devices will emerge
    to improve physical monitoring and illness diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: Mobile Pattern Recognition. Recent advanced mobile devices offer people a portable
    intelligent assistant, which fosters a diverse set of applications that can classify
    surrounding objects (e.g. [[245](#bib.bib245), [246](#bib.bib246), [250](#bib.bib250),
    [247](#bib.bib247)]) or users’ behaviors (e.g. [[252](#bib.bib252), [476](#bib.bib476),
    [261](#bib.bib261), [255](#bib.bib255), [112](#bib.bib112), [262](#bib.bib262),
    [477](#bib.bib477)]) based on patterns observed in the output of the mobile camera
    or other sensors. We review and compare recent works on mobile pattern recognition
    in this part.
  prefs: []
  type: TYPE_NORMAL
- en: '*Object classification* in pictures taken by mobile devices is drawing increasing
    research interest. Li *et al.* develop DeepCham as a mobile object recognition
    framework [[245](#bib.bib245)]. Their architecture involves a crowd-sourcing labeling
    process, which aims to reduce the hand-labeling effort, and a collaborative training
    instance generation pipeline that is built for deployment on mobile devices. Evaluations
    of the prototype system suggest that this framework is efficient and effective
    in terms of training and inference. Tobías *et al.* investigate the applicability
    of employing CNN schemes on mobile devices for objection recognition tasks [[246](#bib.bib246)].
    They conduct experiments on three different model deployment scenarios, i.e.,
    on GPU, CPU, and respectively on mobile devices, with two benchmark datasets.
    The results obtained suggest that deep learning models can be efficiently embedded
    in mobile devices to perform real-time inference.'
  prefs: []
  type: TYPE_NORMAL
- en: Mobile classifiers can also assist Virtual Reality (VR) applications. A CNN
    framework is proposed in [[250](#bib.bib250)] for facial expressions recognition
    when users are wearing head-mounted displays in the VR environment. Rao *et al.*
    incorporate a deep learning object detector into a mobile augmented reality (AR)
    system [[251](#bib.bib251)]. Their system achieves outstanding performance in
    detecting and enhancing geographic objects in outdoor environments. Further work
    focusing on mobile AR applications is introduced in [[478](#bib.bib478)], where
    the authors characterize the tradeoffs between accuracy, latency, and energy efficiency
    of object detection.
  prefs: []
  type: TYPE_NORMAL
- en: '*Activity recognition* is another interesting area that relies on data collected
    by mobile motion sensors [[477](#bib.bib477), [479](#bib.bib479)]. This refers
    to the ability to classify based on data collected via, e.g., video capture, accelerometer
    readings, motion – Passive Infra-Red (PIR) sensing, specific actions and activities
    that a human subject performs. Data collected will be delivered to servers for
    model training and the model will be subsequently deployed for domain-specific
    tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: Essential features of sensor data can be automatically extracted by neural networks.
    The first work in this space that is based on deep learning employs a CNN to capture
    local dependencies and preserve scale invariance in motion sensor data [[252](#bib.bib252)].
    The authors evaluate their proposal on 3 offline datasets, demonstrating their
    proposal yields higher accuracy over statistical methods and Principal Components
    Analysis (PCA). Almaslukh *et al.* employ a deep AE to perform human activity
    recognition by analyzing an offline smart phone dataset gathered from accelerometers
    and gyroscope sensors [[253](#bib.bib253)]. Li *et al.* consider different scenarios
    for activity recognition [[254](#bib.bib254)]. In their implementation, Radio
    Frequency Identification (RFID) data is directly sent to a CNN model for recognizing
    human activities. While their mechanism achieves high accuracy in different applications,
    experiments suggest that the RFID-based method does not work well with metal objects
    or liquid containers.
  prefs: []
  type: TYPE_NORMAL
- en: '[[255](#bib.bib255)] exploits an RBM to predict human activities, given 7 types
    of sensor data collected by a smart watch. Experiments on prototype devices show
    that this approach can efficiently fulfill the recognition objective under tolerable
    power requirements. Ordóñez and Roggen architect an advanced ConvLSTM to fuse
    data gathered from multiple sensors and perform activity recognition [[112](#bib.bib112)].
    By leveraging CNN and LSTM structures, ConvLSTMs can automatically compress spatio-temporal
    sensor data into low-dimensional representations, without heavy data post-processing
    effort. Wang *et al.* exploit Google Soli to architect a mobile user-machine interaction
    platform [[257](#bib.bib257)]. By analyzing radio frequency signals captured by
    millimeter-wave radars, their architecture is able to recognize 11 types of gestures
    with high accuracy. Their models are trained on the server side, and inferences
    are performed locally on mobile devices. More recently, Zhao *et al.* design a
    4D CNN framework (3D for the spatial dimension + 1D for the temporal dimension)
    to reconstruct human skeletons using radio frequency signals [[287](#bib.bib287)].
    This novel approach resembles virtual “X-ray”, enabling to accurately estimate
    human poses, without requiring an actual camera.'
  prefs: []
  type: TYPE_NORMAL
- en: Mobile NLP and ASR. Recent remarkable achievements obtained by deep learning
    in Natural Language Processing (NLP) and Automatic Speech Recognition (ASR) are
    also embraced by applications for mobile devices.
  prefs: []
  type: TYPE_NORMAL
- en: Powered by deep learning, the intelligent personal assistant Siri, developed
    by Apple, employs a deep mixture density networks [[480](#bib.bib480)] to fix
    typical robotic voice issues and synthesize more human-like voice [[277](#bib.bib277)].
    An Android app released by Google supports mobile personalized speech recognition
    [[278](#bib.bib278)]; this quantizes the parameters in LSTM model compression,
    allowing the app to run on low-power mobile phones. Likewise, Prabhavalkar *et
    al.* propose a mathematical RNN compression technique that reduces two thirds
    of an LSTM acoustic model size, while only compromising negligible accuracy [[279](#bib.bib279)].
    This allows building both memory- and energy-efficient ASR applications on mobile
    devices.
  prefs: []
  type: TYPE_NORMAL
- en: Yoshioka *et al.* present a framework that incorporates a network-in-network
    architecture into a CNN model, which allows to perform ASR with mobile multi-microphone
    devices used in noisy environments [[280](#bib.bib280)]. Mobile ASR can also accelerate
    text input on mobile devices, Ruan *et al.*’s study showing that with the help
    of ASR, the input rates of English and Mandarin are 3.0 and 2.8 times faster over
    standard typing on keyboards [[281](#bib.bib281)]. More recently, the applicability
    of deep learning to multi-task audio sensing is investigated in [[97](#bib.bib97)],
    where Georgiev *et al.* propose and evaluate a novel deep learning modelling and
    optimization framework tailored to embedded audio sensing tasks. To this end,
    they selectively share compressed representations between different tasks, which
    reduces training and data storage overhead, without significantly compromising
    accuracy of an individual task. The authors evaluate their framework on a memory-constrained
    smartphone performing four audio tasks (i.e., speaker identification, emotion
    recognition, stress detection, and ambient scene analysis). Experiments suggest
    this proposal can achieve high efficiency in terms of energy, runtime and memory,
    while maintaining excellent accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Other applications. Deep learning also plays an important role in other applications
    that involve app-level data analysis. For instance, Ignatov *et al.* show that
    deep learning can enhance the quality of pictures taken by mobile phones. By employing
    a CNN, they successfully improve the quality of images obtained by different mobile
    devices, to a digital single-lens reflex camera level [[282](#bib.bib282)]. Lu
    *et al.* focus on video post-processing under wireless networks [[283](#bib.bib283)],
    where their framework exploits a customized AlexNet to answer queries about detected
    objects. This framework further involves an optimizer, which instructs mobile
    devices to offload videos, in order to reduce query response time.
  prefs: []
  type: TYPE_NORMAL
- en: Another interesting application is presented in [[284](#bib.bib284)], where
    Lee *et al.* show that deep learning can help smartwatch users reduce distraction
    by eliminating unnecessary notifications. Specifically, the authors use an 11-layer
    MLP to predict the importance of a notification. Fang *et al.* exploit an MLP
    to extract features from high-dimensional and heterogeneous sensor data, including
    accelerometer, magnetometer, and gyroscope measurements [[286](#bib.bib286)].
    Their architecture achieves 95% accuracy in recognizing human transportation modes,
    i.e., still, walking, running, biking, and on vehicle.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lessons Learned: App-level data is heterogeneous and generated from distributed
    mobile devices, and there is a trend to offload the inference process to these
    devices. However, due to computational and battery power limitations, models employed
    in the edge-based scenario are constrained to light-weight architectures, which
    are less suitable for complex tasks. Therefore, the trade-off between model complexity
    and accuracy should be carefully considered [[66](#bib.bib66)]. Numerous efforts
    were made towards tailoring deep learning to mobile devices, in order to make
    algorithms faster and less energy-consuming on embedded equipment. For example,
    model compression, pruning, and quantization are commonly used for this purpose.
    Mobile device manufacturers are also developing new software and hardware to support
    deep learning based applications. We will discuss this work in more detail in
    Sec. [VII](#S7 "VII Tailoring Deep Learning to Mobile Networks ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'At the same time, app-level data usually contains important users information
    and processing this poses significant privacy concerns. Although there have been
    efforts that commit to preserve user privacy, as we discuss in Sec.[VI-H](#S6.SS8
    "VI-H Deep Learning Driven Network Security ‣ VI Deep Learning Driven Mobile and
    Wireless Networks ‣ Deep Learning in Mobile and Wireless Networking: A Survey"),
    research efforts in this direction are new, especially in terms of protecting
    user information in distributed training. We expect more efforts in this direction
    in the future.'
  prefs: []
  type: TYPE_NORMAL
- en: VI-D Deep Learning Driven Mobility Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Understanding movement patterns of groups of human beings and individuals is
    becoming crucial for epidemiology, urban planning, public service provisioning,
    and mobile network resource management [[481](#bib.bib481)]. Deep learning is
    gaining increasing attention in this area, both from a group and individual level
    perspective (see Fig. [13](#S6.F13 "Figure 13 ‣ VI-D Deep Learning Driven Mobility
    Analysis ‣ VI Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey")). In this subsection, we thus discuss
    research using deep learning in this space, which we summarize in Table [XIII](#S6.T13
    "TABLE XIII ‣ VI-D Deep Learning Driven Mobility Analysis ‣ VI Deep Learning Driven
    Mobile and Wireless Networks ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5f951b8d9e211d79ab5b4ab11d712f5e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Illustration of mobility analysis paradigms at individual (left)
    and group (right) levels.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE XIII: A summary of work on deep learning driven mobility analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Reference | Application | Mobility level | Model | Key contribution |'
  prefs: []
  type: TYPE_TB
- en: '| Ouyang *et al.* [[292](#bib.bib292)] | Mobile user trajectory prediction
    | Individual | CNN | Online framework for data stream processing. |'
  prefs: []
  type: TYPE_TB
- en: '| Yang *et al.* [[293](#bib.bib293)] | Social networks and mobile trajectories
    modeling | Mobile Ad-hoc Network | RNN, GRU | Multi-task learning. |'
  prefs: []
  type: TYPE_TB
- en: '| Tkačík and Kordík [[305](#bib.bib305)] | Mobility modelling and prediction
    | Individual | Neural Turing Machine | The Neural Turing Machine can store historical
    data and perform “read” and “write” operations automatically. |'
  prefs: []
  type: TYPE_TB
- en: '| Song *et al.* [[294](#bib.bib294)] | City-wide mobility prediction and transportation
    modeling | City-wide | Multi-task LSTM | Multi-task learning. |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang *et al.* [[295](#bib.bib295)] | City-wide crowd flows prediction |
    City-wide | Deep spatio-temporal residual networks (CNN-based) | Exploitation
    of spatio-temporal characteristics of mobility events. |'
  prefs: []
  type: TYPE_TB
- en: '| Lin *et al.* [[227](#bib.bib227)] | Human activity chains generation | User
    group | Input-Output HMM + LSTM | Generative model. |'
  prefs: []
  type: TYPE_TB
- en: '| Subramanian and Sadiq [[296](#bib.bib296)] | Mobile movement prediction |
    Individual | MLP | Fewer location updates and lower paging signaling costs. |'
  prefs: []
  type: TYPE_TB
- en: '| Ezema and Ani [[297](#bib.bib297)] | Mobile location estimation | Individual
    | MLP | Operates with received signal strength in GSM. |'
  prefs: []
  type: TYPE_TB
- en: '| Shao *et al.* [[298](#bib.bib298)] | CNN driven Pedometer | Individual |
    CNN | Reduced false negatives caused by periodic movements and lower initial response
    time. |'
  prefs: []
  type: TYPE_TB
- en: '| Yayeh *et al.* [[299](#bib.bib299)] | Mobility prediction in mobile Ad-hoc
    network | Individual | MLP | Achieving high prediction accuracy under random waypoint
    mobility model. |'
  prefs: []
  type: TYPE_TB
- en: '| Chen *et al.* [[300](#bib.bib300)] | Mobility driven traffic accident risk
    prediction | City-wide | Stacked denoising AE | Automatically learning correlation
    between human mobility and traffic accident risk. |'
  prefs: []
  type: TYPE_TB
- en: '| Song *et al.* [[301](#bib.bib301)] | Human emergency behavior and mobility
    modelling | City-wide | DBN | Achieves accurate prediction over various disaster
    events, including earthquake, tsunami and nuclear accidents. |'
  prefs: []
  type: TYPE_TB
- en: '| Yao *et al.* [[302](#bib.bib302)] | Trajectory clustering | User group |
    sequence-to-sequence AE with RNNs | The learned representations can robustly encode
    the movement characteristics of the objects and generate spatio-temporally invariant
    clusters. |'
  prefs: []
  type: TYPE_TB
- en: '| Liu *et al.* [[303](#bib.bib303)] | Urban traffic prediction | City-wide
    | CNN, RNN, LSTM, AE, and RBM | Reveals the potential of employing deep learning
    to urban traffic prediction with mobility data. |'
  prefs: []
  type: TYPE_TB
- en: '| Wickramasuriya *et al.* [[304](#bib.bib304)] | Base station prediction with
    proactive mobility management | Individual | RNN | Employs proactive and anticipatory
    mobility management for dynamic base station selection. |'
  prefs: []
  type: TYPE_TB
- en: '| Kim and Song [[306](#bib.bib306)] | User mobility and personality modelling
    | Individual | MLP, RBM | Foundation for the customization of location-based services.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Jiang *et al.* [[307](#bib.bib307)] | Short-term urban mobility prediction
    | City-wide | RNN | Superior prediction accuracy and verified as highly deployable
    prototype system. |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[308](#bib.bib308)] | Mobility management in dense networks
    | Individual | LSTM | Improves the quality of service of mobile users in the handover
    process, while maintaining network energy efficiency. |'
  prefs: []
  type: TYPE_TB
- en: '| Jiang *et al.* [[309](#bib.bib309)] | Urban human mobility prediction | City-wide
    | RNN | First work that utilizes urban region of interest to model human mobility
    city-wide. |'
  prefs: []
  type: TYPE_TB
- en: '| Feng *et al.* [[310](#bib.bib310)] | Human mobility forecasting | Individual
    | Attention RNN | Employs the attention mechanism and combines heterogeneous transition
    regularity and multi-level periodicity. |'
  prefs: []
  type: TYPE_TB
- en: 'Since deep learning is able to capture spatial dependencies in sequential data,
    it is becoming a powerful tool for mobility analysis. The applicability of deep
    learning for trajectory prediction is studied in [[482](#bib.bib482)]. By sharing
    representations learned by RNN and Gate Recurrent Unit (GRU), the framework can
    perform multi-task learning on both social networks and mobile trajectories modeling.
    Specifically, the authors first use deep learning to reconstruct social network
    representations of users, subsequently employing RNN and GRU models to learn patterns
    of mobile trajectories with different time granularity. Importantly, these two
    components jointly share representations learned, which tightens the overall architecture
    and enables efficient implementation. Ouyang *et al.* argue that mobility data
    are normally high-dimensional, which may be problematic for traditional ML models.
    Therefore, they build upon deep learning advances and propose an online learning
    scheme to train a hierarchical CNN architecture, allowing model parallelization
    for data stream processing [[292](#bib.bib292)]. By analyzing usage records, their
    framework “DeepSpace” predicts individuals’ trajectories with much higher accuracy
    as compared to naive CNNs, as shown with experiments on a real-world dataset.
    In [[305](#bib.bib305)], Tkačík and Kordík design a Neural Turing Machine [[483](#bib.bib483)]
    to predict trajectories of individuals using mobile phone data. The Neural Turing
    Machine embraces two major components: a memory module to store the historical
    trajectories, and a controller to manage the “read” and “write” operations over
    the memory. Experiments show that their architecture achieves superior generalization
    over stacked RNN and LSTM, while also delivering more precise trajectory prediction
    than the $n$-grams and $k$ nearest neighbor methods.'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of focusing on individual trajectories, Song *et al.* shed light on
    the mobility analysis at a larger scale [[294](#bib.bib294)]. In their work, LSTM
    networks are exploited to jointly model the city-wide movement patterns of a large
    group of people and vehicles. Their multi-task architecture demonstrates superior
    prediction accuracy over a standard LSTM. City-wide mobile patterns is also researched
    in [[295](#bib.bib295)], where the authors architect deep spatio-temporal residual
    networks to forecast the movements of crowds. In order to capture the unique characteristics
    of spatio-temporal correlations associated with human mobility, their framework
    abandons RNN-based models and constructs three ResNets to extract nearby and distant
    spatial dependencies within a city. This scheme learns temporal features and fuses
    representations extracted by all models for the final prediction. By incorporating
    external events information, their proposal achieves the highest accuracy among
    all deep learning and non-deep learning methods studied. An RNN is also employed
    in [[307](#bib.bib307)], where Jiang *et al.* perform short-term urban mobility
    forecasting on a huge dataset collected from a real-world deployment. Their model
    delivers superior accuracy over the $n$-gram and Markovian approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Lin *et al.* consider generating human movement chains from cellular data, to
    support transportation planning [[227](#bib.bib227)]. In particular, they first
    employ an input-output Hidden Markov Model (HMM) to label activity profiles for
    CDR data pre-processing. Subsequently, an LSTM is designed for activity chain
    generation, given the labeled activity sequences. They further synthesize urban
    mobility plans using the generative model and the simulation results reveal reasonable
    fit accuracy. Jiang *et al.* design 24-h mobility prediction system base on RNN
    mdoels [[309](#bib.bib309)]. They employ dynamic Region of Interests (ROIs) for
    each hour to discovered through divide-and-merge mining from raw trajectory database,
    which leads to high prediction accuracy. Feng *et al.* incorporate attention mechanisms
    on RNN [[310](#bib.bib310)], to capture the complicated sequential transitions
    of human mobility. By combining the heterogeneous transition regularity and multi-level
    periodicity, their model delivers up to 10% of accuracy improvement compared to
    state-of-the-art forecasting models.
  prefs: []
  type: TYPE_NORMAL
- en: Yayeh *et al.* employ an MLP to predict the mobility of mobile devices in mobile
    ad-hoc networks, given previously observed pause time, speed, and movement direction
    [[299](#bib.bib299)]. Simulations conducted using the random waypoint mobility
    model show that their proposal achieves high prediction accuracy. An MLP is also
    adopted in [[306](#bib.bib306)], where Kim and Song model the relationship between
    human mobility and personality, and achieve high prediction accuracy. Yao *et
    al.* discover groups of similar trajectories to facilitate higher-level mobility
    driven applications using RNNs [[302](#bib.bib302)]. Particularly, a sequence-to-sequence
    AE is adopted to learn fixed-length representations of mobile users’ trajectories.
    Experiments show that their method can effectively capture spatio-temporal patterns
    in both real and synthetic datasets. Shao *et al.* design a sophisticated pedometer
    using a CNN [[298](#bib.bib298)]. By reducing false negative steps caused by periodic
    movements, their proposal significantly improves the robustness of the pedometer.
  prefs: []
  type: TYPE_NORMAL
- en: In [[300](#bib.bib300)], Chen *et al.* combine GPS records and traffic accident
    data to understand the correlation between human mobility and traffic accidents.
    To this end, they design a stacked denoising AE to learn a compact representation
    of the human mobility, and subsequently use that to predict the traffic accident
    risk. Their proposal can deliver accurate, real-time prediction across large regions.
    GPS records are also used in other mobility-driven applications. Song *et al.*
    employ DBNs to predict and simulate human emergency behavior and mobility in natural
    disaster, learning from GPS records of 1.6 million users [[301](#bib.bib301)].
    Their proposal yields accurate predictions in different disaster scenarios such
    as earthquakes, tsunamis, and nuclear accidents. GPS data is also utilized in
    [[303](#bib.bib303)], where Liu *et al.* study the potential of employing deep
    learning for urban traffic prediction using mobility data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lessons learned: Mobility analysis is concerned with the movement trajectory
    of a single user or large groups of users. The data of interest are essential
    time series, but have an additional spatial dimension. Mobility data is usually
    subject to stochasticity, loss, and noise; therefore precise modelling is not
    straightforward. As deep learning is able to perform automatic feature extraction,
    it becomes a strong candidate for human mobility modelling. Among them, CNNs and
    RNNs are the most successful architectures in such applications (e.g., [[292](#bib.bib292),
    [293](#bib.bib293), [294](#bib.bib294), [295](#bib.bib295), [227](#bib.bib227)]),
    as they can effectively exploit spatial and temporal correlations.'
  prefs: []
  type: TYPE_NORMAL
- en: VI-E Deep Learning Driven User Localization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'TABLE XIV: Leveraging Deep learning in user localization'
  prefs: []
  type: TYPE_NORMAL
- en: '| Reference | Application | Input data | Model | Key contribution |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[311](#bib.bib311)] | Indoor fingerprinting | CSI | RBM |
    First deep learning driven indoor localization based on CSI |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[272](#bib.bib272), [273](#bib.bib273)] | Indoor localization
    | CSI | RBM | Works with calibrated phase information of CSI |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[312](#bib.bib312)] | Indoor localization | CSI | CNN | Uses
    more robust angle of arrival for estimation |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[313](#bib.bib313)] | Indoor localization | CSI | RBM | Bi-modal
    framework using both angle of arrival and average amplitudes of CSI |'
  prefs: []
  type: TYPE_TB
- en: '| Nowicki and Wietrzykowski [[314](#bib.bib314)] | Indoor localization | WiFi
    scans | Stacked AE | Requires less system tuning or filtering effort |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[315](#bib.bib315), [316](#bib.bib316)] | Indoor localization
    | Received signal strength | Stacked AE | Device-free framework, multi-task learning
    |'
  prefs: []
  type: TYPE_TB
- en: '| Mohammadi*et al.* [[317](#bib.bib317)] | Indoor localization | Received signal
    strength | VAE+DQN | Handles unlabeled data; reinforcement learning aided semi-supervised
    learning |'
  prefs: []
  type: TYPE_TB
- en: '| Anzum *et al.* [[318](#bib.bib318)] | Indoor localization | Received signal
    strength | Counter propagation neural network | Solves the ambiguity among zones
    |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[319](#bib.bib319)] | Indoor localization | Smartphone magnetic
    and light sensors | LSTM | Employ bimodal magnetic field and light intensity data
    |'
  prefs: []
  type: TYPE_TB
- en: '| Kumar *et al.* [[320](#bib.bib320)] | Indoor vehicles localization | Camera
    images | CNN | Focus on vehicles applications |'
  prefs: []
  type: TYPE_TB
- en: '| Zheng and Weng [[321](#bib.bib321)] | Outdoor navigation | Camera images
    ad GPS | Developmental network | Online learning scheme; edge-based |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang *et al.* [[111](#bib.bib111)] | Indoor and outdoor localization | Received
    signal strength | Stacked AE | Operates under both indoor and outdoor environments
    |'
  prefs: []
  type: TYPE_TB
- en: '| Vieira *et al.* [[322](#bib.bib322)] | Massive MIMO fingerprint-based positioning
    | Associated channel fingerprint | CNN | Operates with massive MIMO channels |'
  prefs: []
  type: TYPE_TB
- en: '| Hsu *et al.* [[333](#bib.bib333)] | Activity recognition, localization and
    sleep monitoring | RF Signal | CNN | Multi-user, device-free localization and
    sleep monitoring |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[323](#bib.bib323)] | Indoor localization | CSI | RBM | Explores
    features of wireless channel data and obtains optimal weights as fingerprints
    |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[331](#bib.bib331)] | Indoor localization | CSI | CNN | Exploits
    the angle of arrival for stable indoor localization |'
  prefs: []
  type: TYPE_TB
- en: '| Xiao *et al.* [[332](#bib.bib332)] | 3D Indoor localization | Bluetooth relative
    received signal strength | Denoising AE | Low-cost and robust localization |'
  prefs: []
  type: TYPE_TB
- en: '| Niitsoo *et al.* [[330](#bib.bib330)] | Indoor localization | Raw channel
    impulse response data | CNN | Robust to multipath propagation environments |'
  prefs: []
  type: TYPE_TB
- en: '| Ibrahim *et al.* [[329](#bib.bib329)] | Indoor localization | Received signal
    strength | CNN | 100% accuracy in building and floor identification |'
  prefs: []
  type: TYPE_TB
- en: '| Adege *et al.* [[328](#bib.bib328)] | Indoor localization | Received signal
    strength | MLP + linear discriminant analysis | Accurate in multi-building environments
    |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang *et al.* [[327](#bib.bib327)] | Indoor localization | Pervasive magnetic
    field and CSI | MLP | Using the magnetic field to improve the positioning accuracy
    |'
  prefs: []
  type: TYPE_TB
- en: '| Zhou *et al.* [[326](#bib.bib326)] | Indoor localization | CSI | MLP | Device-free
    localization |'
  prefs: []
  type: TYPE_TB
- en: '| Shokry *et al.* [[325](#bib.bib325)] | Outdoor localization | Crowd-sensed
    received signal strength information | MLP | More accurate than cellular localization
    while requiring less energy |'
  prefs: []
  type: TYPE_TB
- en: '| Chen *et al.* [[324](#bib.bib324)] | Indoor localization | CSI | CNN | Represents
    CSI as feature images |'
  prefs: []
  type: TYPE_TB
- en: '| Guan *et al.* [[334](#bib.bib334)] | Indoor localization | Line-of-sight
    and non line-of-sight radio signals | MLP | Combining deep learning with genetic
    algorithms |'
  prefs: []
  type: TYPE_TB
- en: 'Location-based services and applications (e.g. mobile AR, GPS) demand precise
    individual positioning technology [[484](#bib.bib484)]. As a result, research
    on user localization is evolving rapidly and numerous techniques are emerging
    [[485](#bib.bib485)]. In general, user localization methods can be categorized
    as device-based and device-free [[486](#bib.bib486)]. We illustrate the two different
    paradigms in Fig. [14](#S6.F14 "Figure 14 ‣ VI-E Deep Learning Driven User Localization
    ‣ VI Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning in Mobile
    and Wireless Networking: A Survey"). Specifically, in the first category specific
    devices carried by users become prerequisites for fulfilling the applications’
    localization function. This type of approaches rely on signals from the device
    to identify the location. Conversely, approaches that require no device pertain
    to the device-free category. Instead these employ special equipment to monitor
    signal changes, in order to localize the entities of interest. Deep learning can
    enable high localization accuracy with both paradigms. We summarize the most notable
    contributions in Table [XIV](#S6.T14 "TABLE XIV ‣ VI-E Deep Learning Driven User
    Localization ‣ VI Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey") and delve into the details of these
    works next.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d196e0051c07367630589f96b5f540c1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: An illustration of device-based (left) and device-free (right) indoor
    localization systems.'
  prefs: []
  type: TYPE_NORMAL
- en: To overcome the variability and coarse-granularity limitations of signal strength
    based methods, Wang *et al.* propose a deep learning driven fingerprinting system
    name “DeepFi” to perform indoor localization based on Channel State Information
    (CSI) [[311](#bib.bib311)]. Their toolbox yields much higher accuracy as compared
    to traditional methods, including including FIFS [[487](#bib.bib487)], Horus [[488](#bib.bib488)],
    and Maximum Likelihood [[489](#bib.bib489)]. The same group of authors extend
    their work in [[272](#bib.bib272), [273](#bib.bib273)] and [[312](#bib.bib312),
    [313](#bib.bib313)], where they update the localization system, such that it can
    work with calibrated phase information of CSI [[272](#bib.bib272), [273](#bib.bib273),
    [323](#bib.bib323)]. They further use more sophisticated CNN [[312](#bib.bib312),
    [331](#bib.bib331)] and bi-modal structures [[313](#bib.bib313)] to improve the
    accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Nowicki and Wietrzykowski propose a localization framework that reduces significantly
    the effort of system tuning or filtering and obtains satisfactory prediction performance
    [[314](#bib.bib314)]. Wang *et al.* suggest that the objective of indoor localization
    can be achieved without the help of mobile devices. In [[316](#bib.bib316)], the
    authors employ an AE to learn useful patterns from WiFi signals. By automatic
    feature extraction, they produce a predictor that can fulfill multi-tasks simultaneously,
    including indoor localization, activity, and gesture recognition. A similar work
    in presented in [[326](#bib.bib326)], where Zhou *et al.* employ an MLP structure
    to perform device-free indoor localization using CSI. Kumar *et al.* use deep
    learning to address the problem of indoor vehicles localization [[320](#bib.bib320)].
    They employ CNNs to analyze visual signal and localize vehicles in a car park.
    This can help driver assistance systems operate in underground environments where
    the system has limited vision ability.
  prefs: []
  type: TYPE_NORMAL
- en: In [[332](#bib.bib332)], Xiao *et al.* achieve low cost indoor localization
    with Bluetooth technology. The authors design a denosing AE to extract fingerprint
    features from the received signal strength of Bluetooth Low Energy beacon and
    subsequently project that to the exact position in 3D space. Experiments conducted
    in a conference room demonstrate that the proposed framework can perform precise
    positioning in both vertical and horizontal dimensions in real-time. Niitsoo *et
    al.* employ a CNN to perform localization given raw channel impulse response data
    [[330](#bib.bib330)]. Their framework is robust to multipath propagation environments
    and more precise than signal processing based approaches. A CNN is also adopted
    in [[329](#bib.bib329)], where the authors work with received signal strength
    series and achieve 100% prediction accuracy in terms of building and floor identification.
    The work in [[328](#bib.bib328)] combines deep learning with linear discriminant
    analysis for feature reduction, achieving low positioning errors in multi-building
    environments. Zhang *et al.* combine pervasive magnetic field and WiFi fingerprinting
    for indoor localization using an MLP [[327](#bib.bib327)]. Experiments show that
    adding magnetic field information to the input of the model can improve the prediction
    accuracy, compared to solutions based soley on WiFi fingerprinting.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b5ca8eff609a583609f7dc5bfbf29450.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: EZ-Sleep setup in a subject’s bedroom. Figure adopted from [[333](#bib.bib333)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hsu *et al.* use deep learning to provide Radio Frequency-based user localization,
    sleep monitoring, and insomnia analysis in multi-user home scenarios where individual
    sleep monitoring devices might not be available [[333](#bib.bib333)]. They use
    a CNN classifier with a 14-layer residual network model for sleep monitoring,
    in addition to Hidden Markov Models, to accurately track when the user enters
    or leaves the bed. By deploying sleep sensors called EZ-Sleep in 8 homes (see
    Fig. [15](#S6.F15 "Figure 15 ‣ VI-E Deep Learning Driven User Localization ‣ VI
    Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning in Mobile and
    Wireless Networking: A Survey")), collecting data for 100 nights of sleep over
    a month, and cross-validating this using an electroencephalography-based sleep
    monitor, the authors demonstrate the performance of their solution is comparable
    to that of individual, electroencephalography-based devices.'
  prefs: []
  type: TYPE_NORMAL
- en: Most mobile devices can only produce unlabeled position data, therefore unsupervised
    and semi-supervised learning become essential. Mohammadi *et al.* address this
    problem by leveraging DRL and VAE. In particular, their framework envisions a
    virtual agent in indoor environments [[317](#bib.bib317)], which can constantly
    receive state information during training, including signal strength indicators,
    current agent location, and the real (labeled data) and inferred (via a VAE) distance
    to the target. The agent can virtually move in eight directions at each time step.
    Each time it takes an action, the agent receives an reward signal, identifying
    whether it moves to a correct direction. By employing deep Q learning, the agent
    can finally localize accurately a user, given both labeled and unlabeled data.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond indoor localization, there also exist several research works that apply
    deep learning in outdoor scenarios. For example, Zheng and Weng introduce a lightweight
    developmental network for outdoor navigation applications on mobile devices [[321](#bib.bib321)].
    Compared to CNNs, their architecture requires 100 times fewer weights to be updated,
    while maintaining decent accuracy. This enables efficient outdoor navigation on
    mobile devices. Work in [[111](#bib.bib111)] studies localization under both indoor
    and outdoor environments. They use an AE to pre-train a four-layer MLP, in order
    to avoid hand-crafted feature engineering. The MLP is subsequently used to estimate
    the coarse position of targets. The authors further introduce an HMM to fine-tune
    the predictions based on temporal properties of data. This improves the accuracy
    estimation in both in-/out-door positioning with Wi-Fi signals. More recently,
    Shokry *et al.* propose DeepLoc, a deep learning-based outdoor localization system
    using crowdsensed geo-tagged received signal strength information [[325](#bib.bib325)].
    By using an MLP to learn the correlation between cellular signal and users’ locations,
    their framework can deliver median localization accuracy within 18.8m in urban
    areas and within 15.7m in rural areas on Android devices, while requiring modest
    energy budgets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lessons learned: Localization relies on sensorial output, signal strength,
    or CSI. These data usually have complex features, therefore large amounts of data
    are required for learning [[314](#bib.bib314)]. As deep learning can extract features
    in an unsupervised manner, it has become a strong candidate for localization tasks.
    On the other hand, it can be observed that positioning accuracy and system robustness
    can be improved by fusing multiple types of signals when providing these as the
    input (see, e.g., [[327](#bib.bib327)]). Using deep learning to automatically
    extract features and correlate information from different sources for localization
    purposes is becoming a trend.'
  prefs: []
  type: TYPE_NORMAL
- en: VI-F Deep Learning Driven Wireless Sensor Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'TABLE XV: A summary of work on deep learning driven WSNs.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Perspective | Reference | Application | Model | Optimizer | Key contribution
    |'
  prefs: []
  type: TYPE_TB
- en: '| Centralized vs. Decentralized | Khorasani and Naji [[343](#bib.bib343)] |
    Data aggregation | MLP | Unknown | Improves the energy efficiency in the aggregation
    process |'
  prefs: []
  type: TYPE_TB
- en: '| Li *et al.* [[344](#bib.bib344)] | Distributed data mining | MLP | Unknown
    | Performing data analysis at distributed nodes, reducing by 58.31% the energy
    consumption |'
  prefs: []
  type: TYPE_TB
- en: '| WSN Localization | Bernas and Płaczek [[336](#bib.bib336)] | Indoor localization
    | MLP | Resilient backpropagation | Dramatically reduces the memory consumption
    of received signal strength map storage |'
  prefs: []
  type: TYPE_TB
- en: '| Payal *et al.* [[337](#bib.bib337)] | Node localization | MLP | First-order
    and second-order gradient descent algorithm | Compares different training algorithms
    of MLP for WSN localization |'
  prefs: []
  type: TYPE_TB
- en: '| Dong *et al.* [[338](#bib.bib338)] | Underwater localization | MLP | RMSprop
    | Performs WSN localization in underwater environments |'
  prefs: []
  type: TYPE_TB
- en: '| Phoemphon *et al.* [[348](#bib.bib348)] | WSN node localization | Logic fuzzy
    system + ELM | Algorithm 4 described in [[348](#bib.bib348)] | Combining logic
    fuzzy system and ELM to achieve robust range-free WSN node localization |'
  prefs: []
  type: TYPE_TB
- en: '| Banihashemian *et al.* [[349](#bib.bib349)] | Range-free WSN node localization
    | MLP, ELM | Conjugate gradient based method | Employs a particle swarm optimization
    algorithm to simultaneously optimize the neural network based on storage cost
    and localization accuracy |'
  prefs: []
  type: TYPE_TB
- en: '| Kang *et al.* [[351](#bib.bib351)] | Water leakage detection and localization
    | CNN + SVM | SGD | Propose an enhanced graph-based local search algorithm using
    a virtual node scheme to select the nearest leakage location |'
  prefs: []
  type: TYPE_TB
- en: '| El *et al.* [[354](#bib.bib354)] | WSN localization in the presence of anisotropic
    signal attenuation | MLP | Unknown | Robust against anisotropic signal attenuation
    |'
  prefs: []
  type: TYPE_TB
- en: '| WSN Data Analysis | Yan *et al.* [[339](#bib.bib339)] | Smoldering and flaming
    combustion identification | MLP | SGD | Achieves high accuracy in detecting fire
    in forests using smoke, $CO_{2}$ and temperature sensors |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[340](#bib.bib340)] | Temperature correction | MLP | SGD |
    Employs deep learning to learn correlation between polar radiation and air temperature
    error |'
  prefs: []
  type: TYPE_TB
- en: '| Lee *et al.* [[341](#bib.bib341)] | Online query processing | CNN | Unknown
    | Employs adaptive query refinement to enable real-time analysis |'
  prefs: []
  type: TYPE_TB
- en: '| Li and Serpen [[342](#bib.bib342)] | Self-adaptive WSN | Hopfield network
    | Unknown | Embedding Hopfield NNs as a static optimizer for the weakly-connected
    dominating problem |'
  prefs: []
  type: TYPE_TB
- en: '| Khorasani and Naji [[343](#bib.bib343)] | Data aggregation | MLP | Unknown
    | Improves the energy efficiency in the aggregation process |'
  prefs: []
  type: TYPE_TB
- en: '| Li *et al.* [[344](#bib.bib344)] | Distributed data mining | MLP | Unknown
    | Distributed data mining |'
  prefs: []
  type: TYPE_TB
- en: '| Luo and Nagarajany [[345](#bib.bib345)] | Distributed WSN anomaly detection
    | AE | SGD | Employs distributed anomaly detection techniques to offload computations
    from the cloud |'
  prefs: []
  type: TYPE_TB
- en: '| Other | Heydari *et al.* [[347](#bib.bib347)] | Energy consumption optimization
    and secure communication in wireless multimedia sensor networks | Stacked AE |
    Unknown | Use deep learning to enable fast data transfer and reduce energy consumption
    |'
  prefs: []
  type: TYPE_TB
- en: '| Mehmood *et al.* [[352](#bib.bib352)] | Robust routing for pollution monitoring
    in WSNs | MLP | SGD | Highly energy-efficient |'
  prefs: []
  type: TYPE_TB
- en: '| Alsheikh *et al.* [[353](#bib.bib353)] | Rate-distortion balanced data compression
    for WSNs | AE | Limited memory Broyden Fletcher Goldfarb Shann algorithm | Energy-efficient
    and bounded reconstruction errors |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[355](#bib.bib355)] | Blind drift calibration for WSNs | Projection-recovery
    network (CNN based) | Adam | Exploits spatial and temporal correlations of data
    from all sensors; first work that adopts deep learning in WSN data calibration
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Jia *et al.* [[356](#bib.bib356)] | Ammonia monitoring | LSTM | Adam |
    Low-power and accurate ammonia monitoring |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/b28b0f4868157b06c5f2baa78dcccf97.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: An example framework for WSN data collection and (centralized and
    decentralized) analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Wireless Sensor Networks (WSNs) consist of a set of unique or heterogeneous
    sensors that are distributed over geographical regions. Theses sensors collaboratively
    monitor physical or environment status (e.g. temperature, pressure, motion, pollution,
    etc.) and transmit the data collected to centralized servers through wireless
    channels (see top circle in Fig. [9](#S6.F9 "Figure 9 ‣ VI-A Mobile Big Data as
    a Prerequisite ‣ VI Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey") for an illustration). A WSN typically
    involves three key core tasks, namely sensing, communication and analysis. Deep
    learning is becoming increasingly popular also for WSN applications [[346](#bib.bib346)].
    In what follows, we review works adopting deep learning in this domain, covering
    different angles, namely: centralized vs. decentralized analysis paradigms, WSN
    data analysis per se, WSN localization, and other applications. Note that the
    contributions of these works are distinct from mobile data analysis discussed
    in subsections [VI-B](#S6.SS2 "VI-B Deep Learning Driven Network-level Mobile
    Data Analysis ‣ VI Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey") and [VI-C](#S6.SS3 "VI-C Deep Learning
    Driven App-level Mobile Data Analysis ‣ VI Deep Learning Driven Mobile and Wireless
    Networks ‣ Deep Learning in Mobile and Wireless Networking: A Survey"), as in
    this subsection we only focus on WSN applications. We begin by summarizing the
    most important works in Table [XV](#S6.T15 "TABLE XV ‣ VI-F Deep Learning Driven
    Wireless Sensor Networks ‣ VI Deep Learning Driven Mobile and Wireless Networks
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Centralized vs Decentralized Analysis Approaches: There exist two data processing
    scenarios in WSNs, namely centralized and decentralized. The former simply takes
    sensors as data collectors, which are only responsible for gathering data and
    sending these to a central location for processing. The latter assumes sensors
    have some computational ability and the main server offloads part of the jobs
    to the edge, each sensor performing data processing individually. We show an example
    framework for WSN data collection and analysis in Fig. [16](#S6.F16 "Figure 16
    ‣ VI-F Deep Learning Driven Wireless Sensor Networks ‣ VI Deep Learning Driven
    Mobile and Wireless Networks ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey"), where sensor data is collected via various nodes in a field of interest.
    Such data is delivered to a sink node, which aggregates and optionally further
    processes this. Work in [[343](#bib.bib343)] focuses on the centralized approach
    and the authors apply a 3-layer MLP to reduce data redundancy while maintaining
    essential points for data aggregation. These data are sent to a central server
    for analysis. In contrast, Li *et al.* propose to distribute data mining to individual
    sensors [[344](#bib.bib344)]. They partition a deep neural network into different
    layers and offload layer operations to sensor nodes. Simulations conducted suggest
    that, by pre-processing with NNs, their framework obtains high fault detection
    accuracy, while reducing power consumption at the central server.'
  prefs: []
  type: TYPE_NORMAL
- en: 'WSN Localization: Localization is also an important and challeging task in
    WSNs. Chuang and Jiang exploit neural networks to localize sensor nodes in WSNs
    [[335](#bib.bib335)]. To adapt deep learning models to specific network topology,
    they employ an online training scheme and correlated topology-trained data, enabling
    efficient model implementations and accurate location estimation. Based on this,
    Bernas and Płaczek architect an ensemble system that involves multiple MLPs for
    location estimation in different regions of interest [[336](#bib.bib336)]. In
    this scenario, node locations inferred by multiple MLPs are fused by a fusion
    algorithm, which improves the localization accuracy, particularly benefiting sensor
    nodes that are around the boundaries of regions. A comprehensive comparison of
    different training algorithms that apply MLP-based node localization is presented
    in [[337](#bib.bib337)]. Experiments suggest that the Bayesian regularization
    algorithm in general yields the best performance. Dong *et al.* consider an underwater
    node localization scenario [[338](#bib.bib338)]. Since acoustic signals are subject
    to loss caused by absorption, scattering, noise, and interference, underwater
    localization is not straightforward. By adopting a deep neural network, their
    framework successfully addresses the aforementioned challenges and achieves higher
    inference accuracy as compared to SVM and generalized least square methods.'
  prefs: []
  type: TYPE_NORMAL
- en: Phoemphon *et al.* [[348](#bib.bib348)] combine a fuzzy logic system and an
    ELM via a particle swarm optimization technique to achieve robust range-free location
    estimation for sensor nodes. In particular, the fuzzy logic system is employed
    for adjusting the weight of traditional centroids, while the ELM is used for optimization
    for the localization precision. Their method achieves superior accuracy over other
    soft computing-based approaches. Similarly, Banihashemian *et al.* employ the
    particle swarm optimization technique combining with MLPs to perform range-free
    WSN localization, which achieves low localization error [[349](#bib.bib349)].
    Kang *et al.* shed light water leakage and localization in water distribution
    systems [[351](#bib.bib351)]. They represent the water pipeline network as a graph
    and assume leakage events occur at vertices. They combine CNN with SVM to perform
    detection and localization on wireless sensor network testbed, achieving 99.3%
    leakage detection accuracy and localization error for less than 3 meters.
  prefs: []
  type: TYPE_NORMAL
- en: 'WSN Data Analysis: Deep learning has also been exploited for identification
    of smoldering and flaming combustion phases in forests. In [[339](#bib.bib339)],
    Yan *et al.* embed a set of sensors into a forest to monitor CO[2], smoke, and
    temperature. They suggest that various burning scenarios will emit different gases,
    which can be taken into account when classifying smoldering and flaming combustion.
    Wang *et al.* consider deep learning to correct inaccurate measurements of air
    temperature [[340](#bib.bib340)]. They discover a close relationship between solar
    radiation and actual air temperature, which can be effectively learned by neural
    networks. In [[350](#bib.bib350)], Sun *et al.* employ a Wavelet neural network
    based solution to evaluate radio link quality in WSNs on smart grids. Their proposal
    is more precise than traditional approaches and can provide end-to-end reliability
    guarantees to smart grid applications.'
  prefs: []
  type: TYPE_NORMAL
- en: Missing data or de-synchronization are common in WSN data collection. These
    may lead to serious problems in analysis due to inconsistency. Lee *et al.* address
    this problem by plugging a query refinement component in deep learning based WSN
    analysis systems [[341](#bib.bib341)]. They employ exponential smoothing to infer
    missing data, thereby maintaining the integrity of data for deep learning analysis
    without significantly compromising accuracy. To enhance the intelligence of WSNs,
    Li and Serpen embed an artificial neural network into a WSN, allowing it to agilely
    react to potential changes and following deployment in the field [[342](#bib.bib342)].
    To this end, they employ a minimum weakly-connected dominating set to represent
    the WSN topology, and subsequently use a Hopfield recurrent neural network as
    a static optimizer, to adapt network infrastructure to potential changes as necessary.
    This work represents an important step towards embedding machine intelligence
    in WSNs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other Applications:  The benefits of deep learning have also been demonstrated
    in other WSN applications. The work in [[347](#bib.bib347)] focuses on reducing
    energy consumption while maintaining security in wireless multimedia sensor networks.
    A stacked AE is employed to categorize images in the form of continuous pieces,
    and subsequently send the data over the network. This enables faster data transfer
    rates and lower energy consumption. Mehmood *et al.* employ MLPs to achieve robust
    routing in WSNs, so as to facilitate pollution monitoring [[352](#bib.bib352)].
    Their proposal use the NN to provide an efficiency threshold value and switch
    nodes that consume less energy than this threshold, thereby improving energy efficiency.
    Alsheikh *et al.* introduce an algorithm for WSNs that uses AEs to minimize the
    energy expenditure [[353](#bib.bib353)]. Their architecture exploits spatio-temporal
    correlations to reduce the dimensions of raw data and provides reconstruction
    error bound guarantees.'
  prefs: []
  type: TYPE_NORMAL
- en: Wang *et al.* design a dedicated projection-recovery neural network to blindly
    calibrate sensor measurements in an online manner [[355](#bib.bib355)]. Their
    proposal can automatically extract features from sensor data and exploit spatial
    and temporal correlations among information from all sensors, to achieve high
    accuracy. This is the first effort that adopts deep learning in WSN data calibration.
    Jia *et al.* shed light on ammonia monitoring using deep learning [[356](#bib.bib356)].
    In their design, an LSTM is employed to predict the sensors’ electrical resistance
    during a very short heating pulse, without waiting for settling in an equilibrium
    state. This dramatically reduces the energy consumption of sensors in the waiting
    process. Experiments with 38 prototype sensors and a home-built gas flow system
    show that the proposed LSTM can deliver precise prediction of equilibrium state
    resistance under different ammonia concentrations, cutting down the overall energy
    consumption by approximately 99.6%.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lessons learned: The centralized and decentralized WSN data analysis paradigms
    resemble the cloud and fog computing philosophies in other areas. Decentralized
    methods exploit the computing ability of sensor nodes and perform light processing
    and analysis locally. This offloads the burden on the cloud and significantly
    reduces the data transmission overheads and storage requirements. However, at
    the moment, the centralized approach dominates the WSN data analysis landscape.
    As deep learning implementation on embedded devices becomes more accessible, in
    the future we expect to witness a grow in the popularity of the decentralized
    schemes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, looking at Table [XV](#S6.T15 "TABLE XV ‣ VI-F Deep Learning
    Driven Wireless Sensor Networks ‣ VI Deep Learning Driven Mobile and Wireless
    Networks ‣ Deep Learning in Mobile and Wireless Networking: A Survey"), it is
    interesting to see that the majority of deep learning practices in WSNs employ
    MLP models. Since MLP is straightforward to architect and performs reasonably
    well, it remains a good candidate for WSN applications. However, since most sensor
    data collected is sequential, we expect RNN-based models will play a more important
    role in this area.'
  prefs: []
  type: TYPE_NORMAL
- en: VI-G Deep Learning Driven Network Control
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this part, we turn our attention to mobile network control problems. Due
    to powerful function approximation mechanism, deep learning has made remarkable
    breakthroughs in improving traditional reinforcement learning [[26](#bib.bib26)]
    and imitation learning [[490](#bib.bib490)]. These advances have potential to
    solve mobile network control problems which are complex and previously considered
    intractable [[491](#bib.bib491), [492](#bib.bib492)]. Recall that in reinforcement
    learning, an agent continuously interacts with the environment to learn the best
    action. With constant exploration and exploitation, the agent learns to maximize
    its expected return. Imitation learning follows a different learning paradigm
    called “learning by demonstration”. This learning paradigm relies on a ‘teacher’
    who tells the agent what action should be executed under certain observations
    during the training. After sufficient demonstrations, the agent learns a policy
    that imitates the behavior of the teacher and can operate standalone without supervision.
    For instance, an agent is trained to mimic human behaviour (e.g., in applications
    such as game play, self-driving vehicles, or robotics), instead of learning by
    interacting with the environment, as in the case of pure reinforcement learning.
    This is because in such applications, making mistakes can have fatal consequences [[27](#bib.bib27)].
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/927a6afb81b232b340a2917053e770bb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17: Principles of three control approaches applied in mobile and wireless
    networks control, namely reinforcement learning (above), imitation learning (middle),
    and analysis-based control (below).'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE XVI: A summary of work on deep learning driven network control.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Domain | Reference | Application | Control approach | Model |'
  prefs: []
  type: TYPE_TB
- en: '| Network optimization | Liu *et al.* [[357](#bib.bib357)] | Demand constrained
    energy minimization | Analysis-based | DBN |'
  prefs: []
  type: TYPE_TB
- en: '| Subramanian and Banerjee [[358](#bib.bib358)] | Machine to machine system
    optimization | Analysis-based | Deep multi-modal network |'
  prefs: []
  type: TYPE_TB
- en: '| He *et al.* [[359](#bib.bib359), [360](#bib.bib360)] | Caching and interference
    alignment | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Masmar and Evans [[361](#bib.bib361)] | mmWave Communication performance
    optimization | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[362](#bib.bib362)] | Handover optimization in wireless systems
    | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Chen and Smith [[363](#bib.bib363)] | Cellular network random access optimization
    | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Chen *et al.* [[364](#bib.bib364)] | Automatic traffic optimization | Reinforcement
    learning | Deep policy gradient |'
  prefs: []
  type: TYPE_TB
- en: '| Routing | Lee *et al.* [[365](#bib.bib365)] | Virtual route assignment |
    Analysis-based | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Yang *et al.* [[293](#bib.bib293)] | Routing optimization | Analysis-based
    | Hopfield neural networks |'
  prefs: []
  type: TYPE_TB
- en: '| Mao *et al.* [[186](#bib.bib186)] | Software defined routing | Imitation
    learning | DBN |'
  prefs: []
  type: TYPE_TB
- en: '| Tang *et al.* [[366](#bib.bib366)] | Wireless network routing | Imitation
    learning | CNN |'
  prefs: []
  type: TYPE_TB
- en: '|  | Mao *et al.* [[394](#bib.bib394)] | Intelligent packet routing | Imitation
    learning | Tensor-based DBN |'
  prefs: []
  type: TYPE_TB
- en: '|  | Geyer *et al.* [[395](#bib.bib395)] | Distributed routing | Imitation
    learning | Graph-query neural network |'
  prefs: []
  type: TYPE_TB
- en: '|  | Pham *et al.* [[402](#bib.bib402)] | Routing for knowledge-defined networking
    | Reinforcement learning | Deep Deterministic Policy Gradient |'
  prefs: []
  type: TYPE_TB
- en: '| Scheduling | Zhang *et al.* [[367](#bib.bib367)] | Hybrid dynamic voltage
    and frequency scaling scheduling | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Atallah *et al.* [[368](#bib.bib368)] | Roadside communication network scheduling
    | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Chinchali *et al.* [[369](#bib.bib369)] | Cellular network traffic scheduling
    | Reinforcement learning | Policy gradient |'
  prefs: []
  type: TYPE_TB
- en: '| Atallah *et al.* [[368](#bib.bib368)] | Roadside communications networks
    scheduling | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Wei *et al.* [[370](#bib.bib370)] | User scheduling and content caching for
    mobile edge networks | Reinforcement learning | Deep policy gradient |'
  prefs: []
  type: TYPE_TB
- en: '|  | Mennes *et al.* [[392](#bib.bib392)] | Predicting free slots in a Multiple
    Frequencies Time Division Multiple Access (MF-TDMA) network. | Imitation learning
    | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Resource allocation | Sun *et al.* [[371](#bib.bib371)] | Resource management
    over wireless networks | Imitation learning | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Xu *et al.* [[372](#bib.bib372)] | Resource allocation in cloud radio access
    networks | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Ferreira *et al.* [[373](#bib.bib373)] | Resource management in cognitive
    communications | Reinforcement learning | Deep SARSA |'
  prefs: []
  type: TYPE_TB
- en: '| Challita *et al.* [[375](#bib.bib375)] | Proactive resource management for
    LTE | Reinforcement learning | Deep policy gradient |'
  prefs: []
  type: TYPE_TB
- en: '| Ye and Li [[374](#bib.bib374)] | Resource allocation in vehicle-to-vehicle
    communication | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Li *et al.* [[391](#bib.bib391)] | Computation offloading and resource allocation
    for mobile edge computing | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '|  | Zhou *et al.* [[393](#bib.bib393)] | Radio resource assignment | Analysis-based
    | LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Radio control | Naparstek and Cohen [[376](#bib.bib376)] | Dynamic spectrum
    access | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| O’Shea and Clancy [[377](#bib.bib377)] | Radio control and signal detection
    | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Wijaya *et al.* [[378](#bib.bib378), [380](#bib.bib380)] | Intercell-interference
    cancellation and transmit power optimization | Imitation learning | RBM |'
  prefs: []
  type: TYPE_TB
- en: '| Rutagemwa *et al.* [[379](#bib.bib379)] | Dynamic spectrum alignment | Analysis-based
    | RNN |'
  prefs: []
  type: TYPE_TB
- en: '|  | Yu *et al.* [[387](#bib.bib387)] | Multiple access for wireless network
    | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '|  | Li *et al.* [[397](#bib.bib397)] | Power control for spectrum sharing
    in cognitive radios | Reinforcement learning | DQN |'
  prefs: []
  type: TYPE_TB
- en: '|  | Liu *et al.* [[401](#bib.bib401)] | Anti-jamming communications in dynamic
    and unknown environment | Reinforcement learning | DQN |'
  prefs: []
  type: TYPE_TB
- en: '|  | Luong *et al.* [[396](#bib.bib396)] | Transaction transmission and channel
    selection in cognitive radio blockchain | Reinforcement learning | Double DQN
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Ferreira *et al.* [[493](#bib.bib493)] | Radio transmitter settings selection
    in satellite communications | Reinforcement learning | Deep multi-objective reinforcement
    learning |'
  prefs: []
  type: TYPE_TB
- en: '| Other | Mao *et al.* [[381](#bib.bib381)] | Adaptive video bitrate | Reinforcement
    learning | A3C |'
  prefs: []
  type: TYPE_TB
- en: '| Oda *et al.* [[382](#bib.bib382), [383](#bib.bib383)] | Mobile actor node
    control | Reinforcement learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Kim [[384](#bib.bib384)] | IoT load balancing | Analysis-based | DBN |'
  prefs: []
  type: TYPE_TB
- en: '| Challita *et al.* [[385](#bib.bib385)] | Path planning for aerial vehicle
    networking | Reinforcement learning | Multi-agent echo state networks |'
  prefs: []
  type: TYPE_TB
- en: '| Luo *et al.* [[386](#bib.bib386)] | Wireless online power control | Reinforcement
    learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Xu *et al.* [[388](#bib.bib388)] | Traffic engineering | Reinforcement learning
    | Deep policy gradient |'
  prefs: []
  type: TYPE_TB
- en: '| Liu *et al.* [[389](#bib.bib389)] | Base station sleep control | Reinforcement
    learning | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Zhao *et al.* [[390](#bib.bib390)] | Network slicing | Reinforcement learning
    | Deep Q learning |'
  prefs: []
  type: TYPE_TB
- en: '| Zhu *et al.* [[234](#bib.bib234)] | Mobile edge caching | Reinforcement learning
    | A3C |'
  prefs: []
  type: TYPE_TB
- en: '|  | Liu *et al.* [[399](#bib.bib399)] | Unmanned aerial vehicles control |
    Reinforcement learning | DQN |'
  prefs: []
  type: TYPE_TB
- en: '|  | Lee *et al.* [[398](#bib.bib398)] | Transmit power Control in device-to-device
    communications | Imitation learning | MLP |'
  prefs: []
  type: TYPE_TB
- en: '|  | He *et al.* [[400](#bib.bib400)] | Dynamic orchestration of networking,
    caching, and computing | Reinforcement learning | DQN |'
  prefs: []
  type: TYPE_TB
- en: 'Beyond these two approaches, analysis-based control is gaining traction in
    mobile networking. Specifically, this scheme uses ML models for network data analysis,
    and subsequently exploits the results to aid network control. Unlike reinforcement/imitation
    learning, analysis-based control does not directly output actions. Instead, it
    extract useful information and delivers this to an agent, to execute the actions.
    We illustrate the principles between the three control paradigms in Fig. [17](#S6.F17
    "Figure 17 ‣ VI-G Deep Learning Driven Network Control ‣ VI Deep Learning Driven
    Mobile and Wireless Networks ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey"). We review works proposed so far in this space next, and summarize
    these efforts in Table [XVI](#S6.T16 "TABLE XVI ‣ VI-G Deep Learning Driven Network
    Control ‣ VI Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Network Optimization refers to the management of network resources and functions
    in a given environment, with the goal of improving the network performance. Deep
    learning has recently achieved several successful results in this area. For example,
    Liu *et al.* exploit a DBN to discover the correlations between multi-commodity
    flow demand information and link usage in wireless networks [[357](#bib.bib357)].
    Based on the predictions made, they remove the links that are unlikely to be scheduled,
    so as to reduce the size of data for the demand constrained energy minimization.
    Their method reduces runtime by up to 50%, without compromising optimality. Subramanian
    and Banerjee propose to use deep learning to predict the health condition of heterogeneous
    devices in machine to machine communications [[358](#bib.bib358)]. The results
    obtained are subsequently exploited for optimizing health aware policy change
    decisions.
  prefs: []
  type: TYPE_NORMAL
- en: He *et al.* employ deep reinforcement learning to address caching and interference
    alignment problems in wireless networks [[359](#bib.bib359), [360](#bib.bib360)].
    In particular, they treat time-varying channels as finite-state Markov channels
    and apply deep Q networks to learn the best user selection policy. This novel
    framework demonstrates significantly higher sum rate and energy efficiency over
    existing approaches. Chen *et al.* shed light on automatic traffic optimization
    using a deep reinforcement learning approach [[364](#bib.bib364)]. Specifically,
    they architect a two-level DRL framework, which imitates the Peripheral and Central
    Nervous Systems in animals, to address scalability problems at datacenter scale.
    In their design, multiple peripheral systems are deployed on all end-hosts, so
    as to make decisions locally for short traffic flows. A central system is further
    employed to decide on the optimization with long traffic flows, which are more
    tolerant to longer delay. Experiments in a testbed with 32 severs suggest that
    the proposed design reduces the traffic optimization turn-around time and flow
    completion time significantly, compared to existing approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 'Routing: Deep learning can also improve the efficiency of routing rules. Lee
    *et al.* exploit a 3-layer deep neural network to classify node degree, given
    detailed information of the routing nodes [[365](#bib.bib365)]. The classification
    results along with temporary routes are exploited for subsequent virtual route
    generation using the Viterbi algorithm. Mao *et al.* employ a DBN to decide the
    next routing node and construct a software defined router [[186](#bib.bib186)].
    By considering Open Shortest Path First as the optimal routing strategy, their
    method achieves up to 95% accuracy, while reducing significantly the overhead
    and delay, and achieving higher throughput with a signaling interval of 240 milliseconds.
    In follow up work, the authors use tensors to represent hidden layers, weights
    and biases in DBNs, which further improves the routing performance [[394](#bib.bib394)].'
  prefs: []
  type: TYPE_NORMAL
- en: A similar outcome is obtained in [[293](#bib.bib293)], where the authors employ
    Hopfield neural networks for routing, achieving better usability and survivability
    in mobile ad hoc network application scenarios. Geyer *et al.* represent the network
    using graphs, and design a dedicated Graph-Query NN to address the distributed
    routing problem [[395](#bib.bib395)]. This novel architecture takes graphs as
    input and uses message passing between nodes in the graph, allowing it to operate
    with various network topologies. Pham *et al.* shed light on routing protocols
    in knowledge-defined networking, using a Deep Deterministic Policy Gradient algorithm
    based on reinforcement learning [[402](#bib.bib402)]. Their agent takes traffic
    conditions as input and incorporates QoS into the reward function. Simulations
    show that their framework can effectively learn the correlations between traffic
    flows, which leads to better routing configurations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scheduling: There are several studies that investigate scheduling with deep
    learning. Zhang *et al.* introduce a deep Q learning-powered hybrid dynamic voltage
    and frequency scaling scheduling mechanism, to reduce the energy consumption in
    real-time systems (e.g. Wi-Fi, IoT, video applications) [[367](#bib.bib367)].
    In their proposal, an AE is employed to approximate the Q function and the framework
    performs experience replay [[494](#bib.bib494)] to stabilize the training process
    and accelerate convergence. Simulations demonstrate that this method reduces by
    4.2% the energy consumption of a traditional Q learning based method. Similarly,
    the work in [[368](#bib.bib368)] uses deep Q learning for scheduling in roadside
    communications networks. In particular, interactions between vehicular environments,
    including the sequence of actions, observations, and reward signals are formulated
    as an MDP. By approximating the Q value function, the agent learns a scheduling
    policy that achieves lower latency and busy time, and longer battery life, compared
    to traditional scheduling methods.'
  prefs: []
  type: TYPE_NORMAL
- en: More recently, Chinchali *et al.* present a policy gradient based scheduler
    to optimize the cellular network traffic flow [[369](#bib.bib369)]. Specifically,
    they cast the scheduling problem as a MDP and employ RF to predict network throughput,
    which is subsequently used as a component of a reward function. Evaluations with
    a realistic network simulator demonstrate that this proposal can dynamically adapt
    to traffic variations, which enables mobile networks to carry 14.7% more data
    traffic, while outperforming heuristic schedulers by more than 2$\times$. Wei
    *et al.* address user scheduling and content caching simultaneously [[370](#bib.bib370)].
    In particular, they train a DRL agent, consisting of an actor for deciding which
    base station should serve certain content, and whether to save the content. A
    critic is further employed to estimate the value function and deliver feedback
    to the actor. Simulations over a cluster of base stations show that the agent
    can yield low transmission delay. Li *et al.* shed light on resource allocation
    in a multi-user mobile computing scenario [[391](#bib.bib391)]. They employ a
    deep Q learning framework to jointly optimize the offloading decision and computational
    resource allocation, so as to minimize the sum cost of delay and energy consumption
    of all user equipment. Simulations show that their proposal can reduce the total
    cost of the system, as compared to fully-local, fully-offloading, and naive Q-learning
    approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 'Resource Allocation: Sun *et al.* use a deep neural network to approximate
    the mapping between the input and output of the Weighted Minimum Mean Square Error
    resource allocation algorithm [[495](#bib.bib495)], in interference-limited wireless
    network environments [[371](#bib.bib371)]. By effective imitation learning, the
    neural network approximation achieves close performance to that of its teacher.
    Deep learning has also been applied to cloud radio access networks, Xu *et al.*
    employing deep Q learning to determine the on/off modes of remote radio heads
    given, the current mode and user demand [[372](#bib.bib372)]. Comparisons with
    single base station association and fully coordinated association methods suggest
    that the proposed DRL controller allows the system to satisfy user demand while
    requiring significantly less energy.'
  prefs: []
  type: TYPE_NORMAL
- en: Ferreira *et al.* employ deep State-Action-Reward-State-Action (SARSA) to address
    resource allocation management in cognitive communications [[373](#bib.bib373)].
    By forecasting the effects of radio parameters, this framework avoids wasted trials
    of poor parameters, which reduces the computational resources required. In [[392](#bib.bib392)],
    Mennes *et al.* employ MLPs to precisely forecast free slots prediction in a Multiple
    Frequencies Time Division Multiple Access (MF-TDMA) network, thereby achieving
    efficient scheduling. The authors conduct simulations with a network deployed
    in a 100$\times$100 room, showing that their solution can effectively reduces
    collisions by half. Zhou *et al.* adopt LSTMs to predict traffic load at base
    stations in ultra dense networks [[393](#bib.bib393)]. Based on the predictions,
    their method changes the resource allocation policy to avoid congestion, which
    leads to lower packet loss rates, and higher throughput and mean opinion scores.
  prefs: []
  type: TYPE_NORMAL
- en: 'Radio Control: In [[376](#bib.bib376)], the authors address the dynamic spectrum
    access problem in multichannel wireless network environments using deep reinforcement
    learning. In this setting, they incorporate an LSTM into a deep Q network, to
    maintain and memorize historical observations, allowing the architecture to perform
    precise state estimation, given partial observations. The training process is
    distributed to each user, which enables effective training parallelization and
    the learning of good policies for individual users. Experiments demonstrate that
    this framework achieves double the channel throughput, when compared to a benchmark
    method. Yu *et al.* apply deep reinforcement learning to address challenges in
    wireless multiple access control [[387](#bib.bib387)], recognizing that in such
    tasks DRL agents are fast in terms of convergence and robust against non-optimal
    parameter settings. Li *et al.* investigate power control for spectrum sharing
    in cognitive radios using DRL. In their design, a DQN agent is built to adjust
    the transmit power of a cognitive radio system, such that the overall signal-to-interference-plus-noise
    ratio is maximized.'
  prefs: []
  type: TYPE_NORMAL
- en: The work in [[377](#bib.bib377)] sheds light on the radio control and signal
    detection problems. In particular, the authors introduce a radio signal search
    environment based on the Gym Reinforcement Learning platform. Their agent exhibits
    a steady learning process and is able to learn a radio signal search policy. Rutagemwa
    *et al.* employ an RNN to perform traffic prediction, which can subsequently aid
    the dynamic spectrum assignment in mobile networks [[379](#bib.bib379)]. With
    accurate traffic forecasting, their proposal improves the performance of spectrum
    sharing in dynamic wireless environments, as it attains near-optimal spectrum
    assignments. In [[401](#bib.bib401)], Liu *et al.* approach the anti-jamming communications
    problem in dynamic and unknown environments with a DRL agent. Their system is
    based on a DQN with CNN, where the agent takes raw spectrum information as input
    and requires limited prior knowledge about the environment, in order to improve
    the overall throughput of the network in such adversarial circumstances.
  prefs: []
  type: TYPE_NORMAL
- en: Luong *et al.* incorporate the blockchain technique into cognitive radio networking [[396](#bib.bib396)],
    employing a double DQN agent to maximize the number of successful transaction
    transmissions for secondary users, while minimizing the channel cost and transaction
    fees. Simulations show that the DQN method significantly outperforms na ive Q
    learning in terms of successful transactions, channel cost, and learning speed.
    DRL can further attack problems in the satellite communications domain. In [[493](#bib.bib493)],
    Ferreira *et al.* fuse multi-objective reinforcement learning [[403](#bib.bib403)]
    with deep neural networks to select among multiple radio transmitter settings
    while attempting to achieve multiple conflicting goals, in a dynamically changing
    satellite communications channel. Specifically, two set of NNs are employed to
    execute exploration and exploitation separately. This builds an ensembling system,
    with makes the framework more robust to the changing environment. Simulations
    demonstrate that their system can nearly optimize six different objectives (i.e.
    bit error rate, throughput, bandwidth, spectral efficiency, additional power consumption,
    and power efficiency), only with small performance errors compared to ideal solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other applications: Deep learning is playing an important role in other network
    control problems as well. Mao *et al.* develop the Pensieve system that generates
    adaptive video bit rate algorithms using deep reinforcement learning [[381](#bib.bib381)].
    Specifically, Pensieve employs a state-of-the-art deep reinforcement learning
    algorithm A3C, which takes the bandwidth, bit rate and buffer size as input, and
    selects the bit rate that leads to the best expected return. The model is trained
    offline and deployed on an adaptive bit rate server, demonstrating that the system
    outperforms the best existing scheme by 12%-25% in terms of QoE. Liu *et al.*
    apply deep Q learning to reduce the energy consumption in cellular networks [[389](#bib.bib389)].
    They train an agent to dynamically switch on/off base stations based on traffic
    consumption in areas of interest. An action-wise experience replay mechanism is
    further designed for balancing different traffic behaviours. Experiments show
    that their proposal can significantly reduce the energy consumed by base stations,
    outperforming naive table-based Q learning approaches. A control mechanism for
    unmanned aerial vehicles using DQN is proposed in [[399](#bib.bib399)], where
    multiple objectives are targeted: maximizing energy efficiency, communications
    coverage, fairness and connectivity. The authors conduct extensive simulations
    in an virtual playground, showing that their agent is able to learn the dynamics
    of the environment, achieving superior performance over random and greedy control
    baselines.'
  prefs: []
  type: TYPE_NORMAL
- en: Kim and Kim link deep learning with the load balancing problem in IoT [[384](#bib.bib384)].
    The authors suggest that DBNs can effectively analyze network load and process
    structural configuration, thereby achieving efficient load balancing in IoT. Challita
    *et al.* employ a deep reinforcement learning algorithm based on echo state networks
    to perform path planning for a cluster of unmanned aerial vehicles [[385](#bib.bib385)].
    Their proposal yields lower delay than a heuristic baseline. Xu *et al.* employ
    a DRL agent to learn from network dynamics how to control traffic flow [[388](#bib.bib388)].
    They advocate that DRL is suitable for this problem, as it performs remarkably
    well in handling dynamic environments and sophisticated state spaces. Simulations
    conducted over three network topologies confirm this viewpoint, as the DRL agent
    significantly reduces the delay, while providing throughput comparable to that
    of traditional approaches. Zhu *et al.* employ the A3C algorithm to address the
    caching problem in mobile edge computing. Their method obtains superior cache
    hit ratios and traffic offloading performance over three baselines caching methods.
    Several open challenges are also pointed out, which are worthy of future pursuit.
    The edge caching problem is also addressed in [[400](#bib.bib400)], where He *et
    al.* architect a DQN agent to perform dynamic orchestration of networking, caching,
    and computing. Their method facilitates high revenue to mobile virtual network
    operators.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lessons learned: There exist three approaches to network control using deep
    learning i.e., reinforcement learning, imitation learning, and analysis-based
    control. Reinforcement learning requires to interact with the environment, trying
    different actions and obtaining feedback in order to improve. The agent will make
    mistakes during training, and usually needs a large number of steps of steps to
    become smart. Therefore, most works do not train the agent on the real infrastructure,
    as making mistakes usually can have serious consequences for the network. Instead,
    a simulator that mimics the real network environments is built and the agent is
    trained offline using that. This imposes high fidelity requirements on the simulator,
    as the agent can not work appropriately in an environment that is different from
    the one used for training. On the other hand, although DRL performs remarkable
    well in many applications, considerable amount of time and computing resources
    are required to train an usable agent. This should be considered in real-life
    implementation.'
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, the imitation learning mechanism “learns by demonstration”. It
    requires a teacher that provides labels telling the agent what it should do under
    certain circumstances. In the networking context, this mechanism is usually employed
    to reduce the computational time [[186](#bib.bib186)]. Specifically, in some network
    application (e.g., routing), computing the optimal solution is time-consuming,
    which cannot satisfy the delay constraints of mobile network. To mitigate this,
    one can generate a large dataset offline, and use an NN agent to learn the optimal
    actions.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis-based control on the other hand, is suitable for problems were decisions
    cannot be based solely on the state of the network environment. One can use a
    NN to extract additional information (e.g. traffic forecasts), which subsequently
    aids decisions. For example, the dynamic spectrum assignment can benefit from
    the analysis-based control.
  prefs: []
  type: TYPE_NORMAL
- en: VI-H Deep Learning Driven Network Security
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the increasing popularity of wireless connectivity, protecting users, network
    equipment and data from malicious attacks, unauthorized access and information
    leakage becomes crucial. Cyber security systems guard mobile devices and users
    through firewalls, anti-virus software, and Intrusion Detection Systems (IDS)
    [[496](#bib.bib496)]. The firewall is an access security gateway that allows or
    blocks the uplink and downlink network traffic, based on pre-defined rules. Anti-virus
    software detects and removes computer viruses, worms and Trojans and malware.
    IDSs identify unauthorized and malicious activities, or rule violations in information
    systems. Each performs its own functions to protect network communication, central
    servers and edge devices.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE XVII: A summary of work on deep learning driven network security.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Level | Reference | Application | Problem considered | Learning paradigm
    | Model |'
  prefs: []
  type: TYPE_TB
- en: '| Infrastructure | Azar *et al.* [[404](#bib.bib404)] | Cyber security applications
    | Malware classification & Denial of service, probing, remote to user & user to
    root | Unsupervised & supervised | Stacked AE |'
  prefs: []
  type: TYPE_TB
- en: '| Thing [[185](#bib.bib185)] | IEEE 802.11 network anomaly detection and attack
    classification | Flooding, injection and impersonation attacks | Unsupervised
    & supervised | Stacked AE |'
  prefs: []
  type: TYPE_TB
- en: '| Aminanto and Kim [[405](#bib.bib405)] | Wi-Fi impersonation attacks detection
    | Flooding, injection and impersonation attacks | Unsupervised & supervised |
    MLP, AE |'
  prefs: []
  type: TYPE_TB
- en: '| Feng *et al.* [[406](#bib.bib406)] | Spectrum anomaly detection | Sudden
    signal-to-noise ratio changes in the communication channels | Unsupervised & supervised
    | AE |'
  prefs: []
  type: TYPE_TB
- en: '| Khan *et al.* [[407](#bib.bib407)] | Flooding attacks detection in wireless
    mesh networks | Moderate and severe distributed flood attack | Supervised | MLP
    |'
  prefs: []
  type: TYPE_TB
- en: '| Diro and Chilamkurti [[408](#bib.bib408)] | IoT distributed attacks detection
    | Denial of service, probing, remote to user & user to root | Supervised | MLP
    |'
  prefs: []
  type: TYPE_TB
- en: '| Saied *et al.* [[409](#bib.bib409)] | Distributed denial of service attack
    detection | Known and unknown distributed denial of service attack | Supervised
    | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Martin *et al.* [[410](#bib.bib410)] | IoT intrusion detection | Denial of
    service, probing, remote to user & user to root | Unsupervised & supervised |
    Conditional VAE |'
  prefs: []
  type: TYPE_TB
- en: '| Hamedani *et al.* [[411](#bib.bib411)] | Attacks detection in delayed feedback
    networks | Attack detection in smart grids using reservoir computing | Supervised
    | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Luo and Nagarajany [[345](#bib.bib345)] | Anomalies in WSNs | Spikes and
    burst recorded by temperature and relative humidity sensors | Unsupervised | AE
    |'
  prefs: []
  type: TYPE_TB
- en: '| Das *et al.* [[412](#bib.bib412)] | IoT authentication | Long duration of
    signal imperfections | Supervised | LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Jiang *et al.* [[413](#bib.bib413)] | MAC spoofing detection | Packets from
    different hardware use same MAC address | Supervised | CNN |'
  prefs: []
  type: TYPE_TB
- en: '|  | Jiang *et al.* [[419](#bib.bib419)] | Cyberattack detection in mobile
    cloud computing | Various cyberattacks from 3 different datasets | Unsupervised
    + supervised | RBM |'
  prefs: []
  type: TYPE_TB
- en: '| Software | Yuan *et al.* [[414](#bib.bib414)] | Android malware detection
    | Apps in Contagio Mobile and Google Play Store | Unsupervised & supervised |
    RBM |'
  prefs: []
  type: TYPE_TB
- en: '| Yuan *et al.* [[415](#bib.bib415)] | Android malware detection | Apps in
    Contagio Mobile, Google Play Store and Genome Project | Unsupervised & supervised
    | DBN |'
  prefs: []
  type: TYPE_TB
- en: '| Su *et al.* [[416](#bib.bib416)] | Android malware detection | Apps in Drebin,
    Android Malware Genome Project, the Contagio Community, and Google Play Store
    | Unsupervised & supervised | DBN + SVM |'
  prefs: []
  type: TYPE_TB
- en: '| Hou *et al.* [[417](#bib.bib417)] | Android malware detection | App samples
    from Comodo Cloud Security Center | Unsupervised & supervised | Stacked AE |'
  prefs: []
  type: TYPE_TB
- en: '| Martinelli [[418](#bib.bib418)] | Android malware detection | Apps in Drebin,
    Android Malware Genome Project and Google Play Store | Supersived | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| McLaughlin *et al.* [[420](#bib.bib420)] | Android malware detection | Apps
    in Android Malware Genome project and Google Play Store | Supersived | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Chen *et al.* [[421](#bib.bib421)] | Malicious application detection at the
    network edge | Publicly-available malicious applications | Unsupervised & supervised
    | RBM |'
  prefs: []
  type: TYPE_TB
- en: '| Wang *et al.* [[223](#bib.bib223)] | Malware traffic classification | Traffic
    extracted from 9 types of malware | Superivised | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Oulehla *et al.* [[422](#bib.bib422)] | Mobile botnet detection | Client-server
    and hybrid botnets | Unknown | Unknown |'
  prefs: []
  type: TYPE_TB
- en: '| Torres *et al.* [[423](#bib.bib423)] | Botnet detection | Spam, HTTP and
    unknown traffic | Superivised | LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Eslahi *et al.* [[424](#bib.bib424)] | Mobile botnet detection | HTTP botnet
    traffic | Superivised | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Alauthaman *et al.* [[425](#bib.bib425)] | Peer-to-peer botnet detection
    | Waledac and Strom Bots | Superivised | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| User privacy | Shokri and Shmatikov [[426](#bib.bib426)] | Privacy preserving
    deep learning | Avoiding sharing data in collaborative model training | Superivised
    | MLP, CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Phong *et al.* [[427](#bib.bib427)] | Privacy preserving deep learning |
    Addressing information leakage introduced in [[426](#bib.bib426)] | Supervised
    | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Ossia *et al.* [[428](#bib.bib428)] | Privacy-preserving mobile analytics
    | Offloading feature extraction from cloud | Supervised | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Abadi *et al.* [[429](#bib.bib429)] | Deep learning with differential privacy
    | Preventing exposure of private information in training data | Supervised | MLP
    |'
  prefs: []
  type: TYPE_TB
- en: '| Osia *et al.* [[430](#bib.bib430)] | Privacy-preserving personal model training
    | Offloading personal data from clouds | Unsupervised & supervised | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Servia *et al.* [[431](#bib.bib431)] | Privacy-preserving model inference
    | Breaking down large models for privacy-preserving analytics | Supervised | CNN
    |'
  prefs: []
  type: TYPE_TB
- en: '| Hitaj *et al.* [[432](#bib.bib432)] | Stealing information from collaborative
    deep learning | Breaking the ordinary and differentially private collaborative
    deep learning | Unsupervised | GAN |'
  prefs: []
  type: TYPE_TB
- en: '| Hitaj *et al.* [[429](#bib.bib429)] | Password guessing | Generating passwords
    from leaked password set | Unsupervised | GAN |'
  prefs: []
  type: TYPE_TB
- en: '| Greydanus [[433](#bib.bib433)] | Enigma learning | Reconstructing functions
    of polyalphabetic cipher | Supervised | LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Maghrebi [[434](#bib.bib434)] | Breaking cryptographic | Side channel attacks
    | Supervised | MLP, AE, CNN, LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Liu *et al.* [[435](#bib.bib435)] | Password guessing | Employing adversarial
    generation to guess passwords | Unsupervised | LSTM |'
  prefs: []
  type: TYPE_TB
- en: '|  | Ning *et al.* [[436](#bib.bib436)] | Mobile apps sniffing | Defending
    against mobile apps sniffing through noise injection | Supervised | CNN |'
  prefs: []
  type: TYPE_TB
- en: '|  | Wang *et al.* [[497](#bib.bib497)] | Private inference in mobile cloud
    | Computation offloading and privacy preserving for mobile inference | Supervised
    | MLP, CNN |'
  prefs: []
  type: TYPE_TB
- en: 'Modern cyber security systems benefit increasingly from deep learning [[498](#bib.bib498)],
    since it can enable the system to *(i)* automatically learn signatures and patterns
    from experience and generalize to future intrusions (supervised learning); or
    *(ii)* identify patterns that are clearly differed from regular behavior (unsupervised
    learning). This dramatically reduces the effort of pre-defined rules for discriminating
    intrusions. Beyond protecting networks from attacks, deep learning can also be
    used for attack purposes, bringing huge potential to steal or crack user passwords
    or information. In this subsection, we review deep learning driven network security
    from three perspectives, namely infrastructure, software, and user privacy. Specifically,
    infrastructure level security work focuses on detecting anomalies that occur in
    the physical network and software level work is centred on identifying malware
    and botnets in mobile networks. From the user privacy perspective, we discuss
    methods to protect from how to protect against private information leakage, using
    deep learning. To our knowledge, no other reviews summarize these efforts. We
    summarize these works in Table [XVII](#S6.T17 "TABLE XVII ‣ VI-H Deep Learning
    Driven Network Security ‣ VI Deep Learning Driven Mobile and Wireless Networks
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Infrastructure level security: We mostly focus on anomaly detection at the
    infrastructure level, i.e. identifying network events (e.g., attacks, unexpected
    access and use of data) that do not conform to expected behaviors. Many researchers
    exploit the outstanding unsupervised learning ability of AEs [[404](#bib.bib404)].
    For example, Thing investigates features of attacks and threats that exist in
    IEEE 802.11 networks [[185](#bib.bib185)]. The author employs a stacked AE to
    categorize network traffic into 5 types (i.e. legitimate, flooding, injection
    and impersonation traffic), achieving 98.67% overall accuracy. The AE is also
    exploited in [[405](#bib.bib405)], where Aminanto and Kim use an MLP and stacked
    AE for feature selection and extraction, demonstrating remarkable performance.
    Similarly, Feng *et al.* use AEs to detect abnormal spectrum usage in wireless
    communications [[406](#bib.bib406)]. Their experiments suggest that the detection
    accuracy can significantly benefit from the depth of AEs.'
  prefs: []
  type: TYPE_NORMAL
- en: Distributed attack detection is also an important issue in mobile network security.
    Khan *et al.* focus on detecting flooding attacks in wireless mesh networks [[407](#bib.bib407)].
    They simulate a wireless environment with 100 nodes, and artificially inject moderate
    and severe distributed flooding attacks, to generate a synthetic dataset. Their
    deep learning based methods achieve excellent false positive and false negative
    rates. Distributed attacks are also studied in [[408](#bib.bib408)], where the
    authors focus on an IoT scenario. Another work in [[409](#bib.bib409)] employs
    MLPs to detect distributed denial of service attacks. By characterizing typical
    patterns of attack incidents, the proposed model works well in detecting both
    known and unknown distributed denial of service attacks. More recently, Nguyen
    *et al.* employ RBMs to classify cyberattacks in the mobile cloud in an online
    manner [[419](#bib.bib419)]. Through unsupervised layer-wise pre-training and
    fine-tuning, their methods obtain over 90% classification accuracy on three different
    datasets, significantly outperforming other machine learning approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Martin *et al.* propose a conditional VAE to identify intrusion incidents in
    IoT [[410](#bib.bib410)]. In order to improve detection performance, their VAE
    infers missing features associated with incomplete measurements, which are common
    in IoT environments. The true data labels are embedded into the decoder layers
    to assist final classification. Evaluations on the well-known NSL-KDD dataset
    [[499](#bib.bib499)] demonstrate that their model achieves remarkable accuracy
    in identifying denial of service, probing, remote to user and user to root attacks,
    outperforming traditional ML methods by 0.18 in terms of F1 score. Hamedani *et
    al.* employ MLPs to detect malicious attacks in delayed feedback networks [[411](#bib.bib411)].
    The proposal achieves more than 99% accuracy over 10,000 simulations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Software level security: Nowadays, mobile devices are carrying considerable
    amount of private information. This information can be stolen and exploited by
    malicious apps installed on smartphones for ill-conceived purposes [[500](#bib.bib500)].
    Deep learning is being exploited for analyzing and detecting such threats.'
  prefs: []
  type: TYPE_NORMAL
- en: Yuan *et al.* use both labeled and unlabeled mobile apps to train an RBM [[414](#bib.bib414)].
    By learning from 300 samples, their model can classify Android malware with remarkable
    accuracy, outperforming traditional ML tools by up to 19%. Their follow-up research
    in [[415](#bib.bib415)] named Droiddetector further improves the detection accuracy
    by 2%. Similarly, Su *et al.* analyze essential features of Android apps, namely
    requested permission, used permission, sensitive application programming interface
    calls, action and app components [[416](#bib.bib416)]. They employ DBNs to extract
    features of malware and an SVM for classification, achieving high accuracy and
    only requiring 6 seconds per inference instance.
  prefs: []
  type: TYPE_NORMAL
- en: Hou *et al.* attack the malware detection problem from a different perspective.
    Their research points out that signature-based detection is insufficient to deal
    with sophisticated Android malware [[417](#bib.bib417)]. To address this problem,
    they propose the Component Traversal, which can automatically execute code routines
    to construct weighted directed graphs. By employing a Stacked AE for graph analysis,
    their framework Deep4MalDroid can accurately detect Android malware that intentionally
    repackages and obfuscates to bypass signatures and hinder analysis attempts to
    their inner operations. This work is followed by that of Martinelli *et al.*,
    who exploit CNNs to discover the relationship between app types and extracted
    syscall traces from real mobile devices [[418](#bib.bib418)]. The CNN has also
    been used in [[420](#bib.bib420)], where the authors draw inspiration from NLP
    and take the disassembled byte-code of an app as a text for analysis. Their experiments
    demonstrate that CNNs can effectively learn to detect sequences of opcodes that
    are indicative of malware. Chen *et al.* incorporate location information into
    the detection framework and exploit an RBM for feature extraction and classification
    [[421](#bib.bib421)]. Their proposal improves the performance of other ML methods.
  prefs: []
  type: TYPE_NORMAL
- en: Botnets are another important threat to mobile networks. A botnet is effectively
    a network that consists of machines compromised by bots. These machine are usually
    under the control of a botmaster who takes advantages of the bots to harm public
    services and systems [[501](#bib.bib501)]. Detecting botnets is challenging and
    now becoming a pressing task in cyber security. Deep learning is playing an important
    role in this area. For example, Oulehla *et al.* propose to employ neural networks
    to extract features from mobile botnet behaviors [[422](#bib.bib422)]. They design
    a parallel detection framework for identifying both client-server and hybrid botnets,
    and demonstrate encouraging performance. Torres *et al.* investigate the common
    behavior patterns that botnets exhibit across their life cycle, using LSTMs [[423](#bib.bib423)].
    They employ both under-sampling and over-sampling to address the class imbalance
    between botnet and normal traffic in the dataset, which is common in anomaly detection
    problems. Similar issues are also studies in [[424](#bib.bib424)] and [[425](#bib.bib425)],
    where the authors use standard MLPs to perform mobile and peer-to-peer botnet
    detection respectively, achieving high overall accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'User privacy level: Preserving user privacy during training and evaluating
    a deep neural network is another important research issue [[502](#bib.bib502)].
    Initial research is conducted in [[426](#bib.bib426)], where the authors enable
    user participation in the training and evaluation of a neural network, without
    sharing their input data. This allows to preserve individual’s privacy while benefiting
    all users, as they collaboratively improve the model performance. Their framework
    is revisited and improved in [[427](#bib.bib427)], where another group of researchers
    employ additively homomorphic encryption, to address the information leakage problem
    ignored in [[426](#bib.bib426)], without compromising model accuracy. This significantly
    boosts the security of the system. More recently, Wang *et al.* [[497](#bib.bib497)]
    propose a framework called ARDEN to preserve users’ privacy while reducing communication
    overhead in mobile-cloud deep learning applications. ARDEN partitions a NN across
    cloud and mobile devices, with heavy computation being conducted on the cloud
    and mobile devices performing only simple data transformation and perturbation,
    using a differentially private mechanism. This simultaneously guarantees user
    privacy, improves inference accuracy, and reduces resource consumption.'
  prefs: []
  type: TYPE_NORMAL
- en: Osia *et al.* focus on privacy-preserving mobile analytics using deep learning.
    They design a client-server framework based on the Siamese architecture [[503](#bib.bib503)],
    which accommodates a feature extractor in mobile devices and correspondingly a
    classifier in the cloud [[428](#bib.bib428)]. By offloading feature extraction
    from the cloud, their system offers strong privacy guarantees. An innovative work
    in [[429](#bib.bib429)] implies that deep neural networks can be trained with
    differential privacy. The authors introduce a differentially private SGD to avoid
    disclosure of private information of training data. Experiments on two publicly-available
    image recognition datasets demonstrate that their algorithm is able to maintain
    users privacy, with a manageable cost in terms of complexity, efficiency, and
    performance. This approach is also useful for edge-based privacy filtering techniques
    such as Distributed One-class Learning [[504](#bib.bib504)].
  prefs: []
  type: TYPE_NORMAL
- en: Servia *et al.* consider training deep neural networks on distributed devices
    without violating privacy constraints [[431](#bib.bib431)]. Specifically, the
    authors retrain an initial model locally, tailored to individual users. This avoids
    transferring personal data to untrusted entities, hence user privacy is guaranteed.
    Osia *et al.* focus on protecting user’s personal data from the inferences’ perspective.
    In particular, they break the entire deep neural network into a feature extractor
    (on the client side) and an analyzer (on the cloud side) to minimize the exposure
    of sensitive information. Through local processing of raw input data, sensitive
    personal information is transferred into abstract features, which avoids direct
    disclosure to the cloud. Experiments on gender classification and emotion detection
    suggest that this framework can effectively preserve user privacy, while maintaining
    remarkable inference accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning has also been exploited for cyber attacks, including attempts
    to compromise private user information and guess passwords. In [[432](#bib.bib432)],
    Hitaj *et al.* suggest that learning a deep model collaboratively is not reliable.
    By training a GAN, their attacker is able to affect such learning process and
    lure the victims to disclose private information, by injecting fake training samples.
    Their GAN even successfully breaks the differentially private collaborative learning
    in [[429](#bib.bib429)]. The authors further investigate the use of GANs for password
    guessing. In [[505](#bib.bib505)], they design PassGAN, which learns the distribution
    of a set of leaked passwords. Once trained on a dataset, PassGAN is able to match
    over 46% of passwords in a different testing set, without user intervention or
    cryptography knowledge. This novel technique has potential to revolutionize current
    password guessing algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Greydanus breaks a decryption rule using an LSTM network [[433](#bib.bib433)].
    They treat decryption as a sequence-to-sequence translation task, and train a
    framework with large enigma pairs. The proposed LSTM demonstrates remarkable performance
    in learning polyalphabetic ciphers. Maghrebi *et al.* exploit various deep learning
    models (i.e. MLP, AE, CNN, LSTM) to construct a precise profiling system and perform
    side channel key recovery attacks [[434](#bib.bib434)]. Surprisingly, deep learning
    based methods demonstrate overwhelming performance over other template machine
    learning attacks in terms of efficiency in breaking both unprotected and protected
    Advanced Encryption Standard implementations. In [[436](#bib.bib436)], Ning *et
    al.* demonstrate that an attacker can use a CNN to infer with over 84% accuracy
    what apps run on a smartphone and their usage, based on magnetometer or orientation
    data. The accuracy can increase to 98% if motion sensors information is also taken
    into account, which jeopardizes user privacy. To mitigate this issue, the authors
    propose to inject Gaussian noise into the magnetometer and orientation data, which
    leads to a reduction in inference accuracy down to 15%, thereby effectively mitigating
    the risk of privacy leakage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lessons learned: Most deep learning based solutions focus on existing network
    attacks, yet new attacks emerge every day. As these new attacks may have different
    features and appear to behave ‘normally’, old NN models may not easily detect
    them. Therefore, an effective deep learning technique should be able to *(i)*
    rapidly transfer the knowledge of old attacks to detect newer ones; and *(ii)*
    constantly absorb the features of newcomers and update the underlying model. Transfer
    learning and lifelong learning are strong candidates to address this problems,
    as we will discuss in Sec.[VII-C](#S7.SS3 "VII-C Tailoring Deep Learning to Changing
    Mobile Network Environments ‣ VII Tailoring Deep Learning to Mobile Networks ‣
    Deep Learning in Mobile and Wireless Networking: A Survey"). Research in this
    directions remains shallow, hence we expect more efforts in the future.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another issue to which attention should be paid is the fact that NNs are vulnerable
    to adversarial attacks. This has been briefly discussed in Sec. [III-E](#S3.SS5
    "III-E Limitations of Deep Learning in Mobile and Wireless Networking ‣ III Deep
    Learning 101 ‣ Deep Learning in Mobile and Wireless Networking: A Survey"). Although
    formal reports on this matter are lacking, hackers may exploit weaknesses in NN
    models and training procedures to perform attacks that subvert deep learning based
    cyber-defense systems. This is an important potential pitfall that should be considered
    in real implementations.'
  prefs: []
  type: TYPE_NORMAL
- en: VI-I Deep Learning Driven Signal Processing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Deep learning is also gaining increasing attention in signal processing, in
    applications including Multi-Input Multi-Output (MIMO) and modulation. MIMO has
    become a fundamental technique in current wireless communications, both in cellular
    and WiFi networks. By incorporating deep learning, MIMO performance is intelligently
    optimized based on environment conditions. Modulation recognition is also evolving
    to be more accurate, by taking advantage of deep learning. We give an overview
    of relevant work in this area in Table [XVIII](#S6.T18 "TABLE XVIII ‣ VI-I Deep
    Learning Driven Signal Processing ‣ VI Deep Learning Driven Mobile and Wireless
    Networks ‣ Deep Learning in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE XVIII: A summary of deep learning driven signal processing.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Domain | Reference | Application | Model |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| MIMO systems | Samuel *et al.*  [[446](#bib.bib446)] | MIMO detection | MLP
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Yan *et al.*  [[447](#bib.bib447)] | Signal detection in a MIMO-OFDM system
    | AE+ELM |'
  prefs: []
  type: TYPE_TB
- en: '|  | Vieira *et al.*  [[322](#bib.bib322)] | Massive MIMO fingerprint-based
    positioning | CNN |'
  prefs: []
  type: TYPE_TB
- en: '|  | Neumann *et al.*  [[445](#bib.bib445)] | MIMO channel estimation | CNN
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Wijaya *et al.*  [[378](#bib.bib378), [380](#bib.bib380)] | Inter-cell
    interference cancellation and transmit power optimization | RBM |'
  prefs: []
  type: TYPE_TB
- en: '|  | O’Shea *et al.*  [[437](#bib.bib437)] | Optimization of representations
    and encoding/decoding processes | AE |'
  prefs: []
  type: TYPE_TB
- en: '|  | Borgerding *et al.*  [[438](#bib.bib438)] | Sparse linear inverse problem
    in MIMO | CNN |'
  prefs: []
  type: TYPE_TB
- en: '|  | Fujihashi *et al.*  [[439](#bib.bib439)] | MIMO nonlinear equalization
    | MLP |'
  prefs: []
  type: TYPE_TB
- en: '|  | Huang *et al.*  [[457](#bib.bib457)] | Super-resolution channel and direction-of-arrival
    estimation | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Modulation | Rajendran *et al.*  [[440](#bib.bib440)] | Automatic modulation
    classification | LSTM |'
  prefs: []
  type: TYPE_TB
- en: '|  | West and O’Shea [[441](#bib.bib441)] | Modulation recognition | CNN, ResNet,
    Inception CNN, LSTM |'
  prefs: []
  type: TYPE_TB
- en: '|  | O’Shea *et al.*  [[442](#bib.bib442)] | Modulation recognition | Radio
    transformer network |'
  prefs: []
  type: TYPE_TB
- en: '|  | O’Shea and Hoydis [[448](#bib.bib448)] | Modulation classification | CNN
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Jagannath *et al.*  [[449](#bib.bib449)] | Modulation classification in
    a software defined radio testbed | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Others | O’Shea *et al.*  [[450](#bib.bib450)] | Radio traffic sequence recognition
    | LSTM |'
  prefs: []
  type: TYPE_TB
- en: '|  | O’Shea *et el.*  [[451](#bib.bib451)] | Learning to communicate over an
    impaired channel | AE + radio transformer network |'
  prefs: []
  type: TYPE_TB
- en: '|  | Ye *et al.*  [[452](#bib.bib452)] | Channel estimation and signal detection
    in OFDM systsms. | MLP |'
  prefs: []
  type: TYPE_TB
- en: '|  | Liang *et al.*  [[453](#bib.bib453)] | Channel decoding | CNN |'
  prefs: []
  type: TYPE_TB
- en: '|  | Lyu *et al.*  [[454](#bib.bib454)] | NNs for channel decoding | MLP, CNN
    and RNN |'
  prefs: []
  type: TYPE_TB
- en: '|  | Dörner *et al.*  [[455](#bib.bib455)] | Over-the-air communications system
    | AE |'
  prefs: []
  type: TYPE_TB
- en: '|  | Liao *et al.*  [[456](#bib.bib456)] | Rayleigh fading channel prediction
    | MLP |'
  prefs: []
  type: TYPE_TB
- en: '|  | Huang *et al.*  [[458](#bib.bib458)] | Light-emitting diode (LED) visible
    light downlink error correction | AE |'
  prefs: []
  type: TYPE_TB
- en: '|  | Alkhateeb *et al.*  [[444](#bib.bib444)] | Coordinated beamforming for
    highly-mobile millimeter wave systems | MLP |'
  prefs: []
  type: TYPE_TB
- en: '|  | Gante *et al.*  [[443](#bib.bib443)] | Millimeter wave positioning | CNN
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Ye *et al.*  [[506](#bib.bib506)] | Channel agnostic end-to-end learning
    based communication system | Conditional GAN |'
  prefs: []
  type: TYPE_TB
- en: 'MIMO Systems: Samuel *et al.* suggest that deep neural networks can be a good
    estimator of transmitted vectors in a MIMO channel. By unfolding a projected gradient
    descent method, they design an MLP-based detection network to perform binary MIMO
    detection [[446](#bib.bib446)]. The Detection Network can be implemented on multiple
    channels after a single training. Simulations demonstrate that the proposed architecture
    achieves near-optimal accuracy, while requiring light computation without prior
    knowledge of Signal-to-Noise Ratio (SNR). Yan *et al.* employ deep learning to
    solve a similar problem from a different perspective [[447](#bib.bib447)]. By
    considering the characteristic invariance of signals, they exploit an AE as a
    feature extractor, and subsequently use an Extreme Learning Machine (ELM) to classify
    signal sources in a MIMO orthogonal frequency division multiplexing (OFDM) system.
    Their proposal achieves higher detection accuracy than several traditional methods,
    while maintaining similar complexity.'
  prefs: []
  type: TYPE_NORMAL
- en: Vieira *et al.* show that massive MIMO channel measurements in cellular networks
    can be utilized for fingerprint-based inference of user positions [[322](#bib.bib322)].
    Specifically, they design CNNs with weight regularization to exploit the sparse
    and information-invariance of channel fingerprints, thereby achieving precise
    positions inference. CNNs have also been employed for MIMO channel estimation.
    Neumann *et al.* exploit the structure of the MIMO channel model to design a lightweight,
    approximated maximum likelihood estimator for a specific channel model [[445](#bib.bib445)].
    Their methods outperform traditional estimators in terms of computation cost and
    reduce the number of hyper-parameters to be tuned. A similar idea is implemented
    in [[452](#bib.bib452)], where Ye *et al.* employ an MLP to perform channel estimation
    and signal detection in OFDM systems.
  prefs: []
  type: TYPE_NORMAL
- en: Wijaya *et al.* consider applying deep learning to a different scenario [[378](#bib.bib378),
    [380](#bib.bib380)]. The authors propose to use non-iterative neural networks
    to perform transmit power control at base stations, thereby preventing degradation
    of network performance due to inter-cell interference. The neural network is trained
    to estimate the optimal transmit power at every packet transmission, selecting
    that with the highest activation probability. Simulations demonstrate that the
    proposed framework significantly outperform the belief propagation algorithm that
    is routinely used for transmit power control in MIMO systems, while attaining
    a lower computational cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'More recently, O’Shea *et al.* bring deep learning to physical layer design
    [[437](#bib.bib437)]. They incorporate an unsupervised deep AE into a single-user
    end-to-end MIMO system, to optimize representations and the encoding/decoding
    processes, for transmissions over a Rayleigh fading channel. We illustrate the
    adopted AE-based framework in Fig [18](#S6.F18 "Figure 18 ‣ VI-I Deep Learning
    Driven Signal Processing ‣ VI Deep Learning Driven Mobile and Wireless Networks
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey"). This design incorporates
    a transmitter consisting of an MLP followed by a normalization layer, which ensures
    that physical constraints on the signal are guaranteed. After transfer through
    an additive white Gaussian noise channel, a receiver employs another MLP to decode
    messages and select the one with the highest probability of occurrence. The system
    can be trained with an SGD algorithm in an end-to-end manner. Experimental results
    show that the AE system outperforms the Space Time Block Code approach in terms
    of SNR by approximately 15 dB. In [[438](#bib.bib438)], Borgerding *et al.* propose
    to use deep learning to recover a sparse signal from noisy linear measurements
    in MIMO environments. The proposed scheme is evaluated on compressive random access
    and massive-MIMO channel estimation, where it achieves better accuracy over traditional
    algorithms and CNNs.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5282a4fe42581de10b094e0350f031b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18: A communications system over an additive white Gaussian noise channel
    represented as an autoencoder.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Modulation: West and O’Shea compare the modulation recognition accuracy of
    different deep learning architectures, including traditional CNN, ResNet, Inception
    CNN, and LSTM [[441](#bib.bib441)]. Their experiments suggest that the LSTM is
    the best candidate for modulation recognition, since it achieves the highest accuracy.
    Due to its superior performance, an LSTM is also employed for a similar task in
    [[440](#bib.bib440)]. O’Shea *et al.* then focus on tailoring deep learning architectures
    to radio properties. Their prior work is improved in [[442](#bib.bib442)], where
    they architect a novel deep radio transformer network for precise modulation recognition.
    Specifically, they introduce radio-domain specific parametric transformations
    into a spatial transformer network, which assists in the normalization of the
    received signal, thereby achieving superior performance. This framework also demonstrates
    automatic synchronization abilities, which reduces the dependency on traditional
    expert systems and expensive signal analytic processes. In [[448](#bib.bib448)],
    O’Shea and Hoydis introduce several novel deep learning applications for the network
    physical layer. They demonstrate a proof-of-concept where they employ a CNN for
    modulation classification and obtain satisfying accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Other signal processing applciations: Deep learning is also adopted for radio
    signal analysis. In [[450](#bib.bib450)], O’Shea *et al.* employ an LSTM to replace
    sequence translation routines between radio transmitter and receiver. Although
    their framework works well in ideal environments, its performance drops significantly
    when introducing realistic channel effects. Later, the authors consider a different
    scenario in [[451](#bib.bib451)], where they exploit a regularized AE to enable
    reliable communications over an impaired channel. They further incorporate a radio
    transformer network for signal reconstruction at the decoder side, thereby achieving
    receiver synchronization. Simulations demonstrate that this approach is reliable
    and can be efficiently implemented.'
  prefs: []
  type: TYPE_NORMAL
- en: In [[453](#bib.bib453)], Liang *et al.* exploit noise correlations to decode
    channels using a deep learning approach. Specifically, they use a CNN to reduce
    channel noise estimation errors by learning the noise correlation. Experiments
    suggest that their framework can significantly improve the decoding performance.
    The decoding performance of MLPs , CNNs and RNNs is compared in [[454](#bib.bib454)].
    By conducting experiments in different setting, the obtained results suggest the
    RNN achieves the best decoding performance, nonetheless yielding the highest computational
    overhead. Liao *et al.* employ MLPs to perform accurate Rayleigh fading channel
    prediction [[456](#bib.bib456)]. The authors further equip their proposal with
    a sparse channel sample construction method to save system resources without compromising
    precision. Deep learning can further aid visible light communication. In [[458](#bib.bib458)],
    Huang *et al.* employ a deep learning based system for error correction in optical
    communications. Specifically, an AE is used in their work to perform dimension
    reduction on light-emitting diode (LED) visible light downlink, thereby maximizing
    the channel bandwidth . The proposal follows the theory in [[448](#bib.bib448)],
    where O’Shea *et al.* demonstrate that deep learning driven signal processing
    systems can perform as good as traditional encoding and/or modulation systems.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning has been further adopted in solving millimeter wave beamforming.
    In [[444](#bib.bib444)], Alkhateeb *et al.* propose a millimeter wave communication
    system that utilizes MLPs to predict beamforming vectors from signals received
    from distributed base stations. By substituting a genie-aided solution with deep
    learning, their framework reduces the coordination overhead, enabling wide-coverage
    and low-latency beamforming. Similarly, Gante *et al.* employ CNNs to infer the
    position of a device, given the received millimeter wave radiation. Their preliminary
    simulations show that the CNN-based system can achieve small estimation errors
    in a realistic outdoors scenario, significantly outperforming existing prediction
    approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lessons learned: Deep learning is beginning to play an important role in signal
    processing applications and the performance demonstrated by early prototypes is
    remarkable. This is because deep learning can prove advantageous with regards
    to performance, complexity, and generalization capabilities. At this stage, research
    in this area is however incipient. We can only expect that deep learning will
    become increasingly popular in this area.'
  prefs: []
  type: TYPE_NORMAL
- en: VI-J Emerging Deep Learning Applications in Mobile Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this part, we review work that builds upon deep learning in other mobile
    networking areas, which are beyond the scopes of the subjects discussed thus far.
    These emerging applications open several new research directions, as we discuss
    next. A summary of these works is given in Table [XIX](#S6.T19 "TABLE XIX ‣ VI-J
    Emerging Deep Learning Applications in Mobile Networks ‣ VI Deep Learning Driven
    Mobile and Wireless Networks ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE XIX: A summary of emerging deep learning driven mobile network applications.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Reference | Application | Model | Key contribution |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Gonzalez *et al.* [[459](#bib.bib459)] | Network data monetifzation | - |
    A platform named Net2Vec to facilitate deep learning deployment in communication
    networks. |'
  prefs: []
  type: TYPE_TB
- en: '| Kaminski *et al.* [[460](#bib.bib460)] | In-network computation for IoT |
    MLP | Enables to perform collaborative data processing and reduces latency. |'
  prefs: []
  type: TYPE_TB
- en: '| Xiao *et al.* [[461](#bib.bib461)] | Mobile crowdsensing | Deep Q learning
    | Mitigates vulnerabilities of mobile crowdsensing systems. |'
  prefs: []
  type: TYPE_TB
- en: '| Luong *et al.* [[462](#bib.bib462)] | Resource allocation for mobile blockchains
    | MLP | Employs deep learning to perform monotone transformations of miners’bids
    and outputs the allocation and conditional payment rules in optimal auctions.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Gulati *et al.* [[463](#bib.bib463)] | Data dissemination in Internet of
    Vehicles (IoV) | CNN | Investigates the relationship between data dissemination
    performance and social score, energy level, number of vehicles and their speed.
    |'
  prefs: []
  type: TYPE_TB
- en: 'Network Data Monetization: Gonzalez *et al.* employ unsupervised deep learning
    to generate real-time accurate user profiles [[459](#bib.bib459)] using an on-network
    machine learning platform called Net2Vec [[507](#bib.bib507)]. Specifically, they
    analyze user browsing data in real time and generate user profiles using product
    categories. The profiles can be subsequently associated with the products that
    are of interest to the users and employed for online advertising.'
  prefs: []
  type: TYPE_NORMAL
- en: 'IoT In-Network Computation: Instead of regarding IoT nodes as producers of
    data or the end consumers of processed information, Kaminski *et al.* embed neural
    networks into an IoT deployment and allow the nodes to collaboratively process
    the data generated [[460](#bib.bib460)]. This enables low-latency communication,
    while offloading data storage and processing from the cloud. In particular, the
    authors map each hidden unit of a pre-trained neural network to a node in the
    IoT network, and investigate the optimal projection that leads to the minimum
    communication overhead. Their framework achieves functionality similar to in-network
    computation in WSNs and opens a new research directions in fog computing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mobile Crowdsensing: Xiao *et al.* investigate vulnerabilities facing crowdsensing
    in the mobile network context. They argue that there exist malicious mobile users
    who intentionally provide false sensing data to servers, to save costs and preserve
    their privacy, which in turn can make mobile crowdsensings systems vulnerable
    [[461](#bib.bib461)]. The authors model the server-users system as a Stackelberg
    game, where the server plays the role of a leader that is responsible for evaluating
    the sensing effort of individuals, by analyzing the accuracy of each sensing report.
    Users are paid based on the evaluation of their efforts, hence cheating users
    will be punished with zero reward. To design an optimal payment policy, the server
    employs a deep Q network, which derives knowledge from experience sensing reports,
    without requiring specific sensing models. Simulations demonstrate superior performance
    in terms of sensing quality, resilience to attacks, and server utility, as compared
    to traditional Q learning based and random payment strategies.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mobile Blockchain: Substantial computing resource requirements and energy consumption
    limit the applicability of blockchain in mobile network environments. To mitigate
    this problem, Luong *et al.* shed light on resource management in mobile blockchain
    networks based on optimal auction in [[462](#bib.bib462)]. They design an MLP
    to first conduct monotone transformations of the miners’ bids and subsequently
    output the allocation scheme and conditional payment rules for each miner. By
    running experiments with different settings, the results suggest the propsoed
    deep learning based framework can deliver much higher profit to edge computing
    service provider than the second-price auction baseline.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Internet of Vehicles (IoV): Gulati *et al.* extend the success of deep learning
    to IoV [[463](#bib.bib463)]. The authors design a deep learning-based content
    centric data dissemination approach that comprises three steps, namely *(i)* performing
    energy estimation on selected vehicles that are capable of data dissemination;
    *(ii)* employing a Weiner process model to identify stable and reliable connections
    between vehicles; and *(iii)* using a CNN to predict the social relationship among
    vehicles. Experiments unveil that the volume of data disseminated is positively
    related to social score, energy levels, and number of vehicles, while the speed
    of vehicles has negative impact on the connection probability.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Lessons learned: The adoption of deep learning in the mobile and wireless networking
    domain is exciting and undoubtedly many advances are yet to appear. However, as
    discussed in Sec. [III-E](#S3.SS5 "III-E Limitations of Deep Learning in Mobile
    and Wireless Networking ‣ III Deep Learning 101 ‣ Deep Learning in Mobile and
    Wireless Networking: A Survey"), deep learning solutions are not universal and
    may not be suitable for every problem. One should rather regard deep learning
    as a powerful tool that can assist with fast and accurate inference, and facilitate
    the automation of some processes previously requiring human intervention. Nevertheless,
    deep learning algorithms will make mistakes, and their decisions might not be
    easy to interpret. In tasks that require high interpretability and low fault-tolerance,
    deep learning still has a long way to go, which also holds for the majority of
    ML algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: VII Tailoring Deep Learning to Mobile Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although deep learning performs remarkably in many mobile networking areas,
    the No Free Lunch (NFL) theorem indicates that there is no single model that can
    work universally well in all problems [[508](#bib.bib508)]. This implies that
    for any specific mobile and wireless networking problem, we may need to adapt
    different deep learning architectures to achieve the best performance. In this
    section, we look at how to tailor deep learning to mobile networking applications
    from three perspectives, namely, mobile devices and systems, distributed data
    centers, and changing mobile network environments.
  prefs: []
  type: TYPE_NORMAL
- en: VII-A Tailoring Deep Learning to Mobile Devices and Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The ultra-low latency requirements of future 5G networks demand runtime efficiency
    from all operations performed by mobile systems. This also applies to deep learning
    driven applications. However, current mobile devices have limited hardware capabilities,
    which means that implementing complex deep learning architectures on such equipment
    may be computationally unfeasible, unless appropriate model tuning is performed.
    To address this issue, ongoing research improves existing deep learning architectures
    [[509](#bib.bib509)], such that the inference process does not violate latency
    or energy constraints [[510](#bib.bib510), [511](#bib.bib511)], nor raise any
    privacy concern [[512](#bib.bib512)]. We outline these works in Table [XX](#S7.T20
    "TABLE XX ‣ VII-A Tailoring Deep Learning to Mobile Devices and Systems ‣ VII
    Tailoring Deep Learning to Mobile Networks ‣ Deep Learning in Mobile and Wireless
    Networking: A Survey") and discuss their key contributions next.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE XX: Summary of works on improving deep learning for mobile devices and
    systems.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Reference | Methods | Target model |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Iandola *et al.* [[513](#bib.bib513)] | Filter size shrinking, reducing input
    channels and late downsampling | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Howard *et al.* [[514](#bib.bib514)] | Depth-wise separable convolution |
    CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang *et al.* [[515](#bib.bib515)] | Point-wise group convolution and channel
    shuffle | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang *et al.* [[516](#bib.bib516)] | Tucker decomposition | AE |'
  prefs: []
  type: TYPE_TB
- en: '| Cao *et al.* [[517](#bib.bib517)] | Data parallelization by RenderScript
    | RNN |'
  prefs: []
  type: TYPE_TB
- en: '| Chen *et al.* [[518](#bib.bib518)] | Space exploration for data reusability
    and kernel redundancy removal | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Rallapalli *et al.* [[519](#bib.bib519)] | Memory optimizations | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Lane *et al.* [[520](#bib.bib520)] | Runtime layer compression and deep architecture
    decomposition | MLP, CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Huynh *et al.* [[521](#bib.bib521)] | Caching, Tucker decomposition and computation
    offloading | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Wu *et al.* [[522](#bib.bib522)] | Parameters quantization | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Bhattacharya and Lane [[523](#bib.bib523)] | Sparsification of fully-connected
    layers and separation of convolutional kernels | MLP, CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Georgiev *et al.* [[97](#bib.bib97)] | Representation sharing | MLP |'
  prefs: []
  type: TYPE_TB
- en: '| Cho and Brand [[524](#bib.bib524)] | Convolution operation optimization |
    CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Guo and Potkonjak [[525](#bib.bib525)] | Filters and classes pruning | CNN
    |'
  prefs: []
  type: TYPE_TB
- en: '| Li *et al.* [[526](#bib.bib526)] | Cloud assistance and incremental learning
    | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Zen *et al.* [[527](#bib.bib527)] | Weight quantization | LSTM |'
  prefs: []
  type: TYPE_TB
- en: '| Falcao *et al.* [[528](#bib.bib528)] | Parallelization and memory sharing
    | Stacked AE |'
  prefs: []
  type: TYPE_TB
- en: '| Fang *et al.* [[529](#bib.bib529)] | Model pruning and recovery scheme |
    CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Xu *et al.* [[530](#bib.bib530)] | Reusable region lookup and reusable region
    propagation scheme | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Liu *et al.* [[531](#bib.bib531)] | Using deep Q learning based optimizer
    to achieve appropriate balance between accuracy, latency, storage and energy consumption
    for deep NNs on mobile platforms | CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Chen *et al.* [[532](#bib.bib532)] | Machine learning based optimization
    system to automatically explore and search for optimized tensor operators | All
    NN architectures |'
  prefs: []
  type: TYPE_TB
- en: '| Yao *et al.* [[533](#bib.bib533)] | Learning model execution time and performing
    the model compression | MLP, CNN, GRU, and LSTM |'
  prefs: []
  type: TYPE_TB
- en: Iandola *et al.* design a compact architecture for embedded systems named SqueezeNet,
    which has similar accuracy to that of AlexNet [[86](#bib.bib86)], a classical
    CNN, yet 50 times fewer parameters [[513](#bib.bib513)]. SqueezeNet is also based
    on CNNs, but its significantly smaller model size *(i)* allows more efficiently
    training on distributed systems; *(ii)* reduces the transmission overhead when
    updating the model at the client side; and *(iii)* facilitates deployment on resource-limited
    embedded devices. Howard *et al.* extend this work and introduce an efficient
    family of streamlined CNNs called MobileNet, which uses depth-wise separable convolution
    operations to drastically reduce the number of computations required and the model
    size [[514](#bib.bib514)]. This new design can run with low latency and can satisfy
    the requirements of mobile and embedded vision applications. The authors further
    introduce two hyper-parameters to control the width and resolution of multipliers,
    which can help strike an appropriate trade-off between accuracy and efficiency.
    The ShuffleNet proposed by Zhang *et al.* improves the accuracy of MobileNet by
    employing point-wise group convolution and channel shuffle, while retaining similar
    model complexity [[515](#bib.bib515)]. In particular, the authors discover that
    more groups of convolution operations can reduce the computation requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Zhang *et al.* focus on reducing the number of parameters of structures with
    fully-connected layers for mobile multimedia features learning [[516](#bib.bib516)].
    This is achieved by applying Trucker decomposition to weight sub-tensors in the
    model, while maintaining decent reconstruction capability. The Trucker decomposition
    has also been employed in [[521](#bib.bib521)], where the authors seek to approximate
    a model with fewer parameters, in order to save memory. Mobile optimizations are
    further studied for RNN models. In [[517](#bib.bib517)], Cao *et al.* use a mobile
    toolbox called RenderScript^(32)^(32)32Android Renderscript https://developer.android.com/guide/topics/renderscript/compute.html.
    to parallelize specific data structures and enable mobile GPUs to perform computational
    accelerations. Their proposal reduces the latency when running RNN models on Android
    smartphones. Chen *et al.* shed light on implementing CNNs on iOS mobile devices
    [[518](#bib.bib518)]. In particular, they reduce the model executions latency,
    through space exploration for data re-usability and kernel redundancy removal.
    The former alleviates the high bandwidth requirements of convolutional layers,
    while the latter reduces the memory and computational requirements, with negligible
    performance degradation.
  prefs: []
  type: TYPE_NORMAL
- en: Rallapalli *et al.* investigate offloading *very deep* CNNs from clouds to edge
    devices, by employing memory optimization on both mobile CPUs and GPUs [[519](#bib.bib519)].
    Their framework enables running at high speed deep CNNs with large memory requirements
    in mobile object detection applications. Lane *et al.* develop a software accelerator,
    DeepX, to assist deep learning implementations on mobile devices. The proposed
    approach exploits two inference-time resource control algorithms, i.e., runtime
    layer compression and deep architecture decomposition [[520](#bib.bib520)]. The
    runtime layer compression technique controls the memory and computation runtime
    during the inference phase, by extending model compression principles. This is
    important in mobile devices, since offloading the inference process to edge devices
    is more practical with current hardware platforms. Further, the deep architecture
    designs “decomposition plans” that seek to optimally allocate data and model operations
    to local and remote processors. By combining these two, DeepX enables maximizing
    energy and runtime efficiency, under given computation and memory constraints.
    Yao *et al.* [[533](#bib.bib533)] design a framework called FastDeepIoT, which
    fisrt learns the execution time of NN models on target devices, and subsequently
    conducts model compression to reduce the runtime without compromising the inference
    accuracy. Through this process, up to 78% of execution time and 69% of energy
    consumption is reduced, compared to state-of-the-art compression algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: More recently, Fang *et al.* design a framework called NestDNN, to provide flexible
    resource-accuracy trade-offs on mobile devices [[529](#bib.bib529)]. To this end,
    the NestDNN first adopts a model pruning and recovery scheme, which translates
    deep NNs to single compact multi-capacity models. With this approach up to 4.22%
    inference accuracy can be achieved with six mobile vision applications, at a 2.0$\times$
    faster video frame processing rate and reducing energy consumption by 1.7$\times$.
    In [[530](#bib.bib530)], Xu *et al.* accelerate deep learning inference for mobile
    vision from the caching perspective. In particular, the proposed framework called
    DeepCache stores recent input frames as cache keys and recent feature maps for
    individual CNN layers as cache values. The authors further employ reusable region
    lookup and reusable region propagation, to enable a region matcher to only run
    once per input video frame and load cached feature maps at all layers inside the
    CNN. This reduces the inference time by 18% and energy consumption by 20% on average.
    Liu *et al.* develop a usage-driven framework named AdaDeep, to select a combination
    of compression techniques for a specific deep NN on mobile platforms [[531](#bib.bib531)].
    By using a deep Q learning optimizer, their proposal can achieve appropriate trade-offs
    between accuracy, latency, storage and energy consumption.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond these works, researchers also successfully adapt deep learning architectures
    through other designs and sophisticated optimizations, such as parameters quantization
    [[522](#bib.bib522), [527](#bib.bib527)], sparsification and separation [[523](#bib.bib523)],
    representation and memory sharing [[97](#bib.bib97), [528](#bib.bib528)], convolution
    operation optimization [[524](#bib.bib524)], pruning [[525](#bib.bib525)], cloud
    assistance [[526](#bib.bib526)] and compiler optimization [[532](#bib.bib532)].
    These techniques will be of great significance when embedding deep neural networks
    into mobile systems.
  prefs: []
  type: TYPE_NORMAL
- en: VII-B Tailoring Deep Learning to Distributed Data Containers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'TABLE XXI: Summary of work on model and training parallelism for mobile systems
    and devices.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Parallelism Paradigm | Reference | Target | Core Idea | Improvement |'
  prefs: []
  type: TYPE_TB
- en: '| Model parallelism | Dean *et al.*  [[126](#bib.bib126)] | Very large deep
    neural networks in distributed systems. | Employs downpour SGD to support a large
    number of model replicas and a Sandblaster framework to support a variety of batch
    optimizations. | Up to 12$\times$ model training speed up, using 81 machines.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Teerapittayanon *et al.*  [[534](#bib.bib534)] | Neural network on cloud
    and end devices. | Maps a deep neural network to a distributed setting and jointly
    trains each individual section. | Up to 20$\times$ reduction of communication
    cost. |'
  prefs: []
  type: TYPE_TB
- en: '| De Coninck *et al.*  [[113](#bib.bib113)] | Neural networks on IoT devices.
    | Distills from a pre-trained NN to obtain a smaller NN that performs classification
    on a subset of the entire space. | 10ms inference latency on a mobile device.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Omidshafiei *et al.*  [[535](#bib.bib535)] | Multi-task multi-agent reinforcement
    learning under partial observability. | Deep recurrent Q-networks & cautiously-optimistic
    learners to approximate action-value function; decentralized concurrent experience
    replays trajectories to stabilize training. | Near-optimal execution time. |'
  prefs: []
  type: TYPE_TB
- en: '| Training parallelism | Recht *et al.*  [[536](#bib.bib536)] | Parallelized
    SGD. | Eliminates overhead associated with locking in distributed SGD. | Up to
    10$\times$ speed up in distributed training. |'
  prefs: []
  type: TYPE_TB
- en: '| Goyal *et al.*  [[537](#bib.bib537)] | Distributed synchronous SGD. | Employs
    a hyper-parameter-free learning rule to adjust the learning rate and a warmup
    mechanism to address the early optimization problem. | Trains billions of images
    per day. |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang *et al.*  [[538](#bib.bib538)] | Asynchronous distributed SGD. | Combines
    the stochastic variance reduced gradient algorithm and a delayed proximal gradient
    algorithm. | Up to 6$\times$ speed up |'
  prefs: []
  type: TYPE_TB
- en: '| Hardy *et al.*  [[539](#bib.bib539)] | Distributed deep learning on edge-devices.
    | Compression technique (*AdaComp*) to reduce ingress traffic at parameter severs.
    | Up to 191$\times$ reduction in ingress traffic. |'
  prefs: []
  type: TYPE_TB
- en: '| McMahan *et al.*  [[540](#bib.bib540)] | Distributed training on mobile devices.
    | Users collectively enjoy benefits of shared models trained with big data without
    centralized storage. | Up to 64.3$\times$ training speedup. |'
  prefs: []
  type: TYPE_TB
- en: '| Keith *et al.*  [[541](#bib.bib541)] | Data computation over mobile devices.
    | Secure multi-party computation to obtain model parameters on distributed mobile
    devices. | Up to 1.98$\times$ communication expansion. |'
  prefs: []
  type: TYPE_TB
- en: Mobile systems generate and consume massive volumes of mobile data every day.
    This may involve similar content, but which is distributed around the world. Moving
    such data to centralized servers to perform model training and evaluation inevitably
    introduces communication and storage overheads, which does not scale. However,
    neglecting characteristics embedded in mobile data, which are associated with
    local culture, human mobility, geographical topology, etc., during model training
    can compromise the robustness of the model and implicitly the performance of the
    mobile network applications that build on such models. The solution is to offload
    model execution to distributed data centers or edge devices, to guarantee good
    performance, whilst alleviating the burden on the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: As such, one of the challenges facing parallelism, in the context of mobile
    networking, is that of training neural networks on a large number of mobile devices
    that are battery powered, have limited computational capabilities and in particular
    lack GPUs. The key goal of this paradigm is that of training with a large number
    of mobile CPUs at least as effective as with GPUs. The speed of training remains
    important, but becomes a secondary goal.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1688ab5747c700927585c7f67709d99d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19: The underlying principles of model parallelism (left) and training
    parallelism (right).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, there are two routes to addressing this problem, namely, *(i)* decomposing
    the model itself, to train (or make inference with) its components individually;
    or *(ii)* scaling the training process to perform model update at different locations
    associated with data containers. Both schemes allow one to train a single model
    without requiring to centralize all data. We illustrate the principles of these
    two approaches in Fig. [19](#S7.F19 "Figure 19 ‣ VII-B Tailoring Deep Learning
    to Distributed Data Containers ‣ VII Tailoring Deep Learning to Mobile Networks
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey") and summarize the
    existing work in Table [XXI](#S7.T21 "TABLE XXI ‣ VII-B Tailoring Deep Learning
    to Distributed Data Containers ‣ VII Tailoring Deep Learning to Mobile Networks
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Model Parallelism. Large-scale distributed deep learning is first studied in
    [[126](#bib.bib126)], where the authors develop a framework named *DistBelief*,
    which enables training complex neural networks on thousands of machines. In their
    framework, the full model is partitioned into smaller components and distributed
    over various machines. Only nodes with edges (e.g. connections between layers)
    that cross boundaries between machines are required to communicate for parameters
    update and inference. This system further involves a parameter server, which enables
    each model replica to obtain the latest parameters during training. Experiments
    demonstrate that the proposed framework can be training significantly faster on
    a CPU cluster, compared to training on a single GPU, while achieving state-of-the-art
    classification performance on ImageNet [[191](#bib.bib191)].
  prefs: []
  type: TYPE_NORMAL
- en: Teerapittayanon *et al.* propose deep neural networks tailored to distributed
    systems, which include cloud servers, fog layers and geographically distributed
    devices [[534](#bib.bib534)]. The authors scale the overall neural network architecture
    and distribute its components hierarchically from cloud to end devices. The model
    exploits local aggregators and binary weights, to reduce computational storage,
    and communication overheads, while maintaining decent accuracy. Experiments on
    a multi-view multi-camera dataset demonstrate that this proposal can perform efficient
    cloud-based training and local inference. Importantly, without violating latency
    constraints, the deep neural network obtains essential benefits associated with
    distributed systems, such as fault tolerance and privacy.
  prefs: []
  type: TYPE_NORMAL
- en: Coninck *et al.* consider distributing deep learning over IoT for classification
    applications [[113](#bib.bib113)]. Specifically, they deploy a small neural network
    to local devices, to perform coarse classification, which enables fast response
    filtered data to be sent to central servers. If the local model fails to classify,
    the larger neural network in the cloud is activated to perform fine-grained classification.
    The overall architecture maintains good accuracy, while significantly reducing
    the latency typically introduced by large model inference.
  prefs: []
  type: TYPE_NORMAL
- en: Decentralized methods can also be applied to deep reinforcement learning. In
    [[535](#bib.bib535)], Omidshafiei *et al.* consider a multi-agent system with
    partial observability and limited communication, which is common in mobile systems.
    They combine a set of sophisticated methods and algorithms, including hysteresis
    learners, a deep recurrent Q network, concurrent experience replay trajectories
    and distillation, to enable multi-agent coordination using a single joint policy
    under a set of decentralized partially observable MDPs. Their framework can potentially
    play an important role in addressing control problems in distributed mobile systems.
  prefs: []
  type: TYPE_NORMAL
- en: Training Parallelism is also essential for mobile system, as mobile data usually
    come asynchronously from different sources. Training models effectively while
    maintaining consistency, fast convergence, and accuracy remains however challenging [[542](#bib.bib542)].
  prefs: []
  type: TYPE_NORMAL
- en: A practical method to address this problem is to perform asynchronous SGD. The
    basic idea is to enable the server that maintains a model to accept delayed information
    (e.g. data, gradient updates) from workers. At each update iteration, the server
    only requires to wait for a smaller number of workers. This is essential for training
    a deep neural network over distributed machines in mobile systems. The asynchronous
    SGD is first studied in [[536](#bib.bib536)], where the authors propose a lock-free
    parallel SGD named HOGWILD, which demonstrates significant faster convergence
    over locking counterparts. The Downpour SGD in [[126](#bib.bib126)] improves the
    robustness of the training process when work nodes breakdown, as each model replica
    requests the latest version of the parameters. Hence a small number of machine
    failures will not have a significant impact on the training process. A similar
    idea has been employed in [[537](#bib.bib537)], where Goyal *et al.* investigate
    the usage of a set of techniques (i.e. learning rate adjustment, warm-up, batch
    normalization), which offer important insights into training large-scale deep
    neural networks on distributed systems. Eventually, their framework can train
    an network on ImageNet within 1 hour, which is impressive in comparison with traditional
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Zhang *et al.* argue that most of asynchronous SGD algorithms suffer from slow
    convergence, due to the inherent variance of stochastic gradients [[538](#bib.bib538)].
    They propose an improved SGD with variance reduction to speed up the convergence.
    Their algorithm outperforms other asynchronous SGD approaches in terms of convergence,
    when training deep neural networks on the Google Cloud Computing Platform. The
    asynchronous method has also been applied to deep reinforcement learning. In [[78](#bib.bib78)],
    the authors create multiple environments, which allows agents to perform asynchronous
    updates to the main structure. The new A3C algorithm breaks the sequential dependency
    and speeds up the training of the traditional Actor-Critic algorithm significantly.
    In [[539](#bib.bib539)], Hardy *et al.* further study distributed deep learning
    over cloud and edge devices. In particular, they propose a training algorithm,
    *AdaComp*, which allows to compress worker updates of the target model. This significantly
    reduce the communication overhead between cloud and edge, while retaining good
    fault tolerance.
  prefs: []
  type: TYPE_NORMAL
- en: Federated learning is an emerging parallelism approach that enables mobile devices
    to collaboratively learn a shared model, while retaining all training data on
    individual devices [[540](#bib.bib540), [543](#bib.bib543)]. Beyond offloading
    the training data from central servers, this approach performs model updates with
    a Secure Aggregation protocol [[541](#bib.bib541)], which decrypts the average
    updates only if enough users have participated, without inspecting individual
    updates.
  prefs: []
  type: TYPE_NORMAL
- en: VII-C Tailoring Deep Learning to Changing Mobile Network Environments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Mobile network environments often exhibit changing patterns over time. For
    instance, the spatial distributions of mobile data traffic over a region may vary
    significantly between different times of the day [[544](#bib.bib544)]. Applying
    a deep learning model in changing mobile environments requires lifelong learning
    ability to continuously absorb new features, without forgetting old but essential
    patterns. Moreover, new smartphone-targeted viruses are spreading fast via mobile
    networks and may severely jeopardize users’ privacy and business profits. These
    pose unprecedented challenges to current anomaly detection systems and anti-virus
    software, as such tools must react to new threats in a timely manner, using limited
    information. To this end, the model should have transfer learning ability, which
    can enable the fast transfer of knowledge from pre-trained models to different
    jobs or datasets. This will allow models to work well with limited threat samples
    (one-shot learning) or limited metadata descriptions of new threats (zero-shot
    learning). Therefore, both lifelong learning and transfer learning are essential
    for applications in ever changing mobile network environments. We illustrated
    these two learning paradigms in Fig. [20](#S7.F20 "Figure 20 ‣ VII-C Tailoring
    Deep Learning to Changing Mobile Network Environments ‣ VII Tailoring Deep Learning
    to Mobile Networks ‣ Deep Learning in Mobile and Wireless Networking: A Survey")
    and review essential research in this subsection.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b4b31d18adbacfddc9c26839444e5e21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20: The underlying principles of deep lifelong learning (left) and deep
    transfer learning (right). Lifelong learning retains the knowledge learned while
    transfer learning exploits labeled data of one domain to learn in a new target
    domain.'
  prefs: []
  type: TYPE_NORMAL
- en: Deep Lifelong Learning mimics human behaviors and seeks to build a machine that
    can continuously adapt to new environments, retain as much knowledge as possible
    from previous learning experience [[545](#bib.bib545)]. There exist several research
    efforts that adapt traditional deep learning to lifelong learning. For example,
    Lee *et al.* propose a dual-memory deep learning architecture for lifelong learning
    of everyday human behaviors over non-stationary data streams [[546](#bib.bib546)].
    To enable the pre-trained model to retain old knowledge while training with new
    data, their architecture includes two memory buffers, namely a deep memory and
    a fast memory. The deep memory is composed of several deep networks, which are
    built when the amount of data from an unseen distribution is accumulated and reaches
    a threshold. The fast memory component is a small neural network, which is updated
    immediately when coming across a new data sample. These two memory modules allow
    to perform continuous learning without forgetting old knowledge. Experiments on
    a non-stationary image data stream prove the effectiveness of this model, as it
    significantly outperforms other online deep learning algorithms. The memory mechanism
    has also been applied in [[547](#bib.bib547)]. In particular, the authors introduce
    a differentiable neural computer, which allows neural networks to dynamically
    read from and write to an external memory module. This enables lifelong lookup
    and forgetting of knowledge from external sources, as humans do.
  prefs: []
  type: TYPE_NORMAL
- en: Parisi *et al.* consider a different lifelong learning scenario in [[548](#bib.bib548)].
    They abandon the memory modules in [[546](#bib.bib546)] and design a self-organizing
    architecture with recurrent neurons for processing time-varying patterns. A variant
    of the Growing When Required network is employed in each layer, to to predict
    neural activation sequences from the previous network layer. This allows learning
    time-vary correlations between inputs and labels, without requiring a predefined
    number of classes. Importantly, the framework is robust, as it has tolerance to
    missing and corrupted sample labels, which is common in mobile data.
  prefs: []
  type: TYPE_NORMAL
- en: Another interesting deep lifelong learning architecture is presented in [[549](#bib.bib549)],
    where Tessler *et al.* build a DQN agent that can retain learned skills in playing
    the famous computer game Minecraft. The overall framework includes a pre-trained
    model, Deep Skill Network, which is trained a-priori on various sub-tasks of the
    game. When learning a new task, the old knowledge is maintained by incorporating
    reusable skills through a Deep Skill module, which consists of a Deep Skill Network
    array and a multi-skill distillation network. These allow the agent to selectively
    transfer knowledge to solve a new task. Experiments demonstrate that their proposal
    significantly outperforms traditional double DQNs in terms of accuracy and convergence.
    This technique has potential to be employed in solving mobile networking problems,
    as it can continuously acquire new knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep Transfer Learning: Unlike lifelong learning, transfer learning only seeks
    to use knowledge from a specific domain to aid learning in a target domain. Applying
    transfer learning can accelerate the new learning process, as the new task does
    not require to learn from scratch. This is essential to mobile network environments,
    as they require to agilely respond to new network patterns and threats. A number
    of important applications emerge in the computer network domain [[57](#bib.bib57)],
    such as Web mining [[550](#bib.bib550)], caching [[551](#bib.bib551)] and base
    station sleep strategies [[207](#bib.bib207)].'
  prefs: []
  type: TYPE_NORMAL
- en: There exist two extreme transfer learning paradigms, namely one-shot learning
    and zero-shot learning. One-shot learning refers to a learning method that gains
    as much information as possible about a category from only one or a handful of
    samples, given a pre-trained model [[552](#bib.bib552)]. On the other hand, zero-shot
    learning does not require any sample from a category [[553](#bib.bib553)]. It
    aims at learning a new distribution given meta description of the new category
    and correlations with existing training data. Though research towards deep one-shot
    learning [[95](#bib.bib95), [554](#bib.bib554)] and deep zero-shot learning [[555](#bib.bib555),
    [556](#bib.bib556)] is in its infancy, both paradigms are very promising in detecting
    new threats or traffic patterns in mobile networks.
  prefs: []
  type: TYPE_NORMAL
- en: VIII Future Research Perspectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As deep learning is achieving increasingly promising results in the mobile networking
    domain, several important research issues remain to be addressed in the future.
    We conclude our survey by discussing these challenges and pinpointing key mobile
    networking research problems that could be tackled with novel deep learning tools.
  prefs: []
  type: TYPE_NORMAL
- en: VIII-A Serving Deep Learning with Massive High-Quality Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deep neural networks rely on massive and high-quality data to achieve good performance.
    When training a large and complex architecture, data volume and quality are very
    important, as deeper models usually have a huge set of parameters to be learned
    and configured. This issue remains true in mobile network applications. Unfortunately,
    unlike in other research areas such as computer vision and NLP, high-quality and
    large-scale labeled datasets still lack for mobile network applications, because
    service provides and operators keep the data collected confidential and are reluctant
    to release datasets. While this makes sense from a user privacy standpoint, to
    some extent it restricts the development of deep learning mechanisms for problems
    in the mobile networking domain. Moreover, mobile data collected by sensors and
    network equipment are frequently subject to loss, redundancy, mislabeling and
    class imbalance, and thus cannot be directly employed for training purpose.
  prefs: []
  type: TYPE_NORMAL
- en: To build intelligent 5G mobile network architecture, efficient and mature streamlining
    platforms for mobile data processing are in demand. This requires considerable
    amount of research efforts for data collection, transmission, cleaning, clustering,
    transformation, and annonymization. Deep learning applications in the mobile network
    area can only advance if researchers and industry stakeholder release more datasets,
    with a view to benefiting a wide range of communities.
  prefs: []
  type: TYPE_NORMAL
- en: VIII-B Deep Learning for Spatio-Temporal Mobile Data Mining
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Accurate analysis of mobile traffic data over a geographical region is becoming
    increasingly essential for event localization, network resource allocation, context-based
    advertising and urban planning [[544](#bib.bib544)]. However, due to the mobility
    of smartphone users, the spatio-temporal distribution of mobile traffic [[557](#bib.bib557)]
    and application popularity [[558](#bib.bib558)] are difficult to understand (see
    the example city-scale traffic snapshot in Fig. [21](#S8.F21 "Figure 21 ‣ VIII-B
    Deep Learning for Spatio-Temporal Mobile Data Mining ‣ VIII Future Research Perspectives
    ‣ Deep Learning in Mobile and Wireless Networking: A Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b411bdb53da0444b743f902e3f9a78d9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21: Example of a 3D mobile traffic surface (left) and 2D projection
    (right) in Milan, Italy. Figures adapted from [[216](#bib.bib216)] using data
    from [[559](#bib.bib559)].'
  prefs: []
  type: TYPE_NORMAL
- en: Recent research suggests that data collected by mobile sensors (e.g. mobile
    traffic) over a city can be regarded as pictures taken by panoramic cameras, which
    provide a city-scale sensing system for urban surveillance [[560](#bib.bib560)].
    These traffic sensing images enclose information associated with the movements
    of individuals [[466](#bib.bib466)].
  prefs: []
  type: TYPE_NORMAL
- en: 'From both spatial and temporal dimensions perspective, we recognize that mobile
    traffic data have important similarity with videos or speech, which is an analogy
    made recently also in [[216](#bib.bib216)] and exemplified in Fig. [22](#S8.F22
    "Figure 22 ‣ VIII-B Deep Learning for Spatio-Temporal Mobile Data Mining ‣ VIII
    Future Research Perspectives ‣ Deep Learning in Mobile and Wireless Networking:
    A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/eb482af11f5646a8c15ee7b6fee19a57.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22: Analogies between mobile traffic data consumption in a city (left)
    and other types of data (right).'
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, both videos and the large-scale evolution of mobile traffic are
    composed of sequences of “frames”. Moreover, if we zoom into a small coverage
    area to measure long-term traffic consumption, we can observe that a single traffic
    consumption series looks similar to a natural language sequence. These observations
    suggest that, to some extent, well-established tools for computer vision (e.g.
    CNN) or NLP (e.g. RNN, LSTM) are promising candidate for mobile traffic analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond these similarity, we observe several properties of mobile traffic that
    makes it unique in comparison with images or language sequences. Namely,
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The values of neighboring ‘pixels’ in fine-grained traffic snapshots are not
    significantly different in general, while this happens quite often at the edges
    of natural images.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Single mobile traffic series usually exhibit some periodicity (both daily and
    weekly), yet this is not a feature seen among video pixels.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Due to user mobility, traffic consumption is more likely to stay or shift to
    neighboring cells in the near future, which is less likely to be seen in videos.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Such spatio-temporal correlations in mobile traffic can be exploited as prior
    knowledge for model design. We recognize several unique advantages of employing
    deep learning for mobile traffic data mining:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: CNN structures work well in imaging applications, thus can also serve mobile
    traffic analysis tasks, given the analogies mentioned before.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: LSTMs capture well temporal correlations in time series data such as natural
    language; hence this structure can also be adapted to traffic forecasting problems.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: GPU computing enables fast training of NNs and together with parallelization
    techniques can support low-latency mobile traffic analysis via deep learning tools.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In essence, we expect deep learning tools tailored to mobile networking, will
    overcome the limitation of traditional regression and interpolation tools such
    as Exponential Smoothing [[561](#bib.bib561)], Autoregressive Integrated Moving
    Average model [[562](#bib.bib562)], or unifrom interpolation, which are commonly
    used in operational networks.
  prefs: []
  type: TYPE_NORMAL
- en: VIII-C Deep learning for Geometric Mobile Data Mining
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As discussed in Sec. [III-D](#S3.SS4 "III-D Advantages of Deep Learning in
    Mobile and Wireless Networking ‣ III Deep Learning 101 ‣ Deep Learning in Mobile
    and Wireless Networking: A Survey"), certain mobile data has important geometric
    properties. For instance, the location of mobile users or base stations along
    with the data carried can be viewed as point clouds in a 2D plane. If the temporal
    dimension is also added, this leads to a 3D point cloud representation, with either
    fixed or changing locations. In addition, the connectivity of mobile devices,
    routers, base stations, gateways, and so on can naturally construct a directed
    graph, where entities are represented as vertices, the links between them can
    be seen as edges, and data flows may give direction to these edges. We show examples
    of geometric mobile data and their potential representations in Fig. [23](#S8.F23
    "Figure 23 ‣ VIII-C Deep learning for Geometric Mobile Data Mining ‣ VIII Future
    Research Perspectives ‣ Deep Learning in Mobile and Wireless Networking: A Survey").
    At the top of the figure a group of mobile users is represented as a point cloud.
    Likewise, mobile network entities (e.g. base station, gateway, users) are regarded
    as graphs below, following the rationale explained below. Due to the inherent
    complexity of such representations, traditional ML tools usually struggle to interpret
    geometric data and make reliable inferencess.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5040195930bbfd0c6711fe5a6f9ec24f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 23: Examples of mobile data with geometric properties (left), their
    geometric representations (middle) and their candidate models for analysis (right).
    PointNet++ could be used to infer user trajectories when fed with point cloud
    representations of user locations (above); A GraphCNN may be employed to forecast
    future mobile traffic demand at base station level (below).'
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, a variety of deep learning toolboxes for modelling geometric data
    exist, albeit not having been widely employed in mobile networking yet. For instance,
    PointNet [[563](#bib.bib563)] and the follow on PointNet++ [[100](#bib.bib100)]
    are the first solutions that employ deep learning for 3D point cloud applications,
    including classification and segmentation [[564](#bib.bib564)]. We recognize that
    similar ideas can be applied to geometric mobile data analysis, such as clustering
    of mobile users or base stations, or user trajectory predictions. Further, deep
    learning for graphical data analysis is also evolving rapidly [[565](#bib.bib565)].
    This is triggered by research on Graph CNNs [[101](#bib.bib101)], which brings
    convolution concepts to graph-structured data. The applicability of Graph CNNs
    can be further extend to the temporal domain [[566](#bib.bib566)]. One possible
    application is the prediction of future traffic demand at individual base station
    level. We expect that such novel architectures will play an increasingly important
    role in network graph analysis and applications such as anomaly detection over
    a mobile network graph.
  prefs: []
  type: TYPE_NORMAL
- en: VIII-D Deep Unsupervised Learning in Mobile Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We observe that current deep learning practices in mobile networks largely employ
    supervised learning and reinforcement learning. However, as mobile networks generate
    considerable amounts of unlabeled data every day, data labeling is costly and
    requires domain-specific knowledge. To facilitate the analysis of raw mobile network
    data, unsupervised learning becomes essential in extracting insights from unlabeled
    data [[567](#bib.bib567)], so as to optimize the mobile network functionality
    to improve QoE.
  prefs: []
  type: TYPE_NORMAL
- en: The potential of a range of unsupervised deep learning tools including AE, RBM
    and GAN remains to be further explored. In general, these models require light
    feature engineering and are thus promising for learning from heterogeneous and
    unstructured mobile data. For instance, deep AEs work well for unsupervised anomaly
    detection [[568](#bib.bib568)]. Though less popular, RBMs can perform layer-wise
    unsupervised pre-training, which can accelerate the overall model training process.
    GANs are good at imitating data distributions, thus could be employed to mimic
    real mobile network environments. Recent research reveals that GANs can even protect
    communications by crafting custom cryptography to avoid eavesdropping [[569](#bib.bib569)].
    All these tools require further research to fulfill their full potentials in the
    mobile networking domain.
  prefs: []
  type: TYPE_NORMAL
- en: VIII-E Deep Reinforcement Learning for Mobile Network Control
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many mobile network control problems have been solved by constrained optimization,
    dynamic programming and game theory approaches. Unfortunately, these methods either
    make strong assumptions about the objective functions (e.g. function convexity)
    or data distribution (e.g. Gaussian or Poisson distributed), or suffer from high
    time and space complexity. As mobile networks become increasingly complex, such
    assumptions sometimes turn unrealistic. The objective functions are further affected
    by their increasingly large sets of variables, that pose severe computational
    and memory challenges to existing mathematical approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast, deep reinforcement learning does not make strong assumptions about
    the target system. It employs function approximation, which explicitly addresses
    the problem of large state-action spaces, enabling reinforcement learning to scale
    to network control problems that were previously considered hard. Inspired by
    remarkable achievements in Atari [[19](#bib.bib19)] and Go [[570](#bib.bib570)]
    games, a number of researchers begin to explore DRL to solve complex network control
    problems, as we discussed in Sec. [VI-G](#S6.SS7 "VI-G Deep Learning Driven Network
    Control ‣ VI Deep Learning Driven Mobile and Wireless Networks ‣ Deep Learning
    in Mobile and Wireless Networking: A Survey"). However, these works only scratch
    the surface and the potential of DRL to tackle mobile network control problems
    remains largely unexplored. For instance, as DeepMind trains a DRL agent to reduce
    Google’s data centers cooling bill,^(33)^(33)33DeepMind AI Reduces Google Data
    Center Cooling Bill by 40% https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/
    DRL could be exploited to extract rich features from cellular networks and enable
    intelligent on/off base stations switching, to reduce the infrastructure’s energy
    footprint. Such exciting applications make us believe that advances in DRL that
    are yet to appear can revolutionize the autonomous control of future mobile networks.'
  prefs: []
  type: TYPE_NORMAL
- en: VIII-F Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deep learning is playing an increasingly important role in the mobile and wireless
    networking domain. In this paper, we provided a comprehensive survey of recent
    work that lies at the intersection between deep learning and mobile networking.
    We summarized both basic concepts and advanced principles of various deep learning
    models, then reviewed work specific to mobile networks across different application
    scenarios. We discussed how to tailor deep learning models to general mobile networking
    applications, an aspect overlooked by previous surveys. We concluded by pinpointing
    several open research issues and promising directions, which may lead to valuable
    future research results. Our hope is that this article will become a definite
    guide to researchers and practitioners interested in applying machine intelligence
    to complex problems in mobile network environments.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We would like to thank Zongzuo Wang for sharing valuable insights on deep learning,
    which helped improving the quality of this paper. We also thank the anonymous
    reviewers, whose detailed and thoughtful feedback helped us give this survey more
    depth and a broader scope.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Cisco. Cisco Visual Networking Index: Forecast and Methodology, 2016-2021,
    June 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Ning Wang, Ekram Hossain, and Vijay K Bhargava. Backhauling 5G small cells:
    A radio resource management perspective. IEEE Wireless Communications, 22(5):41–49,
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Fabio Giust, Luca Cominardi, and Carlos J Bernardos. Distributed mobility
    management for future 5G networks: overview and analysis of existing approaches.
    IEEE Communications Magazine, 53(1):142–149, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Mamta Agiwal, Abhishek Roy, and Navrati Saxena. Next generation 5G wireless
    networks: A comprehensive survey. IEEE Communications Surveys & Tutorials, 18(3):1617–1655,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] Akhil Gupta and Rakesh Kumar Jha. A survey of 5G network: Architecture
    and emerging technologies. IEEE access, 3:1206–1232, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] Kan Zheng, Zhe Yang, Kuan Zhang, Periklis Chatzimisios, Kan Yang, and Wei
    Xiang. Big data-driven optimization for mobile networks toward 5G. IEEE network,
    30(1):44–51, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] Chunxiao Jiang, Haijun Zhang, Yong Ren, Zhu Han, Kwang-Cheng Chen, and
    Lajos Hanzo. Machine learning paradigms for next-generation wireless networks.
    IEEE Wireless Communications, 24(2):98–105, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Duong D Nguyen, Hung X Nguyen, and Langford B White. Reinforcement learning
    with network-assisted feedback for heterogeneous rat selection. IEEE Transactions
    on Wireless Communications, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Fairuz Amalina Narudin, Ali Feizollah, Nor Badrul Anuar, and Abdullah Gani.
    Evaluation of machine learning classifiers for mobile malware detection. Soft
    Computing, 20(1):343–357, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Kevin Hsieh, Aaron Harlap, Nandita Vijaykumar, Dimitris Konomis, Gregory R
    Ganger, Phillip B Gibbons, and Onur Mutlu. Gaia: Geo-distributed machine learning
    approaching LAN speeds. In USENIX Symposium on Networked Systems Design and Implementation
    (NSDI), pages 629–647, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Wencong Xiao, Jilong Xue, Youshan Miao, Zhen Li, Cheng Chen, Ming Wu,
    Wei Li, and Lidong Zhou. Tux2: Distributed graph computation for machine learning.
    In USENIX Symposium on Networked Systems Design and Implementation (NSDI), pages
    669–682, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] Paolini, Monica and Fili, Senza . Mastering Analytics: How to benefit
    from big data and network complexity: An Analyst Report. RCR Wireless News, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Chaoyun Zhang, Pan Zhou, Chenghua Li, and Lijun Liu. A convolutional neural
    network for leaves recognition using data augmentation. In Proc. IEEE International
    Conference on Pervasive Intelligence and Computing (PICOM), pages 2143–2150, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Richard Socher, Yoshua Bengio, and Christopher D Manning. Deep learning
    for NLP (without magic). In Tutorial Abstracts of ACL 2012, pages 5–5\. Association
    for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] IEEE Network special issue: Exploring Deep Learning for Efficient and
    Reliable Mobile Sensing. http://www.comsoc.org/netmag/cfp/exploring-deep-learning-efficient-and-reliable-mobile-sensing,
    2017. [Online; accessed 14-July-2017].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] Mowei Wang, Yong Cui, Xin Wang, Shihan Xiao, and Junchen Jiang. Machine
    learning for networking: Workflow, advances and opportunities. IEEE Network, 32(2):92–99,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Mohammad Abu Alsheikh, Dusit Niyato, Shaowei Lin, Hwee-Pink Tan, and Zhu
    Han. Mobile big data analytics using deep learning and Apache Spark. IEEE network,
    30(3):22–29, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep learning. MIT
    press, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel
    Veness, Marc G. Bellemare, Alex Graves, Martin Riedmiller, Andreas K. Fidjeland,
    Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou,
    Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and Demis Hassabis. Human-level
    control through deep reinforcement learning. Nature, 518(7540):529–533, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature,
    521(7553):436–444, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Jürgen Schmidhuber. Deep learning in neural networks: An overview. Neural
    networks, 61:85–117, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Weibo Liu, Zidong Wang, Xiaohui Liu, Nianyin Zeng, Yurong Liu, and Fuad E
    Alsaadi. A survey of deep neural network architectures and their applications.
    Neurocomputing, 234:11–26, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] Li Deng, Dong Yu, et al. Deep learning: methods and applications. Foundations
    and Trends® in Signal Processing, 7(3–4):197–387, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Li Deng. A tutorial survey of architectures, algorithms, and applications
    for deep learning. APSIPA Transactions on Signal and Information Processing, 3,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] Samira Pouyanfar, Saad Sadiq, Yilin Yan, Haiman Tian, Yudong Tao, Maria Presa
    Reyes, Mei-Ling Shyu, Shu-Ching Chen, and S. S. Iyengar. A Survey on Deep Learning:
    Algorithms, Techniques, and Applications. ACM Computing Surveys (CSUR), 51(5):92:1–92:36,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, and Anil Anthony
    Bharath. Deep reinforcement learning: A brief survey. IEEE Signal Processing Magazine,
    34(6):26–38, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] Ahmed Hussein, Mohamed Medhat Gaber, Eyad Elyan, and Chrisina Jayne. Imitation
    learning: A survey of learning methods. ACM Computing Surveys (CSUR), 50(2):21:1–21:35,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] Xue-Wen Chen and Xiaotong Lin. Big data deep learning: challenges and
    perspectives. IEEE access, 2:514–525, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] Maryam M Najafabadi, Flavio Villanustre, Taghi M Khoshgoftaar, Naeem Seliya,
    Randall Wald, and Edin Muharemagic. Deep learning applications and challenges
    in big data analytics. Journal of Big Data, 2(1):1, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] NF Hordri, A Samar, SS Yuhaniz, and SM Shamsuddin. A systematic literature
    review on features of deep learning in big data analytics. International Journal
    of Advances in Soft Computing & Its Applications, 9(1), 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Mehdi Gheisari, Guojun Wang, and Md Zakirul Alam Bhuiyan. A survey on
    deep learning in big data. In Proc. IEEE International Conference on Computational
    Science and Engineering (CSE) and Embedded and Ubiquitous Computing (EUC), volume 2,
    pages 173–180, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] Shuai Zhang, Lina Yao, and Aixin Sun. Deep learning based recommender
    system: A survey and new perspectives. arXiv preprint arXiv:1707.07435, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Shui Yu, Meng Liu, Wanchun Dou, Xiting Liu, and Sanming Zhou. Networking
    for big data: A survey. IEEE Communications Surveys & Tutorials, 19(1):531–549,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] Mohammad Abu Alsheikh, Shaowei Lin, Dusit Niyato, and Hwee-Pink Tan. Machine
    learning in wireless sensor networks: Algorithms, strategies, and applications.
    IEEE Communications Surveys & Tutorials, 16(4):1996–2018, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] Chun-Wei Tsai, Chin-Feng Lai, Ming-Chao Chiang, Laurence T Yang, et al.
    Data mining for Internet of things: A survey. IEEE Communications Surveys and
    Tutorials, 16(1):77–97, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] Xiang Cheng, Luoyang Fang, Xuemin Hong, and Liuqing Yang. Exploiting mobile
    big data: Sources, features, and applications. IEEE Network, 31(1):72–79, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] Mario Bkassiny, Yang Li, and Sudharman K Jayaweera. A survey on machine-learning
    techniques in cognitive radios. IEEE Communications Surveys & Tutorials, 15(3):1136–1159,
    2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] Jeffrey G Andrews, Stefano Buzzi, Wan Choi, Stephen V Hanly, Angel Lozano,
    Anthony CK Soong, and Jianzhong Charlie Zhang. What will 5G be? IEEE Journal on
    selected areas in communications, 32(6):1065–1082, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] Nisha Panwar, Shantanu Sharma, and Awadhesh Kumar Singh. A survey on 5G:
    The next generation of mobile communication. Physical Communication, 18:64–84,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] Olakunle Elijah, Chee Yen Leow, Tharek Abdul Rahman, Solomon Nunoo, and
    Solomon Zakwoi Iliya. A comprehensive survey of pilot contamination in massive
    MIMO–5G system. IEEE Communications Surveys & Tutorials, 18(2):905–923, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] Stefano Buzzi, I Chih-Lin, Thierry E Klein, H Vincent Poor, Chenyang Yang,
    and Alessio Zappone. A survey of energy-efficient techniques for 5G networks and
    challenges ahead. IEEE Journal on Selected Areas in Communications, 34(4):697–709,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] Mugen Peng, Yong Li, Zhongyuan Zhao, and Chonggang Wang. System architecture
    and key technologies for 5G heterogeneous cloud radio access networks. IEEE network,
    29(2):6–14, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] Yong Niu, Yong Li, Depeng Jin, Li Su, and Athanasios V Vasilakos. A survey
    of millimeter wave communications (mmwave) for 5G: opportunities and challenges.
    Wireless Networks, 21(8):2657–2676, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] Xenofon Foukas, Georgios Patounas, Ahmed Elmokashfi, and Mahesh K Marina.
    Network slicing in 5G: Survey and challenges. IEEE Communications Magazine, 55(5):94–100,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] Tarik Taleb, Konstantinos Samdanis, Badr Mada, Hannu Flinck, Sunny Dutta,
    and Dario Sabella. On multi-access edge computing: A survey of the emerging 5G
    network edge architecture & orchestration. IEEE Communications Surveys & Tutorials,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] Pavel Mach and Zdenek Becvar. Mobile edge computing: A survey on architecture
    and computation offloading. IEEE Communications Surveys & Tutorials, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] Yuyi Mao, Changsheng You, Jun Zhang, Kaibin Huang, and Khaled B Letaief.
    A survey on mobile edge computing: The communication perspective. IEEE Communications
    Surveys & Tutorials, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] Ying Wang, Peilong Li, Lei Jiao, Zhou Su, Nan Cheng, Xuemin Sherman Shen,
    and Ping Zhang. A data-driven architecture for personalized QoE management in
    5G wireless networks. IEEE Wireless Communications, 24(1):102–110, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] Qilong Han, Shuang Liang, and Hongli Zhang. Mobile cloud sensing, big
    data, and 5G networks make an intelligent and smart world. IEEE Network, 29(2):40–45,
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] Sukhdeep Singh, Navrati Saxena, Abhishek Roy, and HanSeok Kim. A survey
    on 5G network technologies from social perspective. IETE Technical Review, 34(1):30–39,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] Min Chen, Jun Yang, Yixue Hao, Shiwen Mao, and Kai Hwang. A 5G cognitive
    system for healthcare. Big Data and Cognitive Computing, 1(1):2, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] Xianfu Chen, Jinsong Wu, Yueming Cai, Honggang Zhang, and Tao Chen. Energy-efficiency
    oriented traffic offloading in wireless networks: A brief survey and a learning
    approach for heterogeneous cellular networks. IEEE Journal on Selected Areas in
    Communications, 33(4):627–640, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] Jinsong Wu, Song Guo, Jie Li, and Deze Zeng. Big data meet green challenges:
    big data toward green applications. IEEE Systems Journal, 10(3):888–900, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] Teodora Sandra Buda, Haytham Assem, Lei Xu, Danny Raz, Udi Margolin, Elisha
    Rosensweig, Diego R Lopez, Marius-Iulian Corici, Mikhail Smirnov, Robert Mullins,
    et al. Can machine learning aid in delivering new use cases and scenarios in 5G?
    In IEEE/IFIP Network Operations and Management Symposium (NOMS), pages 1279–1284,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] Ali Imran, Ahmed Zoha, and Adnan Abu-Dayya. Challenges in 5G: how to empower
    SON with big data for enabling 5G. IEEE Network, 28(6):27–33, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] Bharath Keshavamurthy and Mohammad Ashraf. Conceptual design of proactive
    SONs based on the big data framework for 5G cellular networks: A novel machine
    learning perspective facilitating a shift in the son paradigm. In Proc. IEEE International
    Conference on System Modeling & Advancement in Research Trends (SMART), pages
    298–304, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] Paulo Valente Klaine, Muhammad Ali Imran, Oluwakayode Onireti, and Richard Demo
    Souza. A survey of machine learning techniques applied to self organizing cellular
    networks. IEEE Communications Surveys and Tutorials, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] Rongpeng Li, Zhifeng Zhao, Xuan Zhou, Guoru Ding, Yan Chen, Zhongyao Wang,
    and Honggang Zhang. Intelligent 5G: When cellular networks meet artificial intelligence.
    IEEE Wireless communications, 24(5):175–183, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] Nicola Bui, Matteo Cesana, S Amir Hosseini, Qi Liao, Ilaria Malanchini,
    and Joerg Widmer. A survey of anticipatory mobile networking: Context-based classification,
    prediction methodologies, and optimization techniques. IEEE Communications Surveys
    & Tutorials, 19(3):1790–1821, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] Panagiotis Kasnesis, Charalampos Patrikakis, and Iakovos Venieris. Changing
    the game of mobile data analysis with deep learning. IT Professional, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] Xiang Cheng, Luoyang Fang, Liuqing Yang, and Shuguang Cui. Mobile big
    data: the fuel for data-driven wireless. IEEE Internet of Things Journal, 4(5):1489–1516,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] Lidong Wang and Randy Jones. Big data analytics for network intrusion
    detection: A survey. International Journal of Networks and Communications, 7(1):24–31,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] Nei Kato, Zubair Md Fadlullah, Bomin Mao, Fengxiao Tang, Osamu Akashi,
    Takeru Inoue, and Kimihiro Mizutani. The deep learning vision for heterogeneous
    network traffic control: proposal, challenges, and future perspective. IEEE Wireless
    Communications, 24(3):146–153, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] Michele Zorzi, Andrea Zanella, Alberto Testolin, Michele De Filippo De Grazia,
    and Marco Zorzi. Cognition-based networks: A new perspective on network optimization
    using learning and distributed intelligence. IEEE Access, 3:1512–1530, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] Zubair Fadlullah, Fengxiao Tang, Bomin Mao, Nei Kato, Osamu Akashi, Takeru
    Inoue, and Kimihiro Mizutani. State-of-the-art deep learning: Evolving machine
    intelligence toward tomorrow’s intelligent network traffic control systems. IEEE
    Communications Surveys & Tutorials, 19(4):2432–2455, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] Mehdi Mohammadi, Ala Al-Fuqaha, Sameh Sorour, and Mohsen Guizani. Deep
    Learning for IoT Big Data and Streaming Analytics: A Survey. IEEE Communications
    Surveys & Tutorials, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] Nauman Ahad, Junaid Qadir, and Nasir Ahsan. Neural networks in wireless
    networks: Techniques, applications and guidelines. Journal of Network and Computer
    Applications, 68:1–27, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] Qian Mao, Fei Hu, and Qi Hao. Deep learning for intelligent wireless networks:
    A comprehensive survey. IEEE Communications Surveys & Tutorials, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] Nguyen Cong Luong, Dinh Thai Hoang, Shimin Gong, Dusit Niyato, Ping Wang,
    Ying-Chang Liang, and Dong In Kim. Applications of Deep Reinforcement Learning
    in Communications and Networking: A Survey. arXiv preprint arXiv:1810.07862, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] Xiangwei Zhou, Mingxuan Sun, Ye Geoffrey Li, and Biing-Hwang Juang. Intelligent
    Wireless Communications Enabled by Cognitive Radio and Machine Learning. arXiv
    preprint arXiv:1710.11240, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] Mingzhe Chen, Ursula Challita, Walid Saad, Changchuan Yin, and Mérouane
    Debbah. Machine learning for wireless networks with artificial intelligence: A
    tutorial on neural networks. arXiv preprint arXiv:1710.02913, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] Ammar Gharaibeh, Mohammad A Salahuddin, Sayed Jahed Hussini, Abdallah
    Khreishah, Issa Khalil, Mohsen Guizani, and Ala Al-Fuqaha. Smart cities: A survey
    on data management, security, and enabling technologies. IEEE Communications Surveys
    & Tutorials, 19(4):2456–2501, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] Nicholas D Lane and Petko Georgiev. Can deep learning revolutionize mobile
    sensing? In Proc. 16th ACM International Workshop on Mobile Computing Systems
    and Applications, pages 117–122, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] Kaoru Ota, Minh Son Dao, Vasileios Mezaris, and Francesco GB De Natale.
    Deep learning for mobile multimedia: A survey. ACM Transactions on Multimedia
    Computing, Communications, and Applications (TOMM), 13(3s):34, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] Preeti Mishra, Vijay Varadharajan, Uday Tupakula, and Emmanuel S Pilli.
    A detailed investigation and analysis of using machine learning techniques for
    intrusion detection. IEEE Communications Surveys & Tutorials, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] Yuxi Li. Deep reinforcement learning: An overview. arXiv preprint arXiv:1701.07274,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] Longbiao Chen, Dingqi Yang, Daqing Zhang, Cheng Wang, Jonathan Li, et al.
    Deep mobile traffic forecast and complementary base station clustering for C-RAN
    optimization. Journal of Network and Computer Applications, 121:59–69, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy
    Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods
    for deep reinforcement learning. In Proc. International Conference on Machine
    Learning (ICML), pages 1928–1937, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein generative
    adversarial networks. In Proc. International Conference on Machine Learning, pages
    214–223, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] Andreas Damianou and Neil Lawrence. Deep Gaussian processes. In Artificial
    Intelligence and Statistics, pages 207–215, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] Marta Garnelo, Jonathan Schwarz, Dan Rosenbaum, Fabio Viola, Danilo J
    Rezende, SM Eslami, and Yee Whye Teh. Neural processes. arXiv preprint arXiv:1807.01622,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] Zhi-Hua Zhou and Ji Feng. Deep forest: towards an alternative to deep
    neural networks. In Proc. 26th International Joint Conference on Artificial Intelligence,
    pages 3553–3559\. AAAI Press, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] W. McCulloch and W. Pitts. A logical calculus of the ideas immanent in
    nervous activity. Bulletin of Mathematical Biophysics, (5).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning
    representations by back-propagating errors. Nature, 323(6088):533, 1986.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] Yann LeCun, Yoshua Bengio, et al. Convolutional networks for images, speech,
    and time series. The handbook of brain theory and neural networks, 3361(10):1995,
    1995.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification
    with deep convolutional neural networks. In Advances in neural information processing
    systems, pages 1097–1105, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] Pedro Domingos. A few useful things to know about machine learning. Communications
    of the ACM, 55(10):78–87, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] Ivor W Tsang, James T Kwok, and Pak-Ming Cheung. Core vector machines:
    Fast SVM training on very large data sets. Journal of Machine Learning Research,
    6:363–392, 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] Carl Edward Rasmussen and Christopher KI Williams. Gaussian processes
    for machine learning, volume 1. MIT press Cambridge, 2006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] Nicolas Le Roux and Yoshua Bengio. Representational power of restricted
    boltzmann machines and deep belief networks. Neural computation, 20(6):1631–1649,
    2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
    Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets.
    In Advances in neural information processing systems, pages 2672–2680, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] Florian Schroff, Dmitry Kalenichenko, and James Philbin. Facenet: A unified
    embedding for face recognition and clustering. In Proc. IEEE Conference on Computer
    Vision and Pattern Recognition, pages 815–823, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] Diederik P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling.
    Semi-supervised learning with deep generative models. In Advances in Neural Information
    Processing Systems, pages 3581–3589, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] Russell Stewart and Stefano Ermon. Label-free supervision of neural networks
    with physics and domain knowledge. In Proc. National Conference on Artificial
    Intelligence (AAAI), pages 2576–2582, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] Danilo Rezende, Ivo Danihelka, Karol Gregor, Daan Wierstra, et al. One-shot
    generalization in deep generative models. In Proc. International Conference on
    Machine Learning (ICML), pages 1521–1529, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] Richard Socher, Milind Ganjoo, Christopher D Manning, and Andrew Ng. Zero-shot
    learning through cross-modal transfer. In Advances in neural information processing
    systems, pages 935–943, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] Petko Georgiev, Sourav Bhattacharya, Nicholas D Lane, and Cecilia Mascolo.
    Low-resource multi-task audio sensing for mobile and embedded devices via shared
    deep neural network representations. Proc. ACM on Interactive, Mobile, Wearable
    and Ubiquitous Technologies (IMWUT), 1(3):50, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodola, Jan
    Svoboda, and Michael M Bronstein. Geometric deep learning on graphs and manifolds
    using mixture model CNNs. In Proc. IEEE Conference on Computer Vision and Pattern
    Recognition (CVPR), volume 1, page 3, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] Brigitte Le Roux and Henry Rouanet. Geometric data analysis: from correspondence
    analysis to structured data analysis. Springer Science & Business Media, 2004.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] Charles R. Qi, Li Yi, Hao Su, and Leonidas J Guibas. PointNet++: Deep
    hierarchical feature learning on point sets in a metric space. In Advances in
    Neural Information Processing Systems, pages 5099–5108, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] Thomas N Kipf and Max Welling. Semi-supervised classification with graph
    convolutional networks. In Proc. International Conference on Learning Representations
    (ICLR), 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] Xu Wang, Zimu Zhou, Fu Xiao, Kai Xing, Zheng Yang, Yunhao Liu, and Chunyi
    Peng. Spatio-temporal analysis and prediction of cellular traffic in metropolis.
    IEEE Transactions on Mobile Computing, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] Anh Nguyen, Jason Yosinski, and Jeff Clune. Deep neural networks are
    easily fooled: High confidence predictions for unrecognizable images. In Proc.
    IEEE Conference on Computer Vision and Pattern Recognition, pages 427–436, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] Vahid Behzadan and Arslan Munir. Vulnerability of deep reinforcement
    learning to policy induction attacks. In Proc. International Conference on Machine
    Learning and Data Mining in Pattern Recognition, pages 262–275\. Springer, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] Pooria Madani and Natalija Vlajic. Robustness of deep autoencoder in
    intrusion detection under adversarial contamination. In Proc. 5th ACM Annual Symposium
    and Bootcamp on Hot Topics in the Science of Security, page 1, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba.
    Network Dissection: Quantifying Interpretability of Deep Visual Representations.
    In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3319–3327,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] Mike Wu, Michael C Hughes, Sonali Parbhoo, Maurizio Zazzi, Volker Roth,
    and Finale Doshi-Velez. Beyond sparsity: Tree regularization of deep models for
    interpretability. 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] Supriyo Chakraborty, Richard Tomsett, Ramya Raghavendra, Daniel Harborne,
    Moustafa Alzantot, Federico Cerutti, Mani Srivastava, Alun Preece, Simon Julier,
    Raghuveer M Rao, et al. Interpretability of deep learning models: a survey of
    results. In Proc. IEEE Smart World Congress Workshop: DAIS, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] Luis Perez and Jason Wang. The effectiveness of data augmentation in
    image classification using deep learning. arXiv preprint arXiv:1712.04621, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] Chenxi Liu, Barret Zoph, Jonathon Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei,
    Alan Yuille, Jonathan Huang, and Kevin Murphy. Progressive neural architecture
    search. arXiv preprint arXiv:1712.00559, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] Wei Zhang, Kan Liu, Weidong Zhang, Youmei Zhang, and Jason Gu. Deep neural
    networks for wireless localization in indoor and outdoor environments. Neurocomputing,
    194:279–287, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] Francisco Javier Ordóñez and Daniel Roggen. Deep convolutional and LSTM
    recurrent neural networks for multimodal wearable activity recognition. Sensors,
    16(1):115, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] Elias De Coninck, Tim Verbelen, Bert Vankeirsbilck, Steven Bohez, Pieter
    Simoens, Piet Demeester, and Bart Dhoedt. Distributed neural networks for Internet
    of Things: the big-little approach. In Internet of Things. IoT Infrastructures:
    Second International Summit, IoT 360^∘ 2015, Rome, Italy, October 27-29, Revised
    Selected Papers, Part II, pages 484–492\. Springer, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] Norman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav
    Agrawal, Raminder Bajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, et al.
    In-datacenter performance analysis of a tensor processing unit. In ACM/IEEE 44th
    Annual International Symposium on Computer Architecture (ISCA), pages 1–12, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] John Nickolls, Ian Buck, Michael Garland, and Kevin Skadron. Scalable
    parallel programming with CUDA. Queue, 6(2):40–53, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[116] Sharan Chetlur, Cliff Woolley, Philippe Vandermersch, Jonathan Cohen,
    John Tran, Bryan Catanzaro, and Evan Shelhamer. cuDNN: Efficient primitives for
    deep learning. arXiv preprint arXiv:1410.0759, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[117] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
    Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al.
    TensorFlow: A system for large-scale machine learning. In USENIX Symposium on
    Operating Systems Design and Implementation (OSDI), volume 16, pages 265–283,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[118] Theano Development Team. Theano: A Python framework for fast computation
    of mathematical expressions. arXiv e-prints, abs/1605.02688, May 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[119] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan
    Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. Caffe: Convolutional
    architecture for fast feature embedding. arXiv preprint arXiv:1408.5093, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[120] R. Collobert, K. Kavukcuoglu, and C. Farabet. Torch7: A Matlab-like environment
    for machine learning. In Proc. BigLearn, NIPS Workshop, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[121] Vinayak Gokhale, Jonghoon Jin, Aysegul Dundar, Berin Martini, and Eugenio
    Culurciello. A 240 G-ops/s mobile coprocessor for deep neural networks. In Proc.
    IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages 682–687,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[122] ncnn – a high-performance neural network inference framework optimized
    for the mobile platform . https://github.com/Tencent/ncnn, 2017. [Online; accessed
    25-July-2017].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[123] Huawei announces the Kirin 970- new flagship SoC with AI capabilities.
    http://www.androidauthority.com/huawei-announces-kirin-970-797788/, 2017. [Online;
    accessed 01-Sep-2017].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[124] Core ML: Integrate machine learning models into your app. https://developer.apple.com/documentation/coreml,
    2017. [Online; accessed 25-July-2017].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[125] Ilya Sutskever, James Martens, George E Dahl, and Geoffrey E Hinton.
    On the importance of initialization and momentum in deep learning. Proc. international
    conference on machine learning (ICML), 28:1139–1147, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[126] Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark
    Mao, Andrew Senior, Paul Tucker, Ke Yang, Quoc V Le, et al. Large scale distributed
    deep networks. In Advances in neural information processing systems, pages 1223–1231,
    2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[127] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization.
    In Proc. International Conference on Learning Representations (ICLR), 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[128] Tim Kraska, Ameet Talwalkar, John C Duchi, Rean Griffith, Michael J Franklin,
    and Michael I Jordan. MLbase: A distributed machine-learning system. In CIDR,
    volume 1, pages 2–1, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[129] Trishul M Chilimbi, Yutaka Suzue, Johnson Apacible, and Karthik Kalyanaraman.
    Project adam: Building an efficient and scalable deep learning training system.
    In USENIX Symposium on Operating Systems Design and Implementation (OSDI), volume 14,
    pages 571–582, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[130] Henggang Cui, Hao Zhang, Gregory R Ganger, Phillip B Gibbons, and Eric P
    Xing. Geeps: Scalable deep learning on distributed GPUs with a GPU-specialized
    parameter server. In Proc. Eleventh ACM European Conference on Computer Systems,
    page 4, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[131] Xing Lin, Yair Rivenson, Nezih T. Yardimci, Muhammed Veli, Yi Luo, Mona
    Jarrahi, and Aydogan Ozcan. All-optical machine learning using diffractive deep
    neural networks. Science, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[132] Ryan Spring and Anshumali Shrivastava. Scalable and sustainable deep
    learning via randomized hashing. Proc. ACM SIGKDD Conference on Knowledge Discovery
    and Data Mining, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[133] Azalia Mirhoseini, Hieu Pham, Quoc V Le, Benoit Steiner, Rasmus Larsen,
    Yuefeng Zhou, Naveen Kumar, Mohammad Norouzi, Samy Bengio, and Jeff Dean. Device
    placement optimization with reinforcement learning. Proc. International Conference
    on Machine Learning, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[134] Eric P Xing, Qirong Ho, Wei Dai, Jin Kyu Kim, Jinliang Wei, Seunghak
    Lee, Xun Zheng, Pengtao Xie, Abhimanu Kumar, and Yaoliang Yu. Petuum: A new platform
    for distributed machine learning on big data. IEEE Transactions on Big Data, 1(2):49–67,
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[135] Philipp Moritz, Robert Nishihara, Stephanie Wang, Alexey Tumanov, Richard
    Liaw, Eric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael I Jordan,
    et al. Ray: A Distributed Framework for Emerging AI Applications. In Proc. 13th
    USENIX Symposium on Operating Systems Design and Implementation (OSDI), pages 561–577,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[136] Moustafa Alzantot, Yingnan Wang, Zhengshuang Ren, and Mani B Srivastava.
    RSTensorFlow: GPU enabled tensorflow for deep learning on commodity Android devices.
    In Proc. 1st ACM International Workshop on Deep Learning for Mobile Systems and
    Applications, pages 7–12, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[137] Hao Dong, Akara Supratak, Luo Mai, Fangde Liu, Axel Oehmichen, Simiao
    Yu, and Yike Guo. TensorLayer: A versatile library for efficient deep learning
    development. In Proc. ACM on Multimedia Conference, MM ’17, pages 1201–1204, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[138] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang,
    Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic
    differentiation in PyTorch. 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[139] Tianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun
    Xiao, Bing Xu, Chiyuan Zhang, and Zheng Zhang. Mxnet: A flexible and efficient
    machine learning library for heterogeneous distributed systems. arXiv preprint
    arXiv:1512.01274, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[140] Sebastian Ruder. An overview of gradient descent optimization algorithms.
    arXiv preprint arXiv:1609.04747, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[141] Matthew D Zeiler. ADADELTA: an adaptive learning rate method. arXiv preprint
    arXiv:1212.5701, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[142] Timothy Dozat. Incorporating Nesterov momentum into Adam. 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[143] Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David
    Pfau, Tom Schaul, and Nando de Freitas. Learning to learn by gradient descent
    by gradient descent. In Advances in Neural Information Processing Systems, pages
    3981–3989, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[144] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,
    Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going
    deeper with convolutions. In Proc. IEEE conference on computer vision and pattern
    recognition, pages 1–9, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[145] Yingxue Zhou, Sheng Chen, and Arindam Banerjee. Stable gradient descent.
    In Proc. Conference on Uncertainty in Artificial Intelligence, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[146] Wei Wen, Cong Xu, Feng Yan, Chunpeng Wu, Yandan Wang, Yiran Chen, and
    Hai Li. TernGrad: Ternary gradients to reduce communication in distributed deep
    learning. In Advances in neural information processing systems, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[147] Flavio Bonomi, Rodolfo Milito, Preethi Natarajan, and Jiang Zhu. Fog
    computing: A platform for internet of things and analytics. In Big Data and Internet
    of Things: A Roadmap for Smart Environments, pages 169–186\. Springer, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[148] Jiachen Mao, Xiang Chen, Kent W Nixon, Christopher Krieger, and Yiran
    Chen. MoDNN: Local distributed mobile computing system for deep neural network.
    In Proc. IEEE Design, Automation & Test in Europe Conference & Exhibition (DATE),
    pages 1396–1401, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[149] Mithun Mukherjee, Lei Shu, and Di Wang. Survey of fog computing: Fundamental,
    network applications, and research challenges. IEEE Communications Surveys & Tutorials,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[150] Luis M Vaquero and Luis Rodero-Merino. Finding your way in the fog: Towards
    a comprehensive definition of fog computing. ACM SIGCOMM Computer Communication
    Review, 44(5):27–32, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[151] Mohammad Aazam, Sherali Zeadally, and Khaled A Harras. Offloading in
    fog computing for IoT: Review, enabling technologies, and research opportunities.
    Future Generation Computer Systems, 87:278–289, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[152] Rajkumar Buyya, Satish Narayana Srirama, Giuliano Casale, Rodrigo Calheiros,
    Yogesh Simmhan, Blesson Varghese, Erol Gelenbe, Bahman Javadi, Luis Miguel Vaquero,
    Marco A. S. Netto, Adel Nadjaran Toosi, Maria Alejandra Rodriguez, Ignacio M.
    Llorente, Sabrina De Capitani Di Vimercati, Pierangela Samarati, Dejan Milojicic,
    Carlos Varela, Rami Bahsoon, Marcos Dias De Assuncao, Omer Rana, Wanlei Zhou,
    Hai Jin, Wolfgang Gentzsch, Albert Y. Zomaya, and Haiying Shen. A Manifesto for
    Future Generation Cloud Computing: Research Directions for the Next Decade. ACM
    Computing Survey, 51(5):105:1–105:38, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[153] Vivienne Sze, Yu-Hsin Chen, Tien-Ju Yang, and Joel S Emer. Efficient
    processing of deep neural networks: A tutorial and survey. Proc. of the IEEE,
    105(12):2295–2329, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[154] Suyoung Bang, Jingcheng Wang, Ziyun Li, Cao Gao, Yejoong Kim, Qing Dong,
    Yen-Po Chen, Laura Fick, Xun Sun, Ron Dreslinski, et al. 14.7 a 288$\mu$w programmable
    deep-learning processor with 270kb on-chip weight storage using non-uniform memory
    hierarchy for mobile intelligence. In Proc. IEEE International Conference on Solid-State
    Circuits (ISSCC), pages 250–251, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[155] Filipp Akopyan. Design and tool flow of IBM’s truenorth: an ultra-low
    power programmable neurosynaptic chip with 1 million neurons. In Proc. International
    Symposium on Physical Design, pages 59–60\. ACM, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[156] Seyyed Salar Latifi Oskouei, Hossein Golestani, Matin Hashemi, and Soheil
    Ghiasi. Cnndroid: GPU-accelerated execution of trained deep convolutional neural
    networks on Android. In Proc. Proc. ACM on Multimedia Conference, pages 1201–1205,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[157] Corinna Cortes, Xavi Gonzalvo, Vitaly Kuznetsov, Mehryar Mohri, and Scott
    Yang. Adanet: Adaptive structural learning of artificial neural networks. Proc.
    International Conference on Machine Learning (ICML), 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[158] Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh. A fast learning
    algorithm for deep belief nets. Neural computation, 18(7):1527–1554, 2006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[159] Honglak Lee, Roger Grosse, Rajesh Ranganath, and Andrew Y Ng. Convolutional
    deep belief networks for scalable unsupervised learning of hierarchical representations.
    In Proc. 26th ACM annual international conference on machine learning, pages 609–616,
    2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[160] Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and
    Pierre-Antoine Manzagol. Stacked denoising autoencoders: Learning useful representations
    in a deep network with a local denoising criterion. Journal of Machine Learning
    Research, 11(Dec):3371–3408, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[161] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In
    Proc. International Conference on Learning Representations (ICLR), 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[162] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual
    learning for image recognition. In Proc. IEEE conference on computer vision and
    pattern recognition, pages 770–778, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[163] Shuiwang Ji, Wei Xu, Ming Yang, and Kai Yu. 3D convolutional neural networks
    for human action recognition. IEEE transactions on pattern analysis and machine
    intelligence, 35(1):221–231, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[164] Gao Huang, Zhuang Liu, Kilian Q Weinberger, and Laurens van der Maaten.
    Densely connected convolutional networks. IEEE Conference on Computer Vision and
    Pattern Recognition, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[165] Felix A Gers, Jürgen Schmidhuber, and Fred Cummins. Learning to forget:
    Continual prediction with LSTM. 1999.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[166] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning
    with neural networks. In Advances in neural information processing systems, pages
    3104–3112, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[167] Shi Xingjian, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and
    Wang-chun Woo. Convolutional LSTM network: A machine learning approach for precipitation
    nowcasting. In Advances in neural information processing systems, pages 802–810,
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[168] Guo-Jun Qi. Loss-sensitive generative adversarial networks on Lipschitz
    densities. arXiv preprint arXiv:1701.06264, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[169] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training
    for high fidelity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[170] David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre,
    George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam,
    Marc Lanctot, et al. Mastering the game of Go with deep neural networks and tree
    search. Nature, 529(7587):484–489, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[171] Matteo Hessel, Joseph Modayil, Hado Van Hasselt, Tom Schaul, Georg Ostrovski,
    Will Dabney, Dan Horgan, Bilal Piot, Mohammad Azar, and David Silver. Rainbow:
    Combining improvements in deep reinforcement learning. 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[172] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg
    Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[173] Ronan Collobert and Samy Bengio. Links between perceptrons, MLPs and
    SVMs. In Proc. twenty-first ACM international conference on Machine learning,
    page 23, 2004.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[174] Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Deep sparse rectifier
    neural networks. In Proc. fourteenth international conference on artificial intelligence
    and statistics, pages 315–323, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[175] Günter Klambauer, Thomas Unterthiner, Andreas Mayr, and Sepp Hochreiter.
    Self-normalizing neural networks. In Advances in Neural Information Processing
    Systems, pages 971–980, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[176] Sergey Ioffe and Christian Szegedy. Batch Normalization: Accelerating
    Deep Network Training by Reducing Internal Covariate Shift. In Proc. International
    Conference on Machine Learning, pages 448–456, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[177] Geoffrey E Hinton. Training products of experts by minimizing contrastive
    divergence. Neural computation, 14(8):1771–1800, 2002.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[178] George Casella and Edward I George. Explaining the Gibbs sampler. The
    American Statistician, 46(3):167–174, 1992.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[179] Takashi Kuremoto, Masanao Obayashi, Kunikazu Kobayashi, Takaomi Hirata,
    and Shingo Mabu. Forecast chaotic time series data by DBNs. In Proc. 7th IEEE
    International Congress on Image and Signal Processing (CISP), pages 1130–1135,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[180] Yann Dauphin and Yoshua Bengio. Stochastic ratio matching of RBMs for
    sparse high-dimensional inputs. In Advances in Neural Information Processing Systems,
    pages 1340–1348, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[181] Tara N Sainath, Brian Kingsbury, Bhuvana Ramabhadran, Petr Fousek, Petr
    Novak, and Abdel-rahman Mohamed. Making deep belief networks effective for large
    vocabulary continuous speech recognition. In Proc. IEEE Workshop on Automatic
    Speech Recognition and Understanding (ASRU), pages 30–35, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[182] Yoshua Bengio et al. Learning deep architectures for AI. Foundations
    and trends® in Machine Learning, 2(1):1–127, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[183] Mayu Sakurada and Takehisa Yairi. Anomaly detection using autoencoders
    with nonlinear dimensionality reduction. In Proc. Workshop on Machine Learning
    for Sensory Data Analysis (MLSDA), page 4\. ACM, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[184] Miguel Nicolau, James McDermott, et al. A hybrid autoencoder and density
    estimation model for anomaly detection. In Proc. International Conference on Parallel
    Problem Solving from Nature, pages 717–726\. Springer, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[185] Vrizlynn LL Thing. IEEE 802.11 network anomaly detection and attack classification:
    A deep learning approach. In Proc. IEEE Wireless Communications and Networking
    Conference (WCNC), pages 1–6, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[186] Bomin Mao, Zubair Md Fadlullah, Fengxiao Tang, Nei Kato, Osamu Akashi,
    Takeru Inoue, and Kimihiro Mizutani. Routing or computing? the paradigm shift
    towards intelligent computer network packet transmission based on deep learning.
    IEEE Transactions on Computers, 66(11):1946–1960, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[187] Valentin Radu, Nicholas D Lane, Sourav Bhattacharya, Cecilia Mascolo,
    Mahesh K Marina, and Fahim Kawsar. Towards multimodal deep learning for activity
    recognition on mobile devices. In Proc. ACM International Joint Conference on
    Pervasive and Ubiquitous Computing: Adjunct, pages 185–188, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[188] Valentin Radu, Catherine Tong, Sourav Bhattacharya, Nicholas D Lane,
    Cecilia Mascolo, Mahesh K Marina, and Fahim Kawsar. Multimodal deep learning for
    activity and context recognition. Proc. ACM on Interactive, Mobile, Wearable and
    Ubiquitous Technologies (IMWUT), 1(4):157, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[189] Ramachandra Raghavendra and Christoph Busch. Learning deeply coupled
    autoencoders for smartphone based robust periocular verification. In Proc. IEEE
    International Conference on Image Processing (ICIP), pages 325–329, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[190] Jing Li, Jingyuan Wang, and Zhang Xiong. Wavelet-based stacked denoising
    autoencoders for cell phone base station user number prediction. In Proc. IEEE
    International Conference on Internet of Things (iThings) and IEEE Green Computing
    and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom)
    and IEEE Smart Data (SmartData), pages 833–838, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[191] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh,
    Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C.
    Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International
    Journal of Computer Vision (IJCV), 115(3):211–252, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[192] Junmo Kim Yunho Jeon. Active convolution: Learning the shape of convolution
    for image classification. In Proc. IEEE Conference on Computer Vision and Pattern
    Recognition, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[193] Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong Zhang, Han Hu, and
    Yichen Wei. Deformable convolutional networks. In Proc. IEEE International Conference
    on Computer Vision, pages 764–773, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[194] Xizhou Zhu, Han Hu, Stephen Lin, and Jifeng Dai. Deformable ConvNets
    v2: More Deformable, Better Results. arXiv preprint arXiv:1811.11168, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[195] Yoshua Bengio, Patrice Simard, and Paolo Frasconi. Learning long-term
    dependencies with gradient descent is difficult. IEEE transactions on neural networks,
    5(2):157–166, 1994.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[196] Alex Graves, Navdeep Jaitly, and Abdel-rahman Mohamed. Hybrid speech
    recognition with deep bidirectional LSTM. In Proc. IEEE Workshop on Automatic
    Speech Recognition and Understanding (ASRU), pages 273–278, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[197] Rie Johnson and Tong Zhang. Supervised and semi-supervised text categorization
    using LSTM for region embeddings. In Proc. International Conference on Machine
    Learning (ICML), pages 526–534, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[198] Ian Goodfellow. NIPS 2016 tutorial: Generative adversarial networks.
    arXiv preprint arXiv:1701.00160, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[199] Christian Ledig, Lucas Theis, Ferenc Huszár, Jose Caballero, Andrew Cunningham,
    Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et al.
    Photo-realistic single image super-resolution using a generative adversarial network.
    In Proc. IEEE Conference on Computer Vision and Pattern Recognition, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[200] Jianan Li, Xiaodan Liang, Yunchao Wei, Tingfa Xu, Jiashi Feng, and Shuicheng
    Yan. Perceptual generative adversarial networks for small object detection. In
    Proc. IEEE Conference on Computer Vision and Pattern Recognition, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[201] Yijun Li, Sifei Liu, Jimei Yang, and Ming-Hsuan Yang. Generative face
    completion. In IEEE Conference on Computer Vision and Pattern Recognition, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[202] Piotr Gawłowicz and Anatolij Zubow. NS3-Gym: Extending OpenAI Gym for
    Networking Research. arXiv preprint arXiv:1810.03943, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[203] Shixiang Gu, Timothy Lillicrap, Ilya Sutskever, and Sergey Levine. Continuous
    deep Q-learning with model-based acceleration. In Proc. International Conference
    on Machine Learning, pages 2829–2838, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[204] Matej Moravčík, Martin Schmid, Neil Burch, Viliam Lisỳ, Dustin Morrill,
    Nolan Bard, Trevor Davis, Kevin Waugh, Michael Johanson, and Michael Bowling.
    Deepstack: Expert-level artificial intelligence in heads-up no-limit poker. Science,
    356(6337):508–513, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[205] Sergey Levine, Peter Pastor, Alex Krizhevsky, Julian Ibarz, and Deirdre
    Quillen. Learning hand-eye coordination for robotic grasping with deep learning
    and large-scale data collection. The International Journal of Robotics Research,
    37(4-5):421–436, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[206] Ahmad EL Sallab, Mohammed Abdou, Etienne Perot, and Senthil Yogamani.
    Deep reinforcement learning framework for autonomous driving. Electronic Imaging,
    (19):70–76, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[207] Rongpeng Li, Zhifeng Zhao, Xianfu Chen, Jacques Palicot, and Honggang
    Zhang. Tact: A transfer actor-critic learning framework for energy saving in cellular
    radio access networks. IEEE Transactions on Wireless Communications, 13(4):2000–2011,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[208] Hasan AA Al-Rawi, Ming Ann Ng, and Kok-Lim Alvin Yau. Application of
    reinforcement learning to routing in distributed wireless networks: a review.
    Artificial Intelligence Review, 43(3):381–416, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[209] Yan-Jun Liu, Li Tang, Shaocheng Tong, CL Philip Chen, and Dong-Juan Li.
    Reinforcement learning design-based adaptive tracking control with less learning
    parameters for nonlinear discrete-time MIMO systems. IEEE Transactions on Neural
    Networks and Learning Systems, 26(1):165–176, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[210] Laura Pierucci and Davide Micheli. A neural network for quality of experience
    estimation in mobile communications. IEEE MultiMedia, 23(4):42–49, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[211] Youngjune L Gwon and HT Kung. Inferring origin flow patterns in wi-fi
    with deep learning. In Proc. 11th IEEE International Conference on Autonomic Computing
    (ICAC)), pages 73–83, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[212] Laisen Nie, Dingde Jiang, Shui Yu, and Houbing Song. Network traffic
    prediction based on deep belief network in wireless mesh backbone networks. In
    Proc. IEEEWireless Communications and Networking Conference (WCNC), pages 1–5,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[213] Vusumuzi Moyo et al. The generalization ability of artificial neural
    networks in forecasting TCP/IP traffic trends: How much does the size of learning
    rate matter? International Journal of Computer Science and Application, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[214] Jing Wang, Jian Tang, Zhiyuan Xu, Yanzhi Wang, Guoliang Xue, Xing Zhang,
    and Dejun Yang. Spatiotemporal modeling and prediction in cellular networks: A
    big data enabled deep learning approach. In Proc. 36th Annual IEEE International
    Conference on Computer Communications (INFOCOM), 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[215] Chaoyun Zhang and Paul Patras. Long-term mobile traffic forecasting using
    deep spatio-temporal neural networks. In Proc. Eighteenth ACM International Symposium
    on Mobile Ad Hoc Networking and Computing, pages 231–240, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[216] Chaoyun Zhang, Xi Ouyang, and Paul Patras. ZipNet-GAN: Inferring fine-grained
    mobile traffic patterns via a generative adversarial neural network. In Proc.
    13th ACM Conference on Emerging Networking Experiments and Technologies, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[217] Chih-Wei Huang, Chiu-Ti Chiang, and Qiuhui Li. A study of deep learning
    networks on mobile traffic forecasting. In Proc. 28th IEEE Annual International
    Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC), pages
    1–6, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[218] Chuanting Zhang, Haixia Zhang, Dongfeng Yuan, and Minggao Zhang. Citywide
    cellular traffic prediction based on densely connected convolutional neural networks.
    IEEE Communications Letters, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[219] Shiva Navabi, Chenwei Wang, Ozgun Y Bursalioglu, and Haralabos Papadopoulos.
    Predicting wireless channel features using neural networks. arXiv preprint arXiv:1802.00107,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[220] Zhanyi Wang. The applications of deep learning on traffic identification.
    BlackHat USA, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[221] Wei Wang, Ming Zhu, Jinlin Wang, Xuewen Zeng, and Zhongzhen Yang. End-to-end
    encrypted traffic classification with one-dimensional convolution neural networks.
    In Proc. IEEE International Conference on Intelligence and Security Informatics,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[222] Mohammad Lotfollahi, Ramin Shirali, Mahdi Jafari Siavoshani, and Mohammdsadegh
    Saberian. Deep packet: A novel approach for encrypted traffic classification using
    deep learning. arXiv preprint arXiv:1709.02656, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[223] Wei Wang, Ming Zhu, Xuewen Zeng, Xiaozhou Ye, and Yiqiang Sheng. Malware
    traffic classification using convolutional neural network for representation learning.
    In Proc. IEEE International Conference on Information Networking (ICOIN), pages
    712–717, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[224] Victor C Liang, Richard TB Ma, Wee Siong Ng, Li Wang, Marianne Winslett,
    Huayu Wu, Shanshan Ying, and Zhenjie Zhang. Mercury: Metro density prediction
    with recurrent neural network on streaming CDR data. In Proc. IEEE 32nd International
    Conference on Data Engineering (ICDE), pages 1374–1377, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[225] Bjarke Felbo, Pål Sundsøy, Alex’Sandy’ Pentland, Sune Lehmann, and Yves-Alexandre
    de Montjoye. Using deep learning to predict demographics from mobile phone metadata.
    In Proc. workshop track of the International Conference on Learning Representations
    (ICLR), 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[226] Nai Chun Chen, Wanqin Xie, Roy E Welsch, Kent Larson, and Jenny Xie.
    Comprehensive predictions of tourists’ next visit location based on call detail
    records using machine learning and deep learning methods. In Proc. IEEE International
    Congress on Big Data (BigData Congress), pages 1–6, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[227] Ziheng Lin, Mogeng Yin, Sidney Feygin, Madeleine Sheehan, Jean-Francois
    Paiement, and Alexei Pozdnoukhov. Deep generative models of urban mobility. IEEE
    Transactions on Intelligent Transportation Systems, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[228] Chang Xu, Kuiyu Chang, Khee-Chin Chua, Meishan Hu, and Zhenxiang Gao.
    Large-scale Wi-Fi hotspot classification via deep learning. In Proc. 26th International
    Conference on World Wide Web Companion, pages 857–858\. International World Wide
    Web Conferences Steering Committee, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[229] Qianyu Meng, Kun Wang, Bo Liu, Toshiaki Miyazaki, and Xiaoming He. QoE-based
    big data analysis with deep learning in pervasive edge environment. In Proc. IEEE
    International Conference on Communications (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[230] Luoyang Fang, Xiang Cheng, Haonan Wang, and Liuqing Yang. Mobile Demand
    Forecasting via Deep Graph-Sequence Spatiotemporal Modeling in Cellular Networks.
    IEEE Internet of Things Journal, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[231] Changqing Luo, Jinlong Ji, Qianlong Wang, Xuhui Chen, and Pan Li. Channel
    state information prediction for 5G wireless communications: A deep learning approach.
    IEEE Transactions on Network Science and Engineering, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[232] Peng Li, Zhikui Chen, Laurence T. Yang, Jing Gao, Qingchen Zhang, and
    M. Jamal Deen. An Improved Stacked Auto-Encoder for Network Traffic Flow Classification.
    IEEE Network, 32(6):22–27, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[233] Jie Feng, Xinlei Chen, Rundong Gao, Ming Zeng, and Yong Li. DeepTP: An
    End-to-End Neural Network for Mobile Cellular Traffic Prediction. IEEE Network,
    32(6):108–115, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[234] Hao Zhu, Yang Cao, Wei Wang, Tao Jiang, and Shi Jin. Deep Reinforcement
    Learning for Mobile Edge Caching: Review, New Features, and Open Issues. IEEE
    Network, 32(6):50–57, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[235] Sicong Liu and Junzhao Du. Poster: Mobiear-building an environment-independent
    acoustic sensing platform for the deaf using deep learning. In Proc. 14th ACM
    Annual International Conference on Mobile Systems, Applications, and Services
    Companion, pages 50–50, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[236] Liu Sicong, Zhou Zimu, Du Junzhao, Shangguan Longfei, Jun Han, and Xin
    Wang. Ubiear: Bringing location-independent sound awareness to the hard-of-hearing
    people with smartphones. Proc. ACM Interactive, Mobile, Wearable and Ubiquitous
    Technologies (IMWUT), 1(2):17, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[237] Vasu Jindal. Integrating mobile and cloud for PPG signal selection to
    monitor heart rate during intensive physical exercise. In Proc. ACM International
    Workshop on Mobile Software Engineering and Systems, pages 36–37, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[238] Edward Kim, Miguel Corte-Real, and Zubair Baloch. A deep semantic mobile
    application for thyroid cytopathology. In Medical Imaging 2016: PACS and Imaging
    Informatics: Next Generation and Innovations, volume 9789, page 97890A. International
    Society for Optics and Photonics, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[239] Aarti Sathyanarayana, Shafiq Joty, Luis Fernandez-Luque, Ferda Ofli,
    Jaideep Srivastava, Ahmed Elmagarmid, Teresa Arora, and Shahrad Taheri. Sleep
    quality prediction from wearable data using deep learning. JMIR mHealth and uHealth,
    4(4), 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[240] Honggui Li and Maria Trocan. Personal health indicators by deep learning
    of smart phone sensor data. In Proc. 3rd IEEE International Conference on Cybernetics
    (CYBCONF), pages 1–5, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[241] Mohammad-Parsa Hosseini, Tuyen X Tran, Dario Pompili, Kost Elisevich,
    and Hamid Soltanian-Zadeh. Deep learning with edge computing for localization
    of epileptogenicity using multimodal rs-fMRI and EEG big data. In Proc. IEEE International
    Conference on Autonomic Computing (ICAC), pages 83–92, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[242] Cosmin Stamate, George D Magoulas, Stefan Küppers, Effrosyni Nomikou,
    Ioannis Daskalopoulos, Marco U Luchini, Theano Moussouri, and George Roussos.
    Deep learning parkinson’s from smartphone data. In Proc. IEEE International Conference
    on Pervasive Computing and Communications (PerCom), pages 31–40, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[243] Tom Quisel, Luca Foschini, Alessio Signorini, and David C Kale. Collecting
    and analyzing millions of mhealth data streams. In Proc. 23rd ACM SIGKDD International
    Conference on Knowledge Discovery and Data Mining, pages 1971–1980, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[244] Usman Mahmood Khan, Zain Kabir, Syed Ali Hassan, and Syed Hassan Ahmed.
    A deep learning framework using passive WiFi sensing for respiration monitoring.
    In Proc. IEEE Global Communications Conference (GLOBECOM), pages 1–6, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[245] Dawei Li, Theodoros Salonidis, Nirmit V Desai, and Mooi Choo Chuah. Deepcham:
    Collaborative edge-mediated adaptive deep learning for mobile object recognition.
    In Proc. IEEE/ACM Symposium on Edge Computing (SEC), pages 64–76, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[246] Luis Tobías, Aurélien Ducournau, François Rousseau, Grégoire Mercier,
    and Ronan Fablet. Convolutional neural networks for object recognition on mobile
    devices: A case study. In Proc. 23rd IEEE International Conference on Pattern
    Recognition (ICPR), pages 3530–3535, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[247] Parisa Pouladzadeh and Shervin Shirmohammadi. Mobile multi-food recognition
    using deep learning. ACM Transactions on Multimedia Computing, Communications,
    and Applications (TOMM), 13(3s):36, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[248] Ryosuke Tanno, Koichi Okamoto, and Keiji Yanai. DeepFoodCam: A DCNN-based
    real-time mobile food recognition system. In Proc. 2nd ACM International Workshop
    on Multimedia Assisted Dietary Management, pages 89–89, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[249] Pallavi Kuhad, Abdulsalam Yassine, and Shervin Shimohammadi. Using distance
    estimation and deep learning to simplify calibration in food calorie measurement.
    In Proc. IEEE International Conference on Computational Intelligence and Virtual
    Environments for Measurement Systems and Applications (CIVEMSA), pages 1–6, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[250] Teng Teng and Xubo Yang. Facial expressions recognition based on convolutional
    neural networks for mobile virtual reality. In Proc. 15th ACM SIGGRAPH Conference
    on Virtual-Reality Continuum and Its Applications in Industry-Volume 1, pages
    475–478, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[251] Jinmeng Rao, Yanjun Qiao, Fu Ren, Junxing Wang, and Qingyun Du. A mobile
    outdoor augmented reality method combining deep learning object detection and
    spatial relationships for geovisualization. Sensors, 17(9):1951, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[252] Ming Zeng, Le T Nguyen, Bo Yu, Ole J Mengshoel, Jiang Zhu, Pang Wu, and
    Joy Zhang. Convolutional neural networks for human activity recognition using
    mobile sensors. In Proc. 6th IEEE International Conference on Mobile Computing,
    Applications and Services (MobiCASE), pages 197–205, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[253] Bandar Almaslukh, Jalal AlMuhtadi, and Abdelmonim Artoli. An effective
    deep autoencoder approach for online smartphone-based human activity recognition.
    International Journal of Computer Science and Network Security (IJCSNS), 17(4):160,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[254] Xinyu Li, Yanyi Zhang, Ivan Marsic, Aleksandra Sarcevic, and Randall S
    Burd. Deep learning for RFID-based activity recognition. In Proc. 14th ACM Conference
    on Embedded Network Sensor Systems CD-ROM, pages 164–175, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[255] Sourav Bhattacharya and Nicholas D Lane. From smart to deep: Robust activity
    recognition on smartwatches using deep learning. In Proc. IEEE International Conference
    on Pervasive Computing and Communication Workshops (PerCom Workshops), pages 1–6,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[256] Antreas Antoniou and Plamen Angelov. A general purpose intelligent surveillance
    system for mobile devices using deep learning. In Proc. IEEE International Joint
    Conference on Neural Networks (IJCNN), pages 2879–2886, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[257] Saiwen Wang, Jie Song, Jaime Lien, Ivan Poupyrev, and Otmar Hilliges.
    Interacting with Soli: Exploring fine-grained dynamic gesture recognition in the
    radio-frequency spectrum. In Proc. 29th ACM Annual Symposium on User Interface
    Software and Technology, pages 851–860, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[258] Yang Gao, Ning Zhang, Honghao Wang, Xiang Ding, Xu Ye, Guanling Chen,
    and Yu Cao. ihear food: Eating detection using commodity bluetooth headsets. In
    Proc. IEEE First International Conference on Connected Health: Applications, Systems
    and Engineering Technologies (CHASE), pages 163–172, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[259] Jindan Zhu, Amit Pande, Prasant Mohapatra, and Jay J Han. Using deep
    learning for energy expenditure estimation with wearable sensors. In Proc. 17th
    IEEE International Conference on E-health Networking, Application & Services (HealthCom),
    pages 501–506, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[260] Pål Sundsøy, Johannes Bjelland, B Reme, A Iqbal, and Eaman Jahani. Deep
    learning applied to mobile phone data for individual income classification. ICAITA
    doi, 10, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[261] Yuqing Chen and Yang Xue. A deep learning approach to human activity
    recognition based on single accelerometer. In Proc. IEEE International Conference
    on Systems, Man, and Cybernetics (SMC), pages 1488–1492, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[262] Sojeong Ha and Seungjin Choi. Convolutional neural networks for human
    activity recognition using multiple accelerometer and gyroscope sensors. In Proc.
    IEEE International Joint Conference on Neural Networks (IJCNN), pages 381–388,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[263] Marcus Edel and Enrico Köppe. Binarized-BLSTM-RNN based human activity
    recognition. In Proc. IEEE International Conference on Indoor Positioning and
    Indoor Navigation (IPIN), pages 1–7, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[264] Shuangshuang Xue, Lan Zhang, Anran Li, Xiang-Yang Li, Chaoyi Ruan, and
    Wenchao Huang. AppDNA: App behavior profiling via graph-based deep learning. In
    Proc. IEEE Conference on Computer Communications, pages 1475–1483, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[265] Huiqi Liu, Xiang-Yang Li, Lan Zhang, Yaochen Xie, Zhenan Wu, Qian Dai,
    Ge Chen, and Chunxiao Wan. Finding the stars in the fireworks: Deep understanding
    of motion sensor fingerprint. In Proc. IEEE Conference on Computer Communications,
    pages 126–134, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[266] Tsuyoshi Okita and Sozo Inoue. Recognition of multiple overlapping activities
    using compositional cnn-lstm model. In Proc. ACM International Joint Conference
    on Pervasive and Ubiquitous Computing and Proc. ACM International Symposium on
    Wearable Computers, pages 165–168\. ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[267] Gaurav Mittal, Kaushal B Yagnik, Mohit Garg, and Narayanan C Krishnan.
    Spotgarbage: smartphone app to detect garbage using deep learning. In Proc. ACM
    International Joint Conference on Pervasive and Ubiquitous Computing, pages 940–945,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[268] Lorenzo Seidenari, Claudio Baecchi, Tiberio Uricchio, Andrea Ferracani,
    Marco Bertini, and Alberto Del Bimbo. Deep artwork detection and retrieval for
    automatic context-aware audio guides. ACM Transactions on Multimedia Computing,
    Communications, and Applications (TOMM), 13(3s):35, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[269] Xiao Zeng, Kai Cao, and Mi Zhang. Mobiledeeppill: A small-footprint mobile
    deep learning system for recognizing unconstrained pill images. In Proc. 15th
    ACM Annual International Conference on Mobile Systems, Applications, and Services,
    pages 56–67, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[270] Han Zou, Yuxun Zhou, Jianfei Yang, Hao Jiang, Lihua Xie, and Costas J
    Spanos. Deepsense: Device-free human activity recognition via autoencoder long-term
    recurrent convolutional network. 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[271] Xiao Zeng. Mobile sensing through deep learning. In Proc. Workshop on
    MobiSys Ph. D. Forum, pages 5–6\. ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[272] Xuyu Wang, Lingjun Gao, and Shiwen Mao. PhaseFi: Phase fingerprinting
    for indoor localization with a deep learning approach. In Proc. IEEE Global Communications
    Conference (GLOBECOM), pages 1–6, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[273] Xuyu Wang, Lingjun Gao, and Shiwen Mao. CSI phase fingerprinting for
    indoor localization with a deep learning approach. IEEE Internet of Things Journal,
    3(6):1113–1123, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[274] Chunhai Feng, Sheheryar Arshad, Ruiyun Yu, and Yonghe Liu. Evaluation
    and improvement of activity detection systems with recurrent neural network. In
    Proc. IEEE International Conference on Communications (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[275] Bokai Cao, Lei Zheng, Chenwei Zhang, Philip S Yu, Andrea Piscitello,
    John Zulueta, Olu Ajilore, Kelly Ryan, and Alex D Leow. Deepmood: Modeling mobile
    phone typing dynamics for mood detection. In Proc. 23rd ACM SIGKDD International
    Conference on Knowledge Discovery and Data Mining, pages 747–755, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[276] Xukan Ran, Haoliang Chen, Xiaodan Zhu, Zhenming Liu, and Jiasi Chen.
    Deepdecision: A mobile deep learning framework for edge video analytics. In Proc.
    IEEE International Conference on Computer Communications, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[277] Siri Team. Deep Learning for Siri’s Voice: On-device Deep Mixture Density
    Networks for Hybrid Unit Selection Synthesis. https://machinelearning.apple.com/2017/08/06/siri-voices.html,
    2017. [Online; accessed 16-Sep-2017].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[278] Ian McGraw, Rohit Prabhavalkar, Raziel Alvarez, Montse Gonzalez Arenas,
    Kanishka Rao, David Rybach, Ouais Alsharif, Haşim Sak, Alexander Gruenstein, Françoise
    Beaufays, et al. Personalized speech recognition on mobile devices. In Proc. IEEE
    International Conference on Acoustics, Speech and Signal Processing (ICASSP),
    pages 5955–5959, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[279] Rohit Prabhavalkar, Ouais Alsharif, Antoine Bruguier, and Lan McGraw.
    On the compression of recurrent neural networks with an application to LVCSR acoustic
    modeling for embedded speech recognition. In Proc. IEEE International Conference
    on Acoustics, Speech and Signal Processing (ICASSP), pages 5970–5974, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[280] Takuya Yoshioka, Nobutaka Ito, Marc Delcroix, Atsunori Ogawa, Keisuke
    Kinoshita, Masakiyo Fujimoto, Chengzhu Yu, Wojciech J Fabian, Miquel Espi, Takuya
    Higuchi, et al. The NTT CHiME-3 system: Advances in speech enhancement and recognition
    for mobile multi-microphone devices. In Proc. IEEE Workshop on Automatic Speech
    Recognition and Understanding (ASRU), pages 436–443, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[281] Sherry Ruan, Jacob O Wobbrock, Kenny Liou, Andrew Ng, and James Landay.
    Speech is 3x faster than typing for english and mandarin text entry on mobile
    devices. arXiv preprint arXiv:1608.07323, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[282] Andrey Ignatov, Nikolay Kobyshev, Radu Timofte, Kenneth Vanhoey, and
    Luc Van Gool. DSLR-quality photos on mobile devices with deep convolutional networks.
    In IEEE International Conference on Computer Vision (ICCV), 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[283] Zongqing Lu, Noor Felemban, Kevin Chan, and Thomas La Porta. Demo abstract:
    On-demand information retrieval from videos using deep learning in wireless networks.
    In Proc. IEEE/ACM Second International Conference on Internet-of-Things Design
    and Implementation (IoTDI), pages 279–280, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[284] Jemin Lee, Jinse Kwon, and Hyungshin Kim. Reducing distraction of smartwatch
    users with deep learning. In Proc. 18th ACM International Conference on Human-Computer
    Interaction with Mobile Devices and Services Adjunct, pages 948–953, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[285] Toan H Vu, Le Dung, and Jia-Ching Wang. Transportation mode detection
    on mobile devices using recurrent nets. In Proc. ACM on Multimedia Conference,
    pages 392–396, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[286] Shih-Hau Fang, Yu-Xaing Fei, Zhezhuang Xu, and Yu Tsao. Learning transportation
    modes from smartphone sensors based on deep neural network. IEEE Sensors Journal,
    17(18):6111–6118, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[287] Mingmin Zhao, Yonglong Tian, Hang Zhao, Mohammad Abu Alsheikh, Tianhong
    Li, Rumen Hristov, Zachary Kabelac, Dina Katabi, and Antonio Torralba. RF-based
    3D skeletons. In Proc. ACM Conference of the ACM Special Interest Group on Data
    Communication (SIGCOMM), pages 267–281, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[288] Kleomenis Katevas, Ilias Leontiadis, Martin Pielot, and Joan Serrà. Practical
    processing of mobile sensor data for continual deep learning predictions. In Proc.
    1st ACM International Workshop on Deep Learning for Mobile Systems and Applications,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[289] Shuochao Yao, Shaohan Hu, Yiran Zhao, Aston Zhang, and Tarek Abdelzaher.
    Deepsense: A unified deep learning framework for time-series mobile sensing data
    processing. In Proc. 26th International Conference on World Wide Web, pages 351–360\.
    International World Wide Web Conferences Steering Committee, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[290] Kazuya Ohara, Takuya Maekawa, and Yasuyuki Matsushita. Detecting state
    changes of indoor everyday objects using Wi-Fi channel state information. Proc.
    ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), 1(3):88,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[291] Wu Liu, Huadong Ma, Heng Qi, Dong Zhao, and Zhineng Chen. Deep learning
    hashing for mobile visual search. EURASIP Journal on Image and Video Processing,
    (1):17, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[292] Xi Ouyang, Chaoyun Zhang, Pan Zhou, and Hao Jiang. DeepSpace: An online
    deep learning framework for mobile big data to understand human mobility patterns.
    arXiv preprint arXiv:1610.07009, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[293] Hua Yang, Zhimei Li, and Zhiyong Liu. Neural networks for MANET AODV:
    an optimization approach. Cluster Computing, pages 1–9, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[294] Xuan Song, Hiroshi Kanasugi, and Ryosuke Shibasaki. DeepTransport: Prediction
    and simulation of human mobility and transportation mode at a citywide level.
    In Proc. International Joint Conference on Artificial Intelligence, pages 2618–2624,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[295] Junbo Zhang, Yu Zheng, and Dekang Qi. Deep spatio-temporal residual networks
    for citywide crowd flows prediction. In Proc. National Conference on Artificial
    Intelligence (AAAI), 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[296] J Venkata Subramanian and M Abdul Karim Sadiq. Implementation of artificial
    neural network for mobile movement prediction. Indian Journal of science and Technology,
    7(6):858–863, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[297] Longinus S Ezema and Cosmas I Ani. Artificial neural network approach
    to mobile location estimation in GSM network. International Journal of Electronics
    and Telecommunications, 63(1):39–44, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[298] Wenhua Shao, Haiyong Luo, Fang Zhao, Cong Wang, Antonino Crivello, and
    Muhammad Zahid Tunio. DePedo: Anti periodic negative-step movement pedometer with
    deep convolutional neural networks. In Proc. IEEE International Conference on
    Communications (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[299] Yirga Yayeh, Hsin-piao Lin, Getaneh Berie, Abebe Belay Adege, Lei Yen,
    and Shiann-Shiun Jeng. Mobility prediction in mobile Ad-hoc network using deep
    learning. In Proc. IEEE International Conference on Applied System Invention (ICASI),
    pages 1203–1206, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[300] Quanjun Chen, Xuan Song, Harutoshi Yamada, and Ryosuke Shibasaki. Learning
    Deep Representation from Big and Heterogeneous Data for Traffic Accident Inference.
    In Proc. National Conference on Artificial Intelligence (AAAI), pages 338–344,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[301] Xuan Song, Ryosuke Shibasaki, Nicholos Jing Yuan, Xing Xie, Tao Li, and
    Ryutaro Adachi. DeepMob: learning deep knowledge of human emergency behavior and
    mobility from big and heterogeneous data. ACM Transactions on Information Systems
    (TOIS), 35(4):41, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[302] Di Yao, Chao Zhang, Zhihua Zhu, Jianhui Huang, and Jingping Bi. Trajectory
    clustering via deep representation learning. In Proc. IEEE International Joint
    Conference on Neural Networks (IJCNN), pages 3880–3887, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[303] Zhidan Liu, Zhenjiang Li, Kaishun Wu, and Mo Li. Urban Traffic Prediction
    from Mobility Data Using Deep Learning. IEEE Network, 32(4):40–46, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[304] Dilranjan S Wickramasuriya, Calvin A Perumalla, Kemal Davaslioglu, and
    Richard D Gitlin. Base station prediction and proactive mobility management in
    virtual cells using recurrent neural networks. In Proc. IEEE Wireless and Microwave
    Technology Conference (WAMICON), pages 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[305] Jan Tkačík and Pavel Kordík. Neural turing machine for sequential learning
    of human mobility patterns. In Proc. IEEE International Joint Conference on Neural
    Networks (IJCNN), pages 2790–2797, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[306] Dong Yup Kim and Ha Yoon Song. Method of predicting human mobility patterns
    using deep learning. Neurocomputing, 280:56–64, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[307] Renhe Jiang, Xuan Song, Zipei Fan, Tianqi Xia, Quanjun Chen, Satoshi
    Miyazawa, and Ryosuke Shibasaki. DeepUrbanMomentum: An Online Deep-Learning System
    for Short-Term Urban Mobility Prediction. In Proc. National Conference on Artificial
    Intelligence (AAAI), 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[308] Chujie Wang, Zhifeng Zhao, Qi Sun, and Honggang Zhang. Deep Learning-based
    Intelligent Dual Connectivity for Mobility Management in Dense Network. arXiv
    preprint arXiv:1806.04584, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[309] Renhe Jiang, Xuan Song, Zipei Fan, Tianqi Xia, Quanjun Chen, Qi Chen,
    and Ryosuke Shibasaki. Deep ROI-Based Modeling for Urban Human Mobility Prediction.
    Proc. ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT),
    2(1):14, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[310] Jie Feng, Yong Li, Chao Zhang, Funing Sun, Fanchao Meng, Ang Guo, and
    Depeng Jin. DeepMove: Predicting Human Mobility with Attentional Recurrent Networks.
    In Proc. World Wide Web Conference on World Wide Web, pages 1459–1468, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[311] Xuyu Wang, Lingjun Gao, Shiwen Mao, and Santosh Pandey. DeepFi: Deep
    learning for indoor fingerprinting using channel state information. In Proc. IEEE
    Wireless Communications and Networking Conference (WCNC), pages 1666–1671, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[312] Xuyu Wang, Xiangyu Wang, and Shiwen Mao. CiFi: Deep convolutional neural
    networks for indoor localization with 5 GHz Wi-Fi. In Proc. IEEE International
    Conference on Communications (ICC), pages 1–6, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[313] Xuyu Wang, Lingjun Gao, and Shiwen Mao. BiLoc: Bi-modal deep learning
    for indoor localization with commodity 5GHz WiFi. IEEE Access, 5:4209–4220, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[314] Michał Nowicki and Jan Wietrzykowski. Low-effort place recognition with
    WiFi fingerprints using deep learning. In Proc. International Conference Automation,
    pages 575–584. Springer, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[315] Xiao Zhang, Jie Wang, Qinghua Gao, Xiaorui Ma, and Hongyu Wang. Device-free
    wireless localization and activity recognition with deep learning. In Proc. IEEE
    International Conference on Pervasive Computing and Communication Workshops (PerCom
    Workshops), pages 1–5, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[316] Jie Wang, Xiao Zhang, Qinhua Gao, Hao Yue, and Hongyu Wang. Device-free
    wireless localization and activity recognition: A deep learning approach. IEEE
    Transactions on Vehicular Technology, 66(7):6258–6267, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[317] Mehdi Mohammadi, Ala Al-Fuqaha, Mohsen Guizani, and Jun-Seok Oh. Semi-supervised
    deep reinforcement learning in support of IoT and smart city services. IEEE Internet
    of Things Journal, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[318] Nafisa Anzum, Syeda Farzia Afroze, and Ashikur Rahman. Zone-based indoor
    localization using neural networks: A view from a real testbed. In Proc. IEEE
    International Conference on Communications (ICC), pages 1–7, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[319] Xuyu Wang, Zhitao Yu, and Shiwen Mao. DeepML: Deep LSTM for indoor localization
    with smartphone magnetic and light sensors. In Proc. IEEE International Conference
    on Communications (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[320] Anil Kumar Tirumala Ravi Kumar, Bernd Schäufele, Daniel Becker, Oliver
    Sawade, and Ilja Radusch. Indoor localization of vehicles using deep learning.
    In Proc. 17th IEEE International Symposium on World of Wireless, Mobile and Multimedia
    Networks (WoWMoM), pages 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[321] Zejia Zhengj and Juyang Weng. Mobile device based outdoor navigation
    with on-line learning neural network: A comparison with convolutional neural network.
    In Proc. IEEE Conference on Computer Vision and Pattern Recognition Workshops,
    pages 11–18, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[322] Joao Vieira, Erik Leitinger, Muris Sarajlic, Xuhong Li, and Fredrik Tufvesson.
    Deep convolutional neural networks for massive MIMO fingerprint-based positioning.
    In Proc. 28th IEEE Annual International Symposium on Personal, Indoor and Mobile
    Radio Communications, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[323] Xuyu Wang, Lingjun Gao, Shiwen Mao, and Santosh Pandey. CSI-based fingerprinting
    for indoor localization: A deep learning approach. IEEE Transactions on Vehicular
    Technology, 66(1):763–776, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[324] Hao Chen, Yifan Zhang, Wei Li, Xiaofeng Tao, and Ping Zhang. ConFi: Convolutional
    neural networks based indoor wi-fi localization using channel state information.
    IEEE Access, 5:18066–18074, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[325] Ahmed Shokry, Marwan Torki, and Moustafa Youssef. DeepLoc: A ubiquitous
    accurate and low-overhead outdoor cellular localization system. In Proc. 26th
    ACM SIGSPATIAL International Conference on Advances in Geographic Information
    Systems, pages 339–348, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[326] Rui Zhou, Meng Hao, Xiang Lu, Mingjie Tang, and Yang Fu. Device-Free
    Localization Based on CSI Fingerprints and Deep Neural Networks. In Proc. 15th
    Annual IEEE International Conference on Sensing, Communication, and Networking
    (SECON), pages 1–9, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[327] Wei Zhang, Rahul Sengupta, John Fodero, and Xiaolin Li. DeepPositioning:
    Intelligent Fusion of Pervasive Magnetic Field and WiFi Fingerprinting for Smartphone
    Indoor Localization via Deep Learning. In Proc. 16th IEEE International Conference
    on Machine Learning and Applications (ICMLA), pages 7–13, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[328] Abebe Adege, Hsin-Piao Lin, Getaneh Tarekegn, and Shiann-Shiun Jeng.
    Applying Deep Neural Network (DNN) for Robust Indoor Localization in Multi-Building
    Environment. Applied Sciences, 8(7):1062, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[329] Mai Ibrahim, Marwan Torki, and Mustafa ElNainay. CNN based Indoor Localization
    using RSS Time-Series. In Proc. IEEE Symposium on Computers and Communications
    (ISCC), pages 1044–1049, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[330] Arne Niitsoo, Thorsten Edelhäu$\beta$er, and Christopher Mutschler. Convolutional
    neural networks for position estimation in TDoA-based locating systems. In Proc.
    IEEE International Conference on Indoor Positioning and Indoor Navigation (IPIN),
    pages 1–8, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[331] Xuyu Wang, Xiangyu Wang, and Shiwen Mao. Deep convolutional neural networks
    for indoor localization with CSI images. IEEE Transactions on Network Science
    and Engineering, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[332] Chao Xiao, Daiqin Yang, Zhenzhong Chen, and Guang Tan. 3-D BLE indoor
    localization based on denoising autoencoder. IEEE Access, 5:12751–12760, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[333] Chen-Yu Hsu, Aayush Ahuja, Shichao Yue, Rumen Hristov, Zachary Kabelac,
    and Dina Katabi. Zero-Effort In-Home Sleep and Insomnia Monitoring Using Radio
    Signals. Proc. ACM Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT),
    1(3), sep 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[334] Weipeng Guan, Yuxiang Wu, Canyu Xie, Hao Chen, Ye Cai, and Yingcong Chen.
    High-precision approach to localization scheme of visible light communication
    based on artificial neural networks and modified genetic algorithms. Optical Engineering,
    56(10):106103, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[335] Po-Jen Chuang and Yi-Jun Jiang. Effective neural network-based node localisation
    scheme for wireless sensor networks. IET Wireless Sensor Systems, 4(2):97–103,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[336] Marcin Bernas and Bartłomiej Płaczek. Fully connected neural networks
    ensemble with signal strength clustering for indoor localization in wireless sensor
    networks. International Journal of Distributed Sensor Networks, 11(12):403242,
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[337] Ashish Payal, Chandra Shekhar Rai, and BV Ramana Reddy. Analysis of some
    feedforward artificial neural network training algorithms for developing localization
    framework in wireless sensor networks. Wireless Personal Communications, 82(4):2519–2536,
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[338] Yuhan Dong, Zheng Li, Rui Wang, and Kai Zhang. Range-based localization
    in underwater wireless sensor networks using deep neural network. In IPSN, pages
    321–322, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[339] Xiaofei Yan, Hong Cheng, Yandong Zhao, Wenhua Yu, Huan Huang, and Xiaoliang
    Zheng. Real-time identification of smoldering and flaming combustion phases in
    forest using a wireless sensor network-based multi-sensor system and artificial
    neural network. Sensors, 16(8):1228, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[340] Baowei Wang, Xiaodu Gu, Li Ma, and Shuangshuang Yan. Temperature error
    correction based on BP neural network in meteorological wireless sensor network.
    International Journal of Sensor Networks, 23(4):265–278, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[341] Ki-Seong Lee, Sun-Ro Lee, Youngmin Kim, and Chan-Gun Lee. Deep learning–based
    real-time query processing for wireless sensor network. International Journal
    of Distributed Sensor Networks, 13(5), 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[342] Jiakai Li and Gursel Serpen. Adaptive and intelligent wireless sensor
    networks through neural networks: an illustration for infrastructure adaptation
    through hopfield network. Applied Intelligence, 45(2):343–362, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[343] Fereshteh Khorasani and Hamid Reza Naji. Energy efficient data aggregation
    in wireless sensor networks using neural networks. International Journal of Sensor
    Networks, 24(1):26–42, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[344] Chunlin Li, Xiaofu Xie, Yuejiang Huang, Hong Wang, and Changxi Niu. Distributed
    data mining based on deep neural network for wireless sensor network. International
    Journal of Distributed Sensor Networks, 11(7):157453, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[345] Tie Luo and Sai G Nagarajany. Distributed anomaly detection using autoencoder
    neural networks in WSN for IoT. In Proc. IEEE International Conference on Communications
    (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[346] D Praveen Kumar, Tarachand Amgoth, and Chandra Sekhara Rao Annavarapu.
    Machine learning algorithms for wireless sensor networks: A survey. Information
    Fusion, 49:1–25, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[347] Nasim Heydari and Behrouz Minaei-Bidgoli. Reduce energy consumption and
    send secure data wireless multimedia sensor networks using a combination of techniques
    for multi-layer watermark and deep learning. International Journal of Computer
    Science and Network Security (IJCSNS), 17(2):98–105, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[348] Songyut Phoemphon, Chakchai So-In, and Dusit Tao Niyato. A hybrid model
    using fuzzy logic and an extreme learning machine with vector particle swarm optimization
    for wireless sensor network localization. Applied Soft Computing, 65:101–120,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[349] Seyed Saber Banihashemian, Fazlollah Adibnia, and Mehdi A Sarram. A new
    range-free and storage-efficient localization algorithm using neural networks
    in wireless sensor networks. Wireless Personal Communications, 98(1):1547–1568,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[350] Wei Sun, Wei Lu, Qiyue Li, Liangfeng Chen, Daoming Mu, and Xiaojing Yuan.
    WNN-LQE: Wavelet-Neural-Network-Based Link Quality Estimation for Smart Grid WSNs.
    IEEE Access, 5:12788–12797, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[351] Jiheon Kang, Youn-Jong Park, Jaeho Lee, Soo-Hyun Wang, and Doo-Seop Eom.
    Novel Leakage Detection by Ensemble CNN-SVM and Graph-based Localization in Water
    Distribution Systems. IEEE Transactions on Industrial Electronics, 65(5):4279–4289,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[352] Amjad Mehmood, Zhihan Lv, Jaime Lloret, and Muhammad Muneer Umar. ELDC:
    An artificial neural network based energy-efficient and robust routing scheme
    for pollution monitoring in WSNs. IEEE Transactions on Emerging Topics in Computing,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[353] Mohammad Abu Alsheikh, Shaowei Lin, Dusit Niyato, and Hwee-Pink Tan.
    Rate-distortion balanced data compression for wireless sensor networks. IEEE Sensors
    Journal, 16(12):5072–5083, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[354] Ahmad El Assaf, Slim Zaidi, Sofiène Affes, and Nahi Kandil. Robust ANNs-Based
    WSN Localization in the Presence of Anisotropic Signal Attenuation. IEEE Wireless
    Communications Letters, 5(5):504–507, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[355] Yuzhi Wang, Anqi Yang, Xiaoming Chen, Pengjun Wang, Yu Wang, and Huazhong
    Yang. A deep learning approach for blind drift calibration of sensor networks.
    IEEE Sensors Journal, 17(13):4158–4171, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[356] Zhenhua Jia, Xinmeng Lyu, Wuyang Zhang, Richard P Martin, Richard E Howard,
    and Yanyong Zhang. Continuous Low-Power Ammonia Monitoring Using Long Short-Term
    Memory Neural Networks. In Proc. 16th ACM Conference on Embedded Networked Sensor
    Systems, pages 224–236, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[357] Lu Liu, Yu Cheng, Lin Cai, Sheng Zhou, and Zhisheng Niu. Deep learning
    based optimization in wireless network. In Proc. IEEE International Conference
    on Communications (ICC), pages 1–6, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[358] Shivashankar Subramanian and Arindam Banerjee. Poster: Deep learning
    enabled M2M gateway for network optimization. In Proc. 14th ACM Annual International
    Conference on Mobile Systems, Applications, and Services Companion, pages 144–144,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[359] Ying He, Chengchao Liang, F Richard Yu, Nan Zhao, and Hongxi Yin. Optimization
    of cache-enabled opportunistic interference alignment wireless networks: A big
    data deep reinforcement learning approach. In Proc. 2017 IEEE International Conference
    on Communications (ICC), pages 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[360] Ying He, Zheng Zhang, F Richard Yu, Nan Zhao, Hongxi Yin, Victor CM Leung,
    and Yanhua Zhang. Deep reinforcement learning-based optimization for cache-enabled
    opportunistic interference alignment wireless networks. IEEE Transactions on Vehicular
    Technology, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[361] Faris B Mismar and Brian L Evans. Deep reinforcement learning for improving
    downlink mmwave communication performance. arXiv preprint arXiv:1707.02329, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[362] Zhi Wang, Lihua Li, Yue Xu, Hui Tian, and Shuguang Cui. Handover optimization
    via asynchronous multi-user deep reinforcement learning. In Proc. IEEE International
    Conference on Communications (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[363] Ziqi Chen and David B Smith. Heterogeneous machine-type communications
    in cellular networks: Random access optimization by deep reinforcement learning.
    In Proc. IEEE International Conference on Communications (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[364] Li Chen, Justinas Lingys, Kai Chen, and Feng Liu. AuTO: scaling deep
    reinforcement learning for datacenter-scale automatic traffic optimization. In
    Proc. ACM Conference of the ACM Special Interest Group on Data Communication (SIGCOMM),
    pages 191–205, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[365] YangMin Lee. Classification of node degree based on deep learning and
    routing method applied for virtual route assignment. Ad Hoc Networks, 58:70–85,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[366] Fengxiao Tang, Bomin Mao, Zubair Md Fadlullah, Nei Kato, Osamu Akashi,
    Takeru Inoue, and Kimihiro Mizutani. On removing routing protocol from future
    wireless networks: A real-time deep learning approach for intelligent traffic
    control. IEEE Wireless Communications, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[367] Qingchen Zhang, Man Lin, Laurence T Yang, Zhikui Chen, and Peng Li. Energy-efficient
    scheduling for real-time systems based on deep Q-learning model. IEEE Transactions
    on Sustainable Computing, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[368] Ribal Atallah, Chadi Assi, and Maurice Khabbaz. Deep reinforcement learning-based
    scheduling for roadside communication networks. In Proc. 15th IEEE International
    Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks
    (WiOpt), pages 1–8, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[369] Sandeep Chinchali, Pan Hu, Tianshu Chu, Manu Sharma, Manu Bansal, Rakesh
    Misra, Marco Pavone, and Katti Sachin. Cellular network traffic scheduling with
    deep reinforcement learning. In Proc. National Conference on Artificial Intelligence
    (AAAI), 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[370] Yifei Wei, Zhiqiang Zhang, F Richard Yu, and Zhu Han. Joint user scheduling
    and content caching strategy for mobile edge networks using deep reinforcement
    learning. In Proc. IEEE International Conference on Communications Workshops (ICC
    Workshops), 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[371] Haoran Sun, Xiangyi Chen, Qingjiang Shi, Mingyi Hong, Xiao Fu, and Nikos D
    Sidiropoulos. Learning to optimize: Training deep neural networks for wireless
    resource management. In Proc. 18th IEEE International Workshop on Signal Processing
    Advances in Wireless Communications (SPAWC), pages 1–6, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[372] Zhiyuan Xu, Yanzhi Wang, Jian Tang, Jing Wang, and Mustafa Cenk Gursoy.
    A deep reinforcement learning based framework for power-efficient resource allocation
    in cloud RANs. In Proc. 2017 IEEE International Conference on Communications (ICC),
    pages 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[373] Paulo Victor R Ferreira, Randy Paffenroth, Alexander M Wyglinski, Timothy M
    Hackett, Sven G Bilén, Richard C Reinhart, and Dale J Mortensen. Multi-objective
    reinforcement learning-based deep neural networks for cognitive space communications.
    In Proc. Cognitive Communications for Aerospace Applications Workshop (CCAA),
    pages 1–8\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[374] Hao Ye and Geoffrey Ye Li. Deep reinforcement learning for resource allocation
    in V2V communications. In Proc. IEEE International Conference on Communications
    (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[375] Ursula Challita, Li Dong, and Walid Saad. Proactive resource management
    for LTE in unlicensed spectrum: A deep learning perspective. IEEE Transactions
    on Wireless Communications, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[376] Oshri Naparstek and Kobi Cohen. Deep multi-user reinforcement learning
    for dynamic spectrum access in multichannel wireless networks. In Proc. IEEE Global
    Communications Conference, pages 1–7, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[377] Timothy J O’Shea and T Charles Clancy. Deep reinforcement learning radio
    control and signal detection with KeRLym, a gym RL agent. arXiv preprint arXiv:1605.09221,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[378] Michael Andri Wijaya, Kazuhiko Fukawa, and Hiroshi Suzuki. Intercell-interference
    cancellation and neural network transmit power optimization for MIMO channels.
    In Proc. IEEE 82nd Vehicular Technology Conference (VTC Fall), pages 1–5, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[379] Humphrey Rutagemwa, Amir Ghasemi, and Shuo Liu. Dynamic spectrum assignment
    for land mobile radio with deep recurrent neural networks. In Proc. IEEE International
    Conference on Communications Workshops (ICC Workshops), 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[380] Michael Andri Wijaya, Kazuhiko Fukawa, and Hiroshi Suzuki. Neural network
    based transmit power control and interference cancellation for MIMO small cell
    networks. IEICE Transactions on Communications, 99(5):1157–1169, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[381] Hongzi Mao, Ravi Netravali, and Mohammad Alizadeh. Neural adaptive video
    streaming with pensieve. In Proc. Conference of the ACM Special Interest Group
    on Data Communication (SIGCOMM), pages 197–210\. ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[382] Tetsuya Oda, Ryoichiro Obukata, Makoto Ikeda, Leonard Barolli, and Makoto
    Takizawa. Design and implementation of a simulation system based on deep Q-network
    for mobile actor node control in wireless sensor and actor networks. In Proc.
    31st IEEE International Conference on Advanced Information Networking and Applications
    Workshops (WAINA), pages 195–200, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[383] Tetsuya Oda, Donald Elmazi, Miralda Cuka, Elis Kulla, Makoto Ikeda, and
    Leonard Barolli. Performance evaluation of a deep Q-network based simulation system
    for actor node mobility control in wireless sensor and actor networks considering
    three-dimensional environment. In Proc. International Conference on Intelligent
    Networking and Collaborative Systems, pages 41–52\. Springer, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[384] Hye-Young Kim and Jong-Min Kim. A load balancing scheme based on deep-learning
    in IoT. Cluster Computing, 20(1):873–878, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[385] Ursula Challita, Walid Saad, and Christian Bettstetter. Deep reinforcement
    learning for interference-aware path planning of cellular connected UAVs. In Proc.
    IEEE International Conference on Communications (ICC), 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[386] Changqing Luo, Jinlong Ji, Qianlong Wang, Lixing Yu, and Pan Li. Online
    power control for 5G wireless communications: A deep Q-network approach. In Proc.
    IEEE International Conference on Communications (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[387] Yiding Yu, Taotao Wang, and Soung Chang Liew. Deep-reinforcement learning
    multiple access for heterogeneous wireless networks. In Proc. IEEE International
    Conference on Communications (ICC), pages 1–7, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[388] Zhiyuan Xu, Jian Tang, Jingsong Meng, Weiyi Zhang, Yanzhi Wang, Chi Harold
    Liu, and Dejun Yang. Experience-driven networking: A deep reinforcement learning
    based approach. In Proc. IEEE International Conference on Computer Communications,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[389] Jingchu Liu, Bhaskar Krishnamachari, Sheng Zhou, and Zhisheng Niu. DeepNap:
    Data-driven base station sleeping operations through deep reinforcement learning.
    IEEE Internet of Things Journal, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[390] Zhifeng Zhao, Rongpeng Li, Qi Sun, Yangchen Yang, Xianfu Chen, Minjian
    Zhao, Honggang Zhang, et al. Deep Reinforcement Learning for Network Slicing.
    arXiv preprint arXiv:1805.06591, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[391] Ji Li, Hui Gao, Tiejun Lv, and Yueming Lu. Deep reinforcement learning
    based computation offloading and resource allocation for MEC. In Proc. IEEE Wireless
    Communications and Networking Conference (WCNC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[392] Ruben Mennes, Miguel Camelo, Maxim Claeys, and Steven Latré. A neural-network-based
    MF-TDMA MAC scheduler for collaborative wireless networks. In Proc. IEEE Wireless
    Communications and Networking Conference (WCNC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[393] Yibo Zhou, Zubair Md. Fadlullah, Bomin Mao, and Nei Kato. A Deep-Learning-Based
    Radio Resource Assignment Technique for 5G Ultra Dense Networks. IEEE Network,
    32(6):28–34, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[394] Bomin Mao, Zubair Md Fadlullah, Fengxiao Tang, Nei Kato, Osamu Akashi,
    Takeru Inoue, and Kimihiro Mizutani. A Tensor Based Deep Learning Technique for
    Intelligent Packet Routing. In Proc. IEEE Global Communications Conference, pages 1–6\.
    IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[395] Fabien Geyer and Georg Carle. Learning and Generating Distributed Routing
    Protocols Using Graph-Based Deep Learning. In Proc. ACM Workshop on Big Data Analytics
    and Machine Learning for Data Communication Networks, pages 40–45, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[396] Nguyen Cong Luong, Tran The Anh, Huynh Thi Thanh Binh, Dusit Niyato,
    Dong In Kim, and Ying-Chang Liang. Joint Transaction Transmission and Channel
    Selection in Cognitive Radio Based Blockchain Networks: A Deep Reinforcement Learning
    Approach. arXiv preprint arXiv:1810.10139, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[397] Xingjian Li, Jun Fang, Wen Cheng, Huiping Duan, Zhi Chen, and Hongbin
    Li. Intelligent Power Control for Spectrum Sharing in Cognitive Radios: A Deep
    Reinforcement Learning Approach. IEEE access, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[398] Woongsup Lee, Minhoe Kim, and Dong-Ho Cho. Deep Learning Based Transmit
    Power Control in Underlaid Device-to-Device Communication. IEEE Systems Journal,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[399] Chi Harold Liu, Zheyu Chen, Jian Tang, Jie Xu, and Chengzhe Piao. Energy-efficient
    UAV control for effective and fair communication coverage: A deep reinforcement
    learning approach. IEEE Journal on Selected Areas in Communications, 36(9):2059–2070,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[400] Ying He, F Richard Yu, Nan Zhao, Victor CM Leung, and Hongxi Yin. Software-defined
    networks with mobile edge computing and caching for smart cities: A big data deep
    reinforcement learning approach. IEEE Communications Magazine, 55(12):31–37, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[401] Xin Liu, Yuhua Xu, Luliang Jia, Qihui Wu, and Alagan Anpalagan. Anti-jamming
    Communications Using Spectrum Waterfall: A Deep Reinforcement Learning Approach.
    IEEE Communications Letters, 22(5):998–1001, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[402] Quang Tran Anh Pham, Yassine Hadjadj-Aoul, and Abdelkader Outtagarts.
    Deep Reinforcement Learning based QoS-aware Routing in Knowledge-defined networking.
    In Proc. Qshine EAI International Conference on Heterogeneous Networking for Quality,
    Reliability, Security and Robustness, pages 1–13, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[403] Paulo Ferreira, Randy Paffenroth, Alexander Wyglinski, Timothy M Hackett,
    Sven Bilén, Richard Reinhart, and Dale Mortensen. Multi-objective reinforcement
    learning for cognitive radio–based satellite communications. In Proc. 34th AIAA
    International Communications Satellite Systems Conference, page 5726, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[404] Mahmood Yousefi-Azar, Vijay Varadharajan, Len Hamey, and Uday Tupakula.
    Autoencoder-based feature learning for cyber security applications. In Proc. IEEE
    International Joint Conference on Neural Networks (IJCNN), pages 3854–3861, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[405] Muhamad Erza Aminanto and Kwangjo Kim. Detecting impersonation attack
    in WiFi networks using deep learning approach. In Proc. International Workshop
    on Information Security Applications, pages 136–147\. Springer, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[406] Qingsong Feng, Zheng Dou, Chunmei Li, and Guangzhen Si. Anomaly detection
    of spectrum in wireless communication via deep autoencoder. In Proc. International
    Conference on Computer Science and its Applications, pages 259–265\. Springer,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[407] Muhammad Altaf Khan, Shafiullah Khan, Bilal Shams, and Jaime Lloret.
    Distributed flood attack detection mechanism using artificial neural network in
    wireless mesh networks. Security and Communication Networks, 9(15):2715–2729,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[408] Abebe Abeshu Diro and Naveen Chilamkurti. Distributed attack detection
    scheme using deep learning approach for Internet of Things. Future Generation
    Computer Systems, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[409] Alan Saied, Richard E Overill, and Tomasz Radzik. Detection of known
    and unknown DDoS attacks using artificial neural networks. Neurocomputing, 172:385–393,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[410] Manuel Lopez-Martin, Belen Carro, Antonio Sanchez-Esguevillas, and Jaime
    Lloret. Conditional variational autoencoder for prediction and feature recovery
    applied to intrusion detection in IoT. Sensors, 17(9):1967, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[411] Kian Hamedani, Lingjia Liu, Rachad Atat, Jinsong Wu, and Yang Yi. Reservoir
    computing meets smart grids: attack detection using delayed feedback networks.
    IEEE Transactions on Industrial Informatics, 14(2):734–743, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[412] Rajshekhar Das, Akshay Gadre, Shanghang Zhang, Swarun Kumar, and Jose MF
    Moura. A deep learning approach to IoT authentication. In Proc. IEEE International
    Conference on Communications (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[413] Peng Jiang, Hongyi Wu, Cong Wang, and Chunsheng Xin. Virtual MAC spoofing
    detection through deep learning. In Proc. IEEE International Conference on Communications
    (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[414] Zhenlong Yuan, Yongqiang Lu, Zhaoguo Wang, and Yibo Xue. Droid-Sec: deep
    learning in Android malware detection. In ACM SIGCOMM Computer Communication Review,
    volume 44, pages 371–372, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[415] Zhenlong Yuan, Yongqiang Lu, and Yibo Xue. Droiddetector: Android malware
    characterization and detection using deep learning. Tsinghua Science and Technology,
    21(1):114–123, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[416] Xin Su, Dafang Zhang, Wenjia Li, and Kai Zhao. A deep learning approach
    to Android malware feature learning and detection. In IEEE Trustcom/BigDataSE/ISPA,
    pages 244–251, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[417] Shifu Hou, Aaron Saas, Lifei Chen, and Yanfang Ye. Deep4MalDroid: A deep
    learning framework for Android malware detection based on linux kernel system
    call graphs. In Proc. IEEE/WIC/ACM International Conference on Web Intelligence
    Workshops (WIW), pages 104–111, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[418] Fabio Martinelli, Fiammetta Marulli, and Francesco Mercaldo. Evaluating
    convolutional neural network for effective mobile malware detection. Procedia
    Computer Science, 112:2372–2381, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[419] Khoi Khac Nguyen, Dinh Thai Hoang, Dusit Niyato, Ping Wang, Diep Nguyen,
    and Eryk Dutkiewicz. Cyberattack detection in mobile cloud computing: A deep learning
    approach. In Proc. IEEE Wireless Communications and Networking Conference (WCNC),
    pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[420] Niall McLaughlin, Jesus Martinez del Rincon, BooJoong Kang, Suleiman
    Yerima, Paul Miller, Sakir Sezer, Yeganeh Safaei, Erik Trickel, Ziming Zhao, Adam
    Doupé, et al. Deep android malware detection. In Proc. Seventh ACM on Conference
    on Data and Application Security and Privacy, pages 301–308, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[421] Yuanfang Chen, Yan Zhang, and Sabita Maharjan. Deep learning for secure
    mobile edge computing. arXiv preprint arXiv:1709.08025, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[422] Milan Oulehla, Zuzana Komínková Oplatková, and David Malanik. Detection
    of mobile botnets using neural networks. In Proc. IEEE Future Technologies Conference
    (FTC), pages 1324–1326, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[423] Pablo Torres, Carlos Catania, Sebastian Garcia, and Carlos Garcia Garino.
    An analysis of recurrent neural networks for botnet detection behavior. In Proc.
    IEEE Biennial Congress of Argentina (ARGENCON), pages 1–6, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[424] Meisam Eslahi, Moslem Yousefi, Maryam Var Naseri, YM Yussof, NM Tahir,
    and H Hashim. Mobile botnet detection model based on retrospective pattern recognition.
    International Journal of Security and Its Applications, 10(9):39–+, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[425] Mohammad Alauthaman, Nauman Aslam, Li Zhang, Rafe Alasem, and MA Hossain.
    A p2p botnet detection scheme based on decision tree and adaptive multilayer neural
    networks. Neural Computing and Applications, pages 1–14, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[426] Reza Shokri and Vitaly Shmatikov. Privacy-preserving deep learning. In
    Proc. 22nd ACM SIGSAC conference on computer and communications security, pages
    1310–1321, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[427] Yoshinori Aono, Takuya Hayashi, Lihua Wang, Shiho Moriai, et al. Privacy-preserving
    deep learning: Revisited and enhanced. In Proc. International Conference on Applications
    and Techniques in Information Security, pages 100–110\. Springer, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[428] Seyed Ali Ossia, Ali Shahin Shamsabadi, Ali Taheri, Hamid R Rabiee, Nic
    Lane, and Hamed Haddadi. A hybrid deep learning architecture for privacy-preserving
    mobile analytics. arXiv preprint arXiv:1703.02952, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[429] Martín Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov,
    Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proc.
    ACM SIGSAC Conference on Computer and Communications Security, pages 308–318\.
    ACM, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[430] Seyed Ali Osia, Ali Shahin Shamsabadi, Ali Taheri, Kleomenis Katevas,
    Hamed Haddadi, and Hamid R Rabiee. Private and scalable personal data analytics
    using a hybrid edge-cloud deep learning. IEEE Computer Magazine Special Issue
    on Mobile and Embedded Deep Learning, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[431] Sandra Servia-Rodriguez, Liang Wang, Jianxin R Zhao, Richard Mortier,
    and Hamed Haddadi. Personal model training under privacy constraints. In Proc.
    3rd ACM/IEEE International Conference on Internet-of-Things Design and Implementation,
    Apr 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[432] Briland Hitaj, Giuseppe Ateniese, and Fernando Perez-Cruz. Deep models
    under the GAN: information leakage from collaborative deep learning. In Proc.
    ACM SIGSAC Conference on Computer and Communications Security, pages 603–618,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[433] Sam Greydanus. Learning the enigma with recurrent neural networks. arXiv
    preprint arXiv:1708.07576, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[434] Houssem Maghrebi, Thibault Portigliatti, and Emmanuel Prouff. Breaking
    cryptographic implementations using deep learning techniques. In Proc. International
    Conference on Security, Privacy, and Applied Cryptography Engineering, pages 3–26\.
    Springer, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[435] Yunyu Liu, Zhiyang Xia, Ping Yi, Yao Yao, Tiantian Xie, Wei Wang, and
    Ting Zhu. GENPass: A general deep learning model for password guessing with PCFG
    rules and adversarial generation. In Proc. IEEE International Conference on Communications
    (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[436] Rui Ning, Cong Wang, ChunSheng Xin, Jiang Li, and Hongyi Wu. Deepmag:
    sniffing mobile apps in magnetic field through deep convolutional neural networks.
    In Proc. IEEE International Conference on Pervasive Computing and Communications
    (PerCom), pages 1–10, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[437] Timothy J O’Shea, Tugba Erpek, and T Charles Clancy. Deep learning based
    MIMO communications. arXiv preprint arXiv:1707.07980, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[438] Mark Borgerding, Philip Schniter, and Sundeep Rangan. AMP-inspired deep
    networks for sparse linear inverse problems. IEEE Transactions on Signal Processing,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[439] Takuya Fujihashi, Toshiaki Koike-Akino, Takashi Watanabe, and Philip V
    Orlik. Nonlinear equalization with deep learning for multi-purpose visual MIMO
    communications. In Proc. IEEE International Conference on Communications (ICC),
    pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[440] Sreeraj Rajendran, Wannes Meert, Domenico Giustiniano, Vincent Lenders,
    and Sofie Pollin. Deep learning models for wireless signal classification with
    distributed low-cost spectrum sensors. IEEE Transactions on Cognitive Communications
    and Networking, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[441] Nathan E West and Tim O’Shea. Deep architectures for modulation recognition.
    In Proc. IEEE International Symposium on Dynamic Spectrum Access Networks (DySPAN),
    pages 1–6, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[442] Timothy J O’Shea, Latha Pemula, Dhruv Batra, and T Charles Clancy. Radio
    transformer networks: Attention models for learning to synchronize in wireless
    systems. In Proc. 50th Asilomar Conference on Signals, Systems and Computers,
    pages 662–666, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[443] João Gante, Gabriel Falcão, and Leonel Sousa. Beamformed Fingerprint
    Learning for Accurate Millimeter Wave Positioning. arXiv preprint arXiv:1804.04112,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[444] Ahmed Alkhateeb, Sam Alex, Paul Varkey, Ying Li, Qi Qu, and Djordje Tujkovic.
    Deep Learning Coordinated Beamforming for Highly-Mobile Millimeter Wave Systems.
    IEEE Access, 6:37328–37348, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[445] David Neumann, Wolfgang Utschick, and Thomas Wiese. Deep channel estimation.
    In Proc. 21th International ITG Workshop on Smart Antennas, pages 1–6\. VDE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[446] Neev Samuel, Tzvi Diskin, and Ami Wiesel. Deep MIMO detection. arXiv
    preprint arXiv:1706.01151, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[447] Xin Yan, Fei Long, Jingshuai Wang, Na Fu, Weihua Ou, and Bin Liu. Signal
    detection of MIMO-OFDM system based on auto encoder and extreme learning machine.
    In Proc. IEEE International Joint Conference on Neural Networks (IJCNN), pages
    1602–1606, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[448] Timothy O’Shea and Jakob Hoydis. An introduction to deep learning for
    the physical layer. IEEE Transactions on Cognitive Communications and Networking,
    3(4):563–575, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[449] Jithin Jagannath, Nicholas Polosky, Daniel O’Connor, Lakshmi N Theagarajan,
    Brendan Sheaffer, Svetlana Foulke, and Pramod K Varshney. Artificial neural network
    based automatic modulation classification over a software defined radio testbed.
    In Proc. IEEE International Conference on Communications (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[450] Timothy J O’Shea, Seth Hitefield, and Johnathan Corgan. End-to-end radio
    traffic sequence recognition with recurrent neural networks. In Proc. IEEE Global
    Conference on Signal and Information Processing (GlobalSIP), pages 277–281, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[451] Timothy J O’Shea, Kiran Karra, and T Charles Clancy. Learning to communicate:
    Channel auto-encoders, domain specific regularizers, and attention. In Proc. IEEE
    International Symposium on Signal Processing and Information Technology (ISSPIT),
    pages 223–228, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[452] Hao Ye, Geoffrey Ye Li, and Biing-Hwang Juang. Power of deep learning
    for channel estimation and signal detection in OFDM systems. IEEE Wireless Communications
    Letters, 7(1):114–117, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[453] Fei Liang, Cong Shen, and Feng Wu. Exploiting noise correlation for channel
    decoding with convolutional neural networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[454] Wei Lyu, Zhaoyang Zhang, Chunxu Jiao, Kangjian Qin, and Huazi Zhang.
    Performance evaluation of channel decoding with deep neural networks. In Proc.
    IEEE International Conference on Communications (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[455] Sebastian Dörner, Sebastian Cammerer, Jakob Hoydis, and Stephan ten Brink.
    Deep learning based communication over the air. IEEE Journal of Selected Topics
    in Signal Processing, 12(1):132–143, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[456] Run-Fa Liao, Hong Wen, Jinsong Wu, Huanhuan Song, Fei Pan, and Lian Dong.
    The Rayleigh Fading Channel Prediction via Deep Learning. Wireless Communications
    and Mobile Computing, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[457] Huang Hongji, Yang Jie, Song Yiwei, Huang Hao, and Gui Guan. Deep Learning
    for Super-Resolution Channel Estimation and DOA Estimation based Massive MIMO
    System. IEEE Transactions on Vehicular Technology, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[458] Sihao Huang and Haowen Lin. Fully optical spacecraft communications:
    implementing an omnidirectional PV-cell receiver and 8 Mb/s LED visible light
    downlink with deep learning error correction. IEEE Aerospace and Electronic Systems
    Magazine, 33(4):16–22, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[459] Roberto Gonzalez, Alberto Garcia-Duran, Filipe Manco, Mathias Niepert,
    and Pelayo Vallina. Network data monetization using Net2Vec. In Proc. ACM SIGCOMM
    Posters and Demos, pages 37–39, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[460] Nichoas Kaminski, Irene Macaluso, Emanuele Di Pascale, Avishek Nag, John
    Brady, Mark Kelly, Keith Nolan, Wael Guibene, and Linda Doyle. A neural-network-based
    realization of in-network computation for the Internet of Things. In Proc. IEEE
    International Conference on Communications (ICC), pages 1–6, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[461] Liang Xiao, Yanda Li, Guoan Han, Huaiyu Dai, and H Vincent Poor. A secure
    mobile crowdsensing game with deep reinforcement learning. IEEE Transactions on
    Information Forensics and Security, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[462] Nguyen Cong Luong, Zehui Xiong, Ping Wang, and Dusit Niyato. Optimal
    auction for edge computing resource management in mobile blockchain networks:
    A deep learning approach. In Proc. IEEE International Conference on Communications
    (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[463] Amuleen Gulati, Gagangeet Singh Aujla, Rajat Chaudhary, Neeraj Kumar,
    and Mohammad S Obaidat. Deep learning-based content centric data dissemination
    scheme for Internet of Vehicles. In Proc. IEEE International Conference on Communications
    (ICC), pages 1–6, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[464] Ejaz Ahmed, Ibrar Yaqoob, Ibrahim Abaker Targio Hashem, Junaid Shuja,
    Muhammad Imran, Nadra Guizani, and Sheikh Tahir Bakhsh. Recent Advances and Challenges
    in Mobile Big Data. IEEE Communications Magazine, 56(2):102–108, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[465] Demetrios Zeinalipour Yazti and Shonali Krishnaswamy. Mobile big data
    analytics: research, practice, and opportunities. In Proc. 15th IEEE International
    Conference on Mobile Data Management (MDM), volume 1, pages 1–2, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[466] Diala Naboulsi, Marco Fiore, Stephane Ribot, and Razvan Stanica. Large-scale
    mobile traffic analysis: a survey. IEEE Communications Surveys & Tutorials, 18(1):124–161,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[467] Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, and
    Andrew Y Ng. Multimodal deep learning. In Proc. 28th international conference
    on machine learning (ICML), pages 689–696, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[468] Imad Alawe, Adlen Ksentini, Yassine Hadjadj-Aoul, and Philippe Bertin.
    Improving traffic forecasting for 5G core network scalability: A Machine Learning
    approach. IEEE Network, 32(6):42–49, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[469] Giuseppe Aceto, Domenico Ciuonzo, Antonio Montieri, and Antonio Pescapé.
    Mobile encrypted traffic classification using deep learning. In Proc. 2nd IEEE
    Network Traffic Measurement and Analysis Conference, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[470] Ala Al-Fuqaha, Mohsen Guizani, Mehdi Mohammadi, Mohammed Aledhari, and
    Moussa Ayyash. Internet of things: A survey on enabling technologies, protocols,
    and applications. IEEE Communications Surveys & Tutorials, 17(4):2347–2376, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[471] Suranga Seneviratne, Yining Hu, Tham Nguyen, Guohao Lan, Sara Khalifa,
    Kanchana Thilakarathna, Mahbub Hassan, and Aruna Seneviratne. A survey of wearable
    devices and challenges. IEEE Communications Surveys & Tutorials, 19(4):2573–2620,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[472] He Li, Kaoru Ota, and Mianxiong Dong. Learning IoT in edge: Deep learning
    for the Internet of Things with edge computing. IEEE Network, 32(1):96–101, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[473] Nicholas D Lane, Sourav Bhattacharya, Petko Georgiev, Claudio Forlivesi,
    and Fahim Kawsar. An early resource characterization of deep learning on wearables,
    smartphones and internet-of-things devices. In Proc. ACM International Workshop
    on Internet of Things towards Applications, pages 7–12, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[474] Daniele Ravì, Charence Wong, Fani Deligianni, Melissa Berthelot, Javier
    Andreu-Perez, Benny Lo, and Guang-Zhong Yang. Deep learning for health informatics.
    IEEE journal of biomedical and health informatics, 21(1):4–21, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[475] Riccardo Miotto, Fei Wang, Shuang Wang, Xiaoqian Jiang, and Joel T Dudley.
    Deep learning for healthcare: review, opportunities and challenges. Briefings
    in Bioinformatics, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[476] Charissa Ann Ronao and Sung-Bae Cho. Human activity recognition with
    smartphone sensors using deep learning neural networks. Expert Systems with Applications,
    59:235–244, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[477] Jindong Wang, Yiqiang Chen, Shuji Hao, Xiaohui Peng, and Lisha Hu. Deep
    learning for sensor-based activity recognition: A survey. Pattern Recognition
    Letters, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[478] Xukan Ran, Haoliang Chen, Zhenming Liu, and Jiasi Chen. Delivering deep
    learning to mobile devices via offloading. In Proc. ACM Workshop on Virtual Reality
    and Augmented Reality Network, pages 42–47, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[479] Vishakha V Vyas, KH Walse, and RV Dharaskar. A survey on human activity
    recognition using smartphone. International Journal, 5(3), 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[480] Heiga Zen and Andrew Senior. Deep mixture density networks for acoustic
    modeling in statistical parametric speech synthesis. In Proc. IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 3844–3848,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[481] Kai Zhao, Sasu Tarkoma, Siyuan Liu, and Huy Vo. Urban human mobility
    data mining: An overview. In Proc. IEEE International Conference on Big Data (Big
    Data), pages 1911–1920, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[482] Cheng Yang, Maosong Sun, Wayne Xin Zhao, Zhiyuan Liu, and Edward Y Chang.
    A neural network approach to jointly modeling social networks and mobile trajectories.
    ACM Transactions on Information Systems (TOIS), 35(4):36, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[483] Alex Graves, Greg Wayne, and Ivo Danihelka. Neural turing machines. arXiv
    preprint arXiv:1410.5401, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[484] Shixiong Xia, Yi Liu, Guan Yuan, Mingjun Zhu, and Zhaohui Wang. Indoor
    fingerprint positioning based on Wi-Fi: An overview. ISPRS International Journal
    of Geo-Information, 6(5):135, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[485] Pavel Davidson and Robert Piché. A survey of selected indoor positioning
    methods for smartphones. IEEE Communications Surveys & Tutorials, 19(2):1347–1370,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[486] Jiang Xiao, Zimu Zhou, Youwen Yi, and Lionel M Ni. A survey on wireless
    indoor localization from the device perspective. ACM Computing Surveys (CSUR),
    49(2):25, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[487] Jiang Xiao, Kaishun Wu, Youwen Yi, and Lionel M Ni. FIFS: Fine-grained
    indoor fingerprinting system. In Proc. 21st International Conference on Computer
    Communications and Networks (ICCCN), pages 1–7, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[488] Moustafa Youssef and Ashok Agrawala. The Horus WLAN location determination
    system. In Proc. 3rd ACM international conference on Mobile systems, applications,
    and services, pages 205–218, 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[489] Mauro Brunato and Roberto Battiti. Statistical learning theory for location
    fingerprinting in wireless LANs. Computer Networks, 47(6):825–845, 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[490] Jonathan Ho and Stefano Ermon. Generative adversarial imitation learning.
    In Advances in Neural Information Processing Systems, pages 4565–4573, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[491] Michele Zorzi, Andrea Zanella, Alberto Testolin, Michele De Filippo De Grazia,
    and Marco Zorzi. COBANETS: A new paradigm for cognitive communications systems.
    In Proc. IEEE International Conference on Computing, Networking and Communications
    (ICNC), pages 1–7, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[492] Mehdi Roopaei, Paul Rad, and Mo Jamshidi. Deep learning control for complex
    and large scale cloud systems. Intelligent Automation & Soft Computing, pages
    1–3, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[493] Paulo Victor R Ferreira, Randy Paffenroth, Alexander M Wyglinski, Timothy M
    Hackett, Sven G Bilén, Richard C Reinhart, and Dale J Mortensen. Multi-objective
    Reinforcement Learning for Cognitive Satellite Communications using Deep Neural
    Network Ensembles. IEEE Journal on Selected Areas in Communications, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[494] Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver. Prioritized
    experience replay. In Proc. International Conference on Learning Representations
    (ICLR), 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[495] Qingjiang Shi, Meisam Razaviyayn, Zhi-Quan Luo, and Chen He. An iteratively
    weighted MMSE approach to distributed sum-utility maximization for a MIMO interfering
    broadcast channel. IEEE Transactions on Signal Processing, 59(9):4331–4340, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[496] Anna L Buczak and Erhan Guven. A survey of data mining and machine learning
    methods for cyber security intrusion detection. IEEE Communications Surveys &
    Tutorials, 18(2):1153–1176, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[497] Ji Wang, Jianguo Zhang, Weidong Bao, Xiaomin Zhu, Bokai Cao, and Philip S
    Yu. Not just privacy: Improving performance of private deep learning in mobile
    cloud. In Proc. 24th ACM SIGKDD International Conference on Knowledge Discovery
    & Data Mining, pages 2407–2416, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[498] Donghwoon Kwon, Hyunjoo Kim, Jinoh Kim, Sang C Suh, Ikkyun Kim, and Kuinam J
    Kim. A survey of deep learning-based network anomaly detection. Cluster Computing,
    pages 1–13, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[499] Mahbod Tavallaee, Ebrahim Bagheri, Wei Lu, and Ali A Ghorbani. A detailed
    analysis of the kdd cup 99 data set. In Proc. IEEE Symposium on Computational
    Intelligence for Security and Defense Applications, pages 1–6, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[500] Kimberly Tam, Ali Feizollah, Nor Badrul Anuar, Rosli Salleh, and Lorenzo
    Cavallaro. The evolution of android malware and Android analysis techniques. ACM
    Computing Surveys (CSUR), 49(4):76, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[501] Rafael A Rodríguez-Gómez, Gabriel Maciá-Fernández, and Pedro García-Teodoro.
    Survey and taxonomy of botnet research through life-cycle. ACM Computing Surveys
    (CSUR), 45(4):45, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[502] Menghan Liu, Haotian Jiang, Jia Chen, Alaa Badokhon, Xuetao Wei, and
    Ming-Chun Huang. A collaborative privacy-preserving deep learning system in distributed
    mobile environment. In Proc. IEEE International Conference on Computational Science
    and Computational Intelligence (CSCI), pages 192–197, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[503] Sumit Chopra, Raia Hadsell, and Yann LeCun. Learning a similarity metric
    discriminatively, with application to face verification. In Proc. IEEE Conference
    on Computer Vision and Pattern Recognition (CVPR), volume 1, pages 539–546, 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[504] Ali Shahin Shamsabadi, Hamed Haddadi, and Andrea Cavallaro. Distributed
    one-class learning. In Proc. IEEE International Conference on Image Processing
    (ICIP), 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[505] Briland Hitaj, Paolo Gasti, Giuseppe Ateniese, and Fernando Perez-Cruz.
    PassGAN: A deep learning approach for password guessing. arXiv preprint arXiv:1709.00440,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[506] Hao Ye, Geoffrey Ye Li, Biing-Hwang Fred Juang, and Kathiravetpillai
    Sivanesan. Channel agnostic end-to-end learning based communication systems with
    conditional GAN. arXiv preprint arXiv:1807.00447, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[507] Roberto Gonzalez, Filipe Manco, Alberto Garcia-Duran, Jose Mendes, Felipe
    Huici, Saverio Niccolini, and Mathias Niepert. Net2Vec: Deep learning for the
    network. In Proc. ACM Workshop on Big Data Analytics and Machine Learning for
    Data Communication Networks, pages 13–18, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[508] David H Wolpert and William G Macready. No free lunch theorems for optimization.
    IEEE transactions on evolutionary computation, 1(1):67–82, 1997.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[509] Yu Cheng, Duo Wang, Pan Zhou, and Tao Zhang. Model compression and acceleration
    for deep neural networks: The principles, progress, and challenges. IEEE Signal
    Processing Magazine, 35(1):126–136, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[510] Nicholas D Lane, Sourav Bhattacharya, Akhil Mathur, Petko Georgiev, Claudio
    Forlivesi, and Fahim Kawsar. Squeezing deep learning into mobile and embedded
    devices. IEEE Pervasive Computing, 16(3):82–88, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[511] Jie Tang, Dawei Sun, Shaoshan Liu, and Jean-Luc Gaudiot. Enabling deep
    learning on IoT devices. Computer, 50(10):92–96, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[512] Ji Wang, Bokai Cao, Philip Yu, Lichao Sun, Weidong Bao, and Xiaomin Zhu.
    Deep learning towards mobile applications. In Proc. 38th IEEE International Conference
    on Distributed Computing Systems (ICDCS), pages 1385–1393, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[513] Forrest N Iandola, Song Han, Matthew W Moskewicz, Khalid Ashraf, William J
    Dally, and Kurt Keutzer. SqueezeNet: AlexNet-level accuracy with 50x fewer parameters
    and< 0.5 MB model size. In Proc. International Conference on Learning Representations
    (ICLR), 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[514] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang,
    Tobias Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Efficient convolutional
    neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[515] Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. ShuffleNet: An
    extremely efficient convolutional neural network for mobile devices. In The IEEE
    Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[516] Qingchen Zhang, Laurence T Yang, Xingang Liu, Zhikui Chen, and Peng Li.
    A tucker deep computation model for mobile multimedia feature learning. ACM Transactions
    on Multimedia Computing, Communications, and Applications (TOMM), 13(3s):39, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[517] Qingqing Cao, Niranjan Balasubramanian, and Aruna Balasubramanian. MobiRNN:
    Efficient recurrent neural network execution on mobile GPU. In Proc. 1st ACM International
    Workshop on Deep Learning for Mobile Systems and Applications, pages 1–6, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[518] Chun-Fu Chen, Gwo Giun Lee, Vincent Sritapan, and Ching-Yung Lin. Deep
    convolutional neural network on iOS mobile devices. In Proc. IEEE International
    Workshop on Signal Processing Systems (SiPS), pages 130–135, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[519] S Rallapalli, H Qiu, A Bency, S Karthikeyan, R Govindan, B Manjunath,
    and R Urgaonkar. Are very deep neural networks feasible on mobile devices. IEEE
    Transactions on Circuits and Systems for Video Technology, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[520] Nicholas D Lane, Sourav Bhattacharya, Petko Georgiev, Claudio Forlivesi,
    Lei Jiao, Lorena Qendro, and Fahim Kawsar. DeepX: A software accelerator for low-power
    deep learning inference on mobile devices. In Proc. 15th ACM/IEEE International
    Conference on Information Processing in Sensor Networks (IPSN), pages 1–12, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[521] Loc N Huynh, Rajesh Krishna Balan, and Youngki Lee. DeepMon: Building
    mobile GPU deep learning models for continuous vision applications. In Proc. 15th
    ACM Annual International Conference on Mobile Systems, Applications, and Services,
    pages 186–186, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[522] Jiaxiang Wu, Cong Leng, Yuhang Wang, Qinghao Hu, and Jian Cheng. Quantized
    convolutional neural networks for mobile devices. In Proc. IEEE Conference on
    Computer Vision and Pattern Recognition, pages 4820–4828, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[523] Sourav Bhattacharya and Nicholas D Lane. Sparsification and separation
    of deep learning layers for constrained resource inference on wearables. In Proc.
    14th ACM Conference on Embedded Network Sensor Systems CD-ROM, pages 176–189,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[524] Minsik Cho and Daniel Brand. MEC: Memory-efficient convolution for deep
    neural network. In Proc. International Conference on Machine Learning (ICML),
    pages 815–824, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[525] Jia Guo and Miodrag Potkonjak. Pruning filters and classes: Towards on-device
    customization of convolutional neural networks. In Proc. 1st ACM International
    Workshop on Deep Learning for Mobile Systems and Applications, pages 13–17, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[526] Shiming Li, Duo Liu, Chaoneng Xiang, Jianfeng Liu, Yingjian Ling, Tianjun
    Liao, and Liang Liang. Fitcnn: A cloud-assisted lightweight convolutional neural
    network framework for mobile devices. In Proc. 23rd IEEE International Conference
    on Embedded and Real-Time Computing Systems and Applications (RTCSA), pages 1–6,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[527] Heiga Zen, Yannis Agiomyrgiannakis, Niels Egberts, Fergus Henderson,
    and Przemysław Szczepaniak. Fast, compact, and high quality LSTM-RNN based statistical
    parametric speech synthesizers for mobile devices. arXiv preprint arXiv:1606.06061,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[528] Gabriel Falcao, Luís A Alexandre, J Marques, Xavier Frazão, and Joao
    Maria. On the evaluation of energy-efficient deep learning using stacked autoencoders
    on mobile gpus. In Proc. 25th IEEE Euromicro International Conference on Parallel,
    Distributed and Network-based Processing, pages 270–273, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[529] Biyi Fang, Xiao Zeng, and Mi Zhang. NestDNN: Resource-Aware Multi-Tenant
    On-Device Deep Learning for Continuous Mobile Vision. In Proc. 24th ACM Annual
    International Conference on Mobile Computing and Networking, pages 115–127, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[530] Mengwei Xu, Mengze Zhu, Yunxin Liu, Felix Xiaozhu Lin, and Xuanzhe Liu.
    DeepCache: Principled Cache for Mobile Deep Vision. In Proc. 24th ACM Annual International
    Conference on Mobile Computing and Networking, pages 129–144, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[531] Sicong Liu, Yingyan Lin, Zimu Zhou, Kaiming Nan, Hui Liu, and Junzhao
    Du. On-Demand Deep Model Compression for Mobile Devices: A Usage-Driven Model
    Selection Framework. In Proc. 16th ACM Annual International Conference on Mobile
    Systems, Applications, and Services, pages 389–400, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[532] Tianqi Chen, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie Yan,
    Haichen Shen, Meghan Cowan, Leyuan Wang, Yuwei Hu, Luis Ceze, Carlos Guestrin,
    and Arvind Krishnamurthy. TVM: An Automated End-to-End Optimizing Compiler for
    Deep Learning. In 13th USENIX Symposium on Operating Systems Design and Implementation
    (OSDI 18), pages 578–594, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[533] Shuochao Yao, Yiran Zhao, Huajie Shao, ShengZhong Liu, Dongxin Liu, Lu Su,
    and Tarek Abdelzaher. FastDeepIoT: Towards Understanding and Optimizing Neural
    Network Execution Time on Mobile and Embedded Devices. In Proc. 16th ACM Conference
    on Embedded Networked Sensor Systems, pages 278–291, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[534] Surat Teerapittayanon, Bradley McDanel, and HT Kung. Distributed deep
    neural networks over the cloud, the edge and end devices. In Proc. 37th IEEE International
    Conference on Distributed Computing Systems (ICDCS), pages 328–339, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[535] Shayegan Omidshafiei, Jason Pazis, Christopher Amato, Jonathan P How,
    and John Vian. Deep decentralized multi-task multi-agent reinforcement learning
    under partial observability. In Proc. International Conference on Machine Learning
    (ICML), pages 2681–2690, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[536] Benjamin Recht, Christopher Re, Stephen Wright, and Feng Niu. Hogwild:
    A lock-free approach to parallelizing stochastic gradient descent. In Advances
    in neural information processing systems, pages 693–701, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[537] Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski,
    Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large Minibatch
    SGD: Training imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[538] ShuaiZheng Ruiliang Zhang and JamesT Kwok. Asynchronous distributed semi-stochastic
    gradient optimization. In Proc. National Conference on Artificial Intelligence
    (AAAI), 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[539] Corentin Hardy, Erwan Le Merrer, and Bruno Sericola. Distributed deep
    learning on edge-devices: feasibility via adaptive compression. In Proc. 16th
    IEEE International Symposium on Network Computing and Applications (NCA), pages
    1–8, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[540] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera
    y Arcas. Communication-efficient learning of deep networks from decentralized
    data. In Proc. 20th International Conference on Artificial Intelligence and Statistics,
    volume 54, pages 1273–1282, Fort Lauderdale, FL, USA, 20–22 Apr 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[541] Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H. Brendan
    McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth. Practical secure
    aggregation for privacy preserving machine learning. Cryptology ePrint Archive,
    Report 2017/281, 2017. https://eprint.iacr.org/2017/281.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[542] Suyog Gupta, Wei Zhang, and Fei Wang. Model accuracy and runtime tradeoff
    in distributed deep learning: A systematic study. In Proc. IEEE 16th International
    Conference on Data Mining (ICDM), pages 171–180, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[543] B McMahan and Daniel Ramage. Federated learning: Collaborative machine
    learning without centralized training data. Google Research Blog, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[544] Angelo Fumo, Marco Fiore, and Razvan Stanica. Joint spatial and temporal
    classification of mobile traffic demands. In Proc. IEEE Conference on Computer
    Communications, pages 1–9, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[545] Zhiyuan Chen and Bing Liu. Lifelong machine learning. Synthesis Lectures
    on Artificial Intelligence and Machine Learning, 10(3):1–145, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[546] Sang-Woo Lee, Chung-Yeon Lee, Dong-Hyun Kwak, Jiwon Kim, Jeonghee Kim,
    and Byoung-Tak Zhang. Dual-memory deep learning architectures for lifelong learning
    of everyday human behaviors. In Proc. International Joint Conferences on Artificial
    Intelligence, pages 1669–1675, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[547] Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka,
    Agnieszka Grabska-Barwińska, Sergio Gómez Colmenarejo, Edward Grefenstette, Tiago
    Ramalho, John Agapiou, et al. Hybrid computing using a neural network with dynamic
    external memory. Nature, 538(7626):471–476, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[548] German I Parisi, Jun Tani, Cornelius Weber, and Stefan Wermter. Lifelong
    learning of human actions with deep neural network self-organization. Neural Networks,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[549] Chen Tessler, Shahar Givony, Tom Zahavy, Daniel J Mankowitz, and Shie
    Mannor. A deep hierarchical approach to lifelong learning in Minecraft. In Proc.
    National Conference on Artificial Intelligence (AAAI), pages 1553–1561, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[550] Daniel López-Sánchez, Angélica González Arrieta, and Juan M Corchado.
    Deep neural networks and transfer learning applied to multimedia web mining. In
    Proc. 14th International Conference Distributed Computing and Artificial Intelligence,
    volume 620, page 124\. Springer, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[551] Ejder Baştuğ, Mehdi Bennis, and Mérouane Debbah. A transfer learning
    approach for cache-enabled wireless networks. In Proc. 13th IEEE International
    Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks
    (WiOpt), pages 161–166, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[552] Li Fei-Fei, Rob Fergus, and Pietro Perona. One-shot learning of object
    categories. IEEE transactions on pattern analysis and machine intelligence, 28(4):594–611,
    2006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[553] Mark Palatucci, Dean Pomerleau, Geoffrey E Hinton, and Tom M Mitchell.
    Zero-shot learning with semantic output codes. In Advances in neural information
    processing systems, pages 1410–1418, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[554] Oriol Vinyals, Charles Blundell, Tim Lillicrap, Daan Wierstra, et al.
    Matching networks for one shot learning. In Advances in Neural Information Processing
    Systems, pages 3630–3638, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[555] Soravit Changpinyo, Wei-Lun Chao, Boqing Gong, and Fei Sha. Synthesized
    classifiers for zero-shot learning. In Proc. IEEE Conference on Computer Vision
    and Pattern Recognition, pages 5327–5336, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[556] Junhyuk Oh, Satinder Singh, Honglak Lee, and Pushmeet Kohli. Zero-shot
    task generalization with multi-task deep reinforcement learning. In Proc. International
    Conference on Machine Learning (ICML), pages 2661–2670, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[557] Huandong Wang, Fengli Xu, Yong Li, Pengyu Zhang, and Depeng Jin. Understanding
    mobile traffic patterns of large scale cellular towers in urban environment. In
    Proc. ACM Internet Measurement Conference, pages 225–238, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[558] Cristina Marquez, Marco Gramaglia, Marco Fiore, Albert Banchs, Cezary
    Ziemlicki, and Zbigniew Smoreda. Not all Apps are created equal: Analysis of spatiotemporal
    heterogeneity in nationwide mobile service usage. In Proc. 13th ACM Conference
    on Emerging Networking Experiments and Technologies, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[559] Gianni Barlacchi, Marco De Nadai, Roberto Larcher, Antonio Casella, Cristiana
    Chitic, Giovanni Torrisi, Fabrizio Antonelli, Alessandro Vespignani, Alex Pentland,
    and Bruno Lepri. A multi-source dataset of urban life in the city of Milan and
    the province of Trentino. Scientific data, 2, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[560] Liang Liu, Wangyang Wei, Dong Zhao, and Huadong Ma. Urban resolution:
    New metric for measuring the quality of urban sensing. IEEE Transactions on Mobile
    Computing, 14(12):2560–2575, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[561] Denis Tikunov and Toshikazu Nishimura. Traffic prediction for mobile
    network using holt-winter’s exponential smoothing. In Proc. 15th IEEE International
    Conference on Software, Telecommunications and Computer Networks, pages 1–5, 2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[562] Hyun-Woo Kim, Jun-Hui Lee, Yong-Hoon Choi, Young-Uk Chung, and Hyukjoon
    Lee. Dynamic bandwidth provisioning using ARIMA-based traffic forecasting for
    Mobile WiMAX. Computer Communications, 34(1):99–106, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[563] R Qi Charles, Hao Su, Mo Kaichun, and Leonidas J Guibas. Pointnet: Deep
    learning on point sets for 3D classification and segmentation. In Proc. IEEE Conference
    on Computer Vision and Pattern Recognition (CVPR), pages 77–85, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[564] Anastasia Ioannidou, Elisavet Chatzilari, Spiros Nikolopoulos, and Ioannis
    Kompatsiaris. Deep learning advances in computer vision with 3D data: A survey.
    ACM Computing Surveys (CSUR), 50(2):20, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[565] Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and
    Gabriele Monfardini. The graph neural network model. IEEE Transactions on Neural
    Networks, 20(1):61–80, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[566] Yuan Yuan, Xiaodan Liang, Xiaolong Wang, Dit-Yan Yeung, and Abhinav Gupta.
    Temporal dynamic graph LSTM for action-driven video object detection. In Proc.
    IEEE International Conference on Computer Vision (ICCV), pages 1819–1828, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[567] Muhammad Usama, Junaid Qadir, Aunn Raza, Hunain Arif, Kok-Lim Alvin Yau,
    Yehia Elkhatib, Amir Hussain, and Ala Al-Fuqaha. Unsupervised machine learning
    for networking: Techniques, applications and research challenges. arXiv preprint
    arXiv:1709.06599, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[568] Chong Zhou and Randy C Paffenroth. Anomaly detection with robust deep
    autoencoders. In Proc. 23rd ACM SIGKDD International Conference on Knowledge Discovery
    and Data Mining, pages 665–674, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[569] Martín Abadi and David G Andersen. Learning to protect communications
    with adversarial neural cryptography. In Proc. International Conference on Learning
    Representations (ICLR), 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[570] David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou,
    Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore
    Graepel, Timothy Lillicrap, Karen Simonyan, and Demis Hassabis. A general reinforcement
    learning algorithm that masters chess, shogi, and Go through self-play. Science,
    362(6419):1140–1144, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
