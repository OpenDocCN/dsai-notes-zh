- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '分类: 未分类'
- en: 'date: 2024-09-06 20:08:19'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 20:08:19'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1801.06889] Visual Analytics in Deep Learning: An Interrogative Survey for
    the Next Frontiers'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1801.06889] 深度学习中的视觉分析：针对下一前沿的问卷调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1801.06889](https://ar5iv.labs.arxiv.org/html/1801.06889)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1801.06889](https://ar5iv.labs.arxiv.org/html/1801.06889)
- en: 'Visual Analytics in Deep Learning:'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习中的视觉分析：
- en: An Interrogative Survey for the Next Frontiers
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 针对下一前沿的问卷调查
- en: Fred Hohman,  Minsuk Kahng,  Robert Pienta,  and Duen Horng Chau F. Hohman,
    M. Kahng, R. Pienta, and D. H. Chau are with the College of Computing, Georgia
    Tech, Atlanta, Georgia 30332, U.S.A.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Fred Hohman,  Minsuk Kahng,  Robert Pienta,  和 Duen Horng Chau F. Hohman, M.
    Kahng, R. Pienta, 和 D. H. Chau 均来自乔治亚理工学院计算学院，位于美国乔治亚州亚特兰大，邮政编码30332。
- en: 'E-mail: {fredhohman, kahng, pientars, polo}@gatech.edu'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '电子邮件: {fredhohman, kahng, pientars, polo}@gatech.edu'
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep learning has recently seen rapid development and received significant attention
    due to its state-of-the-art performance on previously-thought hard problems. However,
    because of the internal complexity and nonlinear structure of deep neural networks,
    the underlying decision making processes for why these models are achieving such
    performance are challenging and sometimes mystifying to interpret. As deep learning
    spreads across domains, it is of paramount importance that we equip users of deep
    learning with tools for understanding when a model works correctly, when it fails,
    and ultimately how to improve its performance. Standardized toolkits for building
    neural networks have helped democratize deep learning; visual analytics systems
    have now been developed to support model explanation, interpretation, debugging,
    and improvement. We present a survey of the role of visual analytics in deep learning
    research, which highlights its short yet impactful history and thoroughly summarizes
    the state-of-the-art using a human-centered interrogative framework, focusing
    on the Five W’s and How (Why, Who, What, How, When, and Where). We conclude by
    highlighting research directions and open research problems. This survey helps
    researchers and practitioners in both visual analytics and deep learning to quickly
    learn key aspects of this young and rapidly growing body of research, whose impact
    spans a diverse range of domains.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习近年来发展迅速，并因其在曾被认为难题上的卓越表现而受到广泛关注。然而，由于深度神经网络的内部复杂性和非线性结构，解释这些模型为何能够取得如此表现的决策过程既具有挑战性，有时也令人困惑。随着深度学习在各领域的普及，至关重要的是，我们需要为深度学习用户提供工具，以了解模型何时正常工作、何时失败，以及最终如何提升其性能。标准化的神经网络构建工具包已帮助普及深度学习；如今已开发出视觉分析系统以支持模型解释、解读、调试和改进。我们呈现了深度学习研究中视觉分析的作用的调查，突出了其虽短但影响深远的历史，并通过以人为中心的问卷框架，重点关注五个W和一个H（为什么、谁、什么、如何、何时和哪里），全面总结了最新的技术。我们总结了研究方向和开放的研究问题。这项调查帮助视觉分析和深度学习领域的研究人员和从业者迅速了解这一年轻且快速发展的研究领域的关键方面，其影响涵盖了多个领域。
- en: 'Index Terms:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '索引词:'
- en: Deep learning, visual analytics, information visualization, neural networks![Refer
    to caption](img/c2bc6fa9c519fbe8d995f549ec635aca.png)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习、视觉分析、信息可视化、神经网络 ![参见标题](img/c2bc6fa9c519fbe8d995f549ec635aca.png)
- en: 'Figure 1: A visual overview of our interrogative survey, and how each of the
    six questions, ”Why, Who, What, How, When, and Where,” relate to one another.
    Each question corresponds to one section of this survey, indicated by the numbered
    tag, near each question title. Each section lists its major subsections discussed
    in the survey.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：我们问卷调查的视觉概述，以及“为什么、谁、什么、如何、何时和哪里”这六个问题如何相互关联。每个问题对应本调查的一个部分，标有编号标签，位于每个问题标题附近。每个部分列出了调查中讨论的主要子部分。
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Deep learning is a specific set of techniques from the broader field of machine
    learning (ML) that focus on the study and usage of deep artificial neural networks
    to learn structured representations of data. First mentioned as early as the 1940s [[1](#bib.bib1)],
    artificial neural networks have a rich history [[2](#bib.bib2)], and have recently
    seen a dominate and pervasive resurgence [[3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5)]
    in many research domains by producing state-of-the-art results [[6](#bib.bib6),
    [7](#bib.bib7)] on a number of diverse big data tasks [[8](#bib.bib8), [9](#bib.bib9)].
    For example, the premiere machine learning, deep learning, and artificial intelligence
    (AI) conferences have seen enormous growth in attendance and paper submissions
    since early 2010s. Furthermore, open-source toolkits and programming libraries
    for building, training, and evaluating deep neural networks have become more robust
    and easy to use, democratizing deep learning. As a result, the barrier to developing
    deep learning models is lower than ever before and deep learning applications
    are becoming pervasive.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习（ML）广泛领域中的一组特定技术，专注于研究和使用深度人工神经网络来学习数据的结构化表示。早在1940年代就首次提到的[[1](#bib.bib1)]，人工神经网络有着丰富的历史[[2](#bib.bib2)]，并且最近在许多研究领域中出现了主导和广泛的复兴[[3](#bib.bib3),
    [4](#bib.bib4), [5](#bib.bib5)]，在多个多样的大数据任务上取得了最先进的结果[[6](#bib.bib6), [7](#bib.bib7)]。例如，自2010年代初以来，顶级机器学习、深度学习和人工智能（AI）会议的参会人数和论文提交量都大幅增长。此外，用于构建、训练和评估深度神经网络的开源工具包和编程库已经变得更加强大和易于使用，使深度学习变得更加民主化。因此，开发深度学习模型的门槛比以往任何时候都要低，深度学习应用也变得越来越普遍。
- en: While this technological progress is impressive, it comes with unique and novel
    challenges. For example, the lack of interpretability and transparency of neural
    networks, from the learned representations to the underlying decision process,
    is an important problem to address. Making sense of why a particular model misclassifies
    test data instances or behaves poorly at times is a challenging task for model
    developers. Similarly, end-users interacting with an application that relies on
    deep learning to make critical decisions may question its reliability if no explanation
    is given by the model, or become baffled if the explanation is convoluted. While
    explaining neural network decisions is important, there are numerous other problems
    that arise from deep learning, such as AI safety and security (e.g., when using
    models in applications such as self-driving vehicles), and compromised trust due
    to bias in models and datasets, just to name a few. These challenges are often
    compounded, due to the large datasets required to train most deep learning models.
    As worrisome as these problems are, they will likely become even more widespread
    as more AI-powered systems are deployed in the world. Therefore, a general sense
    of model understanding is not only beneficial, but often required to address the
    aforementioned issues.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这一技术进步令人印象深刻，但也带来了独特而新颖的挑战。例如，神经网络的可解释性和透明度问题，从学习到的表示到底层决策过程，都是需要解决的重要问题。理解为什么某个模型会错误分类测试数据实例或在某些时候表现不佳是模型开发者面临的挑战任务。类似地，使用依赖深度学习进行关键决策的应用的最终用户，如果模型没有给出解释，可能会质疑其可靠性，或者如果解释复杂晦涩，可能会感到困惑。虽然解释神经网络决策很重要，但深度学习还带来了许多其他问题，例如AI安全性和安全性（例如，在自动驾驶车辆等应用中使用模型时），以及由于模型和数据集中的偏见导致的信任受损，仅举几例。这些挑战往往由于训练大多数深度学习模型所需的大数据集而加剧。尽管这些问题令人担忧，但随着越来越多的AI驱动系统在世界范围内部署，这些问题可能会变得更加普遍。因此，模型的一般理解不仅有益，而且往往是解决上述问题所必需的。
- en: Data visualization and visual analytics excel at knowledge communication and
    insight discovery by using encodings to transform abstract data into meaningful
    representations. In the seminal work by Zeiler and Fergus [[10](#bib.bib10)],
    a technique called deconvolutional networks enabled projection from a model’s
    learned feature space back to the pixel space. Their technique and results give
    insight into what types of features deep neural networks are learning at specific
    layers, and also serve as a debugging tool for improving a model. This work is
    often credited for popularizing visualization in the machine learning and computer
    vision communities in recent years, putting a spotlight on it as a powerful tool
    that helps people understand and improve deep learning models. However, visualization
    research for neural networks started well before [[11](#bib.bib11), [12](#bib.bib12),
    [13](#bib.bib13)]. Over just a handful of years, many different techniques have
    been introduced to help interpret what neural networks are learning. Many such
    techniques generate static images, such as attention maps and heatmaps for image
    classification, indicating which parts of an image are most important to the classification.
    However, interaction has also been incorporated into the model understanding process
    in visual analytics tools to help people gain insight [[14](#bib.bib14), [15](#bib.bib15),
    [16](#bib.bib16)]. This hybrid research area has grown in both academia and industry,
    forming the basis for many new research papers, academic workshops, and deployed
    industry tools.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可视化和视觉分析通过使用编码将抽象数据转化为有意义的表示，擅长于知识传递和洞察发现。在Zeiler和Fergus的开创性工作中[[10](#bib.bib10)]，一种叫做去卷积网络的技术使得从模型学习的特征空间投影回像素空间成为可能。他们的技术和结果提供了对深度神经网络在特定层次学习到的特征类型的洞察，同时也作为改进模型的调试工具。这项工作通常被认为在近年来使得可视化在机器学习和计算机视觉领域广受欢迎，突显了它作为一个帮助人们理解和改进深度学习模型的强大工具。然而，神经网络的可视化研究早在[[11](#bib.bib11)、[12](#bib.bib12)、[13](#bib.bib13)]之前就已开始。在短短几年间，许多不同的技术被提出以帮助解释神经网络所学习的内容。许多这样的技术生成静态图像，如用于图像分类的注意力图和热图，指出图像的哪些部分对分类最为重要。然而，互动也已被纳入视觉分析工具中的模型理解过程中，以帮助人们获得洞察[[14](#bib.bib14)、[15](#bib.bib15)、[16](#bib.bib16)]。这个混合研究领域在学术界和工业界都得到了发展，形成了许多新的研究论文、学术研讨会和部署的行业工具的基础。
- en: 'In this survey, we summarize a large number of deep learning visualization
    works using the Five W’s and How (Why, Who, What, How, When, and Where). Figure
    [1](#S0.F1 "Figure 1 ‣ Visual Analytics in Deep Learning: An Interrogative Survey
    for the Next Frontiers") presents a visual overview of how these interrogative
    questions reveal and organize the various facets of deep learning visualization
    research and their related topics. By framing the survey in this way, many existing
    works fit a description as the following fictional example:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '在这项调查中，我们使用“五个W和一个H”（为什么、谁、什么、如何、何时和哪里）总结了大量的深度学习可视化工作。图[1](#S0.F1 "Figure
    1 ‣ Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers")展示了这些提问如何揭示和组织深度学习可视化研究的各个方面及其相关主题的可视化概述。通过这种方式框架调查，许多现有工作符合以下虚构示例的描述：'
- en: To interpret representations learned by deep models (why), model developers
    (who) visualize neuron activations in convolutional neural networks (what) using
    t-SNE embeddings (how) after the training phase (when) to solve an urban planning
    problem (where).
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为了解释深度模型学到的表示（为什么），模型开发者（谁）在训练阶段后（何时）使用t-SNE嵌入（如何）可视化卷积神经网络中的神经元激活（什么），以解决城市规划问题（哪里）。
- en: This framing captures the needs, audience, and techniques of deep learning visualization,
    and positions new work’s contributions in the context of existing literature.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这种框架捕捉了深度学习可视化的需求、受众和技术，并将新工作的贡献置于现有文献的背景中。
- en: We conclude by highlighting prominent research directions and open problems.
    We hope that this survey acts as a companion text for researchers and practitioners
    wishing to understand how visualization supports deep learning research and applications.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过突出重要的研究方向和未解的问题来结束。我们希望这项调查能够作为研究人员和实践者理解可视化如何支持深度学习研究和应用的参考资料。
- en: 2 Our Contributions & Method of Survey
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 我们的贡献与调查方法
- en: 2.1 Our Contributions
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 我们的贡献
- en: C1.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C1.
- en: We present a comprehensive, timely survey on visualization and visual analytics
    in deep learning research, using a human-centered, interrogative framework. This
    method enables us to position each work with respect to its Five Ws and How (Why,
    Who, What, How, When, and Where), and flexibly discuss and highlight existing
    works’ multifaceted contributions.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提供了一个全面且及时的调查，关于深度学习研究中的可视化和视觉分析，使用以人为本的、询问式框架。这种方法使我们能够根据五个W和如何（为什么、谁、什么、如何、何时和哪里）定位每项工作，并灵活地讨论和突出现有工作的多方面贡献。
- en: $\bullet$
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Our human-centered approach using the Five W’s and How — based on how we familiarize
    ourselves with new topics in everyday settings — enables readers to quickly grasp
    important facets of this young and rapidly growing body of research.
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们基于五个W和如何的以人为本的方法——基于我们如何在日常环境中熟悉新话题——使读者能够迅速掌握这一年轻且迅速发展的研究领域的重要方面。
- en: $\bullet$
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Our interrogative process provides a framework to describe existing works, as
    well as a model to base new work off of.
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们的询问过程提供了一个描述现有工作的框架，同时也是新工作的基础模型。
- en: C2.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C2.
- en: To highlight and align the cross-cutting impact that visual analytics has had
    on deep learning across a broad range of domains, our survey goes beyond visualization-focused
    venues, extending a wide scope that encompasses most relevant works from many
    top venues in artificial intelligence, machine learning, deep learning, and computer
    vision. We highlight how visual analytics has been an integral component in solving
    some of AI’s biggest modern problems, such as neural network interpretability,
    trust, and security.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了突出和对齐视觉分析在深度学习中对广泛领域的跨切影响，我们的调查超越了以可视化为中心的场所，扩展到涵盖人工智能、机器学习、深度学习和计算机视觉等许多顶级场所的大部分相关工作。我们突出显示了视觉分析在解决一些人工智能现代最大问题中的关键作用，如神经网络的可解释性、信任和安全性。
- en: C3.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C3.
- en: As deep learning, and more generally AI, touches more aspects of our daily lives,
    we highlight important research directions and open problems that we distilled
    from the survey. These include improving the capabilities of visual analytics
    systems for furthering interpretability, conducting more effective design studies
    for evaluating system usability and utility, advocating humans’ important roles
    in AI-powered systems, and promoting proper and ethical use of AI applications
    to benefit society.
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随着深度学习以及更广泛的人工智能影响着我们日常生活的更多方面，我们突出了从调查中提炼出的重要研究方向和未解决的问题。这些包括提高视觉分析系统的能力以促进可解释性，进行更有效的设计研究以评估系统的可用性和实用性，倡导人在人工智能驱动系统中的重要作用，并推动人工智能应用的正确和伦理使用以造福社会。
- en: 2.2 Survey Methodology & Summarization Process
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 调查方法与总结过程
- en: 'We selected existing works from top computer science journals and conferences
    in visualization (e.g., IEEE Transactions on Visualization and Computer Graphics
    (TVCG)), visual analytics (e.g., IEEE Conference on Visual Analytics Science and
    Technology (VAST)) and deep learning (e.g., Conference on Neural Information Processing
    Systems (NIPS) and the International Conference on Machine Learning (ICML)). Since
    deep learning visualization is relatively new, much of the relevant work has appeared
    in workshops at the previously mentioned venues; therefore, we also include those
    works in our survey. Table [I](#S2.T1 "TABLE I ‣ 2.2 Survey Methodology & Summarization
    Process ‣ 2 Our Contributions & Method of Survey ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers") lists some of the most prominent
    publication venues and their acronyms. We also inspected preprints posted on arXiv
    ([https://arxiv.org/](https://arxiv.org/)), an open-access, electronic repository
    of manuscript preprints, whose computer science subject has become a hub for new
    deep learning research. Finally, aside from the traditional aforementioned venues,
    we include non-academic venues with significant attention such as Distill, industry
    lab research blogs, and research blogs of influential figures. Because of the
    rapid growth of deep learning research and the lack of a perfect fit for publishing
    and disseminating work in this hybrid area, therefore, the inclusion of these
    non-traditional sources are important to review, as they are highly influential
    and impactful to the field.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '我们选择了来自顶级计算机科学期刊和会议的现有工作，涉及可视化（例如，IEEE可视化与计算机图形学学报 (TVCG)）、视觉分析（例如，IEEE视觉分析科学与技术会议
    (VAST)）和深度学习（例如，神经信息处理系统会议 (NIPS) 和国际机器学习大会 (ICML)）。由于深度学习可视化相对较新，相关工作大多出现在上述场所的研讨会上，因此我们也在调查中包含了这些工作。表
    [I](#S2.T1 "TABLE I ‣ 2.2 Survey Methodology & Summarization Process ‣ 2 Our Contributions
    & Method of Survey ‣ Visual Analytics in Deep Learning: An Interrogative Survey
    for the Next Frontiers") 列出了部分最突出的出版场所及其缩写。我们还检查了arXiv上发布的预印本 ([https://arxiv.org/](https://arxiv.org/))，这是一个开放访问的电子预印本存储库，其计算机科学主题已成为新兴深度学习研究的中心。最后，除了传统的上述场所外，我们还包括了具有重要关注的非学术场所，如Distill、行业实验室研究博客和有影响力人物的研究博客。由于深度学习研究的快速增长和这一混合领域出版传播的缺乏完美匹配，因此，纳入这些非传统来源对评审非常重要，因为它们对该领域具有重要影响和影响力。'
- en: 'TABLE I: Relevant visualization and AI venues, in the order of: journals, conferences,
    workshops, open access journals, and preprint repositories. In each category,
    visualization venues precede AI venues.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '表 I: 相关可视化和人工智能场所的分类，顺序为：期刊、会议、研讨会、开放获取期刊和预印本存储库。在每个类别中，可视化场所优先于人工智能场所。'
- en: '| TVCG | IEEE Transactions on Visualization and Computer Graphics |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| TVCG | IEEE可视化与计算机图形学学报 |'
- en: '| VAST | IEEE Conference on Visual Analytics Science and Technology |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| VAST | IEEE视觉分析科学与技术会议 |'
- en: '| InfoVis | IEEE Information Visualization |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| InfoVis | IEEE信息可视化 |'
- en: '| VIS | IEEE Visualization Conference (VAST+InfoVis+SciVis) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| VIS | IEEE可视化会议 (VAST+InfoVis+SciVis) |'
- en: '| CHI | ACM Conference on Human Factors in Computing Systems |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| CHI | ACM计算机系统中的人因会议 |'
- en: '| NIPS | Conference on Neural Information Processing Systems |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| NIPS | 神经信息处理系统会议 |'
- en: '| ICML | International Conference on Machine Learning |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| ICML | 国际机器学习大会 |'
- en: '| CVPR | Conference on Computer Vision and Pattern Recognition |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| CVPR | 计算机视觉与模式识别大会 |'
- en: '| ICLR | International Conference on Learning Representations |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| ICLR | 国际学习表示会议 |'
- en: '| VADL | IEEE VIS Workshop on Visual Analytics for Deep Learning |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| VADL | IEEE VIS深度学习可视化研讨会 |'
- en: '| HCML | CHI Workshop on Human Centered Machine Learning |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| HCML | CHI人机中心机器学习研讨会 |'
- en: '| IDEA | KDD Workshop on Interactive Data Exploration & Analytics |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| IDEA | KDD交互数据探索与分析研讨会 |'
- en: '|  | ICML Workshop on Visualization for Deep Learning |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | ICML深度学习可视化研讨会 |'
- en: '| WHI | ICML Workshop on Human Interpretability in ML |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| WHI | ICML机器学习中的人类可解释性研讨会 |'
- en: '|  | NIPS Workshop on Interpreting, Explaining and Visualizing Deep Learning
    |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | NIPS深度学习解释、解释与可视化研讨会 |'
- en: '|  | NIPS Interpretable ML Symposium |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|  | NIPS可解释机器学习研讨会 |'
- en: '| FILM | NIPS Workshop on Future of Interactive Learning Machines |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| FILM | NIPS互动学习机器的未来研讨会 |'
- en: '|  | ACCV Workshop on Interpretation and Visualization of Deep Neural Nets
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  | ACCV深度神经网络解释与可视化研讨会 |'
- en: '|  | ICANN Workshop on Machine Learning and Interpretability |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|  | ICANN机器学习与可解释性研讨会 |'
- en: '| Distill | Distill: Journal for Supporting Clarity in Machine Learning |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| Distill | Distill: Journal for Supporting Clarity in Machine Learning |'
- en: '| arXiv | arXiv.org e-Print Archive |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| arXiv | arXiv.org e-Print Archive |'
- en: 'Visualization takes many forms throughout the deep learning literature. This
    survey focuses on visual analytics for deep learning. We also include related
    works from the AI and computer vision communities that contribute novel static
    visualizations. So far, the majority of work surrounds convolutional neural networks
    (CNNs) and image data; more recent work has begun to visualize other models, e.g.,
    recurrent neural networks (RNNs), long short-term memory units (LSTMs), and generative
    adversarial networks (GANs). For each work, we recorded the following information
    if present:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉化在深度学习文献中有多种形式。本调查专注于深度学习的视觉分析。我们还包括了来自人工智能和计算机视觉社区的相关工作，这些工作提供了新的静态视觉化。目前，大多数工作围绕卷积神经网络（CNNs）和图像数据展开；最近的工作开始可视化其他模型，例如递归神经网络（RNNs）、长短期记忆单元（LSTMs）和生成对抗网络（GANs）。对于每项工作，如果有，我们记录了以下信息：
- en: •
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Metadata (title, authors, venue, and year published)
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 元数据（标题、作者、刊物和出版年份）
- en: •
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: General approach and short summary
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一般方法和简要总结
- en: •
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Explicit contributions
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 明确的贡献
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Future work
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 未来工作
- en: •
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Design component (e.g. user-centered design methodologies, interviews, evaluation)
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 设计组件（例如用户中心设计方法、访谈、评估）
- en: •
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Industry involvement and open-source code
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 行业参与和开源代码
- en: With this information, we used the Five W’s and How (Why, Who, What, How, When,
    and Where) to organize these existing works and the current state-of-the-art of
    visualization and visual analytics in deep learning.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些信息，我们使用了“五个W和一个H”（为什么、谁、什么、如何、何时和哪里）来组织这些现有工作和深度学习中的视觉化与视觉分析的最新状态。
- en: 2.3 Related Surveys
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 相关调查
- en: While there is a larger literature for visualization for machine learning, including
    predictive visual analytics [[17](#bib.bib17), [18](#bib.bib18), [19](#bib.bib19)]
    and human-in-the-loop interactive machine learning [[20](#bib.bib20), [21](#bib.bib21)],
    to our knowledge there is no comprehensive survey of visualization and visual
    analytics for deep learning. Regarding deep neural networks, related surveys include
    a recent book chapter that discusses visualization of deep neural networks related
    to the field of computer vision [[22](#bib.bib22)], an unpublished essay that
    proposes a preliminary taxonomy for visualization techniques [[23](#bib.bib23)],
    and an article that focuses on describing interactive model analysis, which mentions
    deep learning in a few contexts while describing a high-level framework for general
    machine learning models [[24](#bib.bib24)]. A recent overview article by Choo
    and Liu [[25](#bib.bib25)] is the closest in spirit to our survey. Our survey
    provides wider coverage and more detailed analysis of the literature.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管关于机器学习的视觉化文献较多，包括预测性视觉分析[[17](#bib.bib17), [18](#bib.bib18), [19](#bib.bib19)]和人机交互式机器学习[[20](#bib.bib20),
    [21](#bib.bib21)]，但据我们了解，没有针对深度学习的视觉化和视觉分析的全面调查。关于深度神经网络，相关调查包括最近一本书的章节，讨论了与计算机视觉领域相关的深度神经网络的可视化[[22](#bib.bib22)]，一篇未发表的论文提出了视觉化技术的初步分类法[[23](#bib.bib23)]，以及一篇专注于描述交互式模型分析的文章，在描述通用机器学习模型的高级框架时提到了一些深度学习的背景[[24](#bib.bib24)]。Choo和Liu最近的一篇概述文章[[25](#bib.bib25)]在精神上最接近我们的调查。我们的调查提供了更广泛的覆盖和更详细的文献分析。
- en: Different from all the related articles mentioned above, our survey provides
    a comprehensive, human-centered, and interrogative framework to describe deep
    learning visual analytics tools, discusses the new, rapidly growing community
    at large, and presents the major research trajectories synthesized from existing
    literature.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述所有相关文献不同，我们的调查提供了一个全面的、人本中心的、探究性框架来描述深度学习视觉分析工具，讨论了快速增长的新兴社区，并呈现了从现有文献中综合出的主要研究轨迹。
- en: 2.4 Survey Overview & Organization
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 调查概述与组织
- en: 'Section [3](#S3 "3 Common Terminology ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers") introduces common deep learning
    terminology. Figure [1](#S0.F1 "Figure 1 ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers") shows a visual overview of this
    survey’s structure and Table [II](#S3.T2 "TABLE II ‣ 3 Common Terminology ‣ Visual
    Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers") summarizes
    representative works. Each interrogative question (Why, Who, What, How, When,
    and Where) is given its own section for discussion, ordered to best motivate why
    visualization and visual analytics in deep learning is such a rich and exciting
    area of research.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 第[3](#S3 "3 常见术语 ‣ 深度学习中的视觉分析：面向下一个前沿的质疑性调查")节介绍了常见的深度学习术语。图[1](#S0.F1 "图 1
    ‣ 深度学习中的视觉分析：面向下一个前沿的质疑性调查")展示了本调查结构的视觉概述，表[II](#S3.T2 "表 II ‣ 3 常见术语 ‣ 深度学习中的视觉分析：面向下一个前沿的质疑性调查")总结了代表性工作。每个质疑性问题（为什么、谁、什么、如何、何时和哪里）都分配了一个单独的章节进行讨论，按顺序排列，以最佳方式阐明为什么深度学习中的可视化和视觉分析是一个如此丰富且令人兴奋的研究领域。
- en: '<svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="33.06"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="12.3"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">$\boldsymbol{\S}$
    [4](#S4 "4 Why Visualize Deep Learning ‣ Visual Analytics in Deep Learning: An
    Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="33.06"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="12.3"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">$\boldsymbol{\S}$
    [4](#S4 "4 为什么要可视化深度学习 ‣ 深度学习中的视觉分析：面向下一个前沿的质疑性调查")</foreignobject></g></g></svg>
- en: Why do we want to visualize deep learning? Why and for what purpose would one
    want to use visualization in deep learning?
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们为什么要可视化深度学习？为什么以及出于什么目的需要在深度学习中使用可视化？
- en: '<svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="33.06"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="12.3"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">$\boldsymbol{\S}$
    [5](#S5 "5 Who Uses Deep Learning Visualization ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="33.06"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="12.3"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">$\boldsymbol{\S}$
    [5](#S5 "5 谁在使用深度学习可视化 ‣ 深度学习中的视觉分析：面向下一个前沿的质疑性调查")</foreignobject></g></g></svg>
- en: Who wants to visualize deep learning? Who are the types of people and users
    that would use and stand to benefit from visualizing deep learning?
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 谁希望可视化深度学习？哪些人群和用户会使用并从深度学习可视化中受益？
- en: '<svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="33.06"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="12.3"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">$\boldsymbol{\S}$
    [6](#S6 "6 What to Visualize in Deep Learning ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="33.06"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="12.3"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">$\boldsymbol{\S}$
    [6](#S6 "6 什么是深度学习中的可视化 ‣ 深度学习中的视觉分析：面向下一个前沿的质疑性调查")</foreignobject></g></g></svg>
- en: What can we visualize in deep learning? What data, features, and relationships
    are inherent to deep learning that can be visualized?
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以在深度学习中可视化什么？深度学习中固有的数据、特征和关系是什么，可以被可视化？
- en: '<svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="33.06"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="12.3"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">$\boldsymbol{\S}$
    [7](#S7 "7 How to Visualize Deep Learning ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '<svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="33.06"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="12.3"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">$\boldsymbol{\S}$
    [7](#S7 "7 How to Visualize Deep Learning ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
- en: How can we visualize deep learning? How can we visualize the aforementioned
    data, features, and relationships?
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们如何进行深度学习可视化？我们如何可视化上述数据、特征和关系？
- en: '<svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="33.06"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="12.3"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">$\boldsymbol{\S}$
    [8](#S8 "8 When to Visualize in the Deep Learning Process ‣ Visual Analytics in
    Deep Learning: An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '<svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="33.06"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="12.3"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">$\boldsymbol{\S}$
    [8](#S8 "8 When to Visualize in the Deep Learning Process ‣ Visual Analytics in
    Deep Learning: An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
- en: When can we visualize deep learning? When in the deep learning process is visualization
    used and best suited?
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们什么时候可以进行深度学习可视化？在深度学习过程中，什么时候使用可视化最为合适？
- en: '<svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="33.06"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="12.3"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">$\boldsymbol{\S}$
    [9](#S9 "9 Where is Deep Learning Visualization ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '<svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="33.06"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="12.3"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">$\boldsymbol{\S}$
    [9](#S9 "9 Where is Deep Learning Visualization ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
- en: Where is deep learning visualization being used? Where has deep learning visualization
    been used?
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度学习可视化在哪里被使用？深度学习可视化曾经在哪里使用过？
- en: 'Section [10](#S10 "10 Research Directions & Open Problems ‣ Visual Analytics
    in Deep Learning: An Interrogative Survey for the Next Frontiers") presents research
    directions and open problems that we gathered and distilled from the literature
    survey. Section [11](#S11 "11 Conclusion ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers") concludes the survey.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[第10节](#S10 "10 Research Directions & Open Problems ‣ Visual Analytics in Deep
    Learning: An Interrogative Survey for the Next Frontiers")介绍了我们从文献调研中收集和提炼的研究方向和未解决的问题。[第11节](#S11
    "11 Conclusion ‣ Visual Analytics in Deep Learning: An Interrogative Survey for
    the Next Frontiers")总结了本次调研。'
- en: 3 Common Terminology
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 常见术语
- en: 'To enhance readability of this survey, and to provide quick references for
    readers new to deep learning, we have tabulated a sample of relevant and common
    deep learning terminology used in this work, shown in Table [III](#S3.T3 "TABLE
    III ‣ 3 Common Terminology ‣ Visual Analytics in Deep Learning: An Interrogative
    Survey for the Next Frontiers"). The reader may want to refer to Table [III](#S3.T3
    "TABLE III ‣ 3 Common Terminology ‣ Visual Analytics in Deep Learning: An Interrogative
    Survey for the Next Frontiers") throughout this survey for technical terms, meanings,
    and synonyms used in various contexts of discussion. The table serves as an introduction
    and summarization of the state-of-the-art. For definitive technical and mathematical
    descriptions, we encourage the reader to refer to excellent texts on deep learning
    and neural network design, such as the Deep Learning textbook [[26](#bib.bib26)].'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提升本调查的可读性，并为新手快速提供深度学习的参考，我们已经将相关和常见的深度学习术语制成了表格，见表 [III](#S3.T3 "TABLE III
    ‣ 3 常见术语 ‣ 深度学习中的可视分析：针对下一步前沿的探讨调查")。读者可以在本调查过程中参考表 [III](#S3.T3 "TABLE III ‣
    3 常见术语 ‣ 深度学习中的可视分析：针对下一步前沿的探讨调查")，了解技术术语、含义及各种讨论背景下的同义词。该表格作为最前沿技术的介绍和总结。对于详细的技术和数学描述，我们鼓励读者参考优秀的深度学习和神经网络设计教材，如《深度学习》[[26](#bib.bib26)]。
- en: 'TABLE II: Overview of representative works in visual analytics for deep learning.
    Each row is one work; works are sorted alphabetically by first author’s last name.
    Each column corresponds to a subsection from the six interrogative questions.
    A work’s relevant subsection is indicated by a colored cell.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：深度学习可视分析的代表性工作的概述。每一行代表一项工作；这些工作按第一作者的姓氏字母顺序排序。每一列对应于六个质询问题中的一个子部分。工作相关的子部分由彩色单元格表示。
- en: '|  | WHY | WHO | WHAT | HOW | WHEN | WHERE |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|  | 为什么 | 谁 | 什么 | 如何 | 何时 | 哪里 |'
- en: '| Work | <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="22.29"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">[4.1](#S4.SS1
    "4.1 Interpretability & Explainability ‣ 4 Why Visualize Deep Learning ‣ Visual
    Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '| 工作 | <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="22.29"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">[4.1](#S4.SS1
    "4.1 解释性与可解释性 ‣ 4 为什么要可视化深度学习 ‣ 深度学习中的可视分析：针对下一步前沿的探讨调查")</foreignobject></g></g></svg>'
- en: 'Interpretability & Explainability  | <svg  class="ltx_picture"
    height="20.06" overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[4.2](#S4.SS2 "4.2 Debugging & Improving Models ‣ 4 Why Visualize
    Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative Survey for
    the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 解释性与可解释性 | <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="22.29"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">[4.2](#S4.SS2
    "4.2 调试与改进模型 ‣ 4 为什么要可视化深度学习 ‣ 深度学习中的可视分析：针对下一步前沿的探讨调查")</foreignobject></g></g></svg>
- en: 'Debugging & Improving Models  | <svg  class="ltx_picture"
    height="20.06" overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[4.3](#S4.SS3 "4.3 Comparing & Selecting Models ‣ 4 Why Visualize
    Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative Survey for
    the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 调试与改进模型  | <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="22.29"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">[4.3](#S4.SS3
    "4.3 比较与选择模型 ‣ 4 为什么可视化深度学习 ‣ 深度学习中的视觉分析：面向下一个前沿的调查")</foreignobject></g></g></svg>
- en: 'Comparing & Selecting Models  | <svg  class="ltx_picture"
    height="20.06" overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[4.4](#S4.SS4 "4.4 Teaching Deep Learning Concepts ‣ 4 Why Visualize
    Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative Survey for
    the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 比较与选择模型  | <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="22.29"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">[4.4](#S4.SS4
    "4.4 教授深度学习概念 ‣ 4 为什么可视化深度学习 ‣ 深度学习中的视觉分析：面向下一个前沿的调查")</foreignobject></g></g></svg>
- en: 'Teaching Deep Learning Concepts  | <svg  class="ltx_picture"
    height="20.06" overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[5.1](#S5.SS1 "5.1 Model Developers & Builders ‣ 5 Who Uses Deep
    Learning Visualization ‣ Visual Analytics in Deep Learning: An Interrogative Survey
    for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 教授深度学习概念  | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[5.1](#S5.SS1 "5.1 模型开发者与构建者 ‣ 5 谁使用深度学习可视化 ‣ 深度学习中的视觉分析：面向下一个前沿的调查")</foreignobject></g></g></svg>
- en: 'Model Developers & Builders  | <svg  class="ltx_picture"
    height="20.06" overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[5.2](#S5.SS2 "5.2 Model Users ‣ 5 Who Uses Deep Learning Visualization
    ‣ Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发者与构建者  | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[5.2](#S5.SS2 "5.2 模型用户 ‣ 5 谁使用深度学习可视化 ‣ 深度学习中的视觉分析：面向下一个前沿的调查")</foreignobject></g></g></svg>
- en: 'Model Users  | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[5.3](#S5.SS3 "5.3 Non-experts ‣ 5 Who Uses Deep Learning Visualization
    ‣ Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 模型用户  | <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="22.29"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">[5.3](#S5.SS3
    "5.3 非专家 ‣ 5 谁在使用深度学习可视化 ‣ 深度学习中的可视化分析：未来前沿的询问性调查")</foreignobject></g></g></svg>
- en: 'Non-experts  | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[6.1](#S6.SS1 "6.1 Computational Graph & Network Architecture
    ‣ 6 What to Visualize in Deep Learning ‣ Visual Analytics in Deep Learning: An
    Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 非专家  | <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="22.29"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">[6.1](#S6.SS1
    "6.1 计算图与网络架构 ‣ 6 深度学习中的可视化内容 ‣ 深度学习中的可视化分析：未来前沿的询问性调查")</foreignobject></g></g></svg>
- en: 'Computational Graph & Network Architecture  | <svg 
    class="ltx_picture" height="20.06" overflow="visible" version="1.1" width="22.29"><g
    transform="translate(0,20.06) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46
    6.92)"><foreignobject width="15.37" height="13.84" transform="matrix(1 0 0 -1
    0 16.6)" overflow="visible" color="#000000">[6.2](#S6.SS2 "6.2 Learned Model Parameters
    ‣ 6 What to Visualize in Deep Learning ‣ Visual Analytics in Deep Learning: An
    Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 计算图与网络架构  | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[6.2](#S6.SS2 "6.2 已学习的模型参数 ‣ 6 深度学习中的可视化内容 ‣ 深度学习中的可视化分析：未来前沿的询问性调查")</foreignobject></g></g></svg>
- en: 'Learned Model Parameters  | <svg  class="ltx_picture"
    height="20.06" overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[6.3](#S6.SS3 "6.3 Individual Computational Units ‣ 6 What to
    Visualize in Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative
    Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 已学习的模型参数  | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[6.3](#S6.SS3 "6.3 个别计算单元 ‣ 6 深度学习中的可视化内容 ‣ 深度学习中的可视化分析：未来前沿的询问性调查")</foreignobject></g></g></svg>
- en: 'Individual Computational Units  | <svg  class="ltx_picture"
    height="20.06" overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[6.4](#S6.SS4 "6.4 Neurons in High-dimensional Space ‣ 6 What
    to Visualize in Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative
    Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 单独计算单元  | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[6.4](#S6.SS4 "6.4 高维空间中的神经元 ‣ 6 深度学习中需要可视化的内容 ‣ 深度学习中的视觉分析：面向下一前沿的探究性调查")</foreignobject></g></g></svg>
- en: 'Neurons in High-dimensional Space  | <svg  class="ltx_picture"
    height="20.06" overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[6.5](#S6.SS5 "6.5 Aggregated Information ‣ 6 What to Visualize
    in Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative Survey
    for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 高维空间中的神经元  | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[6.5](#S6.SS5 "6.5 聚合信息 ‣ 6 深度学习中需要可视化的内容 ‣ 深度学习中的视觉分析：面向下一前沿的探究性调查")</foreignobject></g></g></svg>
- en: 'Aggregated Information  | <svg  class="ltx_picture"
    height="20.06" overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[7.1](#S7.SS1 "7.1 Node-link Diagrams for Network Architectures
    ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative
    Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合信息  | <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="22.29"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">[7.1](#S7.SS1
    "7.1 网络架构的节点-链接图 ‣ 7 如何可视化深度学习 ‣ 深度学习中的视觉分析：面向下一前沿的探究性调查")</foreignobject></g></g></svg>
- en: 'Node-link Diagrams for Network Architecture  | <svg 
    class="ltx_picture" height="20.06" overflow="visible" version="1.1" width="22.29"><g
    transform="translate(0,20.06) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46
    6.92)"><foreignobject width="15.37" height="13.84" transform="matrix(1 0 0 -1
    0 16.6)" overflow="visible" color="#000000">[7.2](#S7.SS2 "7.2 Dimensionality
    Reduction & Scatter Plots ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics
    in Deep Learning: An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 网络架构的节点-链接图  | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[7.2](#S7.SS2 "7.2 降维与散点图 ‣ 7 如何可视化深度学习 ‣ 深度学习中的视觉分析：面向下一前沿的探究性调查")</foreignobject></g></g></svg>
- en: 'Dimensionality Reduction & Scatter Plots  | <svg 
    class="ltx_picture" height="20.06" overflow="visible" version="1.1" width="22.29"><g
    transform="translate(0,20.06) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46
    6.92)"><foreignobject width="15.37" height="13.84" transform="matrix(1 0 0 -1
    0 16.6)" overflow="visible" color="#000000">[7.3](#S7.SS3 "7.3 Line Charts for
    Temporal Metrics ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics in Deep
    Learning: An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 降维与散点图 | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[7.3](#S7.SS3 "7.3 时间指标的折线图 ‣ 7 如何可视化深度学习 ‣ 深度学习中的视觉分析：面向未来前沿的探讨")</foreignobject></g></g></svg>
- en: 'Line Charts for Temporal Metrics  | <svg  class="ltx_picture"
    height="20.06" overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[7.4](#S7.SS4 "7.4 Instance-based Analysis & Exploration ‣ 7 How
    to Visualize Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative
    Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 时间指标的折线图 | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[7.4](#S7.SS4 "7.4 基于实例的分析与探索 ‣ 7 如何可视化深度学习 ‣ 深度学习中的视觉分析：面向未来前沿的探讨")</foreignobject></g></g></svg>
- en: 'Instance-based Analysis & Exploration  | <svg  class="ltx_picture"
    height="20.06" overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[7.5](#S7.SS5 "7.5 Interactive Experimentation ‣ 7 How to Visualize
    Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative Survey for
    the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 基于实例的分析与探索 | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[7.5](#S7.SS5 "7.5 交互式实验 ‣ 7 如何可视化深度学习 ‣ 深度学习中的视觉分析：面向未来前沿的探讨")</foreignobject></g></g></svg>
- en: 'Interactive Experimentation  | <svg  class="ltx_picture"
    height="20.06" overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[7.6](#S7.SS6 "7.6 Algorithms for Attribution & Feature Visualization
    ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative
    Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 交互式实验 | <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="22.29"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">[7.6](#S7.SS6
    "7.6 属性和特征可视化算法 ‣ 7 如何可视化深度学习 ‣ 深度学习中的视觉分析：面向未来前沿的探讨")</foreignobject></g></g></svg>
- en: 'Algorithms for Attribution & Feature Visualization  | <svg 
    class="ltx_picture" height="20.06" overflow="visible" version="1.1" width="22.29"><g
    transform="translate(0,20.06) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46
    6.92)"><foreignobject width="15.37" height="13.84" transform="matrix(1 0 0 -1
    0 16.6)" overflow="visible" color="#000000">[8.1](#S8.SS1 "8.1 During Training
    ‣ 8 When to Visualize in the Deep Learning Process ‣ Visual Analytics in Deep
    Learning: An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 特征归因与可视化算法  | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[8.1](#S8.SS1 "8.1 训练期间 ‣ 8 深度学习过程中的可视化时机 ‣ 深度学习中的视觉分析：面向下一个前沿的审问调查")</foreignobject></g></g></svg>
- en: 'During Training  | <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[8.2](#S8.SS2 "8.2 After Training ‣ 8 When to Visualize in the
    Deep Learning Process ‣ Visual Analytics in Deep Learning: An Interrogative Survey
    for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 训练期间  | <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="22.29"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">[8.2](#S8.SS2
    "8.2 训练后 ‣ 8 深度学习过程中的可视化时机 ‣ 深度学习中的视觉分析：面向下一个前沿的审问调查")</foreignobject></g></g></svg>
- en: 'After Training  |  <svg  class="ltx_picture" height="20.06"
    overflow="visible" version="1.1" width="22.29"><g transform="translate(0,20.06)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject
    width="15.37" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[9.2](#S9.SS2 "9.2 A Vibrant Research Community: Hybrid, Apace,
    & Open-sourced ‣ 9 Where is Deep Learning Visualization ‣ Visual Analytics in
    Deep Learning: An Interrogative Survey for the Next Frontiers")</foreignobject></g></g></svg>'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后  |  <svg  class="ltx_picture" height="20.06" overflow="visible"
    version="1.1" width="22.29"><g transform="translate(0,20.06) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 3.46 6.92)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">[9.2](#S9.SS2
    "9.2 一个充满活力的研究社区：混合型、开源型 ‣ 9 深度学习可视化的现状 ‣ 深度学习中的视觉分析：面向下一个前沿的审问调查")</foreignobject></g></g></svg>
- en: Publication Venue  |
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 发布场所  |
- en: '| Abadi, et al., 2016 [[27](#bib.bib27)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     arXiv |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| Abadi 等, 2016 [[27](#bib.bib27)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     arXiv |'
- en: '| Bau, et al., 2017 [[28](#bib.bib28)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     CVPR |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| Bau 等, 2017 [[28](#bib.bib28)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     CVPR |'
- en: '| Bilal, et al., 2017 [[29](#bib.bib29)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| Bilal 等, 2017 [[29](#bib.bib29)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
- en: '| Bojarski, et al., 2016 [[30](#bib.bib30)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     arXiv |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| Bojarski 等, 2016 [[30](#bib.bib30)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     arXiv |'
- en: '| Bruckner, 2014 [[31](#bib.bib31)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     MS Thesis |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| Bruckner, 2014 [[31](#bib.bib31)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     MS 论文 |'
- en: '| Carter, et al., 2016 [[32](#bib.bib32)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     Distill |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| Carter 等, 2016 [[32](#bib.bib32)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     Distill |'
- en: '| Cashman, et al., 2017 [[33](#bib.bib33)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     VADL |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| Cashman 等, 2017 [[33](#bib.bib33)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     VADL |'
- en: '| Chae, et al., 2017 [[34](#bib.bib34)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     VADL |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| Chae 等, 2017 [[34](#bib.bib34)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     VADL |'
- en: '| Chung, et al., 2016 [[35](#bib.bib35)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     FILM |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| Chung 等, 2016 [[35](#bib.bib35)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     FILM |'
- en: '| Goyal, et al., 2016 [[36](#bib.bib36)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     arXiv |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| Goyal等，2016 [[36](#bib.bib36)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     arXiv |'
- en: '| Harley, 2015 [[37](#bib.bib37)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ISVC |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| Harley，2015 [[37](#bib.bib37)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ISVC |'
- en: '| Hohman, et al., 2017 [[38](#bib.bib38)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     CHI |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| Hohman等，2017 [[38](#bib.bib38)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     CHI |'
- en: '| Kahng, et al., 2018 [[39](#bib.bib39)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| Kahng等，2018 [[39](#bib.bib39)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
- en: '| Karpathy, et al., 2015 [[40](#bib.bib40)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     arXiv |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| Karpathy等，2015 [[40](#bib.bib40)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     arXiv |'
- en: '| Li, et al., 2015 [[41](#bib.bib41)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     arXiv |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| Li等，2015 [[41](#bib.bib41)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     arXiv |'
- en: '| Liu, et al., 2017 [[14](#bib.bib14)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| Liu等，2017 [[14](#bib.bib14)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
- en: '| Liu, et al., 2018 [[42](#bib.bib42)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| Liu等，2018 [[42](#bib.bib42)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
- en: '| Ming, et al., 2017 [[43](#bib.bib43)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     VAST |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| Ming等，2017 [[43](#bib.bib43)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     VAST |'
- en: '| Norton & Qi, 2017 [[44](#bib.bib44)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     VizSec |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| Norton & Qi，2017 [[44](#bib.bib44)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     VizSec |'
- en: '| Olah, 2014 [[45](#bib.bib45)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     Web |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| Olah，2014 [[45](#bib.bib45)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     Web |'
- en: '| Olah, et al., 2018 [[46](#bib.bib46)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     Distill |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| Olah等，2018 [[46](#bib.bib46)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     Distill |'
- en: '| Pezzotti, et al., 2017 [[47](#bib.bib47)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| Pezzotti等，2017 [[47](#bib.bib47)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
- en: '| Rauber, et al., 2017 [[48](#bib.bib48)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| Rauber等，2017 [[48](#bib.bib48)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
- en: '| Robinson, et al., 2017 [[49](#bib.bib49)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     GeoHum. |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| Robinson等，2017 [[49](#bib.bib49)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     GeoHum. |'
- en: '| Rong & Adar, 2016 [[50](#bib.bib50)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ICML VIS |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| Rong & Adar，2016 [[50](#bib.bib50)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ICML VIS |'
- en: '| Smilkov, et al., 2016 [[51](#bib.bib51)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     NIPS WS. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| Smilkov等，2016 [[51](#bib.bib51)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     NIPS WS. |'
- en: '| Smilkov, et al., 2017 [[16](#bib.bib16)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ICML VIS |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| Smilkov等，2017 [[16](#bib.bib16)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ICML VIS |'
- en: '| Strobelt, et al., 2018 [[52](#bib.bib52)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| Strobelt等，2018 [[52](#bib.bib52)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
- en: '| Tzeng & Ma, 2005 [[13](#bib.bib13)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     VIS |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| Tzeng & Ma，2005 [[13](#bib.bib13)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     VIS |'
- en: '| Wang, et al., 2018 [[53](#bib.bib53)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| Wang等，2018 [[53](#bib.bib53)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
- en: '| Webster, et al., 2017 [[54](#bib.bib54)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     Web |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| Webster等，2017 [[54](#bib.bib54)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     Web |'
- en: '| Wongsuphasawat, et al., 2018 [[15](#bib.bib15)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| Wongsuphasawat等，2018 [[15](#bib.bib15)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     TVCG |'
- en: '| Yosinski, et al., 2015 [[55](#bib.bib55)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ICML DL |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| Yosinski等，2015 [[55](#bib.bib55)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ICML DL |'
- en: '| Zahavy, et al., 2016 [[56](#bib.bib56)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ICML |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| Zahavy等，2016 [[56](#bib.bib56)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ICML |'
- en: '| Zeiler, et al., 2014 [[10](#bib.bib10)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ECCV |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| Zeiler等，2014 [[10](#bib.bib10)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ECCV |'
- en: '| Zeng, et al., 2017 [[57](#bib.bib57)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     VADL |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| Zeng 等，2017 [[57](#bib.bib57)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     VADL |'
- en: '| Zhong, et al., 2017 [[58](#bib.bib58)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ICML VIS |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| Zhong 等，2017 [[58](#bib.bib58)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ICML VIS |'
- en: '| Zhu, et al., 2016 [[59](#bib.bib59)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ECCV |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| Zhu 等，2016 [[59](#bib.bib59)] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
     ECCV |'
- en: 'TABLE III: Foundational deep learning terminology used in this paper, sorted
    by importance. In a term’s “meaning” (last column), defined terms are italicized.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 表 III：本文使用的基础深度学习术语，按重要性排序。在术语的“含义”（最后一列）中，已定义的术语以*斜体*显示。
- en: '| Technical Term | Synonyms | Meaning |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 技术术语 | 同义词 | 含义 |'
- en: '| --- | --- | --- |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Neural Network | Artificial neural net, net | Biologically-inspired models
    that form the basis of deep learning; approximate functions dependent upon a large
    and unknown amount of inputs consisting of layers of neurons |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 神经网络 | 人工神经网络，网络 | 受生物启发的模型，形成深度学习的基础；近似依赖于大量且未知输入的函数，由神经元层组成 |'
- en: '| Neuron | Computational unit, node | Building blocks of neural networks, entities
    that can apply activation functions |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 神经元 | 计算单元，节点 | 神经网络的基本构件，可以应用激活函数 |'
- en: '| Weights | Edges | The trained and updated parameters in the neural network
    model that connect neurons to one another |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 权重 | 边缘 | 神经网络模型中训练和更新的参数，将神经元相互连接 |'
- en: '| Layer | Hidden layer | Stacked collection of neurons that attempt to extract
    features from data; a layer’s input is connected to a previous layer’s output
    |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 层 | 隐藏层 | 尝试从数据中提取特征的神经元堆叠集合；一层的输入连接到前一层的输出 |'
- en: '| Computational Graph | Dataflow graph | Directed graph where nodes represent
    operations and edges represent data paths; when implementing neural network models,
    often times they are represented as these |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 计算图 | 数据流图 | 有向图，其中节点表示操作，边缘表示数据路径；在实现神经网络模型时，通常将其表示为这些图 |'
- en: '| Activation Functions | Transform function | Functions embedded into each
    layer of a neural network that enable the network represent complex non-linear
    decisions boundaries |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 激活函数 | 转换函数 | 嵌入到神经网络每一层的函数，使网络能够表示复杂的非线性决策边界 |'
- en: '| Activations | Internal representation | Given a trained network one can pass
    in data and recover the activations at any layer of the network to obtain its
    current representation inside the network |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 激活 | 内部表示 | 给定一个训练好的网络，可以传入数据并恢复网络任何层的激活，以获得网络内部的当前表示 |'
- en: '| Convolutional Neural Network | CNN, convnet | Type of neural network composed
    of convolutional layers that typically assume image data as input; these layers
    have depth unlike typical layers that only have width (number of neurons in a
    layer); they make use of filters (feature & pattern detectors) to extract spatially
    invariant representations |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 卷积神经网络 | CNN，convnet | 一种由卷积层组成的神经网络类型，这些层通常以图像数据作为输入；这些层具有深度，与仅具有宽度（层中的神经元数量）的典型层不同；它们使用滤波器（特征和模式检测器）来提取空间不变的表示
    |'
- en: '| Long Short-Term Memory | LSTM | Type of neural network, often used in text
    analysis, that addresses the vanishing gradient problem by using memory gates
    to propagate gradients through the network to learn long-range dependencies |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 长短期记忆 | LSTM | 一种神经网络，常用于文本分析，通过使用记忆门来解决梯度消失问题，以便在网络中传播梯度，从而学习长期依赖关系 |'
- en: '| Loss Function | Objective function, cost function, error | Also seen in general
    ML contexts, defines what success looks like when learning a representation, i.e.,
    a measure of difference between a neural network’s prediction and ground truth
    |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 损失函数 | 目标函数，成本函数，误差 | 在一般机器学习背景下也会见到，定义了在学习表示时成功的标准，即神经网络的预测与真实值之间的差异度量 |'
- en: '| Embedding | Encoding | Representation of input data (e.g., images, text,
    audio, time series) as vectors of numbers in a high-dimensional space; oftentimes
    reduced so data points (i.e., their vectors) can be more easily analyzed (e.g.,
    compute similarity) |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 嵌入 | 编码 | 将输入数据（例如图像、文本、音频、时间序列）表示为高维空间中的数字向量；通常会减少以便数据点（即它们的向量）可以更容易地进行分析（例如计算相似性）
    |'
- en: '| Recurrent Neural Network | RNN | Type of neural network where recurrent connections
    allow the persistence (or “memory“) of previous inputs in the network’s internal
    state which are used to influence the network output |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 循环神经网络 | RNN | 一种神经网络类型，通过递归连接允许网络内部状态中之前输入的持久性（或“记忆”），这些状态用于影响网络输出 |'
- en: '| Generative Adversarial Networks | GAN | Method to conduct unsupervised learning
    by pitting a generative network against a discriminative network; the first network
    mimics the probability distribution of a training dataset in order to fool the
    discriminative network into judging that the generated data instance belongs to
    the training set |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 生成对抗网络 | GAN | 一种通过让生成网络与判别网络对抗来进行无监督学习的方法；第一个网络模仿训练数据集的概率分布，以欺骗判别网络，使其判断生成的数据实例属于训练集
    |'
- en: '| Epoch | Data pass | A complete pass through a given dataset; by the end of
    one epoch, a neural network will have seen every datum within the dataset once
    |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 训练轮次 | 数据遍历 | 完整遍历给定数据集的过程；在一个训练轮次结束时，神经网络将每个数据都见过一次 |'
- en: 4 Why Visualize Deep Learning
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 为什么要可视化深度学习
- en: 4.1 Interpretability & Explainability
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 解释性与可解释性
- en: The most abundant, and to some, the most important reason why people want to
    visualize deep learning is to understand how deep learning models make decisions
    and what representations they have learned, so we can place trust in a model [[60](#bib.bib60)].
    This notion of general model understanding has been called the interpretability
    or explainability when referring to machine learning models [[60](#bib.bib60),
    [61](#bib.bib61), [62](#bib.bib62)]. However, neural networks particularly suffer
    from this problem since oftentimes real world and high-performance models contain
    a large number of parameters (in the millions) and exhibit extreme internal complexity
    by using many non-linear transformations at different stages during training.
    Many works motivate this problem by using phrases such as “opening and peering
    through the black-box,” “transparency,” and “interpretable neural networks,” [[13](#bib.bib13),
    [63](#bib.bib63), [56](#bib.bib56)], referring the internal complexity of neural
    networks.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 人们希望可视化深度学习的最主要原因之一，是为了理解深度学习模型如何做出决策以及它们学到了什么表示，这样我们才能对模型建立信任[[60](#bib.bib60)]。这种对模型的通用理解的概念被称为解释性或可解释性，在提到机器学习模型时[[60](#bib.bib60),
    [61](#bib.bib61), [62](#bib.bib62)]。然而，神经网络尤其面临这个问题，因为实际世界中的高性能模型通常包含大量参数（数百万个），并通过在训练过程中的不同阶段使用许多非线性变换而展现出极端的内部复杂性。许多研究通过使用“打开并窥视黑箱”、“透明度”和“可解释的神经网络”等短语来激励这个问题[[13](#bib.bib13),
    [63](#bib.bib63), [56](#bib.bib56)]，这些短语指的是神经网络的内部复杂性。
- en: 4.1.1 Discordant Definitions for Interpretability
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 解释性定义的分歧
- en: Unfortunately, there is no universally formalized and agreed upon definition
    for explainability and interpretability in deep learning, which makes classifying
    and qualifying interpretations and explanations troublesome. In Lipton’s work
    “The Mythos of Model Interpretability [[60](#bib.bib60)],” he surveys interpretability-related
    literature, and discovers diverse motivations for why interpretability is important
    and is occasionally discordant. Despite this ambiguity, he attempts to refine
    the notion of interpretability by making a first step towards providing a comprehensive
    taxonomy of both the desiderata and methods in interpretability research. One
    important point that Lipton makes is the difference between interpretability and
    an explanation; an explanation can show predictions without elucidating the mechanisms
    by which models work [[60](#bib.bib60)].
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，深度学习中的解释性和可解释性没有普遍正式化和达成一致的定义，这使得对解释和说明的分类和定性变得麻烦。在Lipton的工作《模型解释性的神话[[60](#bib.bib60)]》中，他调查了与解释性相关的文献，并发现了对解释性为何重要的不同动机，并且这些动机有时不一致。尽管存在这种模糊性，他试图通过迈出第一步来提供解释性研究中愿望和方法的综合分类，来细化解释性的概念。Lipton指出的一个重要点是解释性与解释之间的区别；解释可以展示预测结果，但不能阐明模型工作的机制[[60](#bib.bib60)]。
- en: In another work originally presented as a tutorial at the International Conference
    on Acoustics, Speech, and Signal Processing by Montavona et al. [[61](#bib.bib61)],
    the authors propose exact definitions of both an interpretation and an explanation.
    First, an interpretation is “the mapping of an abstract concept (e.g., a predicted
    class) into a domain that the human can make sense of.” They then provide some
    examples of interpretable domains, such as images (arrays of pixels) and text
    (sequences of words), and noninterpretable domains, such as abstract vector spaces
    (word embeddings). Second, an explanation is “the collection of features of the
    interpretable domain, that have contributed for a given example to produce a decision
    (e.g., classification or regression).” For example, an explanation can be a heatmap
    highlighting which pixels of the input image most strongly support an image classification
    decision, or in natural language processing, explanations can highlight certain
    phrases of text.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一篇最初作为教程在国际声学、语音和信号处理会议上由Montavona等人[[61](#bib.bib61)]提出的工作中，作者提出了对解释和说明的精确定义。首先，解释是“将一个抽象概念（例如，预测类别）映射到一个人类能够理解的领域。”
    然后，他们提供了一些可解释领域的例子，如图像（像素数组）和文本（单词序列），以及不可解释领域的例子，如抽象向量空间（词嵌入）。其次，说明是“可解释领域的特征集合，这些特征对给定示例的决策（例如，分类或回归）产生了贡献。”
    例如，说明可以是一个热图，突出显示输入图像中哪些像素最强烈地支持图像分类决策，或者在自然语言处理过程中，说明可以突出某些文本短语。
- en: 'However, both of the previous works are written by members of the AI community,
    whereas work by Miller titled “Explanation in Artificial Intelligence: Insights
    from the Social Sciences” [[62](#bib.bib62)] postulates that much of the current
    research uses only AI researchers’ intuition of what constitutes a “good” explanation.
    He suggests that if the focus on explaining decisions or actions to a human observer
    is the goal, then if these techniques are to succeed, the explanations they generate
    should have a structure that humans accept. Much of Miller’s work highlights vast
    and valuable bodies of research in philosophy, psychology, and cognitive science
    for how people define, generate, select, evaluate, and present explanations, and
    he argues that interpretability and explainability research should leverage and
    build upon this history [[62](#bib.bib62)]. In another essay, Offert [[64](#bib.bib64)]
    argues that to make interpretability more rigorous, we must first identify where
    it is impaired by intuitive considerations. That is, we have to “consider it precisely
    in terms of what it is not.” While multiple works bring different perspectives,
    Lipton makes the keen observation that for the field to progress, the community
    must critically engage with this problem formulation issue [[60](#bib.bib60)].
    Further research will help solidify the notions of interpretation and explanation.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，前述的工作都由AI领域的成员撰写，而Miller的工作《人工智能中的解释：社会科学的见解》[[62](#bib.bib62)]则假设目前的大部分研究仅使用AI研究人员对“良好”解释的直觉。他建议，如果目标是向人类观察者解释决策或行为，那么如果这些技术要成功，它们生成的解释应具有被人类接受的结构。Miller的许多工作突出了哲学、心理学和认知科学中有关人们如何定义、生成、选择、评估和呈现解释的大量宝贵研究，他认为可解释性和解释性研究应当利用并基于这一历史[[62](#bib.bib62)]。在另一篇文章中，Offert[[64](#bib.bib64)]认为，为了使可解释性更为严格，我们必须首先识别它在直觉考量下的缺陷。也就是说，我们必须“准确地考虑它是什么而不是它是什么。”
    虽然多个研究带来了不同的视角，但Lipton敏锐地观察到，为了推动该领域的发展，社区必须批判性地参与这一问题的制定[[60](#bib.bib60)]。进一步的研究将有助于巩固解释和说明的概念。
- en: 4.1.2 Interpretation as Qualitative Support for Model Evaluation in Various
    Application Domains
  id: totrans-179
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2 解释作为各种应用领域模型评估的定性支持
- en: While research into interpretation itself is relatively new, its impact has
    already been seen in applied deep learning contexts. A number of applied data
    science and AI projects that use deep learning models include a section on interpretation
    to qualitatively evaluate and support the model’s predictions and the work’s claims
    overall. An example of this is an approach for end-to-end neural machine translation.
    In the work by Johnson et al. [[65](#bib.bib65)], the authors present a simple
    and efficient way to translate between multiple languages using a single model,
    taking advantage of multilingual data to improve neural machine translation for
    all languages involved. The authors visualize an embedding of text sequences,
    for example, sentences from multiple languages, to support and hint at a universal
    interlingua representation. Another work that visualizes large machine learning
    embeddings is by Zahavy et al. [[56](#bib.bib56)], where the authors analyze deep
    Q-networks (DQN), a popular reinforcement learning model, to understand and describe
    the policies learned by DQNs for three different Atari 2600 video games. An application
    for social good by Robinson et al. [[49](#bib.bib49)] demonstrates how to apply
    deep neural networks on satellite imagery to perform population prediction and
    disaggregation, jointly answering the questions “where do people live?” and “how
    many people live there?”. In general, they show how their methodology can be an
    effective tool for extracting information from inherently unstructured, remotely-sensed
    data to provide effective solutions to social problems.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管对解释本身的研究相对较新，但其影响已经在应用深度学习的背景中显现出来。许多应用数据科学和人工智能项目使用深度学习模型时，包括解释部分以定性评估和支持模型的预测及整体工作的声明。例如，端到端神经机器翻译的一种方法。在Johnson等人的工作中[[65](#bib.bib65)]，作者们提出了一种简单高效的方法，利用多语言数据来改进所有涉及语言的神经机器翻译。作者们可视化文本序列的嵌入，例如来自多种语言的句子，以支持和暗示一种通用的中间语表示。另一篇可视化大型机器学习嵌入的工作是由Zahavy等人完成的[[56](#bib.bib56)]，他们分析了深度Q网络（DQN），这是一种流行的强化学习模型，用于理解和描述DQN在三款不同的Atari
    2600视频游戏中学到的策略。Robinson等人的社会公益应用[[49](#bib.bib49)]展示了如何将深度神经网络应用于卫星图像，进行人口预测和分解，共同回答“人们居住在哪里？”和“那里有多少人居住？”的问题。总体上，他们展示了他们的方法论如何成为从固有的非结构化遥感数据中提取信息的有效工具，以提供社会问题的解决方案。
- en: These are only a few domains where visualization and deep learning interpretation
    have been successfully used. Others include building trust in autonomous driving
    vehicles [[30](#bib.bib30)], explaining decisions made by medical imaging models,
    such as MRIs on brain scans, to provide medical experts more information for making
    diagnoses [[66](#bib.bib66)], and using visual analytics to explore automatically-learned
    features from street imagery to gain perspective into identity, function, demographics,
    and affluence in urban spaces, which is useful for urban design and planning [[67](#bib.bib67)].
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是可视化和深度学习解释成功应用的几个领域。其他领域包括建立对自动驾驶车辆的信任[[30](#bib.bib30)]，解释医学成像模型（如MRI在脑部扫描中的决策），为医学专家提供更多诊断信息[[66](#bib.bib66)]，以及使用视觉分析来探索从街道图像中自动学习的特征，以了解城市空间的身份、功能、人口统计和富裕度，这对城市设计和规划非常有用[[67](#bib.bib67)]。
- en: In this survey we will mention interpretation and explanation often, as they
    are the most common motivations for deep learning visualization. Later, we will
    discuss the different visualization techniques and visual analytics systems that
    focus on neural network interpretability for embeddings [[51](#bib.bib51)], text [[41](#bib.bib41),
    [40](#bib.bib40), [32](#bib.bib32)], quantifying interpretability [[28](#bib.bib28)],
    and many different image-based techniques stemming from the AI communities [[68](#bib.bib68),
    [10](#bib.bib10), [69](#bib.bib69), [4](#bib.bib4), [70](#bib.bib70)].
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次调研中，我们经常提到解释和解释，因为它们是深度学习可视化最常见的动机。稍后，我们将讨论不同的可视化技术和专注于神经网络可解释性的视觉分析系统，包括嵌入[[51](#bib.bib51)]、文本[[41](#bib.bib41),
    [40](#bib.bib40), [32](#bib.bib32)]、量化解释性[[28](#bib.bib28)]，以及源自AI社区的许多不同的基于图像的技术[[68](#bib.bib68),
    [10](#bib.bib10), [69](#bib.bib69), [4](#bib.bib4), [70](#bib.bib70)]。
- en: 4.2 Debugging & Improving Models
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 调试与改进模型
- en: Building machine learning models is an iterative design process [[71](#bib.bib71),
    [72](#bib.bib72), [73](#bib.bib73)], and developing deep neural networks is no
    different. While mathematical foundations have been laid, deep learning still
    has many open research questions. For example, finding the exact combinations
    of model depth, layer width, and finely tuned hyperparameters is nontrivial. In
    response to this, many visual analytics systems have been proposed to help model
    developers build and debug their models, with the hope of expediting the iterative
    experimentation process to ultimately improve performance [[15](#bib.bib15), [52](#bib.bib52),
    [47](#bib.bib47)]. Oftentimes this requires monitoring models during the training
    phase [[58](#bib.bib58), [42](#bib.bib42)], identifying misclassified instances
    and testing a handful of well-known data instances to observe performance [[39](#bib.bib39),
    [29](#bib.bib29), [50](#bib.bib50)], and allowing a system to suggest potential
    directions for the model developer to explore [[34](#bib.bib34)]. This reason
    for why we wish to visualize deep learning ultimately provides better tools to
    speed up model development for engineers and researchers so that they can quickly
    identify and fix problems within a model to improve overall performance.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 构建机器学习模型是一个迭代设计过程[[71](#bib.bib71), [72](#bib.bib72), [73](#bib.bib73)]，深度神经网络的开发也不例外。虽然数学基础已奠定，但深度学习仍然有许多未解的研究问题。例如，找到模型深度、层宽和精细调整的超参数的确切组合并非易事。对此，许多可视化分析系统被提出，以帮助模型开发人员构建和调试他们的模型，希望能加快迭代实验过程，从而最终提高性能[[15](#bib.bib15),
    [52](#bib.bib52), [47](#bib.bib47)]。这通常需要在训练阶段监控模型[[58](#bib.bib58), [42](#bib.bib42)]，识别误分类的实例，并测试一些著名的数据实例以观察性能[[39](#bib.bib39),
    [29](#bib.bib29), [50](#bib.bib50)]，并允许系统建议模型开发人员探索的潜在方向[[34](#bib.bib34)]。这种对可视化深度学习的需求最终为工程师和研究人员提供了更好的工具，以加快模型开发，从而迅速识别和修复模型中的问题，提升整体性能。
- en: 4.3 Comparing & Selecting Models
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 比较与选择模型
- en: While certainly related to model debugging and improvement, model comparison
    and selection are slightly different tasks in which visualization can be useful [[74](#bib.bib74),
    [75](#bib.bib75), [76](#bib.bib76)]. Oftentimes model comparison describes the
    notion of choosing a single model among an ensemble of well-performing models.
    That is, no debugging needs to be done; all models have “learned” or have been
    trained semi-successfully. Therefore, the act of selecting a single, best-performing
    model requires inspecting model metrics and visualizing parts of the model to
    pick the one that has the highest accuracy, the lowest loss, or is the most generalizable,
    while avoiding pitfalls such as memorizing training data or overfitting.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然模型比较和选择与模型调试和改进确实相关，但它们是稍有不同的任务，其中可视化可以发挥作用[[74](#bib.bib74), [75](#bib.bib75),
    [76](#bib.bib76)]。通常，模型比较涉及从一组表现良好的模型中选择一个单一模型。也就是说，不需要进行调试；所有模型已经“学习”过或已被半成功地训练。因此，选择一个表现最佳的单一模型需要检查模型指标和可视化模型的各个部分，以挑选出准确率最高、损失最低或最具泛化能力的模型，同时避免如记忆训练数据或过拟合等陷阱。
- en: Some systems take a high-level approach and compare user-defined model metrics,
    like accuracy and loss, and aggregate them on interactive charts for performance
    comparison [[27](#bib.bib27)]. Other frameworks compare neural networks trained
    on different random initializations (an important step in model design) to discover
    how they would affect performance, while also quantifying performance and interpretation [[28](#bib.bib28)].
    Some approaches compare models on image generation techniques, such as performing
    image reconstruction from the internal representations of each layer of different
    networks to compare different network architectures [[77](#bib.bib77)]. Similar
    to comparing model architectures, some systems solely rely on data visualization
    representations and encodings to compare models [[43](#bib.bib43)], while others
    compare different snapshots of a single model as it trains over time, i.e., comparing
    a model after $n_{1}$ epochs and the same model after $n_{2}$ epochs of training
    time [[57](#bib.bib57)].
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 一些系统采用高级方法，比较用户定义的模型指标，如准确率和损失，并在交互式图表上汇总这些指标以进行性能比较[[27](#bib.bib27)]。其他框架比较在不同随机初始化下训练的神经网络（模型设计中的一个重要步骤），以发现它们如何影响性能，同时量化性能和解释[[28](#bib.bib28)]。有些方法比较图像生成技术中的模型，例如从不同网络的每层的内部表示中进行图像重建，以比较不同的网络架构[[77](#bib.bib77)]。类似于比较模型架构，一些系统仅依赖于数据可视化表示和编码来比较模型[[43](#bib.bib43)]，而其他系统比较单个模型在训练过程中的不同快照，即比较模型在$n_{1}$个周期后的状态和在$n_{2}$个周期后的状态[[57](#bib.bib57)]。
- en: 4.4 Teaching Deep Learning Concepts
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 教授深度学习概念
- en: 'Apart from AI experts, another important reason why we may wish to visualize
    deep learning is to educate non-expert users about AI. The exact definition of
    non-experts varies by source and is discussed further in Section [5.3](#S5.SS3
    "5.3 Non-experts ‣ 5 Who Uses Deep Learning Visualization ‣ Visual Analytics in
    Deep Learning: An Interrogative Survey for the Next Frontiers"). An example that
    targets the general public is Teachable Machines [[54](#bib.bib54)], a web-based
    AI experiment that explores and teaches the foundations of an image classifier.
    Users train a three-way image classifier by using their computer’s webcam to generate
    the training data. After providing three different examples of physical objects
    around the user (e.g., holding up a pencil, a coffee mug, and a phone), the system
    then performs real-time inference on whichever object is in view of the webcam,
    and shows a bar chart with the corresponding classification scores. Since inference
    is computed in real-time, the bar charts wiggles and jumps back and forth as the
    user removes an object, say the pencil, from the view and instead holds up the
    coffee mug. The visualization used is a simple bar chart, which provides an approachable
    introduction into image classification, a modern-day computer vision and AI problem.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '除了AI专家之外，我们可能希望可视化深度学习的另一个重要原因是为了教育非专家用户关于AI的知识。非专家的具体定义因来源而异，并在第[5.3](#S5.SS3
    "5.3 Non-experts ‣ 5 Who Uses Deep Learning Visualization ‣ Visual Analytics in
    Deep Learning: An Interrogative Survey for the Next Frontiers")节中进一步讨论。一个针对普通公众的例子是Teachable
    Machines[[54](#bib.bib54)]，这是一个基于Web的AI实验，探索并教授图像分类器的基础知识。用户通过使用计算机的摄像头生成训练数据来训练一个三分类图像分类器。在提供三种不同的物体示例（例如，举起一支铅笔、一杯咖啡和一部手机）之后，系统会对摄像头视野中的物体进行实时推理，并显示一个带有相应分类得分的条形图。由于推理是实时计算的，因此当用户移除物体（例如铅笔）并改为举起咖啡杯时，条形图会摇摆并前后跳动。使用的可视化是一个简单的条形图，它提供了对图像分类的易于接近的介绍，这是一个现代计算机视觉和AI问题。'
- en: Another example for teaching deep learning concepts, the Deep Visualization
    Toolbox [[55](#bib.bib55)] discussed later in this survey, also uses a webcam
    for instant feedback when interacting with a neural network. Taking instantaneous
    feedback a step further, some works have used direct manipulation to engage non-experts
    in the learning process. TensorFlow Playground [[16](#bib.bib16)], a robust, web-based
    visual analytics tool for exploring simple neural networks, uses direct manipulation
    to reinforce deep learning concepts, and importantly, evokes the user’s intuition
    about how neural networks work. Other non-traditional mediums have been used to
    teach deep learning concepts and build an intuition for how neural networks behave
    too. Longform, interactive scrollytelling works focusing on particular AI topics
    that use interactive visualizations as supporting evidence are gaining popularity.
    Examples include “How to Use t-SNE Effectively,” where users can play with hundreds
    of small datasets and vary single parameters to observe their effect on an embedding
     [[78](#bib.bib78)], and a similar interactive article titled “Visualizing MNIST”
    that visualizes different types of embeddings produced by different algorithms [[45](#bib.bib45)].
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 作为教授深度学习概念的另一个例子，深度可视化工具箱[[55](#bib.bib55)]，在本次调查中稍后讨论，也使用了网络摄像头以便在与神经网络交互时提供即时反馈。在即时反馈的基础上，有些工作进一步利用直接操控来吸引非专家参与学习过程。TensorFlow
    Playground [[16](#bib.bib16)] 是一个稳健的基于网络的视觉分析工具，用于探索简单的神经网络，它通过直接操控来强化深度学习概念，并且重要的是，引发用户对神经网络如何工作的直觉。其他非传统媒介也被用于教授深度学习概念，并建立对神经网络行为的直觉。以交互式滚动叙事为重点，关注特定
    AI 主题并使用互动可视化作为支持证据的长篇形式正在获得越来越多的关注。例如，“如何有效使用 t-SNE”，用户可以玩转数百个小数据集并调整单个参数以观察其对嵌入的影响[[78](#bib.bib78)]，以及一个类似的交互式文章
    titled “Visualizing MNIST”，它可视化了不同算法生成的不同类型的嵌入[[45](#bib.bib45)]。
- en: 5 Who Uses Deep Learning Visualization
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 谁在使用深度学习可视化
- en: 'This section describes the groups of people who may stand to benefit from deep
    learning visualization and visual analytics. We loosely organize them into three
    non-mutually exclusive groups by their level of deep learning knowledge (most
    to least): model developers, model users, and non-experts. Note that many of the
    works discussed can benefit multiple groups, e.g., a model developer may use a
    tool aimed at non-experts to reinforce their own intuition for how neural networks
    learn.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了可能从深度学习可视化和视觉分析中获益的人员群体。我们将他们根据深度学习知识水平（从多到少）大致分为三个不相互排斥的群体：模型开发者、模型用户和非专家。请注意，许多讨论中的工作可以惠及多个群体，例如，模型开发者可以使用旨在非专家的工具来加强自己对神经网络学习方式的直觉。
- en: 5.1 Model Developers & Builders
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 模型开发者与构建者
- en: The first group of people who use deep learning visualization are individuals
    whose job is primarily focused on developing, experimenting with, and deploying
    deep neural networks. These model developers and builders, whether they are researchers
    or engineers, have a strong understanding of deep learning techniques and a well-developed
    intuition surrounding model building. Their knowledge expedites key decisions
    in deep learning workflows, such as identifying the which types of models perform
    best on which types of data. These individuals wield mastery over models, e.g.,
    knowing how to vary hyperparameters in the right fashion to achieve better performance.
    These individuals are typically seasoned in building large-scale models and training
    them on high-performance machines to solve real-world problems [[24](#bib.bib24)].
    Therefore, tooling and research for these users is much more technically focused,
    e.g., exposing many hyperparameters for detailed model control.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 使用深度学习可视化的第一组人是那些主要从事开发、实验和部署深度神经网络的个体。这些模型开发者和构建者，无论是研究人员还是工程师，都对深度学习技术有深刻的理解，并且在模型构建方面拥有较为成熟的直觉。他们的知识加速了深度学习工作流程中的关键决策，例如识别哪种类型的模型在何种数据上表现最佳。这些人掌握模型的使用，例如，知道如何以正确的方式调整超参数以实现更好的性能。这些个体通常在构建大规模模型并在高性能计算机上进行训练，以解决现实世界的问题方面经验丰富[[24](#bib.bib24)]。因此，这些用户的工具和研究更多地集中在技术层面，例如，提供许多超参数以实现详细的模型控制。
- en: 'Of the existing deep learning visual analytics tools published, a handful tackle
    the problem of developing tools for model developers, but few have seen widespread
    adoption. Arguably the most well-known system is TensorBoard [[27](#bib.bib27)]:
    Google’s included open-source visualization platform for its dataflow graph library
    TensorFlow. TensorBoard includes a number of built-in components to help model
    developers understand, debug, and optimize TensorFlow programs. It includes real-time
    plotting of quantitative model metrics during training, instance-level predictions,
    and a visualization of the computational graph. The computational graph component
    was published separately by Wongsuphasawat et al. [[15](#bib.bib15)] and works
    by applying a series of graph transformations that enable standard layout techniques
    to produce interactive diagrams of TensorFlow models.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在现有的深度学习视觉分析工具中，一些工具解决了为模型开发者开发工具的问题，但很少有工具得到了广泛采用。可以说，最著名的系统是 TensorBoard [[27](#bib.bib27)]：Google
    提供的开源可视化平台，用于其数据流图库 TensorFlow。TensorBoard 包含多个内置组件，帮助模型开发者理解、调试和优化 TensorFlow
    程序。它包括实时绘制定量模型指标、实例级预测以及计算图的可视化。计算图组件由 Wongsuphasawat 等人 [[15](#bib.bib15)] 单独发布，通过应用一系列图形变换，使标准布局技术能够生成
    TensorFlow 模型的交互式图表。
- en: Other tools, such as DeepEyes [[47](#bib.bib47)], assist in a number of model
    building tasks, e.g., identifying stable layers during the training process, identifying
    unnecessary layers and degenerated filters that do not contribute to a model’s
    decisions, pruning such entities, and identifying patterns undetected by the network,
    indicating that more filters or layers may be needed. Another tool, Blocks [[29](#bib.bib29)],
    allows a model builder to accelerate model convergence and alleviate overfitting,
    through visualizing class-level confusion patterns. Other research has developed
    new metrics beyond measures like loss and accuracy, to help developers inspect
    and evaluate networks while training them [[58](#bib.bib58)].
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 其他工具，如 DeepEyes [[47](#bib.bib47)]，在模型构建任务中提供帮助，例如识别训练过程中的稳定层、识别对模型决策没有贡献的多余层和退化滤波器、修剪这些实体，以及识别网络未检测到的模式，提示可能需要更多的滤波器或层。另一个工具，Blocks [[29](#bib.bib29)]，通过可视化类别级混淆模式，帮助模型构建者加速模型收敛并减轻过拟合。其他研究则开发了超越损失和准确率等指标的新度量，帮助开发者在训练模型时检查和评估网络 [[58](#bib.bib58)]。
- en: 'Some tools also address the inherent iterative nature of training neural networks.
    For example, ML-o-scope [[31](#bib.bib31)] utilizes a time-lapse engine to inspect
    a model’s training dynamics to better tune hyperparameters, while work by Chae
    et al. [[34](#bib.bib34)] visualizes classification results during training and
    suggests potential directions to improve performance in the model building pipeline.
    Lastly, visual analytics tools are beginning to be built for expert users who
    wish to use models that are more challenging to work with. For example, DGMTracker [[42](#bib.bib42)]
    is a visual analytics tool built to help users understand and diagnose the training
    process of deep generative models: powerful networks that perform unsupervised
    and semi-supervised learning where the primary focus is to discover the hidden
    structure of data without resorting to external labels.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 一些工具还解决了训练神经网络固有的迭代性质。例如，ML-o-scope [[31](#bib.bib31)] 利用时间推移引擎检查模型的训练动态，以更好地调整超参数，而
    Chae 等人 [[34](#bib.bib34)] 的工作可视化了训练过程中的分类结果，并建议改进模型构建流程的潜在方向。最后，视觉分析工具开始为希望使用更具挑战性的模型的专家用户构建。例如，DGMTracker [[42](#bib.bib42)]
    是一个视觉分析工具，旨在帮助用户理解和诊断深度生成模型的训练过程：这些强大的网络执行无监督和半监督学习，主要关注发现数据的隐藏结构，而无需依赖外部标签。
- en: '![Refer to caption](img/49c0a4f817d1624fb9ccb7a75a4aa2bc.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/49c0a4f817d1624fb9ccb7a75a4aa2bc.png)'
- en: 'Figure 2: ActiVis [[39](#bib.bib39)]: a visual analytics system for interpreting
    neural network results using a novel visualization that unifies instance- and
    subset-level inspections of neuron activations deployed at Facebook.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：ActiVis [[39](#bib.bib39)]：一个用于解释神经网络结果的视觉分析系统，使用一种新颖的可视化方法，将实例级和子集级的神经元激活检查统一起来，该系统在
    Facebook 部署。
- en: 5.2 Model Users
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 模型用户
- en: The second group of people who may benefit from deep learning visualization
    are model users. These are users who may have some technical background but are
    neural network novices. Common tasks include using well-known neural network architectures
    for developing domain specific applications, training smaller-scale models, and
    downloading pre-trained model weights online to use as a starting point. This
    group of users also include machine learning artists who use models to enable
    and showcase new forms of artistic expression.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 可能从深度学习可视化中受益的第二类人群是模型用户。这些用户可能有一些技术背景，但对神经网络是新手。常见任务包括使用知名神经网络架构开发领域特定应用、训练小规模模型以及在线下载预训练模型权重以作为起点。这个用户群体还包括使用模型来实现和展示新的艺术表达形式的机器学习艺术家。
- en: 'An example visual analytics system for these model users is ActiVis [[39](#bib.bib39)]:
    a visual analytics system for interpreting the results of neural networks by using
    a novel visual representation that unifies instance- and subset-level inspections
    of neuron activations. Model users can flexibly specify subsets using input features,
    labels, or any intermediate outcomes in a machine learning pipeline. ActiVis was
    built for engineers and data scientists at Facebook to explore and interpret deep
    learning models results and is deployed on Facebook’s internal system. LSTMVis [[52](#bib.bib52)]
    is a visual analysis tool for recurrent neural networks with a focus on understanding
    hidden state dynamics in sequence modeling. The tool allows model users to perform
    hypothesis testing by selecting an input range to focus on local state changes,
    then to match these states changes to similar patterns in a large dataset, and
    finally align the results with structural annotations. The LSTMVis work describes
    three types of users: architects, those who wish to develop new deep learning
    methodologies; trainers, those who wish to apply LSTMs to a task in which they
    are domain experts in; and end users, those who use pretrained models for various
    tasks. Lastly, Embedding Projector [[51](#bib.bib51)], while not specifically
    deep learning exclusive, is a visual analytics tool to support interactive visualization
    and interpretation of large-scale embeddings, which are common outputs from neural
    network models. The work presents three important tasks that model users often
    perform while using embeddings; these include exploring local neighborhoods, viewing
    the global geometry to find clusters, and finding meaningful directions within
    an embedding.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 一个针对这些模型用户的示例视觉分析系统是 ActiVis [[39](#bib.bib39)]：这是一个用于解释神经网络结果的视觉分析系统，采用了一种新的视觉表示方法，统一了对神经元激活的实例级和子集级检查。模型用户可以灵活地使用输入特征、标签或机器学习流程中的任何中间结果来指定子集。ActiVis
    是为 Facebook 的工程师和数据科学家构建的，用于探索和解释深度学习模型的结果，并部署在 Facebook 的内部系统上。LSTMVis [[52](#bib.bib52)]
    是一个针对递归神经网络的视觉分析工具，重点在于理解序列建模中的隐藏状态动态。该工具允许模型用户通过选择输入范围来集中关注局部状态变化，然后将这些状态变化与大型数据集中的类似模式匹配，最后将结果与结构注释对齐。LSTMVis
    的工作描述了三种用户类型：架构师，即那些希望开发新的深度学习方法的人；训练者，即那些希望将 LSTM 应用于他们所在领域任务的人；以及终端用户，即那些使用预训练模型进行各种任务的人。最后，Embedding
    Projector [[51](#bib.bib51)]，虽然并不专门用于深度学习，但它是一个支持大规模嵌入交互可视化和解释的工具，这些嵌入是神经网络模型的常见输出。该工作提出了模型用户在使用嵌入时经常执行的三项重要任务；包括探索局部邻域、查看全球几何以查找集群以及在嵌入中找到有意义的方向。
- en: 5.3 Non-experts
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 非专家
- en: The third group of people whom visualization could aid are non-experts in deep
    learning. These are individuals who typically have no prior knowledge about deep
    learning, and may or may not have a technical background. Much of the research
    targeted at this group is for educational purposes, trying to explain what a neural
    network is and how it works at a high-level, sometimes without revealing deep
    learning is present. These group also includes people who simply use AI-powered
    devices and consumer applications.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 第三类可能从可视化中受益的人群是深度学习的非专家。这些人通常对深度学习没有先验知识，并且可能有也可能没有技术背景。针对这个人群的大部分研究是为了教育目的，试图高层次地解释什么是神经网络以及它如何工作，有时不揭示深度学习的存在。这个群体还包括那些仅仅使用
    AI 驱动的设备和消费应用的人。
- en: 'Apart from Teachable Machines [[54](#bib.bib54)] and the Deep Visualization
    Toolbox [[55](#bib.bib55)] mentioned in Section [4.4](#S4.SS4 "4.4 Teaching Deep
    Learning Concepts ‣ 4 Why Visualize Deep Learning ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers"), TensorFlow Playground [[16](#bib.bib16)],
    a web-based interactive visualization of a simple dense network, has become a
    go-to tool for gaining intuition about how neural networks learn. TensorFlow Playground
    uses direct manipulation experimentation rather than coding, enabling users to
    quickly build an intuition about neural networks. The system has been used to
    teach students about foundational neural network properties by using “living lessons,”
    and also makes it straightforward to create a dynamic, interactive educational
    experience. Another web-browser based system, ShapeShop [[38](#bib.bib38)], allows
    users to explore and understand the relationship between input data and a network’s
    learned representations. ShapeShop uses a feature visualization technique called
    class activation maximization to visualize specific classes of an image classifier.
    The system allows users to interactively select classes from a collection of simple
    shapes, select a few hyperparameters, train a model, and view the generated visualizations
    all in real-time.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '除了第[4.4](#S4.SS4 "4.4 Teaching Deep Learning Concepts ‣ 4 Why Visualize Deep
    Learning ‣ Visual Analytics in Deep Learning: An Interrogative Survey for the
    Next Frontiers")节中提到的Teachable Machines [[54](#bib.bib54)] 和 Deep Visualization
    Toolbox [[55](#bib.bib55)]外，TensorFlow Playground [[16](#bib.bib16)]，这是一个基于网页的简单密集网络的互动可视化工具，已经成为理解神经网络学习方式的首选工具。TensorFlow
    Playground 使用直接操作实验而非编码，使用户能够快速建立对神经网络的直觉。该系统已被用于通过“活的课程”向学生教授基础神经网络特性，并且使创建动态、互动的教育体验变得简单。另一个基于网页的系统ShapeShop [[38](#bib.bib38)]允许用户探索和理解输入数据与网络学习表示之间的关系。ShapeShop
    使用一种称为类激活最大化的特征可视化技术来可视化图像分类器的特定类别。该系统允许用户从一组简单形状中交互选择类别，选择几个超参数，训练模型，并实时查看生成的可视化。'
- en: Tools built for non-experts, particularly with an educational focus, are becoming
    more popular on the web. A number of web-based JavaScript frameworks for training
    neural networks and inference have been developed; however, ConvNetJS ([http://cs.stanford.edu/people/karpathy/convnetjs/](http://cs.stanford.edu/people/karpathy/convnetjs/))
    and TensorFlow.js ([https://js.tensorflow.org/](https://js.tensorflow.org/)) are
    the most used and have enabled developers to create highly interactive explorable
    explanations for deep learning models.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 针对非专家，特别是具有教育性质的工具在网络上越来越受欢迎。开发了一些基于网页的JavaScript框架用于训练神经网络和推理；然而，ConvNetJS
    ([http://cs.stanford.edu/people/karpathy/convnetjs/](http://cs.stanford.edu/people/karpathy/convnetjs/))
    和 TensorFlow.js ([https://js.tensorflow.org/](https://js.tensorflow.org/)) 是使用最广泛的，它们使开发者能够创建高度互动的可探索性解释以便于深度学习模型。
- en: 6 What to Visualize in Deep Learning
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 深度学习中的可视化内容
- en: 'This section discusses the technical components of neural networks that could
    be visualized. This section is strongly related to the next section, Section [7](#S7
    "7 How to Visualize Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative
    Survey for the Next Frontiers") “How,” which describes how the components of these
    networks are visualized in existing work. By first describing what may be visualized
    (this section), we can more easily ground our discussion on how to visualize them
    (next section).'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '本节讨论了神经网络中可以可视化的技术组件。本节与下一节，即第[7](#S7 "7 How to Visualize Deep Learning ‣ Visual
    Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers")节“如何”紧密相关，该节描述了这些网络组件在现有工作中的可视化方式。通过首先描述可能的可视化内容（本节），我们可以更容易地为如何可视化它们（下一节）的讨论奠定基础。'
- en: 6.1 Computational Graph & Network Architecture
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 计算图与网络架构
- en: 'The first thing that can be visualized in a deep learning model is the model
    architecture. This includes the computational graph that defines how a neural
    network model would train, test, save data to disk, and checkpoint after epoch
    iterations [[27](#bib.bib27)]. Also called the dataflow graph [[27](#bib.bib27)],
    this defines how data flows from operation to operation to successfully train
    and use a model. This is different than the neural network’s edges and weights,
    discussed next, which are the parameters to be tweaked during training. The dataflow
    graph can be visualized to potentially inform model developers of the types of
    computations occurring within their model, as discussed in Section [7.1](#S7.SS1
    "7.1 Node-link Diagrams for Network Architectures ‣ 7 How to Visualize Deep Learning
    ‣ Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers").'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '深度学习模型中可以视觉化的第一件事是模型架构。这包括定义神经网络模型如何训练、测试、保存数据到磁盘以及在迭代周期后进行检查点的计算图[[27](#bib.bib27)]。也称为数据流图[[27](#bib.bib27)]，它定义了数据如何从一个操作流向另一个操作，以成功训练和使用模型。这不同于神经网络的边缘和权重，后者是训练过程中要调整的参数。数据流图的视觉化可以潜在地帮助模型开发者了解其模型中发生的计算类型，如第[7.1](#S7.SS1
    "7.1 Node-link Diagrams for Network Architectures ‣ 7 How to Visualize Deep Learning
    ‣ Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers")节所述。'
- en: 6.2 Learned Model Parameters
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 学习到的模型参数
- en: Other components that can be visualized are the learned parameters in the network
    during and after training.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 其他可以被视觉化的组件是网络在训练过程中及之后学习到的参数。
- en: 6.2.1 Neural Network Edge Weights
  id: totrans-213
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1 神经网络边缘权重
- en: 'Neural network models are built of many, and sometimes diverse, constructions
    of layers of computational units [[26](#bib.bib26)]. These layers send information
    throughout the network by using edges that connect layers to one another, oftentimes
    in a linear manner, yet some more recent architectures have shown that skipping
    certain layers and combining information in unique ways can lead to better performance.
    Regardless, each node has an outgoing edge with an accompanying weight that sends
    signal from one neuron in a layer to potentially thousands of neurons in an adjacent
    layer [[16](#bib.bib16)]. These are the parameters that are tweaked during the
    backpropagation phase of training a deep model, and could be worthwhile to visualize
    for understanding what the model has learned, as seen in Section [7.1](#S7.SS1
    "7.1 Node-link Diagrams for Network Architectures ‣ 7 How to Visualize Deep Learning
    ‣ Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers").'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '神经网络模型由许多，且有时是多样化的计算单元层构成[[26](#bib.bib26)]。这些层通过连接层与层之间的边缘来传递信息，通常是线性的方式，但一些较新的架构已经表明，跳过某些层并以独特的方式结合信息可以提高性能。无论如何，每个节点都有一个带权重的外发边缘，该边缘将信号从层中的一个神经元传递到相邻层中可能有数千个神经元[[16](#bib.bib16)]。这些是训练深度模型时在反向传播阶段调整的参数，视觉化这些参数可能有助于理解模型所学习的内容，如第[7.1](#S7.SS1
    "7.1 Node-link Diagrams for Network Architectures ‣ 7 How to Visualize Deep Learning
    ‣ Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers")节所示。'
- en: 6.2.2 Convolutional Filters
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.2 卷积滤波器
- en: 'Convolutional neural networks are built using a particular type of layer, aptly
    called the convolutional layer. These convolutional layers apply filters over
    the input data, oftentimes images represented as a two-dimensional matrix of values,
    to generate smaller representations of the data to pass to later layers in the
    network. These filters, like the previously mentioned traditional weights, are
    then updated throughout the training process, i.e., learned by the network, to
    support a given task. Therefore, visualizing the learned filters could be useful
    as an alternate explanation for what a model has learned [[10](#bib.bib10), [55](#bib.bib55)],
    as seen in Section [7.6](#S7.SS6 "7.6 Algorithms for Attribution & Feature Visualization
    ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative
    Survey for the Next Frontiers").'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '卷积神经网络是通过一种特定类型的层构建的，这种层被称为卷积层。这些卷积层对输入数据应用滤波器，通常是表示为二维矩阵的图像，以生成更小的数据表示并传递给网络中的后续层。这些滤波器，像之前提到的传统权重一样，在训练过程中会被更新，即被网络学习，以支持特定任务。因此，视觉化已学习的滤波器可能作为模型已学习内容的替代解释是有用的[[10](#bib.bib10),
    [55](#bib.bib55)]，如第[7.6](#S7.SS6 "7.6 Attribution & Feature Visualization ‣ 7
    How to Visualize Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative
    Survey for the Next Frontiers")节所示。'
- en: 6.3 Individual Computational Units
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 个体计算单元
- en: Albeit reductionist, neural networks can be thought as a collection of layers
    of neurons connected by edge weights. Above, we discussed that the edges can be
    visualized, but the neurons too can be a source of data to investigate.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管具有还原主义特征，神经网络可以被看作是由边权重连接的神经元层的集合。如上所述，边缘可以被可视化，但神经元也可以成为调查数据的来源。
- en: 6.3.1 Activations
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.1 激活
- en: 'When given a trained model, one can perform inference on the model using a
    new data instance to obtain the neural network’s output, e.g., a classification
    or a specific predicted value. Throughout the network, the neurons compute activations
    using activation functions (e.g., weighted sum) to combine the signal from the
    previous layer into a new node [[26](#bib.bib26), [55](#bib.bib55)]. This mapping
    is one of the characteristics that allows a neural network to learn. During inference,
    we can recover the activations produced at each layer. We can use activations
    in multiple ways, e.g., as a collection of individual neurons, spatial positions,
    or channels [[46](#bib.bib46)]. Although these feature representations are typically
    high-dimensional vectors of the input data at a certain stage within the network [[46](#bib.bib46)],
    it could be valuable in helping people visualize how input data is transformed
    into higher-level features, as seen in Section [7.2](#S7.SS2 "7.2 Dimensionality
    Reduction & Scatter Plots ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics
    in Deep Learning: An Interrogative Survey for the Next Frontiers"). Feature representations
    may also shed light upon how the network and its components respond to particular
    data instances [[55](#bib.bib55)], commonly called instance-level observation;
    we will discuss this in detail in Section [7.4](#S7.SS4 "7.4 Instance-based Analysis
    & Exploration ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers") and [7.5](#S7.SS5 "7.5 Interactive
    Experimentation ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics in Deep
    Learning: An Interrogative Survey for the Next Frontiers").'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定一个训练好的模型时，可以使用新的数据实例对模型进行推断，以获得神经网络的输出，例如分类结果或特定的预测值。在整个网络中，神经元使用激活函数（例如加权和）计算激活，将来自前一层的信号组合成一个新的节点[[26](#bib.bib26),
    [55](#bib.bib55)]。这种映射是神经网络学习的特征之一。在推断过程中，我们可以恢复在每一层产生的激活。我们可以以多种方式使用激活，例如作为单个神经元的集合、空间位置或通道[[46](#bib.bib46)]。尽管这些特征表示通常是网络中某一阶段的输入数据的高维向量[[46](#bib.bib46)]，但它们可能有助于帮助人们可视化输入数据如何转化为更高级别的特征，如在第[7.2节](#S7.SS2
    "7.2 降维与散点图 ‣ 7 深度学习的可视化 ‣ 深度学习中的视觉分析：下一前沿的调查")所见。特征表示也可能揭示网络及其组件如何响应特定的数据实例[[55](#bib.bib55)]，这通常被称为实例级观察；我们将在第[7.4节](#S7.SS4
    "7.4 基于实例的分析与探索 ‣ 7 深度学习的可视化 ‣ 深度学习中的视觉分析：下一前沿的调查")和[7.5节](#S7.SS5 "7.5 交互实验 ‣
    7 深度学习的可视化 ‣ 深度学习中的视觉分析：下一前沿的调查")中详细讨论。
- en: 6.3.2 Gradients for Error Measurement
  id: totrans-221
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.2 错误测量的梯度
- en: 'To train a neural network, we commonly use a process known as backpropagation [[26](#bib.bib26)].
    Backpropagation, or sometimes called the backpropagation of errors, is a method
    to calculate the gradient of a specified loss function. When used in combination
    with an optimization algorithm, e.g., gradient descent, we can compute the error
    at the output layer of a neural network and redistribute the error by updating
    the model weights using the computed gradient. These gradients flow over the same
    edges defined in the network that contain the weights, but flow in the opposite
    direction., e.g., from the output layer to the input layer. Therefore, it could
    be useful to visualize the gradients of a network to see how much error is produced
    at certain outputs and where it is distributed [[35](#bib.bib35), [33](#bib.bib33)],
    as mentioned in Section [7.6](#S7.SS6 "7.6 Algorithms for Attribution & Feature
    Visualization ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers").'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '训练神经网络时，我们通常使用一种称为反向传播的过程[[26](#bib.bib26)]。反向传播，或有时称为误差反向传播，是一种计算指定损失函数梯度的方法。当与优化算法（例如梯度下降）结合使用时，我们可以计算神经网络输出层的误差，并通过使用计算出的梯度来更新模型权重，从而重新分配误差。这些梯度沿着网络中定义的相同边缘流动，这些边缘包含权重，但流动方向相反，例如，从输出层到输入层。因此，可视化网络的梯度可能很有用，以了解在某些输出处产生了多少误差以及它是如何分布的[[35](#bib.bib35)，[33](#bib.bib33)]，如第[7.6节](#S7.SS6
    "7.6 Algorithms for Attribution & Feature Visualization ‣ 7 How to Visualize Deep
    Learning ‣ Visual Analytics in Deep Learning: An Interrogative Survey for the
    Next Frontiers")中提到的。'
- en: 6.4 Neurons in High-dimensional Space
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 高维空间中的神经元
- en: 'Continuing the discussion of visualizing activations of a data instance, we
    can think of the feature vectors recovered as vectors in a high-dimensional space.
    Each neuron in a layer then becomes a “dimension.” This shift in perspective is
    powerful, since we can now take advantage of high-dimensional visualization techniques
    to visualize extracted activations [[48](#bib.bib48), [79](#bib.bib79)]. Sometimes,
    people use neural networks simply as feature vector generators, and defer the
    actual task to other computational techniques, e.g., traditional machine learning
    models [[49](#bib.bib49), [4](#bib.bib4)]. In this perspective, we now can think
    of deep neural networks as feature generators, whose output embeddings could be
    worth exploring. A common technique is to use dimensionality reduction to take
    the space spanned by the activations and embed it into 2D or 3D for visualization
    purposes [[79](#bib.bib79), [51](#bib.bib51), [48](#bib.bib48)], as discussed
    in Section [7.2](#S7.SS2 "7.2 Dimensionality Reduction & Scatter Plots ‣ 7 How
    to Visualize Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative
    Survey for the Next Frontiers").'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '继续讨论数据实例激活的可视化时，我们可以将恢复的特征向量视为高维空间中的向量。每一层的神经元就成为了一个“维度”。这种视角的转换非常强大，因为我们现在可以利用高维可视化技术来可视化提取的激活[[48](#bib.bib48)，[79](#bib.bib79)]。有时，人们仅仅将神经网络用作特征向量生成器，并将实际任务委托给其他计算技术，例如传统的机器学习模型[[49](#bib.bib49)，[4](#bib.bib4)]。从这个角度来看，我们现在可以将深度神经网络视为特征生成器，其输出嵌入值得探索。一个常见的技术是使用降维技术，将激活所展开的空间嵌入到2D或3D中以便于可视化[[79](#bib.bib79)，[51](#bib.bib51)，[48](#bib.bib48)]，如第[7.2节](#S7.SS2
    "7.2 Dimensionality Reduction & Scatter Plots ‣ 7 How to Visualize Deep Learning
    ‣ Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers")所讨论的。'
- en: 6.5 Aggregated Information
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5 聚合信息
- en: 6.5.1 Groups of Instances
  id: totrans-226
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.5.1 实例组
- en: 'As mentioned earlier, instance-level activations allow one to recover the mapping
    from data input to a feature vector output. While this can be done for a single
    data instance, it can also be done on collections of instances. While at first
    this does not seem like a major differentiation from before, instance groups provide
    some unique advantages [[39](#bib.bib39), [43](#bib.bib43)]. For example, since
    instance groups by definition are composed of many instances, one can compute
    all the activations simultaneously. Using visualization, we can now compare these
    individual activations to see how similar or different they are from one another.
    Taking this further, with instance groups, we can now take multiple groups, potentially
    from differing classes, and compare how the distribution of activations from one
    group compares or differs from another. This aggregation of known instances into
    higher-level groups could be useful for uncovering the learned decision boundary
    in classification tasks, as seen in Section [7.2](#S7.SS2 "7.2 Dimensionality
    Reduction & Scatter Plots ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics
    in Deep Learning: An Interrogative Survey for the Next Frontiers") and Section
    [7.4](#S7.SS4 "7.4 Instance-based Analysis & Exploration ‣ 7 How to Visualize
    Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative Survey for
    the Next Frontiers").'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '如前所述，实例级激活允许从数据输入恢复到特征向量输出的映射。虽然这可以针对单个数据实例进行，但也可以针对实例集合进行。虽然起初这似乎与之前没有重大区别，但实例组提供了一些独特的优势 [[39](#bib.bib39),
    [43](#bib.bib43)]。例如，由于实例组由许多实例组成，因此可以同时计算所有激活。利用可视化，我们现在可以比较这些个体激活，查看它们彼此的相似或不同之处。更进一步，通过实例组，我们现在可以选择多个组，可能来自不同类别，并比较一个组的激活分布与另一个组的比较或差异。这种将已知实例聚合到更高层次组的做法可能有助于揭示分类任务中的学习决策边界，如第
    [7.2](#S7.SS2 "7.2 Dimensionality Reduction & Scatter Plots ‣ 7 How to Visualize
    Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative Survey for
    the Next Frontiers") 节和第 [7.4](#S7.SS4 "7.4 Instance-based Analysis & Exploration
    ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative
    Survey for the Next Frontiers") 节所示。'
- en: 6.5.2 Model Metrics
  id: totrans-228
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.5.2 模型指标
- en: 'While instance- and group-level activations could be useful for investigating
    how neural networks respond to particular results a-priori, they suffer from scalability
    issues, since deep learning models typically wrangle large datasets. An alternative
    object to visualize are model metrics, including loss, accuracy, and other measures
    of error [[27](#bib.bib27)]. These summary statistics are typically computed every
    epoch and represented as a time series over the course of a model’s training phase.
    Representing the state of a model through a single number, or handful of numbers,
    abstracts away much of the subtle and interesting features of deep neural networks;
    however, these metrics are key indicators for communicating how the network is
    progressing during the training phase [[47](#bib.bib47)]. For example, is the
    network “learning” anything at all or is it learning “too much” and is simply
    memorizing data causing it to overfit? Not only do these metrics describe notions
    of a single model’s performance over time, but in the case of model comparison,
    these metrics become more important, as they can provide a quick and easy way
    to compare multiple models at once. For this reason, visualizing model metrics
    can be an important and powerful tool to consider for visual analytics, as discussed
    in Section [7.3](#S7.SS3 "7.3 Line Charts for Temporal Metrics ‣ 7 How to Visualize
    Deep Learning ‣ Visual Analytics in Deep Learning: An Interrogative Survey for
    the Next Frontiers").'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '虽然实例级和组级激活有助于研究神经网络如何对特定结果作出响应，但由于深度学习模型通常处理大量数据，这些方法存在可扩展性问题。另一种可视化对象是模型指标，包括损失、准确率以及其他错误测量 [[27](#bib.bib27)]。这些汇总统计通常在每个周期计算，并在模型训练阶段以时间序列形式表示。通过一个或几个数字来表示模型状态，虽然抽象了深度神经网络的许多微妙和有趣的特征，但这些指标是传达网络在训练阶段进展的关键指标 [[47](#bib.bib47)]。例如，网络是否“学习”到任何东西，还是“过度学习”并仅仅记忆数据导致过拟合？这些指标不仅描述了单个模型随时间的表现，还在模型比较中变得更加重要，因为它们可以提供一种快速、简便的方法来同时比较多个模型。因此，如第
    [7.3](#S7.SS3 "7.3 Line Charts for Temporal Metrics ‣ 7 How to Visualize Deep
    Learning ‣ Visual Analytics in Deep Learning: An Interrogative Survey for the
    Next Frontiers") 节所述，可视化模型指标可能是视觉分析中一个重要且强大的工具。'
- en: 7 How to Visualize Deep Learning
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 如何可视化深度学习
- en: In the previous section, we described what technical components of neural networks
    could be visualized. In this section, we summarize how the components are visualized
    and interacted with in existing literature. For most neural network components,
    they are often visualized using a few common approaches. For example, network
    architectures are often represented as node-link diagrams; embeddings of many
    activations are typically represented as scatter plots; and model metrics over
    epoch time are almost always represented as line charts. In this section, we will
    also discuss other representations, going beyond the typical approaches.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们描述了神经网络的哪些技术组件可以进行可视化。在本节中，我们总结了现有文献中这些组件是如何被可视化和交互的。对于大多数神经网络组件，它们通常使用一些常见的方法进行可视化。例如，网络架构通常表示为节点-链接图；许多激活的嵌入通常表示为散点图；模型在周期时间上的度量几乎总是表示为折线图。在本节中，我们还将讨论其他表示方法，超越典型的方法。
- en: 7.1 Node-link Diagrams for Network Architectures
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 网络架构的节点-链接图
- en: Given a neural network’s dataflow graph or model architecture, the most common
    way to visualize where data flows and the magnitude of edge weights is a node-link
    diagram. Neurons are shown as nodes, and edge weights as links. For computational
    and dataflow graphs, Kahng et al. [[39](#bib.bib39)] describe two methods for
    creating node-link diagrams. The first represents only operations as nodes, while
    the second represents both operations and data as nodes. The first way is becoming
    the standard due to the popularity of TensorBoard [[27](#bib.bib27)] and the inclusion
    of its interactive dataflow graph visualization [[15](#bib.bib15)]. However, displaying
    large numbers of links from complex models can generate “hairball” visualizations
    where many edge crossings impede pattern discovery. To address this problem, Wongsuphasawat
    et al. [[15](#bib.bib15)] extracts high-degree nodes (responsible for many of
    the edge crossings), visualizes them separately from the main graph, and allow
    users to define super-groups within the code. Another approach to reduce clutter
    is to place more information on each node; DGMTracker [[42](#bib.bib42)] provides
    a quick snapshot of the dataflow in and out of a node by visualizing its activations
    within each node.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 给定神经网络的数据流图或模型架构，最常见的可视化数据流动和边缘权重大小的方法是节点-链接图。神经元被显示为节点，边缘权重则为链接。对于计算和数据流图，Kahng等人[[39](#bib.bib39)]描述了两种创建节点-链接图的方法。第一种方法仅将操作表示为节点，而第二种方法将操作和数据都表示为节点。由于TensorBoard的普及[[27](#bib.bib27)]及其交互式数据流图可视化[[15](#bib.bib15)]，第一种方法正逐渐成为标准。然而，显示复杂模型的大量链接可能会生成“毛球”可视化，其中许多边缘交叉会妨碍模式发现。为了解决这个问题，Wongsuphasawat等人[[15](#bib.bib15)]提取了高阶节点（负责许多边缘交叉），将它们与主图分开可视化，并允许用户在代码中定义超组。另一种减少混乱的方法是对每个节点放置更多信息；DGMTracker[[42](#bib.bib42)]通过可视化节点内部的激活，提供节点数据流入和流出的快速快照。
- en: Regarding neural network architecture, many visual analytics systems use node-link
    diagrams (neurons as nodes, weights as links) [[13](#bib.bib13), [16](#bib.bib16),
    [37](#bib.bib37), [14](#bib.bib14), [35](#bib.bib35)]. The weight magnitude and
    sign can then be encoded using color or link thickness. This technique was one
    of the the first to be proposed [[13](#bib.bib13)], and the trend has continued
    on in literature. Building on this technique, Harley [[37](#bib.bib37)] visualizes
    the convolution windows on each layer and how the activations propagate through
    the network to make the final classification. Similar to the dataflow graph examples
    above, some works include richer information inside each node besides an activation
    value, such as showing a list of images that highly activate that neuron or the
    activations at a neuron as a matrix [[14](#bib.bib14)]. As mentioned in the dataflow
    graph visualizations, node-link diagrams for network architecture work well for
    smaller networks [[16](#bib.bib16)], but they also suffer from scalabilty issues.
    CNNVis [[14](#bib.bib14)], a visual analytics system that visualizes convolutional
    neural networks, proposes to use a bi-clustering-based edge bundling technique
    to reduce visual clutter caused by too many links.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 关于神经网络架构，许多视觉分析系统使用节点-链接图（神经元作为节点，权重作为链接）[[13](#bib.bib13), [16](#bib.bib16),
    [37](#bib.bib37), [14](#bib.bib14), [35](#bib.bib35)]。权重的大小和符号可以通过颜色或链接的粗细来编码。这种技术是最早被提出的技术之一[[13](#bib.bib13)]，并且这一趋势在文献中持续存在。基于这一技术，Harley
    [[37](#bib.bib37)] 通过可视化每一层的卷积窗口以及激活如何通过网络传播以进行最终分类。类似于上述的数据流图示例，一些研究在每个节点中包含了更多的信息，除了激活值之外，例如显示高度激活该神经元的图像列表或以矩阵形式展示神经元的激活[[14](#bib.bib14)]。正如数据流图可视化中所提到的，网络架构的节点-链接图适用于较小的网络[[16](#bib.bib16)]，但它们也面临可扩展性问题。CNNVis
    [[14](#bib.bib14)]，一个可视化卷积神经网络的视觉分析系统，提出使用基于双聚类的边缘捆绑技术来减少由于链接过多而造成的视觉混乱。
- en: '![Refer to caption](img/b743ac88f81155230e699f5c55beae77.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b743ac88f81155230e699f5c55beae77.png)'
- en: 'Figure 3: Each point is a data instance’s high-dimensional activations at a
    particular layer inside of a neural network, dimensionally reduced, and plotted
    in 2D. Notice as the data flows through the network the activation patterns become
    more discernible (left to right) [[39](#bib.bib39)].'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：每个点代表数据实例在神经网络特定层的高维激活，经过降维处理并绘制在2D中。注意随着数据在网络中的流动，激活模式变得更加明显（从左到右）[[39](#bib.bib39)]。
- en: 7.2 Dimensionality Reduction & Scatter Plots
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 降维与散点图
- en: 'In Section [6](#S6 "6 What to Visualize in Deep Learning ‣ Visual Analytics
    in Deep Learning: An Interrogative Survey for the Next Frontiers"), “What,” we
    discussed different types of high-dimensional embeddings: text can be represented
    as vectors in word embeddings for natural language processing and images can be
    represented as feature vectors inside of a neural network. Both of these types
    of embeddings are mathematically represented as large tensors, or sometimes as
    2D matrices, where each row may correspond to an instance and each column a feature.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '在第[6](#S6 "6 What to Visualize in Deep Learning ‣ Visual Analytics in Deep
    Learning: An Interrogative Survey for the Next Frontiers")节中，“What”，我们讨论了不同类型的高维嵌入：文本可以在自然语言处理中的词嵌入中表示为向量，图像可以在神经网络中表示为特征向量。这两种嵌入类型在数学上都表示为大型张量，有时也表示为2D矩阵，其中每一行可能对应一个实例，每一列对应一个特征。'
- en: The most common technique to visualize these embeddings is performing dimensionality
    reduction to reduce the number of columns (e.g., features) to two or three. Projecting
    onto two dimensions would mean computing $(x,y)$ coordinates for every data instance;
    for three dimensions, we compute an additional $z$ component, resulting in $(x,y,z)$.
    In the 2D case, we can plot all data instances as points in a scatter plot where
    the axes may or may not have interpretable meaning, depending on the reduction
    technique used, e.g., principal component analysis (PCA) or t-distributed stochastic
    neighbor embedding (t-SNE) [[79](#bib.bib79)]. In the 3D case, we can still plot
    each data instance as a point in 3D space and use interactions to pan, rotate,
    and navigate this space [[51](#bib.bib51)]. These types of embeddings are often
    included in visual analytics systems as one of the main views [[47](#bib.bib47),
    [35](#bib.bib35)], and are also used in application papers as static figures [[65](#bib.bib65),
    [56](#bib.bib56)]. However, viewing a 3D space on a 2D medium (e.g., computer
    screen) may not be ideal for tasks like comparing exact distances.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化这些嵌入的最常见技术是执行降维，将列数（例如特征）减少到二或三。投影到二维意味着为每个数据实例计算$(x,y)$坐标；对于三维，我们计算额外的$z$分量，得到$(x,y,z)$。在2D情况下，我们可以将所有数据实例绘制为散点图中的点，坐标轴可能具有解释意义，也可能没有，具体取决于使用的降维技术，例如主成分分析（PCA）或t分布随机邻域嵌入（t-SNE）[[79](#bib.bib79)]。在3D情况下，我们仍然可以将每个数据实例绘制为3D空间中的一个点，并使用交互操作来平移、旋转和导航这个空间[[51](#bib.bib51)]。这些类型的嵌入通常被包含在视觉分析系统中作为主要视图之一[[47](#bib.bib47),
    [35](#bib.bib35)]，也在应用论文中作为静态图形使用[[65](#bib.bib65), [56](#bib.bib56)]。然而，在2D介质（例如计算机屏幕）上查看3D空间可能不适合进行精确距离比较等任务。
- en: Since each reduced point corresponds to an original data instance, another common
    approach is to retrieve the original image and place it at the reduced coordinate
    location. Although the image size must be greatly reduced to prevent excessive
    overlap, viewing all the images at once can provide insight into what a deep learning
    model has learned, as seen in the example in [[77](#bib.bib77)] where the authors
    visualize ImageNet test data, or in [[80](#bib.bib80)] where the authors create
    many synthetic images from a single class and compare the variance across many
    random initial starting seeds for the generation algorithm. We have discussed
    the typical case where each dot in the scatter plot is a data instance, but some
    work has also visualized neurons in a layer as separate data instances [[58](#bib.bib58)].
    Another work studies closely how data instances are transformed as their information
    is passed through the deep network, which in effect visualizes how the neural
    network separates various classes along approximated decision boundaries [[48](#bib.bib48)].
    It is also possible to use time-dependent data and visualize how an embedding
    changes over time, or in the case of deep learning, over epochs [[81](#bib.bib81)].
    This can be useful for evaluating the quality of the embedding during the training
    phase.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个减少后的点对应一个原始数据实例，另一种常见的方法是检索原始图像并将其放置在减少的坐标位置。尽管图像大小必须大大缩小以防止过度重叠，但一次查看所有图像可以提供对深度学习模型所学内容的洞察，例如在[[77](#bib.bib77)]中的示例，作者可视化了ImageNet测试数据，或在[[80](#bib.bib80)]中，作者从单一类别创建了许多合成图像，并比较了生成算法在多个随机初始种子下的方差。我们讨论了每个散点图中的点是数据实例的典型情况，但也有工作将层中的神经元可视化为单独的数据实例[[58](#bib.bib58)]。另一项工作详细研究了数据实例在通过深度网络传递信息时的转换过程，这实际上可视化了神经网络如何沿近似决策边界分离不同类别[[48](#bib.bib48)]。还可以使用时间相关数据来可视化嵌入随时间的变化，或在深度学习的情况下，随着训练周期的变化[[81](#bib.bib81)]。这对于评估训练阶段嵌入的质量非常有用。
- en: However, these scatter plots raise problems too. The quality of the embeddings
    greatly depends on the algorithm used to perform the reduction. Some works have
    studied how PCA and t-SNE differ, mathematical and visually, and suggest new reduction
    techniques to capture the semantic and syntactic qualities within word embeddings [[82](#bib.bib82)].
    It has also been shown that popular reduction techniques like t-SNE are sensitive
    to changes in the hyperparameter space. Wattenberg meticulously explores the hyperparameter
    space for t-SNE, and offers lessons learned and practical advice for those who
    wish to use dimensionality reduction methods [[78](#bib.bib78)]. While these techniques
    are commonplace, there are still iterative improvements that can be done using
    clever interaction design, such as finding instances similar to a target instance,
    i.e., those “near” the target in the projected space, helping people build intuition
    for how data is spatially arranged [[51](#bib.bib51)].
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些散点图也会带来问题。嵌入的质量很大程度上取决于用于执行降维的算法。一些研究已经探讨了 PCA 和 t-SNE 在数学和视觉上的不同，并提出了新的降维技术，以捕捉词嵌入中的语义和句法特征[[82](#bib.bib82)]。还显示了流行的降维技术如
    t-SNE 对超参数空间的变化非常敏感。Wattenberg 详细探讨了 t-SNE 的超参数空间，并为希望使用降维方法的人提供了经验教训和实际建议[[78](#bib.bib78)]。虽然这些技术很常见，但仍然可以通过巧妙的交互设计进行迭代改进，例如找到与目标实例相似的实例，即在投影空间中“接近”目标的实例，这有助于人们建立数据空间排列的直观理解[[51](#bib.bib51)]。
- en: 7.3 Line Charts for Temporal Metrics
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 时间序列指标的折线图
- en: Model developers track the progression of their deep learning models by monitoring
    and observing a number of different metrics computed after each epoch, including
    the loss, accuracy, and different measure of errors. This can be useful for diagnosing
    the long training process of deep learning models., The most common visualization
    technique for visualizing this data is by considering the metrics as time series
    and plotting them in line charts [[27](#bib.bib27)]. This approach is widely used
    in deep learning visual analytics tools [[47](#bib.bib47), [35](#bib.bib35)].
    After each epoch, a new entry in the time series is computed, therefore some tools,
    like TensorBoard, run alongside models as they train and update with the latest
    status [[27](#bib.bib27)]. TensorBoard focuses much of its screen real-estate
    to these types of charts and supports interactions for plotting multiple metrics
    in small multiples, plotting multiple models on top of one another, filtering
    different models, providing tooltips for the exact metric values, and resizing
    charts for closer inspection. This technique appears in many visual analytics
    systems and has become a staple for model training, comparison, and selection.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发者通过监控和观察在每个训练周期后计算的不同指标（包括损失、准确率和各种误差测量）来跟踪其深度学习模型的进展。这对于诊断深度学习模型的长时间训练过程非常有用。可视化这些数据的最常见技术是将指标视为时间序列，并以折线图的形式绘制[[27](#bib.bib27)]。这种方法在深度学习可视化分析工具中被广泛使用[[47](#bib.bib47),
    [35](#bib.bib35)]。每个周期后，会计算出时间序列中的新条目，因此一些工具，如 TensorBoard，会在模型训练时并行运行，并更新最新状态[[27](#bib.bib27)]。TensorBoard
    将大量屏幕空间用于这些类型的图表，并支持绘制多个指标的小图、在同一图上绘制多个模型、过滤不同模型、提供准确的指标值工具提示，并调整图表以便更仔细地检查。这项技术出现在许多可视化分析系统中，并已成为模型训练、比较和选择的基础。
- en: 7.4 Instance-based Analysis & Exploration
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4 基于实例的分析与探索
- en: Another technique to help interpret and debug deep learning models is testing
    specific data instances to understand how they progress throughout a model. Many
    experts have built up their own collection of data instances over time, having
    developed deep knowledge about their expected behaviors in models while also knowing
    their ground truth labels [[39](#bib.bib39), [19](#bib.bib19)]. For example, an
    instance consisting of a single image or a single text phrase is much easier to
    understand than an entire image dataset or word embedding consisting of thousands
    of numerical features extracted from an end user’s data. This is called instance-level
    observation, where intensive analysis and scrutiny is placed on a single data
    instance’s transformation process throughout the network, and ultimately its final
    output.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种帮助解释和调试深度学习模型的技术是测试特定的数据实例，以了解它们在模型中的进展情况。许多专家随着时间的推移建立了自己的数据实例集合，发展了对这些实例在模型中预期行为的深刻了解，同时也知道它们的真实标签 [[39](#bib.bib39),
    [19](#bib.bib19)]。例如，由单张图片或单个文本短语组成的实例比由从最终用户数据中提取的成千上万的数值特征构成的整个图像数据集或词嵌入要容易理解得多。这被称为实例级观察，其中对单个数据实例在网络中的转换过程进行深入分析和审查，最终得出其最终输出。
- en: 7.4.1 Identifying & Analyzing Misclassified Instances
  id: totrans-246
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.1 识别与分析错误分类实例
- en: 'One application of instance-level analysis is using instances as unit tests
    for deep learning models. In the best case scenario, all the familiar instances
    are classified or predicted correctly; however, it is important to understand
    when a specific instance can fail and how it fails. For example, in the task of
    predicting population from satellite imagery, the authors showcase three maps
    of areas with high errors by using a translucent heatmap overlaid on the satellite
    imagery [[49](#bib.bib49)]. Inspecting these instances reveals three geographic
    areas that contain high amounts of man-made features and signs of activity but
    have no registered people living in them: an army base, a national lab, and Walt
    Disney World. The visualization helps demonstrate that the proposed model is indeed
    learning high-level features about the input data. Another technique, HOGgles [[83](#bib.bib83)],
    uses an algorithm to visualize feature spaces by using object detectors while
    inverting visual features back to natural images. The authors find that when visualizing
    the features of misclassified images, although the classification is wrong in
    the image space, they look deceptively similar to the true positives in the feature
    space. Therefore, by visualizing feature spaces of misclassified instances, we
    can gain a more intuitive understanding of recognition systems.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 实例级分析的一种应用是将实例用作深度学习模型的单元测试。在最佳情况下，所有熟悉的实例都被正确分类或预测；然而，了解特定实例何时失败以及如何失败是重要的。例如，在从卫星图像预测人口的任务中，作者通过在卫星图像上叠加半透明热图展示了三个错误率较高的区域 [[49](#bib.bib49)]。检查这些实例揭示了三个包含大量人为特征和活动迹象但没有登记住户的地理区域：一个军营，一个国家实验室和华特迪士尼世界。可视化结果有助于展示所提出的模型确实在学习关于输入数据的高级特征。另一种技术，HOGgles [[83](#bib.bib83)]，使用算法通过使用物体检测器来可视化特征空间，同时将视觉特征反向转换回自然图像。作者发现，当可视化错误分类图像的特征时，尽管在图像空间中的分类是错误的，但它们在特征空间中看起来与真正的正例非常相似。因此，通过可视化错误分类实例的特征空间，我们可以更直观地理解识别系统。
- en: For textual data, a popular technique for analyzing particular data instances
    is to use color as the primary encoding. For example, the background of particular
    characters in a phrase of words in a sentence would be colored using a divergent
    color scheme according to some criteria, often their activation magnitudes [[40](#bib.bib40),
    [32](#bib.bib32), [36](#bib.bib36)]. This helps identify particular data instances
    that may warrant deeper inspection (e.g., those misclassified) [[19](#bib.bib19)].
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 对于文本数据，一种流行的分析特定数据实例的技术是使用颜色作为主要编码。例如，句子中某些字符的背景会根据某些标准使用发散色彩方案进行着色，通常是它们的激活幅度 [[40](#bib.bib40),
    [32](#bib.bib32), [36](#bib.bib36)]。这有助于识别可能需要更深入检查的特定数据实例（例如，被错误分类的实例） [[19](#bib.bib19)]。
- en: When pre-defined data instances are not unavailable (e.g., when analyzing a
    new dataset), how can we guide users towards important and interesting instances?
    To address this problem, a visual analytics system called Blocks [[29](#bib.bib29)]
    uses confusion matrices, a technique for summarizing the performance of a classification
    algorithm, and matrix-level sorting interactions to reveal that class error often
    occurs in hierarchies. Blocks incorporates these techniques with a sample viewer
    in the user interface to show selected samples potentially worth exploring.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 当预定义的数据实例不可用时（例如，在分析新数据集时），我们如何引导用户关注重要且有趣的实例？为了解决这个问题，一个名为 Blocks [[29](#bib.bib29)]
    的可视分析系统使用混淆矩阵，这是一种总结分类算法性能的技术，并结合矩阵级排序交互来揭示类错误通常发生在层次结构中。Blocks 将这些技术与用户界面的样本查看器结合起来，展示潜在值得探索的选定样本。
- en: 7.4.2 Analyzing Groups of Instances
  id: totrans-250
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.2 分析实例组
- en: Instead of using individual data instances for testing and debugging a model,
    it is also common for experts to perform similar similar tasks using groups of
    instances [[19](#bib.bib19)]. While some detail may be lost when performing group-level
    analysis it allows experts to further test the model by evaluating its average
    and aggregate performance across different groups.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 与使用单个数据实例进行模型测试和调试不同，专家也常常使用实例组执行类似的任务 [[19](#bib.bib19)]。虽然在执行组级分析时可能会丢失一些细节，但它允许专家通过评估模型在不同组中的平均和汇总性能来进一步测试模型。
- en: Much of the work using this technique is done on text data using LSTM models [[52](#bib.bib52)].
    Some approaches compute the saliency for groups of words across the model and
    visualize the values as a matrix [[41](#bib.bib41)], while others use matrix visualizations
    to show the activations of word groups when represented as feature vectors in
    word embeddings [[50](#bib.bib50), [84](#bib.bib84)]. One system, ActiVis [[39](#bib.bib39)],
    places instance group analysis at the focus of its interactive interface, allowing
    users to compare preset and user-defined groups of activations. Similar to the
    matrix visualization that summarizes activations for each class in CNNVis [[14](#bib.bib14)],
    ActiVis also uses a scrolling matrix visualization to unify both instance-level
    and group-level analysis into a single view where users can compare the activations
    of the user-defined instances.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种技术的大部分工作是基于文本数据，使用 LSTM 模型 [[52](#bib.bib52)]。一些方法计算模型中词汇组的显著性，并将这些值可视化为矩阵
    [[41](#bib.bib41)]，而其他方法则使用矩阵可视化来展示在词嵌入中作为特征向量表示的词汇组的激活 [[50](#bib.bib50), [84](#bib.bib84)]。一个系统
    ActiVis [[39](#bib.bib39)]，将实例组分析置于其交互界面的核心，允许用户比较预设和用户定义的激活组。类似于 CNNVis [[14](#bib.bib14)]
    总结每个类别激活的矩阵可视化，ActiVis 还使用滚动矩阵可视化将实例级和组级分析统一到一个视图中，用户可以在其中比较用户定义实例的激活。
- en: However, sometimes it can be challenging to define groups for images or text.
    For textual data, people often use words to group documents and provide aggregated
    data. ConceptVector [[85](#bib.bib85)] addresses the instance group generation
    problem by providing an interactive interface to create interesting groups of
    concepts for model testing. Furthermore, this system also suggests additional
    words to include in the user-defined groups, helping guide the user to create
    semantically sound concepts.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时为图像或文本定义组可能具有挑战性。对于文本数据，人们通常使用词语对文档进行分组并提供汇总数据。ConceptVector [[85](#bib.bib85)]
    通过提供一个交互式界面来创建有趣的概念组以供模型测试，从而解决了实例组生成问题。此外，该系统还建议将额外的词汇包含在用户定义的组中，帮助指导用户创建语义上合理的概念。
- en: 7.5 Interactive Experimentation
  id: totrans-254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5 交互式实验
- en: Interactive experimentation, another interesting area that integrates deep learning
    visualization, makes heavy use of interactions for users to experiment with models [[86](#bib.bib86)].
    By using direct manipulation for testing models, a user can pose “what if?” questions
    and observe how the input data affects the results. Called explorable explanations [[87](#bib.bib87)],
    this type of visual experimentation is popular for making sense of complex concepts
    and systems.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 交互式实验，另一种有趣的深度学习可视化集成领域，广泛利用用户交互来实验模型 [[86](#bib.bib86)]。通过直接操作进行模型测试，用户可以提出“如果……会怎么样？”的问题，并观察输入数据如何影响结果。这种被称为可探索解释
    [[87](#bib.bib87)] 的视觉实验类型，在理解复杂概念和系统方面非常受欢迎。
- en: 7.5.1 Models Responding to User-provided Input Data
  id: totrans-256
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.5.1 响应用户提供的输入数据的模型
- en: To engage the user with the desired concepts to be taught, many systems require
    the user to provide some kind of input data into the system to obtain results.
    Some visual analytics systems use a webcam to capture live videos, and visualize
    how the internals of neural network models respond to these dynamic inputs [[55](#bib.bib55)].
    Another example is a 3D visualization of a CNN trained on the classic MNIST dataset
    ¹¹1MNIST is a small, popular dataset consisting of thousands of 28$\times$28px
    images of handwritten digits (0 to 9). MNIST is commonly used as a benchmark for
    image classification models. that shows the convolution windows and activations
    on images that the user draws by hand [[37](#bib.bib37)]. For example, drawing
    a “5” in the designated area passes that example throughout the network and populates
    the visualization with the corresponding activations using a node-link diagram.
    A final example using image data is ShapeShop [[38](#bib.bib38)], a system that
    allows a user to select data from a bank of simple shapes to be classified. The
    system then trains a neural network and using the class activation maximization
    technique to generate visualizations of the learned features of the model. This
    can be done in real-time, therefore a user can quickly train multiple models with
    different shapes to observe the effect of adding more diverse data to improve
    the internal model representation.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用户能够掌握所需的概念，许多系统要求用户提供某种输入数据以获得结果。一些视觉分析系统使用网络摄像头捕捉实时视频，并可视化神经网络模型如何响应这些动态输入[[55](#bib.bib55)]。另一个例子是对在经典MNIST数据集上训练的CNN进行的3D可视化¹¹1MNIST是一个小型流行的数据集，由成千上万张28$\times$28像素的手写数字（0到9）图像组成。MNIST通常作为图像分类模型的基准。该可视化展示了卷积窗口和用户手绘图像上的激活[[37](#bib.bib37)]。例如，在指定区域绘制一个“5”会将该示例传递通过网络，并使用节点-链接图填充相应的激活。另一个使用图像数据的例子是ShapeShop[[38](#bib.bib38)]，一个允许用户从简单形状库中选择数据进行分类的系统。该系统随后训练一个神经网络，并使用类激活最大化技术生成模型学习特征的可视化。这可以实时完成，因此用户可以快速训练多个不同形状的模型，以观察添加更多多样化数据对改进内部模型表示的效果。
- en: '![Refer to caption](img/79a0734619162fdb0c2d5643df2127e8.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![Refer to caption](img/79a0734619162fdb0c2d5643df2127e8.png)'
- en: 'Figure 4: TensorFlow Playground [[16](#bib.bib16)]: a web-based visual analytics
    tool for exploring simple neural networks that uses direct manipulation rather
    than programming to teach deep learning concepts and develop an intuition about
    how neural networks behave.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：TensorFlow Playground[[16](#bib.bib16)]：一个基于Web的视觉分析工具，用于探索简单的神经网络，通过直接操作而非编程来教授深度学习概念，并培养对神经网络行为的直觉。
- en: An example using textual data is the online, interactive Distill article for
    handwriting prediction [[32](#bib.bib32)], which allows a user to write words
    on screen, and in real-time, the system draws multiple to-be-drawn curves predicting
    what the user’s next stroke would be, while also visualizing the model’s activations.
    Another system uses GANs to interactively generate images based off of user’s
    sketches [[59](#bib.bib59)]. By sketching a few colored lines, the system presents
    the user with multiple synthetic images using the sketch as a guideline for what
    to generate. A final example is the Adversarial Playground [[44](#bib.bib44)],
    a visual analytics system that enables users to compare adversarially-perturbed
    images, to help users understand why an adversarial example can fool a CNN image
    classifier. The user can select from one of the MNIST digits and adjust the strength
    of adversarial attack. The system then compares the classifications scores in
    a bar chart to observe how simple perturbations can greatly impact classification
    accuracy.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 使用文本数据的一个例子是在线互动的Distill文章，用于手写预测[[32](#bib.bib32)]，该文章允许用户在屏幕上书写单词，并实时绘制多个待绘制曲线以预测用户的下一个笔画，同时可视化模型的激活。另一个系统使用GANs根据用户的草图互动生成图像[[59](#bib.bib59)]。通过绘制几条彩色线条，该系统为用户展示多个合成图像，使用草图作为生成的指导。最后一个例子是对抗性游乐场[[44](#bib.bib44)]，一个视觉分析系统，允许用户比较对抗性扰动图像，以帮助用户理解为什么对抗性示例会欺骗CNN图像分类器。用户可以从MNIST数字中选择一个，并调整对抗攻击的强度。系统随后在条形图中比较分类得分，以观察简单的扰动如何显著影响分类准确性。
- en: 7.5.2 How Hyperparameters Affect Results
  id: totrans-261
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.5.2 超参数如何影响结果
- en: While deep learning models automatically adjust their internal parameters, their
    hyperparameters still require fine-tuning. These hyperparameters can have major
    impact on model performance and robustness. Some visual analytics systems expose
    model hyperparameters to the user for interactive experimentation. One example
    previously mentioned is TensorFlow Playground [[16](#bib.bib16)], where users
    can use direct manipulation to adjust the architecture of a simple, fully-connected
    neural network, as well as the hyperparameters associated with its training, such
    as the learning rate, activation function, and regularization. Another example
    is a Distill article that meticulously explores the hyperparaemters of the t-SNE
    dimensionality reduction method [[78](#bib.bib78)]. This article tests dozens
    of synthetic datasets in different arrangements, while varying hyperparameters
    such as the t-SNE perplexity and the number of iterations to run the algorithm
    for.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度学习模型会自动调整其内部参数，但其超参数仍需细致调整。这些超参数可能对模型性能和鲁棒性产生重大影响。一些视觉分析系统向用户暴露模型超参数，以便进行互动实验。一个之前提到的例子是
    TensorFlow Playground[[16](#bib.bib16)]，用户可以通过直接操作来调整简单的全连接神经网络的架构，以及与训练相关的超参数，如学习率、激活函数和正则化。另一个例子是
    Distill 文章，详细探讨了 t-SNE 降维方法的超参数[[78](#bib.bib78)]。这篇文章测试了数十种不同排列的合成数据集，同时调整了如
    t-SNE 困惑度和算法运行迭代次数等超参数。
- en: 7.6 Algorithms for Attribution & Feature Visualization
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.6 归因和特征可视化的算法
- en: The final method for how to visualize deep learning hails from the AI and computer
    vision communities. These are algorithmic techniques that entail image generation.
    Given a trained a model, one can select a single image instance and use one of
    the algorithmic techniques to generate a new image of the same size that either
    highlights important regions of the image (often called attribution) or is an
    entirely new image that supposedly is representative of the same class (often
    called feature visualization) [[88](#bib.bib88), [46](#bib.bib46)]. In these works,
    it is common to see large, full-page figures consisting of hundreds of such images
    corresponding to multiple images classes [[89](#bib.bib89)]. However, it is uncommon
    to see interactivity in these works, as the primary contribution is often about
    algorithms, not interactive techniques or systems. Since the focus of this interrogative
    survey is on visual analytics in deep learning, we do not discuss in detail the
    various types of algorithmic techniques. Rather, we mention the most prominent
    techniques developed, since they are impactful to the growing field of deep learning
    visualization and could be incorporated into visual analytics systems in the future.
    For more details about these techniques, such as input modification, deconvolutional
    methods [[10](#bib.bib10)], and input reconstruction methods, we refer our readers
    to the taxonomies [[90](#bib.bib90)] and literature surveys for visualizing learned
    features in CNNs [[22](#bib.bib22), [91](#bib.bib91)], and a tutorial that presents
    the theory behind many of these interpretation techniques and discusses tricks
    and recommendations to efficiently use them on real data [[61](#bib.bib61)].
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的深度学习可视化方法源于人工智能和计算机视觉社区。这些是涉及图像生成的算法技术。给定一个训练好的模型，可以选择单个图像实例，并使用其中一种算法技术生成一个大小相同的新图像，该图像可以突出显示图像的重要区域（通常称为归因）或是一个完全新的图像，代表相同类别（通常称为特征可视化）[[88](#bib.bib88),
    [46](#bib.bib46)]。在这些工作中，常见的是大型的整页图像，由数百张对应多个图像类别的图像组成[[89](#bib.bib89)]。然而，这些工作中很少见到互动性，因为主要贡献通常是算法，而不是互动技术或系统。由于本次调查重点在于深度学习中的视觉分析，我们不会详细讨论各种算法技术。而是提到一些最突出的技术，因为它们对深度学习可视化领域的成长具有重大影响，并且可能会被纳入未来的视觉分析系统中。关于这些技术的更多细节，如输入修改、反卷积方法[[10](#bib.bib10)]和输入重建方法，我们建议读者参考分类法[[90](#bib.bib90)]和CNN中学习特征可视化的文献综述[[22](#bib.bib22),
    [91](#bib.bib91)]，以及一个介绍许多这些解释技术背后理论的教程，并讨论了在真实数据上有效使用这些技术的技巧和建议[[61](#bib.bib61)]。
- en: 7.6.1 Heatmaps for Attribution, Attention, & Saliency
  id: totrans-265
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.6.1 归因、注意力和显著性的热图
- en: One research area generates translucent heatmaps that overlay images to highlight
    important regions that contribute towards classification and their sensitivity [[4](#bib.bib4),
    [92](#bib.bib92), [93](#bib.bib93), [69](#bib.bib69), [94](#bib.bib94)]. One technique
    called visual backpropagation attempts to visualize which parts of an image have
    contributed to the classification, and can do so in real-time in a model debugging
    tool for self-driving vehicles [[30](#bib.bib30)]. Another technique is to invert
    representations, i.e., attempt to reconstruct an image using a feature vector
    to understand the what a CNN has learned [[95](#bib.bib95), [96](#bib.bib96),
    [77](#bib.bib77)]. Prediction difference analysis is a method that highlights
    features in an image to provide evidence for or against a certain class[[66](#bib.bib66)].
    Other work hearkens back to more traditional computer vision techniques by exploring
    how object detectors emerge in CNNs and attempts to give humans object detector
    vision capabilities to better align humans and deep learning vision for images [[97](#bib.bib97),
    [83](#bib.bib83)]. Visualizing CNN filters is also popular, and has famously shown
    to generate dream-like images, becoming popular in artistic tasks [[98](#bib.bib98),
    [99](#bib.bib99)] . Some work for interpreting visual question answering (VQA)
    models and tasks use these heatmaps to explain which parts of an image a VQA model
    is looking at in unison with text activation maps when answering the given textual
    questions [[36](#bib.bib36)]. However, recent work has shown that some of these
    methods fail to provide correct results and argue that we should develop explanation
    methods that work on simpler models before extending them to the more complex
    ones [[91](#bib.bib91)].
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 一个研究领域生成半透明的热图，这些热图覆盖图像以突出重要区域，这些区域对分类贡献及其敏感性 [[4](#bib.bib4), [92](#bib.bib92),
    [93](#bib.bib93), [69](#bib.bib69), [94](#bib.bib94)]。一种叫做视觉反向传播的技术试图可视化图像的哪些部分对分类做出了贡献，并且可以在自动驾驶车辆的模型调试工具中实时实现 [[30](#bib.bib30)]。另一种技术是反向表示，即尝试使用特征向量重建图像，以理解CNN学到了什么 [[95](#bib.bib95),
    [96](#bib.bib96), [77](#bib.bib77)]。预测差异分析是一种突出图像中特征的方法，用于提供证据支持或反对某一类别[[66](#bib.bib66)]。其他工作回溯到更传统的计算机视觉技术，通过探索CNN中如何出现目标检测器，并尝试赋予人类目标检测器的视觉能力，以更好地对齐人类和深度学习图像视觉 [[97](#bib.bib97),
    [83](#bib.bib83)]。可视化CNN滤波器也很受欢迎，著名地生成了梦幻般的图像，成为艺术任务中的热门 [[98](#bib.bib98), [99](#bib.bib99)]。一些解释视觉问答（VQA）模型和任务的工作使用这些热图来解释VQA模型在回答给定的文本问题时，图像的哪些部分与文本激活图同时被关注 [[36](#bib.bib36)]。然而，最近的研究表明，其中一些方法未能提供正确的结果，并主张我们应开发在简单模型上有效的解释方法，然后再扩展到更复杂的模型 [[91](#bib.bib91)]。
- en: 7.6.2 Feature Visualization
  id: totrans-267
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.6.2 特征可视化
- en: For feature visualization, while some techniques have proven interesting [[100](#bib.bib100)],
    one of the most studied techniques, class activation maximization, maximizes the
    activation of a chosen, specific neuron using an optimization scheme, such as
    gradient ascent, and generates synthetic images that are representative of what
    the model has learned about the chosen class [[68](#bib.bib68)]. This led to a
    number of works improving the quality of the generated images. Some studies generated
    hundreds of these non-deterministic synthetic images and clustered them to see
    how variations in the class activation maximization algorithm affects the output
    image [[80](#bib.bib80)]. In some of their most recent work on this topic, Ngyuen
    et al. [[70](#bib.bib70)] present hundreds of high-quality images using a deep
    generator network to improve upon the state-of-the-art, and include figures comparing
    their technique to many of the existing and previous attempts to improve the quality
    of generated images. The techniques developed in this research area have improved
    dramatically over the past few years, where now it is possibly to synthetically
    generate photorealistic images [[101](#bib.bib101)]. A recent comparison of feature
    visualization techniques highlights their usefulness [[88](#bib.bib88)]; however,
    the authors note that they remain skeptical of their trustworthiness, e.g., do
    neurons have a consistent meaning across different inputs, and if so, is that
    meaning accurately reified by feature visualization [[46](#bib.bib46)]?
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特征可视化，虽然一些技术已经证明非常有趣 [[100](#bib.bib100)]，但最被研究的技术之一是类别激活最大化，它通过优化方案（如梯度上升）最大化选定特定神经元的激活，并生成代表模型对选定类别所学内容的合成图像 [[68](#bib.bib68)]。这导致了一些改进生成图像质量的工作。一些研究生成了数百张这些非确定性的合成图像，并对它们进行聚类，以观察类别激活最大化算法的变化如何影响输出图像 [[80](#bib.bib80)]。在他们最近的一些工作中，Ngyuen等人 [[70](#bib.bib70)]
    使用深度生成网络展示了数百张高质量图像，以提高现有技术水平，并包括了将他们的技术与许多现有和之前尝试改进生成图像质量的方法进行比较的图表。这些研究领域开发的技术在过去几年中取得了显著进展，现在可以合成生成逼真的图像 [[101](#bib.bib101)]。最近对特征可视化技术的比较突显了它们的有用性 [[88](#bib.bib88)]；然而，作者指出他们对其可靠性持怀疑态度，例如，神经元是否在不同输入之间具有一致的含义，如果有的话，这种含义是否被特征可视化准确体现 [[46](#bib.bib46)]？
- en: 8 When to Visualize in the Deep Learning Process
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 深度学习过程中的可视化时机
- en: 'This section describes when visualizing deep learning may be most relevant
    and useful. Our discussion primarily centers around the training process: an iterative,
    foundational procedure for using deep learning models. We identify two distinct,
    non-mutually exclusive times for when to visualize: during training and after
    training. Some works propose that visualization be used both during and after
    training.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了在何时可视化深度学习可能最相关和有用。我们的讨论主要集中在训练过程：一个用于深度学习模型的迭代、基础程序。我们确定了两个不同的、并不相互排斥的可视化时机：训练过程中和训练之后。一些工作建议在训练期间和训练之后都使用可视化。
- en: 8.1 During Training
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1 训练过程中的可视化
- en: Artificial neural networks learn higher-level features that are useful for class
    discrimination as training progress [[102](#bib.bib102)]. By using visualization
    during the training process, there is potential to monitor one’s model as it learns
    to closely observe and track the model’s performance [[48](#bib.bib48)].
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络学习到的高级特征对于类别区分在训练过程中非常有用 [[102](#bib.bib102)]。通过在训练过程中使用可视化技术，有可能监控模型的学习过程，以密切观察和跟踪模型的性能 [[48](#bib.bib48)]。
- en: 'Many of the systems in this category run in a separate web-browser alongside
    the training process, and interface with the underlying model to query the latest
    model status. This way, users can visually explore and rigorously monitor their
    models in real time, while they are trained elsewhere. The visualization systems
    dynamically update the charts with metrics recomputed after every epoch, e.g.,
    the loss, accuracy, and training time. Such metrics are important to model developers
    because they rely on them to determine if a model (1) has begun to learn anything
    at all; (2) is converging and reaching the peak of its performance; or (3) has
    potentially overfitted and memorized the training data. Therefore, many of the
    visual analytics systems used during training support and show these updating
    visualizations as a primary view in the interface [[27](#bib.bib27), [16](#bib.bib16),
    [35](#bib.bib35), [47](#bib.bib47), [42](#bib.bib42), [34](#bib.bib34)]. One system,
    Deep View [[58](#bib.bib58)], visualizes model metrics during the training process
    and uses its own defined metrics for monitoring (rather than the loss): a discriminability
    metric, which evaluates neuron evolution, and a density metric which evaluates
    the output feature maps. This way, for detecting overfitting, the user does not
    need to wait long to view to infer overfitting; they simply observe the neuron
    density early in training phase.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 该类别中的许多系统在训练过程中通过单独的网页浏览器运行，并与底层模型接口以查询最新的模型状态。这样，用户可以实时可视化地探索和严格监控他们的模型，而模型则在其他地方进行训练。这些可视化系统会动态更新图表，显示每个周期后重新计算的指标，例如损失、准确性和训练时间。这些指标对模型开发者至关重要，因为他们依赖这些指标来确定模型（1）是否已经开始学习；（2）是否正在收敛并达到性能巅峰；或（3）是否可能过拟合并记住了训练数据。因此，许多在训练期间使用的视觉分析系统将这些更新的可视化作为接口中的主要视图进行支持和显示 [[27](#bib.bib27),
    [16](#bib.bib16), [35](#bib.bib35), [47](#bib.bib47), [42](#bib.bib42), [34](#bib.bib34)]。其中一个系统，Deep
    View [[58](#bib.bib58)]，在训练过程中可视化模型指标，并使用其自己定义的监控指标（而非损失）：一种可分辨性指标，用于评估神经元演变，以及一种密度指标，用于评估输出特征图。这样，用户无需长时间等待即可检测到过拟合；他们只需在训练早期观察神经元密度即可。
- en: Similarly, some systems help reduce development time and save computational
    resources by visualizing metrics that indicate whether a model is successfully
    learning or not, allowing a user to stop the training process early [[16](#bib.bib16)].
    By using visualization during model training, users can save development time
    through model steering [[35](#bib.bib35)] and utilizing suggestions for model
    improvement [[34](#bib.bib34)]. Lastly, another model development time minimization
    focuses on diagnosing neurons and layers that are not training correctly or are
    misclassifying data instances. Examples include DeepEyes [[47](#bib.bib47)], a
    system that identifies stable and unstable layers and neurons so users may prune
    their models to speed up training; Blocks [[29](#bib.bib29)], a system that visualizes
    class confusion and reveals that confusion patterns follow a hierarchical structure
    over the classes which can then be exploited to design hierarchy-aware architectures;
    and DGMTracker [[42](#bib.bib42)], a system that proposes a credit assignment
    algorithm that indicates how other neurons contribute to the output of particular
    failing neurons.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，一些系统通过可视化指标来减少开发时间和节省计算资源，这些指标指示模型是否成功学习，使用户能够提前停止训练过程 [[16](#bib.bib16)]。通过在模型训练期间使用可视化，用户可以通过模型引导 [[35](#bib.bib35)]
    和利用模型改进建议 [[34](#bib.bib34)] 来节省开发时间。最后，另一个减少模型开发时间的方法侧重于诊断训练不正确或错误分类数据实例的神经元和层。例如，DeepEyes [[47](#bib.bib47)]
    是一个识别稳定和不稳定层及神经元的系统，用户可以修剪他们的模型以加速训练；Blocks [[29](#bib.bib29)] 是一个可视化类别混淆的系统，揭示了混淆模式在类别间遵循层次结构，这些可以被利用来设计具有层次感知的架构；DGMTracker [[42](#bib.bib42)]
    是一个提出了信用分配算法的系统，该算法指示其他神经元如何对特定失败神经元的输出作出贡献。
- en: 8.2 After Training
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2 训练后
- en: 'While some works support neural network design during the iterative model building
    process, there are other works that focus their visualization efforts after a
    model has been trained. In other words, these works assume a trained model as
    input to the system or visualization technique. Note that many, if not most, of
    the previously mentioned algorithmic techniques developed in the AI fields, such
    as attribution and feature visualization, are performed after training. These
    techniques are discussed more in Section [7.6](#S7.SS6 "7.6 Algorithms for Attribution
    & Feature Visualization ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics
    in Deep Learning: An Interrogative Survey for the Next Frontiers").'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '虽然有些工作在迭代模型构建过程中支持神经网络设计，但也有其他工作将其可视化努力集中在模型训练后。换句话说，这些工作假设一个训练好的模型作为系统或可视化技术的输入。请注意，许多（如果不是大多数）先前提到的
    AI 领域中开发的算法技术，如归因和特征可视化，都是在训练后进行的。这些技术在第 [7.6](#S7.SS6 "7.6 Algorithms for Attribution
    & Feature Visualization ‣ 7 How to Visualize Deep Learning ‣ Visual Analytics
    in Deep Learning: An Interrogative Survey for the Next Frontiers") 节中讨论得更为详细。'
- en: The Embedding Projector [[51](#bib.bib51)] specializes in visualizing 2D and
    3D embeddings produced by trained neural networks. While users can visualize typical
    high-dimensional datasets in this tool, the Embedding Projector tailors the experience
    towards embeddings commonly used deep learning. Once a neural network model has
    been trained, one can compute the activations for a given test dataset and visualize
    the activations in the Embedding Projector to visualize and explore the space
    that the network has learned. Instead of generating an overview embedding, another
    previously discussed system, the Deep Visualization Toolbox [[55](#bib.bib55)],
    uses a trained model to visualize live activations in a large small-multiples
    view to understand of what types of filters a convolutional network has learned.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: Embedding Projector [[51](#bib.bib51)] 专注于可视化由训练好的神经网络生成的 2D 和 3D 嵌入。虽然用户可以在这个工具中可视化典型的高维数据集，但
    Embedding Projector 将体验定制为深度学习中常用的嵌入。一旦神经网络模型经过训练，就可以计算给定测试数据集的激活，并在 Embedding
    Projector 中可视化这些激活，从而可视化和探索网络所学习的空间。与生成概览嵌入的系统不同，之前讨论过的 Deep Visualization Toolbox [[55](#bib.bib55)]
    使用训练好的模型在一个大规模的小多重视图中可视化实时激活，以了解卷积网络学习了什么类型的过滤器。
- en: More traditional visual analytics systems have also been developed to inspect
    a model after it has finished training. ActiVis [[39](#bib.bib39)], a visual analytics
    system for neural network interpretation deployed at Facebook reports that Facebook
    engineers and data scientists use visual analytics systems often in their normal
    workflow. Another system, RNNVis [[43](#bib.bib43)], visualizes and compares different
    RNN models for various natural language processing tasks. This system positions
    itself as a natural extension of TensorFlow; using multiple TensorFlow models
    as input, the system then analyzes the trained models to extract learned representations
    in hidden states, and further processes the evaluation results for visualization.
    Lastly, the LSTMVis [[52](#bib.bib52)] system, a visual analysis tool for RNN
    interpretability, separates model training from the visualization. This system
    takes a model as input that must be trained separately, and from the model, gathers
    the required information to produce the interactive visualizations to be rendered
    in a web-based front-end.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 更传统的可视化分析系统也已开发出来，用于检查模型训练完成后的情况。ActiVis [[39](#bib.bib39)] 是一个用于神经网络解释的可视化分析系统，在
    Facebook 部署，报告称 Facebook 工程师和数据科学家在其正常工作流程中经常使用可视化分析系统。另一个系统，RNNVis [[43](#bib.bib43)]，用于可视化和比较用于各种自然语言处理任务的不同
    RNN 模型。该系统将自己定位为 TensorFlow 的自然扩展；通过使用多个 TensorFlow 模型作为输入，该系统分析训练好的模型以提取隐藏状态中的学习表示，并进一步处理评估结果以进行可视化。最后，LSTMVis [[52](#bib.bib52)]
    系统是一个用于 RNN 可解释性的可视化分析工具，将模型训练与可视化分开。该系统接收一个必须单独训练的模型，并从模型中收集所需信息，以生成将在基于 Web
    的前端呈现的交互式可视化。
- en: 9 Where is Deep Learning Visualization
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 深度学习可视化在哪里
- en: 'For the last question of the interrogative survey, we divide up “Where” into
    two subsections: where deep learning visualization research has been applied,
    and where deep learning visualization research has been conducted, describing
    the new and hybrid community. This division provides a concise summary for practitioners
    who wish to investigate the usage of the described techniques for their own work,
    and provides new researchers with the main venues for this research area to investigate
    existing literature.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 对于问卷调查的最后一个问题，我们将“Where”分为两个子部分：深度学习可视化研究已经应用的地方，以及进行深度学习可视化研究的地方，描述了新的和混合的社区。这种划分为希望调查所述技术在自身工作中应用的从业者提供了简明的总结，也为新研究人员提供了主要的研究领域，以调查现有文献。
- en: 9.1 Application Domains & Models
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1 应用领域与模型
- en: 'While many non-neural approaches are used for real-world applications, deep
    learning has successfully achieved state-of-the-art performance in several domains.
    Previously in Section [4.1.2](#S4.SS1.SSS2 "4.1.2 Interpretation as Qualitative
    Support for Model Evaluation in Various Application Domains ‣ 4.1 Interpretability
    & Explainability ‣ 4 Why Visualize Deep Learning ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers"), we presented works that apply
    neural networks to particular domains and use visualizations to lend qualitative
    support to their usual quantitative results to strengthen users’ trust in their
    models. These domains included neural machine translation [[65](#bib.bib65)],
    reinforcement learning [[56](#bib.bib56)], social good [[49](#bib.bib49)], autonomous
    vehicles [[30](#bib.bib30)], medical imaging diagnostics [[66](#bib.bib66)], and
    urban planning [[67](#bib.bib67)].'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管许多非神经网络方法被应用于实际场景中，深度学习在多个领域中成功达到了**最先进的性能**。之前在第[4.1.2节](#S4.SS1.SSS2 "4.1.2
    Interpretation as Qualitative Support for Model Evaluation in Various Application
    Domains ‣ 4.1 Interpretability & Explainability ‣ 4 Why Visualize Deep Learning
    ‣ Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers")中，我们介绍了将神经网络应用于特定领域的工作，并使用可视化手段为其通常的定量结果提供**定性支持**，以增强用户对模型的信任。这些领域包括神经机器翻译[[65](#bib.bib65)]、强化学习[[56](#bib.bib56)]、社会公益[[49](#bib.bib49)]、自动驾驶车辆[[30](#bib.bib30)]、医学影像诊断[[66](#bib.bib66)]和城市规划[[67](#bib.bib67)]。'
- en: Next we summarize the types of models that have been used in deep learning visualization.
    Much of the existing work has used image-based data and models, namely CNNs, to
    generate attribution and feature visualization explanations for what a model has
    learned from an image dataset. CNNs, while not exclusively used for images, have
    become popular in the computer vision community and are often used for image classification
    and interactive, image-based creative tasks [[59](#bib.bib59), [103](#bib.bib103)].
    Besides images, sequential data (e.g., text, time series data, and music) has
    also been studied. This research stems from the natural language processing community,
    where researchers typically favor RNNs for learning representations of large text
    corpora. These researchers make sense of large word embeddings by using interactive
    tools that support dimensionality reduction techniques to solve problems such
    as sequence-to-sequence conversion, translation, and audio recognition. Research
    combining both image and text data has also been done, such as image captioning
    and visual question answering [[104](#bib.bib104), [105](#bib.bib105)]. Harder
    still are new types of networks called generative adversarial networks, or GANs
    for short, that have produced remarkable results for data generation [[106](#bib.bib106)],
    e.g., producing real-looking yet fake images [[107](#bib.bib107)]. While GANs
    have only existed for a couple of years, they are now receiving significant research
    attention. To make sense of the learned features and distributions from GANs,
    two visual analytics systems, DGMTracker [[42](#bib.bib42)] and GANViz [[53](#bib.bib53)],
    focus on understanding the training dynamics of GANs to help model developers
    better train these complex models, often consisting of multiple dueling neural
    networks.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们总结了在深度学习可视化中使用的模型类型。现有的研究大多使用基于图像的数据和模型，即 CNNs，来生成模型从图像数据集中学到的归因和特征可视化解释。虽然
    CNNs 并不完全用于图像，但它们在计算机视觉社区中变得非常流行，通常用于图像分类和互动的图像创意任务 [[59](#bib.bib59), [103](#bib.bib103)]。除了图像之外，序列数据（如文本、时间序列数据和音乐）也得到了研究。这项研究源于自然语言处理社区，在这里，研究人员通常偏好
    RNNs 来学习大规模文本语料库的表示。这些研究人员通过使用支持降维技术的互动工具来理解大规模的词嵌入，以解决诸如序列到序列转换、翻译和音频识别等问题。结合图像和文本数据的研究也已展开，例如图像描述和视觉问答 [[104](#bib.bib104),
    [105](#bib.bib105)]。更复杂的是一种称为生成对抗网络的新型网络，简称 GANs，这些网络在数据生成方面取得了显著成果 [[106](#bib.bib106)]，例如生成逼真的但虚假的图像 [[107](#bib.bib107)]。尽管
    GANs 仅存在了几年，但它们现在正受到显著的研究关注。为了理解从 GANs 学到的特征和分布，两个可视化分析系统，DGMTracker [[42](#bib.bib42)]
    和 GANViz [[53](#bib.bib53)]，专注于理解 GANs 的训练动态，以帮助模型开发人员更好地训练这些复杂的模型，这些模型通常由多个对抗神经网络组成。
- en: '9.2 A Vibrant Research Community: Hybrid, Apace, & Open-sourced'
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2 充满活力的研究社区：混合、快速、开源
- en: 'As seen from this survey, bringing together the visualization communities with
    the AI communities has led to the design and development of numerous tools and
    techniques for improving deep learning interpretability and democratization. This
    hybrid research area has seen accelerated attention and interest due to its widespread
    impact, as evidenced by the large number of works published in just a few years,
    as seen in Table [II](#S3.T2 "TABLE II ‣ 3 Common Terminology ‣ Visual Analytics
    in Deep Learning: An Interrogative Survey for the Next Frontiers"). A consequence
    of this rapid progress is that deep learning visualization research are being
    disseminated across multiple related venues. In academia, the premiere venues
    for deep learning visualization research consists of two main groups: the information
    visualization and visual analytics communities; and the artificial intelligence
    and deep learning communities. Furthermore, since this area is relatively new,
    it has seen more attention at multiple workshops at the previously mentioned academic
    conferences, as tabulated in Table [I](#S2.T1 "TABLE I ‣ 2.2 Survey Methodology
    & Summarization Process ‣ 2 Our Contributions & Method of Survey ‣ Visual Analytics
    in Deep Learning: An Interrogative Survey for the Next Frontiers").'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '从这项调查中可以看出，将可视化社区与 AI 社区结合起来，促成了许多工具和技术的设计与开发，以提高深度学习的可解释性和民主化。由于其广泛的影响，这一混合研究领域受到了加速关注和兴趣，这从仅在短短几年内发表的大量作品中可以看出，如表
    [II](#S3.T2 "TABLE II ‣ 3 Common Terminology ‣ Visual Analytics in Deep Learning:
    An Interrogative Survey for the Next Frontiers") 所示。这一快速进展的结果是，深度学习可视化研究正在多个相关场所传播。在学术界，深度学习可视化研究的主要场所包括两个主要群体：信息可视化和视觉分析社区；以及人工智能和深度学习社区。此外，由于这一领域相对较新，它在前述学术会议的多个研讨会上受到了更多关注，具体见表
    [I](#S2.T1 "TABLE I ‣ 2.2 Survey Methodology & Summarization Process ‣ 2 Our Contributions
    & Method of Survey ‣ Visual Analytics in Deep Learning: An Interrogative Survey
    for the Next Frontiers")。'
- en: Another consequence of this rapidly developing area is that new work is immediately
    publicized and open-sourced, without waiting for it to be “officially” published
    at conferences, journals, etc. Many of these releases take the form of a preprint
    publication posted on arXiv, where a deep learning presence has thrived. Not only
    is it common for academic research labs and individuals to publish work on arXiv,
    but companies from industry are also publishing results, code, and tools. For
    example, the most popular libraries²²2Popular libraries include TensorFlow [[27](#bib.bib27)],
    Keras, Caffe, PyTorch, and Theano. for implementing neural networks are open-source
    and have consistent contributions for improving all areas of the codebase, e.g.,
    installation, computation, and deployment into specific programming languages’
    open-source environments.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 这个迅速发展的领域的另一个结果是，新工作会立即被公开和开源，而无需等待其在会议、期刊等地的“正式”发表。这些发布中许多以预印本形式出现在 arXiv 上，在这里深度学习的影响力蓬勃发展。学术研究实验室和个人在
    arXiv 上发布工作已是常态，工业界的公司也在发布结果、代码和工具。例如，最受欢迎的库²²²受欢迎的库包括 TensorFlow [[27](#bib.bib27)]、Keras、Caffe、PyTorch
    和 Theano，用于实现神经网络的开源库不断改进代码库的各个领域，如安装、计算和特定编程语言开源环境中的部署。
- en: 'Some works have a corresponding blog post on an industry research blog³³3High
    impact industry blogs include: Google Research Blog, OpenAI, Facebook Research
    Blog, the Apple Machine Learning Journal, NVIDIA Deep Learning AI, and Uber AI,
    which, while non-traditional, has large impact due to their prominent visibility
    and large readership. While posting preprints may have its downsides (e.g., little
    quality control) the communities have been promoting the good practices of open-sourcing
    developed code and including direct links within the preprints; both practices
    are now the norm. Although it may be overwhelming to digest the amount of new
    research published daily, having access to the work with its code could encourage
    reproducibility and allow the communities to progress faster. In summary, given
    the increasing interest in deep learning visualization research and its importance,
    we believe our communities will continue to thrive, and will positively impact
    many domains for years to come.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 一些工作在行业研究博客上有对应的博客文章³³3高影响力的行业博客包括：Google Research Blog、OpenAI、Facebook Research
    Blog、Apple Machine Learning Journal、NVIDIA Deep Learning AI 和 Uber AI，这些博客虽然不传统，但由于其显著的可见性和广泛的读者群体，影响力巨大。虽然发布预印本可能有其缺点（例如，质量控制不足），但社区已经提倡开放源代码和在预印本中包含直接链接的良好做法；这两种做法现在已成为常态。尽管每天发布的大量新研究可能让人不知所措，但能够获取带有代码的工作可以促进研究的可重复性，并使社区能够更快地进步。总之，鉴于深度学习可视化研究的兴趣不断增加及其重要性，我们相信我们的社区将继续蓬勃发展，并对未来几年内的许多领域产生积极影响。
- en: 10 Research Directions & Open Problems
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 个研究方向与未解决的问题
- en: Now we present research directions and open problems for future research distilled
    from the surveyed works.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们呈现从调查的工作中提炼出的未来研究方向和未解决的问题。
- en: 10.1 Furthering Interpretability
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1 进一步推动可解释性
- en: Unsurprisingly, with the amount of attention and importance on interpretability
    and explainability in the deep learning visualization literature, the first area
    for future work is continuing to create new interpretable methods for deep learning
    models. For the information visualization and visual analytics communities, this
    could constitute creating new visual representations for the components in deep
    learning models, or developing new interaction techniques to reveal deeper insights
    about one’s model. For the AI communities, more insightful attribution and feature
    visualization techniques for trained models that are fast (computationally cheap)
    could be incorporated into visualization systems. Combining visual representations,
    helpful interactions, and state-of-the-art attribution and feature visualization
    techniques together into rich user interfaces could lead to major breakthroughs
    for understanding neural networks [[46](#bib.bib46)].
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无意外地，考虑到在深度学习可视化文献中对可解释性和解释性的关注和重要性，未来工作的第一个领域是继续创建新的深度学习模型的可解释方法。对于信息可视化和视觉分析社区，这可能包括为深度学习模型中的组件创建新的视觉表示，或开发新的交互技术以揭示模型的更深层次洞察。对于AI社区，可以将更多有洞察力的归因和特征可视化技术（这些技术计算上便宜且快速）融入到可视化系统中。将视觉表示、有效的交互以及最先进的归因和特征可视化技术结合到丰富的用户界面中，可能会在理解神经网络方面带来重大突破[[46](#bib.bib46)]。
- en: '![Refer to caption](img/2819753867197638784a43583ff8722c.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2819753867197638784a43583ff8722c.png)'
- en: 'Figure 5: Distill: The Building Blocks of Interpretability [[46](#bib.bib46)]:
    an interactive user interface that combines feature visualization and attribution
    techniques to interpret neural networks.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5：Distill: 可解释性的构建块[[46](#bib.bib46)]：一个结合特征可视化和归因技术以解释神经网络的互动用户界面。'
- en: 10.2 System & Visual Scalability
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2 系统与视觉可扩展性
- en: Throughout this survey, we have covered many visual analytics systems that facilitate
    interpretation and model understanding. However, some systems suffer from scalability
    problems. Visual scalability challenges arise when dealing with large data, e.g.,
    large number of hyperparameters and millions of parameters in deep neural networks.
    Some research has started to address this, by simplifying complex dataflow graphs
    and network weights for better model explanations [[15](#bib.bib15), [14](#bib.bib14),
    [52](#bib.bib52)]. But, regarding activations and embeddings, dimensionality reduction
    techniques have a limit to their usability when it comes to the number of points
    to visualize [[48](#bib.bib48)]. We think this is an important research direction,
    especially given that the information visualization communities have developed
    techniques to visualize large, high-dimensional data that could potentially be
    applicable to deep learning [[108](#bib.bib108)].
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次调查中，我们覆盖了许多促进解释和模型理解的可视分析系统。然而，一些系统存在可扩展性问题。处理大数据时，视觉可扩展性挑战就会出现，例如，深度神经网络中的大量超参数和百万级参数。一些研究已经开始解决这一问题，通过简化复杂的数据流图和网络权重来提供更好的模型解释 [[15](#bib.bib15),
    [14](#bib.bib14), [52](#bib.bib52)]。但在处理激活和嵌入时，维度降低技术在可视化点数方面有其局限性 [[48](#bib.bib48)]。我们认为这是一个重要的研究方向，特别是考虑到信息可视化社区已经开发出可用于可视化大型、高维数据的技术，这些技术可能适用于深度学习 [[108](#bib.bib108)]。
- en: Aside from visual scalability, some tools also suffer from system scalability.
    While some of these problems may be more engineering-centric, we think that for
    visual analytics systems to adopted, they need to handle state-of-the-art deep
    models without penalizing performance or increasing model development time. Furthermore,
    these systems (often web-based) will greatly benefit from fast computations, supporting
    real-time, rich user interactions [[50](#bib.bib50)]. This is especially important
    for visual systems that need to perform pre-computation before rendering visualizations
    to the screen.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 除了视觉可扩展性，一些工具还面临系统可扩展性问题。虽然这些问题中的一些可能更偏向于工程技术，但我们认为，为了让视觉分析系统被广泛采用，它们需要处理最先进的深度模型，而不影响性能或增加模型开发时间。此外，这些系统（通常是基于网络的）将从快速计算中大大受益，支持实时、丰富的用户互动 [[50](#bib.bib50)]。对于需要在呈现可视化之前进行预计算的视觉系统，这一点尤为重要。
- en: '10.3 Design Studies for Evaluation: Utility & Usability'
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3 评估设计研究：实用性与可用性
- en: An important facet of visualization research is the evaluation of the utility
    and usefulness of the visual representation. Equally important is to evaluate
    the usability of deployed systems and their interactive visual analytics techniques.
    It is encouraging to see many of the visual analytics systems recognize this importance
    and report on design studies conducted with AI experts before building a tool
    to understand the users and their needs [[15](#bib.bib15), [39](#bib.bib39), [52](#bib.bib52),
    [14](#bib.bib14), [43](#bib.bib43), [19](#bib.bib19)]. It is common to see example
    use cases or illustrative usage scenarios that demonstrate the capabilities of
    the interactive systems. Some works go beyond these and conduct user studies to
    evaluate utility and usability [[31](#bib.bib31)]. In the AI communities, most
    works do not include user studies. For those that do, they greatly benefit from
    showing why their proposed methods are superior to the ones being tested against [[69](#bib.bib69),
    [109](#bib.bib109), [89](#bib.bib89), [110](#bib.bib110)]. Taking this idea to
    the quantifiable extreme, a related avenue of evaluating these techniques is the
    notion of quantifying interpretability, which has been recently studied [[28](#bib.bib28),
    [111](#bib.bib111)]. Other domains have recognized that interpretable deep learning
    research may require evaluation techniques for their interpretations, and argue
    that there is a large body of work from fields such as philosophy, cognitive science,
    and social psychology that could be utilized [[62](#bib.bib62), [112](#bib.bib112)].
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化研究的一个重要方面是评估视觉表示的效用和实用性。同样重要的是评估已部署系统及其交互式视觉分析技术的可用性。看到许多视觉分析系统认识到这一点并在构建工具之前与AI专家进行设计研究以了解用户及其需求，这令人鼓舞[[15](#bib.bib15),
    [39](#bib.bib39), [52](#bib.bib52), [14](#bib.bib14), [43](#bib.bib43), [19](#bib.bib19)]。常见的做法是展示示例用例或说明性的使用场景，以展示交互系统的能力。一些研究超越了这些，进行用户研究来评估效用和可用性[[31](#bib.bib31)]。在AI社区中，大多数研究未包括用户研究。对于那些包括用户研究的工作，通过展示为什么他们提出的方法优于对比方法，他们获得了极大的好处[[69](#bib.bib69),
    [109](#bib.bib109), [89](#bib.bib89), [110](#bib.bib110)]。将这一思想推向量化的极端，评估这些技术的相关途径是量化可解释性的概念，这一概念最近得到了研究[[28](#bib.bib28),
    [111](#bib.bib111)]。其他领域已经认识到，可解释的深度学习研究可能需要对其解释进行评估技术，并认为来自哲学、认知科学和社会心理学等领域的大量工作可以被利用[[62](#bib.bib62),
    [112](#bib.bib112)]。
- en: When surveying the interfaces of deep learning visual analytics tools, many
    of them contain multiple-coordinated views with many visual representations. Displaying
    this much information at once can be overwhelming, and when interpretability is
    the primary focus, it is critical for these systems to have superior usability.
    Therefore, we think future works could further benefit from including more members
    of the human-computer interaction communities, including interface and user experience
    designers, that could help organize and prioritize interfaces using well-studied
    guidelines [[86](#bib.bib86)].
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在调查深度学习视觉分析工具的界面时，许多工具包含多个协调视图和多种视觉表示。一次显示这么多信息可能会让人不知所措，当可解释性是主要关注点时，这些系统必须具有卓越的可用性。因此，我们认为未来的工作可以进一步受益于包括更多人机交互社区的成员，包括界面和用户体验设计师，他们可以帮助组织和优先考虑界面，使用经过充分研究的指南[[86](#bib.bib86)]。
- en: 10.4 The Human Role in Interpretability
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4 可解释性中的人类角色
- en: 10.4.1 Human v. Machine Understanding of the World
  id: totrans-301
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 10.4.1 人类与机器对世界的理解
- en: In deep learning interpretability work, researchers are developing methods to
    produce better explanations to “see through the black-box,” but unfortunately
    some of these methods produce visualizations that, while visually interesting
    and thought-provoking [[98](#bib.bib98)], are not fully understandable by their
    human viewers. That is an important facet of deep learning interpretability, namely,
    producing visualizations and interpretations that are human understandable [[88](#bib.bib88)].
    Some methods compare algorithmic results with an empirically derived human baseline;
    this enables comparison between machine and human generated responses to objects
    in the world, particularly in images [[113](#bib.bib113)]. Ultimately, researchers
    seek to understand the commonalities and differences between how humans and machines
    see and decompose the world [[114](#bib.bib114)]. Some tools that we have surveyed
    achieve this by using live-video to compare the input images and the neural network’s
    activations and filters in real time [[55](#bib.bib55)]. Other tools give users
    explicit control of an experiment by training multiple small models with only
    a few exposed hyperparameters, automatically generating visualizations to then
    see the effect that the input data has on the learned representation [[38](#bib.bib38)].
    These “what-if” tools and scenarios could potentially be extended to incorporate
    human feedback into the training or model steering process of neural network to
    better improve performance.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习可解释性工作中，研究人员正在开发方法来提供更好的解释，以“透视黑箱”，但不幸的是，这些方法中一些虽然在视觉上有趣且引人深思[[98](#bib.bib98)]，却无法被人类观众完全理解。这是深度学习可解释性的一个重要方面，即生成易于人类理解的可视化和解释[[88](#bib.bib88)]。一些方法通过将算法结果与经验上得出的人工基准进行比较，从而实现机器和人类对世界中物体（特别是图像）的响应比较[[113](#bib.bib113)]。最终，研究人员寻求理解人类和机器在观察和分解世界时的共性和差异[[114](#bib.bib114)]。我们调查的一些工具通过使用实时视频来比较输入图像与神经网络的激活和过滤器，从而实现这一点[[55](#bib.bib55)]。其他工具通过训练多个小模型，仅暴露少量超参数，自动生成可视化，然后查看输入数据对学习表示的影响，从而为用户提供明确的实验控制[[38](#bib.bib38)]。这些“如果”工具和场景可能会扩展到将人类反馈纳入神经网络的训练或模型指导过程中，以更好地提升性能。
- en: 10.4.2 Human-AI Pairing
  id: totrans-303
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 10.4.2 人工智能与人类配对
- en: 'Much of this survey is dedicated towards reviewing the state-of-the-art in
    visual analytics for deep learning, with a focus on interpretability. These works
    use visualization to explain, explore, and debug models in order to choose the
    best preforming model for a given task, often by placing a human in the loop.
    However, a slight twist on this idea hearkening back to the original envisioning
    of the computer has lead to the emergence of a new research area, one where tasks
    are not exclusively performed by humans or machines, but one where the two complement
    each other. This area, recently dubbed artificial intelligence augmentation describes
    the use of AI systems to help develop new methods for intelligence augmentation [[103](#bib.bib103)].
    Some related works we have covered already propose artificial intelligence augmentation
    ideas, such as a system that suggests potentially interesting directions to explore
    in a high-dimensional 3D embedding [[51](#bib.bib51)], predicting and showing
    where the next stroke of a word could be when handwriting text [[32](#bib.bib32)],
    automatically generating images based off of user-provided sketches [[59](#bib.bib59)],
    and dynamically changing and steering a neural network model while it trains [[35](#bib.bib35)].
    We believe this is a rich, under-explored area for future research: using well-designed
    interfaces for humans to interact with machine learning models, and for these
    machine learning models to augment creative human tasks.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查的大部分内容致力于审查深度学习视觉分析领域的**最新技术**，重点关注可解释性。这些工作利用可视化来解释、探索和调试模型，以选择适用于特定任务的最佳表现模型，通常通过将人类纳入循环来实现。然而，这一理念的略微转变回到计算机的最初设想，促使了一个新研究领域的出现——一个任务不仅由人类或机器单独执行，而是两者相互补充的领域。这个新领域最近被称为人工智能增强，描述了利用AI系统帮助开发智能增强的新方法[[103](#bib.bib103)]。我们已涵盖的一些相关工作已经提出了人工智能增强的想法，例如一个系统，它建议在高维3D嵌入中探索的潜在有趣方向[[51](#bib.bib51)]，预测并显示手写文本时下一个笔划的位置[[32](#bib.bib32)]，根据用户提供的草图自动生成图像[[59](#bib.bib59)]，以及在训练过程中动态改变和引导神经网络模型[[35](#bib.bib35)]。我们相信这是一个丰富的、尚未充分探索的未来研究领域：利用精心设计的界面让人类与机器学习模型进行互动，以及让这些机器学习模型增强创造性的人类任务。
- en: 10.5 Social Good & Bias Detection
  id: totrans-305
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5 社会公益与偏见检测
- en: The aspirational pairing of humans and machines is a long-term research endeavor.
    To quicken our pace, we must continue to democratize artificial intelligence via
    educational tools, perhaps by using direct manipulation as an invitation for people
    to engage with AI [[16](#bib.bib16), [46](#bib.bib46)], clear explanations for
    model decision making, and robust tooling and libraries for programming languages
    for people to develop such models [[27](#bib.bib27), [15](#bib.bib15)]. While
    doing this, we must also ensure that AI applications remain ethical, fair, safe,
    transparent, and are benefiting society [[63](#bib.bib63)].
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 人类与机器的理想配对是一个长期的研究努力。为了加快步伐，我们必须继续通过教育工具来普及人工智能，也许通过直接操作作为邀请人们参与AI[[16](#bib.bib16),
    [46](#bib.bib46)]，为模型决策提供明确的解释，以及为人们开发此类模型提供强大的工具和库[[27](#bib.bib27), [15](#bib.bib15)]。在做到这一点的同时，我们还必须确保AI应用保持伦理、公平、安全、透明，并对社会产生积极的影响[[63](#bib.bib63)]。
- en: Another important consideration for future research is detecting bias. This
    has been identified as a major problem in deep learning [[115](#bib.bib115), [116](#bib.bib116)],
    and a number of researchers are using visualization to understand why a model
    may be biased [[117](#bib.bib117)]. One example that aims to detect data bias
    is Google’s Facets tool [[118](#bib.bib118)], a visual analytics system designed
    specifically to preview and visualize machine learning datasets before training.
    This allows one to inspect large datasets by exploring the different classes or
    data instances, to see if there are any high-level imbalances in the class or
    data distribution.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的未来研究考量是检测偏见。这被识别为深度学习中的一个主要问题[[115](#bib.bib115), [116](#bib.bib116)]，一些研究人员正在使用可视化来理解模型为何可能存在偏见[[117](#bib.bib117)]。一个旨在检测数据偏见的例子是谷歌的Facets工具[[118](#bib.bib118)]，这是一个专门设计的可视化分析系统，用于在训练前预览和可视化机器学习数据集。这使得人们可以通过探索不同的类别或数据实例来检查大型数据集，以查看类或数据分布是否存在任何高层次的不平衡。
- en: Other works have begun to explore if the mathematical algorithms themselves
    can be biased towards particular decisions. An example of this is an interactive
    article titled “Attacking discrimination with smarter machine learning” [[117](#bib.bib117)],
    which explores how one can can create both fair and unfair threshold classifiers
    in an example task such as loan granting scenarios where a bank may grant or deny
    a loan based on a single, automatically computed number such as a credit score.
    The article aims to highlight that equal opportunity [[119](#bib.bib119)] is not
    preserved by machine learning algorithms, and that as AI-powered systems continue
    to make important decisions across core social domains, it is critical to ensure
    decisions are not discriminatory.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 其他研究开始探讨数学算法本身是否对特定决策存在偏见。例如，一篇题为“用更智能的机器学习对抗歧视”的互动文章[[117](#bib.bib117)]探讨了如何在像贷款批准这样的任务中创建公平和不公平的阈值分类器，其中银行可能会根据一个自动计算的数字（如信用评分）来批准或拒绝贷款。文章旨在突出*平等机会*[[119](#bib.bib119)]并非由机器学习算法保障，并且随着AI系统在核心社会领域中做出重要决策，确保决策不具歧视性是至关重要的。
- en: Finally, aside from data and model bias, humans are often inherently biased
    decision makers. In response, there is a growing area of research into detecting
    and understanding bias in visual analytics ⁴⁴4The DECISIVe Workshop ([http://decisive-workshop.dbvis.de/](http://decisive-workshop.dbvis.de/))
    at IEEE VIS is dedicated to understanding cognitive bias in visualization. and
    its affect on the decision making process [[120](#bib.bib120)]. Some work has
    developed metrics to detect types of bias to present to a user during data analysis [[120](#bib.bib120)]
    which could also be applied to visual tools for deep learning in the future. Some
    work has employed developmental and cognitive psychology analysis techniques to
    understand how humans learn, focusing on uncovering how human bias is developed
    and influences learning, to ultimately influence artificial neural network design [[112](#bib.bib112)].
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，除了数据和模型偏差之外，人类往往本身就是偏见的决策者。为此，越来越多的研究致力于检测和理解视觉分析中的偏见⁴⁴4The DECISIVe Workshop
    ([http://decisive-workshop.dbvis.de/](http://decisive-workshop.dbvis.de/))在IEEE
    VIS上专注于理解可视化中的认知偏见及其对决策过程的影响[[120](#bib.bib120)]。一些研究开发了度量标准，以在数据分析过程中向用户展示偏见类型[[120](#bib.bib120)]，这些方法未来也可能应用于深度学习的可视化工具。一些研究采用了发展心理学和认知心理学分析技术，深入了解人类如何学习，揭示人类偏见是如何形成并影响学习的，从而*最终*影响人工神经网络设计[[112](#bib.bib112)]。
- en: 10.6 Protecting Against Adversarial Attacks
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.6 保护免受对抗性攻击
- en: Regardless of the benefits AI systems are bringing to society, we would be remiss
    to immediately trust them; like most technologies, AI too has security faults.
    Identified and studied in seminal works, it has been shown that deep learning
    models such as image classifiers can be easily fooled by perturbing an input image [[121](#bib.bib121),
    [122](#bib.bib122), [123](#bib.bib123)]. Most alarming, some perturbations are
    so subtle that they are untraceable by the human eye, yet would completely fool
    a model into misclassification [[122](#bib.bib122)]. This sparked great interest
    in the AI communities, and much work has been done to understand how fragile deep
    neural network image classifiers are, identify in what ways can they break, and
    explore methods for protecting them. Norton et al. [[44](#bib.bib44)] demonstrate
    adding adversarial perturbations to images in an interactive tool, where users
    can tweak the type and intensity of the attack, and observe the resulting (mis)classification.
    This is a great first start for using visualization to identify potential attacks,
    but we think visualization can be majorly impactful in this research space, by
    not only showcasing how the attacks work and detecting them, but also by taking
    action and protecting AI systems from the attacks themselves. While some work,
    primarily originating from the AI communities, has proposed computational techniques
    to protect AI from attacks, such as identifying adversarial examples before classification [[124](#bib.bib124)],
    modifying the network architecture [[125](#bib.bib125)], modifying the training
    process [[126](#bib.bib126), [122](#bib.bib122)], and performing pre-processing
    steps before classification [[127](#bib.bib127), [128](#bib.bib128)], we think
    visualization can have great impact for combating adversarial machine learning.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管人工智能系统给社会带来了许多好处，但我们不应立即对它们产生完全信任；与大多数技术一样，人工智能也存在安全漏洞。已有开创性的研究显示，深度学习模型如图像分类器可以通过扰动输入图像轻易被欺骗 [[121](#bib.bib121),
    [122](#bib.bib122), [123](#bib.bib123)]。更令人担忧的是，一些扰动细微到人眼无法察觉，却足以使模型完全误分类 [[122](#bib.bib122)]。这引起了人工智能社区的极大关注，许多研究致力于理解深度神经网络图像分类器的脆弱性，识别它们可能出现故障的方式，并探索保护它们的方法。Norton
    等人 [[44](#bib.bib44)] 展示了如何在一个交互式工具中向图像添加对抗性扰动，用户可以调整攻击的类型和强度，并观察结果的（误）分类。这是利用可视化识别潜在攻击的一个很好的起点，但我们认为，可视化在这一研究领域的影响可能更为深远，不仅能展示攻击的工作原理和检测攻击，还能采取行动保护人工智能系统免受攻击。虽然一些主要来自人工智能社区的研究提出了保护人工智能免受攻击的计算技术，例如在分类前识别对抗样本 [[124](#bib.bib124)]，修改网络结构 [[125](#bib.bib125)]，修改训练过程 [[126](#bib.bib126),
    [122](#bib.bib122)]，以及在分类前进行预处理 [[127](#bib.bib127), [128](#bib.bib128)]，我们认为可视化在对抗性机器学习方面可以发挥重要作用。
- en: 11 Conclusion
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: We presented a comprehensive, timely survey on visualization and visual analytics
    in deep learning research, using a human-centered, interrogative framework. Our
    method helps researchers and practitioners in visual analytics and deep learning
    to quickly learn key aspects of this young and rapidly growing body of research,
    whose impact spans a broad range of domains. Our survey goes beyond visualization-focused
    venues to extend a wide scope that also encompasses relevant works from top venues
    in AI, ML, and computer vision. We highlighted visual analytics as an integral
    component in addressing pressing issues in modern AI, helping to discover and
    communicate insight, from discerning model bias, understanding models, to promoting
    AI safety. We concluded by highlighting impactful research directions and open
    problems.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对深度学习研究中的可视化和视觉分析进行了全面且及时的综述，采用以人为本的质询框架。我们的方法帮助研究人员和从业者迅速了解这一新兴且迅速发展的研究领域的关键方面，其影响涉及广泛的领域。我们的综述不仅关注可视化，还扩展到涵盖人工智能、机器学习和计算机视觉领域的顶级作品。我们强调了视觉分析在解决现代人工智能中紧迫问题中的重要性，帮助发现和传达见解，从辨别模型偏差、理解模型到促进人工智能安全。我们总结时指出了有影响力的研究方向和待解决的问题。
- en: Acknowledgments
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work was supported by NSF grants IIS-1563816, CNS-1704701, and TWC-1526254;
    NIBIB grant U54EB020404; NSF GRFP DGE-1650044; NASA Space Technology Research
    Fellowship; and gifts from Intel, Google, Symantec.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作得到了 NSF 资助 IIS-1563816、CNS-1704701 和 TWC-1526254；NIBIB 资助 U54EB020404；NSF
    GRFP DGE-1650044；NASA 太空技术研究奖学金；以及来自 Intel、Google、Symantec 的捐赠。
- en: References
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] W. S. McCulloch and W. Pitts, “A logical calculus of the ideas immanent
    in nervous activity,” *The bulletin of mathematical biophysics*, vol. 5, no. 4,
    1943.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] W. S. McCulloch 和 W. Pitts，“神经活动中固有思想的逻辑演算，” *数学生物物理学公报*，第5卷，第4期，1943年。'
- en: '[2] W. Rawat and Z. Wang, “Deep convolutional neural networks for image classification:
    A comprehensive review,” *Neural computation*, vol. 29, no. 9, 2017.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] W. Rawat 和 Z. Wang，“图像分类的深度卷积神经网络：全面综述，” *神经计算*，第29卷，第9期，2017年。'
- en: '[3] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet classification
    with deep convolutional neural networks,” in *NIPS*, 2012.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] A. Krizhevsky, I. Sutskever 和 G. E. Hinton，“利用深度卷积神经网络进行 ImageNet 分类，”
    在 *NIPS*，2012年。'
- en: '[4] K. Simonyan, A. Vedaldi, and A. Zisserman, “Deep inside convolutional networks:
    Visualising image classification models and saliency maps,” *arXiv:1312.6034*,
    2013.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] K. Simonyan, A. Vedaldi 和 A. Zisserman，“深入卷积网络内部：可视化图像分类模型和显著性图，” *arXiv:1312.6034*，2013年。'
- en: '[5] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan,
    V. Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,” in *CVPR*,
    2015.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan,
    V. Vanhoucke 和 A. Rabinovich，“通过卷积深入探索，” 在 *CVPR*，2015年。'
- en: '[6] A. Karpathy, “What I learned from competing against a convnet on ImageNet,”
    2014\. [Online]. Available: [http://karpathy.github.io/2014/09/02/what-i-learned-from-eompeting-against-a-convnet-on-imagenet](http://karpathy.github.io/2014/09/02/what-i-learned-from-eompeting-against-a-convnet-on-imagenet)'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] A. Karpathy，“我从与 ImageNet 上的卷积网络竞争中学到了什么，” 2014年。 [在线]. 可用：[http://karpathy.github.io/2014/09/02/what-i-learned-from-eompeting-against-a-convnet-on-imagenet](http://karpathy.github.io/2014/09/02/what-i-learned-from-eompeting-against-a-convnet-on-imagenet)'
- en: '[7] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
    recognition,” in *CVPR*, 2016.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] K. He, X. Zhang, S. Ren 和 J. Sun，“用于图像识别的深度残差学习，” 在 *CVPR*，2016年。'
- en: '[8] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “ImageNet:
    A large-scale hierarchical image database,” in *CVPR*, 2009.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li 和 L. Fei-Fei，“ImageNet：大规模层次图像数据库，”
    在 *CVPR*，2009年。'
- en: '[9] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang,
    A. Karpathy, A. Khosla, M. Bernstein *et al.*, “Imagenet large scale visual recognition
    challenge,” *IJCV*, vol. 115, no. 3, 2015.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang,
    A. Karpathy, A. Khosla, M. Bernstein *等*，“ImageNet 大规模视觉识别挑战，” *IJCV*，第115卷，第3期，2015年。'
- en: '[10] M. D. Zeiler and R. Fergus, “Visualizing and understanding convolutional
    networks,” in *ECCV*.   Springer, 2014.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] M. D. Zeiler 和 R. Fergus，“可视化和理解卷积网络，” 在 *ECCV*。Springer，2014年。'
- en: '[11] M. W. Craven and J. W. Shavlik, “Visualizing learning and computation
    in artificial neural networks,” *International Journal on Artificial Intelligence
    Tools*, vol. 1, no. 03, 1992.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] M. W. Craven 和 J. W. Shavlik，“在人工神经网络中可视化学习和计算，” *国际人工智能工具期刊*，第1卷，第03期，1992年。'
- en: '[12] M. J. Streeter, M. O. Ward, and S. A. Alvarez, “NVIS: An interactive visualization
    tool for neural networks,” in *Visual Data Exploration and Analysis VIII*, vol.
    4302.   International Society for Optics and Photonics, 2001.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] M. J. Streeter, M. O. Ward 和 S. A. Alvarez，“NVIS：一个用于神经网络的交互式可视化工具，” 在
    *视觉数据探索与分析 VIII*，第4302卷。国际光学和光子学学会，2001年。'
- en: '[13] F.-Y. Tzeng and K.-L. Ma, “Opening the black box: Data driven visualization
    of neural networks,” in *IEEE Visualization*, 2005.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] F.-Y. Tzeng 和 K.-L. Ma，“打开黑箱：神经网络的数据驱动可视化，” 在 *IEEE 可视化*，2005年。'
- en: '[14] M. Liu, J. Shi, Z. Li, C. Li, J. Zhu, and S. Liu, “Towards better analysis
    of deep convolutional neural networks,” *IEEE TVCG*, vol. 23, no. 1, 2017.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] M. Liu, J. Shi, Z. Li, C. Li, J. Zhu 和 S. Liu，“朝着更好的深度卷积神经网络分析，” *IEEE
    TVCG*，第23卷，第1期，2017年。'
- en: '[15] K. Wongsuphasawat, D. Smilkov, J. Wexler, J. Wilson, D. Mané, D. Fritz,
    D. Krishnan, F. B. Viégas, and M. Wattenberg, “Visualizing dataflow graphs of
    deep learning models in TensorFlow,” *IEEE TVCG*, vol. 24, no. 1, 2018.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] K. Wongsuphasawat, D. Smilkov, J. Wexler, J. Wilson, D. Mané, D. Fritz,
    D. Krishnan, F. B. Viégas 和 M. Wattenberg，“在 TensorFlow 中可视化深度学习模型的数据流图，” *IEEE
    TVCG*，第24卷，第1期，2018年。'
- en: '[16] D. Smilkov, S. Carter, D. Sculley, F. B. Viegas, and M. Wattenberg, “Direct-manipulation
    visualization of deep networks,” in *ICML Workshop on Vis for Deep Learning*,
    2016.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] D. Smilkov, S. Carter, D. Sculley, F. B. Viegas 和 M. Wattenberg，“深度网络的直接操控可视化，”
    在 *ICML 深度学习可视化工作坊*，2016年。'
- en: '[17] J. Lu, W. Chen, Y. Ma, J. Ke, Z. Li, F. Zhang, and R. Maciejewski, “Recent
    progress and trends in predictive visual analytics,” *Frontiers of Computer Science*,
    2017.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] J. Lu, W. Chen, Y. Ma, J. Ke, Z. Li, F. Zhang 和 R. Maciejewski，“预测视觉分析的最新进展和趋势，”
    *计算机科学前沿*，2017年。'
- en: '[18] Y. Lu, R. Garcia, B. Hansen, M. Gleicher, and R. Maciejewski, “The state-of-the-art
    in predictive visual analytics,” in *Computer Graphics Forum*, vol. 36, no. 3.   Wiley
    Online Library, 2017.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Y. Lu, R. Garcia, B. Hansen, M. Gleicher, 和 R. Maciejewski，“预测性可视分析的最新进展，”见
    *计算机图形论坛*，第36卷，第3期。Wiley Online Library, 2017.'
- en: '[19] D. Ren, S. Amershi, B. Lee, J. Suh, and J. D. Williams, “Squares: Supporting
    interactive performance analysis for multiclass classifiers,” *IEEE TVCG*, vol. 23,
    no. 1, 2017.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] D. Ren, S. Amershi, B. Lee, J. Suh, 和 J. D. Williams，“Squares：支持多类别分类器的交互式性能分析，”
    *IEEE TVCG*，第23卷，第1期，2017.'
- en: '[20] S. Amershi, M. Cakmak, W. B. Knox, and T. Kulesza, “Power to the people:
    The role of humans in interactive machine learning,” *AI Magazine*, vol. 35, no. 4,
    2014.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] S. Amershi, M. Cakmak, W. B. Knox, 和 T. Kulesza，“赋予人们权力：人类在交互式机器学习中的角色，”
    *AI 杂志*，第35卷，第4期，2014.'
- en: '[21] D. Sacha, M. Sedlmair, L. Zhang, J. A. Lee, D. Weiskopf, S. North, and
    D. Keim, “Human-centered machine learning through interactive visualization,”
    in *ESANN*, 2016.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] D. Sacha, M. Sedlmair, L. Zhang, J. A. Lee, D. Weiskopf, S. North, 和 D.
    Keim，“通过交互式可视化实现以人为本的机器学习，”见 *ESANN*，2016.'
- en: '[22] C. Seifert, A. Aamir, A. Balagopalan, D. Jain, A. Sharma, S. Grottel,
    and S. Gumhold, “Visualizations of deep neural networks in computer vision: A
    survey,” in *Transparent Data Mining for Big and Small Data*.   Springer, 2017.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] C. Seifert, A. Aamir, A. Balagopalan, D. Jain, A. Sharma, S. Grottel,
    和 S. Gumhold，“计算机视觉中深度神经网络的可视化：综述，”见 *透明数据挖掘：大数据与小数据*。Springer, 2017.'
- en: '[23] H. Zeng, “Towards better understanding of deep learning with visualization,”
    *The Hong Kong University of Science and Technology*, 2016.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] H. Zeng，“通过可视化更好地理解深度学习，” *香港科技大学*，2016.'
- en: '[24] S. Liu, X. Wang, M. Liu, and J. Zhu, “Towards better analysis of machine
    learning models: A visual analytics perspective,” *Visual Informatics*, vol. 1,
    no. 1, 2017.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] S. Liu, X. Wang, M. Liu, 和 J. Zhu，“朝向更好的机器学习模型分析：一个可视分析的视角，” *视觉信息学*，第1卷，第1期，2017.'
- en: '[25] J. Choo and S. Liu, “Visual analytics for explainable deep learning,”
    *IEEE Computer Graphics and Applications*, 2018.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] J. Choo 和 S. Liu，“可解释深度学习的可视分析，” *IEEE 计算机图形与应用*，2018.'
- en: '[26] I. Goodfellow, Y. Bengio, and A. Courville, *Deep Learning*.   MIT Press,
    2016, [http://www.deeplearningbook.org](http://www.deeplearningbook.org).'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] I. Goodfellow, Y. Bengio, 和 A. Courville, *深度学习*。MIT Press, 2016, [http://www.deeplearningbook.org](http://www.deeplearningbook.org).'
- en: '[27] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado,
    A. Davis, J. Dean, M. Devin *et al.*, “TensorFlow: Large-scale machine learning
    on heterogeneous distributed systems,” *arXiv:1603.04467*, 2016.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado,
    A. Davis, J. Dean, M. Devin *等*，“TensorFlow：异构分布式系统上的大规模机器学习，” *arXiv:1603.04467*，2016.'
- en: '[28] D. Bau, B. Zhou, A. Khosla, A. Oliva, and A. Torralba, “Network Dissection:
    Quantifying interpretability of deep visual representations,” in *CVPR*, 2017.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] D. Bau, B. Zhou, A. Khosla, A. Oliva, 和 A. Torralba，“网络解剖：量化深度视觉表征的可解释性，”见
    *CVPR*，2017.'
- en: '[29] A. Bilal, A. Jourabloo, M. Ye, X. Liu, and L. Ren, “Do convolutional neural
    networks learn class hierarchy?” *IEEE TVCG*, vol. 24, no. 1, pp. 152–162, 2018.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] A. Bilal, A. Jourabloo, M. Ye, X. Liu, 和 L. Ren，“卷积神经网络是否学习类别层次结构？” *IEEE
    TVCG*，第24卷，第1期，第152–162页，2018.'
- en: '[30] M. Bojarski, A. Choromanska, K. Choromanski, B. Firner, L. Jackel, U. Muller,
    and K. Zieba, “Visualbackprop: visualizing cnns for autonomous driving,” *arXiv:1611.05418*,
    2016.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] M. Bojarski, A. Choromanska, K. Choromanski, B. Firner, L. Jackel, U.
    Muller, 和 K. Zieba，“Visualbackprop: 可视化用于自动驾驶的卷积神经网络，” *arXiv:1611.05418*，2016.'
- en: '[31] D. Bruckner, “Ml-o-scope: a diagnostic visualization system for deep machine
    learning pipelines,” Master’s thesis, EECS Department, University of California,
    Berkeley, May 2014\. [Online]. Available: [http://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-99.html](http://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-99.html)'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] D. Bruckner，“Ml-o-scope：深度机器学习管道的诊断可视化系统，”硕士论文，加州大学伯克利分校EECS系，2014年5月。[在线].
    可用：[http://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-99.html](http://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-99.html)'
- en: '[32] S. Carter, D. Ha, I. Johnson, and C. Olah, “Experiments in handwriting
    with a neural network,” *Distill*, 2016.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] S. Carter, D. Ha, I. Johnson, 和 C. Olah，“用神经网络进行手写实验，” *Distill*，2016.'
- en: '[33] D. Cashman, G. Patterson, A. Mosca, and R. Chang, “RNNbow: Visualizing
    learning via backpropagation gradients in recurrent neural networks,” in *Workshop
    on Visual Analytics for Deep Learning*, 2017.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] D. Cashman, G. Patterson, A. Mosca, 和 R. Chang，“RNNbow：通过回传梯度可视化递归神经网络的学习，”见
    *深度学习可视分析研讨会*，2017.'
- en: '[34] J. Chae, S. Gao, A. Ramanthan, C. Steed, and G. D. Tourassi, “Visualization
    for classification in deep neural networks,” in *Workshop on Visual Analytics
    for Deep Learning*, 2017.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] J. Chae, S. Gao, A. Ramanthan, C. Steed, 和 G. D. Tourassi，“深度神经网络分类的可视化，”在*Workshop
    on Visual Analytics for Deep Learning*，2017年。'
- en: '[35] S. Chung, C. Park, S. Suh, K. Kang, J. Choo, and B. C. Kwon, “ReVACNN:
    Steering convolutional neural network via real-time visual analytics,” in *NIPS
    Workshop on Future of Interactive Learning Machines*, 2016.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] S. Chung, C. Park, S. Suh, K. Kang, J. Choo, 和 B. C. Kwon，“ReVACNN: 通过实时视觉分析引导卷积神经网络，”在*NIPS
    Workshop on Future of Interactive Learning Machines*，2016年。'
- en: '[36] Y. Goyal, A. Mohapatra, D. Parikh, and D. Batra, “Towards transparent
    ai systems: Interpreting visual question answering models,” *arXiv:1608.08974*,
    2016.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Y. Goyal, A. Mohapatra, D. Parikh, 和 D. Batra，“迈向透明的人工智能系统：解释视觉问答模型，”*arXiv:1608.08974*，2016年。'
- en: '[37] A. W. Harley, “An interactive node-link visualization of convolutional
    neural networks,” in *ISVC*, 2015, pp. 867–877.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] A. W. Harley，“卷积神经网络的互动节点-链接可视化，”在*ISVC*，2015年，第867–877页。'
- en: '[38] F. Hohman, N. Hodas, and D. H. Chau, “ShapeShop: Towards understanding
    deep learning representations via interactive experimentation,” in *CHI, Extended
    Abstracts*, 2017.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] F. Hohman, N. Hodas, 和 D. H. Chau，“ShapeShop: 通过互动实验理解深度学习表示，”在*CHI, Extended
    Abstracts*，2017年。'
- en: '[39] M. Kahng, P. Andrews, A. Kalro, and D. H. Chau, “ActiVis: Visual exploration
    of industry-scale deep neural network models,” *IEEE TVCG*, vol. 24, no. 1, 2018.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] M. Kahng, P. Andrews, A. Kalro, 和 D. H. Chau，“ActiVis: 行业规模深度神经网络模型的可视化探索，”*IEEE
    TVCG*，第24卷，第1期，2018年。'
- en: '[40] A. Karpathy, J. Johnson, and L. Fei-Fei, “Visualizing and understanding
    recurrent networks,” *arXiv:1506.02078*, 2015.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] A. Karpathy, J. Johnson, 和 L. Fei-Fei，“可视化和理解递归网络，”*arXiv:1506.02078*，2015年。'
- en: '[41] J. Li, X. Chen, E. Hovy, and D. Jurafsky, “Visualizing and understanding
    neural models in nlp,” *arXiv:1506.01066*, 2015.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] J. Li, X. Chen, E. Hovy, 和 D. Jurafsky，“可视化和理解 NLP 中的神经模型，”*arXiv:1506.01066*，2015年。'
- en: '[42] M. Liu, J. Shi, K. Cao, J. Zhu, and S. Liu, “Analyzing the training processes
    of deep generative models,” *IEEE TVCG*, vol. 24, no. 1, 2018.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] M. Liu, J. Shi, K. Cao, J. Zhu, 和 S. Liu，“分析深度生成模型的训练过程，”*IEEE TVCG*，第24卷，第1期，2018年。'
- en: '[43] Y. Ming, S. Cao, R. Zhang, Z. Li, and Y. Chen, “Understanding hidden memories
    of recurrent neural networks,” *VAST*, 2017.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Y. Ming, S. Cao, R. Zhang, Z. Li, 和 Y. Chen，“理解递归神经网络的隐藏记忆，”*VAST*，2017年。'
- en: '[44] A. P. Norton and Y. Qi, “Adversarial-Playground: A visualization suite
    showing how adversarial examples fool deep learning,” in *VizSec*.   IEEE, 2017.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] A. P. Norton 和 Y. Qi，“Adversarial-Playground: 一个展示对抗样本如何欺骗深度学习的可视化套件，”在*VizSec*。IEEE，2017年。'
- en: '[45] C. Olah, “Visualizing MNIST,” *Olah’s Blog*, 2014\. [Online]. Available:
    [http://colah.github.io/posts/2014-10-Visualizing-MNIST/](http://colah.github.io/posts/2014-10-Visualizing-MNIST/)'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] C. Olah，“可视化 MNIST，”*Olah’s Blog*，2014年。[在线]. 可用链接: [http://colah.github.io/posts/2014-10-Visualizing-MNIST/](http://colah.github.io/posts/2014-10-Visualizing-MNIST/)'
- en: '[46] C. Olah, A. Satyanarayan, I. Johnson, S. Carter, L. Schubert, K. Ye, and
    A. Mordvintsev, “The building blocks of interpretability,” *Distill*, 2018.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] C. Olah, A. Satyanarayan, I. Johnson, S. Carter, L. Schubert, K. Ye, 和
    A. Mordvintsev，“可解释性的构建块，”*Distill*，2018年。'
- en: '[47] N. Pezzotti, T. Höllt, J. Van Gemert, B. P. Lelieveldt, E. Eisemann, and
    A. Vilanova, “DeepEyes: Progressive visual analytics for designing deep neural
    networks,” *IEEE TVCG*, vol. 24, no. 1, 2018.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] N. Pezzotti, T. Höllt, J. Van Gemert, B. P. Lelieveldt, E. Eisemann, 和
    A. Vilanova，“DeepEyes: 进阶视觉分析用于设计深度神经网络，”*IEEE TVCG*，第24卷，第1期，2018年。'
- en: '[48] P. E. Rauber, S. G. Fadel, A. X. Falcao, and A. C. Telea, “Visualizing
    the hidden activity of artificial neural networks,” *IEEE TVCG*, vol. 23, no. 1,
    2017.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] P. E. Rauber, S. G. Fadel, A. X. Falcao, 和 A. C. Telea，“可视化人工神经网络的隐藏活动，”*IEEE
    TVCG*，第23卷，第1期，2017年。'
- en: '[49] C. Robinson, F. Hohman, and B. Dilkina, “A deep learning approach for
    population estimation from satellite imagery,” in *SIGSPATIAL Workshop on Geospatial
    Humanities*, 2017.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] C. Robinson, F. Hohman, 和 B. Dilkina，“一种基于深度学习的卫星图像人口估计方法，”在*SIGSPATIAL
    Workshop on Geospatial Humanities*，2017年。'
- en: '[50] X. Rong and E. Adar, “Visual tools for debugging neural language models,”
    in *ICML Workshop on Vis for Deep Learning*, 2016.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] X. Rong 和 E. Adar，“用于调试神经语言模型的视觉工具，”在*ICML Workshop on Vis for Deep Learning*，2016年。'
- en: '[51] D. Smilkov, N. Thorat, C. Nicholson, E. Reif, F. B. Viégas, and M. Wattenberg,
    “Embedding Projector: Interactive visualization and interpretation of embeddings,”
    in *NIPS Workshop on Interpretable ML in Complex Systems*, 2016.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] D. Smilkov, N. Thorat, C. Nicholson, E. Reif, F. B. Viégas, 和 M. Wattenberg，“Embedding
    Projector: 嵌入的互动可视化和解释，”在*NIPS Workshop on Interpretable ML in Complex Systems*，2016年。'
- en: '[52] H. Strobelt, S. Gehrmann, H. Pfister, and A. M. Rush, “LSTMVis: A tool
    for visual analysis of hidden state dynamics in recurrent neural networks,” *IEEE
    TVCG*, vol. 24, no. 1, 2018.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] H. Strobelt, S. Gehrmann, H. Pfister, 和 A. M. Rush，“LSTMVis：一个用于递归神经网络隐状态动态可视化的工具”，*IEEE
    TVCG*，第24卷，第1期，2018年。'
- en: '[53] J. Wang, L. Gou, H. Yang, and H.-W. Shen, “GANViz: A visual analytics
    approach to understand the adversarial game,” *IEEE TVCG*, 2018.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] J. Wang, L. Gou, H. Yang, 和 H.-W. Shen，“GANViz：一种用于理解对抗游戏的可视分析方法”，*IEEE
    TVCG*，2018年。'
- en: '[54] B. Webster, “Now anyone can explore machine learning, no coding required,”
    *Google Official Blog*, 2017\. [Online]. Available: [https://www.blog.google/topics/machine-learning/now-anyone-can-explore-machine-learning-no-coding-required/](https://www.blog.google/topics/machine-learning/now-anyone-can-explore-machine-learning-no-coding-required/)'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] B. Webster，“现在任何人都可以探索机器学习，无需编码”，*谷歌官方博客*，2017年。[在线]. 可用: [https://www.blog.google/topics/machine-learning/now-anyone-can-explore-machine-learning-no-coding-required/](https://www.blog.google/topics/machine-learning/now-anyone-can-explore-machine-learning-no-coding-required/)'
- en: '[55] J. Yosinski, J. Clune, A. Nguyen, T. Fuchs, and H. Lipson, “Understanding
    neural networks through deep visualization,” in *ICML Deep Learning Workshop*,
    2015.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] J. Yosinski, J. Clune, A. Nguyen, T. Fuchs, 和 H. Lipson，“通过深度可视化理解神经网络”，在*ICML深度学习研讨会*，2015年。'
- en: '[56] T. Zahavy, N. Ben-Zrihem, and S. Mannor, “Graying the black box: Understanding
    DQNs,” in *ICML*, 2016.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] T. Zahavy, N. Ben-Zrihem, 和 S. Mannor，“揭开黑箱：理解DQN”，在*ICML*，2016年。'
- en: '[57] H. Zeng, H. Haleem, X. Plantaz, N. Cao, and H. Qu, “CNNComparator: Comparative
    analytics of convolutional neural networks,” in *Workshop on Visual Analytics
    for Deep Learning*, 2017.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] H. Zeng, H. Haleem, X. Plantaz, N. Cao, 和 H. Qu，“CNNComparator：卷积神经网络的比较分析”，在*视觉分析与深度学习研讨会*，2017年。'
- en: '[58] W. Zhong, C. Xie, Y. Zhong, Y. Wang, W. Xu, S. Cheng, and K. Mueller,
    “Evolutionary visual analysis of deep neural networks,” in *ICML Workshop on Vis
    for Deep Learning*, 2017.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] W. Zhong, C. Xie, Y. Zhong, Y. Wang, W. Xu, S. Cheng, 和 K. Mueller，“深度神经网络的进化视觉分析”，在*ICML视觉与深度学习研讨会*，2017年。'
- en: '[59] J.-Y. Zhu, P. Krähenbühl, E. Shechtman, and A. A. Efros, “Generative visual
    manipulation on the natural image manifold,” in *ECCV*.   Springer, 2016.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] J.-Y. Zhu, P. Krähenbühl, E. Shechtman, 和 A. A. Efros，“在自然图像流形上的生成视觉操控”，在*ECCV*。Springer，2016年。'
- en: '[60] Z. C. Lipton, “The mythos of model interpretability,” *arXiv:1606.03490*,
    2016.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Z. C. Lipton，“模型可解释性的神话”，*arXiv:1606.03490*，2016年。'
- en: '[61] G. Montavon, W. Samek, and K.-R. Müller, “Methods for interpreting and
    understanding deep neural networks,” *Digital Signal Processing*, 2017.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] G. Montavon, W. Samek, 和 K.-R. Müller，“解释和理解深度神经网络的方法”，*数字信号处理*，2017年。'
- en: '[62] T. Miller, “Explanation in artificial intelligence: Insights from the
    social sciences,” *arXiv:1706.07269*, 2017.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] T. Miller，“人工智能中的解释：来自社会科学的见解”，*arXiv:1706.07269*，2017年。'
- en: '[63] A. Weller, “Challenges for transparency,” *ICML Workshop on Human Interpretability
    in ML*, 2017.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] A. Weller，“透明性的挑战”，*ICML人类可解释性研讨会*，2017年。'
- en: '[64] F. Offert, “”i know it when I see it”. visualization and intuitive interpretability,”
    *NIPS Symposium on Interpretable ML*, 2017.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] F. Offert，““我知道我看到的是什么”。可视化和直观可解释性”，*NIPS可解释机器学习研讨会*，2017年。'
- en: '[65] M. Johnson, M. Schuster, Q. V. Le, M. Krikun, Y. Wu, Z. Chen, N. Thorat,
    F. Viégas, M. Wattenberg, G. Corrado *et al.*, “Google’s multilingual neural machine
    translation system: enabling zero-shot translation,” *arXiv:1611.04558*, 2016.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] M. Johnson, M. Schuster, Q. V. Le, M. Krikun, Y. Wu, Z. Chen, N. Thorat,
    F. Viégas, M. Wattenberg, G. Corrado *等*，“谷歌的多语言神经机器翻译系统：实现零样本翻译”，*arXiv:1611.04558*，2016年。'
- en: '[66] L. M. Zintgraf, T. S. Cohen, T. Adel, and M. Welling, “Visualizing deep
    neural network decisions: Prediction difference analysis,” *arXiv:1702.04595*,
    2017.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] L. M. Zintgraf, T. S. Cohen, T. Adel, 和 M. Welling，“可视化深度神经网络决策：预测差异分析”，*arXiv:1702.04595*，2017年。'
- en: '[67] L. Li, J. Tompkin, P. Michalatos, and H. Pfister, “Hierarchical visual
    feature analysis for city street view datasets,” in *Workshop on Visual Analytics
    for Deep Learning*, 2017.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] L. Li, J. Tompkin, P. Michalatos, 和 H. Pfister，“城市街景数据集的层次视觉特征分析”，在*视觉分析与深度学习研讨会*，2017年。'
- en: '[68] D. Erhan, Y. Bengio, A. Courville, and P. Vincent, “Visualizing higher-layer
    features of a deep network,” *University of Montreal*, vol. 1341, 2009.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] D. Erhan, Y. Bengio, A. Courville, 和 P. Vincent，“可视化深度网络的高级特征”，*蒙特利尔大学*，第1341卷，2009年。'
- en: '[69] R. R. Selvaraju, A. Das, R. Vedantam, M. Cogswell, D. Parikh, and D. Batra,
    “Grad-CAM: Why did you say that? visual explanations from deep networks via gradient-based
    localization,” *arXiv:1610.02391*, 2016.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] R. R. Selvaraju, A. Das, R. Vedantam, M. Cogswell, D. Parikh, 和 D. Batra，“Grad-CAM：你为什么这么说？通过基于梯度的定位获得深度网络的视觉解释，”
    *arXiv:1610.02391*，2016。'
- en: '[70] A. Nguyen, A. Dosovitskiy, J. Yosinski, T. Brox, and J. Clune, “Synthesizing
    the preferred inputs for neurons in neural networks via deep generator networks,”
    in *NIPS*, 2016.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] A. Nguyen, A. Dosovitskiy, J. Yosinski, T. Brox, 和 J. Clune，“通过深度生成网络合成神经网络中神经元的首选输入，”
    在 *NIPS*，2016。'
- en: '[71] K. Patel, J. Fogarty, J. A. Landay, and B. Harrison, “Investigating statistical
    machine learning as a tool for software development,” in *CHI*, 2008.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] K. Patel, J. Fogarty, J. A. Landay, 和 B. Harrison，“研究统计机器学习作为软件开发工具，”
    在 *CHI*，2008。'
- en: '[72] T. Kulesza, M. Burnett, W.-K. Wong, and S. Stumpf, “Principles of explanatory
    debugging to personalize interactive machine learning,” in *IUI*, 2015.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] T. Kulesza, M. Burnett, W.-K. Wong, 和 S. Stumpf，“解释性调试原则以个性化交互式机器学习，”
    在 *IUI*，2015。'
- en: '[73] B. Nushi, E. Kamar, E. Horvitz, and D. Kossmann, “On human intellect and
    machine failures: Troubleshooting integrative machine learning systems,” in *AAAI*,
    2017.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] B. Nushi, E. Kamar, E. Horvitz, 和 D. Kossmann，“论人类智能与机器故障：排查集成机器学习系统，”
    在 *AAAI*，2017。'
- en: '[74] E. Alexander and M. Gleicher, “Task-driven comparison of topic models,”
    *IEEE TVCG*, vol. 22, no. 1, 2016.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] E. Alexander 和 M. Gleicher，“任务驱动的主题模型比较，” *IEEE TVCG*，第 22 卷，第 1 期，2016。'
- en: '[75] H. B. McMahan, G. Holt, D. Sculley, M. Young, D. Ebner, J. Grady, L. Nie,
    T. Phillips, E. Davydov, D. Golovin, S. Chikkerur, D. Liu, M. Wattenberg, A. M.
    Hrafnkelsson, T. Boulos, and J. Kubica, “Ad click prediction: A view from the
    trenches,” in *KDD*, 2013.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] H. B. McMahan, G. Holt, D. Sculley, M. Young, D. Ebner, J. Grady, L. Nie,
    T. Phillips, E. Davydov, D. Golovin, S. Chikkerur, D. Liu, M. Wattenberg, A. M.
    Hrafnkelsson, T. Boulos, 和 J. Kubica，“广告点击预测：来自战壕的视角，” 在 *KDD*，2013。'
- en: '[76] M. Kahng, D. Fang, and D. H. P. Chau, “Visual exploration of machine learning
    results using data cube analysis,” in *SIGMOD Workshop on Human-In-the-Loop Data
    Analytics*, 2016.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] M. Kahng, D. Fang, 和 D. H. P. Chau，“使用数据立方体分析进行机器学习结果的可视化探索，” 在 *SIGMOD
    Workshop on Human-In-the-Loop Data Analytics*，2016。'
- en: '[77] W. Yu, K. Yang, Y. Bai, H. Yao, and Y. Rui, “Visualizing and comparing
    convolutional neural networks,” *arXiv:1412.6631*, 2014.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] W. Yu, K. Yang, Y. Bai, H. Yao, 和 Y. Rui，“可视化和比较卷积神经网络，” *arXiv:1412.6631*，2014。'
- en: '[78] M. Wattenberg, F. Viégas, and I. Johnson, “How to use t-SNE effectively,”
    *Distill*, 2016.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] M. Wattenberg, F. Viégas, 和 I. Johnson，“如何有效使用 t-SNE，” *Distill*，2016。'
- en: '[79] L. v. d. Maaten and G. Hinton, “Visualizing data using t-SNE,” *JMLR*,
    vol. 9, no. Nov, 2008.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] L. v. d. Maaten 和 G. Hinton，“使用 t-SNE 可视化数据，” *JMLR*，第 9 卷，第 Nov 期，2008。'
- en: '[80] A. Nguyen, J. Yosinski, and J. Clune, “Multifaceted feature visualization:
    Uncovering the different types of features learned by each neuron in deep neural
    networks,” in *ICML Workshop on Vis for Deep Learning*, 2016.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] A. Nguyen, J. Yosinski, 和 J. Clune，“多面特征可视化：揭示深度神经网络中每个神经元学习的不同类型特征，”
    在 *ICML Workshop on Vis for Deep Learning*，2016。'
- en: '[81] P. E. Rauber, A. X. Falcão, and A. C. Telea, “Visualizing time-dependent
    data using dynamic t-sne,” *EuroVis*, vol. 2, no. 5, 2016.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] P. E. Rauber, A. X. Falcão, 和 A. C. Telea，“使用动态 t-SNE 可视化时间相关数据，” *EuroVis*，第
    2 卷，第 5 期，2016。'
- en: '[82] S. Liu, P.-T. Bremer, J. J. Thiagarajan, V. Srikumar, B. Wang, Y. Livnat,
    and V. Pascucci, “Visual exploration of semantic relationships in neural word
    embeddings,” *IEEE TVCG*, vol. 24, no. 1, 2018.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] S. Liu, P.-T. Bremer, J. J. Thiagarajan, V. Srikumar, B. Wang, Y. Livnat,
    和 V. Pascucci，“在神经词嵌入中可视化语义关系，” *IEEE TVCG*，第 24 卷，第 1 期，2018。'
- en: '[83] C. Vondrick, A. Khosla, T. Malisiewicz, and A. Torralba, “Hoggles: Visualizing
    object detection features,” in *ICCV*, 2013.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] C. Vondrick, A. Khosla, T. Malisiewicz, 和 A. Torralba，“Hoggles：可视化对象检测特征，”
    在 *ICCV*，2013。'
- en: '[84] X. Rong, “word2vec parameter learning explained,” *arXiv:1411.2738*, 2014.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] X. Rong，“word2vec 参数学习解释，” *arXiv:1411.2738*，2014。'
- en: '[85] D. Park, S. Kim, J. Lee, J. Choo, N. Diakopoulos, and N. Elmqvist, “ConceptVector:
    text visual analytics via interactive lexicon building using word embedding,”
    *IEEE TVCG*, vol. 24, no. 1, 2018.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] D. Park, S. Kim, J. Lee, J. Choo, N. Diakopoulos, 和 N. Elmqvist，“ConceptVector：通过使用词嵌入的交互式词汇构建进行文本可视分析，”
    *IEEE TVCG*，第 24 卷，第 1 期，2018。'
- en: '[86] D. S. Weld and G. Bansal, “Intelligible artificial intelligence,” *arXiv:1803.04263*,
    2018.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] D. S. Weld 和 G. Bansal，“可理解的人工智能，” *arXiv:1803.04263*，2018。'
- en: '[87] C. Olah and S. Carter, “Research debt,” *Distill*, 2017.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] C. Olah 和 S. Carter，“研究债务，” *Distill*，2017。'
- en: '[88] C. Olah, A. Mordvintsev, and L. Schubert, “Feature visualization,” *Distill*,
    2017.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] C. Olah, A. Mordvintsev, 和 L. Schubert，“特征可视化，” *Distill*，2017。'
- en: '[89] A. Mahendran and A. Vedaldi, “Visualizing deep convolutional neural networks
    using natural pre-images,” *IJCV*, vol. 120, no. 3, 2016.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] A. Mahendran 和 A. Vedaldi，“使用自然预图像可视化深度卷积神经网络”，*《计算机视觉国际期刊》*，第 120 卷，第
    3 期，2016 年。'
- en: '[90] F. Grün, C. Rupprecht, N. Navab, and F. Tombari, “A taxonomy and library
    for visualizing learned features in convolutional neural networks,” *ICML Workshop
    on Vis for Deep Learning*, 2016.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] F. Grün, C. Rupprecht, N. Navab 和 F. Tombari，“用于可视化卷积神经网络中学习特征的分类法和库”，*ICML
    深度学习可视化研讨会*，2016 年。'
- en: '[91] P.-J. Kindermans, K. T. Schütt, M. Alber, K.-R. Müller, and S. Dähne,
    “Learning how to explain neural networks: Patternnet and patternattribution,”
    *arXiv:1705.05598*, 2017.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] P.-J. Kindermans, K. T. Schütt, M. Alber, K.-R. Müller 和 S. Dähne，“学习如何解释神经网络：Patternnet
    和 patternattribution”，*arXiv:1705.05598*，2017 年。'
- en: '[92] H. Li, K. Mueller, and X. Chen, “Beyond saliency: understanding convolutional
    neural networks from saliency prediction on layer-wise relevance propagation,”
    *arXiv:1712.08268*, 2017.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] H. Li, K. Mueller 和 X. Chen，“超越显著性：从显著性预测到逐层相关传播理解卷积神经网络”，*arXiv:1712.08268*，2017
    年。'
- en: '[93] D. Smilkov, N. Thorat, B. Kim, F. Viégas, and M. Wattenberg, “SmoothGrad:
    removing noise by adding noise,” in *ICML Workshop on Vis for Deep Learning*,
    2017.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] D. Smilkov, N. Thorat, B. Kim, F. Viégas 和 M. Wattenberg，“SmoothGrad：通过添加噪声去除噪声”，在
    *ICML 深度学习可视化研讨会*，2017 年。'
- en: '[94] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba, “Learning
    deep features for discriminative localization,” in *CVPR*, 2016.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva 和 A. Torralba，“为判别性定位学习深度特征”，在
    *CVPR*，2016 年。'
- en: '[95] A. Dosovitskiy and T. Brox, “Inverting visual representations with convolutional
    networks,” in *CVPR*, 2016.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] A. Dosovitskiy 和 T. Brox，“用卷积网络反转视觉表示”，在 *CVPR*，2016 年。'
- en: '[96] A. Mahendran and A. Vedaldi, “Understanding deep image representations
    by inverting them,” in *CVPR*, 2015.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] A. Mahendran 和 A. Vedaldi，“通过反转理解深度图像表示”，在 *CVPR*，2015 年。'
- en: '[97] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba, “Object detectors
    emerge in deep scene CNNs,” *arXiv:1412.6856*, 2014.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva 和 A. Torralba，“对象检测器在深度场景 CNN
    中出现”，*arXiv:1412.6856*，2014 年。'
- en: '[98] A. Mordvintsev, C. Olah, and M. Tyka, “Inceptionism: Going deeper into
    neural networks,” *Google Research Blog*, 2015.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] A. Mordvintsev, C. Olah 和 M. Tyka，“Inceptionism：深入神经网络”，*Google Research
    Blog*，2015 年。'
- en: '[99] J. T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller, “Striving
    for simplicity: The all convolutional net,” *arXiv:1412.6806*, 2014.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] J. T. Springenberg, A. Dosovitskiy, T. Brox 和 M. Riedmiller，“追求简洁：全卷积网络”，*arXiv:1412.6806*，2014
    年。'
- en: '[100] D. Wei, B. Zhou, A. Torrabla, and W. Freeman, “Understanding intra-class
    knowledge inside CNN,” *arXiv:1507.02379*, 2015.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] D. Wei, B. Zhou, A. Torrabla 和 W. Freeman，“理解 CNN 内的类内知识”，*arXiv:1507.02379*，2015
    年。'
- en: '[101] A. Nguyen, J. Yosinski, Y. Bengio, A. Dosovitskiy, and J. Clune, “Plug
    & play generative networks: Conditional iterative generation of images in latent
    space,” *arXiv:1612.00005*, 2016.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] A. Nguyen, J. Yosinski, Y. Bengio, A. Dosovitskiy 和 J. Clune，“即插即用生成网络：在潜在空间中条件迭代生成图像”，*arXiv:1612.00005*，2016
    年。'
- en: '[102] Y. Bengio *et al.*, “Learning deep architectures for ai,” *Foundations
    and trends in Machine Learning*, vol. 2, no. 1, 2009.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] Y. Bengio *等人*，“为 AI 学习深度架构”，*《机器学习中的基础与趋势》*，第 2 卷，第 1 期，2009 年。'
- en: '[103] S. Carter and M. Nielsen, “Using artificial intelligence to augment human
    intelligence,” *Distill*, 2017.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] S. Carter 和 M. Nielsen，“使用人工智能增强人类智能”，*Distill*，2017 年。'
- en: '[104] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan, “Show and tell: A neural
    image caption generator,” in *CVPR*, 2015.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] O. Vinyals, A. Toshev, S. Bengio 和 D. Erhan，“展示与讲述：一个神经图像字幕生成器”，在 *CVPR*，2015
    年。'
- en: '[105] S. Antol, A. Agrawal, J. Lu, M. Mitchell, D. Batra, C. Lawrence Zitnick,
    and D. Parikh, “Vqa: Visual question answering,” in *ICCV*, 2015.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] S. Antol, A. Agrawal, J. Lu, M. Mitchell, D. Batra, C. Lawrence Zitnick
    和 D. Parikh，“VQA：视觉问答”，在 *ICCV*，2015 年。'
- en: '[106] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, and Y. Bengio, “Generative adversarial nets,” in *NIPS*, 2014.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S.
    Ozair, A. Courville 和 Y. Bengio，“生成对抗网络”，在 *NIPS*，2014 年。'
- en: '[107] I. Goodfellow, “NIPS 2016 tutorial: Generative adversarial networks,”
    *arXiv:1701.00160*, 2016.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] I. Goodfellow，“NIPS 2016 教程：生成对抗网络”，*arXiv:1701.00160*，2016 年。'
- en: '[108] S. Liu, D. Maljovec, B. Wang, P.-T. Bremer, and V. Pascucci, “Visualizing
    high-dimensional data: Advances in the past decade,” *IEEE TVCG*, vol. 23, no. 3,
    2017.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] S. Liu, D. Maljovec, B. Wang, P.-T. Bremer 和 V. Pascucci，“高维数据可视化：过去十年的进展”，*IEEE
    TVCG*，第 23 卷，第 3 期，2017 年。'
- en: '[109] W. Samek, A. Binder, G. Montavon, S. Lapuschkin, and K.-R. Müller, “Evaluating
    the visualization of what a deep neural network has learned,” *IEEE transactions
    on neural networks and learning systems*, 2017.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] W. Samek, A. Binder, G. Montavon, S. Lapuschkin, 和 K.-R. Müller, “评估深度神经网络所学内容的可视化,”
    *IEEE transactions on neural networks and learning systems*, 2017。'
- en: '[110] M. T. Ribeiro, S. Singh, and C. Guestrin, “Why should I trust you?: Explaining
    the predictions of any classifier,” in *KDD*, 2016.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] M. T. Ribeiro, S. Singh, 和 C. Guestrin, “我为什么要信任你?: 解释任何分类器的预测,” 收录于
    *KDD*, 2016。'
- en: '[111] C.-Y. Tsai and D. D. Cox, “Characterizing visual representations within
    convolutional neural networks: Toward a quantitative approach,” *ICML Workshop
    on Vis for Deep Learning*, 2016.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] C.-Y. Tsai 和 D. D. Cox, “卷积神经网络中的视觉表示特征: 朝向量化方法,” *ICML Workshop on Vis
    for Deep Learning*, 2016。'
- en: '[112] S. Ritter, D. G. Barrett, A. Santoro, and M. M. Botvinick, “Cognitive
    psychology for deep neural networks: A shape bias case study,” *arXiv:1706.08606*,
    2017.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] S. Ritter, D. G. Barrett, A. Santoro, 和 M. M. Botvinick, “深度神经网络的认知心理学:
    形状偏差案例研究,” *arXiv:1706.08606*, 2017。'
- en: '[113] A. Das, H. Agrawal, L. Zitnick, D. Parikh, and D. Batra, “Human attention
    in visual question answering: Do humans and deep networks look at the same regions?”
    *Computer Vision and Image Understanding*, 2017.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] A. Das, H. Agrawal, L. Zitnick, D. Parikh, 和 D. Batra, “视觉问答中的人类注意力:
    人类和深度网络是否关注相同区域?” *Computer Vision and Image Understanding*, 2017。'
- en: '[114] G. K. Tam, V. Kothari, and M. Chen, “An analysis of machine-and human-analytics
    in classification,” *IEEE TVCG*, vol. 23, no. 1, 2017.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] G. K. Tam, V. Kothari, 和 M. Chen, “分类中的机器与人类分析的比较,” *IEEE TVCG*, vol.
    23, no. 1, 2017。'
- en: '[115] S. Barocas and A. D. Selbst, “Big data’s disparate impact,” *Calif. L.
    Rev.*, vol. 104, pp. 671–769, 2016.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] S. Barocas 和 A. D. Selbst, “大数据的不同影响,” *Calif. L. Rev.*, vol. 104, 页码
    671–769, 2016。'
- en: '[116] A. Caliskan, J. J. Bryson, and A. Narayanan, “Semantics derived automatically
    from language corpora contain human-like biases,” *Science*, vol. 356, no. 6334,
    2017.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] A. Caliskan, J. J. Bryson, 和 A. Narayanan, “从语言语料库自动生成的语义包含类人偏差,” *Science*,
    vol. 356, no. 6334, 2017。'
- en: '[117] M. Wattenberg, F. Viegas, and M. Hardt, “Attacking discrimination with
    smarter machine learning,” *Google Research Website*, 2016\. [Online]. Available:
    [https://research.google.com/bigpicture/attacking-discrimination-in-ml/](https://research.google.com/bigpicture/attacking-discrimination-in-ml/)'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] M. Wattenberg, F. Viegas, 和 M. Hardt, “通过更智能的机器学习攻击歧视,” *Google Research
    Website*, 2016\. [在线]. 可用: [https://research.google.com/bigpicture/attacking-discrimination-in-ml/](https://research.google.com/bigpicture/attacking-discrimination-in-ml/)'
- en: '[118] “Facets,” *Google PAIR*, 2017\. [Online]. Available: [https://pair-code.github.io/facets/](https://pair-code.github.io/facets/)'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] “Facets,” *Google PAIR*, 2017\. [在线]. 可用: [https://pair-code.github.io/facets/](https://pair-code.github.io/facets/)'
- en: '[119] M. Hardt, E. Price, N. Srebro *et al.*, “Equality of opportunity in supervised
    learning,” in *NIPS*, 2016.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] M. Hardt, E. Price, N. Srebro *et al.*, “监督学习中的机会平等,” 收录于 *NIPS*, 2016。'
- en: '[120] E. Wall, L. Blaha, L. Franklin, and A. Endert, “Warning, bias may occur:
    A proposed approach to detecting cognitive bias in interactive visual analytics,”
    *VAST*, 2017.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] E. Wall, L. Blaha, L. Franklin, 和 A. Endert, “警告，可能会出现偏差: 一种检测互动可视分析中认知偏差的建议方法,”
    *VAST*, 2017。'
- en: '[121] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow,
    and R. Fergus, “Intriguing properties of neural networks,” *arXiv:1312.6199*,
    2013.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow,
    和 R. Fergus, “神经网络的有趣属性,” *arXiv:1312.6199*, 2013。'
- en: '[122] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing
    adversarial examples,” *ICLR*, 2014.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] I. J. Goodfellow, J. Shlens, 和 C. Szegedy, “解释和利用对抗样本,” *ICLR*, 2014。'
- en: '[123] A. Nguyen, J. Yosinski, and J. Clune, “Deep neural networks are easily
    fooled: High confidence predictions for unrecognizable images,” in *CVPR*, 2015.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] A. Nguyen, J. Yosinski, 和 J. Clune, “深度神经网络容易被愚弄: 高置信度对不可识别图像的预测,” 收录于
    *CVPR*, 2015。'
- en: '[124] J. H. Metzen, T. Genewein, V. Fischer, and B. Bischoff, “On detecting
    adversarial perturbations,” in *ICLR*, 2017.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] J. H. Metzen, T. Genewein, V. Fischer, 和 B. Bischoff, “检测对抗扰动的研究,” 收录于
    *ICLR*, 2017。'
- en: '[125] S. Gu and L. Rigazio, “Towards deep neural network architectures robust
    to adversarial examples,” *arXiv:1412.5068*, 2014.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] S. Gu 和 L. Rigazio, “朝向对抗样本鲁棒的深度神经网络架构,” *arXiv:1412.5068*, 2014。'
- en: '[126] N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami, “Distillation
    as a defense to adversarial perturbations against deep neural networks,” in *Security
    and Privacy*, 2016.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] N. Papernot, P. McDaniel, X. Wu, S. Jha, 和 A. Swami, “蒸馏作为对抗深度神经网络的防御,”
    收录于 *Security and Privacy*, 2016。'
- en: '[127] N. Das, M. Shanbhogue, S.-T. Chen, F. Hohman, S. Li, L. Chen, M. E. Kounavis,
    and D. H. Chau, “Shield: Fast, practical defense and vaccination for deep learning
    using jpeg compression,” *arXiv:1802.06816*, 2018.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] N. Das, M. Shanbhogue, S.-T. Chen, F. Hohman, S. Li, L. Chen, M. E. Kounavis,
    和 D. H. Chau, “Shield: 快速、实用的深度学习防御和疫苗接种，使用 JPEG 压缩，” *arXiv:1802.06816*，2018
    年。 |'
- en: '[128] A. Kurakin, I. Goodfellow, and S. Bengio, “Adversarial examples in the
    physical world,” *arXiv:1607.02533*, 2016.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] A. Kurakin, I. Goodfellow, 和 S. Bengio, “物理世界中的对抗样本，” *arXiv:1607.02533*，2016
    年。'
- en: '| ![[Uncaptioned image]](img/4c15581baa77108eb45c66351abd7738.png) | Fred Hohman
    is a PhD student at Georgia Tech’s College of Computing. His research combines
    HCI principles and ML techniques to improve deep learning interpretability. He
    won the NASA Space Technology Research Fellowship. He received his B.S. in mathematics
    and physics. He won SIGMOD’17 Best Demo, Honorable Mention; Microsoft AI for Earth
    Award for using AI to improve sustainability; and the President’s Fellowship for
    top incoming PhD students. |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/4c15581baa77108eb45c66351abd7738.png) | Fred Hohman 是乔治亚理工学院计算学院的博士生。他的研究结合了
    HCI 原则和 ML 技术，以提高深度学习的可解释性。他获得了 NASA 太空技术研究奖学金。他获得了数学和物理学的学士学位。他获得了 SIGMOD''17
    最佳演示奖，荣誉提名；微软 AI for Earth 奖，因使用 AI 改善可持续性；以及总统奖学金，授予顶级新进博士生。 |'
- en: '| ![[Uncaptioned image]](img/96bbfa2e1fbaf0d882784bd8f86a7df3.png) | Minsuk
    Kahng is a computer science PhD student at Georgia Tech. His thesis research focuses
    on building visual analytics tools for exploring, interpreting, and interacting
    with complex machine learning models and results, by combining methods from information
    visualization, machine learning, and databases. He received the Google PhD Fellowship
    and NSF Graduate Research Fellowship. His ActiVis deep learning visualization
    system has been deployed on Facebook’s machine learning platform. |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/96bbfa2e1fbaf0d882784bd8f86a7df3.png) | Minsuk Kahng 是乔治亚理工学院的计算机科学博士生。他的论文研究专注于通过结合信息可视化、机器学习和数据库的方法，构建用于探索、解释和与复杂机器学习模型及结果互动的视觉分析工具。他获得了
    Google 博士生奖学金和 NSF 研究生奖学金。他的 ActiVis 深度学习可视化系统已经在 Facebook 的机器学习平台上部署。 |'
- en: '| ![[Uncaptioned image]](img/5032f16dab9b44b982a296a0d1fca350.png) | Robert
    Pienta is an industry researcher in applied machine learning and visual analytics.
    He received his PhD degree in computational science and engineering from Georgia
    Tech in 2017\. He was an NSF FLAMEL fellow and presidential scholar at Georgia
    Tech. His research interests include visual analytics, graph analytics, and machine
    learning. In particular, the algorithms and design techniques for interactive
    graph querying and exploration. |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/5032f16dab9b44b982a296a0d1fca350.png) | Robert Pienta 是一位从事应用机器学习和视觉分析的行业研究员。他于
    2017 年获得乔治亚理工学院计算科学与工程的博士学位。他曾是 NSF FLAMEL 奖学金获得者和乔治亚理工学院的总统学者。他的研究兴趣包括视觉分析、图形分析和机器学习，特别是互动图形查询和探索的算法和设计技术。
    |'
- en: '| ![[Uncaptioned image]](img/a6519b46820b2b5cb798eb1eeb205cb6.png) | Duen Horng
    (Polo) Chau is an Associate Professor at Georgia Tech. His research bridges data
    mining and HCI to make sense of massive datasets. His thesis won Carnegie Mellon’s
    CS Dissertation Award, Honorable Mention. He received awards from Intel, Google,
    Yahoo, LexisNexis, and Symantec; He won paper awards at SIGMOD, KDD and SDM. He
    is an ACM IUI steering committee member, IUI’15 co-chair, and IUI’19 program co-chair.
    His research is deployed by Facebook, Symantec, and Yahoo. |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/a6519b46820b2b5cb798eb1eeb205cb6.png) | Duen Horng (Polo)
    Chau 是乔治亚理工学院的副教授。他的研究桥接数据挖掘和 HCI，以理解大规模数据集。他的论文获得了卡内基梅隆大学的计算机科学论文奖，荣誉提名。他获得了
    Intel、Google、Yahoo、LexisNexis 和 Symantec 的奖项；并在 SIGMOD、KDD 和 SDM 上获得了论文奖。他是 ACM
    IUI 指导委员会成员，IUI’15 联席主席和 IUI’19 程序联席主席。他的研究被 Facebook、Symantec 和 Yahoo 部署。 |'
