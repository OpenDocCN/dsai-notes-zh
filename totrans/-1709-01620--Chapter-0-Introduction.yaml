- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:08:40'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:08:40
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1709.01620] Chapter 0 Introduction'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1709.01620] 第0章 引言'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1709.01620](https://ar5iv.labs.arxiv.org/html/1709.01620)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1709.01620](https://ar5iv.labs.arxiv.org/html/1709.01620)
- en: Deep Learning Techniques for Music Generation – A Survey Jean-Pierre Briot^(∗,)¹¹1Also
    Visiting Professor at UNIRIO (Universidade Federal do Estado do Rio de Janeiro)
    and Permanent Visiting Professor at PUC-Rio (Pontifícia Universidade Católica
    do Rio de Janeiro), Rio de Janeiro, Brazil., Gaëtan Hadjeres^† and François-David
    Pachet^‡ ^∗ Sorbonne Université, CNRS, LIP6, F-75005 Paris, France
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习音乐生成技术综述 – 让-皮埃尔·布里奥^(∗,)¹¹1 也担任 UNIRIO（里约热内卢州立大学）访问教授，以及 PUC-Rio（里约热内卢天主教大学）常驻访问教授，巴西里约热内卢；盖坦·哈杰雷^†
    和 弗朗索瓦-大卫·帕切^‡ ^∗ 索邦大学，法国国家科学研究中心，LIP6，F-75005 巴黎，法国
- en: ^† Sony Computer Science Laboratories, CSL-Paris, F-75005 Paris, France
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ^† 索尼计算机科学实验室，CSL-巴黎，F-75005 巴黎，法国
- en: ^‡ Spotify Creator Technology Research Lab, CTRL, F-75008 Paris, France
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ^‡ Spotify 创作者技术研究实验室，CTRL，F-75008 巴黎，法国
- en: 'This paper is a survey and an analysis of different ways of using deep learning
    (deep artificial neural networks) to generate musical content. We propose a methodology
    based on five dimensions for our analysis:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文综述并分析了使用深度学习（深度人工神经网络）生成音乐内容的不同方法。我们提出了一种基于五个维度的分析方法：
- en: •
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Objective
  id: totrans-11
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标
- en: –
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: What musical content is to be generated?
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 生成什么样的音乐内容？
- en: 'Examples are: melody, polyphony, accompaniment or counterpoint.'
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例包括：旋律、和声、伴奏或对位。
- en: –
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: For what destination and for what use?
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用于什么目的和用途？
- en: To be performed by a human(s) (in the case of a musical score), or by a machine
    (in the case of an audio file).
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以由人类（在音乐谱的情况下）或机器（在音频文件的情况下）执行。
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Representation
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 表示
- en: –
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: What are the concepts to be manipulated?
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要操作的概念是什么？
- en: 'Examples are: waveform, spectrogram, note, chord, meter and beat.'
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例包括：波形、频谱图、音符、和弦、拍号和节拍。
- en: –
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: What format is to be used?
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用什么格式？
- en: 'Examples are: MIDI, piano roll or text.'
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例包括：MIDI、钢琴卷或文本。
- en: –
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: How will the representation be encoded?
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 表示将如何编码？
- en: 'Examples are: scalar, one-hot or many-hot.'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例包括：标量、单热编码或多热编码。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Architecture
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 架构
- en: –
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: What type(s) of deep neural network is (are) to be used?
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将使用什么类型的深度神经网络？
- en: 'Examples are: feedforward network, recurrent network, autoencoder or generative
    adversarial networks.'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例包括：前馈网络、递归网络、自编码器或生成对抗网络。
- en: •
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Challenge
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 挑战
- en: –
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: What are the limitations and open challenges?
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有哪些限制和未解决的挑战？
- en: 'Examples are: variability, interactivity and creativity.'
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例包括：变异性、互动性和创造性。
- en: •
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Strategy
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 策略
- en: –
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: How do we model and control the process of generation?
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们如何建模和控制生成过程？
- en: 'Examples are: single-step feedforward, iterative feedforward, sampling or input
    manipulation.'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例包括：单步前馈、迭代前馈、采样或输入操作。
- en: For each dimension, we conduct a comparative analysis of various models and
    techniques and we propose some tentative multidimensional typology. This typology
    is bottom-up, based on the analysis of many existing deep-learning based systems
    for music generation selected from the relevant literature. These systems are
    described and are used to exemplify the various choices of objective, representation,
    architecture, challenge and strategy. The last section includes some discussion
    and some prospects.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个维度，我们进行各种模型和技术的比较分析，并提出一些初步的多维分类法。这种分类法是自下而上的，基于对从相关文献中选取的许多现有深度学习音乐生成系统的分析。这些系统被描述并用于举例说明目标、表示、架构、挑战和策略的各种选择。最后一部分包括一些讨论和前景展望。
- en: 'Supplementary material is provided at the following companion web site:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 额外材料提供于以下配套网站：
- en: www.briot.info/dlt4mg/
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: www.briot.info/dlt4mg/
- en: 'This paper is a simplified (weak DRM²²2In addition to including high quality
    color figures, the book includes: a table of contents, a list of tables, a list
    of figures, a table of acronyms, a glossary and an index.) version of the following
    book briot:dlt4mg:book:2019: Jean-Pierre Briot, Gaëtan Hadjeres and François-David
    Pachet, Deep Learning Techniques for Music Generation, Computational Synthesis
    and Creative Systems, Springer, 2019. Hardcover ISBN: 978-3-319-70162-2. eBook
    ISBN: 978-3-319-70163-9. Series ISSN: 2509-6575.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 本文是以下书籍的简化版（弱DRM²²2除了包含高质量彩色插图外，本书还包括：目录、表格清单、图形清单、缩略语表、术语表和索引。）briot:dlt4mg:book:2019：Jean-Pierre
    Briot, Gaëtan Hadjeres 和 François-David Pachet，《音乐生成的深度学习技术、计算合成与创意系统》，Springer，2019年。硬封面
    ISBN：978-3-319-70162-2。电子书 ISBN：978-3-319-70163-9。系列 ISSN：2509-6575。
- en: Chapter 0 Introduction
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第0章 引言
- en: Abstract
  id: totrans-49
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: '*Chapter 1 Introduction provides motivation for this book. It includes a short
    summary of the history of computer music and music generation (including previous
    uses of artificial neural networks as well as other models such as grammars, rules
    and Markov chains) up to the recent rise of deep learning. It also describes the
    organization and the public of the book as well as related work.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*第1章 引言提供了本书的动机。它包括计算机音乐和音乐生成的历史简要总结（包括人工神经网络以及其他模型如文法、规则和马尔可夫链的早期应用）直到深度学习的近期崛起。它还描述了本书的组织和读者群体，以及相关工作。'
- en: Deep learning has recently become a fast growing domain and is now used routinely
    for classification and prediction tasks, such as image recognition, voice recognition
    or translation. It became popular in 2012, when a deep learning architecture significantly
    outperformed standard techniques relying on handcrafted features in an image classification
    competition, see more details in Section LABEL:section:architectures:history.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习最近成为一个快速增长的领域，现在被广泛用于分类和预测任务，如图像识别、语音识别或翻译。它在2012年变得流行，当时一种深度学习架构在图像分类比赛中显著超越了依赖手工特征的标准技术，详细信息见第LABEL:section:architectures:history节。
- en: 'We may explain this success and reemergence of artificial neural network techniques
    by the combination of:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下几点来解释人工神经网络技术的成功和重现：
- en: •
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: availability of massive data;
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大规模的数据可用性；
- en: •
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: availability of efficient and affordable computing power¹¹1Notably, thanks to
    graphics processing units (GPU), initially designed for video games, which have
    now one of their biggest markets in data science and deep learning applications.;
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高效且负担得起的计算能力¹¹1尤其是得益于最初为视频游戏设计的图形处理单元（GPU），它们现在在数据科学和深度学习应用中拥有最大的市场之一。；
- en: •
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'technical advances, such as:'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 技术进步，例如：
- en: –
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: pre-training, which resolved initially inefficient training of neural networks
    with many layers hinton:fast:algorithm:2006²²2Although nowadays it has being replaced
    by other techniques, such as batch normalization ioffe:batch:normalization:arxiv:2015
    and deep residual learning he:resnet:deep:residual:arxiv:2015.;
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预训练，解决了具有多层神经网络的初始训练效率低的问题 hinton:fast:algorithm:2006²²2虽然如今它已被其他技术取代，如批量归一化
    ioffe:batch:normalization:arxiv:2015 和深度残差学习 he:resnet:deep:residual:arxiv:2015。；
- en: –
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: convolutions, which provide motif translation invariance le:cun:convolutional:handbook:1998;
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 卷积，这提供了图案的平移不变性 le:cun:convolutional:handbook:1998；
- en: –
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: LSTM (long short-term memory), which resolved initially inefficient training
    of recurrent neural networks hochreiter:lstm:1997.
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: LSTM（长短期记忆），解决了递归神经网络的初始训练效率低的问题 hochreiter:lstm:1997。
- en: 'There is no consensual definition for deep learning. It is a repertoire of
    machine learning (ML) techniques, based on artificial neural networks. The key
    aspect and common ground is the term deep. This means that there are multiple
    layers processing multiple hierarchical levels of abstractions, which are automatically
    extracted from data³³3That said, although deep learning will automatically extract
    significant features from the data, manual choices of input representation, e.g.,
    spectrum vs raw wave signal for audio, may be very significant for the accuracy
    of the learning and for the quality of the generated content, see Section LABEL:section:representation:feature:extraction..
    Thus a deep architecture can manage and decompose complex representations in terms
    of simpler representations. The technical foundation is mostly artificial neural
    networks, as we will see in Chapter LABEL:section:chapter:architecture, with many
    extensions, such as: convolutional networks, recurrent networks, autoencoders,
    and restricted Boltzmann machines. For more information about the history and
    various facets of deep learning, see, e.g., a recent comprehensive book on the
    domain goodfellow:deep:learning:book:2016.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习没有统一的定义。它是一种基于人工神经网络的机器学习（ML）技术的综合体。关键方面和共同点是“深度”这个术语。这意味着有多个层次处理多个层次的抽象，这些抽象是从数据中自动提取的³³3虽然深度学习会自动提取数据中的重要特征，但输入表示的手动选择，例如音频的频谱与原始波形信号，对于学习的准确性和生成内容的质量可能非常重要，请参见第LABEL:section:representation:feature:extraction节。因此，深度架构可以管理和分解复杂的表示，转化为更简单的表示。其技术基础主要是人工神经网络，如我们将在第LABEL:section:chapter:architecture章中看到的，还有许多扩展，如：卷积网络、递归网络、自编码器和限制玻尔兹曼机。有关深度学习历史和各种方面的更多信息，请参见例如，最近的一本全面介绍该领域的书籍goodfellow:deep:learning:book:2016。
- en: 'Driving applications of deep learning are traditional machine learning tasks⁴⁴4Tasks
    in machine learning are types of problems and may also be described in terms of
    how the machine learning system should process an example (goodfellow:deep:learning:book:2016,
    Section 5.1.1). Examples are: classification, regression and anomaly detection.:
    classification (for instance, identification of images) and prediction⁵⁵5As a
    testimony of the initial DNA of neural networks: linear regression and logistic
    regression, see Section LABEL:section:architecture:linear:regression. (for instance,
    of the weather) and also more recent ones such as translation.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的驱动应用是传统的机器学习任务⁴⁴4机器学习中的任务是问题类型，也可以描述为机器学习系统应该如何处理一个示例（goodfellow:deep:learning:book:2016，第5.1.1节）。示例包括：分类、回归和异常检测：分类（例如，图像识别）和预测⁵⁵5作为神经网络初始DNA的见证：线性回归和逻辑回归，请参见第LABEL:section:architecture:linear:regression节。（例如，天气预测）以及更近期的应用，如翻译。
- en: 'But a growing area of application of deep learning techniques is the generation
    of content. Content can be of various kinds: images, text and music, the latter
    being the focus of our analysis. The motivation is in using now widely available
    various corpora to automatically learn musical styles and to generate new musical
    content based on this.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 但深度学习技术的一个增长领域是内容生成。内容可以是多种类型的：图像、文本和音乐，后者是我们分析的重点。动机在于利用现在广泛可用的各种语料库，自动学习音乐风格，并基于此生成新的音乐内容。
- en: 1 Motivation
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1 动机
- en: 1 Computer-Based Music Systems
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1 基于计算机的音乐系统
- en: The first music generated by computer appeared in 1957. It was a 17 seconds
    long melody named “The Silver Scale” by its author Newman Guttman and was generated
    by a software for sound synthesis named Music I, developed by Mathews at Bell
    Laboratories. The same year, “The Illiac Suite” was the first score composed by
    a computer lejaren:illiac:book:1959. It was named after the ILLIAC I computer
    at the University of Illinois at Urbana-Champaign (UIUC) in the United States.
    The human “meta-composers” were Lejaren A. Hiller and Leonard M. Isaacson, both
    musicians and scientists. It was an early example of algorithmic composition,
    making use of stochastic models (Markov chains) for generation as well as rules
    to filter generated material according to desired properties.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机生成的第一首音乐出现在1957年。它是一首17秒长的旋律，名为“银色音阶”，由其作者纽曼·古特曼创作，并由贝尔实验室开发的音乐合成软件Music
    I生成。同年，“伊利亚克组曲”是由计算机首次作曲的乐谱。它以美国伊利诺伊大学厄巴纳-香槟分校（UIUC）的ILLIAC I计算机命名。人类“元作曲家”是音乐家兼科学家雷加伦·A·希勒和莱昂纳德·M·艾萨克森。这是算法作曲的早期示例，利用随机模型（马尔可夫链）生成以及根据所需属性过滤生成材料的规则。
- en: In the domain of sound synthesis, a landmark was the release in 1983 by Yamaha
    of the DX 7 synthesizer, building on groundwork by Chowning on a model of synthesis
    based on frequency modulation (FM). The same year, the MIDI⁶⁶6Musical instrument
    digital interface, to be introduced in Section LABEL:section:representation:midi.
    interface was launched, as a way to interoperate various software and instruments
    (including the Yamaha DX 7 synthesizer). Another landmark was the development
    by Puckette at IRCAM of the Max/MSP real-time interactive processing environment,
    used for real-time synthesis and for interactive performances.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在声音合成领域，一个里程碑是1983年雅马哈发布DX 7合成器，基于乔宁关于基于频率调制（FM）合成模型的工作。同年，音乐乐器数字接口（MIDI）⁶⁶6详见第LABEL:section:representation:midi节。接口推出，作为各种软件和乐器（包括雅马哈DX
    7合成器）进行互操作的一种方式。另一个里程碑是在IRCAM由普克特开发的Max/MSP实时交互处理环境，用于实时合成和互动表演。
- en: Regarding algorithmic composition, in the early 1960s Iannis Xenakis explored
    the idea of stochastic composition⁷⁷7One of the first documented case of stochastic
    music, long before computers, is the Musikalisches Wurfelspiel (Dice Music), attributed
    to Wolfgang Amadeus Mozart. It was designed for using dice to generate music by
    concatenating randomly selected predefined music segments composed in a given
    style (Austrian waltz in a given key). xenakis:formalized:music:book:1963, in
    his composition named “Atrées” in 1962. The idea involved using computer fast
    computations to calculate various possibilities from a set of probabilities designed
    by the composer in order to generate samples of musical pieces to be selected.
    In another approach following the initial direction of “The Illiac Suite”, grammars
    and rules were used to specify the style of a given corpus or more generally tonal
    music theory. An example is the generation in the 1980s by Ebcioğlu’s composition
    software named CHORAL of a four-part chorale in the style of Johann Sebastian
    Bach, according to over 350 handcrafted rules ebcioglu:expert:system:bach:cmj:1988.
    In the late 1980s David Cope’s system named Experiments in Musical Intelligence
    (EMI) extended that approach with the capacity to learn from a corpus of scores
    of a composer to create its own grammar and database of rules cope:algorithmic:composer:book:2000.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在算法作曲方面，20世纪60年代初，伊安尼斯·克萨纳基斯探索了随机作曲的概念⁷⁷7早在计算机出现之前，就有记录的随机音乐案例之一是沃尔夫冈·阿马德乌斯·莫扎特的《音乐骰子游戏》。这是为了通过使用骰子按照给定风格（奥地利圆舞曲在特定调性中）随机连接预定义的音乐片段来生成音乐
    xenakis:formalized:music:book:1963。他在1962年的作品《阿特里斯》中实现了这一理念。这一想法涉及使用计算机快速计算来根据作曲家设计的一组概率计算各种可能性，以生成要选择的音乐片段样本。在“伊利亚克组曲”最初方向的另一种方法中，使用语法和规则来指定给定语料库或更普遍的音乐理论的风格。一个例子是在1980年代，埃比奥尔格鲁的作曲软件CHORAL中生成类似约翰·塞巴斯蒂安·巴赫风格的四声部赞美诗，根据超过350条手工制作的规则
    ebcioglu:expert:system:bach:cmj:1988。在1980年代末，大卫·科普的系统名为音乐智能实验（EMI），通过学习作曲家的乐谱库来扩展这一方法，创建自己的语法和规则数据库
    cope:algorithmic:composer:book:2000。
- en: Since then, computer music has continued developing for the general public,
    if we consider, for instance, the GarageBand music composition and production
    application for Apple platforms (computers, tablets and cellphones), as an offspring
    of the initial Cubase sequencer software, released by Steinberg in 1989.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 自那时以来，计算机音乐持续发展以服务于大众，例如考虑到 GarageBand 音乐创作和制作应用程序，它是 Apple 平台（计算机、平板电脑和手机）的一个衍生品，而
    GarageBand 最初源于 Steinberg 于 1989 年发布的 Cubase 序列软件。
- en: For more details about the history and principles of computer music in general,
    see, for example, the book by Roads roads:computer:music:tutorial:book:1996. For
    more details about the history and principles of algorithmic composition, see,
    for example, maurer:brief:history:algorithmic:composition:1999 and the books by
    Cope cope:algorithmic:composer:book:2000 or Dean and McLean dean:oxford:handbook:2018.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 关于计算机音乐的历史和原则的更多细节，请参阅，例如 Roads 的书籍（roads:computer:music:tutorial:book:1996）。关于算法作曲的历史和原则的更多细节，请参阅，例如
    maurer 的著作（maurer:brief:history:algorithmic:composition:1999）以及 Cope 的书籍（cope:algorithmic:composer:book:2000）或
    Dean 和 McLean 的著作（dean:oxford:handbook:2018）。
- en: 2 Autonomy versus Assistance
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2 自主性与辅助性
- en: When talking about computer-based music generation, there is actually some ambiguity
    about whether the objective is
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 说到计算机生成音乐时，实际上存在一些模糊性，即目标是否是
- en: •
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: to design and construct autonomous music-making systems – two recent examples
    being the deep-learning based Amper™ and Jukedeck systems/companies aimed at the
    creation of original music for commercials and documentary; or
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 设计和构建自主音乐创作系统——最近的两个例子是基于深度学习的 Amper™ 和 Jukedeck 系统/公司，旨在为广告和纪录片创作原创音乐；或者
- en: •
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: to design and construct computer-based environments to assist human musicians
    (composers, arrangers, producers, etc.) – two examples being the FlowComposer
    environment developed at Sony CSL-Paris papadopoulos:flow:composer:cp:2016 (introduced
    in Section LABEL:section:systems:flow:composer) and the OpenMusic environment
    developed at IRCAM assayag:openmusic:cmj:1999.
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 设计和构建计算机环境以辅助人类音乐家（作曲家、编曲家、制作人等）——例如，Sony CSL-Paris 开发的 FlowComposer 环境（在第 LABEL:section:systems:flow:composer
    节中介绍）和 IRCAM 开发的 OpenMusic 环境（assayag:openmusic:cmj:1999）就是两个例子。
- en: 'The quest for autonomous music-making systems may be an interesting perspective
    for exploring the process of composition⁸⁸8As Richard Feynman coined it: “What
    I cannot create, I do not understand.” and it also serves as an evaluation method.
    An example of a musical Turing test⁹⁹9Initially codified in 1950 by Alan Turing
    and named by him the “imitation game” turing:test:mind:1950, the “Turing test”
    is a test of the ability for a machine to exhibit intelligent behavior equivalent
    to (and more precisely, indistinguishable from) the behavior of a human. In his
    imaginary experimental setting, Turing proposed the test to be a natural language
    conversation between a human (the evaluator) and a hidden actor (another human
    or a machine). If the evaluator cannot reliably tell the machine from the human,
    the machine is said to have passed the test. will be introduced in Section LABEL:section:experiment:deep:bach.
    It consists in presenting to various members of the public (from beginners to
    experts) chorales composed by J. S. Bach or generated by a deep learning system
    and played by human musicians^(10)^(10)10This is to avoid the bias (synthetic
    flavor) of a computer rendered generated music.. As we will see in the following,
    deep learning techniques turn out to be very efficient at succeeding in such tests,
    due to their capacity to learn musical style from a given corpus and to generate
    new music that fits into this style. That said, we consider that such a test is
    more a means than an end.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于自主音乐创作系统的探索可能是一个有趣的视角来研究创作过程⁸⁸8正如理查德·费曼所言：“我不能创造的东西，我不理解。” 它也作为一种评估方法。例如，音乐图灵测试⁹⁹9最初由艾伦·图灵于
    1950 年制定，并由他命名为“模仿游戏”（turing:test:mind:1950），该测试是对机器是否能展现出等同于（更准确地说，是无法区分的）人类智能行为的测试。在他的虚拟实验设置中，图灵提出了一个自然语言对话的测试，其中人类（评估者）与隐藏的演员（另一个人或机器）进行对话。如果评估者不能可靠地区分机器和人类，则认为机器通过了测试。将在第
    LABEL:section:experiment:deep:bach 节中介绍。这种测试涉及向不同公众（从初学者到专家）展示由 J. S. 巴赫创作的合唱曲或由深度学习系统生成并由人类音乐家演奏的合唱曲^(10)^(10)10
    这是为了避免计算机生成音乐的偏见（合成风味）.. 如我们将在下文中看到的，深度学习技术在这样的测试中表现出色，因为它们能够从特定的语料库中学习音乐风格并生成符合该风格的新音乐。也就是说，我们认为这样的测试更多的是一种手段而非目的。
- en: 'A broader perspective is in assisting human musicians during the various steps
    of music creation: composition, arranging, orchestration, production, etc. Indeed,
    to compose or to improvise^(11)^(11)11Improvisation is a form of real time composition.,
    a musician rarely creates new music from scratch. S/he reuses and adapts, consciously
    or unconsciously, features from various music that s/he already knows or has heard,
    while following some principles and guidelines, such as theories about harmony
    and scales. A computer-based musician assistant may act during different stages
    of the composition, to initiate, suggest, provoke and/or complement the inspiration
    of the human composer.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 更广泛的视角是帮助人类音乐家在音乐创作的各个阶段：作曲、编曲、编排、制作等。确实，要进行作曲或即兴创作^(11)^(11)11即兴创作是一种实时作曲形式。，音乐家很少从零开始创作新音乐。他/她会有意识或无意识地重用和适应自己已经知道或听过的各种音乐特征，同时遵循一些原则和指导方针，例如和声和音阶理论。基于计算机的音乐助手可以在创作的不同阶段发挥作用，以启动、建议、激发和/或补充人类作曲家的灵感。
- en: That said, as we will see, the majority of current deep-learning based systems
    for generating music are still focused on autonomous generation, although more
    and more systems are addressing the issue of human-level control and interaction.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，正如我们将看到的那样，目前大多数基于深度学习的音乐生成系统仍然专注于自主生成，尽管越来越多的系统正在解决人类水平的控制和互动问题。
- en: 3 Symbolic versus Sub-Symbolic AI
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3 符号AI与子符号AI
- en: 'Artificial Intelligence (AI) is often divided into two main streams^(12)^(12)12With
    some precaution, as this division is not that strict.:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）通常分为两个主要方向^(12)^(12)12有一些例外，因为这种划分并不那么严格。：
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: symbolic AI – dealing with high-level symbolic representations (e.g., chords,
    harmony…) and processes (harmonization, analysis…); and
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 符号AI - 处理高级符号表示（例如，和弦、和声……）和过程（和声化、分析……）；以及
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: sub-symbolic AI – dealing with low-level representations (e.g., sound, timbre…)
    and processes (pitch recognition, classification…).
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 子符号AI - 处理低级表示（例如，声音、音色……）和过程（音高识别、分类……）。
- en: Examples of symbolic models used for music are rule-based systems or grammars
    to represent harmony. Examples of sub-symbolic models used for music are machine
    learning algorithms for automatically learning musical styles from a corpus of
    musical pieces. These models can then be used in a generative and interactive
    manner, to help musicians in creating new music, by taking advantage of this added
    “intelligent” memory (associative, inductive and generative) to suggest proposals,
    sketches, extrapolations, mappings, etc. This is now feasible because of the growing
    availability of music in various forms, e.g., sound, scores and MIDI files, which
    can be automatically processed by computers.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 用于音乐的符号模型的例子包括基于规则的系统或语法来表示和声。用于音乐的子符号模型的例子包括机器学习算法，它们通过从一系列音乐作品中自动学习音乐风格。这些模型可以以生成性和互动性的方式使用，帮助音乐家创作新音乐，通过利用这种附加的“智能”记忆（联想、归纳和生成）来建议提案、草图、推断、映射等。这现在是可行的，因为各种形式的音乐（例如声音、乐谱和MIDI文件）越来越容易获得，可以由计算机自动处理。
- en: A recent example of an integrated music composition environment is FlowComposer
    papadopoulos:flow:composer:cp:2016, which we will introduce in Section LABEL:section:systems:flow:composer.
    It offers various symbolic and sub-symbolic techniques, e.g., Markov chains for
    modeling style, a constraint solving module for expressing constraints, a rule-based
    module to produce harmonic analysis; and an audio mapping module to produce rendering.
    Another example of an integrated music composition environment is OpenMusic assayag:openmusic:cmj:1999.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最近一个集成音乐创作环境的例子是FlowComposer papadopoulos:flow:composer:cp:2016，我们将在第LABEL:section:systems:flow:composer节中介绍它。它提供了各种符号和子符号技术，例如，用于建模风格的马尔可夫链、用于表达约束的约束求解模块、用于生成和声分析的基于规则的模块，以及用于生成渲染的音频映射模块。另一个集成音乐创作环境的例子是OpenMusic
    assayag:openmusic:cmj:1999。
- en: However, a deeper integration of sub-symbolic techniques, such as deep learning,
    with symbolic techniques, such as constraints and reasoning, is still an open
    issue^(13)^(13)13The general objective of integrating sub-symbolic and symbolic
    levels into a complete AI system is among the “Holy Grails” of AI., although some
    partial integrations in restricted contexts already exist (see, for example, Markov
    constraints in pachet:markov:constraints:constraints:2011; barbieri:lyrics:style:2012
    and an example of use for FlowComposer in Section LABEL:section:systems:flow:composer).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，符号技术（如约束和推理）与子符号技术（如深度学习）的更深层次整合仍然是一个未解的问题^(13)^(13)13将子符号和符号层整合成一个完整的AI系统的总体目标是AI的“圣杯”之一，尽管在有限的背景下已经存在一些部分整合（例如，pachet:markov:constraints:constraints:2011;
    barbieri:lyrics:style:2012中的Markov约束，以及FlowComposer的一个使用示例见Section LABEL:section:systems:flow:composer）。
- en: 4 Deep Learning
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4 深度学习
- en: The motivation for using deep learning (and more generally machine learning
    techniques) to generate musical content is its generality. As opposed to handcrafted
    models, such as grammar-based steedman:generative:grammar:blues:mp:1984 or rule-based
    music generation systems ebcioglu:expert:system:bach:cmj:1988, a machine learning-based
    generation system can be agnostic, as it learns a model from an arbitrary corpus
    of music. As a result, the same system may be used for various musical genres.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用深度学习（以及更一般的机器学习技术）生成音乐内容的动机在于其通用性。与手工制作的模型（如基于语法的steedman:generative:grammar:blues:mp:1984或基于规则的音乐生成系统
    ebcioglu:expert:system:bach:cmj:1988）相比，基于机器学习的生成系统可以是不可知的，因为它从任意音乐语料库中学习模型。因此，同一系统可以用于各种音乐类型。
- en: Therefore, as more large scale musical datasets are made available, a machine
    learning-based generation system will be able to automatically learn a musical
    style from a corpus and to generate new musical content. As stated by Fiebrink
    and Caramiaux fiebrink:ml:creative:tool:arxiv:2016, some benefits are
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，随着更多大规模音乐数据集的提供，基于机器学习的生成系统将能够从语料库中自动学习音乐风格并生成新的音乐内容。正如Fiebrink和Caramiaux所述
    fiebrink:ml:creative:tool:arxiv:2016，一些好处是
- en: •
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: it can make creation feasible when the desired application is too complex to
    be described by analytical formulations or manual brute force design, and
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 它可以使创作变得可行，当期望的应用过于复杂以至于无法通过分析公式或手动设计完成时，
- en: •
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: learning algorithms are often less brittle than manually designed rule sets
    and learned rules are more likely to generalize accurately to new contexts in
    which inputs may change.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学习算法通常比手动设计的规则集更不易脆弱，学习到的规则更可能准确地推广到输入可能变化的新上下文中。
- en: Moreover, as opposed to structured representations like rules and grammars,
    deep learning is good at processing raw unstructured data, from which its hierarchy
    of layers will extract higher level representations adapted to the task.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，与结构化表示（如规则和语法）相反，深度学习擅长处理原始非结构化数据，从中其层次结构将提取适应任务的高级表示。
- en: 5 Present and Future
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5 现状与未来
- en: As we will see, the research domain in deep learning-based music generation
    has turned hot recently, building on initial work using artificial neural networks
    to generate music (e.g., the pioneering experiments by Todd in 1989 todd:connectionist:composition:1989
    and the CONCERT system developed by Mozer in 1994 mozer:composition:prediction:1994),
    while creating an active stream of new ideas and challenges made possible thanks
    to the progress of deep learning. Let us also note the growing interest by some
    private big actors of digital media in the computer-aided generation of artistic
    content, with the creation by Google in June 2016 of the Magenta research project
    google:magenta:project:web and the creation by Spotify in September 2017 of the
    Creator Technology Research Lab (CTRL) spotify:ctrl:2017. This is likely to contribute
    to blurring the line between music creation and music consumption through the
    personalization of musical content amato:ai:media:arxiv:2019.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将看到的，基于深度学习的音乐生成研究领域最近变得非常热门，这建立在最初利用人工神经网络生成音乐的工作基础上（例如，1989年Todd的开创性实验
    todd:connectionist:composition:1989 和1994年Mozer开发的CONCERT系统 mozer:composition:prediction:1994），同时也由于深度学习的进步而带来了大量的新思想和挑战。我们还注意到一些大型数字媒体公司对计算机辅助艺术内容生成的兴趣日益增长，Google在2016年6月创建了Magenta研究项目
    google:magenta:project:web，Spotify在2017年9月创建了Creator Technology Research Lab (CTRL)
    spotify:ctrl:2017。这可能会通过音乐内容的个性化模糊音乐创作和音乐消费之间的界限 amato:ai:media:arxiv:2019。
- en: 2 This Book
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2 本书
- en: The lack (to our knowledge) of a comprehensive survey and analysis of this active
    research domain motivated the writing of this book, built in a bottom-up way from
    the analysis of numerous recent research works. The objective is to provide a
    comprehensive description of the issues and techniques for using deep learning
    to generate music, illustrated through the analysis of various architectures,
    systems and experiments presented in the literature. We also propose a conceptual
    framework and typology aimed at a better understanding of the design decisions
    for current as well as future systems.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们所知缺乏对这一活跃研究领域的全面调查和分析，这激发了本书的编写，该书从大量近期研究工作的分析中自下而上地构建。其目标是提供有关使用深度学习生成音乐的问题和技术的全面描述，通过对文献中各种架构、系统和实验的分析进行说明。我们还提出了一个概念框架和类型学，以便更好地理解当前和未来系统的设计决策。
- en: 1 Other Books and Sources
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 其他书籍和来源
- en: To our knowledge, there are only a few partial attempts at analyzing the use
    of deep learning for generating music. In briot:dlt4mg:arxiv:2017, a very preliminary
    version of this work, Briot et al. proposed a first survey of various systems
    through a multicriteria analysis (considering as dimensions the objective, representation,
    architecture and strategy). We have extended and consolidated this study by integrating
    as an additional dimension the challenge (after having analyzed it in briot:mgbdl:cd:ncaa:2018).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们了解，目前只有少数对使用深度学习生成音乐的分析尝试。在briot:dlt4mg:arxiv:2017中，Briot等人提出了通过多标准分析（考虑目标、表示、架构和策略作为维度）对各种系统的首次调查。我们通过将挑战作为附加维度进行扩展和整合（在briot:mgbdl:cd:ncaa:2018中进行了分析）。
- en: In graves:generating:sequences:rnn:arxiv:2014, Graves presented an analysis
    focusing on recurrent neural networks and text generation. In humphrey:feature:learning:music:2013,
    Humphrey et al. presented another analysis, sharing some issues about music representation
    (see Section LABEL:section:representation) but dedicated to music information
    retrieval (MIR) tasks, such as chord recognition, genre recognition and mood estimation.
    On MIR applications of deep learning, see also the recent tutorial paper by Choi
    et al. choi:tutorial:deep:learning:mir:arxiv:2017.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在graves:generating:sequences:rnn:arxiv:2014中，Graves呈现了一个关注于递归神经网络和文本生成的分析。在humphrey:feature:learning:music:2013中，Humphrey等人提出了另一个分析，讨论了音乐表示的一些问题（见第LABEL:section:representation节），但专注于音乐信息检索（MIR）任务，如和弦识别、流派识别和情绪估计。有关深度学习在MIR应用中的教程，请参见Choi等人的最近教程论文choi:tutorial:deep:learning:mir:arxiv:2017。
- en: One could also consult the proceedings of some recently created international
    workshops on the topic, such as
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以查阅一些最近创建的国际研讨会的会议记录，例如
- en: •
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: the Workshop on Constructive Machine Learning (CML 2016), held during the 30th
    Annual Conference on Neural Information Processing Systems (NIPS 2016) cml:nips:2016;
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2016年构造性机器学习研讨会（CML 2016），在第30届神经信息处理系统年会（NIPS 2016）上举行cml:nips:2016；
- en: •
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: the Workshop on Deep Learning for Music (DLM), held during the International
    Joint Conference on Neural Networks (IJCNN 2017) dl4m:ijcnn:2017, followed by
    a special journal issue herremans:deep:music:ncaa:2019; and
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度学习音乐研讨会（DLM），在国际联合神经网络会议（IJCNN 2017）期间举行dl4m:ijcnn:2017，之后是特别期刊文章herremans:deep:music:ncaa:2019；以及
- en: •
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: on the deep challenge of creativity, the related Series of International Conferences
    on Computational Creativity (ICCC) iacc:iccc:web.
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于创意的深层挑战，相关的国际计算创意会议系列（ICCC）iacc:iccc:web。
- en: For a more general survey of computer-based techniques to generate music, the
    reader can refer to general books such as
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对于计算机生成音乐的更一般性调查，读者可以参考一些通用书籍，例如
- en: •
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Roads’ book about computer music roads:computer:music:tutorial:book:1996;
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Roads关于计算机音乐的书籍roads:computer:music:tutorial:book:1996；
- en: •
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Cope’s cope:algorithmic:composer:book:2000, Dean and McLean’s dean:oxford:handbook:2018
    and/or Nierhaus’ books nierhaus:algorithmic:composition:book:2009 about algorithmic
    composition;
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Cope的cope:algorithmic:composer:book:2000，Dean和McLean的dean:oxford:handbook:2018和/或Nierhaus的nierhaus:algorithmic:composition:book:2009有关算法作曲的书籍；
- en: •
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: a recent survey about AI methods in algorithmic composition fernandez:ai:methods:algorithmic:composition:survey:jair:2013;
    and
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于算法作曲中AI方法的最近调查fernandez:ai:methods:algorithmic:composition:survey:jair:2013；以及
- en: •
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Cope’s book about models of musical creativity cope:musical:creativity:book:2005.
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Cope关于音乐创意模型的书籍cope:musical:creativity:book:2005。
- en: About machine learning in general, some examples of textbooks are
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 关于机器学习，一些教科书的例子有
- en: •
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: the textbook by Mitchell mitchell:ml:book:1997;
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: mitchell的教科书 mitchell:ml:book:1997；
- en: •
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: a nice introduction and summary by Domingos domingos:things:know:2012; and
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Domingos的精彩介绍和总结 domingos:things:know:2012；以及
- en: •
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: a recent, complete and comprehensive book about deep learning by Goodfellow
    et al. goodfellow:deep:learning:book:2016.
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于深度学习的最新、完整且全面的书籍 Goodfellow 等著 goodfellow:deep:learning:book:2016。
- en: 2 Other Models
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2 其他模型
- en: We have to remember that there are various other models and techniques for using
    computers to generate music, such as rules, grammars, automata, Markov models
    and graphical models. These models are either manually defined by experts or are
    automatically learnt from examples by using various machine learning techniques.
    They will not be addressed in this book as we are concerned here with deep learning
    techniques. However, in the following section we make a quick comparison of deep
    learning and Markov models.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须记住，除了马尔可夫模型和图形模型外，还有许多其他模型和技术用于生成音乐，例如规则、语法、自动机等。这些模型要么由专家手动定义，要么通过各种机器学习技术从示例中自动学习。由于本书关注的是深度学习技术，因此这些模型不会在书中讨论。然而，在接下来的部分中，我们将对深度学习和马尔可夫模型进行快速比较。
- en: 3 Deep Learning versus Markov Models
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3 深度学习与马尔可夫模型的比较
- en: 'Deep learning models are not the only models able to learn musical style from
    examples. Markov chain models are also widely used, see, for example, pachet:continuator:ieee:cga:2004.
    A quick comparison (inspired by the analysis of Mozer in mozer:composition:prediction:1994^(14)^(14)14Note
    that he made his analysis in in 1994, long before the deep learning wave.) of
    the pros (+) and cons (–) of deep neural network models and Markov chain models
    is as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型并不是唯一能够从示例中学习音乐风格的模型。马尔可夫链模型也被广泛使用，例如，参见 pachet:continuator:ieee:cga:2004。一个关于深度神经网络模型和马尔可夫链模型优缺点的快速比较（灵感来源于
    Mozer 的分析 mozer:composition:prediction:1994^(14)^(14)14请注意，他的分析是在1994年完成的，远在深度学习浪潮之前。）如下：
- en: '[–]'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[–]'
- en: +
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: +
- en: Markov models are conceptually simple.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫模型在概念上简单。
- en: +
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: +
- en: Markov models have a simple implementation and a simple learning algorithm,
    as the model is a transition probability table^(15)^(15)15Statistics are collected
    from the dataset of examples in order to compute the probabilities..
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫模型具有简单的实现和学习算法，因为该模型是一个转移概率表^(15)^(15)15统计数据是从示例数据集中收集的，用于计算概率。
- en: –
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: –
- en: Neural network models are conceptually simple but the optimized implementations
    of current deep network architectures may be complex and need a lot of tuning.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络模型在概念上简单，但当前深度网络架构的优化实现可能复杂且需要大量调优。
- en: –
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: –
- en: Order 1 Markov models (that is, considering only the previous state) do not
    capture long-term temporal structures.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 一阶马尔可夫模型（即只考虑前一个状态）无法捕捉长期的时间结构。
- en: –
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: –
- en: Order n Markov models (considering n previous states) are possible but require
    an explosive training set size^(16)^(16)16See the discussion in (mozer:composition:prediction:1994,
    page 249). and can lead to plagiarism^(17)^(17)17By recopying too long sequences
    from the corpus. Some promising solution is to consider a variable order Markov
    model and to constrain the generation (through min order and max order constraints)
    on some sweet spot between junk and plagiarism papadopoulos:maxorder:universality:book:2016..
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: n阶马尔可夫模型（考虑前n个状态）是可能的，但需要巨大的训练集^(16)^(16)16参见 (mozer:composition:prediction:1994，第249页)
    并且可能导致抄袭^(17)^(17)17通过从语料库中抄袭过长的序列。一些有前途的解决方案是考虑变阶马尔可夫模型，并通过最小阶和最大阶约束来限制生成（在垃圾和抄袭之间找到某个甜点）。
    papadopoulos:maxorder:universality:book:2016。
- en: +
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: +
- en: Neural networks can capture various types of relations, contexts and regularities.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络可以捕捉各种类型的关系、上下文和规律。
- en: +
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: +
- en: Deep networks can learn long-term and high-order dependencies.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 深度网络可以学习长期和高阶依赖关系。
- en: +
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: +
- en: Markov models can learn from a few examples.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫模型可以从少量示例中学习。
- en: –
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: –
- en: Neural networks need a lot of examples in order to be able to learn well.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络需要大量示例才能很好地学习。
- en: –
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: –
- en: Markov models do not generalize very well.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫模型的泛化能力较差。
- en: +
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: +
- en: Neural networks generalize better through the use of distributed representations
    hinton:boltzmann:machines:pdp:1986.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络通过分布式表示的使用具有更好的泛化能力 hinton:boltzmann:machines:pdp:1986。
- en: +
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: +
- en: Markov models are operational models (automata) on which some control on the
    generation could be attached^(18)^(18)18Examples are Markov constraints pachet:markov:constraints:constraints:2011
    and factor graphs pachet:variations:structured:ismir:2017..
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫模型是可附加某些生成控制的操作模型（自动机）^(18)^(18)18例如马尔可夫约束 pachet:markov:constraints:constraints:2011
    和因子图 pachet:variations:structured:ismir:2017。
- en: –
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: –
- en: Deep networks are generative models with a distributed representation and therefore
    with no direct control to be attached^(19)^(19)19This issue as well as some possible
    solutions will be discussed in Section LABEL:section:challenges:strategies:control:dimensions:strategies..
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 深度网络是具有分布式表示的生成模型，因此没有直接控制机制可以附加^(19)^(19)19此问题及一些可能的解决方案将在第LABEL:section:challenges:strategies:control:dimensions:strategies节中讨论。
- en: As deep learning implementations are now mature and a large number of examples
    are available, deep learning-based models are in high demand for their characteristics.
    That said, other models (such as Markov chains, graphical models, etc.) are still
    useful and used and the choice of a model and its tuning depends on the characteristics
    of the problem.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习实现的成熟和大量示例的出现，基于深度学习的模型因其特性而需求旺盛。尽管如此，其他模型（如马尔可夫链、图形模型等）仍然有用并且被使用，模型的选择及其调整取决于问题的特性。
- en: 4 Requisites and Roadmap
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4 个必要条件和路线图
- en: This book does not require prior knowledge about deep learning and neural networks
    nor music.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 本书不要求读者具备深度学习、神经网络或音乐方面的先验知识。
- en: Chapter 1 Introduction (this chapter) introduces the purpose and rationale of
    the book.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 第1章 引言（本章）介绍了本书的目的和基本原理。
- en: Chapter [1](#Ch1 "Chapter 1 Method") Method introduces the method of analysis
    (conceptual framework) and the five dimensions at its basis (objective, representation,
    architecture, challenge and strategy), dimensions that we discuss within the next
    four chapters.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 第[1](#Ch1 "第1章 方法")章 方法介绍了分析方法（概念框架）及其基础上的五个维度（目标、表示、架构、挑战和策略），这些维度将在接下来的四章中讨论。
- en: Chapter LABEL:section:chapter:objective Objective concerns the different types
    of musical content that we want to generate (such as a melody or an accompaniment
    to an existing melody)^(20)^(20)20Our proposed typology of possible objectives
    will turn out to be useful for our analysis because, as we will see, different
    objectives can lead to different architectures and strategies., as well as their
    expected use (by a human and/or a machine).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 第LABEL:section:chapter:objective章 目标涉及我们希望生成的不同类型的音乐内容（如旋律或对现有旋律的伴奏）^(20)^(20)20我们提出的可能目标类型将对我们的分析有用，因为正如我们将看到的，不同的目标可以导致不同的架构和策略，以及其预期的使用（由人类和/或机器）。
- en: Chapter LABEL:section:chapter:representation Representation provides an analysis
    of the different types of representation and techniques for encoding musical content
    (such as notes, durations or chords) for a deep learning architecture. This chapter
    may be skipped by a reader already expert in computer music, although some of
    the encoding strategies are specific to neural networks and deep learning architectures.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 第LABEL:section:chapter:representation章 表示提供了对不同类型表示和编码音乐内容（如音符、时值或和弦）技术的分析，以适用于深度学习架构。本章可由已经精通计算机音乐的读者跳过，尽管一些编码策略对神经网络和深度学习架构是特定的。
- en: Chapter LABEL:section:chapter:architecture Architecture summarizes the most
    common deep learning architectures (such as feedforward, recurrent or autoencoder)
    used for the generation of music. This includes a short reminder of the very basics
    of a simple neural network. This chapter may be skipped by a reader already expert
    in artificial neural networks and deep learning architectures.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 第LABEL:section:chapter:architecture章 架构总结了用于音乐生成的最常见的深度学习架构（如前馈、递归或自编码器）。包括对简单神经网络基本知识的简短回顾。本章可由已经精通人工神经网络和深度学习架构的读者跳过。
- en: Chapter LABEL:section:chapter:challenges:strategies Challenge and Strategy provides
    an analysis of the various challenges that occur when applying deep learning techniques
    to music generation, as well as various strategies for addressing them. We will
    ground our study in the analysis of various systems and experiments surveyed from
    the literature. This chapter is the core of the book.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 第LABEL:section:chapter:challenges:strategies章 挑战与策略提供了在应用深度学习技术于音乐生成时所遇到的各种挑战的分析，以及应对这些挑战的各种策略。我们将以从文献中调查的各种系统和实验的分析为基础。该章是本书的核心。
- en: Chapter LABEL:section:chapter:analysis Analysis summarizes the survey and analysis
    conducted in Chapter LABEL:section:chapter:challenges:strategies through some
    tables as a way to identify the design decisions and their interrelations for
    the different systems surveyed^(21)^(21)21And hopefully also for the future ones.
    If we draw the analogy (at some meta-level) with the expected ability for a model
    learnt from a corpus by a machine to be able to generalize to future examples
    (see Section LABEL:section:architecture:training:overfitting), we hope that the
    conceptual framework presented in this book, (manually) inducted from a corpus
    of scientific and technical literature about deep-learning-based music generation
    systems, will also be able to help in the design and the understanding of future
    systems..
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 第LABEL章:部分:章:分析 分析总结了第LABEL章:部分:章:挑战:策略中进行的调查和分析，通过一些表格来识别不同系统的设计决策及其相互关系^(21)^(21)21并希望对未来的系统也有所帮助。如果我们在某种元层面上将其与期望模型从语料库中学习的能力进行类比，期望其能够推广到未来的示例（见第LABEL章:部分:架构:训练:过拟合），我们希望本书中提出的概念框架（从深度学习音乐生成系统的科学和技术文献语料库中手动引导出来）也能在未来系统的设计和理解中提供帮助。
- en: Chapter LABEL:section:chapter:discussion:conclusion Discussion and Conclusion
    revisits some of the open issues that were touched in during the analysis of challenges
    and strategies presented in Chapter LABEL:section:chapter:challenges:strategies,
    before concluding this book.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 第LABEL章:部分:章:讨论:结论 讨论与结论回顾了在第LABEL章:部分:章:挑战:策略中分析挑战和策略时提到的一些未解问题，然后对本书进行总结。
- en: A table of contents, a table of acronyms, a list of references, a glossary and
    an index complete this book.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 书末附有目录、缩略语表、参考文献列表、术语表和索引。
- en: 'Supplementary material is provided at the following companion web site:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 附加材料可在以下伴随网站获取：
- en: www.briot.info/dlt4mg/
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: www.briot.info/dlt4mg/
- en: 5 Limits
  id: totrans-176
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5 限制
- en: This book does not intend to be a general introduction to deep learning – a
    recent and broad spectrum book on this topic is goodfellow:deep:learning:book:2016.
    We do not intend to get into all technical details of implementation, like engineering
    and tuning, as well as theory^(22)^(22)22For instance, we will not develop the
    probability theory and information theory frameworks for formalizing and interpreting
    the behavior of neural networks and deep learning. However, Section LABEL:section:architecture:neural:network:entropy
    will introduce the intuition behind the notions of entropy and cross-entropy,
    used for measuring the progress made during learning., as we wish to focus on
    the conceptual level, whilst providing a sufficient degree of precision. Also,
    although having a clear pedagogical objective, we do not provide some end-to-end
    tutorial with all the steps and details on how to implement and tune a complete
    deep learning-based music generation system.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 本书并不打算成为深度学习的通用介绍——最近的一本关于这一主题的全面书籍是goodfellow:deep:learning:book:2016。我们不打算涉及所有实施的技术细节，如工程和调整，以及理论^(22)^(22)22例如，我们不会展开神经网络和深度学习行为的概率论和信息论框架。然而，第LABEL章:部分:架构:神经:网络:熵
    将介绍熵和交叉熵的直觉，这些概念用于衡量学习过程中取得的进展。我们希望专注于概念层面，同时提供足够的精确度。此外，尽管有明确的教学目标，我们并没有提供有关如何实施和调整完整的深度学习音乐生成系统的端到端教程及所有步骤和细节。
- en: Last, as this book is about a very active domain and as our survey and analysis
    is based on existing systems, our analysis is obviously not exhaustive. We have
    tried to select the most representative proposals and experiments, while new proposals
    are being presented at the time of our writing. Therefore, we encourage readers
    and colleagues to provide any feedback and suggestions for improving this survey
    and analysis which is a still ongoing project.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于本书涉及的是一个非常活跃的领域，并且我们的调查和分析基于现有系统，因此我们的分析显然不够全面。我们尽力选择了最具代表性的提案和实验，而新的提案在我们写作时正不断出现。因此，我们鼓励读者和同行提供反馈和建议，以改进本调查和分析，这是一个仍在进行的项目。
- en: Chapter 1 Method
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一章 方法
